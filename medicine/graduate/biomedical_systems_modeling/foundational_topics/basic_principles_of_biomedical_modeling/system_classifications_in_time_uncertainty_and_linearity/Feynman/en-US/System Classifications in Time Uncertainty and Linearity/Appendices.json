{
    "hands_on_practices": [
        {
            "introduction": "Many complex biomedical systems are inherently nonlinear, but their behavior near a stable equilibrium can often be approximated linearly. This practice asks you to investigate the limits of such an approximation in a cardiac cell model by directly testing the superposition principle. You will calculate the leading-order deviation from linear behavior, providing a concrete, quantitative measure of local nonlinearity. ",
            "id": "3934919",
            "problem": "A simplified current-balance model for a single cardiac myocyte near its resting potential is given by the membrane equation\n$$\nC_{\\mathrm{m}} \\frac{dV}{dt} \\;=\\; - I_{\\mathrm{ion}}(V) \\;+\\; I_{\\mathrm{stim}}(t),\n$$\nwhere $C_{\\mathrm{m}}$ is the membrane capacitance, $V$ is the transmembrane potential, $I_{\\mathrm{ion}}(V)$ is the net ionic current as a function of voltage, and $I_{\\mathrm{stim}}(t)$ is an externally applied stimulus current. Assume there exists a resting potential $V_{\\mathrm{r}}$ at zero stimulus, that is, $I_{\\mathrm{stim}}(t) \\equiv 0$ and $I_{\\mathrm{ion}}(V_{\\mathrm{r}})=0$. Introduce the local coordinate $v = V - V_{\\mathrm{r}}$ and suppose that, in a neighborhood of $v = 0$, the ionic current admits a second-order Taylor approximation\n$$\nI_{\\mathrm{ion}}(V_{\\mathrm{r}} + v) \\;=\\; G_{1} \\, v \\;+\\; K_{2} \\, v^{2} \\;+\\; \\text{higher-order terms},\n$$\nwith $G_{1} > 0$ and $K_{2}$ finite. Assume gating variables are quasi-stationary so that this reduction is valid over the time scale of interest.\n\nConsider constant (direct current) stimulus inputs of small amplitude. For a constant input $u \\in \\mathbb{R}$, the steady state $v^{\\ast}(u)$ satisfies\n$$\n0 \\;=\\; - G_{1} \\, v^{\\ast}(u) \\;-\\; K_{2} \\, \\big(v^{\\ast}(u)\\big)^{2} \\;+\\; u,\n$$\nneglecting higher-than-second-order terms. Let two small constant inputs be $u_{1} = \\epsilon \\, a$ and $u_{2} = \\epsilon \\, b$, where $\\epsilon > 0$ is a scalar amplitude parameter and $a, b \\in \\mathbb{R}$ are fixed, nonzero constants.\n\nDefine the non-superposition residual for the steady-state input-to-state mapping as\n$$\nr(\\epsilon) \\;=\\; v^{\\ast}\\!\\big(\\epsilon (a + b)\\big) \\;-\\; v^{\\ast}(\\epsilon a) \\;-\\; v^{\\ast}(\\epsilon b).\n$$\nUsing only the current-balance law above and the stated Taylor approximation, compute the leading-order coefficient\n$$\nS \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{r(\\epsilon)}{\\epsilon^{2}}\n$$\nin closed form as a function of $G_{1}$, $K_{2}$, $a$, and $b$. Your final answer must be a single analytical expression. Do not include units. No rounding is required. Based on the sign of $S$ and whether $S$ is zero or nonzero, the system can be classified locally in terms of linearity via the superposition principle, but you should report only the value of $S$ as your final answer.",
            "solution": "The problem has been validated and is deemed to be scientifically grounded, well-posed, and objective. All necessary information is provided, and the setup is free from contradictions or ill-defined terms. The problem is a standard exercise in nonlinear systems analysis applied to a simplified biophysical model.\n\nThe objective is to compute the leading-order non-superposition coefficient $S$ for the steady-state response of a cardiac myocyte model. The steady-state voltage deviation $v^{\\ast}(u)$ for a constant stimulus current $u$ is governed by the algebraic equation derived from the given membrane equation by setting the time derivative to zero, $dV/dt = 0$. The local coordinate is $v = V - V_{\\mathrm{r}}$, so $dV/dt = dv/dt$. At steady state, $dv/dt=0$. The stimulus is $I_{\\mathrm{stim}}(t) = u$. The ionic current is approximated as $I_{\\mathrm{ion}}(V_{\\mathrm{r}} + v) \\approx G_{1} v + K_{2} v^{2}$.\n\nSubstituting these into the membrane equation yields the steady-state condition:\n$$\n0 \\;=\\; -I_{\\mathrm{ion}}(V_{\\mathrm{r}} + v^{\\ast}) \\;+\\; u\n$$\nUsing the provided Taylor approximation for $I_{\\mathrm{ion}}$:\n$$\n0 \\;=\\; -(G_{1} v^{\\ast} + K_{2} (v^{\\ast})^{2}) \\;+\\; u\n$$\nRearranging gives the governing equation for the steady-state response $v^{\\ast}(u)$:\n$$\nG_{1} v^{\\ast}(u) + K_{2} \\big(v^{\\ast}(u)\\big)^{2} \\;=\\; u\n$$\nThis is a quadratic equation for $v^{\\ast}(u)$. Since the problem concerns small amplitude inputs $u$, we expect the response $v^{\\ast}(u)$ to be small as well. This suggests that we can find a solution for $v^{\\ast}(u)$ as a power series in $u$. This method, known as a perturbation expansion, is appropriate for this context. Let us assume an expansion of the form:\n$$\nv^{\\ast}(u) \\;=\\; c_{1} u + c_{2} u^{2} + c_{3} u^{3} + \\dots\n$$\nWe substitute this series into the governing equation:\n$$\nG_{1} \\left(c_{1} u + c_{2} u^{2} + \\dots \\right) + K_{2} \\left(c_{1} u + c_{2} u^{2} + \\dots \\right)^{2} \\;=\\; u\n$$\nNext, we expand the squared term and collect terms by powers of $u$:\n$$\nG_{1} c_{1} u + G_{1} c_{2} u^{2} + \\dots + K_{2} \\left( (c_{1}u)^{2} + 2(c_{1}u)(c_{2}u^{2}) + \\dots \\right) \\;=\\; u\n$$\n$$\nG_{1} c_{1} u + G_{1} c_{2} u^{2} + \\dots + K_{2} c_{1}^{2} u^{2} + \\dots \\;=\\; u\n$$\nGrouping coefficients for each power of $u$:\n$$\n(G_{1} c_{1} - 1) u + (G_{1} c_{2} + K_{2} c_{1}^{2}) u^{2} + O(u^{3}) \\;=\\; 0\n$$\nFor this identity to hold for all small $u$, the coefficient of each power of $u$ must be zero.\n\nEquating the coefficient of $u^{1}$ to zero:\n$$\nG_{1} c_{1} - 1 \\;=\\; 0 \\quad \\implies \\quad c_{1} \\;=\\; \\frac{1}{G_{1}}\n$$\nThis coefficient $c_{1}$ represents the linear response of the system, as determined by the transmembrane conductance $G_{1}$.\n\nEquating the coefficient of $u^{2}$ to zero:\n$$\nG_{1} c_{2} + K_{2} c_{1}^{2} \\;=\\; 0 \\quad \\implies \\quad G_{1} c_{2} \\;=\\; -K_{2} c_{1}^{2}\n$$\nSubstituting the value of $c_{1}$:\n$$\nG_{1} c_{2} \\;=\\; -K_{2} \\left(\\frac{1}{G_{1}}\\right)^{2} \\;=\\; -\\frac{K_{2}}{G_{1}^{2}} \\quad \\implies \\quad c_{2} \\;=\\; -\\frac{K_{2}}{G_{1}^{3}}\n$$\nThis second-order coefficient $c_{2}$ captures the leading-order nonlinear effects.\n\nThus, the series expansion for the steady-state response up to the second order in $u$ is:\n$$\nv^{\\ast}(u) \\;=\\; \\frac{1}{G_{1}} u - \\frac{K_{2}}{G_{1}^{3}} u^{2} + O(u^{3})\n$$\nThe problem defines the non-superposition residual as $r(\\epsilon) = v^{\\ast}(\\epsilon (a + b)) - v^{\\ast}(\\epsilon a) - v^{\\ast}(\\epsilon b)$. We can now use our series expansion for $v^{\\ast}$ to find an expression for $r(\\epsilon)$. We substitute $u = \\epsilon(a+b)$, $u = \\epsilon a$, and $u = \\epsilon b$ into the expansion.\n\nFor $u = \\epsilon(a+b)$:\n$$\nv^{\\ast}(\\epsilon(a+b)) \\;=\\; \\frac{1}{G_{1}}(\\epsilon(a+b)) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon(a+b))^{2} + O(\\epsilon^{3})\n$$\nFor $u = \\epsilon a$:\n$$\nv^{\\ast}(\\epsilon a) \\;=\\; \\frac{1}{G_{1}}(\\epsilon a) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon a)^{2} + O(\\epsilon^{3})\n$$\nFor $u = \\epsilon b$:\n$$\nv^{\\ast}(\\epsilon b) \\;=\\; \\frac{1}{G_{1}}(\\epsilon b) - \\frac{K_{2}}{G_{1}^{3}}(\\epsilon b)^{2} + O(\\epsilon^{3})\n$$\n\nNow, we compute $r(\\epsilon)$:\n$$\nr(\\epsilon) \\;=\\; \\left[ \\frac{\\epsilon(a+b)}{G_{1}} - \\frac{K_{2}\\epsilon^{2}(a+b)^{2}}{G_{1}^{3}} \\right] - \\left[ \\frac{\\epsilon a}{G_{1}} - \\frac{K_{2}\\epsilon^{2}a^{2}}{G_{1}^{3}} \\right] - \\left[ \\frac{\\epsilon b}{G_{1}} - \\frac{K_{2}\\epsilon^{2}b^{2}}{G_{1}^{3}} \\right] + O(\\epsilon^{3})\n$$\nWe group the terms by powers of $\\epsilon$.\nThe terms of order $\\epsilon^{1}$ are:\n$$\n\\frac{\\epsilon(a+b)}{G_{1}} - \\frac{\\epsilon a}{G_{1}} - \\frac{\\epsilon b}{G_{1}} \\;=\\; \\frac{\\epsilon}{G_{1}}(a+b-a-b) \\;=\\; 0\n$$\nAs expected, the linear terms cancel, because a linear system would obey superposition perfectly, resulting in a zero residual.\n\nThe terms of order $\\epsilon^{2}$ are:\n$$\n-\\frac{K_{2}\\epsilon^{2}(a+b)^{2}}{G_{1}^{3}} - \\left(-\\frac{K_{2}\\epsilon^{2}a^{2}}{G_{1}^{3}}\\right) - \\left(-\\frac{K_{2}\\epsilon^{2}b^{2}}{G_{1}^{3}}\\right) \\;=\\; -\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} \\left[ (a+b)^{2} - a^{2} - b^{2} \\right]\n$$\nExpanding the binomial term $(a+b)^{2} = a^{2} + 2ab + b^{2}$:\n$$\n-\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} \\left[ (a^{2} + 2ab + b^{2}) - a^{2} - b^{2} \\right] \\;=\\; -\\frac{K_{2}\\epsilon^{2}}{G_{1}^{3}} (2ab) \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2}\n$$\nSo, the leading-order behavior of the residual is:\n$$\nr(\\epsilon) \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2} + O(\\epsilon^{3})\n$$\nFinally, we compute the desired limit $S$:\n$$\nS \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{r(\\epsilon)}{\\epsilon^{2}} \\;=\\; \\lim_{\\epsilon \\to 0} \\frac{-\\frac{2K_{2}ab}{G_{1}^{3}}\\epsilon^{2} + O(\\epsilon^{3})}{\\epsilon^{2}} \\;=\\; \\lim_{\\epsilon \\to 0} \\left( -\\frac{2K_{2}ab}{G_{1}^{3}} + O(\\epsilon) \\right)\n$$\n$$\nS \\;=\\; -\\frac{2K_{2}ab}{G_{1}^{3}}\n$$\nThis expression is the leading-order coefficient that quantifies the failure of superposition for the steady-state response, arising from the quadratic nonlinearity $K_{2}v^{2}$ in the ionic current model.",
            "answer": "$$\n\\boxed{-\\frac{2K_{2}ab}{G_{1}^{3}}}\n$$"
        },
        {
            "introduction": "For Linear Time-Invariant (LTI) systems, it is tempting to believe that a stable input-output response implies a fully stable system. This problem presents a critical counterexample using a two-compartment drug model, forcing you to confront the difference between external (BIBO) stability and internal stability. By analyzing the system's controllability and observability, you will discover how unstable internal dynamics can be 'hidden' from the input and output, a crucial concept for ensuring the safety and robustness of any modeled system. ",
            "id": "3934917",
            "problem": "A biomedical engineer models a two-compartment continuous-time drug-regulation subsystem obtained by linearization around a nominal operating point. The state vector is $x(t) = \\begin{bmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{bmatrix}$, where $x_{2}(t)$ is the measured plasma drug concentration and $x_{1}(t)$ is a latent regulatory activity that may undergo pathological self-amplification. The infusion input is $u(t)$ and the measured output is $y(t) = x_{2}(t)$. The model is\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t), \\quad D = 0,\n$$\nwith\n$$\nA = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad C = \\begin{bmatrix} 0 & 1 \\end{bmatrix},\n$$\nwhere $\\alpha = 0.3 \\,\\text{h}^{-1}$ represents a self-amplifying latent regulatory mode and $\\beta = 1.0 \\,\\text{h}^{-1}$ models first-order clearance of the drug. Assume zero initial conditions for the input-output (external) analysis, consistent with the definition of Bounded-Input, Bounded-Output (BIBO) stability, and consider asymptotic internal stability in the sense of the autonomous state matrix $A$ being Hurwitz.\n\nNow suppose there is small structural uncertainty in the physiological couplings, modeled as additive perturbations to $A$ and $C$:\n$$\n\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}, \\quad \\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix},\n$$\nwith $|\\delta_{12}| \\leq 10^{-2}$, $|\\delta_{21}| \\leq 10^{-2}$, and $|\\varepsilon| \\leq 10^{-2}$. The perturbations capture weak bidirectional couplings and slight sensor cross-talk that may render previously latent dynamics externally visible or driven.\n\nUsing only fundamental definitions for Linear Time-Invariant (LTI) systems (transfer function, BIBO stability defined via poles of the transfer function in the open left-half plane, internal stability defined by the eigenvalues of $A$ lying in the open left-half plane, and the concepts of controllability/observability and minimal realizations), determine the correct classification of the baseline model and its discrepancy between external and internal notions of stability, together with the correct time and uncertainty interpretations.\n\nWhich option is correct?\n\nA. The baseline system is continuous-time LTI and BIBO stable, but internally unstable because $A$ has an unstable eigenvalue. The discrepancy arises from a non-minimal realization: the unstable mode is both unobservable and uncontrollable relative to $(B,C)$, so it cancels from the transfer function. The external stability is fragile: arbitrarily small $\\delta_{12}$, $\\delta_{21}$, or $\\varepsilon$ can render the unstable mode externally connected, introducing a right-half-plane pole in the transfer function and destroying BIBO stability.\n\nB. The baseline system is discrete-time and nonlinear, and therefore BIBO stability implies internal stability; hence both notions agree and the system is stable internally and externally. The discrepancy cannot occur in this case.\n\nC. The baseline system is continuous-time LTI and minimal but has a right-half-plane zero; it is BIBO stable yet internally unstable due to the non-minimum-phase zero, and this behavior is robust to small uncertainty.\n\nD. The baseline system is continuous-time LTI and BIBO unstable because of the unstable eigenvalue of $A$; internal instability and BIBO instability coincide, and the external instability is robust to small uncertainty in $A$ and $C$.",
            "solution": "The user has provided a problem to be validated and solved.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   **System Type**: Continuous-time two-compartment drug-regulation subsystem, linearized.\n-   **State Vector**: $x(t) = \\begin{bmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{bmatrix}$.\n-   **Input**: $u(t)$.\n-   **Output**: $y(t) = x_{2}(t)$.\n-   **Baseline State-Space Model**:\n    -   $\\dot{x}(t) = A x(t) + B u(t)$\n    -   $y(t) = C x(t)$\n    -   $D = 0$\n-   **Baseline Matrices and Constants**:\n    -   $A = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix}$ with $\\alpha = 0.3 \\,\\text{h}^{-1}$ and $\\beta = 1.0 \\,\\text{h}^{-1}$.\n    -   $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$.\n    -   $C = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$.\n-   **Initial Conditions**: Zero for input-output analysis.\n-   **Stability Definitions**:\n    -   Bounded-Input, Bounded-Output (BIBO) stability: Poles of the transfer function are in the open left-half complex plane.\n    -   Internal stability: Eigenvalues of the state matrix $A$ are in the open left-half complex plane (i.e., $A$ is Hurwitz).\n-   **Perturbed Model**:\n    -   $\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}$.\n    -   $\\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix}$.\n-   **Perturbation Bounds**: $|\\delta_{12}| \\leq 10^{-2}$, $|\\delta_{21}| \\leq 10^{-2}$, and $|\\varepsilon| \\leq 10^{-2}$.\n-   **Objective**: Classify the baseline model, explain the discrepancy between internal and external stability, and analyze the effect of small structural uncertainty using fundamental LTI system concepts.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientifically Grounded**: The problem uses a standard linear time-invariant (LTI) state-space representation, a cornerstone of systems and control theory. The context is a linearized compartment model from biomedical engineering, which is a standard and valid application. The given parameters are physically plausible.\n2.  **Well-Posed**: The problem is fully specified. All matrices, parameters, and definitions (internal vs. external stability, controllability, observability) are provided and are standard in the field. The question asks for a classification and analysis that can be uniquely determined from the given information.\n3.  **Objective**: The language is precise, technical, and free of subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is scientifically sound, well-posed, and objective. It is a valid problem in LTI systems theory. Proceeding to solution.\n\n### Solution Derivation\n\nThe analysis proceeds in three parts: (1) analysis of the baseline system's stability properties, (2) analysis of its minimality (controllability and observability), and (3) analysis of the effect of the small perturbations.\n\n**1. Baseline System Stability Analysis**\n\nThe baseline system is a continuous-time LTI system described by the matrices $A$, $B$, $C$.\n\n-   **Internal Stability**: Internal stability is determined by the eigenvalues of the state matrix $A$.\n    $$A = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} 0.3 & 0 \\\\ 0 & -1.0 \\end{bmatrix}$$\n    Since $A$ is a diagonal matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 0.3$ and $\\lambda_2 = -1.0$.\n    The eigenvalue $\\lambda_1 = 0.3$ is positive, so it lies in the open right-half of the complex plane (RHP). According to the provided definition, for a system to be internally stable, all eigenvalues of $A$ must lie in the open left-half plane (LHP). Therefore, the baseline system is **internally unstable**.\n\n-   **External (BIBO) Stability**: BIBO stability is determined by the poles of the system's transfer function, $H(s) = C(sI - A)^{-1}B + D$. Given $D=0$.\n    First, we find the inverse of $(sI - A)$:\n    $$sI - A = s\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} - \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} s - \\alpha & 0 \\\\ 0 & s + \\beta \\end{bmatrix}$$\n    $$(sI - A)^{-1} = \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} s+\\beta & 0 \\\\ 0 & s-\\alpha \\end{bmatrix}$$\n    Now, we compute the transfer function $H(s)$:\n    $$H(s) = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\left( \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} s+\\beta & 0 \\\\ 0 & s-\\alpha \\end{bmatrix} \\right) \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n    $$H(s) = \\frac{1}{(s-\\alpha)(s+\\beta)} \\begin{bmatrix} 0 & s-\\alpha \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n    $$H(s) = \\frac{s-\\alpha}{(s-\\alpha)(s+\\beta)}$$\n    A pole-zero cancellation occurs at $s=\\alpha$. The simplified transfer function is:\n    $$H(s) = \\frac{1}{s+\\beta} = \\frac{1}{s+1.0}$$\n    The poles of the transfer function are the roots of the denominator, which is $s = -\\beta = -1.0$. This pole is in the open LHP. According to the provided definition, the system is **BIBO stable**.\n\nThere is a discrepancy: the system is internally unstable but externally (BIBO) stable.\n\n**2. Minimality Analysis (Controllability and Observability)**\n\nThis discrepancy arises when a system realization is non-minimal, meaning some modes are either uncontrollable, unobservable, or both.\n\n-   **Controllability**: We check the rank of the controllability matrix $\\mathcal{C} = \\begin{bmatrix} B & AB \\end{bmatrix}$.\n    $$B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad AB = \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -\\beta \\end{bmatrix}$$\n    $$\\mathcal{C} = \\begin{bmatrix} 0 & 0 \\\\ 1 & -\\beta \\end{bmatrix}$$\n    The determinant is $\\det(\\mathcal{C}) = (0)(-\\beta) - (0)(1) = 0$. The rank of $\\mathcal{C}$ is $1$, which is less than the system order $n=2$. Thus, the system is **uncontrollable**. The unstable mode corresponding to eigenvalue $\\lambda_1 = \\alpha$ is associated with the state $x_1$, and the input $u$ only affects $x_2$ (via $B$), so the unstable mode cannot be controlled by the input.\n\n-   **Observability**: We check the rank of the observability matrix $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix}$.\n    $$C = \\begin{bmatrix} 0 & 1 \\end{bmatrix}, \\quad CA = \\begin{bmatrix} 0 & 1 \\end{bmatrix} \\begin{bmatrix} \\alpha & 0 \\\\ 0 & -\\beta \\end{bmatrix} = \\begin{bmatrix} 0 & -\\beta \\end{bmatrix}$$\n    $$\\mathcal{O} = \\begin{bmatrix} 0 & 1 \\\\ 0 & -\\beta \\end{bmatrix}$$\n    The determinant is $\\det(\\mathcal{O}) = (0)(-\\beta) - (1)(0) = 0$. The rank of $\\mathcal{O}$ is $1$, which is less than $n=2$. Thus, the system is **unobservable**. The unstable mode associated with state $x_1$ does not affect the output $y=x_2$ (via $C$), so its behavior is not visible at the output.\n\nSince the unstable mode at $s=\\alpha$ is both uncontrollable and unobservable, it is completely decoupled from the input-output dynamics. This leads to its cancellation in the transfer function, explaining why the internal instability is hidden from the external behavior. The state-space realization is non-minimal.\n\n**3. Perturbed System Analysis**\n\nNow we consider the perturbed system with matrices $\\tilde{A}$ and $\\tilde{C}$.\n$$\\tilde{A} = \\begin{bmatrix} \\alpha & \\delta_{12} \\\\ \\delta_{21} & -\\beta \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad \\tilde{C} = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix}$$\nThe new transfer function $\\tilde{H}(s) = \\tilde{C}(sI-\\tilde{A})^{-1}B$ is computed.\n$$sI - \\tilde{A} = \\begin{bmatrix} s-\\alpha & -\\delta_{12} \\\\ -\\delta_{21} & s+\\beta \\end{bmatrix}$$\n$$\\det(sI - \\tilde{A}) = (s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}$$\n$$(sI - \\tilde{A})^{-1} = \\frac{1}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}} \\begin{bmatrix} s+\\beta & \\delta_{12} \\\\ \\delta_{21} & s-\\alpha \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix} \\frac{1}{\\det(sI - \\tilde{A})} \\begin{bmatrix} s+\\beta & \\delta_{12} \\\\ \\delta_{21} & s-\\alpha \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\frac{1}{\\det(sI - \\tilde{A})} \\begin{bmatrix} \\varepsilon & 1 \\end{bmatrix} \\begin{bmatrix} \\delta_{12} \\\\ s-\\alpha \\end{bmatrix}$$\n$$\\tilde{H}(s) = \\frac{\\varepsilon\\delta_{12} + s-\\alpha}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}}$$\nThe poles of the perturbed system are the roots of the denominator, i.e., the eigenvalues of $\\tilde{A}$. For small perturbations, one root will be close to $\\alpha = 0.3$ and still be in the RHP. The zero of the transfer function is at $s_z = \\alpha - \\varepsilon\\delta_{12}$.\nThe pole-zero cancellation that occurred in the baseline system at $s=\\alpha$ will generally *not* occur in the perturbed system. For cancellation to happen, the zero $s_z$ must be equal to one of the poles. For arbitrary small, non-zero $\\delta_{12}, \\delta_{21}, \\varepsilon$, this coincidence is not guaranteed. For example, if we take $\\varepsilon=0$, $\\delta_{12} \\neq 0$, and $\\delta_{21} \\neq 0$, the transfer function becomes:\n$$\\tilde{H}(s) = \\frac{s-\\alpha}{(s-\\alpha)(s+\\beta) - \\delta_{12}\\delta_{21}}$$\nThe zero is at $s=\\alpha$, but the poles are no longer at $s=\\alpha$ and $s=-\\beta$. The RHP pole is approximately $s_p \\approx \\alpha + \\frac{\\delta_{12}\\delta_{21}}{\\alpha+\\beta}$. Since $s_p \\neq s_z$, the pole does not cancel. This RHP pole in the transfer function means the perturbed system is **BIBO unstable**. This demonstrates that the BIBO stability of the baseline system is **fragile** and not robust to small structural perturbations that break the perfect decoupling of the unstable mode.\n\n### Option-by-Option Analysis\n\n**A. The baseline system is continuous-time LTI and BIBO stable, but internally unstable because $A$ has an unstable eigenvalue. The discrepancy arises from a non-minimal realization: the unstable mode is both unobservable and uncontrollable relative to $(B,C)$, so it cancels from the transfer function. The external stability is fragile: arbitrarily small $\\delta_{12}$, $\\delta_{21}$, or $\\varepsilon$ can render the unstable mode externally connected, introducing a right-half-plane pole in the transfer function and destroying BIBO stability.**\n-   This statement accurately describes the baseline system as continuous-time LTI, BIBO stable, and internally unstable.\n-   It correctly identifies the cause of the stability discrepancy as a non-minimal realization where the unstable mode is both uncontrollable and unobservable, leading to a pole-zero cancellation.\n-   It correctly concludes that this situation is fragile, as small, generic perturbations break the cancellation, expose the RHP pole in the transfer function, and thus destroy BIBO stability.\n-   **Verdict: Correct.**\n\n**B. The baseline system is discrete-time and nonlinear, and therefore BIBO stability implies internal stability; hence both notions agree and the system is stable internally and externally. The discrepancy cannot occur in this case.**\n-   The system is explicitly defined as continuous-time ($\\dot{x}(t)$) and linear ($\\dot{x}=Ax+Bu$). This option mischaracterizes the system type.\n-   For LTI systems, internal stability implies BIBO stability. The converse is only true if the system is minimal, which is not the case here. The premise is flawed.\n-   **Verdict: Incorrect.**\n\n**C. The baseline system is continuous-time LTI and minimal but has a right-half-plane zero; it is BIBO stable yet internally unstable due to the non-minimum-phase zero, and this behavior is robust to small uncertainty.**\n-   The system is not minimal, as shown by the controllability and observability analyses.\n-   Internal instability is caused by a RHP eigenvalue (a pole of the state dynamics), not a RHP zero of the transfer function. Non-minimum-phase zeros affect transient response, not stability.\n-   The behavior is not robust; it is fragile, as shown by the analysis of the perturbed system.\n-   **Verdict: Incorrect.**\n\n**D. The baseline system is continuous-time LTI and BIBO unstable because of the unstable eigenvalue of $A$; internal instability and BIBO instability coincide, and the external instability is robust to small uncertainty in $A$ and $C$.**\n-   The baseline system is BIBO stable, not BIBO unstable. The unstable pole is cancelled.\n-   For the baseline system, internal instability and BIBO stability do not coincide. This is the central point of the problem.\n-   The premise that the baseline system is externally unstable is false.\n-   **Verdict: Incorrect.**\n\nAll parts of option A are rigorously supported by the derivation from first principles.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Real biological systems are never truly deterministic; they are subject to inherent randomness. This practice moves beyond ordinary differential equations to model a neuron's membrane potential with a stochastic differential equation (SDE) that includes state-dependent, or multiplicative, noise. You will use the tools of Itô calculus to derive the condition for mean-square stability, revealing the often counter-intuitive principle that noise itself can be a driving force of instability in a system. ",
            "id": "3934901",
            "problem": "Consider a linearized subthreshold membrane potential deviation $x(t)$ from a resting equilibrium for a single-compartment neuron under multiplicative synaptic drive, modeled as the Itô stochastic differential equation (SDE): \n$$\ndx(t)=a\\,x(t)\\,dt+\\sigma\\,x(t)\\,dW_t,\\quad x(0)=x_0,\n$$\nwhere $a$ and $\\sigma$ are real constants, $x_0$ is a nonrandom constant, and $W_t$ is a standard Wiener process (Brownian motion). Using only foundational definitions from Itô calculus and the definition of mean-square stability (that is, the condition under which $\\mathbb{E}[x(t)^2]\\to 0$ as $t\\to\\infty$), proceed as follows:\n\n1. Starting from the Itô formula for a twice-differentiable function and the quadratic variation of Brownian motion, derive the exact deterministic differential equation governing the second moment $m_2(t)=\\mathbb{E}[x(t)^2]$.\n\n2. Solve this differential equation in closed form to obtain the exponential growth/decay rate of $m_2(t)$, that is, the mean-square Lyapunov exponent $\\gamma_2$ defined by $m_2(t)=m_2(0)\\exp(\\gamma_2\\,t)$.\n\n3. From first principles, state the necessary and sufficient condition on $a$ and $\\sigma$ for mean-square stability, and identify the critical and unstable regimes based on the sign of $\\gamma_2$.\n\n4. Classify this neuronal system with respect to time dependence (time-invariant or time-varying), uncertainty (deterministic or stochastic), and linearity (linear or nonlinear) by appealing to the defining structural features of the drift and diffusion terms.\n\nReport as your final answer the exact analytic expression for the mean-square Lyapunov exponent $\\gamma_2$ in terms of $a$ and $\\sigma$. Express $\\gamma_2$ in $\\mathrm{s}^{-1}$. No numerical values are required and no rounding is necessary.",
            "solution": "The problem is valid. It is a well-posed, scientifically grounded, and objective problem in the field of stochastic differential equations applied to biophysical modeling. All necessary information is provided, and the tasks are clearly defined.\n\nWe are given the Itô stochastic differential equation (SDE) for the subthreshold membrane potential deviation $x(t)$:\n$$dx(t) = a\\,x(t)\\,dt + \\sigma\\,x(t)\\,dW_t, \\quad x(0) = x_0$$\nwhere $a$ and $\\sigma$ are real constants, $x_0$ is a nonrandom initial condition, and $W_t$ is a standard Wiener process.\n\n**1. Derivation of the ODE for the second moment $m_2(t)$**\n\nWe seek to find the differential equation governing the second moment, $m_2(t) = \\mathbb{E}[x(t)^2]$. We use the Itô formula, which describes the differential of a function of an Itô process. For a process $X_t$ following $dX_t = \\mu(X_t, t) dt + g(X_t, t) dW_t$ and a twice-differentiable function $f(X_t)$, Itô's formula states:\n$$df(X_t) = \\left( \\mu(X_t, t) \\frac{\\partial f}{\\partial X_t} + \\frac{1}{2} g(X_t, t)^2 \\frac{\\partial^2 f}{\\partial X_t^2} \\right) dt + g(X_t, t) \\frac{\\partial f}{\\partial X_t} dW_t$$\nThe term involving the second derivative arises from the fact that a Wiener process has a non-zero quadratic variation, heuristically $(dW_t)^2 = dt$.\n\nIn our case, the process is $x(t)$, a function of time $t$. The function of interest is $f(x) = x^2$. The drift and diffusion coefficients are $\\mu(x,t) = a x$ and $g(x,t) = \\sigma x$, respectively. The derivatives of $f(x)$ are:\n$$\n\\frac{\\partial f}{\\partial x} = 2x\n$$\n$$\n\\frac{\\partial^2 f}{\\partial x^2} = 2\n$$\nSubstituting these into Itô's formula, we obtain the SDE for $x(t)^2$:\n$$\nd(x^2) = \\left( (a x) (2x) + \\frac{1}{2} (\\sigma x)^2 (2) \\right) dt + (\\sigma x) (2x) dW_t\n$$\n$$\nd(x^2) = (2ax^2 + \\sigma^2 x^2) dt + 2\\sigma x^2 dW_t\n$$\n$$\nd(x^2) = (2a + \\sigma^2) x^2 dt + 2\\sigma x^2 dW_t\n$$\nTo find the equation for the mean $m_2(t) = \\mathbb{E}[x^2]$, we take the expectation of the integral form of this SDE. The integral form is:\n$$\nx(t)^2 - x(0)^2 = \\int_0^t (2a + \\sigma^2) x(s)^2 ds + \\int_0^t 2\\sigma x(s)^2 dW_s\n$$\nTaking the expectation of both sides:\n$$\n\\mathbb{E}[x(t)^2 - x(0)^2] = \\mathbb{E}\\left[\\int_0^t (2a + \\sigma^2) x(s)^2 ds\\right] + \\mathbb{E}\\left[\\int_0^t 2\\sigma x(s)^2 dW_s\\right]\n$$\nUsing the linearity of expectation and interchanging expectation and the time integral (Fubini-Tonelli theorem):\n$$\n\\mathbb{E}[x(t)^2] - \\mathbb{E}[x(0)^2] = \\int_0^t (2a + \\sigma^2) \\mathbb{E}[x(s)^2] ds + \\mathbb{E}\\left[\\int_0^t 2\\sigma x(s)^2 dW_s\\right]\n$$\nA fundamental property of Itô integrals is that the expectation of an Itô integral with respect to a Wiener process is zero, provided the integrand is a non-anticipating (adapted) process. Thus,\n$$\n\\mathbb{E}\\left[\\int_0^t 2\\sigma x(s)^2 dW_s\\right] = 0\n$$\nSubstituting $m_2(t) = \\mathbb{E}[x(t)^2]$ and $m_2(0) = \\mathbb{E}[x(0)^2] = \\mathbb{E}[x_0^2] = x_0^2$ (since $x_0$ is nonrandom), we get the integral equation:\n$$\nm_2(t) - m_2(0) = \\int_0^t (2a + \\sigma^2) m_2(s) ds\n$$\nDifferentiating both sides with respect to $t$ via the Fundamental Theorem of Calculus yields the deterministic ordinary differential equation (ODE) for the second moment:\n$$\n\\frac{d m_2(t)}{dt} = (2a + \\sigma^2) m_2(t)\n$$\n\n**2. Solution of the ODE and the Mean-Square Lyapunov Exponent $\\gamma_2$**\n\nThe derived ODE is a first-order linear homogeneous equation with a constant coefficient. The general solution is of the form:\n$$\nm_2(t) = C \\exp((2a + \\sigma^2)t)\n$$\nwhere $C$ is a constant of integration. We find $C$ using the initial condition $m_2(0) = x_0^2$:\n$$\nm_2(0) = C \\exp(0) = C \\implies C = m_2(0)\n$$\nThus, the closed-form solution for the second moment is:\n$$\nm_2(t) = m_2(0) \\exp((2a + \\sigma^2)t)\n$$\nThe problem defines the mean-square Lyapunov exponent $\\gamma_2$ by the relation $m_2(t) = m_2(0)\\exp(\\gamma_2 t)$. By direct comparison with our solution, we identify the exponent as:\n$$\n\\gamma_2 = 2a + \\sigma^2\n$$\nThe units of $a$ and $\\sigma^2$ must be $\\mathrm{s}^{-1}$ for dimensional consistency of the original SDE, so $\\gamma_2$ is in $\\mathrm{s}^{-1}$ as requested.\n\n**3. Condition for Mean-Square Stability**\n\nMean-square stability is defined as the condition under which $\\lim_{t\\to\\infty} \\mathbb{E}[x(t)^2] = 0$. Using our solution for $m_2(t)$:\n$$\n\\lim_{t\\to\\infty} m_2(t) = \\lim_{t\\to\\infty} m_2(0) \\exp(\\gamma_2 t) = 0\n$$\nAssuming a non-trivial initial condition $x_0 \\neq 0$, so $m_2(0) \\neq 0$, this limit is zero if and only if the argument of the exponential is negative, i.e., $\\gamma_2 < 0$.\nTherefore, the necessary and sufficient condition for mean-square stability is:\n$$\n2a + \\sigma^2 < 0\n$$\nThe regimes of stability are classified by the sign of $\\gamma_2$:\n- **Mean-Square Stable**: $\\gamma_2 < 0$, i.e., $2a + \\sigma^2 < 0$. The second moment exponentially decays to zero.\n- **Mean-Square Critical**: $\\gamma_2 = 0$, i.e., $2a + \\sigma^2 = 0$. The second moment remains constant: $m_2(t) = m_2(0)$.\n- **Mean-Square Unstable**: $\\gamma_2 > 0$, i.e., $2a + \\sigma^2 > 0$. The second moment grows exponentially without bound.\n\n**4. System Classification**\n\nWe classify the system based on the structure of its governing SDE, $dx(t) = a\\,x(t)\\,dt + \\sigma\\,x(t)\\,dW_t$.\n- **Time Dependence**: The coefficients $a$ and $\\sigma$ are constants. The drift term, $\\mu(x,t) = ax$, and the diffusion term, $g(x,t) = \\sigma x$, do not have explicit dependence on time $t$. Therefore, the system is **time-invariant** (or autonomous).\n- **Uncertainty**: The dynamics are driven by a standard Wiener process $W_t$, a source of randomness. The diffusion coefficient $g(x,t) = \\sigma x$ is non-zero (assuming $\\sigma \\neq 0$ and a non-trivial state $x \\neq 0$). The presence of this stochastic term means the system's evolution is not predictable with certainty. Therefore, the system is **stochastic**.\n- **Linearity**: The drift term $\\mu(x,t) = ax$ is a linear function of the state variable $x$. The diffusion term $g(x,t) = \\sigma x$ is also a linear function of $x$. An SDE is linear if both its drift and diffusion coefficients are linear in the state variable. This can be confirmed by checking for superposition. If $x_1(t)$ and $x_2(t)$ are two solutions, then any linear combination $y(t) = c_1 x_1(t) + c_2 x_2(t)$ also satisfies the SDE, as $dy = a(c_1 x_1 + c_2 x_2) dt + \\sigma(c_1 x_1 + c_2 x_2) dW_t = ay\\,dt + \\sigma y\\,dW_t$. Therefore, the system is **linear**.",
            "answer": "$$\n\\boxed{2a + \\sigma^2}\n$$"
        }
    ]
}