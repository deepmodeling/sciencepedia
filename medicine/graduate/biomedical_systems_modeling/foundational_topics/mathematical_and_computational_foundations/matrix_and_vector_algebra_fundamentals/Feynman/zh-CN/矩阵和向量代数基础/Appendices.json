{
    "hands_on_practices": [
        {
            "introduction": "在生物医学建模中，选择合适的基来表示数据或模型参数至关重要，尤其是在处理像扩散磁共振成像（dMRI）这样的高维数据时。本练习  将引导你实践 Gram-Schmidt 正交化过程，这是一个构建标准正交基的基本工具。更重要的是，本练习将揭示在处理现实世界中近乎共线的向量时，经典算法所面临的数值不稳定性问题。",
            "id": "3899444",
            "problem": "在扩散磁共振成像 (MRI) 中，一组扩散编码梯度方向可以表示为 $\\mathbb{R}^{3}$ 中的向量。当这些方向近似共线时，相应的设计矩阵会变得病态，需要进行正交归一化来稳定组织微观结构线性模型中的估计。考虑以下三个由一个小的正参数 $\\epsilon$ 参数化的扩散方向向量：\n$$\n\\mathbf{a}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{2} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix}, \\quad\n\\mathbf{a}_{3} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix},\n$$\n其中 $\\epsilon > 0$ 且 $\\epsilon \\ll 1$。令 $A = \\begin{pmatrix} \\mathbf{a}_{1}  \\mathbf{a}_{2}  \\mathbf{a}_{3} \\end{pmatrix} \\in \\mathbb{R}^{3 \\times 3}$。你的任务是：\n\n- 仅以欧几里得内积和正交投影的定义为出发点，应用 Gram–Schmidt 过程为 $A$ 的列空间求得一组标准正交基 $\\{\\mathbf{q}_{1}, \\mathbf{q}_{2}, \\mathbf{q}_{3}\\}$，并由此构成矩阵 $Q = \\begin{pmatrix} \\mathbf{q}_{1}  \\mathbf{q}_{2}  \\mathbf{q}_{3} \\end{pmatrix}$ 和上三角矩阵 $R$，使得 $A = QR$。\n- 明确指出 $R$ 的对角线元素 $r_{11}$、$r_{22}$ 和 $r_{33}$ 作为 $\\epsilon$ 的函数。\n- 从投影和有限精度计算的基本原理出发，解释为什么近线性相关（小的 $\\epsilon$）对经典 Gram–Schmidt 算法在数值上是有问题的，并讨论一种适用于生物医学系统建模工作流的原则性补救措施。\n- 对于最终报告的结果，提供 $R$ 的第三个对角线元素 $r_{33}$ 作为 $\\epsilon$ 的函数的解析表达式。\n\n将最终答案表示为关于 $\\epsilon$ 的闭式解析表达式。无需四舍五入。最终答案无单位，应写为单个数学表达式。",
            "solution": "我们从具有欧几里得内积的实内积空间 $\\mathbb{R}^{3}$ 中的定义开始。对于向量 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^{3}$，内积为 $\\langle \\mathbf{x}, \\mathbf{y} \\rangle = \\mathbf{x}^{\\top}\\mathbf{y}$，向量 $\\mathbf{v}$ 在非零向量 $\\mathbf{u}$ 上的正交投影为 $\\mathrm{proj}_{\\mathbf{u}}(\\mathbf{v}) = \\frac{\\langle \\mathbf{u}, \\mathbf{v} \\rangle}{\\langle \\mathbf{u}, \\mathbf{u} \\rangle} \\mathbf{u}$。Gram–Schmidt 过程通过迭代地减去投影并进行归一化，从输入向量 $\\mathbf{a}_{1}, \\mathbf{a}_{2}, \\mathbf{a}_{3}$ 构造标准正交向量 $\\mathbf{q}_{1}, \\mathbf{q}_{2}, \\mathbf{q}_{3}$。\n\n步骤 $1$：从 $\\mathbf{a}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ 开始。设\n$$\n\\mathbf{u}_{1} = \\mathbf{a}_{1}, \\quad r_{11} = \\|\\mathbf{u}_{1}\\|_{2} = \\sqrt{\\langle \\mathbf{u}_{1}, \\mathbf{u}_{1} \\rangle} = \\sqrt{1^{2} + 0^{2} + 0^{2}} = 1, \\quad \\mathbf{q}_{1} = \\frac{\\mathbf{u}_{1}}{r_{11}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n\n步骤 $2$：将 $\\mathbf{a}_{2} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix}$ 相对于 $\\mathbf{q}_{1}$ 进行正交化并归一化。计算\n$$\nr_{12} = \\langle \\mathbf{q}_{1}, \\mathbf{a}_{2} \\rangle = \\begin{pmatrix} 1  0  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} = 1,\n$$\n$$\n\\mathbf{u}_{2} = \\mathbf{a}_{2} - r_{12} \\mathbf{q}_{1} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} - 1 \\cdot \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ 0 \\end{pmatrix}.\n$$\n然后\n$$\nr_{22} = \\|\\mathbf{u}_{2}\\|_{2} = \\sqrt{0^{2} + \\epsilon^{2} + 0^{2}} = \\epsilon \\quad (\\text{给定 } \\epsilon > 0),\n$$\n且\n$$\n\\mathbf{q}_{2} = \\frac{\\mathbf{u}_{2}}{r_{22}} = \\frac{1}{\\epsilon} \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\n\n步骤 $3$：将 $\\mathbf{a}_{3} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix}$ 相对于 $\\mathbf{q}_{1}$ 和 $\\mathbf{q}_{2}$ 进行正交化并归一化。首先，\n$$\nr_{13} = \\langle \\mathbf{q}_{1}, \\mathbf{a}_{3} \\rangle = \\begin{pmatrix} 1  0  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix} = 1,\n$$\n$$\n\\mathbf{w}_{3} = \\mathbf{a}_{3} - r_{13} \\mathbf{q}_{1} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix}.\n$$\n接下来，\n$$\nr_{23} = \\langle \\mathbf{q}_{2}, \\mathbf{w}_{3} \\rangle = \\begin{pmatrix} 0  1  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix} = \\epsilon,\n$$\n$$\n\\mathbf{u}_{3} = \\mathbf{w}_{3} - r_{23} \\mathbf{q}_{2} = \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ \\epsilon^{2} \\end{pmatrix} - \\epsilon \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\epsilon^{2} \\end{pmatrix}.\n$$\n然后\n$$\nr_{33} = \\|\\mathbf{u}_{3}\\|_{2} = \\sqrt{0^{2} + 0^{2} + \\epsilon^{4}} = \\epsilon^{2},\n$$\n且\n$$\n\\mathbf{q}_{3} = \\frac{\\mathbf{u}_{3}}{r_{33}} = \\frac{1}{\\epsilon^{2}} \\begin{pmatrix} 0 \\\\ 0 \\\\ \\epsilon^{2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n\n汇总起来，标准正交基为\n$$\nQ = \\begin{pmatrix} \\mathbf{q}_{1}  \\mathbf{q}_{2}  \\mathbf{q}_{3} \\end{pmatrix} = \n\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix},\n$$\n上三角因子 $R$ 的元素为\n$$\nR = \\begin{pmatrix}\nr_{11}  r_{12}  r_{13} \\\\\n0  r_{22}  r_{23} \\\\\n0  0  r_{33}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n1  1  1 \\\\\n0  \\epsilon  \\epsilon \\\\\n0  0  \\epsilon^{2}\n\\end{pmatrix}.\n$$\n因此，明确地，$r_{11} = 1$，$r_{22} = \\epsilon$，$r_{33} = \\epsilon^{2}$。\n\n关于小 $\\epsilon$ 的数值问题：当 $\\epsilon \\ll 1$ 时，$A$ 的列向量近似共线，因此问题是病态的。在经典 Gram–Schmidt 算法中，对 $\\mathbf{a}_{2}$ 的正交化步骤执行的是对两个几乎相等的向量的减法，\n$$\n\\mathbf{u}_{2} = \\mathbf{a}_{2} - \\langle \\mathbf{q}_{1}, \\mathbf{a}_{2} \\rangle \\mathbf{q}_{1} = \\begin{pmatrix} 1 \\\\ \\epsilon \\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\epsilon \\\\ 0 \\end{pmatrix},\n$$\n这在有限精度算术中会在第一个分量上遭受灾难性抵消：相对于数值 $1$，机器精度 $u$ 级别的舍入误差可能会在 $\\mathbf{u}_{2}$ 的第一个分量中留下一个数量级为 $u$ 的伪残差。随后的归一化操作会把这个舍入误差的相对效应放大约 $1/\\epsilon$ 倍，因为 $\\|\\mathbf{u}_{2}\\|_{2} = \\epsilon$。类似地，$\\mathbf{u}_{3}$ 的计算涉及到从 $\\mathbf{w}_{3}$ 中减去一个大小为 $\\epsilon$ 的投影，留下一个范数为 $\\epsilon^{2}$ 的向量。当 $\\epsilon^{2} \\lesssim u$ 时，在较大分量尺度上累积的任何数量级为 $u$ 的舍入误差都可能主导真实信号，导致计算出的 $\\mathbf{q}_{j}$ 之间失去正交性，并且 $R$ 的对角线元素变得不可靠。特别地，当在双精度（其中 $u \\approx 2^{-53}$）下 $\\epsilon \\lesssim \\sqrt{u}$ 时，$r_{33} = \\epsilon^{2}$ 的量级接近机器精度，变得难以精确求解。\n\n一种原则性的补救措施是使用数值稳定的正交化方法，例如修正的 Gram–Schmidt 算法（它会根据当前的标准正交向量进行顺序重正交化，从而减少抵消）或 Householder 反射（它通过具有更优稳定性的正交变换来构造 $Q$）。在生物医学系统建模工作流中，特别是对于扩散 MRI 设计矩阵，将基于 Householder 的 $\\mathrm{QR}$ 分解与列主元法相结合，可以通过揭示数值秩和控制条件数来进一步减轻近相关性的影响。\n\n最后，根据以上推导，$R$ 的第三个对角线元素作为 $\\epsilon$ 的函数是\n$$\nr_{33}(\\epsilon) = \\epsilon^{2}.\n$$",
            "answer": "$$\\boxed{\\epsilon^{2}}$$"
        },
        {
            "introduction": "在建立了网络模型之后，我们需要理解其动态行为，特别是它如何放大或衰减输入信号。本练习  将矩阵视为一个改变状态向量的线性算子。通过计算诱导2-范数，你将学会如何量化系统对输入的“最坏情况”下的放大效应，这对于分析生物网络模型的稳定性和灵敏度至关重要。",
            "id": "3899454",
            "problem": "考虑一个微电路的线性时不变 (LTI) 网络模型，其状态向量为 $\\mathbf{x} \\in \\mathbb{R}^{5}$，局部受线性映射 $\\mathbf{x} \\mapsto A \\mathbf{x}$ 控制，其中 $A \\in \\mathbb{R}^{5 \\times 5}$ 是一个对称、无量纲的连接矩阵，表示无向耦合强度。$A$ 的第 $i$ 个对角线元素量化了子群体 $i$ 的内在自耦合，而每个非对角线元素量化了不同子群体之间的均匀双向耦合。具体来说，设\n$$\nA \\;=\\; \\frac{1}{5}\\begin{pmatrix}\n3  1  1  1  1 \\\\\n1  3  1  1  1 \\\\\n1  1  3  1  1 \\\\\n1  1  1  3  1 \\\\\n1  1  1  1  3 \\\\\n\\end{pmatrix}.\n$$\n从向量 2-范数 $\\|\\mathbf{x}\\|_{2} = \\sqrt{\\mathbf{x}^{\\top}\\mathbf{x}}$、诱导（算子）矩阵 2-范数\n$$\n\\|A\\|_{2} \\;=\\; \\sup_{\\|\\mathbf{x}\\|_{2} = 1} \\|A\\mathbf{x}\\|_{2},\n$$\n以及 $A$ 的奇异值（定义为 $A^{\\top}A$ 的特征值的平方根）这些核心定义出发，推导对称矩阵 $A$ 的 $\\|A\\|_{2}$ 表达式，并计算给定连接矩阵的 $\\|A\\|_{2}$。在你的推导中，仅使用这些基础定义以及关于 $A^{\\top}A$ 和全一矩阵特征值的经过充分检验的事实。简要论证所计算出的 $\\|A\\|_{2}$ 对于该微电路中瞬时线性映射 $\\mathbf{x} \\mapsto A\\mathbf{x}$ 下小输入扰动的最坏情况放大有何意义。将 $\\|A\\|_{2}$ 的最终数值表示为一个无单位的有理数，无需四舍五入。",
            "solution": "该问题陈述经评估是有效的。它在线性系统理论中有科学依据，是适定的、客观的、自洽的，并且可以通过数学方法验证。该问题要求在一个合理的应用背景下进行矩阵分析中的标准推导和计算。\n\n我们首先建立诱导 2-范数 $\\|A\\|_{2}$ 与对称矩阵 $A$ 的特征值之间的关系。诱导 2-范数的定义是\n$$\n\\|A\\|_{2} = \\sup_{\\|\\mathbf{x}\\|_{2} = 1} \\|A\\mathbf{x}\\|_{2}\n$$\n其中 $\\|\\mathbf{x}\\|_{2} = \\sqrt{\\mathbf{x}^{\\top}\\mathbf{x}}$。\n\n由于范数总是非负的，我们可以等价地处理其平方：\n$$\n\\|A\\|_{2}^2 = \\left( \\sup_{\\|\\mathbf{x}\\|_{2} = 1} \\|A\\mathbf{x}\\|_{2} \\right)^2 = \\sup_{\\|\\mathbf{x}\\|_{2} = 1} \\|A\\mathbf{x}\\|_{2}^2\n$$\n使用向量 2-范数的定义，我们可以重写上确界内的项：\n$$\n\\|A\\mathbf{x}\\|_{2}^2 = (A\\mathbf{x})^{\\top}(A\\mathbf{x}) = \\mathbf{x}^{\\top}A^{\\top}A\\mathbf{x}\n$$\n因此，我们有\n$$\n\\|A\\|_{2}^2 = \\sup_{\\|\\mathbf{x}\\|_{2} = 1} \\mathbf{x}^{\\top}(A^{\\top}A)\\mathbf{x}\n$$\n对于 $\\|\\mathbf{x}\\|_{2}=1$，表达式 $\\mathbf{x}^{\\top}(A^{\\top}A)\\mathbf{x}$ 是矩阵 $A^{\\top}A$ 的瑞利商。线性代数的一个基本结果表明，对称矩阵的瑞利商的上确界是其最大特征值。矩阵 $A^{\\top}A$ 总是对称的。设 $\\lambda_{\\max}(M)$ 表示一个兼容矩阵 $M$ 的最大特征值。那么，\n$$\n\\|A\\|_{2}^2 = \\lambda_{\\max}(A^{\\top}A)\n$$\n根据问题的定义，$A$ 的奇异值（记为 $\\sigma_i$）是 $A^{\\top}A$ 的特征值的平方根。最大奇异值为 $\\sigma_{\\max} = \\sqrt{\\lambda_{\\max}(A^{\\top}A)}$。因此，在一般情况下，$\\|A\\|_{2} = \\sigma_{\\max}(A)$。\n\n对于 $A$ 是对称矩阵的特定情况，我们有 $A^{\\top} = A$。平方范数的表达式变为：\n$$\n\\|A\\|_{2}^2 = \\lambda_{\\max}(A^{\\top}A) = \\lambda_{\\max}(A^2)\n$$\n如果 $\\lambda_i$ 是 $A$ 的特征值，对应的特征向量为 $\\mathbf{v}_i$，那么 $A\\mathbf{v}_i = \\lambda_i\\mathbf{v}_i$。再次应用 $A$ 得到 $A^2\\mathbf{v}_i = A(\\lambda_i\\mathbf{v}_i) = \\lambda_i(A\\mathbf{v}_i) = \\lambda_i(\\lambda_i\\mathbf{v}_i) = \\lambda_i^2\\mathbf{v}_i$。因此，$A^2$ 的特征值是 $A$ 的特征值的平方。$A^2$ 的最大特征值是这些平方值的最大值：\n$$\n\\lambda_{\\max}(A^2) = \\max_{i} (\\lambda_i^2) = (\\max_{i} |\\lambda_i|)^2\n$$\n将此代回范数的表达式中：\n$$\n\\|A\\|_{2}^2 = (\\max_{i} |\\lambda_i|)^2\n$$\n对两边取平方根，我们得到对称矩阵所需的表达式：\n$$\n\\|A\\|_{2} = \\max_{i} |\\lambda_i|\n$$\n这个量也被称为 $A$ 的谱半径。\n\n接下来，我们计算给定连接矩阵 $A$ 的特征值：\n$$\nA \\;=\\; \\frac{1}{5}\\begin{pmatrix}\n3  1  1  1  1 \\\\\n1  3  1  1  1 \\\\\n1  1  3  1  1 \\\\\n1  1  1  3  1 \\\\\n1  1  1  1  3 \\\\\n\\end{pmatrix}\n$$\n这个矩阵可以方便地用 $5 \\times 5$ 的单位矩阵 $I$ 和 $5 \\times 5$ 的全一矩阵 $J$ 来表示：\n$$\nA = \\frac{1}{5} (2I + J)\n$$\n$A$ 的特征值可以从 $J$ 的熟知特征值确定。矩阵 $J$ 的秩为 $1$。全一向量 $\\mathbf{v}_1 = [1, 1, 1, 1, 1]^{\\top}$ 是 $J$ 的一个特征向量，其特征值为 $5$，因为 $J\\mathbf{v}_1 = 5\\mathbf{v}_1$。$J$ 的零空间维数为 $5-1=4$。任何与 $\\mathbf{v}_1$ 正交的向量都位于零空间中，因此 $J$ 有一个重数为 $4$ 的特征值 $0$。\n\n对于常数 $c_1, c_2$，$J$ 的特征向量也是 $A = c_1 I + c_2 J$ 的特征向量。如果 $J\\mathbf{v} = \\lambda_J \\mathbf{v}$，那么\n$$\nA\\mathbf{v} = \\left(\\frac{2}{5}I + \\frac{1}{5}J\\right)\\mathbf{v} = \\frac{2}{5}I\\mathbf{v} + \\frac{1}{5}J\\mathbf{v} = \\frac{2}{5}\\mathbf{v} + \\frac{1}{5}\\lambda_J\\mathbf{v} = \\left(\\frac{2}{5} + \\frac{1}{5}\\lambda_J\\right)\\mathbf{v}\n$$\n所以 $A$ 的特征值（记为 $\\lambda_A$）由 $\\lambda_A = \\frac{2 + \\lambda_J}{5}$ 给出。\n\n对于特征值 $\\lambda_J = 5$（重数为 $1$），$A$ 的相应特征值是：\n$$\n\\lambda_1 = \\frac{2 + 5}{5} = \\frac{7}{5}\n$$\n对于特征值 $\\lambda_J = 0$（重数为 $4$），$A$ 的相应特征值是：\n$$\n\\lambda_{2,3,4,5} = \\frac{2 + 0}{5} = \\frac{2}{5}\n$$\n$A$ 的特征值集合是 $\\{\\frac{7}{5}, \\frac{2}{5}, \\frac{2}{5}, \\frac{2}{5}, \\frac{2}{5}\\}$。\n由于 $A$ 是对称的，它的 2-范数是其特征值绝对值的最大值：\n$$\n\\|A\\|_{2} = \\max\\left(\\left|\\frac{7}{5}\\right|, \\left|\\frac{2}{5}\\right|\\right) = \\frac{7}{5}\n$$\n值 $\\|A\\|_{2} = \\frac{7}{5} = 1.4$ 表示在瞬时线性映射 $\\mathbf{x} \\mapsto A\\mathbf{x}$ 下，任何状态向量 $\\mathbf{x}$ 的大小的最大放大因子。根据定义，$\\|A\\|_{2} = \\sup_{\\mathbf{x} \\neq \\mathbf{0}} \\frac{\\|A\\mathbf{x}\\|_{2}}{\\|\\mathbf{x}\\|_{2}}$。在对系统状态施加小扰动 $\\delta\\mathbf{x}$ 的背景下，范数 $\\|A\\|_{2}$ 给出了扰动幅度瞬时放大的最坏情况。$\\|A\\|_{2} > 1$ 的值表明，状态空间中存在一些方向，扰动会沿着这些方向被放大。在这个模型中，扰动最多可以被放大 $1.4$ 倍。这种最坏情况下的放大发生在扰动与对应最大特征值 $\\lambda_1 = 7/5$ 的特征向量（即全一向量 $[1, 1, 1, 1, 1]^{\\top}$）对齐时。",
            "answer": "$$\\boxed{\\frac{7}{5}}$$"
        },
        {
            "introduction": "最后一个练习将前面的概念与生物医学建模中的一个核心挑战联系起来：如何从充满噪声和相关的测量数据中获得可靠的参数估计。通过分析一个病态的线性系统 ，你将亲眼看到预测变量之间的共线性如何导致估计量方差的急剧膨胀。接着，你将应用一种基于矩阵代数的解决方案——Tikhonov 正则化——来稳定估计结果，从而体会到矩阵理论在稳健数据分析中的强大作用。",
            "id": "3899461",
            "problem": "一个生物医学化学计量传感系统使用三个光谱通道，根据测量模型 $y = A x + \\varepsilon$ 估计收集在向量 $x \\in \\mathbb{R}^{2}$ 中的两种代谢物浓度，其中 $y \\in \\mathbb{R}^{3}$，$A \\in \\mathbb{R}^{3 \\times 2}$，且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{3})$。由于光谱特征重叠，$A$ 的列是高度共线的。设列向量为 $a_{1}, a_{2} \\in \\mathbb{R}^{3}$，满足 $\\|a_{1}\\|_{2} = \\|a_{2}\\|_{2} = 1$ 且内积 $a_{1}^{\\top} a_{2} = s = 0.999$，因此格拉姆 (Gram) 矩阵为 $G = A^{\\top} A = \\begin{pmatrix} 1  s \\\\ s  1 \\end{pmatrix}$。普通最小二乘 (OLS) 估计量 $\\hat{x}_{\\text{OLS}}$ 的协方差为 $\\operatorname{Cov}(\\hat{x}_{\\text{OLS}}) = \\sigma^{2} (A^{\\top} A)^{-1}$。岭 (Tikhonov) 估计量为 $\\hat{x}_{\\lambda} = (A^{\\top} A + \\lambda I_{2})^{-1} A^{\\top} y$，其协方差 $\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 由噪声模型和 $A$ 决定。\n\n从线性模型和这些定义出发：\n- 推导 $\\operatorname{Cov}(\\hat{x}_{\\text{OLS}})$ 关于 $s$ 和 $\\sigma^{2}$ 的闭式表达式，并计算当 $\\sigma^{2} = 1$ 和 $s = 0.999$ 时 $\\hat{x}_{\\text{OLS}}$ 两个分量的方差。\n- 利用对 $G$ 的谱分析，推导 $\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 的特征值作为 $G$ 的特征值和 $\\lambda$ 的函数。然后，确定最小的 $\\lambda > 0$，使得当 $\\sigma^{2} = 1$ 和 $s = 0.999$ 时，$\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 的最大特征值等于目标值 $v^{\\star} = 0.1$。\n\n将 $\\lambda$ 的最终数值四舍五入到四位有效数字。将 $\\lambda$ 表示为无量纲量。最终答案必须是一个数字。",
            "solution": "线性高斯模型 $y = A x + \\varepsilon$（其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{3})$）产生的普通最小二乘 (OLS) 估计量为 $\\hat{x}_{\\text{OLS}} = (A^{\\top} A)^{-1} A^{\\top} y$。在各向同性噪声下，任何线性估计量 $L y$ 的协方差为 $\\operatorname{Cov}(L y) = L \\operatorname{Cov}(y) L^{\\top} = \\sigma^{2} L L^{\\top}$。因此，对于 OLS，$\\operatorname{Cov}(\\hat{x}_{\\text{OLS}}) = \\sigma^{2} (A^{\\top} A)^{-1}$。\n\n首先，我们通过格拉姆 (Gram) 矩阵 $G = A^{\\top} A$ 分析 $A$ 中共线性的影响。给定 $\\|a_{1}\\|_{2} = \\|a_{2}\\|_{2} = 1$ 和 $a_{1}^{\\top} a_{2} = s$，格拉姆矩阵为\n$$\nG = \\begin{pmatrix} 1  s \\\\ s  1 \\end{pmatrix}.\n$$\n对于一个形如\n$$\n\\begin{pmatrix} \\alpha  \\beta \\\\ \\beta  \\alpha \\end{pmatrix}\n$$\n的 $2 \\times 2$ 对称矩阵，其逆矩阵（当 $\\alpha^{2} - \\beta^{2} \\neq 0$ 时）为\n$$\n\\frac{1}{\\alpha^{2} - \\beta^{2}} \\begin{pmatrix} \\alpha  -\\beta \\\\ -\\beta  \\alpha \\end{pmatrix}.\n$$\n将 $\\alpha = 1$ 和 $\\beta = s$ 应用于此，我们得到\n$$\nG^{-1} = \\frac{1}{1 - s^{2}} \\begin{pmatrix} 1  -s \\\\ -s  1 \\end{pmatrix}.\n$$\n因此，\n$$\n\\operatorname{Cov}(\\hat{x}_{\\text{OLS}}) = \\sigma^{2} G^{-1} = \\frac{\\sigma^{2}}{1 - s^{2}} \\begin{pmatrix} 1  -s \\\\ -s  1 \\end{pmatrix}.\n$$\n各分量的方差是其对角线元素：\n$$\n\\operatorname{Var}(\\hat{x}_{\\text{OLS},1}) = \\operatorname{Var}(\\hat{x}_{\\text{OLS},2}) = \\frac{\\sigma^{2}}{1 - s^{2}}.\n$$\n当 $\\sigma^{2} = 1$ 和 $s = 0.999$ 时，我们有 $s^{2} = 0.998001$ 和 $1 - s^{2} = 0.001999$，所以\n$$\n\\operatorname{Var}(\\hat{x}_{\\text{OLS},1}) = \\operatorname{Var}(\\hat{x}_{\\text{OLS},2}) = \\frac{1}{0.001999} \\approx 5.002501250625313 \\times 10^{2}.\n$$\n这表明近似共线性（$s \\approx 1$）会急剧增大了方差，因为 $1 - s^{2}$ 变得很小，使得 $G$ 成为病态矩阵。\n\n为了通过正则化提出补救措施，考虑岭估计量\n$$\n\\hat{x}_{\\lambda} = (A^{\\top} A + \\lambda I_{2})^{-1} A^{\\top} y,\n$$\n它是 $y$ 的线性函数，其中 $L_{\\lambda} = (A^{\\top} A + \\lambda I_{2})^{-1} A^{\\top}$。其协方差为\n$$\n\\operatorname{Cov}(\\hat{x}_{\\lambda}) = \\sigma^{2} L_{\\lambda} L_{\\lambda}^{\\top} = \\sigma^{2} (A^{\\top} A + \\lambda I_{2})^{-1} A^{\\top} A (A^{\\top} A + \\lambda I_{2})^{-1}.\n$$\n设 $G = A^{\\top} A$。由于 $G$ 是实对称半正定矩阵，它可以进行特征值分解\n$$\nG = U \\begin{pmatrix} \\mu_{1}  0 \\\\ 0  \\mu_{2} \\end{pmatrix} U^{\\top},\n$$\n其中 $U$ 是标准正交矩阵，特征值为 $\\mu_{1}, \\mu_{2} \\geq 0$。那么\n$$\nA^{\\top} A + \\lambda I_{2} = U \\begin{pmatrix} \\mu_{1} + \\lambda  0 \\\\ 0  \\mu_{2} + \\lambda \\end{pmatrix} U^{\\top},\n$$\n且\n$$\n(A^{\\top} A + \\lambda I_{2})^{-1} A^{\\top} A (A^{\\top} A + \\lambda I_{2})^{-1} = U \\begin{pmatrix} \\dfrac{\\mu_{1}}{(\\mu_{1} + \\lambda)^{2}}  0 \\\\ 0  \\dfrac{\\mu_{2}}{(\\mu_{2} + \\lambda)^{2}} \\end{pmatrix} U^{\\top}.\n$$\n因此，$\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 的特征值为\n$$\n\\sigma^{2} \\frac{\\mu_{i}}{(\\mu_{i} + \\lambda)^{2}}, \\quad i = 1,2.\n$$\n对于我们的 $G = \\begin{pmatrix} 1  s \\\\ s  1 \\end{pmatrix}$，其特征值是众所周知的：\n$$\n\\mu_{\\max} = 1 + s, \\quad \\mu_{\\min} = 1 - s.\n$$\n当 $s = 0.999$ 时，我们有\n$$\n\\mu_{\\max} = 1.999, \\quad \\mu_{\\min} = 0.001.\n$$\n题目要求我们选择最小的 $\\lambda > 0$，使得当 $\\sigma^{2} = 1$ 时，$\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 的最大特征值等于目标值 $v^{\\star} = 0.1$。$\\operatorname{Cov}(\\hat{x}_{\\lambda})$ 的最大特征值为\n$$\n\\max \\left\\{ \\sigma^{2} \\frac{\\mu_{\\min}}{(\\mu_{\\min} + \\lambda)^{2}}, \\ \\sigma^{2} \\frac{\\mu_{\\max}}{(\\mu_{\\max} + \\lambda)^{2}} \\right\\}.\n$$\n函数 $f(\\mu) = \\mu / (\\mu + \\lambda)^{2}$ 满足 $\\dfrac{\\partial f}{\\partial \\mu} = \\dfrac{\\lambda - \\mu}{(\\mu + \\lambda)^{3}}$。因此，当 $\\lambda > \\mu_{\\max}$ 时，$f(\\mu)$ 在 $[0, \\mu_{\\max}]$ 上是关于 $\\mu$ 的增函数，最大特征值在 $\\mu_{\\max}$ 处取得。我们将构造 $\\lambda$，使其满足 $\\lambda > \\mu_{\\max}$ 和\n$$\n\\sigma^{2} \\frac{\\mu_{\\max}}{(\\mu_{\\max} + \\lambda)^{2}} = v^{\\star}.\n$$\n解出 $\\lambda$ 可得\n$$\n\\mu_{\\max} + \\lambda = \\sqrt{\\frac{\\sigma^{2} \\mu_{\\max}}{v^{\\star}}} \\quad \\Longrightarrow \\quad \\lambda = \\sqrt{\\frac{\\sigma^{2} \\mu_{\\max}}{v^{\\star}}} - \\mu_{\\max}.\n$$\n代入 $\\sigma^{2} = 1$，$\\mu_{\\max} = 1.999$ 和 $v^{\\star} = 0.1$ 可得\n$$\n\\lambda = \\sqrt{\\frac{1 \\times 1.999}{0.1}} - 1.999 = \\sqrt{19.99} - 1.999.\n$$\n计算 $\\sqrt{19.99} \\approx 4.471017955$，所以\n$$\n\\lambda \\approx 4.471017955 - 1.999 = 2.472017955.\n$$\n我们验证 $\\lambda > \\mu_{\\max}$，因为 $2.472017955 > 1.999$，这与我们用来选择 $\\mu_{\\max}$ 作为最大化值的单调性条件是一致的。四舍五入到四位有效数字，\n$$\n\\lambda \\approx 2.472.\n$$\n这个岭参数将岭估计量协方差的最大特征值减小到目标值 $v^{\\star} = 0.1$，从而减轻了由 $A$ 列的共线性引起的方差膨胀。",
            "answer": "$$\\boxed{2.472}$$"
        }
    ]
}