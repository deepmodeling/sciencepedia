{
    "hands_on_practices": [
        {
            "introduction": "A mathematical model, particularly one derived from experimental data, is only as good as its physical realism. For compartmental systems, this realism is encoded in the structural properties of the system matrix. This exercise  challenges you to act as a model validator, testing whether an estimated matrix adheres to the fundamental rules of mass conservation and nonnegative transfer rates, a crucial step in building trustworthy biomedical models.",
            "id": "3877432",
            "problem": "Consider a linear, time-invariant multi-compartment model for drug distribution in three tissue compartments, represented by the Ordinary Differential Equation (ODE) system $\\dot{\\mathbf{x}} = A \\mathbf{x}$ with $\\mathbf{x} \\in \\mathbb{R}^3_{\\ge 0}$ denoting the vector of compartmental amounts. In a physically meaningful compartmental model, intercompartmental transfer rates are nonnegative and appear as off-diagonal coefficients, while diagonal entries represent net outflows and are nonpositive. Moreover, mass conservation and leakage constraints imply that for each compartment, the sum of the entries in its corresponding column represents the net loss to the exterior and must be nonpositive, and equal to zero when there is no elimination from that compartment.\n\nAn investigator estimates the following matrix $A$ from data:\n$$\n\\hat{A} \\;=\\;\n\\begin{bmatrix}\n-0.60  0.20  -0.05 \\\\\n0.40  -0.50  0.10 \\\\\n0.30  0.10  -0.20\n\\end{bmatrix}.\n$$\nAssess whether $\\hat{A}$ is consistent with a valid compartmental structure under the above physical constraints, and choose the statement that correctly evaluates validity and proposes a scientifically sound correction with minimal deviation from $\\hat{A}$, when violations are present.\n\nA. $\\hat{A}$ is not valid because $A_{13}  0$ violates the Metzler property and the column sum for column $1$ equals $-0.60 + 0.40 + 0.30 = 0.10  0$; a minimal correction is to set $A_{13} \\leftarrow 0$ and adjust the diagonal $A_{11} \\leftarrow -0.70$ so that all off-diagonals are nonnegative and column sums become $\\le 0$ (specifically, column $1$ sums to $0$, columns $2$ and $3$ remain nonpositive).\n\nB. $\\hat{A}$ is valid because all diagonal entries are negative and the sum of each row is nonpositive, which ensures nonincreasing total mass and positivity of $\\mathbf{x}$.\n\nC. $\\hat{A}$ is not valid due to $A_{13}  0$; it can be corrected by setting $A_{13} \\leftarrow +0.05$ and $A_{33} \\leftarrow -0.15$ to preserve the column $3$ sum at $0$, which then ensures a valid compartmental matrix.\n\nD. $\\hat{A}$ is not valid due to the positive column $1$ sum; a correction is to subtract $0.10$ from every element in column $1$, yielding $A_{11} = -0.70$, $A_{21} = 0.30$, $A_{31} = 0.20$, which resolves the column sum violation and yields a valid compartmental matrix without further changes.",
            "solution": "To solve this problem, we must assess the given matrix $\\hat{A}$ against the physical constraints of a compartmental model. A valid compartmental matrix $A$ must satisfy three key properties:\n1.  **Nonnegative off-diagonal entries:** $A_{ij} \\ge 0$ for $i \\ne j$. This reflects that mass transfer between compartments cannot be negative.\n2.  **Nonpositive diagonal entries:** $A_{ii} \\le 0$. This reflects that mass flows out of compartment $i$.\n3.  **Nonpositive column sums:** $\\sum_{i} A_{ij} \\le 0$ for all $j$. The sum of the $j$-th column represents the net rate of change of total system mass due to processes originating in compartment $j$. A nonpositive sum ensures that mass is not spontaneously created.\n\nLet's check the given matrix $\\hat{A}$:\n$$\n\\hat{A} \\;=\\;\n\\begin{bmatrix}\n-0.60  0.20  -0.05 \\\\\n0.40  -0.50  0.10 \\\\\n0.30  0.10  -0.20\n\\end{bmatrix}\n$$\n\n1.  **Off-diagonal entries:** The entry $A_{13} = -0.05$ is negative. This violates the first constraint. $\\hat{A}$ is not a valid compartmental matrix.\n2.  **Diagonal entries:** The diagonal entries ($-0.60, -0.50, -0.20$) are all nonpositive. This constraint is satisfied.\n3.  **Column sums:**\n    *   Column 1: $-0.60 + 0.40 + 0.30 = +0.10$. This sum is positive, violating the third constraint.\n    *   Column 2: $0.20 - 0.50 + 0.10 = -0.20$. This sum is nonpositive, so it is valid.\n    *   Column 3: $-0.05 + 0.10 - 0.20 = -0.15$. This sum is nonpositive, so it is valid.\n\nThe matrix $\\hat{A}$ is invalid due to two violations: a negative off-diagonal element ($A_{13}$) and a positive column sum (column 1).\n\nNow we evaluate the given options:\n\n**A.** This option correctly identifies both violations: $A_{13}  0$ and the positive sum of column 1. It proposes a correction: set $A_{13} \\leftarrow 0$ (the most minimal change to fix the negative value) and $A_{11} \\leftarrow -0.70$. Let's check the new column 1 sum: $-0.70 + 0.40 + 0.30 = 0$. This fixes the column sum violation. The new matrix would have all nonnegative off-diagonals, all nonpositive diagonals, and all nonpositive column sums. This is a valid and well-justified correction. This statement is correct.\n\n**B.** This option incorrectly claims $\\hat{A}$ is valid. It also gives incorrect reasoning, stating that row sums must be nonpositive. The relevant constraint is on column sums. Furthermore, the sum of row 3 is $0.30 + 0.10 - 0.20 = +0.20$, which is positive, so the premise is factually wrong. This statement is incorrect.\n\n**C.** This option correctly identifies the $A_{13}  0$ violation but fails to notice the positive column 1 sum. The proposed correction does not address the column 1 violation, so the resulting matrix would still be invalid. This statement is incorrect.\n\n**D.** This option correctly identifies the positive column 1 sum but fails to notice the $A_{13}  0$ violation. The proposed correction does not address the negative off-diagonal element, so the resulting matrix would still be invalid. This statement is incorrect.\n\nTherefore, only option A provides a complete and correct analysis and a valid correction.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond a valid structure, understanding a model requires knowing which parameters most influence its behavior over time. Normalized sensitivity analysis is a powerful tool for this purpose, revealing the dynamic 'levers' of the system. In this hands-on coding practice , you will implement a forward sensitivity analysis to quantify and rank parameter influence, providing insight into the optimal time windows for their estimation.",
            "id": "3877353",
            "problem": "Consider an intravenous bolus administration into a three-compartment pharmacokinetic model. Let the compartment amounts be denoted by $A_1(t)$, $A_2(t)$, and $A_3(t)$ in $\\mathrm{mg}$, with $A_1(0) = D$ and $A_2(0) = A_3(0) = 0$. The central compartment concentration is $C_1(t) = A_1(t)/V_1$ in $\\mathrm{mg/L}$, where $V_1$ is a known central volume in $\\mathrm{L}$. The intercompartmental and elimination rate constants are defined by $k_{12}$, $k_{21}$, $k_{13}$, $k_{31}$, and $k_{10}$ in $\\mathrm{h}^{-1}$. The mass balance ordinary differential equations (ODEs) are:\n$$\n\\frac{dA_1}{dt} = -\\left(k_{10}+k_{12}+k_{13}\\right)A_1 + k_{21}A_2 + k_{31}A_3,\n$$\n$$\n\\frac{dA_2}{dt} = k_{12}A_1 - k_{21}A_2,\n$$\n$$\n\\frac{dA_3}{dt} = k_{13}A_1 - k_{31}A_3.\n$$\nDefine the parameter vector $\\mathbf{p} = \\left[k_{12}, k_{21}, k_{13}, k_{31}, k_{10}\\right]$ and the scalar output $y(t) = C_1(t) = A_1(t)/V_1$. The normalized sensitivity coefficient of $y(t)$ with respect to parameter $p_j$ is:\n$$\nS_j(t) = \\frac{p_j}{y(t)}\\frac{\\partial y(t)}{\\partial p_j}.\n$$\nYour task is to compute $S_j(t)$ for all parameters in $\\mathbf{p}$ across a specified time grid using forward sensitivity analysis derived from the ODE system, then use these normalized sensitivities to:\n- rank parameter influence in three fixed time windows, and\n- propose time windows where specific parameters are best estimable.\n\nUse the following definitions and rules:\n1. The sensitivities of the states with respect to parameters satisfy the forward sensitivity equations:\n$$\n\\frac{d}{dt}\\left(\\frac{\\partial \\mathbf{A}}{\\partial p_j}\\right) = \\mathbf{J}(t)\\frac{\\partial \\mathbf{A}}{\\partial p_j} + \\frac{\\partial \\mathbf{f}}{\\partial p_j},\n$$\nwhere $\\mathbf{A} = \\left[A_1,A_2,A_3\\right]^\\top$, $\\mathbf{f} = \\left[f_1,f_2,f_3\\right]^\\top$ is the right-hand side of the ODEs, and $\\mathbf{J}(t) = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{A}}$ is the Jacobian matrix with respect to the states.\n2. The output sensitivity is $\\frac{\\partial y}{\\partial p_j}(t) = \\frac{1}{V_1}\\frac{\\partial A_1}{\\partial p_j}(t)$.\n3. If $y(t)$ is numerically very small, to avoid division by zero set $S_j(t) = 0$ whenever $y(t)  10^{-12} \\mathrm{mg/L}$.\n4. Define three fixed windows in hours: early window $[0,1]$, middle window $[1,8]$, and late window $[8,24]$; all times are in $\\mathrm{h}$. In each window, compute the mean of $\\left|S_j(t)\\right|$ over the time samples in that window and rank parameters by this mean; select the parameter index $j$ with the largest mean as the window's dominant parameter.\n5. To propose estimable time windows, declare a parameter $p_j$ to be \"dominant\" at time $t$ if $\\left|S_j(t)\\right|$ is strictly greater than the absolute normalized sensitivities of all other parameters at $t$, and $\\left|S_j(t)\\right| \\ge \\tau$, where $\\tau = 0.2$ is a threshold on absolute normalized sensitivity. For each parameter, identify the single longest contiguous time interval on the grid during which it is dominant under this rule; if no such interval exists, report $[-1.0,-1.0]$.\n\nFundamental base for derivation: use conservation of mass and first-order exchange/elimination kinetics as encoded in the ODEs, the definition of the Jacobian $\\mathbf{J}(t)$, and the forward sensitivity equations for parametric sensitivities of ODE solutions.\n\nImplement the computation on a uniform time grid from $t=0$ to $t=24$ hours with $501$ equally spaced points. Compute normalized sensitivities, perform window dominance ranking, and propose the longest dominance interval per parameter as described.\n\nPhysical units and numeric reporting requirements:\n- Report all times in hours ($\\mathrm{h}$).\n- Use the provided fixed windows in hours.\n- Round all reported time boundaries to three decimal places.\n\nTest suite and output specification:\n- Use intravenous bolus dose $D = 100 \\mathrm{mg}$ and known central volume $V_1 = 10 \\mathrm{L}$ for Test Case $1$, $V_1 = 20 \\mathrm{L}$ for Test Case $2$, $V_1 = 8 \\mathrm{L}$ for Test Case $3$, and $V_1 = 40 \\mathrm{L}$ for Test Case $4$.\n- Define four parameter sets to exercise coverage:\n    - Test Case $1$ (happy path): $\\left[k_{12},k_{21},k_{13},k_{31},k_{10}\\right] = [0.7, 0.4, 0.2, 0.1, 0.5] \\mathrm{h}^{-1}$, $V_1 = 10 \\mathrm{L}$.\n    - Test Case $2$ (slow peripheral exchange, boundary): $\\left[k_{12},k_{21},k_{13},k_{31},k_{10}\\right] = [0.05, 0.02, 0.01, 0.005, 0.6] \\mathrm{h}^{-1}$, $V_1 = 20 \\mathrm{L}$.\n    - Test Case $3$ (fast exchange and elimination, edge): $\\left[k_{12},k_{21},k_{13},k_{31},k_{10}\\right] = [3.0, 2.0, 1.0, 1.0, 2.5] \\mathrm{h}^{-1}$, $V_1 = 8 \\mathrm{L}$.\n    - Test Case $4$ (large central volume, balanced rates, edge): $\\left[k_{12},k_{21},k_{13},k_{31},k_{10}\\right] = [0.5, 0.5, 0.3, 0.3, 0.4] \\mathrm{h}^{-1}$, $V_1 = 40 \\mathrm{L}$.\n- For each test case, your program must produce a single list composed of:\n    - three integers for the dominant parameter indices in the early, middle, and late windows, respectively; indices are $0$ for $k_{12}$, $1$ for $k_{21}$, $2$ for $k_{13}$, $3$ for $k_{31}$, and $4$ for $k_{10}$,\n    - followed by ten floats giving the start and end times (rounded to three decimal places, in $\\mathrm{h}$) of the longest dominance intervals for parameters $k_{12}$, $k_{21}$, $k_{13}$, $k_{31}$, and $k_{10}$, in that order; if no dominance interval exists for a parameter, use $-1.0$ for both start and end.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $\\left[\\text{result1},\\text{result2},\\text{result3},\\text{result4}\\right]$), where each $\\text{resultX}$ is the list described above for the corresponding test case.\n\nThe program must be self-contained, take no input, and compute the required outputs according to the specification above.",
            "solution": "The solution is implemented by first formulating the augmented state-space model required for forward sensitivity analysis. The original system describes the time evolution of the drug amounts in three compartments, denoted by the state vector $\\mathbf{A}(t) = [A_1(t), A_2(t), A_3(t)]^\\top$. The dynamics are given by the linear ODE system $\\frac{d\\mathbf{A}}{dt} = \\mathbf{K}\\mathbf{A}$, where $\\mathbf{K}$ is the constant matrix of rate coefficients:\n$$\n\\mathbf{K} = \\begin{pmatrix}\n-\\left(k_{10}+k_{12}+k_{13}\\right)  k_{21}  k_{31} \\\\\nk_{12}  -k_{21}  0 \\\\\nk_{13}  0  -k_{31}\n\\end{pmatrix}\n$$\nThe sensitivity of the state vector $\\mathbf{A}(t)$ with respect to a parameter $p_j$ is the vector $\\mathbf{S}_j(t) = \\frac{\\partial \\mathbf{A}(t)}{\\partial p_j}$. Its dynamics are governed by the forward sensitivity equations:\n$$\n\\frac{d\\mathbf{S}_j}{dt} = \\mathbf{J}(t)\\mathbf{S}_j + \\frac{\\partial \\mathbf{f}}{\\partial p_j}\n$$\nwhere $\\mathbf{f}(\\mathbf{A}, \\mathbf{p}) = \\mathbf{K}\\mathbf{A}$ is the right-hand side of the state equations and $\\mathbf{J}(t) = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{A}}$ is the Jacobian matrix. Since the system is linear in $\\mathbf{A}$, the Jacobian $\\mathbf{J}$ is simply the matrix $\\mathbf{K}$.\n\nThe forcing terms $\\frac{\\partial \\mathbf{f}}{\\partial p_j}$ are derived for each of the five parameters $p_j$ in $\\mathbf{p} = [k_{12}, k_{21}, k_{13}, k_{31}, k_{10}]$:\n- For $p_0=k_{12}$: $\\frac{\\partial \\mathbf{f}}{\\partial k_{12}} = \\left[-A_1, A_1, 0\\right]^\\top$\n- For $p_1=k_{21}$: $\\frac{\\partial \\mathbf{f}}{\\partial k_{21}} = \\left[A_2, -A_2, 0\\right]^\\top$\n- For $p_2=k_{13}$: $\\frac{\\partial \\mathbf{f}}{\\partial k_{13}} = \\left[-A_1, 0, A_1\\right]^\\top$\n- For $p_3=k_{31}$: $\\frac{\\partial \\mathbf{f}}{\\partial k_{31}} = \\left[A_3, 0, -A_3\\right]^\\top$\n- For $p_4=k_{10}$: $\\frac{\\partial \\mathbf{f}}{\\partial k_{10}} = \\left[-A_1, 0, 0\\right]^\\top$\n\nWe construct an augmented ODE system of $3$ state equations and $5 \\times 3 = 15$ sensitivity equations, for a total of $18$ ODEs. The augmented state vector is $\\mathbf{Y}(t) = [\\mathbf{A}(t)^\\top, \\mathbf{S}_0(t)^\\top, \\dots, \\mathbf{S}_4(t)^\\top]^\\top$. The initial conditions are $A_1(0) = D$, $A_2(0) = A_3(0) = 0$, and $\\mathbf{S}_j(0) = \\mathbf{0}$ for all $j$, since the initial state does not depend on the rate parameters. This augmented system is solved numerically over a time grid from $t=0$ to $t=24$ hours with $501$ points.\n\nOnce the numerical solution for $\\mathbf{A}(t)$ and all $\\mathbf{S}_j(t)$ is obtained, we compute the normalized sensitivity coefficients for the output $y(t) = C_1(t) = A_1(t)/V_1$. The sensitivity coefficient is:\n$$\nS_j(t) = \\frac{p_j}{y(t)}\\frac{\\partial y(t)}{\\partial p_j} = \\frac{p_j}{A_1(t)/V_1} \\frac{1}{V_1} \\frac{\\partial A_1(t)}{\\partial p_j} = \\frac{p_j}{A_1(t)}\\frac{\\partial A_1(t)}{\\partial p_j}\n$$\nA special condition sets $S_j(t)=0$ if $y(t)  10^{-12}$ to ensure numerical stability.\n\nWith the time courses of all $S_j(t)$ computed, we perform two analyses:\n1.  **Window Ranking**: For each of the three time windows ($[0,1]$, $[1,8]$, $[8,24]$ hours), we calculate the mean of the absolute value of each sensitivity coefficient, $\\text{mean}(|S_j(t)|)$. The parameter with the highest mean value in a given window is designated as the dominant parameter for that window.\n2.  **Longest Dominance Interval**: For each parameter $p_j$, we search the time grid for the longest contiguous interval where it is \"dominant\". A parameter is dominant at time $t$ if its absolute normalized sensitivity $|S_j(t)|$ is strictly greater than all other $|S_k(t)|$ for $k \\ne j$, and $|S_j(t)|$ is greater than or equal to a threshold $\\tau = 0.2$. The start and end times of the longest such interval are found for each parameter. If no such interval exists, `[-1.0, -1.0]` is reported.",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the execution for all test cases.\n    \"\"\"\n    \n    def solve_for_case(case_params):\n        \"\"\"\n        Solves the full sensitivity analysis problem for a single test case.\n        \n        Args:\n            case_params (tuple): A tuple containing (p_vector, V1, D).\n        \n        Returns:\n            list: A list containing 3 dominant parameter indices and 10 floats for \n                  the start/end times of longest dominance intervals.\n        \"\"\"\n        p_vector, V1, D = case_params\n        k12, k21, k13, k31, k10 = p_vector\n\n        def ode_system(t, y):\n            # Unpack the 18-element state vector\n            A = y[0:3]                     # State variables A1, A2, A3\n            S_matrix = y[3:].reshape((5, 3)) # Sensitivity matrix (5 params x 3 states)\n\n            # Jacobian matrix (which is the rate constant matrix K)\n            K = np.array([\n                [-(k10 + k12 + k13), k21, k31],\n                [k12, -k21, 0],\n                [k13, 0, -k31]\n            ])\n\n            # State derivatives: dA/dt = K * A\n            dA_dt = K @ A\n\n            # Forcing terms for sensitivity equations: d(f)/d(p_j)\n            G = np.zeros((5, 3))\n            G[0, :] = [-A[0], A[0], 0]      # dF/dk12\n            G[1, :] = [A[1], -A[1], 0]      # dF/dk21\n            G[2, :] = [-A[0], 0, A[0]]      # dF/dk13\n            G[3, :] = [A[2], 0, -A[2]]      # dF/dk31\n            G[4, :] = [-A[0], 0, 0]         # dF/dk10\n\n            # Sensitivity derivatives: dS/dt = K*S + G\n            dS_dt = (K @ S_matrix.T).T + G\n            \n            # Flatten and return all derivatives\n            return np.concatenate([dA_dt, dS_dt.flatten()])\n\n        t_span = [0, 24]\n        t_eval = np.linspace(t_span[0], t_span[1], 501)\n        \n        y0 = np.zeros(18)\n        y0[0] = D\n\n        sol = solve_ivp(ode_system, t_span, y0, t_eval=t_eval, method='RK45', atol=1e-8, rtol=1e-6)\n        solution = sol.y\n\n        # Extract states and their sensitivities from the solution\n        A1 = solution[0, :]\n        # d(A1)/d(p_j) for j=0..4 are at indices 3, 6, 9, 12, 15\n        dA1_dp = solution[[3, 6, 9, 12, 15], :]\n\n        # Calculate normalized sensitivities, S_j(t)\n        C1 = A1 / V1\n        is_small_C1 = C1  1e-12\n        \n        # S_j = (p_j / C_1) * d(C_1)/d(p_j) = (p_j / A1) * d(A1)/d(p_j)\n        norm_sens = np.zeros_like(dA1_dp)\n        p_vec_col = np.array(p_vector, dtype=float).reshape(-1, 1)\n\n        valid_indices = np.where(~is_small_C1)[0]\n        if valid_indices.size  0:\n            A1_valid = A1[valid_indices]\n            dA1_dp_valid = dA1_dp[:, valid_indices]\n            \n            # Avoid division by zero, although C1 check should prevent this\n            A1_valid_safe = np.where(A1_valid == 0, 1e-15, A1_valid)\n            norm_sens[:, valid_indices] = (p_vec_col / A1_valid_safe) * dA1_dp_valid\n\n        # Task 1: Window Dominance Ranking\n        early_mask = (t_eval = 0)  (t_eval = 1)\n        middle_mask = (t_eval = 1)  (t_eval = 8)\n        late_mask = (t_eval = 8)  (t_eval = 24)\n\n        mean_abs_sens_early = np.mean(np.abs(norm_sens[:, early_mask]), axis=1)\n        mean_abs_sens_middle = np.mean(np.abs(norm_sens[:, middle_mask]), axis=1)\n        mean_abs_sens_late = np.mean(np.abs(norm_sens[:, late_mask]), axis=1)\n\n        dominant_indices = [\n            int(np.argmax(mean_abs_sens_early)),\n            int(np.argmax(mean_abs_sens_middle)),\n            int(np.argmax(mean_abs_sens_late))\n        ]\n\n        # Task 2: Longest Dominance Interval\n        abs_norm_sens = np.abs(norm_sens)\n        tau = 0.2\n        \n        max_sens_vals = np.max(abs_norm_sens, axis=0)\n        is_max_mask = (abs_norm_sens == max_sens_vals)\n        is_unique_max = np.sum(is_max_mask, axis=0) == 1\n        is_above_thresh = max_sens_vals = tau\n        dominant_mask = is_unique_max  is_above_thresh\n        \n        argmax_sens = np.argmax(abs_norm_sens, axis=0)\n        dominant_param_indices = -np.ones_like(t_eval, dtype=int)\n        dominant_param_indices[dominant_mask] = argmax_sens[dominant_mask]\n        \n        longest_intervals = []\n        for j in range(5):\n            is_j_dominant = (dominant_param_indices == j)\n            \n            if not np.any(is_j_dominant):\n                longest_intervals.append([-1.0, -1.0])\n                continue\n                \n            changes = np.diff(is_j_dominant.astype(int))\n            starts = np.where(changes == 1)[0] + 1\n            ends = np.where(changes == -1)[0]\n            \n            if is_j_dominant[0]:\n                starts = np.insert(starts, 0, 0)\n            if is_j_dominant[-1]:\n                ends = np.append(ends, len(is_j_dominant) - 1)\n            \n            if len(starts) == 0 or len(ends) == 0:\n                longest_intervals.append([-1.0, -1.0])\n                continue\n            \n            durations = t_eval[ends] - t_eval[starts]\n            max_dur_idx = np.argmax(durations)\n            start_idx = starts[max_dur_idx]\n            end_idx = ends[max_dur_idx]\n            \n            start_time = round(t_eval[start_idx], 3)\n            end_time = round(t_eval[end_idx], 3)\n            longest_intervals.append([start_time, end_time])\n\n        flat_intervals = [item for sublist in longest_intervals for item in sublist]\n        return dominant_indices + flat_intervals\n\n    # Define the test cases from the problem statement.\n    Dose = 100.0\n    test_cases = [\n        ([0.7, 0.4, 0.2, 0.1, 0.5], 10.0, Dose),\n        ([0.05, 0.02, 0.01, 0.005, 0.6], 20.0, Dose),\n        ([3.0, 2.0, 1.0, 1.0, 2.5], 8.0, Dose),\n        ([0.5, 0.5, 0.3, 0.3, 0.4], 40.0, Dose),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_for_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The power of sensitivity analysis comes from its ability to distinguish the effects of different parameters. But what happens when these effects become entangled? This exercise  explores the critical issue of practical non-identifiability, where collinear sensitivity functions make it impossible to estimate parameters reliably. You will analyze the consequences on the Fisher Information Matrix and evaluate various strategies to restore identifiability, a key skill for robust systems modeling.",
            "id": "3877374",
            "problem": "Consider a linear, two-compartment intravenous bolus model described by a system of Ordinary Differential Equations (ODEs) with micro-rate constants $k_{12}$, $k_{21}$, and $k_{10}$ and plasma volume $V$. Let the measured output be plasma concentration $C_{p}(t)$, sampled at times $t_1 = 0.5$, $t_2 = 1.0$, $t_3 = 1.5$, and $t_4 = 2.0$ (in consistent time units). Suppose the measurement errors are independent and identically distributed Gaussian with variance $\\sigma^2 = 0.01$ (in consistent concentration units squared). Around a nominal parameter vector, the local output sensitivities with respect to $\\theta_{1} = k_{12}$ and $\\theta_{2} = k_{21}$ are numerically obtained at these sampling times and are given by the two columns of the sensitivity matrix\n$$\nS = \n\\begin{bmatrix}\n1.00  0.99 \\\\\n2.00  1.98 \\\\\n3.00  2.97 \\\\\n4.00  3.96\n\\end{bmatrix}.\n$$\nYou are to analyze parameter identifiability and variance inflation under the standard local linearization and Gaussian noise assumptions for parameter estimation and propose mitigation strategies. Which of the following statements are correct? Select all that apply.\n\nA. Under local linearization with independent Gaussian measurement noise, the Fisher Information Matrix (FIM) $F$ for $(\\theta_{1}, \\theta_{2})$ equals $\\sigma^{-2} S^{\\top} S$. Because the two sensitivity columns are exactly collinear, $F$ is rank-deficient with one eigenvalue equal to $0$, and the Cramér–Rao lower bound implies that the variance of any unbiased estimator is unbounded along the unidentifiable direction.\n\nB. Augmenting the least squares objective with a Tikhonov (ridge) regularizer $\\lambda \\lVert \\theta \\rVert_{2}^{2}$ adds $\\lambda I$ to the normal matrix. This makes the effective information matrix $F + \\lambda I$ positive definite, reduces variance inflation, and introduces bias that depends on $\\lambda$.\n\nC. Rescaling parameters to normalize the sensitivity columns, i.e., replacing $S$ by $S D$ for a diagonal scaling matrix $D$ that makes each column have unit Euclidean norm, fully resolves identifiability and yields unbiased, finite-variance estimates for both parameters without changing the data.\n\nD. Replicating the same sampling schedule and measurements $m$ times independently reduces the smallest eigenvalue of $F$, thereby worsening variance inflation relative to the single-schedule case.\n\nE. Placing an informative Gaussian prior $\\theta \\sim \\mathcal{N}(\\theta_{0}, \\Sigma_{0})$ contributes prior precision $\\Sigma_{0}^{-1}$ to the information, so the posterior precision becomes $F + \\Sigma_{0}^{-1}$; if $\\Sigma_{0}^{-1}$ is nonsingular on the nullspace induced by collinearity, the zero eigenvalue is lifted and the posterior variance is finite.\n\nF. Redesigning the experiment to choose sampling times that more strongly and differentially excite the two compartments (e.g., targeting early transients for one rate constant and later phases for the other) can reduce sensitivity collinearity, improve the conditioning and determinant of $F$, and does not introduce bias in the absence of model misspecification.",
            "solution": "The core of the problem lies in the properties of the given sensitivity matrix $S$. Let the two columns of $S$ be $s_1$ and $s_2$. We observe that $s_2 = 0.99 \\cdot s_1$. The columns are exactly collinear, meaning they are linearly dependent, and the rank of $S$ is 1. The Fisher Information Matrix (FIM) for the parameter vector $\\theta = (\\theta_1, \\theta_2)$ is given by $F = \\sigma^{-2} S^{\\top} S$. Since the columns of $S$ are linearly dependent, the matrix $S^{\\top} S$ is singular (its determinant is zero), and therefore the FIM is also singular. A singular FIM indicates that the parameters are not locally identifiable from the given experimental data. The Cramér-Rao Lower Bound, which relies on the inverse of the FIM, implies that the variance for estimating at least one linear combination of the parameters is infinite. With this foundation, we evaluate each statement.\n\n**A.** This statement correctly identifies that the FIM is $F = \\sigma^{-2} S^{\\top} S$. It correctly concludes that due to collinearity, $F$ is rank-deficient and has a zero eigenvalue. This singularity implies an unbounded variance for any unbiased estimator along the unidentifiable direction, according to the Cramér-Rao lower bound. This statement is **correct**.\n\n**B.** Tikhonov (or ridge) regularization adds a penalty term $\\lambda \\lVert \\theta \\rVert_{2}^{2}$ to the least-squares objective. The Hessian of the resulting cost function is approximately $S^\\top S + \\lambda I$ (or a scaled version), which corresponds to an effective FIM of $F + \\lambda' I$. Since $F$ is positive semi-definite and $\\lambda' I$ is positive definite (for $\\lambda' > 0$), their sum is positive definite and thus invertible. This makes the variance finite, but at the cost of introducing bias that pulls the estimate towards the origin. This statement accurately describes the effect of Tikhonov regularization. This statement is **correct**.\n\n**C.** Rescaling the columns of $S$ to have unit norm does not change their direction. If $s_2 = 0.99 s_1$, the normalized columns $s'_1 = s_1/\\lVert s_1 \\rVert_2$ and $s'_2 = s_2/\\lVert s_2 \\rVert_2$ will be identical: $s'_2 = s'_1$. The new sensitivity matrix will still have perfectly collinear columns and a rank of 1. Therefore, rescaling cannot resolve the non-identifiability problem. This statement is **incorrect**.\n\n**D.** Replicating an experiment $m$ times results in a total FIM of $F_m = m F$. The eigenvalues of $F_m$ are $m$ times the eigenvalues of $F$. The smallest eigenvalue, which was zero, remains zero ($m \\cdot 0 = 0$). The non-zero eigenvalues increase, which corresponds to *more* information and *less* variance. The statement incorrectly claims the smallest eigenvalue is reduced and that variance inflation is worsened. This statement is **incorrect**.\n\n**E.** In a Bayesian framework, the posterior precision (inverse of posterior covariance) is the sum of the likelihood precision (the FIM, $F$) and the prior precision ($\\Sigma_{0}^{-1}$). If the prior is proper, its precision matrix $\\Sigma_{0}^{-1}$ is positive definite. The sum of a positive semi-definite matrix ($F$) and a positive definite matrix ($\\Sigma_{0}^{-1}$) is always positive definite. This guarantees the posterior precision is invertible, and the posterior variance is finite, thus \"lifting\" the zero eigenvalue. This statement is **correct**.\n\n**F.** The collinearity of sensitivities is a result of a suboptimal experimental design (i.e., the choice of sampling times). A different set of sampling times could yield sensitivity vectors that are less collinear. This is the goal of optimal experimental design (OED). A successful redesign would make the FIM non-singular or at least better conditioned, improving parameter identifiability and reducing estimation variance. This approach addresses the root cause of the problem and does not introduce estimation bias, unlike regularization methods. This statement is **correct**.\n\nTherefore, the correct statements are A, B, E, and F.",
            "answer": "$$\\boxed{ABEF}$$"
        }
    ]
}