{
    "hands_on_practices": [
        {
            "introduction": "This first practice is a foundational exercise designed to solidify your understanding of Lyapunov's direct method. You will directly apply this cornerstone of stability theory to a simple two-state biomedical model by solving the algebraic Lyapunov equation for a quadratic Lyapunov function $V(x) = x^{\\top} P x$. By computing the matrix $P$ that satisfies $A^{\\top}P + PA = -Q$, you will generate a concrete certificate of the system's asymptotic stability, bridging the gap between abstract theory and practical verification .",
            "id": "3930335",
            "problem": "A two-compartment biomedical regulation model is linearized around a nominal operating point, yielding a continuous-time Linear Time-Invariant (LTI) system of the form $\\dot{x}(t)=A\\,x(t)$, where $x(t)\\in\\mathbb{R}^{2}$ represents small perturbations of physiologically meaningful quantities (for example, concentrations or rates), and\n$$\nA=\\begin{bmatrix}-0.7  0.3 \\\\ -0.2  -0.5\\end{bmatrix}.\n$$\nConsider the candidate quadratic Lyapunov function $V(x)=x^{\\top}P\\,x$ with a symmetric matrix $P\\in\\mathbb{R}^{2\\times 2}$. Let $Q=I_{2}$, the identity matrix. From first principles, the continuous-time algebraic Lyapunov equation linking $A$, $P$, and $Q$ is\n$$\nA^{\\top}P + P A = -Q.\n$$\nYour tasks are:\n- Derive and solve for the entries of the symmetric matrix $P$ that satisfy the Lyapunov equation, starting from the definition of $V(x)$ and its time derivative along trajectories of $\\dot{x}(t)=A\\,x(t)$.\n- Using eigenvalue-based stability criteria for linear systems, justify why the existence of such a matrix $P$ with $P0$ certifies asymptotic stability of the origin for the given $A$.\n- As a quantitative certificate of positive definiteness, compute the smallest eigenvalue of $P$ in exact analytical form.\n\nReport as your final answer the smallest eigenvalue of $P$ as a single closed-form expression. No rounding is required, and the quantity is dimensionless.",
            "solution": "The problem statement is subjected to validation prior to any attempt at a solution.\n\n**Step 1: Extract Givens**\n- Continuous-time LTI system: $\\dot{x}(t)=A\\,x(t)$, with $x(t)\\in\\mathbb{R}^{2}$.\n- System matrix: $A=\\begin{bmatrix}-0.7  0.3 \\\\ -0.2  -0.5\\end{bmatrix}$.\n- Candidate quadratic Lyapunov function: $V(x)=x^{\\top}P\\,x$, with $P$ being a symmetric matrix in $\\mathbb{R}^{2\\times 2}$.\n- Auxiliary matrix: $Q=I_{2}$, the $2 \\times 2$ identity matrix.\n- Continuous-time algebraic Lyapunov equation: $A^{\\top}P + P A = -Q$.\n- Tasks:\n    1. Derive and solve for the entries of the symmetric matrix $P$.\n    2. Justify why the existence of $P0$ certifies asymptotic stability of the origin.\n    3. Compute the smallest eigenvalue of $P$ in exact analytical form.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, employing standard principles of linear systems theory and Lyapunov stability analysis. The concept of linearizing a biomedical regulation model is a valid and common practice in systems biology and control engineering.\n\nThe problem is well-posed. The stability of the matrix $A$ determines if a unique, positive definite solution $P$ exists for the Lyapunov equation. The eigenvalues $\\lambda$ of $A$ are given by the characteristic equation $\\det(A - \\lambda I) = 0$:\n$$ \\det\\begin{bmatrix}-0.7 - \\lambda  0.3 \\\\ -0.2  -0.5 - \\lambda\\end{bmatrix} = 0 $$\n$$ (-0.7 - \\lambda)(-0.5 - \\lambda) - (0.3)(-0.2) = 0 $$\n$$ \\lambda^2 + 0.5\\lambda + 0.7\\lambda + 0.35 + 0.06 = 0 $$\n$$ \\lambda^2 + 1.2\\lambda + 0.41 = 0 $$\nFor a second-order characteristic polynomial $\\lambda^2 + a_1\\lambda + a_0 = 0$, the system is asymptotically stable if and only if $a_1 > 0$ and $a_0 > 0$. Here, $a_1 = 1.2 > 0$ and $a_0 = 0.41 > 0$. Therefore, the matrix $A$ is Hurwitz, meaning all its eigenvalues have negative real parts. According to Lyapunov theory for LTI systems, for any symmetric positive definite matrix $Q$, the equation $A^{\\top}P + P A = -Q$ has a unique, symmetric, positive definite solution $P$. Since $Q=I_2$ is positive definite, the problem is well-posed and a unique solution for $P$ exists and is positive definite.\n\nThe problem is objective, complete, and contains no contradictions or unrealistic data.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A complete solution will be provided.\n\n**Solution Derivation**\n\nThe problem requires us to analyze the stability of the system $\\dot{x}(t) = A x(t)$ using the Lyapunov function $V(x) = x^{\\top}P x$.\n\n**Task 1: Derive and Solve for the Matrix P**\n\nFirst, we derive the Lyapunov equation from first principles. The time derivative of the Lyapunov function $V(x)$ along the system's trajectories is:\n$$ \\dot{V}(x) = \\frac{d}{dt}(x^{\\top}P x) = \\dot{x}^{\\top}P x + x^{\\top}P \\dot{x} $$\nSubstituting $\\dot{x} = Ax$:\n$$ \\dot{V}(x) = (Ax)^{\\top}P x + x^{\\top}P (Ax) $$\n$$ \\dot{V}(x) = x^{\\top}A^{\\top}P x + x^{\\top}P A x $$\n$$ \\dot{V}(x) = x^{\\top}(A^{\\top}P + PA)x $$\nThe Lyapunov stability theorem requires $\\dot{V}(x)$ to be negative definite. We enforce this by setting $A^{\\top}P + PA = -Q$, where $Q$ is a positive definite matrix. The problem specifies $Q=I_2$. This yields the continuous-time algebraic Lyapunov equation:\n$$ A^{\\top}P + PA = -I_2 $$\nNow we solve for the symmetric matrix $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$.\nThe matrix $A$ is $A=\\begin{bmatrix}-0.7  0.3 \\\\ -0.2  -0.5\\end{bmatrix}$ and its transpose is $A^{\\top}=\\begin{bmatrix}-0.7  -0.2 \\\\ 0.3  -0.5\\end{bmatrix}$.\n\nSubstituting $A$ and $P$ into the Lyapunov equation:\n$$ \\begin{bmatrix}-0.7  -0.2 \\\\ 0.3  -0.5\\end{bmatrix}\\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} + \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}\\begin{bmatrix}-0.7  0.3 \\\\ -0.2  -0.5\\end{bmatrix} = \\begin{bmatrix}-1  0 \\\\ 0  -1 \\end{bmatrix} $$\nPerforming the matrix multiplications:\n$$ \\begin{bmatrix} -0.7p_{11} - 0.2p_{12}  -0.7p_{12} - 0.2p_{22} \\\\ 0.3p_{11} - 0.5p_{12}  0.3p_{12} - 0.5p_{22} \\end{bmatrix} + \\begin{bmatrix} -0.7p_{11} - 0.2p_{12}  0.3p_{11} - 0.5p_{12} \\\\ -0.7p_{12} - 0.2p_{22}  0.3p_{12} - 0.5p_{22} \\end{bmatrix} = \\begin{bmatrix}-1  0 \\\\ 0  -1 \\end{bmatrix} $$\nSumming the matrices on the left-hand side gives:\n$$ \\begin{bmatrix} -1.4p_{11} - 0.4p_{12}  0.3p_{11} - 1.2p_{12} - 0.2p_{22} \\\\ 0.3p_{11} - 1.2p_{12} - 0.2p_{22}  0.6p_{12} - p_{22} \\end{bmatrix} = \\begin{bmatrix}-1  0 \\\\ 0  -1 \\end{bmatrix} $$\nEquating the corresponding entries yields a system of three linear equations for $p_{11}$, $p_{12}$, and $p_{22}$:\n1. $-1.4p_{11} - 0.4p_{12} = -1 \\implies 1.4p_{11} + 0.4p_{12} = 1 \\implies 7p_{11} + 2p_{12} = 5$\n2. $0.6p_{12} - p_{22} = -1 \\implies p_{22} = 0.6p_{12} + 1$\n3. $0.3p_{11} - 1.2p_{12} - 0.2p_{22} = 0 \\implies 3p_{11} - 12p_{12} - 2p_{22} = 0$\n\nSubstitute (2) into (3):\n$$ 3p_{11} - 12p_{12} - 2(0.6p_{12} + 1) = 0 $$\n$$ 3p_{11} - 12p_{12} - 1.2p_{12} - 2 = 0 $$\n$$ 3p_{11} - 13.2p_{12} = 2 $$\nWe now have a system of two equations for $p_{11}$ and $p_{12}$:\n(I) $7p_{11} + 2p_{12} = 5$\n(II) $3p_{11} - 13.2p_{12} = 2$\n\nFrom (I), $p_{11} = \\frac{5 - 2p_{12}}{7}$. Substitute this into (II):\n$$ 3\\left(\\frac{5 - 2p_{12}}{7}\\right) - 13.2p_{12} = 2 $$\nMultiply by $7$ to clear the denominator:\n$$ 3(5 - 2p_{12}) - 7(13.2)p_{12} = 14 $$\n$$ 15 - 6p_{12} - 92.4p_{12} = 14 $$\n$$ 1 = 98.4p_{12} \\implies p_{12} = \\frac{1}{98.4} = \\frac{10}{984} = \\frac{5}{492} $$\nNow we find $p_{11}$:\n$$ p_{11} = \\frac{5 - 2(\\frac{5}{492})}{7} = \\frac{5 - \\frac{10}{492}}{7} = \\frac{\\frac{5 \\times 492 - 10}{492}}{7} = \\frac{2460 - 10}{492 \\times 7} = \\frac{2450}{3444} = \\frac{350}{492} = \\frac{175}{246} $$\nFinally, we find $p_{22}$:\n$$ p_{22} = 0.6p_{12} + 1 = \\frac{6}{10} \\times \\frac{5}{492} + 1 = \\frac{30}{4920} + 1 = \\frac{3}{492} + 1 = \\frac{1}{164} + 1 = \\frac{165}{164} $$\nThe matrix $P$ is:\n$$ P = \\begin{bmatrix} \\frac{175}{246}  \\frac{5}{492} \\\\ \\frac{5}{492}  \\frac{165}{164} \\end{bmatrix} $$\nTo work with a common denominator, we use $492 = 2 \\times 246 = 3 \\times 164$.\n$$ P = \\begin{bmatrix} \\frac{350}{492}  \\frac{5}{492} \\\\ \\frac{5}{492}  \\frac{495}{492} \\end{bmatrix} = \\frac{1}{492}\\begin{bmatrix} 350  5 \\\\ 5  495 \\end{bmatrix} $$\n\n**Task 2: Justify Asymptotic Stability**\n\nAccording to Lyapunov's direct method, the equilibrium point $x=0$ of the system $\\dot{x}=Ax$ is globally asymptotically stable if there exists a scalar function $V(x)$ such that:\n1. $V(x)$ is positive definite, i.e., $V(0) = 0$ and $V(x) > 0$ for all $x \\neq 0$.\n2. $\\dot{V}(x)$ is negative definite, i.e., $\\dot{V}(x)  0$ for all $x \\neq 0$.\n\nFor our chosen Lyapunov function candidate $V(x) = x^{\\top}P x$, the first condition requires the matrix $P$ to be positive definite ($P \\succ 0$). The second condition requires its time derivative $\\dot{V}(x)$ to be negative definite. As shown previously, $\\dot{V}(x) = x^{\\top}(A^{\\top}P + PA)x$. By solving $A^{\\top}P + PA = -I$, we have enforced that $\\dot{V}(x) = -x^{\\top}I x = -x^{\\top}x = -\\|x\\|_2^2$. Since $\\|x\\|_2^2 > 0$ for any $x \\neq 0$, $\\dot{V}(x)$ is negative definite.\n\nThus, proving the asymptotic stability of the origin is reduced to certifying that the solution matrix $P$ is positive definite. A symmetric matrix is positive definite if and only if all its eigenvalues are strictly positive. The existence of such a matrix $P$ is a certificate of stability. This connects to the eigenvalue-based stability criterion for $A$: for an LTI system, the matrix $A$ is Hurwitz (all its eigenvalues have negative real parts) if and only if for any given symmetric positive definite matrix $Q$, there exists a unique symmetric positive definite solution $P$ to the Lyapunov equation $A^{\\top}P + PA = -Q$. Since we established that $A$ is Hurwitz, the existence of such a $P \\succ 0$ is guaranteed. By explicitly finding it, we are confirming the stability predicted by the eigenvalues of $A$.\n\n**Task 3: Compute the Smallest Eigenvalue of P**\n\nTo confirm that $P$ is positive definite, we compute its eigenvalues, denoted by $\\lambda_P$. The eigenvalues are the roots of the characteristic equation $\\det(P - \\lambda_P I) = 0$.\nIt is easier to first find the eigenvalues $\\mu$ of the scaled matrix $P' = 492P = \\begin{bmatrix} 350  5 \\\\ 5  495 \\end{bmatrix}$. The eigenvalues of $P$ will then be $\\lambda_P = \\mu / 492$.\n$$ \\det(P' - \\mu I) = \\det\\begin{bmatrix} 350 - \\mu  5 \\\\ 5  495 - \\mu \\end{bmatrix} = 0 $$\n$$ (350 - \\mu)(495 - \\mu) - 5^2 = 0 $$\n$$ \\mu^2 - (350 + 495)\\mu + (350 \\times 495) - 25 = 0 $$\n$$ \\mu^2 - 845\\mu + 173250 - 25 = 0 $$\n$$ \\mu^2 - 845\\mu + 173225 = 0 $$\nWe solve this quadratic equation for $\\mu$ using the quadratic formula:\n$$ \\mu = \\frac{-(-845) \\pm \\sqrt{(-845)^2 - 4(1)(173225)}}{2(1)} $$\n$$ \\mu = \\frac{845 \\pm \\sqrt{714025 - 692900}}{2} = \\frac{845 \\pm \\sqrt{21125}}{2} $$\nTo simplify the square root: $21125 = 25 \\times 845 = 25 \\times 5 \\times 169 = 5^3 \\times 13^2$.\n$$ \\sqrt{21125} = \\sqrt{5^2 \\times 13^2 \\times 5} = 5 \\times 13 \\sqrt{5} = 65\\sqrt{5} $$\nThe eigenvalues of $P'$ are:\n$$ \\mu = \\frac{845 \\pm 65\\sqrt{5}}{2} $$\nThe two eigenvalues of $P$ are $\\lambda_{P,1} = \\frac{845 + 65\\sqrt{5}}{2 \\times 492} = \\frac{845 + 65\\sqrt{5}}{984}$ and $\\lambda_{P,2} = \\frac{845 - 65\\sqrt{5}}{984}$.\nThe smallest eigenvalue is $\\lambda_{P,min}$:\n$$ \\lambda_{P,min} = \\frac{845 - 65\\sqrt{5}}{984} $$\nTo verify positive definiteness, we must check if this eigenvalue is positive. This is true if $845 - 65\\sqrt{5} > 0$, which simplifies to $845 > 65\\sqrt{5}$, or $13 > \\sqrt{5}$. Squaring both sides, $169 > 5$, which is true. Therefore, both eigenvalues are positive, $P$ is positive definite, and the origin of the system is asymptotically stable. The smallest eigenvalue is the required quantitative certificate.",
            "answer": "$$\n\\boxed{\\frac{845 - 65\\sqrt{5}}{984}}\n$$"
        },
        {
            "introduction": "Moving from stability analysis to the fundamental limits of feedback control, this practice explores a critical question: can an unstable system always be stabilized? You will investigate a hypothetical model of a pathological condition where an unstable dynamic is disconnected from both the control input and the available measurement. This exercise  necessitates a deep dive into the concepts of stabilizability and detectability, revealing why some biomedical systems are inherently impossible to stabilize, regardless of the controller's complexity.",
            "id": "3930062",
            "problem": "Consider a linear time-invariant (LTI) system describing a simplified hemodynamic regulation around a diseased equilibrium in a critically ill patient, with state vector $x \\in \\mathbb{R}^3$ representing $x_1$: effective vascular resistance, $x_2$: heart rate, and $x_3$: venous blood volume. The input $u \\in \\mathbb{R}$ is the infusion rate of a pure chronotropic agent that directly acts on the cardiac pacemaker cells, and the measured output $y \\in \\mathbb{R}$ is a noninvasive sensor reading. The linearized model is\n$$\n\\dot{x} = A x + B u, \\quad y = C x,\n$$\nwith\n$$\nA = \\begin{bmatrix}\n0.2  0  0 \\\\\n0  -0.5  0 \\\\\n0  0  -0.1\n\\end{bmatrix}, \\quad\nB = \\begin{bmatrix}\n0 \\\\ 1 \\\\ 0\n\\end{bmatrix}, \\quad\nC = \\begin{bmatrix}\n0  1  0\n\\end{bmatrix}.\n$$\nClinical interpretation: $x_1$ follows an unstable vascular resistance dynamics due to a pathological positive feedback mediated by inflammatory cytokines near this equilibrium, $x_2$ and $x_3$ are intrinsically stable in the absence of input, the input $u$ can only modulate $x_2$, and the available noninvasive measurement $y$ reports heart rate but not central vascular resistance or central venous volume. You are allowed to implement any causal output-feedback controller, including static output feedback $u = K_y y$ or a strictly proper dynamic compensator with internal state $w$, of the form\n$$\n\\dot{w} = F w + G y, \\quad u = H w + J y,\n$$\nwhere $(F,G,H,J)$ are finite-dimensional constant matrices you may choose.\n\nStarting from the fundamental definitions of controllability, stabilizability, observability, and detectability for linear time-invariant systems, and the intrinsic invariance of uncontrollable subspaces to feedback, evaluate which of the following statements are true. Your reasoning must not rely on ad hoc numerical tricks but should proceed from first principles in linear systems theory applied to this biomedical context.\n\nA. The plant is not stabilizable because the unstable eigenvalue at $\\lambda = 0.2$ is not influenced by the input. Therefore, no choice of static state feedback $u = K x$ nor any dynamic output feedback of the form given can render the closed loop asymptotically stable.\n\nB. A sufficiently high-order dynamic output-feedback controller can relocate the unstable pole at $\\lambda = 0.2$ into the left half-plane by exact pole–zero cancellation, even though $x_1$ is not actuated by $u$.\n\nC. If an additional noninvasive sensor were added to provide direct measurement of $x_1$ so that $C$ became $C_{\\text{aug}} = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$, then an appropriately designed output-feedback controller could stabilize the original plant without changing the actuator location.\n\nD. If the actuator were replaced by a vasoactive input that directly influences vascular smooth muscle tone so that $B$ became $B_{\\text{new}} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$, and the measurement were augmented to ensure detectability of the unstable mode (for example, adding a central pressure line to include $x_1$ in $y$), then dynamic output feedback could stabilize the closed loop.\n\nSelect all that apply.",
            "solution": "The problem statement will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n\nThe linearized time-invariant (LTI) system is described by the state-space equations:\n$$\n\\dot{x} = A x + B u, \\quad y = C x\n$$\nwhere the state vector is $x \\in \\mathbb{R}^3$, the input is $u \\in \\mathbb{R}$, and the output is $y \\in \\mathbb{R}$. The system matrices are given as:\n$$\nA = \\begin{bmatrix}\n0.2  0  0 \\\\\n0  -0.5  0 \\\\\n0  0  -0.1\n\\end{bmatrix}, \\quad\nB = \\begin{bmatrix}\n0 \\\\ 1 \\\\ 0\n\\end{bmatrix}, \\quad\nC = \\begin{bmatrix}\n0  1  0\n\\end{bmatrix}\n$$\nThe state variables represent:\n- $x_1$: effective vascular resistance\n- $x_2$: heart rate\n- $x_3$: venous blood volume\n\nThe problem allows for the implementation of any causal output-feedback controller, either static ($u = K_y y$) or dynamic:\n$$\n\\dot{w} = F w + G y, \\quad u = H w + J y\n$$\n\n### Step 2: Validate Using Extracted Givens\n\n1.  **Scientifically Grounded**: The problem uses a linearized state-space model to represent a simplified physiological system. This is a standard and well-established technique in biomedical systems modeling and control engineering. The interpretation of the states, input, and output is plausible within this simplified framework. The presence of an unstable mode models a pathological condition, which is a common subject of control-oriented medical studies. The problem is scientifically grounded in the principles of linear systems theory applied to a simplified biomedical context.\n2.  **Well-Posed**: The system matrices and equations are fully specified. The question asks for an evaluation of statements based on fundamental concepts of control theory (stabilizability, detectability, etc.), which are well-defined for the given LTI system. The problem is structured to yield a unique, definite answer for each statement.\n3.  **Objective**: The problem is expressed in precise mathematical language. The clinical interpretation provides context but does not introduce subjectivity into the analysis, which is based entirely on the mathematical model.\n4.  **Incomplete or Contradictory**: The problem provides all necessary information (matrices $A$, $B$, $C$) to analyze the core system's properties. There are no contradictions in the setup.\n5.  **Unrealistic or Infeasible**: The diagonal form of the matrix $A$ represents a simplification (uncoupled state dynamics in the open loop), but this is a common feature of pedagogical problems designed to isolate and test specific concepts. It is not physically impossible and does not invalidate the problem.\n6.  **Ill-Posed or Poorly Structured**: The questions posed are standard in linear systems theory and have definite answers that can be derived from the given model.\n7.  **Pseudo-Profound, Trivial, or Tautological**: The problem is straightforward for one trained in control theory but correctly tests fundamental concepts regarding the coupling between inputs/outputs and system modes, which is a core challenge. The structure isolates a key principle: the inability of feedback to affect uncontrollable modes.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. It is a well-posed problem in linear systems theory, framed within a plausible, albeit simplified, biomedical context. I will now proceed with the solution derivation.\n\n### System Analysis\n\nThe system matrix $A$ is diagonal, so its diagonal entries are the eigenvalues (poles) of the system: $\\lambda_1 = 0.2$, $\\lambda_2 = -0.5$, and $\\lambda_3 = -0.1$. The corresponding eigenvectors are the standard basis vectors $e_1 = [1, 0, 0]^T$, $e_2 = [0, 1, 0]^T$, and $e_3 = [0, 0, 1]^T$.\n\nThe system has one unstable mode associated with $\\lambda_1 = 0.2$. For the closed-loop system to be asymptotically stable, all its poles must be in the open left-half of the complex plane. This requires any feedback controller to be able to relocate the unstable pole $\\lambda_1 = 0.2$ into the left-half plane.\n\nThe ability to relocate poles with feedback is determined by the properties of stabilizability and detectability.\n\n**Stabilizability Analysis**: A system $(A, B)$ is stabilizable if all its unstable modes are controllable. A mode associated with an eigenvalue $\\lambda$ is controllable if it passes the Popov-Hautus-Belevitch (PHB) test: $\\text{rank}[A - \\lambda I, B] = n$, where $n$ is the dimension of the state space.\nFor the unstable mode $\\lambda_1 = 0.2$ and $n=3$:\n$$\n[A - 0.2I, B] = \\begin{bmatrix}\n0.2-0.2  0  0  0 \\\\\n0  -0.5-0.2  0  1 \\\\\n0  0  -0.1-0.2  0\n\\end{bmatrix}\n= \\begin{bmatrix}\n0  0  0  0 \\\\\n0  -0.7  0  1 \\\\\n0  0  -0.3  0\n\\end{bmatrix}\n$$\nThe rank of this $3 \\times 4$ matrix is $2$, because the first row is all zeros. Since $\\text{rank}[A - 0.2I, B] = 2  3$, the unstable mode at $\\lambda_1 = 0.2$ is uncontrollable. Therefore, the system is **not stabilizable**.\n\nThis can also be seen from the structure of $A$ and $B$. The first state equation is $\\dot{x}_1 = 0.2 x_1$. The input $u$ does not appear in this equation, as the first row of $B$ is zero. The dynamics of $x_1$ are completely independent of the input.\n\n**Detectability Analysis**: A system $(C, A)$ is detectable if all its unstable modes are observable. A mode associated with eigenvalue $\\lambda$ is observable if its corresponding eigenvector $v$ satisfies $Cv \\neq 0$.\nFor the unstable mode $\\lambda_1 = 0.2$, the eigenvector is $v_1 = [1, 0, 0]^T$.\n$$\nC v_1 = \\begin{bmatrix} 0  1  0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix} = 0\n$$\nSince $C v_1 = 0$, the unstable mode is unobservable. Therefore, the system is **not detectable**.\n\nA fundamental result in control theory states that a stabilizing dynamic output-feedback controller exists if and only if the system is both stabilizable and detectable. Since the given system is neither, it cannot be stabilized by any output-feedback controller.\n\n### Option-by-Option Analysis\n\n**A. The plant is not stabilizable because the unstable eigenvalue at $\\lambda = 0.2$ is not influenced by the input. Therefore, no choice of static state feedback $u = K x$ nor any dynamic output feedback of the form given can render the closed loop asymptotically stable.**\n\nOur analysis confirms the first part: the system is not stabilizable because the unstable mode at $\\lambda = 0.2$ is uncontrollable (\"not influenced by the input\"). An uncontrollable subspace is invariant under state feedback. The dynamics of the state $x_1$, $\\dot{x}_1 = 0.2 x_1$, cannot be altered by any feedback law of the form $u = f(x, w, y)$. Thus, the eigenvalue $\\lambda_1 = 0.2$ will always be a pole of the closed-loop system, regardless of the controller.\nA system is stabilizable by state feedback ($u=Kx$) if and only if it is stabilizable. Since our system is not stabilizable, no state feedback can stabilize it.\nA system is stabilizable by dynamic output feedback if and only if it is both stabilizable and detectable. Since our system is neither, no dynamic output feedback controller can stabilize it.\nThe statement is entirely correct.\n\n**Verdict: Correct.**\n\n**B. A sufficiently high-order dynamic output-feedback controller can relocate the unstable pole at $\\lambda = 0.2$ into the left half-plane by exact pole–zero cancellation, even though $x_1$ is not actuated by $u$.**\n\nThis statement is fundamentally flawed. Stabilization via pole-zero cancellation in the context of feedback control refers to a controller $K(s)$ canceling a pole of the plant's transfer function $G(s)$. Let's compute the transfer function:\n$$\nG(s) = C(sI - A)^{-1}B = \\begin{bmatrix} 0  1  0 \\end{bmatrix} \\begin{bmatrix} \\frac{1}{s-0.2}  0  0 \\\\ 0  \\frac{1}{s+0.5}  0 \\\\ 0  0  \\frac{1}{s+0.1} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix} = \\frac{1}{s+0.5}\n$$\nThe transfer function from the input $u$ to the output $y$ does not contain the unstable pole at $s = 0.2$. This is because the mode at $\\lambda_1=0.2$ is both uncontrollable and unobservable. The controller has no \"access\" to this pole through the input-output channel, and therefore cannot place a zero to \"cancel\" it. Even if it were possible (e.g., if the mode were controllable but unobservable), pole-zero cancellation of an unstable pole leads to internal instability, which is unacceptable. In this case, the premise is impossible to begin with. The dynamics of $x_1$ remain $\\dot{x}_1 = 0.2x_1$, which is unstable.\n\n**Verdict: Incorrect.**\n\n**C. If an additional noninvasive sensor were added to provide direct measurement of $x_1$ so that $C$ became $C_{\\text{aug}} = \\begin{bmatrix} 1  0  0 \\\\ 0  1  0 \\end{bmatrix}$, then an appropriately designed output-feedback controller could stabilize the original plant without changing the actuator location.**\n\nThis modification changes the output matrix to $C_{\\text{aug}}$, potentially making the system observable or detectable. However, the condition for stabilization via feedback requires, at a minimum, that the system be stabilizable. Stabilizability is a property of the pair $(A, B)$ and is independent of the output matrix $C$. The actuator location is unchanged, so the matrix $B$ is the same as in the original problem. We have already established that the pair $(A, B)$ is not stabilizable because the unstable mode at $\\lambda_1 = 0.2$ is uncontrollable. Since the system remains not stabilizable, no output feedback controller—no matter how sophisticated or what measurements it uses—can stabilize the system.\n\n**Verdict: Incorrect.**\n\n**D. If the actuator were replaced by a vasoactive input that directly influences vascular smooth muscle tone so that $B$ became $B_{\\text{new}} = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$, and the measurement were augmented to ensure detectability of the unstable mode (for example, adding a central pressure line to include $x_1$ in $y$), then dynamic output feedback could stabilize the closed loop.**\n\nThis option proposes modifying both the input matrix $B$ and the output mapping $C$. Let's analyze the new system.\nThe new input matrix is $B_{\\text{new}} = [1, 1, 0]^T$.\n**Stabilizability Check**: We check the controllability of the unstable mode at $\\lambda_1 = 0.2$ for the pair $(A, B_{\\text{new}})$.\n$$\n[A - 0.2I, B_{\\text{new}}] = \\begin{bmatrix}\n0.2-0.2  0  0  1 \\\\\n0  -0.5-0.2  0  1 \\\\\n0  0  -0.1-0.2  0\n\\end{bmatrix}\n= \\begin{bmatrix}\n0  0  0  1 \\\\\n0  -0.7  0  1 \\\\\n0  0  -0.3  0\n\\end{bmatrix}\n$$\nThe columns corresponding to basis vectors $e_2$, $e_3$ and the input vector $B_{\\text{new}}$ form the submatrix $\\begin{bmatrix} 0  0  1 \\\\ -0.7  0  1 \\\\ 0  -0.3  0 \\end{bmatrix}$. Its determinant is $1( (-0.7)(-0.3) - 0) = 0.21 \\neq 0$. Thus, the rank of the full $3 \\times 4$ matrix is $3$. Since $\\text{rank}[A - 0.2I, B_{\\text{new}}] = 3 = n$, the unstable mode is now controllable. This means the system $(A, B_{\\text{new}})$ is **stabilizable**.\n\n**Detectability Check**: The problem states that the measurement is \"augmented to ensure detectability of the unstable mode\". This is given. Let's verify with the example where $y$ includes $x_1$. This can be represented by $C_{\\text{new}} = \\begin{bmatrix} 1  0  0 \\end{bmatrix}$ or the $C_{\\text{aug}}$ from option C. Let's use $C_{\\text{new}} = \\begin{bmatrix} 1  0  0 \\end{bmatrix}$. The unstable mode corresponds to eigenvector $v_1=[1,0,0]^T$. We have $C_{\\text{new}}v_1 = \\begin{bmatrix} 1  0  0 \\end{bmatrix}[1, 0, 0]^T = 1 \\neq 0$. Thus, the unstable mode is now observable. This ensures the system $(C_{\\text{new}}, A)$ is **detectable**.\n\nSince the modified system is both stabilizable and detectable, a dynamic output-feedback controller exists that can asymptotically stabilize the closed-loop system.\n\n**Verdict: Correct.**",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "Our final practice brings stability analysis into the realm of modern computational systems biology. For complex models composed of interconnected physiological modules, searching for a single, dense Lyapunov matrix is often intractable. This exercise  introduces the powerful concept of a *structured* Lyapunov function that respects the system's underlying biological organization. You will formulate the stability condition $A^{\\top} P + P A \\prec 0$ as a Linear Matrix Inequality (LMI) and write a program to solve it, a technique widely used for the robust analysis and control of large-scale biomedical networks.",
            "id": "3930099",
            "problem": "Consider a continuous-time Linear Time-Invariant (LTI) system representing coupled physiological subsystems in biomedical systems modeling. Let $x(t) \\in \\mathbb{R}^n$ denote the state, and let the system dynamics be given by $\\dot{x}(t) = A x(t)$, where $A \\in \\mathbb{R}^{n \\times n}$ is a constant system matrix. Suppose that $x(t)$ is partitioned into $m$ physiological subsystems of sizes $n_1, n_2, \\dots, n_m$, so that $n = \\sum_{i=1}^m n_i$ and the matrix $A$ is conformally partitioned into $m \\times m$ blocks consistent with this physiology-motivated state decomposition.\n\nThe goal is to guarantee overall asymptotic stability using a Lyapunov function that respects subsystem sparsity. Specifically, consider a quadratic Lyapunov function $V(x) = x^\\top P x$ with a block-diagonal structure $P = \\mathrm{diag}(P_1, P_2, \\dots, P_m)$, where each $P_i \\in \\mathbb{R}^{n_i \\times n_i}$ is symmetric positive definite. Imposing a conservative but physiologically meaningful structure, take each block as a scaled identity: $P_i = \\alpha_i I_{n_i}$ with $\\alpha_i  0$. The Linear Matrix Inequality (LMI) condition for global asymptotic stability is $A^\\top P + P A \\prec 0$ together with $P \\succ 0$, while respecting the block-diagonal sparsity induced by the physiological partition.\n\nStarting from first principles of Lyapunov stability, pose this LMI for the given systems and determine whether there exist positive scalars $\\alpha_1, \\alpha_2, \\dots, \\alpha_m$ such that the LMI holds. Your task is to write a program that, for each provided test case, searches for $\\alpha_1, \\dots, \\alpha_m  0$ and decides whether the structured LMI is feasible. If feasible, output the boolean value $true$; otherwise, output the boolean value $false$.\n\nFoundational base to use:\n- Definition of continuous-time LTI systems $\\dot{x}(t) = A x(t)$.\n- Quadratic Lyapunov functions $V(x) = x^\\top P x$ with $P \\succ 0$.\n- The Lyapunov inequality $A^\\top P + P A \\prec 0$ that implies global asymptotic stability.\n\nYou must not use any pre-derived shortcut formula beyond these foundations. Express all mathematics using LaTeX notation.\n\nTest suite:\nUse the following four test cases with $m = 2$ subsystems, each of dimension $n_1 = 2$ and $n_2 = 2$, so $n = 4$. In each case, define\n$$\nA = \\begin{bmatrix}\nA_1  K_{12} \\\\\nK_{21}  A_2\n\\end{bmatrix},\n$$\nwith the blocks specified below.\n\n- Case 1 (baseline physiological coupling, expected to be stable under structured Lyapunov): \n  $$\n  A_1 = \\begin{bmatrix}\n  -0.9  0.3 \\\\\n  -0.4  -0.7\n  \\end{bmatrix}, \\quad\n  A_2 = \\begin{bmatrix}\n  -1.0  0.2 \\\\\n  0.1  -0.8\n  \\end{bmatrix}, \\quad\n  K_{12} = 0.05 I_2, \\quad\n  K_{21} = 0.02 I_2.\n  $$\n- Case 2 (strong bidirectional coupling, potentially destabilizing):\n  $\n  A_1, A_2 \\text{ as in Case 1}, \\quad\n  K_{12} = 0.9 I_2, \\quad\n  K_{21} = 0.9 I_2.\n  $\n- Case 3 (one subsystem intrinsically unstable):\n  $$\n  A_1 = \\begin{bmatrix}\n  -0.9  0.3 \\\\\n  -0.4  -0.7\n  \\end{bmatrix}, \\quad\n  A_2 = \\begin{bmatrix}\n  0.2  0.0 \\\\\n  0.0  -0.1\n  \\end{bmatrix}, \\quad\n  K_{12} = 0.1 I_2, \\quad\n  K_{21} = 0.1 I_2.\n  $$\n- Case 4 (asymmetric coupling near a boundary condition):\n  $$\n  A_1 = \\begin{bmatrix}\n  -0.9  0.3 \\\\\n  -0.4  -0.7\n  \\end{bmatrix}, \\quad\n  A_2 = \\begin{bmatrix}\n  -1.0  0.2 \\\\\n  0.1  -0.8\n  \\end{bmatrix}, \\quad\n  K_{12} = \\begin{bmatrix}\n  0.2  -0.1 \\\\\n  0.05  0.0\n  \\end{bmatrix}, \\quad\n  K_{21} = \\begin{bmatrix}\n  0.0  0.15 \\\\\n  -0.05  0.2\n  \\end{bmatrix}.\n  $$\n\nYour program must, for each case, determine whether there exist $\\alpha_1 > 0$ and $\\alpha_2 > 0$ such that $P = \\mathrm{diag}(\\alpha_1 I_2, \\alpha_2 I_2)$ satisfies $A^\\top P + P A \\prec 0$. Use a numerically sound search procedure over positive $\\alpha_i$ values that does not rely on external data. Use a strict feasibility tolerance: declare feasibility only if the largest eigenvalue of $A^\\top P + P A$ is strictly less than $-10^{-8}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true,false,true,false]\"), in the same order as the test cases above. All outputs must be booleans. No physical units, angles, or percentages are involved in this problem.",
            "solution": "The problem requires an analysis of the asymptotic stability of a continuous-time Linear Time-Invariant (LTI) system, $\\dot{x}(t) = A x(t)$, using a structured Lyapunov function.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- **System Dynamics**: $\\dot{x}(t) = A x(t)$, where $x(t) \\in \\mathbb{R}^n$ and $A \\in \\mathbb{R}^{n \\times n}$.\n- **State Partitioning**: The state vector $x(t)$ is partitioned into $m$ subsystems of sizes $n_1, n_2, \\dots, n_m$, with $n = \\sum_{i=1}^m n_i$.\n- **Lyapunov Function Candidate**: $V(x) = x^\\top P x$.\n- **Structure of P**: $P$ is block-diagonal, $P = \\mathrm{diag}(P_1, P_2, \\dots, P_m)$, with $P_i \\in \\mathbb{R}^{n_i \\times n_i}$ being symmetric positive definite.\n- **Specific Structure of $P_i$**: $P_i = \\alpha_i I_{n_i}$ for some positive scalars $\\alpha_i > 0$.\n- **Stability Condition**: The Linear Matrix Inequality (LMI) $A^\\top P + P A \\prec 0$ (negative definite).\n- **Task**: For given system matrices $A$, determine if there exist scalars $\\alpha_1, \\dots, \\alpha_m > 0$ such that the LMI is satisfied.\n- **Test Cases**: Four specific $4 \\times 4$ matrices $A$ are provided, with $m=2$, $n_1=2$, $n_2=2$.\n- **Numerical Criterion**: Feasibility is declared if the largest eigenvalue of $A^\\top P + P A$ is strictly less than $-10^{-8}$.\n\n**1.2. Validation Using Extracted Givens**\n- **Scientifically Grounded**: The problem is firmly rooted in Lyapunov stability theory, a cornerstone of modern control theory and dynamical systems analysis, particularly relevant to biomedical systems modeling. The concepts of LTI systems, quadratic Lyapunov functions, and LMIs are standard and well-established.\n- **Well-Posed**: The problem is mathematically well-defined. It asks for the feasibility of an LMI with respect to a set of positive parameters. This is a convex feasibility problem, which is known to have a well-defined solution (either feasible or not).\n- **Objective**: The problem is stated using precise mathematical language and definitions. The test cases and the success criterion are specified objectively and quantitatively.\n- **Other checks**: The problem is self-contained, with all necessary information provided. It does not violate any scientific principles, contains no contradictions, and is not trivial.\n\n**1.3. Verdict and Action**\nThe problem is deemed **valid**. It is a standard, well-posed problem in stability analysis. A full solution will be provided.\n\n### Step 2: Derivation of the Solution\n\nThe foundation of the analysis is Lyapunov's second method for stability. For an autonomous system $\\dot{x} = f(x)$, if there exists a continuously differentiable function $V(x)$, called a Lyapunov function, such that:\n1. $V(x) > 0$ for all $x \\neq 0$ and $V(0)=0$ (positive definite).\n2. $\\dot{V}(x)  0$ for all $x \\neq 0$ (negative definite time derivative along system trajectories).\nThen, the origin is a globally asymptotically stable equilibrium point.\n\nFor the given LTI system $\\dot{x}(t) = A x(t)$, we consider the quadratic Lyapunov function candidate $V(x) = x^\\top P x$.\n\nThe first condition, $V(x) > 0$ for $x \\neq 0$, requires the matrix $P$ to be positive definite, denoted as $P \\succ 0$. The problem specifies the structure of $P$ as $P = \\mathrm{diag}(\\alpha_1 I_{n_1}, \\alpha_2 I_{n_2}, \\dots, \\alpha_m I_{n_m})$, where $I_{n_i}$ is the $n_i \\times n_i$ identity matrix. The eigenvalues of this block-diagonal matrix $P$ are the eigenvalues of its blocks $\\alpha_i I_{n_i}$. The eigenvalues of $\\alpha_i I_{n_i}$ are all equal to $\\alpha_i$. Therefore, for $P$ to be positive definite, all its eigenvalues must be positive, which requires $\\alpha_i > 0$ for all $i=1, \\dots, m$. This is given as a constraint in the problem, so the first Lyapunov condition is satisfied by construction.\n\nThe second condition requires analyzing the time derivative of $V(x)$:\n$$\n\\dot{V}(x) = \\frac{d}{dt}(x^\\top P x) = \\dot{x}^\\top P x + x^\\top P \\dot{x}\n$$\nSubstituting the system dynamics $\\dot{x} = A x$:\n$$\n\\dot{V}(x) = (A x)^\\top P x + x^\\top P (A x) = x^\\top A^\\top P x + x^\\top P A x = x^\\top (A^\\top P + P A) x\n$$\nThe condition $\\dot{V}(x)  0$ for all $x \\neq 0$ is equivalent to the matrix $Q(\\alpha_1, \\dots, \\alpha_m) = A^\\top P + P A$ being negative definite, denoted as $A^\\top P + P A \\prec 0$. This is the LMI we must test for feasibility.\n\nLet the system matrix $A$ be partitioned conformally with the state subsystems:\n$$\nA = \\begin{bmatrix}\nA_{11}  A_{12}  \\dots  A_{1m} \\\\\nA_{21}  A_{22}  \\dots  A_{2m} \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\nA_{m1}  A_{m2}  \\dots  A_{mm}\n\\end{bmatrix}\n$$\nwhere $A_{ij} \\in \\mathbb{R}^{n_i \\times n_j}$.\nSubstituting the structured $P = \\mathrm{diag}(\\alpha_1 I_{n_1}, \\dots, \\alpha_m I_{n_m})$ into the LMI gives:\n$$\nA^\\top P + PA = \\begin{bmatrix}\nA_{11}^\\top  \\dots  A_{m1}^\\top \\\\\n\\vdots  \\ddots  \\vdots \\\\\nA_{1m}^\\top  \\dots  A_{mm}^\\top\n\\end{bmatrix}\n\\begin{bmatrix}\n\\alpha_1 I_{n_1}   0 \\\\\n \\ddots  \\\\\n0   \\alpha_m I_{n_m}\n\\end{bmatrix}\n+\n\\begin{bmatrix}\n\\alpha_1 I_{n_1}   0 \\\\\n \\ddots  \\\\\n0   \\alpha_m I_{n_m}\n\\end{bmatrix}\n\\begin{bmatrix}\nA_{11}  \\dots  A_{1m} \\\\\n\\vdots  \\ddots  \\vdots \\\\\nA_{m1}  \\dots  A_{mm}\n\\end{bmatrix}\n$$\nThe $(i, j)$-th block of the resulting matrix $Q$ is given by $Q_{ij} = \\alpha_j A_{ji}^\\top + \\alpha_i A_{ij}$. The full matrix is:\n$$\nQ(\\alpha_1, \\dots, \\alpha_m) = \\begin{bmatrix}\n\\alpha_1(A_{11}^\\top + A_{11})  \\alpha_2 A_{21}^\\top + \\alpha_1 A_{12}  \\dots \\\\\n\\alpha_1 A_{12}^\\top + \\alpha_2 A_{21}  \\alpha_2(A_{22}^\\top + A_{22})  \\dots \\\\\n\\vdots  \\vdots  \\ddots\n\\end{bmatrix}\n$$\nThe task is to find if there exists a set of positive scalars $\\{\\alpha_i\\}_{i=1}^m$ that makes this symmetric matrix $Q$ negative definite. A matrix is negative definite if and only if all its eigenvalues are strictly negative.\n\nThe LMI is homogeneous in the variables $\\alpha_i$. That is, if $Q(\\alpha_1, \\dots, \\alpha_m) \\prec 0$, then for any scalar $k > 0$, $Q(k\\alpha_1, \\dots, k\\alpha_m) = k \\cdot Q(\\alpha_1, \\dots, \\alpha_m) \\prec 0$ as well. This property allows us to reduce the dimensionality of the search space. We can fix one variable, say $\\alpha_1=1$, and search over the ratios $\\rho_i = \\alpha_{i+1} / \\alpha_1$ for $i=1, \\dots, m-1$.\n\nFor the specific test cases, $m=2$. We need to find if there exist $\\alpha_1 > 0$ and $\\alpha_2 > 0$ such that the LMI holds. We set $\\alpha_1=1$ and search for a single positive ratio $\\rho = \\alpha_2 > 0$. The partitioned matrix $A$ is given as $A = \\begin{bmatrix} A_1  K_{12} \\\\ K_{21}  A_2 \\end{bmatrix}$. The LMI becomes finding $\\rho > 0$ such that:\n$$\nQ(1, \\rho) = \\begin{bmatrix}\nA_1^\\top + A_1  \\rho K_{21}^\\top + K_{12} \\\\\nK_{12}^\\top + \\rho K_{21}  \\rho(A_2^\\top + A_2)\n\\end{bmatrix} \\prec 0\n$$\nTo solve this, we can define an objective function $f(\\rho) = \\lambda_{\\max}(Q(1, \\rho))$, where $\\lambda_{\\max}(\\cdot)$ denotes the maximum eigenvalue. Since $Q(1, \\rho)$ is a symmetric matrix whose entries are affine functions of $\\rho$, the function $f(\\rho)$ is convex. We can therefore use a numerical optimization algorithm to find the minimum of $f(\\rho)$ over $\\rho > 0$. If the minimum value of $f(\\rho)$ is less than the specified tolerance of $-10^{-8}$, the LMI is feasible, and stability can be guaranteed with this Lyapunov function structure. Otherwise, it is not.\n\nThe algorithm is as follows for a given test case:\n1. Define the objective function $f(\\rho) = \\lambda_{\\max}(Q(1, \\rho))$, where $\\rho > 0$.\n2. Use a numerical optimizer (e.g., `scipy.optimize.minimize_scalar`) to find $\\min_{\\rho > 0} f(\\rho)$.\n3. If the resulting minimum value is less than $-10^{-8}$, the system is certifiably stable with the structured Lyapunov function, and the result is `true`. Otherwise, the result is `false`.\n\nA necessary (but not sufficient in general) condition for the global matrix $Q$ to be negative definite is that its diagonal blocks must be negative definite. That is, $\\alpha_i(A_{ii}^\\top + A_{ii}) \\prec 0$. Since $\\alpha_i > 0$, this means $A_{ii}^\\top + A_{ii}$ must be negative definite. If for any subsystem $i$, the matrix $A_{ii}^\\top + A_{ii}$ is not negative definite, then $Q$ cannot be negative definite, and the LMI is infeasible. This provides a quick check, as observed in Case 3 where $A_2^\\top + A_2$ is not negative definite, immediately implying infeasibility.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the feasibility of a structured Lyapunov-based stability condition\n    for a set of LTI systems.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (A1, A2, K12, K21).\n    test_cases = [\n        # Case 1: Baseline physiological coupling\n        (\n            np.array([[-0.9, 0.3], [-0.4, -0.7]]),\n            np.array([[-1.0, 0.2], [0.1, -0.8]]),\n            0.05 * np.eye(2),\n            0.02 * np.eye(2),\n        ),\n        # Case 2: Strong bidirectional coupling\n        (\n            np.array([[-0.9, 0.3], [-0.4, -0.7]]),\n            np.array([[-1.0, 0.2], [0.1, -0.8]]),\n            0.9 * np.eye(2),\n            0.9 * np.eye(2),\n        ),\n        # Case 3: One subsystem intrinsically unstable\n        (\n            np.array([[-0.9, 0.3], [-0.4, -0.7]]),\n            np.array([[0.2, 0.0], [0.0, -0.1]]),\n            0.1 * np.eye(2),\n            0.1 * np.eye(2),\n        ),\n        # Case 4: Asymmetric coupling near a boundary condition\n        (\n            np.array([[-0.9, 0.3], [-0.4, -0.7]]),\n            np.array([[-1.0, 0.2], [0.1, -0.8]]),\n            np.array([[0.2, -0.1], [0.05, 0.0]]),\n            np.array([[0.0, 0.15], [-0.05, 0.2]]),\n        ),\n    ]\n\n    results = []\n    for case in test_cases:\n        is_feasible = check_lmi_feasibility(case)\n        results.append(str(is_feasible).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef check_lmi_feasibility(case_params):\n    \"\"\"\n    Checks if there exists a ratio rho  0 such that the LMI A'P + PA  0 holds.\n    \n    The problem is to find alpha_1, alpha_2  0. Due to homogeneity, we can fix\n    alpha_1 = 1 and search for the ratio rho = alpha_2 / alpha_1  0.\n    \n    The function to minimize is the maximum eigenvalue of the matrix Q(rho),\n    which is a convex function of rho.\n    \"\"\"\n    A1, A2, K12, K21 = case_params\n    \n    # Pre-calculate constant parts of the Q matrix\n    Q11_block = A1.T + A1\n    A2_sym_part = A2.T + A2\n\n    def objective_function(rho):\n        \"\"\"\n        Calculates the maximum eigenvalue of the matrix Q for a given rho.\n        \n        Q(rho) = [ A1'+A1,       rho*K21' + K12 ]\n                 [ K12'+rho*K21,  rho*(A2'+A2)    ]\n        \"\"\"\n        if rho = 0:\n            return np.inf # We are searching for rho  0\n\n        # Construct the matrix Q(rho)\n        Q12_block = rho * K21.T + K12\n        Q21_block = K12.T + rho * K21\n        Q22_block = rho * A2_sym_part\n        \n        Q = np.block([\n            [Q11_block, Q12_block],\n            [Q21_block, Q22_block]\n        ])\n        \n        # We need the maximum eigenvalue of this symmetric matrix.\n        # eigvalsh is efficient for symmetric/Hermitian matrices.\n        max_eigenvalue = np.max(np.linalg.eigvalsh(Q))\n        \n        return max_eigenvalue\n\n    # Search for the optimal rho that minimizes the maximum eigenvalue.\n    # The search range for the ratio rho is chosen to be wide enough\n    # to cover typical physiological parameter ratios.\n    # 'bounded' method is suitable for a single-variable search in a range.\n    res = minimize_scalar(\n        objective_function,\n        bounds=(1e-6, 1e6),\n        method='bounded'\n    )\n    \n    # The minimum value found by the optimizer corresponds to the \"most negative\"\n    # the maximum eigenvalue can be made by choosing the best rho.\n    min_max_eigenvalue = res.fun\n    \n    # Check if this value meets the strict negativity condition.\n    feasibility_tolerance = -1e-8\n    \n    return min_max_eigenvalue  feasibility_tolerance\n\nsolve()\n```"
        }
    ]
}