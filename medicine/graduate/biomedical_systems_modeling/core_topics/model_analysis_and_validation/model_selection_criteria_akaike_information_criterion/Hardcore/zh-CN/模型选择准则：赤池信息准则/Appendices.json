{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握赤池信息准则（AIC），我们不仅要会用公式，更要理解其背后的理论根基。本练习旨在连接理论与实践，它要求我们从信息论中的Kullback-Leibler散度这一第一性原理出发，推导出AIC的表达式。通过将该准则应用于一个实际的药代动力学模型选择问题，我们将亲手计算并比较两个候选模型的AIC值，从而加深对模型拟合优度与复杂性之间权衡的理解。",
            "id": "3903661",
            "problem": "一个药物动力学建模团队正在比较用于一个患者队列中肝脏药物清除的两种候选群体模型。每个候选模型都是一个通过最大似然 (ML) 估计的非线性混合效应 (NLME) 模型。第一个模型包括清除率和体积的固定效应和随机效应，有 $k=14$ 个自由估计参数。第二个模型在清除率上增加了一个额外的随机效应协方差项和一个非线性协变量效应，从而有 $k=16$ 个自由估计参数。ML 拟合得到的最大对数似然对于第一个模型为 $\\ell_{1}=-1020.5$，对于第二个模型为 $\\ell_{2}=-1018.0$，其中 $\\ell$ 表示在 ML 估计值处计算的自然对数似然。\n\n从未知数据生成机制与参数化候选模型之间的期望 Kullback–Leibler (KL) 散度的定义出发，并基于 ML 估计最大化样本对数似然的原则，推导出适用于 ML 拟合的参数化模型的模型选择准则，即赤池信息准则 (Akaike Information Criterion, AIC)。使用此推导计算两个模型的 AIC，根据 AIC 确定首选模型，然后报告两个模型之间的 AIC 差异，该差异定义为较差（非首选）模型的 AIC 减去较好（首选）模型的 AIC。\n\n将最终报告的差异四舍五入到四位有效数字。最终量不需要物理单位。",
            "solution": "题目要求从与 Kullback–Leibler (KL) 散度相关的基本原理出发，推导赤池信息准则 (AIC)，并将其应用于药物动力学建模中的模型选择问题。\n\n首先，进行 AIC 的理论推导。AIC 的基础是信息论。设真实、未知的数据生成过程由概率密度函数 (pdf) $f(x)$ 表示。我们的目标是使用来自一族由 $g(x|\\theta)$ 表示的 pdf 的参数化模型来近似这个过程，其中 $\\theta$ 是一个参数向量。Kullback–Leibler (KL) 散度，或称相对熵，量化了当使用模型 $g(x|\\theta)$ 来近似真实过程 $f(x)$ 时所损失的信息。它定义为关于真实分布 $f$ 的两个密度比值的对数的期望：\n$$ D_{KL}(f || g(\\cdot|\\theta)) = E_f\\left[\\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right)\\right] = \\int f(x) \\ln(f(x)) dx - \\int f(x) \\ln(g(x|\\theta)) dx $$\n在此表达式中，项 $\\int f(x) \\ln(f(x)) dx$ 是真实分布的熵。由于对于给定的真实过程 $f(x)$，该项是常数，并且不依赖于模型 $g(x|\\theta)$，因此最小化 KL 散度等价于最大化第二项 $E_f[\\ln(g(x|\\theta))]$。该项表示在真实数据生成分布下模型的期望对数似然。\n\n在实践中，真实分布 $f(x)$ 和一个理想化模型应有的真实参数 $\\theta_0$ 都是未知的。我们有一组观测数据，记为 $y$，它是来自分布 $f(x)$ 的一个实现。使用这些数据，我们通常通过最大似然 (ML) 法得到参数的估计值 $\\hat{\\theta}$。ML 估计值 $\\hat{\\theta}_{ML}$ 是使观测数据的对数似然函数 $\\ell(\\theta|y) = \\ln g(y|\\theta)$ 最大化的 $\\theta$ 值。\n\n最大化对数似然 $\\ell(\\hat{\\theta}_{ML}|y)$ 衡量了模型对用于拟合的数据的拟合优度。然而，对于模型在一个新的、独立的、同样来自 $f(x)$ 的数据集 $y_{new}$ 上的预测准确性而言，它是一个乐观偏倚的估计量。我们在模型选择中真正希望最大化的量是期望预测对数似然，它可以表示为对原始数据 $y$ 的分布的期望：$E_y \\left[ E_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{ML}(y))] \\right]$。\n\nAkaike 证明，在某些正则性条件下且对于大样本，样本内最大化对数似然会高估这个目标量。他建立了两者之间的渐近关系：\n$$ E_y \\left[ \\ell(\\hat{\\theta}_{ML}(y)|y) \\right] - E_y \\left[ E_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{ML}(y))] \\right] \\approx k $$\n其中 $k$ 是参数向量 $\\theta$ 中自由估计参数的数量。这意味着，作为期望预测对数似然的估计，最大化对数似然 $\\ell(\\hat{\\theta}_{ML}|y)$ 平均而言存在一个约为 $k$ 的向上偏倚。\n\n为了获得一个偏差较小的预测准确性估计，我们可以通过从最大化对数似然中减去偏倚项 $k$ 来校正这种乐观性。因此，期望预测对数似然的一个近似无偏估计量是 $\\ell(\\hat{\\theta}_{ML}|y) - k$。最大化这个量是模型选择的一个合理原则。\n\n出于与偏差 (deviance) 和似然比检验相关的历史原因，Akaike 通过将这个经偏倚校正的对数似然乘以 $-2$ 来定义他的准则。这将目标从最大化转变为最小化。因此，赤池信息准则 (AIC) 定义为：\n$$ AIC = -2 (\\ell - k) = -2\\ell + 2k $$\n其中 $\\ell$ 是模型的最大化对数似然值， $k$ 是自由估计参数的数量。AIC 值最低的模型被选为在拟合优度（高 $\\ell$）和简约性（低 $k$）之间达到最佳平衡的模型。\n\n现在，我们将此公式应用于问题中描述的两个候选模型。\n\n对于模型 1：\n参数数量，$k_1 = 14$。\n最大化对数似然，$\\ell_1 = -1020.5$。\n模型 1 的 AIC 为：\n$$ AIC_1 = -2\\ell_1 + 2k_1 = -2(-1020.5) + 2(14) $$\n$$ AIC_1 = 2041.0 + 28 = 2069.0 $$\n\n对于模型 2：\n参数数量，$k_2 = 16$。\n最大化对数似然，$\\ell_2 = -1018.0$。\n模型 2 的 AIC 为：\n$$ AIC_2 = -2\\ell_2 + 2k_2 = -2(-1018.0) + 2(16) $$\n$$ AIC_2 = 2036.0 + 32 = 2068.0 $$\n\n为了选择首选模型，我们比较它们的 AIC 值。AIC 值较低的模型被认为是更优的。\n$AIC_1 = 2069.0$\n$AIC_2 = 2068.0$\n由于 $AIC_2  AIC_1$，模型 2 是首选模型。根据 AIC，拟合度的改善（对数似然增加 $2.5$）足以证明增加 $2$ 个额外参数是合理的。\n\n最后一步是计算较差（非首选）模型与较好（首选）模型之间的 AIC 差异。\n较差模型：模型 1 ($AIC_1 = 2069.0$)\n较好模型：模型 2 ($AIC_2 = 2068.0$)\n差异 $\\Delta AIC$ 为：\n$$ \\Delta AIC = AIC_{worse} - AIC_{better} = AIC_1 - AIC_2 $$\n$$ \\Delta AIC = 2069.0 - 2068.0 = 1.0 $$\n题目要求将此结果报告为四位有效数字。值 $1.0$ 必须写成 $1.000$ 以满足此精度要求。\n$$ \\Delta AIC = 1.000 $$",
            "answer": "$$\n\\boxed{1.000}\n$$"
        },
        {
            "introduction": "单个模型的AIC值本身并没有绝对意义，模型选择本质上是一个相对比较的过程。在拥有多个候选模型时，我们需要一套系统的方法来量化它们之间的相对支持度。本练习将引导我们超越原始的AIC值，专注于计算更具解释性的指标：$\\Delta \\mathrm{AIC}$和证据比。通过分析一个葡萄糖-胰岛素调控模型的案例，我们将学习如何根据$\\Delta \\mathrm{AIC}$对模型进行排序，并利用证据比来评估数据对某个模型优于另一个模型的支持强度，从而做出更稳健的科学推断。",
            "id": "3903626",
            "problem": "一个转化生理学研究团队正在利用连续血糖监测和胰岛素输注记录，构建成人葡萄糖-胰岛素调节的系统级模型。三个机制性候选模型通过最大似然法对同一队列和数据集进行了拟合：一个简约的单室摄取模型、一个带有远程胰岛素动力学的双室最小模型，以及一个具有可饱和葡萄糖转运的非线性摄取模型。这三个模型在参数数量和结构上有所不同，但在现有数据上均是可识别的。模型拟合得到的三个候选模型的Akaike信息准则值分别为 $134.2$、$135.0$ 和 $141.3$。\n\n从Akaike信息准则是在最大似然法下对拟合模型的期望Kullback–Leibler信息进行偏差校正的估计量这一核心定义出发，并且模型支持度可以通过模型间该准则的差异进行比较，请完成以下任务：\n\n1. 计算这三个模型的 $\\Delta \\mathrm{AIC}$ 值集合。\n2. 利用这些差异，从基于似然信息的首要原则出发，推导出一个一致的模型支持度度量，并用它来量化每个模型的相对支持度，进而计算这三个模型两两之间的支持度比较。\n3. 在此生物医学背景下，根据您的定量比较，解释每个模型的实际支持水平，并明确评论哪些模型应被视为基本上无法区分，哪些支持度中等偏低，哪些支持度相当低。\n\n为了评分，请报告支持度最高的模型相对于支持度最低的模型的证据比，并四舍五入到四位有效数字，作为您的最终答案。证据比是无量纲的，请勿在最终答案中包含单位。",
            "solution": "该问题提供了三个葡萄糖-胰岛素调节候选模型的Akaike信息准则 (AIC) 值，并要求基于信息论原理对其相对支持度进行定量和解释性比较。该问题具有科学依据，提法明确，并包含了完整解答所需的所有信息。\n\n设三个模型分别为 $M_1$、$M_2$ 和 $M_3$。提供的AIC值为：\n$\\mathrm{AIC}_1 = 134.2$ (简约单室模型)\n$\\mathrm{AIC}_2 = 135.0$ (双室最小模型)\n$\\mathrm{AIC}_3 = 141.3$ (非线性摄取模型)\n\n整个过程按要求包括三个不同的任务。\n\n**1. 计算 $\\Delta \\mathrm{AIC}$ 值**\n\n使用AIC比较模型，首先要计算每个模型的AIC值与候选模型集中观察到的最小AIC值之间的差值。这个差值（对于模型 $i$ 记为 $\\Delta \\mathrm{AIC}_i$）量化了当使用模型 $M_i$ 而非集合中拟合最优模型时所造成的信息损失。\n\n最小的AIC值为：\n$$\n\\mathrm{AIC}_{\\min} = \\min(\\mathrm{AIC}_1, \\mathrm{AIC}_2, \\mathrm{AIC}_3) = \\min(134.2, 135.0, 141.3) = 134.2\n$$\n因此，集合中最优的模型是 $M_1$。\n\n三个模型的 $\\Delta \\mathrm{AIC}$ 值为：\n$$\n\\Delta \\mathrm{AIC}_1 = \\mathrm{AIC}_1 - \\mathrm{AIC}_{\\min} = 134.2 - 134.2 = 0\n$$\n$$\n\\Delta \\mathrm{AIC}_2 = \\mathrm{AIC}_2 - \\mathrm{AIC}_{\\min} = 135.0 - 134.2 = 0.8\n$$\n$$\n\\Delta \\mathrm{AIC}_3 = \\mathrm{AIC}_3 - \\mathrm{AIC}_{\\min} = 141.3 - 134.2 = 7.1\n$$\n$\\Delta \\mathrm{AIC}$ 值的集合是 $\\{0, 0.8, 7.1\\}$。\n\n**2. 相对模型支持度的推导与计算**\n\n问题要求从基于似然信息的首要原则出发，推导出一个模型支持度的度量。AIC源于Kullback-Leibler (KL) 信息论。其核心思想是，在给定数据 $D$ 的情况下，模型 $M_i$ 的似然 $\\mathcal{L}(M_i|D)$ 与其相对于真实数据生成过程的估计KL信息损失的负值的指数成正比。Akaike证明了这个相对期望信息的无偏估计量是 $\\frac{1}{2} \\mathrm{AIC}_i$。\n\n因此，给定数据下模型 $M_i$ 的似然 $\\mathcal{L}(M_i|D)$ 可以通过以下变换与其AIC值相关联：\n$$\n\\mathcal{L}(M_i|D) \\propto \\exp\\left(-\\frac{1}{2}\\mathrm{AIC}_i\\right)\n$$\n这种变换将模型置于一个似然尺度上，从而可以直接比较。一个模型 ($M_i$) 相对于另一个模型 ($M_j$) 的相对支持度通过证据比来量化，即它们似然的比值：\n$$\n\\frac{\\mathcal{L}(M_i|D)}{\\mathcal{L}(M_j|D)} = \\frac{\\exp(-\\frac{1}{2}\\mathrm{AIC}_i)}{\\exp(-\\frac{1}{2}\\mathrm{AIC}_j)} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_i - \\mathrm{AIC}_j)\\right) = \\exp\\left(-\\frac{1}{2}\\Delta_{ij}\\right)\n$$\n其中 $\\Delta_{ij} = \\mathrm{AIC}_i - \\mathrm{AIC}_j$。这个证据比就是所要求的一致的模型支持度度量。\n\n利用这个推导出的关系，我们在适当的情况下使用最优模型 $M_1$ 作为参照，计算两两之间的支持度比较：\n-   **模型 $M_1$ 与模型 $M_2$ 的比较**：$M_1$ 相对于 $M_2$ 的证据比为\n    $$\n    E_{1,2} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_2)\\right) = \\exp\\left(-\\frac{1}{2}(134.2 - 135.0)\\right) = \\exp(0.4) \\approx 1.492\n    $$\n-   **模型 $M_1$ 与模型 $M_3$ 的比较**：$M_1$ 相对于 $M_3$ 的证据比为\n    $$\n    E_{1,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_3)\\right) = \\exp\\left(-\\frac{1}{2}(134.2 - 141.3)\\right) = \\exp(3.55) \\approx 34.813\n    $$\n-   **模型 $M_2$ 与模型 $M_3$ 的比较**：$M_2$ 相对于 $M_3$ 的证据比为\n    $$\n    E_{2,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_2 - \\mathrm{AIC}_3)\\right) = \\exp\\left(-\\frac{1}{2}(135.0 - 141.3)\\right) = \\exp(3.15) \\approx 23.336\n    $$\n\n**3. 实际支持水平的解释**\n\n对定量结果的解释依赖于关于 $\\Delta \\mathrm{AIC}$ 值的既定启发式法则（例如，由 Burnham and Anderson 在2002年提出的法则）。\n-   $\\Delta \\mathrm{AIC} \\in [0, 2]$：模型具有相当大的支持度，与最优模型基本上无法区分。\n-   $\\Delta \\mathrm{AIC} \\in [4, 7]$：模型的支持度相当低。\n-   $\\Delta \\mathrm{AIC}  10$：模型基本上没有支持度，可以被舍弃。\n\n将这些启发式法则应用于当前的生物医学建模背景中：\n-   **模型 $M_1$ (单室模型)** 的 $\\Delta \\mathrm{AIC}_1 = 0$，根据定义，它是该模型集合中支持度最高的模型。\n-   **模型 $M_2$ (双室模型)** 的 $\\Delta \\mathrm{AIC}_2 = 0.8$，完全落在“相当大的支持度”范围内。约等于1.5的证据比表明，$M_1$ 的合理性仅略高于 $M_2$。在实际应用中，这两个模型将被视为**基本上无法区分**。数据并未提供强有力的依据来拒绝结构稍复杂的双室模型 $M_2$，而选择更简约的单室模型 $M_1$。\n-   **模型 $M_3$ (非线性模型)** 的 $\\Delta \\mathrm{AIC}_3 = 7.1$，处于“支持度相当低”类别的上边界。约等于35的证据比表明，数据对最优模型 $M_1$ 的支持度是 $M_3$ 的近35倍。这代表了强烈的证据差异。在此生物医学背景下，模型 $M_3$ 将被视为**支持度相当低**，是解释所观察到的葡萄糖-胰岛素动力学的一个不佳候选者，很可能应被排除在进一步的考虑之外。\n\n最终要求的答案是支持度最高的模型 ($M_1$) 相对于支持度最低的模型 ($M_3$) 的证据比。这在第2部分中已计算为 $E_{1,3}$。\n$$\nE_{1,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_3)\\right) = \\exp(3.55) \\approx 34.813395\n$$\n将该值四舍五入到四位有效数字，得到 $34.81$。",
            "answer": "$$\\boxed{34.81}$$"
        },
        {
            "introduction": "经典的AIC是基于大样本假设推导得出的，但在生物医学研究中，有限的样本量是常态。当样本量相对于模型参数数量较小时，AIC可能会倾向于选择过于复杂的模型，导致过拟合。为了解决这个问题，修正的赤池信息准则（AICc）应运而生。本练习将通过一个细胞因子信号动力学模型的例子，展示何时以及如何应用AICc。我们将计算AIC和AICc的值，并直接比较两者差异，从而体会小样本修正对于惩罚模型复杂性和避免过拟合的重要性。",
            "id": "3903628",
            "problem": "一个生物医学系统建模小组正在根据来自 $n=30$ 名患者的实验时间序列数据，校准一个细胞因子信号动态的机理模型。该候选机理模型有 $k=8$ 个自由参数。设 $\\ell(\\hat{\\theta})$ 表示在候选模型的最大似然估计 (MLE) $\\hat{\\theta}$ 处计算得到的最大化对数似然，并假设 $\\ell(\\hat{\\theta})=-120$。从最小化由 Kullback-Leibler 散度 (KL) 测量的预期信息损失的原则出发，推导赤池信息准则 (Akaike Information Criterion, AIC) 和小样本校正的赤池信息准则 (AICc) 的形式。然后，为给定的 $(n,k,\\ell(\\hat{\\theta}))$ 计算 $AIC$ 和 $AICc$，并从绝对值和相对值两个方面解释小样本校正相对于 $AIC$ 的量级。精确表达最终的数值计算结果，不要四舍五入。只提供 $AIC$ 和 $AICc$ 的最终数值结果。",
            "solution": "该问题是有效的，因为它在科学上基于统计信息论，问题表述清晰且提供了所有必要信息，并且没有任何事实或逻辑上的不一致之处。\n\n赤池信息准则 (AIC) 及其小样本校正版本 (AICc) 是基于信息论的模型选择准则。它们提供了当使用一个给定模型来表示生成数据的过程时，预期相对信息损失的估计。推导始于 Kullback-Leibler (KL) 散度。\n\n设真实的、未知的数据生成过程的概率分布函数（或密度）表示为 $f(x)$。设我们的候选模型由一个分布族 $g(x|\\theta)$ 表示，该分布族由一个向量 $\\theta$ 参数化。使用 $g$ 来近似 $f$ 所产生的 KL 散度（或信息损失）定义为：\n$$\nI(f,g) = \\int f(x) \\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right) dx\n$$\n这个表达式可以展开为：\n$$\nI(f,g) = \\int f(x) \\ln(f(x)) dx - \\int f(x) \\ln(g(x|\\theta)) dx\n$$\n第一项 $\\int f(x) \\ln(f(x)) dx$ 只依赖于真实分布 $f$，并且相对于模型 $g$ 是一个常数。因此，最小化 KL 散度 $I(f,g)$ 等价于最大化第二项，即模型 $g(x|\\theta)$ 的期望对数似然，其中期望是相对于真实分布 $f$ 计算的：\n$$\nE_{x \\sim f}[\\ln(g(x|\\theta))] = \\int f(x) \\ln(g(x|\\theta)) dx\n$$\n在实践中，我们不知道模型族的真实参数向量 $\\theta$。我们通常使用最大似然估计 (MLE) 从数据中估计它，记为 $\\hat{\\theta}$。具有估计参数 $g(x|\\hat{\\theta})$ 的模型的质量，是通过其在从同一真实分布 $f$ 中抽取的新数据 $y$ 上的预期性能来评估的。这就是预期的信息损失：\n$$\nE_{y \\sim f} \\left[ E_{x \\sim f}[\\ln(g(y|\\hat{\\theta}(x)))] \\right]\n$$\n其中，双重期望表示我们对训练数据 $x$（它决定了 $\\hat{\\theta}$）和新的、独立的验证数据 $y$ 两者都进行平均。\n\nAkaike 证明，从训练数据得到的最大化对数似然 $\\ell(\\hat{\\theta}) = \\ln(\\mathcal{L}(\\hat{\\theta}|x))$（其中 $\\mathcal{L}$ 是似然函数）是该目标量的一个有偏估计。对于大样本量 $n$，其渐近偏差近似为模型中可估计参数的数量 $k$。也就是说：\n$$\nE[\\ell(\\hat{\\theta})] \\approx E_{y \\sim f} \\left[ E_{x \\sim f}[\\ln(g(y|\\hat{\\theta}(x)))] \\right] + k\n$$\n因此，用于预测目的的期望对数似然的偏差校正估计是 $\\ell(\\hat{\\theta}) - k$。出于与离差统计量相关的历史原因，Akaike 将此量乘以 $-2$ 来定义他的准则：\n$$\nAIC = -2 (\\ell(\\hat{\\theta}) - k) = -2\\ell(\\hat{\\theta}) + 2k\n$$\n这就是赤池信息准则。较低的 AIC 值表示模型在拟合优度（高 $\\ell(\\hat{\\theta})$）和复杂度（低 $k$）之间有更好的预期权衡。\n\n偏差校正项 $k$ 是一个渐近结果。对于较小的样本量，当比率 $n/k$ 不大时（通常是当 $n/k  40$ 时），这种校正是不充分的。一个考虑了样本量的二阶校正项，可以提供更准确的信息损失估计。这就得到了小样本校正的赤池信息准则，即 AICc。更准确的偏差校正不是 $k$，而是 $k \\frac{n}{n-k-1}$。AICc 定义为：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k \\frac{n}{n-k-1}\n$$\nAICc 和 AIC 之间的关系可以通过分离出额外的惩罚项来表示：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k + 2k\\left(\\frac{n}{n-k-1} - 1\\right)\n$$\n$$\nAICc = AIC + 2k\\left(\\frac{n - (n-k-1)}{n-k-1}\\right) = AIC + 2k\\left(\\frac{k+1}{n-k-1}\\right)\n$$\n$$\nAICc = AIC + \\frac{2k(k+1)}{n-k-1}\n$$\n这种形式明确地显示了小样本校正惩罚项，它同时依赖于参数数量 $k$ 和样本量 $n$。当 $n \\to \\infty$ 时，校正项消失，并且 $AICc \\to AIC$。\n\n现在我们为给定的问题计算这些值。提供的值是：\n- 样本量, $n = 30$\n- 自由参数数量, $k = 8$\n- 最大化对数似然, $\\ell(\\hat{\\theta}) = -120$\n\n首先，我们计算 AIC：\n$$\nAIC = -2\\ell(\\hat{\\theta}) + 2k = -2(-120) + 2(8) = 240 + 16 = 256\n$$\n接下来，我们计算 AICc：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k \\frac{n}{n-k-1} = -2(-120) + 2(8) \\frac{30}{30-8-1}\n$$\n$$\nAICc = 240 + 16 \\left(\\frac{30}{21}\\right) = 240 + 16 \\left(\\frac{10}{7}\\right) = 240 + \\frac{160}{7}\n$$\n为了将其表示为单个分数：\n$$\nAICc = \\frac{240 \\times 7}{7} + \\frac{160}{7} = \\frac{1680 + 160}{7} = \\frac{1840}{7}\n$$\n问题要求对小样本校正进行解释。比率 $n/k = 30/8 = 3.75$。由于这个比率远小于通常经验法则的阈值 $40$，因此强烈推荐使用 AICc 而非 AIC。\n\n小样本校正的量级是 AICc 和 AIC 之间的差值：\n$$\n\\text{绝对校正值} = AICc - AIC = \\frac{1840}{7} - 256 = \\frac{1840 - 256 \\times 7}{7} = \\frac{1840 - 1792}{7} = \\frac{48}{7}\n$$\n这个 $\\frac{48}{7} \\approx 6.86$ 的绝对差异是相当大的。模型选择决策通常基于 AIC 值的差异（例如，大于 $2$ 的差异被认为是有意义的），因此这个校正值足够大，可能会改变关于哪个模型是最佳的结论。\n\n相对于 AIC 的相对校正值为：\n$$\n\\text{相对校正值} = \\frac{AICc - AIC}{AIC} = \\frac{48/7}{256} = \\frac{48}{7 \\times 256} = \\frac{3 \\times 16}{7 \\times 16 \\times 16} = \\frac{3}{7 \\times 16} = \\frac{3}{112}\n$$\n这对应于约 $\\frac{3}{112} \\approx 2.68\\%$ 的相对增加。AICc 值高于 AIC 值，反映了对模型复杂度的更大惩罚。这种增加的惩罚有助于防止过拟合，这是一种模型过分拟合特定数据集中的噪声，从而导致其在新数据上预测性能不佳的现象。在 $n/k$ 比率较低的情况下，这种风险尤其高，使得 AICc 校正对于稳健的模型选择至关重要。\n最终要求的输出是 $AIC$ 和 $AICc$ 的数值。\n\n$AIC = 256$\n$AICc = \\frac{1840}{7}$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 256  \\frac{1840}{7} \\end{pmatrix}}\n$$"
        }
    ]
}