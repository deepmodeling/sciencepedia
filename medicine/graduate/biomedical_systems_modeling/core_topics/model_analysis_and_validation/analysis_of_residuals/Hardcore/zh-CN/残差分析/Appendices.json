{
    "hands_on_practices": [
        {
            "introduction": "在普通最小二乘 (OLS) 回归中，残差具有特定的数学性质。本练习将通过经验验证其中一个最基本的性质：当模型包含截距时，残差之和为零。这项实践旨在加深对 OLS 几何投影本质的理解，并突显截距项在模型中的关键作用。",
            "id": "4982788",
            "problem": "考虑一个临床建模场景，其中使用普通最小二乘法 (OLS) 将收缩压对年龄和身体质量指数进行回归。设 $n$ 表示患者数量，$\\mathbf{y} \\in \\mathbb{R}^{n}$ 是以毫米汞柱 (mmHg) 为单位的实测收缩压值的向量，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是预测变量的设计矩阵。当包含截距项时，$\\mathbf{X}$ 的第一列是全为1的常数向量，其余列是观测到的协变量。OLS 估计量 $\\hat{\\boldsymbol{\\beta}}$ 最小化残差平方和 $\\sum_{i=1}^{n} \\left(y_{i} - \\hat{y}_{i}\\right)^{2}$，其中拟合值定义为 $\\hat{\\mathbf{y}} = \\mathbf{X} \\hat{\\boldsymbol{\\beta}}$，残差定义为 $e_{i} = y_{i} - \\hat{y}_{i}$（$i=1,\\dots,n$）。\n\n从基本的 OLS 设置和定义出发，您必须通过经验验证当模型包含截距项时，残差之和为零。您将实现的计算过程是：对于每个测试数据集，拟合 OLS 模型（根据指定是否包含截距项），构建残差 $e_{i} = y_{i} - \\hat{y}_{i}$，然后计算标量 $\\sum_{i=1}^{n} e_{i}$。您必须使用弧度来表示三角函数中使用的角度。每个测试数据集的最终结果必须以布尔值的形式报告，当且仅当残差之和的绝对值至多为 $\\tau = 10^{-10}$ (单位为 mmHg) 时，结果为真，否则为假。数值计算必须使用 Moore–Penrose 伪逆来获得 OLS 解。\n\n实现一个程序，对每个测试用例执行以下操作：\n- 根据是否包含截距项来构建设计矩阵 $\\mathbf{X}$。\n- 计算 $\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+} \\mathbf{y}$，其中 $\\mathbf{X}^{+}$ 表示 Moore–Penrose 伪逆。\n- 计算残差 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}}$ 和标量 $S = \\sum_{i=1}^{n} e_{i}$。\n- 返回一个布尔值，指示是否满足 $\\lvert S \\rvert \\le \\tau$。\n\n使用以下五个测试用例，所有用例均在物理现实范围内，并确保所有三角函数参数均以弧度为单位。在每个用例中，年龄以年为单位，身体质量指数以千克/平方米为单位，收缩压以毫米汞柱为单位。\n\n测试用例1 (一般情况，异方差噪声，包含截距项):\n- 样本量 $n_{1} = 26$。\n- 年龄：$a_{i} = 30 + 2i$，其中 $i = 0, 1, \\dots, 25$。\n- 身体质量指数：$b_{i} = 25 + 0.1(a_{i} - 50) + 2 \\sin(a_{i} / 10)$。\n- 噪声：$\\eta_{i} = 0.1 \\left(1 + 0.05 b_{i}\\right) \\sin(0.3 a_{i})$。\n- 收缩压：$y_{i} = 95 + 0.6 a_{i} + 1.1 b_{i} + \\eta_{i}$。\n- 包含截距项。\n\n测试用例2 (完美线性拟合，包含截距项):\n- 样本量 $n_{2} = 8$。\n- 年龄：$a_{i} \\in \\{20, 25, 30, 35, 40, 45, 50, 55\\}$ (按顺序)。\n- 身体质量指数：$b_{i} = 22 + 0.3 i$，其中 $i = 0, 1, \\dots, 7$。\n- 收缩压：$y_{i} = 90 + 0.5 a_{i} + 1.3 b_{i}$。\n- 包含截距项。\n\n测试用例3 (小样本，欠定，包含截距项):\n- 样本量 $n_{3} = 3$。\n- 年龄：$(40, 60, 80)$。\n- 身体质量指数：$(22, 30, 28)$。\n- 噪声向量：$(\\nu_{1}, \\nu_{2}, \\nu_{3}) = (0.1 \\times (-0.5), 0.1 \\times 0.3, 0.1 \\times (-0.2))$。\n- 收缩压：$y_{i} = 100 + 0.4 a_{i} + 1.0 b_{i} + \\nu_{i}$。\n- 包含截距项。\n\n测试用例4 (对比情况，数据与测试用例1相同，但不包含截距项):\n- 使用与测试用例1中相同的 $a_{i}$、$b_{i}$ 和 $y_{i}$。\n- 不包含截距项。\n\n测试用例5 (预测变量间存在强共线性，包含截距项):\n- 样本量 $n_{5} = 12$。\n- 年龄：$a_{i} = 30 + 5i$，其中 $i = 0, 1, \\dots, 11$。\n- 身体质量指数：$b_{i} = 15 + 0.2 a_{i} + 0.1 \\sin(a_{i})$。\n- 噪声：$\\xi_{i} = 0.05 \\cos(0.5 a_{i})$。\n- 收缩压：$y_{i} = 80 + 0.7 a_{i} + 0.5 b_{i} + \\xi_{i}$。\n- 包含截距项。\n\n您的程序应生成单行输出，其中包含五个测试用例的结果，按所列顺序排列，格式为方括号内以逗号分隔的列表，例如，“[result1,result2,result3,result4,result5]”。每个元素必须是一个布尔值，指示残差之和是否在上述定义的容差 $\\tau$ 范围内。不应产生其他任何输出。",
            "solution": "用户希望通过经验验证普通最小二乘法 (OLS) 回归的一个基本性质：当模型包含截距项时，残差之和为零。此验证将通过在多个测试数据集上进行数值计算来完成。\n\n### 第1步：OLS 残差的理论基础\n\nOLS 方法旨在找到使残差平方和 (SSR) 最小化的系数向量 $\\hat{\\boldsymbol{\\beta}}$。给定响应向量 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 和设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$，残差向量定义为 $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$，其中 $\\hat{\\mathbf{y}} = \\mathbf{X}\\boldsymbol{\\beta}$ 是拟合值。\n\nSSR 由下式给出：\n$$SSR(\\boldsymbol{\\beta}) = \\mathbf{e}^\\top\\mathbf{e} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\top(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})$$\n$$SSR(\\boldsymbol{\\beta}) = \\mathbf{y}^\\top\\mathbf{y} - 2\\boldsymbol{\\beta}^\\top\\mathbf{X}^\\top\\mathbf{y} + \\boldsymbol{\\beta}^\\top\\mathbf{X}^\\top\\mathbf{X}\\boldsymbol{\\beta}$$\n\n为求最小值，我们将 $SSR(\\boldsymbol{\\beta})$ 对 $\\boldsymbol{\\beta}$求导，并令梯度为零：\n$$\\nabla_{\\boldsymbol{\\beta}} SSR = -2\\mathbf{X}^\\top\\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{0}$$\n\n这就得到了**正规方程**：\n$$\\mathbf{X}^\\top\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^\\top\\mathbf{y}$$\n\nOLS 残差向量为 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$。通过左乘 $\\mathbf{X}^\\top$ 可以推导出这些残差的一个关键性质：\n$$\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{X}^\\top(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = \\mathbf{X}^\\top\\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$\n\n将正规方程代入此表达式，我们发现：\n$$\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{X}^\\top\\mathbf{y} - \\mathbf{X}^\\top\\mathbf{y} = \\mathbf{0}$$\n\n这个结果 $\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{0}$ 表明残差向量 $\\mathbf{e}$ 与设计矩阵 $\\mathbf{X}$ 的每个列向量正交。\n\n### 第2步：截距项的作用\n\n当回归模型包含截距项时，设计矩阵 $\\mathbf{X}$ 包含一个全为1的列向量，我们将其表示为 $\\mathbf{1} \\in \\mathbb{R}^{n}$。\n$$\\mathbf{X} = [\\mathbf{1} \\mid \\mathbf{x}_1 \\mid \\dots \\mid \\mathbf{x}_{p-1}]$$\n\n由于残差向量 $\\mathbf{e}$ 与 $\\mathbf{X}$ 的每一列都正交，因此它也必须与第一列 $\\mathbf{1}$ 正交：\n$$\\mathbf{1}^\\top\\mathbf{e} = 0$$\n\n展开这个点积可以得到各个残差之和：\n$$\\mathbf{1}^\\top\\mathbf{e} = \\sum_{i=1}^{n} 1 \\cdot e_i = \\sum_{i=1}^{n} e_i$$\n\n因此，对于任何包含截距项的 OLS 模型，从数学上必然得出残差之和为零：\n$$\\sum_{i=1}^{n} e_i = 0$$\n\n如果模型不包含截距项（即 $\\mathbf{X}$ 不包含全为1的列），正交条件 $\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{0}$ 仍然成立，但我们无法再断定 $\\mathbf{1}^\\top\\mathbf{e} = 0$。残差之和通常不为零。\n\n### 第3步：计算策略与 Moore-Penrose 伪逆\n\n问题要求使用 Moore-Penrose 伪逆 $\\mathbf{X}^{+}$ 来求解 OLS 系数。OLS 系数估计量由下式给出：\n$$\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+}\\mathbf{y}$$\n\n这种方法比通过矩阵求逆（例如 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\mathbf{y}$）求解正规方程更为通用，因为它在数值上是稳定的，并且即使在 $\\mathbf{X}$ 不是满列秩（例如，由于多重共线性）或不是一个“高”矩阵时，也能提供唯一解。\n\n残差向量计算如下：\n$$\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{y} - \\mathbf{X}\\mathbf{X}^{+}\\mathbf{y}$$\n\n对于包含截距项的模型，$\\sum e_i = 0$ 的理论性质在这种计算方法下仍然有效。然而，由于有限精度的浮点运算，计算出的和可能是一个非常小的非零数。因此，我们将通过检查和的绝对值是否小于或等于一个小容差 $\\tau = 10^{-10}$ 来测试该条件。\n\n每个测试用例的步骤如下：\n1.  生成响应向量 $\\mathbf{y}$ 和预测变量（年龄和BMI）。\n2.  构建设计矩阵 $\\mathbf{X}$。如果包含截距项，则在预测变量矩阵前添加一列全为1的向量。\n3.  使用 `numpy.linalg.pinv` 计算 $\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+}\\mathbf{y}$。\n4.  计算残差 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$。\n5.  计算总和 $S = \\sum_{i=1}^{n} e_i$。\n6.  评估布尔条件 $|\\S| \\le \\tau$。\n\n此程序应用于五个不同的测试用例。用例1、2、3和5包含截距项，预计将满足条件。用例4省略了截距项，预计不满足条件，作为一个关键的对照。用例2（完美拟合）和用例3（饱和模型，$n=p$）是特殊情况，其中残差本身应几乎为零，从而保证其和为零。用例5测试了在强多重共线性下该性质的稳健性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Empirically verifies the OLS property that residuals sum to zero for models\n    with an intercept.\n    \"\"\"\n\n    def get_test_cases():\n        \"\"\"Generates data for the five specified test cases.\"\"\"\n        cases = []\n        \n        # Test case 1: General case with heteroscedastic noise, intercept included.\n        n1 = 26\n        i1 = np.arange(n1)\n        a1 = 30.0 + 2.0 * i1\n        b1 = 25.0 + 0.1 * (a1 - 50.0) + 2.0 * np.sin(a1 / 10.0)\n        eta1 = 0.1 * (1.0 + 0.05 * b1) * np.sin(0.3 * a1)\n        y1 = 95.0 + 0.6 * a1 + 1.1 * b1 + eta1\n        predictors1 = np.stack([a1, b1], axis=1)\n        cases.append({'y': y1, 'predictors': predictors1, 'intercept': True, 'name': 'Case 1'})\n\n        # Test case 2: Perfect linear fit, intercept included.\n        n2 = 8\n        a2 = np.array([20.0, 25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0])\n        i2 = np.arange(n2)\n        b2 = 22.0 + 0.3 * i2\n        y2 = 90.0 + 0.5 * a2 + 1.3 * b2\n        predictors2 = np.stack([a2, b2], axis=1)\n        cases.append({'y': y2, 'predictors': predictors2, 'intercept': True, 'name': 'Case 2'})\n\n        # Test case 3: Small sample, saturated model (n=p), intercept included.\n        n3 = 3\n        a3 = np.array([40.0, 60.0, 80.0])\n        b3 = np.array([22.0, 30.0, 28.0])\n        nu3 = 0.1 * np.array([-0.5, 0.3, -0.2])\n        y3 = 100.0 + 0.4 * a3 + 1.0 * b3 + nu3\n        predictors3 = np.stack([a3, b3], axis=1)\n        cases.append({'y': y3, 'predictors': predictors3, 'intercept': True, 'name': 'Case 3'})\n\n        # Test case 4: Contrast case, same data as case 1 but without intercept.\n        cases.append({'y': y1, 'predictors': predictors1, 'intercept': False, 'name': 'Case 4'})\n\n        # Test case 5: Strong collinearity, intercept included.\n        n5 = 12\n        i5 = np.arange(n5)\n        a5 = 30.0 + 5.0 * i5\n        b5 = 15.0 + 0.2 * a5 + 0.1 * np.sin(a5)\n        xi5 = 0.05 * np.cos(0.5 * a5)\n        y5 = 80.0 + 0.7 * a5 + 0.5 * b5 + xi5\n        predictors5 = np.stack([a5, b5], axis=1)\n        cases.append({'y': y5, 'predictors': predictors5, 'intercept': True, 'name': 'Case 5'})\n\n        return cases\n\n    test_cases = get_test_cases()\n    results = []\n    tau = 1.0e-10\n\n    for case in test_cases:\n        y = case['y']\n        predictors = case['predictors']\n        include_intercept = case['intercept']\n\n        # Construct the design matrix X\n        if include_intercept:\n            n_obs = predictors.shape[0]\n            intercept_col = np.ones((n_obs, 1))\n            X = np.hstack([intercept_col, predictors])\n        else:\n            X = predictors\n\n        # Compute OLS solution using Moore-Penrose pseudoinverse\n        X_pinv = np.linalg.pinv(X)\n        beta_hat = X_pinv @ y\n        \n        # Compute residuals and their sum\n        residuals = y - (X @ beta_hat)\n        residual_sum = np.sum(residuals)\n        \n        # Check if the sum is within the tolerance\n        is_zero = abs(residual_sum) = tau\n        results.append(is_zero)\n    \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "原始残差虽然有用，但其量级取决于数据的单位，这使得直接比较变得困难。为了建立一个通用的标准来识别异常观测值（离群点），我们使用标准化残差。本练习将指导您计算这些残差，它们同时考虑了模型的整体误差和每个数据点的杠杆率，从而能够对模型拟合情况进行更客观的评估。",
            "id": "4982808",
            "problem": "考虑一项临床流行病学中的队列研究，其中生物标志物C-反应蛋白 (CRP) 以毫克/升为单位进行测量，然后进行对数转换以稳定方差。将对数转换后的CRP记为 $y_i$，年龄（以年为单位）记为 $x_i$，吸烟状态指示变量记为 $z_i$，其中 $z_i \\in \\{0,1\\}$，$z_i=1$ 表示当前吸烟者，$z_i=0$ 表示其他情况。我们考虑一个针对 $i=1,\\dots,n$ 的线性模型，定义为 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中误差项 $\\varepsilon_i$ 假定为独立同分布的高斯分布，均值为 $0$，方差为 $\\sigma^2$。使用普通最小二乘法 (OLS)，从数据中获得拟合值和残差，帽子矩阵的对角元素 $h_{ii}$ 用于量化杠杆值。标准化残差 $r_i$ 用于回归诊断，以评估模型充分性和异常值，而诸如 $|r_i|>2$ 之类的数值阈值通常根据标准正态参考分布下的近似尾部概率进行解释。\n\n根据高斯-马尔可夫 (Gauss–Markov) 假设的基本原理以及 OLS 估计量的性质，实现一个算法，该算法：\n- 使用设计矩阵 $X$（其列分别为截距项、年龄 $x_i$ 和吸烟指示变量 $z_i$）拟合线性模型以获得 $\\hat{\\beta}$。\n- 计算残差 $e_i$ 和帽子矩阵 $H$ 以获得 $h_{ii}$。\n- 使用 $n-p$ 自由度，通过残差均方 $s^2$ 估计 $\\sigma^2$，其中 $p$ 是包括截距在内的回归系数数量（此处 $p=3$）。\n- 计算所有观测值的标准化残差 $r_i$。\n- 通过报告在标准正态参考下的近似双侧尾部概率 $2\\{1 - \\Phi(2)\\}$ 来解释阈值 $|r_i|>2$，其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。此外，报告每个残差的近似双侧尾部概率 $p_i = 2\\Phi(-|r_i|)$。\n\n所有年龄 $x_i$ 必须以年为单位处理。由于 $y_i$ 是对数值，因此输出是无单位的。\n\n您的程序必须将上述方法应用于以下三个数据集的测试套件，每个数据集均指定为三元组 $(\\{x_i\\},\\{z_i\\},\\{y_i\\})$：\n\n- 测试用例 1（典型变异性，$n=10$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[22,34,47,51,36,63,41,55,29,68]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1,0,1,0,1,0,1]$\n  - 对数-CRP $\\{y_i\\}$: $[0.79,1.35,1.24,1.59,1.15,1.85,1.26,1.80,0.96,1.97]$\n\n- 测试用例 2（一个高杠杆率异常值，$n=8$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[25,40,45,50,55,60,65,95]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,0,1,0,1,0,1,1]$\n  - 对数-CRP $\\{y_i\\}$: $[0.93,1.16,1.61,1.41,1.70,1.62,1.95,0.80]$\n\n- 测试用例 3（接近边界的小样本，$n=4$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[30,50,70,60]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1]$\n  - 对数-CRP $\\{y_i\\}$: $[1.01,1.64,1.78,1.86]$\n\n对于每个测试用例，生成：\n- 标准化残差列表 $[r_1,\\dots,r_n]$，四舍五入到 $6$ 位小数。\n- 近似双侧尾部概率列表 $[p_1,\\dots,p_n]$，其中 $p_i = 2\\Phi(-|r_i|)$，四舍五入到 $6$ 位小数。\n- 残差绝对值大于2的整数计数 $c$。\n- 浮点数 $\\pi_2 = 2\\{1 - \\Phi(2)\\}$，四舍五入到 $6$ 位小数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试用例，并且本身是按上述顺序排列的列表。例如，总体格式为 $[[\\text{case1\\_residuals},\\text{case1\\_pvals},c_1,\\pi_2],[\\text{case2\\_residuals},\\text{case2\\_pvals},c_2,\\pi_2],[\\text{case3\\_residuals},\\text{case3\\_pvals},c_3,\\pi_2]]$。所有概率必须以小数形式表示，不能使用百分号。",
            "solution": "用户提供了一个统计回归诊断领域的问题，要求实现一个算法来计算和解释多元线性回归模型的标准化残差。问题陈述已经过严格验证，并被确定为有效。\n\n### 验证结论：\n该问题是**有效的**。\n- **科学依据**：该问题基于线性模型、普通最小二乘 (OLS) 估计和标准回归诊断的经典理论。所有概念，包括高斯-马尔可夫模型、帽子矩阵、杠杆值和标准化残差，都是统计学的基础。\n- **适定性**：问题定义清晰，所有必要的数据和数学公式均已提供或是该领域的标准。对于所提供的数据集，OLS 解存在且唯一，因为设计矩阵具有满列秩（$np$ 且没有完全共线性）。\n- **客观性**：问题使用精确、无歧义的数学语言陈述，没有主观性断言。\n- **完整与一致性**：提供了三个测试用例的所有必需数据，并明确概述了算法的步骤。方差估计量 $s^2$ 及其自由度的定义与标准 OLS 理论一致。标准化残差的定义隐含为标准定义 $r_i = e_i / (s \\sqrt{1-h_{ii}})$，这是恰当的。\n\n该问题是已建立的统计方法的直接应用，并且已完全指定，从而可以得到唯一且可验证的解。\n\n### 解题推导\n将遵循问题陈述中概述的算法步骤来实现解决方案，这些步骤基于普通最小二乘 (OLS) 回归的原理。\n\n对于每个包含 $n$ 个 $(y_i, x_i, z_i)$ 观测值的数据集，我们将模型定义为：\n$y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\text{i.i.d. } N(0, \\sigma^2)$。\n\n这可以用矩阵形式表示为 $y = X\\beta + \\varepsilon$，其中：\n- $y$ 是 $n \\times 1$ 的响应向量 $\\{y_i\\}$。\n- $X$ 是 $n \\times p$ 的设计矩阵，其中 $p=3$。$X$ 的列分别是代表截距 $\\beta_0$ 的全1向量、年龄向量 $\\{x_i\\}$ 和吸烟指示变量向量 $\\{z_i\\}$。\n- $\\beta = (\\beta_0, \\beta_1, \\beta_2)^T$ 是系数向量。\n- $\\varepsilon$ 是误差项向量。\n\n算法按以下步骤进行：\n\n**1. $\\beta$ 的 OLS 估计**：\nOLS 估计量 $\\hat{\\beta}$ 最小化残差平方和 $RSS = \\sum e_i^2 = (y - X\\beta)^T(y - X\\beta)$。解由正规方程给出：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n$$\n\n**2. 残差和帽子矩阵的计算**：\n- 拟合值计算为 $\\hat{y} = X\\hat{\\beta}$。\n- 原始残差是观测值与拟合值之间的差异：$e = y - \\hat{y}$。\n- 帽子矩阵 $H$ 将观测值 $y$ 投影到由 $X$ 的列张成的空间上以产生拟合值：$\\hat{y} = Hy$。其定义为：\n$$\nH = X(X^T X)^{-1} X^T\n$$\n帽子矩阵的对角元素 $h_{ii}$ 是每个观测值的杠杆分数。它们满足 $0 \\le h_{ii} \\le 1$ 和 $\\sum_{i=1}^n h_{ii} = p$。\n\n**3. 误差方差 $\\sigma^2$ 的估计**：\n未知误差方差 $\\sigma^2$ 通过残差均方 $s^2$ 进行估计：\n$$\ns^2 = \\frac{RSS}{n-p} = \\frac{e^T e}{n-p}\n$$\n其中 $n-p$ 是残差自由度。误差标准差的估计量是 $s = \\sqrt{s^2}$。\n\n**4. 标准化残差的计算**：\n第 $i$ 个原始残差 $e_i$ 的方差是 $\\text{Var}(e_i) = \\sigma^2(1-h_{ii})$。标准化残差 $r_i$ 是原始残差除以其估计的标准差：\n$$\nr_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}}\n$$\n在模型假设下，每个 $r_i$ 的均值约为 $0$，方差约为 $1$。对于大的 $n$，它们的分布可以很好地用标准正态分布 $N(0, 1)$ 来近似。\n\n**5. 概率计算**：\n- 阈值 $|r_i|  2$ 的参考概率是在标准正态近似下计算的：\n$$\n\\pi_2 = P(|Z|  2) = 2 \\cdot P(Z  2) = 2 \\Phi(-2)\n$$\n其中 $Z \\sim N(0,1)$，$\\Phi(\\cdot)$ 是标准正态累积分布函数 (CDF)。\n- 对于每个标准化残差 $r_i$，其对应的近似双侧尾部概率为：\n$$\np_i = P(|Z|  |r_i|) = 2 \\Phi(-|r_i|)\n$$\n标准正态 CDF 是使用其与 `scipy.special` 中可用的误差函数 $\\text{erf}(x)$ 的关系来计算的：\n$$\n\\Phi(z) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)\n$$\n这导出了双侧尾部概率的表达式：\n$$\np_i = 2(1 - \\Phi(|r_i|)) = 2\\left(1 - \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\\right)\\right) = 1 - \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\n$$\n类似的公式也适用于 $\\pi_2$。实现将使用这种基于 `erf` 的计算。\n\n最后一步是计算 $|r_i|  2$ 的残差数量 $c$，并将所有结果组合成指定的输出格式。这个完整的过程将应用于三个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (typical variability, n=10, p=3)\n        (\n            [22, 34, 47, 51, 36, 63, 41, 55, 29, 68],  # Ages {x_i}\n            [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],          # Smoking indicators {z_i}\n            [0.79, 1.35, 1.24, 1.59, 1.15, 1.85, 1.26, 1.80, 0.96, 1.97] # Log-CRP {y_i}\n        ),\n        # Test case 2 (one high-leverage outlier, n=8, p=3)\n        (\n            [25, 40, 45, 50, 55, 60, 65, 95],         # Ages {x_i}\n            [0, 0, 1, 0, 1, 0, 1, 1],                 # Smoking indicators {z_i}\n            [0.93, 1.16, 1.61, 1.41, 1.70, 1.62, 1.95, 0.80] # Log-CRP {y_i}\n        ),\n        # Test case 3 (near-boundary small sample, n=4, p=3)\n        (\n            [30, 50, 70, 60],                         # Ages {x_i}\n            [0, 1, 0, 1],                             # Smoking indicators {z_i}\n            [1.01, 1.64, 1.78, 1.86]                  # Log-CRP {y_i}\n        )\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        result = process_case(case_data)\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The str() of a list automatically includes spaces, e.g., '[1, 2]'.\n    # To get a compact representation, we can build the string manually.\n    result_strings = []\n    for res in all_results:\n        r_list_str = f\"[{','.join(map(str, res[0]))}]\"\n        p_list_str = f\"[{','.join(map(str, res[1]))}]\"\n        c_str = str(res[2])\n        pi2_str = str(res[3])\n        result_strings.append(f\"[{r_list_str},{p_list_str},{c_str},{pi2_str}]\")\n    \n    # The problem example implies that str(list) is fine. Let's use the simpler approach.\n    print(str(all_results).replace(\" \", \"\"))\n\n\ndef process_case(case_data):\n    \"\"\"\n    Implements OLS regression and diagnostics for a single dataset.\n\n    Args:\n        case_data (tuple): A tuple containing lists for ages, smoking indicators,\n                           and log-CRP values.\n\n    Returns:\n        list: A list containing [standardized_residuals, tail_probabilities, count, pi_2].\n    \"\"\"\n    x_i, z_i, y_i = case_data\n    \n    # Convert input lists to numpy arrays for vector/matrix operations.\n    x_vec = np.array(x_i)\n    z_vec = np.array(z_i)\n    y_vec = np.array(y_i)\n    \n    n = len(y_vec)  # Number of observations\n    p = 3           # Number of parameters (beta_0, beta_1, beta_2)\n    \n    # Construct the n x p design matrix X.\n    X = np.ones((n, p))\n    X[:, 1] = x_vec\n    X[:, 2] = z_vec\n    \n    # Step 1: Fit the linear model using OLS to get beta_hat.\n    # beta_hat = (X'X)^-1 * X'y\n    XTX = X.T @ X\n    XTX_inv = np.linalg.inv(XTX)\n    XTY = X.T @ y_vec\n    beta_hat = XTX_inv @ XTY\n    \n    # Step 2: Compute residuals and hat matrix.\n    # Fitted values: y_hat = X * beta_hat\n    y_hat = X @ beta_hat\n    # Raw residuals: e = y - y_hat\n    residuals = y_vec - y_hat\n    # Hat matrix: H = X * (X'X)^-1 * X'\n    hat_matrix = X @ XTX_inv @ X.T\n    # Leverage values (diagonal of H): h_ii\n    leverages = np.diag(hat_matrix)\n    \n    # Step 3: Estimate error variance sigma^2.\n    # Residual Sum of Squares (RSS)\n    rss = residuals.T @ residuals\n    # Degrees of freedom for error\n    df = n - p\n    # Residual Mean Square (s^2)\n    s_squared = rss / df\n    # Residual standard error (s)\n    s = np.sqrt(s_squared)\n    \n    # Step 4: Compute standardized residuals.\n    # r_i = e_i / (s * sqrt(1 - h_ii))\n    denom = s * np.sqrt(1 - leverages)\n    # Avoid division by zero in case of h_ii=1 (not expected here)\n    # Adding a small epsilon would be robust, but not necessary for these test cases.\n    standardized_residuals = residuals / denom\n    \n    # Step 5  6: Compute tail probabilities and count.\n    # The two-sided tail probability is P(|Z| > |x|) = 2 * (1 - Phi(|x|))\n    # which simplifies to 1 - erf(|x|/sqrt(2)).\n    \n    # For the threshold |r_i| > 2\n    pi_2 = 1.0 - erf(2.0 / np.sqrt(2.0))\n    \n    # For each standardized residual\n    tail_probabilities = 1.0 - erf(np.abs(standardized_residuals) / np.sqrt(2.0))\n    \n    # Count of residuals with absolute value greater than 2.\n    count_gt_2 = np.sum(np.abs(standardized_residuals) > 2)\n\n    # Prepare the output lists and values, rounded to 6 decimal places.\n    r_list = np.round(standardized_residuals, 6).tolist()\n    p_vals_list = np.round(tail_probabilities, 6).tolist()\n    \n    return [r_list, p_vals_list, int(count_gt_2), round(pi_2, 6)]\n\n# Execute the solver\nsolve()\n```"
        },
        {
            "introduction": "并非所有离群点都会对模型的结论产生重大影响。本练习介绍库克距离 (Cook's distance)，这是一个衡量单个观测值对模型参数估计影响的关键诊断指标。通过推导和计算该指标，您将理解残差的大小和数据点的杠杆率是如何共同决定其整体影响力的，这是构建稳健的生物医学模型时的一个核心概念。",
            "id": "3871239",
            "problem": "一个生物医学系统模型被用于在一个队列研究中关联暴露向量与多生物标志物响应。在一个工作点附近进行线性化后，单个生物标志物的模型表示为标准线性回归，\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon},\n$$\n其中 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 是测量的对数转换响应向量，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是编码暴露和协变量（包括截距）的设计矩阵，$\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$ 是未知参数向量，$\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{n}$ 是满足 $\\mathbb{E}[\\boldsymbol{\\varepsilon}]=\\mathbf{0}$ 和 $\\operatorname{Var}(\\boldsymbol{\\varepsilon})=\\sigma^{2}\\mathbf{I}_{n}$ 的噪声向量。普通最小二乘（OLS）估计量为 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}$，拟合值为 $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$，残差为 $\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{y}}$。令帽子矩阵为 $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}$，第 $i$ 个观测值的杠杆值为 $h_{ii} = \\mathbf{x}_{i}^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_{i}$，其中 $\\mathbf{x}_{i}^{\\top}$ 是 $\\mathbf{X}$ 的第 $i$ 行。\n\n考虑删除观测值 $i$，得到留一法估计量 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 和拟合值 $\\hat{\\mathbf{y}}_{(i)}$。仅从线性模型、上述 OLS 定义和标准矩阵恒等式出发，推导观测值 $i$ 的 Cook 距离，将其作为因案例删除引起的拟合值变化的标量度量。明确地将此标量与残差 $r_{i}$、杠杆值 $h_{ii}$ 以及由 $\\boldsymbol{\\beta}$ 的变化量化的参数影响联系起来。根据需要使用参数数量 $p$ 和全模型残差方差估计 $\\hat{\\sigma}^{2} = \\|\\mathbf{r}\\|^{2}/(n-p)$。\n\n然后，对于一个药物基因组学子研究中的特定患者，其参数为 $p=4$，残差 $r_{i}=0.85$，杠杆值 $h_{ii}=0.12$，全模型方差估计 $\\hat{\\sigma}^{2}=0.30$，计算该观测值的 Cook 距离。将最终数值答案四舍五入到四位有效数字。Cook 距离是无单位的；将最终值表示为无单位量。",
            "solution": "问题要求在线性回归模型中推导单个观测值 $i$ 的 Cook 距离，并随后为一特定案例计算其值。\n\n首先，我们验证问题。\n\n### 第1步：提取已知条件\n- 模型：$\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$\n- $\\mathbf{y} \\in \\mathbb{R}^{n}$：响应向量\n- $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$：设计矩阵\n- $\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$：参数向量\n- $\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{n}$：噪声向量，满足 $\\mathbb{E}[\\boldsymbol{\\varepsilon}]=\\mathbf{0}$ 和 $\\operatorname{Var}(\\boldsymbol{\\varepsilon})=\\sigma^{2}\\mathbf{I}_{n}$\n- OLS 估计量：$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}$\n- 拟合值：$\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$\n- 残差：$\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{y}}$\n- 帽子矩阵：$\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}$\n- 观测值 $i$ 的杠杆值：$h_{ii} = \\mathbf{x}_{i}^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_{i}$，其中 $\\mathbf{x}_{i}^{\\top}$ 是 $\\mathbf{X}$ 的第 $i$ 行\n- 留一法估计量：$\\hat{\\boldsymbol{\\beta}}_{(i)}$\n- 残差方差估计：$\\hat{\\sigma}^{2} = \\|\\mathbf{r}\\|^{2}/(n-p)$\n- 特定案例数据：$p=4$, $r_{i}=0.85$, $h_{ii}=0.12$, $\\hat{\\sigma}^{2}=0.30$\n- 任务：推导 Cook 距离，然后为特定案例计算其值，结果四舍五入到四位有效数字。\n\n### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据，是统计学中回归诊断的标准课题。问题提法很严谨，为获得唯一解提供了所有必要的定义和数据。语言客观且数学上精确。问题是自洽的，没有矛盾或事实错误。该任务与生物医学建模中的残差分析直接相关。\n\n### 第3步：结论与行动\n问题有效。将提供完整解答。\n\n### Cook 距离的推导\nCook 距离 $D_i$ 衡量观测值 $i$ 对模型参数的影响。它可以定义为使用和不使用第 $i$ 个观测值计算出的拟合值向量之间的欧几里得距离平方，并由模型方差和自由度进行缩放。一个等价且更具洞察力的定义是基于参数向量 $\\boldsymbol{\\beta}$ 的位移：\n$$\nD_i = \\frac{(\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)})^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})(\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)})}{p\\hat{\\sigma}^{2}}\n$$\n这种形式量化了观测值 $i$ 对参数估计 $\\hat{\\boldsymbol{\\beta}}$ 的影响。我们的目标是用残差 $r_i$ 和杠杆值 $h_{ii}$ 来表示它。\n\n关键是找到系数变化 $\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)}$ 的表达式。留一法估计量 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 是使用移除了第 $i$ 个观测值的数据计算得出的。令 $\\mathbf{X}_{(i)}$ 和 $\\mathbf{y}_{(i)}$ 表示删除了第 $i$ 个案例后的设计矩阵和响应向量。我们可以写出：\n$$\n\\mathbf{X}^{\\top}\\mathbf{X} = \\sum_{j=1}^{n} \\mathbf{x}_j \\mathbf{x}_j^{\\top} = \\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)} + \\mathbf{x}_i \\mathbf{x}_i^{\\top}\n$$\n$$\n\\mathbf{X}^{\\top}\\mathbf{y} = \\sum_{j=1}^{n} \\mathbf{x}_j y_j = \\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)} + \\mathbf{x}_i y_i\n$$\n由此，我们得到 $\\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)} = \\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top}$ 和 $\\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)} = \\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i$。\n\n留一法估计量为 $\\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)})^{-1}\\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)}$。代入上述表达式：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1}(\\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i)\n$$\n为了处理秩为1更新矩阵的逆，我们使用 Sherman-Morrison-Woodbury 公式：$(\\mathbf{A} - \\mathbf{u}\\mathbf{v}^{\\top})^{-1} = \\mathbf{A}^{-1} + \\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^{\\top}\\mathbf{A}^{-1}}{1 - \\mathbf{v}^{\\top}\\mathbf{A}^{-1}\\mathbf{u}}$。\n令 $\\mathbf{A} = \\mathbf{X}^{\\top}\\mathbf{X}$ 和 $\\mathbf{u} = \\mathbf{v} = \\mathbf{x}_i$，我们得到：\n$$\n(\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - \\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i}\n$$\n分母包含杠杆值 $h_{ii} = \\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i$。所以，\n$$\n(\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - h_{ii}}\n$$\n现在，将此代回 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 的表达式中：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\left[ (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - h_{ii}} \\right] (\\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i)\n$$\n展开此乘积得到四项：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\underbrace{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}}_{\\hat{\\boldsymbol{\\beta}}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i y_i + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}\\overbrace{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}}^{\\hat{\\boldsymbol{\\beta}}}}{1 - h_{ii}} - \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\overbrace{\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i}^{h_{ii}} y_i}{1 - h_{ii}}\n$$\n认识到拟合值 $\\hat{y}_i = \\mathbf{x}_i^{\\top}\\hat{\\boldsymbol{\\beta}}$，第三项简化为：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i y_i + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\hat{y}_i}{1 - h_{ii}} - \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i h_{ii} y_i}{1 - h_{ii}}\n$$\n提出公因子 $(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i$：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( y_i - \\frac{\\hat{y}_i}{1 - h_{ii}} + \\frac{h_{ii} y_i}{1 - h_{ii}} \\right)\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i(1 - h_{ii}) - \\hat{y}_i + h_{ii} y_i}{1 - h_{ii}} \\right) = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i - y_i h_{ii} - \\hat{y}_i + h_{ii} y_i}{1 - h_{ii}} \\right)\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)\n$$\n使用残差的定义 $r_i = y_i - \\hat{y}_i$，我们得到系数变化的表达式：\n$$\n\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}}\n$$\n这个方程明确地量化了观测值 $i$ 的参数影响。现在我们将其代入 Cook 距离的定义中：\n$$\nD_i = \\frac{1}{p\\hat{\\sigma}^{2}} \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}} \\right)^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X}) \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}} \\right)\n$$\n$$\nD_i = \\frac{1}{p\\hat{\\sigma}^{2}} \\left( \\frac{r_i}{1-h_{ii}} \\right)^2 \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\right)^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X}) \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\right)\n$$\n$$\nD_i = \\frac{r_i^2}{p\\hat{\\sigma}^{2}(1-h_{ii})^2} \\left( \\mathbf{x}_i^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} (\\mathbf{X}^{\\top}\\mathbf{X}) (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{x}_i \\right)\n$$\n括号中的表达式简化为 $\\mathbf{x}_i^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{x}_i = h_{ii}$。因此，我们得到了 Cook 距离的最终所需形式：\n$$\nD_i = \\frac{r_i^2}{p\\hat{\\sigma}^{2}} \\frac{h_{ii}}{(1-h_{ii})^2}\n$$\n这个结果优雅地表明，一个观测值的影响 $D_i$ 是其残差平方（拟合不佳的程度）、杠杆值（其在预测变量空间中离中心的距离）、参数数量和整体模型误差的函数。\n\n### 数值计算\n对于一个特定患者，我们有以下给定值：\n- 参数数量 $p = 4$\n- 残差 $r_i = 0.85$\n- 杠杆值 $h_{ii} = 0.12$\n- 全模型残差方差估计 $\\hat{\\sigma}^{2} = 0.30$\n\n我们将这些值代入推导出的 Cook 距离公式中：\n$$\nD_i = \\frac{(0.85)^2}{(4)(0.30)} \\frac{0.12}{(1 - 0.12)^2}\n$$\n首先，计算表达式的各个组成部分：\n- $r_i^2 = (0.85)^2 = 0.7225$\n- $p\\hat{\\sigma}^2 = 4 \\times 0.30 = 1.2$\n- $1 - h_{ii} = 1 - 0.12 = 0.88$\n- $(1 - h_{ii})^2 = (0.88)^2 = 0.7744$\n\n现在，将这些代回 $D_i$ 的表达式中：\n$$\nD_i = \\frac{0.7225}{1.2} \\times \\frac{0.12}{0.7744}\n$$\n$$\nD_i \\approx (0.6020833...) \\times (0.1549651...)\n$$\n$$\nD_i \\approx 0.09330357...\n$$\n问题要求将最终答案四舍五入到四位有效数字。\n$$\nD_i \\approx 0.09330\n$$\n该观测值的 Cook 距离约为 $0.09330$。",
            "answer": "$$\n\\boxed{0.09330}\n$$"
        }
    ]
}