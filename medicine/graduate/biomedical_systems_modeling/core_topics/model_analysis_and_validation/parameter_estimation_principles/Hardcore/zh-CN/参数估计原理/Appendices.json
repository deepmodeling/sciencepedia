{
    "hands_on_practices": [
        {
            "introduction": "在尝试估计模型参数之前，我们必须首先确定一个根本问题：仅从实验数据中是否可能唯一地确定参数值。这个基本属性被称为结构可辨识性。本练习将引导您从第一性原理出发，为一个简单的线性模型推导可辨识性条件，为分析更复杂的系统建立坚实的理论基础 。",
            "id": "3916249",
            "problem": "考虑一个生物医学系统建模中简化但科学上合理的输注-响应子系统模型，其中测量的输出 $y(t)$（例如，与给药输入成比例的生物标志物浓度）在有限的观察窗口内对所有 $t$ 满足 $y(t)=\\theta u(t)$，其中未知的实标量参数 $\\theta$ 捕捉了从输入 $u(t)$ 到输出 $y(t)$ 的增益。假设在不同的时间点 $t_1,\\dots,t_N$ 进行无噪声测量 $y(t_i)$，并且输入 $u(t)$ 是完全已知的，可以在这些时间点进行评估。使用结构可辨识性的定义，即在给定输入下参数到输出映射的单射性，从第一性原理推导使 $\\theta$ 具有结构可辨识性的输入值 $u(t_1),\\dots,u(t_N)$ 的充分必要条件。然后，在这些条件下，推导出一个显式的闭式逆映射，从测量数据 $\\{(t_i,u(t_i),y(t_i))\\}_{i=1}^{N}$ 中恢复 $\\theta$，而不使用任何快捷公式。你的最终答案必须是仅用 $\\{u(t_i),y(t_i)\\}_{i=1}^{N}$ 表示 $\\theta$ 的单一解析表达式。无需四舍五入；请精确表达你的答案，最终表达式中不需要物理单位。",
            "solution": "该问题要求我们首先推导参数 $\\theta$ 结构可辨识的条件，然后推导从数据中求解 $\\theta$ 的显式逆映射。\n\n**第一步：可辨识性条件**\n首先，我们将参数到输出的映射形式化。模型方程为 $y(t_i) = \\theta u(t_i)$，适用于 $i = 1, \\dots, N$。我们可以将这组方程写成向量形式。设观测输出向量为 $\\mathbf{y} = \\begin{pmatrix} y(t_1), \\dots, y(t_N) \\end{pmatrix}^T$，已知输入向量为 $\\mathbf{u} = \\begin{pmatrix} u(t_1), \\dots, u(t_N) \\end{pmatrix}^T$。模型方程变为：\n$$\\mathbf{y} = \\theta \\mathbf{u}$$\n参数到输出的映射 $\\mathcal{M}$ 是一个函数，它接受参数 $\\theta$ 并为给定的输入实验 $\\mathbf{u}$ 产生输出向量 $\\mathbf{y}$，即 $\\mathcal{M}(\\theta) = \\theta \\mathbf{u}$。\n\n结构可辨识性要求映射 $\\mathcal{M}$ 是单射的（一对一的）。这意味着如果两个不同的参数值 $\\theta_1$ 和 $\\theta_2$ 产生相同的输出，那么这两个参数值必须相等。形式上：\n$$\\mathcal{M}(\\theta_1) = \\mathcal{M}(\\theta_2) \\implies \\theta_1 = \\theta_2$$\n将映射的定义代入前提 $\\mathcal{M}(\\theta_1) = \\mathcal{M}(\\theta_2)$，我们得到：\n$$\\theta_1 \\mathbf{u} = \\theta_2 \\mathbf{u}$$\n整理后得：\n$$(\\theta_1 - \\theta_2) \\mathbf{u} = \\mathbf{0}$$\n其中 $\\mathbf{0}$ 是 $N$ 维零向量。这个向量方程意味着对于所有 $i=1, \\dots, N$，都有 $(\\theta_1 - \\theta_2) u(t_i) = 0$。\n\n为了使 $\\theta_1 = \\theta_2$（即 $\\theta_1 - \\theta_2 = 0$）成为这个方程的唯一解，必须存在至少一个时间点 $t_j$ 使得 $u(t_j) \\neq 0$。如果存在这样的 $u(t_j)$，那么 $(\\theta_1 - \\theta_2) u(t_j) = 0$ 必然要求 $\\theta_1 - \\theta_2 = 0$。反之，如果对于所有时间点 $t_i$，都有 $u(t_i)=0$（即 $\\mathbf{u} = \\mathbf{0}$），那么方程 $(\\theta_1 - \\theta_2) \\cdot 0 = 0$ 对于任意的 $\\theta_1$ 和 $\\theta_2$ 都成立，我们无法得出 $\\theta_1 = \\theta_2$ 的结论。\n\n因此，$\\theta$ 具有结构可辨识性的充分必要条件是：**输入向量 $\\mathbf{u}$ 不是零向量，即必须存在至少一个测量时间点 $t_i$，在该时间点输入 $u(t_i)$ 不为零。**\n\n**第二步：推导逆映射**\n在满足可辨识性条件的情况下，我们需要从数据 $\\{(t_i, u(t_i), y(t_i))\\}_{i=1}^{N}$ 中求解 $\\theta$。即使在无噪声的情况下，使用最小二乘法也是一种系统性的方法，它通过最小化模型预测与测量值之间的残差平方和来找到最优参数。\n\n定义成本函数 $J(\\theta)$ 为残差平方和：\n$$J(\\theta) = \\sum_{i=1}^{N} (y(t_i) - \\theta u(t_i))^2$$\n为了找到最小化 $J(\\theta)$ 的 $\\theta$ 值，我们对 $J$ 关于 $\\theta$ 求导并设为零：\n$$\\frac{dJ}{d\\theta} = \\sum_{i=1}^{N} 2(y(t_i) - \\theta u(t_i))(-u(t_i)) = -2 \\sum_{i=1}^{N} (y(t_i)u(t_i) - \\theta u(t_i)^2)$$\n将导数设为零：\n$$\\sum_{i=1}^{N} (y(t_i)u(t_i) - \\theta u(t_i)^2) = 0$$\n$$\\sum_{i=1}^{N} y(t_i)u(t_i) - \\theta \\sum_{i=1}^{N} u(t_i)^2 = 0$$\n整理后得到：\n$$\\theta \\sum_{i=1}^{N} u(t_i)^2 = \\sum_{i=1}^{N} y(t_i)u(t_i)$$\n为了求解 $\\theta$，我们需要除以 $\\sum_{i=1}^{N} u(t_i)^2$。这个分母为零当且仅当对于所有 $i$ 都有 $u(t_i)=0$，这正是参数不可辨识的条件。由于我们是在可辨识性条件下进行推导，分母保证不为零。\n\n因此，显式的闭式逆映射为：\n$$\\theta = \\frac{\\sum_{i=1}^{N} y(t_i) u(t_i)}{\\sum_{i=1}^{N} u(t_i)^2}$$\n这个表达式仅用 $\\{u(t_i)\\}$ 和 $\\{y(t_i)\\}$ 来表示 $\\theta$，符合问题的要求。",
            "answer": "$$\n\\boxed{\\frac{\\sum_{i=1}^{N} y(t_i) u(t_i)}{\\sum_{i=1}^{N} u(t_i)^2}}\n$$"
        },
        {
            "introduction": "在实际建模中，许多模型由于其结构中的对称性而最初是不可辨识的，这意味着不同的参数组合可能产生完全相同的模型输出。本练习将展示结构不可辨识性是如何产生的，以及如何通过丰富数据集（例如，增加一个独立的测量输出来打破对称性）来解决这个问题。理解这一原则对于设计能够有效约束模型参数的实验至关重要 。",
            "id": "3916199",
            "problem": "考虑一个用于生物医学系统建模的最小双物种生物分子衰变模型。两个物种，其浓度分别为 $x_1(t)$ 和 $x_2(t)$，经历独立的由常微分方程（ODE）系统控制的一阶衰变\n$$\\frac{d x_{1}}{dt} \\;=\\; -\\theta_{1}\\, x_{1}, \\qquad \\frac{d x_{2}}{dt} \\;=\\; -\\theta_{2}\\, x_{2},$$\n初始条件为 $x_1(0) = 1$ 和 $x_2(0) = 1$。第一个测量通道（例如，分光光度法检测）返回总和信号\n$$y_{1}(t) \\;=\\; x_{1}(t) \\;+\\; x_{2}(t),$$\n而第二个独立的测量通道（例如，具有不同结合亲和力的检测）返回一个加权和\n$$y_{2}(t) \\;=\\; c\\, x_{1}(t) \\;+\\; x_{2}(t),$$\n其中已知常数 $c$ 满足 $c \\neq 1$。给定 $c = 3$，时间单位为小时，因此参数 $\\theta_{1}$ 和 $\\theta_{2}$ 的单位为 $\\text{h}^{-1}$。\n\nA 部分（单输出不可辨识性）：仅使用第一个输出 $y_{1}(t)$，证明模型中由对称性导致的参数非唯一性。具体来说，展示两个不同的参数向量 $(\\theta_{1}, \\theta_{2})$ 和 $(\\tilde{\\theta}_{1}, \\tilde{\\theta}_{2})$，它们对于所有 $t \\geq 0$ 产生完全相同的 $y_{1}(t)$。使用提供的样本数据 $y_{1}(1) = 1.1901471847989395$ 和 $y_{1}(2) = 0.7507081540886818$（时间单位为小时）。\n\nB 部分（使用多输出恢复可辨识性）：证明在单个时间点 $t^{\\star}$ 添加第二个输出 $y_{2}(t)$ 可以打破对称性并实现唯一的参数辨识。推导 $(\\theta_{1}, \\theta_{2})$ 关于 $y_{1}(t^{\\star})$, $y_{2}(t^{\\star})$, $c$ 和 $t^{\\star}$ 的闭式表达式。您的推导必须从常微分方程和测量定义所蕴含的第一性原理出发。\n\nC 部分（数值辨识）：使用测量值 $y_{1}(1) = 1.1901471847989395$ 和 $y_{2}(1) = 2.6717836261623753$，以及 $c = 3$ 和 $t^{\\star} = 1$ 小时，计算唯一的参数向量 $(\\theta_{1}, \\theta_{2})$。将最终参数以 $\\text{h}^{-1}$ 表示，并将您的答案四舍五入到四位有效数字。",
            "solution": "首先，我们求解给定初始条件的常微分方程（ODEs）。$x_1(t)$ 物种的常微分方程是\n$$ \\frac{dx_{1}}{dt} = -\\theta_{1} x_{1} $$\n在初始条件 $x_1(0) = 1$ 下，解为\n$$ x_1(t) = x_1(0) \\exp(-\\theta_{1}t) = \\exp(-\\theta_{1}t) $$\n类似地，对于物种 $x_2(t)$，其常微分方程为\n$$ \\frac{dx_{2}}{dt} = -\\theta_{2} x_{2} $$\n在初始条件 $x_2(0) = 1$ 下，解为\n$$ x_2(t) = x_2(0) \\exp(-\\theta_{2}t) = \\exp(-\\theta_{2}t) $$\n\n测量输出定义为\n$$ y_{1}(t) = x_1(t) + x_2(t) = \\exp(-\\theta_{1}t) + \\exp(-\\theta_{2}t) $$\n$$ y_{2}(t) = c\\,x_1(t) + x_2(t) = c\\,\\exp(-\\theta_{1}t) + \\exp(-\\theta_{2}t) $$\n\n**A 部分（单输出不可辨识性）**\n\n仅使用输出 $y_{1}(t)$，模型由 $y_{1}(t) = \\exp(-\\theta_{1}t) + \\exp(-\\theta_{2}t)$ 给出。此表达式关于参数 $\\theta_{1}$ 和 $\\theta_{2}$ 是对称的。如果一个参数向量 $(\\theta_{1}, \\theta_{2}) = (a, b)$ 是一个解，那么将参数交换为 $(\\tilde{\\theta}_{1}, \\tilde{\\theta}_{2}) = (b, a)$ 将产生完全相同的输出：\n$$ y_{1}(t) = \\exp(-bt) + \\exp(-at) = \\exp(-at) + \\exp(-bt) $$\n这种固有的对称性意味着，在没有更多信息的情况下，我们无法区分 $(\\theta_{1}, \\theta_{2})$ 和 $(\\theta_{2}, \\theta_{1})$。这证明了参数的非唯一性。\n\n为了展示两个不同的参数向量，我们使用所提供的数据。令 $u = \\exp(-\\theta_{1})$ 和 $v = \\exp(-\\theta_{2})$。$t=1$ 和 $t=2$ 时的数据给出了一个关于 $u$ 和 $v$ 的方程组：\n$$ y_{1}(1) = \\exp(-\\theta_{1}) + \\exp(-\\theta_{2}) = u + v $$\n$$ y_{1}(2) = \\exp(-2\\theta_{1}) + \\exp(-2\\theta_{2}) = u^{2} + v^{2} $$\n给定 $y_{1}(1) = 1.1901471847989395$ 和 $y_{1}(2) = 0.7507081540886818$。\n由第一个方程，得 $v = y_{1}(1) - u$。将其代入第二个方程：\n$$ u^{2} + (y_{1}(1) - u)^{2} = y_{1}(2) $$\n$$ u^{2} + y_{1}(1)^{2} - 2y_{1}(1)u + u^{2} = y_{1}(2) $$\n$$ 2u^{2} - 2y_{1}(1)u + (y_{1}(1)^{2} - y_{1}(2)) = 0 $$\n这是一个关于 $u$ 的二次方程。该二次方程的根将给出 $u$ 和 $v$ 的值。根据问题的对称性，如果 $u_{A}$ 是一个根，则另一个根必须是 $u_{B} = y_{1}(1) - u_{A}$，这对应于 $v$。\n求解该二次方程得到两个根，我们可以称之为 $u_{\\text{sol}}$ 和 $v_{\\text{sol}}$：\n$u_{\\text{sol}} = \\exp(-\\theta_{A}) = 0.7408182206817179$\n$v_{\\text{sol}} = \\exp(-\\theta_{B}) = 0.4493289641172216$\n这给出了两个不同的速率常数：\n$\\theta_{A} = -\\ln(0.7408182206817179) = 0.30000000... \\, \\text{h}^{-1}$\n$\\theta_{B} = -\\ln(0.4493289641172216) = 0.80000000... \\, \\text{h}^{-1}$\n由于对称性，我们有两个可能的参数向量产生相同的 $y_{1}(t)$：\n1. $(\\theta_{1}, \\theta_{2}) = (0.3, 0.8) \\, \\text{h}^{-1}$\n2. $(\\tilde{\\theta}_{1}, \\tilde{\\theta}_{2}) = (0.8, 0.3) \\, \\text{h}^{-1}$\n这两个不同的向量对所有 $t \\geq 0$ 产生相同的输出 $y_{1}(t)$，从而证明了不可辨识性。\n\n**B 部分（使用多输出恢复可辨识性）**\n\n通过在单个时间点 $t^{\\star}$ 测量两个输出 $y_{1}(t)$ 和 $y_{2}(t)$，我们可以唯一地确定参数。令 $u = \\exp(-\\theta_{1}t^{\\star})$ 和 $v = \\exp(-\\theta_{2}t^{\\star})$。方程组为：\n$$ y_{1}(t^{\\star}) = u + v $$\n$$ y_{2}(t^{\\star}) = c\\,u + v $$\n这是一个关于 $u$ 和 $v$ 的二元线性方程组。对称性被打破，因为在第二个方程中 $u$ 和 $v$ 的系数不再可互换（因为 $c \\neq 1$）。用第二个方程减去第一个方程得到：\n$$ y_{2}(t^{\\star}) - y_{1}(t^{\\star}) = (c\\,u + v) - (u + v) = (c-1)u $$\n因为给定 $c \\neq 1$，我们可以解出 $u$：\n$$ u = \\frac{y_{2}(t^{\\star}) - y_{1}(t^{\\star})}{c-1} $$\n将 $u$ 的这个表达式代回第一个方程 $v = y_{1}(t^{\\star}) - u$：\n$$ v = y_{1}(t^{\\star}) - \\frac{y_{2}(t^{\\star}) - y_{1}(t^{\\star})}{c-1} = \\frac{(c-1)y_{1}(t^{\\star}) - (y_{2}(t^{\\star}) - y_{1}(t^{\\star}))}{c-1} $$\n$$ v = \\frac{cy_{1}(t^{\\star}) - y_{1}(t^{\\star}) - y_{2}(t^{\\star}) + y_{1}(t^{\\star})}{c-1} = \\frac{c\\,y_{1}(t^{\\star}) - y_{2}(t^{\\star})}{c-1} $$\n现在我们可以根据 $u$ 和 $v$ 的定义求解 $\\theta_{1}$ 和 $\\theta_{2}$：\n$$ \\exp(-\\theta_{1}t^{\\star}) = u \\implies -\\theta_{1}t^{\\star} = \\ln(u) \\implies \\theta_{1} = -\\frac{1}{t^{\\star}} \\ln(u) $$\n$$ \\theta_{1} = -\\frac{1}{t^{\\star}} \\ln\\left(\\frac{y_{2}(t^{\\star}) - y_{1}(t^{\\star})}{c-1}\\right) $$\n对于 $\\theta_{2}$：\n$$ \\exp(-\\theta_{2}t^{\\star}) = v \\implies -\\theta_{2}t^{\\star} = \\ln(v) \\implies \\theta_{2} = -\\frac{1}{t^{\\star}} \\ln(v) $$\n$$ \\theta_{2} = -\\frac{1}{t^{\\star}} \\ln\\left(\\frac{c\\,y_{1}(t^{\\star}) - y_{2}(t^{\\star})}{c-1}\\right) $$\n这些表达式为有序对 $(\\theta_{1}, \\theta_{2})$ 提供了唯一的解，从而解决了不可辨识性问题。\n\n**C 部分（数值辨识）**\n\n我们使用推导出的公式和给定的数据：$t^{\\star} = 1$ 小时, $c=3$, $y_{1}(1) = 1.1901471847989395$, 和 $y_{2}(1) = 2.6717836261623753$。\n\n首先，计算对数的参数：\n对于 $\\theta_{1}$：\n$$ \\frac{y_{2}(1) - y_{1}(1)}{c-1} = \\frac{2.6717836261623753 - 1.1901471847989395}{3-1} = \\frac{1.4816364413634358}{2} = 0.7408182206817179 $$\n对于 $\\theta_{2}$：\n$$ \\frac{c\\,y_{1}(1) - y_{2}(1)}{c-1} = \\frac{3 \\times 1.1901471847989395 - 2.6717836261623753}{3-1} = \\frac{3.5704415543968185 - 2.6717836261623753}{2} = \\frac{0.8986579282344432}{2} = 0.4493289641172216 $$\n现在，我们用 $t^{\\star}=1$ 计算参数 $\\theta_{1}$ 和 $\\theta_{2}$：\n$$ \\theta_{1} = -\\frac{1}{1} \\ln(0.7408182206817179) = -(-0.30000000000000004) \\approx 0.3000 \\, \\text{h}^{-1} $$\n$$ \\theta_{2} = -\\frac{1}{1} \\ln(0.4493289641172216) = -(-0.8000000000000002) \\approx 0.8000 \\, \\text{h}^{-1} $$\n四舍五入到四位有效数字，唯一的参数向量是 $(\\theta_{1}, \\theta_{2}) = (0.3000, 0.8000) \\, \\text{h}^{-1}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.3000 & 0.8000 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "一旦确定了参数的可辨识性，我们的目标就是找到该参数的“最佳”估计量。本练习探讨了估计理论中的核心概念——偏差-方差权衡，通过比较一个无偏估计量和一个有偏的“收缩”估计量来阐明这一点。您将会看到，引入少量偏差有时可以显著降低估计量的方差，从而获得更低的均方误差（Mean Squared Error, MSE）和更精确的整体估计 。",
            "id": "3916253",
            "problem": "某实验室正在对一个单室静脉推注药代动力学模型中的肝清除率进行量化，该参数用 $\\theta$ 表示，单位为升/小时。对于单个受试者，重复的微透析校准产生独立的测量值 $y_{i}$，这些测量值遵循加性噪声模型 $y_{i} = \\theta + \\varepsilon_{i}$，其中 $\\varepsilon_{i}$ 是独立同分布的，服从高斯分布 $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2})$。对相似队列的荟萃分析为收缩估计提供了一个基线清除率 $\\mu_{0}$。\n\n考虑 $\\theta$ 的两个估计量：\n- 无偏估计量 $\\hat{\\theta}_{U} = \\bar{y}$，其中 $\\bar{y}$ 是 $\\{y_{i}\\}_{i=1}^{n}$ 的样本均值。\n- 收缩估计量 $\\hat{\\theta}_{\\alpha} = \\alpha \\bar{y} + (1 - \\alpha)\\mu_{0}$，具有固定的收缩权重 $\\alpha \\in [0, 1]$。\n\n从偏差、方差和均方误差（MSE）的定义出发，在给定的测量模型下，均方误差（MSE）定义为 $\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}\\big[(\\hat{\\theta} - \\theta)^{2}\\big]$，推导这两个估计量的 MSE，使其成为 $\\alpha$、$n$、$\\sigma^{2}$、$\\mu_{0}$ 和 $\\theta$ 的函数。然后，确定使收缩估计量的 MSE 最小化的 $\\alpha$ 值。使用该最小化因子，计算在以下情景中，有偏估计量的最小化 MSE 与无偏估计量的 MSE 之比：\n- $n = 12$\n- $\\sigma = 0.9$ 升/小时\n- $\\mu_{0} = 1.2$ 升/小时\n- $\\theta = 0.8$ 升/小时\n\n将最终比率表示为无量纲小数。将最终答案四舍五入到四位有效数字。",
            "solution": "该问题要求推导参数 $\\theta$ 的两个估计量的均方误差（MSE），优化收缩参数 $\\alpha$，并计算特定情景下的 MSE 之比。\n\n首先，我们确定样本均值 $\\bar{y}$ 的统计特性。测量值由模型 $y_{i} = \\theta + \\varepsilon_{i}$ 给出，其中 $\\varepsilon_{i}$ 是来自高斯分布 $\\mathcal{N}(0, \\sigma^{2})$ 的独立同分布（i.i.d.）随机变量。\n单个测量值的期望为 $\\mathbb{E}[y_i] = \\mathbb{E}[\\theta + \\varepsilon_i] = \\theta + \\mathbb{E}[\\varepsilon_i] = \\theta + 0 = \\theta$。\n单个测量值的方差为 $\\operatorname{Var}(y_i) = \\operatorname{Var}(\\theta + \\varepsilon_i) = \\operatorname{Var}(\\varepsilon_i) = \\sigma^2$。\n\n样本均值为 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$。\n其期望为 $\\mathbb{E}[\\bar{y}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} y_i\\right] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[y_i] = \\frac{1}{n} (n\\theta) = \\theta$。\n因为测量值 $y_i$ 是独立的，所以样本均值的方差为 $\\operatorname{Var}(\\bar{y}) = \\operatorname{Var}\\left(\\frac{1}{n} \\sum_{i=1}^{n} y_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^{n} \\operatorname{Var}(y_i) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n}$。\n\n估计量 $\\hat{\\theta}$ 的均方误差定义为 $\\operatorname{MSE}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\theta)^2]$。这可以分解为偏差的平方与估计量方差之和：$\\operatorname{MSE}(\\hat{\\theta}) = (\\operatorname{Bias}(\\hat{\\theta}))^2 + \\operatorname{Var}(\\hat{\\theta})$，其中 $\\operatorname{Bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$。\n\n**1. 无偏估计量 $\\hat{\\theta}_{U}$ 的 MSE**\n无偏估计量由 $\\hat{\\theta}_{U} = \\bar{y}$ 给出。\n该估计量的偏差为 $\\operatorname{Bias}(\\hat{\\theta}_{U}) = \\mathbb{E}[\\hat{\\theta}_{U}] - \\theta = \\mathbb{E}[\\bar{y}] - \\theta = \\theta - \\theta = 0$。\n该估计量的方差为 $\\operatorname{Var}(\\hat{\\theta}_{U}) = \\operatorname{Var}(\\bar{y}) = \\frac{\\sigma^2}{n}$。\n因此，无偏估计量的 MSE 为：\n$$ \\operatorname{MSE}(\\hat{\\theta}_{U}) = (0)^2 + \\frac{\\sigma^2}{n} = \\frac{\\sigma^2}{n} $$\n\n**2. 收缩估计量 $\\hat{\\theta}_{\\alpha}$ 的 MSE**\n收缩估计量由 $\\hat{\\theta}_{\\alpha} = \\alpha \\bar{y} + (1 - \\alpha)\\mu_{0}$ 给出，其中 $\\mu_{0}$ 是一个固定常数。\n首先，我们求其偏差。其期望为 $\\mathbb{E}[\\hat{\\theta}_{\\alpha}] = \\mathbb{E}[\\alpha \\bar{y} + (1 - \\alpha)\\mu_{0}] = \\alpha \\mathbb{E}[\\bar{y}] + (1 - \\alpha)\\mu_{0} = \\alpha\\theta + (1 - \\alpha)\\mu_{0}$。\n偏差为 $\\operatorname{Bias}(\\hat{\\theta}_{\\alpha}) = \\mathbb{E}[\\hat{\\theta}_{\\alpha}] - \\theta = (\\alpha\\theta + (1 - \\alpha)\\mu_{0}) - \\theta = \\theta(\\alpha - 1) + (1 - \\alpha)\\mu_{0} = (1 - \\alpha)(\\mu_{0} - \\theta)$。\n接下来，我们求其方差。由于 $\\mu_0$ 是一个常数，$\\operatorname{Var}(\\hat{\\theta}_{\\alpha}) = \\operatorname{Var}(\\alpha \\bar{y} + (1 - \\alpha)\\mu_{0}) = \\operatorname{Var}(\\alpha \\bar{y}) = \\alpha^2 \\operatorname{Var}(\\bar{y}) = \\alpha^2 \\frac{\\sigma^2}{n}$。\n收缩估计量的 MSE 是其偏差平方与方差之和：\n$$ \\operatorname{MSE}(\\hat{\\theta}_{\\alpha}) = ((1 - \\alpha)(\\mu_{0} - \\theta))^2 + \\left(\\alpha^2 \\frac{\\sigma^2}{n}\\right) = (1 - \\alpha)^2 (\\mu_{0} - \\theta)^2 + \\frac{\\alpha^2 \\sigma^2}{n} $$\n\n**3. $\\operatorname{MSE}(\\hat{\\theta}_{\\alpha})$ 的最小化**\n为了找到使 $\\operatorname{MSE}(\\hat{\\theta}_{\\alpha})$ 最小的 $\\alpha$ 值，我们对其关于 $\\alpha$ 求导，并令其等于零。\n令 $M(\\alpha) = \\operatorname{MSE}(\\hat{\\theta}_{\\alpha})$。\n$$ \\frac{dM}{d\\alpha} = \\frac{d}{d\\alpha} \\left[ (1 - \\alpha)^2 (\\mu_{0} - \\theta)^2 + \\frac{\\alpha^2 \\sigma^2}{n} \\right] = -2(1 - \\alpha)(\\mu_{0} - \\theta)^2 + \\frac{2\\alpha \\sigma^2}{n} $$\n将导数设为零以求最优的 $\\alpha$，我们将其记为 $\\alpha_{\\text{opt}}$：\n$$ -2(1 - \\alpha_{\\text{opt}})(\\mu_{0} - \\theta)^2 + \\frac{2\\alpha_{\\text{opt}} \\sigma^2}{n} = 0 $$\n$$ \\alpha_{\\text{opt}} \\frac{\\sigma^2}{n} = (1 - \\alpha_{\\text{opt}})(\\mu_{0} - \\theta)^2 $$\n$$ \\alpha_{\\text{opt}} \\frac{\\sigma^2}{n} = (\\mu_{0} - \\theta)^2 - \\alpha_{\\text{opt}}(\\mu_{0} - \\theta)^2 $$\n$$ \\alpha_{\\text{opt}} \\left( \\frac{\\sigma^2}{n} + (\\mu_{0} - \\theta)^2 \\right) = (\\mu_{0} - \\theta)^2 $$\n$$ \\alpha_{\\text{opt}} = \\frac{(\\mu_{0} - \\theta)^2}{(\\mu_{0} - \\theta)^2 + \\frac{\\sigma^2}{n}} $$\n二阶导数 $\\frac{d^2M}{d\\alpha^2} = 2(\\mu_0 - \\theta)^2 + \\frac{2\\sigma^2}{n}$ 总是正的（对于 $\\sigma^2 > 0$），这证实了该 $\\alpha$ 值对应于一个最小值。\n\n**4. 最小化 MSE 之比**\n所要求的比率为 $R = \\frac{\\operatorname{MSE}(\\hat{\\theta}_{\\alpha_{\\text{opt}}})}{\\operatorname{MSE}(\\hat{\\theta}_{U})}$。\n通过代入 $\\alpha_{\\text{opt}}$ 的表达式，我们可以直接计算比率 $R$：\n$$ R = \\frac{\\operatorname{MSE}(\\hat{\\theta}_{\\alpha_{\\text{opt}}})}{\\operatorname{MSE}(\\hat{\\theta}_{U})} = \\frac{(1 - \\alpha_{\\text{opt}})^2 (\\mu_{0} - \\theta)^2 + \\alpha_{\\text{opt}}^2 \\frac{\\sigma^2}{n}}{\\frac{\\sigma^2}{n}} $$\n一个更简洁的方法是注意到 $\\alpha_{\\text{opt}}$ 本身就等于这个比率。从 $\\alpha_{\\text{opt}}$ 的定义式可以推导出：\n$$ \\alpha_{\\text{opt}} \\left( (\\mu_{0} - \\theta)^2 + \\frac{\\sigma^2}{n} \\right) = (\\mu_{0} - \\theta)^2 $$\n$\\operatorname{MSE}(\\hat{\\theta}_{\\alpha_{\\text{opt}}}) = (1 - \\alpha_{\\text{opt}})^2 (\\mu_{0} - \\theta)^2 + \\alpha_{\\text{opt}}^2 \\frac{\\sigma^2}{n}$。利用 $\\alpha_{\\text{opt}} \\frac{\\sigma^2}{n} = (1 - \\alpha_{\\text{opt}})(\\mu_{0} - \\theta)^2$, 可以简化 $\\operatorname{MSE}(\\hat{\\theta}_{\\alpha_{\\text{opt}}})$ 为 $\\alpha_{\\text{opt}} \\frac{\\sigma^2}{n}$。\n因此，\n$$ R = \\frac{\\alpha_{\\text{opt}} \\frac{\\sigma^2}{n}}{\\frac{\\sigma^2}{n}} = \\alpha_{\\text{opt}} $$\n所以，比率 $R$ 就等于 $\\alpha_{\\text{opt}}$ 的值：\n$$ R = \\frac{(\\mu_{0} - \\theta)^2}{(\\mu_{0} - \\theta)^2 + \\frac{\\sigma^2}{n}} $$\n\n**5. 数值计算**\n给定以下数值：\n$n = 12$\n$\\sigma = 0.9$ 升/小时, 所以 $\\sigma^2 = 0.81$ (升/小时)$^2$\n$\\mu_{0} = 1.2$ 升/小时\n$\\theta = 0.8$ 升/小时\n\n首先，我们计算 $R$ 表达式的各组成部分：\n分母中的偏差平方项是 $(\\mu_{0} - \\theta)^2 = (1.2 - 0.8)^2 = (0.4)^2 = 0.16$。\n样本均值的方差是 $\\frac{\\sigma^2}{n} = \\frac{0.81}{12} = 0.0675$。\n\n现在，我们计算比率 $R$：\n$$ R = \\frac{0.16}{0.16 + 0.0675} = \\frac{0.16}{0.2275} $$\n$$ R \\approx 0.703296703... $$\n四舍五入到四位有效数字，我们得到 $0.7033$。",
            "answer": "$$\\boxed{0.7033}$$"
        }
    ]
}