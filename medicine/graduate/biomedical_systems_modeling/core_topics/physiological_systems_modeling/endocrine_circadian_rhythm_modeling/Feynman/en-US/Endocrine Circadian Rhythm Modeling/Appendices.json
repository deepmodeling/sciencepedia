{
    "hands_on_practices": [
        {
            "introduction": "At the heart of circadian biology lies the concept of a self-sustaining oscillator that can synchronize to external cues. This exercise explores this fundamental principle using the Stuart-Landau oscillator, a canonical model for systems near a Hopf bifurcation. By analyzing how a periodic forcing term, representing a light-dark cycle, influences the oscillator's amplitude and phase, you will derive the conditions for entrainment and gain a deeper understanding of the dynamics of phase-locking .",
            "id": "3883882",
            "problem": "Consider a minimal circadian clock model for an endocrine rhythm, where the phase-coherent oscillation of a hormone proxy variable is represented by a complex variable $z(t)$ obeying the Stuart–Landau dynamics, a canonical normal form near a supercritical Hopf bifurcation. The unforced model is $\\dot{z}=(\\lambda+i\\omega)z-\\beta|z|^{2}z$, with $\\lambda>0$ and $\\beta>0$ describing the growth and nonlinear saturation of the amplitude, and $\\omega>0$ the intrinsic angular frequency. To model light-driven entrainment due to photic input to the suprachiasmatic nucleus (SCN) and its downstream endocrine influence, incorporate a periodic light drive as an additive complex forcing term $\\dot{z}=(\\lambda+i\\omega)z-\\beta|z|^{2}z+f\\exp(i\\Omega t)$, where $f\\ge 0$ is the coupling strength of the light input and $\\Omega$ is the angular frequency of the light-dark cycle.\n\nTasks:\n1) Starting from the forced Stuart–Landau equation, write $z(t)=r(t)\\exp(i\\theta(t))$ with real amplitude $r(t)\\ge 0$ and phase $\\theta(t)\\in\\mathbb{R}$. Derive the coupled ordinary differential equations for the amplitude $r(t)$ and phase $\\theta(t)$ by separating real and imaginary parts.\n2) In the weak-forcing regime with $0<f\\ll 1$ and near the unforced limit cycle, justify the approximation $r(t)\\approx r^{\\ast}$, where $r^{\\ast}$ is the unforced steady amplitude, and define the phase difference $\\psi(t)=\\theta(t)-\\Omega t$. Reduce the dynamics to a single scalar equation for $\\psi(t)$ and determine the fixed-point condition for $1{:}1$ entrainment.\n3) Determine, in closed-form and as a symbolic expression, the minimal light coupling strength $f_{c}$ required for stable $1{:}1$ entrainment in terms of $\\lambda$, $\\beta$, $\\omega$, and $\\Omega$. Your final answer must be a single analytical expression. Do not include any units in your final answer box. No numerical rounding is requested; present the exact symbolic expression.\n\nExplain qualitatively how the light-driven term modifies entrainment through its effects on amplitude and phase dynamics, referencing the derived equations. Your explanation should be based on first principles of amplitude-phase decomposition for oscillators near a Hopf bifurcation and standard averaging arguments for weak periodic forcing.",
            "solution": "The user has provided a problem in the domain of biomedical systems modeling, specifically concerning the entrainment of a circadian oscillator. I will first validate the problem statement according to the specified criteria.\n\n### Step 1: Extract Givens\n- Unforced Model: $\\dot{z}=(\\lambda+i\\omega)z-\\beta|z|^{2}z$\n- Forced Model: $\\dot{z}=(\\lambda+i\\omega)z-\\beta|z|^{2}z+f\\exp(i\\Omega t)$\n- Parameter Conditions: $\\lambda > 0$, $\\beta > 0$, $\\omega > 0$, $f \\ge 0$.\n- Definitions: $z(t)$ is a complex variable representing a hormone proxy. $\\lambda$ is an amplitude growth rate, $\\omega$ is the intrinsic angular frequency, $\\beta$ is a nonlinear saturation coefficient, $f$ is the light coupling strength, and $\\Omega$ is the angular frequency of the light drive.\n- Polar Representation: $z(t)=r(t)\\exp(i\\theta(t))$, where $r(t) \\ge 0$ is the amplitude and $\\theta(t) \\in \\mathbb{R}$ is the phase.\n- Phase Difference: $\\psi(t)=\\theta(t)-\\Omega t$.\n- Approximation Regime: Weak forcing, $0 < f \\ll 1$, and $r(t) \\approx r^{\\ast}$, where $r^{\\ast}$ is the unforced steady amplitude.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The Stuart-Landau equation is the canonical normal form model for a system near a supercritical Hopf bifurcation. Its use to model self-sustained oscillations, such as circadian rhythms, is a cornerstone of theoretical biology and nonlinear dynamics. The addition of a periodic forcing term to model entrainment is a standard and well-established technique. The problem is firmly grounded in established scientific principles.\n2.  **Well-Posed**: The problem is presented as a sequence of tasks that build upon each other logically. It starts with a standard change of coordinates (Cartesian to polar), proceeds with a well-known approximation method (averaging in a rotating frame), and concludes with a stability analysis to find a critical parameter. The structure is sound and leads to a unique, meaningful solution.\n3.  **Objective**: The problem is stated in precise, mathematical language, free of any subjective or ambiguous terminology.\n4.  **Completeness and Consistency**: All variables, parameters, and equations necessary for the solution are provided. The condition $\\lambda > 0$ ensures the existence of a stable limit cycle in the unforced system, which is the basis for studying entrainment. The setup is internally consistent.\n\n### Step 3: Verdict and Action\nThe problem is scientifically valid, well-posed, and complete. I will proceed with a full solution.\n\n### Part 1: Derivation of Amplitude and Phase Equations\nWe start with the forced Stuart–Landau equation:\n$$\n\\dot{z}=(\\lambda+i\\omega)z-\\beta|z|^{2}z+f\\exp(i\\Omega t)\n$$\nWe substitute the polar form $z(t) = r(t)\\exp(i\\theta(t))$. The time derivative of $z(t)$ is:\n$$\n\\dot{z} = \\frac{d}{dt}\\left(r\\exp(i\\theta)\\right) = \\dot{r}\\exp(i\\theta) + ir\\dot{\\theta}\\exp(i\\theta)\n$$\nSubstituting this and $z=r\\exp(i\\theta)$ into the equation gives:\n$$\n\\dot{r}\\exp(i\\theta) + ir\\dot{\\theta}\\exp(i\\theta) = (\\lambda+i\\omega)r\\exp(i\\theta) - \\beta|r\\exp(i\\theta)|^{2}r\\exp(i\\theta) + f\\exp(i\\Omega t)\n$$\nNoting that $|r\\exp(i\\theta)|=r$, we simplify the nonlinear term to $\\beta r^{3}\\exp(i\\theta)$. Dividing the entire equation by $\\exp(i\\theta)$ yields:\n$$\n\\dot{r} + ir\\dot{\\theta} = (\\lambda+i\\omega)r - \\beta r^3 + f\\exp(i(\\Omega t - \\theta))\n$$\nWe expand the complex terms and separate the equation into its real and imaginary parts.\n$$\n\\dot{r} + ir\\dot{\\theta} = \\lambda r + i\\omega r - \\beta r^3 + f(\\cos(\\Omega t - \\theta) + i\\sin(\\Omega t - \\theta))\n$$\nEquating the real parts:\n$$\n\\dot{r} = \\lambda r - \\beta r^3 + f\\cos(\\Omega t - \\theta)\n$$\nEquating the imaginary parts:\n$$\nr\\dot{\\theta} = \\omega r + f\\sin(\\Omega t - \\theta)\n$$\nUsing the identities $\\cos(-x)=\\cos(x)$ and $\\sin(-x)=-\\sin(x)$ to express the forcing in terms of the phase difference $\\psi(t) = \\theta(t) - \\Omega t$, we obtain the coupled ordinary differential equations for amplitude $r(t)$ and phase $\\theta(t)$:\n$$\n\\dot{r} = \\lambda r - \\beta r^3 + f\\cos(\\psi)\n$$\n$$\n\\dot{\\theta} = \\omega + \\frac{f}{r}\\sin(-\\psi) = \\omega - \\frac{f}{r}\\sin(\\psi)\n$$\n\n### Part 2: Reduction to a Single Equation for Phase Difference $\\psi(t)$\nFirst, we determine the steady amplitude $r^{\\ast}$ of the unforced oscillator. For the unforced case ($f=0$), the amplitude equation is $\\dot{r} = r(\\lambda - \\beta r^2)$. The steady state ($\\dot{r} = 0$) has a non-trivial solution when $\\lambda - \\beta r^2 = 0$. Since $\\lambda > 0$, this gives a stable limit cycle amplitude:\n$$\nr^{\\ast} = \\sqrt{\\frac{\\lambda}{\\beta}}\n$$\nIn the weak-forcing regime ($f \\ll 1$), the amplitude $r(t)$ remains close to $r^{\\ast}$. This approximation is justified by the fact that the amplitude relaxation to the limit cycle is typically much faster than the evolution of the phase difference, allowing for an averaging procedure. We substitute $r(t) \\approx r^{\\ast}$ into the phase equation.\n\nNext, we define the phase difference $\\psi(t) = \\theta(t) - \\Omega t$. Its time derivative is:\n$$\n\\dot{\\psi} = \\dot{\\theta} - \\Omega\n$$\nSubstituting the expression for $\\dot{\\theta}$ from Part 1:\n$$\n\\dot{\\psi} = \\left(\\omega - \\frac{f}{r}\\sin(\\psi)\\right) - \\Omega\n$$\nUsing the approximation $r \\approx r^{\\ast}$, we get the reduced scalar equation for $\\psi(t)$:\n$$\n\\dot{\\psi} = (\\omega - \\Omega) - \\frac{f}{r^{\\ast}}\\sin(\\psi)\n$$\nThis is the Adler equation. The condition for $1{:}1$ entrainment, or phase-locking, is the existence of a stable fixed point $\\psi^{\\ast}$ for this equation, where $\\dot{\\psi}=0$. The fixed-point condition is thus:\n$$\n0 = (\\omega - \\Omega) - \\frac{f}{r^{\\ast}}\\sin(\\psi^{\\ast})\n$$\nwhich can be rewritten as:\n$$\n\\sin(\\psi^{\\ast}) = \\frac{r^{\\ast}(\\omega - \\Omega)}{f}\n$$\n\n### Part 3: Minimal Light Coupling Strength $f_c$\nFor a real solution $\\psi^{\\ast}$ to exist, the value of $\\sin(\\psi^{\\ast})$ must lie in the interval $[-1, 1]$. This imposes the following condition:\n$$\n\\left| \\frac{r^{\\ast}(\\omega - \\Omega)}{f} \\right| \\le 1\n$$\n$$\n\\frac{r^{\\ast}|\\omega - \\Omega|}{f} \\le 1\n$$\nThis inequality can be solved for the forcing strength $f$:\n$$\nf \\ge r^{\\ast}|\\omega - \\Omega|\n$$\nThe minimal light coupling strength, $f_c$, is the threshold at which entrainment becomes possible. This corresponds to the equality in the condition above.\n$$\nf_c = r^{\\ast}|\\omega - \\Omega|\n$$\nSubstituting the expression for the unforced amplitude $r^{\\ast} = \\sqrt{\\lambda/\\beta}$:\n$$\nf_c = |\\omega - \\Omega| \\sqrt{\\frac{\\lambda}{\\beta}}\n$$\nFor $f < f_c$, no fixed point exists, and the system exhibits phase slipping (quasi-periodicity). For $f > f_c$, two fixed points appear via a saddle-node bifurcation, one of which is stable, corresponding to a stable entrained state.\n\n### Qualitative Explanation\nThe derived equations from Part 1, $\\dot{r} = \\lambda r - \\beta r^3 + f\\cos(\\psi)$ and $\\dot{\\theta} = \\omega - \\frac{f}{r}\\sin(\\psi)$, clearly show how the light-driven term modifies the oscillator's dynamics. The forcing $f$ has two distinct effects based on its projection onto the amplitude and phase directions in the complex plane.\n\n1.  **Phase Modulation**: The term $-\\frac{f}{r}\\sin(\\psi)$ in the $\\dot{\\theta}$ equation directly modifies the oscillator's instantaneous frequency. This frequency \"pulling\" effect of the external drive is maximized when $\\psi = \\pm\\pi/2$. Entrainment occurs when this phase-modifying term is, on average, strong enough to compensate for the intrinsic frequency detuning, $\\Delta\\omega = \\omega - \\Omega$, by establishing a stable phase lag $\\psi^{\\ast}$. This is the essence of phase locking.\n\n2.  **Amplitude Modulation**: The term $f\\cos(\\psi)$ in the $\\dot{r}$ equation directly affects the amplitude dynamics. This means the forcing can either enhance ($\\cos(\\psi) > 0$) or suppress ($\\cos(\\psi) < 0$) the amplitude. In the standard averaging argument for weak forcing, this effect is often considered secondary because the intrinsic amplitude dynamics are assumed to be \"stiff,\" meaning the amplitude relaxes quickly to its steady-state value $r^{\\ast}$. The phase, being a neutrally stable direction for the unforced oscillator, evolves much more slowly. Thus, the dynamics are assumed to collapse onto the limit cycle, and the primary effect of forcing is to govern the slow evolution of the phase difference $\\psi$ as captured by the Adler equation. The critical strength $f_c$ represents the boundary of the Arnold tongue, defining the region in the parameter space of forcing strength ($f$) versus frequency detuning ($|\\omega - \\Omega|$) where entrainment is possible. It highlights the trade-off: a larger frequency mismatch requires a stronger light stimulus to achieve synchronization. The dependence on $\\sqrt{\\lambda/\\beta}$ shows that oscillators with larger intrinsic amplitudes are more robust and require stronger forcing to be entrained.",
            "answer": "$$\\boxed{|\\omega - \\Omega| \\sqrt{\\frac{\\lambda}{\\beta}}}$$"
        },
        {
            "introduction": "Theoretical models are powerful, but their real-world utility often depends on our ability to parameterize them from experimental data. This practice bridges theory and experiment by tasking you with estimating a Phase Response Curve (PRC), a key function that quantifies an oscillator's response to stimuli like light. You will use linear least squares to fit a Fourier series model to observed phase shift data, a common technique in system identification, and then use your empirical model to simulate the pacemaker's response to a sequence of light pulses .",
            "id": "3883953",
            "problem": "Consider a single-variable phase oscillator representation of the human circadian pacemaker measured via melatonin onset, where the instantaneous phase is denoted by $\\phi \\in [0,2\\pi)$. A light pulse delivered at a given circadian phase produces a phase shift captured by the Phase Response Curve (PRC) defined as $Z(\\phi)$ in radians. The response of the oscillator to a discrete sequence of light pulses can be approximated by the discrete phase map $ \\phi_{n+1} = \\phi_n + Z(\\phi_n) $, with the understanding that phase should be considered modulo $2\\pi$ so that $ \\phi_{n+1} \\leftarrow \\phi_{n+1} \\bmod 2\\pi $.\n\nFundamental definitions and assumptions are as follows:\n- The circadian phase $\\phi$ corresponding to a circadian time $CT$ in hours is defined by $\\phi = 2\\pi \\, CT / 24$.\n- The observed melatonin phase shift in hours, denoted $\\Delta t$, corresponds to a phase displacement $\\Delta \\phi = 2\\pi \\, \\Delta t / 24$.\n- The Phase Response Curve (PRC) $Z(\\phi)$ is a function of the circadian phase at which the pulse is delivered and is to be estimated from data using a truncated Fourier series representation consistent with periodicity and smoothness.\n\nYou are provided with observed data comprising pairs of circadian times (in hours) and melatonin phase shifts (in hours) in response to light pulses:\n- Circadian times $CT$ (in hours): $[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22]$.\n- Observed melatonin phase shifts $\\Delta t$ (in hours): $[1.910, 1.558, 1.158, 0.778, 0.459, 0.208, 0.000, -0.208, -0.459, -0.778, -1.158, -1.558]$.\n\nTasks:\n1. Estimate the PRC $Z(\\phi)$ from the provided data using a truncated Fourier series that includes up to the second harmonic, namely $Z(\\phi) = c_0 + c_1 \\sin(\\phi) + c_2 \\cos(\\phi) + c_3 \\sin(2\\phi) + c_4 \\cos(2\\phi)$, where the coefficients $c_0, c_1, c_2, c_3, c_4$ are determined by minimizing the sum of squared errors between the observed phase shifts and the model predictions. All computations of $\\Delta \\phi$ must use radians. The estimation method should respect the periodic nature of $Z(\\phi)$.\n2. Using the estimated PRC $Z(\\phi)$, predict the final phase after a sequence of light pulses by iterating the discrete phase map $ \\phi_{n+1} = \\phi_n + Z(\\phi_n) $, applying modulo $2\\pi$ after each update to keep the phase in $[0, 2\\pi)$.\n3. For the following test suite, compute the final phase (in radians) after the specified number of pulses, starting from the given initial phase:\n   - Test case $1$: initial phase $\\phi_0 = 1.0$ radians, number of pulses $N = 5$.\n   - Test case $2$: initial phase $\\phi_0 = 6.0$ radians, number of pulses $N = 8$.\n   - Test case $3$: initial phase $\\phi_0 = 0.01$ radians, number of pulses $N = 1$.\n   - Test case $4$: initial phase $\\phi_0 = 3.0$ radians, number of pulses $N = 20$.\n\nAngle unit requirement: all angles must be in radians. Time unit requirement: all time quantities must be in hours. Express the final phases in radians.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$, where each $\\text{result}_i$ is the final phase for the corresponding test case, rounded to six decimal places. The output must contain no other text.",
            "solution": "The problem requires us to model a human circadian pacemaker using a single-variable phase oscillator model. The core tasks are to estimate the system's Phase Response Curve (PRC) from provided data and then use this estimated PRC to simulate the phase evolution under a series of discrete light pulses. The solution is structured into three primary steps.\n\n**Step 1: Data Conversion and PRC Estimation**\n\nThe first step is to determine the PRC, denoted $Z(\\phi)$, from the experimental data. The data pairs consist of circadian times ($CT$ in hours) and the corresponding observed melatonin phase shifts ($\\Delta t$ in hours). These must be converted into the phase domain, where all angles are in radians.\n\nThe conversion from circadian time $CT$ to phase $\\phi$ is given by the definition:\n$$ \\phi = \\frac{2\\pi \\cdot CT}{24} $$\nSimilarly, the time shift $\\Delta t$ is converted to a phase displacement $\\Delta \\phi$ using:\n$$ \\Delta \\phi = \\frac{2\\pi \\cdot \\Delta t}{24} $$\n\nThe provided data is:\n- Circadian times $CT$ (hours): $[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22]$.\n- Observed melatonin phase shifts $\\Delta t$ (hours): $[1.910, 1.558, 1.158, 0.778, 0.459, 0.208, 0.000, -0.208, -0.459, -0.778, -1.158, -1.558]$.\n\nWe apply the conversion formulas to these 12 data points to obtain a set of phase pairs $(\\phi_i, \\Delta\\phi_i)$. For clarity, we will denote the observed phase shifts $\\Delta\\phi_i$ as $y_i$.\n\nThe PRC, $Z(\\phi)$, is modeled as a truncated Fourier series, including terms up to the second harmonic:\n$$ Z(\\phi) = c_0 + c_1 \\sin(\\phi) + c_2 \\cos(\\phi) + c_3 \\sin(2\\phi) + c_4 \\cos(2\\phi) $$\nThe vector of coefficients, $\\boldsymbol{c} = [c_0, c_1, c_2, c_3, c_4]^T$, must be estimated by minimizing the Sum of Squared Errors (SSE) between the model's predictions $Z(\\phi_i)$ and the observed data $y_i$:\n$$ \\text{SSE} = \\sum_{i=1}^{12} (y_i - Z(\\phi_i))^2 $$\n\nThis is a standard linear least squares problem. It can be formulated in matrix notation as finding the vector $\\boldsymbol{c}$ that best solves the overdetermined system $\\boldsymbol{y} \\approx \\boldsymbol{X}\\boldsymbol{c}$. Here, $\\boldsymbol{y}$ is the vector of observed phase shifts $y_i$, and $\\boldsymbol{X}$ is the design matrix. The $i$-th row of $\\boldsymbol{X}$, corresponding to the $i$-th data point with phase $\\phi_i$, is constructed from the basis functions of the Fourier series:\n$$ \\boldsymbol{X}_i = [1, \\sin(\\phi_i), \\cos(\\phi_i), \\sin(2\\phi_i), \\cos(2\\phi_i)] $$\nThe solution $\\boldsymbol{c}$ is found by solving the normal equations $\\boldsymbol{X}^T\\boldsymbol{X}\\boldsymbol{c} = \\boldsymbol{X}^T\\boldsymbol{y}$. A numerically stable method, such as Singular Value Decomposition (SVD), is employed to find the least squares solution. In our implementation, `numpy.linalg.lstsq` will perform this computation.\n\n**Step 2: The Iterative Phase Map**\n\nWith the coefficients $\\boldsymbol{c}$ estimated, the PRC function $Z(\\phi)$ is fully defined. The response of the oscillator to a sequence of light pulses is governed by the discrete phase map:\n$$ \\phi_{n+1} = \\phi_n + Z(\\phi_n) $$\nSince phase is a circular variable defined on a $2\\pi$-radian cycle, the result must be normalized to stay within the interval $[0, 2\\pi)$. This is accomplished by applying the modulo operator after each iteration:\n$$ \\phi_{n+1} = (\\phi_n + Z(\\phi_n)) \\bmod 2\\pi $$\n\n**Step 3: Simulation for Test Cases**\n\nThe final task is to use the derived model to predict the final phase for four specific scenarios. Each scenario is defined by an initial phase $\\phi_0$ and a number of pulses $N$. For each test case, we start with $\\phi = \\phi_0$ and iteratively apply the phase map $N$ times.\n\nThe procedure for a single test case $(\\phi_0, N)$ is as follows:\n1. Initialize phase: $\\phi \\leftarrow \\phi_0$.\n2. Loop $N$ times (for $n$ from 0 to $N-1$):\n    a. Calculate the phase shift for the current phase $\\phi_n$: $\\Delta \\phi_n = Z(\\phi_n)$.\n    b. Update the phase: $\\phi_{n+1} = \\phi_n + \\Delta \\phi_n$.\n    c. Normalize the result: $\\phi_{n+1} \\leftarrow \\phi_{n+1} \\bmod 2\\pi$.\nThe final value $\\phi_N$ after $N$ iterations is the required result. This process is repeated for all four test cases using the same estimated PRC, and the final phases are reported.\n\nTest cases to be simulated:\n- Test case 1: initial phase $\\phi_0 = 1.0$ radians, number of pulses $N = 5$.\n- Test case 2: initial phase $\\phi_0 = 6.0$ radians, number of pulses $N = 8$.\n- Test case 3: initial phase $\\phi_0 = 0.01$ radians, number of pulses $N = 1$.\n- Test case 4: initial phase $\\phi_0 = 3.0$ radians, number of pulses $N = 20$.\n\nThe computed final phases for these cases will be rounded to six decimal places for the final output.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Estimates the Phase Response Curve (PRC) for a circadian oscillator and\n    simulates its phase evolution under a series of light pulses.\n    \"\"\"\n    # Define the provided experimental data.\n    CT_data = np.array([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22])\n    delta_t_data = np.array([1.910, 1.558, 1.158, 0.778, 0.459, 0.208, 0.000, \n                             -0.208, -0.459, -0.778, -1.158, -1.558])\n\n    # --- Step 1: Estimate PRC from data ---\n    \n    # Convert time-based data (hours) to phase-based data (radians).\n    phi_data = 2 * np.pi * CT_data / 24.0\n    delta_phi_data = 2 * np.pi * delta_t_data / 24.0\n\n    # Construct the design matrix X for the linear least squares problem.\n    # The model is Z(phi) = c0 + c1*sin(phi) + c2*cos(phi) + c3*sin(2*phi) + c4*cos(2*phi).\n    X = np.vstack([\n        np.ones(phi_data.shape),\n        np.sin(phi_data),\n        np.cos(phi_data),\n        np.sin(2 * phi_data),\n        np.cos(2 * phi_data)\n    ]).T\n\n    # Solve for the Fourier coefficients [c0, c1, c2, c3, c4] using least squares.\n    # np.linalg.lstsq is a robust method for this.\n    coeffs, _, _, _ = np.linalg.lstsq(X, delta_phi_data, rcond=None)\n    c0, c1, c2, c3, c4 = coeffs\n\n    # --- Step 2: Define the PRC and iterative map ---\n    \n    # Define the estimated PRC function Z(phi) using the calculated coefficients.\n    def Z(phi):\n        return (c0 + \n                c1 * np.sin(phi) + \n                c2 * np.cos(phi) + \n                c3 * np.sin(2 * phi) + \n                c4 * np.cos(2 * phi))\n\n    # --- Step 3: Run simulations for test cases ---\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 5),   # (initial_phase_rad, num_pulses)\n        (6.0, 8),\n        (0.01, 1),\n        (3.0, 20)\n    ]\n\n    results = []\n    for phi0, N in test_cases:\n        phi = phi0\n        # Iterate the phase map N times.\n        for _ in range(N):\n            phase_shift = Z(phi)\n            phi = phi + phase_shift\n            # Apply modulo 2*pi to keep the phase in the [0, 2*pi) range.\n            # Python's % operator works correctly for this purpose with floats.\n            phi = phi % (2 * np.pi)\n        results.append(phi)\n\n    # Format the final output as a comma-separated list in brackets,\n    # with each result rounded to six decimal places.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "A central challenge in applying circadian models clinically is determining an individual's internal phase from sparse and noisy measurements. This exercise introduces a powerful Bayesian framework to tackle this state estimation problem, demonstrating how to infer the latent circadian phase from a few melatonin samples. By combining a generative model of the rhythm with prior knowledge, you will learn to compute the most probable phase estimate and, crucially, to quantify its uncertainty using the Laplace approximation .",
            "id": "3883910",
            "problem": "You are tasked with estimating the circadian phase of melatonin secretion from three salivary melatonin concentration samples using a principled probabilistic model grounded in biomedical systems modeling of endocrine circadian rhythms. Consider the circadian oscillator to be well-approximated by a single harmonic component of the melatonin secretion, with additive Gaussian measurement noise. The modeling objective is to infer the phase of the oscillator and quantify its uncertainty.\n\nAssume the following generative model for melatonin concentration:\nFor observation times $t_1$, $t_2$, and $t_3$ (expressed in hours), the measured melatonin concentrations $y_1$, $y_2$, and $y_3$ (expressed in picograms per milliliter, $\\mathrm{pg/mL}$) are modeled as\n$$\ny_i = B + A \\cos(\\omega t_i - \\phi) + \\epsilon_i,\\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\\quad i \\in \\{1,2,3\\},\n$$\nwhere $B$ is the baseline concentration in $\\mathrm{pg/mL}$, $A$ is the oscillation amplitude in $\\mathrm{pg/mL}$, $\\phi$ is the circadian phase (an angle in radians), $\\sigma$ is the measurement noise standard deviation in $\\mathrm{pg/mL}$, and $\\omega$ is the angular frequency defined by the circadian period of $24$ hours:\n$$\n\\omega = \\frac{2\\pi}{24}\\ \\text{radians per hour}.\n$$\nAssume the prior distribution for the phase $\\phi$ is von Mises with mean direction $\\mu$ (in radians) and concentration parameter $\\kappa$:\n$$\np(\\phi) \\propto \\exp\\!\\big(\\kappa \\cos(\\phi - \\mu)\\big).\n$$\n\nStarting from fundamental bases appropriate for biomedical systems modeling of endocrine circadian rhythms:\n- The definition of a periodic oscillator and its angular frequency, with the relation $\\omega = 2\\pi/T$ for period $T$.\n- The Gaussian noise model for measurement error, with $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$.\n- Bayes' rule for combining likelihood and prior to form the posterior $p(\\phi\\mid y) \\propto p(y\\mid \\phi) p(\\phi)$.\n\nDerive the posterior for $\\phi$ and compute the maximum a posteriori estimate $\\hat{\\phi}$ by maximizing the posterior. Quantify the uncertainty in $\\hat{\\phi}$ by approximating the local curvature of the log-posterior at $\\hat{\\phi}$ using a Laplace approximation, reporting the posterior standard deviation $\\sigma_\\phi$ as\n$$\n\\sigma_\\phi \\approx \\sqrt{\\frac{1}{\\mathcal{H}}},\n$$\nwhere $\\mathcal{H}$ is the negative of the second derivative of the log-posterior with respect to $\\phi$ evaluated at $\\hat{\\phi}$.\n\nAngle unit requirement: all angles, including the estimated phase $\\hat{\\phi}$ and the reported uncertainty $\\sigma_\\phi$, must be expressed in radians.\n\nPhysical unit requirement: melatonin concentrations are to be treated in $\\mathrm{pg/mL}$, times in hours, angular frequency in radians per hour.\n\nImplement a program that:\n- Constructs the log-posterior function for $\\phi$ using the likelihood derived from the Gaussian noise model and the von Mises prior defined above.\n- Finds $\\hat{\\phi}$ by maximizing the log-posterior over the interval $[0,2\\pi)$.\n- Approximates $\\sigma_\\phi$ using a second-derivative finite-difference approximation of the log-posterior at $\\hat{\\phi}$.\n- Returns the results for each test case as a pair $[\\hat{\\phi}, \\sigma_\\phi]$.\n\nTest suite:\nProvide results for the following parameter sets (each with times $t_i$ in hours, concentrations $y_i$ in $\\mathrm{pg/mL}$, amplitude $A$ in $\\mathrm{pg/mL}$, baseline $B$ in $\\mathrm{pg/mL}$, noise standard deviation $\\sigma$ in $\\mathrm{pg/mL}$, prior mean $\\mu$ in radians, and prior concentration $\\kappa$). For each case, take $\\omega = 2\\pi/24$ radians per hour.\n\n- Case $1$ (typical nocturnal sampling, informative data):\n  - $t_1 = 22.0$, $t_2 = 2.0$, $t_3 = 6.0$.\n  - $y_1 = 38.0$, $y_2 = 55.0$, $y_3 = 26.0$.\n  - $A = 25.0$, $B = 30.0$, $\\sigma = 5.0$.\n  - $\\mu = \\omega \\cdot 2.0$, $\\kappa = 2.0$.\n\n- Case $2$ (midday sampling, weakly informative data, prior influences posterior):\n  - $t_1 = 12.0$, $t_2 = 12.5$, $t_3 = 13.0$.\n  - $y_1 = 28.0$, $y_2 = 31.0$, $y_3 = 27.0$.\n  - $A = 25.0$, $B = 30.0$, $\\sigma = 8.0$.\n  - $\\mu = \\omega \\cdot 2.0$, $\\kappa = 1.5$.\n\n- Case $3$ (typical nocturnal sampling, high noise, broad posterior):\n  - $t_1 = 22.0$, $t_2 = 2.0$, $t_3 = 6.0$.\n  - $y_1 = 60.0$, $y_2 = 20.0$, $y_3 = 45.0$.\n  - $A = 25.0$, $B = 30.0$, $\\sigma = 15.0$.\n  - $\\mu = \\omega \\cdot 2.0$, $\\kappa = 0.5$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be the two-element list $[\\hat{\\phi}, \\sigma_\\phi]$ for one test case, both expressed in radians. For example, the output should look like\n$$\n[\\,[\\hat{\\phi}_1,\\sigma_{\\phi,1}],\\,[\\hat{\\phi}_2,\\sigma_{\\phi,2}],\\,[\\hat{\\phi}_3,\\sigma_{\\phi,3}]\\,]\n$$\nwith no spaces in the printed line.",
            "solution": "The problem requires the estimation of the circadian phase, $\\phi$, of melatonin secretion from three discrete concentration measurements. This is framed as a Bayesian inference problem, where we seek the maximum a posteriori (MAP) estimate of the phase, $\\hat{\\phi}$, and a measure of its uncertainty, the posterior standard deviation $\\sigma_\\phi$. The solution proceeds by first defining the statistical model, then deriving the posterior distribution, and finally detailing the numerical methods for optimization and uncertainty quantification.\n\nThe foundational principles are:\n1.  A sinusoidal model for the circadian rhythm of melatonin: $y(t) = B + A \\cos(\\omega t - \\phi)$.\n2.  An additive Gaussian noise model for measurement error: $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$.\n3.  Bayes' rule for inference: $p(\\phi \\mid \\mathbf{y}) \\propto p(\\mathbf{y} \\mid \\phi) p(\\phi)$.\n\n**1. Bayesian Model Formulation**\n\nThe first step is to construct the posterior probability distribution for the phase $\\phi$ given the observed data $\\mathbf{y} = \\{y_1, y_2, y_3\\}$. According to Bayes' rule, the posterior is proportional to the product of the likelihood and the prior.\n\n**1.1. Likelihood Function, $p(\\mathbf{y} \\mid \\phi)$**\nThe generative model for a single melatonin concentration measurement $y_i$ at time $t_i$ is given as:\n$$\ny_i = B + A \\cos(\\omega t_i - \\phi) + \\epsilon_i\n$$\nThe term $\\epsilon_i$ represents measurement noise, which is assumed to be drawn from a zero-mean Gaussian distribution with variance $\\sigma^2$, i.e., $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$. This implies that the probability distribution of a single measurement $y_i$, conditioned on the phase $\\phi$, is also Gaussian:\n$$\ny_i \\mid \\phi \\sim \\mathcal{N}\\big(B + A \\cos(\\omega t_i - \\phi), \\sigma^2\\big)\n$$\nThe probability density function (PDF) for the $i$-th observation is therefore:\n$$\np(y_i \\mid \\phi) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_i - [B + A \\cos(\\omega t_i - \\phi)])^2}{2\\sigma^2} \\right)\n$$\nAssuming the three measurements are conditionally independent given the phase $\\phi$, the total likelihood for the data vector $\\mathbf{y}$ is the product of the individual probabilities:\n$$\np(\\mathbf{y} \\mid \\phi) = \\prod_{i=1}^{3} p(y_i \\mid \\phi) = \\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\right)^3 \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{3} (y_i - B - A \\cos(\\omega t_i - \\phi))^2 \\right)\n$$\n\n**1.2. Prior Distribution, $p(\\phi)$**\nThe prior distribution for the phase, $p(\\phi)$, encapsulates our belief about $\\phi$ before observing the data. The problem specifies a von Mises distribution, which is a suitable choice for circular data like phase angles. The PDF is given by:\n$$\np(\\phi) \\propto \\exp\\big(\\kappa \\cos(\\phi - \\mu)\\big)\n$$\nwhere $\\mu$ is the prior mean direction (our a priori best guess for the phase) and $\\kappa \\geq 0$ is the concentration parameter, which indicates the strength of our prior belief. A larger $\\kappa$ corresponds to a more concentrated (more certain) prior.\n\n**2. The Log-Posterior Distribution**\nFor computational stability and mathematical convenience, particularly for optimization, we work with the natural logarithm of the posterior distribution, $L(\\phi) = \\log p(\\phi \\mid \\mathbf{y})$.\n$$\nL(\\phi) = \\log(p(\\mathbf{y} \\mid \\phi) p(\\phi)) + C_0 = \\log p(\\mathbf{y} \\mid \\phi) + \\log p(\\phi) + C_0\n$$\nwhere $C_0$ is a normalization constant that does not depend on $\\phi$. Substituting the expressions for the likelihood and prior, and dropping all terms constant with respect to $\\phi$, we get:\n$$\nL(\\phi) \\propto -\\frac{1}{2\\sigma^2} \\sum_{i=1}^{3} (y_i - B - A \\cos(\\omega t_i - \\phi))^2 + \\kappa \\cos(\\phi - \\mu)\n$$\nThis function, the log-posterior, represents the relative posterior probability of any given phase $\\phi$.\n\n**3. Maximum a Posteriori (MAP) Estimation**\nThe MAP estimate, $\\hat{\\phi}$, is the value of $\\phi$ that maximizes the posterior probability, or equivalently, the log-posterior function.\n$$\n\\hat{\\phi} = \\underset{\\phi \\in [0, 2\\pi)}{\\arg\\max} \\, L(\\phi)\n$$\nThis maximization problem does not have a simple closed-form solution and must be solved numerically. The search for the maximum is performed over the interval $[0, 2\\pi)$, representing all possible phases. Computationally, this is achieved by minimizing the negative log-posterior, $-L(\\phi)$, using a numerical optimization algorithm.\n\n**4. Uncertainty Quantification: Laplace Approximation**\nThe uncertainty in the estimate $\\hat{\\phi}$ is quantified by the width of the posterior distribution around its peak. The Laplace approximation models the posterior distribution as a Gaussian distribution centered at the MAP estimate $\\hat{\\phi}$. The variance of this approximating Gaussian serves as our measure of uncertainty.\n\nFor a one-dimensional parameter $\\phi$, the posterior is approximated as:\n$$\np(\\phi \\mid \\mathbf{y}) \\approx \\mathcal{N}(\\hat{\\phi}, \\mathcal{H}^{-1})\n$$\nwhere $\\mathcal{H}$ is the observed Fisher information, or more simply, the negative of the second derivative of the log-posterior evaluated at the mode $\\hat{\\phi}$:\n$$\n\\mathcal{H} = - \\frac{d^2 L(\\phi)}{d\\phi^2} \\Bigg|_{\\phi=\\hat{\\phi}}\n$$\nThe value of $\\mathcal{H}$ measures the curvature of the log-posterior at its peak; a larger curvature (larger $\\mathcal{H}$) implies a sharper peak and thus lower uncertainty.\n\nThe problem specifies using a finite-difference scheme to approximate this second derivative. The central difference formula is:\n$$\n\\frac{d^2 L(\\phi)}{d\\phi^2} \\Bigg|_{\\phi=\\hat{\\phi}} \\approx \\frac{L(\\hat{\\phi}+h) - 2L(\\hat{\\phi}) + L(\\hat{\\phi}-h)}{h^2}\n$$\nfor a small step size $h$. Thus, $\\mathcal{H}$ is computed as:\n$$\n\\mathcal{H} \\approx -\\frac{L(\\hat{\\phi}+h) - 2L(\\hat{\\phi}) + L(\\hat{\\phi}-h)}{h^2}\n$$\nThe posterior variance is $\\sigma_\\phi^2 \\approx 1/\\mathcal{H}$, and the standard deviation, which is the desired measure of uncertainty, is:\n$$\n\\sigma_\\phi \\approx \\sqrt{\\frac{1}{\\mathcal{H}}}\n$$\n\n**Summary of the computational procedure:**\nFor each test case:\n1.  Define a function for the negative log-posterior, $-L(\\phi)$, using the provided parameters ($t_i$, $y_i$, $A$, $B$, $\\sigma$, $\\mu$, $\\kappa$).\n2.  Use a bounded numerical minimizer (e.g., `scipy.optimize.minimize_scalar`) to find $\\hat{\\phi}$ in the interval $[0, 2\\pi)$.\n3.  Evaluate the negative log-posterior function at $\\hat{\\phi}$, $\\hat{\\phi}+h$, and $\\hat{\\phi}-h$ for a small $h$ (e.g., $10^{-5}$).\n4.  Use these values to compute the second derivative of the negative log-posterior, which is our estimate for $\\mathcal{H}$.\n5.  Calculate the posterior standard deviation as $\\sigma_\\phi = 1/\\sqrt{\\mathcal{H}}$.\n6.  Return the pair $[\\hat{\\phi}, \\sigma_\\phi]$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Solves for the MAP estimate and uncertainty of the circadian phase for given test cases.\n    \"\"\"\n    \n    # Define the constant angular frequency\n    omega = 2 * np.pi / 24.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (typical nocturnal sampling, informative data)\n        {\n            \"t\": [22.0, 2.0, 6.0], \"y\": [38.0, 55.0, 26.0],\n            \"A\": 25.0, \"B\": 30.0, \"sigma\": 5.0,\n            \"mu\": omega * 2.0, \"kappa\": 2.0\n        },\n        # Case 2 (midday sampling, weakly informative data)\n        {\n            \"t\": [12.0, 12.5, 13.0], \"y\": [28.0, 31.0, 27.0],\n            \"A\": 25.0, \"B\": 30.0, \"sigma\": 8.0,\n            \"mu\": omega * 2.0, \"kappa\": 1.5\n        },\n        # Case 3 (typical nocturnal sampling, high noise)\n        {\n            \"t\": [22.0, 2.0, 6.0], \"y\": [60.0, 20.0, 45.0],\n            \"A\": 25.0, \"B\": 30.0, \"sigma\": 15.0,\n            \"mu\": omega * 2.0, \"kappa\": 0.5\n        }\n    ]\n\n    results = []\n    h = 1e-5  # Step size for finite difference approximation\n\n    for case in test_cases:\n        t = np.array(case[\"t\"])\n        y = np.array(case[\"y\"])\n        A = case[\"A\"]\n        B = case[\"B\"]\n        sigma = case[\"sigma\"]\n        mu = case[\"mu\"]\n        kappa = case[\"kappa\"]\n\n        def neg_log_posterior(phi):\n            \"\"\"\n            Computes the negative of the log-posterior for a given phase phi.\n            The function is defined as - (log_likelihood + log_prior).\n            Constants independent of phi are ignored.\n            \"\"\"\n            # Likelihood term\n            model_predictions = B + A * np.cos(omega * t - phi)\n            sum_sq_errors = np.sum(((y - model_predictions) / sigma) ** 2)\n            log_likelihood = -0.5 * sum_sq_errors\n            \n            # Prior term\n            log_prior = kappa * np.cos(phi - mu)\n            \n            # Negative log posterior to be minimized\n            return -(log_likelihood + log_prior)\n\n        # Find the MAP estimate by minimizing the negative log-posterior\n        # over the interval [0, 2*pi).\n        opt_result = minimize_scalar(\n            neg_log_posterior, \n            bounds=(0, 2 * np.pi), \n            method='bounded'\n        )\n        phi_hat = opt_result.x\n\n        # Calculate the Hessian (H) using a central finite-difference approximation\n        # of the second derivative of the function we minimized (neg_log_posterior).\n        # H = f''(x_min) approx (f(x_min+h) - 2f(x_min) + f(x_min-h)) / h^2\n        f_val_at_min = opt_result.fun\n        f_val_plus_h = neg_log_posterior(phi_hat + h)\n        f_val_minus_h = neg_log_posterior(phi_hat - h)\n        \n        hessian = (f_val_plus_h - 2 * f_val_at_min + f_val_minus_h) / (h ** 2)\n\n        # The posterior standard deviation sigma_phi is sqrt(1/H).\n        # We check for hessian > 0 to ensure we are at a minimum and variance is positive.\n        if hessian > 0:\n            sigma_phi = np.sqrt(1.0 / hessian)\n        else:\n            # This case indicates a problem (e.g., optimization failed, flat posterior)\n            # and results in undefined or infinite uncertainty.\n            sigma_phi = np.inf\n        \n        results.append([phi_hat, sigma_phi])\n\n    # Format the final output string exactly as specified, with no spaces.\n    results_str_parts = [f\"[{res[0]},{res[1]}]\" for res in results]\n    final_output_str = f\"[{','.join(results_str_parts)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}