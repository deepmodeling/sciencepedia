{
    "hands_on_practices": [
        {
            "introduction": "Any sophisticated model is only as good as the data it is built on. In heart rate variability (HRV) analysis, the transformation from a continuous physiological signal—the electrocardiogram (ECG)—to a discrete sequence of beat-to-beat ($RR$) intervals is a critical first step. This exercise explores the fundamental trade-offs involved in this digitalization process, focusing on how the sampling rate affects both signal fidelity and timing precision. By working through this problem , you will gain a first-principles understanding of how the choice of ECG sampling rate directly impacts the integrity of the derived $RR$ interval data, a crucial consideration for any subsequent HRV analysis.",
            "id": "3906338",
            "problem": "An Electrocardiogram (ECG) is sampled at frequency $f_{s}$ to detect $R$-peaks and construct a sequence of beat-to-beat intervals ($RR$ intervals). High-Frequency (HF) heart rate variability (HRV) refers to fluctuations in the $RR$ series within the nominal band $0.15$–$0.40$ Hz associated with respiratory sinus arrhythmia. In HF spectral analysis, the $RR$ series is typically resampled to a uniform time grid, and aliasing must be avoided in the band of interest. The discrete sampling of ECG introduces timing quantization in detected $R$-peak times, which propagates as jitter to the $RR$ intervals.\n\nStarting from the Nyquist–Shannon sampling theorem and the definition of uniform quantization error, justify the choice of ECG sampling rate $f_{s}$ required to both (i) prevent aliasing when the $RR$ series is later uniformly resampled for HF-band analysis, and (ii) minimize timing jitter due to ECG sampling resolution. Assume the following modeling assumptions:\n- The HF band of interest is $0.15$–$0.40$ Hz.\n- Resampling of the $RR$ series for spectral analysis will use a strictly band-limited low-pass interpolation filter prior to uniform resampling.\n- Each detected $R$-peak time is quantized to the nearest ECG sample time, and the per-peak quantization error is uniformly distributed over the interval $\\left[-\\frac{T_{s}}{2}, \\frac{T_{s}}{2}\\right]$, where $T_{s} = \\frac{1}{f_{s}}$ is the ECG sampling period.\n- Quantization errors of successive $R$-peaks are independent.\n\nThen, derive from first principles an analytic expression for the root-mean-square (RMS) timing error in a single $RR$ interval due solely to ECG sampling quantization, and compute its value at $f_{s} = 250$ Hz. Express the final error in seconds and round your answer to four significant figures.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of digital signal processing and biomedical systems modeling, is well-posed with sufficient and consistent information, and is stated in objective, formal language. We will proceed with the solution.\n\nThe problem consists of two parts. First, to justify the choice of ECG sampling rate, $f_{s}$, based on aliasing and timing jitter considerations. Second, to derive an expression for the root-mean-square (RMS) timing error in an $RR$ interval and compute its value for a given $f_s$.\n\nPart 1: Justification for the choice of ECG sampling rate $f_s$.\n\nThe choice of a sufficiently high ECG sampling rate $f_s$ is critical for two primary reasons that align with the problem's requirements.\n\n(i) Prevention of Aliasing: The problem requires preventing aliasing in the High-Frequency (HF) band of interest, defined as $0.15$–$0.40$ Hz. According to the Nyquist-Shannon sampling theorem, to avoid aliasing when sampling a signal, the sampling frequency must be strictly greater than twice the maximum frequency component in the signal ($f_{\\text{sample}} > 2f_{\\text{max}}$). The signal being analyzed for HRV is the sequence of $RR$ intervals. This sequence is typically resampled onto a uniform time grid at a frequency $f_{\\text{resample}}$. To analyze spectral content up to $f_{\\text{max,HRV}} = 0.40$ Hz without aliasing, this resampling frequency must satisfy $f_{\\text{resample}} > 2 \\times 0.40 \\text{ Hz} = 0.8$ Hz.\n\nWhile the ECG sampling rate $f_s$ does not directly set $f_{\\text{resample}}$, it is a crucial prerequisite for the validity of the entire analysis. The $RR$ intervals are derived from the locations of $R$-peaks in the ECG signal. The ECG waveform itself, particularly the QRS complex which contains the $R$-peak, has significant frequency components extending to $100$ Hz and beyond. To accurately represent the morphology of the QRS complex and thus precisely locate the $R$-peak, the ECG signal must be sampled at a rate $f_s$ high enough to prevent aliasing of the ECG signal itself. If $f_s$ is too low, the QRS complex will be distorted, leading to systematic errors in $R$-peak detection that are far more severe than simple quantization jitter. Therefore, a high $f_s$ (typically $\\geq 250$ Hz) is necessary to ensure the integrity of the raw data from which the $RR$ series is constructed. This prevents corruption of the $RR$ interval data before the HRV-specific resampling and spectral analysis are even performed.\n\n(ii) Minimization of Timing Jitter: The discrete nature of ECG sampling introduces a quantization error in the time domain. The true time of an $R$-peak can occur at any point, but it is detected and recorded at the time of the nearest sample. This creates a timing error, or jitter. The problem states this error is uniformly distributed in the interval $\\left[-\\frac{T_{s}}{2}, \\frac{T_{s}}{2}\\right]$, where $T_s = 1/f_s$ is the ECG sampling period. The magnitude of this timing error is directly proportional to the sampling period $T_s$. To minimize this error, one must minimize $T_s$. Since $T_s = 1/f_s$, minimizing $T_s$ is equivalent to maximizing the sampling frequency $f_s$. A higher sampling rate $f_s$ provides a finer time grid, reducing the maximum possible quantization error and, consequently, the overall variance of the timing jitter in the detected $R$-peak locations. This jitter propagates into the calculated $RR$ intervals, appearing as broadband noise in the HRV spectrum. Reducing this noise floor by choosing a high $f_s$ is essential for accurately quantifying the physiological low-amplitude signals in the HF band.\n\nIn summary, a high $f_s$ is chosen to ensure the underlying ECG signal is accurately captured for reliable $R$-peak detection and to directly minimize the time quantization error that manifests as noise in the derived $RR$ interval series.\n\nPart 2: Derivation and computation of RMS timing error.\n\nLet the true, continuous-time locations of two successive $R$-peaks be $t_{i}$ and $t_{i+1}$. The true $RR$ interval is $RR_{\\text{true}} = t_{i+1} - t_{i}$.\nThe corresponding measured times, quantized to the nearest sample, are $\\hat{t}_i$ and $\\hat{t}_{i+1}$. The measured $RR$ interval is $\\widehat{RR} = \\hat{t}_{i+1} - \\hat{t}_i$.\nThe quantization error for a single peak is a random variable $e_k = \\hat{t}_k - t_k$. The problem states that $e_k$ is uniformly distributed over the interval $[-\\frac{T_s}{2}, \\frac{T_s}{2}]$, where $T_s = 1/f_s$.\n\nThe error in a single $RR$ interval, $E_{RR}$, is the difference between the measured and true intervals:\n$$E_{RR} = \\widehat{RR} - RR_{\\text{true}} = (\\hat{t}_{i+1} - \\hat{t}_i) - (t_{i+1} - t_i) = (\\hat{t}_{i+1} - t_{i+1}) - (\\hat{t}_i - t_i) = e_{i+1} - e_i$$\nWe need to find the root-mean-square (RMS) value of $E_{RR}$, which is defined as $\\sqrt{\\mathrm{E}[E_{RR}^2]}$, where $\\mathrm{E}[\\cdot]$ is the expectation operator.\n\nFirst, let's find the mean and variance of the single-peak quantization error, $e_k$. For a random variable $X$ uniformly distributed on $[a, b]$, the mean is $\\mathrm{E}[X] = \\frac{a+b}{2}$ and the variance is $\\mathrm{Var}(X) = \\frac{(b-a)^2}{12}$.\nFor $e_k$, we have $a = -T_s/2$ and $b = T_s/2$.\nThe mean of the error is:\n$$\\mathrm{E}[e_k] = \\frac{-\\frac{T_s}{2} + \\frac{T_s}{2}}{2} = 0$$\nThe variance of the error is:\n$$\\mathrm{Var}(e_k) = \\frac{(\\frac{T_s}{2} - (-\\frac{T_s}{2}))^2}{12} = \\frac{T_s^2}{12}$$\n\nNow, we analyze the $RR$ interval error, $E_{RR} = e_{i+1} - e_i$.\nThe mean of the $RR$ interval error is:\n$$\\mathrm{E}[E_{RR}] = \\mathrm{E}[e_{i+1} - e_i] = \\mathrm{E}[e_{i+1}] - \\mathrm{E}[e_i] = 0 - 0 = 0$$\nThe variance of the $RR$ interval error is $\\mathrm{Var}(E_{RR})$. The problem states that the quantization errors of successive $R$-peaks are independent. For independent random variables, the variance of their difference is the sum of their variances:\n$$\\mathrm{Var}(E_{RR}) = \\mathrm{Var}(e_{i+1} - e_i) = \\mathrm{Var}(e_{i+1}) + \\mathrm{Var}(e_i)$$\nSince $e_i$ and $e_{i+1}$ are identically distributed, they have the same variance:\n$$\\mathrm{Var}(E_{RR}) = \\frac{T_s^2}{12} + \\frac{T_s^2}{12} = \\frac{2T_s^2}{12} = \\frac{T_s^2}{6}$$\nThe RMS value is $\\sqrt{\\mathrm{E}[E_{RR}^2]}$. For a random variable $X$ with mean $\\mu_X$, we have $\\mathrm{Var}(X) = \\mathrm{E}[X^2] - (\\mathrm{E}[X])^2$.\nSince $\\mathrm{E}[E_{RR}] = 0$, the variance is equal to the mean square value: $\\mathrm{Var}(E_{RR}) = \\mathrm{E}[E_{RR}^2]$.\nTherefore, the RMS error is the square root of the variance:\n$$\\text{RMS}(E_{RR}) = \\sqrt{\\mathrm{Var}(E_{RR})} = \\sqrt{\\frac{T_s^2}{6}} = \\frac{T_s}{\\sqrt{6}}$$\nThis is the required analytic expression for the RMS timing error in a single $RR$ interval. Substituting $T_s = 1/f_s$, the expression is $\\frac{1}{f_s\\sqrt{6}}$.\n\nNow, we compute this value for an ECG sampling rate of $f_s = 250$ Hz.\nThe sampling period is $T_s = \\frac{1}{f_s} = \\frac{1}{250} \\text{ s} = 0.004$ s.\nSubstituting this value into the RMS error expression:\n$$\\text{RMS}(E_{RR}) = \\frac{0.004}{\\sqrt{6}} \\text{ s}$$\nNumerically, this is:\n$$\\text{RMS}(E_{RR}) \\approx \\frac{0.004}{2.44948974...} \\text{ s} \\approx 0.00163299... \\text{ s}$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\\text{RMS}(E_{RR}) \\approx 0.001633 \\text{ s}$$\nIn scientific notation, this is $1.633 \\times 10^{-3}$ s.",
            "answer": "$$\\boxed{1.633 \\times 10^{-3}}$$"
        },
        {
            "introduction": "A primary goal of HRV analysis is to non-invasively probe the function of the autonomic nervous system. This practice introduces magnitude-squared coherence, a powerful frequency-domain tool for quantifying the linear relationship between two time series, in this case, respiration and the $RR$ interval tachogram. This exercise  provides hands-on experience in implementing and interpreting coherence analysis to quantify Respiratory Sinus Arrhythmia (RSA), a key indicator of parasympathetic nervous system activity. You will learn to use this standard technique to transform raw physiological signals into a meaningful, quantitative measure of neuro-cardiac coupling.",
            "id": "3906314",
            "problem": "You are tasked with formalizing and computing a frequency-domain coupling measure between a respiratory signal and an interbeat-interval series relevant to heart rate variability analysis in biomedical systems modeling. The goal is to define a dimensionless measure of linear association across frequency, denoted $C_{xy}(f)$, between a respiratory signal $x(t)$ and an interbeat-interval (respiratory sinus arrhythmia related) signal $y(t)$, and then to compute and interpret this measure in the high-frequency band associated with Respiratory Sinus Arrhythmia (RSA). Begin from first principles using the definitions of cross-correlation and the Fourier transform, and the notion of spectral density derived from those definitions. You must not assume any shortcut formulas. Your derivation must be anchored in the following base definitions:\n- The cross-correlation $R_{xy}(\\tau)$ is defined as the expected value of the time-shifted product, $R_{xy}(\\tau) = \\mathbb{E}[x(t)\\,y(t+\\tau)]$.\n- The power spectral density is defined from the Fourier transform of the autocorrelation, and the cross-spectral density is defined from the Fourier transform of the cross-correlation.\n- The Fourier transform uses angles in radians, and frequency is in hertz, so the argument is $2\\pi f t$.\n\nAfter completing the derivation to a normalized frequency-domain association measure $C_{xy}(f)$ that is bounded between $0$ and $1$, implement a program to compute it using discrete-time estimators grounded in the same principles. Specifically:\n- The program must compute the magnitude-squared coherence $C_{xy}(f)$ using estimators consistent with the above derivation and with windowed, averaged periodograms (Welch’s method) for the auto- and cross-spectral densities.\n- Interpret the strength of respiratory sinus arrhythmia by averaging $C_{xy}(f)$ over the high-frequency band $[0.15,\\,0.40]$ in hertz; the resulting average is a real number between $0$ and $1$, where larger values indicate stronger RSA coupling.\n\nSignals and units:\n- Treat $x(t)$ as a uniformly sampled respiration time series and $y(t)$ as a uniformly sampled interbeat-interval time series (tachogram). Time is in seconds, frequency is in hertz, angles in the sinusoidal arguments are in radians, and $C_{xy}(f)$ is dimensionless.\n- Use a sampling frequency $f_s$ (in hertz) and duration $T$ (in seconds) to construct $N = \\lfloor f_s T \\rfloor$ samples with sampling interval $\\Delta t = 1/f_s$.\n- The respiratory signal is modeled as $x(t) = A_r \\sin(2\\pi f_r t) + \\eta_x(t)$.\n- The interbeat-interval signal is modeled as $y(t) = RR_0 + k \\sin(2\\pi f_r t + \\phi) + \\eta_y(t)$, where $RR_0$ is a baseline interval in seconds, $k$ is a coupling strength (seconds), and $\\phi$ is a phase offset in radians. Let $\\phi = 0$.\n- The noise terms $\\eta_x(t)$ and $\\eta_y(t)$ are independent zero-mean Gaussian white noises with standard deviations $\\sigma_x$ and $\\sigma_y$, respectively.\n\nAlgorithmic requirements:\n- Use windowed, overlapped segment averaging (Welch’s method) with a Hann window for spectral estimation.\n- Ensure frequency resolution sufficient to resolve the high-frequency band $[0.15,\\,0.40]$ hertz; angles are in radians.\n- Compute $C_{xy}(f)$ consistent with your derivation, and then compute the average of $C_{xy}(f)$ over the high-frequency band.\n\nTest suite:\nUse the following parameter sets to construct signals and compute the averaged high-frequency coherence. For each case, set $f_s = 4$ (hertz), and use independent random seeds as specified for reproducibility.\n1. Happy path RSA case: $T = 300$, $A_r = 1.0$, $f_r = 0.25$, $RR_0 = 0.80$, $k = 0.12$, $\\sigma_x = 0.05$, $\\sigma_y = 0.02$, seed $= 42$.\n2. No coupling case: $T = 300$, $A_r = 1.0$, $f_r = 0.25$, $RR_0 = 0.80$, $k = 0.00$, $\\sigma_x = 0.05$, $\\sigma_y = 0.02$, seed $= 43$.\n3. Boundary high-frequency RSA case: $T = 300$, $A_r = 1.0$, $f_r = 0.40$, $RR_0 = 0.80$, $k = 0.12$, $\\sigma_x = 0.05$, $\\sigma_y = 0.02$, seed $= 44$.\n4. Low-frequency respiration coupling case: $T = 300$, $A_r = 1.0$, $f_r = 0.10$, $RR_0 = 0.80$, $k = 0.12$, $\\sigma_x = 0.05$, $\\sigma_y = 0.02$, seed $= 45$.\n\nOutput specification:\n- For each test case, compute the average of $C_{xy}(f)$ over the band $[0.15,\\,0.40]$ hertz and return it as a float.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each value rounded to three decimal places, for example, $[r_1,r_2,r_3,r_4]$ where each $r_i$ is the averaged high-frequency coherence for the $i$-th test case.",
            "solution": "The problem requires the formal derivation of a normalized frequency-domain coupling measure, the magnitude-squared coherence, and its subsequent computation for modeled respiratory and interbeat-interval signals. The validation and solution are presented below.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Base Definitions:**\n    - Cross-correlation: $R_{xy}(\\tau) = \\mathbb{E}[x(t)\\,y(t+\\tau)]$.\n    - Spectral densities (power and cross) are defined as the Fourier transform of the corresponding correlation functions.\n    - Fourier transform angle: Argument is $2\\pi f t$.\n- **Objective:**\n    - Derive a normalized frequency-domain association measure $C_{xy}(f)$ bounded between $0$ and $1$.\n    - Compute the magnitude-squared coherence $C_{xy}(f)$ using windowed, averaged periodograms (Welch’s method).\n    - Interpret Respiratory Sinus Arrhythmia (RSA) strength by averaging $C_{xy}(f)$ over the high-frequency (HF) band $[0.15,\\,0.40]$ hertz.\n- **Signal Models and Parameters:**\n    - Signals: $x(t)$ (respiration) and $y(t)$ (interbeat-interval).\n    - Time $t$ in seconds, frequency $f$ in hertz.\n    - Sampling frequency: $f_s$. Sampling interval: $\\Delta t = 1/f_s$. Number of samples: $N = \\lfloor f_s T \\rfloor$.\n    - Respiration signal: $x(t) = A_r \\sin(2\\pi f_r t) + \\eta_x(t)$.\n    - Interbeat-interval signal: $y(t) = RR_0 + k \\sin(2\\pi f_r t + \\phi) + \\eta_y(t)$, with phase offset $\\phi=0$.\n    - Noise: $\\eta_x(t)$ and $\\eta_y(t)$ are independent, zero-mean Gaussian white noises with standard deviations $\\sigma_x$ and $\\sigma_y$.\n- **Algorithmic Requirements:**\n    - Spectral estimation: Welch’s method with a Hann window.\n    - Averaging band: $[0.15,\\,0.40]$ Hz.\n- **Test Suite:**\n    - Common parameters: $f_s = 4$ Hz, $T = 300$ s.\n    - Case 1 (Happy path): $A_r = 1.0, f_r = 0.25, RR_0 = 0.80, k = 0.12, \\sigma_x = 0.05, \\sigma_y = 0.02$, seed $= 42$.\n    - Case 2 (No coupling): $A_r = 1.0, f_r = 0.25, RR_0 = 0.80, k = 0.00, \\sigma_x = 0.05, \\sigma_y = 0.02$, seed $= 43$.\n    - Case 3 (Boundary HF): $A_r = 1.0, f_r = 0.40, RR_0 = 0.80, k = 0.12, \\sigma_x = 0.05, \\sigma_y = 0.02$, seed $= 44$.\n    - Case 4 (Low-frequency): $A_r = 1.0, f_r = 0.10, RR_0 = 0.80, k = 0.12, \\sigma_x = 0.05, \\sigma_y = 0.02$, seed $= 45$.\n- **Output Specification:**\n    - A single line of output: `[r_1,r_2,r_3,r_4]` where $r_i$ is the averaged HF coherence for case $i$, rounded to three decimal places.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is evaluated against the validation criteria:\n\n- **Scientifically Grounded:** The problem is firmly rooted in the established principles of time-series analysis and biomedical signal processing. The concepts of correlation, spectral density, coherence, and Welch's method are standard tools in these fields. The application to modeling respiratory sinus arrhythmia (RSA) is a classic and well-understood problem in physiology and biomedical engineering. The problem is scientifically sound.\n- **Well-Posed:** All necessary parameters, signal models, and algorithmic constraints are explicitly provided. The objective is clearly defined: derive a standard quantity and compute it for a given set of parameters. This structure ensures that a unique and meaningful solution can be found for each test case, given the specified random seeds for reproducibility. The problem is well-posed.\n- **Objective:** The problem is formulated using precise, quantitative, and unbiased technical language. It is free from subjective claims or opinions.\n- **Completeness and Consistency:** The problem is self-contained. It provides all data and definitions required for its solution. There are no contradictions in the provided information.\n- **Realism:** While the signal models are simplifications of true physiological signals, they are standard and useful first-order approximations for studying the linear coupling aspects of RSA. The parameters and frequency bands are physiologically realistic.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It satisfies all criteria for being scientifically grounded, well-posed, objective, and complete. Therefore, a full solution will be provided.\n\n### Derivation of the Magnitude-Squared Coherence\n\nWe begin from the first principles as stipulated for two jointly wide-sense stationary random processes, $x(t)$ and $y(t)$.\n\nThe cross-correlation function between $x(t)$ and $y(t)$ is defined as:\n$$ R_{xy}(\\tau) = \\mathbb{E}[x(t) y(t+\\tau)] $$\nwhere $\\mathbb{E}[\\cdot]$ denotes the expectation operator and $\\tau$ is the time lag. The autocorrelation functions are special cases:\n$$ R_{xx}(\\tau) = \\mathbb{E}[x(t) x(t+\\tau)] $$\n$$ R_{yy}(\\tau) = \\mathbb{E}[y(t) y(t+\\tau)] $$\n\nThe Wiener-Khinchin theorem relates the correlation functions to the spectral density functions via the Fourier transform. The cross-spectral density, $S_{xy}(f)$, is the Fourier transform of the cross-correlation function:\n$$ S_{xy}(f) = \\mathcal{F}\\{R_{xy}(\\tau)\\} = \\int_{-\\infty}^{\\infty} R_{xy}(\\tau) e^{-i 2\\pi f \\tau} d\\tau $$\nSimilarly, the power spectral densities (PSDs), $S_{xx}(f)$ and $S_{yy}(f)$, are the Fourier transforms of their respective autocorrelation functions:\n$$ S_{xx}(f) = \\mathcal{F}\\{R_{xx}(\\tau)\\} = \\int_{-\\infty}^{\\infty} R_{xx}(\\tau) e^{-i 2\\pi f \\tau} d\\tau $$\n$$ S_{yy}(f) = \\mathcal{F}\\{R_{yy}(\\tau)\\} = \\int_{-\\infty}^{\\infty} R_{yy}(\\tau) e^{-i 2\\pi f \\tau} d\\tau $$\n\nThe PSDs $S_{xx}(f)$ and $S_{yy}(f)$ are real-valued and non-negative, representing the distribution of power of the signals over frequency. The cross-spectral density $S_{xy}(f)$ is, in general, a complex function. Its magnitude indicates the extent to which $x(t)$ and $y(t)$ are correlated at frequency $f$, and its phase indicates the phase lag between the signals at that frequency.\n\nTo obtain a dimensionless measure of linear association, we normalize the cross-spectral density. This leads to the definition of the complex coherence function, $\\gamma_{xy}(f)$:\n$$ \\gamma_{xy}(f) = \\frac{S_{xy}(f)}{\\sqrt{S_{xx}(f) S_{yy}(f)}} $$\n\nThe most commonly used measure is the magnitude-squared coherence (MSC), denoted here as $C_{xy}(f)$, which is a real-valued function:\n$$ C_{xy}(f) = |\\gamma_{xy}(f)|^2 = \\frac{|S_{xy}(f)|^2}{S_{xx}(f) S_{yy}(f)} $$\n\nTo prove that $C_{xy}(f)$ is bounded between $0$ and $1$, we rely on a property equivalent to the Cauchy-Schwarz inequality. Consider an arbitrary complex constant $\\alpha$. The power spectral density of the combined process $x(t) - \\alpha y(t)$ must be non-negative for all frequencies $f$:\n$$ S_{x-\\alpha y, x-\\alpha y}(f) \\ge 0 $$\nExpanding this expression using the linearity of the expectation and Fourier transform operators, we have:\n$$ S_{x-\\alpha y, x-\\alpha y}(f) = S_{xx}(f) - \\alpha S_{yx}(f) - \\alpha^* S_{xy}(f) + |\\alpha|^2 S_{yy}(f) \\ge 0 $$\nNote that $S_{yx}(f) = S_{xy}^*(f)$. Therefore, the expression becomes:\n$$ S_{xx}(f) - \\alpha S_{xy}^*(f) - \\alpha^* S_{xy}(f) + |\\alpha|^2 S_{yy}(f) \\ge 0 $$\nThis inequality must hold for any choice of complex $\\alpha$. We choose a specific $\\alpha$ to maximize the information gained. Let $\\alpha = \\frac{S_{xy}(f)}{S_{yy}(f)}$. Substituting this into the inequality (assuming $S_{yy}(f) > 0$):\n$$ S_{xx}(f) - \\frac{S_{xy}(f)}{S_{yy}(f)} S_{xy}^*(f) - \\frac{S_{xy}^*(f)}{S_{yy}(f)} S_{xy}(f) + \\frac{|S_{xy}(f)|^2}{S_{yy}(f)^2} S_{yy}(f) \\ge 0 $$\n$$ S_{xx}(f) - \\frac{|S_{xy}(f)|^2}{S_{yy}(f)} - \\frac{|S_{xy}(f)|^2}{S_{yy}(f)} + \\frac{|S_{xy}(f)|^2}{S_{yy}(f)} \\ge 0 $$\n$$ S_{xx}(f) - \\frac{|S_{xy}(f)|^2}{S_{yy}(f)} \\ge 0 $$\nRearranging the terms, we get:\n$$ S_{xx}(f) S_{yy}(f) \\ge |S_{xy}(f)|^2 $$\nSince PSDs are non-negative, we can divide by the product $S_{xx}(f)S_{yy}(f)$ (assuming it is non-zero) without changing the inequality's direction:\n$$ 1 \\ge \\frac{|S_{xy}(f)|^2}{S_{xx}(f) S_{yy}(f)} $$\nThe left side of the definition of $C_{xy}(f)$ is a squared magnitude divided by non-negative values, so it must be non-negative. Combining these results, we confirm the bounds:\n$$ 0 \\le C_{xy}(f) \\le 1 $$\nThis completes the derivation. $C_{xy}(f)$ provides a normalized measure of the linear coupling between two signals at each frequency $f$. A value of $1$ indicates perfect linear correlation, while a value of $0$ indicates no linear correlation at that frequency.\n\n### Computational Implementation\n\nThe program will implement the computation of $C_{xy}(f)$ and its average over the HF band for the given test cases.\n\n1.  **Signal Generation**: For each test case, discrete-time signals $x[n]$ and $y[n]$ are generated according to the specified models. A time vector is created from $t=0$ to $T$ with a step of $\\Delta t=1/f_s$. Noise is generated using a reproducible random number generator seeded for each case. The DC term $RR_0$ in $y(t)$ is handled by the spectral estimation function.\n\n2.  **Spectral Estimation (Welch's Method)**: The `scipy.signal.coherence` function is used. This function internally estimates the PSDs ($S_{xx}, S_{yy}$) and the cross-spectral density ($S_{xy}$) by:\n    a. Dividing the signals into overlapping segments.\n    b. Applying a window function (Hann window, as specified) to each segment to reduce spectral leakage.\n    c. Computing the squared-magnitude FFT for PSDs and the conjugate product for the CSD for each segment.\n    d. Averaging these spectral estimates across all segments. This averaging reduces the variance of the final estimate.\n    The function then computes $C_{xy}(f)$ according to the derived formula. A segment length (`nperseg`) of $256$ is chosen to provide a frequency resolution of $f_s/\\text{nperseg} = 4/256 \\approx 0.0156$ Hz, which is adequate for the specified band. An overlap of $50\\%$ (`noverlap=128`) is used, which is a common choice.\n\n3.  **Band Averaging**: The output of the coherence function is a vector of coherence values and a corresponding vector of frequencies. The program identifies the indices corresponding to frequencies within the HF band $[0.15, 0.40]$ Hz. The mean of the coherence values at these indices is then calculated, yielding a single scalar value that quantifies the strength of RSA.\n\n4.  **Iteration and Output**: The process is repeated for all four test cases. The resulting average coherence values are collected and formatted into the required string output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import signal\n\ndef solve():\n    \"\"\"\n    Solves the problem of computing high-frequency coherence for four test cases.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1: Happy path RSA\n        {'T': 300, 'Ar': 1.0, 'fr': 0.25, 'RR0': 0.80, 'k': 0.12, 'sigma_x': 0.05, 'sigma_y': 0.02, 'seed': 42, 'fs': 4.0},\n        # Case 2: No coupling\n        {'T': 300, 'Ar': 1.0, 'fr': 0.25, 'RR0': 0.80, 'k': 0.00, 'sigma_x': 0.05, 'sigma_y': 0.02, 'seed': 43, 'fs': 4.0},\n        # Case 3: Boundary high-frequency RSA\n        {'T': 300, 'Ar': 1.0, 'fr': 0.40, 'RR0': 0.80, 'k': 0.12, 'sigma_x': 0.05, 'sigma_y': 0.02, 'seed': 44, 'fs': 4.0},\n        # Case 4: Low-frequency respiration coupling\n        {'T': 300, 'Ar': 1.0, 'fr': 0.10, 'RR0': 0.80, 'k': 0.12, 'sigma_x': 0.05, 'sigma_y': 0.02, 'seed': 45, 'fs': 4.0},\n    ]\n\n    results = []\n\n    def compute_hf_coherence(params):\n        \"\"\"\n        Generates signals and computes the average high-frequency coherence.\n        \"\"\"\n        # Unpack parameters\n        T = params['T']\n        Ar = params['Ar']\n        fr = params['fr']\n        RR0 = params['RR0']\n        k = params['k']\n        sigma_x = params['sigma_x']\n        sigma_y = params['sigma_y']\n        seed = params['seed']\n        fs = params['fs']\n\n        # Set up a random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Generate time vector\n        N = int(fs * T)\n        t = np.arange(N) / fs\n\n        # Generate noise signals\n        eta_x = rng.normal(0, sigma_x, N)\n        eta_y = rng.normal(0, sigma_y, N)\n\n        # Generate respiration and interbeat-interval signals\n        # x(t) = A_r * sin(2*pi*f_r*t) + eta_x(t)\n        x = Ar * np.sin(2 * np.pi * fr * t) + eta_x\n        # y(t) = RR_0 + k * sin(2*pi*f_r*t) + eta_y(t), phase phi=0\n        y = RR0 + k * np.sin(2 * np.pi * fr * t) + eta_y\n\n        # Define spectral estimation parameters for Welch's method\n        # nperseg determines frequency resolution. res = fs/nperseg = 4/256 = 0.015625 Hz\n        nperseg = 256\n        noverlap = nperseg // 2 # 50% overlap\n\n        # Compute magnitude-squared coherence using Welch's method\n        # The detrend='constant' argument (default) correctly handles the RR0 mean offset in y(t).\n        frequencies, Cxy = signal.coherence(x, \n                                             y, \n                                             fs=fs, \n                                             window='hann', \n                                             nperseg=nperseg, \n                                             noverlap=noverlap)\n\n        # Define high-frequency band for RSA\n        hf_band_low = 0.15\n        hf_band_high = 0.40\n\n        # Find indices of frequencies within the high-frequency band\n        hf_indices = np.where((frequencies >= hf_band_low) & (frequencies <= hf_band_high))\n        \n        # Extract coherence values in the HF band\n        hf_coherence = Cxy[hf_indices]\n        \n        # Compute the average coherence over the band\n        if len(hf_coherence) == 0:\n            return 0.0 # Should not happen with chosen parameters\n        \n        avg_hf_coherence = np.mean(hf_coherence)\n\n        return avg_hf_coherence\n\n    for case in test_cases:\n        result = compute_hf_coherence(case)\n        results.append(result)\n\n    # Format the final output string as specified, rounding to 3 decimal places\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While descriptive methods like spectral analysis are valuable, a deeper understanding of cardiac dynamics can be achieved through generative, parametric models that capture the underlying stochastic process of heartbeat generation. This practice moves into the realm of advanced statistical modeling, using a history-dependent inverse Gaussian renewal process to model the sequence of $RR$ intervals. The core task is to apply the principle of maximum likelihood estimation (MLE), a cornerstone of modern statistical inference. Deriving the score function  is the essential first step in fitting such a model to data, equipping you with the foundational skills to develop and estimate sophisticated, theory-driven models of physiological time series.",
            "id": "3906288",
            "problem": "You are given a sequence of observed beat-to-beat $RR$ intervals $\\{t_{i}\\}_{i=1}^{n}$ (in seconds) from a single subject under resting conditions. Assume the inter-beat intervals form a renewal process whose conditional inter-arrival time distribution, given the history $\\mathcal{H}_{i-1}$ up to beat $i-1$, is inverse Gaussian with a history-dependent mean. Specifically, let the conditional distribution be inverse Gaussian with mean $\\mu_{i}$ and shape $\\lambda$, where the mean depends on a parsimonious autoregressive history feature via\n$$\n\\mu_{i} \\equiv \\mu(t_{i}\\,|\\,\\mathcal{H}_{i-1}) \\;=\\; \\exp\\!\\big(\\beta_{0} + \\beta_{1}\\, (t_{i-1} - m_{i-1})\\big),\n$$\nand the shape parameter $\\lambda>0$ is constant across $i$. The quantity $m_{i}$ is a smoothed baseline constructed as an exponentially weighted moving average with a known smoothing factor $\\alpha \\in (0,1)$,\n$$\nm_{i} \\;=\\; (1-\\alpha)\\, m_{i-1} + \\alpha\\, t_{i}, \\quad \\text{with } m_{0} \\text{ known},\n$$\nand we condition on the initial value $t_{0}$ as known. The inverse Gaussian density for $t>0$ with mean $\\mu>0$ and shape $\\lambda>0$ is\n$$\nf(t \\mid \\mu,\\lambda) \\;=\\; \\sqrt{\\frac{\\lambda}{2\\pi t^{3}}}\\, \\exp\\!\\left(-\\frac{\\lambda\\,(t-\\mu)^{2}}{2\\,\\mu^{2}\\, t}\\right).\n$$\nAssume conditional independence across intervals given the history so that the likelihood is the product of the conditional densities. Using only the definitions above and first principles of maximum likelihood estimation, construct the full log-likelihood for the parameter vector $\\theta = (\\beta_{0}, \\beta_{1}, \\lambda)$ based on $\\{t_{i}\\}_{i=1}^{n}$, and derive the score function $s(\\theta) = \\partial \\ell(\\theta)/\\partial \\theta$ as a closed-form analytic expression. Express the final score vector explicitly in terms of $\\{t_{i}\\}_{i=1}^{n}$, $\\{m_{i-1}\\}_{i=1}^{n}$, $\\alpha$, and the parameters $\\beta_{0}$, $\\beta_{1}$, and $\\lambda$, with the understanding that $\\{m_{i}\\}$ and $t_{0}$ are treated as given functions of the data and known constants (hence do not introduce additional parameters).\n\nProvide your final answer as a single row vector expression for $s(\\theta)$ with entries corresponding to the partial derivatives with respect to $\\beta_{0}$, $\\beta_{1}$, and $\\lambda$, respectively. Do not round. No units are required in the final answer.",
            "solution": "The problem requires the derivation of the log-likelihood function and the corresponding score function for a specified time-series model of heart rate variability.\n\n### Problem Validation\n\nFirst, we validate the problem statement.\n\n**Step 1: Extract Givens**\n- Data: A sequence of $RR$ intervals $\\{t_{i}\\}_{i=1}^{n}$.\n- Model: A renewal process where the conditional distribution of the inter-arrival time $t_i$ given the history $\\mathcal{H}_{i-1}$ is an inverse Gaussian distribution, $t_i | \\mathcal{H}_{i-1} \\sim \\text{IG}(\\mu_i, \\lambda)$.\n- Inverse Gaussian PDF: $f(t \\mid \\mu,\\lambda) = \\sqrt{\\frac{\\lambda}{2\\pi t^{3}}}\\, \\exp\\left(-\\frac{\\lambda\\,(t-\\mu)^{2}}{2\\,\\mu^{2}\\, t}\\right)$ for $t>0$, $\\mu>0$, $\\lambda>0$.\n- Conditional Mean: $\\mu_{i} = \\exp(\\beta_{0} + \\beta_{1}\\, (t_{i-1} - m_{i-1}))$.\n- Shape Parameter: $\\lambda > 0$, constant for all $i$.\n- Smoothed Baseline: $m_{i} = (1-\\alpha)\\, m_{i-1} + \\alpha\\, t_{i}$ with $\\alpha \\in (0,1)$ and $m_{0}$ known.\n- Initial Condition: $t_{0}$ is known.\n- Parameter Vector: $\\theta = (\\beta_{0}, \\beta_{1}, \\lambda)$.\n- Task: Construct the log-likelihood $\\ell(\\theta)$ and derive the score function $s(\\theta) = \\partial \\ell(\\theta)/\\partial \\theta$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed for validity.\n- **Scientifically Grounded:** The model is a specific form of a point process model with autoregressive features, a standard approach in biomedical systems modeling, particularly for heart rate variability. The inverse Gaussian distribution is a common and appropriate choice for modeling positive-valued event times. The model is scientifically coherent.\n- **Well-Posed:** The problem is mathematically well-defined. It asks for the derivation of a log-likelihood and its gradient (the score function) for a fully specified parametric model. This is a standard and solvable problem in maximum likelihood theory.\n- **Objective:** The problem is stated using precise, unambiguous mathematical language.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. We proceed to derive the solution.\n\n### Likelihood and Log-Likelihood Construction\n\nThe problem states that given the history, the intervals are conditionally independent. The total likelihood function $L(\\theta)$ for the observed sequence $\\{t_i\\}_{i=1}^n$ is the product of the conditional probability densities:\n$$\nL(\\theta) = \\prod_{i=1}^{n} f(t_i \\mid \\mathcal{H}_{i-1}) = \\prod_{i=1}^{n} f(t_i \\mid \\mu_i(\\beta_0, \\beta_1), \\lambda)\n$$\nwhere the parameters are $\\theta = (\\beta_0, \\beta_1, \\lambda)$.\n\nThe log-likelihood function, $\\ell(\\theta) = \\ln L(\\theta)$, is the sum of the individual log-densities:\n$$\n\\ell(\\theta) = \\sum_{i=1}^{n} \\ln f(t_i \\mid \\mu_i, \\lambda)\n$$\nSubstituting the expression for the inverse Gaussian density:\n$$\n\\ell(\\theta) = \\sum_{i=1}^{n} \\ln \\left[ \\left(\\frac{\\lambda}{2\\pi t_i^3}\\right)^{1/2} \\exp\\left(-\\frac{\\lambda(t_i - \\mu_i)^2}{2\\mu_i^2 t_i}\\right) \\right]\n$$\n$$\n\\ell(\\theta) = \\sum_{i=1}^{n} \\left[ \\frac{1}{2}\\ln\\left(\\frac{\\lambda}{2\\pi}\\right) - \\frac{3}{2}\\ln(t_i) - \\frac{\\lambda(t_i - \\mu_i)^2}{2\\mu_i^2 t_i} \\right]\n$$\nSeparating terms that depend on the parameters from those that do not:\n$$\n\\ell(\\theta) = \\frac{n}{2}\\ln(\\lambda) - \\frac{n}{2}\\ln(2\\pi) - \\frac{3}{2}\\sum_{i=1}^{n}\\ln(t_i) - \\frac{\\lambda}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^2}{\\mu_i^2 t_i}\n$$\nThe terms $-\\frac{n}{2}\\ln(2\\pi) - \\frac{3}{2}\\sum_{i=1}^{n}\\ln(t_i)$ are constant with respect to $\\theta$ and will vanish upon differentiation. For the purpose of finding the score function, we can focus on the parameter-dependent part of $\\ell(\\theta)$:\n$$\n\\ell(\\theta) = \\frac{n}{2}\\ln(\\lambda) - \\frac{\\lambda}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^2}{\\mu_i^2 t_i} + \\text{const.}\n$$\nThe term $\\mu_i = \\exp(\\beta_0 + \\beta_1(t_{i-1} - m_{i-1}))$ depends on $\\beta_0$ and $\\beta_1$.\n\n### Score Function Derivation\n\nThe score function is the vector of partial derivatives of the log-likelihood with respect to each parameter: $s(\\theta) = \\frac{\\partial\\ell(\\theta)}{\\partial\\theta} = \\begin{pmatrix} \\frac{\\partial\\ell}{\\partial\\beta_0} & \\frac{\\partial\\ell}{\\partial\\beta_1} & \\frac{\\partial\\ell}{\\partial\\lambda} \\end{pmatrix}$.\n\n**1. Partial Derivative with respect to $\\lambda$**\n\nWe differentiate $\\ell(\\theta)$ with respect to $\\lambda$, treating $\\mu_i$ as constant since it does not depend on $\\lambda$.\n$$\n\\frac{\\partial\\ell}{\\partial\\lambda} = \\frac{\\partial}{\\partial\\lambda}\\left( \\frac{n}{2}\\ln(\\lambda) - \\frac{\\lambda}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^2}{\\mu_i^2 t_i} \\right)\n$$\n$$\n\\frac{\\partial\\ell}{\\partial\\lambda} = \\frac{n}{2\\lambda} - \\frac{1}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^2}{\\mu_i^2 t_i}\n$$\n\n**2. Partial Derivatives with respect to $\\beta_0$ and $\\beta_1$**\n\nThese derivatives require the chain rule, as $\\ell$ depends on $\\beta_0$ and $\\beta_1$ through $\\mu_i$. Let $\\ell_i$ be the $i$-th term in the log-likelihood sum.\n$$\n\\frac{\\partial\\ell}{\\partial\\beta_j} = \\sum_{i=1}^{n} \\frac{\\partial\\ell_i}{\\partial\\beta_j} = \\sum_{i=1}^{n} \\frac{\\partial\\ell_i}{\\partial\\mu_i} \\frac{\\partial\\mu_i}{\\partial\\beta_j} \\quad \\text{for } j=0, 1.\n$$\nFirst, let's find the derivative of the relevant part of $\\ell_i$ with respect to $\\mu_i$:\n$$\n\\frac{\\partial}{\\partial\\mu_i}\\left( -\\frac{\\lambda(t_i - \\mu_i)^2}{2\\mu_i^2 t_i} \\right) = -\\frac{\\lambda}{2t_i} \\frac{\\partial}{\\partial\\mu_i}\\left( \\frac{t_i^2 - 2t_i\\mu_i + \\mu_i^2}{\\mu_i^2} \\right)\n$$\n$$\n= -\\frac{\\lambda}{2t_i} \\frac{\\partial}{\\partial\\mu_i}\\left( t_i^2\\mu_i^{-2} - 2t_i\\mu_i^{-1} + 1 \\right)\n$$\n$$\n= -\\frac{\\lambda}{2t_i} \\left( t_i^2(-2)\\mu_i^{-3} - 2t_i(-1)\\mu_i^{-2} \\right) = -\\frac{\\lambda}{2t_i} \\left( \\frac{-2t_i^2}{\\mu_i^3} + \\frac{2t_i}{\\mu_i^2} \\right)\n$$\n$$\n= -\\frac{\\lambda}{2t_i} \\cdot \\frac{2t_i}{\\mu_i^3} (-\\mu_i + t_i) = \\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^3}\n$$\nNext, we find the partial derivatives of $\\mu_i$ with respect to $\\beta_0$ and $\\beta_1$:\n$$\n\\mu_i = \\exp(\\beta_0 + \\beta_1(t_{i-1} - m_{i-1}))\n$$\n$$\n\\frac{\\partial\\mu_i}{\\partial\\beta_0} = \\exp(\\beta_0 + \\beta_1(t_{i-1} - m_{i-1})) \\cdot 1 = \\mu_i\n$$\n$$\n\\frac{\\partial\\mu_i}{\\partial\\beta_1} = \\exp(\\beta_0 + \\beta_1(t_{i-1} - m_{i-1})) \\cdot (t_{i-1} - m_{i-1}) = \\mu_i(t_{i-1} - m_{i-1})\n$$\nNow, we combine these results using the chain rule.\n\nFor $\\beta_0$:\n$$\n\\frac{\\partial\\ell}{\\partial\\beta_0} = \\sum_{i=1}^{n} \\frac{\\partial\\ell_i}{\\partial\\mu_i}\\frac{\\partial\\mu_i}{\\partial\\beta_0} = \\sum_{i=1}^{n} \\left(\\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^3}\\right) (\\mu_i) = \\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^2}\n$$\n\nFor $\\beta_1$:\n$$\n\\frac{\\partial\\ell}{\\partial\\beta_1} = \\sum_{i=1}^{n} \\frac{\\partial\\ell_i}{\\partial\\mu_i}\\frac{\\partial\\mu_i}{\\partial\\beta_1} = \\sum_{i=1}^{n} \\left(\\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^3}\\right) (\\mu_i(t_{i-1} - m_{i-1}))\n$$\n$$\n\\frac{\\partial\\ell}{\\partial\\beta_1} = \\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)(t_{i-1} - m_{i-1})}{\\mu_i^2}\n$$\n\n**3. Assemble the Score Vector**\n\nThe score function $s(\\theta)$ is the row vector of the partial derivatives:\n$$\ns(\\theta) = \\begin{pmatrix} \\frac{\\partial\\ell}{\\partial\\beta_0} & \\frac{\\partial\\ell}{\\partial\\beta_1} & \\frac{\\partial\\ell}{\\partial\\lambda} \\end{pmatrix}\n$$\nSubstituting the derived expressions, we get the final result:\n$$\ns(\\theta) = \\begin{pmatrix}\n\\displaystyle\\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^2} &\n\\displaystyle\\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)(t_{i-1} - m_{i-1})}{\\mu_i^2} &\n\\displaystyle\\frac{n}{2\\lambda} - \\frac{1}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^2}{\\mu_i^2 t_i}\n\\end{pmatrix}\n$$\nwhere $\\mu_i = \\exp(\\beta_0 + \\beta_1(t_{i-1} - m_{i-1}))$. This expression is in terms of the specified quantities.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\displaystyle\\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)}{\\mu_i^2} & \\displaystyle\\sum_{i=1}^{n} \\frac{\\lambda(t_i - \\mu_i)(t_{i-1} - m_{i-1})}{\\mu_i^2} & \\displaystyle\\frac{n}{2\\lambda} - \\frac{1}{2}\\sum_{i=1}^{n}\\frac{(t_i - \\mu_i)^{2}}{\\mu_i^{2} t_i}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}