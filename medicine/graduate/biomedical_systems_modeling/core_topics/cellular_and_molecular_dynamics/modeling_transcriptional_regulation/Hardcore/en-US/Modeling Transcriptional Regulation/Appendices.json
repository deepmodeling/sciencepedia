{
    "hands_on_practices": [
        {
            "introduction": "To begin modeling transcriptional regulation, we first turn to the principles of equilibrium statistical mechanics. By enumerating the possible microscopic states of a promoter—such as being empty, bound by an activator, or bound by RNA polymerase—we can derive a macroscopic input-output function that predicts gene expression level as a function of activator concentration. This foundational practice  will guide you through deriving such a function, demonstrating how concepts like statistical weights, the partition function, and cooperativity combine to define the system's behavior and how non-dimensionalization reveals the core parameters governing its response.",
            "id": "3908138",
            "problem": "A promoter is regulated by a single transcriptional activator whose binding increases the probability of ribonucleic acid (RNA) polymerase (RNAP) loading. Assume the following quasi-equilibrium thermodynamic model for promoter states, which is widely used in modeling transcriptional regulation:\n\n- The promoter has $4$ mutually exclusive states: empty, activator-bound only, RNAP-bound only, and activator-RNAP co-bound.\n- The activator binds as an oligomer of size $n$ to a single site with dissociation constant $K_d$, so that the thermodynamic weight for activator occupancy is proportional to $(c/K_d)^{n}$, where $c$ is the free activator concentration.\n- RNAP binds with an effective dimensionless weight $p$, which combines the RNAP concentration and its dissociation constant for the promoter.\n- When the activator and RNAP are simultaneously bound, there is a stabilizing interaction parameterized by a dimensionless cooperativity factor $\\omega$, which multiplies the weight of the co-bound state.\n- Transcription occurs only when RNAP is bound, with initiation rate $r$. Messenger RNA is degraded/diluted with first-order rate $\\gamma$, yielding a steady-state activity $f(c) = \\alpha \\, P_{\\mathrm{RNAP}}(c)$, where $\\alpha = r/\\gamma$ and $P_{\\mathrm{RNAP}}(c)$ is the probability that RNAP is bound.\n\nLet $f_{\\max} \\equiv \\lim_{c \\to \\infty} f(c)$ denote the asymptotic maximal activity at saturating activator. Define the dimensionless input $x = c/K_d$ and the dimensionless output $y = f(c)/f_{\\max}$.\n\nStarting from the quasi-equilibrium statistical occupancy framework and mass-action binding for the activator, derive a closed-form expression for the dimensionless input-output function $y(x)$ expressed only in terms of $x$, $n$, $p$, and $\\omega$. Identify in your derivation the key independent dimensionless groups that determine the shape of $y(x)$, and show explicitly how dimensional parameters cancel in $y(x)$.\n\nExpress your final answer as the single closed-form expression for $y(x)$, in terms of $x$, $n$, $p$, and $\\omega$. Do not include units. No rounding is required.",
            "solution": "The problem statement describes a standard thermodynamic model of transcriptional regulation and is scientifically grounded, well-posed, and objective. It contains all necessary information for a rigorous derivation. Therefore, the problem is valid.\n\nThe derivation begins from the principles of statistical mechanics applied to the quasi-equilibrium binding of an activator and RNA polymerase (RNAP) to a promoter. The system has four mutually exclusive states, and the probability of the promoter being in any particular state is proportional to the state's thermodynamic weight.\n\nLet's define the statistical weight, $W$, for each of the four promoter states relative to the empty state, which is assigned a weight of $1$. The dimensionless concentration of the activator is $x = c/K_d$.\n\n1.  **Empty state (promoter only):** No molecules are bound.\n    $$W_0 = 1$$\n2.  **Activator-bound state:** The activator oligomer is bound, but RNAP is not. The weight is given as proportional to $(c/K_d)^n$.\n    $$W_A = x^n$$\n3.  **RNAP-bound state:** RNAP is bound, but the activator is not. The weight is given by the dimensionless parameter $p$.\n    $$W_P = p$$\n4.  **Activator-RNAP co-bound state:** Both the activator and RNAP are bound simultaneously. The weight is the product of the individual binding weights, multiplied by the dimensionless cooperativity factor $\\omega$.\n    $$W_{AP} = W_A \\cdot W_P \\cdot \\omega = x^n \\cdot p \\cdot \\omega$$\n\nThe partition function, $Z(x)$, is the sum of the statistical weights of all possible states. It serves as the normalization constant for calculating probabilities.\n$$Z(x) = W_0 + W_A + W_P + W_{AP}$$\n$$Z(x) = 1 + x^n + p + p\\omega x^n$$\nWe can collect terms in powers of $x$:\n$$Z(x) = (1+p) + (1+p\\omega)x^n$$\n\nAccording to the problem, transcription occurs only when RNAP is bound. This corresponds to the RNAP-bound state and the co-bound state. The probability of RNAP being bound, $P_{\\mathrm{RNAP}}(x)$, is the sum of the weights of these two states divided by the partition function.\n$$P_{\\mathrm{RNAP}}(x) = \\frac{W_P + W_{AP}}{Z(x)} = \\frac{p + p\\omega x^n}{(1+p) + (1+p\\omega)x^n}$$\nThis can be factored as:\n$$P_{\\mathrm{RNAP}}(x) = \\frac{p(1 + \\omega x^n)}{(1+p) + (1+p\\omega)x^n}$$\n\nThe steady-state transcriptional activity is given by $f(c) = \\alpha \\, P_{\\mathrm{RNAP}}(c)$, where $\\alpha = r/\\gamma$. In terms of the dimensionless input $x$, this is $f(x) = \\alpha \\, P_{\\mathrm{RNAP}}(x)$.\n\nNext, we must find the asymptotic maximal activity, $f_{\\max}$, which is defined as the limit of $f(c)$ as $c \\to \\infty$. This is equivalent to the limit of $f(x)$ as $x \\to \\infty$.\n$$f_{\\max} = \\lim_{x \\to \\infty} f(x) = \\lim_{x \\to \\infty} \\left( \\alpha \\frac{p(1 + \\omega x^n)}{(1+p) + (1+p\\omega)x^n} \\right)$$\nTo evaluate the limit, we divide the numerator and the denominator by the highest power of $x$, which is $x^n$.\n$$f_{\\max} = \\alpha \\lim_{x \\to \\infty} \\frac{p(\\frac{1}{x^n} + \\omega)}{(\\frac{1+p}{x^n}) + (1+p\\omega)}$$\nAs $x \\to \\infty$, terms with $x^n$ in the denominator go to $0$.\n$$f_{\\max} = \\alpha \\frac{p(0 + \\omega)}{0 + (1+p\\omega)} = \\alpha \\frac{p\\omega}{1+p\\omega}$$\nIt is important to note that if $\\omega=0$ or $p=0$, then $f_{\\max}=0$. The problem is physically meaningful for $\\omega > 0$ and $p>0$.\n\nThe final step is to derive the dimensionless input-output function, $y(x) = f(x)/f_{\\max}$.\n$$y(x) = \\frac{f(x)}{f_{\\max}} = \\frac{\\alpha \\, P_{\\mathrm{RNAP}}(x)}{\\alpha \\frac{p\\omega}{1+p\\omega}}$$\nThe dimensional constant $\\alpha=r/\\gamma$ cancels out, demonstrating that the normalized output is independent of the absolute rates of transcription and degradation.\n$$y(x) = \\frac{\\frac{p(1 + \\omega x^n)}{(1+p) + (1+p\\omega)x^n}}{\\frac{p\\omega}{1+p\\omega}}$$\nAssuming $p > 0$, the factor of $p$ also cancels:\n$$y(x) = \\frac{1 + \\omega x^n}{(1+p) + (1+p\\omega)x^n} \\cdot \\frac{1+p\\omega}{\\omega}$$\nThis expression gives $y(x)$ in terms of $x$, $n$, $p$, and $\\omega$. The dimensional parameters $c$ and $K_d$ are contained within the dimensionless input $x$, and all other dimensional parameters ($r, \\gamma$) have cancelled. The shape of the input-output curve is thus determined solely by the dimensionless groups $n$, $p$, and $\\omega$.\n\nFor a more elegant and insightful form, we can simplify this expression. Let's manipulate the fraction by multiplying the numerator by $(1+p\\omega)$ and the denominator by $\\omega$.\n$$y(x) = \\frac{(1 + \\omega x^n)(1+p\\omega)}{\\omega((1+p) + (1+p\\omega)x^n)}$$\nNow, divide both the numerator and the denominator of this larger fraction by the term $\\omega(1+p\\omega)$.\nThe numerator becomes:\n$$\\frac{(1 + \\omega x^n)(1+p\\omega)}{\\omega(1+p\\omega)} = \\frac{1 + \\omega x^n}{\\omega} = x^n + \\frac{1}{\\omega}$$\nThe denominator becomes:\n$$\\frac{\\omega((1+p) + (1+p\\omega)x^n)}{\\omega(1+p\\omega)} = \\frac{(1+p) + (1+p\\omega)x^n}{1+p\\omega} = \\frac{1+p}{1+p\\omega} + \\frac{(1+p\\omega)x^n}{1+p\\omega} = x^n + \\frac{1+p}{1+p\\omega}$$\nCombining these results gives the final closed-form expression for $y(x)$:\n$$y(x) = \\frac{x^n + \\frac{1}{\\omega}}{x^n + \\frac{1+p}{1+p\\omega}}$$\nThis expression is the required input-output function, written solely in terms of the dimensionless input $x$ and the dimensionless parameters $n$, $p$, and $\\omega$.",
            "answer": "$$\\boxed{\\frac{x^n + \\frac{1}{\\omega}}{x^n + \\frac{1+p}{1+p\\omega}}}$$"
        },
        {
            "introduction": "While equilibrium models describe the average behavior of a cell population, gene expression within a single cell is inherently stochastic, characterized by bursts of activity. The \"telegraph model\" provides a powerful framework for capturing this dynamic reality by treating promoter switching, transcription, and degradation as distinct stochastic events. This exercise  delves into this canonical model to derive the stationary distribution of messenger RNA counts, which forms the basis for constructing a likelihood function essential for inferring kinetic rates from modern single-cell snapshot data.",
            "id": "3908091",
            "problem": "Consider a two-state promoter model for a single gene in a homogeneous population of cells, where the promoter toggles between an inactive state and an active state. The transitions are modeled as a continuous-time Markov process with the following biochemical rates: the promoter switches from the inactive state to the active state at rate $k_{\\text{on}}$, and from the active state back to the inactive state at rate $k_{\\text{off}}$. While active, the gene transcribes messenger ribonucleic acid (mRNA) molecules at rate $k_{\\text{tx}}$ according to a Poisson process. Each mRNA molecule degrades independently at rate $\\gamma$ following first-order kinetics. Assume the system has reached a stationary regime under constant environmental conditions.\n\nYou collect a snapshot of single-cell mRNA counts from $M$ independent cells at stationarity; denote the observed counts by $\\{n_{i}\\}_{i=1}^{M}$, where $n_{i} \\in \\{0,1,2,\\dots\\}$.\n\nStarting only from the above definitions and the standard properties of Poisson processes, exponential lifetimes, and the superposition and thinning of point processes, do the following:\n\n1. Model transcriptional bursts as sequences of promoter activations. Derive the stationary distribution of the total mRNA count in a cell. Express your result in closed form and identify the distribution family. Determine the distribution’s parameters as functions of $k_{\\text{on}}$, $k_{\\text{off}}$, $k_{\\text{tx}}$, and $\\gamma$.\n\n2. Using the derived stationary distribution, write the likelihood function $L(k_{\\text{on}},k_{\\text{off}},k_{\\text{tx}},\\gamma \\,;\\, n_{1},\\dots,n_{M})$ for the observed data, assuming independence across cells.\n\n3. Outline a maximum likelihood estimation procedure for the parameters $\\left(k_{\\text{on}},k_{\\text{off}},k_{\\text{tx}},\\gamma\\right)$, including (i) a clear reparameterization that enforces positivity constraints, (ii) the role of the log-likelihood and its gradients, (iii) any identifiability considerations that arise from the snapshot counts in this model, and (iv) a principled way to incorporate any external measurements that resolve non-identifiabilities.\n\nProvide your final likelihood as a single analytic expression in terms of $k_{\\text{on}}$, $k_{\\text{off}}$, $k_{\\text{tx}}$, $\\gamma$, and $\\{n_{i}\\}_{i=1}^{M}$. No numerical evaluation is required.",
            "solution": "The problem describes the \"telegraph model\" of gene expression, a canonical model in stochastic systems biology. The problem is scientifically sound, well-posed, and objective, asking for standard derivations related to this model. Therefore, the problem is valid.\n\n**1. Stationary Distribution of mRNA Count**\n\nThe number of mRNA molecules, $n$, in a cell at any given time is the result of the stochastic processes of transcription and degradation. The transcription rate is not constant but is modulated by the promoter state, which switches between an active state (rate $k_{\\text{tx}}$) and an inactive state (rate $0$). Each mRNA molecule, once produced, has an independent, exponentially distributed lifetime with mean $1/\\gamma$.\n\nAt stationarity, the number of mRNA molecules $n$ is equivalent to the number of arrivals from a modulated Poisson process that are still \"alive\" at the time of observation. An mRNA molecule produced at time $t-\\tau$ survives until time $t$ with probability $\\exp(-\\gamma \\tau)$. Let $S(t)$ be the promoter state, with $S(t)=1$ for active and $S(t)=0$ for inactive. The instantaneous transcription rate is $k_{\\text{tx}}S(t)$. The mRNA count $n$ at time $t$ can be described as a Poisson random variable whose parameter, $\\Lambda(t)$, is the integrated history of past transcription, weighted by the survival probability:\n$$ \\Lambda(t) = \\int_{0}^{\\infty} k_{\\text{tx}} S(t-\\tau) \\exp(-\\gamma \\tau) d\\tau $$\nSince the system is at stationarity, the distribution of $n$ is constant. We can characterize this distribution by finding the distribution of the random variable $\\Lambda$. Let $x = \\gamma \\int_{0}^{\\infty} S(t-\\tau) \\exp(-\\gamma \\tau) d\\tau$. This variable $x$ is an exponentially-weighted moving average of the promoter state history. The stochastic differential equation for $x$ is $dx/dt = \\gamma(S(t) - x)$. This is an Ornstein-Uhlenbeck process driven by the telegraph noise $S(t)$.\n\nFor a two-state Markov process $S(t)$ with switching rates $k_{\\text{on}}$ and $k_{\\text{off}}$, the stationary distribution of the filtered process $x(t)$ is a Beta distribution on the interval $[0, 1]$:\n$$ x \\sim \\text{Beta}(a, b) \\quad \\text{with PDF} \\quad f(x|a, b) = \\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)} $$\nThe parameters of this Beta distribution are given by the ratios of the kinetic rates:\n$$ a = \\frac{k_{\\text{on}}}{\\gamma} \\quad \\text{and} \\quad b = \\frac{k_{\\text{off}}}{\\gamma} $$\nThe mRNA count $n$ is therefore a mixed Poisson variable, where $n \\sim \\text{Poisson}(\\lambda)$ and the rate parameter $\\lambda = \\frac{k_{\\text{tx}}}{\\gamma} x = \\beta x$, with $\\beta = k_{\\text{tx}}/\\gamma$. The resulting distribution of $n$ is a **Poisson-Beta distribution**.\n\nThe probability mass function (PMF), $P(n)$, is obtained by marginalizing over the distribution of $x$:\n$$ P(n) = \\int_0^1 P(n|\\lambda=\\beta x) f(x|a,b) dx $$\n$$ P(n) = \\int_0^1 \\frac{(\\beta x)^n \\exp(-\\beta x)}{n!} \\frac{x^{a-1}(1-x)^{b-1}}{B(a,b)} dx $$\nwhere $B(a,b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$ is the Beta function. Rearranging the terms, we get:\n$$ P(n) = \\frac{\\beta^n}{n! B(a,b)} \\int_0^1 x^{n+a-1} (1-x)^{b-1} \\exp(-\\beta x) dx $$\nThe integral is a representation of the confluent hypergeometric function of the first kind, ${}_1F_1(u;v;z)$, also known as Kummer's function. The PMF can be written in closed form as:\n$$ P(n) = \\frac{B(n+a, b)}{B(a,b)} \\frac{\\beta^n}{n!} {}_1F_1(n+a; n+a+b; -\\beta) $$\nUsing the property of the Pochhammer symbol $(q)_k = \\Gamma(q+k)/\\Gamma(q)$, this simplifies to:\n$$ P(n | a, b, \\beta) = \\frac{(a)_n}{(a+b)_n} \\frac{\\beta^n}{n!} {}_1F_1(a+n; a+b+n; -\\beta) $$\nwhere the parameters are functions of the underlying kinetic rates:\n- $a = k_{\\text{on}}/\\gamma$\n- $b = k_{\\text{off}}/\\gamma$\n- $\\beta = k_{\\text{tx}}/\\gamma$\n\n**2. Likelihood Function**\n\nThe observed data consists of $M$ independent measurements of mRNA counts $\\{n_1, n_2, \\dots, n_M\\}$. The likelihood function $L$ for the model parameters $\\theta = (k_{\\text{on}}, k_{\\text{off}}, k_{\\text{tx}}, \\gamma)$ is the product of the probabilities of observing each count, given the parameters.\n$$ L(\\theta \\,;\\, \\{n_i\\}_{i=1}^M) = \\prod_{i=1}^M P(n_i | \\theta) $$\nSubstituting the PMF derived above, and letting $a(\\theta) = k_{\\text{on}}/\\gamma$, $b(\\theta) = k_{\\text{off}}/\\gamma$, and $\\beta(\\theta) = k_{\\text{tx}}/\\gamma$:\n$$ L(k_{\\text{on}}, k_{\\text{off}}, k_{\\text{tx}}, \\gamma \\,;\\, \\{n_i\\}) = \\prod_{i=1}^M \\left[ \\frac{(a)_{n_i}}{(a+b)_{n_i}} \\frac{\\beta^{n_i}}{n_i!} {}_1F_1(a+n_i; a+b+n_i; -\\beta) \\right] $$\nThis is the required likelihood function.\n\n**3. Maximum Likelihood Estimation (MLE) Procedure**\n\nThe goal of MLE is to find the parameter values $\\hat{\\theta}$ that maximize the likelihood function $L(\\theta)$.\n\n**(i) Reparameterization:**\nThe kinetic rates $k_{\\text{on}}, k_{\\text{off}}, k_{\\text{tx}}, \\gamma$ must be strictly positive. To enforce this constraint during numerical optimization, it is standard practice to reparameterize them. A common choice is an exponential transformation:\n$$ k_{\\text{on}} = \\exp(\\kappa_{\\text{on}}), \\quad k_{\\text{off}} = \\exp(\\kappa_{\\text{off}}), \\quad k_{\\text{tx}} = \\exp(\\kappa_{\\text{tx}}), \\quad \\gamma = \\exp(\\kappa_{\\gamma}) $$\nThe optimization is then performed over the new parameters $\\kappa \\in \\mathbb{R}^4$, which is an unconstrained problem more suitable for standard gradient-based algorithms.\n\n**(ii) Log-likelihood and Gradients:**\nMaximizing the likelihood $L$ is equivalent to maximizing the log-likelihood $\\mathcal{L} = \\ln(L)$, which is numerically more stable and analytically more convenient.\n$$ \\mathcal{L}(\\theta \\,;\\, \\{n_i\\}) = \\sum_{i=1}^M \\ln P(n_i | \\theta) $$\n$$ \\mathcal{L} = \\sum_{i=1}^M \\left[ \\sum_{j=0}^{n_i-1}\\ln(a+j) - \\sum_{j=0}^{n_i-1}\\ln(a+b+j) + n_i\\ln(\\beta) - \\ln(n_i!) + \\ln({}_1F_1(a+n_i; a+b+n_i; -\\beta)) \\right] $$\nThe MLE estimate $\\hat{\\theta}$ is found by solving $\\nabla_{\\kappa} \\mathcal{L}(\\kappa) = 0$. This typically requires numerical optimization methods (e.g., L-BFGS, Nelder-Mead) that use the gradient of the log-likelihood with respect to the $\\kappa$ parameters. The gradients are computed using the chain rule, for example $\\frac{\\partial \\mathcal{L}}{\\partial \\kappa_j} = \\frac{\\partial \\mathcal{L}}{\\partial k_j} \\frac{\\partial k_j}{\\partial \\kappa_j} = \\frac{\\partial \\mathcal{L}}{\\partial k_j} k_j$. This requires computing derivatives of the log-gamma function (digamma function) and derivatives of the confluent hypergeometric function.\n\n**(iii) Identifiability Considerations:**\nThe likelihood function is parameterized entirely by the three dimensionless quantities $a=k_{\\text{on}}/\\gamma$, $b=k_{\\text{off}}/\\gamma$, and $\\beta=k_{\\text{tx}}/\\gamma$. This means that from a single snapshot of stationary mRNA counts, one can only identify these three ratios. The four underlying kinetic parameters $(k_{\\text{on}}, k_{\\text{off}}, k_{\\text{tx}}, \\gamma)$ are not uniquely identifiable. For any optimal set of ratios $(\\hat{a}, \\hat{b}, \\hat{\\beta})$, any parameter set of the form $(C\\hat{a}\\gamma, C\\hat{b}\\gamma, C\\hat{\\beta}\\gamma, C\\gamma)$ for any constant $C0$ yields the same likelihood. This ambiguity reflects the fact that the stationary distribution does not contain information about the absolute timescale of the system dynamics, which is set by $\\gamma$.\n\n**(iv) Resolving Non-identifiabilities:**\nTo uniquely determine all four kinetic rates, additional experimental information is required to break the scaling ambiguity. A principled way to achieve this involves:\n- **Independent Measurement of a Rate:** The most common approach is to measure one of the rates independently. For instance, the mRNA degradation rate $\\gamma$ can be measured by treating cells with a transcription inhibitor (like Actinomycin D) and quantifying the decay of mRNA over time. If a value for $\\gamma$ is obtained, it can be fixed in the MLE procedure, and the likelihood can be maximized with respect to the remaining three parameters, $k_{\\text{on}}$, $k_{\\text{off}}$, and $k_{\\text{tx}}$, which then become uniquely identifiable from the relations $k_{\\text{on}} = a \\gamma$, $k_{\\text{off}} = b \\gamma$, and $k_{\\text{tx}} = \\beta \\gamma$.\n- **Time-Series Data:** Alternatively, measuring mRNA counts in single cells over time (live-cell imaging) provides information about the system's temporal correlations. The decay rate of the mRNA auto-correlation function is related to $\\gamma$ and $k_{\\text{on}}+k_{\\text{off}}$. This additional information provides a constraint on the absolute timescale, allowing for the unique identification of all four parameters from a joint fit to the stationary distribution and the temporal correlation data.",
            "answer": "$$ \\boxed{ L(k_{\\text{on}},k_{\\text{off}},k_{\\text{tx}},\\gamma \\,;\\, \\{n_{i}\\}_{i=1}^{M}) = \\prod_{i=1}^{M} \\left[ \\frac{(\\frac{k_{\\text{on}}}{\\gamma})_{n_i}}{(\\frac{k_{\\text{on}}+k_{\\text{off}}}{\\gamma})_{n_i}} \\frac{(\\frac{k_{\\text{tx}}}{\\gamma})^{n_i}}{n_i!} {}_1F_1\\left(\\frac{k_{\\text{on}}}{\\gamma}+n_i; \\frac{k_{\\text{on}}+k_{\\text{off}}}{\\gamma}+n_i; -\\frac{k_{\\text{tx}}}{\\gamma}\\right) \\right] } $$"
        },
        {
            "introduction": "Once a model is formulated, we must confront it with experimental data to estimate its parameters, but this process often reveals a fundamental challenge known as parameter sloppiness. Even for a simple regulatory model, some combinations of parameters can be changed drastically without significantly affecting the model's fit to the data, making them practically unidentifiable. In this practice , you will linearize a model around its best-fit parameters and analyze the Hessian of the cost function to quantitatively understand why some parameter directions are \"stiff\" and well-constrained by data, while others are \"sloppy\" and poorly determined.",
            "id": "3908118",
            "problem": "A single transcription factor binds a promoter with rapid equilibrium kinetics, and the promoter occupancy is well-approximated by the equilibrium binding fraction $h(x) = \\frac{x}{K + x}$, where $x$ is the transcription factor concentration and $K$ is the dissociation constant. The steady-state messenger ribonucleic acid (mRNA) level of a regulated gene is modeled as $y(x; \\theta_0, \\theta_1) = \\theta_0 + \\theta_1 h(x)$, where $\\theta_0$ is the basal expression and $\\theta_1$ is the activation amplitude. Assume additive, independent, identically distributed Gaussian measurement noise with standard deviation $\\sigma$ on each measurement.\n\nYou collect data under three transcription factor concentrations $x_1 = 1$, $x_2 = 10$, and $x_3 = 100$, all in the same units as $K$, and the dissociation constant is known to be $K = 10$. Let the noise standard deviation be $\\sigma = 1$. Consider the least-squares objective $J(\\theta_0, \\theta_1) = \\frac{1}{2\\sigma^2}\\sum_{i=1}^{3}\\left(y_i - y(x_i;\\theta_0,\\theta_1)\\right)^2$ and linearize this objective around the best-fit parameters $(\\theta_0^{\\ast}, \\theta_1^{\\ast})$ to study the local parameter landscape.\n\nStarting from first principles of equilibrium binding and the definition of the least-squares objective under Gaussian noise, construct the sensitivity-based second-order approximation to $J$ around $(\\theta_0^{\\ast}, \\theta_1^{\\ast})$, derive the associated $2 \\times 2$ symmetric matrix whose eigenvalues quantify local stiffness and sloppiness in parameter space, and compute its two eigenvalues. Report the ratio of the largest to the smallest eigenvalue as a single real number. Round your answer to four significant figures. Express the final answer without units.",
            "solution": "The problem asks to analyze the parameter landscape for a model of transcriptional regulation by calculating the eigenvalues of the Hessian matrix of the least-squares objective function. The problem is scientifically sound, well-posed, and objective.\n\nThe local curvature of the least-squares objective function $J(\\theta_0, \\theta_1)$ around the best-fit parameters $(\\theta_0^{\\ast}, \\theta_1^{\\ast})$ is described by the Hessian matrix of $J$.\n\nLet the parameter vector be $\\vec{\\theta} = \\begin{pmatrix} \\theta_0 \\\\ \\theta_1 \\end{pmatrix}$. The model is given by $y(x_i; \\vec{\\theta}) = \\theta_0 + \\theta_1 h(x_i)$.\nThe objective function is:\n$$ J(\\vec{\\theta}) = \\frac{1}{2\\sigma^2}\\sum_{i=1}^{3}\\left(y_i - y(x_i;\\vec{\\theta})\\right)^2 $$\nThe Hessian matrix $\\mathbf{H}$ has elements $H_{jk} = \\frac{\\partial^2 J}{\\partial \\theta_j \\partial \\theta_k}$. For a model that is linear in its parameters, the Hessian simplifies to the Fisher Information Matrix (up to a scaling factor), which is constant and independent of the measured data $y_i$:\n$$ H_{jk} = \\frac{1}{\\sigma^2} \\sum_{i=1}^{3} \\frac{\\partial y(x_i;\\vec{\\theta})}{\\partial \\theta_j} \\frac{\\partial y(x_i;\\vec{\\theta})}{\\partial \\theta_k} $$\nThis can be written as $\\mathbf{H} = \\frac{1}{\\sigma^2} \\mathbf{S}^T \\mathbf{S}$, where $\\mathbf{S}$ is the sensitivity matrix with elements $S_{ij} = \\frac{\\partial y(x_i)}{\\partial \\theta_j}$.\n\nFirst, we calculate the partial derivatives of the model function with respect to the parameters:\n$$ \\frac{\\partial y}{\\partial \\theta_0} = 1 $$\n$$ \\frac{\\partial y}{\\partial \\theta_1} = h(x) = \\frac{x}{K+x} $$\nNext, we evaluate the function $h(x)$ for the three given concentrations $x_1=1$, $x_2=10$, $x_3=100$, with $K=10$:\n$$ h(x_1) = h(1) = \\frac{1}{10+1} = \\frac{1}{11} $$\n$$ h(x_2) = h(10) = \\frac{10}{10+10} = \\frac{10}{20} = \\frac{1}{2} $$\n$$ h(x_3) = h(100) = \\frac{100}{10+100} = \\frac{100}{110} = \\frac{10}{11} $$\nThe sensitivity matrix $\\mathbf{S}$ for the data points $(x_1, x_2, x_3)$ is a $3 \\times 2$ matrix:\n$$ \\mathbf{S} = \\begin{pmatrix} \\frac{\\partial y(x_1)}{\\partial \\theta_0}  \\frac{\\partial y(x_1)}{\\partial \\theta_1} \\\\ \\frac{\\partial y(x_2)}{\\partial \\theta_0}  \\frac{\\partial y(x_2)}{\\partial \\theta_1} \\\\ \\frac{\\partial y(x_3)}{\\partial \\theta_0}  \\frac{\\partial y(x_3)}{\\partial \\theta_1} \\end{pmatrix} = \\begin{pmatrix} 1  \\frac{1}{11} \\\\ 1  \\frac{1}{2} \\\\ 1  \\frac{10}{11} \\end{pmatrix} $$\nNow we can compute the matrix $\\mathbf{S}^T \\mathbf{S}$:\n$$ \\mathbf{S}^T \\mathbf{S} = \\begin{pmatrix} 1  1  1 \\\\ \\frac{1}{11}  \\frac{1}{2}  \\frac{10}{11} \\end{pmatrix} \\begin{pmatrix} 1  \\frac{1}{11} \\\\ 1  \\frac{1}{2} \\\\ 1  \\frac{10}{11} \\end{pmatrix} $$\nThe elements of the resulting $2 \\times 2$ matrix are:\n$$ (\\mathbf{S}^T \\mathbf{S})_{11} = 1 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 1 = 3 $$\n$$ (\\mathbf{S}^T \\mathbf{S})_{12} = (\\mathbf{S}^T \\mathbf{S})_{21} = 1 \\cdot \\frac{1}{11} + 1 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{10}{11} = \\frac{1+10}{11} + \\frac{1}{2} = 1 + \\frac{1}{2} = \\frac{3}{2} $$\n$$ (\\mathbf{S}^T \\mathbf{S})_{22} = \\left(\\frac{1}{11}\\right)^2 + \\left(\\frac{1}{2}\\right)^2 + \\left(\\frac{10}{11}\\right)^2 = \\frac{1}{121} + \\frac{1}{4} + \\frac{100}{121} = \\frac{101}{121} + \\frac{1}{4} = \\frac{404 + 121}{484} = \\frac{525}{484} $$\nGiven $\\sigma = 1$, the Hessian matrix is $\\mathbf{H} = \\frac{1}{1^2} \\mathbf{S}^T \\mathbf{S} = \\mathbf{S}^T \\mathbf{S}$:\n$$ \\mathbf{H} = \\begin{pmatrix} 3  \\frac{3}{2} \\\\ \\frac{3}{2}  \\frac{525}{484} \\end{pmatrix} $$\nThis is the required $2 \\times 2$ symmetric matrix. To find its eigenvalues $\\lambda$, we solve the characteristic equation $\\det(\\mathbf{H} - \\lambda\\mathbf{I}) = 0$.\nThe eigenvalues $\\lambda_{1,2}$ for a general $2 \\times 2$ symmetric matrix $\\begin{pmatrix} a  b \\\\ b  d \\end{pmatrix}$ are given by $\\lambda = \\frac{(a+d) \\pm \\sqrt{(a-d)^2 + 4b^2}}{2}$.\nHere, $a=3$, $b=3/2$, and $d=525/484$.\nThe trace is $\\text{Tr}(\\mathbf{H}) = a+d = 3 + \\frac{525}{484} = \\frac{1452+525}{484} = \\frac{1977}{484}$.\nThe term under the square root is:\n$$ (a-d)^2 + 4b^2 = \\left(3 - \\frac{525}{484}\\right)^2 + 4\\left(\\frac{3}{2}\\right)^2 = \\left(\\frac{1452 - 525}{484}\\right)^2 + 9 = \\left(\\frac{927}{484}\\right)^2 + 9 = \\frac{859329}{234256} + \\frac{2108304}{234256} = \\frac{2967633}{234256} $$\nThe eigenvalues are:\n$$ \\lambda_{1,2} = \\frac{\\frac{1977}{484} \\pm \\sqrt{\\frac{2967633}{234256}}}{2} = \\frac{\\frac{1977}{484} \\pm \\frac{\\sqrt{2967633}}{484}}{2} = \\frac{1977 \\pm \\sqrt{2967633}}{968} $$\nThe largest eigenvalue is $\\lambda_{\\text{max}} = \\frac{1977 + \\sqrt{2967633}}{968}$ and the smallest is $\\lambda_{\\text{min}} = \\frac{1977 - \\sqrt{2967633}}{968}$.\nThe ratio of the largest to the smallest eigenvalue is:\n$$ R = \\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}} = \\frac{1977 + \\sqrt{2967633}}{1977 - \\sqrt{2967633}} $$\nNumerically:\n$$ \\sqrt{2967633} \\approx 1722.682033 $$\n$$ R \\approx \\frac{1977 + 1722.682033}{1977 - 1722.682033} = \\frac{3699.682033}{254.317967} \\approx 14.5473708 $$\nRounding the result to four significant figures gives $14.55$.",
            "answer": "$$\\boxed{14.55}$$"
        }
    ]
}