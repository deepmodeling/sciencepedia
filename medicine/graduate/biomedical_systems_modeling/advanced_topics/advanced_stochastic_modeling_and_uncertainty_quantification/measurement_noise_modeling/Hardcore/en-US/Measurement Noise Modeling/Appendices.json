{
    "hands_on_practices": [
        {
            "introduction": "The conversion of continuous physiological signals into a digital format is a fundamental step in modern biomedical instrumentation. This process, performed by an Analog-to-Digital Converter (ADC), inevitably introduces an error known as quantization noise. This exercise guides you through a first-principles derivation of the power of this noise, a critical parameter for determining the ultimate precision of any digital measurement system .",
            "id": "3900253",
            "problem": "A biomedical monitoring system uses an Analog-to-Digital Converter (ADC) to digitize a band-limited arterial pressure waveform. The ADC can be modeled as a uniform mid-tread quantizer with step size $\\Delta$, mapping any real input $x$ to $Q(x)$ defined by $Q(x) = \\Delta \\cdot \\mathrm{round}(x/\\Delta)$. Let the quantization error be $e = Q(x) - x$. Assume the following well-tested conditions for quantization noise modeling: (i) the input is such that $e$ is statistically independent of $x$, and (ii) $e$ is equally likely to take any value within a quantization cell, that is, $e$ has a uniform distribution on $[-\\Delta/2, \\Delta/2]$.\n\n1. Using only the definition of variance and the assumed uniform distribution of $e$, derive the quantization noise variance $\\sigma_q^2$.\n\n2. The input waveform to the ADC during a calibration stage is a sinusoid $x[n] = A \\sin(2\\pi f n T_s)$, where $A$ is the amplitude, $f$ the frequency, and $T_s$ the sampling period, with $A$ small enough to avoid clipping and $f T_s$ such that the sampled phases are ergodic over $[0, 2\\pi)$. Under the independence assumption stated above, compute the Signal-to-Noise Ratio (SNR), defined as the ratio of the mean signal power to the quantization noise variance, $ \\mathrm{SNR} = P_x / \\sigma_q^2$, where $P_x$ is the time-averaged power of $x[n]$. Express the SNR as a closed-form, dimensionless ratio in terms of $A$ and $\\Delta$.\n\nProvide a single final answer that includes both the quantization noise variance and the SNR as a row matrix. No numerical values are required.",
            "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a complete derivation. We will proceed in two parts as requested.\n\nPart 1: Derivation of the quantization noise variance $\\sigma_q^2$.\n\nThe quantization error is given as a random variable $e$ with a uniform probability distribution over the interval $[-\\frac{\\Delta}{2}, \\frac{\\Delta}{2}]$. The probability density function (PDF) of $e$, denoted by $p(e)$, is therefore:\n$$\np(e) =\n\\begin{cases}\n\\frac{1}{\\Delta}  \\text{for } -\\frac{\\Delta}{2} \\le e \\le \\frac{\\Delta}{2} \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThe variance of a random variable $e$, denoted $\\sigma_q^2$, is defined as $\\sigma_q^2 = \\mathrm{E}[(e - \\mu_e)^2]$, where $\\mu_e = \\mathrm{E}[e]$ is the mean of $e$.\n\nFirst, we compute the mean value $\\mu_e$:\n$$\n\\mu_e = \\mathrm{E}[e] = \\int_{-\\infty}^{\\infty} e \\cdot p(e) \\, de\n$$\nSubstituting the PDF $p(e)$:\n$$\n\\mu_e = \\int_{-\\frac{\\Delta}{2}}^{\\frac{\\Delta}{2}} e \\cdot \\frac{1}{\\Delta} \\, de = \\frac{1}{\\Delta} \\left[ \\frac{e^2}{2} \\right]_{-\\frac{\\Delta}{2}}^{\\frac{\\Delta}{2}}\n$$\n$$\n\\mu_e = \\frac{1}{2\\Delta} \\left( \\left(\\frac{\\Delta}{2}\\right)^2 - \\left(-\\frac{\\Delta}{2}\\right)^2 \\right) = \\frac{1}{2\\Delta} \\left( \\frac{\\Delta^2}{4} - \\frac{\\Delta^2}{4} \\right) = 0\n$$\nSince the mean of the quantization error is $0$, the variance simplifies to the mean of the squared error, $\\sigma_q^2 = \\mathrm{E}[e^2]$.\n$$\n\\sigma_q^2 = \\mathrm{E}[e^2] = \\int_{-\\infty}^{\\infty} e^2 \\cdot p(e) \\, de\n$$\n$$\n\\sigma_q^2 = \\int_{-\\frac{\\Delta}{2}}^{\\frac{\\Delta}{2}} e^2 \\cdot \\frac{1}{\\Delta} \\, de = \\frac{1}{\\Delta} \\left[ \\frac{e^3}{3} \\right]_{-\\frac{\\Delta}{2}}^{\\frac{\\Delta}{2}}\n$$\n$$\n\\sigma_q^2 = \\frac{1}{3\\Delta} \\left( \\left(\\frac{\\Delta}{2}\\right)^3 - \\left(-\\frac{\\Delta}{2}\\right)^3 \\right) = \\frac{1}{3\\Delta} \\left( \\frac{\\Delta^3}{8} - \\left(-\\frac{\\Delta^3}{8}\\right) \\right)\n$$\n$$\n\\sigma_q^2 = \\frac{1}{3\\Delta} \\left( \\frac{\\Delta^3}{8} + \\frac{\\Delta^3}{8} \\right) = \\frac{1}{3\\Delta} \\left( 2 \\frac{\\Delta^3}{8} \\right) = \\frac{1}{3\\Delta} \\left( \\frac{\\Delta^3}{4} \\right)\n$$\n$$\n\\sigma_q^2 = \\frac{\\Delta^2}{12}\n$$\nThis is the quantization noise variance.\n\nPart 2: Calculation of the Signal-to-Noise Ratio (SNR).\n\nThe SNR is defined as $\\mathrm{SNR} = \\frac{P_x}{\\sigma_q^2}$, where $P_x$ is the mean power of the input signal $x[n]$ and $\\sigma_q^2$ is the quantization noise variance derived above.\n\nThe input signal is $x[n] = A \\sin(2\\pi f n T_s)$. The mean signal power $P_x$ is the time-averaged power of $x[n]$. For a sinusoidal signal, or more generally an ergodic signal, this can be calculated as the expectation of the squared signal value. The problem states that the sampled phases are ergodic over $[0, 2\\pi)$, which allows us to treat the phase $\\theta_n = 2\\pi f n T_s$ as a random variable $\\theta$ that is uniformly distributed over the interval $[0, 2\\pi)$.\n$$\nP_x = \\mathrm{E}[x^2] = \\mathrm{E}[(A \\sin(\\theta))^2] = A^2 \\mathrm{E}[\\sin^2(\\theta)]\n$$\nThe expectation $\\mathrm{E}[\\sin^2(\\theta)]$ is calculated by integrating over the distribution of $\\theta$:\n$$\n\\mathrm{E}[\\sin^2(\\theta)] = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\sin^2(\\theta) \\, d\\theta\n$$\nUsing the trigonometric identity $\\sin^2(\\theta) = \\frac{1 - \\cos(2\\theta)}{2}$:\n$$\n\\mathrm{E}[\\sin^2(\\theta)] = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\left(\\frac{1 - \\cos(2\\theta)}{2}\\right) \\, d\\theta = \\frac{1}{4\\pi} \\left[ \\theta - \\frac{\\sin(2\\theta)}{2} \\right]_{0}^{2\\pi}\n$$\n$$\n\\mathrm{E}[\\sin^2(\\theta)] = \\frac{1}{4\\pi} \\left( (2\\pi - 0) - (0 - 0) \\right) = \\frac{2\\pi}{4\\pi} = \\frac{1}{2}\n$$\nThus, the mean signal power is:\n$$\nP_x = A^2 \\cdot \\frac{1}{2} = \\frac{A^2}{2}\n$$\nNow we can compute the SNR using the results for $P_x$ and $\\sigma_q^2$:\n$$\n\\mathrm{SNR} = \\frac{P_x}{\\sigma_q^2} = \\frac{A^2/2}{\\Delta^2/12} = \\frac{A^2}{2} \\cdot \\frac{12}{\\Delta^2} = \\frac{6A^2}{\\Delta^2}\n$$\nThis is the final expression for the Signal-to-Noise Ratio.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{\\Delta^2}{12}  \\frac{6A^2}{\\Delta^2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Beyond characterizing noise sources, a key skill is designing experiments that yield robust conclusions despite the presence of noise. This practice tackles a central question in experimental design: determining the necessary sample size to estimate a parameter with a desired level of confidence. By working through the calibration of a photoplethysmography device under a Gaussian noise model, you will connect core statistical concepts to practical decisions that ensure experimental efficiency and rigor .",
            "id": "3900231",
            "problem": "A biomedical laboratory is calibrating a wrist-worn photoplethysmography device to estimate an individual's resting heart rate, denoted by the parameter $\\theta$ (in beats per minute). During calibration under controlled conditions, the device produces independent repeated measurements $\\{y_{i}\\}_{i=1}^{n}$ modeled by the additive Gaussian noise model $y_{i} = \\theta + \\varepsilon_{i}$, where $\\varepsilon_{i} \\sim \\mathcal{N}(0,\\sigma^{2})$ and $\\sigma^{2}$ is known from prior benchtop characterization. Assume the underlying physiological state is stationary over the short calibration window so that $\\theta$ is constant. The device manufacturer reports $\\sigma^{2} = 9$ (so $\\sigma = 3$). The laboratory wants to construct a two-sided confidence interval (CI) for $\\theta$ with confidence level $1 - \\alpha$ where $\\alpha = 0.05$, using the sample mean $\\bar{y}_{n}$, and requires that the CI half-width be at most $w = 1.5$.\n\n- Using only fundamental definitions of Gaussian measurement noise and the sampling distribution of the sample mean, determine the smallest integer sample size $n$ that guarantees the CI half-width is at most $w$ at confidence level $1 - \\alpha$.\n\n- Separately, analyze robustness to variance misspecification as follows. Suppose the calibration is designed under an assumed variance $\\sigma_{0}^{2}$ but the true measurement variance is $\\sigma^{2}$. Define the variance misspecification factor $\\kappa = \\sigma^{2} / \\sigma_{0}^{2}$. Derive, in closed form, the multiplicative inflation factor $r(\\kappa)$, defined as the ratio of the achieved CI half-width to the target half-width when one uses the sample size computed under $\\sigma_{0}^{2}$.\n\nReport the smallest integer $n$, and report $r(\\kappa)$ as a closed-form analytical expression. Since $n$ is an exact integer, no rounding by significant figures is needed. The inflation factor $r(\\kappa)$ must be expressed exactly.",
            "solution": "The problem presents two distinct tasks: first, to calculate the minimum required sample size for a confidence interval of a specified width; and second, to derive an expression for the inflation of the confidence interval width due to misspecification of the measurement variance. We will address each part systematically.\n\n### Part 1: Minimum Sample Size Calculation\n\nThe model for the individual measurements is given by $y_{i} = \\theta + \\varepsilon_{i}$ for $i=1, 2, \\dots, n$. The measurement errors $\\varepsilon_{i}$ are independent and identically distributed (i.i.d.) random variables following a normal distribution with mean $0$ and known variance $\\sigma^{2}$, i.e., $\\varepsilon_{i} \\sim \\mathcal{N}(0, \\sigma^{2})$. The parameter of interest is the true resting heart rate, $\\theta$.\n\nThe estimator for $\\theta$ is the sample mean, $\\bar{y}_{n} = \\frac{1}{n} \\sum_{i=1}^{n} y_{i}$. Because the $y_{i}$ are i.i.d. normal random variables with mean $\\theta$ and variance $\\sigma^{2}$ (i.e., $y_{i} \\sim \\mathcal{N}(\\theta, \\sigma^{2})$), the sample mean $\\bar{y}_{n}$ follows a normal distribution. The expected value of the sample mean is $E[\\bar{y}_{n}] = \\theta$, and its variance is $\\text{Var}(\\bar{y}_{n}) = \\frac{\\sigma^{2}}{n}$. Thus, the sampling distribution of the estimator is $\\bar{y}_{n} \\sim \\mathcal{N}(\\theta, \\frac{\\sigma^{2}}{n})$.\n\nTo construct a confidence interval for $\\theta$, we form a pivotal quantity by standardizing the estimator $\\bar{y}_{n}$. The standardized variable $Z$ is:\n$$ Z = \\frac{\\bar{y}_{n} - \\theta}{\\sigma/\\sqrt{n}} $$\nThis quantity $Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$.\n\nA two-sided confidence interval (CI) with a confidence level of $1 - \\alpha$ is derived from the probability statement:\n$$ P(-z_{\\alpha/2} \\le Z \\le z_{\\alpha/2}) = 1 - \\alpha $$\nwhere $z_{\\alpha/2}$ is the upper critical value of the standard normal distribution, defined by $P(Z  z_{\\alpha/2}) = \\alpha/2$. Substituting the expression for $Z$:\n$$ P\\left(-z_{\\alpha/2} \\le \\frac{\\bar{y}_{n} - \\theta}{\\sigma/\\sqrt{n}} \\le z_{\\alpha/2}\\right) = 1 - \\alpha $$\nBy rearranging the inequalities to isolate $\\theta$, we obtain the limits for the confidence interval:\n$$ \\bar{y}_{n} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le \\theta \\le \\bar{y}_{n} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} $$\nThe CI is thus $[\\bar{y}_{n} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}, \\bar{y}_{n} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}]$. The half-width of this interval, denoted $H$, is the quantity added to and subtracted from the sample mean:\n$$ H = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} $$\nThe problem requires that this half-width be at most $w = 1.5$. We set up the inequality:\n$$ z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\le w $$\nSolving for the sample size $n$:\n$$ \\sqrt{n} \\ge \\frac{z_{\\alpha/2} \\sigma}{w} $$\n$$ n \\ge \\left(\\frac{z_{\\alpha/2} \\sigma}{w}\\right)^{2} $$\nWe are given the following values:\n- Variance $\\sigma^{2} = 9$, so the standard deviation is $\\sigma = \\sqrt{9} = 3$.\n- Confidence level is $1 - \\alpha = 1 - 0.05 = 0.95$, so $\\alpha = 0.05$ and $\\alpha/2 = 0.025$.\n- The critical value $z_{0.025}$ is the value for which the cumulative distribution function of the standard normal distribution is $1 - 0.025 = 0.975$. This value is $z_{0.025} \\approx 1.95996$. We will use the common approximation $z_{0.025} \\approx 1.96$.\n- The required maximum half-width is $w = 1.5$.\n\nSubstituting these values into the inequality for $n$:\n$$ n \\ge \\left(\\frac{1.96 \\times 3}{1.5}\\right)^{2} $$\n$$ n \\ge \\left(\\frac{5.88}{1.5}\\right)^{2} $$\n$$ n \\ge (3.92)^{2} $$\n$$ n \\ge 15.3664 $$\nSince the sample size $n$ must be an integer, we need to find the smallest integer that satisfies this condition. This is obtained by taking the ceiling of the result:\n$$ n = \\lceil 15.3664 \\rceil = 16 $$\nTherefore, the smallest integer sample size required is $16$.\n\n### Part 2: Robustness to Variance Misspecification\n\nIn this part, we analyze the scenario where the sample size is chosen based on an assumed variance $\\sigma_{0}^{2}$, but the true variance is $\\sigma^{2}$. The target half-width for the CI is $w$.\n\nThe sample size, let's call it $n_{0}$, is determined using the assumed variance $\\sigma_{0}^{2}$. The design equation, which ensures the target half-width $w$ is achieved if the assumed variance is correct, is:\n$$ w = z_{\\alpha/2} \\frac{\\sigma_{0}}{\\sqrt{n_{0}}} $$\nThis equation defines the relationship between the design parameters. For the subsequent analysis, we can express $\\sqrt{n_{0}}$ in terms of the other parameters: $\\sqrt{n_{0}} = \\frac{z_{\\alpha/2} \\sigma_{0}}{w}$.\n\nThe experiment is then conducted with this sample size $n_{0}$. However, the data are generated from a process with the true variance $\\sigma^{2}$. Consequently, the true standard deviation of the sample mean $\\bar{y}_{n_{0}}$ is $\\sigma/\\sqrt{n_{0}}$.\n\nThe half-width of the confidence interval that is actually achieved, which we denote as $H_{\\text{achieved}}$, will be based on this true standard deviation:\n$$ H_{\\text{achieved}} = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n_{0}}} $$\nThe inflation factor, $r(\\kappa)$, is defined as the ratio of the achieved half-width to the target half-width $w$:\n$$ r(\\kappa) = \\frac{H_{\\text{achieved}}}{w} $$\nSubstituting the expressions for $H_{\\text{achieved}}$ and $w$ (from the design equation):\n$$ r(\\kappa) = \\frac{z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n_{0}}}}{z_{\\alpha/2} \\frac{\\sigma_{0}}{\\sqrt{n_{0}}}} $$\nThe terms $z_{\\alpha/2}$ and $\\sqrt{n_{0}}$ cancel out, leaving:\n$$ r(\\kappa) = \\frac{\\sigma}{\\sigma_{0}} $$\nThe problem defines the variance misspecification factor as $\\kappa = \\frac{\\sigma^{2}}{\\sigma_{0}^{2}}$. To express $r(\\kappa)$ as a function of $\\kappa$, we take the square root of $\\kappa$:\n$$ \\sqrt{\\kappa} = \\sqrt{\\frac{\\sigma^{2}}{\\sigma_{0}^{2}}} = \\frac{|\\sigma|}{|\\sigma_{0}|} $$\nSince standard deviations are non-negative, $\\sigma \\ge 0$ and $\\sigma_{0} \\ge 0$, this simplifies to:\n$$ \\sqrt{\\kappa} = \\frac{\\sigma}{\\sigma_{0}} $$\nTherefore, the multiplicative inflation factor $r(\\kappa)$ is given by the closed-form expression:\n$$ r(\\kappa) = \\sqrt{\\kappa} $$\nThis result shows that the CI half-width is inflated by a factor equal to the square root of the ratio of the true variance to the assumed variance.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 16  \\sqrt{\\kappa} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Many noise processes in biomedical sensors, particularly in inertial measurement units (IMUs), are not simple independent random fluctuations but exhibit temporal correlations. This computational exercise introduces the Allan variance, a powerful and widely used technique for identifying and quantifying different types of correlated noise from time-series data. By synthesizing signals and implementing the Allan variance analysis, you will gain hands-on experience in characterizing the complex noise signatures of dynamic sensors like gyroscopes, a crucial step in developing reliable motion tracking systems .",
            "id": "3900256",
            "problem": "Consider a discrete-time angular rate measurement sequence from a gyroscope used in motion tracking for biomedical devices. The sequence is $x_0, x_1, \\dots, x_{N-1}$, sampled at constant interval $T_0 = 1/f_s$ seconds, with $x_k$ in radians per second ($\\mathrm{rad/s}$). The Allan variance at averaging time $ \\tau = m T_0 $ for integer $m \\ge 1$ is defined over the overlapped cluster averages, where the cluster average is $ \\bar{x}_k^{(m)} = \\frac{1}{m} \\sum_{i=k}^{k+m-1} x_i $ for $k \\in \\{0,1,\\dots,N-m\\}$. The Allan variance is $$\\sigma^2(\\tau) = \\frac{1}{2} \\left\\langle \\left( \\bar{x}_{k+1}^{(m)} - \\bar{x}_k^{(m)} \\right)^2 \\right\\rangle,$$ where $\\langle \\cdot \\rangle$ denotes the average over all valid indices $k$ yielding overlapping cluster pairs. The Allan deviation is $ \\sigma(\\tau) = \\sqrt{\\sigma^2(\\tau)} $.\n\nNoise mechanisms in gyroscope measurements can often be classified by the scaling behavior of $ \\sigma(\\tau) $ on a log-log plot, which reflects underlying spectral properties. The objective is to implement the computation of the Allan deviation from $x_k$ for a logarithmically spaced set of averaging times $\\tau$, and then classify the dominant noise mechanism using a single characteristic slope computed over an interior span of $\\tau$ where a single mechanism is expected to dominate.\n\nFundamental base: Use the core definition of overlapped Allan variance as provided, the definition of cluster averages, and the relationship of slope on a log-log scale to scaling behavior. Do not assume any shortcut formulas beyond these core definitions.\n\nYour program must:\n- Synthesize test sequences $x_k$ under specified parameter sets.\n- Compute $ \\sigma(\\tau) $ over a set of averaging times $ \\tau $ equally spaced on a logarithmic scale (choose at least $15$ distinct $m$ values covering from $m=1$ up to $m = \\lfloor N/4 \\rfloor$).\n- Estimate a single representative slope $s$ of $ \\log_{10} \\sigma(\\tau) $ versus $ \\log_{10} \\tau $ over the middle span of the $\\tau$ grid (exclude at least the smallest and largest $20\\%$ of $\\tau$ values to avoid boundary effects).\n- Classify the dominant mechanism according to the following integer code mapping, using the slope $s$:\n    - Code $0$: White noise in angular rate (angle random walk) characterized by $s \\approx -\\tfrac{1}{2}$.\n    - Code $1$: Bias instability (flicker, $1/f$) characterized by $s \\approx 0$.\n    - Code $2$: Rate random walk ($1/f^2$) characterized by $s \\approx +\\tfrac{1}{2}$.\n    - Code $3$: Quantization noise characterized by $s \\approx -1$.\n    - Code $4$: Other or indeterminate behavior (use this code if $s$ does not fall near the listed canonical slopes).\n- The classification decision must be made by thresholding $s$ with reasonable margins so that small numerical deviations do not change the categorical decision. Implement fixed thresholds that partition the slope axis into the categories above.\n\nScientific realism and units:\n- All angular rate values must be in $\\mathrm{rad/s}$, averaging times $\\tau$ in seconds, and sampling frequency $f_s$ in hertz ($\\mathrm{Hz}$).\n- Express any internally computed coefficients in $\\mathrm{rad/s}$ or derived units consistent with $x_k$.\n- The output does not include units, but internal computations must respect units.\n\nTest suite and parameter values to synthesize $x_k$:\nGenerate four independent test cases with the following parameters, each yielding $N$ samples at sampling frequency $f_s$. Construct $x_k$ by summing the specified noise components as described below. Use a fixed random seed for reproducibility in each case.\n\n- Case $1$ (white noise dominated):\n    - $N = 8192$, $f_s = 100\\,\\mathrm{Hz}$.\n    - White noise standard deviation $\\sigma_w = 3.0 \\times 10^{-3}\\,\\mathrm{rad/s}$.\n    - No other components present.\n\n- Case $2$ (bias instability dominated via approximate pink noise):\n    - $N = 8192$, $f_s = 100\\,\\mathrm{Hz}$.\n    - White noise standard deviation $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$.\n    - Add a zero-mean approximate pink noise component (one-sided amplitude shaped proportional to $1/\\sqrt{f}$ in the frequency domain with zero direct current component), scaled to have root-mean-square equal to $5.0 \\times 10^{-3}\\,\\mathrm{rad/s}$.\n\n- Case $3$ (rate random walk dominated via integrated white process):\n    - $N = 8192$, $f_s = 100\\,\\mathrm{Hz}$.\n    - White noise standard deviation $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$.\n    - Add a rate random walk component defined by $b_k = \\sum_{i=0}^{k} w_i$, where $w_i$ are independent normal samples with standard deviation $\\sigma_{\\mathrm{rw}} = 1.0 \\times 10^{-5}\\,\\mathrm{rad/s}$ per sample; the rate random walk component is $b_k$ (units $\\mathrm{rad/s}$).\n\n- Case $4$ (quantization dominated):\n    - $N = 8192$, $f_s = 100\\,\\mathrm{Hz}$.\n    - White noise standard deviation $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$.\n    - Quantize the resulting signal to a step size $q = 5.0 \\times 10^{-3}\\,\\mathrm{rad/s}$ using nearest-step rounding, i.e., $x_k \\leftarrow q \\cdot \\mathrm{round}(x_k / q)$.\n\nSynthesis details:\n- The white noise component is $w_k \\sim \\mathcal{N}(0, \\sigma_w^2)$ independent and added directly to $x_k$.\n- The pink noise component must be synthesized by shaping a complex Gaussian spectrum with amplitude proportional to $1/\\sqrt{f}$ for positive frequencies, setting the zero-frequency component to $0$, and using the inverse discrete Fourier transform to obtain a real-valued time series; scale the resulting series to the specified root-mean-square. Ensure it is zero-mean.\n- The rate random walk component is formed by cumulative summation of its increment process $w_i$; add this to $x_k$.\n\nComputational outputs:\n- For each test case, compute the Allan deviation $ \\sigma(\\tau) $ at the chosen set of $ \\tau $ values, estimate the slope $s$ on the interior span, and classify using the integer code mapping above.\n- The final program output must be a single line containing the four classification codes, in order for cases $1$ to $4$, as a comma-separated list enclosed in square brackets (e.g., $[c_1,c_2,c_3,c_4]$). The output must contain integers only.\n\nAngle unit specification: Angles and angular rates are in radians; averaging times $\\tau$ are in seconds. No angle unit conversion is required.\n\nNumerical specification:\n- Use a minimum of $15$ distinct averaging times and at most $ \\lfloor N/4 \\rfloor $ for the maximum $m$.\n- The interior span for slope estimation must exclude at least the smallest and largest $20\\%$ of $\\tau$ values.\n- The slope estimation must use ordinary least squares on $ (\\log_{10} \\tau, \\log_{10} \\sigma(\\tau)) $ pairs.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[c_1,c_2,c_3,c_4]$).",
            "solution": "The solution to this problem involves synthesizing four distinct time series, each representative of a dominant noise process found in gyroscopic sensors, and then classifying these processes based on the slope of their Allan deviation plots. The methodology is structured into three main stages: signal synthesis, Allan deviation computation, and slope-based classification.\n\n### 1. Signal Synthesis\n\nFor each of the four test cases, a discrete-time signal $x_k$ of length $N=8192$ is generated at a sampling frequency $f_s=100\\,\\mathrm{Hz}$ (sampling period $T_0 = 1/f_s = 0.01\\,\\mathrm{s}$). A unique random seed is used for each case to ensure reproducibility.\n\n- **Case 1 (White Noise):** The signal is composed solely of a zero-mean Gaussian white noise process, $x_k = w_k$, where $w_k \\sim \\mathcal{N}(0, \\sigma_w^2)$ with standard deviation $\\sigma_w = 3.0 \\times 10^{-3}\\,\\mathrm{rad/s}$.\n\n- **Case 2 (Bias Instability):** The signal is a sum of a low-level white noise component ($w_k$ with $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$) and a dominant pink noise (flicker noise) component, $p_k$. The pink noise is synthesized in the frequency domain. A complex Gaussian white noise spectrum is generated and then shaped by an amplitude filter proportional to $1/\\sqrt{f}$ for frequency $f > 0$. The DC component ($f=0$) is set to zero. An inverse Fast Fourier Transform (iFFT) yields the time-domain signal $p_k$, which is then scaled to have a root-mean-square (RMS) value of $5.0 \\times 10^{-3}\\,\\mathrm{rad/s}$ and made zero-mean. The final signal is $x_k = w_k + p_k$.\n\n- **Case 3 (Rate Random Walk):** The signal is a sum of a low-level white noise component ($w_k$ with $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$) and a rate random walk component, $b_k$. The rate random walk is generated by the cumulative summation of a discrete-time white noise process, $b_k = \\sum_{i=0}^{k} w'_i$, where the increments $w'_i$ are drawn from $\\mathcal{N}(0, \\sigma_{\\mathrm{rw}}^2)$ with $\\sigma_{\\mathrm{rw}} = 1.0 \\times 10^{-5}\\,\\mathrm{rad/s}$. The final signal is $x_k = w_k + b_k$.\n\n- **Case 4 (Quantization Noise):** A white noise signal is first generated with $\\sigma_w = 3.0 \\times 10^{-4}\\,\\mathrm{rad/s}$. This signal is then quantized using a nearest-step rounding function with a quantization step size of $q = 5.0 \\times 10^{-3}\\,\\mathrm{rad/s}$. The operation is $x_k \\leftarrow q \\cdot \\mathrm{round}(x_k / q)$.\n\n### 2. Allan Deviation Calculation\n\nThe Allan deviation, $\\sigma(\\tau)$, is computed for a set of averaging times $\\tau$. The averaging times are chosen by selecting a logarithmically spaced set of cluster sizes $m$. A set of approximately $30$ values for $m$ is generated, ranging from $m=1$ to $m_{max} = \\lfloor N/4 \\rfloor = 2048$, which are then rounded to the nearest integer and made unique. This typically results in over $15$ distinct values for $m$. The corresponding averaging times are $\\tau = m T_0$.\n\nFor each value of $m$, the Allan variance $\\sigma^2(\\tau)$ is calculated according to its definition:\n$$ \\sigma^2(\\tau) = \\frac{1}{2} \\left\\langle \\left( \\bar{x}_{k+1}^{(m)} - \\bar{x}_k^{(m)} \\right)^2 \\right\\rangle $$\nwhere $\\bar{x}_k^{(m)}$ is the average of $m$ consecutive samples starting at index $k$:\n$$ \\bar{x}_k^{(m)} = \\frac{1}{m} \\sum_{i=k}^{k+m-1} x_i $$\nThe operator $\\langle \\cdot \\rangle$ denotes an average over the $N-m$ available pairs of adjacent cluster averages (for $k$ from $0$ to $N-m-1$). The variance is thus computed as:\n$$ \\sigma^2(\\tau) = \\frac{1}{2(N-m)} \\sum_{k=0}^{N-m-1} \\left( \\bar{x}_{k+1}^{(m)} - \\bar{x}_k^{(m)} \\right)^2 $$\nComputationally, the cluster averages $\\bar{x}_k^{(m)}$ are efficiently calculated using a 1D convolution of the signal $x_k$ with a normalized window of length $m$. The Allan deviation is then $\\sigma(\\tau) = \\sqrt{\\sigma^2(\\tau)}$.\n\n### 3. Slope Estimation and Classification\n\nThe dominant noise type is identified by the slope of the Allan deviation curve on a log-log plot. A single representative slope, $s$, is estimated by performing an ordinary least-squares linear regression on the pairs $(\\log_{10} \\tau, \\log_{10} \\sigma(\\tau))$. To avoid boundary effects from finite data length (at large $\\tau$) and other noise types (at small $\\tau$), the fit is performed over an interior span of the data. Specifically, the smallest $25\\%$ and largest $25\\%$ of the $(\\tau, \\sigma(\\tau))$ pairs are excluded from the regression.\n\nThe estimated slope $s$ is then used to classify the noise process using the following fixed thresholds, which are set at the midpoints between the canonical slopes:\n- **Code 3 (Quantization):** $s  -0.75$, for a theoretical slope of $-1$.\n- **Code 0 (White Noise / Angle Random Walk):** $-0.75 \\le s  -0.25$, for a theoretical slope of $-0.5$.\n- **Code 1 (Bias Instability / Flicker Noise):** $-0.25 \\le s  +0.25$, for a theoretical slope of $0$.\n- **Code 2 (Rate Random Walk):** $+0.25 \\le s \\le +0.75$, for a theoretical slope of $+0.5$.\n- **Code 4 (Other/Indeterminate):** If $s$ falls outside the above ranges.\n\nThis procedure is applied to each of the four synthesized signals, yielding a classification code for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_white_noise(N, sigma_w, rng):\n    \"\"\"Generates a white noise sequence.\"\"\"\n    return rng.normal(scale=sigma_w, size=N)\n\ndef generate_pink_noise(N, fs, rms_value, rng):\n    \"\"\"Generates an approximate pink noise sequence using FFT.\"\"\"\n    n_freqs = N // 2 + 1\n    freqs = np.fft.rfftfreq(N, d=1.0 / fs)\n\n    # Generate complex Gaussian noise spectrum\n    spec = rng.standard_normal(n_freqs) + 1j * rng.standard_normal(n_freqs)\n    \n    # Shape the spectrum amplitude by 1/sqrt(f)\n    pink_filter = np.ones_like(freqs)\n    if len(freqs) > 1:\n        pink_filter[1:] = 1.0 / np.sqrt(freqs[1:])\n    pink_filter[0] = 0  # No DC component\n\n    spec *= pink_filter\n    \n    # Ensure properties for real signal are met\n    if N % 2 == 0:\n        spec[-1] = np.real(spec[-1])\n\n    # Inverse FFT to get time domain signal\n    signal = np.fft.irfft(spec, n=N)\n\n    # Scale to desired RMS\n    current_rms = np.sqrt(np.mean(signal**2))\n    if current_rms > 1e-9:\n        signal *= (rms_value / current_rms)\n\n    # Remove any residual mean\n    signal -= np.mean(signal)\n    \n    return signal\n\ndef generate_rate_random_walk(N, sigma_rw, rng):\n    \"\"\"Generates a rate random walk sequence.\"\"\"\n    increments = rng.normal(scale=sigma_rw, size=N)\n    return np.cumsum(increments)\n\ndef apply_quantization(signal, q):\n    \"\"\"Applies quantization to a signal.\"\"\"\n    return q * np.round(signal / q)\n\ndef compute_allan_deviation(x, fs, m_values):\n    \"\"\"Computes the overlapped Allan deviation.\"\"\"\n    N = len(x)\n    T0 = 1.0 / fs\n    tau_values = []\n    adev_values = []\n\n    for m in m_values:\n        if m >= N:\n            continue\n        \n        # Efficiently compute cluster averages using convolution\n        cluster_avg = np.convolve(x, np.ones(m) / m, mode='valid')\n        \n        if len(cluster_avg)  2:\n            continue\n            \n        # Compute differences of adjacent cluster averages\n        diffs = cluster_avg[1:] - cluster_avg[:-1]\n        \n        # Compute Allan variance\n        avar = 0.5 * np.mean(diffs**2)\n        \n        # Compute Allan deviation\n        adev = np.sqrt(avar)\n        \n        tau_values.append(m * T0)\n        adev_values.append(adev)\n\n    return np.array(tau_values), np.array(adev_values)\n\ndef get_classification(slope):\n    \"\"\"Classifies the noise type based on the log-log slope.\"\"\"\n    if slope  -0.75:\n        return 3  # Quantization\n    elif slope  -0.25:\n        return 0  # White noise\n    elif slope  0.25:\n        return 1  # Bias instability\n    elif slope = 0.75:\n        return 2  # Rate random walk\n    else:\n        return 4  # Other/Indeterminate\n\ndef process_case(params):\n    \"\"\"Processes a single test case from synthesis to classification.\"\"\"\n    N = params['N']\n    fs = params['fs']\n    rng = np.random.default_rng(params['seed'])\n    \n    # Signal Synthesis\n    x = np.zeros(N, dtype=np.float64)\n    if params['type'] == 'white':\n        x = generate_white_noise(N, params['sigma_w'], rng)\n    elif params['type'] == 'pink':\n        x = generate_white_noise(N, params['sigma_w'], rng)\n        x += generate_pink_noise(N, fs, params['pink_rms'], rng)\n    elif params['type'] == 'rrw':\n        x = generate_white_noise(N, params['sigma_w'], rng)\n        x += generate_rate_random_walk(N, params['sigma_rw'], rng)\n    elif params['type'] == 'quant':\n        signal_unquantized = generate_white_noise(N, params['sigma_w'], rng)\n        x = apply_quantization(signal_unquantized, params['q'])\n\n    # Allan Deviation Calculation\n    m_max = N // 4\n    # Generate a log-spaced set of m values, ensuring at least 15 unique values.\n    m_values = np.unique(np.round(np.logspace(np.log10(1), np.log10(m_max), num=30))).astype(int)\n    \n    tau_values, adev_values = compute_allan_deviation(x, fs, m_values)\n    \n    # Filter out zero or negative adev values for log plot\n    valid_indices = adev_values > 0\n    tau_values = tau_values[valid_indices]\n    adev_values = adev_values[valid_indices]\n\n    if len(tau_values)  5: # Not enough points for a reliable fit\n        return 4\n\n    # Slope Estimation\n    log_tau = np.log10(tau_values)\n    log_adev = np.log10(adev_values)\n    \n    # Fit over the middle span (excluding first and last 25%)\n    n_points = len(log_tau)\n    # The problem asks to exclude at least 20%, we'll use 25% for a more stable interior.\n    start_index = int(np.ceil(0.25 * n_points))\n    end_index = int(np.floor(0.75 * n_points))\n    \n    if end_index = start_index + 1: # Not enough points in the middle span\n        return 4\n\n    fit_log_tau = log_tau[start_index:end_index]\n    fit_log_adev = log_adev[start_index:end_index]\n    \n    slope, _ = np.polyfit(fit_log_tau, fit_log_adev, 1)\n\n    # Classification\n    return get_classification(slope)\n\ndef solve():\n    \"\"\"Main solver function to run all test cases.\"\"\"\n    test_cases = [\n        # Case 1: White noise dominated\n        {'type': 'white', 'N': 8192, 'fs': 100, 'sigma_w': 3.0e-3, 'seed': 0},\n        # Case 2: Bias instability dominated\n        {'type': 'pink', 'N': 8192, 'fs': 100, 'sigma_w': 3.0e-4, 'pink_rms': 5.0e-3, 'seed': 1},\n        # Case 3: Rate random walk dominated\n        {'type': 'rrw', 'N': 8192, 'fs': 100, 'sigma_w': 3.0e-4, 'sigma_rw': 1.0e-5, 'seed': 2},\n        # Case 4: Quantization dominated\n        {'type': 'quant', 'N': 8192, 'fs': 100, 'sigma_w': 3.0e-4, 'q': 5.0e-3, 'seed': 3}\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result_code = process_case(case_params)\n        results.append(result_code)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}