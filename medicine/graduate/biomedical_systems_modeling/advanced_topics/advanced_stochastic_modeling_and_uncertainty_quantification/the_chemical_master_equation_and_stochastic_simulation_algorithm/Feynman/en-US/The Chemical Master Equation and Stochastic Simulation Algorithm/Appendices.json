{
    "hands_on_practices": [
        {
            "introduction": "The first step in building a stochastic model is to translate fundamental chemical reactions into a mathematical form that the Stochastic Simulation Algorithm can use. This foundational exercise guides you through deriving the two key components for a reaction channel: its propensity function, which determines its \"hazard\" or probability of firing, and its stoichiometric update vector, which describes how the system state changes when it does fire. By working from the first principles of molecular counting for a simple bimolecular reaction, you will solidify your understanding of how mass-action kinetics are represented at the single-molecule level .",
            "id": "5278829",
            "problem": "In the immunological synapse between a T cell and an antigen-presenting cell, consider a single reaction channel in a well-mixed microdomain: a T cell receptor binding a peptide–Major Histocompatibility Complex ligand, modeled as the reversible formation of a receptor–ligand complex. Focus on the forward binding reaction $R + L \\to RL$. Let the discrete molecular counts at time $t$ be $x_R(t)$ for unbound receptor $R$, $x_L(t)$ for free ligand $L$, and $x_{RL}(t)$ for the bound complex $RL$. Assume a constant microdomain volume and that the binding events are memoryless, consistent with the Chemical Master Equation (CME) framework. In Gillespie’s stochastic simulation context, each reaction channel is a memoryless jump whose occurrence in an infinitesimal interval is determined by its propensity function.\n\nStarting from the definition that, in the CME, the probability that a given reaction channel fires in an infinitesimal time interval $\\mathrm{d}t$ when the system is in state $x = (x_R, x_L, x_{RL})$ is $a(x)\\,\\mathrm{d}t + o(\\mathrm{d}t)$, and using only first principles of discrete-state, well-mixed reaction kinetics and counting of reactive pairs under mass-action at the molecular scale, derive:\n\n1. The propensity function $a(x)$ for the forward binding reaction $R + L \\to RL$, expressed in terms of an effective stochastic rate constant $c$ and the counts $x_R$ and $x_L$.\n2. The stoichiometric update vector $\\nu$ for this reaction, in the ordered species basis $(R, L, RL)$.\n\nExpress your final answer as a single row matrix $\\left(a(x), \\nu_R, \\nu_L, \\nu_{RL}\\right)$ with no units. No numerical rounding is required.",
            "solution": "The problem requires the derivation of two quantities for the forward binding reaction $R + L \\to RL$: the propensity function $a(x)$ and the stoichiometric update vector $\\nu$. The derivation must be based on first principles of stochastic reaction kinetics.\n\nThe state of the system at any time $t$ is given by the vector of discrete molecular counts $x(t) = (x_R(t), x_L(t), x_{RL}(t))$, where $x_R$, $x_L$, and $x_{RL}$ are the number of molecules of species $R$, $L$, and $RL$, respectively. For simplicity, we denote the state as $x$. The species are ordered as $(R, L, RL)$.\n\nFirst, we will derive the propensity function $a(x)$. The Chemical Master Equation (CME) governs the time evolution of the probability distribution over discrete molecular counts in a well-mixed reaction system. The problem provides the fundamental definition that the probability of a specific reaction channel firing in an infinitesimal time interval $[t, t+dt)$ is $a(x)\\,dt + o(dt)$, where $a(x)$ is the propensity function.\n\nThe reaction is a bimolecular association: $R + L \\to RL$.\nThe derivation proceeds from the physical and probabilistic interpretation of this reaction at the molecular level in a well-mixed system. The \"well-mixed\" assumption implies that molecules are distributed uniformly throughout the volume and every molecule is equally likely to react with any other molecule. The \"memoryless\" assumption means that the probability of a reaction occurring in the next infinitesimal time interval depends only on the current state of the system, not on its history.\n\nLet $c$ be the effective stochastic rate constant. This constant encapsulates the probability that a single, specific pair of $R$ and $L$ molecules will react within a unit time interval. Thus, the probability that a specific pair of reactants, say the $i$-th molecule of $R$ and the $j$-th molecule of $L$, will react in the infinitesimal time interval $dt$ is $c \\, dt$.\n\nThe task is to find the total probability for *any* pair of $R$ and $L$ molecules to react in $dt$. Since the system is in state $x$, there are $x_R$ molecules of species $R$ and $x_L$ molecules of species $L$. The reaction involves two distinct species. The number of distinct pairs of $(R, L)$ that can be formed is the product of the number of molecules of each species.\nNumber of distinct reactive pairs = $x_R \\times x_L$.\n\nSince each of these pairs has an independent probability $c \\, dt$ of reacting in the interval $dt$, and the events are mutually exclusive (if one pair reacts, the state changes, and the conditions for another pair to react in the same infinitesimal instant are altered), the total probability of one reaction event occurring is the sum of the probabilities for each distinct pair.\nProbability(one reaction in $dt$) = $\\sum_{i=1}^{x_R} \\sum_{j=1}^{x_L} (\\text{Probability that pair } (R_i, L_j) \\text{ reacts})$\nProbability(one reaction in $dt$) = $(x_R x_L) \\times (c \\, dt)$\n\nBy comparing this expression with the definition provided in the problem, $a(x)\\,dt$, we can identify the propensity function $a(x)$:\n$a(x) \\, dt = c \\, x_R \\, x_L \\, dt$\nTherefore, the propensity function for the forward binding reaction is:\n$a(x) = c \\, x_R \\, x_L$\n\nNext, we derive the stoichiometric update vector $\\nu$. The vector $\\nu$ describes the change in the molecular counts of all species as a result of a single reaction event. The state vector is ordered as $x = (x_R, x_L, x_{RL})$.\nThe reaction is $R + L \\to RL$.\nEach time this reaction occurs:\n- One molecule of $R$ is consumed. The change in $x_R$ is $\\Delta x_R = -1$.\n- One molecule of $L$ is consumed. The change in $x_L$ is $\\Delta x_L = -1$.\n- One molecule of $RL$ is produced. The change in $x_{RL}$ is $\\Delta x_{RL} = +1$.\n\nThe stoichiometric update vector $\\nu$ is the vector of these changes, corresponding to the ordered species basis $(R, L, RL)$.\n$\\nu = (\\Delta x_R, \\Delta x_L, \\Delta x_{RL})$\nSubstituting the values, we obtain:\n$\\nu = (-1, -1, 1)$\n\nThe components of this vector are $\\nu_R = -1$, $\\nu_L = -1$, and $\\nu_{RL} = 1$.\n\nThe problem asks for a final answer as a single row matrix $(a(x), \\nu_R, \\nu_L, \\nu_{RL})$. Combining our derived results:\n$a(x) = c \\, x_R \\, x_L$\n$\\nu_R = -1$\n$\\nu_L = -1$\n$\\nu_{RL} = 1$\n\nThe final combined result is $(c \\, x_R \\, x_L, -1, -1, 1)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nc x_R x_L & -1 & -1 & 1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The elegance of the Stochastic Simulation Algorithm (SSA) lies in its direct correspondence to the underlying probability theory of the Chemical Master Equation. This practice moves beyond simply applying the algorithm to deriving its core probabilistic features for a simple birth–death process. By calculating the expected waiting time until the next reaction and the expected identity of that reaction, you will gain a deeper intuition for how propensities govern the two random variables—when to jump, and which jump to take—that drive the simulation forward .",
            "id": "2777186",
            "problem": "In a constitutive single-gene expression model for a messenger RNA molecule in synthetic biology, the system is modeled as a two-reaction birth–death process under the Chemical Master Equation (CME) and simulated via the Stochastic Simulation Algorithm (SSA). At time $t$, the system has a current copy number $n \\in \\mathbb{N}_{0}$. The two reactions are:\n- Transcription (birth): $\\varnothing \\rightarrow \\text{mRNA}$ with a constant stochastic rate constant $k_b$ (units: $\\text{time}^{-1}$).\n- Degradation (death): $\\text{mRNA} \\rightarrow \\varnothing$ with a first-order stochastic rate constant $k_d$ (units: $\\text{time}^{-1}$).\n\nAssume that $k_b > 0$, $k_d > 0$, and $n$ is finite and nonnegative. Using only first principles of the Chemical Master Equation (CME) and the definition of propensities as hazard rates under well-mixed mass-action kinetics, consider a single step of the Stochastic Simulation Algorithm (SSA). Define the reaction index $J \\in \\{1,2\\}$, where $J=1$ denotes the transcription event and $J=2$ denotes the degradation event, and let $\\tau$ be the waiting time to the next event.\n\nDerive, from first principles, expressions for the conditional expected waiting time $\\mathbb{E}[\\tau \\mid n]$ and the conditional expected reaction index $\\mathbb{E}[J \\mid n]$ for the very next SSA step, as functions of $k_b$, $k_d$, and $n$. Your derivation must start from the CME interpretation of propensities as hazards and must not assume any specific SSA formulas without derivation.\n\nExpress your final answer as a single row vector $\\big(\\mathbb{E}[\\tau \\mid n],\\, \\mathbb{E}[J \\mid n]\\big)$ in closed form. No numerical approximation is required and no units should be included in the final answer.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is a standard exercise in stochastic chemical kinetics. We will proceed with the derivation from first principles as required.\n\nThe system is defined by two chemical reactions:\n1.  Transcription: $\\varnothing \\xrightarrow{k_b} \\text{mRNA}$\n2.  Degradation: $\\text{mRNA} \\xrightarrow{k_d} \\varnothing$\n\nAt time $t$, the state of the system is the number of mRNA molecules, $n$. The evolution of the system is governed by the propensities of these two reactions. The propensity function $a_j(n)$ for a reaction $j$ represents the hazard rate of that reaction occurring, given the system is in state $n$. For a well-mixed system under mass-action kinetics, the propensities are defined as follows:\n\nFor reaction $1$, transcription, the rate is independent of the number of mRNA molecules, $n$. This is a zero-order reaction. The propensity is equal to the stochastic rate constant $k_b$.\n$$ a_1(n) = k_b $$\nFor reaction $2$, degradation, the rate is proportional to the number of mRNA molecules, $n$. This is a first-order reaction. The propensity is the product of the first-order rate constant $k_d$ and the number of molecules.\n$$ a_2(n) = k_d n $$\nThe total propensity, which is the hazard rate of *any* reaction occurring, is the sum of the individual propensities.\n$$ a_0(n) = a_1(n) + a_2(n) = k_b + k_d n $$\nThe foundation of the Stochastic Simulation Algorithm (SSA) is that the time until the next reaction, $\\tau$, is a continuous random variable, while the index of the next reaction, $J$, is a discrete random variable. We must derive their conditional expectations given the current state $n$.\n\nLet $\\tau_j$ be the waiting time for the next occurrence of reaction $j$. Under the CME, each reaction channel is an independent Poisson process. Therefore, the waiting time for each reaction is an independent, exponentially distributed random variable with a rate parameter equal to its propensity. The probability density function (PDF) for $\\tau_j$ is $f_j(t) = a_j(n) \\exp(-a_j(n) t)$ for $t \\ge 0$.\n\nThe waiting time to the very next event, $\\tau$, is the minimum of the waiting times for all possible reactions.\n$$ \\tau = \\min(\\tau_1, \\tau_2) $$\nThe cumulative distribution function (CDF) of $\\tau$ is $F_\\tau(t) = P(\\tau \\le t)$. It is simpler to first find the survival function, $S_\\tau(t) = P(\\tau > t)$.\n$$ P(\\tau > t) = P(\\min(\\tau_1, \\tau_2) > t) = P(\\tau_1 > t \\text{ and } \\tau_2 > t) $$\nDue to the independence of the reaction channels, we have:\n$$ P(\\tau > t) = P(\\tau_1 > t) P(\\tau_2 > t) $$\nFor an exponential distribution with rate $\\lambda$, the survival function is $P(T > t) = \\exp(-\\lambda t)$. Thus:\n$$ P(\\tau > t) = \\exp(-a_1(n) t) \\exp(-a_2(n) t) = \\exp(-(a_1(n) + a_2(n)) t) = \\exp(-a_0(n) t) $$\nThis is the survival function of an exponential distribution with rate parameter $a_0(n) = k_b + k_d n$. The expected value of an exponential random variable with rate $\\lambda$ is $1/\\lambda$. Therefore, the conditional expected waiting time $\\mathbb{E}[\\tau \\mid n]$ is:\n$$ \\mathbb{E}[\\tau \\mid n] = \\frac{1}{a_0(n)} = \\frac{1}{k_b + k_d n} $$\nThis completes the derivation for the first quantity.\n\nNext, we derive the conditional expectation of the reaction index, $\\mathbb{E}[J \\mid n]$. The random variable $J$ can take values $1$ or $2$. The probability that the next reaction is reaction $j$, $P(J=j \\mid n)$, is the probability that the waiting time for this reaction, $\\tau_j$, is less than or equal to the waiting times for all other reactions. For our two-reaction system, we need to find $P(J=1 \\mid n)$ and $P(J=2 \\mid n)$.\n\nLet us calculate $P(J=1 \\mid n) = P(\\tau_1 \\le \\tau_2)$. We can find this by integrating over all possible times $t$ for $\\tau_1$ to occur, multiplied by the probability that $\\tau_2$ has not occurred by that time.\n$$ P(\\tau_1 \\le \\tau_2) = \\int_0^\\infty P(\\tau_1=t, \\tau_2 \\ge t) dt = \\int_0^\\infty f_1(t) P(\\tau_2 > t) dt $$\nwhere $f_1(t)$ is the PDF of $\\tau_1$.\n$$ P(J=1 \\mid n) = \\int_0^\\infty \\left( a_1(n) \\exp(-a_1(n) t) \\right) \\left( \\exp(-a_2(n) t) \\right) dt $$\n$$ P(J=1 \\mid n) = a_1(n) \\int_0^\\infty \\exp(-(a_1(n) + a_2(n)) t) dt $$\n$$ P(J=1 \\mid n) = a_1(n) \\left[ \\frac{-\\exp(-(a_1(n) + a_2(n)) t)}{a_1(n) + a_2(n)} \\right]_0^\\infty $$\n$$ P(J=1 \\mid n) = a_1(n) \\left( 0 - \\left( \\frac{-1}{a_1(n) + a_2(n)} \\right) \\right) = \\frac{a_1(n)}{a_1(n) + a_2(n)} = \\frac{a_1(n)}{a_0(n)} $$\nSubstituting the propensity expressions:\n$$ P(J=1 \\mid n) = \\frac{k_b}{k_b + k_d n} $$\nSince there are only two reactions, the probabilities must sum to $1$.\n$$ P(J=2 \\mid n) = 1 - P(J=1 \\mid n) = 1 - \\frac{k_b}{k_b + k_d n} = \\frac{k_b + k_d n - k_b}{k_b + k_d n} = \\frac{k_d n}{k_b + k_d n} $$\nThis is consistent with the general formula $P(J=j \\mid n) = a_j(n)/a_0(n)$.\n\nNow we compute the conditional expected value of the reaction index $J$ using its definition:\n$$ \\mathbb{E}[J \\mid n] = \\sum_{j \\in \\{1,2\\}} j \\cdot P(J=j \\mid n) $$\n$$ \\mathbb{E}[J \\mid n] = 1 \\cdot P(J=1 \\mid n) + 2 \\cdot P(J=2 \\mid n) $$\n$$ \\mathbb{E}[J \\mid n] = 1 \\cdot \\left( \\frac{k_b}{k_b + k_d n} \\right) + 2 \\cdot \\left( \\frac{k_d n}{k_b + k_d n} \\right) $$\n$$ \\mathbb{E}[J \\mid n] = \\frac{k_b + 2 k_d n}{k_b + k_d n} $$\nThis completes the derivation for the second quantity.\n\nThe final answer is the row vector containing both derived conditional expected values.",
            "answer": "$$ \\boxed{\\begin{pmatrix} \\frac{1}{k_b + k_d n} & \\frac{k_b + 2 k_d n}{k_b + k_d n} \\end{pmatrix}} $$"
        },
        {
            "introduction": "While mathematically exact, the practical utility of the Stochastic Simulation Algorithm depends critically on its computational implementation, especially for complex networks with many reactions. This exercise explores the crucial topic of algorithmic efficiency by comparing the computational cost of Gillespie's original direct method with the more advanced next-reaction method. Analyzing how the performance of these algorithms scales with the number of reactions, $M$, provides essential insight for choosing and designing efficient simulation tools for large-scale biomedical systems modeling .",
            "id": "3935994",
            "problem": "Consider a well-mixed biochemical reaction network with $M$ reaction channels and a discrete state vector $X(t)$ that evolves according to the Chemical Master Equation (CME). Let the propensity functions be $a_{j}(X(t))$ for $j \\in \\{1,2,\\dots,M\\}$, and let $a_{0}(X(t)) = \\sum_{j=1}^{M} a_{j}(X(t))$. The Stochastic Simulation Algorithm (SSA) advances the system by sampling the next reaction event and its time from the current state.\n\nYou are to analyze, from first principles of event selection implied by the CME and the SSA, the computational complexity per simulation step (i.e., per reaction event) of two SSA variants:\n\n- the direct method (Gillespie’s original algorithm), and\n- the next-reaction method of Gibson–Bruck.\n\nUse the following modeling assumptions for a cost model of primitive operations:\n- Each floating-point addition, multiplication, division, comparison, generation of a uniform random variate on $(0,1)$, and evaluation of the natural logarithm contributes a unit cost of $1$.\n- A binary min-heap (priority queue) keyed by putative firing times supports extract-min and key-decrease (or update) operations at unit cost per heap level, so that the cost scales as $\\log_{2}(M)$ per such operation.\n- The dependency graph of the network has bounded out-degree: the number of propensities affected by any single reaction firing is upper-bounded by a constant $d$ that does not grow with $M$.\n- In the direct method, the reaction index is identified by scanning a cumulative sum of propensities until the threshold is exceeded; do not assume any precomputed tree or alias method.\n- In the next-reaction method, putative firing times are maintained and updated using standard hazard rescaling when propensities change; updates to affected reactions are done via heap key updates.\n\nStarting from the CME interpretation of propensities as hazard rates and the SSA step structure, derive the dominant-order cost per step, expressed solely as a function of $M$, for each of the two methods under the stated assumptions. Ignore additive constants and terms that do not scale with $M$, and report only the leading-order growth in $M$. Provide your final answer as a row matrix with the first entry corresponding to the direct method and the second entry corresponding to the Gibson–Bruck next-reaction method. No rounding is required, and no physical units apply.",
            "solution": "The problem requires a first-principles derivation of the computational complexity per simulation step for two variants of the Stochastic Simulation Algorithm (SSA): the direct method and the next-reaction method. The complexity is to be expressed as the leading-order growth term as a function of the number of reaction channels, $M$.\n\nThe foundation of the SSA lies in the fact that for a system in state $X(t)$, the quantity $a_j(X(t)) dt$ represents the probability that reaction channel $j$ will fire in the infinitesimal time interval $[t, t+dt)$. This interpretation of propensities as hazard rates for Poisson processes implies that the waiting time $\\tau$ for the *next* reaction of any type is an exponential random variable with rate parameter $a_0(X(t)) = \\sum_{j=1}^{M} a_j(X(t))$. The probability density function for $\\tau$ is $P(\\tau) = a_0 \\exp(-a_0 \\tau)$. Given that a reaction occurs at time $t+\\tau$, the probability that it is reaction $\\mu$ is $P(\\mu) = a_\\mu(X(t))/a_0(X(t))$. The two SSA variants are mathematically equivalent methods for sampling the pair $(\\tau, \\mu)$ from their joint distribution.\n\nWe analyze the computational cost of one full step, which propels the system from one reaction event to the next, based on the provided cost model.\n\n**Analysis of the Direct Method**\n\nThe direct method samples $(\\tau, \\mu)$ sequentially. First, it samples the time $\\tau$ to the next event, and then it samples the index $\\mu$ of that event. A single step proceeds as follows:\n\n1.  **Preparation**: At the beginning of a step, the system is in a specific state $X$. To determine the next event, all $M$ propensity functions $a_j(X)$ for $j \\in \\{1, 2, \\dots, M\\}$ must be known. In a naive implementation, all $M$ propensities are re-evaluated at each step. A more optimized approach, leveraging the dependency graph, would only update the propensities that are affected by the previous reaction. However, the step that determines the complexity of the direct method is the selection of the reaction index, which requires access to all $a_j$ values regardless.\n    *   The total propensity $a_0$ must be computed: $a_0 = \\sum_{j=1}^{M} a_j(X)$. This requires $M-1$ floating-point additions. The cost is therefore proportional to $M$.\n\n2.  **Sample the time to the next event, $\\tau$**: The value for $\\tau$ is drawn from an exponential distribution with rate $a_0$. Using the inversion method, this is computed as $\\tau = \\frac{1}{a_0} \\ln(\\frac{1}{r_1})$, where $r_1$ is a random variate from a uniform distribution $U(0,1)$. According to the cost model, this step involves one random number generation, one logarithm, and one division. This is a constant cost, $O(1)$, independent of $M$.\n\n3.  **Sample the index of the next reaction, $\\mu$**: The index $\\mu$ is drawn from the discrete probability distribution $P(\\mu) = a_\\mu/a_0$. The problem specifies that this is accomplished by generating a second uniform random variate $r_2 \\in U(0,1)$ and finding the smallest integer $\\mu$ that satisfies the inequality $\\sum_{k=1}^{\\mu} a_k(X) > r_2 a_0(X)$. This is implemented via a linear search:\n    *   Compute the threshold value $T = r_2 \\times a_0$. This requires one random number generation and one multiplication, an $O(1)$ cost.\n    *   Iteratively compute the cumulative sum $S_j = \\sum_{k=1}^{j} a_k(X)$ for $j=1, 2, \\dots$ and compare it to $T$. The first $j$ for which $S_j > T$ gives $\\mu=j$. This process involves one addition and one comparison per iteration. In the worst case, this search requires $M$ iterations. On average, the search will require $M/2$ iterations.\n\n4.  **Cost Aggregation**: The total cost per step is the sum of the costs of these operations.\n    *   Cost of computing $a_0$: $O(M)$.\n    *   Cost of computing $\\tau$: $O(1)$.\n    *   Cost of linear search for $\\mu$: $O(M)$.\n\nThe overall cost is dominated by the linear operations. Therefore, the leading-order growth of the computational cost per step for the direct method is a linear function of $M$.\n\nDominant-order cost $\\propto M$.\n\n**Analysis of the Next-Reaction Method (Gibson–Bruck)**\n\nThis method reformulates the sampling problem. It views the $M$ reactions as competing Poisson processes. It generates a putative firing time $\\tau_j$ for each reaction channel $j$ and identifies the next event as the one with the minimum putative time, i.e., $(\\tau, \\mu) = (\\min_j\\{\\tau_j\\}, \\arg\\min_j\\{\\tau_j\\})$. To avoid regenerating all $M$ putative times at each step, an indexed priority queue (min-heap) is used to store the pairs $(j, \\tau_j)$. When a reaction fires, only the putative times for a small number of affected reactions need to be updated.\n\nA single step proceeds as follows:\n\n1.  **Determine the next event $(\\mu, \\tau)$**: The next reaction index $\\mu$ and its absolute firing time $\\tau$ correspond to the element with the minimum key in the priority queue. This requires one `extract-min` operation. Based on the cost model for a binary min-heap of size $M$, this operation has a cost proportional to $\\log_2(M)$.\n\n2.  **Update system state and time**: The system time is advanced to $\\tau$, and the state vector $X$ is updated according to the stoichiometry of reaction $\\mu$. This has a cost that is constant with respect to $M$, i.e., $O(1)$.\n\n3.  **Update putative firing times**: The change in state $X$ to $X'$ following the firing of reaction $\\mu$ will alter the propensities of a set of reactions. The problem states that the size of this set is bounded by a constant $d$ (the out-degree of the dependency graph). For each affected reaction $k$, its putative time $\\tau_k$ must be updated.\n    *   **For the reaction $\\mu$ that just fired**: A new putative time must be generated. This involves generating a new random variate $r_\\mu \\sim U(0,1)$, recalculating the propensity $a_\\mu(X')$, and computing the new time increment $\\Delta \\tau_\\mu = \\frac{1}{a_\\mu(X')} \\ln(\\frac{1}{r_\\mu})$. The new absolute time is $\\tau_\\mu' = \\tau + \\Delta \\tau_\\mu$. The cost of these calculations is constant, $O(1)$. This new time $\\tau_\\mu'$ is then inserted back into the priority queue, which has a cost proportional to $\\log_2(M)$.\n    *   **For other affected reactions $k \\neq \\mu$**: The Gibson-Bruck algorithm uses a rescaling rule to update the putative time without generating a new random number: $\\tau_k' = \\tau + \\frac{a_k(X)}{a_k(X')} (\\tau_k - \\tau)$. This calculation involves a few floating-point operations, an $O(1)$ cost, after the new propensity $a_k(X')$ is computed (also an $O(1)$ cost). The key for reaction $k$ in the priority queue must then be updated to $\\tau_k'$. This `key-update` operation has a cost proportional to $\\log_2(M)$.\n\n4.  **Cost Aggregation**: The total cost is the sum of these operations. There is one `extract-min` operation, one `insert` (for reaction $\\mu$), and at most $d-1$ `key-update` operations.\n    *   Cost of finding the next event (`extract-min`): $O(\\log_2 M)$.\n    *   Cost of updating reaction $\\mu$ (calculations + `insert`): $O(1) + O(\\log_2 M)$.\n    *   Cost of updating the other $d-1$ (at most) affected reactions: For each, the cost is $O(1)$ for calculations plus $O(\\log_2 M)$ for the heap update. The total for this part is $(d-1) \\times O(\\log_2 M) = O(d \\log_2 M)$.\n\nThe total cost is the sum of these costs: $O(\\log_2 M) + O(\\log_2 M) + O(d \\log_2 M)$. Since $d$ is a constant independent of $M$, the sum is dominated by terms proportional to $\\log_2(M)$. Therefore, the leading-order growth of the computational cost per step for the next-reaction method is a logarithmic function of $M$.\n\nDominant-order cost $\\propto \\log_2(M)$.\n\n**Conclusion**\n\nThe dominant-order cost per step, expressed as a function of the number of reaction channels $M$, is $M$ for the direct method and $\\log_2(M)$ for the next-reaction method.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nM & \\log_{2}(M)\n\\end{pmatrix}\n}\n$$"
        }
    ]
}