{
    "hands_on_practices": [
        {
            "introduction": "To truly understand the random nature of ion channel gating, it is essential to move beyond deterministic equations and simulate the exact stochastic trajectories. This practice guides you through the core logic of the Gillespie Stochastic Simulation Algorithm (SSA), a fundamental tool in computational biology. By deriving the event-time distribution and selection rule for a population of channels , you will gain a first-principles understanding of how to generate statistically exact simulations of these microscopic systems.",
            "id": "3931884",
            "problem": "Consider a population of $N$ identical, independent, two-state ion channels, each in either a closed state $C$ or an open state $O$. Under voltage-clamp conditions, the membrane potential $V$ is held constant between channel gating events. A channel in state $C$ transitions to state $O$ with voltage-dependent rate $k_{CO}(V)$, and a channel in state $O$ transitions to state $C$ with voltage-dependent rate $k_{OC}(V)$. At time $t$, denote the number of closed channels by $n_C(t)$ and the number of open channels by $n_O(t)$, with $n_C(t) + n_O(t) = N$. Assume $k_{CO}(V)$ and $k_{OC}(V)$ are finite and positive for the clamped $V$, and that channels gate independently.\n\nStarting from the definitions of a continuous-time Markov process with memoryless transitions and the independence of channels, derive the distribution of the waiting time to the next gating event and the rule for selecting the identity and type of the next event. Use these derivations to characterize how the Gillespie Stochastic Simulation Algorithm (SSA) would be executed for this system under the stated voltage-clamp assumption.\n\nWhich option best and completely describes the event-time distribution and event-selection procedure used by the Gillespie SSA for this system?\n\nA. Under voltage clamp, treat $k_{CO}(V)$ and $k_{OC}(V)$ as constants within each inter-event interval. The waiting time $\\tau$ to the next event is exponentially distributed with rate $a_0 = n_C(t)\\,k_{CO}(V) + n_O(t)\\,k_{OC}(V)$. The next event is a $C \\to O$ opening with probability $n_C(t)\\,k_{CO}(V)/a_0$ and an $O \\to C$ closing with probability $n_O(t)\\,k_{OC}(V)/a_0$; the specific channel is chosen uniformly at random within the corresponding state class. The SSA steps are: compute $a_0$, draw $\\tau$ from $\\mathrm{Exponential}(a_0)$, draw the event type by proportionally sampling the propensities, update $n_C(t)$ and $n_O(t)$ and the time $t \\leftarrow t + \\tau$, and repeat.\n\nB. Because there are $N$ channels, the waiting time $\\tau$ is gamma distributed with shape parameter $N$ and rate parameter $k_{CO}(V) + k_{OC}(V)$; the identity of the next event is chosen with equal probability between opening and closing, and then the specific channel is chosen uniformly at random over all channels.\n\nC. The waiting time $\\tau$ is exponentially distributed with rate $\\max\\{k_{CO}(V),\\,k_{OC}(V)\\}$, independent of $n_C(t)$ and $n_O(t)$; the type of event is determined by whichever rate is larger, and the specific channel is the one with the fastest rate.\n\nD. Because $k_{CO}(V)$ and $k_{OC}(V)$ depend on membrane voltage, the waiting time density is $f(\\tau) = a_0(V(t+\\tau))\\,\\exp\\!\\big(-\\int_0^\\tau a_0(V(t+s))\\,ds\\big)$ with $a_0(V) = n_C(t)\\,k_{CO}(V) + n_O(t)\\,k_{OC}(V)$, and the event type is selected by normalizing $n_C(t)\\,k_{CO}(V(t+\\tau))$ and $n_O(t)\\,k_{OC}(V(t+\\tau))$ at the realized $\\tau$.\n\nE. The waiting time $\\tau$ is exponentially distributed with rate $a_0 = n_C(t)\\,k_{CO}(V) + n_O(t)\\,k_{OC}(V)$, but the next event is an opening with probability $k_{CO}(V)/(k_{CO}(V) + k_{OC}(V))$ and a closing with probability $k_{OC}(V)/(k_{CO}(V) + k_{OC}(V))$, independent of $n_C(t)$ and $n_O(t)$.",
            "solution": "We begin from the principle that the gating of each channel is described by a continuous-time Markov process with memoryless transitions. Under voltage-clamp, the membrane potential $V$ is held constant between events, so the rates $k_{CO}(V)$ and $k_{OC}(V)$ are constant over any inter-event interval. Independence of channels implies that, at time $t$, there are $n_C(t)$ independent exponential clocks each with rate $k_{CO}(V)$ for potential openings, and $n_O(t)$ independent exponential clocks each with rate $k_{OC}(V)$ for potential closings.\n\nFor the waiting time distribution, we use the survival probability approach. Let $\\tau$ denote the waiting time to the next event. The probability that no $C \\to O$ transition occurs in the interval $[t, t+\\tau)$ is, by independence and exponential survival, $\\exp\\!\\big(-n_C(t)\\,k_{CO}(V)\\,\\tau\\big)$. Similarly, the probability that no $O \\to C$ transition occurs in $[t, t+\\tau)$ is $\\exp\\!\\big(-n_O(t)\\,k_{OC}(V)\\,\\tau\\big)$. The probability that no event of either type occurs is the product\n$$\nP(\\text{no event in }[t,t+\\tau)) \\;=\\; \\exp\\!\\big(-n_C(t)\\,k_{CO}(V)\\,\\tau\\big)\\,\\exp\\!\\big(-n_O(t)\\,k_{OC}(V)\\,\\tau\\big)\n\\;=\\; \\exp\\!\\big(-a_0\\,\\tau\\big),\n$$\nwhere\n$$\na_0 \\;=\\; n_C(t)\\,k_{CO}(V) \\;+\\; n_O(t)\\,k_{OC}(V).\n$$\nThus, the waiting time $\\tau$ has an exponential distribution with rate $a_0$. The corresponding density is\n$$\nf(\\tau) \\;=\\; a_0\\,\\exp\\!\\big(-a_0\\,\\tau\\big), \\quad \\tau \\ge 0.\n$$\nNext, we derive the event-selection probabilities. The probability that the minimum among all $n_C(t)+n_O(t)$ independent exponential clocks comes from the set of $C \\to O$ clocks equals the total rate contributed by that set divided by the overall rate $a_0$, a standard property of competing exponentials. More formally, for independent exponential clocks with rates $\\{\\lambda_i\\}_{i=1}^m$, the probability that the earliest event is due to clock $j$ is $\\lambda_j / \\sum_{i=1}^m \\lambda_i$. Grouping by reaction class, the probability the next event is an opening is\n$$\nP(\\text{next is }C\\to O) \\;=\\; \\frac{n_C(t)\\,k_{CO}(V)}{a_0},\n$$\nand the probability the next event is a closing is\n$$\nP(\\text{next is }O\\to C) \\;=\\; \\frac{n_O(t)\\,k_{OC}(V)}{a_0}.\n$$\nConditional on the event type, the identity of the specific channel is uniformly distributed among the channels in the corresponding state class, because all channels within a class have identical rates under voltage clamp.\n\nThese results lead directly to the Gillespie Stochastic Simulation Algorithm (SSA) for this system under voltage clamp:\n- Compute the propensities for each reaction class: $a_{CO} = n_C(t)\\,k_{CO}(V)$ and $a_{OC} = n_O(t)\\,k_{OC}(V)$, and their sum $a_0 = a_{CO} + a_{OC}$.\n- Draw the waiting time $\\tau$ from the exponential distribution with rate $a_0$, for example $\\tau = -\\frac{1}{a_0}\\ln(u_1)$ with $u_1 \\sim \\mathrm{Uniform}(0,1)$.\n- Draw the event type using $u_2 \\sim \\mathrm{Uniform}(0,1)$: if $u_2 < a_{CO}/a_0$, select a $C \\to O$ opening; otherwise select an $O \\to C$ closing.\n- Choose a specific channel uniformly at random from the corresponding state class, update its state, and update counts $n_C(t)$ and $n_O(t)$ and the time $t \\leftarrow t + \\tau$.\n- Under voltage clamp, $V$ remains constant; repeat the steps.\n\nOption-by-option analysis:\n- Option A: This matches the derivation exactly under the stated voltage-clamp assumption. It correctly gives $\\tau \\sim \\mathrm{Exponential}(a_0)$ with $a_0 = n_C(t)\\,k_{CO}(V) + n_O(t)\\,k_{OC}(V)$, the correct event-selection probabilities, and the standard SSA steps. Verdict: Correct.\n- Option B: This asserts a gamma (Erlang) waiting time with shape $N$, which is a common misconception. The time to the first event among $N$ independent exponential clocks is exponential with the summed rate, not gamma with shape $N$. It also incorrectly assigns equal probability to opening versus closing, ignoring $n_C(t)$, $n_O(t)$, and the rates. Verdict: Incorrect.\n- Option C: This uses $\\max\\{k_{CO}(V), k_{OC}(V)\\}$ as the rate, which ignores the number of channels and the additive nature of independent hazards. The next event can come from either class, and the total hazard is the sum, not the maximum. It also incorrectly ties the event type to the larger rate deterministically and the identity to the “fastest” channel, which is not how competing exponentials work. Verdict: Incorrect.\n- Option D: This describes an inhomogeneous Poisson process with time-dependent hazard $a_0(V(t+\\tau))$ and selection based on $V(t+\\tau)$. Under voltage clamp, $V$ is constant between events, so the rates are constant and the hazard is not time-dependent. While such a form can be relevant when $V$ evolves continuously between events, it contradicts the stated voltage-clamp assumption in the problem. Verdict: Incorrect in the present setting.\n- Option E: This gets the exponential waiting time with rate $a_0$ correct but then assigns event-selection probabilities that ignore the channel counts $n_C(t)$ and $n_O(t)$, using only the single-channel rates. The correct probabilities must include the multiplicity factors $n_C(t)$ and $n_O(t)$. Verdict: Incorrect.\n\nTherefore, Option A is the correct and complete description under the problem’s assumptions.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A biophysical model is only as good as its parameters, which must be estimated from experimental data. This exercise focuses on this crucial inverse problem: inferring the underlying transition rates from a set of observed channel open times . You will apply the powerful method of Maximum Likelihood Estimation (MLE) to find the most probable value for the channel closing rate and use the Cramér-Rao Lower Bound to establish the fundamental limit on how precisely this rate can be measured.",
            "id": "3931900",
            "problem": "Consider a single voltage-clamped ion channel modeled as a two-state Continuous-Time Markov Chain (CTMC) with states open ($O$) and closed ($C$). The transition from open to closed occurs as a Poisson process with constant rate $k_{OC}$, and the transition from closed to open occurs with constant rate $k_{CO}$. Under stationary conditions at fixed voltage and temperature, assume that each open period ends with an $O \\to C$ transition that is conditionally memoryless given the start of the open period. Consequently, the open dwell time $\\tau$ has an exponential probability density function characterized solely by the closing rate $k_{OC}$.\n\nYou acquire $N$ independent open dwell times $\\{\\tau_k\\}_{k=1}^{N}$ from a long recording of a single channel under ideal detection (no missed short events and no filtering distortion). Starting from the exponential law of waiting times for a Poisson transition and the independence of the recorded open dwell times, do the following:\n\n1. Write the likelihood of the observed sample $\\{\\tau_k\\}_{k=1}^{N}$ as a function of $k_{OC}$ and derive the maximum likelihood estimator for $k_{OC}$.\n2. Using the definition of Fisher information $I(k_{OC})$ based on the expected negative second derivative of the log-likelihood, derive the Cramér-Rao lower bound (CRLB) for the variance of any unbiased estimator of $k_{OC}$.\n\nExpress your final results as closed-form analytic expressions for the maximum likelihood estimate $\\hat{k}_{OC}$ and for the Cramér-Rao lower bound in terms of $N$, $\\{\\tau_k\\}$, and $k_{OC}$. Provide both expressions together as your final answer.",
            "solution": "The probability density function (PDF) for a single open dwell time, $\\tau$, which follows an exponential distribution with rate $k_{OC}$, is:\n$$p(\\tau | k_{OC}) = k_{OC} \\exp(-k_{OC} \\tau), \\quad \\text{for } \\tau \\ge 0$$\n\n**1. Maximum Likelihood Estimator ($\\hat{k}_{OC}$)**\n\nFor a sample of $N$ independent and identically distributed (i.i.d.) dwell times, $\\{\\tau_k\\}_{k=1}^{N}$, the log-likelihood function $\\mathcal{L}(k_{OC})$ is:\n$$\\mathcal{L}(k_{OC}) = \\ln\\left(\\prod_{k=1}^{N} p(\\tau_k | k_{OC})\\right) = \\sum_{k=1}^{N} \\ln(k_{OC} \\exp(-k_{OC} \\tau_k))$$\n$$\\mathcal{L}(k_{OC}) = N \\ln(k_{OC}) - k_{OC} \\sum_{k=1}^{N} \\tau_k$$\n\nTo find the maximum, we set the first derivative with respect to $k_{OC}$ to zero:\n$$\\frac{\\partial \\mathcal{L}}{\\partial k_{OC}} = \\frac{N}{k_{OC}} - \\sum_{k=1}^{N} \\tau_k = 0$$\nSolving for the estimator $\\hat{k}_{OC}$:\n$$\\hat{k}_{OC} = \\frac{N}{\\sum_{k=1}^{N} \\tau_k}$$\nThis is the reciprocal of the sample mean of the dwell times.\n\n**2. Cramér-Rao Lower Bound (CRLB)**\n\nThe Fisher information, $I(k_{OC})$, is the negative expected value of the second derivative of the log-likelihood. The second derivative is:\n$$\\frac{\\partial^2 \\mathcal{L}}{\\partial k_{OC}^2} = -\\frac{N}{k_{OC}^2}$$\nSince this expression does not depend on the data $\\{\\tau_k\\}$, its expectation is the expression itself. The Fisher information is therefore:\n$$I(k_{OC}) = -E\\left[ \\frac{\\partial^2 \\mathcal{L}}{\\partial k_{OC}^2} \\right] = - \\left( -\\frac{N}{k_{OC}^2} \\right) = \\frac{N}{k_{OC}^2}$$\nThe CRLB is the reciprocal of the Fisher information, which provides the lower bound on the variance of any unbiased estimator:\n$$\\text{CRLB} = \\frac{1}{I(k_{OC})} = \\frac{k_{OC}^2}{N}$$",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{N}{\\sum_{k=1}^{N} \\tau_k} & \\frac{k_{OC}^{2}}{N} \\end{pmatrix}}$$"
        },
        {
            "introduction": "Often, the true structure of a biological system is unknown, and scientists must evaluate several competing models. Simply choosing the model with the best fit can lead to overfitting; a more principled approach is needed to balance goodness-of-fit with complexity. This practice introduces two of the most widely used tools for this task: the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) . By applying these criteria to select the best gating model for a channel, you will learn how to make objective, data-driven decisions between competing scientific hypotheses.",
            "id": "3931850",
            "problem": "A single-channel, constant-voltage patch-clamp experiment generates an idealized sequence of open and closed dwell intervals from a single ion channel in a membrane patch. The gating dynamics are modeled as a continuous-time Markov chain (CTMC) with different proposed state schemes. Three competing models are fit by maximum likelihood to the same dataset of $n$ independent dwell intervals, and their maximized log-likelihoods and parameter counts (number of free rate constants) are recorded. The models are:\n- Model $M_1$: two-state closed–open $(C \\leftrightarrow O)$ scheme with $k_1 = 2$ rate parameters and maximized log-likelihood $\\ell_1 = -120{,}050.0$.\n- Model $M_2$: three-state linear $(C_1 \\leftrightarrow C_2 \\leftrightarrow O)$ scheme with $k_2 = 4$ rate parameters and maximized log-likelihood $\\ell_2 = -115{,}030.0$.\n- Model $M_3$: four-state chain $(C_1 \\leftrightarrow C_2 \\leftrightarrow O_1 \\leftrightarrow O_2)$ scheme with $k_3 = 6$ rate parameters and maximized log-likelihood $\\ell_3 = -115{,}024.0$.\nAssume $n = 100{,}000$ dwell intervals and that standard regularity conditions for asymptotic likelihood theory hold (identifiable parameters, well-behaved Fisher information, and correct model likelihood forms for these CTMCs). Using the widely accepted definitions of Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC), select the statement that correctly identifies which model each criterion prefers for this dataset and accurately justifies the origin and scaling of their penalty terms.\n\nA. AIC prefers $M_3$ while BIC prefers $M_2$. The AIC penalty of $2k$ arises from an unbiased estimation of expected out-of-sample Kullback–Leibler (KL) risk, correcting the optimism of the maximized log-likelihood, and the BIC penalty of $k \\ln n$ arises from a Laplace (saddlepoint) approximation to the marginal likelihood under a Bayesian model selection framework, which scales with sample size and favors parsimony as $n$ grows.\n\nB. AIC prefers $M_2$ while BIC prefers $M_1$. Both penalties quantify complexity solely by the number of states rather than free parameters and scale linearly with $n$, because larger datasets amplify overfitting penalties.\n\nC. AIC prefers $M_3$ and BIC prefers $M_3$. The AIC penalty $2k$ comes from imposing a Bayesian prior on parameters, and the BIC penalty $k \\ln n$ is derived from cross-validation; thus both criteria select the most complex model whenever its log-likelihood is largest.\n\nD. AIC prefers $M_2$ while BIC prefers $M_3$. The AIC penalty $2k$ is only valid for Gaussian noise models, and the BIC term $k \\ln n$ vanishes when parameters are identifiable, so BIC reduces to $-2\\ell$ and will always choose the model with the largest maximized log-likelihood in identifiable CTMCs.",
            "solution": "To select the best model, we compute the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for each model. The model with the lower AIC or BIC score is preferred. The formulas are:\n$$ \\text{AIC} = -2\\ell + 2k $$\n$$ \\text{BIC} = -2\\ell + k \\ln(n) $$\nwhere $\\ell$ is the maximized log-likelihood, $k$ is the number of free parameters, and $n$ is the number of data points ($n = 100,000$).\n\nFirst, we calculate the penalty term for BIC: $\\ln(n) = \\ln(100,000) \\approx 11.513$.\n\nNow we compute the criteria for each model:\n\n**Model $M_1$**: $k_1 = 2, \\ell_1 = -120,050.0$\n*   $\\text{AIC}_1 = -2(-120,050.0) + 2(2) = 240,100 + 4 = 240,104$\n*   $\\text{BIC}_1 = 240,100 + 2 \\times 11.513 \\approx 240,123.0$\n\n**Model $M_2$**: $k_2 = 4, \\ell_2 = -115,030.0$\n*   $\\text{AIC}_2 = -2(-115,030.0) + 2(4) = 230,060 + 8 = 230,068$\n*   $\\text{BIC}_2 = 230,060 + 4 \\times 11.513 \\approx 230,106.1$\n\n**Model $M_3$**: $k_3 = 6, \\ell_3 = -115,024.0$\n*   $\\text{AIC}_3 = -2(-115,024.0) + 2(6) = 230,048 + 12 = 230,060$\n*   $\\text{BIC}_3 = 230,048 + 6 \\times 11.513 \\approx 230,117.1$\n\n**Model Selection:**\n*   Comparing AIC values: $\\text{AIC}_3 (230,060)  \\text{AIC}_2 (230,068)  \\text{AIC}_1 (240,104)$. **AIC prefers Model $M_3$**.\n*   Comparing BIC values: $\\text{BIC}_2 (230,106.1)  \\text{BIC}_3 (230,117.1)  \\text{BIC}_1 (240,123.0)$. **BIC prefers Model $M_2$**.\nThe reason for the different preference is that BIC's penalty for complexity ($k \\ln n$) is much stronger than AIC's ($2k$) for large datasets.\n\n**Evaluation of Theoretical Justifications:**\n*   **Option A:** Correctly identifies that AIC prefers $M_3$ and BIC prefers $M_2$. It also provides the correct theoretical origins: AIC corrects for the bias in using log-likelihood to estimate out-of-sample prediction error (related to KL divergence), while BIC is derived from a large-sample Bayesian approximation to the model evidence (marginal likelihood).\n*   **Option B:** Incorrect model selection and justification (penalty scales with $\\ln(n)$ for BIC, not $n$, and is constant for AIC).\n*   **Option C:** Incorrect model selection (for BIC) and incorrect theoretical origins.\n*   **Option D:** Incorrect model selection and justification (AIC is not limited to Gaussian models, and the BIC penalty does not vanish).\n\nTherefore, option A is the only one that is correct in its calculations and its theoretical reasoning.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}