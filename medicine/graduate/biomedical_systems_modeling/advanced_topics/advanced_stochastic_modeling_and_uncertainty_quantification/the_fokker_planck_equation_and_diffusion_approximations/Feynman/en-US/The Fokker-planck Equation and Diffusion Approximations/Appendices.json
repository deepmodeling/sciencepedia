{
    "hands_on_practices": [
        {
            "introduction": "The Fokker-Planck equation provides a complete description of a system's probability density, but in many biomedical applications, we are primarily interested in the dynamics of macroscopic observables like the mean and variance. This practice demonstrates a powerful technique for deriving the equations of motion for these moments directly from the FPE. You will see how, for the analytically tractable Ornstein-Uhlenbeck process, this approach leads to a closed and solvable system, connecting the microscopic description to bulk statistical behavior .",
            "id": "3936839",
            "problem": "A single-cell biomarker concentration $x(t)$ in a well-mixed compartment is modeled as a one-dimensional diffusion approximation with linear homeostatic feedback. The probability density $p(x,t)$ for $x(t)$ obeys the Fokker–Planck equation\n$$\n\\frac{\\partial p(x,t)}{\\partial t} \\;=\\; -\\frac{\\partial}{\\partial x}\\!\\big(a(x)\\,p(x,t)\\big) \\;+\\; \\frac{1}{2}\\,\\frac{\\partial^{2}}{\\partial x^{2}}\\!\\big(b(x)^{2}\\,p(x,t)\\big),\n$$\nwhere $a(x)$ is the drift and $b(x)$ is the diffusion amplitude. Assume the drift is linear, $a(x)=\\alpha - \\beta x$ with constants $\\alpha>0$ and $\\beta>0$, and the diffusion is constant, $b(x)=\\sqrt{2D}$ with $D>0$. The state space is $x\\in\\mathbb{R}$, and $p(x,t)$ and its first derivative vanish sufficiently rapidly as $|x|\\to\\infty$ to justify integration by parts without boundary contributions.\n\nStarting from the Fokker–Planck equation above and the definitions of the first moment and variance,\n$$\n\\mu(t) \\;=\\; \\int_{-\\infty}^{\\infty} x\\,p(x,t)\\,dx,\n\\qquad\n\\sigma^{2}(t) \\;=\\; \\int_{-\\infty}^{\\infty} \\big(x-\\mu(t)\\big)^{2}\\,p(x,t)\\,dx,\n$$\nderive the time-evolution equations for $\\mu(t)$ and $\\sigma^{2}(t)$, and show that they form a closed system that does not involve higher-order moments. Then, given initial conditions $\\mu(0)=\\mu_{0}$ and $\\sigma^{2}(0)=\\sigma_{0}^{2}$, solve these equations to obtain explicit expressions for $\\mu(t)$ and $\\sigma^{2}(t)$ in terms of $\\alpha$, $\\beta$, $D$, $\\mu_{0}$, and $\\sigma_{0}^{2}$.\n\nExpress your final answer as analytic expressions; no rounding is required.",
            "solution": "The problem is first validated against the specified criteria.\n\n### Step 1: Extract Givens\n- Fokker–Planck equation: $\\frac{\\partial p(x,t)}{\\partial t} = -\\frac{\\partial}{\\partial x}(a(x)p(x,t)) + \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b(x)^{2}p(x,t))$\n- Drift function: $a(x) = \\alpha - \\beta x$, with $\\alpha > 0$ and $\\beta > 0$.\n- Diffusion amplitude: $b(x) = \\sqrt{2D}$, with $D > 0$.\n- State space: $x \\in \\mathbb{R}$.\n- Boundary conditions: $p(x,t)$ and its first derivative $\\frac{\\partial p(x,t)}{\\partial x}$ vanish as $|x| \\to \\infty$.\n- Definition of the first moment (mean): $\\mu(t) = \\int_{-\\infty}^{\\infty} x p(x,t) dx$.\n- Definition of the variance: $\\sigma^{2}(t) = \\int_{-\\infty}^{\\infty} (x-\\mu(t))^{2} p(x,t) dx$.\n- Initial conditions: $\\mu(0) = \\mu_{0}$ and $\\sigma^{2}(0) = \\sigma_{0}^{2}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem describes an Ornstein-Uhlenbeck process, a canonical model in stochastic processes with wide applications, including in biomedical modeling. The given Fokker-Planck equation with linear drift and constant diffusion is the standard representation for this process. The premises are scientifically and mathematically sound.\n- **Well-Posed:** The problem is clearly structured, asking for the derivation and solution of a system of ordinary differential equations (ODEs) for the first two moments. The provided information is sufficient and self-consistent, and the initial conditions ensure a unique solution exists.\n- **Objective:** The problem is stated using formal, precise, and unambiguous mathematical language.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is scientifically grounded, well-posed, and objective. A complete solution will be provided.\n\nTo derive the time-evolution equation for the mean $\\mu(t)$, we start with its definition and differentiate with respect to time $t$:\n$$\n\\frac{d\\mu(t)}{dt} = \\frac{d}{dt} \\int_{-\\infty}^{\\infty} x p(x,t) dx = \\int_{-\\infty}^{\\infty} x \\frac{\\partial p(x,t)}{\\partial t} dx.\n$$\nSubstitute the Fokker–Planck equation for $\\frac{\\partial p}{\\partial t}$:\n$$\n\\frac{d\\mu}{dt} = \\int_{-\\infty}^{\\infty} x \\left[ -\\frac{\\partial}{\\partial x}(a(x)p) + \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b(x)^{2}p) \\right] dx.\n$$\nWe evaluate the two terms in the integral separately. For the first term, we use integration by parts, $\\int u dv = uv - \\int v du$, with $u=x$ and $dv = -\\frac{\\partial}{\\partial x}(a(x)p) dx$. This gives $du=dx$ and $v=-a(x)p$.\n$$\n\\int_{-\\infty}^{\\infty} x \\left[-\\frac{\\partial}{\\partial x}(a(x)p)\\right] dx = \\big[-x a(x) p(x,t)\\big]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} (-a(x)p) dx.\n$$\nThe boundary term $\\big[-x a(x) p(x,t)\\big]_{-\\infty}^{\\infty}$ is zero due to the condition that $p(x,t)$ vanishes sufficiently rapidly as $|x|\\to\\infty$. The integral simplifies to $\\int_{-\\infty}^{\\infty} a(x) p(x,t) dx$.\n\nFor the second term, we also use integration by parts with $u=x$ and $dv = \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b(x)^{2}p) dx$. This gives $du=dx$ and $v=\\frac{1}{2}\\frac{\\partial}{\\partial x}(b(x)^{2}p)$.\n$$\n\\int_{-\\infty}^{\\infty} x \\left[\\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b(x)^{2}p)\\right] dx = \\left[x \\frac{1}{2}\\frac{\\partial}{\\partial x}(b(x)^{2}p)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} \\frac{1}{2}\\frac{\\partial}{\\partial x}(b(x)^{2}p) dx.\n$$\nThe boundary term is zero because both $p$ and its first derivative vanish at infinity. The remaining integral is $-\\frac{1}{2} \\big[b(x)^{2}p(x,t)\\big]_{-\\infty}^{\\infty}$, which is also zero. Thus, the second term contributes nothing.\n\nCombining the results, we have:\n$$\n\\frac{d\\mu}{dt} = \\int_{-\\infty}^{\\infty} a(x) p(x,t) dx = \\int_{-\\infty}^{\\infty} (\\alpha - \\beta x) p(x,t) dx.\n$$\nUsing the normalization of probability, $\\int_{-\\infty}^{\\infty} p(x,t) dx = 1$, and the definition of the mean, $\\mu(t) = \\int_{-\\infty}^{\\infty} x p(x,t) dx$, we obtain the first ODE:\n$$\n\\frac{d\\mu}{dt} = \\alpha \\int_{-\\infty}^{\\infty} p(x,t) dx - \\beta \\int_{-\\infty}^{\\infty} x p(x,t) dx = \\alpha - \\beta \\mu(t).\n$$\n\nNext, we derive the time-evolution for the variance $\\sigma^{2}(t)$. It is more convenient to first find the equation for the second moment, $\\langle x^{2} \\rangle(t) = \\int_{-\\infty}^{\\infty} x^{2} p(x,t) dx$.\n$$\n\\frac{d\\langle x^{2} \\rangle}{dt} = \\int_{-\\infty}^{\\infty} x^{2} \\frac{\\partial p}{\\partial t} dx = \\int_{-\\infty}^{\\infty} x^{2} \\left[ -\\frac{\\partial}{\\partial x}(ap) + \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b^{2}p) \\right] dx.\n$$\nWe again evaluate the two terms. For the first term, using integration by parts with $u=x^{2}$ and $dv=-\\frac{\\partial}{\\partial x}(ap)dx$, we get $du=2xdx$ and $v=-ap$:\n$$\n\\int_{-\\infty}^{\\infty} x^{2} \\left[-\\frac{\\partial}{\\partial x}(ap)\\right] dx = \\big[-x^{2}ap\\big]_{-\\infty}^{\\infty} + \\int_{-\\infty}^{\\infty} 2x a(x) p dx = \\int_{-\\infty}^{\\infty} 2x a(x) p dx.\n$$\nFor the second term, we integrate by parts twice. First, with $u=x^{2}$ and $dv=\\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b^{2}p)dx$:\n$$\n\\int_{-\\infty}^{\\infty} x^{2} \\left[\\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}(b^{2}p)\\right] dx = \\left[x^{2} \\frac{1}{2}\\frac{\\partial}{\\partial x}(b^{2}p)\\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} (2x) \\frac{1}{2}\\frac{\\partial}{\\partial x}(b^{2}p) dx = -\\int_{-\\infty}^{\\infty} x \\frac{\\partial}{\\partial x}(b^{2}p) dx.\n$$\nIntegrating by parts again, with $u=x$ and $dv = -\\frac{\\partial}{\\partial x}(b^{2}p)dx$:\n$$\n-\\left( \\big[-x b^{2}p\\big]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} (-b^{2}p) dx \\right) = \\int_{-\\infty}^{\\infty} b(x)^{2} p(x,t) dx.\n$$\nCombining the results for $\\frac{d\\langle x^{2} \\rangle}{dt}$:\n$$\n\\frac{d\\langle x^{2} \\rangle}{dt} = \\int_{-\\infty}^{\\infty} 2x a(x) p dx + \\int_{-\\infty}^{\\infty} b(x)^{2} p dx.\n$$\nSubstituting $a(x) = \\alpha - \\beta x$ and $b(x)^{2} = 2D$:\n$$\n\\frac{d\\langle x^{2} \\rangle}{dt} = \\int_{-\\infty}^{\\infty} 2x(\\alpha - \\beta x) p dx + \\int_{-\\infty}^{\\infty} 2D p dx = 2\\alpha \\int x p dx - 2\\beta \\int x^{2} p dx + 2D \\int p dx.\n$$\nThis gives $\\frac{d\\langle x^{2} \\rangle}{dt} = 2\\alpha\\mu - 2\\beta\\langle x^{2} \\rangle + 2D$.\nNow, using the relationship $\\sigma^{2} = \\langle x^{2} \\rangle - \\mu^{2}$, we differentiate with respect to $t$:\n$$\n\\frac{d\\sigma^{2}}{dt} = \\frac{d\\langle x^{2} \\rangle}{dt} - 2\\mu \\frac{d\\mu}{dt}.\n$$\nSubstituting the derived expressions for $\\frac{d\\langle x^{2} \\rangle}{dt}$ and $\\frac{d\\mu}{dt}$:\n$$\n\\frac{d\\sigma^{2}}{dt} = (2\\alpha\\mu - 2\\beta\\langle x^{2} \\rangle + 2D) - 2\\mu(\\alpha - \\beta\\mu) = 2\\alpha\\mu - 2\\beta\\langle x^{2} \\rangle + 2D - 2\\alpha\\mu + 2\\beta\\mu^{2}.\n$$\n$$\n\\frac{d\\sigma^{2}}{dt} = 2D - 2\\beta(\\langle x^{2} \\rangle - \\mu^{2}) = 2D - 2\\beta\\sigma^{2}.\n$$\nThe resulting system of ODEs is:\n$$\n\\frac{d\\mu}{dt} = \\alpha - \\beta\\mu, \\qquad \\frac{d\\sigma^{2}}{dt} = 2D - 2\\beta\\sigma^{2}.\n$$\nThese two equations depend only on $\\mu(t)$ and $\\sigma^{2}(t)$ respectively, not on any higher-order moments. Thus, the system is closed.\n\nFinally, we solve these two first-order linear ODEs.\nFor $\\mu(t)$, the equation is $\\frac{d\\mu}{dt} + \\beta\\mu = \\alpha$. The general solution is the sum of a homogeneous solution $\\mu_h(t) = C_{1}\\exp(-\\beta t)$ and a particular solution. A constant particular solution is $\\mu_p(t) = \\alpha/\\beta$. Thus, $\\mu(t) = \\frac{\\alpha}{\\beta} + C_{1}\\exp(-\\beta t)$.\nUsing the initial condition $\\mu(0) = \\mu_{0}$:\n$$\n\\mu_{0} = \\frac{\\alpha}{\\beta} + C_{1} \\implies C_{1} = \\mu_{0} - \\frac{\\alpha}{\\beta}.\n$$\nSo, the solution for the mean is:\n$$\n\\mu(t) = \\frac{\\alpha}{\\beta} + \\left(\\mu_{0} - \\frac{\\alpha}{\\beta}\\right)\\exp(-\\beta t).\n$$\n\nFor $\\sigma^{2}(t)$, let $V(t) = \\sigma^{2}(t)$. The equation is $\\frac{dV}{dt} + 2\\beta V = 2D$. This is of the same form. The general solution is $V(t) = \\frac{2D}{2\\beta} + C_{2}\\exp(-2\\beta t) = \\frac{D}{\\beta} + C_{2}\\exp(-2\\beta t)$.\nUsing the initial condition $\\sigma^{2}(0) = \\sigma_{0}^{2}$:\n$$\n\\sigma_{0}^{2} = \\frac{D}{\\beta} + C_{2} \\implies C_{2} = \\sigma_{0}^{2} - \\frac{D}{\\beta}.\n$$\nSo, the solution for the variance is:\n$$\n\\sigma^{2}(t) = \\frac{D}{\\beta} + \\left(\\sigma_{0}^{2} - \\frac{D}{\\beta}\\right)\\exp(-2\\beta t).\n$$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{\\alpha}{\\beta} + \\left(\\mu_{0} - \\frac{\\alpha}{\\beta}\\right)\\exp(-\\beta t)  \\frac{D}{\\beta} + \\left(\\sigma_{0}^{2} - \\frac{D}{\\beta}\\right)\\exp(-2\\beta t) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The Fokker-Planck equation arises from an underlying stochastic differential equation (SDE), but the specific form of the FPE's drift term depends on how one interprets the noise. This is especially critical for multiplicative noise, where the choice between the Itô and Stratonovich frameworks has physical and mathematical consequences. This exercise provides hands-on practice in the essential skill of converting from the Stratonovich form, often more natural for physical modeling, to the mathematically convenient Itô form, revealing the subtle \"spurious drift\" term that arises from the conversion .",
            "id": "3936791",
            "problem": "In a single-cell receptor occupancy model, let $x(t) \\in (0,1)$ denote the fraction of receptors bound by a ligand at time $t$. Due to rapidly fluctuating biochemical microenvironments with finite correlation time, the coarse-grained noise is assumed to be interpreted in the Stratonovich sense. The occupancy dynamics are modeled by the Stratonovich stochastic differential equation (SDE)\n$$\ndx = a_{S}(x)\\,dt + b(x) \\circ dW_{t},\n$$\nwith drift\n$$\na_{S}(x) = k_{\\mathrm{on}}\\,c\\,\\big(1 - x\\big) - k_{\\mathrm{off}}\\,x,\n$$\nand multiplicative noise amplitude\n$$\nb(x) = \\sigma \\sqrt{x\\big(1 - x\\big)},\n$$\nwhere $k_{\\mathrm{on}}$ is the association rate constant, $c$ is the ligand concentration, $k_{\\mathrm{off}}$ is the dissociation rate constant, and $\\sigma$ quantifies extrinsic fluctuations. Assume the model is nondimensionalized so that all quantities are dimensionless.\n\nStarting from the definition of the Stratonovich integral as the limit of midpoint Riemann sums and from the Itô change-of-variables formula for smooth test functions $f(x)$, derive the equivalent Itô SDE\n$$\ndx = a_{I}(x)\\,dt + b(x)\\,dW_{t}\n$$\nthat generates the same Fokker–Planck equation (FPE) for the probability density as the given Stratonovich SDE. Then, using the specific forms of $a_{S}(x)$ and $b(x)$ given above, compute the explicit analytical expression for the Itô drift $a_{I}(x)$ as a function of $x$, $k_{\\mathrm{on}}$, $c$, $k_{\\mathrm{off}}$, and $\\sigma$.\n\nProvide your final answer as a single closed-form expression for $a_{I}(x)$. No numerical rounding is required. Do not include units in your final boxed answer.",
            "solution": "The problem as stated is subjected to validation.\n\n### Step 1: Extract Givens\n\nThe givens extracted verbatim from the problem statement are:\n-   The system is a single-cell receptor occupancy model.\n-   The state variable is $x(t) \\in (0,1)$, representing the fraction of receptors bound by a ligand at time $t$.\n-   The dynamics are modeled by the Stratonovich stochastic differential equation (SDE):\n    $$dx = a_{S}(x)\\,dt + b(x) \\circ dW_{t}$$\n-   The Stratonovich drift is:\n    $$a_{S}(x) = k_{\\mathrm{on}}\\,c\\,\\big(1 - x\\big) - k_{\\mathrm{off}}\\,x$$\n-   The multiplicative noise amplitude is:\n    $$b(x) = \\sigma \\sqrt{x\\big(1 - x\\big)}$$\n-   The parameters are the association rate constant $k_{\\mathrm{on}}$, the ligand concentration $c$, the dissociation rate constant $k_{\\mathrm{off}}$, and the extrinsic fluctuation strength $\\sigma$. All quantities are dimensionless.\n-   The task is to derive the equivalent Itô SDE $dx = a_{I}(x)\\,dt + b(x)\\,dW_{t}$ and compute the explicit analytical expression for the Itô drift $a_{I}(x)$.\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientifically Grounded**: The problem is firmly rooted in the field of quantitative systems biology and stochastic processes. The model describes receptor-ligand kinetics, a fundamental biological process. The use of a Stratonovich SDE is appropriate for modeling systems where the noise has a non-zero, finite correlation time, which is then coarse-grained. The conversion to an equivalent Itô SDE is a standard and essential procedure in the analysis of such systems. The functional forms of the drift (mass-action kinetics) and diffusion (proportional to $\\sqrt{x(1-x)}$, characteristic of binomial-type fluctuations) are standard and physically plausible for a fractional occupancy $x$.\n-   **Well-Posed**: The problem is mathematically well-defined. It provides all necessary functions and parameters to perform the requested derivation and calculation. The objective is unambiguous: find the analytical form of the Itô drift $a_{I}(x)$. A unique solution exists and can be determined from the provided information.\n-   **Objective**: The problem is stated in precise, formal mathematical language, free from any subjectivity or ambiguity.\n\n### Step 3: Verdict and Action\n\nThe problem is scientifically sound, well-posed, and objective. It contains no contradictions, missing information, or other flaws listed in the validation checklist. Therefore, the problem is deemed **valid**. I will proceed with the solution.\n\n### Solution Derivation\n\nThe problem requires finding the drift term $a_{I}(x)$ of an Itô SDE,\n$$dx = a_{I}(x)\\,dt + b(x)\\,dW_{t}$$\nthat is equivalent to the given Stratonovich SDE,\n$$dx = a_{S}(x)\\,dt + b(x) \\circ dW_{t}$$\nEquivalence here means that both SDEs generate the same Fokker-Planck equation for the probability density of $x$, and thus describe the same stochastic process. The conversion between Stratonovich and Itô representations is a fundamental result in stochastic calculus. The relationship between the drift terms is given by the Itô-Stratonovich correction formula. We will derive this relationship as requested.\n\nThe Stratonovich integral, denoted by the symbol $\\circ$, is defined as the limit of a sum where the integrand is evaluated at the midpoint of each time interval:\n$$ \\int_{0}^{t} b(x(\\tau)) \\circ dW_{\\tau} = \\lim_{\\Delta t \\to 0} \\sum_{i} b\\left(\\frac{x(t_{i+1}) + x(t_{i})}{2}\\right) (W_{t_{i+1}} - W_{t_{i}}) $$\nLet $\\Delta W_i = W_{t_{i+1}} - W_{t_{i}}$ and $x_i = x(t_i)$. We can Taylor expand the function $b(x)$ around the point $x_i$:\n$$ b\\left(\\frac{x_{i+1} + x_i}{2}\\right) \\approx b(x_i) + b'(x_i) \\left(\\frac{x_{i+1} + x_i}{2} - x_i\\right) = b(x_i) + \\frac{1}{2} b'(x_i) (x_{i+1} - x_i) $$\nIn the limit $\\Delta t \\to 0$, the increment $\\Delta x_i = x_{i+1} - x_i$ is approximated by the dominant stochastic part of the SDE, which is given in the Itô sense by $b(x_i) \\Delta W_i$. The deterministic part, being of order $\\Delta t$, contributes a term of order $\\Delta t \\Delta W_i \\sim (\\Delta t)^{3/2}$, which vanishes faster than the stochastic term. So, we approximate $\\Delta x_i \\approx b(x_i) \\Delta W_i$. Substituting this into the expansion gives:\n$$ b\\left(\\frac{x_{i+1} + x_i}{2}\\right) \\approx b(x_i) + \\frac{1}{2} b'(x_i) b(x_i) \\Delta W_i $$\nNow, substituting this back into the sum for the Stratonovich integral:\n$$ \\sum_{i} \\left( b(x_i) + \\frac{1}{2} b'(x_i) b(x_i) \\Delta W_i \\right) \\Delta W_i = \\sum_{i} b(x_i) \\Delta W_i + \\sum_{i} \\frac{1}{2} b(x_i) b'(x_i) (\\Delta W_i)^2 $$\nIn the limit $\\Delta t \\to 0$, the first term becomes the Itô integral $\\int_{0}^{t} b(x(\\tau))\\,dW_{\\tau}$. For the second term, we use the property of the quadratic variation of Brownian motion, which states that $(\\Delta W_i)^2$ approaches $dt$ in the limit. Thus, the second sum converges to a standard Riemann integral:\n$$ \\lim_{\\Delta t \\to 0} \\sum_{i} \\frac{1}{2} b(x_i) b'(x_i) (\\Delta W_i)^2 = \\int_{0}^{t} \\frac{1}{2} b(x(\\tau)) b'(x(\\tau))\\,d\\tau $$\nCombining these results, we find the relationship between the Stratonovich and Itô integrals:\n$$ \\int_{0}^{t} b(x) \\circ dW_{\\tau} = \\int_{0}^{t} b(x) \\,dW_{\\tau} + \\int_{0}^{t} \\frac{1}{2} b(x) b'(x)\\,d\\tau $$\nSubstituting this into the original Stratonovich SDE:\n$$ dx = a_{S}(x)\\,dt + \\left( \\frac{1}{2} b(x) b'(x)\\,dt + b(x)\\,dW_{t} \\right) $$\n$$ dx = \\left( a_{S}(x) + \\frac{1}{2}b(x)b'(x) \\right)dt + b(x)\\,dW_{t} $$\nBy comparing this with the Itô SDE form $dx = a_{I}(x)\\,dt + b(x)\\,dW_{t}$, we identify the Itô drift as:\n$$ a_{I}(x) = a_{S}(x) + \\frac{1}{2} b(x) b'(x) $$\nThe term $\\frac{1}{2} b(x) b'(x)$ is the noise-induced drift correction.\n\nNow, we apply this formula to the specific functions given in the problem. The Stratonovich drift is:\n$$ a_{S}(x) = k_{\\mathrm{on}}\\,c\\,\\big(1 - x\\big) - k_{\\mathrm{off}}\\,x $$\nThe noise amplitude is:\n$$ b(x) = \\sigma \\sqrt{x(1 - x)} = \\sigma (x - x^2)^{1/2} $$\nWe need to compute the derivative of $b(x)$ with respect to $x$:\n$$ b'(x) = \\frac{d}{dx} \\left[ \\sigma (x - x^2)^{1/2} \\right] = \\sigma \\cdot \\frac{1}{2} (x - x^2)^{-1/2} \\cdot \\frac{d}{dx}(x - x^2) $$\n$$ b'(x) = \\sigma \\cdot \\frac{1}{2} (x - x^2)^{-1/2} \\cdot (1 - 2x) = \\frac{\\sigma(1 - 2x)}{2 \\sqrt{x(1 - x)}} $$\nNext, we compute the correction term $\\frac{1}{2} b(x) b'(x)$:\n$$ \\frac{1}{2} b(x) b'(x) = \\frac{1}{2} \\left(\\sigma \\sqrt{x(1 - x)}\\right) \\left(\\frac{\\sigma(1 - 2x)}{2 \\sqrt{x(1 - x)}}\\right) $$\nSince $x \\in (0,1)$, the term $\\sqrt{x(1 - x)}$ is non-zero and cancels out:\n$$ \\frac{1}{2} b(x) b'(x) = \\frac{1}{2} \\cdot \\sigma \\cdot \\frac{\\sigma(1 - 2x)}{2} = \\frac{\\sigma^2}{4}(1 - 2x) $$\nFinally, we construct the Itô drift $a_{I}(x)$ by adding the correction term to the Stratonovich drift $a_{S}(x)$:\n$$ a_{I}(x) = a_{S}(x) + \\frac{1}{2} b(x) b'(x) $$\n$$ a_{I}(x) = \\left( k_{\\mathrm{on}}\\,c\\,(1 - x) - k_{\\mathrm{off}}\\,x \\right) + \\frac{\\sigma^2}{4}(1 - 2x) $$\nThis expression represents the full drift term for the equivalent Itô SDE.",
            "answer": "$$\n\\boxed{k_{\\mathrm{on}}\\,c\\,(1 - x) - k_{\\mathrm{off}}\\,x + \\frac{\\sigma^2}{4}(1 - 2x)}\n$$"
        },
        {
            "introduction": "While analytical solutions provide invaluable insight, most FPEs encountered in realistic biomedical models do not have simple closed-form solutions and must be tackled numerically. This practice bridges the gap between theory and computation, guiding you through the implementation of an elegant and powerful spectral method to solve the FPE for the Ornstein-Uhlenbeck process. By using the operator's natural basis functions—the Hermite polynomials—you will build a highly efficient solver and quantitatively analyze its convergence, a key skill for any computational modeler .",
            "id": "3936826",
            "problem": "Consider a one-dimensional Ornstein-Uhlenbeck process used in biomedical systems modeling to represent linearized fluctuations of a biomarker concentration around homeostasis, modeled by the stochastic differential equation $dX_t = -\\theta X_t \\, dt + \\sqrt{2D} \\, dW_t$, where $X_t$ is the state, $\\theta > 0$ is the linear relaxation rate, $D > 0$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. The corresponding Fokker-Planck equation (FPE) for the probability density $p(x,t)$ is\n$$\n\\partial_t p(x,t) = \\theta \\, \\partial_x \\big(x p(x,t)\\big) + D \\, \\partial_{xx} p(x,t)\n$$\nDefine the stationary variance $\\sigma_s^2 = D/\\theta$ and the scaled coordinate $\\xi = x/\\sigma_s$. Let $\\varphi(\\xi)$ denote the standard normal density in $\\xi$, and let $\\mathrm{He}_n(\\xi)$ denote the probabilists' Hermite polynomials, which form an orthogonal polynomial family with respect to $\\varphi(\\xi)$.\n\nYour tasks are:\n1. Starting from the FPE and using projection onto the Hermite polynomial basis in the scaled coordinate $\\xi$, derive a spectral method to approximate the transient density $p(x,t)$ for an initial condition concentrated at $x = x_0$ (mathematically modeled by a Dirac delta at $x_0$). Explicitly show how to construct the truncated spectral approximation in terms of the basis functions and time-dependent coefficients without relying on any pre-given shortcut formulas.\n2. Using the exact transient solution for the Ornstein-Uhlenbeck process with the given parameters, compute the squared-integral error (the $\\mathcal{L}^2$ error norm) between your truncated spectral approximation and the exact density over a sufficiently large finite interval of $x$. Quantify the empirical spectral convergence rate by fitting a linear model to the logarithm of the error versus the truncation order.\n3. Analyze the convergence to the stationary density by computing the $\\mathcal{L}^2$ error between the exact transient density and the stationary density for increasing times, and estimate the exponential decay rate by fitting a linear model to the logarithm of the error versus time.\n\nAll variables must be treated as dimensionless in this problem, so no physical units are required. Angles are not involved. Percentages are not involved; all reported quantities must be decimals.\n\nImplementation requirements:\n- Represent the scaled stationary density in terms of $\\varphi(\\xi)$ and construct the Hermite basis $\\{\\mathrm{He}_n(\\xi)\\}_{n=0}^N$ via its recurrence. Use the orthogonality of $\\mathrm{He}_n$ under the weight $\\varphi(\\xi)$ to obtain evolution equations for the spectral coefficients associated with the initial condition at $x_0$.\n- For numerical integration of errors, use a symmetric grid $x \\in [-L,L]$ with a spacing $\\Delta x$ sufficiently small to capture the tails of the exact Gaussian densities at all required times. Choose $L$ conservatively based on the largest standard deviation encountered and the mean displacement to ensure negligible truncation error.\n- Estimate convergence rates by ordinary least squares regression of $\\log(\\text{error})$ on the independent variable (either truncation order $N$ or time $t$).\n\nTest suite:\n- Stationary convergence rate cases: Use $D = 1.0$, $x_0 = 2.0$, times $t \\in \\{0.3, 0.6, 1.0, 1.5\\}$, and estimate the decay rate for each of the following relaxation rates:\n  - Case S1: $\\theta = 0.5$\n  - Case S2: $\\theta = 1.0$\n  - Case S3: $\\theta = 2.0$\n  For each case, output the single estimated decay rate (a float).\n- Transient spectral convergence rate cases: Use $D = 1.0$, truncation orders $N \\in \\{2, 4, 8, 12, 16, 24, 32\\}$, and estimate the spectral convergence rate (decay rate of the error with increasing $N$) for:\n  - Case T1: $\\theta = 1.0$, $x_0 = 2.0$, $t = 0.3$\n  - Case T2: $\\theta = 1.0$, $x_0 = 2.0$, $t = 0.8$\n  - Case T3: $\\theta = 1.0$, $x_0 = 4.0$, $t = 0.8$\n  For each case, output the single estimated rate (a float).\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,...]\"), ordered as [S1,S2,S3,T1,T2,T3]. Each result must be a float.",
            "solution": "The user-provided problem is assessed to be **valid**. It is scientifically sound, self-contained, and well-posed. The problem statement is grounded in the established theory of stochastic processes (the Ornstein-Uhlenbeck process) and its description via the Fokker-Planck equation. The proposed tasks—deriving a spectral approximation, analyzing its convergence, and analyzing the relaxation to the stationary state—are standard and rigorous exercises in computational science and theoretical biophysics. The parameters and conditions are specified clearly, and the required numerical procedures are well-defined.\n\nThe solution proceeds in three main parts: 1) derivation of the spectral method equations, 2) formulation of the error analysis for both convergence to stationarity and spectral convergence, and 3) description of the numerical implementation.\n\n### 1. Derivation of the Spectral Method\n\nThe starting point is the Fokker-Planck equation (FPE) for the probability density $p(x,t)$ of a one-dimensional Ornstein-Uhlenbeck process:\n$$ \\partial_t p(x,t) = \\theta \\, \\partial_x \\big(x p(x,t)\\big) + D \\, \\partial_{xx} p(x,t) $$\nwhere $\\theta > 0$ is the relaxation rate and $D > 0$ is the diffusion coefficient.\n\nFirst, we non-dimensionalize the spatial coordinate. The stationary distribution for this process is a zero-mean Gaussian with variance $\\sigma_s^2 = D/\\theta$. We define a scaled coordinate $\\xi = x/\\sigma_s$. The probability density in this new coordinate, $q(\\xi,t)$, is related to $p(x,t)$ by $p(x,t)dx = q(\\xi,t)d\\xi$, which implies $p(x,t) = q(\\xi,t)/\\sigma_s$. The derivatives transform as $\\partial_x = (1/\\sigma_s)\\partial_\\xi$ and $\\partial_{xx} = (1/\\sigma_s^2)\\partial_{\\xi\\xi}$. Substituting these into the FPE yields:\n$$ \\frac{1}{\\sigma_s} \\partial_t q(\\xi, t) = \\theta \\frac{1}{\\sigma_s} \\partial_\\xi \\left( (\\xi \\sigma_s) \\frac{q(\\xi, t)}{\\sigma_s} \\right) + D \\frac{1}{\\sigma_s^2} \\partial_{\\xi\\xi} \\left( \\frac{q(\\xi, t)}{\\sigma_s} \\right) $$\nMultiplying by $\\sigma_s$ and using $\\sigma_s^2 = D/\\theta$ simplifies the equation to:\n$$ \\partial_t q(\\xi, t) = \\theta \\left[ \\partial_\\xi (\\xi q(\\xi, t)) + \\partial_{\\xi\\xi} q(\\xi, t) \\right] = \\theta \\mathcal{L}_{FP} q(\\xi, t) $$\nwhere $\\mathcal{L}_{FP} = \\partial_\\xi (\\xi \\cdot) + \\partial_{\\xi\\xi}$ is the Fokker-Planck operator in the scaled coordinate.\n\nThe stationary solution $q_s(\\xi)$ satisfies $\\mathcal{L}_{FP} q_s(\\xi) = 0$, which yields the standard normal density $\\varphi(\\xi)$:\n$$ q_s(\\xi) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\xi^2/2} = \\varphi(\\xi) $$\n\nWe seek a solution for the transient density $q(\\xi,t)$ using a spectral expansion in the basis of probabilists' Hermite polynomials, $\\{\\mathrm{He}_n(\\xi)\\}$, which are orthogonal with respect to the weight function $\\varphi(\\xi)$. We write the solution as:\n$$ q(\\xi,t) = \\varphi(\\xi) \\sum_{n=0}^{\\infty} c_n(t) \\mathrm{He}_n(\\xi) $$\nSubstituting this into the scaled FPE and factoring out $\\varphi(\\xi)$ leads to an evolution equation for the sum:\n$$ \\partial_t \\left( \\sum_{n=0}^{\\infty} c_n(t) \\mathrm{He}_n(\\xi) \\right) = \\theta \\left( \\partial_{\\xi\\xi} - \\xi \\partial_\\xi \\right) \\left( \\sum_{n=0}^{\\infty} c_n(t) \\mathrm{He}_n(\\xi) \\right) $$\nThe differential operator $\\mathcal{H} = \\partial_{\\xi\\xi} - \\xi \\partial_\\xi$ is the generator for the Hermite polynomials, which are its eigenfunctions with eigenvalues $-n$: $\\mathcal{H} \\mathrm{He}_n(\\xi) = -n \\mathrm{He}_n(\\xi)$. Applying this property, we get:\n$$ \\sum_{n=0}^{\\infty} \\frac{dc_n(t)}{dt} \\mathrm{He}_n(\\xi) = \\sum_{n=0}^{\\infty} c_n(t) (-\\theta n) \\mathrm{He}_n(\\xi) $$\nBy the orthogonality of the Hermite polynomials, we can equate the coefficients for each mode $n$:\n$$ \\frac{dc_n(t)}{dt} = -n\\theta c_n(t) $$\nThis is a set of uncoupled ordinary differential equations with solutions $c_n(t) = c_n(0) e^{-n\\theta t}$.\n\nTo find the initial coefficients $c_n(0)$, we project the initial condition onto the basis. The initial condition is a Dirac delta function at $x=x_0$, which is $p(x,0) = \\delta(x-x_0)$. In scaled coordinates, $q(\\xi,0) = \\delta(\\xi - \\xi_0)$, where $\\xi_0 = x_0/\\sigma_s$. Using the orthogonality relation $\\int \\mathrm{He}_n(\\xi)\\mathrm{He}_m(\\xi)\\varphi(\\xi)d\\xi = n!\\delta_{nm}$:\n$$ c_n(0) = \\frac{1}{n!} \\int_{-\\infty}^{\\infty} q(\\xi,0) \\mathrm{He}_n(\\xi) d\\xi = \\frac{1}{n!} \\int_{-\\infty}^{\\infty} \\delta(\\xi-\\xi_0) \\mathrm{He}_n(\\xi) d\\xi = \\frac{\\mathrm{He}_n(\\xi_0)}{n!} $$\nThus, the time-dependent coefficients are $c_n(t) = \\frac{\\mathrm{He}_n(\\xi_0)}{n!} e^{-n\\theta t}$. The spectral approximation of order $N$ is obtained by truncating the series:\n$$ p_{approx, N}(x,t) = \\frac{q_N(\\xi,t)}{\\sigma_s} = \\frac{\\varphi(\\xi)}{\\sigma_s} \\sum_{n=0}^{N} \\frac{\\mathrm{He}_n(\\xi_0)}{n!} e^{-n\\theta t} \\mathrm{He}_n(\\xi) $$\n\n### 2. Error Analysis and Convergence Metrics\n\nThe exact solution to the SDE for an initial condition $X_0 = x_0$ is a Gaussian process. The probability density $p_{exact}(x,t)$ is a normal distribution with time-dependent mean $\\mu(t)$ and variance $\\sigma^2(t)$:\n$$ \\mu(t) = x_0 e^{-\\theta t} \\quad , \\quad \\sigma^2(t) = \\frac{D}{\\theta}(1 - e^{-2\\theta t}) = \\sigma_s^2(1 - e^{-2\\theta t}) $$\n$$ p_{exact}(x,t) = \\mathcal{N}(x; \\mu(t), \\sigma^2(t)) = \\frac{1}{\\sqrt{2\\pi \\sigma^2(t)}} \\exp\\left( - \\frac{(x - \\mu(t))^2}{2 \\sigma^2(t)} \\right) $$\nThe stationary density is the limit as $t \\to \\infty$: $p_s(x) = \\mathcal{N}(x; 0, \\sigma_s^2)$.\n\n**Stationary Convergence:** To analyze the convergence to the stationary density, we compute the $\\mathcal{L}^2$ error norm between the transient and stationary exact solutions:\n$$ E_s(t) = \\left( \\int_{-\\infty}^{\\infty} [p_{exact}(x,t) - p_s(x)]^2 dx \\right)^{1/2} $$\nThe decay is expected to be exponential for large $t$, i.e., $E_s(t) \\sim e^{-\\beta t}$. We estimate the decay rate $\\beta$ by performing an ordinary least squares regression on $\\log(E_s(t))$ versus $t$. The rate $\\beta$ is the negative of the resulting slope. Theoretically, the slowest decaying mode in the spectral expansion is for $n=1$, which decays as $e^{-\\theta t}$, so we expect the estimated rate $\\beta$ to be close to $\\theta$.\n\n**Spectral Convergence:** To quantify the performance of the spectral approximation, we compute the $\\mathcal{L}^2$ error norm between the truncated approximation and the exact solution at a given time $t$:\n$$ E_N(t) = \\left( \\int_{-\\infty}^{\\infty} [p_{approx, N}(x,t) - p_{exact}(x,t)]^2 dx \\right)^{1/2} $$\nFor a smooth function like the Gaussian exact solution (for $t > 0$), spectral methods exhibit exponential convergence, i.e., $E_N(t) \\sim e^{-\\alpha N}$. The spectral convergence rate $\\alpha$ is estimated by performing a linear regression on $\\log(E_N(t))$ versus the truncation order $N$. The rate $\\alpha$ is the negative of the slope.\n\n### 3. Numerical Implementation\n\n- **Grid and Integration:** A uniform spatial grid $x \\in [-L, L]$ is used. The interval half-width $L$ is chosen to be sufficiently large (e.g., $L=20$) to contain the probability mass for all considered parameter sets and times. The grid spacing $\\Delta x$ is chosen small enough (e.g., $\\Delta x = 0.01$) to accurately resolve the shape of the narrowest density function. Integrals for the $\\mathcal{L}^2$ error are computed numerically using the trapezoidal rule, which on a uniform grid corresponds to summing the squared differences and multiplying by $\\Delta x$.\n- **Hermite Polynomials:** The probabilists' Hermite polynomials $\\mathrm{He}_n(\\xi)$ are generated using the three-term recurrence relation:\n$$ \\mathrm{He}_{n+1}(\\xi) = \\xi \\mathrm{He}_n(\\xi) - n \\mathrm{He}_{n-1}(\\xi) $$\nwith initial polynomials $\\mathrm{He}_0(\\xi)=1$ and $\\mathrm{He}_1(\\xi)=\\xi$.\n- **Linear Regression:** The slope $m$ for pairs of data $(x_i, y_i)$ is computed using the standard ordinary least squares formula:\n$$ m = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum (x_i - \\bar{x})^2} $$\nwhere $\\bar{x}$ and $\\bar{y}$ are the sample means. The convergence or decay rate is then given by $-m$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef linear_regression_slope(x_data, y_data):\n    \"\"\"\n    Computes the slope of the best-fit line for y = a + b*x using OLS.\n    \"\"\"\n    x_mean = np.mean(x_data)\n    y_mean = np.mean(y_data)\n    cov_xy = np.sum((x_data - x_mean) * (y_data - y_mean))\n    var_x = np.sum((x_data - x_mean)**2)\n    if var_x == 0.0:\n        return 0.0\n    return cov_xy / var_x\n\ndef exact_density(x, t, x0, D, theta):\n    \"\"\"\n    Computes the exact transient probability density of the OU process.\n    \"\"\"\n    if t == 0:\n        # Handle the initial delta function case crudely, not used in error calcs.\n        pdf = np.zeros_like(x)\n        idx = np.argmin(np.abs(x-x0))\n        if idx  len(pdf):\n            pdf[idx] = 1.0 / (x[1]-x[0])\n        return pdf\n    \n    mean_t = x0 * np.exp(-theta * t)\n    var_t = (D / theta) * (1 - np.exp(-2 * theta * t))\n    \n    if var_t = 0:\n         # Simplified handling for t-0 limit where variance can be numerically unstable\n        pdf = np.zeros_like(x)\n        idx = np.argmin(np.abs(x-mean_t))\n        if idx  len(pdf):\n            pdf[idx] = 1.0 / (x[1]-x[0])\n        return pdf\n\n    std_t = np.sqrt(var_t)\n    pdf = (1.0 / (std_t * np.sqrt(2 * np.pi))) * \\\n          np.exp(-(x - mean_t)**2 / (2 * var_t))\n    return pdf\n\ndef stationary_density(x, D, theta):\n    \"\"\"\n    Computes the stationary probability density of the OU process.\n    \"\"\"\n    var_s = D / theta\n    std_s = np.sqrt(var_s)\n    pdf = (1.0 / (std_s * np.sqrt(2 * np.pi))) * \\\n          np.exp(-x**2 / (2 * var_s))\n    return pdf\n\ndef generate_hermite_basis(N_max, x_vals):\n    \"\"\"\n    Generates probabilists' Hermite polynomials He_n(x) up to order N_max.\n    \"\"\"\n    if N_max  0:\n        return np.empty((0, len(x_vals)))\n    \n    basis = np.zeros((N_max + 1, len(x_vals)))\n    basis[0, :] = 1.0\n    if N_max  0:\n        basis[1, :] = x_vals\n    for n in range(1, N_max):\n        # Recurrence: He_{n+1}(x) = x * He_n(x) - n * He_{n-1}(x)\n        basis[n + 1, :] = x_vals * basis[n, :] - n * basis[n - 1, :]\n    return basis\n\ndef spectral_approx(x, t, N, x0, D, theta):\n    \"\"\"\n    Computes the spectral approximation of the transient density.\n    \"\"\"\n    sigma_s_sq = D / theta\n    sigma_s = np.sqrt(sigma_s_sq)\n    \n    xi = x / sigma_s\n    xi0 = x0 / sigma_s\n\n    # Generate Hermite polynomials evaluated at xi and xi0\n    he_vals_xi = generate_hermite_basis(N, xi)\n    he_vals_xi0 = generate_hermite_basis(N, np.array([xi0]))[:, 0]\n\n    # Compute coefficients c_n(t)\n    c_n = np.zeros(N + 1)\n    fact = 1.0\n    for n in range(N + 1):\n        if n  0:\n            fact *= n\n        c_n[n] = (he_vals_xi0[n] / fact) * np.exp(-n * theta * t)\n        \n    # Reconstruct the density\n    # f_N = sum_n c_n(t) * He_n(xi)\n    f_N = np.dot(c_n, he_vals_xi)\n    \n    # q_N(xi, t) = phi(xi) * f_N(xi, t)\n    phi_xi = (1.0 / np.sqrt(2 * np.pi)) * np.exp(-xi**2 / 2.0)\n    q_N = phi_xi * f_N\n    \n    # p_approx(x,t) = q_N(xi,t) / sigma_s\n    p_approx = q_N / sigma_s\n    return p_approx\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and produce the final output.\n    \"\"\"\n    results = []\n\n    # Numerical grid setup\n    L = 20.0\n    num_points = 4001\n    x_grid = np.linspace(-L, L, num_points)\n    dx = x_grid[1] - x_grid[0]\n\n    # --- Part 1: Stationary Convergence Rate Cases ---\n    s_params = {\n        'D': 1.0,\n        'x0': 2.0,\n        'times': np.array([0.3, 0.6, 1.0, 1.5]),\n    }\n    s_cases = [\n        {'theta': 0.5},  # Case S1\n        {'theta': 1.0},  # Case S2\n        {'theta': 2.0},  # Case S3\n    ]\n\n    for case in s_cases:\n        D = s_params['D']\n        x0 = s_params['x0']\n        times = s_params['times']\n        theta = case['theta']\n        \n        errors = []\n        p_stat = stationary_density(x_grid, D, theta)\n        \n        for t in times:\n            p_exact = exact_density(x_grid, t, x0, D, theta)\n            error_sq_integral = np.sum((p_exact - p_stat)**2) * dx\n            errors.append(np.sqrt(error_sq_integral))\n        \n        log_errors = np.log(np.array(errors))\n        slope = linear_regression_slope(times, log_errors)\n        decay_rate = -slope\n        results.append(decay_rate)\n        \n    # --- Part 2: Transient Spectral Convergence Rate Cases ---\n    t_params = {\n        'D': 1.0,\n        'N_orders': np.array([2, 4, 8, 12, 16, 24, 32]),\n    }\n    t_cases = [\n        {'theta': 1.0, 'x0': 2.0, 't': 0.3}, # Case T1\n        {'theta': 1.0, 'x0': 2.0, 't': 0.8}, # Case T2\n        {'theta': 1.0, 'x0': 4.0, 't': 0.8}, # Case T3\n    ]\n\n    for case in t_cases:\n        D = t_params['D']\n        N_orders = t_params['N_orders']\n        theta = case['theta']\n        x0 = case['x0']\n        t = case['t']\n\n        errors = []\n        p_exact = exact_density(x_grid, t, x0, D, theta)\n\n        for N in N_orders:\n            p_approx = spectral_approx(x_grid, t, N, x0, D, theta)\n            error_sq_integral = np.sum((p_approx - p_exact)**2) * dx\n            errors.append(np.sqrt(error_sq_integral))\n            \n        log_errors = np.log(np.array(errors))\n        slope = linear_regression_slope(N_orders, log_errors)\n        convergence_rate = -slope\n        results.append(convergence_rate)\n        \n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}