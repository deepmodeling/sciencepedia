{
    "hands_on_practices": [
        {
            "introduction": "In agent-based models of immunity or disease, interactions between agents—such as a T cell encountering a cancer cell—are the fundamental events that drive system dynamics. This exercise provides a foundational tool for quantifying the rate of these events by linking microscopic model parameters, like agent density $\\rho$ and interaction radius $r$, to the expected number of contacts. By treating agent locations as a Poisson point process, a standard and powerful assumption for spatially random systems, you will derive a crucial formula for model calibration and analysis. ",
            "id": "3870809",
            "problem": "Consider a two-dimensional ($2$-D) off-lattice Agent-Based Model (ABM) of immune effector cells surveying a tumor monolayer. At each discrete time step, assume the instantaneous positions of all agents are distributed as a homogeneous Poisson point process on the plane with intensity $\\rho$ (agents per unit area), reflecting motility-driven spatial randomness and the absence of spatial correlation at the scale of interest. A binary \"contact\" is recorded for a focal agent whenever another agent lies within an interaction radius $r$ of the focal agent's position at that time step. Assume the focal agent is located at least a distance $r$ from any boundary so that edge effects are negligible, and that self-contact is excluded. Using only fundamental properties of the homogeneous Poisson point process and standard definitions, derive a closed-form analytic expression, in terms of $\\rho$ and $r$, for the expected number of agent-agent contacts observed by this focal agent in a single time step. Express your final answer as an exact analytic expression. The expected number of contacts is a dimensionless quantity; no rounding is required.",
            "solution": "The problem asks for the derivation of the expected number of agent-agent contacts for a focal agent in a single, discrete time step. The agent positions are modeled as a homogeneous Poisson point process.\n\nLet the set of agent positions on the two-dimensional plane, $\\mathbb{R}^{2}$, be a realization of a homogeneous Poisson point process, denoted by $\\Phi$, with a constant intensity $\\rho$. The intensity $\\rho$ represents the average number of agents per unit area.\n\nA \"contact\" event for a focal agent is defined by the presence of at least one other agent within a circular region of radius $r$ centered on the focal agent. We are tasked with finding the expected number of such contacts, which is equivalent to finding the expected number of other agents within this circular region.\n\nDue to the stationarity (or spatial homogeneity) of the Poisson point process, the statistical properties of the process are invariant under translation. This allows us to place the focal agent at any convenient location without loss of generality. We choose the origin, $(0,0)$, as the position of our focal agent.\n\nThe problem specifies that self-contact is excluded. This is a critical detail. We are interested in the number of agents from the process $\\Phi$ that fall within the interaction region, given that our focal agent (which is itself a point of $\\Phi$) is at the origin. A fundamental property of a stationary Poisson point process, a consequence of the Slivnyak-Mecke theorem, states that conditioning on a point of the process existing at the origin does not change the distribution of the remaining points. Therefore, the positions of all *other* agents still constitute a homogeneous Poisson point process with the same intensity $\\rho$.\n\nThe region of interaction around the focal agent at the origin is an open disk of radius $r$, which we denote as $D_r$. The area of this disk, $A(D_r)$, is given by:\n$$A(D_r) = \\pi r^{2}$$\nThe problem states that we can neglect edge effects, which justifies our use of a complete disk on the infinite plane $\\mathbb{R}^{2}$.\n\nLet $N_c$ be the random variable representing the number of contacts for the focal agent. This is precisely the number of other agents located within the disk $D_r$. For a homogeneous Poisson point process with intensity $\\rho$, the number of points in any bounded region $B \\subset \\mathbb{R}^{2}$, let's call this count $N(B)$, follows a Poisson distribution. The expected value (mean) of this distribution is given by the product of the intensity and the area of the region:\n$$E[N(B)] = \\rho \\cdot \\text{Area}(B)$$\n\nApplying this property to our problem, the number of contacts $N_c$ is the number of points from the process of \"other agents\" (which has intensity $\\rho$) that fall into the region $D_r$. The expected number of contacts, $E[N_c]$, is therefore:\n$$E[N_c] = \\rho \\cdot A(D_r)$$\nSubstituting the expression for the area of the disk, we obtain the final expression:\n$$E[N_c] = \\rho \\pi r^{2}$$\nThis expression is a closed-form analytic result in terms of the given parameters $\\rho$ and $r$. The dimensional consistency is confirmed as $\\rho$ has dimensions of $[\\text{length}]^{-2}$ and $r^{2}$ has dimensions of $[\\text{length}]^{2}$, resulting in a dimensionless quantity for the expected number of contacts, as required by the problem statement.",
            "answer": "$$\\boxed{\\rho \\pi r^{2}}$$"
        },
        {
            "introduction": "A central question in immunology is whether a small clone of lymphocytes can expand to control an infection or if it will fail due to random chance. This hands-on coding exercise explores this question using the Galton-Watson branching process, a classic model for population growth. You will implement simulations that go beyond simple averages to reveal how the inherent randomness, or variance, in cell division and death can lead to stochastic extinction, even when the clone is expected to grow. This practice highlights a critical, non-intuitive principle: in stochastic systems, the mean behavior is not the whole story. ",
            "id": "3870786",
            "problem": "Consider a Galton–Watson branching process modeling the size of a lymphocyte clone during an adaptive immune response. The process starts with a single progenitor at generation $0$, and proceeds in discrete generations. Each cell independently produces a random number of offspring cells in the next generation according to a specified offspring distribution with finite mean and variance. Let $Z_t$ denote the clone size at generation $t$. Assume independence among offspring counts and identical distribution across all cells and generations.\n\nUse only fundamental laws and core definitions from probability, including the definition of a Galton–Watson process, the law of iterated (tower) expectation, the law of total variance, and the properties of the probability generating function (PGF). Do not introduce ad hoc or shortcut formulas without derivation from these bases.\n\nTasks to be solved for each test case:\n- Derive an expression for $\\mathbb{E}[Z_t]$ in terms of the offspring mean $m$ and the generation index $t$.\n- Derive an expression for $\\mathrm{Var}(Z_t)$ in terms of the offspring mean $m$, the offspring variance $\\sigma^2$, and the generation index $t$.\n- Compute the time-limited immune failure risk at deadline $t$, defined here as the probability that the clone is absent at the deadline, namely $\\mathbb{P}(Z_t=0)$. Use the PGF composition principle for Galton–Watson processes and evaluate this probability exactly via $t$-fold composition of the offspring PGF evaluated at $0$.\n\nOffspring distributions to be used are standard, with definitions given below. For each distribution, also use its PGF to compute $\\mathbb{P}(Z_t=0)$ by composition:\n- Poisson with parameter $\\lambda$: support $\\{0,1,2,\\dots\\}$, mean $m=\\lambda$, variance $\\sigma^2=\\lambda$, PGF $f(s)=\\exp\\{\\lambda(s-1)\\}$.\n- Geometric with parameter $p$ on $\\{0,1,2,\\dots\\}$, interpreted as the number of failures before the first success in independent Bernoulli($p$) trials: mean $m=(1-p)/p$, variance $\\sigma^2=(1-p)/p^2$, PGF $f(s)=\\dfrac{p}{1-(1-p)s}$.\n- Negative binomial with parameters $r$ (a positive integer) and $p$, interpreted as the number of failures before $r$ successes: mean $m=r(1-p)/p$, variance $\\sigma^2=r(1-p)/p^2$, PGF $f(s)=\\left(\\dfrac{p}{1-(1-p)s}\\right)^r$.\n- Deterministic $k$-offspring: $X=k$ with probability $1$ for $k\\in\\{0,1,2,\\dots\\}$, mean $m=k$, variance $\\sigma^2=0$, PGF $f(s)=s^k$.\n\nDefine the time-limited immune failure risk at deadline $t$ as $\\mathbb{P}(Z_t=0)$ and treat it as the short-term failure event despite the mean growth possibly being supercritical, $m>1$.\n\nYour program must implement the derived expressions to compute, for each test case, the tuple consisting of:\n- the variance $\\mathrm{Var}(Z_t)$,\n- the time-limited failure probability $\\mathbb{P}(Z_t=0)$,\n- the mean $\\mathbb{E}[Z_t]$.\n\nAll three quantities must be rounded to six decimal places. Additionally, include one final boolean result that assesses how variance inflates time-limited failure risk for offspring laws with the same mean. Specifically, compare three offspring distributions that share the same mean $m$ and the same deadline $t$: Poisson, negative binomial with $r=2$, and geometric. Return a boolean indicating whether the ordering\n$\\mathbb{P}_{\\text{geometric}}(Z_t=0)\\ge \\mathbb{P}_{\\text{negative binomial}(r=2)}(Z_t=0)\\ge \\mathbb{P}_{\\text{Poisson}}(Z_t=0)$\nholds for the specified parameter values below.\n\nTest suite to implement:\n- Case $1$: Poisson with $\\lambda=1.2$, deadline $t=8$.\n- Case $2$: Negative binomial with $r=2$ and $p=0.625$ (so that $m=r(1-p)/p=1.2$), deadline $t=8$.\n- Case $3$: Geometric with $p=1/2.2$ (so that $m=(1-p)/p=1.2$), deadline $t=8$.\n- Case $4$: Deterministic with $k=2$, deadline $t=6$.\n- Case $5$: Poisson with $\\lambda=1$, deadline $t=10$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list should contain one sublist per case in the order above, where each sublist is of the form [variance, failure_probability, mean], followed by the final boolean. For example, the overall structure must be\n[[v1,p1,m1],[v2,p2,m2],[v3,p3,m3],[v4,p4,m4],[v5,p5,m5],B]\nwhere each $v_i$, $p_i$, $m_i$ is rounded to six decimal places and $B$ is a boolean.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in the theory of stochastic processes, specifically Galton-Watson branching processes, which are standard models in mathematical biology. The problem is well-posed, with all necessary parameters, definitions, and initial conditions ($Z_0=1$) provided. The tasks are objective, mathematically formalizable, and admit unique, stable solutions. The requested derivations rely on fundamental principles of probability theory as specified.\n\nWe proceed with the derivation of the required statistical properties of the clone size $Z_t$. A Galton-Watson process is defined by the recurrence relation $Z_{t+1} = \\sum_{i=1}^{Z_t} X_{i,t}$, where each $X_{i,t}$ is an independent and identically distributed random variable representing the number of offspring of a single cell. Let the mean of the offspring distribution be $\\mathbb{E}[X] = m$ and the variance be $\\mathrm{Var}(X) = \\sigma^2$. The process starts with a single progenitor, so $Z_0=1$.\n\n**Derivation of the Mean Clone Size $\\mathbb{E}[Z_t]$**\n\nWe use the law of iterated expectation, also known as the tower property, which states $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y|X]]$. Let $Y = Z_{t+1}$ and the conditioning variable be $X = Z_t$.\nThe expectation of $Z_{t+1}$ is $\\mathbb{E}[Z_{t+1}] = \\mathbb{E}[\\mathbb{E}[Z_{t+1}|Z_t]]$.\n\nFirst, we compute the inner conditional expectation. Given that the clone size at generation $t$ is $Z_t=k$, $Z_{t+1}$ is the sum of $k$ independent and identically distributed offspring random variables.\n$$ \\mathbb{E}[Z_{t+1} | Z_t=k] = \\mathbb{E}\\left[\\sum_{i=1}^{k} X_i \\Big| Z_t=k\\right] = \\sum_{i=1}^{k} \\mathbb{E}[X_i] = k \\cdot m $$\nThis holds for any integer $k \\ge 0$. Thus, we can write the conditional expectation as a random variable:\n$$ \\mathbb{E}[Z_{t+1} | Z_t] = Z_t \\cdot m $$\nNow, taking the expectation over $Z_t$:\n$$ \\mathbb{E}[Z_{t+1}] = \\mathbb{E}[Z_t \\cdot m] = m \\cdot \\mathbb{E}[Z_t] $$\nThis establishes a geometric recurrence relation for $\\mathbb{E}[Z_t]$. With the initial condition $Z_0=1$, we have $\\mathbb{E}[Z_0]=1$.\nUnrolling the recurrence:\n$\\mathbb{E}[Z_1] = m \\cdot \\mathbb{E}[Z_0] = m$\n$\\mathbb{E}[Z_2] = m \\cdot \\mathbb{E}[Z_1] = m^2$\nBy induction, the mean clone size at generation $t$ is:\n$$ \\mathbb{E}[Z_t] = m^t $$\n\n**Derivation of the Variance of Clone Size $\\mathrm{Var}(Z_t)$**\n\nWe use the law of total variance: $\\mathrm{Var}(Y) = \\mathbb{E}[\\mathrm{Var}(Y|X)] + \\mathrm{Var}(\\mathbb{E}[Y|X])$. As before, let $Y = Z_{t+1}$ and $X = Z_t$.\n$$ \\mathrm{Var}(Z_{t+1}) = \\mathbb{E}[\\mathrm{Var}(Z_{t+1}|Z_t)] + \\mathrm{Var}(\\mathbb{E}[Z_{t+1}|Z_t]) $$\nWe analyze each term separately.\n\nFor the first term, the conditional variance: Given $Z_t=k$, $Z_{t+1}$ is a sum of $k$ i.i.d. random variables, each with variance $\\sigma^2$. The variance of their sum is the sum of their variances:\n$$ \\mathrm{Var}(Z_{t+1} | Z_t=k) = \\mathrm{Var}\\left(\\sum_{i=1}^{k} X_i\\right) = \\sum_{i=1}^{k} \\mathrm{Var}(X_i) = k \\cdot \\sigma^2 $$\nAs a random variable, this is $\\mathrm{Var}(Z_{t+1} | Z_t) = Z_t \\cdot \\sigma^2$. Taking the expectation:\n$$ \\mathbb{E}[\\mathrm{Var}(Z_{t+1}|Z_t)] = \\mathbb{E}[Z_t \\cdot \\sigma^2] = \\sigma^2 \\mathbb{E}[Z_t] = \\sigma^2 m^t $$\n\nFor the second term, we use the conditional expectation derived earlier: $\\mathbb{E}[Z_{t+1}|Z_t] = Z_t \\cdot m$.\n$$ \\mathrm{Var}(\\mathbb{E}[Z_{t+1}|Z_t]) = \\mathrm{Var}(Z_t \\cdot m) = m^2 \\mathrm{Var}(Z_t) $$\nCombining the two terms, we get a recurrence relation for $V_t = \\mathrm{Var}(Z_t)$:\n$$ V_{t+1} = m^2 V_t + \\sigma^2 m^t $$\nThe initial condition is $V_0 = \\mathrm{Var}(Z_0) = \\mathrm{Var}(1) = 0$. We solve this linear recurrence by unrolling it:\n$V_t = m^2 V_{t-1} + \\sigma^2 m^{t-1}$\n$V_t = m^2 (m^2 V_{t-2} + \\sigma^2 m^{t-2}) + \\sigma^2 m^{t-1} = m^4 V_{t-2} + \\sigma^2 m^t + \\sigma^2 m^{t-1}$\n$V_t = m^{2k} V_{t-k} + \\sigma^2 \\sum_{j=0}^{k-1} m^{t-1+j}$\nSetting $k=t$:\n$V_t = m^{2t} V_0 + \\sigma^2 \\sum_{j=0}^{t-1} m^{t-1+j} = 0 + \\sigma^2 m^{t-1} \\sum_{j=0}^{t-1} m^j$\n\nThe sum is a geometric series. We consider two cases for the mean $m$.\nCase 1: $m=1$. The sum is $\\sum_{j=0}^{t-1} 1^j = t$.\n$$ V_t = \\sigma^2 \\cdot 1^{t-1} \\cdot t = \\sigma^2 t \\quad (\\text{for } m=1) $$\nCase 2: $m \\neq 1$. The sum is $\\sum_{j=0}^{t-1} m^j = \\frac{m^t-1}{m-1}$.\n$$ V_t = \\sigma^2 m^{t-1} \\frac{m^t-1}{m-1} \\quad (\\text{for } m \\neq 1) $$\nThese two expressions provide the variance $\\mathrm{Var}(Z_t)$.\n\n**Derivation of the Time-limited Failure Risk $\\mathbb{P}(Z_t=0)$**\n\nThe probability of the clone being absent at generation $t$, $\\mathbb{P}(Z_t=0)$, can be found using the probability generating function (PGF). Let $f(s) = \\mathbb{E}[s^X]$ be the PGF of the offspring distribution $X$. Let $f_t(s) = \\mathbb{E}[s^{Z_t}]$ be the PGF of the clone size at generation $t$.\n\nBy the law of iterated expectation:\n$f_{t+1}(s) = \\mathbb{E}[s^{Z_{t+1}}] = \\mathbb{E}[\\mathbb{E}[s^{Z_{t+1}}|Z_t]]$\nConditional on $Z_t=k$, $Z_{t+1} = \\sum_{i=1}^k X_i$. The PGF of a sum of independent random variables is the product of their PGFs.\n$\\mathbb{E}[s^{\\sum_{i=1}^k X_i}] = \\prod_{i=1}^k \\mathbb{E}[s^{X_i}] = (f(s))^k$.\nThus, $\\mathbb{E}[s^{Z_{t+1}}|Z_t] = (f(s))^{Z_t}$.\nSubstituting this back:\n$f_{t+1}(s) = \\mathbb{E}[(f(s))^{Z_t}]$.\nThe expression on the right is precisely the definition of the PGF of $Z_t$, evaluated at the point $f(s)$. Therefore, we have the functional composition law:\n$f_{t+1}(s) = f_t(f(s))$.\nWith the initial condition $Z_0=1$, the PGF is $f_0(s) = \\mathbb{E}[s^1] = s$.\nUnrolling the recurrence:\n$f_1(s) = f_0(f(s)) = f(s)$\n$f_2(s) = f_1(f(s)) = f(f(s))$\nIn general, $f_t(s)$ is the $t$-fold composition of $f$ with itself, denoted $f^{\\circ t}(s)$.\n\nThe probability $\\mathbb{P}(Z_t=k)$ is the coefficient of $s^k$ in the power series expansion of $f_t(s)$. The probability of extinction, $\\mathbb{P}(Z_t=0)$, is the constant term, which can be obtained by evaluating the PGF at $s=0$:\n$$ \\mathbb{P}(Z_t=0) = f_t(0) = f^{\\circ t}(0) $$\nThis provides an iterative algorithm to compute the failure risk. Let $p_t = \\mathbb{P}(Z_t=0)$.\n$p_0 = \\mathbb{P}(Z_0=0) = 0$ (since $Z_0=1$).\n$p_1 = f_1(0) = f(0)$.\n$p_2 = f_2(0) = f(f(0)) = f(p_1)$.\n$p_t = f_t(0) = f(f_{t-1}(0)) = f(p_{t-1})$.\nThe algorithm is to start with $p_0=0.0$ and iterate $p_{i} = f(p_{i-1})$ for $i=1, \\dots, t$. The result is $p_t$.\n\nThe final boolean check compares the failure risk for three distributions with the same mean $m=1.2$. The variance of these distributions is $\\sigma^2_{\\text{Poisson}} = \\lambda = 1.2$, $\\sigma^2_{\\text{NegBin}} = r(1-p)/p^2 = 1.92$, and $\\sigma^2_{\\text{Geo}} = (1-p)/p^2 = 2.64$. The ordering of variances is $\\sigma^2_{\\text{Geo}} > \\sigma^2_{\\text{NegBin}} > \\sigma^2_{\\text{Poisson}}$. Generally, for a fixed mean $m>1$, higher offspring variance leads to a higher probability of early extinction. This is because higher variance implies a greater chance of producing zero offspring, which \"lifts\" the PGF curve $f(s)$ for $s \\in [0,1)$ and leads to faster convergence to a higher fixed point (the ultimate extinction probability). The boolean check tests this relationship for the specified finite time $t=8$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the branching process problem for the given test cases.\n    It derives and computes mean, variance, and failure probability for a Galton-Watson process\n    under different offspring distributions.\n    \"\"\"\n\n    # --- PGF Definitions ---\n    def pgf_poisson(s, lam):\n        return np.exp(lam * (s - 1.0))\n\n    def pgf_geometric(s, p):\n        return p / (1.0 - (1.0 - p) * s)\n\n    def pgf_neg_binomial(s, r, p):\n        return (p / (1.0 - (1.0 - p) * s)) ** r\n\n    def pgf_deterministic(s, k):\n        # Handle the case s=0, k=0, which is 0^0 -> 1\n        if s == 0.0 and k == 0:\n            return 1.0\n        return s ** k\n\n    def calculate_failure_prob(pgf_func, t):\n        \"\"\"\n        Calculates P(Z_t=0) by iterating the PGF t times, starting from 0.\n        P(Z_t=0) = f(f(...f(0)...)) t times.\n        \"\"\"\n        p_fail = 0.0\n        for _ in range(t):\n            p_fail = pgf_func(p_fail)\n        return p_fail\n\n    def calculate_metrics(dist_type, params, t):\n        \"\"\"\n        Calculates mean, variance, and failure probability for a given case.\n        \"\"\"\n        # Determine mean(m), variance(sigma2), and PGF based on distribution\n        if dist_type == \"poisson\":\n            lam = params['lambda']\n            m = lam\n            sigma2 = lam\n            pgf = lambda s: pgf_poisson(s, lam)\n        elif dist_type == \"neg_binomial\":\n            r, p = params['r'], params['p']\n            m = r * (1.0 - p) / p\n            sigma2 = r * (1.0 - p) / (p ** 2)\n            pgf = lambda s: pgf_neg_binomial(s, r, p)\n        elif dist_type == \"geometric\":\n            p = params['p']\n            m = (1.0 - p) / p\n            sigma2 = (1.0 - p) / (p ** 2)\n            pgf = lambda s: pgf_geometric(s, p)\n        elif dist_type == \"deterministic\":\n            k = params['k']\n            m = float(k)\n            sigma2 = 0.0\n            pgf = lambda s: pgf_deterministic(s, k)\n        else:\n            raise ValueError(\"Unknown distribution type\")\n\n        # --- Calculate Mean E[Z_t] ---\n        mean_zt = m ** t\n\n        # --- Calculate Variance Var(Z_t) ---\n        if m == 1.0:\n            var_zt = sigma2 * t\n        else:\n            # For m=0, the formula becomes 0. Avoids division by zero if handled this way.\n            if m == 0.0:\n                 var_zt = 0.0\n            else:\n                 var_zt = sigma2 * (m ** (t - 1)) * (m ** t - 1.0) / (m - 1.0)\n\n\n        # --- Calculate Failure Probability P(Z_t=0) ---\n        prob_zt_zero = calculate_failure_prob(pgf, t)\n\n        return var_zt, prob_zt_zero, mean_zt\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': \"poisson\",       'params': {'lambda': 1.2}, 't': 8},\n        {'type': \"neg_binomial\",  'params': {'r': 2, 'p': 0.625}, 't': 8},\n        {'type': \"geometric\",     'params': {'p': 1.0/2.2}, 't': 8},\n        {'type': \"deterministic\", 'params': {'k': 2}, 't': 6},\n        {'type': \"poisson\",       'params': {'lambda': 1.0}, 't': 10},\n    ]\n\n    results = []\n    failure_probs_for_comparison = {}\n\n    for i, case in enumerate(test_cases):\n        var, prob_fail, mean = calculate_metrics(case['type'], case['params'], case['t'])\n        \n        # Round to six decimal places for output\n        v_rounded = round(var, 6)\n        p_rounded = round(prob_fail, 6)\n        m_rounded = round(mean, 6)\n        \n        results.append([v_rounded, p_rounded, m_rounded])\n        \n        # Store unrounded failure probabilities for the boolean check\n        if i + 1 in [1, 2, 3]: # Cases 1, 2, 3\n            failure_probs_for_comparison[i + 1] = prob_fail\n\n    # --- Final Boolean Check ---\n    # Compare P(Z_t=0) for Geometric, Negative Binomial, and Poisson with same mean m=1.2\n    p_geo = failure_probs_for_comparison[3]\n    p_nb = failure_probs_for_comparison[2]\n    p_poi = failure_probs_for_comparison[1]\n    \n    boolean_check = (p_geo >= p_nb) and (p_nb >= p_poi)\n\n    # --- Format final output string ---\n    results_str_list = []\n    for res in results:\n        # Format each number to ensure .6f representation\n        sublist_str = f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\"\n        results_str_list.append(sublist_str)\n\n    # Boolean to string 'True' or 'False'\n    bool_str = str(boolean_check)\n    \n    final_output = f\"[{','.join(results_str_list)},{bool_str}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "Agents in biological systems are profoundly influenced by their chemical environment, such as immune cells following gradients of signaling molecules (cytokines). This practice focuses on modeling this environment by numerically solving the reaction-diffusion equations that govern such chemical fields. You will implement a finite-difference scheme to simulate a substance that diffuses, decays, and is produced, learning essential concepts of numerical stability and boundary conditions along the way. This skill is vital for building realistic hybrid models where discrete agents are coupled to and guided by continuous environmental fields. ",
            "id": "3870827",
            "problem": "You are modeling a diffusing, decaying, and sourced field representing a cytokine concentration in an agent-based model of immune responses, tumors, or infectious disease spread. The macroscopic field obeys the reaction-diffusion partial differential equation $\\,\\partial_t c = D \\nabla^2 c - \\lambda c + S\\,$, where $\\,c\\,$ is a normalized, dimensionless concentration field, $\\,D\\,$ is the diffusion coefficient with units $\\mathrm{m}^2/\\mathrm{s}$, $\\,\\lambda\\,$ is the decay rate with units $\\mathrm{s}^{-1}$, and $\\,S\\,$ is a dimensionless source term. The field is defined on a $\\,d\\,$-dimensional, uniform Cartesian grid with spacing $\\,\\Delta x\\,$ in every dimension, and zero-flux Neumann boundary conditions (zero normal derivative) are imposed everywhere on the boundary.\n\nTask:\n1. Construct a finite-difference explicit update for $\\,c\\,$ using a forward Euler time discretization and second-order central differences for the discrete Laplacian on a uniform grid. Implement zero-flux Neumann boundary conditions by enforcing zero normal derivative via ghost-cell replication of boundary values. Explicitly use the discrete Laplacian that, for interior points, replaces $\\,\\nabla^2\\,$ by a sum of second differences, and for boundary-adjacent points, uses ghost-cell values chosen so that the discrete normal derivative at the boundary face is zero.\n2. From a Von Neumann stability perspective for explicit diffusion, compute the Courant–Friedrichs–Lewy (CFL) time step restriction $\\,\\Delta t \\le \\frac{\\Delta x^2}{2 d D}\\,$ in $\\,d\\,$ dimensions.\n3. For each test case, compute:\n   - The maximum stable time step $\\,\\Delta t_{\\mathrm{CFL}} = \\frac{\\Delta x^2}{2 d D}\\,$ and report it in seconds.\n   - A boolean stating whether the discrete domain-integral of the Laplacian of a randomly initialized $\\,c\\,$ (with a fixed random seed) is numerically zero within a specified tolerance under the imposed Neumann boundary conditions. Specifically, let $\\,\\mathcal{L}[c]\\,$ denote the discrete Laplacian computed with Neumann boundaries. Compute $\\,I = \\Delta x^d \\sum_{\\text{grid}} \\mathcal{L}[c]\\,$ and check $\\,|I| \\le \\varepsilon \\max\\{1, \\Delta x^d \\sum_{\\text{grid}} |c|\\}\\,$ with $\\,\\varepsilon = 10^{-12}\\,$. Report `True` if the inequality holds, otherwise `False`.\n\nFundamental base to use:\n- Fick's law of diffusion, $\\,\\mathbf{J} = - D \\nabla c\\,$.\n- Conservation law in a control volume, $\\,\\partial_t c = - \\nabla \\cdot \\mathbf{J} - \\lambda c + S\\,$, yielding $\\,\\partial_t c = D \\nabla^2 c - \\lambda c + S\\,$.\n- Forward Euler time discretization and standard second-order finite differences for spatial derivatives on uniform grids.\n- Von Neumann stability analysis for explicit schemes applied to linear constant-coefficient diffusion, where the stability bound is set by the largest-magnitude eigenvalue of the discrete Laplacian.\n\nGrid, parameters, and test suite:\nAcross all test cases, use a fixed random seed $\\,42\\,$ to initialize $\\,c\\,$ with independent identically distributed values drawn uniformly from $\\,[0,1]\\,$. For all cases, treat $\\,c\\,$ and $\\,S\\,$ as dimensionless quantities; only $\\,D\\,$, $\\,\\Delta x\\,$, and $\\,\\Delta t\\,$ carry physical units. For each case, use a constant source $\\,S\\,$ (dimensionless) across the grid. The test cases are:\n\n- Case A (happy path, one dimension):\n  - $\\,d = 1\\,$\n  - Grid shape $\\,N = 5\\,$\n  - $\\,\\Delta x = 2 \\times 10^{-5}\\,\\mathrm{m}\\,$\n  - $\\,D = 1 \\times 10^{-10}\\,\\mathrm{m}^2/\\mathrm{s}\\,$\n  - $\\,\\lambda = 0.3\\,\\mathrm{s}^{-1}\\,$\n  - $\\,S = 0.1\\,$\n\n- Case B (two dimensions, moderate diffusion):\n  - $\\,d = 2\\,$\n  - Grid shape $\\,N_x = 21\\,$, $\\,N_y = 21\\,$\n  - $\\,\\Delta x = 1 \\times 10^{-5}\\,\\mathrm{m}\\,$\n  - $\\,D = 1 \\times 10^{-9}\\,\\mathrm{m}^2/\\mathrm{s}\\,$\n  - $\\,\\lambda = 0.5\\,\\mathrm{s}^{-1}\\,$\n  - $\\,S = 0.2\\,$\n\n- Case C (three dimensions, larger spacing):\n  - $\\,d = 3\\,$\n  - Grid shape $\\,N_x = 11\\,$, $\\,N_y = 11\\,$, $\\,N_z = 11\\,$\n  - $\\,\\Delta x = 5 \\times 10^{-5}\\,\\mathrm{m}\\,$\n  - $\\,D = 5 \\times 10^{-10}\\,\\mathrm{m}^2/\\mathrm{s}\\,$\n  - $\\,\\lambda = 0.05\\,\\mathrm{s}^{-1}\\,$\n  - $\\,S = 0.0\\,$\n\n- Case D (edge case, two dimensions, fine grid):\n  - $\\,d = 2\\,$\n  - Grid shape $\\,N_x = 9\\,$, $\\,N_y = 9\\,$\n  - $\\,\\Delta x = 2 \\times 10^{-6}\\,\\mathrm{m}\\,$\n  - $\\,D = 1 \\times 10^{-9}\\,\\mathrm{m}^2/\\mathrm{s}\\,$\n  - $\\,\\lambda = 1.0\\,\\mathrm{s}^{-1}\\,$\n  - $\\,S = 0.0\\,$\n\nOutput specification:\n- For each test case, produce a list $\\,\\left[\\Delta t_{\\mathrm{CFL}},\\, \\text{flux\\_conservative}\\right]\\,$ where $\\,\\Delta t_{\\mathrm{CFL}}\\,$ is a float in seconds and `flux_conservative` is a boolean indicating whether $\\,|I| \\le \\varepsilon \\max\\{1, \\Delta x^d \\sum_{\\text{grid}} |c|\\}\\,$ holds.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $\\,\\left[\\,[\\Delta t_{\\mathrm{CFL},A}, \\text{flux\\_conservative\\_A}],\\,[\\Delta t_{\\mathrm{CFL},B}, \\text{flux\\_conservative\\_B}],\\,[\\Delta t_{\\mathrm{CFL},C}, \\text{flux\\_conservative\\_C}],\\,[\\Delta t_{\\mathrm{CFL},D}, \\text{flux\\_conservative\\_D}]\\,\\right]\\,$.",
            "solution": "The user-provided problem is assessed to be **valid**. It is scientifically grounded, well-posed, objective, and contains all necessary information for a unique, verifiable solution. We will proceed to solve it.\n\n### **1. Theoretical Formulation**\n\nThe problem requires the numerical solution of the reaction-diffusion partial differential equation (PDE) on a $d$-dimensional Cartesian grid:\n$$\n\\partial_t c = D \\nabla^2 c - \\lambda c + S\n$$\nwhere $c$ is the concentration, $D$ is the diffusion coefficient, $\\lambda$ is the decay rate, and $S$ is a source term.\n\n#### **1.1. Finite-Difference Discretization**\n\nWe employ a finite-difference method to discretize the PDE.\n\n**Time Discretization**: A forward Euler scheme is used for the time derivative $\\partial_t c$. For a time step $\\Delta t$, the concentration $c^{n+1}$ at time step $n+1$ is updated from the concentration $c^n$ at step $n$ as:\n$$\n\\frac{c^{n+1} - c^n}{\\Delta t} = D \\nabla^2 c^n - \\lambda c^n + S\n$$\nRearranging gives the explicit update rule:\n$$\nc^{n+1} = c^n + \\Delta t (D \\mathcal{L}[c^n] - \\lambda c^n + S)\n$$\nwhere $\\mathcal{L}$ represents the discrete Laplacian operator.\n\n**Spatial Discretization**: The Laplacian operator, $\\nabla^2 = \\sum_{k=1}^d \\frac{\\partial^2}{\\partial x_k^2}$, is discretized using a second-order central difference stencil on a uniform grid with spacing $\\Delta x$. For an interior point $\\mathbf{i} = (i_1, \\dots, i_d)$, the discrete Laplacian is:\n$$\n\\mathcal{L}[c]_{\\mathbf{i}} = \\sum_{k=1}^d \\frac{c_{\\mathbf{i}+\\mathbf{e}_k} - 2c_{\\mathbf{i}} + c_{\\mathbf{i}-\\mathbf{e}_k}}{\\Delta x^2}\n$$\nwhere $\\mathbf{e}_k$ is the unit vector along the $k$-th dimension.\n\n#### **1.2. Neumann Boundary Conditions**\n\nZero-flux Neumann boundary conditions, $\\frac{\\partial c}{\\partial n} = 0$, are imposed on all boundaries. Here, $\\mathbf{n}$ is the outward normal vector. For a Cartesian grid, this simplifies to the partial derivative along the coordinate axis perpendicular to the boundary face being zero.\n\nWe implement this using ghost cells. Consider a 1D grid with points indexed $i = 0, \\dots, N-1$. At the boundary $i=0$, the boundary face is at $i=-1/2$. A second-order central difference for the derivative at this face is:\n$$\n\\frac{\\partial c}{\\partial x}\\bigg|_{i=-1/2} \\approx \\frac{c_0 - c_{-1}}{\\Delta x} = 0 \\implies c_{-1} = c_0\n$$\nThis means the value in the ghost cell at index $i=-1$ is a copy of the value at the boundary cell $i=0$. This method, \"ghost-cell replication,\" is applied to all boundaries.\n\nWhen computing the Laplacian at a boundary point (e.g., $i=0$), we use the standard central difference stencil, which now involves the ghost cell:\n$$\n\\mathcal{L}[c]_0 = \\frac{c_1 - 2c_0 + c_{-1}}{\\Delta x^2}\n$$\nSubstituting the ghost cell value $c_{-1} = c_0$, we obtain:\n$$\n\\mathcal{L}[c]_0 = \\frac{c_1 - 2c_0 + c_0}{\\Delta x^2} = \\frac{c_1 - c_0}{\\Delta x^2}\n$$\nThis approach maintains a consistent stencil structure across the grid, which is advantageous for implementation, particularly in a vectorized manner using libraries like NumPy. The `np.pad` function with `mode='edge'` directly implements this ghost-cell replication.\n\n### **2. Computational Tasks**\n\n#### **2.1. Courant–Friedrichs–Lewy (CFL) Stability Condition**\n\nThe forward Euler time-stepping scheme for the diffusion equation is conditionally stable. A Von Neumann stability analysis shows that the method is stable if and only if the time step $\\Delta t$ satisfies the Courant–Friedrichs–Lewy (CFL) condition. For the $d$-dimensional diffusion equation, this condition is:\n$$\n\\Delta t \\le \\frac{\\Delta x^2}{2 d D}\n$$\nThe problem asks for the maximum stable time step, $\\Delta t_{\\mathrm{CFL}}$, which corresponds to the equality:\n$$\n\\Delta t_{\\mathrm{CFL}} = \\frac{\\Delta x^2}{2 d D}\n$$\nThe reaction term $-\\lambda c$ (with $\\lambda \\ge 0$) does not introduce a stricter stability constraint for the forward Euler method.\n\n#### **2.2. Conservation Property of the Discrete Laplacian**\n\nThe problem requires checking a numerical property related to the integral of the Laplacian. The continuous divergence theorem states that for a vector field $\\mathbf{F}$, $\\int_V (\\nabla \\cdot \\mathbf{F}) dV = \\oint_{\\partial V} \\mathbf{F} \\cdot d\\mathbf{A}$. Letting $\\mathbf{F} = \\nabla c$, this becomes:\n$$\n\\int_V \\nabla^2 c \\, dV = \\oint_{\\partial V} \\nabla c \\cdot d\\mathbf{A}\n$$\nWith zero-flux Neumann boundary conditions, the normal derivative $\\nabla c \\cdot \\mathbf{n}$ is zero everywhere on the boundary $\\partial V$. Therefore, the surface integral on the right-hand side is zero, implying the volume integral of the Laplacian is zero.\n\nThis property holds for our discrete formulation as well. The sum of the discrete Laplacian over the grid is a telescoping series that vanishes due to the ghost-cell conditions. Let's demonstrate in 1D:\n$$\n\\sum_{i=0}^{N-1} \\mathcal{L}[c]_i = \\frac{1}{\\Delta x^2} \\sum_{i=0}^{N-1} (c_{i+1} - 2c_i + c_{i-1})\n$$\nUsing ghost cell values $c_{-1}=c_0$ and $c_N=c_{N-1}$, this sum telescopes:\n$$\n\\sum_{i=0}^{N-1} (c_{i+1} - c_i) - (c_i - c_{i-1}) = (c_N - c_{N-1}) - (c_0 - c_{-1}) = (c_{N-1} - c_{N-1}) - (c_0 - c_0) = 0\n$$\nNumerically, this sum should be zero to within machine precision. We test this by computing the discrete integral $I = \\Delta x^d \\sum_{\\text{grid}} \\mathcal{L}[c]$ and verifying if it is numerically zero using the provided tolerance check:\n$$\n|I| \\le \\varepsilon \\max\\{1, \\Delta x^d \\sum_{\\text{grid}} |c|\\}\n$$\nwith $\\varepsilon = 10^{-12}$. This check robustly compares the absolute error $|I|$ against a threshold that scales with the magnitude of the field $c$, while providing a minimum absolute tolerance of $\\varepsilon$.\n\n### **3. Implementation and Solution Logic**\n\nFor each test case, the following steps are performed:\n1.  Set the dimension $d$, grid shape, and physical parameters $\\Delta x$ and $D$.\n2.  Calculate the maximum stable time step $\\Delta t_{\\mathrm{CFL}} = \\frac{\\Delta x^2}{2 d D}$.\n3.  Initialize a $d$-dimensional grid of concentration values $c$ by drawing from a uniform distribution on $[0, 1]$ using a fixed random seed of $42$ for reproducibility.\n4.  Implement a function to compute the discrete Laplacian, $\\mathcal{L}[c]$, on the grid. This function uses padding (`np.pad` with `mode='edge'`) to correctly handle the ghost cells for the Neumann boundary conditions in any number of dimensions.\n5.  Compute the discrete integral of the Laplacian, $I = \\Delta x^d \\sum \\mathcal{L}[c]$.\n6.  Evaluate the boolean condition $|I| \\le 10^{-12} \\max\\{1, \\Delta x^d \\sum |c|\\}$.\n7.  Store the pair $[\\Delta t_{\\mathrm{CFL}}, \\text{boolean result}]$ for the test case.\n8.  After iterating through all test cases, format the collected results into the specified output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the CFL time step and checking the \n    conservation property of the discrete Laplacian for several test cases.\n    \"\"\"\n\n    def compute_laplacian(c: np.ndarray, dx: float) -> np.ndarray:\n        \"\"\"\n        Computes the discrete Laplacian of a d-dimensional field 'c' with \n        zero-flux Neumann boundary conditions.\n\n        Args:\n            c (np.ndarray): The input concentration field.\n            dx (float): The uniform grid spacing.\n\n        Returns:\n            np.ndarray: The discrete Laplacian of the field.\n        \"\"\"\n        d = c.ndim\n        lap_c = np.zeros_like(c, dtype=np.float64)\n        denom = dx**2\n\n        # Sum the second differences along each dimension\n        for axis in range(d):\n            # Pad the array along the current axis to handle boundaries.\n            # mode='edge' replicates boundary values, implementing the ghost\n            # cell rule c_{-1} = c_0.\n            padding = [(0, 0)] * d\n            padding[axis] = (1, 1)\n            c_padded = np.pad(c, pad_width=padding, mode='edge')\n\n            # Use slicing on the padded array to get neighbors.\n            # These slices are constructed to produce arrays of the same shape as 'c'.\n            slice_plus = [slice(None)] * d\n            slice_plus[axis] = slice(2, None)\n            \n            slice_center = [slice(None)] * d\n            slice_center[axis] = slice(1, -1)\n\n            slice_minus = [slice(None)] * d\n            slice_minus[axis] = slice(0, -2)\n\n            lap_c += (c_padded[tuple(slice_plus)] \n                      - 2 * c_padded[tuple(slice_center)] \n                      + c_padded[tuple(slice_minus)])\n\n        return lap_c / denom\n\n    test_cases = [\n        # Case A: d=1, N=5, dx=2e-5, D=1e-10, lam=0.3, S=0.1\n        {\n            \"d\": 1, \"shape\": (5,), \"dx\": 2e-5, \"D\": 1e-10,\n            \"lambda\": 0.3, \"S\": 0.1\n        },\n        # Case B: d=2, Nx=21, Ny=21, dx=1e-5, D=1e-9, lam=0.5, S=0.2\n        {\n            \"d\": 2, \"shape\": (21, 21), \"dx\": 1e-5, \"D\": 1e-9,\n            \"lambda\": 0.5, \"S\": 0.2\n        },\n        # Case C: d=3, Nx=11, Ny=11, Nz=11, dx=5e-5, D=5e-10, lam=0.05, S=0.0\n        {\n            \"d\": 3, \"shape\": (11, 11, 11), \"dx\": 5e-5, \"D\": 5e-10,\n            \"lambda\": 0.05, \"S\": 0.0\n        },\n        # Case D: d=2, Nx=9, Ny=9, dx=2e-6, D=1e-9, lam=1.0, S=0.0\n        {\n            \"d\": 2, \"shape\": (9, 9), \"dx\": 2e-6, \"D\": 1e-9,\n            \"lambda\": 1.0, \"S\": 0.0\n        },\n    ]\n\n    results = []\n    # Use a fixed random seed for reproducibility.\n    rng = np.random.default_rng(seed=42)\n    \n    for case in test_cases:\n        d = case[\"d\"]\n        shape = case[\"shape\"]\n        dx = case[\"dx\"]\n        D = case[\"D\"]\n        \n        # Task 1: Compute the maximum stable time step (CFL condition)\n        dt_cfl = (dx**2) / (2 * d * D)\n        \n        # Task 2: Check the numerical conservation of the Laplacian\n        \n        # Initialize the concentration field 'c'\n        c = rng.uniform(0, 1, size=shape)\n        \n        # Compute the discrete Laplacian\n        lap_c = compute_laplacian(c, dx)\n        \n        # Compute the discrete integral I\n        volume_element = dx**d\n        laplacian_integral = volume_element * np.sum(lap_c)\n        \n        # Compute the comparison term for the tolerance check\n        norm_c_integral = volume_element * np.sum(np.abs(c))\n        \n        # Check if the integral is numerically zero within the given tolerance\n        epsilon = 1e-12\n        threshold = epsilon * max(1.0, norm_c_integral)\n        is_flux_conservative = np.abs(laplacian_integral) = threshold\n        \n        results.append([dt_cfl, is_flux_conservative])\n\n    # Convert the list of lists to the required string format.\n    # The boilerplate f\"[{','.join(map(str, results))}]\" produces the correct format\n    # which includes spaces after commas within the inner lists, e.g., '[2.0, True]'.\n    final_output_string = f\"[{','.join(map(str, results))}]\"\n    \n    # Print the final output in the required single-line format.\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}