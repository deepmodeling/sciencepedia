{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides foundational practice in applying the Pontryagin's Minimum Principle (PMP), the cornerstone of analytical optimal control. We will formulate the necessary conditions for optimality for a classic biomedical problem: designing an optimal insulin infusion strategy for glucose regulation . By deriving the Hamiltonian, the costate (or adjoint) dynamics, and the stationary control law, you will gain hands-on experience with the core mechanics of the PMP, which is essential for understanding and solving continuous-time optimal control problems.",
            "id": "3914940",
            "problem": "Consider a single-subject glucose-insulin regulation model during exogenous insulin infusion. The glucose state, insulin action, and plasma insulin are denoted by $G(t)$, $X(t)$, and $I(t)$, respectively. The exogenous carbohydrate disturbance $D(t)$ is known and nonnegative, and the control input $u(t)$ is the externally infused insulin. Let $G_{\\mathrm{b}}$ denote the basal glucose level and $G_{\\mathrm{ref}}$ the desired glucose setpoint. The dynamics are specified by\n$$\n\\begin{aligned}\n\\dot{G}(t) &= -k_{g}\\big(G(t)-G_{\\mathrm{b}}\\big) - X(t)\\,G(t) + D(t), \\\\\n\\dot{X}(t) &= -k_{x} X(t) + s\\, I(t), \\\\\n\\dot{I}(t) &= -k_{i} I(t) + u(t),\n\\end{aligned}\n$$\nwhere $k_{g}>0$, $k_{x}>0$, $k_{i}>0$, and $s>0$ are known physiological parameters. The control is bounded as $0 \\leq u(t) \\leq u_{\\max}$ and the horizon is $t\\in[0,T]$ with $T>0$. The performance index penalizes glucose excursion and control energy via\n$$\nJ[u] \\;=\\; \\frac{1}{2} \\int_{0}^{T} \\left( q\\,\\big(G(t)-G_{\\mathrm{ref}}\\big)^{2} \\;+\\; r\\, u(t)^{2} \\right)\\, dt \\;+\\; \\frac{1}{2}\\, p\\,\\big(G(T)-G_{\\mathrm{ref}}\\big)^{2},\n$$\nwhere $q>0$, $r>0$, and $p\\ge 0$ are weighting coefficients, and $G_{\\mathrm{ref}}$ is constant.\n\nUsing the Pontryagin's Minimum Principle (PMP), derive from first principles the Hamiltonian $H(x,\\lambda,u,t)$ and the costate dynamics $\\dot{\\lambda}(t) = -\\partial H/\\partial x$, with $x(t) = \\big(G(t), X(t), I(t)\\big)^{\\top}$ and costates $\\lambda(t) = \\big(\\lambda_{G}(t), \\lambda_{X}(t), \\lambda_{I}(t)\\big)^{\\top}$. Then determine the stationary control law $u^{\\ast}(t)$ in terms of the switching function for this input-affine system, explicitly accounting for the control bounds.\n\nExpress your final result in the following order inside a single row matrix:\n1) the Hamiltonian $H$,\n2) the costate dynamics as the $3$-tuple $\\big(\\dot{\\lambda}_{G},\\dot{\\lambda}_{X},\\dot{\\lambda}_{I}\\big)$,\n3) the stationary control $u^{\\ast}(t)$ given explicitly in terms of the switching function.\n\nNo numerical evaluation is required. Your final answer must be a single closed-form analytic expression. If you use any acronym, spell out its full name at first appearance. Do not include units.",
            "solution": "The user has provided a problem in optimal control theory applied to a biological system. The task is to derive the Hamiltonian, the costate dynamics, and the optimal control law using the Pontryagin's Minimum Principle (PMP).\n\n### Step 1: Extract Givens\n\nThe state vector is $x(t) = \\big(G(t), X(t), I(t)\\big)^{\\top}$, representing glucose concentration, insulin action, and plasma insulin, respectively. The control input is the external insulin infusion rate, $u(t)$.\n\nThe state dynamics are given by the system of ordinary differential equations:\n$$\n\\begin{aligned}\n\\dot{G}(t) &= -k_{g}\\big(G(t)-G_{\\mathrm{b}}\\big) - X(t)\\,G(t) + D(t) \\\\\n\\dot{X}(t) &= -k_{x} X(t) + s\\, I(t) \\\\\n\\dot{I}(t) &= -k_{i} I(t) + u(t)\n\\end{aligned}\n$$\nThe parameters $k_{g}$, $k_{x}$, $k_{i}$, and $s$ are positive constants. $G_{\\mathrm{b}}$ is the basal glucose level, a constant. $D(t)$ is a known non-negative disturbance function.\n\nThe control input is bounded: $0 \\leq u(t) \\leq u_{\\max}$.\n\nThe performance index (cost functional) to be minimized is:\n$$\nJ[u] \\;=\\; \\frac{1}{2} \\int_{0}^{T} \\left( q\\,\\big(G(t)-G_{\\mathrm{ref}}\\big)^{2} \\;+\\; r\\, u(t)^{2} \\right)\\, dt \\;+\\; \\frac{1}{2}\\, p\\,\\big(G(T)-G_{\\mathrm{ref}}\\big)^{2}\n$$\nThe weighting coefficients $q$, $r$ are positive, and $p$ is non-negative. $G_{\\mathrm{ref}}$ is the constant desired glucose setpoint. The time horizon is $t \\in [0, T]$ with $T>0$.\n\nThe costate vector is denoted by $\\lambda(t) = \\big(\\lambda_{G}(t), \\lambda_{X}(t), \\lambda_{I}(t)\\big)^{\\top}$.\n\n### Step 2: Validate Using Extracted Givens\n\n1.  **Scientifically Grounded:** The problem uses a simplified version of the Bergman minimal model, a widely accepted mathematical model for glucose-insulin dynamics. The objective function is a standard quadratic form used in optimal control to penalize deviations from a setpoint and control effort. The setup is scientifically and mathematically sound.\n2.  **Well-Posed:** The problem provides all necessary components to apply the Pontryagin's Minimum Principle (PMP). The dynamics are defined, the cost functional is specified, and the control constraints are given. The existence of a solution is expected for this class of problems.\n3.  **Objective:** The problem is stated using precise mathematical language without ambiguity or subjective elements.\n4.  **Completeness and Consistency:** All parameters and functions are defined. There are no missing data or contradictory constraints for the task of deriving the Hamiltonian, costate equations, and control law.\n5.  **No Other Flaws:** The problem is not trivial, ill-posed, or unrealistic within the context of mathematical modeling.\n\n### Step 3: Verdict and Action\n\nThe problem statement is valid. I will proceed with the derivation.\n\n### Derivation using the Pontryagin's Minimum Principle (PMP)\n\nThe PMP provides necessary conditions for an optimal control. It involves defining a Hamiltonian function and analyzing its properties.\n\n**1. The Hamiltonian**\n\nThe Hamiltonian $H(x, \\lambda, u, t)$ is defined as $H = L + \\lambda^{\\top}f$, where $L(x, u, t)$ is the integrand of the cost functional and $f(x, u, t)$ is the vector field of the state dynamics.\n\nThe integrand $L$ is:\n$$\nL(G, X, I, u) = \\frac{1}{2} q \\left(G - G_{\\mathrm{ref}}\\right)^{2} + \\frac{1}{2} r u^{2}\n$$\nThe state dynamics vector $f$ is:\n$$\nf(G, X, I, u, t) = \\begin{pmatrix} -k_{g}\\big(G-G_{\\mathrm{b}}\\big) - XG + D(t) \\\\ -k_{x} X + sI \\\\ -k_{i} I + u \\end{pmatrix}\n$$\nThe Hamiltonian is therefore:\n$$\nH = L + \\lambda_{G} \\dot{G} + \\lambda_{X} \\dot{X} + \\lambda_{I} \\dot{I}\n$$\nSubstituting the expressions for $L$ and the state derivatives yields the Hamiltonian, where for clarity the time dependence of variables is omitted:\n$$\nH = \\frac{1}{2} q \\left(G - G_{\\mathrm{ref}}\\right)^{2} + \\frac{1}{2} r u^{2} + \\lambda_{G} \\left(-k_{g}(G - G_{\\mathrm{b}}) - XG + D(t)\\right) + \\lambda_{X} \\left(-k_{x} X + sI\\right) + \\lambda_{I} \\left(-k_{i} I + u\\right)\n$$\n\n**2. The Costate Dynamics**\n\nThe costate (or adjoint) equations are given by $\\dot{\\lambda}(t) = -\\frac{\\partial H}{\\partial x}$. We compute the partial derivative of the Hamiltonian with respect to each state variable.\n\nFor $\\lambda_{G}$:\n$$\n\\frac{\\partial H}{\\partial G} = q\\left(G - G_{\\mathrm{ref}}\\right) + \\lambda_{G}\\left(-k_{g} - X\\right)\n$$\n$$\n\\dot{\\lambda}_{G} = -\\frac{\\partial H}{\\partial G} = -q\\left(G - G_{\\mathrm{ref}}\\right) + \\lambda_{G}\\left(k_{g} + X\\right)\n$$\nFor $\\lambda_{X}$:\n$$\n\\frac{\\partial H}{\\partial X} = \\lambda_{G}(-G) + \\lambda_{X}(-k_{x}) = -G\\lambda_{G} - k_{x}\\lambda_{X}\n$$\n$$\n\\dot{\\lambda}_{X} = -\\frac{\\partial H}{\\partial X} = G\\lambda_{G} + k_{x}\\lambda_{X}\n$$\nFor $\\lambda_{I}$:\n$$\n\\frac{\\partial H}{\\partial I} = \\lambda_{X}(s) + \\lambda_{I}(-k_{i}) = s\\lambda_{X} - k_{i}\\lambda_{I}\n$$\n$$\n\\dot{\\lambda}_{I} = -\\frac{\\partial H}{\\partial I} = -s\\lambda_{X} + k_{i}\\lambda_{I}\n$$\nThe costate dynamics are thus the 3-tuple:\n$$\n\\left(\\dot{\\lambda}_{G}, \\dot{\\lambda}_{X}, \\dot{\\lambda}_{I}\\right) = \\left(-q(G - G_{\\mathrm{ref}}) + \\lambda_{G}(k_{g} + X), \\quad G\\lambda_{G} + k_{x}\\lambda_{X}, \\quad -s\\lambda_{X} + k_{i}\\lambda_{I}\\right)\n$$\n\n**3. The Stationary Control Law**\n\nAccording to the PMP, the optimal control $u^{\\ast}(t)$ must minimize the Hamiltonian $H$ at each time $t$ over the set of admissible controls, $\\mathcal{U} = [0, u_{\\max}]$.\nThe Hamiltonian is a function of $u$:\n$$\nH(u) = \\frac{1}{2} r u^{2} + \\lambda_{I} u + (\\text{terms not involving } u)\n$$\nSince $r > 0$, $H(u)$ is a convex parabola in $u$. To find its minimum, we compute the derivative with respect to $u$:\n$$\n\\frac{\\partial H}{\\partial u} = ru + \\lambda_{I}\n$$\nSetting the derivative to zero gives the unconstrained minimum at $u = -\\frac{\\lambda_{I}}{r}$.\n\nTo account for the bounds $0 \\leq u \\leq u_{\\max}$, we project this unconstrained solution onto the admissible interval $[0, u_{\\max}]$. This yields a saturated control law. The analysis is as follows:\n- If $-\\frac{\\lambda_{I}}{r} < 0$, which is equivalent to $\\lambda_{I} > 0$, the minimum of the increasing function $H(u)$ on $[0, u_{\\max}]$ occurs at the lower bound, $u^{\\ast} = 0$.\n- If $-\\frac{\\lambda_{I}}{r} > u_{\\max}$, which is equivalent to $\\lambda_{I} < -r u_{\\max}$, the minimum of the decreasing function $H(u)$ on $[0, u_{\\max}]$ occurs at the upper bound, $u^{\\ast} = u_{\\max}$.\n- If $0 \\leq -\\frac{\\lambda_{I}}{r} \\leq u_{\\max}$, which is equivalent to $-r u_{\\max} \\leq \\lambda_{I} \\leq 0$, the unconstrained minimum lies within the admissible interval, so $u^{\\ast} = -\\frac{\\lambda_{I}}{r}$.\n\nThe problem refers to a \"switching function\". In this context, the costate $\\lambda_{I}(t)$ acts as the switching function, as its value determines which control regime (lower bound, upper bound, or interior) is active. The optimal control law $u^{\\ast}(t)$ is expressed explicitly as a piecewise function of this switching function $\\lambda_{I}(t)$:\n$$\nu^{\\ast}(t) = \\begin{cases} u_{\\max} & \\text{if } \\lambda_I(t) < -r u_{\\max} \\\\ -\\frac{\\lambda_I(t)}{r} & \\text{if } -r u_{\\max} \\le \\lambda_I(t) \\le 0 \\\\ 0 & \\text{if } \\lambda_I(t) > 0 \\end{cases}\n$$\nThis completes the required derivations. The results will be assembled into the specified matrix format.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2} q (G - G_{\\mathrm{ref}})^{2} + \\frac{1}{2} r u^{2} + \\lambda_{G} (-k_{g}(G - G_{\\mathrm{b}}) - XG + D(t)) + \\lambda_{X} (-k_{x} X + sI) + \\lambda_{I} (-k_{i} I + u) & \\begin{pmatrix} -q(G - G_{\\mathrm{ref}}) + \\lambda_{G}(k_{g} + X) \\\\ G\\lambda_{G} + k_{x}\\lambda_{X} \\\\ -s\\lambda_{X} + k_{i}\\lambda_{I} \\end{pmatrix} & \\begin{cases} u_{\\max} & \\text{if } \\lambda_I < -r u_{\\max} \\\\ -\\frac{\\lambda_I}{r} & \\text{if } -r u_{\\max} \\le \\lambda_I \\le 0 \\\\ 0 & \\text{if } \\lambda_I > 0 \\end{cases} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Building on the fundamentals of the PMP, this practice explores the more advanced and subtle case of singular control. Such scenarios often arise in biological control problems where the control input, like a gene transcription rate, affects the system dynamics linearly . You will learn to identify when a singular arc might occur and derive the singular control law by analyzing higher-order time derivatives of the switching function, revealing a feedback structure hidden within the optimality conditions.",
            "id": "3914914",
            "problem": "Consider a linearized two-stage gene expression model for a single protein under optogenetic regulation about a nonzero basal operating point. Let the state vector be $x(t) = \\begin{pmatrix} m(t) \\\\ p(t) \\end{pmatrix}$, where $m(t)$ is the deviation of messenger ribonucleic acid (mRNA) concentration from baseline and $p(t)$ is the deviation of protein concentration from baseline. The scalar control $u(t)$ represents the deviation of the transcription initiation rate from baseline, allowed to take positive or negative values due to small-signal linearization. The dynamics are\n$$\n\\dot{m}(t) = k_{m}\\,u(t) - \\delta_{m}\\,m(t), \\qquad\n\\dot{p}(t) = k_{p}\\,m(t) - \\delta_{p}\\,p(t),\n$$\nwith strictly positive parameters $k_{m}$, $k_{p}$, $\\delta_{m}$, and $\\delta_{p}$. Consider the finite-horizon optimal control problem on $[0,T]$ with the cost functional\n$$\nJ[u] = \\int_{0}^{T} \\left( \\tfrac{1}{2}\\,q_{m}\\,m(t)^{2} + \\tfrac{1}{2}\\,q_{p}\\,p(t)^{2} + \\rho\\,u(t) \\right)\\,dt,\n$$\nwhere $q_{m}>0$, $q_{p}>0$, and $\\rho>0$. There is no terminal cost and no explicit control bounds for the purpose of the singular arc analysis.\n\nUsing the Pontryagin's Minimum Principle (PMP) for minimization, analyze the necessary conditions for optimality and determine whether a singular arc can occur. If so, determine the order of singularity (the smallest integer $r \\geq 0$ such that the $r$-th time derivative of the switching function depends explicitly on $u$) and compute the corresponding singular control law $u_{\\mathrm{sing}}(t)$ expressed purely in terms of $m(t)$, $p(t)$, and the model parameters. Assume the costates are absolutely continuous and all functions are sufficiently smooth for the required differentiations.\n\nYour final answer must be a row matrix with two entries: first the integer order of singularity, then the closed-form expression of the singular control. No numerical evaluation is required; express the final result symbolically. If you choose to define any intermediate symbols, eliminate them in the final expression so that the singular control is given directly in terms of $m(t)$, $p(t)$, and the given parameters.",
            "solution": "The problem as stated is valid. It is a well-posed optimal control problem grounded in the standard principles of systems biology and control theory. The system dynamics represent a linearized two-stage gene expression model, a common and scientifically sound construct. The objective functional is clearly defined, and all parameters are specified with the necessary conditions (e.g., positivity). The task requires the application of Pontryagin's Minimum Principle (PMP) to analyze singular arcs, which is a standard procedure in optimal control theory. The problem is self-contained, mathematically consistent, and free from any scientific or logical flaws.\n\nWe apply the Pontryagin's Minimum Principle for minimization. The state vector is $x(t) = \\begin{pmatrix} m(t) \\\\ p(t) \\end{pmatrix}$ and the costate vector is $\\lambda(t) = \\begin{pmatrix} \\lambda_m(t) \\\\ \\lambda_p(t) \\end{pmatrix}$. The Hamiltonian $H$ for this system is defined as:\n$$\nH(x, u, \\lambda) = L(x, u) + \\lambda^{T}f(x, u)\n$$\nwhere $L(x, u) = \\tfrac{1}{2}\\,q_{m}\\,m(t)^{2} + \\tfrac{1}{2}\\,q_{p}\\,p(t)^{2} + \\rho\\,u(t)$ is the integrand of the cost functional, and $f(x, u)$ is the vector field describing the system dynamics.\nSubstituting the given expressions, the Hamiltonian is:\n$$\nH = \\left( \\tfrac{1}{2}\\,q_{m}\\,m^{2} + \\tfrac{1}{2}\\,q_{p}\\,p^{2} + \\rho\\,u \\right) + \\lambda_{m}(k_{m}\\,u - \\delta_{m}\\,m) + \\lambda_{p}(k_{p}\\,m - \\delta_{p}\\,p)\n$$\nWe can regroup the terms based on the control input $u(t)$:\n$$\nH = (k_{m}\\lambda_{m} + \\rho)u + \\tfrac{1}{2}\\,q_{m}\\,m^{2} + \\tfrac{1}{2}\\,q_{p}\\,p^{2} - \\delta_{m}\\lambda_{m}m + k_{p}\\lambda_{p}m - \\delta_{p}\\lambda_{p}p\n$$\nThe PMP states that the optimal control $u^{*}(t)$ must minimize the Hamiltonian $H$ at each time $t \\in [0,T]$. Since the Hamiltonian is linear in the control $u$, the minimizing control depends on the sign of its coefficient, which is called the switching function, $\\Phi(t)$.\n$$\n\\Phi(t) = \\frac{\\partial H}{\\partial u} = k_{m}\\lambda_{m}(t) + \\rho\n$$\nAs there are no explicit bounds on $u$, non-singular optimal control would be \"bang-bang\" with infinite amplitude, which is physically unrealistic and suggests that the optimal trajectory may lie on a singular arc. A singular arc may occur if the switching function is zero over a finite time interval, i.e., $\\Phi(t) = 0$ for $t \\in [t_1, t_2] \\subseteq [0,T]$. For this to hold, all time derivatives of $\\Phi(t)$ must also be zero on this interval.\n\nThe order of singularity, $r$, is the smallest integer such that the $r$-th total time derivative of $\\Phi(t)$, denoted $\\Phi^{(r)}(t)$, explicitly depends on the control $u(t)$. We compute these derivatives.\n\nFor a singular arc to exist, the first condition is:\n$$\n\\Phi(t) = k_{m}\\lambda_{m}(t) + \\rho = 0\n$$\nThis implies that on the singular arc, the costate $\\lambda_m(t)$ must be constant:\n$$\n\\lambda_{m}(t) = -\\frac{\\rho}{k_{m}}\n$$\nThis is the zeroth-order condition ($r=0$). It does not contain $u$. We proceed to the first derivative, $\\dot{\\Phi}(t)$.\n$$\n\\dot{\\Phi}(t) = k_{m}\\dot{\\lambda}_{m}(t)\n$$\nThe costate dynamics are given by $\\dot{\\lambda} = -\\frac{\\partial H}{\\partial x}$.\n$$\n\\dot{\\lambda}_{m} = -\\frac{\\partial H}{\\partial m} = -\\left( q_{m}m - \\delta_{m}\\lambda_{m} + k_{p}\\lambda_{p} \\right) = -q_{m}m + \\delta_{m}\\lambda_{m} - k_{p}\\lambda_{p}\n$$\n$$\n\\dot{\\lambda}_{p} = -\\frac{\\partial H}{\\partial p} = -\\left( q_{p}p - \\delta_{p}\\lambda_{p} \\right) = -q_{p}p + \\delta_{p}\\lambda_{p}\n$$\nThus, the first derivative of the switching function is:\n$$\n\\dot{\\Phi}(t) = k_{m}(-q_{m}m + \\delta_{m}\\lambda_{m} - k_{p}\\lambda_{p})\n$$\nThis expression for $\\dot{\\Phi}(t)$ does not explicitly depend on $u(t)$. For a singular arc, we require $\\dot{\\Phi}(t) = 0$.\n$$\n-q_{m}m(t) + \\delta_{m}\\lambda_{m}(t) - k_{p}\\lambda_{p}(t) = 0\n$$\nSubstituting the constant value of $\\lambda_{m}(t)$ from the $\\Phi(t)=0$ condition:\n$$\n-q_{m}m(t) + \\delta_{m}\\left(-\\frac{\\rho}{k_{m}}\\right) - k_{p}\\lambda_{p}(t) = 0\n$$\nThis allows us to express the costate $\\lambda_p(t)$ in terms of the state $m(t)$ along the singular arc:\n$$\n\\lambda_{p}(t) = -\\frac{q_{m}}{k_{p}}m(t) - \\frac{\\rho\\delta_{m}}{k_{m}k_{p}}\n$$\nNow, we compute the second time derivative, $\\ddot{\\Phi}(t)$.\n$$\n\\ddot{\\Phi}(t) = \\frac{d}{dt}\\left( \\dot{\\Phi}(t) \\right) = k_{m}(-q_{m}\\dot{m} + \\delta_{m}\\dot{\\lambda}_{m} - k_{p}\\dot{\\lambda}_{p})\n$$\nOn the singular arc, $\\lambda_m(t)$ is constant, so $\\dot{\\lambda}_m(t)=0$. The expression simplifies to:\n$$\n\\ddot{\\Phi}(t) = k_{m}(-q_{m}\\dot{m} - k_{p}\\dot{\\lambda}_{p})\n$$\nWe substitute the expressions for the state and costate dynamics:\n$\\dot{m}(t) = k_{m}u(t) - \\delta_{m}m(t)$\n$\\dot{\\lambda}_{p}(t) = -q_{p}p(t) + \\delta_{p}\\lambda_{p}(t)$\nSubstituting these into $\\ddot{\\Phi}(t)$:\n$$\n\\ddot{\\Phi}(t) = k_{m}\\left( -q_{m}(k_{m}u - \\delta_{m}m) - k_{p}(-q_{p}p + \\delta_{p}\\lambda_{p}) \\right)\n$$\n$$\n\\ddot{\\Phi}(t) = k_{m}\\left( -q_{m}k_{m}u + q_{m}\\delta_{m}m + k_{p}q_{p}p-k_{p}\\delta_{p}\\lambda_{p} \\right)\n$$\nThe control $u(t)$ appears explicitily for the first time in the second derivative of the switching function. Therefore, the order of singularity is $r=2$.\n\nTo find the singular control, $u_{\\mathrm{sing}}(t)$, we set $\\ddot{\\Phi}(t)=0$ and solve for $u$:\n$$\n-q_{m}k_{m}u_{\\mathrm{sing}} + q_{m}\\delta_{m}m + k_{p}q_{p}p - k_{p}\\delta_{p}\\lambda_{p} = 0\n$$\n$$\nu_{\\mathrm{sing}}(t) = \\frac{1}{q_{m}k_{m}}\\left( q_{m}\\delta_{m}m(t) + k_{p}q_{p}p(t) - k_{p}\\delta_{p}\\lambda_{p}(t) \\right)\n$$\nThis expression currently depends on the costate $\\lambda_p(t)$. We eliminate it using the relationship derived from the $\\dot{\\Phi}(t)=0$ condition:\n$$\n\\lambda_{p}(t) = -\\frac{q_{m}}{k_{p}}m(t) - \\frac{\\rho\\delta_{m}}{k_{m}k_{p}}\n$$\nSubstituting this into the expression for $u_{\\mathrm{sing}}(t)$:\n$$\nu_{\\mathrm{sing}}(t) = \\frac{1}{q_{m}k_{m}}\\left[ q_{m}\\delta_{m}m(t) + k_{p}q_{p}p(t) - k_{p}\\delta_{p}\\left(-\\frac{q_{m}}{k_{p}}m(t) - \\frac{\\rho\\delta_{m}}{k_{m}k_{p}}\\right) \\right]\n$$\n$$\nu_{\\mathrm{sing}}(t) = \\frac{1}{q_{m}k_{m}}\\left[ q_{m}\\delta_{m}m(t) + k_{p}q_{p}p(t) + q_{m}\\delta_{p}m(t) + \\frac{\\rho\\delta_{m}\\delta_{p}}{k_{m}} \\right]\n$$\nGrouping terms with $m(t)$ and simplifying:\n$$\nu_{\\mathrm{sing}}(t) = \\frac{1}{q_{m}k_{m}}\\left[ q_{m}(\\delta_{m}+\\delta_{p})m(t) + q_{p}k_{p}p(t) + \\frac{\\rho\\delta_{m}\\delta_{p}}{k_{m}} \\right]\n$$\nFinally, distributing the outer term gives the singular control as a function of the states and system parameters:\n$$\nu_{\\mathrm{sing}}(t) = \\frac{\\delta_{m} + \\delta_{p}}{k_{m}} m(t) + \\frac{q_{p}k_{p}}{q_{m}k_{m}} p(t) + \\frac{\\rho\\delta_{m}\\delta_{p}}{q_{m}k_{m}^{2}}\n$$\nThis represents a linear state-feedback control law with an affine offset.\n\nThe two parts of the answer are the order of singularity, $r=2$, and the derived expression for $u_{\\mathrm{sing}}(t)$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & \\frac{\\delta_{m}+\\delta_{p}}{k_{m}}m(t) + \\frac{q_{p}k_{p}}{q_{m}k_{m}}p(t) + \\frac{\\rho\\delta_{m}\\delta_{p}}{q_{m}k_{m}^{2}} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While analytical methods like the PMP offer profound insight, most complex optimal control problems are ultimately solved using numerical techniques. This exercise bridges the gap between continuous-time theory and computational practice by introducing direct collocation, a powerful method for transcribing an optimal control problem into a nonlinear programming (NLP) problem . You will discretize a tumor growth model and derive the Karush-Kuhn-Tucker (KKT) conditions, discovering the deep connection between the continuous costates of PMP and the discrete Lagrange multipliers, which act as 'shadow prices' in the resulting optimization.",
            "id": "3914945",
            "problem": "Consider a single-compartment model of tumor cell population under chemotherapeutic dosing, where conservation of mass and linearization about a nominal operating point yield the controlled dynamics $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ over a dosing interval of duration $h>0$. Here $x(t)$ is the tumor cell population, $u(t)$ is the dosing rate, $a$ is the local tumor net growth rate constant, and $b$ is the local drug efficacy coefficient mapping dose rate to net reduction in tumor growth. Assume the dosing decision is made once per interval and held constant at the collocation stage.\n\nUse the implicit midpoint direct collocation scheme to discretize the dynamics on a single interval $\\left[0,h\\right]$. Introduce the decision variables $x_c$, $u_c$, and $x_1$ denoting the state and control at the collocation point and the state at the end of the interval, respectively, with a known initial state $x_0$. The direct collocation equalities are\n$$\nx_c = x_0 + \\frac{h}{2}\\,f(x_c,u_c), \\qquad x_1 = x_0 + h\\,f(x_c,u_c),\n$$\nwhere $f(x,u) = a\\,x + b\\,u$.\n\nFormulate the nonlinear programming (NLP) problem that minimizes a standard quadratic surrogate for clinical objectives,\n$$\nJ(x_1,u_c) = \\frac{1}{2}\\,q\\,x_1^{2} + \\frac{1}{2}\\,r\\,u_c^{2},\n$$\nwith $q>0$ penalizing terminal tumor burden and $r>0$ penalizing dosing toxicity, subject to the direct collocation equalities. Starting from the fundamental definitions of the Karush-Kuhn-Tucker (KKT) conditions for equality-constrained optimization, derive the stationarity and feasibility conditions for this discretized optimal control problem by introducing Lagrange multipliers for the collocation equations. Then, reduce the KKT system to obtain a single closed-form analytic expression for the optimal collocation control $u_c^{\\star}$ as a function of $a$, $b$, $q$, $r$, $h$, and $x_0$ only.\n\nExplain the biological interpretation of the resulting KKT conditions as discrete balance laws: identify how each stationarity equation expresses a balance between marginal toxicity and marginal therapeutic benefit, and how the Lagrange multipliers act as shadow prices that propagate marginal value of tumor cells across the collocation stage and the end of the interval.\n\nProvide the final expression for $u_c^{\\star}$ in symbolic form. Do not substitute numerical values. Do not include units in your final expression. No rounding is required.",
            "solution": "The problem is to find the optimal constant control $u_c$ over a single time interval $[0,h]$ that minimizes a quadratic cost function, subject to the dynamics of a tumor cell population discretized by the implicit midpoint collocation method. This can be formulated as a nonlinear programming (NLP) problem with equality constraints.\n\nThe decision variables for the NLP are the collocation state $x_c$, the collocation control $u_c$, and the terminal state $x_1$. The initial state $x_0$ is a given parameter.\n\nThe objective function to be minimized is:\n$$\nJ(x_1, u_c) = \\frac{1}{2} q x_1^2 + \\frac{1}{2} r u_c^2\n$$\nThe problem is subject to two equality constraints derived from the implicit midpoint collocation scheme:\n\\begin{align*}\nc_1(x_c, u_c, x_1) &= x_c - x_0 - \\frac{h}{2} f(x_c, u_c) = 0 \\\\\nc_2(x_c, u_c, x_1) &= x_1 - x_0 - h f(x_c, u_c) = 0\n\\end{align*}\nwhere the system dynamics function is $f(x,u) = ax + bu$. Substituting this into the constraints yields:\n\\begin{align*}\nc_1(x_c, u_c, x_1) &= x_c - x_0 - \\frac{h}{2}(a x_c + b u_c) = 0 \\label{eq:c1} \\\\\nc_2(x_c, u_c, x_1) &= x_1 - x_0 - h(a x_c + b u_c) = 0 \\label{eq:c2}\n\\end{align*}\nTo solve this constrained optimization problem, we use the method of Lagrange multipliers. We form the Lagrangian function $L$ by augmenting the objective function with the constraints, weighted by Lagrange multipliers $\\lambda_c$ and $\\lambda_1$:\n$$\nL(x_c, u_c, x_1, \\lambda_c, \\lambda_1) = J(x_1, u_c) - \\lambda_c c_1(x_c, u_c, x_1) - \\lambda_1 c_2(x_c, u_c, x_1)\n$$\nSubstituting the expressions for $J$ and the constraints:\n$$\nL = \\frac{1}{2}q x_1^2 + \\frac{1}{2}r u_c^2 - \\lambda_c \\left( x_c - x_0 - \\frac{h}{2}(a x_c + b u_c) \\right) - \\lambda_1 \\left( x_1 - x_0 - h(a x_c + b u_c) \\right)\n$$\nThe first-order necessary conditions for optimality are the Karush-Kuhn-Tucker (KKT) conditions. For this equality-constrained problem, they consist of the stationarity and feasibility conditions.\n\nThe stationarity conditions require the gradient of the Lagrangian with respect to the decision variables $(x_c, u_c, x_1)$ to be zero:\n\\begin{align*}\n\\frac{\\partial L}{\\partial x_c} &= -\\lambda_c \\left(1 - \\frac{ah}{2}\\right) - \\lambda_1(-ah) = 0 \\label{eq:dLdxc} \\\\\n\\frac{\\partial L}{\\partial u_c} &= r u_c - \\lambda_c \\left(-\\frac{bh}{2}\\right) - \\lambda_1(-bh) = 0 \\label{eq:dLduc} \\\\\n\\frac{\\partial L}{\\partial x_1} &= q x_1 - \\lambda_1 = 0 \\label{eq:dLdx1}\n\\end{align*}\nThe feasibility conditions require that the constraints are satisfied, which is equivalent to setting the partial derivatives of $L$ with respect to the multipliers to zero:\n\\begin{align*}\n\\frac{\\partial L}{\\partial \\lambda_c} &= -(x_c - x_0 - \\frac{h}{2}(a x_c + b u_c)) = 0 \\label{eq:dLdlamc} \\\\\n\\frac{\\partial L}{\\partial \\lambda_1} &= -(x_1 - x_0 - h(a x_c + b u_c)) = 0 \\label{eq:dLdlam1}\n\\end{align*}\nThis gives a system of five equations for the five unknowns $x_c$, $u_c$, $x_1$, $\\lambda_c$, and $\\lambda_1$.\n\nBefore solving the system, we can interpret these KKT conditions.\nThe feasibility conditions simply state that the solution must obey the discretized system dynamics.\nThe stationarity conditions express economic-like balance principles. The Lagrange multipliers, $\\lambda_c$ and $\\lambda_1$, are interpreted as shadow prices, representing the marginal cost (or sensitivity of the objective function $J$) with respect to a small change in the constraints.\n$1$. The condition $\\frac{\\partial L}{\\partial x_1} = q x_1 - \\lambda_1 = 0$ implies $\\lambda_1 = q x_1$. This equation sets the shadow price of the terminal tumor population, $\\lambda_1$, equal to its marginal penalty, $\\frac{\\partial J}{\\partial x_1} = q x_1$. This is a terminal boundary condition for the shadow price.\n$2$. The condition $\\frac{\\partial L}{\\partial u_c} = r u_c + \\frac{bh}{2}\\lambda_c + bh\\lambda_1 = 0$ can be written as $r u_c = -(\\frac{bh}{2}\\lambda_c + bh\\lambda_1)$. The left side, $r u_c$, represents the marginal toxicity cost of the drug dose. The right side represents the marginal therapeutic benefit, which is the reduction in total cost achieved by applying the control $u_c$, propagated through its effect on the states $x_c$ and $x_1$. The optimality condition requires balancing this marginal cost against the marginal benefit.\n$3$. The condition $\\frac{\\partial L}{\\partial x_c} = -\\lambda_c(1 - \\frac{ah}{2}) + ah\\lambda_1 = 0$, or $\\lambda_c(1 - \\frac{ah}{2}) = ah\\lambda_1$, is a discrete adjoint (or co-state) equation. It relates the shadow price at the collocation point, $\\lambda_c$, to the shadow price at the end of the interval, $\\lambda_1$. It describes how the marginal value of the tumor population is propagated backward in time through the interval, adjusted by the tumor's natural growth dynamics represented by the parameter $a$.\n\nNow, we solve this system for $u_c^{\\star}$.\nFrom $\\frac{\\partial L}{\\partial x_1} = 0$, we have $\\lambda_1 = q x_1$.\nSubstitute this into the other two stationarity equations:\n\\begin{align*}\n-\\lambda_c\\left(1 - \\frac{ah}{2}\\right) + ah(q x_1) &= 0 \\implies \\lambda_c = \\frac{ahq x_1}{1 - \\frac{ah}{2}} \\\\\nr u_c + \\frac{bh}{2}\\lambda_c + bh(q x_1) &= 0\n\\end{align*}\nSubstitute the expression for $\\lambda_c$ into the second equation:\n$$\nr u_c + \\frac{bh}{2} \\left( \\frac{ahq x_1}{1 - \\frac{ah}{2}} \\right) + bhq x_1 = 0\n$$\nFactor out $bhq x_1$:\n$$\nr u_c + bhq x_1 \\left( \\frac{a h/2}{1 - ah/2} + 1 \\right) = 0\n$$\nSimplify the term in the parentheses:\n$$\n\\frac{ah/2 + 1 - ah/2}{1 - ah/2} = \\frac{1}{1 - ah/2}\n$$\nThe equation becomes:\n$$\nr u_c + \\frac{bhq x_1}{1 - ah/2} = 0\n$$\nThis gives a direct relationship between the optimal control $u_c$ and the terminal state $x_1$:\n$$\nu_c = -\\frac{bhq}{r(1 - ah/2)} x_1\n$$\nNext, we must express $x_1$ in terms of the initial state $x_0$ and the system parameters. We use the two feasibility (collocation) equations:\n\\begin{align*}\nx_c(1 - \\frac{ah}{2}) &= x_0 + \\frac{bh}{2} u_c \\implies x_c = \\frac{x_0 + \\frac{bh}{2} u_c}{1 - \\frac{ah}{2}} \\\\\nx_1 &= x_0 + h(a x_c + b u_c)\n\\end{align*}\nSubstitute the expression for $x_c$ into the equation for $x_1$:\n$$\nx_1 = x_0 + h \\left( a \\left( \\frac{x_0 + \\frac{bh}{2} u_c}{1 - \\frac{ah}{2}} \\right) + b u_c \\right)\n$$\nNow substitute the expression for $u_c$ in terms of $x_1$ into this equation:\n$$\nx_1 = x_0 + h \\left( a \\frac{x_0 + \\frac{bh}{2} \\left(-\\frac{bhq}{r(1 - ah/2)} x_1\\right)}{1 - \\frac{ah}{2}} + b \\left(-\\frac{bhq}{r(1 - ah/2)} x_1\\right) \\right)\n$$\nThis equation contains only the unknown $x_1$. We solve for $x_1$:\n$$\nx_1 = x_0 + \\frac{ahx_0}{1 - ah/2} - \\frac{ab^2h^3q}{2r(1 - ah/2)^2} x_1 - \\frac{b^2h^2q}{r(1 - ah/2)} x_1\n$$\nGroup terms with $x_1$ on the left-hand side and terms with $x_0$ on the right-hand side:\n$$\nx_1 \\left( 1 + \\frac{ab^2h^3q}{2r(1 - ah/2)^2} + \\frac{b^2h^2q}{r(1 - ah/2)} \\right) = x_0 \\left( 1 + \\frac{ah}{1 - ah/2} \\right)\n$$\nSimplify both sides. For the right-hand side:\n$$\nx_0 \\left( \\frac{1 - ah/2 + ah}{1 - ah/2} \\right) = x_0 \\frac{1 + ah/2}{1 - ah/2}\n$$\nFor the coefficient of $x_1$ on the left-hand side:\n$$\n1 + \\frac{b^2h^2q}{r(1-ah/2)^2} \\left( \\frac{ah}{2} + (1 - \\frac{ah}{2}) \\right) = 1 + \\frac{b^2h^2q}{r(1-ah/2)^2}\n$$\nSo the equation for $x_1$ becomes:\n$$\nx_1 \\left( 1 + \\frac{b^2h^2q}{r(1-ah/2)^2} \\right) = x_0 \\frac{1 + ah/2}{1 - ah/2}\n$$\n$$\nx_1 \\left( \\frac{r(1-ah/2)^2 + b^2h^2q}{r(1-ah/2)^2} \\right) = x_0 \\frac{1 + ah/2}{1 - ah/2}\n$$\n$$\nx_1 = x_0 \\frac{1 + ah/2}{1 - ah/2} \\frac{r(1-ah/2)^2}{r(1-ah/2)^2 + b^2h^2q} = x_0 \\frac{r(1+ah/2)(1-ah/2)}{r(1-ah/2)^2 + b^2h^2q}\n$$\nFinally, we substitute this expression for $x_1$ back into our equation for $u_c$:\n$$\nu_c^{\\star} = -\\frac{bhq}{r(1 - ah/2)} x_1 = -\\frac{bhq}{r(1 - ah/2)} \\left( x_0 \\frac{r(1+ah/2)(1-ah/2)}{r(1-ah/2)^2 + b^2h^2q} \\right)\n$$\nThe term $r(1 - ah/2)$ cancels from the numerator and the denominator, leading to the final expression for the optimal control $u_c^{\\star}$:\n$$\nu_c^{\\star} = -bhq x_0 \\frac{1+ah/2}{r(1-ah/2)^2 + b^2h^2q}\n$$\nThis expression can be expanded for clarity, but this compact form is sufficient. The denominator can be written as $r(1 - ah + a^2h^2/4) + qb^2h^2$.",
            "answer": "$$\\boxed{- \\frac{b h q x_{0} (1 + \\frac{ah}{2})}{r(1-\\frac{ah}{2})^{2} + q b^{2} h^{2}}}$$"
        }
    ]
}