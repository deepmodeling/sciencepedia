{
    "hands_on_practices": [
        {
            "introduction": "Understanding higher-order Runge-Kutta methods begins with their construction. This exercise  takes you back to first principles, showing how the coefficients in a Butcher tableau are not arbitrary but are derived by solving a system of algebraic equations known as order conditions. By building a third-order method from scratch, you will gain a deeper appreciation for the interplay between accuracy and the specific choice of method parameters, including how these choices impact desirable properties like non-negativity in biomedical simulations.",
            "id": "3890888",
            "problem": "A pharmacokinetic one-compartment model with elimination is governed by the ordinary differential equation (ODE) $dx/dt = f(t,x)$ with $x(t) \\ge 0$ representing the drug amount. In biomedical systems modeling of such dynamics, one often seeks time-stepping schemes that are accurate and that preserve nonnegativity of stage evaluations and weights to avoid introducing artificial negative concentrations. Consider an explicit $3$-stage Runge–Kutta (RK) method for approximating solutions of $dx/dt = f(t,x)$ over a stepsize $h>0$, specified by a strictly lower-triangular Butcher matrix $A \\in \\mathbb{R}^{3 \\times 3}$, weights $b \\in \\mathbb{R}^{3}$, and nodes $c \\in \\mathbb{R}^{3}$ with $c_1 = 0$, $c_2 \\in (0,1)$, and $c_3 = 1$. The method is required to satisfy the third-order conditions up to order $3$ (using the standard rooted-tree moment constraints): $b^{\\top}\\mathbf{1} = 1$, $b^{\\top} c = 1/2$, $b^{\\top} c^{[2]} = 1/3$, and $b^{\\top} A c = 1/6$, where $\\mathbf{1} = (1,1,1)^{\\top}$ and $c^{[2]}$ denotes the elementwise square of $c$. Assume the method is explicit so that $c_2 = a_{21}$ and $c_3 = a_{31} + a_{32}$.\n\nDerive, from first principles starting at the definition of explicit Runge–Kutta methods and the above order conditions, explicit expressions for $b_2$ and $b_3$ in terms of $c_2$ and $c_3$, then specialize to $c_3 = 1$ to obtain $b_2(c_2)$ and $b_3(c_2)$. Next, use the condition $b^{\\top} A c = 1/6$ to express $a_{32}$ and $a_{31}$ in terms of $c_2$ and $b_3$. Discuss the feasibility of the resulting $(A,b,c)$ under the biomedical nonnegativity desiderata, including whether $a_{31}$ can be nonnegative, and identify any restrictions on $c_2$ required for the weights to be nonnegative.\n\nFinally, report the supremum of $c_2 \\in (0,1)$ for which all weights $b_1$, $b_2$, and $b_3$ are nonnegative and the order conditions admit a finite explicit scheme with $c_3 = 1$. Your final answer must be a single number written exactly (no rounding). No units are required. If you use any approximations in intermediate steps, do not round the final result.",
            "solution": "The user wants to analyze a 3-stage, third-order explicit Runge-Kutta method.\n\n### Step 1: Extract Givens\n- **ODE Model**: $\\frac{dx}{dt} = f(t,x)$ for a drug amount $x(t) \\ge 0$.\n- **Method Type**: Explicit $3$-stage Runge-Kutta (RK) method.\n- **Butcher Tableau Components**:\n    - `A`: a strictly lower-triangular matrix, $A \\in \\mathbb{R}^{3 \\times 3}$.\n    - `b`: a vector of weights, $b \\in \\mathbb{R}^{3}$.\n    - `c`: a vector of nodes, $c \\in \\mathbb{R}^{3}$.\n- **Node Conditions**:\n    - $c_1 = 0$\n    - $c_2 \\in (0,1)$\n    - $c_3 = 1$ (This is specified initially as $c_3 \\in (0,1]$ in some parts of the prompt, but the main derivation and final question fix $c_3=1$). Let's assume $c_3=1$ for the relevant parts as instructed.\n- **Order Conditions (up to order 3)**:\n    1. $b^{\\top}\\mathbf{1} = 1$, where $\\mathbf{1} = (1,1,1)^{\\top}$.\n    2. $b^{\\top}c = 1/2$.\n    3. $b^{\\top}c^{[2]} = 1/3$, where $c^{[2]}$ is the elementwise square of $c$.\n    4. $b^{\\top}Ac = 1/6$.\n- **Explicitness Conditions**:\n    - $A$ is strictly lower-triangular, i.e., $a_{ij} = 0$ for $j \\ge i$.\n    - $c_i = \\sum_{j=1}^{i-1} a_{ij}$ for $i=2,3$. This specializes to $c_2 = a_{21}$ and $c_3 = a_{31} + a_{32}$.\n- **Biomedical Desiderata**: Nonnegativity of weights ($b_i \\ge 0$) and stage coefficients ($a_{ij} \\ge 0$).\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It deals with standard theory of Runge-Kutta methods, specifically the derivation of coefficients from order conditions. The application to pharmacokinetic models and the associated nonnegativity constraints are a well-established topic in numerical analysis for biomedical systems (e.g., strong stability preserving methods). The problem is well-posed, providing sufficient equations and constraints to derive the requested quantities. The language is objective and precise. The problem is self-contained and does not violate any physical or mathematical principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe analysis proceeds by systematically solving the algebraic constraints imposed by the order conditions.\n\n**1. Derive expressions for the weights $b_i$**\n\nThe first three order conditions form a linear system for the weights $b_1$, $b_2$, and $b_3$.\nThe conditions are:\n1. $\\sum_{i=1}^3 b_i = b_1 + b_2 + b_3 = 1$\n2. $\\sum_{i=1}^3 b_i c_i = b_1 c_1 + b_2 c_2 + b_3 c_3 = 1/2$\n3. $\\sum_{i=1}^3 b_i c_i^2 = b_1 c_1^2 + b_2 c_2^2 + b_3 c_3^2 = 1/3$\n\nSubstituting the given node value $c_1 = 0$, the system simplifies to:\n1. $b_1 + b_2 + b_3 = 1$\n2. $b_2 c_2 + b_3 c_3 = 1/2$\n3. $b_2 c_2^2 + b_3 c_3^2 = 1/3$\n\nWe can solve the last two equations for $b_2$ and $b_3$ in terms of $c_2$ and $c_3$. This is a $2 \\times 2$ linear system:\n$$\n\\begin{pmatrix} c_2 & c_3 \\\\ c_2^2 & c_3^2 \\end{pmatrix} \\begin{pmatrix} b_2 \\\\ b_3 \\end{pmatrix} = \\begin{pmatrix} 1/2 \\\\ 1/3 \\end{pmatrix}\n$$\nThe determinant of the coefficient matrix is $D = c_2 c_3^2 - c_3 c_2^2 = c_2 c_3(c_3 - c_2)$. Since $c_2 \\in (0,1)$ and we are given $c_3$ as a distinct value in $(0,1]$, this determinant is non-zero. Using Cramer's rule:\n$$\nb_2 = \\frac{\\det \\begin{pmatrix} 1/2 & c_3 \\\\ 1/3 & c_3^2 \\end{pmatrix}}{D} = \\frac{\\frac{1}{2}c_3^2 - \\frac{1}{3}c_3}{c_2 c_3(c_3 - c_2)} = \\frac{\\frac{3c_3^2 - 2c_3}{6}}{c_2 c_3(c_3 - c_2)} = \\frac{c_3(3c_3 - 2)}{6c_2 c_3(c_3 - c_2)} = \\frac{3c_3 - 2}{6c_2(c_3 - c_2)}\n$$\n$$\nb_3 = \\frac{\\det \\begin{pmatrix} c_2 & 1/2 \\\\ c_2^2 & 1/3 \\end{pmatrix}}{D} = \\frac{\\frac{1}{3}c_2 - \\frac{1}{2}c_2^2}{c_2 c_3(c_3 - c_2)} = \\frac{\\frac{2c_2 - 3c_2^2}{6}}{c_2 c_3(c_3 - c_2)} = \\frac{c_2(2 - 3c_2)}{6c_2 c_3(c_3 - c_2)} = \\frac{2 - 3c_2}{6c_3(c_3 - c_2)}\n$$\nNow, we specialize to the case $c_3 = 1$:\n$$\nb_2(c_2) = \\frac{3(1) - 2}{6c_2(1 - c_2)} = \\frac{1}{6c_2(1 - c_2)}\n$$\n$$\nb_3(c_2) = \\frac{2 - 3c_2}{6(1)(1 - c_2)} = \\frac{2 - 3c_2}{6(1 - c_2)}\n$$\nWe find $b_1$ from $b_1 = 1 - b_2 - b_3$:\n$$\nb_1(c_2) = 1 - \\frac{1}{6c_2(1 - c_2)} - \\frac{2 - 3c_2}{6(1 - c_2)}\n$$\nTo combine these terms, we use the common denominator $6c_2(1 - c_2)$:\n$$\nb_1(c_2) = \\frac{6c_2(1 - c_2) - 1 - c_2(2 - 3c_2)}{6c_2(1 - c_2)} = \\frac{6c_2 - 6c_2^2 - 1 - 2c_2 + 3c_2^2}{6c_2(1 - c_2)}\n$$\n$$\nb_1(c_2) = \\frac{-3c_2^2 + 4c_2 - 1}{6c_2(1 - c_2)} = \\frac{-(3c_2^2 - 4c_2 + 1)}{6c_2(1 - c_2)}\n$$\nThe numerator factors as $-(3c_2 - 1)(c_2 - 1)$.\n$$\nb_1(c_2) = \\frac{-(3c_2 - 1)(c_2 - 1)}{6c_2(1 - c_2)} = \\frac{(3c_2 - 1)(1 - c_2)}{6c_2(1 - c_2)}\n$$\nSince $c_2 \\neq 1$, we can cancel the term $(1 - c_2)$, yielding:\n$$\nb_1(c_2) = \\frac{3c_2 - 1}{6c_2}\n$$\n\n**2. Derive expressions for $a_{31}$ and $a_{32}$**\n\nThe fourth order condition is $b^{\\top} A c = 1/6$. The Butcher matrix $A$ for a $3$-stage explicit method is:\n$$\nA = \\begin{pmatrix} 0 & 0 & 0 \\\\ a_{21} & 0 & 0 \\\\ a_{31} & a_{32} & 0 \\end{pmatrix}\n$$\nWith the explicit RK conditions $c_2 = a_{21}$ and $c_3 = a_{31} + a_{32}$, and setting $c_3=1$, we have $a_{21}=c_2$ and $a_{31} + a_{32} = 1$.\nFirst, calculate the product $Ac$:\n$$\nAc = \\begin{pmatrix} 0 & 0 & 0 \\\\ a_{21} & 0 & 0 \\\\ a_{31} & a_{32} & 0 \\end{pmatrix} \\begin{pmatrix} c_1 \\\\ c_2 \\\\ c_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ a_{21}c_2 \\\\ a_{31}c_2 + a_{32}c_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ c_2^2 \\\\ a_{31}c_2 + a_{32} \\end{pmatrix}\n$$\nNow compute the scalar product $b^{\\top}Ac$:\n$$\nb^{\\top}Ac = b_1(0) + b_2(c_2^2) + b_3(a_{31}c_2 + a_{32}) = \\frac{1}{6}\n$$\nSubstitute $a_{31} = 1 - a_{32}$ into the equation:\n$$\nb_2 c_2^2 + b_3((1 - a_{32})c_2 + a_{32}) = \\frac{1}{6}\n$$\n$$\nb_2 c_2^2 + b_3 c_2 - b_3 a_{32} c_2 + b_3 a_{32} = \\frac{1}{6}\n$$\n$$\na_{32} (b_3 - b_3 c_2) = \\frac{1}{6} - b_2 c_2^2 - b_3 c_2 \\implies a_{32} b_3 (1-c_2) = \\frac{1}{6} - b_2 c_2^2 - b_3 c_2\n$$\nSolving for $a_{32}$:\n$$\na_{32} = \\frac{\\frac{1}{6} - b_2 c_2^2 - b_3 c_2}{b_3(1-c_2)}\n$$\nSubstitute the expressions for $b_2$ and $b_3$:\n- The denominator is $b_3(1 - c_2) = \\frac{2 - 3c_2}{6(1-c_2)}(1-c_2) = \\frac{2 - 3c_2}{6}$.\n- The numerator is $\\frac{1}{6} - \\left(\\frac{1}{6c_2(1 - c_2)}\\right)c_2^2 - \\left(\\frac{2-3c_2}{6(1-c_2)}\\right)c_2 = \\frac{1}{6} - \\frac{c_2}{6(1-c_2)} - \\frac{c_2(2-3c_2)}{6(1-c_2)}$.\nCombining terms in the numerator:\n$$\n\\text{Numerator} = \\frac{1}{6} \\left(1 - \\frac{c_2}{1-c_2} - \\frac{c_2(2-3c_2)}{1-c_2} \\right) = \\frac{1}{6} \\left( \\frac{1-c_2 - c_2 - 2c_2 + 3c_2^2}{1-c_2} \\right)\n$$\n$$\n\\text{Numerator} = \\frac{1}{6} \\left( \\frac{3c_2^2 - 4c_2 + 1}{1-c_2} \\right) = \\frac{1}{6} \\frac{(3c_2 - 1)(c_2 - 1)}{1-c_2} = \\frac{1}{6} (-(3c_2 - 1)) = \\frac{1 - 3c_2}{6}\n$$\nSo, we find $a_{32}$:\n$$\na_{32} = \\frac{(1-3c_2)/6}{(2 - 3c_2)/6} = \\frac{1 - 3c_2}{2 - 3c_2}\n$$\nThen $a_{31}$ is found from $a_{31} = 1 - a_{32}$:\n$$\na_{31} = 1 - \\frac{1-3c_2}{2-3c_2} = \\frac{(2-3c_2) - (1-3c_2)}{2-3c_2} = \\frac{1}{2-3c_2}\n$$\n\n**3. Discussion of Feasibility and Nonnegativity**\n\nFor the method to be suitable for biomedical applications where concentrations must remain positive, it is desirable for all coefficients $b_i$ and $a_{ij}$ to be nonnegative. We analyze the constraints on $c_2 \\in (0,1)$.\n\n- **Nonnegativity of weights ($b_i \\ge 0$)**:\n    - $b_1 = \\frac{3c_2 - 1}{6c_2} \\ge 0 \\implies 3c_2 - 1 \\ge 0 \\implies c_2 \\ge \\frac{1}{3}$.\n    - $b_2 = \\frac{1}{6c_2(1-c_2)} > 0$ for all $c_2 \\in (0,1)$.\n    - $b_3 = \\frac{2 - 3c_2}{6(1-c_2)} \\ge 0 \\implies 2 - 3c_2 \\ge 0 \\implies c_2 \\le \\frac{2}{3}$.\n    - For all weights to be nonnegative, we require $c_2 \\in [\\frac{1}{3}, \\frac{2}{3}]$.\n\n- **Nonnegativity of matrix coefficients ($a_{ij} \\ge 0$)**:\n    - $a_{21} = c_2 > 0$ for all $c_2 \\in (0,1)$.\n    - $a_{31} = \\frac{1}{2-3c_2} \\ge 0 \\implies 2-3c_2 > 0 \\implies c_2 < \\frac{2}{3}$. Thus, $a_{31}$ can be nonnegative.\n    - $a_{32} = \\frac{1-3c_2}{2-3c_2} \\ge 0$. This requires the numerator and denominator to have the same sign.\n        - Case 1 (both positive): $1-3c_2 \\ge 0$ AND $2-3c_2 > 0 \\implies c_2 \\le \\frac{1}{3}$ AND $c_2 < \\frac{2}{3}$. This gives $c_2 \\le \\frac{1}{3}$.\n        - Case 2 (both negative): $1-3c_2 \\le 0$ AND $2-3c_2 < 0 \\implies c_2 \\ge \\frac{1}{3}$ AND $c_2 > \\frac{2}{3}$. This gives $c_2 > \\frac{2}{3}$.\n        - So, $a_{32} \\ge 0$ requires $c_2 \\in (0, 1/3] \\cup (2/3, 1)$.\n\n- **Overall Nonnegativity**: For both weights and matrix coefficients to be nonnegative, we must find the intersection of the valid ranges for $c_2$: $[\\frac{1}{3}, \\frac{2}{3}] \\cap [c_2 < \\frac{2}{3}] \\cap [c_2 \\in (0, \\frac{1}{3}] \\cup (\\frac{2}{3}, 1)]$. This intersection is the single point $c_2 = \\frac{1}{3}$.\n\n**4. Final Supremum Calculation**\n\nThe final question asks for the supremum of $c_2 \\in (0,1)$ such that all weights $b_i$ are nonnegative and the scheme is well-defined (i.e., admits finite coefficients). This does not require the matrix coefficients $a_{ij}$ to be nonnegative.\n\nFrom our analysis, the condition $b_i \\ge 0$ for all $i=1,2,3$ restricts $c_2$ to the interval $[\\frac{1}{3}, \\frac{2}{3}]$.\nThe scheme is \"finite\" or well-defined as long as the denominators in the expressions for its coefficients are non-zero. The coefficients $b_i$ are well-defined for $c_2 \\in (0,1)$. The coefficients $a_{31}$ and $a_{32}$ have a denominator of $2-3c_2$, which is zero when $c_2 = \\frac{2}{3}$. Therefore, the scheme is not defined at $c_2 = \\frac{2}{3}$.\n\nThe set of $c_2$ values for which all weights are nonnegative and a finite scheme exists is the intersection of the interval for non-negative weights, $[\\frac{1}{3}, \\frac{2}{3}]$, and the domain where the scheme is defined, $c_2 \\neq \\frac{2}{3}$. This yields the set $[\\frac{1}{3}, \\frac{2}{3})$.\n\nThe supremum of a set is its least upper bound. For the interval $[\\frac{1}{3}, \\frac{2}{3})$, the supremum is $\\frac{2}{3}$.",
            "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$"
        },
        {
            "introduction": "Theoretical properties of a numerical method are best understood when seen in action. This computational practice  challenges you to implement and compare two different explicit Runge-Kutta methods on a classic metabolic pathway model. By contrasting a Strong Stability Preserving (SSP) method with the standard fourth-order RK4, you will directly observe how the internal structure of a method impacts its ability to maintain physical positivity and conserve system invariants, especially when using adaptive time-stepping.",
            "id": "3890900",
            "problem": "A sequential metabolic pathway with three metabolites is modeled as an ordinary differential equation (ODE) under first-order mass-action kinetics. Let the metabolite concentrations be $x_1(t)$, $x_2(t)$, and $x_3(t)$, each in millimolar (mM), and let the rate constants be $k_1$ and $k_2$, each in inverse seconds ($\\text{s}^{-1}$). The pathway is $x_1 \\rightarrow x_2 \\rightarrow x_3$, resulting in the autonomous system\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-k_1 x_1 \\\\\nk_1 x_1 - k_2 x_2 \\\\\nk_2 x_2\n\\end{bmatrix},\n$$\nwith initial condition $x(0) = [x_1(0), x_2(0), x_3(0)]^\\top$ and terminal time $T > 0$. This system preserves the invariant $I(t) = x_1(t) + x_2(t) + x_3(t)$, so that $I(t) = I(0)$ for all $t \\ge 0$, and the exact solution maintains positivity $x_i(t) \\ge 0$ for all $i \\in \\{1,2,3\\}$ and all $t \\ge 0$.\n\nYou must implement two explicit time-integration methods:\n- A Strong Stability Preserving Runge-Kutta (SSP RK) method of order $3$ with $3$ stages (denoted SSPRK$(3,3)$).\n- The classical Runge-Kutta method of order $4$ (denoted RK$4$), which is not Strong Stability Preserving.\n\nBoth methods must be run under identical adaptive tolerance control. Use the following step-doubling local error estimator: given a current state $x$ at time $t$, a proposed step size $h > 0$, and a Runge-Kutta method of order $p$, compute one full step $y_h$ with step size $h$ and two half steps $y_{h/2}$ with step size $h/2$ applied twice. Define the local error estimate\n$$\ne = \\|y_{h/2} - y_h\\|_{\\infty}.\n$$\nAccept the step if $e \\le \\tau$, where $\\tau > 0$ is the given tolerance. On acceptance, advance the solution using the more accurate two-half-step value $y_{h/2}$. Update the step size using the identical control law for both methods,\n$$\nh_{\\text{new}} = s \\, h \\left(\\frac{\\tau}{\\max(e, \\epsilon)}\\right)^{\\frac{1}{p+1}},\n$$\nwhere $s$ is a safety factor and $\\epsilon$ is a small positive floor to avoid division by zero. On rejection, do not advance time and reduce $h$ using the same formula. Ensure that the last step exactly reaches $T$ by truncating $h$ if necessary. Do not clamp or otherwise modify negative states; any negativity must be recorded.\n\nDefine positivity preservation as the condition that for all accepted step endpoints $t_n$, the minimum component satisfies $\\min_i x_i(t_n) \\ge 0$, within a strict absolute threshold $\\epsilon_p = 10^{-12}$. Declare positivity preserved if and only if $\\min_i x_i(t_n) \\ge -\\epsilon_p$ for all $n$. Define invariant error as the absolute deviation of the invariant at the terminal time,\n$$\nE_{\\text{inv}} = \\left| \\left(x_1(T) + x_2(T) + x_3(T)\\right) - \\left(x_1(0) + x_2(0) + x_3(0)\\right) \\right|.\n$$\n\nImplement both methods with the same adaptive tolerance $\\tau$, the same safety factor $s$, and the same $\\epsilon$. Use the same initial step size selection strategy for both methods. The program must evaluate and report, for each test case, the positivity preservation booleans and the invariant errors for both methods.\n\nUse the following test suite:\n- Case $1$: $k_1 = 1.0$, $k_2 = 0.5$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 10.0$, $\\tau = 10^{-6}$.\n- Case $2$: $k_1 = 1.0$, $k_2 = 0.5$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 10.0$, $\\tau = 10^{-3}$.\n- Case $3$: $k_1 = 10.0$, $k_2 = 1.0$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 2.0$, $\\tau = 10^{-5}$.\n- Case $4$: $k_1 = 0.1$, $k_2 = 0.1$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 100.0$, $\\tau = 10^{-6}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist in the order\n$$\n[\\text{pos}_{\\text{SSP}}, \\text{pos}_{\\text{RK4}}, E_{\\text{inv,SSP}}, E_{\\text{inv,RK4}}],\n$$\nwith booleans $\\text{pos}_{\\text{SSP}}$ and $\\text{pos}_{\\text{RK4}}$, and floats $E_{\\text{inv,SSP}}$ and $E_{\\text{inv,RK4}}$. The final output must be a list of these four-element lists for the four cases, for example\n$$\n[[\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}]].\n$$\nNo physical units are required in the output; report only the specified booleans and floats.",
            "solution": "The sequential metabolic pathway with first-order mass-action kinetics is a linear compartment model in which the state vector $x(t) = [x_1(t), x_2(t), x_3(t)]^\\top$ evolves under\n$$\n\\frac{d x}{d t} = f(x) =\n\\begin{bmatrix}\n-k_1 x_1 \\\\\nk_1 x_1 - k_2 x_2 \\\\\nk_2 x_2\n\\end{bmatrix},\n$$\nwith $x(0) = x_0$. This formulation is grounded in the widely accepted law of mass action, which dictates that a unimolecular reaction $X \\rightarrow Y$ proceeds at a rate $v = k \\, x$, where $k$ is the rate constant and $x$ is the concentration of the reactant. The system matrix is Metzler (nonnegative off-diagonals), which implies that the positive orthant is forward invariant for the exact dynamics, and the invariant $I(t) = x_1(t) + x_2(t) + x_3(t)$ is conserved because the net flux is internal to the pathway, yielding\n$$\n\\frac{d}{dt} \\left( x_1 + x_2 + x_3 \\right) = -k_1 x_1 + \\left(k_1 x_1 - k_2 x_2\\right) + k_2 x_2 = 0.\n$$\n\nTo numerically approximate $x(T)$, we use explicit Runge-Kutta methods. A method of order $p$ satisfies that its local truncation error scales as $\\mathcal{O}(h^{p+1})$ for step size $h$. The Strong Stability Preserving (SSP) Runge-Kutta method SSPRK$(3,3)$ is constructed so that, under the same time-step restriction that guarantees stability for the forward Euler method, it preserves certain monotonicity properties such as positivity for suitable classes of problems (including linear systems with a Metzler matrix). In Shu-Osher form, SSPRK$(3,3)$ can be written as a convex combination of forward Euler steps:\n1. $u^{(1)} = u^n + h f(u^n)$,\n2. $u^{(2)} = \\frac{3}{4} u^n + \\frac{1}{4} \\left( u^{(1)} + h f(u^{(1)}) \\right)$,\n3. $u^{n+1} = \\frac{1}{3} u^n + \\frac{2}{3} \\left( u^{(2)} + h f(u^{(2)}) \\right)$.\nEach stage is a convex combination with nonnegative coefficients, so if forward Euler preserves positivity under a given step size bound, the SSP scheme will also preserve positivity under that bound.\n\nThe classical Runge-Kutta method of order $4$ (RK$4$) is defined by its stages\n$$\nk_1 = f(u^n), \\quad\nk_2 = f\\left(u^n + \\frac{h}{2} k_1\\right), \\quad\nk_3 = f\\left(u^n + \\frac{h}{2} k_2\\right), \\quad\nk_4 = f\\left(u^n + h k_3\\right),\n$$\nand update\n$$\nu^{n+1} = u^n + \\frac{h}{6} \\left( k_1 + 2 k_2 + 2 k_3 + k_4 \\right).\n$$\nThis method is not Strong Stability Preserving; it can violate monotonicity or positivity even when forward Euler would not, depending on step size.\n\nTo enforce identical tolerance control across both methods, we use step doubling to estimate the local error. Given a proposed $h$ at state $x$, compute $y_h$ using one step of the method and $y_{h/2}$ using two consecutive half steps. The infinity-norm error estimate is $e = \\|y_{h/2} - y_h\\|_\\infty$. Accept the step if $e \\le \\tau$ and advance the solution using $y_{h/2}$, as it is the more accurate approximation. The step size update uses the fact that local error scales as $h^{p+1}$:\n$$\nh_{\\text{new}} = s \\, h \\left(\\frac{\\tau}{\\max(e, \\epsilon)}\\right)^{\\frac{1}{p+1}},\n$$\nwith a safety factor $s$ to avoid aggressive changes and a small floor $\\epsilon$ to handle vanishing error estimates. On rejection ($e > \\tau$), the same update formula reduces $h$, and the state and time are not advanced.\n\nPositivity preservation is evaluated by checking the minimum state component at every accepted step endpoint. Define $\\epsilon_p = 10^{-12}$; if $\\min_i x_i(t_n) \\ge -\\epsilon_p$ for all accepted times $t_n$, we declare positivity preserved. Invariant preservation is evaluated by computing $E_{\\text{inv}} = |(x_1(T) + x_2(T) + x_3(T)) - (x_1(0) + x_2(0) + x_3(0))|$.\n\nAlgorithmic steps:\n- Initialize $t = 0$, $x = x_0$, and set $h$ to a reasonable initial guess (for example, $h = \\min(0.1, T/10)$), safety factor $s$ (for example, $s = 0.9$), and floor $\\epsilon$ (for example, $\\epsilon = 10^{-16}$).\n- While $t < T$:\n  - Set $h = \\min(h, T - t)$ to ensure $t$ does not overshoot $T$.\n  - Compute $y_h$ via one full step and $y_{h/2}$ via two half steps.\n  - Compute $e = \\|y_{h/2} - y_h\\|_\\infty$.\n  - If $e \\le \\tau$ or $h$ is at the numerical floor:\n    - Accept: set $x \\leftarrow y_{h/2}$, update the running minimum $\\min_i x_i$, and $t \\leftarrow t + h$.\n    - Update $h$ using $h_{\\text{new}}$ with exponent $1/(p+1)$.\n  - Else:\n    - Reject: reduce $h$ using the same update formula and repeat without advancing $t$ or $x$.\n- After reaching $T$, compute $E_{\\text{inv}}$ and $\\text{pos}$ using the saved minimum.\n\nThis design ensures a principled, method-agnostic tolerance control while isolating the impact of SSP structure on positivity and invariant preservation. The test suite covers a typical pathway ($k_1 = 1.0$, $k_2 = 0.5$) under both stringent ($\\tau = 10^{-6}$) and coarse ($\\tau = 10^{-3}$) tolerances, a faster upstream reaction ($k_1 = 10.0$, $k_2 = 1.0$) to probe stiffness-like behavior, and a slow, long-duration scenario ($k_1 = 0.1$, $k_2 = 0.1$, $T = 100.0$) to examine cumulative invariant errors. The outputs are booleans and floats that quantify positivity and invariant preservation for both SSPRK$(3,3)$ and RK$4$ under identical tolerances.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x, k1, k2):\n    # RHS of the metabolic pathway ODE: x1 -> x2 -> x3\n    dx1 = -k1 * x[0]\n    dx2 = k1 * x[0] - k2 * x[1]\n    dx3 = k2 * x[1]\n    return np.array([dx1, dx2, dx3], dtype=float)\n\ndef ssprk3_step(x, h, k1, k2):\n    # SSPRK(3,3) in Shu-Osher form\n    f1 = f(x, k1, k2)\n    u1 = x + h * f1\n    f2 = f(u1, k1, k2)\n    u2 = (3.0/4.0) * x + (1.0/4.0) * (u1 + h * f2)\n    f3 = f(u2, k1, k2)\n    u3 = (1.0/3.0) * x + (2.0/3.0) * (u2 + h * f3)\n    return u3\n\ndef rk4_step(x, h, k1, k2):\n    # Classical RK4\n    k1v = f(x, k1, k2)\n    k2v = f(x + 0.5 * h * k1v, k1, k2)\n    k3v = f(x + 0.5 * h * k2v, k1, k2)\n    k4v = f(x + h * k3v, k1, k2)\n    return x + (h / 6.0) * (k1v + 2.0 * k2v + 2.0 * k3v + k4v)\n\ndef integrate(method_step, order, x0, T, tau, k1, k2,\n              safety=0.9, eps_floor=1e-16, min_h=1e-16, max_growth=2.0):\n    # Adaptive integration using step-doubling error estimate\n    t = 0.0\n    x = x0.copy()\n    total0 = float(np.sum(x))\n    min_comp = float(np.min(x))\n    # Initial step heuristic\n    h = min(0.1, T / 10.0) if T > 0 else 0.0\n\n    # Guard against T == 0\n    if T == 0.0:\n        inv_err = abs(float(np.sum(x)) - total0)\n        pos_preserved = (min_comp >= -1e-12)\n        return pos_preserved, inv_err\n\n    while t  T:\n        # Prevent overshoot\n        h = min(h, T - t)\n        if h  min_h:\n            # Accept tiny step to avoid stalling\n            y_full = method_step(x, h, k1, k2)\n            y_half = method_step(method_step(x, 0.5 * h, k1, k2), 0.5 * h, k1, k2)\n            x = y_half\n            t += h\n            min_comp = min(min_comp, float(np.min(x)))\n            # Attempt to grow step modestly\n            h = min(max_growth * h, T - t if T - t > 0 else h)\n            continue\n\n        # One full step\n        y_full = method_step(x, h, k1, k2)\n        # Two half steps\n        y_half = method_step(method_step(x, 0.5 * h, k1, k2), 0.5 * h, k1, k2)\n\n        # Infinity-norm error estimate\n        e = float(np.max(np.abs(y_half - y_full)))\n\n        if e = tau or h = min_h:\n            # Accept: advance with the more accurate two-half-step value\n            x = y_half\n            t += h\n            min_comp = min(min_comp, float(np.min(x)))\n            # Update step size\n            exponent = 1.0 / (order + 1)\n            h_candidate = safety * h * (tau / max(e, eps_floor))**exponent\n            # Limit excessive growth\n            h = min(h_candidate, max_growth * h)\n        else:\n            # Reject: reduce h and retry\n            exponent = 1.0 / (order + 1)\n            h = safety * h * (tau / e)**exponent\n            if h  min_h:\n                h = min_h\n\n    inv_err = abs(float(np.sum(x)) - total0)\n    pos_preserved = (min_comp >= -1e-12)\n    return pos_preserved, inv_err\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (k1, k2, x0, T, tau)\n        (1.0, 0.5, np.array([1.0, 0.0, 0.0], dtype=float), 10.0, 1e-6),\n        (1.0, 0.5, np.array([1.0, 0.0, 0.0], dtype=float), 10.0, 1e-3),\n        (10.0, 1.0, np.array([1.0, 0.0, 0.0], dtype=float), 2.0, 1e-5),\n        (0.1, 0.1, np.array([1.0, 0.0, 0.0], dtype=float), 100.0, 1e-6),\n    ]\n\n    results = []\n    for k1, k2, x0, T, tau in test_cases:\n        # SSPRK(3,3): order = 3\n        pos_ssp, inv_ssp = integrate(ssprk3_step, 3, x0, T, tau, k1, k2)\n        # RK4: order = 4\n        pos_rk4, inv_rk4 = integrate(rk4_step, 4, x0, T, tau, k1, k2)\n        results.append([pos_ssp, pos_rk4, inv_ssp, inv_rk4])\n\n    # Final print statement in the exact required format.\n    # Produces a single line: list of per-case lists [bool,bool,float,float]\n    print(f\"[{','.join([str(r) for r in results])}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Many biomedical systems, particularly those involving enzyme kinetics, are described by stiff ordinary differential equations, where explicit methods become prohibitively expensive. This advanced exercise  guides you through the implementation of a high-order implicit Gauss-Legendre method, a powerful tool for efficiently solving stiff systems. Using the method of manufactured solutions, you will not only tackle a challenging problem but also learn a rigorous technique for verifying that your code achieves its theoretical order of accuracy.",
            "id": "3890916",
            "problem": "Implement a self-contained program that constructs and applies an implicit Gauss–Legendre Runge–Kutta method to a stiff enzyme reaction network under a manufactured (forcing) solution paradigm, and uses it to empirically verify the theoretical convergence order. The program must be general and reproducible, must not require user input, and must output a single line as specified at the end of this problem.\n\nThe fundamental base of the model is a standard mass-action enzyme reaction network describing substrate consumption catalyzed by an enzyme with complex formation, given by the reactions substrate plus enzyme reversibly forming a complex that irreversibly produces product. Let the state vector be $y(t) = [S(t), E(t), C(t), P(t)]^\\top$ where $S$ is substrate, $E$ is free enzyme, $C$ is complex, and $P$ is product. The mass-action dynamics without forcing are\n$$\n\\begin{aligned}\n\\frac{dS}{dt} = -k_1 S E + k_2 C, \\\\\n\\frac{dE}{dt} = -k_1 S E + (k_2 + k_3) C, \\\\\n\\frac{dC}{dt} = k_1 S E - (k_2 + k_3) C, \\\\\n\\frac{dP}{dt} = k_3 C,\n\\end{aligned}\n$$\nwith rate constants $k_1$, $k_2$, $k_3$. To enable exact error evaluation, use the method of manufactured solutions: prescribe a smooth, stiff, and invariant-respecting exact solution $y_{\\mathrm{ex}}(t)$ and define a time-dependent forcing $r(t)$ so that the non-autonomous system\n$$\n\\frac{dy}{dt} = f(t, y) := f_{\\mathrm{mass}}(y) + r(t)\n$$\nhas the exact solution $y_{\\mathrm{ex}}(t)$ for given initial data. Here, $f_{\\mathrm{mass}}(y)$ is the right-hand side defined by the mass-action kinetics above. The manufactured solution must satisfy enzyme conservation and substrate-total conservation at all times, that is $E(t) + C(t) = E_{\\mathrm{tot}}$ and $S(t) + C(t) + P(t) = S_{\\mathrm{tot}}$ for constants $E_{\\mathrm{tot}}$ and $S_{\\mathrm{tot}}$. Define the manufactured solution by\n$$\n\\begin{aligned}\nC(t) = c_1 e^{-\\alpha t} + c_2 e^{-t}, \\\\\nE(t) = E_{\\mathrm{tot}} - C(t), \\\\\nS(t) = s_0 + s_1 e^{-t} + s_2 e^{-3 t}, \\\\\nP(t) = S_{\\mathrm{tot}} - S(t) - C(t),\n\\end{aligned}\n$$\nwith constants $E_{\\mathrm{tot}}$, $S_{\\mathrm{tot}}$, $c_1$, $c_2$, $s_0$, $s_1$, $s_2$, and stiffness parameter $\\alpha  0$. Construct $r(t)$ by the identity $r(t) = \\frac{d}{dt} y_{\\mathrm{ex}}(t) - f_{\\mathrm{mass}}(y_{\\mathrm{ex}}(t))$, which guarantees $y_{\\mathrm{ex}}(t)$ is the exact solution of $\\frac{dy}{dt} = f(t, y)$ starting from $y_{\\mathrm{ex}}(0)$.\n\nYou must implement an implicit Gauss–Legendre Runge–Kutta method of higher order using collocation at Gauss points:\n- Implement the two-stage Gauss–Legendre method (which has theoretical global order $4$).\n- Implement the three-stage Gauss–Legendre method (which has theoretical global order $6$).\n\nThe implicit stage equations must be solved by a Newton method that uses the exact Jacobian of $f(t, y)$ with respect to $y$, i.e., the Jacobian of $f_{\\mathrm{mass}}(y)$, since the forcing $r(t)$ is $y$-independent. The block-structured Newton system for the stages must be assembled and solved at each time step.\n\nFrom first principles, your program shall:\n- Define $f_{\\mathrm{mass}}(y)$ from the above mass-action laws.\n- Define $y_{\\mathrm{ex}}(t)$ with parameter values that ensure $E(t) + C(t) = E_{\\mathrm{tot}}$ and $S(t) + C(t) + P(t) = S_{\\mathrm{tot}}$ for all $t$.\n- Derive $r(t)$ via $r(t) = \\frac{d}{dt} y_{\\mathrm{ex}}(t) - f_{\\mathrm{mass}}(y_{\\mathrm{ex}}(t))$.\n- Implement Newton’s method for the implicit stages using the exact Jacobian of $f_{\\mathrm{mass}}$.\n- Advance the numerical solution from $t=0$ to $t=T$ with a fixed step size $h$.\n\nUse the following scientifically plausible and self-consistent parameters for the enzyme network and the manufactured solution, chosen to introduce stiffness and maintain invariants:\n- Enzyme and substrate totals: $E_{\\mathrm{tot}} = 1$, $S_{\\mathrm{tot}} = 1$.\n- Kinetic rates: $k_1 = 100$, $k_2 = 10$, $k_3 = 1$.\n- Manufactured coefficients: $c_1 = 0.05$, $c_2 = 0.02$, $s_0 = 0.1$, $s_1 = 0.4$, $s_2 = 0.2$.\n\nThe Jacobian of $f_{\\mathrm{mass}}(y)$ with respect to $y = [S,E,C,P]^\\top$ is\n$$\nJ(y) =\n\\begin{bmatrix}\n- k_1 E  - k_1 S  k_2  0 \\\\\n- k_1 E  - k_1 S  k_2 + k_3  0 \\\\\nk_1 E  k_1 S  -(k_2 + k_3)  0 \\\\\n0  0  k_3  0\n\\end{bmatrix}.\n$$\n\nYour program must verify the theoretical order via grid refinement using the exact error at $t = T$ defined by $e(h) = \\lVert y_{\\mathrm{num}}(T; h) - y_{\\mathrm{ex}}(T) \\rVert_2$. For each method, compute observed orders via\n$$\np(h_1 \\to h_2) = \\frac{\\log\\left( \\frac{e(h_1)}{e(h_2)} \\right)}{\\log(2)},\n$$\nfor successive step halvings $h_2 = h_1 / 2$.\n\nTest Suite and Answer Specification:\n- Case $1$ (happy path, moderate stiffness): two-stage Gauss–Legendre, final time $T = 1$, stiffness parameter $\\alpha = 50$, step sizes $h \\in \\{0.2, 0.1, 0.05\\}$. Report two floats: $p(0.2 \\to 0.1)$ and $p(0.1 \\to 0.05)$.\n- Case $2$ (higher-order coverage): three-stage Gauss–Legendre, final time $T = 1$, stiffness parameter $\\alpha = 50$, step sizes $h \\in \\{0.1, 0.05, 0.025\\}$. Report two floats: $p(0.1 \\to 0.05)$ and $p(0.05 \\to 0.025)$.\n- Case $3$ (edge case, more extreme stiffness): two-stage Gauss–Legendre, final time $T = 0.2$, stiffness parameter $\\alpha = 200$, step sizes $h \\in \\{0.05, 0.025, 0.0125\\}$. Report two floats: $p(0.05 \\to 0.025)$ and $p(0.025 \\to 0.0125)$.\n\nAll initial conditions must be set to the manufactured exact solution at $t=0$:\n$$\ny(0) = y_{\\mathrm{ex}}(0).\n$$\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[\\;p_{1,1},\\;p_{1,2},\\;p_{2,1},\\;p_{2,2},\\;p_{3,1},\\;p_{3,2}\\;],\n$$\nwhere $p_{i,j}$ denotes the observed orders for case $i$ and pair $j$ as defined above. For example, the output should look like $[x_1,x_2,x_3,x_4,x_5,x_6]$ with each $x_k$ a float. No other text may be printed.",
            "solution": "The user has requested the implementation and verification of implicit Gauss-Legendre Runge-Kutta methods for a stiff enzyme kinetics model. The verification is to be performed using the method of manufactured solutions to enable exact error calculation and empirical order of convergence analysis.\n\n### Step 1: Problem Formulation and Mathematical Framework\n\nThe problem revolves around the numerical solution of a non-autonomous system of ordinary differential equations (ODEs) of the form $\\frac{dy}{dt} = f(t, y)$. The state vector is $y(t) = [S(t), E(t), C(t), P(t)]^\\top$, representing the concentrations of Substrate, Enzyme, Complex, and Product, respectively.\n\nThe right-hand side function $f(t, y)$ is composed of two parts: a term from mass-action kinetics, $f_{\\mathrm{mass}}(y)$, and a time-dependent forcing term, $r(t)$, introduced by the method of manufactured solutions.\n$$\n\\frac{dy}{dt} = f(t, y) = f_{\\mathrm{mass}}(y) + r(t)\n$$\nThe mass-action kinetics are given by:\n$$\nf_{\\mathrm{mass}}(y) = \\begin{bmatrix}\n-k_1 S E + k_2 C \\\\\n-k_1 S E + (k_2 + k_3) C \\\\\nk_1 S E - (k_2 + k_3) C \\\\\nk_3 C\n\\end{bmatrix}\n$$\nA manufactured solution $y_{\\mathrm{ex}}(t)$ is prescribed to satisfy specified conservation laws: $E(t) + C(t) = E_{\\mathrm{tot}}$ and $S(t) + C(t) + P(t) = S_{\\mathrm{tot}}$. The forcing term $r(t)$ is then defined such that $y_{\\mathrm{ex}}(t)$ is the exact solution to the ODE system:\n$$\nr(t) = \\frac{d y_{\\mathrm{ex}}(t)}{dt} - f_{\\mathrm{mass}}(y_{\\mathrm{ex}}(t))\n$$\nWe will need to compute both $y_{\\mathrm{ex}}(t)$ and its derivative $\\frac{d y_{\\mathrm{ex}}(t)}{dt}$ to construct the full ODE system.\n\nThe Jacobian of the ODE's right-hand side, $J(t, y) = \\frac{\\partial f(t, y)}{\\partial y}$, is required for the Newton's method solver. Since the forcing term $r(t)$ is independent of $y$, the Jacobian is simply the Jacobian of the mass-action term, $J(t, y) = J_{\\mathrm{mass}}(y)$. The problem provides this Jacobian:\n$$\nJ_{\\mathrm{mass}}(y) =\n\\begin{bmatrix}\n- k_1 E  - k_1 S  k_2  0 \\\\\n- k_1 E  - k_1 S  k_2 + k_3  0 \\\\\nk_1 E  k_1 S  -(k_2 + k_3)  0 \\\\\n0  0  k_3  0\n\\end{bmatrix}\n$$\n\n### Step 2: Implicit Runge-Kutta Methods (Gauss-Legendre)\n\nAn $s$-stage implicit Runge-Kutta (IRK) method advances the solution from $y_n$ at time $t_n$ to $y_{n+1}$ at time $t_{n+1} = t_n + h$ using the formula:\n$$\ny_{n+1} = y_n + h \\sum_{i=1}^s b_i k_i\n$$\nThe stage derivatives $k_i$ are solutions to a system of coupled, generally nonlinear equations:\n$$\nk_i = f\\left(t_n + c_i h, y_n + h \\sum_{j=1}^s a_{ij} k_j\\right), \\quad i = 1, \\dots, s\n$$\nIt is more convenient to solve for the stage values $Y_i = y_n + h \\sum_{j=1}^s a_{ij} k_j$. The system for the stage values is:\n$$\nY_i = y_n + h \\sum_{j=1}^s a_{ij} f(t_n + c_j h, Y_j), \\quad i = 1, \\dots, s\n$$\nThis is a system of $s \\times d$ nonlinear equations for the unknowns $Y_1, \\dots, Y_s$, where $d=4$ is the dimension of $y$. We solve this system using Newton's method.\n\n#### Newton's Method for Stage Values\nLet $\\mathbf{Y} = [Y_1^\\top, \\ldots, Y_s^\\top]^\\top$ be the concatenated vector of all stage values. We seek the root of the function $\\mathbf{G}(\\mathbf{Y}) = 0$, where:\n$$\nG_i(\\mathbf{Y}) = Y_i - y_n - h \\sum_{j=1}^s a_{ij} f(t_n + c_j h, Y_j)\n$$\nThe Newton iteration is $\\mathbf{Y}^{(k+1)} = \\mathbf{Y}^{(k)} + \\Delta\\mathbf{Y}^{(k)}$, where the update $\\Delta\\mathbf{Y}^{(k)}$ is the solution to the linear system:\n$$\n\\mathcal{J}_G(\\mathbf{Y}^{(k)}) \\Delta\\mathbf{Y}^{(k)} = -\\mathbf{G}(\\mathbf{Y}^{(k)})\n$$\nThe Jacobian of $\\mathbf{G}$, denoted $\\mathcal{J}_G$, is a block matrix of size $(s \\cdot d) \\times (s \\cdot d)$. The block at position $(i,j)$ is $\\frac{\\partial G_i}{\\partial Y_j} = \\delta_{ij}I_d - h a_{ij} J(t_n+c_j h, Y_j)$, where $I_d$ is the $d \\times d$ identity matrix and $\\delta_{ij}$ is the Kronecker delta.\n\nThe Butcher tableaus $(A, b, c)$ for the required Gauss-Legendre methods are:\n\n1.  **Two-Stage Gauss-Legendre (Order 4)**:\n    -   $s=2$, $c_1 = \\frac{1}{2} - \\frac{\\sqrt{3}}{6}$, $c_2 = \\frac{1}{2} + \\frac{\\sqrt{3}}{6}$\n    -   $b = [1/2, 1/2]^\\top$\n    -   $A = \\begin{pmatrix} 1/4  1/4 - \\sqrt{3}/6 \\\\ 1/4 + \\sqrt{3}/6  1/4 \\end{pmatrix}$\n\n2.  **Three-Stage Gauss-Legendre (Order 6)**:\n    -   $s=3$, $c_1 = \\frac{1}{2} - \\frac{\\sqrt{15}}{10}$, $c_2 = \\frac{1}{2}$, $c_3 = \\frac{1}{2} + \\frac{\\sqrt{15}}{10}$\n    -   $b = [5/18, 8/18, 5/18]^\\top$\n    -   $A = \\begin{pmatrix}\n        5/36  2/9 - \\sqrt{15}/15  5/36 - \\sqrt{15}/30 \\\\\n        5/36 + \\sqrt{15}/24  2/9  5/36 - \\sqrt{15}/24 \\\\\n        5/36 + \\sqrt{15}/30  2/9 + \\sqrt{15}/15  5/36\n        \\end{pmatrix}$\n\n### Step 3: Empirical Order Verification\n\nThe program will execute the simulations as specified in the three test cases. For each case, it will integrate the ODE system from $t=0$ to $t=T$ using a sequence of decreasing step sizes $h$. The numerical solution at the final time, $y_{\\mathrm{num}}(T; h)$, is compared against the exact solution $y_{\\mathrm{ex}}(T)$ to compute the error $e(h) = \\lVert y_{\\mathrm{num}}(T; h) - y_{\\mathrm{ex}}(T) \\rVert_2$.\nThe observed order of convergence $p$ is then calculated for successive step size refinements $h_2 = h_1 / 2$:\n$$\np(h_1 \\to h_2) = \\frac{\\log(e(h_1)/e(h_2))}{\\log(2)}\n$$\nThe results from all test cases will be aggregated into a single list for the final output. The implementation will follow the logic detailed above, encapsulating the physical model and the numerical solver into separate, well-defined components.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and applies implicit Gauss-Legendre Runge-Kutta methods to\n    a stiff enzyme reaction network, and verifies the theoretical convergence order.\n    \"\"\"\n\n    # --- Butcher Tableaus for Gauss-Legendre Methods ---\n    s3 = np.sqrt(3)\n    s15 = np.sqrt(15)\n\n    TABLEAUS = {\n        'GL4': {  # 2-stage, order 4\n            'A': np.array([\n                [1/4, 1/4 - s3/6],\n                [1/4 + s3/6, 1/4]\n            ]),\n            'b': np.array([1/2, 1/2]),\n            'c': np.array([1/2 - s3/6, 1/2 + s3/6])\n        },\n        'GL6': {  # 3-stage, order 6\n            'A': np.array([\n                [5/36, 2/9 - s15/15, 5/36 - s15/30],\n                [5/36 + s15/24, 2/9, 5/36 - s15/24],\n                [5/36 + s15/30, 2/9 + s15/15, 5/36]\n            ]),\n            'b': np.array([5/18, 8/18, 5/18]),\n            'c': np.array([1/2 - s15/10, 1/2, 1/2 + s15/10])\n        }\n    }\n\n    class EnzymeModel:\n        \"\"\"\n        Represents the enzyme kinetics model with a manufactured solution.\n        y = [S, E, C, P]\n        \"\"\"\n        def __init__(self, alpha):\n            self.k1, self.k2, self.k3 = 100.0, 10.0, 1.0\n            self.Etot, self.Stot = 1.0, 1.0\n            self.c1, self.c2 = 0.05, 0.02\n            self.s0, self.s1, self.s2 = 0.1, 0.4, 0.2\n            self.alpha = float(alpha)\n            self.dim = 4\n\n        def f_mass(self, y):\n            S, E, C, _ = y\n            r1 = self.k1 * S * E\n            r2 = self.k2 * C\n            r3 = self.k3 * C\n            return np.array([\n                -r1 + r2,\n                -r1 + r2 + r3,\n                 r1 - r2 - r3,\n                 r3\n            ])\n\n        def J_mass(self, y):\n            S, E, _, _ = y\n            J = np.zeros((self.dim, self.dim))\n            J[0, 0] = -self.k1 * E\n            J[0, 1] = -self.k1 * S\n            J[0, 2] = self.k2\n            J[1, 0] = -self.k1 * E\n            J[1, 1] = -self.k1 * S\n            J[1, 2] = self.k2 + self.k3\n            J[2, 0] = self.k1 * E\n            J[2, 1] = self.k1 * S\n            J[2, 2] = -(self.k2 + self.k3)\n            J[3, 2] = self.k3\n            return J\n\n        def y_ex(self, t):\n            exp_a = np.exp(-self.alpha * t)\n            exp_1 = np.exp(-t)\n            exp_3 = np.exp(-3.0 * t)\n            C = self.c1 * exp_a + self.c2 * exp_1\n            E = self.Etot - C\n            S = self.s0 + self.s1 * exp_1 + self.s2 * exp_3\n            P = self.Stot - S - C\n            return np.array([S, E, C, P])\n\n        def y_ex_dot(self, t):\n            exp_a = np.exp(-self.alpha * t)\n            exp_1 = np.exp(-t)\n            exp_3 = np.exp(-3.0 * t)\n            C_dot = -self.alpha * self.c1 * exp_a - self.c2 * exp_1\n            E_dot = -C_dot\n            S_dot = -self.s1 * exp_1 - 3.0 * self.s2 * exp_3\n            P_dot = -S_dot - C_dot\n            return np.array([S_dot, E_dot, C_dot, P_dot])\n        \n        def r(self, t):\n            return self.y_ex_dot(t) - self.f_mass(self.y_ex(t))\n\n        def f(self, t, y):\n            return self.f_mass(y) + self.r(t)\n        \n        def J(self, t, y):\n            return self.J_mass(y)\n\n    class IRKSolver:\n        \"\"\"\n        An implicit Runge-Kutta solver using Newton's method for stage equations.\n        \"\"\"\n        def __init__(self, model, tableau, newton_tol=1e-12, max_newton_iter=10):\n            self.model = model\n            self.A = tableau['A']\n            self.b = tableau['b']\n            self.c = tableau['c']\n            self.s = len(self.b)\n            self.dim = model.dim\n            self.tol = newton_tol\n            self.max_iter = max_newton_iter\n\n        def step(self, y_n, t_n, h):\n            # Initial guess for stage values Y_i is y_n for all i\n            Y = np.tile(y_n, (self.s, 1))\n\n            # Newton's method for stage values\n            for _ in range(self.max_iter):\n                # Form residual G and Jacobian J_G\n                f_vals = np.array([self.model.f(t_n + self.c[i] * h, Y[i, :]) for i in range(self.s)])\n                G = Y - np.tile(y_n, (self.s, 1)) - h * (self.A @ f_vals)\n                \n                J_vals = [self.model.J(t_n + self.c[i] * h, Y[i, :]) for i in range(self.s)]\n                J_G = np.zeros((self.s * self.dim, self.s * self.dim))\n\n                for i in range(self.s):\n                    for j in range(self.s):\n                        block = -h * self.A[i, j] * J_vals[j]\n                        if i == j:\n                            block += np.identity(self.dim)\n                        J_G[i*self.dim:(i+1)*self.dim, j*self.dim:(j+1)*self.dim] = block\n\n                # Solve linear system and update\n                delta_Y_flat = np.linalg.solve(J_G, -G.flatten())\n                Y += delta_Y_flat.reshape((self.s, self.dim))\n\n                if np.linalg.norm(delta_Y_flat)  self.tol:\n                    break\n            \n            # Compute final solution y_{n+1}\n            f_vals = np.array([self.model.f(t_n + self.c[i] * h, Y[i, :]) for i in range(self.s)])\n            y_np1 = y_n + h * (self.b @ f_vals)\n            return y_np1\n\n    def run_simulation(solver, model, T, h):\n        num_steps = int(round(T / h))\n        y = model.y_ex(0.0)\n        t = 0.0\n        for _ in range(num_steps):\n            y = solver.step(y, t, h)\n            t += h\n        return y\n    \n    test_cases = [\n        {'id': 1, 'method': 'GL4', 'T': 1.0, 'alpha': 50, 'hs': [0.2, 0.1, 0.05]},\n        {'id': 2, 'method': 'GL6', 'T': 1.0, 'alpha': 50, 'hs': [0.1, 0.05, 0.025]},\n        {'id': 3, 'method': 'GL4', 'T': 0.2, 'alpha': 200, 'hs': [0.05, 0.025, 0.0125]}\n    ]\n\n    all_orders = []\n    for case in test_cases:\n        model = EnzymeModel(alpha=case['alpha'])\n        tableau = TABLEAUS[case['method']]\n        solver = IRKSolver(model, tableau)\n        \n        errors = []\n        for h in case['hs']:\n            y_final_num = run_simulation(solver, model, case['T'], h)\n            y_final_ex = model.y_ex(case['T'])\n            error = np.linalg.norm(y_final_num - y_final_ex)\n            errors.append(error)\n        \n        order1 = np.log(errors[0] / errors[1]) / np.log(2.0)\n        order2 = np.log(errors[1] / errors[2]) / np.log(2.0)\n        all_orders.extend([order1, order2])\n\n    print(f\"[{','.join(map(str, all_orders))}]\")\n\nsolve()\n\n```"
        }
    ]
}