{
    "hands_on_practices": [
        {
            "introduction": "A crucial step in population modeling is choosing how to represent variability between individuals. This choice is not merely a statistical detail; it can significantly influence the model's predictions. This exercise  provides a foundational practice by asking you to derive and compare the population-average concentration profiles resulting from two common assumptions for parameter variability: additive-normal and multiplicative-lognormal distributions.",
            "id": "3920831",
            "problem": "Consider a population pharmacokinetic one-compartment intravenous bolus model in the context of Nonlinear Mixed-Effects (NLME) modeling. The fundamental base is that the individual concentration-time profile in a one-compartment model with first-order elimination is given by $C(t \\mid CL, V) = \\frac{D}{V} \\exp\\!\\left(-\\frac{CL}{V} t\\right)$, where $D$ is dose, $V$ is the central volume of distribution, $CL$ is clearance, and $t$ is time. Assume $V$ is fixed (no interindividual variability) and that variability enters only through $CL$.\n\nTwo scientifically plausible and commonly contrasted random-effect parameterizations for $CL$ are considered, each sharing the same typical clearance $\\bar{CL}$:\n1. Additive-normal parameterization: $CL_i = \\bar{CL} + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\omega_{N}^{2})$. Assume $\\bar{CL} > 3 \\omega_{N}$ so that the probability of $CL_i \\leq 0$ is negligible, ensuring scientific realism.\n2. Multiplicative-lognormal parameterization: $CL_i = \\exp(\\theta + \\eta_i)$, where $\\eta_i \\sim \\mathcal{N}(0, \\omega_{L}^{2})$ and $\\exp(\\theta) = \\bar{CL}$, which ensures $CL_i > 0$ almost surely.\n\nStarting only from the fundamental one-compartment formula above and the definition of the marginal mean (population average) $\\mathbb{E}[C(t)]$, derive the marginal mean under each parameterization: for the additive-normal case, derive the exact expression; for the multiplicative-lognormal case, derive a second-order approximation in $\\omega_{L}$ by using a Taylor expansion around $\\eta = 0$ and the properties of the normal distribution. Then, use these results to derive a closed-form analytic expression for the ratio\n$$\nR(t) \\equiv \\frac{\\mathbb{E}_{\\text{additive-normal}}[C(t)]}{\\mathbb{E}_{\\text{multiplicative-lognormal}}[C(t)]}\n$$\nas a function of $t$, $V$, $\\bar{CL}$, $\\omega_{N}$, and $\\omega_{L}$. Express your final answer for $R(t)$ as a single simplified analytic expression. Do not report units, and no rounding is required. Your derivation must be self-contained and scientifically consistent with the stated assumptions.",
            "solution": "The objective is to compute the ratio $R(t)$ of the marginal mean concentrations from two different random-effect models for clearance, $CL$. The marginal mean is the expectation of the concentration function over the distribution of the random effects.\n\n**1. Marginal Mean for the Additive-Normal Parameterization**\n\nThe concentration for an individual $i$ is given by substituting $CL_i = \\bar{CL} + \\epsilon_i$ into the base model:\n$$\nC_i(t) = \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} + \\epsilon_i}{V} t\\right)\n$$\nThe marginal mean, $\\mathbb{E}_{\\text{additive-normal}}[C(t)]$, is the expectation of $C_i(t)$ with respect to the distribution of $\\epsilon_i$.\n$$\n\\mathbb{E}_{\\text{additive-normal}}[C(t)] = \\mathbb{E}_{\\epsilon_i}\\left[ \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} + \\epsilon_i}{V} t\\right) \\right]\n$$\nWe can separate the terms that do not depend on the random variable $\\epsilon_i$:\n$$\n\\mathbb{E}_{\\text{additive-normal}}[C(t)] = \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\mathbb{E}_{\\epsilon_i}\\left[ \\exp\\left(-\\frac{t}{V} \\epsilon_i\\right) \\right]\n$$\nThe expectation term $\\mathbb{E}\\left[\\exp(s \\epsilon_i)\\right]$ is the moment-generating function (MGF) of $\\epsilon_i$, denoted $M_{\\epsilon_i}(s)$, evaluated at $s = -\\frac{t}{V}$. Given that $\\epsilon_i \\sim \\mathcal{N}(0, \\omega_{N}^{2})$, its MGF is $M_{\\epsilon_i}(s) = \\exp\\left(0 \\cdot s + \\frac{1}{2}\\omega_{N}^{2}s^2\\right) = \\exp\\left(\\frac{1}{2}\\omega_{N}^{2}s^2\\right)$.\nSubstituting $s = -\\frac{t}{V}$:\n$$\n\\mathbb{E}_{\\epsilon_i}\\left[ \\exp\\left(-\\frac{t}{V} \\epsilon_i\\right) \\right] = \\exp\\left(\\frac{1}{2}\\omega_{N}^{2}\\left(-\\frac{t}{V}\\right)^2\\right) = \\exp\\left(\\frac{\\omega_{N}^{2}t^2}{2V^2}\\right)\n$$\nSubstituting this back into the expression for the marginal mean gives the exact analytical form:\n$$\n\\mathbb{E}_{\\text{additive-normal}}[C(t)] = \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\exp\\left(\\frac{\\omega_{N}^{2}t^2}{2V^2}\\right) = \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V} + \\frac{\\omega_{N}^{2}t^2}{2V^2}\\right)\n$$\n\n**2. Marginal Mean for the Multiplicative-Lognormal Parameterization (Second-Order Approximation)**\n\nFor this parameterization, $CL_i = \\exp(\\theta + \\eta_i) = \\exp(\\theta)\\exp(\\eta_i)$. With the constraint $\\exp(\\theta) = \\bar{CL}$, we have $CL_i = \\bar{CL} \\exp(\\eta_i)$. The concentration for an individual $i$ is:\n$$\nC_i(t) = \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL}\\exp(\\eta_i)}{V} t\\right)\n$$\nThe marginal mean is the expectation with respect to $\\eta_i \\sim \\mathcal{N}(0, \\omega_{L}^{2})$.\n$$\n\\mathbb{E}_{\\text{multiplicative-lognormal}}[C(t)] = \\frac{D}{V} \\mathbb{E}_{\\eta_i}\\left[ \\exp\\left(-\\frac{\\bar{CL} t}{V} \\exp(\\eta_i)\\right) \\right]\n$$\nWe are instructed to find a second-order approximation by using a Taylor expansion around $\\eta_i = 0$. Let $f(\\eta) = \\exp\\left(-k \\exp(\\eta)\\right)$, where $k = \\frac{\\bar{CL} t}{V}$ is a constant with respect to $\\eta$. The second-order Taylor expansion of $f(\\eta)$ around $\\eta = 0$ is:\n$$\nf(\\eta) \\approx f(0) + f'(0)\\eta + \\frac{f''(0)}{2!}\\eta^2\n$$\nTaking the expectation over the distribution of $\\eta_i$:\n$$\n\\mathbb{E}[f(\\eta_i)] \\approx \\mathbb{E}\\left[ f(0) + f'(0)\\eta_i + \\frac{f''(0)}{2}\\eta_i^2 \\right] = f(0) + f'(0)\\mathbb{E}[\\eta_i] + \\frac{f''(0)}{2}\\mathbb{E}[\\eta_i^2]\n$$\nGiven $\\eta_i \\sim \\mathcal{N}(0, \\omega_{L}^{2})$, we have $\\mathbb{E}[\\eta_i] = 0$ and $\\mathbb{E}[\\eta_i^2] = \\text{Var}(\\eta_i) + (\\mathbb{E}[\\eta_i])^2 = \\omega_{L}^{2} + 0^2 = \\omega_{L}^{2}$. The approximation becomes:\n$$\n\\mathbb{E}[f(\\eta_i)] \\approx f(0) + \\frac{f''(0)}{2}\\omega_{L}^{2}\n$$\nNow, we compute the necessary function values and derivatives:\n- $f(\\eta) = \\exp(-k \\exp(\\eta))$\n  - $f(0) = \\exp(-k \\exp(0)) = \\exp(-k)$\n- $f'(\\eta) = \\frac{d}{d\\eta}\\left(\\exp(-k e^\\eta)\\right) = \\exp(-k e^\\eta) \\cdot (-k e^\\eta)$\n- $f''(\\eta) = \\frac{d}{d\\eta}\\left(-k e^\\eta \\exp(-k e^\\eta)\\right) = (-k e^\\eta)\\exp(-k e^\\eta) + (-k e^\\eta)\\exp(-k e^\\eta)(-k e^\\eta) = (-k e^\\eta + k^2 e^{2\\eta})\\exp(-k e^\\eta)$\n  - $f''(0) = (-k e^0 + k^2 e^0) \\exp(-k e^0) = (k^2 - k)\\exp(-k)$\n\nSubstituting these into the approximation for $\\mathbb{E}[f(\\eta_i)]$:\n$$\n\\mathbb{E}[f(\\eta_i)] \\approx \\exp(-k) + \\frac{(k^2 - k)\\exp(-k)}{2}\\omega_{L}^{2} = \\exp(-k)\\left(1 + \\frac{k^2 - k}{2}\\omega_{L}^{2}\\right)\n$$\nNow, substitute back $k = \\frac{\\bar{CL} t}{V}$:\n$$\n\\mathbb{E}_{\\eta_i}\\left[\\dots\\right] \\approx \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\left(1 + \\frac{1}{2}\\left[\\left(\\frac{\\bar{CL} t}{V}\\right)^2 - \\frac{\\bar{CL} t}{V}\\right]\\omega_{L}^{2}\\right)\n$$\nThe second-order approximation for the marginal mean is:\n$$\n\\mathbb{E}_{\\text{multiplicative-lognormal}}[C(t)] \\approx \\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\left(1 + \\frac{\\omega_{L}^{2}}{2}\\left[\\left(\\frac{\\bar{CL} t}{V}\\right)^2 - \\frac{\\bar{CL} t}{V}\\right]\\right)\n$$\n\n**3. Derivation of the Ratio R(t)**\n\nThe ratio is defined as $R(t) = \\frac{\\mathbb{E}_{\\text{additive-normal}}[C(t)]}{\\mathbb{E}_{\\text{multiplicative-lognormal}}[C(t)]}$. Using the expressions derived above:\n$$\nR(t) \\approx \\frac{\\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\exp\\left(\\frac{\\omega_{N}^{2}t^2}{2V^2}\\right)}{\\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right) \\left(1 + \\frac{\\omega_{L}^{2}}{2}\\left[\\left(\\frac{\\bar{CL} t}{V}\\right)^2 - \\frac{\\bar{CL} t}{V}\\right]\\right)}\n$$\nThe common factor of $\\frac{D}{V} \\exp\\left(-\\frac{\\bar{CL} t}{V}\\right)$ in the numerator and denominator cancels. This yields the final expression for the ratio $R(t)$:\n$$\nR(t) \\approx \\frac{\\exp\\left(\\frac{\\omega_{N}^{2}t^2}{2V^2}\\right)}{1 + \\frac{\\omega_{L}^{2}}{2}\\left(\\left(\\frac{\\bar{CL} t}{V}\\right)^2 - \\frac{\\bar{CL} t}{V}\\right)}\n$$\nThis expression is a function of $t$, $V$, $\\bar{CL}$, $\\omega_{N}$, and $\\omega_{L}$ as required.",
            "answer": "$$\n\\boxed{\\frac{\\exp\\left(\\frac{\\omega_{N}^{2}t^2}{2V^2}\\right)}{1 + \\frac{\\omega_{L}^{2}}{2}\\left(\\left(\\frac{\\bar{CL} t}{V}\\right)^2 - \\frac{\\bar{CL} t}{V}\\right)}}\n$$"
        },
        {
            "introduction": "The quality of a population model depends heavily on the quality of the data used to build it. Optimal design theory provides a powerful framework for planning experiments that maximize the information gathered about model parameters. In this practice , you will implement an algorithm to find the D-optimal sampling times for a pharmacokinetic study, using the Fisher Information Matrix to quantify the information content of different designs.",
            "id": "3920779",
            "problem": "You are asked to write a complete, runnable program that optimizes sampling times for a one-compartment pharmacokinetic model within a nonlinear mixed-effects (NLME) population framework, including variability components. The model is intravenous bolus dosing in a single compartment with first-order elimination. The observable is the drug concentration as a function of time. The design objective is to select $k$ sampling times (in hours) from a given discrete grid to maximize the information about the fixed-effect parameters, interpreted via a Fisher information criterion. You must use a principled approximation that is standard in NLME design: First-Order linearization of random effects and Gaussian observation modeling with proportional residual error.\n\nStart from the following fundamental base:\n- The one-compartment intravenous bolus model has concentration $C(t)$ described by a deterministic function $f(t,\\boldsymbol{\\theta}_i)$, where the individual parameter vector $\\boldsymbol{\\theta}_i$ contains clearance $CL_i$ and volume of distribution $V_i$, and the elimination rate is $k_i = CL_i / V_i$. The concentration is $f(t,\\boldsymbol{\\theta}_i) = \\dfrac{D}{V_i} \\exp\\!\\left(-\\dfrac{CL_i}{V_i} t\\right)$ where $D$ is the administered dose.\n- Nonlinear Mixed-Effects (NLME) models represent between-subject variability by modeling individual parameters as random deviations from population parameters. Use a log-normal representation: $CL_i = CL \\exp(\\eta_{CL,i})$ and $V_i = V \\exp(\\eta_{V,i})$, where $\\eta_{CL,i}$ and $\\eta_{V,i}$ are independent and identically distributed Gaussian random variables with zero mean and covariance matrix $\\boldsymbol{\\Omega}$.\n- Proportional residual error: measurements satisfy $y_{ij} = f(t_{ij},\\boldsymbol{\\theta}_i) \\left(1+\\epsilon_{ij}\\right)$ with $\\epsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_{\\text{prop}}^2)$ independently across all observations and individuals.\n\nUsing First-Order linearization of the random effects around $\\boldsymbol{\\eta}=\\boldsymbol{0}$, approximate the marginal distribution of the measurement vector for one individual at sampling times $\\mathbf{t}=(t_1,\\dots,t_k)$ as multivariate Gaussian with mean vector equal to the deterministic model evaluated at the population parameters $CL$ and $V$, and covariance matrix equal to a sum of the contribution from random effects and the residual error. Use this Gaussian model to derive the corresponding Fisher information matrix for the fixed-effect parameters $CL$ and $V$, using the standard expression for linear-Gaussian models with known covariance evaluated at the population parameters. The First-Order approximation requires computing the Jacobians with respect to fixed effects and with respect to random effects at the population parameters.\n\nYour program must:\n- Enumerate all $k$-tuples of sampling times from a specified discrete grid, with times sorted in ascending order and without repetition.\n- For each candidate design (set of $k$ times), compute the Fisher information matrix for the fixed-effect parameters $CL$ and $V$ under the First-Order approximation described above, multiply by the number of subjects $N$, and evaluate the design criterion defined as the natural logarithm of the determinant of this matrix.\n- Identify the design that maximizes the design criterion and report its sampling times and the maximum criterion value.\n- Additionally, compute and report the same criterion for an \"early-only\" design consisting of the earliest $k$ times in the grid, and a \"late-only\" design consisting of the latest $k$ times in the grid. This will demonstrate the trade-off between early and late sampling under proportional error and variability components.\n\nPhysical and numerical unit specifications:\n- Time must be in hours, and the program must output time values in hours.\n- The final design criterion values (natural logarithm of the determinant of the Fisher information) are dimensionless real numbers and must be output as decimal floats.\n- Do not use a percentage sign anywhere; any fractional quantities must appear as decimal values.\n\nTest suite and answer specification:\nFor each test case below, your program must produce a result in the format described in the final output format. The parameters for each test case are:\n1. Happy path case with moderate variability and residual error:\n   - Dose $D = 100$ mg.\n   - Clearance $CL = 5$ L/h.\n   - Volume $V = 40$ L.\n   - Number of subjects $N = 50$.\n   - Interindividual variability covariance $\\boldsymbol{\\Omega} = \\operatorname{diag}(0.3^2,\\,0.25^2)$ on $\\log(CL)$ and $\\log(V)$.\n   - Proportional residual error standard deviation $\\sigma_{\\text{prop}} = 0.2$.\n   - Sampling horizon $T_{\\text{end}} = 24$ h.\n   - Grid step $\\Delta t = 2$ h; grid is $\\{0, 2, 4, \\dots, 24\\}$ h.\n   - Number of sampling time points $k = 3$.\n2. Boundary case with small measurement noise and wider grid, emphasizing spread:\n   - Dose $D = 50$ mg.\n   - Clearance $CL = 1.5$ L/h.\n   - Volume $V = 20$ L.\n   - Number of subjects $N = 200$.\n   - Interindividual variability covariance $\\boldsymbol{\\Omega} = \\operatorname{diag}(0.5^2,\\,0.3^2)$.\n   - Proportional residual error standard deviation $\\sigma_{\\text{prop}} = 0.05$.\n   - Sampling horizon $T_{\\text{end}} = 12$ h.\n   - Grid step $\\Delta t = 1$ h; grid is $\\{0, 1, 2, \\dots, 12\\}$ h.\n   - Number of sampling time points $k = 3$.\n3. Edge case with large interindividual variability, highlighting the covariance contribution:\n   - Dose $D = 250$ mg.\n   - Clearance $CL = 6$ L/h.\n   - Volume $V = 80$ L.\n   - Number of subjects $N = 30$.\n   - Interindividual variability covariance $\\boldsymbol{\\Omega} = \\operatorname{diag}(0.7^2,\\,0.6^2)$.\n   - Proportional residual error standard deviation $\\sigma_{\\text{prop}} = 0.3$.\n   - Sampling horizon $T_{\\text{end}} = 12$ h.\n   - Grid step $\\Delta t = 3$ h; grid is $\\{0, 3, 6, 9, 12\\}$ h.\n   - Number of sampling time points $k = 4$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with no spaces.\n- Each test case result must itself be a bracketed list containing, in order:\n  1. The $k$ optimized sampling times in hours as decimal floats rounded to two decimals.\n  2. The optimized design criterion value (natural logarithm of the determinant) as a decimal float rounded to six decimals.\n  3. The \"early-only\" design criterion value as a decimal float rounded to six decimals.\n  4. The \"late-only\" design criterion value as a decimal float rounded to six decimals.\n- For example, the single line should look like: \"[[t1,t2,t3,best_logdet,early_logdet,late_logdet],[...],...]\".",
            "solution": "The problem requires the determination of optimal sampling times for a pharmacokinetic (PK) study based on a one-compartment intravenous (IV) bolus model within a nonlinear mixed-effects (NLME) framework. The objective is to maximize the information content about the fixed-effect population parameters, clearance ($CL$) and volume of distribution ($V$), using the D-optimality criterion, which corresponds to maximizing the natural logarithm of the determinant of the Fisher Information Matrix (FIM). The solution is derived using the standard First-Order (FO) approximation method.\n\n### 1. The Pharmacokinetic and Statistical Model\n\nThe concentration of a drug in the central compartment at time $t$ for an individual $i$ is described by the deterministic function:\n$$\nf(t, \\boldsymbol{\\theta}_i) = \\frac{D}{V_i} \\exp\\left(-\\frac{CL_i}{V_i} t\\right)\n$$\nwhere $D$ is the administered dose, and $\\boldsymbol{\\theta}_i = (CL_i, V_i)$ is the vector of individual-specific parameters for clearance and volume of distribution.\n\nThe NLME model accounts for between-subject variability by relating individual parameters to population-typical parameters ($CL$, $V$) and individual random effects ($\\boldsymbol{\\eta}_i$). A log-normal distribution is assumed for the parameters:\n$$\nCL_i = CL \\cdot \\exp(\\eta_{CL,i})\n$$\n$$\nV_i = V \\cdot \\exp(\\eta_{V,i})\n$$\nwhere the random effects vector $\\boldsymbol{\\eta}_i = (\\eta_{CL,i}, \\eta_{V,i})^T$ is assumed to follow a multivariate normal distribution with zero mean and covariance matrix $\\boldsymbol{\\Omega}$:\n$$\n\\boldsymbol{\\eta}_i \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Omega})\n$$\nThe problem specifies a diagonal covariance matrix $\\boldsymbol{\\Omega} = \\operatorname{diag}(\\omega_{CL}^2, \\omega_V^2)$.\n\nThe measured concentration for subject $i$ at time $t_{ij}$, denoted $y_{ij}$, includes proportional residual error:\n$$\ny_{ij} = f(t_{ij}, \\boldsymbol{\\theta}_i) (1 + \\epsilon_{ij})\n$$\nwhere $\\epsilon_{ij}$ are independent and identically distributed normal random variables with mean $0$ and variance $\\sigma_{\\text{prop}}^2$, i.e., $\\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_{\\text{prop}}^2)$.\n\n### 2. First-Order Approximation of the Marginal Distribution\n\nTo derive the FIM, we first need the marginal distribution of the observation vector for a single subject, $\\mathbf{y}_i = (y_{i1}, \\dots, y_{ik})^T$, taken at a set of $k$ time points $\\mathbf{t} = (t_1, \\dots, t_k)^T$. The First-Order (FO) method linearizes the model function vector $\\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\theta}_i)$ around the mean of the random effects, $\\boldsymbol{\\eta}_i = \\boldsymbol{0}$.\n\nLet $\\boldsymbol{\\xi} = (CL, V)^T$ be the vector of fixed-effect population parameters. The model prediction vector is $\\mathbf{f}_i(\\mathbf{t}, \\boldsymbol{\\xi}, \\boldsymbol{\\eta}_i)$. The linearization is:\n$$\n\\mathbf{f}_i(\\mathbf{t}, \\boldsymbol{\\xi}, \\boldsymbol{\\eta}_i) \\approx \\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\xi}) + \\mathbf{F}_{\\boldsymbol{\\eta}} \\boldsymbol{\\eta}_i\n$$\nwhere $\\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\xi})$ is the vector of model predictions using the population parameters, and $\\mathbf{F}_{\\boldsymbol{\\eta}}$ is the $k \\times 2$ Jacobian matrix of the model predictions with respect to the random effects, evaluated at $\\boldsymbol{\\eta}_i = \\boldsymbol{0}$:\n$$\n\\mathbf{F}_{\\boldsymbol{\\eta}} = \\left. \\frac{\\partial \\mathbf{f}_i}{\\partial \\boldsymbol{\\eta}_i^T} \\right|_{\\boldsymbol{\\eta}_i=\\boldsymbol{0}}\n$$\nUnder this approximation, the vector of observations $\\mathbf{y}_i$ for a subject follows a multivariate normal distribution:\n$$\n\\mathbf{y}_i \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\n$$\nThe mean vector $\\boldsymbol{\\mu}$ is the model prediction at the population parameters:\n$$\n\\boldsymbol{\\mu} = E[\\mathbf{y}_i] \\approx \\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\xi})\n$$\nThe covariance matrix $\\boldsymbol{\\Sigma}$ is the sum of the variance from random effects and the variance from residual error:\n$$\n\\boldsymbol{\\Sigma} = \\operatorname{Var}(\\mathbf{y}_i) \\approx \\mathbf{F}_{\\boldsymbol{\\eta}} \\boldsymbol{\\Omega} \\mathbf{F}_{\\boldsymbol{\\eta}}^T + \\mathbf{R}\n$$\nHere, $\\mathbf{R}$ is the covariance matrix of the residual error, evaluated at the population parameters. For a proportional error model, it is a diagonal matrix with elements:\n$$\n\\mathbf{R}_{jj} = [f(t_j, \\boldsymbol{\\xi})]^2 \\sigma_{\\text{prop}}^2\n$$\n\n### 3. The Fisher Information Matrix for Fixed Effects\n\nFor a model where observations are Gaussian with mean $\\boldsymbol{\\mu}(\\boldsymbol{\\xi})$ and known covariance $\\boldsymbol{\\Sigma}$, the FIM for the fixed effects $\\boldsymbol{\\xi}$ is given by:\n$$\nM(\\boldsymbol{\\xi}) = \\left(\\frac{\\partial \\boldsymbol{\\mu}(\\boldsymbol{\\xi})}{\\partial \\boldsymbol{\\xi}^T}\\right)^T \\boldsymbol{\\Sigma}^{-1} \\left(\\frac{\\partial \\boldsymbol{\\mu}(\\boldsymbol{\\xi})}{\\partial \\boldsymbol{\\xi}^T}\\right)\n$$\nLet $\\mathbf{F}_{\\boldsymbol{\\xi}}$ be the $k \\times 2$ Jacobian matrix of the model predictions with respect to the fixed effects:\n$$\n\\mathbf{F}_{\\boldsymbol{\\xi}} = \\frac{\\partial \\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\xi})}{\\partial \\boldsymbol{\\xi}^T}\n$$\nThe single-subject FIM is then:\n$$\nM = \\mathbf{F}_{\\boldsymbol{\\xi}}^T \\boldsymbol{\\Sigma}^{-1} \\mathbf{F}_{\\boldsymbol{\\xi}}\n$$\nThe total FIM for a population of $N$ subjects is $M_{\\text{total}} = N \\cdot M$.\n\n### 4. The D-Optimal Design Criterion\n\nThe D-optimality criterion aims to minimize the volume of the confidence ellipsoid for the parameter estimates, which is equivalent to maximizing the determinant of the FIM. For numerical stability and convenience, we maximize the natural logarithm of the determinant:\n$$\n\\text{Criterion} = \\log(\\det(M_{\\text{total}})) = \\log(\\det(N \\cdot M))\n$$\nSince $M$ is a $2 \\times 2$ matrix (for parameters $CL$ and $V$), $\\det(N \\cdot M) = N^2 \\det(M)$. Thus, the criterion is:\n$$\n\\text{Criterion} = \\log(N^2 \\det(M)) = 2\\log(N) + \\log(\\det(M))\n$$\n\n### 5. Derivation of Required Jacobians\n\nLet $f(t, CL, V) = \\frac{D}{V}e^{-(CL/V)t}$. The required partial derivatives for the Jacobians, evaluated at the population parameters ($CL, V$), are:\n\n**a. Jacobian with respect to fixed effects, $\\mathbf{F}_{\\boldsymbol{\\xi}}$:**\nThe columns of $\\mathbf{F}_{\\boldsymbol{\\xi}}$ are the vectors of partial derivatives with respect to $CL$ and $V$. For each time point $t_j$:\n$$\n\\frac{\\partial f}{\\partial CL} (t_j) = \\frac{\\partial}{\\partial CL} \\left(\\frac{D}{V}e^{-\\frac{CL}{V}t_j}\\right) = -\\frac{D t_j}{V^2}e^{-\\frac{CL}{V}t_j}\n$$\n$$\n\\frac{\\partial f}{\\partial V} (t_j) = \\frac{\\partial}{\\partial V} \\left(\\frac{D}{V}e^{-\\frac{CL}{V}t_j}\\right) = \\frac{D}{V^2}\\left(\\frac{CL \\cdot t_j}{V} - 1\\right)e^{-\\frac{CL}{V}t_j}\n$$\n\n**b. Jacobian with respect to random effects, $\\mathbf{F}_{\\boldsymbol{\\eta}}$:**\nUsing the chain rule, and evaluating at $\\boldsymbol{\\eta}=\\boldsymbol{0}$ (where $CL_i=CL, V_i=V$):\n$$\n\\frac{\\partial f}{\\partial \\eta_{CL}} = \\frac{\\partial f}{\\partial CL_i}\\frac{\\partial CL_i}{\\partial \\eta_{CL}} = \\left(-\\frac{D t_j}{(V_i)^2}e^{-\\frac{CL_i}{V_i}t_j}\\right) (CL \\cdot e^{\\eta_{CL, i}}) \\bigg|_{\\boldsymbol{\\eta}=\\boldsymbol{0}} = -\\frac{D \\cdot CL \\cdot t_j}{V^2}e^{-\\frac{CL}{V}t_j}\n$$\n$$\n\\frac{\\partial f}{\\partial \\eta_{V}} = \\frac{\\partial f}{\\partial V_i}\\frac{\\partial V_i}{\\partial \\eta_{V}} = \\left(\\frac{D}{(V_i)^2}\\left(\\frac{CL_i t_j}{V_i} - 1\\right)e^{-\\frac{CL_i}{V_i}t_j}\\right) (V \\cdot e^{\\eta_{V, i}}) \\bigg|_{\\boldsymbol{\\eta}=\\boldsymbol{0}} = \\frac{D}{V}\\left(\\frac{CL \\cdot t_j}{V} - 1\\right)e^{-\\frac{CL}{V}t_j}\n$$\n\n### 6. The Computational Algorithm\n\nThe optimal design is found by searching over a discrete set of possible sampling schedules.\n1.  **Generate Candidate Designs:** For a given sampling grid $\\{t_1, t_2, \\dots, t_m\\}$ and a requirement of $k$ samples, all unique combinations of $k$ time points are enumerated.\n2.  **Evaluate Each Design:** For each candidate design (a set of $k$ time points):\n    a. Calculate the model predictions $\\mathbf{f}(\\mathbf{t}, \\boldsymbol{\\xi})$ at the population parameters.\n    b. Calculate the Jacobians $\\mathbf{F}_{\\boldsymbol{\\xi}}$ and $\\mathbf{F}_{\\boldsymbol{\\eta}}$.\n    c. Construct the residual error matrix $\\mathbf{R}$ and the component from random effects $\\mathbf{F}_{\\boldsymbol{\\eta}} \\boldsymbol{\\Omega} \\mathbf{F}_{\\boldsymbol{\\eta}}^T$.\n    d. Form the marginal covariance matrix $\\boldsymbol{\\Sigma} = \\mathbf{F}_{\\boldsymbol{\\eta}} \\boldsymbol{\\Omega} \\mathbf{F}_{\\boldsymbol{\\eta}}^T + \\mathbf{R}$.\n    e. Compute the single-subject FIM, $M = \\mathbf{F}_{\\boldsymbol{\\xi}}^T \\boldsymbol{\\Sigma}^{-1} \\mathbf{F}_{\\boldsymbol{\\xi}}$.\n    f. Calculate the design criterion value, $2\\log(N) + \\log(\\det(M))$. If $\\det(M) \\le 0$, the design is considered non-informative and its criterion is effectively $-\\infty$.\n3.  **Identify Optimal Design:** The design that yields the maximum criterion value is selected as the D-optimal design.\n4.  **Evaluate Reference Designs:** The same criterion is computed for two fixed reference designs: the \"early-only\" design, comprising the first $k$ points on the grid, and the \"late-only\" design, comprising the last $k$ points. This comparison highlights the impact of sampling time choices on the information gained.\n\nThis systematic procedure is implemented for each test case to find the optimal sampling times and associated criterion values.",
            "answer": "```python\nimport numpy as np\nfrom itertools import combinations\n\ndef calculate_log_det_fim(times, D, CL, V, N, Omega_diag, sigma_prop):\n    \"\"\"\n    Calculates the log-determinant of the total Fisher Information Matrix.\n    \"\"\"\n    times = np.array(times, dtype=float)\n    k = len(times)\n    \n    # Model predictions at population parameters\n    k_e = CL / V\n    f_t = (D / V) * np.exp(-k_e * times)\n    \n    # Jacobian w.r.t. fixed effects (xi = [CL, V])\n    # Column for CL\n    g_cl_t = (-times / V) * f_t\n    # Column for V\n    g_v_t = ((k_e * times - 1) / V) * f_t\n    F_xi = np.vstack((g_cl_t, g_v_t)).T # k x 2 matrix\n    \n    # Jacobian w.r.t. random effects (eta = [eta_CL, eta_V])\n    h_cl_t = g_cl_t * CL\n    h_v_t = g_v_t * V\n    F_eta = np.vstack((h_cl_t, h_v_t)).T # k x 2 matrix\n\n    # Residual error covariance matrix R\n    R = np.diag(f_t**2 * sigma_prop**2) # k x k matrix\n    \n    # Marginal covariance matrix Sigma\n    omega_cl_sq, omega_v_sq = Omega_diag\n    # Outer products create k x k matrices\n    cov_re = omega_cl_sq * np.outer(h_cl_t, h_cl_t) + omega_v_sq * np.outer(h_v_t, h_v_t)\n    Sigma = cov_re + R # k x k matrix\n    \n    try:\n        Sigma_inv = np.linalg.inv(Sigma)\n    except np.linalg.LinAlgError:\n        return -np.inf # Matrix is singular\n        \n    # Single-subject FIM (M)\n    FIM_single = F_xi.T @ Sigma_inv @ F_xi # 2 x 2 matrix\n    \n    # Determinant of single-subject FIM\n    det_FIM_single = np.linalg.det(FIM_single)\n    \n    if det_FIM_single = 0:\n        return -np.inf\n\n    # Total log-determinant for N subjects\n    # log(det(N*M)) = log(N^2 * det(M)) = 2*log(N) + log(det(M))\n    log_det_total_FIM = 2 * np.log(N) + np.log(det_FIM_single)\n    \n    return log_det_total_FIM\n\ndef find_optimal_design(params):\n    \"\"\"\n    Finds the optimal design by enumerating all possibilities.\n    \"\"\"\n    D, CL, V, N, Omega_diag, sigma_prop, Tend, dt, k = params\n    \n    time_grid = np.arange(0, Tend + dt, dt)\n    \n    best_design = None\n    max_log_det = -np.inf\n    \n    for design_times in combinations(time_grid, k):\n        log_det = calculate_log_det_fim(design_times, D, CL, V, N, Omega_diag, sigma_prop)\n        if log_det > max_log_det:\n            max_log_det = log_det\n            best_design = design_times\n            \n    # Calculate for early-only and late-only designs\n    early_design = tuple(time_grid[:k])\n    late_design = tuple(time_grid[-k:])\n    \n    early_log_det = calculate_log_det_fim(early_design, D, CL, V, N, Omega_diag, sigma_prop)\n    late_log_det = calculate_log_det_fim(late_design, D, CL, V, N, Omega_diag, sigma_prop)\n    \n    result = []\n    # Format times to two decimal places\n    result.extend([f\"{t:.2f}\" for t in best_design])\n    # Format criteria to six decimal places\n    result.extend([f\"{val:.6f}\" for val in [max_log_det, early_log_det, late_log_det]])\n    \n    return result\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (D, CL, V, N, Omega_diag, sigma_prop, Tend, dt, k)\n        (100, 5, 40, 50, (0.3**2, 0.25**2), 0.2, 24, 2, 3),\n        (50, 1.5, 20, 200, (0.5**2, 0.3**2), 0.05, 12, 1, 3),\n        (250, 6, 80, 30, (0.7**2, 0.6**2), 0.3, 12, 3, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        # returns a list of formatted strings\n        result = find_optimal_design(case)\n        results.append(f\"[{','.join(result)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "After fitting a population model, we must rigorously assess its predictive performance to ensure it provides a reliable representation of the data. The Visual Predictive Check (VPC) is an essential graphical diagnostic tool that compares the distribution of observed data to the distribution of simulated data from the model. This exercise  guides you through the implementation of a stratified VPC, a practical skill for any modeler seeking to validate their work.",
            "id": "3920841",
            "problem": "You are tasked with constructing a Visual Predictive Check (VPC) for a nonlinear mixed-effects population model in a biomedical systems modeling context. The population model is a one-compartment intravenous bolus pharmacokinetic model with proportional residual error. The VPC must specify a binning strategy over time, compute simulation-based prediction intervals within each bin, and perform stratification by a clinically relevant covariate. The final output of your program must be a single line containing the requested VPC metrics for a provided test suite of parameter settings.\n\nUse the following scientifically grounded base. The one-compartment intravenous bolus pharmacokinetic model under first-order elimination is derived from the mass balance and first-order kinetics. For subject $i$ with clearance $CL_i$ and volume of distribution $V_i$, the drug concentration $C_i(t)$ in plasma at time $t$ after an intravenous bolus dose $D_i$ follows\n$$\n\\frac{dC_i(t)}{dt} \\;=\\; -\\frac{CL_i}{V_i} \\, C_i(t),\n$$\nwith initial condition $C_i(0^+) = \\frac{D_i}{V_i}$. The solution is\n$$\nC_i(t) \\;=\\; \\frac{D_i}{V_i} \\, \\exp\\!\\Big(-\\frac{CL_i}{V_i} \\, t\\Big).\n$$\nIn a nonlinear mixed-effects framework, interindividual variability is modeled by random effects. Let population parameters be $CL_{\\text{pop}}$ and $V_{\\text{pop}}$, and let a covariate model for clearance be included using body weight $WT_i$ with an allometric form. The individual parameters are modeled as\n$$\nCL_i \\;=\\; \\theta_{CL} \\,\\Big(\\frac{WT_i}{70}\\Big)^{\\theta_{WT}} \\, \\exp(\\eta_{CL,i}), \\quad \\eta_{CL,i} \\sim \\mathcal{N}(0,\\omega_{CL}^2),\n$$\n$$\nV_i \\;=\\; \\theta_{V} \\, \\exp(\\eta_{V,i}), \\quad \\eta_{V,i} \\sim \\mathcal{N}(0,\\omega_{V}^2),\n$$\nwith $\\eta_{CL,i}$ and $\\eta_{V,i}$ independent. The proportional residual error model for observed concentrations $Y_{ij}$ at time $t_{ij}$ is\n$$\nY_{ij} \\;=\\; C_i(t_{ij}) \\, \\big(1 + \\epsilon_{ij}\\big), \\quad \\epsilon_{ij} \\sim \\mathcal{N}(0,\\sigma^2),\n$$\nindependent across $i$ and $j$.\n\nThe Visual Predictive Check (VPC) compares observed statistics to simulation-based prediction intervals under the fitted model structure. Your VPC design and algorithm must adhere to the following specification:\n\n1. Stratification by covariate:\n   - Define two strata based on body weight $WT_i$: a \"low weight\" stratum with $WT_i  75$ and a \"high weight\" stratum with $WT_i \\ge 75$.\n   - Perform the VPC computations independently within each stratum and aggregate the coverage metrics across strata.\n\n2. Binning strategy over time $t$:\n   - Quantile (equal-count) binning: Partition the observed time points within a stratum into $B$ bins such that the total number of observations per bin is approximately equal, assigning whole unique time points to bins to avoid empty bins.\n   - Fixed-width binning: Use provided bin edges $\\{b_0, b_1, \\dots, b_B\\}$ to assign times $t$ to bins by the rule $b_k \\le t  b_{k+1}$ for $k = 0, \\dots, B-2$ and $b_{B-1} \\le t \\le b_{B}$ for the last bin.\n\n3. Prediction intervals:\n   - For each bin and stratum, simulate concentrations consistent with the model and compute lower and upper prediction interval bounds defined by quantiles at probability levels $p_{\\text{low}}$ and $p_{\\text{high}}$ (for example, $p_{\\text{low}} = 0.05$, $p_{\\text{high}} = 0.95$). Also compute the simulated binwise median.\n\n4. Observed reference statistic:\n   - For each bin and stratum, compute the observed median of $Y_{ij}$.\n\n5. Coverage metric:\n   - For each bin and stratum, compute the indicator that the observed median lies within the simulated prediction interval $[Q_{p_{\\text{low}}}, Q_{p_{\\text{high}}}]$.\n   - Aggregate across all bins and strata to compute a single coverage fraction $\\in [0,1]$ defined as the number of bins whose observed median is within the simulated interval divided by the total number of bins considered.\n\nUse the following synthetic observed dataset design so that the VPC can be performed without external input. The observed dataset should be generated internally by your program using a fixed random seed and the following parameters:\n- Number of subjects $N_{\\text{subj}} = 24$.\n- Dose $D_i = 100$ milligrams for all subjects. Concentrations should be expressed in milligrams per liter.\n- Sampling times $t \\in \\{0.5, 1.0, 2.0, 4.0, 8.0, 12.0\\}$ hours for all subjects.\n- Body weights $WT_i$ drawn independently and uniformly from $[50, 100]$ kilograms.\n- True generative population parameters for the observed dataset: $\\theta_{CL}^{\\text{true}} = 5$ liters per hour, $\\theta_{V}^{\\text{true}} = 50$ liters, $\\theta_{WT}^{\\text{true}} = 0.75$, $\\omega_{CL}^{\\text{true}} = 0.25$, $\\omega_{V}^{\\text{true}} = 0.20$, and $\\sigma^{\\text{true}} = 0.15$.\n- Use a fixed random seed $12345$ for all random draws in generating the observed dataset.\n\nFor the VPC simulations under each test case, use the same subjects, weights, dose, and sampling times as in the observed dataset, but use the parameter values specified by each test case. For each test case, simulate $R$ replicates by sampling the random effects and residual errors anew for each replicate and subject.\n\nTest suite specification (three test cases):\n- Test case $1$ (quantile binning, $4$ bins, $90\\%$ interval):\n  - Binning: quantile, $B = 4$.\n  - Prediction interval: $p_{\\text{low}} = 0.05$, $p_{\\text{high}} = 0.95$.\n  - Variability parameters: $\\sigma = 0.20$, $\\omega_{CL} = 0.30$, $\\omega_{V} = 0.20$.\n  - Covariate parameter: $\\theta_{WT} = 0.75$.\n  - Replicates: $R = 300$.\n- Test case $2$ (quantile binning, $4$ bins, $80\\%$ interval, low residual error):\n  - Binning: quantile, $B = 4$.\n  - Prediction interval: $p_{\\text{low}} = 0.10$, $p_{\\text{high}} = 0.90$.\n  - Variability parameters: $\\sigma = 0.01$, $\\omega_{CL} = 0.30$, $\\omega_{V} = 0.20$.\n  - Covariate parameter: $\\theta_{WT} = 0.75$.\n  - Replicates: $R = 300$.\n- Test case $3$ (fixed-width binning, $4$ bins, $90\\%$ interval, higher interindividual variability in clearance):\n  - Binning: fixed-width with edges $[0.5, 1.5, 3.0, 6.0, 12.0]$ hours, i.e., $B=4$ bins: $[0.5,1.5)$, $[1.5,3.0)$, $[3.0,6.0)$, $[6.0,12.0]$.\n  - Prediction interval: $p_{\\text{low}} = 0.05$, $p_{\\text{high}} = 0.95$.\n  - Variability parameters: $\\sigma = 0.20$, $\\omega_{CL} = 0.60$, $\\omega_{V} = 0.30$.\n  - Covariate parameter: $\\theta_{WT} = 0.75$.\n  - Replicates: $R = 300$.\n\nPopulation-fixed parameters for all test cases: $\\theta_{CL} = 5$ liters per hour, $\\theta_{V} = 50$ liters. Concentrations should be handled in milligrams per liter. Angles are not involved. Express all final coverage metrics as decimal fractions in $[0,1]$.\n\nAlgorithmic requirements:\n- Implement the model simulation as specified.\n- Implement stratification by weight categories.\n- Implement both quantile binning and fixed-width binning strategies.\n- For each bin and stratum, compute simulated prediction intervals and observed medians.\n- Compute the coverage fraction as defined above for each test case.\n\nFinal output format:\n- Your program should produce a single line of output containing the coverage fractions for the three test cases as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3]$, where each $x_k$ is a decimal fraction in $[0,1]$ for test case $k$.",
            "solution": "The solution requires implementing a Visual Predictive Check (VPC) for a population pharmacokinetic model. This involves three main stages: generating a synthetic \"observed\" dataset, performing simulations based on the model structure for different parameter sets (test cases), and comparing the observed data to the simulation results to calculate a coverage metric.\n\n**1. Generation of the Synthetic Observed Dataset**\n\nFirst, we construct a single, fixed \"observed\" dataset according to the specified study design and true generative parameters. This dataset serves as the reference against which the VPC simulations are compared.\n- A deterministic process is established by setting a fixed random seed ($12345$).\n- We generate $N_{\\text{subj}} = 24$ subjects, each assigned a body weight $WT_i$ drawn from a uniform distribution $\\mathcal{U}[50, 100]$.\n- For each subject $i$, we sample individual random effects, $\\eta_{CL,i}$ and $\\eta_{V,i}$, from their respective normal distributions, $\\mathcal{N}(0, (\\omega_{CL}^{\\text{true}})^2)$ and $\\mathcal{N}(0, (\\omega_{V}^{\\text{true}})^2)$.\n- Using the \"true\" population parameters $(\\theta_{CL}^{\\text{true}}, \\theta_{V}^{\\text{true}}, \\theta_{WT}^{\\text{true}})$ and the subject's specific $WT_i$ and sampled $\\eta$ values, we compute their individual pharmacokinetic parameters, $CL_i$ and $V_i$.\n- For each of the $6$ specified sampling times $t_{ij}$, we calculate the true concentration $C_i(t_{ij})$.\n- A residual error term $\\epsilon_{ij}$ is sampled from $\\mathcal{N}(0, (\\sigma^{\\text{true}})^2)$, and the final \"observed\" concentration is computed as $Y_{ij} = C_i(t_{ij})(1 + \\epsilon_{ij})$.\nThis process yields a complete dataset of subject IDs, body weights, time points, and observed concentrations, which remains constant for all subsequent test cases.\n\n**2. VPC Simulation and Analysis Algorithm**\n\nFor each test case, we execute the VPC algorithm. The core of the algorithm is to simulate many datasets under the assumptions of the test case's model parameters and compare their distribution to the observed data.\n\n**2.1. Stratification**\nThe first step is to stratify the subjects and their corresponding observations based on body weight $WT_i$, creating a \"low weight\" stratum ($WT_i  75$) and a \"high weight\" stratum ($WT_i \\ge 75$). The VPC analysis is then performed independently within each stratum. This accounts for the covariate's influence on the pharmacokinetics.\n\n**2.2. Binning**\nWithin each stratum, the observations are grouped into bins based on time.\n- **Quantile Binning**: All observations in the stratum are sorted by their time values. The sorted list is then partitioned into $B$ groups of nearly equal size. Each group of observations constitutes a bin. This ensures that each bin contains a similar number of data points, providing comparable statistical power across bins.\n- **Fixed-Width Binning**: Observations are assigned to one of $B$ predefined time intervals. An observation at time $t$ is placed in bin $k$ if $t$ falls within the $k$-th interval $[b_{k-1}, b_k)$. The final bin is inclusive of its upper bound.\n\n**2.3. Simulation and Prediction Interval Construction**\nFor each stratum, we simulate $R$ new datasets. For each replicate $r=1, \\dots, R$:\n- For each subject $i$ in the stratum, we sample new random effects $\\eta'_{CL,i}$ and $\\eta'_{V,i}$ from normal distributions with variances $\\omega_{CL}^2$ and $\\omega_{V}^2$ as specified by the test case.\n- We then calculate the simulated individual parameters $CL'_i$ and $V'_i$ using the test case's population parameters ($\\theta_{CL}, \\theta_{V}, \\theta_{WT}$).\n- For each original sampling time $t_{ij}$, we compute the simulated true concentration $C'_i(t_{ij})$ and add multiplicative noise by sampling a new residual error term $\\epsilon'_{ij}$ from $\\mathcal{N}(0, \\sigma^2)$, where $\\sigma$ is given by the test case, yielding the simulated observation $Y'_{ij}$.\n\nAfter generating all $R$ replicates, for each bin, we aggregate all simulated observations ($Y'_{ij}$) that fall into that bin's time range across all subjects and all replicates. From this large collection of simulated points, we compute the empirical quantiles corresponding to the specified probabilities $p_{\\text{low}}$ and $p_{\\text{high}}$. These quantiles define the lower and upper bounds of the simulated prediction interval for that bin.\n\n**2.4. Calculation of the Coverage Fraction**\nFor each bin, we calculate the median of the original \"observed\" data points, $M_{\\text{obs}}$, that belong to that bin. We then check if this observed median lies within the corresponding simulated prediction interval $[Q_{p_{\\text{low}}}, Q_{p_{\\text{high}}}]$.\n\nThe final metric for each test case is the coverage fraction: the total number of bins (across both strata) for which the observed median was \"covered\" by the prediction interval, divided by the total number of bins. This fraction, a value between $0$ and $1$, quantifies how well the model specified in the test case predicts the central tendency of the observed data. A value close to the nominal coverage of the prediction interval (e.g., $0.90$ for a $90\\%$ PI) suggests a good model fit.\n\nThis entire procedure is repeated for each of the three test cases, yielding three distinct coverage fractions.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the VPC analysis for all test cases.\n    \"\"\"\n\n    def generate_observed_data(seed):\n        \"\"\"\n        Generates the synthetic 'observed' dataset based on true parameters.\n        This dataset is generated once and used for all test cases.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        \n        # True generative parameters\n        theta_cl_true, theta_v_true, theta_wt_true = 5.0, 50.0, 0.75\n        omega_cl_true, omega_v_true, sigma_true = 0.25, 0.20, 0.15\n        \n        n_subj = 24\n        dose = 100.0\n        times = np.array([0.5, 1.0, 2.0, 4.0, 8.0, 12.0])\n        n_times = len(times)\n        \n        # Generate subject-level data\n        subj_ids = np.arange(1, n_subj + 1)\n        wts = rng.uniform(50, 100, n_subj)\n        \n        eta_cl = rng.normal(0, omega_cl_true, n_subj)\n        eta_v = rng.normal(0, omega_v_true, n_subj)\n        \n        # Individual PK parameters\n        cl_ind = theta_cl_true * (wts / 70.0)**theta_wt_true * np.exp(eta_cl)\n        _v_ind = theta_v_true * np.exp(eta_v)\n        \n        # Expand for time-level data\n        obs_subj_ids = np.repeat(subj_ids, n_times)\n        obs_wts = np.repeat(wts, n_times)\n        obs_times = np.tile(times, n_subj)\n        \n        cl_obs = np.repeat(cl_ind, n_times)\n        v_obs = np.repeat(_v_ind, n_times)\n        \n        # Model predictions\n        c_pred = (dose / v_obs) * np.exp(-(cl_obs / v_obs) * obs_times)\n        \n        # Add residual error\n        epsilon = rng.normal(0, sigma_true, len(c_pred))\n        y_obs = c_pred * (1 + epsilon)\n        \n        return {\n            'subj_ids': obs_subj_ids, 'wts': obs_wts, 'times': obs_times, 'y_obs': y_obs\n        }\n\n    def run_vpc_case(observed_data, case_params):\n        \"\"\"\n        Runs the VPC simulation and analysis for a single test case.\n        \"\"\"\n        # A fixed seed for all simulations for reproducibility\n        sim_rng = np.random.default_rng(54321)\n\n        # Unpack case parameters\n        theta_cl, theta_v = case_params['theta_cl'], case_params['theta_v']\n        theta_wt = case_params['theta_wt']\n        omega_cl, omega_v, sigma = case_params['omega_cl'], case_params['omega_v'], case_params['sigma']\n        p_low, p_high = case_params['p_low'], case_params['p_high']\n        bin_strat = case_params['binning_strategy']\n        num_bins = case_params['num_bins']\n        fixed_bin_edges = case_params.get('fixed_bin_edges')\n        R = case_params['replicates']\n        dose = 100.0\n        \n        unique_subj_ids = np.unique(observed_data['subj_ids'])\n        subj_wts_map = {sid: observed_data['wts'][observed_data['subj_ids'] == sid][0] for sid in unique_subj_ids}\n\n        strata = {\n            'low_wt': [sid for sid, wt in subj_wts_map.items() if wt  75],\n            'high_wt': [sid for sid, wt in subj_wts_map.items() if wt = 75]\n        }\n        \n        total_covered_bins = 0\n        total_bins_evaluated = 0\n\n        for stratum_name, sids_in_stratum in strata.items():\n            if not sids_in_stratum:\n                continue\n\n            stratum_mask = np.isin(observed_data['subj_ids'], sids_in_stratum)\n            obs_y_stratum = observed_data['y_obs'][stratum_mask]\n            obs_t_stratum = observed_data['times'][stratum_mask]\n            obs_subj_ids_stratum = observed_data['subj_ids'][stratum_mask]\n            obs_wts_stratum = observed_data['wts'][stratum_mask]\n            n_obs_stratum = len(obs_y_stratum)\n            \n            # Map stratum-level subject index to observation data\n            unique_sids, subj_indices_in_stratum = np.unique(obs_subj_ids_stratum, return_inverse=True)\n            wts_for_sim = np.array([subj_wts_map[sid] for sid in unique_sids])\n            n_subj_stratum = len(unique_sids)\n\n            # --- Binning ---\n            bin_assignments = np.zeros(n_obs_stratum, dtype=int)\n            if bin_strat == 'quantile':\n                sort_indices = np.argsort(obs_t_stratum)\n                # Split sorted indices into B chunks to define bins\n                binned_indices_groups = np.array_split(sort_indices, num_bins)\n                for i, group in enumerate(binned_indices_groups):\n                    bin_assignments[group] = i\n            elif bin_strat == 'fixed-width':\n                # Use all but the last edge for np.digitize.\n                # It bins [b0,b1), [b1,b2), ..., [b_{B-1}, inf)\n                # which aligns with problem for times = max_edge.\n                # np.digitize is 1-based, subtract 1 for 0-based bin index\n                bin_assignments = np.digitize(obs_t_stratum, fixed_bin_edges[:-1]) - 1\n\n            # --- Simulation ---\n            sim_y_matrix = np.zeros((R, n_obs_stratum))\n            for r in range(R):\n                eta_cl_r = sim_rng.normal(0, omega_cl, n_subj_stratum)\n                eta_v_r = sim_rng.normal(0, omega_v, n_subj_stratum)\n\n                cl_ind_r = theta_cl * (wts_for_sim / 70.0)**theta_wt * np.exp(eta_cl_r)\n                v_ind_r = theta_v * np.exp(eta_v_r)\n                \n                cl_obs_r = cl_ind_r[subj_indices_in_stratum]\n                v_obs_r = v_ind_r[subj_indices_in_stratum]\n                \n                c_pred_r = (dose / v_obs_r) * np.exp(-(cl_obs_r / v_obs_r) * obs_t_stratum)\n                \n                epsilon_r = sim_rng.normal(0, sigma, n_obs_stratum)\n                sim_y_matrix[r, :] = c_pred_r * (1 + epsilon_r)\n                \n            # --- Statistics and Coverage ---\n            for k in range(num_bins):\n                bin_mask = (bin_assignments == k)\n                if not np.any(bin_mask):\n                    continue\n                \n                total_bins_evaluated += 1\n                \n                obs_median_bin = np.median(obs_y_stratum[bin_mask])\n                \n                sim_data_bin = sim_y_matrix[:, bin_mask].flatten()\n                \n                pi_low, pi_high = np.quantile(sim_data_bin, [p_low, p_high])\n                \n                if pi_low = obs_median_bin = pi_high:\n                    total_covered_bins += 1\n        \n        return total_covered_bins / total_bins_evaluated if total_bins_evaluated  0 else 0\n\n\n    # --- Setup and Execution ---\n    observed_data = generate_observed_data(seed=12345)\n\n    test_cases = [\n        { # Case 1\n            'binning_strategy': 'quantile', 'num_bins': 4,\n            'p_low': 0.05, 'p_high': 0.95,\n            'sigma': 0.20, 'omega_cl': 0.30, 'omega_v': 0.20,\n            'theta_cl': 5.0, 'theta_v': 50.0, 'theta_wt': 0.75,\n            'replicates': 300\n        },\n        { # Case 2\n            'binning_strategy': 'quantile', 'num_bins': 4,\n            'p_low': 0.10, 'p_high': 0.90,\n            'sigma': 0.01, 'omega_cl': 0.30, 'omega_v': 0.20,\n            'theta_cl': 5.0, 'theta_v': 50.0, 'theta_wt': 0.75,\n            'replicates': 300\n        },\n        { # Case 3\n            'binning_strategy': 'fixed-width', 'num_bins': 4,\n            'fixed_bin_edges': np.array([0.5, 1.5, 3.0, 6.0, 12.0]),\n            'p_low': 0.05, 'p_high': 0.95,\n            'sigma': 0.20, 'omega_cl': 0.60, 'omega_v': 0.30,\n            'theta_cl': 5.0, 'theta_v': 50.0, 'theta_wt': 0.75,\n            'replicates': 300\n        }\n    ]\n\n    results = [run_vpc_case(observed_data, case) for case in test_cases]\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}