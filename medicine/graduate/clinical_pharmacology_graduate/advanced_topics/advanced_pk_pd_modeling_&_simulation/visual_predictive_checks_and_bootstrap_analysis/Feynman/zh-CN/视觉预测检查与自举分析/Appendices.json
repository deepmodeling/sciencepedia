{
    "hands_on_practices": [
        {
            "introduction": "在构建可视化预测检验（VPC）图时，一个关键步骤是将独立变量（如时间）进行分箱。每个分箱中数据的数量直接影响我们对药物浓度分布分位数估计的可靠性。这项练习将引导您从第一性原理出发，探索每个分箱中的样本量 $n$ 与分位数估计稳定性之间的统计关系，并量化所需的最小样本量 。理解这一点对于正确解读VPC图至关重要，特别是能够帮助您识别和避免因数据稀疏而导致的“伪过覆盖”（apparent overcoverage）现象。",
            "id": "4601292",
            "problem": "一个临床药理学团队正在为一个群体药代动力学模型准备视觉预测检验 (VPC)。在每个时间区间内，VPC 会显示根据该区间内观测样本量模拟的重复实验中，浓度分布的经验 $p$-分位数（例如，$10\\%$ 和 $90\\%$ 分位数）的模拟预测带。在一个代表性的时间区间 $\\mathcal{B}$ 的观测数据，是由一个累积分布函数为 $F(x)$、密度函数为 $f(x)$ 的连续分布生成的。令 $q_p$ 表示真实的 $p$-分位数，使得 $F(q_p) = p$；令 $\\hat{q}_p$ 表示根据区间 $\\mathcal{B}$ 中的 $n$ 个观测值计算出的经验 $p$-分位数。该团队注意到，当每个区间的 $n$ 很小时，模拟的分位数带会非常宽，并且观测到的分位数曲线似乎比预期更频繁地落在模拟带内（表观过度覆盖），即使在模型没有明显错配的情况下也是如此。\n\n从基本原理出发，解释为什么小的 $n$ 会增加 $\\hat{q}_p$ 的方差，以及为什么这会导致 VPC 中出现表观过度覆盖。然后，为区间的最小计数提出定量标准。具体来说，考虑区间 $\\mathcal{B}$ 的以下设计目标：在 $\\mathcal{B}$ 处，经验 $10\\%$-分位数的模拟 $90\\%$ 预测带的半宽为 $B = 0.50$ mg/L，并且团队要求 $\\hat{q}_{0.1}$ 的 $95\\%$ 置信区间半宽不应超过 $B$ 的一个分数 $r = 0.5$。在真实的下分位数处，密度为 $f(q_{0.1}) = 0.50$ (mg/L)$^{-1}$。基于一个有原则的大样本近似，推导出满足团队要求的最小 $n$。此外，根据期望的尾部计数 $n p$ 和 $n (1-p)$ 提出一个经验法则标准，并描述一个基于自助法 (bootstrap) 的替代方案，该方案可在实践中用于验证每个区间内 $n$ 的充分性。\n\n哪个选项最好地提供了正确的机制和定量合理的标准？\n\nA. 小 $n$ 会夸大 $\\hat{q}_p$ 的抽样变异性，因为在 $q_p$ 附近的经验累积分布函数存在噪声，而到 $\\hat{q}_p$ 的反向映射会通过一个与 $1/f(q_p)$ 相关的因子放大这种噪声。因此，随着 $n$ 的减小，经验分位数的模拟带会变宽，所以观测到的 $\\hat{q}_p$ 会更频繁地出现在带内（表观过度覆盖）。一个有原则的大样本近似得出的要求是 $n \\ge \\left(\\dfrac{z_{0.975}\\sqrt{p(1-p)}}{r\\,B\\,f(q_p)}\\right)^2$，对于 $p=0.1$，$f(q_{0.1})=0.50$ (mg/L)$^{-1}$，$B=0.50$ mg/L，以及 $r=0.5$ 时，该式给出 $n \\ge 22.1$，因此每个区间的最小值为 $n=23$。一个补充的经验法则要求 $n p \\ge 10$ 和 $n(1-p) \\ge 10$，这意味着对于 $p=0.1$，$n \\ge \\max\\{10/p,\\,10/(1-p)\\} = 100$。在实践中，可以在每个区间内使用非参数自助法来估计 $\\hat{q}_p$ 的 $95\\%$ 置信区间宽度；可以要求自助法 $95\\%$ 区间半宽 $\\le r B$ 来确认 $n$ 的充分性。\n\nB. 小 $n$ 会减小 $\\hat{q}_p$ 的方差，因为点数越少意味着顺序统计量中的随机性越小，从而导致覆盖不足。因此，每个区间 $n \\ge 10$ 的简单标准对任何分位数都足够了，并且如果平均浓度稳定，则自助法是不必要的。\n\nC. 表观过度覆盖主要是由模型错配引起的，而不是抽样变异性。每个区间的观测数量不会实质性地改变分位数方差，因此不需要定量的最小 $n$；相反，应该拟合一个更灵活的模型，并避免使用自助法，因为它只会放大模型误差。\n\nD. 与 VPC 分位数带相关的变异性是平均浓度的方差，根据中心极限定理，该方差为 $\\sigma^2/n$；分位数具有相同的方差缩放。利用这一点，可以设置 $n$ 使得 $z_{0.975}\\,\\sigma/\\sqrt{n} \\le r B$，对于典型的 $\\sigma$，$n \\ge 22$ 就足够了。没有必要考虑 $f(q_p)$ 或尾部计数，并且自助法应侧重于均值，而不是分位数。",
            "solution": "问题陈述要求对临床药理学中构建可靠的视觉预测检验 (VPC) 所需的样本量 ($n$) 进行多部分分析，重点关注经验分位数的变异性。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n- **背景**：针对群体药代动力学模型的视觉预测检验 (VPC)。\n- **现象**：当每个时间区间的样本量 $n$ 较小时，模拟的预测带很宽，观测到的分位数曲线似乎比预期更频繁地落在带内（表观过度覆盖）。\n- **随机模型**：时间区间 $\\mathcal{B}$ 内的观测值来自一个累积分布函数 (CDF) 为 $F(x)$、概率密度函数 (PDF) 为 $f(x)$ 的连续分布。\n- **定义**：$q_p$ 是真实的 $p$-分位数，其中 $F(q_p) = p$。$\\hat{q}_p$ 是来自 $n$ 个观测值的经验 $p$-分位数。\n- **设计目标**：分析重点关注区间 $\\mathcal{B}$ 中的经验 $10\\%$-分位数 ($\\hat{q}_{0.1}$)。\n- **设计参数**：\n    - $\\hat{q}_{0.1}$ 的模拟 $90\\%$ 预测带的半宽为 $B = 0.50$ mg/L。\n    - 要求的精度是 $\\hat{q}_{0.1}$ 的 $95\\%$ 置信区间 (CI) 半宽不得超过 $B$ 的一个分数 $r = 0.5$。\n    - 真实分位数处的密度给定为 $f(q_{0.1}) = 0.50$ (mg/L)$^{-1}$。\n- **任务**：\n    1. 解释小 $n$、$\\hat{q}_p$ 的方差和表观过度覆盖之间的关系。\n    2. 使用大样本近似，根据给定的设计目标推导最小样本量 $n$。\n    3. 根据期望的尾部计数提出一个经验法则。\n    4. 描述一个基于自助法的替代方案，用于验证 $n$ 的充分性。\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题在科学上和数学上都是合理的。在药代动力学计量学中，由于稀疏数据导致 VPC 中汇总统计量的高抽样变异性而引起的“表观过度覆盖”现象是一个已知问题。该问题利用了样本分位数公认的渐近理论。执行所需推导的所有必要定量信息（$p$、$r$、$B$、$f(q_{0.1})$ 和 CI 的置信水平）均已提供。定义和任务清晰、明确且自洽。该问题提法恰当，并与指定领域相关。\n\n**第 3 步：结论与行动**\n问题有效。解决方案将继续进行推导和分析。\n\n### 解答推导\n\n**1. 理论解释：$\\hat{q}_p$ 的方差与表观过度覆盖**\n\n经验 $p$-分位数 $\\hat{q}_p$ 是真实总体分位数 $q_p$ 的一个估计量。其值由大小为 $n$ 的样本的顺序统计量确定。根据统计学中的大样本理论，对于来自具有 PDF $f(x)$ 的连续分布的样本，样本分位数 $\\hat{q}_p$ 渐近地服从以真实分位数 $q_p$ 为中心的常态分布，其方差为：\n$$ \\text{Var}(\\hat{q}_p) \\approx \\frac{p(1-p)}{n [f(q_p)]^2} $$\n这个公式揭示了两个关键的依赖关系：\n- **与 $n$ 的反比关系**：分位数估计量的方差与样本量 $n$ 成反比。当 $n$ 变小时，$\\text{Var}(\\hat{q}_p)$ 会显著增加。\n- **与 $f(q_p)^2$ 的反比关系**：方差与分位数处概率密度的平方成反比。对于尾部分位数（其中 $p$ 接近 $0$ 或 $1$），密度 $f(q_p)$ 通常较低。这会放大方差，意味着尾部分位数本质上比中位数等中心分位数更具变异性，也更难准确估计。\n\n在 VPC 中，经验分位数的预测区间是通过从所提出的模型中模拟许多大小为 $n$ 的数据集（例如，$1000$ 次重复）并为每个数据集计算经验分位数来构建的。例如，$90\\%$ 的预测区间将是覆盖这些模拟分位数中心 $90\\%$ 的范围（例如，从模拟值的第 $5$ 百分位数到第 $95$ 百分位数）。\n\n如果 $n$ 很小，根据上述公式，这些模拟分位数的方差会很大。这导致一个非常宽的预测区间。从原始数据（在该区间中也只有 $n$ 个点）计算出的观测经验分位数只是从这个高方差分布中的一次抽样。一个宽的预测区间很有可能包含这个单一的观测值，其概率通常会超过名义覆盖概率（例如，$>90\\%$）。这种现象被称为“表观过度覆盖”。这并不表示模型特别好，而是表明诊断检验（VPC）由于与小 $n$ 相关的高统计噪声而检测模型错配的能力较低。\n\n**2. 最小样本量 $n$ 的推导**\n\n我们需要找到最小的 $n$，使得 $\\hat{q}_{0.1}$ 的 $95\\%$ 置信区间的半宽不超过 $r \\times B$。\n\n$\\hat{q}_p$ 的渐近分布是 $N(q_p, \\frac{p(1-p)}{n [f(q_p)]^2})$。\n$\\hat{q}_p$ 的标准误是 $\\text{SE}(\\hat{q}_p) = \\sqrt{\\text{Var}(\\hat{q}_p)} \\approx \\frac{\\sqrt{p(1-p)}}{\\sqrt{n} f(q_p)}$。\n\n$q_p$ 的一个 $(1-\\alpha) \\times 100\\%$ 置信区间由 $\\hat{q}_p \\pm z_{1-\\alpha/2} \\cdot \\text{SE}(\\hat{q}_p)$ 给出。\n此 CI 的半宽 ($H$) 是：\n$$ H = z_{1-\\alpha/2} \\frac{\\sqrt{p(1-p)}}{\\sqrt{n} f(q_p)} $$\n问题指定了 $95\\%$ 的 CI，因此 $\\alpha = 0.05$ 且 $z_{1-\\alpha/2} = z_{0.975} \\approx 1.960$。\n\n要求是 $H \\le r B$。代入 $H$ 的表达式：\n$$ z_{0.975} \\frac{\\sqrt{p(1-p)}}{\\sqrt{n} f(q_p)} \\le r B $$\n我们对这个不等式求解 $n$：\n$$ \\sqrt{n} \\ge \\frac{z_{0.975} \\sqrt{p(1-p)}}{r B f(q_p)} $$\n$$ n \\ge \\left( \\frac{z_{0.975} \\sqrt{p(1-p)}}{r B f(q_p)} \\right)^2 $$\n现在，我们代入给定的值：\n- $p = 0.1$，所以 $\\sqrt{p(1-p)} = \\sqrt{0.1 \\times 0.9} = \\sqrt{0.09} = 0.3$。\n- $z_{0.975} = 1.960$。\n- $r = 0.5$。\n- $B = 0.50$ mg/L。\n- $f(q_{0.1}) = 0.50$ (mg/L)$^{-1}$。\n\n将这些值代入公式：\n$$ n \\ge \\left( \\frac{1.960 \\times 0.3}{0.5 \\times 0.50 \\times 0.50} \\right)^2 $$\n$$ n \\ge \\left( \\frac{0.588}{0.125} \\right)^2 $$\n$$ n \\ge (4.704)^2 $$\n$$ n \\ge 22.127... $$\n由于样本量 $n$ 必须是整数，因此每个区间所需的最小观测数量为 $n=23$。\n\n**3. 经验法则标准**\n\n用于 $\\hat{q}_p$ 分布的正态近似是从二项分布的正态近似推导出来的。当分位数两侧的期望计数足够大时，这种近似通常被认为是有效的。一个常见的经验法则是，期望计数 $np$ 和 $n(1-p)$ 都应至少为 $5$，或者更保守地，为 $10$。\n\n使用更严格的 $10$ 的标准：\n$$ np \\ge 10 \\quad \\text{和} \\quad n(1-p) \\ge 10 $$\n这意味着：\n$$ n \\ge \\frac{10}{p} \\quad \\text{和} \\quad n \\ge \\frac{10}{1-p} $$\n所以，我们必须满足 $n \\ge \\max\\left\\{\\frac{10}{p}, \\frac{10}{1-p}\\right\\}$。\n对于 $10\\%$-分位数 ($p=0.1$)：\n$$ n \\ge \\max\\left\\{\\frac{10}{0.1}, \\frac{10}{1-0.1}\\right\\} = \\max\\{100, 11.11...\\} $$\n因此，这个经验法则建议最小样本量为 $n=100$，以确保第 $10$ 百分位数的正态近似的有效性。这是用于估计量有效性的一般性指南，与第 2 部分中基于精度的计算不同。\n\n**4. 基于自助法的替代方案**\n\n渐近公式需要知道分位数处的 PDF 值 $f(q_p)$，这在实践中很少是已知的。非参数自助法提供了一种实用的、数据驱动的替代方法来评估 $n$ 的充分性。对于一个有 $n$ 个观测值的给定区间：\n1.  通过从区间中的原始 $n$ 个数据点中有放回地重抽样 $n$ 个观测值，生成大量的自助样本（例如，$B_{boot} = 1000$）。\n2.  对于每个自助样本，计算经验 $p$-分位数 $\\hat{q}_p^*$。\n3.  这个过程产生一个包含 $B_{boot}$ 个自助分位数的分布，该分布近似于 $\\hat{q}_p$ 的抽样分布。\n4.  可以从这个分布构建 $q_p$ 的 $95\\%$ 置信区间，例如，通过取自助分位数分布的第 $2.5$ 和第 $97.5$ 百分位数（百分位法）。\n5.  然后可以计算此自助 CI 的半宽。\n6.  这个经验半宽可以直接与设计目标进行比较：自助 CI 半宽是否 $\\le rB$？如果是，则认为该区间中的样本量 $n$ 对于所期望的精度水平是足够的。\n\n### 选项分析\n\n**A. 小 $n$ 会夸大 $\\hat{q}_p$ 的抽样变异性...**\n这个选项正确地指出，小 $n$ 会增加 $\\hat{q}_p$ 的方差，并提到了 $1/f(q_p)$ 的作用。它正确地解释了这会导致更宽的模拟带和表观过度覆盖。它基于大样本近似给出了最小 $n$ 的正确公式。计算结果 $n \\ge 22.1$，得出最小值为 $n=23$，是正确的。经验法则的计算 $n \\ge \\max\\{10/0.1, 10/0.9\\} = 100$ 也是正确的。最后，它正确描述了如何使用非参数自助法根据 CI 宽度来验证 $n$ 的充分性。该选项与推导出的解决方案完全一致。\n**结论：正确。**\n\n**B. 小 $n$ 会减小 $\\hat{q}_p$ 的方差...**\n这个选项声称小 $n$ 会*减小*方差，这在根本上是错误的。任何标准统计估计量（包括样本分位数）的方差都会随着样本量的减小而增加。这个错误的前提使得整个选项无效。所提出的 $n \\ge 10$ 的标准是任意的，并且通常是不够的。\n**结论：错误。**\n\n**C. 表观过度覆盖主要由模型错配引起...**\n这个选项错误地归因了表观过度覆盖的原因。虽然模型错配是建模中的一个主要问题，但“表观过度覆盖”是由于稀疏数据导致的高抽样变异性所特有的一种现象，它可能掩盖模型错配。声称 $n$ 不会实质性地改变分位数方差，这直接与统计理论相矛盾。\n**结论：错误。**\n\n**D. 与 VPC 分位数带相关的变异性是平均浓度的方差...**\n这个选项错误地将样本分位数的方差等同于样本均值的方差 ($\\sigma^2/n$)。样本分位数的方差有不同的公式，该公式关键性地依赖于分位数处的 PDF，$f(q_p)$。忽略 $f(q_p)$ 并将用于均值的中心极限定理应用于一个关于分位数的问题，是一个重大的概念错误。\n**结论：错误。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "在确认了分箱样本量的重要性之后，下一个实际问题是如何选择最优的分箱策略。不同的分箱方法，如等宽分箱、等计数分箱或基于k-均值聚类的分箱，会对VPC结果的偏倚和方差产生不同影响。本练习旨在挑战您批判性地思考偏倚-方差权衡，并根据数据的具体分布特征（如自变量的偏态分布和响应变量的非平稳性）选择最合适的分箱方法 。这对于进行稳健的VPC分析是一项核心技能。",
            "id": "4601332",
            "problem": "在一个非线性混合效应药代动力学模型的视觉预测检验（VPC）中，您需要计算观测浓度在给定时间下的每分箱样本分位数，记为$Q_{p}(t)$（其中$p \\in \\{0.10, 0.50, 0.90\\}$），以便与模拟的预测区间进行比较。观测到的采样时间$t$呈强烈的右偏态：大约$80\\%$的观测值位于$t \\in [0,8]$小时的区间内，具有密集的早期采样和多个由方案驱动的时间点，而其余$20\\%$的观测值位于$t \\in (8,48]$小时的区间内，采样更稀疏、不均匀，且存在间断。给定时间$t$，浓度$C$的条件分布是连续的，其分位数函数$Q_{p}(t)$随$t$平滑递减，在$t$较小时下降更陡峭，在$t$较大时逐渐平缓。您必须选择一种对$t$的分箱策略，以计算VPC的每分箱分位数估计值，并使用$B_{\\text{boot}}$次自举重采样在每个分箱内生成非参数自举置信区间。\n\n考虑将$t$轴划分为$B$个分箱的三种方法：\n- 等宽分箱：将观测到的$t$的范围划分为$B$个等长度的区间。\n- 等数分箱：将排序后的$t$值划分为$B$个相邻的分箱，每个分箱包含相同数量的观测值$n_{b}$（由于取整最多相差1）。\n- 对$t$进行$k$-均值分箱：在标量$t$上使用欧几里得距离和$k=B$应用$k$-均值聚类，将每个观测值分配到一个簇，并将每个簇在$t$上的凸包作为一个分箱。\n\n假设使用箱内非参数自举重采样来量化每分箱样本分位数的不确定性，重采样大小等于原始的每分箱观测数$n_{b}$。仅利用分位数、混合分布的基本性质以及样本分位数的大样本行为，比较这三种分箱方法在每分箱分位数估计量的偏差和方差以及自举置信区间的稳定性方面的表现，同时考虑到给定的$t$和$Q_{p}(t)$的分布特性。哪种选择最适合此VPC，为什么？\n\n选择唯一的最佳选项。\n\nA. 等宽分箱最合适，因为每个分箱具有相等的时间跨度，这既保证了每分箱样本分位数的最小偏差，又保证了各分箱间的方差近似相等，从而即使在$t$呈右偏态的情况下也能得到宽度一致且窄的自举置信区间。\n\nB. 等数分箱最合适，因为它使每分箱的样本量$n_{b}$均等，从而稳定了每分箱分位数估计量的方差及其自举置信区间；在$t$呈右偏态且$Q_{p}(t)$在$t$较小时快速变化的情况下，等数分箱在早期会变得更窄（在曲率高的地方限制了偏差），在晚期会变得更宽（在曲率低的地方，保持偏差较小）。\n\nC. $k$-均值分箱最合适，因为它同时确保了$t$上的分箱宽度相等和每分箱的计数相等，从而同时最小化了每分箱分位数的偏差和方差，并使自举置信区间的宽度均等。\n\nD. $k$-均值分箱最合适，因为在$Q_{p}(t)$存在趋势的情况下，最小化$t$上的箱内平方距离直接最小化了每分箱样本分位数的偏差，因此无论$t$的偏度如何，都能在各分箱间产生一致的方差和自举置信区间宽度。",
            "solution": "目标是比较在视觉预测检验（VPC）中对$t$进行分箱的各种策略，依据是它们对每分箱分位数估计量的偏差和方差以及对自举置信区间稳定性的影响，前提是$t$的分布呈强右偏态，且分位数函数$Q_{p}(t)$是一个平滑但非平稳的函数，在$t$较小时变化迅速，在$t$较大时变化缓慢。\n\n我们从基本定义和经过充分检验的渐近结果出发：\n\n1. 每分箱分位数目标和由分箱引起的偏差的定义。对于一个索引为$b$的分箱，其中$t \\in I_{b}$，其箱内经验分布为$F_{t|b}$，箱内合并的数据是从条件混合分布中抽取的样本\n$$\nG_{b}(c) \\equiv \\int F_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t),\n$$\n其密度为\n$$\ng_{b}(c) \\equiv \\int f_{C|t}(c \\mid t)\\,\\mathrm{d}F_{t|b}(t).\n$$\n水平为$p$的每分箱样本分位数，记作$\\widehat{Q}_{p,b}$，是混合分位数$Q_{p,b}^{\\text{mix}}$的一致估计量，由$G_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)=p$定义。对于可视化而言，科学上相关的目标是作为$t$的函数的点态条件分位数$Q_{p}(t)$。因此，如果$Q_{p}(t)$在$I_{b}$内变化，分箱就会引入偏差，因为对于$I_{b}$中的一个通用点$t_{0}$，$Q_{p,b}^{\\text{mix}} \\neq Q_{p}(t_{0})$。对于小的分箱和平滑的$Q_{p}(t)$，一阶近似表明，偏差与$t$的箱内变异以及$Q_{p}(t)$的局部斜率或曲率成比例。因此，在$|Q_{p}'(t)|$或$|Q_{p}''(t)|$大的地方使用更窄的分箱可以减少偏差。\n\n2. 样本分位数的大样本方差。对于从一个连续分布中抽取的$n_{b}$个独立同分布的样本，若其密度$g_{b}$在其第$p$个分位数$Q_{p,b}^{\\text{mix}}$处为正，则样本分位数的渐近方差满足经典结果\n$$\n\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx \\frac{p(1-p)}{n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}}.\n$$\n因此，对于固定的$p$和在各分箱间相似的$g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)$，方差近似地与$1/n_{b}$成比例。因此，每分箱的样本量$n_{b}$是各分箱间方差异质性的主要驱动因素。每个分箱内的非参数自举方法有放回地重采样$n_{b}$个观测值，因此自举分布和置信区间的宽度主要反映了此方差；小的$n_{b}$会导致不稳定且宽的区间。\n\n3. $t$的箱内宽度（驱动偏差）与每分箱计数$n_{b}$（驱动方差）之间的权衡。在$Q_{p}(t)$变化迅速的地方（$t$较小），控制偏差倾向于使用窄分箱；在$Q_{p}(t)$变化缓慢的地方（$t$较大），可以容忍更宽的分箱而不会产生大的偏差。在$t$稀疏的地方（$t$较大），等宽分箱有$n_{b}$过小的风险，从而增大了方差并使自举不稳定。\n\n根据给定的情景：$t$呈强右偏态，早期采样密集（$t \\in [0,8]$），晚期采样稀疏（$t \\in (8,48]$）。分位数函数$Q_{p}(t)$在$t$较小时下降更陡峭，在$t$较大时趋于平缓。\n\n我们现在分析每种分箱方法。\n\n等宽分箱。等宽分箱为每个分箱施加相同的时间跨度。在密集的早期区域，每个分箱将包含许多观测值，因此$n_{b}$会很大，$\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$会很小，产生窄的自举区间。在稀疏的晚期区域，一些分箱的$n_{b}$会很小，从而增大了方差并加宽了自举区间，如果$n_{b}$对于极端分位数来说太小，甚至可能导致不稳定。在偏差方面，等宽分箱统一控制了最大的箱内时间跨度；然而，由于$Q_{p}(t)$在$t$较小时变化更快，对于固定的分箱宽度，该处的偏差仍然可能很显著，因为偏差是由$|Q_{p}'(t)|$和$|Q_{p}''(t)|$的大小驱动的。相比之下，在$t$较大且$Q_{p}(t)$较平坦处，等宽分箱产生的偏差较小。总体而言，由于$t$的右偏态，等宽分箱在各分箱间产生显著的方差异质性，导致晚期分位数和自举区间具有高方差和不稳定性。这违背了获得跨$t$稳定且可解释的VPC区间的目标。\n\n等数分箱。等数分箱强制$n_{b}$在各分箱间几乎恒定，通过$1/n_{b}$的比例关系直接稳定了$\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right)$，并导致自举区间的宽度在$t$上更一致。因为$t$在早期是密集的，所以等数分箱在该处的$t$宽度会很窄，这在$Q_{p}(t)$快速变化的地方减少了偏差。因为$t$在晚期是稀疏的，等数分箱会更宽，可能增加偏差；然而，在所述情景中$Q_{p}(t)$在$t$较大时趋于平缓，所以由更宽的晚期分箱带来的偏差惩罚被减轻了。净效应是：在重要的地方（$t$较小）减少了偏差，在曲率低的地方（$t$较大）控制了偏差，并在各分箱间稳定了方差和自举区间的宽度。\n\n对$t$进行$k$-均值分箱。在一维和欧几里得距离下，$k$-均值将$t$划分为连续的区间（沃罗诺伊单元），其质心在观测密集的区域更密集。这倾向于在密集的早期区域产生更窄的分箱，在稀疏的晚期区域产生更宽的分箱，这在质量上与等数分箱的偏差控制相似。然而，$k$-均值不强制每个分箱的计数$n_{b}$相等，也不直接考虑$Q_{p}(t)$或$f_{C|t}$。因此，每分箱的样本量仍然可能变化，尤其是在$t$中存在间断或簇的情况下，导致异质的方差和自举区间宽度。此外，$k$-均值最小化的是$t$的箱内平方距离，而不是直接最小化混合分位数的偏差；虽然减小$t$的箱内散布可以减少偏差，但当$Q_{p}(t)$的曲率和采样密度以不同方式变化时，相对于等数分箱，无法保证方差稳定或偏差最优。\n\n综合分析。基本的方差关系$\\mathrm{Var}\\!\\left(\\widehat{Q}_{p,b}\\right) \\approx p(1-p)/\\left(n_{b}\\,g_{b}\\!\\left(Q_{p,b}^{\\text{mix}}\\right)^{2}\\right)$突出了$n_{b}$是方差和自举区间宽度的关键驱动因素。等数分箱直接稳定了$n_{b}$，其在$t$上的自适应分箱宽度自然地匹配了在$Q_{p}(t)$变化快的地方需要窄分箱、在$Q_{p}(t)$平坦的地方需要宽分箱的需求。在偏态$t$下，等宽分箱未能稳定方差，而$k$-均值不保证$n_{b}$相等或自举稳定性一致。因此，对于给定的$t$分布和$Q_{p}(t)$行为，等数分箱最好地平衡了偏差和方差。\n\n逐项分析选项：\n\nA. 声称在右偏态$t$下，等宽分箱既能产生最小偏差，又能产生近似相等的各分箱方差。这与方差与$1/n_{b}$的比例关系相矛盾：等宽分箱在早期分箱产生大的$n_{b}$，在晚期分箱产生小的$n_{b}$，因此导致异质的方差和自举宽度。偏差并非一致最小，因为$Q_{p}(t)$在$t$较小时变化迅速；固定宽度可能在早期留下不可忽略的偏差。错误。\n\nB. 指出等数分箱稳定了$n_{b}$，因此稳定了方差和自举区间，并且更窄的早期分箱在$Q_{p}(t)$变化迅速的地方减少了偏差，而更宽的晚期分箱在曲率低的地方产生的偏差较小。这与渐近方差关系和混合分布的偏差考量一致。正确。\n\nC. 断言$k$-均值确保了分箱宽度和计数均等。在一维$k$-均值中，既不保证宽度相等，也不保证计数相等；计数和宽度会根据局部密度自适应，没有相等约束。因此所述理由是错误的。错误。\n\nD. 声称$k$-均值直接最小化了分位数偏差，并无论偏度如何都能产生一致的方差和自举宽度。$k$-均值最小化的是$t$的箱内平方偏差，而不是分位数偏差，并且不保证$n_{b}$相等或自举宽度一致，尤其是在有偏态$t$和间断的情况下。错误。\n\n因此，最合适的选择是等数分箱。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "最后的这项综合练习将前面探讨的理论概念和策略选择融入一个完整的实际工作流程中。您将执行一个在药理学上更具针对性的“部分VPC”（partial VPC），仅在与药物吸收或消除最相关的预定时间窗口内评估模型。此任务要求您模拟具有个体间和残差变异的药代动力学曲线，计算预测区间，并应用非参数自助法（bootstrap）来评估最终结果的稳健性 。这项练习为您提供了从模型模拟到统计评估的全面动手体验。",
            "id": "4601305",
            "problem": "考虑一个单剂量口服药代动力学情景，该情景基于具有一级吸收和一级消除的一室模型。在时间 $t = 0$ 时给予剂量 $D$ 的结构浓度-时间函数由一个经过充分检验的公式给出，该公式源自一级吸收一室模型的质量平衡和线性处置：\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right),  K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t},  K_a = k,\n\\end{cases}\n$$\n其中，$K_a$ 是一级吸收速率常数，单位为 $\\mathrm{h}^{-1}$；$CL$ 是清除率，单位为 $\\mathrm{L}\\,\\mathrm{h}^{-1}$；$V$ 是分布容积，单位为 $\\mathrm{L}$；$k = CL / V$ 是消除速率常数，单位为 $\\mathrm{h}^{-1}$。吸收半衰期为 $t_{1/2,a} = \\ln(2)/K_a$，消除半衰期为 $t_{1/2,e} = \\ln(2)/k$。在 $K_a \\neq k$ 条件下，达到最大浓度的时间为\n$$\nt_{\\max} = \\frac{\\ln(K_a/k)}{K_a - k}.\n$$\n\n视觉预测检验 (Visual Predictive Check, VPC) 是一种基于模拟的诊断方法，其过程为在一个模型下生成多个模拟数据集，并将观测数据与模拟的分位数或预测区间进行比较。此处，通过将评估限制在药理学上预定义的早期和晚期时间窗内，以避免择优挑选数据，从而进行部分VPC。这些时间窗根据机理依据定义如下：\n- 早期时间窗：$[0, n_a \\cdot t_{1/2,a}]$，其中 $n_a$ 是一个正常量。\n- 晚期时间窗：$[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$，其中 $n_e$ 是一个正常量。\n\n为了考虑变异性，使用对数正态模型为参数 $K_a$、$CL$ 和 $V$ 应用个体间变异，即 $K_a^{(i)} = K_a \\exp(\\eta_{K_a}^{(i)})$，$CL^{(i)} = CL \\exp(\\eta_{CL}^{(i)})$ 和 $V^{(i)} = V \\exp(\\eta_{V}^{(i)})$，其中 $\\eta$ 项从均值为 $0$、标准差为指定的 $\\omega_{K_a}$、$\\omega_{CL}$ 和 $\\omega_V$ 的正态分布中抽样。残差未解释变异使用混合误差模型进行建模，使得模拟观测值 $\\tilde{C}(t)$ 为\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\n其中 $\\epsilon_{\\mathrm{prop}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{prop}})$ 和 $\\epsilon_{\\mathrm{add}} \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{add}})$ 相互独立。\n\n对于名义覆盖率为 $1 - \\alpha$（例如，当 $\\alpha = 0.10$ 时为 $0.90$）的双侧预测区间，令 $q_{\\mathrm{low}}$ 和 $q_{\\mathrm{high}}$ 为定义的时间窗内所有重复模拟的浓度汇集后的下分位数限和上分位数限。观测浓度使用群体参数（即无个体间变异）加上述残差误差生成一次。覆盖率比例计算为位于 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 区间内的窗口化观测浓度的比例。为了量化观测覆盖率的不确定性，采用非参数自举法对窗口化观测浓度进行 $B$ 次有放回重抽样；每个自举样本都会产生一个覆盖率比例，从而形成一个自举分布，并从此分布中取 $0.025$ 和 $0.975$ 分位数得到双侧区间。如果名义目标 $1 - \\alpha$ 位于此自举区间内，则认为该测试用例通过。如果时间窗内不包含任何观测时间点，则返回哨兵覆盖值 $-1.0$ 和通过指示符 $0$。\n\n请实现一个程序，为每个指定的测试用例执行上述部分VPC和自举程序。所有时间单位均为 $\\mathrm{h}$，浓度单位均为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$。程序必须使用固定的随机种子以保证可复现性。使用包含边界的时间窗。\n\n测试套件（每个用例提供参数并指定评估早期还是晚期时间窗）：\n- 用例 1（早期时间窗，理想路径）：\n  - $D = 100$ $\\mathrm{mg}$, $K_a = 1.0$ $\\mathrm{h}^{-1}$, $CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V = 50.0$ $\\mathrm{L}$。\n  - 观测时间 $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$。\n  - $n_a = 3.0$, $n_e = 1.0$, 时间窗类型 早期。\n  - 个体间变异标准差 $\\omega_{K_a} = 0.2$, $\\omega_{CL} = 0.2$, $\\omega_V = 0.2$。\n  - 残差误差 $\\sigma_{\\mathrm{prop}} = 0.2$, $\\sigma_{\\mathrm{add}} = 0.05$ $\\mathrm{mg}\\,\\mathrm{L}^{-1}$。\n  - 模拟重复次数 $N_{\\mathrm{sim}} = 1000$, 自举重抽样次数 $B = 400$, $\\alpha = 0.10$。\n\n- 用例 2（晚期时间窗，理想路径）：\n  - 与用例1相同，时间窗类型 晚期，$n_e = 1.0$。\n\n- 用例 3（晚期时间窗，无窗口化观测的边界情况）：\n  - 与用例1相同，时间窗类型 晚期，$n_e = 100.0$。\n\n- 用例 4（早期时间窗，包含边界条件）：\n  - $D = 100$ $\\mathrm{mg}$, $K_a = \\ln(2)$ $\\mathrm{h}^{-1}$, $CL = 5.0$ $\\mathrm{L}\\,\\mathrm{h}^{-1}$, $V = 50.0$ $\\mathrm{L}$。\n  - 观测时间 $\\{0.25, 0.5, 1, 2, 4, 6, 8, 12, 24\\}$ $\\mathrm{h}$。\n  - $n_a = 2.0$, $n_e = 1.0$, 时间窗类型 早期。\n  - 个体间变异和残差误差与用例1相同。\n  - $N_{\\mathrm{sim}} = 1000$, $B = 400$, $\\alpha = 0.10$。\n  - 注意：$n_a \\cdot t_{1/2,a} = 2.0$ $\\mathrm{h}$，因此必须包含边界时间 $t = 2.0$ $\\mathrm{h}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序如下：\n$[$coverage$_1$,pass$_1$,coverage$_2$,pass$_2$,coverage$_3$,pass$_3$,coverage$_4$,pass$_4]$,\n其中 coverage 是 $\\left[0,1\\right]$ 范围内的浮点数（如果无窗口化观测，则为 $-1.0$），pass 是 $\\{0,1\\}$ 中的整数。",
            "solution": "该问题要求实现一个临床药理学中常见的模拟与分析工作流，具体来说是带有自举分析的部分视觉预测检验 (VPC)，用以评估模型预测性能的不确定性。该解决方案通过将所述的药代动力学模型、统计程序和评估标准进行算法化形式化来设计。\n\n问题的核心在于一个具有一级吸收和一级消除的一室药代动力学模型。口服剂量 $D$ 后，药物在时间 $t$ 的浓度 $C(t)$ 由Bateman函数描述：\n$$\nC(t) = \\begin{cases}\n\\frac{D K_a}{V (K_a - k)} \\left( e^{-k t} - e^{-K_a t} \\right),  K_a \\neq k, \\\\\n\\frac{D}{V} K_a t e^{-k t},  K_a = k,\n\\end{cases}\n$$\n其中 $K_a$ 是吸收速率常数，$V$ 是分布容积，$k = CL / V$ 是由清除率 $CL$ 导出的消除速率常数。为了数值稳定性，当 $K_a = k$ 的情况被分开处理，它代表了第一个表达式在 $K_a \\to k$ 时的数学极限。此函数是所有浓度预测的基础。\n\n该分析在特定的时间窗内评估模型，这些时间窗是根据机理定义的，用以区分药物处置的吸收和消除阶段。\n- 早期时间窗，侧重于吸收，定义为 $[0, n_a \\cdot t_{1/2,a}]$，其中 $t_{1/2,a} = \\ln(2)/K_a$ 是吸收半衰期。\n- 晚期时间窗，侧重于消除，定义为 $[t_{\\max} + n_e \\cdot t_{1/2,e}, \\infty)$，其中 $t_{1/2,e} = \\ln(2)/k$ 是消除半衰期，$t_{\\max}$ 是达到最大浓度的时间。$t_{\\max}$ 计算如下：\n$$\nt_{\\max} = \\begin{cases}\n\\frac{\\ln(K_a/k)}{K_a - k},  K_a \\neq k, \\\\\n\\frac{1}{k},  K_a = k.\n\\end{cases}\n$$\n对这些计算使用群体参数可确保给定模型的窗口定义一致。所有指定的观测时间点都经过筛选，仅保留那些落在给定测试用例计算出的窗口的包含性边界内的时间点。如果没有时间点落在窗口内，则该用例的分析将终止，并返回哨兵值。\n\n模拟过程引入了变异性以反映真实世界的群体。个体间变异 (IIV) 通过假设个体特定参数围绕群体典型值呈对数正态分布来进行建模。对于一个通用参数 $P$，个体的参数 $P^{(i)}$ 被模拟为 $P^{(i)} = P \\exp(\\eta_P^{(i)})$，其中 $\\eta_P^{(i)}$ 是从正态分布 $\\mathcal{N}(0, \\omega_P^2)$ 中抽样的随机偏差，$\\omega_P$ 是该参数IIV的指定标准差。这适用于 $K_a$、$CL$ 和 $V$。\n\n残差未解释变异 (RUV) 用于解释测量误差和模型设定错误。使用了一个混合的比例和加性误差模型。模拟观测值 $\\tilde{C}(t)$ 是从真实模型预测浓度 $C(t)$ 通过以下方式生成的：\n$$\n\\tilde{C}(t) = C(t)\\left(1 + \\epsilon_{\\mathrm{prop}}\\right) + \\epsilon_{\\mathrm{add}},\n$$\n其中 $\\epsilon_{\\mathrm{prop}}$ 和 $\\epsilon_{\\mathrm{add}}$ 分别从正态分布 $\\mathcal{N}(0, \\sigma_{\\mathrm{prop}}^2)$ 和 $\\mathcal{N}(0, \\sigma_{\\mathrm{add}}^2)$ 中独立抽样。\n\nVPC的核心是创建预测区间 (PI)。这是通过生成 $N_{\\mathrm{sim}}$ 组个体药代动力学特征来实现的。对于每个模拟个体 $i=1, \\dots, N_{\\mathrm{sim}}$，我们首先抽样其个体参数 $K_a^{(i)}, CL^{(i)}, V^{(i)}$，然后计算他们在所有窗口化时间点上的浓度曲线 $C^{(i)}(t)$。然后将RUV加到这些预测中，以产生模拟观测值 $\\tilde{C}^{(i)}(t)$。窗口内所有个体和所有时间点的所有模拟观测值被汇集到一个大的数据集中。PI的下界和上界，$q_{\\mathrm{low}}$ 和 $q_{\\mathrm{high}}$，通过计算这个汇集分布的 $\\alpha/2$ 和 $1 - \\alpha/2$ 分位数来确定，从而得到一个名义覆盖率为 $1 - \\alpha$ 的PI。\n\n为了评估模型，会生成一个单一的“观测”数据集。这是通过使用群体典型参数（即无IIV）计算浓度曲线，并在每个窗口化时间点上添加一次RUV的实现来完成的。主要指标，即覆盖率比例，是这些观测数据点落在PI内，即区间 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 内的比例。\n\n为了量化这个观测覆盖率比例的统计不确定性，采用了一种非参数自举程序。窗口内的观测浓度集进行 $B$ 次有放回重抽样，创建 $B$ 个自举样本，每个样本的大小与原始窗口化观测集相同。对于每个自举样本，使用原始固定的PI $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 重新计算覆盖率比例。这个过程会生成一个包含 $B$ 个覆盖率比例的分布。然后通过从此自举分布中取 $0.025$ 和 $0.975$ 分位数来构建覆盖率比例的 $95\\%$ 置信区间。\n\n最后，如果目标名义覆盖率 $1 - \\alpha$ 位于这个 $95\\%$ 自举置信区间内，则认为一个测试用例“通过”。这表明观测到的覆盖率与预期覆盖率在统计上是一致的。整个过程被封装在一个程序中，该程序遍历每个测试用例，报告计算出的覆盖率比例和二进制的通过/失败指示符。固定的随机种子确保了模拟和分析中所有随机元素的可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef _concentration(t, D, Ka, V, k):\n    \"\"\"Calculates concentration using the one-compartment oral absorption model.\"\"\"\n    if V == 0:\n        return np.inf\n    \n    # Use the appropriate formula based on whether Ka is close to k\n    # to maintain numerical stability.\n    if abs(Ka - k)  1e-9:\n        concentration = (D / V) * Ka * t * np.exp(-k * t)\n    else:\n        # Pre-calculate common terms for efficiency.\n        factor = D * Ka / (V * (Ka - k))\n        concentration = factor * (np.exp(-k * t) - np.exp(-Ka * t))\n    \n    return concentration\n\ndef _tmax(Ka, k):\n    \"\"\"Calculates time to maximum concentration.\"\"\"\n    if abs(Ka - k)  1e-9:\n        return 1.0 / k if k > 0 else 0.0\n    if Ka = 0 or k = 0:\n        return 0.0\n    return np.log(Ka / k) / (Ka - k)\n\ndef solve():\n    \"\"\"\n    Main function to run the VPC simulation and bootstrap analysis for all test cases.\n    \"\"\"\n    # Fixed random seed for reproducibility as required.\n    SEED = 0\n    rng = np.random.default_rng(SEED)\n\n    # Test suite definition as per the problem statement.\n    test_cases = [\n        # Case 1 (early window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 2 (late window, happy path)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 1.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 3 (late window, edge case with no windowed observations)\n        {'D': 100.0, 'Ka_pop': 1.0, 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 3.0, 'ne': 100.0, 'window_type': 'late',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n        # Case 4 (early window, boundary condition inclusion)\n        {'D': 100.0, 'Ka_pop': np.log(2), 'CL_pop': 5.0, 'V_pop': 50.0,\n         'obs_times': np.array([0.25, 0.5, 1, 2, 4, 6, 8, 12, 24]),\n         'na': 2.0, 'ne': 1.0, 'window_type': 'early',\n         'omega_Ka': 0.2, 'omega_CL': 0.2, 'omega_V': 0.2,\n         'sigma_prop': 0.2, 'sigma_add': 0.05,\n         'N_sim': 1000, 'B': 400, 'alpha': 0.10},\n    ]\n\n    final_results = []\n\n    for case in test_cases:\n        # Unpack parameters for the current test case\n        k_pop = case['CL_pop'] / case['V_pop']\n        \n        # Calculate window boundaries based on population parameters\n        if case['window_type'] == 'early':\n            t_half_a = np.log(2) / case['Ka_pop'] if case['Ka_pop'] > 0 else 0\n            window_start, window_end = 0.0, case['na'] * t_half_a\n        else: # 'late'\n            tmax = _tmax(case['Ka_pop'], k_pop)\n            t_half_e = np.log(2) / k_pop if k_pop > 0 else np.inf\n            window_start, window_end = tmax + case['ne'] * t_half_e, np.inf\n\n        # Filter observation times to include only those within the window\n        obs_times_windowed = case['obs_times'][(case['obs_times'] >= window_start)  (case['obs_times'] = window_end)]\n\n        # Handle the case where no observations are in the window\n        if len(obs_times_windowed) == 0:\n            final_results.extend([-1.0, 0])\n            continue\n            \n        # Generate \"observed\" data: population pred + residual error\n        c_pop_windowed = _concentration(obs_times_windowed, case['D'], case['Ka_pop'], case['V_pop'], k_pop)\n        eps_prop_obs = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n        eps_add_obs = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n        c_obs_windowed = c_pop_windowed * (1 + eps_prop_obs) + eps_add_obs\n        c_obs_windowed = np.maximum(0, c_obs_windowed) # Concentrations cannot be negative\n\n        # Perform simulation for Prediction Interval (PI)\n        simulated_concentrations = []\n        for _ in range(case['N_sim']):\n            # Sample inter-individual variability (IIV)\n            eta_Ka, eta_CL, eta_V = rng.normal(0, [case['omega_Ka'], case['omega_CL'], case['omega_V']])\n            Ka_ind = case['Ka_pop'] * np.exp(eta_Ka)\n            CL_ind = case['CL_pop'] * np.exp(eta_CL)\n            V_ind = case['V_pop'] * np.exp(eta_V)\n            k_ind = CL_ind / V_ind if V_ind > 0 else np.inf\n            \n            # Calculate individual concentration predictions\n            c_ind_pred = _concentration(obs_times_windowed, case['D'], Ka_ind, V_ind, k_ind)\n            \n            # Add residual unexplained variability (RUV)\n            eps_prop = rng.normal(0, case['sigma_prop'], size=len(obs_times_windowed))\n            eps_add = rng.normal(0, case['sigma_add'], size=len(obs_times_windowed))\n            c_ind_sim = c_ind_pred * (1 + eps_prop) + eps_add\n            \n            simulated_concentrations.extend(np.maximum(0, c_ind_sim))\n\n        # Calculate Prediction Interval from pooled simulated data\n        q_low, q_high = np.quantile(simulated_concentrations, [case['alpha']/2, 1 - case['alpha']/2])\n        \n        # Calculate observed coverage\n        in_interval = (c_obs_windowed >= q_low)  (c_obs_windowed = q_high)\n        observed_coverage = np.mean(in_interval)\n        \n        # Perform non-parametric bootstrap to find CI of coverage\n        n_obs_windowed = len(c_obs_windowed)\n        bootstrap_coverages = []\n        for _ in range(case['B']):\n            bootstrap_sample = rng.choice(c_obs_windowed, size=n_obs_windowed, replace=True)\n            bootstrap_coverage = np.mean((bootstrap_sample >= q_low)  (bootstrap_sample = q_high))\n            bootstrap_coverages.append(bootstrap_coverage)\n            \n        ci_low, ci_high = np.quantile(bootstrap_coverages, [0.025, 0.975])\n        \n        # Determine pass/fail status\n        target_coverage = 1 - case['alpha']\n        is_pass = 1 if ci_low = target_coverage = ci_high else 0\n        \n        final_results.extend([observed_coverage, is_pass])\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(f'{x:.6f}' if isinstance(x, float) else str(x) for x in final_results)}]\")\n\nsolve()\n```"
        }
    ]
}