{
    "hands_on_practices": [
        {
            "introduction": "A common challenge in planning a clinical trial is the uncertainty around nuisance parameters like outcome variance, which can lead to an underpowered study. Blinded sample size re-estimation (SSR) is a powerful adaptive technique that allows for adjusting the sample size based on an interim variance estimate without compromising trial integrity. This practice problem guides you through the SSR calculation from first principles, connecting the foundational concepts of statistical power to a practical strategy for improving trial efficiency .",
            "id": "4772912",
            "problem": "A two-arm, equal-allocation, parallel-group superiority trial with a continuous primary endpoint is planned using a normal-theory framework justified by the Central Limit Theorem (CLT). Let the individual outcomes be independently and identically distributed with variance $\\sigma^{2}$ in each arm, and suppose the treatment effect is defined as a mean difference $\\delta = \\mu_{1} - \\mu_{2}$. The test is one-sided at type I error $\\alpha = 0.025$ and targets power $1 - \\beta = 0.9$ to detect $\\delta = 0.3$. The initial planning assumed $\\sigma^{2} = 1$. The design uses blinded sample size re-estimation based on the information function at an interim information time $t = 0.5$, where the pooled blinded variance estimate is $\\hat{\\sigma}^{2} = 1.44$.\n\nStarting from first principles—namely, the sampling distribution of the difference in sample means under the null and alternative hypotheses, the definition of type I error and power, and the behavior of the one-sided $z$-test—derive the continuous target for the total re-estimated sample size across both arms, $N_{\\text{new}}$, when the blinded interim estimate $\\hat{\\sigma}^{2}$ replaces the planning value $\\sigma^{2}$. Assume equal allocation, no other adaptations, and preservation of the originally planned critical value. Ignore integer constraints; report the real-valued $N_{\\text{new}}$ rounded to four significant figures.",
            "solution": "The problem requires the derivation of the re-estimated total sample size, $N_{\\text{new}}$, for a two-arm superiority clinical trial, based on an interim blinded variance estimate. We will begin from first principles, namely the statistical framework of the two-sample $z$-test for means.\n\nLet $X_{1j}$ and $X_{2j}$ be the continuous outcomes for the $j$-th subject in the treatment arm (arm $1$) and control arm (arm $2$), respectively. The outcomes are assumed to be independent and (approximately) normally distributed, $X_{ij} \\sim N(\\mu_i, \\sigma^2)$ for $i \\in \\{1, 2\\}$, with a common variance $\\sigma^2$. This is justified by the Central Limit Theorem. The treatment effect is the difference in means, $\\delta = \\mu_1 - \\mu_2$.\n\nThe trial uses equal allocation, so the sample sizes in each arm are $n_1 = n_2 = N/2$, where $N$ is the total sample size. The estimator for the treatment effect is the difference in sample means, $\\hat{\\delta} = \\bar{X}_1 - \\bar{X}_2$.\n\nThe sampling distribution of $\\hat{\\delta}$ is normal with mean $E[\\hat{\\delta}] = \\mu_1 - \\mu_2 = \\delta$ and variance $\\text{Var}(\\hat{\\delta}) = \\text{Var}(\\bar{X}_1) + \\text{Var}(\\bar{X}_2) = \\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2} = \\frac{\\sigma^2}{N/2} + \\frac{\\sigma^2}{N/2} = \\frac{4\\sigma^2}{N}$. Thus, $\\hat{\\delta} \\sim N(\\delta, \\frac{4\\sigma^2}{N})$.\n\nThe trial is designed to test the one-sided null hypothesis $H_0: \\delta \\le 0$ against the alternative $H_1: \\delta > 0$. For constructing the test, we consider the boundary case $H_0: \\delta = 0$. The standardized test statistic is:\n$$ Z = \\frac{\\hat{\\delta} - 0}{\\sqrt{\\text{Var}(\\hat{\\delta})}} = \\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{4\\sigma^2/N}} $$\nUnder $H_0$, $Z$ follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nThe one-sided type I error rate is specified as $\\alpha = 0.025$. The null hypothesis is rejected if the test statistic $Z$ exceeds a critical value, $c$. This critical value is determined by $P(Z > c | H_0) = \\alpha$. For a standard normal variable, this implies $c = z_{1-\\alpha}$, the $(1-\\alpha)$-quantile of the standard normal distribution. Given $\\alpha = 0.025$, the critical value is $c = z_{1-0.025} = z_{0.975}$.\n\nPower is the probability of correctly rejecting $H_0$ when a specific alternative hypothesis is true. The trial is powered to detect a treatment effect $\\delta_A = 0.3$ with power $1 - \\beta = 0.9$.\n$$ 1 - \\beta = P\\left(Z > z_{1-\\alpha} \\mid \\delta = \\delta_A\\right) $$\nSubstituting the definition of $Z$:\n$$ 1 - \\beta = P\\left(\\frac{\\bar{X}_1 - \\bar{X}_2}{\\sqrt{4\\sigma^2/N}} > z_{1-\\alpha} \\mid \\delta = \\delta_A\\right) $$\nTo evaluate this probability under the alternative hypothesis (where $E[\\bar{X}_1 - \\bar{X}_2] = \\delta_A$), we standardize the expression differently:\n$$ 1 - \\beta = P\\left(\\frac{(\\bar{X}_1 - \\bar{X}_2) - \\delta_A}{\\sqrt{4\\sigma^2/N}} > z_{1-\\alpha} - \\frac{\\delta_A}{\\sqrt{4\\sigma^2/N}}\\right) $$\nThe expression on the left inside the probability is a standard normal variable. Let $Z' \\sim N(0,1)$. Then:\n$$ P\\left(Z' > z_{1-\\alpha} - \\frac{\\delta_A \\sqrt{N}}{2\\sigma}\\right) = 1 - \\beta $$\nThis implies that the argument of the probability must be the $\\beta$-quantile of the standard normal distribution, $z_{\\beta}$, which is equal to $-z_{1-\\beta}$.\n$$ z_{1-\\alpha} - \\frac{\\delta_A \\sqrt{N}}{2\\sigma} = -z_{1-\\beta} $$\nSolving for the total sample size $N$ gives the general formula:\n$$ z_{1-\\alpha} + z_{1-\\beta} = \\frac{\\delta_A \\sqrt{N}}{2\\sigma} $$\n$$ \\sqrt{N} = \\frac{2\\sigma (z_{1-\\alpha} + z_{1-\\beta})}{\\delta_A} $$\n$$ N = \\frac{4\\sigma^2 (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta_A^2} $$\nThe problem describes a blinded sample size re-estimation procedure. This involves using an interim estimate of the variance, $\\hat{\\sigma}^2 = 1.44$, to recalculate the required sample size to achieve the target power. The re-estimation preserves the originally planned critical value ($z_{1-\\alpha}$), the target power ($1-\\beta$), and the effect size of interest ($\\delta_A$). Therefore, we can use the derived sample size formula, replacing the planning variance $\\sigma^2 = 1$ with the interim estimate $\\hat{\\sigma}^2 = 1.44$. All other parameters remain the same.\n\nThe re-estimated total sample size, $N_{\\text{new}}$, is given by:\n$$ N_{\\text{new}} = \\frac{4\\hat{\\sigma}^2 (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta_A^2} $$\nWe substitute the given values:\n$\\hat{\\sigma}^2 = 1.44$\n$\\delta_A = 0.3$\n$\\alpha = 0.025 \\implies z_{1-\\alpha} = z_{0.975}$\n$1-\\beta = 0.9 \\implies z_{1-\\beta} = z_{0.9}$\n\nThe required quantiles from the standard normal distribution are $z_{0.975} \\approx 1.959964$ and $z_{0.9} \\approx 1.281552$.\nPlugging these into the equation for $N_{\\text{new}}$:\n$$ N_{\\text{new}} = \\frac{4(1.44) (z_{0.975} + z_{0.9})^2}{(0.3)^2} $$\n$$ N_{\\text{new}} = \\frac{5.76}{0.09} (1.959964 + 1.281552)^2 $$\n$$ N_{\\text{new}} = 64 \\times (3.241516)^2 $$\n$$ N_{\\text{new}} = 64 \\times 10.507427... $$\n$$ N_{\\text{new}} = 672.4753... $$\nThe problem requires the result to be rounded to four significant figures.\n$$ N_{\\text{new}} \\approx 672.5 $$\nThis value represents the continuous target for the total sample size across both arms needed to achieve $90\\%$ power under the observed interim variance.",
            "answer": "$$\n\\boxed{672.5}\n$$"
        },
        {
            "introduction": "In early-phase clinical trials, identifying a safe and effective dose is paramount. The Continual Reassessment Method (CRM) is a sophisticated Bayesian adaptive design that uses accumulating data to dynamically guide dose selection. This hands-on practice walks you through a full cycle of the CRM, from setting up the model to using patient outcomes to make a principled recommendation for the next dose, showcasing Bayesian updating in action .",
            "id": "4519450",
            "problem": "A Phase I dose-finding study of a cytotoxic agent is conducted under the Continual Reassessment Method (CRM). The clinical goal is to identify the dose whose true probability of dose-limiting toxicity (DLT) is closest to the target toxicity level $p_{T}$. In this design, one assumes a parametric, monotone model for the DLT probability across ordered dose levels, together with a prior on the model parameter, and updates the posterior as cohort outcomes accrue to recommend the next dose. \n\nUsing fundamental Bayesian principles (Bayes' theorem with a Bernoulli likelihood) and a one-parameter monotone dose-toxicity model, address the following:\n\n1. Define the CRM with target toxicity level $p_{T} = 0.25$, a skeleton of prior DLT probabilities $q_{d}$ across $D=4$ ordered dose levels $d \\in \\{1,2,3,4\\}$ given by $(q_{1}, q_{2}, q_{3}, q_{4}) = (0.08, 0.14, 0.25, 0.40)$, and the one-parameter logistic shift model \n$$\\text{logit}\\left(p_{d}(\\theta)\\right) = \\text{logit}(q_{d}) + \\theta,$$\nwhere $\\theta$ is an unknown scalar parameter and $\\text{logit}(u) = \\ln\\!\\left(\\frac{u}{1-u}\\right)$.\n\n2. Specify a zero-mean Gaussian prior $\\theta \\sim \\mathcal{N}(0, 1)$.\n\n3. Suppose five patients have been treated with observed pairs $(x_{i}, y_{i})$ for $i \\in \\{1,2,3,4,5\\}$, where $x_{i} \\in \\{1,2,3,4\\}$ is the administered dose level and $y_{i} \\in \\{0,1\\}$ indicates DLT ($1$) or no DLT ($0$). The observed outcomes are:\n$$(x_{1}, y_{1}) = (1, 0), \\quad (x_{2}, y_{2}) = (2, 0), \\quad (x_{3}, y_{3}) = (2, 0), \\quad (x_{4}, y_{4}) = (3, 1), \\quad (x_{5}, y_{5}) = (3, 0).$$\n\nAssuming conditional independence of outcomes given $\\theta$, use Bayesian updating to obtain the maximum a posteriori (MAP) estimate $\\hat{\\theta}$ by maximizing the log-posterior. Then, compute the plug-in estimates $\\hat{p}_{d} = p_{d}(\\hat{\\theta})$ for $d \\in \\{1,2,3,4\\}$ and recommend the next dose level as the index $d^{\\star}$ that minimizes $|\\,\\hat{p}_{d} - p_{T}\\,|$.\n\nReport the recommended next dose level index $d^{\\star}$ as the final answer. No rounding instruction is necessary because the answer is an integer and has no physical units.",
            "solution": "The problem requires us to determine the recommended next dose level in a Phase I clinical trial using the Continual Reassessment Method (CRM). This involves performing a Bayesian analysis to update the probabilities of dose-limiting toxicity (DLT) based on observed patient outcomes. The final recommendation is based on finding the dose whose updated DLT probability is closest to the target toxicity level.\n\nFirst, we establish the Bayesian framework. The posterior probability of the model parameter $\\theta$, given the observed data $D_N = \\{(x_i, y_i)\\}_{i=1}^{5}$, is given by Bayes' theorem:\n$$P(\\theta | D_N) \\propto L(D_N | \\theta) P(\\theta)$$\nwhere $L(D_N | \\theta)$ is the likelihood of the data given $\\theta$, and $P(\\theta)$ is the prior distribution of $\\theta$. We are tasked with finding the maximum a posteriori (MAP) estimate $\\hat{\\theta}$, which maximizes this posterior probability. Maximizing the posterior is equivalent to maximizing its logarithm, the log-posterior $\\mathcal{L}(\\theta)$.\n$$\\mathcal{L}(\\theta) = \\ln(L(D_N | \\theta)) + \\ln(P(\\theta))$$\n\nThe dose-toxicity model is given by the one-parameter logistic shift model:\n$$\\text{logit}(p_d(\\theta)) = \\text{logit}(q_d) + \\theta$$\nwhere $p_d(\\theta)$ is the probability of DLT at dose level $d$, $q_d$ is the prior DLT probability at dose $d$ (the skeleton), and $\\text{logit}(u) = \\ln\\left(\\frac{u}{1-u}\\right)$. This can be rearranged to express $p_d(\\theta)$ explicitly:\n$$p_d(\\theta) = \\frac{\\exp(\\text{logit}(q_d) + \\theta)}{1 + \\exp(\\text{logit}(q_d) + \\theta)}$$\nLet $a_d = \\text{logit}(q_d)$. The model is $p_d(\\theta) = \\frac{\\exp(a_d + \\theta)}{1 + \\exp(a_d + \\theta)}$.\n\nThe observed data consists of five patient outcomes: $(x_1, y_1) = (1, 0)$, $(x_2, y_2) = (2, 0)$, $(x_3, y_3) = (2, 0)$, $(x_4, y_4) = (3, 1)$, and $(x_5, y_5) = (3, 0)$. Here, $y_i=1$ indicates a DLT and $y_i=0$ indicates no DLT.\nAssuming the outcomes are conditionally independent given $\\theta$, the likelihood function is the product of Bernoulli probabilities:\n$$L(D_N | \\theta) = \\prod_{i=1}^{5} [p_{x_i}(\\theta)]^{y_i} [1 - p_{x_i}(\\theta)]^{1-y_i}$$\nGrouping the outcomes by dose level:\n- Dose $d=1$: $1$ patient, $0$ DLTs.\n- Dose $d=2$: $2$ patients, $0$ DLTs.\n- Dose $d=3$: $2$ patients, $1$ DLT.\nThe likelihood function becomes:\n$$L(D_N | \\theta) = [p_1(\\theta)]^0 [1-p_1(\\theta)]^1 \\cdot [p_2(\\theta)]^0 [1-p_2(\\theta)]^2 \\cdot [p_3(\\theta)]^1 [1-p_3(\\theta)]^1$$\n$$L(D_N | \\theta) = (1-p_1(\\theta)) \\cdot (1-p_2(\\theta))^2 \\cdot p_3(\\theta)(1-p_3(\\theta))$$\nThe log-likelihood $\\ell(\\theta) = \\ln(L(D_N | \\theta))$ is:\n$$\\ell(\\theta) = \\ln(1-p_1(\\theta)) + 2\\ln(1-p_2(\\theta)) + \\ln(p_3(\\theta)) + \\ln(1-p_3(\\theta))$$\nUsing the relations $\\ln(p_d(\\theta)) = a_d+\\theta - \\ln(1+\\exp(a_d+\\theta))$ and $\\ln(1-p_d(\\theta)) = -\\ln(1+\\exp(a_d+\\theta))$, we get:\n$$\\ell(\\theta) = [-\\ln(1+\\exp(a_1+\\theta))] + 2[-\\ln(1+\\exp(a_2+\\theta))] + [a_3+\\theta - \\ln(1+\\exp(a_3+\\theta))] + [-\\ln(1+\\exp(a_3+\\theta))]$$\n$$\\ell(\\theta) = a_3 + \\theta - \\ln(1+\\exp(a_1+\\theta)) - 2\\ln(1+\\exp(a_2+\\theta)) - 2\\ln(1+\\exp(a_3+\\theta))$$\n\nThe prior for $\\theta$ is a standard normal distribution, $\\theta \\sim \\mathcal{N}(0, 1)$, with probability density function $P(\\theta) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-\\frac{\\theta^2}{2})$. The log-prior is:\n$$\\ln(P(\\theta)) = -\\frac{\\theta^2}{2} - \\frac{1}{2}\\ln(2\\pi)$$\nThe log-posterior $\\mathcal{L}(\\theta)$, ignoring constant terms, is:\n$$\\mathcal{L}(\\theta) = a_3 + \\theta - \\ln(1+\\exp(a_1+\\theta)) - 2\\ln(1+\\exp(a_2+\\theta)) - 2\\ln(1+\\exp(a_3+\\theta)) - \\frac{\\theta^2}{2}$$\nTo find the MAP estimate $\\hat{\\theta}$, we differentiate $\\mathcal{L}(\\theta)$ with respect to $\\theta$ and set the derivative to zero. Note that $\\frac{d}{d\\theta}\\ln(1+\\exp(a_d+\\theta)) = \\frac{\\exp(a_d+\\theta)}{1+\\exp(a_d+\\theta)} = p_d(\\theta)$.\n$$\\frac{d\\mathcal{L}(\\theta)}{d\\theta} = 1 - p_1(\\theta) - 2p_2(\\theta) - 2p_3(\\theta) - \\theta$$\nThe MAP estimate $\\hat{\\theta}$ is the solution to the equation:\n$$1 - p_1(\\theta) - 2p_2(\\theta) - 2p_3(\\theta) - \\theta = 0$$\nThe second derivative, $\\frac{d^2\\mathcal{L}(\\theta)}{d\\theta^2} = -p_1(\\theta)(1-p_1(\\theta)) - 2p_2(\\theta)(1-p_2(\\theta)) - 2p_3(\\theta)(1-p_3(\\theta)) - 1$, is always negative, ensuring that the log-posterior is strictly concave and has a unique maximum.\n\nWe must solve this equation numerically. First, we compute the constants $a_d = \\text{logit}(q_d)$ from the skeleton $(q_1, q_2, q_3, q_4) = (0.08, 0.14, 0.25, 0.40)$:\n$a_1 = \\text{logit}(0.08) = \\ln(\\frac{0.08}{1-0.08}) = \\ln(\\frac{0.08}{0.92}) \\approx -2.4423$\n$a_2 = \\text{logit}(0.14) = \\ln(\\frac{0.14}{1-0.14}) = \\ln(\\frac{0.14}{0.86}) \\approx -1.8153$\n$a_3 = \\text{logit}(0.25) = \\ln(\\frac{0.25}{1-0.25}) = \\ln(\\frac{0.25}{0.75}) \\approx -1.0986$\n$a_4 = \\text{logit}(0.40) = \\ln(\\frac{0.40}{1-0.40}) = \\ln(\\frac{0.40}{0.60}) \\approx -0.4055$\n\nThe equation for $\\hat{\\theta}$ is:\n$$1 - \\theta - \\frac{\\exp(a_1+\\theta)}{1+\\exp(a_1+\\theta)} - 2\\frac{\\exp(a_2+\\theta)}{1+\\exp(a_2+\\theta)} - 2\\frac{\\exp(a_3+\\theta)}{1+\\exp(a_3+\\theta)} = 0$$\nUsing a numerical root-finding method (such as Newton's method), we find the solution to be $\\hat{\\theta} \\approx 0.08287$.\n\nNext, we compute the posterior plug-in estimates of the DLT probabilities, $\\hat{p}_d = p_d(\\hat{\\theta})$, for each dose level $d \\in \\{1,2,3,4\\}$:\n$\\hat{p}_1 = p_1(\\hat{\\theta}) = \\frac{\\exp(a_1 + \\hat{\\theta})}{1 + \\exp(a_1 + \\hat{\\theta})} = \\frac{\\exp(-2.4423 + 0.08287)}{1 + \\exp(-2.4423 + 0.08287)} \\approx 0.0865$\n$\\hat{p}_2 = p_2(\\hat{\\theta}) = \\frac{\\exp(a_2 + \\hat{\\theta})}{1 + \\exp(a_2 + \\hat{\\theta})} = \\frac{\\exp(-1.8153 + 0.08287)}{1 + \\exp(-1.8153 + 0.08287)} \\approx 0.1502$\n$\\hat{p}_3 = p_3(\\hat{\\theta}) = \\frac{\\exp(a_3 + \\hat{\\theta})}{1 + \\exp(a_3 + \\hat{\\theta})} = \\frac{\\exp(-1.0986 + 0.08287)}{1 + \\exp(-1.0986 + 0.08287)} \\approx 0.2658$\n$\\hat{p}_4 = p_4(\\hat{\\theta}) = \\frac{\\exp(a_4 + \\hat{\\theta})}{1 + \\exp(a_4 + \\hat{\\theta})} = \\frac{\\exp(-0.4055 + 0.08287)}{1 + \\exp(-0.4055 + 0.08287)} \\approx 0.4199$\n\nThe final step is to recommend the next dose level, $d^{\\star}$, which is the dose that minimizes the absolute difference between the estimated DLT probability $\\hat{p}_d$ and the target toxicity level $p_T = 0.25$:\n$d^{\\star} = \\arg\\min_{d \\in \\{1,2,3,4\\}} |\\hat{p}_d - p_T|$\n\nWe calculate the absolute differences for each dose level:\nFor $d=1$: $|\\hat{p}_1 - 0.25| = |0.0865 - 0.25| = 0.1635$\nFor $d=2$: $|\\hat{p}_2 - 0.25| = |0.1502 - 0.25| = 0.0998$\nFor $d=3$: $|\\hat{p}_3 - 0.25| = |0.2658 - 0.25| = 0.0158$\nFor $d=4$: $|\\hat{p}_4 - 0.25| = |0.4199 - 0.25| = 0.1699$\n\nThe minimum absolute difference is $0.0158$, which corresponds to dose level $d=3$. Therefore, the recommended next dose level is $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Adaptive trials often include rules to stop early for overwhelming efficacy, but this can lead to a significant overestimation of the treatment effect. This phenomenon, often called statistical bias, is a critical issue in the interpretation of results from sequential trials. This advanced exercise guides you through the mathematical derivation of this bias by calculating the estimator's expectation conditional on stopping, and shows how to construct a corrected estimator for a more accurate assessment of the treatment effect .",
            "id": "4772890",
            "problem": "Consider a two-arm randomized clinical trial comparing an experimental treatment to control with a continuous primary outcome. Assume the outcomes in each arm are independent and identically distributed as Gaussian with known variance $\\sigma^{2}$ and equal allocation. Let $\\delta$ denote the true mean difference (experimental minus control). At an interim analysis after $n_{1}$ patients per arm, the naive estimator of $\\delta$ is the difference in sample means,\n$$\n\\hat{\\delta}_{1},\n$$\nwhich satisfies\n$$\n\\hat{\\delta}_{1} \\sim \\mathcal{N}\\!\\left(\\delta, \\ \\frac{2 \\sigma^{2}}{n_{1}}\\right).\n$$\nDefine the standardized $Z$-statistic at interim as\n$$\nZ_{1} \\equiv \\hat{\\delta}_{1} \\sqrt{I_{1}}, \\quad \\text{where } I_{1} \\equiv \\frac{n_{1}}{2 \\sigma^{2}}.\n$$\nA one-sided early-stopping rule for efficacy is used: the trial is stopped for efficacy at the interim if and only if $Z_{1} \\geq c$ for a fixed boundary $c > 0$; otherwise, the trial continues to a final analysis (not considered here). Investigators who stop early for efficacy report the naive estimator $\\hat{\\delta}_{1}$ computed at the interim as the treatment effect.\n\nStarting only from the model above and standard properties of the Gaussian distribution, do the following:\n1. Derive the conditional expectation $\\mathbb{E}[Z_{1} \\mid Z_{1} \\geq c]$ and use it to obtain the conditional expectation $\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c]$.\n2. Hence, show that early stopping for efficacy induces upward bias in the naive estimator, and derive the closed-form expression for the conditional bias\n$$\n\\mathrm{Bias}(\\hat{\\delta}_{1} \\mid Z_{1} \\geq c) \\equiv \\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] - \\delta,\n$$\nexpressed in terms of the inverse Mills ratio $\\lambda(x) \\equiv \\frac{\\phi(x)}{1 - \\Phi(x)}$, where $\\phi$ and $\\Phi$ are the standard normal probability density function and cumulative distribution function, respectively.\n3. Using conditional expectation given stopping, derive a bias-corrected estimator $\\tilde{\\delta}$ of $\\delta$ that removes this conditional bias when the conditioning event $Z_{1} \\geq c$ occurs, and express it in closed form as a function of $\\hat{\\delta}_{1}$, $c$, $n_{1}$, and $\\sigma^{2}$, allowing explicit dependence on $\\delta$ if unavoidable.\n\nYour final answer should be a single closed-form expression or a $1 \\times 2$ row expression giving both the conditional bias and the bias-corrected estimator in terms of $\\delta$, $c$, $n_{1}$, and $\\sigma^{2}$. No numerical evaluation is required, and no rounding is necessary. Use only the symbols defined above and standard normal functions in your expressions. Do not include any units in your final expressions.",
            "solution": "The core of the problem involves computing the expectation of a Gaussian random variable conditional on it exceeding a certain threshold. This is the expectation of a truncated normal distribution.\n\nFirst, we establish the distribution of the standardized $Z$-statistic, $Z_{1}$. The naive estimator for the treatment effect $\\delta$ is $\\hat{\\delta}_{1}$, with distribution given as\n$$\n\\hat{\\delta}_{1} \\sim \\mathcal{N}\\!\\left(\\delta, \\ \\frac{2 \\sigma^{2}}{n_{1}}\\right).\n$$\nThe $Z$-statistic is defined as $Z_{1} \\equiv \\hat{\\delta}_{1} \\sqrt{I_{1}}$, where $I_{1} = \\frac{n_{1}}{2 \\sigma^{2}}$.\nSince $Z_{1}$ is a linear transformation of a Gaussian random variable, it is also Gaussian. Its expectation is\n$$\n\\mathbb{E}[Z_{1}] = \\mathbb{E}[\\hat{\\delta}_{1} \\sqrt{I_{1}}] = \\mathbb{E}[\\hat{\\delta}_{1}] \\sqrt{I_{1}} = \\delta \\sqrt{I_{1}}.\n$$\nLet us denote this mean by $\\theta = \\delta \\sqrt{I_{1}}$.\nThe variance of $Z_{1}$ is\n$$\n\\mathrm{Var}(Z_{1}) = \\mathrm{Var}(\\hat{\\delta}_{1} \\sqrt{I_{1}}) = (\\sqrt{I_{1}})^{2} \\mathrm{Var}(\\hat{\\delta}_{1}) = I_{1} \\left(\\frac{2 \\sigma^{2}}{n_{1}}\\right) = \\left(\\frac{n_{1}}{2 \\sigma^{2}}\\right) \\left(\\frac{2 \\sigma^{2}}{n_{1}}\\right) = 1.\n$$\nThus, the distribution of the $Z$-statistic is $Z_{1} \\sim \\mathcal{N}(\\theta, 1)$, a standard normal distribution with mean $\\theta$.\n\nWith the distribution of $Z_1$ established, we can proceed to the three parts of the problem.\n\n1. Derivation of conditional expectations:\nWe need to find the conditional expectation $\\mathbb{E}[Z_{1} \\mid Z_{1} \\geq c]$. This is the mean of a $\\mathcal{N}(\\theta, 1)$ distribution truncated from below at $c$. Let $X$ be a random variable such that $X \\sim \\mathcal{N}(\\theta, 1)$. Its probability density function (PDF) is $f(x) = \\phi(x-\\theta)$, where $\\phi(\\cdot)$ is the standard normal PDF.\nThe conditional expectation is defined as:\n$$\n\\mathbb{E}[X \\mid X \\geq c] = \\frac{\\int_{c}^{\\infty} x f(x) \\,dx}{P(X \\geq c)}.\n$$\nThe denominator is the probability of the conditioning event:\n$$\nP(X \\geq c) = \\int_{c}^{\\infty} \\phi(x-\\theta) \\,dx.\n$$\nBy substituting $u = x - \\theta$, we get $du = dx$, and the lower integration limit becomes $c-\\theta$.\n$$\nP(X \\geq c) = \\int_{c-\\theta}^{\\infty} \\phi(u) \\,du = 1 - \\Phi(c-\\theta),\n$$\nwhere $\\Phi(\\cdot)$ is the standard normal cumulative distribution function (CDF).\nThe numerator of the conditional expectation is $\\int_{c}^{\\infty} x \\phi(x-\\theta) \\,dx$. Using the same substitution $u = x - \\theta$ (so $x=u+\\theta$):\n$$\n\\int_{c}^{\\infty} x \\phi(x-\\theta) \\,dx = \\int_{c-\\theta}^{\\infty} (u+\\theta) \\phi(u) \\,du = \\int_{c-\\theta}^{\\infty} u \\phi(u) \\,du + \\theta \\int_{c-\\theta}^{\\infty} \\phi(u) \\,du.\n$$\nFor the first integral, we use the fact that $\\frac{d}{du}\\phi(u) = -u\\phi(u)$, which implies $\\int u\\phi(u)du = -\\phi(u)$. Thus,\n$$\n\\int_{c-\\theta}^{\\infty} u \\phi(u) \\,du = [-\\phi(u)]_{c-\\theta}^{\\infty} = -\\lim_{u\\to\\infty}\\phi(u) - (-\\phi(c-\\theta)) = 0 + \\phi(c-\\theta) = \\phi(c-\\theta).\n$$\nThe second integral is simply $\\theta P(X \\ge c) = \\theta(1 - \\Phi(c-\\theta))$.\nCombining these results, the numerator is $\\phi(c-\\theta) + \\theta(1 - \\Phi(c-\\theta))$.\nThe conditional expectation is therefore:\n$$\n\\mathbb{E}[X \\mid X \\geq c] = \\frac{\\phi(c-\\theta) + \\theta(1 - \\Phi(c-\\theta))}{1 - \\Phi(c-\\theta)} = \\theta + \\frac{\\phi(c-\\theta)}{1 - \\Phi(c-\\theta)}.\n$$\nUsing the definition of the inverse Mills ratio, $\\lambda(x) = \\frac{\\phi(x)}{1 - \\Phi(x)}$, we can write this as\n$$\n\\mathbb{E}[Z_{1} \\mid Z_{1} \\geq c] = \\theta + \\lambda(c-\\theta).\n$$\nNow, we find $\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c]$. Since $\\hat{\\delta}_{1} = Z_{1} / \\sqrt{I_{1}}$ and the conditioning event $Z_{1} \\ge c$ is equivalent to $\\hat{\\delta}_{1} \\ge c/\\sqrt{I_1}$, we have:\n$$\n\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] = \\mathbb{E}\\left[\\frac{Z_{1}}{\\sqrt{I_{1}}} \\mid Z_{1} \\geq c\\right] = \\frac{1}{\\sqrt{I_{1}}} \\mathbb{E}[Z_{1} \\mid Z_{1} \\geq c] = \\frac{1}{\\sqrt{I_{1}}} (\\theta + \\lambda(c-\\theta)).\n$$\nSubstituting $\\theta = \\delta \\sqrt{I_{1}}$:\n$$\n\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] = \\frac{1}{\\sqrt{I_{1}}} (\\delta \\sqrt{I_{1}} + \\lambda(c-\\delta \\sqrt{I_{1}})) = \\delta + \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}).\n$$\n\n2. Derivation of conditional bias:\nThe conditional bias is defined as $\\mathrm{Bias}(\\hat{\\delta}_{1} \\mid Z_{1} \\geq c) \\equiv \\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] - \\delta$. Using the result from part 1:\n$$\n\\mathrm{Bias}(\\hat{\\delta}_{1} \\mid Z_{1} \\geq c) = \\left(\\delta + \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}})\\right) - \\delta = \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}).\n$$\nTo show this represents an upward bias, we examine the sign of this term. The standard normal PDF $\\phi(x)$ is strictly positive for all real $x$. The standard normal CDF $\\Phi(x)$ is strictly less than $1$, so $1-\\Phi(x)$ is strictly positive. Therefore, the inverse Mills ratio $\\lambda(x)$ is strictly positive. The information $I_{1} = \\frac{n_1}{2\\sigma^2}$ is also positive since $n_1 > 0$ and $\\sigma^2 > 0$. Thus, the bias is strictly positive, meaning that $\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] > \\delta$. This confirms that early stopping for efficacy induces an upward bias in the naive estimator.\nThe closed-form expression for the bias in terms of the original parameters is obtained by substituting $I_{1}$:\n$$\n\\mathrm{Bias}(\\hat{\\delta}_{1} \\mid Z_{1} \\geq c) = \\sqrt{\\frac{2\\sigma^2}{n_1}} \\lambda\\left(c-\\delta\\sqrt{\\frac{n_1}{2\\sigma^2}}\\right).\n$$\n\n3. Derivation of a bias-corrected estimator:\nWe seek an estimator $\\tilde{\\delta}$ such that its conditional expectation, given that the trial stops early, is equal to the true parameter $\\delta$. That is, $\\mathbb{E}[\\tilde{\\delta} \\mid Z_{1} \\geq c] = \\delta$.\nWe can construct such an estimator by subtracting the conditional bias from the naive estimator $\\hat{\\delta}_{1}$. The problem allows this corrected estimator to depend on the true parameter $\\delta$.\nLet us define the estimator $\\tilde{\\delta}$ as:\n$$\n\\tilde{\\delta} \\equiv \\hat{\\delta}_{1} - \\mathrm{Bias}(\\hat{\\delta}_{1} \\mid Z_{1} \\geq c) = \\hat{\\delta}_{1} - \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}).\n$$\nThis estimator is a function of the data (via $\\hat{\\delta}_{1}$) and the true parameter $\\delta$. Let's verify that it is conditionally unbiased:\n$$\n\\mathbb{E}[\\tilde{\\delta} \\mid Z_{1} \\geq c] = \\mathbb{E}\\left[\\hat{\\delta}_{1} - \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}) \\mid Z_{1} \\geq c\\right].\n$$\nThe bias term depends on $\\delta$, $c$, and $I_{1}$, which are constants with respect to the expectation over the random variable $\\hat{\\delta}_{1}$ (or $Z_{1}$). Therefore, we can write:\n$$\n\\mathbb{E}[\\tilde{\\delta} \\mid Z_{1} \\geq c] = \\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c] - \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}).\n$$\nSubstituting the expression for $\\mathbb{E}[\\hat{\\delta}_{1} \\mid Z_{1} \\geq c]$ from part 1:\n$$\n\\mathbb{E}[\\tilde{\\delta} \\mid Z_{1} \\geq c] = \\left(\\delta + \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}})\\right) - \\frac{1}{\\sqrt{I_{1}}} \\lambda(c-\\delta\\sqrt{I_{1}}) = \\delta.\n$$\nThe estimator $\\tilde{\\delta}$ is indeed conditionally unbiased. Its closed-form expression in terms of the specified parameters is:\n$$\n\\tilde{\\delta} = \\hat{\\delta}_{1} - \\sqrt{\\frac{2\\sigma^2}{n_1}} \\lambda\\left(c-\\delta\\sqrt{\\frac{n_1}{2\\sigma^2}}\\right).\n$$\nThis estimator, while being a theoretical construct due to its dependence on $\\delta$, provides the exact correction required to remove the bias from early stopping.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\sqrt{\\frac{2\\sigma^2}{n_1}} \\lambda\\left(c-\\delta\\sqrt{\\frac{n_1}{2\\sigma^2}}\\right) & \\hat{\\delta}_1 - \\sqrt{\\frac{2\\sigma^2}{n_1}} \\lambda\\left(c-\\delta\\sqrt{\\frac{n_1}{2\\sigma^2}}\\right)\n\\end{pmatrix}\n}\n$$"
        }
    ]
}