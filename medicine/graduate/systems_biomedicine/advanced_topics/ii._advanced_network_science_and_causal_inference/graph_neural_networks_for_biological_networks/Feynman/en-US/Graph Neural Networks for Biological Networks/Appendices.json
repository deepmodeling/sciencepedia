{
    "hands_on_practices": [
        {
            "introduction": "To begin, we will perform a hands-on calculation of a single message-passing step, the fundamental building block of any Graph Neural Network. This exercise  demonstrates how a central node aggregates information from its neighbors and updates its own feature vector. By working through this core mechanic, you will gain a concrete understanding of how GNNs learn from network-structured data like protein-protein interaction networks.",
            "id": "1436694",
            "problem": "In the field of systems biology, Graph Neural Networks (GNNs) are powerful tools for learning from data structured as networks, such as protein-protein interaction (PPI) networks. Consider a simple GNN model designed to update the features of proteins based on their connections.\n\nWe are focused on a small part of a PPI network involving a central protein, Protein V, which interacts with two neighboring proteins, Protein U1 and Protein U2. Each protein is described by a 2-dimensional feature vector. The first element of the vector represents the protein's normalized expression level, and the second element represents its mitochondrial localization score.\n\nThe initial feature vectors are given as:\n- Protein V: $h_V = [0.1, 0.9]$\n- Protein U1: $h_{U1} = [0.2, 0.3]$\n- Protein U2: $h_{U2} = [0.6, 0.1]$\n\nThe GNN performs an update to find a new feature vector for Protein V, denoted as $h'_V$, in a single message-passing step. This process involves two stages:\n\n1.  **Aggregation:** An aggregated neighbor vector, $h_{N(V)}$, is created by taking the element-wise sum of the feature vectors of all of Protein V's neighbors.\n2.  **Update:** The new feature vector $h'_V$ is calculated by adding the aggregated neighbor vector $h_{N(V)}$ to Protein V's original feature vector $h_V$, and then applying an element-wise Rectified Linear Unit (ReLU) activation function to the result. The ReLU function is defined as $\\text{ReLU}(x) = \\max(0, x)$ for each component of the vector.\n\nCalculate the updated feature vector $h'_V$ for Protein V.",
            "solution": "We are given initial feature vectors for three proteins:\n$$\nh_{V}=\\begin{pmatrix}0.1 & 0.9\\end{pmatrix},\\quad\nh_{U1}=\\begin{pmatrix}0.2 & 0.3\\end{pmatrix},\\quad\nh_{U2}=\\begin{pmatrix}0.6 & 0.1\\end{pmatrix}.\n$$\nAggregation step: the aggregated neighbor vector is the element-wise sum of neighbor features,\n$$\nh_{N(V)}=h_{U1}+h_{U2}\n=\\begin{pmatrix}0.2 & 0.3\\end{pmatrix}+\\begin{pmatrix}0.6 & 0.1\\end{pmatrix}\n=\\begin{pmatrix}0.8 & 0.4\\end{pmatrix}.\n$$\nUpdate step: apply the element-wise ReLU to the sum of $h_{V}$ and $h_{N(V)}$,\n$$\nh'_{V}=\\operatorname{ReLU}\\!\\big(h_{V}+h_{N(V)}\\big)\n=\\operatorname{ReLU}\\!\\left(\\begin{pmatrix}0.1 & 0.9\\end{pmatrix}+\\begin{pmatrix}0.8 & 0.4\\end{pmatrix}\\right)\n=\\operatorname{ReLU}\\!\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}.\n$$\nSince each component is positive, $\\operatorname{ReLU}(x)=x$ for both components, hence\n$$\nh'_{V}=\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}0.9 & 1.3\\end{pmatrix}}$$"
        },
        {
            "introduction": "While the message-passing paradigm is powerful, its effectiveness is fundamentally constrained by the underlying graph topology. This next exercise  presents a common scenario in systems biology where a GNN fails to learn effectively due to a fragmented network structure. Analyzing this failure will deepen your understanding of the critical role that graph connectivity plays in information propagation and model generalization.",
            "id": "1436702",
            "problem": "A systems biologist is investigating protein functions using a Graph Neural Network (GNN). The dataset is a protein-protein interaction (PPI) network where nodes represent proteins and edges represent experimentally verified interactions. The goal is to perform node classification, predicting a functional category for each protein. However, due to the sparse nature of the experimental data, the resulting graph is not a single connected entity. Instead, it consists of numerous small, disconnected components—isolated islands of a few interacting proteins with no known interactions linking one island to another.\n\nAfter training a standard message-passing GNN on this network, the biologist observes that the model's performance on a held-out test set is exceptionally poor, barely better than random guessing. Which of the following statements provides the most fundamental and direct explanation for this failure?\n\nA. The message-passing mechanism, which updates a node's features based on its neighbors, confines information flow entirely within each disconnected component. This prevents the model from learning and generalizing patterns that may be shared across different components of the graph.\n\nB. The model is experiencing severe overfitting because the training data is not large enough. The presence of disconnected components is irrelevant to the model's performance.\n\nC. GNNs require the input graph to be represented as a single, dense adjacency matrix. A graph with disconnected components cannot be represented in this format, causing a fundamental data structure incompatibility.\n\nD. The non-linear activation functions used in the GNN, such as the Rectified Linear Unit (ReLU), are mathematically unstable when applied to nodes with a very low number of connections (degree), a common characteristic of nodes in small components.\n\nE. Message passing in GNNs becomes computationally inefficient and slow on graphs with many components, causing the training process to terminate prematurely before the model can converge to a good solution.",
            "solution": "A standard message-passing GNN updates node embeddings by aggregating information only from adjacent nodes. A canonical layer can be written as\n$$\nh_{v}^{(k+1)}=\\phi\\!\\left(h_{v}^{(k)},\\;\\square_{u\\in\\mathcal{N}(v)}\\psi\\!\\left(h_{u}^{(k)}, e_{uv}\\right)\\right),\n$$\nwhere $h_{v}^{(k)}$ is the representation of node $v$ at layer $k$, $\\mathcal{N}(v)$ is the neighbor set of $v$, $e_{uv}$ encodes edge features, $\\psi$ is a message function, $\\square$ is a permutation-invariant aggregator, and $\\phi$ is an update function. After $K$ layers, $h_{v}^{(K)}$ depends only on nodes within the $K$-hop neighborhood of $v$. If the graph consists of disconnected components, then for any two nodes in different components, there is no path between them, hence no sequence of message-passing layers can transmit information across components.\n\nTherefore, for node classification, any label or structural signal available in one component cannot be propagated to nodes in another component through message passing. If the train-test split places labeled nodes in some components and test nodes in different, disconnected components, the predictions for those test nodes cannot benefit from relational information or label propagation from the training components. While GNN parameters are shared globally across all nodes, the primary inductive bias of message-passing models is to leverage graph connectivity; when connectivity between training and test nodes is absent, the model’s core mechanism for capturing and transferring relational patterns is fundamentally blocked. This directly explains performance near random guessing on isolated test components.\n\nEvaluating the options:\n- A correctly identifies that message passing confines information flow within connected components, which is the fundamental mechanism-level reason for failure in this setting.\n- B attributes failure to overfitting and dismisses the role of disconnected components, which is not the most direct explanation given the described setup.\n- C is false: disconnected graphs are representable by block-diagonal adjacency matrices without incompatibility.\n- D is false: standard activations like ReLU are not mathematically unstable at low degrees.\n- E is not fundamental and is generally incorrect; disconnectedness does not inherently cause premature termination.\n\nThus, A provides the most fundamental and direct explanation.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Ultimately, the goal of applying GNNs in systems biomedicine is to generate novel, testable hypotheses that can drive experimental discovery. This final, advanced practice  moves beyond the algorithm and challenges you to design a complete wet-lab validation protocol for a GNN's predictions. Success requires integrating principles of experimental design, biostatistics, and resource management, reflecting the interdisciplinary nature of modern biological research.",
            "id": "4349417",
            "problem": "A Graph Neural Network (GNN) trained on a multiplex biological network with node features derived from transcriptomics and phospho-proteomics predicts that under ligand stimulation $L$, perturbing certain source genes will increase a readout marker $Y$ (for example, phosphorylated ribosomal protein S6) via specific protein-protein interaction edges. The GNN outputs a ranked list of $m = 300$ candidate edges. You plan wet-lab validation using Clustered Regularly Interspaced Short Palindromic Repeats interference (CRISPRi) to perturb source genes, measuring $Y$ by quantitative immunoblotting. A pilot study on the same cell line under $L$ yields an empirical variance $\\sigma^2 = 0.09$ for $Y$ (standardized units), and the GNN-predicted minimum effect size of interest is $\\delta = 0.40$ (increase in group mean of the perturbed condition relative to non-targeting control). Plates accommodate $b = 24$ wells, and day-to-day batch effects are non-negligible.\n\nYou must design a validation protocol that links model predictions to wet-lab experiments with appropriate controls, replicates, and statistical significance thresholds. The protocol must:\n\n- Map each edge-level prediction to a falsifiable hypothesis with a null hypothesis $H_0$ stating no change in the mean of $Y$ under the corresponding perturbation and an alternative hypothesis $H_1$ specifying an increase by at least $\\delta$.\n- Include both negative controls (non-targeting guide) and positive controls (a known ligand-responsive interaction that increases $Y$) on every plate.\n- Arrange randomization of guides to wells and blinding of the measurement to avoid allocation and measurement bias.\n- Use biological replicates (independent cultures across days), explicitly distinguishing them from technical replicates (multiple wells per culture), and avoid pseudo-replication by defining the unit of inference as the biological replicate.\n- Control for multiple testing across $m$ hypotheses using a principled procedure with a stated error rate (for example, False Discovery Rate (FDR) at level $q$ or family-wise error rate).\n- Justify per-condition sample sizes from first principles to achieve power $1 - \\beta = 0.80$ at a stated significance level for confirmatory testing, explicitly accounting for the observed $\\sigma^2$ and the minimally interesting effect size $\\delta$.\n\nWhich of the following protocols best satisfies these requirements while remaining scientifically sound and resource-feasible?\n\nA. Screen all $m = 300$ predictions in a single stage with $n = 3$ wells per condition per plate, treat wells as independent replicates, apply an uncorrected two-sided test at $\\alpha = 0.05$, and call hits by combining a fold-change threshold $\\geq \\delta$ with $p < 0.05$. Include only a non-targeting negative control. No randomization, no blinding, and no adjustment for batch effects.\n\nB. Use a two-stage design. Stage $1$: for all $m = 300$ predictions, randomize guide assignment across plates and days, blind $Y$ measurements, and include per-plate negative and positive controls. Collect $n_s = 6$ biological replicates per condition across $r_b = 3$ independent days, with $r_t = 2$ technical wells per biological replicate; analyze biological-replicate means with a linear mixed-effects model including day as a random effect to mitigate batch variation. Control the False Discovery Rate (FDR) at $q = 0.10$ across $m$ hypotheses (Benjamini–Hochberg). Stage $2$: for the top $k$ candidates from Stage $1$ and all controls, perform confirmatory experiments with independent cultures, randomization and blinding, and compute per-condition sample size $n_c$ from first principles to achieve power $1 - \\beta = 0.80$ at a one-sided $\\alpha = 0.01$ given $\\sigma^2 = 0.09$ and $\\delta = 0.40$; analyze with a two-sample test on biological-replicate means and report effect sizes with confidence intervals. Declare validated if the confirmatory $p$-value is below $\\alpha$ and the estimated effect is $\\geq \\delta$. \n\nC. Perform a single-stage experiment with $n = 4$ wells per condition, count each well as an independent replicate, and apply Bonferroni correction across $m = 300$ tests with per-test threshold $\\alpha = 0.05 / 300$. Include a non-targeting negative control but omit the positive control. Do not randomize across plates; assign all guides for a given prediction to the same plate. Use the raw well-level data without modeling batch effects.\n\nD. Use a single-stage experiment with $n = 10$ biological replicates per condition, randomize and blind, include negative and positive controls, and test each prediction with an uncorrected one-sided test at $\\alpha = 0.05$. Do not perform multiple testing correction; instead, apply a fold-change filter $\\geq \\delta$ and require $p < 0.05$ to declare significance. No confirmatory follow-up.\n\nSelect the best option.",
            "solution": "The problem asks for the design of a wet-lab validation protocol for computational predictions from a Graph Neural Network (GNN). The protocol's quality is to be judged against a specific set of requirements for scientific and statistical rigor.\n\nFirst, we validate the problem statement.\n\n### Step 1: Extract Givens\n-   **Model:** Graph Neural Network (GNN) on a multiplex biological network.\n-   **GNN Input:** Node features from transcriptomics and phospho-proteomics.\n-   **GNN Output:** Ranked list of $m = 300$ candidate edges predicted to increase readout marker $Y$ upon source gene perturbation under ligand stimulation $L$.\n-   **Validation Technique:** CRISPRi perturbation of source genes.\n-   **Readout Measurement:** Quantitative immunoblotting for $Y$.\n-   **Pilot Data:** Empirical variance of $Y$ is $\\sigma^2 = 0.09$ (standardized units).\n-   **Effect Size:** Minimum effect size of interest is an increase of $\\delta = 0.40$ in the group mean.\n-   **Experimental Constraints:** Plate size is $b = 24$ wells; non-negligible day-to-day batch effects.\n-   **Protocol Requirements:**\n    1.  Map predictions to falsifiable hypotheses ($H_0$: no change, $H_1$: increase $\\ge \\delta$).\n    2.  Include per-plate negative and positive controls.\n    3.  Implement randomization and blinding.\n    4.  Use true biological replicates, distinguish from technical replicates, and avoid pseudo-replication.\n    5.  Control for multiple testing across $m=300$ hypotheses using a principled method.\n    6.  Justify sample size for a power of $1 - \\beta = 0.80$ at a stated significance level, using the given $\\sigma^2$ and $\\delta$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, well-posed, and objective. It outlines a standard and realistic scenario in systems biology where computational predictions are validated experimentally. All terms (GNN, CRISPRi, FDR, power analysis) are standard in the field. The provided data ($\\sigma^2=0.09$, $\\delta=0.40$, $m=300$) are plausible. The requirements for the protocol correspond to bedrock principles of good experimental design and statistical analysis. The problem is free of scientific unsoundness, ambiguity, or contradiction.\n\n### Step 3: Verdict and Action\nThe problem is valid. We will proceed to analyze the options. A key quantitative requirement is the sample size calculation (Requirement 6), which we perform first.\n\n### Principle-Based Derivation: Sample Size Calculation\n\nThe protocol must justify sample sizes to achieve a power of $1 - \\beta = 0.80$ for detecting an effect size of at least $\\delta = 0.40$. The alternative hypothesis is directional ($H_1$: increase in $Y$), so a one-sided statistical test is appropriate. The formula for the required sample size $n$ per group in a two-sample test (assuming known variance) is:\n$$ n = \\frac{(\\sigma_1^2 + \\sigma_2^2) (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta^2} $$\nAssuming equal variance in both the control and perturbed groups, $\\sigma_1^2 = \\sigma_2^2 = \\sigma^2$, the formula simplifies to:\n$$ n = \\frac{2 \\sigma^2 (z_{1-\\alpha} + z_{1-\\beta})^2}{\\delta^2} $$\nWe are given:\n-   Variance: $\\sigma^2 = 0.09$, so standard deviation $\\sigma = \\sqrt{0.09} = 0.30$.\n-   Effect size: $\\delta = 0.40$.\n-   Power: $1 - \\beta = 0.80$, which corresponds to a standard normal quantile of $z_{1-\\beta} = z_{0.80} \\approx 0.842$.\n\nOption B specifies a confirmatory significance level of $\\alpha = 0.01$. For a one-sided test, this corresponds to $z_{1-\\alpha} = z_{0.99} \\approx 2.326$.\n\nLet's calculate the required sample size $n_c$ for the confirmatory stage as described in Option B:\n$$ n_c = \\frac{2 \\times 0.09 \\times (z_{0.99} + z_{0.80})^2}{(0.40)^2} $$\n$$ n_c = \\frac{0.18 \\times (2.326 + 0.842)^2}{0.16} $$\n$$ n_c = \\frac{0.18 \\times (3.168)^2}{0.16} $$\n$$ n_c = \\frac{0.18 \\times 10.036224}{0.16} \\approx 11.29 $$\nSince the number of replicates must be an integer, the experiment requires $n_c = 12$ biological replicates per condition (e.g., $12$ for the perturbed group and $12$ for the non-targeting control group) to meet these stringent confirmatory criteria.\n\n### Option-by-Option Analysis\n\n**A. Screen all $m = 300$ predictions in a single stage with $n = 3$ wells per condition per plate, treat wells as independent replicates, apply an uncorrected two-sided test at $\\alpha = 0.05$, and call hits by combining a fold-change threshold $\\geq \\delta$ with $p < 0.05$. Include only a non-targeting negative control. No randomization, no blinding, and no adjustment for batch effects.**\n\n*   **Requirement 1 (Hypothesis):** Fails. Uses a two-sided test for a directional prediction (\"increase\"), which reduces statistical power.\n*   **Requirement 2 (Controls):** Fails. Omits the required positive control.\n*   **Requirement 3 (Bias Control):** Fails. Explicitly states \"No randomization, no blinding,\" inviting systematic bias.\n*   **Requirement 4 (Replication):** Fails. Commits the serious error of pseudo-replication by treating wells (technical replicates) as independent biological replicates.\n*   **Requirement 5 (Multiple Testing):** Fails. Uses an \"uncorrected\" test for $m=300$ hypotheses, which would lead to a large number of false positives (on average, $300 \\times 0.05 = 15$). A simple p-value plus fold-change threshold is not a principled method for controlling error rates.\n*   **Requirement 6 (Power):** Fails. The sample size of $n=3$ is arbitrary and grossly insufficient for the desired power.\n\n**Verdict:** Incorrect. This protocol is fundamentally unsound and violates every key principle of robust experimental design.\n\n**B. Use a two-stage design. Stage $1$: for all $m = 300$ predictions, randomize guide assignment across plates and days, blind $Y$ measurements, and include per-plate negative and positive controls. Collect $n_s = 6$ biological replicates per condition across $r_b = 3$ independent days, with $r_t = 2$ technical wells per biological replicate; analyze biological-replicate means with a linear mixed-effects model including day as a random effect to mitigate batch variation. Control the False Discovery Rate (FDR) at $q = 0.10$ across $m$ hypotheses (Benjamini–Hochberg). Stage $2$: for the top $k$ candidates from Stage $1$ and all controls, perform confirmatory experiments with independent cultures, randomization and blinding, and compute per-condition sample size $n_c$ from first principles to achieve power $1 - \\beta = 0.80$ at a one-sided $\\alpha = 0.01$ given $\\sigma^2 = 0.09$ and $\\delta = 0.40$; analyze with a two-sample test on biological-replicate means and report effect sizes with confidence intervals. Declare validated if the confirmatory $p$-value is below $\\alpha$ and the estimated effect is $\\geq \\delta$.**\n\n*   **Requirement 1 (Hypothesis):** Met. The confirmatory stage uses a one-sided test and an effect size criterion, directly testing the specified hypothesis.\n*   **Requirement 2 (Controls):** Met. Includes both negative and positive controls.\n*   **Requirement 3 (Bias Control):** Met. Explicitly includes randomization and blinding.\n*   **Requirement 4 (Replication):** Met. Correctly distinguishes biological ($n_s=6$) and technical ($r_t=2$) replicates, avoids pseudo-replication, and uses a sophisticated mixed-effects model to properly handle batch effects and the data structure.\n*   **Requirement 5 (Multiple Testing):** Met. Uses FDR control via Benjamini-Hochberg, which is the standard and appropriate method for a discovery screen of this nature.\n*   **Requirement 6 (Power):** Met. Explicitly commits to computing the sample size $n_c$ for the confirmatory stage from first principles, using the exact parameters given in the problem statement. The two-stage design is also a highly efficient use of resources.\n\n**Verdict:** Correct. This protocol is an exemplar of rigorous, modern experimental design. It correctly addresses all specified requirements with appropriate statistical methods.\n\n**C. Perform a single-stage experiment with $n = 4$ wells per condition, count each well as an independent replicate, and apply Bonferroni correction across $m = 300$ tests with per-test threshold $\\alpha = 0.05 / 300$. Include a non-targeting negative control but omit the positive control. Do not randomize across plates; assign all guides for a given prediction to the same plate. Use the raw well-level data without modeling batch effects.**\n\n*   **Requirement 1 (Hypothesis):** Partially met, assuming a test is performed.\n*   **Requirement 2 (Controls):** Fails. Omits the positive control.\n*   **Requirement 3 (Bias Control):** Fails. Lack of randomization across plates introduces confounding between treatment and plate effects. No mention of blinding.\n*   **Requirement 4 (Replication):** Fails. Engages in pseudo-replication (\"count each well as an independent replicate\").\n*   **Requirement 5 (Multiple Testing):** Met in principle. It uses Bonferroni correction, which is a valid but extremely conservative way to control the family-wise error rate.\n*   **Requirement 6 (Power):** Fails. With an adjusted significance level of $\\alpha_{adj} = 0.05 / 300 \\approx 0.000167$ and an unjustified sample size of $n=4$, the statistical power to detect any true effects would be infinitesimally small, rendering the experiment futile.\n\n**Verdict:** Incorrect. Although it correctly identifies the multiple testing problem, its other design flaws (pseudo-replication, lack of controls, no randomization) and the impractical combination of Bonferroni correction with a tiny sample size make it a poor design.\n\n**D. Use a single-stage experiment with $n = 10$ biological replicates per condition, randomize and blind, include negative and positive controls, and test each prediction with an uncorrected one-sided test at $\\alpha = 0.05$. Do not perform multiple testing correction; instead, apply a fold-change filter $\\geq \\delta$ and require $p < 0.05$ to declare significance. No confirmatory follow-up.**\n\n*   **Requirement 1 (Hypothesis):** Met. Correctly uses a one-sided test.\n*   **Requirement 2 (Controls):** Met. Includes both negative and positive controls.\n*   **Requirement 3 (Bias Control):** Met. Includes randomization and blinding.\n*   **Requirement 4 (Replication):** Met. Correctly uses a reasonable number ($n=10$) of *biological* replicates.\n*   **Requirement 5 (Multiple Testing):** Fails. Critically, it explicitly states \"Do not perform multiple testing correction,\" which is unacceptable for an experiment with $m=300$ hypotheses.\n*   **Requirement 6 (Power):** Partially met. The sample size $n=10$ is reasonable and likely to achieve adequate power (our calculation for $\\alpha=0.05$ yielded $n=7$), but the protocol does not commit to deriving it from first principles.\n\n**Verdict:** Incorrect. This protocol has several good features, but the complete omission of multiple testing correction is a fatal flaw that invalidates any conclusions drawn from the screen.\n\n**Conclusion:** Protocol B is the only option that satisfies all requirements of a rigorous, statistically sound, and well-designed validation experiment. It demonstrates a sophisticated understanding of experimental design principles, including staged design, power analysis, control of error rates, and mitigation of batch effects.",
            "answer": "$$\\boxed{B}$$"
        }
    ]
}