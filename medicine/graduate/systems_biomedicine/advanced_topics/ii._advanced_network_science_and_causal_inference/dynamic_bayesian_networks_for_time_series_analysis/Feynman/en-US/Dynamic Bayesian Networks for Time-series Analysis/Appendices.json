{
    "hands_on_practices": [
        {
            "introduction": "The fundamental task in analyzing time-series data with a Dynamic Bayesian Network (DBN) is tracking the evolution of hidden states given a sequence of observations, a process known as filtering. This is achieved through a recursive application of prediction and update steps, derived from the laws of probability and the model's Markov assumptions. This exercise provides hands-on practice with the core filtering algorithm, allowing you to gain a concrete understanding of how evidence is incorporated and propagated through the network by manually calculating belief states .",
            "id": "4336551",
            "problem": "Consider a gene-regulatory time-series modeled by a Dynamic Bayesian Network (DBN), where the hidden variables are a transcription factor activity $T_t \\in \\{0,1\\}$ and a gene activation state $G_t \\in \\{0,1\\}$, and the observed variable is a discretized expression measurement $Y_t \\in \\{0,1\\}$ at time $t$. The DBN is defined by the following structure: an initial prior $p(T_1)$ and $p(G_1 \\mid T_1)$; Markovian transitions $p(T_t \\mid T_{t-1})$ and $p(G_t \\mid G_{t-1}, T_t)$; and an emission model $p(Y_t \\mid G_t)$. The Conditional Probability Tables (CPTs) are given below (all numbers are probabilities):\n\n- Initial prior for the transcription factor: $p(T_1=1) = 0.6$, $p(T_1=0) = 0.4$.\n- Initial gene state given the transcription factor: $p(G_1=1 \\mid T_1=1) = 0.7$, $p(G_1=0 \\mid T_1=1) = 0.3$; $p(G_1=1 \\mid T_1=0) = 0.2$, $p(G_1=0 \\mid T_1=0) = 0.8$.\n- Transcription factor dynamics: $p(T_t=1 \\mid T_{t-1}=1) = 0.8$, $p(T_t=0 \\mid T_{t-1}=1) = 0.2$; $p(T_t=1 \\mid T_{t-1}=0) = 0.3$, $p(T_t=0 \\mid T_{t-1}=0) = 0.7$.\n- Gene dynamics conditioned on previous gene state and current transcription factor: $p(G_t=1 \\mid G_{t-1}=1, T_t=1) = 0.9$, $p(G_t=0 \\mid G_{t-1}=1, T_t=1) = 0.1$; $p(G_t=1 \\mid G_{t-1}=0, T_t=1) = 0.5$, $p(G_t=0 \\mid G_{t-1}=0, T_t=1) = 0.5$; $p(G_t=1 \\mid G_{t-1}=1, T_t=0) = 0.6$, $p(G_t=0 \\mid G_{t-1}=1, T_t=0) = 0.4$; $p(G_t=1 \\mid G_{t-1}=0, T_t=0) = 0.1$, $p(G_t=0 \\mid G_{t-1}=0, T_t=0) = 0.9$.\n- Emission model: $p(Y_t=1 \\mid G_t=1) = 0.85$, $p(Y_t=0 \\mid G_t=1) = 0.15$; $p(Y_t=1 \\mid G_t=0) = 0.2$, $p(Y_t=0 \\mid G_t=0) = 0.8$.\n\nYou observe the sequence $y_{1:3} = (y_1, y_2, y_3) = (1, 0, 1)$. Using the fundamental basis of Bayes’ theorem, the law of total probability, and the Markov property encoded by the DBN conditional independencies, perform exact filtering to compute the normalized joint beliefs $p(T_t, G_t \\mid y_{1:t})$ for $t \\in \\{1,2,3\\}$ for the ordered state pairs $(T_t,G_t) \\in \\{(1,1),(1,0),(0,1),(0,0)\\}$.\n\nFinally, compute the posterior probability $p(G_3 = 1 \\mid y_{1:3})$ and report this as your final answer. Round your final answer to four significant figures. Express the final answer as a pure number (no units and no percentage sign).",
            "solution": "The problem requires performing exact filtering on a Dynamic Bayesian Network (DBN) to compute the posterior probability of hidden states given a sequence of observations. The hidden state at time $t$ is a composite variable $X_t = (T_t, G_t)$, where $T_t$ is the transcription factor activity and $G_t$ is the gene activation state. The state space for $X_t$ consists of $4$ possible states, which we will consistently order as $\\{(1,1), (1,0), (0,1), (0,0)\\}$. The observation at time $t$ is $Y_t$. We are given the observation sequence $y_{1:3}=(1,0,1)$.\n\nThe filtering task is to compute the posterior distribution $p(X_t \\mid y_{1:t})$ for $t=1, 2, 3$. This is achieved via a recursive process involving a prediction step and an update step. Let $\\pi_t(X_t) \\equiv p(X_t \\mid y_{1:t})$ be the filtered belief at time $t$.\n\nThe recursion is as follows:\n1.  **Prediction**: The one-step-ahead prediction of the state is given by the Chapman-Kolmogorov equation:\n    $$p(X_t \\mid y_{1:t-1}) = \\sum_{X_{t-1}} p(X_t \\mid X_{t-1}) p(X_{t-1} \\mid y_{1:t-1})$$\n    The transition probability $p(X_t \\mid X_{t-1})$ is determined by the DBN structure: $p(X_t \\mid X_{t-1}) = p(T_t, G_t \\mid T_{t-1}, G_{t-1}) = p(T_t \\mid T_{t-1}) p(G_t \\mid G_{t-1}, T_t)$.\n\n2.  **Update**: The predicted distribution is updated using the observation $y_t$ via Bayes' rule:\n    $$p(X_t \\mid y_{1:t}) = \\frac{p(y_t \\mid X_t, y_{1:t-1}) p(X_t \\mid y_{1:t-1})}{p(y_t \\mid y_{1:t-1})}$$\n    Given the DBN structure, the emission $Y_t$ is conditionally independent of past states and observations given the current state $X_t$. Specifically, $p(y_t \\mid X_t, y_{1:t-1}) = p(y_t \\mid X_t) = p(y_t \\mid G_t)$. The denominator is a normalization constant. Thus, the update can be written as:\n    $$\\pi_t(X_t) \\propto p(y_t \\mid G_t) p(X_t \\mid y_{1:t-1})$$\n\nWe will now apply this process for $t=1, 2, 3$.\n\n**Time Step $t=1$**\n\nFor $t=1$, the \"prediction\" is simply the prior distribution over the initial state $X_1$.\nThe prior joint probability is $p(X_1) = p(T_1, G_1) = p(T_1) p(G_1 \\mid T_1)$.\n$p(T_1=1, G_1=1) = p(T_1=1) p(G_1=1 \\mid T_1=1) = 0.6 \\times 0.7 = 0.42$.\n$p(T_1=1, G_1=0) = p(T_1=1) p(G_1=0 \\mid T_1=1) = 0.6 \\times 0.3 = 0.18$.\n$p(T_1=0, G_1=1) = p(T_1=0) p(G_1=1 \\mid T_1=0) = 0.4 \\times 0.2 = 0.08$.\n$p(T_1=0, G_1=0) = p(T_1=0) p(G_1=0 \\mid T_1=0) = 0.4 \\times 0.8 = 0.32$.\n\nNext, we update this prior with the observation $y_1=1$. The unnormalized posterior (forward message) $\\alpha_1(X_1)$ is:\n$\\alpha_1(X_1) = p(y_1 \\mid G_1) p(X_1)$.\nEmission probabilities for $y_1=1$: $p(Y_1=1 \\mid G_1=1) = 0.85$, $p(Y_1=1 \\mid G_1=0) = 0.2$.\n$\\alpha_1(1,1) = p(Y_1=1 \\mid G_1=1) p(1,1) = 0.85 \\times 0.42 = 0.357$.\n$\\alpha_1(1,0) = p(Y_1=1 \\mid G_1=0) p(1,0) = 0.20 \\times 0.18 = 0.036$.\n$\\alpha_1(0,1) = p(Y_1=1 \\mid G_1=1) p(0,1) = 0.85 \\times 0.08 = 0.068$.\n$\\alpha_1(0,0) = p(Y_1=1 \\mid G_1=0) p(0,0) = 0.20 \\times 0.32 = 0.064$.\n\nThe normalization constant is $Z_1 = \\sum_{X_1} \\alpha_1(X_1) = 0.357 + 0.036 + 0.068 + 0.064 = 0.525$.\nThe filtered belief $\\pi_1(X_1)=p(X_1 \\mid y_1)$ is:\n$\\pi_1(1,1) = 0.357 / 0.525 = 0.68$.\n$\\pi_1(1,0) = 0.036 / 0.525 \\approx 0.06857$.\n$\\pi_1(0,1) = 0.068 / 0.525 \\approx 0.12952$.\n$\\pi_1(0,0) = 0.064 / 0.525 \\approx 0.12190$.\n\n**Time Step $t=2$**\n\nFirst, the prediction step. We compute $p(X_2 \\mid y_1) = \\sum_{X_1} p(X_2 \\mid X_1) \\pi_1(X_1)$.\n$p(X_2=(T_2,G_2) \\mid y_1) = \\sum_{T_1,G_1} p(T_2 \\mid T_1) p(G_2 \\mid G_1, T_2) \\pi_1(T_1, G_1)$.\nThis calculation is performed for each of the $4$ states of $X_2$. For brevity, we present the results for the predicted probability vector $(p(1,1 \\mid y_1), p(1,0 \\mid y_1), p(0,1 \\mid y_1), p(0,0 \\mid y_1))$:\n$p(X_2 \\mid y_1) \\approx (0.57029, 0.10400, 0.14590, 0.17981)$. These are calculated as sums of products of transition probabilities and the $\\pi_1$ vector.\nPredicted probabilities for all $4$ states of $X_2$ can be written exactly as: $(\\frac{299.4}{525}, \\frac{54.6}{525}, \\frac{76.6}{525}, \\frac{94.4}{525})$.\n\nNext, we update with the observation $y_2=0$. Emission probabilities for $y_2=0$: $p(Y_2=0 \\mid G_2=1) = 0.15$, $p(Y_2=0 \\mid G_2=0) = 0.8$.\nThe unnormalized posterior is $\\alpha_2(X_2) = p(y_2 \\mid G_2) p(X_2 \\mid y_1)$.\n$\\alpha_2(1,1) = 0.15 \\times (299.4/525) = 44.91/525$.\n$\\alpha_2(1,0) = 0.80 \\times (54.6/525) = 43.68/525$.\n$\\alpha_2(0,1) = 0.15 \\times (76.6/525) = 11.49/525$.\n$\\alpha_2(0,0) = 0.80 \\times (94.4/525) = 75.52/525$.\n\nThe normalization constant is $Z_2 = \\sum_{X_2} \\alpha_2(X_2) = (44.91 + 43.68 + 11.49 + 75.52) / 525 = 175.6/525$.\nThe filtered belief $\\pi_2(X_2)=p(X_2 \\mid y_{1:2})$ is:\n$\\pi_2(1,1) = (44.91/525) / (175.6/525) = 44.91 / 175.6 \\approx 0.25575$.\n$\\pi_2(1,0) = 43.68 / 175.6 \\approx 0.24875$.\n$\\pi_2(0,1) = 11.49 / 175.6 \\approx 0.06543$.\n$\\pi_2(0,0) = 75.52 / 175.6 \\approx 0.43007$.\n\n**Time Step $t=3$**\n\nPrediction step: $p(X_3 \\mid y_{1:2}) = \\sum_{X_2} p(X_3 \\mid X_2) \\pi_2(X_2)$.\nThe predicted probability vector for $X_3$, written with exact fractions:\n$p(X_3 \\mid y_{1:2}) = (\\frac{64.2375}{175.6}, \\frac{32.7375}{175.6}, \\frac{16.375}{175.6}, \\frac{62.25}{175.6})$.\n\nUpdate with the observation $y_3=1$. Emission probabilities for $y_3=1$: $p(Y_3=1 \\mid G_3=1) = 0.85$, $p(Y_3=1 \\mid G_3=0) = 0.2$.\nThe unnormalized posterior is $\\alpha_3(X_3) = p(y_3 \\mid G_3) p(X_3 \\mid y_{1:2})$.\n$\\alpha_3(1,1) = 0.85 \\times (64.2375/175.6) = 54.601875/175.6$.\n$\\alpha_3(1,0) = 0.20 \\times (32.7375/175.6) = 6.5475/175.6$.\n$\\alpha_3(0,1) = 0.85 \\times (16.375/175.6) = 13.91875/175.6$.\n$\\alpha_3(0,0) = 0.20 \\times (62.25/175.6) = 12.45/175.6$.\n\nNormalization constant $Z_3 = \\sum_{X_3} \\alpha_3(X_3) = (54.601875 + 6.5475 + 13.91875 + 12.45) / 175.6 = 87.518125/175.6$.\nThe filtered belief $\\pi_3(X_3)=p(X_3 \\mid y_{1:3})$ is:\n$\\pi_3(1,1) = 54.601875 / 87.518125 \\approx 0.62388$.\n$\\pi_3(1,0) = 6.5475 / 87.518125 \\approx 0.07481$.\n$\\pi_3(0,1) = 13.91875 / 87.518125 \\approx 0.15904$.\n$\\pi_3(0,0) = 12.45 / 87.518125 \\approx 0.14225$.\n\n**Final Answer Calculation**\n\nThe problem asks for the posterior probability $p(G_3=1 \\mid y_{1:3})$. This is obtained by marginalizing the joint posterior distribution $p(T_3, G_3 \\mid y_{1:3})$ over the variable $T_3$.\n$$p(G_3=1 \\mid y_{1:3}) = \\sum_{T_3 \\in \\{0,1\\}} p(T_3, G_3=1 \\mid y_{1:3})$$\n$$p(G_3=1 \\mid y_{1:3}) = p(T_3=1, G_3=1 \\mid y_{1:3}) + p(T_3=0, G_3=1 \\mid y_{1:3})$$\n$$p(G_3=1 \\mid y_{1:3}) = \\pi_3(1,1) + \\pi_3(0,1)$$\nUsing the unrounded values for maximum precision:\n$$p(G_3=1 \\mid y_{1:3}) = \\frac{54.601875}{87.518125} + \\frac{13.91875}{87.518125} = \\frac{54.601875 + 13.91875}{87.518125} = \\frac{68.520625}{87.518125}$$\n$$p(G_3=1 \\mid y_{1:3}) \\approx 0.78293605$$\nRounding the result to four significant figures gives $0.7829$.",
            "answer": "$$\\boxed{0.7829}$$"
        },
        {
            "introduction": "While filtering assumes a known model, a more common scenario in systems biomedicine is learning a model's parameters directly from experimental data. The Expectation-Maximization (EM) algorithm, specifically the Baum-Welch algorithm for Hidden Markov Models, provides a powerful framework for this task. This practice problem guides you through a complete cycle of the algorithm, applying the forward-backward algorithm to compute smoothed posteriors and using them to derive an updated parameter estimate, thus demonstrating how DBNs can be learned from data .",
            "id": "4336550",
            "problem": "Consider a Dynamic Bayesian Network (DBN) representation of a two-state Hidden Markov Model (HMM) for a single gene’s regulatory activity in systems biomedicine. The latent regulatory state is denoted by $Z_t \\in \\{1,2\\}$, where $Z_t=1$ denotes an inactive state and $Z_t=2$ denotes an active state. The observed expression measurement at time $t$ is a continuous variable $Y_t \\in \\mathbb{R}$. The model obeys the first-order Markov property and conditional independence between observations given the latent state, with the following components as the fundamental basis:\n- The initial distribution $p(Z_1=i)=\\pi_i$.\n- The transition distribution $p(Z_t=j \\mid Z_{t-1}=i)=a_{ij}$, where for each $i$, $\\sum_{j} a_{ij}=1$ and $a_{ij} \\ge 0$.\n- The emission distribution $p(Y_t \\mid Z_t=i)$.\n\nAssume the emission model is Gaussian: $Y_t \\mid Z_t=i \\sim \\mathcal{N}(\\mu_i,\\sigma^2)$ with $\\mu_1=0$, $\\mu_2=2$, and $\\sigma^2=1$. The HMM parameters for the latent dynamics are:\n- Initial distribution $\\pi_1=0.6$, $\\pi_2=0.4$.\n- Transition matrix entries $a_{11}=0.85$, $a_{12}=0.15$, $a_{21}=0.30$, $a_{22}=0.70$.\n\nYou observe the time series $Y_1=0.3$, $Y_2=1.9$, $Y_3=2.1$ (i.e., $T=3$). Using the forward-backward algorithm derived from the joint factorization $p(Z_{1:T},Y_{1:T}) = p(Z_1)\\prod_{t=2}^{T}p(Z_t\\mid Z_{t-1})\\prod_{t=1}^{T}p(Y_t\\mid Z_t)$ and the definition of conditional expectations, compute the expected transition counts $\\mathbb{E}\\left[\\mathbb{I}\\{Z_{t-1}=1,Z_t=2\\}\\mid Y_{1:3}\\right]$ for $t=2$ and $t=3$, and use them to perform the maximum-likelihood update of the transition probability $p(Z_t=2\\mid Z_{t-1}=1)$ under the normalization constraint $\\sum_{j} a_{1j}=1$.\n\nProvide the final updated value of $p(Z_t=2\\mid Z_{t-1}=1)$ as a single real number. Round your answer to four significant figures. Express the probability as a decimal (no percentage sign).",
            "solution": "The objective is to find the M-step update for the transition probability $a_{12} = p(Z_t=2 \\mid Z_{t-1}=1)$. The general formula for the re-estimation of $a_{ij}$ in the Baum-Welch algorithm is the ratio of the expected number of transitions from state $i$ to state $j$, to the expected number of transitions out of state $i$.\n$$\n\\hat{a}_{ij} = \\frac{\\sum_{t=2}^{T} p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T})}{\\sum_{k=1}^{2} \\sum_{t=2}^{T} p(Z_{t-1}=i, Z_t=k \\mid Y_{1:T})} = \\frac{\\sum_{t=2}^{T} p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T})}{\\sum_{t=1}^{T-1} p(Z_t=i \\mid Y_{1:T})}\n$$\nThe quantities $p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T})$ and $p(Z_t=i \\mid Y_{1:T})$ are the smoothed posterior probabilities, which are computed using the forward-backward algorithm.\n\nLet $\\alpha_t(i) = p(Y_{1:t}, Z_t=i)$ be the forward variable and $\\beta_t(i) = p(Y_{t+1:T} \\mid Z_t=i)$ be the backward variable.\nThe smoothed probability for a single state $Z_t$ is denoted by $\\gamma_t(i)$:\n$$\n\\gamma_t(i) = p(Z_t=i \\mid Y_{1:T}) = \\frac{\\alpha_t(i)\\beta_t(i)}{p(Y_{1:T})}\n$$\nThe smoothed probability for a pair of consecutive states $(Z_{t-1}, Z_t)$ is denoted by $\\xi_t(i,j)$:\n$$\n\\xi_t(i,j) = p(Z_{t-1}=i, Z_t=j \\mid Y_{1:T}) = \\frac{\\alpha_{t-1}(i) a_{ij} p(Y_t \\mid Z_t=j) \\beta_t(j)}{p(Y_{1:T})}\n$$\nThe likelihood of the observation sequence is $p(Y_{1:T}) = \\sum_{i=1}^2 \\alpha_T(i)$.\n\nWith $T=3$, the update formula for $a_{12}$ becomes:\n$$\n\\hat{a}_{12} = \\frac{\\xi_2(1,2) + \\xi_3(1,2)}{\\gamma_1(1) + \\gamma_2(1)}\n$$\n\n**Step I: Emission Probabilities**\nLet $b_i(Y_t) = p(Y_t \\mid Z_t=i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(Y_t - \\mu_i)^2}{2\\sigma^2}\\right)$. With $\\sigma^2=1$:\n-   $Y_1=0.3$:\n    $b_1(Y_1) = \\mathcal{N}(0.3; 0, 1) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-0.045) \\approx 0.381384$\n    $b_2(Y_1) = \\mathcal{N}(0.3; 2, 1) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-1.445) \\approx 0.094045$\n-   $Y_2=1.9$:\n    $b_1(Y_2) = \\mathcal{N(1.9; 0, 1)} = \\frac{1}{\\sqrt{2\\pi}} \\exp(-1.805) \\approx 0.065616$\n    $b_2(Y_2) = \\mathcal{N(1.9; 2, 1)} = \\frac{1}{\\sqrt{2\\pi}} \\exp(-0.005) \\approx 0.396953$\n-   $Y_3=2.1$:\n    $b_1(Y_3) = \\mathcal{N(2.1; 0, 1)} = \\frac{1}{\\sqrt{2\\pi}} \\exp(-2.205) \\approx 0.043984$\n    $b_2(Y_3) = \\mathcal{N(2.1; 2, 1)} = \\frac{1}{\\sqrt{2\\pi}} \\exp(-0.005) \\approx 0.396953$\n\n**Step II: Forward Pass ($\\alpha_t(i)$)**\n-   $t=1$:\n    $\\alpha_1(1) = \\pi_1 b_1(Y_1) = 0.6 \\times 0.381384 = 0.228830$\n    $\\alpha_1(2) = \\pi_2 b_2(Y_1) = 0.4 \\times 0.094045 = 0.037618$\n-   $t=2$:\n    $\\alpha_2(1) = (\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}) b_1(Y_2) = (0.228830 \\times 0.85 + 0.037618 \\times 0.30) \\times 0.065616 = 0.205791 \\times 0.065616 \\approx 0.013504$\n    $\\alpha_2(2) = (\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}) b_2(Y_2) = (0.228830 \\times 0.15 + 0.037618 \\times 0.70) \\times 0.396953 = 0.060657 \\times 0.396953 \\approx 0.024078$\n-   $t=3$:\n    $\\alpha_3(1) = (\\alpha_2(1)a_{11} + \\alpha_2(2)a_{21}) b_1(Y_3) = (0.013504 \\times 0.85 + 0.024078 \\times 0.30) \\times 0.043984 = 0.018702 \\times 0.043984 \\approx 0.00082256$\n    $\\alpha_3(2) = (\\alpha_2(1)a_{12} + \\alpha_2(2)a_{22}) b_2(Y_3) = (0.013504 \\times 0.15 + 0.024078 \\times 0.70) \\times 0.396953 = 0.018880 \\times 0.396953 \\approx 0.00749448$\n-   Data likelihood: $p(Y_{1:3}) = \\alpha_3(1) + \\alpha_3(2) \\approx 0.00082256 + 0.00749448 = 0.00831704$\n\n**Step III: Backward Pass ($\\beta_t(i)$)**\n-   $t=3$: $\\beta_3(1) = 1, \\beta_3(2) = 1$.\n-   $t=2$:\n    $\\beta_2(1) = a_{11}b_1(Y_3)\\beta_3(1) + a_{12}b_2(Y_3)\\beta_3(2) = (0.85 \\times 0.043984) + (0.15 \\times 0.396953) = 0.037386 + 0.059543 = 0.096929$\n    $\\beta_2(2) = a_{21}b_1(Y_3)\\beta_3(1) + a_{22}b_2(Y_3)\\beta_3(2) = (0.30 \\times 0.043984) + (0.70 \\times 0.396953) = 0.013195 + 0.277867 = 0.291062$\n-   $t=1$:\n    $\\beta_1(1) = a_{11}b_1(Y_2)\\beta_2(1) + a_{12}b_2(Y_2)\\beta_2(2) = (0.85 \\times 0.065616 \\times 0.096929) + (0.15 \\times 0.396953 \\times 0.291062) = 0.005405 + 0.017329 = 0.022734$\n    $\\beta_1(2) = a_{21}b_1(Y_2)\\beta_2(1) + a_{22}b_2(Y_2)\\beta_2(2) = (0.30 \\times 0.065616 \\times 0.096929) + (0.70 \\times 0.396953 \\times 0.291062) = 0.001908 + 0.080870 = 0.082778$\n\n**Step IV: Smoothed Probabilities**\n-   $\\gamma_t(i)$ computation:\n    $\\gamma_1(1) = \\frac{\\alpha_1(1)\\beta_1(1)}{p(Y_{1:3})} = \\frac{0.228830 \\times 0.022734}{0.00831704} \\approx 0.62557$\n    $\\gamma_2(1) = \\frac{\\alpha_2(1)\\beta_2(1)}{p(Y_{1:3})} = \\frac{0.013504 \\times 0.096929}{0.00831704} \\approx 0.15738$\n    The denominator for the update rule is $\\gamma_1(1) + \\gamma_2(1) \\approx 0.62557 + 0.15738 = 0.78295$.\n\n-   $\\xi_t(i,j)$ computation for the numerator:\n    $\\xi_2(1,2) = \\frac{\\alpha_1(1) a_{12} b_2(Y_2) \\beta_2(2)}{p(Y_{1:3})} = \\frac{0.228830 \\times 0.15 \\times 0.396953 \\times 0.291062}{0.00831704} = \\frac{0.0039665}{0.00831704} \\approx 0.47691$\n    $\\xi_3(1,2) = \\frac{\\alpha_2(1) a_{12} b_2(Y_3) \\beta_3(2)}{p(Y_{1:3})} = \\frac{0.013504 \\times 0.15 \\times 0.396953 \\times 1}{0.00831704} = \\frac{0.00080447}{0.00831704} \\approx 0.096726$\n    The numerator for the update rule is $\\xi_2(1,2) + \\xi_3(1,2) \\approx 0.47691 + 0.096726 = 0.573636$.\n\n**Step V: Parameter Update**\nThe updated transition probability $\\hat{a}_{12}$ is:\n$$\n\\hat{a}_{12} = \\frac{\\xi_2(1,2) + \\xi_3(1,2)}{\\gamma_1(1) + \\gamma_2(1)} = \\frac{0.573636}{0.78295} \\approx 0.73266\n$$\nRounding to four significant figures, the result is $0.7327$.",
            "answer": "$$\\boxed{0.7327}$$"
        },
        {
            "introduction": "A primary goal in systems biology is to predict the effects of experimental interventions, such as gene knockouts or drug treatments. DBNs can be extended into powerful causal models to answer such \"what-if\" questions by formally modifying the graph structure to represent the act of exogenously setting a variable's value. This exercise will guide you through the process of formalizing an intervention within the DBN framework, connecting the probabilistic semantics of the model to the principles of causal inference for predictive modeling of experimental perturbations .",
            "id": "4336566",
            "problem": "In a systems biomedicine setting, consider a regulatory module modeled as a Dynamic Bayesian Network (DBN), represented with a Two-slice Temporal Bayesian Network (2TBN). The module contains three discrete-valued biological state variables at each time index $t \\in \\{0,1,\\dots,T\\}$: a transcription factor $X_t$, a downstream gene product $Y_t$, and a post-translational modification state $Z_t$. Assume a first-order Markov property across time slices and no intra-slice edges, with inter-slice parent sets given by $\\mathrm{Pa}(X_t)=\\{X_{t-1},Z_{t-1}\\}$, $\\mathrm{Pa}(Y_t)=\\{X_{t-1},Y_{t-1}\\}$, and $\\mathrm{Pa}(Z_t)=\\{Y_{t-1},Z_{t-1}\\}$. Let $p(X_0,Y_0,Z_0)$ denote the initial-joint distribution at time $t=0$, and for $t \\ge 1$ let $p(X_t \\mid X_{t-1},Z_{t-1})$, $p(Y_t \\mid X_{t-1},Y_{t-1})$, and $p(Z_t \\mid Y_{t-1},Z_{t-1})$ denote the observational conditional probability distributions (CPDs).\n\nYou are asked to incorporate explicit intervention nodes to represent time-localized experimental perturbations. Introduce a binary intervention node $I_t \\in \\{0,1\\}$ for each time $t \\in \\{1,\\dots,T\\}$, with a directed edge $I_t \\to X_t$, whose semantics are: when $I_t=0$ the observational dynamics for $X_t$ apply, and when $I_t=1$ the variable $X_t$ is exogenously set to a fixed value $x^{\\star}$ independent of its parents. Consider a single hard intervention applied at a particular time $t_{\\mathrm{int}} \\in \\{1,\\dots,T\\}$, where $I_{t_{\\mathrm{int}}}=1$ and $X_{t_{\\mathrm{int}}}$ is thereby forced to $x^{\\star}$, while for all $t \\ne t_{\\mathrm{int}}$ we have $I_t=0$. Let $\\delta_{a,b}$ denote the Kronecker delta, equal to $1$ if $a=b$ and $0$ otherwise.\n\nStarting only from the chain rule for joint distributions, the Bayesian network factorization rule, and the first-order Markov property defined by the two-slice template above, derive the modified factorization for the interventional joint distribution over the full trajectory $(X_0,\\dots,X_T,Y_0,\\dots,Y_T,Z_0,\\dots,Z_T)$ induced by the described intervention. Your final expression should factorize over time and clearly reflect that $X_{t_{\\mathrm{int}}}$ is set to $x^{\\star}$, while all other CPDs remain observational. Express your final answer as a single closed-form analytic expression in terms of $p(X_0,Y_0,Z_0)$, the observational CPDs, and the Kronecker delta $\\delta_{a,b}$. Do not include an equality sign in your final answer. No numerical approximation or rounding is required, and no physical units apply.",
            "solution": "We begin with the standard principles that define a Two-slice Temporal Bayesian Network (2TBN) for a Dynamic Bayesian Network (DBN). The two key foundational elements are: the chain rule for joint distributions and the Bayesian network factorization property. Together with the first-order Markov property, these imply that, over a finite horizon $t \\in \\{0,1,\\dots,T\\}$, the joint observational distribution factorizes as\n$$\np(X_0,Y_0,Z_0) \\prod_{t=1}^{T} p(X_t \\mid X_{t-1},Z_{t-1}) \\, p(Y_t \\mid X_{t-1},Y_{t-1}) \\, p(Z_t \\mid Y_{t-1},Z_{t-1}) .\n$$\nThis arises because the first-order Markov property and the specified parent sets $\\mathrm{Pa}(X_t)=\\{X_{t-1},Z_{t-1}\\}$, $\\mathrm{Pa}(Y_t)=\\{X_{t-1},Y_{t-1}\\}$, and $\\mathrm{Pa}(Z_t)=\\{Y_{t-1},Z_{t-1}\\}$ determine the conditional independences that the 2TBN encodes, and the Bayesian network factorization writes the joint as the product of each node’s conditional probability given its parents.\n\nWe now incorporate explicit intervention nodes. For each time $t \\in \\{1,\\dots,T\\}$, we add a binary intervention variable $I_t \\in \\{0,1\\}$ with a directed edge $I_t \\to X_t$. The semantics are as follows: when $I_t=0$, $X_t$ follows its observational CPD $p(X_t \\mid X_{t-1},Z_{t-1})$; when $I_t=1$, the incoming edges into $X_t$ from its observational parents are effectively cut and $X_t$ is deterministically set to a fixed value $x^{\\star}$, independent of $(X_{t-1},Z_{t-1})$. A convenient and standard way to encode this in a single conditional probability table for $X_t$ is to define\n$$\np(X_t \\mid X_{t-1},Z_{t-1},I_t) \\;=\\; (1-I_t)\\, p(X_t \\mid X_{t-1},Z_{t-1}) \\;+\\; I_t \\, \\delta_{X_t,\\,x^{\\star}} ,\n$$\nwhere $\\delta_{a,b}$ is the Kronecker delta, equal to $1$ when $a=b$ and $0$ otherwise. This defines a valid conditional distribution for $X_t$ because it is a convex combination of two valid conditionals for all $I_t \\in \\{0,1\\}$ and sums to $1$ over the support of $X_t$.\n\nWith these intervention nodes added, the augmented Bayesian network over $(X_{0:T},Y_{0:T},Z_{0:T},I_{1:T})$ factorizes as\n$$\np(X_0,Y_0,Z_0)\\,\\prod_{t=1}^{T} p(I_t)\\, p(X_t \\mid X_{t-1},Z_{t-1},I_t)\\, p(Y_t \\mid X_{t-1},Y_{t-1})\\, p(Z_t \\mid Y_{t-1},Z_{t-1}) .\n$$\nHere $p(I_t)$ are arbitrary exogenous priors for the intervention nodes. Under a hard, time-localized intervention at $t_{\\mathrm{int}} \\in \\{1,\\dots,T\\}$ that sets $I_{t_{\\mathrm{int}}}=1$ and $I_t=0$ for all $t \\ne t_{\\mathrm{int}}$, we appeal to the intervention semantics that fix those variables and remove the need to include their probabilities in the interventional distribution over the biological state variables $(X_{0:T},Y_{0:T},Z_{0:T})$. Concretely, the interventional joint distribution $p_{\\mathrm{do}}(X_{0:T},Y_{0:T},Z_{0:T})$ is obtained by replacing the observational factor $p(X_{t_{\\mathrm{int}}} \\mid X_{t_{\\mathrm{int}}-1},Z_{t_{\\mathrm{int}}-1})$ with the degenerate factor $\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}$, while leaving all other factors unchanged. This is a direct consequence of the Bayesian network factorization with the modified conditional for $X_{t_{\\mathrm{int}}}$ induced by $I_{t_{\\mathrm{int}}}=1$, together with $I_t=0$ for all $t \\ne t_{\\mathrm{int}}$ which restores the observational conditional for $X_t$ at those times.\n\nTherefore, the modified factorization for the interventional joint over the full trajectory of biological states is\n$$\np(X_0,Y_0,Z_0)\\;\n\\left[\\prod_{\\substack{t=1\\\\ t \\ne t_{\\mathrm{int}}}}^{T} p(X_t \\mid X_{t-1},Z_{t-1})\\right]\\;\n\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}\\;\n\\left[\\prod_{t=1}^{T} p(Y_t \\mid X_{t-1},Y_{t-1})\\; p(Z_t \\mid Y_{t-1},Z_{t-1})\\right] .\n$$\nThis expression reflects exactly the intervention’s effect: the factor for $X_{t_{\\mathrm{int}}}$ is replaced by $\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}$, encoding that $X_{t_{\\mathrm{int}}}$ is fixed to $x^{\\star}$, while all other factors remain observational and preserve the original time-factorized structure implied by the 2TBN. The downstream impact of the intervention propagates forward in time through the unchanged observational CPDs that depend on $X_{t}$ for $t \\ge t_{\\mathrm{int}}+1$.",
            "answer": "$$\\boxed{p(X_0,Y_0,Z_0)\\,\\left[\\prod_{\\substack{t=1\\\\ t \\ne t_{\\mathrm{int}}}}^{T} p(X_t \\mid X_{t-1},Z_{t-1})\\right]\\,\\delta_{X_{t_{\\mathrm{int}}},\\,x^{\\star}}\\,\\left[\\prod_{t=1}^{T} p(Y_t \\mid X_{t-1},Y_{t-1})\\,p(Z_t \\mid Y_{t-1},Z_{t-1})\\right]}$$"
        }
    ]
}