{
    "hands_on_practices": [
        {
            "introduction": "At the heart of cellular decision-making lies the ability to commit to distinct, stable fates. This practice explores how a common molecular motif, the self-activating gene circuit, can generate such robust behavior through bistability. By analyzing the system's nonlinear dynamics, you will derive the precise conditions under which this cellular switch operates, revealing how its robustness is inherently fragile to shifts in the underlying biochemical parameters of feedback gain $A$ and ultrasensitivity $n$ . This exercise provides a foundational understanding of how robust phenotypes can emerge from simple circuits, and the trade-offs that govern their existence.",
            "id": "4339395",
            "problem": "Consider a self-activating gene circuit modeled as a single-species ordinary differential equation (ODE) for the concentration $x(t)$ of a transcription factor that activates its own expression. The production rate is given by a Hill function with coefficient $n$ and half-saturation constant $K$, scaled by a feedback gain $A$, and the degradation is linear with rate constant $\\beta$. The dynamics are\n$$\n\\frac{dx}{dt} \\;=\\; A \\,\\frac{x^{n}}{K^{n} + x^{n}} \\;-\\; \\beta\\, x \\,,\n$$\nwhere $A > 0$, $K > 0$, $\\beta > 0$, and $n \\ge 1$. The Hill function captures ultrasensitivity when $n > 1$. The robustness-fragility trade-off in systems biomedicine predicts that ultrasensitive positive feedback can generate bistability and hysteresis that are robust to small perturbations in state $x$, yet fragile to parameter shifts in $n$ and $A$.\n\nStarting from the foundational facts of deterministic nonlinear dynamics that a saddle-node (fold) bifurcation occurs when a steady state satisfies both the equilibrium condition and loss of normal hyperbolicity (the derivative of the vector field with respect to $x$ vanishes at the steady state), and using only the definition of the Hill function, derive the precise condition under which the system exhibits bistability and hysteresis. In particular:\n\n- Determine the analytic threshold on the feedback gain $A$ in terms of the Hill coefficient $n$, the half-saturation constant $K$, and the degradation rate $\\beta$, at which a saddle-node bifurcation first appears and bistability is created for $n > 1$.\n- Explain how this threshold implies robustness to small perturbations in $x$ (local stability of the two outer equilibria) but fragility to parameter shifts (loss of bistability when $A$ or $n$ crosses the threshold), without invoking stochastic dynamics.\n\nYour final answer must be the closed-form analytic expression for the critical gain $A_{c}(n, K, \\beta)$ at the onset of bistability. Express your final answer for $A_{c}$ in units of concentration per time. No numerical evaluation or rounding is needed.",
            "solution": "The problem requires the derivation of the critical condition for bistability in a self-activating gene circuit, based on the principles of nonlinear dynamics, specifically the occurrence of a saddle-node bifurcation. We must also explain the implied robustness-fragility trade-off.\n\nThe dynamics of the system are described by the ordinary differential equation (ODE) for the protein concentration $x(t)$:\n$$\n\\frac{dx}{dt} = f(x; A, K, \\beta, n) = A \\frac{x^{n}}{K^{n} + x^{n}} - \\beta x\n$$\nThe parameters are the feedback gain $A > 0$, the half-saturation constant $K > 0$, the degradation rate $\\beta > 0$, and the Hill coefficient $n \\ge 1$.\n\nA steady state, denoted by $x_{ss}$, is a concentration where the rate of change is zero, i.e., $\\frac{dx}{dt} = 0$. This gives the equilibrium condition:\n$$\nf(x_{ss}) = A \\frac{x_{ss}^{n}}{K^{n} + x_{ss}^{n}} - \\beta x_{ss} = 0 \\quad (*_1)\n$$\nThis equation always has a trivial solution $x_{ss} = 0$. Non-trivial solutions must satisfy:\n$$\nA \\frac{x_{ss}^{n-1}}{K^{n} + x_{ss}^{n}} = \\beta\n$$\nA saddle-node bifurcation, which marks the birth of a pair of new steady states (one stable, one unstable), occurs at a critical parameter value where a steady state loses its normal hyperbolicity. This means that the linearization of the system at the steady state has a zero eigenvalue. For a one-dimensional system, this corresponds to the derivative of the right-hand side of the ODE being zero. Let the steady state at the bifurcation point be $x_{sn}$. The conditions are:\n1.  Equilibrium condition: $f(x_{sn}) = 0$.\n2.  Bifurcation condition: $\\frac{df}{dx}\\bigg|_{x=x_{sn}} = 0$.\n\nFirst, we compute the derivative of $f(x)$ with respect to $x$:\n$$\n\\frac{df}{dx} = A \\frac{d}{dx}\\left(\\frac{x^{n}}{K^{n} + x^{n}}\\right) - \\beta\n$$\nUsing the quotient rule for differentiation, $\\frac{d}{dx}\\left(\\frac{u}{v}\\right) = \\frac{\\frac{du}{dx}v - u\\frac{dv}{dx}}{v^{2}}$, with $u = x^{n}$ and $v = K^{n} + x^{n}$:\n$$\n\\frac{d}{dx}\\left(\\frac{x^{n}}{K^{n} + x^{n}}\\right) = \\frac{(nx^{n-1})(K^{n} + x^{n}) - (x^{n})(nx^{n-1})}{(K^{n} + x^{n})^{2}} = \\frac{nx^{n-1}K^{n}}{(K^{n} + x^{n})^{2}}\n$$\nThus, the derivative of $f(x)$ is:\n$$\n\\frac{df}{dx} = A \\frac{nx^{n-1}K^{n}}{(K^{n} + x^{n})^{2}} - \\beta\n$$\nThe bifurcation condition $\\frac{df}{dx}|_{x=x_{sn}} = 0$ is therefore:\n$$\nA \\frac{nx_{sn}^{n-1}K^{n}}{(K^{n} + x_{sn}^{n})^{2}} - \\beta = 0 \\quad (*_2)\n$$\nWe now have a system of two equations, $(*_1)$ and $(*_2)$, that must be satisfied simultaneously by the steady state concentration $x_{sn}$ and the critical feedback gain, which we will call $A_c$.\nFrom $(*_1)$, for a non-trivial steady state $x_{sn} > 0$:\n$$\nA_c \\frac{x_{sn}^{n-1}}{K^{n} + x_{sn}^{n}} = \\beta \\implies A_c = \\beta \\frac{K^{n} + x_{sn}^{n}}{x_{sn}^{n-1}} \\quad (Eq. 1)\n$$\nFrom $(*_2)$:\n$$\nA_c \\frac{nx_{sn}^{n-1}K^{n}}{(K^{n} + x_{sn}^{n})^{2}} = \\beta \\implies A_c = \\beta \\frac{(K^{n} + x_{sn}^{n})^{2}}{nx_{sn}^{n-1}K^{n}} \\quad (Eq. 2)\n$$\nTo find $x_{sn}$, we equate the two expressions for $A_c$:\n$$\n\\beta \\frac{K^{n} + x_{sn}^{n}}{x_{sn}^{n-1}} = \\beta \\frac{(K^{n} + x_{sn}^{n})^{2}}{nx_{sn}^{n-1}K^{n}}\n$$\nSince we are seeking a non-trivial bifurcation ($x_{sn} > 0$) and $\\beta > 0$, we can cancel $\\beta$ and the term $x_{sn}^{n-1}$. We also know $K^{n} + x_{sn}^{n} > 0$, so we can divide by it:\n$$\n1 = \\frac{K^{n} + x_{sn}^{n}}{nK^{n}}\n$$\nRearranging to solve for $x_{sn}$:\n$$\nnK^{n} = K^{n} + x_{sn}^{n}\n$$\n$$\nx_{sn}^{n} = nK^{n} - K^{n} = (n-1)K^{n}\n$$\n$$\nx_{sn} = K(n-1)^{1/n}\n$$\nThis gives the steady-state concentration at the point of the saddle-node bifurcation. For $x_{sn}$ to be a real and positive value, we must have $n-1 > 0$, which means $n > 1$. This confirms the problem's premise that ultrasensitivity ($n > 1$) is required for bistability.\n\nNow we find the critical gain $A_c$ by substituting this value of $x_{sn}$ back into one of the equations for $A_c$. Using the simpler form from $(Eq. 1)$:\n$$\nA_c = \\beta \\frac{K^{n} + x_{sn}^{n}}{x_{sn}^{n-1}}\n$$\nSubstitute $x_{sn}^n = (n-1)K^n$:\n$$\nK^{n} + x_{sn}^{n} = K^{n} + (n-1)K^{n} = nK^{n}\n$$\nSubstitute $x_{sn} = K(n-1)^{1/n}$ into the denominator:\n$$\nx_{sn}^{n-1} = \\left(K(n-1)^{1/n}\\right)^{n-1} = K^{n-1} (n-1)^{(n-1)/n}\n$$\nCombining these results gives the expression for $A_c$:\n$$\nA_c = \\beta \\frac{nK^{n}}{K^{n-1}(n-1)^{(n-1)/n}} = \\beta n K \\frac{1}{(n-1)^{(n-1)/n}}\n$$\nThis expression can be rewritten as:\n$$\nA_c = \\frac{\\beta n K}{(n-1)^{1 - 1/n}}\n$$\nBistability exists when the feedback gain $A$ is greater than this critical value, i.e., $A > A_c$. At $A=A_c$, the saddle-node bifurcation occurs, and for $A  A_c$, the system is monostable with a single steady state at $x=0$.\n\nNow, we explain the robustness-fragility trade-off:\n1.  **Robustness to State Perturbations**: For $A > A_c$, the S-shaped production curve $A \\frac{x^n}{K^n+x^n}$ intersects the linear degradation line $\\beta x$ at three points: a low stable state (near $x=0$), an intermediate unstable state, and a high stable state. The system can exist in either the 'low' (OFF) or 'high' (ON) stable state. If the system is in one of these stable states, small perturbations in the concentration $x$ will decay, and the system will return to its original state. This represents robustness to fluctuations in the dynamic variable. A large perturbation is required to push the system across the threshold defined by the unstable intermediate state to switch it from ON to OFF or vice versa. This property of maintaining a state in the face of small disturbances is a form of robustness.\n\n2.  **Fragility to Parameter Shifts**: This robustness is conditional upon the parameters of the system remaining in the bistable regime ($A > A_c$). The existence of the bistable switch is fragile with respect to changes in the parameters $A$ and $n$ that define the threshold $A_c$. If the system is in the high 'ON' state and a parameter, for example the gain $A$, is slowly decreased until it crosses the critical value $A_c$, the high stable state and the intermediate unstable state merge and annihilate in the saddle-node bifurcation. The only remaining steady state is the low 'OFF' state. Consequently, the system will undergo a catastrophic drop in concentration from the high state to the low state. A small change in the parameter $A$ around the threshold $A_c$ leads to a large, qualitative change in the system's behavior (loss of a stable state). Similarly, $A_c$ is highly sensitive to the Hill coefficient $n$, especially for $n$ close to $1$, where $A_c \\to \\infty$. A small decrease in $n$ can raise $A_c$ above the operating gain $A$, thus destroying bistability. This dependence of the system's qualitative behavior on specific parameter values is a form of fragility.\n\nIn summary, the system is robust to perturbations of its state variable $x$ but fragile to perturbations of its underlying parameters $A$ and $n$.",
            "answer": "$$\\boxed{\\frac{\\beta n K}{(n-1)^{1 - 1/n}}}$$"
        },
        {
            "introduction": "From the molecular scale, we now move to the population level to investigate how genetic architecture influences the path of evolution. The genetic variance-covariance matrix, or $\\mathbf{G}$-matrix, captures the web of correlations between traits, which can either facilitate or constrain adaptation. This exercise provides a quantitative look at this phenomenon using the multivariate breeder's equation, $\\Delta\\mathbf{\\bar{z}} = \\mathbf{G}\\beta$ . By calculating the evolutionary response to a specific selection pressure, you will see firsthand how the integrated structure of a system, while providing robustness, can render it fragile and unable to adapt when the environment demands a novel configuration of traits.",
            "id": "4339449",
            "problem": "In a systems biomedicine model, consider two interacting quantitative traits that represent coordinated immune-metabolic phenotypes in a patient population: trait $x_{1}$ is a standardized pro-inflammatory signaling activity and trait $x_{2}$ is a standardized hepatic lipid export activity. Empirically, the Genetic Variance-Covariance matrix (G-matrix) is estimated as\n$$\n\\mathbf{G}=\\begin{pmatrix}\n0.8  0.6 \\\\\n0.6  1.2\n\\end{pmatrix},\n$$\nwhere all entries are dimensionless because the traits are standardized. Suppose stabilizing clinical management is disrupted so that natural selection temporarily favors decreasing $x_{2}$ while modestly increasing $x_{1}$. The directional selection gradient vector is\n$$\n\\beta=\\begin{pmatrix}\n0.5 \\\\\n-0.25\n\\end{pmatrix}.\n$$\nUsing only fundamental quantitative genetics principles, compute the expected mean response of the trait vector and the scalar evolvability along the given selection direction. Then, explain qualitatively how an architectural change that reduces cross-trait coupling (for example, a shift toward modularity that sets the genetic covariance to zero while leaving the marginal variances unchanged) would affect evolvability and the robustness-fragility trade-off in this immune-metabolic system.\n\nExpress your single final numeric answer as the scalar evolvability along the given selection gradient. Do not round; provide the exact value without units. All intermediate quantities and symbols in your work must be written in mathematical notation.",
            "solution": "The user wants to solve a quantitative genetics problem related to evolvability and robustness in a systems biomedicine context.\n\n### Step 1: Extract Givens\n-   **Genetic Variance-Covariance Matrix (G-matrix):**\n    $$\n    \\mathbf{G}=\\begin{pmatrix}\n    0.8  0.6 \\\\\n    0.6  1.2\n    \\end{pmatrix}\n    $$\n-   **Directional Selection Gradient Vector ($\\beta$):**\n    $$\n    \\beta=\\begin{pmatrix}\n    0.5 \\\\\n    -0.25\n    \\end{pmatrix}\n    $$\n-   **Traits:** $x_{1}$ (pro-inflammatory signaling) and $x_{2}$ (hepatic lipid export).\n-   **Qualitative scenario:** An architectural change that sets genetic covariance to zero while leaving marginal variances unchanged.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded:** The problem uses the multivariate breeder's equation, a cornerstone of evolutionary quantitative genetics. The concepts of the G-matrix, selection gradient, evolvability, and the robustness-fragility trade-off are central to modern evolutionary biology and its application in systems medicine. The scenario is scientifically plausible.\n2.  **Well-Posed:** The problem is well-posed. It provides all necessary data (the matrix $\\mathbf{G}$ and the vector $\\beta$) to compute the requested quantitative values. The definitions of mean response and scalar evolvability are standard and lead to a unique solution.\n3.  **Objective:** The problem is stated in precise, objective, and mathematical language.\n4.  **Completeness and Consistency:** The problem is self-contained. The G-matrix provided is symmetric and positive-definite (determinant is $0.8 \\times 1.2 - 0.6 \\times 0.6 = 0.96 - 0.36 = 0.6  0$), which are required properties of a variance-covariance matrix. The data are consistent.\n5.  **No other flaws detected.** The problem is realistic, clearly structured, and verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution\n\nThe problem requires the calculation of two quantities: the expected mean response of the trait vector, $\\Delta\\mathbf{\\bar{z}}$, and the scalar evolvability, $e(\\beta)$, along the given selection gradient. It also asks for a qualitative explanation of how modularity affects evolvability and the robustness-fragility trade-off.\n\nThe fundamental equation of multivariate quantitative genetics that describes the response to selection is the multivariate breeder's equation:\n$$\n\\Delta\\mathbf{\\bar{z}} = \\mathbf{G}\\beta\n$$\nwhere $\\Delta\\mathbf{\\bar{z}}$ is the vector of the change in mean traits per generation, $\\mathbf{G}$ is the genetic variance-covariance matrix, and $\\beta$ is the directional selection gradient vector.\n\nFirst, we compute the expected mean response vector, $\\Delta\\mathbf{\\bar{z}}$, by multiplying the given $\\mathbf{G}$ matrix and $\\beta$ vector. Let $\\Delta\\mathbf{\\bar{z}} = \\begin{pmatrix} \\Delta\\bar{x}_{1} \\\\ \\Delta\\bar{x}_{2} \\end{pmatrix}$.\n$$\n\\Delta\\mathbf{\\bar{z}} = \\begin{pmatrix} 0.8  0.6 \\\\ 0.6  1.2 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ -0.25 \\end{pmatrix}\n$$\nThe components of the response vector are:\n$$\n\\Delta\\bar{x}_{1} = (0.8)(0.5) + (0.6)(-0.25) = 0.4 - 0.15 = 0.25\n$$\n$$\n\\Delta\\bar{x}_{2} = (0.6)(0.5) + (1.2)(-0.25) = 0.3 - 0.3 = 0\n$$\nThus, the expected mean response of the trait vector is:\n$$\n\\Delta\\mathbf{\\bar{z}} = \\begin{pmatrix} 0.25 \\\\ 0 \\end{pmatrix}\n$$\nThis result indicates that while selection favors an increase in $x_{1}$ and a decrease in $x_{2}$, the system is predicted to respond only by increasing the mean of $x_{1}$. The mean of $x_{2}$ is not expected to change. This is a classic example of a genetic constraint, where the genetic correlations between traits prevent the population from evolving in the direction favored by selection. The positive genetic covariance ($G_{12}=0.6$) means that selection to increase $x_{1}$ also tends to increase $x_{2}$, which counteracts the direct selection to decrease $x_{2}$.\n\nNext, we compute the scalar evolvability, $e(\\beta)$, which is the projection of the response vector $\\Delta\\mathbf{\\bar{z}}$ onto the selection gradient vector $\\beta$. It measures the rate of adaptation in the direction of selection and is calculated as:\n$$\ne(\\beta) = \\frac{\\beta^T \\Delta\\mathbf{\\bar{z}}}{||\\beta||^2} = \\frac{\\beta^T \\mathbf{G} \\beta}{||\\beta||^2}\n$$\nConventionally, evolvability is often discussed in terms of a normalized selection gradient where $||\\beta||=1$. In that case, $e(\\beta) = \\beta^T \\mathbf{G} \\beta$. Since standard texts often use this latter formula for evolvability (representing the additive genetic variance in the direction of selection), we will compute this value.\n$$\ne(\\beta) = \\beta^T (\\mathbf{G}\\beta)\n$$\nWe have already computed $\\mathbf{G}\\beta = \\Delta\\mathbf{\\bar{z}} = \\begin{pmatrix} 0.25 \\\\ 0 \\end{pmatrix}$. Now we compute the dot product with $\\beta^T$:\n$$\ne(\\beta) = \\begin{pmatrix} 0.5  -0.25 \\end{pmatrix} \\begin{pmatrix} 0.25 \\\\ 0 \\end{pmatrix}\n$$\n$$\ne(\\beta) = (0.5)(0.25) + (-0.25)(0) = 0.125\n$$\nThe scalar evolvability along the given selection gradient is $0.125$.\n\nFor the qualitative part, we consider an architectural change that sets the genetic covariance to zero. The new G-matrix, $\\mathbf{G}'$, would be:\n$$\n\\mathbf{G}' = \\begin{pmatrix} 0.8  0 \\\\ 0  1.2 \\end{pmatrix}\n$$\nThis represents a move towards a modular system where the genetic influences on $x_{1}$ and $x_{2}$ are independent. Let's calculate the new response vector, $\\Delta\\mathbf{\\bar{z}}'$, and the new evolvability, $e'(\\beta)$, for this modular system.\n$$\n\\Delta\\mathbf{\\bar{z}}' = \\mathbf{G}'\\beta = \\begin{pmatrix} 0.8  0 \\\\ 0  1.2 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ -0.25 \\end{pmatrix} = \\begin{pmatrix} (0.8)(0.5) \\\\ (1.2)(-0.25) \\end{pmatrix} = \\begin{pmatrix} 0.4 \\\\ -0.3 \\end{pmatrix}\n$$\nThe new evolvability is:\n$$\ne'(\\beta) = \\beta^T \\Delta\\mathbf{\\bar{z}}' = \\begin{pmatrix} 0.5  -0.25 \\end{pmatrix} \\begin{pmatrix} 0.4 \\\\ -0.3 \\end{pmatrix} = (0.5)(0.4) + (-0.25)(-0.3) = 0.2 + 0.075 = 0.275\n$$\nSince $e'(\\beta) = 0.275 > e(\\beta) = 0.125$, the evolvability in the direction of selection increases significantly. By removing the genetic covariance, the genetic constraint is lifted. The conflicting pleiotropic effects are eliminated, allowing trait $x_{2}$ to decrease as favored by selection. The response vector $\\Delta\\mathbf{\\bar{z}}'$ is now much more aligned with the selection gradient $\\beta$.\n\nThis illustrates the robustness-fragility trade-off.\n-   **Robustness:** The original coupled system (with non-zero covariance) can be considered robust to perturbations that require a coordinated change in $x_{1}$ and $x_{2}$. The tight coupling helps maintain a specific functional relationship between the immune and metabolic traits, which was likely advantageous under the prior regime of stabilizing clinical management. This integration buffers the system's state.\n-   **Fragility:** This same coupling, however, makes the system fragile when faced with a novel selection pressure that requires the traits to change in a discoordinated way (increase $x_{1}$, decrease $x_{2}$). The system's inability to evolve in the required direction ($\\Delta\\bar{x}_{2} = 0$) demonstrates this fragility or lack of adaptability.\n-   **Effect of Modularity:** Shifting to the modular system ($\\mathbf{G}'$) increases evolvability, making the system less fragile and more adaptable to the new selection pressure. However, this comes at the cost of the original functional integration. The system may become less robust to perturbations that were previously managed by the coordinated response of the two traits. The modular architecture is more \"evolvable\" but potentially less \"robust\" in its homeostatic regulation.\nIn summary, an architectural change towards modularity (zero covariance) breaks the genetic constraint, increases evolvability in the direction of selection, and exemplifies the trade-off by which an increase in adaptability (reduced fragility to specific selective pressures) may come at the cost of integrated physiological stability (robustness).",
            "answer": "$$\n\\boxed{0.125}\n$$"
        },
        {
            "introduction": "This final practice challenges you to move from analysis to design, applying your understanding of evolvability to a critical problem in systems biomedicine: antibiotic resistance. You will formulate the problem of selecting sequential antibiotic treatments as a Markov Decision Process (MDP), a powerful framework for optimal control under uncertainty. This advanced computational exercise requires you to explicitly model the trade-off between the short-term robustness of a treatment (its ability to clear an infection) and its long-term impact on evolvability (the probability of creating multi-drug resistance) . By solving for the optimal policy, you will be designing a strategy to navigate the complex evolutionary landscape of resistance, a capstone application of the principles discussed.",
            "id": "4339419",
            "problem": "You are tasked with constructing a resistance–sensitivity network and formulating a Markov Decision Process (MDP) to compute optimal antibiotic sequences that minimize the probability of multi-drug resistance emergence in a bacterial population. The formulation must reflect the evolvability and robustness–fragility trade-off: actions (antibiotic choices) that robustly clear the population can simultaneously alter the likelihood of collateral resistance or sensitivity, thereby affecting future evolvability. Your program must implement this MDP and return, for each test case, the minimal probability (as a decimal between $0$ and $1$) that the system reaches a multi-drug resistant state at a fixed time horizon under an optimal policy, together with one canonical optimal sequence inferred from that policy. No physical units are involved; probabilities must be expressed as decimals, not percentages.\n\nUse the following formal structure:\n\n- Resistance–sensitivity network: A directed weighted graph with $N$ antibiotics, represented by a weight matrix $W \\in \\mathbb{R}^{N \\times N}$, where $w_{a j}$ is the weight from antibiotic $a$ to resistance in drug $j$. The sign of $w_{a j}$ encodes collateral sensitivity (negative) or cross-resistance (positive).\n- States: Each bacterial state is a binary resistance profile $s \\in \\{0,1\\}^{N}$, where $s_j = 1$ indicates resistance to drug $j$. Include one absorbing clearance state $\\mathrm{CL}$ indicating the bacterial population is cleared.\n- Actions: At each discrete time step, choose one antibiotic $a \\in \\{1, \\dots, N\\}$.\n- Evolvability and robustness–fragility trade-off:\n  - Baseline mutation probability $p_0 \\in [0,1)$.\n  - Modulation parameter $\\beta \\in \\mathbb{R}$.\n  - Clearance probabilities $c_a \\in [0,1)$ for each action $a$.\n  - Under action $a$ and state $s$, the probability to acquire resistance in drug $j$ (only if $s_j = 0$) is\n    $$p_j(a,s) = p_0 \\cdot \\exp(\\beta \\cdot w_{a j}) \\cdot \\mathbb{1}[s_j = 0].$$\n  - Assume at most one new resistance arises per time step. The transition probabilities from $s$ under action $a$ are:\n    - To the absorbing clearance state $\\mathrm{CL}$: probability $c_a$.\n    - To state $s'$ with exactly one new resistance at position $j$ relative to $s$: probability $p_j(a,s)$.\n    - To remain in the same state $s$: probability\n      $$p_{\\text{stay}}(a,s) = 1 - c_a - \\sum_{j : s_j = 0} p_j(a,s).$$\n  You must ensure parameters satisfy $p_{\\text{stay}}(a,s) \\geq 0$ for all states and actions in the test suite.\n\n- Objective: Given a threshold $K \\in \\{1, \\dots, N\\}$, define the multi-drug resistant set\n  $$\\mathcal{B}_K = \\{s \\in \\{0,1\\}^{N} : \\sum_{j=1}^{N} s_j \\geq K\\}.$$\n  With a fixed horizon $H \\in \\mathbb{N}$, the goal is to minimize the probability that the system is in $\\mathcal{B}_K$ at time $H$. This is a finite-horizon MDP cost minimization with absorbing clearance state $\\mathrm{CL}$ incurring zero terminal cost. Formally, for terminal time,\n  $$V_0(s) = \\begin{cases}\n  1  \\text{if } s \\in \\mathcal{B}_K, \\\\\n  0  \\text{if } s \\notin \\mathcal{B}_K, \\\\\n  0  \\text{if } s = \\mathrm{CL}.\n  \\end{cases}$$\n  For $t \\geq 1$,\n  $$V_t(s) = \\min_{a \\in \\{1,\\dots,N\\}} \\sum_{s' \\in \\{0,1\\}^{N} \\cup \\{\\mathrm{CL}\\}} P(s' \\mid s, a) \\cdot V_{t-1}(s').$$\n  The quantity of interest is $V_H(s_0)$ where $s_0 = (0,0,\\dots,0)$ is the fully susceptible state.\n\n- Canonical optimal sequence reporting: Although the optimal policy is state-dependent, you must also report one canonical optimal action sequence of length $H$ constructed as follows. Starting from $s = s_0$ and time $t = H$ down to $t = 1$, at each step pick the action $a^\\star(t,s)$ that achieves the minimum in $V_t(s)$, then advance $s$ deterministically to the most likely next state $s' = \\arg\\max_{x} P(x \\mid s, a^\\star)$; repeat until the sequence has length $H$ (if $s = \\mathrm{CL}$, remain in $\\mathrm{CL}$ and continue selecting any action minimizing $V_t(\\mathrm{CL})$, which is indifferent).\n\nYour program must implement this MDP and produce results for the following test suite. Each test case is a tuple specifying $(N, W, p_0, \\beta, c, H, K)$:\n\n- Test case $1$ (general case with mixed collateral effects):\n  - $N = 3$,\n  - $$W = \\begin{bmatrix}\n  0.3  -0.8  -0.4 \\\\\n  0.0  0.3  0.6 \\\\\n  0.5  -0.2  0.3\n  \\end{bmatrix},$$\n  - $p_0 = 0.02$,\n  - $\\beta = 2.0$,\n  - $c = [0.3, 0.25, 0.2]$,\n  - $H = 4$,\n  - $K = 2$.\n\n- Test case $2$ (boundary case with zero evolvability):\n  - $N = 3$,\n  - $$W = \\begin{bmatrix}\n  0.1  0.0  0.0 \\\\\n  0.0  0.1  0.0 \\\\\n  0.0  0.0  0.1\n  \\end{bmatrix},$$\n  - $p_0 = 0.0$,\n  - $\\beta = 2.0$,\n  - $c = [0.2, 0.2, 0.2]$,\n  - $H = 5$,\n  - $K = 2$.\n\n- Test case $3$ (high cross-resistance with low clearance):\n  - $N = 3$,\n  - $$W = \\begin{bmatrix}\n  0.4  0.4  0.4 \\\\\n  0.4  0.4  0.4 \\\\\n  0.4  0.4  0.4\n  \\end{bmatrix},$$\n  - $p_0 = 0.03$,\n  - $\\beta = 3.0$,\n  - $c = [0.1, 0.1, 0.1]$,\n  - $H = 3$,\n  - $K = 2$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a list of the form $[\\text{minimal\\_probability}, [a_1, a_2, \\dots, a_H]]$, where $\\text{minimal\\_probability}$ is a decimal between $0$ and $1$ rounded to six decimals, and $[a_1, a_2, \\dots, a_H]$ is the canonical optimal action sequence of integers using $1$-based indexing for antibiotics. For example: $[[0.123456,[1,2,3,4]],[0.000000,[1,1,1,1,1]],[0.543210,[3,3,2]]]$.",
            "solution": "The problem requires the formulation and solution of a finite-horizon Markov Decision Process (MDP) to determine an optimal sequence of antibiotics that minimizes the probability of a bacterial population reaching a state of multi-drug resistance. The model must capture the trade-off between the robustness of an antibiotic treatment (its ability to clear the infection) and its effect on the system's evolvability (the propensity to develop new resistances).\n\nThe solution is based on dynamic programming, specifically backward induction (or value iteration) for a finite-horizon problem.\n\n**1. Formal MDP Specification**\n\nThe problem is structured as an MDP with the following components:\n\n*   **States ($s$)**: The state space consists of $2^N + 1$ states. There are $2^N$ possible bacterial resistance profiles, represented by binary vectors $s \\in \\{0,1\\}^N$, where $s_j=1$ indicates resistance to drug $j$. For computational purposes, each state $s$ can be uniquely mapped to an integer from $0$ to $2^N-1$. An additional absorbing state, denoted $\\mathrm{CL}$, represents the clearance of the bacterial population.\n\n*   **Actions ($a$)**: The actions are the choice of an antibiotic, $a \\in \\{1, \\dots, N\\}$.\n\n*   **Transition Probabilities ($P(s' \\mid s, a)$)**: The transition dynamics from a state $s$ under action $a$ are defined as follows, assuming at most one mutation event per time step:\n    *   Transition to the clearance state $\\mathrm{CL}$: $P(\\mathrm{CL} \\mid s, a) = c_a$, where $c_a$ is the clearance probability of antibiotic $a$.\n    *   Transition to a new resistance state $s'$, where $s'$ differs from $s$ only by gaining resistance to drug $j$ (i.e., $s'_j=1$ and $s_j=0$): The probability is given by $p_j(a,s) = p_0 \\cdot \\exp(\\beta \\cdot w_{aj}) \\cdot \\mathbb{1}[s_j = 0]$. Here, $p_0$ is a baseline mutation rate, $\\beta$ is a modulation parameter, and $w_{aj}$ is an entry from the collateral effect matrix $W$, encoding cross-resistance ($w_{aj} > 0$) or collateral sensitivity ($w_{aj}  0$).\n    *   Remaining in the same state $s$: The probability is deduced by the law of total probability, $p_{\\text{stay}}(a,s) = 1 - c_a - \\sum_{j : s_j = 0} p_j(a,s)$. The problem states parameters are such that $p_{\\text{stay}} \\geq 0$.\n    *   The state $\\mathrm{CL}$ is absorbing, so $P(\\mathrm{CL} \\mid \\mathrm{CL}, a) = 1$ for any action $a$.\n\n*   **Cost Function and Objective**: The objective is to minimize the probability of the system being in a multi-drug resistant state at a fixed time horizon $H$. The set of \"bad\" states is $\\mathcal{B}_K = \\{s \\in \\{0,1\\}^{N} : \\sum_{j=1}^{N} s_j \\geq K\\}$. This is a cost-minimization problem where the cost is incurred only at the terminal time $H$. The value function $V_t(s)$ represents the minimum probability of reaching a state in $\\mathcal{B}_K$ with $t$ time steps remaining, starting from state $s$.\n    The terminal value function (at time $H$, or $t=0$ steps to go) is:\n    $$V_0(s) = \\begin{cases}\n    1  \\text{if } s \\in \\mathcal{B}_K \\\\\n    0  \\text{if } s \\notin \\mathcal{B}_K \\text{ and } s \\neq \\mathrm{CL} \\\\\n    0  \\text{if } s = \\mathrm{CL}\n    \\end{cases}$$\n\n**2. Dynamic Programming Solution**\n\nWe employ backward induction to solve the Bellman optimality equation for this finite-horizon problem. The value functions $V_t(s)$ are computed iteratively for $t=1, \\dots, H$.\n\nFor each time step $t$ (from $1$ to $H$) and each state $s$, the value function is updated according to:\n$$V_t(s) = \\min_{a \\in \\{1,\\dots,N\\}} Q_t(s, a)$$\nwhere $Q_t(s, a)$ is the action-value function, representing the cost of taking action $a$ in state $s$ with $t$ steps remaining:\n$$Q_t(s, a) = \\sum_{s' \\in \\{0,1\\}^{N} \\cup \\{\\mathrm{CL}\\}} P(s' \\mid s, a) \\cdot V_{t-1}(s')$$\nSubstituting the transition probabilities, this expands to:\n$$Q_t(s, a) = c_a V_{t-1}(\\mathrm{CL}) + p_{\\text{stay}}(a,s) V_{t-1}(s) + \\sum_{j: s_j=0} p_j(a,s) V_{t-1}(s'_j)$$\nwhere $s'_j$ is the state derived from $s$ by acquiring resistance to drug $j$. Since $V_t(\\mathrm{CL}) = 0$ for all $t$, the equation simplifies.\n\nThe optimal policy $\\pi_t(s)$ for each state $s$ and time-to-go $t$ is the action $a$ that minimizes this $Q_t(s, a)$:\n$$\\pi_t(s) = \\arg\\min_{a \\in \\{1,\\dots,N\\}} Q_t(s, a)$$\nTies are broken by selecting the action with the smallest index.\n\nThis process is repeated from $t=1$ up to $H$. The final answer for the minimal probability of resistance is $V_H(s_0)$, where $s_0$ is the fully susceptible initial state, $s_0 = (0, \\dots, 0)$.\n\n**3. Canonical Optimal Sequence Construction**\n\nAfter computing the full set of optimal policies $\\{\\pi_t\\}_{t=1}^H$, we construct a single canonical action sequence. This is done by simulating the system's trajectory forward in time from $t=1$ to $H$, starting at $s^{(0)} = s_0$.\n\nAt each time step $k \\in \\{1, \\dots, H\\}$:\n1.  The system is in state $s^{(k-1)}$. The number of steps-to-go is $H-k+1$.\n2.  The optimal action is selected from the pre-computed policy: $a_k = \\pi_{H-k+1}(s^{(k-1)})$.\n3.  The system transitions to the next state $s^{(k)}$ deterministically, by choosing the most probable outcome given state $s^{(k-1)}$ and action $a_k$. That is, $s^{(k)} = \\arg\\max_{s'} P(s' \\mid s^{(k-1)}, a_k)$. Ties for the most likely state are broken by choosing the state with the smallest integer representation.\n4.  The action $a_k$ is recorded.\n\nThe final canonical sequence is the list of actions $[a_1, a_2, \\dots, a_H]$. This procedure provides a concrete, representative path even though the true optimal policy is state-dependent.\n\nThe following Python code implements this dynamic programming solution.\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_mdp(N, W, p0, beta, c, H, K):\n    \"\"\"\n    Solves the finite-horizon MDP defined in the problem for a given set of parameters.\n\n    Args:\n        N (int): Number of antibiotics.\n        W (np.array): Resistance-sensitivity network matrix.\n        p0 (float): Baseline mutation probability.\n        beta (float): Modulation parameter.\n        c (list): Clearance probabilities for each antibiotic.\n        H (int): Time horizon.\n        K (int): Resistance threshold for defining multi-drug resistant states.\n\n    Returns:\n        tuple: A tuple containing:\n            - float: The minimal probability of reaching a multi-drug resistant state.\n            - list: The canonical optimal action sequence (1-based).\n    \"\"\"\n    num_states_bacterial = 2**N\n    cl_state_idx = num_states_bacterial\n    total_states = num_states_bacterial + 1\n    \n    # State representation:\n    # - Integers 0 to 2**N-1 represent bacterial resistance profiles s in {0,1}^N.\n    # - The integer 2**N represents the absorbing clearance state (CL).\n\n    # Initialize Value Function V_0 (for t=0, i.e., 0 steps to go).\n    # V[t, s] stores the value function for t steps-to-go and state s.\n    V = np.zeros((H + 1, total_states))\n    \n    # Policy Pi[t, s] stores the optimal action index (0-based) for t steps-to-go and state s.\n    Pi = np.zeros((H + 1, total_states), dtype=int)\n\n    # Define terminal costs V_0: 1 for \"bad\" states, 0 otherwise.\n    for s in range(num_states_bacterial):\n        # Count number of resistances by counting set bits in the integer representation.\n        if bin(s).count('1') >= K:\n            V[0, s] = 1.0\n            \n    # Dynamic Programming (Value Iteration) backward in time from t=1 to H.\n    for t in range(1, H + 1):  # t represents the number of steps to go.\n        for s in range(num_states_bacterial):\n            q_values = np.zeros(N)\n            \n            # Find indices j where resistance is not present (s_j = 0).\n            unresisted_indices = [j for j in range(N) if not ((s >> j)  1)]\n            \n            for a in range(N):  # a = action index (0-indexed).\n                # Calculate transition probabilities for action a.\n                \n                # Probability of acquiring new resistances.\n                p_new_resistance_contrib = 0.0\n                sum_p_new = 0.0\n                for j in unresisted_indices:\n                    # w_aj is W[a, j] in 0-based indexing.\n                    p_j = p0 * np.exp(beta * W[a, j])\n                    next_s = s | (1  j) # Next state if resistance j is acquired.\n                    p_new_resistance_contrib += p_j * V[t - 1, next_s]\n                    sum_p_new += p_j\n                \n                # Probability of staying in the same state.\n                p_stay = 1.0 - c[a] - sum_p_new\n                \n                # Calculate the Q-value Q_t(s, a).\n                # Q_t(s, a) = sum_{s'} P(s'|s,a) * V_{t-1}(s').\n                # The term for transitioning to CL is c[a] * V[t-1, cl_state_idx], which is 0.\n                q_val = (p_stay * V[t - 1, s]) + p_new_resistance_contrib\n                q_values[a] = q_val\n\n            # Find the best action (that minimizes the Q-value).\n            V[t, s] = np.min(q_values)\n            Pi[t, s] = np.argmin(q_values) # np.argmin handles tie-breaking.\n    \n        # The CL state is absorbing with a value of 0.\n        V[t, cl_state_idx] = 0.0\n        # Policy at CL is indifferent; pick action 0 for determinism.\n        Pi[t, cl_state_idx] = 0\n\n    # The minimal probability of failure is V_H(s_0), where s_0 is state 0.\n    s0_idx = 0\n    min_prob = V[H, s0_idx]\n\n    # Construct the canonical optimal sequence by simulating forward.\n    optimal_sequence = []\n    current_state = s0_idx\n    \n    for k in range(1, H + 1): # k = current time step from 1 to H.\n        steps_to_go = H - k + 1\n        \n        # Get optimal action from the pre-computed policy table for the current state.\n        action = Pi[steps_to_go, current_state]\n        optimal_sequence.append(action + 1) # Append 1-based action.\n\n        # If already in the cleared state, stay there.\n        if current_state == cl_state_idx:\n            continue\n\n        # Determine the most likely next state for the canonical sequence.\n        transition_probs = np.zeros(total_states)\n        \n        # Probability to transition to CL.\n        transition_probs[cl_state_idx] = c[action]\n        \n        # Probabilities to transition to new resistance states.\n        unresisted_indices = [j for j in range(N) if not ((current_state >> j)  1)]\n        sum_p_new = 0.0\n        for j in unresisted_indices:\n            p_j = p0 * np.exp(beta * W[action, j])\n            next_s = current_state | (1  j)\n            transition_probs[next_s] = p_j\n            sum_p_new += p_j\n            \n        # Probability to stay in the current state.\n        p_stay = 1.0 - c[action] - sum_p_new\n        transition_probs[current_state] = p_stay\n        \n        # Find next state using argmax (breaks ties by picking the smallest index).\n        current_state = np.argmax(transition_probs)\n\n    return round(min_prob, 6), optimal_sequence\n```",
            "answer": "[[0.019559,[1, 1, 1, 1]],[0.000000,[1, 1, 1, 1, 1]],[0.170669,[1, 1, 1]]]"
        }
    ]
}