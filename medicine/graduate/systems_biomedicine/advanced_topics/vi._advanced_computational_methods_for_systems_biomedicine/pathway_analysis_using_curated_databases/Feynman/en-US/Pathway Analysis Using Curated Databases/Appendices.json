{
    "hands_on_practices": [
        {
            "introduction": "Pathway analysis begins with a clean, well-defined list of genes. However, a common practical hurdle is that gene identifiers from experimental platforms (like UniProt) must be mapped to those used in pathway databases (like Entrez Gene), a process fraught with ambiguity. This exercise demonstrates how to apply a rigorous Bayesian framework to this challenge, using multiple lines of evidence to resolve ambiguous mappings in a principled, quantitative manner, which is a critical skill for ensuring the integrity of any downstream analysis. ",
            "id": "4373294",
            "problem": "A research group is performing pathway analysis using curated databases such as the Kyoto Encyclopedia of Genes and Genomes (KEGG) and Reactome. Their assay’s feature table is annotated using identifiers from Universal Protein Resource (UniProt) and Entrez Gene. During identifier harmonization, they encounter $32$ assay features with ambiguous synonyms, each of which can map to exactly two candidate Entrez Gene identifiers. The group resolves each ambiguity by combining two independent lines of curated evidence: cross-database synonym curation (from UniProt and manual curation notes) and pathway co-membership evidence (from KEGG and Reactome). They treat these evidences as conditionally independent given the true mapping.\n\nFor each ambiguous feature, they use Bayes’ theorem with equal prior odds for the two candidates and a maximum a posteriori decision rule: select the candidate with the higher posterior probability. For each ambiguous feature, the synonym curation evidence yields a likelihood ratio $\\lambda$ in favor of candidate $g_{1}$ over candidate $g_{2}$, and the pathway co-membership evidence yields a likelihood ratio $\\mu$ (also in favor of $g_{1}$ over $g_{2}$). Under the conditional independence assumption, the combined likelihood ratio is $L = \\lambda \\times \\mu$. The ambiguous features are partitioned into three disjoint categories according to the strengths of curated evidence:\n\n- Category $\\mathcal{A}$: $n_{\\mathcal{A}} = 12$ features with $\\lambda_{\\mathcal{A}} = 2.5$ and $\\mu_{\\mathcal{A}} = 1.8$.\n- Category $\\mathcal{B}$: $n_{\\mathcal{B}} = 10$ features with $\\lambda_{\\mathcal{B}} = 1.2$ and $\\mu_{\\mathcal{B}} = 0.9$.\n- Category $\\mathcal{C}$: $n_{\\mathcal{C}} = 10$ features with $\\lambda_{\\mathcal{C}} = 0.7$ and $\\mu_{\\mathcal{C}} = 0.6$.\n\nAssume that for each feature, the probability that the selected candidate is the true identifier equals the posterior probability of the selected candidate under Bayes’ theorem with equal priors and combined likelihood ratio $L$. Using only fundamental definitions of Bayes’ theorem, conditional independence, and the maximum a posteriori rule, derive an expression for the expected number of correctly resolved identifiers across the $32$ ambiguous features and compute its value for the given categories. Round your final numerical answer to four significant figures. Express the final answer as a dimensionless count.",
            "solution": "The user wants to solve a problem about identifier harmonization in bioinformatics using a Bayesian framework. The problem asks for the expected number of correctly resolved identifiers.\n\n### Step 1: Problem Validation\n\nFirst, I will validate the problem statement.\n\n**1.1. Extract Givens**\n- Total ambiguous features: $32$.\n- Each feature maps to two candidate Entrez Gene identifiers, denoted as $g_1$ and $g_2$.\n- Decision rule: Bayes' theorem with equal prior odds and a maximum a posteriori (MAP) rule.\n- Evidence: Two lines of evidence, synonym curation and pathway co-membership, are treated as conditionally independent given the true mapping.\n- Likelihood ratio for synonym curation: $\\lambda = \\frac{P(\\text{synonym evidence} | g_1 \\text{ is true})}{P(\\text{synonym evidence} | g_2 \\text{ is true})}$.\n- Likelihood ratio for pathway co-membership: $\\mu = \\frac{P(\\text{pathway evidence} | g_1 \\text{ is true})}{P(\\text{pathway evidence} | g_2 \\text{ is true})}$.\n- Combined-evidence likelihood ratio: $L = \\lambda \\times \\mu$.\n- Feature categories:\n    - Category $\\mathcal{A}$: $n_{\\mathcal{A}} = 12$ features, $\\lambda_{\\mathcal{A}} = 2.5$, $\\mu_{\\mathcal{A}} = 1.8$.\n    - Category $\\mathcal{B}$: $n_{\\mathcal{B}} = 10$ features, $\\lambda_{\\mathcal{B}} = 1.2$, $\\mu_{\\mathcal{B}} = 0.9$.\n    - Category $\\mathcal{C}$: $n_{\\mathcal{C}} = 10$ features, $\\lambda_{\\mathcal{C}} = 0.7$, $\\mu_{\\mathcal{C}} = 0.6$.\n- Total features check: $n_{\\mathcal{A}} + n_{\\mathcal{B}} + n_{\\mathcal{C}} = 12 + 10 + 10 = 32$.\n- Assumption: For each feature, the probability of a correct resolution is equal to the posterior probability of the selected candidate.\n- Task: Derive an expression for and compute the expected number of correctly resolved identifiers.\n- Rounding: The final numerical answer must be rounded to four significant figures.\n\n**1.2. Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is well-grounded in statistical methodology commonly used in systems biomedicine. Bayesian inference, likelihood ratios, and evidence integration for identifier mapping are standard and realistic concepts.\n- **Well-Posed**: The problem is clearly stated, provides all necessary numerical values and probabilistic assumptions, and asks for a specific, calculable quantity.\n- **Objective**: The language is technical and precise, with no subjective or ambiguous elements.\n- **Flaw Checklist**: The problem does not violate any of the invalidity criteria. It is scientifically sound, formalizable, complete, realistic, and well-posed. The definition of \"probability that the selected candidate is the true identifier\" is explicitly given, precluding ambiguity.\n\n**1.3. Verdict and Action**\nThe problem is valid. I will proceed with the solution.\n\n### Step 2: Solution Derivation\n\nThe problem requires us to calculate the expected number of correctly resolved identifiers over a set of $32$ ambiguous features. Let's formalize the Bayesian framework for a single feature.\n\nLet $H_1$ be the hypothesis that candidate gene $g_1$ is the true identifier, and $H_2$ be the hypothesis that $g_2$ is the true identifier. The problem states there are equal prior odds, which for two mutually exclusive and exhaustive hypotheses means they have equal prior probabilities:\n$$ P(H_1) = P(H_2) = \\frac{1}{2} $$\nLet $E$ represent the combined evidence from synonym curation ($E_s$) and pathway co-membership ($E_p$). The core of Bayesian inference is to update our prior beliefs in light of this evidence to obtain posterior probabilities, $P(H_1|E)$ and $P(H_2|E)$.\n\nBayes' theorem in odds form relates the posterior odds to the prior odds and the likelihood ratio:\n$$ \\frac{P(H_1|E)}{P(H_2|E)} = \\frac{P(E|H_1)}{P(E|H_2)} \\times \\frac{P(H_1)}{P(H_2)} $$\nThe term $\\frac{P(E|H_1)}{P(E|H_2)}$ is the likelihood ratio, which the problem denotes by $L$. Given the equal priors, the prior odds ratio $\\frac{P(H_1)}{P(H_2)} = 1$. Thus, the posterior odds are equal to the likelihood ratio:\n$$ \\frac{P(H_1|E)}{P(H_2|E)} = L $$\nThe problem states that the two lines of evidence are conditionally independent, and provides their individual likelihood ratios, $\\lambda$ and $\\mu$. The combined likelihood ratio $L$ is their product, $L = \\lambda \\mu$, which is consistent with the conditional independence assumption.\n\nWe can express the posterior probabilities in terms of $L$. Since $P(H_1|E) + P(H_2|E) = 1$, we can substitute $P(H_1|E) = L \\cdot P(H_2|E)$ into this sum:\n$$ L \\cdot P(H_2|E) + P(H_2|E) = 1 \\implies P(H_2|E)(L+1) = 1 \\implies P(H_2|E) = \\frac{1}{L+1} $$\nConsequently, the posterior probability for $H_1$ is:\n$$ P(H_1|E) = 1 - P(H_2|E) = 1 - \\frac{1}{L+1} = \\frac{L}{L+1} $$\n\nThe decision is made using a maximum a posteriori (MAP) rule, which means selecting the hypothesis with the highest posterior probability.\n- If $P(H_1|E) > P(H_2|E)$, which is equivalent to $\\frac{L}{L+1} > \\frac{1}{L+1}$ or $L>1$, we select candidate $g_1$.\n- If $P(H_2|E) > P(H_1|E)$, which is equivalent to $L<1$, we select candidate $g_2$.\n- If $L=1$, the probabilities are equal, and the choice is ambiguous, but this case does not occur with the given data.\n\nThe problem defines the probability of a correct resolution, $P_C$, for a single feature as the posterior probability of the *selected* candidate.\n- If $L>1$, we select $g_1$, and the probability of this choice being correct is $P_C = P(H_1|E) = \\frac{L}{L+1}$.\n- If $L<1$, we select $g_2$, and the probability of this choice being correct is $P_C = P(H_2|E) = \\frac{1}{L+1}$.\nThis can be written compactly as $P_C = \\max\\left(\\frac{L}{L+1}, \\frac{1}{L+1}\\right)$.\n\nThe total expected number of correctly resolved identifiers, $E[\\text{correct}]$, is the sum of the probabilities of correct resolution for each of the $32$ features, by linearity of expectation. We can group the features by their category.\n$$ E[\\text{correct}] = n_{\\mathcal{A}} P_{C, \\mathcal{A}} + n_{\\mathcal{B}} P_{C, \\mathcal{B}} + n_{\\mathcal{C}} P_{C, \\mathcal{C}} $$\nwhere $P_{C, k}$ is the probability of correct resolution for a feature in category $k$.\n\nNow, we calculate $P_C$ for each category:\n\n**Category $\\mathcal{A}$:**\n- Number of features: $n_{\\mathcal{A}} = 12$.\n- Likelihood ratios: $\\lambda_{\\mathcal{A}} = 2.5$, $\\mu_{\\mathcal{A}} = 1.8$.\n- Combined likelihood ratio: $L_{\\mathcal{A}} = \\lambda_{\\mathcal{A}} \\times \\mu_{\\mathcal{A}} = 2.5 \\times 1.8 = 4.5$.\n- Since $L_{\\mathcal{A}} = 4.5 > 1$, we select candidate $g_1$.\n- Probability of correct resolution: $P_{C, \\mathcal{A}} = \\frac{L_{\\mathcal{A}}}{L_{\\mathcal{A}}+1} = \\frac{4.5}{4.5+1} = \\frac{4.5}{5.5} = \\frac{9}{11}$.\n\n**Category $\\mathcal{B}$:**\n- Number of features: $n_{\\mathcal{B}} = 10$.\n- Likelihood ratios: $\\lambda_{\\mathcal{B}} = 1.2$, $\\mu_{\\mathcal{B}} = 0.9$.\n- Combined likelihood ratio: $L_{\\mathcal{B}} = \\lambda_{\\mathcal{B}} \\times \\mu_{\\mathcal{B}} = 1.2 \\times 0.9 = 1.08$.\n- Since $L_{\\mathcal{B}} = 1.08 > 1$, we select candidate $g_1$.\n- Probability of correct resolution: $P_{C, \\mathcal{B}} = \\frac{L_{\\mathcal{B}}}{L_{\\mathcal{B}}+1} = \\frac{1.08}{1.08+1} = \\frac{1.08}{2.08} = \\frac{108}{208} = \\frac{27}{52}$.\n\n**Category $\\mathcal{C}$:**\n- Number of features: $n_{\\mathcal{C}} = 10$.\n- Likelihood ratios: $\\lambda_{\\mathcal{C}} = 0.7$, $\\mu_{\\mathcal{C}} = 0.6$.\n- Combined likelihood ratio: $L_{\\mathcal{C}} = \\lambda_{\\mathcal{C}} \\times \\mu_{\\mathcal{C}} = 0.7 \\times 0.6 = 0.42$.\n- Since $L_{\\mathcal{C}} = 0.42 < 1$, we select candidate $g_2$.\n- Probability of correct resolution: $P_{C, \\mathcal{C}} = \\frac{1}{L_{\\mathcal{C}}+1} = \\frac{1}{0.42+1} = \\frac{1}{1.42} = \\frac{100}{142} = \\frac{50}{71}$.\n\nFinally, we compute the total expected number of correctly resolved identifiers:\n$$ E[\\text{correct}] = n_{\\mathcal{A}} P_{C, \\mathcal{A}} + n_{\\mathcal{B}} P_{C, \\mathcal{B}} + n_{\\mathcal{C}} P_{C, \\mathcal{C}} $$\n$$ E[\\text{correct}] = 12 \\left(\\frac{9}{11}\\right) + 10 \\left(\\frac{27}{52}\\right) + 10 \\left(\\frac{50}{71}\\right) $$\n$$ E[\\text{correct}] = \\frac{108}{11} + \\frac{270}{52} + \\frac{500}{71} $$\nNow, we convert to decimal values for the final sum:\n$$ E[\\text{correct}] \\approx 9.818181... + 5.192307... + 7.042253... $$\n$$ E[\\text{correct}] \\approx 22.052742... $$\nThe problem requires the final answer to be rounded to four significant figures. The first four significant digits are $2$, $2$, $0$, and $5$. The fifth significant digit is $2$, so we round down.\n$$ E[\\text{correct}] \\approx 22.05 $$\nThe expected number of correctly resolved identifiers is approximately $22.05$.",
            "answer": "$$\\boxed{22.05}$$"
        },
        {
            "introduction": "Once you have a reliable list of genes, the next step is to perform the enrichment analysis. While many software packages can do this, a deep understanding comes from building the core algorithms from scratch. This practice guides you through implementing two foundational methods: Over-Representation Analysis (ORA), which uses the hypergeometric distribution to test for enrichment in a list of significant genes, and a weighted running-sum method inspired by Gene Set Enrichment Analysis (GSEA) for ranked gene lists. By coding these algorithms from their statistical definitions, you will move beyond being a user of \"black boxes\" to an informed practitioner who truly understands their assumptions and mechanics. ",
            "id": "4373311",
            "problem": "Develop a complete, runnable program that implements two foundational pathway analysis procedures that are widely used in Systems Biomedicine and inspired by practical tooling from the R/Bioconductor ecosystem, using only first principles and well-tested statistical definitions. The goal is to analyze curated pathway gene sets against a ranked list of genes and a set of significant genes, both defined on a fixed gene universe. Your program must compute, for each provided test case, two quantities: (i) the smallest Benjamini–Hochberg adjusted p-value from a one-sided over-representation analysis across all provided pathways, and (ii) the maximum absolute normalized enrichment score across these pathways computed by a weighted running-sum enrichment analysis with an exact null obtained by enumeration. All computations must be fully deterministic with no user input.\n\nStart from the following fundamental base.\n\n1) Curated pathway as a gene set. A pathway is represented as a curated set of genes from sources such as Kyoto Encyclopedia of Genes and Genomes (KEGG) or Reactome. Algorithmically, each pathway is a finite subset of a fixed gene universe of size $N$.\n\n2) Over-representation analysis as sampling without replacement. Consider a fixed gene universe of size $N$, of which $K$ genes are labeled “significant.” For a particular pathway of size $n$, suppose $k$ of its genes are significant. Under the null hypothesis that significance is independent of pathway membership, the number of significant genes observed in the pathway follows a hypergeometric law. The one-sided over-representation p-value is the probability of observing at least $k$ significant genes:\n$$\np_{\\mathrm{ORA}} \\;=\\; \\sum_{j=k}^{\\min(n,K)} \\frac{\\binom{K}{j}\\,\\binom{N-K}{n-j}}{\\binom{N}{n}} \\, .\n$$\nAcross $m$ pathways, the Benjamini–Hochberg multiple testing correction maps the p-values $\\{p_{(1)} \\le \\dots \\le p_{(m)}\\}$ to adjusted values $q_{(i)} = \\min_{t \\ge i} \\left( \\frac{m}{t} \\, p_{(t)} \\right)$, which are then returned to original order to obtain $\\{q_1,\\dots,q_m\\}$.\n\n3) Weighted running-sum gene set enrichment on a ranked list. Let the universe genes be ranked by a real-valued score vector $r = (r_1,\\dots,r_N)$ in decreasing order. For a pathway $S$ of size $N_h = |S|$, define weights $w_i = |r_i|^p$ with exponent $p \\ge 0$. The running-sum walk scans the rank from $i=1$ to $i=N$ and updates a cumulative sum by\n- incrementing by $w_i / \\mathrm{NR}$ when gene $i$ is in $S$, where $\\mathrm{NR} = \\sum_{i \\in S} w_i$,\n- decrementing by $1/(N-N_h)$ when gene $i$ is not in $S$,\nwith the convention that if $N_h \\in \\{0,N\\}$ the enrichment score is set to $0$.\nLet the running cumulative sum be $\\mathrm{RS}_i$. The enrichment score $\\mathrm{ES}(S)$ is the more extreme of the maximum and minimum values of $\\mathrm{RS}_i$ in absolute value, with its sign determined by the direction of the more extreme deviation. To normalize, define the exact null by enumerating all $\\binom{N}{N_h}$ ways of placing the $N_h$ “hit” positions among the $N$ ranks, compute the corresponding enrichment scores under these placements while holding $w_i$ fixed, and let $\\mu_+ = \\mathbb{E}[\\mathrm{ES} \\mid \\mathrm{ES}>0]$ and $\\mu_- = \\mathbb{E}[-\\mathrm{ES} \\mid \\mathrm{ES}<0]$. The normalized enrichment score for a pathway with observed $\\mathrm{ES}$ is\n$$\n\\mathrm{NES}(S) \\;=\\;\n\\begin{cases}\n\\mathrm{ES}/\\mu_+ & \\text{if } \\mathrm{ES} > 0 \\text{ and } \\mu_+ > 0,\\\\\n-\\mathrm{ES}/\\mu_- & \\text{if } \\mathrm{ES} < 0 \\text{ and } \\mu_- > 0,\\\\\n0 & \\text{if } N_h \\in \\{0,N\\} \\text{ or the relevant mean is } 0 \\, .\n\\end{cases}\n$$\nIn each test case, report the maximum absolute normalized enrichment score across all provided pathways.\n\nYour program must implement the above from these definitions, without requiring any user input or external files, and must execute deterministically.\n\nUse the following test suite. In all cases, the gene universe is $\\{1,2,\\dots,N\\}$, ranks are in decreasing order of the provided scores $r$, and the weighting exponent is $p=1$.\n\n- Test Case $1$:\n  - Universe size $N = 12$.\n  - Ranked scores $r = [2.5, 1.8, 1.2, 0.9, 0.4, -0.2, -0.5, -1.0, -1.3, -1.7, -2.0, -2.6]$.\n  - Significant genes $G_{\\mathrm{sig}} = \\{1,2,3,8,11,12\\}$, so $K = 6$.\n  - Pathways (curated sets): $S_1 = \\{1,4,6,8\\}$, $S_2 = \\{2,3,5,7,9\\}$, $S_3 = \\{10,11,12\\}$.\n\n- Test Case $2$:\n  - Universe size $N = 10$.\n  - Ranked scores $r = [3.0, 2.2, 1.5, 0.8, 0.1, -0.3, -0.9, -1.4, -2.1, -2.8]$.\n  - Significant genes $G_{\\mathrm{sig}} = \\{1,2,3,9\\}$, so $K = 4$.\n  - Pathways: $S_1 = \\{4,5,6\\}$, $S_2 = \\{1,2,3,9\\}$, $S_3 = \\{7\\}$.\n\n- Test Case $3$:\n  - Universe size $N = 8$.\n  - Ranked scores $r = [1.2, 0.7, 0.3, -0.1, -0.4, -0.8, -1.1, -1.5]$.\n  - Significant genes $G_{\\mathrm{sig}} = \\varnothing$, so $K = 0$.\n  - Pathways: $S_1 = \\{1,2,3\\}$, $S_2 = \\{4,5,6,7,8\\}$, $S_3 = \\{1,2,3,4,5,6,7,8\\}$.\n\nFor each test case, compute:\n- The smallest Benjamini–Hochberg adjusted p-value across the listed pathways from the over-representation analysis defined above, as a float rounded to $6$ decimal places.\n- The maximum absolute normalized enrichment score across the listed pathways from the weighted running-sum analysis with exact null enumeration, as a float rounded to $6$ decimal places.\n\nFinal output format. Your program should produce a single line of output containing a comma-separated list of the results for the three test cases, each result itself being a two-element list in the order described above. Concretely, the output must be a single line of the form\n$[[a_1,b_1],[a_2,b_2],[a_3,b_3]]$\nwhere each $a_i$ and $b_i$ are floats rounded to exactly $6$ decimal places.",
            "solution": "The problem requires the implementation of two distinct bioinformatics pathway analysis algorithms: a one-sided over-representation analysis (ORA) with Benjamini-Hochberg (BH) correction, and a weighted running-sum gene set enrichment analysis (GSEA) with normalization against an exact null distribution. The solution is partitioned into functions that directly implement the statistical and algorithmic definitions provided.\n\n**1. Over-Representation Analysis (ORA)**\n\nThe ORA component quantifies whether a pathway is enriched with \"significant\" genes. The statistical basis is the hypergeometric distribution, which models sampling without replacement.\n\n**1.1. Hypergeometric p-value**\n\nThe core of ORA is to calculate the probability of observing at least $k$ significant genes in a pathway of size $n$, drawn from a universe of $N$ genes containing $K$ significant ones. This one-sided p-value is given by the survival function of the hypergeometric distribution:\n$$\np_{\\mathrm{ORA}} \\;=\\; P(X \\ge k) \\;=\\; \\sum_{j=k}^{\\min(n,K)} \\frac{\\binom{K}{j}\\,\\binom{N-K}{n-j}}{\\binom{N}{n}}\n$$\nThis formula is implemented by first defining a function to compute the binomial coefficient $\\binom{n}{k}$, for which we can leverage `scipy.special.comb`. A function `calculate_hypergeometric_p_value(k, n, K, N)` iterates from $j=k$ to $\\min(n, K)$, summing the probabilities for each outcome. The numerator is the product of two binomial coefficients, `comb(K, j)` and `comb(N-K, n-j)`, and the denominator is `comb(N, n)`. Special cases such as $k=0$ result in $p_{\\mathrm{ORA}}=1$, which is handled explicitly.\n\n**1.2. Benjamini-Hochberg (BH) Multiple Testing Correction**\n\nWhen testing multiple pathways, the resulting p-values must be adjusted to control the false discovery rate. The Benjamini-Hochberg procedure is implemented as follows:\n1.  Let the initial p-values for the $m$ pathways be $\\{p_1, p_2, \\dots, p_m\\}$.\n2.  Sort the p-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$. The original indices are retained to restore the order later.\n3.  Calculate the raw adjusted p-values, let's call them $q'_{\\text{raw}}$, for each sorted p-value: $q'_{(i)} = \\frac{m}{i} p_{(i)}$, where $i$ is the rank from $1$ to $m$.\n4.  To ensure the adjusted p-values are monotonically increasing with the original sorted p-values, a cumulative minimum is taken. The final adjusted p-value $q_{(i)}$ for rank $i$ is defined by the rule $q_{(i)} = \\min_{t \\ge i} \\left( \\frac{m}{t} p_{(t)} \\right)$. This can be computed efficiently by iterating backwards from rank $m$:\n    $$\n    q_{(m)} = p_{(m)} \\\\\n    q_{(i)} = \\min\\left(q_{(i+1)}, \\frac{m}{i} p_{(i)}\\right) \\quad \\text{for } i = m-1, m-2, \\dots, 1\n    $$\n5.  The computed sorted q-values $\\{q_{(1)}, \\dots, q_{(m)}\\}$ are then reordered to match the original input order of the pathways.\nThe final result for the ORA part of the problem is the minimum value among these adjusted p-values $\\{q_1, \\dots, q_m\\}$.\n\n**2. Weighted Running-Sum Gene Set Enrichment Analysis (GSEA)**\n\nThis GSEA-like procedure assesses whether a pathway's genes are concentrated at the top or bottom of a pre-ranked list of all genes.\n\n**2.1. Calculation of the Enrichment Score (ES)**\n\nFor a given pathway $S$ of size $N_h$, the algorithm proceeds as follows:\n1.  The genes in the universe are ordered from $1$ to $N$ based on the provided decreasing scores $r_i$.\n2.  A weight $w_i = |r_i|^p$ is assigned to each gene, with $p=1$ for this problem.\n3.  A running sum $\\mathrm{RS}$ is initialized to $0$. The algorithm iterates through the ranked list of genes from $i=1$ to $N$.\n4.  At each step $i$, the running sum is updated:\n    -   If gene $i$ is in the pathway $S$ (a \"hit\"), the sum is incremented: $\\mathrm{RS}_i = \\mathrm{RS}_{i-1} + \\frac{w_i}{\\mathrm{NR}}$, where $\\mathrm{NR} = \\sum_{j \\in S} w_j$ is the sum of weights for all genes in the pathway.\n    -   If gene $i$ is not in the pathway $S$ (a \"miss\"), the sum is decremented: $\\mathrm{RS}_i = \\mathrm{RS}_{i-1} - \\frac{1}{N-N_h}$.\n5.  The Enrichment Score, $\\mathrm{ES}(S)$, is the maximum deviation of the running sum from $0$. It is defined as the value among all $\\mathrm{RS}_i$ that has the greatest absolute magnitude, retaining its original sign. This is found by computing $\\max_i(\\mathrm{RS}_i)$ and $\\min_i(\\mathrm{RS}_i)$ and choosing the one with the larger absolute value.\n6.  By definition, if the pathway is empty ($N_h=0$) or contains all genes ($N_h=N$), the enrichment score is $0$.\n\n**2.2. Normalization via Exact Null Distribution**\n\nTo make scores comparable across different pathways and datasets, the observed $\\mathrm{ES}$ is normalized.\n1.  An exact null distribution of enrichment scores is generated by calculating the $\\mathrm{ES}$ for every possible pathway of size $N_h$. There are $\\binom{N}{N_h}$ such pathways. This is achieved by generating all combinations of $N_h$ genes from the universe of $N$ genes.\n2.  For each \"null\" pathway, an $\\mathrm{ES}_{\\text{null}}$ is computed using the same running-sum method described above, while keeping the gene weights $w_i$ fixed.\n3.  From the resulting collection of all $\\mathrm{ES}_{\\text{null}}$ values, the positive and negative scores are separated to calculate two normalization factors:\n    -   $\\mu_+ = \\mathbb{E}[\\mathrm{ES} \\mid \\mathrm{ES}>0]$: the mean of all positive enrichment scores from the null distribution.\n    -   $\\mu_- = \\mathbb{E}[-\\mathrm{ES} \\mid \\mathrm{ES}<0]$: the mean of the absolute values of all negative enrichment scores from the null distribution.\n4.  The Normalized Enrichment Score, $\\mathrm{NES}(S)$, for the observed pathway $S$ is then calculated:\n    $$\n    \\mathrm{NES}(S) \\;=\\;\n    \\begin{cases}\n    \\mathrm{ES}(S)/\\mu_+ & \\text{if } \\mathrm{ES}(S) > 0 \\text{ and } \\mu_+ > 0,\\\\\n    -\\mathrm{ES}(S)/\\mu_- & \\text{if } \\mathrm{ES}(S) < 0 \\text{ and } \\mu_- > 0,\\\\\n    0 & \\text{otherwise.}\n    \\end{cases}\n    $$\n    The negative sign in the second case ensures that the NES is positive for both positive and negative enrichment. The final result for the GSEA part of the problem is the maximum absolute NES value across all pathways in a test case.\n\n**3. Program Structure and Execution**\n\nThe overall program is structured to process each test case independently.\n1.  The test cases are defined in a list, with each entry containing the universe size $N$, the ranked scores $r$, the set of significant genes $G_{\\mathrm{sig}}$, and the list of pathways.\n2.  For each test case, the program first computes the smallest BH-adjusted p-value. It calculates the raw p-value for each pathway and then applies the BH correction to the entire set of p-values.\n3.  Next, it computes the maximum absolute NES. To optimize the GSEA calculation, the normalization factors $\\mu_+$ and $\\mu_-$ are cached. Since these factors depend only on the universe size $N$, the pathway size $N_h$, and the ranked list weights, they are computed only once for each unique pathway size within a given test case.\n4.  Finally, the two required values for each test case—the minimum adjusted p-value and the maximum absolute NES—are rounded to $6$ decimal places and formatted into the specified output string.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\nfrom itertools import combinations\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the pathway analysis problem for a suite of test cases.\n    It implements Over-Representation Analysis (ORA) with Benjamini-Hochberg\n    correction and a weighted Gene Set Enrichment Analysis (GSEA) with an\n    exact null distribution, as per the problem definitions.\n    \"\"\"\n\n    # --- ORA Helper Functions ---\n\n    def calculate_hypergeometric_p_value(k, n, K, N):\n        \"\"\"\n        Computes the one-sided ORA p-value using the hypergeometric distribution.\n        p_ORA = P(X >= k) = sum_{j=k to min(n,K)} [C(K,j)*C(N-K,n-j)] / C(N,n)\n        \n        Args:\n            k (int): Number of significant genes in the pathway.\n            n (int): Size of the pathway.\n            K (int): Total number of significant genes in the universe.\n            N (int): Size of the gene universe.\n\n        Returns:\n            float: The hypergeometric p-value.\n        \"\"\"\n        if k < 0 or n < k or K < k or N < n or N < K:\n            # Invalid parameters are not expected but good to handle.\n            return 1.0\n\n        # P(X>=k) is 1 if k=0\n        if k == 0:\n            return 1.0\n        \n        try:\n            total_combinations = comb(N, n, exact=True)\n            if total_combinations == 0:\n                return 1.0\n        except ValueError: # Occurs if comb returns a non-integer float\n             total_combinations = comb(N, n, exact=False)\n\n        p_sum = 0.0\n        for j in range(k, min(n, K) + 1):\n            try:\n                term = comb(K, j, exact=True) * comb(N - K, n - j, exact=True)\n                p_sum += term\n            except (ValueError, TypeError): # Handle non-integer results if numbers are large\n                term = comb(K, j, exact=False) * comb(N - K, n - j, exact=False)\n                p_sum += term\n                \n        return p_sum / float(total_combinations)\n\n    def benjamini_hochberg(p_values):\n        \"\"\"\n        Applies the Benjamini-Hochberg (BH) multiple testing correction.\n\n        Args:\n            p_values (list[float]): A list of raw p-values.\n\n        Returns:\n            list[float]: A list of BH-adjusted p-values in the original order.\n        \"\"\"\n        m = len(p_values)\n        if m == 0:\n            return []\n        \n        p_values_np = np.array(p_values)\n        sorted_indices = np.argsort(p_values_np)\n        sorted_p_values = p_values_np[sorted_indices]\n        \n        q_values_sorted = np.zeros(m)\n        q_values_sorted[m-1] = sorted_p_values[m-1]\n        for i in range(m - 2, -1, -1):\n            rank = i + 1\n            correction = m / rank\n            q_values_sorted[i] = min(q_values_sorted[i+1], sorted_p_values[i] * correction)\n\n        q_values = np.zeros(m)\n        q_values[sorted_indices] = q_values_sorted\n        \n        return q_values.tolist()\n\n    # --- GSEA Helper Functions ---\n    \n    def calculate_es(pathway, weights, N):\n        \"\"\"\n        Calculates the Enrichment Score (ES) for a a single pathway.\n\n        Args:\n            pathway (set or list): The set of gene indices in the pathway.\n            weights (list[float]): The weights for all genes in the universe.\n            N (int): The size of the gene universe.\n\n        Returns:\n            float: The raw Enrichment Score.\n        \"\"\"\n        pathway_set = set(pathway)\n        N_h = len(pathway_set)\n        \n        if N_h == 0 or N_h == N:\n            return 0.0\n\n        # Calculate NR, sum of weights for genes in the pathway\n        NR_list = [weights[i-1] for i in pathway_set]\n        NR = sum(NR_list)\n\n        # If all weights in pathway are 0, NR is 0, increments are 0; ES should be -1.\n        # But problem states mu+ > 0 etc, which will fail. Let's rely on problem data not having this.\n        # For given data, all r_i != 0, so w_i > 0, NR > 0.\n        if NR == 0.0:\n            return -1.0 # The running sum will only decrease.\n\n        miss_penalty = 1.0 / (N - N_h)\n        \n        rs = 0.0\n        max_rs = -np.inf\n        min_rs = np.inf\n\n        for i in range(1, N + 1):\n            if i in pathway_set:\n                rs += weights[i-1] / NR\n            else:\n                rs -= miss_penalty\n            \n            if rs > max_rs:\n                max_rs = rs\n            if rs < min_rs:\n                min_rs = rs\n        \n        # Return the deviation with the larger absolute value\n        if max_rs > -min_rs:\n            return max_rs\n        else:\n            return min_rs\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": 12, \"r\": [2.5, 1.8, 1.2, 0.9, 0.4, -0.2, -0.5, -1.0, -1.3, -1.7, -2.0, -2.6],\n            \"G_sig\": {1, 2, 3, 8, 11, 12},\n            \"pathways\": [{1, 4, 6, 8}, {2, 3, 5, 7, 9}, {10, 11, 12}],\n            \"p_exp\": 1\n        },\n        {\n            \"N\": 10, \"r\": [3.0, 2.2, 1.5, 0.8, 0.1, -0.3, -0.9, -1.4, -2.1, -2.8],\n            \"G_sig\": {1, 2, 3, 9},\n            \"pathways\": [{4, 5, 6}, {1, 2, 3, 9}, {7}],\n            \"p_exp\": 1\n        },\n        {\n            \"N\": 8, \"r\": [1.2, 0.7, 0.3, -0.1, -0.4, -0.8, -1.1, -1.5],\n            \"G_sig\": set(),\n            \"pathways\": [{1, 2, 3}, {4, 5, 6, 7, 8}, {1, 2, 3, 4, 5, 6, 7, 8}],\n            \"p_exp\": 1\n        }\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        N = case[\"N\"]\n        r = case[\"r\"]\n        G_sig = case[\"G_sig\"]\n        pathways = case[\"pathways\"]\n        p_exp = case[\"p_exp\"]\n        K = len(G_sig)\n        \n        # --- Part 1: ORA Calculation ---\n        ora_p_values = []\n        for S in pathways:\n            n = len(S)\n            k = len(S.intersection(G_sig))\n            p_val = calculate_hypergeometric_p_value(k, n, K, N)\n            ora_p_values.append(p_val)\n        \n        q_values = benjamini_hochberg(ora_p_values)\n        min_q_value = min(q_values) if q_values else 0.0\n        \n        # --- Part 2: GSEA Calculation ---\n        all_nes_values = []\n        gsea_norm_cache = {} \n        weights = [abs(score)**p_exp for score in r]\n        gene_indices = range(1, N + 1)\n        \n        for S in pathways:\n            N_h = len(S)\n            \n            if N_h == 0 or N_h == N:\n                nes = 0.0\n            else:\n                if N_h not in gsea_norm_cache:\n                    # Calculate null distribution for this N_h and cache it\n                    positive_es_sum, negative_es_sum = 0.0, 0.0\n                    n_pos, n_neg = 0, 0\n                    \n                    for null_pathway in combinations(gene_indices, N_h):\n                        es_null = calculate_es(null_pathway, weights, N)\n                        if es_null > 0:\n                            positive_es_sum += es_null\n                            n_pos += 1\n                        elif es_null < 0:\n                            negative_es_sum += es_null\n                            n_neg += 1\n                            \n                    mu_plus = positive_es_sum / n_pos if n_pos > 0 else 0.0\n                    mu_minus = -negative_es_sum / n_neg if n_neg > 0 else 0.0\n                    gsea_norm_cache[N_h] = (mu_plus, mu_minus)\n                \n                mu_plus, mu_minus = gsea_norm_cache[N_h]\n                observed_es = calculate_es(S, weights, N)\n                \n                if observed_es > 0 and mu_plus > 0:\n                    nes = observed_es / mu_plus\n                elif observed_es < 0 and mu_minus > 0:\n                    nes = -observed_es / mu_minus\n                else:\n                    nes = 0.0\n            \n            all_nes_values.append(nes)\n            \n        max_abs_nes = max([abs(nes) for nes in all_nes_values]) if all_nes_values else 0.0\n        \n        final_results.append([min_q_value, max_abs_nes])\n    \n    # Format the final output as specified\n    formatted_case_results = [f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in final_results]\n    print(f\"[{','.join(formatted_case_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Obtaining a p-value from a pathway analysis is only the beginning; its correct interpretation depends critically on understanding the null hypothesis being tested. This advanced exercise explores this concept by having you implement two different permutation-based null models: a \"competitive\" model and a \"self-contained\" model. This practice directly contrasts the statistical questions behind \"Is my pathway more dysregulated than random gene sets?\" and \"Are the genes in my pathway associated with the phenotype at all?\", building the statistical intuition necessary to choose the appropriate method and critically evaluate published results. ",
            "id": "4373301",
            "problem": "You are given a small curated pathway database and a synthetic gene expression study with two phenotypic groups. The objective is to implement two null models for pathway enrichment assessment using permutation strategies and to compute Monte Carlo $p$-values for a defined pathway-level statistic. Your program must implement both the competitive null model (sampling random gene sets) and the self-contained null model (permuting sample labels), and then evaluate specific test cases.\n\nFundamental base:\n- The null hypothesis framework asserts that under the null, a test statistic’s distribution is invariant to transformations that preserve the null structure (exchangeability). In permutation testing, this invariance allows empirical estimation of the null distribution by resampling.\n- For two independent groups with continuous measurements, the unpaired two-sample $t$-statistic with pooled variance provides a standardized effect size for each gene.\n\nDefinitions and data:\n- Gene universe $\\mathcal{U}$ of size $|\\mathcal{U}| = 10$: $\\{\\text{G1}, \\text{G2}, \\text{G3}, \\text{G4}, \\text{G5}, \\text{G6}, \\text{G7}, \\text{G8}, \\text{G9}, \\text{G10}\\}$.\n- Curated pathways (each is a subset of $\\mathcal{U}$):\n  - Pathway $\\text{P1} = \\{\\text{G1}, \\text{G2}, \\text{G3}, \\text{G4}\\}$.\n  - Pathway $\\text{P2} = \\{\\text{G3}, \\text{G5}, \\text{G7}, \\text{G9}\\}$.\n  - Pathway $\\text{P3} = \\{\\text{G10}\\}$.\n- Expression matrix $X \\in \\mathbb{R}^{10 \\times 8}$ with genes ordered as listed above and samples ordered consistently for all genes. There are $8$ samples: the first $4$ are group A (controls) and the last $4$ are group B (cases). For gene $\\text{Gi}$, the row $X_{i,\\cdot}$ (values across $8$ samples) is specified as follows:\n  - $\\text{G1}$: $[5.0, 5.2, 4.8, 5.1, 6.8, 7.1, 7.0, 6.9]$.\n  - $\\text{G2}$: $[3.0, 3.1, 3.2, 2.9, 4.0, 4.1, 3.9, 4.2]$.\n  - $\\text{G3}$: $[8.0, 7.9, 8.1, 8.2, 6.8, 6.9, 7.0, 6.7]$.\n  - $\\text{G4}$: $[10.0, 9.8, 10.1, 10.2, 8.9, 9.1, 9.0, 9.2]$.\n  - $\\text{G5}$: $[2.0, 2.1, 2.0, 1.9, 2.0, 2.1, 2.2, 2.1]$.\n  - $\\text{G6}$: $[5.0, 5.0, 5.1, 4.9, 5.0, 5.0, 4.9, 5.1]$.\n  - $\\text{G7}$: $[7.0, 7.1, 6.9, 7.0, 7.2, 7.0, 7.1, 7.1]$.\n  - $\\text{G8}$: $[3.0, 3.1, 2.9, 3.0, 3.0, 3.1, 3.0, 2.9]$.\n  - $\\text{G9}$: $[6.0, 6.1, 5.9, 6.2, 6.0, 6.1, 6.2, 5.8]$.\n  - $\\text{G10}$: $[4.0, 4.2, 4.1, 4.0, 5.0, 5.2, 5.1, 5.1]$.\n- Group labels vector $y \\in \\{0,1\\}^{8}$ is $[0, 0, 0, 0, 1, 1, 1, 1]$.\n\nGene-level statistic:\n- For each gene $g$, let group A indices be $\\mathcal{I}_0$ with $n_0 = 4$ samples and group B indices be $\\mathcal{I}_1$ with $n_1 = 4$ samples.\n- Let $\\bar{x}_{g0}$ and $\\bar{x}_{g1}$ be the sample means in groups A and B, respectively, and $s^2_{g0}$ and $s^2_{g1}$ be their unbiased sample variances. The pooled variance is\n$$\ns_{p,g}^2 = \\frac{(n_0 - 1)s^2_{g0} + (n_1 - 1)s^2_{g1}}{n_0 + n_1 - 2}.\n$$\n- The unpaired two-sample $t$-statistic with equal variances is\n$$\nt_g = \\frac{\\bar{x}_{g1} - \\bar{x}_{g0}}{\\sqrt{s_{p,g}^2\\left(\\frac{1}{n_0} + \\frac{1}{n_1}\\right)}}.\n$$\n\nPathway-level statistic:\n- For a pathway $P \\subset \\mathcal{U}$, define $S(P) = \\frac{1}{|P|}\\sum_{g \\in P} |t_g|$.\n\nNull models and permutation strategies:\n- Competitive null model: under the null, the observed gene-level $t$-statistics are not unusually concentrated in $P$ compared to random gene sets of the same size. The permutation strategy is to draw, without replacement, random subsets $R_r \\subset \\mathcal{U}$ with $|R_r| = |P|$, for $r \\in \\{1,\\dots,R\\}$, and compute $S(R_r)$.\n- Self-contained null model: under the null, genes in $P$ are not associated with the phenotype. The permutation strategy is to randomly permute the sample labels $y$ to obtain $y^{(r)}$ for $r \\in \\{1,\\dots,R\\}$, recompute gene-level $t^{(r)}_g$ using $y^{(r)}$, and then compute $S^{(r)}(P)$.\n- Monte Carlo $p$-value: for a one-sided test of enrichment,\n$$\n\\hat{p} = \\frac{1 + \\sum_{r=1}^{R} \\mathbf{1}\\{ S^{(r)} \\ge S_{\\text{obs}} \\}}{R + 1},\n$$\nwhere $S^{(r)}$ denotes $S(R_r)$ in the competitive null and $S^{(r)}(P)$ in the self-contained null, and $S_{\\text{obs}}$ is the observed $S(P)$ computed with the given labels $y$.\n\nRandomness and reproducibility:\n- Use the NumPy pseudorandom number generator with the PCG64 bit generator. For each test case, instantiate a new generator with the specified seed, and perform exactly $R$ permutations as specified.\n\nTest suite:\nImplement a program that computes $\\hat{p}$ for each of the following parameter sets. Each parameter set is a tuple $(\\text{null\\_type}, \\text{pathway}, R, \\text{seed})$, where $\\text{null\\_type} \\in \\{\\text{\"competitive\"}, \\text{\"self-contained\"}\\}$.\n- Case $1$: $(\\text{\"competitive\"}, \\text{\"P1\"}, 1000, 2023)$.\n- Case $2$: $(\\text{\"self-contained\"}, \\text{\"P1\"}, 200, 7)$.\n- Case $3$: $(\\text{\"competitive\"}, \\text{\"P3\"}, 500, 999)$.\n- Case $4$: $(\\text{\"self-contained\"}, \\text{\"P2\"}, 50, 12345)$.\n- Case $5$: $(\\text{\"competitive\"}, \\text{\"P2\"}, 1, 42)$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the cases above. Example format: $[\\text{result1},\\text{result2},\\text{result3},\\text{result4},\\text{result5}]$.\n- Each result must be a floating-point number equal to the Monte Carlo $p$-value $\\hat{p}$ rounded to exactly $6$ decimal places.",
            "solution": "We begin from the foundational principle of permutation tests: under a null hypothesis that renders certain transformations of the data invariant, the joint distribution of the data is exchangeable with respect to those transformations. In a gene expression context with two phenotypic groups and curated pathways, two distinct nulls are common. The competitive null tests whether the chosen pathway is more enriched for strong signals than random gene sets of the same size, which is suitable when comparing a pathway against the rest of the genome or curated database. The self-contained null tests whether the genes within the pathway are associated with the phenotype at all, assessed by breaking the link between samples and phenotypes while preserving intra-gene structure.\n\nGene-level statistic derivation:\nFor each gene $g$, with group A sample set $\\mathcal{I}_0$ of size $n_0$ and group B sample set $\\mathcal{I}_1$ of size $n_1$, compute the sample means $\\bar{x}_{g0}$ and $\\bar{x}_{g1}$ and unbiased variances $s^2_{g0}$ and $s^2_{g1}$. Assuming equal population variances across the two groups, the pooled variance $s_{p,g}^2$ estimates the common variance using\n$$\ns_{p,g}^2 = \\frac{(n_0 - 1)s^2_{g0} + (n_1 - 1)s^2_{g1}}{n_0 + n_1 - 2}.\n$$\nThe standardized difference in means is\n$$\nt_g = \\frac{\\bar{x}_{g1} - \\bar{x}_{g0}}{\\sqrt{s_{p,g}^2\\left(\\frac{1}{n_0} + \\frac{1}{n_1}\\right)}},\n$$\nwhich is a well-established statistic for comparing two independent groups in the presence of approximately equal variances. We adopt this to quantify per-gene signal because under the null of no differential expression, $t_g$ has a distribution centered near zero, and the magnitude $|t_g|$ reflects effect strength irrespective of direction.\n\nPathway-level statistic:\nA pathway consists of curated genes $P \\subset \\mathcal{U}$. Aggregating $|t_g|$ over $g \\in P$ yields\n$$\nS(P) = \\frac{1}{|P|}\\sum_{g \\in P} |t_g|.\n$$\nThe absolute value provides a two-sided sensitivity condensed into a single-sided enrichment statistic. The mean accounts for pathway size, enabling fair comparison across sets of different cardinalities, including the boundary case $|P| = 1$.\n\nNull model constructions via exchangeability:\n- Competitive null: The hypothesis is that $P$ contains no more signal than a typical set of $|P|$ genes drawn from $\\mathcal{U}$. Given observed $t_g$ computed with the true labels $y$, the resampling procedure that preserves the null is random sampling without replacement of gene sets $R_r \\subset \\mathcal{U}$ with $|R_r| = |P|$. Under the null, the positions of large $|t_g|$ among genes are exchangeable, so the distribution of $S(R_r)$ estimates the null distribution of $S(P)$.\n- Self-contained null: The hypothesis is that genes in $P$ are not associated with the phenotype. Under the null, labels are exchangeable with respect to samples. Thus, permuting the labels $y$ to $y^{(r)}$ and recomputing gene-level statistics $t^{(r)}_g$ preserves the null structure while breaking any association. The distribution of $S^{(r)}(P)$ estimates the null distribution for $S(P)$ within the pathway.\n\nMonte Carlo $p$-value:\nFor a one-sided test that larger $S$ indicates stronger enrichment, the Monte Carlo estimator\n$$\n\\hat{p} = \\frac{1 + \\sum_{r=1}^{R} \\mathbf{1}\\{ S^{(r)} \\ge S_{\\text{obs}} \\}}{R + 1}\n$$\nfollows from counting how often the resampled statistic is as extreme or more extreme than the observed. The $+1$ in numerator and denominator produces an unbiased estimate under the randomization distribution and prevents zero values when $R$ is finite. The indicator $\\mathbf{1}\\{\\cdot\\}$ counts events where $S^{(r)}$ meets or exceeds $S_{\\text{obs}}$, matching the directionality of the enrichment test.\n\nAlgorithmic design:\n1. Encode the gene universe $\\mathcal{U}$, curated pathways, expression matrix $X$, and labels $y$ exactly as specified. The sample sizes are $n_0 = 4$ and $n_1 = 4$.\n2. Compute per-gene $t$-statistics $t_g$ using the pooled-variance formula shown above. This can be vectorized across genes by slicing columns corresponding to $y=0$ and $y=1$, computing means and variances with degrees of freedom $1$, then assembling $t_g$.\n3. For each test case $(\\text{null\\_type}, P, R, \\text{seed})$:\n   - Initialize a NumPy Generator with PCG64, seeded by the provided integer seed.\n   - Compute the observed $S_{\\text{obs}} = S(P)$ using $|t_g|$ and the pathway membership $P$.\n   - If $\\text{null\\_type} = \\text{\"competitive\"}$:\n     - Repeat $R$ times: sample, without replacement, a subset of gene indices of size $|P|$ uniformly from $\\{1,\\dots,|\\mathcal{U}|\\}$ using the generator. Compute $S(R_r)$ as the mean of $|t_g|$ over the sampled indices. Count how many times $S(R_r) \\ge S_{\\text{obs}}$.\n   - If $\\text{null\\_type} = \\text{\"self-contained\"}$:\n     - Repeat $R$ times: permute $y$ to $y^{(r)}$ using the generator. Recompute $t^{(r)}_g$ with the permuted labels via the pooled-variance formula and then compute $S^{(r)}(P)$ as the mean of $|t^{(r)}_g|$ over genes in $P$. Count how many times $S^{(r)}(P) \\ge S_{\\text{obs}}$.\n   - Compute $\\hat{p}$ via the Monte Carlo formula and round to exactly $6$ decimal places.\n4. Aggregate the five results into a single list and print them in the required single-line format without spaces.\n\nEdge cases and coverage:\n- The case with $R = 1$ tests the boundary behavior; the $+1$ adjustment ensures a valid probability in $\\{\\frac{1}{2}, 1\\}$ depending on whether the single resample exceeds $S_{\\text{obs}}$.\n- Pathway $\\text{P3}$ with $|\\text{P3}| = 1$ tests pathway size boundary handling, where $S(P)$ reduces to $|t_g|$ for a single gene.\n- Different seeds ensure independent and reproducible Monte Carlo estimates.\n- Both null models are exercised on overlapping and distinct pathway content to probe the logic and implementation.\n\nComputational considerations:\n- With $R \\le 1000$ and $|\\mathcal{U}| = 10$, the algorithm is efficient and numerically stable. The pooled variance denominator remains positive given the variability in the provided expression data, avoiding division by zero.\n\nThe final program follows these steps precisely, initializes the random generator per case with the specified seed, and outputs the list $[\\hat{p}_1,\\hat{p}_2,\\hat{p}_3,\\hat{p}_4,\\hat{p}_5]$ with each $\\hat{p}_i$ rounded to $6$ decimals.",
            "answer": "```python\nimport numpy as np\n\ndef compute_t_stats_equal_var(expr_matrix, labels):\n    \"\"\"\n    Compute per-gene two-sample t-statistics with pooled variance.\n    expr_matrix: shape (G, N)\n    labels: array length N with values 0 or 1\n    Returns: array of length G with t statistics (group1 - group0)\n    \"\"\"\n    labels = np.asarray(labels)\n    idx0 = np.where(labels == 0)[0]\n    idx1 = np.where(labels == 1)[0]\n    x0 = expr_matrix[:, idx0]\n    x1 = expr_matrix[:, idx1]\n    n0 = x0.shape[1]\n    n1 = x1.shape[1]\n    mean0 = x0.mean(axis=1)\n    mean1 = x1.mean(axis=1)\n    # Unbiased sample variances with ddof=1\n    var0 = x0.var(axis=1, ddof=1)\n    var1 = x1.var(axis=1, ddof=1)\n    sp2 = (((n0 - 1) * var0) + ((n1 - 1) * var1)) / (n0 + n1 - 2)\n    denom = np.sqrt(sp2 * (1.0 / n0 + 1.0 / n1))\n    # To be safe, handle any potential zero denominators by setting t=0\n    with np.errstate(divide='ignore', invalid='ignore'):\n        t = (mean1 - mean0) / denom\n        t = np.where(np.isfinite(t), t, 0.0)\n    return t\n\ndef s_stat(mean_abs_t_values, indices):\n    \"\"\"\n    Compute S(P) = mean(|t_g|) over indices for a given pathway.\n    mean_abs_t_values: precomputed |t_g| for all genes\n    indices: list/array of gene indices in the pathway\n    \"\"\"\n    if len(indices) == 0:\n        return 0.0\n    return float(np.mean(mean_abs_t_values[indices]))\n\ndef monte_carlo_pvalue_competitive(abs_t, pathway_indices, R, seed):\n    \"\"\"\n    Competitive null: sample random gene sets of same size as pathway, compute S, compare to observed.\n    \"\"\"\n    rng = np.random.Generator(np.random.PCG64(seed))\n    k = len(pathway_indices)\n    S_obs = s_stat(abs_t, pathway_indices)\n    count_ge = 0\n    G = abs_t.shape[0]\n    all_idx = np.arange(G)\n    for _ in range(R):\n        sampled = rng.choice(all_idx, size=k, replace=False)\n        S_perm = s_stat(abs_t, sampled)\n        if S_perm >= S_obs:\n            count_ge += 1\n    p_hat = (1 + count_ge) / (R + 1)\n    return p_hat\n\ndef monte_carlo_pvalue_selfcontained(expr_matrix, labels, pathway_indices, R, seed):\n    \"\"\"\n    Self-contained null: permute labels, recompute t-stats, compute S on pathway, compare to observed S.\n    \"\"\"\n    # Observed S using original labels\n    t_obs = compute_t_stats_equal_var(expr_matrix, labels)\n    abs_t_obs = np.abs(t_obs)\n    S_obs = s_stat(abs_t_obs, pathway_indices)\n\n    rng = np.random.Generator(np.random.PCG64(seed))\n    labels = np.asarray(labels)\n    count_ge = 0\n    for _ in range(R):\n        permuted = rng.permutation(labels)\n        t_perm = compute_t_stats_equal_var(expr_matrix, permuted)\n        abs_t_perm = np.abs(t_perm)\n        S_perm = s_stat(abs_t_perm, pathway_indices)\n        if S_perm >= S_obs:\n            count_ge += 1\n    p_hat = (1 + count_ge) / (R + 1)\n    return p_hat\n\ndef solve():\n    # Gene universe and pathways\n    genes = [\"G1\",\"G2\",\"G3\",\"G4\",\"G5\",\"G6\",\"G7\",\"G8\",\"G9\",\"G10\"]\n    pathway_map = {\n        \"P1\": [\"G1\",\"G2\",\"G3\",\"G4\"],\n        \"P2\": [\"G3\",\"G5\",\"G7\",\"G9\"],\n        \"P3\": [\"G10\"],\n    }\n    # Expression matrix X: shape (10, 8)\n    X = np.array([\n        [5.0, 5.2, 4.8, 5.1, 6.8, 7.1, 7.0, 6.9],  # G1\n        [3.0, 3.1, 3.2, 2.9, 4.0, 4.1, 3.9, 4.2],  # G2\n        [8.0, 7.9, 8.1, 8.2, 6.8, 6.9, 7.0, 6.7],  # G3\n        [10.0, 9.8, 10.1, 10.2, 8.9, 9.1, 9.0, 9.2],  # G4\n        [2.0, 2.1, 2.0, 1.9, 2.0, 2.1, 2.2, 2.1],  # G5\n        [5.0, 5.0, 5.1, 4.9, 5.0, 5.0, 4.9, 5.1],  # G6\n        [7.0, 7.1, 6.9, 7.0, 7.2, 7.0, 7.1, 7.1],  # G7\n        [3.0, 3.1, 2.9, 3.0, 3.0, 3.1, 3.0, 2.9],  # G8\n        [6.0, 6.1, 5.9, 6.2, 6.0, 6.1, 6.2, 5.8],  # G9\n        [4.0, 4.2, 4.1, 4.0, 5.0, 5.2, 5.1, 5.1],  # G10\n    ], dtype=float)\n    # Labels: first 4 controls (0), last 4 cases (1)\n    y = np.array([0,0,0,0,1,1,1,1], dtype=int)\n\n    # Precompute observed gene-level t statistics using provided labels for competitive null\n    t_obs_all = compute_t_stats_equal_var(X, y)\n    abs_t_obs_all = np.abs(t_obs_all)\n\n    # Build pathway index lists\n    gene_index = {g: i for i, g in enumerate(genes)}\n    pathway_indices = {k: np.array([gene_index[g] for g in v], dtype=int) for k, v in pathway_map.items()}\n\n    # Define test cases: (null_type, pathway, R, seed)\n    test_cases = [\n        (\"competitive\", \"P1\", 1000, 2023),\n        (\"self-contained\", \"P1\", 200, 7),\n        (\"competitive\", \"P3\", 500, 999),\n        (\"self-contained\", \"P2\", 50, 12345),\n        (\"competitive\", \"P2\", 1, 42),\n    ]\n\n    results = []\n    for null_type, pathway, R, seed in test_cases:\n        idx = pathway_indices[pathway]\n        if null_type == \"competitive\":\n            p = monte_carlo_pvalue_competitive(abs_t_obs_all, idx, R, seed)\n        elif null_type == \"self-contained\":\n            p = monte_carlo_pvalue_selfcontained(X, y, idx, R, seed)\n        else:\n            raise ValueError(\"Unknown null_type\")\n        results.append(round(p, 6))\n\n    # Print in the exact required format, no spaces, 6 decimals\n    formatted = \"[\" + \",\".join(f\"{v:.6f}\" for v in results) + \"]\"\n    print(formatted)\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}