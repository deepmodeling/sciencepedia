{
    "hands_on_practices": [
        {
            "introduction": "In systems biomedicine, deep learning models like the U-Net are crucial for segmenting structures in histopathology or microscopy images. This exercise  provides hands-on practice in tracking the spatial dimensions of feature maps as they pass through a typical encoder-decoder network. Mastering these layer-by-layer calculations is a fundamental skill for designing custom architectures and for debugging the tensor size mismatches that frequently arise in practice.",
            "id": "4332691",
            "problem": "In a systems biomedicine pipeline for whole-slide histopathology analysis, a convolutional encoder–decoder network of the U-Net family is used to segment cellular compartments in multiplexed immunofluorescence images. Consider a $2$-dimensional U-Net with $3$ down-sampling stages and $3$ up-sampling stages. The spatial dimensions only are of interest. The input image has spatial size $(H, W)$, where $H$ and $W$ are positive integers. The architecture is as follows, with spatial operations specified exactly:\n\n- Encoder stage $1$: two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and zero-padding chosen to preserve spatial size at each convolution (“same” padding); then a max-pooling layer with kernel size $2 \\times 2$, stride $2$, and zero-padding $0$.\n- Encoder stage $2$: two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding; then a max-pooling layer with kernel size $2 \\times 2$, stride $2$, and zero-padding $0$.\n- Encoder stage $3$: two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding; then a max-pooling layer with kernel size $2 \\times 2$, stride $2$, and zero-padding $0$.\n- Bottleneck: two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding.\n- Decoder stage $3$: one transposed convolution (“up-convolution”) with kernel size $2 \\times 2$, stride $2$, zero-padding $0$, and output padding $0$; concatenate with the encoder stage $3$ feature map taken immediately after its two “same”-padded convolutions and before its max-pooling (use symmetric center-cropping of the skip feature map if the spatial sizes do not match exactly); then two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding.\n- Decoder stage $2$: one transposed convolution with kernel size $2 \\times 2$, stride $2$, zero-padding $0$, and output padding $0$; concatenate with the encoder stage $2$ feature map taken immediately after its two “same”-padded convolutions and before its max-pooling (use symmetric center-cropping if needed); then two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding.\n- Decoder stage $1$: one transposed convolution with kernel size $2 \\times 2$, stride $2$, zero-padding $0$, and output padding $0$; concatenate with the encoder stage $1$ feature map taken immediately after its two “same”-padded convolutions and before its max-pooling (use symmetric center-cropping if needed); then two convolutional layers with kernel size $3 \\times 3$, stride $1$, dilation $1$, and “same” padding.\n- Final prediction layer: a $1 \\times 1$ convolution with stride $1$.\n\nAssume all operations are applied identically and independently along the $H$ and $W$ dimensions; channel counts do not affect spatial sizes and may be ignored. Concatenation does not change spatial sizes and is performed only after exactly matching the spatial sizes by symmetric cropping of the skip feature maps as described.\n\nTasks:\n- Using only fundamental definitions of discrete convolution, striding, padding, and pooling, compute the spatial size at the output of every spatial operation in the encoder and decoder as a function of $(H, W)$, showing how rounding arises where applicable. Explicitly identify any points where symmetric cropping of skip connections is required and quantify the mismatch at each skip as a function of $H$ and $W$.\n- Derive a closed-form analytical expression for the final segmentation map spatial size as a function of $(H, W)$ under the above architecture and cropping rule.\n- Briefly discuss how the choice of padding (“same” versus “valid”) in the convolutional layers would alter the layer-by-layer sizes and the final output size, and argue which padding strategy is preferable for tile-based histopathology inference to mitigate border artifacts, justifying your answer from first principles of discrete convolution and sampling theory.\n\nProvide your final answer for the closed-form final spatial size as a row matrix containing the two expressions for the height and width, respectively. No units are required. If you choose to express intermediate rounding, use the floor function notation. Do not include any text in the final answer box.",
            "solution": "The problem statement is well-defined, scientifically grounded in the principles of deep learning architectures, and internally consistent. It describes a standard U-Net architecture with specific layer parameters, providing a clear basis for calculation and analysis. The tasks are objective and solvable using the provided information. Therefore, the problem is valid.\n\nWe will analyze the spatial dimensions, denoted by $(H, W)$, as they are transformed by the layers of the specified U-Net architecture. The operations on the height dimension $H$ and the width dimension $W$ are identical and independent. We will derive the expressions for $H$, and the results for $W$ follow by analogy.\n\nThe fundamental formulae for the output size $S_{out}$ given an input size $S_{in}$, kernel size $k$, stride $s$, padding $p$, and dilation $d$ are:\n- For a standard 2D convolution: $S_{out} = \\lfloor \\frac{S_{in} + 2p - d(k-1) - 1}{s} \\rfloor + 1$.\n- For a max-pooling layer: $S_{out} = \\lfloor \\frac{S_{in} + 2p - k}{s} \\rfloor + 1$.\n- For a transposed convolution: $S_{out} = (S_{in} - 1)s - 2p + k + p_{out}$, where $p_{out}$ is the output padding.\n\nLet's apply these to the specified architecture.\n\n**1. Layer-by-Layer Spatial Size Calculation**\n\nLet the input image size be $(H, W)$. Let $f_{down}(x) = \\lfloor x/2 \\rfloor$.\n\n**Encoder Path**\n- **Input:** The initial spatial size is $(H, W)$.\n\n- **Encoder stage 1:**\n  - Two convolutions with kernel size $k=3$, stride $s=1$, dilation $d=1$, and \"same\" padding. \"Same\" padding is defined to preserve spatial size. For $k=3, s=1, d=1$, this requires $p=1$. The size after these two convolutions remains $(H, W)$. This feature map, denoted $S_1$, is passed to the skip connection.\n  - One max-pooling layer with $k=2, s=2, p=0$. The output size is $S_{out} = \\lfloor \\frac{S_{in} - 2}{2} \\rfloor + 1 = \\lfloor S_{in}/2 - 1 \\rfloor + 1 = \\lfloor S_{in}/2 \\rfloor = f_{down}(S_{in})$.\n  - Output size of stage 1: $(f_{down}(H), f_{down}(W))$.\n\n- **Encoder stage 2:**\n  - Input size: $(f_{down}(H), f_{down}(W))$.\n  - Two \"same\" padded convolutions preserve the size. The feature map $S_2$ for the skip connection has size $(f_{down}(H), f_{down}(W))$.\n  - One max-pooling layer reduces the size.\n  - Output size of stage 2: $(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$.\n\n- **Encoder stage 3:**\n  - Input size: $(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$.\n  - Two \"same\" padded convolutions preserve the size. The feature map $S_3$ for the skip connection has size $(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$.\n  - One max-pooling layer reduces the size.\n  - Output size of stage 3: $(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W))))$.\n\n**Bottleneck**\n- Input size: $(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W))))$.\n- Two \"same\" padded convolutions preserve the size.\n- Output size of bottleneck: $(f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W))))$. Let's denote this $(H_b, W_b)$.\n\n**Decoder Path and Skip Connection Mismatches**\nLet $f_{up}(x) = 2x$.\n\n- **Decoder stage 3:**\n  - Input from bottleneck: $(H_b, W_b) = (f_{down}(f_{down}(f_{down}(H))), f_{down}(f_{down}(f_{down}(W))))$.\n  - One transposed convolution with $k=2, s=2, p=0, p_{out}=0$. The output size is $S_{out} = (S_{in}-1) \\cdot 2 - 0 + 2 + 0 = 2S_{in}$. The size becomes $(2H_b, 2W_b)$. Let's call this $(H_{u3}, W_{u3})$.\n  - Skip connection $S_3$ size: $(f_{down}(f_{down}(H)), f_{down}(f_{down}(W)))$.\n  - **Mismatch for $H$ dimension:** The mismatch is $\\Delta H_3 = f_{down}(f_{down}(H)) - 2H_b = f_{down}(f_{down}(H)) - 2 f_{down}(f_{down}(f_{down}(H)))$.\n    This difference is $f_{down}(f_{down}(H)) \\pmod 2$, which is $0$ if $f_{down}(f_{down}(H))$ is even, and $1$ if it is odd. Symmetric cropping of $S_3$ is required if this mismatch is non-zero. The width mismatch $\\Delta W_3$ is analogous.\n  - After cropping and concatenation, the size is $(2H_b, 2W_b)$.\n  - Two \"same\" convolutions preserve the size.\n  - Output size of decoder stage 3: $(H_{d3}, W_{d3}) = (2H_b, 2W_b)$.\n\n- **Decoder stage 2:**\n  - Input from decoder stage 3: $(H_{d3}, W_{d3}) = (2H_b, 2W_b)$.\n  - One transposed convolution doubles the size to $(2 H_{d3}, 2 W_{d3}) = (4H_b, 4W_b)$. Let's call this $(H_{u2}, W_{u2})$.\n  - Skip connection $S_2$ size: $(f_{down}(H), f_{down}(W))$.\n  - **Mismatch for $H$ dimension:** $\\Delta H_2 = f_{down}(H) - 4H_b = f_{down}(H) - 4 f_{down}(f_{down}(f_{down}(H)))$. Symmetric cropping of $S_2$ is required to match the size $(4H_b, 4W_b)$.\n  - After cropping and concatenation, the size is $(4H_b, 4W_b)$.\n  - Two \"same\" convolutions preserve the size.\n  - Output size of decoder stage 2: $(H_{d2}, W_{d2}) = (4H_b, 4W_b)$.\n\n- **Decoder stage 1:**\n  - Input from decoder stage 2: $(H_{d2}, W_{d2}) = (4H_b, 4W_b)$.\n  - One transposed convolution doubles the size to $(2 H_{d2}, 2 W_{d2}) = (8H_b, 8W_b)$. Let's call this $(H_{u1}, W_{u1})$.\n  - Skip connection $S_1$ size: $(H, W)$.\n  - **Mismatch for $H$ dimension:** $\\Delta H_1 = H - 8H_b = H - 8 f_{down}(f_{down}(f_{down}(H)))$. Symmetric cropping of $S_1$ is required to match the size $(8H_b, 8W_b)$.\n  - After cropping and concatenation, the size is $(8H_b, 8W_b)$.\n  - Two \"same\" convolutions preserve the size.\n  - Output size of decoder stage 1: $(H_{d1}, W_{d1}) = (8H_b, 8W_b)$.\n\n**Final Prediction Layer**\n- Input size: $(8H_b, 8W_b)$.\n- A $1 \\times 1$ convolution with stride $1$ preserves the spatial size.\n- Final output size: $(H_{out}, W_{out}) = (8H_b, 8W_b)$.\n\n**2. Closed-Form Expression for Final Size**\n\nThe final output height is given by:\n$$ H_{out} = 8 H_b = 8 \\cdot f_{down}(f_{down}(f_{down}(H))) = 8 \\left\\lfloor \\frac{\\lfloor \\frac{\\lfloor H/2 \\rfloor}{2} \\rfloor}{2} \\right\\rfloor $$\nThis expression can be simplified. A property of the floor function is that $\\lfloor \\lfloor x/n \\rfloor / m \\rfloor = \\lfloor x/(nm) \\rfloor$. Applying this property iteratively:\n$$ H_{out} = 8 \\left\\lfloor \\frac{\\lfloor H/4 \\rfloor}{2} \\right\\rfloor = 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor $$\nThis expression calculates the largest multiple of $8$ that is less than or equal to $H$.\nThe same logic applies to the width dimension $W$. Thus, the final spatial size of the segmentation map is:\n$$ (H_{out}, W_{out}) = \\left( 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor, 8 \\left\\lfloor \\frac{W}{8} \\right\\rfloor \\right) $$\n\n**3. Discussion of Padding Strategy**\n\nThe choice of padding in the convolutional layers significantly impacts the network's behavior, particularly for tile-based analysis.\n\n- **\"Same\" Padding (as specified):** With \"same\" padding, the convolutions within each encoder and decoder block do not shrink the feature maps. Size reduction only occurs at max-pooling layers. This simplifies the architecture but, as shown, leads to an asymmetry between the down-sampling path ($S_{out} = \\lfloor S_{in}/2 \\rfloor$) and the up-sampling path ($S_{out} = 2S_{in}$). This asymmetry necessitates cropping of the high-resolution feature maps from the skip connections before concatenation. The final output has a smaller size than the input, unless input dimensions are multiples of $2^D$, where $D=3$ is the number of down-sampling stages. When processing tiles, the output tiles have the same dimension issues. While this makes stitching seem conceptually simple if input sizes are chosen carefully (e.g., multiples of $8$), the predictions at the borders of each output tile are inherently less reliable. This is because the receptive fields of these output pixels extend into the zero-padded regions of the original input tile, which is artificial data. Simply stitching these tiles would create a grid of artifact-laden seams in the final whole-slide segmentation. An explicit post-processing step to crop the unreliable borders from each output tile would be necessary.\n\n- **\"Valid\" Padding:** With \"valid\" padding ($p=0$), each convolution would reduce the spatial size. For a $3 \\times 3$ kernel, the size shrinks by $2$ at each layer ($S_{out} = S_{in} - 2$). A block of two convolutions would shrink the size by $4$. This would create a much larger size discrepancy at the skip connections, requiring more aggressive cropping. The final output of the network would be significantly smaller than the input.\n  In the context of tile-based histopathology inference, this is often the preferable strategy. The \"overlap-tile\" method is a standard technique to mitigate border artifacts. One extracts overlapping input tiles from the whole-slide image, processes each one through the network, and then discards the unreliable border region of each output prediction map before stitching the valid central parts together. A U-Net with \"valid\" convolutions naturally implements the discarding of borders. The shrinking of the feature map means that every pixel in the final, smaller output map is calculated based on a receptive field that was fully contained within the valid (non-padded) region of the input tile. From a sampling theory perspective, this ensures that every output is a function only of true image signal, not artificial padding. This increases the fidelity of the results and simplifies the stitching logic, as the network's architecture itself defines the \"valid\" region of the output, obviating the need for a separate manual cropping parameter in post-processing. Therefore, for producing a high-quality, seamless segmentation of a large image from tiles, \"valid\" padding is the more principled and robust choice.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} 8 \\left\\lfloor \\frac{H}{8} \\right\\rfloor & 8 \\left\\lfloor \\frac{W}{8} \\right\\rfloor \\end{pmatrix} } $$"
        },
        {
            "introduction": "Predicting patient outcomes over time is a core task in clinical applications, but the presence of right-censored data complicates model evaluation. This problem  walks through the manual calculation of the Concordance Index (C-index), a standard metric for assessing the discriminative power of survival models. This practice solidifies the definition of concordance and encourages critical thinking about the metric's properties and limitations in real-world biomedical cohorts.",
            "id": "4332649",
            "problem": "A Deep Learning (DL) survival model is trained on a systems biomedicine oncology cohort to predict patient risk scores for time-to-event outcomes. For each patient $i$, the model outputs a real-valued risk score $s_i$ where larger $s_i$ denotes higher estimated instantaneous risk. The observed data consist of follow-up time $T_i$ (in months) and event indicator $\\delta_i \\in \\{0,1\\}$, where $\\delta_i = 1$ denotes an observed event and $\\delta_i = 0$ denotes right censoring. The Concordance Index (C-index) is defined as the probability that, among all unordered patient pairs $(i,j)$ for which the earlier observed time corresponds to an event, the ordering of the predicted risks agrees with the ordering of observed times (i.e., the patient who experienced the earlier event has the larger predicted risk). Tied observed times are excluded. For tied risk scores within a comparable pair, assign a concordance credit of $\\frac{1}{2}$.\n\nYou are given $8$ patients with $(T_i, \\delta_i, s_i)$:\n- Patient $1$: $(T_1, \\delta_1, s_1) = (\\,5,\\;1,\\;0.9\\,)$\n- Patient $2$: $(T_2, \\delta_2, s_2) = (\\,12,\\;0,\\;0.7\\,)$\n- Patient $3$: $(T_3, \\delta_3, s_3) = (\\,9,\\;1,\\;1.1\\,)$\n- Patient $4$: $(T_4, \\delta_4, s_4) = (\\,4,\\;1,\\;0.6\\,)$\n- Patient $5$: $(T_5, \\delta_5, s_5) = (\\,15,\\;0,\\;0.8\\,)$\n- Patient $6$: $(T_6, \\delta_6, s_6) = (\\,8,\\;0,\\;0.9\\,)$\n- Patient $7$: $(T_7, \\delta_7, s_7) = (\\,10,\\;1,\\;1.0\\,)$\n- Patient $8$: $(T_8, \\delta_8, s_8) = (\\,7,\\;1,\\;0.5\\,)$\n\nStarting from the foundational survival analysis definition above, compute the C-index on this cohort. Additionally, use first principles to justify whether the C-index is invariant under strictly monotone transformations of the risk scores and explain limitations of the C-index in heavily censored cohorts in systems biomedicine applications (for example, oncology or critical care). Express the final C-index as a decimal rounded to four significant figures. No units are required for the C-index.",
            "solution": "The problem requires the computation of the Concordance Index (C-index) for a given cohort of $8$ patients from a systems biomedicine study, along with a theoretical justification of the C-index's invariance properties and a discussion of its limitations.\n\n**1. Computation of the C-index**\n\nThe Concordance Index (C-index) is a measure of the discriminative ability of a survival model. It is defined as the proportion of comparable patient pairs for which the model's predicted risk scores are concordant with the actual survival outcomes.\n\nA pair of patients, $(i, j)$, is **comparable** if the patient with the earlier observed time experienced an event. Specifically, for an unordered pair $(i, j)$, comparability requires that if $T_i < T_j$, we must have $\\delta_i = 1$, or if $T_j < T_i$, we must have $\\delta_j = 1$. Pairs with tied observed times ($T_i = T_j$) are excluded. In the given dataset, all event times are unique.\n\nFor a comparable pair where patient $i$ has an event at time $T_i$ and patient $j$ has an observation time $T_j > T_i$, the pair is:\n- **Concordant** if the patient with the earlier event has a higher predicted risk score, i.e., $s_i > s_j$. This contributes $1$ to the numerator.\n- **Discordant** if $s_i < s_j$. This contributes $0$ to the numerator.\n- **Tied-Risk** if $s_i = s_j$. This contributes $0.5$ to the numerator.\n\nThe C-index is calculated using the formula:\n$$ C = \\frac{\\text{Number of Concordant Pairs} + 0.5 \\times \\text{Number of Tied-Risk Pairs}}{\\text{Total Number of Comparable Pairs}} $$\n\nThe patient data provided is:\n- P1: $(T_1, \\delta_1, s_1) = (5, 1, 0.9)$\n- P2: $(T_2, \\delta_2, s_2) = (12, 0, 0.7)$\n- P3: $(T_3, \\delta_3, s_3) = (9, 1, 1.1)$\n- P4: $(T_4, \\delta_4, s_4) = (4, 1, 0.6)$\n- P5: $(T_5, \\delta_5, s_5) = (15, 0, 0.8)$\n- P6: $(T_6, \\delta_6, s_6) = (8, 0, 0.9)$\n- P7: $(T_7, \\delta_7, s_7) = (10, 1, 1.0)$\n- P8: $(T_8, \\delta_8, s_8) = (7, 1, 0.5)$\n\nThe patients who experienced an event ($\\delta_i = 1$) are P1, P3, P4, P7, and P8. We systematically identify all comparable pairs by considering each event patient and pairing them with all other patients who have a later observation time.\n\n- **Patient 4 ($T_4=4, \\delta_4=1, s_4=0.6$):** $T_4$ is the minimum time. Thus, P4 is comparable with all other $7$ patients.\n  - vs P1($T_1=5, s_1=0.9$): $T_4<T_1$, expect $s_4>s_1$. Observed $0.6 < 0.9$ (Discordant).\n  - vs P2($T_2=12, s_2=0.7$): $T_4<T_2$, expect $s_4>s_2$. Observed $0.6 < 0.7$ (Discordant).\n  - vs P3($T_3=9, s_3=1.1$): $T_4<T_3$, expect $s_4>s_3$. Observed $0.6 < 1.1$ (Discordant).\n  - vs P5($T_5=15, s_5=0.8$): $T_4<T_5$, expect $s_4>s_5$. Observed $0.6 < 0.8$ (Discordant).\n  - vs P6($T_6=8, s_6=0.9$): $T_4<T_6$, expect $s_4>s_6$. Observed $0.6 < 0.9$ (Discordant).\n  - vs P7($T_7=10, s_7=1.0$): $T_4<T_7$, expect $s_4>s_7$. Observed $0.6 < 1.0$ (Discordant).\n  - vs P8($T_8=7, s_8=0.5$): $T_4<T_8$, expect $s_4>s_8$. Observed $0.6 > 0.5$ (Concordant).\n  - *Subtotal: $1$ Concordant, $6$ Discordant, $0$ Tied.* Total $7$ comparable pairs.\n\n- **Patient 1 ($T_1=5, \\delta_1=1, s_1=0.9$):** Comparable with all patients $j$ where $T_j > 5$. These are P2, P3, P5, P6, P7, P8.\n  - vs P2($T_2=12, s_2=0.7$): $T_1<T_2$, expect $s_1>s_2$. Observed $0.9 > 0.7$ (Concordant).\n  - vs P3($T_3=9, s_3=1.1$): $T_1<T_3$, expect $s_1>s_3$. Observed $0.9 < 1.1$ (Discordant).\n  - vs P5($T_5=15, s_5=0.8$): $T_1<T_5$, expect $s_1>s_5$. Observed $0.9 > 0.8$ (Concordant).\n  - vs P6($T_6=8, s_6=0.9$): $T_1<T_6$, expect $s_1>s_6$. Observed $0.9 = 0.9$ (Tied-Risk).\n  - vs P7($T_7=10, s_7=1.0$): $T_1<T_7$, expect $s_1>s_7$. Observed $0.9 < 1.0$ (Discordant).\n  - vs P8($T_8=7, s_8=0.5$): $T_1<T_8$, expect $s_1>s_8$. Observed $0.9 > 0.5$ (Concordant).\n  - *Subtotal: $3$ Concordant, $2$ Discordant, $1$ Tied.* Total $6$ comparable pairs.\n\n- **Patient 8 ($T_8=7, \\delta_8=1, s_8=0.5$):** Comparable with all patients $j$ where $T_j > 7$. These are P2, P3, P5, P6, P7.\n  - vs P2($T_2=12, s_2=0.7$): $T_8<T_2$, expect $s_8>s_2$. Observed $0.5 < 0.7$ (Discordant).\n  - vs P3($T_3=9, s_3=1.1$): $T_8<T_3$, expect $s_8>s_3$. Observed $0.5 < 1.1$ (Discordant).\n  - vs P5($T_5=15, s_5=0.8$): $T_8<T_5$, expect $s_8>s_5$. Observed $0.5 < 0.8$ (Discordant).\n  - vs P6($T_6=8, s_6=0.9$): $T_8<T_6$, expect $s_8>s_6$. Observed $0.5 < 0.9$ (Discordant).\n  - vs P7($T_7=10, s_7=1.0$): $T_8<T_7$, expect $s_8>s_7$. Observed $0.5 < 1.0$ (Discordant).\n  - *Subtotal: $0$ Concordant, $5$ Discordant, $0$ Tied.* Total $5$ comparable pairs.\n\n- **Patient 3 ($T_3=9, \\delta_3=1, s_3=1.1$):** Comparable with all patients $j$ where $T_j > 9$. These are P2, P5, P7.\n  - vs P2($T_2=12, s_2=0.7$): $T_3<T_2$, expect $s_3>s_2$. Observed $1.1 > 0.7$ (Concordant).\n  - vs P5($T_5=15, s_5=0.8$): $T_3<T_5$, expect $s_3>s_5$. Observed $1.1 > 0.8$ (Concordant).\n  - vs P7($T_7=10, s_7=1.0$): $T_3<T_7$, expect $s_3>s_7$. Observed $1.1 > 1.0$ (Concordant).\n  - *Subtotal: $3$ Concordant, $0$ Discordant, $0$ Tied.* Total $3$ comparable pairs.\n\n- **Patient 7 ($T_7=10, \\delta_7=1, s_7=1.0$):** Comparable with all patients $j$ where $T_j > 10$. These are P2, P5.\n  - vs P2($T_2=12, s_2=0.7$): $T_7<T_2$, expect $s_7>s_2$. Observed $1.0 > 0.7$ (Concordant).\n  - vs P5($T_5=15, s_5=0.8$): $T_7<T_5$, expect $s_7>s_5$. Observed $1.0 > 0.8$ (Concordant).\n  - *Subtotal: $2$ Concordant, $0$ Discordant, $0$ Tied.* Total $2$ comparable pairs.\n\n**Total Counts:**\n- Total Comparable Pairs = $7 + 6 + 5 + 3 + 2 = 23$.\n- Total Concordant Pairs = $1 + 3 + 0 + 3 + 2 = 9$.\n- Total Tied-Risk Pairs = $0 + 1 + 0 + 0 + 0 = 1$.\n\n**C-index Calculation:**\n$$ C = \\frac{9 + 0.5 \\times 1}{23} = \\frac{9.5}{23} \\approx 0.413043... $$\nRounding to four significant figures, the C-index is $0.4130$.\n\n**2. Invariance of the C-index**\n\nThe C-index is invariant under any strictly monotone increasing transformation of the risk scores.\nLet $S = \\{s_1, s_2, ..., s_n\\}$ be the set of original risk scores. Let $f: \\mathbb{R} \\to \\mathbb{R}$ be a strictly monotone increasing function. Let $S' = \\{s'_1, s'_2, ..., s'_n\\}$ be the transformed scores where $s'_i = f(s_i)$ for all $i$.\n\nThe calculation of the C-index depends on pairwise comparisons of risk scores, not their absolute values.\n- The set of comparable pairs is determined solely by the times $T_i$ and event indicators $\\delta_i$, so it remains unchanged by any transformation of the scores.\n- For any pair of scores $s_i, s_j$, because $f$ is strictly monotone increasing, the following holds:\n  - $s_i > s_j \\iff f(s_i) > f(s_j) \\iff s'_i > s'_j$\n  - $s_i < s_j \\iff f(s_i) < f(s_j) \\iff s'_i < s'_j$\n  - $s_i = s_j \\iff f(s_i) = f(s_j) \\iff s'_i = s'_j$\n- Consequently, a pair of patients that is concordant, discordant, or tied-risk with respect to the original scores $S$ will be classified identically with respect to the transformed scores $S'$.\n- This means the total number of concordant pairs and tied-risk pairs remains the same. Since the total number of comparable pairs also remains the same, the C-index value is invariant: $C(S) = C(S')$.\n\nIt is important to note that this invariance does not hold for strictly monotone *decreasing* transformations. A decreasing transformation would invert the rank ordering, causing concordant pairs to become discordant and vice versa, leading to a new C-index of $1 - C$.\n\n**3. Limitations of the C-index in Heavily Censored Cohorts**\n\nIn systems biomedicine applications such as oncology, cohorts are often subject to heavy right-censoring (a large fraction of patients have $\\delta_i=0$). This presents several limitations for the C-index as an evaluation metric.\n\n- **Reduction of statistical power:** The C-index is computed only on comparable pairs, where the patient with the earlier observation time must have had an event. In a heavily censored dataset, the number of events is small, which drastically reduces the total number of comparable pairs. A metric computed on a small effective sample size is subject to high variance, making it an unstable and unreliable estimate of the model's true performance.\n- **Information loss from censored observations:** The C-index completely discards information from pairs where the patient with the earlier follow-up is censored (e.g., $(T_i < T_j, \\delta_i=0)$). It also ignores pairs where both patients are censored. This is a significant loss of information, as the relative risks of these patients still contain useful data about model performance. For example, for two censored patients where one has a much longer follow-up time, a good model should ideally assign a lower risk to the longer-surviving patient.\n- **Lack of time-dependency:** The C-index provides a single, global summary of discrimination over the entire study period. It does not reveal if a model's performance is strong for short-term predictions but weak for long-term ones, or vice-versa. This is a critical deficiency in fields like oncology where predicting both early and late events is important. Metrics like time-dependent AUC can provide a more granular assessment of performance at specific time horizons.\n- **Equal weighting of all pairs:** The C-index gives equal importance to correctly ordering a pair with a small difference in survival times (e.g., $1$ month) and a pair with a large difference (e.g., $10$ years). In many clinical contexts, the clinical significance of these two correct predictions may be vastly different. The metric does not capture this nuance.\n\nDue to these limitations, while the C-index is a useful and widely-used metric, it should be supplemented with other performance measures, especially in the context of heavily censored data common in systems biomedicine.",
            "answer": "$$\\boxed{0.4130}$$"
        },
        {
            "introduction": "For deep learning models to be trusted in high-stakes clinical decision-making, their predictions must be interpretable. This exercise  delves into Integrated Gradients, a powerful feature attribution method grounded in solid theoretical principles. By deriving the method from the fundamental theorem of calculus for line integrals and applying it to a linear model, you will gain a deep understanding of how to assign responsibility for a prediction back to the input features.",
            "id": "4332698",
            "problem": "A systems biomedicine pipeline uses a differentiable scalar predictive model $F:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$ to map a vector of standardized molecular features (for example, transcript abundances or protein markers) $x\\in\\mathbb{R}^{n}$ to a disease activity score. To interpret feature contributions, consider Integrated Gradients (IG), defined for a baseline representing a healthy homeostatic state $x'\\in\\mathbb{R}^{n}$ and a straight-line path from $x'$ to $x$. Starting only from the gradient definition, the chain rule, and the fundamental theorem of line integrals for conservative vector fields (namely, that for a differentiable scalar field $F$, the integral of $\\nabla F$ along any smooth path between two points equals the difference in $F$ evaluated at the endpoints), derive an analytic expression for the attribution assigned to feature $i$ along the straight-line path from $x'$ to $x$. Then, specialize your expression to the linear model $F(x)=w^{\\top}x+b$ and compute the attribution for feature $i=2$ for the following values:\n- $w=\\left(0.92,\\,-0.68,\\,0.11,\\,0.35\\right)$,\n- $x=\\left(0.50,\\,1.25,\\,-0.30,\\,0.80\\right)$,\n- $x'=\\left(0.10,\\,0.15,\\,-0.30,\\,0.20\\right)$.\nProvide the final numerical value for the feature $i=2$ attribution as an exact number; no rounding is required. Do not include units.",
            "solution": "The problem requires the derivation of an analytic expression for the Integrated Gradients (IG) attribution for a feature $i$, starting from fundamental principles. This expression must then be specialized for a linear model and used to compute a specific numerical value.\n\nFirst, we derive the general expression for the attribution. The problem states that we should use the fundamental theorem of line integrals for conservative vector fields. For a differentiable scalar field $F:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$, its gradient $\\nabla F$ is a conservative vector field. The theorem states that the integral of $\\nabla F$ along any smooth path $\\gamma$ from a point $x'$ to a point $x$ is equal to the difference in the scalar field's value at the endpoints:\n$$F(x) - F(x') = \\int_{\\gamma} \\nabla F(\\mathbf{r}) \\cdot d\\mathbf{r}$$\nThe problem specifies a straight-line path from the baseline $x'$ to the input $x$. We can parameterize this path as $\\gamma(\\alpha) = x' + \\alpha(x - x')$ for a parameter $\\alpha \\in [0, 1]$. At $\\alpha=0$, we have $\\gamma(0) = x'$, and at $\\alpha=1$, we have $\\gamma(1) = x' + (x - x') = x$. The differential path element is $d\\mathbf{r} = \\frac{d\\gamma}{d\\alpha}d\\alpha = (x - x')d\\alpha$.\n\nSubstituting this parameterization into the line integral gives:\n$$F(x) - F(x') = \\int_{0}^{1} \\nabla F(\\gamma(\\alpha)) \\cdot \\frac{d\\gamma}{d\\alpha} d\\alpha$$\n$$F(x) - F(x') = \\int_{0}^{1} \\nabla F(x' + \\alpha(x - x')) \\cdot (x - x') d\\alpha$$\nThe gradient vector is $\\nabla F(\\mathbf{r}) = \\left(\\frac{\\partial F}{\\partial x_1}, \\frac{\\partial F}{\\partial x_2}, \\dots, \\frac{\\partial F}{\\partial x_n}\\right)$, and the vector $(x - x')$ is $(x_1 - x'_1, x_2 - x'_2, \\dots, x_n - x'_n)$. The dot product in the integrand is:\n$$\\nabla F(x' + \\alpha(x - x')) \\cdot (x - x') = \\sum_{i=1}^{n} \\frac{\\partial F}{\\partial x_i}\\bigg|_{\\mathbf{r}=x' + \\alpha(x - x')} (x_i - x'_i)$$\nwhere $\\frac{\\partial F}{\\partial x_i}\\big|_{\\mathbf{r}=\\dots}$ denotes the partial derivative evaluated at the point $\\mathbf{r}$ on the path.\n\nSubstituting this sum into the integral expression for the total change in $F$:\n$$F(x) - F(x') = \\int_{0}^{1} \\sum_{i=1}^{n} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} (x_i - x'_i) d\\alpha$$\nSince the sum is finite, we can interchange the summation and integration operators:\n$$F(x) - F(x') = \\sum_{i=1}^{n} \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} (x_i - x'_i) d\\alpha$$\nThe term $(x_i - x'_i)$ is constant with respect to the integration variable $\\alpha$, so it can be moved outside the integral:\n$$F(x) - F(x') = \\sum_{i=1}^{n} (x_i - x'_i) \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} d\\alpha$$\nThe Integrated Gradients framework defines the attribution for feature $i$, denoted as $IG_i(x, x')$, as the $i$-th term in this summation. This ensures that the sum of attributions over all features equals the total change $F(x) - F(x')$. Thus, the analytic expression for the attribution assigned to feature $i$ is:\n$$IG_i(x, x') = (x_i - x'_i) \\int_{0}^{1} \\frac{\\partial F}{\\partial x_i}\\bigg|_{x' + \\alpha(x - x')} d\\alpha$$\nThis completes the first part of the problem.\n\nNext, we specialize this expression for the linear model $F(x) = w^{\\top}x + b$, which can be written as $F(x) = \\sum_{j=1}^{n} w_j x_j + b$. We need to find the partial derivative of $F$ with respect to a feature $x_i$:\n$$\\frac{\\partial F}{\\partial x_i} = \\frac{\\partial}{\\partial x_i} \\left(\\sum_{j=1}^{n} w_j x_j + b\\right) = w_i$$\nNotably, for a linear model, the partial derivative $\\frac{\\partial F}{\\partial x_i}$ is a constant, $w_i$, and does not depend on the input vector $x$. Therefore, its value is constant along the entire integration path.\n\nSubstituting this into the general attribution formula:\n$$IG_i(x, x') = (x_i - x'_i) \\int_{0}^{1} w_i d\\alpha$$\nThe integral of the constant $w_i$ over the interval $[0, 1]$ is:\n$$\\int_{0}^{1} w_i d\\alpha = w_i [\\alpha]_{0}^{1} = w_i (1 - 0) = w_i$$\nSo, for a linear model, the attribution for feature $i$ simplifies to:\n$$IG_i(x, x') = w_i (x_i - x'_i)$$\n\nFinally, we compute the attribution for feature $i=2$ using the given numerical values:\n- Weight vector: $w=\\left(0.92,\\,-0.68,\\,0.11,\\,0.35\\right)$, so the weight for feature $2$ is $w_2 = -0.68$.\n- Input feature vector: $x=\\left(0.50,\\,1.25,\\,-0.30,\\,0.80\\right)$, so the value for feature $2$ is $x_2 = 1.25$.\n- Baseline feature vector: $x'=\\left(0.10,\\,0.15,\\,-0.30,\\,0.20\\right)$, so the baseline value for feature $2$ is $x'_2 = 0.15$.\n\nUsing the specialized formula for the linear model:\n$$IG_2(x, x') = w_2 (x_2 - x'_2)$$\nSubstituting the values:\n$$IG_2(x, x') = (-0.68) \\times (1.25 - 0.15)$$\n$$IG_2(x, x') = (-0.68) \\times (1.10)$$\n$$IG_2(x, x') = -0.748$$\nThe attribution for feature $i=2$ is $-0.748$.",
            "answer": "$$\\boxed{-0.748}$$"
        }
    ]
}