{
    "hands_on_practices": [
        {
            "introduction": "虽然联邦学习的主要优势在于将数据保留在本地，但它也引入了通信开销这一主要的实践挑战。本练习将让你通过计算传输模型更新所需的时间来量化这一通信成本 。通过比较不同的数据编码方案，你将对系统设计选择如何直接影响联邦训练的可行性和效率获得一个具体的理解。",
            "id": "4840332",
            "problem": "一个由多家医院组成的联盟正在使用联邦平均（Federated Averaging, FedAvg）训练一个共享的诊断模型。联邦平均是联邦学习中的一种标准算法，通过将数据保留在本地来保护患者隐私。在每一轮通信中，每家医院都将其本地模型更新传输给协调者，然后接收聚合后的全局模型。假设模型有 $d=10^{7}$ 个可训练参数，并且一次传输的更新大小等于参数向量的大小。考虑两种参数编码方案：每参数使用32位的单精度浮点数和每参数使用8位的均匀量化。每家医院可用的网络链接速率为每秒100兆比特（megabits），其中1兆比特等于$10^{6}$比特。\n\n从数据大小和吞吐量的核心定义（数据大小以比特计，吞吐量以比特/秒计，时间等于数据大小除以速率）出发，推导在两种编码方案下，每家医院每轮的总通信时间（上传加下载）。假设没有压缩，没有协议开销，并且协调者返回的模型大小与医院发送的更新大小相同。\n\n判断在每轮2秒的墙上时钟预算下，每种方案是否可行。可行性定义为每轮总通信时间小于或等于$2\\,\\mathrm{s}$。\n\n将最终的数值时间四舍五入到四位有效数字，并以秒为单位表示。将您的最终答案以行矩阵的形式给出，第一个条目等于32位方案的时间，第二个条目等于8位方案的时间。",
            "solution": "首先根据要求标准对问题进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   模型参数数量：$d = 10^7$\n-   编码方案1（单精度）：每参数 $b_{32} = 32$ 比特\n-   编码方案2（量化）：每参数 $b_8 = 8$ 比特\n-   网络链接速率（吞吐量）：$R = 100$ 兆比特/秒，其中 1 兆比特 $= 10^6$ 比特。\n-   通信轮结构：每家医院执行一次上传和一次下载。\n-   下载模型的大小：与上传的模型更新大小相同。\n-   假设：无压缩，无协议开销。\n-   可行性预算：每轮总通信时间 $\\le T_{budget} = 2\\,\\mathrm{s}$。\n-   计算基础：时间 = 数据大小 / 吞吐量。\n-   舍入要求：最终时间需四舍五入至四位有效数字。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在科学上基于计算机网络和联邦学习的原理。该场景是联邦学习在医学信息学中的一个标准应用。所提供的参数（$10^7$个参数、100 Mbps链路、32位和8位编码）在现代机器学习和网络基础设施中是现实的。问题定义明确，提供了计算唯一解所需的所有信息和清晰、客观的定义（例如，1兆比特 $= 10^6$ 比特）。它没有科学缺陷、歧义或矛盾。\n\n**步骤3：结论与行动**\n该问题被认为是有效的。将提供解答。\n\n### 解题推导\n\n分析过程首先为每种编码方案定义单次通信轮中要传输的总数据大小。然后，利用给定的网络吞吐量计算此传输所需的时间。最后，将此时间与指定的可行性预算进行比较。\n\n设 $d$ 为模型中可训练参数的数量。\n设 $b$ 为用于编码每个参数的比特数。\n模型更新的大小 $S$（以比特为单位）由参数数量和每参数比特数的乘积给出：\n$$S = d \\times b$$\n\n网络链接速率 $R$ 为每秒100兆比特。根据所提供的定义，即：\n$$R = 100 \\times 10^6 \\frac{\\mathrm{bits}}{\\mathrm{second}} = 10^8 \\frac{\\mathrm{bits}}{\\mathrm{second}}$$\n\n对于一家医院，单次通信轮包括一次向协调者上传模型更新和一次从协调者下载聚合的全局模型。问题说明下载的模型与上传的更新大小相同。因此，每家医院每轮传输的总数据量 $S_{total}$ 是单个更新大小的两倍：\n$$S_{total} = S_{upload} + S_{download} = S + S = 2S$$\n\n一轮的总时间 $T_{round}$ 是总数据大小除以网络链接速率：\n$$T_{round} = \\frac{S_{total}}{R} = \\frac{2S}{R} = \\frac{2db}{R}$$\n\n我们现在为两种编码方案计算这个时间。\n\n**方案1：单精度浮点数（32位）**\n\n在这种情况下，每参数的比特数是 $b_{32} = 32$。\n参数数量为 $d = 10^7$。\n单个模型更新的大小为：\n$$S_{32} = d \\times b_{32} = 10^7 \\times 32 = 3.2 \\times 10^8 \\text{ bits}$$\n\n每轮总通信时间 $T_{round, 32}$ 为：\n$$T_{round, 32} = \\frac{2 S_{32}}{R} = \\frac{2 \\times (3.2 \\times 10^8 \\text{ bits})}{10^8 \\text{ bits/s}} = 2 \\times 3.2\\,\\mathrm{s} = 6.4\\,\\mathrm{s}$$\n\n问题要求四舍五入到四位有效数字。因此，$T_{round, 32} = 6.400\\,\\mathrm{s}$。\n\n**方案1的可行性检查：**\n可行性预算为 $T_{budget} = 2\\,\\mathrm{s}$。\n我们比较计算出的时间：$6.400\\,\\mathrm{s} > 2\\,\\mathrm{s}$。\n因此，在给定的约束条件下，32位编码方案是**不可行**的。\n\n**方案2：均匀量化（8位）**\n\n在这种情况下，每参数的比特数是 $b_8 = 8$。\n参数数量为 $d = 10^7$。\n单个模型更新的大小为：\n$$S_8 = d \\times b_8 = 10^7 \\times 8 = 8 \\times 10^7 \\text{ bits}$$\n\n每轮总通信时间 $T_{round, 8}$ 为：\n$$T_{round, 8} = \\frac{2 S_8}{R} = \\frac{2 \\times (8 \\times 10^7 \\text{ bits})}{10^8 \\text{ bits/s}} = 2 \\times 0.8\\,\\mathrm{s} = 1.6\\,\\mathrm{s}$$\n\n问题要求四舍五入到四位有效数字。因此，$T_{round, 8} = 1.600\\,\\mathrm{s}$。\n\n**方案2的可行性检查：**\n可行性预算为 $T_{budget} = 2\\,\\mathrm{s}$。\n我们比较计算出的时间：$1.600\\,\\mathrm{s} \\le 2\\,\\mathrm{s}$。\n因此，在给定的约束条件下，8位编码方案是**可行**的。\n\n最终答案要求将两个计算出的时间（以秒为单位，并四舍五入到四位有效数字）以行矩阵的形式呈现。\n32位方案的时间是 $6.400\\,\\mathrm{s}$。\n8位方案的时间是 $1.600\\,\\mathrm{s}$。\n行矩阵为 $\\begin{pmatrix} 6.400  1.600 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n6.400  1.600\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "将数据保留在本地是保护隐私的必要第一步，但这足够吗？本练习揭示了一个称为“梯度反演攻击”的关键漏洞，在这种攻击中，恶意服务器仅通过观察训练过程中共享的模型梯度就能重建敏感的私人数据 。通过为一个简单模型推导其重建公式，你将发现信息泄漏的微妙方式，并体会到采用更强大的隐私增强技术的必要性。",
            "id": "4341228",
            "problem": "一个医院联合体在联邦学习 (FL) 框架下合作，为系统生物医学中的一个连续生物标志物构建一个线性预测器。在每一轮中，一个客户端使用单个随机抽样的患者记录计算正则化平方损失的梯度，并将此梯度发送给协调者。一个敌对的协调者通过旁路信息知道了当前的模型参数和患者的标签。考虑一个具有特征 $x \\in \\mathbb{R}^{d}$、非负标签 $y \\in \\mathbb{R}_{\\ge 0}$ 和模型参数 $w \\in \\mathbb{R}^{d}$ 的单个样本，其中由于领域约束（例如，非负的表达特征和可解释性约束所施加的非负权重），$x$ 和 $w$ 的所有条目都是非负的。客户端使用正则化平方损失\n$$\n\\mathcal{L}(w;x,y) = \\frac{1}{2}\\left(w^{\\top} x - y\\right)^{2} + \\frac{\\lambda}{2}\\|w\\|^{2},\n$$\n其中正则化系数 $\\lambda \\ge 0$，并将梯度 $\\nabla_{w}\\mathcal{L}$ 传输到服务器。假设对手观察到 $g = \\nabla_{w}\\mathcal{L}(w;x,y)$，并且也知道 $w$、$y$ 和 $\\lambda$。您可以进一步假设 $w^{\\top}\\left(g - \\lambda w\\right) > 0$，这是在上述非负性假设下保证唯一性的一个充分条件。\n\n仅使用基本定义，推导出一个闭式解析表达式 $x^{\\star}(g,w,y,\\lambda)$，该表达式能从观察到的梯度 $g$、已知的标签 $y$、参数 $w$ 和正则化系数 $\\lambda$ 中精确地重构输入特征 $x$。作为一种保护隐私的缓解措施，请提出一个在客户端应用的线性披露映射，用以改变通信的数据，使得无法再从单轮通信中精确重构 $x$，同时保留其用于聚合的效用。您的推导必须从给定损失的梯度定义和标准线性代数恒等式开始，并且不得提前假设或陈述目标重构公式。\n\n请将您最终重构的 $x^{\\star}$ 表示为一个单一的闭式解析表达式。不需要进行数值评估，也不需要四舍五入。如果您在缓解措施中提出了任何角度或物理单位，请分别指明是弧度或适当的单位；否则，保持缓解措施为符号形式。",
            "solution": "该问题被评估为有效。它在机器学习和隐私领域具有科学依据，问题提法良好，信息充分，并有确保唯一性的特定条件，同时使用标准数学符号进行了客观表述。\n\n解决方案分为两部分。首先，我们推导特征向量 $x$ 的闭式表达式。其次，我们提出一个线性披露映射来缓解这种隐私泄露。\n\n**第1部分：$x^{\\star}$ 重构公式的推导**\n\n客户端计算正则化平方损失函数的梯度：\n$$\n\\mathcal{L}(w;x,y) = \\frac{1}{2}\\left(w^{\\top} x - y\\right)^{2} + \\frac{\\lambda}{2}\\|w\\|^{2}\n$$\n其中 $\\|w\\|^2 = w^\\top w$。关于模型参数 $w$ 的梯度 $g$ 由下式给出：\n$$\ng = \\nabla_{w}\\mathcal{L} = \\frac{\\partial}{\\partial w} \\left( \\frac{1}{2}\\left(w^{\\top} x - y\\right)^{2} + \\frac{\\lambda}{2}w^{\\top}w \\right)\n$$\n对第一项使用链式法则，对第二项使用二次型的标准梯度，我们得到：\n$$\n\\nabla_{w} \\left( \\frac{1}{2}\\left(w^{\\top} x - y\\right)^{2} \\right) = \\frac{1}{2} \\cdot 2 \\left(w^{\\top} x - y\\right) \\cdot \\nabla_{w}(w^{\\top}x - y) = \\left(w^{\\top} x - y\\right)x\n$$\n$$\n\\nabla_{w} \\left( \\frac{\\lambda}{2}w^{\\top}w \\right) = \\lambda w\n$$\n结合这些项，得到观察到的梯度 $g$ 的表达式：\n$$\ng = (w^{\\top}x - y)x + \\lambda w\n$$\n对手的目标是在已知 $g$、$w$、$y$ 和 $\\lambda$ 的情况下，解出这个方程中的未知特征向量 $x$。我们可以重新整理方程，以分离出包含 $x$ 的项：\n$$\ng - \\lambda w = (w^{\\top}x - y)x\n$$\n这个方程表明，左侧的已知向量 $g - \\lambda w$ 是未知向量 $x$ 的一个标量倍。这意味着 $x$ 必须与 $g - \\lambda w$ 平行。然而，由于 $x$ 出现在标量项 $w^{\\top}x - y$ 内部，直接求解 $x$ 会很复杂。\n\n为继续求解，我们可以先求出标量 $S = w^{\\top}x$ 的值。我们将整理后方程的两边与 $w$ 作内积：\n$$\nw^{\\top}(g - \\lambda w) = w^{\\top}((w^{\\top}x - y)x)\n$$\n利用内积的线性性，我们得到：\n$$\nw^{\\top}(g - \\lambda w) = (w^{\\top}x - y)(w^{\\top}x)\n$$\n让我们代入 $S = w^{\\top}x$ 并定义已知常数 $C = w^{\\top}(g - \\lambda w)$。该方程成为一个关于 $S$ 的二次方程：\n$$\nC = (S - y)S\n$$\n$$\nS^2 - yS - C = 0\n$$\n使用二次公式求解 $S$：\n$$\nS = \\frac{-(-y) \\pm \\sqrt{(-y)^2 - 4(1)(-C)}}{2(1)} = \\frac{y \\pm \\sqrt{y^2 + 4C}}{2}\n$$\n将 $C = w^{\\top}(g - \\lambda w)$ 代回：\n$$\nS = w^{\\top}x = \\frac{y \\pm \\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)}}{2}\n$$\n问题指明特征 $x \\in \\mathbb{R}^d$ 和权重 $w \\in \\mathbb{R}^d$ 的所有条目都是非负的。因此，它们的内积 $w^{\\top}x = \\sum_{i=1}^d w_i x_i$ 必须是非负的，即 $w^{\\top}x \\ge 0$。\n问题还提供了条件 $C = w^{\\top}(g - \\lambda w) > 0$。由于 $y \\ge 0$，我们有 $y^2 \\ge 0$。因此，平方根下的项 $y^2 + 4C$ 是严格为正的。令 $D = \\sqrt{y^2 + 4C}$。由于 $C>0$，我们有 $D > \\sqrt{y^2} = |y| = y$。\n\n$S$ 的两个可能解是 $S_1 = \\frac{y+D}{2}$ 和 $S_2 = \\frac{y-D}{2}$。\n由于 $D > y$，第二个解 $S_2$ 是负的。在约束 $S = w^{\\top}x \\ge 0$ 下，这个解是无效的。\n第一个解 $S_1$ 是正的，因为 $y \\ge 0$ 且 $D > 0$。因此，我们得到 $S$ 的唯一解：\n$$\nw^{\\top}x = \\frac{y + \\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)}}{2}\n$$\n既然我们已经确定了 $w^{\\top}x$ 的值，我们就可以求出标量乘数 $(w^{\\top}x - y)$ 的值。\n$$\nw^{\\top}x - y = \\left( \\frac{y + \\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)}}{2} \\right) - y = \\frac{-y + \\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)}}{2}\n$$\n由于 $\\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)} > y$，这个标量项是严格为正的。这意味着我们可以用它来作除数。回到方程 $g - \\lambda w = (w^{\\top}x - y)x$，我们现在可以解出 $x$：\n$$\nx^{\\star} = \\frac{g - \\lambda w}{w^{\\top}x - y}\n$$\n代入分母的表达式，我们得到闭式重构公式：\n$$\nx^{\\star} = \\frac{g - \\lambda w}{\\frac{-y + \\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)}}{2}} = \\frac{2(g - \\lambda w)}{\\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)} - y}\n$$\n这就是从对手可获得的信息中对特征向量 $x$ 的精确重构。\n\n**第2部分：保护隐私的缓解措施**\n\n推导出的重构公式揭示了一个严重的隐私泄露。为了缓解这个问题，我们提出了一个线性披露映射，通过改变被通信的梯度 $g$ 来使精确重构变得不可能，同时保留其用于联邦聚合过程的效用。\n\n提出的缓解措施是**梯度投影**。客户端不传输原始梯度 $g$，而是传输一个投影后的版本 $g'$。\n\n**机制：** 客户端像之前一样计算梯度 $g=\\nabla_w \\mathcal{L}$。然后，它计算 $g$ 在与当前权重向量 $w$ 正交的子空间上的投影。这是一个由投影矩阵 $P_w = I - \\frac{w w^{\\top}}{\\|w\\|^2}$ 定义的线性映射。客户端将改变后的量 $g'$ 发送给服务器：\n$$\ng' = P_w g = \\left(I - \\frac{w w^{\\top}}{\\|w\\|^2}\\right) g\n$$\n\n**防止重构：** 观察到 $g'$ 的对手会尝试同样的重构攻击。他们知道 $g'$、$w$、$y$ 和 $\\lambda$。该攻击从根本上依赖于 $g - \\lambda w$ 与 $x$ 成正比这一事实。当对手接收到 $g'$ 时，他们不能再做出这个假设。如果他们试图为 $x$ 建立一个方程，他们将从投影对原始梯度方程的影响开始：\n$$\ng' = P_w g = P_w \\left( (w^{\\top}x - y)x + \\lambda w \\right)\n$$\n由于 $P_w w = 0$，正则化项在投影下消失：\n$$\ng' = (w^{\\top}x - y) P_w x\n$$\n对手观察到 $g'$ 并希望解出 $x$。向量 $x$ 可以被分解为两个正交分量：$x = x_{||w} + x_{\\perp w}$，其中 $x_{||w}$ 与 $w$ 平行，而 $x_{\\perp w}$ 与 $w$ 正交。投影 $P_w x$ 正是 $x_{\\perp w}$。方程变为：\n$$\ng' = (w^{\\top}x - y) x_{\\perp w}\n$$\n这个方程只包含关于 $x$ 中与 $w$ 正交的分量的信息。$x$ 中与 $w$ 平行的分量 $x_{||w} = \\frac{w^\\top x}{\\|w\\|^2}w$ 已从方程中被完全消除。对手可以确定 $x_{\\perp w}$（最多存在一个类似于原始攻击中的标量模糊度），但从 $g'$ 中得不到关于 $x_{||w}$ 的任何信息。由于对于任意标量 $\\alpha$，任何形式为 $x' = x_{\\perp w} + \\alpha w$ 的向量都具有相同的投影 $P_w x' = x_{\\perp w}$，因此重构问题变得欠定。所以，精确重构 $x$ 是不可能的。\n\n**聚合的效用：** 服务器的目标是聚合梯度，例如 $\\frac{1}{N} \\sum_i g_i$，以执行模型更新。采用此缓解措施后，服务器聚合投影后的梯度：\n$$\n\\frac{1}{N} \\sum_i g'_i = \\frac{1}{N} \\sum_i P_w g_i = P_w \\left( \\frac{1}{N} \\sum_i g_i \\right)\n$$\n服务器获得真实平均梯度的投影。形式为 $w_{t+1} \\leftarrow w_t - \\eta \\left( \\sum_i g'_i \\right)$ 的模型更新现在是在一个与 $w_t$ 正交的方向上进行更新。这对应于一个投影梯度下降算法，它将优化轨迹约束在半径为 $\\|w_t\\|$ 的超球面上。虽然这改变了标准梯度下降的优化动态，但它是一个定义明确的优化过程，在这个新约束下仍然旨在最小化损失函数，因此保留了一种明确的效用形式。",
            "answer": "$$\n\\boxed{\\frac{2(g - \\lambda w)}{\\sqrt{y^2 + 4w^{\\top}(g - \\lambda w)} - y}}\n$$"
        },
        {
            "introduction": "为了应对梯度泄漏等威胁，差分隐私 (Differential Privacy, DP) 提供了一个严格的数学框架来保障隐私。本练习提供了将 DP 应用于联邦平均算法的核心机制的实践经验 。你将学习如何计算模型聚合过程的敏感度，并用它来校准高斯和拉普拉斯机制为实现正式的隐私保障所需的精确噪声量。",
            "id": "4341061",
            "problem": "在系统生物医学中，一个联邦平均 (FedAvg) 服务器通过计算 $m$ 个客户端梯度的平均值来聚合每轮的客户端梯度，其中每个梯度都在欧几里得范数上被裁剪到一个界限 $C>0$，然后为保护隐私添加噪声。考虑一个单轮过程，在该轮中，服务器发布一个固定的 $m$ 个客户端集合的带噪声的平均值。设梯度维度为 $d$，并根据替换邻接关系定义相邻数据集：如果两个客户端集合的差异在于用另一个被裁剪的梯度向量替换了其中一个被裁剪的梯度向量，则称它们为相邻的。该随机化机制必须满足差分隐私 (DP)，其定义如下：对于所有相邻数据集 $D$ 和 $D'$ 以及所有可测集 $S$，如果一个机制 $\\mathcal{M}$ 满足 $\\Pr[\\mathcal{M}(D)\\in S]\\leq \\exp(\\epsilon)\\Pr[\\mathcal{M}(D')\\in S]+\\delta$，则该机制是 $(\\epsilon,\\delta)$-DP 的。对于拉普拉斯机制，考虑纯 $\\epsilon$-DP 的情况，其中 $\\delta=0$。\n\n从 DP 的形式化定义和向量值查询的全局敏感度定义出发，根据第一性原理推导在替换邻接关系下，为使平均化的裁剪梯度私有化所需的噪声分布的校准方法：\n1. 对于高斯机制，推导为 $m$ 个欧几里得范数界限为 $C$ 的裁剪梯度的平均值实现 $(\\epsilon,\\delta)$-DP 所需的每个坐标的噪声标准差 $s_{G}$。\n2. 对于拉普拉斯机制，当噪声独立地添加到每个坐标时，推导为相同的平均值实现 $\\epsilon$-DP 所需的每个坐标的拉普拉斯尺度 $b_{L}$。\n\n假设在系统生物医学模型训练中的单次发布使用以下科学上真实的参数：\n- 梯度维度 $d=100$，\n- 参与的客户端数量 $m=50$，\n- 裁剪界限 $C=0.5$ (欧几里得范数)，\n- 高斯机制的目标 $\\epsilon=0.8$ 和 $\\delta=1.0\\times 10^{-6}$，\n- 拉普拉斯机制的目标 $\\epsilon=0.8$。\n\n在这些参数下，计算 $s_{G}$ 和 $b_{L}$ 的数值。将您的答案四舍五入到四位有效数字。按 $\\big(s_{G},\\, b_{L}\\big)$ 的顺序将这两个值作为一个单行向量提供。不需要单位。",
            "solution": "该问题要求推导和计算高斯机制和拉普拉斯机制的噪声参数，以确保裁剪梯度的联邦平均满足差分隐私 (DP)。我们首先形式化查询，并计算其在指定邻接定义下的全局敏感度。\n\n设 $m$ 个客户端梯度的集合为 $D = \\{g_1, g_2, \\ldots, g_m\\}$，其中每个梯度 $g_i \\in \\mathbb{R}^d$ 是 $d$ 维空间中的一个向量。每个梯度都经过裁剪，使其欧几里得范数（或 $L_2$ 范数）被一个常数 $C > 0$ 所限制，即对所有 $i \\in \\{1, \\ldots, m\\}$ 都有 $\\|g_i\\|_2 \\leq C$。\n\n查询函数 $f$ 计算这些梯度的平均值：\n$$\nf(D) = \\frac{1}{m} \\sum_{i=1}^{m} g_i\n$$\n问题指定了替换邻接关系：如果数据集 $D'$ 可以通过将数据集 $D$ 中的单个客户端梯度向量（例如 $g_i$）替换为另一个有效的梯度向量 $g'_i$ 来获得，则认为 $D$ 和 $D'$ 是相邻的。$g_i$ 和 $g'_i$ 都必须满足裁剪约束，即 $\\|g_i\\|_2 \\leq C$ 且 $\\|g'_i\\|_2 \\leq C$。\n\n为了校准 DP 机制的噪声，我们必须首先计算查询函数 $f$ 的全局敏感度。全局敏感度定义为在所有可能的相邻数据集上，$f$ 的输出在特定范数下的最大变化量。\n\n**1. 高斯机制与 $L_2$ 敏感度**\n\n高斯机制添加的噪声是根据查询函数的 $L_2$ 敏感度来校准的，其定义为 $\\Delta_2(f) = \\max_{D, D'} \\|f(D) - f(D')\\|_2$，其中最大值取自所有相邻数据集 $D$ 和 $D'$。\n\n设 $D = \\{g_1, \\ldots, g_i, \\ldots, g_m\\}$ 及其相邻数据集 $D' = \\{g_1, \\ldots, g'_i, \\ldots, g_m\\}$。查询输出的差异是：\n$$\nf(D) - f(D') = \\left(\\frac{1}{m} \\sum_{j=1}^{m} g_j\\right) - \\left(\\frac{1}{m} \\left( \\sum_{j \\neq i} g_j + g'_i \\right)\\right) = \\frac{1}{m}(g_i - g'_i)\n$$\n我们需要找到这个差值的最大 $L_2$ 范数：\n$$\n\\|f(D) - f(D')\\|_2 = \\left\\|\\frac{1}{m}(g_i - g'_i)\\right\\|_2 = \\frac{1}{m}\\|g_i - g'_i\\|_2\n$$\n为了找到全局敏感度，我们必须在所有有效的 $g_i$ 和 $g'_i$ 选择上最大化这个量。根据三角不等式：\n$$\n\\|g_i - g'_i\\|_2 \\leq \\|g_i\\|_2 + \\|-g'_i\\|_2 = \\|g_i\\|_2 + \\|g'_i\\|_2\n$$\n由于 $\\|g_i\\|_2 \\leq C$ 且 $\\|g'_i\\|_2 \\leq C$，可能的最大值为 $C + C = 2C$。例如，当选择 $g'_i = -g_i$ 且 $\\|g_i\\|_2 = C$ 时，可以达到这个最大值。这两个向量都满足裁剪约束。\n\n因此，平均查询的 $L_2$ 全局敏感度是：\n$$\n\\Delta_2(f) = \\frac{2C}{m}\n$$\n高斯机制向查询结果 $f(D)$ 添加各向同性噪声 $Z \\sim \\mathcal{N}(0, s_G^2 I_d)$，其中 $I_d$ 是 $d \\times d$ 单位矩阵，$s_G$ 是每个坐标的标准差。对于给定的 $(\\epsilon, \\delta)$-DP 保证，其中 $\\epsilon \\in (0,1)$，标准差 $s_G$ 的一个充分条件是：\n$$\ns_G \\geq \\frac{\\Delta_2(f) \\sqrt{2 \\ln(1.25/\\delta)}}{\\epsilon}\n$$\n为了最小化添加的噪声，我们选择等式：\n$$\ns_G = \\frac{2C}{m\\epsilon} \\sqrt{2 \\ln\\left(\\frac{1.25}{\\delta}\\right)}\n$$\n\n**2. 拉普拉斯机制与 $L_1$ 敏感度**\n\n拉普拉斯机制通过向每个坐标添加独立噪声来应用于向量值查询，其校准使用的是查询函数的 $L_1$ 全局敏感度，定义为 $\\Delta_1(f) = \\max_{D, D'} \\|f(D) - f(D')\\|_1$。\n添加的噪声向量 $Y=(Y_1, \\ldots, Y_d)$ 的密度，其分量 $Y_j \\sim \\text{Laplace}(b_L)$ 是独立同分布的，与 $\\exp(-\\|y\\|_1/b_L)$ 成正比。为了实现 $\\epsilon$-DP，尺度参数 $b_L$ 必须满足 $b_L \\ge \\Delta_1(f) / \\epsilon$。\n\n我们接着计算 $\\Delta_1(f)$：\n$$\n\\|f(D) - f(D')\\|_1 = \\left\\|\\frac{1}{m}(g_i - g'_i)\\right\\|_1 = \\frac{1}{m}\\|g_i - g'_i\\|_1\n$$\n我们必须在 $\\|g_i\\|_2 \\leq C$ 和 $\\|g'_i\\|_2 \\leq C$ 的约束下最大化 $\\|g_i - g'_i\\|_1$。设 $v = g_i - g'_i$。根据三角不等式，$\\|v\\|_2 = \\|g_i - g'_i\\|_2 \\leq \\|g_i\\|_2 + \\|g'_i\\|_2 \\leq 2C$。我们寻求在约束 $\\|v\\|_2 \\leq 2C$ 下最大化 $\\|v\\|_1$。\n\n使用柯西-施瓦茨不等式，对于任何向量 $v \\in \\mathbb{R}^d$：\n$$\n\\|v\\|_1 = \\sum_{j=1}^{d} |v_j| = \\sum_{j=1}^{d} 1 \\cdot |v_j| \\leq \\left(\\sum_{j=1}^{d} 1^2\\right)^{1/2} \\left(\\sum_{j=1}^{d} v_j^2\\right)^{1/2} = \\sqrt{d} \\|v\\|_2\n$$\n因此，$\\|v\\|_1 \\leq \\sqrt{d}(2C)$。这个上界是紧的。当 $|v_1| = |v_2| = \\ldots = |v_d|$ 时可以达到，例如，如果对于所有 $j$ 都有 $v_j = \\frac{2C}{\\sqrt{d}}$。对于这样一个向量 $v$，$\\|v\\|_2 = \\sqrt{\\sum_{j=1}^d (\\frac{2C}{\\sqrt{d}})^2} = \\sqrt{d \\cdot \\frac{4C^2}{d}} = 2C$。我们可以构造 $g_i = v/2$ 和 $g'_i = -v/2$。那么 $\\|g_i\\|_2 = \\|v/2\\|_2 = C$ 且 $\\|g'_i\\|_2 = \\|-v/2\\|_2 = C$，并且 $g_i - g'_i = v$。因此，$\\max \\|g_i - g'_i\\|_1 = 2C\\sqrt{d}$。\n\n平均查询的 $L_1$ 全局敏感度是：\n$$\n\\Delta_1(f) = \\frac{2C\\sqrt{d}}{m}\n$$\n实现 $\\epsilon$-DP 所需的每个坐标的拉普拉斯尺度 $b_L$ 由以下公式给出：\n$$\nb_L = \\frac{\\Delta_1(f)}{\\epsilon} = \\frac{2C\\sqrt{d}}{m\\epsilon}\n$$\n\n**数值计算**\n\n我们有以下给定参数：\n- 梯度维度: $d = 100$\n- 客户端数量: $m = 50$\n- 裁剪界限: $C = 0.5$\n- 高斯 DP 参数: $\\epsilon = 0.8$, $\\delta = 1.0 \\times 10^{-6}$\n- 拉普拉斯 DP 参数: $\\epsilon = 0.8$\n\n**对于高斯机制的标准差 $s_G$：**\n$$\ns_G = \\frac{2(0.5)}{50(0.8)} \\sqrt{2 \\ln\\left(\\frac{1.25}{1.0 \\times 10^{-6}}\\right)} = \\frac{1}{40} \\sqrt{2 \\ln(1.25 \\times 10^6)}\n$$\n$$\ns_G = 0.025 \\sqrt{2(14.038681)} = 0.025 \\sqrt{28.077362} \\approx 0.025 \\times 5.2988076 \\approx 0.13247019\n$$\n四舍五入到四位有效数字，$s_G \\approx 0.1325$。\n\n**对于拉普拉斯机制的尺度 $b_L$：**\n$$\nb_L = \\frac{2(0.5)\\sqrt{100}}{50(0.8)} = \\frac{1 \\times 10}{40} = \\frac{10}{40} = 0.25\n$$\n这个值是精确的。保留四位有效数字，$b_L = 0.2500$。\n\n计算出的值为 $(s_G, b_L) = (0.1325, 0.2500)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.1325  0.2500 \\end{pmatrix}}\n$$"
        }
    ]
}