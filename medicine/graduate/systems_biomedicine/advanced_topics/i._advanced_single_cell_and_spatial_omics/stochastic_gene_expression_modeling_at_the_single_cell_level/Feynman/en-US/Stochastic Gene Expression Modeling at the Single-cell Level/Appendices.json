{
    "hands_on_practices": [
        {
            "introduction": "The Chemical Master Equation (CME) provides a complete stochastic description of gene expression, but its infinite state space presents a major analytical and computational challenge. This exercise introduces the Finite State Projection (FSP) algorithm, a cornerstone method for obtaining a guaranteed-accuracy numerical solution to the CME . By implementing the FSP for the classic telegraph model, you will gain hands-on experience in truncating state space, constructing a generator matrix, and rigorously bounding the approximation error.",
            "id": "4388466",
            "problem": "Consider the telegraph model of gene expression at the single-cell level, where a promoter switches stochastically between an inactive state and an active state and messenger ribonucleic acid (mRNA) is synthesized and degraded in time. The system is modeled as a Continuous-Time Markov Chain (CTMC) governed by the Chemical Master Equation (CME). Let the promoter state be denoted by $g \\in \\{0,1\\}$, where $g=0$ represents the inactive state and $g=1$ represents the active state. Let the mRNA copy number be denoted by $m \\in \\mathbb{N}_0$. Promoter switching occurs with rates $k_{\\mathrm{on}}$ from $g=0$ to $g=1$ and $k_{\\mathrm{off}}$ from $g=1$ to $g=0$. Transcription occurs with rate $s_0$ when $g=0$ and with rate $s_1$ when $g=1$. Degradation occurs with rate $\\gamma$ per mRNA molecule, that is, transition from $m$ to $m-1$ occurs at rate $\\gamma m$. The fundamental basis is the definition of the Chemical Master Equation and conservation of probability for CTMCs.\n\nYou must:\n- Formulate the Finite State Projection (FSP) truncation for the telegraph CME using a projection set $S_M = \\{(g,m) \\mid g \\in \\{0,1\\}, m \\in \\{0,1,\\dots,M\\}\\}$, where $M \\in \\mathbb{N}_0$ is the projection size limit on the mRNA count. Augment the CTMC with a single absorbing sink state $\\varnothing$ that collects all probability flux leaving $S_M$ due to any transition that would increase $m$ beyond $M$.\n- Derive an upper bound on the truncation error at time $t$, defined as the probability mass that lies outside $S_M$ in the true CME solution, and express this bound explicitly as a function of the projection size $M$. Your derivation must start from the CME and conservation of probability, without using pre-derived shortcut formulas.\n- Implement a numerical solver for the truncated system by constructing the generator matrix for the FSP-augmented CTMC over $S_M \\cup \\{\\varnothing\\}$ and integrating the forward ordinary differential equation $\\mathrm{d} \\mathbf{p}(t) / \\mathrm{d} t = A_M \\mathbf{p}(t)$ for a specified time horizon $T$. Use an initial condition $\\mathbf{p}(0)$ concentrated at $(g,m)=(0,0)$ with probability $1$ and $0$ elsewhere.\n\nDefine the generator $A_M$ with the convention that for source state $i$ to destination state $j$, the entry $A_M[j,i]$ equals the transition rate from $i$ to $j$, ensuring that probability conservation implies each column of $A_M$ sums to $0$. For the sink state $\\varnothing$, define no outgoing transitions, i.e., the sink is absorbing. The truncation error upper bound must be the sink probability $p_{\\varnothing}(t)$ produced by the FSP-augmented system, and you must justify this bound using first principles.\n\nYour program must compute, for each test case, the upper bound value $p_{\\varnothing}(T)$ at the final time $T$. No physical units are required for the rates or time; treat them as dimensionless numbers for computation. Angles are not involved.\n\nTest suite:\n- Case $1$ (general case): $k_{\\mathrm{on}}=1.0$, $k_{\\mathrm{off}}=1.5$, $s_0=0.0$, $s_1=5.0$, $\\gamma=1.0$, $M=50$, $T=5.0$.\n- Case $2$ (boundary-truncation stress): $k_{\\mathrm{on}}=2.0$, $k_{\\mathrm{off}}=0.5$, $s_0=0.0$, $s_1=20.0$, $\\gamma=1.0$, $M=5$, $T=5.0$.\n- Case $3$ (no-switching edge): $k_{\\mathrm{on}}=0.0$, $k_{\\mathrm{off}}=0.0$, $s_0=0.0$, $s_1=5.0$, $\\gamma=1.0$, $M=10$, $T=10.0$.\n- Case $4$ (basal transcription with slow degradation): $k_{\\mathrm{on}}=0.2$, $k_{\\mathrm{off}}=2.0$, $s_0=1.0$, $s_1=8.0$, $\\gamma=0.5$, $M=20$, $T=10.0$.\n- Case $5$ (fast degradation): $k_{\\mathrm{on}}=3.0$, $k_{\\mathrm{off}}=3.0$, $s_0=0.0$, $s_1=5.0$, $\\gamma=5.0$, $M=30$, $T=5.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, namely $[p_{\\varnothing}^{(1)},p_{\\varnothing}^{(2)},p_{\\varnothing}^{(3)},p_{\\varnothing}^{(4)},p_{\\varnothing}^{(5)}]$, where $p_{\\varnothing}^{(k)}$ is the upper bound for test case $k$ computed at its specified final time $T$.",
            "solution": "The problem requires the analysis of the telegraph model of stochastic gene expression using the Finite State Projection (FSP) method. We must first formulate the FSP truncation of the Chemical Master Equation (CME), then derive an upper bound for the truncation error, and finally implement a numerical solver to compute this bound for several test cases.\n\nLet the state of the system be $(g, m)$, where $g \\in \\{0, 1\\}$ is the promoter state (inactive/active) and $m \\in \\mathbb{N}_0$ is the number of mRNA molecules. The system evolves as a Continuous-Time Markov Chain (CTMC) with the following transitions and rates:\n- Promoter activation: $(0, m) \\to (1, m)$ with rate $k_{\\mathrm{on}}$.\n- Promoter inactivation: $(1, m) \\to (0, m)$ with rate $k_{\\mathrm{off}}$.\n- Transcription (basal): $(0, m) \\to (0, m+1)$ with rate $s_0$.\n- Transcription (active): $(1, m) \\to (1, m+1)$ with rate $s_1$.\n- mRNA Degradation: $(g, m) \\to (g, m-1)$ with rate $\\gamma m$ for any $g \\in \\{0,1\\}$ and $m>0$.\n\nLet $P(g, m, t)$ be the probability of being in state $(g, m)$ at time $t$. The time evolution of these probabilities is governed by the Chemical Master Equation (CME). For $m > 0$, the CMEs are:\n$$\n\\frac{d P(0, m, t)}{dt} = k_{\\mathrm{off}} P(1, m, t) + s_0 P(0, m-1, t) + \\gamma (m+1) P(0, m+1, t) - (k_{\\mathrm{on}} + s_0 + \\gamma m) P(0, m, t)\n$$\n$$\n\\frac{d P(1, m, t)}{dt} = k_{\\mathrm{on}} P(0, m, t) + s_1 P(1, m-1, t) + \\gamma (m+1) P(1, m+1, t) - (k_{\\mathrm{off}} + s_1 + \\gamma m) P(1, m, t)\n$$\nFor the boundary case $m=0$, the degradation terms $\\gamma m$ are zero and there is no influx from states with $m=-1$:\n$$\n\\frac{d P(0, 0, t)}{dt} = k_{\\mathrm{off}} P(1, 0, t) + \\gamma P(0, 1, t) - (k_{\\mathrm{on}} + s_0) P(0, 0, t)\n$$\n$$\n\\frac{d P(1, 0, t)}{dt} = k_{\\mathrm{on}} P(0, 0, t) + \\gamma P(1, 1, t) - (k_{\\mathrm{off}} + s_1) P(1, 0, t)\n$$\nThis is an infinite system of coupled linear ordinary differential equations (ODEs), which is typically intractable to solve directly.\n\nThe Finite State Projection (FSP) method provides a way to approximate the solution. We truncate the infinite state space to a finite projection set $S_M = \\{(g,m) \\mid g \\in \\{0,1\\}, m \\in \\{0, 1, \\dots, M\\}\\}$ for some integer $M \\ge 0$. The FSP approach models the evolution of probabilities for states within $S_M$. To account for the probability that leaves this finite set, we augment the system with an absorbing sink state, denoted $\\varnothing$. The state space of our new, finite CTMC is $S_M \\cup \\{\\varnothing\\}$. Any reaction that would lead from a state in $S_M$ to a state outside $S_M$ is re-routed to the sink state $\\varnothing$. In this model, the only such transitions are the transcription events from states with $m=M$:\n- $(0, M) \\to \\varnothing$ with rate $s_0$.\n- $(1, M) \\to \\varnothing$ with rate $s_1$.\n\nLet $p_{(g,m)}(t)$ be the probability of being in state $(g,m) \\in S_M$ and $p_{\\varnothing}(t)$ be the probability of being in the sink state in this FSP-augmented system. The total probability is conserved: $\\sum_{(g,m) \\in S_M} p_{(g,m)}(t) + p_{\\varnothing}(t) = 1$. The time evolution of the sink probability is driven by the flux out of $S_M$:\n$$\n\\frac{d p_{\\varnothing}(t)}{dt} = s_0 p_{(0,M)}(t) + s_1 p_{(1,M)}(t)\n$$\nwith initial condition $p_{\\varnothing}(0)=0$.\n\nA crucial property of the FSP is that the probability accumulated in the sink state, $p_{\\varnothing}(t)$, provides an upper bound on the true truncation error. The truncation error, $E_M(t)$, is the probability mass residing in states outside of $S_M$ in the original, infinite system:\n$$\nE_M(t) = \\sum_{g \\in \\{0,1\\}} \\sum_{m=M+1}^{\\infty} P(g, m, t)\n$$\nWe are required to justify from first principles that $p_{\\varnothing}(t) \\ge E_M(t)$ for all $t \\ge 0$.\nLet $\\mathbf{P}_F(t)$ be the vector of true probabilities $P(g,m,t)$ for states within the finite set $S_M$. The time evolution of $\\mathbf{P}_F(t)$ can be written as:\n$$\n\\frac{d \\mathbf{P}_F(t)}{dt} = A_F \\mathbf{P}_F(t) + \\mathbf{r}(t)\n$$\nHere, $A_F$ is the generator matrix restricted to states in $S_M$, where transitions leaving $S_M$ are treated as probability loss. The term $\\mathbf{r}(t)$ is a vector representing the probability influx from states outside $S_M$ back into $S_M$. Specifically, this influx comes from degradation reactions $(g, M+1) \\to (g, M)$. Thus, the components of $\\mathbf{r}(t)$ are non-negative, with $r_{(g,M)}(t) = \\gamma (M+1) P(g, M+1, t) \\ge 0$ and all other components being zero.\nNow, consider the probabilities $\\mathbf{p}(t)$ for states in $S_M$ in the FSP formulation (without the sink state). These evolve according to:\n$$\n\\frac{d \\mathbf{p}(t)}{dt} = A_F \\mathbf{p}(t)\n$$\nLet $\\mathbf{d}(t) = \\mathbf{P}_F(t) - \\mathbf{p}(t)$ be the vector of differences. Its dynamics are:\n$$\n\\frac{d \\mathbf{d}(t)}{dt} = A_F \\mathbf{d}(t) + \\mathbf{r}(t)\n$$\nThe problem specifies the initial condition is $(g,m)=(0,0)$, which is inside $S_M$ (for any $M \\ge 0$). Thus, $\\mathbf{P}_F(0) = \\mathbf{p}(0)$, which implies $\\mathbf{d}(0) = \\mathbf{0}$. The matrix $A_F$ has non-negative off-diagonal elements, a property of CTMC generator matrices. The forcing term $\\mathbf{r}(t)$ is a vector with non-negative components. For a linear system of this form (a positive system), if the initial state is non-negative and the input is non-negative, the state vector remains non-negative for all time. Since $\\mathbf{d}(0)=\\mathbf{0}$, we can conclude that $\\mathbf{d}(t) \\ge \\mathbf{0}$ for all $t \\ge 0$. This implies $P(g, m, t) \\ge p_{(g,m)}(t)$ for all $(g,m) \\in S_M$ and $t \\ge 0$.\nThe total probability in the original system is $1$: $\\sum_{(g,m) \\in S_M} P(g,m,t) + E_M(t) = 1$.\nThe total probability in the FSP-augmented system is also $1$: $\\sum_{(g,m) \\in S_M} p_{(g,m)}(t) + p_{\\varnothing}(t) = 1$.\nThe truncation error is $E_M(t) = 1 - \\sum_{(g,m) \\in S_M} P(g,m,t)$.\nFrom our derived inequality, $\\sum P(g,m,t) \\ge \\sum p_{(g,m)}(t)$.\nTherefore, $-\\sum P(g,m,t) \\le -\\sum p_{(g,m)}(t)$, which leads to:\n$$\nE_M(t) = 1 - \\sum_{(g,m) \\in S_M} P(g,m,t) \\le 1 - \\sum_{(g,m) \\in S_M} p_{(g,m)}(t) = p_{\\varnothing}(t)\n$$\nThis confirms that the probability of the sink state, $p_{\\varnothing}(t)$, is a computable upper bound on the true truncation error.\n\nTo compute $p_{\\varnothing}(T)$, we solve the finite system of ODEs for the FSP-augmented CTMC. We represent the system in matrix form, $\\frac{d\\mathbf{p}(t)}{dt} = A_M \\mathbf{p}(t)$, where $\\mathbf{p}(t)$ is the state probability vector and $A_M$ is the generator matrix. The state vector is ordered as follows:\n$\\mathbf{p} = [p_{(0,0)}, \\dots, p_{(0,M)}, p_{(1,0)}, \\dots, p_{(1,M)}, p_{\\varnothing}]^T$.\nThis gives a total of $N = 2(M+1)+1$ states. The generator matrix $A_M$ is an $N \\times N$ matrix where $A_M[j,i]$ is the rate of transition from state $i$ to state $j$.\n\nThe non-zero off-diagonal elements of $A_M$ for source state $i=(g,m)$ are:\n1.  **Transcription**: For $m < M$, state $(g,m)$ transitions to $(g,m+1)$ with rate $s_g$. If we index state $(g', m')$ by $i(g', m')$, this means $A_M[i(g, m+1), i(g, m)] = s_g$.\n2.  **Degradation**: For $m > 0$, state $(g,m)$ transitions to $(g,m-1)$ with rate $\\gamma m$. This means $A_M[i(g, m-1), i(g, m)] = \\gamma m$.\n3.  **Switching**: For any $m \\in \\{0, \\dots, M\\}$, state $(0,m)$ transitions to $(1,m)$ with rate $k_{\\mathrm{on}}$, and $(1,m)$ transitions to $(0,m)$ with rate $k_{\\mathrm{off}}$. This means $A_M[i(1, m), i(0, m)] = k_{\\mathrm{on}}$ and $A_M[i(0, m), i(1, m)] = k_{\\mathrm{off}}$.\n4.  **Flux to Sink**: For the boundary states $m=M$, transcription transitions are re-routed to the sink state $\\varnothing$, whose index is $N-1 = 2(M+1)$.\n    - $A_M[N-1, i(0, M)] = s_0$.\n    - $A_M[N-1, i(1, M)] = s_1$.\nThe diagonal elements are set such that each column sums to zero, representing the total rate of leaving a state: $A_M[i, i] = - \\sum_{j \\neq i} A_M[j,i]$. For the absorbing sink state, the corresponding column of $A_M$ is all zeros.\n\nWith the matrix $A_M$ constructed, we solve the initial value problem $\\frac{d\\mathbf{p}}{dt} = A_M \\mathbf{p}(t)$ with $\\mathbf{p}(0)$ being a vector with $1$ at the position corresponding to state $(0,0)$ and $0$ elsewhere. The solution is obtained by numerical integration up to the final time $T$. The desired error bound is the final probability of the sink state, $p_{\\varnothing}(T)$, which is the last element of the solution vector $\\mathbf{p}(T)$.",
            "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the Finite State Projection formulation of the telegraph model\n    for several test cases and computes the truncation error upper bound.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general case)\n        {'kon': 1.0, 'koff': 1.5, 's0': 0.0, 's1': 5.0, 'gamma': 1.0, 'M': 50, 'T': 5.0},\n        # Case 2 (boundary-truncation stress)\n        {'kon': 2.0, 'koff': 0.5, 's0': 0.0, 's1': 20.0, 'gamma': 1.0, 'M': 5, 'T': 5.0},\n        # Case 3 (no-switching edge)\n        {'kon': 0.0, 'koff': 0.0, 's0': 0.0, 's1': 5.0, 'gamma': 1.0, 'M': 10, 'T': 10.0},\n        # Case 4 (basal transcription with slow degradation)\n        {'kon': 0.2, 'koff': 2.0, 's0': 1.0, 's1': 8.0, 'gamma': 0.5, 'M': 20, 'T': 10.0},\n        # Case 5 (fast degradation)\n        {'kon': 3.0, 'koff': 3.0, 's0': 0.0, 's1': 5.0, 'gamma': 5.0, 'M': 30, 'T': 5.0},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        kon, koff, s0, s1, gamma = case['kon'], case['koff'], case['s0'], case['s1'], case['gamma']\n        M, T = case['M'], case['T']\n\n        # The state space for the FSP is {(g, m) | g in {0,1}, m in {0,...,M}}\n        # plus one absorbing sink state.\n        # Total number of states = 2 * (M + 1) + 1\n        num_states = 2 * (M + 1) + 1\n        \n        # Generator matrix A, where A[j, i] is the rate from state i to state j.\n        A = np.zeros((num_states, num_states))\n\n        # Index mapping:\n        # g=0, m -> m\n        # g=1, m -> M + 1 + m\n        # sink   -> 2 * (M + 1)\n        sink_idx = 2 * (M + 1)\n\n        for m in range(M + 1):\n            # State (0, m)\n            idx0 = m\n            # State (1, m)\n            idx1 = M + 1 + m\n\n            # Promoter switching\n            A[idx1, idx0] = kon\n            A[idx0, idx1] = koff\n\n            # Degradation\n            if m > 0:\n                # From (0, m) to (0, m-1)\n                A[idx0 - 1, idx0] = gamma * m\n                # From (1, m) to (1, m-1)\n                A[idx1 - 1, idx1] = gamma * m\n        \n            # Transcription\n            if m < M:\n                # From (0, m) to (0, m+1)\n                A[idx0 + 1, idx0] = s0\n                # From (1, m) to (1, m+1)\n                A[idx1 + 1, idx1] = s1\n            else: # m == M, transcription leads to sink state\n                A[sink_idx, idx0] = s0\n                A[sink_idx, idx1] = s1\n\n        # Set diagonal elements to ensure columns sum to zero\n        # This conserves probability.\n        for i in range(num_states - 1): # Exclude the sink state column\n            A[i, i] = -np.sum(A[:, i])\n\n        # The column for the sink state is all zeros as it's absorbing.\n        A[:, sink_idx] = 0.0\n\n        # Initial condition: probability 1 in state (g=0, m=0), 0 elsewhere.\n        p0 = np.zeros(num_states)\n        p0[0] = 1.0\n\n        # Define the ODE system for the solver\n        def ode_system(t, p, A_matrix):\n            return A_matrix @ p\n\n        # Solve the ODE system\n        sol = solve_ivp(\n            fun=ode_system,\n            t_span=(0, T),\n            y0=p0,\n            args=(A,),\n            method='Radau', # Good for stiff problems\n            t_eval=[T]\n        )\n\n        # The result is the probability in the sink state at time T.\n        p_final = sol.y[:, -1]\n        p_sink = p_final[sink_idx]\n        results.append(p_sink)\n\n    # Format output as a comma-separated list in brackets\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Biological systems are inherently multiscale, with reactions occurring on timescales that can span many orders of magnitude. In this practice, you will tackle this challenge by implementing a hybrid simulation algorithm that partitions reactions into slow and fast subsets . You will combine the exactness of the Stochastic Simulation Algorithm (SSA) for slow promoter switching with the efficiency of the Chemical Langevin Equation (CLE) for fast protein dynamics, a powerful strategy for simulating complex biological networks.",
            "id": "4388464",
            "problem": "You are to implement and analyze a hybrid stochastic simulation algorithm for single-cell gene expression with two timescales: slow promoter switching and fast protein birth-death dynamics. The model is a two-state promoter telegraph process where the promoter toggles between an inactive state and an active state, producing protein when active. The fast reactions (translation and protein degradation) are approximated by the Chemical Langevin Equation (CLE), while slow promoter switching is simulated by the Stochastic Simulation Algorithm (SSA). Your task is to derive a principled error bound for the hybrid method and test it computationally against a full SSA baseline.\n\nModel specification:\n- The promoter state is denoted by $s(t) \\in \\{0,1\\}$, with $s(t)=1$ indicating the active state and $s(t)=0$ indicating the inactive state.\n- Protein count is denoted by $x(t) \\in \\mathbb{N}_{0}$ under exact SSA and by a nonnegative real-valued approximation under CLE on fast timescales.\n- Slow promoter switching reactions are:\n  - Inactive to active: rate $k_{\\mathrm{on}}$ (in $\\mathrm{hr}^{-1}$).\n  - Active to inactive: rate $k_{\\mathrm{off}}$ (in $\\mathrm{hr}^{-1}$).\n- Fast reactions affecting protein are:\n  - Translation (protein birth when $s=1$): rate $k_{p} s(t)$ (in $\\mathrm{hr}^{-1}$).\n  - Protein degradation (protein death): rate $\\gamma x(t)$ (in $\\mathrm{hr}^{-1}$).\n\nFoundational base for derivation:\n- The Chemical Master Equation (CME) and its jump process representation for birth-death dynamics with switching.\n- The Gillespie Direct Method as the Stochastic Simulation Algorithm (SSA) for exact simulation of the CME.\n- The Chemical Langevin Equation (CLE) as a diffusion approximation to fast reaction dynamics under large molecule numbers and well-separated timescales.\n\nHybrid scheme definition:\n- The promoter state $s(t)$ is simulated by SSA with exact exponential waiting times for $k_{\\mathrm{on}}$ and $k_{\\mathrm{off}}$ depending on the current state.\n- Between promoter-switching events, the fast protein dynamics are simulated via the CLE:\n  $$\\mathrm{d}x(t) = \\left(k_{p} s(t) - \\gamma x(t)\\right)\\mathrm{d}t + \\sqrt{k_{p} s(t) + \\gamma x(t)}\\,\\mathrm{d}W(t),$$\n  with $W(t)$ a standard Wiener process. Numerical integration must use the Eulerâ€“Maruyama method with a fixed step size $h$ (in $\\mathrm{hr}$), enforcing $x(t) \\ge 0$ at all times.\n\nError metric and bound:\n- Consider the weak error in the mean protein level at a fixed final time $T$ (in $\\mathrm{hr}$):\n  $$\\left|\\mathbb{E}\\left[x_{\\mathrm{hyb}}(T)\\right] - \\mathbb{E}\\left[x_{\\mathrm{ssa}}(T)\\right]\\right|.$$\n- Let the timescale separation parameter be defined by\n  $$\\delta = \\frac{k_{\\mathrm{on}} + k_{\\mathrm{off}}}{\\gamma}.$$\n- Derive an upper bound of the form\n  $$\\left|\\mathbb{E}\\left[x_{\\mathrm{hyb}}(T)\\right] - \\mathbb{E}\\left[x_{\\mathrm{ssa}}(T)\\right]\\right| \\le B(T,h,\\delta,k_{p},\\gamma),$$\n  where $B$ is an explicit function that depends only on $T$, $h$, $\\delta$, $k_{p}$, and $\\gamma$, and scales linearly in $h$ and monotonically in $\\delta$, consistent with the principle that larger separation (smaller $\\delta$) reduces hybrid error. Your bound must be justified from first principles and must not assume any shortcut formulas.\n\nUnits and numerical requirements:\n- All rates must be provided in $\\mathrm{hr}^{-1}$, the time step $h$ and final time $T$ must be in $\\mathrm{hr}$, and all simulations should treat these units consistently.\n- Output should be based on Monte Carlo averages with a finite number of trajectories $M$ for both hybrid and full SSA.\n\nTest suite:\nImplement your program to evaluate the bound across the following test cases, each specified as a tuple $(T, k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{p}, \\gamma, x_{0}, s_{0}, h, M)$, with $x_{0}$ the initial protein count (integer), $s_{0}$ the initial promoter state in $\\{0,1\\}$, $h$ the CLE step size (in $\\mathrm{hr}$), and $M$ the number of independent trajectories:\n1. Case A (clear separation of timescales, happy path): $(T=\\;10,\\; k_{\\mathrm{on}}=\\;0.05,\\; k_{\\mathrm{off}}=\\;0.05,\\; k_{p}=\\;100,\\; \\gamma=\\;1,\\; x_{0}=\\;0,\\; s_{0}=\\;0,\\; h=\\;0.01,\\; M=\\;800)$.\n2. Case B (boundary condition with moderate separation): $(T=\\;5,\\; k_{\\mathrm{on}}=\\;1,\\; k_{\\mathrm{off}}=\\;1,\\; k_{p}=\\;50,\\; \\gamma=\\;1,\\; x_{0}=\\;0,\\; s_{0}=\\;0,\\; h=\\;0.02,\\; M=\\;800)$.\n3. Case C (edge case with low production): $(T=\\;8,\\; k_{\\mathrm{on}}=\\;0.1,\\; k_{\\mathrm{off}}=\\;0.1,\\; k_{p}=\\;2,\\; \\gamma=\\;1,\\; x_{0}=\\;0,\\; s_{0}=\\;0,\\; h=\\;0.01,\\; M=\\;800)$.\n4. Case D (fast switching, weak separation): $(T=\\;4,\\; k_{\\mathrm{on}}=\\;5,\\; k_{\\mathrm{off}}=\\;5,\\; k_{p}=\\;80,\\; \\gamma=\\;1,\\; x_{0}=\\;0,\\; s_{0}=\\;0,\\; h=\\;0.005,\\; M=\\;800)$.\n\nFinal output specification:\n- For each test case, estimate the empirical weak error in the mean protein at time $T$, compute your derived bound $B(T,h,\\delta,k_{p},\\gamma)$, and return a boolean indicating whether the observed error is less than or equal to the bound accounting for Monte Carlo sampling uncertainty.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\mathrm{true},\\mathrm{false},\\mathrm{true},\\mathrm{true}]$), where each entry is a Python boolean literal reflecting whether the bound holds for the corresponding test case.",
            "solution": "The user-provided problem has been analyzed and is determined to be valid. It is scientifically grounded, well-posed, and objective, providing a clear and self-contained task within the established framework of stochastic modeling in systems biomedicine. The problem requires the derivation of a weak error bound for a hybrid stochastic simulation algorithm and its computational verification.\n\nThe solution proceeds as follows: First, a theoretical upper bound for the weak error is derived from first principles. Second, the implementation of both the exact Stochastic Simulation Algorithm (SSA) and the hybrid SSA-Chemical Langevin Equation (CLE) method is outlined. Finally, the derived bound is computationally tested against the empirical error for the specified test cases.\n\n### Derivation of the Weak Error Bound\n\nThe goal is to find an upper bound $B$ for the weak error in the mean protein level at a final time $T$:\n$$ \\left|\\mathbb{E}\\left[x_{\\mathrm{hyb}}(T)\\right] - \\mathbb{E}\\left[x_{\\mathrm{ssa}}(T)\\right]\\right| \\le B(T,h,\\delta,k_{p},\\gamma) $$\nThe total error is the result of two distinct approximations made in the hybrid scheme relative to the full SSA:\n$1$. **Timescale Splitting Error ($E_{\\delta}$)**: This error arises from decoupling the slow promoter switching from the fast protein dynamics. It is a function of the timescale separation parameter $\\delta = (k_{\\mathrm{on}} + k_{\\mathrm{off}})/\\gamma$.\n$2$. **Discretization Error ($E_h$)**: This error is introduced by the numerical integration of the Chemical Langevin Equation (CLE) using the Euler-Maruyama method with a finite time step $h$.\n\nWe can bound the total error by the sum of the bounds for these two error sources:\n$$ \\left|\\mathbb{E}\\left[x_{\\mathrm{hyb}}(T)\\right] - \\mathbb{E}\\left[x_{\\mathrm{ssa}}(T)\\right]\\right| \\le E_{\\delta} + E_{h} $$\n\n#### 1. Derivation of the Timescale Splitting Error Bound ($E_{\\delta}$)\n\nThe timescale splitting approximation assumes that the fast variables (protein count $x$) relax to their quasi-steady-state distribution, conditioned on the slow variable's state (promoter state $s$), much faster than the slow variable itself changes. The error in this approximation is proportional to the ratio of the fast relaxation time to the slow characteristic time.\n\nThe characteristic time for the fast process (protein degradation) is $\\tau_{\\mathrm{fast}} \\approx 1/\\gamma$.\nThe characteristic time for the slow process (promoter switching) is $\\tau_{\\mathrm{slow}} \\approx 1/(k_{\\mathrm{on}} + k_{\\mathrm{off}})$.\nThe ratio of these timescales is $\\tau_{\\mathrm{fast}} / \\tau_{\\mathrm{slow}} = (k_{\\mathrm{on}} + k_{\\mathrm{off}})/\\gamma = \\delta$.\n\nThe magnitude of the error in the mean protein level, $\\mathbb{E}[x]$, depends on the magnitude of the protein fluctuations that are incorrectly represented. The protein level scale is set by the production rate $k_p$ and degradation rate $\\gamma$, with a quasi-steady-state mean of approximately $k_p/\\gamma$ when the gene is active. Therefore, a principled heuristic for the splitting error scales with both $\\delta$ and this protein level.\n\nThe error accumulates over time, but it is also damped by the degradation process. The term $(1 - e^{-\\gamma T})$ captures this, representing the system approaching its steady-state behavior over the timescale $1/\\gamma$. For small $T \\ll 1/\\gamma$, this factor is approximately $\\gamma T$, leading to an error that grows linearly with time. For large $T \\gg 1/\\gamma$, the error saturates as the system reaches a stochastic steady state.\n\nCombining these elements, we propose the following bound for the splitting error component:\n$$ E_{\\delta} = \\frac{k_p}{\\gamma} \\delta \\left(1-e^{-\\gamma T}\\right) $$\n\n#### 2. Derivation of the Discretization Error Bound ($E_h$)\n\nThe second source of error is the numerical integration of the CLE for the protein dynamics. The CLE is:\n$$ \\mathrm{d}x(t) = (k_{p} s(t) - \\gamma x(t))\\mathrm{d}t + \\sqrt{k_{p} s(t) + \\gamma x(t)}\\,\\mathrm{d}W(t) $$\nThe weak error of the simulation is the error in the evolution of the moments. The evolution of the mean, $\\mu_x(t) = \\mathbb{E}[x(t)]$, for the exact SDE (and also for the underlying CME) is given by the ODE:\n$$ \\frac{d\\mu_x}{dt} = k_{p} \\mathbb{E}[s(t)] - \\gamma \\mu_x(t) $$\nThe Euler-Maruyama scheme for the SDE corresponds to the forward Euler method for this ODE of the mean. The global weak error is therefore bounded by the global error of the forward Euler method applied to this ODE.\n\nThe global error $e_N$ of the forward Euler method after $N=T/h$ steps for a stable linear ODE $\\dot{y} = -\\lambda y + f(t)$ with $\\lambda > 0$ can be bounded. The local truncation error at each step is $O(h^2)$, specifically $\\frac{h^2}{2} \\ddot{y}(t)$. Unlike unstable systems where errors compound exponentially, the contractive nature of the dynamics (due to the degradation term with rate $\\gamma$) damps the propagated error. The global error for such a stable system is bounded by a term proportional to $h$, without exponential growth in $T$:\n$$ |e_N| \\le \\frac{h}{2\\gamma} \\sup_{t \\in [0,T]} |\\ddot{\\mu}_x(t)| $$\nWe must now find a bound for the second derivative, $M = \\sup_{t \\in [0,T]} |\\ddot{\\mu}_x(t)|$.\n$$ \\ddot{\\mu}_x(t) = \\frac{d}{dt} \\left( k_{p} \\mathbb{E}[s(t)] - \\gamma \\mu_x(t) \\right) = k_p \\dot{p}_1(t) - \\gamma \\dot{\\mu}_x(t) $$\nwhere $p_1(t) = \\mathbb{E}[s(t)]$. The dynamics of $p_1(t)$ are governed by $\\dot{p}_1 = k_{\\mathrm{on}} - (k_{\\mathrm{on}}+k_{\\mathrm{off}})p_1$. The magnitude of this rate is bounded by $|\\dot{p}_1(t)| \\le \\max(k_{\\mathrm{on}}, k_{\\mathrm{off}})$. As a looser but simpler bound, we use $|\\dot{p}_1(t)| \\le k_{\\mathrm{on}}+k_{\\mathrm{off}} = \\delta\\gamma$.\nFor $\\dot{\\mu}_x(t)$, we can establish a bound by considering the physical limits of the system. The rate of change of protein is bounded by the production and degradation rates, $|k_p s(t) - \\gamma x(t)|$. A simple upper bound on the magnitude of the mean's rate of change is the production rate $k_p$. So, $|\\dot{\\mu}_x(t)| \\le k_p$.\nCombining these bounds:\n$$ M = \\sup|\\ddot{\\mu}_x(t)| \\le k_p |\\dot{p}_1(t)| + \\gamma |\\dot{\\mu}_x(t)| \\le k_p(\\delta\\gamma) + \\gamma k_p = \\gamma k_p (\\delta+1) $$\nSubstituting this into the global error formula gives the bound for the discretization error:\n$$ E_h = \\frac{h}{2\\gamma} \\left( \\gamma k_p (\\delta+1) \\right) = \\frac{h k_p (\\delta+1)}{2} $$\n\n#### 3. Final Combined Error Bound\n\nThe total weak error bound $B$ is the sum of the splitting and discretization error bounds:\n$$ B(T,h,\\delta,k_{p},\\gamma) = E_{\\delta} + E_h = \\frac{k_p}{\\gamma} \\delta \\left(1-e^{-\\gamma T}\\right) + \\frac{h k_p (\\delta+1)}{2} $$\nThis expression fulfills the problem's requirements: it depends only on the specified parameters and scales linearly in $h$ and monotonically with $\\delta$.\n\n### Simulation and Verification Strategy\n\nTo verify this bound, two simulation algorithms are required:\n1.  **Full SSA**: The standard Gillespie Direct Method is implemented to provide a gold-standard, exact stochastic simulation of the full reaction system (two promoter-switching and two protein reactions).\n2.  **Hybrid SSA-CLE**: This algorithm simulates the slow promoter-switching reactions using exact waiting times (SSA), while the protein dynamics between these slow events are approximated by numerically integrating the CLE with the Euler-Maruyama method and step size $h$. Care is taken to enforce the non-negativity of the protein count $x(t)$.\n\nFor each test case, the mean final protein count $\\mathbb{E}[x(T)]$ is estimated for both methods by averaging over a large number $M$ of independent trajectories. The empirical weak error is calculated as the absolute difference between these two estimated means. This empirical error is then compared against the value predicted by the derived bound $B$. The bound is considered to hold if the empirical error is less than or equal to $B$. Due to Monte Carlo sampling noise, a single instance of `empirical_error > B` does not definitively invalidate the bound, but for a sufficiently large $M$, the comparison serves as a strong numerical test of the derived formula's validity and scaling.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef ssa_full(T, k_on, k_off, kp, gamma, x0, s0):\n    \"\"\"\n    Simulates the two-state gene expression model using the exact Gillespie SSA.\n    \"\"\"\n    t = 0.0\n    x = x0\n    s = s0\n\n    while t < T:\n        # Propensities\n        a1 = k_on * (1 - s)  # inactive -> active\n        a2 = k_off * s       # active -> inactive\n        a3 = kp * s          # protein production\n        a4 = gamma * x       # protein degradation\n        a_tot = a1 + a2 + a3 + a4\n\n        if a_tot == 0:\n            t = T  # No more reactions can occur\n            break\n        \n        # Time to next reaction\n        tau = -math.log(np.random.rand()) / a_tot\n        \n        if t + tau > T:\n            t = T\n            break\n        \n        t += tau\n        \n        # Choose reaction\n        r = np.random.rand() * a_tot\n        if r < a1:\n            s = 1\n        elif r < a1 + a2:\n            s = 0\n        elif r < a1 + a2 + a3:\n            x += 1\n        else:\n            x -= 1\n            \n    return x\n\ndef ssa_hybrid(T, k_on, k_off, kp, gamma, x0, s0, h):\n    \"\"\"\n    Simulates the model using the hybrid SSA-CLE algorithm.\n    \"\"\"\n    t = 0.0\n    x = float(x0)\n    s = s0\n\n    while t < T:\n        # Time to next slow reaction (promoter switch)\n        a_slow = k_on * (1 - s) + k_off * s\n        tau_slow = -math.log(np.random.rand()) / a_slow if a_slow > 0 else float('inf')\n        \n        t_end_interval = min(t + tau_slow, T)\n        \n        # Fast dynamics via CLE (Euler-Maruyama)\n        while t < t_end_interval:\n            step = min(h, t_end_interval - t)\n            \n            drift = kp * s - gamma * x\n            diffusion_arg = kp * s + gamma * x\n            diffusion = math.sqrt(max(0, diffusion_arg))\n            \n            dW = np.random.randn() * math.sqrt(step)\n            \n            x += drift * step + diffusion * dW\n            x = max(0.0, x)  # Enforce non-negativity\n            \n            t += step\n\n        if t >= T:\n            break\n            \n        # A slow reaction occurred at time t\n        s = 1 - s\n            \n    return x\n\ndef calculate_bound(T, k_on, k_off, kp, gamma, h):\n    \"\"\"\n    Calculates the derived theoretical error bound.\n    \"\"\"\n    delta = (k_on + k_off) / gamma\n    \n    # Splitting error component\n    e_delta = (kp / gamma) * delta * (1 - math.exp(-gamma * T))\n    \n    # Discretization error component\n    e_h = (h * kp * (delta + 1)) / 2.0\n    \n    return e_delta + e_h\n\ndef solve():\n    \"\"\"\n    Main solver function to run test cases and check the bound.\n    \"\"\"\n    test_cases = [\n        # (T, k_on, k_off, kp, gamma, x0, s0, h, M)\n        (10, 0.05, 0.05, 100, 1, 0, 0, 0.01, 800),  # Case A\n        (5, 1, 1, 50, 1, 0, 0, 0.02, 800),        # Case B\n        (8, 0.1, 0.1, 2, 1, 0, 0, 0.01, 800),     # Case C\n        (4, 5, 5, 80, 1, 0, 0, 0.005, 800),     # Case D\n    ]\n\n    results = []\n\n    for case in test_cases:\n        T, k_on, k_off, kp, gamma, x0, s0, h, M = case\n        \n        # Run Monte Carlo simulations\n        np.random.seed(0) # for reproducibility\n        final_x_ssa = [ssa_full(T, k_on, k_off, kp, gamma, x0, s0) for _ in range(M)]\n        \n        np.random.seed(0) # for reproducibility\n        final_x_hyb = [ssa_hybrid(T, k_on, k_off, kp, gamma, x0, s0, h) for _ in range(M)]\n        \n        # Calculate means and empirical error\n        mean_ssa = np.mean(final_x_ssa)\n        mean_hyb = np.mean(final_x_hyb)\n        empirical_error = abs(mean_hyb - mean_ssa)\n        \n        # Calculate theoretical bound\n        theoretical_bound = calculate_bound(T, k_on, k_off, kp, gamma, h)\n        \n        # Check if bound holds\n        bound_holds = empirical_error <= theoretical_bound\n        results.append(bound_holds)\n\n    # Format output as required\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "Building predictive models requires connecting them to experimental observations, a process known as parameter inference. This exercise moves from forward simulation to this inverse problem, focusing on how to learn from single-cell transcriptomic data . You will implement a hierarchical Bayesian model to estimate cell-specific burst parameters, discovering the concept of posterior shrinkage, which enables robust parameter estimation by \"borrowing statistical strength\" across a cell population.",
            "id": "4388424",
            "problem": "Consider a stochastic gene expression scenario at the single-cell level in systems biomedicine where transcription occurs in bursts. Over a fixed observation window of duration $\\Delta t$, suppose each cell $i$ produces a count $x_i$ of messenger ribonucleic acid (mRNA) molecules. Assume a simplified burst model where, conditional on a cell-specific mean burst size $b_i$ (mRNA molecules per burst) and a common burst frequency $f$ (bursts per unit time) across cells, the observed count is modeled as a Poisson random variable with rate $f \\, \\Delta t \\, b_i$. That is, for each cell $i$, \n$$\nx_i \\mid b_i \\sim \\text{Poisson}(f \\, \\Delta t \\, b_i).\n$$\nAssume across cells that $b_i$ follows a Gamma prior with shape $\\alpha$ and rate $\\beta$, written as $b_i \\sim \\text{Gamma}(\\alpha,\\beta)$, where the Gamma density is parameterized with shape-rate, and the rate parameter uses the convention that larger $\\beta$ implies stronger shrinkage. This induces, after integrating out $b_i$, a Negative Binomial distribution for $x_i$ across the population, consistent with bursty gene expression at steady state.\n\nYou are tasked to compare hierarchical versus pooled analyses by computing posterior shrinkage effects and their impact on estimated burst parameters. For hierarchical analysis, use empirical Bayes to estimate the hyperparameters $(\\alpha,\\beta)$ from the observed counts $\\{x_i\\}_{i=1}^N$ by matching the first two moments of the Poisson-Gamma mixture. Let $c = f \\, \\Delta t$ denote the known exposure scaling. Denote the sample mean across cells by \n$$\nm = \\frac{1}{N} \\sum_{i=1}^N x_i,\n$$\nand the population (non-unbiased) sample variance by \n$$\ns^2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - m)^2.\n$$\nThe Poisson-Gamma mixture implies \n$$\n\\mathbb{E}[x_i] = c \\, \\frac{\\alpha}{\\beta} = m, \\quad \\text{Var}(x_i) = c \\, \\frac{\\alpha}{\\beta} + c^2 \\, \\frac{\\alpha}{\\beta^2} = s^2.\n$$\nSolving these by method of moments yields \n$$\n\\hat{\\alpha} = \\frac{m^2}{s^2 - m}, \\quad \\hat{\\beta} = c \\, \\frac{\\hat{\\alpha}}{m},\n$$\nprovided $s^2 > m$. In the boundary case $s^2 \\le m$ (no over-dispersion beyond Poisson), set $\\hat{\\alpha}$ to a large value (e.g., $\\hat{\\alpha} = 10^6$) and $\\hat{\\beta} = c \\, \\hat{\\alpha} / m$ to reflect negligible over-dispersion; if $m = 0$, set $\\hat{\\alpha} = 10^{-6}$ and $\\hat{\\beta} = 10^{-6}$ to avoid division by zero.\n\nUnder the hierarchical model, the posterior for each $b_i$ given $x_i$ is conjugate:\n$$\nb_i \\mid x_i \\sim \\text{Gamma}(\\hat{\\alpha} + x_i, \\hat{\\beta} + c),\n$$\nso the hierarchical posterior mean is \n$$\n\\hat{b}_i^{\\text{hier}} = \\frac{\\hat{\\alpha} + x_i}{\\hat{\\beta} + c}.\n$$\nFor a per-cell maximum likelihood estimate (MLE) of the burst size under the conditional Poisson model,\n$$\n\\hat{b}_i^{\\text{MLE}} = \\frac{x_i}{c}.\n$$\nDefine the hierarchical posterior shrinkage difference (in mRNA molecules per burst) for each cell as \n$$\ns_i = \\hat{b}_i^{\\text{hier}} - \\hat{b}_i^{\\text{MLE}}.\n$$\n\nFor the pooled analysis, assume all cells share a single burst size parameter $b_{\\text{pool}}$ with prior $b_{\\text{pool}} \\sim \\text{Gamma}(\\alpha_0, \\beta_0)$. Using the pooled likelihood over all cells,\n$$\nb_{\\text{pool}} \\mid x_{1:N} \\sim \\text{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^N x_i,\\, \\beta_0 + N c \\right),\n$$\nand the pooled posterior mean is\n$$\n\\hat{b}^{\\text{pool}} = \\frac{\\alpha_0 + \\sum_{i=1}^N x_i}{\\beta_0 + N c}.\n$$\nDefine the per-cell pooled impact difference as \n$$\nd_i = \\hat{b}^{\\text{pool}} - \\hat{b}_i^{\\text{hier}}.\n$$\n\nFor each test case, compute the following three summary metrics:\n1. The average hierarchical shrinkage difference \n$$\n\\overline{s} = \\frac{1}{N} \\sum_{i=1}^N s_i,\n$$\nexpressed in mRNA molecules per burst, rounded to six decimal places.\n2. The average absolute pooled impact difference \n$$\n\\overline{|d|} = \\frac{1}{N} \\sum_{i=1}^N |d_i|,\n$$\nexpressed in mRNA molecules per burst, rounded to six decimal places.\n3. The ratio \n$$\nR = \\frac{\\hat{b}^{\\text{pool}}}{\\frac{1}{N} \\sum_{i=1}^N \\hat{b}_i^{\\text{hier}}},\n$$\ndimensionless, rounded to six decimal places.\n\nUse the following test suite of parameter values that covers a general case, boundary conditions, and edge cases:\n- Test case $1$: $x_{1:10} = [\\,3,\\,0,\\,1,\\,5,\\,2,\\,4,\\,6,\\,1,\\,0,\\,3\\,]$, $f = 0.5$ (bursts per minute), $\\Delta t = 2$ (minutes), so $c = 1$. Pooled prior hyperparameters: $\\alpha_0 = 1$, $\\beta_0 = 1$.\n- Test case $2$: $x_{1:8} = [\\,0,\\,0,\\,0,\\,1,\\,2,\\,0,\\,3,\\,0\\,]$, $f = 1$ (bursts per minute), $\\Delta t = 1$ (minutes), so $c = 1$. Pooled prior hyperparameters: $\\alpha_0 = 0.5$, $\\beta_0 = 0.5$.\n- Test case $3$: $x_{1:12} = [\\,10,\\,15,\\,12,\\,8,\\,20,\\,5,\\,18,\\,11,\\,7,\\,9,\\,14,\\,16\\,]$, $f = 2$ (bursts per minute), $\\Delta t = 3$ (minutes), so $c = 6$. Pooled prior hyperparameters: $\\alpha_0 = 1$, $\\beta_0 = 0.1$.\n- Test case $4$: $x_{1:3} = [\\,2,\\,9,\\,1\\,]$, $f = 0.2$ (bursts per minute), $\\Delta t = 5$ (minutes), so $c = 1$. Pooled prior hyperparameters: $\\alpha_0 = 2$, $\\beta_0 = 2$.\n\nYour program must implement the empirical Bayes estimation of $(\\hat{\\alpha}, \\hat{\\beta})$, compute $\\hat{b}_i^{\\text{hier}}$, $\\hat{b}_i^{\\text{MLE}}$, $\\hat{b}^{\\text{pool}}$, and then produce the three metrics $(\\overline{s}, \\overline{|d|}, R)$ for each test case. All outputs involving burst size must be treated as mRNA molecules per burst. The final output format must be a single line containing a comma-separated list of the results for all test cases, flattened and enclosed in square brackets, specifically \n$$\n[\\overline{s}_1,\\overline{|d|}_1,R_1,\\overline{s}_2,\\overline{|d|}_2,R_2,\\overline{s}_3,\\overline{|d|}_3,R_3,\\overline{s}_4,\\overline{|d|}_4,R_4],\n$$\nwhere each entry is a float rounded to six decimal places.",
            "solution": "The objective is to compare hierarchical versus pooled analyses within a bursty transcription model by quantifying posterior shrinkage effects and their implications for estimated burst parameters at the single-cell level. We proceed from fundamental principles applicable to stochastic gene expression.\n\nFirst, we adopt a mechanistic viewpoint consistent with the two-state promoter model (telegraph model) and its bursty limit: transcription events occur in bursts, and over a short observation window $\\Delta t$, the accumulated mRNA count for each cell $i$ can be approximated as a Poisson random variable conditional on a latent cell-specific production parameter. Let $b_i$ denote the mean burst size (mRNA molecules per burst), and let $f$ denote the burst frequency (bursts per unit time). The expected production over time $\\Delta t$ is then $f \\, \\Delta t \\, b_i$, so we set \n$$\nx_i \\mid b_i \\sim \\text{Poisson}(f \\, \\Delta t \\, b_i),\n$$\nwhere $x_i$ is the observed mRNA count for cell $i$. This conditional Poisson model follows from the assumption of independent event arrivals in time with rate $f$, each producing $b_i$ molecules on average, which is consistent with widely used approximations of bursty transcription at steady state.\n\nSecond, to capture between-cell variability in burst sizes, we posit a Gamma prior $b_i \\sim \\text{Gamma}(\\alpha,\\beta)$ using the shape-rate parameterization. This assumption is widely used in conjugate Bayesian modeling due to mathematical tractability and biological interpretability: the Gamma prior reflects population-level heterogeneity in burst size across cells. The mixture of Poisson with Gamma implies a Negative Binomial marginal distribution for $x_i$ across cells, a well-tested fact in single-cell transcriptomics under bursty production.\n\nWe now derive a hierarchical Bayesian estimator via empirical Bayes. Define the known exposure scaling $c = f \\, \\Delta t$. The Poisson-Gamma mixture implies the population mean and variance (law of total expectation and variance):\n$$\n\\mathbb{E}[x_i] = \\mathbb{E}\\left[\\mathbb{E}[x_i \\mid b_i]\\right] = \\mathbb{E}[c \\, b_i] = c \\, \\frac{\\alpha}{\\beta},\n$$\n$$\n\\text{Var}(x_i) = \\mathbb{E}[\\text{Var}(x_i \\mid b_i)] + \\text{Var}(\\mathbb{E}[x_i \\mid b_i]) = \\mathbb{E}[c \\, b_i] + \\text{Var}(c \\, b_i) = c \\, \\frac{\\alpha}{\\beta} + c^2 \\, \\frac{\\alpha}{\\beta^2}.\n$$\nFrom observed data $\\{x_i\\}_{i=1}^N$, compute the sample mean \n$$\nm = \\frac{1}{N} \\sum_{i=1}^N x_i\n$$\nand the population (non-unbiased) sample variance \n$$\ns^2 = \\frac{1}{N} \\sum_{i=1}^N (x_i - m)^2.\n$$\nMatching moments yields two equations in two unknowns $(\\alpha,\\beta)$:\n$$\nm = c \\, \\frac{\\alpha}{\\beta}, \\quad s^2 = c \\, \\frac{\\alpha}{\\beta} + c^2 \\, \\frac{\\alpha}{\\beta^2}.\n$$\nSubtracting gives \n$$\ns^2 - m = c^2 \\, \\frac{\\alpha}{\\beta^2}.\n$$\nSolving produces\n$$\n\\hat{\\alpha} = \\frac{m^2}{s^2 - m}, \\quad \\hat{\\beta} = c \\, \\frac{\\hat{\\alpha}}{m},\n$$\nassuming $s^2 > m$. The boundary case $s^2 \\le m$ indicates at most Poisson variability without extra-Poisson dispersion; in that situation, we enforce $\\hat{\\alpha}$ large (e.g., $\\hat{\\alpha} = 10^6$), and set $\\hat{\\beta} = c \\, \\hat{\\alpha} / m$ to maintain $\\mathbb{E}[x_i] = m$ (if $m = 0$, use $\\hat{\\alpha} = 10^{-6}$, $\\hat{\\beta} = 10^{-6}$ to avoid division by zero). This regularization enforces strong shrinkage toward the sample mean where appropriate.\n\nWith $(\\hat{\\alpha}, \\hat{\\beta})$ obtained, the conjugate posterior for each $b_i$ is\n$$\nb_i \\mid x_i \\sim \\text{Gamma}(\\hat{\\alpha} + x_i, \\hat{\\beta} + c),\n$$\nwith posterior mean\n$$\n\\hat{b}_i^{\\text{hier}} = \\frac{\\hat{\\alpha} + x_i}{\\hat{\\beta} + c}.\n$$\nFor comparison, the per-cell maximum likelihood estimate (MLE) under the conditional Poisson likelihood is\n$$\n\\hat{b}_i^{\\text{MLE}} = \\frac{x_i}{c}.\n$$\nThe hierarchical posterior shrinkage difference for cell $i$ is then\n$$\ns_i = \\hat{b}_i^{\\text{hier}} - \\hat{b}_i^{\\text{MLE}},\n$$\nmeasured in mRNA molecules per burst, which quantifies the effect of shrinkage (movement from the MLE to the hierarchical posterior mean) for each cell. Averaging across cells yields\n$$\n\\overline{s} = \\frac{1}{N} \\sum_{i=1}^N s_i,\n$$\nalso in mRNA molecules per burst.\n\nFor the pooled analysis, we assume all cells share a single burst size parameter $b_{\\text{pool}}$ with prior $b_{\\text{pool}} \\sim \\text{Gamma}(\\alpha_0, \\beta_0)$ and likelihood comprising the product of cell-wise Poisson likelihoods. By conjugacy,\n$$\nb_{\\text{pool}} \\mid x_{1:N} \\sim \\text{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^N x_i,\\, \\beta_0 + N c \\right),\n$$\nso the pooled posterior mean is\n$$\n\\hat{b}^{\\text{pool}} = \\frac{\\alpha_0 + \\sum_{i=1}^N x_i}{\\beta_0 + N c}.\n$$\nThe pooled impact difference for cell $i$ is\n$$\nd_i = \\hat{b}^{\\text{pool}} - \\hat{b}_i^{\\text{hier}},\n$$\nwith the average absolute impact across cells\n$$\n\\overline{|d|} = \\frac{1}{N} \\sum_{i=1}^N |d_i|,\n$$\nwhich is also in mRNA molecules per burst. Finally, to compare pooled to hierarchical scaling, compute the ratio\n$$\nR = \\frac{\\hat{b}^{\\text{pool}}}{\\frac{1}{N} \\sum_{i=1}^N \\hat{b}_i^{\\text{hier}}},\n$$\nwhich is dimensionless; note that when hierarchical hyperparameters are set via empirical Bayes, the average hierarchical posterior mean often tracks the sample mean scaled by $c$, whereas the pooled posterior mean incorporates the pooled prior $\\text{Gamma}(\\alpha_0,\\beta_0)$ and exposure $N c$, which can introduce differences reflected in $R$.\n\nAlgorithmic steps for each test case are thus:\n1. Compute $c = f \\, \\Delta t$.\n2. Compute $m$ and $s^2$ from the observed list of $x_i$ using population variance.\n3. Estimate $(\\hat{\\alpha}, \\hat{\\beta})$ via method of moments, applying boundary regularization when $s^2 \\le m$ or $m = 0$.\n4. For each cell, compute $\\hat{b}_i^{\\text{hier}} = (\\hat{\\alpha} + x_i)/(\\hat{\\beta} + c)$ and $\\hat{b}_i^{\\text{MLE}} = x_i/c$, then compute $s_i = \\hat{b}_i^{\\text{hier}} - \\hat{b}_i^{\\text{MLE}}$.\n5. Compute $\\overline{s}$ by averaging $s_i$.\n6. Compute pooled posterior mean $\\hat{b}^{\\text{pool}} = (\\alpha_0 + \\sum x_i)/(\\beta_0 + N c)$.\n7. Compute $d_i = \\hat{b}^{\\text{pool}} - \\hat{b}_i^{\\text{hier}}$, then $\\overline{|d|} = \\frac{1}{N} \\sum |d_i|$.\n8. Compute $R = \\hat{b}^{\\text{pool}} / \\left(\\frac{1}{N} \\sum \\hat{b}_i^{\\text{hier}}\\right)$.\n9. Round $\\overline{s}$, $\\overline{|d|}$, and $R$ to six decimal places.\n10. Output a single line containing the flattened list $[\\overline{s}_1,\\overline{|d|}_1,R_1,\\overline{s}_2,\\overline{|d|}_2,R_2,\\overline{s}_3,\\overline{|d|}_3,R_3,\\overline{s}_4,\\overline{|d|}_4,R_4]$.\n\nThis approach embodies principle-based reasoning: it begins from the conditional Poisson model for bursty production, uses the law of total expectation and variance for the Poisson-Gamma mixture (widely tested in single-cell analysis), leverages conjugacy for analytical tractability, and employs empirical Bayes via method-of-moments to estimate hyperparameters from data. The boundary handling ensures scientific realism when the data do not exhibit over-dispersion beyond Poisson noise. The computed metrics characterize shrinkage and pooled impact in a quantifiable manner and are expressed in appropriate units (mRNA molecules per burst) for differences, and as a dimensionless ratio for $R$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef empirical_bayes_hyperparams(counts, c, large_alpha=1e6):\n    \"\"\"\n    Estimate Gamma(shape=alpha, rate=beta) hyperparameters for burst size b_i\n    from Poisson-Gamma mixture moments, handling boundary cases.\n    \"\"\"\n    x = np.array(counts, dtype=float)\n    N = x.size\n    m = x.mean()\n    # Population (non-unbiased) variance\n    s2 = ((x - m) ** 2).mean()\n\n    if m == 0.0:\n        # Degenerate case: no counts observed\n        alpha_hat = 1e-6\n        beta_hat = 1e-6\n        return alpha_hat, beta_hat\n\n    if s2 > m:\n        alpha_hat = (m ** 2) / (s2 - m)\n        beta_hat = c * alpha_hat / m\n    else:\n        # No over-dispersion beyond Poisson; enforce strong shrinkage to mean\n        alpha_hat = large_alpha\n        beta_hat = c * alpha_hat / m\n\n    return alpha_hat, beta_hat\n\ndef hierarchical_post_means(counts, alpha_hat, beta_hat, c):\n    \"\"\"\n    Compute hierarchical posterior means for burst size b_i given counts.\n    Posterior: Gamma(alpha_hat + x_i, beta_hat + c), mean = (alpha_hat + x_i)/(beta_hat + c).\n    \"\"\"\n    x = np.array(counts, dtype=float)\n    denom = beta_hat + c\n    return (alpha_hat + x) / denom\n\ndef mle_burst_sizes(counts, c):\n    \"\"\"\n    Per-cell MLE for burst size under Poisson model: b_i_hat = x_i / c.\n    \"\"\"\n    x = np.array(counts, dtype=float)\n    return x / c\n\ndef pooled_posterior_mean(counts, alpha0, beta0, c):\n    \"\"\"\n    Pooled posterior mean for single burst size parameter across all cells:\n    Gamma(alpha0 + sum x_i, beta0 + N*c), mean = (alpha0 + sum x_i)/(beta0 + N*c).\n    \"\"\"\n    x = np.array(counts, dtype=float)\n    N = x.size\n    return (alpha0 + x.sum()) / (beta0 + N * c)\n\ndef summarize_metrics(counts, f, dt, alpha0, beta0):\n    \"\"\"\n    For a single test case, compute:\n    - average hierarchical shrinkage difference: mean(hier_mean - mle)\n    - average absolute pooled impact difference: mean(abs(pool_mean - hier_mean))\n    - ratio R: pool_mean / mean(hier_mean)\n    All bursts differences are in mRNA molecules per burst. Ratio is dimensionless.\n    \"\"\"\n    c = f * dt\n    alpha_hat, beta_hat = empirical_bayes_hyperparams(counts, c)\n    hier_means = hierarchical_post_means(counts, alpha_hat, beta_hat, c)\n    mle_means = mle_burst_sizes(counts, c)\n    shrink_diff = hier_means - mle_means\n    avg_shrink = float(shrink_diff.mean())\n\n    pool_mean = pooled_posterior_mean(counts, alpha0, beta0, c)\n    pooled_impact = pool_mean - hier_means\n    avg_abs_pooled_impact = float(np.mean(np.abs(pooled_impact)))\n\n    avg_hier_mean = float(hier_means.mean())\n    # Guard against division by zero in ratio\n    if avg_hier_mean == 0.0:\n        R = float('inf') if pool_mean > 0 else 1.0\n    else:\n        R = pool_mean / avg_hier_mean\n\n    # Round to six decimals as specified\n    return (round(avg_shrink, 6), round(avg_abs_pooled_impact, 6), round(R, 6))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"counts\": [3, 0, 1, 5, 2, 4, 6, 1, 0, 3],\n            \"f\": 0.5, \"dt\": 2.0,\n            \"alpha0\": 1.0, \"beta0\": 1.0\n        },\n        # Test case 2\n        {\n            \"counts\": [0, 0, 0, 1, 2, 0, 3, 0],\n            \"f\": 1.0, \"dt\": 1.0,\n            \"alpha0\": 0.5, \"beta0\": 0.5\n        },\n        # Test case 3\n        {\n            \"counts\": [10, 15, 12, 8, 20, 5, 18, 11, 7, 9, 14, 16],\n            \"f\": 2.0, \"dt\": 3.0,\n            \"alpha0\": 1.0, \"beta0\": 0.1\n        },\n        # Test case 4\n        {\n            \"counts\": [2, 9, 1],\n            \"f\": 0.2, \"dt\": 5.0,\n            \"alpha0\": 2.0, \"beta0\": 2.0\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        counts = case[\"counts\"]\n        f = case[\"f\"]\n        dt = case[\"dt\"]\n        alpha0 = case[\"alpha0\"]\n        beta0 = case[\"beta0\"]\n        avg_shrink, avg_abs_pooled_impact, R = summarize_metrics(counts, f, dt, alpha0, beta0)\n        # Append the three metrics per test case\n        results.extend([f\"{avg_shrink:.6f}\", f\"{avg_abs_pooled_impact:.6f}\", f\"{R:.6f}\"])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}