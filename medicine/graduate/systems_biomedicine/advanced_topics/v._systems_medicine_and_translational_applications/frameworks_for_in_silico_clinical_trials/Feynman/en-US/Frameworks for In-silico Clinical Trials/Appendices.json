{
    "hands_on_practices": [
        {
            "introduction": "Before embarking on a complex parameter estimation for a virtual patient, we must ask a fundamental question: can the parameters of our model even be uniquely determined from the data we plan to collect? This problem of 'identifiability' is critical, as a non-identifiable model can have multiple different parameter sets that produce the exact same output, a phenomenon known as equifinality. This exercise  challenges you to explore this concept using a simple pharmacokinetic model, forcing you to reason about how the choice of measurement directly impacts what can be learned and how to redesign an experiment to resolve ambiguity.",
            "id": "4343782",
            "problem": "Consider an in-silico clinical trial framework in systems biomedicine using a standard one-compartment intravenous bolus pharmacokinetic/pharmacodynamic (PK/PD) model. The pharmacokinetic mass-balance is given by conservation of mass: the amount of drug in the body, $A(t)$, obeys $\\frac{dA(t)}{dt} = - CL \\, C(t)$, with $A(t) = V \\, C(t)$, where $CL$ is clearance, $V$ is apparent volume of distribution, and $C(t)$ is plasma concentration. A known bolus dose $D$ is administered at $t=0$, so $A(0) = D$ and $C(0) = D/V$. The clinical assay used in this trial yields only a normalized concentration time course $B(t) = \\frac{C(t)}{C(0)}$ at sampling times $t \\in \\{1,2,4\\}$ hours, due to calibration constraints that preclude absolute quantification. No other measurements are collected in the baseline protocol.\n\nTwo virtual patients are simulated:\n- Patient $1$: $(CL_1, V_1) = (0.5 \\,\\text{L/h}, 10 \\,\\text{L})$.\n- Patient $2$: $(CL_2, V_2) = (1.0 \\,\\text{L/h}, 20 \\,\\text{L})$.\n\nYou are asked to reason from first principles (mass conservation and the definitions above) to evaluate equifinality: the phenomenon where distinct parameter sets yield indistinguishable outputs under the chosen measurement and protocol. Then, propose experimental design modifications that would break this equivalence.\n\nSelect all statements that are correct.\n\nA. Under the baseline protocol that records only $B(t)$ at $t \\in \\{1,2,4\\}$ hours, Patient $1$ and Patient $2$ produce identical $B(t)$ trajectories for all $t \\ge 0$.\n\nB. Augmenting the baseline protocol with a single absolute plasma concentration measurement at $t=0$ (that is, observing $C(0)$ in addition to $B(t)$) suffices to uniquely recover $V$ and then $CL$ for a bolus dose, thereby breaking the equivalence between Patient $1$ and Patient $2$.\n\nC. Replacing the bolus by a constant-rate intravenous infusion with known input rate $R_{\\text{in}}$ and sampling absolute concentration during the rising phase and after infusion cessation allows separate identification of $V$ (from the initial slope) and $CL$ (from the terminal slope), thus breaking the equivalence.\n\nD. Adding more post-dose sampling times for $B(t)$ (without any absolute concentration measurements) will break the equivalence by better resolving the curvature of $B(t)$.\n\nE. Administering two different bolus doses but continuing to record only $B(t)$ will break the equivalence because $B(t)$ depends on dose, so comparing responses across doses identifies $V$ and $CL$ separately.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It describes a classic structural identifiability problem in pharmacokinetics. I will proceed with the solution.\n\nFirst, we derive the mathematical expression for the measured output, $B(t)$, from the given first principles. The model is defined by two equations:\n$1.$ The mass balance for the amount of drug in the body, $A(t)$: $\\frac{dA(t)}{dt} = -CL \\cdot C(t)$.\n$2.$ The relationship between amount and concentration, $C(t)$: $A(t) = V \\cdot C(t)$.\n\nHere, $CL$ is the clearance and $V$ is the apparent volume of distribution. We can combine these two equations. By differentiating the second equation with respect to time $t$, we get $\\frac{dA(t)}{dt} = V \\frac{dC(t)}{dt}$. Equating this with the first equation gives:\n$$V \\frac{dC(t)}{dt} = -CL \\cdot C(t)$$\n$$\\frac{dC(t)}{dt} = -\\frac{CL}{V} C(t)$$\nLet's define the elimination rate constant $k_e = \\frac{CL}{V}$. The differential equation simplifies to $\\frac{dC(t)}{dt} = -k_e C(t)$.\nThis is a first-order linear ordinary differential equation. Its solution is an exponential decay function:\n$$C(t) = C(0) e^{-k_e t} = C(0) e^{-(CL/V)t}$$\nThe problem states that a bolus dose $D$ is administered at $t=0$, so $A(0)=D$. From $A(t)=VC(t)$, we have $C(0) = D/V$.\nThe measured output is the normalized concentration time course, $B(t)$:\n$$B(t) = \\frac{C(t)}{C(0)} = \\frac{C(0) e^{-(CL/V)t}}{C(0)} = e^{-(CL/V)t}$$\nThis derivation shows that under the baseline protocol, the only quantity that can be identified is the ratio $k_e = CL/V$. The individual parameters $CL$ and $V$ are not separately identifiable from measurements of $B(t)$ alone. This is known as structural non-identifiability.\n\nNow, we evaluate this for the two virtual patients:\n- Patient $1$: $(CL_1, V_1) = (0.5 \\,\\text{L/h}, 10 \\,\\text{L})$. The elimination rate constant is $k_{e1} = \\frac{CL_1}{V_1} = \\frac{0.5 \\,\\text{L/h}}{10 \\,\\text{L}} = 0.05 \\,\\text{h}^{-1}$.\n- Patient $2$: $(CL_2, V_2) = (1.0 \\,\\text{L/h}, 20 \\,\\text{L})$. The elimination rate constant is $k_{e2} = \\frac{CL_2}{V_2} = \\frac{1.0 \\,\\text{L/h}}{20 \\,\\text{L}} = 0.05 \\,\\text{h}^{-1}$.\n\nSince $k_{e1} = k_{e2}$, the observable output is identical for both patients for all time $t \\ge 0$:\n$$B_1(t) = e^{-0.05t} \\quad \\text{and} \\quad B_2(t) = e^{-0.05t}$$\nThis confirms the equifinality: the distinct parameter sets $(CL_1, V_1)$ and $(CL_2, V_2)$ produce indistinguishable outputs under the specified measurement protocol.\n\nNow, we evaluate each statement.\n\n**A. Under the baseline protocol that records only $B(t)$ at $t \\in \\{1,2,4\\}$ hours, Patient $1$ and Patient $2$ produce identical $B(t)$ trajectories for all $t \\ge 0$.**\n\nAs demonstrated above, the function $B(t)$ depends only on the ratio $CL/V$. For both patients, this ratio is $0.05 \\,\\text{h}^{-1}$. Therefore, their normalized concentration profiles $B(t)$ are not just identical at the sampling times $t \\in \\{1,2,4\\}$, but are described by the exact same mathematical function $B(t) = e^{-0.05t}$ for all $t \\ge 0$.\n**Verdict: Correct.**\n\n**B. Augmenting the baseline protocol with a single absolute plasma concentration measurement at $t=0$ (that is, observing $C(0)$ in addition to $B(t)$) suffices to uniquely recover $V$ and then $CL$ for a bolus dose, thereby breaking the equivalence between Patient $1$ and Patient $2$.**\n\nAn augmented protocol provides two pieces of information:\n$1$. The time course of $B(t)$, which allows for the determination of $k_e = CL/V$. From Part A, we know $k_e = 0.05 \\,\\text{h}^{-1}$ for both patients.\n$2$. A measurement of the absolute concentration $C(0)$.\nThe initial concentration is defined as $C(0) = D/V$. The dose $D$ is known. Therefore, if $C(0)$ is measured, we can directly calculate the volume of distribution:\n$$V = \\frac{D}{C(0)}$$\nOnce $V$ is determined, we can use the value of $k_e$ obtained from $B(t)$ to find the clearance:\n$$CL = k_e \\cdot V$$\nFor the two patients, assuming a known dose $D$, their initial concentrations would be different: $C_1(0) = D/V_1 = D/10$ and $C_2(0) = D/V_2 = D/20$. Since $C_1(0) \\ne C_2(0)$, measuring $C(0)$ would immediately distinguish the two patients and allow for the unique determination of their respective $(V_1, CL_1)$ and $(V_2, CL_2)$ parameter sets. This breaks the equivalence.\n**Verdict: Correct.**\n\n**C. Replacing the bolus by a constant-rate intravenous infusion with known input rate $R_{\\text{in}}$ and sampling absolute concentration during the rising phase and after infusion cessation allows separate identification of $V$ (from the initial slope) and $CL$ (from the terminal slope), thus breaking the equivalence.**\n\nFor a constant-rate IV infusion starting at $t=0$ with $C(0)=0$, the mass-balance equation is $\\frac{dA(t)}{dt} = R_{\\text{in}} - CL \\cdot C(t)$. Substituting $A(t) = VC(t)$, we get:\n$$V \\frac{dC(t)}{dt} = R_{\\text{in}} - CL \\cdot C(t) \\implies \\frac{dC(t)}{dt} = \\frac{R_{\\text{in}}}{V} - \\frac{CL}{V} C(t)$$\nAt the very beginning of the infusion ($t \\to 0^+$), $C(t)$ is close to $0$, so the equation approximates to $\\frac{dC(t)}{dt} \\approx \\frac{R_{\\text{in}}}{V}$. The initial slope of the concentration curve is directly proportional to $1/V$. By measuring this initial slope and knowing $R_{\\text{in}}$, one can determine $V$.\nAfter the infusion is stopped at some time $T$, for $t > T$, $R_{\\text{in}}=0$ and the equation reverts to $\\frac{dC(t)}{dt} = -\\frac{CL}{V} C(t)$. The slope of $\\ln(C(t))$ versus $t$ in this terminal phase is $-CL/V$. So, this \"terminal slope\" allows determination of the ratio $k_e = CL/V$.\nWith $V$ identified from the initial phase and $CL/V$ identified from the terminal phase, $CL$ can be calculated as $CL = (CL/V) \\cdot V$. This experimental design allows for the separate identification of $V$ and $CL$.\nPatient $1$ ($V_1 = 10 \\,\\text{L}$) and Patient $2$ ($V_2 = 20 \\,\\text{L}$) would have different initial slopes, breaking the equivalence.\n**Verdict: Correct.**\n\n**D. Adding more post-dose sampling times for $B(t)$ (without any absolute concentration measurements) will break the equivalence by better resolving the curvature of $B(t)$.**\n\nAs shown in the initial analysis, the reason for the equifinality is that the observable function $B(t)=e^{-(CL/V)t}$ is structurally dependent only on the ratio $CL/V$. For both patients, this function is $B(t) = e^{-0.05t}$. The two patients generate mathematically identical output functions. Adding more sampling points, no matter how many or where, will only provide more points on this same curve. While more data can improve the precision of the estimate for the parameter $k_e=CL/V$, it cannot provide any information to distinguish $CL$ and $V$ individually. The \"curvature\" of the exponential decay is determined solely by $k_e$, which is identical for both patients. This is a structural identifiability problem, not a practical one solvable with more data of the same kind.\n**Verdict: Incorrect.**\n\n**E. Administering two different bolus doses but continuing to record only $B(t)$ will break the equivalence because $B(t)$ depends on dose, so comparing responses across doses identifies $V$ and $CL$ separately.**\n\nThe premise of this statement is false. As derived earlier, the observable is $B(t) = C(t)/C(0)$. The concentration at any time $t$ is $C(t) = (D/V)e^{-(CL/V)t}$, and the initial concentration is $C(0) = D/V$. Both $C(t)$ and $C(0)$ are directly proportional to the dose $D$. In their ratio, the dose $D$ cancels out:\n$$B(t) = \\frac{(D/V)e^{-(CL/V)t}}{D/V} = e^{-(CL/V)t}$$\nThe normalized concentration $B(t)$ is independent of the dose $D$. Administering different doses will produce the exact same $B(t)$ curve for a given patient. This experiment provides no new information to break the equifinality.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{ABC}$$"
        },
        {
            "introduction": "Once we establish that a model's parameters are identifiable, the next logical question is how *precisely* we can estimate them. The quality of our parameter estimates is not accidental; it is a direct consequence of the experimental design. This practice  introduces a cornerstone of optimal experimental design: the Fisher Information Matrix ($F$). By deriving and computing the $F$, you will learn how to quantify the maximum possible precision for parameter estimates and understand how factors like sampling times contribute to the information content of a virtual experiment.",
            "id": "4343747",
            "problem": "In the context of designing an in-silico clinical trial for a pharmacokinetic (PK) parameter estimation study, consider a single-compartment intravenous bolus model for plasma concentration with additive independent Gaussian measurement noise. The model for concentration is given by\n$$\nC(t;\\theta) \\;=\\; \\frac{D}{V} \\exp\\!\\left(-\\frac{CL}{V}\\,t\\right),\n$$\nwhere $D$ is the administered dose, $CL$ is the clearance, $V$ is the volume of distribution, and $\\theta = (CL, V)^{\\top}$. Measurements $y_i$ at sampling times $t_i$ follow\n$$\ny_i \\;=\\; C(t_i;\\theta) + \\varepsilon_i,\\quad \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2),\\quad \\text{independent across } i.\n$$\nStart from the definition of the likelihood for independent Gaussian errors and the definition of the Fisher Information Matrix (FIM) as the expected negative Hessian of the log-likelihood (equivalently, the expected outer product of the score). Derive the FIM for $\\theta$ in terms of the model sensitivities with respect to $CL$ and $V$. Then specialize to the above PK model, and analytically derive the sensitivities $\\partial C/\\partial CL$ and $\\partial C/\\partial V$.\n\nUse the resulting expressions to compute the FIM at the following nominal design and parameter values representative of a virtual patient in an in-silico trial:\n- Dose $D = 100$ mg,\n- Nominal clearance $CL = 5$ L/h,\n- Nominal volume $V = 50$ L,\n- Sampling times $t \\in \\{0.5, 1, 2, 4, 8, 12\\}$ hours,\n- Known noise standard deviation $\\sigma = 0.05$ mg/L.\n\nUsing the Cramér–Rao lower bound (CRLB), approximate the lower bound on the standard deviation of the maximum likelihood estimator of $CL$ under this design. Express your final answer in L/h, and round your answer to four significant figures. Your final answer must be a single real number.",
            "solution": "The user wants to solve a problem related to pharmacokinetic modeling and experimental design using the Fisher Information Matrix (FIM).\n\nHere's my plan:\n1.  **Validate the Problem:** I will first verify that the problem is scientifically sound, well-posed, and complete. This involves checking the model, parameters, and experimental setup for consistency and realism.\n2.  **Derive the Fisher Information Matrix:** I will start from the likelihood function for independent Gaussian noise and derive the general form of the FIM in terms of model sensitivities.\n3.  **Calculate Model Sensitivities:** I will analytically compute the partial derivatives of the given pharmacokinetic model with respect to the parameters $CL$ and $V$.\n4.  **Compute the FIM Numerically:** Using the provided parameter values and sampling times, I will evaluate the sensitivities and assemble the numerical FIM.\n5.  **Apply the Cramér-Rao Lower Bound (CRLB):** I will invert the FIM to find the CRLB for the variance of the $CL$ estimator, then take the square root to find the lower bound on its standard deviation.\n\nThis systematic approach ensures all parts of the question are addressed logically and correctly.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   Concentration model: $C(t;\\theta) = \\frac{D}{V} \\exp\\left(-\\frac{CL}{V}\\,t\\right)$\n-   Parameter vector: $\\theta = (CL, V)^{\\top}$\n-   Measurement model: $y_i = C(t_i;\\theta) + \\varepsilon_i$\n-   Noise distribution: $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$, independent for each measurement $i$.\n-   Dose: $D = 100$ mg\n-   Nominal clearance: $CL = 5$ L/h\n-   Nominal volume of distribution: $V = 50$ L\n-   Sampling times: $t \\in \\{0.5, 1, 2, 4, 8, 12\\}$ hours\n-   Noise standard deviation: $\\sigma = 0.05$ mg/L\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem uses a standard single-compartment intravenous bolus pharmacokinetic model. The assumption of additive, independent, and identically distributed Gaussian noise is a common and valid starting point for many regression problems in pharmacology. The Fisher Information Matrix and the Cramér-Rao Lower Bound are fundamental, well-established concepts in statistical estimation theory and are standard tools for optimal experimental design.\n-   **Well-Posed:** The problem is clearly stated, providing a specific model, parameter values, and a set of discrete tasks (derivation and computation). All necessary information is provided to arrive at a unique numerical answer.\n-   **Objective:** The problem is described using precise, objective mathematical and scientific language. There are no subjective or ambiguous statements.\n-   **Consistency and Feasibility:** The units are consistent (mg, L, h). The argument of the exponential, $(CL/V)t$, is dimensionless as required: $(\\text{L}/\\text{h}) / \\text{L} \\times \\text{h}$. The model and parameters are physically realistic for a drug in a human subject.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a standard and well-posed problem in pharmacokinetic/pharmacodynamic (PK/PD) modeling and optimal design. I will proceed with the full solution.\n\n### Derivation and Solution\n\n**1. General Fisher Information Matrix for Additive Gaussian Noise**\n\nThe likelihood function for a set of $N$ independent measurements $y = \\{y_1, y_2, \\ldots, y_N\\}$ is the product of the probability density functions (PDFs) for each measurement. Given that $y_i \\sim \\mathcal{N}(C(t_i;\\theta), \\sigma^2)$, the PDF for a single measurement $y_i$ is:\n$$\np(y_i|\\theta) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(y_i - C(t_i;\\theta))^2}{2\\sigma^2} \\right)\n$$\nThe log-likelihood, $\\ell(\\theta; y) = \\ln(\\prod_{i=1}^N p(y_i|\\theta))$, is the sum of the individual log-PDFs:\n$$\n\\ell(\\theta; y) = \\sum_{i=1}^N \\left( -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(y_i - C(t_i;\\theta))^2}{2\\sigma^2} \\right)\n$$\nThe Fisher Information Matrix (FIM), $F$, is defined as the negative expectation of the Hessian of the log-likelihood. The entry $(j,k)$ of the FIM is $F_{jk} = -E\\left[\\frac{\\partial^2 \\ell}{\\partial\\theta_j \\partial\\theta_k}\\right]$.\n\nFirst, we find the first partial derivative (the score vector component):\n$$\n\\frac{\\partial\\ell}{\\partial\\theta_j} = \\sum_{i=1}^N \\frac{\\partial}{\\partial\\theta_j} \\left(-\\frac{(y_i - C_i)^2}{2\\sigma^2}\\right) = \\sum_{i=1}^N \\frac{y_i - C_i}{\\sigma^2} \\frac{\\partial C_i}{\\partial\\theta_j}\n$$\nwhere $C_i = C(t_i;\\theta)$.\n\nNext, we find the second partial derivative:\n$$\n\\frac{\\partial^2\\ell}{\\partial\\theta_j \\partial\\theta_k} = \\frac{\\partial}{\\partial\\theta_k} \\left( \\sum_{i=1}^N \\frac{y_i - C_i}{\\sigma^2} \\frac{\\partial C_i}{\\partial\\theta_j} \\right) = \\sum_{i=1}^N \\frac{1}{\\sigma^2} \\left[ -\\frac{\\partial C_i}{\\partial\\theta_k} \\frac{\\partial C_i}{\\partial\\theta_j} + (y_i - C_i) \\frac{\\partial^2 C_i}{\\partial\\theta_j \\partial\\theta_k} \\right]\n$$\nTaking the expectation, we use the fact that $E[y_i - C_i] = E[\\varepsilon_i] = 0$:\n$$\nE\\left[\\frac{\\partial^2\\ell}{\\partial\\theta_j \\partial\\theta_k}\\right] = \\sum_{i=1}^N \\frac{1}{\\sigma^2} \\left[ -\\frac{\\partial C_i}{\\partial\\theta_k} \\frac{\\partial C_i}{\\partial\\theta_j} + E[y_i - C_i] \\frac{\\partial^2 C_i}{\\partial\\theta_j \\partial\\theta_k} \\right] = -\\frac{1}{\\sigma^2} \\sum_{i=1}^N \\frac{\\partial C_i}{\\partial\\theta_j} \\frac{\\partial C_i}{\\partial\\theta_k}\n$$\nThe FIM element is then:\n$$\nF_{jk} = -E\\left[\\frac{\\partial^2\\ell}{\\partial\\theta_j \\partial\\theta_k}\\right] = \\frac{1}{\\sigma^2} \\sum_{i=1}^N \\frac{\\partial C_i}{\\partial\\theta_j} \\frac{\\partial C_i}{\\partial\\theta_k}\n$$\nThis can be written in matrix form. Let $S(t_i) = \\nabla_\\theta C(t_i;\\theta)$ be the sensitivity vector of the model output with respect to the parameters at time $t_i$. Then the FIM is:\n$$\nF = \\frac{1}{\\sigma^2} \\sum_{i=1}^N S(t_i) S(t_i)^\\top\n$$\n\n**2. Derivation of Model Sensitivities**\n\nThe parameter vector is $\\theta = (CL, V)^{\\top}$. The model is $C(t; CL, V) = \\frac{D}{V} \\exp\\left(-\\frac{CL}{V}t\\right)$.\n\nSensitivity with respect to $CL$:\n$$\n\\frac{\\partial C}{\\partial CL} = \\frac{\\partial}{\\partial CL} \\left[ \\frac{D}{V} \\exp\\left(-\\frac{CL}{V}t\\right) \\right] = \\frac{D}{V} \\exp\\left(-\\frac{CL}{V}t\\right) \\cdot \\left(-\\frac{t}{V}\\right) = -\\frac{Dt}{V^2} \\exp\\left(-\\frac{CL}{V}t\\right)\n$$\n\nSensitivity with respect to $V$: We use the product rule for $f(V)g(V)$ where $f(V) = D/V$ and $g(V) = \\exp(-CL \\cdot t/V)$.\n$$\n\\frac{\\partial C}{\\partial V} = \\frac{\\partial}{\\partial V}\\left(\\frac{D}{V}\\right) \\exp\\left(-\\frac{CL}{V}t\\right) + \\frac{D}{V} \\frac{\\partial}{\\partial V}\\left(\\exp\\left(-\\frac{CL}{V}t\\right)\\right)\n$$\n$$\n\\frac{\\partial C}{\\partial V} = \\left(-\\frac{D}{V^2}\\right) \\exp\\left(-\\frac{CL}{V}t\\right) + \\frac{D}{V} \\exp\\left(-\\frac{CL}{V}t\\right) \\cdot \\left(-\\frac{CLt}{-V^2}\\right)\n$$\n$$\n\\frac{\\partial C}{\\partial V} = -\\frac{D}{V^2} \\exp\\left(-\\frac{CL}{V}t\\right) + \\frac{D \\cdot CL \\cdot t}{V^3} \\exp\\left(-\\frac{CL}{V}t\\right)\n$$\nFactoring out common terms:\n$$\n\\frac{\\partial C}{\\partial V} = \\frac{D}{V^2} \\exp\\left(-\\frac{CL}{V}t\\right) \\left(\\frac{CLt}{V} - 1\\right)\n$$\n\n**3. Numerical Computation of the FIM**\n\nWe are given the values: $D=100$, $CL=5$, $V=50$, $\\sigma=0.05$, and sampling times $t_i \\in \\{0.5, 1, 2, 4, 8, 12\\}$.\nFirst, calculate the constants:\n-   $CL/V = 5/50 = 0.1$ h$^{-1}$\n-   $D/V^2 = 100/50^2 = 100/2500 = 0.04$\n-   $1/\\sigma^2 = 1/(0.05^2) = 1/0.0025 = 400$\n\nLet $S_1(t) = \\partial C/\\partial CL$ and $S_2(t) = \\partial C/\\partial V$. The sensitivity expressions become:\n-   $S_1(t) = -0.04 \\cdot t \\cdot \\exp(-0.1 t)$\n-   $S_2(t) = 0.04 \\cdot \\exp(-0.1 t) \\cdot (0.1 t - 1)$\n\nWe compute the values of $S_1(t_i)$, $S_2(t_i)$, and their products for each sampling time $t_i$:\n\n| $t_i$ (h) | $S_1(t_i)$       | $S_2(t_i)$       | $S_1(t_i)^2$     | $S_2(t_i)^2$     | $S_1(t_i)S_2(t_i)$ |\n|-----------|------------------|------------------|------------------|------------------|--------------------|\n| $0.5$     | $-0.019025$      | $-0.036147$      | $0.0003619$      | $0.0013066$      | $0.0006877$        |\n| $1.0$     | $-0.036193$      | $-0.032574$      | $0.0013100$      | $0.0010611$      | $0.0011790$        |\n| $2.0$     | $-0.065498$      | $-0.026199$      | $0.0042900$      | $0.0006864$      | $0.0017160$        |\n| $4.0$     | $-0.107251$      | $-0.016088$      | $0.0115028$      | $0.0002588$      | $0.0017255$        |\n| $8.0$     | $-0.143785$      | $-0.003595$      | $0.0206734$      | $0.0000129$      | $0.0005169$        |\n| $12.0$    | $-0.144573$      | $+0.002410$      | $0.0208994$      | $0.0000058$      | $-0.0003484$       |\n| **Sum**   |                  |                  | $\\mathbf{0.0590375}$ | $\\mathbf{0.0033316}$ | $\\mathbf{0.0054767}$ |\n\nThe sum of outer products is $\\sum_{i=1}^6 S(t_i)S(t_i)^{\\top} = \\begin{pmatrix} 0.0590375 & 0.0054767 \\\\ 0.0054767 & 0.0033316 \\end{pmatrix}$.\nThe FIM is this matrix multiplied by $1/\\sigma^2=400$:\n$$\nF = 400 \\begin{pmatrix} 0.0590375 & 0.0054767 \\\\ 0.0054767 & 0.0033316 \\end{pmatrix} = \\begin{pmatrix} 23.615 & 2.19068 \\\\ 2.19068 & 1.33264 \\end{pmatrix}\n$$\n\n**4. Cramér-Rao Lower Bound (CRLB) for the Standard Deviation of CL**\n\nThe CRLB states that the covariance matrix of any unbiased estimator $\\hat{\\theta}$ is bounded below by the inverse of the FIM, i.e., $\\text{Cov}(\\hat{\\theta}) \\ge F^{-1}$. The variance of the estimator for $CL$ is therefore bounded by the first diagonal element of $F^{-1}$:\n$$\n\\text{Var}(\\widehat{CL}) \\ge (F^{-1})_{11}\n$$\nFor a $2 \\times 2$ matrix $M = \\begin{pmatrix} a & b \\\\ b & d \\end{pmatrix}$, its inverse is $M^{-1} = \\frac{1}{ad-b^2} \\begin{pmatrix} d & -b \\\\ -b & a \\end{pmatrix}$.\nThe $(1,1)$ element of $F^{-1}$ is $\\frac{d}{ad-b^2}$, where $a = F_{11}$, $b=F_{12}$, and $d=F_{22}$.\nLet's compute the determinant of $F$:\n$$\n\\det(F) = (23.615)(1.33264) - (2.19068)^2 = 31.4728 - 4.79908 = 26.67372\n$$\nNow, we find $(F^{-1})_{11}$:\n$$\n(F^{-1})_{11} = \\frac{1.33264}{26.67372} \\approx 0.049959\n$$\nThis is the lower bound on the variance of $\\widehat{CL}$. The lower bound on the standard deviation is its square root:\n$$\n\\text{SD}(\\widehat{CL}) \\ge \\sqrt{0.049959} \\approx 0.2235148\n$$\nRounding to four significant figures, the lower bound on the standard deviation of the maximum likelihood estimator of $CL$ is $0.2235$ L/h.",
            "answer": "$$\n\\boxed{0.2235}\n$$"
        },
        {
            "introduction": "The ultimate purpose of an in-silico clinical trial is to serve as a computational sandbox for estimating the causal effects of interventions. This moves beyond simple prediction to answering counterfactual 'what if' questions, such as what would be the average outcome if every patient received a specific treatment policy. This final practice  bridges the gap between mechanistic modeling and formal causal inference. You will derive and implement the g-computation formula, a powerful tool for using a structural model of the world to estimate the potential outcomes of static and dynamic treatment strategies, a key deliverable of any decision-making framework.",
            "id": "4343764",
            "problem": "You are asked to build a principled computational estimator for average treatment effects using the g-computation approach within the setting of In-Silico Clinical Trials (ISCT). Start from the potential outcomes framework and formal identifiability assumptions, and derive a computable expression for the average potential outcome under specified interventions. Then implement the resulting estimator as a complete, runnable program that evaluates a defined test suite.\n\nThe setting is as follows. Let $L$ be a baseline covariate, $A \\in \\{0,1\\}$ be a binary treatment, and $Y$ be a scalar outcome. The potential outcome $Y^a$ denotes the outcome that would be observed under treatment level $A=a$. Assume a Structural Causal Model (SCM) with the following outcome structural equation:\n$$\nY \\;=\\; \\beta_0 + \\beta_1 A + \\beta_2 L + \\beta_3 A L + \\beta_4 L^2 + \\epsilon,\n$$\nwhere $\\epsilon \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2)$, independent of $L$ and independent of $A$ conditional on $L$. The baseline covariate distribution is $L \\sim \\mathcal{N}(\\mu, \\sigma^2)$. You should treat $\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4,\\mu,\\sigma,\\sigma_\\epsilon$ as parameters that will be specified by the test suite below. You must not use the observational assignment mechanism of $A$ to estimate causal effects; instead, evaluate the interventional estimands using the g-computation formula derived from first principles.\n\nTasks:\n- Derive, from the fundamental definitions of potential outcomes and the standard identifiability assumptions (consistency, conditional exchangeability given $L$, and positivity), a computable formula for the average potential outcome $E[Y^a]$ under a static intervention $A=a$ for $a \\in \\{0,1\\}$.\n- Generalize the derivation to a dynamic threshold policy $d_c(L) = \\mathbb{I}\\{L>c\\}$ and obtain $E[Y^{d_c}]$ for any real threshold $c$.\n- Implement the derived formulas in a program that computes, for each parameter set in the test suite, the following quantities in the exact order listed:\n  1. $E[Y^0]$ as a float.\n  2. $E[Y^1]$ as a float.\n  3. The average treatment effect $E[Y^1] - E[Y^0]$ as a float.\n  4. $E[Y^{d_{c_1}}]$ as a float.\n  5. $E[Y^{d_{c_2}}]$ as a float.\n  6. $E[Y^{d_{c_3}}]$ as a float.\n\nAll outputs must be floats rounded to six decimal places.\n\nFundamental base to use for the derivation:\n- Potential outcomes definitions: $Y^a$ is the outcome under the intervention $A=a$.\n- Consistency: $Y = Y^A$.\n- Conditional exchangeability given $L$: $Y^a \\perp A \\mid L$ for each $a \\in \\{0,1\\}$.\n- Positivity: for all $l$ with support under $L$, $P(A=a \\mid L=l) > 0$ for each $a \\in \\{0,1\\}$.\n- Law of total expectation and standard probability calculus.\n- Properties of the Normal distribution $\\mathcal{N}(\\mu,\\sigma^2)$ and truncated moments of a Normal variable.\n\nTest suite:\nProvide results for $3$ parameter sets. Each set specifies $(\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4,\\mu,\\sigma,\\sigma_\\epsilon)$ along with three threshold values $(c_1,c_2,c_3)$ to define dynamic policies $d_{c_j}(L) = \\mathbb{I}\\{L>c_j\\}$.\n\n- Case $1$:\n  - Parameters: $(\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4,\\mu,\\sigma,\\sigma_\\epsilon) = (2.0,\\,1.2,\\,0.5,\\,0.8,\\,0.3,\\,0.5,\\,1.0,\\,1.0)$.\n  - Thresholds: $(c_1,c_2,c_3) = (0.0,\\,1.5,\\,-2.0)$.\n\n- Case $2$:\n  - Parameters: $(\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4,\\mu,\\sigma,\\sigma_\\epsilon) = (0.0,\\,0.7,\\,0.0,\\,1.5,\\,0.1,\\,-0.25,\\,0.5,\\,0.5)$.\n  - Thresholds: $(c_1,c_2,c_3) = (-1.0,\\,0.0,\\,0.5)$.\n\n- Case $3$:\n  - Parameters: $(\\beta_0,\\beta_1,\\beta_2,\\beta_3,\\beta_4,\\mu,\\sigma,\\sigma_\\epsilon) = (-1.0,\\,2.0,\\,1.0,\\,-0.4,\\,0.0,\\,1.0,\\,2.0,\\,2.0)$.\n  - Thresholds: $(c_1,c_2,c_3) = (1.0,\\,3.0,\\,-1.0)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the quantities listed above, concatenated across the $3$ cases. For example, the output must look like\n$[r_1,r_2,\\dots,r_{18}]$\nwith each $r_k$ being a float rounded to six decimal places, and no additional text before or after the brackets.",
            "solution": "The problem requires the derivation and implementation of a computational estimator for average treatment effects based on the g-computation formula within a specified Structural Causal Model (SCM).\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Variables**: Baseline covariate $L$, binary treatment $A \\in \\{0, 1\\}$, scalar outcome $Y$.\n- **Potential Outcomes**: $Y^a$ is the outcome under intervention $A=a$.\n- **Structural Causal Model (SCM)**: $Y = \\beta_0 + \\beta_1 A + \\beta_2 L + \\beta_3 A L + \\beta_4 L^2 + \\epsilon$.\n- **Distributions**:\n    - Error term: $\\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$, with $\\epsilon$ independent of $L$, and $\\epsilon$ independent of $A$ conditional on $L$.\n    - Covariate: $L \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n- **Parameters**: $\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4, \\mu, \\sigma, \\sigma_\\epsilon$.\n- **Identifiability Assumptions**:\n    - Consistency: $Y = Y^A$.\n    - Conditional Exchangeability: $Y^a \\perp A \\mid L$ for $a \\in \\{0, 1\\}$.\n    - Positivity: $P(A=a \\mid L=l) > 0$ for all $l$ in the support of $L$ and for $a \\in \\{0, 1\\}$.\n- **Dynamic Policy**: $d_c(L) = \\mathbb{I}\\{L>c\\}$, where $\\mathbb{I}\\{\\cdot\\}$ is the indicator function.\n- **Quantities to Compute**: For each test case, compute: $E[Y^0]$, $E[Y^1]$, $E[Y^1] - E[Y^0]$, $E[Y^{d_{c_1}}]$, $E[Y^{d_{c_2}}]$, $E[Y^{d_{c_3}}]$.\n- **Test Suite**: Three sets of parameters $(\\beta_0, \\dots, \\sigma_\\epsilon)$ and thresholds $(c_1, c_2, c_3)$ are provided.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is assessed based on the specified criteria:\n- **Scientifically Grounded**: The problem is firmly located within the standard frameworks of modern causal inference, specifically using Pearl's SCMs and the potential outcomes (Neyman-Rubin) model. The g-computation formula is a cornerstone of causal effect estimation. All components are scientifically sound.\n- **Well-Posed**: The problem is fully specified. The generative model for the data is given, all parameters are defined, and the target estimands are precise mathematical quantities. A unique, stable solution can be derived from the provided information.\n- **Objective**: The problem statement is formal and mathematical, free from ambiguity or subjective language.\n\nThe problem does not exhibit any flaws such as scientific unsoundness, incompleteness, contradiction, or infeasibility. The use of identifiability assumptions to derive a formula, which is then evaluated on the true SCM, is a standard and valid pedagogical approach. The task is non-trivial, requiring derivation and calculation involving moments of normal and truncated normal distributions.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A principled solution will be constructed.\n\n### Derivation of Estimands\n\nThe objective is to derive computable formulas for the average potential outcomes under different interventions.\n\n**1. Static Interventions: $E[Y^a]$**\n\nThe quantity of interest is the average potential outcome $E[Y^a]$ under a fixed treatment level $A=a$. The derivation starts from this definition and applies fundamental principles of probability and the given causal assumptions.\n\nBy the Law of Total Expectation, we can express the expectation of $Y^a$ by conditioning on the covariate $L$:\n$$E[Y^a] = E_L[E[Y^a \\mid L]]$$\nThis can be written as an integral over the distribution of $L$:\n$$E[Y^a] = \\int E[Y^a \\mid L=l] p(l) dl$$\nwhere $p(l)$ is the probability density function of $L$.\n\nThe standard identifiability assumptions allow us to connect the potential outcome $Y^a$ to the observed outcome $Y$.\n- By **conditional exchangeability** ($Y^a \\perp A \\mid L$), we can introduce the observed treatment $A$ into the conditional expectation:\n  $E[Y^a \\mid L=l] = E[Y^a \\mid L=l, A=a]$.\n- By **consistency** ($Y=Y^A$), for subjects who actually received treatment $a$ (i.e., $A=a$), their observed outcome is their potential outcome, so $Y=Y^a$. This allows us to replace the potential outcome with the observed outcome in the expectation:\n  $E[Y^a \\mid L=l, A=a] = E[Y \\mid L=l, A=a]$.\n\nCombining these steps yields the g-computation formula:\n$$E[Y^a] = E_L[E[Y \\mid L, A=a]] = \\int E[Y \\mid L=l, A=a] p(l) dl$$\n\nThe inner conditional expectation, $E[Y \\mid L=l, A=a]$, is determined by the SCM:\n$$Y = \\beta_0 + \\beta_1 A + \\beta_2 L + \\beta_3 A L + \\beta_4 L^2 + \\epsilon$$\nTaking the expectation conditional on $L=l$ and $A=a$:\n$$E[Y \\mid L=l, A=a] = E[\\beta_0 + \\beta_1 a + \\beta_2 l + \\beta_3 a l + \\beta_4 l^2 + \\epsilon \\mid L=l, A=a]$$\nDue to linearity of expectation and since $E[\\epsilon \\mid L=l, A=a] = E[\\epsilon] = 0$ (by assumption), we get:\n$$E[Y \\mid L, A=a] = \\beta_0 + \\beta_1 a + \\beta_2 L + \\beta_3 a L + \\beta_4 L^2$$\n\nNow, we compute the outer expectation over the distribution of $L \\sim \\mathcal{N}(\\mu, \\sigma^2)$:\n$$E[Y^a] = E_L[\\beta_0 + \\beta_1 a + \\beta_2 L + \\beta_3 a L + \\beta_4 L^2]$$\nUsing linearity of expectation again:\n$$E[Y^a] = \\beta_0 + \\beta_1 a + \\beta_2 E[L] + \\beta_3 a E[L] + \\beta_4 E[L^2]$$\nThe first two moments of a normal distribution $L \\sim \\mathcal{N}(\\mu, \\sigma^2)$ are $E[L]=\\mu$ and $E[L^2] = \\text{Var}(L) + (E[L])^2 = \\sigma^2 + \\mu^2$. Substituting these yields:\n$$E[Y^a] = \\beta_0 + \\beta_1 a + \\beta_2 \\mu + \\beta_3 a \\mu + \\beta_4 (\\sigma^2 + \\mu^2)$$\n\nFor $a=0$ and $a=1$:\n$$E[Y^0] = \\beta_0 + \\beta_2 \\mu + \\beta_4 (\\sigma^2 + \\mu^2)$$\n$$E[Y^1] = \\beta_0 + \\beta_1 + \\beta_2 \\mu + \\beta_3 \\mu + \\beta_4 (\\sigma^2 + \\mu^2)$$\nThe average treatment effect (ATE) is:\n$$ATE = E[Y^1] - E[Y^0] = \\beta_1 + \\beta_3 \\mu$$\n\n**2. Dynamic Policy: $E[Y^{d_c}]$**\n\nThe dynamic policy is $d_c(L) = \\mathbb{I}\\{L>c\\}$, which assigns treatment $A=1$ if $L>c$ and $A=0$ if $L \\le c$. The potential outcome under this policy is denoted $Y^{d_c(L)}$.\nBy definition, this can be written as:\n$$Y^{d_c(L)} = Y^1 \\cdot \\mathbb{I}\\{L>c\\} + Y^0 \\cdot \\mathbb{I}\\{L \\le c\\}$$\nWe can simplify this expression by substituting the structural relationship between $Y^1$ and $Y^0$. From the SCM, the structural equation for $Y^a$ is $Y^a = \\beta_0 + \\beta_1 a + \\beta_2 L + \\beta_3 a L + \\beta_4 L^2 + \\epsilon$.\nThus, $Y^1 = Y^0 + \\beta_1 + \\beta_3 L$. Substituting this into the expression for $Y^{d_c(L)}$:\n$$Y^{d_c(L)} = (Y^0 + \\beta_1 + \\beta_3 L) \\cdot \\mathbb{I}\\{L>c\\} + Y^0 \\cdot \\mathbb{I}\\{L \\le c\\}$$\n$$Y^{d_c(L)} = Y^0 (\\mathbb{I}\\{L>c\\} + \\mathbb{I}\\{L \\le c\\}) + (\\beta_1 + \\beta_3 L) \\cdot \\mathbb{I}\\{L>c\\}$$\nSince $\\mathbb{I}\\{L>c\\} + \\mathbb{I}\\{L \\le c\\} = 1$:\n$$Y^{d_c(L)} = Y^0 + (\\beta_1 + \\beta_3 L) \\cdot \\mathbb{I}\\{L>c\\}$$\nNow, we take the expectation of this expression:\n$$E[Y^{d_c(L)}] = E[Y^0 + (\\beta_1 + \\beta_3 L) \\cdot \\mathbb{I}\\{L>c\\}]$$\n$$E[Y^{d_c(L)}] = E[Y^0] + E[(\\beta_1 + \\beta_3 L) \\cdot \\mathbb{I}\\{L>c\\}]$$\n$$E[Y^{d_c(L)}] = E[Y^0] + \\beta_1 E[\\mathbb{I}\\{L>c\\}] + \\beta_3 E[L \\cdot \\mathbb{I}\\{L>c\\}]$$\nWe need to compute the terms:\n1.  \n$E[Y^0]$: We have already derived this as $\\beta_0 + \\beta_2 \\mu + \\beta_4 (\\sigma^2 + \\mu^2)$.\n2.  \n$E[\\mathbb{I}\\{L>c\\}] = P(L>c)$. Let $Z = (L-\\mu)/\\sigma$ be the standardized variable, $Z \\sim \\mathcal{N}(0,1)$. Then $L>c$ is equivalent to $Z > (c-\\mu)/\\sigma$. Let $\\alpha = (c-\\mu)/\\sigma$.\n    $$P(L>c) = P(Z > \\alpha) = 1 - \\Phi(\\alpha)$$\n    where $\\Phi(\\cdot)$ is the CDF of the standard normal distribution.\n3.  \n$E[L \\cdot \\mathbb{I}\\{L>c\\}]$. This is the first partial moment of $L$.\n    $$E[L \\cdot \\mathbb{I}\\{L>c\\}] = \\int_c^\\infty l \\cdot p(l) dl$$\n    We perform a change of variables to $z=(l-\\mu)/\\sigma$, so $l=\\mu+\\sigma z$ and $p(l)dl = \\phi(z)dz$, where $\\phi(\\cdot)$ is the PDF of the standard normal distribution. The integration limit becomes $\\alpha=(c-\\mu)/\\sigma$.\n    $$\\int_\\alpha^\\infty (\\mu+\\sigma z)\\phi(z)dz = \\mu \\int_\\alpha^\\infty \\phi(z)dz + \\sigma \\int_\\alpha^\\infty z\\phi(z)dz$$\n    The first integral is $\\mu P(Z>\\alpha) = \\mu(1-\\Phi(\\alpha))$.\n    The second integral is $\\int_\\alpha^\\infty z \\frac{1}{\\sqrt{2\\pi}}e^{-z^2/2} dz$. This integral evaluates to $\\phi(\\alpha)$.\n    Therefore,\n    $$E[L \\cdot \\mathbb{I}\\{L>c\\}] = \\mu(1-\\Phi(\\alpha)) + \\sigma \\phi(\\alpha)$$\n\nCombining all parts, the final formula is:\n$$E[Y^{d_c(L)}] = (\\beta_0 + \\beta_2 \\mu + \\beta_4 (\\sigma^2 + \\mu^2)) + \\beta_1(1 - \\Phi(\\alpha)) + \\beta_3(\\mu(1 - \\Phi(\\alpha)) + \\sigma \\phi(\\alpha))$$\nwith $\\alpha = (c-\\mu)/\\sigma$. These derived formulas can now be implemented.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the causal inference problem for all test cases.\n    \"\"\"\n    # Test cases defined in the problem statement.\n    # Each case is a tuple: (parameters_dict, thresholds_tuple)\n    test_cases = [\n        (\n            {'beta0': 2.0, 'beta1': 1.2, 'beta2': 0.5, 'beta3': 0.8, 'beta4': 0.3, 'mu': 0.5, 'sigma': 1.0, 'sigma_epsilon': 1.0},\n            (0.0, 1.5, -2.0)\n        ),\n        (\n            {'beta0': 0.0, 'beta1': 0.7, 'beta2': 0.0, 'beta3': 1.5, 'beta4': 0.1, 'mu': -0.25, 'sigma': 0.5, 'sigma_epsilon': 0.5},\n            (-1.0, 0.0, 0.5)\n        ),\n        (\n            {'beta0': -1.0, 'beta1': 2.0, 'beta2': 1.0, 'beta3': -0.4, 'beta4': 0.0, 'mu': 1.0, 'sigma': 2.0, 'sigma_epsilon': 2.0},\n            (1.0, 3.0, -1.0)\n        )\n    ]\n\n    all_results = []\n    \n    for params, thresholds in test_cases:\n        # Unpack parameters for clarity\n        beta0 = params['beta0']\n        beta1 = params['beta1']\n        beta2 = params['beta2']\n        beta3 = params['beta3']\n        beta4 = params['beta4']\n        mu = params['mu']\n        sigma = params['sigma']\n\n        # Task 1 and 2: Calculate E[Y^0] and E[Y^1]\n        # First two moments of L ~ N(mu, sigma^2)\n        E_L = mu\n        E_L2 = sigma**2 + mu**2\n        \n        # E[Y^0] = beta0 + beta2*E[L] + beta4*E[L^2]\n        EY0 = beta0 + beta2 * E_L + beta4 * E_L2\n        \n        # E[Y^1] = E[Y^0] + beta1 + beta3*E[L]\n        EY1 = EY0 + beta1 + beta3 * E_L\n        \n        # Task 3: Calculate Average Treatment Effect (ATE)\n        # ATE = E[Y^1] - E[Y^0] = beta1 + beta3*E[L]\n        ATE = beta1 + beta3 * E_L\n\n        results_for_case = [\n            round(EY0, 6),\n            round(EY1, 6),\n            round(ATE, 6)\n        ]\n\n        # Inner function to compute E[Y^d_c] for a given threshold c\n        def calculate_EY_dc(c):\n            \"\"\"\n            Calculates the average potential outcome under the dynamic policy d_c(L).\n            \"\"\"\n            if sigma == 0:\n                # Handle degenerate case where L is a constant\n                if mu > c:\n                     # Policy sets A=1 with certainty\n                     return EY1\n                else: \n                     # Policy sets A=0 with certainty\n                     return EY0\n\n            # Standardized threshold\n            alpha = (c - mu) / sigma\n            \n            # P(L > c) = 1 - Phi(alpha)\n            prob_L_gt_c = 1.0 - norm.cdf(alpha)\n            \n            # E[L * I(L > c)] = mu * (1 - Phi(alpha)) + sigma * phi(alpha)\n            E_L_indicator = mu * prob_L_gt_c + sigma * norm.pdf(alpha)\n            \n            # E[Y^d_c] = E[Y^0] + beta1*P(L>c) + beta3*E[L*I(L>c)]\n            EY_dc = EY0 + beta1 * prob_L_gt_c + beta3 * E_L_indicator\n            \n            return EY_dc\n\n        # Tasks 4, 5, 6: Calculate E[Y^d_c] for each threshold\n        c1, c2, c3 = thresholds\n        EY_dc1 = calculate_EY_dc(c1)\n        EY_dc2 = calculate_EY_dc(c2)\n        EY_dc3 = calculate_EY_dc(c3)\n        \n        results_for_case.extend([\n            round(EY_dc1, 6),\n            round(EY_dc2, 6),\n            round(EY_dc3, 6)\n        ])\n        \n        all_results.extend(results_for_case)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n\n```"
        }
    ]
}