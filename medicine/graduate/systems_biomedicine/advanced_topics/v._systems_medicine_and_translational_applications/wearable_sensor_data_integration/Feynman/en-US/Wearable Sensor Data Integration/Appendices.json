{
    "hands_on_practices": [
        {
            "introduction": "Integrating data from wearable sensors begins with understanding the properties of the raw signals themselves. Due to strict power and memory constraints, wearable devices often sample physiological signals at rates lower than what might be considered ideal. This practice  explores a critical consequence of such design choices: aliasing. By working through a hypothetical yet realistic gait monitoring scenario, you will apply the principles of the Nyquist-Shannon sampling theorem to predict how undersampling can cause a high-frequency signal component to be misinterpreted as a lower frequency, and quantify the direct impact on a clinically relevant metric like step count.",
            "id": "4399053",
            "problem": "A wearable Inertial Measurement Unit (IMU) accelerometer used in systems biomedicine for gait monitoring acquires a continuous-time signal with a dominant narrowband component at the per-step frequency $f_{g} = 2$ $\\text{Hz}$. Due to power constraints, this accelerometer is uniformly sampled at a rate $f_{s} = 3$ $\\text{Hz}$, and the step-counting algorithm estimates the step count by detecting the dominant frequency in the sampled signal and multiplying this estimate by the observation duration $T$, assuming one step per cycle of the dominant component.\n\nStarting from the sampling theorem and the definition that uniform sampling of a continuous-time signal produces spectral replicas shifted by integer multiples of the sampling rate, derive the frequency content that will be observed after sampling, and determine the aliased frequency $f_{a}$ that lies within the baseband interval $[0, f_{s}/2]$. Then, assuming an asymptotically long observation window $T$ and a perfect frequency estimator that outputs the dominant frequency in the sampled, discrete-time data, derive the multiplicative bias in the estimated step count relative to the true count. Express this bias as a single dimensionless decimal number, defined as the ratio of the estimated count to the true count in the limit $T \\to \\infty$. No rounding is required.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of digital signal processing, specifically the Nyquist-Shannon sampling theorem and the phenomenon of aliasing. The problem is well-posed, objective, and contains all necessary information to derive a unique, meaningful solution. The scenario described is a standard application in systems biomedicine and wearable technology.\n\nThe core of this problem lies in the consequences of sampling a continuous-time signal at a rate below the Nyquist rate. The Nyquist-Shannon sampling theorem states that for a bandlimited signal with a maximum frequency $f_{max}$, the sampling frequency $f_s$ must be strictly greater than twice the maximum frequency, i.e., $f_s > 2 f_{max}$, to avoid the loss of information and enable perfect reconstruction. The frequency $2 f_{max}$ is known as the Nyquist rate.\n\nIn this problem, the continuous-time signal has a dominant frequency component at the gait frequency $f_g = 2$ Hz. Therefore, the maximum frequency to be preserved is $f_{max} = f_g = 2$ Hz. The Nyquist rate required to sample this signal without aliasing is $2 \\cdot f_g = 2 \\cdot 2 = 4$ Hz.\n\nThe accelerometer, however, samples the signal at a rate of $f_s = 3$ Hz. Since the sampling frequency $f_s = 3$ Hz is less than the Nyquist rate of $4$ Hz, the signal is undersampled, and a phenomenon known as aliasing will occur.\n\nUniform sampling of a continuous-time signal with a spectral component at frequency $f_g$ produces a discrete-time signal whose spectrum contains replicas of the original component, shifted by all integer multiples of the sampling frequency $f_s$. The frequencies present in the spectrum of the sampled signal are given by the relation:\n$$\nf_{observed} = |f_g - k \\cdot f_s|\n$$\nwhere $k$ is any integer ($k \\in \\{\\dots, -2, -1, 0, 1, 2, \\dots\\}$).\n\nThe frequency estimator operates on the sampled data and thus observes frequencies within the principal or baseband interval. For a real-valued signal, this interval is defined as $[0, f_s/2]$. Given $f_s = 3$ Hz, the baseband interval is $[0, 3/2]$ Hz, or $[0, 1.5]$ Hz. We must find the value of $k$ for which $f_{observed}$ falls into this interval.\n\nLet's evaluate $f_{observed}$ for different integer values of $k$:\n\\begin{itemize}\n    \\item For $k = 0$: $f_{observed} = |2 - 0 \\cdot 3| = 2$ Hz. This is outside the baseband $[0, 1.5]$ Hz.\n    \\item For $k = 1$: $f_{observed} = |2 - 1 \\cdot 3| = |-1| = 1$ Hz. This frequency lies within the baseband $[0, 1.5]$ Hz.\n    \\item For $k = -1$: $f_{observed} = |2 - (-1) \\cdot 3| = |2 + 3| = 5$ Hz. This is outside the baseband.\n    \\item For $k = 2$: $f_{observed} = |2 - 2 \\cdot 3| = |-4| = 4$ Hz. This is outside the baseband.\n\\end{itemize}\nThe only spectral replica that appears in the defined baseband interval is at $1$ Hz. Therefore, the aliased frequency $f_a$ that will be detected by the perfect frequency estimator is:\n$$\nf_a = 1 \\text{ Hz}\n$$\nThe problem states that the step-counting algorithm estimates the step count by multiplying the estimated frequency by the observation duration $T$. The true step count, $N_{true}$, is based on the actual per-step frequency, $f_g$:\n$$\nN_{true} = f_g \\cdot T\n$$\nThe estimated step count, $N_{est}$, is based on the aliased frequency, $f_a$, which is what the algorithm detects from the sampled data:\n$$\nN_{est} = f_a \\cdot T\n$$\nThe multiplicative bias is defined as the ratio of the estimated count to the true count. In the limit of an asymptotically long observation window ($T \\to \\infty$), the duration $T$ is a common factor and cancels out:\n$$\n\\text{Bias} = \\frac{N_{est}}{N_{true}} = \\frac{f_a \\cdot T}{f_g \\cdot T} = \\frac{f_a}{f_g}\n$$\nSubstituting the known values for the aliased frequency $f_a$ and the true gait frequency $f_g$:\n$$\n\\text{Bias} = \\frac{1 \\text{ Hz}}{2 \\text{ Hz}} = 0.5\n$$\nThe resulting multiplicative bias is a dimensionless decimal number, as required. Due to undersampling, the algorithm will estimate a step count that is half of the true step count.",
            "answer": "$$\\boxed{0.5}$$"
        },
        {
            "introduction": "Fusing data streams from multiple sensors is only meaningful if the measurements are aligned to a common, accurate timeline. However, the internal clocks of wearable devices are imperfect and subject to drift, creating subtle but cumulative timing errors. This hands-on exercise  provides a model for this clock imperfection and challenges you to develop a linear correction scheme. More importantly, it demonstrates how to quantify the residual, non-linear error that remains even after a simple correction, a crucial step in assessing the quality of sensor synchronization.",
            "id": "4399003",
            "problem": "A systems biomedicine team is integrating streams from a Photoplethysmography (PPG) sensor and an Inertial Measurement Unit (IMU) in a wearable device. To align multimodal signals, they must correct the IMU’s internal timestamp clock to true time. Let true time be denoted by $t$ (in seconds), and let the raw IMU timestamp be $S(t)$. The IMU clock exhibits a fractional frequency error $\\delta(t)$ relative to true time defined as the dimensionless deviation in tick rate, so that the fundamental kinematic relationship between $S(t)$ and $t$ is $\\frac{dS}{dt} = 1 + \\delta(t)$. Over an observation interval of length $T = 3600$ s ($1$ hour), suppose $\\delta(t)$ is driven by a warm-up effect and varies linearly from $45$ parts per million (ppm) at $t=0$ to $55$ ppm at $t=T$, centered around an average drift of $50$ ppm. That is, assume $\\delta(t) = a + b t$ with $a = 45 \\times 10^{-6}$ and $b = \\frac{55 \\times 10^{-6} - 45 \\times 10^{-6}}{T}$. The integration pipeline applies a linear drift correction of the form $\\hat{t}(t) = \\alpha S(t) + \\beta$ that enforces the boundary conditions $\\hat{t}(0) = 0$ and $\\hat{t}(T) = T$, which correspond to perfect anchor alignment at the start and end of the interval.\n\nStarting strictly from the above definitions and relationships, first derive the corrected timestamp mapping $\\hat{t}(t)$ implied by these boundary conditions. Then, using this mapping, derive the residual misalignment $e(t) = \\hat{t}(t) - t$ and determine its maximum absolute value on the interval $t \\in [0, T]$. Express the final answer as the single number equal to the maximum absolute residual misalignment in seconds, and round your answer to four significant figures. Use seconds as the unit for your final reported quantity.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the principles of clock physics and signal processing, well-posed with sufficient information to derive a unique solution, and expressed in objective, formal language. All provided data are consistent and physically realistic for the scenario described. We may therefore proceed with the solution.\n\nThe problem asks for the maximum absolute residual misalignment, $|e(t)|_{max}$, on the interval $t \\in [0, T]$, resulting from a linear correction applied to a timestamp clock with a time-varying frequency error.\n\nFirst, we must determine the raw IMU timestamp $S(t)$ as a function of true time $t$. The relationship is given by the differential equation:\n$$\n\\frac{dS}{dt} = 1 + \\delta(t)\n$$\nThe fractional frequency error $\\delta(t)$ is given as a linear function of time:\n$$\n\\delta(t) = a + bt\n$$\nwhere the constants are $a = 45 \\times 10^{-6}$ and $b = \\frac{(55 - 45) \\times 10^{-6}}{T} = \\frac{10 \\times 10^{-6}}{T}$.\nWe can find $S(t)$ by integrating $\\frac{dS}{dt}$ with respect to time from $0$ to $t$. We assume the initial condition $S(0) = 0$, which is the standard convention for a clock starting its count at the beginning of an observation.\n$$\nS(t) - S(0) = \\int_0^t (1 + \\delta(\\tau)) d\\tau\n$$\n$$\nS(t) = \\int_0^t (1 + a + b\\tau) d\\tau\n$$\nEvaluating the integral gives:\n$$\nS(t) = \\left[ \\tau + a\\tau + \\frac{1}{2}b\\tau^2 \\right]_0^t = t + at + \\frac{1}{2}bt^2\n$$\nNext, we determine the parameters of the linear drift correction $\\hat{t}(t) = \\alpha S(t) + \\beta$. The problem states two boundary conditions: $\\hat{t}(0) = 0$ and $\\hat{t}(T) = T$.\nApplying the first boundary condition at $t=0$:\n$$\n\\hat{t}(0) = \\alpha S(0) + \\beta = 0\n$$\nSince $S(0) = 0$, this immediately implies that $\\beta = 0$.\n\nApplying the second boundary condition at $t=T$:\n$$\n\\hat{t}(T) = \\alpha S(T) = T\n$$\nWe need to evaluate $S(T)$:\n$$\nS(T) = T + aT + \\frac{1}{2}bT^2\n$$\nNow, we can solve for $\\alpha$:\n$$\n\\alpha \\left(T + aT + \\frac{1}{2}bT^2\\right) = T\n$$\n$$\n\\alpha = \\frac{T}{T(1 + a + \\frac{1}{2}bT)} = \\frac{1}{1 + a + \\frac{1}{2}bT}\n$$\nThe average frequency error over the interval, $\\bar{\\delta}$, is $\\frac{1}{T}\\int_0^T \\delta(t) dt = \\frac{1}{T}\\int_0^T (a+bt)dt = a + \\frac{1}{2}bT$. Thus, $\\alpha = \\frac{1}{1+\\bar{\\delta}}$.\n\nNow we have the full expression for the corrected timestamp, $\\hat{t}(t)$:\n$$\n\\hat{t}(t) = \\alpha S(t) = \\frac{1}{1 + a + \\frac{1}{2}bT} \\left(t + at + \\frac{1}{2}bt^2\\right)\n$$\nThe residual misalignment is defined as $e(t) = \\hat{t}(t) - t$. Substituting the expression for $\\hat{t}(t)$:\n$$\ne(t) = \\frac{t + at + \\frac{1}{2}bt^2}{1 + a + \\frac{1}{2}bT} - t\n$$\nTo simplify, we put everything over a common denominator:\n$$\ne(t) = \\frac{(t + at + \\frac{1}{2}bt^2) - t(1 + a + \\frac{1}{2}bT)}{1 + a + \\frac{1}{2}bT}\n$$\n$$\ne(t) = \\frac{t + at + \\frac{1}{2}bt^2 - t - at - \\frac{1}{2}bTt}{1 + a + \\frac{1}{2}bT}\n$$\nThe terms $t$ and $at$ cancel out, leaving:\n$$\ne(t) = \\frac{\\frac{1}{2}bt^2 - \\frac{1}{2}bTt}{1 + a + \\frac{1}{2}bT} = \\frac{\\frac{b}{2}(t^2 - Tt)}{1 + a + \\frac{1}{2}bT}\n$$\nTo find the maximum absolute value of $e(t)$ on the interval $[0, T]$, we need to find the extremum of the numerator, which is a parabolic function of $t$. Let $f(t) = t^2 - Tt$. We find the critical point by taking the derivative with respect to $t$ and setting it to zero:\n$$\n\\frac{df}{dt} = 2t - T = 0 \\implies t = \\frac{T}{2}\n$$\nThe extremum occurs at the midpoint of the interval, $t = T/2$. We substitute this value back into the expression for $e(t)$ to find the maximum misalignment magnitude.\n$$\ne\\left(\\frac{T}{2}\\right) = \\frac{\\frac{b}{2}\\left(\\left(\\frac{T}{2}\\right)^2 - T\\left(\\frac{T}{2}\\right)\\right)}{1 + a + \\frac{1}{2}bT} = \\frac{\\frac{b}{2}\\left(\\frac{T^2}{4} - \\frac{T^2}{2}\\right)}{1 + a + \\frac{1}{2}bT} = \\frac{\\frac{b}{2}\\left(-\\frac{T^2}{4}\\right)}{1 + a + \\frac{1}{2}bT} = \\frac{-bT^2 / 8}{1 + a + \\frac{1}{2}bT}\n$$\nThe maximum absolute residual misalignment is the absolute value of this quantity:\n$$\n|e(t)|_{max} = \\left|e\\left(\\frac{T}{2}\\right)\\right| = \\frac{bT^2}{8(1 + a + \\frac{1}{2}bT)}\n$$\nNow, we substitute the given numerical values.\n$T = 3600$ s.\n$a = 45 \\times 10^{-6}$.\n$b = \\frac{10 \\times 10^{-6}}{T} = \\frac{10^{-5}}{3600}$ s$^{-1}$.\n\nLet's calculate the terms:\nThe term $bT^2$ in the numerator simplifies to:\n$$\nbT^2 = \\left(\\frac{10^{-5}}{T}\\right) T^2 = 10^{-5} T = 10^{-5} \\times 3600 = 0.036\n$$\nThe term $a + \\frac{1}{2}bT$ in the denominator is:\n$$\na + \\frac{1}{2}bT = 45 \\times 10^{-6} + \\frac{1}{2}\\left(\\frac{10^{-5}}{T}\\right)T = 45 \\times 10^{-6} + \\frac{1}{2} \\times 10^{-5} = 45 \\times 10^{-6} + 5 \\times 10^{-6} = 50 \\times 10^{-6}\n$$\nThis is the average fractional frequency error $\\bar{\\delta} = 50$ ppm, as described in the problem.\nNow, we can compute the final value:\n$$\n|e(t)|_{max} = \\frac{0.036}{8(1 + 50 \\times 10^{-6})} = \\frac{0.036}{8(1.00005)} = \\frac{0.0045}{1.00005}\n$$\nPerforming the division:\n$$\n|e(t)|_{max} \\approx 0.004499775011 \\text{ s}\n$$\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $4$, $4$, $9$, $9$. The fifth significant figure is $7$, which is greater than or equal to $5$, so we round up the fourth significant digit. Rounding $0.004499$ up results in $0.004500$.\n\nThe maximum absolute residual misalignment is $0.004500$ seconds.",
            "answer": "$$\n\\boxed{0.004500}\n$$"
        },
        {
            "introduction": "Systems biomedicine often leverages multiple modalities to measure the same physiological variable, such as using both electrocardiography (ECG) and photoplethysmography (PPG) to estimate heart rate. A fundamental question is whether these two measurement methods agree sufficiently to be used interchangeably. This practice  introduces a cornerstone of clinical measurement comparison, the Bland-Altman analysis, to move beyond simple correlation and rigorously quantify the systematic bias and random error between two devices. By implementing this analysis, you will gain a key skill for validating and integrating data from different sensor technologies.",
            "id": "4399060",
            "problem": "Consider inter-device heart rate integration in systems biomedicine using wearable sensors. Electrocardiography (ECG) and Photoplethysmography (PPG) are two modalities for estimating heart rate. Let the underlying true heart rate be denoted by $h_i$ for the $i$-th paired observation. The ECG-derived heart rate is denoted by $y^{\\mathrm{ECG}}_i$ and the PPG-derived heart rate is denoted by $y^{\\mathrm{PPG}}_i$, both measured in beats per minute (bpm). Assume that each observed heart rate is the true heart rate perturbed by device-specific measurement error, that is, $y^{\\mathrm{ECG}}_i = h_i + \\varepsilon^{\\mathrm{ECG}}_i$ and $y^{\\mathrm{PPG}}_i = h_i + \\varepsilon^{\\mathrm{PPG}}_i$, where $\\varepsilon^{\\mathrm{ECG}}_i$ and $\\varepsilon^{\\mathrm{PPG}}_i$ are random errors with finite variance. Define the paired difference $d_i = y^{\\mathrm{PPG}}_i - y^{\\mathrm{ECG}}_i$ and the paired mean $m_i = \\left(y^{\\mathrm{PPG}}_i + y^{\\mathrm{ECG}}_i\\right)/2$. The inter-device bias is the expected value of the difference, $\\mathbb{E}[d_i]$, and a Bland–Altman analysis characterizes agreement between devices under a Normal model for the differences.\n\nYour task is to write a program that, for each test case, performs the following computations from first principles:\n- Estimate the inter-device bias using the paired differences $d_i$ after removing any pair where either $y^{\\mathrm{ECG}}_i$ or $y^{\\mathrm{PPG}}_i$ is missing. Missing values are represented as not-a-number and should be excluded by pairwise deletion.\n- Estimate the dispersion of $d_i$ using the unbiased sample standard deviation.\n- Assuming that the differences $d_i$ are independent and approximately Normally distributed with constant variance, compute the two-sided $95$-coverage Bland–Altman limits of agreement for the differences using the appropriate Normal quantile.\n- Assess proportional bias by fitting the ordinary least squares regression $d_i = a + b\\,m_i + \\eta_i$ and test the null hypothesis of no proportional bias, $b = 0$, using a two-sided significance level $\\alpha = 0.05$ expressed as a decimal. Report the slope $b$ and a boolean indicating whether proportional bias is statistically significant at the given level. If the regression is undefined due to zero variance in $m_i$ or insufficient data, treat the slope as $0$ and the significance as false.\n\nAll bias and limits-of-agreement answers must be expressed in beats per minute (bpm). The slope $b$ is dimensionless in bpm per bpm. Angles are not involved. Percentages must be treated as decimals; do not use the percentage sign.\n\nUse the following test suite of paired observations (each value is in bpm). For each case, the ECG list and PPG list are aligned pairs measured across sessions; treat them as one combined dataset per case.\n\n- Case $1$ (general case with small positive bias):\n  - ECG: $\\{\\,72,\\,75,\\,80,\\,78,\\,90,\\,92,\\,88,\\,85,\\,76,\\,84\\,\\}$\n  - PPG: $\\{\\,74,\\,77,\\,83,\\,80,\\,93,\\,94,\\,90,\\,86,\\,78,\\,86\\,\\}$\n\n- Case $2$ (boundary case with zero bias and zero dispersion):\n  - ECG: $\\{\\,60,\\,65,\\,70,\\,75,\\,80,\\,85\\,\\}$\n  - PPG: $\\{\\,60,\\,65,\\,70,\\,75,\\,80,\\,85\\,\\}$\n\n- Case $3$ (edge case with proportional bias increasing with heart rate):\n  - ECG: $\\{\\,50,\\,60,\\,70,\\,80,\\,90,\\,100,\\,110\\,\\}$\n  - PPG: $\\{\\,52,\\,62,\\,74.5,\\,84,\\,92.5,\\,107,\\,115.5\\,\\}$\n\n- Case $4$ (edge case with missing values requiring pairwise deletion):\n  - ECG: $\\{\\,70,\\,\\text{NaN},\\,85,\\,95,\\,100\\,\\}$\n  - PPG: $\\{\\,72,\\,78,\\,\\text{NaN},\\,99,\\,102\\,\\}$\n\nThe required final output format for your program is a single line containing a list of results for the four cases, in order, where each case’s result is itself a list with the following six elements in this precise order:\n$[\\,\\widehat{B},\\,\\widehat{S}_d,\\,\\mathrm{LOA}_{\\mathrm{lower}},\\,\\mathrm{LOA}_{\\mathrm{upper}},\\,\\widehat{b},\\,\\mathrm{is\\_significant}\\,]$,\nwhere $\\widehat{B}$ is the estimated bias in bpm, $\\widehat{S}_d$ is the unbiased sample standard deviation of $d_i$ in bpm, $\\mathrm{LOA}_{\\mathrm{lower}}$ and $\\mathrm{LOA}_{\\mathrm{upper}}$ are the Bland–Altman limits of agreement in bpm, $\\widehat{b}$ is the regression slope in bpm per bpm, and $\\mathrm{is\\_significant}$ is a boolean for the proportional-bias test at $\\alpha = 0.05$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with each case’s list enclosed in its own square brackets, for example: $[[r_{1,1},r_{1,2},\\ldots],[r_{2,1},r_{2,2},\\ldots],[r_{3,1},\\ldots],[r_{4,1},\\ldots]]$.",
            "solution": "The problem is valid as it is scientifically grounded in standard biostatistical methods, well-posed with sufficient and consistent information, and objectively formulated. The task is to perform a Bland-Altman analysis and assess proportional bias for paired heart rate measurements from ECG and PPG sensors.\n\nThe solution proceeds by first implementing data preprocessing, followed by the calculation of specified statistical measures from first principles.\n\n**1. Data Preprocessing**\nFor each test case, the paired observations $(y^{\\mathrm{ECG}}_i, y^{\\mathrm{PPG}}_i)$ are processed. Any pair containing a missing value, represented as not-a-number (NaN), is removed. This procedure is known as pairwise deletion. Let $n$ be the number of valid pairs remaining after this step. For all provided test cases, $n \\ge 3$, which is sufficient for all subsequent calculations.\n\n**2. Paired Differences and Means**\nFrom the cleaned data, we compute the paired differences $d_i$ and paired means $m_i$ for each observation $i=1, \\dots, n$:\n$$d_i = y^{\\mathrm{PPG}}_i - y^{\\mathrm{ECG}}_i$$\n$$m_i = \\frac{y^{\\mathrm{PPG}}_i + y^{\\mathrm{ECG}}_i}{2}$$\n\n**3. Bland-Altman Analysis**\nThe Bland-Altman analysis quantifies the agreement between the two measurement devices.\n\n**3.1. Inter-Device Bias Estimation**\nThe inter-device bias, $\\mathbb{E}[d_i]$, is estimated by the sample mean of the differences, denoted $\\widehat{B}$:\n$$\\widehat{B} = \\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$$\n\n**3.2. Dispersion Estimation**\nThe dispersion of the differences is estimated using the unbiased sample standard deviation, denoted $\\widehat{S}_d$:\n$$\\widehat{S}_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (d_i - \\bar{d})^2}$$\nThis calculation requires at least $n=2$ valid pairs.\n\n**3.3. Limits of Agreement (LOA)**\nAssuming the differences $d_i$ follow a Normal distribution, the $95\\%$ limits of agreement are calculated. These limits define the range within which $95\\%$ of the differences between the two methods are expected to lie.\n$$\\mathrm{LOA} = \\bar{d} \\pm z_{1-\\alpha/2} \\cdot \\widehat{S}_d$$\nFor a two-sided $95\\%$ coverage, the significance level is $\\alpha=0.05$. We use the $1-\\alpha/2 = 0.975$ quantile of the standard Normal distribution, $z_{0.975} \\approx 1.95996$. The lower and upper limits are:\n$$\\mathrm{LOA}_{\\mathrm{lower}} = \\bar{d} - z_{0.975} \\cdot \\widehat{S}_d$$\n$$\\mathrm{LOA}_{\\mathrm{upper}} = \\bar{d} + z_{0.975} \\cdot \\widehat{S}_d$$\n\n**4. Proportional Bias Assessment**\nProportional bias occurs if the difference between the two measurements varies systematically with the magnitude of the measurement. This is assessed by fitting an ordinary least squares (OLS) regression model:\n$$d_i = a + b\\,m_i + \\eta_i$$\nwhere $\\eta_i$ are the error terms.\n\n**4.1. Slope Estimation**\nThe slope coefficient $\\widehat{b}$ is estimated using the OLS formula:\n$$\\widehat{b} = \\frac{\\sum_{i=1}^{n} (m_i - \\bar{m})(d_i - \\bar{d})}{\\sum_{i=1}^{n} (m_i - \\bar{m})^2} = \\frac{\\mathrm{Cov}(m, d)}{\\mathrm{Var}(m)}$$\nwhere $\\bar{m}$ is the sample mean of the $m_i$. This calculation is undefined if the variance of $m_i$ is zero. In such a case, as per the problem statement, we set $\\widehat{b}=0$ and conclude there is no significant proportional bias.\n\n**4.2. Hypothesis Testing for the Slope**\nWe test the null hypothesis $H_0: b = 0$ (no proportional bias) against the alternative $H_1: b \\neq 0$ at a significance level of $\\alpha = 0.05$. The test statistic is the t-statistic, which under $H_0$ follows a t-distribution with $n-2$ degrees of freedom:\n$$t = \\frac{\\widehat{b}}{\\mathrm{SE}(\\widehat{b})}$$\nThe standard error of the slope, $\\mathrm{SE}(\\widehat{b})$, is calculated as:\n$$\\mathrm{SE}(\\widehat{b}) = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (m_i - \\bar{m})^2}}$$\nwhere $\\hat{\\sigma}^2$ is the unbiased estimator of the variance of the residuals $\\eta_i$:\n$$\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum_{i=1}^{n} e_i^2$$\nand $e_i = d_i - (\\hat{a} + \\hat{b}m_i)$ are the residuals from the regression, with $\\hat{a} = \\bar{d} - \\hat{b}\\bar{m}$. This test is valid for $n > 2$.\n\nThe null hypothesis is rejected if the absolute value of the test statistic exceeds the critical value from the t-distribution:\n$$|t| > t_{n-2, 1-\\alpha/2}$$\nwhere $t_{n-2, 1-\\alpha/2}$ is the upper critical value for a two-sided test. If $|t| \\le t_{n-2, 1-\\alpha/2}$, we fail to reject $H_0$, and the proportional bias is not statistically significant. The boolean `is_significant` is set accordingly.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Performs Bland-Altman and proportional bias analysis on paired heart rate data.\n    \"\"\"\n    test_cases = [\n        # Case 1: general case with small positive bias\n        {\n            'ECG': [72, 75, 80, 78, 90, 92, 88, 85, 76, 84],\n            'PPG': [74, 77, 83, 80, 93, 94, 90, 86, 78, 86]\n        },\n        # Case 2: boundary case with zero bias and zero dispersion\n        {\n            'ECG': [60, 65, 70, 75, 80, 85],\n            'PPG': [60, 65, 70, 75, 80, 85]\n        },\n        # Case 3: edge case with proportional bias\n        {\n            'ECG': [50, 60, 70, 80, 90, 100, 110],\n            'PPG': [52, 62, 74.5, 84, 92.5, 107, 115.5]\n        },\n        # Case 4: edge case with missing values\n        {\n            'ECG': [70, np.nan, 85, 95, 100],\n            'PPG': [72, 78, np.nan, 99, 102]\n        },\n    ]\n\n    all_results = []\n\n    for case_data in test_cases:\n        y_ecg = np.array(case_data['ECG'], dtype=float)\n        y_ppg = np.array(case_data['PPG'], dtype=float)\n\n        # Step 1: Pairwise deletion for NaN values\n        valid_mask = ~np.isnan(y_ecg) & ~np.isnan(y_ppg)\n        y_ecg_clean = y_ecg[valid_mask]\n        y_ppg_clean = y_ppg[valid_mask]\n\n        n = len(y_ecg_clean)\n\n        # Step 2: Compute paired differences (d) and means (m)\n        d = y_ppg_clean - y_ecg_clean\n        m = (y_ppg_clean + y_ecg_clean) / 2.0\n\n        # Step 3.1: Estimate inter-device bias\n        bias_est = np.mean(d) if n > 0 else 0.0\n\n        # Step 3.2: Estimate dispersion (unbiased sample standard deviation)\n        sd_est = np.std(d, ddof=1) if n > 1 else 0.0\n\n        # Step 3.3: Compute 95% Bland-Altman limits of agreement\n        z_crit = norm.ppf(0.975)\n        loa_margin = z_crit * sd_est\n        loa_lower = bias_est - loa_margin\n        loa_upper = bias_est + loa_margin\n\n        # Step 4: Assess proportional bias\n        slope_est = 0.0\n        is_significant = False\n\n        # Regression and t-test require n >= 3 and Var(m) > 0\n        if n >= 3 and np.var(m) > 1e-12:\n            # Step 4.1: OLS slope estimation from first principles\n            m_mean = np.mean(m)\n            d_mean = np.mean(d)\n            \n            # Covariance term S_md and variance term S_mm\n            cov_md_sum = np.sum((m - m_mean) * (d - d_mean))\n            var_m_sum = np.sum((m - m_mean) ** 2)\n            \n            slope_est = cov_md_sum / var_m_sum\n\n            # Step 4.2: Hypothesis testing for the slope\n            df = n - 2\n            \n            # Sum of squared residuals (SSR)\n            var_d_sum = np.sum((d - d_mean) ** 2)\n            ssr = var_d_sum - slope_est * cov_md_sum\n            \n            # Handle potential floating point inaccuracies\n            ssr = max(0, ssr)\n\n            # Estimated variance of the residuals\n            residual_var_est = ssr / df\n            \n            # Standard error of the slope\n            se_slope = np.sqrt(residual_var_est / var_m_sum)\n            \n            # Perform t-test if SE is non-zero\n            if se_slope > 1e-12:\n                t_stat = slope_est / se_slope\n                alpha = 0.05\n                t_crit = t.ppf(1 - alpha / 2, df=df)\n                is_significant = np.abs(t_stat) > t_crit\n            # If se_slope is zero, it implies a perfect fit. If slope is also\n            # zero, H0 is not rejected (is_significant remains False).\n\n        all_results.append([\n            bias_est, sd_est, loa_lower, loa_upper, slope_est, is_significant\n        ])\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}