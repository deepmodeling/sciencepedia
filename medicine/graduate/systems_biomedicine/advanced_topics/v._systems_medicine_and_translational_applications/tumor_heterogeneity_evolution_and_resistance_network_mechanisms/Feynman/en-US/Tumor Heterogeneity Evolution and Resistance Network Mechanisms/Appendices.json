{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of cancer genomics is the ability to interpret quantitative data from DNA sequencing. The Variant Allele Frequency ($VAF$), or the fraction of sequencing reads harboring a mutation, is a powerful observable quantity that contains rich information about a tumor's composition and history. This exercise  guides you through deriving and applying the fundamental model that connects the expected $VAF$ to tumor purity, local copy number, and the multiplicity of the variant allele, enabling the timing of mutations relative to major events like whole-genome duplication.",
            "id": "4396552",
            "problem": "A tumor sample contains a dominant malignant clone mixed with non-malignant diploid cells. The fraction of malignant cells (tumor purity) is $p=0.8$. In a specific genomic segment of the malignant clone, a Whole-Genome Duplication (WGD) event occurred, yielding a post-WGD total copy number $C=4$ in that segment for tumor cells. Consider two clonal Single-Nucleotide Variant (SNV) scenarios in that segment: (i) the SNV was acquired before WGD, so that after WGD it resides on $m=2$ of the $C=4$ copies; (ii) the SNV was acquired after WGD, so that it resides on $m=1$ of the $C=4$ copies. Assume unbiased short-read sequencing sampling from all alleles present in the mixture of tumor and normal cells, and that normal cells are diploid with no variant at this locus. Using first principles of mixture sampling and definitions of Variant Allele Frequency (VAF) as the expected fraction of reads bearing the variant allele among all reads at the locus, derive an expression for the expected VAF as a function of $p$, $C$, and $m$, and then compute the expected VAFs for the two scenarios described. Provide your final numerical answers as the ordered pair $(\\text{VAF}_{\\text{pre-WGD}}, \\text{VAF}_{\\text{post-WGD}})$, expressed as decimals rounded to four significant figures. No units are required.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of cancer genomics, well-posed with sufficient information for a unique solution, and stated objectively. We can therefore proceed with the derivation.\n\nThe Variant Allele Frequency ($\\text{VAF}$) is defined as the expected fraction of sequencing reads harboring a variant allele out of all reads covering that specific genomic locus. In a mixed sample of tumor and normal cells, the total pool of alleles at a locus is a weighted sum of alleles from both cell types.\n\nLet $p$ be the tumor purity, which is the fraction of malignant cells in the sample. Consequently, the fraction of non-malignant (normal) cells is $1-p$.\nThe normal cells are diploid, meaning they have a total copy number of $C_N = 2$ at any autosomal locus.\nThe tumor cells in the specified genomic segment have a total copy number of $C$.\nThe number of copies of the allele carrying the Single-Nucleotide Variant (SNV) in a tumor cell is $m$. Normal cells do not carry the variant.\n\nTo derive the expected VAF, we calculate the proportional contribution of variant alleles and total alleles from the mixture. Assuming unbiased sampling of DNA from all cells, the total number of alleles at the locus in the mixture is proportional to the sum of alleles from each population.\n\nThe total number of alleles, let's call its proportional measure $A_{\\text{total}}$, is the sum of contributions from tumor cells and normal cells:\n$$ A_{\\text{total}} \\propto (\\text{fraction of tumor cells} \\times \\text{copies per tumor cell}) + (\\text{fraction of normal cells} \\times \\text{copies per normal cell}) $$\n$$ A_{\\text{total}} \\propto p \\cdot C + (1-p) \\cdot C_N $$\nGiven that normal cells are diploid, $C_N=2$. So, the total proportional number of alleles is:\n$$ A_{\\text{total}} \\propto pC + 2(1-p) $$\n\nNext, we calculate the total proportional number of variant alleles, $A_{\\text{variant}}$. The SNV is only present in the tumor cells. In each tumor cell, there are $m$ copies of the allele with the variant. Normal cells contribute zero variant alleles.\n$$ A_{\\text{variant}} \\propto (\\text{fraction of tumor cells} \\times \\text{variant copies per tumor cell}) + (\\text{fraction of normal cells} \\times \\text{variant copies per normal cell}) $$\n$$ A_{\\text{variant}} \\propto p \\cdot m + (1-p) \\cdot 0 $$\n$$ A_{\\text{variant}} \\propto pm $$\n\nThe expected VAF is the ratio of the proportional number of variant alleles to the proportional total number of alleles:\n$$ \\text{VAF}(p, C, m) = \\frac{A_{\\text{variant}}}{A_{\\text{total}}} = \\frac{pm}{pC + 2(1-p)} $$\nThis is the general expression for the expected VAF as a function of tumor purity $p$, tumor-specific total copy number $C$, and variant allele copy number $m$.\n\nNow, we apply this formula to the given scenarios using the provided values: $p=0.8$ and $C=4$.\nFirst, let's calculate the denominator, which is common to both scenarios:\n$$ \\text{Denominator} = pC + 2(1-p) = (0.8)(4) + 2(1-0.8) = 3.2 + 2(0.2) = 3.2 + 0.4 = 3.6 $$\n\nScenario (i): The SNV was acquired before the Whole-Genome Duplication (WGD).\nIn a diploid cell (pre-WGD), a clonal heterozygous mutation occurs on one of the two homologous chromosomes. After WGD, all chromosomes are duplicated. Therefore, the single mutated allele is duplicated, resulting in $m=2$ variant alleles out of a total of $C=4$ alleles in the tumor cells.\nUsing $m=2$:\n$$ \\text{VAF}_{\\text{pre-WGD}} = \\frac{pm}{\\text{Denominator}} = \\frac{(0.8)(2)}{3.6} = \\frac{1.6}{3.6} = \\frac{16}{36} = \\frac{4}{9} $$\nAs a decimal, this is $0.444444...$. Rounded to four significant figures, $\\text{VAF}_{\\text{pre-WGD}} = 0.4444$.\n\nScenario (ii): The SNV was acquired after the WGD.\nThe WGD has already occurred, so the tumor cells have $C=4$ copies of the chromosome segment. A new clonal mutation then occurs on only one of these four copies. Therefore, the number of variant alleles is $m=1$.\nUsing $m=1$:\n$$ \\text{VAF}_{\\text{post-WGD}} = \\frac{pm}{\\text{Denominator}} = \\frac{(0.8)(1)}{3.6} = \\frac{0.8}{3.6} = \\frac{8}{36} = \\frac{2}{9} $$\nAs a decimal, this is $0.222222...$. Rounded to four significant figures, $\\text{VAF}_{\\text{post-WGD}} = 0.2222$.\n\nThe final answer is the ordered pair $(\\text{VAF}_{\\text{pre-WGD}}, \\text{VAF}_{\\text{post-WGD}})$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4444 & 0.2222\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Acquired resistance to targeted therapy often involves the dynamic rewiring of intracellular signaling networks, a core topic in resistance network mechanisms. A classic example is the 'relief-of-feedback' reactivation of upstream pathways when a downstream kinase is inhibited. This practice  introduces a powerful systems biology approach, Granger causality, to move from static pathway diagrams to data-driven inference, allowing you to detect this network rewiring from time-resolved molecular data.",
            "id": "4396571",
            "problem": "You are given a conceptual model of a signaling feedback loop relevant to tumor heterogeneity, evolution, and resistance network mechanisms in systems biomedicine. Consider a downstream kinase $X$ (for example, extracellular signal-regulated kinase phosphorylation), and an upstream receptor $Y$ (for example, epidermal growth factor receptor phosphorylation). Before treatment with v-raf murine sarcoma viral oncogene homolog B (BRAF) inhibitor, $X$ exerts a negative feedback influence on $Y$. After treatment, inhibition of $X$ relieves this feedback, potentially allowing $Y$ to reactivate. Your task is to implement an inference procedure, rooted in first principles of time-series causal analysis, to detect the presence of relief-of-feedback reactivation using Granger causality (GC) or Dynamic Bayesian Network (DBN) modeling. For this problem, you must implement Granger causality.\n\nFundamental base and model assumptions to use:\n- Granger causality (GC) is defined by predictive improvement: a time series $X$ Granger-causes $Y$ if the past of $X$ provides additional predictive power for $Y$ beyond the past of $Y$ alone.\n- Use vector autoregression (VAR) with a fixed lag order $p$ to capture the linear dependencies among $X$ and $Y$.\n- Ordinary least squares (OLS) is a valid estimator for linear regression under standard conditions of independent errors and finite variance.\n\nData generation protocol:\n- For each test case, you must generate time-resolved phosphoproteomics signals for $X$ and $Y$ in two phases: pre-treatment and post-treatment. Use a second-order ($p=2$) VAR with specified coefficients to simulate:\n  - Pre-treatment dynamics:\n    - $$Y_t = a_{y1} Y_{t-1} + a_{y2} Y_{t-2} + c_{xy1} X_{t-1} + c_{xy2} X_{t-2} + b_y + \\varepsilon^y_t,$$\n    - $$X_t = a_{x1} X_{t-1} + a_{x2} X_{t-2} + d_{y1} Y_{t-1} + b_x + \\varepsilon^x_t.$$\n  - Post-treatment dynamics:\n    - Apply BRAF inhibitor by scaling $a_{x1}$ and $b_x$ by a factor $s_x \\in (0,1]$ while keeping other coefficients unchanged. Continue simulating from the last state of the pre-treatment phase to mimic continuity.\n- Noise terms $\\varepsilon^y_t$ and $\\varepsilon^x_t$ are independent Gaussian random variables with zero mean and specified standard deviations $\\sigma_y$ and $\\sigma_x$.\n\nInference procedure requirements:\n- For each phase (pre-treatment and post-treatment), fit two OLS models for $Y_t$ using $p=2$:\n  1. Restricted model using only $Y$ lags: $$Y_t = \\alpha_0 + \\sum_{i=1}^{p} \\alpha_i Y_{t-i} + \\eta_t.$$\n  2. Unrestricted model using $Y$ and $X$ lags: $$Y_t = \\beta_0 + \\sum_{i=1}^{p} \\beta_i Y_{t-i} + \\sum_{i=1}^{p} \\gamma_i X_{t-i} + \\nu_t.$$\n- Quantify the predictive gain of including $X$ by the fractional reduction in the sum of squared residuals when going from the restricted to the unrestricted model, defined as $$G = \\frac{\\mathrm{SSR}_{\\mathrm{restricted}} - \\mathrm{SSR}_{\\mathrm{unrestricted}}}{\\mathrm{SSR}_{\\mathrm{restricted}}}.$$\n- Determine the sign of the feedback influence by the sum of the estimated unrestricted coefficients on $X$ lags, $$S = \\sum_{i=1}^{p} \\hat{\\gamma}_i.$$ A negative $S$ indicates inhibitory feedback from $X$ to $Y$.\n\nRelief-of-feedback reactivation detection criterion:\n- Declare relief-of-feedback reactivation present if and only if all of the following hold:\n  1. Pre-treatment predictive gain satisfies $G_{\\mathrm{pre}} \\geq \\tau_{\\mathrm{gain}}$ with a negative influence $S_{\\mathrm{pre}} < 0$.\n  2. Post-treatment predictive gain satisfies $G_{\\mathrm{post}} \\leq \\lambda \\, G_{\\mathrm{pre}}$, indicating a drop in the strength of predictive influence from $X$ to $Y$ after inhibition.\n  3. The mean level of $Y$ increases after treatment, $\\overline{Y}_{\\mathrm{post}} \\geq (1+\\rho) \\, \\overline{Y}_{\\mathrm{pre}}$, reflecting reactivation consistent with relief of feedback.\n- Use fixed thresholds $\\tau_{\\mathrm{gain}} = 0.05$, $\\lambda = 0.5$, and $\\rho = 0.1$.\n\nAngle units are not applicable. Physical units for time are not required in the output since the results are booleans. All outputs must be unitless booleans.\n\nTest suite (four cases to ensure coverage: happy path, no relief, high noise, small-sample boundary):\n- Case $1$ (happy path, strong negative feedback and strong inhibition):\n  - $T_{\\mathrm{pre}}=300$, $T_{\\mathrm{post}}=300$, $p=2$, $\\sigma_y=0.1$, $\\sigma_x=0.1$,\n  - $a_{y1}=0.7$, $a_{y2}=0.2$, $a_{x1}=0.6$, $a_{x2}=0.1$, $c_{xy1}=-0.8$, $c_{xy2}=0.0$, $d_{y1}=0.1$, $b_y=1.0$, $b_x=0.5$, $s_x=0.2$.\n- Case $2$ (no relief, weak feedback and no inhibition):\n  - $T_{\\mathrm{pre}}=300$, $T_{\\mathrm{post}}=300$, $p=2$, $\\sigma_y=0.15$, $\\sigma_x=0.15$,\n  - $a_{y1}=0.6$, $a_{y2}=0.2$, $a_{x1}=0.6$, $a_{x2}=0.1$, $c_{xy1}=-0.2$, $c_{xy2}=0.0$, $d_{y1}=0.1$, $b_y=1.0$, $b_x=0.5$, $s_x=1.0$.\n- Case $3$ (high noise, strong inhibition but reduced detectability):\n  - $T_{\\mathrm{pre}}=300$, $T_{\\mathrm{post}}=300$, $p=2$, $\\sigma_y=0.5$, $\\sigma_x=0.5$,\n  - $a_{y1}=0.7$, $a_{y2}=0.2$, $a_{x1}=0.6$, $a_{x2}=0.1$, $c_{xy1}=-0.7$, $c_{xy2}=0.0$, $d_{y1}=0.1$, $b_y=1.0$, $b_x=0.5$, $s_x=0.2$.\n- Case $4$ (small-sample boundary, moderate noise):\n  - $T_{\\mathrm{pre}}=60$, $T_{\\mathrm{post}}=60$, $p=2$, $\\sigma_y=0.3$, $\\sigma_x=0.3$,\n  - $a_{y1}=0.7$, $a_{y2}=0.2$, $a_{x1}=0.6$, $a_{x2}=0.1$, $c_{xy1}=-0.7$, $c_{xy2}=0.0$, $d_{y1}=0.1$, $b_y=1.0$, $b_x=0.5$, $s_x=0.2$.\n\nYour program must:\n- Use a fixed random seed for reproducibility.\n- Simulate the pre-treatment segment and then continue into the post-treatment segment with the scaled inhibitor parameters.\n- For each case, compute $G_{\\mathrm{pre}}$, $S_{\\mathrm{pre}}$, $G_{\\mathrm{post}}$, and $\\overline{Y}_{\\mathrm{pre}}$, $\\overline{Y}_{\\mathrm{post}}$, and then determine a boolean indicating relief-of-feedback reactivation according to the criterion above.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, `[r1,r2,r3,r4]`), where each $r_i$ is a boolean corresponding to the detection result for Case $i$.",
            "solution": "The objective of this problem is to implement a computational procedure for detecting \"relief-of-feedback reactivation\" in a simplified model of a tumor signaling pathway. This phenomenon is critical in understanding acquired resistance to targeted therapies. The methodology prescribed is based on Granger causality, a concept from time-series analysis used to infer directional influence between variables. We will use a Vector Autoregressive (VAR) model to capture the dynamics of the system.\n\nThe core of the problem involves a two-step process: first, simulating time-series data representing the activity of an upstream receptor $Y$ and a downstream kinase $X$ under pre-treatment and post-treatment conditions; second, analyzing this data to infer changes in the causal relationship from $X$ to $Y$.\n\n**1. Data Simulation via Vector Autoregression (VAR)**\n\nWe simulate the system's dynamics using a second-order Vector Autoregressive model, specified as $p=2$. The state of the system at time $t$ is defined by the values of $Y_t$ and $X_t$.\n\nFor the pre-treatment phase, the evolution of the system is governed by the following set of coupled difference equations:\n$$Y_t = a_{y1} Y_{t-1} + a_{y2} Y_{t-2} + c_{xy1} X_{t-1} + c_{xy2} X_{t-2} + b_y + \\varepsilon^y_t$$\n$$X_t = a_{x1} X_{t-1} + a_{x2} X_{t-2} + d_{y1} Y_{t-1} + b_x + \\varepsilon^x_t$$\nHere, the coefficients $a_{y1}, a_{y2}, a_{x1}, a_{x2}$ represent autoregressive dependencies (self-influence), while $c_{xy1}, c_{xy2}$ represent the influence of past $X$ on current $Y$, and $d_{y1}$ represents the influence of past $Y$ on current $X$. The terms $b_y$ and $b_x$ are constant biases. The terms $\\varepsilon^y_t$ and $\\varepsilon^x_t$ are independent and identically distributed noise processes, drawn from Gaussian distributions $\\mathcal{N}(0, \\sigma_y^2)$ and $\\mathcal{N}(0, \\sigma_x^2)$ respectively. A negative value for the sum of $c_{xy}$ coefficients signifies an inhibitory feedback from $X$ to $Y$.\n\nThe post-treatment phase models the effect of a BRAF inhibitor, which targets the kinase $X$. This is simulated by scaling the autoregressive coefficient $a_{x1}$ and the bias term $b_x$ by a factor $s_x \\in (0,1]$. This modification reduces the activity of $X$. The simulation proceeds continuously from the final state of the pre-treatment phase to ensure temporal coherence.\n\n**2. Inference of Causal Influence using Ordinary Least Squares (OLS)**\n\nTo assess whether the past of series $X$ provides statistically significant information for predicting the future of series $Y$, we employ the Granger causality test framework. This involves comparing two linear regression models for $Y_t$:\n\n1.  **Restricted Model:** This model predicts $Y_t$ using only its own past values (lags). For a lag order of $p=2$, the model is:\n    $$Y_t = \\alpha_0 + \\alpha_1 Y_{t-1} + \\alpha_2 Y_{t-2} + \\eta_t$$\n    The coefficients $\\alpha_i$ are estimated using Ordinary Least Squares (OLS) to minimize the sum of squared residuals, $\\mathrm{SSR}_{\\mathrm{restricted}} = \\sum \\hat{\\eta}_t^2$.\n\n2.  **Unrestricted Model:** This model includes the past values of both $Y$ and $X$ as predictors:\n    $$Y_t = \\beta_0 + \\beta_1 Y_{t-1} + \\beta_2 Y_{t-2} + \\gamma_1 X_{t-1} + \\gamma_2 X_{t-2} + \\nu_t$$\n    Similarly, the coefficients $\\beta_i$ and $\\gamma_i$ are estimated via OLS, yielding the minimal sum of squared residuals, $\\mathrm{SSR}_{\\mathrm{unrestricted}} = \\sum \\hat{\\nu}_t^2$.\n\nThe inference procedure is performed separately for the pre-treatment and post-treatment time series data.\n\n**3. Quantification of Feedback and Reactivation**\n\nThe comparison between the two models allows us to quantify the influence of $X$ on $Y$.\n\n-   **Predictive Gain ($G$):** The improvement in prediction accuracy from including the $X$ terms is measured by the fractional reduction in the sum of squared residuals:\n    $$G = \\frac{\\mathrm{SSR}_{\\mathrm{restricted}} - \\mathrm{SSR}_{\\mathrm{unrestricted}}}{\\mathrm{SSR}_{\\mathrm{restricted}}}$$\n    A larger value of $G$ indicates a stronger predictive influence from $X$ to $Y$.\n\n-   **Sign of Influence ($S$):** The nature of the feedback (inhibitory vs. activatory) is determined by the sign of the sum of the estimated coefficients for the $X$ lags in the unrestricted model:\n    $$S = \\sum_{i=1}^{p} \\hat{\\gamma}_i = \\hat{\\gamma}_1 + \\hat{\\gamma}_2$$\n    A value of $S < 0$ indicates, on average, a negative or inhibitory feedback from $X$ to $Y$.\n\n**4. Detection Criterion for Relief-of-Feedback Reactivation**\n\nThe phenomenon of relief-of-feedback reactivation is declared present if three specific conditions, based on the metrics derived above, are met simultaneously. These criteria formalize the biological hypothesis:\n\n1.  **Pre-treatment Negative Feedback:** There must be a sufficiently strong negative feedback from $X$ to $Y$ before treatment. This is captured by a predictive gain $G_{\\mathrm{pre}}$ exceeding a threshold $\\tau_{\\mathrm{gain}}$ and a negative influence sign $S_{\\mathrm{pre}} < 0$.\n    $$G_{\\mathrm{pre}} \\geq \\tau_{\\mathrm{gain}} \\quad \\text{and} \\quad S_{\\mathrm{pre}} < 0$$\n    with $\\tau_{\\mathrm{gain}} = 0.05$.\n\n2.  **Post-treatment Reduction of Feedback:** The inhibition of $X$ must lead to a significant reduction in its influence on $Y$. This is confirmed if the post-treatment predictive gain $G_{\\mathrm{post}}$ is substantially smaller than the pre-treatment gain.\n    $$G_{\\mathrm{post}} \\leq \\lambda \\, G_{\\mathrm{pre}}$$\n    with $\\lambda = 0.5$.\n\n3.  **Post-treatment Reactivation of Y:** The relief of negative feedback from $X$ should cause the activity level of $Y$ to rise. This is verified by comparing the mean levels of $Y$ before and after treatment.\n    $$\\overline{Y}_{\\mathrm{post}} \\geq (1+\\rho) \\, \\overline{Y}_{\\mathrm{pre}}$$\n    with $\\rho = 0.1$.\n\n**5. Computational Implementation**\n\nFor each test case, the algorithm proceeds as follows:\n-   A fixed random seed is set to ensure reproducibility.\n-   A continuous time series for $X$ and $Y$ is generated, encompassing both pre- and post-treatment phases according to the specified VAR parameters.\n-   The full time series is partitioned into pre- and post-treatment segments for analysis.\n-   For each segment, the OLS procedure is applied to fit the restricted and unrestricted models, from which $\\mathrm{SSR}$ values are calculated.\n-   The metrics $G$ and $S$ are computed for the pre-treatment phase, and $G$ is computed for the post-treatment phase. The mean levels $\\overline{Y}_{\\mathrm{pre}}$ and $\\overline{Y}_{\\mathrm{post}}$ are also calculated.\n-   The three conditions of the detection criterion are evaluated to yield a final boolean result for the test case.\n-   The results for all four test cases are compiled into a list.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef perform_inference(X_data, Y_data, p):\n    \"\"\"\n    Performs Granger causality inference using OLS.\n\n    Args:\n        X_data (np.ndarray): Time series for variable X.\n        Y_data (np.ndarray): Time series for variable Y.\n        p (int): Lag order.\n\n    Returns:\n        tuple: A tuple containing:\n            - G (float): Predictive gain.\n            - S (float): Sum of influence coefficients.\n    \"\"\"\n    num_points = len(Y_data)\n    num_samples = num_points - p\n\n    if num_samples <= p * 2: # Not enough data points to fit the model\n        return 0.0, 0.0\n\n    # Target variable for regression\n    y_target = Y_data[p:]\n\n    # --- Restricted Model: Y_t ~ 1 + Y_{t-1} + Y_{t-2} ---\n    M_restr = np.ones((num_samples, p + 1))\n    for i in range(p):\n        M_restr[:, i + 1] = Y_data[p - (i + 1) : num_points - (i + 1)]\n\n    _, ssr_restr_list, _, _ = np.linalg.lstsq(M_restr, y_target, rcond=None)\n    ssr_restr = ssr_restr_list[0] if len(ssr_restr_list) > 0 else np.sum((y_target - np.mean(y_target))**2)\n\n    # --- Unrestricted Model: Y_t ~ 1 + Y_{t-1} + Y_{t-2} + X_{t-1} + X_{t-2} ---\n    M_unrestr = np.ones((num_samples, 1 + 2 * p))\n    # Y lags\n    for i in range(p):\n        M_unrestr[:, i + 1] = Y_data[p - (i + 1) : num_points - (i + 1)]\n    # X lags\n    for i in range(p):\n        M_unrestr[:, p + i + 1] = X_data[p - (i + 1) : num_points - (i + 1)]\n\n    coeffs_unrestr, ssr_unrestr_list, _, _ = np.linalg.lstsq(M_unrestr, y_target, rcond=None)\n    ssr_unrestr = ssr_unrestr_list[0] if len(ssr_unrestr_list) > 0 else np.sum((y_target - np.mean(y_target))**2)\n    \n    # Calculate G (predictive gain)\n    if ssr_restr == 0:\n        G = 0.0 if ssr_unrestr == 0 else 1.0\n    else:\n        G = (ssr_restr - ssr_unrestr) / ssr_restr\n\n    # Calculate S (sum of influence coefficients)\n    # The coefficients for X lags are the last p elements\n    S = np.sum(coeffs_unrestr[p + 1:])\n\n    return G, S\n\ndef simulate_var(params):\n    \"\"\"\n    Simulates time-series data from a VAR(p) model for pre- and post-treatment.\n    \"\"\"\n    T_pre, T_post, p = params['T_pre'], params['T_post'], params['p']\n    sigma_y, sigma_x = params['sigma_y'], params['sigma_x']\n    \n    total_duration = T_pre + T_post\n    X = np.zeros(total_duration + p)\n    Y = np.zeros(total_duration + p)\n    \n    noise_y = np.random.normal(0, sigma_y, total_duration)\n    noise_x = np.random.normal(0, sigma_x, total_duration)\n\n    # Pre-treatment parameters\n    a_y1, a_y2 = params['a_y1'], params['a_y2']\n    c_xy1, c_xy2 = params['c_xy1'], params['c_xy2']\n    b_y = params['b_y']\n    a_x1_pre, a_x2 = params['a_x1'], params['a_x2']\n    d_y1 = params['d_y1']\n    b_x_pre = params['b_x']\n    \n    # Post-treatment parameters (inhibited)\n    s_x = params['s_x']\n    a_x1_post = a_x1_pre * s_x\n    b_x_post = b_x_pre * s_x\n    \n    for t in range(p, total_duration + p):\n        # Determine which set of parameters to use\n        if t < T_pre + p:\n            a_x1_current = a_x1_pre\n            b_x_current = b_x_pre\n        else:\n            a_x1_current = a_x1_post\n            b_x_current = b_x_post\n            \n        noise_idx = t - p\n        \n        Y[t] = (a_y1 * Y[t-1] + a_y2 * Y[t-2] +\n                c_xy1 * X[t-1] + c_xy2 * X[t-2] +\n                b_y + noise_y[noise_idx])\n                \n        X[t] = (a_x1_current * X[t-1] + a_x2 * X[t-2] +\n                d_y1 * Y[t-1] +\n                b_x_current + noise_x[noise_idx])\n                \n    return X, Y\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    # Use a fixed random seed for reproducibility.\n    np.random.seed(42)\n\n    test_cases = [\n        { # Case 1\n            \"T_pre\": 300, \"T_post\": 300, \"p\": 2, \"sigma_y\": 0.1, \"sigma_x\": 0.1,\n            \"a_y1\": 0.7, \"a_y2\": 0.2, \"a_x1\": 0.6, \"a_x2\": 0.1,\n            \"c_xy1\": -0.8, \"c_xy2\": 0.0, \"d_y1\": 0.1, \"b_y\": 1.0, \"b_x\": 0.5, \"s_x\": 0.2\n        },\n        { # Case 2\n            \"T_pre\": 300, \"T_post\": 300, \"p\": 2, \"sigma_y\": 0.15, \"sigma_x\": 0.15,\n            \"a_y1\": 0.6, \"a_y2\": 0.2, \"a_x1\": 0.6, \"a_x2\": 0.1,\n            \"c_xy1\": -0.2, \"c_xy2\": 0.0, \"d_y1\": 0.1, \"b_y\": 1.0, \"b_x\": 0.5, \"s_x\": 1.0\n        },\n        { # Case 3\n            \"T_pre\": 300, \"T_post\": 300, \"p\": 2, \"sigma_y\": 0.5, \"sigma_x\": 0.5,\n            \"a_y1\": 0.7, \"a_y2\": 0.2, \"a_x1\": 0.6, \"a_x2\": 0.1,\n            \"c_xy1\": -0.7, \"c_xy2\": 0.0, \"d_y1\": 0.1, \"b_y\": 1.0, \"b_x\": 0.5, \"s_x\": 0.2\n        },\n        { # Case 4\n            \"T_pre\": 60, \"T_post\": 60, \"p\": 2, \"sigma_y\": 0.3, \"sigma_x\": 0.3,\n            \"a_y1\": 0.7, \"a_y2\": 0.2, \"a_x1\": 0.6, \"a_x2\": 0.1,\n            \"c_xy1\": -0.7, \"c_xy2\": 0.0, \"d_y1\": 0.1, \"b_y\": 1.0, \"b_x\": 0.5, \"s_x\": 0.2\n        }\n    ]\n\n    results = []\n    \n    # Thresholds for detection criterion\n    tau_gain = 0.05\n    lambda_val = 0.5\n    rho = 0.1\n\n    for case_params in test_cases:\n        p = case_params['p']\n        T_pre = case_params['T_pre']\n        T_post = case_params['T_post']\n\n        X_series, Y_series = simulate_var(case_params)\n\n        # Pre-treatment analysis\n        X_pre_segment = X_series[0 : T_pre + p]\n        Y_pre_segment = Y_series[0 : T_pre + p]\n        G_pre, S_pre = perform_inference(X_pre_segment, Y_pre_segment, p)\n        mean_Y_pre = np.mean(Y_series[p : T_pre + p])\n        \n        # Post-treatment analysis\n        # Segment starts at T_pre to include last p points of pre-treatment as initial lags\n        X_post_segment = X_series[T_pre : T_pre + T_post + p]\n        Y_post_segment = Y_series[T_pre : T_pre + T_post + p]\n        G_post, _ = perform_inference(X_post_segment, Y_post_segment, p)\n        mean_Y_post = np.mean(Y_series[T_pre + p:])\n\n        # Apply detection criterion\n        cond1 = (G_pre >= tau_gain) and (S_pre < 0)\n        cond2 = (G_post <= lambda_val * G_pre)\n        cond3 = (mean_Y_post >= (1 + rho) * mean_Y_pre)\n        \n        detection_result = cond1 and cond2 and cond3\n        results.append(detection_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [r for r in results]))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The evolution of drug resistance is an emergent property of the entire tumor ecosystem, influenced by factors beyond cell-intrinsic genetics. Spatial heterogeneity in the microenvironment, such as variable drug exposure due to distance from blood vessels, can create sanctuaries where tumor cells survive and evolve resistance. In this capstone exercise , you will build a comprehensive stochastic simulation to integrate pharmacokinetics, pharmacodynamics, and population dynamics, providing a virtual laboratory to investigate how such spatial heterogeneity impacts the time to clinical progression.",
            "id": "4396524",
            "problem": "You are tasked with building a complete, runnable program that simulates the emergence time of resistance in a spatial tumor model where drug concentration decays with distance from blood vessels, and then determines how heterogeneity in exposure shifts the distribution of time to progression. The simulation must be based on core mechanistic principles relevant to systems biomedicine and tumor evolution.\n\nFundamental bases and core definitions to be used:\n- Steady-state diffusion-decay of a drug from a point source in tissue implies an exponential drop-off with distance. For a homogeneous field of vessels, this can be approximated by the functional form $C(r) = C_0 \\exp(-r/\\lambda)$, where $C(r)$ is drug concentration at distance $r$, $C_0$ is the near-vessel concentration, and $\\lambda$ is a decay length scale determined by diffusion and clearance.\n- The nearest-vessel distance in a two-dimensional homogeneous Poisson point process (PPP) has the probability density function $f_R(r) = 2 \\pi \\rho_v r \\exp(-\\pi \\rho_v r^2)$ with cumulative distribution function $F_R(r) = 1 - \\exp(-\\pi \\rho_v r^2)$, which yields sampling via $r = \\sqrt{-\\ln(1-U)/(\\pi \\rho_v)}$ for $U \\sim \\mathrm{Uniform}(0,1)$.\n- Pharmacodynamics (PD) under a simple Hill-$1$ model yields a fractional effect $E(C) = \\frac{C}{C + EC_{50}}$, where $E(C)$ is the effect (unitless), $C$ is the concentration, and $EC_{50}$ is the concentration at half-maximal effect. The drug-induced death rate contribution is scaled by a parameter $k_{\\mathrm{pd}}$.\n- Tumor cell population dynamics per microregion follows birth-death with logistic limitation. For sensitive cells, per-microregion births per unit time are $b_s N_s \\left(1 - \\frac{N_s + N_r}{K}\\right)$ and deaths per unit time are $\\left(d_0 + k_{\\mathrm{pd}} E(C)\\right) N_s$. For resistant cells, births are $b_r N_r \\left(1 - \\frac{N_s + N_r}{K}\\right)$ and deaths are $\\left(d_0 + \\alpha_r k_{\\mathrm{pd}} E(C)\\right) N_r$, where $N_s$ and $N_r$ are sensitive and resistant counts in the microregion, $K$ is carrying capacity per microregion, $b_s$ and $b_r$ are baseline birth rates, $d_0$ is baseline death rate, and $\\alpha_r \\in [0,1]$ scales the drug effect on resistant cells.\n- Mutational conversion from sensitive to resistant occurs during sensitive divisions, with mutation probability $\\mu$ per sensitive birth event. That is, of the $b_s N_s \\left(1 - \\frac{N_s + N_r}{K}\\right)$ sensitive birth events in a time step, a fraction $\\mu$ produce resistant daughter cells rather than sensitive ones.\n\nYou will implement a discrete-time tau-leaping approximation to the stochastic birth-death-mutation process:\n- At each time step of size $\\Delta t$, for each microregion, sample births and deaths as Poisson random variables with means given by the rates above multiplied by $\\Delta t$. Split sensitive births into mutated resistant births using a Binomial random variable with parameters equal to the number of sensitive births and success probability $\\mu$.\n- Update counts ensuring non-negativity. Track the total resistant population across microregions $N_r^{\\mathrm{tot}}(t) = \\sum_i N_{r,i}(t)$ and define progression time $T_{\\mathrm{prog}}$ as the first time $t$ when $N_r^{\\mathrm{tot}}(t) \\ge N_{\\mathrm{prog}}$. If no progression occurs up to a maximum time $T_{\\max}$, set $T_{\\mathrm{prog}} = T_{\\max}$ (right-censoring).\n\nSpatial heterogeneity specification:\n- For the heterogeneous cases, sample nearest-vessel distances $r_i$ for each microregion $i$ using the PPP formula and compute $C_i = C_0 \\exp(-r_i/\\lambda)$.\n- For the homogeneous exposure case, set $C_i = C_0$ for all microregions.\n\nOutputs and units:\n- Report the median progression time across stochastic replicates for each test case as a float in days. Express the final results in days and round each to two decimal places.\n\nTest suite:\nUse the following parameter sets, expressed as a tuple per test case. The parameters are $(N_0, M, K_{\\mathrm{factor}}, b_s, b_r, d_0, k_{\\mathrm{pd}}, \\alpha_r, \\mu, C_0, EC_{50}, \\lambda, \\rho_v, \\Delta t, T_{\\max}, N_{\\mathrm{prog}}, R, \\text{heterogeneous})$, where:\n- $N_0$ is the initial total sensitive cell count,\n- $M$ is the number of microregions,\n- $K_{\\mathrm{factor}}$ defines per-microregion carrying capacity $K = K_{\\mathrm{factor}} \\cdot \\frac{N_0}{M}$,\n- $b_s$ and $b_r$ are birth rates (per day),\n- $d_0$ is baseline death rate (per day),\n- $k_{\\mathrm{pd}}$ is drug kill scaling (per day),\n- $\\alpha_r$ is resistant drug scaling,\n- $\\mu$ is mutation probability per sensitive birth,\n- $C_0$ and $EC_{50}$ are concentrations (arbitrary units, internally consistent),\n- $\\lambda$ is the decay length (same spatial units as $r$),\n- $\\rho_v$ is vessel intensity in the PPP (in units of inverse area, internally consistent),\n- $\\Delta t$ is the time step (days),\n- $T_{\\max}$ is the maximum simulated time (days),\n- $N_{\\mathrm{prog}}$ is the progression threshold in resistant cells,\n- $R$ is the number of stochastic replicates,\n- $\\text{heterogeneous}$ is a boolean: $1$ for heterogeneous exposure, $0$ for homogeneous exposure.\n\nProvide the following three test cases:\n1. Case A (homogeneous exposure, baseline drug potency): $(N_0 = 10^6, M = 200, K_{\\mathrm{factor}} = 3, b_s = 0.035, b_r = 0.030, d_0 = 0.010, k_{\\mathrm{pd}} = 0.120, \\alpha_r = 0.100, \\mu = 10^{-7}, C_0 = 10, EC_{50} = 2, \\lambda = 30, \\rho_v = 5 \\times 10^{-4}, \\Delta t = 0.2, T_{\\max} = 200, N_{\\mathrm{prog}} = 5 \\times 10^4, R = 30, \\text{heterogeneous} = 0)$.\n2. Case B (moderate heterogeneity): $(N_0 = 10^6, M = 200, K_{\\mathrm{factor}} = 3, b_s = 0.035, b_r = 0.030, d_0 = 0.010, k_{\\mathrm{pd}} = 0.120, \\alpha_r = 0.100, \\mu = 10^{-7}, C_0 = 10, EC_{50} = 2, \\lambda = 30, \\rho_v = 5 \\times 10^{-4}, \\Delta t = 0.2, T_{\\max} = 200, N_{\\mathrm{prog}} = 5 \\times 10^4, R = 30, \\text{heterogeneous} = 1)$.\n3. Case C (extreme heterogeneity, sparse vessels with steep decay): $(N_0 = 10^6, M = 200, K_{\\mathrm{factor}} = 3, b_s = 0.035, b_r = 0.030, d_0 = 0.010, k_{\\mathrm{pd}} = 0.120, \\alpha_r = 0.100, \\mu = 10^{-7}, C_0 = 10, EC_{50} = 2, \\lambda = 15, \\rho_v = 5 \\times 10^{-5}, \\Delta t = 0.2, T_{\\max} = 200, N_{\\mathrm{prog}} = 5 \\times 10^4, R = 30, \\text{heterogeneous} = 1)$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the median progression times (in days) for Cases A, B, and C, rounded to two decimal places, as a comma-separated list enclosed in square brackets, for example, `[12.34,56.78,90.12]`.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It provides a formal specification for a stochastic simulation based on established principles in systems biomedicine, including population dynamics (logistic growth, birth-death processes), pharmacokinetics (exponential drug decay), pharmacodynamics (Hill-1 effect model), and stochastic processes (Poisson point process, tau-leaping approximation). All parameters and conditions are explicitly defined, creating a self-contained and computationally solvable problem.\n\nThe task is to simulate the emergence of drug resistance in a tumor modeled as a collection of microregions. The simulation will be performed for three scenarios: one with homogeneous drug exposure and two with heterogeneous exposure derived from a spatial model of blood vessels. The core of the solution is a discrete-time stochastic simulation using the tau-leaping method.\n\nThe implementation will proceed through the following steps for each test case:\n\n1.  **Parameter Initialization**: For each test case, the parameters $(N_0, M, K_{\\mathrm{factor}}, b_s, b_r, d_0, k_{\\mathrm{pd}}, \\alpha_r, \\mu, C_0, EC_{50}, \\lambda, \\rho_v, \\Delta t, T_{\\max}, N_{\\mathrm{prog}}, R, \\text{heterogeneous})$ are defined. A key derived parameter is the per-microregion carrying capacity, $K = K_{\\mathrm{factor}} \\cdot (N_0/M)$.\n\n2.  **Stochastic Replicates**: The simulation is repeated $R$ times to account for stochasticity. For each replicate, a progression time is calculated. The final result for the test case is the median of these $R$ progression times.\n\n3.  **Spatial and Drug Exposure Setup (per Replicate)**:\n    *   **Homogeneous Case ($\\text{heterogeneous} = 0$)**: The drug concentration $C_i$ is set to $C_0$ for all $M$ microregions.\n    *   **Heterogeneous Case ($\\text{heterogeneous} = 1$)**: For each of the $M$ microregions, a nearest-vessel distance $r_i$ is sampled. The distribution of these distances follows that of a 2D homogeneous Poisson Point Process (PPP) with vessel intensity $\\rho_v$. We sample $r_i$ using inverse transform sampling from the cumulative distribution function $F_R(r) = 1 - \\exp(-\\pi \\rho_v r^2)$. Setting a uniform random variate $U_i \\sim \\mathrm{Uniform}(0,1)$ equal to $F_R(r_i)$ and solving for $r_i$ gives $r_i = \\sqrt{-\\ln(1-U_i)/(\\pi \\rho_v)}$. Since $1-U_i$ is also uniformly distributed, we use the equivalent formulation $r_i = \\sqrt{-\\ln(U'_i)/(\\pi \\rho_v)}$, where $U'_i \\sim \\mathrm{Uniform}(0,1)$. The drug concentration in microregion $i$ is then calculated as $C_i = C_0 \\exp(-r_i/\\lambda)$.\n    *   The drug effect $E_i$ in each microregion is then computed using the Hill-1 equation: $E_i = C_i / (C_i + EC_{50})$. This vector of effects is constant throughout a single simulation replicate.\n\n4.  **Initial Population State (per Replicate)**: The tumor begins with a total of $N_0$ sensitive cells and no resistant cells. These are distributed evenly across the microregions: $N_{s,i}(t=0) = N_0/M$ and $N_{r,i}(t=0) = 0$ for all $i=1, \\dots, M$.\n\n5.  **Tau-Leaping Simulation (per Replicate)**: The system evolves in discrete time steps of size $\\Delta t$ from $t=0$ to $T_{\\max}$. At each time step:\n    *   The simulation state is represented by two vectors, $\\mathbf{N}_s$ and $\\mathbf{N}_r$, of size $M$, holding the counts of sensitive and resistant cells in each microregion.\n    *   The logistic growth term is calculated for each microregion: $P_i = (N_{s,i} + N_{r,i}) / K$. The birth rate multiplier is $(1 - P_i)$, which is set to $0$ if $P_i > 1$ to prevent negative birth rates.\n    *   The rates for four events (sensitive birth, sensitive death, resistant birth, resistant death) are calculated for each microregion $i$:\n        *   Rate of sensitive births: $\\mathcal{R}_{b_s, i} = b_s N_{s,i} \\max(0, 1 - P_i)$\n        *   Rate of sensitive deaths: $\\mathcal{R}_{d_s, i} = (d_0 + k_{\\mathrm{pd}} E_i) N_{s,i}$\n        *   Rate of resistant births: $\\mathcal{R}_{b_r, i} = b_r N_{r,i} \\max(0, 1 - P_i)$\n        *   Rate of resistant deaths: $\\mathcal{R}_{d_r, i} = (d_0 + \\alpha_r k_{\\mathrm{pd}} E_i) N_{r,i}$\n    *   The number of events occurring in the interval $\\Delta t$ is sampled from a Poisson distribution with mean equal to the rate multiplied by $\\Delta t$. For instance, the number of sensitive births in microregion $i$ is $\\Delta B_{s,i} \\sim \\mathrm{Poisson}(\\mathcal{R}_{b_s, i} \\cdot \\Delta t)$. This is performed for all four events across all $M$ microregions, efficiently handled using vectorized operations.\n    *   Mutations are handled by sampling from a Binomial distribution. Out of the $\\Delta B_{s,i}$ sensitive birth events, the number that result in a resistant daughter cell is $\\Delta M_{i} \\sim \\mathrm{Binomial}(\\Delta B_{s,i}, \\mu)$.\n    *   The cell counts are updated:\n        *   $N_{s,i}(t+\\Delta t) = N_{s,i}(t) + \\Delta B_{s,i} - \\Delta M_i - \\Delta D_{s,i}$\n        *   $N_{r,i}(t+\\Delta t) = N_{r,i}(t) + \\Delta B_{r,i} + \\Delta M_i - \\Delta D_{r,i}$\n    *   To correct for the artifact of the tau-leaping approximation where deaths can exceed the population, counts are floored at zero: $N_{s,i} = \\max(0, N_{s,i})$ and $N_{r,i} = \\max(0, N_{r,i})$.\n\n6.  **Progression and Censoring**: After each time step, the total resistant population $N_r^{\\mathrm{tot}} = \\sum_i N_{r,i}$ is calculated. If $N_r^{\\mathrm{tot}} \\ge N_{\\mathrm{prog}}$, the simulation for that replicate is stopped, and the progression time $T_{\\mathrm{prog}}$ is recorded as the current time $t+\\Delta t$. If the simulation reaches $T_{\\max}$ without the resistant population reaching the threshold, the progression time is right-censored and recorded as $T_{\\max}$.\n\n7.  **Final Calculation and Output**: After all $R$ replicates are completed for a test case, the median of the recorded progression times is computed. This process is repeated for all three test cases, and the resulting median times are rounded to two decimal places and printed in the specified format. The use of NumPy allows for efficient, vectorized computation across all microregions simultaneously, which is essential for the performance of the simulation.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef run_simulation(params):\n    \"\"\"\n    Runs a single simulation case for a given set of parameters.\n    \"\"\"\n    (N0, M, K_factor, bs, br, d0, k_pd, alpha_r, mu, C0, EC50, \n     lambda_decay, rho_v, dt, T_max, N_prog, R, heterogeneous) = params\n\n    # Derived parameters\n    K = K_factor * (N0 / M)\n    \n    progression_times = np.zeros(R)\n    \n    rng = np.random.default_rng()\n\n    for i in range(R):\n        # Initialize populations\n        Ns = np.full(M, N0 / M)\n        Nr = np.zeros(M)\n        \n        # Set up drug concentration profile for the replicate\n        if heterogeneous:\n            # Sample M uniform random numbers for distance calculation\n            # Use clipping to avoid log(0)\n            u = rng.uniform(low=np.finfo(float).eps, high=1.0, size=M)\n            r = np.sqrt(-np.log(u) / (np.pi * rho_v))\n            C = C0 * np.exp(-r / lambda_decay)\n        else:\n            C = np.full(M, C0)\n        \n        # Calculate drug effect E\n        E = C / (C + EC50)\n        \n        # Pre-calculate death rate components\n        sensitive_death_mult = d0 + k_pd * E\n        resistant_death_mult = d0 + alpha_r * k_pd * E\n        \n        # Time loop\n        prog_time_found = False\n        num_steps = int(T_max / dt)\n        \n        for t_step in range(num_steps):\n            current_time = t_step * dt\n            \n            # Ensure population counts are integers for stochastic sampling\n            Ns = Ns.astype(np.int64)\n            Nr = Nr.astype(np.int64)\n\n            # Prevent division by zero if K is zero.\n            if K > 0:\n                population_pressure = (Ns + Nr) / K\n            else:\n                population_pressure = np.inf\n\n            growth_factor = np.maximum(0, 1 - population_pressure)\n            \n            # Calculate event rates\n            rate_bs = bs * Ns * growth_factor\n            rate_ds = sensitive_death_mult * Ns\n            rate_br = br * Nr * growth_factor\n            rate_dr = resistant_death_mult * Nr\n            \n            # Sample event counts using Poisson distribution\n            mean_bs = rate_bs * dt\n            mean_ds = rate_ds * dt\n            mean_br = rate_br * dt\n            mean_dr = rate_dr * dt\n\n            delta_Bs = rng.poisson(mean_bs)\n            delta_Ds = rng.poisson(mean_ds)\n            delta_Br = rng.poisson(mean_br)\n            delta_Dr = rng.poisson(mean_dr)\n            \n            # Sample mutations from sensitive births\n            mutations = rng.binomial(delta_Bs, mu)\n            \n            # Update populations\n            Ns_new = Ns + delta_Bs - mutations - delta_Ds\n            Nr_new = Nr + delta_Br + mutations - delta_Dr\n            \n            # Enforce non-negativity\n            Ns = np.maximum(0, Ns_new)\n            Nr = np.maximum(0, Nr_new)\n\n            # Check for progression\n            if np.sum(Nr) >= N_prog:\n                progression_times[i] = current_time + dt\n                prog_time_found = True\n                break\n        \n        # Handle censoring if progression not reached\n        if not prog_time_found:\n            progression_times[i] = T_max\n            \n    return np.median(progression_times)\n\ndef solve():\n    \"\"\"\n    Defines test cases and runs simulations to find median progression times.\n    \"\"\"\n    # Define test cases as per the problem description.\n    # (N0, M, K_factor, bs, br, d0, k_pd, alpha_r, mu, C0, EC50, \n    #  lambda_decay, rho_v, dt, T_max, N_prog, R, heterogeneous)\n    test_cases = [\n        # Case A: Homogeneous exposure\n        (1e6, 200, 3, 0.035, 0.030, 0.010, 0.120, 0.100, 1e-7, 10, 2, 30, 5e-4, 0.2, 200, 5e4, 30, 0),\n        # Case B: Moderate heterogeneity\n        (1e6, 200, 3, 0.035, 0.030, 0.010, 0.120, 0.100, 1e-7, 10, 2, 30, 5e-4, 0.2, 200, 5e4, 30, 1),\n        # Case C: Extreme heterogeneity\n        (1e6, 200, 3, 0.035, 0.030, 0.010, 0.120, 0.100, 1e-7, 10, 2, 15, 5e-5, 0.2, 200, 5e4, 30, 1)\n    ]\n\n    results = []\n    for params in test_cases:\n        median_time = run_simulation(params)\n        results.append(round(median_time, 2))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}