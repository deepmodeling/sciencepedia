{
    "hands_on_practices": [
        {
            "introduction": "Complex biomolecular networks often have a heterogeneous structure, with some regions being densely interconnected while others are sparse. This practice introduces a fundamental algorithmic tool, $k$-core decomposition, for dissecting this structure. By deriving and implementing an algorithm to iteratively peel away the least connected nodes, you will learn how to identify the nested hierarchy of cores within a network, revealing its most structurally robust subgraphs . This technique is essential for pinpointing critical functional modules that are resilient to the loss of peripheral components.",
            "id": "4367933",
            "problem": "Consider an undirected simple graph with no self-loops represented by an adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ that is symmetric with zeros on the diagonal. Let $G = (V,E)$ denote the graph, where $V = \\{0,1,\\dots,n-1\\}$ is the set of nodes and $E$ is the set of edges with $(i,j) \\in E$ if and only if $A_{ij} = 1$. The degree of a node $i$ is $d(i) = \\sum_{j=0}^{n-1} A_{ij}$. A subgraph $H$ induced by $S \\subseteq V$ is the pair $(S, E|_S)$ where $E|_S = \\{(i,j) \\in E \\mid i \\in S, j \\in S\\}$. The $k$-core of $G$ is defined as the unique maximal induced subgraph $H_k$ such that every node in $H_k$ has degree at least $k$ when degrees are computed with respect to $H_k$. The core number (also called coreness) of a node $i$ is the largest integer $k \\ge 0$ such that $i \\in H_k$.\n\nTask: Starting from the core definitions above and the basic notion of iterative constraint satisfaction on graphs (remove nodes that violate a local degree threshold until a fixed point is reached), derive an algorithm that computes, for a given adjacency matrix $A$, the core number vector $c \\in \\mathbb{Z}_{\\ge 0}^n$ where $c_i$ is the core number of node $i$. Your derivation must identify why the fixed-point iterative pruning procedure terminates, why the resulting subgraph is maximal, and why the largest $k$ for which a node $i$ survives equals its core number.\n\nEpistemic significance requirement: Explain, in formal terms grounded in the above definitions, why the $k$-core identifies substructures that are robust under removal of low-degree nodes, and how this relates to resilience analysis in systems biomedicine where biological interaction networks exhibit modularity and redundancy.\n\nComputation requirement: Implement the algorithm you derive and apply it to the following test suite of adjacency matrices. For each test case, compute and return the list of core numbers in node index order $[0,1,\\dots,n-1]$.\n\nTest suite:\n- Case A (mixed dense and sparse structure, $n=6$):\n$$\nA^{(A)} =\n\\begin{pmatrix}\n0 & 1 & 1 & 1 & 0 & 1 \\\\\n1 & 0 & 1 & 0 & 0 & 1 \\\\\n1 & 1 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 & 0 & 0 \\\\\n1 & 1 & 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n$$\n- Case B (empty graph, $n=4$):\n$$\nA^{(B)} =\n\\begin{pmatrix}\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n$$\n- Case C (complete graph $K_5$, $n=5$):\n$$\nA^{(C)} =\n\\begin{pmatrix}\n0 & 1 & 1 & 1 & 1 \\\\\n1 & 0 & 1 & 1 & 1 \\\\\n1 & 1 & 0 & 1 & 1 \\\\\n1 & 1 & 1 & 0 & 1 \\\\\n1 & 1 & 1 & 1 & 0 \\\\\n\\end{pmatrix}\n$$\n- Case D (star graph with center at node $0$, $n=6$):\n$$\nA^{(D)} =\n\\begin{pmatrix}\n0 & 1 & 1 & 1 & 1 & 1 \\\\\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n1 & 0 & 0 & 0 & 0 & 0 \\\\\n\\end{pmatrix}\n$$\n\nFinal output specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result is the list of core numbers for a test case, in node index order. For example, the format must be $[\\,[c^{(A)}_0,\\dots,c^{(A)}_{n_A-1}],\\,[c^{(B)}_0,\\dots,c^{(B)}_{n_B-1}],\\,[c^{(C)}_0,\\dots,c^{(C)}_{n_C-1}],\\,[c^{(D)}_0,\\dots,c^{(D)}_{n_D-1}]\\,]$. All reported values are integers with no physical units. The program must run without user input.",
            "solution": "The problem requires the derivation and implementation of an algorithm to compute the core number for each node in a graph specified by an adjacency matrix $A$.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n- **Graph representation**: Undirected simple graph $G=(V,E)$ with $V=\\{0, 1, \\dots, n-1\\}$, no self-loops. Represented by a symmetric adjacency matrix $A \\in \\{0,1\\}^{n \\times n}$ with zeros on the diagonal. An edge $(i,j) \\in E$ exists if and only if $A_{ij}=1$.\n- **Node degree**: The degree of a node $i$ is $d(i) = \\sum_{j=0}^{n-1} A_{ij}$.\n- **Induced subgraph**: For a subset of vertices $S \\subseteq V$, the induced subgraph $H=(S, E|_S)$ contains the nodes $S$ and all edges from $E$ that connect two nodes in $S$.\n- **$k$-core**: The unique maximal induced subgraph $H_k$ where every node in $H_k$ has a degree of at least $k$ with respect to the subgraph $H_k$.\n- **Core number (coreness)**: The core number of a node $i$, denoted $c_i$, is the largest integer $k \\ge 0$ such that node $i$ is a member of the vertex set of the $k$-core, $H_k$.\n- **Task**: Derive an algorithm to compute the core number vector $c \\in \\mathbb{Z}_{\\ge 0}^n$. The derivation must justify the algorithm's correctness (termination, maximality, etc.).\n- **Epistemic Requirement**: Explain the relationship between $k$-cores, robustness, and their application in systems biomedicine.\n- **Computation Requirement**: Implement the algorithm and apply it to four test cases: $A^{(A)}$, $A^{(B)}$, $A^{(C)}$, and $A^{(D)}$.\n- **Output Format**: A single line containing a list of lists of core numbers, e.g., `[[c_A], [c_B], [c_C], [c_D]]`.\n\n**1.2. Validate Using Extracted Givens**\nThe problem is assessed against the validation criteria:\n- **Scientifically Grounded**: All definitions (graph, adjacency matrix, degree, induced subgraph, $k$-core, core number) are standard and fundamental concepts in graph theory and network science. The problem is scientifically and mathematically sound.\n- **Well-Posed**: The definitions are precise and unambiguous. For any given graph, the $k$-core is uniquely defined, and consequently, the core number of each node is also uniquely determined. The problem is well-posed.\n- **Objective**: The problem is stated in formal mathematical language, free from subjectivity or bias.\n- **Completeness and Consistency**: The problem provides all necessary definitions and data (the adjacency matrices for the test cases). There are no contradictions.\n\n**1.3. Verdict and Action**\nThe problem is **valid**. A solution will be provided.\n\n### Step 2: Algorithm Derivation and Justification\n\n**2.1. Finding the $k$-core for a fixed $k$**\n\nThe definition of the $k$-core suggests an algorithm based on iterative constraint satisfaction. The constraint is that every node in the target subgraph must have a degree of at least $k$. We can find the $k$-core by starting with the entire graph $G$ and iteratively removing any nodes that violate this constraint.\n\nLet $G_0 = G$. For $t = 0, 1, 2, \\dots$, let $G_t = (V_t, E_t)$ be the graph at step $t$.\n1. Identify the set of nodes to be removed: $S_t = \\{v \\in V_t \\mid \\deg_{G_t}(v) < k\\}$.\n2. If $S_t$ is empty, the process has reached a fixed point. The current graph $G_t$ is the $k$-core.\n3. If $S_t$ is not empty, form the next graph $G_{t+1}$ by removing the nodes in $S_t$ and their incident edges. $G_{t+1}$ is the subgraph of $G_t$ induced by the vertex set $V_{t+1} = V_t \\setminus S_t$.\n4. Repeat from step 1.\n\n**Justification:**\n- **Termination**: The graph is finite. At each step where $S_t$ is non-empty, at least one node is removed from the graph. Since nodes are never added, this process must terminate in at most $n$ steps.\n- **Correctness**: The resulting subgraph, let's call it $H'$, contains only nodes with degree at least $k$ within $H'$, by construction.\n- **Maximality**: To show $H'$ is the unique *maximal* such subgraph, we use proof by contradiction. Assume there exists another induced subgraph $H''$ satisfying the $k$-core property (all nodes have degree $\\ge k$ within $H''$), such that $V(H') \\subset V(H'')$. Let $v$ be a node in $V(H'') \\setminus V(H')$. Since $v$ is not in $H'$, it must have been removed by our algorithm at some step $t$. This means its degree in the graph $G_t$ was less than $k$, i.e., $\\deg_{G_t}(v) < k$. However, at that step $t$, the vertex set $V_t$ was a superset of $V(H'')$, because $v$ had not yet been removed. Therefore, the degree of $v$ in $G_t$ must be greater than or equal to its degree in $H''$: $\\deg_{G_t}(v) \\ge \\deg_{H''}(v)$. By the premise for $H''$, we know $\\deg_{H''}(v) \\ge k$. This leads to the contradiction $\\deg_{G_t}(v) \\ge k$. Thus, no such $H''$ can exist, and the subgraph $H'$ found by the algorithm is the unique maximal $k$-core.\n\n**2.2. Computing Core Numbers for All Nodes**\n\nThe core number $c_i$ is the largest $k$ such that node $i$ is in the $k$-core $H_k$. This is equivalent to saying that $c_i=k$ if node $i$ is in $H_k$ but not in $H_{k+1}$. This directly suggests an algorithm. The set of all nodes with core number $k$ is $V(H_k) \\setminus V(H_{k+1})$.\n\nThe $k$-cores form a nested sequence of subgraphs: $G \\supseteq H_1 \\supseteq H_2 \\supseteq \\dots \\supseteq H_{k_{\\text{max}}}$. We can find the core numbers by iteratively peeling away the outermost layers of the graph.\n\n**Algorithm:**\n1. Initialize a mutable array of current degrees, `d_current`, with the degrees of all nodes in the original graph $G$.\n2. Initialize a `cores` array of size $n$ with a sentinel value (e.g., $-1$) indicating that no core number has been assigned yet.\n3. Initialize a variable for the current core level, `k = 0`.\n4. While there are still nodes with unassigned core numbers:\n    a. Repeatedly find all active nodes `v` (where `cores[v]` is still the sentinel value) whose current degree `d_current[v]` is less than or equal to `k`.\n    b. If no such nodes exist, increment `k` and go to step 4a.\n    c. For each such node `v`:\n        i. Assign its core number: `cores[v] = k`.\n        ii. \"Remove\" `v` from the graph (conceptually, by marking it as processed).\n        iii. For each neighbor `u` of `v`, decrement its current degree: `d_current[u] -= 1`.\n    d. Repeat step 4a without incrementing `k`, as the degree reduction may cause other nodes to now satisfy the condition `d_current <= k`.\n5. The `cores` array now holds the core number for each node.\n\nThis \"level-by-level\" peeling process ensures that when a node `v` is removed at level `k`, it is because its degree has dropped to `k` (or less), and it cannot be part of any higher-order core. The set of nodes removed at stage `k` are precisely those that belong to the `k`-core but not the `(k+1)`-core.\n\n### Step 3: Epistemic Significance in Systems Biomedicine\n\nThe $k$-core decomposition provides a topologically-grounded method for identifying influential or central parts of a network, which is highly relevant to the analysis of biological systems.\n\n- **Robustness and Resilience**: In network theory, robustness refers to the ability of a system to maintain its function despite perturbations, such as the removal of nodes or edges. The $k$-core structure formalizes one aspect of this. The innermost core, $H_{k_{\\text{max}}}$, represents the most densely interconnected and resilient part of the network. Removing low-degree (peripheral) nodes does not affect the integrity of this core. A node with a high core number $c_i$ is structurally embedded in a robust neighborhood, meaning its removal would require the prior or simultaneous failure of many other nodes in its local, dense community.\n\n- **Modularity and Redundancy in Biological Networks**: Biological networks, such as protein-protein interaction (PPI) networks or gene regulatory networks, are known to be modular. These modules often correspond to groups of biomolecules that cooperate to perform a specific biological function (e.g., a protein complex or a signaling pathway). High-order cores frequently map to these functional modules. The high interconnectivity within a core provides redundancy; if one protein (node) is knocked out, its function may be compensated for by its numerous partners within the same core, making the overall function resilient to single-point failures. For example, in a PPI network, the $k_{\\text{max}}$-core may comprise proteins essential for cell survival, forming a stable complex. Identifying such cores helps researchers pinpoint critical components of cellular machinery, which can be potential targets for drug development or biomarkers for disease. Peripheral nodes (low core numbers) may be involved in less critical or more transient functions, connecting different modules or responding to external stimuli.\n\n### Step 4: Implementation and Computation\n\nThe derived algorithm is implemented to process the given test suite of adjacency matrices. The results are computed and formatted as specified.\n\nThe implemented algorithm follows the \"level-by-level\" peeling logic derived in Section 2.2. It iterates through core levels `k` from $0$ upwards. In each iteration, it repeatedly finds and \"removes\" all nodes whose current degree has fallen to `k` or below, assigning them the core number `k`. This process continues until all nodes have been assigned a core number.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the core number computation problem for the given test suite.\n    \"\"\"\n\n    def compute_core_numbers(A: np.ndarray) -> list[int]:\n        \"\"\"\n        Computes the core number for each node in a graph given by its adjacency matrix.\n        \n        The algorithm is based on iteratively peeling away nodes. It works by levels.\n        For a level k, it removes all nodes with degree <= k. This is repeated until\n        a fixed point is reached for the current k. Then k is incremented. The core\n        number of a node is the level k at which it is removed.\n\n        Args:\n            A: A numpy array representing the symmetric adjacency matrix of the graph.\n\n        Returns:\n            A list of integers representing the core number of each node.\n        \"\"\"\n        n = A.shape[0]\n        if n == 0:\n            return []\n\n        # Make a copy of degrees to be modified during the peeling process.\n        current_degrees = A.sum(axis=1).astype(int)\n        \n        # core_numbers[i] will store the core number of node i.\n        # Initialize with -1 to mark nodes as unprocessed.\n        core_numbers = np.full(n, -1, dtype=int)\n        \n        nodes_processed = 0\n        k = 0 # Start with the 0-core level.\n\n        while nodes_processed < n:\n            # Iteratively remove nodes with degree <= k at the current level.\n            # This inner loop continues until no more nodes can be removed at level k.\n            was_node_removed_in_pass = True\n            while was_node_removed_in_pass:\n                was_node_removed_in_pass = False\n                nodes_to_remove_this_pass = []\n                \n                # Find all unprocessed nodes with degree <= k.\n                for i in range(n):\n                    if core_numbers[i] == -1 and current_degrees[i] <= k:\n                        nodes_to_remove_this_pass.append(i)\n\n                if nodes_to_remove_this_pass:\n                    was_node_removed_in_pass = True\n                    # Process the removal of these nodes.\n                    for v in nodes_to_remove_this_pass:\n                        # Assign core number and mark as processed.\n                        core_numbers[v] = k\n                        nodes_processed += 1\n                        \n                        # Decrement the degrees of its neighbors.\n                        # We iterate through the adjacency matrix row for node v.\n                        for u in range(n):\n                            if A[v, u] == 1:\n                                current_degrees[u] -= 1\n            \n            # Move to the next core level.\n            k += 1\n            \n        return core_numbers.tolist()\n\n\n    # Test Suite from the problem statement.\n    A_A = np.array([\n        [0, 1, 1, 1, 0, 1],\n        [1, 0, 1, 0, 0, 1],\n        [1, 1, 0, 0, 0, 0],\n        [1, 0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0, 0],\n        [1, 1, 0, 0, 0, 0],\n    ])\n\n    A_B = np.array([\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n        [0, 0, 0, 0],\n    ])\n\n    A_C = np.array([\n        [0, 1, 1, 1, 1],\n        [1, 0, 1, 1, 1],\n        [1, 1, 0, 1, 1],\n        [1, 1, 1, 0, 1],\n        [1, 1, 1, 1, 0],\n    ])\n\n    A_D = np.array([\n        [0, 1, 1, 1, 1, 1],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n    ])\n\n    test_cases = [A_A, A_B, A_C, A_D]\n    \n    results = [compute_core_numbers(A) for A in test_cases]\n\n    # Format the results into the required string format.\n    # Ex: [[2,2,2,1,1,2],[0,0,0,0],[4,4,4,4,4],[1,1,1,1,1,1]]\n    result_str = \",\".join(map(str, results))\n    result_str = result_str.replace(\" \", \"\") # Remove spaces for compact representation.\n\n    print(f\"[{result_str}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "While network structure provides a static picture of robustness, biological function is inherently dynamic. This practice shifts our focus from static topology to the temporal resilience of a system's state. You will analyze a linearized model of a genetic negative feedback circuit, a ubiquitous motif in cellular regulation, and apply Lyapunov stability theory to formally assess its behavior . By constructing a Lyapunov function, you will not only prove the system's stability but also derive a quantitative bound on its return time to equilibrium after a perturbation, providing a concrete measure of its dynamic resilience.",
            "id": "4367859",
            "problem": "Consider a minimal negative feedback motif modeling a gene-protein regulatory circuit in systems biomedicine. Let $x(t)$ denote the concentration of an output species and $y(t)$ denote a regulatory inhibitor that is produced proportionally to $x(t)$ and represses $x(t)$ production. Let the upstream input $u(t)$ represent an external transcriptional drive. Near a nominal operating point, linearization of standard mass-action and first-order degradation kinetics yields the two-dimensional ordinary differential equation (ODE) model\n$$\n\\frac{d}{dt}\\begin{pmatrix}x(t)\\\\y(t)\\end{pmatrix} = A\\begin{pmatrix}x(t)\\\\y(t)\\end{pmatrix} + B u(t),\n$$\nwhere\n$$\nA = \\begin{pmatrix}-1.5 & -1.0 \\\\ 2.0 & -3.0\\end{pmatrix},\\quad B = \\begin{pmatrix}1.0 \\\\ 0.0\\end{pmatrix}.\n$$\nAll rate constants are in units of $\\text{min}^{-1}$, so time is measured in minutes, and $x(t)$ and $y(t)$ are in consistent concentration units. Assume the system is initially at the steady state corresponding to the constant input $u(t)\\equiv u_{0}$ for $t<0$. At $t=0$, a step perturbation is applied that changes the input to a new constant $u(t)\\equiv u_{1}$ for all $t\\ge 0$. Take $u_{0}=0$ and $u_{1}=1$.\n\nStarting from fundamental stability concepts in dynamical systems and control, specifically Lyapunov stability theory, do the following:\n\n1. Construct a Lyapunov function for the error dynamics about the new equilibrium for $t\\ge 0$. That is, define the error $z(t) = \\big(x(t),y(t)\\big)^{\\top} - \\big(x^{\\ast}(u_{1}),y^{\\ast}(u_{1})\\big)^{\\top}$, where $\\big(x^{\\ast}(u),y^{\\ast}(u)\\big)$ is the equilibrium satisfying $A\\begin{pmatrix}x^{\\ast}(u)\\\\y^{\\ast}(u)\\end{pmatrix} + B\\,u = \\begin{pmatrix}0\\\\0\\end{pmatrix}$. Using a quadratic candidate of the form $V(z) = z^{\\top}Pz$ with a symmetric positive definite matrix $P\\in\\mathbb{R}^{2\\times 2}$, determine $P$ by solving a continuous-time Lyapunov equation with a positive definite right-hand side.\n\n2. Using your Lyapunov function, derive an explicit analytic upper bound $T_{\\delta}$ such that for every $t\\ge T_{\\delta}$, the Euclidean norm of the error satisfies $\\|z(t)\\|\\le \\delta$, with $\\delta = 0.05$. Express $T_{\\delta}$ in closed form in terms of the matrices and parameters of the system and the initial error $z(0)$ induced by the step change.\n\n3. Substitute the given numerical values and compute the numerical value of $T_{\\delta}$ for the specified step perturbation from $u_{0}=0$ to $u_{1}=1$. Round your answer to four significant figures and express the final time in minutes. The final answer must be a single real number.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded, well-posed, objective, and self-contained. The model is a standard linearized representation of a genetic regulatory network, a common approach in systems biomedicine. The system matrix $A$ is Hurwitz, as its trace is $\\text{tr}(A) = -1.5 - 3.0 = -4.5 < 0$ and its determinant is $\\det(A) = (-1.5)(-3.0) - (-1.0)(2.0) = 4.5 + 2.0 = 6.5 > 0$. This ensures the existence of a unique, stable equilibrium for any constant input, making the problem well-posed. All required parameters and conditions are provided, and there are no internal contradictions. We may proceed with the solution.\n\nLet the state vector be $\\mathbf{x}(t) = \\begin{pmatrix}x(t) \\\\ y(t)\\end{pmatrix}$. The system dynamics are given by $\\frac{d\\mathbf{x}}{dt} = A\\mathbf{x}(t) + B u(t)$. An equilibrium state $\\mathbf{x}^{\\ast}(u)$ corresponding to a constant input $u$ is found by setting the time derivative to zero: $A\\mathbf{x}^{\\ast}(u) + B u = \\mathbf{0}$, which yields $\\mathbf{x}^{\\ast}(u) = -A^{-1}Bu$.\n\nFor $t \\ge 0$, the input is constant at $u(t) \\equiv u_1 = 1$. The new equilibrium state is $\\mathbf{x}^{\\ast}(u_1) = -A^{-1}Bu_1$. The error vector is defined as $z(t) = \\mathbf{x}(t) - \\mathbf{x}^{\\ast}(u_1)$. The dynamics of the error are:\n$$\n\\frac{dz(t)}{dt} = \\frac{d\\mathbf{x}(t)}{dt} - \\frac{d\\mathbf{x}^{\\ast}(u_1)}{dt} = (A\\mathbf{x}(t) + Bu_1) - \\mathbf{0}\n$$\nSince $A\\mathbf{x}^{\\ast}(u_1) + Bu_1 = \\mathbf{0}$, we can write $Bu_1 = -A\\mathbf{x}^{\\ast}(u_1)$. Substituting this into the error dynamics equation:\n$$\n\\frac{dz(t)}{dt} = A\\mathbf{x}(t) - A\\mathbf{x}^{\\ast}(u_1) = A(\\mathbf{x}(t) - \\mathbf{x}^{\\ast}(u_1)) = Az(t)\n$$\nThus, the error dynamics are governed by the homogeneous system $\\dot{z} = Az$.\n\n**1. Construction of a Lyapunov function for the error dynamics**\n\nWe seek a quadratic Lyapunov function $V(z) = z^{\\top}Pz$, where $P \\in \\mathbb{R}^{2\\times 2}$ is a symmetric positive definite matrix. The time derivative of $V(z)$ along the trajectories of the system is:\n$$\n\\dot{V}(z) = \\frac{d}{dt}(z^{\\top}Pz) = \\dot{z}^{\\top}Pz + z^{\\top}P\\dot{z} = (Az)^{\\top}Pz + z^{\\top}P(Az) = z^{\\top}(A^{\\top}P + PA)z\n$$\nFor asymptotic stability, $\\dot{V}(z)$ must be negative definite. This can be ensured by choosing $P$ such that $A^{\\top}P + PA = -Q$ for some symmetric positive definite matrix $Q$. This is the continuous-time Lyapunov equation. A standard choice for $Q$ is the identity matrix, $Q=I$, which is positive definite. We solve for $P$ in the equation $A^{\\top}P + PA = -I$.\n\nLet $P = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}$. The equation becomes:\n$$\n\\begin{pmatrix}-1.5 & 2.0 \\\\ -1.0 & -3.0\\end{pmatrix}\\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix} + \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}\\begin{pmatrix}-1.5 & -1.0 \\\\ 2.0 & -3.0\\end{pmatrix} = \\begin{pmatrix}-1 & 0 \\\\ 0 & -1\\end{pmatrix}\n$$\nExpanding the matrix products gives:\n$$\n\\begin{pmatrix} -3p_{11} + 4p_{12} & -p_{11} - 4.5p_{12} + 2p_{22} \\\\ -p_{11} - 4.5p_{12} + 2p_{22} & -2p_{12} - 6p_{22} \\end{pmatrix} = \\begin{pmatrix}-1 & 0 \\\\ 0 & -1\\end{pmatrix}\n$$\nThis yields a system of linear equations for the elements of $P$:\n1) $-3p_{11} + 4p_{12} = -1$\n2) $-p_{11} - 4.5p_{12} + 2p_{22} = 0$\n3) $-2p_{12} - 6p_{22} = -1 \\implies 2p_{12} + 6p_{22} = 1$\n\nFrom (1), $p_{11} = \\frac{1+4p_{12}}{3}$. From (3), $p_{22} = \\frac{1-2p_{12}}{6}$. Substituting these into (2):\n$$\n-\\left(\\frac{1+4p_{12}}{3}\\right) - 4.5p_{12} + 2\\left(\\frac{1-2p_{12}}{6}\\right) = 0\n$$\n$$\n-\\frac{1}{3} - \\frac{4}{3}p_{12} - \\frac{9}{2}p_{12} + \\frac{1}{3} - \\frac{2}{3}p_{12} = 0\n$$\n$$\n\\left(-\\frac{4}{3} - \\frac{9}{2} - \\frac{2}{3}\\right)p_{12} = 0 \\implies \\left(-2 - \\frac{9}{2}\\right)p_{12} = 0 \\implies -6.5p_{12} = 0\n$$\nThus, $p_{12}=0$. Substituting back, we find $p_{11} = 1/3$ and $p_{22} = 1/6$.\nThe matrix $P$ is:\n$$\nP = \\begin{pmatrix} 1/3 & 0 \\\\ 0 & 1/6 \\end{pmatrix}\n$$\nThis matrix is diagonal with positive entries, so it is positive definite. The Lyapunov function is $V(z) = \\frac{1}{3}z_1^2 + \\frac{1}{6}z_2^2$, and its derivative is $\\dot{V}(z) = -z^{\\top}Iz = -\\|z\\|^2$.\n\n**2. Derivation of the upper bound $T_{\\delta}$**\n\nThe Lyapunov function $V(z)$ can be bounded in terms of the squared Euclidean norm $\\|z\\|^2 = z^{\\top}z$. The bounds are related to the minimum and maximum eigenvalues of $P$, $\\lambda_{\\min}(P)$ and $\\lambda_{\\max}(P)$:\n$$\n\\lambda_{\\min}(P)\\|z\\|^2 \\le V(z) \\le \\lambda_{\\max}(P)\\|z\\|^2\n$$\nFor our diagonal matrix $P$, the eigenvalues are the diagonal elements: $\\lambda_{\\min}(P) = 1/6$ and $\\lambda_{\\max}(P) = 1/3$.\nFrom $\\dot{V}(z) = -\\|z\\|^2$ and $\\|z\\|^2 \\ge V(z)/\\lambda_{\\max}(P)$, we get the differential inequality:\n$$\n\\dot{V}(z) \\le -\\frac{V(z)}{\\lambda_{\\max}(P)}\n$$\nBy GrÃ¶nwall's inequality, this implies an exponential decay for $V(z(t))$:\n$$\nV(z(t)) \\le V(z(0)) \\exp\\left(-\\frac{t}{\\lambda_{\\max}(P)}\\right)\n$$\nWe want to find an upper bound on the time $T_{\\delta}$ such that for all $t \\ge T_{\\delta}$, $\\|z(t)\\| \\le \\delta$. This condition is guaranteed if we ensure that $\\|z(t)\\|^2 \\le \\delta^2$.\nUsing the lower bound on $V(z)$, we have $\\|z(t)\\|^2 \\le V(z(t))/\\lambda_{\\min}(P)$.\nSo, the condition $\\|z(t)\\| \\le \\delta$ is met if $V(z(t))/\\lambda_{\\min}(P) \\le \\delta^2$, or $V(z(t)) \\le \\lambda_{\\min}(P)\\delta^2$.\nWe can find $T_{\\delta}$ by setting the upper bound of $V(z(t))$ to this value:\n$$\nV(z(0)) \\exp\\left(-\\frac{T_{\\delta}}{\\lambda_{\\max}(P)}\\right) = \\lambda_{\\min}(P)\\delta^2\n$$\nSolving for $T_{\\delta}$:\n$$\n\\exp\\left(-\\frac{T_{\\delta}}{\\lambda_{\\max}(P)}\\right) = \\frac{\\lambda_{\\min}(P)\\delta^2}{V(z(0))}\n$$\n$$\n-\\frac{T_{\\delta}}{\\lambda_{\\max}(P)} = \\ln\\left(\\frac{\\lambda_{\\min}(P)\\delta^2}{V(z(0))}\\right)\n$$\n$$\nT_{\\delta} = -\\lambda_{\\max}(P) \\ln\\left(\\frac{\\lambda_{\\min}(P)\\delta^2}{V(z(0))}\\right) = \\lambda_{\\max}(P) \\ln\\left(\\frac{V(z(0))}{\\lambda_{\\min}(P)\\delta^2}\\right)\n$$\nThe system is initially at steady state for $u_0=0$. So, $\\mathbf{x}(0) = \\mathbf{x}^{\\ast}(u_0) = -A^{-1}Bu_0 = \\mathbf{0}$. The new equilibrium is $\\mathbf{x}^{\\ast}(u_1) = -A^{-1}Bu_1$.\nThe initial error is $z(0) = \\mathbf{x}(0) - \\mathbf{x}^{\\ast}(u_1) = -A^{-1}B(u_0 - u_1)$.\nThe initial value of the Lyapunov function is $V(z(0)) = z(0)^{\\top}Pz(0) = (-A^{-1}B(u_0 - u_1))^{\\top}P(-A^{-1}B(u_0 - u_1))$.\n$$\nV(z(0)) = (u_1-u_0)^2 (A^{-1}B)^{\\top}P(A^{-1}B)\n$$\nSubstituting this into the expression for $T_{\\delta}$ gives the final analytic form.\n\n**3. Numerical evaluation of $T_{\\delta}$**\n\nFirst, we compute the necessary numerical values.\nThe inverse of $A$ is $A^{-1} = \\frac{1}{\\det(A)}\\begin{pmatrix}-3.0 & 1.0 \\\\ -2.0 & -1.5\\end{pmatrix} = \\frac{1}{6.5}\\begin{pmatrix}-3.0 & 1.0 \\\\ -2.0 & -1.5\\end{pmatrix}$.\nThe initial error $z(0)$ is:\n$$\nz(0) = -A^{-1}B(u_0 - u_1) = -\\frac{1}{6.5}\\begin{pmatrix}-3.0 & 1.0 \\\\ -2.0 & -1.5\\end{pmatrix}\\begin{pmatrix}1.0 \\\\ 0.0\\end{pmatrix}(0-1) = \\frac{1}{6.5}\\begin{pmatrix}-3.0 \\\\ -2.0\\end{pmatrix} = \\frac{1}{13}\\begin{pmatrix}-6 \\\\ -4\\end{pmatrix}\n$$\nNow, we compute $V(z(0)) = z(0)^{\\top}Pz(0)$:\n$$\nV(z(0)) = \\left(\\frac{1}{13}\\begin{pmatrix}-6 \\\\ -4\\end{pmatrix}\\right)^{\\top} \\begin{pmatrix}1/3 & 0 \\\\ 0 & 1/6\\end{pmatrix} \\left(\\frac{1}{13}\\begin{pmatrix}-6 \\\\ -4\\end{pmatrix}\\right) = \\frac{1}{169}\\begin{pmatrix}-6 & -4\\end{pmatrix}\\begin{pmatrix}1/3 & 0 \\\\ 0 & 1/6\\end{pmatrix}\\begin{pmatrix}-6 \\\\ -4\\end{pmatrix}\n$$\n$$\nV(z(0)) = \\frac{1}{169}\\left(\\frac{1}{3}(-6)^2 + \\frac{1}{6}(-4)^2\\right) = \\frac{1}{169}\\left(\\frac{36}{3} + \\frac{16}{6}\\right) = \\frac{1}{169}\\left(12 + \\frac{8}{3}\\right) = \\frac{1}{169}\\left(\\frac{44}{3}\\right) = \\frac{44}{507}\n$$\nWe have the following parameters:\n- $\\lambda_{\\max}(P) = 1/3$\n- $\\lambda_{\\min}(P) = 1/6$\n- $V(z(0)) = 44/507$\n- $\\delta = 0.05 = 1/20 \\implies \\delta^2 = 1/400$\n\nWe substitute these values into the expression for $T_{\\delta}$:\n$$\nT_{\\delta} = \\lambda_{\\max}(P) \\ln\\left(\\frac{V(z(0))}{\\lambda_{\\min}(P)\\delta^2}\\right) = \\frac{1}{3} \\ln\\left(\\frac{44/507}{(1/6)(1/400)}\\right)\n$$\n$$\nT_{\\delta} = \\frac{1}{3} \\ln\\left(\\frac{44/507}{1/2400}\\right) = \\frac{1}{3} \\ln\\left(\\frac{44 \\times 2400}{507}\\right)\n$$\nSince $507 = 3 \\times 169$ and $2400 = 3 \\times 800$, we can simplify the argument of the logarithm:\n$$\n\\frac{44 \\times 2400}{507} = \\frac{44 \\times 3 \\times 800}{3 \\times 169} = \\frac{44 \\times 800}{169} = \\frac{35200}{169}\n$$\nSo, the final analytical expression for the time is:\n$$\nT_{\\delta} = \\frac{1}{3} \\ln\\left(\\frac{35200}{169}\\right)\n$$\nNumerically, this value is:\n$$\nT_{\\delta} \\approx \\frac{1}{3} \\ln(208.28402...) \\approx \\frac{1}{3}(5.33890...) \\approx 1.779634...\n$$\nRounding to four significant figures, we get $T_{\\delta} \\approx 1.780$. The units are minutes.",
            "answer": "$$\\boxed{1.780}$$"
        },
        {
            "introduction": "A central goal in systems and synthetic biology is to build complex functions from simpler, modular parts, but connecting these modules can introduce unintended interactions that compromise robustness. This exercise confronts this challenge by exploring the concept of retroactivity, where a downstream load alters the behavior of an upstream signaling module . Your task is to mathematically analyze this effect and derive the design specifications for a buffer device that can insulate the module and maintain its functional integrity, a crucial step in engineering predictable and resilient biological systems.",
            "id": "4367911",
            "problem": "Consider an upstream gene-expression module that produces a transcription factor species $X$ in a mammalian cell. Let the module be characterized at steady state by a production rate proportional to an input $U$ and a first-order degradation of the total $X$ (free plus complexes), so that the steady-state total $X$ is $X_{\\text{tot}} = \\alpha U/\\gamma$, where $\\alpha$ is a positive proportionality constant and $\\gamma$ is the first-order degradation rate constant. When the module is connected to a downstream load consisting of $L_{\\text{tot}}$ identical binding sites (for example, promoter sites), $X$ binds these sites with a one-to-one reversible interaction characterized by a dissociation constant $K_{d}^{L}$ under rapid binding equilibrium. To buffer the retroactivity induced by the load, an insulation device is introduced upstream: a buffer protein $B$ that binds $X$ one-to-one with dissociation constant $K_{d}^{B}$ under rapid binding equilibrium. Assume that complexes $XL$ and $XB$ are not consumed or produced by any other reactions and that degradation is applied to the total $X$ at rate $\\gamma X_{\\text{tot}}$. Under these assumptions, the steady-state free $X$ concentration, $X_{\\text{free}}$, is determined by mass conservation and rapid equilibrium, and depends on $X_{\\text{tot}}$, $L_{\\text{tot}}$, $B_{\\text{tot}}$, $K_{d}^{L}$, and $K_{d}^{B}$.\n\nDefine robustness to load in terms of the log-sensitivity of $X_{\\text{free}}$ to the total load sites as $S \\equiv \\left|\\frac{\\partial \\ln X_{\\text{free}}}{\\partial \\ln L_{\\text{tot}}}\\right|$. Starting from mass-action binding and conservation laws and the definition of $S$, derive an analytic expression for the minimum buffer pool $B_{\\text{tot}}$ that ensures $S \\leq \\delta$ at a specified operating point $X_{\\text{free}} = X^{\\ast}$, where $\\delta$ is a given small positive constant. Then evaluate this minimum $B_{\\text{tot}}$ numerically for the following scientifically realistic parameter values: $L_{\\text{tot}} = 80$ nanomolar (nM), $K_{d}^{L} = 20$ nM, $K_{d}^{B} = 5$ nM, $X^{\\ast} = 120$ nM, and $\\delta = 0.10$. Express your final numeric answer for $B_{\\text{tot}}$ in nM, and round your answer to three significant figures.",
            "solution": "The user has provided a problem from the field of systems biomedicine, concerning the design of an insulation device to buffer retroactivity in a gene-expression module. I will first validate the problem statement according to the required protocol.\n\n### Step 1: Extract Givens\n- System components: a transcription factor species $X$, an input $U$, a downstream load $L$, and a buffer protein $B$.\n- Upstream module steady-state total concentration of $X$: $X_{\\text{tot}} = \\alpha U/\\gamma$, where $\\alpha > 0$ and $\\gamma$ is the degradation rate constant.\n- Load interaction: $X$ binds to $L_{\\text{tot}}$ identical sites in a one-to-one reversible interaction with dissociation constant $K_{d}^{L}$, under rapid binding equilibrium.\n- Buffer interaction: $X$ binds to $B$ in a one-to-one reversible interaction with dissociation constant $K_{d}^{B}$, under rapid binding equilibrium.\n- Assumptions: Complexes $XL$ and $XB$ are stable (not consumed or produced by other reactions). Degradation applies to total $X$ at rate $\\gamma X_{\\text{tot}}$.\n- Definition of robustness to load: Log-sensitivity $S \\equiv \\left|\\frac{\\partial \\ln X_{\\text{free}}}{\\partial \\ln L_{\\text{tot}}}\\right|$.\n- Objective 1 (Analytical): Derive an analytic expression for the minimum buffer pool, $B_{\\text{tot}}$, that ensures $S \\leq \\delta$ at a specified operating point $X_{\\text{free}} = X^{\\ast}$, where $\\delta$ is a small positive constant.\n- Objective 2 (Numerical): Evaluate the minimum $B_{\\text{tot}}$ for the given parameters: $L_{\\text{tot}} = 80$ nM, $K_{d}^{L} = 20$ nM, $K_{d}^{B} = 5$ nM, $X^{\\ast} = 120$ nM, and $\\delta = 0.10$.\n- Final answer requirements: Provide the numerical value for $B_{\\text{tot}}$ in units of nM, rounded to three significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, employing standard models of biochemical interactions (mass-action kinetics, rapid equilibrium) and sensitivity analysis from systems biology. The concepts of retroactivity, buffering, and log-sensitivity are central to this field. The language is precise and objective. The problem is well-posed, providing all necessary definitions, relationships, and parameters to derive a unique solution. The model is a valid simplification of a real biological system, and the numerical values are within a realistic range for intracellular biochemical parameters. No scientific, logical, or structural flaws are detected.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation and Solution\n\nThe problem requires us to find the minimum total buffer concentration, $B_{\\text{tot}}$, needed to achieve a specified level of robustness, $S \\leq \\delta$, at a particular operating point for the free transcription factor, $X_{\\text{free}} = X^{\\ast}$.\n\nFirst, we establish the governing biochemical equations based on mass conservation and rapid binding equilibria. Let $X_{\\text{free}}$, $B_{\\text{free}}$, and $L_{\\text{free}}$ denote the concentrations of free $X$, $B$, and $L$ sites, respectively. Let $[XB]$ and $[XL]$ be the concentrations of the complexes.\n\nThe total concentrations are conserved:\n$1.$ Total $X$: $X_{\\text{tot}} = X_{\\text{free}} + [XB] + [XL]$\n$2.$ Total buffer: $B_{\\text{tot}} = B_{\\text{free}} + [XB]$\n$3.$ Total load: $L_{\\text{tot}} = L_{\\text{free}} + [XL]$\n\nThe rapid binding equilibria are described by the dissociation constants:\n$4.$ Buffer binding: $K_{d}^{B} = \\frac{X_{\\text{free}} B_{\\text{free}}}{[XB]}$\n$5.$ Load binding: $K_{d}^{L} = \\frac{X_{\\text{free}} L_{\\text{free}}}{[XL]}$\n\nFrom these equations, we express the concentrations of the complexes in terms of total concentrations and $X_{\\text{free}}$. From equations $(2)$ and $(4)$:\n$[XB] = \\frac{X_{\\text{free}} B_{\\text{free}}}{K_{d}^{B}} = \\frac{X_{\\text{free}} (B_{\\text{tot}} - [XB])}{K_{d}^{B}}$\nSolving for $[XB]$ gives:\n$[XB](K_{d}^{B} + X_{\\text{free}}) = X_{\\text{free}} B_{\\text{tot}} \\implies [XB] = \\frac{B_{\\text{tot}} X_{\\text{free}}}{K_{d}^{B} + X_{\\text{free}}}$\n\nSimilarly, from equations $(3)$ and $(5)$:\n$[XL] = \\frac{L_{\\text{tot}} X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}}$\n\nSubstituting these expressions into the mass conservation equation for $X$ (1) yields the central equation of the system:\n$$ X_{\\text{tot}} = X_{\\text{free}} + \\frac{B_{\\text{tot}} X_{\\text{free}}}{K_{d}^{B} + X_{\\text{free}}} + \\frac{L_{\\text{tot}} X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} $$\nThis equation implicitly defines $X_{\\text{free}}$ as a function of the system's total species concentrations $X_{\\text{tot}}$, $B_{\\text{tot}}$, and $L_{\\text{tot}}$.\n\nNext, we derive the expression for the log-sensitivity, $S$.\n$$ S = \\left|\\frac{\\partial \\ln X_{\\text{free}}}{\\partial \\ln L_{\\text{tot}}}\\right| = \\left|\\frac{L_{\\text{tot}}}{X_{\\text{free}}} \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}}\\right| $$\nTo find the derivative $\\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}}$, we perform implicit differentiation on the central equation with respect to $L_{\\text{tot}}$, treating $X_{\\text{tot}}$ and $B_{\\text{tot}}$ as constants.\n$$ \\frac{\\partial}{\\partial L_{\\text{tot}}} (X_{\\text{tot}}) = \\frac{\\partial}{\\partial L_{\\text{tot}}} \\left( X_{\\text{free}} + \\frac{B_{\\text{tot}} X_{\\text{free}}}{K_{d}^{B} + X_{\\text{free}}} + \\frac{L_{\\text{tot}} X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} \\right) $$\n$$ 0 = \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} + \\frac{d}{d X_{\\text{free}}} \\left(\\frac{B_{\\text{tot}} X_{\\text{free}}}{K_{d}^{B} + X_{\\text{free}}}\\right) \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} + \\frac{\\partial}{\\partial L_{\\text{tot}}}\\left(\\frac{L_{\\text{tot}} X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}}\\right) $$\nUsing the quotient rule for the buffer term:\n$\\frac{d}{d X_{\\text{free}}} \\left(\\frac{B_{\\text{tot}} X_{\\text{free}}}{K_{d}^{B} + X_{\\text{free}}}\\right) = \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2}$\nUsing the product rule and quotient rule for the load term:\n$\\frac{\\partial}{\\partial L_{\\text{tot}}}\\left(\\frac{L_{\\text{tot}} X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}}\\right) = \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} + L_{\\text{tot}} \\frac{d}{d X_{\\text{free}}}\\left(\\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}}\\right)\\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} = \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}}$\nSubstituting these back into the differentiated equation:\n$$ 0 = \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2} \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} + \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} $$\nSolving for $\\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}}$:\n$$ \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} \\left( 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} \\right) = - \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} $$\n$$ \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} = - \\frac{ \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} }{ 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} } $$\nSince an increase in load $L_{\\text{tot}}$ sequesters more $X$, $X_{\\text{free}}$ must decrease, so $\\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} < 0$. The absolute value in the definition of $S$ removes the negative sign.\n$$ S = \\frac{L_{\\text{tot}}}{X_{\\text{free}}} \\left| \\frac{\\partial X_{\\text{free}}}{\\partial L_{\\text{tot}}} \\right| = \\frac{L_{\\text{tot}}}{X_{\\text{free}}} \\frac{ \\frac{X_{\\text{free}}}{K_{d}^{L} + X_{\\text{free}}} }{ 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} } $$\n$$ S = \\frac{ \\frac{L_{\\text{tot}}}{K_{d}^{L} + X_{\\text{free}}} }{ 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X_{\\text{free}})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X_{\\text{free}})^2} } $$\nWe require $S \\leq \\delta$ at the operating point $X_{\\text{free}} = X^{\\ast}$. The minimum $B_{\\text{tot}}$ that satisfies this condition is found by setting $S = \\delta$:\n$$ \\delta = \\frac{ \\frac{L_{\\text{tot}}}{K_{d}^{L} + X^{\\ast}} }{ 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X^{\\ast})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} } $$\nNow, we solve for $B_{\\text{tot}}$:\n$$ \\delta \\left( 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X^{\\ast})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} \\right) = \\frac{L_{\\text{tot}}}{K_{d}^{L} + X^{\\ast}} $$\n$$ 1 + \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X^{\\ast})^2} + \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} = \\frac{L_{\\text{tot}}}{\\delta (K_{d}^{L} + X^{\\ast})} $$\n$$ \\frac{B_{\\text{tot}} K_{d}^{B}}{(K_{d}^{B} + X^{\\ast})^2} = \\frac{L_{\\text{tot}}}{\\delta (K_{d}^{L} + X^{\\ast})} - 1 - \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} $$\nMultiplying by $\\frac{(K_{d}^{B} + X^{\\ast})^2}{K_{d}^{B}}$ yields the analytical expression for the minimum $B_{\\text{tot}}$:\n$$ B_{\\text{tot}} = \\frac{(K_{d}^{B} + X^{\\ast})^2}{K_{d}^{B}} \\left[ \\frac{L_{\\text{tot}}}{\\delta(K_{d}^{L} + X^{\\ast})} - 1 - \\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} \\right] $$\nThis is the required analytical solution.\n\nFinally, we evaluate this expression using the provided numerical parameters:\n- $L_{\\text{tot}} = 80$ nM\n- $K_{d}^{L} = 20$ nM\n- $K_{d}^{B} = 5$ nM\n- $X^{\\ast} = 120$ nM\n- $\\delta = 0.10$\n\nWe calculate the components of the expression:\n- $K_{d}^{L} + X^{\\ast} = 20 + 120 = 140$ nM\n- $K_{d}^{B} + X^{\\ast} = 5 + 120 = 125$ nM\n\nNow, the terms inside the square brackets:\n- Term 1: $\\frac{L_{\\text{tot}}}{\\delta(K_{d}^{L} + X^{\\ast})} = \\frac{80}{0.10 \\times 140} = \\frac{80}{14} = \\frac{40}{7}$\n- Term 2: $1$\n- Term 3: $\\frac{L_{\\text{tot}} K_{d}^{L}}{(K_{d}^{L} + X^{\\ast})^2} = \\frac{80 \\times 20}{(140)^2} = \\frac{1600}{19600} = \\frac{16}{196} = \\frac{4}{49}$\n\nThe value of the bracketed expression is:\n$$ \\frac{40}{7} - 1 - \\frac{4}{49} = \\frac{40 \\times 7}{49} - \\frac{49}{49} - \\frac{4}{49} = \\frac{280 - 49 - 4}{49} = \\frac{227}{49} $$\nThe pre-factor is:\n$$ \\frac{(K_{d}^{B} + X^{\\ast})^2}{K_{d}^{B}} = \\frac{(125)^2}{5} = \\frac{15625}{5} = 3125 \\text{ nM} $$\nCombining these results to find $B_{\\text{tot}}$:\n$$ B_{\\text{tot}} = 3125 \\times \\frac{227}{49} = \\frac{709375}{49} \\approx 14477.0408... \\text{ nM} $$\nThe problem requires the answer to be rounded to three significant figures.\n$14477.0408...$ nM rounds to $14500$ nM. In scientific notation, this is $1.45 \\times 10^4$ nM.",
            "answer": "$$\\boxed{1.45 \\times 10^{4}}$$"
        }
    ]
}