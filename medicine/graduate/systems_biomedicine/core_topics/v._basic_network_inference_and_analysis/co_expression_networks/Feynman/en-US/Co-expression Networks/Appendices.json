{
    "hands_on_practices": [
        {
            "introduction": "The foundation of building a co-expression network lies in transforming raw correlation data into a topologically meaningful structure. This first practice provides a concrete, step-by-step guide to the core mechanics of Weighted Gene Co-expression Network Analysis (WGCNA). By working through a small three-gene system, you will learn how to compute a weighted adjacency matrix from Pearson correlations and then refine it into the widely used Topological Overlap Measure (TOM) .",
            "id": "2854762",
            "problem": "In systems genetics, gene co-expression networks are constructed by transforming pairwise gene-gene correlations into a weighted adjacency, and then quantifying node proximity via the Topological Overlap Measure (TOM). Consider three genes, $G_{1}$, $G_{2}$, and $G_{3}$, with a symmetric matrix of pairwise Pearson correlations given by $r_{12} = 0.8$, $r_{13} = 0.3$, and $r_{23} = -0.4$, and $r_{ii} = 1$ for $i \\in \\{1,2,3\\}$. Use the unsigned Weighted Gene Co-expression Network Analysis (WGCNA) convention with soft-thresholding power $\\beta = 6$ to construct the weighted adjacency, and then compute the weighted Topological Overlap Measure (TOM) between $G_{1}$ and $G_{2}$. Assume the standard WGCNA convention that self-adjacencies satisfy $a_{ii} = 0$.\n\nPerform the following:\n- From the given pairwise correlations, compute all off-diagonal adjacency entries $a_{ij}$.\n- Using the standard weighted definition of TOM used in Weighted Gene Co-expression Network Analysis (WGCNA), compute the TOM between $G_{1}$ and $G_{2}$.\n\nReport as your final answer only the TOM between $G_{1}$ and $G_{2}$, rounded to four significant figures. No units are required.",
            "solution": "The problem statement is scientifically grounded, well-posed, and provides all necessary information for a unique solution. It is a standard application of the Weighted Gene Co-expression Network Analysis (WGCNA) methodology. We will proceed with the calculation.\n\nThe first step is to construct the weighted adjacency matrix, $A = [a_{ij}]$, from the given Pearson correlation matrix, $R = [r_{ij}]$. For an unsigned network, the adjacency $a_{ij}$ between genes $i$ and $j$ is calculated using a soft-thresholding power $\\beta$. The formula is:\n$$a_{ij} = |r_{ij}|^{\\beta}$$\nThe problem provides the soft-thresholding power $\\beta = 6$. The given non-diagonal Pearson correlations are $r_{12} = 0.8$, $r_{13} = 0.3$, and $r_{23} = -0.4$. The adjacency matrix is symmetric ($a_{ij} = a_{ji}$), and the problem specifies the diagonal elements are zero ($a_{ii} = 0$). We compute the required off-diagonal adjacency entries:\n$$a_{12} = |r_{12}|^{\\beta} = |0.8|^{6} = (0.8)^{6} = 0.262144$$\n$$a_{13} = |r_{13}|^{\\beta} = |0.3|^{6} = (0.3)^{6} = 0.000729$$\n$$a_{23} = |r_{23}|^{\\beta} = |-0.4|^{6} = (0.4)^{6} = 0.004096$$\n\nThe second step is to compute the Topological Overlap Measure (TOM) between genes $G_1$ and $G_2$, denoted as $\\omega_{12}$. The standard formula for the weighted TOM is:\n$$\\omega_{ij} = \\frac{l_{ij} + a_{ij}}{\\min(k_i, k_j) + 1 - a_{ij}}$$\nHere, $k_i$ is the total network connectivity (or node degree) of gene $i$, and $l_{ij}$ represents the shared connectivity between genes $i$ and $j$. These terms are defined as:\n$$k_i = \\sum_{u \\neq i} a_{iu}$$\n$$l_{ij} = \\sum_{u \\neq i, j} a_{iu} a_{uj}$$\nWe must calculate these quantities for the pair $(i, j) = (1, 2)$.\n\nFirst, we compute the connectivities $k_1$ and $k_2$:\n$$k_1 = \\sum_{u \\neq 1} a_{1u} = a_{12} + a_{13} = 0.262144 + 0.000729 = 0.262873$$\n$$k_2 = \\sum_{u \\neq 2} a_{2u} = a_{21} + a_{23} = a_{12} + a_{23} = 0.262144 + 0.004096 = 0.26624$$\n\nNext, we calculate the shared connectivity term $l_{12}$. The sum is over all nodes $u$ that are not $1$ or $2$. In this three-gene system, the only such node is $u=3$.\n$$l_{12} = \\sum_{u \\neq 1, 2} a_{1u} a_{u2} = a_{13} a_{32} = a_{13} a_{23}$$\n$$l_{12} = (0.000729) \\times (0.004096) = 0.000002985984 = 2.985984 \\times 10^{-6}$$\n\nNow we have all components to calculate $\\omega_{12}$. The numerator is:\n$$l_{12} + a_{12} = 2.985984 \\times 10^{-6} + 0.262144 = 0.262146985984$$\nThe denominator requires $\\min(k_1, k_2)$:\n$$\\min(k_1, k_2) = \\min(0.262873, 0.26624) = 0.262873$$\nSo, the denominator is:\n$$\\min(k_1, k_2) + 1 - a_{12} = 0.262873 + 1 - 0.262144 = 1.000729$$\n\nFinally, we compute the TOM value $\\omega_{12}$:\n$$\\omega_{12} = \\frac{0.262146985984}{1.000729} \\approx 0.26196232$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\\omega_{12} \\approx 0.2620$$\nThis value represents the topological overlap between genes $G_1$ and $G_2$, which quantifies their similarity based on both their direct connection and their shared connections with other genes in the network.",
            "answer": "$$\\boxed{0.2620}$$"
        },
        {
            "introduction": "After learning how to calculate the Topological Overlap Measure (TOM), it is crucial to understand *why* it is such a powerful tool for network inference. This practice moves beyond pure calculation to provide a conceptual and quantitative demonstration of TOM's primary function: to enhance signal and reduce noise. You will explore how TOM re-weights network edges based on shared neighborhood context, effectively penalizing spurious connections and reinforcing those embedded within coherent modules .",
            "id": "4328763",
            "problem": "You are tasked with formalizing, from first principles, why the Topological Overlap Measure (TOM) reduces spurious connections in weighted co-expression networks that arise from single high-correlation edges without broader topological support, and then quantifying this effect on several small, scientifically plausible test networks. Begin from the following foundational bases that are standard in systems biomedicine and gene co-expression analysis.\n\nBase definitions and assumptions:\n- A gene co-expression network is an undirected weighted graph over $n$ genes, where the weight between gene $i$ and gene $j$ is a function of their pairwise Pearson correlation $r_{ij}$, with $-1 \\le r_{ij} \\le 1$ and $r_{ii} = 1$ by definition.\n- A soft-thresholded adjacency for a Weighted Gene Co-expression Network Analysis (WGCNA)-style network is constructed as $a_{ij} = |r_{ij}|^\\beta$ for $i \\ne j$, with $a_{ii} = 0$ and $\\beta > 0$. This is a well-tested approach for emphasizing strong correlations while preserving continuous weights.\n- The Topological Overlap Measure (TOM) between two nodes is a function that depends on the weighted shared neighborhood overlap and their node degrees. It is widely used to refine adjacency by accounting for network topology rather than pairwise correlation alone.\n\nYour program must implement the following, without relying on any external input:\n1. Given a symmetric correlation matrix $R \\in \\mathbb{R}^{n \\times n}$ with $R_{ii} = 1$ and $|R_{ij}| \\le 1$, and a soft-threshold exponent $\\beta > 0$, compute the weighted adjacency $A$ as $A_{ij} = |R_{ij}|^\\beta$ for $i \\ne j$ and $A_{ii} = 0$.\n2. Compute the Weighted Topological Overlap Measure (TOM) matrix $T$ from $A$ based on the standard neighborhood-overlap construction that incorporates shared neighbor connectivity and node degrees. Use the symmetric formulation that depends on the pairwise shared-neighbor sum and a denominator that includes the smaller of the two degrees and a normalization term that prevents inflation when there is no shared neighborhood support.\n3. For a designated edge $(p,q)$ in each test network, compute the reduction factor $r_{pq} = T_{pq} / A_{pq}$, which quantifies how TOM modifies the raw adjacency for that edge. This factor is a dimensionless float.\n\nConceptual target:\n- Provide a conceptual argument, supported by the mathematics codified in your implementation, that explains why TOM down-weights edges that lack shared neighbors despite having high pairwise correlation, and why TOM tends to preserve edges that are embedded within shared neighborhoods. The argument should derive its logic from the interplay between shared neighbor connectivity, node degrees, and normalization.\n\nTest suite:\nUse $\\beta = 6$ for all test cases and compute $r_{pq}$ for the designated $(p,q)$ in each case.\n\n- Test case $1$ (toy network with a single outlier edge and disjoint neighbor sets, $n=6$): \n  $$R^{(1)} = \\begin{pmatrix}\n  1 & 0.1 & 0.1 & 0.1 & 0.6 & 0.1 \\\\\n  0.1 & 1 & 0.1 & 0.1 & 0.6 & 0.1 \\\\\n  0.1 & 0.1 & 1 & 0.1 & 0.1 & 0.6 \\\\\n  0.1 & 0.1 & 0.1 & 1 & 0.1 & 0.6 \\\\\n  0.6 & 0.6 & 0.1 & 0.1 & 1 & 0.9 \\\\\n  0.1 & 0.1 & 0.6 & 0.6 & 0.9 & 1\n  \\end{pmatrix},\\quad (p,q) = (4,5).$$\n  This network contains a single high-correlation edge $(4,5)$ with $R_{45} = 0.9$, while nodes $4$ and $5$ have moderate correlations to disjoint sets of neighbors, resulting in no shared neighbors between them.\n\n- Test case $2$ (embedded module edge with strong shared neighbors, $n=6$):\n  $$R^{(2)} = \\begin{pmatrix}\n  1 & 0.9 & 0.9 & 0.9 & 0.1 & 0.1 \\\\\n  0.9 & 1 & 0.9 & 0.9 & 0.1 & 0.1 \\\\\n  0.9 & 0.9 & 1 & 0.85 & 0.1 & 0.1 \\\\\n  0.9 & 0.9 & 0.85 & 1 & 0.1 & 0.1 \\\\\n  0.1 & 0.1 & 0.1 & 0.1 & 1 & 0.1 \\\\\n  0.1 & 0.1 & 0.1 & 0.1 & 0.1 & 1\n  \\end{pmatrix},\\quad (p,q) = (0,1).$$\n  Nodes $(0,1)$ share strong neighbors $(2,3)$, forming an embedded module-like structure.\n\n- Test case $3$ (uniform network baseline, $n=5$):\n  $$R^{(3)}_{ij} = \\begin{cases} 1 & \\text{if } i=j, \\\\ 0.8 & \\text{if } i \\ne j \\end{cases}$$\n  $\\quad (p,q) = (0,1).$\n  This case examines behavior when all edges are equally strong.\n\n- Test case $4$ (boundary case with a single nonzero edge, $n=5$):\n  $$R^{(4)}_{ij} = \\begin{cases}\n  1 & \\text{if } i=j, \\\\\n  0.9 & \\text{if } \\{i,j\\} = \\{3,4\\}, \\\\\n  0 & \\text{otherwise}\n  \\end{cases}$$\n  $\\quad (p,q) = (3,4).$\n  This case tests the limit where there is no network context beyond the single edge.\n\nFinal output specification:\n- Your program should produce a single line of output containing the four reduction factors as a comma-separated list enclosed in square brackets, in the order of test cases $1$ through $4$, with each factor rounded to six decimal places (e.g., $[0.914999,1.000000,1.000000,1.000000]$). No additional text may be printed.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of network biology, specifically Weighted Gene Co-expression Network Analysis (WGCNA), is well-posed with all necessary data provided, and is mathematically formalizable.\n\nThe objective is to formalize the mathematical principles behind the Topological Overlap Measure (TOM) and quantify its effect on re-weighting network edges based on their neighborhood context. We will analyze why TOM tends to suppress the weight of edges that lack shared neighborhood support, while preserving or even amplifying the weight of edges embedded within well-connected modules. We will use the standard formulation of TOM and apply it to several test networks.\n\nLet the network be defined over a set of $n$ genes. The analysis proceeds in three main steps:\n\n**1. From Correlation to Adjacency**\n\nThe initial input is a symmetric Pearson correlation matrix $R \\in \\mathbb{R}^{n \\times n}$, where $R_{ij} = r_{ij}$ is the correlation between the expression profiles of gene $i$ and gene $j$. By definition, $r_{ii} = 1$ and $-1 \\le r_{ij} \\le 1$.\n\nTo construct a weighted co-expression network, we first transform the correlation matrix $R$ into an adjacency matrix $A$ using a soft-thresholding function. The adjacency $A_{ij} = a_{ij}$ between two distinct genes $i$ and $j$ is defined as:\n$$\na_{ij} = |r_{ij}|^\\beta \\quad \\text{for } i \\ne j\n$$\nHere, $\\beta > 0$ is the soft-thresholding power. This operation serves to amplify strong correlations (where $|r_{ij}|$ is close to $1$) and suppress weak correlations (where $|r_{ij}|$ is close to $0$), thereby emphasizing the most significant biological relationships while maintaining the continuous nature of connection strengths. By convention, we set self-connections to zero, $a_{ii} = 0$, to avoid self-loops in topological calculations. For all test cases, we use the specified value $\\beta = 6$.\n\n**2. The Topological Overlap Measure (TOM)**\n\nThe adjacency matrix $A$ only captures the direct relationship between two genes. The core idea of TOM is to refine this measure by incorporating information about the shared network topology of the two genes. The TOM between genes $i$ and $j$, denoted $T_{ij}$, is defined based on the concept of shared neighbors.\n\nThe standard symmetric formulation for the weighted TOM is:\n$$\nT_{ij} = \\frac{l_{ij} + a_{ij}}{\\min(k_i, k_j) + 1 - a_{ij}}\n$$\nEach component of this formula has a distinct topological meaning:\n- $a_{ij}$: This is the direct connection strength between nodes $i$ and $j$, as defined in the adjacency matrix.\n- $k_i = \\sum_{u} a_{iu}$: This is the total connectivity, or weighted degree, of node $i$. It represents the sum of connection strengths from node $i$ to all other nodes in the network.\n- $l_{ij} = \\sum_{u} a_{iu} a_{uj}$: This term quantifies the extent of shared neighborhood connectivity between nodes $i$ and $j$. It is the sum of weighted paths of length two between $i$ and $j$. Note that since $a_{uu}=0$, node $u$ cannot be $i$ or $j$ for a path to have distinct intermediate nodes. Computationally, the matrix of all $l_{ij}$ values is given by the matrix product $L = A^2 = A \\cdot A$.\n\nThe numerator, $l_{ij} + a_{ij}$, represents the total topological relationship between $i$ and $j$, combining their direct connection ($a_{ij}$) and their indirect connection through all possible shared one-step neighbors ($l_{ij}$).\n\nThe denominator, $\\min(k_i, k_j) + 1 - a_{ij}$, serves as a normalization factor. It ensures that $T_{ij}$ is bounded (typically within $[0, 1]$). It relates the shared connectivity $l_{ij}$ to the maximum possible shared connectivity, which is limited by the smaller of the two node connectivities, $\\min(k_i, k_j)$. The term $1 - a_{ij}$ is a crucial stabilizer that prevents the denominator from becoming zero when nodes have low connectivity.\n\n**3. Quantifying the Effect of TOM: The Re-weighting Factor**\n\nTo analyze how TOM modifies the initial adjacency, we compute a re-weighting factor, defined in the problem as $r_{pq} = T_{pq} / A_{pq}$ for a designated edge $(p,q)$. This factor quantifies the change in edge weight from the raw adjacency $A_{pq}$ to the topologically informed measure $T_{pq}$.\n\n- If $r_{pq} < 1$, TOM has down-weighted or \"penalized\" the edge.\n- If $r_{pq} = 1$, TOM has preserved the edge weight.\n- If $r_{pq} > 1$, TOM has up-weighted or \"amplified\" the edge.\n\nThe behavior of this factor is dictated by the interplay between shared neighbors and overall connectivity:\n\n- **Case of an isolated high-correlation edge (Test Cases 1 & 4):**\nConsider two nodes $p$ and $q$ with a high adjacency $A_{pq}$ but few or no shared neighbors. This means $l_{pq} \\approx 0$. The TOM formula becomes $T_{pq} \\approx \\frac{A_{pq}}{\\min(k_p, k_q) + 1 - A_{pq}}$. The connectivities $k_p$ and $k_q$ are composed of the direct edge $A_{pq}$ plus connections to their other, largely disjoint, neighbors. If these other connections are significant, $\\min(k_p, k_q)$ will be substantially larger than $A_{pq}$. This makes the denominator large, resulting in $T_{pq} < A_{pq}$ and a re-weighting factor $r_{pq} < 1$. This is the mechanism by which TOM reduces the influence of \"spurious\" connections that lack broader topological support. Test Case 1 is designed to illustrate this, where nodes $4$ and $5$ have a strong direct link but connect to disjoint parts of the network, resulting in a reduction. In the extreme scenario of Test Case 4, where the edge $(3,4)$ is the *entire* network, there is no other topological context. Here, $k_p = k_q = A_{pq}$ and $l_{pq}=0$, which yields $T_{pq} = \\frac{A_{pq}}{A_{pq} + 1 - A_{pq}} = A_{pq}$. Thus, $r_{pq}=1$. TOM acts neutrally when there is no external topology to consider.\n\n- **Case of an edge embedded in a module (Test Cases 2 & 3):**\nConsider two nodes $p$ and $q$ that not only have a high adjacency $A_{pq}$ but also share many strongly connected neighbors. This is typical of nodes within a functional module. In this case, the shared neighbor term $l_{pq}$ is large.\nThe factor $r_{pq} = \\frac{l_{pq} + A_{pq}}{A_{pq}(\\min(k_p, k_q) + 1 - A_{pq})} = \\frac{l_{pq}/A_{pq} + 1}{\\min(k_p, k_q) + 1 - A_{pq}}$. If the shared connections are strong, $l_{pq}$ can be substantial relative to the connectivities, leading to $r_{pq} \\ge 1$. In Test Case 2, nodes $0$ and $1$ are part of a dense cluster, leading to a large $l_{01}$, which results in an amplification of the edge weight ($r_{01} > 1$). This shows that TOM reinforces connections that are structurally central to a neighborhood. In the perfectly uniform network of Test Case 3, every edge has identical and maximal topological support relative to the graph structure. The formula elegantly simplifies such that $T_{pq} = A_{pq}$, yielding $r_{pq}=1$.\n\nIn summary, TOM is not merely a reduction mechanism but a sophisticated re-weighting scheme. It uses the principle of neighborhood overlap to assess whether a direct connection is topologically corroborated. It penalizes topologically isolated edges, preserves edges in uniform contexts, and rewards edges central to dense local neighborhoods. This property is what makes TOM a powerful tool for defining and identifying robust network modules.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    def compute_tom_reduction_factor(R: np.ndarray, p: int, q: int, beta: float) -> float:\n        \"\"\"\n        Computes the adjacency matrix, TOM matrix, and the re-weighting factor for a given edge.\n\n        The function implements the following steps:\n        1.  Computes the soft-thresholded adjacency matrix A from the correlation matrix R.\n        2.  Calculates the Topological Overlap Measure (TOM) matrix T from A.\n        3.  Computes the re-weighting factor r_pq = T_pq / A_pq for the specified edge (p,q).\n\n        Args:\n            R (np.ndarray): The n x n symmetric correlation matrix.\n            p (int): The first node index of the target edge (0-based).\n            q (int): The second node index of the target edge (0-based).\n            beta (float): The soft-thresholding power.\n\n        Returns:\n            float: The re-weighting factor T_pq / A_pq.\n        \"\"\"\n        n = R.shape[0]\n\n        # Step 1: Compute the weighted adjacency matrix A\n        # A_ij = |R_ij|^beta for i != j, and A_ii = 0\n        A = np.abs(R)**beta\n        np.fill_diagonal(A, 0)\n\n        # Step 2: Compute the Weighted Topological Overlap Measure (TOM) matrix T\n        \n        # Calculate connectivity (weighted degree) for each node: k_i = sum_u a_iu\n        k = np.sum(A, axis=1)\n\n        # Calculate the shared neighbor term matrix L: L_ij = sum_u (a_iu * a_uj)\n        # This is efficiently calculated as the matrix product of A with itself.\n        L = A @ A\n\n        # Vectorized calculation of the TOM matrix T.\n        # The formula is T_ij = (L_ij + A_ij) / (min(k_i, k_j) + 1 - A_ij)\n        \n        # To vectorize min(k_i, k_j), we create an n x n matrix of these minimums.\n        k_col = k.reshape(-1, 1)\n        k_row = k.reshape(1, -1)\n        min_k_matrix = np.minimum(k_col, k_row)\n        \n        # Numerator of the TOM formula\n        numerator = L + A\n        \n        # Denominator of the TOM formula. This is guaranteed to be positive for A_ij <= 1.\n        denominator = min_k_matrix + 1 - A\n        \n        # Element-wise division to get the TOM matrix T\n        T = numerator / denominator\n        # By convention, the topological overlap of a node with itself is 1.\n        np.fill_diagonal(T, 1)\n\n        # Step 3: Compute the re-weighting factor r_pq = T_pq / A_pq\n        A_pq = A[p, q]\n        T_pq = T[p, q]\n\n        # The problem's test cases all have A_pq > 0.\n        if A_pq == 0:\n            if T_pq == 0:\n                return 1.0  # Convention for no change when both are zero.\n            else:\n                return np.inf # TOM found a path where no direct adjacency existed.\n        \n        factor = T_pq / A_pq\n        return factor\n\n    # Shared parameter for all test cases\n    beta = 6.0\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1: Outlier edge with disjoint neighbors\n        (\n            np.array([\n                [1.0, 0.1, 0.1, 0.1, 0.6, 0.1],\n                [0.1, 1.0, 0.1, 0.1, 0.6, 0.1],\n                [0.1, 0.1, 1.0, 0.1, 0.1, 0.6],\n                [0.1, 0.1, 0.1, 1.0, 0.1, 0.6],\n                [0.6, 0.6, 0.1, 0.1, 1.0, 0.9],\n                [0.1, 0.1, 0.6, 0.6, 0.9, 1.0]\n            ]),\n            (4, 5) # Designated edge (p,q)\n        ),\n        # Test Case 2: Embedded module edge with shared neighbors\n        (\n            np.array([\n                [1.0, 0.9, 0.9, 0.9, 0.1, 0.1],\n                [0.9, 1.0, 0.9, 0.9, 0.1, 0.1],\n                [0.9, 0.9, 1.0, 0.85, 0.1, 0.1],\n                [0.9, 0.9, 0.85, 1.0, 0.1, 0.1],\n                [0.1, 0.1, 0.1, 0.1, 1.0, 0.1],\n                [0.1, 0.1, 0.1, 0.1, 0.1, 1.0]\n            ]),\n            (0, 1)\n        ),\n        # Test Case 3: Uniform network baseline\n        (\n            np.full((5, 5), 0.8, dtype=float) + np.diag([0.2]*5),\n            (0, 1)\n        ),\n        # Test Case 4: Boundary case with a single edge\n        (\n            np.array([\n                [1.0, 0.0, 0.0, 0.0, 0.0],\n                [0.0, 1.0, 0.0, 0.0, 0.0],\n                [0.0, 0.0, 1.0, 0.0, 0.0],\n                [0.0, 0.0, 0.0, 1.0, 0.9],\n                [0.0, 0.0, 0.0, 0.9, 1.0]\n            ]),\n            (3, 4)\n        )\n    ]\n\n    results = []\n    for R, (p, q) in test_cases:\n        factor = compute_tom_reduction_factor(R, p, q, beta)\n        results.append(factor)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Constructing a robust co-expression network requires making principled decisions about key parameters. This advanced practice addresses the selection of the soft-thresholding power, $\\beta$, which governs the overall topology of the network. You will implement a standard procedure that balances the trade-off between achieving an approximately scale-free network—a desirable biological property—and maintaining sufficient mean connectivity to retain information .",
            "id": "4328704",
            "problem": "You are given the task of designing and implementing a principled selection procedure for the soft-thresholding power parameter $ \\beta $ in the construction of a weighted co-expression network from gene expression data, consistent with the goals of systems biomedicine. The network is constructed using the absolute Pearson correlation coefficient $ |r_{ij}| $ transformed via $ a_{ij} = |r_{ij}|^{\\beta} $ to define a weighted adjacency matrix, where $ a_{ii} = 0 $ and $ i \\neq j $ indexes distinct genes. The target is to choose $ \\beta $ that balances two objectives: approximate scale-free behavior and sufficient mean connectivity.\n\nFundamental definitions and starting points to be used:\n- Pearson correlation between gene $ i $ and gene $ j $ is defined for expression vectors $ \\mathbf{x}_i \\in \\mathbb{R}^m $ and $ \\mathbf{x}_j \\in \\mathbb{R}^m $ across $ m $ samples by\n$$\nr_{ij} = \\frac{\\sum_{s=1}^{m} (x_{i,s} - \\bar{x}_i)(x_{j,s} - \\bar{x}_j)}{\\sqrt{\\sum_{s=1}^{m} (x_{i,s} - \\bar{x}_i)^2} \\sqrt{\\sum_{s=1}^{m} (x_{j,s} - \\bar{x}_j)^2}},\n$$\nwhere $ \\bar{x}_i $ is the sample mean of $ \\mathbf{x}_i $.\n- The weighted adjacency matrix is defined by\n$$\na_{ij}(\\beta) = \n\\begin{cases}\n|r_{ij}|^{\\beta}, & \\text{for } i \\neq j, \\\\\n0, & \\text{for } i = j.\n\\end{cases}\n$$\n- The weighted connectivity (degree) of node $ i $ is\n$$\nk_i(\\beta) = \\sum_{j \\neq i} a_{ij}(\\beta).\n$$\n- The mean connectivity is\n$$\n\\bar{k}(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} k_i(\\beta),\n$$\nwhere $ n $ is the number of genes.\n- Approximate scale-free behavior is assessed by the linear fit of the empirical distribution $ p(k) $ against a power law $ p(k) \\propto k^{-\\gamma} $, operationalized by the coefficient of determination $ R^2(\\beta) $ of the linear regression of $ \\log p(k) $ versus $ \\log k $. To approximate $ p(k) $, use a histogram of $ \\{k_i(\\beta)\\}_{i=1}^{n} $ with Sturges' bin count $ B = \\lceil \\log_2(n) + 1 \\rceil $ and midpoints $ \\{m_b\\}_{b=1}^{B} $. For stability, exclude bins with zero counts and add a small constant $ \\delta $ to avoid logarithms of zero, i.e., compute $ y_b = \\log(p_b + \\delta) $ and $ x_b = \\log(m_b + \\delta) $ for the regression. The linear regression is ordinary least squares, and the coefficient of determination is\n$$\nR^2(\\beta) = 1 - \\frac{\\sum_{b} (y_b - \\hat{y}_b)^2}{\\sum_{b} (y_b - \\bar{y})^2},\n$$\nwhere $ \\hat{y}_b $ are the fitted values and $ \\bar{y} $ is the mean of $ \\{y_b\\} $. If there are fewer than $ 2 $ non-empty bins or the variance of $ \\{y_b\\} $ is zero, set $ R^2(\\beta) = 0 $.\n\nDesign the selection procedure as follows:\n1. For each candidate $ \\beta $ in a provided set, compute $ R^2(\\beta) $ as defined above and the mean connectivity $ \\bar{k}(\\beta) $.\n2. Normalize the mean connectivity by its theoretical maximum $ n - 1 $ to obtain\n$$\nc(\\beta) = \\frac{\\bar{k}(\\beta)}{n - 1},\n$$\nwhich lies in $ [0, 1] $.\n3. Define a scalar objective that balances the two goals using a weight $ \\alpha \\in [0, 1] $:\n$$\nO(\\beta) = \\alpha \\, R^2(\\beta) + (1 - \\alpha) \\, c(\\beta).\n$$\n4. Select $ \\beta^\\star $ that maximizes $ O(\\beta) $. In case of ties within numerical tolerance, prefer the smallest $ \\beta $.\n5. Report the triple $ [\\beta^\\star, R^2(\\beta^\\star), \\bar{k}(\\beta^\\star)] $ with the second and third entries expressed as decimals (no percentage sign) rounded to four decimal places.\n\nImplement this procedure and apply it to the following test suite. In all cases, set $ \\delta = 10^{-10} $ when taking logarithms. There are no physical units involved. Angles do not appear. All results must be decimals or integers without percentage signs.\n\nTest Suite:\n- Case $ A $ (happy path, modular structure):\n    - Number of genes $ n = 50 $, number of samples $ m = 60 $.\n    - Construct $ 2 $ latent module factors $ \\mathbf{L}_1, \\mathbf{L}_2 \\in \\mathbb{R}^m $ with entries drawn independently from the standard normal distribution.\n    - Assign genes $ 1 $ through $ 20 $ to module $ 1 $, genes $ 21 $ through $ 35 $ to module $ 2 $, and genes $ 36 $ through $ 50 $ as non-modular.\n    - For genes in module $ j \\in \\{1, 2\\} $, generate expression as $ \\mathbf{x}_i = 0.9 \\, \\mathbf{L}_j + \\boldsymbol{\\epsilon}_i $, with independent noise $ \\boldsymbol{\\epsilon}_i $ having entries drawn from the normal distribution with mean $ 0 $ and standard deviation $ 0.5 $.\n    - For non-modular genes, use $ \\mathbf{x}_i = \\boldsymbol{\\epsilon}_i $ with entries drawn from the normal distribution with mean $ 0 $ and standard deviation $ 1 $.\n    - Compute $ r_{ij} $ across samples, then $ a_{ij}(\\beta) $.\n    - Candidate powers: $ \\beta \\in \\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\} $.\n    - Weight: $ \\alpha = 0.8 $.\n    - Random seed: use a fixed seed of $ 42 $ for reproducibility in this case.\n\n- Case $ B $ (boundary case, nearly complete network with uniform correlation):\n    - Number of genes $ n = 30 $.\n    - Define $ r_{ij} = 0.9 $ for $ i \\neq j $ and $ r_{ii} = 1 $.\n    - Candidate powers: $ \\beta \\in \\{1, 2, 4, 8\\} $.\n    - Weight: $ \\alpha = 0.5 $.\n\n- Case $ C $ (edge case, weak co-expression):\n    - Number of genes $ n = 40 $, number of samples $ m = 50 $.\n    - Generate each $ \\mathbf{x}_i $ with entries drawn independently from the standard normal distribution (independent across genes).\n    - Compute $ r_{ij} $ across samples, then $ a_{ij}(\\beta) $.\n    - Candidate powers: $ \\beta \\in \\{1, 2, 3, 4, 5\\} $.\n    - Weight: $ \\alpha = 0.7 $.\n    - Random seed: use a fixed seed of $ 123 $ for reproducibility in this case.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list in the form $ [\\beta^\\star, R^2(\\beta^\\star), \\bar{k}(\\beta^\\star)] $. For example, the format must be $ [[b_1,r_1,k_1],[b_2,r_2,k_2],[b_3,r_3,k_3]] $. All numeric entries must be decimals or integers without percentage signs, with $ R^2 $ and $ \\bar{k} $ rounded to four decimal places.",
            "solution": "The task is to devise and implement a procedure for selecting the optimal soft-thresholding power, $\\beta$, used in constructing a weighted gene co-expression network. The selection must balance two competing objectives: achieving a network topology that is approximately scale-free and maintaining a sufficient level of mean connectivity. This is a common and fundamental problem in systems biomedicine, particularly in methods like Weighted Gene Co-expression Network Analysis (WGCNA).\n\nThe core principle behind this procedure is the trade-off inherent in the choice of $\\beta$. The adjacency matrix of the network is defined by transforming the absolute Pearson correlation values $|r_{ij}|$ between gene expression profiles via the power function $a_{ij} = |r_{ij}|^{\\beta}$ for $i \\neq j$. A higher value of $\\beta$ amplifies the contrast between high and low correlations, effectively filtering out weak connections and emphasizing strong ones. This can push the network's degree distribution, $p(k)$, towards a power law, $p(k) \\propto k^{-\\gamma}$, which is characteristic of a scale-free topology. Scale-free networks are thought to be robust and possess key hub nodes, a desirable feature for identifying important genes. However, an excessively high $\\beta$ can also lead to a very sparse network with low overall connectivity, potentially discarding valuable biological information contained in moderate correlations.\n\nOur procedure systematically evaluates a set of candidate $\\beta$ values against a formal objective function that encapsulates this trade-off. The designed algorithm proceeds through the following steps for each test case.\n\nFirst, we establish the base correlation structure. For cases requiring data generation (Case A and C), we synthesize an expression matrix $\\mathbf{X}$ of size $n \\times m$ ($n$ genes, $m$ samples) according to the specified statistical model and random seed. For Case B, the correlation matrix $\\mathbf{R}$ is defined directly. For cases A and C, the Pearson correlation matrix $\\mathbf{R}$ is computed from $\\mathbf{X}$, where each entry $r_{ij}$ measures the linear relationship between the expression of gene $i$ and gene $j$.\n\nSecond, for each candidate power $\\beta$ from the supplied set, we perform the following calculations:\n1.  **Construct the Adjacency Matrix**: The weighted adjacency matrix $\\mathbf{A}(\\beta)$ is computed. Its elements are given by $a_{ij}(\\beta) = |r_{ij}|^{\\beta}$ for $i \\neq j$, and the diagonal elements $a_{ii}(\\beta)$ are set to $0$ to preclude self-loops.\n\n2.  **Calculate Node Connectivity**: The connectivity (or degree) $k_i(\\beta)$ for each gene $i$ is calculated by summing the weights of all its connections: $k_i(\\beta) = \\sum_{j \\neq i} a_{ij}(\\beta)$.\n\n3.  **Assess Scale-Free Topology**: We quantify how well the network's connectivity distribution approximates a power law. This is operationalized by calculating the coefficient of determination, $R^2(\\beta)$, from a linear regression.\n    - The set of connectivities $\\{k_i(\\beta)\\}_{i=1}^{n}$ is binned into a histogram. The number of bins, $B$, is determined by Sturges' formula, $B = \\lceil \\log_2(n) + 1 \\rceil$.\n    - The core idea of a power-law distribution $p(k) \\propto k^{-\\gamma}$ is that its logarithm is linear in the logarithm of the variable: $\\log p(k) = -\\gamma \\log k + C$. We test this relationship.\n    - For each non-empty bin $b$ of the histogram, we identify its midpoint $m_b$ and its frequency count $p_b$. We then perform an ordinary least squares linear regression on the transformed coordinates $y_b = \\log(p_b + \\delta)$ versus $x_b = \\log(m_b + \\delta)$, where $\\delta=10^{-10}$ is a small constant to prevent numerical issues with logarithms of zero.\n    - The $R^2(\\beta)$ value from this regression measures the goodness of fit to the linear model. A value close to $1$ indicates a good fit to a power law and thus an approximately scale-free topology. Special cases where fewer than $2$ bins are non-empty or the variance of $\\{y_b\\}$ is zero result in $R^2(\\beta)$ being defined as $0$.\n\n4.  **Calculate Mean Connectivity**: The mean connectivity of the network, $\\bar{k}(\\beta) = \\frac{1}{n} \\sum_{i=1}^{n} k_i(\\beta)$, is computed. To create a standardized metric, this value is normalized by the maximum possible mean connectivity, $n-1$, yielding $c(\\beta) = \\frac{\\bar{k}(\\beta)}{n-1}$. This normalized value $c(\\beta)$ lies in the range $[0, 1]$.\n\nThird, we select the optimal power $\\beta^\\star$. The two metrics, $R^2(\\beta)$ and $c(\\beta)$, are combined into a single scalar objective function $O(\\beta) = \\alpha \\, R^2(\\beta) + (1 - \\alpha) \\, c(\\beta)$, where $\\alpha \\in [0, 1]$ is a weight that tunes the relative importance of scale-free topology fit versus mean connectivity. We compute $O(\\beta)$ for all candidate powers.\n\nThe optimal power, $\\beta^\\star$, is chosen as the one that maximizes $O(\\beta)$. In the event of a tie in the value of $O(\\beta)$ (within numerical precision), the smallest $\\beta$ among the contenders is selected. This tie-breaking rule favors simpler models and denser networks when the primary objective metric is saturated.\n\nFinally, for each test case, the chosen triple $[\\beta^\\star, R^2(\\beta^\\star), \\bar{k}(\\beta^\\star)]$ is reported, with the $R^2$ and mean connectivity values rounded to four decimal places. This entire procedure is implemented and applied to the provided test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef calculate_r_squared(k, n, delta):\n    \"\"\"\n    Calculates the scale-free topology fit R^2 for a given connectivity vector k.\n    \n    Args:\n        k (np.ndarray): Vector of node connectivities.\n        n (int): Number of genes (nodes).\n        delta (float): Small constant to avoid log(0).\n\n    Returns:\n        float: The R^2 value.\n    \"\"\"\n    if n <= 1:\n        return 0.0\n    num_bins = int(np.ceil(np.log2(n) + 1))\n    \n    # Filter out any potential non-finite values from k\n    k_finite = k[np.isfinite(k)]\n    if k_finite.size == 0:\n        return 0.0\n\n    counts, bin_edges = np.histogram(k_finite, bins=num_bins)\n    \n    non_empty_indices = np.where(counts > 0)[0]\n    \n    # If there are fewer than 2 non-empty bins, R^2 is undefined/unstable.\n    if len(non_empty_indices) < 2:\n        return 0.0\n        \n    non_empty_counts = counts[non_empty_indices]\n    \n    bin_midpoints = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n    non_empty_midpoints = bin_midpoints[non_empty_indices]\n    \n    # Avoid log of zero for midpoints\n    # Connectivities k_i are >= 0, so midpoints are >= 0.\n    valid_midpoints_mask = non_empty_midpoints > 0\n    if np.sum(valid_midpoints_mask) < 2:\n        return 0.0\n\n    x = np.log(non_empty_midpoints[valid_midpoints_mask] + delta)\n    y = np.log(non_empty_counts[valid_midpoints_mask] + delta)\n    \n    if x.size < 2:\n        return 0.0\n\n    # If variance of y is zero, R^2 is 0 or undefined.\n    if np.var(y) < 1e-12:\n        return 0.0\n        \n    # If variance of x is zero (should not happen if x.size > 1 and midpoints are distinct)\n    if np.var(x) < 1e-12:\n        return 0.0\n\n    lin_reg_result = stats.linregress(x, y)\n    r_squared = lin_reg_result.rvalue**2\n    \n    return r_squared\n\ndef solve_case(params):\n    \"\"\"\n    Solves a single test case for beta selection.\n    \"\"\"\n    case_name = params['name']\n    n = params['n']\n    beta_candidates = params['betas']\n    alpha = params['alpha']\n    delta = 1e-10\n    \n    R = None\n\n    if case_name == 'A':\n        m = params['m']\n        seed = params['seed']\n        rng = np.random.default_rng(seed)\n        \n        L1 = rng.normal(size=m)\n        L2 = rng.normal(size=m)\n        X = np.zeros((n, m))\n        \n        # Module 1: genes 1-20 (indices 0-19)\n        eps1 = rng.normal(loc=0.0, scale=0.5, size=(20, m))\n        X[0:20, :] = 0.9 * L1[np.newaxis, :] + eps1\n        # Module 2: genes 21-35 (indices 20-34)\n        eps2 = rng.normal(loc=0.0, scale=0.5, size=(15, m))\n        X[20:35, :] = 0.9 * L2[np.newaxis, :] + eps2\n        # Non-modular: genes 36-50 (indices 35-49)\n        eps3 = rng.normal(loc=0.0, scale=1.0, size=(15, m))\n        X[35:50, :] = eps3\n        \n        R = np.corrcoef(X)\n        \n    elif case_name == 'B':\n        R = np.full((n, n), 0.9)\n        np.fill_diagonal(R, 1.0)\n        \n    elif case_name == 'C':\n        m = params['m']\n        seed = params['seed']\n        rng = np.random.default_rng(seed)\n        X = rng.normal(loc=0.0, scale=1.0, size=(n, m))\n        R = np.corrcoef(X)\n    \n    abs_R = np.abs(R)\n    \n    results = []\n    for beta in beta_candidates:\n        A = np.power(abs_R, beta)\n        np.fill_diagonal(A, 0)\n        \n        k = A.sum(axis=1)\n        k_bar = k.mean()\n        \n        r_sq = calculate_r_squared(k, n, delta)\n        \n        c = k_bar / (n - 1) if n > 1 else 0\n        \n        O = alpha * r_sq + (1 - alpha) * c\n        \n        results.append({'beta': beta, 'O': O, 'r_sq': r_sq, 'k_bar': k_bar})\n        \n    # Sort by objective value descending, then by beta ascending to break ties\n    best_result = sorted(results, key=lambda x: (-x['O'], x['beta']))[0]\n    \n    return [best_result['beta'], best_result['r_sq'], best_result['k_bar']]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        {\n            'name': 'A', 'n': 50, 'm': 60, 'seed': 42,\n            'betas': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'alpha': 0.8\n        },\n        {\n            'name': 'B', 'n': 30, 'betas': [1, 2, 4, 8], 'alpha': 0.5\n        },\n        {\n            'name': 'C', 'n': 40, 'm': 50, 'seed': 123,\n            'betas': [1, 2, 3, 4, 5], 'alpha': 0.7\n        }\n    ]\n\n    all_results = []\n    for case_params in test_cases:\n        result = solve_case(case_params)\n        all_results.append(result)\n\n    # Format the final output string as per requirements\n    formatted_parts = []\n    for part in all_results:\n        beta_val = part[0]\n        r2_val = part[1]\n        k_val = part[2]\n        formatted_parts.append(f\"[{beta_val},{r2_val:.4f},{k_val:.4f}]\")\n    \n    print(f\"[{','.join(formatted_parts)}]\")\n\nsolve()\n\n```"
        }
    ]
}