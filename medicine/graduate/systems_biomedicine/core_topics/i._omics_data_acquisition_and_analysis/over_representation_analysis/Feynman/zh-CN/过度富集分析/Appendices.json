{
    "hands_on_practices": [
        {
            "introduction": "经典的过表示分析（ORA）依赖于一些在真实生物数据中常常不成立的强假设。本练习将挑战你对这些假设进行批判性思考，探讨转录组学中常见的混杂因素，如细胞类型组成差异和基因长度偏好，这些因素可能导致富集的假阳性信号。通过识别这些陷阱，你将理解为何需要采用比基本超几何检验更复杂的分析方法。",
            "id": "4371331",
            "problem": "一项系统生物医学领域的队列研究使用RNA测序（RNA-seq）来探究疾病特异性的转录变化。病例样本是具有不同免疫浸润水平的整体肿瘤活检组织，而对照组是免疫细胞含量较低的邻近正常组织。下游分析对差异表达基因（DEGs）进行基于基因本体论（Gene Ontology）生物学过程类别的过表征分析（ORA）。\n\n假设对于一个病例与对照组的比较，有以下条件：\n- 总基因全集包含 $N = 20000$ 个已注释的基因。\n- 差异表达基因的数量为 $K = 800$。\n- 在完整注释中，一个标准的免疫激活基因集大小为 $M = 300$。\n- 在 $K$ 个差异表达基因中，属于免疫激活基因集的基因数量为 $x = 90$。\n- 由于平台特异性的可检测性和组织背景，病例样本中表达量高于阈值的基因数量为 $N_{\\mathrm{expr}} = 12000$，并且在这些样本中，免疫激活基因集有 $M_{\\mathrm{expr}} = 250$ 个成员表达。\n- 组间的细胞类型组成不同：病例组的免疫细胞比例为 $f_{\\mathrm{case}} = 0.35$，对照组为 $f_{\\mathrm{ctrl}} = 0.10$。\n- RNA-seq中存在已知的基因长度效应：差异表达基因中长基因的比例为 $p_{L}^{\\mathrm{DE}} = 0.50$，而在整个基因全集中该比例为 $p_{L}^{U} = 0.20$，在免疫激活基因集中该比例为 $p_{L}^{S} = 0.60$。\n\n从ORA的基本原理出发，即零假设模型将 $K$ 个选定的差异表达基因视为从一个大小为 $N$ 的固定基因全集（或一个适当定义的背景子集）中无放回均匀抽取的样本，并假设在给定基因全集的情况下，基因的选择与基因集成员身份无关，回答以下问题：\n\n在此情境下，关于病例特异性混杂因素和ORA的有效推断，以下哪些陈述是正确的？\n\nA. 因为 $f_{\\mathrm{case}} \\neq f_{\\mathrm{ctrl}}$，ORA所基于的均匀抽样假设被违反：仅在免疫细胞中表达的基因具有与疾病机制无关的、更高的被选择概率。一种可行的缓解方法是在差异表达模型中考虑细胞类型组成，和/或执行以细胞类型特异性表达为条件的分层ORA。\n\nB. 将基因全集限制为 $N_{\\mathrm{expr}} = 12000$ 个基因，并将基因集大小限制为 $M_{\\mathrm{expr}} = 250$ 可以完全解决由细胞类型组成引起的混杂问题，因此此后计算的超几何p值无需进一步调整即有效。\n\nC. 基因长度偏倚（$p_{L}^{\\mathrm{DE}}  p_{L}^{U}$ 且 $p_{L}^{S}$ 偏高）会夸大表观的过表征；一种基于原则的校正方法是使用一个能调整基因长度的模型，例如将差异表达和基因长度作为协变量，对基因集成员身份进行逻辑回归，或者使用能匹配长度分布的重抽样方法。\n\nD. 在进行ORA之前移除重叠或冗余的基因集，能保证对假发现率的控制并消除病例特异性混杂因素，从而使标准的超几何p值变得可靠。",
            "solution": "该问题要求在一个特定的系统生物医学背景下，评估关于过表征分析（ORA）中混杂因素的几个陈述的正确性。ORA的有效性取决于其核心假设：$K$ 个差异表达基因（DEGs）的集合代表了从一个大小为 $N$ 的基因全集中无放回均匀随机抽取的样本。任何导致一个基因被选为DEG的概率不均匀的系统性因素，都会违反这一假设，并可能导致虚假结果。ORA的标准统计检验是超几何检验，它计算在给定基因全集大小为 $N$ 的情况下，在 $K$ 个DEGs列表中观察到来自一个大小为 $M$ 的特定基因集的基因数量为 $x$ 或更多的概率。观察到恰好 $k$ 次成功的概率公式为：\n$$ P(X=k) = \\frac{\\binom{M}{k} \\binom{N-M}{K-k}}{\\binom{N}{K}} $$\n该模型仅在 $K$ 个基因的抽样确实是均匀的情况下才有效。我们将根据这一原则评估每个陈述。\n\n给定的数据如下：\n- 总基因全集大小：$N = 20000$\n- 差异表达基因数量：$K = 800$\n- 免疫基因集大小：$M = 300$\n- 免疫基因集中的差异表达基因数量：$x = 90$\n- 表达基因全集：$N_{\\mathrm{expr}} = 12000$\n- 表达的免疫基因集成员数量：$M_{\\mathrm{expr}} = 250$\n- 病例组中的免疫细胞比例：$f_{\\mathrm{case}} = 0.35$\n- 对照组中的免疫细胞比例：$f_{\\mathrm{ctrl}} = 0.10$\n- 基因长度比例：$p_{L}^{\\mathrm{DE}} = 0.50$（在差异表达基因中），$p_{L}^{U} = 0.20$（在全集中），$p_{L}^{S} = 0.60$（在免疫基因集中）。\n\n### 选项A分析\n\n该陈述讨论了来自细胞类型组成的混杂因素。问题指出，病例样本中的免疫细胞比例（$f_{\\mathrm{case}} = 0.35$）显著高于对照样本（$f_{\\mathrm{ctrl}} = 0.10$）。整体RNA-seq测量的是组织匀浆中所有细胞中一个基因的平均表达量。对于一个仅在免疫细胞中表达的基因，其在整体样本中测得的表达量将大致与免疫细胞的比例成正比。因此，这样一个基因在病例组与对照组相比会表现为上调，这仅仅是由于细胞群体的变化，而不一定是由于任何特定细胞类型内基因调控的变化。这样一个基因的近似倍数变化将是 $f_{\\mathrm{case}} / f_{\\mathrm{ctrl}} = 0.35 / 0.10 = 3.5$。对于整一类基因（免疫细胞特异性基因）而言，这种巨大的、系统性的倍数变化极大地增加了它们被选为差异表达基因的概率。这直接违反了ORA的均匀抽样假设，即全集中的每个基因都应有相等的被选择机会（$K/N$）。因此，差异表达基因列表中免疫基因的富集受到了细胞类型组成差异的混杂影响。该陈述提出了两种有效的缓解策略：（1）在差异表达模型中考虑细胞类型组成，例如，在线性模型中将细胞类型比例作为协变量（例如 `~ condition + immune_fraction`），这有助于将疾病`condition`的影响与细胞类型丰度的影响分离开来；以及（2）进行分层ORA，即在已知于特定细胞类型中表达的基因集内进行富集检验。这两种方法都是成熟且有原则的方法，用以解决这一常见的混杂因素。\n\n该陈述在科学上和统计上都是合理的。\n\n**结论：正确**\n\n### 选项B分析\n\n该陈述表明，将分析限制在表达基因的背景上（$N_{\\mathrm{expr}} = 12000$ 和 $M_{\\mathrm{expr}} = 250$）足以解决由细胞类型组成引起的混杂问题。虽然使用表达基因作为背景是一种好的做法（因为未表达的基因不可能差异表达），但这并不能解决在表达基因*之间*存在偏倚选择的问题。细胞类型组成的差异（$f_{\\mathrm{case}} \\neq f_{\\mathrm{ctrl}}$）导致在 $N_{\\mathrm{expr}}$ 个表达基因的集合*内部*，被选为DEG的概率不均匀。由于选项A中描述的细胞群体变化这一混杂因素，存在于 $N_{\\mathrm{expr}}$ 全集中的免疫特异性基因仍然比非免疫特异性基因更有可能被判定为差异表达基因。调整背景集的大小会使检验更具特异性，但并不能纠正输入DEG列表中的偏倚。超几何p值仍然无效，因为从 $N_{\\mathrm{expr}}$ 个基因中产生 $K$ 个DEGs的底层抽样过程不是均匀的。\n\n该陈述提供了一种虚假的安全感，并错误地识别了混杂因素的性质。\n\n**结论：不正确**\n\n### 选项C分析\n\n该陈述讨论了基因长度偏倚。问题指出，差异表达基因中长基因的比例（$p_{L}^{\\mathrm{DE}} = 0.50$）远高于其在全集中的比例（$p_{L}^{U} = 0.20$）。这凭经验证明了较长的基因有更高的概率被鉴定为差异表达基因。这是RNA-seq分析中一个已知的技术性假象，较长的基因会累积更多的读数（reads），这增加了检测其表达变化的统计功效。这再次违反了ORA的均匀抽样假设。该陈述进一步指出，免疫激活基因集本身也富含长基因（$p_{L}^{S} = 0.60$）。这就造成了一个经典的混杂情景：感兴趣的基因集（免疫激活）在差异表达基因列表中富集，部分或全部原因是因为这两个列表共享一个共同属性（长基因），而这个属性与所研究的生物学过程无关。为了获得有效的结果，必须对这种偏倚进行校正。该陈述提出了有原则的校正方法：使用一个统计模型，如逻辑回归，其中基因成为DEG的概率被建模为基因长度的函数；或者使用基于重抽样的方法，通过抽取与测试集长度分布相匹配的随机基因集来构建零分布。这些方法，例如在GOseq R包中实现的方法，是校正基因集分析中基因长度偏倚的标准且合适的方法。\n\n该陈述正确地指出了问题，并提出了有效的解决方案。\n\n**结论：正确**\n\n### 选项D分析\n\n该陈述声称，在进行ORA之前移除重叠或冗余的基因集，能保证对假发现率（FDR）的控制并消除病例特异性混杂因素。移除冗余基因集是提高ORA结果可解释性的一个有用的后处理步骤。像基因本体论（Gene Ontology）这样的基因层级结构包含许多相关术语，报告所有这些术语可能会信息量不足。然而，这一操作对于解决输入数据中的根本性偏倚毫无作用。病例特异性的混杂因素，例如来自细胞类型组成或像基因长度偏倚这样的技术性假象，发生在差异表达分析步骤中，该步骤生成了 $K$ 个DEGs的列表。这些偏倚使ORA的p值本身无效。事后对结果列表进行修剪，并不能纠正被修剪数值的无效性。此外，这并不能“保证”对假发现率（FDR）的控制。FDR是通过像Benjamini-Hochberg这样应用于一组p值的程序来控制的。如果p值本身存在系统性偏倚（例如，由于混杂因素而偏向于显著性），那么最终经过FDR调整后的值（q值）也将是不可靠的。\n\n该陈述将用于解释的后处理与上游的偏倚校正相混淆，并对“保证”FDR控制提出了一个毫无根据的强硬断言。\n\n**结论：不正确**",
            "answer": "$$\\boxed{AC}$$"
        },
        {
            "introduction": "除了对混杂因素进行显式建模外，另一种高级策略是通过生成经验零分布来内在地考虑数据结构。本练习将通过分层分析和置换检验（permutation testing）来探索这一概念，你将实现一种方法，用于比较来自一个分层零模型的精确 $p$ 值与通过在预定义层内随机打乱基因标签所生成的经验 $p$ 值。这个实践展示了在复杂场景下，当参数模型的假设不确定时，基于模拟的非参数方法在假设检验中的强大作用。",
            "id": "4371319",
            "problem": "你的任务是实现一个程序，该程序使用精确零模型和通过置换获得的经验零模型来评估过表达分析 (ORA; Over-Representation Analysis) 中的富集情况。设定如下。一个实体全集被划分为 $B$ 个不相交的组（bin），索引为 $i \\in \\{1,\\dots,B\\}$。在组 $i$ 中，总共有 $N_i$ 个实体，其中 $M_i$ 个被注释到给定的目标类别（例如，一个生物通路），并且一个选定的列表包含从该组中抽取的 $n_i$ 个实体。在选定列表和该类别之间，跨所有组观测到的总重叠数为 $k$。零模型固定了各组的计数 $\\{N_i,M_i,n_i\\}_{i=1}^B$，并断言在每个组内，实体是可交换的，且选择是无放回的随机抽样。在此零假设下，每个组内的重叠数是一个随机变量，跨组的总重叠数是这些组内重叠随机变量的总和。\n\n你的任务是：\n- 计算精确的单侧尾部概率 $p_{\\text{exact}} = \\mathbb{P}(K \\ge k)$，其中 $K$ 是在分层零假设下的总重叠数，该假设假定每个组内的实体是可交换的，以及由组内无放回随机化所引出的组间独立性。\n- 通过模拟 $P$ 次独立的随机选择来计算经验零分布的尾部概率 $p_{\\text{emp}}$，这些选择在每个组内都保持 $\\{n_i\\}_{i=1}^B$ 不变，并计算模拟的总重叠数 $K^{(s)}$ 大于或等于 $k$ 的频率。使用保守估计量 $p_{\\text{emp}} = \\dfrac{1 + \\sum_{s=1}^P \\mathbf{1}\\{K^{(s)} \\ge k\\}}{1 + P}$ 以避免零估计。\n- 所有概率必须以小数形式表示。\n\n你必须依赖的基础理论：\n- ORA的零模型是一个基于随机化的模型。在该模型中，于每个组 $i$ 内，从包含 $M_i$ 个带注释和 $N_i - M_i$ 个不带注释的总共 $N_i$ 个实体中，进行无放回抽样，精确抽取 $n_i$ 个。由于不同组中的选择是独立的，因此各组的重叠数在组间是独立的。\n- 总重叠数 $K$ 的精确分布是通过各组的零分布及其独立性获得的，而经验零分布是通过重复随机化获得的，该随机化过程保持了零模型的相关不变量。\n\n设计要求：\n- 实现一个数值稳定的方法来计算 $p_{\\text{exact}}$，该方法适用于任何满足 $N_i \\ge 0$、 $M_i \\ge 0$、 $n_i \\ge 0$、 $M_i \\le N_i$、 $n_i \\le N_i$ 以及 $k \\in \\mathbb{Z}$ 且 $0 \\le k \\le \\sum_{i=1}^B \\min(M_i,n_i)$ 的有效输入。\n- 使用 $P$ 次模拟实现经验估计量 $p_{\\text{emp}}$，每次模拟都保持每个组内的 $\\{n_i\\}_{i=1}^B$ 不变。\n\n测试套件和参数：\n对以下每个测试用例，计算并返回数值对 $\\big[p_{\\text{exact}}, p_{\\text{emp}}\\big]$。\n\n- 测试用例 1 (非分层基线):\n  - $B = 1$\n  - $N_1 = 1000$, $M_1 = 50$, $n_1 = 60$\n  - $k = 8$\n  - $P = 4000$\n  - 伪随机种子 $= 1729$\n\n- 测试用例 2 (分层，中等计数):\n  - $B = 3$\n  - $(N_1,N_2,N_3) = (500, 800, 700)$\n  - $(M_1,M_2,M_3) = (30, 50, 20)$\n  - $(n_1,n_2,n_3) = (20, 40, 25)$\n  - $k = 11$\n  - $P = 5000$\n  - 伪随机种子 $= 2718$\n\n- 测试用例 3 (含零边界情况):\n  - $B = 2$\n  - $(N_1,N_2) = (400, 600)$\n  - $(M_1,M_2) = (0, 10)$\n  - $(n_1,n_2) = (50, 0)$\n  - $k = 0$\n  - $P = 3000$\n  - 伪随机种子 $= 3141$\n\n- 测试用例 4 (接近最大重叠):\n  - $B = 2$\n  - $(N_1,N_2) = (100, 200)$\n  - $(M_1,M_2) = (20, 40)$\n  - $(n_1,n_2) = (20, 100)$\n  - $k = 60$\n  - $P = 8000$\n  - 伪随机种子 $= 1618$\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个元素按顺序对应一个测试用例，并且本身是一个双元素列表 $[p_{\\text{exact}},p_{\\text{emp}}]$。每个概率必须四舍五入到 $6$ 位小数。例如：\"[[0.123456,0.123250],[0.500000,0.499875]]\"。\n- 程序必须是完全自包含的：它不能读取任何输入，也不能访问外部文件或网络。使用上面提供的种子以确保可复现性。",
            "solution": "该问题要求实现两种方法，用于在分层的过表达分析 (ORA) 中计算富集的统计显著性。第一种方法在定义的零模型下计算精确p值，而第二种方法通过置换检验计算经验p值。\n\n### 理论框架\n\n问题描述了一个分层的实体全集，它被划分为 $B$ 个不相交的组。对每个组 $i \\in \\{1, \\dots, B\\}$，我们给定：\n- $N_i$: 实体总数。\n- $M_i$: 注释到目标类别的实体数。\n- $n_i$: 从该组中抽取的选定列表中的实体数。\n\n零假设陈述，在每个组 $i$ 内，从总共 $N_i$ 个实体中，以无放回的方式均匀随机地选择 $n_i$ 个实体。不同组中的选择是相互独立的。\n\n在此零模型下，组 $i$ 中被选中且同时被注释到该类别的实体数量，由随机变量 $K_i$ 表示，服从超几何分布。$K_i$ 的概率质量函数 (PMF) 由下式给出：\n$$ \\mathbb{P}(K_i = k_i) = \\frac{\\binom{M_i}{k_i} \\binom{N_i - M_i}{n_i - k_i}}{\\binom{N_i}{n_i}} $$\n其中 $k_i$ 是支撑集范围 $\\max(0, n_i - (N_i - M_i)) \\le k_i \\le \\min(n_i, M_i)$ 内的一个整数。\n\n跨所有组的总重叠实体数是这些组内随机变量的和：\n$$ K = \\sum_{i=1}^{B} K_i $$\n由于每个组中的选择是独立的，随机变量 $\\{K_i\\}_{i=1}^B$ 也是独立的。因此，$K$ 的分布是一系列独立（但不一定同分布）的超几何随机变量之和的分布。\n\n### 精确p值 ($p_{\\text{exact}}$) 的计算\n\n精确的单侧p值是观测到总重叠数至少为观测值 $k$ 的概率：$p_{\\text{exact}} = \\mathbb{P}(K \\ge k)$。\n\n独立随机变量之和的PMF是它们各自PMF的卷积。令 $p_{K_i}$ 为 $K_i$ 的 PMF。总重叠数 $K$ 的 PMF 是：\n$$ p_K = p_{K_1} * p_{K_2} * \\dots * p_{K_B} $$\n其中 $*$ 表示离散卷积运算。\n\n这个卷积可以迭代计算。令 $S_j = \\sum_{i=1}^j K_i$ 为前 $j$ 个组的部分和。我们从 $p_{S_0}$ 开始，这是一个确定性为零的随机变量的PMF（即，在值0处的概率为1）。然后，对于 $j=1, \\dots, B$，我们通过将 $S_{j-1}$ 的 PMF 与 $K_j$ 的 PMF进行卷积来计算 $S_j$ 的 PMF：\n$$ p_{S_j} = p_{S_{j-1}} * p_{K_j} $$\n经过 $B$ 次迭代后，我们得到最终的 PMF, $p_K$。\n\n实现的一个关键方面是数值稳定性。对于大的参数，直接计算二项式系数 $\\binom{n}{k}$ 可能会导致溢出。标准做法是首先使用对数伽马函数 ($\\gammaln$) 计算PMF的对数：\n$$ \\log \\mathbb{P}(K_i = k_i) = \\gammaln(M_i+1) + \\gammaln(N_i-M_i+1) + \\gammaln(n_i+1) + \\gammaln(N_i-n_i+1) - \\gammaln(k_i+1) - \\gammaln(M_i-k_i+1) - \\gammaln(n_i-k_i+1) - \\gammaln(N_i-M_i-n_i+k_i+1) - \\gammaln(N_i+1) $$\n像 `scipy.stats` 这样的专用库提供了该对数PMF的数值稳健实现。然而，卷积是在标准概率上执行的，这些概率是通过对对数PMF值取指数来恢复的。\n\n一旦计算出 $K$ 的最终 PMF，p值通过对分布上尾部的概率求和来计算：\n$$ p_{\\text{exact}} = \\sum_{j = k}^{\\sum_{i=1}^B \\min(M_i, n_i)} \\mathbb{P}(K=j) $$\n\n### 经验p值 ($p_{\\text{emp}}$) 的计算\n\n经验p值是使用蒙特卡洛模拟方法确定的，也称为置换检验。该过程从零分布中生成大量的（$P$个）模拟总重叠数。\n\n对每次模拟 $s \\in \\{1, \\dots, P\\}$：\n1.  通过对每个组的零分布进行独立抽样并求和，生成一个总重叠数 $K^{(s)}$。对于每个组 $i$，从 $\\text{Hypergeometric}(N=N_i, K=M_i, n=n_i)$ 分布中抽取一个随机值 $K_i^{(s)}$。\n2.  模拟的总重叠数即为 $K^{(s)} = \\sum_{i=1}^B K_i^{(s)}$。\n\n值集合 $\\{K^{(s)}\\}_{s=1}^P$ 构成了总重叠数 $K$ 的经验零分布。通过将观测到的重叠数 $k$ 与该经验分布进行比较来估计p值。问题指定了一个保守估计量以避免p值为零：\n$$ p_{\\text{emp}} = \\frac{1 + \\sum_{s=1}^P \\mathbf{1}\\{K^{(s)} \\ge k\\}}{1 + P} $$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，当其参数为真时值为1，否则为0。项 $\\sum_{s=1}^P \\mathbf{1}\\{K^{(s)} \\ge k\\}$ 统计了模拟的总重叠数中大于或等于观测重叠数的次数。为确保可复现性，用于模拟的伪随机数生成器在每个测试用例中都用特定的种子进行初始化。这确保了每次执行程序时随机抽样的序列都是相同的。\n\n实现将利用 `scipy.stats.hypergeom` 进行精确 PMF 计算，`numpy.convolve` 用于组合分布，以及 `numpy.random.Generator.hypergeometric` 用于为经验估计高效地、向量化地生成随机样本。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import hypergeom\n\ndef calculate_p_exact(N_vals, M_vals, n_vals, k_obs):\n    \"\"\"\n    Computes the exact one-sided p-value for stratified ORA.\n\n    The method computes the PMF of the sum of independent hypergeometric\n    random variables by iteratively convolving the PMF of each bin's\n    hypergeometric distribution.\n\n    Args:\n        N_vals (list or np.ndarray): Total items per bin.\n        M_vals (list or np.ndarray): \"Success\" items per bin.\n        n_vals (list or np.ndarray): Sampled items per bin.\n        k_obs (int): The observed total number of successes.\n\n    Returns:\n        float: The exact p-value, P(K = k_obs).\n    \"\"\"\n    B = len(N_vals)\n    # Start with the PMF of a random variable that is deterministically 0.\n    # This is the identity element for convolution of PMFs of non-negative RVs.\n    total_pmf = np.array([1.0])\n\n    for i in range(B):\n        Ni, Mi, ni = N_vals[i], M_vals[i], n_vals[i]\n\n        # Handle trivial bins where overlap is always 0.\n        if Mi == 0 or ni == 0:\n            bin_pmf = np.array([1.0])\n        else:\n            # Determine the support of the hypergeometric distribution for this bin\n            k_min_i = max(0, ni - (Ni - Mi))\n            k_max_i = min(ni, Mi)\n            support_i = np.arange(k_min_i, k_max_i + 1)\n            \n            # Calculate the PMF for the current bin\n            bin_pmf = hypergeom.pmf(support_i, Ni, Mi, ni)\n        \n        # Convolve with the aggregate PMF from previous bins\n        total_pmf = np.convolve(total_pmf, bin_pmf)\n\n    # The support of the total PMF is from 0 to len(total_pmf) - 1.\n    # The p-value is the sum of probabilities for outcomes = k_obs.\n    if k_obs = len(total_pmf):\n        return 0.0\n    \n    p_exact = np.sum(total_pmf[k_obs:])\n    return p_exact\n\n\ndef calculate_p_emp(N_vals, M_vals, n_vals, k_obs, P, seed):\n    \"\"\"\n    Computes an empirical p-value for stratified ORA via simulation.\n\n    Args:\n        N_vals (list or np.ndarray): Total items per bin.\n        M_vals (list or np.ndarray): \"Success\" items per bin.\n        n_vals (list or np.ndarray): Sampled items per bin.\n        k_obs (int): The observed total number of successes.\n        P (int): The number of permutations.\n        seed (int): The seed for the pseudorandom number generator.\n\n    Returns:\n        float: The empirical p-value.\n    \"\"\"\n    B = len(N_vals)\n    rng = np.random.default_rng(seed)\n\n    # Vectorized simulation of P total overlaps\n    total_simulated_k = np.zeros(P, dtype=np.int64)\n    for i in range(B):\n        Ni, Mi, ni = N_vals[i], M_vals[i], n_vals[i]\n        # numpy's hypergeometric takes (ngood, nbad, nsample)\n        if Mi > 0 and ni > 0:\n            simulated_k_i = rng.hypergeometric(Mi, Ni - Mi, ni, size=P)\n            total_simulated_k += simulated_k_i\n    \n    # Count how many simulations yield a total overlap = k_obs\n    count_ge_k = np.sum(total_simulated_k = k_obs)\n\n    # Apply the conservative estimator\n    p_emp = (1.0 + count_ge_k) / (1.0 + P)\n    return p_emp\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'N': [1000], 'M': [50], 'n': [60], 'k': 8, 'P': 4000, 'seed': 1729},\n        {'N': [500, 800, 700], 'M': [30, 50, 20], 'n': [20, 40, 25], 'k': 11, 'P': 5000, 'seed': 2718},\n        {'N': [400, 600], 'M': [0, 10], 'n': [50, 0], 'k': 0, 'P': 3000, 'seed': 3141},\n        {'N': [100, 200], 'M': [20, 40], 'n': [20, 100], 'k': 60, 'P': 8000, 'seed': 1618},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p_exact = calculate_p_exact(case['N'], case['M'], case['n'], case['k'])\n        p_emp = calculate_p_emp(case['N'], case['M'], case['n'], case['k'], case['P'], case['seed'])\n        all_results.append([p_exact, p_emp])\n\n    # Format the final output string\n    formatted_results = [f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}