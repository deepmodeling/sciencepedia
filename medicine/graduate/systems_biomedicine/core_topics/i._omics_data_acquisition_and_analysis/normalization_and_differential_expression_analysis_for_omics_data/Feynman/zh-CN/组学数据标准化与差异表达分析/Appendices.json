{
    "hands_on_practices": [
        {
            "introduction": "我们首先研究一种广泛使用的归一化方法——每百万转录本（TPM），以理解其固有的局限性。通过动手模拟，你将发现TPM数据的组合性质如何引入虚假相关性，并导致差异表达分析得出错误结论 。这个练习突显了为何在分析组学数据时，必须采用更复杂的统计模型。",
            "id": "4370568",
            "problem": "考虑一个用于系统生物医学中基因水平定量的简化核糖核酸测序场景，其目标是为“组学”数据进行归一化和差异表达分析。其基础是每百万转录本 (Transcripts Per Million, TPM) 的定义以及成分数据在闭合约束下的性质。对于一个由 $s$ 索引的样本，其中有 $G$ 个基因，索引为 $i \\in \\{1,\\dots,G\\}$，设 $c_{i,s}$ 表示样本 $s$ 中基因 $i$ 的观测读数计数，设 $\\ell_i$ 表示其有效转录本长度（单位为碱基对）。样本 $s$ 中基因 $i$ 的 TPM 定义为\n$$\n\\mathrm{TPM}_{i,s} \\equiv 10^6 \\cdot \\frac{c_{i,s}/\\ell_i}{\\sum_{j=1}^{G} c_{j,s}/\\ell_j}.\n$$\n在此归一化下，由于每个样本 $s$ 都满足闭合约束 $\\sum_{i=1}^{G} \\mathrm{TPM}_{i,s} = 10^6$，向量 $\\left(\\mathrm{TPM}_{1,s},\\dots,\\mathrm{TPM}_{G,s}\\right)$ 位于 $G$ 维单纯形上。在成分数据分析中，对于受确定性约束 $\\sum_{i=1}^{G} X_i = K$ 的随机变量 $X_1,\\dots,X_G$，根据协方差性质可得\n$$\n\\sum_{j=1}^{G} \\mathrm{cov}(X_i,X_j) = \\mathrm{cov}\\left(X_i,\\sum_{j=1}^{G}X_j\\right) = \\mathrm{cov}(X_i,K) = 0,\n$$\n这意味着 $\\sum_{j \\neq i} \\mathrm{cov}(X_i,X_j) = -\\mathrm{var}(X_i)$，从而在与其他组分的协方差中强制产生负平衡。该原理表明，闭合约束会在基因间的协方差和相关性中引入一种结构，而这种结构与真实的生物协同调控无关。\n\n您的任务是提供一个反例，证明在不显式地对成分约束进行建模的情况下，TPM 归一化不能用于差异表达检验，并量化由闭合约束在基因间引入的相关性。实现一个程序，该程序模拟指定基因集在两种条件下的测序计数，计算 TPM 值，对目标基因的 TPM 值执行朴素的 Welch 双样本 t 检验以评估差异表达，并使用所有模拟样本的 TPM 值计算基因间的平均非对角皮尔逊相关性。\n\n假设以下模拟模型，该模型对于批量核糖核酸测序是标准且科学上合理的：\n- 对于给定的条件，将每个细胞中每个基因的预期分子数定义为一个具有严格正值的向量 $\\mathbf{m} = (m_1,\\dots,m_G)$。\n- 对于一个文库大小为 $L$ 总读数的样本，每个样本的基因概率与 $m_i \\ell_i$ 成正比，即\n$$\np_i = \\frac{m_i \\ell_i}{\\sum_{j=1}^{G} m_j \\ell_j}.\n$$\n- 对于每个重复样本，观测计数 $(c_{1,s},\\dots,c_{G,s})$ 独立地从多项分布 $\\mathrm{Multinomial}(L; p_1,\\dots,p_G)$ 中抽样。\n\n以此为基础，构建以下测试套件，每个测试都需要一个可量化的输出：\n\n测试用例 1 (关于未改变基因出现假阳性的反例)：\n- 参数：$G=4$，$\\ell = (1000, 1000, 1000, 1000)$，条件 A 分子数 $\\mathbf{m}^{(A)} = (1000, 1000, 1000, 1000)$，条件 B 分子数 $\\mathbf{m}^{(B)} = (1000, 1000, 100000, 1000)$，每个条件的重复数 $R=12$，文库大小 $L = 2{,}000{,}000$，随机种子在不同条件下固定但不同，显著性水平 $\\alpha = 0.001$，目标基因索引 $i^\\star = 1$。\n- 任务：模拟 A 和 B 的计数，计算每个样本的 TPM，对 $\\{\\mathrm{TPM}_{i^\\star,s} : s \\in A\\}$ 与 $\\{\\mathrm{TPM}_{i^\\star,s} : s \\in B\\}$ 执行 Welch t 检验，并返回一个布尔值，该值指示在 TPM 上进行的朴素差异表达检测结果与基因 $i^\\star$ 的绝对分子数未改变的事实相矛盾。具体来说，如果检验的 p 值严格小于 $\\alpha$，并且条件 B 中的平均 TPM 严格小于条件 A 中的平均 TPM，则返回 true，即使 $m^{(A)}_{i^\\star} = m^{(B)}_{i^\\star}$。\n\n测试用例 2 (关于全局缩放下出现假阴性的反例)：\n- 参数：$G=4$，$\\ell = (800, 1000, 1200, 1500)$，条件 A 分子数 $\\mathbf{m}^{(A)} = (1000, 2000, 3000, 4000)$，条件 B 分子数 $\\mathbf{m}^{(B)} = 2 \\cdot \\mathbf{m}^{(A)}$ (所有基因全局增加两倍)，每个条件的重复数 $R=12$，文库大小 $L = 2{,}000{,}000$，随机种子在不同条件下固定但不同，显著性水平 $\\alpha = 0.001$，目标基因索引 $i^\\star = 1$。\n- 任务：模拟 A 和 B 的计数，计算每个样本的 TPM，对跨条件的 $\\mathrm{TPM}_{i^\\star}$ 执行 Welch t 检验，并返回一个布尔值，该值指示朴素方法未能检测到由全局缩放引起的真实变化。具体来说，如果检验的 p 值大于或等于 $\\alpha$，则返回 true，即使目标基因的绝对分子数已加倍。\n\n测试用例 3 (量化闭合引入的相关性)：\n- 重用测试用例 1 的参数，并合并两个条件下的所有 TPM 样本（总共 $2R$ 个样本）。\n- 任务：使用所有 $2R$ 个样本的 TPM 值计算 $G$ 个基因间的皮尔逊相关矩阵。返回平均非对角相关值（浮点数），该值计算为所有 $i \\neq j$ 的两两相关性的均值。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为用方括号括起来的逗号分隔列表，顺序为：测试用例 1 布尔值，测试用例 2 布尔值，测试用例 3 浮点数。例如，一个有效的输出可能看起来像“[true,true,-0.215432]”。对布尔值使用小写的“true”/“false”，并用标准十进制表示法表示浮点数。不应打印任何额外文本。",
            "solution": "该问题要求通过实现一个数值模拟，来演示在核糖核酸测序 (RNA-seq) 数据的差异表达分析中使用每百万转录本 (TPM) 归一化所产生的基本伪影。其核心科学原理是，TPM 值是成分性的，意味着它们是整体的一部分，其总和为一个固定常数 ($10^6$) 。这种闭合性质会引入伪相关，并可能导致那些未明确考虑数据成分性质的统计检验得出错误结论。该解决方案围绕三个测试用例设计，以突显这些问题：一个假阳性、一个假阴性，以及对引入的负相关性的量化。\n\n算法设计结构如下：\n1.  一个基于科学上合理的生成模型来模拟 RNA-seq 计数的函数。\n2.  一个从原始计数计算 TPM 值的函数。\n3.  一系列三个测试用例，按规定实现模拟、归一化和统计分析。\n\n**1. RNA-seq 计数的模拟**\n\n分析的基础是对测序过程的真实模拟。我们将一个包含 $G$ 个基因的样本 $s$ 的读数计数建模为从多项分布中的一次抽样：\n$$\n(c_{1,s}, \\dots, c_{G,s}) \\sim \\mathrm{Multinomial}(L; p_1, \\dots, p_G)\n$$\n在这里，$L$ 是总文库大小（样本的总读数数），$\\mathbf{p} = (p_1, \\dots, p_G)$ 是给定读数来源于特定基因的概率向量。该模型捕捉了高通量测序的随机抽样性质。概率 $p_i$ 由每个基因的潜在真实分子丰度 $m_i$ 及其有效转录本长度 $\\ell_i$ 决定。更长或丰度更高的转录本更有可能被抽样。因此，基因 $i$ 的概率与乘积 $m_i \\ell_i$ 成正比，并被归一化以使总和为一：\n$$\np_i = \\frac{m_i \\ell_i}{\\sum_{j=1}^{G} m_j \\ell_j}\n$$\n对每个实验条件（A 和 B）中的 $R$ 个重复样本，此模拟是独立执行的，使用不同的分子丰度向量 $\\mathbf{m}^{(A)}$ 和 $\\mathbf{m}^{(B)}$，但为了可复现性，使用固定的随机种子。\n\n**2. TPM 归一化**\n\n根据模拟的计数 $c_{i,s}$，我们计算 TPM 值。其公式为：\n$$\n\\mathrm{TPM}_{i,s} = 10^6 \\cdot \\frac{c_{i,s}/\\ell_i}{\\sum_{j=1}^{G} c_{j,s}/\\ell_j}\n$$\n项 $c_{i,s}/\\ell_i$ 代表转录本每个碱基的读数率，可作为转录本丰度的代理指标。归一化步骤包括将此比率除以样本中所有此类比率的总和，将其转换为相对比例，并将其缩放至总和为一百万。这个分母 $\\sum_{j=1}^{G} c_{j,s}/\\ell_j$ 是将样本内所有基因的 TPM 值耦合在一起的关键组成部分，从而施加了闭合约束 $\\sum_{i=1}^{G} \\mathrm{TPM}_{i,s} = 10^6$。\n\n**3. 测试用例和统计分析**\n\n**测试用例 1：假阳性检测**\n这个案例演示了一个基因的变化如何在一个不相关、未改变的基因中产生统计上显著但人为的变化。\n-   **原理**：我们将目标基因 ($i^\\star = 1$) 的真实分子丰度在条件 A ($\\mathbf{m}^{(A)}_{1} = 1000$) 和条件 B ($\\mathbf{m}^{(B)}_{1} = 1000$) 之间设为相同。但是，在条件 B 中，我们大幅增加另一个基因 ($i=3$) 的丰度。\n-   **机制**：$\\mathbf{m}^{(B)}_3$ 的大幅增加会极大地增加条件 B 样本中所有基因 TPM 计算的分母。因此，即使基因 1 的原始计数可能与条件 A 中的相似（除去采样噪声），其 TPM 值也会被人为地抑制。\n-   **实现**：为每个条件的 $R=12$ 个重复样本模拟计数。为所有样本计算 TPM 值。对两个条件之间目标基因 ($i^\\star = 1$) 的 TPM 值执行 Welch 双样本 t 检验。如果得到的 p 值小于显著性水平 $\\alpha=0.001$ 并且 B 中的平均 TPM 小于 A 中的平均 TPM，则该检验被视为“假阳性”，这会被朴素地解释为下调。\n\n**测试用例 2：假阴性检测**\n这个案例说明了 TPM 无法检测到影响所有基因的全局性、系统性变化。\n-   **原理**：我们模拟一个场景，其中条件 B 中每个基因的真实分子丰度都是条件 A 中的两倍，即 $\\mathbf{m}^{(B)} = 2 \\cdot \\mathbf{m}^{(A)}$。这代表了一个真实的、生物学上显著的变化。\n-   **机制**：当所有 $m_i$ 都按一个常数因子 $k$（此处 $k=2$）进行缩放时，多项分布概率 $p_i$ 保持不变：\n$$\np_i^{(B)} = \\frac{(k \\cdot m_i^{(A)}) \\ell_i}{\\sum_{j=1}^{G} (k \\cdot m_j^{(A)}) \\ell_j} = \\frac{k (m_i^{(A)} \\ell_i)}{k (\\sum_{j=1}^{G} m_j^{(A)} \\ell_j)} = p_i^{(A)}\n$$\n由于两个条件的抽样概率相同，因此计数的预期分布以及 TPM 的预期分布也相同。归一化完全掩盖了潜在的绝对丰度两倍增加。\n-   **实现**：像之前一样生成计数和 TPM。预期对目标基因 ($i^\\star=1$) 的 TPM 进行的 Welch t 检验会得到一个很高的 p 值，从而未能检测到真实的变化。如果 p 值大于或等于 $\\alpha = 0.001$，则该检验被视为“假阴性”。\n\n**测试用例 3：量化引入的相关性**\n该测试衡量由闭合性质强制施加的负相关结构。\n-   **原理**：如问题所述，对于具有恒定总和的成分数据 $X_i$，$\\sum_{j \\neq i} \\mathrm{cov}(X_i,X_j) = -\\mathrm{var}(X_i)$。这意味着平均而言，一个组分的增加必须由其他组分的减少来平衡，从而促成负协方差和负相关，这些是归一化产生的数学伪影，而不一定是生物协同调控。\n-   **机制**：我们使用测试用例 1 的数据，其中条件 A 和 B 之间的显著差异（由基因 3 驱动）在 TPM 数据中产生了强烈的变异。这种变异为观察引入的相关性提供了良好的基础。\n-   **实现**：将测试用例 1 的两个条件的 TPM 矩阵合并成一个包含 $2R=24$ 个样本的单一数据集。然后计算 $G=4$ 个基因间的皮尔逊相关矩阵。最终输出是该相关矩阵所有非对角元素的平均值，它量化了在这种特定情况下由 TPM 归一化引入的平均成对相关性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import ttest_ind\n\ndef solve():\n    \"\"\"\n    Solves the three test cases related to RNA-seq data normalization and analysis.\n    \"\"\"\n\n    # Helper function to simulate RNA-seq counts using a multinomial model.\n    def simulate_counts(m, l, L, R, seed):\n        \"\"\"\n        Simulates counts for R replicates.\n        \n        Args:\n            m (np.array): Vector of molecule counts per gene.\n            l (np.array): Vector of gene lengths.\n            L (int): Library size (total reads).\n            R (int): Number of replicates.\n            seed (int): Random seed for reproducibility.\n\n        Returns:\n            np.array: An (R x G) matrix of simulated counts.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        # Calculate sampling probabilities proportional to molecule count * length\n        ml = m * l\n        # Check for sum of ml being zero to avoid division by zero, though unlikely.\n        sum_ml = np.sum(ml)\n        p = ml / sum_ml if sum_ml  0 else np.zeros_like(ml)\n        \n        counts = rng.multinomial(n=L, pvals=p, size=R)\n        return counts\n\n    # Helper function to calculate TPM from a counts matrix.\n    def calculate_tpm(counts, l):\n        \"\"\"\n        Calculates Transcripts Per Million (TPM).\n\n        Args:\n            counts (np.array): An (R x G) matrix of counts.\n            l (np.array): Vector of gene lengths.\n\n        Returns:\n            np.array: An (R x G) matrix of TPM values.\n        \"\"\"\n        # rate = counts per kilobase\n        rate = counts / l\n        # sum of rates per sample\n        sum_of_rates = np.sum(rate, axis=1, keepdims=True)\n        # Avoid division by zero if a sample has all zero counts\n        sum_of_rates[sum_of_rates == 0] = 1\n        \n        tpm = 1e6 * (rate / sum_of_rates)\n        return tpm\n\n    results = []\n\n    # --- Test Case 1: Counterexample for false positive ---\n    params1 = {\n        'G': 4,\n        'l': np.array([1000, 1000, 1000, 1000], dtype=float),\n        'm_A': np.array([1000, 1000, 1000, 1000], dtype=float),\n        'm_B': np.array([1000, 1000, 100000, 1000], dtype=float),\n        'R': 12,\n        'L': 2_000_000,\n        'alpha': 0.001,\n        'target_gene_idx': 0,  # Gene i* = 1 is at index 0\n        'seed_A': 123,\n        'seed_B': 456\n    }\n    \n    counts_A1 = simulate_counts(params1['m_A'], params1['l'], params1['L'], params1['R'], params1['seed_A'])\n    counts_B1 = simulate_counts(params1['m_B'], params1['l'], params1['L'], params1['R'], params1['seed_B'])\n    \n    tpm_A1 = calculate_tpm(counts_A1, params1['l'])\n    tpm_B1 = calculate_tpm(counts_B1, params1['l'])\n\n    tpm_A1_target = tpm_A1[:, params1['target_gene_idx']]\n    tpm_B1_target = tpm_B1[:, params1['target_gene_idx']]\n\n    _, p_val1 = ttest_ind(tpm_A1_target, tpm_B1_target, equal_var=False)\n    \n    result1 = (p_val1  params1['alpha']) and (np.mean(tpm_B1_target)  np.mean(tpm_A1_target))\n    results.append(str(result1).lower())\n\n    # --- Test Case 2: Counterexample for false negative ---\n    params2 = {\n        'G': 4,\n        'l': np.array([800, 1000, 1200, 1500], dtype=float),\n        'm_A': np.array([1000, 2000, 3000, 4000], dtype=float),\n        'm_B': 2 * np.array([1000, 2000, 3000, 4000], dtype=float),\n        'R': 12,\n        'L': 2_000_000,\n        'alpha': 0.001,\n        'target_gene_idx': 0, # Gene i* = 1 is at index 0\n        'seed_A': 123,\n        'seed_B': 456\n    }\n\n    counts_A2 = simulate_counts(params2['m_A'], params2['l'], params2['L'], params2['R'], params2['seed_A'])\n    counts_B2 = simulate_counts(params2['m_B'], params2['l'], params2['L'], params2['R'], params2['seed_B'])\n    \n    tpm_A2 = calculate_tpm(counts_A2, params2['l'])\n    tpm_B2 = calculate_tpm(counts_B2, params2['l'])\n\n    tpm_A2_target = tpm_A2[:, params2['target_gene_idx']]\n    tpm_B2_target = tpm_B2[:, params2['target_gene_idx']]\n\n    _, p_val2 = ttest_ind(tpm_A2_target, tpm_B2_target, equal_var=False)\n    \n    result2 = p_val2 = params2['alpha']\n    results.append(str(result2).lower())\n    \n    # --- Test Case 3: Quantifying closure-induced correlation ---\n    # Reuses TPM data from Test Case 1\n    all_tpm = np.vstack((tpm_A1, tpm_B1))\n    \n    # rowvar=False because genes are columns, samples are rows\n    corr_matrix = np.corrcoef(all_tpm, rowvar=False)\n    \n    G = params1['G']\n    # Sum of off-diagonal elements / number of off-diagonal elements\n    num_off_diagonal = G * G - G\n    sum_off_diagonal = np.sum(corr_matrix) - np.trace(corr_matrix)\n    avg_corr = sum_off_diagonal / num_off_diagonal if num_off_diagonal  0 else 0.0\n    \n    # Format to 6 decimal places as in the example\n    results.append(f\"{avg_corr:.6f}\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "认识到朴素归一化的陷阱后，下一步是为差异表达分析构建一个严谨的统计框架。本练习将指导你从零开始，使用迭代重加权最小二乘法（IRLS）算法实现一个泊松广义线性模型（GLM）。你将学习如何正确地处理批次效应和文库大小等混杂变量，从而准确地估计实验条件特异性的效应。",
            "id": "4370596",
            "problem": "您将处理一个广义线性建模任务，该任务针对系统生物医学背景下的高通量计数数据。目标是在存在批次效应的情况下计算条件特异性效应，同时通过偏移量对文库大小进行适当的归一化。模型必须基于泊松广义线性模型（Poisson GLM）的规范定义，从第一性原理出发进行推导和实现，该模型使用对数连接函数和已知的偏移量。\n\n请从以下基本原理和定义开始。对于每个基因，各样本的观测计数值被建模为 $y_i \\sim \\text{Poisson}(\\mu_i)$，其中 $i \\in \\{1,\\dots,n\\}$，$n$ 是样本数量。具有对数连接和已知偏移量的泊松 GLM 满足\n$$\n\\log \\mu_i \\;=\\; \\eta_i \\;=\\; x_i^\\top \\beta \\;+\\; o_i,\n$$\n其中 $x_i \\in \\mathbb{R}^p$ 是样本 $i$ 的协变量行向量，$\\beta \\in \\mathbb{R}^p$ 是待估计的回归系数，$o_i$ 是一个已知的偏移量。在此问题中，偏移量必须通过使用文库大小的自然对数来编码文库大小归一化。为保证数值稳定性和截距项的可解释性，请使用中心化的偏移量，即 $o_i \\;=\\; \\log L_i - \\frac{1}{n}\\sum_{j=1}^n \\log L_j$，其中 $L_i$ 是样本 $i$ 的文库大小。系统性成分使用一个截距项、一个条件指示变量和一个批次指示变量。条件特异性效应是与条件指示变量对应的系数，批次效应是与批次指示变量对应的系数。所有拟合都必须通过使用迭代重加权最小二乘法（IRLS）进行最大似然估计来执行，该算法源自具有对数连接和已知偏移量的泊松似然函数，且不得依赖任何黑盒建模库。\n\n将条件效应的对比构建为线性泛函 $c^\\top \\beta$，其中 $c \\in \\mathbb{R}^p$ 用于选择条件系数，同时保持截距项和批次效应恒定。在无交互作用的加性模型中，使用 $c = [0, 1, 0]^\\top$，其中系数顺序为截距项、条件、批次。将 $c^\\top \\beta$ 解释为在自然对数尺度上，经过批次和文库大小校正后的条件效应的估计对数速率比。通过除以 $\\log 2$ 将其转换为以 $2$ 为底的对数，从而获得估计的 $\\log_2$ 倍数变化。\n\n实现要求。对于每个基因，使用标准的泊松 GLM 工作响应和权重，通过 IRLS 求解 $\\beta$。具体来说，在给定当前 $\\beta$ 的情况下，计算 $\\eta = X \\beta + o$，$\\mu = \\exp(\\eta)$，工作响应 $z = \\eta + \\frac{y - \\mu}{\\mu}$，以及对角权重矩阵 $W = \\mathrm{diag}(\\mu)$。通过求解加权最小二乘正规方程组来更新 $\\beta$，以逼近 $X \\beta \\approx z - o$，其中使用 $W$ 作为权重，即\n$$\n\\beta_{\\text{new}} \\;=\\; \\arg\\min_{\\beta \\in \\mathbb{R}^p} \\; \\sum_{i=1}^n \\mu_i \\,\\big(z_i - o_i - x_i^\\top \\beta\\big)^2.\n$$\n为确保在边缘情况下的数值稳定性，请在正规方程组上加入一个小的岭回归正则化项 $\\lambda I_p$，其中 $\\lambda  0$ 是一个非常小的值（例如，$\\lambda = 10^{-6}$），$I_p$ 是 $p \\times p$ 的单位矩阵。迭代直至系数差异的欧几里得范数小于某个容差 $\\varepsilon$（例如，$\\varepsilon = 10^{-8}$），或达到最大迭代次数。最终估计值应与应用于偏移量的任何常数移位无关（按规定对偏移量进行中心化可确保截距项具有良好的尺度）。\n\n设计矩阵和样本注释。共有 $n = 4$ 个样本，包含一个截距项、一个二元条件指示变量和一个二元批次指示变量。设计矩阵的列顺序为截距项、条件、批次。样本注释如下：样本 $1$ 的条件为 $0$、批次为 $0$；样本 $2$ 的条件为 $0$、批次为 $1$；样本 $3$ 的条件为 $1$、批次为 $0$；样本 $4$ 的条件为 $1$、批次为 $1$。因此，$X$ 的行分别为 $[1,0,0]$、$[1,0,1]$、$[1,1,0]$ 和 $[1,1,1]$。\n\n测试套件。实现您的程序以处理以下三个独立的测试用例。在每个测试用例中，按给定基因的顺序，为每个基因计算条件效应的估计 $\\log_2$ 倍数变化。对于包含 $4$ 个样本的测试用例，偏移量必须计算为 $o_i = \\log L_i - \\frac{1}{4}\\sum_{j=1}^4 \\log L_j$。对比始终为 $c = [0,1,0]^\\top$。对于每个测试用例，设计矩阵和列顺序均如上所述。\n\n测试用例 1（理想情况）：两个基因，四个样本，不同的文库大小。\n- 文库大小 $L = [$ $10^6$, $5\\times 10^5$, $2\\times 10^6$, $1.5\\times 10^6$ $]$。\n- 基因 $1$ 计数 $y^{(1)} = [$ $10$, $5$, $42$, $26$ $]$。\n- 基因 $2$ 计数 $y^{(2)} = [$ $15$, $10$, $28$, $30$ $]$。\n\n测试用例 2（包含零值和相反效应的边缘情况）：三个基因，四个样本，文库大小与测试用例 1 相同。\n- 文库大小 $L = [$ $10^6$, $5\\times 10^5$, $2\\times 10^6$, $1.5\\times 10^6$ $]$。\n- 基因 $1$ 计数 $y^{(1)} = [$ $39$, $19$, $18$, $14$ $]$。\n- 基因 $2$ 计数 $y^{(2)} = [$ $8$, $7$, $15$, $19$ $]$。\n- 基因 $3$ 计数 $y^{(3)} = [$ $0$, $0$, $2$, $1$ $]$。\n\n测试用例 3（文库大小相等且真实条件效应为零的边界情况）：一个基因，四个样本，相等的文库大小。\n- 文库大小 $L = [$ $10^6$, $10^6$, $10^6$, $10^6$ $]$。\n- 基因 $1$ 计数 $y^{(1)} = [$ $12$, $18$, $12$, $18$ $]$。\n\n最终输出要求。您的程序必须生成单行输出，其中包含一个列表，该列表聚合了所有测试用例的所有估计 $\\log_2$ 倍数变化，顺序如下：首先是测试用例 1 的所有基因（按基因顺序），然后是测试用例 2 的所有基因（按基因顺序），最后是测试用例 3 的所有基因（按基因顺序）。每个值必须精确四舍五入到 $4$ 位小数，并以十进制数形式打印。输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，例如 $[$ $x_1$, $x_2$, $\\dots$, $x_m$ $]$，其中 $m$ 是所有测试用例中基因特异性结果的总数。不得打印任何其他文本。",
            "solution": "该问题是有效的。它提出了一个清晰、有科学依据且定义明确的计算统计学任务，具体涉及实现泊松广义线性模型（GLM）以分析高通量计数数据。所有必要的数据、模型规范和算法细节都已提供。\n\n根据要求，解决方案从第一性原理出发。我们将样本 $i$ 中每个基因的观测计数值 $y_i$ 建模为服从泊松分布，即 $y_i \\sim \\text{Poisson}(\\mu_i)$。GLM 的核心是期望计数值 $\\mu_i$ 与一组协变量之间的关系，这由一个连接函数和一个线性预测器定义。\n\n问题指定了对数连接函数，从而得出模型：\n$$\n\\log(\\mu_i) = \\eta_i = x_i^\\top \\beta + o_i\n$$\n此处，$\\eta_i$ 是线性预测器，$x_i^\\top$ 是设计矩阵 $X$ 的第 $i$ 行，编码了实验因素（截距项、条件、批次），$\\beta$ 是待估计的系数向量，$o_i$ 是一个已知的偏移量。偏移量对于归一化计数值以考虑样本间文库大小（$L_i$）的变化至关重要。指定的中心化偏移量 $o_i = \\log L_i - \\frac{1}{n}\\sum_{j=1}^n \\log L_j$ 可确保截距项系数 $\\beta_0$ 可解释为具有平均文库大小的样本的基线对数速率，同时不影响其他系数的估计值。\n\n系数 $\\beta$ 是通过最大似然估计（MLE）来估计的。对于 GLM，似然函数并非通过封闭形式解来最大化，而是通过迭代数值方法。用于此目的的标准算法是迭代重加权最小二乘法（IRLS）。IRLS 等同于牛顿-拉弗森法或费雪评分法，用于找到似然函数梯度（得分函数）的根。\n\nIRLS 算法的每次迭代都涉及构建并求解一个加权最小二乘（WLS）问题，该问题局部逼近了 MLE 问题。根据规定，对于给定的估计值 $\\beta_{\\text{old}}$，我们为每个样本 $i=1, \\dots, n$ 计算以下量：\n1.  线性预测器：$\\eta_i = x_i^\\top \\beta_{\\text{old}} + o_i$。\n2.  估计均值：$\\mu_i = \\exp(\\eta_i)$。\n3.  对角权重矩阵：$W = \\mathrm{diag}(\\mu_1, \\dots, \\mu_n)$。对于具有对数连接的泊松模型，权重就是估计的均值。\n4.  工作响应：$z_i = \\eta_i + \\frac{y_i - \\mu_i}{\\mu_i}$。这个量将模型在当前估计值附近线性化。\n\n系数向量的更新值 $\\beta_{\\text{new}}$ 是通过求解一个 WLS 问题得到的，即将“工作残差” $z_i - o_i$ 对协变量 $x_i$ 进行回归，权重为 $\\mu_i$。这对应于最小化加权平方和：\n$$\n\\beta_{\\text{new}} = \\arg\\min_{\\beta \\in \\mathbb{R}^p} \\sum_{i=1}^n \\mu_i (z_i - o_i - x_i^\\top \\beta)^2\n$$\n该 WLS 问题的解由其正规方程组给出。为了增强数值稳定性，特别是在计数值低、数据分离或近共线性的情况下，会增加一个小的岭回归正则化项 $\\lambda I_p$。因此，$\\beta$ 的更新值通过求解以下线性系统获得：\n$$\n(X^\\top W X + \\lambda I_p) \\beta_{\\text{new}} = X^\\top W (z - o)\n$$\n其中 $z$ 和 $o$ 分别是工作响应和偏移量的列向量。\n\n实现将从 $\\beta$ 的一个初始猜测（例如 $\\beta = 0$）开始，并重复求解此线性系统，在每一步更新 $\\beta$。该过程持续进行，直到两次迭代之间 $\\beta$ 向量的变化（用欧几里得范数 $\\|\\beta_{\\text{new}} - \\beta_{\\text{old}}\\|_2$ 衡量）小于指定的容差 $\\varepsilon = 10^{-8}$，或达到最大迭代次数。在实现中，计算工作响应 $z_i$ 时必须小心，因为 $\\mu_i$ 可能接近于零。一种常见的做法（也将被采纳）是在分母 $\\mu_i$ 上加上一个小的正常数，以防止除以零。\n\n收敛后，算法得出最大似然估计值 $\\hat\\beta$。问题要求计算条件特异性效应，由对比 $c = [0, 1, 0]^\\top$ 定义。因此，条件的估计对数速率比（在自然对数尺度上）为 $c^\\top \\hat\\beta = \\hat\\beta_1$。为将其表示为 $\\log_2$ 倍数变化（在基因组学中是常规做法），该值需除以 $\\log 2$：\n$$\n\\text{log}_2 \\text{FoldChange} = \\frac{\\hat\\beta_1}{\\log 2}\n$$\n此过程将独立应用于所提供测试套件中的每个基因，以计算所需的值。",
            "answer": "```python\nimport numpy as np\n\ndef irls_poisson_glm(y, X, L, lambda_reg, tol, max_iter):\n    \"\"\"\n    Fits a Poisson GLM with a log link and library size offsets using IRLS.\n\n    Args:\n        y (np.ndarray): Vector of observed counts.\n        X (np.ndarray): Design matrix.\n        L (np.ndarray): Vector of library sizes.\n        lambda_reg (float): Ridge regularization parameter.\n        tol (float): Convergence tolerance for the norm of beta difference.\n        max_iter (int): Maximum number of iterations.\n\n    Returns:\n        np.ndarray: The estimated coefficient vector beta.\n    \"\"\"\n    n_samples, n_coeffs = X.shape\n\n    # 1. Compute centered log-library size offsets\n    log_L = np.log(L)\n    offsets = log_L - np.mean(log_L)\n\n    # 2. Initialize beta coefficients to zero\n    beta = np.zeros(n_coeffs)\n\n    # 3. Perform Iteratively Reweighted Least Squares (IRLS)\n    for _ in range(max_iter):\n        beta_old = beta.copy()\n\n        # Compute linear predictor and mean response\n        eta = X @ beta + offsets\n        mu = np.exp(eta)\n\n        # Compute working response `z`\n        # A small constant is added to mu in the denominator for numerical stability,\n        # especially important for samples with zero counts where mu can be very small.\n        mu_safe_denominator = np.maximum(mu, 1e-12)\n        z = eta + (y - mu) / mu_safe_denominator\n\n        # Compute diagonal weight matrix W (as a vector for efficiency)\n        W_diag = mu\n        \n        # Solve the regularized normal equations for the WLS problem:\n        # (X^T W X + lambda*I) beta = X^T W (z - o)\n        \n        # Construct the left-hand side matrix, A\n        # Using element-wise multiplication for efficiency (avoids forming large W matrix)\n        A = X.T @ (X * W_diag[:, np.newaxis]) + lambda_reg * np.identity(n_coeffs)\n\n        # Construct the right-hand side vector, b\n        b_vec = W_diag * (z - offsets)\n        b = X.T @ b_vec\n\n        # Solve for the new beta\n        try:\n            beta = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # In case of a singular matrix despite regularization,\n            # we halt and return the last valid estimate.\n            return beta_old\n\n        # Check for convergence\n        if np.linalg.norm(beta - beta_old)  tol:\n            break\n\n    return beta\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    # Define the fixed design matrix for all test cases\n    # Columns: Intercept, Condition, Batch\n    X = np.array([\n        [1, 0, 0],\n        [1, 0, 1],\n        [1, 1, 0],\n        [1, 1, 1]\n    ], dtype=float)\n\n    # Parameters for the IRLS algorithm from the problem description\n    lambda_reg = 1e-6\n    tol = 1e-8\n    max_iter = 100\n\n    # Define the test suite\n    test_cases = [\n        # Test case 1\n        {\n            \"L\": np.array([1e6, 5e5, 2e6, 1.5e6]),\n            \"genes\": [\n                np.array([10, 5, 42, 26]),\n                np.array([15, 10, 28, 30])\n            ]\n        },\n        # Test case 2\n        {\n            \"L\": np.array([1e6, 5e5, 2e6, 1.5e6]),\n            \"genes\": [\n                np.array([39, 19, 18, 14]),\n                np.array([8, 7, 15, 19]),\n                np.array([0, 0, 2, 1])\n            ]\n        },\n        # Test case 3\n        {\n            \"L\": np.array([1e6, 1e6, 1e6, 1e6]),\n            \"genes\": [\n                np.array([12, 18, 12, 18])\n            ]\n        }\n    ]\n\n    all_results = []\n    \n    # Process each test case\n    for case in test_cases:\n        L = case[\"L\"]\n        for y_counts in case[\"genes\"]:\n            # Ensure count vector is a float array for calculations\n            y = np.array(y_counts, dtype=float)\n            \n            # Fit the GLM to get the beta coefficients\n            beta_hat = irls_poisson_glm(y, X, L, lambda_reg, tol, max_iter)\n            \n            # The condition effect coefficient is beta_hat[1]\n            # This corresponds to c^T * beta where c = [0, 1, 0]^T\n            log_rate_ratio = beta_hat[1]\n            \n            # Convert to log2 fold change\n            log2_fold_change = log_rate_ratio / np.log(2)\n            \n            all_results.append(log2_fold_change)\n\n    # Format results to 4 decimal places and create the output string\n    formatted_results = [f\"{val:.4f}\" for val in all_results]\n    \n    # Print the final output in the specified format\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "虽然GLM为差异表达分析提供了坚实的基础，但其原始的对数倍数变化（$LFC$）估计值对于低计数或高变异性的基因可能并不可靠。这项高级练习深入探讨了经验贝叶斯收缩，这是一种强大的统计技术，用于稳定这些$LFC$估计值 。通过实现受现代工具启发的程序，你将洞悉偏差-方差权衡，并学会如何生成更稳健、更具解释性的结果。",
            "id": "4370601",
            "problem": "给定一个小的双条件RNA测序计数数据集，要求您实现对数倍数变化的经验贝叶斯收缩。该设计的基础始于贝叶斯定理、用于测序计数的负二项模型、通过比例中值法定义的规模因子归一化，以及使用delta方法推导方差的最大似然对数倍数变化估计量的正态近似。目标是使用两种先验为每个基因计算收缩后的对数倍数变化：柯西先验（类似apeglm）和零中心正态混合先验（自适应收缩，类似ashr），并通过计算与指定真实对数倍数变化向量的均方误差来量化偏差-方差权衡。\n\n考虑$G=6$个基因和$S=6$个样本，分为两个条件，$A$和$B$，每个条件有$n_A=n_B=3$个重复。样本排序为$A_1,A_2,A_3,B_1,B_2,B_3$。基因$g \\in \\{1,\\dots,6\\}$和样本$i \\in \\{1,\\dots,6\\}$的观测原始计数$x_{g,i}$如下：\n\n- 基因1：条件$A$计数$[48,52,55]$，条件$B$计数$[50,49,53]$。\n- 基因2：条件$A$计数$[30,28,32]$，条件$B$计数$[60,64,58]$。\n- 基因3：条件$A$计数$[90,85,95]$，条件$B$计数$[60,70,65]$。\n- 基因4：条件$A$计数$[0,1,0]$，条件$B$计数$[8,13,11]$。\n- 基因5：条件$A$计数$[6,5,7]$，条件$B$计数$[5,6,6]$。\n- 基因6：条件$A$计数$[500,520,480]$，条件$B$计数$[250,240,260]$。\n\n归一化：令$s_i$为样本$i$的规模因子，通过比例中值法计算。对于每个基因$g$，计算其在所有样本中的几何平均值，\n$$\n\\text{gm}_g = \\exp\\left(\\frac{1}{S}\\sum_{i=1}^S \\log(x_{g,i})\\right),\n$$\n在计算$\\text{gm}_g$时排除任何含有零计数的基因。对于每个样本$i$，对$\\text{gm}_g0$的基因$g$计算比率$r_{g,i} = x_{g,i}/\\text{gm}_g$，并设置\n$$\ns_i = \\text{median}\\left(\\{r_{g,i} : \\text{gm}_g  0\\}\\right).\n$$\n定义归一化计数$y_{g,i} = x_{g,i} / s_i$。\n\n对数倍数变化估计与方差：对于每个基因$g$，计算归一化计数的条件均值，\n$$\nm_{g,A} = \\frac{1}{n_A}\\sum_{i:\\text{cond}(i)=A} y_{g,i},\\quad m_{g,B} = \\frac{1}{n_B}\\sum_{i:\\text{cond}(i)=B} y_{g,i}.\n$$\n使用一个小的伪计数$\\varepsilon=0.5$来稳定比率，并定义观测到的对数倍数变化估计值\n$$\n\\hat{\\beta}_g = \\log\\left(\\frac{m_{g,B} + \\varepsilon}{m_{g,A} + \\varepsilon}\\right).\n$$\n假设负二项方差模型$\\operatorname{Var}(Y)=\\mu + \\alpha \\mu^2$。通过矩估计法估计每个基因的离散度$\\alpha_g$：计算每个条件下$y_{g,i}$的样本方差$v_{g,A}$和$v_{g,B}$，设$\\bar{v}_g = (v_{g,A}+v_{g,B})/2$和$\\bar{m}_g = (m_{g,A}+m_{g,B})/2$，则\n$$\n\\alpha_g = \\max\\left(\\frac{\\bar{v}_g - \\bar{m}_g}{\\bar{m}_g^2},\\,0\\right).\n$$\n使用对数的delta方法，将$\\hat{\\beta}_g$的方差近似为\n$$\ns_g^2 = \\frac{m_{g,B} + \\alpha_g m_{g,B}^2}{n_B\\, m_{g,B}^2} + \\frac{m_{g,A} + \\alpha_g m_{g,A}^2}{n_A\\, m_{g,A}^2}.\n$$\n\n经验贝叶斯收缩方法：\n\n1. 柯西先验收缩（类似apeglm）：假设$\\beta_g$的先验由尺度为$\\gamma$的柯西分布给出：$p(\\beta_g) \\propto \\left(1 + (\\beta_g/\\gamma)^2\\right)^{-1}$。在正态似然$\\hat{\\beta}_g \\sim \\mathcal{N}(\\beta_g, s_g^2)$下，通过求解\n$$\n\\frac{\\tilde{\\beta}_g - \\hat{\\beta}_g}{s_g^2} - \\frac{2\\tilde{\\beta}_g}{\\gamma^2 + \\tilde{\\beta}_g^2} = 0\n$$\n来计算后验众数$\\tilde{\\beta}_g$，使用牛顿法求解，初始值设为$\\hat{\\beta}_g$。\n\n2. 自适应收缩（类似ashr）正态混合先验：假设$\\beta_g$的零中心正态混合先验为\n$$\np(\\beta_g) = \\sum_{k=0}^{K-1} \\pi_k \\,\\mathcal{N}(0, \\sigma_k^2),\n$$\n网格为$\\{\\sigma_k\\}_{k=0}^{K-1} = \\{0, 0.1, 0.2, 0.5, 1.0, 2.0\\}$，混合权重$\\pi_k$通过期望最大化算法最大化所有基因的边际似然来估计。$\\hat{\\beta}_g$的边际密度为\n$$\nf(\\hat{\\beta}_g) = \\sum_{k=0}^{K-1} \\pi_k \\,\\mathcal{N}\\left(0, s_g^2 + \\sigma_k^2\\right).\n$$\n在E步中，计算责任度\n$$\nr_{gk} = \\frac{\\pi_k \\,\\mathcal{N}\\left(\\hat{\\beta}_g; 0, s_g^2 + \\sigma_k^2\\right)}{\\sum_{j=0}^{K-1} \\pi_j \\,\\mathcal{N}\\left(\\hat{\\beta}_g; 0, s_g^2 + \\sigma_j^2\\right)}.\n$$\n在M步中，更新混合权重$\\pi_k \\leftarrow \\frac{1}{G}\\sum_{g=1}^G r_{gk}$。收敛后，计算每个基因的后验均值收缩：\n$$\n\\tilde{\\beta}_g = \\sum_{k=0}^{K-1} w_{gk} \\,\\mu_{gk},\\quad \\mu_{gk} = \\frac{\\sigma_k^2}{\\sigma_k^2 + s_g^2} \\hat{\\beta}_g,\n$$\n其中$w_{gk}$是归一化的后验分量权重，与$\\pi_k \\,\\mathcal{N}\\left(\\hat{\\beta}_g; 0, s_g^2 + \\sigma_k^2\\right)$成正比。\n\n用于偏差-方差分析的真实值：假设基因的真实对数倍数变化（自然对数）如下：\n- 基因1：$\\beta^\\star_1 = 0$。\n- 基因2：$\\beta^\\star_2 = \\log(2)$。\n- 基因3：$\\beta^\\star_3 = \\log(0.7)$。\n- 基因4：$\\beta^\\star_4 = \\log(10)$。\n- 基因5：$\\beta^\\star_5 = 0$。\n- 基因6：$\\beta^\\star_6 = \\log(0.5)$。\n\n对于每种方法和指定参数，计算均方误差\n$$\n\\text{MSE} = \\frac{1}{G}\\sum_{g=1}^G \\left(\\tilde{\\beta}_g - \\beta^\\star_g\\right)^2.\n$$\n\n测试组：\n- 情况1：使用$\\gamma=0.5$的柯西先验收缩。\n- 情况2：使用$\\gamma=1.0$的柯西先验收缩。\n- 情况3：使用$\\gamma=2.5$的柯西先验收缩。\n- 情况4：使用网格$\\{0, 0.1, 0.2, 0.5, 1.0, 2.0\\}$的自适应收缩正态混合先验，初始化为均匀混合权重，并迭代直到$\\pi_k$的最大绝对变化小于$10^{-6}$或达到最大1000次迭代。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按上述测试用例的顺序排列结果，每个值都是一个浮点数，例如$[\\text{mse}_{\\gamma=0.5},\\text{mse}_{\\gamma=1.0},\\text{mse}_{\\gamma=2.5},\\text{mse}_{\\text{ashr}}]$。本问题不涉及任何物理单位或角度；请将所有数值输出表示为该单行上的纯十进制浮点数。",
            "solution": "该问题要求实现和评估两种用于RNA测序（RNA-seq）计数数据中对数倍数变化（LFCs）的经验贝叶斯收缩方法。分析过程分为三个主要阶段：首先，从原始计数中初步估计LFCs及其方差；其次，将收缩方法应用于这些估计值；第三，使用均方误差（MSE）与真实LFCs进行评估。\n\n数据集包含$G=6$个基因和$S=6$个样本，两个条件A和B各有$n_A=n_B=3$个重复。原始计数矩阵$X \\in \\mathbb{N}_0^{G \\times S}$如下所示：\n$$\nX = \\begin{pmatrix}\n48  52  55  50  49  53 \\\\\n30  28  32  60  64  58 \\\\\n90  85  95  60  70  65 \\\\\n0  1  0  8  13  11 \\\\\n6  5  7  5  6  6 \\\\\n500  520  480  250  240  260\n\\end{pmatrix}\n$$\n\n**步骤1：归一化和初步估计**\n\n归一化对于调整样本间测序深度和文库组成的差异至关重要。我们按照指定使用比例中值法。\n\n1.  **几何平均值计算**：对于每个基因$g$，我们通过其在所有样本中的计数的几何平均值来计算一个伪参考样本。任何含有零计数的基因都将从此步骤中排除，以避免几何平均值为零。在我们的数据集中，基因4有零计数，因此被排除。对于剩余的基因$g' \\in \\{1, 2, 3, 5, 6\\}$，其几何平均值为：\n    $$\n    \\text{gm}_{g'} = \\left( \\prod_{i=1}^S x_{g',i} \\right)^{1/S} = \\exp\\left(\\frac{1}{S}\\sum_{i=1}^S \\log(x_{g',i})\\right)\n    $$\n2.  **规模因子计算**：对于每个样本$i$，我们计算其对每个基因$g'$的计数与该基因几何平均值的比率，$r_{g',i} = x_{g',i}/\\text{gm}_{g'}$。样本$i$的规模因子$s_i$是这些比率的中位数：\n    $$\n    s_i = \\text{median}\\left(\\{r_{g',i} : \\text{gm}_{g'}  0\\}\\right)\n    $$\n3.  **归一化计数**：将原始计数$x_{g,i}$除以相应样本的规模因子$s_i$，得到归一化计数$y_{g,i}$：\n    $$\n    y_{g,i} = \\frac{x_{g,i}}{s_i}\n    $$\n4.  **LFC和方差估计**：\n    -   对于每个基因$g$，计算每个条件的平均归一化计数：\n        $$\n        m_{g,A} = \\frac{1}{n_A}\\sum_{i \\in \\text{cond A}} y_{g,i},\\quad m_{g,B} = \\frac{1}{n_B}\\sum_{i \\in \\text{cond B}} y_{g,i}\n        $$\n    -   使用伪计数$\\varepsilon=0.5$来计算对数倍数变化的最大似然估计（MLE）$\\hat{\\beta}_g$，以稳定比率，特别是对于低计数：\n        $$\n        \\hat{\\beta}_g = \\log\\left(\\frac{m_{g,B} + \\varepsilon}{m_{g,A} + \\varepsilon}\\right)\n        $$\n    -   计数的方差由负二项分布建模，$\\operatorname{Var}(Y) = \\mu + \\alpha \\mu^2$，其中$\\alpha$是离散度参数。我们使用矩估计法来估计每个基因的离散度$\\alpha_g$。首先，我们计算每个条件下归一化计数的样本方差，$v_{g,A}$和$v_{g,B}$，并将它们合并：$\\bar{v}_g = (v_{g,A}+v_{g,B})/2$。我们还合并了均值：$\\bar{m}_g = (m_{g,A}+m_{g,B})/2$。然后离散度为：\n        $$\n        \\alpha_g = \\max\\left(\\frac{\\bar{v}_g - \\bar{m}_g}{\\bar{m}_g^2},\\,0\\right)\n        $$\n    -   LFC估计量的方差，$s_g^2 = \\operatorname{Var}(\\hat{\\beta}_g)$，使用delta方法近似。$\\log(m)$的方差约为$\\operatorname{Var}(m)/m^2$。对于有$n$个重复的负二项分布，$\\operatorname{Var}(m) = (\\mu+\\alpha\\mu^2)/n$。这得到：\n        $$\n        s_g^2 = \\frac{\\operatorname{Var}(m_{g,B})}{m_{g,B}^2} + \\frac{\\operatorname{Var}(m_{g,A})}{m_{g,A}^2} = \\frac{m_{g,B} + \\alpha_g m_{g,B}^2}{n_B\\, m_{g,B}^2} + \\frac{m_{g,A} + \\alpha_g m_{g,A}^2}{n_A\\, m_{g,A}^2} = \\frac{1}{n_B}\\left(\\frac{1}{m_{g,B}} + \\alpha_g\\right) + \\frac{1}{n_A}\\left(\\frac{1}{m_{g,A}} + \\alpha_g\\right)\n        $$\n        其中$n_A=n_B=3$。\n\n**步骤2：经验贝叶斯收缩**\n\n我们将两种收缩方法应用于配对$(\\hat{\\beta}_g, s_g^2)$，假设存在一个正态似然$\\hat{\\beta}_g | \\beta_g \\sim \\mathcal{N}(\\beta_g, s_g^2)$。\n\n1.  **柯西先验收缩（类似apeglm）**：假设真实LFC $\\beta_g$服从尺度为$\\gamma$的重尾柯西先验：$p(\\beta_g | \\gamma) \\propto (1 + (\\beta_g/\\gamma)^2)^{-1}$。收缩后的估计值$\\tilde{\\beta}_g$是后验众数。对数后验为$\\log p(\\beta_g | \\hat{\\beta}_g) \\propto -(\\hat{\\beta}_g-\\beta_g)^2/(2s_g^2) - \\log(1+(\\beta_g/\\gamma)^2)$。将其关于$\\beta_g$的导数设为零，得到指定方程：\n    $$\n    \\frac{\\tilde{\\beta}_g - \\hat{\\beta}_g}{s_g^2} - \\frac{2\\tilde{\\beta}_g}{\\gamma^2 + \\tilde{\\beta}_g^2} = 0\n    $$\n    我们对每个基因使用牛顿法求解此方程以得到$\\tilde{\\beta}_g$。设$f(\\beta) = \\frac{\\beta - \\hat{\\beta}_g}{s_g^2} - \\frac{2\\beta}{\\gamma^2 + \\beta^2}$。迭代更新公式为$\\beta_{k+1} = \\beta_k - f(\\beta_k)/f'(\\beta_k)$，初始值为$\\beta_0 = \\hat{\\beta}_g$。导数为$f'(\\beta) = \\frac{1}{s_g^2} - \\frac{2(\\gamma^2 - \\beta^2)}{(\\gamma^2 + \\beta^2)^2}$。对$\\gamma \\in \\{0.5, 1.0, 2.5\\}$重复此过程。\n\n2.  **自适应收缩（类似ashr）**：该方法对真实LFC使用一个灵活的正态混合先验：\n    $$\n    p(\\beta_g | \\pi, \\Sigma) = \\sum_{k=0}^{K-1} \\pi_k \\,\\mathcal{N}(\\beta_g; 0, \\sigma_k^2)\n    $$\n    标准差固定为网格$\\{\\sigma_k\\} = \\{0, 0.1, 0.2, 0.5, 1.0, 2.0\\}$。混合权重$\\pi = (\\pi_0, \\dots, \\pi_{K-1})$通过使用期望最大化（EM）算法最大化所有$\\hat{\\beta}_g$的边际似然从数据中估计。\n    -   **初始化**：对于$k=0,\\dots,5$，使用均匀权重$\\pi_k = 1/K$。\n    -   **E步**：对于每个基因$g$和分量$k$，计算责任度$r_{gk}$，即$\\hat{\\beta}_g$来自第$k$个分量的后验概率。这使用了第$k$个分量的边际密度，$f_k(\\hat{\\beta}_g) = \\mathcal{N}(\\hat{\\beta}_g; 0, s_g^2 + \\sigma_k^2)$:\n        $$\n        r_{gk} = \\frac{\\pi_k f_k(\\hat{\\beta}_g)}{\\sum_{j=0}^{K-1} \\pi_j f_j(\\hat{\\beta}_g)}\n        $$\n    -   **M步**：通过对所有$G$个基因的责任度取平均来更新混合权重：\n        $$\n        \\pi_k^{\\text{new}} = \\frac{1}{G}\\sum_{g=1}^G r_{gk}\n        $$\n    -   E步和M步被迭代执行，直到任何$\\pi_k$的最大绝对变化小于$10^{-6}$或达到1000次迭代。\n    -   **后验均值计算**：在$\\pi_k$值收敛后，收缩估计$\\tilde{\\beta}_g$被计算为后验均值$E[\\beta_g | \\hat{\\beta}_g, s_g^2, \\pi]$。这是来自每个分量的后验均值的加权平均：\n        $$\n        \\tilde{\\beta}_g = \\sum_{k=0}^{K-1} w_{gk} \\mu_{gk}\n        $$\n        其中$w_{gk}$是最终的责任度$r_{gk}$，而$\\mu_{gk}$是第$k$个分量的后验均值：\n        $$\n        \\mu_{gk} = E[\\beta_g | \\hat{\\beta}_g, s_g^2, \\text{component}=k] = \\frac{\\sigma_k^2}{\\sigma_k^2+s_g^2}\\hat{\\beta}_g\n        $$\n\n**步骤3：性能评估**\n\n每种收缩方法的性能通过与一组真实LFCs $\\beta^\\star = (\\beta^\\star_1, \\dots, \\beta^\\star_G)$ 的均方误差（MSE）来量化：\n$$\n\\beta^\\star = (0, \\log(2), \\log(0.7), \\log(10), 0, \\log(0.5))\n$$\n对于一组给定的收缩估计值$\\tilde{\\beta} = (\\tilde{\\beta}_1, \\dots, \\tilde{\\beta}_G)$，其均方误差为：\n$$\n\\text{MSE} = \\frac{1}{G}\\sum_{g=1}^G \\left(\\tilde{\\beta}_g - \\beta^\\star_g\\right)^2\n$$\n对三种柯西收缩情况和一种类似ashr的收缩情况执行此计算，得出四个最终的MSE值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Implements and evaluates empirical Bayesian shrinkage for RNA-seq LFCs.\n    \"\"\"\n    #\n    # Data Setup\n    #\n    G, S = 6, 6\n    n_A, n_B = 3, 3\n    \n    counts = np.array([\n        [48, 52, 55, 50, 49, 53],    # Gene 1\n        [30, 28, 32, 60, 64, 58],    # Gene 2\n        [90, 85, 95, 60, 70, 65],    # Gene 3\n        [0, 1, 0, 8, 13, 11],        # Gene 4\n        [6, 5, 7, 5, 6, 6],          # Gene 5\n        [500, 520, 480, 250, 240, 260] # Gene 6\n    ], dtype=float)\n\n    #\n    # Step 1: Normalization and Initial Estimation\n    #\n\n    # 1.1: Size Factors (Median-of-ratios)\n    # Find genes with no zero counts\n    genes_for_norm = np.all(counts  0, axis=1)\n    \n    # Geometric means for these genes\n    log_counts_for_norm = np.log(counts[genes_for_norm])\n    geo_means = np.exp(np.mean(log_counts_for_norm, axis=1))\n    \n    # Ratios\n    ratios = counts[genes_for_norm] / geo_means[:, np.newaxis]\n    \n    # Size factors\n    size_factors = np.median(ratios, axis=0)\n\n    # 1.2: Normalized Counts\n    norm_counts = counts / size_factors\n\n    # 1.3: LFC and Variance Estimation\n    means_A = np.mean(norm_counts[:, :n_A], axis=1)\n    means_B = np.mean(norm_counts[:, n_A:], axis=1)\n\n    pseudocount = 0.5\n    beta_hat = np.log((means_B + pseudocount) / (means_A + pseudocount))\n\n    var_A = np.var(norm_counts[:, :n_A], axis=1, ddof=1)\n    var_B = np.var(norm_counts[:, n_A:], axis=1, ddof=1)\n    v_bar = (var_A + var_B) / 2\n    m_bar = (means_A + means_B) / 2\n    \n    # Handle m_bar == 0 case (though not present here)\n    m_bar_sq = m_bar**2\n    alpha = np.zeros_like(m_bar)\n    non_zero_m = m_bar_sq  0\n    alpha[non_zero_m] = np.maximum(0, (v_bar[non_zero_m] - m_bar[non_zero_m]) / m_bar_sq[non_zero_m])\n\n    s_sq = np.zeros_like(alpha)\n    # Handle means == 0 cases in variance calc (not present, but good practice)\n    valid_A = means_A  0\n    valid_B = means_B  0\n    valid_both = valid_A  valid_B\n    \n    if np.any(valid_both):\n        s_sq[valid_both] = (1/n_A) * (1/means_A[valid_both] + alpha[valid_both]) + \\\n                           (1/n_B) * (1/means_B[valid_both] + alpha[valid_both])\n    # For invalid means, variance would be infinite. We have no such cases here.\n    # If s_sq ends up with zeros or negative values, they are invalid.\n    s_sq[s_sq = 0] = np.min(s_sq[s_sq  0]) # Small positive value for stability if needed\n\n    #\n    # Step 2: Empirical Bayes Shrinkage\n    #\n\n    # 2.1: Cauchy Prior Shrinkage (apeglm-like)\n    def shrink_cauchy(beta_hat_g, s_sq_g, gamma):\n        beta = beta_hat_g  # Initialize with MLE\n        for _ in range(20): # Newton's method iterations\n            beta_sq = beta**2\n            gamma_sq = gamma**2\n            \n            f_beta = (beta - beta_hat_g) / s_sq_g - (2 * beta) / (gamma_sq + beta_sq)\n            \n            f_prime_beta = 1/s_sq_g - (2 * (gamma_sq - beta_sq)) / (gamma_sq + beta_sq)**2\n            \n            if np.abs(f_prime_beta)  1e-9:\n                break # Avoid division by zero\n            \n            beta = beta - f_beta / f_prime_beta\n        return beta\n\n    beta_tilde_cauchy_0_5 = np.array([shrink_cauchy(beta_hat[g], s_sq[g], 0.5) for g in range(G)])\n    beta_tilde_cauchy_1_0 = np.array([shrink_cauchy(beta_hat[g], s_sq[g], 1.0) for g in range(G)])\n    beta_tilde_cauchy_2_5 = np.array([shrink_cauchy(beta_hat[g], s_sq[g], 2.5) for g in range(G)])\n    \n    # 2.2: Adaptive Shrinkage (ashr-like)\n    def shrink_ashr(beta_hat, s_sq):\n        K = 6\n        sigma = np.array([0, 0.1, 0.2, 0.5, 1.0, 2.0])\n        pi = np.full(K, 1/K)\n        \n        # EM Algorithm\n        for _ in range(1000):\n            pi_old = pi.copy()\n            \n            # E-step\n            log_lik_matrix = np.zeros((G, K))\n            for k in range(K):\n                # Likelihood N(beta_hat_g; 0, s_sq_g + sigma_k^2)\n                # scipy.stats.norm.pdf(x, loc=mu, scale=std_dev)\n                total_var = s_sq + sigma[k]**2\n                log_lik_matrix[:, k] = norm.logpdf(beta_hat, loc=0, scale=np.sqrt(total_var))\n\n            log_pi = np.log(pi)\n            joint_log_lik = log_pi + log_lik_matrix\n            \n            # Normalize to get responsibilities r_gk (in log space to avoid underflow)\n            log_marg_lik = np.log(np.sum(np.exp(joint_log_lik - np.max(joint_log_lik, axis=1, keepdims=True)), axis=1)) + np.max(joint_log_lik, axis=1)\n            log_r_gk = joint_log_lik - log_marg_lik[:, np.newaxis]\n            r_gk = np.exp(log_r_gk)\n\n            # M-step\n            pi = np.mean(r_gk, axis=0)\n\n            if np.max(np.abs(pi - pi_old))  1e-6:\n                break\n        \n        # Posterior mean calculation\n        beta_tilde = np.zeros(G)\n        for g in range(G):\n            # component posterior means\n            mu_gk = (sigma**2 / (sigma**2 + s_sq[g])) * beta_hat[g]\n            # final responsibilities/weights are w_gk = r_gk\n            w_gk = r_gk[g, :]\n            beta_tilde[g] = np.sum(w_gk * mu_gk)\n\n        return beta_tilde\n\n    beta_tilde_ashr = shrink_ashr(beta_hat, s_sq)\n\n    #\n    # Step 3: Performance Evaluation\n    #\n    beta_star = np.array([\n        0,                 # Gene 1\n        np.log(2),         # Gene 2\n        np.log(0.7),       # Gene 3\n        np.log(10),        # Gene 4\n        0,                 # Gene 5\n        np.log(0.5)        # Gene 6\n    ])\n\n    def calculate_mse(beta_tilde, beta_star):\n        return np.mean((beta_tilde - beta_star)**2)\n\n    mse_cauchy_0_5 = calculate_mse(beta_tilde_cauchy_0_5, beta_star)\n    mse_cauchy_1_0 = calculate_mse(beta_tilde_cauchy_1_0, beta_star)\n    mse_cauchy_2_5 = calculate_mse(beta_tilde_cauchy_2_5, beta_star)\n    mse_ashr = calculate_mse(beta_tilde_ashr, beta_star)\n\n    results = [mse_cauchy_0_5, mse_cauchy_1_0, mse_cauchy_2_5, mse_ashr]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}