{
    "hands_on_practices": [
        {
            "introduction": "The structure of a biological network often encodes its function. A powerful way to uncover this structure is by translating the network's adjacency matrix into the language of linear algebra. This practice demonstrates how a fundamental matrix operation, the trace, can be used to count the number of directed 3-cycles, which are crucial feedback loop motifs in gene regulatory networks . Mastering this connection provides a computationally efficient tool for identifying key regulatory patterns from network topology.",
            "id": "4349908",
            "problem": "Consider a directed gene regulatory network with six Transcription Factors (TFs), modeled by a simple directed graph (no self-loops and no multi-edges) whose structure is encoded by the $6 \\times 6$ adjacency matrix $A$, where $A_{ij} = 1$ if there is a directed interaction from TF $i$ to TF $j$, and $A_{ij} = 0$ otherwise. The matrix $A$ is\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0 & 1 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 1 & 1 & 0 & 1 \\\\\n1 & 0 & 0 & 1 & 0 & 0 \\\\\n0 & 1 & 0 & 0 & 1 & 0 \\\\\n0 & 0 & 1 & 0 & 0 & 1 \\\\\n1 & 0 & 0 & 1 & 0 & 0\n\\end{pmatrix}.\n$$\nUsing only core definitions and well-tested facts of graph theory pertaining to adjacency matrices and walks in directed graphs, derive how the quantity $\\mathrm{tr}(A^{3})$ reveals the presence of directed $3$-cycles (three-node feedback loops) in this network. Then evaluate $\\mathrm{tr}(A^{3})$ for the given $A$. Your final answer must be the value of $\\mathrm{tr}(A^{3})$ as a single real number. Additionally, as part of your derivation, briefly justify the biological significance of directed $3$-cycles in systems biomedicine. Do not include any units in the final numerical answer.",
            "solution": "The problem asks for a derivation of the relationship between the trace of the cube of the adjacency matrix, $\\mathrm{tr}(A^3)$, and the number of directed $3$-cycles in a graph, followed by the calculation of this value for a specific gene regulatory network.\n\nFirst, let us establish the theoretical foundation. A fundamental result in graph theory states that for a simple directed graph with $n$ nodes and an adjacency matrix $A$, the entry $(A^k)_{ij}$ of the matrix power $A^k$ gives the number of distinct walks of length $k$ from node $i$ to node $j$. A walk of length $k$ is a sequence of $k+1$ nodes $v_0, v_1, \\dots, v_k$ such that there is a directed edge from $v_{m-1}$ to $v_m$ for all $m \\in \\{1, \\dots, k\\}$.\n\nFor $k=3$, the element $(A^3)_{ij}$ is the number of distinct walks of length $3$ from node $i$ to node $j$. The matrix $A^3$ is the product of $A^2$ and $A$, where $(A^2)_{ip} = \\sum_{q=1}^{n} A_{iq}A_{qp}$. Thus, the elements of $A^3$ are given by:\n$$ (A^3)_{ij} = \\sum_{p=1}^{n} (A^2)_{ip} A_{pj} = \\sum_{p=1}^{n} \\left( \\sum_{q=1}^{n} A_{iq}A_{qp} \\right) A_{pj} = \\sum_{p=1}^{n}\\sum_{q=1}^{n} A_{iq}A_{qp}A_{pj} $$\nThis expression counts the number of walks of the form $i \\to q \\to p \\to j$.\n\nThe trace of $A^3$, denoted $\\mathrm{tr}(A^3)$, is the sum of the diagonal elements of $A^3$:\n$$ \\mathrm{tr}(A^3) = \\sum_{i=1}^{n} (A^3)_{ii} $$\nSubstituting the expression for the diagonal elements, we get:\n$$ \\mathrm{tr}(A^3) = \\sum_{i=1}^{n} \\sum_{p=1}^{n}\\sum_{q=1}^{n} A_{iq}A_{qp}A_{pi} $$\nEach term $A_{iq}A_{qp}A_{pi}$ is equal to $1$ if and only if the sequence of edges $(i, q)$, $(q, p)$, and $(p, i)$ all exist in the graph, forming a closed walk of length $3$: $i \\to q \\to p \\to i$. Otherwise, the term is $0$. Therefore, $\\mathrm{tr}(A^3)$ counts the total number of closed walks of length $3$ in the graph.\n\nLet's analyze the types of closed walks of length $3$:\nA walk $i \\to q \\to p \\to i$ can have repeated nodes.\n1. All nodes are the same: $i=p=q$. The walk is $i \\to i \\to i \\to i$. Its existence requires $A_{ii}=1$. However, the problem states the graph has no self-loops, which is confirmed by the given matrix $A$ having all its diagonal elements equal to $0$. Thus, this type of walk does not exist in our network.\n2. Two nodes are the same (e.g., $i=p$, $p \\neq q$). The walk is $i \\to q \\to i \\to i$. This would require an edge from $i$ to $i$, so $A_{ii}=1$, which is not the case. The same logic applies if $i=q$ or $p=q$ (e.g., $i \\to p \\to p \\to i$ requires $A_{pp}=1$).\n3. All three nodes $i, p, q$ are distinct. The walk $i \\to q \\to p \\to i$ is a directed cycle of length $3$, also known as a $3$-cycle.\n\nSince walks with repeated nodes are ruled out by the absence of self-loops, the quantity $\\mathrm{tr}(A^3)$ counts only the closed walks of length $3$ where all three nodes are distinct. Each such walk corresponds to a unique directed $3$-cycle. A specific $3$-cycle, say involving nodes $\\{v_1, v_2, v_3\\}$ with edges $(v_1, v_2)$, $(v_2, v_3)$, and $(v_3, v_1)$, will be counted three times in the sum for $\\mathrm{tr}(A^3)$:\n- Once as the closed walk $v_1 \\to v_2 \\to v_3 \\to v_1$ (when $i=v_1$).\n- Once as the closed walk $v_2 \\to v_3 \\to v_1 \\to v_2$ (when $i=v_2$).\n- Once as the closed walk $v_3 \\to v_1 \\to v_2 \\to v_3$ (when $i=v_3$).\n\nTherefore, $\\mathrm{tr}(A^3)$ is equal to $3$ times the number of directed $3$-cycles in the graph. If we denote the number of $3$-cycles by $N_3$, we have $\\mathrm{tr}(A^3) = 3 N_3$. This demonstrates how the quantity reveals the presence and abundance of these structures.\n\nIn systems biomedicine, directed cycles are fundamental network motifs known as feedback loops. A $3$-cycle represents a three-component feedback loop (e.g., TF $1$ regulates TF $2$, TF $2$ regulates TF $3$, and TF $3$ in turn regulates TF $1$). Such motifs are of profound biological significance as they are key building blocks for complex dynamic behaviors. For instance, negative feedback loops (those with an odd number of repressive interactions) are critical for promoting stability and homeostasis. Positive feedback loops (with an even number of repressive interactions) can generate bistability, allowing a cell to switch between distinct functional states, a process central to cell differentiation. The interplay of positive and negative feedback can create oscillations, which underpin biological rhythms like the cell cycle and circadian clocks. Thus, identifying and quantifying $3$-cycles is a crucial step in dissecting the functional logic of a gene regulatory network.\n\nNow, we evaluate $\\mathrm{tr}(A^3)$ for the given adjacency matrix $A$:\n$$ A = \\begin{pmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 1 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\end{pmatrix} $$\nFirst, we compute $A^2 = A \\times A$:\n$$ A^2 = \\begin{pmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 1 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 1 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 1 \\\\ 1 & 0 & 0 & 1 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 2 & 1 & 0 & 2 \\\\ 2 & 1 & 0 & 2 & 1 & 0 \\\\ 0 & 2 & 0 & 0 & 2 & 0 \\\\ 0 & 0 & 2 & 1 & 0 & 2 \\\\ 2 & 0 & 0 & 2 & 0 & 0 \\\\ 0 & 2 & 0 & 0 & 2 & 0 \\end{pmatrix} $$\nNext, we compute $A^3 = A^2 \\times A$. We only need the diagonal elements for the trace. The $i$-th diagonal element of $A^3$, $(A^3)_{ii}$, is the dot product of the $i$-th row of $A^2$ and the $i$-th column of $A$.\n$(A^3)_{11} = (0)(0) + (0)(0) + (2)(1) + (1)(0) + (0)(0) + (2)(1) = 2+2=4$\n$(A^3)_{22} = (2)(1) + (1)(0) + (0)(0) + (2)(1) + (1)(0) + (0)(0) = 2+2=4$\n$(A^3)_{33} = (0)(0) + (2)(1) + (0)(0) + (0)(0) + (2)(1) + (0)(0) = 2+2=4$\n$(A^3)_{44} = (0)(0) + (0)(1) + (2)(1) + (1)(0) + (0)(0) + (2)(1) = 2+2=4$\n$(A^3)_{55} = (2)(1) + (0)(0) + (0)(0) + (2)(1) + (0)(0) + (0)(0) = 2+2=4$\n$(A^3)_{66} = (0)(0) + (2)(1) + (0)(0) + (0)(0) + (2)(1) + (0)(0) = 2+2=4$\n\nThe diagonal elements of $A^3$ are all equal to $4$. The trace is the sum of these elements:\n$$ \\mathrm{tr}(A^3) = \\sum_{i=1}^{6} (A^3)_{ii} = 4 + 4 + 4 + 4 + 4 + 4 = 6 \\times 4 = 24 $$\nThe value of $\\mathrm{tr}(A^3)$ is $24$. This indicates that there are $N_3 = \\frac{24}{3} = 8$ distinct directed $3$-cycles in this gene regulatory network.",
            "answer": "$$\\boxed{24}$$"
        },
        {
            "introduction": "Beyond static topology, graph theory provides a framework for understanding the dynamics of biological systems. In metabolic or chemical reaction networks, the stoichiometric matrix $N$ maps reaction rates to changes in species concentrations. This exercise explores how fundamental concepts from linear algebra can reveal profound biological properties by finding the system's conservation laws—combinations of species whose total amount is constant—as vectors in the left null space of $N$ .",
            "id": "4349885",
            "problem": "Consider a Chemical Reaction Network (CRN) represented as a directed graph whose nodes are chemical species and whose edges are reactions transferring a single conserved moiety along a chain. The species are $A$, $B$, $C$, and $D$, and the reactions are $R_{1}: A \\to B$, $R_{2}: B \\to C$, and $R_{3}: C \\to D$. The stoichiometric matrix $N \\in \\mathbb{R}^{4 \\times 3}$ maps reaction fluxes to species concentration changes and is defined by the net stoichiometric change of each species per reaction (negative for reactants, positive for products). Using only fundamental definitions from graph theory and mass-balance laws for CRNs, perform the following:\n\n- Construct the stoichiometric matrix $N$ for this network.\n- Compute the stoichiometric subspace $\\mathcal{S} = \\mathrm{im}(N)$ by deriving a basis and its dimension from first principles.\n- Derive all independent linear conservation laws as vectors in the orthogonal complement $\\mathcal{S}^{\\perp}$, equivalently the left null space $\\ker(N^{\\top})$, by enforcing the condition that the conserved linear combinations remain invariant under all reaction fluxes induced by $N$.\n- Select the unique nonzero conservation-law vector $c \\in \\mathcal{S}^{\\perp}$ normalized so that the sum of its components equals $1$.\n\nReport only the normalized conservation-law vector $c$ as your final answer. Express the final answer as a single $1 \\times 4$ row vector using exact rational numbers. No rounding is required or permitted. Do not include units.",
            "solution": "The problem statement is evaluated as scientifically grounded, well-posed, objective, and self-contained. It presents a standard problem in chemical reaction network theory, using established definitions and principles from linear algebra and mass-balance laws. All necessary information is provided, and the problem is free of contradictions, ambiguities, or factual unsoundness. Thus, the problem is valid, and we proceed to the solution.\n\nThe task is to determine a specific, normalized conservation-law vector for a given chemical reaction network. A conservation law is a linear combination of species concentrations that remains constant over time, regardless of the reaction rates.\n\nLet the vector of species concentrations be $x = ([A], [B], [C], [D])^{\\top}$. The time evolution of these concentrations is governed by the mass-balance equation $\\frac{dx}{dt} = Nv$, where $N$ is the stoichiometric matrix and $v$ is the vector of reaction fluxes.\n\nA linear conservation law is defined by a vector $c$ such that the quantity $c^{\\top}x$ is constant. Its time derivative must be zero:\n$$ \\frac{d}{dt}(c^{\\top}x) = c^{\\top}\\frac{dx}{dt} = c^{\\top}N v = 0 $$\nFor this to hold for any arbitrary vector of reaction fluxes $v$, it must be that $c^{\\top}N = \\mathbf{0}^{\\top}$. This is equivalent to the condition $N^{\\top}c = \\mathbf{0}$, which states that $c$ must belong to the left null space of $N$, denoted $\\ker(N^{\\top})$. The left null space of $N$ is the orthogonal complement of its column space (the stoichiometric subspace $\\mathcal{S}$), i.e., $\\ker(N^{\\top}) = (\\mathrm{im}(N))^{\\perp} = \\mathcal{S}^{\\perp}$.\n\nThe first step is to construct the stoichiometric matrix $N$. The species are ordered as $(A, B, C, D)$, corresponding to the rows, and the reactions as $(R_1, R_2, R_3)$, corresponding to the columns. The dimensions of $N$ are $4 \\times 3$. The entries $N_{ij}$ represent the net change in the amount of species $i$ due to one unit of reaction $j$. Reactants have negative coefficients, and products have positive ones. The problem statement specifies that a single conserved moiety is transferred, implying all non-zero stoichiometric coefficients are $\\pm 1$.\n\nFor reaction $R_{1}: A \\to B$:\nSpecies $A$ is consumed (coefficient $-1$), and species $B$ is produced (coefficient $+1$). The first column of $N$ is $[-1, 1, 0, 0]^{\\top}$.\n\nFor reaction $R_{2}: B \\to C$:\nSpecies $B$ is consumed (coefficient $-1$), and species $C$ is produced (coefficient $+1$). The second column of $N$ is $[0, -1, 1, 0]^{\\top}$.\n\nFor reaction $R_{3}: C \\to D$:\nSpecies $C$ is consumed (coefficient $-1$), and species $D$ is produced (coefficient $+1$). The third column of $N$ is $[0, 0, -1, 1]^{\\top}$.\n\nCombining these columns, we construct the stoichiometric matrix $N$:\n$$ N = \\begin{pmatrix} -1 & 0 & 0 \\\\ 1 & -1 & 0 \\\\ 0 & 1 & -1 \\\\ 0 & 0 & 1 \\end{pmatrix} $$\n\nNext, we find the conservation-law vectors $c$ by solving $N^{\\top}c = \\mathbf{0}$. The transpose of $N$ is:\n$$ N^{\\top} = \\begin{pmatrix} -1 & 1 & 0 & 0 \\\\ 0 & -1 & 1 & 0 \\\\ 0 & 0 & -1 & 1 \\end{pmatrix} $$\n\nLet the conservation-law vector be $c = [c_A, c_B, c_C, c_D]^{\\top}$. The system of linear equations is:\n$$ N^{\\top}c = \\begin{pmatrix} -1 & 1 & 0 & 0 \\\\ 0 & -1 & 1 & 0 \\\\ 0 & 0 & -1 & 1 \\end{pmatrix} \\begin{pmatrix} c_A \\\\ c_B \\\\ c_C \\\\ c_D \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\nThis yields the following equations:\n1. $-c_A + c_B = 0 \\implies c_A = c_B$\n2. $-c_B + c_C = 0 \\implies c_B = c_C$\n3. $-c_C + c_D = 0 \\implies c_C = c_D$\n\nFrom these equations, we deduce that all components of $c$ must be equal: $c_A = c_B = c_C = c_D$.\nAny vector in the left null space of $N$ must be of the form $c = [k, k, k, k]^{\\top}$ for some scalar $k \\in \\mathbb{R}$. This means the space of conservation laws, $\\mathcal{S}^{\\perp}$, is a $1$-dimensional subspace of $\\mathbb{R}^4$ spanned by the vector $[1, 1, 1, 1]^{\\top}$. This single independent conservation law corresponds to the total number of conserved moieties in the system, which is $[A] + [B] + [C] + [D] = \\text{constant}$.\n\nThe problem requires us to find the unique nonzero conservation-law vector $c$ that is normalized such that the sum of its components is equal to $1$.\nThe sum of the components of our general vector $c$ is:\n$$ c_A + c_B + c_C + c_D = k + k + k + k = 4k $$\nWe set this sum equal to $1$:\n$$ 4k = 1 \\implies k = \\frac{1}{4} $$\nSubstituting this value of $k$ back into the general form of $c$, we obtain the specific normalized vector:\n$$ c = \\begin{pmatrix} 1/4 \\\\ 1/4 \\\\ 1/4 \\\\ 1/4 \\end{pmatrix} $$\nThe problem asks for this to be expressed as a $1 \\times 4$ row vector. Transposing the column vector gives:\n$$ c^{\\top} = \\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix} $$\nThis is the final answer.",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\end{pmatrix} } $$"
        },
        {
            "introduction": "In large-scale biological networks, a key challenge is to identify the most influential nodes. The PageRank algorithm, originally developed for ranking web pages, provides a robust method for this by simulating a random walk on the network. This hands-on programming exercise guides you through implementing the Personalized PageRank algorithm from first principles, translating the mathematical theory of Markov chains into a practical tool for analyzing transcriptional networks . This practice emphasizes the rigorous handling of network features like dangling nodes to build a correct and robust implementation.",
            "id": "4349876",
            "problem": "Implement a program that computes the Personalized PageRank on small directed transcriptional networks, with rigorous handling of dangling nodes. The goal is to derive and implement the algorithm from first principles of Markov chains and graph stochasticity, not by quoting a pre-existing formula without justification. Concretely, consider a directed graph representing a transcriptional regulatory network, where nodes are genes or transcription factors, and directed edges represent regulation. Let the damping factor be denoted by $\\alpha \\in (0,1)$, and let the personalization vector be denoted by $v \\in \\mathbb{R}^n$ with $v \\ge 0$ and $\\sum_{i=1}^n v_i = 1$. The PageRank vector $p \\in \\mathbb{R}^n$ is defined as the stationary distribution of a random walk with teleportation on this graph.\n\nFundamental base to use:\n- Use the definition of a discrete-time Markov chain with a column-stochastic transition matrix, and the notion that a stationary distribution $p$ satisfies $p = M p$ for a suitable column-stochastic matrix $M$, together with $\\sum_{i=1}^n p_i = 1$ and $p \\ge 0$.\n- Use the well-tested observation that, in the PageRank random walk, with probability $\\alpha$ the walker follows an outgoing edge uniformly at random, and with probability $(1-\\alpha)$ the walker teleports to a node sampled from the personalization vector $v$.\n- Use the fact that a dangling node (a node with zero out-degree) yields a column with zero sum in the raw transition matrix, and must be handled by redistributing its probability mass according to $v$ so that the effective transition is still column-stochastic.\n\nYour program must implement the following from these principles:\n- Construct a column-stochastic transition model from the directed graph, where for each node with at least one outgoing edge, the probability to go to any of its out-neighbors is equal and sums to $1$. For any node with zero out-degree (a dangling node), ensure that its probability mass is redistributed according to $v$.\n- Compute the unique PageRank vector $p$ for given $\\alpha$ and $v$ by power iteration until convergence in the $\\ell_1$ norm, with a tolerance $\\varepsilon = 10^{-12}$ and a hard cap of $10000$ iterations. Initialize the iteration with $p^{(0)} = v$.\n- Return the resulting $p$ rounded to six decimal places for each entry.\n\nGraph representation:\n- Let nodes be indexed from $0$ to $n-1$. The directed edge notation $j \\to i$ means \"from node $j$ to node $i$\", which corresponds to an entry in a column-stochastic adjacency where column $j$ contains the outgoing probabilities from node $j$.\n- A transcriptional network with nodes $\\{A,B,C,D,E\\}$ is mapped to indices $A \\mapsto 0$, $B \\mapsto 1$, $C \\mapsto 2$, $D \\mapsto 3$, $E \\mapsto 4$.\n\nTest suite:\n- Test case $1$: Graph $G_1$ with nodes $\\{0,1,2,3,4\\}$ and edges $0 \\to 1$, $0 \\to 2$, $1 \\to 2$, $1 \\to 3$, $2 \\to 1$, $3 \\to 2$, $3 \\to 4$, and node $4$ is dangling (no outgoing edges). Use $\\alpha = 0.85$ and a uniform personalization vector $v = \\left[\\frac{1}{5},\\frac{1}{5},\\frac{1}{5},\\frac{1}{5},\\frac{1}{5}\\right]$.\n- Test case $2$: Same graph $G_1$ as in test case $1$, with $\\alpha = 0.95$ and the same uniform $v$.\n- Test case $3$: Same graph $G_1$ as in test case $1$, with $\\alpha = 0.85$ and a non-uniform personalization vector $v = [0.05, 0.05, 0.8, 0.05, 0.05]$.\n- Test case $4$: Graph $G_2$ with nodes $\\{0,1,2\\}$ and no edges at all, so all nodes are dangling. Use $\\alpha = 0.85$ and the uniform $v = \\left[\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right]$.\n- Test case $5$: Graph $G_3$ with nodes $\\{0,1,2\\}$ and a single edge $0 \\to 1$, with nodes $1$ and $2$ dangling. Use $\\alpha = 0.85$ and the uniform $v = \\left[\\frac{1}{3},\\frac{1}{3},\\frac{1}{3}\\right]$.\n\nConvergence and numeric specifications:\n- Use $\\varepsilon = 10^{-12}$ for the $\\ell_1$ convergence criterion.\n- Use a maximum of $10000$ iterations.\n- Round each entry of the final PageRank vector to six decimal places before output.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the test cases in order as a comma-separated list of lists, with no spaces. For example, the output format must be exactly\n\"[[p11,p12,...,p1n],[p21,p22,...],[...],...]\"\nwhere $p_{kj}$ are floats rounded to six decimal places for test case $k$.",
            "solution": "The problem of computing the Personalized PageRank vector is a problem of finding the stationary distribution of a specific discrete-time Markov chain. The solution will be derived from first principles, starting with the construction of the transition matrix for the random walk and culminating in the power iteration algorithm.\n\n### 1. The Underlying Markov Chain\n\nA random walk on a directed graph $G = (V, E)$ with $n = |V|$ nodes can be modeled as a Markov chain. The state of the system at step $k$ is a probability distribution vector $p^{(k)} \\in \\mathbb{R}^n$, where $p_i^{(k)}$ is the probability of a random walker being at node $i$. The state evolves according to $p^{(k+1)} = M p^{(k)}$, where $M$ is a column-stochastic transition matrix. The entry $M_{ij}$ represents the probability of transitioning from node $j$ to node $i$. A stationary distribution $p$ satisfies $p = M p$, along with the constraints $p \\ge 0$ and $\\sum_{i=1}^n p_i = 1$.\n\n### 2. Constructing the PageRank Transition Model\n\nThe PageRank random walker's movement is a weighted combination of two actions:\n1.  With probability $\\alpha$, the walker follows a randomly chosen outgoing edge from its current node.\n2.  With probability $1-\\alpha$, the walker \"teleports\" to a node chosen randomly according to the personalization vector $v$.\n\nWe must construct a column-stochastic matrix $M$ that captures this behavior.\n\n#### 2.1. Handling the Graph-Based Walk (The `S` Matrix)\n\nLet's first model a walk that purely follows the graph structure.\n- For a non-dangling node $j$ (a node with out-degree $d_j > 0$), a walker at $j$ moves to any of its neighbors $i$ with uniform probability $1/d_j$.\n- For a dangling node $j$ (a node with out-degree $d_j = 0$), the walker is trapped. The problem specifies that this probability mass must be redistributed according to the personalization vector $v$. This is equivalent to a forced teleport: from a dangling node $j$, the walker jumps to any node $i$ with probability $v_i$.\n\nLet's build a matrix $S$ that represents this graph-based walk, including the dangling node correction.\n- Let $A$ be a matrix representing the transitions for non-dangling nodes.\n$$\nA_{ij} = \\begin{cases} 1/d_j & \\text{if } j \\to i \\text{ is an edge and } d_j > 0 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe columns of $A$ corresponding to non-dangling nodes sum to $1$, while columns for dangling nodes are all zero.\n- To handle dangling nodes, we add a correction term. Let $d \\in \\{0,1\\}^n$ be an indicator vector where $d_j=1$ if node $j$ is dangling, and $d_j=0$ otherwise. The transition from a dangling node $j$ is a jump to a node $i$ with probability $v_i$. This can be represented by the outer product $v d^T$.\n- The complete stochastic transition matrix for the graph walk, $S$, is the sum of these two parts:\n$$\nS = A + v d^T\n$$\nLet's verify that $S$ is column-stochastic. The sum of column $j$ is $\\sum_i S_{ij}$.\n- If $j$ is not dangling ($d_j=0$): $\\sum_i S_{ij} = \\sum_i A_{ij} = \\sum_{i \\in \\text{neighbors}(j)} 1/d_j = d_j \\cdot (1/d_j) = 1$.\n- If $j$ is dangling ($d_j=1$): $\\sum_i S_{ij} = \\sum_i (A_{ij} + v_i d_j) = \\sum_i (0 + v_i) = \\sum_i v_i = 1$.\nThus, $S$ is a valid column-stochastic matrix.\n\n#### 2.2. Incorporating Teleportation (The `M` Matrix)\n\nThe full PageRank transition at each step is a combination of the graph walk (governed by $S$) and global teleportation (governed by $v$).\nThe probability of transitioning from any node $j$ to a target node $i$ is:\n$$\nP(j \\to i) = \\alpha \\cdot (\\text{Prob. via graph walk}) + (1-\\alpha) \\cdot (\\text{Prob. via teleportation})\n$$\nThe probability of transitioning from $j$ to $i$ via the graph walk is given by $S_{ij}$. The probability of teleporting to node $i$ is $v_i$, and this is independent of the starting node $j$.\nTherefore, the entry $M_{ij}$ of the final Google matrix $M$ is:\n$$\nM_{ij} = \\alpha S_{ij} + (1-\\alpha)v_i\n$$\nIn matrix notation, this is $M = \\alpha S + (1-\\alpha) v \\mathbf{1}^T$, where $\\mathbf{1}^T$ is a row vector of all ones. This matrix $M$ is column-stochastic, and its unique principal eigenvector (for eigenvalue $1$) is the PageRank vector $p$.\n\n### 3. The Power Iteration Algorithm\n\nThe PageRank vector $p$ is the stationary distribution satisfying $p = M p$. This can be found by the power iteration method: starting with an initial guess $p^{(0)}$, we repeatedly apply the transition matrix: $p^{(k+1)} = M p^{(k)}$. The sequence $p^{(k)}$ converges to $p$.\n\nLet's derive the iterative update rule:\n$$\np^{(k+1)} = M p^{(k)} = (\\alpha S + (1-\\alpha) v \\mathbf{1}^T) p^{(k)}\n$$\n$$\np^{(k+1)} = \\alpha S p^{(k)} + (1-\\alpha) v (\\mathbf{1}^T p^{(k)})\n$$\nSince $p^{(k)}$ is a probability distribution, $\\sum_j p_j^{(k)} = 1$, which means $\\mathbf{1}^T p^{(k)} = 1$.\n$$\np^{(k+1)} = \\alpha S p^{(k)} + (1-\\alpha) v\n$$\nThis gives us a more direct iterative update. For computational efficiency, we can further expand $S$:\n$$\np^{(k+1)} = \\alpha (A + v d^T) p^{(k)} + (1-\\alpha) v\n$$\n$$\np^{(k+1)} = \\alpha A p^{(k)} + \\alpha v (d^T p^{(k)}) + (1-\\alpha) v\n$$\nLet $m_d^{(k)} = d^T p^{(k)} = \\sum_{j \\text{ is dangling}} p_j^{(k)}$ be the total probability mass residing on dangling nodes at step $k$. The equation becomes:\n$$\np^{(k+1)} = \\alpha (A p^{(k)}) + (\\alpha m_d^{(k)} + 1 - \\alpha) v\n$$\nThis is the final, computationally efficient update rule for the power iteration.\n\n**Algorithm:**\n1.  **Initialization**: Set the initial PageRank vector $p^{(0)} = v$, and iteration counter $k=0$.\n2.  **Preprocessing**: From the graph edges, determine the out-degrees $d_j$ and identify the set of dangling nodes $D = \\{j \\mid d_j=0\\}$. Construct the non-dangling transition matrix $A$, or an equivalent representation.\n3.  **Iteration**: Repeat for $k=0, 1, 2, \\dots$ up to a maximum of $10000$ iterations:\n    a.  Store the current vector: $p_{\\text{old}} = p^{(k)}$.\n    b.  Calculate the dangling mass: $m_d = \\sum_{j \\in D} p_j^{\\text{old}}$.\n    c.  Calculate the walk contribution: $p'_{\\text{walk}} = A p_{\\text{old}}$. This is done by summing, for each node $i$, the incoming probability flows: $(p'_{\\text{walk}})_i = \\sum_{j \\to i, j \\notin D} p_j^{\\text{old}} / d_j$.\n    d.  Calculate the new PageRank vector: $p^{(k+1)} = \\alpha p'_{\\text{walk}} + (\\alpha m_d + 1 - \\alpha) v$.\n    e.  **Check for Convergence**: Compute the $\\ell_1$ norm of the difference: $\\Delta = ||p^{(k+1)} - p_{\\text{old}}||_1 = \\sum_i |p_i^{(k+1)} - p_i^{\\text{old}}|$. If $\\Delta < \\varepsilon = 10^{-12}$, terminate the iteration.\n4.  **Result**: The final vector $p^{(k+1)}$ is the computed PageRank vector. Round its entries to six decimal places.",
            "answer": "[[0.06018,0.203333,0.360173,0.150495,0.225819],[0.040187,0.260589,0.370845,0.145893,0.182486],[0.048144,0.134371,0.722915,0.046427,0.048144],[0.333333,0.333333,0.333333],[0.147222,0.441111,0.411667]]"
        }
    ]
}