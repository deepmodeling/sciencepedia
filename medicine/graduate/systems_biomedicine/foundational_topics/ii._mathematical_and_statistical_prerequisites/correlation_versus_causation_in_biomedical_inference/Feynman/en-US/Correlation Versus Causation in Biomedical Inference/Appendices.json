{
    "hands_on_practices": [
        {
            "introduction": "Perhaps the most vivid illustration of confounding is Simpson's Paradox, where an association observed in an entire population is reversed within each of its subgroups. This counterintuitive phenomenon highlights why aggregating data without considering underlying structure can lead to spurious conclusions. This exercise provides a hands-on opportunity to numerically demonstrate the paradox, building a foundational intuition for why marginal correlation is not a reliable proxy for causation and why stratification is a crucial first step in causal analysis .",
            "id": "4332365",
            "problem": "Consider an observational cohort study in systems biomedicine that investigates a treatment $X$ (binary, $X=1$ for treated, $X=0$ for untreated) and a binary outcome $Y$ (mortality at $30$ days, $Y=1$ for death, $Y=0$ for survival). Let $Z$ be a stratifying variable representing baseline severity (binary, $Z=1$ for high severity, $Z=0$ for low severity). The following quantities are obtained from well-calibrated electronic health records:\n\n1. Conditional outcome risks within severity strata:\n$$\n\\mathbb{P}(Y=1 \\mid X=1, Z=1) = 0.70, \\quad \\mathbb{P}(Y=1 \\mid X=0, Z=1) = 0.80,\n$$\n$$\n\\mathbb{P}(Y=1 \\mid X=1, Z=0) = 0.10, \\quad \\mathbb{P}(Y=1 \\mid X=0, Z=0) = 0.20.\n$$\n\n2. Severity distributions differ by treatment assignment (reflecting non-random treatment allocation):\n$$\n\\mathbb{P}(Z=1 \\mid X=1) = 0.90, \\quad \\mathbb{P}(Z=1 \\mid X=0) = 0.10,\n$$\nand therefore\n$$\n\\mathbb{P}(Z=0 \\mid X=1) = 0.10, \\quad \\mathbb{P}(Z=0 \\mid X=0) = 0.90.\n$$\n\nStarting from the axioms of probability and the law of total probability, and using the standard definition of the risk ratio as the ratio of risks across treatment arms, perform the following:\n\n- Derive the expressions for the marginal risks $\\mathbb{P}(Y=1 \\mid X=1)$ and $\\mathbb{P}(Y=1 \\mid X=0)$ in terms of the given conditional risks and severity distributions.\n- Compute the conditional risk ratios within each stratum of $Z$,\n$$\n\\mathrm{RR}_{Z=z} = \\frac{\\mathbb{P}(Y=1 \\mid X=1, Z=z)}{\\mathbb{P}(Y=1 \\mid X=0, Z=z)} \\quad \\text{for } z \\in \\{0,1\\},\n$$\nand the marginal risk ratio,\n$$\n\\mathrm{RR}_{\\text{marginal}} = \\frac{\\mathbb{P}(Y=1 \\mid X=1)}{\\mathbb{P}(Y=1 \\mid X=0)}.\n$$\n- Using these computations, demonstrate numerically that the conditional risk ratios suggest benefit of treatment within each stratum ($\\mathrm{RR}_{Z=z} < 1$ for both $z=0$ and $z=1$), while the marginal risk ratio suggests harm ($\\mathrm{RR}_{\\text{marginal}} > 1$), thereby exhibiting the correlation-versus-causation paradox under confounding by $Z$.\n\nFinally, report the numerical value of the marginal risk ratio $\\mathrm{RR}_{\\text{marginal}}$, rounded to four significant figures. No units are required.",
            "solution": "The primary task is to compute and compare stratum-specific and marginal risk ratios to demonstrate the paradox of confounding.\n\nFirst, we derive the expressions for the marginal risks, $\\mathbb{P}(Y=1 \\mid X=1)$ and $\\mathbb{P}(Y=1 \\mid X=0)$. We use the law of total probability, marginalizing over the stratifying variable $Z$. For a fixed treatment status $X=x$, the probability of the outcome $Y=1$ is a weighted average of the stratum-specific probabilities, where the weights are the probabilities of being in each stratum.\n\nThe marginal risk for the treated group ($X=1$) is:\n$$\n\\mathbb{P}(Y=1 \\mid X=1) = \\sum_{z \\in \\{0,1\\}} \\mathbb{P}(Y=1 \\mid X=1, Z=z) \\mathbb{P}(Z=z \\mid X=1)\n$$\n$$\n\\mathbb{P}(Y=1 \\mid X=1) = \\mathbb{P}(Y=1 \\mid X=1, Z=1)\\mathbb{P}(Z=1 \\mid X=1) + \\mathbb{P}(Y=1 \\mid X=1, Z=0)\\mathbb{P}(Z=0 \\mid X=1)\n$$\nThe marginal risk for the untreated group ($X=0$) is:\n$$\n\\mathbb{P}(Y=1 \\mid X=0) = \\sum_{z \\in \\{0,1\\}} \\mathbb{P}(Y=1 \\mid X=0, Z=z) \\mathbb{P}(Z=z \\mid X=0)\n$$\n$$\n\\mathbb{P}(Y=1 \\mid X=0) = \\mathbb{P}(Y=1 \\mid X=0, Z=1)\\mathbb{P}(Z=1 \\mid X=0) + \\mathbb{P}(Y=1 \\mid X=0, Z=0)\\mathbb{P}(Z=0 \\mid X=0)\n$$\nThese are the required general expressions.\n\nNext, we compute the conditional risk ratios for each stratum of $Z$. The risk ratio is defined as the risk in the treated group divided by the risk in the untreated group.\n\nFor the high severity stratum ($Z=1$):\n$$\n\\mathrm{RR}_{Z=1} = \\frac{\\mathbb{P}(Y=1 \\mid X=1, Z=1)}{\\mathbb{P}(Y=1 \\mid X=0, Z=1)} = \\frac{0.70}{0.80} = 0.875\n$$\nFor the low severity stratum ($Z=0$):\n$$\n\\mathrm{RR}_{Z=0} = \\frac{\\mathbb{P}(Y=1 \\mid X=1, Z=0)}{\\mathbb{P}(Y=1 \\mid X=0, Z=0)} = \\frac{0.10}{0.20} = 0.50\n$$\nIn both strata, the conditional risk ratio is less than $1$ ($\\mathrm{RR}_{Z=1} < 1$ and $\\mathrm{RR}_{Z=0} < 1$). This indicates that within each severity level, the treatment is associated with a lower risk of mortality, suggesting a beneficial effect.\n\nNow, we compute the marginal risks by substituting the given numerical values into the derived expressions.\nFor the treated group ($X=1$):\n$$\n\\mathbb{P}(Y=1 \\mid X=1) = (0.70)(0.90) + (0.10)(0.10) = 0.63 + 0.01 = 0.64\n$$\nFor the untreated group ($X=0$):\n$$\n\\mathbb{P}(Y=1 \\mid X=0) = (0.80)(0.10) + (0.20)(0.90) = 0.08 + 0.18 = 0.26\n$$\nThe marginal risk of death is $0.64$ for the treated group and $0.26$ for the untreated group.\n\nFinally, we compute the marginal risk ratio, $\\mathrm{RR}_{\\text{marginal}}$:\n$$\n\\mathrm{RR}_{\\text{marginal}} = \\frac{\\mathbb{P}(Y=1 \\mid X=1)}{\\mathbb{P}(Y=1 \\mid X=0)} = \\frac{0.64}{0.26} = \\frac{32}{13} \\approx 2.461538...\n$$\nThe marginal risk ratio is greater than $1$. This suggests that, overall, the treatment is associated with a higher risk of mortality, suggesting a harmful effect.\n\nThis demonstrates the paradox:\n-   **Conditional Analysis:** Within both low- and high-severity groups, the treatment appears beneficial ($\\mathrm{RR} < 1$).\n-   **Marginal Analysis:** When the groups are combined, the treatment appears harmful ($\\mathrm{RR} > 1$).\n\nThis reversal is a classic manifestation of Simpson's Paradox, caused by the confounding variable $Z$ (severity). The variable $Z$ is a confounder because:\n1.  It is associated with the outcome $Y$ (higher severity leads to higher mortality risk, regardless of treatment).\n2.  It is associated with the treatment $X$ (patients with high severity are much more likely to receive the treatment, as $\\mathbb{P}(Z=1 \\mid X=1) = 0.90$ while $\\mathbb{P}(Z=1 \\mid X=0) = 0.10$). This is known as confounding by indication.\n\nThe marginal risk calculation is a weighted average, but the weights\n($\\mathbb{P}(Z=z \\mid X=x)$) are different for the treated and untreated populations. The treated group is predominantly composed of high-risk patients ($90\\%$), while the untreated group is predominantly composed of low-risk patients ($90\\%$). The marginal comparison is therefore not a comparison of like with like, but rather a comparison of a treated high-risk group with an untreated low-risk group. The stratum-specific risk ratios provide a more meaningful estimate of the treatment's effect by comparing treated and untreated patients with the same baseline severity. The correlation observed in the marginal analysis is spurious and does not reflect a causal relationship.\n\nThe value of the marginal risk ratio, rounded to four significant figures, is $2.462$.",
            "answer": "$$\n\\boxed{2.462}\n$$"
        },
        {
            "introduction": "Moving from numerical examples to formal models, we can use Structural Causal Models (SCMs) to precisely define and quantify confounding. This practice challenges you to derive the difference between the observational expectation, $E[Y \\mid X=x]$, and the causal or interventional expectation, $E[Y \\mid do(X=x)]$. By working through the mechanics of a linear SCM with a common cause, you will analytically isolate the bias term, offering a clear mathematical representation of how a confounder generates a spurious association .",
            "id": "4332362",
            "problem": "Consider a simplified systems biomedicine scenario in which a pro-inflammatory cytokine level $X$ appears correlated with a clinical severity score $Y$. An upstream immune activation state $Z$ both increases the cytokine level $X$ and independently worsens severity $Y$, creating a confounding pathway. Suppose the data-generating mechanism is a linear Gaussian Structural Causal Model (SCM) defined by the following structural equations with mutually independent, zero-mean Gaussian exogenous terms:\n- $Z \\sim \\mathcal{N}(0, 2)$,\n- $X = Z + U_{X}$ with $U_{X} \\sim \\mathcal{N}(0, 2)$,\n- $Y = 1 \\cdot X + 1 \\cdot Z + U_{Y}$ with $U_{Y} \\sim \\mathcal{N}(0, 1)$.\n\nAll exogenous variables $Z$, $U_{X}$, and $U_{Y}$ are mutually independent. The intervention $do(X = x)$ represents setting $X$ to the fixed value $x$ by external manipulation.\n\nUsing only fundamental properties of multivariate normal distributions, definitions of conditional expectations, and the intervention semantics of the SCM (that is, replacing the structural equation for $X$ by $X = x$ under $do(X = x)$), derive from first principles the expressions for $E[Y \\mid X = x]$ and $E[Y \\mid do(X = x)]$, and then compute the difference $E[Y \\mid X = x] - E[Y \\mid do(X = x)]$ as a simplified closed-form analytic expression in $x$.\n\nProvide your final answer as a single exact expression in $x$. No rounding is required and there are no physical units to report.",
            "solution": "The problem requires the derivation of two quantities, the observational conditional expectation $E[Y \\mid X = x]$ and the interventional conditional expectation $E[Y \\mid do(X = x)]$, and their difference. The derivation will be conducted from first principles using the provided Structural Causal Model (SCM) and properties of multivariate normal distributions.\n\nThe SCM is defined by the following equations:\n$Z \\sim \\mathcal{N}(0, 2)$\n$X = Z + U_{X}$, with $U_{X} \\sim \\mathcal{N}(0, 2)$\n$Y = X + Z + U_{Y}$, with $U_{Y} \\sim \\mathcal{N}(0, 1)$\nThe exogenous variables $Z$, $U_X$, and $U_Y$ are mutually independent.\n\nFirst, we derive the observational conditional expectation, $E[Y \\mid X = x]$.\nUsing the structural equation for $Y$ and the linearity of expectation, we have:\n$$E[Y \\mid X = x] = E[X + Z + U_Y \\mid X = x]$$\n$$E[Y \\mid X = x] = E[X \\mid X = x] + E[Z \\mid X = x] + E[U_Y \\mid X = x]$$\n\nWe evaluate each term separately:\n1.  $E[X \\mid X = x]$: The expectation of $X$ conditioned on its own value being $x$ is simply $x$.\n    $$E[X \\mid X = x] = x$$\n\n2.  $E[U_Y \\mid X = x]$: The variable $X$ is defined as $X = Z + U_X$. Since the exogenous variable $U_Y$ is mutually independent of $Z$ and $U_X$, it is also independent of their sum, $X$. Therefore, conditioning on $X$ does not alter the expectation of $U_Y$.\n    $$E[U_Y \\mid X = x] = E[U_Y] = 0$$\n\n3.  $E[Z \\mid X = x]$: To find this conditional expectation, we must determine the joint distribution of the random variables $X$ and $Z$. Both are linear combinations of independent Gaussian variables, so their joint distribution is a bivariate normal distribution. We need to compute their means, variances, and covariance.\n\n    The means are:\n    $E[Z] = 0$\n    $E[X] = E[Z + U_X] = E[Z] + E[U_X] = 0 + 0 = 0$\n\n    The variances are:\n    $\\text{Var}(Z) = 2$\n    Since $Z$ and $U_X$ are independent,\n    $\\text{Var}(X) = \\text{Var}(Z + U_X) = \\text{Var}(Z) + \\text{Var}(U_X) = 2 + 2 = 4$\n\n    The covariance is:\n    $\\text{Cov}(X, Z) = \\text{Cov}(Z + U_X, Z) = \\text{Cov}(Z, Z) + \\text{Cov}(U_X, Z)$\n    Since $U_X$ and $Z$ are independent, $\\text{Cov}(U_X, Z) = 0$.\n    $\\text{Cov}(Z, Z) = \\text{Var}(Z) = 2$.\n    Thus, $\\text{Cov}(X, Z) = 2$.\n\n    The vector $(X, Z)^T$ follows a bivariate normal distribution with mean vector $\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and covariance matrix $\\Sigma = \\begin{pmatrix} \\text{Var}(X) & \\text{Cov}(X, Z) \\\\ \\text{Cov}(Z, X) & \\text{Var}(Z) \\end{pmatrix} = \\begin{pmatrix} 4 & 2 \\\\ 2 & 2 \\end{pmatrix}$.\n\n    The formula for conditional expectation in a bivariate normal distribution is:\n    $$E[Z \\mid X = x] = E[Z] + \\frac{\\text{Cov}(X, Z)}{\\text{Var}(X)}(x - E[X])$$\n    Substituting the computed values:\n    $$E[Z \\mid X = x] = 0 + \\frac{2}{4}(x - 0) = \\frac{1}{2}x$$\n\n    Combining these terms, we find the expression for $E[Y \\mid X = x]$:\n    $$E[Y \\mid X = x] = x + \\frac{1}{2}x + 0 = \\frac{3}{2}x$$\n\nNext, we derive the interventional expectation, $E[Y \\mid do(X = x)]$.\nThe intervention $do(X = x)$ modifies the SCM by replacing the structural equation for $X$. The new set of equations for the system is:\n$Z \\sim \\mathcal{N}(0, 2)$\n$X = x$\n$Y = X + Z + U_Y = x + Z + U_Y$\n$U_Y \\sim \\mathcal{N}(0, 1)$\n\nThe intervention on $X$ breaks the influence of $Z$ on $X$, but does not affect the distribution of the upstream variable $Z$ or the independent exogenous variable $U_Y$. We compute the expectation of $Y$ in this modified model:\n$$E[Y \\mid do(X = x)] = E[x + Z + U_Y]$$\nBy linearity of expectation:\n$$E[Y \\mid do(X = x)] = E[x] + E[Z] + E[U_Y]$$\nSince $x$ is a constant, $E[x]=x$. The expectations of the exogenous variables remain zero.\n$$E[Y \\mid do(X = x)] = x + 0 + 0 = x$$\n\nFinally, we compute the difference between the observational and interventional expectations:\n$$E[Y \\mid X = x] - E[Y \\mid do(X = x)] = \\frac{3}{2}x - x$$\n$$E[Y \\mid X = x] - E[Y \\mid do(X = x)] = \\frac{1}{2}x$$\nThis difference quantifies the confounding bias. The observational quantity $E[Y \\mid X = x]$ incorporates both the direct causal effect of $X$ on $Y$ and the spurious correlation arising from the common cause $Z$. The interventional quantity $E[Y \\mid do(X = x)]$ isolates the direct causal effect. The difference reveals the magnitude of the confounding pathway's contribution, which is $c_{ZY} \\cdot (E[Z|X=x] - E[Z]) = 1 \\cdot (\\frac{1}{2}x - 0) = \\frac{1}{2}x$.",
            "answer": "$$\\boxed{\\frac{1}{2}x}$$"
        },
        {
            "introduction": "When confounding variables are unmeasured or unknown, simple adjustment is not possible. The instrumental variable (IV) framework offers a powerful alternative for estimating causal effects in such scenarios. This exercise simulates a Mendelian Randomization study, a common application of IV in biomedicine, where a genetic variant serves as an instrument. You will calculate the causal effect using the two-stage least squares (2SLS) estimator and assess the instrument's validity by computing the first-stage $F$-statistic, a critical diagnostic in any applied IV analysis .",
            "id": "4332361",
            "problem": "A systems biomedicine team investigates whether circulating Interleukin-6 (IL-6) causally affects systolic blood pressure. Let $Y$ denote systolic blood pressure in millimeters of mercury, $X$ denote the natural logarithm of plasma IL-6 concentration, and $Z$ denote the allele count ($0$, $1$, $2$) of a cis-acting genetic variant near the $IL6$ gene. Assume linear structural relations and the standard instrumental variable assumptions: relevance ($Z$ is associated with $X$), exclusion (the effect of $Z$ on $Y$ operates only through $X$), and independence (no unmeasured common causes of $Z$ and the outcome error). All variables are mean-centered prior to computing the following sample statistics.\n\nYou are given the following unbiased sample moments and sample size:\n- Sample size $n = 1800$.\n- Sample variance $\\widehat{\\operatorname{Var}}(Z) = 0.42$.\n- Sample variance $\\widehat{\\operatorname{Var}}(X) = 0.27$.\n- Sample covariance $\\widehat{\\operatorname{Cov}}(Z, X) = 0.03$.\n- Sample covariance $\\widehat{\\operatorname{Cov}}(Z, Y) = 0.138$.\n\nUsing only core definitions from linear models and estimation theory (ordinary least squares, sample variance and covariance, and the definition of the $F$-statistic for testing a single regressor), do the following:\n1. Compute the Two-Stage Least Squares (2SLS) estimate of the causal effect of $X$ on $Y$ using $Z$ as an instrument, based on the given summary statistics.\n2. Assess potential weak instrument bias by computing the first-stage $F$-statistic for the null hypothesis that the instrument has no linear association with $X$ in the first-stage model, and interpret it relative to the conventional rule-of-thumb threshold.\n\nReport only the 2SLS effect estimate as your final answer. Round your answer to four significant figures. Express the effect in millimeters of mercury per log-unit of IL-6 concentration.",
            "solution": "We consider the linear structural model $Y = \\beta X + u$ with an instrument $Z$ satisfying relevance, exclusion, and independence. In the case of a single endogenous regressor $X$ and a single instrument $Z$, the Two-Stage Least Squares (2SLS) estimator can be derived from first principles using ordinary least squares (OLS) definitions.\n\nFirst, define the first-stage regression of $X$ on $Z$:\n$$\nX = \\pi Z + v.\n$$\nThe OLS estimator for the slope $\\pi$ with mean-centered variables is\n$$\n\\widehat{\\pi} = \\frac{\\sum_{i=1}^{n} Z_i X_i}{\\sum_{i=1}^{n} Z_i^2} = \\frac{\\widehat{\\operatorname{Cov}}(Z,X)}{\\widehat{\\operatorname{Var}}(Z)}.\n$$\nSimilarly, define the reduced-form regression of $Y$ on $Z$:\n$$\nY = \\gamma Z + w,\n$$\nwith OLS slope\n$$\n\\widehat{\\gamma} = \\frac{\\sum_{i=1}^{n} Z_i Y_i}{\\sum_{i=1}^{n} Z_i^2} = \\frac{\\widehat{\\operatorname{Cov}}(Z,Y)}{\\widehat{\\operatorname{Var}}(Z)}.\n$$\nIn the single-instrument, single-endogenous-regressor case, the 2SLS estimator equals the ratio of the reduced-form to the first-stage slopes, which follows from the construction of the second-stage regression on the fitted values $\\widehat{X} = \\widehat{\\pi} Z$:\n$$\n\\widehat{\\beta}_{2\\text{SLS}} = \\frac{\\widehat{\\gamma}}{\\widehat{\\pi}} = \\frac{\\frac{\\widehat{\\operatorname{Cov}}(Z,Y)}{\\widehat{\\operatorname{Var}}(Z)}}{\\frac{\\widehat{\\operatorname{Cov}}(Z,X)}{\\widehat{\\operatorname{Var}}(Z)}} = \\frac{\\widehat{\\operatorname{Cov}}(Z,Y)}{\\widehat{\\operatorname{Cov}}(Z,X)}.\n$$\nUsing the provided sample covariances, we have\n$$\n\\widehat{\\beta}_{2\\text{SLS}} = \\frac{0.138}{0.03} = 4.6.\n$$\nThis is the effect of a one log-unit increase in IL-6 on systolic blood pressure, in millimeters of mercury per log-unit.\n\nNext, we assess instrument strength via the first-stage $F$-statistic for the null $H_{0} : \\pi = 0$ in the regression of $X$ on $Z$. For a single regressor, the coefficient of determination in the first stage is\n$$\nR^{2} = \\left(\\widehat{\\operatorname{Corr}}(Z,X)\\right)^{2} = \\frac{\\widehat{\\operatorname{Cov}}(Z,X)^{2}}{\\widehat{\\operatorname{Var}}(Z)\\,\\widehat{\\operatorname{Var}}(X)}.\n$$\nSubstituting the given values,\n$$\nR^{2} = \\frac{(0.03)^{2}}{0.42 \\times 0.27} = \\frac{0.0009}{0.1134} = \\frac{9 \\times 10^{-4}}{1134 \\times 10^{-4}} = \\frac{9}{1134} = \\frac{1}{126}.\n$$\nFor a single regressor, the $F$-statistic can be written as\n$$\nF = \\frac{R^{2}}{1 - R^{2}} \\times (n - 2).\n$$\nUsing $R^{2} = \\frac{1}{126}$ and $n = 1800$,\n$$\nF = \\frac{\\frac{1}{126}}{1 - \\frac{1}{126}} \\times (1800 - 2) = \\frac{\\frac{1}{126}}{\\frac{125}{126}} \\times 1798 = \\frac{1}{125} \\times 1798 = 14.384.\n$$\nInterpretation: By the conventional rule-of-thumb, an $F$-statistic larger than $10$ indicates that weak instrument concerns are attenuated. Here $F = 14.384$, which exceeds $10$, suggesting the instrument is reasonably strong. While stronger instruments (larger $F$) further reduce finite-sample bias toward the ordinary least squares estimator, this value indicates that substantial weak-instrument bias is unlikely.\n\nFinally, we report the 2SLS estimate rounded to four significant figures, in millimeters of mercury per log-unit of IL-6 concentration:\n$$\n\\widehat{\\beta}_{2\\text{SLS}} = 4.600.\n$$",
            "answer": "$$\\boxed{4.600}$$"
        }
    ]
}