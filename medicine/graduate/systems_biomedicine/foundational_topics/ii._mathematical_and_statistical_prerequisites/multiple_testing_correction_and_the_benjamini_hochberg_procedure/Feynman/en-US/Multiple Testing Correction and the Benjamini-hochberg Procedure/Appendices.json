{
    "hands_on_practices": [
        {
            "introduction": "This first exercise provides a foundational walkthrough of the Benjamini-Hochberg (BH) procedure. By manually applying the algorithm to a small, concrete set of $p$-values from a hypothetical gene expression study , you will solidify your understanding of its core mechanics: ranking, calculating rank-dependent thresholds, and identifying the final set of significant findings. This practice is essential for moving from theory to practical application.",
            "id": "4363527",
            "problem": "In a systems biomedicine investigation of a perturbation to an intracellular signaling network, you measure changes in messenger ribonucleic acid (mRNA) abundance for $m=10$ candidate genes thought to function as hubs that integrate stress signals. For each gene, you perform a null-hypothesis test of no change under perturbation relative to control, obtaining the following vector of $p$-values (ordered by the gene indexing used in the assay design, not by magnitude):\n$$\n\\mathbf{p} = \\left(0.0009,\\ 0.003,\\ 0.021,\\ 0.055,\\ 0.13,\\ 0.24,\\ 0.0004,\\ 0.0085,\\ 0.041,\\ 0.72\\right).\n$$\nYou aim to control the False Discovery Rate (FDR) at target level $q=0.1$ using the Benjamini–Hochberg procedure. Starting from fundamental definitions of FDR and the canonical steps underlying Benjamini–Hochberg, compute the Benjamini–Hochberg rejection set at level $q=0.1$ for the given $p$-values. Your derivation must explicitly show:\n- the ranking of the $p$-values in ascending order with their original gene indices,\n- the sequence of threshold comparisons at each rank,\n- the identification of the largest rank $k$ that determines the step-up cutoff,\n- the mapping back to the original indices to state the final rejection set.\n\nExpress the final rejection set as the list of original gene indices written in increasing numerical order. The final answer must be a calculation and should be given as a single row matrix using the LaTeX `pmatrix` environment inside the answer box. No rounding is required.",
            "solution": "The problem requires the application of the Benjamini-Hochberg (BH) procedure to a given set of $p$-values from a systems biomedicine experiment to control the False Discovery Rate (FDR).\n\nFirst, let us establish the fundamental definitions. We are given $m$ null hypothesis tests, $H_1, H_2, \\ldots, H_m$, and their corresponding $p$-values, $p_1, p_2, \\ldots, p_m$. We summarize the outcomes of the $m$ tests in a contingency table:\n\n|                  | Null Hypothesis is True | Alternative is True | Total     |\n|------------------|-------------------------|---------------------|-----------|\n| **Not Rejected** | $U$ (True Negatives)    | $T$ (False Negatives) | $m-R$     |\n| **Rejected**     | $V$ (False Positives)   | $S$ (True Positives)  | $R$       |\n| **Total**        | $m_0$                   | $m - m_0$           | $m$       |\n\nHere, $R$ is the total number of rejected hypotheses, and $V$ is the number of true null hypotheses that are incorrectly rejected (Type I errors, or false discoveries). The False Discovery Rate is defined as the expected value of the proportion of false discoveries among all discoveries:\n$$\n\\text{FDR} = E\\left[ \\frac{V}{R} \\middle| R > 0 \\right] P(R > 0)\n$$\nThe Benjamini-Hochberg procedure provides a way to control the FDR such that $\\text{FDR} \\le q$ for a specified target level $q$.\n\nThe givens in this problem are:\n- The total number of hypothesis tests (genes): $m = 10$.\n- The vector of $p$-values, with indices from $1$ to $10$:\n$$\n\\mathbf{p} = \\left(0.0009,\\ 0.003,\\ 0.021,\\ 0.055,\\ 0.13,\\ 0.24,\\ 0.0004,\\ 0.0085,\\ 0.041,\\ 0.72\\right)\n$$\n- The target FDR level: $q = 0.1$.\n\nThe Benjamini-Hochberg procedure consists of the following steps:\n\n1.  **Rank the $p$-values**: Let $p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$ be the $p$-values sorted in ascending order. We must keep track of their original indices.\n\nThe original $p$-values and their indices are:\n- $p_1 = 0.0009$\n- $p_2 = 0.003$\n- $p_3 = 0.021$\n- $p_4 = 0.055$\n- $p_5 = 0.13$\n- $p_6 = 0.24$\n- $p_7 = 0.0004$\n- $p_8 = 0.0085$\n- $p_9 = 0.041$\n- $p_{10} = 0.72$\n\nSorting these $p$-values in ascending order, we obtain the ranked list along with their original gene indices:\n\n| Rank ($i$) | Original Index | Sorted $p$-value ($p_{(i)}$) |\n|------------|----------------|------------------------------|\n| $1$        | $7$            | $0.0004$                     |\n| $2$        | $1$            | $0.0009$                     |\n| $3$        | $2$            | $0.003$                      |\n| $4$        | $8$            | $0.0085$                     |\n| $5$        | $3$            | $0.021$                      |\n| $6$        | $9$            | $0.041$                      |\n| $7$        | $4$            | $0.055$                      |\n| $8$        | $5$            | $0.13$                       |\n| $9$        | $6$            | $0.24$                       |\n| $10$       | $10$           | $0.72$                       |\n\n2.  **Find the rejection cutoff**: We find the largest rank $k$ such that the corresponding $p$-value $p_{(k)}$ satisfies the condition:\n$$\np_{(k)} \\le \\frac{k}{m}q\n$$\nFor our problem, with $m=10$ and $q=0.1$, the threshold for each rank $i$ is $\\frac{i}{10}(0.1) = 0.01 \\times i$. We now perform the sequence of comparisons for each rank $i=1, \\ldots, 10$:\n\n- For $i=1$: $p_{(1)} = 0.0004$. Threshold: $\\frac{1}{10}(0.1) = 0.01$. Comparison: $0.0004 \\le 0.01$ (True).\n- For $i=2$: $p_{(2)} = 0.0009$. Threshold: $\\frac{2}{10}(0.1) = 0.02$. Comparison: $0.0009 \\le 0.02$ (True).\n- For $i=3$: $p_{(3)} = 0.003$. Threshold: $\\frac{3}{10}(0.1) = 0.03$. Comparison: $0.003 \\le 0.03$ (True).\n- For $i=4$: $p_{(4)} = 0.0085$. Threshold: $\\frac{4}{10}(0.1) = 0.04$. Comparison: $0.0085 \\le 0.04$ (True).\n- For $i=5$: $p_{(5)} = 0.021$. Threshold: $\\frac{5}{10}(0.1) = 0.05$. Comparison: $0.021 \\le 0.05$ (True).\n- For $i=6$: $p_{(6)} = 0.041$. Threshold: $\\frac{6}{10}(0.1) = 0.06$. Comparison: $0.041 \\le 0.06$ (True).\n- For $i=7$: $p_{(7)} = 0.055$. Threshold: $\\frac{7}{10}(0.1) = 0.07$. Comparison: $0.055 \\le 0.07$ (True).\n- For $i=8$: $p_{(8)} = 0.13$. Threshold: $\\frac{8}{10}(0.1) = 0.08$. Comparison: $0.13 \\le 0.08$ (False).\n- For $i=9$: $p_{(9)} = 0.24$. Threshold: $\\frac{9}{10}(0.1) = 0.09$. Comparison: $0.24 \\le 0.09$ (False).\n- For $i=10$: $p_{(10)} = 0.72$. Threshold: $\\frac{10}{10}(0.1) = 0.1$. Comparison: $0.72 \\le 0.1$ (False).\n\nThe largest rank $k$ for which the condition $p_{(k)} \\le \\frac{k}{m}q$ is satisfied is $k=7$.\n\n3.  **Determine the rejection set**: The BH procedure rejects all null hypotheses $H_{(i)}$ for $i=1, \\ldots, k$. This means we reject the null hypotheses corresponding to the $k=7$ smallest $p$-values. The $p$-values to be declared significant are $p_{(1)}, p_{(2)}, p_{(3)}, p_{(4)}, p_{(5)}, p_{(6)},$ and $p_{(7)}$.\n\n4.  **Map back to original indices**: We now identify the original gene indices corresponding to these $7$ significant $p$-values from the table in step 1.\n- $p_{(1)}$ corresponds to original index $7$.\n- $p_{(2)}$ corresponds to original index $1$.\n- $p_{(3)}$ corresponds to original index $2$.\n- $p_{(4)}$ corresponds to original index $8$.\n- $p_{(5)}$ corresponds to original index $3$.\n- $p_{(6)}$ corresponds to original index $9$.\n- $p_{(7)}$ corresponds to original index $4$.\n\nThe rejection set, in terms of original gene indices, is $\\{1, 2, 3, 4, 7, 8, 9\\}$. The problem asks for this set to be expressed as a list of indices in increasing numerical order. Sorting these indices gives the final result.",
            "answer": "$$\\boxed{\\begin{pmatrix} 1 & 2 & 3 & 4 & 7 & 8 & 9 \\end{pmatrix}}$$"
        },
        {
            "introduction": "While the BH procedure is powerful, its original proof assumes independence or positive dependence among tests, conditions that may not hold in complex biological systems. This exercise introduces the more conservative Benjamini-Yekutieli (BY) procedure, which controls the False Discovery Rate under arbitrary dependence. By applying both BH and BY to the same dataset and comparing the results , you will gain an intuitive feel for the trade-off between statistical power and robustness to dependence structures.",
            "id": "4363605",
            "problem": "A systems biomedicine study evaluates differential abundance for $m=20$ plasma proteins measured across two patient cohorts. For each protein, a single hypothesis test is performed and a $p$-value is obtained. The investigator seeks to control the false discovery rate (FDR) at level $q=0.05$ using both the Benjamini–Hochberg (BH) and Benjamini–Yekutieli (BY) procedures, where BY is intended to be valid under arbitrary dependence among the test statistics, and BH is valid under independence or certain positive dependence structures.\n\nYou are given the unsorted $p$-value vector (one per protein):\n$$\n\\{\\,0.04000,\\;0.01410,\\;0.00030,\\;0.05500,\\;0.01270,\\;0.00150,\\;0.04900,\\;0.00012,\\;0.01900,\\;0.03200,\\;0.00620,\\;0.08000,\\;0.00210,\\;0.01050,\\;0.00410,\\;0.00090,\\;0.02500,\\;0.00840,\\;0.00320,\\;0.04400\\,\\}.\n$$\n\nStarting from the core definition of false discovery rate and the principle that step-up procedures operate on the ascendingly ordered $p$-values, determine the rejection sets produced by the Benjamini–Hochberg (BH) procedure at $q=0.05$ and the Benjamini–Yekutieli (BY) procedure at $q=0.05$ for $m=20$ tests. Then contrast these sets by computing the difference in the number of rejections, defined as\n$$\nR_{\\mathrm{BH}} - R_{\\mathrm{BY}},\n$$\nwhere $R_{\\mathrm{BH}}$ is the number of hypotheses rejected by BH and $R_{\\mathrm{BY}}$ is the number rejected by BY.\n\nReport this difference as a single integer. No rounding is required.",
            "solution": "The task is to apply two different multiple testing correction procedures, the Benjamini-Hochberg (BH) and Benjamini-Yekutieli (BY) procedures, to a given set of $p$-values and to determine the difference in the number of rejected hypotheses.\n\nThe problem involves $m=20$ hypothesis tests, and the goal is to control the false discovery rate (FDR) at a level $q=0.05$. The provided unsorted $p$-values are:\n$$\nP = \\{\\,0.04000,\\;0.01410,\\;0.00030,\\;0.05500,\\;0.01270,\\;0.00150,\\;0.04900,\\;0.00012,\\;0.01900,\\;0.03200,\\;0.00620,\\;0.08000,\\;0.00210,\\;0.01050,\\;0.00410,\\;0.00090,\\;0.02500,\\;0.00840,\\;0.00320,\\;0.04400\\,\\}.\n$$\n\nBoth the BH and BY procedures are step-up procedures, which means they operate on the $p$-values sorted in ascending order. Let the sorted $p$-values be denoted by $p_{(1)}, p_{(2)}, \\dots, p_{(m)}$.\n\nFirst, we sort the provided $p$-values:\n$p_{(1)} = 0.00012$\n$p_{(2)} = 0.00030$\n$p_{(3)} = 0.00090$\n$p_{(4)} = 0.00150$\n$p_{(5)} = 0.00210$\n$p_{(6)} = 0.00320$\n$p_{(7)} = 0.00410$\n$p_{(8)} = 0.00620$\n$p_{(9)} = 0.00840$\n$p_{(10)} = 0.01050$\n$p_{(11)} = 0.01270$\n$p_{(12)} = 0.01410$\n$p_{(13)} = 0.01900$\n$p_{(14)} = 0.02500$\n$p_{(15)} = 0.03200$\n$p_{(16)} = 0.04000$\n$p_{(17)} = 0.04400$\n$p_{(18)} = 0.04900$\n$p_{(19)} = 0.05500$\n$p_{(20)} = 0.08000$\n\nNow, we will apply each procedure.\n\n**Benjamini–Hochberg (BH) Procedure**\nThe BH procedure finds the largest integer $k$ such that the corresponding sorted $p$-value $p_{(k)}$ satisfies the condition:\n$$\np_{(k)} \\le \\frac{k}{m}q\n$$\nIf such a $k$ exists, all null hypotheses corresponding to $p_{(1)}, \\dots, p_{(k)}$ are rejected. The number of rejected hypotheses is $R_{\\mathrm{BH}} = k$.\n\nGiven $m=20$ and $q=0.05$, the BH threshold for the $i$-th sorted $p$-value is:\n$$\n\\frac{i}{20} \\times 0.05 = i \\times 0.0025\n$$\nWe must find the largest index $k$ for which $p_{(k)} \\le k \\times 0.0025$.\n\nFor $i=16$:\n$p_{(16)} = 0.04000$.\nThe BH threshold is $\\frac{16}{20} \\times 0.05 = 0.8 \\times 0.05 = 0.04$.\nThe condition is $0.04000 \\le 0.04$, which is true.\n\nFor $i=17$:\n$p_{(17)} = 0.04400$.\nThe BH threshold is $\\frac{17}{20} \\times 0.05 = 0.85 \\times 0.05 = 0.0425$.\nThe condition is $0.04400 \\le 0.0425$, which is false.\n\nSince the condition holds for $k=16$ but fails for $k=17$, the largest index for which the inequality is satisfied is $k=16$. Therefore, the BH procedure rejects $16$ hypotheses.\n$$\nR_{\\mathrm{BH}} = 16\n$$\n\n**Benjamini–Yekutieli (BY) Procedure**\nThe BY procedure is a more conservative method that controls the FDR under arbitrary dependence assumptions. It finds the largest integer $k$ such that:\n$$\np_{(k)} \\le \\frac{k}{m \\cdot C(m)}q\n$$\nwhere $C(m)$ is the sum of the reciprocals of the integers from $1$ to $m$, also known as the $m$-th Harmonic number, $H_m$.\n$$\nC(m) = \\sum_{i=1}^{m} \\frac{1}{i}\n$$\nFor $m=20$, we must first calculate $C(20)$:\n$$\nC(20) = H_{20} = \\sum_{i=1}^{20} \\frac{1}{i} = 1 + \\frac{1}{2} + \\frac{1}{3} + \\dots + \\frac{1}{20}\n$$\nNumerically evaluating this sum gives:\n$$\nC(20) \\approx 3.597739657\n$$\nThe BY threshold for the $i$-th sorted $p$-value is:\n$$\n\\frac{i}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{i \\times 0.0025}{3.59774}\n$$\nWe must find the largest index $k$ for which $p_{(k)} \\le \\frac{k \\times 0.0025}{C(20)}$.\n\nFor $i=7$:\n$p_{(7)} = 0.00410$.\nThe BY threshold is $\\frac{7}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{7 \\times 0.05}{20 \\times 3.59774} \\approx \\frac{0.35}{71.9548} \\approx 0.004864$.\nThe condition is $0.00410 \\le 0.004864$, which is true.\n\nFor $i=8$:\n$p_{(8)} = 0.00620$.\nThe BY threshold is $\\frac{8}{20 \\cdot C(20)} \\times 0.05 \\approx \\frac{8 \\times 0.05}{20 \\times 3.59774} \\approx \\frac{0.40}{71.9548} \\approx 0.005559$.\nThe condition is $0.00620 \\le 0.005559$, which is false.\n\nThe largest index for which the BY condition holds is $k=7$. Thus, the BY procedure rejects $7$ hypotheses.\n$$\nR_{\\mathrm{BY}} = 7\n$$\n\n**Difference in the Number of Rejections**\nThe problem asks for the difference $R_{\\mathrm{BH}} - R_{\\mathrm{BY}}$.\n$$\nR_{\\mathrm{BH}} - R_{\\mathrm{BY}} = 16 - 7 = 9\n$$\nThe difference in the number of rejections between the Benjamini-Hochberg and Benjamini-Yekutieli procedures is $9$.",
            "answer": "$$\\boxed{9}$$"
        },
        {
            "introduction": "A multiple testing procedure is only as reliable as the $p$-values it is given. This final practice shifts focus from algorithmic application to the critical, upstream step of diagnostic validation. By analyzing the shape of a large-scale $p$-value distribution from a hypothetical study , you will learn to spot red flags like model misspecification or $p$-hacking and to estimate the proportion of true null hypotheses, $\\pi_0$, a key parameter for adaptive FDR control.",
            "id": "4363560",
            "problem": "A systems biomedicine laboratory conducts differential expression analyses across $m$ gene-level hypotheses in a large single-cell RNA sequencing study. The statistical workflow will apply the Benjamini-Hochberg (BH) procedure to control the false discovery rate (FDR), but the team first wants to diagnose calibration and estimate the null proportion $\\pi_{0}$ from the empirical distribution of $p$-values. The following context is available and scientifically well-established: under a true null hypothesis, a $p$-value is uniformly distributed on $(0,1)$ and, across $m$ tests, the $p$-value distribution can be approximated as a mixture of a uniform component (from true nulls) and a component stochastically concentrated near $0$ (from true alternatives). The team constructs an equal-width histogram with bin width $0.05$ and also computes several summaries:\n- The fraction of $p$-values greater than $0.8$ is $0.19$.\n- The counts in the narrow windows $(0.045,0.05]$ and $(0.05,0.055]$ are $600$ and $250$, respectively.\n- The fraction of $p$-values less than $0.001$ is $0.03$.\nAssume $m = 20{,}000$ and that the tests are designed so that, under true nulls, $p$-values are independent and identically distributed and continuous.\n\nWhich option best describes a statistically sound $p$-value histogram diagnostic that both provides a defensible estimate of $\\pi_{0}$ and can flag $p$-hacking or model misspecification prior to applying BH?\n\nA. Construct equal-width bins over $(0,1]$ with sufficient expected uniform counts per bin, visually and formally assess whether the high-$p$ region (for example $p \\in (0.5,1]$) is approximately flat, and estimate $\\pi_{0}$ by comparing the observed upper-tail fraction to the uniform expectation across several thresholds (for example $\\lambda \\in \\{0.5,0.6,0.7,0.8,0.9\\}$) and checking stability. Using the given summary for $\\lambda = 0.8$, report $\\hat{\\pi}_{0} \\approx 0.95$; interpret the pronounced asymmetry between $(0.045,0.05]$ and $(0.05,0.055]$ as evidence consistent with researcher degrees of freedom or discretization, prompting targeted quality control and model checks. Proceed with BH once the upper-tail uniformity and $\\hat{\\pi}_{0}$ stability are verified.\n\nB. Test the entire histogram against a uniform distribution on $(0,1]$ with a goodness-of-fit test; if uniformity is rejected due to many small $p$-values or a spike near $p \\approx 0.05$, conclude BH is invalid in this setting and switch to Bonferroni. For $\\pi_{0}$, use the location of the histogram’s mode (near $p = 1$ here) to set $\\hat{\\pi}_{0} = 1$ and proceed.\n\nC. Focus on the left tail because it is “most informative”: estimate $\\pi_{0}$ from the proportion of $p$-values less than $0.2$, then treat the spike just below $0.05$ as expected under multiple testing. Proceed with BH without additional checks provided the fraction of $p$-values below $0.001$ exceeds $0.02$.\n\nD. Estimate $\\pi_{0}$ directly as the observed fraction of $p$-values exceeding $0.8$ (namely $0.19$), because true nulls produce many large $p$-values. Ignore local features around $p = 0.05$ because BH will correct them, and apply BH immediately at the desired FDR level.",
            "solution": "This problem asks us to identify the most statistically sound procedure for diagnosing a large set of $p$-values before applying a multiple testing correction like the Benjamini-Hochberg (BH) procedure. A proper diagnostic workflow is crucial for ensuring the validity of the final results.\n\nThe core principle behind such diagnostics is that the distribution of $p$-values is a mixture. The $p$-values from true null hypotheses follow a Uniform(0,1) distribution, creating a flat \"floor\" in the histogram. The $p$-values from true alternative hypotheses are concentrated near zero, creating a peak.\n\nA sound diagnostic procedure should:\n1.  **Validate the null distribution:** Check if the right tail of the $p$-value histogram (e.g., for $p > 0.5$) is approximately flat. This confirms that the statistical tests are well-calibrated under the null hypothesis.\n2.  **Estimate the null proportion ($\\pi_0$):** Use the height of the flat part of the histogram to estimate the proportion of true nulls. A standard method is to choose a threshold $\\lambda$ (e.g., $\\lambda=0.8$) and use the formula $\\hat{\\pi}_0(\\lambda) = \\frac{\\#\\{p_i > \\lambda\\}}{m(1-\\lambda)}$, checking for stability across different $\\lambda$ values.\n3.  **Identify artifacts:** Look for sharp, unnatural features in the histogram, especially near common significance cutoffs like $p=0.05$. Such features can indicate problems like \"p-hacking\" or model misspecification.\n\nLet's evaluate the options based on these principles:\n\n*   **Option A:** This option correctly describes all the key steps of a rigorous diagnostic.\n    *   It emphasizes assessing the flatness of the upper tail.\n    *   It proposes a stable method for estimating $\\pi_0$. Using the provided data for $\\lambda=0.8$, the calculation is correct: $\\hat{\\pi}_0 = \\frac{\\text{fraction of p-values} > 0.8}{1 - 0.8} = \\frac{0.19}{0.20} = 0.95$.\n    *   It correctly identifies the sharp drop in counts around $p=0.05$ (from 600 to 250 in adjacent bins) as a red flag for p-hacking or other artifacts that need investigation.\n    *   The proposed workflow—diagnose, investigate anomalies, then proceed with BH—is the correct and responsible approach.\n\n*   **Option B:** This option is incorrect. It suggests testing the *entire* distribution for uniformity. This test is expected to fail in any successful experiment because of the true alternative hypotheses, so its rejection is uninformative. Switching to Bonferroni does not address the underlying issue of p-value validity.\n\n*   **Option C:** This option is incorrect because it focuses only on the left tail. The right tail is essential for validating the null distribution. It also dangerously dismisses the sharp feature at $p=0.05$ as \"expected,\" when it is in fact a sign of a problem.\n\n*   **Option D:** This option is incorrect for two reasons. First, it uses the wrong formula for $\\pi_0$, failing to normalize by the width of the tail interval $(1-\\lambda)$. Second, it irresponsibly suggests ignoring the artifact at $p=0.05$. The BH procedure cannot correct for invalid input $p$-values (\"garbage in, garbage out\").\n\nTherefore, Option A provides the only statistically sound and comprehensive diagnostic plan.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}