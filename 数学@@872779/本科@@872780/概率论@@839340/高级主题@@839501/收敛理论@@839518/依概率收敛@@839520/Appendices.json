{"hands_on_practices": [{"introduction": "概率收敛是衡量估计量性能的一个核心概念。这个练习提供了一个理想的起点，通过一个关于传感器精度不断提高的直观场景，来实践证明概率收敛的基本方法。你将应用切比雪夫不等式，这是一个连接随机变量方差与其偏离期望值概率的强大工具，来严格证明测量结果为何会收敛到真实值。[@problem_id:1910709]", "problem": "一位工程师正在开发一种新传感器，用于测量某个特定的物理属性，其真实值是一个未知的常数 $c$。该工程师进行了一系列测量。令 $X_n$ 为表示第 $n$ 次测量结果的随机变量，其中 $n=1, 2, 3, \\ldots$。由于实验装置的改进，测量是无偏的，这意味着任何一次测量的期望值都是真实值，即对于所有 $n \\geq 1$ 都有 $\\mathbb{E}[X_n] = c$。每次测量的精度都会提高，第 $n$ 次测量的方差为 $\\operatorname{Var}(X_n) = \\frac{\\sigma^2}{n^2}$，其中 $\\sigma$ 是一个已知的正常数，表示基准测量不确定度。\n\n测量序列 $\\{X_n\\}$ 依概率收敛到一个特定的值。确定这个值。", "solution": "我们想求当 $n \\to \\infty$ 时 $X_{n}$ 的依概率极限。根据定义，$X_{n}$ 依概率收敛于 $c$ 是指对于任意 $\\varepsilon  0$，\n$$\n\\lim_{n \\to \\infty} P\\left(|X_{n} - c|  \\varepsilon\\right) = 0.\n$$\n由于测量是无偏的，对于所有 $n \\geq 1$ 都有 $\\mathbb{E}[X_{n}] = c$。根据切比雪夫不等式，对于任意 $\\varepsilon  0$，\n$$\nP\\left(|X_{n} - \\mathbb{E}[X_{n}]| \\geq \\varepsilon\\right) \\leq \\frac{\\operatorname{Var}(X_{n})}{\\varepsilon^{2}}.\n$$\n使用 $\\operatorname{Var}(X_{n}) = \\frac{\\sigma^{2}}{n^{2}}$ 和 $\\mathbb{E}[X_{n}] = c$，我们得到\n$$\nP\\left(|X_{n} - c| \\geq \\varepsilon\\right) \\leq \\frac{\\sigma^{2}}{n^{2}\\varepsilon^{2}} \\xrightarrow[n \\to \\infty]{} 0.\n$$\n因此，根据依概率收敛的定义，有 $X_{n} \\xrightarrow{p} c$。等价地，可以观察到\n$$\n\\mathbb{E}\\left[(X_{n} - c)^{2}\\right] = \\operatorname{Var}(X_{n}) = \\frac{\\sigma^{2}}{n^{2}} \\to 0,\n$$\n所以 $X_{n}$ 均方收敛于 $c$，这意味着它依概率收敛于 $c$。", "answer": "$$\\boxed{c}$$", "id": "1910709"}, {"introduction": "在掌握了单个序列的收敛性分析之后，下一步是研究随机变量序列的组合。这个问题探讨了当一个收敛序列与另一个噪声序列相加时会发生什么，后者的影响随着时间的推移而减小。这个练习有助于你理解概率收敛的代数性质，这在处理由多个随机部分组成的复杂模型时至关重要。[@problem_id:1910723]", "problem": "设 $\\{X_n\\}_{n=1}^{\\infty}$ 和 $\\{Y_n\\}_{n=1}^{\\infty}$ 是两个随机变量序列。已知序列 $\\{X_n\\}$ 依概率收敛于常数 5。序列 $\\{Y_n\\}$ 的特征是，对于所有正整数 $n$，其均值为 $\\mathbb{E}[Y_n] = 0$，方差为 $\\operatorname{Var}(Y_n) = \\frac{1}{\\sqrt{n}}$。一个新的随机变量序列 $\\{Z_n\\}_{n=1}^{\\infty}$ 由和式 $Z_n = X_n + Y_n$ 定义。\n\n求序列 $\\{Z_n\\}$ 依概率收敛到的数值。", "solution": "我们已知 $X_{n} \\xrightarrow{p} 5$，即对于每个 $\\varepsilon0$，\n$$\n\\lim_{n\\to\\infty}P\\big(|X_{n}-5|\\varepsilon\\big)=0.\n$$\n对于 $Y_{n}$，我们有对于所有 $n$，$\\mathbb{E}[Y_{n}]=0$ 且 $\\operatorname{Var}(Y_{n})=n^{-1/2}$。根据切比雪夫不等式，对于任意 $\\varepsilon0$，\n$$\nP\\big(|Y_{n}|\\varepsilon\\big)=P\\big(|Y_{n}-\\mathbb{E}[Y_{n}]|\\varepsilon\\big)\\leq \\frac{\\operatorname{Var}(Y_{n})}{\\varepsilon^{2}}=\\frac{n^{-1/2}}{\\varepsilon^{2}}\\xrightarrow[n\\to\\infty]{}0.\n$$\n因此 $Y_{n}\\xrightarrow{p}0$。\n\n定义 $Z_{n}=X_{n}+Y_{n}$。对于任意 $\\varepsilon0$，根据三角不等式，\n$$\n|Z_{n}-5|=\\big|(X_{n}-5)+Y_{n}\\big|\\leq |X_{n}-5|+|Y_{n}|.\n$$\n因此，使用并集界，\n$$\nP\\big(|Z_{n}-5|\\varepsilon\\big)\\leq P\\big(|X_{n}-5|\\varepsilon/2\\big)+P\\big(|Y_{n}|\\varepsilon/2\\big)\\xrightarrow[n\\to\\infty]{}0,\n$$\n因为第一项因 $X_{n}\\xrightarrow{p}5$ 而趋于零，第二项根据上面所示的切比雪夫不等式也趋于零。因此 $Z_{n}\\xrightarrow{p}5$。\n\n所以，$Z_{n}$ 依概率收敛到的数值是 $5$。", "answer": "$$\\boxed{5}$$", "id": "1910723"}, {"introduction": "并非所有看似合理的估计量都是有效的。这个练习提供了一个重要的反例，旨在加深你对收敛定义的理解。通过分析一个只使用第一个观测值作为总体均值估计量的“静态”估计量，你将发现为什么利用不断增长的样本信息是实现一致性的关键。[@problem_id:1910737]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是来自一个总体的独立同分布（i.i.d.）随机变量序列，该总体的均值 $\\mathbb{E}[X_i] = \\mu$ 为有限值，方差 $\\operatorname{Var}(X_i) = \\sigma^2$ 为有限非零值。\n\n一位研究者提出了一个总体均值 $\\mu$ 的估计量，定义为 $\\hat{\\mu}_n = X_1$。无论总样本大小 $n$ 为多少，该估计量只使用第一个观测值。我们希望分析该估计量的一致性。\n\n当样本大小 $n$ 趋于无穷大时，下列哪个陈述正确描述了估计量 $\\hat{\\mu}_n$ 的收敛性質？\n\nA. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为它是 $\\mu$ 的一个无偏估计量。\n\nB. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为大数定律保证了当样本大小 $n$ 无限增大时，任何估计量都会收敛。\n\nC. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为随着 $n$ 的增加，该估计量与 $\\mu$ 的距离大于某个小值的概率保持为一个固定的正数。\n\nD. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为该估计量是有偏的，而有偏估计量永远不可能是一致的。\n\nE. 在不知道 $X_i$ 变量的潜在分布是否为正态分布的情况下，无法确定 $\\hat{\\mu}_n$ 是否依概率收敛于 $\\mu$。", "solution": "设 $\\{X_{i}\\}_{i=1}^{n}$ 是独立同分布的，其中 $\\mathbb{E}[X_{i}] = \\mu$ 且 $\\operatorname{Var}(X_{i}) = \\sigma^{2}$，且 $\\sigma^{2} \\in (0,\\infty)$。所提出的估计量是 $\\hat{\\mu}_{n} = X_{1}$，对所有 $n$ 成立。\n\n根据定义，$\\hat{\\mu}_{n}$ 是 $\\mu$ 的一致估计量，当且仅当对于任意 $\\varepsilon  0$，有\n$$\n\\lim_{n \\to \\infty} P\\left(|\\hat{\\mu}_{n} - \\mu|  \\varepsilon\\right) = 0.\n$$\n由于对所有 $n$，$\\hat{\\mu}_{n} = X_{1}$，我们有对于任意 $\\varepsilon  0$ 和任意 $n$，\n$$\nP\\left(|\\hat{\\mu}_{n} - \\mu|  \\varepsilon\\right) = P\\left(|X_{1} - \\mu|  \\varepsilon\\right) =: p(\\varepsilon),\n$$\n这个概率不依赖于 $n$。\n\n我们现在证明对于至少一个 $\\varepsilon  0$，$p(\\varepsilon)$ 是严格为正的。假设，为了引出矛盾，对于所有 $\\varepsilon  0$，$p(\\varepsilon) = 0$。那么对于每一个有理数序列 $\\{\\varepsilon_{k}\\}$ 且 $\\varepsilon_{k} \\downarrow 0$，有\n$$\nP\\left(|X_{1} - \\mu| \\le \\varepsilon_{k}\\right) = 1 \\quad \\text{for all } k,\n$$\n因此\n$$\nP\\left(\\bigcap_{k=1}^{\\infty} \\{|X_{1} - \\mu| \\le \\varepsilon_{k}\\}\\right) = 1,\n$$\n这意味着 $P(X_{1} = \\mu) = 1$，所以 $\\operatorname{Var}(X_{1}) = 0$，这与 $\\sigma^{2}  0$ 相矛盾。因此，存在 $\\varepsilon_{0}  0$ 使得\n$$\np(\\varepsilon_{0}) = P\\left(|X_{1} - \\mu|  \\varepsilon_{0}\\right)  0.\n$$\n因此，\n$$\n\\lim_{n \\to \\infty} P\\left(|\\hat{\\mu}_{n} - \\mu|  \\varepsilon_{0}\\right) = \\lim_{n \\to \\infty} p(\\varepsilon_{0}) = p(\\varepsilon_{0})  0,\n$$\n所以一致性条件不成立。因此，$\\hat{\\mu}_{n}$ 不依概率收敛于 $\\mu$。\n\n逐项评估：\n- A 是错误的：仅有无偏性并不能保证一致性。\n- B 是错误的：大数定律适用于依赖于 $n$ 的样本均值，而不适用于忽略 $n$ 的 $X_{1}$。\n- C 是正确的：对于某个小的 $\\varepsilon$，误差概率是一个固定的正常数，与 $n$无关。\n- D 是错误的：该估计量是无偏的，并且在任何情况下，有偏性通常并不妨碍一致性。\n- E 是错误的：正态性不是必需的；论证仅依赖于 $\\sigma^{2}  0$。\n\n因此，正确选项是 C。", "answer": "$$\\boxed{C}$$", "id": "1910737"}]}