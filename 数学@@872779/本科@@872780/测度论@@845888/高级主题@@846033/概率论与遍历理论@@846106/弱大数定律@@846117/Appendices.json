{"hands_on_practices": [{"introduction": "弱大数定律的强大之处在于它不仅适用于样本均值 $\\bar{X}_n$。该定律实际上适用于独立同分布随机变量的任意函数 $g(X_i)$ 的样本均值，只要该函数的期望存在。本练习将通过一个具体案例 $g(X) = X^2$ 来阐释这一原理，这与分布的二阶矩概念直接相关 [@problem_id:864091]。掌握如何估计分布的高阶矩是理解其更深层次特性的关键一步。", "problem": "设 $X_1, X_2, \\dots$ 是一列独立同分布 (i.i.d.) 的随机变量，其中每个 $X_i$ 服从速率参数为 $\\lambda > 0$ 的泊松分布。每个 $X_i$ 的概率质量函数由下式给出：\n$$\nP(X_i = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!} \\quad \\text{for } k \\in \\{0, 1, 2, \\dots\\}\n$$\n考虑这些随机变量平方的样本均值，定义为：\n$$\nM_n = \\frac{1}{n} \\sum_{i=1}^n X_i^2\n$$\n弱大数定律指出，当 $n \\to \\infty$ 时，若一个独立同分布变量序列的期望是有限的，则其样本均值依概率收敛于该变量的期望值。在本例中，$M_n$ 依概率收敛于一个常数值，我们称之为 $L$。\n\n推导 $L$ 的值，将其表示为参数 $\\lambda$ 的函数。", "solution": "我们要求解当 $n\\to\\infty$ 时\n$$\nM_n = \\frac{1}{n}\\sum_{i=1}^n X_i^2\n$$\n的概率极限。\n\n根据弱大数定律，$M_n$ 依概率收敛于\n$$\nE[X^2].\n$$\n\n我们使用恒等式\n$$\nE[X^2] = \\mathrm{Var}(X) + \\bigl(E[X]\\bigr)^2.\n$$\n\n对于 $X\\sim\\mathrm{Poisson}(\\lambda)$，我们有\n$$\nE[X] = \\lambda,\n\\qquad\n\\mathrm{Var}(X) = \\lambda.\n$$\n\n因此\n$$\nE[X^2] = \\lambda + \\lambda^2.\n$$", "answer": "$$\\boxed{\\lambda + \\lambda^2}$$", "id": "864091"}, {"introduction": "我们已经看到弱大数定律如何应用于随机变量的函数，现在让我们来探讨其最重要的应用之一：统计推断。本问题将展示弱大数定律如何为估计量的一致性 (consistency) 提供理论基础，确保当我们收集更多数据时，我们的估计值会依概率收敛到我们试图测量的参数的真实值 [@problem_id:864068]。我们将通过研究一个均匀分布的简单估计量来具体了解这一过程。", "problem": "设 $X_1, X_2, \\ldots, X_n$ 是从区间 $[0, \\theta]$ 上的连续均匀分布中抽取的一系列独立同分布 (i.i.d.) 的随机变量，其中 $\\theta > 0$ 是一个未知参数。每个 $X_i$ 的概率密度函数由下式给出：\n$$\nf(x; \\theta) = \\begin{cases} \\frac{1}{\\theta}  \\text{if } 0 \\le x \\le \\theta \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n样本均值定义为 $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$。通过矩方法得到的参数 $\\theta$ 的一个常见估计量是 $\\hat{\\theta}_n = 2\\bar{X}_n$。\n\n如果对于每个 $\\epsilon > 0$，以下条件成立，我们就称随机变量序列 $Y_n$ 依概率收敛于常数 $c$ (记作 $Y_n \\xrightarrow{p} c$)：\n$$\n\\lim_{n \\to \\infty} P(|Y_n - c| > \\epsilon) = 0\n$$\n弱大数定律 (WLLN) 表明，如果 $X_1, X_2, \\ldots$ 是具有有限期望值 $E[X_i] = \\mu$ 的独立同分布随机变量，那么它们的样本均值 $\\bar{X}_n$ 依概率收敛于 $\\mu$。\n\n使用弱大数定律和依概率收敛的性质，确定值 $c$，使得估计量 $\\hat{\\theta}_n$ 依概率收敛于 $c$。", "solution": "我们使用弱大数定律来寻求 $\\hat\\theta_n=2\\bar X_n$ 的依概率收敛极限。\n1. 每个 $X_i\\sim\\mathrm{Uniform}[0,\\theta]$ 的期望是\n$$\nE[X_i]=\\int_{0}^{\\theta}x\\,\\frac{1}{\\theta}\\,dx\n=\\frac{1}{\\theta}\\,\\frac{\\theta^2}{2}\n=\\frac{\\theta}{2}.\n$$\n2. 根据弱大数定律，\n$$\n\\bar X_n=\\frac{1}{n}\\sum_{i=1}^nX_i\n\\xrightarrow{p}E[X_i]\n=\\frac{\\theta}{2}.\n$$\n3. 因此\n$$\n\\hat\\theta_n\n=2\\bar X_n\n\\xrightarrow{p}2\\cdot\\frac{\\theta}{2}\n=\\theta.\n$$\n所以，$\\hat\\theta_n$ 依概率收敛于 $\\theta\\,$。", "answer": "$$\\boxed{\\theta}$$", "id": "864068"}, {"introduction": "在估计量概念的基础上，最后一个练习将进一步拓展我们的理解。弱大数定律与连续映射定理 (Continuous Mapping Theorem) 相结合，使我们能够确定样本均值的复杂非线性函数的收敛性 [@problem_id:863858]。这种强大的组合在统计学和机器学习的许多领域都至关重要，因为在这些领域中我们经常需要处理经过变换的统计量。", "problem": "设 $X_1, X_2, \\dots, X_n$ 为一列独立同分布 (i.i.d.) 的随机变量，其中每个 $X_i$ 服从区间 $(0, \\theta)$ 上的连续均匀分布，$\\theta > 0$ 是一个固定参数。样本均值定义为 $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$。\n\n考虑一个新的随机变量 $Y_n$，它是样本均值的有理函数：\n$$Y_n = \\frac{(\\bar{X}_n)^2}{1 + \\bar{X}_n}$$\n\n使用大数弱定律及其关于随机变量函数的相关性质，推导当 $n$ 趋于无穷大时，$Y_n$ 依概率收敛到的值 $L$。", "solution": "1. 对于 $X_i\\sim \\mathrm{Uniform}(0,\\theta)$，我们有\n$$E[X_i]=\\frac{\\theta}{2},\\quad \\mathrm{Var}(X_i)=\\frac{\\theta^2}{12}.$$\n根据大数弱定律，\n$$\\bar X_n=\\frac1n\\sum_{i=1}^nX_i\\;\\xrightarrow{P}\\;E[X_1]=\\frac{\\theta}{2}.$$\n2. 定义连续函数\n$$f(x)=\\frac{x^2}{1+x}.$$\n根据连续映射定理，\n$$Y_n=f(\\bar X_n)\\;\\xrightarrow{P}\\;f\\bigl(E[X_1]\\bigr)\n=f\\Bigl(\\frac{\\theta}{2}\\Bigr).$$\n3. 计算该极限：\n$$f\\Bigl(\\frac{\\theta}{2}\\Bigr)\n=\\frac{\\bigl(\\frac{\\theta}{2}\\bigr)^2}{1+\\frac{\\theta}{2}}\n=\\frac{\\frac{\\theta^2}{4}}{\\frac{2+\\theta}{2}}\n=\\frac{\\theta^2}{2(\\theta+2)}.$$", "answer": "$$\\boxed{\\frac{\\theta^2}{2(\\theta+2)}}$$", "id": "863858"}]}