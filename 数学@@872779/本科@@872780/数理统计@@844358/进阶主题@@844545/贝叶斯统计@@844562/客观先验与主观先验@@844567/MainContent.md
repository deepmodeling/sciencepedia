## 引言
在贝叶斯统计的宏伟框架中，先验分布的选择是一个基石性议题，同时也是一个充满深刻哲学思辨的领域。先验分布量化了我们在观测数据之前对未知参数的信念，它直接与数据提供的证据（通过[似然函数](@entry_id:141927)表达）相结合，共同塑造了我们最终的后验认知。然而，如何构建一个“好”的先验，是所有[贝叶斯分析](@entry_id:271788)者都必须面对的核心问题。这一选择的背后，存在着一个根本性的张力：我们应该如何平衡利用宝贵的领域知识（主观性）与追求让数据自身揭示规律的理想（客观性）？这个知识差距正是本文旨在解决的核心问题。

本文将系统性地剖析主观与[客观先验](@entry_id:167984)这两种方法论。在第一章“原则与机制”中，我们将深入探讨两类先验的构建原理，揭示[主观先验](@entry_id:174420)如何通过共轭性实现数学上的便利与知识融合，并阐明[客观先验](@entry_id:167984)如何借助不变性原则与Jeffreys法则来追求“无信息”的目标。接着，在“应用与跨学科联系”一章中，我们将视野扩展到真实世界，展示这些理论如何在机器学习、[生物统计学](@entry_id:266136)、金融学等多个领域中发挥作用，从编码专家意见到作为模型的正则化工具。最后，通过“动手实践”环节，读者将有机会亲手推导和应用这些先验，将理论知识转化为解决实际问题的能力。通过这一结构化的学习路径，本文旨在为读者在采纳和评估先验分布时，提供一个清晰、坚实的理论与实践基础。

## 原则与机制

在[贝叶斯推断](@entry_id:146958)的框架中，[先验分布](@entry_id:141376) $p(\theta)$ 是一个基石，它量化了在观测到数据 $D$ 之前我们关于未知参数 $\theta$ 的信念。根据[贝叶斯定理](@entry_id:151040)，[后验分布](@entry_id:145605) $p(\theta|D)$ 是通过似然函数 $p(D|\theta)$ 与[先验分布](@entry_id:141376) $p(\theta)$ 的乘积来更新的，即 $p(\theta|D) \propto p(D|\theta) p(\theta)$。[先验分布](@entry_id:141376)的选择是[贝叶斯建模](@entry_id:178666)中一个深刻且具有挑战性的方面，它直接影响最终的推断结果。对先验分布的讨论通常围绕两大类哲学思想展开：**[主观先验](@entry_id:174420)（subjective priors）**和**[客观先验](@entry_id:167984)（objective priors）**。本章旨在阐明这两类先验的构建原则与作用机制。

### [主观先验](@entry_id:174420)与共轭性

**[主观先验](@entry_id:174420)**旨在将分析者关于参数的真实、个人的信念、领域专长或来自先前研究的信息数学化地编码到模型中。当存在可靠的外部知识时，[主观先验](@entry_id:174420)是一个强有力的工具，能够使模型更贴近现实，并在数据有限时稳定推断结果。

一个在实践中广泛应用的核心机制是**共轭性（conjugacy）**。如果一个先验分布族与某个似然函数是**共轭**的，那么在该先验下，相应的[后验分布](@entry_id:145605)将属于同一个[分布](@entry_id:182848)族。例如，如果先验是Beta[分布](@entry_id:182848)，[似然函数](@entry_id:141927)是[二项分布](@entry_id:141181)，那么[后验分布](@entry_id:145605)也必然是Beta[分布](@entry_id:182848)。共轭性的主要优点在于其数学上的便利性，它使得后验分布的计算从复杂的积分问题简化为简单的参数更新。

#### Beta-二项共轭模型

在许多应用场景中，我们关心的是一个二项过程的成功概率 $p$，例如一种新药的治愈率或一个制造的传感器存在缺陷的概率。对于参数 $p \in [0, 1]$，Beta[分布](@entry_id:182848)是一个非常灵活的先验分布选择，其[概率密度函数](@entry_id:140610)（PDF）为：
$$
p(p | \alpha, \beta) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} p^{\alpha-1} (1-p)^{\beta-1}
$$
其中，参数 $\alpha$ 和 $\beta$ 分别可以被解释为先验的“伪成功次数”和“伪失败次数”。一个较大的 $\alpha$ 值代表了对高成功率的强烈[先验信念](@entry_id:264565)。

假设我们进行 $n$ 次独立试验，观测到 $k$ 次成功。似然函数是[二项分布](@entry_id:141181) $L(p|k,n) \propto p^k (1-p)^{n-k}$。结合Beta先验，后验分布为：
$$
p(p|k,n) \propto p^k (1-p)^{n-k} \cdot p^{\alpha-1} (1-p)^{\beta-1} = p^{\alpha+k-1} (1-p)^{\beta+n-k-1}
$$
这正是 $\operatorname{Beta}(\alpha+k, \beta+n-k)$ [分布](@entry_id:182848)的核。后验分布的均值，常被用作 $p$ 的[点估计](@entry_id:174544)，为：
$$
E[p|k,n] = \frac{\alpha+k}{\alpha+\beta+n}
$$
这个公式直观地展示了[贝叶斯更新](@entry_id:179010)的本质：[后验均值](@entry_id:173826)是[先验信息](@entry_id:753750)（由 $\alpha$ 和 $\beta$ 体现）与数据信息（由 $k$ 和 $n$ 体现）的加权平均。

例如，在评估一种新药的疗效时，一位有经验的医生可能会根据药物的机理设定一个乐观的[主观先验](@entry_id:174420)，如 $\operatorname{Beta}(5, 2)$，这反映了他相信成功率大约是 $5/(5+2) \approx 0.71$。如果[临床试验](@entry_id:174912)中20名患者有17名成功，那么更新后的[后验均值](@entry_id:173826)为 $\frac{5+17}{5+2+20} = \frac{22}{27} \approx 0.815$ [@problem_id:1940910]。这个结果被[先验信念](@entry_id:264565)从数据比例 $17/20 = 0.85$ 向先验均值 $0.71$ “拉”近了。

#### 正态-正态共轭模型

当似然函数和先验分布都是[正态分布](@entry_id:154414)时，我们也拥有共轭性。考虑估计一个[正态分布](@entry_id:154414)总体的均值 $\theta$，例如预测下一年的通货膨胀率。假设我们观测到的数据 $x_1, \dots, x_n$ 来自 $\mathcal{N}(\theta, \sigma^2)$，其中观测[方差](@entry_id:200758) $\sigma^2$ 已知。样本均值 $\bar{x}$ 的[分布](@entry_id:182848)为 $\mathcal{N}(\theta, \sigma^2/n)$。

一位经济学家可以设定一个主观的正态先验 $\theta \sim \mathcal{N}(\mu_0, \sigma_0^2)$，其中 $\mu_0$ 是他的专家预测值，$\sigma_0^2$ 反映了他对该预测的不确定性 [@problem_id:1940949]。[后验分布](@entry_id:145605) $p(\theta|\bar{x})$ 将正比于似然与先验的乘积：
$$
p(\theta|\bar{x}) \propto \exp\left(-\frac{n(\theta - \bar{x})^2}{2\sigma^2}\right) \cdot \exp\left(-\frac{(\theta - \mu_0)^2}{2\sigma_0^2}\right)
$$
通过[配方法](@entry_id:265480)可以证明，[后验分布](@entry_id:145605)仍然是[正态分布](@entry_id:154414) $\mathcal{N}(\mu_{\text{post}}, \sigma_{\text{post}}^2)$。其精度（[方差](@entry_id:200758)的倒数）具有一个特别简洁的形式：
$$
\frac{1}{\sigma_{\text{post}}^2} = \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}
$$
这表明，**后验精度等于先验精度与数据精度的总和**。信息（以精度的形式）在[贝叶斯更新](@entry_id:179010)中被累加。后验[方差](@entry_id:200758)因此为：
$$
\sigma_{\text{post}}^2 = \left(\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}\right)^{-1} = \frac{\sigma^2 \sigma_0^2}{n\sigma_0^2 + \sigma^2}
$$
这显示了数据越多（$n$ 越大），数据精度的主导作用就越强，后验[方差](@entry_id:200758)越小，我们的信念也越确定。

#### Gamma-泊松共轭模型

在对计数数据进行建模时，泊松分布是一个常用模型，其参数 $\lambda$ 代表事件发生的平均速率。例如，一位[网络安全](@entry_id:262820)分析师可能使用泊松过程来模拟恶意连接尝试的次数 [@problem_id:1940936]。Gamma[分布](@entry_id:182848)是泊松[似然](@entry_id:167119)的[共轭先验](@entry_id:262304)，其PDF（使用率参数 $\beta$）为：
$$
p(\lambda|\alpha, \beta) \propto \lambda^{\alpha-1} \exp(-\beta\lambda)
$$
如果在一个时长为 $T$ 的时段内观测到总共 $k$ 个事件，则似然函数为 $L(\lambda|k,T) \propto (\lambda T)^k \exp(-\lambda T) \propto \lambda^k \exp(-\lambda T)$。[后验分布](@entry_id:145605)为：
$$
p(\lambda|k,T) \propto \lambda^k \exp(-\lambda T) \cdot \lambda^{\alpha-1} \exp(-\beta\lambda) = \lambda^{\alpha+k-1} \exp(-(\beta+T)\lambda)
$$
这是 $\operatorname{Gamma}(\alpha+k, \beta+T)$ [分布](@entry_id:182848)的核。其[后验均值](@entry_id:173826)为 $\frac{\alpha+k}{\beta+T}$。同样，这个结果是[先验信息](@entry_id:753750)和数据信息的融合。

### [客观先验](@entry_id:167984)的构建原则

与[主观先验](@entry_id:174420)相反，**[客观先验](@entry_id:167984)**（或称**[无信息先验](@entry_id:172418)**，non-informative priors）试图在分析中最小化[先验信念](@entry_id:264565)的影响，目标是“让数据说话”。尽管完全的“客观性”是一个难以企及的理想，但一些形式化原则可以指导我们构建出影响较小、并具有良好性质的先验。

#### 原则一：不变性

一个核心思想是，先验信念不应依赖于[模型参数化](@entry_id:752079)或测量单位的任意选择。这导致了**不变性（invariance）**原则。

**[位置不变性](@entry_id:171525)（Location Invariance）**
对于一个**[位置参数](@entry_id:176482)** $\theta$，比如粒子束撞击位置的中位数 [@problem_id:1940924]，其物理意义不应随[坐标系](@entry_id:156346)原点的改变而改变。如果我们将数据移动一个常数 $c$，我们的推断也应该相应地移动 $c$。这要求[先验分布](@entry_id:141376)满足平移不变性，即对于任何区间 $[a,b]$ 和常数 $c$：
$$
\int_{a}^{b} \pi(\theta) \,d\theta = \int_{a+c}^{b+c} \pi(\theta) \,d\theta
$$
可以证明，唯一满足此条件的先验密度函数（在相差一个常数倍的意义下）是[常数函数](@entry_id:152060)，即：
$$
\pi(\theta) \propto 1
$$
这被称为**均匀先验（uniform prior）**。需要注意的是，这个先验在整个实数轴上是**不正常的（improper）**，即其积分发散。然而，只要它与[似然函数](@entry_id:141927)的乘积（后验）是可积的，它仍然可以用于[贝叶斯推断](@entry_id:146958)。

**[尺度不变性](@entry_id:180291)（Scale Invariance）**
对于一个**[尺度参数](@entry_id:268705)** $\sigma > 0$，例如物理测量的标准差，我们的先验知识不应因测量单位的改变（如从米到厘米）而改变。如果我们将单位乘以一个因子 $c>0$，参数会从 $\sigma$ 变为 $\tau = c\sigma$。[尺度不变性](@entry_id:180291)原则要求分配给任意区间 $[\sigma_a, \sigma_b]$ 的[先验概率](@entry_id:275634)，等于分配给相应缩放后区间 $[c\sigma_a, c\sigma_b]$ 的概率 [@problem_id:1940908]：
$$
\int_{\sigma_a}^{\sigma_b} \pi(\sigma) \,d\sigma = \int_{c\sigma_a}^{c\sigma_b} \pi(\tau) \,d\tau
$$
满足这一条件的先验是：
$$
\pi(\sigma) \propto \frac{1}{\sigma} \quad \text{或} \quad \pi(\sigma) \propto \sigma^{-1}
$$
这个先验也常被称为对数均匀先验，因为它等价于在 $\log \sigma$ 上设定一个均匀先验。它同样是不正常的。

#### 原则二：Jeffreys法则

Harold Jeffreys 提出了一种生成[客观先验](@entry_id:167984)的通用自动化方法，其核心优势在于**[重参数化不变性](@entry_id:197540)（reparameterization invariance）**。这意味着无论我们是对参数 $\theta$ 还是其某个变换（如 $\psi = g(\theta)$）设定Jeffreys先验，最终得到的关于 $\theta$ 的[后验分布](@entry_id:145605)是相同的。

Jeffreys法则是将先验设定为正比于**Fisher信息** $I(\theta)$ 的平方根：
$$
\pi(\theta) \propto \sqrt{I(\theta)}
$$
其中，对于单次观测 $X$，Fisher信息定义为 $I(\theta) = -E\left[ \frac{\partial^2}{\partial \theta^2} \ln p(X|\theta) \right]$。

**示例：伯努利参数**
考虑一个伯努利过程，如估计某制造过程中产品缺陷的概率 $p$ [@problem_id:1940942]。对数似然为 $\ln L(p|x) = x\ln p + (1-x)\ln(1-p)$。其关于 $p$ 的[二阶导数](@entry_id:144508)为 $-\frac{x}{p^2} - \frac{1-x}{(1-p)^2}$。在 $X \sim \text{Bernoulli}(p)$ 的期望下，$E[X]=p$，我们得到Fisher信息：
$$
I(p) = -E\left[-\frac{X}{p^2} - \frac{1-X}{(1-p)^2}\right] = \frac{p}{p^2} + \frac{1-p}{(1-p)^2} = \frac{1}{p} + \frac{1}{1-p} = \frac{1}{p(1-p)}
$$
因此，Jeffreys先验为：
$$
\pi_J(p) \propto \sqrt{I(p)} = \frac{1}{\sqrt{p(1-p)}} = p^{-1/2}(1-p)^{-1/2}
$$
这恰好是 $\operatorname{Beta}(1/2, 1/2)$ [分布](@entry_id:182848)的核。

**示例：泊松率**
对于[泊松分布](@entry_id:147769)，如模拟珍稀鸟类的日观测次数 [@problem_id:1940922]，其参数为 $\lambda$。[对数似然](@entry_id:273783)为 $x\ln\lambda - \lambda - \ln(x!)$。[二阶导数](@entry_id:144508)为 $-x/\lambda^2$。在 $X \sim \text{Poisson}(\lambda)$ 的期望下，$E[X]=\lambda$，Fisher信息为：
$$
I(\lambda) = -E\left[-\frac{X}{\lambda^2}\right] = \frac{E[X]}{\lambda^2} = \frac{\lambda}{\lambda^2} = \frac{1}{\lambda}
$$
因此，Jeffreys先验为：
$$
\pi_J(\lambda) \propto \sqrt{I(\lambda)} = \sqrt{\frac{1}{\lambda}} = \lambda^{-1/2}
$$
这是一个不正常的Gamma[分布](@entry_id:182848)。

### 主观与客观方法的比较

主观和[客观先验](@entry_id:167984)的选择会导致不同的推断结果，尤其是在数据量较少时。让我们回到评估新药疗效的例子 [@problem_id:1940910]。分析师A使用客观的Jeffreys先验 $\operatorname{Beta}(1/2, 1/2)$，而分析师B（医生）使用主观的乐观先验 $\operatorname{Beta}(5, 2)$。面对 $n=20, k=17$ 的数据：
- **分析师A (客观)** 的[后验均值](@entry_id:173826)为 $\mu_A = \frac{1/2+17}{1/2+1/2+20} = \frac{17.5}{21} \approx 0.833$。
- **分析师B (主观)** 的[后验均值](@entry_id:173826)为 $\mu_B = \frac{5+17}{5+2+20} = \frac{22}{27} \approx 0.815$。

数据本身的最大似然估计为 $\hat{p}_{MLE} = 17/20 = 0.85$。我们可以看到，[客观先验](@entry_id:167984)产生的估计值非常接近数据本身提供的证据。而[主观先验](@entry_id:174420)由于包含了“相当于观测到5次成功和2次失败”的[先验信息](@entry_id:753750)，将后验估计拉向了其先验均值 $5/7 \approx 0.714$。

这也凸显出，“客观性”本身并非一个单一的概念。例如，在估计成功概率 $p$ 时，除了Jeffreys先验 $\operatorname{Beta}(1/2, 1/2)$，另一种常见的“无信息”选择是均匀先验 $\operatorname{Beta}(1, 1)$。在分析一位新棋手对战引擎的胜率时，若数据为 $n=20, k=12$，使用[主观先验](@entry_id:174420) $\operatorname{Beta}(4,3)$ 和均匀先验 $\operatorname{Beta}(1,1)$ 会得到不同的[后验均值](@entry_id:173826) [@problem_id:1940953]。这提醒我们，即使在寻求客观性的框架内，选择依然存在，并且需要审慎的理由。

### [客观先验](@entry_id:167984)的高级主题与警示

虽然[客观先验](@entry_id:167984)在概念上很有吸[引力](@entry_id:175476)，但在多参数模型和复杂情境下，其应用需要格外小心。

#### 不正常后验问题

许多[客观先验](@entry_id:167984)，如 $\pi(\theta) \propto 1$ 和 $\pi(\sigma) \propto 1/\sigma$，都是不正常的。这本身不是问题，但它可能导致**不正常的[后验分布](@entry_id:145605)（improper posterior）**，即 $p(\theta|D) \propto L(\theta|D)\pi(\theta)$ 在参数空间上的积分是无限的。一个不正常的后验不是一个合法的[概率分布](@entry_id:146404)，基于它的任何推断（如均值、置信区间）都是无意义的。

考虑一个[分层模型](@entry_id:274952)，用于研究来自 $K$ 个工厂的合金[抗拉强度](@entry_id:161506)。假设工厂 $i$ 的效应 $\alpha_i \sim \mathcal{N}(0, \sigma^2)$，其中我们关心工厂间的[方差](@entry_id:200758) $\sigma^2$。如果我们为 $\sigma^2$ 选择一个不正常先验族 $p(\sigma^2) \propto (\sigma^2)^{-c}$，后验分布是否正常将取决于 $c$ 的值 [@problem_id:1940947]。通过分析后验密度函数在 $\sigma^2 \to 0$ 和 $\sigma^2 \to \infty$ 时的[渐近行为](@entry_id:160836)，可以证明，对于给定的工厂数 $K$，只有当 $c$ 位于特定区间 $(1-K/2, 1)$ 内时，后验分布才是正常的。例如，当 $K=5$ 时，只有当 $c \in (-1.5, 1)$ 时，才能获得有效的贝叶斯推断。这表明，即使选择“无信息”先验，也必须检查其是否与模型和数据兼容以产生合法的后验。

#### 边际化悖论

在涉及多个参数的模型中，[客观先验](@entry_id:167984)的应用变得更加棘手。一个著名的现象是**边际化悖論（marginalization paradox）**。该悖论指出，对一个多参数模型采用两种不同但看似都“客观”的先验设定，可能会导致对同一个感兴趣参数的边际后验分布截然不同。

一个经典的例子出现在[方差分量](@entry_id:267561)模型中 [@problem_id:1940918]。假设我们有组内平方和 $S_W$ 和组间平方和 $S_B$，它们的[分布](@entry_id:182848)分别依赖于[误差方差](@entry_id:636041) $\sigma^2$ 和随机效应[方差](@entry_id:200758) $\tau^2$。我们感兴趣的参数是[方差比](@entry_id:162608) $\phi = \tau^2 / \sigma^2$。

- **分析A**：在基础[方差分量](@entry_id:267561) $(\sigma^2, \tau^2)$ 上分别设定独立的Jeffreys先验，即 $p_A(\sigma^2, \tau^2) \propto (\sigma^2 \tau^2)^{-1}$。
- **分析B**：在模型结构参数 $(V_W, V_B)$ 上设定独立的Jeffreys先验，其中 $V_W = \sigma^2$，$V_B = \sigma^2 + n\tau^2$。这导致 $p_B(V_W, V_B) \propto (V_W V_B)^{-1}$。

尽管两种方法都源于Jeffreys法则的应用，但它们作用于不同的[参数化](@entry_id:272587)。通过复杂的变量变换和积分，可以推导出两种分析下 $\phi$ 的边际后验密度核 $k_A(\phi)$ 和 $k_B(\phi)$。惊人的是，它们并不成比例，其比值为：
$$
\frac{k_A(\phi)}{k_B(\phi)} = \frac{1+n\phi}{\phi}
$$
这表明两种“客观”方法得出了关于 $\phi$ 的不同结论。这个悖论深刻地揭示了，在多参数情况下，不存在一个普适的、唯一的[客观先验](@entry_id:167984)。先验的选择，即使是所谓的“无信息”先验，也内含了关于模型结构的隐性假设，并且对参数化的选择十分敏感。

总之，先验分布的选择是[贝叶斯建模](@entry_id:178666)中一个不可或缺的组成部分。[主观先验](@entry_id:174420)通过共轭性等机制，提供了一种融合专家知识的强大途径。[客观先验](@entry_id:167984)则遵循不变性等原则，试图提供一个基准或参考分析。然而，统计学家必须清醒地认识到，任何先验选择都带有一定的假设，尤其是在处理不正常先验和多参数模型时，必须进行审慎的检查和论证。