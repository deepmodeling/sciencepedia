{"hands_on_practices": [{"introduction": "在统计建模中，我们总是在模型的拟合优度与复杂度之间寻求平衡。一个更复杂的模型几乎总能更好地拟合数据，但这可能只是捕捉了数据中的噪声，即所谓的“过拟合”。赤池信息准则（Akaike Information Criterion, AIC）为我们提供了一个量化这种权衡的有力工具。通过这个练习，你将直接应用 AIC 来比较两个竞争模型，并选择在解释力与简约性之间达到最佳平衡的模型 [@problem_id:1936627]。", "problem": "一位生态学家正在开发统计模型，以了解某受保护湿地中一种特定鸟类的种群动态。他们收集了多年来的数据。提出了两个相互竞争的模型来解释年度种群波动。\n\n模型A是一个较简单的模型，它将给定年份的鸟类种群与平均温度和降雨量等气候变量联系起来。将此模型与数据拟合后，发现它有 $k_A = 4$ 个估计参数，其对数似然函数的最大值为 $\\ln(\\mathcal{L}_A) = -85.2$。\n\n模型B是一个更复杂的模型，它包含与模型A相同的气候变量，但还纳入了关键捕食者物种的种群数量。这个更全面的模型有 $k_B = 6$ 个估计参数，并获得了更高的最大化对数似然值 $\\ln(\\mathcal{L}_B) = -83.5$。\n\n为了决定哪个模型在拟合优度和复杂性之间提供了更好的平衡，这位生态学家使用了赤池信息准则（Akaike Information Criterion, AIC）。一个模型的AIC定义为 $\\text{AIC} = -2\\ln(\\mathcal{L}) + 2k$，其中 $k$ 是模型中估计参数的数量，$\\ln(\\mathcal{L})$ 是对数似然函数的最大值。AIC值较低的模型被认为是更好的模型。\n\n根据AIC，哪个模型更受青睐？它们各自的AIC值是多少？\n\nA. 模型A更优，其 $AIC_A = 178.4$ 且 $AIC_B = 179.0$。\n\nB. 模型B更优，其 $AIC_A = 178.4$ 且 $AIC_B = 179.0$。\n\nC. 模型A更优，其 $AIC_A = -162.4$ 且 $AIC_B = -155.0$。\n\nD. 模型B更优，其 $AIC_A = 178.4$ 且 $AIC_B = 171.0$。\n\nE. 模型B更优，其 $AIC_A = 178.4$ 且 $AIC_B = 173.0$。", "solution": "赤池信息准则定义为\n$$\n\\text{AIC} = -2\\ln(\\mathcal{L}) + 2k.\n$$\n对于模型A，其参数为 $k_{A} = 4$ 和 $\\ln(\\mathcal{L}_{A}) = -85.2$，\n$$\n\\text{AIC}_{A} = -2\\cdot(-85.2) + 2\\cdot 4 = 170.4 + 8 = 178.4.\n$$\n对于模型B，其参数为 $k_{B} = 6$ 和 $\\ln(\\mathcal{L}_{B}) = -83.5$，\n$$\n\\text{AIC}_{B} = -2\\cdot(-83.5) + 2\\cdot 6 = 167.0 + 12 = 179.0.\n$$\n由于 $\\text{AIC}_{A} = 178.4  \\text{AIC}_{B} = 179.0$，模型A的AIC值更低，因此更优。这些值与选项A相对应。", "answer": "$$\\boxed{A}$$", "id": "1936627"}, {"introduction": "当候选预测变量数量众多时，逐一评估所有可能的模型组合是不现实的。因此，统计学家开发了逐步选择（stepwise selection）等自动化算法，它们利用 AIC 等准则来有效地探索模型空间。这个练习将带你亲手执行两种最常见的逐步选择方法——向前选择和向后剔除——并揭示一个重要事实：这些启发式方法所走的路径不同，有时会得出不同的“最佳”模型 [@problem_id:1936615]。", "problem": "一位农业科学家正在研究一种新作物品种的产量。他们从 $n=100$ 个实验小区收集了数据。这位科学家希望建立一个线性回归模型，使用三个潜在的预测变量来预测作物产量 ($Y$)：\n- $X_1$：特定氮肥的施用量。\n- $X_2$：土壤pH值。\n- $X_3$：日均供水量。\n\n为了找到最佳模型，该科学家计算了涉及这三个预测变量的所有可能的线性模型的残差平方和 (RSS)。所有模型都包含截距项。结果总结在下表中：\n\n| 模型预测变量 | 预测变量数量 ($p$) | 残差平方和 (RSS) |\n|------------------|----------------------------|-------------------------------|\n| 无 (仅截距) | 0 | 200 |\n| {$X_1$} | 1 | 150 |\n| {$X_2$} | 1 | 160 |\n| {$X_3$} | 1 | 165 |\n| {$X_1, X_2$} | 2 | 110 |\n| {$X_1, X_3$} | 2 | 120 |\n| {$X_2, X_3$} | 2 | 100 |\n| {$X_1, X_2, X_3$} | 3 | 108 |\n\n该科学家决定使用两种常见的自动化模型选择程序：基于赤池信息准则 (AIC) 的前向选择 (Forward Selection) 和后向剔除 (Backward Elimination)。AIC 是一种用于模型选择的统计度量，对于假设误差呈正态分布的线性模型，其计算公式为：\n$$\\text{AIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + 2k$$\n其中 $n$ 是观测数量，$RSS$ 是模型的残差平方和，$k$ 是模型中的参数总数（$k=p+2$, 包括 $p$ 个预测变量、1个截距和1个误差方差项）。在选择过程的每一步，都会选择能使模型 AIC 值最低的变更。当没有单一步骤可以进一步降低 AIC 时，该过程停止。\n\n设 $M_F$ 是通过前向选择选出的最终模型中的预测变量集合，而 $M_B$ 是通过后向剔除选出的最终模型中的预测变量集合。以下哪个选项正确地指出了这两个最终模型？\n\nA. $M_F = \\{X_1, X_2\\}$, $M_B = \\{X_1, X_2\\}$\n\nB. $M_F = \\{X_1, X_2\\}$, $M_B = \\{X_2, X_3\\}$\n\nC. $M_F = \\{X_2, X_3\\}$, $M_B = \\{X_1, X_2\\}$\n\nD. $M_F = \\{X_2, X_3\\}$, $M_B = \\{X_2, X_3\\}$\n\nE. $M_F = \\{X_1, X_2, X_3\\}$, $M_B = \\{X_2, X_3\\}$\n\nF. $M_F = \\{X_1\\}$, $M_B = \\{X_1, X_2, X_3\\}$", "solution": "我们使用针对正态分布误差的线性模型的赤池信息准则：\n$$\\text{AIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + 2k,$$\n其中 $n=100$，$RSS$ 是模型的残差平方和，$k=p+2$，$p$ 是预测变量的数量。\n\n**前向选择**从仅含截距的模型开始（$p=0, k=2$）。其 AIC 值为\n$$\\text{AIC}_{\\emptyset} = 100 \\ln\\left(\\frac{200}{100}\\right) + 2(2) = 100 \\ln(2) + 4.$$\n对于单预测变量模型 ($p=1, k=3$)：\n- 对于 $\\{X_{1}\\}$: $\\text{AIC}_{1} = 100 \\ln\\left(\\frac{150}{100}\\right) + 2(3) = 100 \\ln(1.5) + 6.$\n- 对于 $\\{X_{2}\\}$: $\\text{AIC}_{2} = 100 \\ln(1.6) + 6.$\n- 对于 $\\{X_{3}\\}$: $\\text{AIC}_{3} = 100 \\ln(1.65) + 6.$\n由于 $\\ln(1.5)  \\ln(1.6)  \\ln(1.65)$，模型 $\\{X_1\\}$ 的 AIC 值最低。由于 $\\text{AIC}_{1}  \\text{AIC}_{\\emptyset}$，第一步选择 $X_1$。\n\n从 $\\{X_{1}\\}$ 开始，考虑再添加一个预测变量 ($p=2, k=4$)：\n- 对于 $\\{X_{1},X_{2}\\}$: $\\text{AIC}_{12} = 100 \\ln\\left(\\frac{110}{100}\\right) + 2(4) = 100 \\ln(1.1) + 8.$\n- 对于 $\\{X_{1},X_{3}\\}$: $\\text{AIC}_{13} = 100 \\ln(1.2) + 8.$\n由于 $\\ln(1.1)  \\ln(1.2)$，模型 $\\{X_1, X_2\\}$ 的 AIC 值更低。由于 $\\text{AIC}_{12}  \\text{AIC}_{1}$，第二步选择 $X_2$，得到模型 $\\{X_{1},X_{2}\\}$。\n\n从 $\\{X_{1},X_{2}\\}$ 开始，考虑添加 $X_{3}$ 得到全模型 ($p=3, k=5$)：\n$$\\text{AIC}_{123} = 100 \\ln\\left(\\frac{108}{100}\\right) + 2(5) = 100 \\ln(1.08) + 10.$$\n与 $\\{X_{1},X_{2}\\}$ 相比：$\\text{AIC}_{123} - \\text{AIC}_{12} = 100 \\ln\\left(\\frac{1.08}{1.1}\\right) + 2 \\approx 100(-0.018) + 2 = 0.2 > 0$。\n所以添加 $X_{3}$ 会增加 AIC。前向选择停止，最终模型为 $M_{F} = \\{X_{1},X_{2}\\}$。\n\n**后向剔除**从全模型 $\\{X_{1},X_{2},X_{3}\\}$ 开始 ($p=3, k=5$)，其 AIC 值为\n$$\\text{AIC}_{123} = 100 \\ln(1.08) + 10.$$\n考虑移除一个预测变量，得到双预测变量模型 ($p=2, k=4$)：\n- 移除 $X_{3}$：$\\text{AIC}_{12} = 100 \\ln(1.1) + 8.$\n- 移除 $X_{2}$：$\\text{AIC}_{13} = 100 \\ln(1.2) + 8.$\n- 移除 $X_{1}$：$\\text{AIC}_{23} = 100 \\ln\\left(\\frac{100}{100}\\right) + 8 = 8.$\n在这些模型中，$\\text{AIC}_{23}$ 是最小的。由于 $\\text{AIC}_{23}  \\text{AIC}_{123}$，移除 $X_1$ 降低了 AIC。模型变为 $\\{X_{2},X_{3}\\}$。\n\n从 $\\{X_{2},X_{3}\\}$ 开始，考虑再移除一个预测变量，得到单变量模型 ($p=1, k=3$)：\n- 移除 $X_3 \\to \\{X_{2}\\}$: $\\text{AIC}_{2} = 100 \\ln(1.6) + 6.$\n- 移除 $X_2 \\to \\{X_{3}\\}$: $\\text{AIC}_{3} = 100 \\ln(1.65) + 6.$\n由于 $\\text{AIC}_{2} > 8$ 且 $\\text{AIC}_{3} > 8$，任何移除操作都会增加 AIC。后向剔除停止，最终模型为 $M_{B} = \\{X_{2},X_{3}\\}$。\n\n因此，前向选择得到的模型是 $\\{X_1, X_2\\}$，后向剔除得到的模型是 $\\{X_2, X_3\\}$。这与选项 B 相符。", "answer": "$$\\boxed{B}$$", "id": "1936615"}, {"introduction": "模型选择准则虽然强大，但并非万能。有时，数据的内在特性，例如预测变量之间的高度相关性（即多重共线性），会使得选出唯一的“最佳”模型变得困难。在这个实践中，你将使用贝叶斯信息准则（Bayesian Information Criterion, BIC）来分析一个存在多重共线性的场景。你会发现，不同的模型可能得到非常相近的 BIC 值，这说明数据本身无法明确区分它们，从而强调了在模型选择中进行诊断性检查的重要性 [@problem_id:1936660]。", "problem": "一位环境科学家正在建立一个线性回归模型，以预测河流中某种污染物浓度 $y$（单位：$\\mu$g/L）。该数据集包含 $n=200$ 次独立测量。这位科学家正在考虑四个潜在的预测变量：$x_1$，上游工业排放量（单位：m$^3$/天）；$x_2$，农业径流指数（无量纲）；$x_3$，在 A 站测得的水温（单位：摄氏度）；以及 $x_4$，在紧邻 A 下游的 B 站测得的水温（单位：摄氏度）。\n\n科学家拟合了几个候选的线性模型，并计算了每个模型的残差平方和（RSS）。对于一个有 $p$ 个预测变量的模型，估计参数的数量取为 $k = p+2$，这包括了 $p$ 个斜率系数、截距以及误差项的方差。\n\n建模结果总结在下表中：\n\n| 模型ID | 模型包含的预测变量 | 残差平方和 (RSS) |\n|---|---|---|\n| M1 | $x_1, x_2$ | 2150 |\n| M2 | $x_1, x_2, x_3$ | 1840 |\n| M3 | $x_1, x_2, x_4$ | 1845 |\n| M4 | $x_1, x_2, x_3, x_4$ | 1838 |\n\n为了比较这些模型，科学家使用了贝叶斯信息准则（BIC），其定义为：\n$$\n\\text{BIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + k \\ln(n)\n$$\n科学家假设两个温度测量值 $x_3$ 和 $x_4$ 高度相关，导致模型 M2 和 M3 尽管使用了不同的预测变量，但在统计上却非常相似。为量化这种相似性，计算差值 $\\Delta \\text{BIC} = \\text{BIC}_{\\text{M3}} - \\text{BIC}_{\\text{M2}}$。\n\n将您的答案报告为一个数值，四舍五入到四位有效数字。", "solution": "我们使用贝叶斯信息准则（BIC）的定义来计算模型 M2 和 M3 的 BIC 值之差。\n$$\n\\text{BIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + k \\ln(n)\n$$\n给定参数为 $n=200$。对于模型 M2，预测变量为 $\\{x_1, x_2, x_3\\}$，因此 $p=3$。根据题目定义，$k_{\\text{M2}} = p+2 = 5$。其残差平方和为 $\\text{RSS}_{\\text{M2}} = 1840$。\n对于模型 M3，预测变量为 $\\{x_1, x_2, x_4\\}$，因此 $p=3$。同样地，$k_{\\text{M3}} = p+2 = 5$。其残差平方和为 $\\text{RSS}_{\\text{M3}} = 1845$。\n\n我们想计算 $\\Delta \\text{BIC} = \\text{BIC}_{\\text{M3}} - \\text{BIC}_{\\text{M2}}$。\n$$\n\\text{BIC}_{\\text{M2}} = n \\ln\\left(\\frac{\\text{RSS}_{\\text{M2}}}{n}\\right) + k_{\\text{M2}} \\ln(n)\n$$\n$$\n\\text{BIC}_{\\text{M3}} = n \\ln\\left(\\frac{\\text{RSS}_{\\text{M3}}}{n}\\right) + k_{\\text{M3}} \\ln(n)\n$$\n由于 $k_{\\text{M2}} = k_{\\text{M3}} = 5$，惩罚项 $k \\ln(n)$ 在相减时会相互抵消。\n$$\n\\Delta \\text{BIC} = \\left[n \\ln\\left(\\frac{\\text{RSS}_{\\text{M3}}}{n}\\right) + k_{\\text{M3}} \\ln(n)\\right] - \\left[n \\ln\\left(\\frac{\\text{RSS}_{\\text{M2}}}{n}\\right) + k_{\\text{M2}} \\ln(n)\\right]\n$$\n$$\n\\Delta \\text{BIC} = n \\ln\\left(\\frac{\\text{RSS}_{\\text{M3}}}{n}\\right) - n \\ln\\left(\\frac{\\text{RSS}_{\\text{M2}}}{n}\\right)\n$$\n使用对数性质 $\\ln(a) - \\ln(b) = \\ln(a/b)$：\n$$\n\\Delta \\text{BIC} = n \\ln\\left(\\frac{\\text{RSS}_{\\text{M3}}/n}{\\text{RSS}_{\\text{M2}}/n}\\right) = n \\ln\\left(\\frac{\\text{RSS}_{\\text{M3}}}{\\text{RSS}_{\\text{M2}}}\\right)\n$$\n代入给定值：\n$$\n\\Delta \\text{BIC} = 200 \\ln\\left(\\frac{1845}{1840}\\right)\n$$\n进行数值计算：\n$$\n\\Delta \\text{BIC} = 200 \\ln(1.00271739...) \\approx 200 \\times 0.00271365... \\approx 0.54273\n$$\n四舍五入到四位有效数字，我们得到：\n$$\n\\Delta \\text{BIC} \\approx 0.5427\n$$", "answer": "$$\\boxed{0.5427}$$", "id": "1936660"}]}