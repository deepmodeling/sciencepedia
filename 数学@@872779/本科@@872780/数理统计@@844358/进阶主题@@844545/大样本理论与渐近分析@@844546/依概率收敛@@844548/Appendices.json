{"hands_on_practices": [{"introduction": "大数定律是概率论的基石，它告诉我们独立同分布随机变量的样本均值会依概率收敛到其期望值。这个练习将这一思想推广到了一个更普遍的情形：加权平均值，其中较新的观测值被赋予更大的权重。通过解决这个问题，你将练习使用切比雪夫不等式来证明依概率收敛的核心技巧，即证明估计量的方差趋于零，从而加深对收敛概念背后机制的理解。", "problem": "考虑一个独立同分布 (i.i.d.) 的随机变量序列 $X_1, X_2, \\dots, X_n, \\dots$。这些变量具有相同的有限均值 $E[X_i] = \\mu$ 和相同的有限非零方差 $\\text{Var}(X_i) = \\sigma^2$。\n\n一个新的随机变量序列 $Y_n$ 被构造为该序列前 $n$ 个变量的加权平均值：\n$$Y_n = \\frac{\\sum_{i=1}^n i X_i}{\\sum_{i=1}^n i}$$\n这种加权平均对序列中靠后的观测值给予线性递增的权重。可以证明，当 $n \\to \\infty$ 时，序列 $Y_n$ 依概率收敛到一个特定的常数值。\n\n确定这个常数值。您的答案应为用给定参数表示的解析表达式。", "solution": "定义归一化和 $S_{n}=\\sum_{i=1}^{n} i=\\frac{n(n+1)}{2}$。那么加权平均可以写成\n$$\nY_{n}=\\sum_{i=1}^{n}\\frac{i}{S_{n}}X_{i}.\n$$\n使用期望的线性性质和共同均值 $E[X_{i}]=\\mu$ 计算其期望：\n$$\nE[Y_{n}]=\\sum_{i=1}^{n}\\frac{i}{S_{n}}E[X_{i}]=\\mu\\sum_{i=1}^{n}\\frac{i}{S_{n}}=\\mu.\n$$\n使用独立性，$\\text{Var}(X_{i})=\\sigma^{2}$，以及当 $i\\neq j$ 时 $\\text{Cov}(X_{i},X_{j})=0$ 来计算其方差：\n$$\n\\text{Var}(Y_{n})=\\sum_{i=1}^{n}\\left(\\frac{i}{S_{n}}\\right)^{2}\\text{Var}(X_{i})=\\sigma^{2}\\frac{\\sum_{i=1}^{n} i^{2}}{S_{n}^{2}}.\n$$\n使用恒等式 $\\sum_{i=1}^{n} i^{2}=\\frac{n(n+1)(2n+1)}{6}$ 和 $S_{n}^{2}=\\left(\\frac{n(n+1)}{2}\\right)^{2}=\\frac{n^{2}(n+1)^{2}}{4}$ 可得\n$$\n\\text{Var}(Y_{n})=\\sigma^{2}\\cdot\\frac{\\frac{n(n+1)(2n+1)}{6}}{\\frac{n^{2}(n+1)^{2}}{4}}\n=\\sigma^{2}\\cdot\\frac{4(2n+1)}{6n(n+1)}\n=\\sigma^{2}\\cdot\\frac{2(2n+1)}{3n(n+1)}.\n$$\n由于当 $n\\to\\infty$ 时 $\\frac{2(2n+1)}{3n(n+1)}\\to 0$，因此有 $\\text{Var}(Y_{n})\\to 0$。根据切比雪夫不等式，对于任何 $\\varepsilon>0$，\n$$\nP\\big(|Y_{n}-\\mu|>\\varepsilon\\big)=P\\big(|Y_{n}-E[Y_{n}]|>\\varepsilon\\big)\\leq \\frac{\\text{Var}(Y_{n})}{\\varepsilon^{2}}\\to 0.\n$$\n因此 $Y_{n}$ 依概率收敛到 $\\mu$。该常数极限为 $\\mu$。", "answer": "$$\\boxed{\\mu}$$", "id": "1910722"}, {"introduction": "在学习了平均值收敛的例子后，一个自然的问题是：样本均值总是会收敛到一个常数吗？大数定律的成立依赖于一些关键前提，其中之一就是期望值的存在性。[@problem_id:1353353] 这个练习通过著名的柯西分布，探讨了当这个核心假设不被满足时会发生什么。这个练习是一个至关重要的反例，它不仅能加深你对极限定理适用边界的理解，也展示了特征函数在分析随机变量和（尤其是在矩不存在时）的强大威力。", "problem": "在一个数据分析场景中，记录了一个独立同分布 (i.i.d.) 的测量序列 $X_1, X_2, \\dots, X_n$。每个测量值 $X_i$ 是一个服从标准柯西分布的随机变量。标准柯西分布的概率密度函数 (PDF) 由下式给出：\n$$f(x) = \\frac{1}{\\pi(1+x^2)}$$\n其中 $-\\infty  x  \\infty$。\n\n这些测量值的样本均值计算为 $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^n X_i$。\n\n考虑当测量次数 $n$ 趋于无穷大时，样本均值 $\\bar{X}_n$ 的行为。随机变量序列 $\\{\\bar{X}_n\\}$ 依分布收敛于什么？\n\nA. 常数 0。\n\nB. 一个服从标准柯西分布的随机变量。\n\nC. 一个服从标准正态分布的随机变量。\n\nD. 它不依分布收敛于任何随机变量或常数。\n\nE. 一个服从自由度为 $n-1$ 的学生 t-分布的随机变量。", "solution": "设 $X_{1},\\dots,X_{n}$ 为独立同分布的标准柯西随机变量，其密度函数为 $f(x)=\\frac{1}{\\pi(1+x^{2})}$。记 $S_{n}=\\sum_{i=1}^{n}X_{i}$ 和 $\\bar{X}_{n}=\\frac{S_{n}}{n}$。\n\n一个关键的工具是特征函数。标准柯西随机变量 $X$ 的特征函数是一个已知的公式\n$$\n\\varphi_{X}(t)=\\exp(-|t|),\\quad t\\in\\mathbb{R}.\n$$\n因为 $X_{1},\\dots,X_{n}$ 是独立同分布的，所以它们的和的特征函数是各个特征函数的乘积：\n$$\n\\varphi_{S_{n}}(t)=\\prod_{i=1}^{n}\\varphi_{X_{i}}(t)=[\\varphi_{X}(t)]^{n}=\\exp(-n|t|).\n$$\n函数 $t\\mapsto \\exp(-\\gamma|t|)$ 是位置参数为 $0$、尺度参数为 $\\gamma$ 的柯西分布的特征函数。因此，$S_{n}$ 服从一个尺度参数为 $n$ 的柯西分布。\n\n对于样本均值 $\\bar{X}_{n}=S_{n}/n$，根据特征函数的尺度变换性质，其特征函数为\n$$\n\\varphi_{\\bar{X}_{n}}(t)=\\varphi_{S_{n}}(t/n)=\\exp\\!\\left(-n\\left|\\frac{t}{n}\\right|\\right)=\\exp(-|t|).\n$$\n这正好是标准柯西随机变量的特征函数。因此，对每个 $n$，\n$$\n\\bar{X}_{n}\\stackrel{d}{=}\\text{Cauchy}(0,1).\n$$\n因此，序列 $\\{\\bar{X}_{n}\\}$ 的分布不随 $n$ 的变化而改变，所以它（平凡地）依分布收敛于一个标准柯西随机变量。这也表明经典的中心极限定理在此不适用，因为柯西分布没有有限方差。\n\n因此，正确选项是 B。", "answer": "$$\\boxed{B}$$", "id": "1353353"}, {"introduction": "随机过程的收敛有多种不同的模式，其中最重要的是依概率收敛和殆必收敛。这两种收敛模式之间有何区别？著名的“打字机序列”正是为了阐明它们之间的微妙差异而构建的经典范例。[@problem_id:1293189] 通过分析这个序列，你将具体理解为什么依概率收敛是一个比殆必收敛更弱的条件。它清晰地表明，一个随机变量序列可以在概率上收敛（即偏离极限值的可能性变得很小），但其几乎每一个实现路径本身却不收敛。", "problem": "考虑一个概率空间 $(\\Omega, \\mathcal{F}, P)$，其中 $\\Omega = [0, 1]$，$\\mathcal{F}$ 是 $[0, 1]$ 上的 Borel σ-代数，而 $P$ 是 $[0, 1]$ 上的均匀（勒贝格）测度。我们如下定义一个随机变量序列 $\\{X_n\\}_{n=1}^{\\infty}$。对于任意整数 $n \\ge 1$，存在唯一的非负整数对 $(k, j)$，使得 $n = 2^k + j$，其中 $0 \\le j  2^k$。随机变量 $X_n$ 在 $\\omega \\in \\Omega$ 处的值定义为：\n$$\nX_n(\\omega) =\n\\begin{cases}\n1  \\text{若 } \\omega \\in \\left[\\frac{j}{2^k}, \\frac{j+1}{2^k}\\right] \\\\\n0  \\text{否则}\n\\end{cases}\n$$\n这个序列可以看作一个“扫描”区间的指示函数，该区间以递减的宽度反复扫过整个空间 $[0, 1]$。令 $X$ 是恒为零的随机变量，即对所有 $\\omega \\in \\Omega$ 都有 $X(\\omega)=0$。\n\n下列哪个陈述正确地描述了序列 $\\{X_n\\}$ 到 $X=0$ 的收敛性？\n\nA. 序列 $\\{X_n\\}$ 几乎必然收敛到 0，但不依概率收敛。\n\nB. 序列 $\\{X_n\\}$ 依概率收敛到 0，但不几乎必然收敛。\n\nC. 序列 $\\{X_n\\}$ 既几乎必然收敛到 0，也依概率收敛。\n\nD. 序列 $\\{X_n\\}$ 既不几乎必然收敛到 0，也不依概率收敛。", "solution": "我们回顾一下定义。对于每个整数 $n \\geq 1$，存在唯一的整数对 $(k,j)$，其中 $k \\in \\mathbb{Z}_{\\ge 0}$ 且 $0 \\le j  2^{k}$，使得 $n = 2^{k} + j$。则\n$$\nX_{n}(\\omega) = \\mathbf{1}_{\\left[\\frac{j}{2^{k}},\\, \\frac{j+1}{2^{k}}\\right]}(\\omega).\n$$\n令 $X \\equiv 0$。我们分析到 $X$ 的几乎必然收敛和依概率收敛。\n\n几乎必然收敛：根据定义，$\\{X_{n}\\}$ 几乎必然收敛到 $0$，如果\n$$\nP\\big(\\{\\omega \\in \\Omega : \\lim_{n \\to \\infty} X_{n}(\\omega) = 0\\}\\big) = 1.\n$$\n固定任意 $\\omega \\in [0,1]$。对于每个 $k \\in \\mathbb{Z}_{\\ge 0}$，区间族 $\\left\\{\\left[\\frac{j}{2^{k}}, \\frac{j+1}{2^{k}}\\right] : j = 0,1,\\dots,2^{k}-1\\right\\}$ 覆盖了 $[0,1]$，因此存在 $j_{k} \\in \\{0,\\dots,2^{k}-1\\}$ 使得\n$$\n\\omega \\in \\left[\\frac{j_{k}}{2^{k}}, \\frac{j_{k}+1}{2^{k}}\\right].\n$$\n定义 $n_{k} = 2^{k} + j_{k}$。根据构造，对每个 $k$ 都有 $X_{n_{k}}(\\omega) = 1$。因此，对于每个 $\\omega$，存在无穷多个 $n$ 使得 $X_{n}(\\omega) = 1$。此外，在每个区块 $\\{2^{k},\\dots,2^{k+1}-1\\}$ 中，至多有两个指标使得 $X_{n}(\\omega) = 1$（如果 $\\omega$ 不是分母为 $2^{k}$ 的二进有理数，则恰好有一个），其余的指标则得到 $X_{n}(\\omega) = 0$，所以也存在无穷多个 $n$ 使得 $X_{n}(\\omega) = 0$。因此，对于每个 $\\omega \\in [0,1]$，序列 $\\{X_{n}(\\omega)\\}$ 会无限次取值 1 和 0，并且不收敛（特别地，它不收敛到 0）。所以，\n$$\nP\\big(\\{\\omega : \\lim_{n \\to \\infty} X_{n}(\\omega) = 0\\}\\big) = 0 \\neq 1,\n$$\n所以 $X_{n} \\not\\to 0$ 几乎必然地。\n\n依概率收敛：根据定义，$X_{n} \\to 0$ 依概率收敛，如果对于每个 $\\epsilon > 0$，\n$$\n\\lim_{n \\to \\infty} P\\big(|X_{n} - 0| > \\epsilon\\big) = 0.\n$$\n由于 $X_{n}$ 只取 0 和 1 两个值，对于任意 $\\epsilon \\in (0,1]$，\n$$\n\\{|X_{n} - 0| > \\epsilon\\} = \\{X_{n} = 1\\},\n$$\n所以\n$$\nP\\big(|X_{n}| > \\epsilon\\big) = P(X_{n} = 1).\n$$\n给定 $n = 2^{k} + j$，$X_{n}$ 是一个长度为 $2^{-k}$ 的区间的指示函数，且 $P$ 是 $[0,1]$ 上的勒贝格测度。因此\n$$\nP(X_{n} = 1) = 2^{-k}.\n$$\n令 $k(n)$ 表示与 $n$ 相关联的 $k$。当 $n \\to \\infty$ 时，必然有 $k(n) \\to \\infty$，因为 $n \\in \\{2^{k},\\dots,2^{k+1}-1\\}$ 且这些区块会移向更大的 $k$。因此，\n$$\n\\lim_{n \\to \\infty} P\\big(|X_{n}| > \\epsilon\\big) = \\lim_{n \\to \\infty} 2^{-k(n)} = 0 \\quad \\text{对所有 } \\epsilon \\in (0,1].\n$$\n对于 $\\epsilon > 1$，$P(|X_{n}| > \\epsilon) = 0$ 对所有 $n$ 成立，所以极限也是 0。因此 $X_{n} \\to 0$ 依概率收敛。\n\n综合两部分，正确的陈述是 $\\{X_{n}\\}$ 依概率收敛到 0，但不几乎必然收敛。", "answer": "$$\\boxed{B}$$", "id": "1293189"}]}