{"hands_on_practices": [{"introduction": "要真正掌握一种算法，最好的方法莫过于亲手实现它。这项练习旨在通过从头开始编程实现自助法 (bootstrap) 和刀切法 (jackknife)，来揭开这两种重抽样方法的神秘面纱。通过仅使用均匀分布随机数生成器来构建自助法样本索引，你将对这些强大的不确定性量化方法的工作机制有更深刻的理解，并锻炼自己将统计理论转化为可执行代码的能力。[@problem_id:2404323]", "problem": "您必须编写一个完整的程序，以如下方式实现用于不确定性量化的非参数重抽样。给定一个实数有限数据集 $\\{x_{1},x_{2},\\dots,x_{n}\\}$ 和一个将任意实数有限序列映射为一个实数的统计量 $T$，您的目标是计算两个不确定性量化指标：给定数据集上统计量 $T$ 的自助法标准误和刀切法标准误，以及一个自助法百分位置信区间（confidence interval, CI）。实现时必须只使用一个独立抽样源 $U \\sim \\mathrm{Uniform}(0,1)$ 来执行自助法重抽样；不得使用任何直接有放回地抽样索引或元素的内置抽样函数。自助法索引抽样的正确性必须遵循以下事实：如果 $U \\sim \\mathrm{Uniform}(0,1)$ 且 $n \\in \\mathbb{N}$ 是数据集大小，则整数 $J=\\lfloor n U \\rfloor$ 在 $\\{0,1,\\dots,n-1\\}$ 上均匀分布，即对于每个整数 $k \\in \\{0,1,\\dots,n-1\\}$ 都有 $\\mathbb{P}(J=k)=1/n$。利用这一事实将 $U$ 的独立抽样映射为独立的自助法索引。您不能调用任何直接有放回地抽样元素或索引的函数。请使用以下基本定义作为您的出发点。对于选定的统计量 $T$，自助法程序通过对每个复制 $b \\in \\{1,2,\\dots,B\\}$ 从 $\\{0,1,\\dots,n-1\\}$ 中有放回地抽样索引来生成大小为 $n$ 的重抽样样本，并对该重抽样样本计算 $T$，从而形成 $B$ 个自助法复制。将这些自助法统计量表示为 $\\{\\hat{\\theta}_{b}\\}_{b=1}^{B}$。自助法标准误是 $\\{\\hat{\\theta}_{b}\\}$ 的样本标准差，即 $s_{\\mathrm{boot}}=\\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$，其中 $\\bar{\\theta}=\\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$。名义水平为 $1-\\alpha$ 的自助法百分位置信区间由 $\\{\\hat{\\theta}_{b}\\}$ 在概率 $p_{\\ell}=\\alpha/2$ 和 $p_{u}=1-\\alpha/2$ 处的经验分位数定义。为避免歧义，将概率 $p \\in [0,1]$ 处的经验分位数定义如下：如果 $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$ 是排序后的自助法值，则 $q_{p}=t_{(k)}$，其中 $k=\\lceil p B \\rceil$，并约定如果 $p$ 为 $0$ 或 $1$，则 $k$ 被限制在 $\\{1,2,\\dots,B\\}$ 的范围内。对于刀切法，定义留一法统计量 $\\{\\hat{\\theta}_{(i)}\\}_{i=1}^{n}$，其中 $\\hat{\\theta}_{(i)}=T(x_{1},\\dots,x_{i-1},x_{i+1},\\dots,x_{n})$ 是在省略 $x_{i}$ 的数据集上计算的。设 $\\bar{\\theta}_{\\mathrm{jack}}=\\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$。刀切法标准误为 $s_{\\mathrm{jack}}=\\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$。您的程序必须精确实现这些定义。请在实数有限数组上实现以下统计量 $T$：样本均值和样本中位数，其中偶数长度的中位数是两个中心顺序统计量的平均值。您不得使用任何内置的重抽样函数，例如直接有放回选择的例程；所有自助法索引都必须通过使用 $J=\\lfloor n U \\rfloor$ 转换来自 $\\mathrm{Uniform}(0,1)$ 的独立抽样来生成。请使用以下测试套件。对于每个测试用例，您将获得一个数据集、一个统计量选择、自助法复制次数 $B$、一个名义尾部概率 $\\alpha$ 和一个随机种子。对于每个测试用例，按顺序计算并返回四个值：自助法标准误 $s_{\\mathrm{boot}}$、刀切法标准误 $s_{\\mathrm{jack}}$，以及使用上述分位数定义的水平为 $1-\\alpha$ 的自助法百分位置信区间的下界和上界 $(q_{\\ell},q_{u})$。测试套件如下：\n- 案例 1：数据 $[1.2,2.0,3.4,2.2]$，统计量 均值，$B=5000$，$\\alpha=0.1$，种子 $=12345$。\n- 案例 2：数据 $[5.0,5.0,5.0,5.0,5.0]$，统计量 中位数，$B=3000$，$\\alpha=0.2$，种子 $=2468$。\n- 案例 3：数据 $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$，统计量 中位数，$B=6000$，$\\alpha=0.1$，种子 $=13579$。\n- 案例 4：数据 $[0.2,0.5,1.1,2.8,4.0,7.5,9.0]$，统计量 均值，$B=6000$，$\\alpha=0.05$，种子 $=98765$。\n您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按此顺序包含 $16$ 个实数：对于案例 1，输出 $s_{\\mathrm{boot}}$, $s_{\\mathrm{jack}}$, $q_{\\ell}$, $q_{u}$；然后是案例 2，顺序相同；然后是案例 3；然后是案例 4。为保证数值稳定性和结果的直接可比性，请将每个输出值四舍五入到恰好 $6$ 位小数。不涉及物理单位。不涉及角度。百分比必须表示为小数，因此 $\\alpha$ 直接以 $[0,1]$ 中的数字形式提供，您不得打印任何百分号。", "solution": "该问题是有效的。它提出了一个清晰、独立且科学上合理的计算统计学任务。所有定义、数据和参数都已明确提供，可以直接且可验证地实现。问题的核心是实现两种非参数重抽样技术——自助法（bootstrap）和刀切法（jackknife）——来估计给定统计量的不确定性。\n\n解决方案首先定义必要的统计函数，然后按照规定实现重抽样过程。\n\n**1. 统计学预备知识**\n\n给定一个大小为 $n$ 的数据集 $X = \\{x_{1}, x_{2}, \\dots, x_{n}\\}$ 和一个统计量 $T$，我们的目标是量化估计值 $\\hat{\\theta} = T(X)$ 的不确定性。\n\n问题要求实现两个特定的统计量：\n- **样本均值**：对于数据集 $\\{y_1, \\dots, y_k\\}$，均值为 $\\bar{y} = \\frac{1}{k}\\sum_{i=1}^{k} y_i$。\n- **样本中位数**：对于一个有序数据集 $y_{(1)} \\le y_{(2)} \\le \\dots \\le y_{(k)}$，如果 $k$ 是奇数，中位数定义为 $y_{((k+1)/2)}$；如果 $k$ 是偶数，则定义为 $\\frac{1}{2}(y_{(k/2)} + y_{(k/2+1)})$。\n\n**2. 自助法（Bootstrap）过程**\n\n自助法通过从给定数据集中重复抽样来估计 $\\hat{\\theta}$ 的抽样分布。\n\n- **重抽样**：该过程涉及生成 $B$ 个自助法复制。对于每个复制 $b \\in \\{1, 2, \\dots, B\\}$，我们通过从 $\\{0, 1, \\dots, n-1\\}$ 中有放回地抽样索引来构建一个大小为 $n$ 的自助法样本 $X^{*b}$。问题规定了此操作的具体方法：对于自助法样本中的每个位置，从一个均匀随机变量 $U \\sim \\mathrm{Uniform}(0,1)$ 使用公式 $J = \\lfloor nU \\rfloor$ 生成一个索引 $J \\in \\{0, 1, \\dots, n-1\\}$。重复此过程 $n$ 次，以获得一个自助法样本的全套索引。\n- **自助法统计量**：对每个自助法样本 $X^{*b}$ 计算统计量 $T$，得到一个自助法统计量 $\\hat{\\theta}_b = T(X^{*b})$。对所有 $B$ 个复制重复此过程，形成自助法分布 $\\{\\hat{\\theta}_1, \\hat{\\theta}_2, \\dots, \\hat{\\theta}_B\\}$。\n\n- **自助法标准误 ($s_{\\mathrm{boot}}$)**：$\\hat{\\theta}$ 的标准误的自助法估计是自助法统计量的样本标准差：\n$$s_{\\mathrm{boot}} = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{\\theta}_{b}-\\bar{\\theta}\\right)^{2}}$$\n其中 $\\bar{\\theta} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{\\theta}_{b}$ 是自助法统计量的平均值。\n\n- **自助法百分位置信区间**：为了构建一个 $(1-\\alpha)$ 置信区间，我们使用排序后的自助法统计量 $t_{(1)} \\le t_{(2)} \\le \\dots \\le t_{(B)}$ 的分位数。该区间由 $[q_{\\ell}, q_{u}]$ 给出，其中 $q_{\\ell}$ 和 $q_{u}$ 分别是对应于概率 $p_{\\ell} = \\alpha/2$ 和 $p_{u} = 1-\\alpha/2$ 的经验分位数。根据问题的定义，分位数 $q_p$ 是 $t_{(k)}$，其中索引 $k$ 计算为 $k = \\lceil pB \\rceil$。这个基于1的索引 $k$ 被限制在 $\\{1, 2, \\dots, B\\}$ 的范围内。为实现这一点，对于给定的概率 $p$，我们计算 $k = \\max(1, \\lceil pB \\rceil)$，并从基于0索引的已排序自助法统计量数组中选择索引为 $k-1$ 的元素。\n\n**3. 刀切法（Jackknife）过程**\n\n刀切法是另一种重抽样技术，它系统地从数据集中省略每个观测值。\n\n- **重抽样**：对于每个观测值 $i \\in \\{1, 2, \\dots, n\\}$，通过从原始数据集中移除 $x_i$ 来形成一个刀切法样本 $X_{(i)}$。这将创建 $n$ 个数据集，每个数据集的大小为 $n-1$。\n- **刀切法统计量**：对这 $n$ 个样本中的每一个计算统计量 $T$，得到留一法统计量 $\\{\\hat{\\theta}_{(1)}, \\hat{\\theta}_{(2)}, \\dots, \\hat{\\theta}_{(n)}\\}$。\n\n- **刀切法标准误 ($s_{\\mathrm{jack}}$)**：$\\hat{\\theta}$ 的标准误的刀切法估计定义为：\n$$s_{\\mathrm{jack}} = \\sqrt{\\frac{n-1}{n}\\sum_{i=1}^{n}\\left(\\hat{\\theta}_{(i)}-\\bar{\\theta}_{\\mathrm{jack}}\\right)^{2}}$$\n其中 $\\bar{\\theta}_{\\mathrm{jack}} = \\frac{1}{n}\\sum_{i=1}^{n}\\hat{\\theta}_{(i)}$ 是刀切法统计量的平均值。\n\n**4. 实现策略**\n\n整个程序的结构是为了处理指定的测试用例。一个主函数遍历每个用例，调用一个核心计算函数。对于给定的数据集、统计量和参数（$B, \\alpha$, 种子），此函数执行以下步骤：\n1.  设置随机数生成器种子以确保可复现性。\n2.  执行自助法过程：使用指定的 $\\lfloor nU \\rfloor$ 方法生成 $B$ 个自助法样本，计算 $B$ 个统计量，然后计算 $s_{\\mathrm{boot}}$ 和百分位置信区间界限 $(q_{\\ell}, q_{u})$。\n3.  执行刀切法过程：生成 $n$ 个留一法样本，计算 $n$ 个统计量，并计算 $s_{\\mathrm{jack}}$。\n4.  返回四个所需的值：$s_{\\mathrm{boot}}, s_{\\mathrm{jack}}, q_{\\ell}, q_{u}$。\n\n收集所有测试用例的最终结果，四舍五入到 $6$ 位小数，并以要求的单行格式打印。", "answer": "```python\nimport numpy as np\nimport math\n\ndef compute_uncertainties(data, statistic_name, B, alpha, seed):\n    \"\"\"\n    Computes bootstrap and jackknife standard errors and a bootstrap percentile CI.\n\n    Args:\n        data (np.ndarray): The input dataset.\n        statistic_name (str): The name of the statistic ('mean' or 'median').\n        B (int): The number of bootstrap replicates.\n        alpha (float): The significance level for the confidence interval.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        tuple: A tuple containing (s_boot, s_jack, ci_lower, ci_upper).\n    \"\"\"\n    # Set the random seed for reproducibility\n    np.random.seed(seed)\n\n    # Convert data to numpy array\n    data = np.array(data, dtype=float)\n    n = len(data)\n\n    # Define statistic functions\n    if statistic_name == 'mean':\n        statistic_fn = np.mean\n    elif statistic_name == 'median':\n        statistic_fn = np.median\n    else:\n        raise ValueError(\"Unknown statistic\")\n\n    # --- Bootstrap Procedure ---\n    bootstrap_stats = np.empty(B)\n    for i in range(B):\n        # Generate n uniform random numbers U ~ Uniform(0,1)\n        uniform_draws = np.random.rand(n)\n        # Generate bootstrap indices using J = floor(n*U)\n        bootstrap_indices = np.floor(n * uniform_draws).astype(int)\n        # Create bootstrap sample\n        bootstrap_sample = data[bootstrap_indices]\n        # Compute statistic\n        bootstrap_stats[i] = statistic_fn(bootstrap_sample)\n\n    # Bootstrap Standard Error\n    s_boot = np.std(bootstrap_stats, ddof=1)\n\n    # Bootstrap Percentile Confidence Interval\n    sorted_bootstrap_stats = np.sort(bootstrap_stats)\n    \n    # Lower bound\n    p_lower = alpha / 2.0\n    k_lower = int(math.ceil(p_lower * B))\n    k_lower = max(1, k_lower)\n    ci_lower = sorted_bootstrap_stats[k_lower - 1]\n\n    # Upper bound\n    p_upper = 1.0 - alpha / 2.0\n    k_upper = int(math.ceil(p_upper * B))\n    k_upper = max(1, k_upper) \n    ci_upper = sorted_bootstrap_stats[k_upper - 1]\n\n    # --- Jackknife Procedure ---\n    jackknife_stats = np.empty(n)\n    for i in range(n):\n        # Create leave-one-out sample\n        jackknife_sample = np.delete(data, i)\n        # Compute statistic\n        jackknife_stats[i] = statistic_fn(jackknife_sample)\n\n    # Jackknife Standard Error\n    theta_jack_mean = np.mean(jackknife_stats)\n    sum_sq_diff = np.sum((jackknife_stats - theta_jack_mean)**2)\n    s_jack = np.sqrt(((n - 1) / n) * sum_sq_diff)\n    \n    return s_boot, s_jack, ci_lower, ci_upper\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        {'data': [1.2, 2.0, 3.4, 2.2], 'statistic': 'mean', 'B': 5000, 'alpha': 0.1, 'seed': 12345},\n        {'data': [5.0, 5.0, 5.0, 5.0, 5.0], 'statistic': 'median', 'B': 3000, 'alpha': 0.2, 'seed': 2468},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'median', 'B': 6000, 'alpha': 0.1, 'seed': 13579},\n        {'data': [0.2, 0.5, 1.1, 2.8, 4.0, 7.5, 9.0], 'statistic': 'mean', 'B': 6000, 'alpha': 0.05, 'seed': 98765}\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = compute_uncertainties(\n            case['data'],\n            case['statistic'],\n            case['B'],\n            case['alpha'],\n            case['seed']\n        )\n        all_results.extend(results)\n\n    # Format results to 6 decimal places and create the final output string\n    formatted_results = [f\"{val:.6f}\" for val in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2404323"}, {"introduction": "现实世界的数据往往不满足“独立同分布”(i.i.d.) 这一基本假设，例如嵌套在不同组别中的数据。这项练习将引导你思考如何为更复杂的聚类数据 (clustered data) 或分层数据 (hierarchical data) 设计有效的自助法程序，其中的关键在于重抽样的单位必须是数据中的独立单元。通过分析不同重抽样方案的有效性，你将学会如何批判性地审视重抽样方法的应用前提，并使其适应真实数据复杂的依赖结构。[@problem_id:1951652]", "problem": "一位环境科学家正在研究工业排放对鱼类体内汞含量的影响。数据从 $M$ 个不同的河流系统中收集。在每个河流系统 $i$ 中（其中 $i=1, \\dots, M$），采集了 $n_i$ 条鱼的样本，对于每条鱼 $j$（其中 $j=1, \\dots, n_i$），记录了两个测量值：其汞浓度 $Y_{ij}$，以及其与特定工业排放点的接近程度 $X_{ij}$。抽样的鱼类总数为 $N = \\sum_{i=1}^M n_i$。\n\n该科学家提出了一个简单线性回归模型来描述这种关系：\n$$\nY_{ij} = \\beta_0 + \\beta_1 X_{ij} + \\epsilon_{ij}\n$$\n主要目标是为系数 $\\beta_1$ 构建一个95%的置信区间。一个关键的考虑因素是来自同一河流系统的观测值可能不是独立的。河流所共有的未观测因素（例如，当地的水化学特性、特定的食物链特征）可能会在误差项中引起相关性。也就是说，对于同一河流 $i$ 内的鱼，当 $j \\neq k$ 时，$\\text{Cov}(\\epsilon_{ij}, \\epsilon_{ik}) \\neq 0$。然而，来自不同河流系统的观测值被假定为独立的。\n\n为了解释这种数据结构，考虑了几种基于自助法（bootstrap）的程序来估计普通最小二乘（OLS）估计量 $\\hat{\\beta_1}$ 的抽样分布。下列哪个陈述最准确地描述了一个有效的程序及其在此背景下有效性的原因？\n\nA. 非聚类（朴素）自助法：通过从所有鱼的完整数据集中有放回地抽取 $N$ 条单独的鱼来创建自助样本，忽略它们来自哪条河流。这个程序是有效的，因为根据中心极限定理，对于较大的鱼类总数 $N$，OLS估计量 $\\hat{\\beta_1}$ 的分布将近似正态。\n\nB. 聚类自助法：通过从原始的 $M$ 条河流列表中有放回地抽取 $M$ 个河流系统来创建自助样本。然后，对于每个选中的河流，将其所有相关的鱼样本都包含在新的自助数据集中。这个程序是有效的，因为它将河流系统视为独立的抽样单位，从而保留了原始数据中河流内部的相关性结构。\n\nC. 参数自助法：首先，将OLS模型拟合到原始数据上，以获得估计值 $\\hat{\\beta_0}$ 和 $\\hat{\\beta_1}$ 以及所有 $N$ 个残差的集合 $\\{e_{ij}\\}$。然后，通过从 $\\{e_{ij}\\}$ 中有放回地抽样一个残差 $e_{ij}^*$ 并设置 $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + e_{ij}^*$，为每个观测值创建一个自助结果 $Y_{ij}^*$。这个程序是有效的，因为它从拟合模型中模拟新数据，同时保留了原始的预测变量值。\n\nD. 聚类内重抽样自助法：通过保持原始的 $M$ 个河流集合固定来创建自助样本。然后，对于每条河流 $i$，通过从该河流中原始的 $n_i$ 条鱼中有放回地重抽样，为该河流生成一组新的 $n_i$ 条鱼。这个程序是有效的，因为它正确地模拟了每个独立河流系统内部发生的抽样变异性。\n\nE. 固定X自助法：通过首先拟合OLS模型以获得残差 $\\{e_{ij}\\}$ 来创建自助样本。然后，对于每条鱼，创建一个新的结果 $Y_{ij}^* = \\hat{\\beta_0} + \\hat{\\beta_1} X_{ij} + \\delta_{ij}$，其中 $\\delta_{ij}$ 是从一个正态分布 $\\mathcal{N}(0, \\hat{\\sigma}^2)$ 中抽取的随机值，$\\hat{\\sigma}^2$ 是残差的估计方差。只要误差是同方差且近似正态的，这个程序就是有效的。", "solution": "我们得到的是聚类数据：鱼嵌套在河流系统内。线性模型是\n$$\nY_{ij}=\\beta_{0}+\\beta_{1}X_{ij}+\\epsilon_{ij},\n$$\n其特点是河流之间独立，但河流内部存在相关性。形式上，对于 $i \\neq i'$，\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{i'k})=0,\n$$\n而对于同一河流 $i$ 和不同的鱼 $j \\neq k$，\n$$\n\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik}) \\neq 0.\n$$\n一种标准的表达方式是通过随机效应分解，\n$$\n\\epsilon_{ij}=u_{i}+v_{ij},\n$$\n其中 $u_{i}$ 是河流特定成分，$v_{ij}$ 是特异成分，且 $\\text{Var}(u_{i})=\\sigma_{u}^{2}$，$\\text{Var}(v_{ij})=\\sigma_{v}^{2}$，$\\text{Cov}(u_{i},v_{ij})=0$，这意味着\n$$\n\\text{Var}(\\epsilon_{ij})=\\sigma_{u}^{2}+\\sigma_{v}^{2},\\quad \\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}\\quad \\text{for }j \\neq k.\n$$\n独立的抽样单位是聚类 $\\mathcal{C}_{i}=\\{(X_{ij},Y_{ij}):j=1,\\dots,n_{i}\\}$，其中 $i=1,\\dots,M$。为了使自助法在聚类依赖下对 $\\hat{\\beta}_{1}$ 的抽样分布保持一致性，重抽样方案必须模仿这种依赖结构：重抽样独立的单位（即河流），并保留聚类内的联合分布。\n\n对所提出程序的评估：\n- 选项 A（朴素的个体层面自助法）从合并样本中独立同分布地抽取 $N$ 条鱼，忽略了河流成员关系。这在所有重抽样观测值上强加了一个独立同分布的误差结构，并且没有复现河流内部的协方差 $\\text{Cov}(\\epsilon_{ij},\\epsilon_{ik})=\\sigma_{u}^{2}$。因此，当 $\\sigma_{u}^{2}0$ 时，它产生的自助方差通常会向下偏倚。诉诸于大 $N$ 下的中心极限定理并不能修复自助法的不一致性；自助法必须复制正确的依赖关系，才能估计聚类情况下 $\\hat{\\beta}_{1}$ 的方差。\n- 选项 B（聚类自助法）从 $\\{1,\\dots,M\\}$ 中有放回地抽样河流，并包括每个被选中河流中的所有鱼，从而将 $\\{\\mathcal{C}_{i}\\}$ 作为独立同分布的单位进行重抽样。这保留了由 $u_{i}$ 引起的河流内部相关性，并反映了哪些河流进入样本的随机性。在标准的正则性条件下（特别是，$M \\to \\infty$ 且 $n_{i}$ 有界或受到适当控制），该程序对于具有聚类误差的 $\\hat{\\beta}_{1}$ 的抽样分布是渐近有效的。\n- 选项 C（汇集所有残差的残差自助法）从汇集集合 $\\{e_{ij}\\}$ 中独立同分布地抽样残差，并构造 $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+e_{ij}^{*}$。这在自助法世界中强制实施了独立同分布的误差，并破坏了河流内部的协方差结构；因此，对于聚类依赖性是无效的。\n- 选项 D（固定聚类的聚类内重抽样）在每个观测到的河流内重抽样鱼，保持河流集合不变。这以特定的已实现聚类效应为条件，并未反映当河流是独立单位时驱动 $\\hat{\\beta}_{1}$ 抽样分布的河流间抽样变异性。当聚类效应是随机的时，它会低估方差，并且对于以河流总体为目标的推断通常是无效的。\n- 选项 E（带有独立同分布噪声的固定X高斯参数自助法）独立地抽取 $\\delta_{ij}\\sim \\mathcal{N}(0,\\hat{\\sigma}^{2})$ 并设置 $Y_{ij}^{*}=\\hat{\\beta}_{0}+\\hat{\\beta}_{1}X_{ij}+\\delta_{ij}$。这强加了同方差的独立同分布误差，并且未能编码河流内部的协方差；即使在正态性假设下，正确的参数自助法也需要从具有估计的聚类协方差的多元正态分布中为每条河流抽取一个误差向量，而不是进行独立抽取。如上所述，它对于聚类依赖性是无效的。\n\n因此，将河流正确地视为独立抽样单位并保留河流内部相关性的程序是选项 B 中描述的聚类自助法，其陈述的理由与所需证明相符。", "answer": "$$\\boxed{B}$$", "id": "1951652"}, {"introduction": "重抽样方法的应用不仅限于估计置信区间，它同样是进行假设检验的强大工具。本练习将介绍一种经典的非参数方法——置换检验 (permutation test)。你将运用该方法，通过对数据进行随机排列来构建原假设下的检验统计量分布，进而评估两个独立样本的变异程度是否存在显著差异。这项练习不仅能让你亲手计算基于模拟结果的 $p$-值，还能加深你对“原假设下数据可交换性”这一核心思想的理解。[@problem_id:1951649]", "problem": "一位工业统计学家负责比较两种生产特定类型电阻器的制造工艺的一致性。工艺 A 和工艺 B 用于生产批次的电阻器，并测量其电阻值。目标是确定工艺 B 是否比工艺 A 表现出更大的变异性。由于可能存在离群值和非正态数据，因此选择了一种稳健的非参数方法。\n\n收集了两个独立的电阻值（单位：欧姆）随机样本：\n- 样本 A（来自工艺 A）：$\\{10, 12, 13, 15\\}$\n- 样本 B（来自工艺 B）：$\\{40, 48, 50, 53, 61\\}$\n\n该统计学家决定使用基于两个样本的中位数绝对偏差（MAD）之比的检验。样本 $\\{x_1, x_2, \\dots, x_n\\}$ 的 MAD 定义为每个数据点与样本中位数之间绝对差的中位数：\n$$ \\text{MAD} = \\text{median} \\left( |x_i - \\text{median}(\\{x_j\\})| \\right) $$\n在此分析中，MAD 的任何标准缩放常数都被忽略，因为它会在比率中被抵消。检验统计量定义为 $T = \\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$。\n\n为了评估观测到的检验统计量的显著性，执行了一个计算置换程序。将 $4+5=9$ 个总数据点汇集在一起。从这个组合集中，生成了 9,999 个随机置换。在每次置换中，无放回地形成一个大小为 4 的新样本（称之为 A'）和一个大小为 5 的新样本（B'），并计算统计量 $T^* = \\frac{\\text{MAD}(B')}{\\text{MAD}(A')}$。\n\n从 9,999 次置换中得到的 30 个最大的 $T^*$ 值，按降序排列如下：\n`3.15, 2.98, 2.81, 2.75, 2.66, 2.54, 2.49, 2.41, 2.35, 2.33, 2.28, 2.22, 2.19, 2.15, 2.11, 2.08, 2.05, 2.02, 1.99, 1.97, 1.94, 1.90, 1.88, 1.85, 1.83, 1.80, 1.77, 1.76, 1.75, 1.72`\n\n使用提供的模拟结果，计算用于检验工艺 B 的尺度（变异性）大于工艺 A 的假设的单侧 p 值。p 值的计算公式为 $p = \\frac{1+k}{1+N}$，其中 $N$ 是置换次数，$k$ 是置换统计量 $T^*$ 大于或等于从原始样本中观测到的统计量的次数。将你的答案以小数形式给出，并四舍五入到四位有效数字。", "solution": "我们正在使用中位数绝对偏差（MAD）的比率来检验工艺 B 是否比工艺 A 具有更大的变异性。样本 $\\{x_{1},\\dots,x_{n}\\}$ 的 MAD 定义为\n$$\n\\text{MAD}=\\text{median}\\left(|x_{i}-\\text{median}(\\{x_{j}\\})|\\right).\n$$\n首先计算观测统计量 $T=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}$。\n\n对于样本 A，$\\{10,12,13,15\\}$，样本中位数是中间两个顺序统计量的平均值：\n$$\n\\text{median}(A)=\\frac{12+13}{2}=12.5.\n$$\n与 $12.5$ 的绝对偏差为\n$$\n|10-12.5|=2.5,\\quad |12-12.5|=0.5,\\quad |13-12.5|=0.5,\\quad |15-12.5|=2.5.\n$$\n将这些值排序得到 $0.5,0.5,2.5,2.5$，所以 MAD 是这四个数的中位数，即中间两个值的平均值：\n$$\n\\text{MAD}(A)=\\frac{0.5+2.5}{2}=1.5.\n$$\n\n对于样本 B，$\\{40,48,50,53,61\\}$，样本中位数是中间的顺序统计量：\n$$\n\\text{median}(B)=50.\n$$\n与 $50$ 的绝对偏差为\n$$\n|40-50|=10,\\quad |48-50|=2,\\quad |50-50|=0,\\quad |53-50|=3,\\quad |61-50|=11.\n$$\n将这些值排序得到 $0,2,3,10,11$，所以 MAD 是中间值：\n$$\n\\text{MAD}(B)=3.\n$$\n因此，观测到的检验统计量为\n$$\nT=\\frac{\\text{MAD}(B)}{\\text{MAD}(A)}=\\frac{3}{1.5}=2.\n$$\n\n根据 $N=9999$ 次置换的置换程序，我们必须计算 $k$，即置换统计量 $T^{*}$ 大于或等于观测值 $T=2$ 的次数。给出了按降序排列的 $30$ 个最大的 $T^{*}$ 值。在这些值中，第 $18$ 大的值是 $2.02\\geq 2$，而第 $19$ 大的值是 $1.992$。由于所有其余的值都小于或等于 $1.99$，因此恰好有 $k=18$ 次置换满足 $T^{*}\\geq 2$。\n\n使用加一 p 值公式\n$$\np=\\frac{1+k}{1+N}=\\frac{1+18}{1+9999}=\\frac{19}{10000}=1.9\\times 10^{-3}.\n$$\n四舍五入到四位有效数字，结果是\n$$\n1.900\\times 10^{-3}.\n$$", "answer": "$$\\boxed{1.900 \\times 10^{-3}}$$", "id": "1951649"}]}