{"hands_on_practices": [{"introduction": "Rao-Blackwell定理的威力在于它能利用样本中的全部信息来改进一个初步的估计量。本练习以泊松分布为背景，从一个仅依赖于单次观测的无偏估计量出发。通过对充分统计量（样本总和）取条件期望，我们将构造出一个方差更小、统计效率更高的估计量，这是一个将离散随机变量的条件分布知识付诸实践的绝佳范例。[@problem_id:1922440]", "problem": "设 $X_1, X_2, \\ldots, X_n$ 是来自一个未知均值 $\\lambda > 0$ 的泊松分布的大小为 $n > 1$ 的独立同分布随机样本。我们有兴趣估计参数 $\\theta = \\lambda^2$。\n\n可以证明，统计量 $T = X_1(X_1 - 1)$ 是 $\\theta$ 的一个无偏估计量。然而，这个估计量并非最优，因为它只基于单个观测值 $X_1$。为了构造一个统计上更有效的估计量，可以计算在给定 $\\lambda$ 的充分统计量的情况下 $T$ 的条件期望。对于泊松样本，充分统计量是观测值的和，$S = \\sum_{i=1}^n X_i$。\n\n你的任务是计算改进后的估计量 $T'$，它被定义为在给定 $S$ 的情况下 $T$ 的条件期望。\n$$T' = E[T | S]$$\n将你的最终答案表示为充分统计量 $S$ 和样本大小 $n$ 的解析函数。", "solution": "设 $X_{1},\\ldots,X_{n}$ 是独立同分布于 $\\operatorname{Poisson}(\\lambda)$ 的随机变量，且 $S=\\sum_{i=1}^{n}X_{i}$ 是 $\\lambda$ 的充分统计量。定义 $T=X_{1}(X_{1}-1)$。Rao-Blackwell 改进是 $T'=\\mathbb{E}[T\\mid S]$。\n\n对于独立同分布的泊松变量，在给定 $S=s$ 的条件下，向量 $(X_{1},\\ldots,X_{n})$ 服从一个试验次数为 $s$、各单元概率相等的 $1/n$ 的多项分布。特别地，\n$$\nX_{1}\\mid S=s \\sim \\operatorname{Binomial}\\!\\left(s,\\frac{1}{n}\\right).\n$$\n使用恒等式 $\\mathbb{E}[X(X-1)]=\\operatorname{Var}(X)+\\{\\mathbb{E}[X]\\}^{2}-\\mathbb{E}[X]$，并将其应用于条件于 $S=s$ 的情况，我们计算\n$$\n\\mathbb{E}\\!\\left[X_{1}(X_{1}-1)\\mid S=s\\right]\n=\\operatorname{Var}(X_{1}\\mid S=s)+\\left(\\mathbb{E}[X_{1}\\mid S=s]\\right)^{2}-\\mathbb{E}[X_{1}\\mid S=s].\n$$\n对于 $X_{1}\\mid S=s\\sim \\operatorname{Binomial}(s,1/n)$，我们有\n$$\n\\mathbb{E}[X_{1}\\mid S=s]=\\frac{s}{n},\\qquad \\operatorname{Var}(X_{1}\\mid S=s]=\\frac{s}{n}\\left(1-\\frac{1}{n}\\right)=\\frac{s(n-1)}{n^{2}}.\n$$\n因此，\n$$\n\\mathbb{E}\\!\\left[X_{1}(X_{1}-1)\\mid S=s\\right]\n=\\frac{s(n-1)}{n^{2}}+\\left(\\frac{s}{n}\\right)^{2}-\\frac{s}{n}\n=\\frac{s^{2}-s}{n^{2}}\n=\\frac{s(s-1)}{n^{2}}.\n$$\n由于这对每一个 $s$ 都成立，所以作为 $S$ 的函数的改进估计量是\n$$\nT'=\\mathbb{E}[T\\mid S]=\\frac{S(S-1)}{n^{2}}.\n$$\n作为无偏性的检验，注意到 $S\\sim \\operatorname{Poisson}(n\\lambda)$，所以 $\\mathbb{E}[S(S-1)]=(n\\lambda)^{2}$，因此 $\\mathbb{E}[T']=\\lambda^{2}$，这与目标 $\\theta$ 一致。", "answer": "$$\\boxed{\\frac{S(S-1)}{n^{2}}}$$", "id": "1922440"}, {"introduction": "将离散分布中的思想延伸至连续分布，本练习探讨了伽玛分布的参数估计问题。初始估计量虽然无偏，但仅利用了第一个样本点，因而效率不高。通过利用样本总和这一充分统计量，我们将应用拉奥-布莱克韦尔定理系统性地改进该估计量，这个过程将展示伽玛分布与贝塔分布之间的深刻联系。[@problem_id:1922421]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是从一个伽马分布中抽取的独立同分布随机样本。该分布的概率密度函数由下式给出：\n$$f(x; \\alpha, \\beta) = \\frac{1}{\\Gamma(\\alpha)\\beta^{\\alpha}} x^{\\alpha-1} \\exp(-x/\\beta)$$\n对于 $x > 0$。形状参数 $\\alpha > 0$ 是一个已知常数，而尺度参数 $\\beta > 0$ 是未知的。\n\n我们仅使用第一个观测值构造未知参数 $\\beta$ 的一个初始简单估计量，定义为 $T_0 = \\frac{X_1}{\\alpha}$。为了获得一个更精细的估计量，可以计算在给定观测值总和 $S = \\sum_{i=1}^{n} X_i$ 的条件下 $T_0$ 的条件期望。\n\n设这个精细估计量为 $T_1 = E[T_0 | S]$。求 $T_1$ 关于 $n$、$\\alpha$ 和样本总和 $S$ 的表达式。", "solution": "设 $X_{1},\\dots,X_{n}$ 独立同分布（i.i.d.），其密度函数为 $f(x;\\alpha,\\beta)=\\left(\\Gamma(\\alpha)\\beta^{\\alpha}\\right)^{-1}x^{\\alpha-1}\\exp(-x/\\beta)$（对于 $x>0$），其中 $\\alpha>0$ 已知，$\\beta>0$ 未知。定义 $T_{0}=X_{1}/\\alpha$ 和 $S=\\sum_{i=1}^{n}X_{i}$。我们要求解 $T_{1}=E[T_{0}\\mid S]$。\n\n根据条件期望的线性性质，\n$$\nT_{1}=E\\!\\left[\\frac{X_{1}}{\\alpha}\\,\\middle|\\,S\\right]=\\frac{1}{\\alpha}E[X_{1}\\mid S].\n$$\n因此，只需计算 $E[X_{1}\\mid S]$。\n\n写出 $X=(X_{1},\\dots,X_{n})$ 的联合密度函数：\n$$\nf_{X}(x_{1},\\dots,x_{n})=\\left(\\Gamma(\\alpha)\\beta^{\\alpha}\\right)^{-n}\\left(\\prod_{i=1}^{n}x_{i}^{\\alpha-1}\\right)\\exp\\!\\left(-\\frac{1}{\\beta}\\sum_{i=1}^{n}x_{i}\\right),\\quad x_{i}>0.\n$$\n进行变量替换\n$$\nS=\\sum_{i=1}^{n}X_{i},\\quad U_{i}=\\frac{X_{i}}{S}\\ \\text{for}\\ i=1,\\dots,n-1,\\quad U_{n}=1-\\sum_{i=1}^{n-1}U_{i},\n$$\n其雅可比行列式为 $J=S^{n-1}$。那么\n$$\nf_{S,U}(s,u_{1},\\dots,u_{n-1})=\\left(\\Gamma(\\alpha)\\beta^{\\alpha}\\right)^{-n}\\left(\\prod_{i=1}^{n}(su_{i})^{\\alpha-1}\\right)\\exp\\!\\left(-\\frac{s}{\\beta}\\right)S^{n-1}\n$$\n$$\n=\\left(\\Gamma(\\alpha)\\beta^{\\alpha}\\right)^{-n}s^{n\\alpha-1}\\exp\\!\\left(-\\frac{s}{\\beta}\\right)\\prod_{i=1}^{n}u_{i}^{\\alpha-1},\n$$\n其中 $s>0$, $u_{i}>0$, 且 $\\sum_{i=1}^{n}u_{i}=1$。该式可以分解为一个关于 $s$ 的函数与一个关于 $u=(u_{1},\\dots,u_{n})$ 的函数的乘积，因此在给定 $S=s$ 的条件下，$U$ 的条件密度函数为\n$$\nf_{U\\mid S}(u\\mid s)=\\frac{\\Gamma(n\\alpha)}{\\Gamma(\\alpha)^{n}}\\prod_{i=1}^{n}u_{i}^{\\alpha-1},\n$$\n这是一个参数为 $(\\alpha,\\dots,\\alpha)$ 的狄利克雷(Dirichlet)分布。因此，$U_{1}\\mid S=s$ 服从贝塔(Beta)分布 $\\mathrm{Beta}(\\alpha,(n-1)\\alpha)$，于是\n$$\nE[U_{1}\\mid S=s]=\\frac{\\alpha}{\\alpha+(n-1)\\alpha}=\\frac{1}{n}.\n$$\n由于 $X_{1}=SU_{1}$，我们得到\n$$\nE[X_{1}\\mid S=s]=s\\,E[U_{1}\\mid S=s]=\\frac{s}{n}.\n$$\n因此，作为 $S$ 的函数，\n$$\nE[X_{1}\\mid S]=\\frac{S}{n},\n$$\n于是\n$$\nT_{1}=E\\!\\left[\\frac{X_{1}}{\\alpha}\\,\\middle|\\,S\\right]=\\frac{1}{\\alpha}\\cdot\\frac{S}{n}=\\frac{S}{n\\alpha}.\n$$", "answer": "$$\\boxed{\\frac{S}{n\\alpha}}$$", "id": "1922421"}, {"introduction": "充分统计量并非总是样本之和。本练习将挑战我们对均匀分布的理解，其参数 $\\theta$ 的充分统计量是样本最大值。我们将从一个基于样本最小值的无偏估计量开始，通过对样本最大值取条件期望来改进它，这个过程不仅展示了Rao-Blackwell定理的普适性，也为处理顺序统计量提供了宝贵的实践经验。[@problem_id:1922455]", "problem": "设 $X_1, \\dots, X_n$ 是一个来自区间 $(0, \\theta)$ 上连续均匀分布的大小为 $n > 1$ 的随机样本，其中 $\\theta > 0$ 是一个未知参数。该分布的概率密度函数为，当 $0  x  \\theta$ 时，$f(x) = \\frac{1}{\\theta}$，否则 $f(x)=0$。\n\n设 $X_{(1)} = \\min(X_1, \\dots, X_n)$ 为样本最小值，$X_{(n)} = \\max(X_1, \\dots, X_n)$ 为样本最大值。\n\n一个针对 $\\theta$ 的初始但次优的无偏估计量由 $T = (n+1)X_{(1)}$ 给出。通过利用样本最大值 $X_{(n)}$ 中包含的信息，可以构造一个新的估计量 $T'$，它对 $\\theta$ 也是无偏的，但具有更小的方差。\n\n求出这个改进的估计量 $T'$ 的表达式。你的答案应该是样本大小 $n$ 和样本最大值 $X_{(n)}$ 的函数。", "solution": "我们旨在计算 $T' = E[T | X_{(n)}] = E[(n+1)X_{(1)} | X_{(n)}]$。根据条件期望的线性性质，这等价于 $(n+1)E[X_{(1)} | X_{(n)}]$。因此，我们的核心任务是求出在给定样本最大值 $X_{(n)}=y_n$ 的条件下，样本最小值 $X_{(1)}$ 的条件期望。\n\n首先，我们需要求出 $X_{(1)}$ 和 $X_{(n)}$ 的联合概率密度函数 (PDF)。对于一个来自 $U(0, \\theta)$ 的大小为 $n$ 的样本，对于 $0  y_1  y_n  \\theta$，其联合 PDF 为：\n$$ f_{X_{(1)}, X_{(n)}}(y_1, y_n) = n(n-1) \\frac{(y_n - y_1)^{n-2}}{\\theta^n} $$\n其次，我们需要 $X_{(n)}$ 的边际 PDF。对于 $0  y_n  \\theta$，其 PDF 为：\n$$ f_{X_{(n)}}(y_n) = n \\frac{y_n^{n-1}}{\\theta^n} $$\n然后，我们可以得到在 $X_{(n)}=y_n$ 条件下 $X_{(1)}$ 的条件 PDF，其定义域为 $0  y_1  y_n$：\n$$ f_{X_{(1)}|X_{(n)}}(y_1 | y_n) = \\frac{f_{X_{(1)}, X_{(n)}}(y_1, y_n)}{f_{X_{(n)}}(y_n)} = \\frac{n(n-1)(y_n - y_1)^{n-2}/\\theta^n}{n y_n^{n-1}/\\theta^n} = \\frac{(n-1)(y_n - y_1)^{n-2}}{y_n^{n-1}} $$\n接下来，我们利用这个条件 PDF 计算条件期望 $E[X_{(1)} | X_{(n)}=y_n]$：\n$$ E[X_{(1)} | X_{(n)}=y_n] = \\int_0^{y_n} y_1 \\cdot f_{X_{(1)}|X_{(n)}}(y_1 | y_n) \\,dy_1 = \\int_0^{y_n} y_1 \\frac{(n-1)(y_n - y_1)^{n-2}}{y_n^{n-1}} \\,dy_1 $$\n为了求解这个积分，我们可以做一个变量代换，令 $u = y_1/y_n$，则 $y_1 = u y_n$ 且 $dy_1 = y_n \\,du$。积分限从 $y_1=0$ 到 $y_1=y_n$ 变为 $u=0$ 到 $u=1$。\n\\begin{align*} E[X_{(1)} | X_{(n)}=y_n] = \\frac{n-1}{y_n^{n-1}} \\int_0^1 (u y_n) (y_n - u y_n)^{n-2} (y_n \\,du) \\\\ = \\frac{n-1}{y_n^{n-1}} \\int_0^1 u y_n \\cdot y_n^{n-2}(1-u)^{n-2} \\cdot y_n \\,du \\\\ = (n-1)y_n \\int_0^1 u(1-u)^{n-2} \\,du \\end{align*}\n这个积分是一个贝塔函数的形式 $B(a,b) = \\int_0^1 t^{a-1}(1-t)^{b-1}dt = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$。在这里，$a=2, b=n-1$。\n$$ \\int_0^1 u(1-u)^{n-2} \\,du = B(2, n-1) = \\frac{\\Gamma(2)\\Gamma(n-1)}{\\Gamma(2+n-1)} = \\frac{1! \\cdot (n-2)!}{n!} = \\frac{1}{n(n-1)} $$\n因此，条件期望为：\n$$ E[X_{(1)} | X_{(n)}=y_n] = (n-1)y_n \\cdot \\frac{1}{n(n-1)} = \\frac{y_n}{n} $$\n将 $y_n$ 替换回随机变量 $X_{(n)}$，我们得到 $E[X_{(1)} | X_{(n)}] = \\frac{X_{(n)}}{n}$。\n最后，我们计算改进后的估计量 $T'$：\n$$ T' = (n+1)E[X_{(1)} | X_{(n)}] = (n+1) \\frac{X_{(n)}}{n} = \\frac{n+1}{n}X_{(n)} $$", "answer": "$$\\boxed{\\frac{n+1}{n}\\,X_{(n)}}$$", "id": "1922455"}]}