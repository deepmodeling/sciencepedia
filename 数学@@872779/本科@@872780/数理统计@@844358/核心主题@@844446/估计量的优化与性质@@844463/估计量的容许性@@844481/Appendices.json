{"hands_on_practices": [{"introduction": "统计学初学者常常有一个误解：无偏估计量总是“好”的估计量。虽然无偏性，即估计量的期望值等于真实参数，是一个理想的属性，但它并不能保证估计量在风险函数（例如均方误差）下的最优性。这个练习 [@problem_id:1894912] 将通过一个具体的反例，直接挑战这一观念，向你展示一个有偏估计量如何能够一致地优于一个无偏估计量，从而引入可容许性的核心思想。", "problem": "考虑从区间 $(0, \\theta)$ 上的均匀概率分布中抽取的单个测量值 $X$，其中参数 $\\theta > 0$ 是未知的。我们希望使用估计量 $\\delta(X) = 2X$ 来估计 $\\theta$。\n\n估计量的性能通过平方误差损失函数来评估，其定义为 $L(\\theta, a) = (a - \\theta)^2$。估计量 $\\delta$ 的风险是其期望损失，由 $R(\\theta, \\delta) = E[(\\delta(X) - \\theta)^2]$ 给出。\n\n如果存在另一个估计量 $\\delta'$，使得对于参数 $\\theta$ 的所有值都有 $R(\\theta, \\delta') \\le R(\\theta, \\delta)$，并且至少对一个值 $\\theta_0$ 有 $R(\\theta_0, \\delta')  R(\\theta_0, \\delta)$，则称估计量 $\\delta$ 是*不可容许的*。如果不存在这样的估计量 $\\delta'$，则称 $\\delta$ 是*可容许的*。\n\n关于估计量 $\\delta(X)=2X$ 的以下陈述中，哪一个是正确的？\n\nA. 该估计量是可容许的，因为它是无偏的。\n\nB. 该估计量是可容许的，因为它的风险是所有估计量中最小的。\n\nC. 该估计量是不可容许的，因为估计量 $\\delta'(X) = X$ 对所有 $\\theta > 0$ 都具有更小的风险。\n\nD. 该估计量是不可容许的，因为估计量 $\\delta'(X) = \\frac{3}{2}X$ 对所有 $\\theta > 0$ 都具有更小的风险。\n\nE. 该估计量是不可容许的，因为它是 $\\theta$ 的一个有偏估计量。", "solution": "问题要求我们判断在平方误差损失函数 $L(\\theta, a) = (a - \\theta)^2$ 下，对于 $U(0, \\theta)$ 分布的参数 $\\theta$，估计量 $\\delta(X) = 2X$ 是否是可容许的。为此，我们需要计算 $\\delta(X)$ 的风险，并看是否能找到另一个具有一致更小风险的估计量 $\\delta'(X)$。\n\n首先，我们来求随机变量 $X \\sim U(0, \\theta)$ 的性质。其概率密度函数 (PDF) 为 $f(x|\\theta) = \\frac{1}{\\theta}$ (当 $0  x  \\theta$ 时)，其他情况下为 $0$。\n我们需要 $X$ 的前两阶矩。\n$X$ 的期望值为：\n$$E[X] = \\int_{0}^{\\theta} x f(x|\\theta) dx = \\int_{0}^{\\theta} x \\left(\\frac{1}{\\theta}\\right) dx = \\frac{1}{\\theta} \\left[\\frac{x^2}{2}\\right]_{0}^{\\theta} = \\frac{1}{\\theta} \\left(\\frac{\\theta^2}{2}\\right) = \\frac{\\theta}{2}$$\n$X^2$ 的期望值为：\n$$E[X^2] = \\int_{0}^{\\theta} x^2 f(x|\\theta) dx = \\int_{0}^{\\theta} x^2 \\left(\\frac{1}{\\theta}\\right) dx = \\frac{1}{\\theta} \\left[\\frac{x^3}{3}\\right]_{0}^{\\theta} = \\frac{1}{\\theta} \\left(\\frac{\\theta^3}{3}\\right) = \\frac{\\theta^2}{3}$$\n\n现在，我们来分析给定的估计量 $\\delta(X) = 2X$。\n首先，我们检查它是否有偏（这与选项E相关）。估计量的偏差为 $Bias(\\delta) = E[\\delta(X)] - \\theta$。\n$$E[\\delta(X)] = E[2X] = 2E[X] = 2\\left(\\frac{\\theta}{2}\\right) = \\theta$$\n由于 $E[\\delta(X)] = \\theta$，偏差为零。该估计量是无偏的。这立即告诉我们选项E是不正确的，因为它的前提是错误的。选项A提出因无偏性而可容许，这是一个我们必须研究的常见误解。\n\n接下来，我们计算 $\\delta(X) = 2X$ 的风险。风险即均方误差 (MSE)，$R(\\theta, \\delta) = E[(\\delta(X) - \\theta)^2]$。\n$$R(\\theta, \\delta) = E[(2X - \\theta)^2] = E[4X^2 - 4\\theta X + \\theta^2]$$\n使用期望的线性性质：\n$$R(\\theta, \\delta) = 4E[X^2] - 4\\theta E[X] + \\theta^2$$\n代入我们计算出的矩：\n$$R(\\theta, \\delta) = 4\\left(\\frac{\\theta^2}{3}\\right) - 4\\theta\\left(\\frac{\\theta}{2}\\right) + \\theta^2 = \\frac{4}{3}\\theta^2 - 2\\theta^2 + \\theta^2 = \\left(\\frac{4}{3} - 1\\right)\\theta^2 = \\frac{1}{3}\\theta^2$$\n因此，估计量 $\\delta(X)=2X$ 的风险是 $R(\\theta, \\delta) = \\frac{\\theta^2}{3}$。\n\n为了检查可容许性，我们检验选项中提出的替代估计量。\n\n我们来检查选项C，它提出了估计量 $\\delta_C(X) = X$。我们来计算其风险。\n$$R(\\theta, \\delta_C) = E[(X - \\theta)^2] = E[X^2 - 2\\theta X + \\theta^2]$$\n$$R(\\theta, \\delta_C) = E[X^2] - 2\\theta E[X] + \\theta^2 = \\frac{\\theta^2}{3} - 2\\theta\\left(\\frac{\\theta}{2}\\right) + \\theta^2 = \\frac{\\theta^2}{3} - \\theta^2 + \\theta^2 = \\frac{1}{3}\\theta^2$$\n$\\delta_C(X)$ 的风险是 $R(\\theta, \\delta_C) = \\frac{\\theta^2}{3}$，这与 $\\delta(X)$ 的风险相等。要使 $\\delta(X)$ 因为 $\\delta_C(X)$ 的存在而成为不可容许的，$\\delta_C(X)$ 的风险需要对所有 $\\theta$ 都小于或等于 $\\delta(X)$ 的风险，并对至少一个 $\\theta$ 严格小于。由于风险完全相同，$\\delta_C(X)$ 并不优于 $\\delta(X)$。因此，选项C是不正确的。\n\n现在，我们来检查选项D，它提出了估计量 $\\delta_D(X) = \\frac{3}{2}X$。我们来计算其风险。\n$$R(\\theta, \\delta_D) = E\\left[\\left(\\frac{3}{2}X - \\theta\\right)^2\\right] = E\\left[\\frac{9}{4}X^2 - 3\\theta X + \\theta^2\\right]$$\n$$R(\\theta, \\delta_D) = \\frac{9}{4}E[X^2] - 3\\theta E[X] + \\theta^2 = \\frac{9}{4}\\left(\\frac{\\theta^2}{3}\\right) - 3\\theta\\left(\\frac{\\theta}{2}\\right) + \\theta^2$$\n$$R(\\theta, \\delta_D) = \\frac{3}{4}\\theta^2 - \\frac{3}{2}\\theta^2 + \\theta^2 = \\left(\\frac{3}{4} - \\frac{6}{4} + \\frac{4}{4}\\right)\\theta^2 = \\frac{1}{4}\\theta^2$$\n$\\delta_D(X)$ 的风险是 $R(\\theta, \\delta_D) = \\frac{1}{4}\\theta^2$。\n\n我们将这个风险与我们原始估计量的风险 $R(\\theta, \\delta) = \\frac{1}{3}\\theta^2$ 进行比较。\n对于任何 $\\theta > 0$，我们有 $\\frac{1}{4}  \\frac{1}{3}$，这意味着 $\\frac{1}{4}\\theta^2  \\frac{1}{3}\\theta^2$。\n所以，对于所有 $\\theta > 0$，都有 $R(\\theta, \\delta_D)  R(\\theta, \\delta)$。\n这意味着估计量 $\\delta_D(X) = \\frac{3}{2}X$ 优于估计量 $\\delta(X) = 2X$。根据可容许性的定义，存在这样一个严格更优的估计量使得 $\\delta(X) = 2X$ 是不可容许的。\n因此，选项D是正确的陈述。\n\n这一发现也使我们能够排除其余的选项。\n- 选项A是错误的：我们已经证明了 $\\delta(X)$ 是无偏的，但它是不可容许的。所以，无偏性并不意味着可容许性。\n- 选项B是错误的：$\\delta(X)$ 不是最小风险估计量，因为 $\\delta_D(X)$ 有更小的风险。\n- 选项E是错误的：如前所示，$\\delta(X)$ 是无偏的。\n\n正确的选项是D。", "answer": "$$\\boxed{D}$$", "id": "1894912"}, {"introduction": "在评估估计量时，我们不仅要关心估计量本身，还必须明确我们如何定义“误差”。平方误差损失函数因其对称性和数学上的便利性而被广泛使用，但这远非唯一的选择。本练习 [@problem_id:1894881] 将介绍一种非对称的Linex损失函数，它对高估和低估施加不同的惩罚，这在许多现实世界问题中更为贴切。通过这个练习，你将发现，当我们改变衡量误差的标准时，一个在平方误差损失下表现良好的标准估计量可能会变得不可容许。", "problem": "考虑来自正态分布的单次观测 $X$，其均值 $\\theta \\in \\mathbb{R}$ 未知，方差已知为 1，即 $X \\sim N(\\theta, 1)$。我们希望估计参数 $\\theta$。估计量 $\\delta(X)$ 的优劣通过 Linex (线性指数) 损失函数来评估，其定义为：\n$$L(\\theta, a) = \\exp(c(a-\\theta)) - c(a-\\theta) - 1$$\n其中 $a$ 是估计值，$c$ 是一个已知的非零实常数。\n\n如果存在另一个估计量 $\\delta'$ 优于 $\\delta$，则称估计量 $\\delta$ 是不可容许的。优于意味着对于所有的 $\\theta$，$\\delta'$ 的风险函数 $R(\\theta, \\delta') = E_{\\theta}[L(\\theta, \\delta'(X))]$ 小于或等于 $\\delta$ 的风险函数 $R(\\theta, \\delta) = E_{\\theta}[L(\\theta, \\delta(X))]$，并且至少对一个 $\\theta$ 值，不等式是严格成立的。\n\n考虑标准估计量 $\\delta_0(X) = X$。现在，我们再定义另外两个可能的估计量：$\\delta_1(X) = X-c$ 和 $\\delta_*(X) = X - \\frac{c}{2}$。\n\n关于 $\\delta_0(X)$ 的可容許性，以下哪个陈述是正确的？\n\nA. 估计量 $\\delta_0(X)$ 是可容许的。\n\nB. 估计量 $\\delta_0(X)$ 是不可容许的，因为它被 $\\delta_1(X)$ 优于，但没被 $\\delta_*(X)$ 优于。\n\nC. 估计量 $\\delta_0(X)$ 是不可容许的，因为它被 $\\delta_*(X)$ 优于，但没被 $\\delta_1(X)$ 优于。\n\nD. 估计量 $\\delta_0(X)$ 是不可容许的，因为它同时被 $\\delta_1(X)$ 和 $\\delta_*(X)$ 优于。\n\nE. 估计量 $\\delta_0(X)$ 是不可容许的，但 $\\delta_1(X)$ 和 $\\delta_*(X)$ 都不是优于它的估计量。", "solution": "设 $X \\sim N(\\theta,1)$，并考虑 Linex 损失 $L(\\theta,a)=\\exp(c(a-\\theta)) - c(a-\\theta) - 1$，其中 $c \\neq 0$。对于形式为 $\\delta_{b}(X)=X-b$ 的平移估计量，记 $Z=X-\\theta \\sim N(0,1)$，因此 $a-\\theta=\\delta_{b}(X)-\\theta=Z-b$。风险为\n$$\nR(\\theta,\\delta_{b})=E_{\\theta}[L(\\theta,\\delta_{b}(X))]=E\\big[\\exp(c(Z-b)) - c(Z-b) - 1\\big].\n$$\n利用期望的线性性质和 $Z \\sim N(0,1)$ 的矩生成函数 $E[\\exp(tZ)]=\\exp(t^{2}/2)$，我们得到\n$$\nE[\\exp(c(Z-b))]=\\exp(-cb)\\,E[\\exp(cZ)]=\\exp\\!\\left(\\frac{c^{2}}{2}-cb\\right),\\quad E[c(Z-b)]=c(E[Z]-b)=-cb,\n$$\n因此\n$$\nR(\\theta,\\delta_{b})=\\exp\\!\\left(\\frac{c^{2}}{2}-cb\\right)+cb-1.\n$$\n该风险不依赖于 $\\theta$。为了找到最佳的平移量 $b$，我们对 $b$ 求导：\n$$\n\\frac{d}{db}R(\\theta,\\delta_{b})=-c\\,\\exp\\!\\left(\\frac{c^{2}}{2}-cb\\right)+c,\\quad \\frac{d^{2}}{db^{2}}R(\\theta,\\delta_{b})=c^{2}\\,\\exp\\!\\left(\\frac{c^{2}}{2}-cb\\right)>0.\n$$\n令一阶导数为零，得到\n$$\n\\exp\\!\\left(\\frac{c^{2}}{2}-cb\\right)=1 \\;\\;\\Longrightarrow\\;\\; \\frac{c^{2}}{2}-cb=0 \\;\\;\\Longrightarrow\\;\\; b=\\frac{c}{2},\n$$\n根据二阶导数大于零，可知这是唯一的极小值点。因此 $\\delta_{*}(X)=X-\\frac{c}{2}$ 在这类估计量中最小化了常数风险，其风险为\n$$\nR(\\theta,\\delta_{*})=\\exp\\!\\left(\\frac{c^{2}}{2}-c\\cdot\\frac{c}{2}\\right)+c\\cdot\\frac{c}{2}-1=\\exp(0)+\\frac{c^{2}}{2}-1=\\frac{c^{2}}{2}.\n$$\n计算所提出的估计量的风险：\n- 对于 $\\delta_{0}(X)=X$ ($b=0$):\n$$\nR(\\theta,\\delta_{0})=\\exp\\!\\left(\\frac{c^{2}}{2}\\right)-1.\n$$\n- 对于 $\\delta_{1}(X)=X-c$ ($b=c$):\n$$\nR(\\theta,\\delta_{1})=\\exp\\!\\left(\\frac{c^{2}}{2}-c^{2}\\right)+c^{2}-1=\\exp\\!\\left(-\\frac{c^{2}}{2}\\right)+c^{2}-1.\n$$\n比较风险：\n1) $\\delta_{*}$ 与 $\\delta_{0}$：\n令 $x=\\frac{c^{2}}{2}>0$。那么\n$$\nR(\\theta,\\delta_{0})-R(\\theta,\\delta_{*})=\\exp(x)-1 - x.\n$$\n由于当 $x>0$ 时有 $\\exp(x) > 1+x$，因此对于所有 $c \\neq 0$ 都有 $R(\\theta,\\delta_{0})>R(\\theta,\\delta_{*})$。这表明 $\\delta_*(X)$ 优于 $\\delta_0(X)$。\n\n2) $\\delta_{1}$ 与 $\\delta_{0}$：\n令 $x=\\frac{c^{2}}{2}>0$。风险之差为：\n$$\nR(\\theta,\\delta_{1})-R(\\theta,\\delta_{0})=\\exp(-x)+2x-1-\\exp(x).\n$$\n定义 $q(x)=\\exp(-x)-\\exp(x)+2x$。则 $q(0)=0$ 且\n$$\nq'(x)=-\\exp(-x)-\\exp(x)+2=2-(\\exp(x)+\\exp(-x)).\n$$\n因为当 $x>0$ 时，$\\exp(x)+\\exp(-x) > 2$，所以对于 $x>0$，$q'(x)  0$。\n由于 $q(0)=0$ 且当 $x>0$ 时 $q(x)$ 严格递减，所以对于 $x>0$ 有 $q(x)  0$。这意味着 $R(\\theta, \\delta_1)  R(\\theta, \\delta_0)$ 对所有 $c \\neq 0$ 成立。这表明 $\\delta_1(X)$ 也优于 $\\delta_0(X)$。\n\n因为估计量 $\\delta_0(X)$ 同时被 $\\delta_1(X)$ 和 $\\delta_*(X)$ 优于，所以它是不可容许的。正确的陈述是D。", "answer": "$$\\boxed{D}$$", "id": "1894881"}, {"introduction": "可容许性的概念有时会引出一些非常深刻且出乎意料的结果。即使对于一个标准的估计量和常见的损失函数，可容许性也可能取决于参数空间的具体结构，这是一个微妙但至关重要的点。这个问题 [@problem_id:1894876] 提供了一个极具启发性的场景：在一个受限的、离散的参数空间中，一个在连续参数空间中可容许的估计量，竟然变得不可容许了。解决这个问题将加深你对统计决策理论严谨性和深度的理解。", "problem": "一位物理学家正在研究一个放射源。根据一个推测性的量子模型，该源的有效衰变率参数 $\\lambda$ 是量子化的，这意味着在其自然单位中，它只能取正整数值。因此，$\\lambda$ 的参数空间是正整数集合 $\\Theta = \\{1, 2, 3, \\ldots\\}$。已知在单位时间间隔内观测到的衰变次数 $X$ 服从均值为 $\\lambda$ 的泊松分布，即 $X \\sim \\text{Poisson}(\\lambda)$，其概率质量函数为 $P(X=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$，其中 $k=0, 1, 2, \\ldots$。\n\n为了估计未知的 $\\lambda$ 值，标准的选择是使用观测到的计数值本身作为估计量，记作 $\\delta_0(X) = X$。任何估计量 $\\delta$ 的性能都通过平方误差损失函数 $L(\\lambda, \\delta) = (\\delta - \\lambda)^2$ 及其对应的风险函数（即均方误差 $R(\\lambda, \\delta) = E_{\\lambda}[(\\delta(X) - \\lambda)^2]$）来评估。\n\n如果存在另一个估计量 $\\delta_1$ 优于估计量 $\\delta_0$，则称 $\\delta_0$ 是不可容许的。优于意味着对于所有的 $\\lambda \\in \\Theta$ 都有 $R(\\lambda, \\delta_1) \\le R(\\lambda, \\delta_0)$，并且至少存在一个值 $\\lambda_0 \\in \\Theta$ 使得不等式严格成立：$R(\\lambda_0, \\delta_1)  R(\\lambda_0, \\delta_0)$。\n\n一位同事建议研究一类修正的估计量 $\\delta_c(X)$，其定义如下：\n$$\n\\delta_c(X) = \\begin{cases} c,   \\text{if } X=0 \\\\ X,   \\text{if } X \\ge 1 \\end{cases}\n$$\n其中 $c$ 是一个实常数。请注意，标准估计量 $\\delta_0(X)$ 是此类中 $c=0$ 的一个成员。\n\n通过分析形式为 $\\delta_c(X)$ 的估计量是否能优于 $\\delta_0(X)$，判断下列哪个陈述是正确的。\n\nA. 估计量 $\\delta_0(X)=X$ 是可容许的，因为它是一个无偏估计量，其风险无法被一致地改进。\n\nB. 估计量 $\\delta_0(X)=X$ 是不可容许的。当 $c=1$ 时，估计量 $\\delta_c(X)$ 优于 $\\delta_0(X)$。\n\nC. 估计量 $\\delta_0(X)=X$ 是不可容许的。当 $c=0$ 时，估计量 $\\delta_c(X)$ 优于 $\\delta_0(X)$。\n\nD. 估计量 $\\delta_0(X)=X$ 是不可容许的。当 $c=-1$ 时，估计量 $\\delta_c(X)$ 优于 $\\delta_0(X)$。\n\nE. 对于所有 $c \\ne 0$，形式为 $\\delta_c(X)$ 的估计量的风险函数，对于至少一个 $\\lambda$ 值，都严格大于 $\\delta_0(X)$ 的风险，因此它们都不能优于 $\\delta_0(X)$。", "solution": "为了确定哪个陈述是正确的，我们需要通过比较标准估计量 $\\delta_0(X) = X$ 的风险函数与所提出的估计量 $\\delta_c(X)$ 的风险函数，来分析其可容许性。\n\n首先，我们计算标准估计量 $\\delta_0(X) = X$ 的风险。风险是均方误差：\n$R(\\lambda, \\delta_0) = E_{\\lambda}[ (X - \\lambda)^2 ]$\n由于 $E_{\\lambda}[X] = \\lambda$，这恰好是泊松分布的方差。\n$R(\\lambda, \\delta_0) = \\text{Var}_{\\lambda}(X) = \\lambda$。\n\n接下来，我们计算修正估计量 $\\delta_c(X)$ 的风险。\n$R(\\lambda, \\delta_c) = E_{\\lambda}[ (\\delta_c(X) - \\lambda)^2 ] = \\sum_{k=0}^{\\infty} (\\delta_c(k) - \\lambda)^2 P(X=k)$\n我们可以根据 $\\delta_c(X)$ 的定义将求和式拆分：\n$R(\\lambda, \\delta_c) = (\\delta_c(0) - \\lambda)^2 P(X=0) + \\sum_{k=1}^{\\infty} (\\delta_c(k) - \\lambda)^2 P(X=k)$\n代入 $\\delta_c(k)$ 的定义和泊松概率质量函数 $P(X=k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$：\n$R(\\lambda, \\delta_c) = (c - \\lambda)^2 P(X=0) + \\sum_{k=1}^{\\infty} (k - \\lambda)^2 P(X=k)$\n\n为了便于比较，我们用类似的求和形式表示 $\\delta_0(X)$ 的风险：\n$R(\\lambda, \\delta_0) = \\sum_{k=0}^{\\infty} (k - \\lambda)^2 P(X=k) = (0 - \\lambda)^2 P(X=0) + \\sum_{k=1}^{\\infty} (k - \\lambda)^2 P(X=k)$\n$R(\\lambda, \\delta_0) = \\lambda^2 P(X=0) + \\sum_{k=1}^{\\infty} (k - \\lambda)^2 P(X=k)$\n\n现在，我们可以求出风险函数之差，$\\Delta R(\\lambda) = R(\\lambda, \\delta_c) - R(\\lambda, \\delta_0)$：\n$\\Delta R(\\lambda) = \\left[ (c - \\lambda)^2 P(X=0) + \\sum_{k=1}^{\\infty} (k - \\lambda)^2 P(X=k) \\right] - \\left[ \\lambda^2 P(X=0) + \\sum_{k=1}^{\\infty} (k - \\lambda)^2 P(X=k) \\right]$\n求和项相互抵消，剩下：\n$\\Delta R(\\lambda) = ((c - \\lambda)^2 - \\lambda^2) P(X=0)$\n代入 $P(X=0) = e^{-\\lambda}$：\n$\\Delta R(\\lambda) = (c^2 - 2c\\lambda + \\lambda^2 - \\lambda^2) e^{-\\lambda} = (c^2 - 2c\\lambda) e^{-\\lambda}$\n\n要使 $\\delta_c(X)$ 优于 $\\delta_0(X)$，必须满足两个条件：\n1. 对所有 $\\lambda \\in \\Theta = \\{1, 2, 3, \\ldots\\}$，都有 $\\Delta R(\\lambda) \\le 0$。\n2. 至少存在一个 $\\lambda_0 \\in \\Theta$，使得 $\\Delta R(\\lambda_0)  0$。\n\n因为对所有 $\\lambda$，都有 $e^{-\\lambda} > 0$，所以第一个条件简化为：\n$c^2 - 2c\\lambda \\le 0 \\implies c(c - 2\\lambda) \\le 0$\n这个不等式必须对所有 $\\lambda \\in \\{1, 2, 3, \\ldots\\}$ 成立。\n\n我们来逐一检查选项：\n\n- **陈述 C (c=0)：**\n如果 $c=0$，则 $c(c - 2\\lambda) = 0$。所以对所有 $\\lambda$，都有 $\\Delta R(\\lambda) = 0$。其风险与 $\\delta_0(X)$ 的风险完全相同。因此，$\\delta_0(X)$ 不优于其自身。此陈述不正确。\n\n- **陈述 D (c=-1)：**\n如果 $c=-1$，条件是 $(-1)(-1 - 2\\lambda) \\le 0$，简化为 $1 + 2\\lambda \\le 0$。由于参数空间是 $\\lambda \\ge 1$，所以 $1 + 2\\lambda$ 总是正数（例如，当 $\\lambda=1$ 时，其值为 3）。该不等式永远不会满足。实际上，对所有 $\\lambda \\in \\Theta$，都有 $\\Delta R(\\lambda) > 0$，这意味着 $\\delta_{-1}(X)$ 严格劣于 $\\delta_0(X)$。此陈述不正确。\n\n- **陈述 B (c=1)：**\n如果 $c=1$，条件是 $1(1 - 2\\lambda) \\le 0$。由于 $\\lambda \\in \\{1, 2, 3, \\ldots\\}$，$\\lambda$ 的最小值为 1。\n当 $\\lambda=1$ 时，$1 - 2(1) = -1 \\le 0$。\n当 $\\lambda \\ge 1$ 时，我们有 $2\\lambda \\ge 2$，所以 $1-2\\lambda \\le -1  0$。\n条件 $c(c - 2\\lambda) \\le 0$ 对所有 $\\lambda \\in \\Theta$ 都满足。\n此外，该不等式对所有 $\\lambda \\in \\Theta$ 都是严格的。这意味着对所有 $\\lambda \\in \\{1, 2, 3, \\ldots\\}$，都有 $\\Delta R(\\lambda) = (1 - 2\\lambda)e^{-\\lambda}  0$。\n所以，对于参数空间中的所有 $\\lambda$ 值，都有 $R(\\lambda, \\delta_1)  R(\\lambda, \\delta_0)$。这是一个严格优于的例子。因此，$\\delta_1(X)$ 优于 $\\delta_0(X)$，这证明了 $\\delta_0(X)=X$ 是一个不可容许的估计量。陈述 B 是正确的。\n\n- **陈述 A：**\n这个陈述是错误的，因为我们找到了一个估计量 $\\delta_1(X)$，它一致地改进了 $\\delta_0(X)$。$\\delta_0(X)$ 是无偏的这一事实不足以保证其可容许性，尤其是在这个特殊的参数空间下。\n\n- **陈述 E：**\n这个陈述是错误的，因为我们发现当 $c=1$ 时，风险是一致地更小。\n\n因此，唯一正确的陈述是 B。", "answer": "$$\\boxed{B}$$", "id": "1894876"}]}