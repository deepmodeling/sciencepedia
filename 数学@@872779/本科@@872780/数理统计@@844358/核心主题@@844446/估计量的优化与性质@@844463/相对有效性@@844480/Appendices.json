{"hands_on_practices": [{"introduction": "该问题为比较均匀分布参数的两种不同类型估计量提供了一个具体场景。虽然样本均值是一种普遍常用的估计量，但其性能并非总是最优。本练习将引导你基于样本最大值构造一个无偏估计量，并将其效率与基于样本均值的估计量进行比较，从而揭示估计量的选择应如何适应数据的内在分布特性。[@problem_id:1951462]", "problem": "一个制造商正在测试一种新型固态电池。电池的寿命，用随机变量 $X$ 表示，假设服从区间 $[0, \\theta]$ 上的均匀分布，其中 $\\theta$ 是未知的最大可能寿命。为了估计 $\\theta$，对 $n$ 个电池的随机样本 $X_1, X_2, \\dots, X_n$ 进行测试，直到它们失效为止。\n\n提出了两种不同的 $\\theta$ 估计量：\n1. 第一个估计量 $T_1$ 定义为样本均值的两倍：$T_1 = 2\\bar{X}$，其中 $\\bar{X} = \\frac{1}{n}\\sum_{i=1}^{n} X_i$。\n2. 第二个估计量 $T_2$ 是通过对样本最大值 $X_{(n)} = \\max(X_1, X_2, \\dots, X_n)$ 进行缩放构造的，使得 $T_2$ 是 $\\theta$ 的一个无偏估计量。\n\n计算 $T_1$ 相对于 $T_2$ 的相对效率。将你的答案表示为样本量 $n$ 的函数。", "solution": "设 $X_{1},\\dots,X_{n}$ 是来自 $\\mathrm{Uniform}(0,\\theta)$ 分布的独立同分布样本。那么单个观测值的均值和方差分别为\n$$\n\\mathbb{E}[X_{i}]=\\frac{\\theta}{2},\\qquad \\mathrm{Var}(X_{i})=\\frac{\\theta^{2}}{12}.\n$$\n对于样本均值 $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$，根据期望的线性性和独立性，\n$$\n\\mathbb{E}[\\bar{X}]=\\frac{\\theta}{2},\\qquad \\mathrm{Var}(\\bar{X})=\\frac{1}{n}\\mathrm{Var}(X_{i})=\\frac{\\theta^{2}}{12n}.\n$$\n第一个估计量是 $T_{1}=2\\bar{X}$，所以\n$$\n\\mathbb{E}[T_{1}]=2\\,\\mathbb{E}[\\bar{X}]=\\theta,\\qquad \\mathrm{Var}(T_{1})=4\\,\\mathrm{Var}(\\bar{X})=\\frac{\\theta^{2}}{3n}.\n$$\n\n令 $X_{(n)}=\\max(X_{1},\\dots,X_{n})$ 表示样本最大值。对于 $X_{i}\\sim \\mathrm{Uniform}(0,\\theta)$，缩放后的最大值 $X_{(n)}/\\theta$ 服从 $\\mathrm{Beta}(n,1)$ 分布。因此\n$$\n\\mathbb{E}[X_{(n)}]=\\theta\\,\\frac{n}{n+1},\\qquad \\mathrm{Var}\\!\\left(X_{(n)}\\right)=\\theta^{2}\\,\\frac{n}{(n+1)^{2}(n+2)}.\n$$\n为了使 $T_{2}$ 无偏，定义 $T_{2}=c\\,X_{(n)}$，并选择 $c$ 使得 $\\mathbb{E}[T_{2}]=\\theta$。使用 $\\mathbb{E}[X_{(n)}]=\\theta\\,\\frac{n}{n+1}$，\n$$\nc\\,\\theta\\,\\frac{n}{n+1}=\\theta\\;\\;\\Rightarrow\\;\\; c=\\frac{n+1}{n},\n$$\n所以\n$$\nT_{2}=\\frac{n+1}{n}\\,X_{(n)},\\qquad \\mathrm{Var}(T_{2})=\\left(\\frac{n+1}{n}\\right)^{2}\\mathrm{Var}\\!\\left(X_{(n)}\\right)=\\left(\\frac{n+1}{n}\\right)^{2}\\theta^{2}\\frac{n}{(n+1)^{2}(n+2)}=\\frac{\\theta^{2}}{n(n+2)}.\n$$\n\n对于两个无偏估计量， $T_{1}$ 相对于 $T_{2}$ 的相对效率定义为\n$$\n\\mathrm{RE}(T_{1}\\text{ w.r.t. }T_{2})=\\frac{\\mathrm{Var}(T_{2})}{\\mathrm{Var}(T_{1})}.\n$$\n代入上面推导出的方差，得到\n$$\n\\mathrm{RE}(T_{1}\\text{ w.r.t. }T_{2})=\\frac{\\theta^{2}/\\bigl(n(n+2)\\bigr)}{\\theta^{2}/(3n)}=\\frac{3}{n+2}.\n$$\n这就将相对效率表示为 $n$ 的函数。", "answer": "$$\\boxed{\\frac{3}{n+2}}$$", "id": "1951462"}, {"introduction": "在实践中，我们常常可以接触到多个测量系统或方法，每个都能提供一个有效但非完美的估计。与其只选择其一，我们不如将它们组合起来以获得更精确的结果。这个问题解决了一个根本性的问题：如何最优地组合两个相关的无偏估计量，以最小化最终合成估计量的方差。解决这个问题将让你掌握一种从工程学到元分析等领域都在使用的强大技术。[@problem_id:1951437]", "problem": "一位材料科学家正在开发一类新型半导体晶圆，需要精确估计其平均杂质浓度 $\\theta$。现有两种不同的测量系统可用。系统 A 产生 $\\theta$ 的一个无偏估计 $T_1$，系统 B 产生 $\\theta$ 的另一个无偏估计 $T_2$。根据历史数据，已知这些估计量的方差分别为 $\\text{Var}(T_1) = \\sigma_1^2$ 和 $\\text{Var}(T_2) = \\sigma_2^2$。由于影响两个系统的共同环境因素，这两个估计不是独立的，它们的相关系数为 $\\text{Corr}(T_1, T_2) = \\rho$，其中 $|\\rho|  1$。\n\n为了改进估计，提出了一个组合线性估计量：$T_C = w T_1 + (1-w) T_2$，其中 $w$ 是一个实值权重。\n\n您的任务是找到这个组合估计量的最优配置。确定使 $T_C$ 的方差最小化的最优权重 $w_{opt}$ 的表达式。然后，求出这个最优组合估计量 $T_{C,opt}$ 相对于估计量 $T_1$ 的相对效率的表达式。相对效率定义为比率 $\\text{Eff}(T_{C,opt}, T_1) = \\frac{\\text{Var}(T_1)}{\\text{Var}(T_{C,opt})}$。\n\n将您的最终答案表示为一个行矩阵，其中包含两个元素：第一个元素为 $w_{opt}$ 的表达式，第二个元素为相对效率的表达式。", "solution": "组合估计量为 $T_{C}=w T_{1}+(1-w) T_{2}$。由于 $T_{1}$ 和 $T_{2}$ 是 $\\theta$ 的无偏估计，且权重之和为 1，因此 $T_{C}$ 是无偏的：$\\mathbb{E}[T_{C}]=w \\theta+(1-w)\\theta=\\theta$。\n\n$T_{C}$ 的方差使用了 $\\text{Cov}(T_{1},T_{2})=\\rho \\sigma_{1}\\sigma_{2}$：\n$$\n\\text{Var}(T_{C})=\\text{Var}\\big(w T_{1}+(1-w) T_{2}\\big)\n=w^{2}\\sigma_{1}^{2}+(1-w)^{2}\\sigma_{2}^{2}+2 w(1-w)\\rho \\sigma_{1}\\sigma_{2}.\n$$\n定义 $V(w)=w^{2}\\sigma_{1}^{2}+(1-w)^{2}\\sigma_{2}^{2}+2 w(1-w)\\rho \\sigma_{1}\\sigma_{2}$。对其求导并令其为零：\n$$\n\\frac{dV}{dw}=2 w \\sigma_{1}^{2}-2(1-w)\\sigma_{2}^{2}+2(1-2w)\\rho \\sigma_{1}\\sigma_{2}=0.\n$$\n化简得\n$$\nw\\big(\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}\\big)+\\big(\\rho \\sigma_{1}\\sigma_{2}-\\sigma_{2}^{2}\\big)=0,\n$$\n因此最优权重为\n$$\nw_{\\text{opt}}=\\frac{\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}.\n$$\n二阶导数为\n$$\n\\frac{d^{2}V}{dw^{2}}=2\\big(\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}\\big)=2\\,\\text{Var}(T_{1}-T_{2})0,\n$$\n由于 $|\\rho|1$，这确保了所求的是一个最小值。\n\n为了求得最小方差，将 $V(w)$ 写成 $V(w)=a w^{2}+2 b w+c$ 的形式，其中\n$$\na=\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2},\\quad b=-(\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}),\\quad c=\\sigma_{2}^{2}.\n$$\n则\n$$\n\\text{Var}(T_{C,\\text{opt}})=V(w_{\\text{opt}})=c-\\frac{b^{2}}{a}\n=\\frac{\\sigma_{1}^{2}\\sigma_{2}^{2}(1-\\rho^{2})}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}.\n$$\n$T_{C,\\text{opt}}$ 相对于 $T_{1}$ 的相对效率为\n$$\n\\text{Eff}(T_{C,\\text{opt}},T_{1})=\\frac{\\text{Var}(T_{1})}{\\text{Var}(T_{C,\\text{opt}})}\n=\\frac{\\sigma_{1}^{2}}{\\dfrac{\\sigma_{1}^{2}\\sigma_{2}^{2}(1-\\rho^{2})}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}}\n=\\frac{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{2}^{2}(1-\\rho^{2})}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\\dfrac{\\sigma_{2}^{2}-\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}  \\dfrac{\\sigma_{1}^{2}+\\sigma_{2}^{2}-2\\rho \\sigma_{1}\\sigma_{2}}{\\sigma_{2}^{2}(1-\\rho^{2})}\\end{pmatrix}}$$", "id": "1951437"}, {"introduction": "本练习将我们的讨论提升到渐近领域，将相对效率与费雪信息 (Fisher information) 这一基本概念联系起来。在许多现实世界的建模情境中，我们必须同时估计多个参数，其中一些是主要关注的，而另一些则是“讨厌”参数。该问题以 Gumbel 分布为案例，精确量化了当尺度参数未知时，对位置参数的估计效率会损失多少。这展示了“未知带来的代价”以及渐近理论在评估估计量性能方面的威力。[@problem_id:1951476]", "problem": "在统计建模中，估计量的效率会受到讨厌参数存在的显著影响。考虑一个服从 Gumbel 分布的随机变量 $Y$，Gumbel 分布是一个非对称的位置-尺度分布族。其概率密度函数由一个位置参数 $\\mu$ 和一个正的尺度参数 $\\sigma$ 参数化。\n\n对于单个观测值 $Y$，参数向量 $\\boldsymbol{\\theta} = (\\mu, \\sigma)^T$ 的费雪信息矩阵 (FIM) 由下式给出\n$$\nI(\\mu, \\sigma) = \\frac{1}{\\sigma^2}\n\\begin{pmatrix}\n1  1-\\gamma \\\\\n1-\\gamma  \\frac{\\pi^2}{6} + (1-\\gamma)^2\n\\end{pmatrix}\n$$\n其中 $\\gamma$ 是欧拉-马斯刻若尼常数 ($\\gamma \\approx 0.5772$)。由于 Gumbel 分布的非对称性，非对角线项不为零。\n\n我们感兴趣的是估计位置参数 $\\mu$。基于 $n$ 个独立同分布的观测值 $Y_1, \\dots, Y_n$ 的大样本，比较以下两种情况：\n1.  **尺度已知：** 尺度参数 $\\sigma$ 已知为某个值 $\\sigma_0$，我们只需要估计 $\\mu$。\n2.  **尺度未知：** $\\mu$ 和 $\\sigma$ 均为未知，必须同时进行估计。\n\n估计量的性能由其渐近方差来衡量。估计量 $\\hat{\\theta}_A$ 相对于另一个估计量 $\\hat{\\theta}_B$ 的渐近相对效率 (ARE) 定义为它们渐近方差的比值，即 $\\text{ARE}(\\hat{\\theta}_A, \\hat{\\theta}_B) = \\frac{\\text{Asymptotic Var}(\\hat{\\theta}_B)}{\\text{Asymptotic Var}(\\hat{\\theta}_A)}$。\n\n计算在“尺度未知”情况下 $\\mu$ 的最大似然估计量 (MLE) 相对于在“尺度已知”情况下 $\\mu$ 的 MLE 的渐近相对效率 (ARE)。将您的答案表示为以 $\\pi$ 和 $\\gamma$ 表示的闭式解析表达式。", "solution": "对于单个观测值，$\\boldsymbol{\\theta} = (\\mu,\\sigma)^{T}$ 的费雪信息矩阵 (FIM) 为\n$$\nI_{1}(\\mu,\\sigma) = \\frac{1}{\\sigma^{2}}\n\\begin{pmatrix}\n1  1-\\gamma \\\\\n1-\\gamma  \\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}\n\\end{pmatrix},\n$$\n对于 $n$ 个独立同分布的观测值，该矩阵为 $I_{n}(\\mu,\\sigma) = n I_{1}(\\mu,\\sigma)$。\n\nMLE 的渐近正态性意味着，对于大的 $n$，联合 MLE 的渐近协方差矩阵为 $(I_{n})^{-1} = \\frac{1}{n} I_{1}^{-1}$，因此 $\\hat{\\mu}$ 的渐近方差等于 $\\frac{1}{n} I_{1}^{-1}$ 的 (1,1) 元。\n\n尺度 $\\sigma$ 已知：\n当 $\\sigma$ 已知时，关于 $\\mu$ 的相关费雪信息是标量 $I_{1,\\mu\\mu} = \\sigma^{-2}$。因此，对于 $n$ 个观测值，MLE $\\hat{\\mu}$ 的渐近方差为\n$$\n\\operatorname{Avar}_{\\text{known}}(\\hat{\\mu}) = \\frac{1}{n I_{1,\\mu\\mu}} = \\frac{\\sigma^{2}}{n}.\n$$\n\n尺度 $\\sigma$ 未知：\n当 $\\mu$ 和 $\\sigma$ 均为未知时，将每个观测值的 FIM 写为\n$$\nI_{1} = \\frac{1}{\\sigma^{2}} M,\\quad M =\n\\begin{pmatrix}\n1  a \\\\\na  b\n\\end{pmatrix},\\quad a = 1-\\gamma,\\quad b = \\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}.\n$$\n那么 $I_{1}^{-1} = \\sigma^{2} M^{-1}$。对于一个 $2\\times 2$ 矩阵，$M^{-1} = \\frac{1}{\\det(M)}\n\\begin{pmatrix}\nb  -a \\\\\n-a  1\n\\end{pmatrix}$，所以 (1,1) 元是 $(M^{-1})_{11} = b/\\det(M)$。行列式为\n$$\n\\det(M) = 1\\cdot b - a^{2} = \\left(\\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}\\right) - (1-\\gamma)^{2} = \\frac{\\pi^{2}}{6}.\n$$\n因此，\n$$\n(I_{1}^{-1})_{11} = \\sigma^{2} \\frac{b}{\\det(M)} = \\sigma^{2} \\frac{\\frac{\\pi^{2}}{6} + (1-\\gamma)^{2}}{\\frac{\\pi^{2}}{6}}\n= \\sigma^{2}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right).\n$$\n从而，对于 $n$ 个观测值，\n$$\n\\operatorname{Avar}_{\\text{unknown}}(\\hat{\\mu}) = \\frac{1}{n} (I_{1}^{-1})_{11}\n= \\frac{\\sigma^{2}}{n}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right).\n$$\n\n渐近相对效率：\n根据定义，对于估计量 A（尺度未知）相对于估计量 B（尺度已知），\n$$\n\\text{ARE}(\\hat{\\mu}_{\\text{unknown}}, \\hat{\\mu}_{\\text{known}}) = \\frac{\\operatorname{Avar}_{\\text{known}}(\\hat{\\mu})}{\\operatorname{Avar}_{\\text{unknown}}(\\hat{\\mu})}\n= \\frac{\\sigma^{2}/n}{\\frac{\\sigma^{2}}{n}\\left(1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}\\right)}\n= \\frac{1}{1 + \\frac{6}{\\pi^{2}}(1-\\gamma)^{2}}\n= \\frac{\\pi^{2}}{\\pi^{2} + 6(1-\\gamma)^{2}}.\n$$\n这就给出了用 $\\pi$ 和 $\\gamma$ 表示的闭式表达式。", "answer": "$$\\boxed{\\frac{\\pi^{2}}{\\pi^{2} + 6\\left(1-\\gamma\\right)^{2}}}$$", "id": "1951476"}]}