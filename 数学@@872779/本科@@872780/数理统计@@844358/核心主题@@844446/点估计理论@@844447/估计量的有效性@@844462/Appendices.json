{"hands_on_practices": [{"introduction": "在评估估计量的优劣时，克拉默-罗下界（Cramér-Rao Lower Bound, CRLB）提供了一个重要的理论基准。它为任何无偏估计量的方差设定了一个无法超越的下限。一个估计量的效率，正是衡量其方差在多大程度上接近这个理想下限的指标。这个练习将带你亲手计算指数分布中参数 $\\lambda$ 的CRLB，并评估一个给定的无偏估计量是否达到了这个理论最优值 [@problem_id:1914827]。", "problem": "某种电子元件的寿命服从指数分布，其概率密度函数 (PDF) 为 $f(x; \\lambda) = \\lambda \\exp(-\\lambda x)$，$x  0$。其中 $\\lambda  0$ 是恒定的失效率。对一个由 $n$ 个此类元件组成的随机样本 $X_1, X_2, \\dots, X_n$ 进行测试，并记录它们的寿命。\n\n一位工程师提出了失效率 $\\lambda$ 的如下估计量：\n$$\n\\hat{\\lambda} = \\frac{n-1}{\\sum_{i=1}^n X_i}\n$$\n已知当样本量 $n  1$ 时，此估计量是 $\\lambda$ 的无偏估计量。\n\n假设样本量 $n  2$，计算此估计量 $\\hat{\\lambda}$ 的效率。效率定义为 $\\lambda$ 的无偏估计量的克拉默-拉奥下界 (CRLB) 与估计量 $\\hat{\\lambda}$ 的实际方差之比。将你的最终答案表示为 $n$ 的函数。", "solution": "首先，我们计算估计量 $\\hat{\\lambda} = \\frac{n-1}{S}$ 的方差，其中 $S = \\sum_{i=1}^n X_i$。由于 $X_i \\sim \\text{Exp}(\\lambda)$（其中 $\\lambda$ 是率参数），$S$ 服从形状参数为 $n$、率参数为 $\\lambda$ 的伽马分布，记为 $S \\sim \\text{Gamma}(n, \\lambda)$。\n估计量的方差为：\n$$ \\text{Var}(\\hat{\\lambda}) = \\text{Var}\\left(\\frac{n-1}{S}\\right) = (n-1)^2 \\text{Var}\\left(\\frac{1}{S}\\right) = (n-1)^2 \\left( E\\left[\\frac{1}{S^2}\\right] - \\left(E\\left[\\frac{1}{S}\\right]\\right)^2 \\right) $$\n我们需要计算 $S$ 的负矩。对于 $Y \\sim \\text{Gamma}(\\alpha, \\beta)$（$\\beta$ 为率参数），有 $E[Y^k] = \\frac{\\Gamma(\\alpha+k)}{\\Gamma(\\alpha)\\beta^k}$（要求 $\\alpha+k > 0$）。\n对于 $S \\sim \\text{Gamma}(n, \\lambda)$：\n当 $k=-1$ (要求 $n>1$)：\n$$ E\\left[\\frac{1}{S}\\right] = \\frac{\\Gamma(n-1)}{\\Gamma(n)\\lambda^{-1}} = \\frac{\\lambda\\Gamma(n-1)}{(n-1)\\Gamma(n-1)} = \\frac{\\lambda}{n-1} $$\n当 $k=-2$ (要求 $n>2$)：\n$$ E\\left[\\frac{1}{S^2}\\right] = \\frac{\\Gamma(n-2)}{\\Gamma(n)\\lambda^{-2}} = \\frac{\\lambda^2\\Gamma(n-2)}{(n-1)(n-2)\\Gamma(n-2)} = \\frac{\\lambda^2}{(n-1)(n-2)} $$\n将矩代入方差公式：\n$$ \\text{Var}(\\hat{\\lambda}) = (n-1)^2 \\left( \\frac{\\lambda^2}{(n-1)(n-2)} - \\left(\\frac{\\lambda}{n-1}\\right)^2 \\right) = (n-1)^2 \\left( \\frac{\\lambda^2}{(n-1)(n-2)} - \\frac{\\lambda^2}{(n-1)^2} \\right) $$\n$$ = \\lambda^2 (n-1)^2 \\left( \\frac{(n-1) - (n-2)}{(n-1)^2(n-2)} \\right) = \\frac{\\lambda^2}{n-2} $$\n接下来，计算克拉默-拉奥下界 (CRLB)。单个观测的对数似然函数为 $\\ln f(x; \\lambda) = \\ln \\lambda - \\lambda x$。其关于 $\\lambda$ 的二阶导数为 $\\frac{\\partial^2}{\\partial \\lambda^2} \\ln f(x; \\lambda) = -\\frac{1}{\\lambda^2}$。\n单个观测的费雪信息量为 $I(\\lambda) = -E\\left[-\\frac{1}{\\lambda^2}\\right] = \\frac{1}{\\lambda^2}$。\n对于 $n$ 个独立样本，总费雪信息量为 $I_n(\\lambda) = n I(\\lambda) = \\frac{n}{\\lambda^2}$。\nCRLB 为：\n$$ \\text{CRLB} = \\frac{1}{I_n(\\lambda)} = \\frac{\\lambda^2}{n} $$\n最后，效率为 CRLB 与估计量方差之比：\n$$ \\text{效率} = \\frac{\\text{CRLB}}{\\text{Var}(\\hat{\\lambda})} = \\frac{\\lambda^2/n}{\\lambda^2/(n-2)} = \\frac{n-2}{n} $$", "answer": "$$\\boxed{\\frac{n-2}{n}}$$", "id": "1914827"}, {"introduction": "无偏性虽然是估计量的一个理想属性，但并非评估其性能的唯一标准。在某些情况下，一个有偏估计量可能因为其方差更小，而拥有更低的总误差。这个练习将引导你使用均方误差（Mean Squared Error, MSE）这一更普适的度量，来比较一个有偏的最大似然估计量和一个无偏估计量，从而揭示在估计量选择中至关重要的“偏差-方差权衡”思想 [@problem_id:1914869]。", "problem": "设 $X_1, X_2, \\dots, X_n$ 是从区间 $[0, \\theta]$ 上的连续均匀分布中抽取的一个随机样本，其中 $\\theta  0$ 是一个未知参数。\n$\\theta$ 的最大似然估计量 (MLE) 为 $\\hat{\\theta}_{MLE} = X_{(n)}$，其中 $X_{(n)}$ 是样本中的最大值，即 $X_{(n)} = \\max\\{X_1, X_2, \\dots, X_n\\}$。\n已知该估计量是有偏的。$\\theta$ 的一个相应的无偏估计量为 $\\hat{\\theta}_{U} = \\frac{n+1}{n}X_{(n)}$。\n\n为了比较这两个估计量的性能，我们可以使用均方误差 (MSE)，对于一个通用估计量 $\\hat{\\theta}$，其定义为 $\\text{MSE}(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2]$。\n\n计算有偏估计量的 MSE 与无偏估计量的 MSE 之比，即 $\\frac{\\text{MSE}(\\hat{\\theta}_{MLE})}{\\text{MSE}(\\hat{\\theta}_{U})}$。将答案表示为样本大小 $n$ 的函数。", "solution": "首先，我们推导样本最大值 $X_{(n)}$ 的概率分布及其矩。对于来自 $U[0, \\theta]$ 的独立同分布样本，$X_{(n)}$ 的概率密度函数 (PDF) 为 $f_{X_{(n)}}(x) = \\frac{n}{\\theta^n}x^{n-1}$，其中 $0  x  \\theta$。\n计算 $X_{(n)}$ 的前两阶矩：\n$$ E[X_{(n)}] = \\int_0^\\theta x \\cdot \\frac{n}{\\theta^n}x^{n-1} dx = \\frac{n}{\\theta^n} \\left[ \\frac{x^{n+1}}{n+1} \\right]_0^\\theta = \\frac{n}{n+1}\\theta $$\n$$ E[X_{(n)}^2] = \\int_0^\\theta x^2 \\cdot \\frac{n}{\\theta^n}x^{n-1} dx = \\frac{n}{\\theta^n} \\left[ \\frac{x^{n+2}}{n+2} \\right]_0^\\theta = \\frac{n}{n+2}\\theta^2 $$\n现在，我们分别计算两个估计量的均方误差 (MSE)。\n            \n1.  **对于有偏的最大似然估计量 $\\hat{\\theta}_{MLE} = X_{(n)}$：**\n    *   偏差: $\\text{Bias}(\\hat{\\theta}_{MLE}) = E[X_{(n)}] - \\theta = \\frac{n}{n+1}\\theta - \\theta = -\\frac{\\theta}{n+1}$\n    *   方差: $\\text{Var}(X_{(n)}) = E[X_{(n)}^2] - (E[X_{(n)}])^2 = \\frac{n}{n+2}\\theta^2 - \\left(\\frac{n\\theta}{n+1}\\right)^2 = \\theta^2 \\left( \\frac{n}{n+2} - \\frac{n^2}{(n+1)^2} \\right) = \\theta^2 \\frac{n(n+1)^2 - n^2(n+2)}{(n+2)(n+1)^2} = \\frac{n\\theta^2}{(n+2)(n+1)^2}$\n    *   均方误差: $\\text{MSE}(\\hat{\\theta}_{MLE}) = \\text{Var}(X_{(n)}) + [\\text{Bias}(\\hat{\\theta}_{MLE})]^2 = \\frac{n\\theta^2}{(n+2)(n+1)^2} + \\left(-\\frac{\\theta}{n+1}\\right)^2 = \\frac{n\\theta^2 + (n+2)\\theta^2}{(n+2)(n+1)^2} = \\frac{2(n+1)\\theta^2}{(n+2)(n+1)^2} = \\frac{2\\theta^2}{(n+1)(n+2)}$\n\n2.  **对于无偏估计量 $\\hat{\\theta}_{U} = \\frac{n+1}{n}X_{(n)}$：**\n    *   偏差: $\\text{Bias}(\\hat{\\theta}_{U}) = 0$ (根据其定义)\n    *   方差: $\\text{Var}(\\hat{\\theta}_{U}) = \\text{Var}\\left(\\frac{n+1}{n}X_{(n)}\\right) = \\left(\\frac{n+1}{n}\\right)^2 \\text{Var}(X_{(n)}) = \\frac{(n+1)^2}{n^2} \\cdot \\frac{n\\theta^2}{(n+2)(n+1)^2} = \\frac{\\theta^2}{n(n+2)}$\n    *   均方误差: $\\text{MSE}(\\hat{\\theta}_{U}) = \\text{Var}(\\hat{\\theta}_{U}) + 0^2 = \\frac{\\theta^2}{n(n+2)}$\n\n最后，计算两个 MSE 的比值：\n$$ \\frac{\\text{MSE}(\\hat{\\theta}_{MLE})}{\\text{MSE}(\\hat{\\theta}_{U})} = \\frac{2\\theta^2 / ((n+1)(n+2))}{\\theta^2 / (n(n+2))} = \\frac{2}{n+1} \\cdot n = \\frac{2n}{n+1} $$", "answer": "$$\\boxed{\\frac{2n}{n+1}}$$", "id": "1914869"}, {"introduction": "我们不仅可以评估一个给定估计量的效率，在很多情况下，我们甚至可以直接构造出“最好”的无偏估计量。这个练习将向你介绍一个强大的工具——Lehmann-Scheffé定理，用它来寻找伯努利分布方差 $p(1-p)$ 的一致最小方差无偏估计量（UMVUE）。通过这个过程，你将发现这个看似抽象的理论概念，最终会导向我们所熟悉的样本方差，从而建立起新旧知识之间的深刻联系 [@problem_id:1914847]。", "problem": "在半导体制造厂的质量控制过程中，每个硅晶片都会针对特定类型的关键缺陷进行测试。每个晶片的结果可以建模为一次伯努利试验，其中晶片要么是次品（用 1 表示），要么不是次品（用 0 表示）。\n\n设 $X_1, X_2, \\ldots, X_n$ 是来自伯努利分布的大小为 $n$ 的随机样本，其为次品的未知概率为 $p$。参数 $p$ 是 $X_i = 1$ 的概率。该过程的总体方差由 $\\theta = \\text{Var}(X_i) = p(1-p)$ 给出。\n\n您的任务是确定该方差的最佳可能估计量。具体来说，求参数 $\\theta = p(1-p)$ 的一致最小方差无偏估计量（UMVUE）。\n\n将您的最终答案表示为关于样本大小 $n$ 和样本中观察到的次品晶片总数 $T = \\sum_{i=1}^n X_i$ 的单个封闭形式解析表达式。", "solution": "设 $X_{1},\\ldots,X_{n}$ 独立同分布于 $X_{i}\\sim\\text{Bernoulli}(p)$，并设 $T=\\sum_{i=1}^{n}X_{i}$。则 $T\\sim\\text{Binomial}(n,p)$。根据因子分解定理，$T$ 是 $p$ 的充分统计量，因为联合概率质量函数（pmf）仅通过 $T$ 依赖于样本。此外，$T$ 对于伯努利族是完备的：如果对于所有 $p\\in(0,1)$ 都有 $E_{p}[h(T)]=0$，那么由二项式概率构成的关于 $p$ 的多项式将迫使 $h(T)=0$ 几乎必然成立。因此，根据 Lehmann–Scheffé 定理，任何 $p$ 的函数的 UMVUE 是作为 $T$ 的函数的唯一无偏估计量。\n\n我们需要 $\\theta=p(1-p)$ 的一个无偏估计量。首先使用 $T$ 构造 $p$ 和 $p^{2}$ 的无偏估计量：\n$$\nE[T]=np\\quad\\Rightarrow\\quad E\\!\\left[\\frac{T}{n}\\right]=p,\n$$\n并使用阶乘矩，\n$$\nE\\!\\left[T(T-1)\\right]=n(n-1)p^{2}\\quad\\Rightarrow\\quad E\\!\\left[\\frac{T(T-1)}{n(n-1)}\\right]=p^{2}.\n$$\n因此\n$$\ng(T)\\equiv\\frac{T}{n}-\\frac{T(T-1)}{n(n-1)}\n$$\n满足 $E[g(T)]=p-p^{2}=p(1-p)=\\theta$，所以 $g(T)$ 是 $\\theta$ 的无偏估计。因为 $g$ 是完备充分统计量 $T$ 的函数，所以 $g(T)$ 是 $\\theta$ 的 UMVUE。\n\n我们可以对 $g(T)$ 进行代数化简：\n$$\n\\frac{T}{n}-\\frac{T(T-1)}{n(n-1)}=\\frac{T(n-1)-T(T-1)}{n(n-1)}=\\frac{Tn-T^{2}}{n(n-1)}=\\frac{T\\,(n-T)}{n(n-1)}.\n$$\n因此，对于 $n\\geq 2$，$\\theta=p(1-p)$ 的 UMVUE 是\n$$\n\\widehat{\\theta}_{\\text{UMVUE}}=\\frac{T\\,(n-T)}{n(n-1)}.\n$$\n等价地，注意到对于伯努利变量有 $X_{i}^{2}=X_{i}$，无偏样本方差\n$$\nS^{2}=\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(X_{i}-\\overline{X}\\right)^{2}=\\frac{T-\\frac{T^{2}}{n}}{n-1}=\\frac{T(n-T)}{n(n-1)}\n$$\n与 $T$ 的同一函数重合，这证实了它对于 $p(1-p)$ 是无偏的，并且根据完备性，它是 UMVUE。", "answer": "$$\\boxed{\\frac{T\\,(n-T)}{n(n-1)}}$$", "id": "1914847"}]}