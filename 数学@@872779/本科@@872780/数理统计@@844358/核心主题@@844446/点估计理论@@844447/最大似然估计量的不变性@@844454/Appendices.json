{"hands_on_practices": [{"introduction": "我们从一个基本但至关重要的例子开始。这个练习将探讨在二项分布的背景下，如何应用极大似然估计的不变性原理。通过计算一个我们熟悉参数（如成功概率 $p$）的MLE，我们可以直接得到一个更复杂函数（如分布的方差 $np(1-p)$）的MLE，这清晰地展示了该原理的“即插即用”特性。[@problem_id:1925545]", "problem": "一家工厂大批量生产微芯片。从中选取一批次的 $n$ 个微芯片进行质量控制检验。在这一批次中，发现有 $x$ 个微芯片是有缺陷的。假设一批次大小为 $n$ 的微芯片中，有缺陷的微芯片数量服从二项分布，记为 $B(n, p)$，其中 $p$ 是任意一个微芯片为缺陷品的未知概率。参数 $n$ 是一个已知的正整数， $x$ 是观测到的缺陷数量，其中 $0 \\le x \\le n$。该二项分布的方差由公式 $\\text{Var}(X) = np(1-p)$ 给出。你的任务是求出有缺陷微芯片数量的方差的最大似然估计。请用 $n$ 和 $x$ 的公式表示你的答案。", "solution": "设 $X \\sim B(n,p)$ 表示一批次大小为 $n$ 的微芯片中缺陷品的数量，其观测值为 $x$。给定 $x$ 时 $p$ 的似然函数为\n$$\nL(p \\mid x) = \\binom{n}{x} p^{x} (1-p)^{n-x}.\n$$\n对数似然函数为\n$$\n\\ell(p) = \\ln L(p \\mid x) = \\ln \\binom{n}{x} + x \\ln p + (n-x) \\ln(1-p).\n$$\n对 $p$ 求导并令其为零，得到\n$$\n\\frac{d\\ell}{dp} = \\frac{x}{p} - \\frac{n-x}{1-p} = 0 \\quad \\Rightarrow \\quad x(1-p) = (n-x)p \\quad \\Rightarrow \\quad \\hat{p} = \\frac{x}{n}.\n$$\n二阶导数，\n$$\n\\frac{d^{2}\\ell}{dp^{2}} = -\\frac{x}{p^{2}} - \\frac{n-x}{(1-p)^{2}}  0 \\quad \\text{for } p \\in (0,1),\n$$\n确认了这是一个最大值，并且边界情况 $x=0$ 或 $x=n$ 分别得出 $\\hat{p}=0$ 或 $\\hat{p}=1$ ，这与 $\\hat{p}=x/n$ 一致。\n\n$X$ 的方差是 $np(1-p)$。根据最大似然估计的不变性，方差的最大似然估计（MLE）可以通过代入 $\\hat{p}$ 得到：\n$$\n\\widehat{\\text{Var}}(X) = n \\hat{p} \\left(1 - \\hat{p}\\right) = n \\left(\\frac{x}{n}\\right) \\left(1 - \\frac{x}{n}\\right) = \\frac{x(n - x)}{n}.\n$$\n因此，方差的最大似然估计用 $n$ 和 $x$ 表示为 $\\frac{x(n - x)}{n}$。", "answer": "$$\\boxed{\\frac{x(n - x)}{n}}$$", "id": "1925545"}, {"introduction": "并非所有极大似然估计都通过简单的求导得出。这个练习将挑战我们处理一个非标准情况——均匀分布，其似然函数在参数空间的边界处达到最大值。这个例子旨在强调，无论求取原始参数 $\\hat{\\theta}$ 的方法如何，不变性原理依然是一个普遍适用的强大工具，极大地扩展了其应用范围。[@problem_id:1925562]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是从区间 $(0, \\theta)$ 上的连续均匀分布中抽取的样本容量为 $n$ 的随机样本，其中 $\\theta > 0$ 是一个未知参数。任何单个观测值 $X_i$ 的概率密度函数由 $f(x | \\theta) = \\frac{1}{\\theta}$ (当 $0  x  \\theta$ 时) 给出，其他情况下 $f(x|\\theta) = 0$。\n\n设 $X_{(n)}$ 表示样本中的最大值，即 $X_{(n)} = \\max(X_1, X_2, \\dots, X_n)$。\n\n求该分布方差的最大似然估计量 (MLE)。答案请用 $X_{(n)}$ 和数值常数表示。", "solution": "我们首先写出样本的联合似然函数。对于来自 $(0,\\theta)$ 上均匀分布的独立观测，\n$$\nL(\\theta \\mid x_{1},\\dots,x_{n})=\\prod_{i=1}^{n} f(x_{i}\\mid \\theta)=\\prod_{i=1}^{n}\\frac{1}{\\theta}\\,\\mathbf{1}_{\\{0  x_i  \\theta\\}}\n$$\n等价于\n$$\nL(\\theta \\mid x_{1},\\dots,x_{n})=\\left(\\frac{1}{\\theta}\\right)^{n}\\,\\prod_{i=1}^{n}\\mathbf{1}_{\\{x_i \\in (0,\\theta)\\}} = \\left(\\frac{1}{\\theta}\\right)^{n}\\,\\mathbf{1}_{\\{0  x_{(1)} \\text{ and } x_{(n)}  \\theta\\}}.\n$$\n其中 $x_{(1)}$ 和 $x_{(n)}$ 分别是样本的最小值和最大值。为了最大化该似然函数，我们需要在满足约束 $\\theta \\ge x_{(n)}$ 的前提下，使 $\\theta$ 尽可能小。很明显，当 $\\theta = x_{(n)}$ 时，该函数达到最大值。因此，$\\theta$ 的最大似然估计量是 $\\hat{\\theta} = X_{(n)}$。\n\n均匀分布 $U(0, \\theta)$ 的方差是 $\\operatorname{Var}(X) = \\frac{(b-a)^{2}}{12} = \\frac{(\\theta - 0)^{2}}{12} = \\frac{\\theta^{2}}{12}$。\n根据最大似然估计的不变性，方差的最大似然估计量可以通过将 $\\hat{\\theta}$ 代入方差公式得到：\n$$\n\\widehat{\\operatorname{Var}}(X) = \\frac{\\hat{\\theta}^{2}}{12} = \\frac{X_{(n)}^{2}}{12}.\n$$\n因此，方差的最大似然估计量是 $\\frac{X_{(n)}^{2}}{12}$。", "answer": "$$\\boxed{\\frac{X_{(n)}^{2}}{12}}$$", "id": "1925562"}, {"introduction": "现在，让我们看一个更高级的应用，展示不变性原理在复杂统计模型中的威力。零膨胀泊松 (ZIP) 分布在生态学和流行病学等领域很常见，但其参数估计可能很复杂。本练习演示了如何利用不变性原理，从基础参数的估计值（即使它们的推导过程很复杂）轻松地获得整个分布方差的极大似然估计，凸显了该性质在解决前沿问题时的实用价值。[@problem_id:1925553]", "problem": "如果一个随机变量 $Y$ 的概率质量函数（PMF）由下式给出，则称其服从参数为 $\\pi \\in [0, 1)$ 和 $\\lambda  0$ 的零膨胀泊松（Zero-Inflated Poisson, ZIP）分布：\n$$\nP(Y=y) = \n\\begin{cases}\n\\pi + (1-\\pi)\\exp(-\\lambda)  \\text{若 } y=0 \\\\\n(1-\\pi) \\frac{\\lambda^y \\exp(-\\lambda)}{y!}  \\text{若 } y \\in \\{1, 2, 3, \\ldots\\}\n\\end{cases}\n$$\n其中，$\\pi$ 表示并非来自泊松过程的额外零计数的概率，而 $\\lambda$ 是其底层泊松分布的均值。\n\n考虑从一个 ZIP 分布中抽取的随机样本 $y_1, y_2, \\ldots, y_n$。令 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^n y_i$ 为样本均值。参数 $\\pi$ 和 $\\lambda$ 是未知的。令 $\\hat{\\pi}$ 和 $\\hat{\\lambda}$ 分别表示它们的最大似然估计量（MLE）。\n\n利用最大似然估计量（MLE）的不变性，求此分布方差 $\\sigma^2 = \\text{Var}(Y)$ 的最大似然估计量。请将答案表示为关于样本均值 $\\bar{y}$ 和 MLE $\\hat{\\lambda}$ 的封闭形式解析表达式。", "solution": "对于一个参数为 $\\pi \\in [0,1)$ 和 $\\lambda  0$ 的零膨胀泊松（ZIP）随机变量 $Y$，可将其写为 $Y = Z X$，其中 $Z \\sim \\text{Bernoulli}(1-\\pi)$，并且在 $Z=1$ 的条件下，$X \\sim \\text{Poisson}(\\lambda)$；否则 $Y=0$。使用这个混合表示：\n$$\n\\mathbb{E}[Y] = (1 - \\pi)\\lambda \\equiv \\mu,\n$$\n并且由于对于 $X \\sim \\text{Poisson}(\\lambda)$，有 $\\mathbb{E}[X^{2}] = \\lambda + \\lambda^{2}$，我们得到\n$$\n\\mathbb{E}[Y^{2}] = (1 - \\pi)\\mathbb{E}[X^{2}] = (1 - \\pi)(\\lambda + \\lambda^{2}).\n$$\n因此，\n$$\n\\operatorname{Var}(Y) = \\mathbb{E}[Y^{2}] - \\{\\mathbb{E}[Y]\\}^{2} = (1 - \\pi)\\lambda + (1 - \\pi)\\lambda^{2} - (1 - \\pi)^{2}\\lambda^{2} = (1 - \\pi)\\lambda\\{1 + \\pi\\lambda\\}.\n$$\n等价地，用 $\\mu = (1 - \\pi)\\lambda$ 来表示，注意到 $\\pi\\lambda = \\lambda - \\mu$，所以\n$$\n\\sigma^{2} = \\operatorname{Var}(Y) = \\mu\\{1 + \\lambda - \\mu\\}.\n$$\n\n根据最大似然估计量的不变性，将参数的最大似然估计量代入此函数即可得到 $\\sigma^{2}$ 的最大似然估计量。为了将结果表示为样本均值 $\\bar{y}$ 和 $\\hat{\\lambda}$ 的形式，我们证明 $\\mu$ 的最大似然估计量等于 $\\bar{y}$。\n\n通过 $\\mu = (1 - \\pi)\\lambda$ 进行重新参数化，使得 $\\pi = 1 - \\mu/\\lambda$。令 $n_{0} = \\sum_{i=1}^{n} \\mathbf{1}\\{y_{i}=0\\}$。对数似然函数（忽略不含 $\\mu$ 的项）为\n$$\n\\ell(\\mu,\\lambda) = n_{0}\\ln\\!\\left(1 - \\frac{\\mu}{\\lambda}\\{1 - \\exp(-\\lambda)\\}\\right) + (n - n_{0})\\ln \\mu + C(\\lambda,y).\n$$\n对 $\\mu$ 求导并令其为零可得\n$$\n\\frac{\\partial \\ell}{\\partial \\mu} = -\\,\\frac{n_{0}\\,\\{(1/\\lambda)(1 - \\exp(-\\lambda))\\}}{1 - \\frac{\\mu}{\\lambda}(1 - \\exp(-\\lambda))} + \\frac{n - n_{0}}{\\mu} = 0,\n$$\n解得\n$$\n(n - n_{0})\\lambda = \\mu\\,n\\,(1 - \\exp(-\\lambda)).\n$$\n由关于 $\\lambda$ 的得分方程，可以得到\n$$\n\\frac{n\\bar{y}}{\\lambda} = \\frac{n - n_{0}}{1 - \\exp(-\\lambda)}.\n$$\n结合这两个恒等式可得 $\\mu = \\bar{y}$。因此，在最大似然估计处，$\\hat{\\mu} = (1 - \\hat{\\pi})\\hat{\\lambda} = \\bar{y}$，即\n$$\n\\hat{\\pi} = 1 - \\frac{\\bar{y}}{\\hat{\\lambda}}.\n$$\n\n对 $\\sigma^{2} = \\mu(1 + \\lambda - \\mu)$ 应用不变性，可得\n$$\n\\hat{\\sigma}^{2} = \\hat{\\mu}\\{1 + \\hat{\\lambda} - \\hat{\\mu}\\} = \\bar{y}\\{1 + \\hat{\\lambda} - \\bar{y}\\}.\n$$\n这是一个关于 $\\bar{y}$ 和 $\\hat{\\lambda}$ 的封闭形式解析表达式。", "answer": "$$\\boxed{\\bar{y}\\left(1+\\hat{\\lambda}-\\bar{y}\\right)}$$", "id": "1925553"}]}