## 引言
在科学探索与数据驱动决策的时代，我们如何从充满不确定性的观测数据中得出关于世界运行规律的可靠结论？无论是评估新药的疗效、验证物理学的新理论，还是分析经济市场的趋势，我们都需要一个严谨的框架来量化证据，并对提出的假设做出判断。**[检验统计量](@entry_id:167372) (Test Statistic)** 正是这一框架的核心，它扮演着连接原始数据与科学假设之间不可或缺的角色。它解决了从混乱的样本信息到清晰的[统计决策](@entry_id:170796)这一关键难题。

本文将带领读者深入探索检验统计量的世界。在第一章**“原理与机制”**中，我们将剖析[检验统计量](@entry_id:167372)的基本构造，理解其如何通过[枢轴量](@entry_id:168397)、p值和[拒绝域](@entry_id:172793)等概念发挥作用，并深入探讨构建最优检验的深刻理论，包括[Neyman-Pearson引理](@entry_id:163022)和作为现代统计学基石的似然比、沃尔德及分数检验。随后的第二章**“应用与跨学科联系”**将展示这些理论的强大生命力，通过一系列来自农业、医学、物理学乃至[基因组学](@entry_id:138123)等领域的真实案例，揭示[检验统计量](@entry_id:167372)如何解决各学科中的核心问题。最后，通过**“动手实践”**环节，您将有机会亲手应用所学知识，巩固对这些关键概念的理解。通过本次学习，您将掌握的不仅是计算公式，更是一种将数据转化为知识的[科学思维](@entry_id:268060)方式。

## 原理与机制

在[假设检验](@entry_id:142556)的框架中，**[检验统计量](@entry_id:167372) (test statistic)** 是连接观测数据与待检验假设的桥梁。它是一个根据样本数据计算出的数值，其核心作用是将样本中蕴含的、与原假设 $H_0$ 相关的证据浓缩成一个单一的、可解释的度量。一个精心构造的检验统计量能够量化样本结果与原假设预期结果之间的差异。理想情况下，我们希望这个统计量在[原假设](@entry_id:265441)为真时的[概率分布](@entry_id:146404)是已知的，并且不依赖于任何未知参数。满足此性质的统计量被称为**[枢轴量](@entry_id:168397) (pivotal quantity)**。

例如，考虑一个从正态分布 $N(\mu, \sigma^2)$ 中抽取的随机样本 $X_1, \dots, X_n$，其中[方差](@entry_id:200758) $\sigma^2$ 已知。我们要检验关于均值 $\mu$ 的原假设 $H_0: \mu = \mu_0$。样本均值 $\bar{X} = \frac{1}{n}\sum_{i=1}^{n} X_i$ 是 $\mu$ 的一个自然估计量。然而，$\bar{X}$ 本身的[分布](@entry_id:182848)是 $N(\mu, \sigma^2/n)$，这依赖于未知的真实均值 $\mu$。因此，$\bar{X}$ 并非一个[枢轴量](@entry_id:168397)。但是，通过将其[标准化](@entry_id:637219)，我们可以构造一个[枢轴量](@entry_id:168397)。具体来说，在原假设 $H_0$ 成立的前提下，我们有 $\bar{X} \sim N(\mu_0, \sigma^2/n)$。通过减去其均值 $\mu_0$ 并除以其标准差 $\sigma/\sqrt{n}$，我们得到统计量：

$$Z = \frac{\bar{X} - \mu_0}{\sigma / \sqrt{n}}$$

在 $H_0$ 之下，$Z$ 的[分布](@entry_id:182848)为标准正态分布 $N(0, 1)$。这个[分布](@entry_id:182848)是完全确定的，不依赖于任何未知参数，因此 $Z$ 是一个用于此场景的理想[枢轴量](@entry_id:168397)和[检验统计量](@entry_id:167372) [@problem_id:1958122] [@problem_id:1958144]。它将样本均值与假设均值之间的差异，用其自身的标准误差单位进行了度量。一个远离 0 的 $Z$ 值表明观测数据与[原假设](@entry_id:265441)不符。

### 决策规则：[拒绝域](@entry_id:172793)与p值

一旦我们计算出检验统计量的值，就需要一个明确的规则来决定是否拒绝原假设。这个决策过程可以通过两种等价的方式来表述：拒绝域方法和[p值](@entry_id:136498)方法。

**拒绝域 (rejection region)**，或称临界域 (critical region)，是检验统计量所有可能取值的一个[子集](@entry_id:261956)。如果计算出的检验统计量的值落入这个区域，我们就拒绝[原假设](@entry_id:265441) $H_0$。这个区域的边界由**[显著性水平](@entry_id:170793) (significance level)** $\alpha$ 决定。$\alpha$ 是我们预先设定的、愿意承担的犯**[第一类错误](@entry_id:163360) (Type I error)** 的最大概率，即错误地拒绝一个为真的原假设的概率。

例如，一位[材料科学](@entry_id:152226)家假设一种新工艺生产的钢丝的平均[抗拉强度](@entry_id:161506) $\mu$ 高于旧工艺的平均值 $\mu_0$。这构成了一个右尾检验，其[备择假设](@entry_id:167270)为 $H_a: \mu > \mu_0$。[检验统计量](@entry_id:167372)为 $Z = (\bar{X} - \mu_0)/(\sigma/\sqrt{n})$。在[显著性水平](@entry_id:170793) $\alpha$ 下，我们需要找到一个临界值 $z_{1-\alpha}$，使得当 $H_0$ 为真时，$P(Z > z_{1-\alpha}) = \alpha$。这里的 $z_{1-\alpha}$ 是[标准正态分布](@entry_id:184509)的 $(1-\alpha)$ [分位数](@entry_id:178417)。因此，拒绝域被定义为所有大于 $z_{1-\alpha}$ 的值所构成的集合。如果观测到的 $Z$ 值大于 $z_{1-\alpha}$，我们就拒绝 $H_0$，认为有足够证据支持新工艺提高了平均[抗拉强度](@entry_id:161506)。例如，若 $\alpha = 0.01$，则临界值 $z_{0.99} \approx 2.33$，[拒绝域](@entry_id:172793)为 $[2.33, \infty)$ [@problem_id:1958132]。

另一种等价的决策工具是 **p值 (p-value)**。[p值](@entry_id:136498)是在原假设 $H_0$ 为真的前提下，观测到当前检验统计量的值，或者更极端、更不利于 $H_0$ 的值的概率。[p值](@entry_id:136498)越小，意味着在 $H_0$ 的框架下，我们观测到的数据就越“罕见”或“令人惊讶”，因此反对 $H_0$ 的证据就越强。决策规则很简单：如果[p值](@entry_id:136498)小于或等于预设的[显著性水平](@entry_id:170793) $\alpha$，我们就拒绝 $H_0$。

对于一个[检验统计量](@entry_id:167372)为 $T$、观测值为 $t_{obs}$ 的右尾检验，其“更极端”的值是指所有大于或等于 $t_{obs}$ 的值。因此，p值被定义为 $p = P(T \ge t_{obs} | H_0)$。如果我们用 $S_T(t) = P(T \ge t)$ 表示[检验统计量](@entry_id:167372) $T$ 在 $H_0$ 下的**生存函数 (survival function)**，那么右尾检验的[p值](@entry_id:136498)可以直接表示为 $S_T(t_{obs})$ [@problem_id:1958118]。类似地，对于左尾检验 ($H_a: \theta  \theta_0$)，p值为 $P(T \le t_{obs} | H_0)$；对于双尾检验 ($H_a: \theta \neq \theta_0$)，p值通常是 $2 \times P(T \ge |t_{obs}| | H_0)$（假设 $T$ 在 $H_0$ 下的[分布](@entry_id:182848)关于0对称）。

这两种方法是相通的。一个检验统计量的值落在[拒绝域](@entry_id:172793)内，当且仅当其对应的p值小于 $\alpha$。此外，[假设检验与置信区间](@entry_id:176458)之间存在着深刻的**对偶性 (duality)**。一个在[显著性水平](@entry_id:170793) $\alpha$ 下关于参数 $\theta$ 的双尾检验 $H_0: \theta = \theta_0$ 拒绝原假设，当且仅当 $\theta_0$ 不在参数 $\theta$ 的 $(1-\alpha)$ 置信区间之内 [@problem_id:1958144]。

### 检验性能的评估：第一类与[第二类错误](@entry_id:173350)

任何基于样本数据的[统计决策](@entry_id:170796)都存在犯错误的风险。除了前面提到的[第一类错误](@entry_id:163360)（弃真），还存在**[第二类错误](@entry_id:173350) (Type II error)**，即未能拒绝一个实际上为假的原假设（纳伪）。犯[第二类错误](@entry_id:173350)的概率通常用 $\beta$ 表示。

与 $\alpha$ 是一个固定的设计参数不同，$\beta$ 的值依赖于真实的参数值。当备择假设 $H_a$ 为真时，真实参数与[原假设](@entry_id:265441) $H_0$ 中设定的参数值相距越远，我们所用的检验就越容易“看穿” $H_0$ 的伪装，从而 $\beta$ 就越小。一个检验正确地拒绝一个错误的[原假设](@entry_id:265441)的概率被称为**检验的势 (power of a test)**，其值为 $1-\beta$。在设计实验时，我们希望在控制[第一类错误](@entry_id:163360)率 $\alpha$ 的同时，最大化检验的势（即最小化 $\beta$）。

我们可以推导 $\beta$ 的表达式来量化检验的性能。假设一位工程师检验一批催化转化器，其[预热](@entry_id:159073)时间 $X \sim N(\mu, \sigma^2)$，其中 $\sigma$ 已知。检验的假设为 $H_0: \mu = \mu_0$，而[备择假设](@entry_id:167270)是 $\mu > \mu_0$。检验规则是：如果样本均值 $\bar{X}$ 大于等于某个临界值 $c$，就拒绝 $H_0$。现在假设由于生产瑕疵，这批产品的真实平均[预热](@entry_id:159073)时间为 $\mu_1$，且 $\mu_1 > \mu_0$。在这种情况下，[原假设](@entry_id:265441) $H_0$ 是错误的。[第二类错误](@entry_id:173350)在这里表现为未能发现均值实际上不是 $\mu_0$，即观测到的 $\bar{X}$ 最终小于 $c$。因此，$\beta$ 是在真实均值为 $\mu_1$ 的条件下，$\bar{X}  c$ 的概率。

由于在真实条件下 $\bar{X} \sim N(\mu_1, \sigma^2/n)$，我们可以计算：
$$\beta = P(\bar{X}  c | \mu = \mu_1) = P\left(\frac{\bar{X} - \mu_1}{\sigma/\sqrt{n}}  \frac{c - \mu_1}{\sigma/\sqrt{n}}\right) = \Phi\left(\frac{\sqrt{n}(c - \mu_1)}{\sigma}\right)$$
其中 $\Phi(\cdot)$ 是标准正态分布的[累积分布函数 (CDF)](@entry_id:264700) [@problem_id:1958156]。这个表达式清晰地展示了 $\beta$ 如何依赖于真实值 $\mu_1$、样本量 $n$、[标准差](@entry_id:153618) $\sigma$ 和决策边界 $c$。

### [检验统计量](@entry_id:167372)的构建原理

我们如何系统地构建出“好”的[检验统计量](@entry_id:167372)？统计理论提供了几个核心原理，它们不仅为现有检验提供了理论依据，也指导着新检验方法的开发。

#### 充分性原理

**充分统计量 (sufficient statistic)** 是一个包含了样本中关于未知参数所有信息的统计量。从信息的角度看，一旦我们知道了充分统计量的值，原始样本数据中的每个具体观测值对于推断该参数就不再提供任何额外的信息。因此，基于充分性原理，我们的[统计推断](@entry_id:172747)（包括假设检验）应该只依赖于充分统计量。

**[Neyman-Fisher因子分解定理](@entry_id:167279) (Neyman-Fisher Factorization Theorem)** 为我们识别充分统计量提供了一个强大的数学工具。该定理指出，一个统计量 $T(\mathbf{X})$ 是参数 $\theta$ 的充分统计量，当且仅当样本 $\mathbf{X} = (X_1, \dots, X_n)$ 的[联合概率密度函数](@entry_id:267139)（或[概率质量函数](@entry_id:265484)）$f(\mathbf{x}; \theta)$ 可以分解为两个函数的乘积：一个函数只通过 $T(\mathbf{x})$ 与 $\theta$ 相关，另一个函数则完全不依赖于 $\theta$。即：
$$f(\mathbf{x}; \theta) = g(T(\mathbf{x}); \theta) \cdot h(\mathbf{x})$$

考虑一个例子：检测[光纤](@entry_id:273502)中的瑕疵数量，假设每米[光纤](@entry_id:273502)的瑕疵数 $X$ 服从参数为 $\lambda$ 的泊松分布。对于一个包含 $n$ 个样本 $X_1, \dots, X_n$ 的随机样本，其[联合概率质量函数](@entry_id:184238)为：
$$\prod_{i=1}^{n} \frac{\lambda^{x_i} \exp(-\lambda)}{x_i!} = \exp(-n\lambda) \lambda^{\sum_{i=1}^{n} x_i} \left(\prod_{i=1}^{n} \frac{1}{x_i!}\right)$$
令 $T(\mathbf{X}) = \sum_{i=1}^{n} X_i$ 为总瑕疵数。我们可以看到，[联合概率质量函数](@entry_id:184238)成功地分解为 $g(T; \lambda) = \exp(-n\lambda) \lambda^T$ 和 $h(\mathbf{x}) = (\prod x_i!)^{-1}$ 的乘积。根据[因子分解定理](@entry_id:749213)，$T = \sum X_i$ 是参数 $\lambda$ 的充分统计量。这意味着，要对 $\lambda$ 进行任何推断，我们只需要知道总瑕疵数 $T$ 即可，而无需关心这 $T$ 个瑕疵是如何[分布](@entry_id:182848)在 $n$ 个样本段中的。这为仅使用总瑕疵数来构建关于 $\lambda$ 的检验提供了根本的统计学理由 [@problem_id:1958139]。

#### [似然](@entry_id:167119)原理与最优检验

**[似然函数](@entry_id:141927) (likelihood function)** $L(\theta|\mathbf{x}) = f(\mathbf{x}; \theta)$ 是现代统计推断的基石。对于给定的观测数据 $\mathbf{x}$，它被看作是参数 $\theta$ 的函数，衡量了不同 $\theta$ 值产生当前观测数据的“可能性”大小。[似然](@entry_id:167119)原理主张，数据 $\mathbf{x}$ 中所有与参数 $\theta$ 相关的信息都包含在[似然函数](@entry_id:141927)中。

在检验**简单假设**（即假设完全确定了[分布](@entry_id:182848)，如 $H_0: \theta = \theta_0$ 对 $H_1: \theta = \theta_1$）的场景中，**[Neyman-Pearson引理](@entry_id:163022) (Neyman-Pearson Lemma)** 提供了一个构建**最优势检验 (most powerful test)** 的方法。最优势检验是在给定[第一类错误](@entry_id:163360)率 $\alpha$ 的所有检验中，具有最高势（即最低[第二类错误](@entry_id:173350)率 $\beta$）的检验。该引理指出，最优势检验的拒绝域由**似然比 (likelihood ratio)** $\Lambda(\mathbf{x}) = L(\theta_1|\mathbf{x}) / L(\theta_0|\mathbf{x})$ 的值决定。具体来说，当似然比大于某个阈值时，我们拒绝 $H_0$。

直观上，如果 $\Lambda(\mathbf{x})$ 很大，意味着观测数据 $\mathbf{x}$ 在备择假设 $H_1$ 下出现的可能性远大于在[原假设](@entry_id:265441) $H_0$ 下出现的可能性，因此我们有强有力的证据反对 $H_0$。

例如，评估一种新型诊断测试的灵敏度 $p$（即在感染者中检测出阳性的概率）。我们要检验 $H_0: p = p_0$ 对 $H_1: p = p_1$（假设 $p_1 > p_0$）。对于单次[伯努利试验](@entry_id:268355)结果 $X$（$X=1$ 为阳性，$X=0$ 为阴性），似然函数为 $L(p|x) = p^x(1-p)^{1-x}$。[似然比](@entry_id:170863)为：
$$\Lambda(x) = \frac{L(p_1|x)}{L(p_0|x)} = \frac{p_1^x (1-p_1)^{1-x}}{p_0^x (1-p_0)^{1-x}}$$

如果观测结果为阳性 ($x=1$)，似然比为 $\Lambda(1) = p_1/p_0$。如果为阴性 ($x=0$)，似然比为 $\Lambda(0) = (1-p_1)/(1-p_0)$。由于 $p_1 > p_0$，我们有 $\Lambda(1) > 1$；由于 $1-p_1  1-p_0$，我们有 $\Lambda(0)  1$。阳性结果支持 $H_1$，而阴性结果支持 $H_0$。这两个值的比率 $\frac{\Lambda(1)}{\Lambda(0)} = \frac{p_1(1-p_0)}{p_0(1-p_1)}$ 量化了“阳性”结果相对于“阴性”结果对 $H_1$ 的支持强度 [@problem_id:1958153]。[Neyman-Pearson引理](@entry_id:163022)告诉我们，基于这个[似然比](@entry_id:170863)的检验是区分这两种简单假设的最优方法。

#### 渐近检验的三位一体

对于更复杂的**[复合假设](@entry_id:164787)**（即假设没有完全确定[分布](@entry_id:182848)，如 $H_0: \theta \le \theta_0$ 或 $H_0: \theta_1 = 1$），寻找一个在所有备择参数值下都一致最优势的检验通常是不可能的。在这种情况下，尤其是在大样本情形下，统计学家们开发了一套功能强大的**渐近检验 (asymptotic tests)**。其中最著名的三个是[似然比检验](@entry_id:268070)、沃尔德检验和拉奥分数检验。这三者在许多标准模型下是[渐近等价](@entry_id:273818)的，但在有限样本或复杂模型中各有优劣。

**1. [似然比检验](@entry_id:268070) (Likelihood Ratio Test, LRT)**

LRT 将 Neyman-Pearson 的思想推广到[复合假设](@entry_id:164787)。它比较了在受约束的[参数空间](@entry_id:178581) $\Theta_0$（由 $H_0$ 定义）中最大化的似然值与在整个参数空间 $\Omega$ 中最大化的似然值。似然比统计量定义为：
$$\Lambda = \frac{\sup_{\boldsymbol{\uptheta} \in \Theta_0} L(\boldsymbol{\uptheta})}{\sup_{\boldsymbol{\uptheta} \in \Omega} L(\boldsymbol{\uptheta})}$$

$\Lambda$ 的值在 0 和 1 之间。如果 $\Lambda$ 接近 1，说明在 $H_0$ 的约束下，似然函数并未损失太多，因此没有理由拒绝 $H_0$。反之，如果 $\Lambda$ 接近 0，说明 $H_0$ 的约束严重降低了数据的[似然](@entry_id:167119)，提供了反对 $H_0$ 的证据。

**[Wilks定理](@entry_id:169826) (Wilks' Theorem)** 是一个里程碑式的成果，它阐明了 LRT 统计量的[渐近分布](@entry_id:272575)。该定理指出，在 $H_0$ 为真且满足一定[正则性条件](@entry_id:166962)下，统计量 $W = -2 \ln \Lambda$ 在样本量 $n \to \infty$ 时，其[分布](@entry_id:182848)收敛于一个卡方 ($\chi^2$) [分布](@entry_id:182848)。该[卡方分布](@entry_id:165213)的自由度 $r$ 等于全[参数空间](@entry_id:178581) $\Omega$ 的维度与受约束参数空间 $\Theta_0$ 的维度之差。

例如，假设器件寿命服从伽玛[分布](@entry_id:182848)，其参数为形状 $\alpha$ 和尺度 $\theta$。我们要检验寿命模型是否可以简化为更简单的[指数分布](@entry_id:273894)，这等价于检验 $H_0: \alpha=1$。这里的全[参数空间](@entry_id:178581) $\Omega = \{(\alpha, \theta) | \alpha > 0, \theta > 0\}$ 是二维的。[原假设](@entry_id:265441)下的受约束参数空间 $\Theta_0 = \{(1, \theta) | \theta > 0\}$ 是一维的。因此，自由度 $r = \dim(\Omega) - \dim(\Theta_0) = 2 - 1 = 1$。根据 Wilks 定理，检验统计量 $W = -2 \ln \Lambda$ 将渐近服从自由度为 1 的[卡方分布](@entry_id:165213)，即 $\chi^2_1$ [分布](@entry_id:182848) [@problem_id:1958162]。

**2. 沃尔德检验 (Wald Test)**

沃尔德检验的直观思想是：如果[原假设](@entry_id:265441) $H_0: h(\boldsymbol{\theta}) = c$ 为真，那么基于**[最大似然估计量](@entry_id:163998) (Maximum Likelihood Estimator, MLE)** $\hat{\boldsymbol{\theta}}$ 计算出的 $h(\hat{\boldsymbol{\theta}})$ 应该接近于 $c$。沃尔德检验通过将这个差值的平方用其[方差](@entry_id:200758)进行[标准化](@entry_id:637219)来衡量其显著性。其一般的平方形式为：
$$W = \frac{(h(\hat{\boldsymbol{\theta}}) - c)^2}{\widehat{\text{Var}}(h(\hat{\boldsymbol{\theta}}))}$$

这里的 $\widehat{\text{Var}}(h(\hat{\boldsymbol{\theta}}))$ 是 $h(\hat{\boldsymbol{\theta}})$ [方差](@entry_id:200758)的估计值。这个[方差](@entry_id:200758)通常通过**delta方法 (delta method)** 结合 MLE 的[渐近方差](@entry_id:269933)（即**Fisher信息 (Fisher information)** 的逆）来得到。在大样本下，$W$ 渐近服从自由度为 $h$ 的维数的[卡方分布](@entry_id:165213)（对于标量函数 $h$，自由度为1）。

考虑一个检验帕累托 (Pareto) [分布](@entry_id:182848)[中位数](@entry_id:264877)对数值的例子 [@problem_id:1958128]。假设原假设为 $H_0: \ln(m) = 0.25$，其中中位数 $m$ 是[形状参数](@entry_id:270600) $\alpha$ 的函数 $m = 2^{1/\alpha}$。因此，我们检验的函数是 $h(\alpha) = \ln(2)/\alpha$。沃尔德检验的步骤是：首先计算 $\alpha$ 的 MLE $\hat{\alpha}$；然后利用 delta 方法估计 $h(\hat{\alpha})$ 的[方差](@entry_id:200758)，$\text{Var}(h(\hat{\alpha})) \approx [h'(\hat{\alpha})]^2 \text{Var}(\hat{\alpha})$；最后将这些值代入沃尔德统计量的公式中。这种方法的优势在于它只依赖于无约束模型下的 MLE。

**3. 拉奥分数检验 (Rao Score Test)**

拉奥分数检验，也称[拉格朗日乘子](@entry_id:142696) (Lagrange Multiplier, LM) 检验，其直观思想源于似然函数的几何形状。如果[原假设](@entry_id:265441) $H_0: \boldsymbol{\theta} = \boldsymbol{\theta}_0$ 为真，那么[对数似然函数](@entry_id:168593) $\ell(\boldsymbol{\theta})$ 在 $\boldsymbol{\theta}_0$ 处的“斜率”应该接近于零。这个“斜率”就是**[分数函数](@entry_id:164520) (score function)** $U(\boldsymbol{\theta}) = \frac{\partial}{\partial \boldsymbol{\theta}} \ell(\boldsymbol{\theta})$。

分数检验统计量通过将在原假设值 $\boldsymbol{\theta}_0$ 处计算的[分数函数](@entry_id:164520)的平方，用其[方差](@entry_id:200758)（即 [Fisher 信息](@entry_id:144784)）进行标准化：
$$S = [U(\boldsymbol{\theta}_0)]^T [I(\boldsymbol{\theta}_0)]^{-1} [U(\boldsymbol{\theta}_0)]$$
其中 $I(\boldsymbol{\theta}_0)$ 是在 $\boldsymbol{\theta}_0$ 处评估的 [Fisher 信息矩阵](@entry_id:268156)。在大样本下，$S$ 渐近服从卡方分布，自由度与被约束的参数个数相同。

分数检验的一个显著优点是它**仅需在原假设下进行[模型拟合](@entry_id:265652)**。我们只需要计算 $\boldsymbol{\theta}_0$ 处的分数和 [Fisher 信息](@entry_id:144784)，而无需计算复杂的无约束 MLE $\hat{\boldsymbol{\theta}}$，这在备择模型非常复杂时尤其具有计算优势。例如，在检验威布尔 (Weibull) [分布](@entry_id:182848)的形状参数 $k$ 是否等于某个值 $k_0$ 时，我们可以直接在 $k=k_0$ 的条件下计算[分数函数](@entry_id:164520) $U(k_0)$ 和 Fisher 信息 $I_n(k_0)$，然后构造分数统计量 $S = [U(k_0)]^2 / I_n(k_0)$ [@problem_id:1958119]。

总之，从基本的[枢轴量](@entry_id:168397)构造，到基于似然原理的最优性理论，再到适用于广泛模型的大样本[渐近方法](@entry_id:177759)，检验统计量的构建和使用构成了[统计推断](@entry_id:172747)的核心技术体系。理解这些原理与机制，对于在科学研究和工程实践中正确应用和解读[假设检验](@entry_id:142556)至关重要。