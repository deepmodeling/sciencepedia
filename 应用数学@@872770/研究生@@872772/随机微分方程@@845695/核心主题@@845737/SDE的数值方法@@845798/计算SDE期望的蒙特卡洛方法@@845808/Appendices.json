{"hands_on_practices": [{"introduction": "任何蒙特卡洛模拟都面临着一个根本性的权衡：为了提高精度，我们需要更多的样本，但这会增加计算成本。本练习将引导你探究期望的均方根误差（$RMSE$）、被估计量的方差（$V$）以及所需样本量（$N$）之间的核心关系。掌握这一计算是设计任何高效、可靠的蒙特卡洛研究的第一步 [@problem_id:2988319]。", "problem": "考虑一个一维 Itô 随机微分方程 (SDE) $dX_{t}=\\mu(X_{t},t)\\,dt+\\sigma(X_{t},t)\\,dW_{t}$，其具有确定性初始条件 $X_{0}=x_{0}$，其中 $\\mu$ 和 $\\sigma$ 满足确保强解存在唯一性以及 $X_{t}$ 泛函的二阶矩有限的标准条件。设 $T0$ 为一个固定的终端时间，并设 $\\varphi:\\mathbb{R}\\to\\mathbb{R}$ 是一个可测函数，使得 $\\mathbb{E}\\big[|\\varphi(X_{T})|^{2}\\big]  \\infty$。计算任务是通过蒙特卡洛抽样来近似期望 $\\mathbb{E}[\\varphi(X_{T})]$。\n\n假设在一个理想化情景下，$X_{T}$ 的抽样是精确的（即，忽略任何离散化偏差），并假设可以抽取 $N$ 个独立样本 $Y_{1},\\dots,Y_{N}$，其中 $Y_{i}=\\varphi(X_{T}^{(i)})$，而 $X_{T}^{(i)}$ 是 $X_{T}$ 的独立副本。设 $V=\\mathrm{Var}(Y_{1})$ 已知且有限，且 $V0$。对于蒙特卡洛估计量 $\\widehat{m}_{N}=\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}$，设定一个目标均方根误差 (RMSE) 阈值 $\\varepsilon0$。\n\n在零偏差的假设下，从方差、独立性和均方误差的定义出发，推导为确保 $\\widehat{m}_{N}$ 的 RMSE 不超过 $\\varepsilon$ 所需的最小整数样本量 $N$。然后，通过推导连续松弛 $N(V)$ 相对于 $V$ 的一阶敏感性以及在 $V$ 处的相应相对敏感性，来量化所需样本量对方法差误估的敏感性。\n\n最终答案必须是单个闭式解析表达式或包含表达式的单行矩阵。不需要进行数值近似。", "solution": "我们首先的目标是使用蒙特卡洛估计量 $\\widehat{m}_{N}=\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}$ 来估计期望 $\\mathbb{E}[\\varphi(X_{T})]$，其中 $Y_{i}=\\varphi(X_{T}^{(i)})$ 且 $X_{T}^{(i)}$ 是 $X_{T}$ 的独立实现。在所述假设下，样本 $Y_{1},\\dots,Y_{N}$ 独立同分布，具有有限方差 $V=\\mathrm{Var}(Y_{1})$ 和均值 $m=\\mathbb{E}[Y_{1}]=\\mathbb{E}[\\varphi(X_{T})]$。\n\n$\\widehat{m}_{N}$ 的均方误差 (MSE) 定义为\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\mathbb{E}\\big[(\\widehat{m}_{N}-m)^{2}\\big].\n$$\n根据偏差-方差分解，\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\big(\\mathbb{E}[\\widehat{m}_{N}]-m\\big)^{2}+\\mathrm{Var}(\\widehat{m}_{N}).\n$$\n在我们的理想化情景中，不存在离散化偏差，且估计量是无偏的，因此 $\\mathbb{E}[\\widehat{m}_{N}]=m$，偏差项为零。所以，\n$$\n\\mathrm{MSE}(\\widehat{m}_{N})=\\mathrm{Var}(\\widehat{m}_{N}).\n$$\n利用独立同分布的性质，样本均值的方差为\n$$\n\\mathrm{Var}(\\widehat{m}_{N})=\\mathrm{Var}\\!\\left(\\frac{1}{N}\\sum_{i=1}^{N}Y_{i}\\right)=\\frac{1}{N^{2}}\\sum_{i=1}^{N}\\mathrm{Var}(Y_{i})=\\frac{1}{N^{2}}\\cdot N\\cdot V=\\frac{V}{N}.\n$$\n均方根误差 (RMSE) 是均方误差 (MSE) 的平方根：\n$$\n\\mathrm{RMSE}(\\widehat{m}_{N})=\\sqrt{\\mathrm{MSE}(\\widehat{m}_{N})}=\\sqrt{\\frac{V}{N}}.\n$$\n设定目标 RMSE 阈值 $\\varepsilon0$ 意味着要求\n$$\n\\sqrt{\\frac{V}{N}}\\leq \\varepsilon.\n$$\n两边平方并解出 $N$，\n$$\n\\frac{V}{N}\\leq \\varepsilon^{2}\\quad\\Longleftrightarrow\\quad N\\geq \\frac{V}{\\varepsilon^{2}}.\n$$\n因为 $N$ 必须是整数，所以达到目标的最小整数样本量为\n$$\nN^{\\star}=\\left\\lceil\\frac{V}{\\varepsilon^{2}}\\right\\rceil.\n$$\n\n现在我们分析所需样本量对方法差误估的敏感性。考虑连续松弛 $N(V)=\\frac{V}{\\varepsilon^{2}}$（为进行微分分析，忽略向上取整函数）。$N$ 相对于 $V$ 的一阶敏感性是其导数\n$$\n\\frac{dN}{dV}=\\frac{d}{dV}\\left(\\frac{V}{\\varepsilon^{2}}\\right)=\\frac{1}{\\varepsilon^{2}}.\n$$\n为了量化相对敏感性，定义对数导数（弹性）\n$$\nS_{\\mathrm{rel}}(V)=\\frac{dN/N}{dV/V}=\\frac{\\frac{dN}{dV}\\cdot \\frac{1}{N}}{\\frac{1}{V}}.\n$$\n代入 $N(V)=\\frac{V}{\\varepsilon^{2}}$ 和 $\\frac{dN}{dV}=\\frac{1}{\\varepsilon^{2}}$，我们发现\n$$\nS_{\\mathrm{rel}}(V)=\\frac{\\left(\\frac{1}{\\varepsilon^{2}}\\right)\\cdot \\left(\\frac{\\varepsilon^{2}}{V}\\right)}{\\frac{1}{V}}=1.\n$$\n因此，在一阶近似下，所需（连续）样本量的相对误差等于 $V$ 的相对误差：如果 $V$ 被误估为 $V(1+\\delta)$（其中 $\\delta$ 很小），那么在不考虑向上取整函数的影响下，$N$ 将被误估为 $N(1+\\delta)$。特别是，对 $V$ 的低估会导致对所需 $N$ 的同等比例低估，这有可能违反 RMSE 约束 $\\sqrt{V/N}\\leq \\varepsilon$；而对 $V$ 的高估会按比例地过度配置 $N$，这是一种保守的做法。", "answer": "$$\\boxed{\\begin{pmatrix}\\left\\lceil \\dfrac{V}{\\varepsilon^{2}} \\right\\rceil  \\dfrac{1}{\\varepsilon^{2}}  1\\end{pmatrix}}$$", "id": "2988319"}, {"introduction": "在实践中，我们很少能对随机微分方程（SDE）的精确解进行抽样，而必须依赖像欧拉-丸山（Euler-Maruyama）这样的数值格式，但这会引入系统性误差。本练习要求你分析并计算这种数值格式的“弱偏差”，即数值解的期望与真实解期望之间的差异 [@problem_id:2988356]。通过对几何布朗运动这一基本过程的分析，你将深刻理解离散化如何影响模拟结果的准确性。", "problem": "设 $\\{X_t\\}_{t \\in [0,T]}$ 是几何布朗运动 (GBM) 随机微分方程 (SDE) 的解\n$$\ndX_t \\;=\\; \\mu\\,X_t\\,dt \\;+\\; \\sigma\\,X_t\\,dW_t, \\qquad X_0 \\;=\\; x \\;\\; 0,\n$$\n其中 $\\mu \\in \\mathbb{R}$ 和 $\\sigma \\geq 0$ 是常数，$\\{W_t\\}_{t \\geq 0}$ 是标准布朗运动。考虑使用均匀时间步长 $\\Delta t \\;=\\; T/N$（其中 $N \\geq 1$ 为某个整数）的欧拉-丸山 (EM) 时间离散化，由以下递推关系定义\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t} \\;+\\; \\mu\\,X_n^{\\Delta t}\\,\\Delta t \\;+\\; \\sigma\\,X_n^{\\Delta t}\\,\\Delta W_n, \\qquad X_0^{\\Delta t} \\;=\\; x,\n$$\n其中 $\\Delta W_n \\sim \\mathcal{N}(0,\\Delta t)$ 是独立同分布的，并且独立于 $X_0^{\\Delta t}$。一个基于EM和 $L$ 条独立模拟路径的 $\\mathbb{E}[X_T]$ 的蒙特卡罗估计量为\n$$\n\\widehat{M}_L(\\Delta t) \\;=\\; \\frac{1}{L}\\sum_{\\ell=1}^{L} X_{N}^{\\Delta t,(\\ell)},\n$$\n其中 $X_{N}^{\\Delta t,(\\ell)}$ 表示第 $\\ell$ 条路径在时间 $T$ 的终端EM近似值。\n\n仅从SDE定义、EM递推关系以及布朗运动增量的基本性质出发，推导 $\\mathbb{E}[X_{N}^{\\Delta t}]$ 作为 $\\mu$、$\\sigma$、$x$、$T$ 和 $\\Delta t$ 的函数的闭式表达式，然后为精确的GBM解推导 $\\mathbb{E}[X_T]$。使用这些结果计算基于EM的蒙特卡罗估计量的弱偏差，其定义为\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; \\mathbb{E}[X_{N}^{\\Delta t}] \\;-\\; \\mathbb{E}[X_T].\n$$\n以 $\\operatorname{bias}(\\Delta t)$ 关于 $\\mu$、$\\sigma$、$x$、$T$ 和 $\\Delta t$ 的单个闭式解析表达式的形式提供最终答案。不需要数值。", "solution": "本题要求推导几何布朗运动 (GBM) 过程的欧拉-丸山 (EM) 方法的弱偏差。弱偏差定义为 $\\operatorname{bias}(\\Delta t) = \\mathbb{E}[X_{N}^{\\Delta t}] - \\mathbb{E}[X_T]$，其中 $X_{N}^{\\Delta t}$ 是时间 $T$ 的数值解，$X_T$ 是精确解。推导将分三步进行：首先，我们计算EM近似的期望 $\\mathbb{E}[X_{N}^{\\Delta t}]$；其次，我们计算精确解的期望 $\\mathbb{E}[X_T]$；最后，我们计算它们的差值。\n\n首先，我们确定从欧拉-丸山格式获得的数值解的期望。递推关系由下式给出：\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t} \\;+\\; \\mu\\,X_n^{\\Delta t}\\,\\Delta t \\;+\\; \\sigma\\,X_n^{\\Delta t}\\,\\Delta W_n\n$$\n其中 $n = 0, 1, \\dots, N-1$。我们可以提出 $X_n^{\\Delta t}$ 得到：\n$$\nX_{n+1}^{\\Delta t} \\;=\\; X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n)\n$$\n设 $\\mathcal{F}_{t_n}$ 是由直到时间 $t_n = n\\Delta t$ 的布朗运动生成的滤子。$X_n^{\\Delta t}$ 的值在时间 $t_n$ 是已知的，因此它是 $\\mathcal{F}_{t_n}$-可测的。布朗增量 $\\Delta W_n = W_{t_{n+1}} - W_{t_n}$ 独立于 $\\mathcal{F}_{t_n}$。我们通过对 $\\mathcal{F}_{t_n}$ 取条件期望，然后应用全期望定律来计算 $X_{n+1}^{\\Delta t}$ 的期望。\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; \\mathbb{E}[X_n^{\\Delta t}(1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n) | \\mathcal{F}_{t_n}]\n$$\n由于 $X_n^{\\Delta t}$ 是 $\\mathcal{F}_{t_n}$-可测的，我们可以在条件期望中将其视为常数：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; X_n^{\\Delta t} \\,\\mathbb{E}[1 + \\mu\\,\\Delta t + \\sigma\\,\\Delta W_n | \\mathcal{F}_{t_n}]\n$$\n由于 $\\Delta W_n$ 独立于 $\\mathcal{F}_{t_n}$ 且性质 $\\mathbb{E}[\\Delta W_n] = 0$，表达式简化为：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}] \\;=\\; X_n^{\\Delta t} \\,(1 + \\mu\\,\\Delta t + \\sigma\\,\\mathbb{E}[\\Delta W_n]) \\;=\\; X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t)\n$$\n现在，使用全期望定律 $\\mathbb{E}[Y] = \\mathbb{E}[\\mathbb{E}[Y|\\mathcal{F}]]$ 对两边取无条件期望，我们得到：\n$$\n\\mathbb{E}[X_{n+1}^{\\Delta t}] \\;=\\; \\mathbb{E}[\\mathbb{E}[X_{n+1}^{\\Delta t} | \\mathcal{F}_{t_n}]] \\;=\\; \\mathbb{E}[X_n^{\\Delta t}\\,(1 + \\mu\\,\\Delta t)] \\;=\\; (1 + \\mu\\,\\Delta t)\\,\\mathbb{E}[X_n^{\\Delta t}]\n$$\n这是一个关于 $\\mathbb{E}[X_n^{\\Delta t}]$ 的递推关系。初始条件是 $\\mathbb{E}[X_0^{\\Delta t}] = \\mathbb{E}[x] = x$。我们可以通过从 $n=0$ 到 $N$ 迭代来解这个递推关系：\n$$\n\\mathbb{E}[X_N^{\\Delta t}] \\;=\\; (1 + \\mu\\,\\Delta t)^N \\mathbb{E}[X_0^{\\Delta t}] \\;=\\; x(1 + \\mu\\,\\Delta t)^N\n$$\n代入 $N = T/\\Delta t$，我们得到EM近似期望的闭式表达式：\n$$\n\\mathbb{E}[X_N^{\\Delta t}] \\;=\\; x\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t}\n$$\n\n其次，我们推导精确解 $X_T$ 的期望。SDE的微分形式为 $dX_t = \\mu X_t dt + \\sigma X_t dW_t$。其积分形式为：\n$$\nX_T \\;=\\; X_0 + \\int_0^T \\mu\\,X_t\\,dt + \\int_0^T \\sigma\\,X_t\\,dW_t\n$$\n对两边取期望，我们得到：\n$$\n\\mathbb{E}[X_T] \\;=\\; \\mathbb{E}[X_0] + \\mathbb{E}\\left[\\int_0^T \\mu\\,X_t\\,dt\\right] + \\mathbb{E}\\left[\\int_0^T \\sigma\\,X_t\\,dW_t\\right]\n$$\n我们计算右侧的每一项。初始条件给出 $\\mathbb{E}[X_0] = x$。对于漂移项，我们可以根据 Fubini 定理交换期望和黎曼积分：\n$$\n\\mathbb{E}\\left[\\int_0^T \\mu\\,X_t\\,dt\\right] \\;=\\; \\mu \\int_0^T \\mathbb{E}[X_t]\\,dt\n$$\n对于扩散项，伊藤积分的一个基本性质是其期望为零，前提是被积函数是一个满足特定可积条件的适应过程，这对于GBM SDE的解是成立的。因此：\n$$\n\\mathbb{E}\\left[\\int_0^T \\sigma\\,X_t\\,dW_t\\right] \\;=\\; 0\n$$\n将这些代回，并令 $m(t) = \\mathbb{E}[X_t]$，我们得到一个关于 $m(T)$ 的积分方程：\n$$\nm(T) \\;=\\; x + \\mu \\int_0^T m(t)\\,dt\n$$\n对 $T$ 求导，得到常微分方程 (ODE)：\n$$\n\\frac{dm(T)}{dT} \\;=\\; \\mu\\,m(T)\n$$\n初始条件为 $m(0) = \\mathbb{E}[X_0] = x$。此ODE的解为：\n$$\nm(T) \\;=\\; x\\,\\exp(\\mu T)\n$$\n因此，精确解的期望是：\n$$\n\\mathbb{E}[X_T] \\;=\\; x\\,\\exp(\\mu T)\n$$\n注意，数值解和精确解的期望都与波动率参数 $\\sigma$ 无关。\n\n最后，我们通过计算上面推导的两个期望之差来计算弱偏差：\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; \\mathbb{E}[X_{N}^{\\Delta t}] - \\mathbb{E}[X_T] \\;=\\; x\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t} - x\\,\\exp(\\mu T)\n$$\n这个表达式可以因式分解得到最终形式：\n$$\n\\operatorname{bias}(\\Delta t) \\;=\\; x\\left(\\left(1 + \\mu\\,\\Delta t\\right)^{T/\\Delta t} - \\exp(\\mu T)\\right)\n$$\n这就是弱偏差作为指定参数的函数的闭式表达式。", "answer": "$$\n\\boxed{x\\left(\\left(1 + \\mu\\Delta t\\right)^{\\frac{T}{\\Delta t}} - \\exp(\\mu T)\\right)}\n$$", "id": "2988356"}, {"introduction": "在理解了统计误差和离散化误差之后，我们可以探索一种强大的技术来协同处理这两种误差。多层蒙特卡洛（MLMC）方法通过智能地结合不同精度水平的模拟结果，革新了SDE模拟的效率。这个动手编程练习将指导你实现MLMC效率的关键——精细和粗糙模拟路径之间的“耦合”[@problem_id:2988362]。通过构建和分析这种耦合模拟，你将在最先进的方差缩减方法上获得实践技能，并亲眼见证理论上的收敛阶数如何转化为实际的计算增益。", "problem": "考虑随机微分方程 (SDE) $dX_t = a X_t \\, dt + \\sigma \\, dW_t$，其初始条件为 $X_0 = x_0$，其中 $W_t$ 是标准布朗运动，且 $a,\\sigma,x_0 \\in \\mathbb{R}$。令 $\\phi:\\mathbb{R}\\to\\mathbb{R}$ 为函数 $\\phi(x) = \\sin(x)$，该函数全局利普希茨，利普希茨常数为 $L = 1$。我们关注欧拉-丸山 (EM) 方法以及由精细和粗糙时间离散化的显式耦合构建的多层蒙特卡洛 (MLMC) 层级差分的方差缩放。该框架是纯数学的，不涉及物理单位；所有量均为无量纲。\n\n基本依据和定义：\n- 随机微分方程 (SDE) 是由一个随机过程驱动的微分方程，此处为 $dX_t = a X_t \\, dt + \\sigma \\, dW_t$，其中 $W_t$ 是一个布朗运动，其特征是具有独立的高斯增量，即 $W_{t+\\Delta t} - W_t \\sim \\mathcal{N}(0,\\Delta t)$ 且独立于过去。\n- 对于时间步长 $h0$，欧拉-丸山 (EM) 方法通过递推式 $X_{n+1}^{(h)} = X_n^{(h)} + a X_n^{(h)} h + \\sigma \\Delta W_n^{(h)}$ 来近似SDE，其中 $\\Delta W_n^{(h)} \\sim \\mathcal{N}(0,h)$ 是独立的增量。\n- 多层蒙特卡洛 (MLMC) 方法通过将多个离散化层级与一个能最小化层级差分方差的耦合相结合来估计期望值；此处，我们考虑一个两层差分 $Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$，其中 $H = 2h$。\n\n耦合指令：\n通过聚合高斯增量，在时间步长为 $h$ 的精细层级和时间步长为 $H = 2h$ 的粗糙层级之间构建一个显式耦合。具体来说，对于每个粗糙区间 $[(t_{2m}), (t_{2m+2})]$，将粗糙增量定义为 $\\Delta W_m^{(H)} := \\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}$。验证这保留了高斯定律，即 $\\Delta W_m^{(H)} \\sim \\mathcal{N}(0, H)$，并且该耦合利用了共同的随机性来减少 $Y$ 的方差。\n\n方差缩放分析目标：\n从布朗运动的基本性质和EM递推式出发，分析上述线性SDE和利普希茨支付函数 $\\phi$ 的 $\\operatorname{Var}(Y)$ 作为 $h$ 的函数的缩放性质。分析必须从定义开始，并使用经过充分检验的事实，例如布朗运动的独立增量性质以及线性系统上EM方法的标准稳定性界。不要使用任何捷径或预先声明的缩放公式；从此背景下的第一性原理推导出方差阶。\n\n算法构建要求：\n实现一个完整的程序，该程序：\n- 通过将精细增量相加形成粗糙增量来强制执行显式耦合。\n- 使用 $N=20000$ 条独立的耦合路径和固定的随机种子 $42$ 来计算蒙特卡洛估计量。\n- 对每个测试用例，计算经验方差 $\\operatorname{Var}(Y)$（使用无偏样本方差）和选定的归一化量以研究缩放性质。\n\n测试套件规范：\n使用以下科学合理的一系列参数集来测试不同方面（正常路径、边界条件和边缘情况）：\n\n1. 正常路径缩放测试：\n   - 参数：$a = -1$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1$。\n   - 精细步长：$h \\in \\{1/64, 1/128, 1/256\\}$，粗糙步长 $H = 2h$。\n   - 对每个 $h$，计算 $V(h) = \\operatorname{Var}(Y)$ 和缩放量 $S(h) = V(h)/h$。\n\n2. 缩放比例检查：\n   - 参数与正常路径相同。\n   - 计算 $R = V(1/128)/V(1/64)$ 和布尔值 $B$，该值指示 $|R - 1/2| \\leq 0.1$ 是否成立。\n\n3. 无漂移边界：\n   - 参数：$a = 0$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1$, $h = 1/64$, $H = 2h$。\n   - 计算 $V_{\\text{driftless}} = \\operatorname{Var}(Y)$。\n\n4. 确定性边界：\n   - 参数：$a = -1$, $\\sigma = 0$, $x_0 = 0.5$, $T = 1$, $h = 1/64$, $H = 2h$。\n   - 计算 $V_{\\text{det}} = \\operatorname{Var}(Y)$。\n\n5. 短时边缘情况：\n   - 参数：$a = -1$, $\\sigma = 0.7$, $x_0 = 0.5$, $T = 1/8$, $h = 1/256$, $H = 2h$。\n   - 计算 $S_{\\text{short}} = V(h)/h$。\n\n最终输出格式要求：\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，并严格按照以下顺序排列：\n$[S(1/64), S(1/128), S(1/256), R, B, V_{\\text{driftless}}, V_{\\text{det}}, S_{\\text{short}}]$。\n所有输出必须是数值浮点数或布尔值。不应打印其他任何文本。", "solution": "该问题是有效的，因为它是科学合理的、适定的和完整的。它提出了一个随机微分方程数值分析中标准但内容充实的练习。问题的核心是从第一性原理推导多层蒙特卡洛 (MLMC) 层级差分的方差缩放，然后通过数值模拟进行验证。\n\n我们给定线性随机微分方程 (SDE)，也称为奥恩斯坦-乌伦贝克过程，\n$$dX_t = a X_t \\, dt + \\sigma \\, dW_t, \\quad X_0 = x_0$$\n其中 $W_t$ 是一个标准布朗运动。我们感兴趣的是 $\\phi(X_T) = \\sin(X_T)$ 的期望值。这将使用欧拉-丸山 (EM) 方法进行估计。\n\n采用时间步长 $h$ 的EM离散化由以下递推关系给出：\n$$X_{n+1}^{(h)} = X_n^{(h)} (1 + ah) + \\sigma \\Delta W_n^{(h)}$$\n其中 $\\Delta W_n^{(h)} \\sim \\mathcal{N}(0,h)$ 是独立的随机增量。\n\n目标是分析精细近似和粗糙近似之间差分的方差，$Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$，其中粗糙时间步长为 $H = 2h$。这两种近似是通过从精细布朗增量构造粗糙布朗增量来耦合的。具体来说，在一个长度为 $H$ 的粗糙时间区间上，粗糙增量 $\\Delta W_m^{(H)}$ 是两个对应的精细增量 $\\Delta W_{2m}^{(h)}$ 和 $\\Delta W_{2m+1}^{(h)}$ 的和：\n$$\\Delta W_m^{(H)} = \\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}$$\n由于精细增量是独立同分布于 $\\mathcal{N}(0,h)$，它们的和是一个高斯随机变量，其均值为 $0+0=0$，方差为 $h+h=2h=H$。因此，$\\Delta W_m^{(H)} \\sim \\mathcal{N}(0,H)$，正确地保留了粗糙路径的统计特性。\n\n让我们将精细时间步 $t_k = kh$ 处的精细路径表示为 $\\hat{X}_k = X_{t_k}^{(h)}$，将粗糙时间步 $t'_m = mH$ 处的粗糙路径表示为 $X_m = X_{t'_m}^{(H)}$。注意 $t'_{m} = t_{2m}$。我们在粗糙网格点上分析路径之间的差值 $e_m = \\hat{X}_{2m} - X_m$ 的演化。初始差值为 $e_0 = \\hat{X}_0 - X_0 = x_0 - x_0 = 0$。\n\n粗糙路径在一步内从 $t'_m$ 演化到 $t'_{m+1}$：\n$$X_{m+1} = X_m (1+aH) + \\sigma \\Delta W_m^{(H)} = X_m (1+2ah) + \\sigma (\\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)})$$\n\n精细路径在两步内从 $t_{2m}$ 演化到 $t_{2m+2}$：\n$$\\hat{X}_{2m+1} = \\hat{X}_{2m} (1+ah) + \\sigma \\Delta W_{2m}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m+1} (1+ah) + \\sigma \\Delta W_{2m+1}^{(h)} = \\left(\\hat{X}_{2m} (1+ah) + \\sigma \\Delta W_{2m}^{(h)}\\right)(1+ah) + \\sigma \\Delta W_{2m+1}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m} (1+ah)^2 + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)}$$\n$$\\hat{X}_{2m+2} = \\hat{X}_{2m} (1+2ah+a^2h^2) + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)}$$\n\n差值 $e_{m+1} = \\hat{X}_{2m+2} - X_{m+1}$ 是：\n$$e_{m+1} = \\left[ \\hat{X}_{2m} (1+2ah+a^2h^2) + \\sigma(1+ah)\\Delta W_{2m}^{(h)} + \\sigma \\Delta W_{2m+1}^{(h)} \\right] - \\left[ X_m(1+2ah) + \\sigma (\\Delta W_{2m}^{(h)} + \\Delta W_{2m+1}^{(h)}) \\right]$$\n代入 $\\hat{X}_{2m} = X_m + e_m$ 并化简：\n$$e_{m+1} = (X_m+e_m)(1+2ah+a^2h^2) - X_m(1+2ah) + \\sigma(1+ah-1)\\Delta W_{2m}^{(h)}$$\n$$e_{m+1} = X_m(a^2h^2) + e_m(1+2ah+a^2h^2) + \\sigma a h \\Delta W_{2m}^{(h)}$$\n由于 $H=2h$，我们可以将其写为 $e_{m+1} = e_m(1+aH+O(h^2)) + \\left( X_m a^2h^2 + \\sigma a h \\Delta W_{2m}^{(h)} \\right)$。\n\n括号中的项是在第 $m$ 步引入的局部误差。它有一个 $O(h^2)$ 阶的确定性部分和一个 $h \\times (\\text{方差为 } h \\text{ 的高斯变量})$ 阶的随机部分，其大小为 $O(h^{3/2})$。该局部误差的均方由随机项主导：\n$$\\mathbb{E}\\left[ \\left( \\sigma a h \\Delta W_{2m}^{(h)} \\right)^2 \\bigg| \\mathcal{F}_{t_{2m}} \\right] = \\sigma^2 a^2 h^2 \\mathbb{E}\\left[ (\\Delta W_{2m}^{(h)})^2 \\right] = \\sigma^2 a^2 h^2 \\cdot h = \\sigma^2 a^2 h^3$$\n粗糙步数是 $M_c = T/H = T/(2h) = O(h^{-1})$。最终均方误差 $\\mathbb{E}[e_{M_c}^2] = \\mathbb{E}[(X_T^{(h)} - X_T^{(H)})^2]$ 是这些局部均方误差在所有粗糙步上累积的总和。离散的 Gronwall 论证表明，这导致了 $O(h^{-1}) \\times O(h^3) = O(h^2)$ 阶的全局均方误差。这种高阶收敛性，$\\mathbb{E}[(X_T^{(h)} - X_T^{(H)})^2] = O(h^2)$，是具有可加性或可交换噪声的SDE的一个特殊特征，对于这类SDE，欧拉-丸山格式具有 $\\beta=1$ 的强收敛阶。\n\n现在我们考虑 $Y = \\phi(X_T^{(h)}) - \\phi(X_T^{(H)})$ 的方差。支付函数 $\\phi(x) = \\sin(x)$ 是无限可微的 ($C^\\infty$) 且其导数有界。因此，我们可以对差值 $E_T = X_T^{(h)} - X_T^{(H)}$ 应用泰勒展开：\n$$Y = \\phi(X_T^{(H)} + E_T) - \\phi(X_T^{(H)}) \\approx \\phi'(X_T^{(H)}) E_T$$\n方差则为 $\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$。\n差分的平方是 $Y^2 \\approx (\\phi'(X_T^{(H)}))^2 E_T^2$。取期望，并假设支付函数的导数与误差项近似独立，我们得到：\n$$\\mathbb{E}[Y^2] \\approx \\mathbb{E}[(\\phi'(X_T^{(H)}))^2] \\mathbb{E}[E_T^2]$$\n由于 $\\mathbb{E}[E_T^2] = O(h^2)$，我们有 $\\mathbb{E}[Y^2] = O(h^2)$。EM格式的弱误差是 $O(h)$ 阶的，所以 $\\mathbb{E}[Y] = O(h)$ 且 $(\\mathbb{E}[Y])^2 = O(h^2)$。\n因此，$\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2 = O(h^2) - O(h^2) = O(h^2)$。\n\n这个理论结果，即 $\\operatorname{Var}(Y)$ 与 $h^2$ 成比例缩放，是一个关键发现。它意味着缩放量 $S(h) = \\operatorname{Var}(Y)/h$ 应按 $O(h)$ 缩放。它还意味着对于步长 $h$ 和 $h/2$ 的方差之比应为：\n$$R = \\frac{\\operatorname{Var}(Y \\text{ for } h/2)}{\\operatorname{Var}(Y \\text{ for } h)} \\approx \\frac{C (h/2)^2}{C h^2} = \\frac{1}{4}$$\n问题要求计算 $B = \\text{bool}(|R - 1/2| \\leq 0.1)$。根据我们的分析，我们预期 $R \\approx 0.25$，所以 $|0.25 - 0.5| = 0.25$，这不小于或等于 $0.1$。我们预测 $B$ 将为 `False`。\n\n对于边界情况：\n- 如果 $a=0$ (无漂移)，SDE为 $dX_t = \\sigma dW_t$。EM格式变为 $X_{n+1} = X_n + \\sigma \\Delta W_n$。通过指定的耦合，精细路径和粗糙路径在粗糙时间点上是相同的，即对于每条路径都有 $X_T^{(h)} = X_T^{(H)}$。因此，对所有路径 $Y=0$，且 $\\operatorname{Var}(Y) = 0$。\n- 如果 $\\sigma=0$ (确定性)，SDE是常微分方程(ODE) $dX_t = a X_t dt$。数值解 $X_T^{(h)}$ 和 $X_T^{(H)}$ 是确定性的但不相等的值。差值 $Y$ 是一个常数，而一个常数的样本方差为零。因此，$\\operatorname{Var}(Y) = 0$。\n\n实现将通过蒙特卡洛模拟计算这些量，并遵守指定的参数。", "answer": "```python\nimport numpy as np\n\ndef simulate_one_coupled_path(params, T, h, rng):\n    \"\"\"\n    Simulates one pair of coupled paths (fine and coarse) for the SDE.\n    dX_t = a * X_t * dt + sigma * dW_t\n\n    Args:\n        params (tuple): (a, sigma, x0)\n        T (float): Final time.\n        h (float): Fine time step.\n        rng (numpy.random.Generator): Random number generator.\n\n    Returns:\n        tuple: (x_fine, x_coarse) final values of the paths.\n    \"\"\"\n    a, sigma, x0 = params\n    H = 2 * h\n    \n    # Ensure T/h is an even integer for proper coupling.\n    # This is guaranteed by the problem statement for the given test cases.\n    num_fine_steps = int(round(T / h))\n    num_coarse_steps = num_fine_steps // 2\n\n    x_fine = float(x0)\n    x_coarse = float(x0)\n\n    sqrt_h = np.sqrt(h)\n\n    for _ in range(num_coarse_steps):\n        # Generate two fine-scale Brownian increments\n        dw1 = rng.normal(0.0, sqrt_h)\n        dw2 = rng.normal(0.0, sqrt_h)\n        \n        # Store current coarse path value for its update\n        x_coarse_prev = x_coarse\n\n        # Update fine path twice\n        x_fine = x_fine * (1 + a * h) + sigma * dw1\n        x_fine = x_fine * (1 + a * h) + sigma * dw2\n\n        # Update coarse path once using the coupled increment\n        dw_coarse = dw1 + dw2\n        x_coarse = x_coarse_prev * (1 + a * H) + sigma * dw_coarse\n\n    return x_fine, x_coarse\n\ndef compute_variance_of_difference(params, T, h, N, rng):\n    \"\"\"\n    Computes the sample variance of phi(X_T^h) - phi(X_T^H).\n    \"\"\"\n    payoff_diffs = np.zeros(N)\n    \n    for i in range(N):\n        x_fine_T, x_coarse_T = simulate_one_coupled_path(params, T, h, rng)\n        payoff_diffs[i] = np.sin(x_fine_T) - np.sin(x_coarse_T)\n        \n    # Use unbiased sample variance (ddof=1)\n    variance = np.var(payoff_diffs, ddof=1)\n    return variance\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    N = 20000\n    SEED = 42\n    rng = np.random.default_rng(seed=SEED)\n\n    results = []\n\n    # --- Test Case 1: Happy path scaling test ---\n    params_happy = (-1.0, 0.7, 0.5)\n    T_happy = 1.0\n    h_values = [1/64, 1/128, 1/256]\n    \n    variances = []\n    for h in h_values:\n        V = compute_variance_of_difference(params_happy, T_happy, h, N, rng)\n        variances.append(V)\n        S = V / h\n        results.append(S)\n\n    # --- Test Case 2: Ratio check for scaling ---\n    v_64, v_128 = variances[0], variances[1]\n    R = v_128 / v_64 if v_64 != 0 else np.nan\n    B = np.abs(R - 0.5) = 0.1\n    results.append(R)\n    results.append(B)\n\n    # --- Test Case 3: Driftless boundary ---\n    params_driftless = (0.0, 0.7, 0.5)\n    T_driftless = 1.0\n    h_driftless = 1/64\n    V_driftless = compute_variance_of_difference(params_driftless, T_driftless, h_driftless, N, rng)\n    results.append(V_driftless)\n\n    # --- Test Case 4: Deterministic boundary ---\n    params_det = (-1.0, 0.0, 0.5)\n    T_det = 1.0\n    h_det = 1/64\n    V_det = compute_variance_of_difference(params_det, T_det, h_det, N, rng)\n    results.append(V_det)\n\n    # --- Test Case 5: Short-time edge case ---\n    params_short = (-1.0, 0.7, 0.5)\n    T_short = 1/8\n    h_short = 1/256\n    V_short = compute_variance_of_difference(params_short, T_short, h_short, N, rng)\n    S_short = V_short / h_short\n    results.append(S_short)\n    \n    # Format and print the final output\n    # Ensure boolean is lowercase 'true'/'false' as per Python's str()\n    formatted_results = [f\"{r}\".lower() if isinstance(r, bool) else f\"{r}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "2988362"}]}