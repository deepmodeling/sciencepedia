{"hands_on_practices": [{"introduction": "要理解张量分解，第一步是掌握如何分析张量的内在结构。一种强大的技术是“矩阵化”（matricization）或称“展开”（unfolding），它将高阶张量重塑为矩阵，从而使我们能够运用成熟的矩阵分析工具。这项练习将引导你计算一个张量的多线性秩（multilinear rank），这是理解张量特性并应用于塔克（Tucker）分解等方法的关键实践。[@problem_id:1542439]", "problem": "在张量分析中，一个高阶张量可以通过一个称为矩阵化或展开的过程表示成矩阵形式。这使得可以应用标准的矩阵分析工具来理解张量的性质。其中一个性质就是多线性秩。\n\n考虑一个三阶张量 $T \\in \\mathbb{R}^{2 \\times 3 \\times 4}$。$T$ 的元素记为 $t_{ijk}$，其中 $i \\in \\{1,2\\}$，$j \\in \\{1,2,3\\}$，$k \\in \\{1,2,3,4\\}$，由其四个额状切片 $F_k = T(:,:,k) \\in \\mathbb{R}^{2 \\times 3}$ 给出：\n\n$F_1 = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\end{pmatrix}$\n\n$F_2 = \\begin{pmatrix} 0  1  1 \\\\ 1  -1  0 \\end{pmatrix}$\n\n$F_3 = \\begin{pmatrix} 2  1  3 \\\\ 1  0  1 \\end{pmatrix}$\n\n$F_4 = \\begin{pmatrix} 1  1  2 \\\\ 1  0  1 \\end{pmatrix}$\n\n张量 $T$ 可以以三种主要方式进行矩阵化，分别对应其每个模。对于一个大小为 $I_1 \\times I_2 \\times I_3$ 的张量：\n- 模-1 矩阵化 $T_{(1)}$ 是一个大小为 $I_1 \\times (I_2 I_3)$ 的矩阵，其行是向量化后的水平切片 $T(i,:,:)$。\n- 模-2 矩阵化 $T_{(2)}$ 是一个大小为 $I_2 \\times (I_1 I_3)$ 的矩阵，其行是向量化后的侧向切片 $T(:,j,:)$。\n- 模-3 矩阵化 $T_{(3)}$ 是一个大小为 $I_3 \\times (I_1 I_2)$ 的矩阵，其行是向量化后的额状切片 $T(:,:,k)$。\n\n为了进行向量化，一个矩阵通过将其列按顺序堆叠来进行展平。例如，对于矩阵 $M = \\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$，其向量化为 $\\text{vec}(M) = \\begin{pmatrix} a \\\\ c \\\\ b \\\\ d \\end{pmatrix}$。\n\n张量 $T$ 的多线性秩定义为其各个矩阵化的秩组成的元组 $(R_1, R_2, R_3)$，其中 $R_n = \\text{rank}(T_{(n)})$。\n\n计算给定张量 $T$ 的多线性秩 $(R_1, R_2, R_3)$。将你的答案表示为一个包含三个整数元素的行矩阵。", "solution": "我们已知一个三阶张量 $T \\in \\mathbb{R}^{2 \\times 3 \\times 4}$，它由其额状切片 $F_{k} = T(:,:,k) \\in \\mathbb{R}^{2 \\times 3}$ 给出，其中向量化定义为堆叠矩阵的列。多线性秩为 $(R_{1},R_{2},R_{3})$，其中 $R_{n} = \\operatorname{rank}(T_{(n)})$。\n\n模-3 矩阵化 $T_{(3)}$ 的大小为 $I_{3} \\times (I_{1} I_{2}) = 4 \\times 6$，其第 $k$ 行为 $\\operatorname{vec}(F_{k})^{\\top}$。计算这四个向量：\n$$\n\\operatorname{vec}(F_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ 0 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{3}) = \\begin{pmatrix} 2 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 3 \\\\ 1 \\end{pmatrix},\\quad\n\\operatorname{vec}(F_{4}) = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\n观察到 $F_{4} = F_{1} + F_{2}$，因此 $\\operatorname{vec}(F_{4}) = \\operatorname{vec}(F_{1}) + \\operatorname{vec}(F_{2})$，所以 $\\operatorname{rank}(T_{(3)}) \\leq 3$。为检验 $\\operatorname{vec}(F_{1}), \\operatorname{vec}(F_{2}), \\operatorname{vec}(F_{3})$ 是否线性无关，假设 $a\\,F_{1} + b\\,F_{2} + c\\,F_{3} = 0$。逐个查看位置 $(2,2)$、$(1,1)$ 和 $(2,1)$ 上的元素，可得\n$$\na - b = 0,\\quad a + 2c = 0,\\quad b + c = 0.\n$$\n由 $a=b$ 和 $b = -c$，我们得到 $a = -c$，然后 $a + 2c = 0$ 给出 $c = 0$，因此 $a=b=0$。因此，这三者是线性无关的，所以 $R_{3} = \\operatorname{rank}(T_{(3)}) = 3$。\n\n模-1 矩阵化 $T_{(1)}$ 的大小为 $I_{1} \\times (I_{2} I_{3}) = 2 \\times 12$，其第 $i$ 行等于 $\\operatorname{vec}(T(i,:,:))^{\\top}$。对于 $i=1$，构造 $M_{1} = T(1,:,:) \\in \\mathbb{R}^{3 \\times 4}$，其第 $k$ 列是 $F_k$ 第一行的转置：\n$$\nM_{1} = \\begin{pmatrix}\n1  0  2  1 \\\\\n0  1  1  1 \\\\\n1  1  3  2\n\\end{pmatrix},\\quad\n\\operatorname{vec}(M_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 2 \\\\ 1 \\\\ 3 \\\\ 1 \\\\ 1 \\\\ 2 \\end{pmatrix}.\n$$\n对于 $i=2$，构造 $M_{2} = T(2,:,:) \\in \\mathbb{R}^{3 \\times 4}$，其第 $k$ 列是 $F_k$ 第二行的转置：\n$$\nM_{2} = \\begin{pmatrix}\n0  1  1  1 \\\\\n1  -1  0  0 \\\\\n1  0  1  1\n\\end{pmatrix},\\quad\n\\operatorname{vec}(M_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n$T_{(1)}$ 的两个行向量是 $\\operatorname{vec}(M_{1})^{\\top}$ 和 $\\operatorname{vec}(M_{2})^{\\top}$。它们不成比例，因为它们的第一个分量不同（$1$ 对 $0$）。因此 $R_{1} = \\operatorname{rank}(T_{(1)}) = 2$。\n\n模-2 矩阵化 $T_{(2)}$ 的大小为 $I_{2} \\times (I_{1} I_{3}) = 3 \\times 8$，其第 $j$ 行等于 $\\operatorname{vec}(T(:,j,:))^{\\top}$。对于每个 $j$，$T(:,j,:)$ 是一个 $2 \\times 4$ 的矩阵，其第 $k$ 列是 $F_k$ 的第 $j$ 列。因此：\n$$\nA_{1} = T(:,1,:) = \\begin{pmatrix} 1  0  2  1 \\\\ 0  1  1  1 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{1}) = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 2 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix},\n$$\n$$\nA_{2} = T(:,2,:) = \\begin{pmatrix} 0  1  1  1 \\\\ 1  -1  0  0 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{2}) = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\\\ -1 \\\\ 1 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix},\n$$\n$$\nA_{3} = T(:,3,:) = \\begin{pmatrix} 1  1  3  2 \\\\ 1  0  1  1 \\end{pmatrix},\\quad\n\\operatorname{vec}(A_{3}) = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 0 \\\\ 3 \\\\ 1 \\\\ 2 \\\\ 1 \\end{pmatrix}.\n$$\n我们有 $A_{3} = A_{1} + A_{2}$，因此 $\\operatorname{vec}(A_{3}) = \\operatorname{vec}(A_{1}) + \\operatorname{vec}(A_{2})$，所以 $\\operatorname{rank}(T_{(2)}) \\leq 2$。由于 $\\operatorname{vec}(A_{1})$ 和 $\\operatorname{vec}(A_{2})$ 不成比例（它们的第一个元素分别是 $1$ 和 $0$），所以它们是线性无关的。因此 $R_{2} = \\operatorname{rank}(T_{(2)}) = 2$。\n\n汇总这三个秩，得到多线性秩元组 $(R_{1}, R_{2}, R_{3}) = (2, 2, 3)$。", "answer": "$$\\boxed{\\begin{pmatrix} 2  2  3 \\end{pmatrix}}$$", "id": "1542439"}, {"introduction": "与塔克分解不同，CANDECOMP/PARAFAC (CP) 分解将张量建模为一系列秩-1张量之和。在这种分解方法中，Khatri-Rao积是一个核心运算，它能够以简洁的矩阵形式表示CP模型。通过完成这项练习，你将熟练掌握这一关键运算，这对于理解和实现CP分解算法至关重要。[@problem_id:1542398]", "problem": "在张量分析中，按列 Khatri-Rao 积是一种基本运算，用于各种张量分解方法，例如 CANDECOMP/PARAFAC (CP) 分解。\n\n考虑两个实值矩阵 $B$ 和 $C$，由下式给出：\n$$\nB = \\begin{pmatrix} 1  5 \\\\ 2  0 \\\\ 3  1 \\end{pmatrix}\n$$\n和\n$$\nC = \\begin{pmatrix} 4  2 \\\\ 6  3 \\\\ 7  8 \\end{pmatrix}\n$$\n\n计算它们的按列 Khatri-Rao 积，记为 $A = C \\odot B$。", "solution": "两个具有相同列数的矩阵的按列 Khatri-Rao 积定义如下：如果 $B \\in \\mathbb{R}^{I \\times K}$ 且 $C \\in \\mathbb{R}^{J \\times K}$，那么 $C \\odot B \\in \\mathbb{R}^{IJ \\times K}$ 的各列由 $(C \\odot B)_{: , k} = c_{k} \\otimes b_{k}$ 给出，其中 $k = 1, \\ldots, K$，$\\otimes$ 表示 Kronecker 积。\n\n已知\n$$\nB = \\begin{pmatrix} 1  5 \\\\ 2  0 \\\\ 3  1 \\end{pmatrix}, \\quad\nC = \\begin{pmatrix} 4  2 \\\\ 6  3 \\\\ 7  8 \\end{pmatrix},\n$$\n两个矩阵都有 $K = 2$ 列，所以 $A = C \\odot B \\in \\mathbb{R}^{9 \\times 2}$。\n\n使用 $c_{1} = \\begin{pmatrix} 4 \\\\ 6 \\\\ 7 \\end{pmatrix}$ 和 $b_{1} = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$ 计算第一列：\n$$\nc_{1} \\otimes b_{1} = \\begin{pmatrix} 4 b_{1} \\\\ 6 b_{1} \\\\ 7 b_{1} \\end{pmatrix}\n= \\begin{pmatrix} 4 \\\\ 8 \\\\ 12 \\\\ 6 \\\\ 12 \\\\ 18 \\\\ 7 \\\\ 14 \\\\ 21 \\end{pmatrix}.\n$$\n\n使用 $c_{2} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 8 \\end{pmatrix}$ 和 $b_{2} = \\begin{pmatrix} 5 \\\\ 0 \\\\ 1 \\end{pmatrix}$ 计算第二列：\n$$\nc_{2} \\otimes b_{2} = \\begin{pmatrix} 2 b_{2} \\\\ 3 b_{2} \\\\ 8 b_{2} \\end{pmatrix}\n= \\begin{pmatrix} 10 \\\\ 0 \\\\ 2 \\\\ 15 \\\\ 0 \\\\ 3 \\\\ 40 \\\\ 0 \\\\ 8 \\end{pmatrix}.\n$$\n\n将这些列组合起来得到\n$$\nA = C \\odot B = \\begin{pmatrix}\n4  10 \\\\\n8  0 \\\\\n12  2 \\\\\n6  15 \\\\\n12  0 \\\\\n18  3 \\\\\n7  40 \\\\\n14  0 \\\\\n21  8\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}\n4  10 \\\\\n8  0 \\\\\n12  2 \\\\\n6  15 \\\\\n12  0 \\\\\n18  3 \\\\\n7  40 \\\\\n14  0 \\\\\n21  8\n\\end{pmatrix}}$$", "id": "1542398"}, {"introduction": "在了解了张量分解的基本构造模块之后，一个自然而然的问题是：我们如何实际计算出这些分解量？这项练习将带你探索张量幂法（tensor power method），这是一种类似于矩阵幂法的迭代算法，用于寻找对称张量的主要秩-1分量。通过推导该算法的核心步骤，你将深入了解支撑张量分解的优化原理。[@problem_id:1542377]", "problem": "在高阶数据分析中，一个三阶张量 $T \\in \\mathbb{R}^{d \\times d \\times d}$ 可以模拟数据集内部的三向关系。我们考虑一个完全对称的张量 $T$，这意味着其分量在索引的任何排列下都是不变的，即 $T_{ijk} = T_{ikj} = T_{jik}$ 等。\n\n一个基本任务是找到 $T$ 的主秩-1分量。这涉及到通过一个形如 $\\lambda(u \\otimes u \\otimes u)$ 的秩-1张量来找到 $T$ 的最佳近似，其中 $u \\in \\mathbb{R}^d$ 是一个单位向量 ($\\|u\\|_2=1$)，$\\lambda$ 是一个标量，而 $\\otimes$ 表示外积。这个秩-1张量的分量由 $(\\lambda(u \\otimes u \\otimes u))_{ijk} = \\lambda u_i u_j u_k$ 给出。\n\n提供最佳近似的向量 $u$ 是在约束条件 $\\|u\\|_2 = 1$ 下，最大化目标函数 $f(u) = \\sum_{i,j,k=1}^{d} T_{ijk} u_i u_j u_k$ 的向量。这个约束优化问题的驻点满足非线性特征值方程 $T(u,u) = \\lambda u$，其中 $T(u,u)$ 是一个向量，其第 $i$ 个分量由双重缩并定义为 $(T(u,u))_i = \\sum_{j,k=1}^{d} T_{ijk} u_j u_k$。\n\n这个方程启发了一种简单的迭代算法，类似于矩阵幂法，用于找到“主”特征向量 $u$。从一个随机的初始单位向量 $u_0$ 开始，该算法通过以下两步过程生成一个向量序列：\n1.  计算下一步的未归一化向量：$v_{k+1} = \\text{operation}(T, u_k)$\n2.  归一化向量：$u_{k+1} = \\frac{v_{k+1}}{\\|v_{k+1}\\|_2}$\n\n根据非线性特征值方程 $T(u,u) = \\lambda u$ 的结构，确定步骤1中未归一化向量 $v_{k+1}$ 的表达式。用张量 $T$ 的分量（例如，$T_{ijl}$）和上一步的向量 $u_k$ 的分量（例如，$(u_k)_j$）来表示该向量的第 $i$ 个分量 $(v_{k+1})_i$。", "solution": "我们通过在约束条件 $\\|u\\|_{2} = 1$ 下最大化 $f(u) = \\sum_{i,j,k=1}^{d} T_{ijk} u_{i} u_{j} u_{k}$ 来寻找一个完全对称张量 $T \\in \\mathbb{R}^{d \\times d \\times d}$ 的主秩-1分量。这个约束优化的驻点满足非线性特征值方程 $T(u,u) = \\lambda u$，其中 $T(u,u)$ 表示 $T$ 与 $u$ 在两个模态上的双重缩并，其分量为\n$$\n\\big(T(u,u)\\big)_{i} = \\sum_{j=1}^{d} \\sum_{k=1}^{d} T_{ijk} u_{j} u_{k}.\n$$\n这可由拉格朗日函数 $L(u,\\mu) = f(u) - \\mu(u^{\\top}u - 1)$ 推导得出，其梯度条件给出 $\\nabla f(u) = 2 \\mu u$。利用 $T$ 的对称性，$f$ 的梯度为\n$$\n\\frac{\\partial f}{\\partial u_{i}} = 3 \\sum_{j=1}^{d} \\sum_{k=1}^{d} T_{ijk} u_{j} u_{k} = 3 \\big(T(u,u)\\big)_{i},\n$$\n从而得到 $T(u,u) = \\lambda u$，其中 $\\lambda = \\frac{2}{3}\\mu$。\n\n类似幂法的迭代通过在当前迭代值 $u_k$ 处计算该特征方程的左侧，然后进行归一化来模仿该方程。因此，未归一化的更新是 $T$ 与 $u_k$ 的双重缩并：\n$$\nv_{k+1} = T(u_{k}, u_{k}),\n$$\n其第 $i$ 个分量通过对第二和第三个索引进行缩并得到：\n$$\n(v_{k+1})_{i} = \\sum_{j=1}^{d} \\sum_{l=1}^{d} T_{ijl} (u_{k})_{j} (u_{k})_{l}.\n$$\n因为 $T$ 是完全对称的，所以选择哪两个索引进行缩并是无关紧要的，上述表达式是未归一化更新的标准形式。", "answer": "$$\\boxed{\\sum_{j=1}^{d}\\sum_{l=1}^{d} T_{ijl}\\,(u_{k})_{j}\\,(u_{k})_{l}}$$", "id": "1542377"}]}