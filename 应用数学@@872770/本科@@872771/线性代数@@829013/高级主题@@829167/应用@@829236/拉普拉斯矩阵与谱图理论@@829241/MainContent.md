## 引言
在数字时代，从社交网络、通信系统到[生物分子结构](@entry_id:169093)，各种复杂的连接关系都可以被抽象为图。然而，仅仅画出这些图并不足以揭示其深层的组织原则和行为模式。我们如何才能从数学上量化一个网络的“连通性”有多强，或者自动识别出其中紧密联系的“社群”？这正是[谱图论](@entry_id:150398)（spectral graph theory）试图回答的问题，而其核心工具，便是**[拉普拉斯矩阵](@entry_id:152110)**。

本文旨在系统性地介绍[拉普拉斯矩阵](@entry_id:152110)及其在[图分析](@entry_id:750011)中的核心作用。我们将跨越图论与线性代数的边界，展示如何通过分析一个矩阵的[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)来“听”出图的形状与结构。无论您是计算机科学、物理学还是工程学的学生，理解拉普拉斯矩阵都将为您提供一个分析网络化系统的强大视角。

为帮助读者循序渐进地掌握这一主题，本文将分为三个核心部分：
- 在“**原理与机制**”一章中，我们将从[拉普拉斯矩阵](@entry_id:152110)的定义出发，深入探讨其关键的代数性质，如[半正定性](@entry_id:147720)，并揭示其谱（[特征值](@entry_id:154894)）与图的连通分量、[代数连通度](@entry_id:152762)之间的深刻联系。
- 接下来，在“**应用与[交叉](@entry_id:147634)学科联系**”一章中，我们将展示这些理论如何在现实世界中大放异彩，涵盖从数据科学中的谱聚类，到物理系统中的[同步现象](@entry_id:201511)，再到网络科学中的鲁棒性分析等多个领域。
- 最后，“**动手实践**”部分将提供一系列精心设计的问题，引导您亲手计算和分析[拉普拉斯谱](@entry_id:275024)，将抽象的理论转化为具体的分析技能。

让我们一同开始，探索[拉普拉斯矩阵](@entry_id:152110)如何成为解读[复杂网络](@entry_id:261695)奥秘的钥匙。

## 原理与机制

在上一章中，我们初步探讨了如何使用图来为各种网络和系统建模。现在，我们将深入研究一种功能强大的代数工具——**[拉普拉斯矩阵](@entry_id:152110)**（Laplacian matrix），它是连接图论和线性代数的桥梁。通过分析拉普拉斯矩阵的谱（即其[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)），我们可以揭示关于图的深层结构信息，例如其连通性、瓶颈和社[群结构](@entry_id:146855)。这一领域被称为**[谱图论](@entry_id:150398)**（spectral graph theory）。本章将系统地阐述[拉普拉斯矩阵](@entry_id:152110)的定义、核心性质及其谱特性背后的原理。

### 图拉普拉斯矩阵的定义

为了从代数上捕捉图的结构，我们通常从两个[基本矩阵](@entry_id:275638)开始：**[邻接矩阵](@entry_id:151010)**（adjacency matrix）和**度矩阵**（degree matrix）。考虑一个具有 $n$ 个顶点的简单[无向图](@entry_id:270905) $G=(V, E)$，其中 $V = \{v_1, v_2, \dots, v_n\}$ 是顶点集，$E$ 是[边集](@entry_id:267160)。

- **邻接矩阵** $A$ 是一个 $n \times n$ 的矩阵，其元素 $A_{ij}$ 定义为：如果顶点 $v_i$ 和 $v_j$ 之间存在一条边，则 $A_{ij} = 1$；否则 $A_{ij} = 0$。对于简单图，对角[线元](@entry_id:196833)素 $A_{ii}$ 始终为 0。

- **度矩阵** $D$ 是一个 $n \times n$ 的[对角矩阵](@entry_id:637782)，其中对角线元素 $D_{ii}$ 等于顶点 $v_i$ 的度（degree），即与该顶点相连的边的数量，记作 $\deg(v_i)$。所有非对角线元素均为 0。

基于这两个矩阵，**图拉普拉斯矩阵** $L$ 被定义为它们的差：
$$
L = D - A
$$
这个定义初看起来可能有些随意，但我们将很快发现，这种构造方式巧妙地编码了图的连通结构。

让我们通过一个具体的例子来构建拉普拉斯矩阵。考虑一个由四个粒子组成的系统，它们以线性链的方式连接：粒子1与2相连，2与1和3相连，3与2和4相连，4只与3相连。这个系统可以被建模为一个4个顶点的路径图（Path Graph $P_4$）[@problem_id:1371459]。

首先，我们写出其邻接矩阵 $A$ 和度矩阵 $D$。
顶点1、2、3、4的度分别为1、2、2、1。因此，度矩阵 $D$ 为：
$$
D=\begin{pmatrix}
1  & 0  & 0  & 0 \\
0  & 2  & 0  & 0 \\
0  & 0  & 2  & 0 \\
0  & 0  & 0  & 1
\end{pmatrix}
$$
邻接矩阵 $A$ 描述了顶点间的连接关系：
$$
A=\begin{pmatrix}
0  & 1  & 0  & 0 \\
1  & 0  & 1  & 0 \\
0  & 1  & 0  & 1 \\
0  & 0  & 1  & 0
\end{pmatrix}
$$
根据定义 $L = D - A$，我们逐元素相减得到该图的[拉普拉斯矩阵](@entry_id:152110)：
$$
L = \begin{pmatrix}
1  & 0  & 0  & 0 \\
0  & 2  & 0  & 0 \\
0  & 0  & 2  & 0 \\
0  & 0  & 0  & 1
\end{pmatrix}
-
\begin{pmatrix}
0  & 1  & 0  & 0 \\
1  & 0  & 1  & 0 \\
0  & 1  & 0  & 1 \\
0  & 0  & 1  & 0
\end{pmatrix}
=
\begin{pmatrix}
1  & -1  & 0  & 0 \\
-1  & 2  & -1  & 0 \\
0  & -1  & 2  & -1 \\
0  & 0  & -1  & 1
\end{pmatrix}
$$
观察这个矩阵的结构，我们可以得到一些初步的直觉。对角线元素 $L_{ii} = \deg(v_i)$，而非对角[线元](@entry_id:196833)素 $L_{ij}$ 在 $v_i$ 和 $v_j$ 相邻时为 -1，否则为 0。这种结构并非巧合，而是拉普拉斯矩阵所有重要性质的根源。

### 拉普拉斯矩阵的基本性质

拉普拉斯矩阵拥有一系列优美的性质，这些性质使其成为分析图结构的理想工具。

#### 行和、零[特征值](@entry_id:154894)与平凡[特征向量](@entry_id:151813)

拉普拉斯矩阵最直接的一个性质是其**每一行的元素之和都为零**。我们可以很容易地证明这一点。对于第 $i$ 行，其行和为：
$$
\sum_{j=1}^{n} L_{ij} = L_{ii} + \sum_{j \neq i} L_{ij}
$$
根据定义，$L_{ii} = \deg(v_i)$，而对于 $j \neq i$，$L_{ij} = -A_{ij}$。因此，
$$
\sum_{j=1}^{n} L_{ij} = \deg(v_i) - \sum_{j \neq i} A_{ij}
$$
由于 $\sum_{j \neq i} A_{ij}$ 正是与顶点 $v_i$ 相邻的顶点数量，这恰好是 $v_i$ 的度 $\deg(v_i)$。所以，
$$
\sum_{j=1}^{n} L_{ij} = \deg(v_i) - \deg(v_i) = 0
$$
这个性质有一个重要的线性代数推论。考虑一个所有分量都为1的列向量 $\mathbf{1} = \begin{pmatrix} 1 & 1 & \dots & 1 \end{pmatrix}^T$。当我们计算乘积 $L\mathbf{1}$ 时，结果向量的第 $i$ 个分量正是 $L$ 的第 $i$ 行元素之和。由于所有行和都为0，我们得到：
$$
L\mathbf{1} = \mathbf{0}
$$
其中 $\mathbf{0}$ 是[零向量](@entry_id:156189)。根据[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)的定义 ($M\mathbf{v} = \lambda\mathbf{v}$)，这个等式表明 $\lambda_1 = 0$ 始终是拉普拉斯矩阵的一个[特征值](@entry_id:154894)，而全1向量 $\mathbf{1}$ 是其对应的[特征向量](@entry_id:151813)。这个[特征值](@entry_id:154894)和[特征向量](@entry_id:151813)通常被称为图的**平凡[特征值](@entry_id:154894)**和**平凡[特征向量](@entry_id:151813)**，因为它们不依赖于图的具体结构，对任何图都存在 [@problem_id:1371394]。

这个性质在分析中非常有用。例如，如果我们考虑一个算子 $M = L + cI$，其中 $c$ 是常数，$I$ 是[单位矩阵](@entry_id:156724)，并将其作用于均匀[状态向量](@entry_id:154607) $\mathbf{u} = \mathbf{1}$，我们会发现 $M\mathbf{u} = (L+cI)\mathbf{u} = L\mathbf{u} + cI\mathbf{u} = \mathbf{0} + c\mathbf{u} = c\mathbf{u}$。这表明 $\mathbf{1}$ 也是 $M$ 的一个[特征向量](@entry_id:151813)，其[特征值](@entry_id:154894)为 $c$ [@problem_id:1371449]。

#### 对称性与[半正定性](@entry_id:147720)：拉普拉斯二次型

对于[无向图](@entry_id:270905)，其[邻接矩阵](@entry_id:151010) $A$ 是对称的（$A=A^T$），度矩阵 $D$ 是对角矩阵，因此也是对称的。所以，拉普拉斯矩阵 $L = D - A$ 也是一个**[对称矩阵](@entry_id:143130)**（$L=L^T$）。根据[谱理论](@entry_id:275351)，[对称矩阵](@entry_id:143130)的所有[特征值](@entry_id:154894)都是实数，并且其[特征向量](@entry_id:151813)可以构成一组正交基。

一个更深刻的性质是，拉普拉斯矩阵是**半正定的**（positive semidefinite）。这意味着对于任何非[零向量](@entry_id:156189) $\mathbf{x} \in \mathbb{R}^n$，其对应的**二次型**（quadratic form）$\mathbf{x}^T L \mathbf{x}$ 总是非负的，即 $\mathbf{x}^T L \mathbf{x} \ge 0$。这个性质保证了 $L$ 的所有[特征值](@entry_id:154894) $\lambda_i \ge 0$。

为了证明这一点，并理解其物理意义，我们来展开二次型 $\mathbf{x}^T L \mathbf{x}$：
$$
\mathbf{x}^T L \mathbf{x} = \mathbf{x}^T (D - A) \mathbf{x} = \mathbf{x}^T D \mathbf{x} - \mathbf{x}^T A \mathbf{x}
$$
第一项是 $\mathbf{x}^T D \mathbf{x} = \sum_{i=1}^n D_{ii} x_i^2 = \sum_{i=1}^n \deg(v_i) x_i^2$。
第二项是 $\mathbf{x}^T A \mathbf{x} = \sum_{i=1}^n \sum_{j=1}^n A_{ij} x_i x_j$。由于图是无向的，$A_{ij}=A_{ji}$，我们可以将这个和写为 $\sum_{(i,j) \in E} 2x_i x_j$，其中求和遍历图中每条无向边一次。
将两项合并，并将 $\deg(v_i)$ 写成 $\sum_{j: (i,j)\in E} 1$，我们得到一个非常优美的恒等式：
$$
\begin{align*}
\mathbf{x}^T L \mathbf{x}  &= \sum_{i=1}^n \deg(v_i) x_i^2 - \sum_{(i,j) \in E} 2x_i x_j \\
 &= \sum_{(i,j) \in E} (x_i^2 + x_j^2) - \sum_{(i,j) \in E} 2x_i x_j \\
 &= \sum_{(i,j) \in E} (x_i - x_j)^2
\end{align*}
$$
这个恒等式是[谱图论](@entry_id:150398)的基石之一 [@problem_id:1371428] [@problem_id:1371446]。它表明，拉普拉斯二次型等于对图中每条边的两个端点上的 $x_i$ 值之差的平方求和。如果我们将向量 $\mathbf{x}$ 想象为在每个顶点上的一个信号或[势能](@entry_id:748988)值，那么 $\mathbf{x}^T L \mathbf{x}$ 就度量了整个网络中信号的总“变异”或“张力”。

由于 $(x_i - x_j)^2$ 永远是非负的，它们的和也必然非负。因此，$\mathbf{x}^T L \mathbf{x} \ge 0$ 对所有 $\mathbf{x}$ 成立，证明了 $L$ 是半正定的。例如，对于一个[中心顶点](@entry_id:264579)为1的5顶点[星形图](@entry_id:271558)，其[边集](@entry_id:267160)为 $\{(1,2), (1,3), (1,4), (1,5)\}$。如果我们给定一个向量 $\mathbf{x}$，那么其二次型可以直接通过计算 $(x_1-x_2)^2 + (x_1-x_3)^2 + (x_1-x_4)^2 + (x_1-x_5)^2$ 得到，而无需显式地构建和乘以矩阵 $L$ [@problem_id:1371428]。

### 另一种构建方式：[关联矩阵](@entry_id:263683)

除了 $L=D-A$ 之外，还有一种更基本的方式来构造[拉普拉斯矩阵](@entry_id:152110)，即通过**[关联矩阵](@entry_id:263683)**（incidence matrix）。这种方法不仅为 $L$ 的[半正定性](@entry_id:147720)提供了另一种优雅的证明，还揭示了它与[网络流](@entry_id:268800)和[微分几何](@entry_id:145818)的深刻联系。

首先，我们需要为图 $G$ 的每条边任意指定一个方向，将其变为一个有向图。注意，这个方向只是为了计算方便，最终得到的[拉普拉斯矩阵](@entry_id:152110)与我们如何选择方向无关。对于一个有 $n$ 个顶点和 $m$ 条边的图，其**[有向关联矩阵](@entry_id:274962)** $B$ 是一个 $n \times m$ 的矩阵，其元素 $B_{ie}$ 定义如下：
- 如果顶点 $v_i$ 是边 $e$ 的终点（箭头指向它），则 $B_{ie} = 1$。
- 如果顶点 $v_i$ 是边 $e$ 的起点（箭头离开它），则 $B_{ie} = -1$。
- 如果顶点 $v_i$ 与边 $e$ 无关，则 $B_{ie} = 0$。

现在，我们来计算矩阵乘积 $BB^T$。这是一个 $n \times n$ 的矩阵。其对角[线元](@entry_id:196833)素 $(BB^T)_{ii}$ 是 $B$ 的第 $i$ 行与自身的[点积](@entry_id:149019)。$B$ 的第 $i$ 行的非零元素对应于与顶点 $v_i$ 相关联的边，这些元素的值是 $+1$ 或 $-1$。因此，$(BB^T)_{ii}$ 的值等于与 $v_i$ 相连的边的数量，即 $\deg(v_i)$。

对于非对角[线元](@entry_id:196833)素 $(BB^T)_{ij}$（其中 $i \neq j$），它是 $B$ 的第 $i$ 行和第 $j$ 行的[点积](@entry_id:149019)。这个[点积](@entry_id:149019)只有在存在一条边 $e$ 同时连接顶点 $v_i$ 和 $v_j$ 时才可能非零。在这种情况下，对于边 $e$ 所在的列，第 $i$ 行和第 $j$ 行的元素一个是 $+1$，另一个是 $-1$。它们的乘积是 $-1$。如果有多条边连接 $v_i$ 和 $v_j$（在[多重图](@entry_id:261576)中），则会累加。对于[简单图](@entry_id:274882)，$(BB^T)_{ij} = -1$。如果 $v_i$ 和 $v_j$ 之间没有边，则[点积](@entry_id:149019)为0。

综上所述，我们发现：
$$
(BB^T)_{ij} = 
\begin{cases} 
\deg(v_i) & \text{if } i = j \\
-1 & \text{if } (v_i, v_j) \in E \\
0 & \text{otherwise}
\end{cases}
$$
这正是拉普拉斯矩阵 $L$ 的定义！因此，我们得到了一个重要的关系：
$$
L = BB^T
$$
我们可以用一个3-环图（$C_3$）来验证这一点 [@problem_id:1371430]。如果我们任意定向边为 $v_1 \to v_2$, $v_2 \to v_3$, $v_3 \to v_1$，其[关联矩阵](@entry_id:263683) $B$ 和 $L=BB^T$ 的计算结果将与 $D-A$ 的结果完全一致。

这个关系 $L = BB^T$ 立即为我们提供了 $L$ 是对称且半正定的另一个证明。对称性是显然的，因为 $(BB^T)^T = (B^T)^T B^T = BB^T$。[半正定性](@entry_id:147720)则可以通过二次型看出：
$$
\mathbf{x}^T L \mathbf{x} = \mathbf{x}^T (BB^T) \mathbf{x} = (\mathbf{x}^T B) (B^T \mathbf{x}) = (B^T \mathbf{x})^T (B^T \mathbf{x}) = \|B^T \mathbf{x}\|^2 \ge 0
$$
这里 $\| \cdot \|$ 表示[欧几里得范数](@entry_id:172687)。这表明二次型是一个[向量的范数](@entry_id:154882)平方，因此永远是非负的。

### [拉普拉斯谱](@entry_id:275024)：揭示图的结构

[拉普拉斯矩阵](@entry_id:152110)的谱，即其[特征值](@entry_id:154894)集合 $\sigma(L) = \{\lambda_1, \lambda_2, \dots, \lambda_n\}$，编码了关于图的拓扑结构的丰富信息。由于 $L$ 是对称半正定的，其[特征值](@entry_id:154894)都是非负实数，我们通常按升序[排列](@entry_id:136432)它们：$0 = \lambda_1 \le \lambda_2 \le \dots \le \lambda_n$。

#### 零[特征值](@entry_id:154894)的重数与图的[连通分量](@entry_id:141881)

我们已经知道 $\lambda_1 = 0$ 总是存在。现在我们提出一个更深刻的问题：$\lambda=0$ 这个[特征值](@entry_id:154894)出现了多少次？答案是[谱图论](@entry_id:150398)中最基本和最重要的定理之一：**零[特征值](@entry_id:154894)的重数（multiplicity）等于图的[连通分量](@entry_id:141881)（connected components）的数量**。

让我们来理解为什么。一个向量 $\mathbf{x}$ 是[特征值](@entry_id:154894)0对应的[特征向量](@entry_id:151813)，当且仅当 $L\mathbf{x} = \mathbf{0}$。这种情况也意味着 $\mathbf{x}^T L \mathbf{x} = \mathbf{x}^T \mathbf{0} = 0$。利用二次型恒等式，我们有：
$$
\mathbf{x}^T L \mathbf{x} = \sum_{(i,j) \in E} (x_i - x_j)^2 = 0
$$
由于这是一个平方和，总和为零的唯一可能是每一项都为零，即对于图中存在的每一条边 $(i, j)$，都必须满足 $x_i = x_j$。

这个条件意味着，[特征向量](@entry_id:151813) $\mathbf{x}$ 的分量值在图的每个**[连通分量](@entry_id:141881)**内部必须是常数。如果图是连通的（只有一个[连通分量](@entry_id:141881)），那么所有 $x_i$ 都必须相等，即 $\mathbf{x}$ 必须是全1向量 $\mathbf{1}$ 的常数倍。在这种情况下，[特征值](@entry_id:154894)0的[特征空间](@entry_id:638014)是一维的，由 $\mathbf{1}$ 张成。因此，$\lambda_2 > 0$。

如果图有两个[连通分量](@entry_id:141881)，例如 $C_1$ 和 $C_2$，我们可以构造两个线性无关的[特征向量](@entry_id:151813)。一个是在 $C_1$ 的顶点上取值为1，在 $C_2$ 的顶点上取值为0；另一个则相反。这两个向量都满足 $L\mathbf{x} = \mathbf{0}$ 的条件。这两个向量张成的二维空间就是[特征值](@entry_id:154894)0的[特征空间](@entry_id:638014)（[零空间](@entry_id:171336)）。因此，0[特征值](@entry_id:154894)的重数是2 [@problem_id:1371455]。

这个定理具有很强的实际应用价值。例如，一个由自主探测车组成的网络，其通信链路构成一个图。如果我们计算该网络拉普拉斯矩阵的[特征值](@entry_id:154894)，发现它们是 $\{0, 0, 3, 4, 5\}$，那么0[特征值](@entry_id:154894)出现了两次。这立即告诉我们，这个网络由两个独立的、无法相互通信的探测车集群组成 [@problem_id:1371411]。

#### [代数连通度](@entry_id:152762)：衡量图的“连接紧密程度”

对于一个连通图，我们知道 $0 = \lambda_1  \lambda_2 \le \dots \le \lambda_n$。第二个最小的[特征值](@entry_id:154894) $\lambda_2$ 有一个特殊的名称：**[代数连通度](@entry_id:152762)**（algebraic connectivity）。这个值在某种程度上衡量了图的“连接紧密程度”。$\lambda_2$ 越大，图的鲁棒性越强，越难被分割成两个大的部分。

[代数连通度](@entry_id:152762)与图的**[边连通度](@entry_id:272500)** $\kappa_E$ (edge connectivity) 和**点连通度** $\kappa_V$ (vertex connectivity) 密切相关。[边连通度](@entry_id:272500)定义为移除最少多少条边可以使图变得不连通。可以证明，[代数连通度](@entry_id:152762)为点连通度和[边连通度](@entry_id:272500)提供了下界。一个著名的不等式（对于非[完全图](@entry_id:266483)）是：
$$
\lambda_2 \le \kappa_V \le \kappa_E
$$
这表明，如果我们能计算出 $\lambda_2$，我们就能得到网络韧性的一个保证。例如，如果一个网络的 $\lambda_2=2$，我们可以推断出其[边连通度](@entry_id:272500) $\kappa_E \ge 2$。这意味着移除任何一条边都无法使网络断开 [@problem_id:1546633]。$\lambda_2$ 对应的[特征向量](@entry_id:151813)，被称为**[Fiedler向量](@entry_id:148200)**，在[图分割](@entry_id:152532)算法（如谱[聚类](@entry_id:266727)）中扮演着核心角色，因为它通常能有效地将[图划分](@entry_id:152532)为两个[子集](@entry_id:261956)。

### 归一化[拉普拉斯矩阵](@entry_id:152110)及其变体

标准的拉普拉斯矩阵 $L=D-A$ 在处理[顶点度数](@entry_id:264944)差异很大的图（例如社交网络中的“明星”节点）时，有时会表现出一些不理想的性质。为了解决这个问题，研究人员提出了几种**归一化[拉普拉斯矩阵](@entry_id:152110)**（normalized Laplacians）。

最常见的两种是：
1.  **对称归一化[拉普拉斯矩阵](@entry_id:152110)** ($L_{sym}$):
    $$
    L_{sym} = D^{-1/2} L D^{-1/2} = I - D^{-1/2} A D^{-1/2}
    $$
    这里的 $D^{-1/2}$ 是一个[对角矩阵](@entry_id:637782)，其对角元素为 $1/\sqrt{\deg(v_i)}$。$L_{sym}$ 仍然是对称半正定的，并且其[特征值](@entry_id:154894)被归一化到区间 $[0, 2]$ 内。

2.  **[随机游走](@entry_id:142620)归一化[拉普拉斯矩阵](@entry_id:152110)** ($L_{rw}$):
    $$
    L_{rw} = D^{-1} L = I - D^{-1} A
    $$
    这个矩阵与[图上的随机游走](@entry_id:273686)过程密切相关，但它通常不是对称的。它的[特征值](@entry_id:154894)也在 $[0, 2]$ 区间内。

让我们以一个3顶点的[路径图](@entry_id:274599) $P_3$ 为例，计算其对称归一化拉普拉斯矩阵 $L_{sym}$ [@problem_id:1371447]。顶点1、2、3的度分别为1、2、1。我们已经知道其标准[拉普拉斯矩阵](@entry_id:152110)为：
$$
L=\begin{pmatrix}
1   -1   0 \\
-1   2   -1 \\
0   -1   1
\end{pmatrix}
$$
其度[矩阵的逆](@entry_id:140380)平方根为 $D^{-1/2} = \mathrm{diag}(1, 1/\sqrt{2}, 1)$。根据定义 $L_{sym} = D^{-1/2} L D^{-1/2}$，我们进行[矩阵乘法](@entry_id:156035)：
$$
\begin{align*}
L_{sym}  = \begin{pmatrix} 1  0  0 \\ 0  1/\sqrt{2}  0 \\ 0  0  1 \end{pmatrix} \begin{pmatrix} 1  -1  0 \\ -1  2  -1 \\ 0  -1  1 \end{pmatrix} \begin{pmatrix} 1  0  0 \\ 0  1/\sqrt{2}  0 \\ 0  0  1 \end{pmatrix} \\
 = \begin{pmatrix} 1  -1  0 \\ -1/\sqrt{2}  \sqrt{2}  -1/\sqrt{2} \\ 0  -1  1 \end{pmatrix} \begin{pmatrix} 1  0  0 \\ 0  1/\sqrt{2}  0 \\ 0  0  1 \end{pmatrix} \\
 = \begin{pmatrix} 1  -1/\sqrt{2}  0 \\ -1/\sqrt{2}  1  -1/\sqrt{2} \\ 0  -1/\sqrt{2}  1 \end{pmatrix}
\end{align*}
$$
这种归一化形式在谱聚类、[社区发现](@entry_id:143791)等高级应用中至关重要，因为它能更好地处理不同规模和密度的子图。

本章介绍了拉普拉斯矩阵的基本定义、核心性质以及如何通过其谱特性来解读图的结构。我们从简单的定义出发，逐步揭示了其与图的连通性之间深刻的数学联系。在后续章节中，我们将看到这些原理如何被应用于解决实际世界中的[图分割](@entry_id:152532)、[数据聚类](@entry_id:265187)和网络分析等问题。