{"hands_on_practices": [{"introduction": "依概率收敛的一个重要性质是它在代数运算下的封闭性。本练习将通过一个具体例子来探讨这个性质，即两个依概率收敛的随机变量序列之和的行为。通过结合切比雪夫不等式和依概率收敛的定义，我们可以推导出和序列的收敛极限，这对于理解更复杂的随机过程模型至关重要。[@problem_id:1910723]", "problem": "设 $\\{X_n\\}_{n=1}^{\\infty}$ 和 $\\{Y_n\\}_{n=1}^{\\infty}$ 是两个随机变量序列。已知序列 $\\{X_n\\}$ 依概率收敛于常数 5。序列 $\\{Y_n\\}$ 的特征是，对所有正整数 $n$，其均值为 $E[Y_n] = 0$，方差为 $\\text{Var}(Y_n) = \\frac{1}{\\sqrt{n}}$。\n\n一个新随机变量序列 $\\{Z_n\\}_{n=1}^{\\infty}$ 由和 $Z_n = X_n + Y_n$ 定义。\n\n确定序列 $\\{Z_n\\}$ 依概率收敛到的数值。", "solution": "我们已知 $X_n \\xrightarrow{p} 5$，即对任意 $\\varepsilon>0$，\n$$\n\\lim_{n\\to\\infty} P(|X_n - 5| > \\varepsilon) = 0.\n$$\n对于 $Y_n$，我们有 $E[Y_n]=0$ 且对所有 $n$ 有 $\\text{Var}(Y_n)=n^{-1/2}$。根据切比雪夫不等式，对任意 $\\varepsilon>0$，\n$$\nP(|Y_n| > \\varepsilon) = P(|Y_n - E[Y_n]| > \\varepsilon) \\leq \\frac{\\text{Var}(Y_n)}{\\varepsilon^{2}} = \\frac{n^{-1/2}}{\\varepsilon^{2}} \\to 0 \\text{ as } n\\to\\infty.\n$$\n因此 $Y_n \\xrightarrow{p} 0$。\n\n定义 $Z_n=X_n+Y_n$。对任意 $\\varepsilon>0$，根据三角不等式，\n$$\n|Z_n-5|=\\big|(X_n-5)+Y_n\\big|\\leq |X_n-5|+|Y_n|.\n$$\n因此，使用并集界，\n$$\nP(|Z_n-5|>\\varepsilon)\\leq P(|X_n-5|>\\varepsilon/2)+P(|Y_n|>\\varepsilon/2)\\to 0 \\text{ as } n\\to\\infty,\n$$\n因为第一项根据 $X_n \\xrightarrow{p} 5$ 趋于零，第二项根据上述切比雪夫不等式也趋于零。因此 $Z_n \\xrightarrow{p} 5$。\n\n所以，$Z_n$ 依概率收敛到的数值是 $5$。", "answer": "$$\\boxed{5}$$", "id": "1910723"}, {"introduction": "依概率收敛在统计推断中扮演着核心角色，特别是在证明估计量的一致性方面。本练习将探讨一个实际应用场景：估计一个系统的效率，这被建模为两个随机变量样本均值的比率。通过应用弱大数定律和连续映射定理，我们将展示如何证明一个复合估计量依概率收敛到其真实的目标参数。[@problem_id:1910693]", "problem": "一位工程师正在对一种新型热电发电机进行特性表征。在 $n$ 次独立试验中，每次试验 $i$ 都会测量两个物理量：通过发电机的热流 $X_i$ 和产生的电功率输出 $Y_i$。\n\n测量序列 $\\{X_1, X_2, \\dots, X_n\\}$ 和 $\\{Y_1, Y_2, \\dots, Y_n\\}$ 可以建模如下：\n- 热流测量值 $\\{X_i\\}$ 是独立同分布（i.i.d.）的随机变量，其真实平均热流为 $E[X_i] = \\mu_{Q}$，且方差有限。\n- 功率输出测量值 $\\{Y_i\\}$ 是独立同分布的随机变量，其真实平均功率输出为 $E[Y_i] = \\mu_{P}$，且方差有限。\n- 已知真实平均热流不为零，即 $\\mu_{Q} \\neq 0$。\n\n为了估计发电机的转换效率，工程师在 $n$ 次试验后计算了两组测量值的样本均值：\n$$\n\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\quad \\text{and} \\quad \\bar{Y}_n = \\frac{1}{n} \\sum_{i=1}^{n} Y_i\n$$\n然后，工程师将效率的估计量 $\\eta_n$ 定义为样本平均功率输出与样本平均热流之比：\n$$\n\\eta_n = \\frac{\\bar{Y}_n}{\\bar{X}_n}\n$$\n确定当试验次数 $n$ 趋于无穷大时，随机变量序列 $\\eta_n$ 依概率收敛到的值。用包含 $\\mu_{Q}$ 和 $\\mu_{P}$ 的解析表达式表示你的答案。", "solution": "根据假设，热流测量值 $\\{X_i\\}$ 是独立同分布的，具有有限方差和均值 $E[X_i]=\\mu_{Q}$，功率测量值 $\\{Y_i\\}$ 也是独立同分布的，具有有限方差和均值 $E[Y_i]=\\mu_{P}$。定义样本均值为\n$$\n\\bar{X}_n=\\frac{1}{n}\\sum_{i=1}^{n}X_i,\\qquad \\bar{Y}_n=\\frac{1}{n}\\sum_{i=1}^{n}Y_i.\n$$\n根据弱大数定律（WLLN），有限方差意味着\n$$\n\\bar{X}_n \\xrightarrow{p} \\mu_{Q}\\quad\\text{and}\\quad \\bar{Y}_n \\xrightarrow{p} \\mu_{P}\\quad\\text{as }n\\to\\infty.\n$$\n由此可得，这对变量依概率联合收敛：对于任意 $\\varepsilon>0$，\n$$\nP(\\left\\|(\\bar{X}_n,\\bar{Y}_n)-(\\mu_{Q},\\mu_{P})\\right\\| > \\varepsilon)\n\\leq P(|\\bar{X}_n-\\mu_{Q}| > \\frac{\\varepsilon}{2}) + P(|\\bar{Y}_n-\\mu_{P}| > \\frac{\\varepsilon}{2}) \\to 0,\n$$\n因此 $(\\bar{X}_n,\\bar{Y}_n)\\xrightarrow{p}(\\mu_{Q},\\mu_{P})$。因为 $\\mu_{Q}\\neq 0$，映射 $g(x,y)=y/x$ 在 $(\\mu_{Q},\\mu_{P})$ 处是连续的。根据连续映射定理，\n$$\n\\eta_n=\\frac{\\bar{Y}_n}{\\bar{X}_n}=g(\\bar{X}_n,\\bar{Y}_n)\\xrightarrow{p} g(\\mu_{Q},\\mu_{P})=\\frac{\\mu_{P}}{\\mu_{Q}}.\n$$\n最后，$\\mu_{Q}\\neq 0$ 这一事实也保证了 $P(|\\bar{X}_n|>\\tfrac{|\\mu_{Q}|}{2})\\to 1$，因此该比值以趋近于 1 的概率是良定义的。\n因此，$\\eta_n$ 依概率收敛于 $\\mu_{P}/\\mu_{Q}$。", "answer": "$$\\boxed{\\frac{\\mu_{P}}{\\mu_{Q}}}$$", "id": "1910693"}, {"introduction": "一个好的估计量不仅需要无偏，还应具备一致性，即随着样本量的增加，它能够收敛到真实参数。本练习提供了一个反例，考察一个仅使用第一个观测值的“估计量”。通过严格应用依概率收敛的定义，我们将揭示为什么这个估计量不具备一致性，从而加深对一致性本质的理解。[@problem_id:1910737]", "problem": "设 $X_1, X_2, \\dots, X_n$ 是来自一个总体的独立同分布（i.i.d.）随机变量序列，该总体具有有限均值 $E[X_i] = \\mu$ 和有限非零方差 $\\text{Var}(X_i) = \\sigma^2$。\n\n一位研究者提出了一个用于估计总体均值 $\\mu$ 的估计量，定义为 $\\hat{\\mu}_n = X_1$。这个估计量只使用第一个观测值，而不考虑总样本量 $n$。我们希望分析这个估计量的一致性。\n\n当样本量 $n$ 趋于无穷大时，下列哪个陈述正确描述了估计量 $\\hat{\\mu}_n$ 的收敛性质？\n\nA. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为它是 $\\mu$ 的无偏估计量。\nB. $\\hat{\\mu}_n$ 依概率收敛于 $\\mu$，因为大数定律保证了当样本量 $n$ 无限增大时，任何估计量都会收敛。\nC. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为随着 $n$ 的增加，估计量与 $\\mu$ 的距离超过一个很小的数的概率保持为一个固定的正数。\nD. $\\hat{\\mu}_n$ 不依概率收敛于 $\\mu$，因为该估计量是有偏的，而有偏估计量永远不可能是一致的。\nE. 如果不知道 $X_i$ 变量的基础分布是否为正态分布，则无法确定 $\\hat{\\mu}_n$ 是否依概率收敛于 $\\mu$。", "solution": "设 $\\{X_{i}\\}_{i=1}^{n}$ 是独立同分布的，其中 $E[X_{i}] = \\mu$ 且 $\\text{Var}(X_{i}) = \\sigma^{2}$，这里 $\\sigma^{2} \\in (0,\\infty)$。所提出的估计量是 $\\hat{\\mu}_{n} = X_{1}$，对所有 $n$ 均成立。\n\n根据定义，$\\hat{\\mu}_{n}$ 是 $\\mu$ 的一致估计量，当且仅当对于任意 $\\varepsilon > 0$，都有\n$$\n\\lim_{n \\to \\infty} P(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon) = 0.\n$$\n因为对所有 $n$，$\\hat{\\mu}_{n} = X_{1}$，所以对于任意 $\\varepsilon > 0$ 和任意 $n$，我们有\n$$\nP(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon) = P(|X_{1} - \\mu| > \\varepsilon) =: p(\\varepsilon),\n$$\n该概率不依赖于 $n$。\n\n我们现在证明对于至少一个 $\\varepsilon > 0$，$p(\\varepsilon)$ 是严格为正的。使用反证法，假设对于所有 $\\varepsilon > 0$ 都有 $p(\\varepsilon) = 0$。那么对于任意满足 $\\varepsilon_{k} \\downarrow 0$ 的有理数序列 $\\{\\varepsilon_{k}\\}$，我们有\n$$\nP(|X_{1} - \\mu| \\le \\varepsilon_{k}) = 1 \\quad \\text{对所有 } k \\text{ 成立},\n$$\n因此\n$$\nP\\left(\\bigcap_{k=1}^{\\infty} \\{|X_{1} - \\mu| \\le \\varepsilon_{k}\\}\\right) = 1,\n$$\n这意味着 $P(X_{1} = \\mu) = 1$，从而 $\\text{Var}(X_{1}) = 0$，这与 $\\sigma^{2} > 0$ 的假设相矛盾。因此，存在 $\\varepsilon_{0} > 0$ 使得\n$$\np(\\varepsilon_{0}) = P(|X_{1} - \\mu| > \\varepsilon_{0}) > 0.\n$$\n因此，\n$$\n\\lim_{n \\to \\infty} P(|\\hat{\\mu}_{n} - \\mu| > \\varepsilon_{0}) = \\lim_{n \\to \\infty} p(\\varepsilon_{0}) = p(\\varepsilon_{0}) > 0,\n$$\n所以一致性条件不成立。因此，$\\hat{\\mu}_{n}$ 不依概率收敛于 $\\mu$。\n\n逐项评估选项：\n- A 是错误的：仅有无偏性并不意味着一致性。\n- B 是错误的：大数定律适用于依赖于 $n$ 的样本均值，而不适用于忽略了 $n$ 的 $X_{1}$。\n- C 是正确的：对于某个小的 $\\varepsilon$，误差概率是一个与 $n$ 无关的固定正常数。\n- D 是错误的：该估计量是无偏的，而且在一般情况下，有偏性并不排除一致性。\n- E 是错误的：正态性不是必需的；论证仅依赖于 $\\sigma^{2} > 0$。\n\n因此，正确选项是 C。", "answer": "$$\\boxed{C}$$", "id": "1910737"}]}