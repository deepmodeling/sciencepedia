{"hands_on_practices": [{"introduction": "要真正掌握一个算法，最好的方法就是动手计算。这个练习将带你完成 Metropolis-Hastings 算法最核心的一步：计算接受概率 [@problem_id:1962612]。通过一个简单的离散型目标分布（泊松分布）和对称提议分布，我们将清晰地看到算法的基本运作机制，为后续更复杂的应用打下坚实的基础。", "problem": "一位统计学家正在实施一个马尔可夫链蒙特卡洛 (MCMC) 模拟，以从一个目标概率分布中生成样本。所选的目标分布是泊松分布，它模拟了在固定的时间或空间间隔内事件发生的次数 $k$。泊松分布的概率质量函数由下式给出：\n$$ P(k; \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} $$\n其中 $\\lambda$ 是事件的平均发生率。对于本次特定的模拟，参数被设置为 $\\lambda = 5$。\n\n该模拟使用 Metropolis-Hastings 算法并采用对称提议分布，这意味着从状态 $k_1$ 提议移动到状态 $k_2$ 的概率与从状态 $k_2$ 提议移动到状态 $k_1$ 的概率相同。\n\n假设链的当前状态为 $k=5$。算法接着提议移动到一个新状态 $k'=6$。\n\n计算从 $k=5$ 移动到 $k'=6$ 这个提议的接受概率。将您的答案表示为小数，并四舍五入到三位有效数字。", "solution": "在采用对称提议分布的 Metropolis-Hastings 算法中，从状态 $k$ 提议移动到 $k'$ 的接受概率为\n$$\n\\alpha = \\min\\left(1, \\frac{\\pi(k')}{\\pi(k)}\\right),\n$$\n其中 $\\pi(\\cdot)$ 是目标概率质量函数。对于参数为 $\\lambda$ 的泊松分布，其 PMF 为\n$$\n\\pi(k) = \\frac{\\lambda^{k} \\exp(-\\lambda)}{k!}.\n$$\n因此，该比率可简化为\n$$\n\\frac{\\pi(k')}{\\pi(k)} = \\frac{\\lambda^{k'} \\exp(-\\lambda) / k'!}{\\lambda^{k} \\exp(-\\lambda) / k!} = \\lambda^{k'-k} \\frac{k!}{k'!}.\n$$\n当 $k=5$，$k'=6$ 且 $\\lambda=5$ 时，我们有 $k'-k=1$ 且 $6! = 6 \\cdot 5!$，所以\n$$\n\\frac{\\pi(6)}{\\pi(5)} = \\lambda \\cdot \\frac{5!}{6!} = \\lambda \\cdot \\frac{1}{6} = \\frac{5}{6}.\n$$\n因此，接受概率为\n$$\n\\alpha = \\min\\left(1, \\frac{5}{6}\\right) = \\frac{5}{6}.\n$$\n表示为小数并四舍五入到三位有效数字，结果为 $0.833$。", "answer": "$$\\boxed{0.833}$$", "id": "1962612"}, {"introduction": "在掌握了基本计算之后，下一个练习将探讨一个常见但至关重要的错误。我们将研究当提议分布不对称时，如果错误地使用了简化的 Metropolis 接受准则，会发生什么 [@problem_id:1343405]。这个思想实验强调了完整的 Metropolis-Hastings 公式为何如此重要，特别是其对非对称性的校正项，是确保马尔可夫链收敛到正确目标分布的关键。", "problem": "一位分析师正在实现一个马尔可夫链蒙特卡洛（MCMC）算法，用于从一个定义在三个状态 $S_1$、$S_2$ 和 $S_3$ 上的离散目标概率分布 $\\pi$ 中进行采样。目标分布由下式给出：\n$$\n\\pi(S_1) = \\frac{1}{2}, \\quad \\pi(S_2) = \\frac{1}{3}, \\quad \\pi(S_3) = \\frac{1}{6}\n$$\n该分析师设计了一个确定性的、循环的提议机制，由提议分布 $Q(x,y)$ 描述。从状态 $S_i$ 出发，它总是提议循环 $S_1 \\to S_2 \\to S_3 \\to S_1$ 中的下一个状态。具体来说，非零的提议概率为 $Q(S_1, S_2) = 1$、$Q(S_2, S_3) = 1$ 和 $Q(S_3, S_1) = 1$。\n\n然而，在设置接受概率 $\\alpha(x,y)$ 时，该分析师错误地使用了简化的Metropolis接受准则：\n$$\n\\alpha(x,y) = \\min\\left(1, \\frac{\\pi(y)}{\\pi(x)}\\right)\n$$\n该准则通常仅在提议分布 $Q(x,y)$ 是对称的情况下才有效。\n\n由此产生的马尔可夫链收敛到一个平稳分布，我们称之为 $\\pi'$，它与预期的目标分布 $\\pi$ 不同。计算该链处于状态 $S_2$ 的长期概率。将你的答案表示为最简分数形式。", "solution": "我们构建由确定性提议和错误的Metropolis接受准则所导出的马尔可夫链。对于状态 $S_{1}, S_{2}, S_{3}$，提议为 $S_{1}\\to S_{2}\\to S_{3}\\to S_{1}$，使用的接受概率为\n$$\n\\alpha(x,y)=\\min\\left(1,\\frac{\\pi(y)}{\\pi(x)}\\right).\n$$\n已知 $\\pi(S_{1})=\\frac{1}{2}$，$\\pi(S_{2})=\\frac{1}{3}$ 和 $\\pi(S_{3})=\\frac{1}{6}$，对提议的移动，其接受概率为：\n$$\n\\alpha(S_{1},S_{2})=\\min\\left(1,\\frac{\\pi(S_{2})}{\\pi(S_{1})}\\right)=\\min\\left(1,\\frac{\\frac{1}{3}}{\\frac{1}{2}}\\right)=\\frac{2}{3},\n$$\n$$\n\\alpha(S_{2},S_{3})=\\min\\left(1,\\frac{\\pi(S_{3})}{\\pi(S_{2})}\\right)=\\min\\left(1,\\frac{\\frac{1}{6}}{\\frac{1}{3}}\\right)=\\frac{1}{2},\n$$\n$$\n\\alpha(S_{3},S_{1})=\\min\\left(1,\\frac{\\pi(S_{1})}{\\pi(S_{3})}\\right)=\\min\\left(1,\\frac{\\frac{1}{2}}{\\frac{1}{6}}\\right)=1.\n$$\n因此，转移概率（接受或停留在原状态）为：\n- 从 $S_{1}$ 出发：$P(S_{1}\\to S_{2})=\\frac{2}{3}$，$P(S_{1}\\to S_{1})=\\frac{1}{3}$。\n- 从 $S_{2}$ 出发：$P(S_{2}\\to S_{3})=\\frac{1}{2}$，$P(S_{2}\\to S_{2})=\\frac{1}{2}$。\n- 从 $S_{3}$ 出发：$P(S_{3}\\to S_{1})=1$。\n\n因此，按 $(S_{1},S_{2},S_{3})$ 顺序排列的转移矩阵 $P$ 为\n$$\nP=\\begin{pmatrix}\n\\frac{1}{3}  \\frac{2}{3}  0 \\\\\n0  \\frac{1}{2}  \\frac{1}{2} \\\\\n1  0  0\n\\end{pmatrix}.\n$$\n设平稳分布为 $\\pi'=(a,b,c)$，满足 $a+b+c=1$ 且 $\\pi'=\\pi'P$。平稳性方程组为：\n$$\na=a\\cdot\\frac{1}{3}+b\\cdot 0+c\\cdot 1,\\quad\nb=a\\cdot\\frac{2}{3}+b\\cdot\\frac{1}{2}+c\\cdot 0,\\quad\nc=a\\cdot 0+b\\cdot\\frac{1}{2}+c\\cdot 0.\n$$\n由第三个方程得，$c=\\frac{b}{2}$。由第一个方程得，$a=\\frac{a}{3}+c$，因此 $c=a-\\frac{a}{3}=\\frac{2a}{3}$。令两个关于 $c$ 的表达式相等，得到 $\\frac{b}{2}=\\frac{2a}{3}$，所以 $b=\\frac{4a}{3}$。利用 $a+b+c=1$ 可得\n$$\na+\\frac{4a}{3}+\\frac{2a}{3}=a+2a=3a=1\\quad\\Rightarrow\\quad a=\\frac{1}{3},\n$$\n因此\n$$\nb=\\frac{4}{9},\\qquad c=\\frac{2}{9}.\n$$\n因此，该链处于状态 $S_{2}$ 的长期概率是 $b=\\frac{4}{9}$。", "answer": "$$\\boxed{\\frac{4}{9}}$$", "id": "1343405"}, {"introduction": "即使算法的实现完全正确，一些实践中的选择仍会极大地影响采样器的性能。最后一个练习将我们带入 MCMC 的一个常见挑战：从多峰分布中采样 [@problem_id:1962668]。我们将看到，一个看似合理的提议步长选择，可能会导致采样器“卡在”一个局部区域，从而无法探索整个概率空间。这揭示了采样器“混合性”的关键概念以及为保证有效探索而调整采样器的艺术。", "problem": "一位数据科学家正在分析一个复杂气候模型中参数 $\\theta$ 的后验概率分布。分析表明，记为 $p(\\theta)$ 的后验分布是双峰的，在 $\\theta_A$ 和 $\\theta_B$ 处有两个明显的高概率峰，它们之间被一个很宽的极低概率区域隔开。为了探索该分布并估计诸如后验均值等性质，这位科学家采用了Metropolis-Hastings (M-H) 算法。\n\nM-H 采样器以位于第一个峰 $\\theta_A$ 附近的高概率区域内的起始值 $\\theta_0$ 进行初始化。采用了一个对称的提议分布 $q(\\theta' | \\theta) = \\mathcal{N}(\\theta' | \\theta, \\sigma^2)$，其中 $\\mathcal{N}$ 是以当前状态 $\\theta$ 为中心、标准差为 $\\sigma$ 的正态分布，$\\sigma$ 代表提议步长。这位科学家为了获得高接受率，为 $\\sigma$ 选择了一个相对于两模式间距离 $|\\theta_A - \\theta_B|$ 非常小的值。\n\n在 M-H 采样器运行了非常大量的迭代之后，下列哪个描述最准确地刻画了这次模拟的预期结果？\n\nA. 采样器将高效地找到后验分布 $p(\\theta)$ 的全局最大值并停留在那里，从而为参数提供一个极好的点估计。\n\nB. 对提议状态的接受率将非常低，导致链停留在初始状态 $\\theta_0$ 附近，并且只探索了极小部分的参数空间。\n\nC. 生成的样本链将高度自相关，其直方图将主要呈现 $\\theta_A$ 附近模式的形状，而无法发现 $\\theta_B$ 附近的模式。\n\nD. 样本将以系统性的方式在两个模式之间交替，以固定的频率从 $\\theta_A$ 区域跳到 $\\theta_B$ 区域再跳回。\n\nE. 链的状态将彼此近似独立，表明采样器已成功收敛到真实的双峰后验分布。", "solution": "我们分析使用对称提议分布且提议尺度相对于后验 $p(\\theta)$ 在 $\\theta_{A}$ 和 $\\theta_{B}$ 处的两个分离模式之间的距离非常小的 Metropolis-Hastings (M-H) 采样器。\n\n对于对称提议分布 $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta' \\mid \\theta, \\sigma^{2})$，Metropolis-Hastings 接受概率为\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\}.\n$$\n链在 $\\theta_{A}$ 附近的高概率区域中的 $\\theta_{0}$ 处初始化。因为选择的 $\\sigma$ 相对于间隔 $|\\theta_{A} - \\theta_{B}|$ 非常小，提议的移动满足 $|\\theta' - \\theta| = O(\\sigma)$，因此会保持在离当前状态非常近的位置。在模式附近的高概率区域中，对于小步长，$p(\\theta')$ 接近 $p(\\theta)$，所以\n$$\n\\frac{p(\\theta')}{p(\\theta)} \\approx 1,\n$$\n这意味着 $a(\\theta \\rightarrow \\theta') \\approx 1$ 并且局部接受率很高。因此，选项 B（非常低的接受率）与这种小步长、模式内的行为相矛盾。\n\n接下来，考虑模式之间的转换。在高斯提议分布下，从一个靠近 $\\theta_{A}$ 的当前状态直接提议一个靠近 $\\theta_{B}$ 的状态的概率是\n$$\nq(\\theta_{B} \\mid \\theta) \\propto \\exp\\left(-\\frac{|\\theta_{B} - \\theta|^{2}}{2 \\sigma^{2}}\\right).\n$$\n由于 $\\sigma \\ll |\\theta_{A} - \\theta_{B}|$，这个提议概率在 $|\\theta_{A} - \\theta_{B}|^{2} / \\sigma^{2}$ 上呈指数级小。因此，在实际的时间尺度上，跨越低概率谷的直接跳跃基本上永远不会被提议。另一种方式是，通过许多小步来穿越这个谷，这需要反复地提议移动到 $p(\\theta') \\ll p(\\theta)$ 的区域，而对于这类移动，\n$$\na(\\theta \\rightarrow \\theta') = \\min\\left\\{1, \\frac{p(\\theta')}{p(\\theta)}\\right\\} \\ll 1,\n$$\n所以这样的步骤绝大多数都会被拒绝。因此，链在很长一段时间内实际上被困在 $\\theta_{A}$ 附近，在实践中无法发现 $\\theta_{B}$。\n\n因为移动非常局部化，且链停留在同一模式内，所以连续的样本是高度自相关的。因此，经验直方图反映了 $\\theta_{A}$ 附近的局部形状，但没有捕捉到 $\\theta_{B}$ 附近的分离模式。这排除了选项 E（独立性和成功收敛）和选项 D（模式间的规律性交替）。选项 A 是不正确的，因为 M-H 是一个以 $p(\\theta)$ 为目标的采样器，而不是一个优化器；此外，在小步长和双峰性的情况下，它既不能高效地找到全局最大值，也不能停留在那里。\n\n因此，最准确的描述是链表现出高自相关性，主要在 $\\theta_{A}$ 的邻域进行采样，并且无法发现第二个模式 $\\theta_{B}$。\n\n正确的选项是 C。", "answer": "$$\\boxed{C}$$", "id": "1962668"}]}