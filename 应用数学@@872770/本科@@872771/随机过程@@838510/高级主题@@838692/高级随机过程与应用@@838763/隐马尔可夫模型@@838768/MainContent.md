## 引言
在许多科学和工程领域，我们经常遇到这样一类系统：其内部状态的演变对系统行为至关重要，但这些状态本身却无法被直接观测。我们只能通过一系列有噪声或间接的输出来窥探其内部运作。从解读[基因序列](@entry_id:191077)的生物功能，到预测金融市场的波动机制，再到理解自然语言的语法结构，我们如何才能对这类“黑箱”系统进行有效的建模和推理？

隐马尔可夫模型（Hidden Markov Model, HMM）为解决这一挑战提供了强大而优雅的统计框架。它假设系统内部存在一个遵循[马尔可夫性质](@entry_id:139474)的[隐藏状态](@entry_id:634361)序列，而我们观测到的数据序列则由这些隐藏状态以一定的概率生成。通过这种方式，HMM能够捕捉动态系统的时间依赖性和不确定性，并允许我们从可观测数据中推断出最可能的潜在结构。

本文将系统地引导你掌握隐马尔可夫模型的核心知识。在**“原理与机制”**一章中，我们将深入剖析HMM的数学定义、两大核心假设，并详细推导解决评估和[解码问题](@entry_id:264478)的关键算法——[前向算法](@entry_id:165467)和[维特比算法](@entry_id:269328)。接下来，在**“应用与跨学科联系”**一章中，我们将展示HMM如何在自然语言处理、生物信息学、金融等多个前沿领域中发挥作用，并探讨其重要的理论扩展。最后，通过**“动手实践”**部分的精选问题，你将有机会亲自应用所学知识，巩固对HMM的理解，并解决具体的数据分析任务。

## 原理与机制

在“引言”部分，我们已经了解了隐马尔可夫模型 (Hidden Markov Model, HMM) 作为一种强大的统计工具，能够为那些其内部状态无法直接观测，但能产生一系列可观测输出的系统进行建模。本章将深入探讨构成 HMM 的核心原理及其关键的计算机制。我们将剖析定义 HMM 的数学组件，阐明其根本性的概率假设，并详细推导用于解决 HMM 相关核心问题的三大算法。

### 隐马尔可夫模型的结构

要理解 HMM 的“隐”字，最有效的方法是将其与标准的[马尔可夫链](@entry_id:150828)进行对比。一个标准的（或可观测的）[马尔可夫链](@entry_id:150828)，其状态序列 $\{X_1, X_2, \dots, X_t\}$ 是可以直接观测的。该序列的核心特性是[马尔可夫性质](@entry_id:139474)，即未来状态的概率仅依赖于当前状态，而与过去的状态无关。

然而，在许多现实世界的系统中，我们无法直接观测到驱动系统演变的内部状态。相反，我们只能观测到这些状态产生的某种“信号”或“输出”。HMM 正是为了对这类过程进行建模。它包含两条并行的[随机过程](@entry_id:159502)序列：

1.  一个不可观测的**隐状态序列** (hidden state sequence) $\{Z_1, Z_2, \dots, Z_t, \dots\}$。这个序列本身是一个标准的马尔可夫链，由一组有限的状态构成。
2.  一个可观测的**观测序列** (observation sequence) $\{O_1, O_2, \dots, O_t, \dots\}$。每个观测值 $O_t$ 的[概率分布](@entry_id:146404)取决于系统在同一时刻 $t$ 所处的隐状态 $Z_t$。

关键的区别在于，标准的[马尔可夫链](@entry_id:150828)中，观测到的序列 $\{X_t\}$ 本身具有马尔可夫性质。而在 HMM 中，只有隐状态序列 $\{Z_t\}$ 遵循[马尔可夫性质](@entry_id:139474)；观测序列 $\{O_t\}$ 本身通常不具备这一性质，因为要预测下一个观测值，仅仅知道当前的观测值是不够的——我们实际上需要推断当前隐状态的[概率分布](@entry_id:146404)，而这个推断过程需要利用到过去所有的观测历史 [@problem_id:1306002]。

为了形式化地定义一个 HMM，我们需要以下五个要素，通常记为 $\lambda = (S, V, A, B, \pi)$：

1.  **隐状态集合 (Set of Hidden States)** $S = \{s_1, s_2, \dots, s_N\}$：系统可能处于的 $N$ 个不可观测的内部状态。

2.  **观测符号集合 (Set of Observation Symbols)** $V = \{v_1, v_2, \dots, v_M\}$：系统在每个状态下可能产生的 $M$ 个可观测的输出或符号。

3.  **初始状态[分布](@entry_id:182848) (Initial State Distribution)** $\pi = [\pi_i]$：一个向量，其中 $\pi_i = P(Z_1 = s_i)$ 表示系统在时间步 $t=1$ 时处于状态 $s_i$ 的初始概率。显然，$\sum_{i=1}^N \pi_i = 1$。

4.  **状态转移[概率矩阵](@entry_id:274812) (State Transition Probability Matrix)** $A = [a_{ij}]$：一个 $N \times N$ 的矩阵，其中 $a_{ij} = P(Z_{t+1} = s_j | Z_t = s_i)$ 表示系统从状态 $s_i$ 转移到状态 $s_j$ 的概率。矩阵的每一行之和必须为 1，即 $\sum_{j=1}^N a_{ij} = 1$ 对所有 $i$ 成立。

5.  **发射[概率矩阵](@entry_id:274812) (Emission Probability Matrix)** $B = [b_j(k)]$：一个 $N \times M$ 的矩阵，其中 $b_j(k) = P(O_t = v_k | Z_t = s_j)$ 表示系统在隐状态 $s_j$ 下产生观测值 $v_k$ 的概率。矩阵的每一行之和也必须为 1，即 $\sum_{k=1}^M b_j(k) = 1$ 对所有 $j$ 成立。

让我们通过一个具体的例子来理解这些组件。假设我们有一个用于装配线上精密质检的机器人 [@problem_id:1305992]。我们无法直接看到它的内部校准情况，但能观察到它的动作是“精确”还是“不精确”。

-   **隐状态 $S$**：$\{s_1=\text{已校准}, s_2=\text{未校准}\}$。$N=2$。
-   **观测符号 $V$**：$\{v_1=\text{精确}, v_2=\text{不精确}\}$。$M=2$。
-   **初始[分布](@entry_id:182848) $\pi$**：假设机器人开始工作时有 $0.9$ 的概率是已校准的，则 $\pi = [0.9, 0.1]$。
-   **[转移矩阵](@entry_id:145510) $A$**：如果机器人已校准，它有 $0.95$ 的概率保持校准，有 $0.05$ 的概率失准。如果未校准，它有 $0.1$ 的概率通过自校正恢复，有 $0.9$ 的概率保持未校准。因此，$A = \begin{pmatrix} 0.95  0.05 \\ 0.10  0.90 \end{pmatrix}$。
-   **发射矩阵 $B$**：已校准时，动作为“精确”的概率为 $0.98$。未校准时，为“精确”的概率仅为 $0.30$。因此，$B = \begin{pmatrix} 0.98  0.02 \\ 0.30  0.70 \end{pmatrix}$。

值得注意的是，发射概率的极端情况，例如某个状态 $s_j$ 产生特定观测 $v_k$ 的概率 $b_j(k)=1$，并不会破坏模型的“隐”特性 [@problem_id:1306012]。这仅仅意味着，如果系统处于状态 $s_j$，它必定会产生观测 $v_k$。然而，状态序列的整体路径依然是未知的，因为状态之间的转移是概率性的。反过来，当我们观测到 $v_k$ 时，这为系统可能处于状态 $s_j$ 提供了强有力的证据，但并不能完全确定。除非其他任何状态都不能产生 $v_k$（即对所有 $i \neq j$，$b_i(k)=0$），否则我们不能从 $P(v_k|s_j)=1$ 直接推断出 $P(s_j|v_k)=1$。这是一个常见的[逻辑谬误](@entry_id:273186)。

### 核心假设：更深入的审视

HMM 的强大能力源于其两个简洁而深刻的概率假设。正是这两个假设，使得对模型进行高效计算成为可能。我们必须精确理解这些假设的含义 [@problem_id:2875860]。

1.  **隐状态的马尔可夫性质 (Markov Property of Hidden States)**：这个假设规定，在任意时刻 $t$，未来的隐状态 $Z_{t+1}$ 的[概率分布](@entry_id:146404)，只取决于当前的隐状态 $Z_t$，而与过去所有的隐状态 $\{Z_1, \dots, Z_{t-1}\}$ 无关。数学上表示为：
    $$P(Z_{t+1} | Z_1, \dots, Z_t) = P(Z_{t+1} | Z_t)$$
    这个性质限制了隐状态之间的依赖关系，使其形成一个简单的链式结构。

2.  **观测独立性假设 (Observation Independence Assumption)**：这个假设是 HMM 的精髓所在。它规定，在任意时刻 $t$，观测值 $O_t$ 的[概率分布](@entry_id:146404)，只取决于当前的隐状态 $Z_t$，而与任何其他的隐状态或观测值都无关。数学上表示为：
    $$P(O_t | Z_1, \dots, Z_T, O_1, \dots, O_{t-1}, O_{t+1}, \dots, O_T) = P(O_t | Z_t)$$
    这个假设的直接推论是 $P(O_t | Z_{1:t}, O_{1:t-1}) = P(O_t | Z_t)$。这意味着一旦我们知道了当前时刻的“真实”状态 $Z_t$，那么过去的状态历史和观测历史对于预测当前观测 $O_t$ 都不再提供任何额外信息。

这两个假设共同决定了 HMM 的[联合概率分布](@entry_id:171550)的[因子分解](@entry_id:150389)形式。对于一个长度为 $T$ 的状态序列 $Z = (Z_1, \dots, Z_T)$ 和观测序列 $O = (O_1, \dots, O_T)$，其联合概率可以写为：
$$P(O, Z | \lambda) = P(Z_1) \left( \prod_{t=2}^T P(Z_t | Z_{t-1}) \right) \left( \prod_{t=1}^T P(O_t | Z_t) \right)$$
利用我们定义的模型参数，上式可以写为：
$$P(O, Z | \lambda) = \pi_{Z_1} b_{Z_1}(O_1) \prod_{t=2}^T a_{Z_{t-1}Z_t} b_{Z_t}(O_t)$$
这种简洁的[因子分解](@entry_id:150389)结构是后续所有高效算法（如[前向算法](@entry_id:165467)、[维特比算法](@entry_id:269328)）的基石。如果观测独立性假设不成立——例如，如果 $O_t$ 同时依赖于 $Z_t$ 和 $Z_{t-1}$——那么标准的 HMM 算法将不再适用，因为上述分解形式将失效 [@problem_id:2875860]。

### HMM 的三个基本问题

围绕 HMM，通常有三个核心的计算问题需要解决：

1.  **评估问题 (Evaluation)**：给定模型参数 $\lambda$ 和一个观测序列 $O$，计算这个观测序列出现的总概率 $P(O|\lambda)$。这可以用于评估不同模型与给定数据的匹配程度。

2.  **[解码问题](@entry_id:264478) (Decoding)**：给定模型参数 $\lambda$ 和一个观测序列 $O$，找到最有可能产生这个观测序列的隐状态序列 $Q^* = \arg\max_Q P(Q|O, \lambda)$。这在词性标注、基因序列分析等应用中至关重要。

3.  **学习问题 (Learning)**：给定一个或多个观测序列，调整模型参数 $(A, B, \pi)$，使得这些观测序列出现的概率最大化。这是模型训练的过程。

接下来的几节，我们将详细介绍解决前两个问题的关键算法。

### 评估问题：[前向算法](@entry_id:165467)

评估问题的目标是计算 $P(O|\lambda)$。一个朴素的方法是枚举所有可能的隐状态序列 $Q=(q_1, \dots, q_T)$，计算每个序列与观测序列的联合概率 $P(O,Q|\lambda)$，然后将它们全部相加：
$$P(O|\lambda) = \sum_{\text{all } Q} P(O,Q|\lambda) = \sum_{q_1, \dots, q_T} \pi_{q_1} b_{q_1}(O_1) \prod_{t=2}^T a_{q_{t-1}q_t} b_{q_t}(O_t)$$
然而，对于一个有 $N$ 个状态、长度为 $T$ 的序列，总共有 $N^T$ 条可能的路径。当 $N$ 和 $T$ 稍大时，这种指数级的计算复杂度是不可接受的。

为了解决这个问题，我们引入一种称为**[前向算法](@entry_id:165467) (Forward Algorithm)** 的动态规划方法。该算法的核心是定义一个**前向变量 (forward variable)** $\alpha_t(i)$：
$$\alpha_t(i) = P(O_1, O_2, \dots, O_t, Z_t = s_i | \lambda)$$
这个变量表示在给定模型下，观测到部分序列 $O_1, \dots, O_t$ 并且在时刻 $t$ 处于状态 $s_i$ 的联合概率。我们可以通过一个简单的递归过程来高效地计算它 [@problem_id:765290]。

**1. 初始化 (t=1):**
对于每个状态 $s_i$，计算在 $t=1$ 时的前向变量。这等于系统开始于状态 $s_i$ 的概率乘以从该状态发射出第一个观测 $O_1$ 的概率。
$$\alpha_1(i) = \pi_i b_i(O_1)$$

**2. 归纳 (t = 2, ..., T):**
要计算 $\alpha_{t+1}(j)$，我们考虑所有可能到达状态 $s_j$ 的路径。在时刻 $t$，系统可以处于任何状态 $s_i$，其对应的前向概率为 $\alpha_t(i)$。从状态 $s_i$ 转移到状态 $s_j$ 的概率是 $a_{ij}$。因此，在观测到 $O_1, \dots, O_t$ 之后，系统在时刻 $t+1$ 到达状态 $s_j$ 的总概率是 $\sum_{i=1}^N \alpha_t(i) a_{ij}$。最后，我们乘以从状态 $s_j$ 发射出观测 $O_{t+1}$ 的概率 $b_j(O_{t+1})$。
$$\alpha_{t+1}(j) = \left[ \sum_{i=1}^N \alpha_t(i) a_{ij} \right] b_j(O_{t+1})$$

**3. 终止:**
当递归进行到最后一步 $t=T$ 时，$\alpha_T(i)$ 表示观测到整个序列 $O$ 并且最终停留在状态 $s_i$ 的概率。因此，将所有最终状态的概率相加，就得到了观测序列 $O$ 的总概率。
$$P(O|\lambda) = \sum_{i=1}^N \alpha_T(i)$$

通过这种方式，每一步的计算量仅为 $O(N^2)$，整个算法的复杂度为 $O(N^2 T)$，远优于朴素的指数级算法。回到之前的机器人质检例子 [@problem_id:1305992]，我们可以利用[前向算法](@entry_id:165467)计算出观测序列（精确，不精确，精确）的总概率。

#### [数值稳定性](@entry_id:146550)：[前向算法](@entry_id:165467)的缩放
在处理长观测序列时，标准的[前向算法](@entry_id:165467)会遇到**数值[下溢](@entry_id:635171) (numerical underflow)** 的问题。由于 $\alpha_t(i)$ 是一个[联合概率](@entry_id:266356)，它会随着 $t$ 的增加而迅速趋近于零，最终超出计算机浮点数的表示范围。

为了解决这个问题，我们引入一个**缩放因子 (scaling factor)** [@problem_id:1306017]。其思想是在每一步计算后对前向变量进行归一化，使其总和为 1。修改后的算法如下：

-   **初始化 (t=1):**
    -   计算 $\alpha_1(i) = \pi_i b_i(O_1)$。
    -   计算缩放因子 $c_1 = \sum_{i=1}^N \alpha_1(i)$。
    -   计算缩放后的前向变量 $\hat{\alpha}_1(i) = \frac{\alpha_1(i)}{c_1}$。

-   **归纳 (t = 2, ..., T):**
    -   使用缩放后的变量计算未缩放的下一步变量：$\alpha_t(j) = \left[ \sum_{i=1}^N \hat{\alpha}_{t-1}(i) a_{ij} \right] b_j(O_t)$。
    -   计算新的缩放因子 $c_t = \sum_{j=1}^N \alpha_t(j)$。
    -   计算新的缩放后变量 $\hat{\alpha}_t(j) = \frac{\alpha_t(j)}{c_t}$。

在这个过程中，$\hat{\alpha}_t(i)$ 可以被解释为给定到时刻 $t$ 的观测序列后，系统处于状态 $s_i$ 的条件概率，即 $P(Z_t = s_i | O_1, \dots, O_t, \lambda)$。由于我们记录了每一步的缩放因子 $c_t = P(O_t | O_1, \dots, O_{t-1}, \lambda)$，整个观测序列的概率可以通过将这些因子相乘得到：
$$P(O|\lambda) = \prod_{t=1}^T c_t$$
为了避免连乘导致的下溢，实际计算中通常使用对数概率：
$$\ln P(O|\lambda) = \sum_{t=1}^T \ln(c_t)$$
这种缩放方法在保证数值稳定性的同时，完整地保留了计算总概率所需的信息 [@problem_id:1306017]。

### [解码问题](@entry_id:264478)：[维特比算法](@entry_id:269328)

[解码问题](@entry_id:264478)旨在寻找“最佳”的隐状态序列，即在给定观测序列 $O$ 的情况下，[后验概率](@entry_id:153467) $P(Q|O, \lambda)$ 最大的状态序列 $Q$。由于 $P(Q|O, \lambda) = P(Q,O|\lambda) / P(O|\lambda)$，而 $P(O|\lambda)$ 对所有路径都是常数，因此该问题等价于寻找使联合概率 $P(Q,O|\lambda)$ 最大的路径。

与[前向算法](@entry_id:165467)计算所有路径概率之和不同，**[维特比算法](@entry_id:269328) (Viterbi Algorithm)** 寻找概率最大的一条路径。它同样采用动态规划，结构与[前向算法](@entry_id:165467)惊人地相似，但将求和操作替换为了求最大值操作 [@problem_id:1306006] [@problem_id:1305975]。

我们定义一个新的变量 $\delta_t(i)$：
$$\delta_t(i) = \max_{q_1, \dots, q_{t-1}} P(q_1, \dots, q_{t-1}, Z_t=s_i, O_1, \dots, O_t | \lambda)$$
$\delta_t(i)$ 表示在所有以状态 $s_i$ 结尾、长为 $t$ 的路径中，能够产生观测序列 $O_1, \dots, O_t$ 的那条路径的最大概率。

**1. 初始化 (t=1):**
$$\delta_1(i) = \pi_i b_i(O_1)$$

**2. 归纳 (t = 2, ..., T):**
要计算 $\delta_{t+1}(j)$，我们考虑所有在 $t$ 时刻可能的状态 $s_i$。从 $s_i$ 转移到 $s_j$ 并产生观测 $O_{t+1}$ 的路径，其概率将是 $\delta_t(i) \cdot a_{ij} \cdot b_j(O_{t+1})$。我们选择使这个值最大的前一状态 $s_i$。
$$\delta_{t+1}(j) = \left[ \max_{1 \le i \le N} (\delta_t(i) a_{ij}) \right] b_j(O_{t+1})$$

为了能够最终回溯找到这条最佳路径，我们还需要一个额外的数组 $\psi_t(j)$ 来记录在时刻 $t$ 使得 $\delta_t(j)$ 达到最大值的前一个状态的索引。
$$\psi_t(j) = \arg\max_{1 \le i \le N} (\delta_t(i) a_{ij})$$

**3. 终止与路径回溯:**
在 $t=T$ 时，整个路径的最大概率为 $P^* = \max_{1 \le i \le N} \delta_T(i)$。最佳路径的最后一个状态为 $q_T^* = \arg\max_{1 \le i \le N} \delta_T(i)$。
然后，我们可以通过 $\psi$ 数组进行回溯，从 $t=T-1$ 开始，依次向前找出最佳路径上的每一个状态：
$$q_t^* = \psi_{t+1}(q_{t+1}^*), \quad \text{for } t = T-1, T-2, \dots, 1$$

通过比较[前向算法](@entry_id:165467)中的求和与[维特比算法](@entry_id:269328)中的求最大值，我们可以清晰地看到两者目标的差异：前者整合所有可能性以评估整体证据，而后者则在每一步都做出“最优”选择以找出单条最佳解释 [@problem_id:1306006]。

### 高级状态推断：平滑与后验概率

[维特比算法](@entry_id:269328)给出了全局最优的状态序列。但有时我们关心的问题是：在观测到**整个**序列后，在**特定时刻** $t$ 系统处于状态 $s_i$ 的概率是多少？即 $P(Z_t = s_i | O, \lambda)$。这被称为**平滑 (smoothing)**，因为它利用了过去和未来的所有信息来推断当前状态。

为了解决这个问题，我们需要引入一个与前向变量相对应的**后向变量 (backward variable)** $\beta_t(i)$ [@problem_id:765245]：
$$\beta_t(i) = P(O_{t+1}, \dots, O_T | Z_t = s_i, \lambda)$$
这个变量表示在时刻 $t$ 处于状态 $s_i$ 的条件下，未来观测序列 $O_{t+1}, \dots, O_T$ 出现的概率。它的计算也是递归的，但方向是从后往前：

**1. 初始化 (t=T):**
按照定义，$\beta_T(i) = 1$ 对所有 $i$ 成立。

**2. 归纳 (t = T-1, ..., 1):**
要计算 $\beta_t(i)$，我们考虑时刻 $t+1$ 的所有可能状态 $s_j$。从 $s_i$ 转移到 $s_j$（概率 $a_{ij}$），然后从 $s_j$ 产生观测 $O_{t+1}$（概率 $b_j(O_{t+1})$），再接着产生余下的观测序列（概率 $\beta_{t+1}(j)$）。将所有可能的 $s_j$ 的情况加总：
$$\beta_t(i) = \sum_{j=1}^N a_{ij} b_j(O_{t+1}) \beta_{t+1}(j)$$

有了前向和后向变量，我们就可以计算我们感兴趣的平滑[后验概率](@entry_id:153467)，通常记为 $\gamma_t(i)$：
$$\gamma_t(i) = P(Z_t=s_i | O, \lambda)$$
根据概率定义，这个条件概率等于[联合概率](@entry_id:266356) $P(Z_t=s_i, O | \lambda)$ 除以 $P(O|\lambda)$。[联合概率](@entry_id:266356)可以被 $\alpha_t(i)$ 和 $\beta_t(i)$ 巧妙地分解：
$$P(Z_t=s_i, O | \lambda) = P(O_1, \dots, O_t, Z_t=s_i | \lambda) \cdot P(O_{t+1}, \dots, O_T | Z_t=s_i, O_1, \dots, O_t, \lambda)$$
由于观测独立性，第二项简化为 $P(O_{t+1}, \dots, O_T | Z_t=s_i, \lambda)$，这正是 $\beta_t(i)$ 的定义。第一项就是 $\alpha_t(i)$ 的定义。因此：
$$P(Z_t=s_i, O | \lambda) = \alpha_t(i) \beta_t(i)$$
而分母 $P(O|\lambda)$ 可以通过在任意时刻 $t$ 对所有状态求和得到：$P(O|\lambda) = \sum_{j=1}^N \alpha_t(j) \beta_t(j)$。
最终，我们得到 $\gamma_t(i)$ 的表达式 [@problem_id:765245]：
$$\gamma_t(i) = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}$$

#### [维特比路径](@entry_id:271181)与最大后验状态的区别
这里存在一个非常重要且微妙的区别。[维特比算法](@entry_id:269328)找到的全局最优路径 $Q^* = (q_1^*, \dots, q_T^*)$ 上的状态 $q_t^*$，与通过[前向-后向算法](@entry_id:194772)找到的在时刻 $t$ 具有[最大后验概率](@entry_id:268939)的状态 $\arg\max_i \gamma_t(i)$，两者**可能不相同** [@problem_id:1306018]。

-   **[维特比算法](@entry_id:269328)**寻找的是一条**单一的、整体概率最高**的路径。它在每一步都进行剪枝，可能会放弃一些局部看起来不是最优、但能汇入未来高概率状态的路径。
-   **[前向-后向算法](@entry_id:194772)**计算的 $\gamma_t(i)$ 则考虑了**所有穿过**状态 $s_i$ 的路径的概率总和。一个状态可能成为时刻 $t$ 的最大后验状态，不是因为它属于那条唯一的最佳路径，而是因为有大量“相当不错”的路径都经过了它，这些路径的概率总和超过了其他任何状态。

可以想象成寻找从城市A到城市B的最佳路线。[维特比算法](@entry_id:269328)会给你一条全程最优的单一路线（例如，全程高速）。而[前向-后向算法](@entry_id:194772)可能会在途中的某个城市C告诉你，大多数合理的旅行计划都会经过C，即使那条全程最优的高速公路绕过了C。因此，尽管[维特比路径](@entry_id:271181)上的状态是全局最优序列的一部分，但它不一定是每个时间点上最可信赖的单个[状态估计](@entry_id:169668)。选择哪种方法取决于你的具体目标：是需要一个连贯的故事（维特比），还是在每个时间点上最稳妥的猜测（前向-后向）。

本章系统地介绍了隐马尔可夫模型的数学原理和三大核心算法的其中两种。通过理解这些机制，我们不仅能够应用 HMM 解决实际问题，更能深入领会其作为一种动态系统建模工具的优雅与力量。