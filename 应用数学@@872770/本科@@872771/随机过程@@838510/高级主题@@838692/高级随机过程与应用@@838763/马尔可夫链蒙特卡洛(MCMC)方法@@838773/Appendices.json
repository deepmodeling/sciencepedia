{"hands_on_practices": [{"introduction": "Metropolis-Hastings 算法的核心在于其巧妙的接受准则，它决定了马尔可夫链是否移动到一个新的状态。这个练习将带你直接计算这个接受概率，这是理解 MCMC 方法如何平衡探索（移动到新区域）和利用（停留在高概率区域）的关键第一步。通过这个具体的计算 [@problem_id:1371728]，你将掌握 MCMC 采样器的基本工作机制。", "problem": "一位数据科学家正在实现一个马尔可夫链蒙特卡洛 (MCMC) 模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与参数负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法和一个对称提议分布 $q(x'|x)$，其中给定当前状态 $x$ 提议新状态 $x'$ 的概率等于给定 $x'$ 提议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态为 $x = 1.5$。然后算法提议移动到一个新的候选状态 $x' = 2.0$。\n\n计算这次特定移动的接受概率。你的答案应该是一个无量纲的实数。将最终答案四舍五入到四位有效数字。", "solution": "对于从 $x$ 到 $x'$ 的移动，当提议分布 $q(x'|x)=q(x|x')$ 是对称的时，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，$\\exp(-0.5)\\approx 0.6065$（四舍五入到四位有效数字）。", "answer": "$$\\boxed{0.6065}$$", "id": "1371728"}, {"introduction": "当处理高维问题时，直接对所有变量进行采样可能非常困难，此时吉布斯采样 (Gibbs sampling) 提供了一种强大的替代方案。该方法通过迭代地从每个变量的条件分布中进行采样来更新状态。这个练习的核心任务是从一个复杂的多维联合分布中推导出所需的条件分布 [@problem_id:1316600]，这是实现吉布斯采样的关键前提和核心技能。", "problem": "考虑一个由A和B两种相互作用的粒子组成的系统。设随机变量 $X$ 和 $Y$ 分别表示A类粒子和B类粒子的数量。粒子对 $(X, Y)$ 的状态空间是所有非负整数对的集合，即 $(x, y)$，其中 $x, y \\in \\{0, 1, 2, \\ldots\\}$。已知观测到特定状态 $(x, y)$ 的联合概率质量函数与以下函数成正比\n$$\nf(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)\n$$\n其中 $\\alpha$、$\\beta$ 和 $\\lambda$ 是正常数，分别代表固有的产生率和相互作用强度。\n\n您的任务是推导对于固定的 $y$ 的条件概率质量函数 $P(X=x | Y=y)$ 和对于固定的 $x$ 的条件概率质量函数 $P(Y=y | X=x)$。将您的最终答案表示为这两个概率的一对符号表达式。", "solution": "问题要求对于一个联合分布，其中 $P(X=x, Y=y) \\propto f(x, y)$，求其条件概率质量函数（PMF）$P(X=x | Y=y)$ 和 $P(Y=y | X=x)$。\n\n对于离散随机变量，条件概率的基本定义是：\n$$\nP(X=x | Y=y) = \\frac{P(X=x, Y=y)}{P(Y=y)}\n$$\n边缘概率质量函数 $P(Y=y)$ 是通过将联合概率质量函数对所有可能的 $X$ 值求和得到的：\n$$\nP(Y=y) = \\sum_{x'=0}^{\\infty} P(X=x', Y=y)\n$$\n由于联合概率质量函数与 $f(x, y)$ 成正比，我们可以写成 $P(X=x, Y=y) = C \\cdot f(x, y)$，其中 $C$ 是一个不依赖于 $x$ 或 $y$ 的归一化常数。将此代入条件概率公式，我们得到：\n$$\nP(X=x | Y=y) = \\frac{C \\cdot f(x, y)}{\\sum_{x'=0}^{\\infty} C \\cdot f(x', y)} = \\frac{f(x, y)}{\\sum_{x'=0}^{\\infty} f(x', y)}\n$$\n这表明我们可以在不需要计算总归一化常数 $C$ 的情况下求出条件分布。\n\n首先，我们来推导 $P(X=x | Y=y)$。\n分子是 $f(x, y) = \\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)$。\n分母是对于一个固定的 $y$，对所有可能的 $x'$ 值求和：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'} \\beta^y}{x' ! y!} \\exp(-\\lambda x' y)\n$$\n在这个求和中，$y$ 是一个常数。我们可以将所有不依赖于求和指数 $x'$ 的项提取出来：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{\\alpha^{x'}}{x'!} \\exp(-\\lambda x' y) = \\frac{\\beta^y}{y!} \\sum_{x'=0}^{\\infty} \\frac{(\\alpha \\exp(-\\lambda y))^{x'}}{x'!}\n$$\n这个求和具有指数函数泰勒级数的形式，$\\sum_{k=0}^{\\infty} \\frac{z^k}{k!} = \\exp(z)$。在我们的例子中，$z = \\alpha \\exp(-\\lambda y)$。因此，这个和是：\n$$\n\\sum_{x'=0}^{\\infty} f(x', y) = \\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))\n$$\n现在我们可以写出条件概率：\n$$\nP(X=x | Y=y) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\beta^y}{y!} \\exp(\\alpha \\exp(-\\lambda y))}\n$$\n项 $\\frac{\\beta^y}{y!}$ 被消掉，剩下：\n$$\nP(X=x | Y=y) = \\frac{\\alpha^x \\exp(-\\lambda x y)}{x! \\exp(\\alpha \\exp(-\\lambda y))} = \\frac{(\\alpha \\exp(-\\lambda y))^x}{x!} \\exp(-\\alpha \\exp(-\\lambda y))\n$$\n这是一个参数为 $\\alpha \\exp(-\\lambda y)$ 的泊松分布的概率质量函数。\n\n接下来，我们来推导 $P(Y=y | X=x)$。这个过程是对称的。\n$$\nP(Y=y | X=x) = \\frac{f(x, y)}{\\sum_{y'=0}^{\\infty} f(x, y')}\n$$\n分母是对于一个固定的 $x$，对所有可能的 $y'$ 值求和：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\sum_{y'=0}^{\\infty} \\frac{\\alpha^x \\beta^{y'}}{x! y'!} \\exp(-\\lambda x y')\n$$\n将不依赖于求和指数 $y'$ 的项提取出来：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{\\beta^{y'}}{y'!} \\exp(-\\lambda x y') = \\frac{\\alpha^x}{x!} \\sum_{y'=0}^{\\infty} \\frac{(\\beta \\exp(-\\lambda x))^{y'}}{y'!}\n$$\n再次使用指数函数的泰勒级数，其中 $z = \\beta \\exp(-\\lambda x)$：\n$$\n\\sum_{y'=0}^{\\infty} f(x, y') = \\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))\n$$\n现在我们写出条件概率：\n$$\nP(Y=y | X=x) = \\frac{\\frac{\\alpha^x \\beta^y}{x! y!} \\exp(-\\lambda x y)}{\\frac{\\alpha^x}{x!} \\exp(\\beta \\exp(-\\lambda x))}\n$$\n项 $\\frac{\\alpha^x}{x!}$ 被消掉，剩下：\n$$\nP(Y=y | X=x) = \\frac{\\beta^y \\exp(-\\lambda x y)}{y! \\exp(\\beta \\exp(-\\lambda x))} = \\frac{(\\beta \\exp(-\\lambda x))^y}{y!} \\exp(-\\beta \\exp(-\\lambda x))\n$$\n这是一个参数为 $\\beta \\exp(-\\lambda x)$ 的泊松分布的概率质量函数。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{(\\alpha \\exp(-\\lambda y))^{x}}{x!} \\exp(-\\alpha \\exp(-\\lambda y)),  \\frac{(\\beta \\exp(-\\lambda x))^{y}}{y!} \\exp(-\\beta \\exp(-\\lambda x)) \\end{pmatrix}}\n$$", "id": "1316600"}, {"introduction": "MCMC 方法虽然功能强大，但并非“即插即用”的黑箱，其性能严重依赖于参数的选择。本练习作为一个思想实验，探讨了一种经典的采样失败模式：当目标分布存在多个分离的峰（多模态）时，一个参数设置不当的采样器可能被困在局部，无法探索整个分布。通过分析这种情况 [@problem_id:1932795]，你将更深刻地理解 MCMC 实践中诊断和调试的重要性。", "problem": "一位数据科学家正在使用马尔可夫链蒙特卡洛（MCMC）方法从一个复杂的一维目标概率密度函数 $\\pi(x)$ 中抽取样本。已知目标分布是一个对称双峰分布，具体来说是两个等权重高斯分布的混合。该密度与两个高斯概率密度函数之和成正比：\n$$ \\pi(x) \\propto \\exp\\left(-\\frac{(x - \\mu_A)^2}{2\\sigma_{mode}^2}\\right) + \\exp\\left(-\\frac{(x - \\mu_B)^2}{2\\sigma_{mode}^2}\\right) $$\n给定参数为 $\\mu_A = -10$，$\\mu_B = 10$，以及 $\\sigma_{mode} = 1$。这种结构导致在 $x=-10$ 和 $x=10$ 处有两个狭窄且分离良好的概率峰，它们之间存在一个概率密度极低的区域。\n\n该科学家使用随机游走Metropolis算法。在每一步，从以当前状态 $x_t$ 为中心的高斯分布中提议一个新状态 $x'$，即 $x' \\sim N(x_t, \\sigma_{step}^2)$。为了获得高接受率，该科学家选择了一个非常小的步长方差，设定 $\\sigma_{step} = 0.1$。MCMC链在其中一个峰的峰值处初始化，即 $x_0 = -10$，并运行 $N=10^6$ 次迭代。\n\n下列哪个陈述最准确地描述了该MCMC采样器的行为以及所得到的样本集 $\\{x_1, x_2, \\dots, x_N\\}$ 的统计特性？\n\nA. 样本将分布在目标分布的真实均值 $x=0$ 附近。样本均值将接近于0，但样本方差会很大（大于100），准确地反映了两个峰之间的显著分离。\n\nB. 提议移动的接受率将非常低（接近0），因为步长没有很好地适应目标分布的整体尺度。链将停留在其初始位置 $x_0 = -10$ 或其附近。\n\nC. 提议移动的接受率将非常高（接近1）。生成的样本将充分探索对应于 $x=-10$ 处峰的区域，但链将无法转换到位于 $x=10$ 的另一个峰。样本均值将约为-10。\n\nD. 采样器将有效地探索整个状态空间。链将在两个峰之间频繁地来回跳跃，样本的直方图将正确地形成以 $x=-10$ 和 $x=10$ 为中心的两个不同峰。\n\nE. 采样器的行为将像一个简单的随机游走，导致样本从起始点扩散开来。最终的样本集合将在以 $x=-10$ 为中心的宽区间上近似均匀分布。", "solution": "我们将目标建模为两个具有相同标准差 $\\sigma_{mode}$ 和均值 $\\mu_{A}$、$\\mu_{B}$ 的等权重高斯密度的混合。在不考虑比例常数的情况下，\n$$\n\\pi(x) \\propto \\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right) + \\exp\\!\\left(-\\frac{(x-\\mu_{B})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n对于使用对称高斯提议 $q(x' \\mid x)=\\mathcal{N}(x,\\sigma_{step}^{2})$ 的随机游走Metropolis采样器，在状态 $x_t$ 对提议 $x'$ 的Metropolis-Hastings接受概率为\n$$\n\\alpha(x_{t},x')=\\min\\!\\left(1,\\frac{\\pi(x')}{\\pi(x_{t})}\\right).\n$$\n\n在 $x_{0}=\\mu_{A}$ 处初始化。由于两个峰分离良好，当 $x$ 靠近 $\\mu_{A}$ 时，$\\pi(x)$ 中来自 $\\mu_{B}$ 分量的贡献相对于来自 $\\mu_{A}$ 分量的贡献可以忽略不计。对于一个小的提议增量 $\\epsilon:=x'-x$，且 $|\\epsilon| \\ll \\sigma_{mode}$，主导比率近似给出\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\frac{\\exp\\!\\left(-\\frac{(x'-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}{\\exp\\!\\left(-\\frac{(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right)}=\\exp\\!\\left(-\\frac{(x'-\\mu_{A})^{2}-(x-\\mu_{A})^{2}}{2\\sigma_{mode}^{2}}\\right).\n$$\n在 $x\\approx\\mu_{A}$ 处，对于小的 $\\epsilon$，这可以简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)} \\approx \\exp\\!\\left(-\\frac{\\epsilon^{2}}{2\\sigma_{mode}^{2}}\\right),\n$$\n因此，当 $\\sigma_{step} \\ll \\sigma_{mode}$ 时，接受概率接近1，因为典型的 $|\\epsilon|$ 与 $\\sigma_{step}$ 是同一数量级。因此，当链在起始峰附近探索时，接受率非常高。\n\n在一次提议中从 $\\mu_{A}$ 的邻域直接跳到 $\\mu_{B}$ 的邻域，需要一个量级为 $|\\mu_{B}-\\mu_{A}|$ 的位移。在方差为 $\\sigma_{step}^{2}$ 的高斯提议下，这样一次跳跃的概率量级为\n$$\n\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{2\\sigma_{step}^{2}}\\right),\n$$\n当 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{step}$ 时，这个概率可以忽略不计。\n\n通过许多小的被接受的步长来穿过低密度区域，在有限的运行时间内也是极不可能的，因为谷底的平稳密度比峰值处的密度要小指数级别。在中点 $x^{\\star}=(\\mu_{A}+\\mu_{B})/2$ 处，目标密度为\n$$\n\\pi(x^{\\star}) \\propto 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right),\n$$\n而在 $x=\\mu_{A}$ 附近，密度为 $\\pi(\\mu_{A}) \\propto 1$（那里的另一个分量可以忽略不计）。因此，比率\n$$\n\\frac{\\pi(x^{\\star})}{\\pi(\\mu_{A})} \\approx 2\\exp\\!\\left(-\\frac{(\\mu_{B}-\\mu_{A})^{2}}{8\\sigma_{mode}^{2}}\\right)\n$$\n当 $|\\mu_{B}-\\mu_{A}| \\gg \\sigma_{mode}$ 时，这个比率是指数级小的。这意味着到达谷底或另一个峰的期望时间是指数级大的，其数量级是这个比率的倒数，当分离很大且提议非常局部时，这个时间远远超过给定的 $N$。\n\n因此，当选择的 $\\sigma_{step}$ 相对于 $\\sigma_{mode}$ 非常小，并且峰被很好地分离时，链具有非常高的接受率，会彻底探索起始峰 $x=\\mu_{A}$ 周围的局部盆地，在运行时间内基本上永远不会转换到另一个峰，并且得到的样本均值约等于 $\\mu_{A}$。在这些选项中，这对应于陈述C。", "answer": "$$\\boxed{C}$$", "id": "1932795"}]}