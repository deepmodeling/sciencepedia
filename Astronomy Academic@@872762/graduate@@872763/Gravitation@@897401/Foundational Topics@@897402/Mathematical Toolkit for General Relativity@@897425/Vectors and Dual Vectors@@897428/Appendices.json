{"hands_on_practices": [{"introduction": "The concept of a dual basis is most tangible when approached from a geometric standpoint, especially when dealing with non-orthogonal coordinate systems. This exercise provides a direct, hands-on method for constructing a dual basis vector using the fundamental defining relationship $\\vec{e}^i \\cdot \\vec{e}_j = \\delta^i_j$. By working through this concrete calculation in a simple 2D space, you will build a solid intuition for the geometric interplay between a vector basis and its dual counterpart.", "problem": "In a two-dimensional Euclidean vector space, a non-orthogonal basis, often called a covariant basis, is defined by the vectors $\\vec{e}_1 = 2\\hat{i} + \\hat{j}$ and $\\vec{e}_2 = \\hat{i} + 2\\hat{j}$, where $\\{\\hat{i}, \\hat{j}\\}$ represents the standard orthonormal Cartesian basis. The corresponding dual basis, also known as the contravariant basis, is denoted by $\\{\\vec{e}^1, \\vec{e}^2\\}$. The relationship between the covariant and contravariant basis vectors is given by the condition $\\vec{e}^i \\cdot \\vec{e}_j = \\delta^i_j$, where $\\delta^i_j$ is the Kronecker delta (i.e., $\\delta^i_j = 1$ if $i=j$ and $\\delta^i_j = 0$ if $i \\neq j$), and the dot product is the standard Euclidean inner product.\n\nDetermine the first contravariant basis vector, $\\vec{e}^1$. Express your answer as a linear combination of the Cartesian basis vectors $\\hat{i}$ and $\\hat{j}$.", "solution": "We are given a non-orthogonal basis in a two-dimensional Euclidean space: $\\vec{e}_{1} = 2\\hat{i} + \\hat{j}$ and $\\vec{e}_{2} = \\hat{i} + 2\\hat{j}$. The dual (contravariant) basis vectors $\\{\\vec{e}^{1}, \\vec{e}^{2}\\}$ satisfy the defining relations $\\vec{e}^{i} \\cdot \\vec{e}_{j} = \\delta^{i}_{j}$ with the standard Euclidean dot product.\n\nTo determine $\\vec{e}^{1}$, write it as an unknown linear combination of the Cartesian basis:\n$$\n\\vec{e}^{1} = x\\hat{i} + y\\hat{j}.\n$$\nImpose the duality conditions:\n$$\n\\vec{e}^{1} \\cdot \\vec{e}_{1} = 1, \\quad \\vec{e}^{1} \\cdot \\vec{e}_{2} = 0.\n$$\nUsing the standard inner product with $\\hat{i}\\cdot\\hat{i} = 1$, $\\hat{j}\\cdot\\hat{j} = 1$, and $\\hat{i}\\cdot\\hat{j} = 0$, compute\n$$\n\\vec{e}^{1} \\cdot \\vec{e}_{1} = (x\\hat{i} + y\\hat{j}) \\cdot (2\\hat{i} + \\hat{j}) = 2x + y = 1,\n$$\n$$\n\\vec{e}^{1} \\cdot \\vec{e}_{2} = (x\\hat{i} + y\\hat{j}) \\cdot (\\hat{i} + 2\\hat{j}) = x + 2y = 0.\n$$\nThis yields the linear system\n$$\n\\begin{cases}\n2x + y = 1,\\\\\nx + 2y = 0.\n\\end{cases}\n$$\nSolve the system: from $x + 2y = 0$ obtain $x = -2y$. Substitute into $2x + y = 1$ to get $2(-2y) + y = -4y + y = -3y = 1$, hence $y = -\\frac{1}{3}$. Then $x = -2\\left(-\\frac{1}{3}\\right) = \\frac{2}{3}$.\n\nTherefore,\n$$\n\\vec{e}^{1} = \\frac{2}{3}\\hat{i} - \\frac{1}{3}\\hat{j}.\n$$\nThis satisfies the required duality relations with $\\vec{e}_{1}$ and $\\vec{e}_{2}$.", "answer": "$$\\boxed{\\frac{2}{3}\\hat{i}-\\frac{1}{3}\\hat{j}}$$", "id": "1490711"}, {"introduction": "Beyond the geometric picture, the concept of duality extends to a more abstract and powerful algebraic framework. In this view, dual vectors are not just geometric objects but are understood as linear functionalsâ€”maps that take a vector and return a scalar. This practice explores this idea within the context of a vector space of polynomials, demonstrating the universality of duality and providing a clear procedure for finding the components of a given functional in the dual basis.", "problem": "Consider the real vector space $V = P_1(\\mathbb{R})$, which consists of all polynomials of degree at most one with real coefficients. Let $B = \\{\\mathbf{v}_1, \\mathbf{v}_2\\}$ be an ordered basis for $V$, where the basis vectors are defined as the polynomials $\\mathbf{v}_1(x) = 1+x$ and $\\mathbf{v}_2(x) = 1-x$.\n\nA linear functional $L: V \\to \\mathbb{R}$ acts on any polynomial $p(x) \\in V$ according to the rule:\n$$L(p) = \\int_0^1 (3x+2) p(x) dx$$\n\nLet $B^* = \\{\\omega^1, \\omega^2\\}$ denote the dual basis corresponding to the ordered basis $B$. Any linear functional in the dual space $V^*$, including $L$, can be expressed as a unique linear combination of these dual basis vectors. For the functional $L$, this expansion is written as $L = c_1 \\omega^1 + c_2 \\omega^2$.\n\nDetermine the ordered pair of coefficients $(c_1, c_2)$.", "solution": "We work in $V = P_{1}(\\mathbb{R})$ with ordered basis $B = \\{\\mathbf{v}_{1}, \\mathbf{v}_{2}\\}$ where $\\mathbf{v}_{1}(x) = 1 + x$ and $\\mathbf{v}_{2}(x) = 1 - x$. The dual basis $B^{*} = \\{\\omega^{1}, \\omega^{2}\\}$ is defined by $\\omega^{i}(\\mathbf{v}_{j}) = \\delta^{i}_{j}$. Any linear functional $L \\in V^{*}$ can be written as $L = c_{1}\\omega^{1} + c_{2}\\omega^{2}$. Evaluating on basis vectors and using the duality property gives\n$$\nL(\\mathbf{v}_{j}) = c_{1}\\omega^{1}(\\mathbf{v}_{j}) + c_{2}\\omega^{2}(\\mathbf{v}_{j}) = c_{1}\\delta^{1}_{j} + c_{2}\\delta^{2}_{j},\n$$\nhence $c_{1} = L(\\mathbf{v}_{1})$ and $c_{2} = L(\\mathbf{v}_{2})$.\n\nCompute $c_{1}$:\n$$\nc_{1} = L(\\mathbf{v}_{1}) = \\int_{0}^{1} (3x+2)(1+x)\\,dx.\n$$\nExpand the integrand:\n$$\n(3x+2)(1+x) = 3x^{2} + 5x + 2.\n$$\nIntegrate term by term:\n$$\n\\int_{0}^{1} 3x^{2}\\,dx = \\left[x^{3}\\right]_{0}^{1} = 1,\\quad \\int_{0}^{1} 5x\\,dx = \\frac{5}{2},\\quad \\int_{0}^{1} 2\\,dx = 2.\n$$\nThus,\n$$\nc_{1} = 1 + \\frac{5}{2} + 2 = \\frac{11}{2}.\n$$\n\nCompute $c_{2}$:\n$$\nc_{2} = L(\\mathbf{v}_{2}) = \\int_{0}^{1} (3x+2)(1 - x)\\,dx.\n$$\nExpand the integrand:\n$$\n(3x+2)(1 - x) = -3x^{2} + x + 2.\n$$\nIntegrate term by term:\n$$\n\\int_{0}^{1} (-3x^{2})\\,dx = -\\left[x^{3}\\right]_{0}^{1} = -1,\\quad \\int_{0}^{1} x\\,dx = \\frac{1}{2},\\quad \\int_{0}^{1} 2\\,dx = 2.\n$$\nThus,\n$$\nc_{2} = -1 + \\frac{1}{2} + 2 = \\frac{3}{2}.\n$$\n\nTherefore, the ordered pair of coefficients is $\\left(c_{1}, c_{2}\\right) = \\left(\\frac{11}{2}, \\frac{3}{2}\\right)$.", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{11}{2} & \\frac{3}{2}\\end{pmatrix}}$$", "id": "1508843"}, {"introduction": "The distinction between vectors and dual vectors becomes critically important in physics, particularly in the study of gravitation and curved spacetime. The metric tensor, which defines the geometry of spacetime, serves as the essential tool for converting between vectors and their duals through the operations of raising and lowering indices. This exercise places you directly in this physical context, challenging you to use a non-trivial spacetime metric to find the vector field dual to a given covector field and compute its invariant squared norm.", "problem": "In a spacetime manifold described by a metric tensor $g_{\\mu\\nu}$, a one-form (covector) field $\\omega$ with components $\\omega_\\mu$ is related to a unique vector field $V$ with components $V^\\mu$ through the metric. This relationship is given by the operation of \"raising the index\":\n$$V^\\mu = g^{\\mu\\nu}\\omega_\\nu$$\nwhere $g^{\\mu\\nu}$ is the inverse metric tensor, satisfying $g^{\\mu\\rho}g_{\\rho\\nu}=\\delta^\\mu_\\nu$. The squared norm of the vector field $V$ is the scalar invariant given by $V^2 = g_{\\mu\\nu}V^\\mu V^\\nu$.\n\nConsider a 4-dimensional spacetime with coordinates $x^\\mu = (x^0, x^1, x^2, x^3)$. The geometry of this spacetime is described by a conformally flat metric of the form:\n$$g_{\\mu\\nu}(x) = \\Omega^2(x) \\eta_{\\mu\\nu}$$\nwhere $\\eta_{\\mu\\nu}$ is the flat Minkowski metric with signature $(-,+,+,+)$, i.e., $\\eta_{\\mu\\nu} = \\text{diag}(-1, 1, 1, 1)$. The conformal factor is given by:\n$$\\Omega(x) = e^{\\alpha x^1}$$\nwhere $\\alpha$ is a non-zero real constant.\n\nLet $\\omega$ be a one-form field whose components $\\omega_\\mu = C_\\mu$ are constant throughout the spacetime, where $C_\\mu = (C_0, C_1, C_2, C_3)$ are four arbitrary real constants.\n\nCalculate the squared norm, $V^2$, of the vector field $V^\\mu$ that is dual to $\\omega_\\mu$. Express your answer in terms of $\\alpha$, the coordinate $x^1$, and the constant components $C_\\mu$.", "solution": "The solution is found by following these steps:\n\n1.  **Find the inverse metric.** The metric $g_{\\mu\\nu} = \\Omega^2 \\eta_{\\mu\\nu}$ is diagonal, so its inverse is $g^{\\mu\\nu} = \\Omega^{-2} \\eta^{\\mu\\nu} = e^{-2\\alpha x^1} \\eta^{\\mu\\nu}$.\n2.  **Raise the index.** The vector field $V^\\mu$ dual to $\\omega_\\nu$ is found by $V^\\mu = g^{\\mu\\nu}\\omega_\\nu$. Since $\\omega_\\nu=C_\\nu$ are constants, we have $V^\\mu = e^{-2\\alpha x^1} \\eta^{\\mu\\nu} C_\\nu$.\n3.  **Calculate the squared norm.** The invariant norm is $V^2 = g_{\\mu\\nu}V^\\mu V^\\nu$. Substituting the expressions for the metric and the vector components and simplifying gives:\n    $$\n    \\begin{aligned}\n    V^2 &= (e^{2\\alpha x^1} \\eta_{\\mu\\nu}) (e^{-2\\alpha x^1} \\eta^{\\mu\\alpha} C_\\alpha) (e^{-2\\alpha x^1} \\eta^{\\nu\\beta} C_\\beta) \\\\\n    &= e^{-2\\alpha x^1} (\\eta_{\\mu\\nu} \\eta^{\\mu\\alpha} \\eta^{\\nu\\beta}) C_\\alpha C_\\beta\n    \\end{aligned}\n    $$\n    Using the identity $\\eta_{\\mu\\nu}\\eta^{\\mu\\alpha} = \\delta^\\alpha_\\nu$, this becomes $V^2 = e^{-2\\alpha x^1} (\\delta^\\alpha_\\nu \\eta^{\\nu\\beta}) C_\\alpha C_\\beta = e^{-2\\alpha x^1} \\eta^{\\alpha\\beta} C_\\alpha C_\\beta$.\n4.  **Expand the final term.** The contraction with the Minkowski metric gives $\\eta^{\\alpha\\beta} C_\\alpha C_\\beta = -C_0^2 + C_1^2 + C_2^2 + C_3^2$.\n\nCombining these results, the final expression for the squared norm is:\n$$ V^2 = e^{-2\\alpha x^1}(-C_0^2 + C_1^2 + C_2^2 + C_3^2) $$", "answer": "$$\\boxed{e^{-2\\alpha x^1}\\bigl(-C_0^2 + C_1^2 + C_2^2 + C_3^2\\bigr)}$$", "id": "926819"}]}