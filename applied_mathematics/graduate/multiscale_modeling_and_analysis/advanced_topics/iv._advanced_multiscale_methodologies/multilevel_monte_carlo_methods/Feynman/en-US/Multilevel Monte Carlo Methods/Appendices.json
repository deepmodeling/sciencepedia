{
    "hands_on_practices": [
        {
            "introduction": "The remarkable efficiency of the Multilevel Monte Carlo method hinges on a single, powerful idea: using correlated sampling to dramatically reduce the variance of the corrections between successive discretization levels. This first practice invites you to explore this foundational principle from the ground up . By analyzing a simple stochastic differential equation, you will derive and contrast the variance of the level difference, $\\mathrm{Var}(P_\\ell - P_{\\ell-1})$, under correct coupling versus an uncoupled, independent sampling strategy, making the mechanism of variance reduction tangible and clear.",
            "id": "3068034",
            "problem": "Consider the scalar stochastic differential equation (SDE) $dX_t = \\sigma\\, dW_t$ with $X_0 = 0$ on the time interval $[0,T]$, where $W_t$ is a standard Wiener process and $\\sigma > 0$ is a constant. Let $P_\\ell$ denote the Euler–Maruyama terminal approximation of $X_T$ computed on level $\\ell$ with $N_\\ell$ steps of size $h_\\ell = T/N_\\ell$, and let $P_{\\ell-1}$ denote the corresponding approximation computed on level $\\ell-1$ with $N_{\\ell-1} = N_\\ell/2$ steps of size $h_{\\ell-1} = 2 h_\\ell$. In both cases, the Euler–Maruyama scheme is defined by $X_{n+1} = X_n + \\sigma\\, \\Delta W_n$, where each Brownian increment $\\Delta W_n$ is distributed as $\\mathcal{N}(0,h)$ with $h$ equal to the relevant step size. Define $P_\\ell = \\sum_{n=1}^{N_\\ell} \\sigma\\, \\Delta W^{(\\ell)}_n$ and $P_{\\ell-1} = \\sum_{m=1}^{N_{\\ell-1}} \\sigma\\, \\Delta W^{(\\ell-1)}_m$. In the Multilevel Monte Carlo (MLMC) method, coupling across levels is used to reduce the variance of the level differences.\n\nTwo coupling strategies are considered:\n- Correct coupling: for each $m \\in \\{1,\\dots,N_{\\ell-1}\\}$, set $\\Delta W^{(\\ell-1)}_m = \\Delta W^{(\\ell)}_{2m-1} + \\Delta W^{(\\ell)}_{2m}$, where the fine-level increments $\\{\\Delta W^{(\\ell)}_n\\}_{n=1}^{N_\\ell}$ are independent and identically distributed with law $\\mathcal{N}(0,h_\\ell)$.\n- Incorrect coupling: generate $\\{\\Delta W^{(\\ell-1)}_m\\}_{m=1}^{N_{\\ell-1}}$ as independent and identically distributed $\\mathcal{N}(0,h_{\\ell-1})$ increments that are independent of the fine-level increments $\\{\\Delta W^{(\\ell)}_n\\}_{n=1}^{N_\\ell}$.\n\nStarting only from the properties of independent Gaussian increments of Brownian motion and the variance additivity for independent random variables, derive $\\mathrm{Var}(P_\\ell - P_{\\ell-1})$ under each coupling strategy. Then, express the incorrect-coupling variance $\\mathrm{Var}(P_\\ell - P_{\\ell-1})$ as a simplified closed-form analytic expression in terms of $\\sigma$ and $T$. Your final answer must be this expression. No rounding is required.",
            "solution": "The problem requires the derivation of the variance of the difference between a fine and a coarse Euler-Maruyama approximation, $\\mathrm{Var}(P_\\ell - P_{\\ell-1})$, under two different coupling strategies for the stochastic differential equation (SDE) $dX_t = \\sigma\\, dW_t$ with $X_0 = 0$. The final answer is the specific expression for this variance under the incorrect coupling strategy.\n\nLet $P_\\ell$ and $P_{\\ell-1}$ be the random variables representing the numerical approximations at the terminal time $T$ on level $\\ell$ (fine) and level $\\ell-1$ (coarse), respectively. The general formula for the variance of the difference of two random variables is:\n$$\n\\mathrm{Var}(P_\\ell - P_{\\ell-1}) = \\mathrm{Var}(P_\\ell) + \\mathrm{Var}(P_{\\ell-1}) - 2 \\mathrm{Cov}(P_\\ell, P_{\\ell-1})\n$$\nWe analyze each coupling strategy by first calculating the individual variances, $\\mathrm{Var}(P_\\ell)$ and $\\mathrm{Var}(P_{\\ell-1})$, and then evaluating the covariance term.\n\nThe fine-level approximation is given by $P_\\ell = \\sum_{n=1}^{N_\\ell} \\sigma\\, \\Delta W^{(\\ell)}_n$, where $\\{\\Delta W^{(\\ell)}_n\\}_{n=1}^{N_\\ell}$ are independent and identically distributed (i.i.d.) random variables with distribution $\\mathcal{N}(0,h_\\ell)$. The variance of $P_\\ell$ is calculated using the property of variance additivity for independent random variables and the scaling property $\\mathrm{Var}(aZ) = a^2 \\mathrm{Var}(Z)$:\n$$\n\\mathrm{Var}(P_\\ell) = \\mathrm{Var}\\left(\\sigma \\sum_{n=1}^{N_\\ell} \\Delta W^{(\\ell)}_n\\right) = \\sigma^2 \\mathrm{Var}\\left(\\sum_{n=1}^{N_\\ell} \\Delta W^{(\\ell)}_n\\right)\n$$\nSince the increments $\\Delta W^{(\\ell)}_n$ are independent, the variance of their sum is the sum of their variances:\n$$\n\\mathrm{Var}(P_\\ell) = \\sigma^2 \\sum_{n=1}^{N_\\ell} \\mathrm{Var}(\\Delta W^{(\\ell)}_n) = \\sigma^2 \\sum_{n=1}^{N_\\ell} h_\\ell = \\sigma^2 N_\\ell h_\\ell\n$$\nGiven that the step size is $h_\\ell = T/N_\\ell$, we have $N_\\ell h_\\ell = T$. Therefore, the variance of the fine-level approximation is:\n$$\n\\mathrm{Var}(P_\\ell) = \\sigma^2 T\n$$\nSimilarly, the coarse-level approximation is given by $P_{\\ell-1} = \\sum_{m=1}^{N_{\\ell-1}} \\sigma\\, \\Delta W^{(\\ell-1)}_m$, where the increments $\\Delta W^{(\\ell-1)}_m$ are i.i.d. $\\mathcal{N}(0,h_{\\ell-1})$. Following the same logic:\n$$\n\\mathrm{Var}(P_{\\ell-1}) = \\sigma^2 \\sum_{m=1}^{N_{\\ell-1}} \\mathrm{Var}(\\Delta W^{(\\ell-1)}_m) = \\sigma^2 \\sum_{m=1}^{N_{\\ell-1}} h_{\\ell-1} = \\sigma^2 N_{\\ell-1} h_{\\ell-1}\n$$\nGiven $h_{\\ell-1} = T/N_{\\ell-1}$, we have $N_{\\ell-1} h_{\\ell-1} = T$. Thus, the variance of the coarse-level approximation is:\n$$\n\\mathrm{Var}(P_{\\ell-1}) = \\sigma^2 T\n$$\nWe now proceed to evaluate $\\mathrm{Var}(P_\\ell - P_{\\ell-1})$ for each coupling strategy.\n\n**1. Incorrect Coupling Strategy**\n\nUnder this strategy, the set of coarse increments $\\{\\Delta W^{(\\ell-1)}_m\\}_{m=1}^{N_{\\ell-1}}$ is generated independently from the set of fine increments $\\{\\Delta W^{(\\ell)}_n\\}_{n=1}^{N_\\ell}$. Since $P_\\ell$ is a function only of the fine increments and $P_{\\ell-1}$ is a function only of the coarse increments, the random variables $P_\\ell$ and $P_{\\ell-1}$ are independent. For independent random variables, the covariance is zero:\n$$\n\\mathrm{Cov}(P_\\ell, P_{\\ell-1}) = 0\n$$\nSubstituting this into the general variance formula gives:\n$$\n\\mathrm{Var}(P_\\ell - P_{\\ell-1}) = \\mathrm{Var}(P_\\ell) + \\mathrm{Var(P_{\\ell-1})}\n$$\nUsing the previously derived variances for $P_\\ell$ and $P_{\\ell-1}$:\n$$\n\\mathrm{Var}(P_\\ell - P_{\\ell-1}) = \\sigma^2 T + \\sigma^2 T = 2 \\sigma^2 T\n$$\nThis is the variance under the incorrect coupling.\n\n**2. Correct Coupling Strategy**\n\nUnder this strategy, the coarse increments are constructed from the fine increments: $\\Delta W^{(\\ell-1)}_m = \\Delta W^{(\\ell)}_{2m-1} + \\Delta W^{(\\ell)}_{2m}$. We compute the difference $P_\\ell - P_{\\ell-1}$ directly:\n$$\nP_\\ell - P_{\\ell-1} = \\sum_{n=1}^{N_\\ell} \\sigma\\, \\Delta W^{(\\ell)}_n - \\sum_{m=1}^{N_{\\ell-1}} \\sigma\\, \\Delta W^{(\\ell-1)}_m\n$$\nSubstituting the coupling definition into the second term:\n$$\n\\sum_{m=1}^{N_{\\ell-1}} \\sigma\\, \\Delta W^{(\\ell-1)}_m = \\sigma \\sum_{m=1}^{N_{\\ell-1}} \\left( \\Delta W^{(\\ell)}_{2m-1} + \\Delta W^{(\\ell)}_{2m} \\right)\n$$\nThis sum covers all the fine increments from $n=1$ to $n=2N_{\\ell-1}$. Since $N_\\ell = 2N_{\\ell-1}$, this sum is precisely the sum of all fine increments:\n$$\n\\sigma \\sum_{m=1}^{N_{\\ell-1}} \\left( \\Delta W^{(\\ell)}_{2m-1} + \\Delta W^{(\\ell)}_{2m} \\right) = \\sigma \\sum_{n=1}^{N_\\ell} \\Delta W^{(\\ell)}_n = P_\\ell\n$$\nTherefore, for this specific SDE, the coarse approximation $P_{\\ell-1}$ is identical to the fine approximation $P_\\ell$ when correct coupling is used. The difference is:\n$$\nP_\\ell - P_{\\ell-1} = P_\\ell - P_\\ell = 0\n$$\nThe variance of a constant is zero:\n$$\n\\mathrm{Var}(P_\\ell - P_{\\ell-1}) = \\mathrm{Var}(0) = 0\n$$\nThis result highlights the a priori variance reduction achieved by correct coupling, which is the foundational principle of the Multilevel Monte Carlo method. For this simple SDE, the reduction is maximal.\n\nThe problem asks for the simplified closed-form analytic expression for the incorrect-coupling variance in terms of $\\sigma$ and $T$. As derived above, this expression is $2 \\sigma^2 T$.",
            "answer": "$$\n\\boxed{2 \\sigma^{2} T}\n$$"
        },
        {
            "introduction": "Once we appreciate that coupling reduces variance, the key practical question becomes how to allocate computational effort across levels to maximize efficiency. This exercise moves from the \"why\" to the \"how\" by tasking you with solving the core optimization problem at the heart of MLMC . Using the method of Lagrange multipliers, you will derive the general closed-form expression for the optimal number of samples $N_{\\ell}$ on each level, which minimizes the total computational cost for a given statistical error tolerance.",
            "id": "3783568",
            "problem": "Consider a hierarchical sequence of discretizations indexed by levels $\\ell \\in \\{0,1,\\dots,L\\}$ for approximating a scalar quantity of interest $P$ arising in a multiscale model. On each level $\\ell$, define the level-difference random variable $\\Delta P_{\\ell} = P_{\\ell} - P_{\\ell-1}$ with $P_{-1} \\equiv 0$, and assume that, conditional on level, independent and identically distributed samples of $\\Delta P_{\\ell}$ can be generated. Let $Y$ denote the multilevel Monte Carlo (MLMC) estimator (Multilevel Monte Carlo (MLMC)) given by\n$$\nY \\;=\\; \\sum_{\\ell=0}^{L} \\frac{1}{N_{\\ell}} \\sum_{i=1}^{N_{\\ell}} \\Delta P_{\\ell}^{(i)},\n$$\nwhere $N_{\\ell}$ is the number of samples drawn at level $\\ell$ and $\\Delta P_{\\ell}^{(i)}$ are independent copies of $\\Delta P_{\\ell}$. Assume the following fundamental facts: for each level $\\ell$, the variance of the sample mean equals the level variance divided by the number of samples, that is,\n$$\n\\operatorname{Var}\\!\\left(\\frac{1}{N_{\\ell}} \\sum_{i=1}^{N_{\\ell}} \\Delta P_{\\ell}^{(i)}\\right) \\;=\\; \\frac{V_{\\ell}}{N_{\\ell}},\n$$\nwhere $V_{\\ell} = \\operatorname{Var}(\\Delta P_{\\ell})$, and that the total variance of $Y$ is the sum of the independent level variances. Further, suppose that the expected computational cost to generate a single sample of $\\Delta P_{\\ell}$ is $C_{\\ell}$, so the total expected cost is \n$$\n\\mathcal{C} \\;=\\; \\sum_{\\ell=0}^{L} N_{\\ell} C_{\\ell}.\n$$\nIn a pilot study, you have obtained empirical estimators $\\hat{V}_{\\ell}$ and $\\hat{C}_{\\ell}$ for $V_{\\ell}$ and $C_{\\ell}$, respectively. You wish to choose $\\{N_{\\ell}\\}_{\\ell=0}^{L}$ to minimize $\\mathcal{C}$ subject to the variance constraint \n$$\n\\operatorname{Var}(Y) \\;=\\; \\sum_{\\ell=0}^{L} \\frac{V_{\\ell}}{N_{\\ell}} \\;\\le\\; \\frac{1}{2}\\,\\varepsilon^{2},\n$$\nwhere $\\varepsilon>0$ is a prescribed accuracy tolerance for the mean-squared error and the remaining half of the error budget is reserved for the squared bias via an appropriate choice of $L$. Treat $\\{N_{\\ell}\\}_{\\ell=0}^{L}$ as continuous positive decision variables and use the pilot estimators in place of the unknown true $V_{\\ell}$ and $C_{\\ell}$. Derive a closed-form expression for the optimal allocation $N_{\\ell}$ in terms of $\\varepsilon$, $\\hat{V}_{\\ell}$, $\\hat{C}_{\\ell}$, and $L$ that minimizes the cost while meeting the variance constraint with equality. Provide your final result as a single analytical expression for $N_{\\ell}$ in terms of these symbols. No rounding is required and no units apply.",
            "solution": "The user has provided a valid problem statement. The task is to find the optimal allocation of samples, $\\{N_{\\ell}\\}_{\\ell=0}^{L}$, for a Multilevel Monte Carlo (MLMC) estimator. This is a classic constrained optimization problem where the goal is to minimize the total computational cost subject to a constraint on the total variance.\n\nThe problem can be formally stated as:\nMinimize the total expected cost,\n$$\n\\mathcal{C}(\\{N_{\\ell}\\}_{\\ell=0}^{L}) \\;=\\; \\sum_{\\ell=0}^{L} N_{\\ell} \\hat{C}_{\\ell}\n$$\nsubject to the variance constraint being met with equality,\n$$\n\\operatorname{Var}(Y) \\;=\\; \\sum_{\\ell=0}^{L} \\frac{\\hat{V}_{\\ell}}{N_{\\ell}} \\;=\\; \\frac{1}{2}\\,\\varepsilon^{2}.\n$$\nHere, $\\{\\hat{V}_{\\ell}\\}_{\\ell=0}^{L}$ and $\\{\\hat{C}_{\\ell}\\}_{\\ell=0}^{L}$ are the empirically estimated level variances and costs, respectively. The sample sizes $\\{N_{\\ell}\\}_{\\ell=0}^{L}$ are treated as continuous positive variables.\n\nThis constrained optimization problem is amenable to the method of Lagrange multipliers. We define the Lagrangian function $\\mathcal{L}$ as the objective function plus a Lagrange multiplier $\\lambda$ times the constraint function:\n$$\n\\mathcal{L}(\\{N_{\\ell}\\}, \\lambda) \\;=\\; \\sum_{\\ell=0}^{L} N_{\\ell} \\hat{C}_{\\ell} + \\lambda \\left( \\left(\\sum_{\\ell=0}^{L} \\frac{\\hat{V}_{\\ell}}{N_{\\ell}}\\right) - \\frac{1}{2}\\varepsilon^{2} \\right).\n$$\nTo find the minimum, we compute the partial derivatives of $\\mathcal{L}$ with respect to each $N_{k}$ for $k \\in \\{0, 1, \\dots, L\\}$ and set them to zero.\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial N_{k}} \\;=\\; \\hat{C}_{k} - \\lambda \\frac{\\hat{V}_{k}}{N_{k}^{2}} \\;=\\; 0.\n$$\nSince $\\hat{C}_{k} > 0$ and $\\hat{V}_{k} \\ge 0$, and we require $N_k > 0$, it follows that the Lagrange multiplier $\\lambda$ must be positive. We can rearrange the equation to solve for $N_{k}$:\n$$\n\\hat{C}_{k} N_{k}^{2} \\;=\\; \\lambda \\hat{V}_{k} \\quad \\implies \\quad N_{k}^{2} \\;=\\; \\lambda \\frac{\\hat{V}_{k}}{\\hat{C}_{k}}.\n$$\nTaking the positive square root, as $N_k$ must be a positive quantity, we get:\n$$\nN_{k} \\;=\\; \\sqrt{\\lambda} \\sqrt{\\frac{\\hat{V}_{k}}{\\hat{C}_{k}}}.\n$$\nThis expression gives the optimal number of samples for each level $k$ in terms of the unknown Lagrange multiplier $\\lambda$. To determine $\\lambda$, we substitute this expression for $N_{k}$ back into the variance constraint equation:\n$$\n\\sum_{k=0}^{L} \\frac{\\hat{V}_{k}}{N_{k}} \\;=\\; \\frac{1}{2}\\varepsilon^{2}.\n$$\n$$\n\\sum_{k=0}^{L} \\frac{\\hat{V}_{k}}{\\sqrt{\\lambda} \\sqrt{\\frac{\\hat{V}_{k}}{\\hat{C}_{k}}}} \\;=\\; \\frac{1}{2}\\varepsilon^{2}.\n$$\nSimplifying the term inside the summation:\n$$\n\\frac{\\hat{V}_{k}}{\\sqrt{\\frac{\\hat{V}_{k}}{\\hat{C}_{k}}}} \\;=\\; \\frac{(\\sqrt{\\hat{V}_{k}})^{2} \\sqrt{\\hat{C}_{k}}}{\\sqrt{\\hat{V}_{k}}} \\;=\\; \\sqrt{\\hat{V}_{k} \\hat{C}_{k}}.\n$$\nThe constraint equation becomes:\n$$\n\\sum_{k=0}^{L} \\frac{\\sqrt{\\hat{V}_{k} \\hat{C}_{k}}}{\\sqrt{\\lambda}} \\;=\\; \\frac{1}{2}\\varepsilon^{2}.\n$$\nWe can factor out the term $1/\\sqrt{\\lambda}$ from the summation:\n$$\n\\frac{1}{\\sqrt{\\lambda}} \\sum_{k=0}^{L} \\sqrt{\\hat{V}_{k} \\hat{C}_{k}} \\;=\\; \\frac{1}{2}\\varepsilon^{2}.\n$$\nNow, we solve for $\\sqrt{\\lambda}$:\n$$\n\\sqrt{\\lambda} \\;=\\; \\frac{2}{\\varepsilon^{2}} \\sum_{k=0}^{L} \\sqrt{\\hat{V}_{k} \\hat{C}_{k}}.\n$$\nFinally, we substitute this expression for $\\sqrt{\\lambda}$ back into our equation for the optimal $N_{\\ell}$ (using the index $\\ell$ as requested in the problem statement):\n$$\nN_{\\ell} \\;=\\; \\sqrt{\\lambda} \\sqrt{\\frac{\\hat{V}_{\\ell}}{\\hat{C}_{\\ell}}} \\;=\\; \\left( \\frac{2}{\\varepsilon^{2}} \\sum_{k=0}^{L} \\sqrt{\\hat{V}_{k} \\hat{C}_{k}} \\right) \\sqrt{\\frac{\\hat{V}_{\\ell}}{\\hat{C}_{\\ell}}}.\n$$\nThis equation provides the closed-form expression for the optimal number of samples $N_{\\ell}$ at each level $\\ell$, which minimizes the total computational cost while satisfying the specified variance constraint.",
            "answer": "$$\\boxed{ N_{\\ell} = \\frac{2}{\\varepsilon^{2}} \\sqrt{\\frac{\\hat{V}_{\\ell}}{\\hat{C}_{\\ell}}} \\sum_{k=0}^{L} \\sqrt{\\hat{V}_{k} \\hat{C}_{k}} }$$"
        },
        {
            "introduction": "Abstract formulas come to life when applied to concrete scenarios. This final practice grounds the theoretical sample allocation strategy in a tangible calculation . Given a set of hypothetical but representative level variances $V_\\ell$ and costs $C_\\ell$, you will apply the optimality formula to determine the specific integer sample counts $N_\\ell$ required to achieve a target accuracy $\\epsilon$, and then compute the total computational work, reinforcing your understanding of the practical mechanics and cost structure of an MLMC simulation.",
            "id": "3067966",
            "problem": "Consider the geometric Brownian motion stochastic differential equation (SDE) $\\,\\mathrm{d}X_t=\\mu X_t\\,\\mathrm{d}t+\\sigma X_t\\,\\mathrm{d}W_t\\,$ on $\\,t\\in[0,1]\\,$ with initial condition $\\,X_0=1\\,$ and parameters $\\,\\mu,\\sigma\\in\\mathbb{R}\\,$. Let the goal be to approximate $\\,\\mathbb{E}[P]\\,$ for a Lipschitz payoff $\\,P=g(X_1)\\,$ using Multilevel Monte Carlo (MLMC). A hierarchy of Euler–Maruyama time steps $\\,h_\\ell=2^{-\\ell}\\,$ for $\\,\\ell=0,1,2,3,4\\,$ has been fixed by an independent bias analysis ensuring that the squared bias contribution is at most $\\,\\epsilon^2/2\\,$ with target accuracy $\\,\\epsilon=10^{-2}\\,$. From pilot simulations, the level-difference variances and per-sample costs are estimated as $\\,V_\\ell=\\operatorname{Var}(Y_\\ell)=2^{-\\ell}\\,$ and $\\,C_\\ell=\\text{cost per sample on level }\\ell=2^{\\ell}\\,$ for $\\,\\ell=0,1,2,3,4\\,$, where $\\,Y_0=P_0\\,$ and $\\,Y_\\ell=P_\\ell-P_{\\ell-1}\\,$ for $\\,\\ell\\ge 1\\,$.\n\nDetermine integer sample counts $\\,N_\\ell\\in\\mathbb{N}\\,$, for $\\,\\ell=0,1,2,3,4\\,$, that minimize the total computational work subject to the variance constraint $\\,\\sum_{\\ell=0}^{4}\\frac{V_\\ell}{N_\\ell}\\le \\epsilon^2/2\\,$. Use only first principles of constrained optimization to derive the allocation. Compute the resulting total work $\\,W=\\sum_{\\ell=0}^{4}N_\\ell\\,C_\\ell\\,$ using your integer $\\,N_\\ell\\,$. Report only the total work as your final answer. No rounding instruction applies to the final number; provide the exact integer.",
            "solution": "The user has provided a scientifically grounded and well-posed problem statement. The task is to determine the integer sample counts $\\,N_\\ell\\,$ for a Multilevel Monte Carlo (MLMC) estimator that minimize the total computational work, subject to a constraint on the estimator's variance. The problem is a classic constrained optimization exercise.\n\nFirst, we formalize the optimization problem.\nLet $\\,L=4\\,$ be the maximum level.\nThe total computational work, which we aim to minimize, is the objective function:\n$$W = \\sum_{\\ell=0}^{L} N_\\ell C_\\ell$$\nHere, $\\,N_\\ell\\,$ are the number of samples on level $\\,\\ell\\,$ and $\\,C_\\ell\\,$ is the computational cost per sample on level $\\,\\ell\\,$.\n\nThe variance of the MLMC estimator is given by $\\,\\sum_{\\ell=0}^{L} \\frac{V_\\ell}{N_\\ell}\\,$, where $\\,V_\\ell\\,$ is the variance of the level difference estimator $\\,Y_\\ell\\,$. The problem specifies a constraint on this variance:\n$$\\sum_{\\ell=0}^{L} \\frac{V_\\ell}{N_\\ell} \\le \\frac{\\epsilon^2}{2}$$\nwhere $\\,\\epsilon\\,$ is the target accuracy.\n\nWe are given the following problem-specific data for levels $\\,\\ell = 0, 1, 2, 3, 4\\,$:\n- Target accuracy: $\\,\\epsilon = 10^{-2}\\,$, so the variance constraint is $\\,\\frac{\\epsilon^2}{2} = \\frac{(10^{-2})^2}{2} = \\frac{10^{-4}}{2} = 5 \\times 10^{-5}\\,$.\n- Level-difference variances: $\\,V_\\ell = 2^{-\\ell}\\,$.\n- Per-sample costs: $\\,C_\\ell = 2^{\\ell}\\,$.\n- The number of levels is $\\,L+1 = 5\\,$.\n\nTo find the minimum of $\\,W\\,$ subject to the constraint, we use the method of Lagrange multipliers. We first treat the $\\,N_\\ell\\,$ as continuous real variables. The minimum work will occur when the variance constraint is active, i.e., at equality:\n$$\\sum_{\\ell=0}^{L} \\frac{V_\\ell}{N_\\ell} = \\frac{\\epsilon^2}{2}$$\n\nThe Lagrangian function $\\,\\mathcal{L}\\,$ is:\n$$\\mathcal{L}(N_0, \\dots, N_L, \\lambda) = \\sum_{\\ell=0}^{L} N_\\ell C_\\ell + \\lambda \\left( \\sum_{\\ell=0}^{L} \\frac{V_\\ell}{N_\\ell} - \\frac{\\epsilon^2}{2} \\right)$$\nwhere $\\,\\lambda\\,$ is the Lagrange multiplier.\n\nTo find the minimum, we set the partial derivatives of $\\,\\mathcal{L}\\,$ with respect to each $\\,N_k\\,$ to zero:\n$$\\frac{\\partial \\mathcal{L}}{\\partial N_k} = C_k - \\lambda \\frac{V_k}{N_k^2} = 0$$\nSolving for $\\,N_k\\,$ gives:\n$$C_k N_k^2 = \\lambda V_k \\implies N_k^2 = \\lambda \\frac{V_k}{C_k} \\implies N_k = \\sqrt{\\lambda} \\sqrt{\\frac{V_k}{C_k}}$$\nThis shows that the optimal number of samples $\\,N_k\\,$ is proportional to $\\,\\sqrt{V_k/C_k}\\,$.\n\nNext, we determine the value of $\\,\\sqrt{\\lambda}\\,$ by substituting this expression for $\\,N_k\\,$ back into the active variance constraint:\n$$\\sum_{\\ell=0}^{L} \\frac{V_\\ell}{\\sqrt{\\lambda} \\sqrt{V_\\ell/C_\\ell}} = \\frac{\\epsilon^2}{2}$$\n$$\\frac{1}{\\sqrt{\\lambda}} \\sum_{\\ell=0}^{L} \\frac{V_\\ell \\sqrt{C_\\ell}}{\\sqrt{V_\\ell}} = \\frac{\\epsilon^2}{2}$$\n$$\\frac{1}{\\sqrt{\\lambda}} \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell} = \\frac{\\epsilon^2}{2}$$\nSolving for $\\,\\sqrt{\\lambda}\\,$:\n$$\\sqrt{\\lambda} = \\frac{2}{\\epsilon^2} \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell}$$\n\nNow we substitute this expression for $\\,\\sqrt{\\lambda}\\,$ back into the equation for $\\,N_k\\,$:\n$$N_k = \\left( \\frac{2}{\\epsilon^2} \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell} \\right) \\sqrt{\\frac{V_k}{C_k}}$$\n\nLet's compute the terms for this specific problem.\nThe product $\\,\\sqrt{V_\\ell C_\\ell}\\,$ is:\n$$\\sqrt{V_\\ell C_\\ell} = \\sqrt{2^{-\\ell} \\cdot 2^{\\ell}} = \\sqrt{1} = 1$$\nThe sum over all levels $\\,L=4\\,$ is:\n$$\\sum_{\\ell=0}^{4} \\sqrt{V_\\ell C_\\ell} = \\sum_{\\ell=0}^{4} 1 = 5$$\nThe term $\\,\\sqrt{V_k/C_k}\\,$ is:\n$$\\sqrt{\\frac{V_k}{C_k}} = \\sqrt{\\frac{2^{-k}}{2^k}} = \\sqrt{2^{-2k}} = 2^{-k}$$\n\nNow we can compute the optimal (real-valued) $\\,N_k\\,$:\n$$N_k = \\left( \\frac{2}{(10^{-2})^2} \\cdot 5 \\right) \\cdot 2^{-k} = \\left( \\frac{2}{10^{-4}} \\cdot 5 \\right) \\cdot 2^{-k} = (2 \\cdot 10^4 \\cdot 5) \\cdot 2^{-k} = 10^5 \\cdot 2^{-k}$$\n\nThe problem requires integer sample counts $\\,N_k \\in \\mathbb{N}\\,$. Let us compute the values:\n- For $\\,\\ell=0\\,$: $\\,N_0 = 10^5 \\cdot 2^{-0} = 100000\\,$\n- For $\\,\\ell=1\\,$: $\\,N_1 = 10^5 \\cdot 2^{-1} = 50000\\,$\n- For $\\,\\ell=2\\,$: $\\,N_2 = 10^5 \\cdot 2^{-2} = 25000\\,$\n- For $\\,\\ell=3\\,$: $\\,N_3 = 10^5 \\cdot 2^{-3} = 12500\\,$\n- For $\\,\\ell=4\\,$: $\\,N_4 = 10^5 \\cdot 2^{-4} = 6250\\,$\n\nSince all calculated optimal $\\,N_\\ell\\,$ values are integers, we do not need to perform any rounding. These are the integer sample counts that minimize the cost.\n\nFinally, we compute the total work $\\,W\\,$ using these optimal sample counts:\n$$W = \\sum_{\\ell=0}^{4} N_\\ell C_\\ell = \\sum_{\\ell=0}^{4} (10^5 \\cdot 2^{-\\ell}) \\cdot (2^{\\ell})$$\n$$W = \\sum_{\\ell=0}^{4} 10^5 = 10^5 \\cdot (4 - 0 + 1) = 5 \\cdot 10^5 = 500000$$\n\nAlternatively, one can derive the minimal work directly:\n$$W = \\sum_{\\ell=0}^{L} N_\\ell C_\\ell = \\sum_{\\ell=0}^{L} \\left( \\sqrt{\\lambda} \\sqrt{\\frac{V_\\ell}{C_\\ell}} \\right) C_\\ell = \\sqrt{\\lambda} \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell}$$\nSubstituting the expression for $\\,\\sqrt{\\lambda}\\,$:\n$$W = \\left( \\frac{2}{\\epsilon^2} \\sum_{j=0}^{L} \\sqrt{V_j C_j} \\right) \\left( \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell} \\right) = \\frac{2}{\\epsilon^2} \\left( \\sum_{\\ell=0}^{L} \\sqrt{V_\\ell C_\\ell} \\right)^2$$\nPlugging in the values for this problem:\n$$W = \\frac{2}{(10^{-2})^2} (5)^2 = \\frac{2}{10^{-4}} \\cdot 25 = 2 \\cdot 10^4 \\cdot 25 = 50 \\cdot 10^4 = 500000$$\nBoth methods yield the same result. The minimal total computational work is $\\,500000\\,$.",
            "answer": "$$\\boxed{500000}$$"
        }
    ]
}