{
    "hands_on_practices": [
        {
            "introduction": "The fundamental promise of Parallel Replica Dynamics is its ability to accelerate simulations of rare events. The key performance metric is the 'speedup', which quantifies how much faster the parallel algorithm is compared to a standard serial simulation. This first exercise  forms the theoretical bedrock of ParRep, guiding you to derive the expected speedup under both ideal and non-ideal conditions, revealing the origins of the algorithm's power and its limitations.",
            "id": "3791178",
            "problem": "Consider a continuous-time Markov process evolving in a metastable set $\\mathcal{S}$, and let the exit time from $\\mathcal{S}$ for a single trajectory be the nonnegative random variable $T$. In the Parallel Replica (ParRep) dynamics algorithm, after a decorrelation and dephasing stage designed to enforce the Quasi-Stationary Distribution (QSD), $N$ independent replicas are launched, each with exit time $T_{i}$, and the algorithm uses the minimum exit time $T_{\\min} = \\min\\{T_{1},\\dots,T_{N}\\}$ to accelerate sampling. Assume the replicas are independent and identically distributed (IID) and that $T$ has survival function $S(t) = \\mathbb{P}(T>t)$.\n\nStarting from foundational definitions appropriate to metastable exit problems and order statistics, derive an analytic expression for the expected speedup $\\mathbb{E}[T]/\\mathbb{E}[T_{\\min}]$ as a function of $N$ in the following two cases:\n\n1. Under the QSD assumption, the exit time is exponential with rate parameter $\\lambda>0$, i.e., $S(t) = \\exp(-\\lambda t)$.\n2. When the QSD assumption is not met and the exit time is non-exponential, model the exit time by a Weibull distribution with shape parameter $k>0$ and scale parameter $1/\\lambda>0$, i.e., $S(t) = \\exp\\!\\big(-(\\lambda t)^{k}\\big)$.\n\nExplain briefly, based on first principles, why deviations from the QSD assumption produce departures from the linear speedup law in ParRep. Your final answer must be the closed-form analytic expression(s) for $\\mathbb{E}[T]/\\mathbb{E}[T_{\\min}]$ in terms of $N$ (and $k$ when applicable). No numerical rounding is required, and no physical units are involved in this dimensionless ratio.",
            "solution": "The problem asks for the expected speedup of the Parallel Replica (ParRep) dynamics algorithm, defined as the ratio $\\mathbb{E}[T]/\\mathbb{E}[T_{\\min}]$, under two different assumptions for the distribution of the single-replica exit time $T$. Here, $T_1, \\dots, T_N$ are the exit times for $N$ independent and identically distributed (IID) replicas, and $T_{\\min} = \\min\\{T_1, \\dots, T_N\\}$ is the observed exit time in the algorithm.\n\nA fundamental result from probability theory states that for any non-negative random variable $X$ with survival function $S_X(x) = \\mathbb{P}(X > x)$, the expected value is given by the integral of the survival function:\n$$\n\\mathbb{E}[X] = \\int_{0}^{\\infty} S_X(x) \\, dx\n$$\nThe survival function for the single-replica exit time $T$ is given as $S(t) = \\mathbb{P}(T > t)$. The survival function for $T_{\\min}$, denoted $S_{\\min}(t)$, can be derived from the IID assumption. The event $T_{\\min} > t$ is equivalent to the event that all individual replica exit times are greater than $t$.\n$$\nS_{\\min}(t) = \\mathbb{P}(T_{\\min} > t) = \\mathbb{P}(T_1 > t, T_2 > t, \\dots, T_N > t)\n$$\nDue to the independence of the replicas, the joint probability is the product of the individual probabilities:\n$$\nS_{\\min}(t) = \\prod_{i=1}^{N} \\mathbb{P}(T_i > t)\n$$\nSince the replicas are identically distributed, $\\mathbb{P}(T_i > t) = S(t)$ for all $i$. Therefore,\n$$\nS_{\\min}(t) = [S(t)]^N\n$$\nThe expected speedup can thus be written as the ratio of two integrals:\n$$\n\\frac{\\mathbb{E}[T]}{\\mathbb{E}[T_{\\min}]} = \\frac{\\int_{0}^{\\infty} S(t) \\, dt}{\\int_{0}^{\\infty} S_{\\min}(t) \\, dt} = \\frac{\\int_{0}^{\\infty} S(t) \\, dt}{\\int_{0}^{\\infty} [S(t)]^N \\, dt}\n$$\nWe now apply this general formula to the two specified cases.\n\nCase 1: Exponential Distribution (QSD Assumption)\nUnder the Quasi-Stationary Distribution (QSD) assumption, the exit time $T$ is exponentially distributed with rate parameter $\\lambda > 0$. The survival function is:\n$$\nS(t) = \\exp(-\\lambda t)\n$$\nThe expected exit time for a single replica is:\n$$\n\\mathbb{E}[T] = \\int_{0}^{\\infty} \\exp(-\\lambda t) \\, dt = \\left[ -\\frac{1}{\\lambda} \\exp(-\\lambda t) \\right]_{0}^{\\infty} = 0 - \\left(-\\frac{1}{\\lambda}\\right) = \\frac{1}{\\lambda}\n$$\nThe survival function for the minimum of $N$ replicas is:\n$$\nS_{\\min}(t) = [S(t)]^N = [\\exp(-\\lambda t)]^N = \\exp(-N\\lambda t)\n$$\nThis shows that $T_{\\min}$ is also exponentially distributed, but with an effective rate parameter of $N\\lambda$. The expected minimum exit time is:\n$$\n\\mathbb{E}[T_{\\min}] = \\int_{0}^{\\infty} \\exp(-N\\lambda t) \\, dt = \\left[ -\\frac{1}{N\\lambda} \\exp(-N\\lambda t) \\right]_{0}^{\\infty} = \\frac{1}{N\\lambda}\n$$\nThe expected speedup is the ratio of these expectations:\n$$\n\\frac{\\mathbb{E}[T]}{\\mathbb{E}[T_{\\min}]} = \\frac{1/\\lambda}{1/(N\\lambda)} = N\n$$\nThis is the well-known linear speedup result for ParRep under the QSD assumption.\n\nCase 2: Weibull Distribution (Deviation from QSD)\nWhen the QSD assumption is not met, the exit time is modeled by a Weibull distribution with shape parameter $k>0$ and scale parameter $1/\\lambda > 0$. The survival function is:\n$$\nS(t) = \\exp(-(\\lambda t)^k)\n$$\nTo find the expected value $\\mathbb{E}[T]$, we integrate $S(t)$:\n$$\n\\mathbb{E}[T] = \\int_{0}^{\\infty} \\exp(-(\\lambda t)^k) \\, dt\n$$\nLet's perform a change of variables. Let $u = (\\lambda t)^k$. Then $t = \\frac{u^{1/k}}{\\lambda}$, and $dt = \\frac{1}{\\lambda k} u^{1/k - 1} \\, du$.\n$$\n\\mathbb{E}[T] = \\int_{0}^{\\infty} \\exp(-u) \\left( \\frac{1}{\\lambda k} u^{1/k - 1} \\right) \\, du = \\frac{1}{\\lambda k} \\int_{0}^{\\infty} u^{1/k - 1} \\exp(-u) \\, du\n$$\nThe integral is the definition of the Gamma function, $\\Gamma(z) = \\int_0^\\infty x^{z-1}\\exp(-x)dx$. Here, $z = 1/k$.\n$$\n\\mathbb{E}[T] = \\frac{1}{\\lambda k} \\Gamma(1/k)\n$$\nUsing the property $\\Gamma(z+1) = z\\Gamma(z)$, this can be written as:\n$$\n\\mathbb{E}[T] = \\frac{1}{\\lambda} \\Gamma\\left(1 + \\frac{1}{k}\\right)\n$$\nNow, we find the expectation for $T_{\\min}$. The survival function is:\n$$\nS_{\\min}(t) = [S(t)]^N = [\\exp(-(\\lambda t)^k)]^N = \\exp(-N(\\lambda t)^k) = \\exp(-(N^{1/k} \\lambda t)^k)\n$$\nThis shows that $T_{\\min}$ also follows a Weibull distribution with the same shape parameter $k$, but with a new effective rate parameter $\\lambda' = N^{1/k}\\lambda$. We can find its expectation by substituting $\\lambda$ with $\\lambda'$ in the expression for $\\mathbb{E}[T]$:\n$$\n\\mathbb{E}[T_{\\min}] = \\frac{1}{\\lambda'} \\Gamma\\left(1 + \\frac{1}{k}\\right) = \\frac{1}{N^{1/k}\\lambda} \\Gamma\\left(1 + \\frac{1}{k}\\right)\n$$\nThe expected speedup is the ratio:\n$$\n\\frac{\\mathbb{E}[T]}{\\mathbb{E}[T_{\\min}]} = \\frac{\\frac{1}{\\lambda} \\Gamma\\left(1 + \\frac{1}{k}\\right)}{\\frac{1}{N^{1/k}\\lambda} \\Gamma\\left(1 + \\frac{1}{k}\\right)} = N^{1/k}\n$$\n\nExplanation of Deviations from Linear Speedup:\nThe QSD assumption implies that the exit process is memoryless. This is characteristic of the exponential distribution, for which the hazard rate, $\\lambda(t) = f(t)/S(t)$, is constant ($\\lambda(t) = \\lambda$). For a memoryless process, the probability of an event occurring in a small time interval is independent of how long the system has already waited. Parallelizing $N$ such processes results in an overall constant hazard rate of $N\\lambda$, which directly leads to a reduction in the mean exit time by a factor of $N$, yielding a linear speedup of $N$.\n\nWhen the QSD is not met, as modeled by the Weibull distribution with $k \\ne 1$, the process has memory. The hazard rate for the Weibull distribution is time-dependent: $\\lambda(t) = k\\lambda^k t^{k-1}$.\n- For $k > 1$, the hazard rate increases with time. This describes a system where an exit becomes more likely the longer it persists (aging). The parallel speedup is $N^{1/k}$, which is sub-linear since $1/k < 1$. The benefit of parallelization is diminished because all replicas spend time in an initial, low-probability exit phase before any one of them reaches a state with a higher exit rate.\n- For $0 < k < 1$, the hazard rate decreases with time. This describes a system with a very high probability of escaping quickly from initial transient states, which becomes more stable if it survives this initial phase. The speedup is $N^{1/k}$, which is super-linear since $1/k > 1$. ParRep is exceptionally effective here because with $N$ replicas, it is highly probable that at least one will find a fast exit pathway during the initial high-hazard phase, dramatically shortening the observed time.\n\nIn summary, the deviation from the constant hazard rate of a memoryless process breaks the simple scaling of the mean exit time, causing the speedup to deviate from the linear law and depend on the nature of the system's \"memory\", as captured by the shape parameter $k$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} N & N^{1/k} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The efficiency of ParRep relies on a clear separation of time scales: the system must relax quickly within a metastable state compared to the very long time it takes to exit that state. This practice  grounds this abstract assumption in a concrete physical system. By analyzing the dynamics of a particle in a classic double-well potential, you will use tools from statistical mechanics to explicitly calculate and compare these two characteristic times, justifying the core principle of metastability that makes ParRep a viable method.",
            "id": "3791213",
            "problem": "Consider the overdamped Langevin dynamics in one spatial dimension at inverse temperature $\\beta$ given by the stochastic differential equation $dX_{t}=-V'(X_{t})\\,dt+\\sqrt{2\\beta^{-1}}\\,dW_{t}$, where $W_{t}$ is a standard Wiener process and $V(x)=\\tfrac{1}{4}x^{4}-\\tfrac{1}{2}x^{2}$ is a double-well potential. In Parallel Replica Dynamics (ParRep), the algorithm relies on a clear separation of time scales between fast intra-well relaxation to a quasi-stationary distribution and rare inter-well exits driven by thermal activation. Starting from the fundamental definitions of the overdamped Langevin dynamics and the Gibbs measure, and using physically justified arguments for barrier crossing and local relaxation, estimate the ratio of the mean exit time from the right-hand well (near $x=1$) to the mean intra-well relaxation time in the small-noise regime (large $\\beta$). Your derivation should:\n- Use the leading Arrhenius barrier-crossing exponent associated with the potential barrier between the minimum and the saddle, and the corresponding harmonic (quadratic) approximations near the minimum and the saddle to obtain the dominant prefactor.\n- Use the spectral gap heuristic for the Fokkerâ€“Planck generator linearized near the minimum to estimate the intra-well relaxation rate.\nAssume the dynamics is confined initially near the minimum at $x=1$ and the relevant saddle is at $x=0$. Provide the ratio as a single closed-form analytical expression in terms of $\\beta$. Express your final result as a dimensionless quantity. Do not perform any numerical rounding.",
            "solution": "The objective is to determine the ratio of the mean exit time from a potential well, $\\tau_{\\text{exit}}$, to the intra-well relaxation time, $\\tau_{\\text{relax}}$, for a particle governed by the overdamped Langevin equation in a double-well potential. This ratio is a key quantity in the context of Parallel Replica (ParRep) dynamics, as its magnitude justifies the time-scale separation assumption upon which the algorithm is built. The analysis will be performed in the small-noise limit, corresponding to a large inverse temperature $\\beta$.\n\nThe stochastic differential equation (SDE) is given by:\n$$\ndX_{t}=-V'(X_{t})\\,dt+\\sqrt{2\\beta^{-1}}\\,dW_{t}\n$$\nwhere the potential is $V(x)=\\frac{1}{4}x^{4}-\\frac{1}{2}x^{2}$.\n\nFirst, we characterize the potential $V(x)$. The force is $-V'(x) = -(x^3 - x)$. The critical points are found by setting $V'(x)=0$:\n$$\nV'(x) = x^{3} - x = x(x-1)(x+1) = 0\n$$\nThe critical points are $x=0$, $x=1$, and $x=-1$. To classify them, we compute the second derivative:\n$$\nV''(x) = 3x^{2} - 1\n$$\n- At $x = \\pm 1$, $V''(\\pm 1) = 3(1)^{2} - 1 = 2 > 0$. These are stable minima. The potential value at the minima is $V(\\pm 1) = \\frac{1}{4}(\\pm 1)^{4} - \\frac{1}{2}(\\pm 1)^{2} = \\frac{1}{4} - \\frac{1}{2} = -\\frac{1}{4}$.\n- At $x=0$, $V''(0) = 3(0)^{2} - 1 = -1 < 0$. This is a local maximum, representing a saddle point between the two wells. The potential value at the saddle is $V(0) = 0$.\n\nThe problem specifies that the particle starts in the right-hand well, near the minimum at $x_{\\text{min}}=1$, and the relevant saddle for escape is at $x_{\\text{sad}}=0$. The potential energy barrier for this transition is:\n$$\n\\Delta V = V(x_{\\text{sad}}) - V(x_{\\text{min}}) = V(0) - V(1) = 0 - \\left(-\\frac{1}{4}\\right) = \\frac{1}{4}\n$$\n\nNext, we calculate the mean exit time, $\\tau_{\\text{exit}}$. In the large $\\beta$ regime, the mean exit time is governed by Kramers' rate theory. For one-dimensional overdamped dynamics with unit friction (as implied by the SDE), the mean exit time from a well minimum $x_{\\text{min}}$ over a saddle $x_{\\text{sad}}$ is given by the Arrhenius formula with the harmonic prefactor:\n$$\n\\tau_{\\text{exit}} = \\frac{2\\pi}{\\sqrt{V''(x_{\\text{min}})|V''(x_{\\text{sad}})|}} \\exp(\\beta \\Delta V)\n$$\nWe have the necessary components:\n- $V''(x_{\\text{min}}) = V''(1) = 2$.\n- $|V''(x_{\\text{sad}})| = |V''(0)| = |-1| = 1$.\n- $\\Delta V = \\frac{1}{4}$.\n\nSubstituting these values into the formula for $\\tau_{\\text{exit}}$:\n$$\n\\tau_{\\text{exit}} = \\frac{2\\pi}{\\sqrt{2 \\cdot 1}} \\exp\\left(\\beta \\cdot \\frac{1}{4}\\right) = \\frac{2\\pi}{\\sqrt{2}} \\exp\\left(\\frac{\\beta}{4}\\right) = \\sqrt{2}\\pi \\exp\\left(\\frac{\\beta}{4}\\right)\n$$\n\nNow, we estimate the intra-well relaxation time, $\\tau_{\\text{relax}}$. The problem instructs us to use the spectral gap heuristic for the Fokker-Planck generator linearized near the minimum. Near the minimum $x_{\\text{min}}=1$, the potential can be approximated by a harmonic potential:\n$$\nV(x) \\approx V(x_{\\text{min}}) + \\frac{1}{2}V''(x_{\\text{min}})(x-x_{\\text{min}})^{2}\n$$\nThe corresponding linearized SDE describes an Ornstein-Uhlenbeck (OU) process for the deviation $y(t) = X(t) - x_{\\text{min}}$:\n$$\ndY_{t} = -V''(x_{\\text{min}}) Y_{t}\\,dt + \\sqrt{2\\beta^{-1}}\\,dW_{t}\n$$\nThe dynamics within the well relaxes toward a quasi-stationary distribution (a local equilibrium) on a time scale determined by the rate of this OU process. The relaxation time is the inverse of the spectral gap of the associated Fokker-Planck operator. For an OU process with drift coefficient $-\\kappa y$, where $\\kappa = V''(x_{\\text{min}})$, the eigenvalues of the negative generator are given by $\\{n\\kappa\\}_{n=0}^{\\infty}$. The spectral gap is the first non-zero eigenvalue, $\\lambda_{1} = \\kappa$.\n\nThe relaxation rate is thus equal to the curvature of the potential at the minimum:\n$$\n\\lambda_{\\text{relax}} = V''(x_{\\text{min}})\n$$\nThe relaxation time is the inverse of this rate:\n$$\n\\tau_{\\text{relax}} = \\frac{1}{\\lambda_{\\text{relax}}} = \\frac{1}{V''(x_{\\text{min}})}\n$$\nUsing our value $V''(1)=2$:\n$$\n\\tau_{\\text{relax}} = \\frac{1}{2}\n$$\n\nFinally, we compute the ratio of the mean exit time to the intra-well relaxation time:\n$$\n\\frac{\\tau_{\\text{exit}}}{\\tau_{\\text{relax}}} = \\frac{\\sqrt{2}\\pi \\exp\\left(\\frac{\\beta}{4}\\right)}{\\frac{1}{2}} = 2\\sqrt{2}\\pi \\exp\\left(\\frac{\\beta}{4}\\right)\n$$\nThis dimensionless quantity shows that the ratio of time scales grows exponentially with $\\beta$, which confirms the time-scale separation required for the validity and efficiency of the ParRep algorithm in the low-temperature regime.",
            "answer": "$$\\boxed{2\\sqrt{2}\\pi\\exp\\left(\\frac{\\beta}{4}\\right)}$$"
        },
        {
            "introduction": "In any real-world application, theoretical speedup must be balanced against practical costs, including computational overhead and numerical accuracy. This final exercise  addresses the practitioner's dilemma: how many replicas should one use? You will construct a realistic performance model that accounts for initialization errors and overheads, and then design a computational experiment to find the optimal number of replicas, $N$, that maximizes performance without sacrificing accuracy beyond a set tolerance.",
            "id": "3791212",
            "problem": "Consider a continuous-time Markov process $X_t$ evolving in a metastable well, with an exit time $\\tau$ from the well. When initialized from the quasi-stationary distribution (QSD), it is a well-tested fact that $\\tau$ is exponentially distributed with rate $\\lambda$ (in $\\mathrm{s}^{-1}$), so the serial expected exit time is $\\mathbb{E}[\\tau]=1/\\lambda$ (in $\\mathrm{s}$). The Parallel Replica (ParRep) algorithm uses $N$ independent replicas to accelerate exits: under perfect dephasing (exact QSD sampling), the minimum of $N$ exponential exit times with rate $\\lambda$ is exponential with rate $N\\lambda$, a standard result for exponential random variables. In practice, dephasing is imperfect. Suppose that after the decorrelation and dephasing stages, the initialization error relative to QSD is bounded by a total variation error $\\varepsilon(N)$, and that the resulting relative bias in the mean exit time is proportional to this error: there exists a proportionality factor $\\kappa>0$ such that the relative bias magnitude satisfies $|\\delta(N)| \\le \\kappa\\,\\varepsilon(N)$. Assume a conservative model that uses the upper bound $\\delta(N)=\\kappa\\,\\varepsilon(N)$ in calculations. Let the decorrelation duration be $t_{\\mathrm{corr}}$ (in $\\mathrm{s}$) and the dephasing duration be $t_{\\mathrm{deph}}$ (in $\\mathrm{s}$). Assume ideal parallel hardware so that the decorrelation and dephasing stages contribute additively in wall-clock time, and the parallel escape stage proceeds with $N$ replicas in parallel.\n\nYou will design a computational experiment that, for each given parameter set, varies $N\\in\\{1,2,\\dots,N_{\\max}\\}$ and measures the effective speedup versus error trade-off to determine an optimal $N$ under a fixed error tolerance. Use the following modeling choices, which are widely used and scientifically sound as first-order approximations in analyses of Parallel Replica dynamics:\n- The serial expected exit time is $\\mathbb{E}[\\tau]=1/\\lambda$ (in $\\mathrm{s}$).\n- Under perfect dephasing, the exit time in the parallel stage with $N$ replicas is exponential with rate $N\\lambda$; thus, its mean is $1/(N\\lambda)$ (in $\\mathrm{s}$).\n- Under imperfect dephasing with relative bias $\\delta(N)$ (nonnegative by the conservative bound), the mean exit time in the parallel stage is scaled by a factor $1-\\delta(N)$ relative to the perfect case.\n- The dephasing error decays as a combination of particle-number and time effects:\n$$\n\\varepsilon(N) \\;=\\; \\frac{\\alpha}{N} \\;+\\; \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}},\n$$\nwhere $\\alpha>0$ is a particle-number constant, $\\beta\\ge 0$ and $\\gamma>0$ control temporal relaxation of dephasing, and $t_{\\mathrm{deph}}>0$ is fixed per case. The overall relative bias bound is $\\delta(N)=\\kappa\\,\\varepsilon(N)$ with $\\kappa>0$.\n- The expected wall-clock time (in $\\mathrm{s}$) for one ParRep cycle consists of the decorrelation time, the dephasing time, and the expected time of the parallel escape stage executed on $N$ cores in parallel.\n- The effective speedup is defined as the ratio of the serial expected time to the ParRep expected wall-clock time.\n\nYour tasks:\n- Starting from the standard exponential exit-time property for QSD, the minimum-of-exponentials fact for independent replicas, and the above error model, derive an explicit formula for the expected ParRep wall-clock time as a function of $N$ and for the corresponding speedup. Express all times in $\\mathrm{s}$ and rates in $\\mathrm{s}^{-1}$. Your derivation must rely only on the provided base facts and definitions.\n- Under a fixed relative error tolerance $\\epsilon_{\\mathrm{tol}}>0$, enforce $\\delta(N)\\le \\epsilon_{\\mathrm{tol}}$. Among all integers $N\\in\\{1,2,\\dots,N_{\\max}\\}$ that satisfy this constraint, select the $N$ that maximizes the speedup. In case of ties in speedup within numerical precision, choose the smallest such $N$.\n- If no $N\\in\\{1,2,\\dots,N_{\\max}\\}$ satisfies $\\delta(N)\\le \\epsilon_{\\mathrm{tol}}$, declare the problem infeasible for that case and return a sentinel choice $N_{\\mathrm{opt}}=-1$, a speedup of $0.0$, and also report the smallest achievable bias value $\\min_{1\\le N\\le N_{\\max}}\\delta(N)$ (dimensionless) to quantify how close the best $N$ comes to the tolerance.\n\nRequired outputs for each test case:\n- $N_{\\mathrm{opt}}$ (an integer).\n- $S_{\\mathrm{opt}}$ (a float), the maximal speedup achieved at $N_{\\mathrm{opt}}$.\n- $\\delta_{\\mathrm{opt}}$ (a float), the bias bound at $N_{\\mathrm{opt}}$; if infeasible, report $\\min_{1\\le N\\le N_{\\max}}\\delta(N)$ instead.\n\nNumerical and formatting requirements:\n- Report $S_{\\mathrm{opt}}$ and $\\delta_{\\mathrm{opt}}$ as decimals (not percentages), each rounded to $6$ decimal places.\n- The program should produce a single line of output containing the results for all test cases as a comma-separated list of lists, e.g., $[\\,[N_1,S_1,\\delta_1],\\,[N_2,S_2,\\delta_2]\\,]$.\n- All physical times must be in $\\mathrm{s}$, and all rates in $\\mathrm{s}^{-1}$.\n\nTest suite (each tuple lists $(\\lambda, t_{\\mathrm{corr}}, t_{\\mathrm{deph}}, \\alpha, \\beta, \\gamma, \\kappa, \\epsilon_{\\mathrm{tol}}, N_{\\max})$):\n- Case A: $(0.05, 1.0, 2.0, 0.5, 0.01, 1.0, 1.0, 0.05, 128)$.\n- Case B: $(0.05, 1.0, 2.0, 0.5, 0.01, 1.0, 1.0, 0.01, 128)$.\n- Case C: $(0.2, 5.0, 10.0, 0.2, 0.02, 0.5, 1.5, 0.02, 64)$.\n- Case D: $(1.0, 0.1, 0.2, 0.05, 0.0, 1.0, 0.5, 0.001, 8)$.\n- Case E: $(0.01, 0.5, 0.5, 0.5, 0.005, 2.0, 1.0, 0.02, 256)$.\n\nYour program should implement the derivation, evaluate all $N\\in\\{1,\\dots,N_{\\max}\\}$ per test case, and output a single line containing a list of $5$ results $[\\,[N_{\\mathrm{opt}},S_{\\mathrm{opt}},\\delta_{\\mathrm{opt}}],\\dots]$, with floats rounded to $6$ decimal places as specified.",
            "solution": "### Derivation of ParRep Wall-Clock Time and Speedup\n\nThe objective is to derive an explicit formula for the expected ParRep wall-clock time, $T_{\\mathrm{ParRep}}(N)$, and the corresponding effective speedup, $S(N)$, as a function of the number of replicas, $N$.\n\n**1. Serial Expected Time**\n\nThe serial process corresponds to a single simulation of the system waiting for an exit event. As given, the exit time $\\tau$ from the quasi-stationary distribution (QSD) is exponentially distributed with rate $\\lambda$. The serial expected exit time, $T_{\\mathrm{serial}}$, is the mean of this distribution:\n$$\nT_{\\mathrm{serial}} = \\mathbb{E}[\\tau] = \\frac{1}{\\lambda}\n$$\n\n**2. ParRep Expected Wall-Clock Time**\n\nThe ParRep algorithm cycle consists of three additive stages in terms of wall-clock time: decorrelation, dephasing, and parallel escape.\n\nThe expected wall-clock time for one cycle, $T_{\\mathrm{ParRep}}(N)$, is the sum of the durations of these stages:\n$$\nT_{\\mathrm{ParRep}}(N) = t_{\\mathrm{corr}} + t_{\\mathrm{deph}} + T_{\\mathrm{escape}}(N)\n$$\nwhere $t_{\\mathrm{corr}}$ is the decorrelation time, $t_{\\mathrm{deph}}$ is the dephasing time, and $T_{\\mathrm{escape}}(N)$ is the expected wall-clock time for the parallel escape stage.\n\nThe parallel escape stage runs $N$ independent replicas simultaneously.\n-   Under perfect dephasing, each replica is initialized from the exact QSD. The time to the first exit among the $N$ replicas is the minimum of $N$ independent and identically distributed exponential random variables, each with rate $\\lambda$. This minimum is itself an exponential random variable with rate $N\\lambda$. Its expected value is therefore $1/(N\\lambda)$.\n-   The problem states that under imperfect dephasing, the mean exit time is scaled by a factor of $1 - \\delta(N)$, where $\\delta(N)$ is the relative bias. The conservative model assumes $\\delta(N) \\ge 0$. Thus, the expected escape time is:\n    $$\n    T_{\\mathrm{escape}}(N) = \\frac{1}{N\\lambda} \\left( 1 - \\delta(N) \\right)\n    $$\n\nThe relative bias $\\delta(N)$ is modeled as being proportional to the total variation error $\\varepsilon(N)$, with proportionality constant $\\kappa$:\n$$\n\\delta(N) = \\kappa\\,\\varepsilon(N)\n$$\nThe dephasing error $\\varepsilon(N)$ is given by the model:\n$$\n\\varepsilon(N) = \\frac{\\alpha}{N} + \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}}\n$$\nSubstituting these expressions, we obtain the full formula for $\\delta(N)$:\n$$\n\\delta(N) = \\kappa \\left( \\frac{\\alpha}{N} + \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}} \\right)\n$$\nNow, substituting the expressions for $T_{\\mathrm{escape}}(N)$ and $\\delta(N)$ back into the equation for $T_{\\mathrm{ParRep}}(N)$:\n$$\nT_{\\mathrm{ParRep}}(N) = t_{\\mathrm{corr}} + t_{\\mathrm{deph}} + \\frac{1}{N\\lambda} \\left[ 1 - \\kappa \\left( \\frac{\\alpha}{N} + \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}} \\right) \\right]\n$$\nThis is the explicit formula for the expected ParRep wall-clock time.\n\n**3. Effective Speedup**\n\nThe effective speedup, $S(N)$, is defined as the ratio of the serial expected time to the ParRep expected wall-clock time:\n$$\nS(N) = \\frac{T_{\\mathrm{serial}}}{T_{\\mathrm{ParRep}}(N)}\n$$\nSubstituting the derived expressions for $T_{\\mathrm{serial}}$ and $T_{\\mathrm{ParRep}}(N)$:\n$$\nS(N) = \\frac{1/\\lambda}{t_{\\mathrm{corr}} + t_{\\mathrm{deph}} + \\frac{1}{N\\lambda} \\left[ 1 - \\kappa \\left( \\frac{\\alpha}{N} + \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}} \\right) \\right]}\n$$\nThis can be rewritten as:\n$$\nS(N) = \\frac{1}{\\lambda(t_{\\mathrm{corr}} + t_{\\mathrm{deph}}) + \\frac{1}{N}\\left[ 1 - \\kappa \\left( \\frac{\\alpha}{N} + \\beta\\,e^{-\\gamma\\,t_{\\mathrm{deph}}} \\right) \\right]}\n$$\nThis is the explicit formula for the effective speedup as a function of $N$.\n\n### Optimization Procedure\n\nThe task is to find the optimal number of replicas, $N_{\\mathrm{opt}}$, that maximizes the speedup $S(N)$ subject to a constraint on the bias $\\delta(N)$.\n\n**1. Constrained Optimization Problem**\nWe must find $N_{\\mathrm{opt}}$ that solves:\n$$\n\\begin{aligned}\n& \\underset{N}{\\text{maximize}}\n& & S(N) \\\\\n& \\text{subject to}\n& & \\delta(N) \\le \\epsilon_{\\mathrm{tol}} \\\\\n& & & N \\in \\{1, 2, \\dots, N_{\\max}\\}\n\\end{aligned}\n$$\nIn case of a tie in the maximum speedup value, the smallest $N$ is to be chosen.\n\n**2. Algorithm**\n\nFor each given parameter set, the following algorithm is executed:\n\n1.  **Identify Feasible Replicas**: Iterate through each integer $N$ from $1$ to $N_{\\max}$. For each $N$, calculate the bias $\\delta(N) = \\kappa (\\alpha/N + \\beta e^{-\\gamma t_{\\mathrm{deph}}})$. If $\\delta(N) \\le \\epsilon_{\\mathrm{tol}}$, then $N$ is a feasible candidate. Collect all such feasible $N$ into a set $\\mathcal{N}_{\\mathrm{feasible}}$.\n\n2.  **Handle Infeasible Case**: If the set $\\mathcal{N}_{\\mathrm{feasible}}$ is empty, it means no number of replicas up to $N_{\\max}$ can satisfy the error tolerance. In this scenario:\n    -   $N_{\\mathrm{opt}}$ is set to $-1$.\n    -   The corresponding speedup $S_{\\mathrm{opt}}$ is set to $0.0$.\n    -   The reported bias, $\\delta_{\\mathrm{opt}}$, is the minimum achievable bias within the search range, which occurs at $N = N_{\\max}$ since $\\delta(N)$ is a monotonically decreasing function of $N$. Thus, $\\delta_{\\mathrm{opt}} = \\delta(N_{\\max})$.\n\n3.  **Handle Feasible Case**: If $\\mathcal{N}_{\\mathrm{feasible}}$ is not empty, iterate through each $N \\in \\mathcal{N}_{\\mathrm{feasible}}$ in increasing order.\n    -   For each feasible $N$, calculate the speedup $S(N)$ using the formula derived above.\n    -   Keep track of the maximum speedup found so far, $S_{\\max}$, and the corresponding number of replicas, $N_{\\mathrm{best}}$. The first feasible $N$ provides the initial values for $S_{\\max}$ and $N_{\\mathrm{best}}$. For subsequent feasible $N$, if its speedup $S(N)$ is strictly greater than $S_{\\max}$, update $S_{\\max} = S(N)$ and $N_{\\mathrm{best}} = N$. The strict inequality and the ascending order of iteration ensure that the smallest $N$ is chosen in case of a tie.\n    -   After checking all feasible $N$, the optimal values are $N_{\\mathrm{opt}} = N_{\\mathrm{best}}$, $S_{\\mathrm{opt}} = S(N_{\\mathrm{best}})$, and $\\delta_{\\mathrm{opt}} = \\delta(N_{\\mathrm{best}})$.\n\nThis procedure guarantees finding the optimal $N$ according to the problem's criteria. The results are then formatted as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ParRep optimization problem for a suite of test cases.\n    \"\"\"\n    # Test suite: (lambda, t_corr, t_deph, alpha, beta, gamma, kappa, eps_tol, N_max)\n    test_cases = [\n        (0.05, 1.0, 2.0, 0.5, 0.01, 1.0, 1.0, 0.05, 128),  # Case A\n        (0.05, 1.0, 2.0, 0.5, 0.01, 1.0, 1.0, 0.01, 128),  # Case B\n        (0.2, 5.0, 10.0, 0.2, 0.02, 0.5, 1.5, 0.02, 64),   # Case C\n        (1.0, 0.1, 0.2, 0.05, 0.0, 1.0, 0.5, 0.001, 8),    # Case D\n        (0.01, 0.5, 0.5, 0.5, 0.005, 2.0, 1.0, 0.02, 256),  # Case E\n    ]\n\n    results = []\n    for params in test_cases:\n        result = find_optimal_n(params)\n        results.append(result)\n\n    # Format the final output string as specified\n    output_strings = []\n    for res_tuple in results:\n        N_opt, S_opt, D_opt = res_tuple\n        S_opt_str = f\"{S_opt:.6f}\"\n        D_opt_str = f\"{D_opt:.6f}\"\n        output_strings.append(f\"[{N_opt},{S_opt_str},{D_opt_str}]\")\n\n    # The final print statement must produce only the specified single-line format.\n    print(f\"[{','.join(output_strings)}]\")\n\ndef find_optimal_n(params):\n    \"\"\"\n    For a single set of parameters, finds the optimal N that maximizes speedup\n    under the given error tolerance.\n    \"\"\"\n    lambda_, t_corr, t_deph, alpha, beta, gamma, kappa, eps_tol, N_max = params\n\n    # Pre-calculate the constant part of the error term\n    temporal_error_term = beta * np.exp(-gamma * t_deph)\n\n    def get_delta(N):\n        \"\"\"Calculates the relative bias delta for a given N.\"\"\"\n        return kappa * (alpha / N + temporal_error_term)\n\n    # 1. Identify all feasible N values\n    feasible_N_list = []\n    for N_val in range(1, N_max + 1):\n        if get_delta(N_val) = eps_tol:\n            feasible_N_list.append(N_val)\n\n    # 2. Handle the infeasible case\n    if not feasible_N_list:\n        N_opt = -1\n        S_opt = 0.0\n        # Per problem spec, report minimum achievable bias if infeasible\n        # delta(N) is monotonically decreasing, so min is at N_max\n        min_delta = get_delta(N_max)\n        delta_opt = min_delta\n        return N_opt, S_opt, delta_opt\n\n    # 3. Handle the feasible case: find N that maximizes speedup\n    max_S = -1.0\n    opt_N = -1\n\n    T_serial = 1.0 / lambda_\n\n    for N in feasible_N_list:\n        delta_N = get_delta(N)\n        \n        # Calculate ParRep wall-clock time\n        # The problem constraints on eps_tol ensure 1 - delta_N > 0\n        T_parrep = t_corr + t_deph + (1.0 / (N * lambda_)) * (1.0 - delta_N)\n        \n        # Calculate speedup\n        current_S = T_serial / T_parrep\n        \n        # Update if a better speedup is found.\n        # Strict inequality ensures the smallest N is chosen in case of a tie,\n        # as we are iterating N in increasing order.\n        if current_S > max_S:\n            max_S = current_S\n            opt_N = N\n    \n    # Final optimal values\n    N_opt = opt_N\n    S_opt = max_S\n    delta_opt = get_delta(opt_N)\n\n    return N_opt, S_opt, delta_opt\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}