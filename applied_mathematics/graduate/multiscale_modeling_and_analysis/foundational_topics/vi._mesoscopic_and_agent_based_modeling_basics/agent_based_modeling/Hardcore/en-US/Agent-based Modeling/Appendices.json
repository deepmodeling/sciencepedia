{
    "hands_on_practices": [
        {
            "introduction": "Understanding Agent-Based Modeling begins with mastering its fundamental mechanics. This first exercise provides a concrete, hands-on calculation to solidify the core concepts of agent state, local neighborhood interaction, and rule-based decision making. By manually calculating the next state of a system of agents on a ring network, you will gain a practical understanding of how local rules, when applied synchronously across the system, give rise to global dynamics. ",
            "id": "4113515",
            "problem": "Consider an Agent-Based Modeling (ABM) system on a ring network with $n$ agents, where $n$ is fixed at $n=10$. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{N}$. The network is a one-dimensional ring: indices are taken modulo $n$, so that for any index $i \\in \\{1,\\dots,n\\}$, the predecessor of $1$ is $n$ and the successor of $n$ is $1$. For each agent $i$, the neighborhood $N(i)$ consists of the two nearest neighbors on each side, specifically $N(i)=\\{i-2,i-1,i+1,i+2\\}$ with indices interpreted modulo $n$. The synchronous update rule is defined by the indicator function\n$$\nx_i(t+1) \\;=\\; \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\;\\geq\\; \\theta \\right\\},\n$$\nwhere $\\theta$ is a fixed threshold applied uniformly to all agents.\n\nYou are given the initial configuration at time $t=0$ as\n$$\nx(0) \\;=\\; \\bigl(x_1(0),x_2(0),x_3(0),x_4(0),x_5(0),x_6(0),x_7(0),x_8(0),x_9(0),x_{10}(0)\\bigr)\n\\;=\\; (1,0,1,1,0,0,1,0,1,0),\n$$\nand the threshold $\\theta=3$.\n\nUsing only the definitions above and the stated synchronous update rule, compute the next state vector $x(1)$. Express your final answer as a single row matrix containing the components in order $\\bigl(x_1(1),x_2(1),\\dots,x_{10}(1)\\bigr)$. No rounding is required, and no units apply.",
            "solution": "The problem statement is validated as being scientifically grounded, well-posed, objective, complete, and consistent. It describes a standard discrete-time dynamical system, specifically a type of one-dimensional cellular automaton on a ring, for which all necessary parameters and initial conditions are provided to compute the subsequent state. The problem is a formalizable exercise in applying a defined rule set and is directly pertinent to the field of agent-based modeling. Therefore, a solution can be derived.\n\nThe problem asks for the state vector $x(1)$ at time $t=1$, given the initial state vector $x(0)$ at time $t=0$. The system consists of $n=10$ agents on a ring. The state of each agent $i$ is binary, $x_i(t) \\in \\{0,1\\}$. The update rule for each agent $i$ is synchronous and determined by its neighbors' states at the previous time step. The neighborhood of agent $i$ is $N(i)=\\{i-2, i-1, i+1, i+2\\}$, with indices taken modulo $n$. The update rule is given by the indicator function:\n$$x_i(t+1) = \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\geq \\theta \\right\\}$$\nwhere $\\mathbb{I}\\{\\cdot\\}$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise. The threshold is given as $\\theta=3$. The initial state vector at $t=0$ is:\n$$x(0) = (x_1(0), \\dots, x_{10}(0)) = (1,0,1,1,0,0,1,0,1,0)$$\nWe must compute $x_i(1)$ for each agent $i \\in \\{1, 2, \\dots, 10\\}$. This involves calculating the sum of the states of the four neighbors for each agent and comparing it to the threshold $\\theta=3$. The indices are interpreted modulo $10$, where the set of indices is $\\{1, 2, \\dots, 10\\}$. For example, for agent $i=1$, the neighbor $i-1=0$ corresponds to agent $10$, and $i-2=-1$ corresponds to agent $9$.\n\nFor agent $i=1$:\nThe neighborhood is $N(1) = \\{9, 10, 2, 3\\}$.\nThe sum of neighbors' states is $S_1 = x_9(0) + x_{10}(0) + x_2(0) + x_3(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_1=2 < \\theta=3$, the new state is $x_1(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=2$:\nThe neighborhood is $N(2) = \\{10, 1, 3, 4\\}$.\nThe sum of neighbors' states is $S_2 = x_{10}(0) + x_1(0) + x_3(0) + x_4(0) = 0 + 1 + 1 + 1 = 3$.\nSince $S_2=3 \\geq \\theta=3$, the new state is $x_2(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=3$:\nThe neighborhood is $N(3) = \\{1, 2, 4, 5\\}$.\nThe sum of neighbors' states is $S_3 = x_1(0) + x_2(0) + x_4(0) + x_5(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_3=2 < \\theta=3$, the new state is $x_3(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=4$:\nThe neighborhood is $N(4) = \\{2, 3, 5, 6\\}$.\nThe sum of neighbors' states is $S_4 = x_2(0) + x_3(0) + x_5(0) + x_6(0) = 0 + 1 + 0 + 0 = 1$.\nSince $S_4=1 < \\theta=3$, the new state is $x_4(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=5$:\nThe neighborhood is $N(5) = \\{3, 4, 6, 7\\}$.\nThe sum of neighbors' states is $S_5 = x_3(0) + x_4(0) + x_6(0) + x_7(0) = 1 + 1 + 0 + 1 = 3$.\nSince $S_5=3 \\geq \\theta=3$, the new state is $x_5(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=6$:\nThe neighborhood is $N(6) = \\{4, 5, 7, 8\\}$.\nThe sum of neighbors' states is $S_6 = x_4(0) + x_5(0) + x_7(0) + x_8(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_6=2 < \\theta=3$, the new state is $x_6(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=7$:\nThe neighborhood is $N(7) = \\{5, 6, 8, 9\\}$.\nThe sum of neighbors' states is $S_7 = x_5(0) + x_6(0) + x_8(0) + x_9(0) = 0 + 0 + 0 + 1 = 1$.\nSince $S_7=1 < \\theta=3$, the new state is $x_7(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=8$:\nThe neighborhood is $N(8) = \\{6, 7, 9, 10\\}$.\nThe sum of neighbors' states is $S_8 = x_6(0) + x_7(0) + x_9(0) + x_{10}(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_8=2 < \\theta=3$, the new state is $x_8(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=9$:\nThe neighborhood is $N(9) = \\{7, 8, 10, 1\\}$.\nThe sum of neighbors' states is $S_9 = x_7(0) + x_8(0) + x_{10}(0) + x_1(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_9=2 < \\theta=3$, the new state is $x_9(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=10$:\nThe neighborhood is $N(10) = \\{8, 9, 1, 2\\}$.\nThe sum of neighbors' states is $S_{10} = x_8(0) + x_9(0) + x_1(0) + x_2(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_{10}=2 < \\theta=3$, the new state is $x_{10}(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nCombining these results, the state vector at time $t=1$ is:\n$$x(1) = \\bigl(x_1(1), x_2(1), x_3(1), x_4(1), x_5(1), x_6(1), x_7(1), x_8(1), x_9(1), x_{10}(1)\\bigr) = (0, 1, 0, 0, 1, 0, 0, 0, 0, 0)$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Beyond the rules for individual agents, the overall behavior of an ABM is critically shaped by the *update schedule*—the sequence in which agents execute their rules. This exercise directly contrasts a synchronous schedule, where all agents decide based on the same snapshot in time, with an asynchronous one, where updates are sequential and immediately affect later agents. By simulating both scenarios, you will discover how this seemingly low-level implementation choice can create path-dependent outcomes and lead to drastically different system-level trajectories. ",
            "id": "4113500",
            "problem": "Consider an Agent-Based Modeling (ABM) setup with a finite set of agents $V = \\{1,2,3,4\\}$ embedded in a directed influence network. Let the binary adoption state of agent $i$ at discrete time tick $t$ be denoted by $x_{i}(t) \\in \\{0,1\\}$, where $x_{i}(t) = 1$ indicates that agent $i$ has adopted. Let the initial state at tick $t=0$ be $x_{1}(0) = 1$ and $x_{2}(0) = x_{3}(0) = x_{4}(0) = 0$. The influence from agent $j$ to agent $i$ is given by a nonnegative weight $w_{ji}$; define the weighted influence matrix with entries\n$$\nw_{12} = 0.6,\\quad w_{32} = 0.5,\\quad w_{42} = 0.2,\\quad w_{13} = 0.7,\\quad w_{23} = 0.4,\\quad w_{43} = 0.3,\\quad w_{14} = 0.4,\\quad w_{24} = 0.5,\\quad w_{34} = 0.5,\n$$\nand $w_{ii} = 0$ for all $i$. Each agent $i$ has an adoption threshold $\\theta_{i}$ such that\n$$\n\\theta_{2} = 0.6,\\quad \\theta_{3} = 0.8,\\quad \\theta_{4} = 0.9.\n$$\nWithin a tick, an agent’s decision rule is defined as follows: when agent $i$ updates during tick $t=1$, it computes the instantaneous influence\n$$\ns_{i} = \\sum_{j \\in V} w_{ji}\\, x_{j}^{\\text{obs}},\n$$\nwhere $x_{j}^{\\text{obs}}$ is the observed adoption state of agent $j$ at the time of evaluation. Agent $i$ adopts (sets $x_{i} = 1$) if and only if $s_{i} \\ge \\theta_{i}$; otherwise, it remains at $x_{i} = 0$. Once adopted, an agent stays adopted.\n\nTwo schedule semantics are considered for tick $t=1$:\n\n- Asynchronous sequential schedule: agents update one by one in the fixed order $(1,3,2,4)$, with adoptions taking effect immediately and influencing subsequent agents in the same tick. In this schedule, $x_{j}^{\\text{obs}}$ is the current state at the moment each agent updates in the sequence.\n\n- Synchronous schedule: all agents compute their influences using the pre-tick state $x_{j}(0)$, and all adoption decisions are applied simultaneously at the end of tick $t=1$. In this schedule, $x_{j}^{\\text{obs}} = x_{j}(0)$ for all agents during the computation of $s_{i}$.\n\nUsing only these definitions and rules, manually simulate one tick ($t=1$) under both schedules. Let $N_{\\text{async}}$ be the total number of adopted agents after the asynchronous sequential schedule completes, and $N_{\\text{sync}}$ be the total number of adopted agents after the synchronous schedule completes. Compute the difference\n$$\n\\Delta = N_{\\text{async}} - N_{\\text{sync}}.\n$$\nExpress the final answer as a single real number. No rounding is required.",
            "solution": "The problem is well-defined and self-contained, presenting a classic linear threshold model on a network, a fundamental concept in agent-based modeling. All parameters, initial conditions, and rules are provided, allowing for a deterministic simulation. The problem is therefore valid.\n\nThe state of the system at any time $t$ is given by the vector of adoption states $x(t) = (x_{1}(t), x_{2}(t), x_{3}(t), x_{4}(t))$. The initial state at time $t=0$ is $x(0) = (1, 0, 0, 0)$.\n\nAn agent $i$ that is not yet adopted ($x_i=0$) will adopt if the total influence $s_i$ it receives from its neighbors meets or exceeds its personal threshold $\\theta_i$. The influence is calculated as $s_{i} = \\sum_{j \\in V} w_{ji}\\, x_{j}^{\\text{obs}}$. Once an agent adopts, its state remains $1$ for all subsequent times.\n\nWe will simulate one time tick, from $t=0$ to $t=1$, under two different scheduling protocols.\n\nAn important detail is the set of neighbors for each agent. The non-zero weights define the influence network structure:\n- Agent $2$ is influenced by agents $1, 3, 4$.\n- Agent $3$ is influenced by agents $1, 2, 4$.\n- Agent $4$ is influenced by agents $1, 2, 3$.\n\nSimulation of the Asynchronous Sequential Schedule\nThe update order for tick $t=1$ is agents $(1, 3, 2, 4)$. The state vector is updated immediately after each agent's decision.\nThe initial state for the tick is $x = (1, 0, 0, 0)$.\n\n1.  Agent $1$ updates: Agent $1$ begins in an adopted state, $x_1=1$. The problem states that an adopted agent stays adopted. Thus, $x_1$ remains $1$.\n    The state vector is unchanged: $(1, 0, 0, 0)$.\n\n2.  Agent $3$ updates: Agent $3$ is not adopted, $x_3=0$. We compute its influence score $s_3$ using the current state of the system, $(1, 0, 0, 0)$.\n    $$\n    s_{3} = \\sum_{j=1}^{4} w_{j3} x_{j} = w_{13}x_{1} + w_{23}x_{2} + w_{33}x_{3} + w_{43}x_{4}\n    $$\n    Substituting the current states and given weights ($w_{13} = 0.7$, $w_{23} = 0.4$, $w_{43} = 0.3$, and $w_{33}=0$):\n    $$\n    s_{3} = (0.7)(1) + (0.4)(0) + (0)(0) + (0.3)(0) = 0.7\n    $$\n    The threshold for agent $3$ is $\\theta_3 = 0.8$. Since $s_3 = 0.7 < \\theta_3$, agent $3$ does not adopt. $x_3$ remains $0$.\n    The state vector is unchanged: $(1, 0, 0, 0)$.\n\n3.  Agent $2$ updates: Agent $2$ is not adopted, $x_2=0$. We compute its influence score $s_2$ using the current state, which is still $(1, 0, 0, 0)$.\n    $$\n    s_{2} = \\sum_{j=1}^{4} w_{j2} x_{j} = w_{12}x_{1} + w_{22}x_{2} + w_{32}x_{3} + w_{42}x_{4}\n    $$\n    Substituting the current states and given weights ($w_{12} = 0.6$, $w_{32} = 0.5$, $w_{42} = 0.2$, and $w_{22}=0$):\n    $$\n    s_{2} = (0.6)(1) + (0)(0) + (0.5)(0) + (0.2)(0) = 0.6\n    $$\n    The threshold for agent $2$ is $\\theta_2 = 0.6$. Since $s_2 = 0.6 \\ge \\theta_2$, agent $2$ adopts. Its state changes to $x_2=1$.\n    The state vector is updated to $(1, 1, 0, 0)$.\n\n4.  Agent $4$ updates: Agent $4$ is not adopted, $x_4=0$. We compute its influence score $s_4$ using the current state, which is now $(1, 1, 0, 0)$ due to the adoption by agent $2$.\n    $$\n    s_{4} = \\sum_{j=1}^{4} w_{j4} x_{j} = w_{14}x_{1} + w_{24}x_{2} + w_{34}x_{3} + w_{44}x_{4}\n    $$\n    Substituting the current states and given weights ($w_{14} = 0.4$, $w_{24} = 0.5$, $w_{34} = 0.5$, and $w_{44}=0$):\n    $$\n    s_{4} = (0.4)(1) + (0.5)(1) + (0.5)(0) + (0)(0) = 0.4 + 0.5 = 0.9\n    $$\n    The threshold for agent $4$ is $\\theta_4 = 0.9$. Since $s_4 = 0.9 \\ge \\theta_4$, agent $4$ adopts. Its state changes to $x_4=1$.\n    The state vector is updated to $(1, 1, 0, 1)$.\n\nThe asynchronous sequential schedule for tick $t=1$ is complete. The final state vector is $x(1)_{\\text{async}} = (1, 1, 0, 1)$. The set of adopted agents is $\\{1, 2, 4\\}$.\nThe total number of adopted agents is $N_{\\text{async}} = 3$.\n\nSimulation of the Synchronous Schedule\nAll agents compute their influence scores based on the state at the beginning of the tick, $x(0)=(1, 0, 0, 0)$. All state changes are then applied simultaneously.\n\n1.  Agent $1$ is already adopted ($x_1(0)=1$), so it remains adopted. Its new state is $x_1(1)=1$.\n\n2.  For agent $2$ ($x_2(0)=0$), the influence score $s_2$ is calculated using $x(0)$:\n    $$\n    s_{2} = \\sum_{j=1}^{4} w_{j2} x_{j}(0) = w_{12}x_1(0) + w_{22}x_2(0) + w_{32}x_3(0) + w_{42}x_4(0)\n    $$\n    $$\n    s_{2} = (0.6)(1) + (0)(0) + (0.5)(0) + (0.2)(0) = 0.6\n    $$\n    Comparing to the threshold $\\theta_2 = 0.6$, we have $s_2 \\ge \\theta_2$. Agent $2$ decides to adopt. Its new state will be $x_2(1)=1$.\n\n3.  For agent $3$ ($x_3(0)=0$), the influence score $s_3$ is calculated using $x(0)$:\n    $$\n    s_{3} = \\sum_{j=1}^{4} w_{j3} x_{j}(0) = w_{13}x_1(0) + w_{23}x_2(0) + w_{33}x_3(0) + w_{43}x_4(0)\n    $$\n    $$\n    s_{3} = (0.7)(1) + (0.4)(0) + (0)(0) + (0.3)(0) = 0.7\n    $$\n    Comparing to the threshold $\\theta_3 = 0.8$, we have $s_3 < \\theta_3$. Agent $3$ does not adopt. Its new state will be $x_3(1)=0$.\n\n4.  For agent $4$ ($x_4(0)=0$), the influence score $s_4$ is calculated using $x(0)$:\n    $$\n    s_{4} = \\sum_{j=1}^{4} w_{j4} x_{j}(0) = w_{14}x_1(0) + w_{24}x_2(0) + w_{34}x_3(0) + w_{44}x_4(0)\n    $$\n    $$\n    s_{4} = (0.4)(1) + (0.5)(0) + (0.5)(0) + (0)(0) = 0.4\n    $$\n    Comparing to the threshold $\\theta_4 = 0.9$, we have $s_4 < \\theta_4$. Agent $4$ does not adopt. Its new state will be $x_4(1)=0$.\n\nAll decisions are applied simultaneously. The new state vector is $x(1)_{\\text{sync}} = (1, 1, 0, 0)$. The set of adopted agents is $\\{1, 2\\}$.\nThe total number of adopted agents is $N_{\\text{sync}} = 2$.\n\nCalculation of the Difference\nThe problem asks for the difference $\\Delta = N_{\\text{async}} - N_{\\text{sync}}$.\n$$\n\\Delta = 3 - 2 = 1\n$$\nThis difference illustrates the path-dependent nature of asynchronous updates, where the order of agent actions can significantly alter the system's trajectory. In this case, agent $2$'s adoption during the asynchronous schedule enabled agent $4$ to reach its threshold, an outcome not possible under the synchronous schedule where agent $2$'s new state was not visible to agent $4$ within the same tick.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Advanced agent-based modeling often involves translating continuous real-world phenomena into discrete computational frameworks, a process that can introduce subtle artifacts. This practice challenges you to model cellular motility, deriving agent choice probabilities from the statistical mechanics principle of maximum entropy. By implementing a program to compute directional bias, you will explore how the choice of a lattice structure and neighborhood definition—fundamental decisions in many spatial ABMs—can unintentionally influence agent behavior. ",
            "id": "4313996",
            "problem": "Consider a square-lattice Agent-Based Model (ABM) of cell motility in the plane, in which each agent executes a time-discrete random walk with one move per time step to a neighboring lattice site. Two neighborhood schemes are considered: the Moore neighborhood (comprising $8$ neighbors with displacements $\\{(\\pm 1,0),(0,\\pm 1),(\\pm 1,\\pm 1)\\}$) and the von Neumann neighborhood (comprising $4$ neighbors with displacements $\\{(\\pm 1,0),(0,\\pm 1)\\}$). The chemotactic gradient is represented by a unit vector $\\hat{\\mathbf{g}}$ orientated at angle $\\theta$ (in radians) relative to the positive $x$-axis, that is $\\hat{\\mathbf{g}} = (\\cos\\theta,\\sin\\theta)$. Assume no resting state.\n\nDefine two step-length conventions for the displacement applied when a move is executed:\n- \"physical\": the displacement vector is the raw lattice vector $\\mathbf{d}_i \\in \\mathbb{Z}^2$, yielding cardinal steps of length $1$ and diagonal steps of length $\\sqrt{2}$.\n- \"normalized\": the displacement vector is the unit vector in the lattice direction $\\hat{\\mathbf{d}}_i = \\mathbf{d}_i/\\|\\mathbf{d}_i\\|$, so all performed steps have unit length.\n\nAssume the agent senses the directional alignment of candidate moves with the gradient (but not their length), and model the choice probabilities by the following principle: among the available neighbor directions $\\{\\mathbf{d}_i\\}$ in the chosen neighborhood, the probability of selecting a direction is governed by maximum entropy under a constraint on the expected alignment with $\\hat{\\mathbf{g}}$, controlled by a sensitivity parameter $\\beta \\ge 0$ (dimensionless). The chosen move is then executed according to the specified step-length convention. The directional bias, $b$, is defined as the expected projection of the step displacement onto $\\hat{\\mathbf{g}}$ per time step (in lattice cell-lengths per step). Formally, let the displacement actually applied be $\\mathbf{s}_i$, and the selection probability be $p_i$, then\n$$\nb = \\sum_i p_i \\, (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}).\n$$\n\nYour task is to derive, from first principles and the stated assumptions, a mathematically explicit expression for the choice probabilities $p_i$ and the resulting directional bias $b$ for a given neighborhood, sensitivity $\\beta$, step-length convention, and gradient angle $\\theta$. Then implement a program that computes $b$ for each of the test cases below.\n\nPhysical unit specification: report $b$ in lattice cell-lengths per step, rounded to six decimal places.\n\nAngle unit specification: input angles are specified in radians.\n\nTest suite and parameter coverage:\n- Case $1$: neighborhood \"Moore\", step-length convention \"physical\", sensitivity $\\beta = 1$, gradient angle $\\theta = \\pi/4$.\n- Case $2$: neighborhood \"vonNeumann\", step-length convention \"normalized\", sensitivity $\\beta = 10$, gradient angle $\\theta = \\pi/4$.\n- Case $3$: neighborhood \"Moore\", step-length convention \"normalized\", sensitivity $\\beta = 0$, gradient angle $\\theta = \\pi/3$.\n- Case $4$: neighborhood \"vonNeumann\", step-length convention \"physical\", sensitivity $\\beta = 1/2$, gradient angle $\\theta = 0$.\n- Case $5$: neighborhood \"Moore\", step-length convention \"physical\", sensitivity $\\beta = 100$, gradient angle $\\theta = \\arctan(2)$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[$result_1,result_2,\\dots$]\"), where each $result_i$ is the directional bias $b$ for the corresponding test case, rounded to six decimal places, in the order of the cases listed above.",
            "solution": "The problem asks for the derivation of an expression for the directional bias, $b$, of a chemotactic agent on a square lattice and its computation for several test cases. The solution proceeds by first deriving the choice probabilities from the principle of maximum entropy and then using these probabilities to compute the expected displacement, i.e., the directional bias.\n\n**1. Derivation of Choice Probabilities from Maximum Entropy**\n\nThe problem states that the probability $p_i$ of selecting a move in direction $i$ is governed by the principle of maximum entropy (MaxEnt). We seek to find the probability distribution $\\{p_i\\}$ over the $N$ available moves that maximizes the Shannon entropy, $S = -\\sum_{i=1}^{N} p_i \\ln p_i$, subject to certain constraints.\n\nThe constraints are:\n1.  **Normalization**: The probabilities must sum to $1$.\n    $$ \\sum_{i=1}^{N} p_i = 1 $$\n2.  **Expected Alignment**: The agent's choice is biased by the alignment of the possible move *directions* with the gradient vector $\\hat{\\mathbf{g}}$. Let the unit vector for the $i$-th move direction be $\\hat{\\mathbf{d}}_i$. The alignment is the scalar product $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$. The constraint is on the expected value of this alignment.\n    $$ \\sum_{i=1}^{N} p_i c_i = \\langle c \\rangle $$\n    where $\\langle c \\rangle$ is a specified mean alignment, whose value is implicitly controlled by the sensitivity parameter $\\beta$.\n\nWe use the method of Lagrange multipliers to maximize $S$ under these constraints. The Lagrangian $\\mathcal{L}$ is:\n$$ \\mathcal{L}(\\{p_i\\}, \\lambda_0, \\beta) = -\\sum_{i=1}^{N} p_i \\ln p_i - \\lambda_0 \\left(\\sum_{i=1}^{N} p_i - 1\\right) - \\beta \\left(\\sum_{i=1}^{N} p_i c_i - \\langle c \\rangle\\right) $$\nHere, $\\lambda_0$ and $\\beta$ are the Lagrange multipliers. The problem identifies $\\beta$ as the \"sensitivity parameter\". For a parameter to represent sensitivity to an attractive gradient, a larger positive $\\beta$ must correspond to a stronger preference for directions aligned with the gradient (larger $\\langle c \\rangle$). We will confirm this interpretation.\n\nDifferentiating $\\mathcal{L}$ with respect to $p_j$ and setting the result to zero gives:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial p_j} = -\\ln p_j - 1 - \\lambda_0 - \\beta c_j = 0 $$\n$$ \\ln p_j = -1 - \\lambda_0 - \\beta c_j \\implies p_j = e^{-1-\\lambda_0} e^{-\\beta c_j} $$\n\nTo find the term $e^{-1-\\lambda_0}$, we apply the normalization constraint:\n$$ \\sum_{j=1}^{N} p_j = e^{-1-\\lambda_0} \\sum_{j=1}^{N} e^{-\\beta c_j} = 1 \\implies e^{-1-\\lambda_0} = \\frac{1}{\\sum_{j=1}^{N} e^{-\\beta c_j}} $$\nThe denominator is the partition function, $Z = \\sum_{j=1}^{N} e^{-\\beta c_j}$. The probability of choosing move $j$ is thus:\n$$ p_j = \\frac{e^{-\\beta c_j}}{Z} $$\nThis is a standard Boltzmann-Gibbs distribution. The expected alignment is $\\langle c \\rangle = \\frac{\\partial \\ln Z}{\\partial(-\\beta)}$. To ensure that $\\langle c \\rangle$ increases with sensitivity, we expect $\\frac{\\partial \\langle c \\rangle}{\\partial \\beta} > 0$. The derivative is $\\frac{\\partial \\langle c \\rangle}{\\partial \\beta} = \\langle c^2 \\rangle - \\langle c \\rangle^2 = \\text{Var}(c) \\ge 0$. If we use the multiplier $-\\beta$, then $\\frac{\\partial \\langle c \\rangle}{\\partial(-\\beta)} = -\\text{Var}(c) \\le 0$. This would imply chemo-repulsion. Therefore, to model attraction as implied by \"sensitivity\", the Lagrange multiplier should be positive, leading to a distribution of the form $p_j \\propto e^{+\\beta c_j}$. The correct formulation is:\n$$ p_i = \\frac{e^{\\beta c_i}}{Z}, \\quad \\text{where} \\quad Z = \\sum_{j=1}^{N} e^{\\beta c_j} $$\nand $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$. This is the probability distribution we will use.\n\n**2. Defining Model Components**\n\nThe calculation of the directional bias $b$ requires defining the specific vectors for each component of the model.\n*   **Gradient Vector**: $\\hat{\\mathbf{g}} = (\\cos\\theta, \\sin\\theta)$, where $\\theta$ is the angle with the positive $x$-axis.\n*   **Neighborhoods and Displacements**: Let $N$ be the number of neighbors.\n    *   **Moore Neighborhood ($N=8$)**: The set of raw lattice displacements is $\\{\\mathbf{d}_i^{\\text{Moore}}\\} = \\{(\\pm 1, 0), (0, \\pm 1), (\\pm 1, \\pm 1)\\}$.\n    *   **von Neumann Neighborhood ($N=4$)**: The set of raw lattice displacements is $\\{\\mathbf{d}_i^{\\text{vN}}\\} = \\{(\\pm 1, 0), (0, \\pm 1)\\}$.\n*   **Direction Vectors**: The unit direction vectors, $\\hat{\\mathbf{d}}_i$, are obtained by normalizing the raw vectors: $\\hat{\\mathbf{d}}_i = \\mathbf{d}_i / \\|\\mathbf{d}_i\\|$. For von Neumann moves, $\\|\\mathbf{d}_i\\|=1$, so $\\hat{\\mathbf{d}}_i=\\mathbf{d}_i$. For Moore, the diagonal moves like $(1,1)$ have length $\\|\\mathbf{d}_i\\|=\\sqrt{2}$, so the corresponding direction vector is $\\hat{\\mathbf{d}}_i=(1/\\sqrt{2}, 1/\\sqrt{2})$.\n*   **Step-Length Conventions**: The actual displacement vector applied, $\\mathbf{s}_i$, depends on the convention.\n    *   **\"physical\"**: The step vector is the raw lattice vector, $\\mathbf{s}_i = \\mathbf{d}_i$.\n    *   **\"normalized\"**: The step vector is the unit direction vector, $\\mathbf{s}_i = \\hat{\\mathbf{d}}_i$.\n\n**3. Formulation of Directional Bias, $b$**\n\nThe directional bias, $b$, is defined as the expected projection of the step displacement vector $\\mathbf{s}_i$ onto the gradient vector $\\hat{\\mathbf{g}}$, averaged over all possible moves.\n$$ b = \\sum_{i=1}^{N} p_i \\, (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}) $$\nUsing the derived probability $p_i$, the full expression for $b$ is:\n$$ b = \\sum_{i=1}^{N} \\left( \\frac{e^{\\beta (\\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}})}}{\\sum_{j=1}^{N} e^{\\beta (\\hat{\\mathbf{d}}_j \\cdot \\hat{\\mathbf{g}})}} \\right) (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}) $$\n\n**4. Computational Algorithm**\n\nFor any given test case (neighborhood, step-length convention, $\\beta$, $\\theta$), the computation of $b$ proceeds as follows:\n\n1.  Identify the set of raw displacement vectors $\\{\\mathbf{d}_i\\}$ for the specified neighborhood.\n2.  Calculate the corresponding set of unit direction vectors $\\{\\hat{\\mathbf{d}}_i\\}$.\n3.  Determine the set of applied step vectors $\\{\\mathbf{s}_i\\}$ based on the step-length convention.\n4.  Construct the gradient vector $\\hat{\\mathbf{g}} = (\\cos\\theta, \\sin\\theta)$.\n5.  Calculate the directional alignments $c_i = \\hat{\\mathbf{d}}_i \\cdot \\hat{\\mathbf{g}}$ for each move $i$.\n6.  Calculate the weights $w_i = e^{\\beta c_i}$.\n7.  Compute the partition function $Z = \\sum_{i=1}^{N} w_i$.\n8.  Determine the choice probabilities $p_i = w_i / Z$.\n9.  Calculate the projected displacement for each move, $b_i = \\mathbf{s}_i \\cdot \\hat{\\mathbf{g}}$.\n10. Compute the final directional bias as the weighted sum $b = \\sum_{i=1}^{N} p_i b_i$.\n\nA special case is $\\beta=0$. Here, $w_i=e^0=1$ for all $i$, so $p_i=1/N$. The bias becomes $b = \\frac{1}{N} \\sum_i (\\mathbf{s}_i \\cdot \\hat{\\mathbf{g}})$. Since both the Moore and von Neumann neighborhoods are symmetric with respect to the origin (i.e., $\\sum_i \\mathbf{d}_i = \\mathbf{0}$ and $\\sum_i \\hat{\\mathbf{d}}_i = \\mathbf{0}$), the bias for $\\beta=0$ is always $0$, as seen in Test Case $3$. For $\\beta > 0$, the bias will be positive, indicating a net drift in the direction of the gradient. For very large $\\beta$, the probability will be concentrated on the move with the highest alignment $c_i$, and $b$ will approach the maximum possible value of $(\\mathbf{s}_{\\text{best}} \\cdot \\hat{\\mathbf{g}})$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the cell motility problem for the given test suite.\n    \"\"\"\n\n    # Define neighborhood raw displacement vectors\n    neighborhoods_raw = {\n        \"Moore\": np.array([\n            [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0],\n            [1.0, 1.0], [-1.0, -1.0], [1.0, -1.0], [-1.0, 1.0]\n        ]),\n        \"vonNeumann\": np.array([\n            [1.0, 0.0], [-1.0, 0.0], [0.0, 1.0], [0.0, -1.0]\n        ])\n    }\n\n    # Define the test cases from the problem statement.\n    # The format is (neighborhood, step-length convention, sensitivity beta, gradient angle theta).\n    test_cases = [\n        (\"Moore\", \"physical\", 1.0, np.pi / 4),\n        (\"vonNeumann\", \"normalized\", 10.0, np.pi / 4),\n        (\"Moore\", \"normalized\", 0.0, np.pi / 3),\n        (\"vonNeumann\", \"physical\", 0.5, 0.0),\n        (\"Moore\", \"physical\", 100.0, np.arctan(2.0)),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        neighborhood_name, convention, beta, theta = case\n\n        # 1. Get raw displacement vectors for the neighborhood\n        d_raw = neighborhoods_raw[neighborhood_name]\n\n        # 2. Calculate unit direction vectors\n        norms = np.linalg.norm(d_raw, axis=1)\n        # Reshape for broadcasting to prevent division errors in logic, although not strictly needed here\n        # as norms are always non-zero.\n        d_unit = d_raw / norms[:, np.newaxis]\n\n        # 3. Determine applied step vectors based on convention\n        if convention == \"physical\":\n            s_vectors = d_raw\n        elif convention == \"normalized\":\n            s_vectors = d_unit\n        else:\n            raise ValueError(f\"Unknown step-length convention: {convention}\")\n\n        # 4. Construct gradient vector\n        g_vector = np.array([np.cos(theta), np.sin(theta)])\n\n        # 5. Calculate directional alignments (c_i = d_hat_i . g_hat)\n        # This is a matrix-vector product where each row of d_unit is a vector\n        alignments = d_unit @ g_vector\n\n        # 6. Calculate choice probabilities (p_i propto exp(beta * c_i))\n        # Handle the beta=0 case explicitly to avoid potential floating point issues,\n        # although np.exp(0) is exactly 1.\n        if beta == 0.0:\n            num_moves = d_raw.shape[0]\n            probabilities = np.full(num_moves, 1.0 / num_moves)\n        else:\n            weights = np.exp(beta * alignments)\n            partition_function = np.sum(weights)\n            probabilities = weights / partition_function\n\n        # 7. Calculate projected displacement for each move (b_i = s_i . g_hat)\n        projected_displacements = s_vectors @ g_vector\n        \n        # 8. Compute final directional bias (b = sum(p_i * b_i))\n        directional_bias = np.sum(probabilities * projected_displacements)\n        \n        results.append(directional_bias)\n\n    # Final print statement in the exact required format.\n    # The results are formatted to six decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}