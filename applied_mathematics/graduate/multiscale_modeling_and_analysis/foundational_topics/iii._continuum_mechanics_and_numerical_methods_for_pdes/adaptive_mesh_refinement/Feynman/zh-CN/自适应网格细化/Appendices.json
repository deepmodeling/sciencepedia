{
    "hands_on_practices": [
        {
            "introduction": "在自适应网格加密（AMR）中，一个核心任务是确保在数据从粗网格传递到细网格时，如质量或动量等物理量保持守恒。本练习将引导你从第一性原理出发，利用多项式重构来构建一个“延拓算子”，这是高阶有限体积方法的一块基石。通过这项实践，你将巩固对如何利用局部数据生成精确的子网格分布，同时严格维持守恒定律的理解。",
            "id": "3730542",
            "problem": "考虑一个长度为 $L$ 的周期性域上的一维均匀网格，该网格被划分为 $N$ 个粗网格单元，单元宽度为 $h = L/N$，单元中心位于 $x_i = \\left(i + \\tfrac{1}{2}\\right) h$，其中 $i = 0, 1, \\dots, N-1$。令粗网格单元的平均值表示为 $\\bar{U}_i$，其中 $\\bar{U}_i$ 是底层充分光滑函数 $u(x)$ 在粗网格单元区间 $[x_{i-\\frac{1}{2}}, x_{i+\\frac{1}{2}}]$ 上的平均值的近似。自适应网格加密（AMR, Adaptive Mesh Refinement）要求从粗网格到细网格的延拓，以使细网格单元的平均值与守恒性一致。\n\n您的任务是在每个粗网格单元内使用高阶重构来构建一个守恒延拓算子。具体来说：\n\n- 在每个粗网格单元 $i$ 内，重构一个至少为二次的多项式 $p_i(x)$，使得 $p_i(x)$ 在 $[x_{i-\\frac{1}{2}}, x_{i+\\frac{1}{2}}]$ 上的平均值等于 $\\bar{U}_i$。仅使用来自 $\\bar{U}_{i-1}$、$\\bar{U}_i$ 和 $\\bar{U}_{i+1}$ 的信息，并对 $i=-1$ 和 $i=N$ 使用周期性索引。\n- 将每个粗网格单元加密成 $r$ 个等宽的细子单元。对于每个细子单元，将其单元平均值计算为重构多项式 $p_i(x)$ 在该子单元上的精确平均值。\n- 通过检查每个粗网格单元的细子单元平均值与细网格宽度之积的总和是否等于粗网格单元平均值与粗网格宽度之积，来验证常数状态下的精确守恒性。此验证必须纯粹使用浮点运算进行数值计算。\n\n您的构建应仅基于有限体积法的基本定义和与多尺度建模一致的中心差分近似。除了要求重构至少是二次的且在上述意义上是守恒的之外，不要假设任何预先推导的延拓公式。\n\n任何三角函数的角度单位都必须是弧度。\n\n您的程序必须实现上述内容，并为所提供的测试套件计算以下指标：\n\n- 对于每个测试用例，计算所有粗网格单元上的最大绝对守恒误差，定义为\n$$\n\\max_i \\left| \\left(\\sum_{k=0}^{r-1} \\bar{u}_{i}^{(k)} \\cdot \\tfrac{h}{r}\\right) - \\bar{U}_i \\cdot h \\right|,\n$$\n其中 $\\bar{u}_{i}^{(k)}$ 是粗网格单元 $i$ 的子单元 $k$ 中的细子单元平均值。\n- 对于非恒定底层函数，计算整个域上所有细子单元的最大绝对重构误差，定义为\n$$\n\\max_{i,k} \\left| \\bar{u}_{i}^{(k)} - \\frac{1}{\\Delta x_f} \\int_{x_{i,k}^{L}}^{x_{i,k}^{R}} u(x)\\, dx \\right|,\n$$\n其中 $\\Delta x_f = h/r$ 是细子单元宽度，$[x_{i,k}^{L}, x_{i,k}^{R}]$ 是粗网格单元 $i$ 中的第 $k$ 个细子单元区间。\n\n测试套件：\n使用以下四个测试用例。对于所有用例，域长度为 $L=1$，并假设采用周期性边界。三角函数中的角度以弧度为单位。\n\n1. 常数状态：\n   - $N = 3$，\n   - $r = 4$，\n   - $u(x) = C$，其中 $C = 1.25$。\n   - 每个测试用例的输出：一个列表 $[\\text{cons\\_err}, \\text{max\\_err}, \\text{const\\_exact}]$，其中 $\\text{cons\\_err}$ 是作为浮点数的最大绝对守恒误差，$\\text{max\\_err}$ 是作为浮点数的最大绝对重构误差，$\\text{const\\_exact}$ 是一个布尔值，指示每个细子单元平均值是否在严格的数值公差内等于 $C$。\n\n2. 线性状态：\n   - $N = 10$，\n   - $r = 3$，\n   - $u(x) = \\alpha + \\beta x$，其中 $\\alpha = 2.0$ 且 $\\beta = -0.7$。\n   - 每个测试用例的输出：一个列表 $[\\text{cons\\_err}, \\text{max\\_err}]$。\n\n3. 二次状态：\n   - $N = 12$，\n   - $r = 2$，\n   - $u(x) = a x^2 + b x + c$，其中 $a = -2.0$，$b = 1.0$ 且 $c = 1.0$。\n   - 每个测试用例的输出：一个列表 $[\\text{cons\\_err}, \\text{max\\_err}]$。\n\n4. 正弦状态：\n   - $N = 16$，\n   - $r = 5$，\n   - $u(x) = \\sin(2\\pi k x)$，其中 $k = 3$。\n   - 每个测试用例的输出：一个列表 $[\\text{cons\\_err}, \\text{max\\_err}]$。\n\n在解析积分简单直接的情况下，必须从 $u(x)$ 精确计算粗网格单元平均值 $\\bar{U}_i$。对于正弦情况，使用每个区间上平均值的精确积分表达式。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个测试用例的结果都表示为上面指定的列表。例如，输出必须类似于 `[ [...], [...], [...], [...]]` 不含任何附加文本。\n\n所有数值答案必须是无量纲的浮点数或布尔值。此问题不涉及物理单位，角度以弧度为单位指定。",
            "solution": "该问题要求在一个一维周期性域上，为自适应网格加密（AMR）框架构建并评估一个守恒的二阶延拓算子。任务的核心是在每个粗网格单元内重构一个二次多项式，然后用它来定义该单元内加密网格上的体积平均值，并确保守恒性。\n\n对于每个测试用例，解决方案按以下几个步骤进行：\n1.  **网格与初始数据**：在域 $[0, L]$ 上定义一个具有 $N$ 个单元的均匀粗网格，单元宽度为 $h = L/N$。对于给定的底层函数 $u(x)$，为每个单元 $i \\in \\{0, ..., N-1\\}$ 计算精确的粗网格单元平均值 $\\bar{U}_i$。\n    $$\n    \\bar{U}_i = \\frac{1}{h} \\int_{ih}^{(i+1)h} u(x) \\, dx\n    $$\n2.  **多项式重构**：对于每个粗网格单元 $i$，我们构建一个二次多项式 $p_i(x)$，用于表示该量在子单元内的分布。为与局部粗网格数据保持一致，该多项式必须满足守恒属性：其在粗网格单元上的平均值必须为 $\\bar{U}_i$。我们将多项式表示为以粗网格单元中点 $x_i = (i + \\frac{1}{2})h$ 为中心的形式：\n    $$\n    p_i(x) = a_i (x - x_i)^2 + b_i (x - x_i) + c_i\n    $$\n    通过将 $p_i(x)$ 在单元 $[x_i - h/2, x_i + h/2]$ 上积分来施加守恒约束：\n    $$\n    \\bar{U}_i = \\frac{1}{h} \\int_{x_i - h/2}^{x_i + h/2} \\left[a_i (x - x_i)^2 + b_i (x - x_i) + c_i\\right] \\, dx = a_i \\frac{h^2}{12} + c_i\n    $$\n    这为三个系数 $a_i, b_i, c_i$ 提供了一个方程。剩下的两个自由度是根据指定的要求，使用相邻单元的信息来确定的。我们基于粗网格单元平均值 $\\bar{U}_{i-1}, \\bar{U}_i, \\bar{U}_{i+1}$，对底层函数在单元中心 $x_i$ 处的一阶和二阶导数使用中心差分近似。\n    二阶导数 $p_i''(x_i) = 2a_i$ 近似为：\n    $$\n    2a_i \\approx \\frac{\\bar{U}_{i+1} - 2\\bar{U}_i + \\bar{U}_{i-1}}{h^2} \\implies a_i = \\frac{\\bar{U}_{i+1} - 2\\bar{U}_i + \\bar{U}_{i-1}}{2h^2}\n    $$\n    一阶导数 $p_i'(x_i) = b_i$ 近似为：\n    $$\n    b_i \\approx \\frac{\\bar{U}_{i+1} - \\bar{U}_{i-1}}{2h}\n    $$\n    在确定了 $a_i$ 和 $b_i$ 之后，从守恒约束中求得 $c_i$：\n    $$\n    c_i = \\bar{U}_i - a_i \\frac{h^2}{12}\n    $$\n    使用周期性边界条件来找到模板值 $\\bar{U}_{-1}$ 和 $\\bar{U}_{N}$。这样就唯一地定义了每个单元 $i$ 的重构多项式 $p_i(x)$。该方法是高阶有限体积法中的一种标准方法。\n\n3.  **延拓**：每个粗网格单元 $i$ 被划分为 $r$ 个宽度为 $\\Delta x_f = h/r$ 的细子单元。对于 $k \\in \\{0, ..., r-1\\}$，第 $k$ 个子单元占据区间 $[x_{i,k}^L, x_{i,k}^R] = [ih+k\\Delta x_f, ih+(k+1)\\Delta x_f]$。通过计算重构多项式 $p_i(x)$ 在该子单元上的精确平均值，得到延拓后的细单元平均值 $\\bar{u}_{i}^{(k)}$：\n    $$\n    \\bar{u}_{i}^{(k)} = \\frac{1}{\\Delta x_f} \\int_{x_{i,k}^L}^{x_{i,k}^R} p_i(x) \\, dx\n    $$\n    此积分使用 $p_i(x)$ 的反导数进行解析计算。\n\n4.  **误差分析**：\n    *   **守恒误差**：此指标验证延拓算子是否守恒。根据构造，细单元上某量的总和必须等于粗单元中的该量。粗网格单元 $i$ 的守恒误差通过数值计算得出：\n        $$\n        E_{\\text{cons}, i} = \\left| \\left(\\sum_{k=0}^{r-1} \\bar{u}_{i}^{(k)} \\cdot \\Delta x_f\\right) - \\bar{U}_i \\cdot h \\right|\n        $$\n        理论上，由于 $\\sum_{k=0}^{r-1} \\int_{x_{i,k}^L}^{x_{i,k}^R} p_i(x) \\, dx = \\int_{ih}^{(i+1)h} p_i(x) \\, dx = \\bar{U}_i h$，该误差应在浮点精度范围内为零。报告的是所有粗网格单元中 $E_{\\text{cons}, i}$ 的最大值。\n    *   **重构误差**：此指标衡量重构的准确性。它是计算出的细单元平均值与真实的细单元平均值（通过对原始函数 $u(x)$ 积分获得）之间的最大绝对差：\n        $$\n        E_{\\text{recon}} = \\max_{i,k} \\left| \\bar{u}_{i}^{(k)} - \\frac{1}{\\Delta x_f} \\int_{x_{i,k}^{L}}^{x_{i,k}^{R}} u(x)\\, dx \\right|\n        $$\n    经分析证明，对于最高为2次多项式的底层函数 $u(x)$，此重构方法是精确的。因此，对于常数、线性和二次测试用例，守恒误差和重构误差都应接近机器精度。对于正弦情况，预计会出现非零的重构误差，因为多项式仅是正弦函数的近似。\n\n实现过程首先为每个测试用例的 $u(x)$ 及其解析积分定义函数。然后一个通用函数通过计算粗网格平均值、重构多项式、计算细网格平均值以及评估指定的误差指标来处理每个用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef process_case(N, r, u_integral_func, L=1.0, case_info=None):\n    \"\"\"\n    Processes a single test case for conservative prolongation.\n\n    Args:\n        N (int): Number of coarse cells.\n        r (int): Refinement ratio.\n        u_integral_func (callable): The antiderivative of the true function u(x).\n        L (float): Domain length.\n        case_info (dict, optional): Dictionary with special case parameters.\n\n    Returns:\n        list: A list containing the computed error metrics for the case.\n    \"\"\"\n    # 1. Mesh setup\n    h = L / N\n    dx_f = h / r\n    coarse_cell_bounds = np.linspace(0, L, N + 1)\n    coarse_cell_centers = coarse_cell_bounds[:-1] + h / 2\n\n    # 2. Compute exact coarse cell averages\n    U_bar = np.zeros(N)\n    for i in range(N):\n        x_L, x_R = coarse_cell_bounds[i], coarse_cell_bounds[i + 1]\n        U_bar[i] = (u_integral_func(x_R) - u_integral_func(x_L)) / h\n\n    # Use np.roll for efficient periodic boundary handling\n    U_bar_plus_1 = np.roll(U_bar, -1)\n    U_bar_minus_1 = np.roll(U_bar, 1)\n\n    conservation_errors = []\n    reconstruction_errors = []\n    all_fine_averages = []\n\n    # 3. Loop over each coarse cell for reconstruction and prolongation\n    for i in range(N):\n        x_i_center = coarse_cell_centers[i]\n        \n        # Get stencil values for cell i\n        U_im1, U_i, U_ip1 = U_bar_minus_1[i], U_bar[i], U_bar_plus_1[i]\n\n        # Reconstruct quadratic p_i(x) = a(x-x_i)^2 + b(x-x_i) + c\n        a_coeff = (U_ip1 - 2 * U_i + U_im1) / (2 * h**2)\n        b_coeff = (U_ip1 - U_im1) / (2 * h)\n        c_coeff = U_i - a_coeff * h**2 / 12\n\n        def F_poly_antiderivative(x):\n            \"\"\"Antiderivative of the reconstructed polynomial p_i(x).\"\"\"\n            dx = x - x_i_center\n            return (a_coeff / 3.0) * dx**3 + (b_coeff / 2.0) * dx**2 + c_coeff * dx\n\n        sum_fine_volume = 0.0\n\n        # Loop over fine subcells within the coarse cell i\n        for k in range(r):\n            # 4. Compute fine cell average from polynomial\n            x_fine_L = coarse_cell_bounds[i] + k * dx_f\n            x_fine_R = coarse_cell_bounds[i] + (k + 1) * dx_f\n\n            integral_p = F_poly_antiderivative(x_fine_R) - F_poly_antiderivative(x_fine_L)\n            u_fine_avg = integral_p / dx_f\n            all_fine_averages.append(u_fine_avg)\n            \n            sum_fine_volume += u_fine_avg * dx_f\n\n            # 5. Compute true fine average for error calculation\n            integral_u_true = u_integral_func(x_fine_R) - u_integral_func(x_fine_L)\n            u_true_fine_avg = integral_u_true / dx_f\n            \n            reconstruction_errors.append(np.abs(u_fine_avg - u_true_fine_avg))\n\n        # 6. Compute conservation error for the coarse cell\n        conservation_errors.append(np.abs(sum_fine_volume - U_i * h))\n        \n    max_cons_err = np.max(conservation_errors) if conservation_errors else 0.0\n    max_recon_err = np.max(reconstruction_errors) if reconstruction_errors else 0.0\n\n    if case_info and case_info.get(\"type\") == \"constant\":\n        C_val = case_info[\"C\"]\n        const_exact = np.allclose(all_fine_averages, C_val, rtol=0, atol=1e-14)\n        return [max_cons_err, max_recon_err, const_exact]\n        \n    return [max_cons_err, max_recon_err]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": 3, \"r\": 4,\n            \"u_integral\": lambda x, C=1.25: C * x,\n            \"info\": {\"type\": \"constant\", \"C\": 1.25}\n        },\n        {\n            \"N\": 10, \"r\": 3,\n            \"u_integral\": lambda x, alpha=2.0, beta=-0.7: alpha * x + 0.5 * beta * x**2,\n            \"info\": None\n        },\n        {\n            \"N\": 12, \"r\": 2,\n            \"u_integral\": lambda x, a=-2.0, b=1.0, c=1.0: (a/3.0)*x**3 + (b/2.0)*x**2 + c*x,\n            \"info\": None\n        },\n        {\n            \"N\": 16, \"r\": 5,\n            \"u_integral\": lambda x, k=3: -np.cos(2 * np.pi * k * x) / (2 * np.pi * k),\n            \"info\": None\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        result = process_case(case[\"N\"], case[\"r\"], case[\"u_integral\"], case_info=case[\"info\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The default string conversion for lists and booleans matches the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "采用自适应网格加密（AMR）的主要动机在于其计算效率，因为对于具有局部特征的问题，使用全局一致的细网格在计算上是极其昂贵的。本练习提供了一个动手实践的数值实验，以验证AMR在理论上的缩放优势，展示它如何降低具有局部奇点问题的计算复杂度。通过数值化地估计缩放指数 $\\alpha$，你将对AMR所能带来的巨大性能提升有一个具体的认识。",
            "id": "3730591",
            "problem": "考虑一维域 $[0,1]$ 以及一个通过权重函数在 $x=0$ 处模拟局部奇点的合成基准测试。我们通过追踪自由度数量如何随解析的最小空间尺度而变化，从第一性原理出发研究多尺度建模中的自适应网格加密（AMR）。目标是通过标度论证和数值验证来证明，当奇点行为局限在一个零测度集上时，AMR能将计算复杂度从 $O(N)$ 降低到 $O(N^{\\alpha})$（其中 $\\alpha < 1$）。程序必须根据均匀加密和AMR策略生成的数据计算有效复杂度指数，并为指定的测试套件返回汇总的指数。\n\n标度分析的基本依据：\n- 将域 $[0,1]$ 离散化为多个区间，其自由度数量与区间数量（记为 $N$）成正比。\n- 对于均匀加密，为达到最小单元尺寸 $h_{\\min}$，区间数量满足 $N \\approx 1/h_{\\min}$，这意味着在 $h_{\\min}$ 尺度上达到分辨率需要 $O(1/h_{\\min})$ 个区间，即复杂度与最小解析尺度的倒数成正比。\n- 一种AMR策略仅使用二分法加密局部奇点的一个逐渐缩小的邻域，从而产生一个局部加密的层次结构。如果每一步只对包含奇点的区间进行二分，那么经过 $L$ 次局部加密后，最小单元尺寸满足 $h_{\\min} \\approx h_{0} 2^{-L}$，其中 $h_{0}$ 是奇点附近的初始单元尺寸。因此，$L \\approx \\log_{2}(h_{0}/h_{\\min})$。总区间数 $N \\approx N_{0} + L$，其中 $N_{0}$ 是初始区间数。当 $h_{\\min} \\to 0$ 时，$N \\sim \\log(1/h_{\\min})$，这可以重写为 $N \\sim (1/h_{\\min})^{\\alpha}$，有效指数 $\\alpha \\to 0$。更一般地，如果在 $D$ 维域中，加密目标是维度为 $d_{s}$ 的低维奇点集，则加密区域的测度尺度关系为 $h_{\\min}^{D-d_{s}}$，总区间（或单元）数在对数因子范围内与 $(1/h_{\\min})^{d_{s}}$ 成比例，因此有效指数 $\\alpha = d_{s}/D < 1$（对于 $d_s < D$ 的情况）。\n\n算法描述：\n1. 用一个包含 $N_0$ 个均匀区间的网格初始化域 $[0, 1]$。\n2. 对一个递增的分辨率目标序列 $M_k$，执行以下AMR模拟：\n    - 迭代加密，直到最小区间宽度 $h_{\\min}$ 满足 $h_{\\min} \\le 1/M_k$。\n    - 在每次迭代中，为每个区间 $i$ 计算一个加密指标 $\\eta_i = (x_i^c + \\varepsilon)^{-\\gamma}$，其中 $x_i^c$ 是区间 $i$ 的中点。\n    - 对具有最大指标值的区间进行二分。\n3. 对每个 $M_k$，记录最终的区间总数 $N_{\\text{AMR}}(M_k)$。\n4. 从所得到的数据对 $(M_k, N_{\\text{AMR}}(M_k))$ 中，通过对 $\\log(N_{\\text{AMR}})$ 与 $\\log(M)$ 的数据进行线性最小二乘拟合，数值化地估计有效复杂度指数 $\\alpha$。斜率即为 $\\alpha$ 的估计值。\n\n测试套件：\n对以下每个测试用例计算指数 $\\alpha$：\n1. $\\gamma = 2.0$, $\\varepsilon = 10^{-12}$, $N_0=8$, $M = \\{64, 256, 1024, 4096, 16384\\}$\n2. $\\gamma = 4.0$, $\\varepsilon = 10^{-12}$, $N_0=8$, $M = \\{64, 256, 1024, 4096, 16384\\}$\n3. $\\gamma = 1.0$, $\\varepsilon = 10^{-12}$, $N_0=16$, $M = \\{64, 256, 1024, 4096, 16384\\}$\n\n最终输出格式：\n该程序应返回一个包含三个计算出的有效复杂度指数 $\\alpha$ 的列表，格式为 `[alpha_1, alpha_2, alpha_3]`。",
            "solution": "对所提供问题的分析始于对其前提和结构的验证，发现在数值分析和多尺度建模领域内，这些前提和结构是合理且适定的。该问题要求对应用于具有局部奇点的一维问题的自适应网格加密（AMR）策略的计算复杂度标度关系进行数值验证。\n\n所研究的基本原理是，对于解析具有局部特征的问题，AMR可以显著降低以自由度数量（$N$）衡量的计算成本。对于一个维度为 $D$ 的空间域，其奇点局限于一个维度为 $d_s < D$ 的集合上，达到最小分辨率 $h_{\\min}$ 所需的网格单元数 $N$ 预计将按 $N \\sim (1/h_{\\min})^{d_s}$ 的关系进行标度（忽略对数因子）。这与均匀网格加密形成对比，后者需要 $N \\sim (1/h_{\\min})^D$ 来将整个域解析到 $h_{\\min}$ 的尺度。AMR的效率源于其有效标度指数 $\\alpha = d_s/D$ 小于1。在本特定问题中，我们在一个一维域 $[0, 1]$ 中有一个位于 $x=0$ 的点奇点。因此，$d_s=0$ 且 $D=1$，得出理论指数 $\\alpha = 0$。这意味着 $N$ 的增长应远慢于 $M = 1/h_{\\min}$ 的任何正次幂，具体来说，是对数增长：$N \\sim \\log(M)$。\n\n我们的任务是实现指定的AMR算法，并通过将幂律 $N(M) \\approx C M^{\\alpha}$ 拟合到模拟数据来数值估计有效指数 $\\alpha$。这等同于对经过对数变换的数据进行线性回归：$\\log(N) = \\alpha \\log(M) + \\log(C)$。这条线的斜率即为 $\\alpha$ 的估计值。\n\nAMR算法定义如下：\n1. 用一个包含 $N_0$ 个区间的均匀网格初始化域 $[0, 1]$。\n2. 对于给定的目标分辨率参数 $M$，进入一个加密循环。循环持续进行，直到最小区间宽度 $h_{\\min}$ 小于或等于 $1/M$。\n3. 在循环内部，为每个区间 $i$ 计算一个加密指标 $\\eta_i$。该指标由函数 $\\eta_i = (x_i^c + \\varepsilon)^{-\\gamma}$ 给出，其中 $x_i^c$ 是区间 $i$ 的中点，$\\varepsilon > 0$ 是一个小的正则化参数，$\\gamma>0$ 决定了指标的尖锐程度。\n4. 找出具有最大指标值 $\\eta_{\\max}$ 的区间。指标函数的选择（作为 $x_i^c$ 的单调递减函数）确保了加密集中在 $x_i^c$ 最小的地方，即 $x=0$ 处的奇点附近。\n5. 对这个目标区间进行二分，创建两个新区间，并将总数 $N$ 增加一。\n6. 一旦满足终止条件 $h_{\\min} \\le 1/M$，针对该 $M$ 值的模拟就结束了。记录下最终的区间数量 $N_{\\text{AMR}}(M)$。\n\n对一系列递增的分辨率目标 $\\{M_k\\}$ 重复此过程。收集得到的数据对 $(M_k, N_{\\text{AMR}}(M_k))$。为了估计 $\\alpha$，我们计算数组 $x = [\\log(M_k)]$ 和 $y = [\\log(N_{\\text{AMR}}(M_k))]$。然后应用线性最小二乘拟合来找到穿过这些点的最佳拟合线的斜率，该斜率即为我们对 $\\alpha$ 的数值估计。\n\n实现将包括一个主函数，用于遍历指定的测试用例。对于每个用例，它将调用一个子函数，为每个所需的 $M_k$ 执行AMR模拟。该子函数将管理网格（表示为一个排序的边界点数组）并执行迭代加密过程。收集数据后，主函数将使用 `numpy.polyfit` 函数执行线性回归并提取斜率 $\\alpha$。所有测试用例计算出的指数将被汇总并以要求的格式打印。$\\alpha$ 的期望值是接近理论值 $0$ 的小正数，这反映了 $N$ 随 $M$ 的对数增长。",
            "answer": "```python\nimport numpy as np\n\ndef run_amr_simulation(gamma, epsilon, N0, M):\n    \"\"\"\n    Runs the Adaptive Mesh Refinement (AMR) simulation for a single test case.\n\n    Args:\n        gamma (float): The exponent in the indicator function.\n        epsilon (float): The regularization constant.\n        N0 (int): The initial number of uniform intervals.\n        M (int): The target resolution parameter, such that h_min = 1/M.\n\n    Returns:\n        int: The final number of intervals (degrees of freedom).\n    \"\"\"\n    # Initialize the mesh as a sorted array of boundary points.\n    boundaries = np.linspace(0.0, 1.0, N0 + 1, dtype=np.float64)\n\n    while True:\n        # Calculate cell widths and find the minimum.\n        h = np.diff(boundaries)\n        h_min = np.min(h)\n\n        # Check for termination condition.\n        if h_min = 1.0 / M:\n            break\n\n        # Calculate cell midpoints.\n        midpoints = boundaries[:-1] + h / 2.0\n        \n        # Compute the refinement indicator for each cell.\n        indicators = (midpoints + epsilon)**(-gamma)\n        \n        # Find the index of the cell with the maximum indicator to be refined.\n        idx_to_refine = np.argmax(indicators)\n        \n        # Bisect the chosen cell by inserting a new boundary point at its midpoint.\n        new_boundary = (boundaries[idx_to_refine] + boundaries[idx_to_refine + 1]) / 2.0\n        boundaries = np.insert(boundaries, idx_to_refine + 1, new_boundary)\n        \n    # The number of intervals is one less than the number of boundary points.\n    return len(boundaries) - 1\n\ndef solve():\n    \"\"\"\n    Main function to execute the test suite and compute effective complexity exponents.\n    \"\"\"\n    test_cases = [\n        # (gamma, epsilon, N0, M_values)\n        (2.0, 1e-12, 8, [64, 256, 1024, 4096, 16384]),\n        (4.0, 1e-12, 8, [64, 256, 1024, 4096, 16384]),\n        (1.0, 1e-12, 16, [64, 256, 1024, 4096, 16384]),\n    ]\n\n    results = []\n    for gamma, epsilon, N0, M_values in test_cases:\n        \n        N_amr_values = []\n        for M in M_values:\n            # Run the AMR simulation for each M and store the resulting cell count.\n            n_amr = run_amr_simulation(gamma, epsilon, N0, M)\n            N_amr_values.append(n_amr)\n\n        # Prepare data for log-log regression.\n        # Ensure data types are float for calculations.\n        log_M = np.log(np.array(M_values, dtype=np.float64))\n        log_N = np.log(np.array(N_amr_values, dtype=np.float64))\n        \n        # Perform linear regression: log(N) = alpha * log(M) + intercept.\n        # np.polyfit returns coefficients [slope, intercept].\n        alpha = np.polyfit(log_M, log_N, 1)[0]\n        results.append(alpha)\n\n    # Format the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(f'{r}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "从静态网格转向动态自适应时，会涌现出新的挑战。当激波等特征在网格间移动时，简单的加密准则可能导致“抖动”现象，即加密状态的频繁切换，从而降低效率。本练习将探讨一种借鉴自控制理论的实用解决方案：滞后效应。你将实现并比较一个简单的阈值方案与一个更鲁棒的、基于滞后效应的方案，以理解它如何稳定网格自适应过程，这是构建实用、高效AMR模拟的一项关键技术。",
            "id": "3094967",
            "problem": "你的任务是设计并实现一种基于滞回的自适应网格加密决策方案，以避免在一维模拟（类似于索德激波管问题）中，当移动的激波穿过单元边界时，出现反复的加密/解密切换。计算目标纯粹是算法性的：不要去求解控制偏微分方程。相反，你需要基于一个从具有移动类间断特征的连续代理密度剖面派生出的误差指示器，来推导、实现和比较决策逻辑。\n\n基本和核心定义：自适应网格加密（Adaptive Mesh Refinement, AMR）会在误差指示器高的区域加密计算网格，在误差指示器低的区域解密网格。索德激波管中的移动激波会在密度场中产生巨大的梯度。设定义域为区间 $[0,1]$。存在 $N_{\\text{cells}}$ 个均匀的粗网格单元，其单元宽度为 $\\Delta x = \\frac{1}{N_{\\text{cells}}}$，单元中心为 $x_i = \\left(i + \\frac{1}{2}\\right)\\Delta x$，其中整数 $i \\in \\{0,1,\\dots,N_{\\text{cells}}-1\\}$。定义一个带有移动跳跃的光滑代理密度场：\n$$\n\\rho(x,t) = \\rho_R + \\left(\\rho_L - \\rho_R\\right) S(x,t), \\quad S(x,t) = \\frac{1}{2}\\left(1 - \\tanh\\left(\\frac{x - x_s(t)}{w}\\right)\\right),\n$$\n其中 $x_s(t) = x_0 + v t$ 是激波位置，$w  0$ 是平滑宽度，$\\rho_L$ 是左侧密度状态，$\\rho_R$ 是右侧密度状态。这个代理模型捕捉了如索德激波管情境下的移动陡峭梯度，但保持了连续性以便进行稳定的有限差分计算。逐单元误差指示器由 $\\rho$ 的离散空间梯度定义：\n$$\nI_i(t) = \\frac{\\left|\\rho(x_{i+1}, t) - \\rho(x_i, t)\\right|}{\\Delta x},\n$$\n为避免边界索引问题，$I_{N_{\\text{cells}}-1}(t)$ 被设定为等于 $I_{N_{\\text{cells}}-2}(t)$。为了模拟传感器不确定性和模型离散化噪声，可以向 $I_i(t)$ 添加一个标准差为 $\\sigma$ 的零均值加性高斯噪声项；添加噪声后产生的负指示器值必须被截断为 $0$。\n\n需要实现和比较的决策方案：\n- 朴素方案（单一阈值）：给定一个阈值 $T$，定义加密标志 $R_i(t)$ 如下：如果 $I_i(t) \\ge T$，则 $R_i(t) = \\text{true}$；否则 $R_i(t) = \\text{false}$。\n- 滞回方案（双阈值加保持时间）：给定一个加密阈值 $T_r$、一个解密阈值 $T_d$（其中 $T_d  T_r$）以及一个以整数时间步为单位的保持时间 $H$，按如下方式实现 $R_i(t)$。如果 $R_i(t-1) = \\text{false}$，则仅当 $I_i(t)  T_r$ 时才进行加密；如果在时间 $t$ 发生加密，则设置一个保持计数器 $h_i(t) = H$。如果 $R_i(t-1) = \\text{true}$，则当 $h_i(t-1)  0$ 时继续保持加密状态，此时无论 $I_i(t)$ 为何值，都设置 $R_i(t) = \\text{true}$ 并令 $h_i(t) = h_i(t-1) - 1$。当保持计数器达到 $0$ 后，仅当 $I_i(t)  T_d$ 时才进行解密；否则保持 $R_i(t) = \\text{true}$。如果 $I_i(t)$ 不满足任一严格不等式（即等于阈值），则保持当前状态。这创建了一个死区和时间上的持续性，以避免抖动。\n\n性能指标与抖动定义：定义模拟过程中的总状态切换次数为\n$$\nN_{\\text{toggles}} = \\sum_{t=1}^{N_{\\text{steps}}-1} \\sum_{i=0}^{N_{\\text{cells}}-1} \\mathbf{1}\\left[R_i(t) \\ne R_i(t-1)\\right],\n$$\n其中 $N_{\\text{steps}}$ 是离散时间步的总数，$\\mathbf{1}[\\cdot]$ 是指示函数（当条件为真时等于 $1$，为假时等于 $0$）。计算朴素方案的 $N_{\\text{toggles}}^{\\text{naive}}$ 和滞回方案的 $N_{\\text{toggles}}^{\\text{hyst}}$，然后对每个测试用例报告其差值 $D = N_{\\text{toggles}}^{\\text{naive}} - N_{\\text{toggles}}^{\\text{hyst}}$。\n\n从基本原理出发：该方案必须源于以下定义：由守恒律驱动的加密（大梯度意味着感兴趣的区域）、作为经过充分检验的数值近似的离散梯度定义，以及作为带有时间持续性的双阈值死区的滞回概念，该概念旨在抑制由小波动引起的快速切换。\n\n算法要求：\n1. 使用每个测试用例中指定的参数来计算代理密度。\n2. 在每个时间点 $t_k = k\\,\\Delta t$（其中整数 $k \\in \\{0,1,\\dots,N_{\\text{steps}}-1\\}$），计算 $\\rho(x_i, t_k)$ 和指示器 $I_i(t_k)$，然后独立地对两种方案应用决策逻辑。\n3. 在整个模拟过程中为每种方案计算切换次数，并为每个测试用例返回差值 $D$。\n\n角度单位不适用，最终答案中无需物理单位；所有量在构造上都是无量纲的。\n\n测试套件与参数：\n提供三个测试用例以探究不同方面：\n- 用例 $1$（带有轻度噪声的常规移动激波）：\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.20$, $v = 0.25$, $w = 0.020$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 0.5$, 随机种子 $s = 42$，\n  - 朴素方案阈值 $T = 14$，\n  - 滞回方案阈值和保持时间 $T_r = 16$, $T_d = 12$, $H = 3$。\n- 用例 $2$（接近等式且无噪声的边界条件）：\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.25$, $v = 0.30$, $w = 0.040$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 0.0$, 随机种子 $s = 7$，\n  - 朴素方案阈值 $T = 11$，\n  - 滞回方案阈值和保持时间 $T_r = 12$, $T_d = 10$, $H = 2$。\n- 用例 $3$（强噪声以诱发振荡的边缘情况）：\n  - $N_{\\text{cells}} = 64$, $N_{\\text{steps}} = 120$, $\\Delta t = 0.005$, $x_0 = 0.20$, $v = 0.25$, $w = 0.020$, $\\rho_L = 1.00$, $\\rho_R = 0.125$, $\\sigma = 3.0$, 随机种子 $s = 123$，\n  - 朴素方案阈值 $T = 14$，\n  - 滞回方案阈值和保持时间 $T_r = 16$, $T_d = 12$, $H = 4$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个方括号括起来的、按顺序排列的三个用例的逗号分隔的差值 $D$ 列表，格式如下：\n`[D_1, D_2, D_3]`",
            "solution": "该问题要求在一个一维移动激波剖面的背景下，设计、实现并比较两种用于自适应网格加密（AMR）的决策方案。目标是量化基于滞回的方案相较于简单的单一阈值方案，在减少加密状态“切换”或“抖动”方面的改进程度。\n\n### 基于原理的设计与模型构建\n\n该问题的基础在于守恒律的数值方法和控制理论的原理。在流体动力学模拟中，像激波这样的特征在物理量（如密度、压力）上表现出巨大的梯度。为了在不耗费过多计算成本的情况下精确解析这些特征，AMR技术在局部对网格进行加密。加密或解密的决策基于一个误差指示器，该指示器通常是局部解梯度的一种度量。\n\n1.  **代理物理模型**：我们使用一个连续的代理密度剖面 $\\rho(x,t)$ 来模拟移动的类激波特征。这避免了求解双曲型偏微分方程的复杂性，同时保留了移动陡峭梯度的核心特征。该函数定义为：\n    $$\n    \\rho(x,t) = \\rho_R + \\left(\\rho_L - \\rho_R\\right) S(x,t)\n    $$\n    其中 $\\rho_L$ 和 $\\rho_R$ 分别是激波左右两侧的密度。过渡过程由一个平滑的阶跃函数控制：\n    $$\n    S(x,t) = \\frac{1}{2}\\left(1 - \\tanh\\left(\\frac{x - x_s(t)}{w}\\right)\\right)\n    $$\n    这里，$x_s(t) = x_0 + v t$ 是激波中心随时间变化的位置，它以速度 $v$ 移动，$w$ 是一个控制梯度宽度或陡峭度的参数。双曲正切函数 $\\tanh$ 提供了一个平滑但急剧的过渡，模拟了在数值网格上解析的激波剖面。\n\n2.  **误差指示器**：任何AMR策略的核心都是误差指示器。数值分析中的一个基本原理是，局部截断误差与解的高阶导数有关。一个简单而有效的误差代理是一阶导数的大小，或其离散近似——梯度。我们基于密度梯度的有限差分近似来定义单元 $i$ 在时间 $t$ 的逐单元误差指示器 $I_i(t)$：\n    $$\n    I_i(t) = \\frac{\\left|\\rho(x_{i+1}, t) - \\rho(x_i, t)\\right|}{\\Delta x}\n    $$\n    其中 $x_i$ 是单元 $i$ 的中心，$\\Delta x$ 是均匀的单元宽度。该指示器在密度变化迅速的区域（即激波附近）会很大，而在解平滑的区域会很小。为了模拟真实模拟中固有的测量噪声和离散化效应，我们向 $I_i(t)$ 添加一个标准差为 $\\sigma$ 的零均值高斯噪声。\n\n3.  **AMR决策方案**：\n    -   **朴素方案**：最简单的方法是，如果一个单元的误差指示器超过一个预定的单一阈值 $T$，则对其进行加密。加密标志 $R_i(t)$ 由以下方式确定：\n        $$\n        R_i(t) = \\begin{cases} \\text{true}  \\text{if } I_i(t) \\geq T \\\\ \\text{false}  \\text{if } I_i(t)  T \\end{cases}\n        $$\n        虽然简单，但如果带噪声的指示器 $I_i(t)$ 在阈值 $T$ 附近波动，该方案极易出现“抖动”——即快速、反复的加密和解密。\n\n    -   **滞回方案**：为了抑制抖动，我们采用滞回，这是控制工程中的一个概念，它为系统引入了记忆。这通过两种机制实现：空间死区和时间保持。\n        -   **空间滞回（死区）**：我们使用两个阈值而不是一个：一个加密阈值 $T_r$ 和一个解密阈值 $T_d$，且 $T_d  T_r$。一个单元仅在其指示器*严格超过* $T_r$ 时才被标记为加密。仅当其指示器*降至* $T_d$ 以下时，才被标记为解密。对于指示器 $I_i(t)$ 在“死区” $[T_d, T_r]$ 内的任何值，单元的加密状态不发生改变。这防止了因指示器在该带内的微小波动而引起的切换。\n        -   **时间滞回（保持时间）**：引入一个保持时间 $H$（一个整数时间步数）。一旦一个单元被加密，它将被强制保持在加密状态至少 $H$ 个时间步，无论指示器的值如何。这强制了时间上的稳定性，并防止系统因指示器的瞬时下降而立即撤销加密决策。\n\n4.  **算法实现与评估**：\n    模拟通过离散的时间步 $t_k = k\\,\\Delta t$ 进行。在每一步，算法执行以下操作：\n    -   计算所有单元中心 $x_i$ 处的激波位置 $x_s(t_k)$ 和密度值 $\\rho(x_i, t_k)$。\n    -   计算所有单元的误差指示器 $I_i(t_k)$，添加指定的噪声，并将负值截断为零。\n    -   独立地应用朴素方案和滞回方案的逻辑，来确定每个单元的加密状态 $R_i(t_k)$。对于滞回方案，这涉及根据前一状态、当前指示器值以及定义的阈值（$T_r, T_d, H$）来更新状态和保持计数器。\n    -   每种方案的性能通过整个模拟过程中的总状态切换次数 $N_{\\text{toggles}}$ 来衡量。如果在时间 $t_k$ 单元 $i$ 的状态满足 $R_i(t_k) \\ne R_i(t_{k-1})$，则计为一次切换。最终的度量指标 $D = N_{\\text{toggles}}^{\\text{naive}} - N_{\\text{toggles}}^{\\text{hyst}}$ 直接量化了滞回方案所带来的改进。正值的 $D$ 表示滞回成功减少了状态改变的次数。\n\n实现将使用 NumPy 进行矢量化以提高效率，在每个时间步同时为所有单元执行计算。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: General moving shock with mild noise\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.20, \"v\": 0.25,\n            \"w\": 0.020, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 0.5,\n            \"seed\": 42, \"T\": 14, \"Tr\": 16, \"Td\": 12, \"H\": 3\n        },\n        # Case 2: Boundary condition with near-equality and no noise\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.25, \"v\": 0.30,\n            \"w\": 0.040, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 0.0,\n            \"seed\": 7, \"T\": 11, \"Tr\": 12, \"Td\": 10, \"H\": 2\n        },\n        # Case 3: Edge case with strong noise to induce oscillations\n        {\n            \"N_cells\": 64, \"N_steps\": 120, \"dt\": 0.005, \"x0\": 0.20, \"v\": 0.25,\n            \"w\": 0.020, \"rho_L\": 1.00, \"rho_R\": 0.125, \"sigma\": 3.0,\n            \"seed\": 123, \"T\": 14, \"Tr\": 16, \"Td\": 12, \"H\": 4\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        diff = run_simulation_case(case)\n        results.append(diff)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_simulation_case(params):\n    \"\"\"\n    Runs the simulation for a single test case and returns the toggle difference D.\n    \"\"\"\n    # Unpack parameters\n    N_cells = params[\"N_cells\"]\n    N_steps = params[\"N_steps\"]\n    dt = params[\"dt\"]\n    x0 = params[\"x0\"]\n    v = params[\"v\"]\n    w = params[\"w\"]\n    rho_L = params[\"rho_L\"]\n    rho_R = params[\"rho_R\"]\n    sigma = params[\"sigma\"]\n    seed = params[\"seed\"]\n    T = params[\"T\"]\n    Tr = params[\"Tr\"]\n    Td = params[\"Td\"]\n    H = params[\"H\"]\n\n    # Setup grid and time\n    dx = 1.0 / N_cells\n    x_centers = (np.arange(N_cells) + 0.5) * dx\n    times = np.arange(N_steps) * dt\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # State history arrays\n    R_naive_hist = np.zeros((N_steps, N_cells), dtype=bool)\n    R_hyst_hist = np.zeros((N_steps, N_cells), dtype=bool)\n    h_hyst_hist = np.zeros((N_steps, N_cells), dtype=int)\n\n    # Time-stepping loop\n    for k, t in enumerate(times):\n        # 1. Compute surrogate density and error indicator\n        x_s = x0 + v * t\n        arg = (x_centers - x_s) / w\n        S_xt = 0.5 * (1 - np.tanh(arg))\n        rho_xt = rho_R + (rho_L - rho_R) * S_xt\n        \n        # Calculate indicators I_i for i = 0 to N_cells-2\n        indicators_part = np.abs(rho_xt[1:] - rho_xt[:-1]) / dx\n        \n        # Assemble N_cells indicators, setting I_{N-1} = I_{N-2}\n        indicators = np.append(indicators_part, indicators_part[-1])\n        \n        # Add noise and clip at 0\n        noise = rng.normal(loc=0.0, scale=sigma, size=N_cells)\n        indicators_noisy = np.maximum(0, indicators + noise)\n\n        # 2. Update Naive Scheme State\n        R_naive_hist[k, :] = (indicators_noisy >= T)\n\n        # 3. Update Hysteresis Scheme State\n        if k == 0:\n            R_hyst_prev = np.zeros(N_cells, dtype=bool)\n            h_hyst_prev = np.zeros(N_cells, dtype=int)\n        else:\n            R_hyst_prev = R_hyst_hist[k - 1, :]\n            h_hyst_prev = h_hyst_hist[k - 1, :]\n\n        R_hyst_curr = np.copy(R_hyst_prev)\n        h_hyst_curr = np.copy(h_hyst_prev)\n        \n        # Logic for cells that were previously NOT refined\n        was_false_mask = ~R_hyst_prev\n        to_refine_mask = was_false_mask  (indicators_noisy > Tr)\n        R_hyst_curr[to_refine_mask] = True\n        h_hyst_curr[to_refine_mask] = H\n\n        # Logic for cells that were previously refined\n        was_true_mask = R_hyst_prev\n        \n        # Decrement hold counter if it's positive\n        holding_mask = was_true_mask  (h_hyst_prev > 0)\n        h_hyst_curr[holding_mask] = h_hyst_prev[holding_mask] - 1\n        \n        # Check for derefinement if hold counter is zero\n        hold_expired_mask = was_true_mask  (h_hyst_prev == 0)\n        to_derefine_mask = hold_expired_mask  (indicators_noisy  Td)\n        R_hyst_curr[to_derefine_mask] = False\n        \n        R_hyst_hist[k, :] = R_hyst_curr\n        h_hyst_hist[k, :] = h_hyst_curr\n\n    # 4. Calculate Toggles\n    # Sum over all cells and time steps from k=1 to N_steps-1\n    toggles_naive = np.sum(R_naive_hist[1:, :] != R_naive_hist[:-1, :])\n    toggles_hyst = np.sum(R_hyst_hist[1:, :] != R_hyst_hist[:-1, :])\n\n    # 5. Return difference\n    return toggles_naive - toggles_hyst\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}