{
    "hands_on_practices": [
        {
            "introduction": "Many phenomena in multiscale analysis, from material science to financial modeling, are characterized by rare but impactful events that lie far in the tails of a probability distribution. This exercise  provides a hands-on guide to a core concept for describing such \"heavy-tailed\" distributions: regular variation. By working through the formal definition and applying it to a concrete Pareto-type function, you will learn to identify the tail index $\\alpha$, a crucial parameter that governs the power-law scaling of extreme fluctuations.",
            "id": "3797810",
            "problem": "Consider a family of heavy-tailed random variables used in multiscale modeling of aggregate fluctuations, where large deviations across scales are governed by power-law decay modulated by slowly varying corrections. In this context, one often studies the survival function tail, defined as $x \\mapsto \\mathbb{P}(X > x)$, and its scaling behavior under dilation. \n\n(a) Provide a mathematically precise definition of a regularly varying tail at infinity for a distribution function $F$ of a real-valued random variable $X$, expressed in terms of the survival function $x \\mapsto \\overline{F}(x) = 1 - F(x)$, and its representation via a slowly varying function.\n\n(b) Consider the following Pareto-type survival function tail for $x \\geq \\exp(\\exp(1))$:\n$$\n\\overline{F}(x) \\;=\\; x^{-7/3} \\, (\\ln x)^{\\delta} \\, (\\ln\\!\\ln x)^{\\eta} \\left(1 + \\frac{1}{\\ln x}\\right),\n$$\nwhere $\\delta \\in \\mathbb{R}$ and $\\eta \\in \\mathbb{R}$ are fixed constants. Using asymptotic equivalence arguments and Karamata’s characterization of regular variation, determine the tail index $\\alpha$ associated with this survival function, defined by the power-law exponent governing the scale transformation of the tail.\n\nYour final answer must be a single real number (no units required). No rounding is necessary; provide the exact value.",
            "solution": "The user wants me to solve a two-part problem concerning regularly varying functions and tail indices from probability theory. I will first validate the problem and then provide a detailed solution.\n\n### Step 1: Extract Givens\n- **(a)** The problem asks for a mathematically precise definition of a regularly varying tail at infinity for a distribution function $F$, using the survival function $\\overline{F}(x) = 1 - F(x)$ and a slowly varying function.\n- **(b)** A specific Pareto-type survival function is given for $x \\geq \\exp(\\exp(1))$:\n$$\n\\overline{F}(x) \\;=\\; x^{-7/3} \\, (\\ln x)^{\\delta} \\, (\\ln\\!\\ln x)^{\\eta} \\left(1 + \\frac{1}{\\ln x}\\right)\n$$\n- The parameters $\\delta$ and $\\eta$ are fixed real constants, $\\delta, \\eta \\in \\mathbb{R}$.\n- The task is to determine the tail index $\\alpha$ associated with this survival function.\n- The tail index $\\alpha$ is defined as the power-law exponent governing the scale transformation of the tail.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound.\n- **Scientific Grounding**: The concepts presented—regular variation, slow variation, survival functions, and tail indices—are standard and central to the theory of heavy-tailed distributions in probability and statistics, particularly in Extreme Value Theory and its applications in fields like finance, hydrology, and physics. Karamata's theory of regular variation provides the rigorous foundation for these concepts.\n- **Well-Posedness**: The problem is well-posed. Part (a) requests a standard definition from the field. Part (b) provides an explicit function and asks for a specific, uniquely determinable parameter ($\\alpha$) based on its asymptotic properties. The condition $x \\geq \\exp(\\exp(1))$ ensures that $\\ln(x) > 1$ and $\\ln(\\ln(x)) > 0$, so all terms in the function are well-defined and real-valued.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free from ambiguity or subjective elements.\n- **Completeness and Consistency**: All necessary information is provided. The form of the function $\\overline{F}(x)$ is explicit, and the definition of the tail index is linked to the standard theory of regular variation. There are no contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will proceed to provide a complete solution.\n\n***\n\n### Part (a): Definition of a Regularly Varying Tail\n\nA function $L: [a, \\infty) \\to (0, \\infty)$ for some $a>0$ is said to be **slowly varying at infinity** if for any constant $t > 0$, it satisfies the condition:\n$$\n\\lim_{x \\to \\infty} \\frac{L(tx)}{L(x)} = 1\n$$\nA function $g: [a, \\infty) \\to (0, \\infty)$ is said to be **regularly varying at infinity with index** $\\rho \\in \\mathbb{R}$ if for any constant $t > 0$, it satisfies the condition:\n$$\n\\lim_{x \\to \\infty} \\frac{g(tx)}{g(x)} = t^{\\rho}\n$$\nBy Karamata's Characterization Theorem, a function $g$ is regularly varying with index $\\rho$ if and only if it can be represented in the form $g(x) = x^{\\rho} L(x)$, where $L(x)$ is a slowly varying function.\n\nA real-valued random variable $X$ with distribution function $F$ is said to have a **regularly varying tail at infinity** if its survival function, $\\overline{F}(x) = \\mathbb{P}(X > x)$, is a regularly varying function at infinity with some index $-\\alpha$, where $\\alpha > 0$. The constant $\\alpha$ is called the **tail index** of the distribution.\n\nTherefore, the mathematically precise definition is: The distribution function $F$ has a regularly varying tail with tail index $\\alpha > 0$ if its survival function can be written in the form:\n$$\n\\overline{F}(x) = x^{-\\alpha} L(x)\n$$\nwhere $L(x)$ is a slowly varying function at infinity.\n\n### Part (b): Determination of the Tail Index $\\alpha$\n\nWe are given the survival function for $x \\geq \\exp(\\exp(1))$:\n$$\n\\overline{F}(x) = x^{-7/3} (\\ln x)^{\\delta} (\\ln\\ln x)^{\\eta} \\left(1 + \\frac{1}{\\ln x}\\right)\n$$\nOur goal is to determine the tail index $\\alpha$. To do this, we must express $\\overline{F}(x)$ in the canonical form $\\overline{F}(x) = x^{-\\alpha} L(x)$, where $L(x)$ is a slowly varying function.\n\nBy direct inspection, we can decompose the given function as follows:\n$$\n\\overline{F}(x) = x^{-7/3} \\cdot \\left[ (\\ln x)^{\\delta} (\\ln\\ln x)^{\\eta} \\left(1 + \\frac{1}{\\ln x}\\right) \\right]\n$$\nThis suggests that the tail index $\\alpha$ might be $7/3$. To confirm this, we must rigorously verify that the term in the brackets is a slowly varying function. Let us define:\n$$\nL(x) = (\\ln x)^{\\delta} (\\ln\\ln x)^{\\eta} \\left(1 + \\frac{1}{\\ln x}\\right)\n$$\nWe rely on the following established properties of slowly varying functions:\n$1$. If $L_1(x)$ and $L_2(x)$ are slowly varying, then their product $L_1(x)L_2(x)$ is also slowly varying.\n$2$. For any real number $p$, if $L(x)$ is slowly varying, then $(L(x))^p$ is also slowly varying.\n$3$. Any function that converges to a positive constant as $x \\to \\infty$ is slowly varying.\n$4$. The function $\\ln x$ is slowly varying.\n\nLet us analyze the components of $L(x)$:\n- **Component 1**: Consider the function $f_1(x) = \\ln x$. To show it is slowly varying, we evaluate the limit for any $t>0$:\n  $$\n  \\lim_{x \\to \\infty} \\frac{\\ln(tx)}{\\ln x} = \\lim_{x \\to \\infty} \\frac{\\ln t + \\ln x}{\\ln x} = \\lim_{x \\to \\infty} \\left( \\frac{\\ln t}{\\ln x} + 1 \\right) = 0 + 1 = 1\n  $$\n  Since $\\ln x$ is slowly varying, by property $2$, the function $L_1(x) = (\\ln x)^{\\delta}$ is also slowly varying for any $\\delta \\in \\mathbb{R}$.\n\n- **Component 2**: Consider the function $f_2(x) = \\ln(\\ln x)$. To show it is slowly varying, we evaluate the limit for any $t>0$:\n  $$\n  \\lim_{x \\to \\infty} \\frac{\\ln(\\ln(tx))}{\\ln(\\ln x)} = \\lim_{x \\to \\infty} \\frac{\\ln(\\ln t + \\ln x)}{\\ln(\\ln x)} = \\lim_{x \\to \\infty} \\frac{\\ln\\left(\\ln x \\left(1 + \\frac{\\ln t}{\\ln x}\\right)\\right)}{\\ln(\\ln x)}\n  $$\n  $$\n  = \\lim_{x \\to \\infty} \\frac{\\ln(\\ln x) + \\ln\\left(1 + \\frac{\\ln t}{\\ln x}\\right)}{\\ln(\\ln x)} = \\lim_{x \\to \\infty} \\left(1 + \\frac{\\ln\\left(1 + \\frac{\\ln t}{\\ln x}\\right)}{\\ln(\\ln x)}\\right)\n  $$\n  As $x \\to \\infty$, $\\ln x \\to \\infty$, so $\\frac{\\ln t}{\\ln x} \\to 0$. This implies $\\ln\\left(1 + \\frac{\\ln t}{\\ln x}\\right) \\to \\ln(1) = 0$. The denominator $\\ln(\\ln x) \\to \\infty$. Thus, the fraction goes to $0$, and the total limit is $1$. Since $\\ln(\\ln x)$ is slowly varying, by property $2$, the function $L_2(x) = (\\ln(\\ln x))^{\\eta}$ is also slowly varying for any $\\eta \\in \\mathbb{R}$.\n\n- **Component 3**: Consider the function $L_3(x) = 1 + \\frac{1}{\\ln x}$. We evaluate its limit as $x \\to \\infty$:\n  $$\n  \\lim_{x \\to \\infty} \\left(1 + \\frac{1}{\\ln x}\\right) = 1+0 = 1\n  $$\n  Since the function converges to a positive constant ($1$), by property $3$, it is slowly varying.\n\nSince $L(x)$ is the product of three slowly varying functions, $L(x) = L_1(x) L_2(x) L_3(x)$, it is itself a slowly varying function by property $1$.\n\nWe have successfully expressed the survival function in the form $\\overline{F}(x) = x^{-\\alpha} L(x)$, where $L(x)$ is a slowly varying function. By comparing\n$$\n\\overline{F}(x) = x^{-7/3} L(x)\n$$\nwith the general form $\\overline{F}(x) = x^{-\\alpha} L(x)$, we can directly identify the tail index $\\alpha$.\n\nThe tail index is $\\alpha = 7/3$.",
            "answer": "$$\\boxed{\\frac{7}{3}}$$"
        },
        {
            "introduction": "In multiscale systems, macroscopic behavior often emerges from the aggregation of countless microscopic components. A central task is to estimate the probability of rare events where the aggregate quantity deviates significantly from its mean. This practice  guides you through a first-principles derivation of Chernoff bounds, a foundational tool in large deviation theory. You will learn to optimize the bound using the moment generating function, yielding a powerful technique to analyze the tail probabilities of sums of random variables, which is crucial for reliability and risk assessment in complex systems.",
            "id": "3797860",
            "problem": "Consider a multiscale reliability model in which a macro-level failure occurs when sufficiently many micro-level components fail. Let $\\{X_{i}\\}_{i=1}^{N}$ be independent and identically distributed (i.i.d.) Bernoulli random variables with parameter $p \\in (0,1)$, representing micro-level failure indicators across $N$ statistically homogeneous microdomains. The macro-level failure count is $S = \\sum_{i=1}^{N} X_{i}$. You are asked to bound from first principles the probability of a macro-scale exceedance event using the method of exponential moments and then optimize the bound.\n\nStarting only from the definition of the moment generating function (MGF), $\\mathbb{E}[\\exp(\\lambda X)]$, and Markov’s inequality, derive the tightest exponential upper bound of the form\n$$\n\\mathbb{P}(S \\geq a) \\leq \\inf_{\\lambda > 0} \\exp\\big(-\\lambda a\\big) \\,\\mathbb{E}\\big[\\exp(\\lambda S)\\big]\n$$\nby optimizing the MGF tilt parameter $\\lambda$ over $\\lambda > 0$. Specialize your derivation to the i.i.d. Bernoulli case and express the optimized bound in closed form.\n\nThen evaluate this bound numerically in the following scientifically realistic setting for multiscale modeling:\n- Number of microdomains: $N = 5000$.\n- Micro-level failure probability: $p = 0.003$.\n- Exceedance threshold: $a = 30$.\n\nRound your final numerical bound to four significant figures, and express it as a unitless decimal (do not use a percentage sign).",
            "solution": "The problem requires the derivation of the tightest exponential upper bound for the probability $\\mathbb{P}(S \\geq a)$, where $S$ is the sum of $N$ independent and identically distributed (i.i.d.) Bernoulli random variables, $S = \\sum_{i=1}^{N} X_{i}$, with $X_i \\sim \\text{Bernoulli}(p)$. The derivation must start from first principles, namely Markov's inequality and the definition of the moment generating function (MGF).\n\nFirst, we state Markov's inequality. For any non-negative random variable $Y$ and any constant $c > 0$, the inequality is:\n$$\n\\mathbb{P}(Y \\geq c) \\leq \\frac{\\mathbb{E}[Y]}{c}\n$$\nThe event of interest is $\\{S \\geq a\\}$. For any parameter $\\lambda > 0$, this event is equivalent to the event $\\{\\lambda S \\geq \\lambda a\\}$, which in turn is equivalent to $\\{\\exp(\\lambda S) \\geq \\exp(\\lambda a)\\}$ because the exponential function is strictly increasing.\n\nLet us define a new non-negative random variable $Y = \\exp(\\lambda S)$. We can apply Markov's inequality to $Y$ with the constant $c = \\exp(\\lambda a)$:\n$$\n\\mathbb{P}(\\exp(\\lambda S) \\geq \\exp(\\lambda a)) \\leq \\frac{\\mathbb{E}[\\exp(\\lambda S)]}{\\exp(\\lambda a)}\n$$\nRewriting this inequality gives us an upper bound for $\\mathbb{P}(S \\geq a)$:\n$$\n\\mathbb{P}(S \\geq a) \\leq \\exp(-\\lambda a) \\mathbb{E}[\\exp(\\lambda S)]\n$$\nThis inequality holds for any choice of $\\lambda > 0$. To obtain the tightest possible bound of this form, we must minimize the right-hand side with respect to $\\lambda$. This leads to the Chernoff bound:\n$$\n\\mathbb{P}(S \\geq a) \\leq \\inf_{\\lambda > 0} \\left( \\exp(-\\lambda a) \\mathbb{E}[\\exp(\\lambda S)] \\right)\n$$\nThe term $\\mathbb{E}[\\exp(\\lambda S)]$ is the moment generating function (MGF) of the random variable $S$, denoted as $M_S(\\lambda)$. Since $S = \\sum_{i=1}^{N} X_{i}$ and the $X_i$ are i.i.d., the MGF of the sum is the product of the individual MGFs:\n$$\nM_S(\\lambda) = \\mathbb{E}\\left[\\exp\\left(\\lambda \\sum_{i=1}^{N} X_i\\right)\\right] = \\mathbb{E}\\left[\\prod_{i=1}^{N} \\exp(\\lambda X_i)\\right] = \\prod_{i=1}^{N} \\mathbb{E}[\\exp(\\lambda X_i)] = \\left(M_X(\\lambda)\\right)^N\n$$\nwhere $M_X(\\lambda)$ is the MGF of a single Bernoulli random variable $X \\sim \\text{Bernoulli}(p)$. We compute $M_X(\\lambda)$ from its definition:\n$$\nM_X(\\lambda) = \\mathbb{E}[\\exp(\\lambda X)] = \\mathbb{P}(X=0)\\exp(\\lambda \\cdot 0) + \\mathbb{P}(X=1)\\exp(\\lambda \\cdot 1) = (1-p) \\cdot 1 + p \\cdot \\exp(\\lambda) = 1 - p + p\\exp(\\lambda)\n$$\nTherefore, the MGF of $S$ is:\n$$\nM_S(\\lambda) = (1 - p + p\\exp(\\lambda))^N\n$$\nSubstituting this back into the bound expression, we need to find:\n$$\n\\inf_{\\lambda > 0} \\exp(-\\lambda a) (1 - p + p\\exp(\\lambda))^N\n$$\nTo find the infimum, we minimize the function $g(\\lambda) = \\exp(-\\lambda a) (1 - p + p\\exp(\\lambda))^N$. It is easier to minimize its natural logarithm, $h(\\lambda) = \\ln(g(\\lambda))$:\n$$\nh(\\lambda) = -\\lambda a + N \\ln(1 - p + p\\exp(\\lambda))\n$$\nWe find the critical point by setting the first derivative with respect to $\\lambda$ to zero:\n$$\n\\frac{dh}{d\\lambda} = -a + N \\frac{p\\exp(\\lambda)}{1 - p + p\\exp(\\lambda)} = 0\n$$\nSolving for $\\exp(\\lambda)$:\n$$\na = N \\frac{p\\exp(\\lambda)}{1 - p + p\\exp(\\lambda)} \\implies a(1 - p + p\\exp(\\lambda)) = Np\\exp(\\lambda)\n$$\n$$\na(1-p) = \\exp(\\lambda)(Np - ap) = p\\exp(\\lambda)(N-a)\n$$\nThis gives the optimal value for $\\exp(\\lambda)$:\n$$\n\\exp(\\lambda^*) = \\frac{a(1-p)}{p(N-a)}\n$$\nThe optimal parameter is thus $\\lambda^* = \\ln\\left(\\frac{a(1-p)}{p(N-a)}\\right)$. For $\\lambda^*$ to be positive, we require its argument to be greater than $1$, which implies $a(1-p) > p(N-a) \\iff a > Np$. This means the exceedance threshold $a$ must be greater than the mean of $S$, which is the regime where large deviation bounds are meaningful. The second derivative of $h(\\lambda)$ is $h''(\\lambda) = N \\frac{p(1-p)\\exp(\\lambda)}{(1-p+p\\exp(\\lambda))^2} > 0$ for $p \\in (0,1)$, confirming that $\\lambda^*$ corresponds to a minimum.\n\nNow, we substitute $\\exp(\\lambda^*)$ back into the bound expression $g(\\lambda)$. The bound is $g(\\lambda^*) = (\\exp(\\lambda^*))^{-a} (1 - p + p\\exp(\\lambda^*))^N$.\nThe first term is:\n$$\n(\\exp(\\lambda^*))^{-a} = \\left(\\frac{a(1-p)}{p(N-a)}\\right)^{-a} = \\left(\\frac{p(N-a)}{a(1-p)}\\right)^a\n$$\nThe second term is:\n$$\n(1 - p + p\\exp(\\lambda^*))^N = \\left(1 - p + p\\frac{a(1-p)}{p(N-a)}\\right)^N = \\left(1 - p + \\frac{a(1-p)}{N-a}\\right)^N = \\left(\\frac{(1-p)(N-a) + a(1-p)}{N-a}\\right)^N = \\left(\\frac{N(1-p)}{N-a}\\right)^N\n$$\nCombining these terms, the optimized bound is:\n$$\n\\mathbb{P}(S \\geq a) \\leq \\left(\\frac{p(N-a)}{a(1-p)}\\right)^a \\left(\\frac{N(1-p)}{N-a}\\right)^N = \\frac{p^a (N-a)^a}{a^a (1-p)^a} \\frac{N^N (1-p)^N}{(N-a)^N} = \\left(\\frac{Np}{a}\\right)^a \\left(\\frac{N(1-p)}{N-a}\\right)^{N-a}\n$$\nThis is the closed-form expression for the optimized Chernoff bound. This expression is equivalent to $\\exp(-N D_{KL}(a/N \\| p))$, where $D_{KL}(q \\| p)$ is the Kullback-Leibler divergence between two Bernoulli distributions with parameters $q=a/N$ and $p$.\n\nNow, we evaluate this bound for the given numerical values:\n- $N = 5000$\n- $p = 0.003$\n- $a = 30$\n\nFirst, we calculate the necessary components for the closed-form expression:\n- Mean number of failures: $\\mathbb{E}[S] = Np = 5000 \\times 0.003 = 15$. The condition $a > Np$ is satisfied ($30 > 15$).\n- $N-a = 5000 - 30 = 4970$.\n- $1-p = 1 - 0.003 = 0.997$.\n\nThe bound is given by:\n$$\nB = \\left(\\frac{15}{30}\\right)^{30} \\left(\\frac{5000 \\times 0.997}{4970}\\right)^{4970} = (0.5)^{30} \\left(\\frac{4985}{4970}\\right)^{4970}\n$$\nTo compute this value, it is numerically more stable to work with the logarithm:\n$$\n\\ln(B) = 30 \\ln(0.5) + 4970 \\ln\\left(\\frac{4985}{4970}\\right)\n$$\nUsing a calculator for high-precision values:\n$$\n\\ln(0.5) \\approx -0.69314718\n$$\n$$\n\\ln\\left(\\frac{4985}{4970}\\right) = \\ln(1.00301810865...) \\approx 0.0030135800\n$$\nSubstituting these values:\n$$\n\\ln(B) \\approx 30 \\times (-0.69314718) + 4970 \\times (0.0030135800)\n$$\n$$\n\\ln(B) \\approx -20.7944154 + 14.9774926\n$$\n$$\n\\ln(B) \\approx -5.8169228\n$$\nThe bound $B$ is then the exponential of this value:\n$$\nB = \\exp(-5.8169228) \\approx 0.00297687\n$$\nRounding the final numerical bound to four significant figures, we get $0.002977$.",
            "answer": "$$\n\\boxed{0.002977}\n$$"
        },
        {
            "introduction": "Beyond analyzing distributions, a key skill in multiscale modeling is generating samples from them, especially for complex interacting systems described by Gibbs distributions. Standard simulation methods like Markov Chain Monte Carlo often only produce approximate samples. This practice  introduces Coupling From The Past (CFTP), an elegant algorithm capable of generating a *perfect* sample from a model's true stationary distribution. By applying CFTP to the classic Ising model, you will gain insight into how abstract probabilistic concepts like monotonicity and coupling can be harnessed to create provably exact computational tools.",
            "id": "3797859",
            "problem": "Consider the one-dimensional ferromagnetic Ising model on a chain of length $n$ with open boundary conditions. A configuration is a vector $s = (s_1, s_2, \\dots, s_n)$ with $s_i \\in \\{-1, +1\\}$ for all $i \\in \\{1, 2, \\dots, n\\}$. The Gibbs distribution at inverse temperature $\\beta > 0$ and external field $h \\in \\mathbb{R}$ assigns probability\n$$\n\\pi(s) \\propto \\exp\\left(\\beta \\sum_{i=1}^{n-1} s_i s_{i+1} + \\beta h \\sum_{i=1}^n s_i\\right).\n$$\nDefine the single-site heat-bath dynamics as a discrete-time Markov chain: at each time step, a site $i \\in \\{1,2,\\dots,n\\}$ is chosen uniformly at random and $s_i$ is resampled from its conditional distribution given its neighbors. For open boundaries, the local field at site $i$ is \n$$\n\\ell_i(s) = \\begin{cases}\ns_{i-1} + s_{i+1} + h & \\text{if } 1 < i < n, \\\\\ns_{2} + h & \\text{if } i = 1, \\\\\ns_{n-1} + h & \\text{if } i = n,\n\\end{cases}\n$$\nand the conditional probability of setting $s_i = +1$ is\n$$\np_i(s) = \\frac{1}{1 + \\exp\\left(-2\\beta \\ell_i(s)\\right)}.\n$$\nThis chain is attractive (monotone) under the coordinate-wise partial order on configurations and admits a monotone grand coupling.\n\nTask: Apply Coupling From The Past (CFTP) to obtain a perfect sample from the stationary Gibbs distribution $\\pi$ for given $(n, \\beta, h)$. Use the following monotone grand coupling: at each update time, a common site index and a common uniform random variable $u \\in (0,1)$ are shared across all chains, and each chain updates $s_i$ to $+1$ if $u < p_i(s)$ and to $-1$ otherwise. Initialize two extremal configurations $s^{\\mathrm{min}} = (-1, -1, \\dots, -1)$ and $s^{\\mathrm{max}} = (+1, +1, \\dots, +1)$ at a sufficiently distant past time $-T$, and evolve them forward to time $0$ using a common update stream of site indices and uniforms. Double the time horizon $T$ until the two extremal chains coalesce at time $0$. Return the common configuration at time $0$ as a perfect sample from $\\pi$.\n\nCompute the magnetization per site\n$$\nm(s) = \\frac{1}{n} \\sum_{i=1}^n s_i\n$$\nfor the perfect sample $s$ produced by CFTP.\n\nTo ensure reproducibility, the program must use a fixed pseudo-random seed equal to $123456789$.\n\nYou must implement the above procedure and produce outputs for the following test suite of parameter values:\n- Case $1$: $(n, \\beta, h) = (10, 0.2, 0.0)$.\n- Case $2$: $(n, \\beta, h) = (10, 1.0, 0.3)$.\n- Case $3$: $(n, \\beta, h) = (20, 0.8, 0.0)$.\n- Case $4$: $(n, \\beta, h) = (5, 2.0, 0.0)$.\n\nFor each case, compute the magnetization per site $m(s)$ of the perfect sample and round it to $3$ decimal places. The final program output must be a single line containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, for example, $[m_1, m_2, m_3, m_4]$.\n\nNo physical units are involved. All computations must use the angle-neutral scalar quantities as defined. Your implementation must be entirely deterministic given the specified random seed and must not require any external input beyond the parameters specified above.",
            "solution": "The user has requested to solve a problem in statistical physics, which requires generating a perfect sample from the Gibbs distribution of a one-dimensional Ising model using the Coupling From The Past (CFTP) algorithm.\n\n### Problem Formulation and Validation\nThe problem is well-defined and scientifically sound. It describes the one-dimensional ferromagnetic Ising model on a chain of length $n$ with open boundary conditions. A state, or configuration, is a vector $s = (s_1, \\dots, s_n)$ where each spin $s_i$ can be either $-1$ or $+1$. The stationary probability of a configuration is given by the Gibbs distribution:\n$$\n\\pi(s) \\propto \\exp\\left(\\beta \\sum_{i=1}^{n-1} s_i s_{i+1} + \\beta h \\sum_{i=1}^n s_i\\right)\n$$\nwhere $\\beta > 0$ is the inverse temperature and $h$ is the external magnetic field.\n\nThe dynamics are governed by a single-site heat-bath (Glauber) update rule. At each discrete time step, a site $i$ is chosen uniformly at random and its spin $s_i$ is resampled from the conditional distribution $\\pi(s_i | s_{-i})$, where $s_{-i}$ denotes all spins other than $s_i$. The probability of resampling $s_i$ to $+1$ is determined by the local field $\\ell_i(s)$:\n$$\np_i(s) = P(s_i' = +1 | s) = \\frac{1}{1 + \\exp(-2\\beta \\ell_i(s))}\n$$\nThe local field $\\ell_i(s)$ for open boundary conditions is given by:\n$$\n\\ell_i(s) = \\begin{cases}\ns_{2} + h & \\text{if } i = 1, \\\\\ns_{i-1} + s_{i+1} + h & \\text{if } 1 < i < n, \\\\\ns_{n-1} + h & \\text{if } i = n.\n\\end{cases}\n$$\nThe problem is valid as all definitions are standard in statistical mechanics and computational statistics, and all necessary parameters for a reproducible solution are provided.\n\n### The Coupling From The Past (CFTP) Algorithm\n\nThe objective is to draw a single sample $s$ exactly from the stationary distribution $\\pi(s)$, rather than an approximate sample from a long run of a Markov chain. The CFTP algorithm achieves this. The key insight is that if we run the Markov chain from a time $-T$ in the sufficiently distant past, the state at time $0$ will be independent of the starting state at time $-T$.\n\nThe specific implementation here relies on the monotonicity of the Ising model dynamics. The state space of configurations can be partially ordered: $s \\le s'$ if $s_i \\le s'_i$ for all $i \\in \\{1, \\dots, n\\}$. The single-site heat-bath update function $\\Phi(s, i, u)$, which produces a new configuration by updating spin $s_i$ using a random number $u \\in (0,1)$, is monotone. This means if $s \\le s'$, then $\\Phi(s, i, u) \\le \\Phi(s', i, u)$ for any common site $i$ and random number $u$.\n\nThis monotonicity allows for a powerful simplification of the CFTP algorithm. Instead of tracking the evolution of all $2^n$ possible starting states, we only need to track the two extremal states:\n- $s^{\\mathrm{min}} = (-1, -1, \\dots, -1)$, the minimal configuration.\n- $s^{\\mathrm{max}} = (+1, +1, \\dots, +1)$, the maximal configuration.\n\nSince for any configuration $s$, we have $s^{\\mathrm{min}} \\le s \\le s^{\\mathrm{max}}$, the monotonicity of the dynamics implies that after any number of common update steps, the evolved states will also maintain this ordering: $s^{\\mathrm{min}}(t) \\le s(t) \\le s^{\\mathrm{max}}(t)$. If we can find a time horizon $T$ such that the extremal chains coalesce, i.e., $s^{\\mathrm{min}}(0) = s^{\\mathrm{max}}(0)$, then it must be that all intermediate chains have also coalesced to this same configuration. This common configuration is a perfect sample from $\\pi$.\n\nThe algorithm proceeds as follows:\n1.  Initialize a time horizon, e.g., $T=1$.\n2.  Generate a sequence of $T$ random events, where each event is a pair $(i, u)$ consisting of a uniformly chosen site index $i \\in \\{1, \\dots, n\\}$ and a uniform random number $u \\in (0,1)$. This sequence represents the stochasticity for the time interval $[-T, -1]$.\n3.  Initialize the two extremal configurations, $s^{\\mathrm{min}}(-T) = (-1, \\dots, -1)$ and $s^{\\mathrm{max}}(-T) = (+1, \\dots, +1)$.\n4.  Evolve both chains forward from time $-T$ to $0$ by applying the same sequence of random updates. At each time step $t \\in \\{-T, \\dots, -1\\}$, update both $s^{\\mathrm{min}}(t)$ and $s^{\\mathrm{max}}(t)$ using the same random event $(i, u)$ to get $s^{\\mathrm{min}}(t+1)$ and $s^{\\mathrm{max}}(t+1)$.\n5.  At time $0$, check for coalescence: if $s^{\\mathrm{min}}(0) = s^{\\mathrm{max}}(0)$.\n    - If they have coalesced, the common configuration is the desired perfect sample from $\\pi$. The algorithm terminates successfully.\n    - If they have not coalesced, the time horizon $T$ was not long enough. Double the horizon to $2T$. The previously generated sequence of $T$ random events is retained for the time interval $[-T, -1]$, and a new sequence of $T$ random events is generated for the new past interval $[-2T, -T)$. The process repeats from step 3 with the new horizon $2T$ and the extended random sequence.\n\nThis procedure is guaranteed to terminate with probability one for a finite state space.\n\n### Implementation and Calculation\n\nFor each parameter set $(n, \\beta, h)$, the CFTP algorithm will be executed as described. A pseudo-random number generator initialized with a fixed seed of $123456789$ will ensure reproducibility. Once a perfect sample $s$ is obtained, its magnetization per site is computed as:\n$$\nm(s) = \\frac{1}{n} \\sum_{i=1}^n s_i\n$$\nThe final result for each case will be this value, rounded to $3$ decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ... # scipy is available but not used in this solution.\n\ndef solve():\n    \"\"\"\n    Implements the Coupling From The Past (CFTP) algorithm for the 1D Ising model\n    and computes the magnetization for a set of test cases.\n    \"\"\"\n\n    test_cases = [\n        # (n, beta, h)\n        (10, 0.2, 0.0),\n        (10, 1.0, 0.3),\n        (20, 0.8, 0.0),\n        (5, 2.0, 0.0),\n    ]\n\n    results = []\n    \n    # Initialize the pseudo-random number generator with the specified seed for reproducibility.\n    rng = np.random.default_rng(123456789)\n\n    def _update_configuration(s_config, site_idx, u_val, n, beta, h):\n        \"\"\"\n        Applies a single-site heat-bath update to a configuration.\n        \"\"\"\n        # Calculate local field, handling open boundary conditions.\n        # Uses 0-based indexing for arrays.\n        if n == 1:\n            local_field = h\n        elif site_idx == 0:\n            local_field = s_config[1] + h\n        elif site_idx == n - 1:\n            local_field = s_config[n - 2] + h\n        else:\n            local_field = s_config[site_idx - 1] + s_config[site_idx + 1] + h\n        \n        # Calculate conditional probability of spin being +1.\n        prob_plus_one = 1.0 / (1.0 + np.exp(-2.0 * beta * local_field))\n        \n        # Update spin based on the uniform random variate u_val.\n        # A copy is created to avoid modifying the original array passed to the function.\n        s_new = s_config.copy()\n        if u_val < prob_plus_one:\n            s_new[site_idx] = 1\n        else:\n            s_new[site_idx] = -1\n            \n        return s_new\n\n    for n, beta, h in test_cases:\n        # Start with a time horizon T=1.\n        T = 1\n        # The random_stream stores pairs of (site_index, uniform_variate).\n        # It is ordered by time, from the most distant past to the most recent.\n        random_stream = [] \n        \n        while True:\n            # Determine how many new random events are needed for the current horizon T.\n            num_new_steps = T - len(random_stream)\n            if num_new_steps > 0:\n                new_sites = rng.integers(0, n, size=num_new_steps)\n                new_uniforms = rng.random(size=num_new_steps)\n                \n                # Prepend the new random events to the stream. These correspond to\n                # the new, earlier time steps.\n                new_stream_part = list(zip(new_sites, new_uniforms))\n                random_stream = new_stream_part + random_stream\n            \n            # Initialize the two extremal configurations for the start of the simulation at time -T.\n            s_min = np.full(n, -1, dtype=np.int8)\n            s_max = np.full(n, 1, dtype=np.int8)\n            \n            # Evolve both chains forward from time -T to 0 using the common random stream.\n            for site_idx, u_val in random_stream:\n                s_min = _update_configuration(s_min, site_idx, u_val, n, beta, h)\n                s_max = _update_configuration(s_max, site_idx, u_val, n, beta, h)\n\n            # Check for coalescence at time 0.\n            if np.array_equal(s_min, s_max):\n                # Coalescence achieved. The sample is perfect.\n                # Calculate magnetization, round it, and add to results.\n                magnetization = np.mean(s_min)\n                results.append(round(magnetization, 3))\n                break  # Exit the while loop and proceed to the next test case.\n            else:\n                # No coalescence. Double the time horizon and try again.\n                T *= 2\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.3f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}