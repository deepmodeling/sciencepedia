{
    "hands_on_practices": [
        {
            "introduction": "The Itô integral is the cornerstone of stochastic calculus, but its definition includes a subtle yet critical requirement: the integrand must be a predictable process. This practice invites you to explore why this condition is not just a technicality by examining a process that is adapted but not predictable . By constructing a valid Itô integral from an invalid one, you will gain a deeper, hands-on understanding of the foundational structure that prevents \"seeing into the future\" and ensures the integral's essential martingale properties.",
            "id": "3809462",
            "problem": "Consider a filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\in [0,1]},\\mathbb{P})$ satisfying the usual conditions, and let $(W_t)_{t \\in [0,1]}$ be a standard Brownian motion adapted to $(\\mathcal{F}_t)_{t \\in [0,1]}$. Recall that the Itô integral $\\int_0^1 H_s \\,\\mathrm{d}W_s$ is defined for processes $H_s$ that are predictable and square-integrable. Define the process $H_s = W_1$ for all $s \\in [0,1]$.\n\n(a) Using only the foundational definitions of adaptedness, predictability, and the definition of the Itô integral via isometry or approximation by simple predictable processes, explain why $H_s = W_1$ is not predictable and why the Itô integral $\\int_0^1 H_s \\,\\mathrm{d}W_s$ is therefore undefined under the usual construction.\n\n(b) Modify $H_s$ to a process $\\widetilde{H}_s$ that is predictable and square-integrable on $[0,1]$, and justify its predictability from first principles. Then, compute the Itô integral $\\int_0^1 \\widetilde{H}_s \\,\\mathrm{d}W_s$ in closed form as a function of $W_1$ by deriving it from fundamental results of stochastic calculus without assuming any shortcut formulas in the problem statement.\n\nYour final answer must be the single closed-form analytic expression for the computed Itô integral in part (b), expressed in terms of $W_1$. Do not provide an inequality or an equation as the final answer; provide the expression only. No rounding is required.",
            "solution": "The problem is first validated by dissecting its components and assessing them against established criteria for scientific and mathematical soundness.\n\n### Step 1: Extract Givens\n- A filtered probability space $(\\Omega,\\mathcal{F},(\\mathcal{F}_t)_{t \\in [0,1]},\\mathbb{P})$ satisfying the usual conditions.\n- $(W_t)_{t \\in [0,1]}$ is a standard Brownian motion adapted to the filtration $(\\mathcal{F}_t)_{t \\in [0,1]}$.\n- The Itô integral $\\int_0^1 H_s \\,\\mathrm{d}W_s$ is defined for processes $H_s$ that are predictable and square-integrable.\n- The process $H_s$ is defined as $H_s = W_1$ for all $s \\in [0,1]$.\n- Part (a) requires an explanation of why $H_s$ is not predictable and why its Itô integral is thus undefined.\n- Part (b) requires modifying $H_s$ to a predictable process $\\widetilde{H}_s$, justifying its properties, and computing the Itô integral $\\int_0^1 \\widetilde{H}_s \\,\\mathrm{d}W_s$ from fundamental principles.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It is firmly grounded in the standard theory of stochastic calculus, using well-defined concepts such as Brownian motion, filtrations, adaptedness, predictability, and the Itô integral. The questions posed are standard and serve to test a foundational understanding of the prerequisites for Itô integration. The problem is self-contained, unambiguous, and well-posed, leading to a unique and meaningful solution. It is free of any factual errors, pseudoscience, or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution is warranted.\n\n***\n\n### Solution\nThis solution is divided into two parts, corresponding to the two parts of the problem statement.\n\n**(a) Analysis of the process $H_s = W_1$**\n\nA stochastic process $(X_t)_{t \\in [0,1]}$ is said to be adapted to the filtration $(\\mathcal{F}_t)_{t \\in [0,1]}$ if for every $t \\in [0,1]$, the random variable $X_t$ is $\\mathcal{F}_t$-measurable. This means the value of the process at time $t$ is determined by the information available up to time $t$.\n\nA process $(H_s)_{s \\in [0,1]}$ is predictable if it is measurable with respect to the predictable $\\sigma$-algebra on $[0,1] \\times \\Omega$, which is the $\\sigma$-algebra generated by all left-continuous adapted processes. An important consequence is that predictable processes are a subset of adapted processes. For the Itô integral to be well-defined, the integrand must be predictable. This condition ensures that the integrand $H_s$ does not depend on future increments of the integrator $W_s$, a scenario akin to insider trading which would violate the martingale property of the Itô integral.\n\nLet us analyze the process $H_s = W_1$ for $s \\in [0,1]$. To determine if $H_s$ is predictable, we first check if it is adapted. For $H_s$ to be adapted, the random variable $H_s$ must be $\\mathcal{F}_s$-measurable for every $s \\in [0,1]$.\n\nConsider any time $s \\in [0,1)$. The random variable is $H_s = W_1$. For $W_1$ to be $\\mathcal{F}_s$-measurable, its value must be fully determined by the information in $\\mathcal{F}_s$. However, by the definition of a standard Brownian motion, the increment $W_1 - W_s$ is independent of the past filtration $\\mathcal{F}_s$. We can express $W_1$ as $W_1 = W_s + (W_1 - W_s)$. Since $W_s$ is $\\mathcal{F}_s$-measurable (as $(W_t)$ is an adapted process), if $W_1$ were also $\\mathcal{F}_s$-measurable, then their difference, $W_1 - W_s$, would have to be $\\mathcal{F}_s$-measurable. A random variable that is independent of a $\\sigma$-algebra $\\mathcal{G}$ can only be $\\mathcal{G}$-measurable if it is constant almost surely. The increment $W_1 - W_s$ follows a normal distribution with mean $0$ and variance $1-s > 0$, so it is not a constant. Therefore, $W_1$ is not $\\mathcal{F}_s$-measurable for any $s < 1$.\n\nSince the process $H_s = W_1$ is not adapted for $s \\in [0,1)$, it cannot be predictable. As the Itô integral $\\int_0^1 H_s \\,\\mathrm{d}W_s$ is defined only for integrands that are predictable (and square-integrable), the expression $\\int_0^1 W_1 \\,\\mathrm{d}W_s$ is undefined within the standard framework of Itô calculus.\n\n**(b) Modification and Computation of the Integral**\n\nThe most natural way to create a predictable process from $H_s = W_1$ is to replace its value at each time $s$ with the best possible estimate of $W_1$ given the information available at that time. This best estimate is the conditional expectation. We define the modified process $\\widetilde{H}_s$ as:\n$$ \\widetilde{H}_s = \\mathbb{E}[H_s | \\mathcal{F}_s] = \\mathbb{E}[W_1 | \\mathcal{F}_s] $$\nTo compute this, we use the properties of Brownian motion. For any $s \\in [0,1]$:\n$$ \\widetilde{H}_s = \\mathbb{E}[W_s + (W_1 - W_s) | \\mathcal{F}_s] = \\mathbb{E}[W_s | \\mathcal{F}_s] + \\mathbb{E}[W_1 - W_s | \\mathcal{F}_s] $$\nSince $W_s$ is $\\mathcal{F}_s$-measurable, $\\mathbb{E}[W_s | \\mathcal{F}_s] = W_s$. Since the increment $W_1 - W_s$ is independent of $\\mathcal{F}_s$ (for $s<1$), its conditional expectation equals its unconditional expectation: $\\mathbb{E}[W_1 - W_s | \\mathcal{F}_s] = \\mathbb{E}[W_1 - W_s] = \\mathbb{E}[W_1] - \\mathbb{E}[W_s] = 0 - 0 = 0$. For $s=1$, $\\mathbb{E}[W_1|\\mathcal{F}_1]=W_1$. Thus, for all $s \\in [0,1]$, the modified process is:\n$$ \\widetilde{H}_s = W_s $$\nThe process $\\widetilde{H}_s = W_s$ is predictable. A standard theorem states that any adapted process with almost surely continuous paths is predictable. The Brownian motion $(W_s)$ is adapted by definition and has continuous paths almost surely, so it is a predictable process.\n\nNext, we verify that $\\widetilde{H}_s$ is square-integrable on $[0,1]$. This requires $\\mathbb{E}\\left[\\int_0^1 \\widetilde{H}_s^2 \\,\\mathrm{d}s\\right] < \\infty$. Using Fubini-Tonelli's theorem:\n$$ \\mathbb{E}\\left[\\int_0^1 W_s^2 \\,\\mathrm{d}s\\right] = \\int_0^1 \\mathbb{E}[W_s^2] \\,\\mathrm{d}s $$\nFor a standard Brownian motion, $W_s$ is normally distributed with mean $0$ and variance $s$. Thus, $\\mathbb{E}[W_s^2] = \\text{Var}(W_s) + (\\mathbb{E}[W_s])^2 = s + 0^2 = s$. The integral becomes:\n$$ \\int_0^1 s \\,\\mathrm{d}s = \\left[\\frac{s^2}{2}\\right]_0^1 = \\frac{1}{2} $$\nSince $\\frac{1}{2} < \\infty$, the process $\\widetilde{H}_s = W_s$ is square-integrable.\n\nWe now compute the Itô integral $I = \\int_0^1 \\widetilde{H}_s \\,\\mathrm{d}W_s = \\int_0^1 W_s \\,\\mathrm{d}W_s$. We derive this from the definition of the Itô integral as the mean-square limit of approximating sums, without direct use of Itô's lemma. Let $\\Pi_n = \\{0=t_0, t_1, \\dots, t_n=1\\}$ be a partition of $[0,1]$ with $t_k = \\frac{k}{n}$ for $k=0, 1, \\dots, n$. The integral is the $L^2(\\Omega)$ limit of the sum:\n$$ S_n = \\sum_{k=0}^{n-1} W_{t_k} (W_{t_{k+1}} - W_{t_k}) $$\nWe utilize the algebraic identity $ab = \\frac{1}{2}[(a+b)^2 - a^2 - b^2]$. A more direct identity for this specific structure is $x(y-x) = \\frac{1}{2}(y^2 - x^2) - \\frac{1}{2}(y-x)^2$. Applying this with $x = W_{t_k}$ and $y = W_{t_{k+1}}$:\n$$ W_{t_k} (W_{t_{k+1}} - W_{t_k}) = \\frac{1}{2}(W_{t_{k+1}}^2 - W_{t_k}^2) - \\frac{1}{2}(W_{t_{k+1}} - W_{t_k})^2 $$\nSumming over $k$ from $0$ to $n-1$:\n$$ S_n = \\sum_{k=0}^{n-1} \\frac{1}{2}(W_{t_{k+1}}^2 - W_{t_k}^2) - \\sum_{k=0}^{n-1} \\frac{1}{2}(W_{t_{k+1}} - W_{t_k})^2 $$\nThe first sum is a telescoping series:\n$$ \\frac{1}{2} \\sum_{k=0}^{n-1} (W_{t_{k+1}}^2 - W_{t_k}^2) = \\frac{1}{2}(W_{t_n}^2 - W_{t_0}^2) = \\frac{1}{2}(W_1^2 - W_0^2) = \\frac{1}{2}W_1^2 $$\nsince $W_0=0$ almost surely. The second sum is half the quadratic variation of $W_t$ over the partition $\\Pi_n$. A fundamental result of stochastic calculus is that the quadratic variation of a standard Brownian motion over an interval $[0,T]$ converges in $L^2$ to $T$ as the mesh of the partition goes to zero. For our case, with $T=1$:\n$$ \\lim_{n \\to \\infty} \\sum_{k=0}^{n-1} (W_{t_{k+1}} - W_{t_k})^2 = 1 \\quad (\\text{in } L^2(\\Omega)) $$\nCombining these results, we take the limit of $S_n$ as $n \\to \\infty$ to find the value of the integral:\n$$ \\int_0^1 W_s \\,\\mathrm{d}W_s = \\lim_{n \\to \\infty} S_n = \\frac{1}{2}W_1^2 - \\frac{1}{2} \\lim_{n \\to \\infty} \\sum_{k=0}^{n-1} (W_{t_{k+1}} - W_{t_k})^2 = \\frac{1}{2}W_1^2 - \\frac{1}{2}(1) $$\nTherefore, the value of the Itô integral is $\\frac{1}{2}W_1^2 - \\frac{1}{2}$.",
            "answer": "$$\n\\boxed{\\frac{1}{2}W_1^2 - \\frac{1}{2}}\n$$"
        },
        {
            "introduction": "Many stochastic differential equations feature complex, state-dependent noise terms that can make analysis difficult. This exercise introduces a powerful technique, often called the Lamperti transform, which uses a carefully chosen change of variables to convert an SDE with multiplicative noise into a simpler one with constant (or unit) diffusion . Mastering this application of Itô's formula is a key skill for simplifying models and is a frequent first step in the analysis of nonlinear SDEs in physics, finance, and biology.",
            "id": "3809540",
            "problem": "Consider the scalar Itô stochastic differential equation (SDE) with multiplicative noise\n$$\n\\mathrm{d}X_{t} = \\mu(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t},\n$$\nwhere $W_{t}$ is a standard Wiener process (Brownian motion), $X_{t} \\in \\mathbb{R}$, and the coefficients are given by\n$$\n\\mu(x) = -\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda\\right)x,\\qquad \\sigma(x) = \\sqrt{\\alpha + \\beta x^{2}},\n$$\nwith parameters $\\alpha > 0$, $\\beta > 0$, $\\gamma > 0$, $\\lambda \\ge 0$, and $\\varepsilon \\in (0,1]$. This form models a linear restoring force with a stiff contribution of order $1/\\varepsilon$ coupled to state-dependent noise typical in multiscale modeling contexts.\n\nUsing only fundamental definitions from stochastic calculus (in particular, Itô’s formula), construct a twice continuously differentiable, strictly increasing transformation $Y_{t} = g(X_{t})$ with $g(0)=0$ such that the SDE for $Y_{t}$ has unit diffusion coefficient. Then compute the transformed drift $b(y)$ explicitly as a function of $y$ and the parameters $\\alpha$, $\\beta$, $\\gamma$, $\\lambda$, and $\\varepsilon$. Provide your final answer as a single closed-form analytic expression for $b(y)$ in terms of $y$, $\\beta$, $\\gamma$, $\\lambda$, and $\\varepsilon$ only. Do not include units. No rounding is required.",
            "solution": "The problem statement is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- A scalar Itô stochastic differential equation (SDE):\n$$ \\mathrm{d}X_{t} = \\mu(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t} $$\n- The state variable is $X_{t} \\in \\mathbb{R}$.\n- $W_{t}$ is a standard Wiener process.\n- The drift coefficient is $\\mu(x) = -\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda\\right)x$.\n- The diffusion coefficient is $\\sigma(x) = \\sqrt{\\alpha + \\beta x^{2}}$.\n- The parameters are constrained as follows: $\\alpha > 0$, $\\beta > 0$, $\\gamma > 0$, $\\lambda \\ge 0$, and $\\varepsilon \\in (0,1]$.\n- A transformation $Y_{t} = g(X_{t})$ is sought with the following properties:\n    1. $g$ is twice continuously differentiable ($g \\in C^2(\\mathbb{R})$).\n    2. $g$ is strictly increasing, i.e., $g'(x) > 0$ for all $x \\in \\mathbb{R}$.\n    3. $g(0) = 0$.\n- The SDE for $Y_{t}$ must have a unit diffusion coefficient.\n- The objective is to compute the transformed drift coefficient, $b(y)$, as a function of $y$, $\\beta$, $\\gamma$, $\\lambda$, and $\\varepsilon$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is set within the established mathematical framework of stochastic calculus and Itô SDEs. The equation is a variant of the Ornstein-Uhlenbeck process with state-dependent diffusion, a standard model in physics and finance. The task of transforming an SDE to one with constant diffusion (the Lamperti transformation) is a fundamental technique in the field.\n- **Well-Posed**: The problem is clearly stated. The conditions on the transformation function $g(x)$ are sufficient to determine it uniquely. The existence of a solution for the transformed drift $b(y)$ is guaranteed under these conditions.\n- **Objective**: The problem is formulated in precise, unambiguous mathematical language.\n- **Completeness and Consistency**: All necessary functions, parameters, and constraints are explicitly provided. The constraint $\\alpha > 0$ ensures that $\\sigma(x)$ is always real and strictly positive, which is crucial for the transformation to be well-defined. There are no contradictions in the givens.\n\n### Step 3: Verdict and Action\nThe problem is valid. A rigorous solution can be constructed.\n\n### Solution Derivation\n\nWe seek a transformation $Y_{t} = g(X_{t})$ that transforms the given SDE into one with a unit diffusion coefficient. We apply Itô’s formula to $g(X_{t})$. For a twice continuously differentiable function $g$, the differential $\\mathrm{d}Y_{t}$ is given by:\n$$ \\mathrm{d}Y_{t} = g'(X_{t})\\,\\mathrm{d}X_{t} + \\frac{1}{2}g''(X_{t})\\,(\\mathrm{d}X_{t})^{2} $$\nThe rules of Itô calculus dictate that $(\\mathrm{d}X_{t})^{2} = \\sigma(X_t)^2\\,\\mathrm{d}t$. Substituting the SDE for $\\mathrm{d}X_{t}$:\n$$ \\mathrm{d}Y_{t} = g'(X_{t})\\left(\\mu(X_{t})\\,\\mathrm{d}t + \\sigma(X_{t})\\,\\mathrm{d}W_{t}\\right) + \\frac{1}{2}g''(X_{t})\\sigma(X_{t})^{2}\\,\\mathrm{d}t $$\nGrouping the $\\mathrm{d}t$ and $\\mathrm{d}W_{t}$ terms, we obtain the SDE for $Y_{t}$:\n$$ \\mathrm{d}Y_{t} = \\left[g'(X_{t})\\mu(X_{t}) + \\frac{1}{2}g''(X_{t})\\sigma(X_{t})^{2}\\right]\\,\\mathrm{d}t + g'(X_{t})\\sigma(X_{t})\\,\\mathrm{d}W_{t} $$\nThe new drift coefficient is the term in the square brackets, and the new diffusion coefficient is the prefactor of $\\mathrm{d}W_{t}$. The problem requires that the diffusion coefficient of the SDE for $Y_t$ be unity. This imposes the following condition on $g(x)$:\n$$ g'(x)\\sigma(x) = 1 $$\nThis implies that the derivative of our transformation function must be:\n$$ g'(x) = \\frac{1}{\\sigma(x)} = \\frac{1}{\\sqrt{\\alpha + \\beta x^2}} $$\nTo find $g(x)$, we integrate $g'(x)$. The condition $g(0)=0$ determines the constant of integration.\n$$ g(x) = \\int_{0}^{x} g'(u)\\,\\mathrm{d}u = \\int_{0}^{x} \\frac{1}{\\sqrt{\\alpha + \\beta u^2}}\\,\\mathrm{d}u $$\nWe evaluate this integral:\n$$ g(x) = \\frac{1}{\\sqrt{\\beta}}\\int_{0}^{x} \\frac{1}{\\sqrt{\\frac{\\alpha}{\\beta} + u^2}}\\,\\mathrm{d}u $$\nThe integral is a standard form. Using the identity $\\int \\frac{\\mathrm{d}u}{\\sqrt{a^2+u^2}} = \\arcsinh(\\frac{u}{a})$, we get:\n$$ g(x) = \\frac{1}{\\sqrt{\\beta}}\\left[\\arcsinh\\left(\\frac{u}{\\sqrt{\\alpha/\\beta}}\\right)\\right]_{0}^{x} = \\frac{1}{\\sqrt{\\beta}}\\left(\\arcsinh\\left(x\\sqrt{\\frac{\\beta}{\\alpha}}\\right) - \\arcsinh(0)\\right) $$\n$$ g(x) = \\frac{1}{\\sqrt{\\beta}}\\arcsinh\\left(x\\sqrt{\\frac{\\beta}{\\alpha}}\\right) $$\nThis function $g(x)$ satisfies all the required properties. Since $\\alpha>0$ and $\\beta>0$, $g'(x) = (\\alpha + \\beta x^2)^{-1/2} > 0$, so $g(x)$ is strictly increasing. It is also twice continuously differentiable.\n\nThe transformed drift, let's call it $B(x)$ in the $x$-coordinate, is:\n$$ B(x) = g'(x)\\mu(x) + \\frac{1}{2}g''(x)\\sigma(x)^{2} $$\nWe need the second derivative of $g(x)$:\n$$ g''(x) = \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left((\\alpha + \\beta x^2)^{-1/2}\\right) = -\\frac{1}{2}(\\alpha + \\beta x^2)^{-3/2}(2\\beta x) = -\\frac{\\beta x}{(\\alpha + \\beta x^2)^{3/2}} $$\nSubstituting the expressions for $\\mu(x)$, $\\sigma(x)$, $g'(x)$, and $g''(x)$ into the drift formula:\n$$ B(x) = \\frac{1}{\\sqrt{\\alpha + \\beta x^2}}\\left(-\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda\\right)x\\right) + \\frac{1}{2}\\left(-\\frac{\\beta x}{(\\alpha + \\beta x^2)^{3/2}}\\right)(\\alpha + \\beta x^2) $$\n$$ B(x) = -\\frac{(\\frac{\\gamma}{\\varepsilon} + \\lambda)x}{\\sqrt{\\alpha + \\beta x^2}} - \\frac{\\beta x}{2\\sqrt{\\alpha + \\beta x^2}} $$\n$$ B(x) = -\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda + \\frac{\\beta}{2}\\right)\\frac{x}{\\sqrt{\\alpha + \\beta x^2}} $$\nThe problem asks for the drift $b(y)$ as a function of $y = g(x)$. To achieve this, we must express the term $\\frac{x}{\\sqrt{\\alpha + \\beta x^2}}$ as a function of $y$. First, we find the inverse transformation $x = g^{-1}(y)$:\n$$ y = \\frac{1}{\\sqrt{\\beta}}\\arcsinh\\left(x\\sqrt{\\frac{\\beta}{\\alpha}}\\right) \\implies \\sqrt{\\beta}y = \\arcsinh\\left(x\\sqrt{\\frac{\\beta}{\\alpha}}\\right) $$\n$$ \\sinh(\\sqrt{\\beta}y) = x\\sqrt{\\frac{\\beta}{\\alpha}} \\implies x = \\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y) $$\nNow, we substitute this expression for $x$ into the term we need to transform:\n$$ \\frac{x}{\\sqrt{\\alpha + \\beta x^2}} = \\frac{\\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y)}{\\sqrt{\\alpha + \\beta \\left(\\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y)\\right)^2}} = \\frac{\\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y)}{\\sqrt{\\alpha + \\alpha\\sinh^2(\\sqrt{\\beta}y)}} $$\nUsing the identity $\\cosh^2(z) = 1 + \\sinh^2(z)$:\n$$ \\frac{x}{\\sqrt{\\alpha + \\beta x^2}} = \\frac{\\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y)}{\\sqrt{\\alpha\\cosh^2(\\sqrt{\\beta}y)}} = \\frac{\\sqrt{\\frac{\\alpha}{\\beta}}\\sinh(\\sqrt{\\beta}y)}{\\sqrt{\\alpha}\\cosh(\\sqrt{\\beta}y)} $$\nNote that $\\cosh(z) > 0$ for all real $z$.\n$$ \\frac{x}{\\sqrt{\\alpha + \\beta x^2}} = \\frac{1}{\\sqrt{\\beta}}\\frac{\\sinh(\\sqrt{\\beta}y)}{\\cosh(\\sqrt{\\beta}y)} = \\frac{1}{\\sqrt{\\beta}}\\tanh(\\sqrt{\\beta}y) $$\nNoticeably, the parameter $\\alpha$ has cancelled out. Finally, we substitute this result back into the expression for the drift $B(x)$ to get $b(y)$:\n$$ b(y) = -\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda + \\frac{\\beta}{2}\\right) \\left(\\frac{1}{\\sqrt{\\beta}}\\tanh(\\sqrt{\\beta}y)\\right) $$\nThis expression can be slightly rearranged for the final answer.\n$$ b(y) = -\\frac{1}{\\sqrt{\\beta}}\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda + \\frac{\\beta}{2}\\right)\\tanh(\\sqrt{\\beta}y) $$\nThis is the required closed-form analytic expression for the transformed drift $b(y)$.",
            "answer": "$$ \\boxed{-\\frac{1}{\\sqrt{\\beta}}\\left(\\frac{\\gamma}{\\varepsilon} + \\lambda + \\frac{\\beta}{2}\\right)\\tanh(\\sqrt{\\beta}y)} $$"
        },
        {
            "introduction": "Systems with interacting components evolving on widely different timescales are ubiquitous in science and engineering. This advanced practice guides you through the core steps of the averaging principle, a cornerstone of multiscale analysis, to derive the effective long-term behavior of a slow variable coupled to a rapidly fluctuating process . By solving the associated Poisson equation for the \"corrector\" function, you will not only derive the simplified averaged dynamics but also compute the leading-order correction, providing a more accurate approximation of the system's true behavior.",
            "id": "3809562",
            "problem": "Consider the one-dimensional slow–fast stochastic differential equation (SDE) system\n$$\n\\begin{aligned}\n\\mathrm{d}X_{t}^{\\varepsilon} &= f\\big(X_{t}^{\\varepsilon},Y_{t}^{\\varepsilon}\\big)\\,\\mathrm{d}t,\\\\\n\\mathrm{d}Y_{t}^{\\varepsilon} &= \\frac{1}{\\varepsilon}\\left[-\\lambda \\left(Y_{t}^{\\varepsilon}-\\theta X_{t}^{\\varepsilon}\\right)\\right]\\mathrm{d}t+\\frac{\\sigma}{\\sqrt{\\varepsilon}}\\,\\mathrm{d}W_{t},\n\\end{aligned}\n$$\nwhere $X_{t}^{\\varepsilon}\\in\\mathbb{R}$ is the slow variable, $Y_{t}^{\\varepsilon}\\in\\mathbb{R}$ is the fast variable, $W_{t}$ is a standard one-dimensional Brownian motion, and the parameters satisfy $\\lambda>0$, $\\sigma>0$, and $\\theta\\in\\mathbb{R}$. The slow drift is linear in both variables,\n$$\nf(x,y)=a\\,x+b\\,y,\n$$\nwith $a,b\\in\\mathbb{R}$. For each frozen $x\\in\\mathbb{R}$, the generator acting on functions of $y$ alone is\n$$\n\\mathcal{L}^{x}\\phi(y)=-\\lambda\\left(y-\\theta x\\right)\\frac{\\partial \\phi}{\\partial y}(y)+\\frac{\\sigma^{2}}{2}\\frac{\\partial^{2} \\phi}{\\partial y^{2}}(y).\n$$\nDenote by $\\mu^{x}(\\mathrm{d}y)$ the unique invariant probability measure of the fast Ornstein–Uhlenbeck dynamics at frozen $x$, and let the averaged drift be\n$$\n\\bar{f}(x)=\\int_{\\mathbb{R}} f(x,y)\\,\\mu^{x}(\\mathrm{d}y).\n$$\nThe averaging principle states that $X_{t}^{\\varepsilon}$ converges, as $\\varepsilon\\to 0$, to the solution of the deterministic ordinary differential equation $\\dot{\\bar{X}}_{t}=\\bar{f}(\\bar{X}_{t})$. A refined multiscale analysis yields an asymptotic expansion for the backward Kolmogorov equation associated with $X_{t}^{\\varepsilon}$, in which the leading-order error involves the corrector $\\Phi(x,y)$ defined as the unique (centered) solution of the Poisson equation\n$$\n\\mathcal{L}^{x}\\Phi(x,y)=f(x,y)-\\bar{f}(x),\\qquad \\int_{\\mathbb{R}}\\Phi(x,y)\\,\\mu^{x}(\\mathrm{d}y)=0.\n$$\n\n(a) Determine explicitly the invariant measure $\\mu^{x}(\\mathrm{d}y)$ and compute $\\bar{f}(x)$.\n\n(b) Solve the Poisson equation for the corrector $\\Phi(x,y)$ satisfying the centering condition.\n\n(c) Using a two-scale expansion of the backward Kolmogorov equation based on the decomposition $\\mathcal{L}^{\\varepsilon}=\\varepsilon^{-1}\\mathcal{L}^{x}+\\mathcal{L}_{1}$ with $\\mathcal{L}_{1}u(x,y)=f(x,y)\\,\\partial_{x}u(x,y)$, identify the leading-order $\\mathcal{O}(\\varepsilon)$ correction to the averaged drift in the effective generator for the slow marginal. Concretely, show that the drift correction is given by a function $B(x)$ proportional to\n$$\nB(x)=-\\int_{\\mathbb{R}} f(x,y)\\,\\frac{\\partial \\Phi}{\\partial x}(x,y)\\,\\mu^{x}(\\mathrm{d}y),\n$$\nand compute $B(x)$ in closed form for the given coefficients.\n\nYour final answer should be the explicit analytic expression for $B(x)$, simplified as a function of $x$, $a$, $b$, $\\theta$, and $\\lambda$. No numerical evaluation is required, and no units are involved. Express the final answer as a single closed-form expression.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   The slow-fast SDE system is given by:\n    $$\n    \\begin{aligned}\n    \\mathrm{d}X_{t}^{\\varepsilon} &= f\\big(X_{t}^{\\varepsilon},Y_{t}^{\\varepsilon}\\big)\\,\\mathrm{d}t,\\\\\n    \\mathrm{d}Y_{t}^{\\varepsilon} &= \\frac{1}{\\varepsilon}\\left[-\\lambda \\left(Y_{t}^{\\varepsilon}-\\theta X_{t}^{\\varepsilon}\\right)\\right]\\mathrm{d}t+\\frac{\\sigma}{\\sqrt{\\varepsilon}}\\,\\mathrm{d}W_{t},\n    \\end{aligned}\n    $$\n-   Variables and parameters: $X_{t}^{\\varepsilon} \\in \\mathbb{R}$ (slow variable), $Y_{t}^{\\varepsilon} \\in \\mathbb{R}$ (fast variable), $W_{t}$ is a standard one-dimensional Brownian motion, $\\varepsilon$ is a small parameter, $\\lambda>0$, $\\sigma>0$, $\\theta\\in\\mathbb{R}$, $a,b\\in\\mathbb{R}$.\n-   The slow drift function is linear: $f(x,y) = a\\,x+b\\,y$.\n-   The generator for the fast dynamics at a frozen $x \\in \\mathbb{R}$ is:\n    $$\n    \\mathcal{L}^{x}\\phi(y)=-\\lambda\\left(y-\\theta x\\right)\\frac{\\partial \\phi}{\\partial y}(y)+\\frac{\\sigma^{2}}{2}\\frac{\\partial^{2} \\phi}{\\partial y^{2}}(y).\n    $$\n-   $\\mu^{x}(\\mathrm{d}y)$ is the unique invariant probability measure corresponding to $\\mathcal{L}^{x}$.\n-   The averaged drift is defined as $\\bar{f}(x)=\\int_{\\mathbb{R}} f(x,y)\\,\\mu^{x}(\\mathrm{d}y)$.\n-   The corrector $\\Phi(x,y)$ is the unique centered solution to the Poisson equation:\n    $$\n    \\mathcal{L}^{x}\\Phi(x,y)=f(x,y)-\\bar{f}(x),\\qquad \\int_{\\mathbb{R}}\\Phi(x,y)\\,\\mu^{x}(\\mathrm{d}y)=0.\n    $$\n-   The drift correction term to be computed is given by the formula:\n    $$\n    B(x)=-\\int_{\\mathbb{R}} f(x,y)\\,\\frac{\\partial \\Phi}{\\partial x}(x,y)\\,\\mu^{x}(\\mathrm{d}y).\n    $$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is well-defined and scientifically sound.\n1.  **Scientific Grounding:** The problem is a standard exercise in the theory of multiscale analysis for stochastic differential equations, specifically focusing on the averaging principle and diffusion approximation for slow-fast systems. All concepts, including the Ornstein-Uhlenbeck process, its generator, invariant measure, the Poisson equation, and the structure of the effective dynamics, are cornerstones of this field.\n2.  **Well-Posedness:** The problem is well-posed. The fast dynamics describe an ergodic Ornstein-Uhlenbeck process for any fixed $x$, which guarantees the existence and uniqueness of the invariant measure $\\mu^x$. The right-hand side of the Poisson equation, $f(x,y) - \\bar{f}(x)$, is centered with respect to $\\mu^x$ by construction, which, by the Fredholm alternative for the operator $\\mathcal{L}^x$, ensures the existence of a solution $\\Phi(x,y)$. The additional centering condition on $\\Phi(x,y)$ makes this solution unique. All subsequent calculations are based on well-defined quantities.\n3.  **Objectivity:** The problem is stated in precise, objective mathematical language, with all terms and objectives clearly defined.\n\n### Step 3: Verdict and Action\nThe problem is valid. A detailed solution follows.\n\n(a) Determination of the invariant measure $\\mu^{x}(\\mathrm{d}y)$ and computation of $\\bar{f}(x)$.\n\nFor a fixed $x$, the fast variable $Y_t^\\varepsilon$ dynamics, after a time-rescaling $\\tau = t/\\varepsilon$, are described by the Ornstein-Uhlenbeck (OU) process:\n$$\n\\mathrm{d}Y_{\\tau} = -\\lambda(Y_{\\tau} - \\theta x)\\,\\mathrm{d}\\tau + \\sigma\\,\\mathrm{d}W_{\\tau}.\n$$\nThis is a standard OU process with mean-reversion rate $\\lambda > 0$, mean-reversion level $\\theta x$, and volatility $\\sigma > 0$. The unique stationary (invariant) distribution for this process is a Gaussian distribution. The mean of this distribution is the mean-reversion level, $\\theta x$. The variance is given by $\\frac{\\sigma^2}{2\\lambda}$.\nThus, the invariant measure $\\mu^x(\\mathrm{d}y)$ is a normal distribution $\\mathcal{N}(\\theta x, \\frac{\\sigma^2}{2\\lambda})$.\n\nNext, we compute the averaged drift $\\bar{f}(x)$:\n$$\n\\bar{f}(x) = \\int_{\\mathbb{R}} f(x,y)\\,\\mu^{x}(\\mathrm{d}y) = \\int_{\\mathbb{R}} (a x + b y)\\,\\mu^{x}(\\mathrm{d}y).\n$$\nBy linearity of the integral, we have:\n$$\n\\bar{f}(x) = a x \\int_{\\mathbb{R}} \\mu^{x}(\\mathrm{d}y) + b \\int_{\\mathbb{R}} y\\,\\mu^{x}(\\mathrm{d}y).\n$$\nThe first integral is $1$ because $\\mu^x$ is a probability measure. The second integral is the expectation of a random variable with distribution $\\mu^x$, which is its mean, $\\theta x$.\n$$\n\\bar{f}(x) = a x \\cdot 1 + b \\cdot (\\theta x) = (a+b\\theta)x.\n$$\n\n(b) Solving the Poisson equation for the corrector $\\Phi(x,y)$.\n\nThe Poisson equation to be solved is $\\mathcal{L}^{x}\\Phi(x,y)=f(x,y)-\\bar{f}(x)$.\nFirst, we compute the right-hand side:\n$$\nf(x,y)-\\bar{f}(x) = (ax+by) - (a+b\\theta)x = by - b\\theta x = b(y-\\theta x).\n$$\nSo, the equation is:\n$$\n-\\lambda\\left(y-\\theta x\\right)\\frac{\\partial \\Phi}{\\partial y}(x,y)+\\frac{\\sigma^{2}}{2}\\frac{\\partial^{2} \\Phi}{\\partial y^{2}}(x,y) = b(y-\\theta x).\n$$\nWe seek a solution $\\Phi(x,y)$ that is a function of $y$ and is centered, $\\int_{\\mathbb{R}}\\Phi(x,y)\\,\\mu^{x}(\\mathrm{d}y)=0$. Given the linear form of the right-hand side in $y$, we posit a linear ansatz for $\\Phi$ in terms of $y$:\n$$\n\\Phi(x,y) = C_1(x)y + C_0(x).\n$$\nThe partial derivatives with respect to $y$ are:\n$$\n\\frac{\\partial \\Phi}{\\partial y} = C_1(x), \\qquad \\frac{\\partial^{2} \\Phi}{\\partial y^{2}} = 0.\n$$\nSubstituting these into the Poisson equation gives:\n$$\n-\\lambda(y-\\theta x)C_1(x) + \\frac{\\sigma^2}{2}(0) = b(y-\\theta x).\n$$\nThis must hold for all $y$, so we can equate the coefficients of $(y-\\theta x)$:\n$$\n-\\lambda C_1(x) = b \\implies C_1(x) = -\\frac{b}{\\lambda}.\n$$\nThe solution so far is $\\Phi(x,y) = -\\frac{b}{\\lambda}y + C_0(x)$. We determine $C_0(x)$ using the centering condition:\n$$\n\\int_{\\mathbb{R}}\\left(-\\frac{b}{\\lambda}y + C_0(x)\\right)\\mu^{x}(\\mathrm{d}y) = 0.\n$$\n$$\n-\\frac{b}{\\lambda}\\int_{\\mathbb{R}}y\\,\\mu^{x}(\\mathrm{d}y) + C_0(x)\\int_{\\mathbb{R}}\\mu^{x}(\\mathrm{d}y) = 0.\n$$\nUsing the known mean $\\theta x$ and total probability $1$, we get:\n$$\n-\\frac{b}{\\lambda}(\\theta x) + C_0(x)(1) = 0 \\implies C_0(x) = \\frac{b\\theta}{\\lambda}x.\n$$\nTherefore, the corrector is:\n$$\n\\Phi(x,y) = -\\frac{b}{\\lambda}y + \\frac{b\\theta}{\\lambda}x = -\\frac{b}{\\lambda}(y-\\theta x).\n$$\n\n(c) Computation of the drift correction $B(x)$.\n\nThe leading-order drift correction is given by the function $B(x)$, defined as:\n$$\nB(x)=-\\int_{\\mathbb{R}} f(x,y)\\,\\frac{\\partial \\Phi}{\\partial x}(x,y)\\,\\mu^{x}(\\mathrm{d}y).\n$$\nFirst, we compute the partial derivative of the corrector $\\Phi(x,y)$ with respect to $x$:\n$$\n\\frac{\\partial \\Phi}{\\partial x}(x,y) = \\frac{\\partial}{\\partial x}\\left(-\\frac{b}{\\lambda}(y-\\theta x)\\right) = -\\frac{b}{\\lambda}(-\\theta) = \\frac{b\\theta}{\\lambda}.\n$$\nThis derivative is a constant. Now, we substitute this and $f(x,y)=ax+by$ into the integral for $B(x)$:\n$$\nB(x)=-\\int_{\\mathbb{R}} (ax+by)\\left(\\frac{b\\theta}{\\lambda}\\right)\\mu^{x}(\\mathrm{d}y).\n$$\nThe term $\\frac{b\\theta}{\\lambda}$ is constant with respect to the integration variable $y$, so it can be factored out:\n$$\nB(x) = -\\frac{b\\theta}{\\lambda}\\int_{\\mathbb{R}} (ax+by)\\,\\mu^{x}(\\mathrm{d}y).\n$$\nThe integral remaining is precisely the definition of the averaged drift $\\bar{f}(x)$, which we have already calculated in part (a):\n$$\n\\int_{\\mathbb{R}} (ax+by)\\,\\mu^{x}(\\mathrm{d}y) = \\bar{f}(x) = (a+b\\theta)x.\n$$\nSubstituting this back into the expression for $B(x)$:\n$$\nB(x) = -\\frac{b\\theta}{\\lambda}(a+b\\theta)x.\n$$\nThis is the final expression for the drift correction function $B(x)$.",
            "answer": "$$\n\\boxed{-\\frac{b\\theta(a+b\\theta)}{\\lambda}x}\n$$"
        }
    ]
}