{
    "hands_on_practices": [
        {
            "introduction": "This exercise provides the fundamental recipe for computing the Mean Squared Displacement (MSD) from discrete simulation data. You will formulate the correct statistical estimator that averages over both an ensemble of particles and multiple time origins within each trajectory . Mastering this technique is the first step toward accurately characterizing diffusion from molecular dynamics or other trajectory-based simulations.",
            "id": "3877884",
            "problem": "In molecular dynamics of guest molecules diffusing through a porous catalytic solid, you record discrete trajectories for $N$ particles at uniformly sampled times $t_n = n\\,\\delta t$ with $n \\in \\{0,1,\\dots,M-1\\}$, where $\\delta t$ is the sampling interval and $M$ is the number of stored frames. Let $\\mathbf{r}_i(t_n)$ denote the unwrapped position of particle $i$ at time $t_n$ in $\\mathbb{R}^3$. Assume stationarity and ergodicity of the increments at long times in the diffusive regime, and that the initial conditions are not special beyond those assumptions. The ensemble mean squared displacement at time lag $\\tau$ is defined as $\\langle \\Delta r^2(\\tau)\\rangle = \\left\\langle \\|\\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\|^2 \\right\\rangle$, where the average is taken over particles and time origins. For discrete data, it is customary to consider lags $\\tau_k = k\\,\\delta t$ with $k \\in \\{1,2,\\dots,M-1\\}$.\n\nWhich option gives a correct time-origin-averaged estimator for $\\langle \\Delta r^2(\\tau_k)\\rangle$ from the discrete data and a scientifically sound prescription for selecting the set of time lags $\\{\\tau_k\\}$ to minimize bias associated with finite trajectory length and dynamical crossovers relevant to diffusion in confined catalysts?\n\nA. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-k)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand select a set of lags by requiring a minimum number of time-origin pairs per lag, $M-k \\ge M_{\\min}$ with $M_{\\min}$ chosen to ensure adequate statistics (for example $M_{\\min} \\approx 50$ to $100$), while restricting to the window where the process is diffusive: exclude small $k$ that lie in the ballistic regime and large $k$ where confinement or drift induces deviations. For stable regression of the diffusion coefficient from the linear regime, use logarithmically spaced $k$ or adaptively choose $k$ so that the effective number of pairs is approximately constant across lags.\n\nB. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,M} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand take all lags $k \\in \\{1,2,\\dots,M-1\\}$ with uniform linear spacing, since ergodicity ensures unbiasedness for any $k$ and larger $k$ improve the estimate by covering longer times.\n\nC. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-1)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand prioritize the largest possible lags, $k$ close to $M-1$, because they emphasize the diffusive regime and reduce the influence of the ballistic regime; use all available $k$ without exclusion to avoid selection bias.\n\nD. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\|\\mathbf{r}_i(t_{k}) - \\mathbf{r}_i(t_{0})\\right\\|^2,$\nto avoid correlation among overlapping time origins, and choose nonoverlapping lags $k$ as large as possible (for example, powers of $2$ up to $M-1$) so that each lag uses a distinct set of frames and thus eliminates bias from time-origin reuse.",
            "solution": "The problem statement is scrutinized for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n-   **System**: Guest molecules diffusing through a porous catalytic solid.\n-   **Simulation Data**: Discrete trajectories for $N$ particles.\n-   **Time Discretization**: Uniformly sampled times $t_n = n\\,\\delta t$ for $n \\in \\{0,1,\\dots,M-1\\}$.\n-   **Position Data**: $\\mathbf{r}_i(t_n)$ is the unwrapped position of particle $i$ at time $t_n$ in $\\mathbb{R}^3$.\n-   **Assumptions**: Stationarity and ergodicity of increments at long times in the diffusive regime.\n-   **Definition**: Ensemble mean squared displacement (MSD) at time lag $\\tau$ is $\\langle \\Delta r^2(\\tau)\\rangle = \\left\\langle \\|\\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\|^2 \\right\\rangle$. The average is over particles and time origins.\n-   **Discrete Time Lags**: $\\tau_k = k\\,\\delta t$ with $k \\in \\{1,2,\\dots,M-1\\}$.\n-   **Question**: Identify the correct estimator for $\\langle \\Delta r^2(\\tau_k)\\rangle$ from discrete data and the scientifically sound procedure for selecting the set of lags $\\{\\tau_k\\}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, describing a standard and fundamental analysis task in computational physics and chemistry: the calculation of the MSD from molecular dynamics trajectories. The terms used—stationarity, ergodicity, ballistic regime, diffusive regime, confinement—are standard concepts in statistical mechanics. The problem is well-posed, asking for a correct statistical estimator and a sound methodological approach, for which there are established best practices. The language is objective and precise. The problem is self-contained and free of contradictions, scientific inaccuracies, or infeasible conditions. It represents a non-trivial challenge in data analysis methodology, specifically the trade-off between statistical bias, variance, and the physical interpretation of different time scales.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation and Analysis\n\nThe objective is to find the best estimator, denoted $\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)$, for the true ensemble average $\\langle \\Delta r^2(\\tau_k)\\rangle$. The averaging $\\langle \\dots \\rangle$ is defined over particles and time origins.\n\nFor a finite trajectory of length $M$ frames and a time lag $\\tau_k = k\\,\\delta t$, the number of available, distinct, overlapping time intervals of duration $\\tau_k$ is $M-k$. The time origins are $t_0, t_1, \\dots, t_{M-k-1}$.\n\nFirst, consider a single particle $i$. The time-averaged MSD for this particle is found by averaging the squared displacements over all possible time origins:\n$$ \\text{MSD}_i(\\tau_k) = \\frac{1}{M-k} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 $$\nThe normalization factor $1/(M-k)$ ensures that this is an average over the number of available samples.\n\nTo obtain the full ensemble average, we then average this quantity over the $N$ independent particles:\n$$ \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\text{MSD}_i(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{1}{M-k} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 \\right) $$\nThis can be written as a single combined expression:\n$$ \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N(M-k)} \\sum_{i=1}^{N} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 $$\nAssuming the process increments are stationary, the expectation of this estimator is:\n$$ E\\left[\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)\\right] = \\frac{1}{N(M-k)} \\sum_{i=1}^{N} \\sum_{n=0}^{M-k-1} E\\left[\\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2\\right] $$\nBy stationarity, $E\\left[\\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2\\right] = \\langle \\Delta r^2(\\tau_k)\\rangle$, independent of the time origin $t_n$. Therefore:\n$$ E\\left[\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)\\right] = \\frac{1}{N(M-k)} \\sum_{i=1}^{N} \\sum_{n=0}^{M-k-1} \\langle \\Delta r^2(\\tau_k)\\rangle = \\frac{N(M-k)}{N(M-k)} \\langle \\Delta r^2(\\tau_k)\\rangle = \\langle \\Delta r^2(\\tau_k)\\rangle $$\nThis confirms that the estimator is unbiased. The normalization by $N(M-k)$ correctly reflects the total number of statistical samples available for the time lag $\\tau_k$.\n\nRegarding the selection of time lags $\\{\\tau_k\\}$, a sound procedure must account for both the physical behavior of the system and statistical limitations:\n1.  **Short-time regime (small $k$):** At very short times, particle motion is ballistic, reflecting its initial velocity, so $\\langle \\Delta r^2(\\tau) \\rangle \\propto \\tau^2$. This regime is not diffusive and must be excluded from any linear fit to extract a diffusion coefficient.\n2.  **Long-time regime (large $k$):** As $k \\to M-1$, the number of samples $M-k$ becomes very small, leading to a large statistical variance in the estimator. The result is increasingly noisy and unreliable. Thus, a cutoff for $k$ is required, e.g., $k \\le M/2$ or more formally $M-k \\ge M_{\\min}$ for some minimum number of statistical samples $M_{\\min}$.\n3.  **Physical long-time effects:** For diffusion in confined media like a catalyst pore, at long times particles begin to encounter the boundaries. This interaction suppresses the growth of the MSD, leading to sub-diffusion or saturation ($\\langle \\Delta r^2(\\tau) \\rangle \\to \\text{constant}$). This region does not reflect the bulk diffusive behavior and must be excluded from a linear fit.\n4.  **Sampling strategy:** For fitting purposes, especially on a log-log plot to diagnose a power-law regime, using logarithmically spaced points for $k$ is more efficient than linear spacing. It provides better resolution at short times where curvature is high and avoids oversampling the long-time linear region.\n\n### Evaluation of Options\n\n**A. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-k)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and select a set of lags by requiring a minimum number of time-origin pairs per lag, $M-k \\ge M_{\\min}$ with $M_{\\min}$ chosen to ensure adequate statistics (for example $M_{\\min} \\approx 50$ to $100$), while restricting to the window where the process is diffusive: exclude small $k$ that lie in the ballistic regime and large $k$ where confinement or drift induces deviations. For stable regression of the diffusion coefficient from the linear regime, use logarithmically spaced $k$ or adaptively choose $k$ so that the effective number of pairs is approximately constant across lags.**\n\nThis option presents the correct, unbiased estimator with the normalization factor $1/(N(M-k))$. The proposed procedure for selecting lags is exemplary. It correctly identifies the need to exclude the short-time ballistic regime and the long-time regime, which is corrupted by poor statistics and/or physical confinement effects. The suggestion of a minimum number of samples ($M-k \\ge M_{\\min}$) is sound statistical practice to control variance. The use of logarithmically spaced points is a standard and effective technique for regression analysis of such data.\n\n**Verdict: Correct.**\n\n**B. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,M} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and take all lags $k \\in \\{1,2,\\dots,M-1\\}$ with uniform linear spacing, since ergodicity ensures unbiasedness for any $k$ and larger $k$ improve the estimate by covering longer times.**\n\nThe estimator formula is flawed. The normalization factor is $1/(NM)$. The expectation of this estimator is $E[\\dots] = \\frac{M-k}{M} \\langle \\Delta r^2(\\tau_k) \\rangle$. This is a biased estimator that systematically underestimates the true MSD, with the bias increasing with $k$. The procedure is also flawed: using all lags up to $M-1$ ignores the catastrophic increase in statistical noise at large $k$. The justification that \"ergodicity ensures unbiasedness\" is incorrect for this specific biased estimator.\n\n**Verdict: Incorrect.**\n\n**C. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-1)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and prioritize the largest possible lags, $k$ close to $M-1$, because they emphasize the diffusive regime and reduce the influence of the ballistic regime; use all available $k$ without exclusion to avoid selection bias.**\n\nThe estimator formula is flawed. The normalization factor $1/(N(M-1))$ leads to a biased estimator with expectation $E[\\dots] = \\frac{M-k}{M-1} \\langle \\Delta r^2(\\tau_k) \\rangle$. The proposed procedure is scientifically unsound. Prioritizing the largest lags ($k \\to M-1$) is exactly the wrong strategy, as these points have the lowest statistical quality (fewest samples). Using all $k$ without exclusion incorrectly mixes data from physically distinct regimes (ballistic, diffusive, confined) and statistically unreliable regions.\n\n**Verdict: Incorrect.**\n\n**D. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\|\\mathbf{r}_i(t_{k}) - \\mathbf{r}_i(t_{0})\\right\\|^2,$ to avoid correlation among overlapping time origins, and choose nonoverlapping lags $k$ as large as possible (for example, powers of $2$ up to $M-1$) so that each lag uses a distinct set of frames and thus eliminates bias from time-origin reuse.**\n\nThis estimator is unbiased, as it uses a valid time interval. However, it is statistically extremely inefficient because it uses only a single time origin ($t_0$) per trajectory, discarding all other $M-k-1$ possible time origins. This leads to an estimator with a much higher variance compared to the estimator in option A. The rationale of \"avoiding correlation\" is misguided; while the individual squared displacements from overlapping time origins are correlated, averaging over them (as in option A) is the standard and correct way to reduce the variance of the final estimate. Discarding data to obtain uncorrelated samples is a poor statistical trade-off that dramatically worsens the precision of the result.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Experimental measurements are not instantaneous, and this finite observation time can distort the data, an effect known as motion blur. This practice challenges you to mathematically model the impact of a finite camera exposure time on the observed MSD of a diffusing particle . Understanding this effect is critical for correctly interpreting data from single-particle tracking microscopy and avoiding mischaracterization of short-time dynamics.",
            "id": "3778555",
            "problem": "A point particle undergoes overdamped Brownian motion in $d$ spatial dimensions with diffusion coefficient $D$ (units of $\\mathrm{length}^2/\\mathrm{time}$). Its true position is $x(t) \\in \\mathbb{R}^d$, modeled as $d$ independent coordinates of a Wiener process with zero mean and covariance $\\mathbb{E}[x_i(t)x_i(s)] = 2 D \\min\\{t,s\\}$ for each coordinate $i \\in \\{1,\\dots,d\\}$, starting at the origin. A camera acquires images with finite exposure time $\\Delta  0$, so that the recorded position at time $t$ is the exposure average\n$$\n\\overline{x}(t) \\;=\\; \\frac{1}{\\Delta} \\int_{t}^{t+\\Delta} x(u) \\,\\mathrm{d}u.\n$$\nDefine the measured mean squared displacement (MSD) at lag $\\tau \\ge 0$ as\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) \\;=\\; \\mathbb{E}\\big[ \\|\\overline{x}(t+\\tau) - \\overline{x}(t)\\|^2 \\big],\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm, and the expectation is taken over the ensemble of Brownian trajectories. Assume there is no additional localization error and that the measurement process is otherwise ideal.\n\nStarting only from the defining properties of Brownian motion and the exposure-averaging measurement model above, derive a closed-form expression for $M_{\\mathrm{obs}}(\\tau;\\Delta)$ valid for all $\\tau \\ge 0$ and $\\Delta  0$. Your result must explicitly exhibit how finite exposure time $\\Delta$ attenuates the short-lag behavior relative to the unblurred MSD and must be expressed as a single analytic expression (it may be piecewise in $\\tau/\\Delta$). Express your final answer in terms of $D$, $d$, $\\tau$, and $\\Delta$, and do not include units in the final answer.",
            "solution": "The problem asks for the derivation of the measured mean squared displacement (MSD) for a particle undergoing $d$-dimensional Brownian motion, where the position is measured by averaging over a finite exposure time $\\Delta$.\n\nThe true position of the particle at time $t$ is given by $x(t) \\in \\mathbb{R}^d$. The motion in each of the $d$ spatial dimensions is modeled as an independent Wiener process, $x_i(t)$, starting from the origin, $x_i(0)=0$. The process has zero mean, $\\mathbb{E}[x_i(t)]=0$, and a specified covariance function $\\mathbb{E}[x_i(t)x_i(s)] = 2D \\min\\{t,s\\}$, where $D$ is the diffusion coefficient.\n\nThe measured position, $\\overline{x}(t)$, is the time average of the true position over an interval of duration $\\Delta$:\n$$\n\\overline{x}(t) = \\frac{1}{\\Delta} \\int_{t}^{t+\\Delta} x(u) \\, \\mathrm{d}u\n$$\nThe measured MSD, $M_{\\mathrm{obs}}(\\tau;\\Delta)$, is defined as the expectation of the squared displacement of the measured position over a lag time $\\tau \\ge 0$:\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) = \\mathbb{E}\\big[ \\|\\overline{x}(t+\\tau) - \\overline{x}(t)\\|^2 \\big]\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm.\n\nSince the $d$ coordinates $x_i(t)$ are independent and identically distributed, the measured coordinates $\\overline{x}_i(t)$ are also independent and identically distributed. The squared Euclidean norm is the sum of the squares of the components: $\\|\\mathbf{v}\\|^2 = \\sum_{i=1}^d v_i^2$. By linearity of expectation, the total MSD is $d$ times the MSD for a single coordinate:\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) = \\sum_{i=1}^d \\mathbb{E}\\big[ (\\overline{x}_i(t+\\tau) - \\overline{x}_i(t))^2 \\big] = d \\cdot \\mathbb{E}\\big[ (\\overline{x}_1(t+\\tau) - \\overline{x}_1(t))^2 \\big]\n$$\nLet's denote the one-dimensional position as $x(t)$ (dropping the subscript $i$) and the one-dimensional measured MSD as $M_{\\mathrm{obs},1D}(\\tau;\\Delta)$. The quantity we need to compute, $\\mathbb{E}[(\\overline{x}(t+\\tau) - \\overline{x}(t))^2]$, should be independent of the absolute time $t$ because the underlying Wiener process has stationary increments. To formally show this, let $x_t(s) = x(t+s) - x(t)$. The process $x_t(s)$ is also a Wiener process with the same statistics as $x(s)$. We can write:\n$$\n\\overline{x}(t+\\tau) - \\overline{x}(t) = \\frac{1}{\\Delta} \\left( \\int_{t+\\tau}^{t+\\tau+\\Delta} x(u) \\, \\mathrm{d}u - \\int_{t}^{t+\\Delta} x(u) \\, \\mathrm{d}u \\right)\n$$\nBy changing the integration variable to $s=u-t$, we get:\n$$\n\\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} x(t+s) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} x(t+s) \\, \\mathrm{d}s \\right) = \\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} (x_t(s)+x(t)) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} (x_t(s)+x(t)) \\, \\mathrm{d}s \\right)\n$$\n$$\n= \\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} x_t(s) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} x_t(s) \\, \\mathrm{d}s \\right)\n$$\nThe expectation of the square of this quantity depends only on the statistics of $x_t(s)$, which are independent of $t$. Thus, we can set $t=0$ for simplicity in our calculation.\n\nLet $M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\mathbb{E}\\left[ \\left( \\frac{1}{\\Delta} \\int_{\\tau}^{\\tau+\\Delta} x(u) \\, \\mathrm{d}u - \\frac{1}{\\Delta} \\int_{0}^{\\Delta} x(v) \\, \\mathrm{d}v \\right)^2 \\right]$.\nLet $I_1 = \\int_{0}^{\\Delta} x(v) \\, \\mathrm{d}v$ and $I_2 = \\int_{\\tau}^{\\tau+\\Delta} x(u) \\, \\mathrm{d}u$.\n$$\nM_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\mathbb{E}[(I_2 - I_1)^2] = \\frac{1}{\\Delta^2} \\left( \\mathbb{E}[I_2^2] - 2\\mathbb{E}[I_1 I_2] + \\mathbb{E}[I_1^2] \\right)\n$$\nWe need to calculate the expectation of products of these integrals. We can use the general covariance of the integrated Wiener process. Let $f(t_1, t_2) = \\mathbb{E}\\left[ \\left(\\int_0^{t_1} x(u)\\,\\mathrm{d}u\\right) \\left(\\int_0^{t_2} x(v)\\,\\mathrm{d}v\\right) \\right]$.\n$$\nf(t_1, t_2) = \\int_0^{t_1} \\int_0^{t_2} \\mathbb{E}[x(u)x(v)] \\, \\mathrm{d}u \\, \\mathrm{d}v = \\int_0^{t_1} \\int_0^{t_2} 2D\\min(u,v) \\, \\mathrm{d}u \\, \\mathrm{d}v\n$$\nAssuming $t_1 \\le t_2$, the calculation yields:\n$$\nf(t_1, t_2) = 2D \\left( \\frac{t_1^2 t_2}{2} - \\frac{t_1^3}{6} \\right) = D \\left( t_1^2 t_2 - \\frac{t_1^3}{3} \\right)\n$$\nNow we compute the terms for the MSD expression.\n$\\mathbb{E}[I_1^2] = \\mathbb{E}[(\\int_0^\\Delta x(v) \\mathrm{d}v)^2] = f(\\Delta, \\Delta) = D(\\Delta^3 - \\frac{\\Delta^3}{3}) = \\frac{2D\\Delta^3}{3}$.\n\n$I_2 = \\int_0^{\\tau+\\Delta} x(u) \\mathrm{d}u - \\int_0^\\tau x(u) \\mathrm{d}u$.\n$\\mathbb{E}[I_2^2] = \\mathbb{E}[ (\\int_0^{\\tau+\\Delta} x(u)\\mathrm{d}u - \\int_0^\\tau x(u)\\mathrm{d}u)^2 ]$\n$= f(\\tau+\\Delta, \\tau+\\Delta) - 2f(\\tau, \\tau+\\Delta) + f(\\tau, \\tau)$.\nSince $\\tau \\le \\tau+\\Delta$, we use $t_1=\\tau, t_2=\\tau+\\Delta$ in the formula for $f$.\n$\\mathbb{E}[I_2^2] = \\frac{2D(\\tau+\\Delta)^3}{3} - 2D\\left( \\tau^2(\\tau+\\Delta) - \\frac{\\tau^3}{3} \\right) + \\frac{2D\\tau^3}{3}$\n$= \\frac{2D}{3}(\\tau^3+3\\tau^2\\Delta+3\\tau\\Delta^2+\\Delta^3) - 2D\\tau^3 - 2D\\tau^2\\Delta + \\frac{2D\\tau^3}{3} + \\frac{2D\\tau^3}{3}$\n$= 2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}$.\n\n$\\mathbb{E}[I_1 I_2] = \\mathbb{E}[ (\\int_0^\\Delta x(v)\\mathrm{d}v) (\\int_0^{\\tau+\\Delta} x(u)\\mathrm{d}u - \\int_0^\\tau x(u)\\mathrm{d}u) ]$\n$= f(\\Delta, \\tau+\\Delta) - f(\\Delta, \\tau)$.\nSince $\\Delta  \\tau+\\Delta$ (for $\\tau  0$), we have $f(\\Delta, \\tau+\\Delta) = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3})$.\nThe calculation of $f(\\Delta, \\tau)$ depends on whether $\\tau  \\Delta$ or $\\tau \\ge \\Delta$.\n\nCase 1: $\\tau \\ge \\Delta$.\nIn this case, $\\min(\\Delta, \\tau) = \\Delta$.\n$f(\\Delta, \\tau) = D(\\Delta^2\\tau - \\frac{\\Delta^3}{3})$.\n$\\mathbb{E}[I_1 I_2] = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3}) - D(\\Delta^2\\tau - \\frac{\\Delta^3}{3}) = D\\Delta^3$.\nNow, assemble the 1D MSD for $\\tau \\ge \\Delta$:\n$M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\left[ \\left(2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}\\right) - 2(D\\Delta^3) + \\frac{2D\\Delta^3}{3} \\right]$\n$= \\frac{1}{\\Delta^2} \\left[ 2D\\tau\\Delta^2 - \\frac{2D\\Delta^3}{3} \\right] = 2D\\tau - \\frac{2D\\Delta}{3} = 2D\\left(\\tau - \\frac{\\Delta}{3}\\right)$.\n\nCase 2: $0 \\le \\tau  \\Delta$.\nIn this case, $\\min(\\Delta, \\tau) = \\tau$.\n$f(\\Delta, \\tau) = D(\\tau^2\\Delta - \\frac{\\tau^3}{3})$.\n$\\mathbb{E}[I_1 I_2] = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3}) - D(\\tau^2\\Delta - \\frac{\\tau^3}{3}) = D\\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right)$.\nNow, assemble the 1D MSD for $0 \\le \\tau  \\Delta$:\n$M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\left[ \\left(2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}\\right) - 2D\\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right) + \\frac{2D\\Delta^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left[ \\left(\\tau\\Delta^2 + \\frac{\\Delta^3}{3}\\right) - \\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right) + \\frac{\\Delta^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left[ \\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau\\Delta^2 - \\frac{2\\Delta^3}{3} + \\tau^2\\Delta - \\frac{\\tau^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left( \\tau^2\\Delta - \\frac{\\tau^3}{3} \\right) = 2D \\left( \\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2} \\right)$.\n\nCombining the results for the $d$-dimensional case by multiplying by $d$:\nFor $\\tau \\ge \\Delta$:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) = 2Dd\\left(\\tau - \\frac{\\Delta}{3}\\right)$.\nFor $0 \\le \\tau  \\Delta$:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) = 2Dd\\left(\\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2}\\right) = 2Dd\\tau \\frac{\\tau}{\\Delta} \\left(1 - \\frac{\\tau}{3\\Delta}\\right)$.\n\nThis piecewise expression is the final result. For large lag times $\\tau \\gg \\Delta$, the measured MSD approaches the true MSD, $2Dd\\tau$, but with a negative offset $-2Dd\\Delta/3$. For short lag times $\\tau \\ll \\Delta$, the measured MSD grows quadratically with $\\tau$ as $M_{\\mathrm{obs}} \\approx 2Dd\\tau^2/\\Delta$, a stark deviation from the linear dependence of the true MSD. This quadratic scaling is a signature of motion-blurring artifacts in MSD analysis.\n\nThe final expression is:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) =\n\\begin{cases}\n2Dd \\left( \\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2} \\right)  \\text{if } 0 \\le \\tau  \\Delta \\\\\n2Dd \\left( \\tau - \\frac{\\Delta}{3} \\right)  \\text{if } \\tau \\ge \\Delta\n\\end{cases}$",
            "answer": "$$\n\\boxed{\n2Dd \\times\n\\begin{cases}\n\\tau - \\frac{\\Delta}{3}  \\text{if } \\tau \\ge \\Delta \\\\\n\\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2}  \\text{if } 0 \\le \\tau  \\Delta\n\\end{cases}\n}\n$$"
        },
        {
            "introduction": "Ideal models often assume measurement noise is random and uncorrelated, but real instruments can introduce systematic, correlated errors. This problem explores how such temporally correlated localization errors affect the measured MSD, revealing a distinct signature compared to simple diffusion . You will also derive a key diagnostic, the covariance of successive increments, which allows experimentalists to test for and identify these subtle but important artifacts.",
            "id": "3778525",
            "problem": "A single-particle trajectory is acquired at uniform sampling interval $\\Delta t$, yielding the discrete observed positions $x_{k}^{\\text{obs}}$ at times $t_{k} = k \\Delta t$ for integer $k$. The true particle dynamics are one-dimensional Brownian motion with diffusion coefficient $D$, so that successive true increments are independent and, over a lag of $\\ell$ steps, the mean squared displacement (MSD) of the true motion satisfies the defining relation $\\mathbb{E}\\!\\left[(x_{k+\\ell} - x_{k})^{2}\\right]$ that depends only on $D$, $\\Delta t$, and $\\ell$. The measurement process is affected by pixel cross-talk that induces temporally correlated localization errors modeled as a zero-mean, stationary, Gaussian, Auto-Regressive of order one (AR(1)) process $\\varepsilon_{k}$, independent of the true motion, with autocovariance $\\gamma(m) = \\mathbb{E}[\\varepsilon_{k} \\varepsilon_{k+m}] = \\sigma^{2} \\varphi^{|m|}$ for integers $m$, where $|\\varphi|  1$ and $\\sigma^{2} = \\mathbb{E}[\\varepsilon_{k}^{2}]$. The observed positions satisfy $x_{k}^{\\text{obs}} = x_{k} + \\varepsilon_{k}$.\n\nUsing only the definitions of the Mean Squared Displacement (MSD) and covariance, along with the independence between the true motion and the measurement errors, derive how the correlated localization errors alter the observed MSD at lag $\\ell$, that is, derive a closed-form expression for\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) \\equiv \\mathbb{E}\\!\\left[\\left(x_{k+\\ell}^{\\text{obs}} - x_{k}^{\\text{obs}}\\right)^{2}\\right]\n$$\nin terms of $D$, $\\Delta t$, $\\sigma^{2}$, $\\varphi$, and $\\ell$. Then, propose a diagnostic for correlated localization errors based on the covariance of successive observed increments, and derive a closed-form expression for\n$$\nC_{\\text{inc}} \\equiv \\operatorname{Cov}\\!\\left(\\Delta x_{k}^{\\text{obs}}, \\Delta x_{k+1}^{\\text{obs}}\\right),\n$$\nwhere $\\Delta x_{k}^{\\text{obs}} \\equiv x_{k+1}^{\\text{obs}} - x_{k}^{\\text{obs}}$.\n\nYour final answer must be a single closed-form analytic expression or a single row matrix of closed-form analytic expressions. No rounding is required.",
            "solution": "The problem is validated as scientifically sound, well-posed, and objective. All necessary information is provided, and the concepts are standard in statistical physics and time series analysis.\n\nThe problem asks for two derivations. First, the expression for the observed Mean Squared Displacement (MSD), $\\operatorname{MSD}_{\\text{obs}}(\\ell)$. Second, the expression for the covariance of successive observed increments, $C_{\\text{inc}}$.\n\nLet us begin with the derivation of $\\operatorname{MSD}_{\\text{obs}}(\\ell)$. The definition is given as:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) \\equiv \\mathbb{E}\\!\\left[\\left(x_{k+\\ell}^{\\text{obs}} - x_{k}^{\\text{obs}}\\right)^{2}\\right]\n$$\nThe observed position is $x_{j}^{\\text{obs}} = x_{j} + \\varepsilon_{j}$, where $x_j$ is the true position and $\\varepsilon_j$ is the measurement error at time $t_j$. Substituting this into the definition:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) = \\mathbb{E}\\!\\left[\\left( (x_{k+\\ell} + \\varepsilon_{k+\\ell}) - (x_{k} + \\varepsilon_{k}) \\right)^{2}\\right]\n$$\nWe can rearrange the terms inside the expectation:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) = \\mathbb{E}\\!\\left[\\left( (x_{k+\\ell} - x_{k}) + (\\varepsilon_{k+\\ell} - \\varepsilon_{k}) \\right)^{2}\\right]\n$$\nExpanding the squared term, we get:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) = \\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_{k})^2 + 2(x_{k+\\ell} - x_k)(\\varepsilon_{k+\\ell} - \\varepsilon_k) + (\\varepsilon_{k+\\ell} - \\varepsilon_k)^2 \\right]\n$$\nUsing the linearity of the expectation operator, we can separate this into three terms:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) = \\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_{k})^2 \\right] + 2\\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_k)(\\varepsilon_{k+\\ell} - \\varepsilon_k) \\right] + \\mathbb{E}\\!\\left[ (\\varepsilon_{k+\\ell} - \\varepsilon_k)^2 \\right]\n$$\nLet's analyze each term individually.\nThe first term, $\\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_{k})^2 \\right]$, is the definition of the true MSD of the particle. For one-dimensional Brownian motion with diffusion coefficient $D$, the MSD is linear with the time lag, $\\tau = t_{k+\\ell} - t_k = \\ell \\Delta t$. Thus, this term is:\n$$\n\\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_{k})^2 \\right] = 2D(\\ell \\Delta t)\n$$\nThe second term is a cross-term involving both the true motion and the measurement error. The problem states that the true motion $\\{x_k\\}$ and the error process $\\{\\varepsilon_k\\}$ are independent. This implies that any function of $\\{x_k\\}$ is independent of any function of $\\{\\varepsilon_k\\}$. Therefore, the expectation of their product is the product of their expectations:\n$$\n\\mathbb{E}\\!\\left[ (x_{k+\\ell} - x_k)(\\varepsilon_{k+\\ell} - \\varepsilon_k) \\right] = \\mathbb{E}\\!\\left[ x_{k+\\ell} - x_k \\right] \\mathbb{E}\\!\\left[ \\varepsilon_{k+\\ell} - \\varepsilon_k \\right]\n$$\nFor Brownian motion, the expectation of an increment is zero: $\\mathbb{E}\\!\\left[ x_{k+\\ell} - x_k \\right] = 0$. The error process $\\varepsilon_k$ is zero-mean, so $\\mathbb{E}\\!\\left[ \\varepsilon_{k+\\ell} - \\varepsilon_k \\right] = \\mathbb{E}[\\varepsilon_{k+\\ell}] - \\mathbb{E}[\\varepsilon_k] = 0 - 0 = 0$. Consequently, the entire cross-term is zero.\n\nThe third term, $\\mathbb{E}\\!\\left[ (\\varepsilon_{k+\\ell} - \\varepsilon_k)^2 \\right]$, represents the contribution from the correlated noise. We expand it:\n$$\n\\mathbb{E}\\!\\left[ (\\varepsilon_{k+\\ell} - \\varepsilon_k)^2 \\right] = \\mathbb{E}\\!\\left[ \\varepsilon_{k+\\ell}^2 - 2\\varepsilon_{k+\\ell}\\varepsilon_k + \\varepsilon_k^2 \\right] = \\mathbb{E}[\\varepsilon_{k+\\ell}^2] - 2\\mathbb{E}[\\varepsilon_{k+\\ell}\\varepsilon_k] + \\mathbb{E}[\\varepsilon_k^2]\n$$\nThe error process is stationary, so the variance at any time is constant: $\\mathbb{E}[\\varepsilon_j^2] = \\sigma^2$ for any $j$. The term $\\mathbb{E}[\\varepsilon_{k+\\ell}\\varepsilon_k]$ is the autocovariance of the error process at a lag of $\\ell$ steps, given by $\\gamma(\\ell) = \\sigma^2 \\varphi^{|\\ell|}$. Since $\\ell$ is a non-negative integer representing the lag, $|\\ell|=\\ell$.\nSubstituting these into the expression for the third term:\n$$\n\\mathbb{E}\\!\\left[ (\\varepsilon_{k+\\ell} - \\varepsilon_k)^2 \\right] = \\sigma^2 - 2(\\sigma^2 \\varphi^{\\ell}) + \\sigma^2 = 2\\sigma^2 - 2\\sigma^2 \\varphi^{\\ell} = 2\\sigma^2(1 - \\varphi^{\\ell})\n$$\nCombining all three terms, we obtain the final expression for the observed MSD:\n$$\n\\operatorname{MSD}_{\\text{obs}}(\\ell) = 2D\\ell\\Delta t + 2\\sigma^2(1 - \\varphi^{\\ell})\n$$\nNext, we derive the expression for $C_{\\text{inc}}$, the covariance of successive observed increments. The diagnostic for correlated errors is that this covariance will be non-zero and will depend on the correlation parameter $\\varphi$. For ideal Brownian motion, successive increments are independent, so their covariance is zero. Any deviation from zero in the observed data indicates the presence of measurement error.\nThe definition is:\n$$\nC_{\\text{inc}} \\equiv \\operatorname{Cov}\\!\\left(\\Delta x_{k}^{\\text{obs}}, \\Delta x_{k+1}^{\\text{obs}}\\right) = \\mathbb{E}\\!\\left[\\Delta x_{k}^{\\text{obs}} \\Delta x_{k+1}^{\\text{obs}}\\right] - \\mathbb{E}\\!\\left[\\Delta x_{k}^{\\text{obs}}\\right]\\mathbb{E}\\!\\left[\\Delta x_{k+1}^{\\text{obs}}\\right]\n$$\nwhere $\\Delta x_{j}^{\\text{obs}} = x_{j+1}^{\\text{obs}} - x_{j}^{\\text{obs}}$. First, let's find the expectation of an observed increment:\n$$\n\\mathbb{E}\\!\\left[\\Delta x_{j}^{\\text{obs}}\\right] = \\mathbb{E}\\!\\left[ (x_{j+1} - x_j) + (\\varepsilon_{j+1} - \\varepsilon_j) \\right] = \\mathbb{E}[x_{j+1} - x_j] + \\mathbb{E}[\\varepsilon_{j+1} - \\varepsilon_j] = 0 + 0 = 0\n$$\nSince the increments have zero mean, the covariance simplifies to the expectation of the product:\n$$\nC_{\\text{inc}} = \\mathbb{E}\\!\\left[\\Delta x_{k}^{\\text{obs}} \\Delta x_{k+1}^{\\text{obs}}\\right]\n$$\nSubstitute the definitions of the increments:\n$$\n\\Delta x_{k}^{\\text{obs}} = (x_{k+1} - x_k) + (\\varepsilon_{k+1} - \\varepsilon_k)\n$$\n$$\n\\Delta x_{k+1}^{\\text{obs}} = (x_{k+2} - x_{k+1}) + (\\varepsilon_{k+2} - \\varepsilon_{k+1})\n$$\nThen, $C_{\\text{inc}}$ is:\n$$\nC_{\\text{inc}} = \\mathbb{E}\\!\\left[ \\left( (x_{k+1} - x_k) + (\\varepsilon_{k+1} - \\varepsilon_k) \\right) \\left( (x_{k+2} - x_{k+1}) + (\\varepsilon_{k+2} - \\varepsilon_{k+1}) \\right) \\right]\n$$\nExpanding and using the linearity of expectation, we get four terms:\n1. $\\mathbb{E}\\!\\left[ (x_{k+1} - x_k)(x_{k+2} - x_{k+1}) \\right]$: Increments of Brownian motion are independent and zero-mean, so this term is $0$.\n2. $\\mathbb{E}\\!\\left[ (x_{k+1} - x_k)(\\varepsilon_{k+2} - \\varepsilon_{k+1}) \\right]$: Cross-term between independent processes. This is $0$.\n3. $\\mathbb{E}\\!\\left[ (\\varepsilon_{k+1} - \\varepsilon_k)(x_{k+2} - x_{k+1}) \\right]$: Another cross-term. This is $0$.\n4. $\\mathbb{E}\\!\\left[ (\\varepsilon_{k+1} - \\varepsilon_k)(\\varepsilon_{k+2} - \\varepsilon_{k+1}) \\right]$: The contribution from the error process.\n\nThus, $C_{\\text{inc}}$ is determined solely by the error term:\n$$\nC_{\\text{inc}} = \\mathbb{E}\\!\\left[ \\varepsilon_{k+1}\\varepsilon_{k+2} - \\varepsilon_{k+1}^2 - \\varepsilon_k\\varepsilon_{k+2} + \\varepsilon_k\\varepsilon_{k+1} \\right]\n$$\n$$\nC_{\\text{inc}} = \\mathbb{E}[\\varepsilon_{k+1}\\varepsilon_{k+2}] - \\mathbb{E}[\\varepsilon_{k+1}^2] - \\mathbb{E}[\\varepsilon_k\\varepsilon_{k+2}] + \\mathbb{E}[\\varepsilon_k\\varepsilon_{k+1}]\n$$\nUsing the autocovariance function $\\gamma(m) = \\sigma^2 \\varphi^{|m|}$:\n$\\mathbb{E}[\\varepsilon_{k+1}\\varepsilon_{k+2}] = \\gamma(1) = \\sigma^2 \\varphi$\n$\\mathbb{E}[\\varepsilon_{k+1}^2] = \\gamma(0) = \\sigma^2$\n$\\mathbb{E}[\\varepsilon_k\\varepsilon_{k+2}] = \\gamma(2) = \\sigma^2 \\varphi^2$\n$\\mathbb{E}[\\varepsilon_k\\varepsilon_{k+1}] = \\gamma(1) = \\sigma^2 \\varphi$\n\nSubstituting these into the expression for $C_{\\text{inc}}$:\n$$\nC_{\\text{inc}} = \\sigma^2\\varphi - \\sigma^2 - \\sigma^2\\varphi^2 + \\sigma^2\\varphi = 2\\sigma^2\\varphi - \\sigma^2 - \\sigma^2\\varphi^2\n$$\nFactoring out $-\\sigma^2$:\n$$\nC_{\\text{inc}} = -\\sigma^2 (1 - 2\\varphi + \\varphi^2) = -\\sigma^2 (1 - \\varphi)^2\n$$\nThis expression for $C_{\\text{inc}}$ is the second required result. It is always non-positive and its magnitude relative to $-\\sigma^2$ (the value for uncorrelated noise) indicates the nature of the temporal correlation.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2D\\ell\\Delta t + 2\\sigma^{2}(1 - \\varphi^{\\ell})  -\\sigma^{2}(1 - \\varphi)^{2}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}