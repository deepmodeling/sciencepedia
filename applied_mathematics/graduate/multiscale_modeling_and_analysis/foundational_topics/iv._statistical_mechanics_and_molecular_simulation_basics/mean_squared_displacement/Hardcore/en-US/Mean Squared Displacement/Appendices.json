{
    "hands_on_practices": [
        {
            "introduction": "Numerical simulations are indispensable tools for studying stochastic dynamics, but it is crucial to understand how the chosen algorithm impacts the results. This exercise  guides you through an analysis of the Euler-Maruyama scheme, a widely used method for simulating Langevin dynamics. By deriving the exact error in the Mean Squared Displacement for a particle in a harmonic potential, you will gain hands-on experience in quantifying the accuracy of a numerical simulation against its underlying theoretical model.",
            "id": "3778498",
            "problem": "Consider the one-dimensional overdamped Langevin equation describing a particle in a harmonic potential at thermal equilibrium,\n$$\ndX_t=-\\mu\\,\\nabla U(X_t)\\,dt+\\sqrt{2D}\\,dW_t,\n$$\nwhere $X_t\\in\\mathbb{R}$ is the position, $U(x)=\\tfrac{1}{2}\\kappa x^2$ is the potential, $\\mu$ is the mobility, $D$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. Assume the Einstein relation $D=k_B T\\,\\mu$, with $k_B$ the Boltzmann constant and $T$ the absolute temperature, and define $a=\\mu\\kappa0$ so that the equation can be written as\n$$\ndX_t=-a X_t\\,dt+\\sqrt{2D}\\,dW_t.\n$$\nAssume the deterministic initial condition $X_0=0$. The Mean Squared Displacement (MSD) at time $t$ is defined as $\\mathbb{E}[|X_t-X_0|^2]=\\mathbb{E}[X_t^2]$.\n\nNow approximate the dynamics with the Euler–Maruyama (EM) scheme with fixed time step $h0$,\n$$\nX_{n+1}=(1-a h)X_n+\\sqrt{2D}\\,\\Delta W_n,\\quad \\Delta W_n\\sim\\mathcal{N}(0,h)\\ \\text{independent},\n$$\nand consider the MSD at a physical time $t=n h$.\n\nStarting from fundamental definitions and Itô calculus, and using only well-tested formulas (without appealing to pre-derived Ornstein–Uhlenbeck results), do the following:\n- Derive an exact closed-form expression for $\\mathbb{E}[X_t^2]$ for the continuous-time dynamics.\n- Derive an exact closed-form expression for $\\mathbb{E}[X_{n}^2]$ produced by the Euler–Maruyama scheme at $t=n h$.\n- Define the weak error in the MSD at time $t$ as\n$$\n\\Delta_{\\mathrm{MSD}}(t,h)=\\mathbb{E}_{\\mathrm{EM}}[X_t^2]-\\mathbb{E}_{\\mathrm{cont}}[X_t^2],\n$$\nand obtain a single closed-form analytic expression for $\\Delta_{\\mathrm{MSD}}(t,h)$ as a function of $t$, $h$, $a$, and $D$.\n\nYour final answer must be the closed-form expression for $\\Delta_{\\mathrm{MSD}}(t,h)$, expressed only in terms of $t$, $h$, $a$, and $D$. No numerical evaluation or rounding is required. If you choose to check the special case $a=0$ (free diffusion), state any limiting procedures clearly, but the required final answer should remain valid for $a0$.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the theory of stochastic processes, well-posed with all necessary information provided, and objective in its formulation. No inconsistencies, unsound premises, or ambiguities are present.\n\nWe proceed with the derivation in three parts as requested.\n\nFirst, we derive the exact closed-form expression for the Mean Squared Displacement (MSD) of the continuous-time process, $\\mathbb{E}[X_t^2]$. The dynamics are given by the stochastic differential equation (SDE):\n$$\ndX_t = -a X_t dt + \\sqrt{2D} dW_t\n$$\nwith initial condition $X_0=0$. Let $m_2(t) = \\mathbb{E}[X_t^2]$. We derive an ordinary differential equation (ODE) for $m_2(t)$. Using Itô's lemma on the function $f(X_t) = X_t^2$, we have:\n$$\nd(X_t^2) = 2X_t dX_t + \\frac{1}{2}(2)(dX_t)^2 = 2X_t dX_t + (dX_t)^2\n$$\nThe differential $dX_t$ is given by the SDE. The quadratic variation term $(dX_t)^2$ is computed using the rules of Itô calculus, where $(dt)^2=0$, $dt dW_t=0$, and $(dW_t)^2=dt$:\n$$\n(dX_t)^2 = (-a X_t dt + \\sqrt{2D} dW_t)^2 = (-a X_t)^2 (dt)^2 + 2(-a X_t)(\\sqrt{2D}) dt dW_t + (\\sqrt{2D})^2(dW_t)^2 = 2D dt\n$$\nSubstituting these into the expression for $d(X_t^2)$:\n$$\nd(X_t^2) = 2X_t(-a X_t dt + \\sqrt{2D} dW_t) + 2D dt = (-2a X_t^2 + 2D) dt + 2\\sqrt{2D} X_t dW_t\n$$\nTaking the expectation of the integral form of this equation from $0$ to $t$:\n$$\n\\mathbb{E}[X_t^2] - \\mathbb{E}[X_0^2] = \\mathbb{E}\\left[\\int_0^t (-2a X_s^2 + 2D) ds\\right] + \\mathbb{E}\\left[\\int_0^t 2\\sqrt{2D} X_s dW_s\\right]\n$$\nThe expectation of the Itô integral term is zero. Since $X_0=0$, we have $\\mathbb{E}[X_0^2]=0$. By Fubini's theorem, we can swap expectation and time integration:\n$$\nm_2(t) = \\int_0^t (-2a \\mathbb{E}[X_s^2] + 2D) ds = \\int_0^t (-2a m_2(s) + 2D) ds\n$$\nDifferentiating with respect to $t$ gives the ODE for $m_2(t)$:\n$$\n\\frac{dm_2}{dt} = -2a m_2(t) + 2D\n$$\nThis is a first-order linear ODE with the initial condition $m_2(0)=0$. The solution is:\n$$\nm_2(t) = \\frac{D}{a}(1 - \\exp(-2at))\n$$\nThis is the exact MSD for the continuous-time process, which we denote as $\\mathbb{E}_{\\mathrm{cont}}[X_t^2]$.\n\nSecond, we derive the exact closed-form expression for the MSD produced by the Euler–Maruyama (EM) scheme, $\\mathbb{E}[X_n^2]$. The scheme is given by:\n$$\nX_{n+1} = (1-ah)X_n + \\sqrt{2D}\\Delta W_n\n$$\nwith $X_0=0$ and $\\Delta W_n$ being independent random variables distributed as $\\mathcal{N}(0,h)$. Let $m_n = \\mathbb{E}[X_n^2]$. We have $m_0 = \\mathbb{E}[X_0^2]=0$. Squaring the EM equation:\n$$\nX_{n+1}^2 = (1-ah)^2 X_n^2 + 2(1-ah)X_n\\sqrt{2D}\\Delta W_n + 2D(\\Delta W_n)^2\n$$\nTaking the expectation of both sides:\n$$\n\\mathbb{E}[X_{n+1}^2] = (1-ah)^2\\mathbb{E}[X_n^2] + 2(1-ah)\\sqrt{2D}\\mathbb{E}[X_n \\Delta W_n] + 2D\\mathbb{E}[(\\Delta W_n)^2]\n$$\nSince $X_n$ is determined by the increments $\\Delta W_0, \\dots, \\Delta W_{n-1}$, it is independent of $\\Delta W_n$. Thus, $\\mathbb{E}[X_n \\Delta W_n] = \\mathbb{E}[X_n]\\mathbb{E}[\\Delta W_n] = \\mathbb{E}[X_n] \\cdot 0 = 0$. The second moment of the increment is $\\mathbb{E}[(\\Delta W_n)^2] = \\mathrm{Var}(\\Delta W_n) + (\\mathbb{E}[\\Delta W_n])^2 = h + 0^2 = h$. This gives a recurrence relation for $m_n$:\n$$\nm_{n+1} = (1-ah)^2 m_n + 2Dh\n$$\nThis is a linear first-order recurrence relation. Let $C=(1-ah)^2$. The solution with $m_0=0$ is given by the sum of a geometric series:\n$$\nm_n = 2Dh \\sum_{k=0}^{n-1} C^k = 2Dh \\frac{1 - C^n}{1 - C} = 2Dh \\frac{1 - (1-ah)^{2n}}{1 - (1-ah)^2} = 2Dh \\frac{1 - (1-ah)^{2n}}{2ah - a^2h^2}\n$$\nSimplifying the expression gives:\n$$\nm_n = \\frac{2D}{a(2-ah)} (1 - (1-ah)^{2n})\n$$\nTo express this at a physical time $t=nh$, we substitute $n=t/h$:\n$$\n\\mathbb{E}_{\\mathrm{EM}}[X_t^2] = \\frac{2D}{a(2-ah)} (1 - (1-ah)^{2t/h})\n$$\nThis formula is valid for $ah  2$, which is the condition for the numerical scheme to be stable in the second moment.\n\nThird, we compute the weak error in the MSD, $\\Delta_{\\mathrm{MSD}}(t,h) = \\mathbb{E}_{\\mathrm{EM}}[X_t^2] - \\mathbb{E}_{\\mathrm{cont}}[X_t^2]$. Substituting the expressions derived above:\n$$\n\\Delta_{\\mathrm{MSD}}(t,h) = \\frac{2D}{a(2-ah)} (1 - (1-ah)^{2t/h}) - \\frac{D}{a} (1 - \\exp(-2at))\n$$\nTo obtain a single closed-form expression, we combine the terms over a common denominator $a(2-ah)$:\n$$\n\\Delta_{\\mathrm{MSD}}(t,h) = \\frac{2D(1 - (1-ah)^{2t/h}) - D(2-ah)(1 - \\exp(-2at))}{a(2-ah)}\n$$\nLet us expand the numerator:\n$$\nD \\left[ 2\\left(1 - (1-ah)^{2t/h}\\right) - (2-ah)\\left(1 - \\exp(-2at)\\right) \\right]\n$$\n$$\n= D \\left[ 2 - 2(1-ah)^{2t/h} - \\left(2 - 2\\exp(-2at) - ah + ah\\exp(-2at)\\right) \\right]\n$$\n$$\n= D \\left[ 2 - 2(1-ah)^{2t/h} - 2 + 2\\exp(-2at) + ah - ah\\exp(-2at) \\right]\n$$\n$$\n= D \\left[ ah - 2(1-ah)^{2t/h} + (2-ah)\\exp(-2at) \\right]\n$$\nThus, the final expression for the weak error is:\n$$\n\\Delta_{\\mathrm{MSD}}(t,h) = \\frac{D}{a(2-ah)} \\left[ ah - 2(1-ah)^{2t/h} + (2-ah)\\exp(-2at) \\right]\n$$\nThis expression is a function of $t$, $h$, $a$, and $D$ as required.",
            "answer": "$$\n\\boxed{\\frac{D}{a(2-ah)} \\left( ah - 2(1-ah)^{2t/h} + (2-ah)\\exp(-2at) \\right)}\n$$"
        },
        {
            "introduction": "Translating theoretical models to experimental observations requires accounting for the limitations of measurement devices. This practice  tackles the common issue of \"motion blur\" in particle tracking, which arises from finite camera exposure times. By deriving the analytical form of the MSD under these conditions, you will learn to identify the characteristic signatures of motion blur and understand how it can lead to misinterpretation of the underlying diffusion process if not properly addressed.",
            "id": "3778555",
            "problem": "A point particle undergoes overdamped Brownian motion in $d$ spatial dimensions with diffusion coefficient $D$ (units of $\\mathrm{length}^2/\\mathrm{time}$). Its true position is $x(t) \\in \\mathbb{R}^d$, modeled as $d$ independent coordinates of a Wiener process with zero mean and covariance $\\mathbb{E}[x_i(t)x_i(s)] = 2 D \\min\\{t,s\\}$ for each coordinate $i \\in \\{1,\\dots,d\\}$, starting at the origin. A camera acquires images with finite exposure time $\\Delta  0$, so that the recorded position at time $t$ is the exposure average\n$$\n\\overline{x}(t) \\;=\\; \\frac{1}{\\Delta} \\int_{t}^{t+\\Delta} x(u) \\,\\mathrm{d}u.\n$$\nDefine the measured mean squared displacement (MSD) at lag $\\tau \\ge 0$ as\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) \\;=\\; \\mathbb{E}\\big[ \\|\\overline{x}(t+\\tau) - \\overline{x}(t)\\|^2 \\big],\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm, and the expectation is taken over the ensemble of Brownian trajectories. Assume there is no additional localization error and that the measurement process is otherwise ideal.\n\nStarting only from the defining properties of Brownian motion and the exposure-averaging measurement model above, derive a closed-form expression for $M_{\\mathrm{obs}}(\\tau;\\Delta)$ valid for all $\\tau \\ge 0$ and $\\Delta  0$. Your result must explicitly exhibit how finite exposure time $\\Delta$ attenuates the short-lag behavior relative to the unblurred MSD and must be expressed as a single analytic expression (it may be piecewise in $\\tau/\\Delta$). Express your final answer in terms of $D$, $d$, $\\tau$, and $\\Delta$, and do not include units in the final answer.",
            "solution": "The problem asks for the derivation of the measured mean squared displacement (MSD) for a particle undergoing $d$-dimensional Brownian motion, where the position is measured by averaging over a finite exposure time $\\Delta$.\n\nThe true position of the particle at time $t$ is given by $x(t) \\in \\mathbb{R}^d$. The motion in each of the $d$ spatial dimensions is modeled as an independent Wiener process, $x_i(t)$, starting from the origin, $x_i(0)=0$. The process has zero mean, $\\mathbb{E}[x_i(t)]=0$, and a specified covariance function $\\mathbb{E}[x_i(t)x_i(s)] = 2D \\min\\{t,s\\}$, where $D$ is the diffusion coefficient.\n\nThe measured position, $\\overline{x}(t)$, is the time average of the true position over an interval of duration $\\Delta$:\n$$\n\\overline{x}(t) = \\frac{1}{\\Delta} \\int_{t}^{t+\\Delta} x(u) \\, \\mathrm{d}u\n$$\nThe measured MSD, $M_{\\mathrm{obs}}(\\tau;\\Delta)$, is defined as the expectation of the squared displacement of the measured position over a lag time $\\tau \\ge 0$:\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) = \\mathbb{E}\\big[ \\|\\overline{x}(t+\\tau) - \\overline{x}(t)\\|^2 \\big]\n$$\nwhere $\\|\\cdot\\|$ is the Euclidean norm.\n\nSince the $d$ coordinates $x_i(t)$ are independent and identically distributed, the measured coordinates $\\overline{x}_i(t)$ are also independent and identically distributed. The squared Euclidean norm is the sum of the squares of the components: $\\|\\mathbf{v}\\|^2 = \\sum_{i=1}^d v_i^2$. By linearity of expectation, the total MSD is $d$ times the MSD for a single coordinate:\n$$\nM_{\\mathrm{obs}}(\\tau;\\Delta) = \\sum_{i=1}^d \\mathbb{E}\\big[ (\\overline{x}_i(t+\\tau) - \\overline{x}_i(t))^2 \\big] = d \\cdot \\mathbb{E}\\big[ (\\overline{x}_1(t+\\tau) - \\overline{x}_1(t))^2 \\big]\n$$\nLet's denote the one-dimensional position as $x(t)$ (dropping the subscript $i$) and the one-dimensional measured MSD as $M_{\\mathrm{obs},1D}(\\tau;\\Delta)$. The quantity we need to compute, $\\mathbb{E}[(\\overline{x}(t+\\tau) - \\overline{x}(t))^2]$, should be independent of the absolute time $t$ because the underlying Wiener process has stationary increments. To formally show this, let $x_t(s) = x(t+s) - x(t)$. The process $x_t(s)$ is also a Wiener process with the same statistics as $x(s)$. We can write:\n$$\n\\overline{x}(t+\\tau) - \\overline{x}(t) = \\frac{1}{\\Delta} \\left( \\int_{t+\\tau}^{t+\\tau+\\Delta} x(u) \\, \\mathrm{d}u - \\int_{t}^{t+\\Delta} x(u) \\, \\mathrm{d}u \\right)\n$$\nBy changing the integration variable to $s=u-t$, we get:\n$$\n\\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} x(t+s) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} x(t+s) \\, \\mathrm{d}s \\right) = \\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} (x_t(s)+x(t)) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} (x_t(s)+x(t)) \\, \\mathrm{d}s \\right)\n$$\n$$\n= \\frac{1}{\\Delta} \\left( \\int_{\\tau}^{\\tau+\\Delta} x_t(s) \\, \\mathrm{d}s - \\int_{0}^{\\Delta} x_t(s) \\, \\mathrm{d}s \\right)\n$$\nThe expectation of the square of this quantity depends only on the statistics of $x_t(s)$, which are independent of $t$. Thus, we can set $t=0$ for simplicity in our calculation.\n\nLet $M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\mathbb{E}\\left[ \\left( \\frac{1}{\\Delta} \\int_{\\tau}^{\\tau+\\Delta} x(u) \\, \\mathrm{d}u - \\frac{1}{\\Delta} \\int_{0}^{\\Delta} x(v) \\, \\mathrm{d}v \\right)^2 \\right]$.\nLet $I_1 = \\int_{0}^{\\Delta} x(v) \\, \\mathrm{d}v$ and $I_2 = \\int_{\\tau}^{\\tau+\\Delta} x(u) \\, \\mathrm{d}u$.\n$$\nM_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\mathbb{E}[(I_2 - I_1)^2] = \\frac{1}{\\Delta^2} \\left( \\mathbb{E}[I_2^2] - 2\\mathbb{E}[I_1 I_2] + \\mathbb{E}[I_1^2] \\right)\n$$\nWe need to calculate the expectation of products of these integrals. We can use the general covariance of the integrated Wiener process. Let $f(t_1, t_2) = \\mathbb{E}\\left[ \\left(\\int_0^{t_1} x(u)\\,\\mathrm{d}u\\right) \\left(\\int_0^{t_2} x(v)\\,\\mathrm{d}v\\right) \\right]$.\n$$\nf(t_1, t_2) = \\int_0^{t_1} \\int_0^{t_2} \\mathbb{E}[x(u)x(v)] \\, \\mathrm{d}u \\, \\mathrm{d}v = \\int_0^{t_1} \\int_0^{t_2} 2D\\min(u,v) \\, \\mathrm{d}u \\, \\mathrm{d}v\n$$\nAssuming $t_1 \\le t_2$, the calculation yields:\n$$\nf(t_1, t_2) = 2D \\left( \\frac{t_1^2 t_2}{2} - \\frac{t_1^3}{6} \\right) = D \\left( t_1^2 t_2 - \\frac{t_1^3}{3} \\right)\n$$\nNow we compute the terms for the MSD expression.\n$\\mathbb{E}[I_1^2] = \\mathbb{E}[(\\int_0^\\Delta x(v) \\mathrm{d}v)^2] = f(\\Delta, \\Delta) = D(\\Delta^3 - \\frac{\\Delta^3}{3}) = \\frac{2D\\Delta^3}{3}$.\n\n$I_2 = \\int_0^{\\tau+\\Delta} x(u) \\mathrm{d}u - \\int_0^\\tau x(u) \\mathrm{d}u$.\n$\\mathbb{E}[I_2^2] = \\mathbb{E}[ (\\int_0^{\\tau+\\Delta} x(u)\\mathrm{d}u - \\int_0^\\tau x(u)\\mathrm{d}u)^2 ]$\n$= f(\\tau+\\Delta, \\tau+\\Delta) - 2f(\\tau, \\tau+\\Delta) + f(\\tau, \\tau)$.\nSince $\\tau \\le \\tau+\\Delta$, we use $t_1=\\tau, t_2=\\tau+\\Delta$ in the formula for $f$.\n$\\mathbb{E}[I_2^2] = \\frac{2D(\\tau+\\Delta)^3}{3} - 2D\\left( \\tau^2(\\tau+\\Delta) - \\frac{\\tau^3}{3} \\right) + \\frac{2D\\tau^3}{3}$\n$= \\frac{2D}{3}(\\tau^3+3\\tau^2\\Delta+3\\tau\\Delta^2+\\Delta^3) - 2D\\tau^3 - 2D\\tau^2\\Delta + \\frac{2D\\tau^3}{3} + \\frac{2D\\tau^3}{3}$\n$= 2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}$.\n\n$\\mathbb{E}[I_1 I_2] = \\mathbb{E}[ (\\int_0^\\Delta x(v)\\mathrm{d}v) (\\int_0^{\\tau+\\Delta} x(u)\\mathrm{d}u - \\int_0^\\tau x(u)\\mathrm{d}u) ]$\n$= f(\\Delta, \\tau+\\Delta) - f(\\Delta, \\tau)$.\nSince $\\Delta  \\tau+\\Delta$ (for $\\tau  0$), we have $f(\\Delta, \\tau+\\Delta) = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3})$.\nThe calculation of $f(\\Delta, \\tau)$ depends on whether $\\tau  \\Delta$ or $\\tau \\ge \\Delta$.\n\nCase 1: $\\tau \\ge \\Delta$.\nIn this case, $\\min(\\Delta, \\tau) = \\Delta$.\n$f(\\Delta, \\tau) = D(\\Delta^2\\tau - \\frac{\\Delta^3}{3})$.\n$\\mathbb{E}[I_1 I_2] = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3}) - D(\\Delta^2\\tau - \\frac{\\Delta^3}{3}) = D\\Delta^3$.\nNow, assemble the 1D MSD for $\\tau \\ge \\Delta$:\n$M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\left[ \\left(2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}\\right) - 2(D\\Delta^3) + \\frac{2D\\Delta^3}{3} \\right]$\n$= \\frac{1}{\\Delta^2} \\left[ 2D\\tau\\Delta^2 - \\frac{2D\\Delta^3}{3} \\right] = 2D\\tau - \\frac{2D\\Delta}{3} = 2D\\left(\\tau - \\frac{\\Delta}{3}\\right)$.\n\nCase 2: $0 \\le \\tau  \\Delta$.\nIn this case, $\\min(\\Delta, \\tau) = \\tau$.\n$f(\\Delta, \\tau) = D(\\tau^2\\Delta - \\frac{\\tau^3}{3})$.\n$\\mathbb{E}[I_1 I_2] = D(\\Delta^2(\\tau+\\Delta) - \\frac{\\Delta^3}{3}) - D(\\tau^2\\Delta - \\frac{\\tau^3}{3}) = D\\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right)$.\nNow, assemble the 1D MSD for $0 \\le \\tau  \\Delta$:\n$M_{\\mathrm{obs},1D}(\\tau;\\Delta) = \\frac{1}{\\Delta^2} \\left[ \\left(2D\\tau\\Delta^2 + \\frac{2D\\Delta^3}{3}\\right) - 2D\\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right) + \\frac{2D\\Delta^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left[ \\left(\\tau\\Delta^2 + \\frac{\\Delta^3}{3}\\right) - \\left(\\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau^2\\Delta + \\frac{\\tau^3}{3}\\right) + \\frac{\\Delta^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left[ \\tau\\Delta^2 + \\frac{2\\Delta^3}{3} - \\tau\\Delta^2 - \\frac{2\\Delta^3}{3} + \\tau^2\\Delta - \\frac{\\tau^3}{3} \\right]$\n$= \\frac{2D}{\\Delta^2} \\left( \\tau^2\\Delta - \\frac{\\tau^3}{3} \\right) = 2D \\left( \\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2} \\right)$.\n\nCombining the results for the $d$-dimensional case by multiplying by $d$:\nFor $\\tau \\ge \\Delta$:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) = 2Dd\\left(\\tau - \\frac{\\Delta}{3}\\right)$.\nFor $0 \\le \\tau  \\Delta$:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) = 2Dd\\left(\\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2}\\right) = 2Dd\\tau \\frac{\\tau}{\\Delta} \\left(1 - \\frac{\\tau}{3\\Delta}\\right)$.\n\nThis piecewise expression is the final result. For large lag times $\\tau \\gg \\Delta$, the measured MSD approaches the true MSD, $2Dd\\tau$, but with a negative offset $-2Dd\\Delta/3$. For short lag times $\\tau \\ll \\Delta$, the measured MSD grows quadratically with $\\tau$ as $M_{\\mathrm{obs}} \\approx 2Dd\\tau^2/\\Delta$, a stark deviation from the linear dependence of the true MSD. This quadratic scaling is a signature of motion-blurring artifacts in MSD analysis.\n\nThe final expression is:\n$M_{\\mathrm{obs}}(\\tau;\\Delta) =\n\\begin{cases}\n2Dd \\left( \\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2} \\right)  \\text{if } 0 \\le \\tau  \\Delta \\\\\n2Dd \\left( \\tau - \\frac{\\Delta}{3} \\right)  \\text{if } \\tau \\ge \\Delta\n\\end{cases}$",
            "answer": "$$\n\\boxed{\n2Dd \\times\n\\begin{cases}\n\\tau - \\frac{\\Delta}{3}  \\text{if } \\tau \\ge \\Delta \\\\\n\\frac{\\tau^2}{\\Delta} - \\frac{\\tau^3}{3\\Delta^2}  \\text{if } 0 \\le \\tau  \\Delta\n\\end{cases}\n}\n$$"
        },
        {
            "introduction": "Ultimately, the MSD is a quantity computed from data, whether from simulations or experiments. This exercise  focuses on the practical task of constructing a robust statistical estimator for the MSD from a finite set of discrete particle trajectories. You will explore the importance of correct normalization and the strategic selection of time lags to balance statistical uncertainty against systematic biases from different physical regimes, a crucial skill for any quantitative analysis of trajectory data.",
            "id": "3877884",
            "problem": "In molecular dynamics of guest molecules diffusing through a porous catalytic solid, you record discrete trajectories for $N$ particles at uniformly sampled times $t_n = n\\,\\delta t$ with $n \\in \\{0,1,\\dots,M-1\\}$, where $\\delta t$ is the sampling interval and $M$ is the number of stored frames. Let $\\mathbf{r}_i(t_n)$ denote the unwrapped position of particle $i$ at time $t_n$ in $\\mathbb{R}^3$. Assume stationarity and ergodicity of the increments at long times in the diffusive regime, and that the initial conditions are not special beyond those assumptions. The ensemble mean squared displacement at time lag $\\tau$ is defined as $\\langle \\Delta r^2(\\tau)\\rangle = \\left\\langle \\|\\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\|^2 \\right\\rangle$, where the average is taken over particles and time origins. For discrete data, it is customary to consider lags $\\tau_k = k\\,\\delta t$ with $k \\in \\{1,2,\\dots,M-1\\}$.\n\nWhich option gives a correct time-origin-averaged estimator for $\\langle \\Delta r^2(\\tau_k)\\rangle$ from the discrete data and a scientifically sound prescription for selecting the set of time lags $\\{\\tau_k\\}$ to minimize bias associated with finite trajectory length and dynamical crossovers relevant to diffusion in confined catalysts?\n\nA. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-k)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand select a set of lags by requiring a minimum number of time-origin pairs per lag, $M-k \\ge M_{\\min}$ with $M_{\\min}$ chosen to ensure adequate statistics (for example $M_{\\min} \\approx 50$ to $100$), while restricting to the window where the process is diffusive: exclude small $k$ that lie in the ballistic regime and large $k$ where confinement or drift induces deviations. For stable regression of the diffusion coefficient from the linear regime, use logarithmically spaced $k$ or adaptively choose $k$ so that the effective number of pairs is approximately constant across lags.\n\nB. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,M} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand take all lags $k \\in \\{1,2,\\dots,M-1\\}$ with uniform linear spacing, since ergodicity ensures unbiasedness for any $k$ and larger $k$ improve the estimate by covering longer times.\n\nC. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-1)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$\nand prioritize the largest possible lags, $k$ close to $M-1$, because they emphasize the diffusive regime and reduce the influence of the ballistic regime; use all available $k$ without exclusion to avoid selection bias.\n\nD. Use\n$\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\|\\mathbf{r}_i(t_{k}) - \\mathbf{r}_i(t_{0})\\right\\|^2,$\nto avoid correlation among overlapping time origins, and choose nonoverlapping lags $k$ as large as possible (for example, powers of $2$ up to $M-1$) so that each lag uses a distinct set of frames and thus eliminates bias from time-origin reuse.",
            "solution": "The problem statement is scrutinized for validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n-   **System**: Guest molecules diffusing through a porous catalytic solid.\n-   **Simulation Data**: Discrete trajectories for $N$ particles.\n-   **Time Discretization**: Uniformly sampled times $t_n = n\\,\\delta t$ for $n \\in \\{0,1,\\dots,M-1\\}$.\n-   **Position Data**: $\\mathbf{r}_i(t_n)$ is the unwrapped position of particle $i$ at time $t_n$ in $\\mathbb{R}^3$.\n-   **Assumptions**: Stationarity and ergodicity of increments at long times in the diffusive regime.\n-   **Definition**: Ensemble mean squared displacement (MSD) at time lag $\\tau$ is $\\langle \\Delta r^2(\\tau)\\rangle = \\left\\langle \\|\\mathbf{r}(t+\\tau)-\\mathbf{r}(t)\\|^2 \\right\\rangle$. The average is over particles and time origins.\n-   **Discrete Time Lags**: $\\tau_k = k\\,\\delta t$ with $k \\in \\{1,2,\\dots,M-1\\}$.\n-   **Question**: Identify the correct estimator for $\\langle \\Delta r^2(\\tau_k)\\rangle$ from discrete data and the scientifically sound procedure for selecting the set of lags $\\{\\tau_k\\}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is scientifically grounded, describing a standard and fundamental analysis task in computational physics and chemistry: the calculation of the MSD from molecular dynamics trajectories. The terms used—stationarity, ergodicity, ballistic regime, diffusive regime, confinement—are standard concepts in statistical mechanics. The problem is well-posed, asking for a correct statistical estimator and a sound methodological approach, for which there are established best practices. The language is objective and precise. The problem is self-contained and free of contradictions, scientific inaccuracies, or infeasible conditions. It represents a non-trivial challenge in data analysis methodology, specifically the trade-off between statistical bias, variance, and the physical interpretation of different time scales.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. A solution will be derived.\n\n### Derivation and Analysis\n\nThe objective is to find the best estimator, denoted $\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)$, for the true ensemble average $\\langle \\Delta r^2(\\tau_k)\\rangle$. The averaging $\\langle \\dots \\rangle$ is defined over particles and time origins.\n\nFor a finite trajectory of length $M$ frames and a time lag $\\tau_k = k\\,\\delta t$, the number of available, distinct, overlapping time intervals of duration $\\tau_k$ is $M-k$. The time origins are $t_0, t_1, \\dots, t_{M-k-1}$.\n\nFirst, consider a single particle $i$. The time-averaged MSD for this particle is found by averaging the squared displacements over all possible time origins:\n$$ \\text{MSD}_i(\\tau_k) = \\frac{1}{M-k} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 $$\nThe normalization factor $1/(M-k)$ ensures that this is an average over the number of available samples.\n\nTo obtain the full ensemble average, we then average this quantity over the $N$ independent particles:\n$$ \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\text{MSD}_i(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{1}{M-k} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 \\right) $$\nThis can be written as a single combined expression:\n$$ \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N(M-k)} \\sum_{i=1}^{N} \\sum_{n=0}^{M-k-1} \\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2 $$\nAssuming the process increments are stationary, the expectation of this estimator is:\n$$ E\\left[\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)\\right] = \\frac{1}{N(M-k)} \\sum_{i=1}^{N} \\sum_{n=0}^{M-k-1} E\\left[\\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2\\right] $$\nBy stationarity, $E\\left[\\left\\| \\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n) \\right\\|^2\\right] = \\langle \\Delta r^2(\\tau_k)\\rangle$, independent of the time origin $t_n$. Therefore:\n$$ E\\left[\\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k)\\right] = \\frac{N(M-k)}{N(M-k)} \\langle \\Delta r^2(\\tau_k)\\rangle = \\langle \\Delta r^2(\\tau_k)\\rangle $$\nThis confirms that the estimator is unbiased. The normalization by $N(M-k)$ correctly reflects the total number of statistical samples available for the time lag $\\tau_k$.\n\nRegarding the selection of time lags $\\{\\tau_k\\}$, a sound procedure must account for both the physical behavior of the system and statistical limitations:\n1.  **Short-time regime (small $k$):** At very short times, particle motion is ballistic, reflecting its initial velocity, so $\\langle \\Delta r^2(\\tau) \\rangle \\propto \\tau^2$. This regime is not diffusive and must be excluded from any linear fit to extract a diffusion coefficient.\n2.  **Long-time regime (large $k$):** As $k \\to M-1$, the number of samples $M-k$ becomes very small, leading to a large statistical variance in the estimator. The result is increasingly noisy and unreliable. Thus, a cutoff for $k$ is required, e.g., $k \\le M/2$ or more formally $M-k \\ge M_{\\min}$ for some minimum number of statistical samples $M_{\\min}$.\n3.  **Physical long-time effects:** For diffusion in confined media like a catalyst pore, at long times particles begin to encounter the boundaries. This interaction suppresses the growth of the MSD, leading to sub-diffusion or saturation ($\\langle \\Delta r^2(\\tau) \\rangle \\to \\text{constant}$). This region does not reflect the bulk diffusive behavior and must be excluded from a linear fit.\n4.  **Sampling strategy:** For fitting purposes, especially on a log-log plot to diagnose a power-law regime, using logarithmically spaced points for $k$ is more efficient than linear spacing. It provides better resolution at short times where curvature is high and avoids oversampling the long-time linear region.\n\n### Evaluation of Options\n\n**A. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-k)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and select a set of lags by requiring a minimum number of time-origin pairs per lag, $M-k \\ge M_{\\min}$ with $M_{\\min}$ chosen to ensure adequate statistics (for example $M_{\\min} \\approx 50$ to $100$), while restricting to the window where the process is diffusive: exclude small $k$ that lie in the ballistic regime and large $k$ where confinement or drift induces deviations. For stable regression of the diffusion coefficient from the linear regime, use logarithmically spaced $k$ or adaptively choose $k$ so that the effective number of pairs is approximately constant across lags.**\n\nThis option presents the correct, unbiased estimator with the normalization factor $1/(N(M-k))$. The proposed procedure for selecting lags is exemplary. It correctly identifies the need to exclude the short-time ballistic regime and the long-time regime, which is corrupted by poor statistics and/or physical confinement effects. The suggestion of a minimum number of samples ($M-k \\ge M_{\\min}$) is sound statistical practice to control variance. The use of logarithmically spaced points is a standard and effective technique for regression analysis of such data.\n\n**Verdict: Correct.**\n\n**B. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,M} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and take all lags $k \\in \\{1,2,\\dots,M-1\\}$ with uniform linear spacing, since ergodicity ensures unbiasedness for any $k$ and larger $k$ improve the estimate by covering longer times.**\n\nThe estimator formula is flawed. The normalization factor is $1/(NM)$. The expectation of this estimator is $E[\\dots] = \\frac{M-k}{M} \\langle \\Delta r^2(\\tau_k) \\rangle$. This is a biased estimator that systematically underestimates the true MSD, with the bias increasing with $k$. The procedure is also flawed: using all lags up to $M-1$ ignores the catastrophic increase in statistical noise at large $k$. The justification that \"ergodicity ensures unbiasedness\" is incorrect for this specific biased estimator.\n\n**Verdict: Incorrect.**\n\n**C. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N\\,(M-1)} \\sum_{i=1}^{N}\\sum_{n=0}^{M-k-1} \\left\\|\\mathbf{r}_i(t_{n+k}) - \\mathbf{r}_i(t_n)\\right\\|^2,$ and prioritize the largest possible lags, $k$ close to $M-1$, because they emphasize the diffusive regime and reduce the influence of the ballistic regime; use all available $k$ without exclusion to avoid selection bias.**\n\nThe estimator formula is flawed. The normalization factor $1/(N(M-1))$ leads to a biased estimator with expectation $E[\\dots] = \\frac{M-k}{M-1} \\langle \\Delta r^2(\\tau_k) \\rangle$. The proposed procedure is scientifically unsound. Prioritizing the largest lags ($k \\to M-1$) is exactly the wrong strategy, as these points have the lowest statistical quality (fewest samples). Using all $k$ without exclusion incorrectly mixes data from physically distinct regimes (ballistic, diffusive, confined) and statistically unreliable regions.\n\n**Verdict: Incorrect.**\n\n**D. Use $\\displaystyle \\widehat{\\langle \\Delta r^2\\rangle}(\\tau_k) = \\frac{1}{N} \\sum_{i=1}^{N} \\left\\|\\mathbf{r}_i(t_{k}) - \\mathbf{r}_i(t_{0})\\right\\|^2,$ to avoid correlation among overlapping time origins, and choose nonoverlapping lags $k$ as large as possible (for example, powers of $2$ up to $M-1$) so that each lag uses a distinct set of frames and thus eliminates bias from time-origin reuse.**\n\nThis estimator is unbiased, as it uses a valid time interval. However, it is statistically extremely inefficient because it uses only a single time origin ($t_0$) per trajectory, discarding all other $M-k-1$ possible time origins. This leads to an estimator with a much higher variance compared to the estimator in option A. The rationale of \"avoiding correlation\" is misguided; while the individual squared displacements from overlapping time origins are correlated, averaging over them (as in option A) is the standard and correct way to reduce the variance of the final estimate. Discarding data to obtain uncorrelated samples is a poor statistical trade-off that dramatically worsens the precision of the result.\n\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}