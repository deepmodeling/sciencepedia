{
    "hands_on_practices": [
        {
            "introduction": "The first step in mastering temperature control is understanding how to implement a simple feedback mechanism. The Berendsen thermostat provides a classic, intuitive example of weakly coupling a system to an external heat bath. This exercise guides you through the fundamental derivation of its velocity rescaling factor, directly linking the continuous differential equation for temperature relaxation to the discrete algorithm used in a molecular dynamics step . By working through this calculation, you will gain a concrete understanding of how thermostat parameters like the coupling time constant govern the system's response.",
            "id": "5274833",
            "problem": "Consider a constant-number, constant-volume Molecular Dynamics (MD) simulation of a biomolecular system with $N_f$ classical degrees of freedom, where temperature is controlled by a velocity-rescaling weak-coupling thermostat of the Berendsen type. The instantaneous kinetic temperature $T_{\\mathrm{inst}}$ is defined via equipartition as $T_{\\mathrm{inst}} = \\frac{2K}{N_f k_B}$, where $K$ is the total kinetic energy and $k_B$ is the Boltzmann constant. At each MD time step, all velocities are scaled by a common factor $\\alpha$, and positions are advanced according to Newton’s equations of motion.\n\nAssume that the target temperature is $T_0$ and that the thermostat imposes a first-order relaxation of the kinetic temperature governed by the ordinary differential equation $\\frac{dT}{dt} = \\frac{1}{\\tau_T}\\left(T_0 - T\\right)$, where $\\tau_T$ is the thermostat time constant. Enforce consistency between the discrete velocity rescaling $v_i \\mapsto \\alpha v_i$ and a first-order forward-Euler integration of the relaxation equation for $T$ over one MD time step of duration $\\Delta t$.\n\nStarting from the equipartition-based definition of $T_{\\mathrm{inst}}$ and the effect of velocity rescaling on kinetic energy, derive the expression for $\\alpha$ that ensures the one-step discrete update of $T_{\\mathrm{inst}}$ matches the forward-Euler discretization of the relaxation equation. Then, for a single rescaling step with $\\tau_T = 0.1\\,\\mathrm{ps}$, $\\Delta t = 2\\,\\mathrm{fs}$, initial $T_{\\mathrm{inst}} = 320\\,\\mathrm{K}$, and target $T_0 = 300\\,\\mathrm{K}$, compute $\\alpha$ and predict the new instantaneous temperature immediately after rescaling.\n\nRound your numerical results to four significant figures. Express the final temperature in $\\mathrm{K}$. Provide your final answer as a row matrix containing $\\alpha$ and the updated $T_{\\mathrm{inst}}$ after one step.",
            "solution": "The user has provided a well-defined problem from the field of computational statistical mechanics, specifically regarding temperature control in Molecular Dynamics (MD) simulations using a Berendsen thermostat.\n\n### Step 1: Extract Givens\n- System description: Constant-number, constant-volume MD simulation with $N_f$ classical degrees of freedom.\n- Temperature control method: Berendsen-type velocity-rescaling weak-coupling thermostat.\n- Definition of instantaneous temperature: $T_{\\mathrm{inst}} = \\frac{2K}{N_f k_B}$, where $K$ is the total kinetic energy and $k_B$ is the Boltzmann constant.\n- Velocity update: At each time step, all velocities $v_i$ are scaled by a factor $\\alpha$, such that the new velocity is $v_i' = \\alpha v_i$.\n- Target temperature: $T_0$.\n- Relaxation dynamics: The thermostat imposes a first-order relaxation of the kinetic temperature $T$ according to the ordinary differential equation (ODE) $\\frac{dT}{dt} = \\frac{1}{\\tau_T}\\left(T_0 - T\\right)$, where $\\tau_T$ is the thermostat time constant.\n- Time step duration: $\\Delta t$.\n- Consistency requirement: The discrete velocity rescaling must be consistent with a first-order forward-Euler integration of the temperature relaxation ODE over one time step $\\Delta t$.\n- Numerical values for calculation:\n  - Time constant, $\\tau_T = 0.1\\,\\mathrm{ps}$.\n  - Time step, $\\Delta t = 2\\,\\mathrm{fs}$.\n  - Initial instantaneous temperature, $T_{\\mathrm{inst}} = 320\\,\\mathrm{K}$.\n  - Target temperature, $T_0 = 300\\,\\mathrm{K}$.\n- Required output:\n  1. An analytical expression for the scaling factor $\\alpha$.\n  2. The numerical value of $\\alpha$ and the new instantaneous temperature after one rescaling step, with results rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, describing the standard implementation of the Berendsen thermostat, a common algorithm in molecular simulations. The underlying principles—the equipartition theorem and first-order kinetics—are well-established. The problem is well-posed, providing all necessary definitions, equations, and parameters to derive a unique solution. The language is objective and precise. All provided numerical values are physically realistic for a biomolecular simulation. The problem is therefore deemed **valid**.\n\n### Step 3: Derivation and Calculation\n\n#### Part 1: Derivation of the Scaling Factor $\\alpha$\n\nWe are tasked with relating two different views of the temperature change over a single MD time step, $\\Delta t$.\n\nFirst, consider the effect of velocity rescaling on the instantaneous temperature. Let $T$ be the instantaneous temperature at the beginning of the time step. By definition, $T = \\frac{2K}{N_f k_B}$, where $K$ is the total kinetic energy of the system. The kinetic energy is given by $K = \\sum_i \\frac{1}{2} m_i v_i^2$.\n\nThe velocities are rescaled by a factor $\\alpha$, so the new velocities are $v_i' = \\alpha v_i$. The new kinetic energy, $K'$, is:\n$$K' = \\sum_i \\frac{1}{2} m_i (v_i')^2 = \\sum_i \\frac{1}{2} m_i (\\alpha v_i)^2 = \\alpha^2 \\left( \\sum_i \\frac{1}{2} m_i v_i^2 \\right) = \\alpha^2 K$$\nThe new instantaneous temperature, $T'$, is related to the new kinetic energy $K'$:\n$$T' = \\frac{2K'}{N_f k_B} = \\frac{2(\\alpha^2 K)}{N_f k_B} = \\alpha^2 \\left( \\frac{2K}{N_f k_B} \\right)$$\nThus, the temperature change due to velocity rescaling is:\n$$T' = \\alpha^2 T$$\n\nSecond, consider the change in temperature dictated by the relaxation equation, $\\frac{dT}{dt} = \\frac{1}{\\tau_T}(T_0 - T)$. We discretize this ODE using a first-order forward-Euler scheme over a time interval $\\Delta t$. The derivative $\\frac{dT}{dt}$ is approximated as $\\frac{T' - T}{\\Delta t}$, where $T'$ is the temperature at the end of the time step.\n$$\\frac{T' - T}{\\Delta t} \\approx \\frac{1}{\\tau_T}(T_0 - T)$$\nSolving for the new temperature $T'$ gives:\n$$T' \\approx T + \\frac{\\Delta t}{\\tau_T}(T_0 - T)$$\n\nTo ensure consistency, we equate the two expressions for the new temperature $T'$:\n$$\\alpha^2 T = T + \\frac{\\Delta t}{\\tau_T}(T_0 - T)$$\nTo solve for $\\alpha$, we divide by $T$ (assuming $T \\neq 0$, which is a valid physical assumption for a system at finite temperature):\n$$\\alpha^2 = 1 + \\frac{\\Delta t}{\\tau_T}\\left(\\frac{T_0 - T}{T}\\right) = 1 + \\frac{\\Delta t}{\\tau_T}\\left(\\frac{T_0}{T} - 1\\right)$$\nTaking the positive square root (as $\\alpha$ is a scaling factor, typically positive to preserve the direction of velocities) yields the final expression for $\\alpha$:\n$$\\alpha = \\sqrt{1 + \\frac{\\Delta t}{\\tau_T}\\left(\\frac{T_0}{T} - 1\\right)}$$\nThis completes the derivation.\n\n#### Part 2: Numerical Calculation\n\nWe are given the following values:\n- $\\tau_T = 0.1\\,\\mathrm{ps} = 0.1 \\times 10^{-12}\\,\\mathrm{s}$\n- $\\Delta t = 2\\,\\mathrm{fs} = 2 \\times 10^{-15}\\,\\mathrm{s}$\n- Initial temperature, $T = T_{\\mathrm{inst}} = 320\\,\\mathrm{K}$\n- Target temperature, $T_0 = 300\\,\\mathrm{K}$\n\nFirst, we compute the dimensionless ratio $\\frac{\\Delta t}{\\tau_T}$:\n$$\\frac{\\Delta t}{\\tau_T} = \\frac{2 \\times 10^{-15}\\,\\mathrm{s}}{0.1 \\times 10^{-12}\\,\\mathrm{s}} = \\frac{2 \\times 10^{-15}\\,\\mathrm{s}}{1 \\times 10^{-13}\\,\\mathrm{s}} = 2 \\times 10^{-2} = 0.02$$\nNow, substitute this and the temperatures into the expression for $\\alpha^2$:\n$$\\alpha^2 = 1 + 0.02 \\left(\\frac{300\\,\\mathrm{K}}{320\\,\\mathrm{K}} - 1\\right)$$\n$$\\alpha^2 = 1 + 0.02 \\left(0.9375 - 1\\right)$$\n$$\\alpha^2 = 1 + 0.02(-0.0625)$$\n$$\\alpha^2 = 1 - 0.00125$$\n$$\\alpha^2 = 0.99875$$\nNow we calculate $\\alpha$ by taking the square root:\n$$\\alpha = \\sqrt{0.99875} \\approx 0.999374811...$$\nRounding to four significant figures, we get:\n$$\\alpha \\approx 0.9994$$\n\nNext, we predict the new instantaneous temperature, $T'$, immediately after rescaling. We can use the forward-Euler expression for this calculation to avoid propagating rounding error from our calculated $\\alpha$.\n$$T' = T + \\frac{\\Delta t}{\\tau_T}(T_0 - T)$$\n$$T' = 320\\,\\mathrm{K} + 0.02(300\\,\\mathrm{K} - 320\\,\\mathrm{K})$$\n$$T' = 320\\,\\mathrm{K} + 0.02(-20\\,\\mathrm{K})$$\n$$T' = 320\\,\\mathrm{K} - 0.4\\,\\mathrm{K}$$\n$$T' = 319.6\\,\\mathrm{K}$$\nThis result already has four significant figures.\n\nThe two requested values are the scaling factor $\\alpha$ and the new instantaneous temperature $T'$.\n$\\alpha \\approx 0.9994$\n$T' = 319.6\\,\\mathrm{K}$\n\nWe present these results as a row matrix as requested.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.9994 & 319.6 \\end{pmatrix}}$$"
        },
        {
            "introduction": "While simple thermostats like the Berendsen method are effective for bringing a system to a target temperature, they famously fail to generate the correct statistical fluctuations of a true canonical ensemble. To achieve rigorous sampling, more advanced methods are required. This practice delves into the two leading paradigms: stochastic thermostats, represented by the Langevin dynamics, and deterministic thermostats, represented by the Nosé–Hoover method . This challenging exercise requires you to analyze their invariant phase-space densities, contrast their crucial ergodicity properties, and quantify their impact on system dynamics, providing deep insight into the theoretical foundations of modern thermostatting.",
            "id": "3823583",
            "problem": "Consider a $d$-dimensional harmonic system with identical masses $m$ and identical angular frequencies $\\omega$, with configurational coordinates $q \\in \\mathbb{R}^{d}$ and velocities $v \\in \\mathbb{R}^{d}$. The physical Hamiltonian is $H(q,v) = \\frac{m}{2} \\|v\\|^{2} + \\frac{m \\omega^{2}}{2} \\|q\\|^{2}$. The target equilibrium is the canonical (Boltzmann) measure at temperature $T$, with inverse temperature $\\beta = \\frac{1}{k_{B} T}$, where $k_{B}$ is the Boltzmann constant.\n\nTwo thermostatting strategies are used for temperature control:\n\n- The Langevin thermostat is defined by the stochastic differential equations (with the Fluctuation–Dissipation Theorem (FDT) enforced) $\\dot{q} = v$ and $m \\dot{v} = - m \\omega^{2} q - \\gamma m v + \\sqrt{2 \\gamma m k_{B} T} \\, \\eta(t)$, where $\\gamma > 0$ is a scalar friction, and $\\eta(t)$ is a standard Gaussian white noise with zero mean and covariance $\\langle \\eta_{i}(t) \\eta_{j}(t') \\rangle = \\delta_{ij} \\delta(t-t')$ for all indices $i,j \\in \\{1,\\dots,d\\}$.\n- The deterministic Nosé–Hoover (NH) thermostat augments the dynamics with a scalar thermostat variable $\\xi$ and mass parameter $Q > 0$, given by $\\dot{q} = v$, $m \\dot{v} = - m \\omega^{2} q - \\xi m v$, and $\\dot{\\xi} = \\frac{1}{Q} \\left( m \\|v\\|^{2} - d k_{B} T \\right)$.\n\nPart A: Starting from the Fokker–Planck equation for the Langevin dynamics and the Liouville equation for the Nosé–Hoover extended deterministic dynamics, derive the invariant phase-space densities and show that the $(q,v)$-marginal invariant measure for both thermostats is the canonical Gaussian measure proportional to $\\exp(-\\beta H(q,v))$.\n\nPart B: Using first-principles reasoning about the generators of the dynamics, contrast the ergodicity properties of the two thermostats for this $d$-dimensional harmonic system. Argue conditions under which the Langevin thermostat is ergodic and the single-variable Nosé–Hoover thermostat fails to be ergodic for harmonic systems.\n\nPart C: Define the normalized single-mode velocity autocorrelation function $C^{\\mathrm{norm}}(t) = \\frac{\\langle v_{1}(t) v_{1}(0) \\rangle}{\\langle v_{1}^{2}(0) \\rangle}$, where $v_{1}$ denotes any one of the $d$ velocity components (by symmetry all modes are identical). Consider the underdamped regime for the Langevin dynamics, $\\gamma < 2 \\omega$, and the weak-coupling limit of the Nosé–Hoover thermostat, $Q \\to \\infty$, in which the thermostat variable evolves on a much slower timescale than the physical oscillator. In this limit, $C^{\\mathrm{norm}}(t)$ for the Nosé–Hoover thermostat coincides with the Hamiltonian autocorrelation of the unthermostatted harmonic oscillator.\n\nDefine the dynamical fidelity functional\n$$F(\\alpha,\\gamma,\\omega) = \\int_{0}^{\\infty} \\exp(-\\alpha t) \\left[ C^{\\mathrm{norm}}_{\\mathrm{Langevin}}(t) - C^{\\mathrm{norm}}_{\\mathrm{NH}}(t) \\right] \\, dt,$$\nwith a convergence rate parameter $\\alpha > 0$. Starting from the fundamental equations of motion and without invoking any shortcut formulas, derive a closed-form analytic expression for $F(\\alpha,\\gamma,\\omega)$ in the specified regime. The final answer must be a single closed-form expression. No rounding is required, and no units are to be included in the final expression.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded, well-posed, and objective. It presents a standard but advanced problem in computational statistical mechanics, requiring the analysis and comparison of two common thermostatting algorithms. All provided equations and parameters are standard and consistent with the established literature.\n\nThe solution is presented in three parts, as requested by the problem statement.\n\n### Part A: Invariant Phase-Space Densities\n\nThe objective is to derive the stationary probability densities for both the Langevin and Nosé–Hoover dynamics and show that their marginals over the physical phase space $(q,v)$ correspond to the canonical Boltzmann distribution, $\\rho(q,v) \\propto \\exp(-\\beta H(q,v))$.\n\n**Langevin Thermostat**\n\nThe dynamics of the system are described by a set of stochastic differential equations. The time evolution of the probability density function $\\rho(q,v,t)$ is governed by the Fokker–Planck equation. For a state vector $\\mathbf{x} = (q,v)$, the general form of the Fokker-Planck equation is $\\frac{\\partial \\rho}{\\partial t} = -\\nabla \\cdot (\\mathbf{A} \\rho) + \\nabla \\cdot (\\mathbf{D} \\nabla \\rho)$, where $\\mathbf{A}$ is the drift vector and $\\mathbf{D}$ is the diffusion matrix.\n\nFor the given Langevin dynamics, the state vector is $(q_1, \\dots, q_d, v_1, \\dots, v_d)$.\nThe drift components are $\\dot{q}_i = v_i$ and $\\dot{v}_i = -\\omega^2 q_i - \\gamma v_i$.\nThe noise term is only in the $\\dot{v}$ equation. The stochastic force is $F_{\\text{stoch}} = \\frac{1}{m} \\sqrt{2\\gamma m k_B T} \\eta(t)$. The diffusion matrix $\\mathbf{D}$ is related to the covariance of the noise. Here, it is non-zero only in the velocity-velocity block:\n$D_{v_i v_j} = \\frac{1}{2} \\cdot \\frac{1}{m^2} \\cdot (2\\gamma m k_B T) \\delta_{ij} = \\frac{\\gamma k_B T}{m}\\delta_{ij}$. Using $\\beta = \\frac{1}{k_B T}$, this is $D_{v_i v_j} = \\frac{\\gamma}{m\\beta}\\delta_{ij}$.\n\nThe Fokker-Planck equation is:\n$$ \\frac{\\partial \\rho}{\\partial t} = - \\sum_{i=1}^d \\frac{\\partial}{\\partial q_i}(v_i \\rho) - \\sum_{i=1}^d \\frac{\\partial}{\\partial v_i} \\left( (-\\omega^2 q_i - \\gamma v_i) \\rho \\right) + \\sum_{i=1}^d \\frac{\\gamma}{m\\beta} \\frac{\\partial^2 \\rho}{\\partial v_i^2} $$\nWe seek a stationary solution $\\rho_s(q,v)$ where $\\frac{\\partial \\rho_s}{\\partial t} = 0$. Let us test the canonical distribution $\\rho_s(q,v) = Z^{-1} \\exp(-\\beta H(q,v))$, where $H(q,v) = \\frac{m}{2}\\|v\\|^2 + \\frac{m\\omega^2}{2}\\|q\\|^2$.\nThe gradients of $\\rho_s$ are:\n$$ \\nabla_q \\rho_s = -\\beta m \\omega^2 q \\rho_s $$\n$$ \\nabla_v \\rho_s = -\\beta m v \\rho_s $$\nSubstituting these into the stationary Fokker-Planck equation:\n$$ 0 = - \\nabla_q \\cdot (v \\rho_s) - \\nabla_v \\cdot ((-\\omega^2 q - \\gamma v) \\rho_s) + \\frac{\\gamma}{m\\beta} \\nabla_v^2 \\rho_s $$\nLet's evaluate each term:\n1.  $- \\nabla_q \\cdot (v \\rho_s) = -v \\cdot \\nabla_q \\rho_s = -v \\cdot (-\\beta m \\omega^2 q \\rho_s) = \\beta m \\omega^2 (v \\cdot q) \\rho_s$.\n2.  $- \\nabla_v \\cdot ((-\\omega^2 q - \\gamma v) \\rho_s) = -(-\\omega^2 q - \\gamma v) \\cdot \\nabla_v \\rho_s - \\rho_s (\\nabla_v \\cdot (-\\omega^2 q - \\gamma v)) = -(-\\omega^2 q - \\gamma v) \\cdot (-\\beta m v \\rho_s) - \\rho_s (-d\\gamma) = -(\\beta m \\omega^2 (q \\cdot v) + \\beta m \\gamma \\|v\\|^2)\\rho_s + d\\gamma \\rho_s$.\n3.  $\\frac{\\gamma}{m\\beta} \\nabla_v^2 \\rho_s = \\frac{\\gamma}{m\\beta} \\nabla_v \\cdot (\\nabla_v \\rho_s) = \\frac{\\gamma}{m\\beta} \\nabla_v \\cdot (-\\beta m v \\rho_s) = -\\gamma \\nabla_v \\cdot (v\\rho_s) = -\\gamma(d\\rho_s + v \\cdot \\nabla_v \\rho_s) = -\\gamma(d\\rho_s + v \\cdot (-\\beta m v \\rho_s)) = (-d\\gamma + \\beta m \\gamma \\|v\\|^2)\\rho_s$.\n\nSumming the terms:\n$$ \\left( \\beta m \\omega^2 (v \\cdot q) \\right) + \\left( -\\beta m \\omega^2 (q \\cdot v) - \\beta m \\gamma \\|v\\|^2 + d\\gamma \\right) + \\left( -d\\gamma + \\beta m \\gamma \\|v\\|^2 \\right) = 0 $$\nAll terms cancel out. Thus, $\\rho_s(q,v) \\propto \\exp(-\\beta H(q,v))$ is indeed the invariant density. The marginal distribution over $(q,v)$ is this distribution itself.\n\n**Nosé–Hoover Thermostat**\n\nThe Nosé–Hoover dynamics are deterministic in an extended phase space $(q,v,\\xi)$. The time evolution of the probability density $\\rho(q,v,\\xi,t)$ is governed by the Liouville equation for a non-Hamiltonian system:\n$$ \\frac{\\partial \\rho}{\\partial t} + \\nabla_{\\mathbf{x}} \\cdot (\\rho \\dot{\\mathbf{x}}) = 0 $$\nwhere $\\mathbf{x} = (q,v,\\xi)$. For a stationary solution $\\rho_s$, we have $\\nabla_{\\mathbf{x}} \\cdot (\\rho_s \\dot{\\mathbf{x}}) = 0$, which can be written as $\\dot{\\mathbf{x}} \\cdot \\nabla_{\\mathbf{x}}\\rho_s + \\rho_s (\\nabla_{\\mathbf{x}} \\cdot \\dot{\\mathbf{x}}) = 0$.\n\nFirst, we compute the divergence of the flow field $\\nabla_{\\mathbf{x}} \\cdot \\dot{\\mathbf{x}}$:\n$$ \\nabla_{\\mathbf{x}} \\cdot \\dot{\\mathbf{x}} = \\nabla_q \\cdot \\dot{q} + \\nabla_v \\cdot \\dot{v} + \\frac{\\partial \\dot{\\xi}}{\\partial \\xi} $$\nUsing the equations of motion $\\dot{q}=v$, $\\dot{v} = -\\omega^2 q - \\xi v$, $\\dot{\\xi} = \\frac{1}{Q}(m\\|v\\|^2 - dk_B T)$:\n- $\\nabla_q \\cdot v = 0$\n- $\\nabla_v \\cdot (-\\omega^2 q - \\xi v) = \\sum_{i=1}^d \\frac{\\partial}{\\partial v_i}(-\\xi v_i) = -d\\xi$\n- $\\frac{\\partial}{\\partial \\xi} \\left( \\frac{1}{Q}(m\\|v\\|^2 - dk_B T) \\right) = 0$\nSo, $\\nabla_{\\mathbf{x}} \\cdot \\dot{\\mathbf{x}} = -d\\xi$. The stationary Liouville equation becomes:\n$$ \\dot{\\mathbf{x}} \\cdot \\nabla_{\\mathbf{x}}\\rho_s - d\\xi \\rho_s = 0 $$\nWe test the proposed invariant density $\\rho_s(q,v,\\xi) \\propto \\exp(-\\beta H'_{\\mathrm{NH}})$, where $H'_{\\mathrm{NH}} = H(q,v) + \\frac{Q}{2}\\xi^2$. The gradients of $\\rho_s$ are:\n$$ \\nabla_q \\rho_s = -\\beta m \\omega^2 q \\rho_s, \\quad \\nabla_v \\rho_s = -\\beta m v \\rho_s, \\quad \\frac{\\partial \\rho_s}{\\partial \\xi} = -\\beta Q \\xi \\rho_s $$\nSubstituting into the stationary Liouville equation and dividing by $\\rho_s$:\n$$ \\dot{q} \\cdot(-\\beta m \\omega^2 q) + \\dot{v} \\cdot(-\\beta m v) + \\dot{\\xi} \\cdot(-\\beta Q \\xi) - d\\xi = 0 $$\n$$ v \\cdot(-\\beta m \\omega^2 q) + (-\\omega^2 q - \\xi v) \\cdot(-\\beta m v) + \\frac{1}{Q}(m\\|v\\|^2 - dk_B T) \\cdot(-\\beta Q \\xi) - d\\xi = 0 $$\n$$ -\\beta m \\omega^2 (v \\cdot q) + \\beta m \\omega^2 (q \\cdot v) + \\beta m \\xi \\|v\\|^2 - \\beta \\xi (m\\|v\\|^2 - dk_B T) - d\\xi = 0 $$\nThe first two terms cancel. The third term cancels with the first part of the fourth term:\n$$ \\beta \\xi dk_B T - d\\xi = 0 $$\nUsing $\\beta = 1/(k_B T)$, we get $\\frac{1}{k_B T}\\xi d k_B T - d\\xi = d\\xi - d\\xi = 0$. This holds.\nThus, $\\rho_s(q,v,\\xi) \\propto \\exp(-\\beta(H(q,v) + \\frac{Q}{2}\\xi^2))$ is the invariant density in the extended phase space.\n\nTo find the marginal distribution for the physical variables $(q,v)$, we integrate over the thermostat variable $\\xi$:\n$$ \\rho_m(q,v) = \\int_{-\\infty}^{\\infty} \\rho_s(q,v,\\xi)d\\xi \\propto \\exp(-\\beta H(q,v)) \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{\\beta Q}{2}\\xi^2\\right) d\\xi $$\nThe integral with respect to $\\xi$ is a Gaussian integral, which evaluates to a constant $\\sqrt{2\\pi/(\\beta Q)}$. Therefore, the marginal distribution is:\n$$ \\rho_m(q,v) \\propto \\exp(-\\beta H(q,v)) $$\nThis confirms that both thermostats generate the correct canonical distribution for the physical part of the system.\n\n### Part B: Ergodicity Properties\n\nErgodicity requires that a single long-time trajectory of the system explores the entire accessible phase space consistent with the conserved quantities, such that time averages equal ensemble averages.\n\n**Langevin Thermostat**\nThe generator of the Langevin dynamics is the Fokker-Planck operator. The dynamics include both a dissipative term ($-\\gamma m v$) and a stochastic fluctuation term ($\\sqrt{2 \\gamma m k_{B} T} \\, \\eta(t)$). The stochastic term, being a Gaussian white noise, acts as a random driving force on all velocity components. This perpetual random \"kicking\" prevents the system from being trapped in any lower-dimensional submanifold of the phase space. The combination of dissipation and fluctuation drives the system towards a unique stationary state (the canonical distribution) and ensures that all regions of the phase space with non-zero probability density are visited over time. Therefore, for any friction coefficient $\\gamma > 0$, the Langevin dynamics for the harmonic system are ergodic with respect to the canonical measure.\n\n**Nosé–Hoover Thermostat**\nThe generator of the Nosé–Hoover dynamics is the Liouvillian operator for a deterministic flow. The system conserves the extended energy $H'_{\\mathrm{NH}} = H(q,v) + \\frac{Q}{2}\\xi^2$. For the system to be ergodic, a typical trajectory must densely fill the constant energy surface defined by $H'_{\\mathrm{NH}} = E$.\n\nHowever, for a harmonic system, the Nosé–Hoover thermostat fails to be ergodic. The dynamics can be decomposed into normal modes. In this problem, all modes have the identical frequency $\\omega$. The equations of motion for each mode $(q_i, v_i)$ are $\\ddot{q}_i + \\xi(t)\\dot{q}_i + \\omega^2 q_i = 0$. The single thermostat variable $\\xi$ is coupled to the total kinetic energy. This coupling is not sufficient to induce chaotic behavior and promote mixing between the modes. The motion remains highly regular and quasi-periodic. Instead of exploring the entire constant-energy surface, trajectories are confined to lower-dimensional invariant tori within this surface. This is a well-known failure of the single-variable Nosé–Hoover thermostat when applied to systems with regular, non-chaotic underlying dynamics like the harmonic oscillator. Consequently, time averages will depend on the initial conditions and will not equal the ensemble averages calculated with the invariant measure derived in Part A.\n\nIn summary, the stochastic nature of Langevin dynamics ensures ergodicity, while the deterministic but overly regular nature of Nosé–Hoover dynamics on a harmonic system leads to a breakdown of ergodicity.\n\n### Part C: Derivation of the Fidelity Functional $F(\\alpha,\\gamma,\\omega)$\n\nThe functional is defined as the Laplace transform of the difference between the two normalized velocity autocorrelation functions (VAFs):\n$$ F(\\alpha,\\gamma,\\omega) = \\int_{0}^{\\infty} \\exp(-\\alpha t) \\left[ C^{\\mathrm{norm}}_{\\mathrm{Langevin}}(t) - C^{\\mathrm{norm}}_{\\mathrm{NH}}(t) \\right] \\, dt = \\mathcal{L}[C^{\\mathrm{norm}}_{\\mathrm{Langevin}}](\\alpha) - \\mathcal{L}[C^{\\mathrm{norm}}_{\\mathrm{NH}}](\\alpha) $$\nThe normalized VAF is $C^{\\mathrm{norm}}(t) = \\frac{\\langle v_{1}(t) v_{1}(0) \\rangle}{\\langle v_{1}^{2}(0) \\rangle}$. The denominator is the mean square velocity at equilibrium. By the equipartition theorem, $\\frac{1}{2}m\\langle v_1^2 \\rangle = \\frac{1}{2}k_B T$, so $\\langle v_1^2 \\rangle = \\frac{k_B T}{m}$.\n\n**1. Nosé–Hoover VAF**\nIn the weak-coupling limit ($Q \\to \\infty$), the problem states that the NH VAF converges to the VAF of the unthermostatted Hamiltonian system. The Hamiltonian equations of motion for one mode are $\\dot{q}_1 = v_1$ and $\\dot{v}_1 = -\\omega^2 q_1$. The solution for $v_1(t)$ is $v_1(t) = v_1(0)\\cos(\\omega t) - q_1(0)\\omega\\sin(\\omega t)$.\nThe VAF is $\\langle v_1(t) v_1(0) \\rangle = \\langle (v_1(0)\\cos(\\omega t) - q_1(0)\\omega\\sin(\\omega t))v_1(0) \\rangle$.\nAt thermal equilibrium, initial positions and velocities are uncorrelated, $\\langle q_1(0) v_1(0) \\rangle = 0$.\nThus, $\\langle v_1(t) v_1(0) \\rangle_{\\mathrm{NH}} = \\langle v_1^2(0) \\rangle \\cos(\\omega t)$.\nThe normalized VAF is $C^{\\mathrm{norm}}_{\\mathrm{NH}}(t) = \\cos(\\omega t)$.\nIts Laplace transform is $\\mathcal{L}[C^{\\mathrm{norm}}_{\\mathrm{NH}}](\\alpha) = \\mathcal{L}[\\cos(\\omega t)](\\alpha) = \\frac{\\alpha}{\\alpha^2 + \\omega^2}$.\n\n**2. Langevin VAF**\nThe equations of motion for a single mode are $\\dot{q}_1 = v_1$ and $\\dot{v}_1 = -\\omega^2 q_1 - \\gamma v_1 + \\frac{1}{m}\\sqrt{2\\gamma m k_B T}\\eta_1(t)$. These can be written in matrix form for the state vector $\\mathbf{x} = (q_1, v_1)^T$: $\\dot{\\mathbf{x}} = \\mathbf{A}\\mathbf{x} + \\mathbf{f}(t)$, where\n$$ \\mathbf{A} = \\begin{pmatrix} 0 & 1 \\\\ -\\omega^2 & -\\gamma \\end{pmatrix}, \\quad \\mathbf{f}(t) = \\begin{pmatrix} 0 \\\\ \\sqrt{\\frac{2\\gamma k_B T}{m}}\\eta_1(t) \\end{pmatrix} $$\nThe solution is $\\mathbf{x}(t) = e^{\\mathbf{A}t}\\mathbf{x}(0) + \\int_0^t e^{\\mathbf{A}(t-s)}\\mathbf{f}(s)ds$.\nThe velocity is $v_1(t) = [e^{\\mathbf{A}t}\\mathbf{x}(0)]_2 + \\dots$.\nThe VAF is $\\langle v_1(t) v_1(0) \\rangle = \\langle ([e^{\\mathbf{A}t}\\mathbf{x}(0)]_2) v_1(0) \\rangle$. The noise term does not contribute as it is uncorrelated with initial conditions.\n$\\langle v_1(t) v_1(0) \\rangle = \\langle ( (e^{\\mathbf{A}t})_{21} q_1(0) + (e^{\\mathbf{A}t})_{22} v_1(0) ) v_1(0) \\rangle$.\nUsing $\\langle q_1(0)v_1(0) \\rangle = 0$, we get $\\langle v_1(t) v_1(0) \\rangle_{\\mathrm{Langevin}} = (e^{\\mathbf{A}t})_{22} \\langle v_1^2(0) \\rangle$.\nSo, $C^{\\mathrm{norm}}_{\\mathrm{Langevin}}(t) = (e^{\\mathbf{A}t})_{22}$.\n\nTo find the Laplace transform of this function, we can transform the matrix exponential itself: $\\mathcal{L}[e^{\\mathbf{A}t}](s) = (s\\mathbf{I}-\\mathbf{A})^{-1}$.\n$$ (s\\mathbf{I}-\\mathbf{A})^{-1} = \\begin{pmatrix} s & -1 \\\\ \\omega^2 & s+\\gamma \\end{pmatrix}^{-1} = \\frac{1}{s(s+\\gamma)+\\omega^2} \\begin{pmatrix} s+\\gamma & 1 \\\\ -\\omega^2 & s \\end{pmatrix} = \\frac{1}{s^2+\\gamma s+\\omega^2} \\begin{pmatrix} s+\\gamma & 1 \\\\ -\\omega^2 & s \\end{pmatrix} $$\nThe Laplace transform of $C^{\\mathrm{norm}}_{\\mathrm{Langevin}}(t)$ is the $(2,2)$ element of this matrix:\n$$ \\mathcal{L}[C^{\\mathrm{norm}}_{\\mathrm{Langevin}}](s) = \\frac{s}{s^2+\\gamma s+\\omega^2} $$\nEvaluating at $s=\\alpha$, we have $\\mathcal{L}[C^{\\mathrm{norm}}_{\\mathrm{Langevin}}](\\alpha) = \\frac{\\alpha}{\\alpha^2+\\gamma\\alpha+\\omega^2}$.\n\n**3. Final Calculation**\nNow we assemble the expression for $F(\\alpha,\\gamma,\\omega)$:\n$$ F(\\alpha,\\gamma,\\omega) = \\frac{\\alpha}{\\alpha^2+\\gamma\\alpha+\\omega^2} - \\frac{\\alpha}{\\alpha^2+\\omega^2} $$\nTo obtain a single closed-form expression, we combine the fractions:\n$$ F(\\alpha,\\gamma,\\omega) = \\frac{\\alpha(\\alpha^2+\\omega^2) - \\alpha(\\alpha^2+\\gamma\\alpha+\\omega^2)}{(\\alpha^2+\\gamma\\alpha+\\omega^2)(\\alpha^2+\\omega^2)} $$\n$$ F(\\alpha,\\gamma,\\omega) = \\frac{\\alpha^3+\\alpha\\omega^2 - \\alpha^3 - \\gamma\\alpha^2 - \\alpha\\omega^2}{(\\alpha^2+\\gamma\\alpha+\\omega^2)(\\alpha^2+\\omega^2)} $$\n$$ F(\\alpha,\\gamma,\\omega) = \\frac{-\\gamma\\alpha^2}{(\\alpha^2+\\gamma\\alpha+\\omega^2)(\\alpha^2+\\omega^2)} $$\nThis is the final closed-form expression for the dynamical fidelity functional.",
            "answer": "$$\\boxed{\\frac{-\\gamma \\alpha^{2}}{(\\alpha^{2} + \\gamma \\alpha + \\omega^{2})(\\alpha^{2} + \\omega^{2})}}$$"
        },
        {
            "introduction": "Theoretical correctness is essential, but practical verification is paramount. Once a thermostat is implemented, how can we be certain it is correctly generating a canonical ensemble? This practice shifts our focus from implementation to validation, providing a hands-on computational workflow to test the output of a thermostat . You will use the fundamental principle that kinetic energy in a canonical ensemble follows a $\\chi^2$ distribution to design and apply a statistical test, comparing synthetic simulation data against this theoretical benchmark. This exercise equips you with a vital skill for quality control in any molecular simulation: the ability to statistically validate that your system is behaving as expected.",
            "id": "5274872",
            "problem": "You are tasked with designing and implementing a statistical analysis to validate temperature control via thermostats in biomolecular Molecular Dynamics (MD). The fundamental expectation under the canonical ensemble is that the distribution of total kinetic energy should be consistent with the Maxwell–Boltzmann distribution of velocities, which implies a specific distribution for kinetic energy. Your program must construct the validation from first principles and produce a final decision for each test case on whether the thermostat is consistent with the theoretically expected distribution.\n\nBegin from the following fundamental bases:\n- The canonical ensemble at temperature $T$ implies that each Cartesian velocity component $v_i$ is independently distributed as a Gaussian with zero mean and variance set by the equipartition principle.\n- For a system with $f$ quadratic degrees of freedom, the total kinetic energy $K$ is the sum over all independent quadratic modes.\n\nDefine the measured kinetic energy values as follows for each test case:\n- Let $f$ be the number of degrees of freedom, $T$ be the thermostat set temperature in Kelvin, $k_{\\mathrm{B}}$ be the Boltzmann constant in $\\mathrm{J/K}$, $n$ be the sample count, and $s$ be a dimensionless scaling factor that represents a measurement or thermostat calibration factor for the kinetic energy. For reproducibility, construct a deterministic synthetic \"measured\" set $\\{K_i\\}_{i=1}^n$ by first forming a set of dimensionless quantiles $\\{Q_i\\}_{i=1}^n$ of the chi-square distribution with $f$ degrees of freedom at cumulative probabilities $p_i = \\frac{i - 0.5}{n}$, then map them to kinetic energies by $K_i = \\frac{1}{2} k_{\\mathrm{B}} T \\, s \\, Q_i$. All $K_i$ must be expressed in Joules.\n\nTo validate the thermostat:\n- Normalize each $K_i$ to the dimensionless variable $X_i$ via $X_i = \\frac{2 K_i}{k_{\\mathrm{B}} T}$.\n- Under the null hypothesis implied by the canonical ensemble, the distribution of $\\{X_i\\}$ should match the theoretical chi-square distribution with $f$ degrees of freedom.\n- Perform a one-sample Kolmogorov–Smirnov (KS) test comparing the empirical distribution of $\\{X_i\\}$ to the theoretical chi-square cumulative distribution function with $f$ degrees of freedom. Let the test significance level be $\\alpha = 0.01$ (expressed as a decimal). Decide \"pass\" if the p-value $p \\ge \\alpha$ and \"fail\" otherwise.\n\nUse the exact value $k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\,\\mathrm{J/K}$. Ensure that any quantity expressed in physical units is handled consistently with these units. Angles are not used in this problem. Percentages (if any) must be expressed as decimals.\n\nImplement your solution to produce results for the following test suite of parameter sets:\n- Case A (happy path, large $f$): $f = 300$, $T = 310\\,\\mathrm{K}$, $n = 1000$, $s = 1.0$.\n- Case B (miscalibrated temperature, large $f$): $f = 300$, $T = 310\\,\\mathrm{K}$, $n = 1000$, $s = 1.1$.\n- Case C (boundary, small $f$): $f = 2$, $T = 300\\,\\mathrm{K}$, $n = 200$, $s = 1.0$.\n- Case D (edge case, small sample with deviation): $f = 60$, $T = 300\\,\\mathrm{K}$, $n = 50$, $s = 1.2$.\n\nYour program should produce a single line of output containing the boolean pass/fail results for the test suite in order, as a comma-separated list enclosed in square brackets, for example: \"[True,False,True,False]\".",
            "solution": "The problem requires the design and implementation of a statistical validation procedure for temperature control in biomolecular simulations. The validation is based on the fundamental principles of statistical mechanics for a system in the canonical ensemble. The solution involves generating synthetic kinetic energy data and then using the one-sample Kolmogorov-Smirnov (KS) test to assess its consistency with the theoretical distribution.\n\n**Theoretical Foundation**\n\nIn statistical mechanics, a system in thermal equilibrium with a heat bath at a constant absolute temperature $T$ is described by the canonical ensemble. A key prediction of this ensemble is the distribution of particle velocities, governed by the Maxwell-Boltzmann distribution. For a classical system, each quadratic degree of freedom (e.g., kinetic energy term $\\frac{1}{2}mv_x^2$ or potential energy term $\\frac{1}{2}kx^2$) has an average energy of $\\frac{1}{2}k_{\\mathrm{B}}T$, a result known as the equipartition theorem, where $k_{\\mathrm{B}}$ is the Boltzmann constant.\n\nThe total kinetic energy $K$ of a system with $f$ independent quadratic degrees of freedom is the sum of the energies from these modes. Each mode's energy, when scaled by $\\frac{1}{k_{\\mathrm{B}}T}$, contributes a term that is the square of a standard normal variable. The variable representing the contribution from a single mode, let's call it $Z$, is distributed as a chi-square distribution with one degree of freedom, $\\chi^2(1)$.\n\nThus, the dimensionless total kinetic energy, defined as the variable $X = \\frac{2K}{k_{\\mathrm{B}}T}$, is the sum of $f$ independent $\\chi^2(1)$ variables. By the definition of the chi-square distribution, this sum follows a chi-square distribution with $f$ degrees of freedom, denoted as $\\chi^2(f)$.\n\nThis theoretical result forms the null hypothesis ($H_0$) for our statistical test:\n$H_0$: The distribution of the observed, normalized kinetic energy data, $\\{X_i\\}$, is the chi-square distribution with $f$ degrees of freedom.\n\n**Data Generation and Test Procedure**\n\nThe problem specifies a deterministic method to generate a synthetic dataset $\\{K_i\\}_{i=1}^n$ for a system with $f$ degrees of freedom at temperature $T$, with $n$ samples. This method uses a dimensionless scaling factor $s$ to simulate either a perfectly calibrated thermostat ($s=1.0$) or a miscalibrated one ($s \\neq 1.0$).\n\n1.  **Quantile Generation**: A set of $n$ cumulative probabilities $\\{p_i\\}$ is first generated using the formula $p_i = \\frac{i - 0.5}{n}$ for $i=1, 2, \\dots, n$. This choice of probabilities symmetrically samples the distribution's quantiles.\n\n2.  **Chi-Square Quantiles**: For each probability $p_i$, the corresponding quantile $Q_i$ of the theoretical $\\chi^2(f)$ distribution is calculated. The quantile $Q_i$ is the value such that the cumulative distribution function (CDF) of the $\\chi^2(f)$ distribution at $Q_i$ is equal to $p_i$.\n\n3.  **Kinetic Energy Synthesis**: The \"measured\" kinetic energies $\\{K_i\\}$ are then synthesized using the relation:\n    $$K_i = \\frac{1}{2} k_{\\mathrm{B}} T s Q_i$$\n    Here, $s$ acts as a calibration factor. If $s=1.0$, the relationship between the expected kinetic energy and temperature is perfectly met. If $s > 1.0$ or $s < 1.0$, it implies a systematic over- or under-estimation of temperature, respectively.\n\n4.  **Normalization**: To perform the statistical test, each synthetic kinetic energy value $K_i$ is normalized according to our theoretical expectation:\n    $$X_i = \\frac{2 K_i}{k_{\\mathrm{B}} T}$$\n    Substituting the expression for $K_i$ from the previous step, we find the direct relationship between the test sample and the theoretical quantiles:\n    $$X_i = \\frac{2}{k_{\\mathrm{B}} T} \\left( \\frac{1}{2} k_{\\mathrm{B}} T s Q_i \\right) = s Q_i$$\n    This reveals that the sample $\\{X_i\\}$ to be tested is simply the set of theoretical quantiles $\\{Q_i\\}$ scaled by the factor $s$.\n\n5.  **Kolmogorov-Smirnov Test**: The one-sample KS test is applied to the generated sample $\\{X_i\\}$. This test compares the empirical cumulative distribution function (ECDF) of the sample, $\\hat{F}_n(x)$, with the theoretical CDF of the $\\chi^2(f)$ distribution, $F_{\\chi^2(f)}(x)$. The test statistic is the maximum absolute difference between these two functions over the entire range of $x$. A p-value is computed from this statistic, which represents the probability of observing a deviation at least as large as the one measured, assuming the null hypothesis is true.\n\n6.  **Decision**: The thermostat is deemed consistent with the canonical ensemble (\"pass\") if the computed p-value $p$ is greater than or equal to the specified significance level $\\alpha = 0.01$. Otherwise, it is a \"fail\". A high p-value ($p \\ge \\alpha$) suggests that the observed data is consistent with the null hypothesis, while a low p-value ($p < \\alpha$) provides evidence to reject it.\n\nFor cases where $s=1.0$, the sample $\\{X_i\\}$ is identical to $\\{Q_i\\}$, which by construction should closely follow the $\\chi^2(f)$ distribution, leading to a large p-value and a \"pass\" decision. For cases where $s \\neq 1.0$, the sample distribution is a scaled version of the theoretical one, and the KS test is expected to detect this discrepancy, resulting in a low p-value and a \"fail\" decision, especially for a sufficiently large sample size $n$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Validates thermostat performance in biomolecular simulations by testing\n    if synthetic kinetic energy data conforms to the theoretical chi-square\n    distribution, as predicted by the canonical ensemble.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each tuple is (f, T, n, s)\n    # f: degrees of freedom\n    # T: temperature (K)\n    # n: sample count\n    # s: dimensionless scaling factor\n    test_cases = [\n        (300, 310.0, 1000, 1.0),  # Case A: happy path, large f\n        (300, 310.0, 1000, 1.1),  # Case B: miscalibrated temperature, large f\n        (2, 300.0, 200, 1.0),    # Case C: boundary, small f\n        (60, 300.0, 50, 1.2),     # Case D: edge case, small sample with deviation\n    ]\n\n    # Physical and statistical constants\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n    alpha = 0.01        # Significance level for the KS test\n\n    results = []\n    for f, T, n, s in test_cases:\n        # Step 1: Generate synthetic \"measured\" data\n        # Create a set of n cumulative probabilities\n        probabilities = (np.arange(1, n + 1) - 0.5) / n\n\n        # Generate the corresponding quantiles of the chi-square distribution\n        # with f degrees of freedom. These are the Q_i values.\n        # ppf is the Percent Point Function (inverse of CDF).\n        q_i = stats.chi2.ppf(probabilities, df=f)\n\n        # According to the problem statement, K_i = 0.5 * k_B * T * s * q_i.\n        # The validation requires normalizing K_i to X_i = 2 * K_i / (k_B * T).\n        # Substituting K_i, we get X_i = s * q_i.\n        # This is more numerically stable than calculating K_i explicitly.\n        x_samples = s * q_i\n        \n        # Step 2: Perform the one-sample Kolmogorov-Smirnov test\n        # We test the sample `x_samples` against the theoretical chi-square\n        # distribution with `f` degrees of freedom.\n        # `stats.chi2.cdf` is the cumulative distribution function for chi-square.\n        # `args=(f,)` passes the degrees of freedom to the cdf.\n        ks_result = stats.ks_1samp(x_samples, stats.chi2.cdf, args=(f,))\n        \n        p_value = ks_result.pvalue\n\n        # Step 3: Make a decision based on the p-value\n        # \"pass\" if p-value is greater than or equal to the significance level.\n        # Python's boolean True/False corresponds to pass/fail.\n        decision = (p_value >= alpha)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) converts boolean True/False to \"True\"/\"False\" strings.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}