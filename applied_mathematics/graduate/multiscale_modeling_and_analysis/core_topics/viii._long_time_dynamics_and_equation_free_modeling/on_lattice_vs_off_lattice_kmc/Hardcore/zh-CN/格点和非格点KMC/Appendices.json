{
    "hands_on_practices": [
        {
            "introduction": "多尺度建模的一个核心目标是从微观规则预测宏观现象。本练习将直接应对这一挑战，要求您直接从离格 KMC 模拟中典型的随机跳跃事件目录，推导出有效扩散系数 $D$ 这一关键输运性质。通过从爱因斯坦关系式出发，您将深刻理解单个的、随机的运动是如何共同产生可预测的扩散行为的 。",
            "id": "3790399",
            "problem": "考虑一个离格动理学蒙特卡洛（kMC）模型，其中一个质点因一个可能的事件目录而在连续空间中移动。每个事件由一个速率 $r_i$（单位为 $\\mathrm{s}^{-1}$）和一个确定性的位移矢量 $\\Delta \\mathbf{x}_i \\in \\mathbb{R}^d$（单位为 $\\mathrm{m}$）来表征。事件作为连续时间马尔可夫链（CTMC）随机发生，其等待时间呈指数分布，且事件的选择与各自的速率成正比。该过程可被看作一个复合泊松过程，在无穷小的时间间隔内，发生类型 $i$ 跳跃的概率与 $r_i$ 成正比，总速率为 $R = \\sum_i r_i$。\n\n从连接均方位移（MSD）与扩散系数的爱因斯坦扩散关系式出发，并基于复合泊松跳跃过程的定义，推导出一个基于第一性原理的算法，用于从事件目录 $\\{(r_i,\\Delta \\mathbf{x}_i)\\}_i$ 计算 $d$ 维空间中的有效标量扩散系数 $D$（以 $\\mathrm{m}^2/\\mathrm{s}$ 为单位表示）。你的推导必须阐明在所述的随机动力学下，MSD如何由特定事件的位移和速率累积而成，并且必须通过 $d$ 维空间中适当的维度因子，将此累积过程与 $D$ 进行逻辑关联。不要假定或使用任何关于 $D$ 的预先推导的快捷公式；相反，应基于上述基本定义来构建计算方法。\n\n实现一个程序，该程序使用你推导出的算法，为每个提供的测试用例计算有效标量扩散系数 $D$（单位为 $\\mathrm{m}^2/\\mathrm{s}$）。此问题不涉及角度，因此无需指定角度单位。程序必须以实数（浮点值）形式生成结果。\n\n使用以下测试套件（每个测试用例定义了维度 $d$ 和一个事件列表，其中每个事件是一个数对 $(r_i, \\Delta \\mathbf{x}_i)$， $r_i$ 的单位是 $\\mathrm{s}^{-1}$，$\\Delta \\mathbf{x}_i$ 的单位是 $\\mathrm{m}$）：\n\n- 测试用例 $1$（正常路径，在 $d=2$ 中各向同性）：$d=2$；事件 $[ (\\,5.0,\\,(1\\times 10^{-9},\\,0)\\,),\\ (\\,5.0,\\,(0,\\,1\\times 10^{-9})\\,) ]$。\n- 测试用例 $2$（在 $d=3$ 中各向异性，具有混合的大小和速率）：$d=3$；事件 $[ (\\,1\\times 10^{3},\\,(1\\times 10^{-10},\\,0,\\,0)\\,),\\ (\\,2\\times 10^{2},\\,(0,\\,2\\times 10^{-10},\\,0)\\,),\\ (\\,5\\times 10^{1},\\,(0,\\,0,\\,1\\times 10^{-9})\\,) ]$。\n- 测试用例 $3$（边界情况，因零位移/零速率导致的零迁移率）：$d=2$；事件 $[ (\\,1\\times 10^{4},\\,(0,\\,0)\\,),\\ (\\,0,\\,(1\\times 10^{-9},\\,-1\\times 10^{-9})\\,) ]$。\n- 测试用例 $4$（在 $d=2$ 中罕见的长跳跃与频繁的短跳跃之间的竞争）：$d=2$；事件 $[ (\\,1.0,\\,(1\\times 10^{-6},\\,1\\times 10^{-6})\\,),\\ (\\,1\\times 10^{5},\\,(1\\times 10^{-9},\\,0)\\,) ]$。\n- 测试用例 $5$（在 $d=3$ 中的离格非正交位移）：$d=3$；事件 $[ (\\,10,\\,(3\\times 10^{-10},\\,4\\times 10^{-10},\\,0)\\,),\\ (\\,20,\\,( -3\\times 10^{-10},\\,0,\\,4\\times 10^{-10})\\,),\\ (\\,30,\\,(0,\\,-4\\times 10^{-10},\\,3\\times 10^{-10})\\,) ]$。\n\n你的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，结果按上述测试用例的顺序排列（例如，$[D_1,D_2,D_3,D_4,D_5]$），其中每个 $D_k$ 是为测试用例 $k$ 计算出的扩散系数，单位为 $\\mathrm{m}^2/\\mathrm{s}$。",
            "solution": "目标是为一个在 $d$ 维连续空间中经历随机跳跃过程的粒子推导计算有效标量扩散系数 $D$ 的算法，然后实现该算法。推导过程必须从第一性原理出发，特别是爱因斯坦关系式和作为基础的复合泊松过程的定义。\n\n### 从第一性原理推导\n\n我们分析的基础是扩散的爱因斯坦关系式，它在长时间极限下将粒子的均方位移（MSD）与扩散系数 $D$ 联系起来。在 $d$ 维空间中，该关系式为：\n$$\n\\langle \\|\\mathbf{x}(t) - \\mathbf{x}(0)\\|^2 \\rangle = 2 d D t\n$$\n其中 $\\mathbf{x}(t)$ 是粒子在时间 $t$ 的位置，$\\langle \\cdot \\rangle$ 表示对所有可能随机轨迹的系综平均。等式左边即为 MSD。由此，扩散系数可以定义为：\n$$\nD = \\lim_{t \\to \\infty} \\frac{\\langle \\|\\mathbf{x}(t) - \\mathbf{x}(0)\\|^2 \\rangle}{2 d t}\n$$\n问题指明，粒子的运动由一个以 $i$ 为索引的、包含不同事件类型的目录所控制。每种事件类型 $i$ 由一个恒定的速率 $r_i$ 和一个确定性的位移矢量 $\\Delta \\mathbf{x}_i$ 表征。类型 $i$ 事件的发生构成一个速率为 $r_i$ 的泊松过程。整个过程是一个复合泊松过程，这意味着不同类型的事件是独立发生的。\n\n让我们对粒子随时间变化的位置进行建模。不失一般性，我们将初始位置设为原点，即 $\\mathbf{x}(0) = \\mathbf{0}$。在稍后的时间 $t$，其位置是在此之前发生的所有位移事件的矢量和：\n$$\n\\mathbf{x}(t) = \\sum_i n_i(t) \\Delta \\mathbf{x}_i\n$$\n其中 $n_i(t)$ 是在时间间隔 $[0, t]$ 内事件 $i$ 发生的次数。由于每种事件类型都遵循泊松过程，因此 $n_i(t)$ 是一个服从泊松分布的随机变量，其均值和方差由下式给出：\n$$\n\\langle n_i(t) \\rangle = \\text{Var}(n_i(t)) = r_i t\n$$\n此外，由于事件过程的独立性，不同类型事件发生次数之间的协方差为零：\n$$\n\\text{Cov}(n_i(t), n_j(t)) = \\langle (n_i(t) - \\langle n_i(t) \\rangle)(n_j(t) - \\langle n_j(t) \\rangle) \\rangle = 0 \\quad \\text{for } i \\neq j\n$$\n综合这些，我们可以写出 $\\text{Cov}(n_i(t), n_j(t)) = \\delta_{ij} r_i t$，其中 $\\delta_{ij}$ 是克罗内克 δ 符号。\n\n爱因斯坦关系式中的 MSD 指的是粒子位置的方差，它衡量了粒子位置围绕其平均位置的散布程度。让我们首先计算平均位置 $\\langle \\mathbf{x}(t) \\rangle$：\n$$\n\\langle \\mathbf{x}(t) \\rangle = \\left\\langle \\sum_i n_i(t) \\Delta \\mathbf{x}_i \\right\\rangle = \\sum_i \\langle n_i(t) \\rangle \\Delta \\mathbf{x}_i = \\sum_i (r_i t) \\Delta \\mathbf{x}_i = t \\left( \\sum_i r_i \\Delta \\mathbf{x}_i \\right)\n$$\n项 $\\mathbf{v}_{\\text{drift}} = \\sum_i r_i \\Delta \\mathbf{x}_i$ 代表一个恒定的漂移速度。扩散运动是围绕此平均漂移的随机涨落。因此，用于计算扩散的正确 MSD 是位置的方差：\n$$\n\\text{MSD}(t) = \\langle \\|\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle\\|^2 \\rangle\n$$\n现在我们来计算这个方差。我们将其表示为 $\\mathbf{x}(t)$ 的协方差矩阵的迹：\n$$\n\\text{MSD}(t) = \\text{Tr}(\\text{Cov}(\\mathbf{x}(t))) = \\text{Tr}\\left( \\left\\langle (\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle)(\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle)^T \\right\\rangle \\right)\n$$\n代入 $\\mathbf{x}(t)$ 的表达式：\n$$\n\\mathbf{x}(t) - \\langle \\mathbf{x}(t) \\rangle = \\sum_i n_i(t) \\Delta \\mathbf{x}_i - \\sum_i \\langle n_i(t) \\rangle \\Delta \\mathbf{x}_i = \\sum_i (n_i(t) - \\langle n_i(t) \\rangle) \\Delta \\mathbf{x}_i\n$$\n那么协方差矩阵为：\n$$\n\\text{Cov}(\\mathbf{x}(t)) = \\left\\langle \\left( \\sum_i (n_i(t) - \\langle n_i(t) \\rangle) \\Delta \\mathbf{x}_i \\right) \\left( \\sum_j (n_j(t) - \\langle n_j(t) \\rangle) \\Delta \\mathbf{x}_j \\right)^T \\right\\rangle\n$$\n$$\n= \\sum_{i,j} \\Delta \\mathbf{x}_i \\Delta \\mathbf{x}_j^T \\left\\langle (n_i(t) - \\langle n_i(t) \\rangle)(n_j(t) - \\langle n_j(t) \\rangle) \\right\\rangle\n$$\n期望项正是协方差 $\\text{Cov}(n_i(t), n_j(t)) = \\delta_{ij} r_i t$。双重求和坍缩为关于 $i$ 的单重求和：\n$$\n\\text{Cov}(\\mathbf{x}(t)) = \\sum_i \\Delta \\mathbf{x}_i \\Delta \\mathbf{x}_i^T (r_i t) = t \\sum_i r_i (\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i)\n$$\n其中 $\\otimes$ 表示外积。MSD 是该矩阵的迹：\n$$\n\\text{MSD}(t) = \\text{Tr}\\left( t \\sum_i r_i (\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i) \\right) = t \\sum_i r_i \\text{Tr}(\\Delta \\mathbf{x}_i \\otimes \\Delta \\mathbf{x}_i)\n$$\n一个矢量与其自身外积的迹，$\\text{Tr}(\\mathbf{v} \\otimes \\mathbf{v})$，等于该矢量的模的平方（或点积），即 $\\|\\mathbf{v}\\|^2$。因此：\n$$\n\\text{MSD}(t) = t \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2\n$$\n这个结果表明 MSD 随时间线性增长，这是扩散过程的标志。其增长速率由每个事件的速率乘以其跳跃距离平方的总和决定。\n\n最后，我们将这个推导出的 MSD 表达式代入扩散系数的定义中：\n$$\nD = \\lim_{t \\to \\infty} \\frac{t \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2}{2 d t}\n$$\n因子 $t$ 被消去，得到最终的公式：\n$$\nD = \\frac{1}{2d} \\sum_i r_i \\|\\Delta \\mathbf{x}_i\\|^2\n$$\n\n### 算法\n基于此推导，计算标量扩散系数 $D$ 的算法如下：\n1.  初始化一个求和变量 $S$ 为 $0$。\n2.  对于所提供目录 $\\{(r_i, \\Delta \\mathbf{x}_i)\\}_i$ 中的每个事件 $i$：\n    a.  取位移矢量 $\\Delta \\mathbf{x}_i$。\n    b.  计算其欧几里得范数的平方（模）：$\\|\\Delta \\mathbf{x}_i\\|^2 = \\Delta \\mathbf{x}_i \\cdot \\Delta \\mathbf{x}_i = \\sum_{j=1}^{d} (\\Delta x_{i,j})^2$。\n    c.  将此范数的平方乘以事件速率 $r_i$。\n    d.  将得到的乘积 $r_i \\|\\Delta \\mathbf{x}_i\\|^2$ 加到求和变量 $S$ 上。\n3.  遍历所有事件后，通过将总和 $S$ 除以因子 $2d$ 来计算扩散系数，其中 $d$ 是空间的维度。\n\n该算法直接实现了所推导的公式，并基于指定的第一性原理。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the effective diffusion coefficient based on a catalog of\n    kMC events.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each test case is a tuple: (dimension, list_of_events)\n    # Each event is a tuple: (rate, displacement_vector)\n    test_cases = [\n        # Test Case 1 (happy path, isotropic in d=2)\n        (2, [\n            (5.0, np.array([1e-9, 0.0])),\n            (5.0, np.array([0.0, 1e-9]))\n        ]),\n        \n        # Test Case 2 (anisotropic in d=3 with mixed magnitudes and rates)\n        (3, [\n            (1e3, np.array([1e-10, 0.0, 0.0])),\n            (2e2, np.array([0.0, 2e-10, 0.0])),\n            (5e1, np.array([0.0, 0.0, 1e-9]))\n        ]),\n\n        # Test Case 3 (boundary case, zero mobility)\n        (2, [\n            (1e4, np.array([0.0, 0.0])),\n            (0.0, np.array([1e-9, -1e-9]))\n        ]),\n\n        # Test Case 4 (competition between rare long jumps and frequent short jumps in d=2)\n        (2, [\n            (1.0, np.array([1e-6, 1e-6])),\n            (1e5, np.array([1e-9, 0.0]))\n        ]),\n\n        # Test Case 5 (off-lattice non-orthogonal displacements in d=3)\n        (3, [\n            (10.0, np.array([3e-10, 4e-10, 0.0])),\n            (20.0, np.array([-3e-10, 0.0, 4e-10])),\n            (30.0, np.array([0.0, -4e-10, 3e-10]))\n        ])\n    ]\n\n    results = []\n    \n    # Process each test case using the derived formula.\n    # D = (1 / (2*d)) * sum(r_i * ||dx_i||^2)\n    for d, events in test_cases:\n        # Initialize the sum of rate-weighted squared displacements\n        sum_r_dx_sq = 0.0\n        \n        for rate, dx_vec in events:\n            # Calculate the squared magnitude (norm) of the displacement vector\n            # ||dx_i||^2 is equivalent to the dot product of the vector with itself\n            squared_magnitude = np.dot(dx_vec, dx_vec)\n            \n            # Add the contribution of this event to the sum\n            sum_r_dx_sq += rate * squared_magnitude\n\n        # Handle the case where the denominator 2*d could be zero, though\n        # d is always >= 1 in this problem's context.\n        if d > 0:\n            diffusion_coefficient = sum_r_dx_sq / (2 * d)\n        else:\n            # Physically, d=0 is ill-defined for diffusion.\n            # For completeness, return 0.\n            diffusion_coefficient = 0.0\n\n        results.append(diffusion_coefficient)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "模拟的可靠性取决于其实现的正确性。本练习将从物理理论转向计算实践，指导您为 KMC 引擎的核心组件设计单元测试。您将学习如何凭经验验证随机事件选择过程的正确性，以及更深入地，如何通过满足细致平衡原则来确认您的模拟遵守热力学一致性 。",
            "id": "3790392",
            "problem": "设计并实现一个程序，为动理学蒙特卡洛 (kMC) 实现构建一套单元测试，以验证其在格点和离格模型中都满足三个核心属性：速率归一化、细致平衡和事件选择正确性。动理学蒙特卡洛 (kMC) 被建模为一个具有离散事件列表和相关速率向量的连续时间马尔可夫过程。其推导的基本依据是连续时间马尔可夫链理论和平衡统计力学。\n\n从以下基本定义和事实出发。一个连续时间马尔可夫链由一组状态和一个速率矩阵 $\\mathbf{R}$ 定义，其中 $R_{i \\to j}$ 是从状态 $i$ 到状态 $j$ 的转移速率。对于从一个给定状态出发的单步 kMC 过程，我们考虑一组候选事件，其速率为 $\\{r_i\\}$。总速率为 $R = \\sum_i r_i$。选择事件 $i$ 的概率为 $p_i = r_i / R$（对于 $R > 0$），到下一个事件的等待时间 $\\Delta t$ 服从参数为 $R$ 的指数分布。在平衡统计力学中，细致平衡条件是等式 $\\pi_i R_{i \\to j} = \\pi_j R_{j \\to i}$ 对所有状态对 $\\{i,j\\}$ 成立，其中 $\\pi_i$ 是状态 $i$ 的稳态概率。对于一个能量为 $\\{E_i\\}$（以热能 $k_{\\mathrm{B}}T$ 为单位）的系统，玻尔兹曼分布为 $\\pi_i = \\exp(-E_i) / Z$，其中 $Z = \\sum_k \\exp(-E_k)$。一个满足细致平衡的充分构造方法是使用对称的指前因子，并选择 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，其中尝试频率 $\\nu > 0$ 为常数。\n\n您的程序必须实现单元测试来检查以下属性：\n- 速率归一化：给定一个有限速率向量 $\\mathbf{r}$，其条目非负 $r_i \\ge 0$，总速率为 $R = \\sum_i r_i$，则对于 $R > 0$，归一化概率满足 $\\sum_i p_i = 1$。程序必须通过随机抽样经验性地估计事件选择概率，并在指定的容差范围内与 $p_i$ 进行比较。\n- 细致平衡：对于具有指定能量 $\\{E_i\\}$（以 $k_{\\mathrm{B}}T$ 为单位）的系统，并且其速率是为满足细致平衡而构造的，连续时间马尔可夫链的稳态分布应等于玻尔兹曼分布。稳态分布 $\\boldsymbol{\\pi}$ 满足 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$ 和 $\\sum_i \\pi_i = 1$，其中 $\\mathbf{G}$ 是生成元矩阵，其非对角线项为 $G_{i j} = R_{i \\to j}$（当 $i \\ne j$ 时），对角线项为 $G_{i i} = -\\sum_{j \\ne i} R_{i \\to j}$。\n- 事件选择正确性：事件抽样过程必须永远不选择速率为零的事件，必须能处理只有一个事件非零的简并情况，并且必须正确处理总速率 $R = 0$（没有事件可选）的边界条件。\n\n请同时处理格点和离格两种情况。在格点 kMC 模型中，状态是离散的格点位置，允许的转移由一个邻接结构指定。在离格 kMC 模型中，事件列表是根据几何关系（例如，实体之间的距离）构建的，速率可能依赖于连续的几何变量；然而，事件选择仍然是在一个具有速率向量的离散事件集上进行。对于本问题中的离格测试，使用的事件速率依赖于距离的指数函数，$r_i = k_0 \\exp(-\\alpha d_i)$，其中 $k_0 > 0$、$\\alpha > 0$ 和 $d_i \\ge 0$ 都是无量纲的。\n\n实现以下测试套件。每个测试必须产生一个布尔结果，指示通过（$\\mathrm{True}$）或失败（$\\mathrm{False}$）。每个测试的随机抽样必须使用固定的种子以确保可复现性。所有指定的能量、速率、距离、计数和容差都是无量纲的。不涉及物理单位。\n\n- 测试 $1$ （格点速率归一化和事件选择）：使用速率向量 $\\mathbf{r} = (1.0, 2.0, 3.0, 0.0)$，抽样次数 $N = 100000$，随机种子 $s = 12345$，归一化容差 $\\varepsilon_{\\mathrm{norm}} = 10^{-12}$，以及频率偏差容差 $\\varepsilon_{\\mathrm{freq}} = 5 \\times 10^{-3}$。如果 $\\left|\\sum_i p_i - 1\\right| < \\varepsilon_{\\mathrm{norm}}$ 并且经验频率与 $p_i$ 之间的最大绝对偏差小于 $\\varepsilon_{\\mathrm{freq}}$，则测试通过。\n- 测试 $2$ （离格速率归一化和事件选择）：使用距离 $\\mathbf{d} = (0.1, 0.2, 1.0)$，$k_0 = 1.0$，$\\alpha = 2.5$，抽样次数 $N = 200000$，随机种子 $s = 54321$，归一化容差 $\\varepsilon_{\\mathrm{norm}} = 10^{-12}$，以及频率偏差容差 $\\varepsilon_{\\mathrm{freq}} = 5 \\times 10^{-3}$。测试通过的标准与测试 1 相同。\n- 测试 $3$ （两状态细致平衡）：使用能量 $\\mathbf{E} = (0.0, 1.0)$（以 $k_{\\mathrm{B}}T$ 为单位），尝试频率 $\\nu = 1.0$，两个状态之间完全邻接，以及细致平衡速率 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$。构建生成元矩阵 $\\mathbf{G}$，通过求解 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$ 和 $\\sum_i \\pi_i = 1$ 计算稳态分布 $\\boldsymbol{\\pi}$，并与玻尔兹曼分布进行比较。如果 $\\boldsymbol{\\pi}$ 与玻尔兹曼分布之间的最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。\n- 测试 $4$ （三状态环形格点上的细致平衡）：使用能量 $\\mathbf{E} = (0.0, 0.5, 1.0)$（以 $k_{\\mathrm{B}}T$ 为单位），尝试频率 $\\nu = 2.0$。使用环形邻接，其中每个状态连接到其两个邻居（对于三个状态，这意味着每个状态都与其他两个状态相连）。构造速率 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，建立 $\\mathbf{G}$，计算 $\\boldsymbol{\\pi}$，并与玻尔兹曼分布进行比较。如果最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。\n- 测试 $5$ （边界情况 $R = 0$）：使用速率向量 $\\mathbf{r} = (0.0, 0.0, 0.0)$。如果事件选择过程正确返回“无事件”（即不选择任何索引），则测试通过。\n- 测试 $6$ （确定性事件选择）：使用速率向量 $\\mathbf{r} = (0.0, 0.0, 5.0)$，抽样次数 $N = 10000$，随机种子 $s = 111$。如果在所有样本中，唯一被选中的事件索引是那个具有非零速率的事件，则测试通过。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表（例如，$[result1,result2,result3]$），其中每个 $resultk$ 是一个布尔值，表示测试 $k$ 的通过/失败结果。不得打印任何额外文本。",
            "solution": "本问题所依据的原理是动理学蒙特卡洛 (kMC) 模拟的基础，该模拟将系统的时间演化建模为连续时间、离散状态的马尔可夫过程。单元测试的设计重点在于对照这些原理，验证 kMC 实现的核心机制。\n\n一个 kMC 模拟步骤包含两个部分：选择下一个将要发生的事件，以及确定系统等待该事件发生的时间。本问题侧重于事件选择机制的正确性。给定当前状态下的 $N$ 个可能事件，每个事件的速率为 $r_i \\ge 0$，总速率为 $R = \\sum_{i=1}^{N} r_i$。根据马尔可夫过程理论，选择事件 $i$ 的概率 $p_i$ 与其速率成正比，即 $p_i = r_i / R$。所选事件发生的等待时间 $\\Delta t$ 是一个从参数为 $R$ 的指数分布中抽取的随机变量。单元测试将验证与此过程相关的三个关键属性。\n\n1.  **速率归一化和事件选择正确性**：\n    理论概率 $p_i = r_i/R$ 的总和必须为 1，即 $\\sum_{i} p_i = 1$（前提是总速率 $R > 0$）。事件选择算法必须遵守这些概率。一种标准且稳健的事件选择方法是“首次通过”或“累积速率”法，本测试将实现此方法。首先，从区间 $[0, R)$ 中抽取一个均匀随机数 $u$。然后，选择事件索引 $k$，使得 $\\sum_{i=0}^{k-1} r_i \\le u  \\sum_{i=0}^{k} r_i$。这确保了速率为 $r_i = 0$ 的事件永远不会被选中（因为它们不增加累积和），并且速率较高的事件覆盖了区间 $[0, R)$ 的更大部分，从而使其被选中的可能性按比例更高。测试通过对给定速率向量 $\\mathbf{r}$ 重复抽样事件，并将选择的经验频率与理论概率 $p_i$ 进行比较来验证这一点。大数定律指出，对于大量的样本 $N_s$，经验频率应收敛于 $p_i$。测试还评估了边界条件：所有速率均为零（$R=0$）的情况，此时不应选择任何事件；以及只有一个事件具有非零速率的确定性情况。\n\n2.  **细致平衡**：\n    对于处于热力学平衡的系统，细致平衡原理必须成立。该原理指出，在平衡状态下，每个微观过程的速率与其逆过程的速率相平衡。对于描述状态 $i$ 和 $j$ 之间转移的马尔可夫过程，这表示为 $\\pi_i R_{i \\to j} = \\pi_j R_{j \\to i}$，其中 $\\pi_k$ 是处于状态 $k$ 的稳态（平衡）概率，而 $R_{i \\to j}$ 是从 $i$ 到 $j$ 的转移速率。一个动力学遵循细致平衡的系统最终将弛豫到一个与统计力学中的平衡分布一致的稳态分布。对于具有离散能级 $E_i$（以热能 $k_{\\mathrm{B}}T$ 为单位）的系统，此平衡分布是玻尔兹曼分布，$\\pi_{i, \\text{B}} = \\exp(-E_i) / Z$，其中 $Z = \\sum_k \\exp(-E_k)$ 是配分函数。\n    问题提供了一种特定的速率形式 $R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，这是满足相对于玻尔兹曼分布的细致平衡的一个充分（但非必要）条件。测试将通过以下方式验证此属性：\n    a. 为连续时间马尔可夫链构建生成元矩阵 $\\mathbf{G}$。非对角元是转移速率 $G_{ij} = R_{i \\to j}$（对于 $i \\ne j$），对角元是负的总迁出率 $G_{ii} = -\\sum_{j \\ne i} R_{i \\to j}$。\n    b. 数值求解稳态分布 $\\boldsymbol{\\pi}$，它是满足线性系统 $\\boldsymbol{\\pi}^\\top \\mathbf{G} = \\mathbf{0}$（等价于 $\\mathbf{G}^\\top \\boldsymbol{\\pi} = \\mathbf{0}$）并在归一化约束 $\\sum_i \\pi_i = 1$ 下的唯一归一化向量。这通过求解从这些条件导出的线性方程组来实现。\n    c. 将数值上得到的稳态分布 $\\boldsymbol{\\pi}$ 与解析推导的玻尔兹曼分布 $\\boldsymbol{\\pi}_{\\text{B}}$ 进行比较。\n\n测试套件的结构旨在检验这些属性在格点（状态转移由固定的邻接关系定义）和离格（事件速率可能依赖于如距离等连续变量）两种情况下的表现。\n\n**测试实现**\n\n**测试 1 和 2（速率归一化和选择）**：\n这些测试将使用累积速率选择算法的实现。对于给定的速率向量 $\\mathbf{r}$，首先计算理论概率 $\\mathbf{p} = \\mathbf{r} / \\sum \\mathbf{r}$。检查归一化的有效性 $|\\sum p_i - 1|  \\varepsilon_{\\mathrm{norm}}$。然后，使用固定的随机种子对大量事件（测试 1 为 $N=100000$，测试 2 为 $N=200000$）进行抽样以保证可复现性。计算每个事件的经验频率，并与理论概率进行比较。如果最大绝对偏差在指定的容差 $\\varepsilon_{\\mathrm{freq}}$ 内，则测试通过。对于测试 1，速率是直接给出的；对于测试 2，速率 $r_i$ 首先根据离格模型 $r_i = k_0 \\exp(-\\alpha d_i)$ 使用所提供的参数计算得出。\n\n**测试 3 和 4（细致平衡）**：\n这些测试验证指定的速率构造方法所产生的稳态分布与玻尔兹曼分布一致。对于给定的能量 $\\mathbf{E}$ 和尝试频率 $\\nu$，构建速率矩阵 $\\mathbf{R}$：$R_{i \\to j} = \\nu \\exp(-(E_j - E_i)/2)$，适用于所有指定的允许转移 $i \\to j$。从 $\\mathbf{R}$ 构建生成元矩阵 $\\mathbf{G}$。稳态分布 $\\boldsymbol{\\pi}$ 通过求解一个线性系统来找到，该系统由 $\\mathbf{G}^\\top \\boldsymbol{\\pi} = \\mathbf{0}$ 中的一个方程被归一化条件 $\\sum_i \\pi_i = 1$ 替换而形成。然后将得到的 $\\boldsymbol{\\pi}$ 与理论玻尔兹曼分布 $\\boldsymbol{\\pi}_{\\text{B}} = \\exp(-\\mathbf{E})/\\sum\\exp(-\\mathbf{E})$ 进行比较。如果 $\\boldsymbol{\\pi}$ 和 $\\boldsymbol{\\pi}_{\\text{B}}$ 的分量之间的最大绝对差小于 $\\varepsilon_{\\mathrm{db}} = 10^{-8}$，则测试通过。测试 3 使用一个两状态系统，测试 4 使用一个三状态系统。\n\n**测试 5（边界情况 $R=0$）**：\n此测试检查对没有可能迁出事件的状态的处理。速率向量为 $\\mathbf{r} = (0.0, 0.0, 0.0)$，因此总速率为 $R=0$。一个正确的 kMC 实现应将此识别为终止状态并且不选择任何事件。如果选择函数返回“无事件”的指示符，则测试通过。\n\n**测试 6（确定性选择）**：\n此测试验证当只有一个事件具有非零速率（例如 $\\mathbf{r} = (0.0, 0.0, 5.0)$）时的正确行为。在这种情况下，选择必须是确定性的：必须总是选择具有正速率的事件。该测试执行 $N=10000$ 次选择，并且只有在每次都选择正确的事件索引时才通过。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the kMC unit test suite and print results.\n    \"\"\"\n\n    def select_event(rates: np.ndarray, rng: np.random.Generator):\n        \"\"\"\n        Selects an event based on a list of rates using the cumulative rate method.\n        \n        Args:\n            rates: A numpy array of event rates.\n            rng: A numpy random number generator instance.\n        \n        Returns:\n            The index of the selected event, or None if the total rate is zero.\n        \"\"\"\n        total_rate = np.sum(rates)\n        \n        # Handle the boundary case where no events are possible.\n        if total_rate = 1e-15: # Use a small tolerance for floating point comparison\n            return None\n\n        # Generate a random number u in [0, total_rate).\n        random_draw = rng.random() * total_rate\n        \n        # Use searchsorted for a robust and efficient implementation of the\n        # first-passage algorithm.\n        cumulative_rates = np.cumsum(rates)\n        \n        # Find the index of the first cumulative rate greater than the random draw.\n        selected_index = np.searchsorted(cumulative_rates, random_draw, side='right')\n        \n        return int(selected_index)\n\n    def test_1():\n        \"\"\"\n        Test 1: On-lattice rate normalization and event selection.\n        \"\"\"\n        rates = np.array([1.0, 2.0, 3.0, 0.0])\n        n_samples = 100000\n        seed = 12345\n        eps_norm = 1e-12\n        eps_freq = 5e-3\n        \n        total_rate = np.sum(rates)\n        if total_rate = 1e-15: return False\n\n        p_theoretical = rates / total_rate\n        \n        # 1. Check rate normalization\n        norm_check = abs(np.sum(p_theoretical) - 1.0)  eps_norm\n        if not norm_check: return False\n        \n        # 2. Empirically estimate probabilities\n        rng = np.random.default_rng(seed)\n        counts = np.zeros_like(rates, dtype=int)\n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx is not None:\n                counts[idx] += 1\n        \n        # Check that the event with rate 0 was never selected\n        if counts[3] != 0: return False\n\n        p_empirical = counts / n_samples\n        \n        # 3. Check frequency deviation\n        freq_check = np.max(np.abs(p_empirical - p_theoretical))  eps_freq\n        \n        return freq_check\n\n    def test_2():\n        \"\"\"\n        Test 2: Off-lattice rate normalization and event selection.\n        \"\"\"\n        distances = np.array([0.1, 0.2, 1.0])\n        k0 = 1.0\n        alpha = 2.5\n        n_samples = 200000\n        seed = 54321\n        eps_norm = 1e-12\n        eps_freq = 5e-3\n        \n        rates = k0 * np.exp(-alpha * distances)\n        total_rate = np.sum(rates)\n        if total_rate = 1e-15: return False\n        \n        p_theoretical = rates / total_rate\n        \n        # 1. Check rate normalization\n        norm_check = abs(np.sum(p_theoretical) - 1.0)  eps_norm\n        if not norm_check: return False\n        \n        # 2. Empirically estimate probabilities\n        rng = np.random.default_rng(seed)\n        counts = np.zeros_like(rates, dtype=int)\n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx is not None:\n                 counts[idx] += 1\n        \n        p_empirical = counts / n_samples\n        \n        # 3. Check frequency deviation\n        freq_check = np.max(np.abs(p_empirical - p_theoretical))  eps_freq\n        \n        return freq_check\n\n    def test_3():\n        \"\"\"\n        Test 3: Two-state detailed balance.\n        \"\"\"\n        energies = np.array([0.0, 1.0])\n        nu = 1.0\n        eps_db = 1e-8\n        n_states = len(energies)\n        \n        # 1. Calculate theoretical Boltzmann distribution\n        pi_boltzmann = np.exp(-energies) / np.sum(np.exp(-energies))\n        \n        # 2. Construct rate and generator matrices\n        rate_matrix = np.zeros((n_states, n_states))\n        for i in range(n_states):\n            for j in range(n_states):\n                if i != j:\n                    rate_matrix[i, j] = nu * np.exp(-(energies[j] - energies[i]) / 2.0)\n        \n        generator_matrix = rate_matrix - np.diag(np.sum(rate_matrix, axis=1))\n\n        # 3. Solve for the stationary distribution\n        # System is G.T @ pi = 0, with sum(pi) = 1\n        A = generator_matrix.T\n        A[-1, :] = 1.0 # Replace last row with normalization condition\n        b = np.zeros(n_states)\n        b[-1] = 1.0\n        \n        try:\n            pi_stationary = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return False\n\n        # 4. Compare distributions\n        return np.max(np.abs(pi_stationary - pi_boltzmann))  eps_db\n\n    def test_4():\n        \"\"\"\n        Test 4: Three-state ring detailed balance on-lattice.\n        \"\"\"\n        energies = np.array([0.0, 0.5, 1.0])\n        nu = 2.0\n        eps_db = 1e-8\n        n_states = len(energies)\n        \n        # 1. Calculate theoretical Boltzmann distribution\n        pi_boltzmann = np.exp(-energies) / np.sum(np.exp(-energies))\n        \n        # 2. Construct rate and generator matrices\n        # For 3 states, a ring is a fully connected graph.\n        rate_matrix = np.zeros((n_states, n_states))\n        for i in range(n_states):\n            for j in range(n_states):\n                if i != j:\n                    rate_matrix[i, j] = nu * np.exp(-(energies[j] - energies[i]) / 2.0)\n\n        generator_matrix = rate_matrix - np.diag(np.sum(rate_matrix, axis=1))\n\n        # 3. Solve for the stationary distribution\n        A = generator_matrix.T\n        A[-1, :] = 1.0\n        b = np.zeros(n_states)\n        b[-1] = 1.0\n        \n        try:\n            pi_stationary = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            return False\n\n        # 4. Compare distributions\n        return np.max(np.abs(pi_stationary - pi_boltzmann))  eps_db\n\n    def test_5():\n        \"\"\"\n        Test 5: Boundary case R = 0.\n        \"\"\"\n        rates = np.array([0.0, 0.0, 0.0])\n        rng = np.random.default_rng() # seed doesn't matter\n        \n        result = select_event(rates, rng)\n        \n        return result is None\n\n    def test_6():\n        \"\"\"\n        Test 6: Deterministic event selection.\n        \"\"\"\n        rates = np.array([0.0, 0.0, 5.0])\n        n_samples = 10000\n        seed = 111\n        \n        rng = np.random.default_rng(seed)\n        correct_index = 2\n        \n        for _ in range(n_samples):\n            idx = select_event(rates, rng)\n            if idx != correct_index:\n                return False\n                \n        return True\n\n    results = [\n        test_1(),\n        test_2(),\n        test_3(),\n        test_4(),\n        test_5(),\n        test_6(),\n    ]\n    \n    # Format and print the final output as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "无记忆性，即马尔可夫动力学的假设，是标准 KMC 的基础，但在记忆效应变得显著的复杂或粗粒化系统中，这一假设可能不成立。这个高级练习将介绍一种基于时间重整化定理的强大统计方法，用于分析您模拟数据中的等待时间分布。这将使您能够诊断出非指数统计特征，从而为您的模型中马尔可夫假设的有效性提供或反对的定量证据 。",
            "id": "3790261",
            "problem": "您的任务是设计并实现一个基于随机过程基本原理的诊断测试，用以区分马尔可夫链格上动力学蒙特卡洛（kinetic Monte Carlo）与通过非指数等待时间统计表现出记忆效应的粗粒化离格动力学。在马尔可夫链格上动力学蒙特卡洛中，由于其无记忆性，事件的等待时间是独立同分布的指数随机变量。相反，粗粒化、未解析的自由度或集体性离格运动会引入有效的记忆核，并导致非指数的等待时间。\n\n从以下基本概念出发：\n\n- 一个更新过程具有独立同分布的等待时间 $\\{T_i\\}_{i=1}^N$，其累积分布函数为 $F(t)$，概率密度函数为 $f(t) = F'(t)$，生存函数为 $S(t) = 1 - F(t)$，风险函数为 $h(t) = \\dfrac{f(t)}{S(t)}$。\n- 泊松过程具有无记忆性 $P(T  t + s \\mid T  s) = P(T  t)$，这等价于风险函数为常数 $h(t) = \\lambda$ 以及概率密度函数为指数分布 $f(t) = \\lambda e^{-\\lambda t}$。\n- 时间重标度定理指出，如果风险函数模型 $h(t)$ 是正确的，那么变换后的变量 $\\tau_i = \\int_0^{T_i} h(s)\\,ds$ 是速率为 1 的独立同分布指数随机变量，并且进一步变换得到的 $U_i = 1 - e^{-\\tau_i}$ 是在 $[0,1]$ 区间上独立同分布的均匀随机变量。\n\n您的目标是构建一个程序，应用基于时间重标度的拟合优度检验来测试等待时间是否服从指数分布（即马尔可夫原假设），从而诊断出指示记忆核存在的偏差。使用以下测试规范：\n\n- 在原假设下，将常数风险估计为 $\\hat{\\lambda} = 1/\\bar{T}$，其中 $\\bar{T}$ 是等待时间的样本均值。\n- 计算 $\\tau_i = \\hat{\\lambda} T_i$ 和 $U_i = 1 - e^{-\\tau_i}$。\n- 在显著性水平 $\\alpha = 0.01$ 下，对 $\\{U_i\\}$ 与 Uniform$(0,1)$ 分布进行 Kolmogorov–Smirnov 检验。拒绝原假设表明统计数据非指数分布，从而说明存在记忆核效应。\n\n此外，计算一个风险变异性指数（用于解释，而非决策），其定义基于经验支撑集上的 $B$ 个等距区间，具体如下：设 $\\widehat{f}_b$ 是区间 $b$ 中基于直方图的密度估计，$\\widehat{S}_b$ 是区间 $b$ 左边缘的经验生存值。对于 $\\widehat{S}_b  0.05$ 的区间，定义分箱风险估计为 $\\widehat{h}_b = \\widehat{f}_b / \\widehat{S}_b$，变异系数为 $\\mathrm{CV}_h = \\dfrac{\\mathrm{std}(\\{\\widehat{h}_b\\})}{\\mathrm{mean}(\\{\\widehat{h}_b\\})}$。接近于零的 $\\mathrm{CV}_h$ 是常数风险的特征。\n\n为以下测试套件构建以秒为单位的合成等待时间样本，以检验该方法的不同方面：\n\n- 案例 A（理想路径，马尔可夫链格上）：指数分布，速率 $\\lambda_A = 2\\,\\mathrm{s}^{-1}$；样本大小 $N_A = 5000$。\n- 案例 B（具有老化记忆的离格系统；重尾行为的边界）：韦布尔分布，形状参数 $k_B = 0.7$，尺度参数 $\\theta_B$ 的选择使得 $\\mathbb{E}[T] = 0.5\\,\\mathrm{s}$，即 $\\theta_B = 0.5 / \\Gamma(1 + 1/k_B)$；样本大小 $N_B = 5000$。\n- 案例 C（隐藏的异质性；导致非指数统计的混合分布）：超指数混合分布，其中以概率 $p_C = 0.3$，等待时间 $T \\sim \\mathrm{Exp}(\\lambda_1)$ 且 $\\lambda_1 = 1\\,\\mathrm{s}^{-1}$，以概率 $1 - p_C$，等待时间 $T \\sim \\mathrm{Exp}(\\lambda_2)$ 且 $\\lambda_2 = 5\\,\\mathrm{s}^{-1}$；样本大小 $N_C = 5000$。\n- 案例 D（小样本边界条件，马尔可夫）：指数分布，速率 $\\lambda_D = 2\\,\\mathrm{s}^{-1}$；样本大小 $N_D = 50$。\n\n所有等待时间均以秒为单位。为保证可复现性，请使用固定的伪随机种子。您的程序必须：\n\n- 为这四个案例生成等待时间样本。\n- 在 $\\alpha = 0.01$ 的显著性水平下应用所述的时间重标度检验。\n- 生成单行输出，包含一个由四个布尔值组成的列表 $[b_A, b_B, b_C, b_D]$，其中如果检验拒绝了案例 $X$ 的指数原假设，则 $b_X$ 为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。该行必须以逗号分隔的 Python 风格列表精确打印，例如：“[True,False,True,False]”。\n\n通过使用给定的分布和参数来确保科学真实性。输出没有物理单位，因为它由布尔值组成。代码必须是自包含的，并且无需用户输入即可运行。",
            "solution": "该问题要求设计并实现一个统计检验，用以诊断动力学蒙特卡洛（kMC）模拟中偏离马尔可夫行为的现象。\n\n此检验的物理基础在于随机过程的马尔可夫性与其等待时间的统计分布之间的密切联系。\n\n格上 kMC 的一个基本原则是，系统的演化是一个连续时间马尔可夫链。这意味着该过程是无记忆的：转移到未来状态的概率仅取决于当前状态，而与到达该状态的路径无关。这种无记忆性的一个直接数学推论是，到下一个事件发生的等待时间 $T$ 服从指数分布 $f(t) = \\lambda e^{-\\lambda t}$，其中速率参数 $\\lambda$ 是从当前状态出发的所有可能事件的速率之和。在总速率恒定的模拟中，等待时间序列 $\\{T_i\\}_{i=1}^N$ 构成了来自泊松过程的样本。\n\n相反，离格系统或粗粒化模型通常表现出记忆性。这种“记忆”源于未解析的自由度或集体运动，导致事件发生的概率取决于系统的历史。这样的过程是非马尔可夫的，其等待时间不服从指数分布。这些过程更普遍地被描述为更新过程，其特征是从某个非指数分布中抽取的独立同分布（i.i.d.）等待时间序列 $\\{T_i\\}$。\n\n任何更新过程都可以用其风险函数 $h(t)$ 来表征，该函数给出在事件尚未发生的情况下，在时间 $t$ 发生事件的瞬时概率速率。其形式化定义为 $h(t) = f(t)/S(t)$，其中 $f(t)$ 是概率密度函数（PDF），$S(t) = 1 - F(t)$ 是生存函数（$F(t)$ 是累积分布函数，CDF）。马尔可夫过程的无记忆性唯一等价于具有恒定的风险函数 $h(t) = \\lambda$。任何偏离常数风险的情况都表明这是一个非马尔可夫的、依赖于记忆的过程。\n\n诊断检验通过时间重标度定理利用了这一原理。该定理指出，如果一组等待时间 $\\{T_i\\}$ 是从一个已知风险函数为 $h(t)$ 的分布中抽取的，那么变换后的变量 $\\tau_i = \\int_0^{T_i} h(s)\\,ds$ 是独立同分布的，且服从速率为 1 的指数分布。\n\n我们可以基于该定理构建一个统计检验。原假设 $H_0$ 是等待时间服从指数分布，这对应于一个马尔可夫过程。\n$H_0$：等待时间 $\\{T_i\\}$ 是从某个未知 $\\lambda  0$ 的 $\\mathrm{Exponential}(\\lambda)$ 分布中抽取的。\n\n在 $H_0$ 假设下，风险函数为常数 $h(t) = \\lambda$。给定一个包含 $N$ 个等待时间的样本，该速率的最大似然估计量是 $\\hat{\\lambda} = 1/\\bar{T}$，其中 $\\bar{T} = \\frac{1}{N}\\sum_{i=1}^N T_i$ 是样本均值。\n\n使用这个估计的风险函数并应用时间重标度定理，我们计算重标度后的时间：\n$$ \\tau_i = \\int_0^{T_i} \\hat{\\lambda}\\,ds = \\hat{\\lambda} T_i $$\n如果 $H_0$ 为真，集合 $\\{\\tau_i\\}$ 应该是一个来自 $\\mathrm{Exponential}(1)$ 分布的样本。\n\n为了便于检验，我们应用概率积分变换。如果一个随机变量 $\\tau$ 服从 $\\mathrm{Exponential}(1)$ 分布，其累积分布函数（CDF）为 $F_{\\tau}(t) = 1 - e^{-t}$。那么变换后的变量 $U = F_{\\tau}(\\tau) = 1 - e^{-\\tau}$ 将在区间 $[0, 1]$ 上均匀分布。因此，通过对整个样本计算 $U_i = 1 - e^{-\\tau_i} = 1 - e^{-\\hat{\\lambda} T_i}$，我们可以将问题重新表述为检验一个新的原假设 $H'_0$：\n$H'_0$：样本 $\\{U_i\\}$ 是从 $\\mathrm{Uniform}(0, 1)$ 分布中抽取的。\n\n这个假设使用双边 Kolmogorov-Smirnov (KS) 检验进行测试。KS 检验将样本 $\\{U_i\\}$ 的经验累积分布函数与 $\\mathrm{Uniform}(0, 1)$ 分布的累积分布函数进行比较。它量化了两者间的最大差异并计算出一个 p 值。这个 p 值表示，如果数据真的来自 $\\mathrm{Uniform}(0, 1)$ 分布，观察到如此大的差异（或更大差异）的概率。如果 p 值小于预定的显著性水平 $\\alpha$（此处为 $\\alpha = 0.01$），我们就拒绝 $H'_0$，并由此拒绝原假设 $H_0$。拒绝原假设表明等待时间数据与指数分布不一致，从而为存在具有记忆的非马尔可夫动力学提供了有力证据。\n\n提供的测试案例旨在验证此程序：\n- 案例 A（指数分布, $N_A=5000$, $\\lambda_A = 2\\,\\mathrm{s}^{-1}$）：原假设为真。我们预期会得到一个较高的 p 值，并且不会拒绝 $H_0$（结果：`False`）。\n- 案例 B（韦布尔分布, $N_B=5000$, $k_B=0.7$）：形状参数 $k_B  1$ 意味着递减的风险率，这明显违反了 $H_0$。对于大样本，检验应该有足够的能力检测到这一点。我们预期会拒绝 $H_0$（结果：`True`）。\n- 案例 C（超指数分布, $N_C=5000$）：这种指数分布的混合本身不是指数分布，并且具有非恒定的风险函数。我们预期会拒绝 $H_0$（结果：`True`）。\n- 案例 D（指数分布, $N_D=50$, $\\lambda_D = 2\\,\\mathrm{s}^{-1}$）：原假设为真，但小样本量极大地降低了检验的统计功效。不拒绝 $H_0$ 是最可能的结果，这说明了在数据不足的情况下进行统计检验的局限性（结果：`False`）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats, special\n\ndef solve():\n    \"\"\"\n    Runs a diagnostic test on four synthetic waiting-time datasets to distinguish\n    Markovian (exponential) from non-Markovian (non-exponential) dynamics.\n    \"\"\"\n    # Define constants and the pseudorandom number generator for reproducibility.\n    SEED = 12345\n    rng = np.random.default_rng(SEED)\n    ALPHA = 0.01\n\n    # --- Case A: Exponential (Markovian null hypothesis is true) ---\n    N_A = 5000\n    lambda_A = 2.0\n    # The 'scale' parameter for numpy.random.exponential is 1/lambda.\n    samples_A = rng.exponential(scale=1.0/lambda_A, size=N_A)\n\n    # --- Case B: Weibull (Non-Markovian, aging memory) ---\n    N_B = 5000\n    k_B = 0.7  # Shape parameter\n    mean_B = 0.5\n    # The mean of a Weibull(k, theta) distribution is theta * Gamma(1 + 1/k).\n    # We solve for the scale parameter theta.\n    theta_B = mean_B / special.gamma(1.0 + 1.0/k_B)\n    # numpy.random.weibull(a) generates samples with scale=1. We must\n    # multiply by the calculated scale parameter theta_B.\n    samples_B = theta_B * rng.weibull(a=k_B, size=N_B)\n\n    # --- Case C: Hyperexponential (Non-Markovian, mixture) ---\n    N_C = 5000\n    p_C = 0.3\n    lambda1_C = 1.0\n    lambda2_C = 5.0\n    \n    # Generate mixture samples.\n    choices_C = rng.uniform(size=N_C)\n    samples_C = np.zeros(N_C)\n    # Create a boolean mask to select which samples come from the first exponential.\n    mask1 = choices_C  p_C\n    n1 = np.sum(mask1)\n    n2 = N_C - n1\n    samples_C[mask1] = rng.exponential(scale=1.0/lambda1_C, size=n1)\n    samples_C[~mask1] = rng.exponential(scale=1.0/lambda2_C, size=n2)\n\n    # --- Case D: Exponential, small sample (test of statistical power) ---\n    N_D = 50\n    lambda_D = 2.0\n    samples_D = rng.exponential(scale=1.0/lambda_D, size=N_D)\n\n    all_samples = [samples_A, samples_B, samples_C, samples_D]\n    results = []\n\n    for T_values in all_samples:\n        # --- Apply the time-rescaling goodness-of-fit test ---\n        \n        # 1. Estimate the constant hazard rate lambda under the null hypothesis.\n        # The Maximum Likelihood Estimator for an exponential distribution is 1/mean.\n        T_bar = np.mean(T_values)\n        \n        # Edge case handling: a non-positive mean is impossible for waiting times\n        # and would not be exponential.\n        if T_bar = 0:\n            results.append(True)  # Reject the null hypothesis.\n            continue\n            \n        lambda_hat = 1.0 / T_bar\n\n        # 2. Apply the time-rescaling theorem and the probability integral transform.\n        # If the data is exponential, the transformed variables U should be Uniform(0,1).\n        U_values = 1.0 - np.exp(-lambda_hat * T_values)\n\n        # 3. Perform a Kolmogorov-Smirnov test against the Uniform(0,1) distribution.\n        # The null hypothesis of kstest is that the data is drawn from the specified dist.\n        ks_statistic, p_value = stats.kstest(U_values, 'uniform')\n\n        # 4. Make a decision based on the significance level alpha.\n        # We reject the null hypothesis if the p-value is less than alpha.\n        is_rejected = p_value  ALPHA\n        results.append(is_rejected)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}