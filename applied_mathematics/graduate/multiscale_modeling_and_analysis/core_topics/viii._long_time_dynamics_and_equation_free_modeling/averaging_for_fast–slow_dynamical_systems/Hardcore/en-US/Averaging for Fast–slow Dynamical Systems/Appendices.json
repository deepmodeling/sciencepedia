{
    "hands_on_practices": [
        {
            "introduction": "Mastering the method of averaging begins with a clear, fundamental example. This practice provides a streamlined system to demonstrate the core mechanics of second-order averaging, a crucial technique for capturing subtle, long-term drifts that first-order averaging might miss. By working through this problem, you will build proficiency in applying near-identity transformations and computing the corrective terms that refine our understanding of the slow dynamics .",
            "id": "3734703",
            "problem": "Consider the two-dimensional fast–slow ordinary differential equation (ODE) with a single fast angular variable\n$$\n\\dot{x} \\;=\\; \\epsilon\\, x \\sin \\theta,\\qquad \\dot{\\theta} \\;=\\; \\omega,\n$$\nwhere $\\epsilon$ is a small, positive, dimensionless parameter, $\\omega \\neq 0$ is a constant frequency, and $\\theta$ is a $2\\pi$-periodic phase variable measured in radians. The function multiplying $\\epsilon$ is $2\\pi$-periodic in $\\theta$ and depends smoothly on $x$.\n\nStarting from the foundational definition of the averaging principle for systems with a single fast phase and employing a near-identity change of variables consistent with second-order averaging, derive the averaged slow dynamics for the $x$-component up to and including the order $\\epsilon^{2}$ term. Then, compute the closed-form analytic expression for the order $\\epsilon^{2}$ correction to the drift of $x$ (that is, the $\\mathcal{O}(\\epsilon^{2})$ averaged vector field for $x$). Your final answer must be given as a single analytic expression. No numerical rounding is required.",
            "solution": "The user wants me to solve a problem.\nMy plan is to first validate the problem statement. If it is valid, I will proceed with solving it.\n\n### Step 1: Extract Givens\nThe problem statement provides the following information:\n1.  A two-dimensional fast–slow ordinary differential equation (ODE) system:\n    -   $\\dot{x} \\;=\\; \\epsilon\\, x \\sin \\theta$\n    -   $\\dot{\\theta} \\;=\\; \\omega$\n2.  Parameters and variables:\n    -   $\\epsilon$: a small, positive, dimensionless parameter.\n    -   $\\omega$: a non-zero constant frequency ($\\omega \\neq 0$).\n    -   $\\theta$: a $2\\pi$-periodic phase variable.\n3.  Properties: The function multiplying $\\epsilon$, i.e., $x \\sin \\theta$, is $2\\pi$-periodic in $\\theta$ and depends smoothly on $x$.\n4.  Task: Derive the averaged slow dynamics for the $x$-component up to and including the order $\\epsilon^{2}$ term and compute the closed-form analytic expression for the order $\\epsilon^{2}$ correction to the drift of $x$. This correction is the $\\mathcal{O}(\\epsilon^{2})$ term in the averaged vector field.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is a standard exercise in the theory of averaging for non-autonomous dynamical systems. The method of averaging is a well-established and rigorously justified technique in the study of nonlinear dynamics and perturbation theory. The ODEs are mathematically sound.\n2.  **Well-Posed**: The problem is well-posed. It asks for the computation of a specific term in a standard perturbation expansion. The inputs are clearly defined, and the procedure leads to a unique, well-defined answer.\n3.  **Objective**: The problem is stated in precise mathematical language, free from any subjective or ambiguous terminology.\n4.  **Completeness**: The problem is self-contained. All necessary equations, parameters, and conditions are provided to carry out the derivation.\n5.  **Relevance**: The problem is directly relevant to the topic of averaging for fast-slow dynamical systems.\n\nThe problem does not exhibit any of the flaws listed in the validation checklist. The fact that the final result of a calculation might be simple (e.g., zero) does not render the problem trivial or pseudo-profound, as the process of arriving at that result requires a correct application of the corresponding theory.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. I will proceed with the solution.\n\nThe problem is to find the averaged dynamics for the slow variable $x$ in the system:\n$$\n\\dot{x} \\;=\\; \\epsilon\\, x \\sin \\theta \\\\\n\\dot{\\theta} \\;=\\; \\omega\n$$\nup to order $\\epsilon^2$. This is a non-autonomous system for $x$ of the form $\\dot{x} = \\epsilon F(x, t)$, where the time-dependence is periodic through $\\theta=\\omega t + \\theta_0$. We can set $\\theta_0=0$ without loss of generality. The vector field is $F(x, \\theta) = x \\sin \\theta.\n$\nThe method of second-order averaging seeks an averaged equation for a slow variable $y(t)$ that approximates $x(t)$ over long time scales. The dynamics of $y$ are given by:\n$$\n\\dot{y} = \\epsilon F_1(y) + \\epsilon^2 F_2(y) + \\mathcal{O}(\\epsilon^3)\n$$\nThe original variable $x$ is related to the averaged variable $y$ by a near-identity transformation:\n$$\nx(t) = y(t) + \\epsilon u_1(y(t), \\theta(t)) + \\mathcal{O}(\\epsilon^2)\n$$\nwhere $u_1$ is a periodic function with zero mean over one period of oscillation.\n\nThe formulas for the first- and second-order averaged terms are:\n1.  $F_1(y) = \\langle F(y, \\theta) \\rangle$\n2.  $F_2(y) = \\left\\langle \\frac{\\partial F}{\\partial y}(y, \\theta) u_1(y, \\theta) \\right\\rangle$\n\nwhere $\\langle \\cdot \\rangle$ denotes the average over one period of the fast variable $\\theta$:\n$$\n\\langle g(\\theta) \\rangle = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} g(\\theta) \\, d\\theta\n$$\nThe function $u_1(y, \\theta)$ is determined by solving the homological equation:\n$$\n\\omega \\frac{\\partial u_1}{\\partial \\theta} = F(y, \\theta) - F_1(y)\n$$\nsuch that $\\langle u_1 \\rangle = 0$.\n\nLet's compute these terms for the given system.\n\n**Step 1: Compute the first-order averaged term $F_1(y)$**\nThe function $F(y, \\theta)$ is $y \\sin \\theta$. We compute its average over $\\theta$:\n$$\nF_1(y) = \\langle y \\sin \\theta \\rangle = y \\langle \\sin \\theta \\rangle = y \\left( \\frac{1}{2\\pi} \\int_{0}^{2\\pi} \\sin \\theta \\, d\\theta \\right)\n$$\nThe integral of $\\sin \\theta$ over a full period is zero:\n$$\n\\int_{0}^{2\\pi} \\sin \\theta \\, d\\theta = [-\\cos \\theta]_{0}^{2\\pi} = -(\\cos(2\\pi) - \\cos(0)) = -(1-1) = 0\n$$\nTherefore, the first-order term is zero:\n$$\nF_1(y) = 0\n$$\n\n**Step 2: Compute the auxiliary function $u_1(y, \\theta)$**\nThe homological equation is:\n$$\n\\omega \\frac{\\partial u_1}{\\partial \\theta} = F(y, \\theta) - F_1(y) = y \\sin \\theta - 0 = y \\sin \\theta\n$$\nWe integrate with respect to $\\theta$ to find $u_1$:\n$$\nu_1(y, \\theta) = \\int \\frac{y}{\\omega} \\sin \\theta \\, d\\theta = \\frac{y}{\\omega} (-\\cos \\theta) + C(y) = -\\frac{y}{\\omega} \\cos \\theta + C(y)\n$$\nwhere $C(y)$ is an integration constant that may depend on $y$. We impose the condition that $u_1$ has zero average:\n$$\n\\langle u_1(y, \\theta) \\rangle = \\left\\langle -\\frac{y}{\\omega} \\cos \\theta + C(y) \\right\\rangle = -\\frac{y}{\\omega} \\langle \\cos \\theta \\rangle + \\langle C(y) \\rangle\n$$\nSince $\\langle \\cos \\theta \\rangle = 0$ and $C(y)$ is independent of $\\theta$, this becomes $\\langle u_1 \\rangle = C(y)$. The condition $\\langle u_1 \\rangle = 0$ requires $C(y) = 0$.\nThus, the auxiliary function is:\n$$\nu_1(y, \\theta) = -\\frac{y}{\\omega} \\cos \\theta\n$$\n\n**Step 3: Compute the second-order averaged term $F_2(y)$**\nThe formula for $F_2(y)$ is $F_2(y) = \\left\\langle \\frac{\\partial F}{\\partial y}(y, \\theta) u_1(y, \\theta) \\right\\rangle$.\nFirst, we compute the partial derivative of $F(y, \\theta) = y \\sin \\theta$ with respect to $y$:\n$$\n\\frac{\\partial F}{\\partial y} = \\frac{\\partial}{\\partial y}(y \\sin \\theta) = \\sin \\theta\n$$\nNow, we form the product inside the average:\n$$\n\\frac{\\partial F}{\\partial y} u_1 = (\\sin \\theta) \\left( -\\frac{y}{\\omega} \\cos \\theta \\right) = -\\frac{y}{\\omega} \\sin \\theta \\cos \\theta\n$$\nWe now compute the average of this expression. We can use the trigonometric identity $\\sin(2\\theta) = 2 \\sin \\theta \\cos \\theta$, which implies $\\sin \\theta \\cos \\theta = \\frac{1}{2} \\sin(2\\theta)$.\n$$\nF_2(y) = \\left\\langle -\\frac{y}{\\omega} \\sin \\theta \\cos \\theta \\right\\rangle = -\\frac{y}{\\omega} \\left\\langle \\frac{1}{2} \\sin(2\\theta) \\right\\rangle = -\\frac{y}{2\\omega} \\langle \\sin(2\\theta) \\rangle\n$$\nThe average of $\\sin(2\\theta)$ over a $2\\pi$ interval is:\n$$\n\\langle \\sin(2\\theta) \\rangle = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\sin(2\\theta) \\, d\\theta = \\frac{1}{2\\pi} \\left[ -\\frac{1}{2} \\cos(2\\theta) \\right]_0^{2\\pi}\n$$\n$$\n= -\\frac{1}{4\\pi} [\\cos(4\\pi) - \\cos(0)] = -\\frac{1}{4\\pi} [1 - 1] = 0\n$$\nTherefore, the second-order averaged term is also zero:\n$$\nF_2(y) = -\\frac{y}{2\\omega} \\times 0 = 0\n$$\nThe averaged equation for the slow dynamics of $x$ up to order $\\epsilon^2$ is $\\dot{y} = \\epsilon(0) + \\epsilon^2(0) = 0$. The order $\\epsilon^2$ correction to the drift of $x$ is the function $F_2(y)$, which is $0$.",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "Having practiced the fundamental calculations, we now apply the averaging principle to a classic model in nonlinear dynamics: the parametrically forced Duffing oscillator. This problem illustrates how to transform a second-order ODE into a system of slow-flow equations for amplitude and phase, a powerful technique for analyzing oscillatory systems. The resulting averaged equations reveal the conditions for parametric resonance, where the system's amplitude can grow due to periodic modulation of its parameters .",
            "id": "3734768",
            "problem": "Consider the dimensionless Duffing oscillator with small periodic parametric forcing,\n$$\n\\ddot{x} + x + \\varepsilon\\left(\\delta\\,x + \\beta\\,x^{3} + \\gamma \\cos(2 t)\\,x\\right) = 0,\n$$\nwhere $x(t)$ is the displacement, $t$ is the fast time, $\\varepsilon$ satisfies $0<\\varepsilon\\ll 1$, and $\\delta$, $\\beta$, $\\gamma$ are fixed real parameters. The term $\\gamma \\cos(2 t)\\,x$ represents a small parametric modulation at frequency $2$, near the principal parametric resonance of the linear oscillator. Introduce the slow time $T=\\varepsilon t$ and perform averaging via a near-identity transformation consistent with removing nonresonant harmonics in the sense of normal form theory. Represent the solution in terms of a slowly varying complex amplitude $a(T)$ by\n$$\nx(t) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t),\n$$\nand then introduce polar variables by $a(T) = \\frac{R(T)}{2}\\exp\\big(i\\theta(T)\\big)$, where $R(T)>0$ is the slow amplitude and $\\theta(T)$ is the slow phase. Working consistently to first order in $\\varepsilon$ and assuming only the fundamental definitions of averaging and near-identity transformations for fast–slow systems, derive the averaged slow dynamics. Report, as your final answer, the single closed-form expression for the averaged drift term $F(R,\\theta)$ that appears in the slow amplitude equation $R'(T) = F(R,\\theta)$, where the prime denotes $\\frac{d}{dT}$. Provide only the expression $F(R,\\theta)$ (do not write the equation), and do not introduce any additional assumptions beyond those stated above. No rounding is required, and no units are involved. Express all intermediate and final formulas in LaTeX.",
            "solution": "The problem requires the derivation of the averaged slow-flow equation for the amplitude of a parametrically forced Duffing oscillator. The system is described by the second-order ordinary differential equation:\n$$\n\\ddot{x} + x + \\varepsilon\\left(\\delta\\,x + \\beta\\,x^{3} + \\gamma \\cos(2 t)\\,x\\right) = 0\n$$\nwhere $0 < \\varepsilon \\ll 1$. We are given the fast time $t$ and the slow time $T = \\varepsilon t$. The solution is sought in the form $x(t) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t)$, where $a(T)$ is a slowly varying complex amplitude.\n\nWe will use the method of multiple scales. We formally treat $t$ and $T$ as independent variables and expand the solution in powers of $\\varepsilon$:\n$$\nx(t) = x_0(t, T) + \\varepsilon x_1(t, T) + \\mathcal{O}(\\varepsilon^2)\n$$\nThe time derivatives are transformed as:\n$$\n\\frac{d}{dt} = \\frac{\\partial}{\\partial t} + \\varepsilon \\frac{\\partial}{\\partial T}\n$$\n$$\n\\frac{d^2}{dt^2} = \\left(\\frac{\\partial}{\\partial t} + \\varepsilon \\frac{\\partial}{\\partial T}\\right)^2 = \\frac{\\partial^2}{\\partial t^2} + 2\\varepsilon \\frac{\\partial^2}{\\partial t \\partial T} + \\varepsilon^2 \\frac{\\partial^2}{\\partial T^2}\n$$\nSubstituting these into the original equation and collecting terms by powers of $\\varepsilon$:\n\nAt order $\\mathcal{O}(\\varepsilon^0)$:\n$$\n\\frac{\\partial^2 x_0}{\\partial t^2} + x_0 = 0\n$$\nThe general solution to this equation is:\n$$\nx_0(t, T) = a(T)\\exp(i t) + \\overline{a(T)}\\exp(-i t)\n$$\nThis matches the form given in the problem statement. Here, $a(T)$ is an arbitrary function of the slow time $T$, to be determined at the next order.\n\nAt order $\\mathcal{O}(\\varepsilon^1)$:\n$$\n\\frac{\\partial^2 x_1}{\\partial t^2} + x_1 = -2\\frac{\\partial^2 x_0}{\\partial t \\partial T} - \\left(\\delta\\,x_0 + \\beta\\,x_0^{3} + \\gamma \\cos(2 t)\\,x_0\\right)\n$$\nThis is a forced linear oscillator equation for $x_1$. To ensure a uniformly valid expansion, we must eliminate secular terms (terms that grow unboundedly in $t$) from the right-hand side. Secular terms arise from forcing terms that are resonant with the natural frequency of the homogeneous operator, i.e., terms proportional to $\\exp(it)$ or $\\exp(-it)$.\n\nFirst, we compute the term involving the mixed partial derivative:\n$$\n\\frac{\\partial x_0}{\\partial t} = i a(T)\\exp(i t) - i \\overline{a(T)}\\exp(-i t)\n$$\n$$\n\\frac{\\partial^2 x_0}{\\partial t \\partial T} = i \\frac{da}{dT}\\exp(i t) - i \\frac{d\\overline{a}}{dT}\\exp(-i t) = i a'(T)\\exp(i t) - i \\overline{a'}(T)\\exp(-i t)\n$$\nSo, the first term on the right-hand side is:\n$$\n-2\\frac{\\partial^2 x_0}{\\partial t \\partial T} = -2i a'(T)\\exp(i t) + 2i \\overline{a'}(T)\\exp(-i t)\n$$\nNext, we expand the nonlinear and parametric terms, keeping $a(T)$ and $\\overline{a(T)}$ as constants with respect to the fast time $t$, and identify the resonant components.\n\n1.  Term $\\delta x_0$:\n    $$\n    \\delta x_0 = \\delta \\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)\n    $$\n    The term proportional to $\\exp(it)$ is $\\delta a\\exp(it)$.\n\n2.  Term $\\beta x_0^3$:\n    $$\n    x_0^3 = \\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)^3 = a^3\\exp(3it) + 3a^2\\overline{a}\\exp(it) + 3a\\overline{a}^2\\exp(-it) + \\overline{a}^3\\exp(-3it)\n    $$\n    The term proportional to $\\exp(it)$ from $\\beta x_0^3$ is $3\\beta a^2\\overline{a}\\exp(it) = 3\\beta |a|^2 a \\exp(it)$.\n\n3.  Term $\\gamma \\cos(2t) x_0$:\n    We use $\\cos(2t) = \\frac{1}{2}(\\exp(2it) + \\exp(-2it))$.\n    $$\n    \\gamma \\cos(2t) x_0 = \\frac{\\gamma}{2}\\left(\\exp(2it) + \\exp(-2it)\\right)\\left(a\\exp(it) + \\overline{a}\\exp(-it)\\right)\n    $$\n    $$\n    = \\frac{\\gamma}{2}\\left(a\\exp(3it) + \\overline{a}\\exp(it) + a\\exp(-it) + \\overline{a}\\exp(-3it)\\right)\n    $$\n    The term proportional to $\\exp(it)$ is $\\frac{\\gamma}{2}\\overline{a}\\exp(it)$.\n\nThe solvability condition requires that the sum of all coefficients of $\\exp(it)$ on the right-hand side of the $x_1$ equation must be zero.\n$$\n-2i a'(T) - \\delta a(T) - 3\\beta a(T)^2\\overline{a(T)} - \\frac{\\gamma}{2}\\overline{a(T)} = 0\n$$\nSolving for $a'(T)$:\n$$\n-2i a'(T) = \\delta a + 3\\beta a^2\\overline{a} + \\frac{\\gamma}{2}\\overline{a}\n$$\n$$\na'(T) = \\frac{i}{2}\\left(\\delta a + 3\\beta a|a|^2 + \\frac{\\gamma}{2}\\overline{a}\\right)\n$$\nThis is the averaged equation for the complex amplitude $a(T)$.\n\nNow, we introduce the polar representation $a(T) = \\frac{R(T)}{2}\\exp(i\\theta(T))$. We need to find the equation for $R'(T)$. We differentiate $a(T)$ with respect to $T$:\n$$\na'(T) = \\frac{R'(T)}{2}\\exp(i\\theta(T)) + i\\frac{R(T)\\theta'(T)}{2}\\exp(i\\theta(T)) = \\left(\\frac{R'}{2} + i\\frac{R\\theta'}{2}\\right)\\exp(i\\theta)\n$$\nWe substitute the polar form into the averaged equation for $a'(T)$:\n$$\na'(T) = \\frac{i}{2}\\left[\\delta \\frac{R}{2}\\exp(i\\theta) + 3\\beta \\left(\\frac{R}{2}\\right)^3\\exp(i\\theta) + \\frac{\\gamma}{2}\\frac{R}{2}\\exp(-i\\theta)\\right]\n$$\n$$\na'(T) = \\frac{i}{2}\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right)\\exp(i\\theta) + \\frac{\\gamma R}{4}\\exp(-i\\theta)\\right]\n$$\nEquating the two expressions for $a'(T)$:\n$$\n\\left(\\frac{R'}{2} + i\\frac{R\\theta'}{2}\\right)\\exp(i\\theta) = \\frac{i}{2}\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right)\\exp(i\\theta) + \\frac{\\gamma R}{4}\\exp(-i\\theta)\\right]\n$$\nMultiplying both sides by $2\\exp(-i\\theta)$:\n$$\nR' + iR\\theta' = i\\left[\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8}\\right) + \\frac{\\gamma R}{4}\\exp(-2i\\theta)\\right]\n$$\nNow, expand $\\exp(-2i\\theta) = \\cos(2\\theta) - i \\sin(2\\theta)$:\n$$\nR' + iR\\theta' = i\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\\right) - i^2\\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\n$$\nR' + iR\\theta' = \\frac{\\gamma R}{4}\\sin(2\\theta) + i\\left(\\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\\right)\n$$\nEquating the real and imaginary parts gives the averaged equations for $R(T)$ and $\\theta(T)$:\n$$\nR'(T) = \\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\n$$\nR\\theta'(T) = \\frac{\\delta R}{2} + \\frac{3\\beta R^3}{8} + \\frac{\\gamma R}{4}\\cos(2\\theta)\n$$\nThe problem asks for the expression $F(R, \\theta)$ in the equation $R'(T) = F(R, \\theta)$. From our derivation, this is:\n$$\nF(R, \\theta) = \\frac{\\gamma R}{4}\\sin(2\\theta)\n$$\nThis result is physically consistent, as the amplitude dynamics (energy injection or dissipation) are governed by the parametric forcing term $\\gamma$ and its phase relationship $2\\theta$ with the oscillator, while the detuning $\\delta$ and the nonlinearity $\\beta$ primarily affect the frequency of oscillation, which is captured in $\\theta'$.\n\nThe final expression is $\\frac{\\gamma R}{4}\\sin(2\\theta)$.",
            "answer": "$$\\boxed{\\frac{\\gamma R}{4}\\sin(2\\theta)}$$"
        },
        {
            "introduction": "Analytical solutions provide deep insight, but complex systems often require numerical simulation, which presents its own challenges for fast-slow dynamics. This practice bridges the gap between theory and computation by exploring a projective integration scheme, a method designed to efficiently handle systems with multiple time scales. By analyzing the numerical stability of this scheme, you will grapple with the practical constraints that fast dynamics impose on large-step integration methods .",
            "id": "3734756",
            "problem": "Consider the fast–slow linear system given by the pair of ordinary differential equations (ODE): \n$$\\frac{dx}{dt} = -\\frac{\\alpha}{\\epsilon}\\left(x - y\\right), \\qquad \\frac{dy}{dt} = -\\beta y + \\gamma,$$\nwhere $\\alpha > 0$, $\\beta \\ge 0$, $\\gamma \\in \\mathbb{R}$, and $0 < \\epsilon \\ll 1$ quantifies time-scale separation. The variable $x$ relaxes rapidly towards $y$ with a fast rate $-\\alpha/\\epsilon$, while $y$ evolves slowly. Let $u = x - y$ denote the fast deviation from the slow manifold.\n\nYou will implement a projective integration scheme using the following structure. Starting at time $t_n$ from a state $(x_n, y_n)$, take $K$ explicit Euler microsteps of size $\\Delta t$ applied to the full system to obtain states $(x_n^{(k)}, y_n^{(k)})$ for $k = 1, \\dots, K$. Then estimate the vector time derivative using the last two microstates as \n$$s = \\frac{1}{\\Delta t}\\Big(\\begin{bmatrix}x_n^{(K)} \\\\ y_n^{(K)}\\end{bmatrix} - \\begin{bmatrix}x_n^{(K-1)} \\\\ y_n^{(K-1)}\\end{bmatrix}\\Big).$$\nExecute a projective macro update of length $M \\Delta t$ by \n$$\\begin{bmatrix}x_{n+1} \\\\ y_{n+1}\\end{bmatrix} = \\begin{bmatrix}x_n^{(K)} \\\\ y_n^{(K)}\\end{bmatrix} + M \\Delta t\\, s,$$\nwhere $M \\ge 0$ is an integer.\n\nFor stability analysis of the fast component, use the scalar linear test problem for the fast mode \n$$\\frac{du}{dt} = \\lambda_f u, \\quad \\text{with} \\quad \\lambda_f = -\\frac{\\alpha}{\\epsilon},$$\nand define $z = \\lambda_f \\Delta t$. Assume that the explicit Euler micro-integrator for the fast mode is stable, which requires $-2 < z < 0$. By composing $K$ microsteps followed by the projective macro update defined above, derive from first principles the one-cycle scalar amplification factor $G(z, K, M)$ that multiplies $u$ across one projective integration cycle. Then, express the necessary and sufficient condition for fast-mode stability over one projective cycle in terms of $z$, $K$, and $M$.\n\nYour program must:\n- Implement the above projective integration scheme for the full $(x,y)$ system.\n- Derive in code, using your analytical result, the closed-form fast-mode amplification factor $G(z, K, M)$ and the induced constraint on admissible $M$ for given $(\\alpha, \\epsilon, \\Delta t, K)$ when $-2 < z < 0$.\n- For each parameter set in the test suite below, compute the maximum nonnegative integer macro projection factor $M_{\\max}$ such that fast-mode stability holds, i.e., $|G(z, K, M)| \\le 1$. If the micro-integrator is unstable (i.e., $z \\notin (-2, 0)$), return $-1$ for that test case.\n\nUse the following test suite of parameter sets, each specified as $(\\alpha, \\epsilon, \\Delta t, K)$:\n- Test $1$: $(10.0, 0.01, 0.0005, 3)$\n- Test $2$: $(10.0, 0.01, 0.0019, 2)$\n- Test $3$: $(5.0, 0.02, 0.0008, 3)$\n- Test $4$: $(1.0, 1.0, 0.01, 5)$\n- Test $5$: $(10.0, 0.01, 0.003, 3)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test suite, where each entry is the integer $M_{\\max}$ computed for that test case. For micro-unstable cases return $-1$. For example, a valid output format is $[m_1,m_2,m_3,m_4,m_5]$ with each $m_i$ an integer.",
            "solution": "The problem statement has been validated and is determined to be sound. It is scientifically grounded in the numerical analysis of stiff ordinary differential equations, specifically using projective integration. The problem is well-posed, providing all necessary information to derive the stability-limiting condition and compute the required values. The terminology is standard and the setup is consistent.\n\nThe core of the problem is to determine the stability of a projective integration scheme when applied to a fast-slow system. We analyze this by considering the scalar linear test problem for the fast mode, $u$, which represents the deviation from the slow manifold. The evolution of this fast mode is governed by:\n$$\n\\frac{du}{dt} = \\lambda_f u, \\quad \\text{with} \\quad \\lambda_f = -\\frac{\\alpha}{\\epsilon}\n$$\nHere, $\\alpha > 0$ and $0 < \\epsilon \\ll 1$, so $\\lambda_f$ is a large negative number.\n\nThe numerical scheme consists of three stages which we analyze step-by-step to find the one-cycle amplification factor $G(z, K, M)$ such that $u_{n+1} = G(z, K, M) u_n$. Let $z = \\lambda_f \\Delta t$, where $\\Delta t$ is the microstep time-step size. The stability of the explicit Euler micro-integrator requires $-2 < z < 0$.\n\n**Step 1: Explicit Euler Micro-integration**\n\nWe start at time $t_n$ with the value $u_n$. We take $K$ explicit Euler microsteps of size $\\Delta t$. The update rule for one step is:\n$$\nu^{(k+1)} = u^{(k)} + \\Delta t (\\lambda_f u^{(k)}) = (1 + \\lambda_f \\Delta t) u^{(k)} = (1 + z) u^{(k)}\n$$\nStarting with $u^{(0)} = u_n$, after $k$ steps, the state is:\n$$\nu_n^{(k)} = (1+z)^k u_n\n$$\nFor the subsequent steps, we will need the states after $K-1$ and $K$ microsteps:\n$$\nu_n^{(K-1)} = (1+z)^{K-1} u_n\n$$\n$$\nu_n^{(K)} = (1+z)^K u_n\n$$\n\n**Step 2: Derivative Estimation**\n\nThe time derivative is estimated using a finite difference on the last two microstates:\n$$\ns_u = \\frac{u_n^{(K)} - u_n^{(K-1)}}{\\Delta t}\n$$\nSubstituting the expressions from Step 1:\n$$\ns_u = \\frac{(1+z)^K u_n - (1+z)^{K-1} u_n}{\\Delta t} = \\frac{u_n}{\\Delta t} (1+z)^{K-1} ((1+z) - 1) = \\frac{u_n}{\\Delta t} (1+z)^{K-1} z\n$$\nSince $z = \\lambda_f \\Delta t$, we have $z/\\Delta t = \\lambda_f$. Thus, the estimated derivative is:\n$$\ns_u = \\lambda_f (1+z)^{K-1} u_n\n$$\n\n**Step 3: Projective Macro Update**\n\nThe final state $u_{n+1}$ is computed by projecting the state $u_n^{(K)}$ forward in time by a duration of $M \\Delta t$ using the estimated derivative $s_u$:\n$$\nu_{n+1} = u_n^{(K)} + M \\Delta t \\, s_u\n$$\nSubstituting the expressions for $u_n^{(K)}$ and $s_u$:\n$$\nu_{n+1} = (1+z)^K u_n + M \\Delta t \\left( \\lambda_f (1+z)^{K-1} u_n \\right)\n$$\nUsing $z = \\lambda_f \\Delta t$ again:\n$$\nu_{n+1} = (1+z)^K u_n + M z (1+z)^{K-1} u_n\n$$\nFactoring out $u_n$:\n$$\nu_{n+1} = \\left[ (1+z)^K + M z (1+z)^{K-1} \\right] u_n\n$$\n\n**Step 4: Amplification Factor and Stability Analysis**\n\nThe term in the brackets is the one-cycle scalar amplification factor, $G(z, K, M)$:\n$$\nG(z, K, M) = (1+z)^K + M z (1+z)^{K-1} = (1+z)^{K-1}[(1+z) + Mz]\n$$\n$$\nG(z, K, M) = (1+z)^{K-1}[1 + (M+1)z]\n$$\nFor the projective integration scheme to be stable for the fast mode, the magnitude of this amplification factor must be no greater than $1$:\n$$\n|G(z, K, M)| \\le 1 \\quad \\implies \\quad |(1+z)^{K-1}[1 + (M+1)z]| \\le 1\n$$\n$$\n|(1+z)^{K-1}| \\cdot |1 + (M+1)z| \\le 1\n$$\nThe problem assumes the micro-integrator is stable, i.e., $-2 < z < 0$, which implies $|1+z| < 1$. This allows us to rearrange the inequality:\n$$\n|1 + (M+1)z| \\le \\frac{1}{|(1+z)^{K-1}|} = |1+z|^{-(K-1)}\n$$\nThis inequality can be expanded into a pair of linear inequalities for the term $(M+1)z$:\n$$\n-|1+z|^{-(K-1)} \\le 1 + (M+1)z \\le |1+z|^{-(K-1)}\n$$\nWe need to solve for the maximum non-negative integer $M$. We isolate the term containing $M$:\n$$\n-1 -|1+z|^{-(K-1)} \\le (M+1)z \\le -1 + |1+z|^{-(K-1)}\n$$\nSince $z < 0$, dividing by $z$ reverses the inequality signs:\n$$\n\\frac{-1 + |1+z|^{-(K-1)}}{z} \\le M+1 \\le \\frac{-1 -|1+z|^{-(K-1)}}{z}\n$$\nThe lower bound for $M$ is satisfied for any non-negative $M$, as the condition results in $M$ being greater than a negative number. We thus focus on the upper bound for $M$:\n$$\nM+1 \\le \\frac{-1 - |1+z|^{-(K-1)}}{z}\n$$\n$$\nM \\le \\frac{-1 - |1+z|^{-(K-1)}}{z} - 1\n$$\nLet this upper bound be $M_{upper}$. The maximum non-negative integer $M$, denoted $M_{\\max}$, that satisfies this condition is the floor of $M_{upper}$. For $z \\in (-2, 0)$ and $K \\ge 2$, this upper bound is non-negative.\n$$\nM_{\\max} = \\left\\lfloor \\frac{-1 - |1+z|^{-(K-1)}}{z} - 1 \\right\\rfloor\n$$\nThis formula is implemented for each test case. If the initial condition for micro-integrator stability is violated ($z \\notin (-2, 0)$), the result is $-1$.\n\nThe algorithm for the program is:\n1.  For each test set $(\\alpha, \\epsilon, \\Delta t, K)$, compute $z = -\\frac{\\alpha}{\\epsilon}\\Delta t$.\n2.  If $z \\le -2$ or $z \\ge 0$, the micro-integrator is unstable. The result for this case is $-1$.\n3.  Otherwise, calculate $M_{upper} = \\frac{-1 - |1+z|^{-(K-1)}}{z} - 1$.\n4.  The result, $M_{\\max}$, is the integer part of $M_{upper}$, which corresponds to the floor operation for a non-negative value.\n5.  Collect the results for all test cases into a list.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the maximum stable macro projection factor M_max for a projective\n    integration scheme applied to a fast-slow linear system.\n    \"\"\"\n    \n    # Test suite of parameter sets: (alpha, epsilon, delta_t, K)\n    test_cases = [\n        (10.0, 0.01, 0.0005, 3),  # Test 1\n        (10.0, 0.01, 0.0019, 2),  # Test 2\n        (5.0, 0.02, 0.0008, 3),   # Test 3\n        (1.0, 1.0, 0.01, 5),      # Test 4\n        (10.0, 0.01, 0.003, 3),   # Test 5\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        alpha, epsilon, delta_t, K = case\n        \n        # Calculate the fast eigenvalue and the stability parameter z\n        lambda_f = -alpha / epsilon\n        z = lambda_f * delta_t\n        \n        # Check for micro-integrator stability. Explicit Euler for u' = lambda_f * u\n        # is stable if and only if z = lambda_f * delta_t is in (-2, 0).\n        if z <= -2.0 or z >= 0:\n            results.append(-1)\n            continue\n            \n        # The derivation for the derivative estimate s requires at least two microstates,\n        # implying K >= 2. All test cases satisfy this.\n\n        # Derive the upper bound for M based on the stability condition |G(z, K, M)| <= 1.\n        # The amplification factor is G(z, K, M) = (1+z)^(K-1) * (1 + (M+1)z).\n        # The stability condition leads to M <= (-1 - |1+z|^-(K-1)) / z - 1.\n        \n        # Use numpy for robust floating-point operations.\n        abs_1_plus_z = np.abs(1.0 + z)\n        \n        # The term |1+z|^-(K-1)\n        term_power = np.power(abs_1_plus_z, -(K - 1))\n        \n        # The upper bound for M\n        M_upper = (-1.0 - term_power) / z - 1.0\n        \n        # M_max is the largest non-negative integer less than or equal to M_upper.\n        # For z in (-2, 0) and K >= 2, M_upper is non-negative, so taking the\n        # integer part is equivalent to the floor function.\n        M_max = int(M_upper)\n        \n        results.append(M_max)\n        \n    # Print the results in the specified format: [m1,m2,m3,m4,m5]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}