{
    "hands_on_practices": [
        {
            "introduction": "The \"lifting\" step in the Equation-Free approach, which creates a microscopic state consistent with a given coarse state, is inherently non-unique. This ambiguity can introduce unphysical fast transients that must be damped out before macroscopic measurements are taken. This exercise provides a concrete, analytical look at this process, allowing you to derive the exact mathematical form of the bias introduced in a coarse derivative estimate when this \"healing\" time is insufficient . By working through a simple linear model, you will gain a clear understanding of how fast modes contaminate coarse observables and why the healing step is crucial for the method's accuracy.",
            "id": "3817569",
            "problem": "Consider a microscopic system with two components, a slow component and a fast component, denoted by $s(t)$ and $f(t)$, respectively, evolving according to a linear ordinary differential equation (ODE) model\n$$\n\\frac{d s}{d t} = \\lambda_{s} s, \\qquad \\frac{d f}{d t} = \\lambda_{f} f,\n$$\nwhere $\\lambda_{s}$ and $\\lambda_{f}$ are real constants satisfying $|\\lambda_{f}| \\gg |\\lambda_{s}|$ and $\\lambda_{f}  0$. The coarse observable used in the Equation-Free Approach (EFA) is defined as\n$$\ny(t) = s(t) + \\beta f(t),\n$$\nwhere $\\beta$ is a fixed real mixing parameter. Let $Y_{0}$ be the target coarse value. The lifting operator constructs a consistent microscopic initial condition by choosing\n$$\ns(0) = Y_{0} - \\beta a, \\qquad f(0) = a,\n$$\nwhere $a$ is a real parameter quantifying the magnitude of an initial fast-component mismatch introduced by lifting. This choice ensures $y(0) = Y_{0}$.\n\nIn the EFA, a healing time $\\tau_{h}  0$ is allowed to pass to damp fast transients before estimating the coarse time derivative using a short microscopic burst of duration $\\delta  0$, $\\delta \\ll 1$. The coarse finite-difference estimate is computed as\n$$\nD_{\\mathrm{est}}(\\tau_{h}, \\delta) = \\frac{y(\\tau_{h} + \\delta) - y(\\tau_{h})}{\\delta}.\n$$\nLet $D_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta)$ denote the same finite-difference estimate that would be obtained if the lifting introduced no fast mismatch, i.e., $a = 0$.\n\nStarting from the definitions above and the ODE dynamics, derive an exact closed-form analytic expression for the bias due to insufficient healing time,\n$$\nB(\\tau_{h}, \\delta) = D_{\\mathrm{est}}(\\tau_{h}, \\delta) - D_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta),\n$$\nas a function of $\\tau_{h}$, $\\delta$, $\\lambda_{s}$, $\\lambda_{f}$, $\\beta$, and $a$. Express your final answer as a single simplified analytic expression. No numerical evaluation is required. Do not include units in your final answer.",
            "solution": "The problem asks for an exact closed-form expression for the bias, $B(\\tau_{h}, \\delta)$, resulting from an initial fast-component mismatch in an Equation-Free Approach (EFA) simulation. The bias is defined as the difference between the estimated coarse time derivative with a fast mismatch ($a \\neq 0$) and the estimate without one ($a=0$).\n\nThe first step is to find the explicit time evolution of the microscopic components, $s(t)$ and $f(t)$. The governing ordinary differential equations (ODEs) are given as:\n$$\n\\frac{d s}{d t} = \\lambda_{s} s, \\qquad \\frac{d f}{d t} = \\lambda_{f} f\n$$\nThese are first-order linear homogeneous ODEs whose solutions are exponential functions of time $t$:\n$$\ns(t) = s(0) \\exp(\\lambda_{s} t)\n$$\n$$\nf(t) = f(0) \\exp(\\lambda_{f} t)\n$$\nwhere $s(0)$ and $f(0)$ are the initial conditions at $t=0$.\n\nThe problem specifies the initial conditions constructed by the lifting operator for a target coarse value $Y_{0}$ and a fast-component mismatch of magnitude $a$:\n$$\ns(0) = Y_{0} - \\beta a\n$$\n$$\nf(0) = a\n$$\nSubstituting these initial conditions into the solutions of the ODEs, we obtain the state of the system for any time $t \\ge 0$:\n$$\ns(t) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} t)\n$$\n$$\nf(t) = a \\exp(\\lambda_{f} t)\n$$\nThe coarse observable $y(t)$ is defined as a linear combination of the microscopic components:\n$$\ny(t) = s(t) + \\beta f(t)\n$$\nSubstituting the expressions for $s(t)$ and $f(t)$ gives the time evolution of the coarse observable:\n$$\ny(t) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} t) + \\beta \\left( a \\exp(\\lambda_{f} t) \\right) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} t) + \\beta a \\exp(\\lambda_{f} t)\n$$\nThe problem defines the coarse finite-difference estimate of the time derivative as:\n$$\nD_{\\mathrm{est}}(\\tau_{h}, \\delta) = \\frac{y(\\tau_{h} + \\delta) - y(\\tau_{h})}{\\delta}\n$$\nwhere $\\tau_{h}$ is the healing time and $\\delta$ is the duration of the microscopic simulation burst. To compute this, we evaluate $y(t)$ at $t=\\tau_h$ and $t=\\tau_h+\\delta$:\n$$\ny(\\tau_{h}) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} \\tau_{h}) + \\beta a \\exp(\\lambda_{f} \\tau_{h})\n$$\n$$\ny(\\tau_{h} + \\delta) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} (\\tau_{h} + \\delta)) + \\beta a \\exp(\\lambda_{f} (\\tau_{h} + \\delta))\n$$\nThe difference $y(\\tau_{h} + \\delta) - y(\\tau_{h})$ is:\n$$\ny(\\tau_{h} + \\delta) - y(\\tau_{h}) = \\left[ (Y_{0} - \\beta a) \\exp(\\lambda_{s} (\\tau_{h} + \\delta)) + \\beta a \\exp(\\lambda_{f} (\\tau_{h} + \\delta)) \\right] - \\left[ (Y_{0} - \\beta a) \\exp(\\lambda_{s} \\tau_{h}) + \\beta a \\exp(\\lambda_{f} \\tau_{h}) \\right]\n$$\nGrouping terms with common coefficients:\n$$\ny(\\tau_{h} + \\delta) - y(\\tau_{h}) = (Y_{0} - \\beta a) \\left[ \\exp(\\lambda_{s} (\\tau_{h} + \\delta)) - \\exp(\\lambda_{s} \\tau_{h}) \\right] + \\beta a \\left[ \\exp(\\lambda_{f} (\\tau_{h} + \\delta)) - \\exp(\\lambda_{f} \\tau_{h}) \\right]\n$$\nFactoring out the terms $\\exp(\\lambda_s \\tau_h)$ and $\\exp(\\lambda_f \\tau_h)$:\n$$\ny(\\tau_{h} + \\delta) - y(\\tau_{h}) = (Y_{0} - \\beta a) \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] + \\beta a \\exp(\\lambda_{f} \\tau_{h}) \\left[ \\exp(\\lambda_{f} \\delta) - 1 \\right]\n$$\nDividing by $\\delta$ gives the full expression for $D_{\\mathrm{est}}(\\tau_{h}, \\delta)$:\n$$\nD_{\\mathrm{est}}(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( (Y_{0} - \\beta a) \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] + \\beta a \\exp(\\lambda_{f} \\tau_{h}) \\left[ \\exp(\\lambda_{f} \\delta) - 1 \\right] \\right)\n$$\nNext, we determine $D_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta)$, which is the estimate for the case of no fast mismatch, i.e., $a=0$. We can obtain this by setting $a=0$ in the expression for $D_{\\mathrm{est}}(\\tau_{h}, \\delta)$:\n$$\nD_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( (Y_{0} - \\beta \\cdot 0) \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] + \\beta \\cdot 0 \\cdot \\exp(\\lambda_{f} \\tau_{h}) \\left[ \\exp(\\lambda_{f} \\delta) - 1 \\right] \\right)\n$$\n$$\nD_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( Y_{0} \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] \\right)\n$$\nFinally, we compute the bias $B(\\tau_{h}, \\delta)$ by subtracting $D_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta)$ from $D_{\\mathrm{est}}(\\tau_{h}, \\delta)$:\n$$\nB(\\tau_{h}, \\delta) = D_{\\mathrm{est}}(\\tau_{h}, \\delta) - D_{\\mathrm{est}}^{0}(\\tau_{h}, \\delta)\n$$\n$$\nB(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( (Y_{0} - \\beta a) \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] + \\beta a \\exp(\\lambda_{f} \\tau_{h}) \\left[ \\exp(\\lambda_{f} \\delta) - 1 \\right] \\right) - \\frac{1}{\\delta} \\left( Y_{0} \\exp(\\lambda_{s} \\tau_{h}) \\left[ \\exp(\\lambda_{s} \\delta) - 1 \\right] \\right)\n$$\nWe can combine the terms:\n$$\nB(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( Y_{0} \\exp(\\lambda_{s} \\tau_{h})[\\exp(\\lambda_{s} \\delta)-1] - \\beta a \\exp(\\lambda_{s} \\tau_{h})[\\exp(\\lambda_{s} \\delta)-1] + \\beta a \\exp(\\lambda_{f} \\tau_{h})[\\exp(\\lambda_{f} \\delta)-1] - Y_{0} \\exp(\\lambda_{s} \\tau_{h})[\\exp(\\lambda_{s} \\delta)-1] \\right)\n$$\nThe terms involving $Y_0$ cancel out, leaving:\n$$\nB(\\tau_{h}, \\delta) = \\frac{1}{\\delta} \\left( - \\beta a \\exp(\\lambda_{s} \\tau_{h})[\\exp(\\lambda_{s} \\delta)-1] + \\beta a \\exp(\\lambda_{f} \\tau_{h})[\\exp(\\lambda_{f} \\delta)-1] \\right)\n$$\nFactoring out the common term $\\frac{\\beta a}{\\delta}$:\n$$\nB(\\tau_{h}, \\delta) = \\frac{\\beta a}{\\delta} \\left( \\exp(\\lambda_{f} \\tau_{h})[\\exp(\\lambda_{f} \\delta)-1] - \\exp(\\lambda_{s} \\tau_{h})[\\exp(\\lambda_{s} \\delta)-1] \\right)\n$$\nThis is the final, exact closed-form analytic expression for the bias as a function of the specified parameters.",
            "answer": "$$\n\\boxed{\\frac{\\beta a}{\\delta} \\left[ \\exp(\\lambda_f \\tau_h) \\left( \\exp(\\lambda_f \\delta) - 1 \\right) - \\exp(\\lambda_s \\tau_h) \\left( \\exp(\\lambda_s \\delta) - 1 \\right) \\right]}\n$$"
        },
        {
            "introduction": "Having established the necessity of a healing period to attenuate fast transients, a critical practical question arises: how long should this period be? A longer healing time reduces error but increases computational expense, creating a fundamental trade-off. This practice challenges you to formalize this trade-off by constructing and minimizing a cost function that penalizes both residual error and computational cost . Solving this optimization problem will equip you with a principled method for selecting the optimal healing burst duration in an EF simulation.",
            "id": "3817578",
            "problem": "In the equation-free (EF) framework for multiscale modeling, a microscopic simulator is used to approximate coarse-grained dynamics without deriving explicit coarse equations. A standard EF coarse time-stepper lifts a coarse state to a consistent microscopic state, evolves it for a short healing burst to attenuate fast transients, and then restricts back to the coarse observables. Near a stable slow manifold, suppose the microscopic dynamics linearize into a fast mode with relaxation rate $\\lambda_f$ and a slow mode with relaxation rate $\\lambda_s$, with $\\lambda_f \\gg \\lambda_s  0$. Assume that the initial lifting introduces a unit-amplitude contamination along the fast mode, and that this contamination induces a mean-square error in the coarse observable proportional to $\\exp(-2 \\lambda_f \\tau)$ after a healing burst of duration $\\tau$.\n\nTo choose $\\tau$, you consider a trade-off between (i) reducing the fast-mode contamination and (ii) incurring computational cost. Let the computational cost per unit microscopic time be $\\kappa  0$ and let the opportunity cost of delaying the slow evolution during healing be measured per unit microscopic time as $\\beta \\lambda_s$ with $\\beta  0$ (so that the total per-unit-time cost is $\\kappa + \\beta \\lambda_s$). Let the weight for penalizing the residual fast contamination be $\\alpha  0$. You therefore adopt the following objective to be minimized with respect to $\\tau \\ge 0$:\n$$\nJ(\\tau) \\;=\\; (\\kappa + \\beta \\lambda_s)\\,\\tau \\;+\\; \\alpha \\,\\exp(-2 \\lambda_f \\tau).\n$$\nAssume the parameters satisfy $2 \\alpha \\lambda_f  \\kappa + \\beta \\lambda_s$ so that the optimal $\\tau$ is strictly positive and interior.\n\nDerive, from first principles based on the linearized decay of modes and the stated cost structure, the closed-form expression for the optimal healing burst length $\\tau^{\\star}$ that minimizes $J(\\tau)$. Express your answer in terms of $\\alpha$, $\\beta$, $\\kappa$, $\\lambda_f$, and $\\lambda_s$. No numerical evaluation is required and no units are requested.",
            "solution": "The objective is to find the value of $\\tau$, denoted $\\tau^{\\star}$, that minimizes the cost function $J(\\tau)$ for $\\tau \\ge 0$. The cost function is given by:\n$$\nJ(\\tau) = (\\kappa + \\beta \\lambda_s)\\tau + \\alpha \\exp(-2 \\lambda_f \\tau)\n$$\nTo find the minimum of a differentiable function, we first compute its derivative with respect to the variable of interest, $\\tau$, and set the result to zero to find the critical points.\n\nThe first derivative of $J(\\tau)$ with respect to $\\tau$ is:\n$$\n\\frac{dJ}{d\\tau} = \\frac{d}{d\\tau} \\left[ (\\kappa + \\beta \\lambda_s)\\tau + \\alpha \\exp(-2 \\lambda_f \\tau) \\right]\n$$\nApplying the rules of differentiation (the sum rule and the chain rule for the exponential term):\n$$\n\\frac{dJ}{d\\tau} = (\\kappa + \\beta \\lambda_s) + \\alpha \\cdot \\exp(-2 \\lambda_f \\tau) \\cdot (-2 \\lambda_f)\n$$\n$$\n\\frac{dJ}{d\\tau} = \\kappa + \\beta \\lambda_s - 2 \\alpha \\lambda_f \\exp(-2 \\lambda_f \\tau)\n$$\nWe set this derivative to zero to find the optimal time $\\tau^{\\star}$:\n$$\n\\left. \\frac{dJ}{d\\tau} \\right|_{\\tau=\\tau^{\\star}} = 0\n$$\n$$\n\\kappa + \\beta \\lambda_s - 2 \\alpha \\lambda_f \\exp(-2 \\lambda_f \\tau^{\\star}) = 0\n$$\nNow, we solve this equation for $\\tau^{\\star}$. Rearranging the terms, we get:\n$$\n2 \\alpha \\lambda_f \\exp(-2 \\lambda_f \\tau^{\\star}) = \\kappa + \\beta \\lambda_s\n$$\nIsolating the exponential term:\n$$\n\\exp(-2 \\lambda_f \\tau^{\\star}) = \\frac{\\kappa + \\beta \\lambda_s}{2 \\alpha \\lambda_f}\n$$\nTo solve for $\\tau^{\\star}$, we take the natural logarithm ($\\ln$) of both sides:\n$$\n\\ln\\left( \\exp(-2 \\lambda_f \\tau^{\\star}) \\right) = \\ln\\left( \\frac{\\kappa + \\beta \\lambda_s}{2 \\alpha \\lambda_f} \\right)\n$$\n$$\n-2 \\lambda_f \\tau^{\\star} = \\ln\\left( \\frac{\\kappa + \\beta \\lambda_s}{2 \\alpha \\lambda_f} \\right)\n$$\nFinally, we solve for $\\tau^{\\star}$:\n$$\n\\tau^{\\star} = -\\frac{1}{2 \\lambda_f} \\ln\\left( \\frac{\\kappa + \\beta \\lambda_s}{2 \\alpha \\lambda_f} \\right)\n$$\nUsing the logarithmic identity $-\\ln(x) = \\ln(1/x)$, we can write the expression in a more convenient form:\n$$\n\\tau^{\\star} = \\frac{1}{2 \\lambda_f} \\ln\\left( \\left(\\frac{\\kappa + \\beta \\lambda_s}{2 \\alpha \\lambda_f}\\right)^{-1} \\right) = \\frac{1}{2 \\lambda_f} \\ln\\left( \\frac{2 \\alpha \\lambda_f}{\\kappa + \\beta \\lambda_s} \\right)\n$$\nTo confirm that this critical point corresponds to a minimum, we examine the second derivative of $J(\\tau)$:\n$$\n\\frac{d^2J}{d\\tau^2} = \\frac{d}{d\\tau} \\left[ \\kappa + \\beta \\lambda_s - 2 \\alpha \\lambda_f \\exp(-2 \\lambda_f \\tau) \\right]\n$$\n$$\n\\frac{d^2J}{d\\tau^2} = -2 \\alpha \\lambda_f \\cdot \\exp(-2 \\lambda_f \\tau) \\cdot (-2 \\lambda_f)\n$$\n$$\n\\frac{d^2J}{d\\tau^2} = 4 \\alpha \\lambda_f^2 \\exp(-2 \\lambda_f \\tau)\n$$\nGiven the problem constraints $\\alpha  0$ and $\\lambda_f  0$, it follows that $4 \\alpha \\lambda_f^2  0$. The exponential term $\\exp(-2 \\lambda_f \\tau)$ is also strictly positive for all real $\\tau$. Thus, $\\frac{d^2J}{d\\tau^2}  0$ for all $\\tau$. This indicates that the function $J(\\tau)$ is strictly convex, and the critical point we found is indeed a unique global minimum.\n\nThe problem includes the assumption $2 \\alpha \\lambda_f  \\kappa + \\beta \\lambda_s$. This implies that the argument of the logarithm in our final expression is greater than $1$:\n$$\n\\frac{2 \\alpha \\lambda_f}{\\kappa + \\beta \\lambda_s}  1\n$$\nTherefore, $\\ln\\left( \\frac{2 \\alpha \\lambda_f}{\\kappa + \\beta \\lambda_s} \\right)  \\ln(1) = 0$. Since $\\lambda_f  0$, our solution for $\\tau^{\\star}$ is strictly positive ($\\tau^{\\star}  0$), consistent with the problem's statement of an interior optimum and the physical requirement $\\tau \\ge 0$.\n\nThe derived closed-form expression for the optimal healing burst length is therefore:\n$$\n\\tau^{\\star} = \\frac{1}{2 \\lambda_f} \\ln\\left( \\frac{2 \\alpha \\lambda_f}{\\kappa + \\beta \\lambda_s} \\right)\n$$",
            "answer": "$$\n\\boxed{\\frac{1}{2 \\lambda_f} \\ln\\left(\\frac{2 \\alpha \\lambda_f}{\\kappa + \\beta \\lambda_s}\\right)}\n$$"
        },
        {
            "introduction": "Beyond the systematic errors from fast dynamics, the Equation-Free approach must also contend with statistical uncertainty. Since coarse derivatives are estimated as averages over a finite ensemble of microscopic simulations, the result is a random variable with its own variance. This exercise guides you through the process of determining the required ensemble size to ensure your coarse derivative estimate achieves a desired level of precision . Applying fundamental statistical principles, you will see how to connect a target confidence interval with the number of simulations needed, a vital skill for designing robust and efficient multiscale computations.",
            "id": "3817524",
            "problem": "Consider the Equation-Free Approach (EFA) for multiscale modeling, in which a coarse observable $u$ is advanced via a coarse time-stepper constructed from short bursts of a microscopic simulator. At a given coarse state $u_{0}$, suppose you estimate the coarse time derivative $\\dot{u}(u_{0})$ by the ensemble average of independent microscopic-burst finite-difference estimates. Specifically, for each replicate $i$, you perform lifting to a consistent microscopic state, evolve the microscopic model for a short time $\\delta t$, restrict to the coarse observable, and form a single-replicate derivative estimate $d^{(i)} = \\big(u^{(i)}(\\delta t) - u_{0}\\big)/\\delta t$. The coarse derivative estimator is the sample mean $\\hat{D}_{M} = \\frac{1}{M}\\sum_{i=1}^{M} d^{(i)}$ computed over $M$ independent and identically distributed (i.i.d.) replicates with finite variance.\n\nFrom a pilot run of $M_{0}$ i.i.d. replicates at the same $u_{0}$ and $\\delta t$, you have computed a sample variance $s_{0}^{2} = 6.25$ for the single-replicate derivative estimates $\\{d^{(i)}\\}$. Assume independence across replicates and that the variance of $d^{(i)}$ is constant at the operating point.\n\nYou wish to choose an ensemble size $M$ large enough that a two-sided Confidence Interval (CI) for the mean derivative $\\mathbb{E}[d^{(i)}]$ at confidence level $1-\\alpha = 0.95$ has half-width no greater than a prescribed tolerance $\\varepsilon = 0.5$. Determine the smallest integer ensemble size $M$ that achieves this target half-width using the pilot variance $s_{0}^{2}$ as a variance proxy. Express your final answer as a single number. No rounding beyond the integer requirement is necessary.",
            "solution": "The problem requires determining the minimum integer ensemble size $M$ to ensure that the half-width of a two-sided confidence interval for the mean coarse time derivative is no larger than a specified tolerance $\\varepsilon$.\n\nThe estimator for the true mean derivative $\\mu = \\mathbb{E}[d^{(i)}]$ is the sample mean over $M$ independent and identically distributed (i.i.d.) replicates, given by:\n$$\n\\hat{D}_{M} = \\frac{1}{M}\\sum_{i=1}^{M} d^{(i)}\n$$\nThe individual derivative estimates $d^{(i)}$ are random variables with mean $\\mu$ and a finite variance $\\sigma^2$. Since the replicates are i.i.d., the variance of the sample mean $\\hat{D}_{M}$ is:\n$$\n\\text{Var}(\\hat{D}_{M}) = \\text{Var}\\left(\\frac{1}{M}\\sum_{i=1}^{M} d^{(i)}\\right) = \\frac{1}{M^2}\\sum_{i=1}^{M}\\text{Var}(d^{(i)}) = \\frac{1}{M^2}(M\\sigma^2) = \\frac{\\sigma^2}{M}\n$$\nThe standard deviation of the estimator, known as the standard error of the mean, is $\\text{SE} = \\frac{\\sigma}{\\sqrt{M}}$.\n\nBy the Central Limit Theorem, for a sufficiently large sample size $M$, the distribution of the sample mean $\\hat{D}_{M}$ can be approximated by a normal distribution with mean $\\mu$ and variance $\\sigma^2/M$. The standardized variable $Z = \\frac{\\hat{D}_{M} - \\mu}{\\sigma/\\sqrt{M}}$ follows a standard normal distribution, $\\mathcal{N}(0,1)$.\n\nA two-sided confidence interval (CI) for the mean $\\mu$ at a confidence level of $1-\\alpha$ is constructed based on the pivotal quantity $Z$. The interval is defined by the probability statement:\n$$\nP\\left(-z_{\\alpha/2} \\le \\frac{\\hat{D}_{M} - \\mu}{\\sigma/\\sqrt{M}} \\le z_{\\alpha/2}\\right) \\approx 1-\\alpha\n$$\nwhere $z_{\\alpha/2}$ is the critical value of the standard normal distribution such that $P(Z  z_{\\alpha/2}) = \\alpha/2$. Rearranging the inequality to isolate $\\mu$ yields the CI:\n$$\n\\left[ \\hat{D}_{M} - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{M}}, \\quad \\hat{D}_{M} + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{M}} \\right]\n$$\nThe half-width of this confidence interval is the distance from the center of the interval, $\\hat{D}_{M}$, to either endpoint. This is given by:\n$$\nW = z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{M}}\n$$\nThe problem requires this half-width to be no greater than a prescribed tolerance $\\varepsilon$. Thus, we must satisfy the inequality:\n$$\nz_{\\alpha/2} \\frac{\\sigma}{\\sqrt{M}} \\le \\varepsilon\n$$\nWe need to solve for the smallest integer $M$ that satisfies this condition. Rearranging the inequality for $M$:\n$$\n\\sqrt{M} \\ge \\frac{z_{\\alpha/2} \\sigma}{\\varepsilon}\n$$\n$$\nM \\ge \\left(\\frac{z_{\\alpha/2} \\sigma}{\\varepsilon}\\right)^2\n$$\nThe problem specifies the following values:\n1.  The confidence level is $1-\\alpha = 0.95$. This implies $\\alpha = 0.05$, and $\\alpha/2 = 0.025$. The corresponding critical value from the standard normal distribution is $z_{0.025}$, which is the value for which the cumulative distribution function is $1 - 0.025 = 0.975$. This standard value is $z_{0.025} \\approx 1.96$.\n2.  The tolerance for the half-width is $\\varepsilon = 0.5$.\n3.  The variance of a single-replicate estimate, $\\sigma^2$, is unknown. However, we are instructed to use the sample variance from a pilot study, $s_{0}^{2} = 6.25$, as a proxy for the true variance $\\sigma^2$. Thus, we set $\\sigma^2 = 6.25$. The corresponding standard deviation is $\\sigma = \\sqrt{6.25} = 2.5$.\n\nSubstituting these values into the inequality for $M$:\n$$\nM \\ge \\left(\\frac{1.96 \\times 2.5}{0.5}\\right)^2\n$$\nWe compute the value of the expression on the right-hand side:\n$$\nM \\ge \\left(\\frac{4.9}{0.5}\\right)^2\n$$\n$$\nM \\ge (9.8)^2\n$$\n$$\nM \\ge 96.04\n$$\nSince the ensemble size $M$ must be an integer, we must select the smallest integer greater than or equal to $96.04$. This is achieved by taking the ceiling of the calculated value:\n$$\nM = \\lceil 96.04 \\rceil = 97\n$$\nTherefore, the smallest integer ensemble size required to achieve the desired precision is $97$.",
            "answer": "$$\n\\boxed{97}\n$$"
        }
    ]
}