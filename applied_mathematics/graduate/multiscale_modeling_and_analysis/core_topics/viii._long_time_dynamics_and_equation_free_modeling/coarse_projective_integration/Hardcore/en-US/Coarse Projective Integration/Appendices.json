{
    "hands_on_practices": [
        {
            "introduction": "To build a strong foundation, it is often helpful to connect a new method to established concepts. This first practice explores the behavior of Coarse Projective Integration (CPI) in an idealized limit. By assuming the microscopic simulation burst is infinitesimally short and provides a perfectly unbiased estimate of the coarse time derivative, you will derive the resulting form of the CPI update rule and see how it relates to a classic numerical integrator .",
            "id": "3744108",
            "problem": "Consider a deterministic coarse variable $U(t) \\in \\mathbb{R}^{m}$ evolving according to the ordinary differential equation (ODE)\n$$\n\\frac{dU}{dt} = F(U),\n$$\nwhere $F:\\mathbb{R}^{m} \\to \\mathbb{R}^{m}$ is continuously differentiable in a neighborhood of a given coarse state $U^{n}$. In a single macro-step of Coarse Projective Integration (CPI), one proceeds as follows: at coarse time $t^{n}$ with coarse state $U^{n}$, one constructs a consistent fine-scale microstate and evolves the microscopic simulator for a healing time $t_{h} > 0$, followed by a short burst of length $\\tau > 0$. Over the burst, a coarse time derivative estimator $\\widehat{F}_{\\tau}(U^{n})$ is formed from the coarse evolution of the microstate. The CPI macro-step then performs a projective update\n$$\nU^{n+1} = U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n}),\n$$\nwhere the macro-step size $\\Delta T > 0$ is fixed and independent of $\\tau$.\n\nAssume the following:\n- The coarse ODE $\\frac{dU}{dt} = F(U)$ is the correct closed evolution for the coarse variable.\n- The healing time $t_{h}$ is sufficiently long to render the subsequent burst derivative estimator asymptotically unbiased with respect to the coarse dynamics at $U^{n}$ in the limit $\\tau \\to 0$, in the sense that\n$$\n\\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n}) = F(U^{n}),\n$$\nand $F$ is locally Lipschitz near $U^{n}$.\n- The macro-step size $\\Delta T$ is fixed and positive.\n\nDefine the CPI macro-slope\n$$\nL(\\tau) := \\frac{U^{n+1} - U^{n}}{\\Delta T}.\n$$\nUsing only the ODE definition $\\frac{dU}{dt} = F(U)$, standard smoothness assumptions on $F$, and the unbiasedness condition stated above, derive the limit\n$$\nL := \\lim_{\\tau \\to 0} L(\\tau)\n$$\nand express it in closed form as a symbolic function of $U^{n}$ and $F$.\n\nYour final answer must be a single closed-form analytic expression for $L$. No numerical approximation is required. If you use any angles, express them in radians. No units are required. Do not present your final answer as an equation; present only the expression for $L$.",
            "solution": "The objective is to determine the limit $L := \\lim_{\\tau \\to 0} L(\\tau)$, where $L(\\tau)$ is the Coarse Projective Integration (CPI) macro-slope. The problem provides the definition of the macro-slope as:\n$$\nL(\\tau) := \\frac{U^{n+1} - U^{n}}{\\Delta T}\n$$\nHere, $U^{n}$ represents the coarse state at a given time $t^{n}$, $U^{n+1}$ is the coarse state after a single macro-step of duration $\\Delta T$, and $\\tau$ is the duration of the microscopic simulation burst used to estimate the time derivative.\n\nThe CPI update rule for advancing the coarse state from $U^{n}$ to $U^{n+1}$ is given by the projective step:\n$$\nU^{n+1} = U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n})\n$$\nIn this expression, $\\widehat{F}_{\\tau}(U^{n})$ is the estimator for the coarse time derivative, $\\frac{dU}{dt}$, computed at the state $U^{n}$ using a simulation of duration $\\tau$.\n\nTo derive an expression for $L(\\tau)$, we substitute the CPI update rule into its definition. This yields:\n$$\nL(\\tau) = \\frac{\\left(U^{n} + \\Delta T\\, \\widehat{F}_{\\tau}(U^{n})\\right) - U^{n}}{\\Delta T}\n$$\nThe terms $U^{n}$ and $-U^{n}$ in the numerator cancel one another, leading to a simplified expression:\n$$\nL(\\tau) = \\frac{\\Delta T\\, \\widehat{F}_{\\tau}(U^{n})}{\\Delta T}\n$$\nThe macro-step size $\\Delta T$ is stated to be a fixed, positive constant, so it can be canceled from the numerator and the denominator, provided $\\Delta T \\neq 0$. This gives a direct relationship between the macro-slope and the derivative estimator:\n$$\nL(\\tau) = \\widehat{F}_{\\tau}(U^{n})\n$$\nWith this simplified expression for $L(\\tau)$, we can now compute the required limit $L$. The limit is defined as:\n$$\nL = \\lim_{\\tau \\to 0} L(\\tau)\n$$\nSubstituting our result for $L(\\tau)$, we have:\n$$\nL = \\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n})\n$$\nThe problem statement includes a critical assumption regarding the asymptotic behavior of the estimator $\\widehat{F}_{\\tau}(U^{n})$. It is assumed that the healing time $t_{h}$ is sufficient to make the estimator asymptotically unbiased in the limit $\\tau \\to 0$. This is formally stated as:\n$$\n\\lim_{\\tau \\to 0} \\widehat{F}_{\\tau}(U^{n}) = F(U^{n})\n$$\nThis condition asserts that as the burst time becomes infinitesimally short, the estimator converges to the exact value of the coarse vector field $F$ at the state $U^{n}$. The function $F(U)$ is defined by the underlying correct coarse ODE, $\\frac{dU}{dt} = F(U)$.\n\nBy applying this given limit directly to our expression for $L$, we arrive at the final result:\n$$\nL = F(U^{n})\n$$\nThus, the limit of the CPI macro-slope as the burst time $\\tau$ approaches zero is simply the true coarse time derivative evaluated at the initial state of the macro-step, $U^{n}$. The other smoothness and Lipschitz continuity assumptions on $F$ ensure that $F(U^{n})$ is a well-defined quantity, which underpins the validity of this entire procedure.",
            "answer": "$$\n\\boxed{F(U^{n})}\n$$"
        },
        {
            "introduction": "A central challenge in equation-free modeling is managing the noise inherent in microscopic simulations. This practice delves into a core statistical technique used in CPI to improve accuracy: ensemble averaging. You will mathematically demonstrate how running multiple independent simulation bursts and averaging their results systematically reduces the variance of the estimated coarse derivative, a principle crucial for robust multiscale computation .",
            "id": "3744088",
            "problem": "Consider a multiscale modeling setting in which Coarse Projective Integration (CPI) is used to advance a macroscopic coarse variable. Let the macroscopic coarse state be denoted by $U^{\\ast}$ at time $t$, and suppose the macroscopic time derivative at $U^{\\ast}$ is $f(U^{\\ast})$. In CPI, one estimates $f(U^{\\ast})$ by running $N$ independent microscopic simulation bursts, each of duration $\\tau$, starting from microstates that are consistent with the coarse state $U^{\\ast}$ via a lifting operation. For burst $i$, define the coarse observable $X_{i}(t)$ and construct the slope estimator\n$$\n\\hat{f}_{i} \\equiv \\frac{X_{i}(t+\\tau) - X_{i}(t)}{\\tau}.\n$$\nAssume that, due to microscopic fluctuations and finite-duration sampling, each $ \\hat{f}_{i} $ is an unbiased estimator of $ f(U^{\\ast}) $ with finite variance and that the estimators are mutually independent across bursts:\n$$\n\\mathbb{E}[\\hat{f}_{i}] = f(U^{\\ast}), \\quad \\mathrm{Var}(\\hat{f}_{i}) = \\sigma^{2}, \\quad \\hat{f}_{1},\\ldots,\\hat{f}_{N} \\text{ independent}.\n$$\nTo reduce estimator variability, CPI forms the ensemble-averaged slope estimator\n$$\n\\hat{f}_{N} \\equiv \\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i},\n$$\nand then executes a projective forward Euler step of size $H$ to approximate the coarse state at time $t+H$ by\n$$\nU_{\\mathrm{proj}} \\equiv U^{\\ast} + H \\hat{f}_{N}.\n$$\nStarting only from the definitions of expectation and variance, the independence of the microscopic bursts, and the linearity of the projective step, derive the variance of the projection error $U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)$ as a function of $N$, $H$, and $\\sigma$. Your final answer must be a single closed-form analytic expression in terms of $N$, $H$, and $\\sigma$, with no numerical substitution. If you introduce any auxiliary symbols, clearly define them in your derivation. No rounding is required, and no physical units are to be reported in the final expression.",
            "solution": "The objective is to derive the variance of the projection error, $U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)$, based on the provided definitions and assumptions.\n\nLet the projection error be denoted by the random variable $\\mathcal{E}$. By definition,\n$$\n\\mathcal{E} \\equiv U_{\\mathrm{proj}} - \\left(U^{\\ast} + H f(U^{\\ast})\\right)\n$$\nSubstituting the expression for the projected state, $U_{\\mathrm{proj}} = U^{\\ast} + H \\hat{f}_{N}$, we get:\n$$\n\\mathcal{E} = \\left(U^{\\ast} + H \\hat{f}_{N}\\right) - \\left(U^{\\ast} + H f(U^{\\ast})\\right)\n$$\nSimplifying the expression by canceling the $U^{\\ast}$ terms and factoring out the projective step size $H$ yields:\n$$\n\\mathcal{E} = H \\left(\\hat{f}_{N} - f(U^{\\ast})\\right)\n$$\nThe problem requires us to find the variance of this error, $\\mathrm{Var}(\\mathcal{E})$. We will proceed by first calculating the expectation of the error $\\mathcal{E}$ and then using the definition of variance, $\\mathrm{Var}(X) = \\mathbb{E}\\left[(X - \\mathbb{E}[X])^2\\right]$.\n\nFirst, let's find the expectation of the ensemble-averaged slope estimator, $\\hat{f}_{N}$. Using the linearity of the expectation operator and the given fact that each individual estimator $\\hat{f}_{i}$ is unbiased, i.e., $\\mathbb{E}[\\hat{f}_{i}] = f(U^{\\ast})$:\n$$\n\\mathbb{E}[\\hat{f}_{N}] = \\mathbb{E}\\left[\\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i}\\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}[\\hat{f}_{i}] = \\frac{1}{N} \\sum_{i=1}^{N} f(U^{\\ast}) = \\frac{1}{N} \\left(N f(U^{\\ast})\\right) = f(U^{\\ast})\n$$\nThis shows that the ensemble-averaged estimator $\\hat{f}_{N}$ is also an unbiased estimator of the true macroscopic derivative $f(U^{\\ast})$.\n\nNow, we can compute the expectation of the projection error $\\mathcal{E}$:\n$$\n\\mathbb{E}[\\mathcal{E}] = \\mathbb{E}\\left[H \\left(\\hat{f}_{N} - f(U^{\\ast})\\right)\\right] = H \\left(\\mathbb{E}[\\hat{f}_{N}] - \\mathbb{E}[f(U^{\\ast})]\\right)\n$$\nSince $f(U^{\\ast})$ is a deterministic quantity (a constant with respect to the microscopic fluctuations), its expectation is itself. Thus,\n$$\n\\mathbb{E}[\\mathcal{E}] = H \\left(f(U^{\\ast}) - f(U^{\\ast})\\right) = 0\n$$\nThe projection error has a mean of zero.\n\nWith the mean of $\\mathcal{E}$ established as $0$, the variance of $\\mathcal{E}$ simplifies to the expectation of its square:\n$$\n\\mathrm{Var}(\\mathcal{E}) = \\mathbb{E}\\left[(\\mathcal{E} - \\mathbb{E}[\\mathcal{E}])^2\\right] = \\mathbb{E}\\left[(\\mathcal{E} - 0)^2\\right] = \\mathbb{E}[\\mathcal{E}^2]\n$$\nSubstituting the expression for $\\mathcal{E}$:\n$$\n\\mathrm{Var}(\\mathcal{E}) = \\mathbb{E}\\left[\\left(H (\\hat{f}_{N} - f(U^{\\ast}))\\right)^2\\right] = H^2 \\mathbb{E}\\left[(\\hat{f}_{N} - f(U^{\\ast}))^2\\right]\n$$\nThe term $\\mathbb{E}\\left[(\\hat{f}_{N} - f(U^{\\ast}))^2\\right]$ is, by definition, the variance of $\\hat{f}_{N}$, since $\\mathbb{E}[\\hat{f}_{N}] = f(U^{\\ast})$. Therefore,\n$$\n\\mathrm{Var}(\\mathcal{E}) = H^2 \\mathrm{Var}(\\hat{f}_{N})\n$$\nOur remaining task is to compute $\\mathrm{Var}(\\hat{f}_{N})$. We start from its definition:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\mathbb{E}\\left[(\\hat{f}_{N} - \\mathbb{E}[\\hat{f}_{N}])^2\\right] = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i} - f(U^{\\ast})\\right)^2\\right]\n$$\nWe can rewrite the term inside the expectation by distributing the constant $f(U^{\\ast})$ inside the summation:\n$$\n\\hat{f}_{N} - f(U^{\\ast}) = \\frac{1}{N} \\sum_{i=1}^{N} \\hat{f}_{i} - \\frac{1}{N} \\sum_{i=1}^{N} f(U^{\\ast}) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(\\hat{f}_{i} - f(U^{\\ast})\\right)\n$$\nLet's define an auxiliary random variable for the fluctuation of each burst estimator: $\\delta_i \\equiv \\hat{f}_{i} - f(U^{\\ast})$. The mean of this fluctuation is $\\mathbb{E}[\\delta_i] = \\mathbb{E}[\\hat{f}_i] - f(U^{\\ast}) = f(U^{\\ast}) - f(U^{\\ast}) = 0$. The variance of this fluctuation is $\\mathrm{Var}(\\delta_i) = \\mathrm{Var}(\\hat{f}_i - f(U^{\\ast})) = \\mathrm{Var}(\\hat{f}_i) = \\sigma^2$. Since $\\mathbb{E}[\\delta_i]=0$, we also have $\\mathbb{E}[\\delta_i^2] = \\mathrm{Var}(\\delta_i) + (\\mathbb{E}[\\delta_i])^2 = \\sigma^2 + 0^2 = \\sigma^2$.\n\nWith this substitution, the variance of $\\hat{f}_{N}$ becomes:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\delta_i\\right)^2\\right] = \\frac{1}{N^2} \\mathbb{E}\\left[\\left(\\sum_{i=1}^{N} \\delta_i\\right)^2\\right]\n$$\nExpanding the squared sum:\n$$\n\\left(\\sum_{i=1}^{N} \\delta_i\\right)^2 = \\sum_{i=1}^{N} \\delta_i^2 + \\sum_{i \\neq j} \\delta_i \\delta_j\n$$\nBy the linearity of expectation:\n$$\n\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N} \\delta_i\\right)^2\\right] = \\mathbb{E}\\left[\\sum_{i=1}^{N} \\delta_i^2\\right] + \\mathbb{E}\\left[\\sum_{i \\neq j} \\delta_i \\delta_j\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\delta_i^2] + \\sum_{i \\neq j} \\mathbb{E}[\\delta_i \\delta_j]\n$$\nWe have already established that $\\mathbb{E}[\\delta_i^2] = \\sigma^2$. For the cross-terms where $i \\neq j$, the estimators $\\hat{f}_i$ and $\\hat{f}_j$ are independent. Consequently, the fluctuations $\\delta_i = \\hat{f}_i - f(U^{\\ast})$ and $\\delta_j = \\hat{f}_j - f(U^{\\ast})$ are also independent. For independent random variables, the expectation of their product is the product of their expectations:\n$$\n\\mathbb{E}[\\delta_i \\delta_j] = \\mathbb{E}[\\delta_i]\\mathbb{E}[\\delta_j] = 0 \\cdot 0 = 0\n$$\nThus, all cross-terms vanish. The expectation of the squared sum simplifies to:\n$$\n\\mathbb{E}\\left[\\left(\\sum_{i=1}^{N} \\delta_i\\right)^2\\right] = \\sum_{i=1}^{N} \\mathbb{E}[\\delta_i^2] = \\sum_{i=1}^{N} \\sigma^2 = N \\sigma^2\n$$\nSubstituting this result back into the expression for $\\mathrm{Var}(\\hat{f}_{N})$:\n$$\n\\mathrm{Var}(\\hat{f}_{N}) = \\frac{1}{N^2} \\left(N \\sigma^2\\right) = \\frac{\\sigma^2}{N}\n$$\nFinally, we substitute this into our expression for the variance of the projection error, $\\mathrm{Var}(\\mathcal{E})$:\n$$\n\\mathrm{Var}(\\mathcal{E}) = H^2 \\mathrm{Var}(\\hat{f}_{N}) = H^2 \\left(\\frac{\\sigma^2}{N}\\right) = \\frac{H^2 \\sigma^2}{N}\n$$\nThis is the final expression for the variance of the projection error as a function of the number of bursts $N$, the projective step size $H$, and the variance of a single burst estimator $\\sigma$.",
            "answer": "$$\n\\boxed{\\frac{H^{2} \\sigma^{2}}{N}}\n$$"
        },
        {
            "introduction": "When applying a time-stepping scheme to a spatially extended system, such as a discretized partial differential equation (PDE), numerical stability is a primary concern. This exercise challenges you to analyze the stability of a CPI scheme used to evolve the diffusion equation. By applying von Neumann stability analysis, you will derive a stability constraint on the macroscopic time step, $\\Delta T$, that is analogous to the famous Courant–Friedrichs–Lewy (CFL) condition .",
            "id": "3744075",
            "problem": "Consider a coarse description of a spatially discretized parabolic partial differential equation (PDE) representing diffusion on a periodic domain of length $L$, with coarse field $u(x,t)$ satisfying $u_{t}=\\nu\\,u_{xx}$, where $\\nu0$ is the diffusivity. Discretize space uniformly into $N$ grid points with spacing $\\Delta x=L/N$, and approximate the second spatial derivative using the standard centered difference operator. Denote by $u_{i}(t)$ the coarse field at grid point $x_{i}=i\\,\\Delta x$, and let the discrete Laplacian operator be defined by\n$$\n\\left(D_{xx}u\\right)_{i}=\\frac{u_{i+1}-2u_{i}+u_{i-1}}{\\Delta x^{2}},\n$$\nwith periodic indexing. The coarse projective integration (CPI) algorithm performs a short inner microscopic burst to estimate the coarse time derivative and then advances the coarse variables via a macro-step projective update. In a first-order projective forward Euler coarse step, the update has the form\n$$\nu^{n+1}=u^{n}+\\Delta T\\,\\widehat{f}(u^{n}),\n$$\nwhere $\\widehat{f}(u^{n})$ is the estimated coarse time derivative obtained from the inner burst and $\\Delta T0$ is the macro-step size. Assume that, after sufficient inner relaxation, the estimated coarse derivative is unbiased on the slow manifold, namely $\\widehat{f}(u)\\approx \\nu\\,D_{xx}u$. \n\nUsing only fundamental and well-tested facts, including discrete Fourier (von Neumann) analysis of linear constant-coefficient schemes and the absolute-stability criterion for the forward Euler method applied to the linear test equation $y'=\\lambda\\,y$ with $\\lambda\\in\\mathbb{C}$, derive a stability restriction for the CPI macro-step size $\\Delta T$ that is analogous to Courant–Friedrichs–Lewy (CFL) conditions. Specifically, determine the largest permissible $\\Delta T$ as a closed-form analytic expression in terms of $\\Delta x$ and $\\nu$ that ensures linear stability of all discrete Fourier modes of the spatially discretized coarse PDE under the projective forward Euler step described above.\n\nYour final answer must be a single closed-form symbolic expression. Do not include units and do not round; no numerical evaluation is required.",
            "solution": "The problem asks for the stability condition on the macro-step size $\\Delta T$ for a coarse projective integration (CPI) scheme applied to a spatially discretized diffusion equation. The coarse dynamics are given by the equation $u_t = \\nu u_{xx}$, where $\\nu  0$. The spatial domain is periodic.\n\nThe CPI scheme uses a first-order projective forward Euler step, given by:\n$$u^{n+1} = u^{n} + \\Delta T \\widehat{f}(u^{n})$$\nHere, $u^{n}$ represents the vector of coarse field values $u_i^n$ at time step $n$, and $\\widehat{f}(u^{n})$ is the estimated time derivative. A crucial piece of information is the assumption that the estimated derivative is unbiased on the slow manifold, yielding the approximation $\\widehat{f}(u) \\approx \\nu D_{xx}u$. The operator $D_{xx}$ is the standard centered difference approximation to the second spatial derivative on a grid with spacing $\\Delta x$:\n$$ (D_{xx}u)_i = \\frac{u_{i+1} - 2u_{i} + u_{i-1}}{\\Delta x^{2}} $$\nSubstituting the approximation for $\\widehat{f}(u^n)$ into the CPI update rule, the scheme for the evolution of the coarse variable at grid point $i$ becomes:\n$$ u_i^{n+1} = u_i^n + \\Delta T \\left(\\nu D_{xx} u^n\\right)_i $$\n$$ u_i^{n+1} = u_i^n + \\Delta T \\nu \\frac{u_{i+1}^n - 2u_i^n + u_{i-1}^n}{\\Delta x^2} $$\nThis is a system of linear ordinary differential equations in time, which is being solved by the forward Euler method with a time step of $\\Delta T$. The stability of this method is determined by the eigenvalues of the operator $\\nu D_{xx}$.\n\nWe perform a discrete Fourier (von Neumann) analysis to find these eigenvalues. We consider a single Fourier mode as an eigenfunction of the spatial discretization operator. On a periodic domain, a general mode can be written as $u_i(t) = \\hat{u}_k(t) e^{I k x_i}$, where $I = \\sqrt{-1}$ is the imaginary unit, $k$ is the wavenumber, and $x_i = i \\Delta x$. Applying the operator $\\nu D_{xx}$ to this mode:\n$$ (\\nu D_{xx} e^{I k x})_i = \\nu \\frac{e^{I k x_{i+1}} - 2e^{I k x_i} + e^{I k x_{i-1}}}{\\Delta x^2} $$\n$$ = \\nu \\frac{e^{I k (x_i + \\Delta x)} - 2e^{I k x_i} + e^{I k (x_i - \\Delta x)}}{\\Delta x^2} $$\nFactoring out the term $e^{I k x_i}$:\n$$ = \\frac{\\nu e^{I k x_i}}{\\Delta x^2} \\left(e^{I k \\Delta x} - 2 + e^{-I k \\Delta x}\\right) $$\nUsing Euler's formula, $e^{I\\theta} + e^{-I\\theta} = 2\\cos(\\theta)$, we can simplify the expression in the parenthesis:\n$$ = \\frac{\\nu e^{I k x_i}}{\\Delta x^2} (2\\cos(k \\Delta x) - 2) $$\n$$ = -\\frac{2\\nu}{\\Delta x^2} (1 - \\cos(k \\Delta x)) e^{I k x_i} $$\nUsing the half-angle trigonometric identity $1 - \\cos(\\theta) = 2\\sin^2(\\theta/2)$:\n$$ = -\\frac{4\\nu}{\\Delta x^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) e^{I k x_i} $$\nThis shows that the Fourier modes $e^{I k x_i}$ are indeed eigenfunctions of the operator $\\nu D_{xx}$. The corresponding eigenvalues, which we denote by $\\lambda_k$, are:\n$$ \\lambda_k = -\\frac{4\\nu}{\\Delta x^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) $$\nSince $\\nu  0$ and $\\sin^2(\\cdot)$ is always non-negative, the eigenvalues $\\lambda_k$ are always real and non-positive, i.e., $\\lambda_k \\in \\mathbb{R}$ and $\\lambda_k \\le 0$.\n\nThe problem states to use the stability criterion for the forward Euler method applied to the linear test equation $y' = \\lambda y$. For such an equation, the forward Euler update is $y^{n+1} = y^n + \\Delta T (\\lambda y^n) = (1 + \\lambda \\Delta T) y^n$. For stability, the amplification factor $G = 1 + \\lambda \\Delta T$ must satisfy $|G| \\le 1$.\n\nThis condition, $|1 + \\lambda \\Delta T| \\le 1$, must hold for every eigenvalue $\\lambda_k$ of our system.\n$$ \\left| 1 + \\Delta T \\lambda_k \\right| \\le 1 $$\nSubstituting the expression for $\\lambda_k$:\n$$ \\left| 1 - \\Delta T \\frac{4\\nu}{\\Delta x^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) \\right| \\le 1 $$\nSince $\\Delta T$, $\\nu$, and $\\Delta x^2$ are all positive, the term subtracted from $1$ is always non-negative. This means the expression inside the absolute value is always less than or equal to $1$. The stability condition thus simplifies to only the lower bound:\n$$ 1 - \\Delta T \\frac{4\\nu}{\\Delta x^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) \\ge -1 $$\n$$ 2 \\ge \\Delta T \\frac{4\\nu}{\\Delta x^2} \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) $$\nRearranging to find the constraint on $\\Delta T$:\n$$ \\Delta T \\le \\frac{2 \\Delta x^2}{4\\nu \\sin^2\\left(\\frac{k \\Delta x}{2}\\right)} = \\frac{\\Delta x^2}{2\\nu \\sin^2\\left(\\frac{k \\Delta x}{2}\\right)} $$\nThis condition must hold for all possible wavenumbers $k$ supported by the discrete grid. To ensure stability for all modes, we must satisfy the most restrictive condition. The most restrictive (smallest) upper bound on $\\Delta T$ occurs when the term $\\sin^2\\left(\\frac{k \\Delta x}{2}\\right)$ in the denominator is at its maximum value.\n\nThe maximum value of $\\sin^2(\\theta)$ is $1$. This occurs for the highest-frequency mode representable on the grid, where $k \\Delta x = \\pi$ (corresponding to the Nyquist frequency). For this mode, we have:\n$$ \\max_k \\left[ \\sin^2\\left(\\frac{k \\Delta x}{2}\\right) \\right] = \\sin^2\\left(\\frac{\\pi}{2}\\right) = 1 $$\nSubstituting this maximum value into our inequality gives the universal stability requirement for $\\Delta T$:\n$$ \\Delta T \\le \\frac{\\Delta x^2}{2\\nu (1)} $$\n$$ \\Delta T \\le \\frac{\\Delta x^2}{2\\nu} $$\nThis is the stability restriction analogous to the Courant–Friedrichs–Lewy (CFL) condition for this scheme. The problem asks for the largest permissible $\\Delta T$, which is the upper bound of this range.\n$$ \\Delta T_{\\max} = \\frac{\\Delta x^2}{2\\nu} $$\nThis expression gives the maximum macro-step size that guarantees linear stability for all discrete Fourier modes.",
            "answer": "$$\\boxed{\\frac{\\Delta x^{2}}{2\\nu}}$$"
        }
    ]
}