{
    "hands_on_practices": [
        {
            "introduction": "The core output of a Dynamic Mode Decomposition analysis is a set of eigenvalues and modes. To extract physical insight, we must translate these mathematical objects into properties of the underlying continuous-time system. This exercise focuses on the fundamental mapping that connects the discrete-time eigenvalues found by DMD to the continuous-time growth rates and frequencies that describe the system's temporal evolution .",
            "id": "860820",
            "problem": "Dynamic Mode Decomposition (DMD) is a data-driven method for analyzing the dynamics of complex systems. Consider a spatiotemporal system, such as a fluid flow or a reaction-diffusion process, whose state is described by a field $\\mathbf{u}(x, t)$. A sequence of snapshots of the system state, $\\mathbf{v}_k = \\mathbf{u}(x, t_k)$, is collected at discrete, uniformly spaced times $t_k = k \\Delta t$.\n\nThe core assumption of DMD is that there exists a linear operator $\\mathbf{A}$ that approximates the evolution of the state from one snapshot to the next, such that $\\mathbf{v}_{k+1} \\approx \\mathbf{A} \\mathbf{v}_k$. The DMD algorithm computes the eigenvalues $\\lambda$ and corresponding eigenvectors (DMD modes) of this operator $\\mathbf{A}$.\n\nThese discrete-time eigenvalues are related to the eigenvalues $\\omega$ of an underlying continuous-time linear operator $\\mathbf{L}$ (from the model $\\frac{d\\mathbf{v}}{dt} = \\mathbf{L}\\mathbf{v}$) by the mapping $\\lambda = e^{\\omega \\Delta t}$. The real part of a continuous-time eigenvalue, $\\text{Re}(\\omega)$, determines the temporal growth or decay rate of the corresponding mode, while the imaginary part, $\\text{Im}(\\omega)$, determines its frequency of oscillation.\n\nA researcher applies DMD to a dataset from a chaotic system and identifies a dynamically significant mode. The complex eigenvalue associated with this mode is found to be $\\lambda = a + i b$, where $a$ and $b$ are given real constants. Given the sampling time step $\\Delta t$, determine the temporal growth rate of this continuous-time mode.",
            "solution": "1. The discrete‐to‐continuous mapping is  \n$$\\lambda = e^{\\omega \\,\\Delta t}\\,. $$\n\n2. Take the complex logarithm:  \n$$\\ln \\lambda = \\omega\\,\\Delta t\\quad\\Longrightarrow\\quad \\omega = \\frac{1}{\\Delta t}\\,\\ln\\lambda\\,. $$\n\n3. Write $\\lambda=a+ib$ in polar form:  \n$$|\\lambda|=\\sqrt{a^2+b^2},\\quad \\arg(\\lambda)=\\tan^{-1}\\!\\frac{b}{a},$$  \nso  \n$$\\ln\\lambda = \\ln|\\lambda| + i\\,\\arg(\\lambda) = \\ln\\sqrt{a^2+b^2} + i\\,\\tan^{-1}\\!\\frac{b}{a}\\,. $$\n\n4. The temporal growth rate is the real part of $\\omega$:  \n$$\\Re(\\omega) = \\frac{1}{\\Delta t}\\,\\Re\\bigl(\\ln\\lambda\\bigr)\n= \\frac{1}{\\Delta t}\\,\\ln\\sqrt{a^2+b^2}\n= \\frac{1}{2\\,\\Delta t}\\,\\ln\\bigl(a^2+b^2\\bigr)\\,. $$",
            "answer": "$$\\boxed{\\frac{1}{2\\,\\Delta t}\\,\\ln\\!\\bigl(a^2+b^2\\bigr)}$$"
        },
        {
            "introduction": "A successful application of DMD begins long before the algorithm is run; it starts with data acquisition. The rate at which we sample a system imposes a fundamental limit on the frequencies we can accurately resolve, a principle captured by the Nyquist-Shannon sampling theorem. This practice demonstrates the critical effect of the sampling interval $\\Delta t$ and how improper sampling can lead to aliasing, where high-frequency dynamics are misinterpreted as lower-frequency phenomena .",
            "id": "2387412",
            "problem": "You are given a family of noise-free, complex-valued snapshot sequences generated by a single, spatially fixed oscillatory mode with angular frequency $\\omega$ (in $\\mathrm{rad/s}$), sampled uniformly in time with spacing $\\Delta t$ (in $\\mathrm{s}$). Let the state at time $t_k = k\\,\\Delta t$ be $x_k \\in \\mathbb{C}^n$, and suppose $x_k = \\alpha \\,\\phi \\, e^{\\mathrm{i}\\,\\omega\\, t_k}$, where $\\alpha \\in \\mathbb{C}$ is a nonzero complex amplitude, $\\phi \\in \\mathbb{C}^n$ is a nonzero spatial mode vector, and $\\mathrm{i}$ is the imaginary unit. For the purposes of this task, take $n=1$, $\\alpha = 1$, and $\\phi = [1]$, so that $x_k = e^{\\mathrm{i}\\,\\omega\\,k\\,\\Delta t}$ is a scalar. You must estimate the sampled-mode eigenvalue $\\lambda$ that advances snapshots by one step and infer a continuous-time angular frequency estimate from it. Then, you must assess whether the inferred frequency indicates temporal aliasing at the given sampling spacing $\\Delta t$.\n\nFor each test case below, construct the snapshot sequence of length $M$ by forming the $M$ snapshots $x_0, x_1, \\dots, x_{M-1}$ at times $t_k = k\\,\\Delta t$. Define the snapshot matrices $X = [x_0,\\dots,x_{M-2}]$ and $Y = [x_1,\\dots,x_{M-1}]$. Consider the best-fit linear operator $A$ (in the least-squares sense) that advances snapshots by one step, such that $Y \\approx A\\,X$. Let $\\lambda$ denote the unique eigenvalue of the restriction of $A$ to the range of $X$. Map $\\lambda$ to a continuous-time angular frequency estimate via the principal value of the complex logarithm: if $\\lambda = e^{(\\sigma + \\mathrm{i}\\,\\theta)}$ for some real $\\sigma$ and real $\\theta \\in (-\\pi,\\pi]$, then define the principal angular frequency estimate $\\widehat{\\omega}_{\\mathrm{pr}} = \\theta/\\Delta t$ (in $\\mathrm{rad/s}$). Report the nonnegative principal value $|\\widehat{\\omega}_{\\mathrm{pr}}|$.\n\nAliasing assessment: temporal aliasing occurs when the true angular frequency $\\omega$ lies outside the resolvable principal band $(-\\pi/\\Delta t,\\ \\pi/\\Delta t]$. In terms of the principal estimate, declare that aliasing is detected if the absolute error between the reported nonnegative principal estimate and the true $\\omega$ exceeds a fixed tolerance $\\tau = 1.0$ (in $\\mathrm{rad/s}$), i.e., if $||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| > \\tau$.\n\nYour program must produce the results for the following test suite of parameter values, each defined by the triple $(\\omega,\\ \\Delta t,\\ M)$:\n\n- Test A (happy path, below Nyquist): $(\\omega,\\ \\Delta t,\\ M) = (40.0,\\ 0.02,\\ 200)$.\n- Test B (above Nyquist, clear aliasing): $(\\omega,\\ \\Delta t,\\ M) = (400.0,\\ 0.01,\\ 300)$.\n- Test C (boundary case at Nyquist): $(\\omega,\\ \\Delta t,\\ M) = \\left(\\dfrac{\\pi}{0.01},\\ 0.01,\\ 200\\right)$.\n\nAll angles must be in radians, and all angular frequencies must be in $\\mathrm{rad/s}$. Time must be in $\\mathrm{s}$. For each test case, output a two-element list $[\\ |\\widehat{\\omega}_{\\mathrm{pr}}|,\\ \\text{is\\_aliased}\\ ]$ where $|\\widehat{\\omega}_{\\mathrm{pr}}|$ is a float rounded to six decimals, and $\\text{is\\_aliased}$ is a boolean as defined above. Your program should produce a single line of output containing the three per-test results as a comma-separated list enclosed in square brackets, for example, $[[\\dots],[\\dots],[\\dots]]$.",
            "solution": "The problem statement is subjected to rigorous validation.\n\nStep 1: Extracted Givens.\n- The system is a single, spatially fixed oscillatory mode.\n- The state at time $t_k = k\\,\\Delta t$ is $x_k \\in \\mathbb{C}^n$.\n- The state evolution is described by $x_k = \\alpha \\,\\phi \\, e^{\\mathrm{i}\\,\\omega\\, t_k}$, where $\\omega$ is the true angular frequency, $\\Delta t$ is the time step, $\\alpha$ is a nonzero complex amplitude, and $\\phi$ is a nonzero spatial mode vector.\n- For this problem, parameters are simplified to $n=1$, $\\alpha=1$, and $\\phi=[1]$, resulting in the scalar snapshot sequence $x_k = e^{\\mathrm{i}\\,\\omega\\,k\\,\\Delta t}$.\n- Snapshot matrices are defined as $X = [x_0, \\dots, x_{M-2}]$ and $Y = [x_1, \\dots, x_{M-1}]$ for a sequence of length $M$.\n- The objective is to find the best-fit linear operator $A$ such that $Y \\approx A\\,X$.\n- $\\lambda$ is defined as the unique eigenvalue of the restriction of $A$ to the range of $X$.\n- The continuous-time angular frequency estimate, $\\widehat{\\omega}_{\\mathrm{pr}}$, is derived from $\\lambda$ using the principal value of the complex logarithm. If $\\lambda = e^{(\\sigma + \\mathrm{i}\\,\\theta)}$ with $\\theta \\in (-\\pi, \\pi]$, then $\\widehat{\\omega}_{\\mathrm{pr}} = \\theta/\\Delta t$. The value to be reported is $|\\widehat{\\omega}_{\\mathrm{pr}}|$.\n- Temporal aliasing is detected if the absolute error between the estimated and true frequencies exceeds a tolerance $\\tau = 1.0 \\, \\mathrm{rad/s}$, i.e., $||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| > \\tau$.\n- Test cases provided are:\n  1. $(\\omega, \\Delta t, M) = (40.0, 0.02, 200)$.\n  2. $(\\omega, \\Delta t, M) = (400.0, 0.01, 300)$.\n  3. $(\\omega, \\Delta t, M) = (\\pi/0.01, 0.01, 200)$.\n\nStep 2: Validation of Givens.\n- **Scientifically Grounded**: The problem is a simplified, noise-free application of Dynamic Mode Decomposition (DMD), a standard and well-established method in computational engineering and data-driven analysis of dynamical systems. The concepts of discrete-time evolution operators, eigenvalues, aliasing, and the Nyquist criterion are fundamental principles in signal processing and numerical analysis.\n- **Well-Posed**: The problem is mathematically unambiguous. For a single, pure harmonic mode, the snapshot matrix $X$ has rank one, which leads to a uniquely defined $1 \\times 1$ operator $A$ and a unique eigenvalue $\\lambda$. The procedure for calculating the frequency estimate and assessing aliasing is explicitly defined.\n- **Objective**: The problem is stated using precise mathematical language, free from subjectivity or ambiguity.\n\nStep 3: Verdict and Action.\nThe problem is scientifically sound, well-posed, and objective. It is deemed **valid**. A solution will be furnished.\n\nThe objective is to compute the principal angular frequency estimate $|\\widehat{\\omega}_{\\mathrm{pr}}|$ and determine the presence of aliasing for a given single-mode system. The procedure is based on a simplified Dynamic Mode Decomposition (DMD) framework.\n\nFirst, we establish the relationship between the snapshot matrices $X$ and $Y$. The snapshots are given by the scalar sequence $x_k = e^{\\mathrm{i}\\,\\omega\\,k\\,\\Delta t}$ for $k = 0, 1, \\dots, M-1$.\nThe snapshot matrices are $1 \\times (M-1)$ row vectors:\n$$ X = [x_0, x_1, \\dots, x_{M-2}] $$\n$$ Y = [x_1, x_2, \\dots, x_{M-1}] $$\nBy examining the components, we see that the $(k+1)$-th snapshot is related to the $k$-th snapshot by a simple complex multiplication:\n$$ x_{k+1} = e^{\\mathrm{i}\\,\\omega\\,(k+1)\\,\\Delta t} = e^{\\mathrm{i}\\,\\omega\\,k\\,\\Delta t} \\cdot e^{\\mathrm{i}\\,\\omega\\,\\Delta t} = x_k \\cdot e^{\\mathrm{i}\\,\\omega\\,\\Delta t} $$\nThis implies a direct linear relationship between the entire snapshot matrices:\n$$ Y = X \\cdot e^{\\mathrm{i}\\,\\omega\\,\\Delta t} $$\nThe problem asks for the best-fit linear operator $A$ that minimizes the Frobenius norm $||Y - AX||_F$. For this scalar case ($n=1$), the operator $A$ is a $1 \\times 1$ matrix, which is equivalent to a scalar. The least-squares solution is given by $A = Y X^{\\dagger}$, where $X^{\\dagger}$ is the Moore-Penrose pseudoinverse of $X$.\nGiven that $Y = X \\cdot e^{\\mathrm{i}\\,\\omega\\,\\Delta t}$, the expression for $A$ becomes:\n$$ A = (X \\cdot e^{\\mathrm{i}\\,\\omega\\,\\Delta t}) X^{\\dagger} = e^{\\mathrm{i}\\,\\omega\\,\\Delta t} (X X^{\\dagger}) $$\nSince $X$ is a non-zero row vector, the matrix $X X^{\\dagger}$ is the identity mapping (a scalar $1$) on the range of $X$. Therefore, the operator $A$ is precisely the complex scalar:\n$$ A = e^{\\mathrm{i}\\,\\omega\\,\\Delta t} $$\nThe eigenvalue $\\lambda$ of the operator $A$ restricted to the range of $X$ is simply the scalar $A$ itself.\n$$ \\lambda = e^{\\mathrm{i}\\,\\omega\\,\\Delta t} $$\nThis result demonstrates that for a noise-free, single-mode system, the DMD algorithm recovers the exact discrete-time evolution eigenvalue. The number of snapshots $M$ (provided $M>1$) is irrelevant to this ideal calculation.\n\nNext, we infer the continuous-time angular frequency. The relationship is given by $\\lambda = e^{\\Omega \\Delta t}$, where $\\Omega = \\sigma + \\mathrm{i}\\widehat{\\omega}$ is the continuous-time eigenvalue. To recover $\\widehat{\\omega}$, we use the complex logarithm:\n$$ \\ln(\\lambda) = \\ln(|e^{\\mathrm{i}\\,\\omega\\,\\Delta t}|) + \\mathrm{i}\\,\\arg(e^{\\mathrm{i}\\,\\omega\\,\\Delta t}) = \\Omega \\Delta t $$\nThe problem specifies using the principal value of the argument, $\\theta = \\arg(\\lambda)$, which lies in the interval $(-\\pi, \\pi]$.\n$$ \\theta = \\mathrm{atan2}(\\mathrm{Im}(\\lambda), \\mathrm{Re}(\\lambda)) $$\nThis operation maps the true phase angle $\\omega\\,\\Delta t$ to its principal value, which is the source of temporal aliasing.\nThe principal angular frequency estimate $\\widehat{\\omega}_{\\mathrm{pr}}$ is then:\n$$ \\widehat{\\omega}_{\\mathrm{pr}} = \\frac{\\theta}{\\Delta t} $$\nThe value to be reported is its non-negative counterpart, $|\\widehat{\\omega}_{\\mathrm{pr}}|$.\n\nFinally, we assess aliasing. The resolvable band of angular frequencies is $(-\\pi/\\Delta t, \\pi/\\Delta t]$. If the true frequency $\\omega$ is outside this band, the estimated frequency $\\widehat{\\omega}_{\\mathrm{pr}}$ will be an \"alias\" of the true frequency. The problem defines a detection condition based on a numerical tolerance $\\tau=1.0$: aliasing is present if\n$$ ||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| > 1.0 $$\n\nWe apply this procedure to each test case.\n\nCase A: $(\\omega, \\Delta t, M) = (40.0, 0.02, 200)$\nThe Nyquist angular frequency is $\\omega_{Nyq} = \\pi/\\Delta t = \\pi/0.02 \\approx 157.08 \\, \\mathrm{rad/s}$. Since $\\omega = 40.0 < \\omega_{Nyq}$, we do not expect aliasing.\n1.  Compute the true phase angle per step: $\\omega\\,\\Delta t = 40.0 \\times 0.02 = 0.8 \\, \\mathrm{rad}$.\n2.  Since $0.8 \\in (-\\pi, \\pi]$, the principal argument is $\\theta = 0.8$.\n3.  Compute the frequency estimate: $\\widehat{\\omega}_{\\mathrm{pr}} = 0.8 / 0.02 = 40.0 \\, \\mathrm{rad/s}$. Then, $|\\widehat{\\omega}_{\\mathrm{pr}}| = 40.0$.\n4.  Check for aliasing: $||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| = |40.0 - 40.0| = 0.0$. Since $0.0 \\le 1.0$, aliasing is not detected.\nResult: $[40.000000, \\mathrm{False}]$\n\nCase B: $(\\omega, \\Delta t, M) = (400.0, 0.01, 300)$\nThe Nyquist angular frequency is $\\omega_{Nyq} = \\pi/\\Delta t = \\pi/0.01 \\approx 314.16 \\, \\mathrm{rad/s}$. Since $\\omega = 400.0 > \\omega_{Nyq}$, we expect aliasing.\n1.  Compute the true phase angle per step: $\\omega\\,\\Delta t = 400.0 \\times 0.01 = 4.0 \\, \\mathrm{rad}$.\n2.  This angle is outside $(-\\pi, \\pi]$. We find the equivalent angle in this interval: $\\theta = 4.0 - 2\\pi \\approx 4.0 - 6.283185 = -2.283185 \\, \\mathrm{rad}$.\n3.  Compute the frequency estimate: $\\widehat{\\omega}_{\\mathrm{pr}} = -2.283185 / 0.01 = -228.3185 \\, \\mathrm{rad/s}$. Then, $|\\widehat{\\omega}_{\\mathrm{pr}}| = 228.3185$.\n4.  Check for aliasing: $||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| = |228.3185 - 400.0| = |-171.6815| = 171.6815$. Since $171.6815 > 1.0$, aliasing is detected.\nResult: $[228.318531, \\mathrm{True}]$\n\nCase C: $(\\omega, \\Delta t, M) = (\\pi/0.01, 0.01, 200)$\nThe true frequency is exactly at the Nyquist boundary: $\\omega = \\pi/0.01 \\approx 314.16 \\, \\mathrm{rad/s}$.\n1.  Compute the true phase angle per step: $\\omega\\,\\Delta t = (\\pi/0.01) \\times 0.01 = \\pi \\, \\mathrm{rad}$.\n2.  The principal argument interval is $(-\\pi, \\pi]$. Since $\\pi$ is included in this interval, the principal argument is $\\theta = \\pi$.\n3.  Compute the frequency estimate: $\\widehat{\\omega}_{\\mathrm{pr}} = \\pi / 0.01 = \\omega$. Then, $|\\widehat{\\omega}_{\\mathrm{pr}}| = \\pi/0.01 \\approx 314.159265$.\n4.  Check for aliasing: $||\\widehat{\\omega}_{\\mathrm{pr}}| - \\omega| = |\\omega - \\omega| = 0.0$. Since $0.0 \\le 1.0$, aliasing is not detected.\nResult: $[314.159265, \\mathrm{False}]$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating angular frequency from sampled data\n    and assessing temporal aliasing based on a simplified DMD model.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (omega, delta_t, M)\n    # where omega is angular frequency, delta_t is sampling interval,\n    # and M is number of snapshots.\n    test_cases = [\n        (40.0, 0.02, 200),\n        (400.0, 0.01, 300),\n        (np.pi / 0.01, 0.01, 200),\n    ]\n\n    # Tolerance for aliasing detection\n    tau = 1.0\n\n    results = []\n    for omega, delta_t, M in test_cases:\n        # The problem describes an ideal, noise-free, single-mode system.\n        # The theoretical discrete-time eigenvalue lambda is simply exp(i * omega * delta_t).\n        # We do not need to construct the snapshot matrices explicitly.\n\n        # 1. Calculate the theoretical DMD eigenvalue lambda.\n        # This is the complex number representing the one-step evolution.\n        lambda_val = np.exp(1j * omega * delta_t)\n\n        # 2. Extract the principal value of the argument (phase angle) of lambda.\n        # np.angle returns values in the interval [-pi, pi], which corresponds\n        # to the problem's definition of the principal interval (-pi, pi].\n        theta = np.angle(lambda_val)\n\n        # 3. Infer the continuous-time principal angular frequency estimate.\n        omega_hat_pr = theta / delta_t\n\n        # 4. Report the non-negative principal value.\n        abs_omega_hat_pr = np.abs(omega_hat_pr)\n\n        # 5. Assess for aliasing based on the given criterion.\n        # Aliasing is detected if | |omega_hat_pr| - omega | > tau.\n        # We need to use abs() again on the inner term as omega_hat_pr could be negative\n        # and we are comparing its magnitude with the true positive frequency.\n        # However, the problem formulation is | |omega_hat_pr| - omega |.\n        is_aliased = np.abs(abs_omega_hat_pr - omega) > tau\n\n        # Store the result for this test case.\n        # The first element is rounded to six decimal places, the second is a boolean.\n        results.append(\n            [round(abs_omega_hat_pr, 6), bool(is_aliased)]\n        )\n\n    # Format the final output string to match the required format: [[...],[...],[...]]\n    # Each inner list is formatted as a string, then they are joined by commas.\n    formatted_results = [f\"[{res[0]:.6f}, {res[1]}]\" for res in results]\n    final_output_string = f\"[{','.join(formatted_results)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world data is often complex and may contain features that are not representative of the system's intrinsic dynamics, such as measurement drift or scaling trends. A naive application of DMD can misinterpret these artifacts as genuine dynamic growth or decay, leading to flawed conclusions. This computational exercise illustrates this common pitfall and demonstrates how a simple preprocessing step—per-snapshot normalization—can effectively separate true oscillatory behavior from superimposed scaling trends .",
            "id": "3121296",
            "problem": "You are to implement a complete program that constructs illustrative data sets and applies Dynamic Mode Decomposition (DMD) to demonstrate how per-snapshot scale changes can cause DMD to misinterpret a trend as a growing mode, and how normalization of each snapshot prevents this misinterpretation.\n\nThe fundamental base you must use is as follows:\n- The data consist of discrete-time snapshots of a state vector, where a best-fit linear operator maps each snapshot to the next. Specifically, the state evolves according to a linear model $x_{t+1} \\approx A x_t$ that minimizes the total squared error over all consecutive snapshot pairs. This is a least-squares problem in which the Frobenius norm of the residual is minimized.\n- The Dynamic Mode Decomposition (DMD) algorithm constructs a low-dimensional representation of the best-fit operator from the snapshot data and returns eigenvalues that approximate the discrete-time dynamics. An eigenvalue with magnitude greater than $1$ indicates growth per time step; a magnitude equal to $1$ indicates neutral oscillation; a magnitude less than $1$ indicates decay.\n\nDesign the program to:\n- Construct matrices of column snapshots for multiple cases, where each column is one snapshot at an integer time $t$.\n- Compute the eigenvalues of the DMD operator and report the spectral radius, defined as the maximum of the magnitudes of the eigenvalues.\n- Apply per-snapshot normalization in the specified cases: divide each column by its Euclidean norm to remove overall scale variations.\n\nData construction details to ensure scientific realism:\n- Use a base two-dimensional oscillatory signal with angular frequency $\\omega$ (in radians per time step) given by $\\omega = 0.37$. For each integer time $t$ with $0 \\le t \\le T-1$ and with number of snapshots $T = 80$, define the unscaled state as $x_t = [\\cos(\\omega t), \\sin(\\omega t)]^\\top$. This corresponds to a pure planar rotation of constant amplitude.\n- For cases with scaling, multiply each snapshot by a scaling factor $s_t = \\alpha^t$ with $\\alpha = 1.02$. This introduces a monotone scale change across time that is not part of the true underlying neutral oscillation but can be incorrectly interpreted by DMD as growth unless snapshots are normalized.\n- For the degenerate edge case, use a constant spatial direction $v \\in \\mathbb{R}^3$ with components $v = [1, -1, 0]^\\top$, and define snapshots $x_t = s_t v$ with the same scaling factor $s_t = \\alpha^t$ and number of snapshots $T = 80$.\n\nAlgorithmic requirements:\n- From the snapshot matrix $X = [x_0, x_1, \\dots, x_{T-1}]$, form $X_1 = [x_0, x_1, \\dots, x_{T-2}]$ and $X_2 = [x_1, x_2, \\dots, x_{T-1}]$.\n- Compute the best-fit linear operator in the least-squares sense and extract its eigenvalues in a numerically stable manner by using a reduced low-rank representation constructed from singular value decomposition. You must not assume prior knowledge of the target matrix or its spectrum; you must derive it from the data.\n- For per-snapshot normalization, scale each column $x_t$ to $\\widehat{x}_t = x_t / \\|x_t\\|_2$ for all $t$ for which the norm is nonzero.\n\nTest suite:\n- Case $1$ (baseline, no scaling): Two-dimensional rotation with $T = 80$, $\\omega = 0.37$, snapshots $x_t = [\\cos(\\omega t), \\sin(\\omega t)]^\\top$. Compute the DMD spectral radius $\\rho_1$. Expect $\\rho_1$ close to $1$.\n- Case $2$ (scale-induced trend): Same as Case $1$ but scaled by $s_t = \\alpha^t$ with $\\alpha = 1.02$. Compute the DMD spectral radius $\\rho_2$. Expect $\\rho_2 > 1$.\n- Case $3$ (normalized to remove scale trend): Same as Case $2$, but normalize each snapshot by its Euclidean norm before applying DMD. Compute the DMD spectral radius $\\rho_3$. Expect $\\rho_3$ close to $1$.\n- Case $4$ (degenerate edge case with rank-$1$ data): Three-dimensional constant direction $v = [1, -1, 0]^\\top$, scaling $s_t = \\alpha^t$ with $\\alpha = 1.02$ and $T = 80$. Compute two spectral radii: $\\rho_{4,\\text{raw}}$ without normalization and $\\rho_{4,\\text{norm}}$ with per-snapshot normalization. Expect $\\rho_{4,\\text{raw}} > 1$ and $\\rho_{4,\\text{norm}}$ close to $1$.\n\nAngle unit specification: All angles are in radians.\n\nAnswer specification:\n- For each case, produce a boolean indicating whether the expected behavior is observed within a small tolerance. Use tolerance $\\varepsilon = 0.05$ for testing closeness to $1$, and test “greater than $1$” by requiring a margin $\\delta = 0.01$.\n- Define the four results as:\n  - $b_1 = (|\\rho_1 - 1| < \\varepsilon)$\n  - $b_2 = (\\rho_2 > 1 + \\delta)$\n  - $b_3 = (|\\rho_3 - 1| < \\varepsilon)$\n  - $b_4 = [(\\rho_{4,\\text{raw}} > 1 + \\delta) \\wedge (|\\rho_{4,\\text{norm}} - 1| < \\varepsilon)]$\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[True,False,True,True]\").\n\nConstraints:\n- Implement the DMD eigenvalue computation using standard numerical linear algebra routines without relying on domain-specific black-box libraries.\n- Do not require any user input and do not access external files or networks. The program must run as is and print the required output line.",
            "solution": "The problem requires the implementation of the Dynamic Mode Decomposition (DMD) algorithm to analyze synthetic datasets. The goal is to demonstrate how DMD can mistake a global scaling trend for dynamic growth and how per-snapshot normalization rectifies this issue. The solution proceeds by first detailing the DMD algorithm, then applying it to the four specified cases.\n\nThe core principle of DMD is to model a time series of state vectors, or snapshots, $\\{x_0, x_1, \\dots, x_{T-1}\\}$ where each $x_t \\in \\mathbb{R}^n$, with a linear dynamical system of the form $x_{t+1} \\approx A x_t$. The DMD algorithm seeks to find the best-fit linear operator $A \\in \\mathbb{R}^{n \\times n}$ that advances the system state in time.\n\nFirst, we assemble the snapshot data into two matrices. Let $X$ be the full data matrix whose columns are the snapshots:\n$$\nX = [x_0, x_1, \\dots, x_{T-1}]\n$$\nWe then form two sub-matrices, $X_1$ and $X_2$, by splitting the data:\n$$\nX_1 = [x_0, x_1, \\dots, x_{T-2}] \\in \\mathbb{R}^{n \\times (T-1)}\n$$\n$$\nX_2 = [x_1, x_2, \\dots, x_{T-1}] \\in \\mathbb{R}^{n \\times (T-1)}\n$$\nThe relationship between these matrices is $X_2 \\approx A X_1$. The operator $A$ is found by solving the least-squares problem that minimizes the Frobenius norm of the residual, $\\|X_2 - A X_1\\|_F$. The solution is given by:\n$$\nA = X_2 X_1^+\n$$\nwhere $X_1^+$ is the Moore-Penrose pseudoinverse of $X_1$.\n\nFor large state dimensions $n$, forming the operator $A$ directly is computationally expensive and numerically unstable. The standard DMD algorithm avoids this by computing the spectral properties of $A$ via a low-rank approximation. This is achieved using the Singular Value Decomposition (SVD) of $X_1$. Let the reduced SVD of $X_1$ be:\n$$\nX_1 = U \\Sigma V^*\n$$\nwhere $U \\in \\mathbb{R}^{n \\times r}$, $\\Sigma \\in \\mathbb{R}^{r \\times r}$ is a diagonal matrix of singular values, and $V \\in \\mathbb{R}^{(T-1) \\times r}$ is a matrix of right singular vectors. Here, $r$ is the rank of $X_1$. The columns of $U$ form an orthonormal basis for the range of $X_1$. The pseudoinverse can be expressed as $X_1^+ = V \\Sigma^{-1} U^*$.\n\nSubstituting this into the expression for $A$ gives $A = X_2 V \\Sigma^{-1} U^*$. Instead of computing $A$, we analyze a smaller, rank-$r$ operator $\\tilde{A}$ that represents the projection of $A$ onto the basis $U$:\n$$\n\\tilde{A} = U^* A U = U^* (X_2 V \\Sigma^{-1} U^*) U = U^* X_2 V \\Sigma^{-1}\n$$\nThe matrix $\\tilde{A} \\in \\mathbb{R}^{r \\times r}$ has the same non-zero eigenvalues as $A$. These eigenvalues, the DMD eigenvalues, characterize the dynamics of the system. The spectral radius $\\rho$ is the maximum of the magnitudes of these eigenvalues, $\\rho = \\max_i(|\\lambda_i|)$. $|\\lambda_i| > 1$ signals growth, $|\\lambda_i| < 1$ signals decay, and $|\\lambda_i| = 1$ signals energy-preserving oscillation.\n\nFor certain cases, per-snapshot normalization is required. Before forming the matrices $X_1$ and $X_2$, each snapshot $x_t$ is scaled by its Euclidean norm, provided the norm is non-zero:\n$$\n\\widehat{x}_t = \\frac{x_t}{\\|x_t\\|_2}\n$$\nThis process removes variations in the overall magnitude of the state, isolating the underlying directional dynamics.\n\nThe problem defines four test cases to validate this understanding.\n\nCase $1$: The data consists of snapshots $x_t = [\\cos(\\omega t), \\sin(\\omega t)]^\\top$ for $T = 80$ snapshots and $\\omega = 0.37$. This represents a pure rotation. The underlying dynamics are energy-preserving, so the true operator is a rotation matrix whose eigenvalues lie on the unit circle. Therefore, the DMD spectral radius $\\rho_1$ is expected to be very close to $1$. The test is $|\\rho_1 - 1| < \\varepsilon$ with $\\varepsilon = 0.05$.\n\nCase $2$: The snapshots from Case $1$ are scaled by a growing factor $s_t = \\alpha^t$ with $\\alpha = 1.02$, so $x_t = \\alpha^t [\\cos(\\omega t), \\sin(\\omega t)]^\\top$. The relationship between consecutive snapshots is $x_{t+1} \\approx \\alpha R x_t$, where $R$ is the rotation operator from Case $1$. The DMD operator will capture both the rotation and the scaling factor $\\alpha$. Its eigenvalues will be approximately $\\alpha$ times the eigenvalues of $R$. The spectral radius $\\rho_2$ is thus expected to be approximately $\\alpha = 1.02$. The test is $\\rho_2 > 1 + \\delta$ with $\\delta = 0.01$.\n\nCase $3$: This case uses the same scaled data as Case $2$ but applies per-snapshot normalization before running DMD. The normalization of a snapshot $x_t$ is $\\widehat{x}_t = x_t / \\|x_t\\|_2 = (\\alpha^t [\\cos(\\omega t), \\sin(\\omega t)]^\\top) / \\|\\alpha^t [\\cos(\\omega t), \\sin(\\omega t)]^\\top\\|_2$. Since $\\|\\cdot\\|_2$ is a norm and $\\alpha^t > 0$, this simplifies to $\\widehat{x}_t = [\\cos(\\omega t), \\sin(\\omega t)]^\\top$, as the base vector has unit norm. Normalization completely removes the scaling trend, recovering the data from Case $1$. Consequently, the spectral radius $\\rho_3$ is expected to be close to $1$, just like $\\rho_1$. The test is $|\\rho_3 - 1| < \\varepsilon$.\n\nCase $4$: This is a degenerate case with a rank-$1$ data matrix. The snapshots are $x_t = s_t v = \\alpha^t [1, -1, 0]^\\top$.\nWithout normalization, the dynamics are exact: $x_{t+1} = \\alpha^{t+1} v = \\alpha (\\alpha^t v) = \\alpha x_t$. The system is perfectly linear with a single eigenvalue $\\alpha = 1.02$. The spectral radius $\\rho_{4,\\text{raw}}$ must therefore be approximately $1.02$. The test is $\\rho_{4,\\text{raw}} > 1 + \\delta$.\nWith normalization, each snapshot becomes $\\widehat{x}_t = x_t / \\|x_t\\|_2 = (\\alpha^t v) / (\\alpha^t \\|v\\|_2) = v / \\|v\\|_2$. All snapshots are identical constant vectors. Thus, $\\widehat{x}_{t+1} = \\widehat{x}_t$. The governing operator is the identity, with a single eigenvalue of $1$. The spectral radius $\\rho_{4,\\text{norm}}$ is expected to be $1$. The test is $|\\rho_{4,\\text{norm}} - 1| < \\varepsilon$.\nThe combined test for this case is $(\\rho_{4,\\text{raw}} > 1 + \\delta) \\wedge (|\\rho_{4,\\text{norm}} - 1| < \\varepsilon)$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef dmd(X):\n    \"\"\"\n    Computes the Dynamic Mode Decomposition of a snapshot matrix X.\n    \n    Args:\n        X (np.ndarray): The snapshot matrix, where each column is a snapshot.\n        \n    Returns:\n        np.ndarray: The eigenvalues of the DMD operator.\n    \"\"\"\n    # 1. Split data into X1 and X2\n    X1 = X[:, :-1]\n    X2 = X[:, 1:]\n\n    # 2. Compute SVD of X1\n    # Use full_matrices=False for economy SVD\n    U, s, Vh = np.linalg.svd(X1, full_matrices=False)\n    \n    # Handle the case where singular values are close to zero to avoid division by zero.\n    # We can truncate, but for this problem, the ranks are well-defined.\n    # Let's ensure no division by a value smaller than machine epsilon occurs.\n    s_inv = np.zeros_like(s)\n    s_inv[s > 1e-15] = 1.0 / s[s > 1e-15]\n\n    # 3. Compute the low-rank operator Atilde\n    # Atilde = U.T @ A @ U = U.T @ (X2 @ V @ inv(Sigma) @ U.T) @ U\n    # Atilde = U.T @ X2 @ V @ inv(Sigma)\n    V = Vh.T\n    Atilde = U.T @ X2 @ V @ np.diag(s_inv)\n\n    # 4. Compute eigenvalues of Atilde\n    eigenvalues = np.linalg.eigvals(Atilde)\n    \n    return eigenvalues\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define problem parameters\n    T = 80\n    omega = 0.37\n    alpha = 1.02\n    v = np.array([1, -1, 0])\n\n    # Tolerances for checks\n    epsilon = 0.05\n    delta = 0.01\n\n    results = []\n    \n    t = np.arange(T)\n\n    # --- Case 1: Baseline, no scaling ---\n    X1_data = np.vstack([np.cos(omega * t), np.sin(omega * t)])\n    eigs1 = dmd(X1_data)\n    rho1 = np.max(np.abs(eigs1))\n    b1 = np.abs(rho1 - 1) < epsilon\n    results.append(b1)\n\n    # --- Case 2: Scale-induced trend ---\n    scaling_factor = alpha**t\n    X2_data = np.vstack([np.cos(omega * t), np.sin(omega * t)]) * scaling_factor\n    eigs2 = dmd(X2_data)\n    rho2 = np.max(np.abs(eigs2))\n    b2 = rho2 > (1 + delta)\n    results.append(b2)\n    \n    # --- Case 3: Normalized to remove scale trend ---\n    # Data is the same as Case 2\n    norms3 = np.linalg.norm(X2_data, axis=0)\n    # Avoid division by zero, although not expected here\n    non_zero_norms = norms3 > 1e-15\n    X3_data = np.zeros_like(X2_data)\n    X3_data[:, non_zero_norms] = X2_data[:, non_zero_norms] / norms3[non_zero_norms]\n    eigs3 = dmd(X3_data)\n    rho3 = np.max(np.abs(eigs3))\n    b3 = np.abs(rho3 - 1) < epsilon\n    results.append(b3)\n\n    # --- Case 4: Degenerate edge case with rank-1 data ---\n    # Reshape v to a column vector (3, 1) and scaling_factor to a row vector (1, T)\n    # The result is a (3, T) matrix\n    X4_data_raw = v[:, np.newaxis] @ scaling_factor[np.newaxis, :]\n    \n    # Compute for raw data\n    eigs4_raw = dmd(X4_data_raw)\n    rho4_raw = np.max(np.abs(eigs4_raw))\n    \n    # Compute for normalized data\n    norms4 = np.linalg.norm(X4_data_raw, axis=0)\n    non_zero_norms_4 = norms4 > 1e-15\n    X4_data_norm = np.zeros_like(X4_data_raw)\n    X4_data_norm[:, non_zero_norms_4] = X4_data_raw[:, non_zero_norms_4] / norms4[non_zero_norms_4]\n    \n    eigs4_norm = dmd(X4_data_norm)\n    rho4_norm = np.max(np.abs(eigs4_norm))\n    \n    b4 = (rho4_raw > (1 + delta)) and (np.abs(rho4_norm - 1) < epsilon)\n    results.append(b4)\n    \n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}