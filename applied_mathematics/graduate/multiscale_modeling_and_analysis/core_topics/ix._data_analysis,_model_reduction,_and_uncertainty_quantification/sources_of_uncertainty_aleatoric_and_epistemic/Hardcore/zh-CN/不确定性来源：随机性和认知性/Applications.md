## 应用与跨学科联系

在前面的章节中，我们已经建立了[偶然不确定性](@entry_id:634772)（aleatoric uncertainty）和认知不确定性（epistemic uncertainty）的核心原理和机制。[偶然不确定性](@entry_id:634772)源于系统固有的、不可简化的随机性，而认知不确定性则源于我们知识的局限性，例如模型结构不完善或参数未知。本章的目标不是重复这些定义，而是展示这些概念在不同科学与工程领域的实际应用中如何发挥关键作用。我们将通过一系列跨学科的应用案例，探讨这两种不确定性的区分如何帮助我们更深刻地理解模型、更可靠地进行推断，并最终做出更负责任的决策。

### 物理与生物系统建模中的不确定性

科学与工程建模的核心任务之一是利用数学方程描述物理或[生物过程](@entry_id:164026)。然而，任何模型都是现实世界的简化，而不确定性量化（UQ）正是为了表征这种简化以及我们观测能力的局限性。[偶然不确定性与认知不确定性](@entry_id:1120923)的划分，为我们提供了一个严谨的框架来分析和处理这些[不确定性的来源](@entry_id:164809)。

在许多应用中，我们使用一个确定的模型（例如一组[常微分方程](@entry_id:147024)或[偏微分](@entry_id:194612)方程）来描述一个系统的演化，但模型的关键参数是未知的。在贝叶斯推断框架下，这种参数不确定性被自然地处理为认知不确定性。例如，在[热传导](@entry_id:143509)问题中，材料的[热导](@entry_id:189019)率 $k$ 和对流换热系数 $h$ 可能未知。通过实验测量温度分布，我们可以构建一个贝叶斯模型来估计这些参数。在这个模型中，代表我们对 $k$ 和 $h$ 先验知识的先验分布 $p(k,h)$ 编码了认知不确定性。相反，测量过程中由于传感器精度限制或环境的微小波动而产生的随机噪声 $\varepsilon$，则被建模为[偶然不确定性](@entry_id:634772)，并体现在[似然函数](@entry_id:921601) $p(\mathbf{y} | k,h)$ 中。随着我们收集更多数据，关于参数的[后验分布](@entry_id:145605)会变得更加集中，认知不确定性随之减小，但测量噪声的固有方差（[偶然不确定性](@entry_id:634772)）则不会消失 。同样，在描述细胞内信号通路或[代谢网络](@entry_id:166711)的[计算系统生物学](@entry_id:747636)中，常微分方程（ODE）模型中的[反应速率常数](@entry_id:187887) $\theta$ 和初始[物种浓度](@entry_id:197022) $x_0$ 往往是未知的。这些未知但固定的量构成了认知[不确定性的来源](@entry_id:164809)，通过对其赋予先验分布并在观测数据下更新为[后验分布](@entry_id:145605)来量化。而实验测量中的噪声则代表了[偶然不确定性](@entry_id:634772) 。

当模型规模扩大到地球系统级别时，这两种不确定性的来源变得更加复杂和多样。在数值天气预报和气候模型中，认知不确定性不仅包括物理参数化方案（如云的形成与消散、[湍流混合](@entry_id:202591)等）中的大量未知参数 $\boldsymbol{\theta}$，还包括模型结构本身的选择（例如，使用哪种对流方案）。通过构建参数扰动集合（PPE）或多模型集合，研究人员可以探索这些认知不确定性对预报结果的影响。另一方面，[偶然不确定性](@entry_id:634772)源于模型无法解析的[次网格尺度过程](@entry_id:1132602)的[随机效应](@entry_id:915431)（通常由随机物理倾向项 $\eta(t)$ 表示），以及气候系统固有的、源于[混沌动力学](@entry_id:142566)的内部变率。例如，即使在外部强迫固定的情况下，不同初始条件下的气候模拟也会产生一系列不同的轨迹，这种轨迹的散布范围就是[内部变率](@entry_id:1126630)（一种[偶然不确定性](@entry_id:634772)）的体现 。在卫星遥感领域，例如[被动微波遥感](@entry_id:1129415)反演土壤湿度时，反演算法中辐射传输算子 $h(\cdot)$ 的参数 $\boldsymbol{\theta}_h$ 的不确定性是认知的，可以通过实验室和田间定标来减少。而传感器本身的热噪声和卫星大像元内真实地表状态（如土壤湿度、植被）的次像元尺度空间[异质性](@entry_id:275678)，则是偶然不确定性的来源，它构成了[观测误差](@entry_id:752871)中不可简化的部分 。

在更形式化的[数学物理](@entry_id:265403)模型中，这种区分也至关重要。考虑[计算流体动力学](@entry_id:142614)（CFD）中跨音速机翼的阻力系数 $C_D$ 预测。我们可以使用总方差定律来分解总预测不确定性：$\mathrm{Var}(Y) = \mathbb{E}[\mathrm{Var}(Y | \Theta)] + \mathrm{Var}(\mathbb{E}[Y | \Theta])$。这里，$\Theta$ 代表模型中由于知识不足而未知的所有因素，如[雷诺平均纳维-斯托克斯](@entry_id:173045)（RANS）模型中的[湍流](@entry_id:151300)闭合系数或翼表面的转捩位置，其不确定性是认知的。即使 $\Theta$ 完全已知，来流中随机的[湍流](@entry_id:151300)阵风（由 $X$ 表示）仍会导致 $C_D$ 变化，这就是[偶然不确定性](@entry_id:634772)，由第一项 $\mathbb{E}[\mathrm{Var}(Y | \Theta)]$ 量化。而第二项 $\mathrm{Var}(\mathbb{E}[Y | \Theta])$ 则量化了由于我们对 $\Theta$ 的无知而导致的预测均值的变化，即认知不确定性 。在[随机均匀化](@entry_id:1132426)理论中，这种分离更加清晰。对于一个具有随机微观结构的多孔介质，其有效（宏观）属性 $A^\star$ 是一个确定性常数，它取决于微观结构场的统计规律。在实际计算中，我们通过[代表性体积元](@entry_id:164290)（RVE）得到一个估计值 $A_L(\omega)$。对于给定的统计规律，由于 RVE 尺寸 $L$ 有限而产生的样本间波动（即 $A_L(\omega)$ 的方差）是偶然的，它会随着 $L \to \infty$ 而消失。然而，如果微观结构场的统计规律本身是由一组未知的超参数 $\theta$ 控制的，那么有效属性 $A^\star$ 就是 $\theta$ 的函数。我们对 $\theta$ 的不确定性（认知不确定性）将导致对 $A^\star$ 的不确定性，这种不确定性不会因为增大 RVE 尺寸而消失，只能通过额外的实验数据来约束 $\theta$ 以减小 。

最后，一个成熟的UQ框架必须承认，任何模型都可能存在结构性缺陷。在核物理的[能量密度泛函](@entry_id:161351)（EDF）理论等前沿领域，标准的[贝叶斯推断](@entry_id:146958)被扩展为包含一个额外的随机项，即[模型差异](@entry_id:198101)项 $\Delta(x)$，以明确表示我们知道模型 $g(x,\theta)$ 本身是不完善的。在这种[分层模型](@entry_id:274952) $Y = g(x,\theta) + \Delta(x) + \varepsilon$ 中，总预测方差可以被清晰地分解为三个部分：来自测量噪声 $\varepsilon$ 的[偶然不确定性](@entry_id:634772) $\mathrm{Var}(\varepsilon)$；来自参数未知性 $\theta$ 的认知不确定性 $\mathrm{Var}_\theta(g(x,\theta))$；以及来自模型结构缺陷的认知不确定性，即[模型差异](@entry_id:198101)项的方差 $\mathrm{Var}(\Delta(x))$。这种分解对于理解预测不确定性的真正来源至关重要 。

### 数据驱动与代理模型中的不确定性

随着机器学习的兴起，数据驱动的模型和代理模型在科学与工程中变得无处不在。在这些模型中，[偶然不确定性与认知不确定性](@entry_id:1120923)的区分同样核心，它帮助我们理解模型的预测能力边界。

[高斯过程](@entry_id:182192)（GP）回归是代理建模中的一个经典例子，它为这两种不确定性提供了优雅的数学分离。当使用GP拟合一组带有噪声的观测数据 $y_i = f(x_i) + \varepsilon_i$ 时，GP模型同时学习潜在函数 $f(x)$ 和噪声水平。在做出新预测时，总预测方差被分解为两部分：$\sigma_{y_\star}^2 = \sigma_{f_\star}^2 + \sigma_n^2$。其中，$\sigma_{f_\star}^2$ 是关于潜在函数 $f(x_\star)$ 的后验方差，它代表了认知不确定性。在数据点密集的区域，这个方差很小；而在数据稀疏的区域，它会增大，反映了模型在这些区域知识的缺乏。随着我们收集更多数据，$\sigma_{f_\star}^2$ 会趋向于零。另一部分 $\sigma_n^2$ 是数据噪声方差的估计值，代表了[偶然不确定性](@entry_id:634772)。这个量是数据生成过程的内在属性，即使有无限多的数据，它也不会消失 。

在更复杂的深度学习模型中，虽然没有GP那样直接的解析分解，但通过特定技术也可以近似地分离这两种不确定性。一种流行的方法是使用蒙特卡洛 dropout 或[深度集成](@entry_id:636362)（deep ensembles），并让神经网络同时预测均值 $\mu_\theta(x)$ 和方差 $\sigma_\theta^2(x)$（即异方差似然）。通过多次随机[前向传播](@entry_id:193086)（使用不同的dropout掩码或不同的集成成员），我们可以得到一组预测 $(\mu^{(k)}(x), \sigma^{2,(k)}(x))$。根据总方差定律，总预测方差可以分解为：$\text{Var}(y) \approx \frac{1}{K}\sum_k \sigma^{2,(k)}(x) + \text{Var}(\{\mu^{(k)}(x)\})$。第一项是模型预测方差的平均值，它捕捉了数据中与输入相关的[固有噪声](@entry_id:261197)，即[偶然不确定性](@entry_id:634772)。第二项是模型预测均值的方差，它反映了由于模型参数的不确定性（由dropout或集成成员的不同来近似）而导致的预测分歧，这正是认知不确定性的体现。随着训练数据的增多，认知不确定性项会减小，而[偶然不确定性](@entry_id:634772)项则会收敛到数据中真实的噪声水平 。

在许多实际的计算科学问题中，我们常常拥有不同保真度的模型。例如，一个高保真模型（如直接数值模拟）计算成本高昂但准确，而一个低保真模型（如基于简化物理的近似模型）计算成本低但存在系统性偏差。这是一个典型的多保真建模场景。高保真模型由于其随机性（例如，它是对某个[随机过程](@entry_id:268487)的[蒙特卡洛估计](@entry_id:637986)），其输出包含采样误差，这是一种[偶然不确定性](@entry_id:634772)，可以通过增加样本量来减小。而低保真模型与真实物理量之间的系统性偏差 $b(x)$ 则是一种[模型形式误差](@entry_id:274198)，属于认知不确定性。多保真建模的目标正是利用少量高保真数据来学习和修正低保真模型的认知偏差，从而以较低的总计算成本获得高精度的预测 。当存在多个竞争性的模型时，我们对“哪个模型是最好的”这一问题本身的不确定性也是一种认知不确定性。[贝叶斯模型平均](@entry_id:168960)（BMA）提供了一个原则性的框架来处理这种[模型选择](@entry_id:155601)不确定性。它不是选择单一“最佳”模型，而是通过后验模型概率对所有模型的预测进行加权平均。总预测方差因此可以分解为模型内部方差的加权平均和模型间方差。模型间方差项直接量化了因模型形式选择不同而产生的认知不确定性 。

### 科学实践与决策中的不确定性

[偶然不确定性与认知不确定性](@entry_id:1120923)的区分，其影响远远超出了模型构建本身，延伸到[科学方法](@entry_id:143231)的实践、模型验证、结果的可复现性，乃至基于模型的决策制定与伦理责任。

在[统计学习](@entry_id:269475)和模型验证的日常实践中，这些概念也有具体的体现。例如，在使用 $k$-折[交叉验证](@entry_id:164650)（CV）评估模型性能时，我们可以从其结果中窥见两种不确定性的影子。当训练数据量趋于无穷大时，对于一个良定义的模型类，CV估计的[均方误差](@entry_id:175403)会收敛到一个下限，这个下限由数据中不可简化的噪声（[偶然不确定性](@entry_id:634772)）和模型类固有的偏差（认知不确定性的一种）决定。如果模型类是正确的，那么CV误差的极限就是[偶然不确定性](@entry_id:634772)的大小。另一方面，CV在不同折（fold）上的性能表现的稳定性，即所谓的“折间方差”，可以作为[模型稳定性](@entry_id:636221)的一个指标。如果一个模型（例如，由于过于灵活或参数不可辨识）对训练数据的微小变化高度敏感，那么它在不同折上训练出的实例 $\hat{g}^{(-j)}$ 会有很大差异，导致各折的误差 $\bar{L}_j$ 波动很大。这种波动性是模型认知不稳定性（epistemic instability）的一个经验信号，反映了由有限数据引起的认知不确定性 。在医学AI等安全攸关领域，这种区分尤为关键。一个预测模型（如[脓毒症](@entry_id:156058)预警系统）的校准度和可靠性是衡量其预测概率是否可信的重要指标。一个理想的模型不仅要有好的区分能力（discrimination, e.g., [AUROC](@entry_id:636693)），还要有好的校准度。在部署时，我们需要监控模型的表现是否因数据漂移（distribution shift）而下降。更重要的是，决策流程的设计应考虑不确定性的来源。当模型表现出高的[偶然不确定性](@entry_id:634772)时，意味着即使是完美的模型也难以对该病例做出确切预测。但当模型表现出高的认知不确定性时，这传递了一个更危险的信号：模型“不知道自己不知道”，它可能正在其未经充分训练的数据区域进行外推。在这种情况下，一个负责任的[临床工作流程](@entry_id:910314)应当将此类病例提交给人类专家进行复核，而不是盲目地相信模型的输出 。

这种区分对于理解和应对科学研究中的“[可复现性危机](@entry_id:163049)”也提供了深刻的见解。我们可以将可复现性问题置于一个统一的不确定性框架中进行分析。例如，一个计算工作流的“[计算可复现性](@entry_id:262414)”——即使用相同的代码和数据能否得到相同的结果——的失败，往往源于分析流程中未被控制的随机性（如随机种子），这可以被视为一种认知不确定性。而“交叉实验室可复现性”——即不同实验室使用各自的方法和新采集的数据能否得出一致的结论——则同时受到[偶然不确定性](@entry_id:634772)（新数据集的随机抽样变异）和认知不确定性（不同实验室选择的不同分析流程 $h$）的影响。通过将总[方差分解](@entry_id:912477)为数据抽样方差、流程随机性方差和流程选择方差，我们可以定量地识别出导致结果不一致的主要来源。[标准化](@entry_id:637219)分析流程可以消除流程选择和流程随机性带来的认知不确定性，但无法消除因重新抽样数据而产生的[偶然不确定性](@entry_id:634772) 。

最终，对不确定性来源的清晰划分直接关系到基于模型进行决策时的伦理责任与问责制。在一个高风险决策场景中，例如设计桥梁的[安全系数](@entry_id:156168)或评估核废料储存库的长期安全性，决策者不仅要考虑预测的不确定性有多大，还要知道这种不确定性的性质。将偶然和认知不确定性混为一谈，用一个单一的方差或[置信区间](@entry_id:142297)来表示总不确定性，会掩盖至关重要的信息。例如，如果总不确定性主要由认知不确定性主导（例如，我们对材料的长期腐蚀模型 $M$ 或其参数 $\theta$ 知之甚少），那么这就意味着通过进一步的研究和数据收集（例如，进行[加速老化](@entry_id:1120669)实验）有可能显著降低风险。在这种情况下，贸然决策而不进行额外研究可能是不负责任的。[信息价值](@entry_id:185629)（Value of Information, VOI）分析等决策理论工具，正是通过量化额外数据对减少认知不确定性并改善决策预期效用的价值，为“是否需要更多研究”这一决策提供理性依据。透明地分解不确定性，明确指出哪些风险是知识上的缺陷（认知的）而非不可避免的自然变异（偶然的），使得责任链条变得清晰：科学家和工程师有责任通过[模型比较](@entry_id:266577)、校准和[实验设计](@entry_id:142447)来减少认知不确定性。这为决策过程提供了可追溯性，是实现伦理问责的基础  。

### 结论

从简单的参数估计到复杂的[地球系统模型](@entry_id:1124096)，从机器学习代理到关乎人类福祉的伦理决策，[偶然不确定性与认知不确定性](@entry_id:1120923)的区分是一个贯穿始终的强大概念工具。它不仅仅是一个学术上的分类，更是一种深刻的思维方式，促使我们审视模型的局限性，明智地分配研究资源，并以一种更加透明和负责任的方式将科学模型应用于解决现实世界的问题。理解“我们知道什么”、“我们不知道什么”以及“什么是本质上不可知的”，是严谨科学实践和审慎工程决策的核心。