{
    "hands_on_practices": [
        {
            "introduction": "The core idea of coarse-graining is to simplify a system's description by grouping its microscopic constituents into larger, effective units. This exercise provides a foundational understanding of this process by applying it to a discrete-state Markov chain . By using only the basic axioms of probability, you will derive the coarse-grained, or \"lumped,\" stationary distribution, making the abstract concept of state-space reduction concrete and intuitive.",
            "id": "3817292",
            "problem": "A discrete-time finite-state Markov chain with state space $X=\\{1,2,3,4,5,6\\}$ has a known stationary distribution $\\pi$, where $\\pi$ is a probability measure on $X$ satisfying the stationarity condition $\\pi P=\\pi$ for some transition matrix $P$ and the normalization $\\sum_{x\\in X}\\pi(x)=1$. Consider the Coarse-Graining (CG) of this chain induced by the partition $\\mathcal{B}=\\{B_{1},B_{2},B_{3}\\}$ given by $B_{1}=\\{1,4\\}$, $B_{2}=\\{2,3\\}$, and $B_{3}=\\{5,6\\}$. Define the coarse-grained chainâ€™s macro-states as the blocks $B_{i}\\in\\mathcal{B}$, and let the coarse-grained stationary distribution $\\tilde{\\pi}$ be the distribution of blocks induced by $\\pi$.\n\nStarting only from the axioms of probability (in particular, finite additivity on disjoint events) and the definition of a stationary distribution as a probability measure on $X$, derive an expression for $\\tilde{\\pi}(B_{i})$ in terms of $\\pi$. Then, for the specific stationary distribution on micro-states\n$$\n\\pi=\\bigg(\\tfrac{1}{8},\\ \\tfrac{1}{6},\\ \\tfrac{5}{24},\\ \\tfrac{1}{12},\\ \\tfrac{1}{4},\\ \\tfrac{1}{6}\\bigg),\n$$\ncompute the coarse-grained stationary distribution $\\tilde{\\pi}$ over the blocks $B_{1},B_{2},B_{3}$ and verify that it is normalized by explicit calculation. Express your final answer as a single row vector using exact rational numbers, with no rounding and no units.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n-   **State Space**: A discrete-time finite-state Markov chain on the state space $X=\\{1,2,3,4,5,6\\}$.\n-   **Stationary Distribution**: A probability measure $\\pi$ on $X$ satisfying $\\pi P=\\pi$ for some transition matrix $P$ and the normalization condition $\\sum_{x\\in X}\\pi(x)=1$.\n-   **Coarse-Graining Partition**: $\\mathcal{B}=\\{B_{1},B_{2},B_{3}\\}$ where $B_{1}=\\{1,4\\}$, $B_{2}=\\{2,3\\}$, and $B_{3}=\\{5,6\\}$.\n-   **Macro-states**: The blocks $B_{i}$ of the partition $\\mathcal{B}$.\n-   **Coarse-Grained Distribution**: $\\tilde{\\pi}$, the distribution over the macro-states induced by $\\pi$.\n-   **Specific Stationary Distribution**: The vector of probabilities for the micro-states is given as $\\pi=\\left(\\frac{1}{8}, \\frac{1}{6}, \\frac{5}{24}, \\frac{1}{12}, \\frac{1}{4}, \\frac{1}{6}\\right)$.\n-   **Task**:\n    1.  Derive a general expression for $\\tilde{\\pi}(B_{i})$ in terms of $\\pi$ using the axioms of probability.\n    2.  Compute the specific coarse-grained distribution $\\tilde{\\pi}$ for the given $\\pi$.\n    3.  Verify that the computed $\\tilde{\\pi}$ is normalized.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientific Grounding**: The problem is based on fundamental concepts of probability theory and the theory of Markov chains, specifically stationary distributions and coarse-graining. These are well-established and core topics in statistical mechanics, mathematics, and multiscale modeling. The problem is scientifically sound.\n-   **Well-Posedness**: The problem is mathematically well-defined. The state space $X$ is partitioned by the sets in $\\mathcal{B}$, as $B_{1} \\cup B_{2} \\cup B_{3} = \\{1,4\\} \\cup \\{2,3\\} \\cup \\{5,6\\} = \\{1,2,3,4,5,6\\} = X$, and the blocks are mutually disjoint ($B_i \\cap B_j = \\emptyset$ for $i \\neq j$). The given micro-state distribution $\\pi$ must be a valid probability distribution; its components must sum to $1$. Let us verify this:\n    $$\n    \\sum_{x \\in X} \\pi(x) = \\frac{1}{8} + \\frac{1}{6} + \\frac{5}{24} + \\frac{1}{12} + \\frac{1}{4} + \\frac{1}{6}\n    $$\n    Using a common denominator of $24$:\n    $$\n    \\frac{3}{24} + \\frac{4}{24} + \\frac{5}{24} + \\frac{2}{24} + \\frac{6}{24} + \\frac{4}{24} = \\frac{3+4+5+2+6+4}{24} = \\frac{24}{24} = 1\n    $$\n    Since the components sum to $1$, the given $\\pi$ is a valid stationary distribution. The problem is self-contained and well-posed.\n-   **Objectivity**: The problem is stated using precise mathematical language and is free from any subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\n\nThe stationary distribution $\\pi$ is a probability measure on the finite sample space $X$. The probability of the system being in a specific micro-state $x \\in X$ is given by $\\pi(x)$. The \"events\" in this probability space are subsets of $X$.\n\nThe coarse-grained distribution $\\tilde{\\pi}$ on the macro-states $\\{B_1, B_2, B_3\\}$ is defined by the probability that the system's micro-state $x$ lies within a given macro-state $B_i$. Formally, for each $i \\in \\{1, 2, 3\\}$, $\\tilde{\\pi}(B_i)$ is the probability of the event $B_i \\subseteq X$.\n\nThe set $B_i$ is a union of its constituent elementary events, which are the singleton sets $\\{x\\}$ for each $x \\in B_i$. That is, $B_i = \\bigcup_{x \\in B_i} \\{x\\}$. The elementary events $\\{x\\}$ and $\\{x'\\}$ for distinct micro-states $x \\neq x'$ are, by definition, disjoint.\n\nAccording to the axioms of probability, specifically the axiom of finite additivity, the probability of a finite union of mutually disjoint events is the sum of their individual probabilities. Applying this axiom to the event $B_i$:\n$$\n\\tilde{\\pi}(B_i) = P(B_i) = P\\left(\\bigcup_{x \\in B_i} \\{x\\}\\right) = \\sum_{x \\in B_i} P(\\{x\\})\n$$\nThe probability measure on the micro-states is $\\pi$, so $P(\\{x\\}) = \\pi(x)$. Substituting this into the equation yields the desired general expression for the coarse-grained probability:\n$$\n\\tilde{\\pi}(B_i) = \\sum_{x \\in B_i} \\pi(x)\n$$\nThis expression demonstrates that the probability of a macro-state is the sum of the probabilities of all micro-states that constitute it.\n\n### Calculation of the Coarse-Grained Distribution\nWe are given the micro-state stationary distribution $\\pi$:\n-   $\\pi(1) = \\frac{1}{8}$\n-   $\\pi(2) = \\frac{1}{6}$\n-   $\\pi(3) = \\frac{5}{24}$\n-   $\\pi(4) = \\frac{1}{12}$\n-   $\\pi(5) = \\frac{1}{4}$\n-   $\\pi(6) = \\frac{1}{6}$\n\nAnd the partition blocks:\n-   $B_1 = \\{1, 4\\}$\n-   $B_2 = \\{2, 3\\}$\n-   $B_3 = \\{5, 6\\}$\n\nUsing the derived formula, we compute the probability for each macro-state:\n\nFor $B_1$:\n$$\n\\tilde{\\pi}(B_1) = \\pi(1) + \\pi(4) = \\frac{1}{8} + \\frac{1}{12} = \\frac{3}{24} + \\frac{2}{24} = \\frac{5}{24}\n$$\n\nFor $B_2$:\n$$\n\\tilde{\\pi}(B_2) = \\pi(2) + \\pi(3) = \\frac{1}{6} + \\frac{5}{24} = \\frac{4}{24} + \\frac{5}{24} = \\frac{9}{24} = \\frac{3}{8}\n$$\n\nFor $B_3$:\n$$\n\\tilde{\\pi}(B_3) = \\pi(5) + \\pi(6) = \\frac{1}{4} + \\frac{1}{6} = \\frac{6}{24} + \\frac{4}{24} = \\frac{10}{24} = \\frac{5}{12}\n$$\n\nThe coarse-grained stationary distribution is the row vector $\\tilde{\\pi} = (\\tilde{\\pi}(B_1), \\tilde{\\pi}(B_2), \\tilde{\\pi}(B_3)) = \\left(\\frac{5}{24}, \\frac{3}{8}, \\frac{5}{12}\\right)$.\n\n### Verification of Normalization\nTo verify that $\\tilde{\\pi}$ is a valid probability distribution, its components must sum to $1$:\n$$\n\\sum_{i=1}^{3} \\tilde{\\pi}(B_i) = \\tilde{\\pi}(B_1) + \\tilde{\\pi}(B_2) + \\tilde{\\pi}(B_3) = \\frac{5}{24} + \\frac{3}{8} + \\frac{5}{12}\n$$\nConverting to a common denominator of $24$:\n$$\n\\frac{5}{24} + \\frac{9}{24} + \\frac{10}{24} = \\frac{5+9+10}{24} = \\frac{24}{24} = 1\n$$\nThe coarse-grained distribution is indeed normalized.\n\nThe final answer is the row vector of these computed probabilities.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{5}{24}  \\frac{3}{8}  \\frac{5}{12} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Moving beyond conceptual definitions, a central task in multiscale modeling is to construct a predictive coarse-grained ($CG$) model from fine-grained data. This practice introduces the force matching method, a powerful and widely used bottom-up technique for parameterizing a $CG$ potential . You will derive the optimal parameters for a given potential by minimizing the discrepancy between the $CG$ forces and the projected forces from an underlying atomistic system, a procedure that amounts to solving a linear least-squares problem.",
            "id": "3817275",
            "problem": "Consider a coarse-grained mapping in multiscale modeling and analysis, where the coarse-grained coordinates are denoted by $X \\in \\mathbb{R}^{d}$ and the atomistic coordinates by $x \\in \\mathbb{R}^{D}$. Let $\\Pi$ be a fixed linear projection operator that maps atomistic forces to coarse-grained forces, so that for any atomistic state $x$, the projected force is $\\Pi F_{\\mathrm{atom}}(x) \\in \\mathbb{R}^{d}$. The coarse-grained force is defined as the negative gradient of a coarse-grained potential, $F_{\\mathrm{CG}}(X) = -\\nabla U_{\\mathrm{CG}}(X)$, where the coarse-grained potential is assumed to be a linear combination of known, continuously differentiable basis functions $\\{\\psi_{k}(X)\\}_{k=1}^{p}$:\n$$\nU_{\\mathrm{CG}}(X; \\theta) = \\sum_{k=1}^{p} \\theta_{k} \\psi_{k}(X),\n$$\nwith parameter vector $\\theta \\in \\mathbb{R}^{p}$.\n\nYou are provided a dataset $\\{(X_{t}, x_{t})\\}_{t=1}^{T}$ of $T$ paired samples of coarse-grained and atomistic configurations, with $T \\geq p$, and you are asked to perform force matching by minimizing the squared discrepancy between the model-predicted coarse-grained forces and the projected atomistic forces. Specifically, define, for each $t$, the $d \\times p$ matrix $B_{t}$ whose $k$-th column is $-\\nabla \\psi_{k}(X_{t})$, and define $y_{t} = \\Pi F_{\\mathrm{atom}}(x_{t}) \\in \\mathbb{R}^{d}$. Consider the objective\n$$\nJ(\\theta) = \\sum_{t=1}^{T} \\left\\| F_{\\mathrm{CG}}(X_{t}; \\theta) - \\Pi F_{\\mathrm{atom}}(x_{t}) \\right\\|^{2} = \\sum_{t=1}^{T} \\left\\| B_{t} \\theta - y_{t} \\right\\|^{2},\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm in $\\mathbb{R}^{d}$.\n\nStarting only from the definitions above and the fact that force is the negative gradient of potential, derive the normal equations that characterize the minimizer of $J(\\theta)$ under the assumption that the matrix $\\sum_{t=1}^{T} B_{t}^{\\top} B_{t}$ is invertible, and provide a closed-form analytic expression for the minimizing parameter vector. Express your final answer as a single analytic expression for the minimizer $\\theta^{\\star}$ in terms of $\\{B_{t}\\}_{t=1}^{T}$ and $\\{y_{t}\\}_{t=1}^{T}$. No numerical evaluation is required. The final answer must be a single analytic expression with no units.",
            "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- Coarse-grained coordinates: $X \\in \\mathbb{R}^{d}$.\n- Atomistic coordinates: $x \\in \\mathbb{R}^{D}$.\n- Linear projection operator: $\\Pi$.\n- Projected atomistic force: $\\Pi F_{\\mathrm{atom}}(x) \\in \\mathbb{R}^{d}$.\n- Coarse-grained force: $F_{\\mathrm{CG}}(X) = -\\nabla U_{\\mathrm{CG}}(X)$.\n- Coarse-grained potential: $U_{\\mathrm{CG}}(X; \\theta) = \\sum_{k=1}^{p} \\theta_{k} \\psi_{k}(X)$, where $\\{\\psi_{k}(X)\\}_{k=1}^{p}$ are known, continuously differentiable basis functions and $\\theta \\in \\mathbb{R}^{p}$ is a parameter vector.\n- Dataset: $\\{(X_{t}, x_{t})\\}_{t=1}^{T}$ of $T$ paired samples.\n- Condition: $T \\geq p$.\n- Matrix $B_{t}$: A $d \\times p$ matrix for each $t$, with its $k$-th column equal to $-\\nabla \\psi_{k}(X_{t})$.\n- Vector $y_{t}$: $y_{t} = \\Pi F_{\\mathrm{atom}}(x_{t}) \\in \\mathbb{R}^{d}$.\n- Objective function: $J(\\theta) = \\sum_{t=1}^{T} \\left\\| F_{\\mathrm{CG}}(X_{t}; \\theta) - \\Pi F_{\\mathrm{atom}}(x_{t}) \\right\\|^{2} = \\sum_{t=1}^{T} \\left\\| B_{t} \\theta - y_{t} \\right\\|^{2}$.\n- Assumption: The matrix $\\sum_{t=1}^{T} B_{t}^{\\top} B_{t}$ is invertible.\n- Task: Derive the normal equations and a closed-form analytic expression for the minimizing parameter vector $\\theta^{\\star}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem describes force matching, a standard and well-established method in multiscale modeling for parameterizing coarse-grained potentials. The formulation as a linear least-squares problem is a canonical approach. All concepts are fundamental to physics, mathematics, and computational science. The problem is scientifically sound.\n2.  **Well-Posed**: The objective function $J(\\theta)$ is a sum of squares, making it a convex quadratic function of $\\theta$. The problem explicitly states that the matrix $\\sum_{t=1}^{T} B_{t}^{\\top} B_{t}$ is invertible, which is the necessary and sufficient condition for the existence of a unique minimizer in this linear least-squares context. The problem is well-posed.\n3.  **Objective**: The problem is stated in precise, formal mathematical language, devoid of ambiguity or subjective claims.\n4.  **Incomplete or Contradictory Setup**: All necessary definitions, variables, and conditions are provided. There are no contradictions. The setup is complete and consistent.\n5.  **Unrealistic or Infeasible**: The setup is a standard theoretical problem in the field. The invertibility of the matrix is a reasonable assumption for a sufficiently rich dataset. No scientifically implausible conditions are present.\n6.  **Ill-Posed or Poorly Structured**: The problem is clearly structured and asks for a standard derivation in optimization and linear algebra.\n7.  **Pseudo-Profound, Trivial, or Tautological**: The problem requires a rigorous, non-trivial mathematical derivation, testing fundamental knowledge of multivariable calculus and linear algebra as applied to statistical fitting. It is not trivial.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically grounded, well-posed, and mathematically coherent. A solution will be derived.\n\nThe objective is to find the parameter vector $\\theta^{\\star}$ that minimizes the objective function $J(\\theta)$. The function $J(\\theta)$ is given by:\n$$\nJ(\\theta) = \\sum_{t=1}^{T} \\left\\| B_{t} \\theta - y_{t} \\right\\|^{2}\n$$\nThe quantity $\\| \\cdot \\|$ denotes the Euclidean norm. The square of the Euclidean norm of a vector $v$ can be expressed as the inner product $v^{\\top}v$. Thus, we can rewrite the objective function as:\n$$\nJ(\\theta) = \\sum_{t=1}^{T} (B_{t} \\theta - y_{t})^{\\top} (B_{t} \\theta - y_{t})\n$$\nWe expand the term inside the summation:\n$$\n(B_{t} \\theta - y_{t})^{\\top} (B_{t} \\theta - y_{t}) = (\\theta^{\\top} B_{t}^{\\top} - y_{t}^{\\top}) (B_{t} \\theta - y_{t}) = \\theta^{\\top} B_{t}^{\\top} B_{t} \\theta - \\theta^{\\top} B_{t}^{\\top} y_t - y_t^{\\top} B_t \\theta + y_t^{\\top} y_t\n$$\nSince $\\theta^{\\top} B_{t}^{\\top} y_t$ is a scalar ($1 \\times p$ times $p \\times d$ times $d \\times 1$ gives $1 \\times 1$), it is equal to its own transpose:\n$$\n(\\theta^{\\top} B_{t}^{\\top} y_t)^{\\top} = y_t^{\\top} (B_t^{\\top})^{\\top} (\\theta^{\\top})^{\\top} = y_t^{\\top} B_t \\theta\n$$\nTherefore, the two middle terms are identical. The expression becomes:\n$$\n\\theta^{\\top} B_t^{\\top} B_t \\theta - 2 y_t^{\\top} B_t \\theta + y_t^{\\top} y_t\n$$\nSubstituting this back into the expression for $J(\\theta)$ and using the linearity of the summation operator:\n$$\nJ(\\theta) = \\sum_{t=1}^{T} (\\theta^{\\top} B_t^{\\top} B_t \\theta - 2 y_t^{\\top} B_t \\theta + y_t^{\\top} y_t)\n$$\n$$\nJ(\\theta) = \\theta^{\\top} \\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right) \\theta - 2 \\left( \\sum_{t=1}^{T} y_t^{\\top} B_t \\right) \\theta + \\sum_{t=1}^{T} y_t^{\\top} y_t\n$$\nThe function $J(\\theta)$ is a quadratic form in $\\theta$. Since the matrix $\\sum_{t=1}^{T} B_t^{\\top} B_t$ is a sum of positive semi-definite matrices ($B_t^{\\top} B_t$) and is given to be invertible, it is positive-definite. Thus, $J(\\theta)$ has a unique global minimum. To find this minimum, we compute the gradient of $J(\\theta)$ with respect to the vector $\\theta$ and set it to the zero vector.\nWe use the standard matrix calculus identities: $\\nabla_{v} (v^{\\top} A v) = (A + A^{\\top})v$ and $\\nabla_{v} (c^{\\top} v) = c$.\nLet $A = \\sum_{t=1}^{T} B_t^{\\top} B_t$. The matrix $A$ is symmetric, since $(B_t^{\\top} B_t)^{\\top} = B_t^{\\top} (B_t^{\\top})^{\\top} = B_t^{\\top} B_t$, and a sum of symmetric matrices is symmetric. Therefore, for symmetric $A$, $\\nabla_{\\theta} (\\theta^{\\top} A \\theta) = 2A\\theta$.\nThe gradient of the linear term is $\\nabla_{\\theta} \\left( -2 \\left( \\sum_{t=1}^{T} y_t^{\\top} B_t \\right) \\theta \\right) = -2 \\left( \\sum_{t=1}^{T} y_t^{\\top} B_t \\right)^{\\top} = -2\\sum_{t=1}^{T} B_t^{\\top} y_t$.\nThe last term, $\\sum_{t=1}^{T} y_t^{\\top} y_t$, is constant with respect to $\\theta$, so its gradient is zero.\nCombining these results, the gradient of $J(\\theta)$ is:\n$$\n\\nabla_{\\theta} J(\\theta) = 2 \\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right) \\theta - 2 \\sum_{t=1}^{T} B_t^{\\top} y_t\n$$\nTo find the minimizing vector $\\theta^{\\star}$, we set the gradient to the zero vector:\n$$\n\\nabla_{\\theta} J(\\theta^{\\star}) = 2 \\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right) \\theta^{\\star} - 2 \\sum_{t=1}^{T} B_t^{\\top} y_t = 0\n$$\nDividing by $2$ and rearranging gives the **normal equations**:\n$$\n\\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right) \\theta^{\\star} = \\sum_{t=1}^{T} B_t^{\\top} y_t\n$$\nThe problem statement assumes that the matrix $\\sum_{t=1}^{T} B_t^{\\top} B_t$ is invertible. We can therefore solve for $\\theta^{\\star}$ by left-multiplying both sides by the inverse of this matrix:\n$$\n\\theta^{\\star} = \\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right)^{-1} \\left( \\sum_{t=1}^{T} B_t^{\\top} y_t \\right)\n$$\nThis is the closed-form analytic expression for the parameter vector that minimizes the sum-of-squares objective function.",
            "answer": "$$\n\\boxed{\\left( \\sum_{t=1}^{T} B_t^{\\top} B_t \\right)^{-1} \\left( \\sum_{t=1}^{T} B_t^{\\top} y_t \\right)}\n$$"
        },
        {
            "introduction": "A coarse-grained model that accurately fits simulation data is not necessarily physically valid; it must also respect the fundamental laws of physics. This final practice focuses on the crucial step of model validation, providing a systematic checklist to assess the physical consistency of a learned model . By implementing checks for momentum conservation, Newton's third law, energetic stability, and the Fluctuation-Dissipation Theorem, you will learn how to diagnose potential failings and ensure the reliability of a coarse-grained model.",
            "id": "3817238",
            "problem": "You are given a learned coarse-grained model intended to approximate the dynamics of a system of $N$ interacting degrees of freedom (beads). The model is linear in the coarse variables and is specified by a coupling matrix $K \\in \\mathbb{R}^{N \\times N}$, a friction matrix $\\Gamma \\in \\mathbb{R}^{N \\times N}$, a discrete-time noise covariance matrix $\\Sigma \\in \\mathbb{R}^{N \\times N}$, a time step $\\Delta t \\in \\mathbb{R}$, and a temperature $T \\in \\mathbb{R}$. All quantities are nondimensional. The model is\n$$ m_i \\dot{v}_i = \\sum_{j=1}^N K_{ij}(x_j - x_i) - \\sum_{j=1}^N \\Gamma_{ij} v_j + \\xi_i(t), $$\nwhere $x_i$ and $v_i$ denote the coarse position and velocity of bead $i$, $m_i$ its mass (set to $1$ for all beads), and $\\xi(t)$ is a zero-mean Gaussian noise with discrete-time covariance $\\Sigma$ over time step $\\Delta t$. The coarse-grained force component due to internal interactions is\n$$ F_i(x) = \\sum_{j=1}^N K_{ij}(x_j - x_i). $$\n\nYour task is to test the internal consistency of the learned coarse-grained model by checking preservation of known invariants and comparing the model against physics-informed constraints to identify violations, using only first-principles reasoning grounded in fundamental laws. Specifically, you must check the following:\n\n1. Known invariant: total momentum preservation by internal forces. In the frictionless, noiseless limit (i.e., ignoring $-\\Gamma v$ and $\\xi$), total momentum conservation requires the net internal force to vanish for any configuration $x$:\n$$ \\sum_{i=1}^N F_i(x) = 0 \\quad \\text{for all } x \\in \\mathbb{R}^N. $$\n2. Physics-informed constraint (Newton's Third Law): pairwise internal forces must be equal and opposite:\n$$ K_{ij} = K_{ji} \\quad \\text{for all } i \\neq j. $$\n3. Physics-informed energetic consistency: the internal force must be conservative and stable. Define the Laplacian-like matrix $L$ associated with $K$ by\n$$ L_{ii} = \\sum_{j=1}^N K_{ij}, \\quad L_{ij} = -K_{ij} \\quad \\text{for } i \\neq j. $$\nEnergetic consistency requires the symmetric part of $L$, given by $L_{\\text{sym}} = \\frac{1}{2}(L + L^\\top)$, to be positive semidefinite, with a translation mode corresponding to a (near) zero eigenvalue. This ensures the existence of a quadratic potential $U(x) = \\tfrac{1}{2} x^\\top L_{\\text{sym}} x$ and stability of internal interactions.\n4. Physics-informed stochastic thermodynamic consistency: the Fluctuation-Dissipation Theorem (FDT) asserts that for linear Langevin dynamics, the noise covariance must satisfy\n$$ \\Sigma = 2 k_B T \\, \\Gamma \\, \\Delta t, $$\nwhere $k_B$ is the Boltzmann constant. In nondimensional units, take $k_B = 1$.\n\nImplement a program that, for each provided test case, returns a list of booleans indicating whether each of the checks (1)-(4) passes, using a uniform numerical tolerance $\\tau = 10^{-8}$ for equality and semidefiniteness checks. Specifically:\n- For total momentum preservation, verify $\\sum_i F_i(x) = 0$ for all $x$ by checking equality of row sums and column sums of $K$ elementwise within tolerance.\n- For Newton's Third Law, verify symmetry of $K$ within tolerance.\n- For energetic consistency, verify that all eigenvalues of $L_{\\text{sym}}$ are greater than or equal to $-\\tau$, and that at least one eigenvalue is in $[-\\tau, \\tau]$ (translation mode).\n- For FDT consistency, verify that $\\Sigma$ equals $2 T \\Gamma \\Delta t$ within tolerance.\n\nAll quantities are nondimensional, so no physical units are required in the output.\n\nTest Suite:\nProvide a program that evaluates the following parameter sets. Each test case is a tuple $(N, K, \\Gamma, \\Sigma, \\Delta t, T)$.\n\n- Case 1 (baseline consistent, frictionless):\n  - $N = 3$\n  - $K = \\begin{bmatrix} 0  1  1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{bmatrix}$\n  - $\\Gamma = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$\n  - $\\Sigma = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$\n  - $\\Delta t = 0.1$\n  - $T = 1.0$\n\n- Case 2 (non-symmetric internal model, frictionless):\n  - $N = 3$\n  - $K = \\begin{bmatrix} 0  1  0.5 \\\\ 0.2  0  1 \\\\ 1.5  0.8  0 \\end{bmatrix}$\n  - $\\Gamma = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$\n  - $\\Sigma = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$\n  - $\\Delta t = 0.1$\n  - $T = 1.0$\n\n- Case 3 (consistent FDT with friction):\n  - $N = 3$\n  - $K = \\begin{bmatrix} 0  1  1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{bmatrix}$\n  - $\\Gamma = \\operatorname{diag}(0.1, 0.2, 0.3)$\n  - $\\Sigma = 2 T \\Gamma \\Delta t$ with $T = 0.5$, $\\Delta t = 0.01$\n  - $\\Delta t = 0.01$\n  - $T = 0.5$\n\n- Case 4 (violated FDT with friction):\n  - $N = 3$\n  - $K = \\begin{bmatrix} 0  1  1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{bmatrix}$\n  - $\\Gamma = \\operatorname{diag}(0.05, 0.05, 0.05)$\n  - $\\Sigma = 1.5 \\times 2 T \\Gamma \\Delta t$ with $T = 1.0$, $\\Delta t = 0.02$\n  - $\\Delta t = 0.02$\n  - $T = 1.0$\n\n- Case 5 (boundary case $N=1$):\n  - $N = 1$\n  - $K = \\begin{bmatrix} 0 \\end{bmatrix}$\n  - $\\Gamma = \\begin{bmatrix} 0 \\end{bmatrix}$\n  - $\\Sigma = \\begin{bmatrix} 0 \\end{bmatrix}$\n  - $\\Delta t = 0.1$\n  - $T = 0.0$\n\nRequired Final Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of four booleans in the order: [momentum_preserved, newton_third_law, energetic_consistency, fdt_consistency]. For example:\n$$ [ [b_1,b_2,b_3,b_4], [b_1,b_2,b_3,b_4], \\dots ] $$",
            "solution": "The problem statement has been critically validated and is deemed to be scientifically grounded, well-posed, and objective. It presents a clear task of validating a coarse-grained model against fundamental physical principles, with all necessary parameters and criteria provided. We may therefore proceed with the solution.\n\nThe core of the task is to implement four distinct checks on a learned coarse-grained linear dynamical model for a system of $N$ beads. These checks verify the model's consistency with principles of momentum conservation, Newton's third law, energetic stability, and thermodynamic consistency. A uniform numerical tolerance of $\\tau = 10^{-8}$ is used for all floating-point comparisons.\n\n**1. Total Momentum Preservation**\n\nThe first check verifies that the internal forces, as defined by the coupling matrix $K$, conserve total system momentum. In a closed system, the net internal force must be zero, as any internal force on one particle must be balanced by a reaction force on another.\n\nThe total internal force on the system is the sum of the forces on each bead:\n$$ F_{\\text{total}}(x) = \\sum_{i=1}^N F_i(x) = \\sum_{i=1}^N \\sum_{j=1}^N K_{ij} (x_j - x_i) $$\nTo ensure this sum is zero for any arbitrary configuration of positions $x \\in \\mathbb{R}^N$, the coefficient of each $x_k$ in the expanded sum must be zero. Let's rewrite the sum by separating terms involving $x_j$ and $x_i$:\n$$ F_{\\text{total}}(x) = \\sum_{i=1}^N \\sum_{j=1}^N K_{ij} x_j - \\sum_{i=1}^N \\sum_{j=1}^N K_{ij} x_i $$\nBy swapping the indices $i$ and $j$ in the first term, we get:\n$$ F_{\\text{total}}(x) = \\sum_{j=1}^N \\sum_{i=1}^N K_{ji} x_i - \\sum_{i=1}^N \\sum_{j=1}^N K_{ij} x_i = \\sum_{i=1}^N \\left( \\sum_{j=1}^N K_{ji} - \\sum_{j=1}^N K_{ij} \\right) x_i $$\nFor this expression to equal zero for all vectors $x$, the coefficient of each $x_i$ must be zero. This yields the condition:\n$$ \\sum_{j=1}^N K_{ij} = \\sum_{j=1}^N K_{ji} \\quad \\text{for each } i = 1, \\dots, N $$\nThis means that for each index $i$, the sum of the elements in the $i$-th row of $K$ must equal the sum of the elements in the $i$-th column of $K$. This condition is computationally verified by calculating the row sums and column sums of the matrix $K$ and checking for their element-wise equality within the tolerance $\\tau$.\n\n**2. Newton's Third Law (Pairwise Force Symmetry)**\n\nNewton's third law states that for every action, there is an equal and opposite reaction. In the context of pairwise interactions between beads $i$ and $j$, the force exerted by $j$ on $i$ must be the negative of the force exerted by $i$ on $j$.\n\nThe force on bead $i$ contains a term $K_{ij}(x_j - x_i)$ that can be interpreted as the force on $i$ due to its interaction with $j$. Similarly, the force on bead $j$ contains a term $K_{ji}(x_i - x_j)$. For these two forces to be equal and opposite, we must have:\n$$ K_{ij}(x_j - x_i) = - K_{ji}(x_i - x_j) = K_{ji}(x_j - x_i) $$\nThis equality must hold for any $x_i \\neq x_j$, which implies:\n$$ K_{ij} = K_{ji} \\quad \\text{for all } i \\neq j $$\nAssuming that diagonal elements $K_{ii}$ are zero (as is typical for spring-like interactions and as seen in the test cases), this condition is equivalent to requiring the entire matrix $K$ to be symmetric, i.e., $K = K^\\top$. This is verified by checking if the absolute difference between $K$ and its transpose $K^\\top$ is negligible for all elements.\n\n**3. Energetic Consistency (Stability)**\n\nThe internal forces should correspond to a physically stable system, meaning the potential energy associated with these forces must be bounded from below. A force $F(x)$ is conservative if it can be written as the negative gradient of a potential energy function $U(x)$, i.e., $F(x) = -\\nabla U(x)$.\n\nThe internal force is $F(x) = -Lx$, where $L$ is the Laplacian-like matrix defined by $L_{ii} = \\sum_{j=1}^N K_{ij}$ and $L_{ij} = -K_{ij}$ for $i \\neq j$. A force is conservative if and only if its Jacobian matrix is symmetric. The Jacobian of $F(x)=-Lx$ is $-L$. Thus, the force is conservative if and only if $L$ is a symmetric matrix.\n\nWhen $L$ is not symmetric, the force is non-conservative. However, we can decompose $L$ into its symmetric and anti-symmetric parts: $L = L_{\\text{sym}} + L_{\\text{asym}}$, where $L_{\\text{sym}} = \\frac{1}{2}(L + L^\\top)$. The conservative part of the force is $F_{\\text{cons}}(x) = -L_{\\text{sym}}x$, which is derivable from the potential $U(x) = \\frac{1}{2} x^\\top L_{\\text{sym}} x$. For the system to be stable, this potential energy must be bounded below, which requires the matrix $L_{\\text{sym}}$ to be positive semidefinite. This means all its eigenvalues must be non-negative.\n\nFurthermore, the potential energy of the system should be invariant to a rigid translation of all bead positions ($x_i \\to x_i + c$ for all $i$). This corresponds to the vector $\\mathbf{1} = (1, 1, \\dots, 1)^\\top$ being in the null space of $L_{\\text{sym}}$, i.e., $L_{\\text{sym}}\\mathbf{1} = 0$. This implies that $L_{\\text{sym}}$ must have an eigenvalue of $0$.\n\nThe check for energetic consistency thus involves two parts:\n1. Verifying that all eigenvalues of $L_{\\text{sym}}$ are non-negative (within tolerance $\\tau$, i.e., $\\lambda \\ge -\\tau$).\n2. Verifying that at least one eigenvalue is zero (within tolerance $\\tau$, i.e., $|\\lambda| \\le \\tau$).\n\n**4. Fluctuation-Dissipation Theorem (FDT)**\n\nThe Fluctuation-Dissipation Theorem (FDT) is a cornerstone of non-equilibrium statistical mechanics. It establishes a fundamental relationship between the dissipation in a system (represented by the friction matrix $\\Gamma$) and the thermal fluctuations (represented by the noise covariance $\\Sigma$). For a system in thermal equilibrium at temperature $T$, the random forces that buffet the particles must precisely balance the energy lost through friction, on average.\n\nFor a linear Langevin system discretized using an Euler-Maruyama scheme with time step $\\Delta t$, this relationship takes the form:\n$$ \\Sigma = 2 k_B T \\Gamma_s \\Delta t $$\nwhere $\\Gamma_s = \\frac{1}{2}(\\Gamma + \\Gamma^\\top)$ is the symmetric part of the friction matrix. However, the problem statement provides a simplified form $\\Sigma = 2 k_B T \\Gamma \\Delta t$, implicitly assuming $\\Gamma$ is symmetric. In our nondimensional units with $k_B = 1$, the condition becomes:\n$$ \\Sigma = 2 T \\Gamma \\Delta t $$\nThis check is implemented by computing the matrix on the right-hand side and comparing it element-wise to the provided $\\Sigma$ matrix within the specified tolerance $\\tau$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Validates a series of coarse-grained models against four physical consistency checks.\n    \"\"\"\n    tau = 1e-8\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (N, K, Gamma, Sigma, dt, T)\n    \n    # Case 1: baseline consistent, frictionless\n    K1 = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n    Gamma1 = np.zeros((3, 3))\n    Sigma1 = np.zeros((3, 3))\n    \n    # Case 2: non-symmetric internal model, frictionless\n    K2 = np.array([[0, 1, 0.5], [0.2, 0, 1], [1.5, 0.8, 0]])\n    Gamma2 = np.zeros((3, 3))\n    Sigma2 = np.zeros((3, 3))\n\n    # Case 3: consistent FDT with friction\n    K3 = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n    Gamma3 = np.diag([0.1, 0.2, 0.3])\n    T3, dt3 = 0.5, 0.01\n    Sigma3 = 2 * T3 * Gamma3 * dt3\n\n    # Case 4: violated FDT with friction\n    K4 = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])\n    Gamma4 = np.diag([0.05, 0.05, 0.05])\n    T4, dt4 = 1.0, 0.02\n    Sigma4 = 1.5 * (2 * T4 * Gamma4 * dt4)\n\n    # Case 5: boundary case N=1\n    K5 = np.array([[0]])\n    Gamma5 = np.array([[0]])\n    Sigma5 = np.array([[0]])\n\n    test_cases = [\n        (3, K1, Gamma1, Sigma1, 0.1, 1.0),\n        (3, K2, Gamma2, Sigma2, 0.1, 1.0),\n        (3, K3, Gamma3, Sigma3, dt3, T3),\n        (3, K4, Gamma4, Sigma4, dt4, T4),\n        (1, K5, Gamma5, Sigma5, 0.1, 0.0)\n    ]\n\n    all_results = []\n    for N, K, Gamma, Sigma, dt, T in test_cases:\n        case_results = []\n\n        # Check 1: Total momentum preservation\n        # sum(row_i of K) == sum(col_i of K) for all i\n        row_sums = K.sum(axis=1)\n        col_sums = K.sum(axis=0)\n        momentum_preserved = np.allclose(row_sums, col_sums, atol=tau, rtol=0)\n        case_results.append(momentum_preserved)\n\n        # Check 2: Newton's Third Law\n        # K is symmetric\n        newton_third_law = np.allclose(K, K.T, atol=tau, rtol=0)\n        case_results.append(newton_third_law)\n\n        # Check 3: Energetic consistency\n        if N > 0:\n            L = -K.copy()\n            np.fill_diagonal(L, K.sum(axis=1))\n            L_sym = 0.5 * (L + L.T)\n            \n            # Use eigvalsh for symmetric matrices\n            eigvals = np.linalg.eigvalsh(L_sym)\n            \n            # All eigenvalues must be >= -tau (positive semidefinite)\n            is_psd = np.all(eigvals >= -tau)\n            # At least one eigenvalue must be near zero for translation mode\n            has_zero_eig = np.any(np.abs(eigvals) = tau)\n            \n            energetic_consistency = is_psd and has_zero_eig\n        else: # N=0 case, vacuously true\n            energetic_consistency = True\n        case_results.append(energetic_consistency)\n\n        # Check 4: FDT consistency\n        # Sigma = 2 * T * Gamma * dt (with k_B = 1)\n        Sigma_fdt = 2 * T * Gamma * dt\n        fdt_consistency = np.allclose(Sigma, Sigma_fdt, atol=tau, rtol=0)\n        case_results.append(fdt_consistency)\n        \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # A space is added after the comma for standard list representation.\n    print(f\"[{', '.join(map(str, all_results))}]\")\n\nsolve()\n```"
        }
    ]
}