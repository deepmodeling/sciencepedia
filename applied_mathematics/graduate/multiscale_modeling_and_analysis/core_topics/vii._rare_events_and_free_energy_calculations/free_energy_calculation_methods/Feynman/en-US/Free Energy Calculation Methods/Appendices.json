{
    "hands_on_practices": [
        {
            "introduction": "Understanding complex free energy methods often begins with simple, solvable models. The harmonic oscillator is a cornerstone of statistical mechanics, and in this exercise, we use it to establish a foundational connection between the definition of free energy and the Free Energy Perturbation (FEP) method. By deriving the free energy difference both analytically from the partition function and through the FEP formalism, you will directly verify the validity of this powerful computational technique. ",
            "id": "3762113",
            "problem": "Consider a classical, one-dimensional ($1$D) coarse-grained degree of freedom $x$ that is modeled at the mesoscale by a harmonic potential $U(x;K) = \\frac{1}{2} K x^{2}$. This setting arises in multiscale modeling when a fine-grained subsystem is represented by an effective harmonic mode whose stiffness depends on the parametrization, leading to state $\\mathrm{A}$ with spring constant $K_{\\mathrm{A}}$ and state $\\mathrm{B}$ with spring constant $K_{\\mathrm{B}}$. Assume a canonical ensemble at temperature $T$, and let $k_{\\mathrm{B}}$ denote the Boltzmann constant. The Helmholtz free energy is defined by $F = - k_{\\mathrm{B}} T \\ln Z$, where $Z$ is the canonical partition function. Because only the potential energy stiffness changes between $\\mathrm{A}$ and $\\mathrm{B}$, and the kinetic energy contribution is identical in both states, focus on the configurational partition function. \n\nStarting from the canonical ensemble and the above definitions:\n- Derive the configurational partition function $Z_{\\text{conf}}(K)$ for the potential $U(x;K) = \\frac{1}{2} K x^{2}$.\n- Use this to derive the Helmholtz free energy difference $\\Delta F = F_{\\mathrm{B}} - F_{\\mathrm{A}}$ as an analytic expression in terms of $K_{\\mathrm{A}}$, $K_{\\mathrm{B}}$, $k_{\\mathrm{B}}$, and $T$.\n- Next, starting from the canonical ensemble definition of averages, derive a Free Energy Perturbation (FEP) estimator for $\\Delta F$ that expresses $\\Delta F$ through an ensemble average over state $\\mathrm{A}$, and evaluate this estimator analytically for the harmonic potential change from $K_{\\mathrm{A}}$ to $K_{\\mathrm{B}}$.\n- Provide the final closed-form expression for $\\Delta F$.\n\nYour final answer must be a single, closed-form analytical expression. Do not provide a numerical approximation. If you introduce the inverse thermal energy, define it as $\\beta = 1/(k_{\\mathrm{B}} T)$, and ensure every mathematical symbol is written in LaTeX.",
            "solution": "The problem statement is validated and found to be scientifically grounded, well-posed, and objective. It presents a standard problem in statistical mechanics, free of any factual unsoundness, ambiguity, or missing information. The premises and definitions are consistent with fundamental principles of classical statistical mechanics and multiscale modeling. We may, therefore, proceed with the solution.\n\nLet the inverse thermal energy be defined as $\\beta = \\frac{1}{k_{\\mathrm{B}} T}$, where $k_{\\mathrm{B}}$ is the Boltzmann constant and $T$ is the temperature. The problem considers a one-dimensional degree of freedom $x$ with a harmonic potential energy function $U(x;K) = \\frac{1}{2} K x^{2}$, where $K$ is the spring constant. We are asked to perform three tasks leading to a final expression for the Helmholtz free energy difference $\\Delta F$ between two states, $\\mathrm{A}$ and $\\mathrm{B}$, characterized by spring constants $K_{\\mathrmA}$ and $K_{\\mathrmB}$, respectively.\n\nFirst, we derive the configurational partition function $Z_{\\text{conf}}(K)$ for a generic spring constant $K$. The configurational partition function for a one-dimensional system is given by the integral of the Boltzmann factor over all possible configurations of the coordinate $x$:\n$$\nZ_{\\text{conf}}(K) = \\int_{-\\infty}^{+\\infty} \\exp(-\\beta U(x;K)) dx\n$$\nSubstituting the given potential energy expression, we have:\n$$\nZ_{\\text{conf}}(K) = \\int_{-\\infty}^{+\\infty} \\exp\\left(-\\beta \\frac{1}{2} K x^{2}\\right) dx\n$$\nThis is a standard Gaussian integral of the form $\\int_{-\\infty}^{+\\infty} \\exp(-ax^{2}) dx = \\sqrt{\\frac{\\pi}{a}}$. In our case, the constant $a$ is $\\frac{\\beta K}{2}$. Therefore, the integral evaluates to:\n$$\nZ_{\\text{conf}}(K) = \\sqrt{\\frac{\\pi}{\\frac{\\beta K}{2}}} = \\sqrt{\\frac{2\\pi}{\\beta K}}\n$$\nThis is the expression for the configurational partition function for a harmonic oscillator with spring constant $K$.\n\nSecond, we use this result to derive the Helmholtz free energy difference $\\Delta F = F_{\\mathrm{B}} - F_{\\mathrm{A}}$. The Helmholtz free energy $F$ is related to the partition function $Z$ by $F = -k_{\\mathrm{B}}T \\ln Z = -\\frac{1}{\\beta} \\ln Z$. Focusing on the configurational contribution, the free energy for a state with spring constant $K$ is:\n$$\nF(K) = -\\frac{1}{\\beta} \\ln(Z_{\\text{conf}}(K))\n$$\nSubstituting our expression for $Z_{\\text{conf}}(K)$:\n$$\nF(K) = -\\frac{1}{\\beta} \\ln\\left(\\sqrt{\\frac{2\\pi}{\\beta K}}\\right) = -\\frac{1}{2\\beta} \\ln\\left(\\frac{2\\pi}{\\beta K}\\right) = \\frac{1}{2\\beta} \\ln\\left(\\frac{\\beta K}{2\\pi}\\right)\n$$\nNow, we can write the free energies for states $\\mathrm{A}$ ($K=K_{\\mathrm{A}}$) and $\\mathrm{B}$ ($K=K_{\\mathrm{B}}$):\n$$\nF_{\\mathrm{A}} = F(K_{\\mathrm{A}}) = \\frac{1}{2\\beta} \\ln\\left(\\frac{\\beta K_{\\mathrm{A}}}{2\\pi}\\right)\n$$\n$$\nF_{\\mathrm{B}} = F(K_{\\mathrm{B}}) = \\frac{1}{2\\beta} \\ln\\left(\\frac{\\beta K_{\\mathrm{B}}}{2\\pi}\\right)\n$$\nThe free energy difference $\\Delta F$ is then:\n$$\n\\Delta F = F_{\\mathrm{B}} - F_{\\mathrm{A}} = \\frac{1}{2\\beta} \\ln\\left(\\frac{\\beta K_{\\mathrm{B}}}{2\\pi}\\right) - \\frac{1}{2\\beta} \\ln\\left(\\frac{\\beta K_{\\mathrm{A}}}{2\\pi}\\right)\n$$\nUsing the property of logarithms, $\\ln(a) - \\ln(b) = \\ln(a/b)$:\n$$\n\\Delta F = \\frac{1}{2\\beta} \\left[ \\ln\\left(\\frac{\\beta K_{\\mathrm{B}}}{2\\pi}\\right) - \\ln\\left(\\frac{\\beta K_{\\mathrm{A}}}{2\\pi}\\right) \\right] = \\frac{1}{2\\beta} \\ln\\left(\\frac{\\frac{\\beta K_{\\mathrm{B}}}{2\\pi}}{\\frac{\\beta K_{\\mathrm{A}}}{2\\pi}}\\right) = \\frac{1}{2\\beta} \\ln\\left(\\frac{K_{\\mathrm{B}}}{K_{\\mathrm{A}}}\\right)\n$$\nSubstituting $\\beta = 1/(k_{\\mathrm{B}} T)$, we arrive at the exact analytical expression for the free energy difference:\n$$\n\\Delta F = \\frac{1}{2} k_{\\mathrm{B}} T \\ln\\left(\\frac{K_{\\mathrm{B}}}{K_{\\mathrm{A}}}\\right)\n$$\n\nThird, we derive the same result using the Free Energy Perturbation (FEP) formalism. The FEP formula expresses the free energy difference as an ensemble average over one of the states (here, state $\\mathrm{A}$):\n$$\n\\Delta F = -\\frac{1}{\\beta} \\ln \\langle \\exp(-\\beta \\Delta U) \\rangle_{\\mathrm{A}}\n$$\nwhere $\\Delta U = U_{\\mathrm{B}}(x) - U_{\\mathrm{A}}(x)$ is the difference in potential energy between the two states, and $\\langle \\dots \\rangle_{\\mathrm{A}}$ denotes a canonical ensemble average taken over the configurations of state $\\mathrm{A}$. The potential energies are $U_{\\mathrm{A}}(x) = \\frac{1}{2} K_{\\mathrm{A}} x^2$ and $U_{\\mathrm{B}}(x) = \\frac{1}{2} K_{\\mathrm{B}} x^2$, so the difference is:\n$$\n\\Delta U(x) = \\frac{1}{2} K_{\\mathrm{B}} x^2 - \\frac{1}{2} K_{\\mathrm{A}} x^2 = \\frac{1}{2}(K_{\\mathrm{B}} - K_{\\mathrm{A}})x^2\n$$\nThe ensemble average is defined as:\n$$\n\\langle \\exp(-\\beta \\Delta U) \\rangle_{\\mathrm{A}} = \\frac{\\int_{-\\infty}^{+\\infty} \\exp(-\\beta \\Delta U(x)) \\exp(-\\beta U_{\\mathrm{A}}(x)) dx}{\\int_{-\\infty}^{+\\infty} \\exp(-\\beta U_{\\mathrm{A}}(x)) dx}\n$$\nThe denominator is simply the partition function of state $\\mathrm{A}$, $Z_{\\text{conf}}(K_{\\mathrm{A}})$. The numerator is:\n$$\n\\int_{-\\infty}^{+\\infty} \\exp\\left(-\\beta \\frac{1}{2}(K_{\\mathrm{B}} - K_{\\mathrm{A}})x^2\\right) \\exp\\left(-\\beta \\frac{1}{2}K_{\\mathrm{A}}x^2\\right) dx = \\int_{-\\infty}^{+\\infty} \\exp\\left(-\\beta \\frac{1}{2}[(K_{\\mathrm{B}} - K_{\\mathrm{A}}) + K_{\\mathrm{A}}] x^2\\right) dx\n$$\nThis simplifies to:\n$$\n\\int_{-\\infty}^{+\\infty} \\exp\\left(-\\beta \\frac{1}{2} K_{\\mathrm{B}} x^2\\right) dx = Z_{\\text{conf}}(K_{\\mathrm{B}})\n$$\nThus, the ensemble average is the ratio of the partition functions:\n$$\n\\langle \\exp(-\\beta \\Delta U) \\rangle_{\\mathrm{A}} = \\frac{Z_{\\text{conf}}(K_{\\mathrm{B}})}{Z_{\\text{conf}}(K_{\\mathrm{A}})}\n$$\nUsing our previously derived expression for $Z_{\\text{conf}}(K)$:\n$$\n\\langle \\exp(-\\beta \\Delta U) \\rangle_{\\mathrm{A}} = \\frac{\\sqrt{\\frac{2\\pi}{\\beta K_{\\mathrm{B}}}}}{\\sqrt{\\frac{2\\pi}{\\beta K_{\\mathrm{A}}}}} = \\sqrt{\\frac{K_{\\mathrm{A}}}{K_{\\mathrm{B}}}} = \\left(\\frac{K_{\\mathrm{A}}}{K_{\\mathrm{B}}}\\right)^{1/2}\n$$\nFinally, we substitute this result back into the FEP formula for $\\Delta F$:\n$$\n\\Delta F = -\\frac{1}{\\beta} \\ln\\left[ \\left(\\frac{K_{\\mathrm{A}}}{K_{\\mathrm{B}}}\\right)^{1/2} \\right] = -\\frac{1}{2\\beta} \\ln\\left(\\frac{K_{\\mathrm{A}}}{K_{\\mathrm{B}}}\\right) = \\frac{1}{2\\beta} \\ln\\left(\\left(\\frac{K_{\\mathrm{A}}}{K_{\\mathrm{B}}}\\right)^{-1}\\right) = \\frac{1}{2\\beta} \\ln\\left(\\frac{K_{\\mathrm{B}}}{K_{\\mathrm{A}}}\\right)\n$$\nSubstituting $\\beta = 1/(k_{\\mathrm{B}} T)$ again gives:\n$$\n\\Delta F = \\frac{1}{2} k_{\\mathrm{B}} T \\ln\\left(\\frac{K_{\\mathrm{B}}}{K_{\\mathrm{A}}}\\right)\n$$\nBoth methods yield the same analytical result, confirming the consistency of the statistical mechanical framework. This is the required final closed-form expression.",
            "answer": "$$\n\\boxed{\\frac{1}{2} k_{\\mathrm{B}} T \\ln\\left(\\frac{K_{\\mathrm{B}}}{K_{\\mathrm{A}}}\\right)}\n$$"
        },
        {
            "introduction": "Free energy landscapes, or Potentials of Mean Force (PMF), describe the effective energy of a system as it moves along a chosen reaction coordinate. This exercise explores a counter-intuitive yet fundamental concept: the emergence of an effective interaction between particles that have no energetic interaction at all. By calculating the PMF between two noninteracting particles, you will uncover how entropy and the geometry of configuration space alone can create a free energy profile, a crucial insight for understanding processes like molecular binding. ",
            "id": "3762101",
            "problem": "Consider two identical, noninteracting point particles in three spatial dimensions confined in a very large cubic box of volume $V$ with periodic boundaries, in the canonical ensemble at temperature $T$. Let the pair separation $r$ be the reaction coordinate, defined by $r = \\| \\mathbf{r}_{2} - \\mathbf{r}_{1} \\|$. The potential of mean force (PMF) $W(r)$ is the reversible Helmholtz free energy associated with constraining the system to a fixed value of the reaction coordinate $r$. Adopt the reference convention $W(r_{0}) = 0$ for a fixed $r_{0} > 0$.\n\nStarting from first principles of equilibrium statistical mechanics and the canonical configurational measure, derive the analytic expression for $W(r)$ for this ideal-gas system. In your derivation, use a change of variables to center-of-mass and relative coordinates, and explain the geometric origin of any measure factors that arise upon marginalizing to the scalar separation $r$. In particular, justify from the integration measure why a term of the form $-k_{B} T \\ln(4 \\pi r^{2})$ appears in $W(r)$ up to an additive constant.\n\nExpress your final answer as a single closed-form analytic expression for $W(r)$ in terms of $k_{B}$, $T$, $r$, and $r_{0}$. Do not substitute numerical values. Do not include units in your final expression. No rounding is required.",
            "solution": "The problem statement is critically validated and is deemed to be self-contained, scientifically grounded, and well-posed. The system describes an ideal gas, a fundamental model in statistical mechanics, and the task is a standard derivation of a potential of mean force (PMF). All necessary information is provided, and no contradictions or ambiguities are present.\n\nThe potential of mean force, $W(r)$, along a reaction coordinate $r$, is the Helmholtz free energy of the system constrained to a specific value of that coordinate. It is related to the equilibrium probability density function, $\\pi(r)$, of the reaction coordinate by the expression:\n$$\nW(r) = -k_{B} T \\ln \\pi(r) + C\n$$\nwhere $k_{B}$ is the Boltzmann constant, $T$ is the absolute temperature, and $C$ is a constant. The reference condition $W(r_{0}) = 0$ for a given $r_{0} > 0$ allows for the determination of this constant. Specifically, we can write the PMF relative to its value at $r_{0}$:\n$$\nW(r) = W(r) - W(r_{0}) = -k_{B} T \\ln \\left( \\frac{\\pi(r)}{\\pi(r_{0})} \\right)\n$$\nThis formulation has the advantage that any normalization constants in the probability density will cancel.\n\nThe probability density $\\pi(r)$ is proportional to the volume of configuration space compatible with the constraint that the particle separation $\\|\\mathbf{r}_{2} - \\mathbf{r}_{1}\\|$ is equal to $r$. For a system with a potential energy function $U(\\mathbf{r}_{1}, \\mathbf{r}_{2})$, the unnormalized probability density is given by the integral over all particle coordinates, weighted by the Boltzmann factor and a Dirac delta function imposing the constraint:\n$$\n\\pi(r) \\propto \\int_{V} d\\mathbf{r}_{1} \\int_{V} d\\mathbf{r}_{2} \\, \\exp\\left(-\\frac{U(\\mathbf{r}_{1}, \\mathbf{r}_{2})}{k_{B}T}\\right) \\delta(r - \\|\\mathbf{r}_{2} - \\mathbf{r}_{1}\\|)\n$$\nFor the specified system of two noninteracting particles, the potential energy $U(\\mathbf{r}_{1}, \\mathbf{r}_{2}) = 0$. The expression for the unnormalized density simplifies to:\n$$\n\\pi(r) \\propto \\int_{V} d\\mathbf{r}_{1} \\int_{V} d\\mathbf{r}_{2} \\, \\delta(r - \\|\\mathbf{r}_{2} - \\mathbf{r}_{1}\\|)\n$$\nThe problem specifies that the particles are identical. However, since the reaction coordinate $r = \\|\\mathbf{r}_{2} - \\mathbf{r}_{1}\\|$ is symmetric with respect to particle exchange, the factor of $1/2!$ that would appear in the canonical partition function for identical particles will cancel when computing the expectation value that defines $\\pi(r)$. We can therefore proceed as if the particles were distinguishable.\n\nTo evaluate the integral, we perform a change of variables from the particle coordinates $(\\mathbf{r}_{1}, \\mathbf{r}_{2})$ to the center-of-mass coordinate $\\mathbf{R}$ and the relative coordinate $\\mathbf{r}$:\n$$\n\\mathbf{R} = \\frac{\\mathbf{r}_{1} + \\mathbf{r}_{2}}{2} \\quad , \\quad \\mathbf{r} = \\mathbf{r}_{2} - \\mathbf{r}_{1}\n$$\nThe Jacobian determinant of this transformation is unity:\n$$\n\\left| \\det \\frac{\\partial(\\mathbf{r}_{1}, \\mathbf{r}_{2})}{\\partial(\\mathbf{R}, \\mathbf{r})} \\right| = \\left| \\det \\begin{pmatrix} \\mathbf{I} & -\\frac{1}{2}\\mathbf{I} \\\\ \\mathbf{I} & \\frac{1}{2}\\mathbf{I} \\end{pmatrix} \\right| = 1\n$$\nwhere $\\mathbf{I}$ is the $3 \\times 3$ identity matrix. Thus, the volume element transforms as $d\\mathbf{r}_{1} d\\mathbf{r}_{2} = d\\mathbf{R} d\\mathbf{r}$. The reaction coordinate is now simply the magnitude of the relative vector, $r = \\|\\mathbf{r}\\|$. The integral becomes:\n$$\n\\pi(r) \\propto \\int d\\mathbf{R} \\int d\\mathbf{r} \\, \\delta(r - \\|\\mathbf{r}\\|)\n$$\nThe integration domain is coupled, as the constraint that both $\\mathbf{r}_{1}$ and $\\mathbf{r}_{2}$ are in the box $V$ imposes a complicated boundary on the $(\\mathbf{R}, \\mathbf{r})$ space. However, the problem specifies a \"very large\" cubic box, which implies we are in the thermodynamic limit. For values of $r$ much smaller than the box dimensions, the integration over the center-of-mass coordinate $\\mathbf{R}$ can be decoupled and simply yields the total volume $V$.\n$$\n\\pi(r) \\propto V \\int d\\mathbf{r} \\, \\delta(r - \\|\\mathbf{r}\\|)\n$$\nThe remaining integral is over the $3$-dimensional space of the relative vector $\\mathbf{r}$. To evaluate it, we express $\\mathbf{r}$ in spherical coordinates $(r', \\theta, \\phi)$, where $r' = \\|\\mathbf{r}\\|$. The volume element is $d\\mathbf{r} = r'^{2}\\sin\\theta \\, dr' \\, d\\theta \\, d\\phi$. The integral becomes:\n$$\n\\int d\\mathbf{r} \\, \\delta(r - \\|\\mathbf{r}\\|) = \\int_{0}^{2\\pi} d\\phi \\int_{0}^{\\pi} d\\theta \\int_{0}^{\\infty} dr' \\, r'^{2}\\sin\\theta \\, \\delta(r - r')\n$$\nThe Dirac delta function collapses the integral over $r'$, picking out the value $r' = r$:\n$$\n= r^{2} \\int_{0}^{2\\pi} d\\phi \\int_{0}^{\\pi} d\\theta \\, \\sin\\theta = r^{2} (2\\pi) [-\\cos\\theta]_{0}^{\\pi} = r^{2} (2\\pi)(2) = 4\\pi r^{2}\n$$\nThis result, $4\\pi r^{2}$, is the surface area of a sphere of radius $r$.\n\nThe geometric origin of this factor lies in the marginalization of the uniform probability density over the phase space of the relative coordinate vector $\\mathbf{r}$. Since the particles are noninteracting, every configuration $(\\mathbf{r}_{1}, \\mathbf{r}_{2})$ is equally probable. Consequently, after changing variables, every configuration of the relative vector $\\mathbf{r}$ is also equally probable (in the large-volume limit). To find the probability density for a specific *magnitude* $r = \\|\\mathbf{r}\\|$, we must integrate over all possible orientations (the angular degrees of freedom) of the vector $\\mathbf{r}$ that share this magnitude. These orientations trace out a spherical surface of area $4\\pi r^{2}$. The volume of available configuration space is thus proportional to this surface area. This is a purely entropic effect: a larger separation $r$ corresponds to a larger spherical shell of possible relative vector configurations, representing a higher entropy.\n\nThe unnormalized probability density is therefore proportional to this geometric factor:\n$$\n\\pi(r) \\propto 4\\pi r^{2}\n$$\nThe PMF, up to an additive constant, is then given by:\n$$\nW(r) = -k_{B} T \\ln(\\text{const} \\cdot 4\\pi r^{2}) = -k_{B} T \\ln(4\\pi r^{2}) + C'\n$$\nThis expression contains the term $-k_{B} T \\ln(4 \\pi r^{2})$ whose origin was to be justified. It arises from the volume (surface area) of the manifold of states in the relative coordinate space corresponding to a fixed scalar separation $r$.\n\nNow, we use the reference condition $W(r_{0}) = 0$ to find the final expression for $W(r)$:\n$$\nW(r) = -k_{B} T \\ln \\left( \\frac{\\pi(r)}{\\pi(r_{0})} \\right)\n$$\nSubstituting $\\pi(r) \\propto 4\\pi r^{2}$:\n$$\nW(r) = -k_{B} T \\ln \\left( \\frac{4\\pi r^{2}}{4\\pi r_{0}^{2}} \\right) = -k_{B} T \\ln \\left( \\frac{r^{2}}{r_{0}^{2}} \\right)\n$$\nUsing the properties of the logarithm, this simplifies to:\n$$\nW(r) = -2 k_{B} T \\ln \\left( \\frac{r}{r_{0}} \\right)\n$$\nThis is the final analytical expression for the potential of mean force for two noninteracting particles in a large volume. The PMF is purely entropic, decreasing logarithmically as the separation $r$ increases, reflecting the larger volume of configuration space accessible at greater separations.",
            "answer": "$$\n\\boxed{-2 k_{B} T \\ln\\left(\\frac{r}{r_{0}}\\right)}\n$$"
        },
        {
            "introduction": "A calculated free energy value is only as good as its uncertainty estimate. In practice, data from molecular simulations are not a series of independent measurements, but are temporally correlated, a fact that significantly impacts statistical error. This exercise addresses this critical issue by deriving the concept of statistical inefficiency, which quantifies how correlations inflate the variance of an observable's mean. Mastering this allows you to determine the true number of effective samples in your data and, consequently, to compute reliable confidence intervals for your free energy estimates. ",
            "id": "3762077",
            "problem": "Consider a single thermodynamic state in a molecular simulation whose time series observable $x_i$ (such as a reduced work or energy contributing to a free energy estimator like the Multistate Bennett Acceptance Ratio (MBAR)) is sampled at discrete times $t_i = i \\Delta t$ for $i = 1, 2, \\dots, N$. Assume $x_i$ is a weakly stationary stochastic process with mean $\\mu = \\langle x_i \\rangle$, variance $\\sigma^2 = \\langle (x_i - \\mu)^2 \\rangle$, and normalized autocorrelation function $\\rho(t)$ defined by $\\rho(t) = \\langle (x_i - \\mu)(x_{i+t} - \\mu) \\rangle / \\sigma^2$ for integer lags $t \\geq 0$. Starting from the definitions of covariance and the variance of the sample mean as $\\operatorname{Var}(\\bar{x}) = \\operatorname{Var} \\left( \\frac{1}{N} \\sum_{i=1}^{N} x_i \\right)$, derive the statistical inefficiency $g$ as a function of the normalized autocorrelation $\\rho(t)$ and explain how it rescales the variance of the sample mean for correlated data. Using this $g$, define the effective sample size $N_{\\mathrm{eff}}$ appropriate for the asymptotic uncertainty scaling of free energy estimators that depend on averages of correlated samples.\n\nNow specialize to the case in which the normalized autocorrelation decays exponentially with lag, $\\rho(t) = \\exp\\left(- t \\Delta t / \\tau_c \\right)$ for integer $t \\geq 1$, where $\\Delta t$ is the sampling interval and $\\tau_c$ is the correlation time. Consider a simulation that produced $N = 2.50 \\times 10^5$ samples at $\\Delta t = 2\\,\\mathrm{fs}$ with a correlation time $\\tau_c = 50\\,\\mathrm{fs}$. Using your derived $g$, compute the effective sample size $N_{\\mathrm{eff}}$ for this dataset.\n\nRound your final numerical answer to four significant figures. Express the final answer as a pure number with no units.",
            "solution": "The problem asks for the derivation of the statistical inefficiency $g$, its role in scaling the variance of the sample mean, the definition of the effective sample size $N_{\\mathrm{eff}}$, and the calculation of $N_{\\mathrm{eff}}$ for a specific case of exponentially decaying autocorrelation.\n\nThe starting point is the definition of the variance of the sample mean, $\\bar{x} = \\frac{1}{N} \\sum_{i=1}^{N} x_i$.\n$$\n\\operatorname{Var}(\\bar{x}) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} x_i\\right)\n$$\nUsing the property of variance, $\\operatorname{Var}(cY) = c^2 \\operatorname{Var}(Y)$ for a constant $c$, we have:\n$$\n\\operatorname{Var}(\\bar{x}) = \\frac{1}{N^2} \\operatorname{Var}\\left(\\sum_{i=1}^{N} x_i\\right)\n$$\nThe variance of a sum of random variables is the sum of all elements in their covariance matrix: $\\operatorname{Var}\\left(\\sum_i Y_i\\right) = \\sum_i \\sum_j \\operatorname{Cov}(Y_i, Y_j)$. Applying this gives:\n$$\n\\operatorname{Var}(\\bar{x}) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\operatorname{Cov}(x_i, x_j)\n$$\nFor a weakly stationary process, the covariance $\\operatorname{Cov}(x_i, x_j) = \\langle (x_i - \\mu)(x_j - \\mu) \\rangle$ depends only on the time lag $t = |i-j|$ between the samples. It can be expressed in terms of the variance $\\sigma^2$ and the normalized autocorrelation function $\\rho(t)$ as:\n$$\n\\operatorname{Cov}(x_i, x_j) = \\sigma^2 \\rho(|i-j|)\n$$\nSubstituting this into the expression for $\\operatorname{Var}(\\bar{x})$:\n$$\n\\operatorname{Var}(\\bar{x}) = \\frac{\\sigma^2}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\rho(|i-j|)\n$$\nThe double summation can be evaluated by grouping terms with the same lag $t = |i-j|$. The lag $t$ ranges from $0$ to $N-1$. For a given lag $t > 0$, there are $2(N-t)$ pairs of indices $(i, j)$ in the sum for which $|i-j|=t$. For the lag $t=0$, there are $N$ pairs where $i=j$. The sum can thus be rewritten as:\n$$\n\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\rho(|i-j|) = N\\rho(0) + \\sum_{t=1}^{N-1} 2(N-t)\\rho(t)\n$$\nBy definition, $\\rho(0)=1$. Therefore:\n$$\n\\sum_{i=1}^{N} \\sum_{j=1}^{N} \\rho(|i-j|) = N + 2 \\sum_{t=1}^{N-1} (N-t)\\rho(t)\n$$\nSubstituting this back into the equation for the variance of the mean:\n$$\n\\operatorname{Var}(\\bar{x}) = \\frac{\\sigma^2}{N^2} \\left[ N + 2 \\sum_{t=1}^{N-1} (N-t)\\rho(t) \\right] = \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{t=1}^{N-1} \\left(1-\\frac{t}{N}\\right)\\rho(t) \\right]\n$$\nThis is an exact expression for a finite number of samples $N$. In the asymptotic limit, where the number of samples $N$ is much larger than the correlation time of the process (i.e., $\\rho(t) \\approx 0$ for $t$ much smaller than $N$), we can make two approximations. First, for lags $t$ where $\\rho(t)$ is non-negligible, $t/N \\ll 1$, so the term $(1-t/N) \\approx 1$. Second, since $\\rho(t)$ decays to zero, the upper limit of summation can be extended from $N-1$ to $\\infty$. This yields the asymptotic formula:\n$$\n\\operatorname{Var}(\\bar{x}) \\approx \\frac{\\sigma^2}{N} \\left[ 1 + 2 \\sum_{t=1}^{\\infty} \\rho(t) \\right]\n$$\nThe statistical inefficiency, $g$, is the factor by which the variance of the sample mean of correlated data is larger than that of uncorrelated (independent) data. For $N$ independent samples, the variance of the mean is $\\sigma^2/N$. We define $g$ such that for correlated data:\n$$\n\\operatorname{Var}(\\bar{x}) = g \\frac{\\sigma^2}{N}\n$$\nBy comparing this definition with the derived asymptotic expression, we identify the statistical inefficiency as:\n$$\ng = 1 + 2 \\sum_{t=1}^{\\infty} \\rho(t)\n$$\nThis expression demonstrates how $g$ rescales the variance. For uncorrelated data, $\\rho(t)=0$ for $t \\ge 1$, so $g=1$. For data with positive correlations, $\\rho(t)>0$, the sum is positive, and thus $g>1$, indicating an increased variance (i.e., higher statistical uncertainty) in the estimated mean.\n\nThe effective sample size, $N_{\\mathrm{eff}}$, is defined as the number of independent samples that would give the same variance in the mean as the $N$ correlated samples. The variance for $N_{\\mathrm{eff}}$ independent samples is $\\sigma^2/N_{\\mathrm{eff}}$. Equating this to the variance for the correlated samples:\n$$\n\\frac{\\sigma^2}{N_{\\mathrm{eff}}} = g \\frac{\\sigma^2}{N}\n$$\nSolving for $N_{\\mathrm{eff}}$ yields:\n$$\nN_{\\mathrm{eff}} = \\frac{N}{g}\n$$\n\nNow, we specialize to the case where the autocorrelation is exponential: $\\rho(t) = \\exp(- t \\Delta t / \\tau_c)$ for $t \\ge 1$. We compute $g$ using this model:\n$$\ng = 1 + 2 \\sum_{t=1}^{\\infty} \\exp\\left(-\\frac{t \\Delta t}{\\tau_c}\\right)\n$$\nThe summation is a geometric series with first term and ratio both equal to $r = \\exp(-\\Delta t / \\tau_c)$. The sum of this series is $\\sum_{t=1}^{\\infty} r^t = \\frac{r}{1-r}$.\nSubstituting this into the expression for $g$:\n$$\ng = 1 + 2 \\frac{r}{1-r} = \\frac{(1-r) + 2r}{1-r} = \\frac{1+r}{1-r}\n$$\nSubstituting $r = \\exp(-\\Delta t / \\tau_c)$ back gives the formula for $g$:\n$$\ng = \\frac{1 + \\exp(-\\Delta t / \\tau_c)}{1 - \\exp(-\\Delta t / \\tau_c)}\n$$\nWe are given the following values: $N = 2.50 \\times 10^5$, $\\Delta t = 2\\,\\mathrm{fs}$, and $\\tau_c = 50\\,\\mathrm{fs}$. First, we compute the ratio in the exponent:\n$$\n\\frac{\\Delta t}{\\tau_c} = \\frac{2\\,\\mathrm{fs}}{50\\,\\mathrm{fs}} = 0.04\n$$\nNow, we can calculate the numerical value of $g$:\n$$\ng = \\frac{1 + \\exp(-0.04)}{1 - \\exp(-0.04)} \\approx \\frac{1 + 0.96078944}{1 - 0.96078944} = \\frac{1.96078944}{0.03921056} \\approx 50.006665\n$$\nFinally, we compute the effective sample size $N_{\\mathrm{eff}}$:\n$$\nN_{\\mathrm{eff}} = \\frac{N}{g} = \\frac{2.50 \\times 10^5}{50.006665} \\approx 4999.3335\n$$\nRounding the result to four significant figures as requested gives $4999$.",
            "answer": "$$\\boxed{4999}$$"
        }
    ]
}