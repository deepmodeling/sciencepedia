{
    "hands_on_practices": [
        {
            "introduction": "A successful umbrella sampling study begins with a thoughtful simulation design. This exercise guides you through the process of selecting the two most critical parameters: the harmonic force constant, $k$, and the spacing between adjacent window centers, $\\Delta\\xi$. By working through this problem, you will learn how to tailor your simulation setup to the intrinsic properties of your system, such as the local curvature of the free energy surface, to ensure both efficient sampling within each window and sufficient overlap between them for robust analysis.",
            "id": "3827385",
            "problem": "In one-dimensional Umbrella Sampling (US) of a reaction coordinate $\\xi$, a harmonic bias $U_{b}(\\xi;\\xi_{0})=\\frac{1}{2}\\,k\\,(\\xi-\\xi_{0})^{2}$ is applied around a window center $\\xi_{0}$ to facilitate sampling of the Potential of Mean Force (PMF). Assume a canonical ensemble at temperature $T$ and that the unbiased PMF near $\\xi_{0}$ is locally quadratic: $F(\\xi)\\approx F(\\xi_{0})+\\frac{1}{2}\\,\\kappa\\,(\\xi-\\xi_{0})^{2}$, where $\\kappa$ is the local curvature (second derivative) of the PMF with respect to $\\xi$. Neglect higher-than-quadratic terms and any spatial variation of $\\kappa$ across the window. Treat $\\xi$ as a one-dimensional Cartesian-like coordinate with units of nanometers. \n\nYou are tasked with designing the harmonic bias to achieve a prescribed within-window sampling width (standard deviation) $\\sigma$ for $\\xi$. Specifically:\n- Choose the force constant $k$ so that the steady-state distribution of $\\xi$ under the biased potential has standard deviation $\\sigma$ around $\\xi_{0}$.\n- To ensure adequate inter-window overlap, select the spacing $\\Delta \\xi$ between neighboring window centers so that the ratio of the biased probability density at the neighbor’s center, $\\xi=\\xi_{0}+\\Delta\\xi$, to that at the current center, $\\xi=\\xi_{0}$, equals a prescribed threshold $r^{\\ast}$.\n\nUse the following data:\n- Temperature $T=300\\,\\mathrm{K}$,\n- Target width $\\sigma=0.10\\,\\mathrm{nm}$,\n- Local PMF curvature $\\kappa=100\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$,\n- Overlap threshold $r^{\\ast}=0.30$.\n\nWork in molar energetic units. Use the gas constant $R=8.314462618\\,\\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$, and convert as needed to $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$. Express the final $k$ in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$ and $\\Delta\\xi$ in $\\mathrm{nm}$. Round your final answers to three significant figures. Provide your final answers as a pair $\\big(k,\\Delta\\xi\\big)$.",
            "solution": "The problem as stated is scientifically sound, well-posed, and contains all necessary information for a unique solution. It describes a standard procedure in computational statistical mechanics for designing Umbrella Sampling simulations. Therefore, we may proceed with the solution.\n\nThe objective is to determine the harmonic bias force constant $k$ and the spacing between adjacent umbrella windows $\\Delta\\xi$.\n\nFirst, we determine the force constant $k$. The total Potential of Mean Force (PMF) experienced by the system within a given sampling window is the sum of the intrinsic, unbiased PMF, $F(\\xi)$, and the applied harmonic bias potential, $U_b(\\xi;\\xi_0)$. The problem provides the following local quadratic forms:\n$$F(\\xi) \\approx F(\\xi_{0}) + \\frac{1}{2}\\,\\kappa\\,(\\xi-\\xi_{0})^{2}$$\n$$U_{b}(\\xi;\\xi_{0}) = \\frac{1}{2}\\,k\\,(\\xi-\\xi_{0})^{2}$$\nThe biased PMF, $F_b(\\xi)$, is their sum:\n$$F_b(\\xi) = F(\\xi) + U_b(\\xi;\\xi_{0}) \\approx \\left( F(\\xi_{0}) + \\frac{1}{2}\\,\\kappa\\,(\\xi-\\xi_{0})^{2} \\right) + \\frac{1}{2}\\,k\\,(\\xi-\\xi_{0})^{2}$$\n$$F_b(\\xi) \\approx F(\\xi_{0}) + \\frac{1}{2}\\,(\\kappa+k)\\,(\\xi-\\xi_{0})^{2}$$\nThis shows that under the local quadratic approximation, the biased system also has a quadratic PMF centered at $\\xi_0$, with an effective spring constant $k_{\\text{eff}} = \\kappa+k$.\n\nIn a canonical ensemble at temperature $T$, the probability distribution of the coordinate $\\xi$ is given by the Boltzmann factor of the PMF. For the biased ensemble, this is:\n$$P_b(\\xi) \\propto \\exp\\left(-\\frac{F_b(\\xi)}{RT}\\right)$$\nwhere $R$ is the molar gas constant. Substituting the expression for $F_b(\\xi)$:\n$$P_b(\\xi) \\propto \\exp\\left(-\\frac{F(\\xi_{0}) + \\frac{1}{2}\\,(\\kappa+k)\\,(\\xi-\\xi_{0})^{2}}{RT}\\right)$$\nThe term $\\exp(-F(\\xi_0)/(RT))$ is a constant and can be absorbed into the normalization constant. Thus, the shape of the distribution is determined by:\n$$P_b(\\xi) \\propto \\exp\\left(-\\frac{(\\kappa+k)(\\xi-\\xi_{0})^{2}}{2RT}\\right)$$\nThis is the functional form of a Gaussian (Normal) distribution, $P(x) \\propto \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma_{\\text{dist}}^2}\\right)$, with mean $\\mu=\\xi_0$ and variance $\\sigma_{\\text{dist}}^2$. By comparing the exponents, we can identify the variance of the biased distribution:\n$$\\frac{1}{2\\sigma_{\\text{dist}}^2} = \\frac{\\kappa+k}{2RT}$$\nThis gives the variance:\n$$\\sigma_{\\text{dist}}^2 = \\frac{RT}{\\kappa+k}$$\nThe problem requires that the standard deviation of this distribution, $\\sigma_{\\text{dist}}$, be equal to the specified target width $\\sigma$. Therefore, $\\sigma_{\\text{dist}}^2 = \\sigma^2$.\n$$\\sigma^2 = \\frac{RT}{\\kappa+k}$$\nWe solve this equation for the unknown bias force constant, $k$:\n$$\\kappa+k = \\frac{RT}{\\sigma^2}$$\n$$k = \\frac{RT}{\\sigma^2} - \\kappa$$\nWe are given the following values: $T=300\\,\\mathrm{K}$, $\\sigma=0.10\\,\\mathrm{nm}$, $\\kappa=100\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$, and $R=8.314462618\\,\\mathrm{J}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$. We first convert $R$ to the required energetic units: $R = 0.008314462618\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$.\nThe thermal energy is:\n$$RT = (0.008314462618\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}) \\times (300\\,\\mathrm{K}) \\approx 2.49434\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$$\nNow, we can calculate $k$:\n$$k = \\frac{2.49434\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}}{(0.10\\,\\mathrm{nm})^2} - 100\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$$\n$$k = \\frac{2.49434\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}}{0.010\\,\\mathrm{nm}^2} - 100\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$$\n$$k = 249.434\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2} - 100\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2} = 149.434\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$$\nRounding to three significant figures, we get $k = 149\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}$.\n\nNext, we determine the window spacing $\\Delta\\xi$. This spacing is set by the condition that the ratio of the biased probability density at a neighbor's center, $\\xi=\\xi_{0}+\\Delta\\xi$, to the density at the current window's center, $\\xi=\\xi_{0}$, equals the threshold $r^{\\ast}$.\n$$\\frac{P_b(\\xi_0 + \\Delta\\xi)}{P_b(\\xi_0)} = r^{\\ast}$$\nUsing our expression for $P_b(\\xi)$:\n$$P_b(\\xi_0) \\propto \\exp\\left(-\\frac{(\\kappa+k)(\\xi_0-\\xi_0)^2}{2RT}\\right) = \\exp(0) = 1$$\n$$P_b(\\xi_0 + \\Delta\\xi) \\propto \\exp\\left(-\\frac{(\\kappa+k)((\\xi_0+\\Delta\\xi)-\\xi_0)^2}{2RT}\\right) = \\exp\\left(-\\frac{(\\kappa+k)(\\Delta\\xi)^2}{2RT}\\right)$$\nThe ratio is therefore:\n$$\\exp\\left(-\\frac{(\\kappa+k)(\\Delta\\xi)^2}{2RT}\\right) = r^{\\ast}$$\nFrom our previous derivation, we know that $\\frac{\\kappa+k}{RT} = \\frac{1}{\\sigma^2}$. Substituting this into the equation simplifies it considerably:\n$$\\exp\\left(-\\frac{(\\Delta\\xi)^2}{2\\sigma^2}\\right) = r^{\\ast}$$\nWe now solve for $\\Delta\\xi$. Taking the natural logarithm of both sides:\n$$-\\frac{(\\Delta\\xi)^2}{2\\sigma^2} = \\ln(r^{\\ast})$$\n$$(\\Delta\\xi)^2 = -2\\sigma^2 \\ln(r^{\\ast})$$\nSince $\\Delta\\xi$ is a spacing, we take the positive square root:\n$$\\Delta\\xi = \\sqrt{-2\\sigma^2 \\ln(r^{\\ast})} = \\sigma \\sqrt{-2 \\ln(r^{\\ast})}$$\nSubstituting the given numerical values, $\\sigma = 0.10\\,\\mathrm{nm}$ and $r^{\\ast}=0.30$:\n$$\\Delta\\xi = (0.10\\,\\mathrm{nm}) \\sqrt{-2 \\ln(0.30)}$$\n$$\\Delta\\xi \\approx (0.10\\,\\mathrm{nm}) \\sqrt{-2 \\times (-1.20397)}$$\n$$\\Delta\\xi \\approx (0.10\\,\\mathrm{nm}) \\sqrt{2.40794}$$\n$$\\Delta\\xi \\approx (0.10\\,\\mathrm{nm}) \\times 1.55175 \\approx 0.155175\\,\\mathrm{nm}$$\nRounding to three significant figures gives $\\Delta\\xi = 0.155\\,\\mathrm{nm}$.\n\nThe final requested pair of values $(k, \\Delta\\xi)$ is $(149\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{nm}^{-2}, 0.155\\,\\mathrm{nm})$.",
            "answer": "$$\\boxed{\\begin{pmatrix} 149 & 0.155 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Once data has been collected from each biased window, the next step is to combine it to reconstruct the unbiased free energy profile. This practice delves into the heart of this process by having you implement one iterative step of the Weighted Histogram Analysis Method (WHAM), the gold standard for this task. By building the update equations from first principles and testing them on synthetic data, you will gain a deep, practical understanding of how WHAM self-consistently resolves the free energy profile and the relative offsets between windows.",
            "id": "3827366",
            "problem": "You are tasked with implementing one iteration of the Weighted Histogram Analysis Method (WHAM) to update the unbiased probability distribution $P(\\xi)$ and the free energy offsets $f_i$ from synthetic umbrella-sampling histograms. Your program must derive its algorithm from first principles of Boltzmann reweighting and normalization, and then evaluate whether the single update moves the estimates toward self-consistency, quantified by a model-data discrepancy metric. All quantities are in dimensionless reduced units; no physical units are required.\n\nContext and definitions:\n- Umbrella sampling produces biased histograms for a collective variable $\\xi$. In window $i$, a harmonic bias $U_i^{\\text{bias}}(\\xi)$ is applied.\n- Let $H_{ij}$ denote the observed histogram counts in window $i$ at bin center $\\xi_j$. Let $n_i = \\sum_j H_{ij}$ be the total count in window $i$.\n- The unbiased free energy profile $F(\\xi)$ defines the unbiased distribution via the Boltzmann principle: $P_{\\text{true}}(\\xi) \\propto \\exp(-\\beta F(\\xi))$, where $\\beta$ is the inverse reduced temperature.\n- Under bias $U_i^{\\text{bias}}(\\xi)$, the biased distribution for window $i$ is proportional to $P_{\\text{true}}(\\xi)\\exp(-\\beta U_i^{\\text{bias}}(\\xi))$ and is normalized over the discrete grid.\n- The Weighted Histogram Analysis Method (WHAM) computes an unbiased $P(\\xi)$ consistent with all histograms via reweighting and determines offsets $f_i$ that enforce partition function consistency across windows.\n\nYour task:\n1. From the foundational Boltzmann reweighting principle and normalization constraints, implement one WHAM update step for $P(\\xi)$ and $f_i$ on a discrete grid:\n   - Initialize with a uniform $P^{(0)}(\\xi)$ across bins and $f_i^{(0)} = 0$.\n   - Use the synthetic histograms $H_{ij}$ and bias energies $U_i^{\\text{bias}}(\\xi_j)$ to compute $P^{(1)}(\\xi_j)$ from the self-consistency framework that aggregates histograms via reweighting and enforces global normalization $\\sum_j P(\\xi_j) = 1$.\n   - Update $f_i^{(1)}$ to satisfy window normalization consistency with $P^{(1)}$.\n2. Define and compute the discrepancy measure that quantifies self-consistency between the model implied by $P(\\xi)$ and the observed histograms:\n   - For any candidate distribution $P(\\xi)$, define\n     $$p_{ij}(P) = \\frac{P(\\xi_j)\\exp(-\\beta U_i^{\\text{bias}}(\\xi_j))}{\\sum_k P(\\xi_k)\\exp(-\\beta U_i^{\\text{bias}}(\\xi_k))},$$\n     which is the model-predicted probability of bin $j$ in window $i$ under $P(\\xi)$.\n   - Define the discrepancy as\n     $$D(P) = \\sum_{i,j}\\left(H_{ij} - n_i\\,p_{ij}(P)\\right)^2.$$\n   - Assess whether the update moves toward self-consistency by checking whether $D(P^{(1)}) < D(P^{(0)})$.\n3. Generate synthetic histograms using a physically plausible unbiased double-well free energy and harmonic biases:\n   - The unbiased free energy is\n     $$F(\\xi) = a\\left(\\xi^2 - b^2\\right)^2,$$\n     and the inverse temperature is $\\beta$ (dimensionless).\n   - For window $i$, the harmonic bias is\n     $$U_i^{\\text{bias}}(\\xi) = \\frac{1}{2}k_i\\left(\\xi - c_i\\right)^2.$$\n   - The unbiased distribution on the grid is $P_{\\text{true}}(\\xi_j) \\propto \\exp\\left(-\\beta F(\\xi_j)\\right)$, normalized so that $\\sum_j P_{\\text{true}}(\\xi_j) = 1$.\n   - The biased distribution in window $i$ is $p_i(\\xi_j) \\propto P_{\\text{true}}(\\xi_j)\\exp\\left(-\\beta U_i^{\\text{bias}}(\\xi_j)\\right)$, normalized so that $\\sum_j p_i(\\xi_j) = 1$.\n   - Synthetic histograms are formed as $H_{ij} = \\text{round}\\left(n_i\\,p_i(\\xi_j)\\right)$, and then adjusted minimally so that $\\sum_j H_{ij} = n_i$ for each $i$.\n4. Implement robustness safeguards to avoid division by zero by clamping denominators to a small positive threshold during computations.\n\nTest suite specification:\n- Use the following three parameter sets to generate the synthetic data and perform the single WHAM update and discrepancy assessment. The grid is specified by its bounds and spacing; the grid points are the bin centers $\\xi_j$.\n\nCase 1 (general overlap, happy path):\n- $\\beta = 1.0$, $a = 1.5$, $b = 1.0$.\n- Grid: $\\xi_{\\min} = -2.5$, $\\xi_{\\max} = 2.5$, $\\Delta \\xi = 0.1$.\n- Windows: $i=1$: $c_1 = -1.5$, $k_1 = 20$, $n_1 = 5000$; $i=2$: $c_2 = 0.0$, $k_2 = 15$, $n_2 = 6000$; $i=3$: $c_3 = 1.5$, $k_3 = 20$, $n_3 = 5000$.\n\nCase 2 (minimal overlap, stiffer biases):\n- $\\beta = 1.0$, $a = 2.0$, $b = 1.2$.\n- Grid: $\\xi_{\\min} = -3.0$, $\\xi_{\\max} = 3.0$, $\\Delta \\xi = 0.15$.\n- Windows: $i=1$: $c_1 = -2.4$, $k_1 = 35$, $n_1 = 4000$; $i=2$: $c_2 = 2.4$, $k_2 = 35$, $n_2 = 4000$.\n\nCase 3 (one low-count window):\n- $\\beta = 0.8$, $a = 1.2$, $b = 1.1$.\n- Grid: $\\xi_{\\min} = -2.2$, $\\xi_{\\max} = 2.2$, $\\Delta \\xi = 0.1$.\n- Windows: $i=1$: $c_1 = -1.1$, $k_1 = 25$, $n_1 = 800$; $i=2$: $c_2 = 0.0$, $k_2 = 10$, $n_2 = 2000$; $i=3$: $c_3 = 1.1$, $k_3 = 25$, $n_3 = 800$.\n\nFinal output specification:\n- For each case, compute the boolean $B$ that is $B = \\text{True}$ if $D(P^{(1)}) < D(P^{(0)})$, and $B = \\text{False}$ otherwise.\n- Your program should produce a single line of output containing the three booleans for the cases in order, as a comma-separated list enclosed in square brackets, for example: \"[True,False,True]\".",
            "solution": "The problem posed is a well-defined computational task in the field of statistical mechanics, requiring the implementation and assessment of one iteration of the Weighted Histogram Analysis Method (WHAM). The problem is scientifically grounded, internally consistent, and contains all necessary information for its resolution. It is therefore deemed valid.\n\nThe solution is developed by first deriving the WHAM update equations from foundational principles of statistical mechanics and then implementing these equations to process synthetically generated data.\n\n### Principle-Based Derivation of the WHAM Algorithm\n\nThe goal of WHAM is to find the best estimate for the unbiased probability distribution, $P(\\xi)$, over a collective variable $\\xi$, by combining data from multiple biased simulations (windows). Each window $i$ has data in the form of a histogram $H_{ij}$ (counts in bin $j$) obtained with a total of $n_i = \\sum_j H_{ij}$ samples under an applied bias potential $U_i^{\\text{bias}}(\\xi)$.\n\nThe core of the method relies on Boltzmann reweighting and the principle of maximum likelihood. The probability of observing a state with coordinate $\\xi_j$ in the biased simulation of window $i$, denoted $p_{ij}$, is related to the unknown unbiased probability $P(\\xi_j)$ by:\n$$\np_i(\\xi_j) \\propto P(\\xi_j) \\exp(-\\beta U_i^{\\text{bias}}(\\xi_j))\n$$\nwhere $\\beta$ is the inverse reduced temperature. To be a valid probability distribution, this must be normalized for each window $i$:\n$$\np_{ij}(P) = \\frac{P(\\xi_j)\\exp(-\\beta U_i^{\\text{bias}}(\\xi_j))}{\\sum_k P(\\xi_k)\\exp(-\\beta U_i^{\\text{bias}}(\\xi_k))}\n$$\nThis equation, given in the problem, is the model's prediction for the probability of observing bin $j$ in window $i$, given a candidate unbiased distribution $P$.\n\nWHAM finds the optimal $P(\\xi)$ by maximizing the log-likelihood of observing the set of all histograms $\\{H_{ij}\\}$. This optimization leads to a set of self-consistent equations that are typically solved iteratively. The problem asks for the implementation of one such iterative step.\n\nThe two coupled, self-consistent equations are:\n\n1.  **Update for the Unbiased Probability Distribution $P(\\xi)$**:\n    The probability $P(\\xi_j)$ is estimated as being proportional to the total number of times the system was observed in bin $j$, summed over all windows. However, these observations are from biased ensembles and must be reweighted. The resulting update rule is:\n    $$\n    P(\\xi_j) = \\mathcal{N} \\frac{\\sum_i H_{ij}}{\\sum_k n_k \\exp(-\\beta [U_k^{\\text{bias}}(\\xi_j) - f_k])}\n    $$\n    Here, $\\mathcal{N}$ is a normalization constant ensuring that $\\sum_j P(\\xi_j) = 1$. The term $f_k$ is the dimensionless free energy offset of window $k$, which accounts for the difference in sampling efficiency between windows. The denominator can be interpreted as the total effective number of observations of bin $j$ across all simulations.\n\n2.  **Update for the Free Energy Offsets $f_i$**:\n    The free energy offsets $f_i$ are intrinsically linked to the partition functions of the biased ensembles. Their values are determined by enforcing consistency with the global probability distribution $P(\\xi)$. The update rule is derived from the denominator of the $p_{ij}(P)$ expression, which is the partition function of window $i$ calculated with respect to $P(\\xi)$:\n    $$\n    \\exp(-\\beta f_i) = \\sum_j P(\\xi_j) \\exp(-\\beta U_i^{\\text{bias}}(\\xi_j))\n    $$\n    This can be rearranged to solve for $f_i$:\n    $$\n    f_i = -\\frac{1}{\\beta} \\ln \\left( \\sum_j P(\\xi_j) \\exp(-\\beta U_i^{\\text{bias}}(\\xi_j)) \\right)\n    $$\n\n### Algorithmic Implementation\n\nThe task is to perform a single update step and evaluate its performance.\n\n**Step 1: Synthetic Data Generation**\nFor each test case, we first generate the synthetic data:\n1.  A discrete grid for the collective variable $\\xi$ is created based on the specified bounds and spacing.\n2.  The true unbiased free energy $F(\\xi) = a(\\xi^2 - b^2)^2$ is computed on this grid.\n3.  The true unbiased probability distribution $P_{\\text{true}}(\\xi_j) \\propto \\exp(-\\beta F(\\xi_j))$ is calculated and normalized.\n4.  For each window $i$, the harmonic bias $U_i^{\\text{bias}}(\\xi_j) = \\frac{1}{2}k_i(\\xi_j - c_i)^2$ is computed.\n5.  The true biased probability distribution for each window, $p_i(\\xi_j) \\propto P_{\\text{true}}(\\xi_j)\\exp(-\\beta U_i^{\\text{bias}}(\\xi_j))$, is calculated and normalized.\n6.  The synthetic histogram $H_{ij}$ is generated by taking $n_i p_i(\\xi_j)$, rounding to the nearest integer, and then minimally adjusting the counts to ensure that $\\sum_j H_{ij} = n_i$ is strictly satisfied. This adjustment is done by adding or subtracting counts from bins with the largest rounding residuals.\n\n**Step 2: Discrepancy Calculation for the Initial Guess**\n1.  The WHAM iteration is initialized with a uniform distribution $P^{(0)}(\\xi_j) = 1/N_{\\text{bins}}$ and zero free energy offsets $f_i^{(0)} = 0$.\n2.  The initial discrepancy, $D(P^{(0)})$, is calculated. This requires computing the model-predicted probabilities $p_{ij}(P^{(0)})$ for each window and bin, and then summing the squared differences between observed counts $H_{ij}$ and predicted counts $n_i p_{ij}(P^{(0)})$.\n    $$\n    D(P^{(0)}) = \\sum_{i,j}\\left(H_{ij} - n_i\\,p_{ij}(P^{(0)})\\right)^2\n    $$\n\n**Step 3: One WHAM Update Iteration**\n1.  **Update $P$**: The new probability distribution $P^{(1)}(\\xi_j)$ is computed using the update rule with the initial free energies $f_i^{(0)}=0$:\n    $$\n    P^{(1, \\text{unnorm})}(\\xi_j) = \\frac{\\sum_i H_{ij}}{\\sum_k n_k \\exp(-\\beta U_k^{\\text{bias}}(\\xi_j))}\n    $$\n    This result is then normalized to yield $P^{(1)}(\\xi_j)$.\n2.  **Update $f$**: The new free energy offsets $f_i^{(1)}$ are calculated using the updated distribution $P^{(1)}(\\xi_j)$. Although not strictly necessary for calculating $D(P^{(1)})$, this completes the iterative step as requested.\n\n**Step 4: Discrepancy Calculation for the Updated Distribution**\n1.  The discrepancy $D(P^{(1)})$ is calculated using the same formula as before, but with the updated distribution $P^{(1)}(\\xi)$.\n2.  The boolean condition $D(P^{(1)}) < D(P^{(0)})$ is evaluated. As WHAM is a maximum likelihood method, each iteration should, in general, decrease the discrepancy and move the estimate closer to the optimal solution.\n\nThis entire procedure is repeated for each of the three test cases provided. To ensure numerical stability, all denominators and arguments of logarithms that could become zero are clamped to a small positive machine-epsilon value.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates one iteration of the Weighted Histogram Analysis Method (WHAM).\n    For each test case, it generates synthetic histogram data, performs one WHAM update\n    from an initial guess, and determines if the update reduces a model-data\n    discrepancy metric.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"params\": {\"beta\": 1.0, \"a\": 1.5, \"b\": 1.0},\n            \"grid\": {\"min\": -2.5, \"max\": 2.5, \"spacing\": 0.1},\n            \"windows\": [\n                {\"c\": -1.5, \"k\": 20.0, \"n\": 5000},\n                {\"c\": 0.0, \"k\": 15.0, \"n\": 6000},\n                {\"c\": 1.5, \"k\": 20.0, \"n\": 5000},\n            ],\n        },\n        {\n            \"params\": {\"beta\": 1.0, \"a\": 2.0, \"b\": 1.2},\n            \"grid\": {\"min\": -3.0, \"max\": 3.0, \"spacing\": 0.15},\n            \"windows\": [\n                {\"c\": -2.4, \"k\": 35.0, \"n\": 4000},\n                {\"c\": 2.4, \"k\": 35.0, \"n\": 4000},\n            ],\n        },\n        {\n            \"params\": {\"beta\": 0.8, \"a\": 1.2, \"b\": 1.1},\n            \"grid\": {\"min\": -2.2, \"max\": 2.2, \"spacing\": 0.1},\n            \"windows\": [\n                {\"c\": -1.1, \"k\": 25.0, \"n\": 800},\n                {\"c\": 0.0, \"k\": 10.0, \"n\": 2000},\n                {\"c\": 1.1, \"k\": 25.0, \"n\": 800},\n            ],\n        },\n    ]\n\n    results = []\n    clamp_val = np.finfo(np.float64).eps\n\n    def calculate_discrepancy(P, H, n_i, U_bias, beta):\n        \"\"\"Calculates the discrepancy D(P).\"\"\"\n        discrepancy = 0.0\n        num_windows = H.shape[0]\n        for i in range(num_windows):\n            exp_bias = np.exp(-beta * U_bias[i, :])\n            # Denominator for p_ij\n            Z_i = np.sum(P * exp_bias)\n            Z_i = max(Z_i, clamp_val)\n            \n            p_ij_model = (P * exp_bias) / Z_i\n            expected_H_ij = n_i[i] * p_ij_model\n            discrepancy += np.sum((H[i, :] - expected_H_ij)**2)\n        return discrepancy\n\n    for case in test_cases:\n        # --- 1. Set up and generate synthetic data ---\n        params = case[\"params\"]\n        grid_spec = case[\"grid\"]\n        windows_spec = case[\"windows\"]\n\n        beta, a, b = params[\"beta\"], params[\"a\"], params[\"b\"]\n        \n        xi_grid = np.arange(grid_spec[\"min\"], grid_spec[\"max\"] + grid_spec[\"spacing\"] / 2, grid_spec[\"spacing\"])\n        num_bins = len(xi_grid)\n        \n        # True unbiased free energy and probability\n        F_true = a * (xi_grid**2 - b**2)**2\n        P_true_unnorm = np.exp(-beta * F_true)\n        P_true = P_true_unnorm / np.sum(P_true_unnorm)\n\n        num_windows = len(windows_spec)\n        c_i = np.array([w[\"c\"] for w in windows_spec])\n        k_i = np.array([w[\"k\"] for w in windows_spec])\n        n_i = np.array([w[\"n\"] for w in windows_spec])\n\n        U_bias = np.zeros((num_windows, num_bins))\n        H = np.zeros((num_windows, num_bins), dtype=np.float64)\n\n        for i in range(num_windows):\n            U_bias[i, :] = 0.5 * k_i[i] * (xi_grid - c_i[i])**2\n            \n            # True biased probability distribution in window i\n            p_biased_unnorm = P_true * np.exp(-beta * U_bias[i, :])\n            p_biased = p_biased_unnorm / np.sum(p_biased_unnorm)\n            \n            # Generate synthetic histogram\n            expected_counts = n_i[i] * p_biased\n            H[i, :] = np.round(expected_counts)\n            \n            # Adjust to conserve total counts\n            count_diff = int(n_i[i] - np.sum(H[i, :]))\n            if count_diff != 0:\n                residuals = expected_counts - H[i, :]\n                if count_diff > 0: # Need to add counts\n                    indices_to_change = np.argsort(residuals)[-count_diff:]\n                    H[i, indices_to_change] += 1\n                else: # Need to remove counts\n                    indices_to_change = np.argsort(residuals)[:abs(count_diff)]\n                    H[i, indices_to_change] -= 1\n\n        # --- 2. Initial state (iteration 0) and discrepancy ---\n        P_0 = np.full(num_bins, 1.0 / num_bins)\n        f_0 = np.zeros(num_windows)\n        D_0 = calculate_discrepancy(P_0, H, n_i, U_bias, beta)\n\n        # --- 3. First WHAM update (iteration 1) ---\n        # Update P\n        sum_H_j = np.sum(H, axis=0) # Numerator of P update\n        \n        # Denominator of P update (vectorized)\n        # With f_0=0, exp(beta*f_0) is 1, so it can be omitted\n        exp_U_bias_term = np.exp(-beta * U_bias)\n        denom_P_j = np.sum(n_i[:, np.newaxis] * exp_U_bias_term, axis=0)\n        \n        denom_P_j = np.maximum(denom_P_j, clamp_val)\n        P_1_unnorm = sum_H_j / denom_P_j\n        P_1 = P_1_unnorm / np.sum(P_1_unnorm)\n\n        # Update f (for completeness of one iteration)\n        f_1 = np.zeros(num_windows)\n        for i in range(num_windows):\n            Z_i_1 = np.sum(P_1 * np.exp(-beta * U_bias[i,:]))\n            Z_i_1 = max(Z_i_1, clamp_val)\n            f_1[i] = -(1.0/beta) * np.log(Z_i_1)\n        \n        # --- 4. Discrepancy after one update and comparison ---\n        D_1 = calculate_discrepancy(P_1, H, n_i, U_bias, beta)\n        results.append(D_1 < D_0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The final, and arguably most crucial, step in any free energy calculation is to validate the result. This exercise addresses the common pitfall of insufficient sampling, which can lead to hysteresis—a discrepancy between results obtained by traversing the reaction coordinate in opposite directions. You will apply a rigorous chi-squared test to data from a hypothetical forward- and backward-initialized simulation, providing you with a quantitative tool to assess convergence and diagnose whether the system has truly reached equilibrium along all relevant degrees of freedom.",
            "id": "3827415",
            "problem": "Consider a one-dimensional reaction coordinate $\\xi$ for a molecular system at temperature $T$, with inverse temperature $\\beta = 1/(k_{\\mathrm{B}} T)$ where $k_{\\mathrm{B}}$ is the Boltzmann constant. The potential of mean force (PMF) along $\\xi$ is defined as $F(\\xi) = -k_{\\mathrm{B}} T \\ln P(\\xi) + C$, where $P(\\xi)$ is the equilibrium marginal probability density of $\\xi$ and $C$ is an arbitrary constant. In umbrella sampling, one augments the system Hamiltonian with window-specific harmonic bias potentials $U_i(\\xi) = \\tfrac{1}{2} k (\\xi - \\xi_i)^2$ at positions $\\xi_i$ with stiffness $k$, and then reweights biased samples to recover $P(\\xi)$ and thus $F(\\xi)$. Under equilibrium sampling and detailed balance, the unbiased PMF $F(\\xi)$ reconstructed from any set of windows is independent of initialization history up to an additive constant.\n\nTo test for hysteresis arising from non-equilibrium sampling in umbrella windows, you perform two independent umbrella sampling campaigns over the same set of windows $\\{\\xi_i\\}$: a forward-initialized campaign (each window $i$ started from an equilibrated configuration at window $i-1$ and then relaxed under $U_i$) and a backward-initialized campaign (each window $i$ started from window $i+1$ and then relaxed under $U_i$). Using the same reweighting protocol (for example, Weighted Histogram Analysis Method (WHAM)), you obtain two PMFs, $F^{\\rightarrow}(\\xi)$ and $F^{\\leftarrow}(\\xi)$, each with pointwise uncertainty estimates $\\sigma^{\\rightarrow}(\\xi)$ and $\\sigma^{\\leftarrow}(\\xi)$ from bootstrap resampling. Assume that the two PMFs are aligned by enforcing a common reference such that any global additive offset is removed via a weighted least-squares alignment.\n\nYou evaluate the discrepancy at $M$ grid points $\\{\\xi_j\\}_{j=1}^{M}$, defining the raw differences $\\Delta F_j^{\\mathrm{raw}} = F^{\\rightarrow}(\\xi_j) - F^{\\leftarrow}(\\xi_j)$ and the combined standard deviations $\\sigma_{c,j} = \\sqrt{ \\left[\\sigma^{\\rightarrow}(\\xi_j)\\right]^2 + \\left[\\sigma^{\\leftarrow}(\\xi_j)\\right]^2 }$, assuming independent estimation errors between the two campaigns. You then compute a weighted mean to remove the residual global offset,\n$$\n\\mu = \\frac{\\sum_{j=1}^{M} w_j \\,\\Delta F_j^{\\mathrm{raw}}}{\\sum_{j=1}^{M} w_j}, \\quad w_j = \\frac{1}{\\sigma_{c,j}^2},\n$$\nand define the aligned differences $\\Delta F_j = \\Delta F_j^{\\mathrm{raw}} - \\mu$. A chi-squared statistic is then constructed as\n$$\n\\chi^2 = \\sum_{j=1}^{M} \\left( \\frac{\\Delta F_j}{\\sigma_{c,j}} \\right)^2,\n$$\nwith degrees of freedom $\\nu = M - 1$ due to the fitted offset $\\mu$. Under the null hypothesis that there is no hysteresis (i.e., both PMFs represent the same underlying equilibrium $F(\\xi)$), $\\chi^2$ should be consistent with the chi-squared distribution with $\\nu$ degrees of freedom.\n\nYou are given $M = 4$ equally spaced grid points $\\xi_1 = 0.2$, $\\xi_2 = 0.4$, $\\xi_3 = 0.6$, $\\xi_4 = 0.8$ (in arbitrary units), and the following data (differences in kilocalories per mole, uncertainties in kilocalories per mole):\n$\\Delta F_1^{\\mathrm{raw}} = 0.30$, $\\sigma_{c,1} = 0.20$;\n$\\Delta F_2^{\\mathrm{raw}} = 1.20$, $\\sigma_{c,2} = 0.30$;\n$\\Delta F_3^{\\mathrm{raw}} = 0.80$, $\\sigma_{c,3} = 0.25$;\n$\\Delta F_4^{\\mathrm{raw}} = -0.10$, $\\sigma_{c,4} = 0.20$.\nTest at significance level $\\alpha = 0.01$ whether hysteresis is present, and interpret any statistically significant discrepancy in terms of non-equilibrium sampling. Assume the critical chi-squared value at $\\alpha = 0.01$ for $\\nu = 3$ is approximately $11.34$.\n\nWhich option best describes the correct conclusion and scientifically sound interpretation?\n\nA. The computed $\\chi^2$ exceeds the $0.01$ threshold for $\\nu = 3$, indicating statistically significant hysteresis; the most plausible cause is non-equilibrium sampling and memory of orthogonal slow degrees of freedom within windows due to insufficient relaxation, and appropriate remedies include increasing per-window equilibration and decorrelation times, employing exchanges between windows, and restarting windows from diverse, decorrelated configurations.\n\nB. The observed forward–backward discrepancies are expected under equilibrium because PMFs are path-dependent; large local deviations relative to error bars are acceptable and indicate complementary sampling paths, so there is no hysteresis.\n\nC. If the autocorrelation time of $\\xi$ in each window appears short, any forward–backward PMF discrepancy cannot be hysteresis and must be entirely due to an incorrect value of the bias stiffness $k$; reducing $k$ strictly removes hysteresis regardless of orthogonal slow variables.\n\nD. A valid hysteresis test must compare average biased potential energies $\\langle U_i \\rangle$ between forward and backward runs instead of PMFs; PMFs are non-unique and therefore cannot be compared for hysteresis testing, so the described chi-squared procedure is invalid.",
            "solution": "The problem asks us to determine if there is statistically significant hysteresis between two potential of mean force (PMF) profiles, $F^{\\rightarrow}(\\xi)$ and $F^{\\leftarrow}(\\xi)$, generated from forward-initialized and backward-initialized umbrella sampling campaigns, respectively. The analysis will be performed using a chi-squared ($\\chi^2$) test on the aligned differences between the two PMFs at a set of grid points.\n\nFirst, we validate the problem statement.\nThe problem setup is scientifically sound and well-posed. It describes a standard and rigorous procedure for quantifying hysteresis in enhanced sampling simulations. The definitions of the PMF, umbrella biasing, and the statistical testing framework are all standard in the field of multiscale modeling and computational chemistry. All necessary data, including the raw differences in PMFs, their combined uncertainties, the number of data points, and the critical value for the statistical test, are provided. The problem is objective and contains no internal contradictions or scientifically implausible information. Thus, the problem is valid, and we may proceed with the calculation.\n\nThe null hypothesis ($H_0$) is that there is no hysteresis, meaning both $F^{\\rightarrow}(\\xi)$ and $F^{\\leftarrow}(\\xi)$ are estimates of the same true underlying equilibrium PMF, $F(\\xi)$. Any observed differences are due to statistical error alone. The alternative hypothesis ($H_1$) is that there is significant hysteresis due to non-equilibrium effects.\n\nWe are given $M=4$ data points. The degrees of freedom for the $\\chi^2$ test are $\\nu = M - 1 = 4 - 1 = 3$, because one degree of freedom is used to estimate the residual offset, $\\mu$.\n\nThe calculation proceeds in four steps:\n1.  Calculate the weights, $w_j = 1/\\sigma_{c,j}^2$.\n2.  Calculate the weighted mean offset, $\\mu$.\n3.  Calculate the aligned differences, $\\Delta F_j = \\Delta F_j^{\\mathrm{raw}} - \\mu$.\n4.  Calculate the $\\chi^2$ statistic, $\\chi^2 = \\sum_{j=1}^{M} (\\Delta F_j / \\sigma_{c,j})^2$.\n5.  Compare the calculated $\\chi^2$ to the critical value.\n\nThe given data are:\n-   $\\Delta F_1^{\\mathrm{raw}} = 0.30$, $\\sigma_{c,1} = 0.20$\n-   $\\Delta F_2^{\\mathrm{raw}} = 1.20$, $\\sigma_{c,2} = 0.30$\n-   $\\Delta F_3^{\\mathrm{raw}} = 0.80$, $\\sigma_{c,3} = 0.25$\n-   $\\Delta F_4^{\\mathrm{raw}} = -0.10$, $\\sigma_{c,4} = 0.20$\n\nAll energy units are in kcal/mol.\n\nStep 1: Calculate the weights $w_j$.\n$$w_1 = \\frac{1}{\\sigma_{c,1}^2} = \\frac{1}{(0.20)^2} = \\frac{1}{0.04} = 25.0$$\n$$w_2 = \\frac{1}{\\sigma_{c,2}^2} = \\frac{1}{(0.30)^2} = \\frac{1}{0.09} \\approx 11.111...$$\n$$w_3 = \\frac{1}{\\sigma_{c,3}^2} = \\frac{1}{(0.25)^2} = \\frac{1}{0.0625} = 16.0$$\n$$w_4 = \\frac{1}{\\sigma_{c,4}^2} = \\frac{1}{(0.20)^2} = \\frac{1}{0.04} = 25.0$$\n\nStep 2: Calculate the weighted mean offset $\\mu$.\n$$ \\mu = \\frac{\\sum_{j=1}^{M} w_j \\,\\Delta F_j^{\\mathrm{raw}}}{\\sum_{j=1}^{M} w_j} $$\nThe numerator is:\n$$ \\sum w_j \\Delta F_j^{\\mathrm{raw}} = (25.0)(0.30) + (1/0.09)(1.20) + (16.0)(0.80) + (25.0)(-0.10) $$\n$$ = 7.5 + 13.333... + 12.8 - 2.5 \\approx 31.133... $$\nThe denominator is:\n$$ \\sum w_j = 25.0 + 11.111... + 16.0 + 25.0 \\approx 77.111... $$\nThus,\n$$ \\mu = \\frac{31.133...}{77.111...} \\approx 0.403746... \\text{ kcal/mol} $$\n\nStep 3: Calculate the aligned differences $\\Delta F_j$.\n$$ \\Delta F_1 = \\Delta F_1^{\\mathrm{raw}} - \\mu = 0.30 - 0.40375 = -0.10375 $$\n$$ \\Delta F_2 = \\Delta F_2^{\\mathrm{raw}} - \\mu = 1.20 - 0.40375 = 0.79625 $$\n$$ \\Delta F_3 = \\Delta F_3^{\\mathrm{raw}} - \\mu = 0.80 - 0.40375 = 0.39625 $$\n$$ \\Delta F_4 = \\Delta F_4^{\\mathrm{raw}} - \\mu = -0.10 - 0.40375 = -0.50375 $$\n\nStep 4: Calculate the $\\chi^2$ statistic.\n$$ \\chi^2 = \\sum_{j=1}^{M} \\left( \\frac{\\Delta F_j}{\\sigma_{c,j}} \\right)^2 $$\n$$ \\chi^2 = \\left(\\frac{-0.10375}{0.20}\\right)^2 + \\left(\\frac{0.79625}{0.30}\\right)^2 + \\left(\\frac{0.39625}{0.25}\\right)^2 + \\left(\\frac{-0.50375}{0.20}\\right)^2 $$\n$$ \\chi^2 = (-0.51875)^2 + (2.65417)^2 + (1.585)^2 + (-2.51875)^2 $$\n$$ \\chi^2 \\approx 0.2691 + 7.0446 + 2.5122 + 6.3441 $$\n$$ \\chi^2 \\approx 16.17 $$\n\nStep 5: Compare the calculated $\\chi^2$ with the critical value.\nThe calculated value is $\\chi^2 \\approx 16.17$. The number of degrees of freedom is $\\nu = 3$. The problem states that the critical value for $\\nu=3$ at a significance level of $\\alpha = 0.01$ is $\\chi^2_{crit}(0.01, 3) \\approx 11.34$.\nSince our calculated value $\\chi^2 \\approx 16.17$ is greater than the critical value $\\chi^2_{crit} \\approx 11.34$, we reject the null hypothesis $H_0$. This means the discrepancy between the forward and backward PMFs is statistically significant at the $\\alpha = 0.01$ level. This significant discrepancy is interpreted as hysteresis.\n\nNow, we evaluate each option:\n\nA. The computed $\\chi^2$ exceeds the $0.01$ threshold for $\\nu = 3$, indicating statistically significant hysteresis; the most plausible cause is non-equilibrium sampling and memory of orthogonal slow degrees of freedom within windows due to insufficient relaxation, and appropriate remedies include increasing per-window equilibration and decorrelation times, employing exchanges between windows, and restarting windows from diverse, decorrelated configurations.\nThis statement is fully consistent with our findings. The calculation confirms that $\\chi^2 > \\chi^2_{crit}$. The physical interpretation is correct: hysteresis in PMF calculations along a chosen reaction coordinate $\\xi$ is a classic sign of insufficient equilibration of other, \"orthogonal\" degrees of freedom that are coupled to $\\xi$. The suggested remedies are all standard best practices for mitigating such non-equilibrium effects and improving the convergence of free energy calculations.\nVerdict: **Correct**.\n\nB. The observed forward–backward discrepancies are expected under equilibrium because PMFs are path-dependent; large local deviations relative to error bars are acceptable and indicate complementary sampling paths, so there is no hysteresis.\nThis statement is fundamentally incorrect. The Potential of Mean Force is an equilibrium property, a state function defined via the Boltzmann distribution. As a state function, it is, by definition, path-independent. The very purpose of the forward-backward test is to check for path dependence, the presence of which signifies a departure from equilibrium (hysteresis).\nVerdict: **Incorrect**.\n\nC. If the autocorrelation time of $\\xi$ in each window appears short, any forward–backward PMF discrepancy cannot be hysteresis and must be entirely due to an incorrect value of the bias stiffness $k$; reducing $k$ strictly removes hysteresis regardless of orthogonal slow variables.\nThis statement is flawed. A short autocorrelation time for the reaction coordinate $\\xi$ itself guarantees only that the system is sampling well within the local potential well created by the bias $U_i(\\xi)$. It does not guarantee that other slow degrees of freedom, orthogonal to $\\xi$, have reached equilibrium. Hysteresis is precisely caused by the slow relaxation of these orthogonal modes. The value of the stiffness $k$ affects the efficiency of sampling and the overlap between adjacent windows, but it is not the root cause of hysteresis, and simply reducing it is not a guaranteed cure. The problem lies with physical relaxation timescales, not just a parameter of the sampling algorithm.\nVerdict: **Incorrect**.\n\nD. A valid hysteresis test must compare average biased potential energies $\\langle U_i \\rangle$ between forward and backward runs instead of PMFs; PMFs are non-unique and therefore cannot be compared for hysteresis testing, so the described chi-squared procedure is invalid.\nThis statement is incorrect. While comparing other observables like $\\langle U_i \\rangle$ can be a useful diagnostic, the ultimate quantity of interest is the PMF, $F(\\xi)$. Comparing the final PMFs is the most direct and meaningful test for hysteresis. The claim that PMFs are \"non-unique\" is a misinterpretation. A PMF is well-defined up to an arbitrary additive constant. The procedure described in the problem correctly accounts for this by calculating and removing a weighted-mean offset, $\\mu$, to align the two curves. After alignment, the shape of the PMF is unique and must be identical between forward and backward runs at equilibrium. The described $\\chi^2$ test is a standard and statistically valid method for performing this comparison.\nVerdict: **Incorrect**.\n\nBased on the calculation and analysis, only option A is correct. It accurately reflects the statistical outcome and provides a scientifically sound interpretation of its physical cause and potential remedies.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}