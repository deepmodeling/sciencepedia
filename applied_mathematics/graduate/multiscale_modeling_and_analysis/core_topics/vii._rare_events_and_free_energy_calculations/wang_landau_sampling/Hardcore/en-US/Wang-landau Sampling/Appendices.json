{
    "hands_on_practices": [
        {
            "introduction": "The heart of the Wang-Landau algorithm is the dynamic modification of the density of states estimate, driven by a convergence factor $f$. The schedule by which this factor is reduced is critical for the efficiency and accuracy of the simulation. This exercise provides a concrete, quantitative look into the convergence process by having you determine how many refinement stages are needed to reach a desired precision under a common update rule, building your intuition for the algorithm's behavior .",
            "id": "3832255",
            "problem": "In Wang-Landau (WL) sampling for estimating the density of states in multiscale models, the modification factor $f$ controls the multiplicative updates to the density-of-states estimate and is reduced across stages to drive convergence. Consider a WL procedure in which the modification factor is initialized to $f_{0} = \\exp(1)$ and is reduced by the square-root schedule at the completion of each refinement stage, meaning that at stage $k$ the factor $f_{k}$ is replaced by $f_{k+1} = \\sqrt{f_{k}}$. The termination criterion is that the natural logarithm of the factor satisfies $\\ln f \\leq 10^{-8}$. Starting from the definition of the square-root schedule and the logarithm law $\\ln(a^{b}) = b \\ln(a)$, derive a closed-form expression for $\\ln f_{n}$ after $n$ refinement stages and determine the minimal integer number of refinement stages required to satisfy the termination criterion when starting from $f_{0} = \\exp(1)$. Report the integer count of stages as your final answer. No rounding instruction is needed since the answer is an integer.",
            "solution": "The problem statement is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\n- **Algorithm**: Wang-Landau (WL) sampling.\n- **Initial modification factor**: $f_{0} = \\exp(1)$.\n- **Reduction schedule**: $f_{k+1} = \\sqrt{f_{k}}$ for the modification factor at stage $k$.\n- **Termination criterion**: $\\ln f \\leq 10^{-8}$.\n- **Provided identity**: $\\ln(a^{b}) = b \\ln(a)$.\n- **Objective 1**: Derive a closed-form expression for $\\ln f_{n}$ after $n$ refinement stages.\n- **Objective 2**: Determine the minimal integer number of refinement stages $n$ required to satisfy the termination criterion.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in computational statistical physics. Wang-Landau sampling is a standard and widely used algorithm. The modification factor $f$, its update schedule, and the convergence criterion are all standard components of this method. The initial value $f_0=\\exp(1)$ and the square-root schedule are common choices.\n- **Well-Posed**: The problem is well-posed. It provides an initial condition ($f_0$), a clear recurrence relation ($f_{k+1} = \\sqrt{f_k}$), and a precise termination condition ($\\ln f_n \\le 10^{-8}$). The goal is to find a specific integer, for which a unique solution exists.\n- **Objective**: The problem is stated using objective, mathematical language, free from ambiguity or subjective claims.\n- **Completeness and Consistency**: The problem is self-contained. All necessary information to derive the solution is provided. There are no internal contradictions.\n- **Realism**: The parameters and context are realistic for a typical implementation of the Wang-Landau algorithm.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is scientifically grounded, well-posed, objective, and complete. I will now proceed with the solution.\n\nThe problem asks for two things: a closed-form expression for $\\ln f_n$ and the minimal number of stages $n$ to meet a convergence criterion.\n\nFirst, we derive the closed-form expression for $f_n$. The update rule is given by:\n$$f_{k+1} = \\sqrt{f_k} = f_k^{1/2}$$\nWe can express $f_n$ in terms of the initial factor $f_0$ by repeatedly applying this rule.\nFor $n=1$:\n$$f_1 = f_0^{1/2}$$\nFor $n=2$:\n$$f_2 = f_1^{1/2} = \\left(f_0^{1/2}\\right)^{1/2} = f_0^{(1/2) \\cdot (1/2)} = f_0^{(1/2)^2}$$\nFor $n=3$:\n$$f_3 = f_2^{1/2} = \\left(f_0^{(1/2)^2}\\right)^{1/2} = f_0^{(1/2)^2 \\cdot (1/2)} = f_0^{(1/2)^3}$$\nBy induction, we can establish a general formula for $f_n$ after $n$ stages:\n$$f_n = f_0^{(1/2)^n}$$\nNow, we derive the expression for $\\ln f_n$. We take the natural logarithm of both sides of the expression for $f_n$:\n$$\\ln(f_n) = \\ln\\left(f_0^{(1/2)^n}\\right)$$\nUsing the provided logarithm identity $\\ln(a^b) = b\\ln(a)$, we get:\n$$\\ln(f_n) = \\left(\\frac{1}{2}\\right)^n \\ln(f_0)$$\nThis is the closed-form expression for $\\ln f_n$.\n\nNext, we use the specific initial condition given in the problem, $f_0 = \\exp(1)$.\n$$\\ln(f_0) = \\ln(\\exp(1)) = 1$$\nSubstituting this into our expression for $\\ln f_n$:\n$$\\ln(f_n) = \\left(\\frac{1}{2}\\right)^n \\cdot 1 = \\left(\\frac{1}{2}\\right)^n = 2^{-n}$$\nThe termination criterion is that the natural logarithm of the factor must be less than or equal to $10^{-8}$. We apply this to $\\ln f_n$:\n$$\\ln(f_n) \\leq 10^{-8}$$\nSubstituting our expression for $\\ln f_n$:\n$$2^{-n} \\leq 10^{-8}$$\nTo solve for $n$, we take the natural logarithm of both sides of the inequality. Since the natural logarithm is a monotonically increasing function, the direction of the inequality is preserved.\n$$\\ln(2^{-n}) \\leq \\ln(10^{-8})$$\nUsing the logarithm power rule again:\n$$-n \\ln(2) \\leq -8 \\ln(10)$$\nTo isolate $n$, we divide both sides by $-\\ln(2)$. Since $\\ln(2)  0$, the term $-\\ln(2)$ is negative. Dividing an inequality by a negative number reverses the direction of the inequality sign.\n$$n \\geq \\frac{-8 \\ln(10)}{-\\ln(2)}$$\n$$n \\geq 8 \\frac{\\ln(10)}{\\ln(2)}$$\nThe expression $\\frac{\\ln(10)}{\\ln(2)}$ is equivalent to the base-2 logarithm of $10$, $\\log_2(10)$, by the change of base formula.\n$$n \\geq 8 \\log_2(10)$$\nWe need to find the numerical value of the right-hand side to determine the minimal integer $n$.\nWe know that $2^3 = 8$ and $2^4 = 16$, so $3  \\log_2(10)  4$. Using numerical values for the logarithms, $\\ln(10) \\approx 2.302585$ and $\\ln(2) \\approx 0.693147$.\n$$\\log_2(10) \\approx \\frac{2.302585}{0.693147} \\approx 3.321928$$\nNow, we compute the lower bound for $n$:\n$$n \\geq 8 \\times 3.321928 \\approx 26.575424$$\nSince the number of refinement stages $n$ must be an integer, the minimal integer value that satisfies this condition is the smallest integer greater than or equal to $26.575424$. This is obtained by taking the ceiling of the value.\n$$n = \\lceil 26.575424 \\rceil = 27$$\nTherefore, a minimum of $27$ refinement stages are required to satisfy the termination criterion.",
            "answer": "$$\\boxed{27}$$"
        },
        {
            "introduction": "A key application of Wang-Landau sampling is the calculation of absolute thermodynamic properties like the Helmholtz free energy. However, the algorithm naturally produces a density of states, $g(E)$, that is correct only up to a multiplicative constant, meaning $\\ln g(E)$ has an unknown additive offset. This practice addresses the crucial post-processing step of normalization, demonstrating how to anchor the relative DOS to an absolute scale using a known physical quantity, such as the ground-state degeneracy, thereby enabling the calculation of physically meaningful results .",
            "id": "3832190",
            "problem": "Consider a finite discrete-energy system intended for multiscale modeling, where accurate absolute thermodynamic potentials must be computed to couple microscopic and mesoscopic descriptions. The microcanonical density of states $g(E)$ is defined as the exact number of microstates with energy $E$. Wang-Landau sampling (WLS) constructs a random walk in energy space and iteratively refines an estimate of $\\ln g(E)$ to flatten the visited-energy histogram. In a finite system, the Wang-Landau sampling output is known to be accurate up to a global multiplicative constant in $g(E)$ (equivalently, an additive constant in $\\ln g(E)$).\n\nYou are given a Wang-Landau sampling estimate $\\ln \\tilde{g}(E)$ for three energy levels $E_0  E_1  E_2$ of a finite system. The known ground-state multiplicity (degeneracy) is $g(E_0) = d_0$, determined independently from symmetry. Assume that Boltzmann’s constant $k_{\\mathrm{B}}$ is set to $1$ and energies are reported in consistent units. The provided data are:\n- Known degeneracy at the ground state: $d_0 = 2$ at $E_0$.\n- Wang-Landau sampling outputs: $\\ln \\tilde{g}(E_0) = \\ln 5$, $\\ln \\tilde{g}(E_1) = \\ln 25$, $\\ln \\tilde{g}(E_2) = \\ln 50$.\n- Energies: $E_0 = -6$, $E_1 = -2$, $E_2 = 0$.\n- Consider the canonical ensemble at inverse temperature $\\beta = 1$.\n\nUsing only first principles and core definitions of the microcanonical density of states and canonical partition function, explain how to obtain an absolute normalization of $g(E)$ from the Wang-Landau sampling estimate by leveraging the known degeneracy at the reference energy $E_0$. Then, demonstrate the normalization procedure on the given data and compute the corresponding canonical partition function $Z(\\beta)$ at $\\beta = 1$.\n\nWhich option correctly describes the normalization principle and provides the correct normalized $g(E)$ values and canonical partition function for the given data?\n\nA. Enforce that the normalized $g(E)$ matches the known degeneracy at $E_0$ by a single global rescaling of $\\tilde{g}(E)$ across all energies. This yields $g(E) = c\\,\\tilde{g}(E)$ with $c$ chosen to satisfy $g(E_0) = d_0$. For the given data, $c = \\dfrac{2}{5}$, so $g(E_0) = 2$, $g(E_1) = 10$, $g(E_2) = 20$, and the canonical partition function at $\\beta = 1$ is $Z(1) = 2\\,e^{6} + 10\\,e^{2} + 20$.\n\nB. Correct the Wang-Landau sampling estimate by adding a constant to $g(E)$ so that $g(E_0)$ equals the known degeneracy, i.e., $g(E) = \\tilde{g}(E) + \\left(d_0 - \\tilde{g}(E_0)\\right)$. For the given data, this yields $g(E_0) = 2$, $g(E_1) = 22$, $g(E_2) = 47$, and $Z(1) = 2\\,e^{6} + 22\\,e^{2} + 47$.\n\nC. Normalize $\\ln \\tilde{g}(E)$ by subtracting $\\left(\\ln d_0 - \\ln \\tilde{g}(E_0)\\right)$ to obtain $\\ln g(E) = \\ln \\tilde{g}(E) - \\left(\\ln d_0 - \\ln \\tilde{g}(E_0)\\right)$. For the given data, this produces $g(E_0) = \\dfrac{25}{2}$, $g(E_1) = \\dfrac{125}{2}$, $g(E_2) = \\dfrac{250}{2}$, and $Z(1) = \\dfrac{25}{2}\\,e^{6} + \\dfrac{125}{2}\\,e^{2} + \\dfrac{250}{2}$.\n\nD. Normalize by converting $\\tilde{g}(E)$ into probabilities via $g_{\\mathrm{prob}}(E) = \\dfrac{\\tilde{g}(E)}{\\sum_{E'} \\tilde{g}(E')}$ and use these to define the partition function as $Z(\\beta) = \\sum_{E} g_{\\mathrm{prob}}(E)\\,e^{-\\beta E}$. For the given data, $\\sum_{E'} \\tilde{g}(E') = 80$, so $g_{\\mathrm{prob}}(E_0) = \\dfrac{5}{80}$, $g_{\\mathrm{prob}}(E_1) = \\dfrac{25}{80}$, $g_{\\mathrm{prob}}(E_2) = \\dfrac{50}{80}$, and $Z(1) = \\dfrac{5}{80}\\,e^{6} + \\dfrac{25}{80}\\,e^{2} + \\dfrac{50}{80}$.",
            "solution": "Begin from the definition of the microcanonical density of states $g(E)$ as the exact count of microstates that have energy $E$. In a finite system, $g(E)$ is an integer-valued function for discrete levels $E$. Wang-Landau sampling (WLS) performs a random walk in energy and updates the estimator of the logarithm of the density of states to flatten the energy histogram. The standard property of the WLS estimator is that it recovers the relative density of states but not its absolute scale, i.e., it determines $\\ln g(E)$ up to an additive constant. Consequently, the estimate $\\tilde{g}(E)$ is proportional to the true $g(E)$ by an unknown multiplicative constant, so there exists a constant $c  0$ such that\n$$\ng(E) = c\\,\\tilde{g}(E), \\quad \\text{equivalently} \\quad \\ln g(E) = \\ln \\tilde{g}(E) + \\ln c.\n$$\n\nTo fix the absolute scale, one uses a known degeneracy at a reference energy $E_{\\mathrm{ref}}$ (here the ground state $E_0$), as is often available from symmetry or exact counting in finite systems. Imposing $g(E_{\\mathrm{ref}}) = d_{\\mathrm{ref}}$ determines the constant:\n$$\nc = \\frac{d_{\\mathrm{ref}}}{\\tilde{g}(E_{\\mathrm{ref}})}, \\quad \\text{or} \\quad \\ln c = \\ln d_{\\mathrm{ref}} - \\ln \\tilde{g}(E_{\\mathrm{ref}}).\n$$\nThis ensures a consistent global normalization of $g(E)$ across all energies. Notably, in the canonical ensemble, probabilities\n$$\np(E) = \\frac{g(E) \\, e^{-\\beta E}}{Z(\\beta)}, \\quad Z(\\beta) = \\sum_{E} g(E) \\, e^{-\\beta E},\n$$\nare invariant under the global rescaling $g(E) \\to c\\,g(E)$ because both numerator and denominator scale by $c$. However, absolute quantities such as the free energy $F(\\beta) = -\\beta^{-1} \\ln Z(\\beta)$ depend on the absolute normalization, which is required for multiscale coupling when combining contributions from different subsystems or scales.\n\nApply the normalization to the given data. The Wang-Landau sampling outputs are\n$$\n\\ln \\tilde{g}(E_0) = \\ln 5, \\quad \\ln \\tilde{g}(E_1) = \\ln 25, \\quad \\ln \\tilde{g}(E_2) = \\ln 50,\n$$\nso\n$$\n\\tilde{g}(E_0) = 5, \\quad \\tilde{g}(E_1) = 25, \\quad \\tilde{g}(E_2) = 50.\n$$\nWith $d_0 = 2$ known at $E_0$, we set\n$$\nc = \\frac{d_0}{\\tilde{g}(E_0)} = \\frac{2}{5}.\n$$\nTherefore, the normalized density of states is\n$$\ng(E_0) = c\\,\\tilde{g}(E_0) = \\frac{2}{5}\\cdot 5 = 2, \\quad\ng(E_1) = c\\,\\tilde{g}(E_1) = \\frac{2}{5}\\cdot 25 = 10, \\quad\ng(E_2) = c\\,\\tilde{g}(E_2) = \\frac{2}{5}\\cdot 50 = 20.\n$$\nAt inverse temperature $\\beta = 1$, the canonical partition function is\n$$\nZ(1) = \\sum_{i=0}^{2} g(E_i)\\, e^{- E_i} = g(E_0)\\, e^{-(-6)} + g(E_1)\\, e^{-(-2)} + g(E_2)\\, e^{-0} = 2\\,e^{6} + 10\\,e^{2} + 20.\n$$\nThis procedure aligns the Wang-Landau sampling estimate with the known ground-state multiplicity, resulting in an absolute normalization suitable for computing free energies and for multiscale coupling.\n\nOption-by-option analysis:\n\n- Option A: It correctly states the principle that the Wang-Landau sampling estimate is normalized by a single global multiplicative constant chosen to match the known degeneracy at the reference energy. It computes $c = 2/5$, yielding $g(E_0) = 2$, $g(E_1) = 10$, $g(E_2) = 20$, and the correct partition function $Z(1) = 2\\,e^{6} + 10\\,e^{2} + 20$. Verdict — Correct.\n\n- Option B: It incorrectly applies an additive correction to $g(E)$ rather than a multiplicative scaling. The quantity $g(E)$ is a count of states, and Wang-Landau sampling errors manifest as a global multiplicative factor, not an additive offset. The proposed $g(E)$ values and partition function are therefore incorrect. Verdict — Incorrect.\n\n- Option C: It proposes adjusting $\\ln \\tilde{g}(E)$ by subtracting $\\left(\\ln d_0 - \\ln \\tilde{g}(E_0)\\right)$, i.e., $\\ln g(E) = \\ln \\tilde{g}(E) - \\left(\\ln d_0 - \\ln \\tilde{g}(E_0)\\right) = \\ln \\tilde{g}(E) - \\ln(2/5)$, which implies $g(E) = \\tilde{g}(E)\\cdot (5/2)$. This is the wrong sign; the correct shift is $\\ln g(E) = \\ln \\tilde{g}(E) + \\left(\\ln d_0 - \\ln \\tilde{g}(E_0)\\right)$, corresponding to $g(E) = \\tilde{g}(E)\\cdot (2/5)$. As written, Option C yields $g(E_0) = 25/2 \\neq 2$, so it fails the normalization requirement. Verdict — Incorrect.\n\n- Option D: It converts $\\tilde{g}(E)$ into probabilities by dividing by their sum and then uses these probabilities in place of a density of states in the partition function. This conflates microcanonical densities with a normalized probability measure and produces an unphysical $Z(\\beta)$ that depends on the arbitrary normalization of probabilities rather than the absolute degeneracies. The canonical partition function must be computed from absolute $g(E)$, not normalized probabilities of energy levels. Verdict — Incorrect.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The versatility of Wang-Landau sampling is fully realized when it is applied to a multi-dimensional space of macroscopic variables, yielding a joint density of states like $g(E,M)$ for energy and magnetization. This powerful output allows for the calculation of any canonical observable at any temperature from a single simulation. This hands-on coding exercise guides you through the entire process for a small Ising model, from understanding the underlying statistical mechanics of joint sampling to implementing the canonical reweighting procedure to compute physical observables like the magnetization distribution $P_{\\beta}(M)$ .",
            "id": "3832210",
            "problem": "Consider a two-dimensional square Ising model with periodic boundary conditions on an $L \\times L$ lattice, with spins $s_{i} \\in \\{-1,+1\\}$ and nearest-neighbor coupling set to unity so that all quantities are dimensionless. Let the energy of a configuration be given by the standard nearest-neighbor Ising Hamiltonian $E(\\mathbf{s}) = -\\sum_{\\langle i,j\\rangle} s_{i} s_{j}$ where the sum is over each unordered nearest-neighbor bond exactly once, and the magnetization be $M(\\mathbf{s}) = \\sum_{i=1}^{L^2} s_{i}$. The joint density of states $g(E,M)$ counts the number of configurations with energy $E$ and magnetization $M$.\n\nYour task is to formulate joint sampling of $g(E,M)$ in the spirit of Wang-Landau (WL) sampling, specify an appropriate binning scheme for the discrete macrostates $(E,M)$, and then use this joint density of states to reweight and obtain the canonical magnetization distribution $P_{\\beta}(M)$ at inverse temperature $\\beta$. You must implement a program that constructs $g(E,M)$ by exact enumeration for small $L$ using the same $(E,M)$ binning you would employ in a joint WL simulation, and then computes $P_{\\beta}(M)$ by canonical reweighting from $g(E,M)$.\n\nStart from fundamental definitions and well-tested facts only; do not use any shortcut formulas that skip the derivation of acceptance criteria or reweighting. In particular, you must:\n- State the target stationary distribution for joint WL sampling over macrostates $(E,M)$ that yields a flat histogram in $(E,M)$ space, and from this derive a Metropolis-Hastings acceptance rule for a single-spin flip proposal that is symmetric in configuration space.\n- Justify an appropriate $(E,M)$ binning for this discrete Ising system to be used in joint WL sampling, and implement the same binning for exact enumeration to construct $g(E,M)$ as integer counts over bins.\n- Using only the canonical ensemble definition, explain how to obtain $P_{\\beta}(M)$ from $g(E,M)$ via reweighting, including proper normalization.\n\nThen implement a self-contained program that:\n- Enumerates all spin configurations for a given $L$ and constructs the exact joint density of states $g(E,M)$ using one bin per distinct energy and one bin per distinct magnetization observed under the model definitions above.\n- For a given inverse temperature $\\beta$, computes the canonical magnetization distribution $P_{\\beta}(M)$ by reweighting from $g(E,M)$ using only the canonical weights and normalizing properly.\n- Computes requested scalar statistics from $P_{\\beta}(M)$ for a small test suite.\n\nUse the following test suite of parameter values to exercise different regimes and edge cases:\n- Test $1$ (boundary case, infinite temperature): $L=2$, $\\beta=0$. Compute $P_{\\beta}(M)$ and return the value at $M=0$.\n- Test $2$ (moderate temperature): $L=2$, $\\beta=1$. Compute the mean absolute magnetization per spin, i.e., $\\langle |m| \\rangle$ with $m = M/L^2$.\n- Test $3$ (near critical region for two-dimensional Ising): $L=3$, $\\beta=0.44068679350977147$. Compute $P_{\\beta}(M)$ and return the value at $M=0$.\n\nAll energies, magnetizations, and inverse temperatures are dimensionless under the given definitions, so no physical unit conversions are required. Angles are not involved. Each requested answer must be a real number. Your program should produce a single line of output containing the results for Tests $1$–$3$ as a comma-separated list enclosed in square brackets, with each floating-point number rounded to six decimal places, in the order specified above, i.e., $[r_1,r_2,r_3]$ where $r_1$ corresponds to Test $1$, $r_2$ to Test $2$, and $r_3$ to Test $3$.",
            "solution": "The problem asks for a theoretical formulation and a computational implementation for analyzing a two-dimensional Ising model. The analysis involves deriving key aspects of joint Wang-Landau sampling, specifying a binning scheme for macrostates, explaining the canonical reweighting procedure, and finally, implementing an exact enumeration for small lattices to compute specific physical quantities.\n\nThe system is defined on an $L \\times L$ square lattice with periodic boundary conditions. The spin at each site $i$ is $s_i \\in \\{-1, +1\\}$. The total number of spins is $N=L^2$. The energy of a configuration $\\mathbf{s} = (s_1, \\dots, s_N)$ is given by the nearest-neighbor Ising Hamiltonian $E(\\mathbf{s}) = -\\sum_{\\langle i,j\\rangle} s_{i} s_{j}$, where the coupling constant is set to unity and the sum is over unique nearest-neighbor pairs. The magnetization is $M(\\mathbf{s}) = \\sum_{i=1}^{N} s_{i}$.\n\nThe problem is valid as it is scientifically grounded in the principles of statistical mechanics, is well-posed with all necessary information provided, and is objective in its formulation.\n\n### 1. Joint Wang-Landau Sampling and Acceptance Criteria\n\nThe goal of Wang-Landau (WL) sampling is to obtain an estimate of the density of states (DOS), in this case, the joint density of states $g(E,M)$, which counts the number of microscopic configurations for each macroscopic state $(E,M)$. The WL algorithm performs a random walk in the space of macrostates, designed to produce a flat histogram across all visited states $(E,M)$. This is achieved by sampling microstates with a probability inversely proportional to the density of states.\n\nThe target stationary distribution for a microstate $\\mathbf{s}$ is therefore $\\pi(\\mathbf{s}) \\propto 1/g(E(\\mathbf{s}), M(\\mathbf{s}))$. The random walk proceeds by proposing a move from a configuration $\\mathbf{s}$ to a new configuration $\\mathbf{s}'$. The problem specifies a single-spin flip proposal mechanism. Flipping a single spin is a symmetric operation: the probability of proposing a move from $\\mathbf{s}$ to $\\mathbf{s}'$ by flipping a specific spin is the same as proposing the reverse move from $\\mathbf{s}'$ to $\\mathbf{s}$ by flipping the same spin. Thus, the proposal probability distribution is symmetric, $p(\\mathbf{s} \\to \\mathbf{s}') = p(\\mathbf{s}' \\to \\mathbf{s})$.\n\nUnder a symmetric proposal, the Metropolis-Hastings acceptance probability $A(\\mathbf{s} \\to \\mathbf{s}')$ simplifies to the Metropolis rule:\n$$A(\\mathbf{s} \\to \\mathbf{s}') = \\min\\left(1, \\frac{\\pi(\\mathbf{s}')}{\\pi(\\mathbf{s})}\\right)$$\nLet the macrostate of $\\mathbf{s}$ be $(E,M)$ and the macrostate of $\\mathbf{s}'$ be $(E',M')$. Substituting our target distribution, we get:\n$$A((E,M) \\to (E',M')) = \\min\\left(1, \\frac{1/g(E',M')}{1/g(E,M)}\\right) = \\min\\left(1, \\frac{g(E,M)}{g(E',M')}\\right)$$\nIn practice, the WL algorithm iteratively builds an estimate for $g(E,M)$, typically by working with its logarithm, $\\ln g(E,M)$. The acceptance probability is then calculated as:\n$$A((E,M) \\to (E',M')) = \\min\\left(1, \\exp[\\ln g(E,M) - \\ln g(E',M')]\\right)$$\nWhenever a macrostate is visited, its corresponding $\\ln g$ value is updated by adding a modification factor, which gradually decreases to refine the DOS estimate.\n\n### 2. Binning Scheme for Macrovariables $(E,M)$\n\nFor the specified Ising model, both energy $E$ and magnetization $M$ are discrete quantities.\n\n**Magnetization ($M$)**: The total magnetization is $M = \\sum_{i=1}^{L^2} s_i$. Let $N_{up}$ be the number of spins with value $+1$ and $N_{down}$ be the number of spins with value $-1$. Then $N_{up} + N_{down} = L^2$ and $M = N_{up} - N_{down}$. Substituting $N_{down} = L^2 - N_{up}$, we find $M = 2N_{up} - L^2$. Since $N_{up}$ can be any integer from $0$ to $L^2$, the possible values of $M$ are $-L^2, -L^2+2, \\dots, L^2-2, L^2$. The magnetization values are integers separated by a step of $\\Delta M = 2$.\n\n**Energy ($E$)**: The energy is $E = -\\sum_{\\langle i,j \\rangle} s_i s_j$. On an $L \\times L$ lattice with periodic boundary conditions, there are $2L^2$ nearest-neighbor bonds. Each term $s_i s_j$ is either $+1$ or $-1$. The energy is therefore an integer. It can be shown that for a single-spin flip, the change in energy $\\Delta E$ is always a multiple of $4$. Consequently, all accessible energy levels for a given lattice are separated by integer multiples of $4$.\n\nGiven that both $E$ and $M$ take on discrete, well-separated values, the most natural and accurate binning scheme is to use one bin for each distinct pair $(E,M)$ that can be realized by the system. This discrete binning avoids any loss of information that would occur with wider bins. For the task of exact enumeration, this corresponds to creating a map or dictionary where each key is a unique $(E,M)$ tuple observed.\n\n### 3. Canonical Reweighting from $g(E,M)$ to $P_{\\beta}(M)$\n\nThe connection between the microcanonical information contained in the density of states $g(E,M)$ and the canonical ensemble properties at an inverse temperature $\\beta = 1/(k_B T)$ is established through the partition function $Z$.\n\nIn the canonical ensemble, the probability of a microstate $\\mathbf{s}$ is given by $P(\\mathbf{s}) = \\frac{e^{-\\beta E(\\mathbf{s})}}{Z}$. The partition function $Z$ is the sum over all microstates:\n$$Z = \\sum_{\\mathbf{s}} e^{-\\beta E(\\mathbf{s})}$$\nWe can restructure this sum by first grouping all microstates that share the same macrostate $(E,M)$. The number of such states is precisely the joint density of states, $g(E,M)$.\n$$Z = \\sum_{E,M} \\sum_{\\substack{\\mathbf{s} \\text{ s.t.} \\\\ E(\\mathbf{s})=E, M(\\mathbf{s})=M}} e^{-\\beta E} = \\sum_{E,M} g(E,M) e^{-\\beta E}$$\nThe probability of observing a particular macrostate $(E,M)$ is the sum of probabilities of all microstates belonging to it:\n$$P_{\\beta}(E,M) = \\frac{g(E,M) e^{-\\beta E}}{Z}$$\nTo obtain the canonical magnetization distribution $P_{\\beta}(M)$, we marginalize this joint probability distribution over all possible energy values $E$:\n$$P_{\\beta}(M) = \\sum_{E} P_{\\beta}(E,M) = \\sum_{E} \\frac{g(E,M) e^{-\\beta E}}{Z}$$\nThe procedure for calculating $P_{\\beta}(M)$ from a known $g(E,M)$ is therefore:\n1.  Calculate the partition function $Z(\\beta) = \\sum_{E,M} g(E,M) e^{-\\beta E}$. The sum is over all $(E,M)$ pairs for which $g(E,M)0$.\n2.  For each possible magnetization value $M_k$, calculate the unnormalized probability $\\tilde{P}_{\\beta}(M_k) = \\sum_{E} g(E,M_k) e^{-\\beta E}$, where the sum is over all energies $E$ associated with $M_k$.\n3.  The normalized probability is $P_{\\beta}(M_k) = \\frac{\\tilde{P}_{\\beta}(M_k)}{Z(\\beta)}$.\n\n### 4. Implementation via Exact Enumeration\n\nFor small lattice sizes, such as $L=2$ and $L=3$, it is feasible to exactly enumerate all $2^{L^2}$ possible spin configurations. The implementation proceeds as follows:\n1.  Initialize an empty dictionary, `g_EM`, to store the joint density of states $g(E,M)$.\n2.  Iterate through all integers from $0$ to $2^{L^2}-1$. Each integer's binary representation maps to a unique spin configuration (e.g., bit $0 \\to s=-1$, bit $1 \\to s=+1$).\n3.  For each configuration, calculate its total energy $E$ and total magnetization $M$. The energy calculation under periodic boundary conditions can be efficiently implemented by summing the product of each spin with its neighbors to the \"right\" and \"down\", which counts each bond exactly once: $E = -\\sum_{i=0}^{L-1}\\sum_{j=0}^{L-1} s_{i,j}(s_{(i+1)\\%L, j} + s_{i,(j+1)\\%L})$.\n4.  Use the calculated $(E,M)$ pair as a key in the `g_EM` dictionary and increment its value (count).\n5.  Once all $2^{L^2}$ configurations have been processed, `g_EM` contains the exact joint density of states.\n6.  Using the `g_EM` dictionary and the reweighting formulas from Part 3, compute the partition function $Z$ and the probability distribution $P_{\\beta}(M)$ for any given $\\beta$.\n7.  Finally, compute the requested statistics from the resulting $P_{\\beta}(M)$ distribution, such as point probabilities $P_{\\beta}(M=M_0)$ or expectation values like $\\langle |m| \\rangle = \\sum_M |M/L^2| P_{\\beta}(M)$.\n\nThis procedure provides an exact solution for the given finite systems, serving as a benchmark for stochastic methods like Wang-Landau sampling.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by enumerating states for small Ising models,\n    calculating the joint density of states g(E,M), and then using\n    canonical reweighting to find properties at given temperatures.\n    \"\"\"\n    test_cases = [\n        # (L, beta, statistic_type)\n        (2, 0.0, \"P(M=0)\"),\n        (2, 1.0, \"|m|\"),\n        (3, 0.44068679350977147, \"P(M=0)\")\n    ]\n\n    results = []\n\n    for L, beta, stat_type in test_cases:\n        N = L * L\n        \n        # 1. Enumerate configurations to get the exact joint DOS g(E,M)\n        # g_em is a dictionary mapping (E, M) tuples to their counts.\n        g_em = {}\n        num_configs = 1  N  # This is 2**N\n\n        for i in range(num_configs):\n            # Generate spin configuration from integer i\n            # bit 0 - spin -1, bit 1 - spin +1\n            spins_1d = np.array([1 if (i  k)  1 else -1 for k in range(N)])\n            spins_2d = spins_1d.reshape((L, L))\n            \n            # Calculate Magnetization M\n            M = np.sum(spins_1d)\n            \n            # Calculate Energy E with periodic boundary conditions.\n            # Summing interaction of each spin with its 'right' and 'down'\n            # neighbor counts each bond exactly once.\n            # np.roll(..., -1, ...) shifts elements to the left/up, so\n            # s_grid[i,j] is multiplied by s_grid[i+1,j] and s_grid[i,j+1]\n            E = -np.sum(spins_2d * (np.roll(spins_2d, -1, axis=0) + \n                                   np.roll(spins_2d, -1, axis=1)))\n\n            # Store in g(E,M) dictionary, using integer keys\n            key = (int(E), int(M))\n            g_em[key] = g_em.get(key, 0) + 1\n\n        # 2. Reweight from g(E,M) to get the canonical distribution P_beta(M)\n        # Find the set of all unique magnetization values\n        M_values = sorted(list(set(m for e, m in g_em.keys())))\n        \n        # Calculate unnormalized probabilities and the partition function Z\n        P_M_unnormalized = {m: 0.0 for m in M_values}\n        Z = 0.0\n\n        for (E, M), count in g_em.items():\n            # Use np.longdouble for precision with large exponentials\n            boltzmann_factor = np.exp(np.longdouble(-beta * E))\n            term = count * boltzmann_factor\n            P_M_unnormalized[M] += term\n            Z += term\n\n        # Normalize to get P_beta(M)\n        if Z == 0.0:\n            # This case should not be reached for finite beta\n            P_M = {m: 0.0 for m in M_values}\n        else:\n            P_M = {m: p / Z for m, p in P_M_unnormalized.items()}\n\n        # 3. Compute the requested statistic\n        if stat_type == \"P(M=0)\":\n            # P_beta(M=0)\n            result = P_M.get(0, 0.0)\n        elif stat_type == \"|m|\":\n            # |m| = |M/L^2|\n            mean_abs_M = sum(abs(m) * p for m, p in P_M.items())\n            result = mean_abs_M / N\n        else:\n            raise ValueError(\"Unknown statistic type\")\n\n        results.append(result)\n\n    # Final print statement in the exact required format\n    final_results_str = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(final_results_str)}]\")\n\nsolve()\n\n```"
        }
    ]
}