{
    "hands_on_practices": [
        {
            "introduction": "傅里叶神经算子 (FNO) 的核心在于其在傅里叶域中执行卷积运算，但我们处理的物理数据通常是实值的。本练习  深入探讨了谱卷积层的实现细节，探索我们如何对可学习的复数权重施加约束，以确保实值输入函数始终映射到实值输出函数。这项实践对于理解 FNO 的基本架构以及傅里叶分析属性与网络设计之间的联系至关重要。",
            "id": "3787660",
            "problem": "考虑一个应用于二维周期域的傅里叶神经算子 (FNO)，用于学习多尺度偏微分方程的解算子。设输入和输出场为实值，分别具有 $C_{\\text{in}}$ 个输入通道和 $C_{\\text{out}}$ 个输出通道。在谱卷积层中，学习到的复值核是一个张量 $R(\\mathbf{k}) \\in \\mathbb{C}^{C_{\\text{out}} \\times C_{\\text{in}}}$，由从截断的矩形集合中提取的离散二维波数 $\\mathbf{k} = (k_{x}, k_{y})$ 索引：\n$$\n\\mathcal{I} = \\{ (k_{x}, k_{y}) \\,:\\, k_{x} \\in \\{-K_{x}, -K_{x}+1, \\dots, K_{x}\\}, \\; k_{y} \\in \\{-K_{y}, -K_{y}+1, \\dots, K_{y}\\} \\},\n$$\n其中 $K_{x}$ 和 $K_{y}$ 是非负整数，指定了每个坐标上的谱截断。\n\n谱卷积的作用是 $\\widehat{y}(\\mathbf{k}) = R(\\mathbf{k}) \\,\\widehat{x}(\\mathbf{k})$，其中 $\\widehat{x}(\\mathbf{k})$ 和 $\\widehat{y}(\\mathbf{k})$ 分别是输入和输出的离散傅里叶变换 (DFT) 系数。利用实值场的 DFT 的基本性质 $\\widehat{f}(-\\mathbf{k}) = \\overline{\\widehat{f}(\\mathbf{k})}$，推导出 $R(\\mathbf{k})$ 必须满足的共轭对称约束，以确保对于所有实值输入，$\\widehat{y}(\\mathbf{k})$ 都对应于一个实值输出场。然后，对于空间维度 $d=2$，通过定义一个代表性的模式半集 $\\mathcal{H} \\subset \\mathcal{I}$ 和实值参数张量，构建 $R(\\mathbf{k})$ 的显式参数化，以确保在整个 $\\mathcal{I}$ 上满足所需的共轭对称性 $R(-\\mathbf{k}) = \\overline{R(\\mathbf{k})}$，包括对零模式的特殊处理。最后，计算在此参数化下指定 $R(\\mathbf{k})$ 所需的独立实标量参数总数的封闭形式表达式，用 $K_{x}$、$K_{y}$、$C_{\\text{in}}$ 和 $C_{\\text{out}}$ 表示。\n\n你的最终答案必须是单一的解析表达式。不需要四舍五入，也不涉及单位。请以最简精确形式表示最终表达式。",
            "solution": "用户希望分析傅里叶神经算子 (FNO) 中谱卷积层的参数化。\n\n### 步骤 1：提取已知条件\n-   域是二维周期域。\n-   输入和输出场是实值的。\n-   输入通道数为 $C_{\\text{in}}$。\n-   输出通道数为 $C_{\\text{out}}$。\n-   学习到的复值核为 $R(\\mathbf{k}) \\in \\mathbb{C}^{C_{\\text{out}} \\times C_{\\text{in}}}$。\n-   波数 $\\mathbf{k} = (k_{x}, k_{y})$ 来自截断集合 $\\mathcal{I} = \\{ (k_{x}, k_{y}) \\,:\\, k_{x} \\in \\{-K_{x}, \\dots, K_{x}\\}, \\; k_{y} \\in \\{-K_{y}, \\dots, K_{y}\\} \\}$。\n-   谱卷积由 $\\widehat{y}(\\mathbf{k}) = R(\\mathbf{k}) \\,\\widehat{x}(\\mathbf{k})$ 给出。\n-   任何实值场 $f$ 的离散傅里叶变换 (DFT) 的性质是 $\\widehat{f}(-\\mathbf{k}) = \\overline{\\widehat{f}(\\mathbf{k})}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n-   **科学依据**：该问题基于傅里叶分析的既定数学原理及其在现代机器学习模型中的应用，特别是傅里叶神经算子。实值函数的 DFT 性质是标准的。该设置在科学上是合理的。\n-   **适定性**：该问题要求推导约束、构建参数化和计算一个数值，所有这些都是基于给定条件的明确定义的数学任务。预期会有一个唯一且有意义的解。\n-   **客观性**：该问题以精确、客观的数学语言陈述。诸如“实值”、“复值核”以及波数集 $\\mathcal{I}$ 的定义等术语都是明确的。\n-   **自洽性与一致性**：提供了所有必要的信息（定义、性质）。没有内部矛盾。\n-   **主题相关性**：该问题正处于*用于多尺度偏微分方程的神经算子*和*多尺度建模与分析*领域的核心。\n\n### 步骤 3：结论与行动\n问题有效。我将继续进行解答。\n\n### 共轭对称约束的推导\n\n问题指出，输入场 $x$ 和输出场 $y$ 都是实值的。根据所提供的实值场的 DFT 性质，它们的傅里叶系数必须满足以下共轭对称条件：\n$$\n\\widehat{x}(-\\mathbf{k}) = \\overline{\\widehat{x}(\\mathbf{k})}\n$$\n$$\n\\widehat{y}(-\\mathbf{k}) = \\overline{\\widehat{y}(\\mathbf{k})}\n$$\n谱卷积层定义为 $\\widehat{y}(\\mathbf{k}) = R(\\mathbf{k}) \\,\\widehat{x}(\\mathbf{k})$。我们可以为波数 $-\\mathbf{k}$ 写出这个关系：\n$$\n\\widehat{y}(-\\mathbf{k}) = R(-\\mathbf{k}) \\,\\widehat{x}(-\\mathbf{k})\n$$\n现在，我们将 $\\widehat{x}$ 和 $\\widehat{y}$ 的对称性质代入此方程：\n$$\n\\overline{\\widehat{y}(\\mathbf{k})} = R(-\\mathbf{k}) \\,\\overline{\\widehat{x}(\\mathbf{k})}\n$$\n从层的原始定义，我们可以对两边取复共轭：\n$$\n\\overline{\\widehat{y}(\\mathbf{k})} = \\overline{R(\\mathbf{k}) \\,\\widehat{x}(\\mathbf{k})} = \\overline{R(\\mathbf{k})} \\;\\overline{\\widehat{x}(\\mathbf{k})}\n$$\n通过令 $\\overline{\\widehat{y}(\\mathbf{k})}$ 的两个表达式相等，我们得到：\n$$\nR(-\\mathbf{k}) \\,\\overline{\\widehat{x}(\\mathbf{k})} = \\overline{R(\\mathbf{k})} \\;\\overline{\\widehat{x}(\\mathbf{k})}\n$$\n这个方程必须对任何实值输入场 $x$ 都成立，这意味着它必须对任何满足实值约束的傅里叶系数集 $\\widehat{x}(\\mathbf{k})$ 都成立。通常情况下，$\\overline{\\widehat{x}(\\mathbf{k})}$ 是一个非零向量，因此我们可以得出结论，矩阵本身必须相等：\n$$\nR(-\\mathbf{k}) = \\overline{R(\\mathbf{k})}\n$$\n这就是对核张量 $R(\\mathbf{k})$ 所需的共轭对称约束。\n\n### 核的显式参数化\n\n为确保满足约束 $R(-\\mathbf{k}) = \\overline{R(\\mathbf{k})}$，我们只需要为具有代表性的“一半”波数定义参数。另一半的值则由对称性确定。所有波数的集合 $\\mathcal{I}$ 关于原点是对称的，即如果 $\\mathbf{k} \\in \\mathcal{I}$，那么 $-\\mathbf{k} \\in \\mathcal{I}$。我们将 $\\mathcal{I}$ 划分为三种类型的波数：零模式 $\\mathbf{k}=(0,0)$，非零模式对 $\\{\\mathbf{k}, -\\mathbf{k}\\}$，以及任何在边界上可能为其自身负值的模式（这仅在零模式下发生）。\n\n让我们定义一个代表性的模式半集 $\\mathcal{H}$ 如下：\n$$\n\\mathcal{H} = \\{ (k_{x}, k_{y}) \\in \\mathcal{I} \\,:\\, k_{y}  0 \\} \\cup \\{ (k_{x}, k_{y}) \\in \\mathcal{I} \\,:\\, k_{y}=0, k_{x} \\ge 0 \\}\n$$\n这个集合为每对 $\\{\\mathbf{k}, -\\mathbf{k}\\}$（对于 $\\mathbf{k} \\neq (0,0)$）包含恰好一个代表，并包括零模式 $\\mathbf{k}=(0,0)$。\n\n我们可以使用为 $\\mathbf{k} \\in \\mathcal{H}$ 定义的两个实值张量 $A(\\mathbf{k}), B(\\mathbf{k}) \\in \\mathbb{R}^{C_{\\text{out}} \\times C_{\\text{in}}}$ 来参数化复值核 $R(\\mathbf{k})$。构建如下：\n1.  对于任何 $\\mathbf{k} \\in \\mathcal{H}$：\n    -   如果 $\\mathbf{k}=(0,0)$，对称性约束为 $R(0,0) = \\overline{R(0,0)}$，这意味着 $R(0,0)$ 必须是一个实矩阵。因此，我们设置 $R(0,0) = A(0,0)$ 并强制其虚部为零。\n    -   如果 $\\mathbf{k} \\in \\mathcal{H}$ 且 $\\mathbf{k} \\neq (0,0)$，我们定义 $R(\\mathbf{k}) = A(\\mathbf{k}) + i B(\\mathbf{k})$。\n2.  对于任何 $\\mathbf{k} \\in \\mathcal{I} \\setminus \\mathcal{H}$：\n    -   通过 $\\mathcal{H}$ 的构造，我们知道 $-\\mathbf{k} \\in \\mathcal{H}$ 且 $-\\mathbf{k} \\neq (0,0)$。然后我们使用对称性约束来定义 $R(\\mathbf{k})$：\n    $$\n    R(\\mathbf{k}) = \\overline{R(-\\mathbf{k})} = \\overline{A(-\\mathbf{k}) + i B(-\\mathbf{k})} = A(-\\mathbf{k}) - i B(-\\mathbf{k})\n    $$\n这种构造通过设计保证了对于所有 $\\mathbf{k} \\in \\mathcal{I}$ 都有 $R(-\\mathbf{k}) = \\overline{R(\\mathbf{k})}$。独立的可学习参数是所有 $\\mathbf{k} \\in \\mathcal{H}$ 的实张量 $A(\\mathbf{k})$ 和所有 $\\mathbf{k} \\in \\mathcal{H} \\setminus \\{(0,0)\\}$ 的实张量 $B(\\mathbf{k})$ 的条目。\n\n### 总参数数量的计算\n\n我们需要计算在整个集合 $\\mathcal{I}$ 上指定核 $R(\\mathbf{k})$ 所需的独立实标量参数的总数。这等同于计算我们构造中使用的实张量 $A$ 和 $B$ 中的标量参数数量。\n\n设 $N = C_{\\text{in}} C_{\\text{out}}$ 为单通道矩阵中的条目数。\n$\\mathcal{I}$ 中的总波数为 $|\\mathcal{I}| = (2K_{x}+1)(2K_{y}+1)$。\n\n我们可以通过考虑基于对称性的不同模式类型来计算参数：\n1.  **零模式 $\\mathbf{k}=(0,0)$**：核 $R(0,0)$ 必须是一个实矩阵。参数数量是这个实矩阵中的条目数，即 $C_{\\text{out}} \\times C_{\\text{in}} = N$。\n\n2.  **非零模式 $\\mathbf{k} \\neq (0,0)$**：这些模式可以被分组为对 $\\{\\mathbf{k}, -\\mathbf{k}\\}$。非零模式的总数为 $|\\mathcal{I}| - 1$。这样的对的数量为 $\\frac{|\\mathcal{I}|-1}{2}$。对于每一对，我们只需要存储一个代表（比如 $\\mathbf{k} \\in \\mathcal{H}$）的参数。核 $R(\\mathbf{k})$ 是一个通用的复矩阵，其 $N$ 个条目中的每一个都需要 2 个实数（实部和虚部）。因此，对于每一对，我们需要 $2N$ 个参数。$R(-\\mathbf{k})$ 的值随后被完全确定。\n    所有这些对的参数数量是：\n    $$\n    \\left( \\frac{|\\mathcal{I}|-1}{2} \\right) \\times (2N) = (|\\mathcal{I}|-1)N\n    $$\n\n独立实标量参数的总数是零模式参数和所有非零模式对参数的总和。\n$$\n\\text{总参数} = (\\text{为 } \\mathbf{k}=0 \\text{ 的参数}) + (\\text{为 } \\mathbf{k} \\neq 0 \\text{ 的参数})\n$$\n$$\n\\text{总参数} = N + (|\\mathcal{I}|-1)N = N + |\\mathcal{I}|N - N = |\\mathcal{I}|N\n$$\n代入 $|\\mathcal{I}|$ 和 $N$ 的表达式：\n$$\n\\text{总参数} = ((2K_{x}+1)(2K_{y}+1)) \\times (C_{\\text{in}}C_{\\text{out}})\n$$\n因此，独立实参数的总数为：\n$$\nC_{\\text{in}}C_{\\text{out}}(2K_{x}+1)(2K_{y}+1)\n$$\n这个优雅的结果表明，参数数量恰好是为频率网格 $\\mathcal{I}$ 中的每个模式存储一个大小为 $C_{\\text{out}} \\times C_{\\text{in}}$ 的实矩阵所需的实参数数量。",
            "answer": "$$\n\\boxed{C_{\\text{in}}C_{\\text{out}}(2K_{x}+1)(2K_{y}+1)}\n$$"
        },
        {
            "introduction": "虽然标准傅里叶神经算子 (FNO) 借助快速傅里叶变换 (FFT) 在周期性域上表现出色，但许多现实世界的问题涉及更复杂的边界条件，如狄利克雷 (Dirichlet) 或诺伊曼 (Neumann) 边界。这项实践  挑战我们去推广 FNO 的核心原理：在一个能将微分算子对角化的基中进行运算。通过为非周期性问题推导正确的本征基（例如正弦/余弦变换），我们学习了如何将神经算子应用于更广泛的物理系统，从而在经典偏微分方程理论与现代深度学习之间架起了一座桥梁。",
            "id": "3787628",
            "problem": "考虑在矩形域 $\\Omega = (0,L_{x}) \\times (0,L_{y})$ 上的二阶线性椭圆偏微分方程 $-\\kappa \\Delta u + \\mu u = f$，其中 $\\kappa  0$，$\\mu \\ge 0$，且 $f$ 是一个平方可积的强迫项。在垂直边界上施加齐次狄利克雷边界条件，在水平边界上施加齐次诺伊曼边界条件，即对所有 $y \\in [0,L_{y}]$ 有 $u(0,y) = u(L_{x},y) = 0$，对所有 $x \\in [0,L_{x}]$ 有 $\\partial_{y} u(x,0) = \\partial_{y} u(x,L_{y}) = 0$。利用斯图姆-刘维尔理论和分离变量法的原理，推导出一个与这些边界条件兼容的 $\\Omega$ 上的标准正交特征函数基，并确定拉普拉斯算子对应的特征值。\n\n假设系数为常数，并利用 $u$ 和 $f$ 在此基下的正交展开来表达展开系数之间的谱关系。然后，通过将 $-\\kappa \\Delta + \\mu$ 的逆视为一个在此基下对角化的卷积型算子，推导出将模式 $(k,\\ell)$ 下 $f$ 的系数映射到同一模式下 $u$ 的系数的闭式谱乘子 $m_{k,\\ell}$。最后，当 $L_{x} = 2$, $L_{y} = 3$, $\\kappa = 0.5$, $\\mu = 0.2$ 时，计算 $m_{2,1}$ 的数值。将最终的数值系数表示为一个无量纲数，并四舍五入到四位有效数字。\n\n在您的推导中，明确指出如何通过用与边界条件兼容的正弦/余弦变换基替换标准的周期性傅里叶基，将谱乘子整合到傅里叶神经算子（FNO, Fourier Neural Operator）层中，推导过程不使用任何快捷公式，而是从正交特征函数展开的基本定义和性质出发。",
            "solution": "该问题要求解决一个关于在混合边界条件下使用谱方法求解椭圆型偏微分方程的问题，并将其与傅里叶神经算子的推广联系起来。\n\n### 步骤1：推导拉普拉斯算子的特征函数与特征值\n\n我们求解在给定边界条件下的负拉普拉斯算子 $-\\Delta$ 的特征值问题：\n$$ -\\Delta \\phi = \\lambda \\phi \\quad \\text{在 } \\Omega \\text{ 上} $$\n其中 $\\phi(0,y) = \\phi(L_{x},y) = 0$ 且 $\\partial_{y} \\phi(x,0) = \\partial_{y} \\phi(x,L_{y}) = 0$。\n我们使用分离变量法，设 $\\phi(x,y) = X(x)Y(y)$。代入PDE得到：\n$$ -\\frac{X''(x)}{X(x)} - \\frac{Y''(y)}{Y(y)} = \\lambda $$\n这可以分解为两个一维的斯图姆-刘维尔问题，令 $-\\frac{X''(x)}{X(x)} = \\lambda_{x}$ 且 $-\\frac{Y''(y)}{Y(y)} = \\lambda_{y}$。\n\n**关于 $X(x)$ 的问题**：$X''(x) + \\lambda_x X(x) = 0$，边界条件为 $X(0) = X(L_x) = 0$。非平凡解在 $\\lambda_x > 0$ 时存在，特征值为 $\\lambda_{x,k} = (\\frac{k\\pi}{L_x})^2$，对应的特征函数为 $X_k(x) = \\sin(\\frac{k\\pi x}{L_x})$，其中 $k = 1, 2, 3, \\ldots$。\n\n**关于 $Y(y)$ 的问题**：$Y''(y) + \\lambda_y Y(y) = 0$，边界条件为 $Y'(0) = Y'(L_y) = 0$。非平凡解在 $\\lambda_y \\ge 0$ 时存在。\n- 当 $\\lambda_y > 0$ 时，特征值为 $\\lambda_{y,\\ell} = (\\frac{\\ell\\pi}{L_y})^2$，对应的特征函数为 $Y_\\ell(y) = \\cos(\\frac{\\ell\\pi y}{L_y})$，其中 $\\ell = 1, 2, 3, \\ldots$。\n- 当 $\\lambda_y = 0$ 时，解为 $Y(y) = C_1 y + C_2$。边界条件要求 $C_1 = 0$，因此常数函数 $Y_0(y) = 1$ 是一个有效的特征函数。\n综合起来，特征值为 $\\lambda_{y,\\ell} = (\\frac{\\ell\\pi}{L_y})^2$，其中 $\\ell = 0, 1, 2, \\ldots$。\n\n**二维特征函数与特征值**：\n算子 $-\\Delta$ 的特征函数为 $\\phi_{k,\\ell}(x,y) = \\sin\\left(\\frac{k\\pi x}{L_x}\\right) \\cos\\left(\\frac{\\ell\\pi y}{L_y}\\right)$，其中 $k \\ge 1, \\ell \\ge 0$。\n对应的特征值为 $\\lambda_{k,\\ell} = \\lambda_{x,k} + \\lambda_{y,\\ell} = \\left(\\frac{k\\pi}{L_x}\\right)^2 + \\left(\\frac{\\ell\\pi}{L_y}\\right)^2$。\n\n### 步骤2：推导谱关系\n\n我们将解 $u(x,y)$ 和强迫项 $f(x,y)$ 在由 $\\phi_{k,\\ell}$ 构成的正交基中展开：\n$$ u(x,y) = \\sum_{k=1}^{\\infty}\\sum_{\\ell=0}^{\\infty} \\hat{u}_{k,\\ell} \\phi_{k,\\ell}(x,y) $$\n$$ f(x,y) = \\sum_{k=1}^{\\infty}\\sum_{\\ell=0}^{\\infty} \\hat{f}_{k,\\ell} \\phi_{k,\\ell}(x,y) $$\n将这些展开式代入原PDE $-\\kappa \\Delta u + \\mu u = f$，并利用 $-\\Delta \\phi_{k,\\ell} = \\lambda_{k,\\ell} \\phi_{k,\\ell}$：\n$$ \\sum_{k,\\ell} \\left( \\kappa \\lambda_{k,\\ell} \\hat{u}_{k,\\ell} + \\mu \\hat{u}_{k,\\ell} \\right) \\phi_{k,\\ell} = \\sum_{k,\\ell} \\hat{f}_{k,\\ell} \\phi_{k,\\ell} $$\n由于基函数的正交性，我们可以对每个模式 $(k,\\ell)$ 的系数进行匹配：\n$$ (\\kappa \\lambda_{k,\\ell} + \\mu) \\hat{u}_{k,\\ell} = \\hat{f}_{k,\\ell} $$\n这就是解和强迫项展开系数之间的谱关系。\n\n### 步骤3：推导谱乘子\n\n谱乘子 $m_{k,\\ell}$ 被定义为 $\\hat{u}_{k,\\ell} = m_{k,\\ell} \\hat{f}_{k,\\ell}$。从上一步的谱关系中，我们可以直接解出 $m_{k,\\ell}$：\n$$ m_{k,\\ell} = \\frac{1}{\\kappa \\lambda_{k,\\ell} + \\mu} $$\n代入特征值 $\\lambda_{k,\\ell}$ 的表达式：\n$$ m_{k,\\ell} = \\frac{1}{\\kappa \\left[ \\left(\\frac{k\\pi}{L_x}\\right)^2 + \\left(\\frac{\\ell\\pi}{L_y}\\right)^2 \\right] + \\mu} $$\n\n### 步骤4：数值计算\n\n我们计算当 $L_x = 2$, $L_y = 3$, $\\kappa = 0.5$, $\\mu = 0.2$ 时，$m_{2,1}$ 的值，对应模式 $(k,\\ell) = (2,1)$：\n$$ m_{2,1} = \\frac{1}{(0.5) \\left[ \\left(\\frac{2\\pi}{2}\\right)^2 + \\left(\\frac{1\\pi}{3}\\right)^2 \\right] + 0.2} $$\n$$ m_{2,1} = \\frac{1}{0.5 \\left[ \\pi^2 + \\frac{\\pi^2}{9} \\right] + 0.2} $$\n$$ m_{2,1} = \\frac{1}{0.5 \\left( \\frac{10\\pi^2}{9} \\right) + 0.2} $$\n$$ m_{2,1} = \\frac{1}{\\frac{5\\pi^2}{9} + 0.2} $$\n使用 $\\pi \\approx 3.14159$，$\\pi^2 \\approx 9.8696044$：\n$$ m_{2,1} = \\frac{1}{\\frac{5 \\times 9.8696044}{9} + 0.2} = \\frac{1}{5.4831136 + 0.2} = \\frac{1}{5.6831136} \\approx 0.17596 $$\n四舍五入到四位有效数字，结果为 $0.1760$。\n\n### 步骤5：与傅里叶神经算子 (FNO) 的联系\n\n上述推导揭示，对于该PDE，解算子 $\\mathcal{G}: f \\mapsto u$ 在由特征函数 $\\{\\phi_{k,\\ell}\\}$ 构成的谱域中表现为一个简单的乘法运算。这意味着 $\\mathcal{G}$ 是一个卷积型算子，并且被我们推导出的正弦-余弦基函数所对角化。对角线上的元素正是谱乘子 $m_{k,\\ell}$。\n\n标准的傅里叶神经算子（FNO）适用于周期性边界条件，因为它的默认谱基是复指数 $\\{e^{i \\mathbf{k} \\cdot \\mathbf{x}}\\}$，其对应的变换是傅里叶变换（可通过快速傅里叶变换 FFT 高效实现）。\n\n为了将FNO架构应用于本问题中的混合非周期性边界条件，我们必须将标准的傅里叶基替换为与问题相适应的特征基。一个广义FNO层的运算流程如下：\n1.  **正变换**：对输入函数 $v(x,y)$，我们不再使用FFT，而是应用一个能将其投影到我们推导出的特征基上的变换。这在实践中通过沿 $x$ 维度执行离散正弦变换（DST）和沿 $y$ 维度执行离散余弦变换（DCT）来实现。该变换计算出谱系数 $\\hat{v}_{k,\\ell}$。\n2.  **谱域乘法**：在谱域中，将系数与一个可学习的权重张量 $R_{k,\\ell}$ 进行逐点相乘。这些权重是神经网络对真实谱乘子 $m_{k,\\ell}$ 的近似。\n3.  **逆变换**：对修改后的系数应用逆变换（逆DST和逆DCT），将结果转换回物理空间。\n4.  **局部路径与激活**：与标准FNO一样，将上述结果与输入的局部线性变换（通过 $1 \\times 1$ 卷积实现）相加，然后通过一个非线性激活函数。\n\n通过选择能够对角化底层微分算子的变换基（DST/DCT），我们为FNO提供了学习解算子的最高效的表示。可学习的谱滤波器 $R_{k,\\ell}$ 只需要学习一个对角算子，这比在非最优基（例如，对非周期问题使用标准傅里叶基）中学习一个更复杂的算子要容易得多，从而提高了参数效率和训练稳定性。",
            "answer": "$$ \\boxed{0.1760} $$"
        },
        {
            "introduction": "深度神经网络在训练过程中容易出现不稳定性，神经算子也不例外。本练习  呈现了一个真实场景：一个深度 FNO 的解导数出现爆炸性增长，这是多尺度模拟中不稳定的常见迹象。这项实践提供了一个机会，让我们学习使用函数空间范数来诊断问题，并探索从经典的去混叠技术到现代的算子范数约束等一系列高级修正措施，这些对于训练稳健可靠的模型至关重要。",
            "id": "3787624",
            "problem": "考虑一个傅里叶神经算子 (FNO) 层，该层作用于一个在 $N^d$ 个点的均匀网格上离散化的 $d$ 维环面 $\\Omega = [0,2\\pi]^d$ 上的周期场。令 $\\mathcal{F}$ 表示离散傅里叶变换，令 $u^\\ell$ 表示第 $\\ell$ 层的隐藏场。一个典型的 FNO 层可以写作 $u^{\\ell+1} = \\sigma\\!\\left(\\mathcal{F}^{-1}\\!\\left(M^\\ell \\cdot \\mathcal{F}u^\\ell\\right) + S^\\ell u^\\ell + b^\\ell\\right)$，其中 $M^\\ell$ 是一个可学习的复值谱乘子，限制在模 $\\{k \\in \\mathbb{Z}^d: |k| \\le k_{\\max}\\}$ 上，$S^\\ell$ 是一个在物理空间中可学习的局部线性算子，$b^\\ell$ 是一个偏置项，而 $\\sigma$ 是一个逐点非线性函数。Sobolev 空间 $H^1(\\Omega)$ 的范数定义为 $\\|u\\|_{H^1}^2 = \\int_\\Omega \\left(|u(x)|^2 + |\\nabla u(x)|^2\\right)\\,dx$，根据 Parseval 恒等式，这等价于 $\\|u\\|_{H^1}^2 = \\sum_{k \\in \\mathbb{Z}^d} \\left(1+|k|^2\\right)\\,|u_k|^2$，其中 $u_k$ 是傅里叶系数。假设该网络被训练来近似一个多尺度偏微分方程到解的算子 $u_\\theta$，其输入在多个尺度范围内表现出显著的能量。\n\n在实践中，物理空间中的逐点非线性函数 $\\sigma$ 会产生高频内容，其傅里叶支撑集超出了谱截断 $\\{|k|\\le k_{\\max}\\}$；因此，投影回截断谱会引发混叠（aliasing）。此外，激进的谱乘子和未归一化的残差路径会导致 $\\|u^\\ell\\|_{H^1}$ 的逐层增长，这与学习到的多尺度动力学离散化中的不稳定性有关。你的任务是设计一个诊断测试，利用 $\\|u^\\ell\\|_{H^1}$ 跨层的增长行为来检测不稳定性，并提出一种修正性的架构修改，该修改以与稳定的多尺度建模相一致的方式，直接解决混叠和/或归一化问题。\n\n假设你在一个代表性的验证集上观察到，对于一定范围内的层 $\\ell$，逐层增长因子 $r_\\ell = \\|u^{\\ell+1}\\|_{H^1}/\\|u^\\ell\\|_{H^1}$ 满足 $r_\\ell \\approx 1.25$，并且在应用 $\\sigma$ 之后，高频带 $B = \\{k: 2k_{\\max}/3  |k| \\le k_{\\max}\\}$ 中的 $H^1$ 加权谱能量的比例超过 $0.3$。从第一性原理出发，定义一个适用于 FNO 类别和多尺度 PDE 设置的诊断方法和一种修正性修改。\n\n选择所有正确指定了基于 $\\|u^\\ell\\|_{H^1}$ 增长的可靠诊断方法和有效的修正性架构修改的选项。\n\nA. 诊断：在验证输入上计算 $r_\\ell = \\|u^{\\ell+1}\\|_{H^1}/\\|u^\\ell\\|_{H^1}$，如果几何平均值 $\\left(\\prod_{\\ell=0}^{L-1} r_\\ell\\right)^{1/L}$ 超过一个大于 $1$ 的阈值，则标记为不稳定。修正：引入 $2/3$ 法则去混叠，即在应用逐点非线性函数之前，在每个维度上对场进行零填充至大小 $3N/2$，然后进行低通滤波并截断回 $N$。并插入一个逐层 Sobolev 归一化，通过选择 $\\alpha_\\ell$ 使得 $\\|u^{\\ell+1}\\|_{H^1} \\le \\beta \\|u^\\ell\\|_{H^1}$（对于给定的 $\\beta \\approx 1$）来重新缩放 $u^{\\ell+1} \\leftarrow \\alpha_\\ell u^{\\ell+1}$。\n\nB. 诊断：只监控跨层的 $L^2(\\Omega)$ 范数 $\\|u^\\ell\\|_{L^2}$，如果 $\\|u^\\ell\\|_{L^2}$ 单调增长，则标记为不稳定。修正：在每个非线性函数之后，在物理空间中应用批归一化 (batch normalization)，而不对 $M^\\ell$ 进行任何谱滤波或约束。\n\nC. 诊断：追踪跨层的 $\\max_{k} |u_k^\\ell|$，如果它增加，则标记为不稳定。修正：增加截断带宽 $k_{\\max}$，同时保持非线性函数和层缩放不变。\n\nD. 诊断：对于每一层，通过在验证输入上进行幂迭代，估计层映射关于 $H^1$ 内积的 Fréchet 导数的最大奇异值（谱半径）；如果该估计值超过 $1$，则标记为不稳定。修正：在谱乘子和残差路径上施加谱归一化，以将 $H^1$ 中的整体 Lipschitz 常数严格限制在 $1$ 以下（例如，重新缩放 $M^\\ell$ 和 $S^\\ell$，使得从 $H^1$ 到 $H^1$ 的诱导算子范数小于 $1$），从而确保在 $H^1$ 中每层都是一个收缩映射。",
            "solution": "该问题要求为傅里叶神经算子 (FNO) 设计一种不稳定性诊断测试和相应的修正性架构修改。这种不稳定的特征是隐藏场的 Sobolev $H^1$ 范数的逐层增长，其根本原因被确定为来自逐点非线性函数的混叠效应以及层更新中线性算子的放大作用。\n\n核心问题是不稳定性，表现为 $H^1$ 范数跨层指数级增长（增长因子 $r_\\ell \\approx 1.25 > 1$）。这种增长会导致激活值和梯度爆炸，从而阻碍成功训练。一个有效的解决方案必须解决其根本原因：层的算子范数过大导致的放大作用，以及混叠可能引起的误差累积。\n\n### 选项分析\n\n**选项 A 分析**\n- **诊断**：计算 $H^1$ 范数的逐层增长因子 $r_\\ell$ 的几何平均值。如果该平均值持续大于1，表明范数在网络深度上呈指数增长。这是一个直接、经验性且可靠的诊断方法，与问题中观察到的现象 $r_\\ell \\approx 1.25$ 完全吻合。\n- **修正**：此修正包含两个部分。\n  1.  **去混叠**：问题描述中高频带的能量集中强烈暗示混叠是问题的来源之一。引入的**2/3法则去混叠**（通过零填充进行过采样计算非线性项，然后截断回原始分辨率）是伪谱法中用于精确计算二次非线性的标准技术，能有效消除混叠误差。\n  2.  **归一化**：通过显式重新缩放每层的输出，强制执行 $\\|u^{\\ell+1}\\|_{H^1} \\le \\beta \\|u^\\ell\\|_{H^1}$ (其中 $\\beta \\approx 1$ )，直接阻止了范数的逐层爆炸。这是一种“强力”但保证稳定性的方法。\n  这种双管齐下的修正方法既解决了混叠问题，又解决了放大问题，因此是有效且恰当的。\n- **结论**：正确。\n\n**选项 B 分析**\n- **诊断**：仅监控 $L^2$ 范数。对于PDE解，这不足以诊断不稳定性。一个函数的 $L^2$ 范数可以保持有界，而其导数（以及 $H^1$ 范数）爆炸，这对应于解变得高度振荡。对于物理模拟，控制导数至关重要。\n- **修正**：应用批归一化 (Batch Normalization)。标准批归一化是针对特征的逐点统计量进行归一化，它并非为控制涉及导数的函数空间范数（如 $H^1$）而设计。它不能解决傅里叶域的混叠问题，也无法直接约束谱算子 $M^\\ell$ 的放大特性。\n- **结论**：不正确。诊断方法不充分，修正方法没有针对问题的核心机制。\n\n**选项 C 分析**\n- **诊断**：追踪单个傅里叶系数的最大值 $\\max_{k} |u_k^\\ell|$。这不能代表整体稳定性，因为能量可以分布在许多模态上，导致范数增长，而单个系数可能不增长。\n- **修正**：增加截断带宽 $k_{\\max}$。这可能会加剧问题。如果不解决算子的放大特性，为不稳定增长提供更多模态只会让情况变得更糟，并增加计算成本。\n- **结论**：不正确。诊断指标不可靠，修正措施是无效甚至有害的。\n\n**选项 D 分析**\n- **诊断**：通过幂迭代估计层映射的 Fréchet 导数在 $H^1$ 空间中的算子范数（谱半径）。这是从动力系统理论角度分析稳定性的最根本方法。如果算子范数大于1，则意味着局部扰动会被放大，导致不稳定性。这是一种理论上极其严谨的诊断方法。\n- **修正**：通过谱归一化等方法，对算子 $M^\\ell$ 和 $S^\\ell$ 施加约束，以确保整个层映射的 $H^1$ Lipschitz常数小于1。这意味着每一层都成为一个收缩映射。收缩映射的复合仍然是收缩的，从而从根本上保证了网络的全局稳定性，防止了任何指数增长。这是一个有原则且强大的修正方法。\n- **结论**：正确。该选项提供了一个理论上最严谨的诊断方法和一个能保证稳定性的强大修正措施。\n\n综上所述，选项A和D都提出了有效且原理正确的诊断与修正策略。选项A更偏向于一种直接解决观察现象的工程实践，而选项D提供了一种更根本的、基于算子理论的数学保证。",
            "answer": "$$\\boxed{AD}$$"
        }
    ]
}