{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of physical modeling is the preservation of fundamental symmetries. For particles in an isotropic system, the interaction energy must be rotationally invariant, depending only on the distance between particles, not their orientation in space. This exercise  provides a concrete, computational demonstration of how a naive coarse-graining map can fail to respect this symmetry, leading to unphysical artifacts, and then shows how a simple machine-learned parameterization correctly restores it.",
            "id": "3776321",
            "problem": "You are given a two-particle microscopic system in two spatial dimensions with a harmonic bond interaction between particles at positions $\\mathbf{r}_1 \\in \\mathbb{R}^2$ and $\\mathbf{r}_2 \\in \\mathbb{R}^2$. The microscopic interparticle distance is $d = \\|\\mathbf{r}_2 - \\mathbf{r}_1\\|_2$, and the microscopic potential energy is $U(d) = \\frac{1}{2} k (d - r_0)^2$, where $k > 0$ is a stiffness and $r_0 > 0$ is the rest length. This form is a well-tested model for bonded interactions and depends only on the Euclidean distance, which is invariant under rotations.\n\nA coarse-graining map that violates rotational invariance defines an anisotropic surrogate distance for a displacement $\\Delta \\mathbf{r} = \\mathbf{r}_2 - \\mathbf{r}_1$ by $\\tilde{d}_\\gamma(\\Delta \\mathbf{r}) = \\sqrt{(\\Delta x)^2 + \\gamma (\\Delta y)^2}$, where $\\gamma > 0$ is a parameter and $\\Delta \\mathbf{r} = (\\Delta x, \\Delta y)$. This surrogate is not invariant under arbitrary rotations unless $\\gamma = 1$. A naive coarse-grained prediction using this map would set $\\tilde{U}_\\gamma(\\Delta \\mathbf{r}) = \\frac{1}{2} k (\\tilde{d}_\\gamma(\\Delta \\mathbf{r}) - r_0)^2$, which may be inconsistent with rotational symmetry of the underlying system.\n\nYour tasks are to compute the error induced by using the anisotropic surrogate in place of the Euclidean distance and then to propose and instantiate a corrected, symmetry-preserving parameterization learned from data. All quantities are dimensionless, and all angles must be treated in radians.\n\nFundamental bases and definitions to use:\n- The Euclidean norm is $\\|\\mathbf{v}\\|_2 = \\sqrt{v_x^2 + v_y^2}$.\n- The harmonic bond energy is $U(d) = \\frac{1}{2} k (d - r_0)^2$, which depends only on the scalar distance $d$.\n- Rotational invariance for a two-body potential means the energy depends only on $d$ and not on the orientation of $\\Delta \\mathbf{r}$.\n\nProgram requirements:\n1. Use $k = 10$ and $r_0 = 1$.\n2. Parameterize a set of test configurations by a true distance $d$ and an orientation $\\phi$, with positions constructed so that $\\Delta \\mathbf{r}(d,\\phi) = (d \\cos \\phi, d \\sin \\phi)$.\n3. For each test case with a specified $\\gamma$, $d$, and $\\phi$, compute the absolute error $E_{\\text{viol}} = \\left|\\tilde{U}_\\gamma(\\Delta \\mathbf{r}(d,\\phi)) - U(d)\\right|$ due to the violating coarse-graining map.\n4. Propose a symmetry-preserving machine-learned coarse-grained parameterization $\\hat{U}(d) = a_0 + a_1 d + a_2 d^2$ that depends only on the Euclidean distance $d$ and estimate $(a_0,a_1,a_2)$ by least squares from a synthetic training set $\\{(d_j, U(d_j))\\}_{j=1}^M$ with distances spanning $[0.5, 2.5]$. Use a uniform grid of $M = 101$ distances on this interval. Then, for each test case, compute the absolute error $E_{\\text{corr}} = \\left|\\hat{U}(d) - U(d)\\right|$ of the corrected parameterization.\n5. The final output must be a single line containing a comma-separated list enclosed in square brackets. For each test case in order, output two numbers: first $E_{\\text{viol}}$, then $E_{\\text{corr}}$. Round each number to within $10^{-10}$.\n6. Angle inputs are in radians.\n\nTest suite to be used by your program, specified as tuples $(\\gamma, d, \\phi)$:\n- $(0.25, 1.0, 0.0)$\n- $(0.25, 1.0, \\pi/2)$\n- $(4.0, 1.0, \\pi/2)$\n- $(0.25, 2.0, \\pi/4)$\n- $(1.0, 0.5, 1.0)$\n- $(4.0, 0.5, \\pi/2)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,\\dots]$), where the list contains, in order, $[E_{\\text{viol}}^{(1)}, E_{\\text{corr}}^{(1)}, E_{\\text{viol}}^{(2)}, E_{\\text{corr}}^{(2)}, \\dots]$ for the test suite above. All outputs are dimensionless real numbers rounded to within $10^{-10}$.",
            "solution": "### Step 1: Extract Givens\n-   System: Two particles at positions $\\mathbf{r}_1, \\mathbf{r}_2 \\in \\mathbb{R}^2$.\n-   Microscopic interparticle distance: $d = \\|\\mathbf{r}_2 - \\mathbf{r}_1\\|_2$.\n-   Microscopic potential energy: $U(d) = \\frac{1}{2} k (d - r_0)^2$.\n-   Constants: stiffness $k > 0$, rest length $r_0 > 0$.\n-   Anisotropic surrogate distance: $\\tilde{d}_\\gamma(\\Delta \\mathbf{r}) = \\sqrt{(\\Delta x)^2 + \\gamma (\\Delta y)^2}$ for $\\Delta \\mathbf{r} = (\\Delta x, \\Delta y)$ and $\\gamma > 0$.\n-   Naive coarse-grained potential: $\\tilde{U}_\\gamma(\\Delta \\mathbf{r}) = \\frac{1}{2} k (\\tilde{d}_\\gamma(\\Delta \\mathbf{r}) - r_0)^2$.\n-   Test configuration parameterization: $\\Delta \\mathbf{r}(d,\\phi) = (d \\cos \\phi, d \\sin \\phi)$.\n-   Violation error: $E_{\\text{viol}} = \\left|\\tilde{U}_\\gamma(\\Delta \\mathbf{r}(d,\\phi)) - U(d)\\right|$.\n-   Symmetry-preserving machine-learned potential: $\\hat{U}(d) = a_0 + a_1 d + a_2 d^2$.\n-   Corrected error: $E_{\\text{corr}} = \\left|\\hat{U}(d) - U(d)\\right|$.\n-   Training data for learning coefficients $(a_0, a_1, a_2)$: A set $\\{(d_j, U(d_j))\\}_{j=1}^M$ with $M = 101$ points from a uniform grid of distances $d_j \\in [0.5, 2.5]$.\n-   Numerical values for constants: $k = 10$, $r_0 = 1$.\n-   Test suite: A list of tuples $(\\gamma, d, \\phi)$ to be evaluated.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to a rigorous validation check.\n1.  **Scientific Grounding**: The problem is well-grounded in the principles of computational statistical mechanics and multiscale modeling. The harmonic potential is a standard model for covalent bonds. The issue of a coarse-graining map breaking a fundamental symmetry (rotational invariance) and the use of machine learning (polynomial regression) to derive a corrected, symmetry-preserving potential are central and valid concepts in the field.\n2.  **Well-Posedness**: The problem is fully specified. All functions, parameters, constants, and evaluation procedures are explicitly defined. The tasks are unambiguous and lead to a unique, computable result.\n3.  **Objectivity**: The problem is stated in precise, mathematical language, free from any subjective or ambiguous terminology.\n4.  **Consistency and Completeness**: The provided information is self-consistent and sufficient to solve the problem. There are no contradictions or missing definitions. The analytical form for learning the corrected potential is a didactic choice that demonstrates a best-case scenario for the machine-learning correction, which is a valid pedagogical approach. The problem does not contain any scientific falsehoods, paradoxical conditions, or infeasible requirements.\n\n### Step 3: Verdict and Action\nThe problem is determined to be **valid**. The solution process will now proceed.\n\n### Solution Derivation\n\nThe problem requires the computation of two error metrics associated with coarse-graining a simple two-particle system. The first error, $E_{\\text{viol}}$, quantifies the inconsistency introduced by a naive, symmetry-violating coarse-graining map. The second error, $E_{\\text{corr}}$, quantifies the accuracy of a corrected potential designed to restore the fundamental rotational symmetry.\n\n**Part 1: Calculation of the Violation Error, $E_{\\text{viol}}$**\n\nThe true microscopic potential energy, $U(d)$, depends only on the Euclidean distance $d = \\|\\Delta \\mathbf{r}\\|_2$ between the two particles. Given $k=10$ and $r_0=1$, the potential is:\n$$\nU(d) = \\frac{1}{2} (10) (d - 1)^2 = 5(d - 1)^2\n$$\nThis potential is rotationally invariant, as its value is the same for any orientation of the displacement vector $\\Delta \\mathbf{r}$, provided the distance $d$ is constant.\n\nThe naive coarse-grained model employs an anisotropic surrogate distance $\\tilde{d}_\\gamma(\\Delta \\mathbf{r})$. For a configuration parameterized by distance $d$ and angle $\\phi$, the displacement vector is $\\Delta \\mathbf{r} = (d \\cos \\phi, d \\sin \\phi)$. The surrogate distance is:\n$$\n\\tilde{d}_\\gamma(d, \\phi) = \\sqrt{(d \\cos \\phi)^2 + \\gamma (d \\sin \\phi)^2} = d\\sqrt{\\cos^2 \\phi + \\gamma \\sin^2 \\phi}\n$$\nThe corresponding naive potential $\\tilde{U}_\\gamma$ is:\n$$\n\\tilde{U}_\\gamma(d, \\phi) = \\frac{1}{2} k (\\tilde{d}_\\gamma(d, \\phi) - r_0)^2 = 5 \\left( d\\sqrt{\\cos^2 \\phi + \\gamma \\sin^2 \\phi} - 1 \\right)^2\n$$\nUnless $\\gamma=1$ or $\\sin\\phi=0$, this potential depends on the orientation $\\phi$, thus violating rotational invariance. The resulting violation error is:\n$$\nE_{\\text{viol}} = \\left| \\tilde{U}_\\gamma(d, \\phi) - U(d) \\right|\n$$\n\n**Part 2: Calculation of the Corrected Error, $E_{\\text{corr}}$**\n\nThe second task is to construct a corrected potential, $\\hat{U}(d)$, that restores rotational invariance by depending only on the true Euclidean distance $d$. The proposed functional form is a quadratic polynomial:\n$$\n\\hat{U}(d) = a_0 + a_1 d + a_2 d^2\n$$\nThe coefficients $(a_0, a_1, a_2)$ are to be determined by a least-squares fit to synthetic, noise-free data generated from the true potential, $\\{ (d_j, U(d_j)) \\}_{j=1}^{101}$ for $d_j \\in [0.5, 2.5]$.\n\nWe observe that the true potential $U(d)$ is itself a quadratic polynomial in $d$:\n$$\nU(d) = 5(d - 1)^2 = 5(d^2 - 2d + 1) = 5d^2 - 10d + 5\n$$\nSince the model $\\hat{U}(d)$ has the same functional form as the data-generating function $U(d)$, and the training data is exact, the least-squares fitting procedure is guaranteed to recover the exact coefficients, up to machine precision. The solution to the linear system $\\mathbf{X}\\mathbf{a} = \\mathbf{y}$ (where $\\mathbf{X}$ is the Vandermonde matrix of the training distances $d_j$ and $\\mathbf{y}$ is the vector of potential values $U(d_j)$) will yield:\n$$\na_2 = 5, \\quad a_1 = -10, \\quad a_0 = 5\n$$\nTherefore, the learned potential will be identical to the true potential: $\\hat{U}(d) \\equiv U(d)$.\nConsequently, the corrected error, $E_{\\text{corr}}$, will be zero for all test cases, up to negligible floating-point error.\n$$\nE_{\\text{corr}} = \\left| \\hat{U}(d) - U(d) \\right| = 0\n$$\n\nThe final algorithm involves performing these calculations for each test case specified in the problem statement. For each tuple $(\\gamma, d, \\phi)$, we will compute $E_{\\text{viol}}$ and $E_{\\text{corr}}$ and append them to the results list.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the coarse-graining problem by calculating violation and corrected errors.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (gamma, d, phi in radians)\n        (0.25, 1.0, 0.0),\n        (0.25, 1.0, np.pi/2),\n        (4.0, 1.0, np.pi/2),\n        (0.25, 2.0, np.pi/4),\n        (1.0, 0.5, 1.0),\n        (4.0, 0.5, np.pi/2),\n    ]\n\n    # Global parameters from the problem\n    k = 10.0\n    r0 = 1.0\n\n    # --- Part 1: Learn the corrected potential coefficients ---\n    # As derived in the solution, we know the exact form. However,\n    # the problem requires us to perform the least-squares fit.\n\n    # Generate synthetic training data\n    M = 101\n    d_train = np.linspace(0.5, 2.5, M)\n    U_train = 0.5 * k * (d_train - r0)**2\n\n    # Set up the design matrix for polynomial regression: 1, d, d^2\n    X_train = np.vstack([np.ones(M), d_train, d_train**2]).T\n\n    # Perform linear least squares to find coefficients (a0, a1, a2)\n    # a will be a numpy array [a0, a1, a2]\n    a, _, _, _ = np.linalg.lstsq(X_train, U_train, rcond=None)\n    a0, a1, a2 = a[0], a[1], a[2]\n    \n    # Store results for all test cases\n    results = []\n    \n    for case in test_cases:\n        gamma, d, phi = case\n\n        # --- Part 2: Calculate the violation error (E_viol) ---\n        \n        # True microscopic potential energy\n        U_d = 0.5 * k * (d - r0)**2\n\n        # Displacement vector components\n        dx = d * np.cos(phi)\n        dy = d * np.sin(phi)\n        \n        # Anisotropic surrogate distance\n        d_tilde = np.sqrt(dx**2 + gamma * dy**2)\n        \n        # Naive coarse-grained potential\n        U_tilde = 0.5 * k * (d_tilde - r0)**2\n        \n        # Violation error\n        E_viol = np.abs(U_tilde - U_d)\n        \n        # --- Part 3: Calculate the corrected error (E_corr) ---\n        \n        # Learned symmetry-preserving potential\n        U_hat = a0 + a1 * d + a2 * d**2\n        \n        # Corrected error\n        E_corr = np.abs(U_hat - U_d)\n        \n        # Append results to the list\n        results.append(E_viol)\n        results.append(E_corr)\n\n    # Final print statement in the exact required format.\n    # The requirement to round \"to within 10^-10\" is a tolerance,\n    # so standard float string formatting is sufficient.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond fundamental symmetries, effective potentials must often incorporate known physical constraints, such as monotonic repulsion at short distances. This practice  explores how to embed such prior knowledge directly into the architecture of a machine-learned model, a more robust approach than relying solely on training data. You will derive how constraints on the coefficients of a B-spline potential enforce shape properties like monotonicity and convexity, providing a powerful technique for creating inherently physical models.",
            "id": "3776310",
            "problem": "A coarse-grained radial potential of mean force $U(r)$ for a bead-spring model must be monotonically nonincreasing and convex on the interval $[0,R_{\\mathrm{c}}]$ to reflect physically required repulsion within a contact range. Monotonic nonincrease means $U'(r) \\le 0$ for all $r \\in [0,R_{\\mathrm{c}}]$, and convexity means $U''(r) \\ge 0$ for all $r \\in [0,R_{\\mathrm{c}}]$. Consider a spline-based parametrization $U(r) = \\sum_{i=0}^{3} c_i N_{i,3}(r)$, where $N_{i,3}(r)$ are the cubic basis spline (B-spline) functions associated with a uniform open knot vector on $[0,3h]$ with spacing $h>0$. The B-spline functions are nonnegative and form a partition of unity on their support.\n\nStarting from the standard recurrence definition of B-splines and the fundamental definitions of monotonicity and convexity via derivatives, derive how conditions on the coefficient sequence $\\{c_i\\}$ ensure $U'(r) \\le 0$ and $U''(r) \\ge 0$ on $[0,3h]$. Then, to encode these shape constraints in a machine-learning-friendly unconstrained parametrization, define auxiliary unconstrained parameters $s_1,s_2,s_3 \\in \\mathbb{R}$ and set the forward differences of the coefficients to\n$$\n\\Delta c_i := c_i - c_{i-1} = -\\sum_{k=i}^{3} s_k^2,\\quad i=1,2,3,\n$$\nwith $c_0 = U_0$ for a fixed boundary value $U_0 \\in \\mathbb{R}$.\n\nCompute the coefficient vector $\\big(c_0,c_1,c_2,c_3\\big)$ explicitly in terms of $U_0$, $s_1$, $s_2$, and $s_3$. Express your final answer as a single closed-form analytic expression. No numerical rounding is required, and no physical units are needed in the final expression.",
            "solution": "The problem asks for two main components: first, to derive the conditions on the coefficients $\\{c_i\\}$ of a cubic B-spline representation of a potential $U(r)$ that ensure it is monotonically nonincreasing and convex; and second, to compute these coefficients explicitly based on a given unconstrained parametrization.\n\nFirst, we address the derivation of the coefficient constraints. The potential is given by a B-spline curve of degree $p=3$:\n$$U(r) = \\sum_{i=0}^{3} c_i N_{i,3}(r)$$\nThe B-spline basis functions $N_{i,3}(r)$ are defined over a uniform knot vector on $[0, 3h]$ with spacing $h$. The derivative of a B-spline curve of degree $p$ with control points $\\{c_i\\}$ is a B-spline curve of degree $p-1$. Its control points $\\{d_i\\}$ are proportional to the forward differences of the original control points, $\\Delta c_i = c_i - c_{i-1}$. The general formula for the derivative is:\n$$ \\frac{d}{dr} \\left( \\sum_{i} c_i N_{i,p}(r) \\right) = p \\sum_{i} \\frac{c_i - c_{i-1}}{\\tau_{i+p} - \\tau_i} N_{i, p-1}(r) $$\nwhere $\\tau_j$ are the knots. For our cubic spline ($p=3$) with a uniform knot vector, the knot spacing relevant to the derivative formula is $\\tau_{i+3} - \\tau_i = 3h$. Thus, the first derivative of $U(r)$ is a quadratic ($p-1=2$) B-spline:\n$$ U'(r) = \\frac{3}{3h} \\sum_{i=1}^{3} (c_i - c_{i-1}) N_{i,2}^*(r) = \\frac{1}{h} \\sum_{i=1}^{3} \\Delta c_i N_{i,2}^*(r) $$\nwhere $N_{i,2}^*(r)$ are quadratic B-spline basis functions and $\\Delta c_i = c_i - c_{i-1}$. The B-spline basis functions are non-negative, $N_{i,2}^*(r) \\ge 0$, for all $r$ in their support. Therefore, a sufficient condition for the potential to be monotonically nonincreasing, $U'(r) \\le 0$, is that all coefficients of the derivative spline are non-positive:\n$$ \\Delta c_i \\le 0 \\quad \\text{for } i=1, 2, 3 $$\nThis implies the sequence of coefficients must be nonincreasing: $c_0 \\ge c_1 \\ge c_2 \\ge c_3$.\n\nNext, we consider the convexity condition, $U''(r) \\ge 0$. We differentiate $U'(r)$:\n$$ U''(r) = \\frac{d}{dr} \\left( \\frac{1}{h} \\sum_{i=1}^{3} \\Delta c_i N_{i,2}^*(r) \\right) = \\frac{1}{h} \\frac{d}{dr} \\left( \\sum_{j=0}^{2} d_j N_{j,2}(r) \\right) $$\nwhere we have re-indexed and defined the coefficients of the quadratic spline as $d_j = \\frac{1}{h}\\Delta c_{j+1}$ for $j=0,1,2$. Applying the derivative formula again for this quadratic spline ($p=2$), where the relevant knot spacing is $2h$, we obtain a linear ($p-1=1$) B-spline:\n$$ U''(r) = \\frac{1}{h} \\left( 2 \\sum_{j=1}^{2} \\frac{d_j - d_{j-1}}{2h} N_{j,1}^{**}(r) \\right) = \\frac{1}{h^2} \\sum_{j=1}^{2} (d_j - d_{j-1}) N_{j,1}^{**}(r) $$\nSubstituting the expressions for $d_j$:\n$d_1 - d_0 = \\frac{1}{h}\\Delta c_2 - \\frac{1}{h}\\Delta c_1 = \\frac{1}{h}(\\Delta c_2 - \\Delta c_1) = \\frac{1}{h}\\Delta^2 c_2$\n$d_2 - d_1 = \\frac{1}{h}\\Delta c_3 - \\frac{1}{h}\\Delta c_2 = \\frac{1}{h}(\\Delta c_3 - \\Delta c_2) = \\frac{1}{h}\\Delta^2 c_3$\nwhere $\\Delta^2 c_i = \\Delta c_i - \\Delta c_{i-1}$ is the second-order forward difference. The second derivative is:\n$$ U''(r) = \\frac{1}{h^3} \\sum_{i=2}^{3} \\Delta^2 c_i N_{i-1,1}^{**}(r) $$\n(The constant factor depends on the precise definition of knot vectors, but the key part is the dependence on $\\Delta^2 c_i$). A more careful derivation yields $U''(r) = \\frac{2}{2h} \\frac{2}{h'}...$, leading to a different coefficient. The standard result for uniform splines gives $U''(r)$ with coefficients proportional to $\\Delta^2 c_i$. The essential point is that since the linear B-spline basis functions $N_{k,1}(r)$ are non-negative, a sufficient condition for convexity, $U''(r) \\ge 0$, is that the coefficients of the second derivative spline are non-negative:\n$$ \\Delta^2 c_i \\ge 0 \\quad \\text{for } i=2, 3 $$\nThis implies that the sequence of first differences $\\{\\Delta c_i\\}$ must be non-decreasing, i.e., $\\Delta c_1 \\le \\Delta c_2 \\le \\Delta c_3$.\n\nThe problem introduces an unconstrained parametrization for the forward differences $\\Delta c_i$ using auxiliary parameters $s_1, s_2, s_3 \\in \\mathbb{R}$:\n$$ \\Delta c_i := c_i - c_{i-1} = -\\sum_{k=i}^{3} s_k^2, \\quad i=1, 2, 3 $$\nWe verify that this parametrization satisfies the derived sufficient conditions.\nFor monotonicity, we require $\\Delta c_i \\le 0$:\n$\\Delta c_1 = -(s_1^2 + s_2^2 + s_3^2) \\le 0$\n$\\Delta c_2 = -(s_2^2 + s_3^2) \\le 0$\n$\\Delta c_3 = -s_3^2 \\le 0$\nSince $s_k^2 \\ge 0$ for any real $s_k$, all first differences are non-positive, satisfying the monotonicity condition.\n\nFor convexity, we require $\\Delta^2 c_i \\ge 0$:\nFor $i=2$: $\\Delta^2 c_2 = \\Delta c_2 - \\Delta c_1 = -(s_2^2 + s_3^2) - (-(s_1^2 + s_2^2 + s_3^2)) = s_1^2 \\ge 0$.\nFor $i=3$: $\\Delta^2 c_3 = \\Delta c_3 - \\Delta c_2 = -s_3^2 - (-(s_2^2 + s_3^2)) = s_2^2 \\ge 0$.\nBoth conditions are satisfied for any real $s_k$. Thus, the parametrization correctly enforces the desired shape constraints.\n\nFinally, we compute the coefficient vector $(c_0, c_1, c_2, c_3)$. We are given the boundary value $c_0 = U_0$. The remaining coefficients can be computed recursively.\nFor $c_1$:\n$c_1 = c_0 + \\Delta c_1 = U_0 - (s_1^2 + s_2^2 + s_3^2)$\n\nFor $c_2$:\n$c_2 = c_1 + \\Delta c_2 = (U_0 - s_1^2 - s_2^2 - s_3^2) + (-(s_2^2 + s_3^2)) = U_0 - s_1^2 - 2s_2^2 - 2s_3^2$\n\nFor $c_3$:\n$c_3 = c_2 + \\Delta c_3 = (U_0 - s_1^2 - 2s_2^2 - 2s_3^2) + (-s_3^2) = U_0 - s_1^2 - 2s_2^2 - 3s_3^2$\n\nThe resulting coefficient vector is $(c_0, c_1, c_2, c_3)$. Collecting the expressions:\n$c_0 = U_0$\n$c_1 = U_0 - s_1^2 - s_2^2 - s_3^2$\n$c_2 = U_0 - s_1^2 - 2s_2^2 - 2s_3^2$\n$c_3 = U_0 - s_1^2 - 2s_2^2 - 3s_3^2$\nThis vector can be presented in a single closed-form expression.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nU_0 & U_0 - s_1^2 - s_2^2 - s_3^2 & U_0 - s_1^2 - 2s_2^2 - 2s_3^2 & U_0 - s_1^2 - 2s_2^2 - 3s_3^2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A successful coarse-grained model must be not only accurate but also numerically stable and efficient to simulate. The properties of a learned force field, such as its local stiffness, directly constrain the maximum stable timestep that can be used in a molecular dynamics simulation. This hands-on practice  delves into this crucial connection, guiding you to analyze the stability of a learned Dissipative Particle Dynamics (DPD) model and propose regularization strategies to ensure its computational feasibility.",
            "id": "3776357",
            "problem": "You are given a coarse-grained particle system modeled by Dissipative Particle Dynamics (DPD), where pairwise forces are parameterized by learned radial functions. The conservative force magnitude is given by $f_{\\mathrm{C}}(r) = a(r) \\, w(r)$, where $a(r)$ is a learned conservative amplitude and $w(r)$ is a compact-support radial weight. The dissipative friction is given by $\\gamma(r)$, acting through a velocity-proportional pairwise force magnitude $f_{\\mathrm{D}}(r) = \\gamma(r) \\, w(r)$. Assume a uniform number density $\\rho$ and a spherical cutoff radius $r_{\\mathrm{c}}$, with $w(r) = \\max(0, 1 - r/r_{\\mathrm{c}})$ for $0 \\le r \\le r_{\\mathrm{c}}$ and $w(r) = 0$ otherwise. Assume the radial distribution function is $g(r) = 1$.\n\nStarting from the linearization of the many-body dynamics around a uniform state, define the effective stiffness $K_{\\mathrm{eff}}$ of the drift as the integral over pairwise stiffness contributions, and the effective damping $\\Gamma_{\\mathrm{eff}}$ as the integral of dissipative friction contributions:\n$$\nK_{\\mathrm{eff}} = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\left| \\frac{\\mathrm{d}}{\\mathrm{d} r}\\left( a(r) \\, w(r) \\right) \\right| \\, \\mathrm{d} r,\n\\quad\n\\Gamma_{\\mathrm{eff}} = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\, \\gamma(r) \\, w(r) \\, \\mathrm{d} r.\n$$\nConsider a second-order explicit integrator for the damped system $m \\, \\ddot{x} + \\Gamma_{\\mathrm{eff}} \\dot{x} + K_{\\mathrm{eff}} x \\approx 0$ obtained by linearization. For stability of the time discretization, require the maximum stable timestep be\n$$\n\\Delta t_{\\max} = \\begin{cases}\n\\min\\!\\left( \\dfrac{2}{\\sqrt{K_{\\mathrm{eff}}/m}}, \\dfrac{2}{\\Gamma_{\\mathrm{eff}}} \\right), & \\Gamma_{\\mathrm{eff}} > 0, \\\\\n0, & \\Gamma_{\\mathrm{eff}} \\le 0,\n\\end{cases}\n$$\nwhich combines the standard explicit linear stability bounds for the undamped and over-damped limits.\n\nYou will implement the following computational tasks:\n\n1. Given $a(r)$ and $\\gamma(r)$ represented as polynomials in $r$, $a(r) = \\sum_{k=0}^{K} c_k \\, r^k, \\quad \\gamma(r) = \\sum_{k=0}^{L} d_k \\, r^k$, and given $m$, $\\rho$, $r_{\\mathrm{c}}$, compute $K_{\\mathrm{eff}}$ and $\\Gamma_{\\mathrm{eff}}$ by numerical quadrature over $[0, r_{\\mathrm{c}}]$. Use $w(r) = \\max(0, 1 - r/r_{\\mathrm{c}})$ and $g(r) = 1$. All quantities are in reduced DPD units; report timesteps in reduced time units.\n\n2. Compute $\\Delta t_{\\max}$ according to the rule above. Given a proposed timestep $\\Delta t_{\\mathrm{prop}}$, determine stability by checking $\\Delta t_{\\mathrm{prop}} \\le \\Delta t_{\\max}$ when $\\Gamma_{\\mathrm{eff}} > 0$. If $\\Gamma_{\\mathrm{eff}} \\le 0$, the system is anti-damped and unstable regardless of $\\Delta t_{\\mathrm{prop}}$.\n\n3. Propose regularization strategies to prevent numerical instabilities by returning quantitative recommendations:\n   - An amplitude scaling factor $s_a = \\min\\!\\left(1, \\dfrac{K_{\\mathrm{target}}}{K_{\\mathrm{eff}}} \\right)$ to uniformly scale $a(r) \\mapsto s_a \\, a(r)$ if $K_{\\mathrm{eff}} > K_{\\mathrm{target}}$.\n   - An additive friction increment $\\Delta \\gamma \\ge 0$ to be added uniformly to $\\gamma(r)$ so that the effective damping meets a target $\\Gamma_{\\mathrm{target}}$. Let\n     $$\n     M_w = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\, w(r) \\, \\mathrm{d} r,\n     \\quad\n     \\Delta \\gamma = \\max\\!\\left( 0, \\dfrac{\\Gamma_{\\mathrm{target}} - \\Gamma_{\\mathrm{eff}}}{M_w} \\right).\n     $$\n   - A dimensionless Lipschitz penalty weight $\\lambda = \\max\\!\\left(0, \\dfrac{K_{\\mathrm{eff}}}{K_{\\mathrm{target}}} - 1 \\right)$ that can be used to penalize excessive stiffness in the learned conservative force during training.\n\nYour program must implement these computations and return, for each test case, a list containing five values in the following order:\n$[\\Delta t_{\\max}, \\text{stable}, s_a, \\Delta \\gamma, \\lambda]$,\nwhere $\\Delta t_{\\max}$, $s_a$, $\\Delta \\gamma$, and $\\lambda$ are floating-point numbers in reduced units, and $\\text{stable}$ is encoded as a floating-point number with $1.0$ representing stable and $0.0$ representing unstable.\n\nUse the following test suite of parameter values, each expressed in reduced DPD units:\n\n- Test case $1$ (general case): $m = 1.0$, $\\rho = 3.0$, $r_{\\mathrm{c}} = 1.0$, $a(r)$ coefficients $[75.0, -50.0, 0.0]$, $\\gamma(r)$ coefficients $[4.0]$, $\\Delta t_{\\mathrm{prop}} = 0.05$, $K_{\\mathrm{target}} = 150.0$, $\\Gamma_{\\mathrm{target}} = 1.0$.\n- Test case $2$ (dissipation-limited boundary): $m = 1.0$, $\\rho = 2.0$, $r_{\\mathrm{c}} = 1.0$, $a(r)$ coefficients $[40.0, -35.0, 0.0]$, $\\gamma(r)$ coefficients $[0.6]$, $\\Delta t_{\\mathrm{prop}} = 3.2$, $K_{\\mathrm{target}} = 100.0$, $\\Gamma_{\\mathrm{target}} = 0.8$.\n- Test case $3$ (steep conservative force edge case): $m = 1.0$, $\\rho = 3.0$, $r_{\\mathrm{c}} = 1.0$, $a(r)$ coefficients $[200.0, -180.0, 0.0]$, $\\gamma(r)$ coefficients $[4.0]$, $\\Delta t_{\\mathrm{prop}} = 0.02$, $K_{\\mathrm{target}} = 100.0$, $\\Gamma_{\\mathrm{target}} = 0.5$.\n- Test case $4$ (anti-damping edge case): $m = 1.0$, $\\rho = 3.0$, $r_{\\mathrm{c}} = 1.0$, $a(r)$ coefficients $[50.0, -30.0, 0.0]$, $\\gamma(r)$ coefficients $[-0.5]$, $\\Delta t_{\\mathrm{prop}} = 0.01$, $K_{\\mathrm{target}} = 100.0$, $\\Gamma_{\\mathrm{target}} = 1.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a bracketed comma-separated list with five decimal numbers formatted to six digits after the decimal point. For example, a valid output format is\n$[[x_{11},x_{12},x_{13},x_{14},x_{15}],[x_{21},x_{22},x_{23},x_{24},x_{25}],\\ldots]$.",
            "solution": "The problem requires the computation of stability metrics and regularization parameters for a Dissipative Particle Dynamics (DPD) system where pairwise interaction forces are described by learned polynomial functions. The solution is structured by implementing the provided mathematical definitions in a step-by-step computational procedure.\n\n**1. Representation of Learned Potentials**\nThe learned conservative amplitude $a(r)$ and dissipative friction function $\\gamma(r)$ are given as polynomials in the particle separation distance $r$. Specifically, $a(r) = \\sum_{k=0}^{K} c_k r^k$ and $\\gamma(r) = \\sum_{k=0}^{L} d_k r^k$. These are represented programmatically using polynomial objects derived from the input coefficient lists $[c_0, c_1, \\dots, c_K]$ and $[d_0, d_1, \\dots, d_L]$. This representation allows for algebraic manipulations, such as differentiation, to be performed systematically.\n\n**2. Formulation of Integrals for Effective Parameters**\nThe core task is to evaluate the effective stiffness $K_{\\mathrm{eff}}$ and effective damping $\\Gamma_{\\mathrm{eff}}$, which are defined by integrals over the interval $[0, r_{\\mathrm{c}}]$, where $r_{\\mathrm{c}}$ is the interaction cutoff radius.\n\nThe effective damping $\\Gamma_{\\mathrm{eff}}$ is defined as:\n$$\n\\Gamma_{\\mathrm{eff}} = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\, \\gamma(r) \\, w(r) \\, \\mathrm{d} r\n$$\nThe integrand is a product of the DPD volume element in spherical coordinates ($4\\pi r^2 \\mathrm{d}r$), the number density $\\rho$, the learned polynomial $\\gamma(r)$, and the standard DPD linear weight function $w(r) = 1 - r/r_{\\mathrm{c}}$ for $r \\in [0, r_{\\mathrm{c}}]$.\n\nThe effective stiffness $K_{\\mathrm{eff}}$ is defined as:\n$$\nK_{\\mathrm{eff}} = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\left| \\frac{\\mathrm{d}}{\\mathrm{d} r}\\left( a(r) \\, w(r) \\right) \\right| \\, \\mathrm{d} r\n$$\nTo construct the integrand, we first compute the derivative of the conservative force magnitude, $f_{\\mathrm{C}}(r) = a(r)w(r)$, with respect to $r$. Using the product rule for differentiation, we get:\n$$\n\\frac{\\mathrm{d}f_{\\mathrm{C}}}{\\mathrm{d}r} = \\frac{\\mathrm{d}a(r)}{\\mathrm{d}r} w(r) + a(r) \\frac{\\mathrm{d}w(r)}{\\mathrm{d}r}\n$$\nSince $a(r)$ is a polynomial, its derivative $\\frac{\\mathrm{d}a(r)}{\\mathrm{d}r}$ is also a polynomial. The derivative of the weight function is a constant, $\\frac{\\mathrm{d}w(r)}{\\mathrm{d}r} = -1/r_{\\mathrm{c}}$. Thus, $\\frac{\\mathrm{d}f_{\\mathrm{C}}}{\\mathrm{d}r}$ is itself a polynomial, which is readily computed. The absolute value of this expression is taken before integration, ensuring that $K_{\\mathrm{eff}} \\ge 0$.\n\n**3. Numerical Integration**\nThe definite integrals for $\\Gamma_{\\mathrm{eff}}$ and $K_{\\mathrm{eff}}$ are computed using numerical quadrature. The `quad` function from the `scipy.integrate` library is employed for this purpose, as it provides a robust and accurate method for integrating the well-behaved polynomial-based functions encountered here.\n\n**4. Calculation of Stability and Regularization Parameters**\nOnce $K_{\\mathrm{eff}}$ and $\\Gamma_{\\mathrm{eff}}$ are computed, the five output quantities for each test case are determined by applying the specified formulas:\n\n- **Maximum Stable Timestep ($\\Delta t_{\\max}$)**: The stability of the linearized system is governed by both stiffness and damping. If $\\Gamma_{\\mathrm{eff}} \\le 0$, the system has non-positive damping (or anti-damping) and is inherently unstable, so $\\Delta t_{\\max}$ is set to $0$. For a physically stable system with $\\Gamma_{\\mathrm{eff}} > 0$, the maximum stable timestep is the more restrictive of the two limits derived from the undamped oscillator frequency and the damping rate:\n$$\n\\Delta t_{\\max} = \\min\\!\\left( \\frac{2}{\\sqrt{K_{\\mathrm{eff}}/m}}, \\frac{2}{\\Gamma_{\\mathrm{eff}}} \\right)\n$$\nThe edge case of $K_{\\mathrm{eff}} = 0$ is handled by considering the stiffness-based limit to be infinite, so the stability is determined solely by the damping term.\n\n- **Stability Check**: The stability of a simulation run with a proposed timestep $\\Delta t_{\\mathrm{prop}}$ is assessed. The result is encoded as $1.0$ (stable) if $\\Gamma_{\\mathrm{eff}} > 0$ and $\\Delta t_{\\mathrm{prop}} \\le \\Delta t_{\\max}$. Otherwise, the result is $0.0$ (unstable).\n\n- **Regularization Parameters**: Three parameters for guiding the learning process are calculated:\n    - The amplitude scaling factor $s_a$ is designed to rescale the conservative force if its effective stiffness exceeds a desired target $K_{\\mathrm{target}}$:\n      $$\n      s_a = \\min\\!\\left(1, \\frac{K_{\\mathrm{target}}}{K_{\\mathrm{eff}}} \\right)\n      $$\n    - The additive friction increment $\\Delta \\gamma$ is a constant value to be added to $\\gamma(r)$ to ensure the total effective damping meets a target $\\Gamma_{\\mathrm{target}}$. Its calculation involves the integrated weight $M_w$:\n      $$\n      M_w = \\rho \\int_{0}^{r_{\\mathrm{c}}} 4\\pi r^2 \\, w(r) \\, \\mathrm{d} r = \\frac{\\pi}{3} \\rho r_{\\mathrm{c}}^3\n      $$\n      This integral is evaluated analytically for optimal precision. Then, $\\Delta \\gamma$ is given by:\n      $$\n      \\Delta \\gamma = \\max\\!\\left( 0, \\frac{\\Gamma_{\\mathrm{target}} - \\Gamma_{\\mathrm{eff}}}{M_w} \\right)\n      $$\n    - The dimensionless Lipschitz penalty weight $\\lambda$ quantifies the excess stiffness for use in a loss function:\n      $$\n      \\lambda = \\max\\!\\left(0, \\frac{K_{\\mathrm{eff}}}{K_{\\mathrm{target}}} - 1 \\right)\n      $$\n\n**5. Implementation and Output Formatting**\nThe described computational procedure is implemented as a single function that processes each test case. The final calculated values $[\\Delta t_{\\max}, \\text{stable}, s_a, \\Delta \\gamma, \\lambda]$ are collected for all test cases and formatted into a single-line string as a list of lists, with all numerical values presented as floating-point numbers with six digits of precision after the decimal point, fulfilling the exact output requirement.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Main function to solve the DPD stability problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general case)\n        {'m': 1.0, 'rho': 3.0, 'rc': 1.0, 'a_coeffs': [75.0, -50.0, 0.0], 'gamma_coeffs': [4.0], 'dt_prop': 0.05, 'K_target': 150.0, 'Gamma_target': 1.0},\n        # Test case 2 (dissipation-limited boundary)\n        {'m': 1.0, 'rho': 2.0, 'rc': 1.0, 'a_coeffs': [40.0, -35.0, 0.0], 'gamma_coeffs': [0.6], 'dt_prop': 3.2, 'K_target': 100.0, 'Gamma_target': 0.8},\n        # Test case 3 (steep conservative force edge case)\n        {'m': 1.0, 'rho': 3.0, 'rc': 1.0, 'a_coeffs': [200.0, -180.0, 0.0], 'gamma_coeffs': [4.0], 'dt_prop': 0.02, 'K_target': 100.0, 'Gamma_target': 0.5},\n        # Test case 4 (anti-damping edge case)\n        {'m': 1.0, 'rho': 3.0, 'rc': 1.0, 'a_coeffs': [50.0, -30.0, 0.0], 'gamma_coeffs': [-0.5], 'dt_prop': 0.01, 'K_target': 100.0, 'Gamma_target': 1.0},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = calculate_metrics(params)\n        all_results.append(result)\n\n    # Format the final output string as a list of lists of numbers\n    results_str = []\n    for res_list in all_results:\n        s = \"[\" + \",\".join(f\"{x:.6f}\" for x in res_list) + \"]\"\n        results_str.append(s)\n    final_output = \"[\" + \",\".join(results_str) + \"]\"\n    \n    print(final_output)\n\ndef calculate_metrics(params):\n    \"\"\"\n    Calculates stability and regularization metrics for a single DPD parameter set.\n    \"\"\"\n    # Extract parameters\n    m, rho, rc = params['m'], params['rho'], params['rc']\n    a_coeffs = np.array(params['a_coeffs'])\n    gamma_coeffs = np.array(params['gamma_coeffs'])\n    dt_prop, K_target, Gamma_target = params['dt_prop'], params['K_target'], params['Gamma_target']\n\n    # Represent a(r) and gamma(r) as polynomial objects.\n    # Note: np.poly1d expects coefficients in order [c_n, c_{n-1}, ..., c_0].\n    a_poly = np.poly1d(a_coeffs[::-1])\n    gamma_poly = np.poly1d(gamma_coeffs[::-1])\n\n    # Define weight function and its derivative for r in [0, rc]\n    def w(r):\n        return 1.0 - r / rc\n\n    def dw_dr(r):\n        return -1.0 / rc\n\n    # --- 1. Compute Gamma_eff ---\n    integrand_Gamma = lambda r: rho * 4.0 * np.pi * r**2 * gamma_poly(r) * w(r)\n    Gamma_eff, _ = quad(integrand_Gamma, 0, rc)\n\n    # --- 2. Compute K_eff ---\n    a_deriv_poly = a_poly.deriv()\n    def dfC_dr(r):\n        return a_deriv_poly(r) * w(r) + a_poly(r) * dw_dr(r)\n\n    integrand_K = lambda r: rho * 4.0 * np.pi * r**2 * np.abs(dfC_dr(r))\n    K_eff, _ = quad(integrand_K, 0, rc)\n\n    # --- 3. Calculate dt_max and stability ---\n    if Gamma_eff <= 0:\n        dt_max = 0.0\n        stable = 0.0\n    else:\n        # Stiffness stability limit\n        if K_eff > 1e-9: # Avoid division by zero for K_eff = 0\n            limit_K = 2.0 / np.sqrt(K_eff / m)\n        else:\n            limit_K = np.inf\n        # Damping stability limit\n        limit_Gamma = 2.0 / Gamma_eff\n        \n        dt_max = min(limit_K, limit_Gamma)\n        stable = 1.0 if dt_prop <= dt_max else 0.0\n    \n    # --- 4. Calculate regularization parameters ---\n    # Amplitude scaling factor sa\n    if K_eff > 1e-9:\n        s_a = min(1.0, K_target / K_eff)\n    else:\n        s_a = 1.0\n\n    # Additive friction increment delta_gamma\n    # M_w is computed analytically: integral of rho * 4*pi*r^2 * (1 - r/rc) from 0 to rc\n    M_w = (np.pi / 3.0) * rho * rc**3\n    if M_w > 1e-9:\n        delta_gamma = max(0.0, (Gamma_target - Gamma_eff) / M_w)\n    else:\n        # If M_w is zero, can't add uniform friction to meet a target\n        delta_gamma = 0.0 if Gamma_target <= Gamma_eff else np.inf # Effectively\n    \n    # Lipschitz penalty weight lambda\n    if K_target > 1e-9:\n        lam = max(0.0, K_eff / K_target - 1.0)\n    else:\n        # If target is zero, any positive stiffness is infinitely penalized\n        lam = np.inf if K_eff > 0 else 0.0\n\n    return [dt_max, stable, s_a, delta_gamma, lam]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}