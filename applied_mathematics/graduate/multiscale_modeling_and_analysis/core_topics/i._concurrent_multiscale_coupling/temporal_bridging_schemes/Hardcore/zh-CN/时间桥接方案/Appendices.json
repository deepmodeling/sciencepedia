{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握时间桥接格式，关键在于理解信息如何在微观和宏观尺度之间传递。这个练习深入探讨了异构多尺度方法（Heterogeneous Multiscale Method, HMM）的内部机制，它是一种典型的“在运行中计算”（on-the-fly）的桥接方案。通过分析一个典型的快慢系统，您将亲手推导微观模拟如何影响宏观动力学，并最终决定整个方案的稳定性，从而具体地理解尺度分离和耦合的核心思想 。",
            "id": "3813623",
            "problem": "考虑作为异构多尺度方法 (Heterogeneous Multiscale Method, HMM) 中时间桥接的原型多尺度模型的线性快慢系统：\n$$\n\\frac{d y}{d t} \\;=\\; a\\, y \\;+\\; c\\, z, \n\\qquad\n\\varepsilon\\,\\frac{d z}{d t} \\;=\\; -\\,b\\, z \\;+\\; d\\, y,\n$$\n其中 $y$ 是粗尺度（慢）变量，$z$ 是快变量，$a\\in\\mathbb{R}$，$b0$，$c\\in\\mathbb{R}$，$d\\in\\mathbb{R}$，且 $\\varepsilon0$ 是一个小的尺度分离参数。所有变量和参数均为无量纲。\n\n在宏观时间 $t_n$，异构多尺度方法 (HMM) 通过将粗尺度状态冻结在 $y(t)=y_n$ 并在持续时间为 $\\tau0$ 的微观窗口上以初始条件 $z(0)=0$ 积分快方程来构造粗尺度漂移的近似：\n$$\n\\varepsilon\\,\\frac{d z}{d t} \\;=\\; -\\,b\\, z \\;+\\; d\\, y_n, \n\\qquad\nz(0)=0,\n\\qquad\nt\\in[0,\\tau].\n$$\nHMM 漂移估计量定义为微观时间平均值\n$$\nf_{\\mathrm{HMM}}(y_n)\\;=\\;a\\,y_n\\;+\\;c\\,\\overline{z},\n\\qquad\n\\overline{z}\\;=\\;\\frac{1}{\\tau}\\int_{0}^{\\tau} z(t)\\,dt.\n$$\n然后，一个前向欧拉宏观积分器通过以下方式推进粗尺度变量\n$$\ny_{n+1}\\;=\\;y_n\\;+\\;\\Delta t\\, f_{\\mathrm{HMM}}(y_n).\n$$\n\n仅从以上定义和线性常微分方程的解出发，推导最大允许宏观时间步长 $\\Delta t_{\\max}(\\tau)$ 的精确表达式，该表达式是关于 $a$、$b$、$c$、$d$、$\\varepsilon$ 和 $\\tau$ 的函数，并保证粗尺度动力学保持在前向欧拉格式的线性稳定区域内；即，关于 $y=0$ 的单步宏观放大因子的模严格小于 $1$。假设选择 $\\tau0$，使得得到的有效线性粗尺度漂移是严格耗散的，即在 $f_{\\mathrm{HMM}}(y_n)$ 中乘以 $y_n$ 的线性系数为负。请将您的最终答案表示为 $\\Delta t_{\\max}(\\tau)$ 关于 $a$、$b$、$c$、$d$、$\\varepsilon$ 和 $\\tau$ 的单个闭式解析表达式。",
            "solution": "我们从给定的快慢系统开始\n$$\n\\frac{d y}{d t} \\;=\\; a\\, y \\;+\\; c\\, z, \n\\qquad\n\\varepsilon\\,\\frac{d z}{d t} \\;=\\; -\\,b\\, z \\;+\\; d\\, y,\n$$\n其中 $b0$ 且 $\\varepsilon0$。在异构多尺度方法 (HMM) 中，粗尺度状态在微观窗口 $[0,\\tau]$ 上被冻结在 $y(t)=y_n$。那么快尺度微观问题是\n$$\n\\varepsilon\\,\\frac{d z}{d t} \\;=\\; -\\,b\\, z \\;+\\; d\\, y_n,\n\\qquad\nz(0)=0,\n\\qquad\nt\\in[0,\\tau].\n$$\n这是一个常系数线性常微分方程。其唯一解可通过求解标量线性方程得到\n$$\n\\varepsilon\\,\\frac{d z}{d t} \\;+\\; b\\,z \\;=\\; d\\,y_n,\n$$\n其平衡值为\n$$\nz_{\\mathrm{eq}} \\;=\\; \\frac{d}{b}\\,y_n.\n$$\n在初始条件 $z(0)=0$ 下，精确解为\n$$\nz(t)\\;=\\;z_{\\mathrm{eq}}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}t\\big)\\Big)\n\\;=\\;\\frac{d}{b}\\,y_n\\,\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}t\\big)\\Big).\n$$\nHMM 漂移估计量使用 $z(t)$ 在 $[0,\\tau]$ 上的时间平均值：\n$$\n\\overline{z}\n\\;=\\;\\frac{1}{\\tau}\\int_{0}^{\\tau} z(t)\\,dt\n\\;=\\;\\frac{1}{\\tau}\\int_{0}^{\\tau} \\frac{d}{b}\\,y_n\\,\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}t\\big)\\Big)\\,dt.\n$$\n由于被积函数对 $y_n$ 是线性的，我们可以提出常数得到\n$$\n\\overline{z}\n\\;=\\;\\frac{d}{b}\\,y_n\\,\\frac{1}{\\tau}\\int_{0}^{\\tau}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}t\\big)\\Big)\\,dt.\n$$\n积分计算结果为\n$$\n\\int_{0}^{\\tau} 1\\,dt \\;=\\; \\tau,\n\\qquad\n\\int_{0}^{\\tau} \\exp\\!\\big(-\\tfrac{b}{\\varepsilon}t\\big)\\,dt \\;=\\; \\frac{\\varepsilon}{b}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big).\n$$\n因此，\n$$\n\\overline{z}\n\\;=\\;\\frac{d}{b}\\,y_n\\,\\frac{1}{\\tau}\\left[\\tau \\;-\\; \\frac{\\varepsilon}{b}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big)\\right]\n\\;=\\;\\frac{d}{b}\\,y_n\\left[1 \\;-\\; \\frac{\\varepsilon}{b\\,\\tau}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big)\\right].\n$$\n根据定义，HMM 漂移估计量是\n$$\nf_{\\mathrm{HMM}}(y_n) \\;=\\; a\\,y_n \\;+\\; c\\,\\overline{z}\n\\;=\\; \\left\\{ a \\;+\\; \\frac{c\\,d}{b}\\left[1 \\;-\\; \\frac{\\varepsilon}{b\\,\\tau}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big)\\right]\\right\\} y_n.\n$$\n引入有效线性系数\n$$\n\\kappa(\\tau) \\;=\\; a \\;+\\; \\frac{c\\,d}{b}\\left[1 \\;-\\; \\frac{\\varepsilon}{b\\,\\tau}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big)\\right].\n$$\n那么前向欧拉宏观更新可写为\n$$\ny_{n+1} \\;=\\; y_n \\;+\\; \\Delta t\\, f_{\\mathrm{HMM}}(y_n)\n\\;=\\; \\big(1 + \\Delta t\\,\\kappa(\\tau)\\big)\\, y_n.\n$$\n对于标量线性递推，前向欧拉方法的线性稳定性要求单步放大因子的模严格小于 $1$：\n$$\n\\left|1 + \\Delta t\\,\\kappa(\\tau)\\right|  1.\n$$\n因为对于实数参数，$\\kappa(\\tau)\\in\\mathbb{R}$，此条件等价于区间约束\n$$\n-1  1 + \\Delta t\\,\\kappa(\\tau)  1,\n$$\n化简为\n$$\n-2  \\Delta t\\,\\kappa(\\tau)  0.\n$$\n根据问题的假设，即有效线性系数是严格耗散的，我们有 $\\kappa(\\tau)  0$。用负数 $\\kappa(\\tau)$ 除，不等号反向，得到\n$$\n0  \\Delta t  \\frac{2}{-\\kappa(\\tau)}.\n$$\n因此，最大允许宏观时间步长是\n$$\n\\Delta t_{\\max}(\\tau) \\;=\\; \\frac{2}{-\\kappa(\\tau)}\n\\;=\\; \\frac{2}{-\\,a \\;-\\; \\frac{c\\,d}{b}\\left[1 \\;-\\; \\frac{\\varepsilon}{b\\,\\tau}\\Big(1-\\exp\\!\\big(-\\tfrac{b}{\\varepsilon}\\tau\\big)\\Big)\\right]}.\n$$\n此表达式在所述的 $\\kappa(\\tau)  0$ 的假设下有效，这保证了分母为正，从而 $\\Delta t_{\\max}(\\tau)$ 为正。",
            "answer": "$$\\boxed{\\dfrac{2}{-\\,a \\;-\\; \\dfrac{c\\,d}{b}\\left[1 \\;-\\; \\dfrac{\\varepsilon}{b\\,\\tau}\\left(1-\\exp\\!\\left(-\\dfrac{b}{\\varepsilon}\\tau\\right)\\right)\\right]}}$$"
        },
        {
            "introduction": "在设计多尺度模拟时，稳定性固然重要，但计算效率同样是决定方案实用性的关键。任何时间桥接方案都涉及在宏观步长带来的加速和微观采样带来的成本与误差之间的权衡。本练习将这一核心挑战转化为一个约束优化问题，要求您在给定的误差容限下，最小化总计算成本，从而推导出最优的宏观时间步长和微观模拟时长 。这个过程将帮助您掌握在多尺度建模中进行性能优化的基本思路。",
            "id": "3813575",
            "problem": "考虑一个多尺度建模中的时间桥接方案，其中宏观层面积分器在一个固定的时间域 $T$ 上推进一个粗粒度变量，其方法是使用短时间的微观模拟片段来估计粗粒度漂移项。假设以下具有科学依据的事实：\n\n- 宏观层面积分器的阶数为 $p \\geq 1$，因此其造成的全局离散误差贡献与 $a\\,\\Delta t^{p}$ 成比例，其中 $a0$ 为某个常数，$\\Delta t$ 是宏观时间步长。\n- 通过在持续时间为 $\\tau$ 的微观模拟片段上对一个遍历快速过程进行平均，得到的粗粒度漂移项的微观层面估计误差与 $b\\,\\tau^{-1/2}$ 成比例，其中 $b0$ 为某个常数。这与中心极限定理一致，并假设微观模拟片段的持续时间长于混合时间，因此偏差可以忽略不计。\n- 单个微观模拟片段的计算成本与其持续时间成线性关系，即 $C_{\\text{micro}}(\\tau)=\\alpha\\,\\tau$，其中 $\\alpha0$ 是单位微观时间的成本。假设与微观模拟片段的成本相比，宏观层面步进的开销可以忽略不计。\n- 在时间域 $T$ 内的宏观步数为 $N=T/\\Delta t$，我们将 $N$ 视为连续变量并忽略取整效应。\n\n在时间域 $T$ 上，定义总成本为 $C_{\\text{tot}}(\\tau,\\Delta t)=N\\,C_{\\text{micro}}(\\tau)$，总误差为 $E_{\\text{tot}}(\\tau,\\Delta t)=a\\,\\Delta t^{p}+b\\,\\tau^{-1/2}$。对于给定的误差容限 $\\varepsilon0$，构建一个约束优化问题，旨在最小化 $C_{\\text{tot}}(\\tau,\\Delta t)$，约束条件为 $E_{\\text{tot}}(\\tau,\\Delta t)\\leq \\varepsilon$。推导最优微观模拟片段持续时间 $\\tau^{\\star}$ 和最优宏观时间步长 $\\Delta t^{\\star}$ 关于 $a$、$b$、$p$ 和 $\\varepsilon$ 的显式解析表达式。\n\n将 $\\tau^{\\star}$ 和 $\\Delta t^{\\star}$ 的最终答案表示为关于 $a$、$b$、$p$ 和 $\\varepsilon$ 的封闭形式表达式。无需进行数值计算。最终表达式中无需包含单位。",
            "solution": "问题在于找到最优的微观模拟片段持续时间 $\\tau^{\\star}$ 和宏观时间步长 $\\Delta t^{\\star}$，以在总误差受约束的情况下最小化总计算成本。这是一个约束优化问题。\n\n给定的量如下：\n总成本函数：$C_{\\text{tot}}(\\tau, \\Delta t) = N\\,C_{\\text{micro}}(\\tau)$，其中 $N = T/\\Delta t$ 且 $C_{\\text{micro}}(\\tau) = \\alpha\\,\\tau$。代入这些量可得 $C_{\\text{tot}}(\\tau, \\Delta t) = T\\alpha\\frac{\\tau}{\\Delta t}$。\n总误差函数：$E_{\\text{tot}}(\\tau, \\Delta t) = a\\,\\Delta t^{p} + b\\,\\tau^{-1/2}$。\n约束条件是总误差不能超过给定的容限 $\\varepsilon  0$，即 $E_{\\text{tot}}(\\tau, \\Delta t) \\leq \\varepsilon$。\n参数 $a, b, \\alpha, T$ 均为正常数，宏观积分器的阶数 $p \\geq 1$。优化变量为 $\\tau  0$ 和 $\\Delta t  0$。\n\n该优化问题可正式表述为：\n最小化 $C_{\\text{tot}}(\\tau, \\Delta t) = T\\alpha\\frac{\\tau}{\\Delta t}$\n约束条件为 $a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} \\leq \\varepsilon$。\n\n成本函数 $C_{\\text{tot}}$ 是关于 $\\tau$ 的严格增函数，关于 $\\Delta t$ 的严格减函数。为最小化成本，我们应寻找尽可能小的 $\\tau$ 和尽可能大的 $\\Delta t$。约束条件 $a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} \\leq \\varepsilon$ 限制了 $\\Delta t$ 的最大值和 $\\tau$ 的最小值。如果不等式是严格的，即 $a\\,\\Delta t^{p} + b\\,\\tau^{-1/2}  \\varepsilon$，人们总能通过增大 $\\Delta t$ 或减小 $\\tau$ (或两者兼有)来进一步降低成本，同时仍然满足约束条件。因此，最小成本必定在约束条件被激活时达到，即等式成立：\n$a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} = \\varepsilon$。\n\n我们使用拉格朗日乘子法来求解此约束优化问题。拉格朗日函数 $\\mathcal{L}$ 定义为：\n$$\n\\mathcal{L}(\\tau, \\Delta t, \\lambda) = C_{\\text{tot}}(\\tau, \\Delta t) + \\lambda (E_{\\text{tot}}(\\tau, \\Delta t) - \\varepsilon)\n$$\n代入函数的具体形式，我们得到：\n$$\n\\mathcal{L}(\\tau, \\Delta t, \\lambda) = T\\alpha\\frac{\\tau}{\\Delta t} + \\lambda(a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} - \\varepsilon)\n$$\n最优解 $(\\tau^{\\star}, \\Delta t^{\\star})$ 必须满足将拉格朗日函数关于 $\\tau$、$\\Delta t$ 和 $\\lambda$ 的偏导数设为零所得到的方程组。\n\n1.  关于 $\\tau$ 的偏导数：\n    $$\n    \\frac{\\partial\\mathcal{L}}{\\partial \\tau} = \\frac{T\\alpha}{\\Delta t} + \\lambda b \\left(-\\frac{1}{2}\\tau^{-3/2}\\right) = 0 \\implies \\frac{T\\alpha}{\\Delta t} = \\frac{\\lambda b}{2}\\tau^{-3/2}\n    $$\n2.  关于 $\\Delta t$ 的偏导数：\n    $$\n    \\frac{\\partial\\mathcal{L}}{\\partial \\Delta t} = T\\alpha\\tau \\left(-\\frac{1}{\\Delta t^2}\\right) + \\lambda a p \\Delta t^{p-1} = 0 \\implies \\frac{T\\alpha\\tau}{\\Delta t^2} = \\lambda a p \\Delta t^{p-1}\n    $$\n3.  关于 $\\lambda$ 的偏导数：\n    $$\n    \\frac{\\partial\\mathcal{L}}{\\partial \\lambda} = a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} - \\varepsilon = 0\n    $$\n\n从前两个方程中，我们可以解出拉格朗日乘子 $\\lambda$：\n从方程(1)可得：\n$$\n\\lambda = \\frac{2T\\alpha\\tau^{3/2}}{b\\Delta t}\n$$\n从方程(2)可得：\n$$\n\\lambda = \\frac{T\\alpha\\tau}{ap\\Delta t^{p+1}}\n$$\n\n令这两个关于 $\\lambda$ 的表达式相等，我们可以在最优点找到 $\\tau$ 和 $\\Delta t$ 之间的关系：\n$$\n\\frac{2T\\alpha\\tau^{3/2}}{b\\Delta t} = \\frac{T\\alpha\\tau}{ap\\Delta t^{p+1}}\n$$\n由于 $T0$、$\\alpha0$、$\\tau0$ 和 $\\Delta t0$，我们可以将等式两边同时除以 $T\\alpha\\tau/\\Delta t$：\n$$\n\\frac{2\\tau^{1/2}}{b} = \\frac{1}{ap\\Delta t^p}\n$$\n重新整理可得最优性条件：\n$$\n2ap\\Delta t^p = b\\tau^{-1/2}\n$$\n该条件代表了两种误差来源之间的最优平衡。宏观层面误差 $a\\Delta t^p$ 应为微观层面误差 $b\\tau^{-1/2}$ 的 $1/(2p)$ 倍。\n\n现在我们可以使用这个条件来求解最优值。将 $b\\tau^{-1/2} = 2ap\\Delta t^p$ 代入约束方程 $a\\,\\Delta t^{p} + b\\,\\tau^{-1/2} = \\varepsilon$：\n$$\na\\,\\Delta t^{p} + 2ap\\Delta t^p = \\varepsilon\n$$\n$$\na\\Delta t^p (1 + 2p) = \\varepsilon\n$$\n求解 $\\Delta t^p$：\n$$\n(\\Delta t^{\\star})^p = \\frac{\\varepsilon}{a(1+2p)}\n$$\n因此，最优宏观时间步长为：\n$$\n\\Delta t^{\\star} = \\left(\\frac{\\varepsilon}{a(1+2p)}\\right)^{1/p}\n$$\n接下来，为了求出最优的 $\\tau$，我们将 $a\\Delta t^p = \\frac{b\\tau^{-1/2}}{2p}$ 代入约束方程：\n$$\n\\frac{b\\tau^{-1/2}}{2p} + b\\tau^{-1/2} = \\varepsilon\n$$\n$$\nb\\tau^{-1/2}\\left(\\frac{1}{2p} + 1\\right) = \\varepsilon\n$$\n$$\nb\\tau^{-1/2}\\left(\\frac{1+2p}{2p}\\right) = \\varepsilon\n$$\n求解 $\\tau^{-1/2}$：\n$$\n(\\tau^{\\star})^{-1/2} = \\frac{2p\\varepsilon}{b(1+2p)}\n$$\n将两边平方后取倒数，得到最优微观模拟片段持续时间：\n$$\n\\tau^{\\star} = \\left(\\frac{b(1+2p)}{2p\\varepsilon}\\right)^2\n$$\n这些关于 $\\tau^{\\star}$ 和 $\\Delta t^{\\star}$ 的表达式提供了在给定误差容限 $\\varepsilon$ 下使总计算成本最小化的最优参数选择。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\left( \\frac{b(1+2p)}{2p \\varepsilon} \\right)^2 \\\\ \\left( \\frac{\\varepsilon}{a(1+2p)} \\right)^{1/p} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "许多复杂的宏观动力学系统表现出记忆效应，其演化不仅取决于当前状态，还依赖于历史路径，这通常通过记忆核函数来描述。然而，这些记忆核函数的形式往往是未知的，需要从底层的微观模拟数据中提取。本练习提供了一个基于真实世界挑战的计算任务：使用Prony方法从一个带噪声的时间序列数据中拟合一个由指数衰减函数叠加而成的记忆核，并利用贝叶斯信息准则（Bayesian Information Criterion, BIC）来确定模型的最佳复杂度 。这个实践将理论与数据分析相结合，展示了如何从数据出发构建有效的粗粒化模型。",
            "id": "3813605",
            "problem": "给定一个微观尺度的离散时间序列，该序列采样了用于多尺度建模中时间桥接方案的记忆核。在许多粗粒度描述中，具有记忆性的可观测量遵循一种积分微分演化形式：$$\\frac{d q(t)}{d t} = F\\big(q(t)\\big) + \\int_{0}^{t} K(t-s)\\, G\\big(q(s)\\big)\\, ds,$$ 其中未知的记忆核 $K(t)$ 通常可以近似为衰减指数和，这使得跨尺度的有效时间桥接成为可能。假设微观时间序列在等间隔时间点 $t_n = n\\,\\Delta t$（对于 $n = 0,1,\\dots,N-1$）提供样本 $s_n \\approx K(n\\,\\Delta t)$，并且 $K(t)$ 具有表示形式 $K(t) \\approx \\sum_{j=1}^{p} a_j e^{-b_j t}$，其中未知的振幅 $a_j$ 和衰减率 $b_j > 0$。等价地，在离散时间中，模型为 $s_n \\approx \\sum_{j=1}^{p} a_j r_j^n$，其中 $r_j = e^{-b_j \\Delta t}$ 满足 $0  r_j  1$（对于正衰减率）。\n\n从该表示和离散时间线性预测（普罗尼方法，Prony’s method）的定义出发，将模型阶数选择问题构建为一个高斯测量噪声下的信息论问题。在假设测量误差是独立同分布的高斯分布（方差为 $\\sigma^2$），并且使用最大似然估计来拟合参数的条件下，赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC）可以表示为残差平方和 $\\mathrm{RSS} = \\sum_{n=0}^{N-1} \\left(s_n - \\hat{s}_n\\right)^2$ 和自由参数数量 $k$ 的函数。对于一个离散时间中的 $p$-指数模型，将 $k$ 视为 $2p$（每个指数项有一个参数 $a_j$ 和一个参数 $r_j$）。\n\n你的任务是，从第一性原理出发，实现以下内容：\n- 一个普罗尼方法估计器：对于每个候选阶数 $p$，通过最小二乘法计算线性预测系数，从相关的特征多项式的根中提取离散衰减因子 $r_j$，并使用对范德蒙系统的最小二乘拟合来估计振幅 $a_j$。\n- 一个信息准则评估器：对于每个 $p$，计算 $\\mathrm{RSS}$，然后计算 $\\mathrm{AIC}(p) = N \\ln\\left(\\mathrm{RSS}/N\\right) + 2k$ 和 $\\mathrm{BIC}(p) = N \\ln\\left(\\mathrm{RSS}/N\\right) + k \\ln(N)$。\n- 一个模型阶数选择器：选择使 $\\mathrm{BIC}(p)$ 最小化的 $p$ 作为 $p^\\ast$，若有多个相同的最小值，则优先选择最小的 $p$。\n\n本问题中的微观时间序列是使用已知的真实参数和加性高斯噪声综合生成的，以保证可测试性。对于每个测试用例，通过 $s_n = \\sum_{j=1}^{p_{\\text{true}}} a_j e^{-b_j n \\Delta t} + \\varepsilon_n$ 生成 $s_n$，其中 $\\varepsilon_n \\sim \\mathcal{N}(0,\\sigma^2)$ 在 $n$ 上是独立的，然后执行上述模型选择。\n\n实现你的程序，使其能够解决以下测试套件：\n- 测试用例 $1$ (正常路径)：$\\Delta t = 0.05$, $N = 64$, $p_{\\text{true}} = 2$, 振幅 $a = [1.0, 0.3]$, 衰减率 $b = [1.8, 0.6]$, 噪声标准差 $\\sigma = 0.002$, 需考虑的最大模型阶数 $p_{\\max} = 4$。\n- 测试用例 $2$ (接近最小长度和低噪声的边界条件)：$\\Delta t = 0.1$, $N = 20$, $p_{\\text{true}} = 1$, 振幅 $a = [0.8]$, 衰减率 $b = [1.2]$, 噪声标准差 $\\sigma = 0.0005$, 需考虑的最大模型阶数 $p_{\\max} = 4$。\n- 测试用例 $3$ (包含三个指数和中等噪声的边缘情况)：$\\Delta t = 0.02$, $N = 120$, $p_{\\text{true}} = 3$, 振幅 $a = [0.4, 0.6, 0.2]$, 衰减率 $b = [2.5, 1.0, 0.15]$, 噪声标准差 $\\sigma = 0.003$, 需考虑的最大模型阶数 $p_{\\max} = 5$。\n\n信息准则的缩写必须在首次使用时定义：赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC）。\n\n你的程序应生成单行输出，其中包含三个测试用例各自选定的阶数 $p^\\ast$，按顺序排列，形式为方括号括起来的逗号分隔列表（例如 $[p_1,p_2,p_3]$）。输出为整数。不涉及物理单位；所有量均为无量纲。通过使用固定的随机种子生成噪声来确保可复现性。你的实现必须是自包含的，无需任何用户输入即可运行，并且必须遵循为最终答案指定的执行环境约束。",
            "solution": "该问题要求为一个表示为衰减指数和的信号选择最优的模型阶数。这项任务置于多尺度建模的背景下，其中此类指数和用于近似粗粒度动力学方程中的记忆核。该方法论包括两个主要部分：使用普罗尼方法（Prony's method）对给定模型阶数进行参数估计，以及使用贝叶斯信息准则（BIC）进行模型选择。\n\n在间隔 $\\Delta t$ 采样的离散时间序列 $s_n$ 的基础模型由下式给出：\n$$s_n = \\sum_{j=1}^{p} a_j r_j^n + \\varepsilon_n, \\quad n=0, 1, \\dots, N-1$$\n其中 $a_j$ 是振幅，$r_j = e^{-b_j \\Delta t}$ 是对应于连续时间衰减率 $b_j > 0$ 的离散衰减因子，$p$ 是模型阶数，$\\varepsilon_n$ 是均值为 $0$、方差为 $\\sigma^2$ 的独立同分布高斯噪声。目标是从数据中确定最合理的阶数 $p$。\n\n### 1. 通过普罗尼方法进行参数估计\n\n对于一个固定的候选阶数 $p$，普罗尼方法提供了一个估计参数 $\\{a_j, r_j\\}_{j=1}^p$ 的程序。该方法巧妙地将这个非线性估计问题转化为一个包含两个线性最小二乘问题的序列。\n\n#### 步骤 1A：线性预测与特征多项式\n\n普罗尼方法的基础在于一个观察：一个由 $p$ 个指数组成的无噪声信号 $s_n = \\sum_{j=1}^{p} a_j r_j^n$ 是一个 $p$-阶线性齐次递推关系的解。该关系由一个特征多项式 $\\Psi(z)$ 定义，其根恰好是衰减因子 $r_j$：\n$$\\Psi(z) = \\prod_{j=1}^{p} (z - r_j) = z^p + c_1 z^{p-1} + \\dots + c_p$$\n这里，$\\{c_i\\}_{i=1}^p$ 是多项式系数。该递推关系为 $\\Psi(E)s_n = 0$，其中 $E$ 是移位算子（$Es_n = s_{n+1}$），明确地给出：\n$$s_{n+p} + c_1 s_{n+p-1} + \\dots + c_p s_n = 0$$\n这可以被重排为一种线性预测形式：\n$$s_k = - \\sum_{i=1}^{p} c_i s_{k-i}$$\n对于 $k \\ge p$。在存在噪声的情况下，这个关系不是精确的。然而，我们可以找到系数 $c_i$，使其在最小二乘意义下最好地满足这个关系。我们为未知系数 $\\mathbf{c} = [c_1, c_2, \\dots, c_p]^T$ 建立一个超定线性方程组。该系统是为 $k = p, p+1, \\dots, N-1$ 构建的：\n$$\n\\begin{pmatrix}\ns_{p-1}  s_{p-2}  \\dots  s_0 \\\\\ns_p  s_{p-1}  \\dots  s_1 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\ns_{N-2}  s_{N-3}  \\dots  s_{N-p-1}\n\\end{pmatrix}\n\\begin{pmatrix} c_1 \\\\ c_2 \\\\ \\vdots \\\\ c_p \\end{pmatrix}\n\\approx\n-\\begin{pmatrix} s_p \\\\ s_{p+1} \\\\ \\vdots \\\\ s_{N-1} \\end{pmatrix}\n$$\n这是一个形式为 $A\\mathbf{c} \\approx \\mathbf{b}$ 的标准线性最小二乘问题，通过求解它可得到系数向量 $\\mathbf{c}$。方程的数量是 $N-p$，未知数的数量是 $p$。对于一个适定的超定系统，我们需要 $N-p \\ge p$，即 $N \\ge 2p$。\n\n#### 步骤 1B：衰减因子 ($r_j$) 的估计\n\n利用估计出的系数 $\\hat{c}_i$，我们构建估计的特征多项式：\n$$\\hat{\\Psi}(z) = z^p + \\hat{c}_1 z^{p-1} + \\dots + \\hat{c}_p$$\n该多项式的根 $\\hat{r}_1, \\hat{r}_2, \\dots, \\hat{r}_p$ 是离散衰减因子的估计值。这些根可以使用标准数值多项式求根算法找到。\n\n#### 步骤 1C：振幅 ($a_j$) 的估计\n\n一旦确定了衰减因子 $\\hat{r}_j$，原始模型 $s_n \\approx \\sum_{j=1}^{p} a_j \\hat{r}_j^n$ 在未知振幅 $a_j$ 上就变成了线性的。因此，我们可以使用另一次线性最小二乘拟合来求解振幅。我们使用所有 $N$ 个数据点（$n=0, \\dots, N-1$）构建以下超定系统：\n$$\n\\begin{pmatrix}\n\\hat{r}_1^0  \\hat{r}_2^0  \\dots  \\hat{r}_p^0 \\\\\n\\hat{r}_1^1  \\hat{r}_2^1  \\dots  \\hat{r}_p^1 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\n\\hat{r}_1^{N-1}  \\hat{r}_2^{N-1}  \\dots  \\hat{r}_p^{N-1}\n\\end{pmatrix}\n\\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_p \\end{pmatrix}\n\\approx\n\\begin{pmatrix} s_0 \\\\ s_1 \\\\ \\vdots \\\\ s_{N-1} \\end{pmatrix}\n$$\n左边的矩阵是一个范德蒙矩阵 $V$。系统 $V\\mathbf{a} \\approx \\mathbf{s}$ 通过求解得到振幅向量 $\\mathbf{a} = [a_1, a_2, \\dots, a_p]^T$，从而完成了对给定阶数 $p$ 的参数估计。\n\n### 2. 模型阶数选择\n\n在为一系列候选阶数 $p=1, 2, \\dots, p_{\\max}$ 估计参数后，我们必须选择最合适的一个。信息准则通过平衡模型保真度（拟合优度）与模型复杂度，为这一选择提供了原则性的方法。\n\n#### 步骤 2A：残差平方和 (RSS)\n\n对于每个阶数为 $p$ 的模型，我们首先使用估计的参数重构信号：\n$$\\hat{s}_n(p) = \\sum_{j=1}^{p} \\hat{a}_j \\hat{r}_j^n$$\n拟合优度由残差平方和（$\\mathrm{RSS}$）量化：\n$$\\mathrm{RSS}(p) = \\sum_{n=0}^{N-1} \\left(s_n - \\hat{s}_n(p)\\right)^2$$\n较低的 $\\mathrm{RSS}$ 表示对数据更好的拟合。\n\n#### 步骤 2B：贝叶斯信息准则 (BIC)\n\n贝叶斯信息准则（BIC）定义为：\n$$\\mathrm{BIC}(p) = N \\ln\\left(\\frac{\\mathrm{RSS}(p)}{N}\\right) + k \\ln(N)$$\n其中 $N$ 是数据点的数量，$k$ 是模型中的自由参数数量。对于一个 $p$-指数模型，我们有 $p$ 个振幅 ($a_j$) 和 $p$ 个衰减因子 ($r_j$)，所以参数总数为 $k=2p$。\n\nBIC 目标函数惩罚模型复杂度。第一项 $N \\ln(\\mathrm{RSS}/N)$ 随着模型更好地拟合数据（即 $\\mathrm{RSS}$ 减小）而减小。第二项 $k \\ln(N)$ 随着参数数量 $p$ 的增加而增加。最优模型阶数 $p^\\ast$ 是使 BIC 最小化的那个，代表了拟合与复杂度之间的最佳权衡。\n\n#### 步骤 2C：选择策略\n\n整个过程如下：\n1.  对于每个候选阶数 $p \\in \\{1, 2, \\dots, p_{\\max}\\}$：\n    a.  应用普罗尼方法估计参数 $\\{\\hat{a}_j, \\hat{r}_j\\}_{j=1}^p$。\n    b.  重构信号 $\\hat{s}_n(p)$ 并计算 $\\mathrm{RSS}(p)$。\n    c.  使用参数数量 $k=2p$ 计算 $\\mathrm{BIC}(p)$。\n2.  选择最优阶数 $p^\\ast$ 作为产生最小 $\\mathrm{BIC}(p)$ 值的 $p$。若有多个相同的最小值，则选择最小的 $p$。\n\n这个过程对每个提供的测试用例都予以实施，首先根据指定的真实参数和噪声水平生成综合时间序列。固定的随机种子确保了噪声生成的可复现性，从而也保证了最终结果的可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model order selection problem for a sum of exponentials\n    using Prony's method and the Bayesian Information Criterion (BIC).\n    \"\"\"\n    # Use a fixed random seed for reproducible noise generation.\n    np.random.seed(0)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'dt': 0.05, 'N': 64, 'p_true': 2, 'a': [1.0, 0.3], 'b': [1.8, 0.6], 'sigma': 0.002, 'p_max': 4},\n        {'dt': 0.1, 'N': 20, 'p_true': 1, 'a': [0.8], 'b': [1.2], 'sigma': 0.0005, 'p_max': 4},\n        {'dt': 0.02, 'N': 120, 'p_true': 3, 'a': [0.4, 0.6, 0.2], 'b': [2.5, 1.0, 0.15], 'sigma': 0.003, 'p_max': 5}\n    ]\n\n    selected_orders = []\n\n    for case in test_cases:\n        dt, N, a_true, b_true, sigma, p_max = \\\n            case['dt'], case['N'], case['a'], case['b'], case['sigma'], case['p_max']\n\n        # 1. Generate the synthetic noisy time series s_n\n        t = np.arange(N) * dt\n        r_true = np.exp(-np.array(b_true) * dt)\n\n        # Generate the clean signal using a Vandermonde matrix approach\n        V_true = np.vander(r_true, N, increasing=True).T\n        s_clean = V_true @ np.array(a_true)\n        \n        # Add independent and identically distributed Gaussian noise\n        noise = np.random.normal(loc=0.0, scale=sigma, size=N)\n        s_n = s_clean + noise\n\n        # 2. Iterate through candidate model orders p to find the best one\n        min_bic = float('inf')\n        p_star = -1\n\n        for p in range(1, p_max + 1):\n            \n            # Prony's method requires N >= 2p for the first least squares problem\n            # to be overdetermined or exactly determined.\n            if N  2 * p:\n                continue\n\n            # --- Prony's Method Implementation ---\n\n            # 2a. Solve for linear prediction coefficients c.\n            # Set up the linear system Ac = b.\n            # A has shape (N-p, p), b has shape (N-p,).\n            A = np.zeros((N - p, p))\n            for i in range(p):\n                A[:, i] = s_n[p - 1 - i : N - 1 - i]\n            b = -s_n[p:N]\n            \n            # Solve for c using linear least squares.\n            c, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n            \n            # 2b. Find the roots of the characteristic polynomial.\n            # The coefficients are [1, c_1, c_2, ...].\n            poly_coeffs = np.concatenate(([1], c))\n            roots = np.roots(poly_coeffs)\n            \n            # 2c. Solve for the amplitudes a.\n            # Set up the Vandermonde system Va = s_n.\n            V = np.vander(roots, N, increasing=True).T\n            \n            # Solve for a using linear least squares.\n            a, residuals, _, _ = np.linalg.lstsq(V, s_n, rcond=None)\n            \n            # --- Model Selection using BIC ---\n            \n            # Reconstruct the fitted signal to calculate RSS.\n            # Note: The RSS can also be obtained directly from the residuals\n            # of the lstsq fit for 'a'.\n            s_hat = V @ a\n            rss = np.sum((s_n - s_hat)**2)\n            \n            # If the fit is perfect (unlikely with noise), rss could be 0.\n            # log(0) is -inf, so we handle this case to avoid errors.\n            if rss = 1e-12: # Check against a small epsilon\n                bic_val = -float('inf') \n            else:\n                # The number of free parameters k is 2*p (p amplitudes, p decays).\n                k = 2 * p\n                # Bayesian Information Criterion (BIC)\n                bic_val = N * np.log(rss / N) + k * np.log(N)\n            \n            # Update the best model order p* if a lower BIC is found.\n            # The loop structure naturally breaks ties by preferring smaller p.\n            if bic_val  min_bic:\n                min_bic = bic_val\n                p_star = p\n        \n        selected_orders.append(p_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, selected_orders))}]\")\n\nsolve()\n```"
        }
    ]
}