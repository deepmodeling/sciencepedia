{
    "hands_on_practices": [
        {
            "introduction": "Before studying the collective dynamics of a particle system, we must first understand its states of equilibrium. This exercise  provides practice in identifying the invariant measures for the Symmetric Simple Exclusion Process (SSEP), which serve as the microscopic foundation for macroscopic equilibrium. By working through this problem, you will see why spatially uniform density profiles are the natural equilibrium states and why the net particle current vanishes in this regime.",
            "id": "3768642",
            "problem": "Consider the Symmetric Simple Exclusion Process (SSEP) on the one-dimensional integer lattice $\\mathbb{Z}$ with state space $\\{0,1\\}^{\\mathbb{Z}}$, where a configuration is denoted by $\\eta = (\\eta(x))_{x \\in \\mathbb{Z}}$ with $\\eta(x) \\in \\{0,1\\}$ indicating the occupation at site $x$. The dynamics is given by the Markov generator acting on local (cylinder) functions $f$ by\n$$\n(L f)(\\eta) \\;=\\; \\sum_{x \\in \\mathbb{Z}} \\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big)\\big(f(\\eta^{x,x+1}) - f(\\eta)\\big) \\;+\\; \\eta(x+1)\\big(1-\\eta(x)\\big)\\big(f(\\eta^{x,x+1}) - f(\\eta)\\big) \\Big],\n$$\nwhere $\\eta^{x,x+1}$ denotes the configuration obtained from $\\eta$ by exchanging the occupations at sites $x$ and $x+1$. Let $\\mu_{\\mathbf{p}}$ be a Bernoulli product measure on $\\{0,1\\}^{\\mathbb{Z}}$ with site-dependent marginals $\\mathbf{p} = (p_x)_{x \\in \\mathbb{Z}}$, i.e., under $\\mu_{\\mathbf{p}}$ the variables $\\eta(x)$ are independent and $\\mu_{\\mathbf{p}}(\\eta(x)=1) = p_x \\in [0,1]$.\n\n(a) Using only the definition of the generator $L$ and the invariance criterion for a stationary measure (that is, $\\int L f \\, d\\mu = 0$ for all local functions $f$), derive a necessary and sufficient condition on the sequence $(p_x)_{x \\in \\mathbb{Z}}$ for $\\mu_{\\mathbf{p}}$ to be invariant under SSEP. Conclude that the only translation-invariant Bernoulli product invariant measures are the homogeneous Bernoulli product measures $\\nu_{\\rho}$ with density parameter $\\rho \\in [0,1]$, i.e., $p_x \\equiv \\rho$ for all $x \\in \\mathbb{Z}$.\n\n(b) For the homogeneous Bernoulli product invariant measure $\\nu_{\\rho}$, define the microscopic current across the bond $(0,1)$ by\n$$\nj_{0,1}(\\eta) \\;=\\; \\eta(0)\\big(1-\\eta(1)\\big) \\;-\\; \\eta(1)\\big(1-\\eta(0)\\big).\n$$\nCompute the expectation $\\mathbb{E}_{\\nu_{\\rho}}\\!\\left[ j_{0,1}(\\eta) \\right]$ as an explicit expression in terms of $\\rho$.\n\nYour final answer must be a single real number or a closed-form expression; no rounding is required.",
            "solution": "We begin from the fundamental definition of the Symmetric Simple Exclusion Process (SSEP) through its Markov generator $L$ and use the invariance criterion for stationary measures: a probability measure $\\mu$ is invariant if and only if $\\int (L f)(\\eta) \\, \\mu(d\\eta) = 0$ for all local functions $f$.\n\nPart (a): Characterization of invariant Bernoulli product measures.\n\nLet $\\mu_{\\mathbf{p}}$ be a Bernoulli product measure with independent coordinates and site-dependent marginals $(p_x)_{x \\in \\mathbb{Z}}$, where $p_x = \\mu_{\\mathbf{p}}(\\eta(x)=1)$. To derive a necessary condition for invariance, it suffices to impose the condition on a separating family of local observables. A natural choice is $f(\\eta) = \\eta(x)$ for a fixed $x \\in \\mathbb{Z}$. We compute $(L \\eta(x))(\\eta)$ by listing all transitions that change $\\eta(x)$. Only exchanges across bonds $(x-1,x)$ and $(x,x+1)$ affect $\\eta(x)$.\n\nBy definition of $L$,\n\\begin{align*}\n(L \\eta(x))(\\eta)\n&= \\big[ \\eta(x-1)\\big(1-\\eta(x)\\big) - \\eta(x)\\big(1-\\eta(x-1)\\big) \\big]\n\\\\\n&\\quad + \\big[ \\eta(x+1)\\big(1-\\eta(x)\\big) - \\eta(x)\\big(1-\\eta(x+1)\\big) \\big].\n\\end{align*}\nIndeed, the first bracket corresponds to inflow to $x$ from $x-1$ minus outflow from $x$ to $x-1$, and the second bracket corresponds to inflow to $x$ from $x+1$ minus outflow from $x$ to $x+1$.\n\nTaking expectation with respect to $\\mu_{\\mathbf{p}}$ and using independence of $\\eta(x-1)$, $\\eta(x)$, and $\\eta(x+1)$,\n\\begin{align*}\n\\mathbb{E}_{\\mu_{\\mathbf{p}}}[(L \\eta(x))(\\eta)]\n&= \\mathbb{E}[\\eta(x-1)(1-\\eta(x))] - \\mathbb{E}[\\eta(x)(1-\\eta(x-1))]\n\\\\\n&\\quad + \\mathbb{E}[\\eta(x+1)(1-\\eta(x))] - \\mathbb{E}[\\eta(x)(1-\\eta(x+1))].\n\\end{align*}\nEach expectation factorizes:\n\\begin{align*}\n\\mathbb{E}[\\eta(x-1)(1-\\eta(x))] &= p_{x-1}(1-p_x), \\\\\n\\mathbb{E}[\\eta(x)(1-\\eta(x-1))] &= p_x(1-p_{x-1}), \\\\\n\\mathbb{E}[\\eta(x+1)(1-\\eta(x))] &= p_{x+1}(1-p_x), \\\\\n\\mathbb{E}[\\eta(x)(1-\\eta(x+1))] &= p_x(1-p_{x+1}).\n\\end{align*}\nTherefore,\n\\begin{align*}\n\\mathbb{E}_{\\mu_{\\mathbf{p}}}[(L \\eta(x))(\\eta)]\n&= \\big[p_{x-1}(1-p_x) - p_x(1-p_{x-1})\\big] + \\big[p_{x+1}(1-p_x) - p_x(1-p_{x+1})\\big] \\\\\n&= (p_{x-1} - p_x) + (p_{x+1} - p_x) \\\\\n&= p_{x-1} + p_{x+1} - 2 p_x.\n\\end{align*}\nThe invariance criterion requires $\\mathbb{E}_{\\mu_{\\mathbf{p}}}[(L \\eta(x))(\\eta)] = 0$ for all $x \\in \\mathbb{Z}$, hence the necessary condition\n$$\np_{x-1} + p_{x+1} - 2 p_x = 0 \\quad \\text{for all } x \\in \\mathbb{Z}.\n$$\nThis is the discrete Laplace equation (discrete harmonicity) for the sequence $(p_x)_{x \\in \\mathbb{Z}}$. Its general solution on $\\mathbb{Z}$ is affine: $p_x = a x + b$ for constants $a,b \\in \\mathbb{R}$. Since $p_x \\in [0,1]$ for all $x$, boundedness forces $a=0$, and thus $p_x \\equiv b$ is constant. Writing $b = \\rho \\in [0,1]$, we obtain $p_x \\equiv \\rho$ for all $x$.\n\nThis shows that a necessary condition for $\\mu_{\\mathbf{p}}$ to be invariant is that it be the homogeneous Bernoulli product measure $\\nu_{\\rho}$ with constant density $\\rho$.\n\nTo show sufficiency, let $\\nu_{\\rho}$ be the homogeneous Bernoulli product measure with marginal $\\nu_{\\rho}(\\eta(x)=1) = \\rho$ at every site, independently. For any local function $f$, we compute $\\mathbb{E}_{\\nu_{\\rho}}[(L f)(\\eta)]$ and use a change-of-variables argument on configurations. Write the generator’s contribution from bond $(x,x+1)$:\n\\begin{align*}\n\\mathbb{E}_{\\nu_{\\rho}}[(L f)(\\eta)]\n&= \\sum_{x \\in \\mathbb{Z}} \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big)\\big(f(\\eta^{x,x+1}) - f(\\eta)\\big) \\\\\n&\\qquad\\qquad\\qquad\\qquad\\quad + \\eta(x+1)\\big(1-\\eta(x)\\big)\\big(f(\\eta^{x,x+1}) - f(\\eta)\\big) \\Big].\n\\end{align*}\nConsider the first term in the summand. Under $\\nu_{\\rho}$, the law of $\\eta$ is invariant under exchanging the occupations at $x$ and $x+1$ because the marginal at each site is the same and sites are independent. Hence, by the change of variables $\\eta \\mapsto \\eta^{x,x+1}$,\n\\begin{align*}\n\\mathbb{E}_{\\nu_{\\rho}}\\big[\\eta(x)\\big(1-\\eta(x+1)\\big) f(\\eta^{x,x+1})\\big]\n&= \\mathbb{E}_{\\nu_{\\rho}}\\big[\\eta(x+1)\\big(1-\\eta(x)\\big) f(\\eta)\\big].\n\\end{align*}\nApplying this identity to both terms and pairing like contributions, we obtain exact cancellation for each $x$:\n\\begin{align*}\n&\\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big) f(\\eta^{x,x+1}) \\Big]\n- \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big) f(\\eta) \\Big] \\\\\n&\\quad + \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x+1)\\big(1-\\eta(x)\\big) f(\\eta^{x,x+1}) \\Big]\n- \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x+1)\\big(1-\\eta(x)\\big) f(\\eta) \\Big] \\\\\n&= \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x+1)\\big(1-\\eta(x)\\big) f(\\eta) \\Big]\n- \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big) f(\\eta) \\Big] \\\\\n&\\quad + \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x)\\big(1-\\eta(x+1)\\big) f(\\eta) \\Big]\n- \\mathbb{E}_{\\nu_{\\rho}}\\Big[ \\eta(x+1)\\big(1-\\eta(x)\\big) f(\\eta) \\Big] \\\\\n&= 0.\n\\end{align*}\nTherefore, $\\mathbb{E}_{\\nu_{\\rho}}[(L f)(\\eta)] = 0$ for all local functions $f$, so $\\nu_{\\rho}$ is invariant. Combining necessity and sufficiency, we conclude that the Bernoulli product invariant measures under SSEP are precisely the homogeneous product measures $\\nu_{\\rho}$, $\\rho \\in [0,1]$, and among translation-invariant product measures, these are the only invariant ones.\n\nPart (b): Microscopic current expectation under $\\nu_{\\rho}$.\n\nBy definition, the microscopic current across bond $(0,1)$ is\n$$\nj_{0,1}(\\eta) \\;=\\; \\eta(0)\\big(1-\\eta(1)\\big) \\;-\\; \\eta(1)\\big(1-\\eta(0)\\big).\n$$\nWe can also rewrite it algebraically as\n\\begin{align*}\nj_{0,1}(\\eta)\n&= \\eta(0) - \\eta(0)\\eta(1) - \\eta(1) + \\eta(0)\\eta(1) \\\\\n&= \\eta(0) - \\eta(1).\n\\end{align*}\nTaking expectation under the homogeneous Bernoulli product measure $\\nu_{\\rho}$ with independent sites and $\\mathbb{E}_{\\nu_{\\rho}}[\\eta(0)] = \\mathbb{E}_{\\nu_{\\rho}}[\\eta(1)] = \\rho$, we obtain\n\\begin{align*}\n\\mathbb{E}_{\\nu_{\\rho}}\\!\\left[ j_{0,1}(\\eta) \\right]\n&= \\mathbb{E}_{\\nu_{\\rho}}[\\eta(0)] - \\mathbb{E}_{\\nu_{\\rho}}[\\eta(1)] \\\\\n&= \\rho - \\rho \\\\\n&= 0.\n\\end{align*}\nHence, the expected microscopic current across any bond under $\\nu_{\\rho}$ is zero, reflecting the absence of drift in symmetric dynamics.\n\nNo rounding is required, and the final answer is exact.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "This practice  represents the core of the hydrodynamic limit program: deriving a macroscopic partial differential equation from the underlying stochastic particle dynamics. You will track the evolution of the empirical density measure under diffusive scaling, using discrete integration by parts and Taylor expansions to see how the microscopic conservation law for particles transforms into the continuous heat equation. This exercise provides direct experience in calculating a fundamental physical parameter—the diffusion coefficient—from first principles.",
            "id": "3768599",
            "problem": "Consider the Simple Symmetric Exclusion Process (SSEP) on the discrete torus $\\mathbb{T}_{N}^{d} \\equiv (\\mathbb{Z}/N\\mathbb{Z})^{d}$ with $d \\in \\mathbb{N}$. A configuration is denoted by $\\eta \\in \\{0,1\\}^{\\mathbb{T}_{N}^{d}}$, where $\\eta(x) = 1$ if site $x \\in \\mathbb{T}_{N}^{d}$ is occupied and $\\eta(x) = 0$ otherwise. The process is defined as the continuous-time Markov chain with generator\n$$\n\\mathcal{L}_{N} f(\\eta) \\;=\\; \\sum_{x \\in \\mathbb{T}_{N}^{d}} \\sum_{i=1}^{d} \\Big( f\\big(\\eta^{x,x+e_{i}}\\big) - f(\\eta) \\Big),\n$$\nwhere $e_{i}$ is the $i$-th coordinate unit vector and $\\eta^{x,x+e_{i}}$ is the configuration obtained from $\\eta$ by exchanging the occupations at $x$ and $x+e_{i}$. Assume the process is started from a sequence of initial laws associated with a macroscopic profile $\\rho_{0} \\in C^{2}(\\mathbb{T}^{d};[0,1])$ in the usual sense of convergence of empirical measures. Consider the empirical density measure on the continuous torus $\\mathbb{T}^{d} \\equiv (\\mathbb{R}/\\mathbb{Z})^{d}$,\n$$\n\\pi_{t}^{N}(du) \\;=\\; \\frac{1}{N^{d}} \\sum_{x \\in \\mathbb{T}_{N}^{d}} \\eta_{tN^{2}}(x) \\, \\delta_{x/N}(du),\n$$\nthat is, evolve the process under the diffusive time scaling $t \\mapsto tN^{2}$ and rescale space by $N$.\n\nUsing only the microscopic conservation law and the generator $\\mathcal{L}_{N}$ above, derive the macroscopic conservation law for the density field by testing against a smooth function $\\varphi \\in C^{\\infty}(\\mathbb{T}^{d})$, and identify the diffusion coefficient $D$ in the limiting Partial Differential Equation (PDE) of the hydrodynamic limit. You must compute the explicit value of $D$ under the normalized symmetric nearest-neighbor scaling encoded by the generator $\\mathcal{L}_{N}$ and the diffusive time acceleration $t \\mapsto tN^{2}$.\n\nYour final answer must be a single real-valued number equal to the computed diffusion coefficient. No rounding is required and no physical units are involved. Express the final answer as an exact number.",
            "solution": "The hydrodynamic limit is found by studying the evolution of the empirical measure $\\pi_t^N$ in the limit $N \\to \\infty$. We test the measure against a smooth, arbitrary test function $\\varphi \\in C^{\\infty}(\\mathbb{T}^d)$. Let $\\langle \\cdot \\rangle$ denote the expectation with respect to the process. The quantity of interest is\n$$\n\\langle \\pi_t^N(\\varphi) \\rangle = \\left\\langle \\int_{\\mathbb{T}^d} \\varphi(u) \\, \\pi_t^N(du) \\right\\rangle = \\left\\langle \\frac{1}{N^d} \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) \\varphi(x/N) \\right\\rangle\n$$\nWe compute the time derivative of this quantity. Let $s = tN^2$ be the microscopic time. Using the property that for any observable $g$, $\\frac{d}{ds} \\langle g(\\eta_s) \\rangle = \\langle (\\mathcal{L}_N g)(\\eta_s) \\rangle$, and the chain rule, we have:\n$$\n\\frac{d}{dt} \\langle \\pi_t^N(\\varphi) \\rangle = \\frac{d}{dt} \\left\\langle \\frac{1}{N^d} \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) \\varphi(x/N) \\right\\rangle = N^2 \\left\\langle \\mathcal{L}_N \\left( \\frac{1}{N^d} \\sum_{y \\in \\mathbb{T}_N^d} \\eta(y) \\varphi(y/N) \\right) \\Big|_{\\eta=\\eta_{tN^2}} \\right\\rangle\n$$\nThe factor $N^2$ is due to the diffusive time scaling $s=tN^2$. Let $f(\\eta) = \\sum_y \\eta(y) \\varphi(y/N)$. We apply the generator $\\mathcal{L}_N$ to $f(\\eta)$:\n$$\n\\mathcal{L}_N f(\\eta) = \\sum_{x \\in \\mathbb{T}_N^d} \\sum_{i=1}^d \\left( f(\\eta^{x, x+e_i}) - f(\\eta) \\right)\n$$\nThe difference $f(\\eta^{x, x+e_i}) - f(\\eta)$ is non-zero only for the terms in the sum where $y=x$ or $y=x+e_i$.\n\\begin{align*}\nf(\\eta^{x, x+e_i}) - f(\\eta) &= \\left( \\eta(x+e_i)\\varphi(x/N) + \\eta(x)\\varphi((x+e_i)/N) \\right) - \\left( \\eta(x)\\varphi(x/N) + \\eta(x+e_i)\\varphi((x+e_i)/N) \\right) \\\\\n&= \\eta(x)\\varphi((x+e_i)/N) - \\eta(x)\\varphi(x/N) - \\eta(x+e_i)\\varphi((x+e_i)/N) + \\eta(x+e_i)\\varphi(x/N) \\\\\n&= (\\eta(x) - \\eta(x+e_i))(\\varphi((x+e_i)/N) - \\varphi(x/N))\n\\end{align*}\nThis expresses the change in the observable as a product of the particle current and the gradient of the test function. Summing over all $x$ and $i$, we get:\n$$\n\\mathcal{L}_N f(\\eta) = \\sum_{x \\in \\mathbb{T}_N^d} \\sum_{i=1}^d (\\eta(x) - \\eta(x+e_i))(\\varphi((x+e_i)/N) - \\varphi(x/N))\n$$\nWe perform a discrete summation by parts to move the difference operator from $\\varphi$ to $\\eta$.\n\\begin{align*}\n\\mathcal{L}_N f(\\eta) &= \\sum_{x,i} \\eta(x) (\\varphi((x+e_i)/N) - \\varphi(x/N)) - \\sum_{x,i} \\eta(x+e_i) (\\varphi((x+e_i)/N) - \\varphi(x/N))\n\\end{align*}\nIn the second term, we change the summation variable from $x$ to $z = x+e_i$, which means $x = z-e_i$. As the sum is over the entire torus $\\mathbb{T}_N^d$, the sum over $z$ is equivalent to the sum over $x$.\n$$\n\\sum_{x,i} \\eta(x+e_i) (\\varphi((x+e_i)/N) - \\varphi(x/N)) = \\sum_{z,i} \\eta(z) (\\varphi(z/N) - \\varphi((z-e_i)/N))\n$$\nSubstituting this back and using $x$ as the dummy variable:\n\\begin{align*}\n\\mathcal{L}_N f(\\eta) &= \\sum_{x,i} \\eta(x) \\left[ (\\varphi((x+e_i)/N) - \\varphi(x/N)) - (\\varphi(z/N) - \\varphi((z-e_i)/N)) \\Big|_{z=x} \\right] \\\\\n&= \\sum_{x,i} \\eta(x) \\left[ \\varphi((x+e_i)/N) - 2\\varphi(x/N) + \\varphi((x-e_i)/N) \\right] \\\\\n&= \\sum_{x \\in \\mathbb{T}_N^d} \\eta(x) \\left( \\sum_{i=1}^d \\left[ \\varphi(x/N + e_i/N) - 2\\varphi(x/N) + \\varphi(x/N - e_i/N) \\right] \\right)\n\\end{align*}\nThe term in the parenthesis is the unscaled discrete Laplacian of $\\varphi$. Let's call it $(\\Delta_d \\varphi)(x/N)$.\nNow, we substitute this back into the expression for the time derivative:\n$$\n\\frac{d}{dt} \\langle \\pi_t^N(\\varphi) \\rangle = \\frac{N^2}{N^d} \\left\\langle \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) (\\Delta_d \\varphi)(x/N) \\right\\rangle\n$$\nFor a smooth function $\\varphi$, we use a Taylor expansion around $u=x/N$:\n$$\n\\varphi(u \\pm e_i/N) = \\varphi(u) \\pm \\frac{1}{N} \\frac{\\partial \\varphi}{\\partial u_i}(u) + \\frac{1}{2N^2} \\frac{\\partial^2 \\varphi}{\\partial u_i^2}(u) + O(N^{-3})\n$$\nThis gives:\n$$\n\\sum_{i=1}^d \\left[ \\varphi(u + e_i/N) - 2\\varphi(u) + \\varphi(u - e_i/N) \\right] = \\frac{1}{N^2} \\sum_{i=1}^d \\frac{\\partial^2 \\varphi}{\\partial u_i^2}(u) + O(N^{-3}) = \\frac{1}{N^2} (\\Delta \\varphi)(u) + O(N^{-3})\n$$\nThus, we can write:\n$$\n\\frac{d}{dt} \\langle \\pi_t^N(\\varphi) \\rangle = \\frac{N^2}{N^d} \\left\\langle \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) \\left( \\frac{1}{N^2} \\Delta\\varphi(x/N) + O(N^{-3}) \\right) \\right\\rangle = \\left\\langle \\frac{1}{N^d} \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) \\Delta\\varphi(x/N) \\right\\rangle + O(N^{-1})\n$$\nThe core assumption of the hydrodynamic limit is that the empirical measure converges in law to a deterministic measure with a density $\\rho(t,u)$, i.e., $\\pi_t^N(du) \\to \\rho(t,u)du$. This means for any continuous function $g$,\n$$\n\\lim_{N \\to \\infty} \\left\\langle \\frac{1}{N^d} \\sum_{x \\in \\mathbb{T}_N^d} \\eta_{tN^2}(x) g(x/N) \\right\\rangle = \\int_{\\mathbb{T}^d} \\rho(t,u) g(u) \\, du\n$$\nTaking the limit $N \\to \\infty$ and assuming the interchange of limit and differentiation is valid, we obtain the weak form of the macroscopic PDE:\n$$\n\\frac{d}{dt} \\int_{\\mathbb{T}^d} \\rho(t,u) \\varphi(u) \\, du = \\int_{\\mathbb{T}^d} \\rho(t,u) \\Delta\\varphi(u) \\, du\n$$\n$$\n\\int_{\\mathbb{T}^d} \\frac{\\partial \\rho}{\\partial t}(t,u) \\varphi(u) \\, du = \\int_{\\mathbb{T}^d} \\rho(t,u) \\Delta\\varphi(u) \\, du\n$$\nUsing Green's second identity on the torus $\\mathbb{T}^d$ (or integration by parts twice, noting that boundary terms vanish), we have $\\int \\rho (\\Delta \\varphi) \\, du = \\int (\\Delta \\rho) \\varphi \\, du$.\n$$\n\\int_{\\mathbb{T}^d} \\frac{\\partial \\rho}{\\partial t}(t,u) \\varphi(u) \\, du = \\int_{\\mathbb{T}^d} (\\Delta \\rho)(t,u) \\varphi(u) \\, du\n$$\nThis can be rewritten as:\n$$\n\\int_{\\mathbb{T}^d} \\left( \\frac{\\partial \\rho}{\\partial t} - \\Delta \\rho \\right) \\varphi(u) \\, du = 0\n$$\nSince this equality must hold for any smooth test function $\\varphi$, the term in the parenthesis must be zero. This gives the strong form of the PDE, which is the macroscopic conservation law:\n$$\n\\frac{\\partial \\rho}{\\partial t} = \\Delta \\rho\n$$\nThis is the heat equation, a specific type of diffusion equation. The general form of a linear diffusion equation is $\\frac{\\partial \\rho}{\\partial t} = D \\Delta \\rho$, where $D$ is the diffusion coefficient. By comparing our derived equation with the general form, we can directly identify the diffusion coefficient as $D=1$.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "The hydrodynamic limit is a law of large numbers, asserting that the random empirical density measure converges to a deterministic solution of a PDE. This practice  explores the rigorous justification for this convergence by analyzing the stochastic fluctuations around the mean behavior. By applying martingale methods to compute the predictable quadratic variation of the fluctuation process, you will demonstrate that these fluctuations vanish in the macroscopic limit, thereby confirming the deterministic nature of the resulting hydrodynamic equation.",
            "id": "3768611",
            "problem": "Consider the one-dimensional discrete torus $\\mathbb{T}_{N} = \\{0,1,\\dots,N-1\\}$ with periodic boundary conditions and the Symmetric Simple Exclusion Process (SSEP) with diffusive scaling. Let $\\eta_{t}^{N}(x) \\in \\{0,1\\}$ denote the occupation variable at site $x \\in \\mathbb{T}_{N}$ and time $t \\geq 0$, and let the generator $L_{N}$ act on bounded cylinder functions $f$ as\n$$\n(L_{N} f)(\\eta) \\;=\\; N^{2} \\sum_{x \\in \\mathbb{T}_{N}} \\big( f(\\eta^{x,x+1}) - f(\\eta) \\big),\n$$\nwhere $\\eta^{x,x+1}$ is the configuration obtained by swapping the values of $\\eta$ at sites $x$ and $x+1$ (indices taken modulo $N$). Define the empirical density field tested against a smooth function by\n$$\nY_{t}^{N}(H) \\;=\\; \\frac{1}{N} \\sum_{x \\in \\mathbb{T}_{N}} H\\!\\left(\\frac{x}{N}\\right)\\, \\eta_{t}^{N}(x),\n$$\nfor $H \\in C^{2}(\\mathbb{T})$, with $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ denoting the continuous unit torus. By Dynkin’s formula, the process\n$$\nM_{t}^{N}(H) \\;=\\; Y_{t}^{N}(H) \\;-\\; Y_{0}^{N}(H) \\;-\\; \\int_{0}^{t} (L_{N} Y_{s}^{N})(H) \\, ds\n$$\nis a martingale. Here $(L_{N} Y_{s}^{N})(H)$ denotes the generator applied to the function $\\eta \\mapsto Y^{N}(\\eta;H)$ evaluated at the configuration $\\eta_{s}^{N}$.\n\nStarting from the definition of the generator and the pure-jump structure of the process, and using only general martingale jump calculus together with smoothness of $H$, derive the predictable Quadratic Variation (QV) $\\langle M^{N}(H) \\rangle_{t}$ of the martingale $M_{t}^{N}(H)$ and determine its limit as $N \\to \\infty$ for any fixed $t \\in [0,T]$ and fixed $T>0$. Provide the exact value of\n$$\n\\lim_{N \\to \\infty} \\langle M^{N}(H) \\rangle_{t}\n$$\nas a single real number. No numerical rounding is required. Express your final answer without units.",
            "solution": "The process $\\eta_t^N$ is a continuous-time Markov jump process on the finite state space $\\{0,1\\}^{\\mathbb{T}_N}$. The martingale $M_t^N(H)$ is associated with the observable $Y_t^N(H)$. The predictable quadratic variation of a pure-jump martingale of the form $f(\\eta_t) - f(\\eta_0) - \\int_0^t Lf(\\eta_s)ds$ is given by\n$$\n\\langle M \\rangle_t = \\int_0^t \\left(L(f^2) - 2f(Lf)\\right)(\\eta_s) \\, ds.\n$$\nIn our case, the function is $f(\\eta) = Y^N(\\eta; H)$. The rate of change of the quadratic variation at time $s$ is given by the term in the integral, evaluated at the configuration $\\eta_s^N$:\n$$\n\\frac{d}{dt}\\langle M^N(H) \\rangle_{t} \\Big|_{t=s} = (L_N (Y_s^N(H))^2 - 2 Y_s^N(H) (L_N Y_s^N))(H).\n$$\nLet's analyze the term $(L_N (g^2) - 2gL_N g)(\\eta)$ for a generic function $g(\\eta)$. Using the definition of the generator $L_N$:\n\\begin{align*}\n(L_N (g^2) - 2gL_N g)(\\eta) &= N^2 \\sum_{x \\in \\mathbb{T}_N} [g(\\eta^{x,x+1})^2 - g(\\eta)^2] - 2g(\\eta) \\left( N^2 \\sum_{x \\in \\mathbb{T}_N} [g(\\eta^{x,x+1}) - g(\\eta)] \\right) \\\\\n&= N^2 \\sum_{x \\in \\mathbb{T}_N} \\left( [g(\\eta^{x,x+1})^2 - g(\\eta)^2] - 2g(\\eta)[g(\\eta^{x,x+1}) - g(\\eta)] \\right) \\\\\n&= N^2 \\sum_{x \\in \\mathbb{T}_N} \\left( g(\\eta^{x,x+1})^2 - 2g(\\eta)g(\\eta^{x,x+1}) + g(\\eta)^2 \\right) \\\\\n&= N^2 \\sum_{x \\in \\mathbb{T}_N} [g(\\eta^{x,x+1}) - g(\\eta)]^2.\n\\end{align*}\nThis is the sum of the jump rates ($N^2$ for each pair $(x, x+1)$) multiplied by the square of the jump size of the observable. Let's calculate the jump size for $g(\\eta) = Y^N(\\eta; H)$:\n\\begin{align*}\nY^N(\\eta^{x,x+1}; H) - Y^N(\\eta; H) &= \\frac{1}{N} \\sum_{y \\in \\mathbb{T}_N} H\\left(\\frac{y}{N}\\right) \\eta^{x,x+1}(y) - \\frac{1}{N} \\sum_{y \\in \\mathbb{T}_N} H\\left(\\frac{y}{N}\\right) \\eta(y) \\\\\n&= \\frac{1}{N} \\sum_{y \\in \\mathbb{T}_N} H\\left(\\frac{y}{N}\\right) (\\eta^{x,x+1}(y) - \\eta(y)).\n\\end{align*}\nThe only non-zero terms in the sum are for $y=x$ and $y=x+1$.\n\\begin{align*}\nY^N(\\eta^{x,x+1}; H) - Y^N(\\eta; H) &= \\frac{1}{N} \\left[ H\\left(\\frac{x}{N}\\right)(\\eta(x+1)-\\eta(x)) + H\\left(\\frac{x+1}{N}\\right)(\\eta(x)-\\eta(x+1)) \\right] \\\\\n&= \\frac{1}{N} \\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right] (\\eta(x) - \\eta(x+1)).\n\\end{align*}\nNow, we can write the expected rate of change of the quadratic variation by taking the expectation over the state $\\eta_s^N$:\n$$\n\\mathbb{E}\\left[\\frac{d}{dt}\\langle M^N(H) \\rangle_t \\Big|_{t=s}\\right] = \\mathbb{E} \\left[ N^2 \\sum_{x \\in \\mathbb{T}_N} \\left(\\frac{1}{N} \\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right] (\\eta_s^N(x) - \\eta_s^N(x+1))\\right)^2 \\right].\n$$\nSimplifying the expression inside the expectation:\n\\begin{align*}\n&N^2 \\sum_{x \\in \\mathbb{T}_N} \\frac{1}{N^2} \\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right]^2 (\\eta_s^N(x) - \\eta_s^N(x+1))^2 \\\\\n&= \\sum_{x \\in \\mathbb{T}_N} \\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right]^2 (\\eta_s^N(x) - \\eta_s^N(x+1))^2.\n\\end{align*}\nLet's denote this quantity by $A_N(\\eta_s^N)$. The quadratic variation is then $\\langle M^N(H) \\rangle_t = \\int_0^t \\mathbb{E}[A_N(\\eta_s^N)] ds$. We need to evaluate the limit of this expression as $N \\to \\infty$.\n\nThe test function $H$ is in $C^2(\\mathbb{T})$, so its first derivative $H'$ is bounded on the compact set $\\mathbb{T}$. Let $\\|H'\\|_{\\infty}$ be the maximum absolute value of $H'$. By the Mean Value Theorem, for each $x \\in \\mathbb{T}_N$, there exists $\\xi_x \\in (\\frac{x}{N}, \\frac{x+1}{N})$ such that:\n$$\nH\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) = H'(\\xi_x) \\left(\\frac{x+1}{N} - \\frac{x}{N}\\right) = \\frac{1}{N} H'(\\xi_x).\n$$\nWe can therefore bound the squared difference:\n$$\n\\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right]^2 = \\frac{1}{N^2} |H'(\\xi_x)|^2 \\leq \\frac{1}{N^2} \\|H'\\|_{\\infty}^2.\n$$\nThe occupation variables $\\eta_s^N(x)$ are either $0$ or $1$. Thus, the term $(\\eta_s^N(x) - \\eta_s^N(x+1))^2$ is either $(0-0)^2=0$, $(1-1)^2=0$, $(1-0)^2=1$, or $(0-1)^2=1$. In all cases, $(\\eta_s^N(x) - \\eta_s^N(x+1))^2 \\leq 1$.\n\nWe can now bound $A_N(\\eta_s^N)$ uniformly for any configuration $\\eta_s^N$:\n$$\nA_N(\\eta_s^N) = \\sum_{x=0}^{N-1} \\left[ H\\left(\\frac{x+1}{N}\\right) - H\\left(\\frac{x}{N}\\right) \\right]^2 (\\eta_s^N(x) - \\eta_s^N(x+1))^2 \\leq \\sum_{x=0}^{N-1} \\left( \\frac{1}{N^2} \\|H'\\|_{\\infty}^2 \\right) \\cdot 1.\n$$\nThe sum has $N$ identical terms:\n$$\nA_N(\\eta_s^N) \\leq N \\cdot \\frac{1}{N^2} \\|H'\\|_{\\infty}^2 = \\frac{1}{N} \\|H'\\|_{\\infty}^2.\n$$\nThis bound holds for any configuration $\\eta_s^N$ and any time $s \\geq 0$. Therefore, the expectation is also bounded:\n$$\n\\mathbb{E}[A_N(\\eta_s^N)] \\leq \\frac{1}{N} \\|H'\\|_{\\infty}^2.\n$$\nAs $N \\to \\infty$, the upper bound $\\frac{1}{N} \\|H'\\|_{\\infty}^2 \\to 0$. Since $A_N(\\eta_s^N) \\geq 0$, we have $\\mathbb{E}[A_N(\\eta_s^N)] \\ge 0$. By the Squeeze Theorem, we conclude that:\n$$\n\\lim_{N \\to \\infty} \\mathbb{E}[A_N(\\eta_s^N)] = 0.\n$$\nThis limit holds for any fixed time $s \\in [0, t]$. To find the limit of the quadratic variation, we must evaluate the limit of the integral:\n$$\n\\lim_{N \\to \\infty} \\langle M^N(H) \\rangle_t = \\lim_{N \\to \\infty} \\int_0^t \\mathbb{E}[A_N(\\eta_s^N)] ds.\n$$\nThe integrand $\\mathbb{E}[A_N(\\eta_s^N)]$ is bounded for any $N \\geq 1$ and $s \\in [0,T]$ by a constant, for instance $\\|H'\\|_{\\infty}^2$. Thus, we can apply the Bounded Convergence Theorem to interchange the limit and the integral:\n$$\n\\lim_{N \\to \\infty} \\langle M^N(H) \\rangle_t = \\int_0^t \\left( \\lim_{N \\to \\infty} \\mathbb{E}[A_N(\\eta_s^N)] \\right) ds = \\int_0^t 0 \\, ds = 0.\n$$\nThe vanishing of the quadratic variation signifies that the stochastic part of the process $Y_t^N(H)$ becomes negligible in the $N\\to\\infty$ limit. The evolution becomes deterministic, which is the essence of the hydrodynamic limit as a law of large numbers.",
            "answer": "$$\n\\boxed{0}\n$$"
        }
    ]
}