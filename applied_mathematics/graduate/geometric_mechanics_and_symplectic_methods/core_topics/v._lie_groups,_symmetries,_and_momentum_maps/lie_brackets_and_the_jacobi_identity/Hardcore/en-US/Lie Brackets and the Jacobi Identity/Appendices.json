{
    "hands_on_practices": [
        {
            "introduction": "To build intuition for the Lie bracket, we begin with a foundational example that connects the abstract commutator of vector fields to the familiar geometry of three-dimensional space. This exercise reveals how the set of infinitesimal rotations, represented by rotational vector fields, forms a Lie algebra isomorphic to $\\mathfrak{so}(3)$. By explicitly computing the bracket, you will see that it corresponds to the vector cross product, and that the Jacobi identity is a direct consequence of the Jacobi identity for the cross product itself .",
            "id": "3753442",
            "problem": "Let $\\mathbb{R}^{3}$ be equipped with its standard Euclidean structure and denote by $\\mathfrak{X}(\\mathbb{R}^{3})$ the Lie algebra of smooth vector fields on $\\mathbb{R}^{3}$ with the Lie bracket defined by $[X,Y](f) \\equiv X(Y(f)) - Y(X(f))$ for all smooth functions $f:\\mathbb{R}^{3} \\to \\mathbb{R}$. For each constant vector $a \\in \\mathbb{R}^{3}$, define the rotational (infinitesimal rotation) vector field $X_{a}$ by\n$$\nX_{a}(x) \\equiv a \\times x,\n$$\nviewed as a first-order linear differential operator $X_{a} = (a \\times x) \\cdot \\nabla$ acting on smooth functions. Here $\\times$ is the Euclidean cross product and $\\nabla$ is the gradient with respect to $x \\in \\mathbb{R}^{3}$.\n\nUsing only the core definitions and standard vector calculus identities, do the following:\n\n1. Starting from the definition of the Lie bracket of vector fields, derive an explicit formula for $[X_{a},X_{b}]$ for arbitrary constant vectors $a,b \\in \\mathbb{R}^{3}$, expressed again as a rotational vector field $X_{c}$ for some $c \\in \\mathbb{R}^{3}$ determined by $a$ and $b$.\n\n2. Deduce from part $1$ that the collection $\\{X_{a} : a \\in \\mathbb{R}^{3}\\}$ is a $3$-dimensional Lie subalgebra of $\\mathfrak{X}(\\mathbb{R}^{3})$, identify it with the Lie algebra of the Special Orthogonal group $\\mathrm{SO}(3)$, and compute its structure constants with respect to the basis $\\{X_{e_{1}},X_{e_{2}},X_{e_{3}}\\}$, where $\\{e_{1},e_{2},e_{3}\\}$ is the standard basis of $\\mathbb{R}^{3}$.\n\n3. Verify the Jacobi identity for this Lie algebra by computing the Jacobiator\n$$\nJ(a,b,c) \\equiv [X_{a},[X_{b},X_{c}]] + [X_{b},[X_{c},X_{a}]] + [X_{c},[X_{a},X_{b}]]\n$$\nfor arbitrary constant vectors $a,b,c \\in \\mathbb{R}^{3}$, using only identities of the Euclidean cross product.\n\nFor grading, report a single scalar quantity as follows: let $f(x) \\equiv \\tfrac{1}{2}\\|x\\|^{2}$. Evaluate the scalar\n$$\n(J(a,b,c)f)(x)\n$$\nat an arbitrary point $x \\in \\mathbb{R}^{3}$ and provide its exact value as your final answer. No rounding is required, and no units are involved. Your final answer must be a single real number or a single closed-form analytic expression.",
            "solution": "### Part 1: Derivation of the Lie Bracket $[X_a, X_b]$\n\nThe Lie bracket of two vector fields $V$ and $W$ is the vector field $[V, W]$ given by $[V, W] = (V \\cdot \\nabla)W - (W \\cdot \\nabla)V$. Here, $V = X_a = a \\times x$ and $W = X_b = b \\times x$.\nThe Lie bracket is therefore:\n$$\n[X_a, X_b] = ((a \\times x) \\cdot \\nabla)(b \\times x) - ((b \\times x) \\cdot \\nabla)(a \\times x)\n$$\nWe use the vector calculus identity $(\\mathbf{v} \\cdot \\nabla)(\\mathbf{u} \\times \\mathbf{r}) = \\mathbf{u} \\times \\mathbf{v}$.\nApplying this identity to each term:\n- For the first term, let $\\mathbf{v} = a \\times x$, $\\mathbf{u} = b$, $\\mathbf{r} = x$. We get $((a \\times x) \\cdot \\nabla)(b \\times x) = b \\times (a \\times x)$.\n- For the second term, let $\\mathbf{v} = b \\times x$, $\\mathbf{u} = a$, $\\mathbf{r} = x$. We get $((b \\times x) \\cdot \\nabla)(a \\times x) = a \\times (b \\times x)$.\n\nSubstituting these back into the expression for the Lie bracket:\n$$\n[X_a, X_b] = b \\times (a \\times x) - a \\times (b \\times x)\n$$\nNow, we use the Jacobi identity for the vector cross product: $A \\times (B \\times C) + B \\times (C \\times A) + C \\times (A \\times B) = 0$.\nLet $A=a$, $B=b$, and $C=x$.\n$a \\times (b \\times x) + b \\times (x \\times a) + x \\times (a \\times b) = 0$.\nUsing the antisymmetry of the cross product, $b \\times (x \\times a) = -b \\times (a \\times x)$.\nSo, $a \\times (b \\times x) - b \\times (a \\times x) + x \\times (a \\times b) = 0$.\nThis gives $b \\times (a \\times x) - a \\times (b \\times x) = x \\times (a \\times b)$.\nUsing antisymmetry again, $x \\times (a \\times b) = -(a \\times b) \\times x$.\nSo we have:\n$$\n[X_a, X_b] = -(a \\times b) \\times x\n$$\nThis expression is the rotational vector field corresponding to the vector $-(a \\times b) = b \\times a$.\nTherefore, we find the formula:\n$$\n[X_a, X_b] = X_{b \\times a} = -X_{a \\times b}\n$$\n\n### Part 2: Lie Subalgebra and Structure Constants\n\nA subset of a Lie algebra is a Lie subalgebra if it is a linear subspace and is closed under the Lie bracket. Let $S = \\{X_a : a \\in \\mathbb{R}^3\\}$.\n1.  **Linear Subspace**: For any scalars $\\alpha, \\beta \\in \\mathbb{R}$ and any vectors $a, b \\in \\mathbb{R}^3$, we have $\\alpha X_a + \\beta X_b$. The corresponding vector field is $(\\alpha(a \\times x) + \\beta(b \\times x)) = (\\alpha a + \\beta b) \\times x = X_{\\alpha a + \\beta b}$. Since $\\alpha a + \\beta b \\in \\mathbb{R}^3$, the vector field $\\alpha X_a + \\beta X_b$ is in $S$. The mapping $a \\mapsto X_a$ is a linear isomorphism from $\\mathbb{R}^3$ to $S$, so $S$ is a $3$-dimensional vector space.\n2.  **Closure under Lie Bracket**: From Part 1, for any $X_a, X_b \\in S$, we have $[X_a, X_b] = X_{b \\times a}$. Since $a,b \\in \\mathbb{R}^3$, their cross product $b \\times a$ is also a vector in $\\mathbb{R}^3$. Therefore, $X_{b \\times a} \\in S$. The set $S$ is closed under the Lie bracket.\nThus, $S$ is a $3$-dimensional Lie subalgebra of $\\mathfrak{X}(\\mathbb{R}^3)$.\n\nThe Lie algebra of the special orthogonal group $\\mathrm{SO}(3)$, denoted $\\mathfrak{so}(3)$, is isomorphic to $(\\mathbb{R}^3, \\times)$. Our result $[X_a, X_b] = X_{b \\times a}$ shows that the map $\\Psi: (\\mathbb{R}^3, \\times) \\to (S, [\\cdot,\\cdot]_{\\text{rev}})$ defined by $\\Psi(a) = X_a$ is a Lie algebra isomorphism if the bracket on $S$ is taken as $[X_a, X_b]' = [X_b, X_a]$. Alternatively, the map from $(\\mathbb{R}^3, \\times)$ is an anti-isomorphism to $(S, [\\cdot,\\cdot])$. The algebra $S$ is isomorphic to $\\mathfrak{so}(3)$.\n\nThe structure constants $c^k_{ij}$ are defined by $[X_{e_i}, X_{e_j}] = \\sum_{k=1}^3 c^k_{ij} X_{e_k}$. We use the basis $\\{X_{e_1}, X_{e_2}, X_{e_3}\\}$.\nUsing our formula:\n$[X_{e_i}, X_{e_j}] = X_{e_j \\times e_i} = X_{-\\epsilon_{ijk} e_k} = -\\epsilon_{ijk} X_{e_k}$.\nThe structure constants are $c^k_{ij} = -\\epsilon_{ijk} = \\epsilon_{jik}$.\n\n### Part 3: Verification of the Jacobi Identity\n\nThe Jacobiator for $X_a, X_b, X_c$ is $J(a,b,c) = [X_a, [X_b, X_c]] + [X_b, [X_c, X_a]] + [X_c, [X_a, X_b]]$.\nWe use our result $[X_u, X_v] = X_{v \\times u}$ to evaluate each term:\n1.  $[X_a, [X_b, X_c]] = [X_a, X_{c \\times b}] = X_{(c \\times b) \\times a}$.\n2.  $[X_b, [X_c, X_a]] = [X_b, X_{a \\times c}] = X_{(a \\times c) \\times b}$.\n3.  $[X_c, [X_a, X_b]] = [X_c, X_{b \\times a}] = X_{(b \\times a) \\times c}$.\n\nThe sum is:\n$J(a,b,c) = X_{(c \\times b) \\times a} + X_{(a \\times c) \\times b} + X_{(b \\times a) \\times c}$.\nBy the linearity of the map $v \\mapsto X_v$, this is equal to:\n$J(a,b,c) = X_{(c \\times b) \\times a + (a \\times c) \\times b + (b \\times a) \\times c}$.\nThe vector argument is the Jacobi identity for the cross product, which is zero:\n$(c \\times b) \\times a + (a \\times c) \\times b + (b \\times a) \\times c = 0$.\nTherefore, $J(a,b,c) = X_0$.\nThe vector field $X_0$ is defined as $X_0(x) = 0 \\times x = 0$. This is the zero vector field. As an operator, $X_0$ acts on any smooth function $f$ as $X_0(f) = (0 \\times x) \\cdot \\nabla f = 0 \\cdot \\nabla f = 0$.\nSo $J(a,b,c)$ is the zero operator.\n\n### Final Calculation\n\nThe problem asks for the scalar quantity $(J(a,b,c)f)(x)$ for $f(x) \\equiv \\frac{1}{2}\\|x\\|^2$ at an arbitrary point $x \\in \\mathbb{R}^3$.\nAs shown above, the Jacobiator $J(a,b,c)$ is the zero operator. This means that for any smooth function $g:\\mathbb{R}^3 \\to \\mathbb{R}$, $(J(a,b,c)g)$ is the function which is identically zero everywhere.\nLet $g(x) = f(x) = \\frac{1}{2}\\|x\\|^2$.\nThen $(J(a,b,c)f)$ is the zero function.\nEvaluating this function at any point $x \\in \\mathbb{R}^3$ yields the scalar value $0$.\nTherefore, $(J(a,b,c)f)(x) = 0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "While many natural structures satisfy the Jacobi identity, it is not an automatic property of any antisymmetric, bilinear operation. This practice underscores the role of the Jacobi identity as a fundamental structural constraint that defines a Lie algebra. By starting with a known Lie algebra and parametrically altering its structure constants, you will directly compute the Jacobiator to see precisely how and under what conditions the identity fails, thereby gaining a deeper appreciation for its non-trivial nature .",
            "id": "3753491",
            "problem": "Let $V$ be a real $3$-dimensional vector space with ordered basis $\\{e_{1}, e_{2}, e_{3}\\}$. In geometric mechanics, Lie algebras model infinitesimal symmetries, and their duals carry Lieâ€“Poisson brackets. A bilinear, antisymmetric bracket $[\\cdot,\\cdot]: V \\times V \\to V$ must satisfy the Jacobi identity to define a Lie algebra. The Jacobi identity requires that, for all $x,y,z \\in V$, the Jacobiator $J(x,y,z) := [x,[y,z]] + [y,[z,x]] + [z,[x,y]]$ vanishes.\n\nStart from the Heisenberg Lie algebra with structure coefficients specified by $[e_{1}, e_{2}] = e_{3}$ and $[e_{2}, e_{3}] = [e_{3}, e_{1}] = 0$, which is known to satisfy the Jacobi identity. Now modify the bracket coefficients by introducing two real parameters $a$ and $b$ as follows:\n- keep $[e_{1}, e_{2}] = e_{3}$,\n- set $[e_{2}, e_{3}] = a\\, e_{2}$,\n- set $[e_{3}, e_{1}] = b\\, e_{3}$,\nand extend these by bilinearity and antisymmetry so that $[e_{j}, e_{i}] = -[e_{i}, e_{j}]$ for all $i,j$.\n\nEquip $V$ with the Euclidean inner product for which $\\{e_{1}, e_{2}, e_{3}\\}$ is an orthonormal basis. Using only the fundamental definitions of bilinearity, antisymmetry, and the Jacobi identity, compute the Jacobiator $J(e_{1}, e_{2}, e_{3})$ explicitly and then evaluate its squared norm $\\|J(e_{1}, e_{2}, e_{3})\\|^{2}$ with respect to this inner product. Express your final answer as a closed-form analytic expression in $a$ and $b$.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It presents a standard calculation in the theory of Lie algebras, based on fundamental definitions.\n\nThe task is to compute the squared norm of the Jacobiator $J(e_{1}, e_{2}, e_{3})$ for a given bracket structure on a $3$-dimensional real vector space $V$. The Jacobiator is defined for any three vectors $x, y, z \\in V$ as:\n$$J(x,y,z) := [x,[y,z]] + [y,[z,x]] + [z,[x,y]]$$\nThe bracket $[\\cdot,\\cdot]: V \\times V \\to V$ is defined on the basis vectors $\\{e_{1}, e_{2}, e_{3}\\}$ by the following relations:\n1. $[e_{1}, e_{2}] = e_{3}$\n2. $[e_{2}, e_{3}] = a\\, e_{2}$\n3. $[e_{3}, e_{1}] = b\\, e_{3}$\n\nThese relations are extended to the entire space $V$ by bilinearity and antisymmetry. The antisymmetry property, $[u,v] = -[v,u]$ for all $u,v \\in V$, implies the following additional relations for the basis vectors:\n- $[e_{2}, e_{1}] = -[e_{1}, e_{2}] = -e_{3}$\n- $[e_{3}, e_{2}] = -[e_{2}, e_{3}] = -a\\, e_{2}$\n- $[e_{1}, e_{3}] = -[e_{3}, e_{1}] = -b\\, e_{3}$\n- $[e_{i}, e_{i}] = 0$ for $i \\in \\{1, 2, 3\\}$.\n\nWe compute the Jacobiator $J(e_{1}, e_{2}, e_{3})$ by evaluating each of its three terms separately.\n\nFirst term: $[e_{1}, [e_{2}, e_{3}]]$\nUsing the given relation $[e_{2}, e_{3}] = a\\, e_{2}$, we have:\n$$[e_{1}, [e_{2}, e_{3}]] = [e_{1}, a\\, e_{2}]$$\nBy the bilinearity of the bracket, we can factor out the scalar $a$:\n$$[e_{1}, a\\, e_{2}] = a\\, [e_{1}, e_{2}]$$\nUsing the given relation $[e_{1}, e_{2}] = e_{3}$, we obtain:\n$$[e_{1}, [e_{2}, e_{3}]] = a\\, e_{3}$$\n\nSecond term: $[e_{2}, [e_{3}, e_{1}]]$\nUsing the given relation $[e_{3}, e_{1}] = b\\, e_{3}$, we have:\n$$[e_{2}, [e_{3}, e_{1}]] = [e_{2}, b\\, e_{3}]$$\nBy bilinearity, we factor out the scalar $b$:\n$$[e_{2}, b\\, e_{3}] = b\\, [e_{2}, e_{3}]$$\nUsing the given relation $[e_{2}, e_{3}] = a\\, e_{2}$, we obtain:\n$$[e_{2}, [e_{3}, e_{1}]] = b\\, (a\\, e_{2}) = ab\\, e_{2}$$\n\nThird term: $[e_{3}, [e_{1}, e_{2}]]$\nUsing the given relation $[e_{1}, e_{2}] = e_{3}$, we have:\n$$[e_{3}, [e_{1}, e_{2}]] = [e_{3}, e_{3}]$$\nBy antisymmetry, the bracket of any vector with itself is the zero vector:\n$$[e_{3}, e_{3}] = 0$$\n\nNow, we sum the three terms to find the Jacobiator:\n$$J(e_{1}, e_{2}, e_{3}) = (a\\, e_{3}) + (ab\\, e_{2}) + (0)$$\n$$J(e_{1}, e_{2}, e_{3}) = ab\\, e_{2} + a\\, e_{3}$$\n\nThe final step is to compute the squared norm of this vector, $\\|J(e_{1}, e_{2}, e_{3})\\|^{2}$. The vector space $V$ is equipped with a Euclidean inner product $\\langle \\cdot, \\cdot \\rangle$ for which the basis $\\{e_{1}, e_{2}, e_{3}\\}$ is orthonormal. This means $\\langle e_{i}, e_{j} \\rangle = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\nThe squared norm of a vector $v$ is given by $\\|v\\|^{2} = \\langle v, v \\rangle$.\nLet $v = J(e_{1}, e_{2}, e_{3}) = ab\\, e_{2} + a\\, e_{3}$. Its squared norm is:\n$$\\|v\\|^{2} = \\langle ab\\, e_{2} + a\\, e_{3}, ab\\, e_{2} + a\\, e_{3} \\rangle$$\nUsing the bilinearity of the inner product:\n$$\\|v\\|^{2} = \\langle ab\\, e_{2}, ab\\, e_{2} \\rangle + \\langle ab\\, e_{2}, a\\, e_{3} \\rangle + \\langle a\\, e_{3}, ab\\, e_{2} \\rangle + \\langle a\\, e_{3}, a\\, e_{3} \\rangle$$\nFactoring out the scalar coefficients:\n$$\\|v\\|^{2} = (ab)^{2} \\langle e_{2}, e_{2} \\rangle + (ab)(a) \\langle e_{2}, e_{3} \\rangle + (a)(ab) \\langle e_{3}, e_{2} \\rangle + a^{2} \\langle e_{3}, e_{3} \\rangle$$\nSubstituting the values from the orthonormal property of the basis: $\\langle e_{2}, e_{2} \\rangle = 1$, $\\langle e_{3}, e_{3} \\rangle = 1$, and $\\langle e_{2}, e_{3} \\rangle = \\langle e_{3}, e_{2} \\rangle = 0$.\n$$\\|J(e_{1}, e_{2}, e_{3})\\|^{2} = a^{2}b^{2}(1) + a^{2}b(0) + a^{2}b(0) + a^{2}(1)$$\n$$\\|J(e_{1}, e_{2}, e_{3})\\|^{2} = a^{2}b^{2} + a^{2}$$\nThis expression can be factored to give the final result:\n$$\\|J(e_{1}, e_{2}, e_{3})\\|^{2} = a^{2}(b^{2} + 1)$$",
            "answer": "$$\n\\boxed{a^{2}(b^{2} + 1)}\n$$"
        },
        {
            "introduction": "We now turn to a sophisticated application in Hamiltonian mechanics, where the Jacobi identity is essential for the consistency of physical dynamics. When a system is subject to second-class constraints, the standard Poisson bracket is inadequate. This problem guides you through the construction of the Dirac bracket, a necessary modification to handle such systems . By verifying that this more complex bracket still satisfies the Jacobi identity, you will confirm that it provides a valid algebraic framework for describing constrained motion.",
            "id": "3753480",
            "problem": "Consider a classical particle in the plane with configuration space $\\mathbb{R}^{2}$ and Cartesian coordinates $(x,y)$. Its canonical phase space is described by coordinates $(x,y,p_{x},p_{y})$ and the canonical Poisson bracket defined by $\\{x,p_{x}\\}=1$, $\\{y,p_{y}\\}=1$, and all other fundamental brackets among $x$, $y$, $p_{x}$, $p_{y}$ vanishing. Impose the holonomic constraint $\\phi_{1}=x^{2}+y^{2}-R^{2}=0$ so the particle is constrained to the circle of radius $R>0$, and impose the secondary constraint $\\phi_{2}=x\\,p_{x}+y\\,p_{y}=0$ so that the momentum is tangent to the circle. Treat the pair $(\\phi_{1},\\phi_{2})$ as a set of second-class constraints and define the Dirac bracket for any pair of smooth functions $F,G$ on phase space by\n$$\n\\{F,G\\}_{D}=\\{F,G\\}-\\{F,\\phi_{a}\\}\\,C^{ab}\\,\\{\\phi_{b},G\\},\n$$\nwhere $C^{ab}$ are the entries of the inverse of the constraint matrix $C_{ab}=\\{\\phi_{a},\\phi_{b}\\}$ with indices $a,b\\in\\{1,2\\}$.\n\nStarting from the canonical Poisson bracket and the constraints above:\n- Compute the constraint matrix $C_{ab}=\\{\\phi_{a},\\phi_{b}\\}$ and its inverse $C^{ab}$.\n- Use these to compute the Dirac brackets $\\{x,y\\}_{D}$, $\\{x,p_{x}\\}_{D}$, and $\\{y,p_{x}\\}_{D}$ explicitly as functions of $x$ and $y$.\n- Verify the Jacobi identity for the coordinate functions $(x,y,p_{x})$ with respect to the Dirac bracket by evaluating the Jacobiator\n$$\nJ(x,y,p_{x})=\\{x,\\{y,p_{x}\\}_{D}\\}_{D}+\\{y,\\{p_{x},x\\}_{D}\\}_{D}+\\{p_{x},\\{x,y\\}_{D}\\}_{D}\n$$\nand showing that $J(x,y,p_{x})=0$.\n\nProvide as your final answer the closed-form expression for the Dirac bracket $\\{x,p_{x}\\}_{D}$ written in terms of $x$ and $y$ only. No numerical evaluation or rounding is required.",
            "solution": "The user has provided a valid problem statement from the field of classical mechanics, specifically concerning Hamiltonian dynamics with second-class constraints. The problem asks for the computation of the Dirac bracket on a constrained phase space and the verification of the Jacobi identity for a specific set of phase space functions. All definitions and conditions are standard, well-posed, and scientifically grounded.\n\nThe problem will be solved in three parts as requested:\n1.  Compute the constraint matrix $C_{ab}$ and its inverse $C^{ab}$.\n2.  Compute the specific Dirac brackets $\\{x,y\\}_{D}$, $\\{x,p_{x}\\}_{D}$, and $\\{y,p_{x}\\}_{D}$.\n3.  Verify the Jacobi identity for the functions $x$, $y$, and $p_x$.\n\nThe canonical Poisson brackets are given by $\\{x,p_{x}\\}=1$, $\\{y,p_{y}\\}=1$, and all others being zero (e.g., $\\{x,y\\}=0$, $\\{x,p_y\\}=0$, etc.). The Poisson bracket of any two functions $F(x,y,p_x,p_y)$ and $G(x,y,p_x,p_y)$ is given by\n$$\n\\{F,G\\} = \\frac{\\partial F}{\\partial x}\\frac{\\partial G}{\\partial p_{x}} - \\frac{\\partial F}{\\partial p_{x}}\\frac{\\partial G}{\\partial x} + \\frac{\\partial F}{\\partial y}\\frac{\\partial G}{\\partial p_{y}} - \\frac{\\partial F}{\\partial p_{y}}\\frac{\\partial G}{\\partial y}.\n$$\nThe constraints are $\\phi_{1}=x^{2}+y^{2}-R^{2}=0$ and $\\phi_{2}=x p_x + y p_y = 0$.\n\n**Part 1: Constraint Matrix and its Inverse**\n\nThe constraint matrix $C_{ab}$ is defined by $C_{ab} = \\{\\phi_{a},\\phi_{b}\\}$ for $a,b \\in \\{1,2\\}$.\nThe diagonal elements are zero due to the antisymmetry of the Poisson bracket:\n$C_{11} = \\{\\phi_{1},\\phi_{1}\\} = 0$\n$C_{22} = \\{\\phi_{2},\\phi_{2}\\} = 0$\n\nThe off-diagonal element $C_{12}$ is:\n$$\nC_{12} = \\{\\phi_{1}, \\phi_{2}\\} = \\{x^{2}+y^{2}-R^{2}, x p_x + y p_y\\}\n$$\nUsing the linearity and Leibniz rule for Poisson brackets:\n$$\nC_{12} = \\{x^{2}, x p_x\\} + \\{x^{2}, y p_y\\} + \\{y^{2}, x p_x\\} + \\{y^{2}, y p_y\\}\n$$\nWe evaluate each term:\n$\\{x^{2}, x p_x\\} = x\\{x^{2}, p_x\\} + \\{x^{2}, x\\}p_x = x(2x\\{x,p_x\\}) + 0 = 2x^{2}(1) = 2x^{2}$.\n$\\{x^{2}, y p_y\\} = y\\{x^{2}, p_y\\} + \\{x^{2}, y\\}p_y = 0+0=0$.\n$\\{y^{2}, x p_x\\} = x\\{y^{2}, p_x\\} + \\{y^{2}, x\\}p_x = 0+0=0$.\n$\\{y^{2}, y p_y\\} = y\\{y^{2}, p_y\\} + \\{y^{2}, y\\}p_y = y(2y\\{y,p_y\\}) + 0 = 2y^{2}(1) = 2y^{2}$.\nSo, $C_{12} = 2x^{2} + 2y^{2} = 2(x^{2}+y^{2})$.\nOn the constraint surface $\\phi_1=0$, we have $x^{2}+y^{2} = R^{2}$. Thus, $C_{12} = 2R^{2}$.\nFrom antisymmetry, $C_{21} = \\{\\phi_{2}, \\phi_{1}\\} = -\\{\\phi_{1}, \\phi_{2}\\} = -2R^{2}$.\n\nThe constraint matrix is:\n$$\nC_{ab} = \\begin{pmatrix} 0 & 2R^2 \\\\ -2R^2 & 0 \\end{pmatrix}\n$$\nThe determinant is $\\det(C) = (0)(0) - (2R^2)(-2R^2) = 4R^{4}$. Since $R>0$, $\\det(C) \\neq 0$, confirming the constraints are second-class.\nThe inverse matrix $C^{ab}$ is:\n$$\nC^{ab} = \\frac{1}{4R^4} \\begin{pmatrix} 0 & -2R^2 \\\\ 2R^2 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & -\\frac{1}{2R^2} \\\\ \\frac{1}{2R^2} & 0 \\end{pmatrix}\n$$\nSo, $C^{11}=C^{22}=0$, $C^{12}=-\\frac{1}{2R^2}$, and $C^{21}=\\frac{1}{2R^2}$.\n\n**Part 2: Computing Dirac Brackets**\n\nThe Dirac bracket is defined as $\\{F,G\\}_{D} = \\{F,G\\} - \\{F,\\phi_{a}\\}C^{ab}\\{\\phi_{b},G\\}$. Expanding with the calculated $C^{ab}$:\n$$\n\\{F,G\\}_{D} = \\{F,G\\} - \\{F,\\phi_{1}\\}C^{12}\\{\\phi_{2},G\\} - \\{F,\\phi_{2}\\}C^{21}\\{\\phi_{1},G\\}\n$$\n$$\n\\{F,G\\}_{D} = \\{F,G\\} - \\{F,\\phi_{1}\\}\\left(-\\frac{1}{2R^2}\\right)\\{\\phi_{2},G\\} - \\{F,\\phi_{2}\\}\\left(\\frac{1}{2R^2}\\right)\\{\\phi_{1},G\\}\n$$\n$$\n\\{F,G\\}_{D} = \\{F,G\\} + \\frac{1}{2R^2} \\left( \\{F,\\phi_{1}\\}\\{\\phi_{2},G\\} - \\{F,\\phi_{2}\\}\\{\\phi_{1},G\\} \\right)\n$$\nTo compute the required brackets, we first find the Poisson brackets of the coordinate functions with the constraints:\n$\\{x, \\phi_{1}\\} = \\{x, x^{2}+y^{2}-R^{2}\\} = 0$\n$\\{y, \\phi_{1}\\} = \\{y, x^{2}+y^{2}-R^{2}\\} = 0$\n$\\{p_{x}, \\phi_{1}\\} = \\{p_{x}, x^{2}+y^{2}-R^{2}\\} = \\{p_x, x^2\\} = 2x\\{p_x,x\\} = -2x$\n\n$\\{x, \\phi_{2}\\} = \\{x, x p_x + y p_y\\} = \\{x, x p_x\\} = x\\{x,p_x\\} + \\{x,x\\}p_x = x(1) = x$\n$\\{y, \\phi_{2}\\} = \\{y, x p_x + y p_y\\} = \\{y, y p_y\\} = y\\{y,p_y\\} + \\{y,y\\}p_y = y(1) = y$\n$\\{p_{x}, \\phi_{2}\\} = \\{p_{x}, x p_x + y p_y\\} = \\{p_x, x p_x\\} = p_x\\{p_x,x\\} + \\{p_x,x\\}p_x = p_x(-1) = -p_x$\n\nNow we compute the specific Dirac brackets:\n\n- **$\\{x,y\\}_{D}$:**\nLet $F=x, G=y$. $\\{x,y\\}=0$. Also $\\{x, \\phi_{1}\\}=0$ and $\\{y, \\phi_{1}\\}=0$. The correction term in the Dirac bracket formula has factors of $\\{x,\\phi_1\\}$ and $\\{\\phi_1,y\\}(=-\\{y,\\phi_1\\})$, so it vanishes.\n$$\n\\{x,y\\}_{D} = \\{x,y\\} + \\frac{1}{2R^2} \\left( \\{x,\\phi_{1}\\}\\{\\phi_{2},y\\} - \\{x,\\phi_{2}\\}\\{\\phi_{1},y\\} \\right) = 0 + \\frac{1}{2R^2} \\left( 0 \\cdot \\{\\phi_{2},y\\} - \\{x,\\phi_{2}\\} \\cdot 0 \\right) = 0\n$$\n\n- **$\\{x,p_{x}\\}_{D}$:**\nLet $F=x, G=p_x$. $\\{x,p_x\\}=1$. We have $\\{x,\\phi_1\\}=0$ and $\\{x,\\phi_2\\}=x$. Also, $\\{\\phi_1, p_x\\} = -\\{p_x, \\phi_1\\} = -(-2x)=2x$.\n$$\n\\{x,p_x\\}_{D} = \\{x,p_x\\} + \\frac{1}{2R^2} \\left( \\{x,\\phi_{1}\\}\\{\\phi_{2},p_x\\} - \\{x,\\phi_{2}\\}\\{\\phi_{1},p_x\\} \\right)\n$$\n$$\n\\{x,p_x\\}_{D} = 1 + \\frac{1}{2R^2} \\left( 0 \\cdot \\{\\phi_{2},p_x\\} - (x)(2x) \\right) = 1 - \\frac{2x^2}{2R^2} = 1 - \\frac{x^2}{R^2}\n$$\nUsing the constraint $R^2 = x^2+y^2$:\n$$\n\\{x,p_{x}\\}_{D} = 1 - \\frac{x^2}{x^2+y^2} = \\frac{x^2+y^2-x^2}{x^2+y^2} = \\frac{y^2}{x^2+y^2}\n$$\n\n- **$\\{y,p_{x}\\}_{D}$:**\nLet $F=y, G=p_x$. $\\{y,p_x\\}=0$. We have $\\{y,\\phi_1\\}=0$ and $\\{y,\\phi_2\\}=y$.\n$$\n\\{y,p_x\\}_{D} = \\{y,p_x\\} + \\frac{1}{2R^2} \\left( \\{y,\\phi_{1}\\}\\{\\phi_{2},p_x\\} - \\{y,\\phi_{2}\\}\\{\\phi_{1},p_x\\} \\right)\n$$\n$$\n\\{y,p_x\\}_{D} = 0 + \\frac{1}{2R^2} \\left( 0 \\cdot \\{\\phi_{2},p_x\\} - (y)(2x) \\right) = -\\frac{2xy}{2R^2} = -\\frac{xy}{R^2}\n$$\nUsing the constraint $R^2 = x^2+y^2$:\n$$\n\\{y,p_{x}\\}_{D} = -\\frac{xy}{x^2+y^2}\n$$\n\n**Part 3: Verification of the Jacobi Identity**\n\nThe Jacobi identity for the Dirac bracket states that for any three functions $A, B, C$,\n$$\n\\{A, \\{B,C\\}_D\\}_D + \\{B, \\{C,A\\}_D\\}_D + \\{C, \\{A,B\\}_D\\}_D = 0\n$$\nWe must verify this for $A=x, B=y, C=p_x$. The Jacobiator is:\n$$\nJ(x,y,p_{x})=\\{x,\\{y,p_{x}\\}_{D}\\}_{D}+\\{y,\\{p_{x},x\\}_{D}\\}_{D}+\\{p_{x},\\{x,y\\}_{D}\\}_{D}\n$$\nLet's evaluate the inner brackets first:\n$\\{y,p_{x}\\}_{D} = -\\frac{xy}{x^2+y^2}$\n$\\{p_{x},x\\}_{D} = -\\{x,p_{x}\\}_{D} = -\\frac{y^2}{x^2+y^2}$\n$\\{x,y\\}_{D} = 0$\n\nSubstituting these into the Jacobiator expression:\n$$\nJ(x,y,p_{x}) = \\left\\{x, -\\frac{xy}{x^2+y^2}\\right\\}_{D} + \\left\\{y, -\\frac{y^2}{x^2+y^2}\\right\\}_{D} + \\{p_{x}, 0\\}_{D}\n$$\nThe third term is immediately zero. Let's analyze the first two terms. Both inner brackets, $-\\frac{xy}{x^2+y^2}$ and $-\\frac{y^2}{x^2+y^2}$, are functions of the coordinates $(x,y)$ only. Let's consider a general case of the Dirac bracket between a coordinate function $q_i \\in \\{x,y\\}$ and an arbitrary function $G(x,y)$ which depends only on the coordinates.\n$$\n\\{q_i, G(x,y)\\}_{D} = \\{q_i, G(x,y)\\} + \\frac{1}{2R^2} \\left( \\{q_i,\\phi_{1}\\}\\{\\phi_{2},G\\} - \\{q_i,\\phi_{2}\\}\\{\\phi_{1},G\\} \\right)\n$$\nWe analyze each term in this expression:\n1.  $\\{q_i, G(x,y)\\} = 0$ because the Poisson bracket between any two functions that depend only on coordinates is zero.\n2.  $\\{q_i, \\phi_1\\} = \\{q_i, x^2+y^2-R^2\\} = 0$ for $q_i \\in \\{x,y\\}$.\n3.  $\\{\\phi_1, G\\} = \\{x^2+y^2-R^2, G(x,y)\\} = 0$ for the same reason as in point 1.\n\nSubstituting these results into the formula for the Dirac bracket:\n$$\n\\{q_i, G(x,y)\\}_{D} = 0 + \\frac{1}{2R^2} \\left( (0)\\{\\phi_{2},G\\} - \\{q_i,\\phi_{2}\\}(0) \\right) = 0\n$$\nThis proves that for this specific constrained system, the Dirac bracket of a coordinate $x$ or $y$ with any function of $x$ and $y$ only is zero.\n\nApplying this result to our Jacobiator:\n- The first term is $\\{x, -\\frac{xy}{x^2+y^2}\\}_{D}$. Here, $q_i=x$ and $G(x,y) = -\\frac{xy}{x^2+y^2}$. Based on our general result, this term is $0$.\n- The second term is $\\{y, -\\frac{y^2}{x^2+y^2}\\}_{D}$. Here, $q_i=y$ and $G(x,y) = -\\frac{y^2}{x^2+y^2}$. This term is also $0$.\n\nTherefore, the Jacobiator is:\n$$\nJ(x,y,p_{x}) = 0 + 0 + 0 = 0\n$$\nThis verifies the Jacobi identity for the functions $x$, $y$, and $p_x$ with respect to the Dirac bracket.\n\nThe problem asks for the expression for $\\{x,p_x\\}_D$ as the final answer. We have computed this to be $\\frac{y^2}{x^2+y^2}$.",
            "answer": "$$\n\\boxed{\\frac{y^2}{x^2+y^2}}\n$$"
        }
    ]
}