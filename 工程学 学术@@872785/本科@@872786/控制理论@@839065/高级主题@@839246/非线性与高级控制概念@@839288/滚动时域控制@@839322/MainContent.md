## 引言
在现代[控制工程](@entry_id:149859)中，如何高效且安全地管理日益复杂的动态系统是一个核心挑战。许多系统不仅具有多变量、强耦合的特性，还必须在严格的物理和操作约束下运行。传统控制方法在应对这些挑战时往往捉襟见肘。递推时域控制（Receding Horizon Control, RHC），也常被称为[模型预测控制](@entry_id:146965)（Model Predictive Control, MPC），作为一种先进的控制策略应运而生，它提供了一个强大而灵活的框架来系统性地解决这些问题。其核心思想在于利用系统模型来预测未来，并在每个时间步在线求解一个[优化问题](@entry_id:266749)，从而找到当前最优的控制决策。这种前瞻性的决策方式使其在性能和安全性方面表现卓越。

本文将引导您深入理解递推时域控制的精髓。在接下来的章节中，您将学习到：

- **原理与机制**：我们将剖析RHC的“预测-优化-滚动实施”核心循环，阐明其如何处理约束、抑制扰动，并探讨其与经典控制理论的深刻联系。
- **应用与跨学科连接**：通过从[过程控制](@entry_id:271184)到自主机器人，再到[生物医学工程](@entry_id:268134)的丰富案例，展示RHC在不同领域解决实际问题的强大能力。
- **动手实践**：通过一系列精心设计的练习，您将有机会将理论知识转化为解决具体问题的实践技能。

让我们首先从RHC的基本工作原理开始，揭示其为何成为现代控制领域中不可或缺的工具。

## 原理与机制

在上一章的引言之后，本章将深入探讨递推时域控制（Receding Horizon Control, RHC），亦称[模型预测控制](@entry_id:146965)（Model Predictive Control, MPC），的核心工作原理与基本机制。我们将从其基本思想出发，系统地剖析其预测、优化和反馈的[循环过程](@entry_id:146195)，并阐明其在处理约束、[多变量系统](@entry_id:169616)以及应对不确定性方面的关键优势。

### 递推时域控制的核心思想

递推时域控制的基本思想可以类比于一位经验丰富的驾驶员在复杂路况下的决策过程。驾驶员不会只盯着车头正前方，而是会向前看一段距离，预测未来几秒内可能的交通状况、道路曲率等，并在脑海中规划出一条既安全又平稳的驾驶轨迹（包括一系列方向盘和油门/刹车的操作）。然而，他并不会完全执行这整个计划。他只会执行计划中的第一个动作——比如轻踩刹车或微调方向盘。紧接着，他会立刻根据新的车辆位置、速度和更新的交通状况，再次向前看一段距离，重新规划一条新的最优轨迹，并同样只执行新计划的第一个动作。这个“向前看、规划、执行一步、再重复”的[循环过程](@entry_id:146195)，正是递推时域控制的精髓。

这一过程在控制工程中被形式化为三个关键步骤：**预测（Predict）**、**优化（Optimize）** 和 **滚动实施（Recede）**。

#### 预测：基于模型的未来展望

为了能够在当前时刻 $k$ 对未来进行规划，控制器必须拥有一个能够描述系统行为的**数学模型**。这个模型是RHC框架不可或缺的基石 [@problem_id:1603985]。该模型的作用是，给定系统在当前时刻 $k$ 的状态 $x(k)$ 以及一个假设的未来控制输入序列，它能够预测出系统在未来一段时间（即**[预测时域](@entry_id:261473)**，prediction horizon）内的状态演化轨迹。

对于一个[离散时间系统](@entry_id:263935)，其动态可以表示为状态[更新方程](@entry_id:264802)：
$$x(k+1) = f(x(k), u(k))$$
其中，$x(k)$ 是在时刻 $k$ 的系统状态向量，$u(k)$ 是控制输入向量。在时刻 $k$，控制器利用这个模型，从当前状态 $x(k)$ 出发，对未来 $N_p$ 步进行预测。对于任意给定的未来控制序列 $\lbrace u(k|k), u(k+1|k), \dots, u(k+N_p-1|k) \rbrace$，可以递归地计算出相应的未来状态序列 $\lbrace x(k+1|k), x(k+2|k), \dots, x(k+N_p|k) \rbrace$。这里的记号 $u(k+i|k)$ 表示在时刻 $k$ 计算出的、计划在未来时刻 $k+i$ 施加的控制输入。

没有这个预测模型，控制器就无法“预见”其决策的后果，也就无法在众多可能的控制策略中进行选择和优化。例如，在一个智能楼宇的暖通空调（HVAC）控制问题中，控制器需要一个[热力学](@entry_id:141121)模型来模拟不同的功率设定序列将如何影响未来几小时的室内温度，从而找到能耗最低且能维持舒适温度的控制策略 [@problem_id:1603985]。

#### 优化：在约束下寻找[最优控制](@entry_id:138479)序列

在获得了预测能力之后，RHC在每个时间步的核心任务是求解一个有限时域的**[优化问题](@entry_id:266749)**。该问题的目标是找到一个最优的未来控制输入序列，使得一个预定义的**代价函数**（cost function）最小化。

这个代价函数通常被设计为反映控制任务的多个目标，例如：
- **性能指标**：惩罚预测的状态轨迹与期望参考轨迹之间的偏差。
- **能耗/成本指标**：惩罚控制输入的大小或变化率，以节约能源或减少执行器的磨损。

一个典型的二次型代价函数形式如下：
$$J = \sum_{i=0}^{N_p-1} \left( \|x(k+i|k) - x_{ref}(k+i)\|_Q^2 + \|u(k+i|k)\|_R^2 \right) + J_f(x(k+N_p|k))$$
其中，$x_{ref}$ 是参考轨迹，$Q$ 和 $R$ 是正定权重矩阵，用于平衡跟踪性能和控制成本。$J_f$ 是一个可选的**终端代价**，我们将在后续讨论其重要性。

此[优化问题](@entry_id:266749)的**决策变量**正是整个未来控制输入序列 $\lbrace u(k|k), u(k+1|k), \dots, u(k+N_p-1|k) \rbrace$ [@problem_id:1603941]。而预测的状态序列 $\lbrace x(k+1|k), \dots, x(k+N_p|k) \rbrace$ 则是依赖于这些决策变量和初始状态 $x(k)$ 的中间变量。

除了最小化[代价函数](@entry_id:138681)，优化过程还必须满足一系列**约束条件**，例如：
- **输入约束**：执行器的物理限制，如电机的最大扭矩或阀门的最大开度，$u_{min} \le u(k+i|k) \le u_{max}$。
- **状态约束**：系统的安全或操作要求，如[化学反应](@entry_id:146973)釜的温度不能超过某个阈值，$x_{min} \le x(k+i|k) \le x_{max}$。

#### 滚动实施：递推的本质

在时刻 $k$ 求解[优化问题](@entry_id:266749)后，我们会得到一个完整的、包含 $N_p$ 个控制动作的最优控制序列 $U_k^* = \lbrace u_k^*, u_{k+1}^*, \dots, u_{k+N_p-1}^* \rbrace$。然而，RHC的一个标志性特征是，它**仅将这个序列中的第一个控制动作 $u_k^*$ 应用于实际系统** [@problem_id:1603993]。

随后，时间向[前推](@entry_id:158718)进到下一时刻 $k+1$。此时，控制器会：
1.  测量（或估计）系统在 $k+1$ 时刻的**新状态** $x(k+1)$。
2.  将整个[预测时域](@entry_id:261473)向前**移动一步（或称“滚动”，recede）**，新的规划区间变为从 $k+1$ 到 $k+1+N_p-1$ [@problem_id:1603955]。
3.  以新的状态 $x(k+1)$ 为[初始条件](@entry_id:152863)，**完全重新求解**一个新的[优化问题](@entry_id:266749)，得到一个新的最优控制序列 $U_{k+1}^*$。
4.  同样地，仅将新序列的第一个元素 $u_{k+1}^*$ 应用于系统。

这个“预测-优化-实施首步-滚动”的循环在每个时间步不断重复，构成了递推时域控制的完[整闭](@entry_id:149392)环操作。术语“递推时域”（Receding Horizon）或“[滚动时域](@entry_id:181425)”形象地描述了预测窗口随时间向前滚动的这一核心机制 [@problem_id:1603955]。

### 关键特性与优势

RHC独特的循环机制赋予了它一系列区别于传统控制方法的强大特性。

#### 内蕴的反馈与[扰动抑制](@entry_id:262021)

尽管RHC在每个时间步求解的是一个开环[优化问题](@entry_id:266749)（即假设未来在没有扰动的情况下演化），但其整体架构却是一个强大的**闭环反馈**系统。反馈的来源在于每个时间步开始时对系统当前状态的重新测量。

当一个未被模型预测到的**扰动**（disturbance）作用于系统时，它会导致系统在下一时刻的实际状态 $x(k+1)$ 偏离控制器在 $k$ 时刻所预测的状态 $x(k+1|k)$。在 $k+1$ 时刻，RHC控制器会测量到这个被扰动影响了的真实状态 $x(k+1)$，并以此为起点重新进行优化。这意味着新的控制计划会自然地将消除该扰动影响作为其优化目标的一部分。

让我们通过一个控制机器人关节的例子来具体说明 [@problem_id:1603951]。假设一个关节的角度误差动力学为 $x[k+1] = x[k] + 0.5 u[k]$，目标是使误差 $x$ 归零。控制器在每一步规划未来两个时刻的力矩 $\lbrace u[k], u[k+1] \rbrace$ 以最小化代价函数 $J_k = u[k]^2 + u[k+1]^2 + 8x[k+2]^2$。

-   在 $k=0$ 时，假设初始误差 $x[0] = 5.0$。通过求解[优化问题](@entry_id:266749)，控制器计算出最优的第一个力矩为 $u[0] = -4.0$。
-   在没有扰动的情况下，系统状态会变为 $x_{expected}[1] = 5.0 + 0.5(-4.0) = 3.0$。
-   现在，假设一个意外的机械冲击给系统带来了一个 $d = -1.0$ 的扰动，导致在 $k=1$ 时刻测量的实际状态为 $x[1] = x_{expected}[1] + d = 3.0 - 1.0 = 2.0$。
-   在 $k=1$ 时刻，RHC控制器会以这个新的、非预期的状态 $x[1] = 2.0$ 为起点重新求解[优化问题](@entry_id:266749)。它不会执行原计划中的第二个动作，而是计算一个全新的最优力矩序列。求解结果表明，新的最优第一个力矩为 $u[1] = -1.60$。

这个计算结果清晰地表明，控制器根据包含了扰动信息的最新测量值，自动调整了其控制策略。相比于原计划（若没有扰动，继续执行可能会导致控制效果不佳），新的控制动作 $u[1]$ 是针对当前实际情况的“修正”行为，从而有效地抑制了扰动的影响。这种在每个[采样周期](@entry_id:265475)都重新评估并优化的机制，使得RHC具有天然的鲁棒性。

#### 对约束的系统性处理

在实际工程应用中，系统几乎总是受到各种物理或操作上的限制。例如，电机的输出力矩有上限，储液罐的液位不能[溢出](@entry_id:172355)，温度不能超出安全范围。RHC最显著的优势之一，就是能够**系统性地、前瞻性地处理这些约束**。

在构建[优化问题](@entry_id:266749)时，可以将对[状态和](@entry_id:193625)输入的约束直接作为[不等式约束](@entry_id:176084)条件包含进去。优化算法在寻找最小化代价函数的解时，会确保整个[预测时域](@entry_id:261473)内的[状态和](@entry_id:193625)输入轨迹都严格位于所设定的可行域内。这意味着控制器在计算当前控制动作时，就已经考虑到了该动作及其后续动作是否会在未来导致约束被违反。如果一个看似激进的控制动作会在几步之后导致系统触及边界，优化器会自动选择一个更温和、更安全的替代方案。

这与传统控制器（如PID）处理约束的方式形成鲜明对比。传统方法通常在[控制器设计](@entry_id:274982)完成后，再附加一些“事后”的补救措施，如抗饱和（anti-windup）逻辑，这种方法往往是启发式的，缺乏最优性保证，并可能引入[非线性](@entry_id:637147)和不稳定性。而RHC则将约束作为问题内在的一部分进行一体化处理，提供了更为优雅和可靠的解决方案。

#### 对多变量耦合系统的有效控制

许多复杂的工业过程，如化工反应、航空航天和高级农业，都是**多输入多输出（MIMO）**系统，并且不同输入输出之间存在显著的**耦合（cross-coupling）**。这意味着一个执行器（输入）的动作不仅会影响其“主要”的被控变量（输出），还会对其他输出产生不期望的副作用。

对于这类系统，若采用多个独立的单输入单输出（SISO）控制器进行[分散控制](@entry_id:264465)，每个控制器会将其他回路带来的耦合效应视为外部扰动来被动地加以抑制。这种方式在[强耦合系统](@entry_id:194992)中往往性能不佳，甚至可能导致[振荡](@entry_id:267781)或不稳定，因为各个控制器之间缺乏协调，无法预见彼此的行为。

RHC由于其基于模型的预测能力，天然地适用于处理[MIMO系统](@entry_id:268566) [@problem_id:1583601]。其所用的多变量模型能够完整地描述所有输入对所有输出的影响，包括耦合项。在优化过程中，控制器可以同时计算所有输入（如 $u_1$ 和 $u_2$）的最优序列。

例如，在一个需要同时控制水体营养物浓度 ($y_1$) 和空气温度 ($y_2$) 的[水培](@entry_id:141599)系统中，使用加热器 ($u_2$) 升温会间接导致营养物浓度 ($y_1$) 下降。一个多变量MPC控制器能够在其模型中预见到这一耦合效应。因此，当它决定增加加热功率 $u_2$ 以提升温度时，会**同时、主动地**调整营养液注入量 $u_1$，以补偿即将发生的浓度下降。这种基于预测的**协调和前馈补偿**是分散式控制无法实现的，也是MPC在处理复杂耦合过程中的核心优势 [@problem_id:1583601]。

### 设计考量与理论关联

尽管RHC原理清晰，但在设计和应用时仍需仔细权衡几个关键参数，并且它与经典的控制理论（如LQR）有着深刻的联系。

#### [预测时域](@entry_id:261473)长度的选择

[预测时域](@entry_id:261473)的长度 $N_p$ 是RHC的一个关键设计参数，其选择直接影响到控制器的性能和计算负担。

-   **短时域 ($N_p$ 较小)**：优点是每一步的[优化问题](@entry_id:266749)规模较小，计算速度快，对硬件要求低。缺点是控制器可能变得“短视”（myopic）。它可能为了在短期内获得良好表现而采取激进的控制策略，却忽略了这些策略可能带来的长期负面影响。

-   **长时域 ($N_p$ 较大)**：优点是控制器具有更广阔的“视野”，能够预见到更远的未来，从而做出更具前瞻性的决策，通常能带来更好的整体性能和稳定性。缺点是[优化问题](@entry_id:266749)的维度和复杂性随 $N_p$ 显著增加，导致计算时间变长，对实时计算能力提出了更高的要求。

一个库存管理系统的例子可以生动地说明这一点 [@problem_id:1603956]。假设一个仓库需要通过每日订货 ($u_k$) 来维持目标库存水平 ($x_{ref}$)。如果今天的需求 ($d_0$) 较小，但明天有一个巨大的需求 ($d_1$) 即将到来。
-   一个[预测时域](@entry_id:261473) $N=1$ 的控制器只能看到今天的需求。它会计算出一个较小的订货量，仅仅用于补充今天的消耗。
-   而一个[预测时域](@entry_id:261473) $N=2$ 的控制器则能“看到”明天的大额需求。它会预见到仅补充今天的消耗将在明天导致严重缺货，因此在今天就会下一个更大的订单，提前为未来的需求做准备。在一个具体的算例中，$N=2$ 控制器计算出的初始订单量可以是 $N=1$ 控制器的2.7倍以上 [@problem_id:1603956]。

这表明，选择足够长的[预测时域](@entry_id:261473)对于控制器做出明智和主动的决策至关重要。

#### 终端代价与稳定性

对于一个有限的[预测时域](@entry_id:261473) $N_p$，即使系统是可稳定的，标准的RHC也**不能自动保证[闭环系统](@entry_id:270770)的稳定性**。原因在于，控制器可能会选择一条在时域 $N_p$ 内代价很小，但在时域末端（时刻 $k+N_p$）却将系统带入一个“危险”状态的轨迹，因为控制器无法“看到”$k+N_p$ 之后的情况。对于开环不稳定的系统，这个问题尤为突出。

为了解决这个问题，一种有效的技术是引入**终端代价** $J_f(x_{k+N_p|k})$ 和/或**[终端约束](@entry_id:176488)集**。终端代价项 $J_f$ 的作用是近似地表示从[预测时域](@entry_id:261473)终点 $x(k+N_p|k)$ 开始直到无穷远的未来所产生的累积代价。通过在总代价函数中加入这一项，控制器在优化时会被激励去将系统在时域末端驱动到一个“好”的状态——即一个从该状态出发能够以较小代价稳定到原点的状态。

一个很好的选择是，将终端代价的权重矩阵 $P$ 选为与系统相关的无限时域[LQR问题](@entry_id:267315)所对应的**代数[Riccati方程](@entry_id:184132)（ARE）**的解 [@problem_id:1603979]。这样一来，终端代价 $x^T P x$ 就精确地代表了从状态 $x$ 开始，在最优[LQR控制](@entry_id:176902)下的无限时域总代价。

在一个不稳定的系统（例如 $x_{k+1} = 1.2 x_k + u_k$）上施加RHC，有无终端代价会产生显著差异。计算表明，当初始状态相同时，使用基于[Riccati方程](@entry_id:184132)解的终端代价的控制器，其计算出的初始控制输入比没有终端代价的控制器更为“有力”或“保守”（例如，控制输入大小的比值为1.323）[@problem_id:1603979]。这是因为终端代价迫使控制器更积极地将状态拉向[稳定区域](@entry_id:166035)，以避免在[预测时域](@entry_id:261473)结束后状态发散带来的巨大“隐性”成本。

#### 与[线性二次调节器](@entry_id:267871)（LQR）的关系

RHC与经典的**[线性二次调节器](@entry_id:267871)（LQR）**之间存在着深刻的理论联系。LQR旨在为[线性系统](@entry_id:147850)找到一个最优的控制律 $u_k = -K x_k$，以最小化一个无限时域的二次型[代价函数](@entry_id:138681)。这个控制律是一个**静态[状态反馈](@entry_id:151441)**，其增益矩阵 $K$ 是一个常数，可以离线计算一次，之后便可永久使用。

现在考虑一个特殊的RHC场景：应用于一个**无约束**的[线性时不变](@entry_id:276287)（LTI）系统，其代价函数与LQR相同（均为二次型），并且其[预测时域](@entry_id:261473)被设为**无限长** ($N_p \to \infty$)。在这种理想情况下，RHC在每一步求解的[优化问题](@entry_id:266749)，实际上就等同于从当前状态 $x_k$ 出发的标准无限时域[LQR问题](@entry_id:267315)。

根据最优控制的贝尔曼最优性原理，这个无限时域问题的解在任何时刻都具有相同的形式。因此，RHC在每一步求解得到的第一个[最优控制](@entry_id:138479)动作，将总是与[LQR控制](@entry_id:176902)律完全一致，即 $u_k = -K x_k$，其中 $K$ 正是LQR的增益矩阵 [@problem_id:1603973]。

这个结论揭示了：**对于无约束[LTI系统](@entry_id:271946)，无限时域RHC等价于[LQR控制器](@entry_id:267871)**。尽管RHC名义上在每一步都“重新优化”，但在这种特殊情况下，每次优化的结果都殊途同归，复现了LQR的静态反馈律。这一联系不仅为RHC提供了坚实的理论基础，也解释了为何LQR的解（[Riccati方程](@entry_id:184132)）在为RHC设计终端代价和证明稳定性时扮演着如此关键的角色。

### 实际应用中的考量

除了理论设计，RHC的成功实施还依赖于对两个关键实际问题的处理。

#### 计算成本

RHC最主要的实践挑战在于其**计算成本**。与LQR或[PID](@entry_id:174286)等控制器相比，RHC的计算负担要大得多。

-   **[LQR控制器](@entry_id:267871)**：其核心计算（求解[Riccati方程](@entry_id:184132)以获得增益 $K$）是**离线**完成的。在**在线**运行时，每一步只需要进行一次简单的矩阵-向量乘法 $u_k = -K x_k$，计算量极小。

-   **RHC控制器**：其核心计算（求解一个[约束优化](@entry_id:635027)问题）是**在线**进行的，并且必须在每个[采样周期](@entry_id:265475)内完成。这个[优化问题](@entry_id:266749)的复杂性随着[预测时域](@entry_id:261473) $N_p$、[状态和](@entry_id:193625)输入的维度以及约束的数量而迅速增长。对于快速动态系统，采样周期很短，这就对处理器的计算能力提出了严峻的挑战 [@problem_id:1603977]。

因此，RHC的应用往往受限于被控系统的动态速度和可用计算资源的限制。近年来，随着计算硬件的飞速发展以及高效优化算法（如主动集法、[内点法](@entry_id:169727)和快速梯度法）的研究，RHC的应用范围已经从传统的慢过程工业（如化工、电力）扩展到了汽车、机器人和航空航天等快速动态领域。

#### [状态估计](@entry_id:169668)

RHC的[优化问题](@entry_id:266749)在时刻 $k$ 是以当前状态 $x(k)$ 作为初始条件进行求解的。然而，在许多实际系统中，并不是所有的[状态变量](@entry_id:138790)都能被传感器直接测量。我们可能只能测得一部分状态的组合，即系统输出 $y_k = C x_k$。

在这种情况下，为了给RHC提供必要的初始状态，需要引入一个**[状态估计器](@entry_id:272846)（State Estimator）**或**观测器（Observer）** [@problem_id:1603989]。[状态估计器](@entry_id:272846)的角色是利用已知的系统模型、过去的控制输入以及当前的测量输出 $y_k$，来实时地计算出对完整状态向量的最佳估计值，记为 $\hat{x}(k)$。常见的[状态估计器](@entry_id:272846)包括卡尔曼滤波器（Kalman Filter）和[龙伯格观测器](@entry_id:150581)（Luenberger Observer）。

在集成了[状态估计器](@entry_id:272846)的RHC框架（有时称为[输出反馈](@entry_id:271838)MPC）中，每一步的流程变为：
1.  在时刻 $k$，测量系统输出 $y_k$。
2.  将 $y_k$ 和上一时刻的控制输入 $u_{k-1}$ 输入到[状态估计器](@entry_id:272846)中，更新得到当前状态的估计值 $\hat{x}(k)$。
3.  将这个**状态估计值 $\hat{x}(k)$ 作为RHC[优化问题](@entry_id:266749)的初始状态**，即 $x(k|k) = \hat{x}(k)$ [@problem_id:1603989]。
4.  求解[优化问题](@entry_id:266749)，得到最优控制序列，并应用其第一个元素 $u_k$。

通过这种方式，[状态估计器](@entry_id:272846)和RHC控制器协同工作，使得RHC能够在只有部分信息可用的情况下，依然能够有效地对系统进行控制。这种组合构成了[现代控制系统](@entry_id:269478)中RHC的完整和实用形态。