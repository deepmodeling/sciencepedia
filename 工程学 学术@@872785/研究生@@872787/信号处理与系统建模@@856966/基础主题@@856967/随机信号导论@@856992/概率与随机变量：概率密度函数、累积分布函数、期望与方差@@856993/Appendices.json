{"hands_on_practices": [{"introduction": "描述多个随机变量的联合行为是概率论在信号处理中的核心应用。本练习将引导你处理一个二维随机向量的联合概率密度函数（PDF），这是对复基带信号的同相和正交分量进行建模的常用方法。你将通过实际计算来巩固基本功：验证一个函数是否为有效的PDF（通过归一化），并计算一个事件发生的概率，这些都是处理多维信号时不可或缺的技能。[@problem_id:2893239]", "problem": "在一个窄带信号处理系统中，考虑一个复基带系数，其由一个二维实随机向量 $(X,Y)$ 建模，该向量表示同相和正交分量。假设 $(X,Y)$ 的联合概率密度函数 (pdf) $f_{X,Y}(x,y)$ 的支撑集为扇形区域\n$$\nS \\triangleq \\left\\{(x,y)\\in\\mathbb{R}^{2} : \\exists\\,(r,\\theta)\\ \\text{with}\\ 1 \\le r \\le 3,\\ 0 \\le \\theta \\le \\frac{\\pi}{3},\\ x = r\\cos\\theta,\\ y = r\\sin\\theta \\right\\},\n$$\n在 $S$ 之外为零。在 $S$ 上，该 pdf 由下式给出\n$$\nf_{X,Y}(x,y) = \\kappa\\left(x^{2}+y^{2}\\right),\n$$\n其中 $\\kappa>0$ 是一个常数，其取值使得 $f_{X,Y}$ 在 $\\mathbb{R}^{2}$ 上的积分为 $1$。角度以弧度为单位。\n\n1. 仅使用概率密度函数 (pdf) 的定义性质以及标准的极坐标换元及其雅可比行列式，验证 $f_{X,Y}$ 的积分为 $1$ 并确定 $\\kappa$ 的值。\n\n2. 令\n$$\nA \\triangleq \\left\\{(x,y)\\in S : 2 \\le \\sqrt{x^{2}+y^{2}} \\le 3,\\ \\frac{\\pi}{12} \\le \\theta \\le \\frac{\\pi}{6}\\right\\},\n$$\n其中 $\\theta$ 是与 $(x,y)$ 相关的极角，即 $x = r\\cos\\theta$, $y = r\\sin\\theta$ 且 $r = \\sqrt{x^{2}+y^{2}}$。计算概率 $\\mathbb{P}\\big((X,Y)\\in A\\big)$。\n\n请给出你的最终答案，形式为单个精确值。不要四舍五入或近似计算。概率无需单位。", "solution": "所述问题具有科学依据且数学上是适定的。这是概率论中的一个标准练习，涉及联合概率密度函数、归一化以及在指定区域上计算概率。我们开始求解。\n\n问题需要进行两项计算。首先，我们必须确定归一化常数 $\\kappa$。其次，我们必须计算随机向量 $(X,Y)$ 属于子区域 $A$ 的概率。\n\n第1部分：确定常数 $\\kappa$。\n任何概率密度函数 $f_{X,Y}(x,y)$ 的定义性质是其在整个样本空间上的积分必须等于 $1$。\n$$ \\iint_{\\mathbb{R}^{2}} f_{X,Y}(x,y) \\,dx\\,dy = 1 $$\n函数 $f_{X,Y}(x,y)$ 仅在其支撑区域 $S$ 上非零。因此，积分简化为：\n$$ \\iint_{S} \\kappa\\left(x^{2}+y^{2}\\right) \\,dx\\,dy = 1 $$\n区域 $S$ 是一个环扇形，最自然的方式是使用极坐标来描述。我们应用变换 $x = r\\cos\\theta$ 和 $y = r\\sin\\theta$。表达式 $x^2+y^2$ 变为 $r^2$。在极坐标中，微分面积元为 $dx\\,dy = r\\,dr\\,d\\theta$，其中 $r$ 是变换的雅可比行列式。区域 $S$ 由约束条件 $1 \\le r \\le 3$ 和 $0 \\le \\theta \\le \\frac{\\pi}{3}$ 定义。\n\n将这些代入积分，我们得到：\n$$ \\int_{0}^{\\pi/3} \\int_{1}^{3} \\kappa(r^2) \\cdot r \\,dr\\,d\\theta = 1 $$\n常数 $\\kappa$ 可以移到积分符号外：\n$$ \\kappa \\int_{0}^{\\pi/3} \\int_{1}^{3} r^3 \\,dr\\,d\\theta = 1 $$\n我们首先计算关于 $r$ 的内层积分：\n$$ \\int_{1}^{3} r^3 \\,dr = \\left[ \\frac{r^4}{4} \\right]_{1}^{3} = \\frac{3^4}{4} - \\frac{1^4}{4} = \\frac{81-1}{4} = \\frac{80}{4} = 20 $$\n现在，我们将此结果代入关于 $\\theta$ 的外层积分：\n$$ \\kappa \\int_{0}^{\\pi/3} 20 \\,d\\theta = 1 $$\n$$ 20\\kappa \\left[ \\theta \\right]_{0}^{\\pi/3} = 1 $$\n$$ 20\\kappa \\left(\\frac{\\pi}{3} - 0\\right) = 1 $$\n$$ \\frac{20\\pi\\kappa}{3} = 1 $$\n解出 $\\kappa$，我们得到：\n$$ \\kappa = \\frac{3}{20\\pi} $$\n由于 $\\pi > 0$，我们有 $\\kappa > 0$，这与问题陈述一致。\n\n第2部分：计算概率 $\\mathbb{P}\\big((X,Y)\\in A\\big)$。\n事件 $(X,Y) \\in A$ 的概率通过在区域 $A$ 上对概率密度函数进行积分得到：\n$$ \\mathbb{P}\\big((X,Y)\\in A\\big) = \\iint_A f_{X,Y}(x,y) \\,dx\\,dy $$\n使用我们求出的 $\\kappa$ 值，在 $S$ 上的 pdf 为 $f_{X,Y}(x,y) = \\frac{3}{20\\pi}(x^2+y^2)$。区域 $A$ 是 $S$ 的一个子集，在极坐标中由 $2 \\le r \\le 3$ 和 $\\frac{\\pi}{12} \\le \\theta \\le \\frac{\\pi}{6}$ 定义。我们再次将积分转换为极坐标：\n$$ \\mathbb{P}\\big((X,Y)\\in A\\big) = \\int_{\\pi/12}^{\\pi/6} \\int_{2}^{3} \\frac{3}{20\\pi}(r^2) \\cdot r \\,dr\\,d\\theta $$\n$$ = \\frac{3}{20\\pi} \\int_{\\pi/12}^{\\pi/6} \\int_{2}^{3} r^3 \\,dr\\,d\\theta $$\n我们计算关于 $r$ 的内层积分：\n$$ \\int_{2}^{3} r^3 \\,dr = \\left[ \\frac{r^4}{4} \\right]_{2}^{3} = \\frac{3^4}{4} - \\frac{2^4}{4} = \\frac{81-16}{4} = \\frac{65}{4} $$\n现在我们将此结果代入概率表达式中：\n$$ \\mathbb{P}\\big((X,Y)\\in A\\big) = \\frac{3}{20\\pi} \\int_{\\pi/12}^{\\pi/6} \\frac{65}{4} \\,d\\theta = \\frac{3 \\cdot 65}{20\\pi \\cdot 4} \\int_{\\pi/12}^{\\pi/6} d\\theta $$\n我们简化常数因子：\n$$ \\frac{3 \\cdot 65}{80\\pi} = \\frac{195}{80\\pi} = \\frac{39 \\cdot 5}{16 \\cdot 5 \\pi} = \\frac{39}{16\\pi} $$\n接下来，我们计算关于 $\\theta$ 的外层积分：\n$$ \\int_{\\pi/12}^{\\pi/6} d\\theta = \\left[ \\theta \\right]_{\\pi/12}^{\\pi/6} = \\frac{\\pi}{6} - \\frac{\\pi}{12} = \\frac{2\\pi}{12} - \\frac{\\pi}{12} = \\frac{\\pi}{12} $$\n最后，我们将两部分相乘得到概率：\n$$ \\mathbb{P}\\big((X,Y)\\in A\\big) = \\frac{39}{16\\pi} \\cdot \\frac{\\pi}{12} = \\frac{39}{16 \\cdot 12} $$\n化简分数：\n$$ \\frac{39}{192} = \\frac{3 \\cdot 13}{3 \\cdot 64} = \\frac{13}{64} $$\n这就是所求的概率。", "answer": "$$\\boxed{\\frac{13}{64}}$$", "id": "2893239"}, {"introduction": "在信号处理中，我们常常需要根据系统模型来推导信号的统计特性，而不仅仅是处理给定的概率分布。这个练习模拟了一个非常经典的场景：一个信号在加性高斯白噪声（AWGN）信道中传输。你将通过变量变换的方法，从输入信号和噪声的分布推导出接收信号的联合概率密度函数，并进一步计算输入与输出之间的协方差与相关性，从而深刻理解系统模型如何决定信号的统计关系。[@problem_id:2893119]", "problem": "一个服从分布 $X \\sim \\mathcal{N}(0,1)$ 的实值基带符号 $X$ 通过一个加性高斯白噪声 (AWGN) 信道传输。接收到的样本为 $Y = X + Z$，其中噪声 $Z \\sim \\mathcal{N}(0,1)$ 与 $X$ 独立。\n\n你的任务是：\n- 从联合分布和随机变量线性变换的基本定义出发，推导随机变量对 $(X,Y)$ 的联合概率密度函数 $f_{X,Y}(x,y)$。然后，用一个关于 $f_{X,Y}$ 的显式二重积分表示联合累积分布函数 $F_{X,Y}(x,y)$，并在适当的情况下，将其识别为具有相应参数的标准二元正态累积分布。\n- 使用你得到的联合密度，计算协方差 $\\operatorname{Cov}(X,Y)$ 和相关系数 $\\rho_{XY}$。\n\n请提供相关系数 $\\rho_{XY}$ 作为你的最终答案。无需单位，也无需四舍五入。最终答案必须是一个单一的实数值或一个单一的闭式解析表达式。", "solution": "该问题陈述已经过验证，被认为是具有科学依据、良定且客观的。它代表了随机过程理论在通信系统中应用的一个标准问题。我们现在将进行正式推导。\n\n给定两个独立的随机变量 $X$ 和 $Z$，它们都服从标准正态分布 $\\mathcal{N}(0,1)$。它们各自的概率密度函数 (PDF) 为：\n$$ f_X(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{x^2}{2}\\right) $$\n$$ f_Z(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right) $$\n由于 $X$ 和 $Z$ 是独立的，它们的联合PDF是它们各自PDF的乘积：\n$$ f_{X,Z}(x,z) = f_X(x)f_Z(z) = \\frac{1}{2\\pi} \\exp\\left(-\\frac{x^2 + z^2}{2}\\right) $$\n接收到的样本是一个由线性变换 $Y = X + Z$ 定义的新随机变量 $Y$。我们的任务是求出随机向量 $(X,Y)$ 的联合PDF，记为 $f_{X,Y}(x,y)$。\n\n为了推导 $f_{X,Y}(x,y)$，我们应用变量替换公式。我们考虑从随机向量 $(X,Z)$ 到 $(X,Y)$ 的变换。令函数为 $g_1(x,z) = x$ 和 $g_2(x,z) = x+z$。我们需要求出 $(U,V)$ 的联合PDF，其中 $U=g_1(X,Z)=X$ 和 $V=g_2(X,Z)=Y$。\n逆变换将 $(u,v)$ 映射回 $(x,z)$。\n从 $u=x$，我们得到 $x=u$。\n从 $v=x+z$，我们得到 $z=v-x = v-u$。\n所以，逆变换为 $x=u$ 和 $z=v-u$。\n\n该逆变换的雅可比行列式是偏导数矩阵的行列式：\n$$ J = \\det \\begin{pmatrix} \\frac{\\partial x}{\\partial u}  \\frac{\\partial x}{\\partial v} \\\\ \\frac{\\partial z}{\\partial u}  \\frac{\\partial z}{\\partial v} \\end{pmatrix} = \\det \\begin{pmatrix} 1  0 \\\\ -1  1 \\end{pmatrix} = (1)(1) - (0)(-1) = 1 $$\n雅可比行列式的绝对值为 $|J| = 1$。\n联合PDF $f_{X,Y}(x,y)$（使用 $x,y$ 而不是 $u,v$ 作为新变量）由下式给出：\n$$ f_{X,Y}(x,y) = f_{X,Z}(x, y-x) |J| $$\n将 $z=y-x$ 代入 $f_{X,Z}(x,z)$ 的表达式中：\n$$ f_{X,Y}(x,y) = \\frac{1}{2\\pi} \\exp\\left(-\\frac{x^2 + (y-x)^2}{2}\\right) \\cdot 1 $$\n指数中的二次型可以化简为：\n$$ x^2 + (y-x)^2 = x^2 + (y^2 - 2xy + x^2) = 2x^2 - 2xy + y^2 $$\n因此，随机变量对 $(X,Y)$ 的联合PDF为：\n$$ f_{X,Y}(x,y) = \\frac{1}{2\\pi} \\exp\\left(-\\frac{2x^2 - 2xy + y^2}{2}\\right) $$\n这是一个均值向量为 $[0,0]^T$ 的二元正态分布的PDF。\n\n联合累积分布函数 (CDF) $F_{X,Y}(x,y) = P(X \\le x, Y \\le y)$ 是通过对联合PDF积分得到的：\n$$ F_{X,Y}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f_{X,Y}(u,v) \\, dv \\, du = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} \\frac{1}{2\\pi} \\exp\\left(-\\frac{2u^2 - 2uv + v^2}{2}\\right) \\, dv \\, du $$\n该积分表示一个二元正态分布的CDF，我们现在将用其参数来刻画它。\n均值为 $E[X]=0$ 和 $E[Y]=E[X+Z]=E[X]+E[Z]=0+0=0$。\n方差为 $\\sigma_X^2 = \\operatorname{Var}(X) = 1$ 以及，由于 $X$ 和 $Z$ 的独立性，$\\sigma_Y^2 = \\operatorname{Var}(Y) = \\operatorname{Var}(X+Z) = \\operatorname{Var}(X) + \\operatorname{Var}(Z) = 1+1=2$。\n\n接下来，我们计算协方差 $\\operatorname{Cov}(X,Y)$。根据定义：\n$$ \\operatorname{Cov}(X,Y) = E[(X-E[X])(Y-E[Y])] $$\n由于 $E[X]=0$ 和 $E[Y]=0$，这可以简化为：\n$$ \\operatorname{Cov}(X,Y) = E[XY] = E[X(X+Z)] = E[X^2 + XZ] = E[X^2] + E[XZ] $$\n对于标准正态变量 $X$， $E[X^2] = \\operatorname{Var}(X) + (E[X])^2 = 1 + 0^2 = 1$。\n因为 $X$ 和 $Z$ 是独立的，$E[XZ] = E[X]E[Z] = 0 \\cdot 0 = 0$。\n因此，协方差为：\n$$ \\operatorname{Cov}(X,Y) = 1 + 0 = 1 $$\n所以，$(X,Y)$ 是一个二元正态随机向量，其均值为 $\\mu = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，协方差矩阵为 $\\Sigma = \\begin{pmatrix} \\sigma_X^2  \\operatorname{Cov}(X,Y) \\\\ \\operatorname{Cov}(X,Y)  \\sigma_Y^2 \\end{pmatrix} = \\begin{pmatrix} 1  1 \\\\ 1  2 \\end{pmatrix}$。CDF $F_{X,Y}(x,y)$ 是具有这些参数的标准二元正态CDF。\n\n最后，我们计算相关系数 $\\rho_{XY}$，其定义为：\n$$ \\rho_{XY} = \\frac{\\operatorname{Cov}(X,Y)}{\\sigma_X \\sigma_Y} $$\n我们有 $X$ 的标准差 $\\sigma_X = \\sqrt{\\operatorname{Var}(X)} = \\sqrt{1} = 1$，以及 $Y$ 的标准差 $\\sigma_Y = \\sqrt{\\operatorname{Var}(Y)} = \\sqrt{2}$。\n代入我们推导出的值：\n$$ \\rho_{XY} = \\frac{1}{1 \\cdot \\sqrt{2}} = \\frac{1}{\\sqrt{2}} $$\n这个值也可以直接从二元正态PDF的一般形式得到，其中指数中交叉项的系数与相关性有关。推导出的结果是正确的，并且经过了严格的论证。", "answer": "$$\\boxed{\\frac{1}{\\sqrt{2}}}$$", "id": "2893119"}, {"introduction": "从理论模型走向实际数据是工程应用的必经之路，这要求我们掌握如何从有限的样本中估计理论参数。本练习聚焦于信号处理中最常见的任务之一：从一系列独立同分布的样本中估计过程的方差。通过推导两种不同方差估计量的期望，你将揭示统计偏差这一精细而重要的概念，并理解为何在样本方差的计算中使用“$n-1$”作为分母（即贝塞尔校正）能够得到无偏估计，这是连接概率论与实用统计学的关键桥梁。[@problem_id:2893255]", "problem": "一个离散时间传感器在一个足够短的时间窗口内，从一个实值广义平稳随机过程中采集了 $n \\ge 2$ 个连续样本 $X_{1},\\dots,X_{n}$，这些样本可以被建模为来自一个具有有限均值 $\\mu$ 和有限方差 $\\sigma^{2}$ 的共同分布的独立同分布（i.i.d.）抽样。令样本均值为 $\\bar{X} \\triangleq \\frac{1}{n}\\sum_{i=1}^{n} X_{i}$。考虑该过程方差的两个估计量：\n- 分母为 $n$ 的估计量 $\\hat{\\sigma}^{2}_{n} \\triangleq \\frac{1}{n}\\sum_{i=1}^{n}\\bigl(X_{i}-\\bar{X}\\bigr)^{2}$。\n- 分母为 $n-1$ 的估计量 $\\hat{\\sigma}^{2}_{n-1} \\triangleq \\frac{1}{n-1}\\sum_{i=1}^{n}\\bigl(X_{i}-\\bar{X}\\bigr)^{2}$。\n\n仅从期望、方差和期望线性性的基本定义出发，并利用样本的独立性，推导用 $n$ 和 $\\sigma^{2}$ 表示的 $\\mathbb{E}\\!\\left[\\hat{\\sigma}^{2}_{n}\\right]$ 和 $\\mathbb{E}\\!\\left[\\hat{\\sigma}^{2}_{n-1}\\right]$，并计算每个估计量相对于 $\\sigma^{2}$ 的偏差，其定义为 $\\mathrm{bias}(\\hat{\\theta}) \\triangleq \\mathbb{E}[\\hat{\\theta}] - \\theta$。然后，从用 $\\bar{X}$ 估计 $\\mu$ 所消耗的自由度的角度，解释为什么将分母 $n$ 替换为 $n-1$ 可以消除偏差（这通常被称为贝塞尔校正，Bessel’s correction）。\n\n将你的最终答案以行矩阵的形式报告，顺序为 $\\bigl(\\mathbb{E}[\\hat{\\sigma}^{2}_{n}],\\ \\mathrm{bias}(\\hat{\\sigma}^{2}_{n}),\\ \\mathbb{E}[\\hat{\\sigma}^{2}_{n-1}],\\ \\mathrm{bias}(\\hat{\\sigma}^{2}_{n-1})\\bigr)$。不需要进行数值取整，也不需要物理单位。", "solution": "所述问题具有科学依据、提法明确且客观。这是统计理论中的一个标准推导，没有任何使其无效的缺陷。我们可以开始求解。\n\n问题要求计算方差 $\\sigma^2$ 的两个估计量的期望值和偏差，这些估计量是根据从一个随机过程中抽取的 $n$ 个独立同分布（i.i.d.）样本 $X_1, \\dots, X_n$ 计算得出的。其基础分布的均值为 $\\mathbb{E}[X_i] = \\mu$，方差为 $\\mathrm{Var}(X_i) = \\mathbb{E}[(X_i - \\mu)^2] = \\sigma^2$。这两个估计量都基于与样本均值 $\\bar{X} \\triangleq \\frac{1}{n}\\sum_{i=1}^{n} X_i$ 的离差平方和。\n\n分析的核心是求出平方和项 $\\sum_{i=1}^{n} (X_i - \\bar{X})^2$ 的期望。我们通过引入真实均值 $\\mu$ 来处理这个表达式：\n$$\n\\sum_{i=1}^{n} (X_i - \\bar{X})^2 = \\sum_{i=1}^{n} \\left( (X_i - \\mu) - (\\bar{X} - \\mu) \\right)^2\n$$\n展开求和式中的平方项得到：\n$$\n\\sum_{i=1}^{n} \\left[ (X_i - \\mu)^2 - 2(X_i - \\mu)(\\bar{X} - \\mu) + (\\bar{X} - \\mu)^2 \\right]\n$$\n我们可以将求和运算分配到这三项上：\n$$\n\\sum_{i=1}^{n} (X_i - \\bar{X})^2 = \\sum_{i=1}^{n} (X_i - \\mu)^2 - 2 \\sum_{i=1}^{n} (X_i - \\mu)(\\bar{X} - \\mu) + \\sum_{i=1}^{n} (\\bar{X} - \\mu)^2\n$$\n我们来分别分析每一项。\n第一项是 $\\sum_{i=1}^{n} (X_i - \\mu)^2$。\n对于第二项，因子 $(\\bar{X} - \\mu)$ 相对于求和索引 $i$ 是常数：\n$$\n-2 (\\bar{X} - \\mu) \\sum_{i=1}^{n} (X_i - \\mu) = -2 (\\bar{X} - \\mu) \\left( \\left(\\sum_{i=1}^{n} X_i\\right) - n\\mu \\right)\n$$\n根据样本均值的定义，$\\sum_{i=1}^{n} X_i = n\\bar{X}$。将其代入，我们得到：\n$$\n-2 (\\bar{X} - \\mu) (n\\bar{X} - n\\mu) = -2n (\\bar{X} - \\mu)^2\n$$\n对于第三项，$(\\bar{X} - \\mu)^2$ 相对于 $i$ 也是常数，所以其和为：\n$$\n\\sum_{i=1}^{n} (\\bar{X} - \\mu)^2 = n(\\bar{X} - \\mu)^2\n$$\n结合这些结果，离差平方和表达式简化为：\n$$\n\\sum_{i=1}^{n} (X_i - \\bar{X})^2 = \\sum_{i=1}^{n} (X_i - \\mu)^2 - 2n(\\bar{X} - \\mu)^2 + n(\\bar{X} - \\mu)^2 = \\sum_{i=1}^{n} (X_i - \\mu)^2 - n(\\bar{X} - \\mu)^2\n$$\n现在，我们对这个表达式求期望。根据期望的线性性质：\n$$\n\\mathbb{E}\\left[ \\sum_{i=1}^{n} (X_i - \\bar{X})^2 \\right] = \\mathbb{E}\\left[ \\sum_{i=1}^{n} (X_i - \\mu)^2 \\right] - n\\mathbb{E}\\left[ (\\bar{X} - \\mu)^2 \\right]\n$$\n我们来计算右边各项的期望。\n对于第一项：\n$$\n\\mathbb{E}\\left[ \\sum_{i=1}^{n} (X_i - \\mu)^2 \\right] = \\sum_{i=1}^{n} \\mathbb{E}\\left[ (X_i - \\mu)^2 \\right]\n$$\n根据定义，$\\mathbb{E}\\left[ (X_i - \\mu)^2 \\right]$ 是 $X_i$ 的方差，即 $\\sigma^2$。由于样本是独立同分布的，这对所有 $i=1, \\dots, n$ 都成立。因此：\n$$\n\\sum_{i=1}^{n} \\mathbb{E}\\left[ (X_i - \\mu)^2 \\right] = \\sum_{i=1}^{n} \\sigma^2 = n\\sigma^2\n$$\n对于第二项，$\\mathbb{E}\\left[ (\\bar{X} - \\mu)^2 \\right]$ 是样本均值的方差，即 $\\mathrm{Var}(\\bar{X})$。我们如下计算：\n$$\n\\mathrm{Var}(\\bar{X}) = \\mathrm{Var}\\left( \\frac{1}{n}\\sum_{i=1}^{n} X_i \\right) = \\frac{1}{n^2} \\mathrm{Var}\\left( \\sum_{i=1}^{n} X_i \\right)\n$$\n由于样本 $X_i$ 是独立的，它们的和的方差等于它们方差的和：\n$$\n\\mathrm{Var}\\left( \\sum_{i=1}^{n} X_i \\right) = \\sum_{i=1}^{n} \\mathrm{Var}(X_i) = \\sum_{i=1}^{n} \\sigma^2 = n\\sigma^2\n$$\n因此，样本均值的方差是：\n$$\n\\mathrm{Var}(\\bar{X}) = \\frac{1}{n^2} (n\\sigma^2) = \\frac{\\sigma^2}{n}\n$$\n将这些结果代回到主期望方程中，我们得到离差平方和的期望值：\n$$\n\\mathbb{E}\\left[ \\sum_{i=1}^{n} (X_i - \\bar{X})^2 \\right] = n\\sigma^2 - n\\left( \\frac{\\sigma^2}{n} \\right) = n\\sigma^2 - \\sigma^2 = (n-1)\\sigma^2\n$$\n有了这个关键结果，我们现在可以求出每个方差估计量的期望。\n\n对于分母为 $n$ 的估计量 $\\hat{\\sigma}^{2}_{n} = \\frac{1}{n}\\sum_{i=1}^{n}\\bigl(X_{i}-\\bar{X}\\bigr)^{2}$：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{n}] = \\mathbb{E}\\left[ \\frac{1}{n}\\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2} \\right] = \\frac{1}{n} \\mathbb{E}\\left[ \\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2} \\right] = \\frac{1}{n} (n-1)\\sigma^2 = \\frac{n-1}{n}\\sigma^2\n$$\n偏差定义为 $\\mathrm{bias}(\\hat{\\theta}) = \\mathbb{E}[\\hat{\\theta}] - \\theta$。对于 $\\hat{\\sigma}^{2}_{n}$，且 $\\theta = \\sigma^2$：\n$$\n\\mathrm{bias}(\\hat{\\sigma}^{2}_{n}) = \\mathbb{E}[\\hat{\\sigma}^{2}_{n}] - \\sigma^2 = \\frac{n-1}{n}\\sigma^2 - \\sigma^2 = \\left( \\frac{n-1 - n}{n} \\right)\\sigma^2 = -\\frac{1}{n}\\sigma^2\n$$\n这个估计量是有偏的，因为它的期望不等于 $\\sigma^2$。它系统地低估了真实方差。\n\n对于分母为 $n-1$ 的估计量 $\\hat{\\sigma}^{2}_{n-1} = \\frac{1}{n-1}\\sum_{i=1}^{n}\\bigl(X_{i}-\\bar{X}\\bigr)^{2}$：\n$$\n\\mathbb{E}[\\hat{\\sigma}^{2}_{n-1}] = \\mathbb{E}\\left[ \\frac{1}{n-1}\\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2} \\right] = \\frac{1}{n-1} \\mathbb{E}\\left[ \\sum_{i=1}^{n}(X_{i}-\\bar{X})^{2} \\right] = \\frac{1}{n-1} (n-1)\\sigma^2 = \\sigma^2\n$$\n该估计量的偏差为：\n$$\n\\mathrm{bias}(\\hat{\\sigma}^{2}_{n-1}) = \\mathbb{E}[\\hat{\\sigma}^{2}_{n-1}] - \\sigma^2 = \\sigma^2 - \\sigma^2 = 0\n$$\n这个估计量是无偏的。\n\n将分母 $n$ 替换为 $n-1$ 能消除偏差的原因与自由度有关。方差 $\\sigma^2$ 是由与真实均值 $\\mu$ 的离差平方的期望定义的。如果 $\\mu$ 已知，估计量 $\\frac{1}{n}\\sum(X_i-\\mu)^2$ 对于 $\\sigma^2$ 将是无偏的，因为它平均了 $n$ 个独立的离差平方，每个的期望都是 $\\sigma^2$。\n然而，$\\mu$ 是未知的，并由 $\\bar{X}$ 估计。样本均值具有最小化离差平方和的性质，即当 $c = \\bar{X}$ 时，$\\sum(X_i - c)^2$ 最小。这意味着对于任何样本集合，都有 $\\sum(X_i - \\bar{X})^2 \\le \\sum(X_i - \\mu)^2$。因此，使用 $\\bar{X}$ 代替 $\\mu$ 会导致平方和平均而言小于围绕真实均值的平方和。我们的计算表明 $\\mathbb{E}[\\sum(X_i - \\bar{X})^2]$ 不是 $n\\sigma^2$ 而是 $(n-1)\\sigma^2$。\n与样本均值的 $n$ 个离差集合 $\\{X_i - \\bar{X}\\}_{i=1}^n$ 并非完全独立。它们受到约束 $\\sum_{i=1}^n(X_i - \\bar{X}) = (\\sum X_i) - n\\bar{X} = n\\bar{X} - n\\bar{X} = 0$ 的影响。这个约束意味着如果知道了 $n-1$ 个离差，第 $n$ 个就完全确定了。这组离差只拥有 $n-1$ 个自由度。通过将离差平方和除以其自由度 $n-1$，我们得到了方差的无偏估计。这个校正因子，将有偏估计乘以 $\\frac{n}{n-1}$ 进行缩放，被称为贝塞尔校正 (Bessel's correction)。它解释了因使用样本均值估计总体均值而损失的一个自由度。\n\n最终结果被汇编到所要求的行矩阵中。\n$\\mathbb{E}[\\hat{\\sigma}^{2}_{n}] = \\frac{n-1}{n}\\sigma^2$\n$\\mathrm{bias}(\\hat{\\sigma}^{2}_{n}) = -\\frac{1}{n}\\sigma^2$\n$\\mathbb{E}[\\hat{\\sigma}^{2}_{n-1}] = \\sigma^2$\n$\\mathrm{bias}(\\hat{\\sigma}^{2}_{n-1}) = 0$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{n-1}{n}\\sigma^{2}  -\\frac{1}{n}\\sigma^{2}  \\sigma^{2}  0\n\\end{pmatrix}\n}\n$$", "id": "2893255"}]}