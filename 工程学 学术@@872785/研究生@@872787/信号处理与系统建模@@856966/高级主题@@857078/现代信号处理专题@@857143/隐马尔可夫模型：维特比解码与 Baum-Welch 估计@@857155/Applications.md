## 应用与跨学科连接

在前面的章节中，我们已经详细介绍了隐马尔可夫模型（HMM）的核心原理、基本假设以及用于参数估计（[Baum-Welch算法](@entry_id:273942)）和状态解码（[Viterbi算法](@entry_id:269328)）的基础算法。这些构成了HM[M理论](@entry_id:161892)的基石。然而，HMM的真正威力在于其强大的通用性和可扩展性，使其能够被应用于解决横跨众多学科领域的复杂现实世界问题。这些应用往往不是对基础模型的简单套用，而是需要根据具体问题对模型结构或算法进行精心的调整和扩展。

本章的宗旨在与展示HMM框架的这种灵活性和实用性。我们将不再重复HMM的基本定义，而是将[焦点](@entry_id:174388)放在如何将核心原理应用于多样化的情境中。通过探索一系列来自计算生物学、金融经济学、信号处理等领域的实际问题，我们将看到HMM如何作为一个强大的工具，用于揭示不可观测的潜在结构、分割[序列数据](@entry_id:636380)、以及对动态系统进行建模。此外，我们还将探讨HMM框架本身的若干重要扩展，例如处理非高斯发射、非几何状态[驻留时间](@entry_id:177781)、以及引入外部协变量等，这些扩展极大地增强了模型的表达能力，使其能够应对更加复杂和真实的数据特性。最后，我们会将HMM置于状态空间模型的更广阔背景下，通过与线性动态系统（卡尔曼滤波器）的对比，深化对其本质和定位的理解。

### [计算生物学](@entry_id:146988)与[生物信息学](@entry_id:146759)中的核心应用

HMM在[计算生物学](@entry_id:146988)领域取得了巨大的成功，这主要得益于[生物序列](@entry_id:174368)（如DNA、RNA和蛋白质）与HMM的内在结构之间的天然契合。[生物序列](@entry_id:174368)可以被看作是沿一维坐标（基因组位置或[氨基酸序列](@entry_id:163755)）展开的观测序列，而其背后隐藏的生物学功能（如基因、[启动子](@entry_id:156503)、结构域）则可以被建模为潜在的、遵循马尔可夫性质的离散状态。

#### 基因发现与模序识别

HMM最经典的应用之一是基因发现和保守模序（motif）识别。例如，在一段未注释的DNA序列中，我们希望识别出功能性的调控模序。这些模序通常具有固定的长度和位置特异性的碱基偏好。一个典型的HMM架构可以被设计用来区分“模序”区域和“背景”区域。该模型通常包含一个代表背景DNA的“背景”状态（$B$），该状态具有一个代表非功能区域碱[基组](@entry_id:160309)成的发射概率，并且有一个高概率的自转移循环（$B \to B$）以模拟任意长度的背景序列。为了模拟一个长度为$L$的模序，模型会包含一个由$L$个状态（$M_1, M_2, \dots, M_L$）组成的线性链。每个模序状态$M_i$都有其自身的位置特异性发射[概率分布](@entry_id:146404)，以捕捉在模序第$i$个位置上的碱基偏好。从$M_i$到$M_{i+1}$的转移概率被设为1，以强制保证模序的固定长度。模型通过$B \to M_1$的转移进入模序，并通过$M_L \to B$的转移返回背景区域。当面对多条独立的、未对齐的序列时，可以通过在[Baum-Welch算法](@entry_id:273942)的E步中汇集所有序列的[期望计数](@entry_id:162854)来共同训练模型参数，然后使用[Viterbi算法](@entry_id:269328)对每条序列分别进行解码，从而在所有序列中标注出模序的位置 [@problem_id:2397582]。

#### 建模分子动力学

HMM同样适用于分析动态的生物物理过程。例如，在细胞内，[信使RNA](@entry_id:262893)（mRNA）分子由分子马达沿着细胞骨架[轨道](@entry_id:137151)进行运输。这个过程可以通过显微镜追踪，表现为快速的“运动”（Run）阶段和短暂的“暂停”（Pause）阶段的交替。我们可以将这一过程建模为一个两状态的HMM，其隐藏状态为“暂停”（$P$）和“运动”（$R$）。在每个时间帧下，我们观测到的是mRNA分子的一维位移。在“暂停”状态下，平均位移为零；而在“运动”状态下，平均位移为一个非零值（$v_{\text{run}} \Delta t$）。假设位移受到热噪声和[测量误差](@entry_id:270998)的影响，其发射概率可以被建模为高斯分布。通过[Baum-Welch算法](@entry_id:273942)，我们可以从观测到的位移序列中估计出离散时间下的[状态转移矩阵](@entry_id:269075)$A$。更有意义的是，这使我们能够连接到潜在的[连续时间马尔可夫过程](@entry_id:272118)（CTMC）的物理参数。离散时间转移概率$a_{ij}$（$i \neq j$）与连续时间转移速率$k_{ij}$之间的关系为$k_{ij} = -\ln(1 - a_{ij}) / \Delta t$，其中$\Delta t$是采样间隔。因此，通过HMM分析，我们不仅可以解码出每个时刻分子最可能处于的运动状态，还能估计出驱动状态转换的基础物理化学速率 [@problem_id:2956149]。

#### 基因组分化岛识别

在群体遗传学中，研究人员关心的是物种形成过程中基因组上哪些区域受到了强烈的选择，形成了所谓的“分化岛”（genomic islands of divergence）。这些区域与基因组的“背景”区域相比，在群体间通常表现出更高的分化水平（如通过$F_{ST}$统计量衡量）和更高的绝对差异（如$d_{XY}$）。我们可以构建一个两状态HMM（状态为“背景”和“岛屿”）来自动分割整个基因组。这里，观测数据不再是单一值，而是沿基因组窗口计算出的二维[特征向量](@entry_id:151813)$[\text{F}_{ST}, d_{XY}]^T$。由于这些特征在每个状态内的[分布](@entry_id:182848)可能很复杂，单一的高斯分布可能不足以描述。一个强大的扩展是使用[高斯混合模型](@entry_id:634640)（GMM）作为HMM中每个状态的发射[分布](@entry_id:182848)，即GMM-HMM。例如，每个状态的发射概率可以是一个包含$K$个成分的二维[高斯混合模型](@entry_id:634640)。这极大地增强了模型的拟合能力。模型的训练通过适用于GMM-HMM的[Baum-Welch算法](@entry_id:273942)完成，解码则依然使用[Viterbi算法](@entry_id:269328)。训练完成后，通过比较两个状态的平均$F_{ST}$值，可以确定哪个状态代表“岛屿”（$F_{ST}$值更高的一方），从而实现对基因组分化景观的自动化、概率化注释 [@problem_id:2718633]。

#### [轨迹推断](@entry_id:176370)与[伪时间分析](@entry_id:267953)

在[单细胞基因组学](@entry_id:274871)领域，一个核心任务是从静态的细胞快照中重建连续的生物学过程，如[细胞分化](@entry_id:273644)，这个过程被称为[轨迹推断](@entry_id:176370)或[伪时间](@entry_id:262363)（pseudotime）分析。HMM为解决这类问题提供了一个自然框架。我们可以将连续的分化过程离散化为$K$个有序的[隐藏状态](@entry_id:634361)，代表从干细胞到终末分化细胞的各个阶段。每个细胞的观测数据是其高维的基因表达谱。为了确保模型学习到的是一个单向的、不可逆的生物学过程，可以对HMM的结构施加约束，构建一个“从左到右”（left-to-right）的模型。在这种模型中，状态转移只允许从当前状态$i$到自身或后续状态$j \ge i$，即转移矩阵$A$为上三角矩阵，且$p(z_1=1)=1$。这种结构保证了解码出的任何状态序列都是单调不减的，从而编码了[伪时间](@entry_id:262363)的概念。此外，由于生物过程的连续性，相邻[伪时间](@entry_id:262363)状态的平均基因表达谱应该是相似的。这种先验知识可以通过在[参数估计](@entry_id:139349)过程中引入正则化项来强制实现，例如，通过惩罚相邻状态[均值向量](@entry_id:266544)的二阶差分（$\sum_{k} \|\mu_{k+1} - 2\mu_k + \mu_{k-1}\|_2^2$）来鼓励表达谱的平滑演化 [@problem_id:2437562]。

#### 时空[转录组学](@entry_id:139549)数据分析

随着技术发展，我们现在可以在保留空间信息的同时测量基因表达，即时空[转录组学](@entry_id:139549)。当对一个生物过程（如免疫反应）进行时间序列的采样时，我们得到了一系列在不同时间点测量的、带有空间坐标的基因表达图谱。一个关键挑战是如何整合这些数据并模拟微环境（domain）随时间的演变。这可以通过一个两步流程实现：首先，利用[组织学](@entry_id:147494)上保守的“地标”（landmarks）将不同时间点的组织切片通过空间配准（spatial registration）对齐到一个共同的[坐标系](@entry_id:156346)下。这一步通常通过最小化地标点之间的几何偏差并加以正则化来求解一个仿射变换。配准后，我们可以在一个固定的空间网格上追踪每个位置的基因表达随时间的变化。然后，对于每个空间位置，我们可以构建一个独立的HMM来模拟其所属组织微环境（如生发中心亮区、暗区等）随时间的演变。由于观测数据是基因表达计数，选择合适的发射模型至关重要。负二项（Negative Binomial）[分布](@entry_id:182848)是对此类过离散计数数据的标准模型，其均值可以根据每个测点的文库大小进行调整。通过对所有空间位置的HMMs进行训练和解码，我们不仅能推断出每个位置在每个时间点的状态，还能学习到不同微环境之间演变的典型模式（即[状态转移矩阵](@entry_id:269075)$A$） [@problem_id:2890149]。

### 金融经济学中的应用

HMM在经济和金融领域同样是分析时间序列的重要工具，尤其适用于那些表现出“状态切换”行为的系统。

#### 市场状态转换模型

金融市场常常在不同“状态”（regime）之间切换，例如高波动性/熊市和低波动性/牛市。这些状态是不可直接观测的，但它们会影响资产回报率的统计特性。HMM提供了一个完美框架来建模这种状态切换行为。我们可以构建一个两状态（或多状态）HMM，其中隐藏状态代表市场所处的宏观状态。每个状态下的观测值（如每日或每周的股票指数回报率）被建模为服从该状态特有的[高斯分布](@entry_id:154414)，即$\mathcal{N}(\mu_i, \sigma_i^2)$，其中状态$i$对应着特定的均值$\mu_i$和[方差](@entry_id:200758)$\sigma_i^2$。通过对历史回报率序列应用[Baum-Welch算法](@entry_id:273942)，我们可以从数据中最大似然地估计出模型的全部参数：初始状态概率、[状态转移矩阵](@entry_id:269075)以及每个状态下回报率[分布](@entry_id:182848)的均值和[方差](@entry_id:200758)。完成训练后，[Viterbi算法](@entry_id:269328)可以解码出最有可能的隐藏状态序列，从而为整个历史时期提供一个关于市场状态的概率化叙事。例如，通过比较估计出的[方差](@entry_id:200758)，我们可以将具有较大$\sigma_i^2$的状态标记为“高波动性”状态，从而识别出历史上的市场动荡期 [@problem_id:2388979]。

在实现这类模型时，[Baum-Welch算法](@entry_id:273942)的[M步](@entry_id:178892)更新规则具有非常直观的形式。例如，对于多元高斯发射[分布](@entry_id:182848)，其[均值向量](@entry_id:266544)$\boldsymbol{\mu}_i$和协方差矩阵$\boldsymbol{\Sigma}_i$的更新公式可以被推导出来。新的均值$\boldsymbol{\mu}_i^{\text{new}}$是所有观测向量$\boldsymbol{x}_t$的加权平均，权重为该观测在$t$时刻由状态$i$生成的后验概率$\gamma_t(i)$。同样，新的协方差矩阵$\boldsymbol{\Sigma}_i^{\text{new}}$是加权样本协[方差](@entry_id:200758)。这与标准的最大似然估计形式一致，只不过每个数据点被其属于该状态的“软”概率所加权 [@problem_id:2875803]。

### HMM框架的扩展与进阶

标准HMM的假设（如几何状态[驻留时间](@entry_id:177781)、观测独立性）虽然简化了计算，但在许多现实应用中可能过于严格。幸运的是，HMM框架具有高度的可扩展性，可以通过多种方式进行推广，以适应更复杂的数据和系统行为。

#### 对复杂发射[分布](@entry_id:182848)建模：GMM-HMM

标准HMM通常假设每个状态的发射概率服从一个简单的参数[分布](@entry_id:182848)（如[高斯分布](@entry_id:154414)或多项式[分布](@entry_id:182848)）。然而，在某些应用中，一个状态内的数据[分布](@entry_id:182848)可能更为复杂，呈现多峰或非对称形态。为了解决这个问题，我们可以将每个状态$i$的发射[分布](@entry_id:182848)$p(\boldsymbol{x}_t | z_t=i)$本身建模为一个[高斯混合模型](@entry_id:634640)（GMM）。这样的模型被称为高斯混合隐马尔可夫模型（GMM-HMM）。

在GMM-HMM中，参数估计变得更加复杂，形成一个“嵌套”的EM结构。在E步中，我们不仅要计算每个时刻$t$处于状态$i$的后验概率$\gamma_i(t)$，还需要进一步计算在该状态下，观测$\boldsymbol{x}_t$是由GMM中第$m$个高斯成分生成的[后验概率](@entry_id:153467)。这个联合[后验概率](@entry_id:153467)$\xi_{im}(t) = p(z_t=i, M_t=m | \boldsymbol{x}_{1:T})$（其中$M_t$是混合成分的[指示变量](@entry_id:266428)）可以被分解为$\gamma_i(t)$与成分责任度的乘积。在[M步](@entry_id:178892)中，状态$i$内部的GMM参数（混合权重、均值、协[方差](@entry_id:200758)）的更新，就变成了对一个标准GMM的加权最大似然估计，其中每个数据点$\boldsymbol{x}_t$的权重是$\xi_{im}(t)$。这种扩展极大地增强了HMM对复杂连续观测的建模能力，在语音识别和我们之前提到的基因组学应用中都至关重要 [@problem_id:2875863] [@problem_id:2718633]。

#### 放宽观测独立性假设：AR-HMM

标准HMM的一个核心假设是：在给定当前[隐藏状态](@entry_id:634361)$z_t$的条件下，当前观测$\boldsymbol{x}_t$与其他所有观测都是独立的。这个假设在许多动态系统中并不成立，因为观测本身可能具有“惯性”或[自相关](@entry_id:138991)性。例如，一个移动物体的位置不仅取决于其当前的运动状态（如“加速”或“匀速”），还取决于它前一刻的位置。

自回归[隐马尔可夫模型](@entry_id:141989)（Autoregressive HMM, AR-HMM）正是为了处理这种情况而设计的。在AR-HMM中，发射概率被修改为同时条件于当前状态$z_t$和过去的$p$个观测值$\boldsymbol{x}_{t-1}, \dots, \boldsymbol{x}_{t-p}$。对于[线性高斯系统](@entry_id:200183)，这通常被建模为$p(\boldsymbol{x}_t | z_t=k, \boldsymbol{x}_{t-1:t-p}) = \mathcal{N}(\boldsymbol{x}_t; \mathbf{A}_k \boldsymbol{\phi}_t, \mathbf{R}_k)$，其中$\boldsymbol{\phi}_t$是过去观测的拼接向量，$\mathbf{A}_k$是状态$k$特有的自[回归系数](@entry_id:634860)矩阵。尽管这个改动破坏了严格的观测独立性，但HMM的动态规划算法（Viterbi和Baum-Welch）的结构依然有效。关键在于，发射概率虽然依赖于过去的观测，但这些观测在计算$t$时刻的概率时是已知的，因此发射概率$b_k(t)$可以被看作是时间依赖的。于是，我们可以在一个时间不均匀的HMM上运行标准的[前向-后向算法](@entry_id:194772)。[M步](@entry_id:178892)的更新也相应改变：转移概率的更新不变，而自回归参数$\mathbf{A}_k$和噪声协[方差](@entry_id:200758)$\mathbf{R}_k$的更新则变成一个加权[最小二乘问题](@entry_id:164198)，权重同样由E步计算出的状态[后验概率](@entry_id:153467)$\gamma_t(k)$给出 [@problem_id:2875836]。

#### 引入外部信息：协变量依赖的HMM

在许多系统中，状态的演化不仅受其内部[马尔可夫动力学](@entry_id:202369)的影响，还可能受到外部随时间变化的因素（[协变](@entry_id:634097)量）的驱动。例如，[交通流](@entry_id:165354)量的状态转换可能取决于天气和一天中的时间；一个人的情绪状态转换可能受到社交互动的影响。

为了将这些外部信息整合到模型中，我们可以让HMM的参数（如转移概率）成为[协变](@entry_id:634097)量的函数。例如，我们可以使用一个[广义线性模型](@entry_id:171019)（GLM），如[多项式逻辑回归](@entry_id:275878)，来对转移概率进行[参数化](@entry_id:272587)。对于从状态$i$出发的转移，其到各个目标状态$j$的概率可以由一个与[协变](@entry_id:634097)量向量$\mathbf{z}_t$相关的线性函数通过softmax变换得到，即$A_{ij}$变为$A_{ij}(\mathbf{z}_t)$。这种模型使得HMM成为时间非均匀的。尽管如此，E步的[前向-后向算法](@entry_id:194772)依然适用，只不过在每一步递推中都必须使用由当前[协变](@entry_id:634097)量$\mathbf{z}_t$计算出的特定于该时刻的转移矩阵$A(t)$。然而，[M步](@entry_id:178892)发生了显著变化。由于参数（GLM的系数）与转移概率之间存在非[线性关系](@entry_id:267880)（如logistic函数），[M步](@entry_id:178892)通常不再有闭合解。取而代之的是，它变成了一个需要通过迭代[优化算法](@entry_id:147840)（如[迭代重加权最小二乘法](@entry_id:175255)IRLS或梯度下降）求解的加权GLM拟合问题。类似地，发射概率也可以依赖于另一组协变量$\mathbf{x}_t$ [@problem_id:2875837]。

#### 建模非几何状态[驻留时间](@entry_id:177781)：HSMM与状态扩展

标准HMM的另一个内在限制源于其一阶马尔可夫假设：系统在任何状态$i$的[驻留时间](@entry_id:177781)（dwell time）——即在转移到另一个状态之前连续处于状态$i$的时间步数——必然服从[几何分布](@entry_id:154371)，其[概率质量函数](@entry_id:265484)为$p(D_i=d) = (1-a_{ii})a_{ii}^{d-1}$。这个[分布](@entry_id:182848)是无记忆的，意味着它在$d=1$处达到峰值，然后单调递减。然而，在许多现实应用中，状态的持续时间有其自身的典型尺度，其[分布](@entry_id:182848)可能在某个大于1的值处出现峰值（例如，一个喷嚏的持续时间通常不会只有一个采样点长）。

为了克服这一限制，隐半马尔可夫模型（Hidden Semi-Markov Model, HSMM）被提出。HSMM显式地为每个状态$i$引入一个[驻留时间](@entry_id:177781)[分布](@entry_id:182848)$p_i(d)$，该[分布](@entry_id:182848)可以是任意的（如泊松、高斯或非参数[分布](@entry_id:182848)）。在HSMM中，当系统进入状态$i$时，它首先从$p_i(d)$中抽取一个持续时间$d$，然后保持在状态$i$并产生$d$个观测值，之后再根据一个（不依赖于自转移的）[转移矩阵](@entry_id:145510)转换到下一个状态。HSMM的推理算法是Viterbi和[Baum-Welch算法](@entry_id:273942)的推广，它们需要在递推中额外对所有可能的[驻留时间](@entry_id:177781)进行最大化或求和，这通常会增加计算复杂度。

一个在实践中非常有用且巧妙的替代方法是在标准HMM框架内近似非几何[驻留时间](@entry_id:177781)，即状态扩展。我们可以将一个具有复杂[驻留时间](@entry_id:177781)的状态$i$替换为一个由$m$个子状态$i_1, i_2, \dots, i_m$组成的从左到右的线性链。系统必须依次通过这$m$个子状态才能“完成”一次在宏观状态$i$的驻留。通过允许在每个子状态上有自转移循环，总的[驻留时间](@entry_id:177781)（即穿过整个链的时间）可以服从更灵活的[分布](@entry_id:182848)，如[负二项分布](@entry_id:262151)，它可以模拟出在$d1$处有峰值的[驻留时间](@entry_id:177781)。这种扩展模型的总状态数增加了，但它仍然是一个标准的HMM，因此可以直接应用Viterbi和[Baum-Welch算法](@entry_id:273942)进行推理和学习，而无需开发新的算法 [@problem_id:2875800]。

### 实践考量与贝叶斯视角

#### [半监督学习](@entry_id:636420)

在许多实际场景中，获取大量未标记的[序列数据](@entry_id:636380)相对容易，而对数据进行精确的逐点标记（即确定每个时刻的[隐藏状态](@entry_id:634361)）则成本高昂。这导致了[半监督学习](@entry_id:636420)（semi-supervised learning）的场景：我们拥有一部分带有“硬”标签的已知状态序列和大量未标记数据。HMM框架可以优雅地处理这种情况。在[Baum-Welch算法](@entry_id:273942)的E步中，这些已知的标签可以被视为对状态[后验概率](@entry_id:153467)的硬性约束。具体来说，我们可以通过一个掩码（mask）来修改[前向-后向算法](@entry_id:194772)。在已知标签的时刻$t$，只有被标记的状态$y_t$的概率为1，其他状态的概率被强制为0。在未标记的时刻，算法则照常计算所有状态的[后验概率](@entry_id:153467)。这样，模型在学习过程中能够充分利用来自少量标签的强监督信号，并将其传播到广阔的未标记数据中，从而获得比纯[无监督学习](@entry_id:160566)更准确的[参数估计](@entry_id:139349) [@problem_id:2875862]。

#### [贝叶斯估计](@entry_id:137133)与正则化

当数据稀疏时，[最大似然估计](@entry_id:142509)（MLE）可能会导致[过拟合](@entry_id:139093)。例如，如果某个状态转移从未在训练数据中出现，其MLE概率将为0，这可能不符合真实情况。贝叶斯方法通过引入参数的[先验分布](@entry_id:141376)来解决这个问题，从而实现正则化。对于HMM中的多项式[分布](@entry_id:182848)参数（即[转移矩阵](@entry_id:145510)的行和发射[概率向量](@entry_id:200434)），其[共轭先验](@entry_id:262304)是狄利克雷（Dirichlet）[分布](@entry_id:182848)。在[M步](@entry_id:178892)中最大化后验概率（[MAP估计](@entry_id:751667)）而不是似然函数，其效果非常直观：它等价于在E步计算出的[期望计数](@entry_id:162854)上加上一些“伪计数”（pseudocounts）。伪计数值由狄利克雷先验的超参数决定。例如，对于转移概率$A_{ij}$，其[MAP估计](@entry_id:751667)为$\hat{A}_{ij} = \frac{n_{ij} + \alpha_{ij}-1}{\sum_k (n_{ik} + \alpha_{ik}-1)}$，其中$n_{ij}$是期望转移计数，$\alpha_{ij}$是先验超参数。当所有$\alpha_{ij}1$时，这起到了平滑作用，保证了所有概率非零。当所有$\alpha_{ij}=1$时（均匀先验），[MAP估计](@entry_id:751667)退化为MLE。而当$0 \lt \alpha_{ij} \lt 1$时，则会鼓励[稀疏性](@entry_id:136793)，即将较小的概率推向0。这种贝叶斯方法为模型引入了有意义的先验知识，并提高了其在小样本或[稀疏数据](@entry_id:636194)条件下的鲁棒性 [@problem_id:2875788]。

### HMM在状态空间模型中的定位

最后，将HMM置于更广阔的统计模型家族中进行审视，有助于我们更深刻地理解其本质。HMM是[状态空间模型](@entry_id:137993)（State-Space Model, SSM）大家族中的一员，其核心特征是拥有一个离散的、不可观测的[隐藏状态](@entry_id:634361)变量。与之形成鲜明对比和深刻联系的是另一类重要的[状态空间模型](@entry_id:137993)——线性动态系统（Linear Dynamical System, LDS），其隐藏状态是连续的（通常是多维实数向量）。LDS的演化和观测过程均被建模为[线性变换](@entry_id:149133)加上高斯噪声，其推理算法就是著名的[卡尔曼滤波器](@entry_id:145240)（Kalman Filter）。

HMM和LDS/卡尔曼滤波器之间存在着优美的对偶关系：
- **潜在状态**：HMM是离散的，LDS是连续的。
- **动态模型**：HMM的状态转移由一个随机矩阵描述；LDS的状态演化由一个[线性变换矩阵](@entry_id:186379)加上高斯过程噪声描述。
- **推理算法**：
    - **滤波（Filtering）**（推断当前状态）：HMM使用[前向算法](@entry_id:165467)；LDS使用[卡尔曼滤波器](@entry_id:145240)。两者都是在线的、递归的。
    - **平滑（Smoothing）**（利用全部数据推断过去状态）：HMM使用[前向-后向算法](@entry_id:194772)；LDS使用Rauch-Tung-Striebel (RTS)[平滑器](@entry_id:636528)。两者都是两遍（前向和后向）算法。
    - **最可能路径解码**：HMM使用[Viterbi算法](@entry_id:269328)，在[离散状态空间](@entry_id:146672)上进行动态规划搜索；对于LDS，由于后验是高斯的，其均值与众数重合，因此最可能的路径就是[后验均值](@entry_id:173826)路径，可由[RTS平滑器](@entry_id:142379)直接算出。
- **参数学习**：在参数未知时，两者都可以使用[期望最大化](@entry_id:273892)（EM）算法进行学习。对于HMM，这就是[Baum-Welch算法](@entry_id:273942)。对于LDS，E步由[卡尔曼平滑器](@entry_id:143392)完成，计算所需的期望统计量（如$\mathbb{E}[\boldsymbol{x}_t]$，$\mathbb{E}[\boldsymbol{x}_t \boldsymbol{x}_t^\top]$），[M步](@entry_id:178892)则变为求解回归问题的闭合解。

理解这种对偶性，不仅让我们看到了处理离散和连续潜在变量的统一视角，也凸显了HMM在建模具有内在“类别”或“模式”切换的系统时的独特优势 [@problem_id:2875786]。