## 引言
隐马尔可夫模型（Hidden Markov Model, HMM）是用于分析和建模序列数据的最强大的统计工具之一，尤其适用于那些由不可观测的潜在状态[序列生成](@entry_id:635570)可观测输出的系统。从语音识别到基因组注释，再到金融市场分析，HMM提供了一个统一的框架来揭示[时间序列数据](@entry_id:262935)背后的动态结构。然而，有效应用HMM的前提是深刻理解其数学原理、核心假设以及解决其基本问题的三大经典算法。本文旨在系统性地解决这一知识需求，为读者提供一个从理论到实践的全面指南。

本文将分为三个核心章节，引领读者逐步深入HMM的世界。在“原理与机制”一章中，我们将建立HMM的形式化数学基础，详细推导解决评估、解码和学习问题的[前向-后向算法](@entry_id:194772)、[维特比算法](@entry_id:269328)和[鲍姆-韦尔奇算法](@entry_id:273942)，并讨论数值稳定性和[模型可辨识性](@entry_id:186414)等关键实践问题。接下来，在“应用与跨学科连接”一章中，我们将展示HMM如何通过各种扩展（如GMM-HMM、AR-HMM）被应用于[计算生物学](@entry_id:146988)、金融经济学等前沿领域，解决基因发现、市场状态切换等真实挑战。最后，通过一系列精心设计的“动手实践”，读者将有机会亲手计算和实现这些算法，从而将理论知识转化为解决问题的具体技能。

## 原理与机制

本章深入探讨[隐马尔可夫模型](@entry_id:141989)（Hidden Markov Model, HMM）的核心原理与关键机制。我们将从其基本定义和数学假设出发，系统性地推导解决其三大核心问题——评估（Evaluation）、解码（Decoding）和学习（Learning）——的经典算法。这些算法构成了HMM在实践中应用的基础。

### [隐马尔可夫模型](@entry_id:141989)的形式化定义

隐马尔可夫模型是一个双重[随机过程](@entry_id:159502)，由一个不可观测的（“隐”）马尔可夫链和一组与该链的状态相关的随机观测组成。一个形式化的HMM由以下五个元素定义，通常表示为元组 $\lambda = (\mathcal{S}, \mathcal{X}, \pi, A, B)$：

1.  **状态空间** $\mathcal{S}$：一个包含 $N$ 个离散隐状态的集合，$\mathcal{S} = \{1, 2, \dots, N\}$。系统在任意时刻 $t$ 的真实状态 $s_t$ 属于此集合，但无法被直接观测。

2.  **观测空间** $\mathcal{X}$：一个包含所有可能观测值的集合。它可以是离散的符号字母表，也可以是连续的[向量空间](@entry_id:151108)。在时刻 $t$ 的观测值 $x_t$ 属于此集合。

3.  **初始状态[分布](@entry_id:182848)** $\pi$：一个维度为 $N$ 的向量，其中元素 $\pi_i = p(s_1=i)$ 表示系统在初始时刻 $t=1$ 处于状态 $i$ 的概率。它必须满足 $\sum_{i=1}^N \pi_i = 1$。

4.  **[状态转移矩阵](@entry_id:269075)** $A$：一个 $N \times N$ 的矩阵，其中元素 $a_{ij} = p(s_t=j \mid s_{t-1}=i)$ 表示系统在时刻 $t-1$ 处于状态 $i$ 的条件下，在时刻 $t$ 转移到状态 $j$ 的概率。该矩阵必须是行随机的，即对所有 $i$，满足 $\sum_{j=1}^N a_{ij} = 1$。

5.  **发射模型** $B$：描述了在给定隐状态下生成特定观测的概率。对于离散观测，它通常是一个 $N \times M$ 的矩阵（其中 $M$ 是观测符号的数量），元素 $b_j(v_k) = p(x_t=v_k \mid s_t=j)$ 表示在状态 $j$ 下观测到符号 $v_k$ 的概率。对于连续观测，它通常是一组[概率密度函数](@entry_id:140610)，如 $b_j(x) = p(x_t=x \mid s_t=j)$，例如高斯分布。

HMM的强大之处在于其简化的假设结构，这使得原本复杂的[联合概率分布](@entry_id:171550)得以高效计算。其核心是两个**[条件独立性](@entry_id:262650)假设** [@problem_id:2875807] [@problem_id:2875860]：

1.  **一阶马尔可夫性（First-Order Markov Property）**：任意时刻 $t$ 的隐状态 $s_t$ 只依赖于其前一时刻的状态 $s_{t-1}$，而与更早的[状态和](@entry_id:193625)所有历史观测均条件独立。数学上，对于 $t \in \{2, \dots, T\}$：
    $$p(s_t \mid s_{1:t-1}, x_{1:t-1}) = p(s_t \mid s_{t-1})$$
    其中 $s_{1:t-1}$ 表示状态序列 $(s_1, \dots, s_{t-1})$。

2.  **观测独立性（Observation Independence Property）**：任意时刻 $t$ 的观测 $x_t$ 只依赖于当前时刻的隐状态 $s_t$，而与所有其他时刻的[状态和](@entry_id:193625)观测均条件独立。数学上，对于 $t \in \{1, \dots, T\}$：
    $$p(x_t \mid s_{1:T}, x_{1:t-1}) = p(x_t \mid s_t)$$
    值得强调的是，正是这一假设，而非马尔可夫性假设，保证了发射概率可以简化为仅依赖于当前状态的形式，这对于后续动态规划算法的有效性至关重要 [@problem_id:2875860]。

基于这两个假设，一个完整的状态序列 $s_{1:T}$ 和观测序列 $x_{1:T}$ 的**[联合概率分布](@entry_id:171550)**可以被优雅地分解为：
$$p(x_{1:T}, s_{1:T}) = p(s_1) p(x_1 \mid s_1) \prod_{t=2}^{T} p(s_t \mid s_{t-1}) p(x_t \mid s_t)$$
使用我们定义的参数，这个表达式变为：
$$p(x_{1:T}, s_{1:T}) = \pi_{s_1} b_{s_1}(x_1) \prod_{t=2}^{T} a_{s_{t-1}, s_t} b_{s_t}(x_t)$$
这个分解式是所有HMM算法的基石。

### HMM的三大核心问题

在实际应用中，我们通常围绕HMM解决三个核心问题：

1.  **评估（Evaluation）**：给定模型 $\lambda$ 和一个观测序列 $x_{1:T}$，计算该观测序列出现的概率 $p(x_{1:T} \mid \lambda)$。这个问题对于[模型选择](@entry_id:155601)和[分类任务](@entry_id:635433)至关重要。

2.  **解码（Decoding）**：给定模型 $\lambda$ 和一个观测序列 $x_{1:T}$，找到最有可能产生该观测序列的隐状态序列 $s^*_{1:T}$。这在序列标注任务（如词性标注）中非常有用。
    $$s^*_{1:T} = \arg\max_{s_{1:T}} p(s_{1:T} \mid x_{1:T}, \lambda) = \arg\max_{s_{1:T}} p(s_{1:T}, x_{1:T} \mid \lambda)$$

3.  **学习（Learning）**：给定一个或多个观测序列，调整模型参数 $\lambda = (\pi, A, B)$，使得这些观测序列出现的概率最大化。这是最困难的问题，通常使用[Baum-Welch算法](@entry_id:273942)解决。

### 评估问题：[前向-后向算法](@entry_id:194772)

直接计算 $p(x_{1:T} \mid \lambda) = \sum_{s_{1:T}} p(x_{1:T}, s_{1:T} \mid \lambda)$ 需要对所有 $N^T$ 种可能的状态序列求和，计算复杂度是指数级的，对于较长的序列是不可行的。幸运的是，我们可以利用HMM的结构，通过动态规划高效地解决此问题。

#### [前向算法](@entry_id:165467)

[前向算法](@entry_id:165467)的核心是定义**前向变量** $\alpha_t(i)$，它表示在时刻 $t$ 观测到序列 $x_{1:t}$ 且系统处于状态 $i$ 的[联合概率](@entry_id:266356)：
$$\alpha_t(i) = p(x_{1:t}, s_t=i)$$

我们可以从一阶原理推导出 $\alpha_t(i)$ 的递归关系 [@problem_id:2875809]。

-   **初始化 ($t=1$)**：
    根据定义，$\alpha_1(i) = p(x_1, s_1=i)$。利用概率链式法则，我们得到：
    $$\alpha_1(i) = p(x_1 \mid s_1=i) p(s_1=i) = \pi_i b_i(x_1)$$

-   **递归 ($t=2, \dots, T$)**：
    我们希望用 $\alpha_{t-1}(\cdot)$ 来表示 $\alpha_t(i)$。首先，引入 $s_{t-1}$ 并对其进行边缘化：
    $$
    \begin{align*}
    \alpha_t(i)  &= p(x_{1:t}, s_t=i) \\
     &= \sum_{j=1}^{N} p(x_{1:t}, s_{t-1}=j, s_t=i) \\
     &= \sum_{j=1}^{N} p(x_t \mid x_{1:t-1}, s_{t-1}=j, s_t=i) p(x_{1:t-1}, s_{t-1}=j, s_t=i)
    \end{align*}
    $$
    应用观测独立性假设，$p(x_t \mid \dots) = p(x_t \mid s_t=i) = b_i(x_t)$。同时，对第二项应用[链式法则](@entry_id:190743)：
    $$
    \begin{align*}
    \alpha_t(i)  &= b_i(x_t) \sum_{j=1}^{N} p(s_t=i \mid x_{1:t-1}, s_{t-1}=j) p(x_{1:t-1}, s_{t-1}=j)
    \end{align*}
    $$
    应用马尔可夫性假设，$p(s_t=i \mid \dots) = p(s_t=i \mid s_{t-1}=j) = a_{ji}$。第二项正是前向变量的定义 $\alpha_{t-1}(j)$。于是得到递归式：
    $$\alpha_t(i) = \left( \sum_{j=1}^{N} \alpha_{t-1}(j) a_{ji} \right) b_i(x_t)$$

-   **终止**：
    当计算出所有 $\alpha_T(i)$ 后，整个观测序列的概率就是将这些值在所有可能的最终状态上求和：
    $$p(x_{1:T}) = \sum_{i=1}^{N} p(x_{1:T}, s_T=i) = \sum_{i=1}^{N} \alpha_T(i)$$

通过这种方式，每一步的计算量为 $O(N^2)$，总的计算复杂度为 $O(N^2 T)$，远低于[指数复杂度](@entry_id:270528)。例如，对于一个具体的HMM模型和观测序列，我们可以逐步计算出每个时刻的 $\alpha$ 向量，并最终求和得到序列的总概率 [@problem_id:2875809]。

#### 后向算法

与[前向算法](@entry_id:165467)类似，我们定义**后向变量** $\beta_t(i)$，它表示在时刻 $t$ 系统处于状态 $i$ 的条件下，观测到未来序列 $x_{t+1:T}$ 的条件概率：
$$\beta_t(i) = p(x_{t+1:T} \mid s_t=i)$$
后向变量的递归关系可以类似地推导出来 [@problem_id:2875830]。

-   **初始化 ($t=T$)**：
    根据定义，$\beta_T(i) = p(x_{T+1:T} \mid s_T=i)$。由于未来观测序列为空，其概率按惯例定义为1：
    $$\beta_T(i) = 1 \quad \forall i$$

-   **递归 ($t=T-1, \dots, 1$)**：
    我们从 $\beta_{t+1}(\cdot)$ 推导 $\beta_t(i)$。引入 $s_{t+1}$ 并边缘化：
    $$
    \begin{align*}
    \beta_t(i)  &= p(x_{t+1:T} \mid s_t=i) \\
     &= \sum_{j=1}^{N} p(x_{t+1:T}, s_{t+1}=j \mid s_t=i) \\
     &= \sum_{j=1}^{N} p(x_{t+2:T} \mid s_{t+1}=j, s_t=i, x_{t+1}) p(x_{t+1} \mid s_{t+1}=j, s_t=i) p(s_{t+1}=j \mid s_t=i)
    \end{align*}
    $$
    应用HMM的独立性假设，上式简化为：
    $$
    \begin{align*}
    \beta_t(i)  &= \sum_{j=1}^{N} p(x_{t+2:T} \mid s_{t+1}=j) p(x_{t+1} \mid s_{t+1}=j) p(s_{t+1}=j \mid s_t=i) \\
     &= \sum_{j=1}^{N} \beta_{t+1}(j) b_j(x_{t+1}) a_{ij}
    \end{align*}
    $$
    所以递归式为：
    $$\beta_t(i) = \sum_{j=1}^{N} a_{ij} b_j(x_{t+1}) \beta_{t+1}(j)$$

虽然单独使用后向算法也可以计算总概率（$p(x_{1:T}) = \sum_i \pi_i b_i(x_1) \beta_1(i)$），但它的主要用途是与[前向算法](@entry_id:165467)结合，为学习算法提供必要的中间量。例如，我们可以证明，在任意时刻 $t$，总概率可以表示为 [@problem_id:2875830]：
$$p(x_{1:T}) = \sum_{i=1}^{N} \alpha_t(i) \beta_t(i)$$

### [解码问题](@entry_id:264478)：[维特比算法](@entry_id:269328)

[解码问题](@entry_id:264478)旨在找到最优的隐状态序列。[维特比算法](@entry_id:269328)（Viterbi Algorithm）同样采用动态规划来解决这个问题，其结构与[前向算法](@entry_id:165467)非常相似，只是将求和操作替换为求最大值操作。

我们定义**维特比变量** $\delta_t(i)$ 为在时刻 $t$ 观测到序列 $x_{1:t}$、系统处于状态 $i$、并且到目前为止的路径是所有可能路径中概率最大的那条路径的概率 [@problem_id:2875781]。
$$\delta_t(i) = \max_{s_{1:t-1}} p(s_{1:t-1}, s_t=i, x_{1:t})$$
为了能够回溯找到最优路径，我们还定义一个**回溯指针** $\psi_t(i)$，它记录了在时刻 $t-1$ 是哪个状态导致了 $\delta_t(i)$ 的最大值。

-   **初始化 ($t=1$)**：
    $$\delta_1(i) = \pi_i b_i(x_1)$$
    $$\psi_1(i) = 0 \quad (\text{或任意标记})$$

-   **递归 ($t=2, \dots, T$)**：
    $\delta_t(i)$ 可以从前一时刻的所有 $\delta_{t-1}(j)$ 转移而来。对于每个可能的上一状态 $j$，路径延伸到当前状态 $i$ 的概率是 $\delta_{t-1}(j) \cdot a_{ji} \cdot b_i(x_t)$。我们选择其中最大的一个：
    $$\delta_t(i) = \left( \max_{j=1, \dots, N} \delta_{t-1}(j) a_{ji} \right) b_i(x_t)$$
    $$\psi_t(i) = \arg\max_{j=1, \dots, N} (\delta_{t-1}(j) a_{ji})$$

-   **终止与回溯**：
    在时刻 $T$，最优路径的概率是 $P^* = \max_{i=1, \dots, N} \delta_T(i)$。
    最优路径的最后一个状态是 $s^*_T = \arg\max_{i=1, \dots, N} \delta_T(i)$。
    然后，我们可以通过回溯指针反向追踪最优路径：
    $$s^*_{t-1} = \psi_t(s^*_t) \quad \text{for } t=T, T-1, \dots, 2$$

#### [维特比算法](@entry_id:269328)的图论视角

[维特比算法](@entry_id:269328)可以被直观地理解为一个在**格状图（Trellis Graph）**上寻找最短路径的问题 [@problem_id:2875811]。这个图是一个有向无环图（DAG），它有 $T$ 层，每层有 $N$ 个节点，代表每个时刻的每个可能状态。

-   **节点**：节点 $(i, t)$ 代表在时刻 $t$ 处于状态 $i$。此外还有一个源节点和一个汇节点。
-   **边和权重**：从节点 $(j, t-1)$ 到 $(i, t)$ 的边表示一次状态转移。为了将最大化概率的乘积问题转化为最小化路径成本的求和问题，我们使用负对数概率作为边的权重。
    -   从源节点到 $(i, 1)$ 的边的权重为 $-\ln(\pi_i) - \ln(b_i(x_1))$。
    -   从 $(j, t-1)$ 到 $(i, t)$ 的边的权重为 $-\ln(a_{ji}) - \ln(b_i(x_t))$。
-   **最短路径**：从源节点到汇节点的最短路径就对应着[维特比路径](@entry_id:271181)（最优状态序列），路径的总成本等于该路径的负对数[联合概率](@entry_id:266356)。

在这个图上，维特bi算法等价于一个按拓扑序（逐层）计算最短路径的动态规划算法。其[时间复杂度](@entry_id:145062)为 $O(|V|+|E|)$，其中 $|V|$ 是节点数，$|E|$ 是边数。对于一个全连接的HMM，边数约为 $(T-1)N^2$，因此[时间复杂度](@entry_id:145062)为 $O(TN^2)$。如果转移矩阵是稀疏的，每个状态平均只有 $d$ 个[出度](@entry_id:263181)，那么复杂度可以降至 $O(TNd)$。算法需要存储所有回溯指针，因此[空间复杂度](@entry_id:136795)为 $O(TN)$。

### 学习问题：[Baum-Welch算法](@entry_id:273942)

学习问题是最具挑战性的，因为它涉及到一个含有[隐变量](@entry_id:150146)（状态序列）的[最大似然估计](@entry_id:142509)问题。[Baum-Welch算法](@entry_id:273942)是解决此问题的经典方法，它本质上是[期望最大化](@entry_id:273892)（Expectation-Maximization, EM）算法在HMM上的一个特例。

[EM算法](@entry_id:274778)通过迭代的方式来寻找参数的最大似然估计。每一次迭代包含两个步骤：

-   **E-步（Expectation）**：给定当前的[参数估计](@entry_id:139349) $\theta^{\text{old}}$，计算完整数据[对数似然函数](@entry_id:168593)关于[隐变量](@entry_id:150146)[后验分布](@entry_id:145605)的期望。这个期望函数被称为辅助函数 $\mathcal{Q}(\theta, \theta^{\text{old}})$。
-   **M-步（Maximization）**：最大化辅助函数 $\mathcal{Q}$，以获得新的[参数估计](@entry_id:139349) $\theta^{\text{new}}$。

#### E-步：计算期望

首先，完整数据 $(x_{1:T}, s_{1:T})$ 的[对数似然函数](@entry_id:168593)为：
$$\ln p(x_{1:T}, s_{1:T} \mid \theta) = \ln \pi_{s_1} + \sum_{t=2}^{T} \ln a_{s_{t-1}, s_t} + \sum_{t=1}^{T} \ln b_{s_t}(x_t)$$

$\mathcal{Q}$ 函数是这个表达式在后验分布 $p(s_{1:T} \mid x_{1:T}, \theta^{\text{old}})$ 下的期望 [@problem_id:2875799] [@problem_id:2875827]。通过利用[期望的线性](@entry_id:273513)性质，$\mathcal{Q}$ 函数可以分解为三部分，分别对应 $\pi, A, B$：
$$
\begin{align*}
\mathcal{Q}(\theta, \theta^{\text{old}}) =  \sum_{i=1}^N \mathbb{E}[\mathbb{I}\{s_1=i\}] \ln \pi_i \\
 + \sum_{t=2}^T \sum_{i=1}^N \sum_{j=1}^N \mathbb{E}[\mathbb{I}\{s_{t-1}=i, s_t=j\}] \ln A_{ij} \\
 + \sum_{t=1}^T \sum_{i=1}^N \mathbb{E}[\mathbb{I}\{s_t=i\}] \ln p(x_t \mid s_t=i; \phi_i)
\end{align*}
$$
其中 $\mathbb{I}\{\cdot\}$ 是指示函数。这里的期望是计算在给定观测序列 $x_{1:T}$ 和旧参数 $\theta^{\text{old}}$ 的条件下的。这些期望正是我们需要的“软计数”（soft counts）：

-   $\gamma_t(i) = p(s_t=i \mid x_{1:T}, \theta^{\text{old}})$：在时刻 $t$ 处于状态 $i$ 的[后验概率](@entry_id:153467)。
-   $\xi_t(i,j) = p(s_t=i, s_{t+1}=j \mid x_{1:T}, \theta^{\text{old}})$：在时刻 $t$ 从状态 $i$ 转移到状态 $j$ 的后验概率。

这些后验概率可以使用前向变量 $\alpha_t(i)$ 和后向变量 $\beta_t(i)$ 高效计算：
$$\gamma_t(i) = \frac{\alpha_t(i) \beta_t(i)}{p(x_{1:T})} = \frac{\alpha_t(i) \beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}$$
$$\xi_t(i,j) = \frac{\alpha_t(i) a_{ij} b_j(x_{t+1}) \beta_{t+1}(j)}{p(x_{1:T})}$$

因此，E-步的核心任务就是运行前向和后向算法，然后利用它们的输出来计算所有时刻的 $\gamma_t(i)$ 和 $\xi_t(i,j)$。

#### M-步：最大化期望

在M-步中，我们固定 $\gamma_t(i)$ 和 $\xi_t(i,j)$，然后最大化 $\mathcal{Q}(\theta, \theta^{\text{old}})$ 函数以更新参数 $\theta = (\pi, A, B)$。由于 $\pi, A, B$ 的项在 $\mathcal{Q}$ 函数中是分离的，我们可以独立地对它们进行最大化，同时要满足概率的归一化约束。使用拉格朗日乘子法可以推导出更新公式 [@problem_id:2875833]。

-   **更新初始[分布](@entry_id:182848) $\pi$**：
    $$\pi_i^{\text{new}} = \frac{\gamma_1(i)}{\sum_{j=1}^{N} \gamma_1(j)} = \gamma_1(i)$$
    这可以解释为模型在时刻1处于状态 $i$ 的期望次数（这里只有一次）。

-   **更新转移矩阵 $A$**：
    $$A_{ij}^{\text{new}} = \frac{\sum_{t=1}^{T-1} \xi_t(i,j)}{\sum_{t=1}^{T-1} \gamma_t(i)}$$
    这可以解释为从状态 $i$ 转移到状态 $j$ 的期望次数，除以从状态 $i$ 出发的所有转移的期望总次数。

-   **更新发射模型 $B$**（以离散观测为例）：
    $$B_{ik}^{\text{new}} = \frac{\sum_{t=1, \text{s.t. } x_t=v_k}^{T} \gamma_t(i)}{\sum_{t=1}^{T} \gamma_t(i)}$$
    这可以解释为在状态 $i$ 下观测到符号 $v_k$ 的期望次数，除以处于状态 $i$ 的期望总次数。

通过反复交替执行E-步和M-步，[Baum-Welch算法](@entry_id:273942)保证了观测序列的似然函数值 $p(x_{1:T} \mid \lambda)$ 单调不减，并最终收敛到一个局部最大值。

### 实践考量与理论细微之处

#### 数值稳定性

当处理长序列时（例如 $T > 100$），前向、后向和维特比变量的值（它们是概率的乘积）会以指数速度趋近于零，迅速超出标准浮点数（如64位[双精度](@entry_id:636927)）的表示范围，导致**数值[下溢](@entry_id:635171)（underflow）** [@problem_id:2875787]。

解决这个问题的标准方法是引入**尺度因子（scaling factors）**。以[前向算法](@entry_id:165467)为例，我们在每一步计算后对 $\alpha_t$ 向量进行归一化，使其元素之和为1。
设 $\hat{\alpha}_t(i)$ 是归一化后的前向变量，[尺度因子](@entry_id:266678) $c_t$ 是[归一化常数](@entry_id:752675)：
$$c_t = \frac{1}{\sum_{j=1}^N \alpha'_t(j)}$$
其中 $\alpha'_t(j)$ 是基于 $\hat{\alpha}_{t-1}(\cdot)$ 计算得到的未归一化前向变量。然后，$\hat{\alpha}_t(j) = c_t \alpha'_t(j)$。
对后向算法也需要进行一致的缩放，$\hat{\beta}_t(i) = c_{t+1} \sum_j a_{ij} b_j(x_{t+1}) \hat{\beta}_{t+1}(j)$。
使用[尺度因子](@entry_id:266678)后，$\gamma_t(i)$ 和 $\xi_t(i,j)$ 的计算公式也相应调整，但结果保持数值稳定。最终，序列的[对数似然](@entry_id:273783)可以由[尺度因子](@entry_id:266678)恢复：
$$\ln p(x_{1:T}) = - \sum_{t=1}^{T} \ln(c_t)$$
类似地，[维特比算法](@entry_id:269328)也可以通过每一步将 $\delta_t$ 向量的最大值归一化为1来保持数值稳定，最终路径的[对数似然](@entry_id:273783)同样可以从尺度因子中恢复。

#### [模型可辨识性](@entry_id:186414)与[标签切换](@entry_id:751100)

HMM的一个重要理论特性是其**非[可辨识性](@entry_id:194150)（non-identifiability）**，这源于所谓的**[标签切换](@entry_id:751100)（label switching）**对称性 [@problem_id:2875828]。对于一个有 $S$ 个状态的HMM，如果我们对这 $S$ 个状态的标签进行任意[置换](@entry_id:136432)（permutation），并相应地重排 $\pi$ 向量、$A$ 矩阵的行和列以及 $B$ 模型的参数，我们会得到一个参数上不同但行为上完[全等](@entry_id:273198)价的新模型。

具体来说，对于任何[置换](@entry_id:136432) $\sigma$，新旧两个模型计算出的任意观测序列的[似然函数](@entry_id:141927)值是完全相同的。这意味着似然函数[曲面](@entry_id:267450)上有 $S!$ 个等价的[全局最大值](@entry_id:174153)。

这给参数估计带来了实际问题：
- [Baum-Welch算法](@entry_id:273942)的收敛点取决于其初始值。从不同的随机初始点出发，算法可能会收敛到这 $S!$ 个等价最大值中的任何一个。
- 在[贝叶斯推断](@entry_id:146958)中，状态标签的[后验分布](@entry_id:145605)会是多峰的，难以解释。

为了解决这个问题，通常需要引入**可辨识性约束**。例如，如果发射模型是[高斯分布](@entry_id:154414)，我们可以强制要求其均值参数按升序[排列](@entry_id:136432)：$\mu_1  \mu_2  \dots  \mu_S$。这种约束为每个等价类选择了一个唯一的、规范的代表，从而使得[最大似然](@entry_id:146147)或最大后验估计的结果唯一，便于解释和比较 [@problem_id:2875828]。