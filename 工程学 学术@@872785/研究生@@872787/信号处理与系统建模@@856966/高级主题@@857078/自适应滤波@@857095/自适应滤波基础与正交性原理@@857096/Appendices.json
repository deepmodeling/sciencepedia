{"hands_on_practices": [{"introduction": "在探索随时间变化的自适应滤波器之前，我们必须首先理解其最终目标：最优的时不变线性滤波器。维纳滤波器代表了这种理想解，其推导是正交性原理的直接应用。本练习 [@problem_id:2850274] 将指导您针对一个具体场景，计算最优的滤波器权重和可实现的最小均方误差 $J_{\\min}$，从而为任何自适应滤波器的性能建立一个基础的理论基准。", "problem": "考虑一个实值、零均值、联合广义平稳（WSS）的随机向量和过程对，其目标是使用线性估计器 $y = \\mathbf{w}^{\\top}\\mathbf{x}$ 从一个二维回归量 $\\mathbf{x} \\in \\mathbb{R}^{2}$ 中估计一个标量期望随机变量 $d$。设均方误差（MSE）代价定义为\n$$\nJ(\\mathbf{w}) \\triangleq \\mathbb{E}\\!\\left[(d - \\mathbf{w}^{\\top}\\mathbf{x})^{2}\\right],\n$$\n并将输入相关矩阵、互相关向量和期望功率分别定义为\n$$\n\\mathbf{R} \\triangleq \\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}], \\quad \\mathbf{p} \\triangleq \\mathbb{E}[\\mathbf{x}d], \\quad \\sigma_{d}^{2} \\triangleq \\mathbb{E}[d^{2}],\n$$\n。仅使用基本定义和正交性原理，推导最优维纳解 $\\mathbf{w}^{\\star}$ 必须满足的正规方程，在给定\n$$\n\\mathbf{R}=\\begin{bmatrix}2  1 \\\\ 1  2\\end{bmatrix}, \\qquad \\mathbf{p}=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix},\n$$\n的条件下显式求解 $\\mathbf{w}^{\\star}$，并以 $\\sigma_{d}^{2}$ 的函数形式计算最小可达均方误差\n$$\nJ_{\\min} \\triangleq \\min_{\\mathbf{w}} J(\\mathbf{w}),\n$$\n的闭合形式解。以单行的形式提供您的最终答案，包含 $\\mathbf{w}^{\\star}$ 的两个分量，后跟 $J_{\\min}$，形式为精确值，无需四舍五入。答案无单位，也不涉及角度单位。", "solution": "在尝试任何解答之前，对问题进行了严格的验证。\n\n从问题陈述中逐字提取已知条件：\n- 一个实值、零均值的标量随机变量 $d$。\n- 一个实值、零均值的二维随机向量 $\\mathbf{x} \\in \\mathbb{R}^{2}$。\n- 对 $(d, \\mathbf{x})$ 是联合广义平稳的（WSS）。\n- 线性估计器为 $y = \\mathbf{w}^{\\top}\\mathbf{x}$。\n- 均方误差（MSE）代价函数为 $J(\\mathbf{w}) \\triangleq \\mathbb{E}\\!\\left[(d - \\mathbf{w}^{\\top}\\mathbf{x})^{2}\\right]$。\n- 输入相关矩阵为 $\\mathbf{R} \\triangleq \\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}]$。\n- 互相关向量为 $\\mathbf{p} \\triangleq \\mathbb{E}[\\mathbf{x}d]$。\n- 期望信号的功率为 $\\sigma_{d}^{2} \\triangleq \\mathbb{E}[d^{2}]$。\n- 相关矩阵和互相关向量的具体值为：\n$$\n\\mathbf{R}=\\begin{bmatrix}2  1 \\\\ 1  2\\end{bmatrix}, \\qquad \\mathbf{p}=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}\n$$\n- 目标是推导正规方程，求出最优维纳解 $\\mathbf{w}^{\\star}$，并计算最小均方误差 $J_{\\min} \\triangleq \\min_{\\mathbf{w}} J(\\mathbf{w})$。\n\n对问题进行有效性评估。这是一个线性估计理论中的标准问题，特别是维纳滤波。所有术语都有明确的定义，其背景牢固地植根于信号处理领域。给定的相关矩阵 $\\mathbf{R}$ 是对称的，其行列式为 $\\det(\\mathbf{R}) = (2)(2) - (1)(1) = 3 \\neq 0$，这确保了 $\\mathbf{R}$ 是可逆的，并且存在最优权重向量 $\\mathbf{w}^{\\star}$ 的唯一解。该问题是自洽的、有科学依据且适定的。因此，该问题被认为是有效的。我们继续进行求解。\n\n均方误差由 $J(\\mathbf{w}) = \\mathbb{E}[(d - \\mathbf{w}^{\\top}\\mathbf{x})^2]$ 给出。我们寻求最小化此代价函数的最优权重向量 $\\mathbf{w}^{\\star}$。估计误差定义为 $e = d - y = d - \\mathbf{w}^{\\top}\\mathbf{x}$。对于最优滤波器 $\\mathbf{w} = \\mathbf{w}^{\\star}$，正交性原理指出，估计误差 $e^{\\star} = d - (\\mathbf{w}^{\\star})^{\\top}\\mathbf{x}$ 必须与输入向量 $\\mathbf{x}$ 正交。在数学上，这表示为误差与输入向量乘积的期望为零。\n$$\n\\mathbb{E}[\\mathbf{x} e^{\\star}] = \\mathbf{0}\n$$\n代入误差 $e^{\\star}$ 的表达式：\n$$\n\\mathbb{E}[\\mathbf{x} (d - (\\mathbf{w}^{\\star})^{\\top}\\mathbf{x})] = \\mathbf{0}\n$$\n使用期望算子的线性性质：\n$$\n\\mathbb{E}[\\mathbf{x}d] - \\mathbb{E}[\\mathbf{x} (\\mathbf{w}^{\\star})^{\\top}\\mathbf{x}] = \\mathbf{0}\n$$\n项 $(\\mathbf{w}^{\\star})^{\\top}\\mathbf{x}$ 是一个标量，因此可以重新排序：$\\mathbf{x} (\\mathbf{w}^{\\star})^{\\top}\\mathbf{x} = \\mathbf{x} \\mathbf{x}^{\\top} \\mathbf{w}^{\\star}$。权重向量 $\\mathbf{w}^{\\star}$ 对于期望而言是确定性的。\n$$\n\\mathbb{E}[\\mathbf{x}d] - \\mathbb{E}[\\mathbf{x} \\mathbf{x}^{\\top}] \\mathbf{w}^{\\star} = \\mathbf{0}\n$$\n使用所提供的定义 $\\mathbf{p} = \\mathbb{E}[\\mathbf{x}d]$ 和 $\\mathbf{R} = \\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}]$，我们得到正规方程，在此离散情况下也称为维纳-霍夫方程：\n$$\n\\mathbf{p} - \\mathbf{R} \\mathbf{w}^{\\star} = \\mathbf{0}\n$$\n$$\n\\mathbf{R} \\mathbf{w}^{\\star} = \\mathbf{p}\n$$\n这是最优维纳解 $\\mathbf{w}^{\\star}$ 必须满足的线性方程组。\n\n为了找到 $\\mathbf{w}^{\\star}$ 的显式解，我们必须解这个方程组。由于 $\\mathbf{R}$ 是可逆的，唯一解由下式给出：\n$$\n\\mathbf{w}^{\\star} = \\mathbf{R}^{-1} \\mathbf{p}\n$$\n给定的矩阵为：\n$$\n\\mathbf{R}=\\begin{bmatrix}2  1 \\\\ 1  2\\end{bmatrix}, \\qquad \\mathbf{p}=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}\n$$\n首先，我们计算 $\\mathbf{R}$ 的逆。对于一个 $2 \\times 2$ 矩阵 $\\begin{bmatrix}a  b \\\\ c  d\\end{bmatrix}$，其逆为 $\\frac{1}{ad-bc}\\begin{bmatrix}d  -b \\\\ -c  a\\end{bmatrix}$。$\\mathbf{R}$ 的行列式为 $\\det(\\mathbf{R}) = (2)(2) - (1)(1) = 4 - 1 = 3$。\n因此，逆矩阵为：\n$$\n\\mathbf{R}^{-1} = \\frac{1}{3}\\begin{bmatrix}2  -1 \\\\ -1  2\\end{bmatrix}\n$$\n现在我们可以计算 $\\mathbf{w}^{\\star}$：\n$$\n\\mathbf{w}^{\\star} = \\frac{1}{3}\\begin{bmatrix}2  -1 \\\\ -1  2\\end{bmatrix} \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = \\frac{1}{3}\\begin{bmatrix}(2)(1) + (-1)(0) \\\\ (-1)(1) + (2)(0)\\end{bmatrix} = \\frac{1}{3}\\begin{bmatrix}2 \\\\ -1\\end{bmatrix} = \\begin{bmatrix}2/3 \\\\ -1/3\\end{bmatrix}\n$$\n所以，最优权重向量的分量是 $w_1^{\\star} = 2/3$ 和 $w_2^{\\star} = -1/3$。\n\n接下来，我们计算最小可达均方误差 $J_{\\min} = J(\\mathbf{w}^{\\star})$。我们从 $J(\\mathbf{w})$ 的定义开始并展开它：\n$$\nJ(\\mathbf{w}) = \\mathbb{E}[(d - \\mathbf{w}^{\\top}\\mathbf{x})^2] = \\mathbb{E}[d^2 - 2d\\mathbf{w}^{\\top}\\mathbf{x} + (\\mathbf{w}^{\\top}\\mathbf{x})^2]\n$$\n根据期望的线性性质：\n$$\nJ(\\mathbf{w}) = \\mathbb{E}[d^2] - 2\\mathbf{w}^{\\top}\\mathbb{E}[\\mathbf{x}d] + \\mathbf{w}^{\\top}\\mathbb{E}[\\mathbf{x}\\mathbf{x}^{\\top}]\\mathbf{w} = \\sigma_{d}^{2} - 2\\mathbf{w}^{\\top}\\mathbf{p} + \\mathbf{w}^{\\top}\\mathbf{R}\\mathbf{w}\n$$\n为了求 $J_{\\min}$，我们代入 $\\mathbf{w} = \\mathbf{w}^{\\star}$：\n$$\nJ_{\\min} = \\sigma_{d}^{2} - 2(\\mathbf{w}^{\\star})^{\\top}\\mathbf{p} + (\\mathbf{w}^{\\star})^{\\top}\\mathbf{R}\\mathbf{w}^{\\star}\n$$\n从正规方程我们知道 $\\mathbf{R}\\mathbf{w}^{\\star} = \\mathbf{p}$。将此代入最后一项：\n$$\nJ_{\\min} = \\sigma_{d}^{2} - 2(\\mathbf{w}^{\\star})^{\\top}\\mathbf{p} + (\\mathbf{w}^{\\star})^{\\top}\\mathbf{p}\n$$\n这简化为最小均方误差的一般表达式：\n$$\nJ_{\\min} = \\sigma_{d}^{2} - (\\mathbf{w}^{\\star})^{\\top}\\mathbf{p}\n$$\n现在，我们代入我们找到的 $\\mathbf{w}^{\\star}$ 的数值和给定的 $\\mathbf{p}$：\n$$\n(\\mathbf{w}^{\\star})^{\\top}\\mathbf{p} = \\begin{bmatrix}2/3  -1/3\\end{bmatrix} \\begin{bmatrix}1 \\\\ 0\\end{bmatrix} = (2/3)(1) + (-1/3)(0) = 2/3\n$$\n因此，最小均方误差是：\n$$\nJ_{\\min} = \\sigma_{d}^{2} - \\frac{2}{3}\n$$\n最终答案包含 $\\mathbf{w}^{\\star}$ 的两个分量和 $J_{\\min}$ 的表达式。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{2}{3}  -\\frac{1}{3}  \\sigma_{d}^{2} - \\frac{2}{3} \\end{pmatrix}}\n$$", "id": "2850274"}, {"introduction": "维纳滤波器的解要求预先知道信号的统计特性（如相关矩阵 $\\mathbf{R}$ 和互相关向量 $\\mathbf{p}$），这在实际应用中往往是无法获取的。像递推最小二乘 (RLS) 这样的自适应算法通过在新数据到达时迭代地优化滤波器权重来克服这个问题。本练习 [@problem_id:2850229] 提供了一个具体的、分步的 RLS 更新机制演练，展示了该算法如何利用每个新的数据点来递归地更新滤波器权重和辅助矩阵，从而逼近最小二乘解。", "problem": "考虑一个阶数为 $M=2$ 的实值、时变、线性有限冲激响应自适应滤波器，该滤波器通过遗忘因子为 $\\lambda$ 的递归最小二乘 (RLS) 方法进行更新。在时刻 $n$，RLS 方法寻找权重向量 $\\mathbf{w}(n) \\in \\mathbb{R}^{2}$，以最小化指数加权最小二乘代价\n$$\nJ(n) \\triangleq \\sum_{i=1}^{n} \\lambda^{n-i} \\left(d(i) - \\mathbf{u}^{\\top}(i)\\,\\mathbf{w}\\right)^{2},\n$$\n其中 $\\mathbf{u}(i) \\in \\mathbb{R}^{2}$ 是回归量， $d(i) \\in \\mathbb{R}$ 是期望响应。最小化器满足相对于由 $\\lambda$ 导出的加权内积的正交性原理，且更新过程使用加权输入相关矩阵的逆矩阵 $\\mathbf{P}(n) \\in \\mathbb{R}^{2 \\times 2}$。\n\n在时刻 $n$，给定：\n- $\\lambda = 1$，\n- $\\mathbf{u}(n) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，\n- $d(n) = 2$，\n- $\\mathbf{P}(n-1) = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}$，\n- $\\mathbf{w}(n-1) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n\n使用与指数加权最小二乘准则和正交性原理一致的标准 RLS 递归，在时刻 $n$ 执行一个更新步骤，以获得更新后的权重向量 $\\mathbf{w}(n)$、更新后的逆相关矩阵 $\\mathbf{P}(n)$ 以及后验误差 $e_{\\mathrm{po}}(n) \\triangleq d(n) - \\mathbf{u}^{\\top}(n)\\,\\mathbf{w}(n)$。\n\n将最终答案表示为一个单行矩阵，其中按顺序包含 $\\mathbf{w}(n)$ 的两个分量、$\\mathbf{P}(n)$ 按行主序排列的四个元素以及 $e_{\\mathrm{po}}(n)$。请使用精确的有理数值，不要进行四舍五入。", "solution": "首先将对问题的科学性和形式正确性进行验证。\n\n### 步骤 1：提取已知条件\n问题为递归最小二乘 (RLS) 自适应滤波器在时间步 $n$ 的更新提供了以下明确数据和定义：\n- 滤波器阶数：$M=2$\n- 遗忘因子：$\\lambda = 1$\n- 时刻 $n$ 的输入回归量向量：$\\mathbf{u}(n) = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n- 时刻 $n$ 的期望响应：$d(n) = 2$\n- 时刻 $n-1$ 的逆相关矩阵：$\\mathbf{P}(n-1) = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}$\n- 时刻 $n-1$ 的权重向量：$\\mathbf{w}(n-1) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$\n- 待最小化的代价函数：$J(n) = \\sum_{i=1}^{n} \\lambda^{n-i} (d(i) - \\mathbf{u}^{\\top}(i)\\,\\mathbf{w})^{2}$\n- 后验误差定义：$e_{\\mathrm{po}}(n) = d(n) - \\mathbf{u}^{\\top}(n)\\,\\mathbf{w}(n)$\n\n### 步骤 2：使用提取的已知条件进行验证\n根据既定标准对问题进行验证。\n- **科学依据**：该问题描述了递归最小二乘算法的一个标准应用，该算法是信号处理中自适应滤波理论的基石。RLS 方程源自最小化加权最小二乘误差准则的原理，这是一个在数学上严谨且在科学上有效的过程。该问题不含任何伪科学或事实性错误。\n- **适定性**：该问题提供了一套完整的初始条件（$\\mathbf{w}(n-1)$、$\\mathbf{P}(n-1)$）和新数据（$\\mathbf{u}(n)$、$d(n)$），这些是执行 RLS 算法单次、唯一更新所必需的。所指定的操作在计算上是良定义的。\n- **客观性**：该问题使用信号处理领域的标准符号，以精确的数学语言陈述。它没有任何主观、模糊或基于观点的陈述。\n- **其他缺陷**：问题设置并非不完整、矛盾、不切实际、不适定、琐碎或无法验证。这是一个应用已知算法的典型练习。\n\n### 步骤 3：结论与行动\n问题被判定为**有效**。这是一个良定义且自洽的工程数学问题。将提供解答。\n\nRLS 算法提供了一种递归方法，用于寻找使指数加权最小二乘代价函数 $J(n)$ 最小化的权重向量 $\\mathbf{w}(n)$。时间步 $n$ 的标准更新过程包括以下计算序列。\n\n1.  **计算增益向量 $\\mathbf{k}(n)$**：\n    增益向量决定了对权重向量修正的方向和大小。其计算公式为：\n    $$\n    \\mathbf{k}(n) = \\frac{\\mathbf{P}(n-1)\\mathbf{u}(n)}{\\lambda + \\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1)\\mathbf{u}(n)}\n    $$\n    首先，我们计算分子 $\\mathbf{P}(n-1)\\mathbf{u}(n)$：\n    $$\n    \\mathbf{P}(n-1)\\mathbf{u}(n) = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (2)(1) + (0)(1) \\\\ (0)(1) + (1)(1) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}\n    $$\n    接下来，我们计算分母中的项 $\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1)\\mathbf{u}(n)$：\n    $$\n    \\mathbf{u}^{\\top}(n)[\\mathbf{P}(n-1)\\mathbf{u}(n)] = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = (1)(2) + (1)(1) = 3\n    $$\n    分母为 $\\lambda + 3 = 1 + 3 = 4$。\n    因此，增益向量为：\n    $$\n    \\mathbf{k}(n) = \\frac{1}{4} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix}\n    $$\n\n2.  **计算先验估计误差 $e_{\\mathrm{pr}}(n)$**：\n    此误差是期望响应 $d(n)$ 与使用前一权重向量 $\\mathbf{w}(n-1)$ 在权重更新前得到的滤波器输出之间的差值。\n    $$\n    e_{\\mathrm{pr}}(n) = d(n) - \\mathbf{u}^{\\top}(n)\\mathbf{w}(n-1)\n    $$\n    $$\n    e_{\\mathrm{pr}}(n) = 2 - \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 2 - ((1)(1) + (1)(-1)) = 2 - 0 = 2\n    $$\n\n3.  **更新滤波器权重向量以获得 $\\mathbf{w}(n)$**：\n    新的权重向量是通过将一个与先验误差和增益向量成比例的修正项加到旧的权重向量上来计算的。\n    $$\n    \\mathbf{w}(n) = \\mathbf{w}(n-1) + \\mathbf{k}(n) e_{\\mathrm{pr}}(n)\n    $$\n    $$\n    \\mathbf{w}(n) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} (2) = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 1+1 \\\\ -1+\\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{1}{2} \\end{pmatrix}\n    $$\n\n4.  **更新逆相关矩阵以获得 $\\mathbf{P}(n)$**：\n    $\\mathbf{P}(n)$ 的更新规则由矩阵求逆引理推导得出，其公式为：\n    $$\n    \\mathbf{P}(n) = \\frac{1}{\\lambda} \\left[ \\mathbf{P}(n-1) - \\mathbf{k}(n)\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1) \\right]\n    $$\n    由于 $\\lambda = 1$，该方程简化为 $\\mathbf{P}(n) = \\mathbf{P}(n-1) - \\mathbf{k}(n)\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1)$。首先，我们计算项 $\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1)$：\n    $$\n    \\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1) = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} (1)(2)+(1)(0)  (1)(0)+(1)(1) \\end{pmatrix} = \\begin{pmatrix} 2  1 \\end{pmatrix}\n    $$\n    接下来，我们计算外积 $\\mathbf{k}(n)[\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1)]$：\n    $$\n    \\mathbf{k}(n)\\mathbf{u}^{\\top}(n)\\mathbf{P}(n-1) = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 2  1 \\end{pmatrix} = \\begin{pmatrix} (\\frac{1}{2})(2)  (\\frac{1}{2})(1) \\\\ (\\frac{1}{4})(2)  (\\frac{1}{4})(1) \\end{pmatrix} = \\begin{pmatrix} 1  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{4} \\end{pmatrix}\n    $$\n    最后，我们更新 $\\mathbf{P}(n)$：\n    $$\n    \\mathbf{P}(n) = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} - \\begin{pmatrix} 1  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 2-1  0-\\frac{1}{2} \\\\ 0-\\frac{1}{2}  1-\\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ -\\frac{1}{2}  \\frac{3}{4} \\end{pmatrix}\n    $$\n\n5.  **计算后验估计误差 $e_{\\mathrm{po}}(n)$**：\n    这是使用更新后的权重向量 $\\mathbf{w}(n)$ 得到的最终误差。\n    $$\n    e_{\\mathrm{po}}(n) = d(n) - \\mathbf{u}^{\\top}(n)\\mathbf{w}(n)\n    $$\n    $$\n    e_{\\mathrm{po}}(n) = 2 - \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -\\frac{1}{2} \\end{pmatrix} = 2 - \\left((1)(2) + (1)\\left(-\\frac{1}{2}\\right)\\right) = 2 - \\left(2 - \\frac{1}{2}\\right) = 2 - \\frac{3}{2} = \\frac{1}{2}\n    $$\n    另外，后验误差也可以由先验误差计算得出：$e_{\\mathrm{po}}(n) = (1 - \\mathbf{u}^{\\top}(n)\\mathbf{k}(n))e_{\\mathrm{pr}}(n)$。我们来验证一下：\n    $$\n    \\mathbf{u}^{\\top}(n)\\mathbf{k}(n) = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{4} \\end{pmatrix} = \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4}\n    $$\n    $$\n    e_{\\mathrm{po}}(n) = \\left(1 - \\frac{3}{4}\\right)(2) = \\left(\\frac{1}{4}\\right)(2) = \\frac{1}{2}\n    $$\n    结果一致。\n\n所需的输出是 $\\mathbf{w}(n)$ 的分量、$\\mathbf{P}(n)$ 按行主序排列的元素以及 $e_{\\mathrm{po}}(n)$ 的值。\n- $\\mathbf{w}(n) = \\begin{pmatrix} w_1(n) \\\\ w_2(n) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{1}{2} \\end{pmatrix}$\n- $\\mathbf{P}(n) = \\begin{pmatrix} p_{11}(n)  p_{12}(n) \\\\ p_{21}(n)  p_{22}(n) \\end{pmatrix} = \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ -\\frac{1}{2}  \\frac{3}{4} \\end{pmatrix}$\n- $e_{\\mathrm{po}}(n) = \\frac{1}{2}$\n\n按要求将这些组合成一个单行矩阵。", "answer": "$$\n\\boxed{\\begin{pmatrix} 2  -\\frac{1}{2}  1  -\\frac{1}{2}  -\\frac{1}{2}  \\frac{3}{4}  \\frac{1}{2} \\end{pmatrix}}\n$$", "id": "2850229"}, {"introduction": "最小均方 (LMS) 算法因其计算简单而备受青睐，但其性能在所有条件下并非一致，一个关键影响因素是输入信号的统计特性。本练习 [@problem_id:2850237] 深入分析了 LMS 算法的收敛速度如何受到输入信号相关矩阵的条件数 $\\kappa$ 的影响。通过这个实践，我们可以从根本上理解为什么当输入信号为“有色的”（即高度相关）时，LMS 的收敛会显著变慢，这为自适应滤波器的实际设计和算法选择提供了至关重要的洞见。", "problem": "考虑一个线性系统辨识问题，其中未知向量为 $w^{\\star} \\in \\mathbb{R}^{m}$，由零均值、广义平稳的输入 $x(n) \\in \\mathbb{R}^{m}$ 驱动，其相关矩阵 $R \\triangleq \\mathbb{E}\\{x(n)x^{\\top}(n)\\}$ 是正定的。期望响应为 $d(n) = x^{\\top}(n) w^{\\star} + v(n)$，其中 $v(n)$ 是零均值、白噪声，且与 $x(n)$ 无关。最小均方 (LMS) 算法根据 $w(n+1) = w(n) + \\mu\\, x(n)\\, e(n)$ 来更新 $w(n)$，其中 $e(n) \\triangleq d(n) - x^{\\top}(n) w(n)$。设步长选择为 $\\mu = \\beta / \\lambda_{\\max}$，其中 $\\beta \\in (0,2)$ 为一固定值，$\\lambda_{\\max}$ 是 $R$ 的最大特征值。$R$ 的条件数为 $\\kappa \\triangleq \\lambda_{\\max} / \\lambda_{\\min}$，其中 $\\lambda_{\\min}$ 是最小特征值。\n\n仅使用基本定义（包括正交性原理，即维纳解 $w^{\\star}$ 使最优误差与回归量正交）以及标准的小步长和独立性假设，从第一性原理推导瞬态均方偏差如何沿着 $R$ 的特征方向衰减。定义一个目标均方偏差衰减因子 $\\rho \\in (0,1)$，该衰减因子需在瞬态（在梯度噪声主导的稳态底限之前）达到，并令 $n(\\kappa,\\rho,\\beta)$ 表示在上述步长规则下，当输入具有条件数 $\\kappa$ 时，实现此衰减所需的迭代次数。\n\n对于“多多少次迭代”，将问题解释为乘法因子 $F(\\kappa,\\beta) \\triangleq \\dfrac{n(\\kappa,\\rho,\\beta)}{n(1,\\rho,\\beta)}$，这是当从 $\\kappa = 1$（白噪声输入）变为具有一般性 $\\kappa$ 的有色输入时，达到相同的固定衰减因子 $\\rho$ 所需的。在小 $\\beta$ 的情况下，估计 $F(\\kappa,\\beta)$ 的闭式解，然后计算其在 $\\kappa = 100$ 时的值。最终答案以一个无单位的数字形式给出。无需四舍五入。", "solution": "首先必须验证问题陈述的科学合理性、一致性和完整性。\n\n步骤 1：提取已知条件。\n-   未知线性系统：一个向量 $w^{\\star} \\in \\mathbb{R}^{m}$。\n-   输入信号：$x(n) \\in \\mathbb{R}^{m}$，一个零均值、广义平稳 (WSS) 过程。\n-   输入相关矩阵：$R \\triangleq \\mathbb{E}\\{x(n)x^{\\top}(n)\\}$，为正定矩阵。\n-   $R$ 的特征值：$\\lambda_{\\max}$ (最大) 和 $\\lambda_{\\min}$ (最小)。\n-   期望响应：$d(n) = x^{\\top}(n) w^{\\star} + v(n)$。\n-   噪声信号：$v(n)$，一个零均值、白噪声过程，与 $x(n)$ 无关。\n-   LMS 算法：$w(n+1) = w(n) + \\mu\\, x(n)\\, e(n)$。\n-   估计误差：$e(n) = d(n) - x^{\\top}(n) w(n)$。\n-   步长：$\\mu = \\beta / \\lambda_{\\max}$，对于一个常数 $\\beta \\in (0,2)$。\n-   条件数：$\\kappa \\triangleq \\lambda_{\\max} / \\lambda_{\\min}$。\n-   假设：小步长假设和独立性假设。独立性假设是指 LMS 分析中的标准简化，即假设输入向量 $x(n)$ 与过去的权重向量 $\\{w(k) | k \\leq n\\}$ 统计独立。\n-   目标：推导瞬态均方偏差沿特征方向的衰减，定义迭代次数的乘法因子 $F(\\kappa,\\beta) \\triangleq n(\\kappa,\\rho,\\beta)/n(1,\\rho,\\beta)$，在小 $\\beta$ 情况下估计该因子，并计算其在 $\\kappa=100$ 时的值。\n\n步骤 2：使用提取的已知条件进行验证。\n该问题是 LMS 自适应算法分析中的一个典型练习，而 LMS 算法是信号处理的基石。所有定义和模型都是标准的。参数定义明确且一致。所作的假设（小步长、独立性）已明确陈述，并且是该算法动态特性入门分析中的标准假设。目标清晰，要求基于自适应滤波器理论的基本原理进行推导。该问题具有科学依据、提法恰当、客观，并且没有明显的缺陷。\n\n步骤 3：结论与行动。\n问题有效。将构建一个严谨的解决方案。\n\n分析始于定义权重误差向量 $\\tilde{w}(n) \\triangleq w(n) - w^{\\star}$。我们推导其动态特性。\n将 $e(n)$ 和 $d(n)$ 的定义代入 LMS 更新规则：\n$$\nw(n+1) = w(n) + \\mu x(n) [ (x^{\\top}(n) w^{\\star} + v(n)) - x^{\\top}(n) w(n) ]\n$$\n$$\nw(n+1) = w(n) + \\mu x(n) [ v(n) - x^{\\top}(n) (w(n) - w^{\\star}) ]\n$$\n从两侧减去最优权重向量 $w^{\\star}$，得到权重误差向量的更新方程：\n$$\n\\tilde{w}(n+1) = \\tilde{w}(n) - \\mu x(n) x^{\\top}(n) \\tilde{w}(n) + \\mu x(n) v(n)\n$$\n为了分析瞬态行为，我们研究权重误差相关矩阵 $K(n) \\triangleq \\mathbb{E}\\{\\tilde{w}(n) \\tilde{w}^{\\top}(n)\\}$ 的演化。我们对误差向量更新方程自身的外积取期望。包含 $v(n)$ 的交叉项在取期望后消失，因为 $v(n)$ 是零均值且与时刻 $n$ 及之前的所有其他信号无关。\n$$\nK(n+1) = \\mathbb{E}\\{ [ \\tilde{w}(n) - \\mu x(n) x^{\\top}(n) \\tilde{w}(n) ] [ \\tilde{w}(n) - \\mu x(n) x^{\\top}(n) \\tilde{w}(n) ]^{\\top} \\} + \\mu^2 \\mathbb{E}\\{ v^2(n) x(n) x^{\\top}(n) \\}\n$$\n第二项是梯度噪声，它决定了稳态均方误差：$\\mu^2 \\sigma_v^2 R$，其中 $\\sigma_v^2 = \\mathbb{E}\\{v^2(n)\\}$。瞬态行为由第一项决定。展开它得到：\n$$\nK(n+1)_{\\text{transient}} = \\mathbb{E}\\{ \\tilde{w}(n)\\tilde{w}^{\\top}(n) - \\mu \\tilde{w}(n)\\tilde{w}^{\\top}(n)x(n)x^{\\top}(n) - \\mu x(n)x^{\\top}(n)\\tilde{w}(n)\\tilde{w}^{\\top}(n) + \\mu^2 x(n)x^{\\top}(n)\\tilde{w}(n)\\tilde{w}^{\\top}(n)x(n)x^{\\top}(n) \\}\n$$\n使用独立性假设（即 $x(n)$ 与 $\\tilde{w}(n)$ 无关）并忽略 $\\mu^2$ 阶项（这在小步长下是有效的），我们得到一个简化的递推关系：\n$$\nK(n+1) \\approx K(n) - \\mu K(n) R - \\mu R K(n)\n$$\n这个一阶近似描述了权重误差相关矩阵的瞬态演化。为了分析沿 $R$ 的特征方向的衰减，我们进行坐标变换。设 $R = Q \\Lambda Q^{\\top}$ 是 $R$ 的特征分解，其中 $Q$ 是特征向量构成的正交矩阵，$\\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_m)$ 是相应特征值构成的对角矩阵。\n我们定义变换后的相关矩阵 $K'(n) \\triangleq Q^{\\top} K(n) Q$。在递推关系的两边分别左乘和右乘 $Q^{\\top}$ 和 $Q$：\n$$\nQ^{\\top}K(n+1)Q \\approx Q^{\\top}K(n)Q - \\mu (Q^{\\top}K(n)Q)(Q^{\\top}RQ) - \\mu (Q^{\\top}RQ)(Q^{\\top}K(n)Q)\n$$\n$$\nK'(n+1) \\approx K'(n) - \\mu K'(n) \\Lambda - \\mu \\Lambda K'(n)\n$$\n由于 $\\Lambda$ 是对角矩阵，这个矩阵方程对于 $K'(n)$ 的对角元素是解耦的。令 $k'_i(n) \\triangleq [K'(n)]_{ii}$ 为第 $i$ 个对角元素，它表示沿第 $i$ 个特征向量方向的权重误差的均方值。$k'_i(n)$ 的递推关系为：\n$$\nk'_i(n+1) \\approx k'_i(n) - \\mu k'_i(n) \\lambda_i - \\mu \\lambda_i k'_i(n) = (1 - 2\\mu\\lambda_i)k'_i(n)\n$$\n这是一个简单的几何级数。其解为：\n$$\nk'_i(n) \\approx (1 - 2\\mu\\lambda_i)^n k'_i(0)\n$$\n整个算法的收敛速度受限于最慢的衰减模式。模式 $i$ 的衰减因子是 $(1 - 2\\mu\\lambda_i)$。由于 $\\mu  0$ 且所有 $\\lambda_i  0$，最慢的收敛发生在衰减因子最接近 1 的模式，这对应于最小的特征值 $\\lambda_{\\min}$。\n在该最慢模式的瞬态分量中，实现衰减因子 $\\rho$ 所需的迭代次数 $n$ 由下式给出：\n$$\n(1 - 2\\mu\\lambda_{\\min})^n = \\rho\n$$\n解出 $n$ 得到：\n$$\nn = \\frac{\\ln(\\rho)}{\\ln(1 - 2\\mu\\lambda_{\\min})}\n$$\n问题指定了步长规则 $\\mu = \\beta / \\lambda_{\\max}$ 和条件数 $\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$。将这些代入 $n$ 的表达式，得到迭代次数作为这些参数的函数：\n$$\nn(\\kappa, \\rho, \\beta) = \\frac{\\ln(\\rho)}{\\ln(1 - 2 (\\frac{\\beta}{\\lambda_{\\max}}) \\lambda_{\\min})} = \\frac{\\ln(\\rho)}{\\ln(1 - \\frac{2\\beta}{\\kappa})}\n$$\n对于白噪声输入的参考情况，$\\kappa=1$。这意味着 $\\lambda_{\\min} = \\lambda_{\\max}$。迭代次数变为：\n$$\nn(1, \\rho, \\beta) = \\frac{\\ln(\\rho)}{\\ln(1 - 2\\beta)}\n$$\n乘法因子 $F(\\kappa, \\beta)$ 是这两个量的比值：\n$$\nF(\\kappa, \\beta) = \\frac{n(\\kappa, \\rho, \\beta)}{n(1, \\rho, \\beta)} = \\frac{\\ln(\\rho) / \\ln(1 - 2\\beta/\\kappa)}{\\ln(\\rho) / \\ln(1 - 2\\beta)} = \\frac{\\ln(1 - 2\\beta)}{\\ln(1 - 2\\beta/\\kappa)}\n$$\n问题要求在“小 $\\beta$”情况下估计该因子。这个条件意味着 $\\beta \\ll 1$。如果 $\\beta$ 很小，那么对数函数的自变量 $2\\beta$ 和 $2\\beta/\\kappa$（因为 $\\kappa \\ge 1$）也都很小。因此，对于小的 $x$，我们可以使用一阶泰勒近似 $\\ln(1-x) \\approx -x$。\n将此近似应用于分子和分母：\n$$\nF(\\kappa, \\beta) \\approx \\frac{-2\\beta}{-2\\beta/\\kappa} = \\kappa\n$$\n这就是所求的估计值。它表明，对于归一化步长，LMS 算法的收敛时间与输入相关矩阵的条件数成线性关系。\n\n最后，我们被要求计算该因子在 $\\kappa = 100$ 时的值。\n$$\nF(100, \\beta) \\approx 100\n$$\n在此近似下，结果与 $\\beta$ 无关。", "answer": "$$\n\\boxed{100}\n$$", "id": "2850237"}]}