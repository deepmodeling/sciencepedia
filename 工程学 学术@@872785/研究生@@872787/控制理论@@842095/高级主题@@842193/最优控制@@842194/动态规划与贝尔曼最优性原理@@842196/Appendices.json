{"hands_on_practices": [{"introduction": "动态规划的核心在于通过后向递归求解贝尔曼方程。这个练习提供了一个离散状态和行动空间的有限时域马尔可夫决策过程，旨在让您从第一性原理出发，亲手实践后向递归算法。通过逐步计算每一时刻的值函数和最优策略，您将对贝尔曼最优性原理的实际应用建立起坚实的直觉 [@problem_id:2703371]。", "problem": "考虑一个有限期界、时间索引的随机控制问题，该问题被建模为一个马尔可夫决策过程（MDP），其状态空间为 $\\mathcal{X}=\\{0,1\\}$，动作空间为 $\\mathcal{U}=\\{a,b\\}$，期界为 $N=3$，决策时间为 $t\\in\\{0,1,2\\}$，并在 $t=3$ 时有一个终端成本。受控状态的演化是时齐的和马尔可夫的：对于每个 $t$，下一状态 $x_{t+1}$ 仅取决于当前状态 $x_t$ 和施加的控制 $u_t$。决策者旨在最小化阶段成本与终端成本之和的期望值。\n\n转移概率如下：\n- 从 $x=0$：在 $u=a$ 下，$x_{t+1}=0$ 的概率为 $\\frac{2}{3}$，$x_{t+1}=1$ 的概率为 $\\frac{1}{3}$；在 $u=b$ 下，$x_{t+1}=1$ 的概率为 $1$。\n- 从 $x=1$：在 $u=a$ 下，$x_{t+1}=0$ 的概率为 $\\frac{1}{2}$，$x_{t+1}=1$ 的概率为 $\\frac{1}{2}$；在 $u=b$ 下，$x_{t+1}=1$ 的概率为 $1$。\n\n在时间 $t\\in\\{0,1,2\\}$，处于状态 $x$ 并采取动作 $u$ 的阶段成本是时不变的，由 $c(x,u)$ 给出：\n- $c(0,a)=0$，$c(0,b)=\\frac{3}{5}$，\n- $c(1,a)=\\frac{3}{2}$，$c(1,b)=0$。\n在 $t=3$ 时的终端成本是 $g(x)$，其中 $g(0)=\\frac{7}{10}$，$g(1)=0$。\n\n从有限期界 MDP 最优控制的基本定义（在容许策略上最小化期望总成本）和 Bellman 最优性原理出发，首先推导刻画最优未来成本函数 $\\{V_t\\}_{t=0}^{3}$ 的反向递推关系，而不借用任何预先给出的“捷径”公式。然后，对所有状态 $x\\in\\{0,1\\}$，显式计算值函数 $V_3$、$V_2$、$V_1$ 和 $V_0$，并确定在每个时间 $t\\in\\{0,1,2\\}$ 和每个状态 $x\\in\\{0,1\\}$ 下的最优策略 $\\pi_t^{\\star}(x)\\in\\{a,b\\}$。最后，通过显式评估竞争动作，验证其最优子结构（Bellman 最优性），即对于从 $(t,x)\\in\\{1,2\\}\\times\\{0,1\\}$ 开始的每个子问题，验证从较早时间得到的最优策略的限制部分对于该子问题确实是最优的。\n\n设初始条件为 $x_0=0$。将最优初始期望总成本 $V_0(x_0)$ 作为一个单一的最简有理数报告为你的最终答案。不要四舍五入；将答案精确地表示为分数形式。", "solution": "### 第 1 步：提取已知条件\n\n- **状态空间**：$\\mathcal{X}=\\{0,1\\}$\n- **动作空间**：$\\mathcal{U}=\\{a,b\\}$\n- **期界**：$N=3$，决策时间 $t \\in \\{0, 1, 2\\}$\n- **终端时间**：$t=3$\n- **转移概率**，$P(x_{t+1}=y | x_t=x, u_t=u)$:\n  - 从 $x=0$:\n    - $u=a$: $P(x_{t+1}=0|0,a) = \\frac{2}{3}$，$P(x_{t+1}=1|0,a) = \\frac{1}{3}$\n    - $u=b$: $P(x_{t+1}=1|0,b) = 1$\n  - 从 $x=1$:\n    - $u=a$: $P(x_{t+1}=0|1,a) = \\frac{1}{2}$，$P(x_{t+1}=1|1,a) = \\frac{1}{2}$\n    - $u=b$: $P(x_{t+1}=1|1,b) = 1$\n- **阶段成本**，$c(x,u)$:\n  - $c(0,a)=0$，$c(0,b)=\\frac{3}{5}$\n  - $c(1,a)=\\frac{3}{2}$，$c(1,b)=0$\n- **终端成本**，$g(x)$:\n  - $g(0)=\\frac{7}{10}$，$g(1)=0$\n- **目标**：最小化期望总成本。\n- **初始条件**：$x_0=0$\n\n该问题是一个标准的、定义良好的马尔可夫决策过程（MDP），是随机控制理论和运筹学的基石。所有概念都基于已建立的数学原理。该问题是自洽且信息完备的。\n\n---\n\n目标是找到一个策略 $\\pi = (\\mu_0, \\mu_1, \\mu_2)$，其中每个 $\\mu_t: \\mathcal{X} \\to \\mathcal{U}$ 是一个决策规则，该策略最小化期望总成本泛函 $J_{\\pi}(x_0)$：\n$$\nJ_{\\pi}(x_0) = \\mathbb{E}_{\\pi} \\left[ g(x_3) + \\sum_{t=0}^{2} c(x_t, u_t) \\mid x_0 \\right]\n$$\n其中 $u_t = \\mu_t(x_t)$。从状态 $x$ 在时间 $t$ 的最优未来成本（或称值函数）定义为从时间 $t$ 到期界 $N=3$ 的最小可能期望成本：\n$$\nV_t(x) = \\min_{\\mu_t, ..., \\mu_{N-1}} \\mathbb{E} \\left[ g(x_N) + \\sum_{k=t}^{N-1} c(x_k, u_k) \\mid x_t = x \\right]\n$$\n整个问题的最优成本是 $V_0(x_0)$。\n\nBellman 最优性原理指出，一个最优策略具有这样的性质：无论当前的状态和控制动作是什么，其后的决策对于由当前动作所产生的新状态而言，也必须构成一个最优策略。该原理导出了一个关于最优未来成本函数的反向递推关系，即 Bellman 方程。\n\n对于最终时间步 $t=N=3$，没有更多的决策可以做出，因此未来成本就是终端成本：\n$$\nV_3(x) = g(x)\n$$\n对于任意时间 $t \\in \\{0, 1, 2\\}$，如果我们处于状态 $x_t=x$ 并选择动作 $u_t=u$，我们将产生一个即时阶段成本 $c(x,u)$ 并转移到一个新状态 $x_{t+1}$。如果我们假设从时间 $t+1$ 开始遵循最优策略，则期望未来成本为 $\\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u]$。为了在时间 $t$ 采取最优行动，我们必须选择能够最小化即时成本与期望未来最优成本之和的动作 $u$。这就建立了反向递推关系：\n$$\nV_t(x) = \\min_{u \\in \\mathcal{U}} \\left\\{ c(x,u) + \\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u] \\right\\}\n$$\n期望值是根据下一状态 $x_{t+1}$ 的概率分布计算的：\n$$\n\\mathbb{E}[V_{t+1}(x_{t+1}) \\mid x_t=x, u_t=u] = \\sum_{y \\in \\mathcal{X}} P(x_{t+1}=y \\mid x_t=x, u_t=u) V_{t+1}(y)\n$$\n在时间 $t$ 的最优策略 $\\pi_t^{\\star}(x) = \\mu_t^{\\star}(x)$ 是实现这个最小值的动作 $u$。我们现在应用这个递推关系，从 $t=3$ 开始反向计算到 $t=0$。\n\n**$t=3$ 步 (终端步)**\n未来成本是终端成本 $g(x)$：\n$V_3(0) = g(0) = \\frac{7}{10}$\n$V_3(1) = g(1) = 0$\n\n**$t=2$ 步 (反向递推)**\n我们使用 $V_3$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_2(x)$。\n对于 $x=0$：\n$$\nV_2(0) = \\min \\left\\{\n\\begin{array}{ll}\nu=a \\text{ 时的成本：}  c(0,a) + P(x_3=0|0,a)V_3(0) + P(x_3=1|0,a)V_3(1) \\\\\nu=b \\text{ 时的成本：}  c(0,b) + P(x_3=0|0,b)V_3(0) + P(x_3=1|0,b)V_3(1)\n\\end{array}\n\\right.\n$$\n$$\nV_2(0) = \\min \\left\\{ 0 + \\frac{2}{3} \\cdot \\frac{7}{10} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\cdot \\frac{7}{10} + 1 \\cdot 0 \\right\\} = \\min \\left\\{ \\frac{14}{30}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{7}{15}, \\frac{9}{15} \\right\\} = \\frac{7}{15}\n$$\n当 $u=a$ 时达到最小值。因此，$V_2(0) = \\frac{7}{15}$ 且 $\\pi_2^{\\star}(0)=a$。\n\n对于 $x=1$：\n$$\nV_2(1) = \\min \\left\\{\n\\begin{array}{ll}\nu=a \\text{ 时的成本：}  c(1,a) + P(x_3=0|1,a)V_3(0) + P(x_3=1|1,a)V_3(1) \\\\\nu=b \\text{ 时的成本：}  c(1,b) + P(x_3=0|1,b)V_3(0) + P(x_3=1|1,b)V_3(1)\n\\end{array}\n\\right.\n$$\n$$\nV_2(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{7}{10} + \\frac{1}{2} \\cdot 0, \\quad 0 + 0 \\cdot \\frac{7}{10} + 1 \\cdot 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{20}, 0 \\right\\} = \\min \\left\\{ \\frac{30}{20} + \\frac{7}{20}, 0 \\right\\} = \\min \\left\\{ \\frac{37}{20}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_2(1) = 0$ 且 $\\pi_2^{\\star}(1)=b$。\n\n**$t=1$ 步 (反向递推)**\n我们使用 $V_2(0)=\\frac{7}{15}$ 和 $V_2(1)=0$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_1(x)$。\n对于 $x=0$：\n$$\nV_1(0) = \\min \\left\\{ 0 + \\frac{2}{3}V_2(0) + \\frac{1}{3}V_2(1), \\quad \\frac{3}{5} + 0 \\cdot V_2(0) + 1 \\cdot V_2(1) \\right\\}\n$$\n$$\nV_1(0) = \\min \\left\\{ \\frac{2}{3} \\cdot \\frac{7}{15} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\right\\} = \\min \\left\\{ \\frac{14}{45}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{14}{45}, \\frac{27}{45} \\right\\} = \\frac{14}{45}\n$$\n当 $u=a$ 时达到最小值。因此，$V_1(0) = \\frac{14}{45}$ 且 $\\pi_1^{\\star}(0)=a$。\n\n对于 $x=1$：\n$$\nV_1(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2}V_2(0) + \\frac{1}{2}V_2(1), \\quad 0 + 0 \\cdot V_2(0) + 1 \\cdot V_2(1) \\right\\}\n$$\n$$\nV_1(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{7}{15} + \\frac{1}{2} \\cdot 0, \\quad 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{30}, 0 \\right\\} = \\min \\left\\{ \\frac{45}{30} + \\frac{7}{30}, 0 \\right\\} = \\min \\left\\{ \\frac{52}{30}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_1(1) = 0$ 且 $\\pi_1^{\\star}(1)=b$。\n\n**$t=0$ 步 (反向递推)**\n我们使用 $V_1(0)=\\frac{14}{45}$ 和 $V_1(1)=0$ 为每个状态 $x \\in \\{0,1\\}$ 计算 $V_0(x)$。\n对于 $x=0$：\n$$\nV_0(0) = \\min \\left\\{ 0 + \\frac{2}{3}V_1(0) + \\frac{1}{3}V_1(1), \\quad \\frac{3}{5} + 0 \\cdot V_1(0) + 1 \\cdot V_1(1) \\right\\}\n$$\n$$\nV_0(0) = \\min \\left\\{ \\frac{2}{3} \\cdot \\frac{14}{45} + \\frac{1}{3} \\cdot 0, \\quad \\frac{3}{5} + 0 \\right\\} = \\min \\left\\{ \\frac{28}{135}, \\frac{3}{5} \\right\\} = \\min \\left\\{ \\frac{28}{135}, \\frac{81}{135} \\right\\} = \\frac{28}{135}\n$$\n当 $u=a$ 时达到最小值。因此，$V_0(0) = \\frac{28}{135}$ 且 $\\pi_0^{\\star}(0)=a$。\n\n为求完备性，我们计算 $V_0(1)$：\n$$\nV_0(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2}V_1(0) + \\frac{1}{2}V_1(1), \\quad 0 + 0 \\cdot V_1(0) + 1 \\cdot V_1(1) \\right\\}\n$$\n$$\nV_0(1) = \\min \\left\\{ \\frac{3}{2} + \\frac{1}{2} \\cdot \\frac{14}{45} + \\frac{1}{2} \\cdot 0, \\quad 0 \\right\\} = \\min \\left\\{ \\frac{3}{2} + \\frac{7}{45}, 0 \\right\\} = \\min \\left\\{ \\frac{135}{90} + \\frac{14}{90}, 0 \\right\\} = \\min \\left\\{ \\frac{149}{90}, 0 \\right\\} = 0\n$$\n当 $u=b$ 时达到最小值。因此，$V_0(1) = 0$ 且 $\\pi_0^{\\star}(1)=b$。\n\n**最优策略总结**\n最优策略 $\\pi^{\\star} = (\\pi_0^{\\star}, \\pi_1^{\\star}, \\pi_2^{\\star})$ 如下：\n- $\\pi_0^{\\star}(0) = a, \\quad \\pi_0^{\\star}(1) = b$\n- $\\pi_1^{\\star}(0) = a, \\quad \\pi_1^{\\star}(1) = b$\n- $\\pi_2^{\\star}(0) = a, \\quad \\pi_2^{\\star}(1) = b$\n\n**最优子结构验证**\n动态规划方法本身，根据其构造，就保证了这一性质。在每一步 $(t,x)$，我们通过显式地最小化当前成本和期望未来最优成本之和来计算 $V_t(x)$。这确保了为任何从时间 $t > 0$ 开始的子问题所选择的策略对该子问题都是最优的。\n例如，我们来验证对于从 $(t,x) = (2,0)$ 开始的子问题，策略 $\\pi_2^{\\star}(0)=a$ 确实是最优的。该动作的成本是 $c(0,a) + \\mathbb{E}[V_3(x_3)|x_2=0, u_2=a] = \\frac{7}{15}$。替代动作 $u=b$ 的成本是 $c(0,b) + \\mathbb{E}[V_3(x_3)|x_2=0, u_2=b] = \\frac{3}{5}$。由于 $\\frac{7}{15}  \\frac{3}{5}$，对于从 $(2,0)$ 开始的子问题，选择 $\\pi_2^{\\star}(0)=a$ 是最优的。我们对 $V_2(0)$ 的计算正是这个验证过程。同样的逻辑适用于所有其他状态和时间。反向递推是 Bellman 最优性原理的算法实现。\n\n问题要求从 $x_0=0$ 开始的最优初始期望总成本。这就是值 $V_0(0)$。\n根据计算，$V_0(0) = \\frac{28}{135}$。这个分数已经是最简形式，因为 $28 = 2^2 \\cdot 7$ 且 $135 = 3^3 \\cdot 5$。", "answer": "$$\n\\boxed{\\frac{28}{135}}\n$$", "id": "2703371"}, {"introduction": "理论模型到实际应用的跨越，往往需要处理各种物理约束，其中执行器饱和是最常见的一种。这个练习将动态规划应用于一个带有输入约束的连续状态系统，挑战您推导出一个分段解析的值函数 [@problem_id:2703354]。解决这个问题能帮助您理解动态规划如何系统性地处理非线性约束，并揭示最优控制策略在状态空间不同区域的行为。", "problem": "考虑一个带执行器饱和的离散时间一维系统\n$$\nx_{k+1} \\;=\\; x_{k} + u_{k}, \\quad k \\in \\{0,1\\},\n$$\n服从以下硬输入约束\n$$\n|u_{k}| \\;\\le\\; 1 \\quad \\text{for all } k.\n$$\n在长度为 $2$ 的有限时域内，性能指标是二次阶段成本与终端成本之和，\n$$\nJ \\;=\\; \\sum_{k=0}^{1} \\big( x_{k}^{2} + u_{k}^{2} \\big) \\;+\\; x_{2}^{2}.\n$$\n使用 Bellman 最优性原理和动态规划 (DP)，从价值函数的定义出发，基于第一性原理推导时域内的 Bellman 递归。然后，求解步骤 $1$ 的问题以获得 $V_{1}(x_{1})$ 和最优策略 $u_{1}^{\\star}(x_{1})$，并仔细处理输入饱和问题。接下来，求解步骤 $0$ 的问题以获得 $V_{0}(x_{0})$ 和最优策略 $u_{0}^{\\star}(x_{0})$，同样要与步骤 $1$ 的解法一致地处理输入饱和问题。精确地确定在每个步骤中，最优控制在状态空间的哪些区域达到饱和，并通过在给定问题数据下有效的凸性论证来证明您的解是全局最优的。\n\n请给出价值函数 $V_{0}(x_{0})$ 作为 $x_{0}$ 的分段解析函数的精确闭式表达式，并尽可能简化。不要近似；无需四舍五入。", "solution": "该问题是一个标准的有限时域离散时间最优控制问题，具有线性动力学、二次型成本和凸约束，因此是适定的。\n\n**使用动态规划推导求解过程**\n\n求解过程从时间 $k=N=2$ 到 $k=0$ 进行反向归纳。价值函数 $V_k(x_k)$ 表示从时间 $k$ 的状态 $x_k$ 出发的最优未来成本。\n\nBellman 递归定义为：\n$$ V_k(x_k) = \\min_{|u_k| \\le 1} \\left\\{ x_k^2 + u_k^2 + V_{k+1}(x_{k+1}) \\right\\}, \\quad k=0, 1 $$\n终端条件为：\n$$ V_2(x_2) = x_2^2 $$\n\n**$k=1$ 步（最后阶段）**\n\n在阶段 $k=1$ 的价值函数是：\n$$ V_1(x_1) = \\min_{|u_1| \\le 1} \\left\\{ x_1^2 + u_1^2 + V_2(x_1 + u_1) \\right\\} = \\min_{|u_1| \\le 1} \\left\\{ x_1^2 + u_1^2 + (x_1 + u_1)^2 \\right\\} $$\n设 $J_1(u_1)$ 为要最小化的量：\n$$ J_1(u_1) = 2x_1^2 + 2x_1 u_1 + 2u_1^2 $$\n这是一个关于 $u_1$ 的严格凸二次函数。无约束最小值通过将导数设为零来求得：\n$$ \\frac{\\partial J_1}{\\partial u_1} = 2x_1 + 4u_1 = 0 \\implies u_{1,\\text{unc}} = -\\frac{1}{2}x_1 $$\n最优控制 $u_1^\\star(x_1)$ 通过将此无约束解投影到可行集 $[-1, 1]$ 上得到：\n$$ u_1^\\star(x_1) = \\text{sat}\\left(-\\frac{1}{2}x_1\\right) = \\begin{cases} 1  \\text{if } x_1  -2 \\\\ -\\frac{1}{2}x_1  \\text{if } |x_1| \\le 2 \\\\ -1  \\text{if } x_1 > 2 \\end{cases} $$\n现在我们通过将 $u_1^\\star(x_1)$ 代入 $J_1(u_1)$ 来计算价值函数 $V_1(x_1)$，这会得到一个分段函数：\n\n1.  当 $|x_1| \\le 2$ （线性区域），$u_1^\\star = -\\frac{1}{2}x_1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1\\left(-\\frac{1}{2}x_1\\right) + 2\\left(-\\frac{1}{2}x_1\\right)^2 = 2x_1^2 - x_1^2 + \\frac{1}{2}x_1^2 = \\frac{3}{2}x_1^2 $$\n2.  当 $x_1 > 2$ （饱和区域），$u_1^\\star = -1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1(-1) + 2(-1)^2 = 2x_1^2 - 2x_1 + 2 $$\n3.  当 $x_1  -2$ （饱和区域），$u_1^\\star = 1$：\n    $$ V_1(x_1) = 2x_1^2 + 2x_1(1) + 2(1)^2 = 2x_1^2 + 2x_1 + 2 $$\n\n因此，在 $k=1$ 时的价值函数为：\n$$ V_1(x_1) = \\begin{cases} 2x_1^2 + 2x_1 + 2  \\text{if } x_1 \\le -2 \\\\ \\frac{3}{2}x_1^2  \\text{if } -2  x_1  2 \\\\ 2x_1^2 - 2x_1 + 2  \\text{if } x_1 \\ge 2 \\end{cases} $$\n这个函数是连续且可微的。其导数为 $V_1'(x_1) = \\begin{cases} 4x_1+2  \\text{if } x_1 \\le -2 \\\\ 3x_1  \\text{if } -2  x_1  2 \\\\ 4x_1-2  \\text{if } x_1 \\ge 2 \\end{cases}$。\n\n**$k=0$ 步（初始阶段）**\n\n在阶段 $k=0$ 的价值函数是：\n$$ V_0(x_0) = \\min_{|u_0| \\le 1} \\left\\{ x_0^2 + u_0^2 + V_1(x_0 + u_0) \\right\\} $$\n设 $J_0(u_0) = x_0^2 + u_0^2 + V_1(x_0 + u_0)$。由于 $J_0(u_0)$ 是关于 $u_0$ 的严格凸函数，其最优解 $u_0^\\star$ 是唯一的。\n无约束最小化子满足 $\\frac{dJ_0}{du_0} = 2u_0 + V_1'(x_0+u_0) = 0$。\n\n- 在 $u_0^\\star = -1$ 处饱和：这发生在 $\\left. \\frac{dJ_0}{du_0} \\right|_{u_0=-1} \\ge 0 \\implies 2(-1) + V_1'(x_0-1) \\ge 0 \\implies V_1'(x_0-1) \\ge 2$。使用 $V_1'(x_1)$ 的表达式，这成立的条件是 $x_0-1 \\ge 2/3$，即 $x_0 \\ge 5/3$。\n\n- 在 $u_0^\\star = 1$ 处饱和：这发生在 $\\left. \\frac{dJ_0}{du_0} \\right|_{u_0=1} \\le 0 \\implies 2(1) + V_1'(x_0+1) \\le 0 \\implies V_1'(x_0+1) \\le -2$。这成立的条件是 $x_0+1 \\le -2/3$，即 $x_0 \\le -5/3$。\n\n- 线性区域：对于 $|x_0| \\le 5/3$，控制是非饱和的。此时 $x_1 = x_0+u_0$ 处于 $V_1$ 的线性区域，最优性条件 $2u_0 + 3(x_0+u_0) = 0$ 给出 $5u_0+3x_0=0$，因此 $u_{0}^\\star = -\\frac{3}{5}x_0$。\n\n最优策略是：\n$$ u_0^\\star(x_0) = \\begin{cases} 1  \\text{if } x_0 \\le -5/3 \\\\ -\\frac{3}{5}x_0  \\text{if } |x_0| \\le 5/3 \\\\ -1  \\text{if } x_0 \\ge 5/3 \\end{cases} $$\n现在我们分段计算价值函数 $V_0(x_0)$：\n\n1.  对于 $|x_0| \\le 5/3$：$u_0^\\star = -3x_0/5$，$x_1 = 2x_0/5$ (在 $(-2,2)$ 区间内)。\n    $$ V_0(x_0) = x_0^2 + \\left(-\\frac{3}{5}x_0\\right)^2 + V_1\\left(\\frac{2}{5}x_0\\right) = x_0^2 + \\frac{9}{25}x_0^2 + \\frac{3}{2}\\left(\\frac{2}{5}x_0\\right)^2 = \\frac{8}{5}x_0^2 $$\n\n2.  对于 $x_0 > 5/3$：$u_0^\\star = -1$，$x_1 = x_0-1$。边界是 $x_1=2 \\implies x_0=3$。\n    - 对于 $5/3  x_0 \\le 3$：$x_1 \\in (2/3, 2]$，所以 $V_1(x_1) = \\frac{3}{2}x_1^2$。\n      $$ V_0(x_0) = x_0^2 + 1 + \\frac{3}{2}(x_0-1)^2 = \\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2} $$\n    - 对于 $x_0 > 3$：$x_1 > 2$，所以 $V_1(x_1) = 2x_1^2-2x_1+2$。\n      $$ V_0(x_0) = x_0^2 + 1 + 2(x_0-1)^2 - 2(x_0-1) + 2 = 3x_0^2 - 6x_0 + 7 $$\n\n3.  对于 $x_0  -5/3$：$u_0^\\star = 1$，$x_1=x_0+1$。边界是 $x_1=-2 \\implies x_0=-3$。\n    - 对于 $-3 \\le x_0  -5/3$：$x_1 \\in [-2, -2/3)$，所以 $V_1(x_1) = \\frac{3}{2}x_1^2$。\n      $$ V_0(x_0) = x_0^2+1+\\frac{3}{2}(x_0+1)^2 = \\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2} $$\n    - 对于 $x_0  -3$：$x_1  -2$，所以 $V_1(x_1) = 2x_1^2+2x_1+2$。\n      $$ V_0(x_0) = x_0^2+1+2(x_0+1)^2+2(x_0+1)+2 = 3x_0^2+6x_0+7 $$\n\n由于总成本函数是控制变量的严格凸函数，且可行集是紧凸集，DP算法找到的唯一解是全局最优解。\n\n价值函数 $V_0(x_0)$ 的最终表达式为：\n$$ V_0(x_0) = \\begin{cases}\n3x_0^2 + 6x_0 + 7  \\text{if } x_0 \\le -3 \\\\\n\\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2}  \\text{if } -3  x_0 \\le -5/3 \\\\\n\\frac{8}{5}x_0^2  \\text{if } |x_0| \\le 5/3 \\\\\n\\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2}  \\text{if } 5/3  x_0 \\le 3 \\\\\n3x_0^2 - 6x_0 + 7  \\text{if } x_0 > 3\n\\end{cases} $$", "answer": "$$\n\\boxed{\nV_0(x_0) = \\begin{cases}\n3x_0^2 + 6x_0 + 7   \\text{if } x_0 \\le -3 \\\\\n\\frac{5}{2}x_0^2 + 3x_0 + \\frac{5}{2}   \\text{if } -3  x_0 \\le -\\frac{5}{3} \\\\\n\\frac{8}{5}x_0^2   \\text{if } -\\frac{5}{3}  x_0  \\frac{5}{3} \\\\\n\\frac{5}{2}x_0^2 - 3x_0 + \\frac{5}{2}   \\text{if } \\frac{5}{3} \\le x_0 \\le 3 \\\\\n3x_0^2 - 6x_0 + 7   \\text{if } x_0 > 3\n\\end{cases}\n}\n$$", "id": "2703354"}, {"introduction": "贝尔曼最优性原理的强大之处在于其广泛的适用性，它不仅限于传统的反馈控制设计。这个练习将带您探索动态规划在最优停时问题中的应用，这是一类在金融、经济学和运筹学中至关重要的问题 [@problem_id:2703363]。通过推导并求解一个具体的最优停时问题，您将学会如何构建相应的贝尔曼方程，并确定最佳决策边界。", "problem": "考虑一个实值状态过程 $\\{x_{t}\\}_{t \\in \\mathbb{N}_{0}}$ 的离散时间最优停时问题，其初始条件为 $x_{0}=x \\in \\mathbb{R}$。在每个时间点 $t$，决策者选择停止并获得即时奖励，或者选择继续并获得一个运行时奖励，并有权在下一个时间点再次决策。当决策为继续时，系统根据一个时齐转移规律演化。目标是最大化期望总贴现奖励。假设贴现因子为 $\\gamma \\in (0,1)$，即时停止奖励由一个可测函数 $\\psi:\\mathbb{R}\\to\\mathbb{R}$ 给出，运行时奖励由一个可测函数 $\\ell:\\mathbb{R}\\to\\mathbb{R}$ 给出，并且在继续的情况下，从 $x$ 到下一个状态 $x'$ 的转移服从一个条件分布，使得条件期望 $\\mathbb{E}[\\cdot \\mid x]$ 是良定义的。\n\n- 仅使用最优性原理和条件期望的塔性质，推导描述该最优停时问题最优值函数 $V:\\mathbb{R}\\to\\mathbb{R}$ 的动态规划方程。清晰地陈述你为证明推导过程而施加的任何正则性条件。\n\n- 现在，将问题具体化为一个一维例子，在继续的情况下具有确定性线性动力学，由 $x_{t+1}=\\lambda x_{t}$ 给出，其中 $\\lambda \\in \\mathbb{R}$ 为定值，运行时奖励为 $\\ell(x)=-q x^{2}$ (其中 $q0$)，停止奖励为 $\\psi(x)=A - B x^{2}$ (其中 $A0$ 且 $B0$)。假设 $\\gamma \\lambda^{2}  1$ 且 $B > \\frac{q}{1-\\gamma \\lambda^{2}}$。\n\n  使用你的动态规划方程，通过假设一个在动力学和奖励下不变的适当函数形式，求解继续区域中的值函数。然后，确定阈值 $x^{\\star}0$，使得最优停止区域为 $\\{x \\in \\mathbb{R} : |x| \\leq x^{\\star}\\}$。用 $A$、$B$、$q$、$\\gamma$ 和 $\\lambda$ 以闭式形式表示 $x^{\\star}$。\n\n- 最后，对具体参数值 $A=3$, $B=5$, $q=1$, $\\gamma=\\frac{1}{2}$ 和 $\\lambda=\\frac{1}{2}$ 计算 $x^{\\star}$。只报告 $x^{\\star}$ 的精确值作为最终答案。不要四舍五入或近似计算。", "solution": "### 第 1 部分：动态规划方程的推导\n\n设 $V(x)$ 为最优值函数，表示从状态 $x_0 = x$ 开始的最大期望总贴现奖励。在任何状态 $x$，决策者可以选择两种行动之一：\n1.  **停止**：过程终止，决策者获得终点奖励 $\\psi(x)$。\n2.  **继续**：决策者获得即时运行时奖励 $\\ell(x)$，然后系统转移到新状态 $x'$。根据最优性原理，从此刻起的总期望奖励为 $\\ell(x) + \\gamma \\mathbb{E}[V(x') \\mid x]$。\n\nBellman 的最优性原理指出，最优值函数 $V(x)$ 必须是与每个可能的初始行动相关联的值中的最大者。因此，该最优停时问题的动态规划方程（或称 Bellman 方程）为：\n$$V(x) = \\max \\left\\{ \\psi(x), \\quad \\ell(x) + \\gamma \\mathbb{E}[V(x') \\mid x] \\right\\}$$\n此方程是关于 $V(x)$ 的一个泛函方程。为了保证此方程解 $V(x)$ 的存在性和唯一性，并证明推导的合理性，需要某些正则性条件。通常，我们假设奖励函数 $\\psi(x)$ 和 $\\ell(x)$ 是有界的，并且算子 $T(f)(x) = \\max\\{\\psi(x), \\ell(x) + \\gamma \\mathbb{E}[f(x') \\mid x]\\}$ 是在具有上确界范数的有界连续函数空间上的一个压缩映射。条件 $\\gamma \\in (0,1)$ 对此至关重要，它使得 $T$ 成为一个压缩映射，并根据 Banach 不动点定理确保值迭代收敛到一个唯一的不动点。\n\n### 第 2 部分：具体例子的求解\n\n我们有以下具体设定：\n- 动力学：$x_{t+1} = \\lambda x_t$。这是确定性的，所以 $\\mathbb{E}[f(x_{t+1}) | x_t] = f(\\lambda x_t)$。\n- 运行时奖励：$\\ell(x) = -q x^2$。\n- 停止奖励：$\\psi(x) = A - B x^2$。\n\n动态规划方程简化为：\n$$V(x) = \\max \\left\\{ A - Bx^2, \\quad -qx^2 + \\gamma V(\\lambda x) \\right\\}$$\n状态空间被划分为一个停止区域 $S$ 和一个继续区域 $C$。\n- 在停止区域 $S$ 中，$V(x) = \\psi(x) = A - Bx^2$。\n- 在继续区域 $C$ 中，$V(x) = \\ell(x) + \\gamma V(\\lambda x) = -qx^2 + \\gamma V(\\lambda x)$。\n\n鉴于奖励函数是二次形式，我们假设继续区域中的值函数也为二次形式，$V_c(x) = K - Px^2$，其中 $K$ 和 $P$ 为待定常数。将该形式代入继续区域的方程中：\n$$K - Px^2 = -qx^2 + \\gamma (K - P(\\lambda x)^2)$$\n$$K - Px^2 = -qx^2 + \\gamma K - \\gamma P \\lambda^2 x^2$$\n为了使该方程在继续区域中的所有 $x$ 上都成立，我们匹配 $x$ 的各次幂的系数：\n- 常数项：$K = \\gamma K \\implies K(1-\\gamma) = 0 \\implies K=0$ (因为 $\\gamma \\in (0,1)$)。\n- $x^2$ 项：$-P = -q - \\gamma P \\lambda^2 \\implies P(1 - \\gamma \\lambda^2) = q$。\n\n由于 $\\gamma \\lambda^2  1$ 且 $q>0$，我们可以解出 $P$：\n$$P = \\frac{q}{1 - \\gamma \\lambda^2}$$\n因此，在继续区域中的值函数是 $V_c(x) = -Px^2 = -\\frac{q}{1 - \\gamma \\lambda^2}x^2$。\n\n最优策略是在停止奖励至少与继续的价值相等时停止。停止区域由 $\\psi(x) \\geq V_c(x)$ 定义。其边界由值匹配条件 $\\psi(x) = V_c(x)$ 给出。\n$$A - Bx^2 = -\\frac{q}{1 - \\gamma \\lambda^2}x^2$$\n$$A = \\left( B - \\frac{q}{1 - \\gamma \\lambda^2} \\right) x^2$$\n问题给出了约束条件 $B > \\frac{q}{1-\\gamma \\lambda^2}$，这确保了 $x^2$ 的系数为正。因此，\n$$x^2 = \\frac{A}{B - \\frac{q}{1 - \\gamma \\lambda^2}}$$\n阈值为 $x = \\pm \\sqrt{\\frac{A}{B - \\frac{q}{1-\\gamma \\lambda^2}}}$。因为 $x^\\star > 0$，我们有：\n$$x^{\\star} = \\sqrt{\\frac{A}{B - \\frac{q}{1-\\gamma \\lambda^2}}}$$\n停止区域为 $\\{x \\in \\mathbb{R} : |x| \\le x^\\star\\}$。\n\n### 第 3 部分：数值计算\n\n给定参数为：$A=3$, $B=5$, $q=1$, $\\gamma=\\frac{1}{2}$ 和 $\\lambda=\\frac{1}{2}$。\n首先，验证约束条件：\n- $\\gamma \\lambda^2 = \\frac{1}{2} \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{8}  1$。\n- $\\frac{q}{1-\\gamma \\lambda^2} = \\frac{1}{1 - 1/8} = \\frac{8}{7}$。条件 $B > \\frac{8}{7}$ 即 $5 > \\frac{8}{7}$ 成立。\n\n现在，我们将这些值代入 $x^{\\star}$ 的表达式中：\n$$x^{\\star} = \\sqrt{\\frac{A}{B - \\frac{q}{1 - \\gamma\\lambda^2}}} = \\sqrt{\\frac{3}{5 - \\frac{8}{7}}}$$\n$$x^{\\star} = \\sqrt{\\frac{3}{\\frac{35-8}{7}}} = \\sqrt{\\frac{3}{\\frac{27}{7}}}$$\n$$x^{\\star} = \\sqrt{\\frac{21}{27}} = \\sqrt{\\frac{7}{9}}$$\n$$x^{\\star} = \\frac{\\sqrt{7}}{3}$$\n停止阈值的精确值为 $\\frac{\\sqrt{7}}{3}$。", "answer": "$$\\boxed{\\frac{\\sqrt{7}}{3}}$$", "id": "2703363"}]}