{"hands_on_practices": [{"introduction": "Superdense coding is a cornerstone protocol demonstrating that quantum entanglement can boost communication efficiency. However, perfect entanglement is an idealization. This exercise explores the practical impact of noise by calculating the classical data rate achievable when the shared resource is a noisy Werner state, connecting the state's fidelity to the channel's capacity via the Holevo quantity [@problem_id:54873].", "problem": "In the standard superdense coding protocol, Alice can send two classical bits to Bob by sending a single qubit, provided they share a maximally entangled Bell state. This problem explores how the communication rate is affected when the shared entangled state is noisy.\n\nSuppose Alice and Bob share a two-qubit state described by the Werner state density matrix:\n$$ \\rho_W = F |\\Psi^-\\rangle\\langle\\Psi^-| + \\frac{1-F}{3}(I - |\\Psi^-\\rangle\\langle\\Psi^-|) $$\nwhere $|\\Psi^-\\rangle = \\frac{1}{\\sqrt{2}}(|01\\rangle - |10\\rangle)$ is a Bell state, $I$ is the $4 \\times 4$ identity matrix, and $F$ is the fidelity of the state with respect to $|\\Psi^-\\rangle$, with $F \\in [1/4, 1]$.\n\nThe communication protocol is as follows: to send one of four possible messages $m \\in \\{0, 1, 2, 3\\}$, Alice applies a corresponding unitary operation $U_m$ from the set $\\{I, \\sigma_x, \\sigma_z, i\\sigma_y\\}$ to her qubit. Here, $\\sigma_x$ and $\\sigma_z$ are the standard Pauli matrices, and $I$ is the $2 \\times 2$ identity. After applying the operation, she sends her qubit to Bob. Bob then possesses the full two-qubit system. Assume that each message is chosen with equal probability $p_m = 1/4$.\n\nDetermine the maximum rate of reliable classical communication, in bits per qubit sent, achievable with this protocol. Express your answer as a closed-form analytic expression in terms of the fidelity $F$.", "solution": "1. The communication rate is given by the Holevo quantity  \n$$\\chi = S\\bigl(\\bar\\rho\\bigr) - \\sum_m p_m S(\\rho_m)\\,. $$  \nHere $p_m=1/4$, $\\rho_m=(U_m\\otimes I)\\rho_W(U_m^\\dagger\\otimes I)$, and $\\bar\\rho=\\sum_m p_m\\rho_m$.  \n\n2. The entropy of each state $\\rho_m$ is the same as the original state $\\rho_W$ because unitary operations do not change the eigenvalues of a density matrix. Thus:\n$$\\sum_m p_m S(\\rho_m) = \\sum_m \\frac{1}{4} S(\\rho_W) = S(\\rho_W)\\,. $$  \n\n3. The average state $\\bar{\\rho}$ is the result of applying a twirling operation on Alice's qubit. For any two-qubit state, this operation results in a state of the form $\\frac{I_A}{2} \\otimes \\text{Tr}_A(\\rho_W)$. Since the reduced state of the Werner state is maximally mixed ($\\text{Tr}_A(\\rho_W) = I_B/2$), the average state is the maximally mixed two-qubit state:\n$$\\bar\\rho=\\frac{I_A}{2} \\otimes \\frac{I_B}{2} = \\frac I4\\implies S(\\bar\\rho)=\\log_2 4=2\\,. $$  \n\n4. Thus the Holevo information is:  \n$$\\chi =2 - S(\\rho_W)\\,. $$\n\n5. The given Werner state is Bell-diagonal with eigenvalues  \n$$\\lambda_1=F,\\quad \\lambda_{2,3,4}=\\frac{1-F}3\\,. $$  \nIts von Neumann entropy is therefore:\n$$S(\\rho_W)=-\\Bigl[F\\log_2F+3\\cdot\\frac{1-F}3\\log_2\\frac{1-F}3\\Bigr] \n=-F\\log_2F-(1-F)\\log_2\\frac{1-F}3\\,. $$\n\n6. Substituting this into the expression for $\\chi$, the maximum rate is:  \n$$\\chi\n=2 + F\\log_2F + (1-F)\\log_2\\frac{1-F}3\\,. $$", "answer": "$$\\boxed{2 + F\\log_2 F + (1-F)\\log_2\\frac{1-F}{3}}$$", "id": "54873"}, {"introduction": "A central question in information theory is how to communicate without any errors. While classical theory provides one answer, quantum mechanics offers another, more powerful one when entanglement is available. This problem provides a striking demonstration of this quantum advantage by calculating the zero-error capacity for a channel whose confusability is described by the pentagon graph, showing how the abstract Lovász number quantifies the real benefit of shared entanglement [@problem_id:54976].", "problem": "In classical Shannon theory, the zero-error capacity of a discrete memoryless channel is determined by the properties of its \"confusability graph\" $G$. The vertices of $G$ represent the input symbols of the channel, and an edge connects two vertices if their corresponding symbols can be confused at the output (i.e., there is at least one output symbol that can be produced by either input symbol). To achieve error-free communication, one must use a set of input symbols such that no two are ever confused. This corresponds to an independent set of vertices in $G$. The maximum number of messages one can send with zero error in a single use of the channel is therefore given by the independence number $\\alpha(G)$, which is the size of the largest independent set in $G$. The classical zero-error capacity is $C_0 = \\log_2 \\alpha(G)$.\n\nQuantum Shannon theory reveals that if the sender and receiver share prior entanglement, they can surpass this classical limit. The entanglement-assisted zero-error capacity is given by $C_{0,E} = \\log_2 \\vartheta(G)$, where $\\vartheta(G)$ is the Lovász number of the graph $G$. The quantity $\\vartheta(G)$ represents the maximum number of messages that can be sent with zero error in a single use of the channel with the help of entanglement.\n\nFor a $k$-regular, edge-transitive graph $G$ on $n$ vertices, the Lovász number can be calculated using its adjacency matrix $A_G$. If $\\lambda_{\\text{min}}$ is the smallest eigenvalue of $A_G$, the Lovász number is given by the formula:\n$$ \\vartheta(G) = \\frac{-n \\lambda_{\\text{min}}}{k - \\lambda_{\\text{min}}} $$\n\nConsider a channel whose confusability graph is the 5-cycle graph, $C_5$. This graph has 5 vertices, labeled $0, 1, 2, 3, 4$, with edges connecting adjacent vertices in the cycle, i.e., $(i, (i+1) \\pmod 5)$. Calculate the ratio $R$ of the maximum number of perfectly distinguishable messages with entanglement assistance to the classical maximum for a single use of this channel. That is, compute $R = \\frac{\\vartheta(C_5)}{\\alpha(C_5)}$.", "solution": "The problem requires calculating the ratio $ R = \\frac{\\vartheta(C_5)}{\\alpha(C_5)} $, where $ C_5 $ is the 5-cycle graph.\n\n1.  **Find the independence number $\\alpha(C_5)$:**\n    The independence number $\\alpha(G)$ is the size of the largest set of vertices in which no two vertices are adjacent. For the 5-cycle graph ($v_0-v_1-v_2-v_3-v_4-v_0$), we can pick at most 2 vertices without them being connected. For example, $\\{v_0, v_2\\}$ is an independent set, but $\\{v_0, v_1, v_3\\}$ is not. Thus, the size of the largest independent set is 2.\n    $$\n    \\alpha(C_5) = 2\n    $$\n\n2.  **Compute the Lovász number $\\vartheta(C_5)$:**\n    We use the provided formula for a $k$-regular, edge-transitive graph:\n    $$\n    \\vartheta(G) = \\frac{-n \\lambda_{\\text{min}}}{k - \\lambda_{\\text{min}}}\n    $$\n    For the graph $C_5$:\n    -   Number of vertices $n = 5$.\n    -   It is a 2-regular graph, so $k = 2$.\n\n    The eigenvalues of the adjacency matrix of a cycle graph $C_n$ are given by $\\lambda_j = 2 \\cos\\left(\\frac{2\\pi j}{n}\\right)$ for $j = 0, 1, \\dots, n-1$. For $n=5$, the smallest eigenvalue occurs when the cosine is most negative, which is for $j=2$ or $j=3$.\n    $$\n    \\lambda_{\\text{min}} = 2 \\cos\\left(\\frac{4\\pi}{5}\\right) = 2 \\cdot \\left(-\\frac{\\sqrt{5} + 1}{4}\\right) = -\\frac{\\sqrt{5} + 1}{2}\n    $$\n    Now, substitute these values into the formula for $\\vartheta(C_5)$:\n    $$\n    \\vartheta(C_5) = \\frac{-5 \\left(-\\frac{\\sqrt{5} + 1}{2}\\right)}{2 - \\left(-\\frac{\\sqrt{5} + 1}{2}\\right)} = \\frac{5(\\sqrt{5} + 1)/2}{(4 + \\sqrt{5} + 1)/2} = \\frac{5(\\sqrt{5} + 1)}{5 + \\sqrt{5}}\n    $$\n    To simplify this expression, factor $\\sqrt{5}$ from the denominator:\n    $$\n    \\vartheta(C_5) = \\frac{5(\\sqrt{5} + 1)}{\\sqrt{5}(\\sqrt{5} + 1)} = \\frac{5}{\\sqrt{5}} = \\sqrt{5}\n    $$\n\n3.  **Calculate the ratio $R$:**\n    $$\n    R = \\frac{\\vartheta(C_5)}{\\alpha(C_5)} = \\frac{\\sqrt{5}}{2}\n    $$", "answer": "$$ \\boxed{\\dfrac{\\sqrt{5}}{2}} $$", "id": "54976"}, {"introduction": "The distinction between classical and quantum information is nowhere more critical than in cryptography. This exercise puts you in the role of a security analyst tasked with quantifying the risk of underestimating an adversary. By calculating and comparing the secret key rates achievable against an eavesdropper with classical versus full quantum side-information, you will determine the precise security cost of using a simplified classical model for a quantum channel [@problem_id:54927].", "problem": "**Problem Statement**\n\nIn the theory of quantum key distribution (QKD), the achievable secret key rate depends crucially on the nature of the eavesdropper's (Eve's) side information. Consider a quantum communication scenario where Alice sends qubits to Bob through a correlated Pauli channel $\\mathcal{N}$. The action of the channel on a state $\\rho$ is given by:\n$$\n\\mathcal{N}(\\rho) = p_I \\rho + p_X X\\rho X + p_Y Y\\rho Y + p_Z Z\\rho Z,\n$$\nwhere $\\{I, X, Y, Z\\}$ are the Pauli matrices and $\\{p_I, p_X, p_Y, p_Z\\}$ are the probabilities of the corresponding errors occurring, with $\\sum_k p_k = 1$.\n\nWe analyze the reduction in the secret key rate when Eve's power is upgraded. We compare two scenarios for her side information:\n\n**Scenario C (Classical Side Information):** Eve has classical knowledge of which Pauli error occurred for each transmitted qubit, but she does not retain any quantum correlation with the system. In this case, the one-way (A to B classical communication) distillable private key rate, denoted $K_C$, is given by the private capacity of the channel:\n$$\nK_C = \\max(0, 1 - h_2(e_b) - h_2(e_p))\n$$\nwhere $h_2(x) = -x\\log_2(x) - (1-x)\\log_2(1-x)$ is the binary entropy function, $e_b = p_X + p_Y$ is the bit-flip error rate, and $e_p = p_Y + p_Z$ is the phase-flip error rate.\n\n**Scenario Q (Quantum Side Information):** Eve holds the full quantum system that purifies the channel's noise process. This represents the most powerful attack allowed by quantum mechanics. The key rate under this condition, $K_Q$, is limited by the quantum capacity of the channel, as all Pauli channels are degradable:\n$$\nK_Q = \\max(0, 1 - H(\\{p_k\\}))\n$$\nwhere $H(\\{p_k\\}) = -\\sum_{k \\in \\{I,X,Y,Z\\}} p_k \\log_2(p_k)$ is the Shannon entropy of the error probability distribution.\n\n**Problem:**\nConsider a specific instance of this correlated Pauli channel defined by the error probabilities:\n$p_X = 0$, $p_Y = p$, $p_Z = p$, and $p_I = 1-2p$. The parameter $p$ is a real number in the range $0 \\le p \\le 1/2$.\n\nDerive the exact analytical expression for the reduction in the secret key rate, $\\Delta K = K_C - K_Q$, for the specific parameter value of $p = 1/3$. Assume the rates are positive in both scenarios.", "solution": "1. **State the relevant equations and parameters:**\n   The secret key rates are given by:\n   $$\n   K_C = 1 - h_2(e_b) - h_2(e_p)\n   $$\n   $$\n   K_Q = 1 - H(\\{p_k\\})\n   $$\n   The error probabilities are $p_X = 0$, $p_Y = p$, $p_Z = p$, and $p_I = 1-2p$. We are given $p = 1/3$.\n   This gives the distribution $\\{p_k\\}$:\n   $$\n   p_I = 1 - 2(1/3) = 1/3, \\quad p_X = 0, \\quad p_Y = 1/3, \\quad p_Z = 1/3\n   $$\n   The bit-flip and phase-flip error rates are:\n   $$\n   e_b = p_X + p_Y = 0 + 1/3 = 1/3\n   $$\n   $$\n   e_p = p_Y + p_Z = 1/3 + 1/3 = 2/3\n   $$\n\n2. **Calculate the classical side-information rate $K_C$:**\n   We need the binary entropies $h_2(1/3)$ and $h_2(2/3)$. Due to the symmetry $h_2(x) = h_2(1-x)$, these are equal.\n   $$\n   h_2(1/3) = -\\frac{1}{3}\\log_2\\left(\\frac{1}{3}\\right) - \\frac{2}{3}\\log_2\\left(\\frac{2}{3}\\right) = \\frac{1}{3}\\log_2(3) - \\frac{2}{3}(\\log_2(2) - \\log_2(3)) = \\frac{1}{3}\\log_2(3) - \\frac{2}{3} + \\frac{2}{3}\\log_2(3) = \\log_2(3) - \\frac{2}{3}\n   $$\n   So, $h_2(1/3) = h_2(2/3) = \\log_2(3) - 2/3$.\n   Then, the key rate is:\n   $$\n   K_C = 1 - h_2(1/3) - h_2(2/3) = 1 - 2\\left(\\log_2(3) - \\frac{2}{3}\\right) = 1 - 2\\log_2(3) + \\frac{4}{3} = \\frac{7}{3} - 2\\log_2(3)\n   $$\n\n3. **Calculate the quantum side-information rate $K_Q$:**\n   We need the Shannon entropy $H(\\{p_k\\})$ for the distribution $\\{1/3, 0, 1/3, 1/3\\}$.\n   $$\n   H(\\{p_k\\}) = -\\left( \\frac{1}{3}\\log_2\\frac{1}{3} + 0 + \\frac{1}{3}\\log_2\\frac{1}{3} + \\frac{1}{3}\\log_2\\frac{1}{3} \\right) = -3 \\cdot \\frac{1}{3}\\log_2\\frac{1}{3} = -\\log_2\\frac{1}{3} = \\log_2(3)\n   $$\n   The key rate is:\n   $$\n   K_Q = 1 - H(\\{p_k\\}) = 1 - \\log_2(3)\n   $$\n\n4. **Calculate the reduction in key rate $\\Delta K$:**\n   The reduction is the difference between the two rates.\n   $$\n   \\Delta K = K_C - K_Q = \\left(\\frac{7}{3} - 2\\log_2(3)\\right) - \\left(1 - \\log_2(3)\\right) = \\left(\\frac{7}{3} - 1\\right) - (2\\log_2(3) - \\log_2(3)) = \\frac{4}{3} - \\log_2(3)\n   $$", "answer": "$$\\boxed{\\frac{4}{3}-\\log_2(3)}$$", "id": "54927"}]}