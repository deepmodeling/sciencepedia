{"hands_on_practices": [{"introduction": "In classical information theory, entropy is a measure of uncertainty, and its various forms can be neatly visualized with Venn diagrams. However, the quantum world often defies classical intuition. This first exercise provides a striking example by asking you to compute the fundamental entropic quantities for a maximally entangled Bell state. By doing so, you will uncover the concept of negative conditional entropy, a purely quantum phenomenon that signals the presence of entanglement stronger than any classical correlation and explains why the simple Venn diagram analogy breaks down. [@problem_id:1667629]", "problem": "In classical information theory, the relationships between the Shannon entropies of different random variables can be intuitively visualized using Venn diagrams, where the area of a region corresponds to the entropy of the associated variable or set of variables. For example, for two random variables $X$ and $Y$, the joint entropy $H(X,Y)$, individual entropies $H(X)$ and $H(Y)$, and mutual information $I(X;Y) = H(X) + H(Y) - H(X,Y)$ are all non-negative quantities that correspond to areas in such a diagram. This geometric picture relies on the non-negativity of conditional entropies, such as $H(X|Y) = H(X,Y) - H(Y) \\ge 0$.\n\nConsider a bipartite quantum system consisting of two qubits, labeled A and B. The combined system is prepared in the maximally entangled Bell state given by $|\\Psi\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle_A \\otimes |1\\rangle_B - |1\\rangle_A \\otimes |0\\rangle_B)$. The von Neumann entropy of a quantum state described by a density matrix $\\rho$ is defined as $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$. Let $\\rho_{AB}$ be the density matrix for the combined system, and let $\\rho_A = \\text{Tr}_B(\\rho_{AB})$ and $\\rho_B = \\text{Tr}_A(\\rho_{AB})$ be the reduced density matrices for subsystems A and B, respectively. The entropies for the joint system and the subsystems are $S(A,B) = S(\\rho_{AB})$, $S(A) = S(\\rho_A)$, and $S(B) = S(\\rho_B)$.\n\nInspired by the classical definitions, we can define the quantum conditional entropy as $S(A|B) = S(A,B) - S(B)$ and the quantum mutual information as $I(A:B) = S(A) + S(B) - S(A,B)$.\n\nWhich of the following information-theoretic quantities, when calculated for this specific entangled state, takes on a negative value, thereby demonstrating a fundamental breakdown of the classical area-based Venn diagram analogy for quantum information?\n\nA. The joint entropy, $S(A,B)$.\n\nB. The quantum mutual information, $I(A:B)$.\n\nC. The conditional entropy, $S(A|B)$.\n\nD. The entropy of subsystem A, $S(A)$.\n\nE. The sum of the subsystem entropies, $S(A) + S(B)$.", "solution": "We are given the bipartite pure state of two qubits,\n$$\n|\\Psi\\rangle=\\frac{1}{\\sqrt{2}}\\big(|0\\rangle_{A}\\otimes|1\\rangle_{B}-|1\\rangle_{A}\\otimes|0\\rangle_{B}\\big).\n$$\nThe density matrix for this pure state is $\\rho_{AB}=|\\Psi\\rangle\\langle\\Psi|$. The von Neumann entropy is defined as $S(\\rho)=-\\operatorname{Tr}(\\rho\\log_2\\rho)$, measured in bits.\n\n1.  **Entropy of the joint system, $S(A,B)$**:\n    Since the combined system is in a pure state, its density matrix $\\rho_{AB}$ has one eigenvalue equal to 1 and all others equal to 0. Therefore, the entropy is:\n    $$\n    S(A,B)=S(\\rho_{AB})=-\\big(1\\cdot\\log_2 1+\\sum_{i}0\\cdot\\log_2 0\\big)=0.\n    $$\n    Here we use the convention that $0\\log_2 0=0$. Option A is non-negative.\n\n2.  **Reduced density matrices and subsystem entropies, $S(A)$ and $S(B)$**:\n    We find the reduced density matrix for subsystem A by tracing over subsystem B:\n    $$\n    \\rho_A = \\operatorname{Tr}_B(\\rho_{AB}) = \\operatorname{Tr}_B\\left(\\frac{1}{2}\\Big(|01\\rangle\\langle 01|-|01\\rangle\\langle 10|-|10\\rangle\\langle 01|+|10\\rangle\\langle 10|\\Big)\\right).\n    $$\n    This yields:\n    $$\n    \\rho_{A}=\\frac{1}{2}\\big(|0\\rangle\\langle 0|+|1\\rangle\\langle 1|\\big)=\\frac{I_{A}}{2}.\n    $$\n    This is the maximally mixed state for a single qubit. Its eigenvalues are $\\{1/2, 1/2\\}$. The entropy is:\n    $$\n    S(A)=S(\\rho_{A})=-\\sum_{i=1}^{2}\\frac{1}{2}\\log_2\\Big(\\frac{1}{2}\\Big)=-2 \\left(\\frac{1}{2} \\cdot (-1)\\right) = 1 \\text{ bit}.\n    $$\n    By symmetry, the reduced state for B is also maximally mixed, $\\rho_{B}=I_{B}/2$, so $S(B) = 1$ bit.\n    Option D, $S(A)$, is positive. Option E, $S(A)+S(B)=2$, is also positive.\n\n3.  **Quantum mutual information, $I(A:B)$**:\n    By definition:\n    $$\n    I(A:B)=S(A)+S(B)-S(A,B)=1 + 1 - 0 = 2 \\text{ bits}.\n    $$\n    Option B is positive.\n\n4.  **Quantum conditional entropy, $S(A|B)$**:\n    By definition:\n    $$\n    S(A|B)=S(A,B)-S(B)=0-1=-1 \\text{ bit}.\n    $$\n    This quantity is negative. For a classical system, conditional entropy is always non-negative, representing the remaining uncertainty. The negative value here is a hallmark of quantum entanglement, showing that classical intuition (and Venn diagrams) fails.\n\nThe only quantity among the options that is negative is the conditional entropy $S(A|B)$.", "answer": "$$\\boxed{C}$$", "id": "1667629"}, {"introduction": "Having established that quantum entropy has unique features, we now turn to its evolution. Quantum systems are rarely static; their interactions cause their correlations to change over time. This practice invites you to analyze two interacting qubits, starting from a simple product state, and to calculate their mutual information as a function of time. This will provide a dynamic picture of how entanglement is generated and oscillates, revealing the flow of information within a closed quantum system. [@problem_id:94563]", "problem": "Consider a system of two interacting qubits, labeled A and B. The dynamics of the system are governed by the XY Hamiltonian:\n$$ H = J (\\sigma_A^x \\sigma_B^x + \\sigma_A^y \\sigma_B^y) $$\nwhere $J$ is a real coupling constant with dimensions of energy, and $\\sigma_A^i$ and $\\sigma_B^i$ (for $i=x,y,z$) are the standard Pauli matrices acting on the Hilbert space of qubit A and B, respectively. The computational basis for a single qubit is $\\{|0\\rangle, |1\\rangle\\}$.\n\nAt time $t=0$, the system is prepared in the separable initial state $|\\psi(0)\\rangle = |0\\rangle_A \\otimes |1\\rangle_B$.\n\nThe von Neumann entropy of a quantum state with density matrix $\\rho$ is defined as $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$. The quantum mutual information $I(A:B)$ quantifies the total correlations between subsystems a and B and is given by:\n$$ I(A:B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB}) $$\nwhere $\\rho_{AB}$ is the density matrix of the total system, and $\\rho_A = \\text{Tr}_B(\\rho_{AB})$ and $\\rho_B = \\text{Tr}_A(\\rho_{AB})$ are the reduced density matrices of the two subsystems.\n\nCalculate the quantum mutual information $I(A:B)$ as a function of time $t$. Express your answer in terms of the coupling constant $J$, time $t$, and the reduced Planck constant $\\hbar$.", "solution": "The Hamiltonian is given by $ H = J (\\sigma_A^x \\sigma_B^x + \\sigma_A^y \\sigma_B^y) $. Using the raising and lowering operators, $ \\sigma^\\pm = \\frac{1}{2} (\\sigma^x \\pm i \\sigma^y) $, the Hamiltonian simplifies to:\n$$\nH = 2J (\\sigma_A^+ \\sigma_B^- + \\sigma_A^- \\sigma_B^+).\n$$\nThis form shows that the Hamiltonian swaps excitations between the two qubits. The initial state is $ |\\psi(0)\\rangle = |0\\rangle_A \\otimes |1\\rangle_B = |01\\rangle $. The only other state the Hamiltonian can couple $|01\\rangle$ to is $|10\\rangle$.\n\nThe time evolution occurs within the subspace spanned by $\\{|01\\rangle, |10\\rangle\\}$. In this basis, the Hamiltonian is:\n$$\nH_{\\text{sub}} = \\begin{pmatrix} 0  2J \\\\ 2J  0 \\end{pmatrix}.\n$$\nThe time evolution operator in this subspace is $U(t) = e^{-iH_{\\text{sub}}t/\\hbar}$. We can compute this using the identity $e^{-i\\alpha \\sigma_x} = \\cos(\\alpha)I - i\\sin(\\alpha)\\sigma_x$. Here, $H_{\\text{sub}} = 2J \\sigma_x$, so $\\alpha = 2Jt/\\hbar$.\n$$\nU(t) = \\cos\\left(\\frac{2Jt}{\\hbar}\\right)I - i\\sin\\left(\\frac{2Jt}{\\hbar}\\right)\\sigma_x = \\begin{pmatrix} \\cos(\\frac{2Jt}{\\hbar})  -i\\sin(\\frac{2Jt}{\\hbar}) \\\\ -i\\sin(\\frac{2Jt}{\\hbar})  \\cos(\\frac{2Jt}{\\hbar}) \\end{pmatrix}.\n$$\nThe initial state vector is $|01\\rangle \\equiv \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ in the $\\{|01\\rangle, |10\\rangle\\}$ basis. Applying the evolution operator:\n$$\n|\\psi(t)\\rangle = U(t) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\cos\\left( \\frac{2J t}{\\hbar} \\right) |01\\rangle - i \\sin\\left( \\frac{2J t}{\\hbar} \\right) |10\\rangle.\n$$\nThe total system remains in a pure state for all time $t$, so its von Neumann entropy is always zero: $S(\\rho_{AB}) = 0$.\n\nTo calculate the mutual information, $I(A:B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB})$, we need the entropies of the reduced states. Let $\\theta = \\frac{2Jt}{\\hbar}$. The total density matrix is $\\rho_{AB}(t) = |\\psi(t)\\rangle\\langle\\psi(t)|$.\nThe reduced density matrix for qubit A is $\\rho_A(t) = \\text{Tr}_B \\rho_{AB}(t)$:\n$$\n\\rho_A(t) = \\cos^2(\\theta)|0\\rangle\\langle0| + \\sin^2(\\theta)|1\\rangle\\langle1| = \\begin{pmatrix} \\cos^2 \\theta  0 \\\\ 0  \\sin^2 \\theta \\end{pmatrix}.\n$$\nThe eigenvalues of $\\rho_A(t)$ are $p_1 = \\cos^2\\theta$ and $p_2 = \\sin^2\\theta$. Its entropy is:\n$$\nS(\\rho_A) = -p_1 \\log_2 p_1 - p_2 \\log_2 p_2 = -\\cos^2 \\theta \\log_2 (\\cos^2 \\theta) - \\sin^2 \\theta \\log_2 (\\sin^2 \\theta).\n$$\nBy symmetry, the reduced density matrix for qubit B is:\n$$\n\\rho_B(t) = \\sin^2(\\theta)|0\\rangle\\langle0| + \\cos^2(\\theta)|1\\rangle\\langle1| = \\begin{pmatrix} \\sin^2 \\theta  0 \\\\ 0  \\cos^2 \\theta \\end{pmatrix}.\n$$\nThis has the same eigenvalues as $\\rho_A(t)$, so $S(\\rho_B) = S(\\rho_A)$.\n\nThe quantum mutual information is:\n$$\nI(A:B) = S(\\rho_A) + S(\\rho_B) - S(\\rho_{AB}) = 2S(\\rho_A) - 0.\n$$\nSubstituting the expression for $S(\\rho_A)$ and $\\theta = \\frac{2Jt}{\\hbar}$:\n$$\nI(A:B) = 2 \\left[ -\\cos^2 \\left( \\frac{2J t}{\\hbar} \\right) \\log_2 \\left( \\cos^2 \\left( \\frac{2J t}{\\hbar} \\right) \\right) - \\sin^2 \\left( \\frac{2J t}{\\hbar} \\right) \\log_2 \\left( \\sin^2 \\left( \\frac{2J t}{\\hbar} \\right) \\right) \\right].\n$$\nThis is twice the binary entropy function of $\\cos^2(\\frac{2Jt}{\\hbar})$. It oscillates between 0 (at $t=0, \\pi\\hbar/2J, ...$) when the state is separable, and 2 bits (at $t=\\pi\\hbar/4J, ...$) when the state is maximally entangled.", "answer": "$$\n\\boxed{-2 \\cos^{2} \\left( \\frac{2J t}{\\hbar} \\right) \\log_{2} \\left( \\cos^{2} \\left( \\frac{2J t}{\\hbar} \\right) \\right) - 2 \\sin^{2} \\left( \\frac{2J t}{\\hbar} \\right) \\log_{2} \\left( \\sin^{2} \\left( \\frac{2J t}{\\hbar} \\right) \\right)}\n$$", "id": "94563"}, {"introduction": "Beyond pairs of systems, quantum information theory provides powerful tools to characterize the intricate web of correlations in multipartite states. Our final exercise explores this by examining a four-qubit system arranged in a \"star graph\" cluster state. You will calculate the conditional mutual information $I(B:C|A)$ and discover a quantum Markov chain, where the central qubit A mediates all correlations between the \"leaf\" qubits B and C. This practice demonstrates how entropic quantities can act as powerful diagnostics for the structural properties of entanglement. [@problem_id:94481]", "problem": "A graph state $|\\psi_G\\rangle$ is a specific type of multipartite entangled quantum state defined by a simple graph $G=(V, E)$, where the vertices $V$ represent qubits and the edges $E$ represent entangling operations. The state is constructed by initializing each qubit in the state $|+\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$, and then applying a controlled-Z (CZ) gate for each edge in $E$. The CZ gate between qubits $i$ and $j$ is given by $CZ_{ij} = |0\\rangle\\langle 0|_i \\otimes I_j + |1\\rangle\\langle 1|_i \\otimes \\sigma_z^{(j)}$, where $\\sigma_z$ is the Pauli-Z operator.\n\nConsider a four-qubit system, with qubits labeled A, B, C, and D. The system is prepared in a cluster state corresponding to a \"star graph,\" where qubit A is the central vertex connected by an edge to each of the other three \"leaf\" vertices (B, C, and D). The graph has edges $E = \\{(A,B), (A,C), (A,D)\\}$.\n\nThe quantum conditional mutual information (CMI) for a tripartite state $\\rho_{XYZ}$ is defined as $I(X:Y|Z) = S(X,Z) + S(Y,Z) - S(X,Y,Z) - S(Z)$, where $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$ is the von Neumann entropy and, for example, $S(X,Z)$ is the entropy of the reduced density matrix $\\rho_{XZ} = \\text{Tr}_Y(\\rho_{XYZ})$. The CMI quantifies the amount of correlation between systems X and Y that is not accounted for by their correlation with Z.\n\nYour task is to calculate the conditional mutual information $I(B:C|A)$ for the four-qubit star-graph cluster state described above.", "solution": "To calculate the conditional mutual information $I(B:C|A) = S(A,B) + S(A,C) - S(A,B,C) - S(A)$, we need to find the von Neumann entropies of four different subsystems. For graph states (which are a type of stabilizer state), the entropy of any subsystem $X$ (in bits) is given by the rank over the field $\\mathbb{F}_2$ of the adjacency submatrix describing the connections between the qubits in $X$ and the qubits in its complement $\\bar{X}$.\n\nThe graph has vertices $V=\\{A,B,C,D\\}$ and edges $E = \\{(A,B), (A,C), (A,D)\\}$.\n\n1.  **Compute $S(A)$**:\n    The subsystem is $X = \\{A\\}$, and its complement is $\\bar{X}=\\{B,C,D\\}$. The edges between $X$ and $\\bar{X}$ are $(A,B), (A,C), (A,D)$. This can be represented by a $1 \\times 3$ adjacency matrix $[1 \\ 1 \\ 1]$. The rank over $\\mathbb{F}_2$ is 1.\n    $$S(A) = 1.$$\n\n2.  **Compute $S(A,B)$**:\n    The subsystem is $X = \\{A,B\\}$, and its complement is $\\bar{X}=\\{C,D\\}$. The edges connecting these two sets are $(A,C)$ and $(A,D)$. There are no edges from $B$ to $\\{C,D\\}$. We can write the adjacency matrix with rows for $\\{A,B\\}$ and columns for $\\{C,D\\}$:\n    $$\n    \\Gamma_{X, \\bar{X}} = \\begin{pmatrix} 1  1 \\\\ 0  0 \\end{pmatrix}\n    $$\n    The rank of this matrix over $\\mathbb{F}_2$ is 1.\n    $$S(A,B) = 1.$$\n\n3.  **Compute $S(A,C)$**:\n    The subsystem is $X=\\{A,C\\}$, and its complement is $\\bar{X}=\\{B,D\\}$. By the symmetry of the graph (swapping labels B and C), the calculation is identical to the previous step. The edges are $(A,B)$ and $(A,D)$.\n    $$S(A,C) = 1.$$\n\n4.  **Compute $S(A,B,C)$**:\n    The subsystem is $X = \\{A,B,C\\}$, and its complement is $\\bar{X}=\\{D\\}$. The only edge connecting $X$ and $\\bar{X}$ is $(A,D)$. The corresponding adjacency matrix is a $3 \\times 1$ matrix:\n    $$\n    \\Gamma_{X, \\bar{X}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n    $$\n    The rank of this matrix is 1.\n    $$S(A,B,C) = 1.$$\n\n5.  **Calculate the Conditional Mutual Information**:\n    Now we substitute these entropy values into the formula for CMI:\n    $$\n    I(B:C|A) = S(A,B) + S(A,C) - S(A,B,C) - S(A)\n    $$\n    $$\n    I(B:C|A) = 1 + 1 - 1 - 1 = 0.\n    $$\nThe result $I(B:C|A)=0$ means that the state forms a quantum Markov chain $B-A-C$. This confirms our intuition from the graph structure: qubit A acts as a central hub that mediates all correlations. Once system A is known, B and C are conditionally independent.", "answer": "$$\\boxed{0}$$", "id": "94481"}]}