{"hands_on_practices": [{"introduction": "This first exercise offers a direct and foundational practice in computing quantum relative entropy. By calculating the distinguishability between two single-qubit states before and after they pass through a dephasing channel, you will gain a concrete understanding of the data processing inequality. This fundamental principle dictates that the distinguishability between states cannot increase under any quantum operation, illustrating the irreversible loss of information [@problem_id:126656].", "problem": "The quantum state of a single qubit can be represented by a density matrix $\\rho$, which can be parametrized by a Bloch vector $\\vec{v} \\in \\mathbb{R}^3$ with $|\\vec{v}| \\le 1$:\n$$\n\\rho(\\vec{v}) = \\frac{1}{2}(I + \\vec{v} \\cdot \\vec{\\sigma})\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix and $\\vec{\\sigma} = (\\sigma_x, \\sigma_y, \\sigma_z)$ is the vector of Pauli matrices.\n\nThe quantum relative entropy of a state $\\rho$ with respect to another state $\\sigma$ is defined as:\n$$\nS(\\rho \\| \\sigma) = \\operatorname{Tr}(\\rho(\\ln \\rho - \\ln \\sigma))\n$$\nwhere $\\ln$ denotes the matrix logarithm. This quantity is a measure of distinguishability between the two states.\n\nConsider two single-qubit states, $\\rho_A$ and $\\rho_B$, described by Bloch vectors $\\vec{r}_A$ and $\\vec{r}_B$ respectively, given by:\n$$\n\\vec{r}_A = (r \\sin\\theta, 0, r \\cos\\theta)\n$$\n$$\n\\vec{r}_B = (0, 0, s)\n$$\nThe parameters $r, s, \\theta$ are constants satisfying $0 < r < 1$, $0 < s < 1$, and $0 < \\theta < \\pi/2$.\n\nNow, consider a quantum channel $\\mathcal{E}$ that corresponds to a projective measurement in the computational basis $\\{|0\\rangle, |1\\rangle\\}$. For any density matrix $\\rho$, this channel is defined by:\n$$\n\\mathcal{E}(\\rho) = P_0 \\rho P_0 + P_1 \\rho P_1\n$$\nwhere $P_0 = |0\\rangle\\langle 0|$ and $P_1 = |1\\rangle\\langle 1|$ are the projectors onto the basis states. This is also known as the Z-dephasing channel.\n\nAccording to the data processing inequality, the relative entropy is non-increasing under the action of any quantum channel, i.e., $S(\\rho \\| \\sigma) \\ge S(\\mathcal{E}(\\rho) \\| \\mathcal{E}(\\sigma))$.\n\nYour task is to compute the total decrease in relative entropy between $\\rho_A$ and $\\rho_B$ when both states are passed through the channel $\\mathcal{E}$. Calculate the quantity $\\Delta S = S(\\rho_A \\| \\rho_B) - S(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B))$. Express your answer in terms of $r$ and $\\theta$ using the natural logarithm.", "solution": "The quantum relative entropy is defined as $S(\\rho \\| \\sigma) = \\operatorname{Tr}(\\rho(\\ln \\rho - \\ln \\sigma))$. The states $\\rho_A$ and $\\rho_B$ have Bloch vectors $\\vec{r}_A = (r \\sin\\theta, 0, r \\cos\\theta)$ and $\\vec{r}_B = (0, 0, s)$, respectively. The channel $\\mathcal{E}$ is the projective measurement in the computational basis, given by $\\mathcal{E}(\\rho) = P_0 \\rho P_0 + P_1 \\rho P_1$, where $P_0 = |0\\rangle\\langle 0|$ and $P_1 = |1\\rangle\\langle 1|$.\n\nFirst, express $\\rho_A$ and $\\rho_B$ in matrix form:\n\n$$\n\\rho_A = \\frac{1}{2} \\begin{pmatrix} 1 + r \\cos\\theta & r \\sin\\theta \\\\ r \\sin\\theta & 1 - r \\cos\\theta \\end{pmatrix}, \\quad\n\\rho_B = \\frac{1}{2} \\begin{pmatrix} 1 + s & 0 \\\\ 0 & 1 - s \\end{pmatrix}.\n$$\n\n\nApplying the channel $\\mathcal{E}$:\n\n$$\n\\mathcal{E}(\\rho_A) = \\begin{pmatrix} \\frac{1 + r \\cos\\theta}{2} & 0 \\\\ 0 & \\frac{1 - r \\cos\\theta}{2} \\end{pmatrix}, \\quad\n\\mathcal{E}(\\rho_B) = \\rho_B.\n$$\n\n\nThe quantity to compute is $\\Delta S = S(\\rho_A \\| \\rho_B) - S(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B))$.\n\nCompute $S(\\rho_A \\| \\rho_B)$:\n\n$$\nS(\\rho_A \\| \\rho_B) = \\operatorname{Tr}(\\rho_A \\ln \\rho_A) - \\operatorname{Tr}(\\rho_A \\ln \\rho_B).\n$$\n\n\nThe eigenvalues of $\\rho_A$ are $\\frac{1 + r}{2}$ and $\\frac{1 - r}{2}$, so:\n\n$$\n\\operatorname{Tr}(\\rho_A \\ln \\rho_A) = \\frac{1 + r}{2} \\ln \\left( \\frac{1 + r}{2} \\right) + \\frac{1 - r}{2} \\ln \\left( \\frac{1 - r}{2} \\right).\n$$\n\n\nSince $\\rho_B$ is diagonal, $\\ln \\rho_B = \\begin{pmatrix} \\ln \\frac{1+s}{2} & 0 \\\\ 0 & \\ln \\frac{1-s}{2} \\end{pmatrix}$, and:\n\n$$\n\\operatorname{Tr}(\\rho_A \\ln \\rho_B) = \\frac{1 + r \\cos\\theta}{2} \\ln \\left( \\frac{1+s}{2} \\right) + \\frac{1 - r \\cos\\theta}{2} \\ln \\left( \\frac{1-s}{2} \\right).\n$$\n\n\nThus:\n\n$$\nS(\\rho_A \\| \\rho_B) = \\left[ \\frac{1 + r}{2} \\ln \\left( \\frac{1 + r}{2} \\right) + \\frac{1 - r}{2} \\ln \\left( \\frac{1 - r}{2} \\right) \\right] - \\left[ \\frac{1 + r \\cos\\theta}{2} \\ln \\left( \\frac{1+s}{2} \\right) + \\frac{1 - r \\cos\\theta}{2} \\ln \\left( \\frac{1-s}{2} \\right) \\right].\n$$\n\n\nNow compute $S(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B))$. Both $\\mathcal{E}(\\rho_A)$ and $\\mathcal{E}(\\rho_B)$ are diagonal, so the relative entropy reduces to classical relative entropy:\n\n$$\nS(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B)) = p_0 \\ln \\frac{p_0}{q_0} + p_1 \\ln \\frac{p_1}{q_1},\n$$\n\nwhere $p_0 = \\frac{1 + r \\cos\\theta}{2}$, $p_1 = \\frac{1 - r \\cos\\theta}{2}$, $q_0 = \\frac{1 + s}{2}$, $q_1 = \\frac{1 - s}{2}$. Thus:\n\n$$\nS(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B)) = \\frac{1 + r \\cos\\theta}{2} \\ln \\left( \\frac{1 + r \\cos\\theta}{1 + s} \\right) + \\frac{1 - r \\cos\\theta}{2} \\ln \\left( \\frac{1 - r \\cos\\theta}{1 - s} \\right).\n$$\n\n\nNow form $\\Delta S$:\n\n$$\n\\Delta S = S(\\rho_A \\| \\rho_B) - S(\\mathcal{E}(\\rho_A) \\| \\mathcal{E}(\\rho_B)).\n$$\n\n\nSubstituting the expressions and simplifying, the terms involving $s$ cancel, resulting in:\n\n$$\n\\Delta S = \\frac{1}{2} \\left[ (1 + r) \\ln (1 + r) + (1 - r) \\ln (1 - r) - (1 + r \\cos\\theta) \\ln (1 + r \\cos\\theta) - (1 - r \\cos\\theta) \\ln (1 - r \\cos\\theta) \\right].\n$$\n\n\nThe parameter $s$ does not appear in the final expression, as required.", "answer": "$$\n\\boxed{\\dfrac{1}{2}\\left[(1+r)\\ln(1+r) + (1-r)\\ln(1-r) - (1 + r \\cos \\theta) \\ln(1 + r \\cos \\theta) - (1 - r \\cos \\theta) \\ln(1 - r \\cos \\theta)\\right]}\n$$", "id": "126656"}, {"introduction": "Bridging the gap between quantum information and statistical mechanics, this practice explores the relative entropy between thermal states. You will calculate the distinguishability between two Gibbs states that, despite being at the same temperature, originate from different and non-commuting Hamiltonians. This exercise demonstrates how relative entropy serves as a powerful tool to quantify the physical difference between equilibrium conditions governed by distinct microscopic interactions [@problem_id:126759].", "problem": "In quantum statistical mechanics, the thermal equilibrium state of a quantum system with Hamiltonian $H$ at inverse temperature $\\beta = 1/(k_B T)$ is described by the Gibbs state (or canonical density operator) $\\rho = \\frac{e^{-\\beta H}}{Z}$, where $Z = \\operatorname{Tr}(e^{-\\beta H})$ is the partition function.\n\nA fundamental concept for distinguishing two quantum states, $\\rho$ and $\\sigma$, is the quantum relative entropy, defined as\n$$\nS(\\rho || \\sigma) = \\operatorname{Tr}(\\rho (\\log \\rho - \\log \\sigma))\n$$\nThis quantity is always non-negative and is zero if and only if $\\rho = \\sigma$.\n\nConsider a single qubit system. Two different physical scenarios are described by the Hamiltonians $H_1 = \\omega \\sigma_z$ and $H_2 = \\omega \\sigma_x$, where $\\omega$ is a positive constant with units of energy, and $\\sigma_x, \\sigma_z$ are the Pauli matrices:\n$$\n\\sigma_x = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad \\sigma_z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\n$$\nLet $\\rho_1$ and $\\rho_2$ be the Gibbs states corresponding to $H_1$ and $H_2$, respectively, both at the same inverse temperature $\\beta$.\n\nCalculate the quantum relative entropy $S(\\rho_1 || \\rho_2)$ between these two states. Express your answer as a closed-form analytical expression in terms of $\\beta$ and $\\omega$.", "solution": "The quantum relative entropy is defined as:\n\n$$\nS(\\rho_1 \\| \\rho_2) = \\operatorname{Tr}[\\rho_1 (\\log \\rho_1 - \\log \\rho_2)]\n$$\n\nwhere $\\rho_1$ and $\\rho_2$ are the Gibbs states for the Hamiltonians $H_1 = \\omega \\sigma_z$ and $H_2 = \\omega \\sigma_x$ at inverse temperature $\\beta$.\n\nThe partition functions for both systems are identical:\n\n$$\nZ = \\operatorname{Tr}(e^{-\\beta H_1}) = \\operatorname{Tr}(e^{-\\beta H_2}) = e^{-\\beta \\omega} + e^{\\beta \\omega} = 2 \\cosh(\\beta \\omega)\n$$\n\n\nThe Gibbs state $\\rho_1$ in the eigenbasis of $\\sigma_z$ is:\n\n$$\n\\rho_1 = \\frac{1}{2 \\cosh(\\beta \\omega)} \\begin{pmatrix} e^{-\\beta \\omega} & 0 \\\\ 0 & e^{\\beta \\omega} \\end{pmatrix}\n$$\n\nLet $a = \\frac{e^{-\\beta \\omega}}{2 \\cosh(\\beta \\omega)}$ and $b = \\frac{e^{\\beta \\omega}}{2 \\cosh(\\beta \\omega)}$, so $\\rho_1 = \\begin{pmatrix} a & 0 \\\\ 0 & b \\end{pmatrix}$.\n\nThe Gibbs state $\\rho_2$ in the same basis is:\n\n$$\n\\rho_2 = \\frac{1}{2} \\begin{pmatrix} 1 & -\\tanh(\\beta \\omega) \\\\ -\\tanh(\\beta \\omega) & 1 \\end{pmatrix}\n$$\n\nwhere $t = \\tanh(\\beta \\omega)$.\n\nThe relative entropy decomposes as:\n\n$$\nS(\\rho_1 \\| \\rho_2) = \\operatorname{Tr}(\\rho_1 \\log \\rho_1) - \\operatorname{Tr}(\\rho_1 \\log \\rho_2)\n$$\n\n\nFirst, compute $\\operatorname{Tr}(\\rho_1 \\log \\rho_1)$:\n\n$$\n\\log \\rho_1 = \\begin{pmatrix} \\log a & 0 \\\\ 0 & \\log b \\end{pmatrix}\n$$\n\n\n$$\n\\operatorname{Tr}(\\rho_1 \\log \\rho_1) = a \\log a + b \\log b\n$$\n\nSubstituting $a$ and $b$:\n\n$$\na \\log a = \\frac{e^{-\\beta \\omega}}{2 \\cosh(\\beta \\omega)} \\left( -\\beta \\omega - \\log(2 \\cosh(\\beta \\omega)) \\right)\n$$\n\n\n$$\nb \\log b = \\frac{e^{\\beta \\omega}}{2 \\cosh(\\beta \\omega)} \\left( \\beta \\omega - \\log(2 \\cosh(\\beta \\omega)) \\right)\n$$\n\nAdding these:\n\n$$\na \\log a + b \\log b = \\frac{1}{2 \\cosh(\\beta \\omega)} \\left[ -\\beta \\omega e^{-\\beta \\omega} + \\beta \\omega e^{\\beta \\omega} - \\log(2 \\cosh(\\beta \\omega)) (e^{-\\beta \\omega} + e^{\\beta \\omega}) \\right]\n$$\n\nUsing $e^{\\beta \\omega} + e^{-\\beta \\omega} = 2 \\cosh(\\beta \\omega)$ and $e^{\\beta \\omega} - e^{-\\beta \\omega} = 2 \\sinh(\\beta \\omega)$:\n\n$$\na \\log a + b \\log b = \\frac{1}{2 \\cosh(\\beta \\omega)} \\left[ 2 \\beta \\omega \\sinh(\\beta \\omega) - 2 \\log(2 \\cosh(\\beta \\omega)) \\cosh(\\beta \\omega) \\right]\n$$\n\n\n$$\n= \\beta \\omega \\tanh(\\beta \\omega) - \\log(2) - \\log(\\cosh(\\beta \\omega))\n$$\n\n\nNext, compute $\\operatorname{Tr}(\\rho_1 \\log \\rho_2)$. The eigenvalues of $\\rho_2$ are $\\lambda_1 = \\frac{1 - t}{2}$ and $\\lambda_2 = \\frac{1 + t}{2}$ with $t = \\tanh(\\beta \\omega)$. Diagonalizing $\\rho_2$:\n\n$$\n\\log \\rho_2 = \\frac{1}{2} \\begin{pmatrix} \\log\\left( \\frac{1 - t^2}{4} \\right) & \\log\\left( \\frac{1 - t}{1 + t} \\right) \\\\ \\log\\left( \\frac{1 - t}{1 + t} \\right) & \\log\\left( \\frac{1 - t^2}{4} \\right) \\end{pmatrix}\n$$\n\nThe diagonal elements are equal, so:\n\n$$\n[\\log \\rho_2]_{11} = [\\log \\rho_2]_{22} = \\frac{1}{2} \\log\\left( \\frac{1 - t^2}{4} \\right)\n$$\n\nThus:\n\n$$\n\\operatorname{Tr}(\\rho_1 \\log \\rho_2) = a \\cdot \\frac{1}{2} \\log\\left( \\frac{1 - t^2}{4} \\right) + b \\cdot \\frac{1}{2} \\log\\left( \\frac{1 - t^2}{4} \\right) = \\frac{1}{2} \\log\\left( \\frac{1 - t^2}{4} \\right)\n$$\n\nUsing $1 - t^2 = \\text{sech}^2(\\beta \\omega)$:\n\n$$\n\\frac{1 - t^2}{4} = \\frac{\\text{sech}^2(\\beta \\omega)}{4}\n$$\n\n\n$$\n\\log\\left( \\frac{\\text{sech}^2(\\beta \\omega)}{4} \\right) = \\log(\\text{sech}^2(\\beta \\omega)) - \\log 4 = 2 \\log(\\text{sech}(\\beta \\omega)) - 2 \\log 2\n$$\n\n\n$$\n\\operatorname{Tr}(\\rho_1 \\log \\rho_2) = \\frac{1}{2} \\left( 2 \\log(\\text{sech}(\\beta \\omega)) - 2 \\log 2 \\right) = \\log(\\text{sech}(\\beta \\omega)) - \\log 2 = -\\log(\\cosh(\\beta \\omega)) - \\log 2\n$$\n\n\nNow combine both terms:\n\n$$\nS(\\rho_1 \\| \\rho_2) = \\left[ \\beta \\omega \\tanh(\\beta \\omega) - \\log 2 - \\log(\\cosh(\\beta \\omega)) \\right] - \\left[ -\\log(\\cosh(\\beta \\omega)) - \\log 2 \\right]\n$$\n\n\n$$\n= \\beta \\omega \\tanh(\\beta \\omega) - \\log 2 - \\log(\\cosh(\\beta \\omega)) + \\log(\\cosh(\\beta \\omega)) + \\log 2\n$$\n\n\n$$\n= \\beta \\omega \\tanh(\\beta \\omega)\n$$", "answer": "$$\n\\boxed{\\beta \\omega \\tanh(\\beta \\omega)}\n$$", "id": "126759"}, {"introduction": "This final practice provides a case study on the application of relative entropy in benchmarking quantum technologies. You will analyze the performance of a standard three-qubit error-correcting code when it faces a type of correlated noise it was not designed to handle. By calculating the relative entropy between the ideal logical state and the imperfectly recovered state, you will quantify the protocol's failure, showcasing how this measure is vital for evaluating the robustness of quantum hardware and algorithms [@problem_id:126748].", "problem": "The three-qubit repetition code is a basic quantum error-correcting code designed to protect a qubit against single bit-flip errors. The logical basis states are defined as $|0_L\\rangle = |000\\rangle$ and $|1_L\\rangle = |111\\rangle$. The standard error correction protocol for this code involves measuring the two syndrome operators $S_1 = Z_1 \\otimes Z_2 \\otimes I_3$ and $S_2 = I_1 \\otimes Z_2 \\otimes Z_3$. Depending on the measurement outcomes (the eigenvalues $\\pm 1$), a specific recovery operation is applied:\n- Outcomes $(+1, +1)$: No error detected. Recovery is Identity.\n- Outcomes $(-1, +1)$: Bit-flip on qubit 1 detected. Recovery is $X_1$.\n- Outcomes $(+1, -1)$: Bit-flip on qubit 3 detected. Recovery is $X_3$.\n- Outcomes $(-1, -1)$: Bit-flip on qubit 2 detected. Recovery is $X_2$.\n\nThis protocol works perfectly for single, uncorrelated bit-flip errors. However, real-world noise can be correlated. Consider a correlated bit-flip channel $\\mathcal{E}$ that acts on the first two qubits of the three-qubit system. Its action on any three-qubit state $\\rho_{sys}$ is described by the Kraus operators $K_0 = \\sqrt{1-p} \\ I \\otimes I \\otimes I$ and $K_1 = \\sqrt{p} \\ X \\otimes X \\otimes I$, such that\n$$\n\\mathcal{E}(\\rho_{sys}) = K_0 \\rho_{sys} K_0^\\dagger + K_1 \\rho_{sys} K_1^\\dagger\n$$\nwhere $p \\in (0, 1)$ is the probability of the correlated error occurring.\n\nSuppose we prepare the system in the logical state $\\rho_{in} = |0_L\\rangle\\langle 0_L|$. This state is then subjected to the correlated error channel $\\mathcal{E}$, resulting in the state $\\rho_{err} = \\mathcal{E}(\\rho_{in})$. Subsequently, the standard error correction protocol, which we denote by the map $\\mathcal{R}$, is applied to $\\rho_{err}$ to produce the final state $\\rho_{out} = \\mathcal{R}(\\rho_{err})$.\n\nThe imperfection of this process can be quantified by the quantum relative entropy between the ideal initial state and the actual final state. The quantum relative entropy is defined as $S(\\rho||\\sigma) = \\operatorname{Tr}(\\rho(\\log_2 \\rho - \\log_2 \\sigma))$.\n\nCalculate the quantum relative entropy $S(\\rho_{in} || \\rho_{out})$ as a function of the error probability $p$.", "solution": "The problem asks for the quantum relative entropy $S(\\rho_{in} || \\rho_{out})$ between the initial logical state $\\rho_{in}$ and the final state $\\rho_{out}$ after a correlated error channel and a standard error correction procedure have been applied.\n\n1.  **Initial State:**\n    The initial state is the logical zero state of the three-qubit repetition code:\n    $$\n    \\rho_{in} = |0_L\\rangle\\langle 0_L| = |000\\rangle\\langle 000|\n    $$\n\n2.  **State after Error Channel:**\n    The initial state $\\rho_{in}$ passes through the correlated bit-flip channel $\\mathcal{E}$. The channel is defined by the Kraus operators $K_0 = \\sqrt{1-p} \\ I_8$ and $K_1 = \\sqrt{p} \\ X \\otimes X \\otimes I$. The state after the channel is $\\rho_{err} = \\mathcal{E}(\\rho_{in})$:\n    $$\n    \\rho_{err} = K_0 \\rho_{in} K_0^\\dagger + K_1 \\rho_{in} K_1^\\dagger\n    $$\n    Let's calculate each term:\n    $$\n    K_0 \\rho_{in} K_0^\\dagger = (\\sqrt{1-p} I_8) |000\\rangle\\langle 000| (\\sqrt{1-p} I_8)^\\dagger = (1-p) |000\\rangle\\langle 000|\n    $$\n    For the second term, we first find the action of $K_1$ on the state vector $|000\\rangle$:\n    $$\n    K_1 |000\\rangle = (\\sqrt{p} X \\otimes X \\otimes I) |000\\rangle = \\sqrt{p} |110\\rangle\n    $$\n    So, the second term is:\n    $$\n    K_1 \\rho_{in} K_1^\\dagger = (\\sqrt{p} |110\\rangle) (\\sqrt{p} \\langle 110|) = p |110\\rangle\\langle 110|\n    $$\n    Combining the two terms, the state after the error channel is a mixture:\n    $$\n    \\rho_{err} = (1-p) |000\\rangle\\langle 000| + p |110\\rangle\\langle 110|\n    $$\n\n3.  **State after Error Correction:**\n    The error correction protocol $\\mathcal{R}$ is applied to $\\rho_{err}$. Since $\\mathcal{R}$ is a linear map, we can apply it to each component of the mixture.\n    \n    -   **For the $|000\\rangle$ component:** We measure the syndromes.\n        $S_1 |000\\rangle = (Z_1 Z_2) |000\\rangle = (+1) |000\\rangle$.\n        $S_2 |000\\rangle = (Z_2 Z_3) |000\\rangle = (+1) |000\\rangle$.\n        The syndrome is $(+1, +1)$, indicating no error. The recovery operation is the identity, so $|000\\rangle$ remains $|000\\rangle$.\n        \n    -   **For the $|110\\rangle$ component:** We measure the syndromes.\n        $S_1 |110\\rangle = (Z_1 Z_2) |110\\rangle = (-1)(-1) |110\\rangle = (+1) |110\\rangle$.\n        $S_2 |110\\rangle = (Z_2 Z_3) |110\\rangle = (-1)(+1) |110\\rangle = (-1) |110\\rangle$.\n        The syndrome is $(+1, -1)$. This indicates an error on qubit 3. The recovery operation is $X_3$. Applying this to the state:\n        $X_3 |110\\rangle = |111\\rangle$.\n        \n    The recovery map $\\mathcal{R}$ transforms the components as $\\mathcal{R}(|000\\rangle\\langle 000|) = |000\\rangle\\langle 000|$ and $\\mathcal{R}(|110\\rangle\\langle 110|) = |111\\rangle\\langle 111|$. Applying this to $\\rho_{err}$:\n    $$\n    \\rho_{out} = \\mathcal{R}(\\rho_{err}) = (1-p) \\mathcal{R}(|000\\rangle\\langle 000|) + p \\mathcal{R}(|110\\rangle\\langle 110|)\n    $$\n    $$\n    \\rho_{out} = (1-p) |000\\rangle\\langle 000| + p |111\\rangle\\langle 111|\n    $$\n    In terms of the logical basis states, this is:\n    $$\n    \\rho_{out} = (1-p) |0_L\\rangle\\langle 0_L| + p |1_L\\rangle\\langle 1_L|\n    $$\n\n4.  **Calculate Quantum Relative Entropy:**\n    We need to compute $S(\\rho_{in} || \\rho_{out})$. The formula is $S(\\rho||\\sigma) = \\operatorname{Tr}(\\rho(\\log_2 \\rho - \\log_2 \\sigma))$.\n    Let $\\rho = \\rho_{in}$ and $\\sigma = \\rho_{out}$.\n    Since $\\rho_{in}$ is a pure state, its von Neumann entropy $S(\\rho_{in})=-\\operatorname{Tr}(\\rho_{in}\\log_2 \\rho_{in})$ is zero. Thus, the term $\\operatorname{Tr}(\\rho_{in}\\log_2\\rho_{in})$ vanishes.\n    The formula simplifies to:\n    $$\n    S(\\rho_{in} || \\rho_{out}) = - \\operatorname{Tr}(\\rho_{in} \\log_2 \\rho_{out})\n    $$\n    To perform this calculation, we can work in the logical basis $\\{|0_L\\rangle, |1_L\\rangle\\}$. In this basis, the states are represented by $2 \\times 2$ matrices.\n    $$\n    \\rho_{in} = |0_L\\rangle\\langle 0_L| \\quad \\rightarrow \\quad \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}\n    $$\n    $$\n    \\rho_{out} = (1-p) |0_L\\rangle\\langle 0_L| + p |1_L\\rangle\\langle 1_L| \\quad \\rightarrow \\quad \\begin{pmatrix} 1-p & 0 \\\\ 0 & p \\end{pmatrix}\n    $$\n    Since $\\rho_{out}$ is diagonal in this basis, its logarithm is found by taking the logarithm of the diagonal elements:\n    $$\n    \\log_2(\\rho_{out}) \\quad \\rightarrow \\quad \\log_2 \\left( \\begin{pmatrix} 1-p & 0 \\\\ 0 & p \\end{pmatrix} \\right) = \\begin{pmatrix} \\log_2(1-p) & 0 \\\\ 0 & \\log_2(p) \\end{pmatrix}\n    $$\n    Now, we compute the trace of the product $\\rho_{in} \\log_2 \\rho_{out}$:\n    $$\n    \\rho_{in} \\log_2 \\rho_{out} \\quad \\rightarrow \\quad \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\begin{pmatrix} \\log_2(1-p) & 0 \\\\ 0 & \\log_2(p) \\end{pmatrix} = \\begin{pmatrix} \\log_2(1-p) & 0 \\\\ 0 & 0 \\end{pmatrix}\n    $$\n    The trace of this matrix is simply the sum of its diagonal elements:\n    $$\n    \\operatorname{Tr}(\\rho_{in} \\log_2 \\rho_{out}) = \\log_2(1-p)\n    $$\n    Finally, we substitute this back into the simplified formula for relative entropy:\n    $$\n    S(\\rho_{in} || \\rho_{out}) = - \\operatorname{Tr}(\\rho_{in} \\log_2 \\rho_{out}) = - \\log_2(1-p)\n    $$", "answer": "$$\n\\boxed{-\\log_2(1-p)}\n$$", "id": "126748"}]}