{"hands_on_practices": [{"introduction": "To begin, we will apply the definitions directly to a foundational example in quantum information. This exercise involves calculating the conditional mutual information, $I(A:C|B)$, for the well-known three-qubit W-state. This practice is essential for mastering the mechanics of computing reduced density matrices and their von Neumann entropies, and it illustrates a typical case where the strong subadditivity inequality is strictly satisfied, yielding a positive result [@problem_id:137276].", "problem": "Consider a tripartite quantum system composed of three qubits, labeled A, B, and C. The state of this system is described by the three-qubit W-state, a specific entangled pure state given by:\n$$\n|\\psi_W\\rangle = \\frac{1}{\\sqrt{3}}(|100\\rangle_{ABC} + |010\\rangle_{ABC} + |001\\rangle_{ABC})\n$$\nwhere $|x_A x_B x_C\\rangle$ denotes a state in the computational basis, with $x_i \\in \\{0, 1\\}$.\n\nThe von Neumann entropy of a quantum state described by a density matrix $\\rho$ is given by $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$. For a composite system with density matrix $\\rho_{XYZ}$, the reduced density matrix of a subsystem, say XY, is obtained by taking the partial trace over the remaining subsystem Z: $\\rho_{XY} = \\text{Tr}_Z(\\rho_{XYZ})$. The entropy of a subsystem is the von Neumann entropy of its reduced density matrix, e.g., $S(XY) = S(\\rho_{XY})$.\n\nThe conditional mutual information between subsystems A and C, conditioned on B, is defined as:\n$$\nI(A:C|B) = S(AB) + S(BC) - S(B) - S(ABC)\n$$\nThis quantity measures the amount of correlation between A and C that is not mediated through B. The strong subadditivity inequality of quantum entropy states that $I(A:C|B) \\ge 0$.\n\nCalculate the exact value of the conditional mutual information $I(A:C|B)$ for the three-qubit W-state.", "solution": "The problem asks for the conditional mutual information $I(A:C|B) = S(AB) + S(BC) - S(B) - S(ABC)$ for the three-qubit W-state. We will calculate each term in this expression step-by-step.\n\nFirst, we write the density matrix for the whole system, $\\rho_{ABC}$. Since the system is in a pure state $|\\psi_W\\rangle$, its density matrix is $\\rho_{ABC} = |\\psi_W\\rangle\\langle\\psi_W|$.\n$$\n\\rho_{ABC} = \\frac{1}{3} \\left( |100\\rangle + |010\\rangle + |001\\rangle \\right) \\left( \\langle 100| + \\langle 010| + \\langle 001| \\right)\n$$\n\n**1. Entropy of the total system, $S(ABC)$**\nFor any pure state $\\rho = |\\psi\\rangle\\langle\\psi|$, the eigenvalues are $\\{1, 0, 0, ...\\}$. The von Neumann entropy is $S(\\rho) = -(1 \\log_2 1 + \\sum_i 0 \\log_2 0) = 0$. Since $|\\psi_W\\rangle$ is a pure state, the entropy of the total system is:\n$$\nS(ABC) = 0\n$$\n\n**2. Entropy of subsystem B, $S(B)$**\nWe need the reduced density matrix $\\rho_B$ by tracing out subsystems A and C from $\\rho_{ABC}$.\n$$\n\\rho_B = \\text{Tr}_{AC}(\\rho_{ABC}) = \\frac{1}{3} \\text{Tr}_{AC} \\left[ \\left( |100\\rangle + |010\\rangle + |001\\rangle \\right) \\left( \\langle 100| + \\langle 010| + \\langle 001| \\right) \\right]\n$$\nWe can trace each term in the expansion. The cross-terms survive the partial trace only if the states of the traced-out systems are identical.\n$$\n\\rho_B = \\frac{1}{3} \\left( \\text{Tr}_{AC}(|100\\rangle\\langle 100|) + \\text{Tr}_{AC}(|010\\rangle\\langle 010|) + \\text{Tr}_{AC}(|001\\rangle\\langle 001|) \\right)\n$$\nThe cross terms vanish, for example $\\text{Tr}_{AC}(|100\\rangle\\langle 010|) = \\langle 0_A|1_A\\rangle \\langle 0_C|0_C\\rangle |0_B\\rangle\\langle 1_B| = 0$.\nPerforming the traces:\n$$\n\\text{Tr}_{AC}(|100\\rangle\\langle 100|) = |0\\rangle_B\\langle 0|_B \\cdot \\langle 1_A|1_A\\rangle \\langle 0_C|0_C\\rangle = |0\\rangle_B\\langle 0|_B\n$$\n$$\n\\text{Tr}_{AC}(|010\\rangle\\langle 010|) = |1\\rangle_B\\langle 1|_B \\cdot \\langle 0_A|0_A\\rangle \\langle 0_C|0_C\\rangle = |1\\rangle_B\\langle 1|_B\n$$\n$$\n\\text{Tr}_{AC}(|001\\rangle\\langle 001|) = |0\\rangle_B\\langle 0|_B \\cdot \\langle 0_A|0_A\\rangle \\langle 1_C|1_C\\rangle = |0\\rangle_B\\langle 0|_B\n$$\nSumming these up:\n$$\n\\rho_B = \\frac{1}{3} \\left( |0\\rangle\\langle 0| + |1\\rangle\\langle 1| + |0\\rangle\\langle 0| \\right) = \\frac{2}{3}|0\\rangle\\langle 0| + \\frac{1}{3}|1\\rangle\\langle 1|\n$$\nThis matrix is diagonal in the computational basis, with eigenvalues $\\lambda_1 = 2/3$ and $\\lambda_2 = 1/3$. The entropy is:\n$$\nS(B) = -\\sum_i \\lambda_i \\log_2 \\lambda_i = -\\left( \\frac{2}{3}\\log_2\\frac{2}{3} + \\frac{1}{3}\\log_2\\frac{1}{3} \\right)\n$$\n$$\nS(B) = -\\frac{2}{3}(\\log_2 2 - \\log_2 3) - \\frac{1}{3}( \\log_2 1 - \\log_2 3) = -\\frac{2}{3}(1 - \\log_2 3) + \\frac{1}{3}\\log_2 3 = \\log_2 3 - \\frac{2}{3}\n$$\nThis is the binary entropy function $H_2(1/3, 2/3)$.\n\n**3. Entropy of subsystem BC, $S(BC)$**\nWe compute $\\rho_{BC}$ by tracing over A. We can write $|\\psi_W\\rangle$ as:\n$$\n|\\psi_W\\rangle = \\frac{1}{\\sqrt{3}} \\left( |1\\rangle_A|00\\rangle_{BC} + |0\\rangle_A|10\\rangle_{BC} + |0\\rangle_A|01\\rangle_{BC} \\right) = \\frac{1}{\\sqrt{3}} \\left( |1\\rangle_A|00\\rangle_{BC} + |0\\rangle_A \\left( |10\\rangle_{BC} + |01\\rangle_{BC} \\right) \\right)\n$$\nSince states $|0\\rangle_A$ and $|1\\rangle_A$ are orthogonal, the density matrix $\\rho_{BC} = \\text{Tr}_A(\\rho_{ABC})$ has no cross-terms between these parts:\n$$\n\\rho_{BC} = \\frac{1}{3} \\left( |00\\rangle\\langle 00| + (|10\\rangle + |01\\rangle)(\\langle 10| + \\langle 01|) \\right)\n$$\n$$\n\\rho_{BC} = \\frac{1}{3} \\left( |00\\rangle\\langle 00| + |10\\rangle\\langle 10| + |01\\rangle\\langle 01| + |10\\rangle\\langle 01| + |01\\rangle\\langle 10| \\right)\n$$\nIn the basis $\\{|00\\rangle, |01\\rangle, |10\\rangle, |11\\rangle\\}$, the matrix is:\n$$\n\\rho_{BC} = \\frac{1}{3} \\begin{pmatrix} 1  0  0  0 \\\\ 0  1  1  0 \\\\ 0  1  1  0 \\\\ 0  0  0  0 \\end{pmatrix}\n$$\nThe eigenvalues can be found from the block-diagonal structure. One eigenvalue is $\\lambda_1=1/3$ (from the $|00\\rangle$ block). Another is $\\lambda_4=0$ (from the $|11\\rangle$ block). The remaining two come from the submatrix $M = \\frac{1}{3}\\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}$. The characteristic equation is $\\det(M - \\lambda I) = (\\frac{1}{3}-\\lambda)^2 - (\\frac{1}{3})^2 = 0$, which gives $\\lambda^2 - \\frac{2}{3}\\lambda = 0$. The roots are $\\lambda_2=2/3$ and $\\lambda_3=0$.\nSo, the eigenvalues of $\\rho_{BC}$ are $\\{1/3, 2/3, 0, 0\\}$. The entropy is:\n$$\nS(BC) = -\\left( \\frac{1}{3}\\log_2\\frac{1}{3} + \\frac{2}{3}\\log_2\\frac{2}{3} \\right) = \\log_2 3 - \\frac{2}{3}\n$$\n\n**4. Entropy of subsystem AB, $S(AB)$**\nWe compute $\\rho_{AB}$ by tracing over C. We can write $|\\psi_W\\rangle$ as:\n$$\n|\\psi_W\\rangle = \\frac{1}{\\sqrt{3}} \\left( |10\\rangle_{AB}|0\\rangle_C + |01\\rangle_{AB}|0\\rangle_C + |00\\rangle_{AB}|1\\rangle_C \\right) = \\frac{1}{\\sqrt{3}} \\left( \\left(|10\\rangle_{AB} + |01\\rangle_{AB}\\right)|0\\rangle_C + |00\\rangle_{AB}|1\\rangle_C \\right)\n$$\nTracing over C gives:\n$$\n\\rho_{AB} = \\text{Tr}_C(\\rho_{ABC}) = \\frac{1}{3} \\left( (|10\\rangle+|01\\rangle)(\\langle 10|+\\langle 01|) + |00\\rangle\\langle 00| \\right)\n$$\nThis expression for $\\rho_{AB}$ is structurally identical to the one for $\\rho_{BC}$, just with different basis labels. The density matrix has the same eigenvalues $\\{1/3, 2/3, 0, 0\\}$. Therefore, the entropy is also the same.\n$$\nS(AB) = \\log_2 3 - \\frac{2}{3}\n$$\n\n**5. Assembling the conditional mutual information**\nFinally, we substitute all the calculated entropies into the definition of $I(A:C|B)$:\n$$\nI(A:C|B) = S(AB) + S(BC) - S(B) - S(ABC)\n$$\n$$\nI(A:C|B) = \\left( \\log_2 3 - \\frac{2}{3} \\right) + \\left( \\log_2 3 - \\frac{2}{3} \\right) - \\left( \\log_2 3 - \\frac{2}{3} \\right) - 0\n$$\n$$\nI(A:C|B) = \\log_2 3 - \\frac{2}{3}\n$$", "answer": "$$ \\boxed{\\log_2 3 - \\frac{2}{3}} $$", "id": "137276"}, {"introduction": "Having seen a case where the conditional mutual information is positive, we now explore a contrasting scenario where it vanishes. We will calculate $I(A:C|B)$ for a specific four-qubit graph state with a star-like structure, where $B$ is the central qubit. This practice introduces the crucial concept of a quantum Markov chain, which corresponds to the saturation of the strong subadditivity inequality, i.e., $I(A:C|B) = 0$ [@problem_id:137365]. Understanding such cases is key to applications like quantum error correction, where information about one part of a system renders another part irrelevant.", "problem": "Graph states are a class of multipartite quantum states that are fundamental in measurement-based quantum computation and quantum error correction. A graph state $|\\psi_G\\rangle$ is associated with a mathematical graph $G=(V, E)$, where the vertices $V$ represent qubits and the edges $E$ represent entangling operations.\n\nThe state is constructed as follows:\n1.  Initialize all $|V|$ qubits in the state $|+\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$.\n2.  For each edge $(i, j) \\in E$, apply a controlled-Z ($CZ_{ij}$) gate to the corresponding pair of qubits.\nThe $CZ_{ij}$ gate acts on the computational basis as $CZ_{ij}|k,l\\rangle = (-1)^{kl}|k,l\\rangle$ for $k,l \\in \\{0,1\\}$, and acts as the identity on all other qubits. The total state is given by:\n$$|\\psi_G\\rangle = \\left( \\prod_{(i,j) \\in E} CZ_{ij} \\right) |+\\rangle^{\\otimes |V|}$$\n\nConsider a 4-qubit star graph, with one central qubit, labeled $B$, and three peripheral qubits, labeled $A$, $C$, and $D$. The edges are $(A,B)$, $(C,B)$, and $(D,B)$.\n\nThe central quantity in this problem is the conditional mutual information (CMI), defined for a tripartite system $ABC$ with density matrix $\\rho_{ABC}$ as:\n$$I(A:C|B) = S(AB) + S(BC) - S(ABC) - S(B)$$\nwhere $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$ is the von Neumann entropy of a quantum state $\\rho$. The argument of the entropy function is the reduced density matrix of the corresponding subsystem, e.g., $S(AB) = S(\\rho_{AB})$ where $\\rho_{AB} = \\text{Tr}_{CD}(\\rho_{ABCD})$.\n\nYour task is to compute the conditional mutual information $I(A:C|B)$ for this 4-qubit star graph state.", "solution": "The graph state for the 4-qubit star graph with central qubit $B$ and peripheral qubits $A$, $C$, and $D$ is constructed by initializing all qubits in $|+\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle)$ and applying controlled-$Z$ gates for edges $(A,B)$, $(C,B)$, and $(D,B)$. The state vector is:\n\n$$\n|\\psi_G\\rangle = \\frac{1}{4} \\sum_{k_A,k_B,k_C,k_D=0}^1 (-1)^{k_B(k_A + k_C + k_D)} |k_A, k_B, k_C, k_D\\rangle.\n$$\n\nThe conditional mutual information $I(A:C|B)$ is defined as:\n\n$$\nI(A:C|B) = S(AB) + S(BC) - S(ABC) - S(B),\n$$\n\nwhere $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$ is the von Neumann entropy, and the reduced density matrices are obtained by tracing out the appropriate subsystems.\n\nFirst, the reduced density matrix $\\rho_{ABC} = \\text{Tr}_D(|\\psi_G\\rangle\\langle\\psi_G|)$ is computed. Summing over the index $m$ for qubit $D$:\n\n$$\n\\rho_{ABC} = \\frac{1}{16} \\sum_m \\sum_{k_A,k_B,k_C} \\sum_{k_A',k_B',k_C'} (-1)^{k_B(k_A + k_C + m) + k_B'(k_A' + k_C' + m)} |k_A, k_B, k_C\\rangle \\langle k_A', k_B', k_C'|.\n$$\n\nThe sum over $m$ gives a factor of 2 when $k_B = k_B'$ and 0 otherwise:\n\n$$\n\\rho_{ABC} = \\frac{1}{8} \\sum_{b=0}^1 \\sum_{k_A,k_C} \\sum_{k_A',k_C'} (-1)^{b(k_A + k_C + k_A' + k_C')} |k_A, b, k_C\\rangle \\langle k_A', b, k_C'|.\n$$\n\nThis simplifies to:\n\n$$\n\\rho_{ABC} = \\frac{1}{2} \\left[ |0\\rangle\\langle 0|_B \\otimes |++\\rangle\\langle ++|_{AC} + |1\\rangle\\langle 1|_B \\otimes |--\\rangle\\langle --|_{AC} \\right],\n$$\n\nwhere $|++\\rangle = |+\\rangle_A |+\\rangle_C$ and $|--\\rangle = |-\\rangle_A |-\\rangle_C$ with $|-\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle - |1\\rangle)$.\n\nNext, the required reduced density matrices are found:\n- $\\rho_{AB} = \\text{Tr}_C(\\rho_{ABC})$:\n  \n$$\n  \\rho_{AB} = \\frac{1}{2} \\left[ |0\\rangle\\langle 0|_B \\otimes |+\\rangle\\langle +|_A + |1\\rangle\\langle 1|_B \\otimes |-\\rangle\\langle -|_A \\right].\n  $$\n\n- $\\rho_{BC} = \\text{Tr}_A(\\rho_{ABC})$ (by symmetry):\n  \n$$\n  \\rho_{BC} = \\frac{1}{2} \\left[ |0\\rangle\\langle 0|_B \\otimes |+\\rangle\\langle +|_C + |1\\rangle\\langle 1|_B \\otimes |-\\rangle\\langle -|_C \\right].\n  $$\n\n- $\\rho_B = \\text{Tr}_{AC}(\\rho_{ABC})$:\n  \n$$\n  \\rho_B = \\frac{1}{2} |0\\rangle\\langle 0|_B + \\frac{1}{2} |1\\rangle\\langle 1|_B.\n  $$\n\n\nThe von Neumann entropies are computed as follows:\n- $S(B)$: The eigenvalues of $\\rho_B$ are $\\frac{1}{2}$ and $\\frac{1}{2}$, so:\n  \n$$\n  S(B) = -\\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1.\n  $$\n\n- $S(ABC)$: The states $|0\\rangle_B |++\\rangle_{AC}$ and $|1\\rangle_B |--\\rangle_{AC}$ are orthogonal and each has probability $\\frac{1}{2}$, so:\n  \n$$\n  S(ABC) = -\\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1.\n  $$\n\n- $S(AB)$: The states $|0\\rangle_B |+\\rangle_A$ and $|1\\rangle_B |-\\rangle_A$ are orthogonal and each has probability $\\frac{1}{2}$, so:\n  \n$$\n  S(AB) = -\\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1.\n  $$\n\n- $S(BC)$: By symmetry, $S(BC) = S(AB) = 1$.\n\nSubstituting into the formula for conditional mutual information:\n\n$$\nI(A:C|B) = S(AB) + S(BC) - S(ABC) - S(B) = 1 + 1 - 1 - 1 = 0.\n$$", "answer": "$$\n\\boxed{0}\n$$", "id": "137365"}, {"introduction": "We have explored cases where conditional mutual information is positive and where it is zero. Now, we will investigate how this quantity behaves when the conditioning system is subjected to a physical process, specifically a measurement. This exercise verifies a powerful consequence of strong subadditivity known as the data processing inequality, which states that local operations on the conditioning system can only increase the conditional mutual information [@problem_id:137327]. This calculation provides deep insight into the operational meaning of quantum correlations, demonstrating how classical information extracted from one part of a system can reveal stronger correlations between other parts.", "problem": "Consider a tripartite quantum system $ABC$, where each subsystem is a qubit. The system is prepared in the Greenberger-Horne-Zeilinger (GHZ) state, given by:\n$$\n|\\text{GHZ}\\rangle_{ABC} = \\frac{1}{\\sqrt{2}} \\left( |000\\rangle_{ABC} + |111\\rangle_{ABC} \\right)\n$$\nThe von Neumann entropy of a quantum state $\\rho$ is defined as $S(\\rho) = -\\text{Tr}(\\rho \\log_2 \\rho)$, with the result expressed in bits. The conditional mutual information between systems $A$ and $C$ given $B$ is defined as:\n$$\nI(A:C|B) = S(\\rho_{AB}) + S(\\rho_{BC}) - S(\\rho_{ABC}) - S(\\rho_B)\n$$\nwhere $\\rho_{X...}$ denotes the reduced density matrix of the subsystem(s) $X...$.\n\nNow, a local projective measurement is performed on qubit $B$ in the Hadamard basis, which consists of the states $|\\pm\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle \\pm |1\\rangle)$. The classical outcome of this measurement is recorded in a classical register $M$. The state of the full system after the measurement, including the classical register, is described by a classical-quantum state $\\rho_{ACM}$. The conditional mutual information, conditioned on the classical outcome, is given by:\n$$\nI(A:C|M) = S(\\rho_{AM}) + S(\\rho_{CM}) - S(\\rho_{ACM}) - S(\\rho_M)\n$$\nIt is a known result that such a measurement on the conditioning system cannot decrease the conditional mutual information, i.e., $I(A:C|M) \\ge I(A:C|B)$.\n\nYour task is to calculate the exact increase in the conditional mutual information, $\\Delta I = I(A:C|M) - I(A:C|B)$, for the given GHZ state and the specified measurement on qubit $B$.", "solution": "The GHZ state is given by:\n\n$$\n|\\text{GHZ}\\rangle_{ABC} = \\frac{1}{\\sqrt{2}} \\left( |000\\rangle_{ABC} + |111\\rangle_{ABC} \\right)\n$$\n\nThe initial state is pure, so $\\rho_{ABC} = |\\text{GHZ}\\rangle\\langle\\text{GHZ}|$ and $S(\\rho_{ABC}) = 0$.\n\nThe reduced density matrices are:\n\n$$\n\\rho_{AB} = \\text{Tr}_C(\\rho_{ABC}) = \\frac{1}{2} \\left( |00\\rangle\\langle 00|_{AB} + |11\\rangle\\langle 11|_{AB} \\right)\n$$\n\n\n$$\n\\rho_{BC} = \\text{Tr}_A(\\rho_{ABC}) = \\frac{1}{2} \\left( |00\\rangle\\langle 00|_{BC} + |11\\rangle\\langle 11|_{BC} \\right)\n$$\n\n\n$$\n\\rho_B = \\text{Tr}_{AC}(\\rho_{ABC}) = \\frac{1}{2} \\left( |0\\rangle\\langle 0|_B + |1\\rangle\\langle 1|_B \\right)\n$$\n\n\nThe entropies are:\n- $S(\\rho_{AB})$: The eigenvalues of $\\rho_{AB}$ are both $\\frac{1}{2}$, so $S(\\rho_{AB}) = -\\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1$ bit.\n- $S(\\rho_{BC})$: Similarly, eigenvalues are both $\\frac{1}{2}$, so $S(\\rho_{BC}) = 1$ bit.\n- $S(\\rho_B)$: Eigenvalues are both $\\frac{1}{2}$, so $S(\\rho_B}) = 1$ bit.\n- $S(\\rho_{ABC}) = 0$ bits.\n\nThe initial conditional mutual information is:\n\n$$\nI(A:C|B) = S(\\rho_{AB}) + S(\\rho_{BC}) - S(\\rho_{ABC}) - S(\\rho_B) = 1 + 1 - 0 - 1 = 1 \\text{ bit}\n$$\n\n\nAfter a projective measurement on qubit $B$ in the Hadamard basis $\\{ |+\\rangle, |-\\rangle \\}$ where $|\\pm\\rangle = \\frac{1}{\\sqrt{2}} (|0\\rangle \\pm |1\\rangle)$, the classical outcome $M$ is recorded. The probabilities and post-measurement states are:\n- Probability $p_+ = \\frac{1}{2}$, state collapses to: $|\\psi_+\\rangle_{AC} = \\frac{1}{\\sqrt{2}} (|00\\rangle_{AC} + |11\\rangle_{AC})$ (associated with outcome $|+\\rangle_M$)\n- Probability $p_- = \\frac{1}{2}$, state collapses to: $|\\psi_-\\rangle_{AC} = \\frac{1}{\\sqrt{2}} (|00\\rangle_{AC} - |11\\rangle_{AC})$ (associated with outcome $|-\\rangle_M$)\n\nThe classical-quantum state $\\rho_{ACM}$ is:\n\n$$\n\\rho_{ACM} = \\frac{1}{2} |\\phi^+\\rangle\\langle\\phi^+|_{AC} \\otimes |+\\rangle\\langle+|_M + \\frac{1}{2} |\\phi^-\\rangle\\langle\\phi^-|_{AC} \\otimes |-\\rangle\\langle-|_M\n$$\n\nwhere $|\\phi^+\\rangle_{AC} = \\frac{1}{\\sqrt{2}} (|00\\rangle + |11\\rangle)$ and $|\\phi^-\\rangle_{AC} = \\frac{1}{\\sqrt{2}} (|00\\rangle - |11\\rangle)$.\n\nThe entropies for $I(A:C|M)$ are computed as follows:\n- $S(\\rho_{ACM})$: Each $\\rho_{AC}^{(m)}$ is pure, so $S(\\rho_{AC}^{(m)}) = 0$. The classical register has Shannon entropy $H(p) = -\\frac{1}{2} \\log_2 \\frac{1}{2} - \\frac{1}{2} \\log_2 \\frac{1}{2} = 1$ bit. Thus, $S(\\rho_{ACM}) = H(p) + \\sum_m p_m S(\\rho_{AC}^{(m)}) = 1 + 0 = 1$ bit.\n- $S(\\rho_M)$: $\\rho_M = \\frac{1}{2} |+\\rangle\\langle+|_M + \\frac{1}{2} |-\\rangle\\langle-|_M$, so eigenvalues are $\\frac{1}{2}, \\frac{1}{2}$, and $S(\\rho_M}) = 1$ bit.\n- $\\rho_{AM} = \\text{Tr}_C(\\rho_{ACM}) = \\frac{1}{4} I_A \\otimes I_M$: This is maximally mixed with four eigenvalues of $\\frac{1}{4}$, so $S(\\rho_{AM}) = -4 \\cdot \\frac{1}{4} \\log_2 \\frac{1}{4} = 2$ bits.\n- $\\rho_{CM} = \\text{Tr}_A(\\rho_{ACM})$: By symmetry, same as $\\rho_{AM}$, so $S(\\rho_{CM}) = 2$ bits.\n\nThe conditional mutual information after measurement is:\n\n$$\nI(A:C|M) = S(\\rho_{AM}) + S(\\rho_{CM}) - S(\\rho_{ACM}) - S(\\rho_M) = 2 + 2 - 1 - 1 = 2 \\text{ bits}\n$$\n\n\nThe increase is:\n\n$$\n\\Delta I = I(A:C|M) - I(A:C|B) = 2 - 1 = 1 \\text{ bit}\n$$", "answer": "$$ \\boxed{1} $$", "id": "137327"}]}