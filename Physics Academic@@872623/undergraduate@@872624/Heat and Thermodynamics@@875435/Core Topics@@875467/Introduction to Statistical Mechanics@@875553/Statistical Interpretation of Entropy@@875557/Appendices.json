{"hands_on_practices": [{"introduction": "Many systems in nature, from long polymer chains to magnetic materials, can be effectively modeled as collections of simple two-state components. This exercise introduces a one-dimensional polymer model, which is mathematically equivalent to the classic random walk problem. By calculating the entropy for a specific end-to-end distance, you will practice using binomial coefficients to count the number of microscopic arrangements (microstates) that correspond to a single macroscopic state, directly applying the foundational principles of statistical mechanics [@problem_id:1891757].", "problem": "Consider a simplified one-dimensional model of a polymer chain consisting of $N$ rigid segments linked end-to-end. Each segment has an identical length $L$ and can be oriented either to the right or to the left along a straight line. The state of the entire chain is specified by the orientation of each of its $N$ segments. A macroscopic state, or \"macrostate,\" of the polymer is defined by its total end-to-end displacement from the origin.\n\nLet's assume the first segment starts at the origin. A particular macrostate is observed where the final end of the chain has a net displacement equivalent to $m$ segments to the right. This means the total end-to-end length is $mL$. It is given that $N$ and $m$ are integers of the same parity (both even or both odd), and $|m| \\leq N$.\n\nUsing the principles of statistical mechanics, determine the statistical entropy, $S$, of this specific macrostate. Your answer should be a single closed-form analytic expression in terms of the total number of segments $N$, the net displacement in segment units $m$, and the Boltzmann constant $k_B$.", "solution": "Each segment can point to the right or left along a line, which we denote by a variable $s_{i}=\\pm 1$ for $i=1,\\dots,N$. The end-to-end displacement in segment units is the sum $\\sum_{i=1}^{N}s_{i}$, and the given macrostate specifies\n$$\n\\sum_{i=1}^{N}s_{i}=m,\n$$\nwith $|m|\\leq N$ and $N$ and $m$ of the same parity so that this constraint is attainable.\n\nLet $n_{+}$ be the number of right-pointing segments ($s_{i}=+1$) and $n_{-}$ the number of left-pointing segments ($s_{i}=-1$). These satisfy\n$$\nn_{+}+n_{-}=N,\\qquad n_{+}-n_{-}=m.\n$$\nSolving these linear equations gives\n$$\nn_{+}=\\frac{N+m}{2},\\qquad n_{-}=\\frac{N-m}{2}.\n$$\nThe number of microstates (multiplicity) consistent with this macrostate is the number of ways to choose which $n_{+}$ segments point right among $N$ segments:\n$$\n\\Omega(N,m)=\\binom{N}{\\frac{N+m}{2}}.\n$$\nBy the Boltzmann definition of entropy,\n$$\nS=k_{B}\\ln\\Omega(N,m)=k_{B}\\ln\\!\\left[\\binom{N}{\\frac{N+m}{2}}\\right].\n$$\nThis expression is valid under the stated parity and bound conditions and depends only on $N$, $m$, and $k_{B}$, as required.", "answer": "$$\\boxed{k_{B}\\ln\\!\\left[\\binom{N}{\\frac{N+m}{2}}\\right]}$$", "id": "1891757"}, {"introduction": "While two-state models are a powerful starting point, real physical systems often involve particles distributed among multiple energy or momentum states. This problem generalizes our analysis to a simplified model of a gas where particles can occupy several discrete momentum states according to a specific distribution. This practice will guide you in using the multinomial coefficient—a natural extension of the binomial coefficient—to calculate the entropy, thereby deepening your understanding of how entropy depends on the way particles are distributed among available states [@problem_id:1891788].", "problem": "Consider a simplified toy model for a classical gas composed of $N$ distinguishable, non-interacting particles. The particles are in a system where their momentum is quantized, meaning it can only take values from a discrete set of momentum states.\n\nA specific macroscopic state (macrostate) of this gas is defined by its distribution of particles among these momentum states. For the system in question, a measurement reveals a specific macrostate where exactly half of the particles ($N/2$) occupy a momentum state $p_1$, one-quarter of the particles ($N/4$) occupy a different momentum state $p_2$, and the remaining one-quarter of the particles ($N/4$) occupy a third momentum state $p_3$. All other possible momentum states are empty.\n\nAssume that the total number of particles $N$ is very large, which justifies the use of Stirling's approximation for the natural logarithm of a factorial: $\\ln(n!) \\approx n \\ln n - n$.\n\nBased on this information, determine the statistical entropy $S$ of this particular macrostate. Express your final answer as a closed-form analytic expression in terms of the total number of particles $N$ and the Boltzmann constant $k_B$.", "solution": "We use Boltzmann’s definition of entropy for a macrostate: $S = k_{B} \\ln \\Omega$, where $\\Omega$ is the number of microstates compatible with the given macrostate.\n\nFor $N$ distinguishable, non-interacting particles distributed among momentum states with occupation numbers $\\{n_{i}\\}$, the number of microstates is given by the multinomial count\n$$\n\\Omega = \\frac{N!}{\\prod_{i} n_{i}!}.\n$$\nIn this problem, only three momentum states are occupied with $n_{1} = N/2$, $n_{2} = N/4$, and $n_{3} = N/4$. Hence\n$$\n\\Omega = \\frac{N!}{\\left(\\frac{N}{2}\\right)!\\left(\\frac{N}{4}\\right)!\\left(\\frac{N}{4}\\right)!}.\n$$\nTherefore,\n$$\nS = k_{B} \\left[ \\ln N! - \\ln\\left(\\frac{N}{2}!\\right) - 2 \\ln\\left(\\frac{N}{4}!\\right) \\right].\n$$\nFor large $N$, apply Stirling’s approximation $\\ln(n!) \\approx n \\ln n - n$ to each factorial:\n$$\n\\ln N! \\approx N \\ln N - N,\n$$\n$$\n\\ln\\left(\\frac{N}{2}!\\right) \\approx \\frac{N}{2} \\ln\\left(\\frac{N}{2}\\right) - \\frac{N}{2},\n$$\n$$\n\\ln\\left(\\frac{N}{4}!\\right) \\approx \\frac{N}{4} \\ln\\left(\\frac{N}{4}\\right) - \\frac{N}{4}.\n$$\nSubstituting into $\\ln \\Omega$ gives\n$$\n\\ln \\Omega \\approx \\left(N \\ln N - N\\right) - \\left[\\frac{N}{2} \\ln\\left(\\frac{N}{2}\\right) - \\frac{N}{2}\\right] - 2\\left[\\frac{N}{4} \\ln\\left(\\frac{N}{4}\\right) - \\frac{N}{4}\\right].\n$$\nCollecting terms,\n$$\n\\ln \\Omega \\approx N \\ln N - \\frac{N}{2} \\ln\\left(\\frac{N}{2}\\right) - \\frac{N}{2} \\ln\\left(\\frac{N}{4}\\right),\n$$\nbecause the linear terms in $N$ cancel: $-N + \\frac{N}{2} + \\frac{N}{2} = 0$. Combine the logarithms:\n$$\n\\ln \\Omega \\approx N \\ln N - \\frac{N}{2} \\left(\\ln\\left(\\frac{N}{2}\\right) + \\ln\\left(\\frac{N}{4}\\right)\\right) = N \\ln N - \\frac{N}{2}\\ln\\left(\\frac{N^2}{8}\\right)\n$$\n$$\n\\ln \\Omega \\approx N \\ln N - \\frac{N}{2}\\left(2 \\ln N - \\ln 8\\right) = N \\ln N - N \\ln N + \\frac{N}{2} \\ln 8 = \\frac{N}{2} \\ln 8.\n$$\nSince $\\ln 8 = 3 \\ln 2$, this is\n$$\n\\ln \\Omega \\approx \\frac{3N}{2} \\ln 2.\n$$\nThus the entropy is\n$$\nS = k_{B} \\ln \\Omega \\approx \\frac{3}{2} N k_{B} \\ln 2.\n$$\nThis is the closed-form analytic expression in terms of $N$ and $k_{B}$.", "answer": "$$\\boxed{\\frac{3}{2}\\,N\\,k_{B}\\,\\ln 2}$$", "id": "1891788"}, {"introduction": "A cornerstone of statistical mechanics is the idea that a system at equilibrium is overwhelmingly likely to be found in its most probable macrostate. This exercise provides a quantitative look at *why* this is the case by exploring the concept of statistical fluctuations. By calculating the entropy difference between the most probable state and a state that deviates slightly, you will discover just how sharply the number of microstates peaks around the maximum, offering a concrete justification for the stability and predictability of macroscopic thermodynamic properties [@problem_id:1891776].", "problem": "Consider a simplified model of a paramagnetic material consisting of $N$ distinguishable, non-interacting magnetic dipoles, where $N$ is a very large number. Each dipole moment can align either parallel ('spin-up') or anti-parallel ('spin-down') to an external axis, with equal intrinsic probability for each state. A macrostate of the system is specified by the number of spin-up dipoles, $n$.\n\nThe most probable macrostate is the one with the highest multiplicity (the greatest number of corresponding microscopic configurations), which occurs when the number of spin-up dipoles is $n_{max} = N/2$. For such a system, the statistical fluctuation in the number of spin-up dipoles is characterized by a standard deviation $\\sigma = \\sqrt{N}/2$.\n\nUsing the Boltzmann definition of entropy and applying Stirling's approximation for the logarithm of factorials of large numbers, determine the change in entropy, $\\Delta S = S_{max} - S_{dev}$. Here, $S_{max}$ is the entropy of the most probable macrostate, and $S_{dev}$ is the entropy of a macrostate where the number of spin-up dipoles deviates from the most probable value by one standard deviation, i.e., $n_{dev} = n_{max} + \\sigma$.\n\nProvide your answer as a closed-form analytic expression in terms of the Boltzmann constant, $k_B$.", "solution": "The problem asks for the difference in entropy between the most probable macrostate and a macrostate that deviates by one standard deviation.\n\nFirst, we define the entropy of a macrostate using the Boltzmann formula:\n$$S = k_B \\ln \\Omega$$\nwhere $k_B$ is the Boltzmann constant and $\\Omega$ is the multiplicity of the macrostate. For a system of $N$ distinguishable two-state particles, the multiplicity of a macrostate with $n$ particles in the 'spin-up' state is given by the binomial coefficient:\n$$\\Omega(N, n) = \\binom{N}{n} = \\frac{N!}{n!(N-n)!}$$\nThe entropy is therefore:\n$$S(N, n) = k_B \\ln\\left(\\frac{N!}{n!(N-n)!}\\right) = k_B (\\ln(N!) - \\ln(n!) - \\ln((N-n)!))$$\nSince $N$ and $n$ are very large, we can use a Gaussian approximation for the logarithm of the multiplicity for states near the maximum. The entropy near the maximum can be expressed as a Taylor series expansion around the deviation $\\delta = n - N/2$.\n$$S(N/2 + \\delta) \\approx S_{max} - k_B \\frac{2\\delta^2}{N}$$\nThis is a standard result derived from applying Stirling's approximation to $\\ln(\\Omega(N,n))$ and keeping terms up to second order in $\\delta$.\n\nThe entropy of the most probable macrostate, $S_{max}$, corresponds to $\\delta=0$. For this state, $n_{max} = N/2$, and the entropy is:\n$$S_{max} = S(N/2) = k_B \\ln\\left(\\binom{N}{N/2}\\right) \\approx k_B N \\ln 2$$\nThe problem specifies a deviation equal to the standard deviation, $\\sigma = \\sqrt{N}/2$. So, for the deviated state, we set $\\delta = \\sigma = \\sqrt{N}/2$. The entropy $S_{dev}$ is:\n$$S_{dev} = S(N/2 + \\sigma) \\approx S_{max} - k_B \\frac{2\\sigma^2}{N}$$\nSubstituting the value of $\\sigma$:\n$$S_{dev} \\approx S_{max} - k_B \\frac{2(\\sqrt{N}/2)^2}{N}$$\n$$S_{dev} \\approx S_{max} - k_B \\frac{2(N/4)}{N} = S_{max} - k_B \\frac{N/2}{N}$$\n$$S_{dev} \\approx S_{max} - \\frac{1}{2} k_B$$\nFinally, we calculate the required difference in entropy, $\\Delta S = S_{max} - S_{dev}$:\n$$\\Delta S = S_{max} - \\left(S_{max} - \\frac{1}{2} k_B\\right)$$\n$$\\Delta S = \\frac{1}{2} k_B$$", "answer": "$$\\boxed{\\frac{1}{2}k_{B}}$$", "id": "1891776"}]}