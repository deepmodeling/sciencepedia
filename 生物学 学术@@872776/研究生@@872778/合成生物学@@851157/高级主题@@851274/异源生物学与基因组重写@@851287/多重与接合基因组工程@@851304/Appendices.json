{"hands_on_practices": [{"introduction": "在合成生物学中，通过基因组重编码来重新分配特定密码子的功能是一项强大的技术，例如，可以借此引入新的非天然氨基酸。然而，这一过程必须精确规划，以确保在消除目标密码子的同时，不会改变现有蛋白质的氨基酸序列。本练习将引导您解决一个核心的计算问题：在满足编码功能不变的前提下，计算消除一个特定密码子所需的最小替换次数，从而帮助您掌握基因组编辑策略背后的算法逻辑。[@problem_id:2752407]", "problem": "您正在设计一种高层规划算法，以支持多重自动化基因组工程（Multiplex Automated Genome Engineering, MAGE）和接合组装基因组工程（Conjugative Assembly Genome Engineering, CAGE）的重编码策略。其目的是在保持蛋白质氨基酸序列的同时，对密码子使用变化进行推理。请使用以下基本依据：分子生物学的中心法则（DNA通过翻译到氨基酸），以及将密码子（由 $\\{A,C,G,T\\}$ 构成的三联体）映射到氨基酸的公认标准遗传密码。\n\n给定：\n- 一个固定的标准遗传密码映射 $G_0$，它将 $64$ 个密码子中的每一个映射到 $20$ 种氨基酸之一或一个终止符号。\n- 一个期望的重分配方案，表示为一个修改后的映射 $G_1$。该映射通过改变一个指定的密码子子集的氨基酸分配从 $G_0$ 获得，其余所有密码子保持不变。\n- 一个目标密码子 $c^\\star$，需要从所有编码序列中消除。\n- 一组或多组编码序列，每个序列表示为由 $\\{A,C,G,T\\}$ 构成的字符串，其长度可被 $3$ 整除，并且意在 $G_0$ 和 $G_1$ 两种编码下都在同一读码框内进行翻译。\n\n定义：\n- 对于任何长度为 $3n$ 的编码序列 $s$，可写作 $s = x_1 x_2 \\dots x_n$，其中每个 $x_i$ 是一个密码子（长度为 $3$ 的字符串）。\n- 对于一个密码子 $x$，定义 $a_0(x) = G_0(x)$ 和 $a_1(x) = G_1(x)$。\n- 按位置替换计划是一个函数 $\\phi$，它将每个密码子 $x_i$ 映射到一个密码子 $\\phi(x_i)$（可能与 $x_i$ 相同）。将 $\\phi$ 应用于 $s$ 会通过独立地用 $\\phi(x_i)$ 替换每个 $x_i$ 来产生一个新序列 $\\phi(s)$。\n- 计划 $\\phi$ 是有效的，如果对于输入集中的所有序列的所有位置 $i$，以下条件均成立：\n  - 消除约束：$\\phi(x_i) \\neq c^\\star$。\n  - 实施前保留：$a_0(\\phi(x_i)) = a_0(x_i)$。\n  - 重分配后保留：$a_1(\\phi(x_i)) = a_0(x_i)$。\n- $\\phi$ 的成本是在所有序列中，满足 $\\phi(x_i) \\neq x_i$ 的位置 $i$ 的数量。\n\n任务：\n- 计算所有有效 $\\phi$ 中的最小可能成本，或者报告不存在有效的 $\\phi$。换言之，计算消除所有 $c^\\star$ 实例所需的最小密码子替换次数，同时确保在每个位置上，根据标准遗传密码和重分配密码产生的氨基酸都与原始密码子在标准遗传密码下产生的氨基酸相匹配。\n\n您的程序必须：\n- 将 $G_0$ 实现为标准遗传密码（使用单字母氨基酸代码，终止密码子用 $*$ 表示）。\n- 通过将每个测试用例中提供的重分配覆盖项应用于 $G_0$ 来构建 $G_1$。\n- 对于每个密码子位置 $x_i$，判断是否需要替换，以及是否存在一个有效的同义替换，该替换满足两个保留约束和消除约束。如果任何位置需要替换但不存在有效的密码子，则该测试用例的结果为 $-1$（不可能）。否则，结果为最小替换次数。\n\n设计约束：\n- 假设密码子位置之间是独立的；不允许移动读码框或使用插入缺失（indels）。只允许在固定位置进行密码子替换。\n- 如果一个位置 $x_i$ 既不等于 $c^\\star$，其含义也未被 $G_1$ 改变（即 $a_1(x_i)=a_0(x_i)$），那么可以保持不变以最小化成本。\n- 对于需要进行更改的位置（为了消除 $c^\\star$ 或恢复 $a_1$ 和 $a_0$ 之间的一致性），该位置的有效选择是任何满足 $G_0(y) = a_0(x_i)$、$G_1(y) = a_0(x_i)$ 和 $y \\neq c^\\star$ 的密码子 $y$。\n\n测试套件：\n为以下测试用例提供结果。每个测试用例指定为一个三元组 $(\\text{sequences}, c^\\star, \\text{reassignments})$，其中：\n- $\\text{sequences}$ 是一个编码序列列表，每个序列的长度可被 $3$ 整除。\n- $c^\\star$ 是一个要消除的密码子字符串。\n- $\\text{reassignments}$ 是一个密码子到氨基酸字母的覆盖字典，用于定义 $G_1$。\n\n测试用例如下：\n- 案例 $1$ (顺利路径，终止密码子消除): sequences $=$ [$\\text{\"ATGAAATAG\"}$], $c^\\star=$ $\\text{\"TAG\"}$, reassignments $=$ $\\{\\text{\"TAG\"}:\\text{\"Q\"}\\}$。\n- 案例 $2$ (有义密码子消除): sequences $=$ [$\\text{\"TCGTCGAGT\"}$], $c^\\star=$ $\\text{\"TCG\"}$, reassignments $=$ $\\{\\text{\"TCG\"}:\\text{\"L\"}\\}$。\n- 案例 $3$ (不可能：甲硫氨酸的唯一密码子): sequences $=$ [$\\text{\"ATGATGATG\"}$], $c^\\star=$ $\\text{\"ATG\"}$, reassignments $=$ $\\{\\}$。\n- 案例 $4$ (因重分配而产生的额外强制替换): sequences $=$ [$\\text{\"TCGAGCAGC\"}$], $c^\\star=$ $\\text{\"TCG\"}$, reassignments $=$ $\\{\\text{\"TCG\"}:\\text{\"L\"}, \\text{\"AGC\"}:\\text{\"G\"}\\}$。\n- 案例 $5$ (不可能：目标不相关，但重分配移除了色氨酸的所有密码子): sequences $=$ [$\\text{\"TGGGATTGG\"}$], $c^\\star=$ $\\text{\"TAG\"}$, reassignments $=$ $\\{\\text{\"TGG\"}:\\text{\"*\"}\\}$。\n\n答案规范：\n- 对于每个案例，输出一个整数：最小替换次数，如果不存在有效计划则为 $-1$。\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[\\text{result}_1,\\text{result}_2,\\dots]$）。输出字符串中不允许有空格。\n\n角度和单位：\n- 此问题中没有物理单位或角度度量。\n\n您的程序必须是自包含的，并且不需要用户输入。", "solution": "所提出的问题是合成生物学领域的一个约束优化任务，具体涉及基因组重编码策略。该分析是有效的，并从第一性原理出发。\n\n核心任务是计算所需的最小成本（定义为密码子替换次数），以转换给定的编码序列集。对于每个序列中的每个密码子位置 $i$，此转换必须遵守三个严格的约束：\n$1$. **消除约束**：最终的密码子 $\\phi(x_i)$ 不得为目标密码子 $c^\\star$。\n$2$. **实施前保留约束**：新密码子 $\\phi(x_i)$ 在标准遗传密码 $G_0$ 下编码的氨基酸必须与原始密码子 $x_i$ 在 $G_0$ 下编码的氨基酸相同。形式上，$a_0(\\phi(x_i)) = a_0(x_i)$，其中 $a_0(x) = G_0(x)$。\n$3$. **重分配后保留约束**：新密码子 $\\phi(x_i)$ 在修改后的遗传密码 $G_1$ 下编码的氨基酸也必须与原始密码子 $x_i$ 在 $G_0$ 下编码的氨基酸相同。形式上，$a_1(\\phi(x_i)) = a_0(x_i)$，其中 $a_1(x) = G_1(x)$。\n\n问题指出密码子替换是独立的。这是一个关键的简化假设。这意味着全局最小成本是每个单独密码子位置的最小成本之和。因此，我们可以设计一种策略，为每个密码子逐一做出局部最优决策。总成本是在每个位置产生的成本之和。如果任何位置无法变得有效，则不存在有效的计划 $\\phi$，任务也就无法完成。\n\n我们的算法结构如下。首先，对于每个测试用例，我们建立必要的上下文：标准密码 $G_0$、目标密码子 $c^\\star$ 以及从 $G_0$ 和指定的重分配派生出的重分配密码 $G_1$。基于此上下文，我们可以为每种氨基酸预先计算一组有效的替换密码子。设 $\\text{AA}$ 为一种氨基酸。$\\text{AA}$ 的有效密码子集合 $S_{\\text{AA}}$ 定义为：\n$$S_{\\text{AA}} = \\{ y \\mid G_0(y) = \\text{AA} \\land G_1(y) = \\text{AA} \\land y \\neq c^\\star \\}$$\n这个集合 $S_{\\text{AA}}$ 包含了所有可以作为任何编码 $\\text{AA}$ 的原始密码子 $x_i$（即 $G_0(x_i) = \\text{AA}$）的有效替换的密码子 $y$。这种预计算是高效的，因为它避免了重复搜索。\n\n准备好这些集合 $S_{\\text{AA}}$ 后，我们遍历每个输入序列的每个密码子 $x_i$。对于每个 $x_i$，我们执行一个两步决策过程。设原始氨基酸为 $\\text{AA}_i = G_0(x_i)$。\n\n首先，我们确定对于密码子 $x_i$ 是否必须进行替换。当且仅当 $x_i$ 本身作为其自身的替换（即 $\\phi(x_i) = x_i$）满足所有三个约束时，才不需要替换。这可以简化为检查两个条件：\n$1$. $x_i \\neq c^\\star$\n$2$. $G_1(x_i) = G_0(x_i)$ (因为 $G_0(x_i) = G_0(x_i)$ 是重言式)\n\n如果两个条件都满足，则密码子 $x_i$ 已经有效。最优选择是保持不变，即 $\\phi(x_i) = x_i$，该位置的成本为 $0$。\n\n其次，如果上述任一条件不满足（$x_i = c^\\star$ 或 $G_1(x_i) \\neq G_0(x_i)$），则必须进行替换。只要能找到一个有效的替换，该位置的成本将为 $1$。一个有效的替换必须是预先计算的集合 $S_{\\text{AA}_i}$ 中的一个元素。\n- 如果集合 $S_{\\text{AA}_i}$ 为空，则表示在整个遗传密码中没有密码子可以在给定约束下有效地编码所需的氨基酸 $\\text{AA}_i$。在这种情况下，无法构建有效的计划 $\\phi$。该测试用例的过程终止，结果报告为 $-1$。\n- 如果 $S_{\\text{AA}_i}$ 不为空，则存在有效的替换。我们不需要选择一个具体的替换；知道至少存在一个就足够了。该位置的最小成本为 $1$（因为变更是强制性的），我们将其加到累计的总成本中。\n\n对所有序列中的所有密码子重复此过程。如果过程完成且没有遇到任何无法进行必要替换的位置，则最终累积的总和即为最小总成本。\n\n让我们用案例4来简要说明：sequences = $[\\text{\"TCGAGCAGC\"}]$, $c^\\star = \\text{\"TCG\"}$, reassignments = $\\{\\text{\"TCG\"}:\\text{\"L\"}, \\text{\"AGC\"}:\\text{\"G\"}\\}$。\n密码子是 $x_1=\\text{\"TCG\"}$, $x_2=\\text{\"AGC\"}$, $x_3=\\text{\"AGC\"}$。\n标准密码 $G_0$ 将 $\\text{\"TCG\"}$ 和 $\\text{\"AGC\"}$ 都映射为丝氨酸（$\\text{S}$）。所以，$\\text{AA}_1 = \\text{AA}_2 = \\text{AA}_3 = \\text{S}$。\n重分配的密码 $G_1$ 将 $\\text{\"TCG\"}$ 映射为亮氨酸（$\\text{L}$），将 $\\text{\"AGC\"}$ 映射为甘氨酸（$\\text{G}$）。\n丝氨酸的有效密码子集合 $S_\\text{S}$ 是那些满足 $G_0(y)=\\text{S}$、$G_1(y)=\\text{S}$ 且 $y \\neq \\text{\"TCG\"}$ 的密码子 $y$。丝氨酸的密码子有 $\\text{\"TCT\"}, \\text{\"TCC\"}, \\text{\"TCA\"}, \\text{\"TCG\"}, \\text{\"AGT\"}, \\text{\"AGC\"}$。我们必须排除 $\\text{\"TCG\"}$（作为 $c^\\star$）和 $\\text{\"AGC\"}$（因为 $G_1(\\text{\"AGC\"})=\\text{G}$）。这使得 $S_\\text{S} = \\{\\text{\"TCT\"}, \\text{\"TCC\"}, \\text{\"TCA\"}, \\text{\"AGT\"}\\}$。\n\n- 对于 $x_1=\\text{\"TCG\"}$：由于 $x_1=c^\\star$，替换是强制性的。集合 $S_\\text{S}$ 不为空，因此可以进行替换。成本为 $1$。\n- 对于 $x_2=\\text{\"AGC\"}$：由于 $G_1(\\text{\"AGC\"}) \\neq G_0(\\text{\"AGC\"})$，替换是强制性的。集合 $S_\\text{S}$ 不为空。成本为 $1$。\n- 对于 $x_3=\\text{\"AGC\"}$：与 $x_2$ 相同。成本为 $1$。\n\n最小总成本为 $1 + 1 + 1 = 3$。这种系统的、与位置无关的评估保证了正确的最小成本或正确地识别出不可能性。", "answer": "```python\nimport numpy as np\n# The problem does not necessitate the use of numpy or scipy,\n# but they are included to strictly adhere to the specified environment.\n\ndef solve():\n    \"\"\"\n    Solves the MAGE/CAGE codon replacement problem for a suite of test cases.\n    \"\"\"\n\n    # The Standard Genetic Code, mapping DNA codons to amino acids.\n    # '*' denotes a STOP codon.\n    STANDARD_GENETIC_CODE = {\n        'TTT': 'F', 'TTC': 'F', 'TTA': 'L', 'TTG': 'L',\n        'TCT': 'S', 'TCC': 'S', 'TCA': 'S', 'TCG': 'S',\n        'TAT': 'Y', 'TAC': 'Y', 'TAA': '*', 'TAG': '*',\n        'TGT': 'C', 'TGC': 'C', 'TGA': '*', 'TGG': 'W',\n        'CTT': 'L', 'CTC': 'L', 'CTA': 'L', 'CTG': 'L',\n        'CCT': 'P', 'CCC': 'P', 'CCA': 'P', 'CCG': 'P',\n        'CAT': 'H', 'CAC': 'H', 'CAA': 'Q', 'CAG': 'Q',\n        'CGT': 'R', 'CGC': 'R', 'CGA': 'R', 'CGG': 'R',\n        'ATT': 'I', 'ATC': 'I', 'ATA': 'I', 'ATG': 'M',\n        'ACT': 'T', 'ACC': 'T', 'ACA': 'T', 'ACG': 'T',\n        'AAT': 'N', 'AAC': 'N', 'AAA': 'K', 'AAG': 'K',\n        'AGT': 'S', 'AGC': 'S', 'AGA': 'R', 'AGG': 'R',\n        'GTT': 'V', 'GTC': 'V', 'GTA': 'V', 'GTG': 'V',\n        'GCT': 'A', 'GCC': 'A', 'GCA': 'A', 'GCG': 'A',\n        'GAT': 'D', 'GAC': 'D', 'GAA': 'E', 'GAG': 'E',\n        'GGT': 'G', 'GGC': 'G', 'GGA': 'G', 'GGG': 'G',\n    }\n    \n    ALL_CODONS = list(STANDARD_GENETIC_CODE.keys())\n    \n    test_cases = [\n        # Case 1: Stop-codon elimination\n        ([\"ATGAAATAG\"], \"TAG\", {\"TAG\": \"Q\"}),\n        # Case 2: Sense-codon elimination\n        ([\"TCGTCGAGT\"], \"TCG\", {\"TCG\": \"L\"}),\n        # Case 3: Impossible due to unique methionine codon\n        ([\"ATGATGATG\"], \"ATG\", {}),\n        # Case 4: Reassignment forces additional replacements\n        ([\"TCGAGCAGC\"], \"TCG\", {\"TCG\": \"L\", \"AGC\": \"G\"}),\n        # Case 5: Impossible due to losing all codons for an amino acid\n        ([\"TGGGATTGG\"], \"TAG\", {\"TGG\": \"*\"}),\n    ]\n\n    results = []\n    \n    for sequences, c_star, reassignments in test_cases:\n        \n        G0 = STANDARD_GENETIC_CODE\n        G1 = G0.copy()\n        G1.update(reassignments)\n        \n        # Pre-compute the set of valid replacement codons for each original amino acid.\n        # A codon `y` is a valid replacement for an original amino acid `aa` if:\n        # 1. G0(y) == aa (pre-preservation via synonymy)\n        # 2. G1(y) == aa (post-preservation)\n        # 3. y != c_star (elimination)\n        valid_codons_map = {}\n        all_amino_acids = set(G0.values())\n        for aa in all_amino_acids:\n            valid_set = set()\n            for codon in ALL_CODONS:\n                if G0[codon] == aa and G1[codon] == aa and codon != c_star:\n                    valid_set.add(codon)\n            valid_codons_map[aa] = valid_set\n\n        total_cost = 0\n        possible = True\n        \n        for seq in sequences:\n            if not possible:\n                break\n            \n            # Process the sequence codon by codon\n            for i in range(0, len(seq), 3):\n                codon = seq[i:i+3]\n                original_aa = G0[codon]\n                \n                # Check if codon needs replacement. This is true if it's the target\n                # for elimination OR if its meaning changes in G1.\n                needs_replacement = (codon == c_star) or (G1[codon] != original_aa)\n                \n                if needs_replacement:\n                    # A change is mandatory. Check if a valid replacement exists.\n                    if not valid_codons_map[original_aa]:\n                        # No valid replacement codon exists for this amino acid.\n                        total_cost = -1\n                        possible = False\n                        break\n                    else:\n                        # A replacement is possible and necessary.\n                        total_cost += 1\n                # If no replacement is needed, cost is 0, so do nothing.\n\n        results.append(total_cost)\n\n    # Format the final output string exactly as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2752407"}, {"introduction": "大规模基因组的重新设计通常需要将巨大的DNA序列分成较小的片段，然后通过共轭接合等方法逐步组装。这种分段策略是一个关键的优化问题：片段越长，转移成功率越低，需要的共轭次数就越多；而片段越短，虽然单次成功率高，但总的组装步骤会增加。本练习模拟了在共轭组装基因组工程（CAGE）中，如何根据片段长度与转移成功率之间的物理关系，利用动态规划来制定最佳的分段方案，以最小化总实验时间。[@problem_id:2752386]", "problem": "一个实验室正在计划一个接合组装基因组工程 (Conjugative Assembly Genome Engineering, CAGE) 项目，通过将一组连续的DNA片段转移到一个受体菌株中来组装一个重新设计的基因组。在每一轮接合中，尝试转移一个长度为 $\\ell$（单位为千碱基，缩写为 kb）的连续片段的成功概率为 $p(\\ell)$，且此过程独立于所有其他轮次和片段。该实验室可以选择一种分段方案，将一个目标基因组长度 $L$（单位为 kb）分割成一个允许多重集的片段大小集合 $S$（单位为 kb），并受限于片段数量最多为 $K_{\\max}$ 的约束。每轮成功转移的概率根据指数法则随片段长度的增加而下降。目标是计算出一个最优的分段方案，以最小化将所有片段按顺序成功转移到单个菌株中所需的总期望接合轮数。\n\n使用以下基本事实和定义作为出发点：\n- 根据分子生物学的中心法则，DNA片段是一种物理基底，其操作概率不依赖于符号解释，而取决于过程参数；因此，我们将每次接合尝试建模为一个成功概率与长度相关的伯努利试验。\n- 对于每次试验成功概率为 $p \\in (0,1]$ 的伯努利过程，首次成功所需的期望试验次数（一个几何随机变量）为 $1/p$。\n- 假设各个片段之间相互独立，并且严格按顺序组装到单个菌株中（即，片段在时间上不重叠，必须一个接一个地完成），总期望轮数是每个片段的期望轮数之和。\n\n长度依赖的转移概率模型：\n- 设 $S$ 为允许的片段大小集合（单位为 kb），并设 $\\ell_{\\min} = \\min S$。\n- 设 $p_0 \\in (0,1]$ 为长度为 $\\ell_{\\min}$ 的片段在单轮中的基准成功概率。\n- 设 $\\alpha > 0$ 为一个衰减常数，单位为 $\\text{kb}^{-1}$。\n- 对于任何允许的片段长度 $\\ell \\in S$，定义\n$$\np(\\ell) = \\min\\!\\left(1,\\; p_0 \\, e^{-\\alpha(\\ell - \\ell_{\\min})}\\right).\n$$\n- 那么，对于单个长度为 $\\ell$ 的片段，期望轮数为\n$$\n\\mathbb{E}[\\text{rounds} \\mid \\ell] = \\frac{1}{p(\\ell)}.\n$$\n\n优化问题：\n- 选择一个多重集 $\\{\\ell_1,\\ell_2,\\dots,\\ell_k\\}$，使得每个 $\\ell_i \\in S$，$\\sum_{i=1}^{k} \\ell_i = L$，并且 $1 \\leq k \\leq K_{\\max}$。\n- 最小化总期望轮数\n$$\n\\sum_{i=1}^{k} \\frac{1}{p(\\ell_i)}.\n$$\n- 如果使用 $S$ 中的元素无法在最多 $K_{\\max}$ 个片段内精确分割 $L$，则报告无可行解。\n- 决胜规则：如果多个分段方案（在模型下的精确计算中）达到了相同的最小总期望轮数，选择 $k$ 值最小的方案；如果仍然平局，选择字典序最小的非递减列表 $(\\ell_1\\leq \\ell_2 \\leq \\dots \\leq \\ell_k)$。\n\n物理单位和输出要求：\n- 所有长度必须以千碱基（kb）表示。\n- 概率是无单位的；不要使用百分号；如果需要，以十进制形式表示任何实值结果。\n- 本问题不涉及角度。\n\n你的任务是编写一个完整的程序，对下面的每个测试用例，根据模型和约束条件计算最优分段方案。如果某个测试用例没有可行的分段方案，则返回空列表。你的程序应该生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表，每个结果本身是一个按非递减顺序列出的整数列表（片段大小，单位为 kb）。例如，一个包含三个结果的有效输出可能看起来像 “[[a,b],[c,d,e],[]]”。\n\n测试套件：\n- 用例 $1$ (通用成功路径):\n  - $L = 200$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 5$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- 用例 $2$ (在严格的 $K_{\\max}$ 下不可行):\n  - $L = 180$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 2$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- 用例 $3$ (单片段边界情况):\n  - $L = 80$ kb\n  - $S = \\{20,40,60,80\\}$ kb\n  - $K_{\\max} = 1$\n  - $p_0 = 0.92$\n  - $\\alpha = 0.03$ $\\text{kb}^{-1}$\n- 用例 $4$ (备选尺寸与权衡):\n  - $L = 240$ kb\n  - $S = \\{30,60,90\\}$ kb\n  - $K_{\\max} = 4$\n  - $p_0 = 0.85$\n  - $\\alpha = 0.02$ $\\text{kb}^{-1}$\n- 用例 $5$ (平衡的内部最优解):\n  - $L = 150$ kb\n  - $S = \\{25,50,75\\}$ kb\n  - $K_{\\max} = 3$\n  - $p_0 = 0.90$\n  - $\\alpha = 0.025$ $\\text{kb}^{-1}$\n\n最终输出格式：\n- 你的程序应该生成单行输出，其中包含按顺序排列的各用例的分段列表，格式为 Python 风格的列表字面量，例如 '[[...],[...],...]'，其中每个内部列表包含表示非递减顺序的片段大小（单位为 kb）的整数。如果某个用例没有可行的分段方案，则为该用例输出 '[]'。", "solution": "所述问题是有效的。它在科学上基于分子生物学和概率论的原理，在数学上被明确表述为一个约束优化问题，并使用了客观、无歧义的术语。所有必要的数据都已提供。不存在内部矛盾或违反基本原则的情况。\n\n问题在于找到目标基因组总长度 $L$ 的一个最优分割，将其分割成一个多重集片段 $\\{\\ell_1, \\ell_2, \\dots, \\ell_k\\}$。每个片段长度 $\\ell_i$ 必须从给定的允许大小集合 $S$ 中选择。该分割必须满足两个约束条件：片段长度之和必须等于目标长度，即 $\\sum_{i=1}^{k} \\ell_i = L$，并且片段总数不能超过一个最大值，即 $k \\leq K_{\\max}$。目标是最小化总期望接合轮数，该值由每个片段的期望轮数之和给出：\n$$\n\\text{Minimize } \\sum_{i=1}^{k} \\mathbb{E}[\\text{rounds} \\mid \\ell_i] = \\sum_{i=1}^{k} \\frac{1}{p(\\ell_i)}\n$$\n其中，长度为 $\\ell$ 的片段的成功概率 $p(\\ell)$ 定义为\n$$\np(\\ell) = \\min\\!\\left(1,\\; p_0 \\, e^{-\\alpha(\\ell - \\ell_{\\min})}\\right)\n$$\n其中 $\\ell_{\\min} = \\min S$。\n\n这个问题是经典“换零钱问题”的一个变体，可以使用动态规划来最优地解决。其核心思想是为从 $1$ 到 $L$ 的递增总长度迭代地构建解决方案。\n\n首先，可以进行一个重要的优化。任何有效的分段都是集合 $S$ 中整数的和。因此，总长度 $L$ 必须是 $S$ 中元素的整数线性组合。这意味着 $L$ 必须是 $S$ 中所有片段大小的最大公约数（GCD）的倍数。如果 $L \\pmod{\\text{gcd}(S)} \\neq 0$，则不存在可行解。这个检查可以立即剪除不可行的情况。如果此条件成立，我们可以通过将 $L$ 和 $S$ 中的所有元素除以它们的 GCD 来缩小问题规模，从而减小动态规划算法的状态空间大小。\n\n设缩放后的目标长度为 $L'$，缩放后的片段大小集合为 $S'$。我们定义一个大小为 $L'+1$ 的 DP 表 `dp`。每个条目 `dp[i]` 将存储组装总缩放长度为 $i$ 的最优解。一个“最优解”必须封装决胜规则所需的所有信息。因此，`dp[i]` 将是一个元组：`(total_cost, num_segments, segmentation_list)`。\n\n递归的基例是总长度为 $0$ 的情况，这需要零个片段，成本为零。\n$$\n\\text{dp}[0] = (0.0, 0, [])\n$$\n所有其他 $i > 0$ 的条目 `dp[i]` 都被初始化为一个表示无穷大的状态，例如 $(\\infty, \\infty, [])$。\n\nDP 表以迭代方式填充，针对从 $1$ 到 $L'$ 的缩放长度 $i$。对于每个长度 $i$，我们考虑通过将一个大小为 $s' \\in S'$ 的片段添加到一个先前计算出的长度为 $i-s'$ 的最优解上来形成它。原始片段大小为 $s = s' \\cdot \\text{gcd}(S)$。从 `dp[i-s']` 和片段 $s$ 派生出的候选解是：\n-   新成本：$\\text{dp}[i-s'].\\text{cost} + \\frac{1}{p(s)}$\n-   新片段计数：$\\text{dp}[i-s'].\\text{count} + 1$\n-   新分段列表：将 $s$ 附加到 $\\text{dp}[i-s'].\\text{list}$ 后排序的列表\n\n只有当候选解的片段计数不超过 $K_{\\max}$ 时，它才是有效的。如果有效，它将与存储在 `dp[i]` 中的当前最优解进行比较。比较严格遵循指定的决胜层级：\n1.  优先选择总成本较低的解。浮点数比较使用一个小的容差 $\\epsilon$。\n2.  如果成本相等，优先选择片段数量较少（$k$ 值较小）的解。\n3.  如果成本和片段计数都相等，优先选择字典序较小的非递减分段列表。\n\n如果候选解优于 `dp[i]` 中的现有条目，则用新的最优解元组更新 `dp[i]`。\n\n在 DP 表完全计算到 $L'$ 后，条目 `dp[L']` 包含原始问题的最优解。如果 `dp[L']` 中的成本仍然是无穷大，则表示没有找到可行的分段方案。否则，存储在 `dp[L']` 中的分段列表就是最终答案。", "answer": "```python\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the CAGE segmentation problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: General happy path\n        {'L': 200, 'S': [20, 40, 60, 80], 'K_max': 5, 'p0': 0.92, 'alpha': 0.03},\n        # Case 2: Infeasible under tight K_max\n        {'L': 180, 'S': [20, 40, 60, 80], 'K_max': 2, 'p0': 0.92, 'alpha': 0.03},\n        # Case 3: Boundary with a single segment\n        {'L': 80, 'S': [20, 40, 60, 80], 'K_max': 1, 'p0': 0.92, 'alpha': 0.03},\n        # Case 4: Alternative allowed sizes and trade-offs\n        {'L': 240, 'S': [30, 60, 90], 'K_max': 4, 'p0': 0.85, 'alpha': 0.02},\n        # Case 5: Balanced interior optimum\n        {'L': 150, 'S': [25, 50, 75], 'K_max': 3, 'p0': 0.90, 'alpha': 0.025},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = find_optimal_segmentation(**case)\n        results.append(result)\n\n    # Format the final output string to match \"[[...],[...],[]]\"\n    def format_list_of_lists(lol):\n        outer_parts = []\n        for inner_list in lol:\n            outer_parts.append(f\"[{','.join(map(str, inner_list))}]\")\n        return f\"[{','.join(outer_parts)}]\"\n\n    print(format_list_of_lists(results))\n\ndef find_optimal_segmentation(L, S, K_max, p0, alpha):\n    \"\"\"\n    Finds the optimal segmentation for a single case using dynamic programming.\n    \"\"\"\n    if not S or L == 0:\n        return []\n\n    # --- Pre-computation and Optimizations ---\n    # GCD optimization: if L is not divisible by gcd of S, no solution exists.\n    g = S[0]\n    for i in range(1, len(S)):\n        g = math.gcd(g, S[i])\n    if L % g != 0:\n        return []\n\n    L_scaled = L // g\n    S_sorted = sorted(S)\n    S_scaled = [s // g for s in S_sorted]\n\n    # Calculate transfer costs for each allowed segment size.\n    l_min = S_sorted[0]\n    \n    def get_prob(l):\n        return min(1.0, p0 * np.exp(-alpha * (l - l_min)))\n        \n    costs = {s: 1.0 / get_prob(s) for s in S_sorted}\n\n    # --- Dynamic Programming Setup ---\n    # dp[i] stores a tuple: (total_cost, num_segments, segmentation_list)\n    dp = [(float('inf'), float('inf'), []) for _ in range(L_scaled + 1)]\n    dp[0] = (0.0, 0, [])\n    \n    EPS = 1e-9 # Epsilon for floating-point comparisons\n\n    def is_better(candidate, best):\n        cand_cost, cand_k, cand_seg = candidate\n        best_cost, best_k, best_seg = best\n\n        if cand_cost  best_cost - EPS: return True\n        if cand_cost > best_cost + EPS: return False\n        \n        if cand_k  best_k: return True\n        if cand_k > best_k: return False\n        \n        if cand_seg  best_seg: return True\n        return False\n\n    # --- DP Computation ---\n    for i in range(1, L_scaled + 1):\n        for s_idx, s_scaled in enumerate(S_scaled):\n            s_original = S_sorted[s_idx]\n            if i >= s_scaled:\n                prev_cost, prev_k, prev_seg = dp[i - s_scaled]\n\n                if prev_k  K_max:\n                    new_cost = prev_cost + costs[s_original]\n                    new_k = prev_k + 1\n                    \n                    # To avoid re-sorting, create the sorted list only when needed for tie-breaking.\n                    # For simplicity and correctness given problem constraints, we form it here.\n                    new_seg = sorted(prev_seg + [s_original])\n                    candidate = (new_cost, new_k, new_seg)\n\n                    if is_better(candidate, dp[i]):\n                        dp[i] = candidate\n\n    # --- Final Result ---\n    final_cost, _, final_segmentation = dp[L_scaled]\n\n    if final_cost == float('inf'):\n        return []\n    else:\n        return final_segmentation\n\nsolve()\n```", "id": "2752386"}, {"introduction": "在多重基因组编辑实验（如MAGE）后，我们需要通过高通量测序来验证编辑的效率和结果。当多个位点被同时编辑，且这些位点的序列非常相似时，测序读段（reads）可能无法唯一地比对到某个特定位点，产生归属不明确的问题。本练习将指导您使用期望最大化（Expectation-Maximization, EM）算法，这是一种处理含潜在变量模型的经典统计方法，来解决这种模糊性，从而准确估计不同编辑位点的相对丰度并量化其不确定性。[@problem_id:2752515]", "problem": "您正在为 Multiplex Automated Genome Engineering (MAGE) 或 Conjugative Assembly Genome Engineering (CAGE) 过程中产生的短测序读数（read）分配到一组密切相关的编辑位点（locus）进行建模。假设每个读数都精确地源自一个编辑位点，但位点间的相似性和测序错误会导致模糊的比对。对于每个读数-位点对，您会得到一个非负的相容性得分，该得分与给定该位点后观察到该读数的条件概率成正比。您将使用基于第一性原理的期望最大化方法来估计位点的混合比例，并量化读数分配和位点比例中的不确定性。\n\n基本原理：\n- 分子生物学的中心法则提供了从DNA到RNA再到蛋白质的信息流；高通量测序读数源自DNA，其比对不确定性源于随机测序错误和序列相似性。\n- Bayes’ theorem 和混合模型：如果一个样本来自比例未知的多个来源的混合，那么对于独立观测，其似然函数是所有观测的混合加权分量似然之和的乘积。\n- 期望最大化（Expectation-Maximization, EM）是针对潜变量模型进行最大似然估计的一种原则性方法，它在计算期望的潜在责任和最大化参数之间交替进行。\n- 为了量化多项式混合比例向量中的参数不确定性，Dirichlet先验会产生Dirichlet后验，从中可以获得解析方差。\n\n数学规格：\n- 设存在 $R$ 个读数和 $L$ 个编辑位点。设 $Q \\in \\mathbb{R}_{\\ge 0}^{R \\times L}$，其条目 $Q_{r\\ell}$ 与 $p(x_r \\mid z_r = \\ell)$ 成正比，其中 $x_r$ 表示读数 $r$，$z_r$ 是其潜在的位点身份。设位点混合比例为 $p = (p_1,\\dots,p_L)$，且满足 $p_\\ell \\ge 0$ 和 $\\sum_{\\ell=1}^L p_\\ell = 1$。\n- 在该混合模型下，数据的对数似然为\n$$\n\\mathcal{L}(p) = \\sum_{r=1}^R \\log\\left(\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell}\\right).\n$$\n- 引入责任（后验分配概率）$\\gamma_{r\\ell}$，满足 $\\gamma_{r\\ell} \\ge 0$ 和 $\\sum_{\\ell=1}^L \\gamma_{r\\ell} = 1$。期望步骤计算\n$$\n\\gamma_{r\\ell} \\propto p_\\ell Q_{r\\ell},\n$$\n并遵循约定：如果 $\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell} = 0$（一个无信息的读数），则 $\\gamma_{r\\cdot} = p$。\n- 最大化步骤通过对软计数进行归一化来更新 $p$：\n$$\np_\\ell \\leftarrow \\frac{1}{R}\\sum_{r=1}^R \\gamma_{r\\ell}.\n$$\n- 为对 $p$ 进行不确定性量化，使用一个浓度向量为 $\\alpha_0 \\in \\mathbb{R}_{0}^L$ 的对称Dirichlet先验，并计算一个Dirichlet后验，其参数为 $a_\\ell = \\alpha_{0,\\ell} + \\sum_{r=1}^R \\gamma_{r\\ell}$，总浓度为 $A = \\sum_{\\ell=1}^L a_\\ell$。$p_\\ell$ 的后验方差为\n$$\n\\mathrm{Var}(p_\\ell) = \\frac{a_\\ell (A - a_\\ell)}{A^2 (A+1)}.\n$$\n- 对于读数分配的不确定性，使用平均每读数熵，\n$$\n\\bar{H} = \\frac{1}{R}\\sum_{r=1}^R \\left(-\\sum_{\\ell=1}^L \\gamma_{r\\ell} \\log \\gamma_{r\\ell}\\right),\n$$\n其中使用自然对数，并遵循约定 $0 \\log 0 = 0$。\n\n编程任务：\n- 实现期望最大化算法，以在给定 $Q$ 的情况下找到 $p$ 的最大似然估计。对于无信息的读数，请使用上述的责任约定。将 $p$ 初始化为均匀分布，迭代直至 $\\mathcal{L}(p)$ 的绝对变化小于 $10^{-12}$ 或达到 $10000$ 次迭代，以先到者为准。使用自然对数。\n- 收敛后，使用每个测试用例提供的浓度向量 $\\alpha_0$ 的对称Dirichlet先验，计算后验标准差 $\\sigma_\\ell = \\sqrt{\\mathrm{Var}(p_\\ell)}$。\n- 计算平均每读数熵 $\\bar{H}$。\n\n测试套件：\n对于每个测试用例，您将得到 $Q$ 和 $\\alpha_0$。\n\n- 测试用例 1（理想情况，三个位点）：\n设 $Q^{(1)} \\in \\mathbb{R}^{5 \\times 3}$，其行为\n(0.90, 0.05, 0.05),\n(0.80, 0.10, 0.10),\n(0.10, 0.80, 0.10),\n(0.05, 0.10, 0.85),\n(0.33, 0.33, 0.34).\n设 $\\alpha_0^{(1)} = (1.0, 1.0, 1.0)$。\n\n- 测试用例 2（不可辨识性/对称性，两个位点）：\n设 $Q^{(2)} \\in \\mathbb{R}^{4 \\times 2}$，其行为\n(0.50, 0.50),\n(0.70, 0.70),\n(0.10, 0.10),\n(1.00, 1.00).\n设 $\\alpha_0^{(2)} = (1.0, 1.0)$。\n\n- 测试用例 3（零支持位点，三个位点）：\n设 $Q^{(3)} \\in \\mathbb{R}^{4 \\times 3}$，其行为\n(0.60, 0.40, 0.00),\n(0.10, 0.90, 0.00),\n(0.50, 0.50, 0.00),\n(0.90, 0.10, 0.00).\n设 $\\alpha_0^{(3)} = (1.0, 1.0, 1.0)$。\n\n- 测试用例 4（四个位点，不同模糊度）：\n设 $Q^{(4)} \\in \\mathbb{R}^{6 \\times 4}$，其行为\n(0.40, 0.30, 0.20, 0.10),\n(0.25, 0.25, 0.25, 0.25),\n(0.10, 0.20, 0.30, 0.40),\n(0.35, 0.30, 0.20, 0.15),\n(0.05, 0.05, 0.45, 0.45),\n(0.45, 0.10, 0.30, 0.15).\n设 $\\alpha_0^{(4)} = (1.0, 1.0, 1.0, 1.0)$。\n\n要求的最终输出格式：\n- 对于每个具有 $L$ 个位点的测试用例，输出一个长度为 $2L+1$ 的扁平列表，依次包含：$L$ 个估计的混合比例 $(p_1,\\dots,p_L)$，$L$ 个后验标准差 $(\\sigma_1,\\dots,\\sigma_L)$，以及最后的标量平均熵 $\\bar{H}$。所有浮点数必须四舍五入到 $6$ 位小数。\n- 将四个测试用例的列表聚合成一个单一列表，并精确打印一行，该行包含此聚合列表，格式为方括号内的逗号分隔列表，例如：$[\\,[\\dots],\\,[\\dots],\\,[\\dots],\\,[\\dots]\\,]$。", "solution": "该问题要求从一个包含 $R$ 个测序读数的数据集中，估计 $L$ 个基因组位点的混合比例，并量化这些估计的不确定性。所提供的数据是一个相容性矩阵 $Q \\in \\mathbb{R}_{\\ge 0}^{R \\times L}$，其中条目 $Q_{r\\ell}$ 与给定读数 $r$ 源自位点 $\\ell$ 的条件概率 $p(x_r | z_r = \\ell)$ 成正比。\n\n其底层的统计框架是一个有限混合模型。未知的混合比例为 $p = (p_1, \\dots, p_L)$，必须满足对所有 $\\ell \\in \\{1, \\dots, L\\}$ 都有 $p_\\ell \\ge 0$ 且 $\\sum_{\\ell=1}^L p_\\ell = 1$。假设观测到的读数是独立的，其对数似然由下式给出：\n$$\n\\mathcal{L}(p) = \\sum_{r=1}^R \\log\\left(\\sum_{\\ell=1}^L p_\\ell Q_{r\\ell}\\right)\n$$\n直接最大化 $\\mathcal{L}(p)$ 是复杂的。在这种潜变量模型中，一种标准且有原则的最大似然估计（MLE）方法是期望最大化（EM）算法。该算法在期望（E）步骤和最大化（M）步骤之间迭代交替，直至收敛。\n\n首先，初始化参数 $p$。选择一个均匀分布，使得对所有 $\\ell$ 都有 $p_\\ell^{(0)} = 1/L$。\n\nE步骤计算潜变量 $z_r$ 的期望值，该变量指示每个读数 $r$ 的来源位点。这等同于在给定当前参数估计 $p$ 的情况下，计算位点 $\\ell$ 对读数 $r$ 负责的后验概率或“责任” $\\gamma_{r\\ell}$。应用Bayes’ theorem：\n$$\n\\gamma_{r\\ell} = P(z_r = \\ell | x_r, p) = \\frac{p(x_r | z_r = \\ell) P(z_r = \\ell)}{\\sum_{k=1}^L p(x_r | z_k = k) P(z_k = k)} = \\frac{p_\\ell Q_{r\\ell}}{\\sum_{k=1}^L p_k Q_{rk}}\n$$\n当分母 $\\sum_{k=1}^L p_k Q_{rk}$ 为零时，会出现一个特殊情况，这表示在当前模型下读数 $r$ 是不可能出现的。对于这类无信息的读数，责任向量 $\\gamma_{r\\cdot}$ 被定义为当前的比例向量 $p$。\n\nM步骤使用在E步骤中计算出的责任来更新参数估计 $p$，以最大化期望的完整数据对数似然。这产生了一个简单直观的更新规则，其中每个比例 $p_\\ell$ 被设置为该位点在所有读数上的平均责任：\n$$\np_\\ell^{\\text{(new)}} \\leftarrow \\frac{1}{R} \\sum_{r=1}^R \\gamma_{r\\ell}\n$$\n重复E和M步骤，直到连续迭代间对数似然 $\\mathcal{L}(p)$ 的绝对变化小于容差 $10^{-12}$，或达到最大迭代次数 $10000$ 次为止。\n\n收敛到最大似然估计 $\\hat{p}$ 后，通过两种方式量化不确定性。\n\n首先，使用贝叶斯框架评估参数估计 $\\hat{p}$ 的不确定性。在比例向量 $p$ 上放置一个对称的Dirichlet先验，$p \\sim \\mathrm{Dir}(\\alpha_0, \\dots, \\alpha_0)$。由于Dirichlet分布和多项式分布的共轭性，后验分布也是一个Dirichlet分布，$p | \\{x_r\\} \\sim \\mathrm{Dir}(a_1, \\dots, a_L)$，其参数为：\n$$\na_\\ell = \\alpha_{0,\\ell} + \\sum_{r=1}^R \\gamma_{r\\ell}\n$$\n其中 $\\gamma_{r\\ell}$ 是使用最大似然估计 $\\hat{p}$ 计算出的最终责任。总浓度为 $A = \\sum_{\\ell=1}^L a_\\ell$。每个分量 $p_\\ell$ 的后验方差则可以解析地由下式给出：\n$$\n\\mathrm{Var}(p_\\ell) = \\frac{a_\\ell (A - a_\\ell)}{A^2 (A+1)}\n$$\n报告的不确定性是标准差 $\\sigma_\\ell = \\sqrt{\\mathrm{Var}(p_\\ell)}$。\n\n其次，使用香农熵量化单个读数分配到各个位点的不确定性。对于每个读数 $r$，其责任向量 $\\gamma_{r\\cdot}$ 的熵度量了其来源的模糊性：$H(\\gamma_{r\\cdot}) = -\\sum_{\\ell=1}^L \\gamma_{r\\ell} \\log \\gamma_{r\\ell}$，其中使用自然对数，并遵循 $0 \\log 0 = 0$ 的约定。平均每读数熵 $\\bar{H}$ 为整个数据集的总体分配模糊性提供了一个单一的度量：\n$$\n\\bar{H} = \\frac{1}{R}\\sum_{r=1}^R H(\\gamma_{r\\cdot})\n$$\n此完整过程被实现用来处理所提供的测试用例，从而得到估计的比例、它们的后验标准差以及平均分配熵。", "answer": "```python\nimport numpy as np\nfrom scipy.special import xlogy\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"Q\": [\n                [0.90, 0.05, 0.05],\n                [0.80, 0.10, 0.10],\n                [0.10, 0.80, 0.10],\n                [0.05, 0.10, 0.85],\n                [0.33, 0.33, 0.34],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.50, 0.50],\n                [0.70, 0.70],\n                [0.10, 0.10],\n                [1.00, 1.00],\n            ],\n            \"alpha_0\": [1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.60, 0.40, 0.00],\n                [0.10, 0.90, 0.00],\n                [0.50, 0.50, 0.00],\n                [0.90, 0.10, 0.00],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0],\n        },\n        {\n            \"Q\": [\n                [0.40, 0.30, 0.20, 0.10],\n                [0.25, 0.25, 0.25, 0.25],\n                [0.10, 0.20, 0.30, 0.40],\n                [0.35, 0.30, 0.20, 0.15],\n                [0.05, 0.05, 0.45, 0.45],\n                [0.45, 0.10, 0.30, 0.15],\n            ],\n            \"alpha_0\": [1.0, 1.0, 1.0, 1.0],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_case(case[\"Q\"], case[\"alpha_0\"])\n        results.append(result)\n\n    # Format the final output string as a list of lists.\n    # The string representation of each sublist is joined by a comma.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _solve_case(Q_list, alpha_0_list):\n    \"\"\"\n    Solves a single test case for MAGE/CAGE analysis.\n    \"\"\"\n    # 1. Initialization\n    Q = np.array(Q_list, dtype=np.float64)\n    alpha_0 = np.array(alpha_0_list, dtype=np.float64)\n    R, L = Q.shape  # Number of reads and loci\n\n    p = np.full(L, 1.0 / L, dtype=np.float64)\n    \n    TOL = 1e-12\n    MAX_ITER = 10000\n\n    log_likelihood_old = -np.inf\n\n    # 2. Expectation-Maximization (EM) Loop\n    for _ in range(MAX_ITER):\n        # --- E-step: Compute responsibilities (gamma) ---\n        weighted_scores = Q @ p\n        numerator = p * Q  # Element-wise product, using broadcasting\n\n        # Denominator for Bayes' rule; has shape (R, 1) for broadcasting\n        denominator = weighted_scores.reshape(R, 1)\n        \n        gamma = np.zeros_like(Q)\n        \n        # Mask for reads with a non-zero marginal probability\n        non_zero_denom_mask = denominator.flatten() > 0\n        \n        # Standard case: update responsibilities where denominator is non-zero\n        gamma[non_zero_denom_mask, :] = numerator[non_zero_denom_mask, :] / denominator[non_zero_denom_mask]\n        \n        # Special convention: for uninformative reads (denominator is zero), gamma = p\n        zero_denom_mask = ~non_zero_denom_mask\n        if np.any(zero_denom_mask):\n            gamma[zero_denom_mask, :] = p\n        \n        # --- M-step: Update mixture proportions (p) ---\n        soft_counts = np.sum(gamma, axis=0)\n        p = soft_counts / R\n\n        # --- Convergence Check ---\n        # Recalculate weighted scores with new p\n        weighted_scores = Q @ p\n        \n        # Filter out zero scores to avoid log(0) -> -inf\n        valid_scores = weighted_scores[weighted_scores > 0]\n        \n        if len(valid_scores)  R:\n            log_likelihood_new = -np.inf\n        else:\n            log_likelihood_new = np.sum(np.log(valid_scores))\n\n        if abs(log_likelihood_new - log_likelihood_old)  TOL:\n            break\n        \n        log_likelihood_old = log_likelihood_new\n\n    # 3. Post-convergence computations using the final p\n    final_p = p\n    \n    # Re-compute final responsibilities with the MLE p\n    weighted_scores = Q @ final_p\n    numerator = final_p * Q\n    denominator = weighted_scores.reshape(R, 1)\n    final_gamma = np.zeros_like(Q)\n    non_zero_denom_mask = denominator.flatten() > 0\n    final_gamma[non_zero_denom_mask, :] = numerator[non_zero_denom_mask, :] / denominator[non_zero_denom_mask]\n    zero_denom_mask = ~non_zero_denom_mask\n    if np.any(zero_denom_mask):\n        final_gamma[zero_denom_mask, :] = final_p\n    \n    # --- Uncertainty in p (Posterior Standard Deviation) ---\n    final_soft_counts = np.sum(final_gamma, axis=0)\n    a = alpha_0 + final_soft_counts\n    A = np.sum(a)\n    \n    # Handle case where A+1 could be zero, though unlikely with alpha_0 > 0\n    if A == 0 or (A + 1) == 0:\n        var_p = np.zeros(L)\n    else:    \n        var_p = (a * (A - a)) / (A**2 * (A + 1))\n    \n    # Ensure variance is non-negative before taking sqrt\n    std_dev_p = np.sqrt(np.maximum(0, var_p))\n\n    # --- Uncertainty in assignments (Mean Per-Read Entropy) ---\n    # xlogy(x, y) computes x*log(y) and handles x=0 correctly\n    entropy_per_read = -np.sum(xlogy(final_gamma, final_gamma), axis=1)\n    H_bar = np.mean(entropy_per_read)\n\n    # 4. Format and return results\n    full_result = np.concatenate([final_p, std_dev_p, [H_bar]])\n    \n    # Round all final values to 6 decimal places\n    rounded_result = [round(x, 6) for x in full_result]\n    \n    return rounded_result\n\nsolve()\n\n```", "id": "2752515"}]}