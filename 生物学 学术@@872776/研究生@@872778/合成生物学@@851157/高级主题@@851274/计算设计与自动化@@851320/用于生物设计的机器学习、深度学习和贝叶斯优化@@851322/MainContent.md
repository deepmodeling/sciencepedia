## 引言
在合成生物学和[生物工程](@entry_id:270890)领域，如何在浩瀚的[生物序列](@entry_id:174368)空间中搜寻并发现具备特定功能的分子，是一个核心挑战。传统的试错法和理性设计方法往往效率低下，难以应对[序列空间](@entry_id:153584)的[组合爆炸](@entry_id:272935)。这在加速新型酶、[抗体](@entry_id:146805)和基因回路的设计过程中，形成了一个显著的知识与效率缺口。

本文旨在系统性地介绍一个数据驱动的框架，利用机器学习、深度学习和[贝叶斯优化](@entry_id:175791)来攻克这一难题。通过本文，读者将踏上一条从理论到实践的学习路径。在“原理与机制”一章中，我们将奠定数学和统计学基础，阐明如何将[生物设计](@entry_id:162951)问题形式化，如何构建能够[量化不确定性](@entry_id:272064)的预测模型，以及[贝叶斯优化](@entry_id:175791)如何智能地指导实验。随后，“应用与[交叉](@entry_id:147634)学科联系”一章将展示这些原理如何应用于[蛋白质工程](@entry_id:150125)、基因设计等真实场景，并与生物学、化学等学科知识深度融合。最后，“动手实践”部分将通过具体的计算练习，帮助读者巩固对关键概念的理解。

这一结构化的学习旅程将从剖析指导这一设计-构建-测试循环的核心原理开始，为读者构建一个坚实的理论根基。

## 原理与机制

在[生物设计](@entry_id:162951)中，利用机器学习来驾驭复杂的序列-功能关系，需要一个将[统计建模](@entry_id:272466)与[序贯决策](@entry_id:145234)相结合的严谨框架。本章旨在阐述指导这一过程的核心原理和机制。我们将从如何将[生物设计](@entry_id:162951)问题形式化为数学上的优化任务开始，然后深入探讨构建和评估预测模型的关键方面，最后转向如何利用这些模型通过[贝叶斯优化](@entry_id:175791)（Bayesian Optimization）等策略智能地指导实验设计。

### 将生物设计形式化为[优化问题](@entry_id:266749)

从根本上说，许多[生物设计](@entry_id:162951)任务，无论是优化酶的催化活性、提高蛋白质的稳定性，还是设计具有特定结合亲和力的[抗体](@entry_id:146805)，都可以被构建为一个[数学优化](@entry_id:165540)问题。我们的目标是在一个巨大的、由可能序列组成的离散设计空间 $\mathcal{X}$ 中，寻找一个序列 $x$（例如，一段DNA或蛋白质序列），以最大化某个我们关心的、但其函数形式未知的黑箱性质 $f(x)$（例如，表达水平或[结合亲和力](@entry_id:261722)）。

这个过程通常还受到一系列生物学和物理化学上的约束，例如序列的毒性、[密码子](@entry_id:274050)的使用偏好或对细胞造成的代谢负担。这些约束可以表示为一组不等式 $g_i(x) \le 0$。因此，逆向[生物设计](@entry_id:162951)（inverse biological design）的核心问题可以严谨地表述为以下[约束优化](@entry_id:635027)问题 [@problem_id:2749069]：
$$
\begin{aligned}
\text{maximize}_{x \in \mathcal{X}} \quad  f(x) \\
\text{subject to} \quad  g_i(x) \le 0, \quad i=1,\dots,m.
\end{aligned}
$$
所有满足约束条件的序列 $x$ 构成了可行集 $\mathcal{F}$。由于[目标函数](@entry_id:267263) $f(x)$ 通常是“黑箱”，即我们没有它的解析表达式，只能通过耗时耗力的湿实验来获得其在特定点 $x_t$ 上的带噪观测值 $y_t = f(x_t) + \varepsilon_t$。

在着手解决这个[优化问题](@entry_id:266749)之前，我们需要考虑它是否是**良定义的（well-posed）**。一个良定义的[优化问题](@entry_id:266749)应当满足三个标准：解的存在性（existence）、唯一性（uniqueness）和稳定性（stability）。

1.  **存在性**：最优解必须存在。在一个离散的设计空间中，如果可行集 $\mathcal{F}$ 是有限且非空的（例如，固定长度 $L$ 的蛋白质序列空间），那么根据[极值定理](@entry_id:142794)，定义在该集合上的任何实值函数都必然能达到其最大值，从而保证了解的存在性。如果可行集是无限的（例如，序列长度可变），则需要更强的条件，比如**长度上的矫顽性（coercivity-in-length）**。这意味着当序列长度 $\ell$ 趋于无穷时，函数值 $f(x)$ 会趋于一个较差的值（例如，$-\infty$）。这一条件有效地将搜索范围限制在一个有限的[子集](@entry_id:261956)内，从而保证了最优解的存在性 [@problem_id:2749069]。

2.  **唯一性**：最优解应该是唯一的。也就是说，只存在一个序列 $x^\star$ 能达到最大函数值。

3.  **稳定性**：最优解应对目标函数的微小扰动不敏感。在我们的情境中，这意味着即使我们的观测带有噪声，找到的解也应是真正最优解。稳定性的一个充分条件是存在一个**严格的最优间隔（strict margin of optimality）** $\gamma > 0$。这意味着最优值 $f(x^\star)$ 与次优值之间存在一个明确的差距，即 $f(x^\star) - \max_{x \in \mathcal{F} \setminus \{x^\star\}} f(x) \ge \gamma$。如果观测噪声的幅度远小于这个间隔（例如，小于 $\gamma/2$），那么基于带噪观测的优化过程就不太可能将次优解误认为是全局最优解，从而保证了优化过程的稳定性 [@problem_id:2749069]。

满足这些条件的问题更易于被算法稳定地求解。因此，在设计实验流程时，对问题结构的理解是至关重要的第一步。

### 构建预测模型：序列-功能图谱

由于直接对[黑箱函数](@entry_id:163083) $f(x)$ 进行优化是不可行的（需要评估空间中的每一个点），我们采用一种“代理模型（surrogate model）”的策略。我们首先进行少量实验，收集一个初始数据集 $\mathcal{D} = \{(x_i, y_i)\}_{i=1}^n$，然后利用这些数据训练一个机器学习模型 $f_\theta$ 来近似未知的真实函数 $f$。这个模型构成了我们对序列-功能关系的理解核心。

#### [生物序列](@entry_id:174368)的表示方法

构建模型的第一步是将[生物序列](@entry_id:174368)（如‘ATGC...’或‘ARND...’）转化为机器可以处理的数值输入。不同的表示方法蕴含着不同的[归纳偏置](@entry_id:137419)（inductive biases），即关于数据结构和对称性的先验假设。

*   **基于序列的表示**：这类方法直接处理序列的线性顺序。
    *   **[独热编码](@entry_id:170007)（One-hot encoding）**：将长度为 $L$、字母表大小为 $K$ 的序列表示为一个 $L \times K$ 的[二元矩阵](@entry_id:265326)。这是一种无损、无偏的表示。
    *   **学习嵌入（Learned embeddings）**：类似于自然语言处理，为每个[单体](@entry_id:136559)（氨基酸或[核苷酸](@entry_id:275639)）学习一个低维稠密向量。
    *   **[k-mer谱](@entry_id:178352)（[k-mer](@entry_id:166084) spectrum）**：通过计算所有长度为 $k$ 的子串（$k$-mers）在序列中出现的频率来生成[特征向量](@entry_id:151813)。这种方法捕捉了关于**局部[序列基序](@entry_id:177422)（local sequence motifs）**的信息。一个基于$k$-mer谱的线性模型实质上假设序列的功能是所有[局部基](@entry_id:151573)序贡献的线性叠加 [@problem_id:2749043]。
    *   **[物理化学](@entry_id:145220)特性聚合（Physicochemical aggregates）**：计算整个序列的平均[物理化学](@entry_id:145220)性质，如平均[疏水性](@entry_id:185618)、净[电荷](@entry_id:275494)等。这种表示方法对序列中残基的位置**[置换](@entry_id:136432)不变（permutation invariant）**，即它只关心全局的氨基酸组成，而忽略了它们的[排列](@entry_id:136432)顺序。当蛋白质的整体稳定性（通常与全局组成相关）是决定功能的关键因素时，这种表示可能很有效。但当功能依赖于特定的[活性位点](@entry_id:136476)基序时，它就会失效 [@problem_id:2749043]。

    对于所有基于序列的表示，关键的[归纳偏置](@entry_id:137419)是**顺序依赖性**。一个蛋白质序列 'A-G' 与 'G-A' 是完全不同的分子，因此模型必须能够处理这种顺序信息，即模型不应该对序列位置的[置换](@entry_id:136432)保持不变 [@problem_id:2749074]。

*   **基于结构的表示**：当分子的三维结构信息可用或可预测时，我们可以使用更具物理意义的表示。
    *   **无[坐标图](@entry_id:156506)表示（Graph representation without coordinates）**：将大分子表示为一个图，其中节点是氨基酸或原子，边代表它们之间的相互作用（如[共价键](@entry_id:141465)或空间邻近）。一个好的图模型必须对节点的任意重新标记（**[图同构](@entry_id:143072)，graph isomorphism**）保持不变，因为节点的索引是人为设定的，没有物理意义 [@problem_id:2749074]。
    *   **含坐标的几何表示（Geometric representation with coordinates）**：将分[子表示](@entry_id:141094)为三维空间中的一组带特征的原子。由于物理定律在空间中是各向同性的，一个预测孤立分子标量性质（如总能量）的模型必须对整个分子的**平移和旋转保持不变**。这些变换构成了[特殊欧几里得群](@entry_id:139383) $SE(3)$。此外，由于[生物分子](@entry_id:176390)具有固定的手性（例如，天然蛋白质由L-amino acids构成），模型**不应该**对镜像反射（reflection）保持不变，因为镜像会产生非自然的D-amino acids。因此，正确的对称性群是 $SE(3)$，而不是包含反射的更宽泛的[正交群](@entry_id:152531) $O(3)$ [@problem_id:2749074]。

选择合适的表示方法是建模成功的一半，因为它将关于生物分子本质的先验知识编码到了模型中。

#### 选择正确的学习框架与损失函数

有了[数值表示](@entry_id:138287)后，我们需要根据实验数据的类型来选择合适的学习框架（回归或分类）和损失函数。一个基本原则是**最大似然估计（Maximum Likelihood Estimation, MLE）**，即我们选择模型参数 $\theta$ 来最大化观测到当前数据集的概率。这等价于最小化[负对数似然](@entry_id:637801)（Negative Log-Likelihood, NLL）。

*   **回归问题（Regression）**：当实验测量值是连续的（如酶活性、荧[光强度](@entry_id:177094)），我们通常将其建模为回归问题。
    *   **异[方差](@entry_id:200758)噪声（Heteroscedastic noise）**：在高通量实验中，不同序列的测量噪声[方差](@entry_id:200758)可能不同。如果我们可以通过技术重复来为每个序列 $x_i$ 估计一个样本均值 $\bar{y}_i$ 和标准误 $\hat{\sigma}_i$，那么一个合理的观测模型是 $\bar{y}_i \sim \mathcal{N}(f_\theta(x_i), \hat{\sigma}_i^2)$。根据MLE原则，这导出的损失函数是**逆[方差](@entry_id:200758)加权的均方误差（inverse-variance-weighted Mean Squared Error, MSE）**，即 $\sum_i (\bar{y}_i - f_\theta(x_i))^2 / \hat{\sigma}_i^2$。这种加权方式合理地给予了更精确的测量点（低[方差](@entry_id:200758)）更大的权重 [@problem_id:2749089]。
    *   **审查数据（Censored data）**：有时测量仪器有[检测限](@entry_id:182454)（limit of detection, LOD）。对于活性低于LOD的序列，我们只知道其真实值 $y_i \le L$，但不知道确切值。在这种情况下，简单地用一个固定值（如0或$L$）替代是错误的，会引入系统偏差。正确的MLE方法是使用**审查回归（censored regression）**模型（如Tobit模型），其似然函数对于这些点包含的是模型预测值落在LOD以下的累积概率，即 $P(y \le L)$ [@problem_id:2749089]。

*   **[分类问题](@entry_id:637153)（Classification）**：当实验将序列分入离散的类别时（如流式细胞术分选出的“高表达”和“低表達”细胞），我们应将其建模为[分类问题](@entry_id:637153)。
    *   **二项分布数据（Binomial data）**：假设对于序列 $x_i$，我们测量了 $n_i$ 个细胞，其中 $k_i$ 个被归为“命中（hit）”。这天然地符合[二项分布](@entry_id:141181) $k_i \sim \text{Binomial}(n_i, p_i)$，其中 $p_i = f_\theta(x_i)$ 是单个细胞成为“命中”的概率。最小化该模型的NLL，可推导出其[损失函数](@entry_id:634569)等价于**樣本數加权的[二元交叉熵](@entry_id:636868)（count-weighted Binary Cross-Entropy, BCE）**損失：$-\sum_i [k_i \log(p_i) + (n_i - k_i) \log(1-p_i)]$ [@problem_id:2749089]。

将数据生成过程与[统计模型](@entry_id:165873)严谨地匹配是构建可靠预测模型的基石。

#### 理解与量化模型的不确定性

为了有效地指导实验设计，我们的代理模型不仅要给出预测值，还必须量化其预测的**不确定性（uncertainty）**。概率模型（如[贝叶斯神经网络](@entry_id:746725)或[高斯过程](@entry_id:182192)）能够自然地提供这种[不确定性估计](@entry_id:191096)。总预测不确定性可以分解为两种截然不同的类型 [@problem_id:2749107]。

*   **偶然不确定性（Aleatoric Uncertainty）**：源于数据生成过程内在的、不可约减的随机性。即使我们拥有完美的模型，对于同一个序列 $x$ 的重复测量也会因为[生物过程](@entry_id:164026)的随机性（如基因表达的随机波动）和测量仪器的噪声（如[光子](@entry_id:145192)散粒噪声）而产生不同的结果。这种不确定性由模型的似然函数 $p(y \mid x, \theta)$ 捕获。它可以通过增加单次测量的重复次数来更精确地估计，但无法通过增加训练数据集中的不同序列来消除。

*   **[认知不确定性](@entry_id:149866)（Epistemic Uncertainty）**：源于模型本身由于数据有限而产生的不确定性。当训练数据稀少或某个查询点 $x$ 远离所有训练数据点时，模型会对真实的 underlying function $f$ 感到“不确定”。这种不确定性体现在模型参数的后验分布 $p(\theta \mid \mathcal{D})$ 中。认知不确定性是**可约减的**：通过收集更多、更多样化的数据，我们可以让模型“更有信心”，从而减小这种不确定性。

根据[全方差定律](@entry_id:184705)，总预测[方差](@entry_id:200758)可以精确地分解为这两部分 [@problem_id:2749107]：
$$
\operatorname{Var}(y \mid x, \mathcal{D}) = \underbrace{\mathbb{E}_{\theta \sim p(\theta \mid \mathcal{D})}\!\left[\operatorname{Var}(y \mid x, \theta)\right]}_{\text{偶然不确定性}} + \underbrace{\operatorname{Var}_{\theta \sim p(\theta \mid \mathcal{D})}\!\left(\mathbb{E}[y \mid x, \theta]\right)}_{\text{认知不确定性}}
$$
第一个术语是模型预测的平均噪声[方差](@entry_id:200758)，而第二个术语是[模型平均](@entry_id:635177)预测值的[方差](@entry_id:200758)（即模型因参数不确定而产生的预测波动）。在指导实验设计时，正是**[认知不确定性](@entry_id:149866)**驱动着我们去探索未知的设计空间。

### [主动学习](@entry_id:157812)与优化：设计-构建-测试循环

拥有一个能够[量化不确定性](@entry_id:272064)的概率代理模型后，我们就可以进入“设计-构建-测试”的[主动学习](@entry_id:157812)循环。核心问题是：下一步应该测试哪个序列？[贝叶斯优化](@entry_id:175791)（BO）为这个问题提供了 principled 的答案。

#### 探索-利用的权衡

BO的核心思想是在**探索（exploration）**和**利用（exploitation）**之间取得平衡。
*   **利用**：测试那些根据当前模型预测性能最好的序列，以期快速收敛到局部最优。
*   **探索**：测试那些[模型不确定性](@entry_id:265539)很高的序列，以期发现全新的高性能区域，并减少全局的[模型不确定性](@entry_id:265539)。

这种权衡与代理模型本身的**偏差-方差权衡（bias-variance trade-off）**密切相关。对于一个在小型数据集上训练的高容量模型（如Transformer），其误差的主要来源通常是**[方差](@entry_id:200758)**，即模型对训练数据的微小变化高度敏感。我们可以通过**[学习曲线](@entry_id:636273)实验**来诊断这种情况：在不同大小 $n$ 的训练[子集](@entry_id:261956)上反复训练模型，并在固定的[测试集](@entry_id:637546)上评估其性能。我们通常会观察到，随着 $n$ 的增加，模型的平均[测试误差](@entry_id:637307)（MSE）会下降，而模型预测的[方差](@entry_id:200758)（在不同训练[子集和](@entry_id:634263)随机种子下）也会减小。如果模型处于[方差](@entry_id:200758)主导的状态，这表明它从数据中学习的能力很强，但受限于数据量。在这种情况下，BO策略应更偏向于**探索**，以收集更多信息来降低模型[方差](@entry_id:200758)，从而建立一个更可靠的全局模型 [@problem_id:2749039] [@problem_id:2749039]。

#### [贝叶斯优化](@entry_id:175791)的[采集函数](@entry_id:168889)

BO通过一个称为**[采集函数](@entry_id:168889)（acquisition function）**的效用函数来具体实现探索-利用的权衡。[采集函数](@entry_id:168889)以代理模型的预测均值 $\mu_t(x)$ 和标准差 $\sigma_t(x)$ 为输入，输出一个分数，该分数的高低代表了测试序列 $x$ 的“价值”。在每一步，我们选择使[采集函数](@entry_id:168889)最大化的序列进行下一个实验。以下是几种经典的[采集函数](@entry_id:168889) [@problem_id:2749080]：

*   **Probability of Improvement (PI)**：该函数计算一个新点 $x$ 的函数值超过当前最优值 $f^\star$ 的概率。其表达式为 $\mathrm{PI}(x) = \Phi\left(Z(x)\right)$，其中 $Z(x) = (\mu_t(x) - f^\star - \xi) / \sigma_t(x)$，$\Phi$ 是标准正态分布的累积分布函数（CDF）。参数 $\xi \ge 0$ 是一个权衡参数，$\xi$ 越大，算法就越倾向于探索不确定性高的区域。

*   **Expected Improvement (EI)**：EI不仅考虑了改进的可能性，还考虑了改进的幅度。它计算的是新点 $x$ 超过当前最优值的期望。其解析表达式为 $\mathrm{EI}(x) = \sigma_t(x) \left( Z(x) \Phi(Z(x)) + \phi(Z(x)) \right)$，其中 $\phi$ 是[标准正态分布](@entry_id:184509)的[概率密度函数](@entry_id:140610)（PDF）。EI通常比PI表现更好，因为它不会[过度利用](@entry_id:196533)那些只有微小改进机会的点。

*   **Upper Confidence Bound (UCB)**：UCB采取一种“乐观主义”策略。它通过在预测均值上增加一个与预测标准差成正比的项来构造一个[置信上界](@entry_id:178122)，然后优化这个[上界](@entry_id:274738)：$\mathrm{UCB}(x) = \mu_t(x) + \kappa \sigma_t(x)$。参数 $\kappa \ge 0$ 直接控制了探索的程度：$\kappa$ 越大，对不确定性的奖励就越大，探索性就越强。

*   **Thompson Sampling**：Thompson Sampling是一种贝叶斯方法，它不构造一个固定的[采集函数](@entry_id:168889)。在每一步，它从代理模型的[后验分布](@entry_id:145605)中**随机抽取一个函数样本** $f^\sim(\cdot)$，然后选择该样本函数的[最大值点](@entry_id:634610)作为下一个评估点。探索-利用的权衡在这里是隐式实现的：在不确定性高的区域，抽取的函数样本形态各异，其[最大值点](@entry_id:634610)也会变化多端（探索）；在不确定性低的区域，所有样本函数都紧密围绕着均值，其[最大值点](@entry_id:634610)会稳定地指向已知的高性能区域（利用）。

重要的是要再次强调，BO中的探索是由**认知不确定性**驱动的。我们的目标是去探索那些我们**不知道**其真实性能的区域，而不是那些本身测量**噪声很大**（偶然不确定性高）的区域 [@problem_id:2749107]。

#### 更广阔的视角：贝叶斯决策理论

[采集函数](@entry_id:168889)可以被看作是更普适的**贝叶斯决策理论（Bayesian Decision Theory）**框架下的特例。在该框架下，理性的决策者应选择一个行动（这里是选择下一个实验点 $x$），以最大化其**[期望效用](@entry_id:147484)（expected utility）**。如果考虑到实验成本 $c(x)$，那么决策准则就是选择 $x$ 来最大化：
$$
\mathcal{J}(x) = \mathbb{E}_{y \sim p(\cdot \mid x, \mathcal{D})}[u(y)] - \lambda c(x)
$$
其中 $u(\cdot)$ 是一个**[效用函数](@entry_id:137807)**，它量化了不同实验结果 $y$ 的价值；$\lambda$ 是一个权衡成本和收益的超参数 [@problem_id:2749066]。

在风险敏感的生物实验设计中（例如，避免设计出有毒或完全无效的分子），我们可以选择一个**凹的（concave）**效用函数来体现**[风险规避](@entry_id:137406)（risk aversion）**。根据琴生不等式，对于[凹函数](@entry_id:274100)，$\mathbb{E}[u(Y)] \le u(\mathbb{E}[Y])$，这意味着具有相同预测均值但更高不确定性（[方差](@entry_id:200758)）的设计将获得更低的[期望效用](@entry_id:147484)。一个经典的[风险规避](@entry_id:137406)[效用函数](@entry_id:137807)是指数效用函数 $u(z) = -\exp(-\alpha z)$（对于 $\alpha > 0$），它的导数 $u'(z) > 0$（偏好更高收益）且[二阶导数](@entry_id:144508) $u''(z)  0$（收益的[边际效用递减](@entry_id:138128)），完美地编码了[风险规避](@entry_id:137406)的偏好 [@problem_id:2749066]。

### 高级主题与挑战

#### 用于[序列生成](@entry_id:635570)的生成式模型

BO通常在一个固定的、预定义的搜索空间中进行优化。然而，有时我们希望模型能直接**生成（generate）**全新的、具有理想性质的序列。这时，我们可以使用生成式模型。不同的模型家族有不同的工作原理和典型的失败模式 [@problem_id:2749047]：

*   **[自回归模型](@entry_id:140558)（Autoregressive Models）**：像GPT一样，逐个生成序列中的氨基酸或[核苷酸](@entry_id:275639)。它们通过最大化[似然](@entry_id:167119)（MLE）进行训练，但存在**[暴露偏差](@entry_id:637009)（exposure bias）**的风险：训练时模型看到的总是真实的前缀，而生成时它必须依赖自己可能出错的输出，导致错误累积。

*   **[变分自编码器](@entry_id:177996)（Variational Autoencoders, VAEs）**：学习一个从数据到低维潜空间的编码器和一个从潜空间到数据空间的解码器。它们通过最大化[证据下界](@entry_id:634110)（ELBO）进行训练，但可能遭遇**后验坍塌（posterior collapse）**，即解码器学会忽略潜空间信息，导致模型失去生成多样性序列的能力。

*   **[生成对抗网络](@entry_id:634268)（Generative Adversarial Networks, GANs）**：通过一个生成器和一个判别器的“猫鼠游戏”进行训练。GANs能够生成非常逼真的样本，但训练过程可能不稳定，并可能发生**模式坍塌（mode collapse）**，即生成器只产生少数几种能够骗过[判别器](@entry_id:636279)的样本，而无法覆盖整个数据[分布](@entry_id:182848)的多样性。

*   **[扩散模型](@entry_id:142185)（Diffusion Models）**：通过学习一个逐步去噪的过程来从纯噪声中生成数据。它们能够生成高质量和多样化的样本，但目前主要的缺点是**采样速度慢**，因为生成一个样本需要经过许多次迭代[去噪](@entry_id:165626)步骤。

#### [维度灾难](@entry_id:143920)与内在维度

序列设计空间的一个核心挑战是其巨大的规模。对于一个长度为 $L$、字母表大小为 $K$ 的序列，总的可能性数量为 $K^L$，这个数字随 $L$ 呈[指数增长](@entry_id:141869)。这就是所谓的**[维度灾难](@entry_id:143920)（curse of dimensionality）**。在一个如此巨大的空间中进行盲目搜索无异于大海捞针。

幸运的是，许多生物功能通常只由序列中的少数几个关键位置决定。这意味着函数的**内在维度（intrinsic dimensionality）** $d_{\text{eff}}$ 可能远小于其所在空间的表观维度 $L$。例如，一个蛋白质的活性可能只取决于[活性位点](@entry_id:136476)及其周围的少数几个残基。

识别这种低维结构是克服维度灾难的关键。一些机器学习方法，如带有**[自动相关性确定](@entry_id:746592)（Automatic Relevance Determination, ARD）**核函数的[高斯过程](@entry_id:182192)，能够自动学习每个序列位置的“重要性”。ARD核函数为每个输入维度（即序列位置）分配一个独立的长度[尺度参数](@entry_id:268705) $\ell_i$。模型会从数据中学习到，对于功能重要的位置，其对应的 $\ell_i$ 会较小（表示函数在该维度上变化快）；而对于不重要的位置，$\ell_i$ 会较大（表示函数在该维度上几乎不变）。通过分析这些学习到的长度尺度或相关的敏感性权重，我们可以估计出内在维度 $d_{\text{eff}}$。例如，我们可以定义 $d_{\text{eff}}$ 为捕获了总敏感度（例如，归一化梯度[方差](@entry_id:200758)）的95%所需的最少位置数。当一个算法（如BO）能够利用这种低维结构时，其收敛所需的样本数量将主要与 $d_{\text{eff}}$ 而非 $L$ 相关，从而极大地缓解了[维度灾难](@entry_id:143920) [@problem_id:2749095] [@problem_id:2749095]。

总之，通过将生物设计问题严谨地数学化，选择与实验数据相匹配的、能够量化不确定性的模型，并利用[贝叶斯优化](@entry_id:175791)等策略智能地平衡[探索与利用](@entry_id:174107)，我们可以构建一个强大的、数据驱动的闭环设计流程。理解并应对维度灾难等挑战，是推动这一领域走向更复杂设计任务的关键。