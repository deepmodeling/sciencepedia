{"hands_on_practices": [{"introduction": "成功的序列验证始于一个根本性的问题：我们需要多少测序数据？本练习将指导您运用一个经典的生物信息学模型——Lander-Waterman模型——来回答这个问题。通过将测序过程抽象为一个泊松过程，您将推导出确保一个合成DNA构建体被完全覆盖所需的平均测序深度，从而将一个基础的统计学原理与实际的实验设计决策联系起来。[@problem_id:2754129]", "problem": "一个合成生物学实验室必须使用下一代测序（NGS）来验证一个长度为 $L$ 个碱基对的从头（de novo）组装的DNA构建体。假设文库制备和测序产生的读段长度固定为 $\\ell$ 个碱基对，并且读段在目标序列上的起始位点遵循均匀泊松点过程，其速率为每个碱基 $\\lambda$。定义平均覆盖深度为 $C=\\lambda \\ell$。忽略末端效应（假设 $L \\gg \\ell$，因此边缘校正可以忽略不计）。\n\n任务：\n1. 仅从泊松点过程的定义性质（即在任何长度为 $x$ 的区间内，事件数量服从均值为 $\\lambda x$ 的泊松分布，且不相交区间内的事件是独立的）出发，推导某个特定碱基未被任何读段覆盖的概率表达式，并用 $C$ 表示。\n2. 设 $\\delta$ 是用户指定的族系风险容忍度，表示在整个目标序列中至少留下一个碱基未被覆盖的风险。在不假设不同碱基间的覆盖事件相互独立的情况下，推导 $C$ 的一个严格下界，该下界能保证在 $L$ 个碱基中至少有一个未被覆盖的概率严格小于 $\\delta$。用 $L$ 和 $\\delta$ 以闭合形式表示你对 $C$ 的界限。\n3. 对于 $L=10^{5}$ 和 $\\delta=10^{-6}$，对你的界限进行数值计算。报告满足该界限的最小 $C$ 值，该值应为一个纯数（无量纲）。将你的答案四舍五入到四位有效数字。", "solution": "所提出的问题具有科学依据、提法明确、客观，并包含足够的信息以进行严格求解。这是生物信息学中的一个标准问题，通常被称为用于测序的Lander-Waterman模型。我们将着手进行推导。\n\n### 第1部分：单个碱基未被覆盖的概率\n\n我们被要求推导某个特定碱基未被任何读段覆盖的概率。让我们考虑位于某个特定基因组坐标上的一个任意碱基。为了使这个碱基被一个长度为 $\\ell$ 的读段覆盖，该读段的起始位置必须能使该碱基落入读段的跨度之内。如果该碱基位于位置 $x$，一个从位置 $s$ 开始的读段将覆盖它，当且仅当 $s \\le x  s + \\ell$。这等价于读段必须在区间 $(x-\\ell, x]$ 内起始。\n\n问题陈述，读段的起始位点遵循一个均匀泊松点过程，速率为每个碱基对 $\\lambda$ 个起始点。$L \\gg \\ell$ 的假设使我们可以忽略末端效应，这意味着我们可以将这个长度为 $\\ell$ 的区间看作不靠近构建体末端的区间。\n\n根据泊松过程的定义，在任何给定长度的区间内发生的事件（读段起始）数量是一个服从泊松分布的随机变量。该分布的均值是速率 $\\lambda$ 与区间长度的乘积。对于区间 $(x-\\ell, x]$，其长度为 $\\ell$。因此，我们称之为随机变量 $N$ 的、在该特定区间内起始的读段数量，服从均值为 $\\lambda \\ell$ 的泊松分布。\n\n问题将平均覆盖深度定义为 $C = \\lambda \\ell$。因此，$N \\sim \\text{Poisson}(C)$。$N$ 的概率质量函数由下式给出：\n$$P(N=k) = \\frac{\\exp(-C) C^k}{k!}$$\n其中 $k$ 是一个非负整数。\n\n一个特定的碱基未被覆盖，当且仅当在对应的长度为 $\\ell$ 的区间内有零个读段起始。这对应于事件 $N=0$。我们可以通过在概率质量函数中设 $k=0$ 来计算这个概率：\n$$P(\\text{base is not covered}) = P(N=0) = \\frac{\\exp(-C) C^0}{0!}$$\n回顾 $C^0=1$ 和 $0!=1$，我们得到某个特定碱基未被覆盖的概率：\n$$P(\\text{base is not covered}) = \\exp(-C)$$\n\n### 第2部分：平均覆盖深度的下界\n\n我们的任务是找到平均覆盖深度 $C$ 的一个下界，该下界能确保在整个长度为 $L$ 的构建体中，至少有一个碱基未被覆盖的概率严格小于指定的容忍度 $\\delta$。\n\n设 $E_i$ 表示第 $i$ 个碱基（$i=1, 2, \\dots, L$）未被任何读段覆盖的事件。“至少有一个碱基未被覆盖”的事件是构建体中所有碱基的此类事件的并集：$\\bigcup_{i=1}^{L} E_i$。我们要求这个并集事件的概率小于 $\\delta$：\n$$P\\left(\\bigcup_{i=1}^{L} E_i\\right)  \\delta$$\n\n问题正确地要求我们不假设事件 $E_i$ 之间是相互独立的。相邻碱基的覆盖状态是相关的。例如，如果碱基 $i$ 未被覆盖，这意味着在区间 $(i-\\ell, i]$ 内没有读段起始。这反过来又影响了碱基 $i+1$ 未被覆盖的概率，因为其潜在覆盖读段的区间 $(i+1-\\ell, i+1]$ 与第一个区间大部分重叠。\n\n为了处理这种依赖性，我们采用并集界（Union Bound），也称为布尔不等式（Boole's inequality）。对于任何事件集合 $E_1, E_2, \\dots, E_L$，该不等式表明：\n$$P\\left(\\bigcup_{i=1}^{L} E_i\\right) \\le \\sum_{i=1}^{L} P(E_i)$$\n\n在第1部分中，我们确定了对于任何单个碱基 $i$，其未被覆盖的概率为 $P(E_i) = \\exp(-C)$。由于我们忽略了末端效应，这个概率对于从 $i=1$ 到 $L$ 的所有碱基都是相同的。将此应用于并集界中的求和：\n$$\\sum_{i=1}^{L} P(E_i) = \\sum_{i=1}^{L} \\exp(-C) = L \\exp(-C)$$\n\n结合这些结果，我们得到了我们所关心的概率的一个上界：\n$$P(\\text{at least one base uncovered}) \\le L \\exp(-C)$$\n\n为了满足条件 $P(\\text{at least one base uncovered})  \\delta$，我们只需施加一个更严格的条件，即其上界小于 $\\delta$：\n$$L \\exp(-C)  \\delta$$\n\n现在我们可以解这个关于 $C$ 的不等式，以找到所需的下界。\n$$\\exp(-C)  \\frac{\\delta}{L}$$\n对两边取自然对数：\n$$-C  \\ln\\left(\\frac{\\delta}{L}\\right)$$\n两边乘以 $-1$ 会反转不等号方向：\n$$C > -\\ln\\left(\\frac{\\delta}{L}\\right)$$\n使用对数性质 $-\\ln(x) = \\ln(1/x)$，我们得到 $C$ 的下界的最终表达式：\n$$C > \\ln\\left(\\frac{L}{\\delta}\\right)$$\n这提供了一个严格的下界，保证了覆盖缺口的族系错误率低于容忍度 $\\delta$。\n\n### 第3部分：数值计算\n\n最后，我们被要求对给定的参数计算这个界限：构建体长度 $L=10^5$ 个碱基对和风险容忍度 $\\delta=10^{-6}$。\n\n使用推导出的不等式，最小覆盖深度 $C$ 必须满足：\n$$C > \\ln\\left(\\frac{10^5}{10^{-6}}\\right)$$\n$$C > \\ln(10^{5 - (-6)})$$\n$$C > \\ln(10^{11})$$\n使用对数性质 $\\ln(x^a) = a \\ln(x)$:\n$$C > 11 \\ln(10)$$\n自然对数 $\\ln(10)$ 的值约为 $2.30258509...$。\n$$C > 11 \\times 2.30258509...$$\n$$C > 25.328436...$$\n问题要求报告满足该界限的最小 $C$ 值，并四舍五入到四位有效数字。将数值结果 $25.328436...$ 四舍五入到四位有效数字得到 $25.33$。因此，在此模型下，需要至少 $25.33$ 的平均覆盖深度才能满足指定的验证标准。", "answer": "$$\\boxed{25.33}$$", "id": "2754129"}, {"introduction": "在验证质粒文库或研究嵌合体时，我们不仅关心序列的完整覆盖，更关心能否检测到混合群体中的稀有变异。本练习探讨了另一个核心问题：需要多大的测序深度才能有把握地发现一个低频存在的变异？您将使用二项分布模型，从第一性原理出发，量化测序深度与错过一个稀有但关键的序列特征的风险之间的关系，这是进行定量群体分析的一项基本技能。[@problem_id:2754073]", "problem": "一个合成生物学团队正在使用下一代测序 (NGS) 技术验证一个混合质粒文库。某个特定变体以未知频率存在于混合群体中，在本分析中，该频率被建模为一个固定比例 $f$，其中 $0  f  1$。假设测序过程从群体中随机独立地抽样，并且产生了一个包含 $n$ 个独立读数的集合。\n\n您的任务是基于上述模型，推导出：\n1. 完全漏检该变体（即在 $n$ 个读数中一次也未观察到）的概率 $P_{\\text{miss}}$ 的解析表达式。该表达式应只与 $f$ 和 $n$ 有关。\n2. 使漏检概率恰好等于某个预定义风险阈值 $\\delta$ (其中 $0  \\delta  1$) 所需的*实值*测序深度 $n^{\\ast}$ 的闭式解析表达式。该表达式应只与 $f$ 和 $\\delta$ 有关。", "solution": "所述问题已经过验证，被认为是科学合理、定义明确且内部一致的。它为定量分子生物学中的一个重要问题提供了一个标准（尽管简化了）的模型。因此，我们可以进行正式推导。\n\n设随机变量 $X$ 表示在总共 $n$ 个独立测序读数中携带目标变体的读数数量。根据问题陈述，每个读数都是一次独立的伯努利试验。成功的概率，即在单个读数中观察到该变体，由变体的频率 $f$ 给出。\n\n在 $n$ 次成功概率恒为 $f$ 的独立伯努利试验中，总成功次数 $X$ 服从二项分布。我们将其记为 $X \\sim \\text{Binomial}(n, f)$。该分布的概率质量函数 (PMF) 给出在 $n$ 次试验中观察到恰好 $k$ 次成功的概率：\n$$P(X=k) = \\binom{n}{k} f^k (1-f)^{n-k}$$\n其中 $k$ 是一个满足 $0 \\le k \\le n$ 的整数，而 $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ 是二项式系数。\n\n第一个任务是推导完全漏检该变体的概率。此事件对应于观察到零次成功，即 $k=0$。我们将 $k=0$ 代入二项分布的概率质量函数：\n$$P(X=0) = \\binom{n}{0} f^0 (1-f)^{n-0}$$\n根据定义，$\\binom{n}{0} = \\frac{n!}{0!(n-0)!} = \\frac{n!}{1 \\cdot n!} = 1$。并且，任何非零数的 $0$ 次方都等于 $1$，因此 $f^0=1$（因为 $f>0$）。\n因此，漏检该变体的概率，我们可以表示为 $P_{\\text{miss}}(n, f)$，是：\n$$P_{\\text{miss}}(n, f) = P(X=0) = 1 \\cdot 1 \\cdot (1-f)^n = (1-f)^n$$\n该表达式确实只与变体频率 $f$ 和测序深度 $n$ 有关，符合要求。这完成了推导的第一部分。\n\n第二个任务是找到最小实值测序深度 $n^{\\ast}$ 的闭式表达式，该深度能导致一个特定的漏检概率 $\\delta$。问题要求我们找到使漏检概率*等于* $\\delta$ 的深度。我们将推导出的漏检概率表达式设为目标值 $\\delta$：\n$$(1-f)^{n^{\\ast}} = \\delta$$\n为了解出 $n^{\\ast}$，我们必须将其从指数中分离出来。标准方法是对等式两边取对数。我们将使用自然对数，记为 $\\ln$。\n$$\\ln\\left((1-f)^{n^{\\ast}}\\right) = \\ln(\\delta)$$\n利用基本对数恒等式 $\\ln(a^b) = b \\ln(a)$，我们得到：\n$$n^{\\ast} \\ln(1-f) = \\ln(\\delta)$$\n为了分离出 $n^{\\ast}$，我们将等式两边同时除以 $\\ln(1-f)$。我们必须确保分母不为零。问题规定 $0  f  1$，这意味着 $0  1-f  1$。对于区间 $(0, 1)$ 中的任意值 $x$，其自然对数 $\\ln(x)$ 是有定义的，并且是严格为负的。因此，$\\ln(1-f)$ 是一个非零的负实数，除法是有效操作。\n$$n^{\\ast} = \\frac{\\ln(\\delta)}{\\ln(1-f)}$$\n这就是以参数 $f$ 和 $\\delta$ 表示的实值测序深度 $n^{\\ast}$ 的闭式解析表达式。值得注意的是，由于 $0  \\delta  1$，$\\ln(\\delta)$ 也是负数。两个负数之比为正数，这与测序深度的物理意义相符。在实际应用中，测序深度必须是整数，通常会计算 $n = \\lceil n^{\\ast} \\rceil$ 以确保漏检概率*至多*为 $\\delta$。然而，本问题明确要求的是使等式成立的实值 $n^{\\ast}$，而这就是我们推导出的结果。", "answer": "$$\\boxed{\\frac{\\ln(\\delta)}{\\ln(1-f)}}$$", "id": "2754073"}, {"introduction": "真实的测序数据充满了噪声，特别是在均聚物（homopolymer）区域，测序仪的“滑移”会导致插入和缺失（indel）错误，这与真实的生物学变异极易混淆。本练习将挑战您从简单的统计推导转向复杂的算法设计。您将构建一个基于配对隐马尔可夫模型（pair-HMM）的局部重比对策略，通过贝叶斯推断来区分真实的indel和测序伪影，这是高保真序列分析中解决实际问题的关键一步。[@problem_id:2754093]", "problem": "您正在为下一代测序（NGS）的读段设计一种基于数学原理的局部重比对策略，该策略用于处理存在同聚物的情况。同聚物是参考基因组中一段连续的相同核苷酸；经验观察表明，聚合酶在同聚物区域的滑移会增加插入-删除（indel）错误，使得朴素比对容易出错。您的目标是形式化地解释为何在同聚物附近进行indel检测容易出错，然后推导并实现一个局部重比对程序，该程序使用贝叶斯推断和配对隐马尔可夫模型（pair-HMM）来比较两个竞争性假设：\n\n- 假设 $\\mathcal{H}_0$（仅错配，无indel）：观测到的读段与参考序列之间的差异仅由碱基替换错误（错配）引起，比对中不允许出现插入或删除。\n- 假设 $\\mathcal{H}_1$（允许单个或多个indel片段）：观测到的差异通过一个可能包含空位（读段相对于参考序列的插入或读段相对于参考序列的删除）的比对来解释，该模型具有空位开放和延伸概率，其中空位开放概率在同聚物内部会增加。\n\n使用以下基本原理：\n- 给定一个比对和一个测序错误的生成模型，各碱基的观测是独立的。\n- 贝叶斯法则 $P(\\mathcal{H}\\mid D)\\propto P(D\\mid \\mathcal{H})P(\\mathcal{H})$。\n- 一个标准的三状态配对隐马尔可夫模型（pair-HMM），包含匹配状态 $M$、插入状态 $I$（参考序列中的空位）和删除状态 $D$（读段中的空位），其转移包含空位开放和空位延伸概率，匹配状态的发射由一个碱基替换错误模型确定。\n- 同聚物敏感的空位开放先验，通过对基础空位开放概率进行logistic变换来建模，并受同聚物长度的调节。\n\n为每个假设构建并实现对数似然函数，并选择后验概率较大的假设（假设先验概率相等 $P(\\mathcal{H}_0)=P(\\mathcal{H}_1)$）。对于 $\\mathcal{H}_0$，完全禁止空位，并仅使用匹配和错配来计算给定参考序列下读段的概率；这仅在读段和参考序列长度相等时有定义。对于 $\\mathcal{H}_1$，在pair-HMM中使用Viterbi解码来找到最大概率比对，该比对可能包含一个或多个空位片段，并遵循以下约束：\n- 在 $M$ 状态中的发射模型：碱基错误率为 $\\varepsilon$，匹配的概率为 $1-\\varepsilon$，错配的概率为 $\\varepsilon/3$。\n- 转移：从 $M$ 状态，您可以以概率 $p_{MM}(k)=1-2\\,p_{\\text{go,eff}}(k)$ 停留在 $M$ 状态，以概率 $p_{\\text{go,eff}}(k)$ 开启一个插入，或以概率 $p_{\\text{go,eff}}(k)$ 开启一个删除，其中 $k$ 是发生转移的参考序列边界的索引。从 $I$ 或 $D$ 状态，您可以以概率 $p_{\\text{ge}}$ 延伸空位，或以概率 $1-p_{\\text{ge}}$ 返回到 $M$ 状态。\n- 同聚物敏感的空位开放概率：在每个参考序列边界 $k$ 处，计算跨越该边界的同聚物运行长度 $L(k)$，并设置\n$$\np_{\\text{go,eff}}(k)=\\sigma\\!\\Big(\\operatorname{logit}(p_{\\text{go,base}})+\\alpha\\big(L(k)-1\\big)\\Big),\n$$\n其中 $\\operatorname{logit}(p)=\\ln\\!\\big(\\tfrac{p}{1-p}\\big)$ 且 $\\sigma(z)=\\tfrac{1}{1+e^{-z}}$，$\\alpha\\ge 0$ 控制同聚物长度对空位开放概率的增加强度。\n- 为简化起见，让插入和删除状态具有恒定的发射（即，除了转移概率外，没有额外的每碱基发射惩罚）。\n- 使用对数空间的动态规划以避免数值下溢。\n\n局部重比对策略的输出：\n- 通过对上述定义的pair-HMM进行Viterbi解码，计算 $\\log P(D\\mid \\mathcal{H}_1)$。\n- 当读段和参考序列长度匹配时，通过对角线比对的对数发射求和来计算 $\\log P(D\\mid \\mathcal{H}_0)$；否则，设置 $\\log P(D\\mid \\mathcal{H}_0)=-\\infty$。\n- 假设 $P(\\mathcal{H}_0)=P(\\mathcal{H}_1)$，因此后验概率的比较简化为似然比；当且仅当 $\\log P(D\\mid \\mathcal{H}_1)\\log P(D\\mid \\mathcal{H}_0)$ 时，选择 $\\mathcal{H}_1$。\n- 如果选择 $\\mathcal{H}_1$，从Viterbi路径中提取最长的连续空位片段（若长度相同，则取比对中最早出现的片段），报告其类型（插入或删除）、起始参考序列边界位置及其长度。使用0-基的参考序列边界索引：对于长度为 $m$ 的参考序列，边界索引 $k$ 位于参考序列索引 $k-1$ 和 $k$ 之间，其中 $k\\in\\{0,1,\\dots,m\\}$。对于读段中的删除（消耗参考序列碱基的空位），报告第一个被删除的参考序列碱基之前的边界索引。对于读段中的插入（参考序列中的空位），报告插入该空位的边界索引。如果选择 $\\mathcal{H}_0$，则返回位置 $-1$ 和长度 $0$ 来表示没有indel。\n\n您的程序必须实现此策略，并在以下测试集上运行。每个测试用例是一个元组，形式为 (参考序列字符串, 读段字符串, 碱基错误率 $\\varepsilon$, 基础空位开放概率 $p_{\\text{go,base}}$, 空位延伸概率 $p_{\\text{ge}}$, 同聚物膨胀系数 $\\alpha$)：\n\n- 测试用例1 (理想路径，同聚物删除)：参考序列 = \"TTTAAAAAAAGGG\", 读段 = \"TTTAAAAAAGGG\", $\\varepsilon=0.01$, $p_{\\text{go,base}}=10^{-5}$, $p_{\\text{ge}}=0.3$, $\\alpha=0.8$。\n- 测试用例2 (长度相等，仅错配，高空位罚分)：参考序列 = \"TTTAAAAAAAGGG\", 读段 = \"TTTAAAATAAGGG\", $\\varepsilon=0.02$, $p_{\\text{go,base}}=10^{-8}$, $p_{\\text{ge}}=0.2$, $\\alpha=0.8$。\n- 测试用例3 (无差异，无同聚物效应)：参考序列 = \"ACGTACGTACGT\", 读段 = \"ACGTACGTACGT\", $\\varepsilon=0.01$, $p_{\\text{go,base}}=10^{-5}$, $p_{\\text{ge}}=0.3$, $\\alpha=1.0$。\n- 测试用例4 (长同聚物，多碱基删除)：参考序列 = \"CCCCCCCCCC\", 读段 = \"CCCCCCCC\", $\\varepsilon=0.005$, $p_{\\text{go,base}}=10^{-5}$, $p_{\\text{ge}}=0.5$, $\\alpha=1.0$。\n- 测试用例5 (同聚物插入)：参考序列 = \"GGGGGTTT\", 读段 = \"GGGGGGTTT\", $\\varepsilon=0.01$, $p_{\\text{go,base}}=10^{-5}$, $p_{\\text{ge}}=0.3$, $\\alpha=0.8$。\n\n您的程序必须为每个测试用例输出一个包含三个整数的列表：\n- 第一个整数：如果选择 $\\mathcal{H}_1$ (indel)，则为 $1$；如果选择 $\\mathcal{H}_0$ (仅错配)，则为 $0$。\n- 第二个整数：按上述定义的0-基参考序列边界位置；如果选择 $\\mathcal{H}_0$，则输出 $-1$。\n- 第三个整数：推断出的indel长度；如果选择 $\\mathcal{H}_0$，则输出 $0$。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有测试用例的结果，形式为方括号括起来的、无空格的、逗号分隔的列表的列表。例如： \"[[a,b,c],[d,e,f],...]\"，其中 $a,b,c,d,e,f$ 是如上所述的整数。", "solution": "该问题要求构建并实现一个贝叶斯假设检验框架，用于区分两种序列比对错误模型：一种只允许碱基替换（$\\mathcal{H}_0$），另一种同时允许替换和插入/删除（indel）（$\\mathcal{H}_1$）。这是从下一代测序（NGS）数据中进行灵敏变异检测的一项常见任务，尤其是在indel错误频发的同聚物区域。解决方案的核心是计算在每个假设下观测到读段序列（$D$）相对于参考序列（$R$）的似然度，即 $P(D \\mid \\mathcal{H}_0)$ 和 $P(D \\mid \\mathcal{H}_1)$，并在假设先验概率 $P(\\mathcal{H}_0)=P(\\mathcal{H}_1)$ 相等的情况下，选择似然度较高的假设。\n\n首先，我们将问题形式化。设参考序列为 $R = r_0r_1\\dots r_{m-1}$，长度为 $m$；读段序列为 $D = d_0d_1\\dots d_{n-1}$，长度为 $n$。我们的决策规则是：当且仅当 $\\log P(D \\mid \\mathcal{H}_1) > \\log P(D \\mid \\mathcal{H}_0)$ 时，选择 $\\mathcal{H}_1$。\n\n**假设 $\\mathcal{H}_0$（仅错配）下的似然度**\n\n该假设假定读段是通过仅替换错误从参考序列生成的。这意味着读段和参考序列之间存在一个固定的一对一比对，这只有在它们的长度相等（即 $m=n$）时才可能。\n如果 $m \\neq n$，则不可能有无空位的比对，因此我们将似然度定义为零，在对数尺度上即 $\\log P(D \\mid \\mathcal{H}_0) = -\\infty$。\n如果 $m=n$，比对由一系列 $m$ 个配对 $(r_i, d_i)$ 组成。假设碱基观测是独立的，对数似然度是每个观测的对数概率之和：\n$$ \\log P(D \\mid \\mathcal{H}_0) = \\sum_{i=0}^{m-1} \\log P(d_i \\mid r_i) $$\n发射概率 $P(d_i \\mid r_i)$ 由碱基错误率 $\\varepsilon$ 定义。对于匹配（$d_i=r_i$），概率为 $1-\\varepsilon$。对于错配（$d_i \\neq r_i$），假设所有三种可能的替换错误等可能，概率为 $\\varepsilon/3$。\n\n**假设 $\\mathcal{H}_1$（允许Indel）下通过Pair-HMM计算的似然度**\n\n该假设允许插入和删除，通过一个三状态配对隐马尔可夫模型（pair-HMM）进行建模。这三个状态是：\n1.  匹配（$M$）：$r_j$ 与 $d_i$ 比对。\n2.  插入（$I$）：$d_i$ 与参考序列中的一个空位比对。\n3.  删除（$D$）：$r_j$ 与读段中的一个空位比对。\n\n为了找到最可能的比对及其对数似然度 $\\log P(D \\mid \\mathcal{H}_1)$，我们使用Viterbi算法。该算法找到一条能最大化观测到读段序列概率的状态路径。我们使用动态规划表 $v_M(i, j)$、$v_I(i, j)$ 和 $v_D(i, j)$，它们分别存储了将前缀 $d_{0..i-1}$ 与 $r_{0..j-1}$ 比对，且以状态 $M$、$I$ 或 $D$ 结尾的最可能路径的对数概率。\n\n关键的创新点是同聚物敏感的空位开放概率 $p_{\\text{go,eff}}(k)$，它在每个参考序列边界 $k \\in \\{0, \\dots, m\\}$ 处计算。$p_{\\text{go,eff}}(k)$ 的值通过logistic变换计算得出：\n$$ p_{\\text{go,eff}}(k) = \\sigma\\Big(\\operatorname{logit}(p_{\\text{go,base}}) + \\alpha\\big(L(k)-1\\big)\\Big) $$\n其中 $\\sigma(z)=(1+e^{-z})^{-1}$ 是sigmoid函数，$\\operatorname{logit}(p)=\\ln(p/(1-p))$，$p_{\\text{go,base}}$ 是基准空位开放概率，$\\alpha$ 是同聚物膨胀系数，$L(k)$ 是跨越边界 $k$ 的同聚物运行长度。我们定义 $L(k)$ 为当 $r_{k-1} = r_k$（对于 $k \\in \\{1,\\dots,m-1\\}$）时的同聚物运行长度，否则（以及对于边界 $k=0$ 和 $k=m$）$L(k)=1$。这增加了在同聚物内部开启一个空位的概率。\n\nViterbi递推公式在对数空间中表示，以防止数值下溢。对于 $i \\in \\{1..n\\}$ 和 $j \\in \\{1..m\\}$：\n$d_{i-1}$ 和 $r_{j-1}$ 比对的对数发射概率为 $\\log e_{ij}$，匹配时为 $\\log(1-\\varepsilon)$，错配时为 $\\log(\\varepsilon/3)$。\n递推关系式为：\n$$ v_M(i,j) = \\log e_{ij} + \\max \\begin{cases} v_M(i-1,j-1) + \\log(1 - 2 p_{\\text{go,eff}}(j-1)) \\\\ v_I(i-1,j-1) + \\log(1 - p_{\\text{ge}}) \\\\ v_D(i-1,j-1) + \\log(1 - p_{\\text{ge}}) \\end{cases} $$\n$$ v_I(i,j) = \\max \\begin{cases} v_M(i-1,j) + \\log p_{\\text{go,eff}}(j) \\\\ v_I(i-1,j) + \\log p_{\\text{ge}} \\end{cases} $$\n$$ v_D(i,j) = \\max \\begin{cases} v_M(i,j-1) + \\log p_{\\text{go,eff}}(j-1) \\\\ v_D(i,j-1) + \\log p_{\\text{ge}} \\end{cases} $$\nDP表初始化时，$v_M(0,0)=0$，所有其他条目为 $-\\infty$。最终的对数似然度是比对结束时的最大值：$\\log P(D \\mid \\mathcal{H}_1) = \\max(v_M(n,m), v_I(n,m), v_D(n,m))$。\n\n在动态规划过程中，我们存储回溯指针以重构最优比对路径。如果选择了 $\\mathcal{H}_1$，我们从 $(n,m)$ 回溯到 $(0,0)$ 以确定状态序列（$M, I, D$）。然后我们解析此路径，找到最长的连续 $I$ 或 $D$ 状态序列。根据指定的输出规则，该序列的起始点决定了indel的位置，其长度即为indel的长度。如果多个空位片段具有相同的最大长度，则报告在比对中最早出现的那个（最接近开头）。如果选择了 $\\mathcal{H}_0$，我们报告未找到indel。\n\n这种基于原理的方法为局部重比对提供了一种定量的、可复现的方法，它在一个贝叶斯框架内直接对测序技术的已知错误模式进行建模。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the local realignment strategy on all test cases.\n    \"\"\"\n    # Test cases as tuples: (reference, read, error_rate, gap_open_base, gap_extend, alpha)\n    test_cases = [\n        (\"TTTAAAAAAAGGG\", \"TTTAAAAAAGGG\", 0.01, 1e-5, 0.3, 0.8),\n        (\"TTTAAAAAAAGGG\", \"TTTAAAATAAGGG\", 0.02, 1e-8, 0.2, 0.8),\n        (\"ACGTACGTACGT\", \"ACGTACGTACGT\", 0.01, 1e-5, 0.3, 1.0),\n        (\"CCCCCCCCCC\", \"CCCCCCCC\", 0.005, 1e-5, 0.5, 1.0),\n        (\"GGGGGTTT\", \"GGGGGGTTT\", 0.01, 1e-5, 0.3, 0.8),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_single_case(*case)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of lists, with no spaces.\n    formatted_results = \",\".join([f\"[{','.join(map(str, r))}]\" for r in results])\n    print(f\"[{formatted_results}]\")\n\ndef _solve_single_case(ref, read, epsilon, p_go_base, p_ge, alpha):\n    \"\"\"\n    Implements the local realignment strategy for a single test case.\n    \"\"\"\n    m = len(ref)\n    n = len(read)\n    \n    # === Step 1: Calculate log likelihood for H0 (mismatch-only model) ===\n    log_p_h0 = -np.inf\n    if m == n:\n        log_p_h0 = 0.0\n        with np.errstate(divide='ignore'):\n            log_match = np.log(1.0 - epsilon)\n            log_mismatch = np.log(epsilon / 3.0)\n        for i in range(m):\n            if ref[i] == read[i]:\n                log_p_h0 += log_match\n            else:\n                log_p_h0 += log_mismatch\n\n    # === Step 2: Calculate log likelihood for H1 (indel-aware model) via Viterbi ===\n    \n    # Pre-compute homopolymer-sensitive gap open probabilities\n    def sigma(z):\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def logit(p):\n        # Add a small epsilon to avoid log(0) for p=1.0 or p=0.0\n        p = np.clip(p, 1e-15, 1.0 - 1e-15)\n        return np.log(p / (1.0 - p))\n\n    logit_p_go_base = logit(p_go_base)\n    \n    p_go_eff = np.zeros(m + 1)\n    run_lengths_map = [1] * m\n    if m > 0:\n        i = 0\n        while i  m:\n            j = i\n            while j  m and ref[j] == ref[i]:\n                j += 1\n            current_run_length = j - i\n            for k in range(i, j):\n                run_lengths_map[k] = current_run_length\n            i = j\n            \n    for k in range(m + 1):\n        L_k = 1\n        if 0  k  m and ref[k - 1] == ref[k]:\n             L_k = run_lengths_map[k]\n        \n        z = logit_p_go_base + alpha * (L_k - 1)\n        p_go_eff[k] = sigma(z)\n\n    # Pre-compute log probabilities for transitions to avoid re-calculation\n    with np.errstate(divide='ignore'):\n        log_p_ge = np.log(p_ge)\n        log_p_close = np.log(1.0 - p_ge)\n        log_p_go_eff = np.log(p_go_eff)\n        log_p_mm_trans = np.log(1.0 - 2 * p_go_eff)\n\n    # Initialize dynamic programming tables for Viterbi\n    v_M = np.full((n + 1, m + 1), -np.inf)\n    v_I = np.full((n + 1, m + 1), -np.inf)\n    v_D = np.full((n + 1, m + 1), -np.inf)\n    \n    # Backtrack pointer tables (0: from M, 1: from I, 2: from D)\n    ptr_M = np.zeros((n + 1, m + 1), dtype=int)\n    ptr_I = np.zeros((n + 1, m + 1), dtype=int)\n    ptr_D = np.zeros((n + 1, m + 1), dtype=int)\n    \n    v_M[0, 0] = 0.0\n\n    # Fill DP tables\n    with np.errstate(divide='ignore'):\n        log_emission_match = np.log(1.0 - epsilon)\n        log_emission_mismatch = np.log(epsilon / 3.0)\n\n    for i in range(n + 1):\n        for j in range(m + 1):\n            if i == 0 and j == 0:\n                continue\n\n            # Update D state (gap in read)\n            if j > 0:\n                from_M_D = v_M[i, j - 1] + log_p_go_eff[j - 1]\n                from_D_D = v_D[i, j - 1] + log_p_ge\n                if from_M_D > from_D_D:\n                    v_D[i, j] = from_M_D\n                    ptr_D[i, j] = 0 # from M\n                else:\n                    v_D[i, j] = from_D_D\n                    ptr_D[i, j] = 2 # from D\n            \n            # Update I state (gap in reference)\n            if i > 0:\n                from_M_I = v_M[i - 1, j] + log_p_go_eff[j]\n                from_I_I = v_I[i - 1, j] + log_p_ge\n                if from_M_I > from_I_I:\n                    v_I[i, j] = from_M_I\n                    ptr_I[i, j] = 0 # from M\n                else:\n                    v_I[i, j] = from_I_I\n                    ptr_I[i, j] = 1 # from I\n\n            # Update M state (match/mismatch)\n            if i > 0 and j > 0:\n                log_emission = log_emission_match if read[i - 1] == ref[j - 1] else log_emission_mismatch\n                \n                from_M_M = v_M[i - 1, j - 1] + log_p_mm_trans[j - 1]\n                from_I_M = v_I[i - 1, j - 1] + log_p_close\n                from_D_M = v_D[i - 1, j - 1] + log_p_close\n                \n                scores = np.array([from_M_M, from_I_M, from_D_M])\n                best_prev_state = np.argmax(scores)\n                v_M[i, j] = log_emission + scores[best_prev_state]\n                ptr_M[i, j] = best_prev_state\n\n    # === Step 3: Compare hypotheses and extract results ===\n    final_scores = [v_M[n, m], v_I[n, m], v_D[n, m]]\n    log_p_h1 = np.max(final_scores)\n    \n    if log_p_h1 = log_p_h0:\n        return [0, -1, 0]\n\n    # H1 is chosen, traceback to find the longest indel\n    path = []\n    state = np.argmax(final_scores)\n    i, j = n, m\n    \n    while i > 0 or j > 0:\n        path.append((state, i, j))\n        if state == 0: # M\n            prev_state = ptr_M[i, j]\n            i, j = i - 1, j - 1\n            state = prev_state\n        elif state == 1: # I\n            prev_state = ptr_I[i, j]\n            i = i - 1\n            state = prev_state\n        else: # D\n            prev_state = ptr_D[i, j]\n            j = j - 1\n            state = prev_state\n    \n    path.reverse()\n    \n    max_indel_len = 0\n    indel_pos = -1\n    \n    k = 0\n    while k  len(path):\n        current_state, _, _ = path[k]\n        if current_state == 1 or current_state == 2: # Found an indel\n            indel_type = current_state\n            start_k = k\n            indel_len = 1\n            while k + 1  len(path) and path[k + 1][0] == indel_type:\n                k += 1\n                indel_len += 1\n            \n            if indel_len > max_indel_len:\n                max_indel_len = indel_len\n                _, start_i, start_j = path[start_k]\n                if indel_type == 1: # Insertion\n                    indel_pos = start_j\n                else: # Deletion\n                    indel_pos = start_j - 1\n        k += 1\n\n    return [1, indel_pos, max_indel_len]\n    \nsolve()\n```", "id": "2754093"}]}