{"hands_on_practices": [{"introduction": "在ChIP-seq实验中，为确保测序资源的有效利用，评估文库的复杂度至关重要。PCR扩增是文库构建的必要步骤，但过度扩增会导致大量重复读数，从而降低发现新分子事件的效率。本练习 [@problem_id:2796455] 将指导您如何利用唯一分子标识符 (Unique Molecular Identifiers, UMIs) 的数据，通过一个基于频率分布的统计模型，来预测增加测序深度预计能带来的新独特分子的数量，从而为实验设计提供数据驱动的决策依据。", "problem": "准备了一项靶向某个转录因子的染色质免疫沉淀测序 (ChIP-seq) 实验，并使用了唯一分子标识符 (UMI) 来对聚合酶链式反应 (PCR) 的扩增重复进行精确去重。比对后，每条读长在某个基因组位点上被分配到一个 UMI 家族；每个 UMI 家族对应一个原始捕获的分子，其家族大小等于为该分子观测到的读长数量。过度扩增会引入一个重尾的家族大小分布，这导致文库复杂度的饱和：随着测序深度的增加，新发现的独特分子的比例会下降，因为额外的读长越来越倾向于重复采样已经观测到的分子。令 $f_k$ 表示当前数据集中大小恰好为 $k$ 的 UMI 家族的观测数量，令 $n=\\sum_{k \\ge 1} k f_k$ 为当前已比对读长的总数。\n\n从“读长是对一个未知的分子丰度离散分布的独立抽样”这一基本假设出发，并对大的 $n$ 和小的单分子采样概率使用标准的泊松分布近似二项分布定律，推导一个表达式，用于计算若额外收集 $m$ 条读长，将会观测到的额外独特分子的期望数量。该表达式需用观测到的频率的频率 $\\{f_k\\}$ 和比率 $t=m/n$ 来表示。你可以假设一个泊松化框架，在该框架下，当前和未来测序的计数在以潜在的分子捕获概率为条件时是独立的泊松随机变量，并且你可以将你的最终表达式截断到 $\\{f_k\\}$ 的观测支撑集上。\n\n现在将你的表达式应用于当前数据集上测得的以下 UMI 家族直方图，其支撑集被截断在 $k \\le 4$ 处，且更高的计数值可以忽略不计：\n- $f_1 = 8.0 \\times 10^{6}$\n- $f_2 = 3.0 \\times 10^{6}$\n- $f_3 = 1.2 \\times 10^{6}$\n- $f_4 = 6.0 \\times 10^{5}$\n\n取当前已比对读长总数为 $n=\\sum_{k=1}^{4} k f_k$，并假设你计划从同一样本文库中额外测序 $m=1.0 \\times 10^{7}$ 条读长。使用你推导出的截断表达式，计算在这次更深的测序中预期会发现的额外独特分子的数量。以普通计数形式报告你的最终结果（无单位），并四舍五入到 $4$ 位有效数字。", "solution": "所述问题具有科学依据，提法明確，并包含足够的信息以得出唯一解。它描述了定量基因组学中的一个标准挑战——从初始测序运行中预测文库复杂度。在此背景下，使用泊松化框架是对此类计数数据进行建模的有效且常用的技术。因此，我将继续进行推导和計算。\n\n首先，我们推导额外独特分子期望数量的一般表达式。假设存在一个未知总数的独特分子，以 $i$ 索引。令文庫中分子 $i$ 的相对丰度为 $c_i$，使得 $\\sum_i c_i = 1$。在初始测序实验中，共生成了 $n$ 条读长。在泊松化框架内，为分子 $i$ 观测到的读长数量，记为 $X_i$，是一个服从泊松分布的随机变量：\n$$X_i \\sim \\text{Poisson}(\\lambda_i)$$\n其中速率参数 $\\lambda_i = n c_i$。\n\n接着进行第二次测序实验，生成额外的 $m$ 条读长。在这个新实验中为分子 $i$ 观测到的读长数量，记为 $X'_i$，也是一个泊松随机变量。其速率与新的测序深度 $m$ 成正比：\n$$X'_i \\sim \\text{Poisson}(\\lambda'_i)$$\n其中 $\\lambda'_i = m c_i$。我们可以通过定义测序深度之比 $t = m/n$ 来将此速率与原始速率 $\\lambda_i$ 联系起来。于是，$\\lambda'_i = (m/n) (n c_i) = t \\lambda_i$。在以潜在丰度 $\\{c_i\\}$ 为条件时，$X_i$ 和 $X'_i$ 的计数是独立的。\n\n我们寻求*额外*独特分子的期望数量，即那些在第一次实验中未被观测到，但在第二次实验中被观测到的分子。如果 $X_i = 0$，则分子 $i$ 在第一次实验中未被观测到。如果 $X'_i > 0$，则它在第二次实验中被观测到。令 $\\Delta U$ 为这类分子的数量。我们关心其期望值 $\\mathbb{E}[\\Delta U]$。\n利用期望的线性性质，我们可以写出：\n$$\\mathbb{E}[\\Delta U] = \\mathbb{E}\\left[\\sum_i \\mathbf{1}_{\\{X_i=0, X'_i > 0\\}}\\right] = \\sum_i \\mathbb{E}[\\mathbf{1}_{\\{X_i=0, X'_i > 0\\}}] = \\sum_i P(X_i=0, X'_i > 0)$$\n由于 $X_i$ 和 $X'_i$ 的独立性，这变为：\n$$\\mathbb{E}[\\Delta U] = \\sum_i P(X_i=0) P(X'_i > 0)$$\n对于一个泊松随机变量 $Z \\sim \\text{Poisson}(\\mu)$，我们有 $P(Z=0) = \\exp(-\\mu)$ 和 $P(Z>0) = 1 - P(Z=0) = 1 - \\exp(-\\mu)$。将此应用于我们的变量：\n$$P(X_i=0) = \\exp(-\\lambda_i)$$\n$$P(X'_i>0) = 1 - \\exp(-t\\lambda_i)$$\n将这些代入 $\\mathbb{E}[\\Delta U]$ 的表达式中：\n$$\\mathbb{E}[\\Delta U] = \\sum_i \\exp(-\\lambda_i) (1 - \\exp(-t\\lambda_i))$$\n这个表达式依赖于未知参数 $\\{\\lambda_i\\}$。题目要求用观测到的频率的频率 $\\{f_k\\}$ 来表示，其中 $f_k$ 是被观测到恰好 $k$ 次的 UMI 家族（分子）的数量。 $f_k$ 的期望值为：\n$$\\mathbb{E}[f_k] = \\mathbb{E}\\left[\\sum_i \\mathbf{1}_{\\{X_i=k\\}}\\right] = \\sum_i P(X_i=k) = \\sum_i \\frac{\\lambda_i^k \\exp(-\\lambda_i)}{k!}$$\n为了将 $\\mathbb{E}[\\Delta U]$ 与 $\\mathbb{E}[f_k]$ 联系起来，我们使用泰勒级数 $\\sum_{k=1}^{\\infty} (-1)^{k-1} \\frac{(t\\lambda_i)^k}{k!}$ 展开我们 $\\mathbb{E}[\\Delta U]$ 表达式中的 $(1 - \\exp(-t\\lambda_i))$ 项。\n\\begin{align*} \\mathbb{E}[\\Delta U] = \\sum_i \\exp(-\\lambda_i) \\left( \\sum_{k=1}^{\\infty} (-1)^{k-1} \\frac{(t\\lambda_i)^k}{k!} \\right) \\\\ = \\sum_i \\sum_{k=1}^{\\infty} (-1)^{k-1} t^k \\frac{\\lambda_i^k \\exp(-\\lambda_i)}{k!} \\end{align*}\n通过交换求和顺序（在此处是允许的）：\n\\begin{align*} \\mathbb{E}[\\Delta U] = \\sum_{k=1}^{\\infty} (-1)^{k-1} t^k \\left( \\sum_i \\frac{\\lambda_i^k \\exp(-\\lambda_i)}{k!} \\right) \\\\ = \\sum_{k=1}^{\\infty} (-1)^{k-1} t^k \\mathbb{E}[f_k] \\end{align*}\n这就提供了所需的联系。为了得到一个 $\\Delta U$ 的实用估计量，我们用其观测值 $f_k$ 替换期望值 $\\mathbb{E}[f_k]$。这是一个矩估计量。因此，额外独特分子的估计数量 $\\widehat{\\Delta U}$ 为：\n$$\\widehat{\\Delta U} = \\sum_{k=1}^{\\infty} (-1)^{k-1} t^k f_k = f_1 t - f_2 t^2 + f_3 t^3 - f_4 t^4 + \\dots$$\n题目规定，该表达式应被截断到 $\\{f_k\\}$ 的观测支撑集上。\n\n现在，我们将此结果应用于所提供的数据。\n给定的 UMI 家族直方图是：\n- $f_1 = 8.0 \\times 10^{6}$\n- $f_2 = 3.0 \\times 10^{6}$\n- $f_3 = 1.2 \\times 10^{6}$\n- $f_4 = 6.0 \\times 10^{5}$\n\n首先，我们计算当前已比对读长的总数 $n$：\n$$n = \\sum_{k=1}^{4} k f_k = (1)(8.0 \\times 10^{6}) + (2)(3.0 \\times 10^{6}) + (3)(1.2 \\times 10^{6}) + (4)(6.0 \\times 10^{5})$$\n$$n = 8.0 \\times 10^{6} + 6.0 \\times 10^{6} + 3.6 \\times 10^{6} + 2.4 \\times 10^{6}$$\n$$n = (8.0 + 6.0 + 3.6 + 2.4) \\times 10^{6} = 20.0 \\times 10^{6} = 2.0 \\times 10^{7}$$\n将要收集的额外读长数量是 $m = 1.0 \\times 10^{7}$。测序深度的比率为：\n$$t = \\frac{m}{n} = \\frac{1.0 \\times 10^{7}}{2.0 \\times 10^{7}} = 0.5$$\n使用截断的 $\\widehat{\\Delta U}$ 表达式和给定数据（直到 $k=4$）：\n$$\\widehat{\\Delta U} = f_1 t - f_2 t^2 + f_3 t^3 - f_4 t^4$$\n我们代入 $f_k$ 和 $t$ 的值：\n$$\\widehat{\\Delta U} = (8.0 \\times 10^{6})(0.5) - (3.0 \\times 10^{6})(0.5)^2 + (1.2 \\times 10^{6})(0.5)^3 - (6.0 \\times 10^{5})(0.5)^4$$\n$$\\widehat{\\Delta U} = (8.0 \\times 10^{6})(0.5) - (3.0 \\times 10^{6})(0.25) + (1.2 \\times 10^{6})(0.125) - (0.6 \\times 10^{6})(0.0625)$$\n对每一项进行计算：\n- 第 1 项： $4.0 \\times 10^{6}$\n- 第 2 项： $0.75 \\times 10^{6}$\n- 第 3 项： $0.15 \\times 10^{6}$\n- 第 4 项： $0.0375 \\times 10^{6}$\n\n现在，我们合并这些项：\n$$\\widehat{\\Delta U} = (4.0 - 0.75 + 0.15 - 0.0375) \\times 10^{6}$$\n$$\\widehat{\\Delta U} = (3.25 + 0.15 - 0.0375) \\times 10^{6}$$\n$$\\widehat{\\Delta U} = (3.40 - 0.0375) \\times 10^{6}$$\n$$\\widehat{\\Delta U} = 3.3625 \\times 10^{6}$$\n题目要求结果四舍五入到 $4$ 位有效数字。\n将数值 $3.3625 \\times 10^{6}$ 四舍五入到 $4$ 位有效数字得到 $3.363 \\times 10^{6}$。\n这就是预期的额外独特分子数量。", "answer": "$$\\boxed{3.363 \\times 10^6}$$", "id": "2796455"}, {"introduction": "获得原始读数计数后，要在不同实验条件（例如，处理组与对照组）之间进行有意义的定量比较，必须进行严格的数据标准化。技术差异，如免疫沉淀效率或测序深度的不同，可能掩盖真实的生物学变化。本练习 [@problem_id:2796414] 介绍了一种强大的标准化方法——外源Spike-in控制，它通过引入已知量的外源染色质来计算一个校正因子，从而准确地对齐不同样本的信号，实现可靠的定量分析。", "problem": "一个实验室使用外源spike-in对照进行染色质免疫沉淀结合高通量DNA测序 (ChIP-seq)，以实现蛋白质-DNA结合谱的样本间标准化。每个生物样本都加入了等量的、来自不同物种的spike-in染色质，并且测序数据经过相同的处理流程，得到内源和spike-in基因组的唯一比对、去除重复的读数计数。\n\n假设以下基本事实成立。首先，在基于测序的分析中，读数计数与从基础片段库中抽样的DNA片段数量成正比。其次，如果在各个样本中加入等量的外源spike-in染色质，并与内源染色质一同处理，那么在不同样本中观察到的spike-in覆盖度的任何差异都源于样本特有的文库抽样因子（如测序深度和免疫沉淀效率），而非spike-in本身的生物学差异。因此，通过使各样本的spike-in覆盖度均等化，可以分离并校正这些技术因素，并且应将相同的乘法校正应用于内源读数，以实现样本间的比较。\n\n给定两个样本：一个参照样本和一个处理样本。经过比对和质量控制后，参照样本中的总spike-in读数为 $4.80 \\times 10^{6}$，处理样本中的总spike-in读数为 $3.20 \\times 10^{6}$。在处理样本中，某个特定启动子区域的原始内源读数计数为 $3740$。\n\n仅使用上述原理，首先推导出一个处理样本的缩放因子表达式，该因子能将处理样本的spike-in覆盖度等同于参照样本，然后应用此因子重新缩放指定启动子区域的处理样本内源读数。仅报告在根据参照样本的spike-in水平进行标准化后，处理样本中该启动子的重缩放内源读数。答案四舍五入至四位有效数字。读数计数无需单位。", "solution": "该问题在科学上是有效且表述清晰的。它描述了定量基因组学中一个标准且方法学上可靠的程序：使用外源spike-in对照对染色质免疫沉淀测序 (ChIP-seq) 数据进行标准化。所提供的原理是高通量测序定量分析的基石。\n\n其核心前提是，在每个样本中都加入了等量的、与内源染色质不同的spike-in染色质。因此，比对到spike-in基因组的测序读数数量的任何观察到的变化，都完全归因于样本间的技术差异，例如免疫沉淀 (IP) 效率、文库构建和测序深度的变化。就所研究的系统而言，这些差异并非源于生物学原因。为了校正这种技术变异，计算一个缩放因子以使所有样本的spike-in读数计数均等化至一个共同的参照水平。然后将此相同因子应用于内源读数计数，从而能够对蛋白质-DNA结合事件进行有效的定量比较。\n\n设 $C_{spike, ref}$ 和 $C_{spike, treat}$ 分别表示参照样本和处理样本中来自spike-in基因组的唯一比对、去除重复的总读数。设 $C_{endo, treat, raw}$ 为处理样本中特定内源启动子区域的原始读数计数。我们的目标是计算处理样本中该启动子的标准化内源读数计数，我们将其表示为 $C_{endo, treat, norm}$。\n\n我们必须首先推导一个缩放因子，称之为 $\\alpha$。当它乘以处理样本的读数计数时，处理样本的spike-in计数变得与参照样本相等。该条件用数学表示为：\n$$ \\alpha \\cdot C_{spike, treat} = C_{spike, ref} $$\n求解缩放因子 $\\alpha$ 可得：\n$$ \\alpha = \\frac{C_{spike, ref}}{C_{spike, treat}} $$\n这个推导出的因子概括了参照样本和处理样本之间技术效率的比率。大于 $1$ 的因子表明处理样本的总体信号回收率低于参照样本，因此其读数必须按比例放大。\n\n题目要求将此相同的乘法校正应用于内源读数计数。因此，处理样本中启动子区域的标准化内源读数计算如下：\n$$ C_{endo, treat, norm} = \\alpha \\cdot C_{endo, treat, raw} $$\n通过代入 $\\alpha$ 的表达式，我们得到完整的标准化公式：\n$$ C_{endo, treat, norm} = \\left( \\frac{C_{spike, ref}}{C_{spike, treat}} \\right) \\cdot C_{endo, treat, raw} $$\n我们获得了以下数值数据：\n-   参照样本中的spike-in计数，$C_{spike, ref} = 4.80 \\times 10^{6}$。\n-   处理样本中的spike-in计数，$C_{spike, treat} = 3.20 \\times 10^{6}$。\n-   处理样本中启动子区域的原始内源计数，$C_{endo, treat, raw} = 3740$。\n\n首先，我们计算缩放因子 $\\alpha$：\n$$ \\alpha = \\frac{4.80 \\times 10^{6}}{3.20 \\times 10^{6}} = \\frac{4.80}{3.20} = 1.5 $$\n缩放因子是一个精确值 $1.5$。\n\n接下来，我们将此因子应用于原始内源读数计数以获得标准化计数：\n$$ C_{endo, treat, norm} = 1.5 \\cdot 3740 = 5610 $$\n计算结果为一个整数值 $5610$。题目要求答案四舍五入至四位有效数字。数字 $5610$ 可以写成 $5.610 \\times 10^3$，明确表示有四位有效数字。由于计算结果是精确的，并且已经以四位数字的形式呈现，因此无需进一步四舍五入。标准化读数计数为 $5610$。", "answer": "$$\n\\boxed{5610}\n$$", "id": "2796414"}, {"introduction": "ChIP-seq分析的核心任务是从背景噪声中识别出真实的蛋白结合信号，这一过程称为“峰识别”（peak calling）。这需要建立一个能够准确描述背景读数分布的统计模型。本动手编程练习 [@problem_id:2796499] 将引导您实现并比较几种基础的背景噪音“零假设”模型，从简单的全局泊松 ($Poisson$) 分布到更精细的局部负二项 ($Negative Binomial$) 分布模型，最终计算出潜在结合位点的统计显著性。", "problem": "染色质免疫沉淀测序（ChIP-seq）的峰识别依赖于为固定宽度基因组窗口内的测序读段计数估计背景模型。请构建一个方法，该方法基于测序实验计数建模的基本原理，使用匹配的对照组轨道来估计局部背景率，并量化此选择如何改变用于检验富集程度的零分布。使用以下核心定义和经过充分检验的建模假设作为起点：在背景条件下，落入长度为 $L$ 的窗口中的读段来自一个泊松过程，其均值等于该窗口中预期的读段数；对照组（input）读段近似于片段化和可比对性的背景分布；相对于泊松模型的过度离散可以通过伽马-泊松混合模型来表示，从而得到计数的负二项（NB）边际分布。\n\n您的程序必须实现以下内容，除了每个测试用例中给出的参数外，不得使用任何外部数据：\n\n- 染色质免疫沉淀测序（ChIP-seq）与对照组之间的文库缩放：如果ChIP的总比对读段数为 $N_{\\mathrm{ChIP}}$，对照组为 $N_{\\mathrm{Ctrl}}$，则定义缩放因子 $s = N_{\\mathrm{ChIP}}/N_{\\mathrm{Ctrl}}$。\n\n- 窗口中的全局背景率：设基因组长度为 $G$（单位：碱基对），窗口长度为 $L$（单位：碱基对）。在均匀背景下，一个窗口中的预期全局背景计数为\n$$\n\\lambda_{\\mathrm{global}} = \\frac{N_{\\mathrm{ChIP}}}{G}\\,L.\n$$\n\n- 使用对照组轨道计算的局部背景率：对于一个以该窗口为中心、长度为 $W$（单位：碱基对）且包含 $C_{\\mathrm{loc}}$ 个对照组读段的局部区域，该窗口的原始局部背景期望为\n$$\n\\lambda_{\\mathrm{local,raw}} = s \\cdot C_{\\mathrm{loc}} \\cdot \\frac{L}{W}.\n$$\n为避免在 $C_{\\mathrm{loc}}$ 很小时出现退化估计，将局部背景率的下限设为全局背景率：\n$$\n\\lambda_{\\mathrm{local}} = \\max\\!\\left(\\lambda_{\\mathrm{local,raw}},\\,\\lambda_{\\mathrm{global}}\\right).\n$$\n\n- 用于检验窗口中观测到的ChIP计数 $X$ 的富集程度的零分布：\n  1. 全局泊松零假设：$X \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{global}})$。\n  2. 局部泊松零假设：$X \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{local}})$。\n  3. 通过伽马-泊松（负二项）混合模型得到的过度离散的局部零假设：假设 $X$ 的均值为 $\\mu=\\lambda_{\\mathrm{local}}$，方差为 $\\mu + \\phi \\mu^{2}$，其中离散参数 $\\phi \\ge 0$。等价地，$X$ 服从负二项分布，其形状参数为 $r = 1/\\phi$，成功概率为 $p = r/(r+\\mu)$，得到\n  $$\n  \\mathbb{E}[X]=\\mu,\\quad \\mathrm{Var}(X)=\\mu+\\phi \\mu^{2}.\n  $$\n  对于 $\\phi = 0$ 的情况，该分布简化为泊松分布。\n\n- 对于每个零假设，计算富集的单侧尾部概率（p值），\n$$\np = \\Pr\\{X' \\ge X \\mid \\text{null}\\}.\n$$\n\n实现上述方法，并将其应用于下面的测试集。对于每个测试用例，您将获得以下参数：$(N_{\\mathrm{ChIP}}, N_{\\mathrm{Ctrl}}, G, L, W, C_{\\mathrm{loc}}, X, \\phi)$：\n\n- 测试用例 1（正常路径，中等程度的局部富集）：$(2\\times 10^{7},\\,1.5\\times 10^{7},\\,3\\times 10^{9},\\,500,\\,10{,}000,\\,60,\\,12,\\,0.2)$。\n- 测试用例 2（边界情况，局部对照组读段为零；局部背景率取全局背景率作为下限）：$(1.2\\times 10^{7},\\,8\\times 10^{6},\\,3\\times 10^{9},\\,1000,\\,10{,}000,\\,0,\\,5,\\,0.3)$。\n- 测试用例 3（高局部背景；局部背景率占主导）：$(2\\times 10^{7},\\,2\\times 10^{7},\\,3\\times 10^{9},\\,200,\\,5{,}000,\\,300,\\,20,\\,0.1)$。\n- 测试用例 4（强过度离散）：$(1.5\\times 10^{7},\\,1.2\\times 10^{7},\\,3\\times 10^{9},\\,400,\\,8{,}000,\\,40,\\,8,\\,0.5)$。\n\n您的程序必须为每个测试用例按所列顺序输出一个包含三个浮点p值的列表：$[p_{\\mathrm{global\\_Poisson}}, p_{\\mathrm{local\\_Poisson}}, p_{\\mathrm{local\\_NB}}]$，其中每个值都四舍五入到6位小数。将所有测试用例的结果聚合到一行中，该行包含一个由这些单个用例列表组成的列表，不含空格，例如：$[[a,b,c],[d,e,f],\\dots]$。\n\n你的程序应仅按此格式产生一行输出，且不得读取任何输入。", "solution": "所提出的问题是一个有效、良构且有科学依据的练习，涉及测序数据的统计建模，特别是针对染色质免疫沉淀测序（ChIP-seq）实验中的峰识别。它通过比较不同的读段计数零模型，正确地阐述了区分真实信号与背景噪声的核心任务。所提出的模型——用于均匀背景的泊松模型、用于局部调整背景的泊松模型以及用于过度离散局部背景的负二项模型——都是计算基因组学中的标准和基本工具。该问题提供了所有必需的参数，并定义了一个清晰、确定性的计算步骤。我现在将着手提供一个基于基本原理的解决方案。\n\nChIP-seq分析的基本目标是识别目标特异性蛋白富集的基因组区域。这是通过测量由靶向该蛋白的抗体进行免疫沉淀的DNA片段数量来实现的。然而，在任何给定基因组窗口中测序读段的原始计数（记为 $X$）本身并不足以断言富集。必须根据一个零假设来评估这个计数，该零假设认为观测到的读段仅仅是由背景过程产生的。该问题要求我们构建并比较三种这样的零模型，并计算在每种模型下观测计数 $X$ 的统计显著性（p值）。\n\n首先，我们必须对测序文库进行标准化。一个ChIP-seq实验通常与一个对照实验（例如，input DNA）配对，以解释各种偏好。总比对读段数 $N_{\\mathrm{ChIP}}$ 和 $N_{\\mathrm{Ctrl}}$ 可能会不同。我们计算一个缩放因子 $s = N_{\\mathrm{ChIP}}/N_{\\mathrm{Ctrl}}$，将对照文库标准化到与ChIP文库相同的有效深度。这确保了读段计数是可比较的。\n\n下一步是定义长度为 $L$ 的基因组窗口内的预期背景读段计数 $\\lambda$。这个 $\\lambda$ 将作为我们零分布的参数。\n\n**1. 全局背景模型：**\n最简单的模型假设背景读段在整个长度为 $G$ 的基因组上均匀分布。ChIP样本的平均读段密度是每个碱基对 $N_{\\mathrm{ChIP}}/G$ 个读段。因此，一个长度为 $L$ 的窗口中预期的读段数是：\n$$\n\\lambda_{\\mathrm{global}} = \\frac{N_{\\mathrm{ChIP}}}{G}\\,L\n$$\n在此模型下，零假设是观测到的计数 $X$ 来自于一个以此全局率为参数的泊松分布：$X' \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{global}})$。泊松分布是为在恒定平均速率下发生的独立事件计数进行建模的经典选择。\n\n**2. 局部背景模型：**\n均匀背景假设是一个粗略的近似。实际上，基因组在可及性、可比对性和GC含量方面表现出显著的局部差异，这导致背景读段呈非均匀分布。匹配的对照实验可以捕捉到这些局部偏好。我们可以使用我们感兴趣的窗口周围一个更大的长度为 $W$ 的区域内的对照样本读段计数，来推导一个更准确的局部背景估计。设 $C_{\\mathrm{loc}}$ 是这个局部区域中的对照组读段数。假设在*该局部区域内*是均匀分布的，那么在较小的长度为 $L$ 的窗口中，预期的对照组读段数将是 $C_{\\mathrm{loc}} \\cdot (L/W)$。然后我们用 $s$ 对其进行缩放以匹配ChIP文库深度，从而得到原始的局部背景率：\n$$\n\\lambda_{\\mathrm{local,raw}} = s \\cdot C_{\\mathrm{loc}} \\cdot \\frac{L}{W}\n$$\n在对照组读段非常少或为零（$C_{\\mathrm{loc}} \\approx 0$）的区域，这个估计可能会退化并被人为地拉低，从而导致伪显著性。为了创建一个更稳健的估计量，我们通过取局部和全局估计值的最大值来对其进行正则化。这确保了局部背景率永远不会低于基线全局率：\n$$\n\\lambda_{\\mathrm{local}} = \\max\\!\\left(\\lambda_{\\mathrm{local,raw}},\\,\\lambda_{\\mathrm{global}}\\right)\n$$\n相应的零假设则是 $X' \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{local}})$。\n\n**3. 过度离散的局部背景模型：**\n对测序数据的经验性分析表明，读段计数的方差通常大于其均值（$\\mathrm{Var}(X) > \\mathbb{E}[X]$），这一现象被称为过度离散。假定 $\\mathrm{Var}(X) = \\mathbb{E}[X] = \\lambda$ 的泊松模型在这种情况下是不够的。一种常见且理论上优美的建模过度离散的方法是假设泊松率参数 $\\lambda$ 本身是一个从伽马分布中抽取的随机变量。这种伽马-泊松混合模型产生的计数边际分布是负二项（NB）分布。\n\nNB分布可以通过多种方式参数化。问题指定了一种参数化方法，其均值为 $\\mu$，离散参数为 $\\phi$，使得方差是均值的二次函数：\n$$\n\\mathrm{Var}(X) = \\mu + \\phi \\mu^2\n$$\n对于我们的零模型，我们将均值设置为背景的最佳估计，即局部背景率，因此 $\\mu = \\lambda_{\\mathrm{local}}$。离散参数 $\\phi \\ge 0$ 捕捉了过度离散的程度；如果 $\\phi = 0$，方差降为 $\\mu$，NB分布收敛到均值为 $\\mu$ 的泊松分布。当 $\\phi > 0$ 时，NB分布可以通过形状参数 $r = 1/\\phi$ 和成功概率 $p = r/(r+\\mu)$ 来定义。此时的零假设是 $X' \\sim \\mathrm{NB}(r, p)$。这个模型更灵活，因为它可以解释简单的泊松过程无法捕捉到的生物学和技术上的变异。\n\n**显著性检验：**\n对于这三个零模型中的每一个，我们都计算一个p值，它是在零假设为真的前提下，观测到至少与测量计数 $X$ 一样极端的计数的概率。这是一个单侧尾部概率：\n$$\np = \\Pr\\{X' \\ge X \\mid \\text{null}\\} = \\sum_{k=X}^{\\infty} \\Pr\\{X' = k \\mid \\text{null}\\}\n$$\n这个量是使用相应分布的生存函数（SF）计算的，其中 $\\mathrm{SF}(k) = \\Pr\\{X' > k\\}$。因此，$\\Pr\\{X' \\ge X\\} = \\mathrm{SF}(X-1)$。\n需要计算的三个p值是：\n1.  $p_{\\mathrm{global\\_Poisson}} = \\Pr\\{X' \\ge X \\mid X' \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{global}})\\}$\n2.  $p_{\\mathrm{local\\_Poisson}} = \\Pr\\{X' \\ge X \\mid X' \\sim \\mathrm{Poisson}(\\lambda_{\\mathrm{local}})\\}$\n3.  $p_{\\mathrm{local\\_NB}} = \\Pr\\{X' \\ge X \\mid X' \\sim \\mathrm{NB}(r=1/\\phi, p=r/(r+\\lambda_{\\mathrm{local}}))\\}$\n\n以下程序为指定的测试用例实现了这一逻辑。它计算缩放因子、全局和局部背景率，然后使用 `scipy.stats` 库中的生存函数计算三个p值。结果按照问题说明进行格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson, nbinom\n\ndef solve():\n    \"\"\"\n    Calculates p-values for ChIP-seq enrichment under three different null models.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: (N_ChIP, N_Ctrl, G, L, W, C_loc, X, phi)\n    test_cases = [\n        (2e7, 1.5e7, 3e9, 500, 10000, 60, 12, 0.2),\n        (1.2e7, 8e6, 3e9, 1000, 10000, 0, 5, 0.3),\n        (2e7, 2e7, 3e9, 200, 5000, 300, 20, 0.1),\n        (1.5e7, 1.2e7, 3e9, 400, 8000, 40, 8, 0.5),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N_ChIP, N_Ctrl, G, L, W, C_loc, X, phi = case\n\n        # Calculate library scaling factor\n        if N_Ctrl == 0:\n            # Avoid division by zero, though not present in test cases.\n            # In a real scenario, a non-zero pseudocount or different logic would be needed.\n            s = 1.0 \n        else:\n            s = N_ChIP / N_Ctrl\n\n        # Calculate global background rate\n        lambda_global = (N_ChIP / G) * L\n\n        # Calculate local background rate\n        lambda_local_raw = s * C_loc * (L / W)\n        lambda_local = max(lambda_local_raw, lambda_global)\n\n        # --- Compute p-values for the three null models ---\n        \n        # 1. Global Poisson null: X ~ Poisson(lambda_global)\n        # p-value is P(X' >= X) = 1 - CDF(X-1) = SF(X-1)\n        p_global_poisson = poisson.sf(X - 1, lambda_global)\n        \n        # 2. Local Poisson null: X ~ Poisson(lambda_local)\n        p_local_poisson = poisson.sf(X - 1, lambda_local)\n        \n        # 3. Overdispersed local null (Negative Binomial)\n        # The problem statement ensures phi > 0 for all test cases.\n        # If phi were 0, the NB model would reduce to the local Poisson model.\n        if phi > 0:\n            mu = lambda_local\n            r = 1.0 / phi\n            # Scipy's nbinom uses parameter p = probability of success.\n            # Mean is mu = n * (1-p) / p, where n is our r.\n            # Solving for p: p = n / (n + mu)\n            # This matches the problem's definition: p = r / (r + mu).\n            p = r / (r + mu)\n            \n            p_local_nb = nbinom.sf(X - 1, n=r, p=p)\n        else:\n            # Fallback to local Poisson if no overdispersion.\n            p_local_nb = p_local_poisson\n            \n        all_results.append([p_global_poisson, p_local_poisson, p_local_nb])\n\n    # Format the final output string exactly as specified.\n    # E.g., [[val1,val2,val3],[val4,val5,val6]] with no spaces.\n    inner_strings = []\n    for res_list in all_results:\n        rounded_res = [f\"{p:.6f}\" for p in res_list]\n        inner_str = f\"[{','.join(rounded_res)}]\"\n        inner_strings.append(inner_str)\n    \n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2796499"}]}