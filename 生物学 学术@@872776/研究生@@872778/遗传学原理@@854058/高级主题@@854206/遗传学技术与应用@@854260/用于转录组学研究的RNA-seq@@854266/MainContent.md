## 引言
[RNA测序](@entry_id:178187)（RNA-sequencing, RNA-seq）已经成为现代生物学研究中不可或缺的基石技术。它通过对细胞内全部或特定RNA群体进行高通量测序，为我们提供了一个关于基因表达活动的全面快照——即[转录组](@entry_id:274025)。理解[转录组](@entry_id:274025)的构成、动态变化及其调控机制，对于揭示从基础细胞生物学到[复杂疾病](@entry_id:261077)发生等一系列生命过程的分子基础至关重要。然而，从原始测序读数到可靠的生物学结论，需要跨越实验设计、生物信息学分析和[统计建模](@entry_id:272466)等多个环节的重重挑战。本文旨在系统性地解构[RNA-seq](@entry_id:140811)技术，帮助读者建立一个从第一性原理出发的坚实知识框架。

本文分为三个核心章节，旨在引导读者逐步深入。在“原理与机制”一章中，我们将从基本的数学模型出发，揭示测序读数与分子丰度之间的关系，并详细探讨实验设计中的关键决策如何影响数据构成，以及如何通过先进的计算方法准确地量化基因表达。随后，在“应用与交叉学科联系”一章中，我们将展示RNA-seq在解析转录本复杂性、研究[演化适应](@entry_id:151186)、推断细胞动态以及与蛋白质组学等[多组学数据整合](@entry_id:164615)中的强大威力。最后，“动手实践”部分将提供一系列精心设计的问题，将理论知识应用于解决实际的分析挑战。通过这一系列的学习，读者将能够全面掌握[RNA-seq](@entry_id:140811)的核心思想，并有能力批判性地评估和应用这一强大的研究工具。

## 原理与机制

本章旨在深入探讨转录组[RNA测序](@entry_id:178187)（[RNA-seq](@entry_id:140811)）技术背后的核心原理与关键机制。我们将从实验设计的基础选择开始，逐步深入到数据生成的数学模型，再到计算分析的统计框架。我们的目标是建立一个严谨的、从第一性原理出发的知识体系，使读者不仅知其然，更知其所以然。

### [RNA测序](@entry_id:178187)的基本定量原理：从分子到读数

[RNA测序](@entry_id:178187)的核心目标是量化细胞内每种RNA转录本的丰度。然而，测序仪本身并不直接“计数”RNA分子。相反，它对从RNA群体中随机抽样的互补DNA（cDNA）片段进行测序。理解这一抽样过程的性质，是准确解释[RNA-seq](@entry_id:140811)数据的基石。

让我们构建一个理想化的数学模型来阐明这一过程[@problem_id:2848905]。假设一个转录组包含 $G$ 个基因，基因 $g$ 在样本中有 $M_g$ 个转录本分子，其转录本长度为 $L_g$ 个[核苷酸](@entry_id:275639)。在文库制备过程中，这些转录本被随机打断成片段。一个长度为 $r$ 的测序读数（read）可以从一个长度为 $L_g$ 的转录本上的任何一个起始位置产生。对于一个给定的转录本分子，可能的读数起始位点数量为 $\ell_g = L_g - r + 1$。这个 $\ell_g$ 被称为转录本的**[有效长度](@entry_id:184361)**。

在理想情况下（即无偏的分子捕获和随机断裂），一个转录本产生的潜在片段数量与其分子数 $M_g$ 和其[有效长度](@entry_id:184361) $\ell_g$ 的乘积成正比。因此，在整个[cDNA文库](@entry_id:262174)中，源自基因 $g$ 的片段所占的比例，也就是任意一个[随机抽样](@entry_id:175193)的读数来自基因 $g$ 的概率 $p_g$，可以表示为：

$$
p_g = \frac{M_g \ell_g}{\sum_{h=1}^G M_h \ell_h}
$$

如果一个实验总共生成了 $N$ 个读数，那么每个读数都可以被看作是一次独立的分类抽样，其结果为 $G$ 个基因之一。因此，观测到的各个基因的读数向量 $X = (X_1, \dots, X_G)$ 服从一个**[多项分布](@entry_id:189072)**（multinomial distribution），其参数为试验总数 $N$ 和[概率向量](@entry_id:200434) $(p_1, \dots, p_G)$。根据[多项分布](@entry_id:189072)的性质，基因 $g$ 的期望读数计数 $\mathbb{E}[X_g]$ 为：

$$
\mathbb{E}[X_g | N] = N \cdot p_g = N \frac{M_g \ell_g}{\sum_{h=1}^G M_h \ell_h}
$$

这个公式揭示了一个至关重要的原理：**观测到的读数计数不仅与分子的真实丰度（$M_g$）成正比，还与其转录本的[有效长度](@entry_id:184361)（$\ell_g$）成正比**。这意味着，即使两个基因的分子丰度完全相同，较长的基因也会因为提供了更多的“靶标”而产生更多的测序读数。这一固有的[长度偏倚](@entry_id:269579)（length bias）是所有后续[数据标准化](@entry_id:147200)的根本原因。

### 实验设计：文库制备中的关键选择

在进入测序环节之前，研究者必须做出几个关键的实验设计决策，这些决策将深刻影响最终数据的构成和可解释性。

#### RNA富集策略：Poly(A)筛选 vs. rRNA去除

细胞总RNA中，约80-90%是核糖体RNA（rRNA），它们通常不是研究的重点。因此，必须先富集[信息量](@entry_id:272315)更丰富的RNA。两种主流策略是**Poly(A)筛选**和**rRNA去除**[@problem_id:2848907]。

**Poly(A)筛选**利用大多数真核生物成熟信使RNA（mRNA）在3'末端具有聚[腺苷](@entry_id:186491)酸尾巴（poly(A) tail）的特性。通过使用固定的寡[核苷酸](@entry_id:275639)（oligo-dT）探针，可以特异性地捕获这些带尾巴的RNA分子。这种方法的优点是能高效富集成熟的、即将用于[蛋白质翻译](@entry_id:203248)的mRNA。然而，它的局限性也很明显：它会丢弃所有不含[poly(A)尾](@entry_id:274750)巴的RNA类别，例如复制依赖的组蛋白mRNA、一部分[长链非编码RNA](@entry_id:180617)（[lncRNA](@entry_id:194588)）、以及所有[环状RNA](@entry_id:173494)（[circRNA](@entry_id:191128)）。此外，该方法对RNA的完整性非常敏感。对于降解严重的样本（如福尔马林固定石蜡包埋，即FFPE样本），RNA分子可能在3'末端之前断裂，导致[poly(A)尾](@entry_id:274750)巴丢失，从而无法被捕获。这会在降解样本中引入强烈的**3'末端覆盖偏倚**，即读数不成比例地集中在基因的3'区域。

**rRNA去除**则是一种负向选择策略。它使用与rRNA序列互补的探针来特异性地结合并去除rRNA分子，而保留文库中所有其他类型的RNA。这种方法能够提供一个更全面的转录组视图，因为它同时保留了带[poly(A)尾](@entry_id:274750)巴和不带[poly(A)尾](@entry_id:274750)巴的转录本，包括[前体mRNA](@entry_id:137517)（pre-mRNA，含有[内含子](@entry_id:144362)）、[lncRNA](@entry_id:194588)和[circRNA](@entry_id:191128)。由于它不依赖于转录本的完整性或3'末端的特定结构，rRNA去除法对**RNA降解的耐受性远高于Poly(A)筛选**，因此是处理FFPE等珍贵但质量不佳样本的首选方法。其缺点在于，rRNA的去除可能不完全，导致测[序数](@entry_id:150084)据中仍有一定比例的rRNA读数残留。

#### 保留链特异性信息

转录可以从DNA双链中的任何一条链上发生，产生正义（sense）和反义（antisense）转录本。在标准文库制备流程中，RNA被[逆转录](@entry_id:141572)成双链cDNA，这个过程会丢失原始RNA的链来源信息。为了区分正义和反义转录，需要采用**链特异性RNA-seq**（strand-specific [RNA-seq](@entry_id:140811)）方案[@problem_id:2848941]。

目前主要有两种链特异性建库方法：

1.  **dUTP法**：该方法通过化学标记来区分cDNA的两条链。在第一条cDNA[链合成](@entry_id:153427)之后，合成第二条链时使用脱氧尿苷三磷酸（dUTP）代替脱氧胸苷三磷酸（dTTP）。这导致第二条链含有尿嘧啶（U）而非[胸腺](@entry_id:182637)嘧啶（T）。在后续的PCR扩增前，使用[尿嘧啶-DNA糖基化酶](@entry_id:175297)（UDG）特异性地切除第二条链上的尿嘧啶，从而使其降解或无法作为模板。因此，只有第一条cDNA链被扩增和测序。由于第一条cDNA链与原始RNA模板是互补的，通过将测序读数比对到基因组，就可以推断出原始RNA的链方向。一个关键点是，如果后续PCR扩增使用的DNA聚合酶能够耐受并扩增含U的模板，链特异性就会被破坏，导致两种cDNA链都被测序[@problem_id:2848941]。

2.  **连接法**：该方法通过物理标记RNA片段的两端来保留方向性。它利用[连接酶](@entry_id:139297)对特定末端化学结构（3'羟基和5'磷酸）的依赖性，将两种不同的接头（Adapter）分别定向连接到RNA片段的5'端和3'端。经过逆转录和扩增后，测序读数会包含片段序列以及两端的接头序列。通过识别读数两端是哪种接头，就可以明确推断出原始RNA片段的5'→3'方向。

#### 校正扩增偏倚：[唯一分子标识符](@entry_id:192673)（UMI）

PCR扩增是[RNA-seq](@entry_id:140811)文库制备中不可或缺的一步，但它会引入严重的偏倚：不同的cDNA分子会被不等地扩增，导致测序读数的数量不再能准确反映原始分子的数量。**[唯一分子标识符](@entry_id:192673)**（Unique Molecular Identifiers, UMI）是一种巧妙的解决方案[@problem_id:2848917]。

UMI是一段短的（例如6-10个碱基）随机寡[核苷酸](@entry_id:275639)序列。在[逆转录](@entry_id:141572)过程中，即在任何PCR扩增**之前**，每个cDNA分子都会被随机标记上一个UMI。这样，源自同一个原始cDNA分子的所有PCR扩增产物都会带有相同的UMI标签。在数据分析时，可以将具有相同UMI和相同基因来源的读数进行“去重”（deduplication），将它们全部折叠成一个计数。这样，我们计数的就不再是测序读数，而是带有独特UMI的分子数，从而得到了对原始分子数的更准确估计。

然而，这里存在一个统计学上的挑战：**UMI碰撞**。如果UMI的种类（例如，长度为8的UMI有 $N = 4^8 = 65,536$ 种）相对于一个基因的分子数（$M$）不是足够大，那么两个或多个不同的原始分子有可能被随机标记上相同的UMI。直接计算独特UMI的数量（$U$）会因此低估真实的分子数 $M$。这个问题可以被建模为一个经典的“占有率问题”（occupancy problem）。一个近似无偏的估计量可以通过以下公式给出，它校正了UMI碰撞的影响：

$$
\widehat{M} \approx -N \ln\left(1 - \frac{U}{N}\right)
$$

例如，在一个单细胞中，某基因测得 $U = 600$ 个独特UMI，UMI长度为 $L=8$（$N=65,536$），校正后的原始分子数估计为 $\widehat{M} \approx -65,536 \ln(1 - 600/65,536) \approx 603$ 个。这个细微的校正对于精确的单细胞定量至关重要[@problem_id:2848917]。

### 从原始数据到比对读数：比[对流](@entry_id:141806)程

测序仪产生大量的短读数后，下一步是将它们与[参考基因组](@entry_id:269221)或[转录组](@entry_id:274025)进行比对，以确定它们的来源。

#### 单端测序 vs. [双端测序](@entry_id:272784)

**单端测序**（Single-End, SE）为每个cDNA片段生成一个读数，而**[双端测序](@entry_id:272784)**（Paired-End, PE）则从每个片段的两端各生成一个读数。在固定的预算下，SE测序可以对更多的独立片段进行取样，这对于简单的基因水平[差异表达分析](@entry_id:266370)可能更有统计功效。然而，PE测序为每个片段提供了更丰富的信息，其优势体现在多个方面[@problem_id:2848911]：

*   **[剪接](@entry_id:181943)事件和异构体鉴定**：PE读数对（mate-pair）之间的距离和方向是已知的（由片段长度[分布](@entry_id:182848)决定）。这一信息对于解析复杂的[剪接](@entry_id:181943)模式至关重要。例如，如果一对读数分别比对到两个不相邻的外显子上，并且它们之间的基因组距离与片段长度一致，这就为连接这两个外显子的[剪接](@entry_id:181943)事件提供了强有力的证据。这对于区分共享大部分[外显子](@entry_id:144480)的不同转录本异构体（isoform）尤其重要。
*   **提高比对唯一性**：在基因组的重复区域或[旁系同源基因](@entry_id:263736)家族中，一个SE读数可能可以比对到多个位置。但是，它的配对读数可能恰好落在一个独特区域。要求整个读数对以正确的距离和方向进行比对，可以大大减少比对的模糊性，将片段唯一地锚定到其真实来源[@problem_id:2848911]。
*   **从头转录组组装和基因融合检测**：在没有参考基因组的情况下，PE读数提供的连接信息对于将短的[重叠群](@entry_id:177271)（contig）组装成更长的转录本（scaffolding）是不可或缺的。在基因融合检测中，PE读数对的“异常”比对（例如，比对到不同[染色体](@entry_id:276543)或距离过远）是检测到[染色体重排](@entry_id:268124)事件的有力证据。

#### [剪接比对](@entry_id:196404)

由于真核基因含有内含子，成熟mRNA是由不连续的[外显子](@entry_id:144480)拼接而成。因此，源自跨越两个[外显子](@entry_id:144480)连接处的读数无法连续地比对到基因组上。**[剪接比对](@entry_id:196404)**（spliced alignment）算法就是为此设计的[@problem_id:2848881]。

这类算法通常采用“**种子-延伸**”（seed-and-extend）策略。首先，将读数的一个短的[子序列](@entry_id:147702)（种子，seed）在基因组中进行快速的精确匹配。然后，从这个种子出发，向两端延伸比对。当延伸遇到错配时，算法会暂停，并尝试在下游基因组区域寻找另一个可以与读数剩余部分匹配的锚点。如果找到了这样一个锚点，就形成了一个跨越内含子的[剪接比对](@entry_id:196404)。

为了确保比对的可靠性并控制计算的复杂性，[剪接比对](@entry_id:196404)器会使用几个关键参数：
*   **最小锚定长度（minimum anchor length, $a_{\min}$）**：要求[剪接](@entry_id:181943)点两侧的外显子上都至少有 $a_{\min}$ 个碱基的匹配。例如，一个[剪接](@entry_id:181943)点一侧只有8个碱基匹配，而要求的 $a_{\min}$ 是9，那么即使另一侧有很长的匹配，该比对也会被拒绝[@problem_id:2848881]。
*   **最大[内含子](@entry_id:144362)长度（maximum intron length, $L_{\max}$）**：限制了寻找下游锚点的搜索范围。设置一个合理的 $L_{\max}$（如50万个碱基）可以避免在基因组中进行无休止的搜索，并减少由随机匹配导致的假阳性[剪接](@entry_id:181943)。然而，这也意味着任何长度超过 $L_{\max}$ 的真实内含子都将无法被检测到。因此，调整 $L_{\max}$ 是在检测长内含子的灵敏度与控制[假阳性率](@entry_id:636147)之间的权衡[@problem_id:2848881]。
*   **[剪接](@entry_id:181943)位点基序**：绝大多数真核[内含子](@entry_id:144362)的两端都有保守的二[核苷酸](@entry_id:275639)基序，最常见的是5'端的GT和3'端的AG（“GT-AG”规则）。比对算法会利用这一生物学先验知识，对符合这些**经典[剪接](@entry_id:181943)基序**的[剪接](@entry_id:181943)事件给予更高的评分，但通常不会完全拒绝非经典基序（如GC-AG），因为它们也少量存在并具有生物学功能。

### 现代定量方法：绕过全比对

传统的[RNA-seq分析](@entry_id:173715)流程依赖于耗时的碱基级别的比对。近年来，涌现出一些创新的“轻量级”方法，它们在保持高精度的同时，极大地提升了定量分析的速度。

#### 伪比对与等价类

像Kallisto和Salmon这样的工具，其核心思想是：**为了定量，我们不需要知道每个读数的确切比对位置，只需要知道它可能来自哪些转录本**。这些工具引入了**伪比对**（pseudoalignment）和**[等价类](@entry_id:156032)**（equivalence classes）的概念[@problem_id:2848943]。

伪比对通过一种基于 **[k-mer](@entry_id:166084)**（长度为k的短[核苷酸](@entry_id:275639)序列）的哈希索引来实现。首先，为所有已知的转录本序列建立一个索引，该索引记录了每个[k-mer](@entry_id:166084)出现在哪些转录本中。然后，对于一个给定的测序读数，算法不是进行传统的比对，而是查找该读数中所有[k-mer](@entry_id:166084)。通过取这些[k-mer](@entry_id:166084)所属转录本集合的交集，可以快速确定这个读数与哪些转录本**兼容**。

**[等价类](@entry_id:156032)**是对所有读数进行的一种划分。如果两个读数与完全相同的转录本[子集](@entry_id:261956)兼容，它们就被归入同一个等价类。例如，一个等价类可能包含所有只与转录本A兼容的读数，另一个等价类可能包含所有与转录本B和C都兼容（但与其他转录本不兼容）的读数。

这种方法的关键统计学洞见在于，对于一个定义好的[生成模型](@entry_id:177561)，**所有用于估计转录本丰度的信息都包含在这些等价类的计数中**。[等价类](@entry_id:156032)计数是估计丰度参数的**充分统计量**[@problem_id:2848943]。这意味着，我们可以完全跳过耗时的碱基级别比对，只需计算每个[等价类](@entry_id:156032)中有多少读数，就可以进行后续的丰度估计。为了进一步提高准确性，这些工具还会采用一些高级策略，例如在索引中加入“**诱饵序列**”（decoy sequences，如整个基因组序列），以吸附那些可能源自未注释基因或重复序列的读数，防止它们被错误地分配到已知的转录本上，从而提高定量精度[@problem_id:2848943]。

#### 解决模糊性：[期望最大化](@entry_id:273892)（EM）算法

无论是传统比对还是伪比对，都会遇到读数可以映射到多个转录本（即“多重映射”或“模糊”读数）的问题。解决这一问题的标准方法是使用**[期望最大化](@entry_id:273892)（Expectation-Maximization, EM）算法**[@problem_id:2848909]。

[EM算法](@entry_id:274778)是一个迭代过程，包含两个步骤：
1.  **E-步（期望步）**：在这一步，算法根据当前对各转录本丰度的估计值，为每个模糊读数计算一个“责任分配”。具体来说，它会计算该读数来自其每一个兼容转录本的[后验概率](@entry_id:153467)。这个概率与转录本的当前丰度估计值和其[有效长度](@entry_id:184361)成正比。例如，如果一个读数与两个转录本A和B兼容，而当前估计A的丰度是B的两倍（长度相同时），那么该读数大约有2/3的概率被认为来自A，1/3的概率来自B。

2.  **M-步（最大化步）**：在这一步，算法利用E-步中计算出的概率性分配来更新丰度估计。每个转录本的新丰度被计算为它所“负责”的所有读数的总和（包括来自唯一映射读数的全部“选票”和来自模糊读数的部分“选票”）。

这个过程反复迭代，直到丰度估计值收敛。[EM算法](@entry_id:274778)提供了一个严谨的概率框架，能够将模糊不清的多重映射读数的信息有效地整合到最终的定量结果中。[@problem_id:2848909]

### 从计数到结论：标准化与[统计建模](@entry_id:272466)

获得了每个转录本的（原始或估计的）读数计数后，我们还需经过[标准化](@entry_id:637219)和统计检验，才能得出可靠的生物学结论。

#### [标准化](@entry_id:637219)单位：CPM、FPKM与[TPM](@entry_id:170576)

原始读数计数同时受到[测序深度](@entry_id:178191)（文库总大小）和转录本长度的影响。为了进行有意义的比较，必须对其进行标准化[@problem_id:2848938]。

*   **CPM (Counts Per Million)**：每百万读数中的计数。CPM仅对[测序深度](@entry_id:178191)进行了标准化，计算方法为 `(基因的读数 / 文库总读数) * 1,000,000`。它没有校正转录本[长度偏倚](@entry_id:269579)，因此**不适合比较同一个样本内不同基因的表达水平**。

*   **FPKM (Fragments Per Kilobase of transcript per Million mapped reads)**：每千碱基转录本每百万映射读数中的片段数。FPKM试图同时对[测序深度](@entry_id:178191)和转录本长度进行[标准化](@entry_id:637219)。然而，由于其标准化的顺序，FPKM值在不同样本间的比较存在问题。一个样本中总FPKM值的和不是固定的，这使得一个样本中高表达基因的变化会影响到所有其他基因的FPKM值，导致跨样本比较的偏差。

*   **[TPM](@entry_id:170576) (Transcripts Per Million)**：每百万转录本中的转录本数。TPM被认为是目前最优秀的[标准化](@entry_id:637219)单位。它首先通过除以基因长度来校正[长度偏倚](@entry_id:269579)，得到一个与真实分子丰度成比例的量。然后，再对这些长度校正后的值进行缩放，使得每个样本中所有[TPM](@entry_id:170576)值的总和都相同（通常为1,000,000）。这种标准化方式确保了**TPM值既可以在样本内比较不同基因的相对丰度，也可以在样本间比较同一个基因的相对丰度**，具有最好的可解释性。

#### 重复的重要性：生物学重复 vs. 技术重复

在设计[差异表达](@entry_id:748396)实验时，一个至关重要的概念是**生物学重复**与**技术重复**的区别[@problem_id:2848903]。

*   **生物学重复**指的是来自不同生物个体的[独立样本](@entry_id:177139)（例如，不同的病人、不同的小鼠或独立培养的细胞皿）。这些重复捕获了群体中由于遗传、环境和随机因素造成的真实**生物学变异**。
*   **技术重复**指的是对同一个生物样本（例如，同一个RNA提取物或同一个文库）进行多次重复的测量。这些重复主要用于评估**技术噪音**，即由文库制备和测序过程引入的变异。

对于[差异表达分析](@entry_id:266370)而言，其推断的目标是**群体水平**的差异，因此**生物学重复是必不可少的**。假设一个基因的表达水平可以被一个[分层模型](@entry_id:274952)描述，其总[方差](@entry_id:200758)由生物学[方差](@entry_id:200758) $\sigma_{\text{bio}}^{2}$ 和技术[方差](@entry_id:200758) $\sigma_{\text{tech}}^{2}$ 构成。那么，我们估计的组间差异的[方差](@entry_id:200758)将大致具有以下形式：

$$
\mathbb{V}\mathrm{ar}(\widehat{\Delta}_g) = \sigma_{g,\mathrm{bio}}^{2} \left(\frac{1}{n_{\mathrm{A}}} + \frac{1}{n_{\mathrm{B}}}\right) + \sigma_{g,\mathrm{tech}}^{2} \left(\frac{1}{n_{\mathrm{A}} t_{\mathrm{A}}} + \frac{1}{n_{\mathrm{B}} t_{\mathrm{B}}}\right)
$$

其中 $n$ 是生物学重复数， $t$ 是技术重复数。从该式可以看出，增加技术重复数 $t$ 只能减小技术[方差](@entry_id:200758)的贡献，而无法减小由生物学重复数 $n$ 决定的生物学[方差](@entry_id:200758)的贡献。在现代测序技术中，技术[方差](@entry_id:200758)通常远小于生物学[方差](@entry_id:200758)。因此，增加生物学重复数是提高统计功效的唯一有效途径。将技术重复误认为生物学重复是一种被称为“**[伪重复](@entry_id:176246)**”（pseudoreplication）的严重统计错误，它会导致标准误的严重低估和假阳性结果的泛滥。

#### [差异表达](@entry_id:748396)的计数模型

[RNA-seq](@entry_id:140811)的读数计数是离散的非负整数。一个简单的模型是[泊松分布](@entry_id:147769)，其特点是[方差](@entry_id:200758)等于均值。然而，由于生物学重复之间存在真实的表达水平波动，RNA-seq数据的[方差](@entry_id:200758)通常远大于其均值，这种现象被称为**过离散**（overdispersion）。

为了处理过离散问题，[差异表达分析](@entry_id:266370)工具（如[DESeq2](@entry_id:167268)和edgeR）普遍采用**负二项分布**（Negative Binomial, NB）模型[@problem_id:2848919]。负二项分布可以看作是泊松分布和一个伽马[分布](@entry_id:182848)的混合，它比泊松分布多一个**[离散度](@entry_id:168823)参数**（dispersion parameter），记为 $\alpha$。在该模型下，一个基因的计数的均值 $\mu$ 与[方差](@entry_id:200758) $\mathrm{Var}(K)$ 的关系为：

$$
\mathrm{Var}(K) = \mu + \alpha \mu^2
$$

这个关系式直观地捕捉了[RNA-seq](@entry_id:140811)数据的[方差](@entry_id:200758)结构：[方差](@entry_id:200758)由两部分构成，一部分是与均值相等的**泊松噪音**（$\mu$，或称散粒噪音），另一部分是随均值的平方增长的**生物学变异**（$\alpha \mu^2$）。[离散度](@entry_id:168823)参数 $\alpha$ 越大，说明该基因在生物学重复间的表达波动越大。由于每个基因的重复样本数通常很少（例如每组3-5个），直接估计每个基因的 $\alpha$ 是不稳定的。因此，这些工具会采用[经验贝叶斯方法](@entry_id:169803)，在所有基因间“共享信息”，将每个基因的[离散度](@entry_id:168823)估计向一个全局的均值-[离散度](@entry_id:168823)趋势进行“压缩”（shrinkage），从而获得更稳健的[方差估计](@entry_id:268607)。

### 前沿与背景：整体测序 vs. [单细胞测序](@entry_id:198847)

最后，我们将RNA-seq技术置于现代生物学研究的更广阔背景中，特别是与**[单细胞RNA测序](@entry_id:142269)**（single-cell [RNA-seq](@entry_id:140811), scRNA-seq）进行对比[@problem_id:2848956]。

传统的[RNA-seq](@entry_id:140811)被称为**整体[RNA测序](@entry_id:178187)**（bulk RNA-seq），因为它测量的是组织或细胞群体中所有细胞表达水平的**平均值**。这种平均化处理对于研究均匀的细胞群体或寻找在所有细胞中都存在的普遍效应是有效且强大的。然而，当组织是异质的（包含多种细胞类型）时，bulk RNA-seq会掩盖重要的细胞类型特异性信息。例如，如果一个遗传变异只影响一个占组织10%的少数细胞亚群的基因表达，那么在bulk数据中，这个真实的生物学信号将被稀释10倍，变得极难检测。

**[scRNA-seq](@entry_id:155798)**通过为每个细胞独立生成表达谱，克服了[信号平均](@entry_id:270779)化的问题。它能够以前所未有的分辨率揭示细胞间的[异质性](@entry_id:275678)，识别稀有细胞类型，并检测细胞类型特异的基因调控效应。然而，[scRNA-seq](@entry_id:155798)也面临其独特的挑战：
*   **灵敏度较低**：由于起始RNA量极低，单个细胞中的许多低表达转录本可能根本没有被捕获到，导致数据中出现大量的零值，这种现象被称为“**dropout**”。
*   **技术噪音更高**：单细胞级别的随机捕获、[逆转录](@entry_id:141572)效率和扩增偏倚等因素，使得技术噪音在scRNA-seq中比在bulk [RNA-seq](@entry_id:140811)中更为显著。

因此，选择哪种技术取决于具体的科学问题。如果研究目标是组织或群体的平均表达水平，或者组织是相对同质的，那么bulk RNA-seq因其高灵敏度和稳定性而成为首选。然而，如果研究的核心在于[细胞异质性](@entry_id:262569)、稀有细胞亚群或细胞类型特异性的调控事件，那么[scRNA-seq](@entry_id:155798)尽管技术挑战更大，却是唯一能够提供所需分辨率的工具。