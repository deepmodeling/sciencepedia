{"hands_on_practices": [{"introduction": "物种界定中的一个核心挑战是区分真正的不连续谱系和由地理隔离导致的连续遗传变异，即“按距离隔离”（Isolation-by-Distance, IBD）。本练习通过一个简化的“踏脚石”模型，要求你从第一性原理出发，推导IBD如何能够在基因型空间中制造出离散簇的假象。通过这个推导，你将深刻理解为何基于聚类的方法在面对空间连续种群时可能会失效，并认识到发展和应用更复杂模型的重要性。[@problem_id:2752715]", "problem": "距离隔离（Isolation-by-distance, IBD）是一种由于扩散受限而产生的种群遗传学后果，即个体间的遗传相似性随着地理距离的增加而降低。在一个空间结构化的种群中，这会在等位基因频率上产生正空间自相关，并表现出遗传协方差随距离衰减的典型特征。众所周知，这种渐变群结构会干扰那些假设存在离散随机交配单元的、基于聚类的物种界定方法。\n\n考虑一个一维踏脚石模型种群，它由 $K$ 个线性排列的亚群组成，这些亚群间距相等，有效种群大小也相等，且在中性演化下处于突变-漂变-迁移平衡状态。假设 $K$ 为偶数。设亚群位置由沿单位长度线段的索引 $j \\in \\{0,1,\\dots,K-1\\}$ 表示，因此空间步长为 $h = 1/(K-1)$。对于每个不连锁、选择中性的双等位基因座 $\\ell \\in \\{1,\\dots,L\\}$，将各亚群中等位基因频率与全局平均值的偏差建模为一个零均值平稳高斯过程 (GP)，其协方差函数为\n$$\nC(d) \\;=\\; \\sigma^{2} \\exp\\!\\left(-\\frac{d}{\\lambda}\\right),\n$$\n其中 $d$ 是地理距离，$\\sigma^{2}$ 是边缘方差，$\\lambda$ 是空间相关长度。假设所有基因座都是独立同分布的，且具有相同的协方差参数 $\\sigma^{2}$ 和 $\\lambda$。通过将每个亚群中的样本平均基因型视为其期望值，来忽略亚群内部的抽样噪音。\n\n你通过将亚群分为左右两半来人为地界定两个假定的“物种”：左组由亚群 $j=0,1,\\dots,\\frac{K}{2}-1$ 组成，右组由亚群 $j=\\frac{K}{2},\\dots,K-1$ 组成。在一个 $L$ 维基因型空间中，其第 $\\ell$ 个坐标是基因座 $\\ell$ 处样本平均等位基因频率的两倍。将两个组的质心定义为其各自亚群的组内平均值的 $L$ 维向量。\n\n从 IBD 的定义和上述踏脚石模型设定出发，推导出这两个质心之间期望欧几里得距离平方的闭式表达式，用 $K$、$L$、$\\sigma^{2}$ 和 $\\lambda$ 表示。你可以用 $M \\equiv K/2$ 来表示，并可以定义 $\\rho \\equiv \\exp\\!\\left(-\\frac{h}{\\lambda}\\right)$ 来简化你的表达式。你的最终答案必须是一个单一的闭式解析表达式。不要进行近似或四舍五入。", "solution": "用户希望我解决一个演化生物学领域的问题。我现在将开始验证，如果问题有效，则开始求解过程。\n\n### 步骤 1：提取已知条件\n-   种群模型：在中性演化下，处于突变-漂变-迁移平衡的一维踏脚石模型种群。\n-   亚群数量：$K$，一个偶数。\n-   亚群位置：沿单位长度线段由 $j \\in \\{0,1,\\dots,K-1\\}$ 索引。\n-   空间步长：$h = 1/(K-1)$。\n-   基因座数量：$L$，不连锁、选择中性、双等位基因。\n-   等位基因频率模型：在亚群 $j$ 的基因座 $\\ell$ 处，等位基因频率与全局平均值的偏差（此处记为 $y_j^{(\\ell)}$）是一个零均值平稳高斯过程。\n-   协方差函数：$C(d) = \\sigma^{2} \\exp(-d/\\lambda)$，其中 $d$ 是地理距离。\n-   基因座是独立同分布 (i.i.d.) 的，参数为 $\\sigma^2$ 和 $\\lambda$。\n-   抽样噪音：忽略；亚群中的样本平均基因型等于其期望。\n-   组的定义：\n    -   左组 ($G_L$)：亚群 $j=0,1,\\dots,\\frac{K}{2}-1$。\n    -   右组 ($G_R$)：亚群 $j=\\frac{K}{2},\\dots,K-1$。\n-   基因型空间：一个 $L$ 维空间，其中亚群 $j$ 的第 $\\ell$ 个坐标是 $g_j^{(\\ell)}$，其值为样本平均等位基因频率 $p_j^{(\\ell)}$ 的两倍。\n-   质心：$C_L$ 和 $C_R$ 是 $L$ 维向量，由各自组内亚群的 $g_j^{(\\ell)}$ 的组内平均值构成。\n-   任务：推导 $C_L$ 和 $C_R$ 之间期望欧几里得距离的平方。\n-   符号辅助：$M \\equiv K/2$，$\\rho \\equiv \\exp(-h/\\lambda)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准评估问题陈述。\n\n-   **科学性基础：** 问题使用了种群遗传学中一个标准且成熟的模型——用于距离隔离 (IBD) 的踏脚石模型。使用具有指数协方差函数的高斯过程来模拟等位基因频率的空间模式是此背景下一种常见且有效的近似方法。该设定在科学上是合理的。\n-   **定义明确：** 问题定义清晰。它明确了模型的所有必要组成部分，并要求推导一个特定量，即两个已定义点之间期望欧几里得距离的平方。存在唯一解，并且可以从前提中推导出来。\n-   **客观性：** 语言技术性强、精确且不含主观性。\n-   **自洽且一致：** 提供了所有必要的信息、变量和定义。没有内部矛盾。\n-   **可行性：** 该场景是一个理论构造，但它基于适用于真实生物种群的原理。\n-   **非平凡性：** 推导过程需要仔细应用统计学原理和级数求和，构成一个实质性的数学挑战。\n\n### 步骤 3：结论与行动\n问题有效。我将继续进行推导。\n\n设 $p_j^{(\\ell)}$ 为亚群 $j$ 中基因座 $\\ell$ 的样本平均等位基因频率。问题陈述基因型空间中的坐标为 $g_j^{(\\ell)} = 2p_j^{(\\ell)}$。\n设 $\\bar{p}^{(\\ell)}$ 为基因座 $\\ell$ 的全局平均等位基因频率。等位基因频率的偏差为 $y_j^{(\\ell)} = p_j^{(\\ell)} - \\bar{p}^{(\\ell)}$。根据定义，$\\mathbb{E}[y_j^{(\\ell)}] = 0$。\n协方差由 $\\mathbb{E}[y_i^{(\\ell)}y_j^{(\\ell')}] = \\delta_{\\ell\\ell'} C(d_{ij})$ 给出，其中 $\\delta_{\\ell\\ell'}$ 是克罗内克 delta（反映基因座的独立性），$d_{ij} = |i-j|h$ 是亚群 $i$ 和 $j$ 之间的地理距离。\n使用所提供的符号，对于单个基因座 $\\ell$，此协方差为 $\\mathbb{E}[y_i^{(\\ell)}y_j^{(\\ell)}] = \\sigma^2 \\exp(-|i-j|h/\\lambda) = \\sigma^2 \\rho^{|i-j|}$。\n\n两个组分别是左组 $G_L = \\{0, \\dots, M-1\\}$ 和右组 $G_R = \\{M, \\dots, 2M-1\\}$，其中 $M=K/2$。\n质心 $C_L$ 和 $C_R$ 是 $L$ 维向量。它们各自的第 $\\ell$ 个分量是：\n$$ (C_L)_{\\ell} = \\frac{1}{M} \\sum_{j=0}^{M-1} g_j^{(\\ell)} \\quad \\text{和} \\quad (C_R)_{\\ell} = \\frac{1}{M} \\sum_{j=M}^{2M-1} g_j^{(\\ell)} $$\n质心之间的欧几里得距离平方是 $D^2 = \\|C_R - C_L\\|^2 = \\sum_{\\ell=1}^L ((C_R)_{\\ell} - (C_L)_{\\ell})^2$。我们需要求其期望 $\\mathbb{E}[D^2]$。\n\n首先，考虑质心第 $\\ell$ 个分量的差：\n$$ (C_R)_{\\ell} - (C_L)_{\\ell} = \\frac{1}{M} \\sum_{j=M}^{2M-1} 2p_j^{(\\ell)} - \\frac{1}{M} \\sum_{j=0}^{M-1} 2p_j^{(\\ell)} $$\n代入 $p_j^{(\\ell)} = y_j^{(\\ell)} + \\bar{p}^{(\\ell)}$：\n$$ (C_R)_{\\ell} - (C_L)_{\\ell} = \\frac{2}{M} \\left( \\sum_{j=M}^{2M-1} (y_j^{(\\ell)} + \\bar{p}^{(\\ell)}) - \\sum_{j=0}^{M-1} (y_j^{(\\ell)} + \\bar{p}^{(\\ell)}) \\right) $$\n$$ = \\frac{2}{M} \\left( \\sum_{j=M}^{2M-1} y_j^{(\\ell)} - \\sum_{j=0}^{M-1} y_j^{(\\ell)} + M\\bar{p}^{(\\ell)} - M\\bar{p}^{(\\ell)} \\right) = \\frac{2}{M} \\left( \\sum_{j \\in G_R} y_j^{(\\ell)} - \\sum_{j \\in G_L} y_j^{(\\ell)} \\right) $$\n设 $\\Delta_{\\ell} = (C_R)_{\\ell} - (C_L)_{\\ell}$。由于 $\\mathbb{E}[y_j^{(\\ell)}]=0$，我们有 $\\mathbb{E}[\\Delta_{\\ell}] = 0$。\n期望距离平方为：\n$$ \\mathbb{E}[D^2] = \\mathbb{E}\\left[\\sum_{\\ell=1}^L \\Delta_{\\ell}^2\\right] = \\sum_{\\ell=1}^L \\mathbb{E}[\\Delta_{\\ell}^2] $$\n由于所有基因座都是独立同分布的，$\\mathbb{E}[\\Delta_{\\ell}^2]$ 对所有 $\\ell$ 都相同。因此，$\\mathbb{E}[D^2] = L \\mathbb{E}[\\Delta_1^2]$。\n让我们计算单个基因座的 $\\mathbb{E}[\\Delta_1^2]$（为清晰起见，省略上标 $\\ell=1$）：\n$$ \\mathbb{E}[\\Delta^2] = \\mathbb{E}\\left[ \\left( \\frac{2}{M} \\left( \\sum_{i \\in G_R} y_i - \\sum_{j \\in G_L} y_j \\right) \\right)^2 \\right] = \\frac{4}{M^2} \\text{Var}\\left( \\sum_{i \\in G_R} y_i - \\sum_{j \\in G_L} y_j \\right) $$\n方差展开为：\n$$ \\text{Var}\\left( \\sum_{i \\in G_R} y_i - \\sum_{j \\in G_L} y_j \\right) = \\text{Var}\\left(\\sum_{i \\in G_R} y_i\\right) + \\text{Var}\\left(\\sum_{j \\in G_L} y_j\\right) - 2\\text{Cov}\\left(\\sum_{i \\in G_R} y_i, \\sum_{j \\in G_L} y_j\\right) $$\n让我们计算每一项：\n$$ \\text{Var}\\left(\\sum_{j \\in G_L} y_j\\right) = \\sum_{j_1, j_2 \\in G_L} \\text{Cov}(y_{j_1}, y_{j_2}) = \\sigma^2 \\sum_{j_1=0}^{M-1} \\sum_{j_2=0}^{M-1} \\rho^{|j_1-j_2|} $$\n根据平稳性，右组的方差是相同的：\n$$ \\text{Var}\\left(\\sum_{i \\in G_R} y_i\\right) = \\text{Var}\\left(\\sum_{j \\in G_L} y_j\\right) $$\n我们将此和表示为 $A = \\sum_{j_1=0}^{M-1} \\sum_{j_2=0}^{M-1} \\rho^{|j_1-j_2|}$。\n协方差项为：\n$$ \\text{Cov}\\left(\\sum_{i \\in G_R} y_i, \\sum_{j \\in G_L} y_j\\right) = \\sum_{i \\in G_R} \\sum_{j \\in G_L} \\text{Cov}(y_i, y_j) = \\sigma^2 \\sum_{i=M}^{2M-1} \\sum_{j=0}^{M-1} \\rho^{|i-j|} $$\n由于 $i \\ge M$ 且 $j \\le M-1$，我们有 $i-j > 0$，所以 $|i-j|=i-j$。\n我们将此和表示为 $B = \\sum_{i=M}^{2M-1} \\sum_{j=0}^{M-1} \\rho^{i-j}$。\n\n综合起来：\n$$ \\mathbb{E}[D^2] = L \\cdot \\frac{4}{M^2} \\left( \\sigma^2 A + \\sigma^2 A - 2\\sigma^2 B \\right) = \\frac{8L\\sigma^2}{M^2}(A-B) $$\n\n现在我们必须计算和 $A$ 与 $B$。\n和 $A$ 可以通过考虑求和矩阵的对角线来计算：\n$A = \\sum_{k=-(M-1)}^{M-1} (M-|k|) \\rho^{|k|} = M + 2\\sum_{k=1}^{M-1}(M-k)\\rho^k$。\n使用几何级数公式 $\\sum_{k=1}^{N} r^k = \\frac{r(1-r^N)}{1-r}$ 和算术-几何级数公式 $\\sum_{k=1}^{N} kr^k = \\frac{r-(N+1)r^{N+1}+Nr^{N+2}}{(1-r)^2}$，我们得到：\n$$ A = \\frac{M(1+\\rho)}{1-\\rho} - \\frac{2\\rho(1-\\rho^M)}{(1-\\rho)^2} = \\frac{M(1-\\rho^2) - 2\\rho(1-\\rho^M)}{(1-\\rho)^2} $$\n和 $B$ 是两个几何级数的乘积：\n$$ B = \\left(\\sum_{i=M}^{2M-1} \\rho^i\\right) \\left(\\sum_{j=0}^{M-1} \\rho^{-j}\\right) = \\left(\\frac{\\rho^M(1-\\rho^M)}{1-\\rho}\\right) \\left(\\frac{1-(\\rho^{-1})^M}{1-\\rho^{-1}}\\right) $$\n$$ = \\frac{\\rho^M(1-\\rho^M)}{1-\\rho} \\cdot \\frac{1-\\rho^{-M}}{-\\rho^{-1}(1-\\rho)} = \\frac{\\rho^M(1-\\rho^M)}{1-\\rho} \\cdot \\frac{\\rho(1-\\rho^{-M})}{\\rho-1} = \\frac{\\rho(1-\\rho^M)^2}{(1-\\rho)^2} $$\n\n现在，我们计算差值 $A-B$：\n$$ A-B = \\frac{M(1-\\rho^2) - 2\\rho(1-\\rho^M)}{(1-\\rho)^2} - \\frac{\\rho(1-\\rho^M)^2}{(1-\\rho)^2} $$\n$$ = \\frac{M(1-\\rho^2) - \\rho(1-\\rho^M)[2 + (1-\\rho^M)]}{(1-\\rho)^2} $$\n$$ = \\frac{M(1-\\rho^2) - \\rho(1-\\rho^M)(3-\\rho^M)}{(1-\\rho)^2} $$\n展开分子：\n$ N = M(1-\\rho^2) - \\rho(3 - 4\\rho^M + \\rho^{2M}) = M - M\\rho^2 - 3\\rho + 4\\rho^{M+1} - \\rho^{2M+1} $。\n所以，\n$$ A-B = \\frac{M(1-\\rho^2) - 3\\rho + 4\\rho^{M+1} - \\rho^{2M+1}}{(1-\\rho)^2} $$\n最后，我们将其代入期望距离平方的表达式中：\n$$ \\mathbb{E}[D^2] = \\frac{8L\\sigma^2}{M^2}(A-B) = \\frac{8L\\sigma^2}{M^2(1-\\rho)^2} \\left( M(1-\\rho^2) - 3\\rho + 4\\rho^{M+1} - \\rho^{2M+1} \\right) $$\n这是最终的闭式表达式。", "answer": "$$ \\boxed{\\frac{8L\\sigma^2}{M^2(1-\\rho)^2} \\left( M(1-\\rho^2) - 3\\rho + 4\\rho^{M+1} - \\rho^{2M+1} \\right)} $$", "id": "2752715"}, {"introduction": "现代物种界定已经从单纯的模式识别转向了严格的统计模型比较，这在贝叶斯框架下尤为突出。本练习将让你亲手实践贝叶斯模型选择的核心工具——贝叶斯因子，用于在多物种溯祖模型下比较两种对立的界定假说（“合并”与“拆分”）。通过根据给定的边际似然值计算并解释贝叶斯因子，你将掌握一种量化数据对不同物种界定模型支持强度的方法，这是整合分类学中一项至关重要的定量技能。[@problem_id:2752783]", "problem": "在一个用于物种界定的多物种溯祖框架中，考虑了针对一个焦点分支的两个竞争模型：模型 $\\mathcal{M}_{A}$（合并两个候选谱系）和模型 $\\mathcal{M}_{B}$（将它们分裂）。使用通过踏脚石抽样的热力学积分，您获得了以下模型证据，以边际似然的自然对数形式报告：$\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A}) = -17890.432$ 和 $\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) = -17882.932$，其中 $\\mathcal{D}$ 表示多位点序列数据集。假设所有模型使用相同的先验和数据处理方法，因此这些值作为模型证据是直接可比的。\n\n使用边际似然和贝叶斯因子的基本定义，计算支持模型 $\\mathcal{M}_{B}$ 相对于模型 $\\mathcal{M}_{A}$ 的贝叶斯因子。然后，使用以下预先指定的标度（Kass–Raftery 风格，为直接贝叶斯因子 $\\mathrm{BF}$ 调整）解释支持 $\\mathcal{M}_{B}$ 的证据强度：\n\n- $1 \\le \\mathrm{BF}  3.2$：不值得一提，\n- $3.2 \\le \\mathrm{BF}  10$：实质性的，\n- $10 \\le \\mathrm{BF}  100$：强的，\n- $\\mathrm{BF} \\ge 100$：决定性的。\n\n将贝叶斯因子报告为一个纯数字，四舍五入到四位有效数字。不要包含任何单位。您可以在推理过程中提供解释，但最终报告的答案必须仅为贝叶斯因子值。", "solution": "对问题进行验证。\n\n**步骤1：提取已知条件**\n- 模型 $\\mathcal{M}_{A}$：合并两个候选谱系。\n- 模型 $\\mathcal{M}_{B}$：分裂两个候选谱系。\n- 模型 $\\mathcal{M}_{A}$ 的边际似然的自然对数：$\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A}) = -17890.432$。\n- 模型 $\\mathcal{M}_{B}$ 的边际似然的自然对数：$\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) = -17882.932$。\n- 数据集：$\\mathcal{D}$，一个多位点序列数据集。\n- 假设：边际似然是直接可比的。\n- 任务：计算支持模型 $\\mathcal{M}_{B}$ 相对于 $\\mathcal{M}_{A}$ 的贝叶斯因子 $\\mathrm{BF}$。\n- 任务：使用提供的标度解释证据强度。\n- 报告要求：报告 $\\mathrm{BF}$ 值，四舍五入到四位有效数字。\n- 解释标度：\n  - $1 \\le \\mathrm{BF}  3.2$：不值得一提。\n  - $3.2 \\le \\mathrm{BF}  10$：实质性的。\n  - $10 \\le \\mathrm{BF}  100$：强的。\n  - $\\mathrm{BF} \\ge 100$：决定性的。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它使用了贝叶斯模型选择的标准原理（贝叶斯因子、边际似然），并将其应用于演化生物学中的一个常见问题（使用多物种溯祖模型进行物种界定）。所提供的对数边际似然值对于基因组数据集来说处于一个合理的数量级。该问题设定良好、客观且完整，提供了所有必要信息和明确的目标。不存在矛盾、歧义或逻辑缺陷。\n\n**步骤3：结论与操作**\n该问题有效。将提供解答。\n\n在贝叶斯框架中，比较两个统计模型 $\\mathcal{M}_{A}$ 和 $\\mathcal{M}_{B}$ 的基本量是贝叶斯因子。贝叶斯因子，记为 $\\mathrm{BF}_{B,A}$，量化了数据 $\\mathcal{D}$ 支持模型 $\\mathcal{M}_{B}$ 超过模型 $\\mathcal{M}_{A}$ 的证据。它被定义为它们边际似然的比值：\n$$\n\\mathrm{BF}_{B,A} = \\frac{p(\\mathcal{D} \\mid \\mathcal{M}_{B})}{p(\\mathcal{D} \\mid \\mathcal{M}_{A})}\n$$\n边际似然 $p(\\mathcal{D} \\mid \\mathcal{M})$ 表示在给定模型 $\\mathcal{M}$ 的情况下观测到数据 $\\mathcal{D}$ 的概率，该概率是在模型的整个参数空间上积分得到的。在实践中，这些值通常非常小，因此使用它们的自然对数进行计算，正如问题陈述中所提供的那样。\n\n给定的是对数边际似然：\n$$\n\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A}) = -17890.432\n$$\n$$\n\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) = -17882.932\n$$\n为了从这些对数值计算贝叶斯因子，我们利用对数的性质，即一个比率的对数等于对数的差：\n$$\n\\ln(\\mathrm{BF}_{B,A}) = \\ln\\left(\\frac{p(\\mathcal{D} \\mid \\mathcal{M}_{B})}{p(\\mathcal{D} \\mid \\mathcal{M}_{A})}\\right) = \\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) - \\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A})\n$$\n这个量 $\\ln(\\mathrm{BF}_{B,A})$ 通常被称为对数贝叶斯因子。代入给定值：\n$$\n\\ln(\\mathrm{BF}_{B,A}) = -17882.932 - (-17890.432) = -17882.932 + 17890.432 = 7.500\n$$\n为了得到贝叶斯因子 $\\mathrm{BF}_{B,A}$ 本身，我们必须对对数贝叶斯因子取指数：\n$$\n\\mathrm{BF}_{B,A} = \\exp(\\ln(\\mathrm{BF}_{B,A})) = \\exp(7.500)\n$$\n计算该值：\n$$\n\\mathrm{BF}_{B,A} \\approx 1808.0424\n$$\n问题要求将此值四舍五入到四位有效数字。前四位有效数字是 $1$、$8$、$0$ 和 $8$。接下来的数字是 $0$，所以不进行进位。该值为 $1808$。\n\n最后一步是使用提供的标度解释这个结果。计算出的贝叶斯因子为 $\\mathrm{BF}_{B,A} = 1808$。由于 $1808 \\ge 100$，支持模型 $\\mathcal{M}_{B}$（分裂模型）相对于模型 $\\mathcal{M}_{A}$（合并模型）的证据被归类为“决定性的”。这表明有力地支持了两个候选谱系代表不同物种的假说。", "answer": "$$\\boxed{1808}$$", "id": "2752783"}, {"introduction": "除了遗传数据，形态学测量在物种界定中也扮演着关键角色，尤其是在整合分类学框架中。这项实践要求你通过编程实现线性判别分析（LDA），并结合留一法交叉验证（LOOCV）来评估基于形态测量数据的物种分类模型的性能与不确定性。这个练习不仅能加深你对多变量统计分类方法的理解，还能锻炼你通过代码解决实际生物学问题并对模型进行严格验证的关键能力。[@problem_id:2752812]", "problem": "您将执行一项基于形态计量学测量的物种界定任务。请按如下方式，纯粹用数学和统计学术语来描述此问题。假设每个假定物种对应一个类别标签，形态计量学测量表示为 $\\mathbb{R}^d$ 中的向量。假定在给定类别 $k \\in \\{1,\\dots,K\\}$ 的条件下，观测值 $\\mathbf{x} \\in \\mathbb{R}^d$ 服从一个多元正态分布 (MVN)，该分布具有类特定的均值 $\\boldsymbol{\\mu}_k \\in \\mathbb{R}^d$ 和一个独立于类的正定协方差矩阵 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$。假定类的先验概率为 $\\pi_k$，其中 $\\sum_{k=1}^K \\pi_k = 1$ 且 $\\pi_k \\in (0,1)$。\n\n基本假设和定义：\n- 生成模型下后验概率的贝叶斯法则：后验概率 $p(y=k \\mid \\mathbf{x})$ 与先验概率和类条件密度的乘积成正比，即 $p(y=k \\mid \\mathbf{x}) \\propto \\pi_k f_k(\\mathbf{x})$，其中 $f_k$ 是类别 $k$ 的 MVN 密度函数。\n- 最大后验分类将 $\\mathbf{x}$ 分配给使 $p(y=k \\mid \\mathbf{x})$ 最大化的类别。\n- 留一法交叉验证 (LOOCV) 通过对每个观测值 $i$ 使用除 $i$ 之外的所有观测值来拟合模型参数，然后用拟合的模型预测其类别，从而估计泛化性能。\n\n您的程序必须在 MVN-共享协方差假设下实现线性判别分析 (LDA)，并使用 LOOCV 来估计样本外性能和量化分类不确定性。对于每个留一法中的观测值 $i$，使用训练集（除 $i$ 之外的所有观测值）来估计：\n- 类别均值 $\\widehat{\\boldsymbol{\\mu}}_k$，作为类别 $k$ 内的经验均值。\n- 合并的类内协方差 $\\widehat{\\boldsymbol{\\Sigma}}$，其计算方法为类内散布之和除以训练自由度，并进行正则化处理 $\\widehat{\\boldsymbol{\\Sigma}} + \\lambda \\mathbf{I}_d$（其中 $\\lambda = 10^{-6}$）以确保数值稳定性。\n- 类别先验概率 $\\widehat{\\pi}_k$，作为训练集中的经验频率。\n\n然后，对于每个测量值为 $\\mathbf{x}_i$ 的留一法观测值 $i$，计算由 MVN 密度和经验先验概率导出的后验类别概率 $p(y=k \\mid \\mathbf{x}_i)$，并通过最大后验概率预测类别。收集以下信息：\n- 错分指示符（预测类别是否与真实类别匹配）。\n- 该观测值被分配到的类别的后验概率。\n- 后验熵 $H(\\mathbf{x}_i) = -\\sum_{k=1}^K p(y=k \\mid \\mathbf{x}_i)\\log p(y=k \\mid \\mathbf{x}_i)$，以自然单位 (nats) 计量。\n\n对所有观测值，计算：\n- 总体错分率 $\\hat{p}$，作为错分指示符的平均值。\n- 对应于错分概率的二项分布参数的 Wilson 得分置信区间，置信水平为 $0.95$，基于 $n$ 次独立伯努利试验和观测比例 $\\hat{p}$。\n- 在所有 LOOCV 折上平均的、所分配类别的平均后验概率。\n- 在所有 LOOCV 折上平均的、以 nats 为单位的平均后验熵。\n\n测试套件。您的程序必须使用以下三个合成测试用例来实现上述功能，每个用例由类别数 $K$、维度 $d$、公共类内协方差矩阵 $\\boldsymbol{\\Sigma}$、类别均值 $\\{\\boldsymbol{\\mu}_k\\}_{k=1}^K$、类别样本大小 $\\{n_k\\}_{k=1}^K$ 和一个固定的伪随机种子定义。对于每个用例，首先从 $\\mathcal{N}(\\boldsymbol{\\mu}_k,\\boldsymbol{\\Sigma})$ 为类别 $k$ 独立抽取 $n_k$ 个样本，然后执行指定的 LOOCV LDA。\n\n- 用例 A（理想情况，类别分离良好）：$K=2$，$d=2$，$\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1  0.3 \\\\ 0.3  1 \\end{bmatrix}$，$\\boldsymbol{\\mu}_1 = [0,0]$，$\\boldsymbol{\\mu}_2 = [3,3]$，$n_1 = 30$，$n_2 = 30$，种子 $= 7$。\n- 用例 B（边界条件，类别重叠）：$K=2$，$d=2$，$\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1  0.7 \\\\ 0.7  1 \\end{bmatrix}$，$\\boldsymbol{\\mu}_1 = [0,0]$，$\\boldsymbol{\\mu}_2 = [0.8,0.8]$，$n_1 = 40$，$n_2 = 40$，种子 $= 13$。\n- 用例 C（边缘情况，三个类别，小样本，中等分离）：$K=3$，$d=3$，$\\boldsymbol{\\Sigma} = 0.5 \\mathbf{I}_3$，$\\boldsymbol{\\mu}_1 = [0,0,0]$，$\\boldsymbol{\\mu}_2 = [2.5,0,2.5]$，$\\boldsymbol{\\mu}_3 = [0,2.5,2.5]$，$n_1 = 8$，$n_2 = 7$，$n_3 = 9$，种子 $= 101$。\n\n输出规格。对于每个用例，返回一个包含五个浮点值的列表：\n- 错分率 $\\hat{p}$。\n- $\\hat{p}$ 的 Wilson $0.95$ 置信区间的下界。\n- $\\hat{p}$ 的 Wilson $0.95$ 置信区间的上界。\n- 所分配类别的平均后验概率。\n- 以 nats 为单位的平均后验熵。\n\n将每个值四舍五入到恰好 $4$ 位小数。您的程序应生成单行输出，其中包含一个列表的列表形式的结果，不含空格，格式完全如下：\n$[[a_1,a_2,a_3,a_4,a_5],[b_1,b_2,b_3,b_4,b_5],[c_1,c_2,c_3,c_4,c_5]]$，\n其中每个 $a_j$、$b_j$ 和 $c_j$ 分别是用例 A、B 和 C 的四舍五入后的值。\n\n此问题不涉及物理单位。所有角度均不相关。置信水平必须表示为小数 $0.95$。", "solution": "该问题要求使用留一法交叉验证 (LOOCV) 来实现和评估线性判别分析 (LDA)。整个过程必须在统计分类理论的框架内进行，其基础假设是每个类别的数据都来自一个具有类特定均值但共享公共协方差矩阵的多元正态分布 (MVN)。\n\n首先，确认问题陈述的有效性。它在科学上基于已建立的统计学原理（MVN、贝叶斯定理、LDA、LOOCV），通过具体的合成数据集和明确的算法流程，问题是良定的，并且陈述客观、没有歧义。合成数据生成的参数已完全指定，确保了唯一且可复现的解。术语“训练自由度”的轻微模糊性通过采用合并协方差估计量的标准统计定义来解决，即 $N_{train} - K$，其中 $N_{train}$ 是训练集的大小，$K$ 是类别数量。\n\n该解决方案按以下算法流程进行：\n\n1.  **数据生成**：对于三个测试用例中的每一个，我们根据提供的规格生成合成数据。对于每个类别 $k \\in \\{1, \\dots, K\\}$，我们使用由指定种子初始化的伪随机数生成器，从多元正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma})$ 中抽取 $n_k$ 个样本。这将创建一个包含 $N = \\sum_{k=1}^K n_k$ 个观测值的完整数据集，每个观测值都带有一个已知的类别标签。\n\n2.  **留一法交叉验证 (LOOCV)**：为了估计 LDA 分类器的泛化性能，我们采用 LOOCV。这涉及迭代 $N$ 次。在每次迭代 $i = 1, \\dots, N$ 中，第 $i$ 个观测值 $(\\mathbf{x}_i, y_i)$ 被指定为测试集，其余 $N-1$ 个观测值构成训练集。\n\n3.  **参数估计**：在每个 LOOCV 折中，生成模型的参数从训练数据（一个大小为 $N_{train} = N-1$ 的集合）中估计。\n    -   **先验概率 ($\\widehat{\\pi}_k$)**：每个类别 $k$ 的先验概率估计为其在训练集中的经验频率：$\\widehat{\\pi}_k = N_k^{train} / N_{train}$，其中 $N_k^{train}$ 是类别 $k$ 中的训练观测值数量。\n    -   **均值 ($\\widehat{\\boldsymbol{\\mu}}_k$)**：每个类别 $k$ 的均值向量通过属于该类别的所有训练观测值的样本均值来估计。\n    -   **合并协方差 ($\\widehat{\\boldsymbol{\\Sigma}}$)**：估计一个单一的、共享的协方差矩阵。首先，计算每个类别的类内散布矩阵：$S_k = \\sum_{\\mathbf{x}_j \\in \\text{class } k} (\\mathbf{x}_j - \\widehat{\\boldsymbol{\\mu}}_k)(\\mathbf{x}_j - \\widehat{\\boldsymbol{\\mu}}_k)^T$。将它们相加形成总的类内散布矩阵，$S_W = \\sum_{k=1}^K S_k$。然后，合并协方差估计量为 $\\widehat{\\boldsymbol{\\Sigma}}_{\\text{pooled}} = S_W / (N_{train} - K)$。分母对应于自由度。按照规定，该矩阵经过正则化处理以确保其为正定且具有良好的求逆条件：$\\widehat{\\boldsymbol{\\Sigma}} = \\widehat{\\boldsymbol{\\Sigma}}_{\\text{pooled}} + \\lambda \\mathbf{I}_d$，其中 $\\lambda = 10^{-6}$。\n\n4.  **对留一样本进行预测和评估**：使用估计的参数对被留出的观测值 $\\mathbf{x}_i$ 进行分类。\n    -   **后验概率计算**：根据贝叶斯定理，观测值 $\\mathbf{x}_i$ 属于类别 $k$ 的后验概率为 $p(y=k \\mid \\mathbf{x}_i) \\propto \\widehat{\\pi}_k f_k(\\mathbf{x}_i)$，其中 $f_k$ 是参数为 $(\\widehat{\\boldsymbol{\\mu}}_k, \\widehat{\\boldsymbol{\\Sigma}})$ 的 MVN 密度函数。为确保数值稳定性，我们计算对数后验概率。对数似然 $\\log f_k(\\mathbf{x}_i)$ 从 MVN 概率密度函数获得。每个类别的未归一化对数后验概率为 $L_k = \\log \\widehat{\\pi}_k + \\log f_k(\\mathbf{x}_i)$。使用 log-sum-exp 变换将它们归一化为概率：$p_k = \\exp(L_k) / \\sum_j \\exp(L_j)$。\n    -   **分类**：$\\mathbf{x}_i$ 的预测类别是具有最大后验概率的类别（MAP 法则）：$\\widehat{y}_i = \\arg\\max_k p(y=k \\mid \\mathbf{x}_i)$。\n    -   **指标收集**：对于每个折 $i$，我们记录：\n        a. 错分指示符：如果 $\\widehat{y}_i \\neq y_i$ 则为 $1$，否则为 $0$。\n        b. 所分配类别的后验概率：$\\max_k p(y=k \\mid \\mathbf{x}_i)$。\n        c. 后验香农熵：$H(\\mathbf{x}_i) = -\\sum_{k=1}^K p(y=k \\mid \\mathbf{x}_i) \\log p(y=k \\mid \\mathbf{x}_i)$，使用自然对数计算（以 nats 为单位）。\n\n5.  **结果聚合**：完成 LOOCV 的所有 $N$ 个折后，将收集到的指标进行聚合，以生成该测试用例的最终摘要统计数据。\n    -   **错分率 ($\\hat{p}$)**：所有 $N$ 个折的错分指示符的简单平均值。\n    -   **Wilson 得分置信区间**：对于估计的错分率 $\\hat{p}$，我们计算真实二项比例的 $95\\%$ 置信区间。给定 $N$ 次试验和比率 $\\hat{p}$，该区间由以下公式给出：\n        $$ \\frac{1}{1+z^2/N} \\left( \\hat{p} + \\frac{z^2}{2N} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N} + \\frac{z^2}{4N^2}} \\right) $$\n        其中 $z \\approx 1.96$ 是来自标准正态分布的 $95\\%$ 置信水平的临界值。\n    -   **平均后验指标**：通过对所有 $N$ 个折中的相应值进行平均，计算所分配类别后验概率的平均值和后验熵的平均值。\n\n最后，对每个测试用例的五个浮点数值结果进行四舍五入至四位小数，并格式化为指定的列表的列表结构。整个过程被封装在一个使用 `numpy` 和 `scipy` 库的 Python 程序中。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import multivariate_normal, norm\n\ndef perform_loocv_lda(case):\n    \"\"\"\n    Performs Linear Discriminant Analysis using Leave-One-Out Cross-Validation.\n\n    Args:\n        case (tuple): A tuple containing problem parameters:\n            K (int): Number of classes.\n            d (int): Dimensionality of data.\n            Sigma (np.ndarray): Common covariance matrix.\n            mus (list of np.ndarray): List of class mean vectors.\n            ns (list of int): List of sample sizes for each class.\n            seed (int): Seed for the pseudo-random number generator.\n\n    Returns:\n        list: A list of five floats containing the aggregated performance metrics.\n    \"\"\"\n    K, d, Sigma, mus, ns, seed = case\n    lambda_reg = 1e-6\n\n    # 1. Generate synthetic data\n    rng = np.random.default_rng(seed)\n    X_list = []\n    y_list = []\n    for k_idx in range(K):\n        data_k = rng.multivariate_normal(mus[k_idx], Sigma, size=ns[k_idx])\n        X_list.append(data_k)\n        y_list.append(np.full(ns[k_idx], k_idx))\n\n    X = np.vstack(X_list)\n    y = np.concatenate(y_list)\n    n_total = X.shape[0]\n\n    # Lists to store results from each LOOCV fold\n    misclass_indicators = []\n    posterior_probs_assigned = []\n    entropies = []\n\n    # 2. LOOCV loop\n    for i in range(n_total):\n        # Define training and test sets for this fold\n        X_test = X[i, :]\n        y_test = y[i]\n        X_train = np.delete(X, i, axis=0)\n        y_train = np.delete(y, i, axis=0)\n        n_train = X_train.shape[0]\n\n        # 3. Parameter estimation on the training set\n        classes, counts = np.unique(y_train, return_counts=True)\n        K_train = len(classes)\n\n        # Estimate class priors\n        pi_hats = counts / n_train\n        \n        # Estimate class means\n        mu_hats = np.array([np.mean(X_train[y_train == k], axis=0) for k in classes])\n\n        # Estimate pooled covariance matrix\n        S_W = np.zeros((d, d))\n        for k_idx, k in enumerate(classes):\n            X_k = X_train[y_train == k]\n            mu_k_hat = mu_hats[k_idx]\n            diff = X_k - mu_k_hat\n            S_W += diff.T @ diff\n        \n        df = n_train - K_train\n        Sigma_pooled = S_W / df\n        Sigma_hat = Sigma_pooled + lambda_reg * np.eye(d)\n\n        # 4. Predict on the left-out test point\n        log_posteriors = np.zeros(K_train)\n        for k_idx, k in enumerate(classes):\n            log_lk = multivariate_normal.logpdf(X_test, mean=mu_hats[k_idx], cov=Sigma_hat)\n            log_posteriors[k_idx] = np.log(pi_hats[k_idx]) + log_lk\n\n        # Normalize to get posterior probabilities using log-sum-exp trick\n        max_log = np.max(log_posteriors)\n        log_sum_exp = max_log + np.log(np.sum(np.exp(log_posteriors - max_log)))\n        post_probs = np.exp(log_posteriors - log_sum_exp)\n\n        # Collect metrics for this fold\n        pred_class_idx = np.argmax(post_probs)\n        pred_class = classes[pred_class_idx]\n        \n        misclass_indicators.append(1 if pred_class != y_test else 0)\n        posterior_probs_assigned.append(post_probs[pred_class_idx])\n\n        valid_probs = post_probs[post_probs > 0]\n        entropy = -np.sum(valid_probs * np.log(valid_probs))\n        entropies.append(entropy)\n\n    # 5. Aggregate results across all folds\n    p_hat = np.mean(misclass_indicators)\n    n = n_total\n    z = norm.ppf(1 - 0.05 / 2) # z for 0.95 CI\n\n    # Wilson score confidence interval\n    denominator = 1 + z**2 / n\n    center = (p_hat + z**2 / (2 * n)) / denominator\n    width = (z / denominator) * np.sqrt((p_hat * (1 - p_hat)) / n + z**2 / (4 * n**2))\n    wilson_lower = center - width\n    wilson_upper = center + width\n\n    mean_post_prob = np.mean(posterior_probs_assigned)\n    mean_entropy = np.mean(entropies)\n\n    return [p_hat, wilson_lower, wilson_upper, mean_post_prob, mean_entropy]\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 2, np.array([[1, 0.3], [0.3, 1]]), [np.array([0, 0]), np.array([3, 3])], [30, 30], 7),\n        (2, 2, np.array([[1, 0.7], [0.7, 1]]), [np.array([0, 0]), np.array([0.8, 0.8])], [40, 40], 13),\n        (3, 3, 0.5 * np.eye(3), [np.array([0, 0, 0]), np.array([2.5, 0, 2.5]), np.array([0, 2.5, 2.5])], [8, 7, 9], 101)\n    ]\n\n    results = []\n    for case in test_cases:\n        case_results = perform_loocv_lda(case)\n        rounded_results = [round(val, 4) for val in case_results]\n        results.append(rounded_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "2752812"}]}