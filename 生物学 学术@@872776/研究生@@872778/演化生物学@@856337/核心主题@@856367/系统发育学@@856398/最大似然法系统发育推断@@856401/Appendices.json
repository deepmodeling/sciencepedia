{"hands_on_practices": [{"introduction": "最大似然法的核心在于计算在给定模型和树的条件下观测到特定数据的概率。本练习将此过程分解为最基本的部分，要求您在一个简化的双状态模型下，为一段序列联配手动计算似然值。通过显式地对所有祖先状态求和，本练习旨在揭示似然值背后的根本机制，为理解更复杂的自动化算法奠定坚实的基础 [@problem_id:2730997]。", "problem": "考虑一个固定的有根二叉系统发育树，该树包含 $4$ 个分类单元 $A,B,C,D$，其拓扑结构为 $\\big((A:0.2,B:0.2):0.3,(C:0.2,D:0.2):0.3\\big)$，其中每个由冒号分隔的数字表示以时间为单位的分支长度。在叶尖观察到 $2$ 个独立的二元性状（状态编码为 $0$ 和 $1$）的比对：\n- 位点 $1$：$A=0$, $B=0$, $C=1$, $D=1$。\n- 位点 $2$：$A=0$, $B=1$, $C=0$, $D=1$。\n\n假设沿分支的演化遵循一个均匀、平稳、可逆的两状态连续时间马尔可夫链（CTMC），其瞬时速率矩阵为\n$$\nQ = \\begin{pmatrix}\n-\\mu  \\mu\\\\\n\\mu  -\\mu\n\\end{pmatrix},\n$$\n其中 $\\mu = 1$。假设在根节点处过程处于平稳状态，其平衡分布为 $\\pi_0=\\pi_1=\\tfrac{1}{2}$，并且各位点在此模型下独立同分布地演化。使用此模型下的最大似然（ML）系统发育推断，您必须：\n1. 通过对所有未观察到的内部状态求和，写出该固定树上每个位点的明确似然表达式（即，一个能清楚地表示对祖先状态求和以及对分支上的转移概率求积的表达式）。\n2. 对给定的数据和参数，对这些表达式进行数值评估，并计算比对似然值 $L$（两个位点似然值的乘积）。\n\n将最终的 $L$ 数值四舍五入到六位有效数字。以一个不带单位的实数形式提供您的答案。", "solution": "所述问题具有科学依据，提法恰当，客观，并包含了获得唯一解所需的所有信息。这是计算系统发育学中的一个典型练习。因此，它被认为是一个有效的问题。\n\n该问题要求计算一个DNA序列比对在固定系统发育树上的似然值。比对的总似然值 $L$ 是每个位点似然值的乘积，因为假设位点是独立演化的。\n$$L = L_1 \\times L_2$$\n其中 $L_1$ 和 $L_2$ 分别是位点 $1$ 和位点 $2$ 的似然值。\n\n演化模型是一个两状态连续时间马尔可夫链，其速率矩阵为\n$$ Q = \\begin{pmatrix} -\\mu  \\mu \\\\ \\mu  -\\mu \\end{pmatrix} $$\n其中 $\\mu = 1$。转移概率矩阵 $P(t) = \\exp(Qt)$ 给出了在长度为 $t$ 的分支上从状态 $i$ 变为状态 $j$ 的概率。对于这个对称模型，概率为：\n$P_{ii}(t) = \\frac{1}{2} + \\frac{1}{2}\\exp(-2\\mu t)$\n$P_{ij}(t) = \\frac{1}{2} - \\frac{1}{2}\\exp(-2\\mu t)$ for $i \\neq j$.\n给定 $\\mu=1$，我们定义 $p_{same}(t) = P_{ii}(t) = \\frac{1}{2} + \\frac{1}{2}\\exp(-2t)$ 和 $p_{diff}(t) = P_{ij}(t) = \\frac{1}{2} - \\frac{1}{2}\\exp(-2t)$。\n根节点的状态从平稳分布 $\\pi = (\\pi_0, \\pi_1) = (\\frac{1}{2}, \\frac{1}{2})$ 中抽取。\n\n单个位点的似然值是通过对树的所有内部节点的可能状态赋值求和来计算的。设树的拓扑结构用 $\\tau$ 表示，分支长度集用 $\\mathbf{t}$ 表示。对于在叶尖观察到数据 $D$ 的一个位点，其似然值为 $L_{site} = P(D|\\tau, \\mathbf{t})$。这可以使用 Felsenstein 的剪枝算法高效计算。\n\n设根节点为 $R$，分类单元 $A$ 和 $B$ 的祖先为节点 $N_1$，分类单元 $C$ 和 $D$ 的祖先为节点 $N_2$。分支长度为 $t_A = t_B = t_C = t_D = 0.2$，通向内部节点的分支长度为 $t_{R \\to N_1} = t_{R \\to N_2} = 0.3$。\n\n具有叶尖数据 $S = (S_A, S_B, S_C, S_D)$ 的位点的似然值由以下通用表达式给出：\n$$L_{S} = \\sum_{i_R \\in \\{0,1\\}} \\pi_{i_R} \\left( \\sum_{i_{N_1} \\in \\{0,1\\}} P_{i_R i_{N_1}}(0.3) P_{i_{N_1} S_A}(0.2) P_{i_{N_1} S_B}(0.2) \\right) \\left( \\sum_{i_{N_2} \\in \\{0,1\\}} P_{i_R i_{N_2}}(0.3) P_{i_{N_2} S_C}(0.2) P_{i_{N_2} S_D}(0.2) \\right)$$\n这个公式明确地显示了对所有未观察到的祖先状态（$i_R, i_{N_1}, i_{N_2}$）的求和，以及对分支上转移概率的乘积。\n\n**1. 位点1的似然表达式与评估**\n\n位点 $1$ 的数据是 $S_1 = (S_A=0, S_B=0, S_C=1, S_D=1)$。\n明确的似然表达式为：\n$$L_1 = \\sum_{i_R \\in \\{0,1\\}} \\pi_{i_R} \\left( \\sum_{i_{N_1} \\in \\{0,1\\}} P_{i_R i_{N_1}}(0.3) P_{i_{N_1} 0}(0.2) P_{i_{N_1} 0}(0.2) \\right) \\left( \\sum_{i_{N_2} \\in \\{0,1\\}} P_{i_R i_{N_2}}(0.3) P_{i_{N_2} 1}(0.2) P_{i_{N_2} 1}(0.2) \\right)$$\n我们可以通过评估内部求和来简化这个表达式。\n设来自 $(A,B)$ 分支的贡献为 $L^{(N_1)}$。\n$L^{(N_1)}(i_{N_1}) = P_{i_{N_1} 0}(0.2) P_{i_{N_1} 0}(0.2)$。\n因此，$L^{(N_1)}(0) = [P_{00}(0.2)]^2 = [p_{same}(0.2)]^2$ 且 $L^{(N_1)}(1) = [P_{10}(0.2)]^2 = [p_{diff}(0.2)]^2$。\n设来自 $(C,D)$ 分支的贡献为 $L^{(N_2)}$。\n$L^{(N_2)}(i_{N_2}) = P_{i_{N_2} 1}(0.2) P_{i_{N_2} 1}(0.2)$。\n因此，$L^{(N_2)}(0) = [P_{01}(0.2)]^2 = [p_{diff}(0.2)]^2$ 且 $L^{(N_2)}(1) = [P_{11}(0.2)]^2 = [p_{same}(0.2)]^2$。\n\n在根节点水平的似然值为：\n$L_1 = \\sum_{i_R \\in \\{0,1\\}} \\pi_{i_R} \\left( \\sum_{i_{N_1}} P_{i_R i_{N_1}}(0.3) L^{(N_1)}(i_{N_1}) \\right) \\left( \\sum_{i_{N_2}} P_{i_R i_{N_2}}(0.3) L^{(N_2)}(i_{N_2}) \\right)$。\n由于模型的对称性和 $\\pi_0 = \\pi_1 = \\frac{1}{2}$，总似然值得以简化。我们计算 $i_R=0$ 的项，然后乘以 $2\\pi_0=1$。\n$L_1 = \\left( P_{00}(0.3)L^{(N_1)}(0) + P_{01}(0.3)L^{(N_1)}(1) \\right) \\times \\left( P_{00}(0.3)L^{(N_2)}(0) + P_{01}(0.3)L^{(N_2)}(1) \\right)$\n$L_1 = \\left( p_{same}(0.3)[p_{same}(0.2)]^2 + p_{diff}(0.3)[p_{diff}(0.2)]^2 \\right) \\times \\left( p_{same}(0.3)[p_{diff}(0.2)]^2 + p_{diff}(0.3)[p_{same}(0.2)]^2 \\right)$。\n\n**2. 位点2的似然表达式与评估**\n\n位点 $2$ 的数据是 $S_2 = (S_A=0, S_B=1, S_C=0, S_D=1)$。\n明确的似然表达式为：\n$$L_2 = \\sum_{i_R \\in \\{0,1\\}} \\pi_{i_R} \\left( \\sum_{i_{N_1} \\in \\{0,1\\}} P_{i_R i_{N_1}}(0.3) P_{i_{N_1} 0}(0.2) P_{i_{N_1} 1}(0.2) \\right) \\left( \\sum_{i_{N_2} \\in \\{0,1\\}} P_{i_R i_{N_2}}(0.3) P_{i_{N_2} 0}(0.2) P_{i_{N_2} 1}(0.2) \\right)$$\n对于 $(A,B)$ 分支：$L^{(N_1)}(i_{N_1}) = P_{i_{N_1} 0}(0.2) P_{i_{N_1} 1}(0.2) = p_{same}(0.2)p_{diff}(0.2)$，与 $i_{N_1}$ 无关。\n对于 $(C,D)$ 分支：$L^{(N_2)}(i_{N_2}) = P_{i_{N_2} 0}(0.2) P_{i_{N_2} 1}(0.2) = p_{same}(0.2)p_{diff}(0.2)$，与 $i_{N_2}$ 无关。\n第一个大括号中的项是 $\\sum_{i_{N_1}} P_{i_R i_{N_1}}(0.3) [p_{same}(0.2)p_{diff}(0.2)] = [p_{same}(0.2)p_{diff}(0.2)] \\sum_{i_{N_1}} P_{i_R i_{N_1}}(0.3) = p_{same}(0.2)p_{diff}(0.2)$。\n同样的情况也适用于第二个括号。\n因此，$L_2 = \\sum_{i_R \\in \\{0,1\\}} \\pi_{i_R} \\left( [p_{same}(0.2)p_{diff}(0.2)] \\times [p_{same}(0.2)p_{diff}(0.2)] \\right) = (\\pi_0+\\pi_1) [p_{same}(0.2)p_{diff}(0.2)]^2$。\n由于 $\\pi_0+\\pi_1=1$，最终表达式为：\n$L_2 = [p_{same}(0.2)p_{diff}(0.2)]^2$。\n\n**3. 数值评估**\n\n首先，我们计算所需的转移概率。\n- 对于 $t=0.2$：\n$p_{same}(0.2) = \\frac{1}{2} + \\frac{1}{2}\\exp(-2 \\times 0.2) = \\frac{1}{2}(1 + \\exp(-0.4)) \\approx \\frac{1}{2}(1 + 0.6703200) = 0.8351600$\n$p_{diff}(0.2) = \\frac{1}{2} - \\frac{1}{2}\\exp(-0.4) = \\frac{1}{2}(1 - \\exp(-0.4)) \\approx \\frac{1}{2}(1 - 0.6703200) = 0.1648400$\n- 对于 $t=0.3$：\n$p_{same}(0.3) = \\frac{1}{2} + \\frac{1}{2}\\exp(-2 \\times 0.3) = \\frac{1}{2}(1 + \\exp(-0.6)) \\approx \\frac{1}{2}(1 + 0.5488116) = 0.7744058$\n$p_{diff}(0.3) = \\frac{1}{2} - \\frac{1}{2}\\exp(-0.6) = \\frac{1}{2}(1 - \\exp(-0.6)) \\approx \\frac{1}{2}(1 - 0.5488116) = 0.2255942$\n\n现在，我们评估 $L_1$ 和 $L_2$。\n- 对于 $L_1$：\n设 $A = p_{same}(0.3)[p_{same}(0.2)]^2 + p_{diff}(0.3)[p_{diff}(0.2)]^2$\n$A \\approx (0.7744058)(0.8351600)^2 + (0.2255942)(0.1648400)^2$\n$A \\approx (0.7744058)(0.6974912) + (0.2255942)(0.0271722)$\n$A \\approx 0.540115 + 0.006127 = 0.546242$\n设 $B = p_{same}(0.3)[p_{diff}(0.2)]^2 + p_{diff}(0.3)[p_{same}(0.2)]^2$\n$B \\approx (0.7744058)(0.1648400)^2 + (0.2255942)(0.8351600)^2$\n$B \\approx (0.7744058)(0.0271722) + (0.2255942)(0.6974912)$\n$B \\approx 0.021045 + 0.157394 = 0.178439$\n$L_1 = A \\times B \\approx 0.546242 \\times 0.178439 \\approx 0.0974558$\n\n- 对于 $L_2$：\n$L_2 = [p_{same}(0.2) \\times p_{diff}(0.2)]^2$\n$L_2 \\approx [0.8351600 \\times 0.1648400]^2 = [0.1376645]^2 \\approx 0.0189510$\n\n**4. 总比对似然值**\n\n总比对似然值 $L$ 是位点似然值的乘积。\n$L = L_1 \\times L_2 \\approx 0.0974558 \\times 0.0189510 \\approx 0.0018469089$\n四舍五入到六位有效数字，我们得到 $0.00184691$。", "answer": "$$\\boxed{0.00184691}$$", "id": "2730997"}, {"introduction": "在掌握了似然性的基本计算方法后，我们需要构建更符合生物学现实的替换模型，这是从简单模型迈向实际应用的关键一步。本练习要求您从瞬时速率矩阵（$Q$ 矩阵）出发，推导出 Jukes-Cantor (JC69) 模型的转移概率。这个推导过程阐明了模型参数与以每个位点的预期替换次数为单位的进化距离之间的重要联系，是理解所有DNA替换模型的理论基石 [@problem_id:2730943]。", "problem": "在最大似然系统发育推断中，沿分支的核苷酸替换过程被建模为齐次连续时间马尔可夫链 (CTMC)。CTMC 的生成元（瞬时速率）矩阵 $Q$ 满足：对于 $i \\neq j$，每个非对角元素 $q_{ij}$ 均为非负数，每行之和为 $0$，以及随时间 $t$ 变化的转移概率矩阵（记为 $P(t)$）是矩阵指数 $P(t) = \\exp(Qt)$。考虑 Jukes–Cantor 模型 (JC69)，其中状态空间是核苷酸集合 $\\{A,C,G,T\\}$，平稳分布是均匀的，且不同核苷酸之间的所有瞬时替换速率都相等。设此公共非对角速率为 $\\alpha$，因此对于 $i \\neq j$ 有 $q_{ij} = \\alpha$，而对角线元素由 $q_{ii} = -\\sum_{j \\neq i} q_{ij}$ 决定。\n \n从 CTMC 和矩阵指数的这些定义和事实出发，完成以下任务：\n \n- 通过计算 $\\exp(Qt)$，推导闭式转移概率 $P_{ii}(t)$ 和 $P_{ij}(t)$（其中 $i \\neq j$）作为 $\\alpha$ 和 $t$ 的函数。\n- 将平稳状态下每位点的平均替换速率 $\\mu$ 定义为 $\\mu = -\\sum_{i} \\pi_{i} q_{ii}$，其中 $\\pi$ 是平稳分布，并建立 $\\alpha$ 与 $\\mu$ 之间的关系。\n- 在最大似然系统发育学中，通常通过设置 $\\mu = 1$ 来固定总体速率标度。在这种单位平均速率归一化下，将 $P_{ii}(t)$ 表示为仅含 $t$ 的函数。\n \n请提供您在单位平均速率归一化下获得的 $P_{ii}(t)$ 的单一闭式表达式作为最终答案。无需进行数值计算。不要包含任何单位。最终答案中不要包含中间步骤。如果引入任何缩写，请在首次使用时定义。", "solution": "我们首先对问题陈述进行形式化验证。\n\n给定条件明确陈述如下：\n- 该过程为齐次连续时间马尔可夫链 (CTMC)。\n- 生成元矩阵为 $Q$，其中对于 $i \\neq j$ 非对角元素 $q_{ij} \\ge 0$，且行和为 $0$。\n- 转移概率矩阵为 $P(t) = \\exp(Qt)$。\n- 模型为 Jukes–Cantor (JC69) 模型，状态空间为 $\\{A,C,G,T\\}$。\n- 平稳分布 $\\pi$ 是均匀的。\n- 不同状态间的瞬时速率相等：对于 $i \\neq j$，$q_{ij} = \\alpha$。\n- 对角元素由行和约束决定：$q_{ii} = -\\sum_{j \\neq i} q_{ij}$。\n- 每位点的平均替换速率定义为 $\\mu = -\\sum_{i} \\pi_{i} q_{ii}$。\n- 任务是：(1) 通过计算 $\\exp(Qt)$ 推导闭式转移概率 $P_{ii}(t)$ 和 $P_{ij}(t)$；(2) 建立 $\\alpha$ 与 $\\mu$ 的关系；以及 (3) 在 $\\mu = 1$ 的归一化下，将 $P_{ii}(t)$ 表示为 $t$ 的函数。\n\n该问题具有科学依据，因为 Jukes–Cantor 模型是分子进化和系统发育学领域中的一个经典基础模型。它是客观的，所有术语都使用精确的数学语言定义。该问题是适定的（well-posed），提供了通过线性代数和马尔可夫过程理论的标准方法推导出唯一解所需的所有必要条件和定义。不存在逻辑矛盾、信息缺失或事实错误。该问题是理论生物学中一个标准的、非平凡的练习。因此，该问题被认定为有效，我们将继续进行推导。\n\n该问题要求为状态空间为 $4$ 个核苷酸的 Jukes-Cantor 模型推导转移概率，我们可以将这些核苷酸索引为 $\\{1, 2, 3, 4\\}$。\n\n首先，我们必须构建生成元矩阵 $Q$。非对角元素给定为 $q_{ij} = \\alpha$，适用于任何不同的状态 $i \\neq j$。对角元素由 $Q$ 矩阵的行和必须为零的性质决定：$q_{ii} = -\\sum_{j \\neq i} q_{ij}$。由于对于任何状态 $i$，都有 $3$ 个其他状态 $j$，因此 $q_{ii} = -3\\alpha$。所以，$Q$ 矩阵是一个 $4 \\times 4$ 矩阵，如下所示：\n$$\nQ = \\begin{pmatrix}\n-3\\alpha  \\alpha  \\alpha  \\alpha \\\\\n\\alpha  -3\\alpha  \\alpha  \\alpha \\\\\n\\alpha  \\alpha  -3\\alpha  \\alpha \\\\\n\\alpha  \\alpha  \\alpha  -3\\alpha\n\\end{pmatrix}\n$$\n该矩阵具有特殊的结构，可以简化其指数的计算。我们可以分解 $Q$，令 $I$ 为 $4 \\times 4$ 单位矩阵，$J$ 为 $4 \\times 4$ 全一矩阵。那么 $Q$ 可以表示为：\n$$\nQ = \\alpha(J - 4I)\n$$\n转移概率矩阵 $P(t)$ 是矩阵指数 $P(t) = \\exp(Qt)$。我们使用 $Q$ 的分解来计算它：\n$$\nP(t) = \\exp(\\alpha t(J - 4I))\n$$\n因为单位矩阵 $I$ 与任何矩阵（特别是与 $J$）都可交换，所以我们可以分离指数：$\\exp(A+B) = \\exp(A)\\exp(B)$。这里，我们设 $A = \\alpha t J$ 和 $B = -4\\alpha t I$。\n$$\nP(t) = \\exp(\\alpha t J) \\exp(-4\\alpha t I)\n$$\n单位矩阵标量倍数的指数是平凡的：$\\exp(-4\\alpha t I) = \\exp(-4\\alpha t) I$。主要任务是计算 $\\exp(\\alpha t J)$。我们使用矩阵指数的泰勒级数定义，$\\exp(X) = \\sum_{k=0}^{\\infty} \\frac{X^k}{k!}$。我们需要求 $J$ 的幂。通过直接矩阵乘法，$J^2 = 4J$，$J^3 = J \\cdot J^2 = J(4J) = 4J^2 = 4(4J) = 4^2 J$。通过归纳法，显然对于所有整数 $k \\ge 1$，$J^k = 4^{k-1}J$。\n\n$\\exp(\\alpha t J)$ 的级数展开为：\n$$\n\\exp(\\alpha t J) = I + \\sum_{k=1}^{\\infty} \\frac{(\\alpha t)^k J^k}{k!} = I + \\sum_{k=1}^{\\infty} \\frac{(\\alpha t)^k (4^{k-1}J)}{k!}\n$$\n我们可以从求和中提出常数项：\n$$\n\\exp(\\alpha t J) = I + \\frac{J}{4} \\sum_{k=1}^{\\infty} \\frac{(4\\alpha t)^k}{k!}\n$$\n该求和是 $\\exp(x)$ 在 $x=4\\alpha t$ 处的泰勒级数，但缺少 $k=0$ 的项，即 $1$。因此，$\\sum_{k=1}^{\\infty} \\frac{(4\\alpha t)^k}{k!} = \\exp(4\\alpha t) - 1$。\n将其代回，我们得到：\n$$\n\\exp(\\alpha t J) = I + \\frac{J}{4}(\\exp(4\\alpha t) - 1)\n$$\n现在，我们组合各部分来求 $P(t)$：\n$$\nP(t) = \\left( I + \\frac{J}{4}(\\exp(4\\alpha t) - 1) \\right) (\\exp(-4\\alpha t)I) = \\exp(-4\\alpha t)I + \\frac{J}{4}(\\exp(4\\alpha t) - 1)\\exp(-4\\alpha t)\n$$\n$$\nP(t) = \\exp(-4\\alpha t)I + \\frac{J}{4}(1 - \\exp(-4\\alpha t))\n$$\n从这个复合矩阵形式中，我们提取单个转移概率。对角元素 $P_{ii}(t)$ 对应于此表达式的对角元素，而非对角元素 $P_{ij}(t)$（其中 $i \\neq j$）对应于其非对角元素。对于对角元素 $P_{ii}(t)$，来自单位矩阵项的贡献是 $\\exp(-4\\alpha t)$，来自 $J$ 矩阵项的贡献是 $\\frac{1}{4}(1 - \\exp(-4\\alpha t))$。\n$$\nP_{ii}(t) = \\exp(-4\\alpha t) + \\frac{1}{4}(1 - \\exp(-4\\alpha t)) = \\frac{1}{4} + \\frac{3}{4}\\exp(-4\\alpha t)\n$$\n对于非对角元素 $P_{ij}(t)$（其中 $i \\neq j$），来自单位矩阵项的贡献是 $0$，来自 $J$ 矩阵项的贡献是 $\\frac{1}{4}(1 - \\exp(-4\\alpha t))$。\n$$\nP_{ij}(t) = \\frac{1}{4}(1 - \\exp(-4\\alpha t))\n$$\n这完成了第一个任务。对于第二个任务，我们必须将 $\\alpha$ 与平均替换速率 $\\mu = -\\sum_{i} \\pi_{i} q_{ii}$ 联系起来。对于 JC69 模型，平稳分布 $\\pi$ 在 $4$ 个状态上是均匀的，即对所有 $i$ 都有 $\\pi_i = \\frac{1}{4}$。$Q$ 的对角元素是 $q_{ii} = -3\\alpha$。将这些值代入 $\\mu$ 的定义中：\n$$\n\\mu = -\\sum_{i=1}^{4} \\pi_{i} q_{ii} = -\\sum_{i=1}^{4} \\left(\\frac{1}{4}\\right)(-3\\alpha) = -4 \\left(\\frac{-3\\alpha}{4}\\right) = 3\\alpha\n$$\n因此，关系式为 $\\mu = 3\\alpha$，这意味着 $\\alpha = \\frac{\\mu}{3}$。\n对于最后一个任务，我们应用系统发育学中使用的归一化，即设置平均速率为单位一：$\\mu = 1$。在此条件下，$\\alpha$ 的值确定为：\n$$\n\\alpha = \\frac{1}{3}\n$$\n现在我们将这个 $\\alpha$ 的值代入我们推导出的对角转移概率 $P_{ii}(t)$ 的表达式中：\n$$\nP_{ii}(t) = \\frac{1}{4} + \\frac{3}{4}\\exp(-4\\alpha t) = \\frac{1}{4} + \\frac{3}{4}\\exp\\left(-4\\left(\\frac{1}{3}\\right)t\\right)\n$$\n当平均替换速率设置为 $1$ 时，这简化为核苷酸在长度为 $t$ 的分支上保持不变的概率的最终表达式：\n$$\nP_{ii}(t) = \\frac{1}{4} + \\frac{3}{4}\\exp\\left(-\\frac{4}{3}t\\right)\n$$\n这就是所要求的表达式。", "answer": "$$\n\\boxed{\\frac{1}{4} + \\frac{3}{4}\\exp\\left(-\\frac{4}{3}t\\right)}\n$$", "id": "2730943"}, {"introduction": "理论推导与手动计算为理解最大似然法提供了概念框架，但实际的系统发育推断依赖于强大的计算方法来寻找最优参数。本练习是本章的高潮，要求您编写一个程序来实现 Felsenstein 的剪枝算法，并使用数值优化来寻找分支长度的最大似然估计值。通过将理论付诸实践，您将模拟任何最大似然系统发育软件的核心引擎，从而巩固对整个推断过程的理解 [@problem_id:2730924]。", "problem": "给定一个在 Jukes–Cantor 1969 (JC69) 核苷酸替换模型下的有根三分类单元系统发育树。这些分类单元被标记为叶节点 $A$、$B$ 和 $C$。有根拓扑结构是固定的：根节点 $R$ 有两个子节点，一个内部节点 $I$ 和一个叶节点 $C$；内部节点 $I$ 有两个子节点，即叶节点 $A$ 和 $B$。需要估计的枝长为边 $(I \\to A)$ 上的 $t_A$，边 $(I \\to B)$ 上的 $t_B$，边 $(R \\to I)$ 上的 $t_I$，以及边 $(R \\to C)$ 上的 $t_C$。所有枝长都以每个位点的预期替换数来衡量（即，时间被缩放，使得每个位点每单位时间的预期替换数为 $1$）。\n\n假设以下基本设定：\n- 在字母表 $\\{A, C, G, T\\}$ 上，位点在时间同质性连续时间马尔可夫链 (CTMC)下独立同分布地演化。\n- 在 Jukes–Cantor 1969 (JC69) 模型下，瞬时速率矩阵具有相等的非对角线速率和平稳碱基频率 $\\pi_{A}=\\pi_{C}=\\pi_{G}=\\pi_{T}=\\frac{1}{4}$。当时间以每个位点的预期替换数计量时，转移概率为\n$$\nP_{ii}(t)=\\tfrac{1}{4}+\\tfrac{3}{4}e^{-4t/3}, \\quad\nP_{ij}(t)=\\tfrac{1}{4}-\\tfrac{1}{4}e^{-4t/3} \\quad (i\\neq j).\n$$\n\n设一个位点模式为一个三元组 $(x_A,x_B,x_C)\\in \\{A,C,G,T\\}^3$，表示在叶节点 $A,B,C$ 处观察到的核苷酸。对于一个叶节点观测值为 $(x_A,x_B,x_C)$ 的单位点，给定枝长 $(t_A,t_B,t_I,t_C)$ 的数据概率是通过 Felsenstein 剪枝算法对未观察到的祖先状态进行边缘化得到的：\n- 对于节点 $I$ 处的每个状态 $s\\in\\{A,C,G,T\\}$，定义部分似然\n$$\nL_I(s)=P_{s,x_A}(t_A)\\,P_{s,x_B}(t_B).\n$$\n- 对于每个根节点状态 $r\\in\\{A,C,G,T\\}$，沿边 $(R\\to I)$ 向上回溯，然后到叶节点 $C$：\n$$\nL_R(r)=\\left(\\sum_{s\\in\\{A,C,G,T\\}} P_{r,s}(t_I)\\,L_I(s)\\right)\\,P_{r,x_C}(t_C).\n$$\n- 那么位点似然为\n$$\n\\Pr(x_A,x_B,x_C\\mid t_A,t_B,t_I,t_C)=\\sum_{r\\in\\{A,C,G,T\\}} \\pi_r\\,L_R(r),\n$$\n其中 $\\pi_r=\\tfrac{1}{4}$。\n\n给定一个带有计数 $\\{n(x_A,x_B,x_C)\\}$ 的位点模式多重集，对数似然为\n$$\n\\ell(t_A,t_B,t_I,t_C)=\\sum_{(x_A,x_B,x_C)\\in \\{A,C,G,T\\}^3} n(x_A,x_B,x_C)\\,\\log\\left(\\Pr(x_A,x_B,x_C\\mid t_A,t_B,t_I,t_C)\\right).\n$$\n你的任务是编写一个完整的程序，实现以下功能：\n- 实现 JC69 转移概率。\n- 在指定的有根拓扑结构上，使用上述剪枝递归计算位点模式概率。\n- 汇总位点模式计数以计算总对数似然。\n- 在非负枝长 $(t_A,t_B,t_I,t_C)$ 上数值最大化对数似然，每个枝长被限制在闭区间 $[10^{-8},5]$ 内以避免简并情况。\n\n测试套件。您的程序必须运行以下三个参数化测试用例。每个测试用例是一个模式计数的字典；任何未列出的模式计数为 $0$。\n\n- 测试用例 1（具有中等分化和姐妹分类单元相似性的一般“理想路径”）：\n  - $AAA: 20$\n  - $AAT: 2$\n  - $AAC: 2$\n  - $AAG: 2$\n  - $CCA: 3$\n  - $CCG: 2$\n  - $CCC: 8$\n  - $TTT: 7$\n  - $GGG: 6$\n  - $GGA: 3$\n  - $GGT: 2$\n  - $AGG: 2$\n  - $TTA: 2$\n  - $TTC: 1$\n\n- 测试用例 2（边界情况：所有分类单元完全保守）：\n  - $AAA: 25$\n  - $CCC: 25$\n  - $GGG: 25$\n  - $TTT: 25$\n\n- 测试用例 3（不平衡：叶节点 A 和 B 大体上共享相同状态，而叶节点 C 经常不同）：\n  - $AAA: 5$\n  - $AAT: 20$\n  - $CCA: 1$\n  - $CCT: 5$\n  - $GGG: 5$\n  - $GGC: 15$\n  - $TTT: 5$\n  - $TTA: 12$\n  - $CCG: 3$\n\n对于每个测试用例，您的程序必须计算在 JC69 模型下 $(t_A,t_B,t_C,t_I)$ 的最大似然估计以及最大对数似然值 $\\ell^\\star$。所有测试用例的最终输出必须是一行：一个列表的列表，其中每个内部列表按顺序对应一个测试用例，包含四个优化后的枝长，后跟最大化的对数似然，\n$$\n[t_A^\\star,t_B^\\star,t_C^\\star,t_I^\\star,\\ell^\\star].\n$$\n每个测试用例的所有五个数字必须四舍五入到 $6$ 位小数。例如，输出格式必须完全是\n$[[t_{A,1}^\\star,t_{B,1}^\\star,t_{C,1}^\\star,t_{I,1}^\\star,\\ell_1^\\star],[t_{A,2}^\\star,t_{B,2}^\\star,t_{C,2}^\\star,t_{I,2}^\\star,\\ell_2^\\star],[t_{A,3}^\\star,t_{B,3}^\\star,t_{C,3}^\\star,t_{I,3}^\\star,\\ell_3^\\star]]$\n不带任何多余的空格或文本。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如 $[result_1,result_2,result_3]$）。", "solution": "该问题是有效的，因为它提出了一个在计算演化生物学领域内定义明确、有科学依据的问题。它要求在一个固定的系统发育树拓扑结构上，对一个由既定模型——Jukes-Cantor 1969 (JC69) 核苷酸替换模型——定义的似然函数进行数值优化。所有必要的数据、模型和约束都已提供。解决方案如下。\n\n问题的核心是为一个给定的有根系统发育树找到四个枝长 $\\{t_A, t_B, t_I, t_C\\}$ 的最大似然估计 (MLE)。这是一个数值优化问题，其目标函数是观察到的位点模式数据的对数似然 $\\ell(t_A, t_B, t_I, t_C)$。目标是找到一组枝长 $(\\hat{t}_A, \\hat{t}_B, \\hat{t}_I, \\hat{t}_C)$ 来最大化此函数，同时受每个枝长必须位于区间 $[10^{-8}, 5]$ 内的约束。\n\n一个包含 $N$ 个位点的序列比对的对数似然由下式给出：\n$$\n\\ell(t_A, t_B, t_I, t_C) = \\sum_{(x_A, x_B, x_C)} n(x_A, x_B, x_C) \\log \\left(\\Pr(x_A, x_B, x_C \\mid t_A, t_B, t_I, t_C)\\right)\n$$\n其中 $n(x_A, x_B, x_C)$ 是位点模式 $(x_A, x_B, x_C)$ 的计数，求和遍及所有可能的模式。单个位点模式的概率 $\\Pr(x_A, x_B, x_C)$ 使用 Felsenstein 剪枝算法计算，该算法通过对树的内部节点所有可能的状态进行边缘化来求得。\n\n解决方案的设计围绕以下原则构建：\n\n1.  **JC69 转移概率矩阵**：JC69 模型假设任意两个不同核苷酸之间的替换速率相等，且平稳频率相等，$\\pi = \\frac{1}{4}$。在长度为 $t$ 的枝上，从状态 $i$ 到状态 $j$ 的替换概率由一个 $4 \\times 4$ 矩阵 $P(t)$ 给出，其元素为：\n    $$\n    P_{ii}(t) = \\frac{1}{4} + \\frac{3}{4}e^{-4t/3}, \\quad P_{ij}(t) = \\frac{1}{4} - \\frac{1}{4}e^{-4t/3} \\quad (i \\neq j)\n    $$\n    实现了一个函数来为任何给定的非负枝长 $t$ 计算这个矩阵。该矩阵对似然计算至关重要。\n\n2.  **Felsenstein 剪枝算法的实现**：观察到叶节点状态为 $(x_A, x_B, x_C)$ 的概率是通过从叶节点到根节点递归计算部分似然来计算的。对于指定的拓扑结构 $((A,B),C)$，问题陈述中提供的过程通过高效的矩阵向量运算得以实现。\n    - 对于内部节点 $I$ 处的每个可能状态 $s \\in \\{A, C, G, T\\}$，部分似然为 $L_I(s) = P_{s,x_A}(t_A) P_{s,x_B}(t_B)$。这可以计算为一个大小为 $4$ 的向量 $\\vec{L}_I$，其元素是 $P(t_A)$ 和 $P(t_B)$ 中对应于观察状态 $x_A$ 和 $x_B$ 的列的逐元素乘积。\n    - 该向量被传播到根节点 $R$。对于根节点处的每个状态 $r \\in \\{A, C, G, T\\}$，部分似然为 $L_R(r) = \\left( \\sum_{s} P_{r,s}(t_I) L_I(s) \\right) P_{r,x_C}(t_C)$。这对应于向量运算 $\\vec{L}_R = (P(t_I) \\vec{L}_I) \\odot \\vec{v}_C$，其中 $\\odot$ 表示逐元素乘积，$\\vec{v}_C$ 是 $P(t_C)$ 中对应状态 $x_C$ 的列。求和项是一个矩阵向量乘积。\n    - 最后，该位点的总似然是所有可能根节点状态的加权和：$\\Pr(\\text{data}) = \\sum_r \\pi_r L_R(r) = \\frac{1}{4} \\sum_r L_R(r)$，代入 JC69 模型的均匀平稳频率。\n\n3.  **通过模式聚合提高计算效率**：对数似然的朴素评估将涉及为数据中存在的每个唯一位点模式计算概率。然而，在 JC69 模型下，位点模式的概率仅取决于哪些核苷酸是相同的，而与它们的具体标签无关。对于一个三分类单元树，这将 $4^3 = 64$ 种可能的位点模式根据叶节点 $A$、$B$ 和 $C$ 的状态同一性划分为五个不同的类别：\n    - 类别 1: $x_A = x_B = x_C$ (例如，$AAA$)\n    - 类别 2: $x_A = x_B \\neq x_C$ (例如，$AAT$)\n    - 类别 3: $x_A = x_C \\neq x_B$ (例如，$ATA$)\n    - 类别 4: $x_B = x_C \\neq x_A$ (例如，$TAA$)\n    - 类别 5: $x_A, x_B, x_C$ 全都不同 (例如，$ATC$)\n    首先通过遍历输入数据计算每个类别的总计数 $N_k$。然后，对数似然函数被简化为对这五个类别的求和：\n    $$\n    \\ell = \\sum_{k=1}^{5} N_k \\log(\\Pr(\\text{pattern}_k))\n    $$\n    其中 $\\Pr(\\text{pattern}_k)$ 是类别 $k$ 中任意代表性模式的概率。这显著减少了优化每一步中所需的概率计算次数，从数据中唯一模式的数量减少到仅 $5$ 次。\n\n4.  **数值优化**：通过最小化负对数似然 $-\\ell$ 来执行优化，这等同于最大化 $\\ell$。使用了 `scipy.optimize.minimize` 函数和 `L-BFGS-B` 算法。这种拟牛顿法非常适合此问题，因为它可以处理枝长参数上的箱式约束 $[10^{-8}, 5]$。优化从一个合理的起始点（例如，所有枝长设置为 $0.1$）开始初始化。\n\n5.  **程序结构**：解决方案封装在一个 Python 程序中。对于每个测试用例，首先解析位点模式计数并将其聚合成五个对称类别。定义了一个目标函数，用于计算给定枝长向量和聚合计数的负对数似然。然后调用优化器来找到最小化该函数的最优枝长。收集得到的最优枝长和相应的最大对数似然值，重新排序以匹配指定的输出格式 $[t_A^\\star,t_B^\\star,t_C^\\star,t_I^\\star,\\ell^\\star]$，并格式化到所需精度。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to run the maximum likelihood estimation for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            'AAA': 20, 'AAT': 2, 'AAC': 2, 'AAG': 2, 'CCA': 3, 'CCG': 2,\n            'CCC': 8, 'TTT': 7, 'GGG': 6, 'GGA': 3, 'GGT': 2, 'AGG': 2,\n            'TTA': 2, 'TTC': 1\n        },\n        # Test case 2\n        {\n            'AAA': 25, 'CCC': 25, 'GGG': 25, 'TTT': 25\n        },\n        # Test case 3\n        {\n            'AAA': 5, 'AAT': 20, 'CCA': 1, 'CCT': 5, 'GGG': 5, 'GGC': 15,\n            'TTT': 5, 'TTA': 12, 'CCG': 3\n        }\n    ]\n\n    # Map nucleotides to integer indices for matrix operations\n    map_char_to_int = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n    \n    # Representative patterns for each of the 5 symmetry classes under JC69\n    # The order of patterns here defines the order in the aggregated counts array.\n    # 1: x_A = x_B = x_C\n    # 2: x_A = x_B != x_C\n    # 3: x_A = x_C != x_B\n    # 4: x_B = x_C != x_A\n    # 5: x_A, x_B, x_C all distinct\n    representative_patterns = [\n        ('A', 'A', 'A'), \n        ('A', 'A', 'T'),\n        ('A', 'T', 'A'),\n        ('T', 'A', 'A'),\n        ('A', 'T', 'C')\n    ]\n\n    def aggregate_counts(pattern_data):\n        \"\"\"\n        Aggregates pattern counts into 5 symmetry classes valid under JC69.\n        \"\"\"\n        # A, C, G, T are interchangeable under JC69, so probabilities only depend on identity pattern.\n        agg_counts = np.zeros(5)\n        for pattern, count in pattern_data.items():\n            s_a, s_b, s_c = pattern[0], pattern[1], pattern[2]\n            if s_a == s_b and s_b == s_c:\n                agg_counts[0] += count\n            elif s_a == s_b and s_b != s_c:\n                agg_counts[1] += count\n            elif s_a == s_c and s_a != s_b:\n                agg_counts[2] += count\n            elif s_b == s_c and s_b != s_a:\n                agg_counts[3] += count\n            else: # All different\n                agg_counts[4] += count\n        return agg_counts\n\n    def jc69_p_matrix(t):\n        \"\"\"\n        Computes the Jukes-Cantor 1969 4x4 transition probability matrix for branch length t.\n        \"\"\"\n        if t  0: t = 1e-8 # Ensure non-negativity\n        \n        val_exp = np.exp(-4.0 * t / 3.0)\n        p_same = 0.25 + 0.75 * val_exp\n        p_diff = 0.25 - 0.25 * val_exp\n\n        # Create the matrix with p_diff and fill diagonal with p_same\n        P = np.full((4, 4), p_diff)\n        np.fill_diagonal(P, p_same)\n        return P\n\n    def get_neg_log_likelihood(params, agg_counts):\n        \"\"\"\n        Objective function for the optimizer. Computes the negative log-likelihood.\n        \"\"\"\n        # Parameters are the four branch lengths t_A, t_B, t_I, t_C\n        t_a, t_b, t_i, t_c = params\n        \n        # Pre-compute probability matrices for each branch\n        P_A = jc69_p_matrix(t_a)\n        P_B = jc69_p_matrix(t_b)\n        P_I = jc69_p_matrix(t_i)\n        P_C = jc69_p_matrix(t_c)\n        \n        site_probs = np.zeros(5)\n\n        for i, pat in enumerate(representative_patterns):\n            # Get integer indices for the nucleotide states\n            ix_a = map_char_to_int[pat[0]]\n            ix_b = map_char_to_int[pat[1]]\n            ix_c = map_char_to_int[pat[2]]\n\n            # Felsenstein's pruning algorithm for topology ((A,B),C)\n            # 1. Partial likelihood at internal node I\n            # L_I(s) = P_s,x_A(t_A) * P_s,x_B(t_B) for each state s at I\n            L_I = P_A[:, ix_a] * P_B[:, ix_b]\n            \n            # 2. Propagate to root R\n            # L_R(r) = (sum_s P_r,s(t_I) * L_I(s)) * P_r,x_C(t_C) for each state r at R\n            # The sum is a matrix-vector product P_I @ L_I\n            L_R = (P_I @ L_I) * P_C[:, ix_c]\n            \n            # 3. Total site likelihood (sum over root states weighted by stationary freqs)\n            # stationary frequencies pi_r are 1/4 for all r under JC69.\n            prob = 0.25 * np.sum(L_R)\n            site_probs[i] = prob\n        \n        # To avoid log(0), clip probabilities at a small positive value\n        site_probs = np.maximum(site_probs, 1e-300)\n        \n        # Compute total log-likelihood over all sites\n        log_L = np.sum(agg_counts * np.log(site_probs))\n        \n        # Return negative log-likelihood for minimization\n        # If log_L is NaN, return a large value to guide optimizer away\n        return -log_L if not np.isnan(log_L) else np.inf\n\n    results = []\n    bounds = [(1e-8, 5.0)] * 4  # Bounds for t_A, t_B, t_I, t_C\n\n    for case_data in test_cases:\n        agg_counts = aggregate_counts(case_data)\n        \n        # Initial guess for branch lengths [t_A, t_B, t_I, t_C]\n        initial_guess = [0.1, 0.1, 0.1, 0.1]\n        \n        # Run the optimizer\n        opt_result = minimize(\n            fun=get_neg_log_likelihood,\n            x0=initial_guess,\n            args=(agg_counts,),\n            method='L-BFGS-B',\n            bounds=bounds\n        )\n\n        # Extract optimal parameters and max log-likelihood\n        t_A_opt, t_B_opt, t_I_opt, t_C_opt = opt_result.x\n        max_logL = -opt_result.fun\n\n        # Arrange results in the specified output order: [t_A, t_B, t_C, t_I, logL]\n        # Note the swap of t_C and t_I from the optimization vector\n        final_values = [t_A_opt, t_B_opt, t_C_opt, t_I_opt, max_logL]\n        \n        results.append(final_values)\n\n    # Format output as required\n    formatted_results = []\n    for res in results:\n        # Round each number to 6 decimal places\n        formatted_res = [f\"{x:.6f}\" for x in res]\n        formatted_results.append(f\"[{','.join(formatted_res)}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2730924"}]}