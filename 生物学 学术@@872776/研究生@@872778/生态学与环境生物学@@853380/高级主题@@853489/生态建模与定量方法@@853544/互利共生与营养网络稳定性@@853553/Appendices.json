{"hands_on_practices": [{"introduction": "本练习将引导你从第一性原理出发，分析一个基础的互利共生系统。你将推导出一个正平衡点存在的条件，并进一步分析其局部稳定性。通过这个过程，你将亲身体会到一个核心的生态学原理：在某些互利共生网络中，保证物种共存（即可行性）的条件，同时也保证了这种共存状态的稳定性 [@problem_id:2510887]。这个练习旨在锻炼你的数学分析能力，并加深对可行性与稳定性之间深刻联系的理解。", "problem": "考虑一个三物种广义 Lotka–Volterra (GLV) 系统，其物种丰度 $x_{1}(t)$、$x_{2}(t)$ 和 $x_{3}(t)$ 由以下方程组支配\n$$\n\\frac{dx_{i}}{dt} \\;=\\; x_{i}\\!\\left(r_{i} \\;+\\; \\sum_{j=1}^{3} a_{ij}\\, x_{j}\\right), \\quad i \\in \\{1,2,3\\},\n$$\n其中 $r = (r_{1},r_{2},r_{3})^{\\top}$ 是内禀增长率向量，$A=(a_{ij})$ 是相互作用矩阵。假设所有内禀增长率相等且为正，即 $r_{1}=r_{2}=r_{3}=r$ 且 $r0$。相互作用矩阵是对称三对角矩阵，\n$$\nA \\;=\\; \\begin{pmatrix}\n-d  m  0 \\\\\nm  -d  m \\\\\n0  m  -d\n\\end{pmatrix},\n$$\n对角线上为自我调节强度 $d0$，相邻物种之间为互利耦合强度 $m\\ge 0$。\n\n从 GLV 系统的定义属性、平衡点的定义以及局部稳定性的线性化原理出发，根据第一性原理推导 $d$ 和 $m$ 需满足的条件，使得系统存在一个严格正平衡点 $x^{\\ast} \\in \\mathbb{R}^{3}_{0}$，并且该平衡点是局部渐近稳定的。然后，确定 $m_{\\max}$ 作为 $d$ 的函数的最大值，使得对于任意 $0 \\le m  m_{\\max}$，系统都存在一个局部渐近稳定的严格正平衡点。将你的最终答案表示为关于 $d$ 的单个闭式表达式。无需四舍五入，也无需单位。你的最终答案必须仅为 $m_{\\max}$ 的表达式。", "solution": "所述问题是适定的，有科学依据的，并包含了唯一解所需的所有信息。分析过程首先确定严格正平衡点存在的条件，其次确定该平衡点局部渐近稳定的条件。\n\n设物种丰度由向量 $\\mathbf{x} = (x_1, x_2, x_3)^{\\top}$ 表示。广义 Lotka-Volterra (GLV) 系统由下式给出\n$$\n\\frac{dx_{i}}{dt} = x_{i} \\left(r_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}\\right), \\quad i \\in \\{1, 2, 3\\}\n$$\n参数为 $r_{1}=r_{2}=r_{3}=r0$ 且相互作用矩阵为\n$$\nA = \\begin{pmatrix}\n-d  m  0 \\\\\nm  -d  m \\\\\n0  m  -d\n\\end{pmatrix}\n$$\n其中 $d0$ 且 $m \\ge 0$。\n\n通过令 $\\frac{d\\mathbf{x}}{dt} = \\mathbf{0}$，可以找到平衡解 $\\mathbf{x}^* = (x_1^*, x_2^*, x_3^*)^{\\top}$。我们寻求一个严格正平衡点，其中对于所有 $i \\in \\{1, 2, 3\\}$ 都有 $x_i^*  0$。对于这样的平衡点，条件简化为以下线性系统：\n$$\nr_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}^* = 0, \\quad \\text{for } i \\in \\{1, 2, 3\\}\n$$\n写成矩阵形式，即为 $A \\mathbf{x}^* = -\\mathbf{r}$，其中 $\\mathbf{r} = (r, r, r)^{\\top}$。方程组为：\n\\begin{align*}\n-d x_1^* + m x_2^* \\quad = -r \\quad (1) \\\\\nm x_1^* - d x_2^* + m x_3^* = -r \\quad (2) \\\\\nm x_2^* - d x_3^* = -r \\quad (3)\n\\end{align*}\n从方程 $(1)$ 和 $(3)$，我们得到 $d x_1^* - r = m x_2^* = d x_3^* - r$，这意味着 $d x_1^* = d x_3^*$。因为 $d0$，我们必有 $x_1^* = x_3^*$。从相互作用矩阵 $A$ 的结构来看，这种对称性是意料之中的。\n\n将 $x_3^* = x_1^*$ 代入方程 $(2)$ 得到 $2m x_1^* - d x_2^* = -r$。现在我们得到一个关于 $x_1^*$ 和 $x_2^*$ 的二元线性方程组：\n\\begin{align*}\n-d x_1^* + m x_2^* = -r \\\\\n2m x_1^* - d x_2^* = -r\n\\end{align*}\n解这个方程组，例如将第一个方程乘以 $d$，第二个方程乘以 $m$ 并相加，得到 $(-d^2 + 2m^2)x_1^* = -dr - mr = -r(d+m)$。这得出：\n$$\nx_1^* = \\frac{-r(d+m)}{2m^2 - d^2} = \\frac{r(d+m)}{d^2 - 2m^2}\n$$\n从 $x_1^* = x_3^*$，我们有 $x_3^* = \\frac{r(d+m)}{d^2 - 2m^2}$。现在，我们求解 $x_2^*$。从方程 $(1)$，有 $m x_2^* = d x_1^* - r$。\n$$\nm x_2^* = d \\left( \\frac{r(d+m)}{d^2 - 2m^2} \\right) - r = r \\left( \\frac{d(d+m)}{d^2 - 2m^2} - 1 \\right) = r \\left( \\frac{d^2+md - (d^2 - 2m^2)}{d^2 - 2m^2} \\right) = r \\frac{md+2m^2}{d^2 - 2m^2} = r \\frac{m(d+2m)}{d^2 - 2m^2}\n$$\n当 $m0$ 时，我们可以除以 $m$ 得到 $x_2^* = \\frac{r(d+2m)}{d^2 - 2m^2}$。如果 $m=0$，系统解耦，可以得到 $x_i^*=r/d  0$。推导出的公式与此极限情况一致。\n\n为使平衡点是严格正的 ($x_i^*  0$)，鉴于 $r0$, $d0$ 且 $m \\ge 0$，分子 $r(d+m)$ 和 $r(d+2m)$ 都是严格为正的。因此，正性条件完全取决于公共分母的符号：\n$$\nd^2 - 2m^2  0 \\implies d^2  2m^2\n$$\n由于 $d$ 和 $m$ 是非负的，这等价于 $d  \\sqrt{2} m$，或 $m  d/\\sqrt{2}$。\n\n接下来，我们分析该平衡点的局部渐近稳定性。稳定性由在平衡点 $\\mathbf{x}^*$ 处计算的雅可比矩阵 $J$ 的特征值决定。雅可比矩阵的元素为：\n$$\nJ_{ik}(\\mathbf{x}) = \\frac{\\partial \\dot{x}_i}{\\partial x_k} = \\delta_{ik}\\left(r_{i} + \\sum_{j=1}^{3} a_{ij} x_{j}\\right) + x_{i} a_{ik}\n$$\n在平衡点 $\\mathbf{x}^*$，括号中的项为零，所以雅可比矩阵为 $J^* = J(\\mathbf{x}^*)$，其元素为 $J_{ik}^* = x_i^* a_{ik}$。这可以写成矩阵形式 $J^* = D_x A$，其中 $D_x = \\text{diag}(x_1^*, x_2^*, x_3^*)$ 是一个对角元为正的对角矩阵。\n\n如果 $J^*$ 的所有特征值的实部都为负，则该平衡点是局部渐近稳定的。为了分析 $J^* = D_x A$ 的特征值，我们进行一个相似变换，该变换保持特征值不变。令 $D_x^{1/2} = \\text{diag}(\\sqrt{x_1^*}, \\sqrt{x_2^*}, \\sqrt{x_3^*})$。考虑矩阵 $S$：\n$$\nS = D_x^{1/2} A D_x^{1/2}\n$$\n雅可比矩阵 $J^*$ 与 $S$ 相似，因为 $S = D_x^{-1/2} J^* D_x^{1/2}$。由于 $A$ 是实对称矩阵，且 $D_x^{1/2}$ 是实的对角矩阵（因此也是对称的），矩阵 $S$ 也是实对称的：\n$$\nS^{\\top} = (D_x^{1/2} A D_x^{1/2})^{\\top} = (D_x^{1/2})^{\\top} A^{\\top} (D_x^{1/2})^{\\top} = D_x^{1/2} A D_x^{1/2} = S\n$$\n实对称矩阵只有实特征值。因此，$S$ 的特征值，也就是 $J^*$ 的特征值，都是实数。对于渐近稳定性，所有特征值必须严格为负。这等价于矩阵 $S$ 是负定矩阵的条件。\n\n矩阵 $S$ 是负定的，当且仅当对于所有非零向量 $\\mathbf{z}$，都有 $\\mathbf{z}^{\\top} S \\mathbf{z}  0$。代入 $S$ 的定义：\n$$\n\\mathbf{z}^{\\top} (D_x^{1/2} A D_x^{1/2}) \\mathbf{z}  0\n$$\n令 $\\mathbf{y} = D_x^{1/2} \\mathbf{z}$。由于 $D_x^{1/2}$ 是可逆的，$\\mathbf{y}$ 是非零向量当且仅当 $\\mathbf{z}$ 是非零向量。条件变为：\n$$\n\\mathbf{y}^{\\top} A \\mathbf{y}  0\n$$\n对于所有非零向量 $\\mathbf{y}$。这正是矩阵 $A$ 是负定的定义。\n\n为了确定对称矩阵 $A$ 何时是负定的，我们将西尔维斯特准则应用于矩阵 $-A$。矩阵 $-A$ 必须是正定的，这意味着它的所有顺序主子式都必须严格为正。\n$$\n-A = \\begin{pmatrix}\nd  -m  0 \\\\\n-m  d  -m \\\\\n0  -m  d\n\\end{pmatrix}\n$$\n第一个顺序主子式是 $\\Delta_1 = d$。条件是 $\\Delta_1  0$，而已知 $d0$。\n第二个顺序主子式是：\n$$\n\\Delta_2 = \\det \\begin{pmatrix} d  -m \\\\ -m  d \\end{pmatrix} = d^2 - m^2\n$$\n条件是 $\\Delta_2  0$，这意味着 $d^2  m^2$，或者因为 $d, m \\ge 0$，所以 $d  m$。\n第三个顺序主子式是 $\\Delta_3 = \\det(-A)$：\n$$\n\\Delta_3 = d(d^2 - m^2) - (-m)(-md) = d^3 - dm^2 - dm^2 = d^3 - 2dm^2 = d(d^2 - 2m^2)\n$$\n条件是 $\\Delta_3  0$。因为 $d0$，这可以简化为 $d^2 - 2m^2  0$，即 $d  \\sqrt{2} m$。\n\n稳定性的条件集是 $\\{d0, dm, d\\sqrt{2} m\\}$。由于 $\\sqrt{2} \\approx 1.414  1$，条件 $d  \\sqrt{2} m$ 是最严格的，并且它蕴含了 $dm$。因此，局部渐近稳定的条件是 $m  d/\\sqrt{2}$。\n\n值得注意的是，严格正平衡点存在的条件 ($m  d/\\sqrt{2}$) 与其局部渐近稳定的条件是相同的。因此，系统存在一个严格正的、局部渐近稳定的平衡点，当且仅当 $0 \\le m  d/\\sqrt{2}$。\n\n问题要求的是最大值 $m_{\\max}$，使得对于区间 $0 \\le m  m_{\\max}$ 中的每一个 $m$，所期望的平衡点都存在且稳定。从我们推导出的条件 $0 \\le m  d/\\sqrt{2}$，我们可以直接确定 $m_{\\max}$。\n$$\nm_{\\max} = \\frac{d}{\\sqrt{2}}\n$$", "answer": "$$\\boxed{\\frac{d}{\\sqrt{2}}}$$", "id": "2510887"}, {"introduction": "在掌握了基础系统的分析方法后，我们将把目光投向更复杂的网络结构。这个练习探讨了网络拓扑结构如何决定整个群落的动态稳定性。通过分析一个典型的双边互利网络，你将发现网络的相互作用矩阵的一个关键谱属性——最大奇异值——如何设定了系统稳定性的临界阈值 [@problem_id:2510923]。这项实践将理论与网络结构联系起来，揭示了增加互利作用强度并非总是有益的，过强的互利可能反而导致系统崩溃。", "problem": "考虑一个由两个功能团（植物和传粉者）组成的互惠群落，该群落由广义Lotka-Volterra (GLV) 方程建模。设植物的丰度为 $x_{i}$（$i \\in \\{1,2\\}$），传粉者的丰度为 $y_{j}$（$j \\in \\{1,2\\}$）。功能团之间的单位个体相互作用结构由一个二分邻接矩阵 $W \\in \\mathbb{R}^{2 \\times 2}$ 给出，其中如果植物 $i$ 和传粉者 $j$ 相互作用，则 $W_{ij} = 1$，否则 $W_{ij} = 0$。假设\n$$\nW \\;=\\; \\begin{pmatrix}\n1  1 \\\\\n1  1\n\\end{pmatrix}.\n$$\n假设每个功能团内部的种内自我调节作用相同：植物的自我调节强度为 $d_{1} = 1$，传粉者的自我调节强度为 $d_{2} = 1$。互惠效应具有统一的强度 $\\gamma  0$，并且仅在功能团之间起作用，因此功能团之间的净相互作用系数分别为 $\\gamma W$ 和 $\\gamma W^{\\top}$。假设存在一个可行的内部平衡点，其物种丰度是均匀的，$x_{i}^{*} = 1$ 和 $y_{j}^{*} = 1$，这可以通过设置适当的内禀增长率来保证。\n\n从局部稳定性分析的第一性原理出发（在平衡点进行线性化，并要求雅可比矩阵的所有特征值都具有负实部），完成以下任务：\n\n1. 计算 $W$ 的最大奇异值。\n2. 仅使用线性化和分块矩阵的谱性质，确定当 $\\gamma$ 增加时，内部平衡点失去局部稳定性的精确阈值互惠强度 $\\gamma_{c}$。\n\n用 $\\gamma_{c}$ 的精确值（不要四舍五入）表示你的最终答案。最终答案仅报告 $\\gamma_{c}$ 的值。", "solution": "该问题已经过验证，被认为是有效的。它具有科学依据，问题陈述清晰，客观，并包含足够的信息以获得唯一解。\n\n该互惠群落的动力学由广义Lotka-Volterra (GLV) 方程描述。设 $\\mathbf{x} = (x_1, x_2)^\\top$ 为植物丰度向量，$\\mathbf{y} = (y_1, y_2)^\\top$ 为传粉者丰度向量。微分方程组为：\n$$\n\\frac{dx_i}{dt} = x_i \\left( r_i - d_1 x_i + \\gamma \\sum_{j=1}^{2} W_{ij} y_j \\right) \\quad \\text{对于 } i \\in \\{1, 2\\}\n$$\n$$\n\\frac{dy_j}{dt} = y_j \\left( s_j - d_2 y_j + \\gamma \\sum_{i=1}^{2} W_{ji}^\\top x_i \\right) \\quad \\text{对于 } j \\in \\{1, 2\\}\n$$\n其中 $r_i$ 和 $s_j$ 是内禀增长率，$d_1 = 1$ 和 $d_2 = 1$ 是种内自我调节强度，$\\gamma  0$ 是互惠强度，$W$ 是相互作用矩阵。问题陈述存在一个内部平衡点，位于 $\\mathbf{x}^* = (1, 1)^\\top$ 和 $\\mathbf{y}^* = (1, 1)^\\top$。\n\n该平衡点的局部稳定性由在该点计算的雅可比矩阵 $J$ 的特征值决定。对于完整的四维系统 $\\mathbf{z} = (\\mathbf{x}^\\top, \\mathbf{y}^\\top)^\\top$，其雅可比矩阵是一个分块矩阵：\n$$\nJ = \\begin{pmatrix}\nJ_{xx}  J_{xy} \\\\\nJ_{yx}  J_{yy}\n\\end{pmatrix}\n$$\n这些分块矩阵的元素是通过计算增长率函数的偏导数，并在平衡点 $\\mathbf{z}^* = (\\mathbf{1}^\\top, \\mathbf{1}^\\top)^\\top$ 处求值得到的。\n\n设 $F_i = \\frac{dx_i}{dt}$ 和 $G_j = \\frac{dy_j}{dt}$。\n植物的种内相互作用分块矩阵为：\n$$\n(J_{xx})_{ik} = \\frac{\\partial F_i}{\\partial x_k}\\bigg|_{\\mathbf{z}^*} = \\delta_{ik}\\left(r_i - d_1 x_i + \\gamma \\sum_j W_{ij} y_j\\right)\\bigg|_{\\mathbf{z}^*} + x_i(-d_1 \\delta_{ik})\\bigg|_{\\mathbf{z}^*}\n$$\n在平衡点，括号中的项为零。因此，$(J_{xx})_{ik} = x_i^*(-d_1 \\delta_{ik}) = -d_1 \\delta_{ik}$。这给出了分块矩阵 $J_{xx} = -d_1 I_2 = -I_2$，其中 $I_2$ 是 $2 \\times 2$ 单位矩阵。\n\n类似地，对于传粉者，$J_{yy} = -d_2 I_2 = -I_2$。\n\n种间相互作用分块矩阵为：\n$$\n(J_{xy})_{ij} = \\frac{\\partial F_i}{\\partial y_j}\\bigg|_{\\mathbf{z}^*} = (x_i \\gamma W_{ij})\\big|_{\\mathbf{z}^*} = x_i^* \\gamma W_{ij} = \\gamma W_{ij}\n$$\n这给出了分块矩阵 $J_{xy} = \\gamma W$。\n$$\n(J_{yx})_{ji} = \\frac{\\partial G_j}{\\partial x_i}\\bigg|_{\\mathbf{z}^*} = (y_j \\gamma W_{ji}^\\top)\\big|_{\\mathbf{z}^*} = y_j^* \\gamma W_{ji}^\\top = \\gamma W_{ji}^\\top\n$$\n这给出了分块矩阵 $J_{yx} = \\gamma W^\\top$。\n\n完整的雅可比矩阵是：\n$$\nJ = \\begin{pmatrix} -I_2  \\gamma W \\\\ \\gamma W^\\top  -I_2 \\end{pmatrix}\n$$\n问题陈述 $W = \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}$，这是一个对称矩阵，所以 $W^\\top = W$。\n$$\nJ = \\begin{pmatrix} -I_2  \\gamma W \\\\ \\gamma W  -I_2 \\end{pmatrix}\n$$\n当且仅当 $J$ 的所有特征值 $\\lambda$ 都具有负实部，即 $\\text{Re}(\\lambda)  0$ 时，该平衡点是局部稳定的。我们通过求解特征向量方程 $J\\mathbf{v} = \\lambda\\mathbf{v}$ 来找到特征值。设特征向量被分块为 $\\mathbf{v} = (\\mathbf{u}^\\top, \\mathbf{w}^\\top)^\\top$。\n$$\n\\begin{pmatrix} -I_2  \\gamma W \\\\ \\gamma W  -I_2 \\end{pmatrix} \\begin{pmatrix} \\mathbf{u} \\\\ \\mathbf{w} \\end{pmatrix} = \\lambda \\begin{pmatrix} \\mathbf{u} \\\\ \\mathbf{w} \\end{pmatrix}\n$$\n这产生了一个包含两个方程的系统：\n$$\n-\\mathbf{u} + \\gamma W \\mathbf{w} = \\lambda \\mathbf{u} \\implies (\\lambda + 1)\\mathbf{u} = \\gamma W \\mathbf{w}\n$$\n$$\n\\gamma W \\mathbf{u} - \\mathbf{w} = \\lambda \\mathbf{w} \\implies (\\lambda + 1)\\mathbf{w} = \\gamma W \\mathbf{u}\n$$\n将第一个方程代入第二个方程：\n$$\n(\\lambda + 1)\\mathbf{w} = \\gamma W \\left( \\frac{\\gamma}{\\lambda + 1} W \\mathbf{w} \\right) = \\frac{\\gamma^2}{(\\lambda + 1)} W^2 \\mathbf{w}\n$$\n假设 $\\lambda \\neq -1$，我们可以写出：\n$$\n(\\lambda+1)^2 \\mathbf{w} = \\gamma^2 W^2 \\mathbf{w}\n$$\n这意味着 $(\\lambda+1)^2 / \\gamma^2$ 必须是 $W^2$ 的一个特征值。设 $\\mu_k$ 是 $W$ 的特征值。那么 $W^2$ 的特征值是 $\\mu_k^2$。因此：\n$$\n\\frac{(\\lambda+1)^2}{\\gamma^2} = \\mu_k^2 \\implies (\\lambda+1)^2 = \\gamma^2 \\mu_k^2 \\implies \\lambda+1 = \\pm \\gamma \\mu_k\n$$\n所以，雅可比矩阵的特征值由 $\\lambda = -1 \\pm \\gamma \\mu_k$ 给出。\n\n更一般地，对于雅可比矩阵 $J = \\begin{pmatrix} -d_1 I  \\gamma W \\\\ \\gamma W^\\top  -d_2 I \\end{pmatrix}$，其特征值 $\\lambda$ 与 $W$ 的奇异值 $\\sigma$（其中 $\\sigma^2$ 是 $W^\\top W$ 的特征值）通过以下特征方程相关联：\n$$\n(\\lambda+d_1)(\\lambda+d_2) = \\gamma^2 \\sigma^2\n$$\n在我们的例子中，$d_1=d_2=1$ 且 $W=W^\\top$，所以 $\\sigma_k = |\\mu_k|$，该关系简化为 $(\\lambda+1)^2 = \\gamma^2 \\mu_k^2$，这与我们直接推导的结果一致。\n\n问题要求我们首先计算 $W$ 的最大奇异值。$W$ 的奇异值 $\\sigma$ 是 $W^\\top W$ 的特征值的平方根。\n给定 $W = \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}$，我们有 $W^\\top W = W^2 = \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 2  2 \\\\ 2  2 \\end{pmatrix}$。\n$W^2$ 的特征值（记为 $\\nu$）可以通过求解 $\\det(W^2 - \\nu I) = 0$ 找到：\n$$\n\\det\\begin{pmatrix} 2-\\nu  2 \\\\ 2  2-\\nu \\end{pmatrix} = (2-\\nu)^2 - 4 = 0\n$$\n$$\n(2-\\nu-2)(2-\\nu+2) = (-\\nu)(4-\\nu) = 0\n$$\n$W^2$ 的特征值是 $\\nu_1 = 0$ 和 $\\nu_2 = 4$。\n$W$ 的奇异值是 $\\sigma_1 = \\sqrt{0} = 0$ 和 $\\sigma_2 = \\sqrt{4} = 2$。\n最大奇异值为 $\\sigma_{\\max}(W) = 2$。\n\n现在我们确定稳定性阈值。$J$ 的特征值由公式 $\\lambda = -1 \\pm \\gamma \\mu_k$ 给出，其中 $\\mu_k$ 是 $W$ 的特征值。因为 $W$ 是对称且非负的，它的最大特征值 $\\mu_{\\max}$ 等于其最大奇异值 $\\sigma_{\\max}(W)$，所以 $\\mu_{\\max}=2$。另一个特征值是 $\\mu_{\\min}=0$。\n$J$ 的特征值集合是：\n- 对于 $\\mu_1=0$：$\\lambda = -1 \\pm \\gamma(0) = -1$。该特征值对应两个特征向量，因此其重数为2。它总是负的。\n- 对于 $\\mu_2=2$：$\\lambda = -1 \\pm \\gamma(2)$。这给出了两个特征值：$\\lambda_3 = -1 - 2\\gamma$ 和 $\\lambda_4 = -1 + 2\\gamma$。\n\n$J$ 的特征值是 $\\{-1, -1, -1-2\\gamma, -1+2\\gamma\\}$。\n为了保证稳定性，所有特征值必须为负。由于 $\\gamma  0$，特征值 $-1$ 和 $-1-2\\gamma$ 总是负的。系统的稳定性由最大特征值 $\\lambda_{\\max} = -1 + 2\\gamma$ 的符号决定。\n当 $\\lambda_{\\max}  0$ 时，系统是稳定的：\n$$\n-1 + 2\\gamma  0 \\implies 2\\gamma  1 \\implies \\gamma  \\frac{1}{2}\n$$\n系统在临界值 $\\gamma_c$ 处失去稳定性，此时最大特征值变为零。\n$$\n-1 + 2\\gamma_c = 0 \\implies \\gamma_c = \\frac{1}{2}\n$$\n这个结果可以推广。对于 $d_1, d_2  0$，稳定性阈值为 $\\gamma_c = \\frac{\\sqrt{d_1 d_2}}{\\sigma_{\\max}(W)}$。在本问题中，$d_1=1$，$d_2=1$，且 $\\sigma_{\\max}(W)=2$，我们确认：\n$$\n\\gamma_c = \\frac{\\sqrt{1 \\cdot 1}}{2} = \\frac{1}{2}\n$$\n在 $\\gamma=\\gamma_c$ 时，一个实特征值穿过零，导致鞍-节分岔，此时平衡点通常会崩溃。", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "2510923"}, {"introduction": "最后一个练习将理论分析与实际应用相结合，解决一个生态管理中的核心问题：如何最有效地干预一个网络以增强其稳定性？本练习将引导你使用矩阵微扰理论中的一个强大工具——特征值敏感性分析。通过编写代码，你将学会识别一个复杂生态系统中的“杠杆点”，即那些对系统稳定性影响最大的相互作用，从而为精准的生态管理和恢复策略提供科学依据 [@problem_id:2510908]。", "problem": "给定代表生态网络群落雅可比矩阵（群落矩阵）的实数方阵，其中对角线元素编码自我调节，非对角线元素编码种间相互作用的净效应。局部稳定性由主特征值决定，该特征值定义为具有最大实部的特征值。考虑由一个二元掩码选择的相互作用系数子集的一个微小的一阶（无穷小）变化。您的任务是为每个测试用例计算单位弗罗贝尼乌斯范数的容许扰动方向，该方向最有效地使主特征值的实部一阶减小，并报告相应的最大瞬时减小值。\n\n需要使用的基本原理包括：矩阵的特征值和左/右特征向量的定义，以及单特征值的一阶矩阵扰动理论。假设在所有提供的案例中，主特征值都是单特征值。设主特征值的实部表示为 $\\Re\\{\\lambda_{\\max}(A)\\}$。设 $A \\in \\mathbb{R}^{n \\times n}$ 表示群落矩阵，设 $M \\in \\{0,1\\}^{n \\times n}$ 是指定哪些元素可以被改变的二元掩码。您必须限制扰动 $\\Delta \\in \\mathbb{R}^{n \\times n}$ 以同时满足两个约束：(i) 元素级支撑约束 $M \\odot \\Delta = \\Delta$（只有掩码值为 $1$ 的元素可以为非零），以及 (ii) 单位弗罗贝尼乌斯范数约束 $\\|\\Delta\\|_{\\mathrm{F}} = 1$。在所有这样的 $\\Delta$ 中，计算在 $A$ 处产生 $\\Re\\{\\lambda_{\\max}(A)\\}$ 最大瞬时减小（最负的一阶方向导数）的方向，并报告这个最大瞬时减小的值。如果没有元素被允许改变（掩码全为零），则容许方向为零矩阵，报告的值必须为 $0$。\n\n角度单位不适用。没有物理单位。所有输出必须是实数。\n\n测试套件。对于下面的每个测试用例，$A$ 是群落矩阵，$M$ 是容许元素的二元掩码：\n- 测试用例 1（类互惠网络；只有非对角线元素可变）：\n  - $A_1 = \\begin{bmatrix} -0.5  0.3  0.2 \\\\ 0.4  -0.6  0.1 \\\\ 0.2  0.15  -0.4 \\end{bmatrix}$\n  - $M_1 = \\begin{bmatrix} 0  1  1 \\\\ 1  0  1 \\\\ 1  1  0 \\end{bmatrix}$\n- 测试用例 2（类营养网络；只有指定的跨功能群链接子集可变）：\n  - $A_2 = \\begin{bmatrix} -0.7  0.0  -0.9  0.0 \\\\ 0.3  -0.5  0.0  -0.6 \\\\ 0.8  0.0  -0.9  0.0 \\\\ 0.0  0.7  0.2  -0.4 \\end{bmatrix}$\n  - $M_2$ 在位置 $(0,2)$、$(1,3)$、$(3,2)$ 处为1，其他位置为0，即\n    $M_2 = \\begin{bmatrix} 0  0  1  0 \\\\ 0  0  0  1 \\\\ 0  0  0  0 \\\\ 0  0  1  0 \\end{bmatrix}$\n- 测试用例 3（无容许变化；掩码全为零）：\n  - $A_3 = \\begin{bmatrix} -0.3  0.2  0.0 \\\\ 0.1  -0.4  0.1 \\\\ 0.0  0.2  -0.5 \\end{bmatrix}$\n  - $M_3 = \\begin{bmatrix} 0  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{bmatrix}$\n- 测试用例 4（捕食者-被捕食者振荡子系统；只有该子系统可变）：\n  - $A_4 = \\begin{bmatrix} -0.1  -1.2  0.0 \\\\ 1.5  -0.1  0.0 \\\\ 0.0  0.0  -0.8 \\end{bmatrix}$\n  - $M_4 = \\begin{bmatrix} 1  1  0 \\\\ 1  1  0 \\\\ 0  0  0 \\end{bmatrix}$\n\n精确的计算要求：\n- 设 $\\lambda_{\\max}(A)$ 表示 $A$ 的具有最大实部的特征值。如果实部存在并列，则可以使用任何一个并列的特征值；提供的测试套件避免了精确并列的情况。\n- 计算 $\\Re\\{\\lambda_{\\max}(A)\\}$ 在 $A$ 处沿容许方向的一阶方向导数，并选择单位弗罗贝尼乌斯范数的容许方向，以最小化该导数（即给出最大的瞬时减小）。\n- 为每个测试用例报告这个最小化的方向导数的值（一个实数 $\\le 0$）。如果 $M$ 是零掩码，则报告 $0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按顺序排列的测试用例结果，格式为逗号分隔的列表，并用方括号括起来，例如 $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$。\n- 每个 $\\text{result}_k$ 必须是一个浮点数，表示单位弗罗贝尼乌斯范数容许扰动下 $\\Re\\{\\lambda_{\\max}(A_k)\\}$ 的最大瞬时减小值。", "solution": "该问题被评估为有效，因为它在科学上基于生态网络稳定性分析和矩阵扰动理论的既定原则，具有明确的目标和约束，是良构的，并以精确、客观的数学语言表达。\n\n目标是找到在无穷小扰动 $\\Delta \\in \\mathbb{R}^{n \\times n}$ 下，群落矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的主特征值实部 $\\Re\\{\\lambda_{\\max}(A)\\}$ 的最大瞬时减小率。这等价于找到 $\\Re\\{\\lambda_{\\max}(A)\\}$ 在容许扰动 $\\Delta$ 方向上的方向导数的最小值。容许扰动受两个条件约束：\n1.  支撑约束：扰动只能影响 $A$ 中二元掩码 $M \\in \\{0,1\\}^{n \\times n}$ 为非零的元素。这表示为 $M \\odot \\Delta = \\Delta$，其中 $\\odot$ 表示逐元素的哈达玛积。\n2.  归一化约束：扰动必须具有单位弗罗贝尼乌斯范数，即 $\\|\\Delta\\|_{\\mathrm{F}} = 1$。\n\n解决方案通过使用一阶矩阵扰动理论推导出该最小值的显式表达式。\n\n设 $\\lambda$ 是矩阵 $A$ 的一个单特征值，其对应的右特征向量为 $v$，左特征向量为 $w$。它们由以下关系定义：\n$$Av = \\lambda v$$\n$$w^T A = \\lambda w^T$$\n第二个方程等价于 $A^T w = \\lambda w$。问题陈述保证对于所有给定的测试用例，主特征值 $\\lambda_{\\max}(A)$ 都是单特征值。\n\n根据一阶扰动理论，由于矩阵 $A$ 的无穷小扰动 $dA$，特征值 $\\lambda$ 的变化由下式给出：\n$$d\\lambda = \\frac{w^T (dA) v}{w^T v}$$\n对于单特征值，这个归一化因子 $w^T v$ 非零。\n\n为了找到最大减小率，我们将其表述为方向导数。$\\lambda$ 在 $A$ 处沿矩阵 $\\Delta$ 方向的方向导数为：\n$$D_{\\Delta}\\lambda(A) = \\frac{w^T \\Delta v}{w^T v}$$\n我们可以将此导数表示为弗罗贝尼乌斯内积，$\\langle X, Y \\rangle_{\\mathrm{F}} = \\text{tr}(X^T Y)$。项 $w^T \\Delta v$ 可以写为：\n$$w^T \\Delta v = \\sum_{i,j} w_i \\Delta_{ij} v_j = \\sum_{i,j} (w_i v_j) \\Delta_{ij} = \\text{tr}((v w^T)^T \\Delta) = \\langle w v^T, \\Delta \\rangle_{\\mathrm{F}}$$\n因此，方向导数为：\n$$D_{\\Delta}\\lambda(A) = \\frac{\\langle w v^T, \\Delta \\rangle_{\\mathrm{F}}}{w^T v} = \\left\\langle \\frac{w v^T}{w^T v}, \\Delta \\right\\rangle_{\\mathrm{F}}$$\n这表明特征值 $\\lambda$ 相对于矩阵 $A_{ij}$ 的梯度是 $\\frac{\\partial\\lambda}{\\partial A_{ij}} = \\frac{w_i v_j}{w^T v}$，因此梯度矩阵为 $\\nabla_A \\lambda = \\frac{w v^T}{w^T v}$。\n所以 $D_{\\Delta}\\lambda(A) = \\langle \\nabla_A \\lambda, \\Delta \\rangle_{\\mathrm{F}} = \\sum_{i,j} (\\nabla_A \\lambda)_{ij} \\Delta_{ij}$。\n\n我们的任务是最小化主特征值 $\\lambda_{\\max}$ 实部的方向导数。由于扰动 $\\Delta$ 是实矩阵，我们有：\n$$D_{\\Delta}\\Re\\{\\lambda_{\\max}\\} = \\Re\\{D_{\\Delta}\\lambda_{\\max}\\} = \\Re\\{\\langle \\nabla_A \\lambda_{\\max}, \\Delta \\rangle_{\\mathrm{F}}\\} = \\langle \\Re\\{\\nabla_A \\lambda_{\\max}\\}, \\Delta \\rangle_{\\mathrm{F}}$$\n设 $G = \\Re\\{\\nabla_A \\lambda_{\\max}\\} = \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\}$，其中 $v$ 和 $w$ 对应于 $\\lambda_{\\max}$。目标是在给定约束下最小化 $\\langle G, \\Delta \\rangle_{\\mathrm{F}}$。\n\n支撑约束 $M \\odot \\Delta = \\Delta$ 限制了搜索空间。我们可以将其纳入目标函数：\n$$\\langle G, \\Delta \\rangle_{\\mathrm{F}} = \\langle G, M \\odot \\Delta \\rangle_{\\mathrm{F}} = \\langle M \\odot G, \\Delta \\rangle_{\\mathrm{F}}$$\n设 $G' = M \\odot G$。问题简化为在 $\\|\\Delta\\|_{\\mathrm{F}} = 1$ 的约束下最小化 $\\langle G', \\Delta \\rangle_{\\mathrm{F}}$。\n\n根据柯西-施瓦茨不等式，对于任意两个矩阵 $X$ 和 $Y$，我们有 $|\\langle X, Y \\rangle_{\\mathrm{F}}| \\le \\|X\\|_{\\mathrm{F}} \\|Y\\|_{\\mathrm{F}}$。当 $\\Delta$ 的方向与 $G'$ 完全相反时，内积达到最小值：\n$$\\Delta_{\\text{opt}} = -\\frac{G'}{\\|G'\\|_{\\mathrm{F}}}$$\n方向导数的最小值为：\n$$\\min_{\\Delta} \\langle G', \\Delta \\rangle_{\\mathrm{F}} = \\left\\langle G', -\\frac{G'}{\\|G'\\|_{\\mathrm{F}}} \\right\\rangle_{\\mathrm{F}} = -\\frac{\\|G'\\|_{\\mathrm{F}}^2}{\\|G'\\|_{\\mathrm{F}}} = -\\|G'\\|_{\\mathrm{F}}$$\n如果 $G'$ 是零矩阵（如果 $M$ 是零矩阵，则会发生这种情况），则范数为 $0$，最小值为 $0$。\n\n因此，最大瞬时减小的最终表达式为：\n$$-\\|G'\\|_{\\mathrm{F}} = -\\left\\| M \\odot \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\} \\right\\|_{\\mathrm{F}}$$\n其中 $v$ 和 $w$ 分别是对应于矩阵 $A$ 的主特征值 $\\lambda_{\\max}$ 的右特征向量和左特征向量。\n\n每个测试用例 $(A, M)$ 的计算过程如下：\n1.  如果掩码 $M$ 是零矩阵，结果为 $0.0$。\n2.  计算 $A$ 的特征值和右特征向量。识别主特征值 $\\lambda_{\\max}$（具有最大实部的那个）及其对应的右特征向量 $v$。\n3.  计算转置矩阵 $A^T$ 的特征值和右特征向量。特征值将与 $A$ 的相同。识别 $A^T$ 的对应于 $\\lambda_{\\max}$ 的特征向量 $w$。这个 $w$ 就是 $A$ 的左特征向量。\n4.  计算梯度矩阵 $G = \\Re\\left\\{\\frac{w v^T}{w^T v}\\right\\}$。请注意，如果 $\\lambda_{\\max}$ 是复数，则标量积 $w^T v$ 和外积 $w v^T$ 必须处理复数值向量。数值库返回的特征向量通常是归一化的，但分母 $w^T v$ 对于梯度的正确定标至关重要，并且通常不等于 $1$。\n5.  将掩码应用于梯度矩阵：$G' = M \\odot G$。\n6.  计算掩码后梯度的弗罗贝尼乌斯范数 $\\|G'\\|_{\\mathrm{F}}$。\n7.  最终结果是该范数的负值，即 $-\\|G'\\|_{\\mathrm{F}}$。该值保证小于或等于零。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all defined test cases and prints the results.\n    \"\"\"\n\n    def calculate_max_decrease(A, M):\n        \"\"\"\n        Computes the maximal instantaneous decrease of the real part of the \n        dominant eigenvalue of matrix A, for admissible perturbations defined by mask M.\n\n        Args:\n            A (np.ndarray): The square community matrix.\n            M (np.ndarray): The binary mask of admissible perturbations.\n\n        Returns:\n            float: The minimal value of the directional derivative, which represents\n                   the maximal instantaneous decrease (a non-positive number).\n        \"\"\"\n        # If the mask M is all zeros, no changes are allowed. The derivative is 0.\n        if not np.any(M):\n            return 0.0\n\n        # Step 1: Compute eigenvalues and right eigenvectors of A.\n        eigvals, right_eigvecs = np.linalg.eig(A)\n\n        # Step 2: Identify the dominant eigenvalue (largest real part) and its right eigenvector.\n        dominant_idx = np.argmax(eigvals.real)\n        lambda_max = eigvals[dominant_idx]\n        v = right_eigvecs[:, dominant_idx]\n\n        # Step 3: Compute the corresponding left eigenvector. This is the right\n        # eigenvector of A.T corresponding to the same eigenvalue lambda_max.\n        eigvals_T, left_eigvecs = np.linalg.eig(A.T)\n        \n        # Find the index of the eigenvalue in the transposed system that is closest to lambda_max.\n        # This handles potential floating point inaccuracies or reordering of eigenvalues.\n        left_dominant_idx = np.argmin(np.abs(eigvals_T - lambda_max))\n        w = left_eigvecs[:, left_dominant_idx]\n\n        # Step 4: Calculate the gradient of the eigenvalue with respect to an entry A_ij.\n        # The gradient matrix is G = (w v^T) / (w^T v).\n        w_dot_v = np.dot(w.conj(), v) # Using conjugate for generality, although w is real here.\n        \n        # The problem statement guarantees a simple eigenvalue, so w_dot_v is non-zero.\n        # For a robust implementation, one could check if np.isclose(w_dot_v, 0),\n        # but it is not necessary for the given problem constraints.\n        grad_lambda = np.outer(w.conj(), v) / w_dot_v\n\n        # Step 5: We are interested in the derivative of the real part of the eigenvalue.\n        # For a real perturbation Delta, this is controlled by the real part of the gradient.\n        real_grad = grad_lambda.real\n\n        # Step 6: Apply the binary mask M to the gradient. This restricts the perturbation\n        # direction to the subspace of admissible changes.\n        masked_grad = M * real_grad\n\n        # Step 7: The maximal instantaneous decrease is the minimum value of the directional\n        # derivative, which equals the negative of the Frobenius norm of the masked gradient.\n        norm_masked_grad = np.linalg.norm(masked_grad, 'fro')\n\n        return -norm_masked_grad\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        (np.array([[-0.5, 0.3, 0.2], \n                   [0.4, -0.6, 0.1], \n                   [0.2, 0.15, -0.4]]),\n         np.array([[0, 1, 1], \n                   [1, 0, 1], \n                   [1, 1, 0]])),\n        # Test case 2\n        (np.array([[-0.7, 0.0, -0.9, 0.0], \n                   [0.3, -0.5, 0.0, -0.6], \n                   [0.8, 0.0, -0.9, 0.0], \n                   [0.0, 0.7, 0.2, -0.4]]),\n         np.array([[0, 0, 1, 0], \n                   [0, 0, 0, 1], \n                   [0, 0, 0, 0], \n                   [0, 0, 1, 0]])),\n        # Test case 3\n        (np.array([[-0.3, 0.2, 0.0], \n                   [0.1, -0.4, 0.1], \n                   [0.0, 0.2, -0.5]]),\n         np.array([[0, 0, 0], \n                   [0, 0, 0], \n                   [0, 0, 0]])),\n        # Test case 4\n        (np.array([[-0.1, -1.2, 0.0], \n                   [1.5, -0.1, 0.0], \n                   [0.0, 0.0, -0.8]]),\n         np.array([[1, 1, 0], \n                   [1, 1, 0], \n                   [0, 0, 0]]))\n    ]\n\n    results = []\n    for A, M in test_cases:\n        result = calculate_max_decrease(A, M)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "2510908"}]}