{"hands_on_practices": [{"introduction": "在微生物生态学中，一个基本问题是“这个群落有多多样化？”。虽然香农熵（Shannon entropy）等传统指数被广泛使用，但其单位（“奈特”或“比特”）并不直观。本练习将引导您将香农熵转换为一个更易于解释的度量——“有效物种数”或“真多样性”（true diversity），它将多样性以等丰度物种数量的形式呈现，从而提供了一种更清晰、更具可比性的方式来理解群落结构。[@problem_id:2509172]", "problem": "对一个珊瑚全息生物（即动物宿主及其相关的微生物共生体）进行取样，以量化其肠道微生物组的宿主内（α）多样性。观察到四个优势细菌扩增子序列变体 (ASV)，其计数分别为 $[40, 30, 20, 10]$，总计 $100$ 个读数。将这些计数视为单个宿主内每个ASV的个体丰度，并假设所有读数都已正确分配给这四个ASV。\n\n使用基于香农熵（使用自然对数以自然单位测量）和希尔数框架的α多样性信息论定义，计算该样本的阶数 $q=1$ 的有效物种数（记为 ${}^{1}D$）。将最终答案表示为一个纯数（无量纲），并将结果四舍五入至四位有效数字。", "solution": "审阅题目陈述后，确认其有效。它在生态学理论上有科学依据，数学上是适定的，并为获得唯一解提供了所有必要数据。我们可以进行计算。\n\n该问题要求根据一组给定的扩增子序列变体 (ASV) 计数，计算阶数 $q=1$ 的有效物种数，记为 ${}^{1}D$。该量是希尔数多样性指数家族的一员。希尔数或称 $q$ 阶真实多样性的一般公式为：\n$$\n{}^{q}D = \\left( \\sum_{i=1}^{S} p_i^q \\right)^{\\frac{1}{1-q}}\n$$\n其中 $S$ 是物种总数（在本例中为ASV），$p_i$ 是第 $i$ 个物种的相对丰度。\n\n给定的四个ASV的计数为 $n_1 = 40$，$n_2 = 30$，$n_3 = 20$ 和 $n_4 = 10$。读数总数 $N$ 是这些计数的总和：\n$$\nN = \\sum_{i=1}^{4} n_i = 40 + 30 + 20 + 10 = 100\n$$\n这与题目陈述中提供的值一致。ASV的数量为 $S=4$。\n\n相对丰度 $p_i = n_i/N$ 的计算如下：\n$$\np_1 = \\frac{40}{100} = 0.4\n$$\n$$\np_2 = \\frac{30}{100} = 0.3\n$$\n$$\np_3 = \\frac{20}{100} = 0.2\n$$\n$$\np_4 = \\frac{10}{100} = 0.1\n$$\n这些相对丰度的总和必须等于1：$\\sum_{i=1}^{4} p_i = 0.4 + 0.3 + 0.2 + 0.1 = 1.0$。\n\n由于指数中存在 $1/(1-q)$ 项，${}^{q}D$ 的一般公式在 $q=1$ 时是未定义的。为了求得 ${}^{1}D$ 的值，我们必须计算当 $q \\to 1$ 时该表达式的极限。该极限得出的结果与香农熵有关。香农熵 $H'$ 定义为：\n$$\nH' = - \\sum_{i=1}^{S} p_i \\ln(p_i)\n$$\n阶数 $q=1$ 的希尔数是香农熵的指数：\n$$\n{}^{1}D = \\lim_{q \\to 1} {}^{q}D = \\exp(H') = \\exp\\left(-\\sum_{i=1}^{S} p_i \\ln(p_i)\\right)\n$$\n这个度量 ${}^{1}D$ 被解释为：要产生与观测样本相同的香农熵值，所需的所有物种丰度均等时的物种数量。\n\n现在我们根据指定的自然对数，计算给定相对丰度的香农熵 $H'$。\n$$\nH' = - \\left( p_1 \\ln(p_1) + p_2 \\ln(p_2) + p_3 \\ln(p_3) + p_4 \\ln(p_4) \\right)\n$$\n$$\nH' = - \\left( 0.4 \\ln(0.4) + 0.3 \\ln(0.3) + 0.2 \\ln(0.2) + 0.1 \\ln(0.1) \\right)\n$$\n对各项进行数值计算：\n$$\n0.4 \\ln(0.4) \\approx 0.4 \\times (-0.9162907) \\approx -0.3665163\n$$\n$$\n0.3 \\ln(0.3) \\approx 0.3 \\times (-1.2039728) \\approx -0.3611918\n$$\n$$\n0.2 \\ln(0.2) \\approx 0.2 \\times (-1.6094379) \\approx -0.3218876\n$$\n$$\n0.1 \\ln(0.1) \\approx 0.1 \\times (-2.3025851) \\approx -0.2302585\n$$\n将这些值相加：\n$$\n\\sum_{i=1}^{4} p_i \\ln(p_i) \\approx -0.3665163 - 0.3611918 - 0.3218876 - 0.2302585 = -1.2798542\n$$\n因此，香农熵为：\n$$\nH' = -(-1.2798542) = 1.2798542\n$$\n现在，我们计算有效物种数 ${}^{1}D$：\n$$\n{}^{1}D = \\exp(H') = \\exp(1.2798542)\n$$\n$$\n{}^{1}D \\approx 3.596093\n$$\n题目要求将结果四舍五入至四位有效数字。前四位有效数字是 $3$、$5$、$9$ 和 $6$。第五位数字是 $0$，所以我们不进位。\n$$\n{}^{1}D \\approx 3.596\n$$\n该值代表了阶数为 $1$ 的真实多样性，以样本中有效ASV数量来衡量。它是一个无量纲的量。", "answer": "$$\n\\boxed{3.596}\n$$", "id": "2509172"}, {"introduction": "量化单个样本的多样性之后，下一个关键步骤是比较不同微生物群落之间的差异（β多样性），并探究这些差异背后的驱动因素。主坐标分析（PCoA）是一种强大的可视化技术，它能将样本间的距离（如Bray-Curtis非相似性）呈现在一个低维空间中。本练习将指导您完成一个完整的分析流程，从计算距离矩阵到执行PCoA，并最终通过与环境梯度的相关性来解释排序轴的生态学意义。[@problem_id:2509183]", "problem": "您会收到三个独立的测试用例，每个测试用例包含一个全息生物丰度表（样本 × 类群）和在相同样本上测量的相应环境梯度矩阵（样本 × 梯度）。您的任务是编写一个程序，为每个测试用例计算样本间的Bray–Curtis相异度，对该相异度矩阵执行主坐标分析（PCoA），并通过相关性分析，用环境梯度来解释前两个PCoA轴。\n\n请从以下基本原理开始：\n- 两个非负丰度向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 之间的Bray–Curtis相异度定义为\n$$\nd_{\\mathrm{BC}}(\\mathbf{x},\\mathbf{y}) \\;=\\; \\frac{\\sum_{k} \\left| x_k - y_k \\right|}{\\sum_{k} \\left( x_k + y_k \\right)},\n$$\n当 $\\sum_k \\left( x_k + y_k \\right) \\gt 0$ 时，该定义有效。\n- 主坐标分析（经典多维标度分析）接收一个 $n \\times n$ 的距离矩阵 $\\mathbf{D}$，计算其距离平方矩阵 $\\mathbf{D}^{(2)}$（元素为 $D_{ij}^2$），并对其进行双重中心化以获得格拉姆矩阵\n$$\n\\mathbf{B} \\;=\\; -\\tfrac{1}{2} \\, \\mathbf{J} \\, \\mathbf{D}^{(2)} \\, \\mathbf{J}, \\quad \\text{with } \\mathbf{J} \\;=\\; \\mathbf{I}_n \\;-\\; \\tfrac{1}{n}\\mathbf{1}\\mathbf{1}^\\top,\n$$\n然后对 $\\mathbf{B}$ 进行特征分解，得到特征值 $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_n$ 和对应的标准正交特征向量。PCoA坐标由 $\\mathbf{X} = \\mathbf{V}_+ \\, \\mathrm{diag}(\\sqrt{\\lambda_+})$ 给出，其中只使用正特征值 $\\lambda_+$ 及其特征向量 $\\mathbf{V}_+$。轴 $j$ 解释的变异比例为 $\\lambda_j \\big/ \\sum_{\\lambda_i \\gt 0} \\lambda_i$。\n- 为用环境梯度向量 $\\mathbf{g}$ 解释排序轴 $\\mathbf{a}$，使用皮尔逊积矩相关系数\n$$\nr(\\mathbf{a},\\mathbf{g}) \\;=\\; \\frac{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)\\left(g_i - \\bar{g}\\right)}{\\sqrt{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)^2} \\, \\sqrt{\\sum_{i=1}^n \\left(g_i - \\bar{g}\\right)^2}}。\n$$\n\n程序要求：\n- 对于每个测试用例，从丰度表中计算样本间的Bray–Curtis相异度矩阵，按上述方法执行PCoA，并提取前两个轴（如果正特征值的数量少于两个，则将缺失轴的解释比例视为 $0$，其得分为零向量）。\n- 对于前两个轴中的每一个，计算其与每个环境梯度（列）的皮尔逊相关性，并找出使相关性绝对值最大的梯度的索引。梯度索引使用基于0的索引。如果相关性绝对值出现平局，选择最小的梯度索引。报告所选梯度的带符号相关系数。\n- 将所有浮点数输出四舍五入到 $6$ 位小数。输出中不包含物理单位；比例以小数形式报告，而非百分比。\n\n输出格式：\n- 对于每个测试用例，按以下顺序生成一个包含 $6$ 个元素的列表：$[\\text{prop\\_axis1}, \\text{prop\\_axis2}, \\text{best\\_grad\\_idx\\_axis1}, \\text{best\\_grad\\_idx\\_axis2}, \\text{corr\\_axis1\\_best}, \\text{corr\\_axis2\\_best}]$，其中 $\\text{prop\\_axis1}$ 和 $\\text{prop\\_axis2}$ 是 $[0,1]$ 范围内的浮点数，$\\text{best\\_grad\\_idx\\_axis1}$ 和 $\\text{best\\_grad\\_idx\\_axis2}$ 是整数，最后两个是 $\\left[-1,1\\right]$ 范围内的带符号相关系数（浮点数）。\n- 您的程序应生成单行输出，其中包含三个测试用例的结果。结果是一个由每个用例的列表组成的、以逗号分隔的列表，并用一对总的方括号括起来。例如：\"[[...],[...],[...]]\"，不含空格。\n\n测试套件：\n- 测试用例 $1$（沿理化梯度的微生物组）：\n  - 丰度表 $\\mathbf{X}_1$（行是样本 $S_1$ 到 $S_5$，列是类群 $T_1$ 到 $T_4$）：\n    - $S_1$: $[60, 25, 10, 5]$\n    - $S_2$: $[50, 30, 15, 5]$\n    - $S_3$: $[30, 30, 25, 15]$\n    - $S_4$: $[15, 25, 30, 30]$\n    - $S_5$: $[5, 15, 30, 50]$\n  - 环境梯度 $\\mathbf{G}_1$，包含两列，行顺序与丰度表相同：\n    - 梯度 $0$（pH，无单位）：$[6.5, 6.8, 7.0, 7.2, 7.5]$\n    - 梯度 $1$（盐度，实用盐度单位视为数值）：$[31.0, 28.2, 26.4, 24.3, 22.1]$\n- 测试用例 $2$（膳食纤维梯度伴随微弱的温度变化）：\n  - 丰度表 $\\mathbf{X}_2$（行是样本 $S_1$ 到 $S_6$，列是类群 $T_1$ 到 $T_4$）：\n    - $S_1$: $[80, 30, 5, 5]$\n    - $S_2$: $[70, 25, 10, 5]$\n    - $S_3$: $[60, 20, 15, 5]$\n    - $S_4$: $[10, 15, 30, 45]$\n    - $S_5$: $[5, 10, 30, 55]$\n    - $S_6$: $[8, 12, 28, 42]$\n  - 环境梯度 $\\mathbf{G}_2$：\n    - 梯度 $0$（纤维，任意单位）：$[0.10, 0.20, 0.35, 0.70, 0.82, 0.95]$\n    - 梯度 $1$（温度，任意单位）：$[15.0, 15.5, 15.0, 16.0, 16.5, 16.0]$\n- 测试用例 $3$（重复样本和部分重叠的梯度）：\n  - 丰度表 $\\mathbf{X}_3$（行是样本 $S_1$ 到 $S_4$，列是类群 $T_1$ 到 $T_4$）：\n    - $S_1$: $[40, 30, 20, 10]$\n    - $S_2$: $[40, 30, 20, 10]$\n    - $S_3$: $[10, 20, 30, 40]$\n    - $S_4$: $[12, 18, 30, 40]$\n  - 环境梯度 $\\mathbf{G}_3$：\n    - 梯度 $0$（溶解氧，任意单位）：$[5.0, 5.0, 8.0, 8.2]$\n    - 梯度 $1$（深度，任意单位）：$[100.0, 100.0, 50.0, 55.0]$\n\n边界情况与平局处理规则：\n- 如果正特征值的数量少于 $2$ 个，将缺失轴的解释比例设置为 $0$，并将其得分视为零向量，这将导致与任何梯度的相关性均为 $0$，最佳梯度索引为 $-1$。\n- 如果两个或更多梯度与某个轴的绝对相关性完全相同，选择最小的梯度索引。\n\n您的程序必须按所述实现所有计算，并按顺序打印一行格式为 \"[[...],[...],[...]]\" (不含空格) 的输出，其中包含三个测试用例的结果。将所有浮点数结果四舍五入到 $6$ 位小数。", "solution": "我们从相异度、排序和相关性的定义出发，构建一种基于原理的计算方法，用以在全息生物框架内将微生物群落组成映射到环境梯度。\n\n相异度的第一原理：给定非负丰度向量 $\\mathbf{x}$ 和 $\\mathbf{y}$，我们使用Bray–Curtis相异度，\n$$\nd_{\\mathrm{BC}}(\\mathbf{x},\\mathbf{y}) \\;=\\; \\frac{\\sum_{k} \\left| x_k - y_k \\right|}{\\sum_{k} \\left( x_k + y_k \\right)}.\n$$\n这种相异度基于生态学理论，因为它对相对丰度敏感，并且忽略了物种的共同缺失。在算法上，对于一个大小为 $n \\times p$（样本 × 类群）的丰度矩阵 $\\mathbf{X}$，我们计算所有成对的相异度，形成一个 $n \\times n$ 的矩阵 $\\mathbf{D}$，其元素为 $D_{ij} = d_{\\mathrm{BC}}(\\mathbf{X}_{i\\cdot}, \\mathbf{X}_{j\\cdot})$。在计算上，分子是 $\\sum_k \\left| X_{ik} - X_{jk} \\right|$，分母是 $\\sum_k \\left( X_{ik} + X_{jk} \\right)$，可简化为样本总和之和 $\\sum_k X_{ik} + \\sum_k X_{jk}$；如果两个总和都为零（我们的测试套件中未出现此情况），则相异度可定义为 $0$。\n\n从距离到欧几里得嵌入：主坐标分析通过对距离平方进行双重中心化，将距离矩阵转换为一个中心化的内积（格拉姆）矩阵，\n$$\n\\mathbf{B} \\;=\\; -\\tfrac{1}{2} \\, \\mathbf{J} \\, \\mathbf{D}^{(2)} \\, \\mathbf{J}, \\quad \\text{with } \\mathbf{J} \\;=\\; \\mathbf{I}_n \\;-\\; \\tfrac{1}{n}\\mathbf{1}\\mathbf{1}^\\top.\n$$\n这源于在中心化坐标系中将欧几里得距离与内积联系起来的恒等式。对于像Bray–Curtis这样的非欧几里得相异度，$\\mathbf{B}$ 可能会有负特征值。标准且经过充分检验的方法是仅保留正特征值 $\\lambda_i \\gt 0$ 及其特征向量来构建坐标，\n$$\n\\mathbf{X} \\;=\\; \\mathbf{V}_+ \\, \\mathrm{diag}\\left( \\sqrt{\\lambda_+} \\right),\n$$\n其中 $\\mathbf{X}$ 的列是PCoA轴（主坐标）。轴 $j$ 解释的变异计算为 $\\lambda_j \\big/ \\sum_{\\lambda_i \\gt 0} \\lambda_i$，这会产生一个在 $\\left[0,1\\right]$ 范围内的合规比例，在谱的正值部分上求和为 $1$。如果正特征值的数量少于两个，我们将缺失轴的解释比例定义为 $0$，其轴得分定义为零向量。\n\n通过环境梯度解释轴：给定一个轴得分向量 $\\mathbf{a} \\in \\mathbb{R}^n$ 和一个环境梯度 $\\mathbf{g} \\in \\mathbb{R}^n$，我们计算皮尔逊相关系数\n$$\nr(\\mathbf{a},\\mathbf{g}) \\;=\\; \\frac{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)\\left(g_i - \\bar{g}\\right)}{\\sqrt{\\sum_{i=1}^n \\left(a_i - \\bar{a}\\right)^2} \\, \\sqrt{\\sum_{i=1}^n \\left(g_i - \\bar{g}\\right)^2}},\n$$\n该系数在一个中心化和标准化的尺度上衡量线性关联。对于每个轴，我们选择具有最大绝对相关性的环境梯度，并报告该梯度的基于0的索引和带符号的相关系数。因为特征向量的方向（符号）是任意的，所以相关性的符号除非有参考，否则在生态学上没有意义；因此，选择是基于绝对值，但报告的是带符号的值。如果轴的方差为零（例如，没有对应的正特征值），我们将其相关性定义为 $0$，并将最佳梯度索引设置为 $-1$。如果多个梯度的绝对相关性出现平局，我们选择最小的索引以保持确定性。\n\n每个测试用例的算法步骤：\n1. 输入丰度矩阵 $\\mathbf{X}$ 和环境矩阵 $\\mathbf{G}$。\n2. 使用上述公式为每对样本计算Bray–Curtis距离矩阵 $\\mathbf{D}$；强制执行对称性和对角线为零。\n3. 通过逐元素平方计算 $\\mathbf{D}^{(2)}$，然后对其进行双重中心化以获得 $\\mathbf{B} = -\\tfrac{1}{2} \\mathbf{J} \\mathbf{D}^{(2)} \\mathbf{J}$，其中 $\\mathbf{J} = \\mathbf{I} - \\frac{1}{n} \\mathbf{1}\\mathbf{1}^\\top$。\n4. 对 $\\mathbf{B}$ 进行特征分解，按降序对特征值进行排序，并仅保留正特征值（大于一个小的数值容差）及相应的特征向量，以形成坐标矩阵 $\\mathbf{X}_{\\mathrm{PCoA}}$，其列通过乘以 $\\sqrt{\\lambda_i}$ 进行缩放。\n5. 计算前两个轴解释的比例，即 $\\lambda_1 / \\sum \\lambda_+$ 和 $\\lambda_2 / \\sum \\lambda_+$（如果存在）；否则，将缺失的比例设置为 $0$。\n6. 对于前两个轴中的每一个（如果缺失则使用零向量），计算其与 $\\mathbf{G}$ 的每一列的皮尔逊相关性。选择使绝对相关性最大化的梯度索引（通过最小索引解决平局），并记录该梯度的带符号相关值。如果轴得分为常数，则将所有相关性定义为 $0$，最佳梯度索引定义为 $-1$。\n7. 将所有浮点数结果四舍五入到 $6$ 位小数，并按要求的顺序组装每个测试用例的列表。\n8. 打印一行，其中包含一个由三个用例列表组成的、用方括号括起来的、以逗号分隔的列表，不含空格。\n\n支撑测试套件的生态学解释：\n- 测试用例 $1$ 模拟了沿理化梯度（pH值增加，盐度降低）的单调群落组成变化，通常会产生一个与这些梯度对齐的、占主导地位的第一轴；两个梯度都信息量很大，但在数值上并非完全共线性，因此可以通过绝对相关性找到唯一的最佳匹配。\n- 测试用例 $2$ 中，存在与膳食纤维含量相关的显著变化，而温度变化很微弱，因此第一轴应主要与纤维梯度对齐。\n- 测试用例 $3$ 包含重复样本，这会导致零距离并可能降低维度；该方法对正特征值的处理以及定义的备用方案确保了即使在某个轴不可用或较弱的情况下，也能产生稳健、确定性的输出。\n\n所有计算均遵循所述定义，不依赖快捷公式，并且四舍五入操作确保了用于评估的一致、可由机器检验的输出。", "answer": "```python\nimport numpy as np\n\ndef bray_curtis_distance_matrix(X: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute the Bray-Curtis dissimilarity matrix for samples (rows) in X.\n    X: n_samples x n_features, nonnegative.\n    Returns: n_samples x n_samples symmetric matrix with zeros on diagonal.\n    \"\"\"\n    n = X.shape[0]\n    D = np.zeros((n, n), dtype=float)\n    # Precompute row sums to speed up denominator computation\n    row_sums = X.sum(axis=1)\n    for i in range(n):\n        xi = X[i]\n        sumi = row_sums[i]\n        for j in range(i + 1, n):\n            xj = X[j]\n            sumj = row_sums[j]\n            denom = sumi + sumj\n            if denom == 0:\n                d = 0.0  # both samples all-zero; define distance as 0\n            else:\n                num = np.abs(xi - xj).sum()\n                d = num / denom\n            D[i, j] = d\n            D[j, i] = d\n    return D\n\ndef pcoa_from_distance(D: np.ndarray, tol: float = 1e-12):\n    \"\"\"\n    Perform PCoA (classical MDS) on a distance matrix D.\n    Returns eigenvalues (sorted descending), coordinates matrix with only positive eigenvalues.\n    \"\"\"\n    n = D.shape[0]\n    # Square distances\n    D2 = D ** 2.0\n    # Double-centering\n    J = np.eye(n) - np.ones((n, n)) / n\n    B = -0.5 * (J @ D2 @ J)\n    # Eigen-decomposition (symmetric)\n    w, V = np.linalg.eigh(B)\n    # Sort in descending order\n    idx = np.argsort(w)[::-1]\n    w = w[idx]\n    V = V[:, idx]\n    # Keep positive eigenvalues\n    pos_mask = w  tol\n    w_pos = w[pos_mask]\n    V_pos = V[:, pos_mask]\n    # Coordinates scaled by sqrt of eigenvalues\n    if w_pos.size  0:\n        coords = V_pos * np.sqrt(w_pos)\n    else:\n        coords = np.zeros((n, 0), dtype=float)\n    return w, w_pos, coords\n\ndef pearson_correlation(x: np.ndarray, y: np.ndarray) - float:\n    \"\"\"\n    Compute Pearson correlation between two 1D arrays.\n    If either has zero variance, return 0.0.\n    \"\"\"\n    x = np.asarray(x, dtype=float)\n    y = np.asarray(y, dtype=float)\n    x_mean = x.mean()\n    y_mean = y.mean()\n    x_centered = x - x_mean\n    y_centered = y - y_mean\n    sx = np.sqrt(np.sum(x_centered ** 2))\n    sy = np.sqrt(np.sum(y_centered ** 2))\n    if sx == 0.0 or sy == 0.0:\n        return 0.0\n    cov = np.sum(x_centered * y_centered)\n    r = cov / (sx * sy)\n    # Clamp small numerical deviations\n    if r  1.0:\n        r = 1.0\n    elif r  -1.0:\n        r = -1.0\n    return r\n\ndef interpret_axes(coords: np.ndarray, env: np.ndarray, num_axes: int = 2):\n    \"\"\"\n    For the first num_axes axes, compute best matching environmental gradient by absolute correlation.\n    Returns:\n      best_indices: list of ints (length num_axes)\n      best_correlations: list of floats (signed, length num_axes)\n    If an axis is missing (coords has fewer columns), treat axis vector as zeros,\n    set best index to -1 and correlation to 0.0.\n    \"\"\"\n    n, k = coords.shape\n    m = env.shape[1]\n    best_indices = []\n    best_correlations = []\n    for axis in range(num_axes):\n        if axis  k:\n            axis_scores = coords[:, axis]\n        else:\n            axis_scores = np.zeros(n, dtype=float)\n        # Compute correlations to each env gradient\n        if np.allclose(axis_scores, axis_scores[0] if len(axis_scores)  0 else 0.0):\n            # Zero variance\n            best_indices.append(-1)\n            best_correlations.append(0.0)\n            continue\n        corrs = []\n        for j in range(m):\n            r = pearson_correlation(axis_scores, env[:, j])\n            corrs.append(r)\n        # Choose by max absolute correlation, break ties by smallest index\n        abs_corrs = np.abs(corrs)\n        max_abs = np.max(abs_corrs)\n        candidates = [j for j, ac in enumerate(abs_corrs) if np.isclose(ac, max_abs, atol=1e-12)]\n        best_j = min(candidates)\n        best_indices.append(int(best_j))\n        best_correlations.append(float(corrs[best_j]))\n    return best_indices, best_correlations\n\ndef round6(x: float) - float:\n    # Round to 6 decimals and avoid -0.0\n    r = float(np.round(x + 0.0, 6))\n    if r == -0.0:\n        r = 0.0\n    return r\n\ndef format_case_output(case_output):\n    # case_output is a list of values (floats and ints)\n    # We must produce a string like [f1,f2,i1,i2,f3,f4] with no spaces\n    parts = []\n    for v in case_output:\n        if isinstance(v, int):\n            parts.append(str(v))\n        else:\n            # ensure 6 decimal places\n            parts.append(f\"{v:.6f}\")\n    return \"[\" + \",\".join(parts) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test case 1\n    X1 = np.array([\n        [60, 25, 10, 5],\n        [50, 30, 15, 5],\n        [30, 30, 25, 15],\n        [15, 25, 30, 30],\n        [5, 15, 30, 50],\n    ], dtype=float)\n    G1 = np.column_stack([\n        np.array([6.5, 6.8, 7.0, 7.2, 7.5], dtype=float),      # pH\n        np.array([31.0, 28.2, 26.4, 24.3, 22.1], dtype=float)  # salinity\n    ])\n\n    # Test case 2\n    X2 = np.array([\n        [80, 30, 5, 5],\n        [70, 25, 10, 5],\n        [60, 20, 15, 5],\n        [10, 15, 30, 45],\n        [5, 10, 30, 55],\n        [8, 12, 28, 42],\n    ], dtype=float)\n    G2 = np.column_stack([\n        np.array([0.10, 0.20, 0.35, 0.70, 0.82, 0.95], dtype=float),  # fiber\n        np.array([15.0, 15.5, 15.0, 16.0, 16.5, 16.0], dtype=float)   # temperature\n    ])\n\n    # Test case 3\n    X3 = np.array([\n        [40, 30, 20, 10],\n        [40, 30, 20, 10],\n        [10, 20, 30, 40],\n        [12, 18, 30, 40],\n    ], dtype=float)\n    G3 = np.column_stack([\n        np.array([5.0, 5.0, 8.0, 8.2], dtype=float),     # oxygen\n        np.array([100.0, 100.0, 50.0, 55.0], dtype=float)  # depth\n    ])\n\n    test_cases = [\n        (X1, G1),\n        (X2, G2),\n        (X3, G3),\n    ]\n\n    results = []\n    for X, G in test_cases:\n        D = bray_curtis_distance_matrix(X)\n        w_all, w_pos, coords = pcoa_from_distance(D, tol=1e-12)\n        # Proportions explained by first two axes among positive eigenvalues\n        if w_pos.size  0:\n            total_pos = float(np.sum(w_pos))\n        else:\n            total_pos = 0.0\n        if w_pos.size = 1 and total_pos  0.0:\n            prop1 = w_pos[0] / total_pos\n        else:\n            prop1 = 0.0\n        if w_pos.size = 2 and total_pos  0.0:\n            prop2 = w_pos[1] / total_pos\n        else:\n            prop2 = 0.0\n        # Interpret axes\n        best_indices, best_corrs = interpret_axes(coords, G, num_axes=2)\n        # Round floats to 6 decimals\n        prop1_r = round6(prop1)\n        prop2_r = round6(prop2)\n        corr1_r = round6(best_corrs[0])\n        corr2_r = round6(best_corrs[1])\n        # Assemble output for this case\n        case_output = [prop1_r, prop2_r, best_indices[0], best_indices[1], corr1_r, corr2_r]\n        results.append(case_output)\n\n    # Final print statement in the exact required format: one line, no spaces.\n    out = \"[\" + \",\".join(format_case_output(case) for case in results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2509183"}, {"introduction": "微生物组测序数据本质上是组分数据，即它们只反映相对丰度而非绝对数量。直接对原始计数或比例应用标准统计方法（如相关性分析）可能会产生虚假的结果。本练习将向您介绍中心对数比（CLR）变换，这是一种处理组分性的关键方法，它能将数据转换到一个可以进行有效统计分析的欧几里得空间中。通过这个练习，您将学会如何计算CLR值，并理解处理数据中常见的“零”值对下游分析的重要性。[@problem_id:2509199]", "problem": "一个珊瑚全息生物体被建模为一个宿主及其相关的微生物组群落，由于测序限制，其分类单元计数是成分性的。对两个单独的宿主（表示为样本 $\\mathrm{H}_1$ 和样本 $\\mathrm{H}_2$）调查了相同的 $D=4$ 个细菌分类单元 $\\{T_1,T_2,T_3,T_4\\}$。观测到的计数向量（以读数计数为单位）为：\n- $\\mathrm{H}_1$: $\\big(0,\\;30,\\;10,\\;10\\big)$\n- $\\mathrm{H}_2$: $\\big(5,\\;15,\\;0,\\;20\\big)$\n\n由于零值无法取对数，因此在每个计数上加上一个伪计数 $\\alpha=0.5$。使用成分数据分析中的中心对数比（CLR）变换，样本 $s$ 中分类单元 $i$ 的变换值定义为\n$$\n\\mathrm{CLR}_i^{(s)} \\;=\\; \\ln\\!\\left(\\frac{x_i^{(s)}+\\alpha}{g\\!\\left(\\mathbf{x}^{(s)}+\\alpha\\mathbf{1}\\right)}\\right),\n$$\n其中 $\\mathbf{x}^{(s)}=(x_1^{(s)},\\dots,x_D^{(s)})$ 是样本 $s$ 的计数向量，$\\mathbf{1}$ 是全为1的 $D$ 维向量，$g(\\cdot)$ 是几何平均值，$g(\\mathbf{z})=\\left(\\prod_{j=1}^D z_j\\right)^{1/D}$。\n\n仅从成分数据和CLR变换的核心定义，以及对数和相关性的标准属性出发，完成以下操作：\n1) 使用 $\\alpha=0.5$ 计算 $\\mathrm{H}_1$ 和 $\\mathrm{H}_2$ 的CLR变换向量。\n2) 将四个分类单元视为配对观测值，计算两个CLR向量之间跨分类单元的皮尔逊相关系数。\n\n在你的推理中，证明引入伪计数 $\\alpha$ 如何影响几何平均值，从而影响CLR值，并从机制上解释当零值出现在不同分类单元时，这种零值处理方法如何改变样本间下游相关性的符号和大小。将最终的相关性表示为无单位的小数。将最终数值答案四舍五入到4位有效数字。", "solution": "该问题涉及来自珊瑚全息生物体两个样本的成分性微生物组计数数据。测序数据是成分性的，因为只保留了相对信息；中心对数比（CLR）变换是一种标准方法，通过计算相对于几何平均值的对数比，将成分从单纯形映射到实向量空间。计数中的零值无法取对数，因此在变换前向每个分量添加一个伪计数 $\\alpha0$。我们从核心定义开始。\n\n设分类单元数为 $D=4$。对于样本 $s\\in\\{\\mathrm{H}_1,\\mathrm{H}_2\\}$，其计数向量为 $\\mathbf{x}^{(s)}=(x_1^{(s)},\\dots,x_4^{(s)})$，定义伪计数调整后的向量为 $\\mathbf{z}^{(s)}=\\mathbf{x}^{(s)}+\\alpha\\mathbf{1}$，其分量为 $z_i^{(s)}=x_i^{(s)}+\\alpha$。几何平均值为\n$$\ng\\!\\left(\\mathbf{z}^{(s)}\\right)\\;=\\;\\left(\\prod_{j=1}^{4} z_j^{(s)}\\right)^{1/4}.\n$$\nCLR分量为\n$$\n\\mathrm{CLR}_i^{(s)} \\;=\\; \\ln\\!\\left(\\frac{z_i^{(s)}}{g(\\mathbf{z}^{(s)})}\\right)\n\\;=\\; \\ln z_i^{(s)} \\;-\\; \\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(s)}.\n$$\n根据构造，对于每个 $s$，$\\sum_{i=1}^4 \\mathrm{CLR}_i^{(s)}=0$。\n\n步骤1：使用 $\\alpha=0.5$ 计算 $\\mathrm{H}_1$ 和 $\\mathrm{H}_2$ 的CLR变换向量。\n\n对于 $\\mathrm{H}_1$，$\\mathbf{x}^{(\\mathrm{H}_1)}=(0,30,10,10)$，因此\n$$\n\\mathbf{z}^{(\\mathrm{H}_1)}=(0.5,\\;30.5,\\;10.5,\\;10.5).\n$$\n计算对数：\n$$\n\\ln z_1^{(\\mathrm{H}_1)}=\\ln 0.5=-0.6931471805599453,\n$$\n$$\n\\ln z_2^{(\\mathrm{H}_1)}=\\ln 30.5=\\ln 61-\\ln 2\\approx 4.110873864173311-0.6931471805599453=3.417726683613366,\n$$\n$$\n\\ln z_3^{(\\mathrm{H}_1)}=\\ln z_4^{(\\mathrm{H}_1)}=\\ln 10.5=\\ln 21-\\ln 2\\approx 3.044522437723423-0.6931471805599453=2.351375257163478.\n$$\n对数的均值为\n$$\n\\bar{\\ell}^{(\\mathrm{H}_1)}=\\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(\\mathrm{H}_1)}=\\frac{-0.6931471805599453+3.417726683613366+2\\times 2.351375257163478}{4}\\approx 1.8568325043450942.\n$$\n因此CLR分量为\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_1)}=\\big(\\,-0.6931471805599453-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;3.417726683613366-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;2.351375257163478-\\bar{\\ell}^{(\\mathrm{H}_1)},\\;2.351375257163478-\\bar{\\ell}^{(\\mathrm{H}_1)}\\,\\big),\n$$\n即，\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_1)}\\approx\\big(-2.5499796849050395,\\;1.5608941792682718,\\;0.4945427528183837,\\;0.4945427528183837\\big).\n$$\n\n对于 $\\mathrm{H}_2$，$\\mathbf{x}^{(\\mathrm{H}_2)}=(5,15,0,20)$，因此\n$$\n\\mathbf{z}^{(\\mathrm{H}_2)}=(5.5,\\;15.5,\\;0.5,\\;20.5).\n$$\n计算对数：\n$$\n\\ln z_1^{(\\mathrm{H}_2)}=\\ln 5.5=\\ln 11-\\ln 2\\approx 2.3978952727983707-0.6931471805599453=1.7047480922384254,\n$$\n$$\n\\ln z_2^{(\\mathrm{H}_2)}=\\ln 15.5=\\ln 31-\\ln 2\\approx 3.4339872044851463-0.6931471805599453=2.740840023925201,\n$$\n$$\n\\ln z_3^{(\\mathrm{H}_2)}=\\ln 0.5=-0.6931471805599453,\n$$\n$$\n\\ln z_4^{(\\mathrm{H}_2)}=\\ln 20.5=\\ln 41-\\ln 2\\approx 3.713572066704308-0.6931471805599453=3.020424886144363.\n$$\n对数的均值为\n$$\n\\bar{\\ell}^{(\\mathrm{H}_2)}=\\frac{1}{4}\\sum_{j=1}^4 \\ln z_j^{(\\mathrm{H}_2)}=\\frac{1.7047480922384254+2.740840023925201-0.6931471805599453+3.020424886144363}{4}\\approx 1.693216455437011.\n$$\n因此CLR分量为\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_2)}=\\big(\\,1.7047480922384254-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;2.740840023925201-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;-0.6931471805599453-\\bar{\\ell}^{(\\mathrm{H}_2)},\\;3.020424886144363-\\bar{\\ell}^{(\\mathrm{H}_2)}\\,\\big),\n$$\n即，\n$$\n\\mathrm{CLR}^{(\\mathrm{H}_2)}\\approx\\big(0.011531636801414384,\\;1.0476235684881902,\\;-2.386363635996956,\\;1.3272084307073518\\big).\n$$\n\n步骤2：计算两个CLR向量之间跨分类单元的皮尔逊相关性。\n\n令 $\\mathbf{c}^{(1)}=\\mathrm{CLR}^{(\\mathrm{H}_1)}$ 且 $\\mathbf{c}^{(2)}=\\mathrm{CLR}^{(\\mathrm{H}_2)}$。跨4个分类单元的皮尔逊相关系数为\n$$\nr \\;=\\; \\frac{\\sum_{i=1}^{4}\\left(c^{(1)}_i-\\bar{c}^{(1)}\\right)\\left(c^{(2)}_i-\\bar{c}^{(2)}\\right)}{\\sqrt{\\sum_{i=1}^{4}\\left(c^{(1)}_i-\\bar{c}^{(1)}\\right)^2}\\;\\sqrt{\\sum_{i=1}^{4}\\left(c^{(2)}_i-\\bar{c}^{(2)}\\right)^2}},\n$$\n其中 $\\bar{c}^{(s)}$ 是向量 $\\mathbf{c}^{(s)}$ 各分量的均值。对于任何CLR向量，$\\sum_{i=1}^4 c^{(s)}_i=0$，因此 $\\bar{c}^{(s)}=0$。所以相关性简化为\n$$\nr \\;=\\; \\frac{\\sum_{i=1}^{4} c^{(1)}_i c^{(2)}_i}{\\sqrt{\\sum_{i=1}^{4}\\left(c^{(1)}_i\\right)^2}\\;\\sqrt{\\sum_{i=1}^{4}\\left(c^{(2)}_i\\right)^2}}.\n$$\n使用计算出的值：\n- 分子：\n$$\n\\sum_{i=1}^{4} c^{(1)}_i c^{(2)}_i \\approx\n(-2.5499796849050395)(0.011531636801414384) + (1.5608941792682718)(1.0476235684881902) \\\\\n+ (0.4945427528183837)(-2.386363635996956) + (0.4945427528183837)(1.3272084307073518)\n\\approx 1.0820246.\n$$\n- 分母项：\n$$\n\\sum_{i=1}^{4}\\left(c^{(1)}_i\\right)^2 \\approx (-2.5499796849050395)^2+(1.5608941792682718)^2+2\\times(0.4945427528183837)^2 \\approx 9.427928,\n$$\n$$\n\\sum_{i=1}^{4}\\left(c^{(2)}_i\\right)^2 \\approx (0.011531636801414384)^2+(1.0476235684881902)^2+(-2.386363635996956)^2+(1.3272084307073518)^2 \\approx 8.553857.\n$$\n因此，\n$$\nr \\;\\approx\\; \\frac{1.0820246}{\\sqrt{9.427928\\times 8.553857}} \\;\\approx\\; \\frac{1.0820246}{8.980264} \\;\\approx\\; 0.120489.\n$$\n四舍五入到4位有效数字，相关性为 $0.1205$。\n\n零值处理及其对相关性影响的概念性论证：在成分数据中，只有比率有意义。CLR变换将每个分量映射为与样本几何平均值的对数比：\n$$\n\\mathrm{CLR}_i^{(s)}=\\ln\\!\\left(x_i^{(s)}+\\alpha\\right) - \\frac{1}{D}\\sum_{j=1}^{D}\\ln\\!\\left(x_j^{(s)}+\\alpha\\right).\n$$\n引入伪计数 $\\alpha$ 会在对数尺度上非线性地移动所有分量。对于大计数 $x_i^{(s)}\\gg \\alpha$，变化 $\\ln(x_i^{(s)}+\\alpha)-\\ln x_i^{(s)}\\approx \\alpha/x_i^{(s)}$ 很小，但对于零值和稀有分类单元 $x_i^{(s)}\\approx 0$，该项变为 $\\ln \\alpha$，这是一个相对于样本对数几何平均值而言很大的负偏移。由于几何平均值也依赖于所有的 $\\ln(x_j^{(s)}+\\alpha)$，添加 $\\alpha$ 会同时改变对数比的分子和分母，其中最大的影响来自稀疏的分类单元。\n\n在样本间的下游相关性分析中，协方差项 $\\sum_i c^{(1)}_i c^{(2)}_i$ 对零值是否出现在不同样本的相同分类单元中很敏感。如果一个分类单元在一个样本中为零，但在另一个样本中不为零，其CLR条目对于零值样本往往具有相反的符号和较大的量级，从而产生一个大的负乘积，这会降低相关性。如果零值在不同样本的相同分类单元中同时出现，它们的大负值CLR值会对齐，从而增加对协方差的正向贡献。这些效应的大小取决于 $\\alpha$：较大的 $\\alpha$ 会降低零值的负CLR值的极端性（缩小其影响），而较小的 $\\alpha$ 则会加剧它们。因此，当零值在不同分类单元间分布不同时，通过伪计数进行零值处理会直接调节CLR向量的尺度以及样本间相关性的符号和大小。", "answer": "$$\\boxed{0.1205}$$", "id": "2509199"}]}