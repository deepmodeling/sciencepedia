{"hands_on_practices": [{"introduction": "在生态毒理学中，设计一个信息量充足且具有成本效益的实验至关重要。本练习将指导您完成一项关键的实验设计任务：功效分析（power analysis）。通过从统计建模和信息论的基本原理出发，您将学习如何量化一个实验设计检测出特定效应大小（例如，两种处理的 $EC_{50}$ 值存在两倍差异）的概率 [@problem_id:2481284]。这项实践将使您掌握在实际数据收集之前，评估和优化实验方案（如剂量选择、重复次数）的能力，从而确保研究的科学严谨性和资源利用效率。", "problem": "您的任务是构建一个程序，在一组指定的假设下，执行基于设计的功效分析，以检测标准化剂量-反应实验中两种处理之间半数有效浓度 (EC50) 的两倍差异。您的方法必须从统计建模和信息论的基本原理出发，然后形成一个适合计算的完全指定的算法。\n\n假设与模型结构：\n- 在处理组 $t \\in \\{\\mathrm{A},\\mathrm{B}\\}$ 中，剂量 $x$ 下的生物反应被建模为\n$$\nY \\mid x,t \\sim \\mathcal{N}\\!\\big(\\mu(x;\\theta_t),\\,\\sigma^2\\big),\n$$\n其残差为独立同分布且方差恒为 $\\sigma^2$，并且在不同处理组和剂量之间独立。反应被标准化到 $0$ 到 $1$ 的范围内，因此不需要额外的尺度参数。\n- 平均函数是具有固定顶部和底部渐近线的 Hill 型剂量-反应函数：\n$$\n\\mu(x;\\theta) \\;=\\; \\frac{1}{1 + \\left(\\frac{x}{\\mathrm{EC}_{50}}\\right)^h} \\;=\\; \\frac{1}{1 + \\exp\\!\\big(h(\\ln x - \\theta)\\big)},\n$$\n其中 $\\theta = \\ln(\\mathrm{EC}_{50})$，$h$ 是两种处理共有的已知 Hill 斜率。顶部固定为 $1$，底部固定为 $0$。\n- 处理组 $\\mathrm{A}$ 的参数为 $\\theta_{\\mathrm{A}} = \\ln(\\mathrm{EC}_{50,\\mathrm{A}})$，处理组 $\\mathrm{B}$ 的参数为 $\\theta_{\\mathrm{B}} = \\theta_{\\mathrm{A}} + \\ln f$，其中 $f$ 是 EC50 的倍数变化。零假设为 $H_0: \\theta_{\\mathrm{B}} - \\theta_{\\mathrm{A}} = 0$，备择假设为 $H_1: \\theta_{\\mathrm{B}} - \\theta_{\\mathrm{A}} = \\ln f$。您必须在显著性水平为 $\\alpha$ 的双边 Wald 检验下，计算 $H_1$ 成立时的功效。\n- 实验设计由一组剂量 $\\{x_i\\}_{i=1}^m$ 指定，每个处理组在每个剂量下有 $r_i$ 个独立重复。假设两种处理组使用相同的分配方案 $\\{(x_i, r_i)\\}$。\n\n推导的基本原理：\n- 对于已知方差的高斯模型下的非线性平均函数，单个观测值对标量参数 $\\theta$ 的 Fisher 信息为\n$$\n\\mathcal{I}(\\theta) \\;=\\; \\frac{1}{\\sigma^2} \\left(\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta}\\right)^2.\n$$\n- 对于独立观测，Fisher 信息在观测值之间和剂量组之间（通过重复计数）是可加的。在大样本情况下，最大似然估计量的方差约等于 Fisher 信息的倒数。\n- 用于检验 $H_0: \\delta = 0$ 的 Wald 统计量（其估计量为 $\\widehat{\\delta}$）满足\n$$\nZ \\;=\\; \\frac{\\widehat{\\delta}}{\\mathrm{SE}(\\widehat{\\delta})} \\;\\approx\\; \\mathcal{N}\\!\\big(\\delta/\\mathrm{SE}(\\widehat{\\delta}),\\,1\\big),\n$$\n因此，在真实 $\\delta \\neq 0$ 的情况下，显著性水平为 $\\alpha$ 的双边检验功效为\n$$\n\\text{Power} \\;=\\; \\Pr\\big(|Z|  z_{1-\\alpha/2}\\big) \\;=\\; 1 - \\Phi\\!\\big(z_{1-\\alpha/2} - \\lambda\\big) + \\Phi\\!\\big(-z_{1-\\alpha/2} - \\lambda\\big),\n$$\n其中 $\\lambda = |\\delta|/\\mathrm{SE}(\\widehat{\\delta})$ 是非中心化参数，$\\Phi$ 是标准正态累积分布函数。\n\n需要实现的推导和算法步骤：\n1. 使用指定的平均函数，推导出 $\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta}$，并用 $\\{x_i,r_i\\}$, $h$ 和 $\\sigma^2$ 表示给定处理组中 $\\theta$ 的总 Fisher 信息。\n2. 将每个处理组 $t \\in \\{\\mathrm{A},\\mathrm{B}\\}$ 的 $\\widehat{\\theta}_t$ 的渐近方差表示为其在 $H_1$ 下的真实 $\\theta_t$ 处求值的 Fisher 信息的倒数。\n3. 由于在给定假设下，两种处理的测量是独立的，因此差异估计量 $\\widehat{\\delta} = \\widehat{\\theta}_{\\mathrm{B}} - \\widehat{\\theta}_{\\mathrm{A}}$ 的方差是两个方差之和。因此，\n$$\n\\mathrm{SE}(\\widehat{\\delta}) \\;=\\; \\sqrt{\\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{A}}) + \\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{B}})}.\n$$\n4. 计算非中心化参数 $\\lambda = |\\ln f| / \\mathrm{SE}(\\widehat{\\delta})$、临界值 $z_{1-\\alpha/2}$，最后使用上述双边正态公式计算功效。\n\n角度单位不适用。如果任何数量需要表示为百分比，您必须将其表示为小数。您的程序必须将每个功效值输出为在 $[0,1]$ 区间内、四舍五入到四位小数的小数。\n\n测试套件：\n对于以下每种情况，计算检测两倍变化的双边功效，即使用 $f=2$。\n\n- 情况 1（均衡、信息量充足、中等方差）：\n  - 剂量 (单位 $\\mu\\mathrm{M}$)：$\\{1,\\,3,\\,10,\\,30,\\,100\\}$\n  - 每剂量每处理组的重复数：$\\{6,\\,6,\\,6,\\,6,\\,6\\}$\n  - 残差标准差：$\\sigma = 0.1$\n  - Hill 斜率：$h = 1.2$\n  - 基线 $\\mathrm{EC}_{50,\\mathrm{A}} = 10\\,\\mu\\mathrm{M}$，因此 $\\theta_{\\mathrm{A}} = \\ln(10)$\n  - 显著性水平：$\\alpha = 0.05$\n\n- 情况 2（剂量远低于基线 $\\mathrm{EC}_{50}$，信息量较低）：\n  - 剂量 (单位 $\\mu\\mathrm{M}$)：$\\{0.01,\\,0.03,\\,0.1,\\,0.3,\\,1\\}$\n  - 每剂量每处理组的重复数：$\\{4,\\,4,\\,4,\\,4,\\,4\\}$\n  - 残差标准差：$\\sigma = 0.15$\n  - Hill 斜率：$h = 1.2$\n  - 基线 $\\mathrm{EC}_{50,\\mathrm{A}} = 10\\,\\mu\\mathrm{M}$，因此 $\\theta_{\\mathrm{A}} = \\ln(10)$\n  - 显著性水平：$\\alpha = 0.05$\n\n- 情况 3（在 $\\mathrm{EC}_{50}$ 附近信息量高，方差小）：\n  - 剂量 (单位 $\\mu\\mathrm{M}$)：$\\{6,\\,8,\\,10,\\,12,\\,15\\}$\n  - 每剂量每处理组的重复数：$\\{20,\\,20,\\,20,\\,20,\\,20\\}$\n  - 残差标准差：$\\sigma = 0.05$\n  - Hill 斜率：$h = 2.0$\n  - 基线 $\\mathrm{EC}_{50,\\mathrm{A}} = 10\\,\\mu\\mathrm{M}$，因此 $\\theta_{\\mathrm{A}} = \\ln(10)$\n  - 显著性水平：$\\alpha = 0.05$\n\n- 情况 4（稀疏设计，最少重复）：\n  - 剂量 (单位 $\\mu\\mathrm{M}$)：$\\{5,\\,10,\\,20\\}$\n  - 每剂量每处理组的重复数：$\\{1,\\,1,\\,1\\}$\n  - 残差标准差：$\\sigma = 0.1$\n  - Hill 斜率：$h = 1.0$\n  - 基线 $\\mathrm{EC}_{50,\\mathrm{A}} = 10\\,\\mu\\mathrm{M}$，因此 $\\theta_{\\mathrm{A}} = \\ln(10)$\n  - 显著性水平：$\\alpha = 0.05$\n\n最终输出格式：\n- 您的程序必须生成单行输出，其中包含与上述四个案例相对应的四个功效值，按顺序排列，并以逗号分隔的列表形式包含在方括号中，例如：$[\\;0.8021,\\,0.0543,\\,0.9999,\\,0.4120\\;]$。每个值必须四舍五入到四位小数，并表示为小数（无百分号）。", "solution": "该问题已经过验证，并被确定为有效。它在科学上基于非线性回归和功效分析的既定统计理论。模型、假设和所需的推导过程定义清晰、客观且自成体系。问题提法得当，并为指定的测试案例提供了所有必要的参数。不存在不一致、模糊或事实不健全之处。因此，我们可以继续进行求解。\n\n任务是计算在剂量-反应实验中，检测两种处理（A 和 B）之间 $\\mathrm{EC}_{50}$ 参数两倍差异的统计功效。推导和计算将遵循基于最大似然估计量的大样本性质和 Fisher 信息矩阵的结构化方法。\n\n在给定剂量 $x$ 和处理 $t$ 下的生物反应 $Y$ 由正态分布 $Y \\mid x,t \\sim \\mathcal{N}(\\mu(x;\\theta_t), \\sigma^2)$ 建模，其中平均反应函数 $\\mu(x;\\theta)$ 遵循一个四参数逻辑斯蒂模型（Hill 方程），其顶部和底部渐近线分别固定为 $1$ 和 $0$。平均函数由下式给出：\n$$\n\\mu(x;\\theta) = \\frac{1}{1 + \\exp(h(\\ln x - \\theta))}\n$$\n这里，$\\theta = \\ln(\\mathrm{EC}_{50})$ 是我们感兴趣的参数，代表产生 $50\\%$ 反应的有效浓度的自然对数，而 $h$ 是 Hill 斜率，假设其已知且在不同处理组之间保持不变。\n\n分析按规定的四个步骤进行。\n\n**步骤 1：偏导数和 Fisher 信息的推导**\n\n首先，我们推导平均函数 $\\mu(x;\\theta)$ 相对于参数 $\\theta$ 的偏导数。该导数对于计算 Fisher 信息至关重要。使用链式法则，令 $u(x;\\theta) = h(\\ln x - \\theta)$。则 $\\mu = (1 + e^u)^{-1}$。\n$$\n\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta} = -\\frac{1}{(1 + e^u)^2} \\cdot \\frac{\\partial}{\\partial \\theta}(e^u) = -\\frac{e^u}{(1 + e^u)^2} \\cdot \\frac{\\partial u}{\\partial \\theta}\n$$\n$u$ 相对于 $\\theta$ 的导数为：\n$$\n\\frac{\\partial u}{\\partial \\theta} = \\frac{\\partial}{\\partial \\theta}(h(\\ln x - \\theta)) = -h\n$$\n将其代回，我们得到：\n$$\n\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta} = -\\frac{\\exp(h(\\ln x - \\theta))}{(1 + \\exp(h(\\ln x - \\theta)))^2} \\cdot (-h) = \\frac{h \\exp(h(\\ln x - \\theta))}{(1 + \\exp(h(\\ln x - \\theta)))^2}\n$$\n通过观察 $\\mu(x;\\theta) = \\frac{1}{1 + e^u}$ 和 $1 - \\mu(x;\\theta) = \\frac{e^u}{1 + e^u}$，可以巧妙地简化此表达式。因此，导数为：\n$$\n\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta} = h \\cdot \\left(\\frac{1}{1+e^u}\\right) \\cdot \\left(\\frac{e^u}{1+e^u}\\right) = h \\cdot \\mu(x;\\theta) \\cdot (1 - \\mu(x;\\theta))\n$$\n在给定剂量 $x$ 下，单个观测值对 $\\theta$ 的 Fisher 信息定义为 $\\mathcal{I}(\\theta; x) = \\frac{1}{\\sigma^2} \\left(\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta}\\right)^2$。代入我们的导数，得到：\n$$\n\\mathcal{I}(\\theta; x) = \\frac{1}{\\sigma^2} \\left[ h \\cdot \\mu(x;\\theta)(1 - \\mu(x;\\theta)) \\right]^2 = \\frac{h^2}{\\sigma^2} [\\mu(x;\\theta)(1 - \\mu(x;\\theta))]^2\n$$\n对于一个由 $m$ 个剂量 $\\{x_i\\}_{i=1}^m$ 和每个剂量下的 $r_i$ 个重复组成的实验设计，一个处理组的总 Fisher 信息是所有独立观测值的总和：\n$$\n\\mathcal{I}_{\\text{total}}(\\theta) = \\sum_{i=1}^{m} r_i \\cdot \\mathcal{I}(\\theta; x_i) = \\frac{h^2}{\\sigma^2} \\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta)(1 - \\mu(x_i;\\theta))]^2\n$$\n\n**步骤 2：参数估计量的渐近方差**\n\n根据大样本理论，最大似然估计量 $\\widehat{\\theta}$ 的方差可近似为总 Fisher 信息的倒数，即 $\\mathrm{Var}(\\widehat{\\theta}) \\approx [\\mathcal{I}_{\\text{total}}(\\theta)]^{-1}$。我们在备择假设 $H_1$ 下，使用真实的参数值计算每个处理组的此方差。\n\n在 $H_1$ 下，真实参数为处理组 A 的 $\\theta_{\\mathrm{A}} = \\ln(\\mathrm{EC}_{50,\\mathrm{A}})$ 和处理组 B 的 $\\theta_{\\mathrm{B}} = \\theta_{\\mathrm{A}} + \\ln f$，其中倍数变化 $f$ 给定为 $f=2$。\n\n$\\theta_{\\mathrm{A}}$ 估计量的方差为：\n$$\n\\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{A}}) \\approx \\left( \\frac{h^2}{\\sigma^2} \\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{A}})(1 - \\mu(x_i;\\theta_{\\mathrm{A}}))]^2 \\right)^{-1}\n$$\n类似地，$\\theta_{\\mathrm{B}}$ 估计量的方差为：\n$$\n\\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{B}}) \\approx \\left( \\frac{h^2}{\\sigma^2} \\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{B}})(1 - \\mu(x_i;\\theta_{\\mathrm{B}}))]^2 \\right)^{-1}\n$$\n\n**步骤 3：差异的标准误**\n\n我们要检验的是差异 $\\delta = \\theta_{\\mathrm{B}} - \\theta_{\\mathrm{A}}$。该差异的估计量是 $\\widehat{\\delta} = \\widehat{\\theta}_{\\mathrm{B}} - \\widehat{\\theta}_{\\mathrm{A}}$。由于处理组 A 和 B 的实验是独立的，$\\widehat{\\delta}$ 的方差是各自方差之和：\n$$\n\\mathrm{Var}(\\widehat{\\delta}) = \\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{A}}) + \\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{B}})\n$$\n差异的标准误 $\\mathrm{SE}(\\widehat{\\delta})$ 是该方差的平方根：\n$$\n\\mathrm{SE}(\\widehat{\\delta}) = \\sqrt{\\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{A}}) + \\mathrm{Var}(\\widehat{\\theta}_{\\mathrm{B}})}\n$$\n代入方差的表达式，我们有：\n$$\n\\mathrm{SE}(\\widehat{\\delta}) = \\sqrt{ \\frac{\\sigma^2}{h^2} \\left(\\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{A}})(1-\\mu(x_i;\\theta_{\\mathrm{A}}))]^2\\right)^{-1} + \\frac{\\sigma^2}{h^2} \\left(\\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{B}})(1-\\mu(x_i;\\theta_{\\mathrm{B}}))]^2\\right)^{-1} }\n$$\n这可以简化为：\n$$\n\\mathrm{SE}(\\widehat{\\delta}) = \\frac{\\sigma}{h} \\sqrt{ \\left(\\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{A}})(1-\\mu(x_i;\\theta_{\\mathrm{A}}))]^2\\right)^{-1} + \\left(\\sum_{i=1}^{m} r_i [\\mu(x_i;\\theta_{\\mathrm{B}})(1-\\mu(x_i;\\theta_{\\mathrm{B}}))]^2\\right)^{-1} }\n$$\n\n**步骤 4：功效计算**\n\n最后一步是计算双边 Wald 检验的功效。在 $H_1$ 下，检验统计量近似服从正态分布：$Z = \\frac{\\widehat{\\delta}}{\\mathrm{SE}(\\widehat{\\delta})} \\approx \\mathcal{N}(\\lambda, 1)$，其中 $\\lambda = \\frac{\\delta}{\\mathrm{SE}(\\widehat{\\delta})}$ 是非中心化参数。$H_1$ 下的真实差异是 $\\delta = \\ln f$。\n$$\n\\lambda = \\frac{|\\ln f|}{\\mathrm{SE}(\\widehat{\\delta})}\n$$\n在显著性水平 $\\alpha$ 下，双边检验的功效是在备择假设 $H_1$ 为真时，拒绝零假设 $H_0: \\delta=0$ 的概率。该概率为：\n$$\n\\text{Power} = \\Pr\\big(|Z|  z_{1-\\alpha/2} \\mid H_1\\big)\n$$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。这可以使用标准正态累积分布函数 $\\Phi$ 来计算：\n$$\n\\text{Power} = 1 - \\Pr\\big(-z_{1-\\alpha/2} \\le Z \\le z_{1-\\alpha/2} \\mid H_1\\big) = 1 - (\\Phi(z_{1-\\alpha/2} - \\lambda) - \\Phi(-z_{1-\\alpha/2} - \\lambda))\n$$\n这是功效的最终公式。实现将遵循这些推导出的步骤。对于每个测试案例，我们将代入给定的 $\\{x_i, r_i\\}$、$\\sigma$、$h$、$\\mathrm{EC}_{50,\\mathrm{A}}$、$f=2$ 和 $\\alpha=0.05$ 的值来计算功效。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves for the statistical power in four dose-response experiment scenarios.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: balanced, informative, moderate variance\n        {\n            \"doses\": np.array([1.0, 3.0, 10.0, 30.0, 100.0]),\n            \"replicates\": np.array([6, 6, 6, 6, 6]),\n            \"sigma\": 0.1,\n            \"h\": 1.2,\n            \"ec50_a\": 10.0,\n            \"f\": 2.0,\n            \"alpha\": 0.05\n        },\n        # Case 2: doses far below baseline EC50, lower information\n        {\n            \"doses\": np.array([0.01, 0.03, 0.1, 0.3, 1.0]),\n            \"replicates\": np.array([4, 4, 4, 4, 4]),\n            \"sigma\": 0.15,\n            \"h\": 1.2,\n            \"ec50_a\": 10.0,\n            \"f\": 2.0,\n            \"alpha\": 0.05\n        },\n        # Case 3: highly informative near EC50, small variance\n        {\n            \"doses\": np.array([6.0, 8.0, 10.0, 12.0, 15.0]),\n            \"replicates\": np.array([20, 20, 20, 20, 20]),\n            \"sigma\": 0.05,\n            \"h\": 2.0,\n            \"ec50_a\": 10.0,\n            \"f\": 2.0,\n            \"alpha\": 0.05\n        },\n        # Case 4: sparse design, minimal replication\n        {\n            \"doses\": np.array([5.0, 10.0, 20.0]),\n            \"replicates\": np.array([1, 1, 1]),\n            \"sigma\": 0.1,\n            \"h\": 1.0,\n            \"ec50_a\": 10.0,\n            \"f\": 2.0,\n            \"alpha\": 0.05\n        }\n    ]\n\n    def calculate_power(doses, replicates, sigma, h, ec50_a, f, alpha):\n        \"\"\"\n        Calculates statistical power based on Fisher information for a given design.\n        \"\"\"\n        # Step 1: Define parameters and mean function\n        theta_a = np.log(ec50_a)\n        theta_b = theta_a + np.log(f)\n\n        def mean_response(x, theta):\n            # Hill-type dose-response function\n            return 1.0 / (1.0 + np.exp(h * (np.log(x) - theta)))\n\n        # Step 2: Calculate total Fisher Information components\n        def get_fisher_info_summand(theta):\n            # Calculates the sum part of the Fisher Information formula\n            # Sum over i of r_i * [mu_i * (1-mu_i)]^2\n            sum_val = 0.0\n            for i in range(len(doses)):\n                mu = mean_response(doses[i], theta)\n                # The weight for each observation is [mu * (1-mu)]^2\n                weight = (mu * (1.0 - mu))**2\n                sum_val += replicates[i] * weight\n            return sum_val\n\n        sum_fisher_a = get_fisher_info_summand(theta_a)\n        sum_fisher_b = get_fisher_info_summand(theta_b)\n        \n        # Step 3: Calculate variances and standard error of the difference\n        # Var(theta_hat) = 1 / I_total(theta) = (sigma^2/h^2) / Sum(...)\n        if sum_fisher_a == 0 or sum_fisher_b == 0:\n            # Avoid division by zero for non-informative designs\n            return 0.0\n            \n        var_theta_a = (sigma**2 / h**2) / sum_fisher_a\n        var_theta_b = (sigma**2 / h**2) / sum_fisher_b\n        \n        se_delta = np.sqrt(var_theta_a + var_theta_b)\n\n        # Step 4: Calculate noncentrality parameter and power\n        delta = np.log(f)\n        if se_delta == 0:\n             return 1.0 if delta != 0 else alpha\n        \n        noncentrality_param = np.abs(delta) / se_delta\n        \n        z_crit = norm.ppf(1.0 - alpha / 2.0)\n        \n        power = 1.0 - (norm.cdf(z_crit - noncentrality_param) - norm.cdf(-z_crit - noncentrality_param))\n        \n        return power\n\n    results = []\n    for case in test_cases:\n        power = calculate_power(\n            doses=case[\"doses\"],\n            replicates=case[\"replicates\"],\n            sigma=case[\"sigma\"],\n            h=case[\"h\"],\n            ec50_a=case[\"ec50_a\"],\n            f=case[\"f\"],\n            alpha=case[\"alpha\"]\n        )\n        # Round to four decimal places\n        results.append(round(power, 4))\n    \n    # Format results as a string with no spaces as per template\n    # Example format required: \"[0.8021,0.0543,0.9999,0.4120]\"\n    formatted_results = [f\"{res:.4f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2481284"}, {"introduction": "毒理学研究常常涉及在一段时间内对同一个体进行重复测量，以观察其生长或响应的动态变化。这种纵向数据（longitudinal data）结构需要超越简单剂量-反应模型的复杂统计方法。本练习将引导您构建一个非线性混合效应模型（nonlinear mixed-effects model），这是一种能够同时处理个体间变异（通过随机效应）和个体内测量数据自相关性（通过自回归误差结构）的强大工具 [@problem_id:2481338]。完成此练习后，您将能够从复杂的时序数据中准确估计如 $EC_{50}$ 这样的关键毒性参数，从而更深入地理解污染物对生物生长过程的动态影响。", "problem": "给定在生态毒理学研究中，多个个体在恒定化学暴露下生成的重复测量生长数据。科学目标是，在一个机理非线性混合效应模型下，估计半数有效浓度 (EC50)，该浓度定义为在该浓度下，生长速率所受影响达到相对于对照组最大差异的一半时的浓度。您必须实现一个程序，为几个指定的测试案例计算 EC50 的最大似然估计 (MLE)，单位为毫克/升，并将这些估计值作为浮点数输出在单行中。\n\n基本基础和模型组件：\n-   半数有效浓度 (EC50) 是一个参数，它根据对内在生长速率的单调抑制效应函数来衡量暴露-响应关系。设暴露浓度为 $C$ 时的生长速率为 $r(C)$。\n-   抑制效应函数遵循Hill型形式，其中Hill系数固定为 $h = 1$，因此浓度依赖性生长速率由映射 $r(C) = \\dfrac{r_{\\max}}{1 + \\left(C/\\theta\\right)^{h}}$ 给出，其中 $\\theta$ 是待估计的 EC50，$r_{\\max}$ 是在没有毒物效应时的最大生长速率，$h$ 固定为 $1$。\n-   对于暴露于恒定浓度 $C_i$ 的个体 $i$，在时间 $t_{i1}, \\dots, t_{iT_i}$（单位为天）进行观察，其平均结构生长轨迹建模为 $m_{ij}(b_i, \\theta) = K_i \\left(1 - \\exp\\left(- r(C_i) \\, t_{ij}\\right)\\right)$，其中渐近尺寸参数为 $K_i = \\exp(\\mu_K + b_i)$，$b_i$ 是特定于受试者的随机效应。\n-   随机效应指定为 $b_i \\sim \\mathcal{N}(0, \\tau^2)$，在个体间独立，因此 $K_i$ 服从对数正态分布。\n-   每个个体内的残差误差过程遵循带有高斯新息的一阶自回归过程 (AR($1$))，定义为 $e_{i1} \\sim \\mathcal{N}\\!\\left(0, \\sigma^2/(1-\\rho^2)\\right)$，并且对于 $j \\ge 2$，$e_{ij} = \\rho \\, e_{i,j-1} + u_{ij}$，其中 $u_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$，$|\\rho|  1$，$\\sigma^2  0$。\n-   观测模型为 $y_{ij} = m_{ij}(b_i, \\theta) + e_{ij}$。\n\n似然基础：\n-   在给定 $b_i$ 的条件下，观测向量 $\\mathbf{y}_i = (y_{i1}, \\dots, y_{iT_i})^\\top$ 服从由上述 AR($1$) 残差结构所隐含的多元正态分布。由于 AR($1$) 过程的高斯马尔可夫性质，条件似然可分解为 $p(y_{i1} \\mid b_i) \\prod_{j=2}^{T_i} p(y_{ij} \\mid y_{i,j-1}, b_i)$。\n-   $\\mathbf{y}_i$ 的边缘似然是对随机效应的积分：$L_i(\\theta) = \\int \\left[\\prod_{j=1}^{T_i} p(y_{ij} \\mid b_i, \\theta)\\right] \\phi(b_i; 0, \\tau^2) \\, \\mathrm{d}b_i$，其中 $\\phi(\\cdot;0,\\tau^2)$ 是均值为 $0$、方差为 $\\tau^2$ 的正态密度函数。\n-   总对数似然为 $\\ell(\\theta) = \\sum_{i=1}^{N} \\log L_i(\\theta)$。\n\n计算要求：\n-   对于这种非线性均值函数，关于 $b_i$ 的积分没有封闭形式；您必须使用至少 $n = 21$ 个节点的高斯-埃尔米特求积法来近似它。使用恒等式\n$$\n\\int_{-\\infty}^{\\infty} \\phi(b; 0, \\tau^2) \\, f(b) \\, \\mathrm{d}b \\;=\\; \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} e^{-x^2} f(\\sqrt{2}\\,\\tau x) \\, \\mathrm{d}x,\n$$\n因此求积近似为\n$$\n\\int \\phi(b;0,\\tau^2) f(b) \\, \\mathrm{d}b \\;\\approx\\; \\frac{1}{\\sqrt{\\pi}} \\sum_{k=1}^{n} w_k \\, f\\!\\left(\\sqrt{2}\\,\\tau \\, x_k\\right),\n$$\n其中 $\\{x_k, w_k\\}_{k=1}^{n}$ 是 $n$ 点高斯-埃尔米特节点和权重。\n-   您必须在 $\\theta  0$ 的范围内最大化 $\\ell(\\theta)$。在 $\\theta \\in [a, b]$（其中 $a = 10^{-2}$ 和 $b = 10^{2}$）上执行单变量有界优化，并报告 $\\theta$ (EC50) 的MLE，单位为毫克/升，形式为浮点数，四舍五入到三位小数。\n\n数据生成协议（您的程序必须精确再现）：\n-   对于每个测试案例，使用指定的参数和伪随机种子根据模型生成数据。对于个体 $i$，抽取 $b_i \\sim \\mathcal{N}(0, \\tau^2)$ 并设置 $K_i = \\exp(\\mu_K + b_i)$。对于 AR($1$) 残差，独立地抽取 $e_{i1} \\sim \\mathcal{N}(0, \\sigma^2/(1-\\rho^2))$，然后 $e_{ij} = \\rho e_{i,j-1} + u_{ij}$，其中 $u_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。观测值为 $y_{ij} = K_i \\left(1 - \\exp\\left(- r(C_i) \\, t_{ij}\\right)\\right) + e_{ij}$，其中 $r(C_i) = \\dfrac{r_{\\max}}{1 + (C_i/\\theta_{\\mathrm{true}})^{h}}$ 且 $h = 1$。所有时间单位为天，所有浓度和 EC50 单位为毫克/升，$r_{\\max}$ 单位为 天$^{-1}$。用于生成每个数据集的真实 EC50 已提供，但在估计中必须视为未知。\n\n测试套件：\n对于每个案例，您的程序必须使用指定的种子和参数生成数据集，然后如上所述计算 $\\theta$ (EC50) 的 MLE。这些案例是：\n\n-   案例 A:\n    -   种子: $202311$\n    -   个体数: $N = 6$\n    -   时间 (天): $[1, 2, 4, 7, 10, 14]$\n    -   暴露浓度 (mg/L): $[0.5, 1.0, 2.0, 4.0, 8.0, 16.0]$\n    -   真实 EC50 (mg/L): $\\theta_{\\mathrm{true}} = 4.0$\n    -   $r_{\\max} = 0.6$ 天$^{-1}$\n    -   $\\mu_K = \\ln(100)$\n    -   $\\tau = 0.2$\n    -   $\\sigma = 3.0$\n    -   $\\rho = 0.5$\n    -   $h = 1$\n\n-   案例 B:\n    -   种子: $202312$\n    -   个体数: $N = 8$\n    -   时间 (天): $[1, 2, 3, 5, 8, 12]$\n    -   暴露浓度 (mg/L): $[0.25, 0.75, 1.5, 3.0, 6.0, 12.0, 18.0, 24.0]$\n    -   真实 EC50 (mg/L): $\\theta_{\\mathrm{true}} = 6.0$\n    -   $r_{\\max} = 0.5$ 天$^{-1}$\n    -   $\\mu_K = \\ln(80)$\n    -   $\\tau = 0.15$\n    -   $\\sigma = 2.0$\n    -   $\\rho = 0.2$\n    -   $h = 1$\n\n-   案例 C:\n    -   种子: $202313$\n    -   个体数: $N = 5$\n    -   时间 (天): $[2, 4, 6, 9, 13]$\n    -   暴露浓度 (mg/L): $[1.0, 2.0, 5.0, 10.0, 20.0]$\n    -   真实 EC50 (mg/L): $\\theta_{\\mathrm{true}} = 5.0$\n    -   $r_{\\max} = 0.7$ 天$^{-1}$\n    -   $\\mu_K = \\ln(150)$\n    -   $\\tau = 0.3$\n    -   $\\sigma = 4.0$\n    -   $\\rho = 0.8$\n    -   $h = 1$\n\n-   案例 D:\n    -   种子: $202314$\n    -   个体数: $N = 4$\n    -   时间 (天): $[1, 3, 7, 14]$\n    -   暴露浓度 (mg/L): $[0.5, 2.0, 4.0, 12.0]$\n    -   真实 EC50 (mg/L): $\\theta_{\\mathrm{true}} = 3.0$\n    -   $r_{\\max} = 0.4$ 天$^{-1}$\n    -   $\\mu_K = \\ln(60)$\n    -   $\\tau = 0.05$\n    -   $\\sigma = 1.0$\n    -   $\\rho = 0.0$\n    -   $h = 1$\n\n您必须计算和输出的内容：\n-   对于每个案例，通过最大化使用高斯-埃尔米特求积（使用至少 $n = 21$ 个节点）构建的边缘对数似然 $\\ell(\\theta)$，来计算EC50的MLE $\\hat{\\theta}$，单位为毫克/升。\n-   在 $\\theta \\in [10^{-2}, 10^{2}]$ 范围内使用有界单变量优化器。在内部，如果需要，您可以通过重新参数化来强制正性，但报告的值必须在原始尺度上。\n-   报告四个估计的EC50值，形式为浮点数，每个都四舍五入到三位小数。\n-   你的程序应生成单行输出，其中包含一个用方brackets括起来的逗号分隔列表形式的结果，顺序为案例A、案例B、案例C、案例D（例如，\"[$\\hat{\\theta}_A,\\hat{\\theta}_B,\\hat{\\theta}_C,\\hat{\\theta}_D$]\"），但输出行中不含任何单位。\n\n所有假设和参数值必须完全按照规定实现。不允许用户输入。输出必须是可复现的。EC50以毫克/升为单位表示，并以浮点数形式四舍五入至三位小数。", "solution": "问题陈述已经过严格审查并被认定为有效。它在科学上是合理的、定义明确的、客观的且内部一致的。它提出了生态毒理学中统计建模的一个标准任务，尽管计算量较大：即在一个非线性混合效应模型中对参数进行最大似然估计。模型组件，包括von Bertalanffy型生长函数、Hill型剂量-响应关系、对数正态随机效应以及AR($1$)残差误差结构，都是该领域的标准构造。关于数据生成和数值近似的指令是精确的，并允许一个唯一的、可验证的解。我们将着手推导和实现该解。\n\n目标是找到半数有效浓度（表示为 $\\theta$ (EC50)）的最大似然估计 (MLE)。MLE $\\hat{\\theta}$ 是使观测数据的总对数似然函数 $\\ell(\\theta)$ 最大化的 $\\theta$ 值。数据由 $N$ 个个体组成，每个个体都有一组在时间 $\\mathbf{t}_i = (t_{i1}, \\dots, t_{iT_i})^\\top$ 于恒定暴露浓度 $C_i$ 下测量的观测值 $\\mathbf{y}_i = (y_{i1}, \\dots, y_{iT_i})^\\top$。\n\n假设个体间相互独立，总对数似然是每个个体对数似然的总和：\n$$\n\\ell(\\theta) = \\sum_{i=1}^{N} \\log L_i(\\theta)\n$$\n这里，$L_i(\\theta)$ 是个体 $i$ 的观测向量 $\\mathbf{y}_i$ 的边缘似然。它是通过将条件似然 $p(\\mathbf{y}_i \\mid b_i, \\theta)$ 对个体特异性随机效应 $b_i$ 的分布进行积分得到的。随机效应 $b_i$ 被指定为服从正态分布 $b_i \\sim \\mathcal{N}(0, \\tau^2)$，其密度为 $\\phi(b_i; 0, \\tau^2)$。因此，边缘似然为：\n$$\nL_i(\\theta) = \\int_{-\\infty}^{\\infty} p(\\mathbf{y}_i \\mid b_i, \\theta) \\, \\phi(b_i; 0, \\tau^2) \\, \\mathrm{d}b_i\n$$\n$p(\\mathbf{y}_i \\mid b_i, \\theta)$ 项是给定随机效应 $b_i$ 和参数 $\\theta$ 时，个体 $i$ 观测值的联合概率密度。问题为残差 $e_{ij} = y_{ij} - m_{ij}(b_i, \\theta)$ 指定了一个一阶自回归 AR($1$) 过程。由于 AR($1$) 过程的马尔可夫性质，条件似然可以分解为：\n$$\np(\\mathbf{y}_i \\mid b_i, \\theta) = p(y_{i1} \\mid b_i, \\theta) \\prod_{j=2}^{T_i} p(y_{ij} \\mid y_{i,j-1}, b_i, \\theta)\n$$\n此乘积中的各项是正态分布的密度：\n1.  第一个观测值 $y_{i1}$ 仅以 $b_i$ 和 $\\theta$ 为条件。其分布为 $y_{i1} \\sim \\mathcal{N}\\left(m_{i1}(b_i, \\theta), \\frac{\\sigma^2}{1-\\rho^2}\\right)$。\n2.  对于后续观测值 ($j \\ge 2$)，$y_{ij}$ 的分布以前一个观测值 $y_{i,j-1}$ 以及 $b_i$ 和 $\\theta$ 为条件。关系 $e_{ij} = \\rho e_{i,j-1} + u_{ij}$ 意味着 $y_{ij} - m_{ij} = \\rho(y_{i,j-1} - m_{i,j-1}) + u_{ij}$，其中 $u_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。因此，$y_{ij} \\mid y_{i,j-1}, b_i, \\theta \\sim \\mathcal{N}\\left(m_{ij} + \\rho(y_{i,j-1} - m_{i,j-1}), \\sigma^2\\right)$。\n\n平均轨迹函数 $m_{ij}(b_i, \\theta)$ 由下式给出：\n$$\nm_{ij}(b_i, \\theta) = K_i \\left(1 - \\exp\\left(- r(C_i, \\theta) \\, t_{ij}\\right)\\right)\n$$\n其中 $K_i = \\exp(\\mu_K + b_i)$ 且 $r(C_i, \\theta) = \\dfrac{r_{\\max}}{1 + (C_i/\\theta)^{h}}$，Hill系数 $h=1$。\n\n由于 $m_{ij}$ 对 $b_i$ 的非线性依赖性，$L_i(\\theta)$ 的积分没有封闭形式解。它必须通过数值方法来近似。问题指定了高斯-埃尔米特求积法。使用提供的恒等式，该积分近似为：\n$$\nL_i(\\theta) \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{k=1}^{n} w_k \\, p(\\mathbf{y}_i \\mid b_k, \\theta)\n$$\n其中 $\\{x_k, w_k\\}_{k=1}^n$ 是 $n$ 点高斯-埃尔米特节点和权重，随机效应值在 $b_k = \\sqrt{2}\\tau x_k$ 处求值。我们将使用 $n=21$ 个节点。\n\n为了稳健地实现这一点，我们计算边缘似然的对数 $\\log L_i(\\theta)$。直接计算总和可能导致数值下溢或上溢。我们应用log-sum-exp技巧。单个个体的对数似然为：\n$$\n\\log L_i(\\theta) \\approx \\log\\left(\\frac{1}{\\sqrt{\\pi}}\\right) + \\log\\left(\\sum_{k=1}^{n} w_k \\, p(\\mathbf{y}_i \\mid b_k, \\theta)\\right) = -\\frac{1}{2}\\log\\pi + \\log\\left(\\sum_{k=1}^{n} \\exp\\left(\\log w_k + \\log p(\\mathbf{y}_i \\mid b_k, \\theta)\\right)\\right)\n$$\n令 $A_k = \\log w_k + \\log p(\\mathbf{y}_i \\mid b_k, \\theta)$ 且 $A_{\\max} = \\max_k A_k$，则该和可计算为 $A_{\\max} + \\log(\\sum_k \\exp(A_k - A_{\\max}))$。\n\n计算流程如下：\n1.  对于每个测试案例，严格按照指定的协议生成数据集。这包括设置随机种子，从指定的正态分布中抽取随机效应和残差误差，并计算观测值。\n2.  定义一个目标函数，该函数在给定 $\\theta$ 值和生成的数据的情况下，计算负的总对数似然 $-\\ell(\\theta)$。该函数遍历每个个体，使用具有log-sum-exp稳定化技巧的 $n=21$ 点高斯-埃尔米特求积法计算其边缘对数似然 $\\log L_i(\\theta)$，然后将它们相加。\n3.  使用数值优化程序找到使该目标函数最小化的 $\\theta$ 值，约束条件为 $\\theta \\in [10^{-2}, 10^{2}]$。这便得到了MLE $\\hat{\\theta}$。\n4.  每个案例的最终结果四舍五入到三位小数。完整的实现已在最终答案中提供。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\nfrom numpy.polynomial.hermite import hermgauss\n\n# Global constants as per problem specification\nN_QUAD = 21\nOPT_BOUNDS = (1e-2, 1e2)\nGH_NODES, GH_WEIGHTS = hermgauss(N_QUAD)\n\ndef generate_data(seed, N, times, exposures, theta_true, r_max, mu_K, tau, sigma, rho, h):\n    \"\"\"\n    Generates simulated toxicity data for N individuals based on the model.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    dataset = []\n\n    for i in range(N):\n        C_i = exposures[i]\n        \n        # 1. Draw random effect b_i and determine individual asymptotic size K_i\n        b_i = rng.normal(loc=0.0, scale=tau)\n        K_i = np.exp(mu_K + b_i)\n        \n        # 2. Calculate the concentration-dependent growth rate r(C_i)\n        r_c = r_max / (1.0 + (C_i / theta_true)**h)\n        \n        # 3. Generate AR(1) residual error series e_ij\n        T_i = len(times)\n        errors = np.zeros(T_i)\n        \n        # Variance of the first error term e_i1\n        var_e1 = sigma**2 / (1.0 - rho**2) if rho != 1.0 else sigma**2\n        errors[0] = rng.normal(loc=0.0, scale=np.sqrt(var_e1))\n        \n        # Subsequent error terms e_ij for j > 1\n        for j in range(1, T_i):\n            u_ij = rng.normal(loc=0.0, scale=sigma)\n            errors[j] = rho * errors[j-1] + u_ij\n            \n        # 4. Compute the mean trajectory and the final observations\n        mean_trajectory = K_i * (1.0 - np.exp(-r_c * times))\n        observations = mean_trajectory + errors\n        \n        dataset.append({'C': C_i, 't': times, 'y': observations})\n        \n    return dataset\n\ndef neg_log_likelihood(theta, data, r_max, mu_K, tau, sigma, rho, h):\n    \"\"\"\n    Calculates the negative marginal log-likelihood for the entire dataset.\n    This is the objective function for the optimizer.\n    \"\"\"\n    total_log_lik = 0.0\n\n    # Iterate over each individual in the dataset\n    for ind_data in data:\n        C_i, t_i, y_i = ind_data['C'], ind_data['t'], ind_data['y']\n        T_i = len(t_i)\n        \n        # Terms for the log-sum-exp computation over quadrature nodes\n        log_lik_terms = np.zeros(N_QUAD)\n\n        # Growth rate for the current candidate theta\n        r_c = r_max / (1.0 + (C_i / theta)**h)\n\n        # Iterate over Gaussian-Hermite quadrature nodes\n        for k in range(N_QUAD):\n            x_k, w_k = GH_NODES[k], GH_WEIGHTS[k]\n            \n            # Map quadrature node to the random effect scale\n            b_k = np.sqrt(2.0) * tau * x_k\n            \n            # Individual's asymptotic size for this value of the random effect\n            K_k = np.exp(mu_K + b_k)\n            \n            # Mean growth trajectory for this b_k and theta\n            m_k = K_k * (1.0 - np.exp(-r_c * t_i))\n            \n            # Calculate conditional log-likelihood log p(y_i | b_k, theta)\n            cond_log_lik = 0.0\n            \n            # Log-likelihood contribution from the first time point (j=1)\n            var1 = sigma**2 / (1.0 - rho**2) if rho != 1.0 else sigma**2\n            log_pdf_1 = -0.5 * np.log(2.0 * np.pi * var1) - ((y_i[0] - m_k[0])**2) / (2.0 * var1)\n            cond_log_lik += log_pdf_1\n            \n            # Log-likelihood contribution from subsequent time points (j>=2)\n            if T_i > 1:\n                innovations = (y_i[1:] - m_k[1:]) - rho * (y_i[:-1] - m_k[:-1])\n                log_pdf_ar1 = -0.5 * np.log(2.0 * np.pi * sigma**2) - (innovations**2) / (2.0 * sigma**2)\n                cond_log_lik += np.sum(log_pdf_ar1)\n                \n            log_lik_terms[k] = np.log(w_k) + cond_log_lik\n\n        # Use log-sum-exp for stable computation of log(integral)\n        max_log = np.max(log_lik_terms)\n        log_L_i = max_log + np.log(np.sum(np.exp(log_lik_terms - max_log)))\n        \n        # Final individual log-likelihood including quadrature constant\n        individual_log_lik = -0.5 * np.log(np.pi) + log_L_i\n        \n        total_log_lik += individual_log_lik\n        \n    return -total_log_lik\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        {\n            'seed': 202311, 'N': 6, 'times': np.array([1, 2, 4, 7, 10, 14]),\n            'exposures': np.array([0.5, 1.0, 2.0, 4.0, 8.0, 16.0]), 'theta_true': 4.0,\n            'r_max': 0.6, 'mu_K': np.log(100), 'tau': 0.2, 'sigma': 3.0, 'rho': 0.5, 'h': 1\n        },\n        {\n            'seed': 202312, 'N': 8, 'times': np.array([1, 2, 3, 5, 8, 12]),\n            'exposures': np.array([0.25, 0.75, 1.5, 3.0, 6.0, 12.0, 18.0, 24.0]), 'theta_true': 6.0,\n            'r_max': 0.5, 'mu_K': np.log(80), 'tau': 0.15, 'sigma': 2.0, 'rho': 0.2, 'h': 1\n        },\n        {\n            'seed': 202313, 'N': 5, 'times': np.array([2, 4, 6, 9, 13]),\n            'exposures': np.array([1.0, 2.0, 5.0, 10.0, 20.0]), 'theta_true': 5.0,\n            'r_max': 0.7, 'mu_K': np.log(150), 'tau': 0.3, 'sigma': 4.0, 'rho': 0.8, 'h': 1\n        },\n        {\n            'seed': 202314, 'N': 4, 'times': np.array([1, 3, 7, 14]),\n            'exposures': np.array([0.5, 2.0, 4.0, 12.0]), 'theta_true': 3.0,\n            'r_max': 0.4, 'mu_K': np.log(60), 'tau': 0.05, 'sigma': 1.0, 'rho': 0.0, 'h': 1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # 1. Generate data for the current case\n        data = generate_data(\n            case['seed'], case['N'], case['times'], case['exposures'], case['theta_true'],\n            case['r_max'], case['mu_K'], case['tau'], case['sigma'], case['rho'], case['h']\n        )\n        \n        # 2. Define the objective function for optimization\n        objective_func = lambda theta: neg_log_likelihood(\n            theta, data, case['r_max'], case['mu_K'], case['tau'],\n            case['sigma'], case['rho'], case['h']\n        )\n        \n        # 3. Perform bounded minimization to find the MLE of theta (EC50)\n        opt_result = minimize_scalar(\n            objective_func,\n            bounds=OPT_BOUNDS,\n            method='bounded'\n        )\n        \n        mle_theta = opt_result.x\n        results.append(f\"{mle_theta:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "2481338"}, {"introduction": "生态风险评估的一个核心挑战是如何整合来自不同物种的毒性数据，以预测对整个生态系统或一个新物种的潜在影响。本练习介绍了一种强大的解决方案：分层贝叶斯模型（hierarchical Bayesian model）。您将学习如何构建一个模型，在该模型中，每个物种的敏感性（以对数尺度的 $EC_{50}$ 表示）被视为从一个总体的物种敏感性分布中抽取的样本 [@problem_id:2481192]。通过这项实践，您不仅可以综合多个物种的数据来估计该总体分布，还能学习如何为先前未观测到的新物种生成后验预测分布，并对其 $EC_{50}$ 值进行不确定性量化，这是高级生态风险评估中的一项核心技能。", "problem": "您正在使用分层贝叶斯框架，在对数尺度上对一种污染物的半数有效浓度（EC50）的种间变异进行建模，以保证浓度的正值性并稳定变异性。设 $S$ 表示在精心设计的实验中，具有可用剂量-反应摘要的物种数量。对于每个物种 $s \\in \\{1,\\dots,S\\}$，设 $y_s$ 为其观测到的有效浓度（单位为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$），并定义 $x_s = \\log(y_s)$，其中 $\\log(\\cdot)$ 是自然对数。假设以下分层模型：潜在的物种水平对数效应 $x_s$ 是独立同分布的，即 $x_s \\mid \\mu,\\tau^2 \\sim \\mathcal{N}(\\mu,\\tau^2)$，其中 $\\mu$ 是跨物种的平均对数效应，$\\tau^2$ 是对数尺度上的跨物种方差。对 $(\\mu,\\tau^2)$ 设置一个共轭的正态-逆伽马先验，具体为 $\\mu \\mid \\tau^2 \\sim \\mathcal{N}(m_0,\\tau^2/\\kappa_0)$ 和 $\\tau^2 \\sim \\mathrm{Inv\\mbox{-}Gamma}(a_0,b_0)$，其中逆伽马分布的密度参数化为 $p(\\tau^2) \\propto (\\tau^2)^{-(a_0+1)} \\exp(-b_0/\\tau^2)$（对于 $\\tau^20$）。\n\n您的任务是：\n- 仅从所述模型和先验出发，推导在给定数据 $\\{x_s\\}_{s=1}^S$ 的条件下 $(\\mu,\\tau^2)$ 的后验分布，然后推导一个新物种的对数效应 $x_{\\mathrm{new}} = \\log(\\mathrm{EC50}_{\\mathrm{new}})$ 的后验预测分布，该分布通过对 $(\\mu,\\tau^2)$ 进行边缘化得到。根据这个对数尺度上的后验预测分布，通过应用适当的单调变换，推导出原始浓度尺度上 $\\mathrm{EC50}_{\\mathrm{new}}$ 的后验中位数和水平为 $q$ 的中心可信区间的表达式。\n- 在一个程序中实现这些表达式，对于下面的每个测试用例，计算：\n  1. $\\mathrm{EC50}_{\\mathrm{new}}$ 的后验中位数（单位为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$），以及\n  2. 水平为 $q = 0.90$ 的 $\\mathrm{EC50}_{\\mathrm{new}}$ 中心可信区间的下界和上界（单位为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$），\n  所有三个报告值都必须以 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$ 表示并四舍五入到 $6$ 位小数。可信区间概率水平 $q$ 必须解释为中心区间，即每个尾部的尾部概率为 $(1-q)/2$，因此下分位数和上分位数分别对应于概率 $0.05$ 和 $0.95$。\n\n测试套件（每个测试用例指定了观测浓度 $\\{y_s\\}_{s=1}^S$（单位为 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$），您必须通过 $x_s=\\log(y_s)$ 进行转换，以及对数尺度上的先验超参数 $(m_0,\\kappa_0,a_0,b_0)$）：\n- 测试用例 1:\n  - 数据 (单位 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$): $[\\,1.0,\\,1.5,\\,2.0,\\,0.8,\\,1.2\\,]$.\n  - 先验: $m_0=\\log(1.0)$, $\\kappa_0=1.0$, $a_0=2.0$, $b_0=0.1$.\n- 测试用例 2:\n  - 数据 (单位 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$): $[\\,0.5,\\,0.6\\,]$.\n  - 先验: $m_0=\\log(0.7)$, $\\kappa_0=5.0$, $a_0=3.0$, $b_0=0.05$.\n- 测试用例 3:\n  - 数据 (单位 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$): $[\\,0.05,\\,0.08,\\,0.07,\\,0.06,\\,0.09,\\,0.10\\,]$.\n  - 先验: $m_0=\\log(0.07)$, $\\kappa_0=0.1$, $a_0=1.0$, $b_0=0.01$.\n\n最终输出格式:\n- 对于每个测试用例，您的程序必须计算三元组 $[\\,\\mathrm{median},\\,\\mathrm{lower},\\,\\mathrm{upper}\\,]$，其中 $\\mathrm{median}$ 是 $\\mathrm{EC50}_{\\mathrm{new}}$ 的后验中位数，$(\\mathrm{lower},\\mathrm{upper})$ 是水平为 $q=0.90$ 的中心可信区间的界限，所有值均以 $\\mathrm{mg}\\,\\mathrm{L}^{-1}$ 为单位并四舍五入到 $6$ 位小数。\n- 将三个用例的三元组按测试用例的相同顺序汇总到一个列表中，并精确打印一行，其中包含此汇总结果，格式为用方括号括起来的逗号分隔列表，例如 $[[v_{11},v_{12},v_{13}],[v_{21},v_{22},v_{23}],[v_{31},v_{32},v_{33}]]$, 不带任何额外文本。", "solution": "所提出的问题是分层贝叶斯建模中的一个标准练习，并且完全有效。它具有科学依据，问题设定良好，且解决该问题所需的所有信息均已提供。我们将继续进行推导和后续计算。\n\n该问题要求我们基于来自 $S$ 个其他物种的观测数据，推导一个新物种的半数有效浓度 $\\mathrm{EC50}_{\\mathrm{new}}$ 的后验预测分布。建模是在浓度的自然对数上进行的，这是一种标准且合理的做法，用于适应浓度的正值域并稳定方差。\n\n设 $S$ 个物种的观测浓度为 $\\{y_s\\}_{s=1}^S$。我们将对数浓度定义为 $x_s = \\log(y_s)$。分层模型规定如下：\n- **似然 (Likelihood)**：物种水平的对数效应 $x_s$ 被假定为在给定分层参数 $\\mu$ 和 $\\tau^2$ 的条件下，从一个正态分布中进行的独立同分布抽样：\n$$x_s \\mid \\mu, \\tau^2 \\sim \\mathcal{N}(\\mu, \\tau^2)$$\n- **先验 (Prior)**：在参数 $(\\mu, \\tau^2)$ 上设置一个共轭的正态-逆伽马先验：\n$$\\mu \\mid \\tau^2 \\sim \\mathcal{N}(m_0, \\tau^2/\\kappa_0)$$\n$$\\tau^2 \\sim \\mathrm{Inv\\mbox{-}Gamma}(a_0, b_0)$$\n联合先验密度为 $p(\\mu, \\tau^2) = p(\\mu \\mid \\tau^2)p(\\tau^2)$。\n\n**1. $(\\mu, \\tau^2)$ 后验分布的推导**\n\n后验分布与似然和先验的乘积成正比，即 $p(\\mu, \\tau^2 \\mid \\mathbf{x}) \\propto p(\\mathbf{x} \\mid \\mu, \\tau^2) p(\\mu, \\tau^2)$。\n数据 $\\mathbf{x} = \\{x_s\\}_{s=1}^S$ 的似然函数为：\n$$p(\\mathbf{x} \\mid \\mu, \\tau^2) = \\prod_{s=1}^S \\frac{1}{\\sqrt{2\\pi\\tau^2}} \\exp\\left(-\\frac{(x_s - \\mu)^2}{2\\tau^2}\\right) \\propto (\\tau^2)^{-S/2} \\exp\\left(-\\frac{1}{2\\tau^2} \\sum_{s=1}^S (x_s - \\mu)^2\\right)$$\n平方和可以分解为 $\\sum_{s=1}^S (x_s - \\mu)^2 = \\sum_{s=1}^S (x_s - \\bar{x})^2 + S(\\bar{x} - \\mu)^2$，其中 $\\bar{x} = \\frac{1}{S}\\sum_{s=1}^S x_s$ 是样本均值。\n\n联合先验密度为：\n$$p(\\mu, \\tau^2) \\propto (\\tau^2)^{-1/2} \\exp\\left(-\\frac{\\kappa_0(\\mu-m_0)^2}{2\\tau^2}\\right) \\cdot (\\tau^2)^{-(a_0+1)} \\exp\\left(-\\frac{b_0}{\\tau^2}\\right)$$\n$$p(\\mu, \\tau^2) \\propto (\\tau^2)^{-(a_0 + 3/2)} \\exp\\left(-\\frac{1}{2\\tau^2} [2b_0 + \\kappa_0(\\mu-m_0)^2]\\right)$$\n\n结合似然和先验，后验核为：\n$$p(\\mu, \\tau^2 \\mid \\mathbf{x}) \\propto (\\tau^2)^{-S/2} \\exp\\left(-\\frac{1}{2\\tau^2} \\left[\\sum(x_s-\\bar{x})^2 + S(\\bar{x}-\\mu)^2\\right]\\right) \\cdot (\\tau^2)^{-(a_0+3/2)} \\exp\\left(-\\frac{1}{2\\tau^2} [2b_0 + \\kappa_0(\\mu-m_0)^2]\\right)$$\n$$p(\\mu, \\tau^2 \\mid \\mathbf{x}) \\propto (\\tau^2)^{-(a_0+S/2+3/2)} \\exp\\left(-\\frac{1}{2\\tau^2} \\left[2b_0 + \\sum(x_s-\\bar{x})^2 + S(\\bar{x}-\\mu)^2 + \\kappa_0(\\mu-m_0)^2\\right]\\right)$$\n通过对指数中涉及 $\\mu$ 的项进行配方，我们可以确定后验的形式。$\\mu$ 的二次项为 $\\mu \\mid \\tau^2, \\mathbf{x}$ 形成了一个新的高斯核，而其余项则更新了 $\\tau^2$ 的逆伽马分布的参数。\n由于正态-逆伽马先验对于正态似然是共轭的，后验分布 $p(\\mu, \\tau^2 \\mid \\mathbf{x})$ 也是一个正态-逆伽马分布，即 $\\mathrm{NIG}(m_S, \\kappa_S, a_S, b_S)$，其更新后的超参数为：\n$$ \\kappa_S = \\kappa_0 + S $$\n$$ m_S = \\frac{\\kappa_0 m_0 + S\\bar{x}}{\\kappa_0 + S} $$\n$$ a_S = a_0 + \\frac{S}{2} $$\n$$ b_S = b_0 + \\frac{1}{2}\\sum_{s=1}^S (x_s - \\bar{x})^2 + \\frac{S\\kappa_0}{2(S+\\kappa_0)}(\\bar{x} - m_0)^2 $$\n\n**2. $x_{\\mathrm{new}}$ 后验预测分布的推导**\n\n新物种对数效应 $x_{\\mathrm{new}}$ 的后验预测分布是通过对参数的后验分布进行边缘化得到的：\n$$p(x_{\\mathrm{new}} \\mid \\mathbf{x}) = \\int_0^\\infty \\int_{-\\infty}^\\infty p(x_{\\mathrm{new}} \\mid \\mu, \\tau^2) p(\\mu, \\tau^2 \\mid \\mathbf{x}) \\,d\\mu \\,d\\tau^2$$\n其中 $p(x_{\\mathrm{new}} \\mid \\mu, \\tau^2) = \\mathcal{N}(x_{\\mathrm{new}} \\mid \\mu, \\tau^2)$ 且 $p(\\mu, \\tau^2 \\mid \\mathbf{x})$ 是上面推导出的后验分布。\n\n这是贝叶斯统计中的一个标准积分。我们首先对 $\\mu$ 进行积分：\n$$p(x_{\\mathrm{new}} \\mid \\tau^2, \\mathbf{x}) = \\int_{-\\infty}^\\infty p(x_{\\mathrm{new}} \\mid \\mu, \\tau^2) p(\\mu \\mid \\tau^2, \\mathbf{x}) \\,d\\mu$$\n这是两个正态分布的卷积：$x_{\\mathrm{new}} \\sim \\mathcal{N}(\\mu, \\tau^2)$ 和 $\\mu \\sim \\mathcal{N}(m_S, \\tau^2/\\kappa_S)$。结果是另一个正态分布：\n$$p(x_{\\mathrm{new}} \\mid \\tau^2, \\mathbf{x}) \\sim \\mathcal{N}\\left(m_S, \\tau^2 + \\frac{\\tau^2}{\\kappa_S}\\right) = \\mathcal{N}\\left(m_S, \\tau^2 \\frac{\\kappa_S+1}{\\kappa_S}\\right)$$\n接下来，我们对 $\\tau^2$ 进行积分：\n$$p(x_{\\mathrm{new}} \\mid \\mathbf{x}) = \\int_0^\\infty p(x_{\\mathrm{new}} \\mid \\tau^2, \\mathbf{x}) p(\\tau^2 \\mid \\mathbf{x}) \\,d\\tau^2$$\n其中 $\\tau^2 \\mid \\mathbf{x} \\sim \\mathrm{Inv\\mbox{-}Gamma}(a_S, b_S)$。该积分产生一个非标准化的学生t-分布。$x_{\\mathrm{new}}$ 的结果分布是一个位置-尺度t-分布，即 $t_{\\nu}(\\mu_{\\text{pred}}, \\sigma^2_{\\text{pred}})$，其参数为：\n- 自由度 (Degrees of freedom): $\\nu = 2a_S$\n- 位置（均值）(Location (mean)): $\\mu_{\\text{pred}} = m_S$\n- 尺度平方 (Scale squared): $\\sigma^2_{\\text{pred}} = \\frac{b_S}{a_S} \\left(1 + \\frac{1}{\\kappa_S}\\right) = \\frac{b_S(\\kappa_S+1)}{a_S\\kappa_S}$\n因此，$(x_{\\mathrm{new}} - m_S) / \\sqrt{\\sigma^2_{\\text{pred}}}$ 服从一个自由度为 $2a_S$ 的标准学生t-分布。\n\n**3. $\\mathrm{EC50}_{\\mathrm{new}}$ 估计量的推导**\n\n我们感兴趣的是 $\\mathrm{EC50}_{\\mathrm{new}} = \\exp(x_{\\mathrm{new}})$ 的性质。由于指数函数是严格单调的，我们可以转换 $x_{\\mathrm{new}}$ 的后验预测分布的分位数，以找到 $\\mathrm{EC50}_{\\mathrm{new}}$ 的相应分位数。\n\n- **后验中位数 (Posterior Median)**：学生t-分布对其位置参数是对称的。因此，$x_{\\mathrm{new}}$ 后验预测分布的中位数是其均值 $m_S$。$\\mathrm{EC50}_{\\mathrm{new}}$ 的后验中位数为：\n$$\\mathrm{Median}(\\mathrm{EC50}_{\\mathrm{new}}) = \\exp(\\mathrm{Median}(x_{\\mathrm{new}})) = \\exp(m_S)$$\n\n- **中心可信区间 (Central Credible Interval)**：$x_{\\mathrm{new}}$ 的一个水平为 $q$ 的中心可信区间由 $[L, U]$ 给出，其中 $L$ 和 $U$ 分别是其后验预测分布的 $(1-q)/2$ 和 $(1+q)/2$ 分位数。设 $t^*_{\\nu}(\\alpha)$ 表示自由度为 $\\nu$ 的标准学生t-分布的 $\\alpha$-分位数。$x_{\\mathrm{new}}$ 的分位数为：\n$$L = m_S + \\sqrt{\\sigma^2_{\\text{pred}}} \\cdot t^*_{2a_S}\\left(\\frac{1-q}{2}\\right)$$\n$$U = m_S + \\sqrt{\\sigma^2_{\\text{pred}}} \\cdot t^*_{2a_S}\\left(\\frac{1+q}{2}\\right)$$\n$\\mathrm{EC50}_{\\mathrm{new}}$ 的相应中心 $q$-水平可信区间为 $[\\exp(L), \\exp(U)]$。对于所要求的水平 $q=0.90$，分位数位于概率 $0.05$ 和 $0.95$ 处。区间界的最终表达式为：\n$$\\text{下界} = \\exp\\left(m_S + \\sqrt{\\frac{b_S(\\kappa_S+1)}{a_S\\kappa_S}} \\cdot t^*_{2a_S}(0.05)\\right)$$\n$$\\text{上界} = \\exp\\left(m_S + \\sqrt{\\frac{b_S(\\kappa_S+1)}{a_S\\kappa_S}} \\cdot t^*_{2a_S}(0.95)\\right)$$\n这些公式为问题提供了完整的解析解，我们现在将对其进行实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves the hierarchical Bayesian modeling problem for the given test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1\n        {\n            \"data\": [1.0, 1.5, 2.0, 0.8, 1.2],\n            \"prior\": {\"m0\": np.log(1.0), \"k0\": 1.0, \"a0\": 2.0, \"b0\": 0.1}\n        },\n        # Test case 2\n        {\n            \"data\": [0.5, 0.6],\n            \"prior\": {\"m0\": np.log(0.7), \"k0\": 5.0, \"a0\": 3.0, \"b0\": 0.05}\n        },\n        # Test case 3\n        {\n            \"data\": [0.05, 0.08, 0.07, 0.06, 0.09, 0.10],\n            \"prior\": {\"m0\": np.log(0.07), \"k0\": 0.1, \"a0\": 1.0, \"b0\": 0.01}\n        }\n    ]\n\n    q = 0.90\n    results = []\n\n    for case in test_cases:\n        y_data = np.array(case[\"data\"])\n        prior = case[\"prior\"]\n        m0, k0, a0, b0 = prior[\"m0\"], prior[\"k0\"], prior[\"a0\"], prior[\"b0\"]\n\n        # Step 1: Log-transform the data\n        x_data = np.log(y_data)\n        \n        # Step 2: Calculate summary statistics for the data\n        S = len(x_data)\n        x_bar = np.mean(x_data)\n        # Sum of squared differences from the mean\n        ss = np.sum((x_data - x_bar)**2)\n\n        # Step 3: Calculate the posterior hyperparameters for the Normal-Inverse-Gamma distribution\n        kS = k0 + S\n        mS = (k0 * m0 + S * x_bar) / kS\n        aS = a0 + S / 2.0\n        bS = b0 + 0.5 * ss + (S * k0 / (2.0 * kS)) * (x_bar - m0)**2\n\n        # Step 4: Calculate the parameters for the posterior predictive t-distribution of x_new\n        # Degrees of freedom\n        nu = 2 * aS\n        # Location (mean)\n        mu_pred = mS\n        # Scale\n        sigma_pred_sq = (bS / aS) * (kS + 1.0) / kS\n        sigma_pred = np.sqrt(sigma_pred_sq)\n        \n        # Step 5: Compute the posterior median of EC50_new\n        median_ec50 = np.exp(mu_pred)\n\n        # Step 6: Compute the central credible interval for EC50_new\n        # Get the quantiles from the standard t-distribution\n        alpha = (1.0 - q) / 2.0  # tail probability, e.g., 0.05 for q=0.90\n        t_quantile_lower = t.ppf(alpha, df=nu)\n        t_quantile_upper = t.ppf(1.0 - alpha, df=nu)\n\n        # Calculate interval bounds for x_new\n        x_new_lower = mu_pred + sigma_pred * t_quantile_lower\n        x_new_upper = mu_pred + sigma_pred * t_quantile_upper\n\n        # Transform bounds back to the original concentration scale\n        lower_bound_ec50 = np.exp(x_new_lower)\n        upper_bound_ec50 = np.exp(x_new_upper)\n\n        # Step 7: Format results to 6 decimal places\n        result_triple = [\n            round(median_ec50, 6),\n            round(lower_bound_ec50, 6),\n            round(upper_bound_ec50, 6)\n        ]\n        results.append(result_triple)\n        \n    # Final print statement in the exact required format.\n    # The format requires no spaces after commas.\n    case_results_str = [f\"[{r[0]:.6f},{r[1]:.6f},{r[2]:.6f}]\" for r in results]\n    final_output_str = f\"[{','.join(case_results_str)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "2481192"}]}