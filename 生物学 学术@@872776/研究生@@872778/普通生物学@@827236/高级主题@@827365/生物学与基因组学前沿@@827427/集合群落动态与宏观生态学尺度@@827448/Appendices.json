{"hands_on_practices": [{"introduction": "物种-面积关系（Species-Area Relationship, SAR）是宏观生态学和生物地理学的基石之一。本练习将通过一个实际的数据分析任务，引导您拟合并比较两种经典的SAR模型形式。通过采用基于泊松误差假设的最大似然估计和赤池信息量准则（AIC），您将掌握超越传统对数-对数线性回归的现代统计方法，从而能够更严谨地评估关于生态学模式的竞争性假说 [@problem_id:2816069]。", "problem": "您将获得来自单个集合群落在多个空间粒度（面积）上的嵌套样方观测数据。每次观测都包含一个以公顷为单位的面积和相应的观测物种丰富度（一个非负整数计数）。假设存在一个单一的物种库，并且在每个粒度上，物种的出现是稀有的，且在物种间近似独立。在这些假设下，面积为 $A$ 的样方中出现的物种数量可以建模为一个泊松随机变量，其均值等于由物种-面积关系函数预测的期望物种丰富度。\n\n您的任务是，对于下面的每个数据集，在泊松抽样模型下，通过最大似然法拟合两个竞争的物种-面积关系模型，然后执行模型选择，以推断出最合理的标度形式。\n\n待拟合的模型：\n- 模型 P（幂律；Arrhenius 形式）：$S(A) = c A^{z}$，其中 $c > 0$ 且 $z > 0$。\n- 模型 G（Gleason 半对数形式）：$S(A) = k + b \\ln A$，约束条件为对于所有观测到的 $A$，都有 $S(A) > 0$。\n\n您必须基于以下基本假设：\n- 在面积 $A_i$ 观测到的物种丰富度是均值为 $\\mu_i = S(A_i)$ 的泊松随机变量的一个实现。\n- 对于独立的泊松观测值 $\\{(A_i, s_i)\\}_{i=1}^{n}$，其对数似然函数为：\n$$\n\\ell(\\theta) = \\sum_{i=1}^{n} \\left[ s_i \\ln \\mu_i(\\theta) - \\mu_i(\\theta) - \\ln(s_i!) \\right],\n$$\n其中 $\\theta$ 表示模型参数，$\\mu_i(\\theta)$ 表示模型对 $A_i$ 预测的均值。\n- 赤池信息准则 (AIC) 为：\n$$\n\\mathrm{AIC} = 2p - 2 \\ell(\\hat{\\theta}),\n$$\n其中 $p$ 是自由参数的数量，$\\hat{\\theta}$ 是最大似然估计值。\n\n实现要求：\n- 通过在给定的参数约束下最大化泊松对数似然（等价于最小化负对数似然）来拟合这两个模型。\n- 对于模型 P，强制 $c > 0$ 和 $z > 0$。为了优化过程中的数值稳定性，您可以为一个小的固定值 $\\varepsilon$ 实现下界 $c \\ge \\varepsilon$ 和 $z \\ge \\varepsilon$。\n- 对于模型 G，强制对所有观测到的 $A_i$ 都有 $k + b \\ln A_i > 0$。为了数值稳定性，您可以为同一个小的 $\\varepsilon$ 实现 $k + b \\ln A_i \\ge \\varepsilon$。\n- 对于每个数据集，使用每个模型的最大化对数似然计算 $\\mathrm{AIC}_\\mathrm{P}$ 和 $\\mathrm{AIC}_\\mathrm{G}$。两个模型都使用 $p = 2$。\n- 决策规则：如果 $\\mathrm{AIC}_\\mathrm{P} + \\delta  \\mathrm{AIC}_\\mathrm{G}$，返回 $0$；如果 $\\mathrm{AIC}_\\mathrm{G} + \\delta  \\mathrm{AIC}_\\mathrm{P}$，返回 $1$；如果 $\\lvert \\mathrm{AIC}_\\mathrm{P} - \\mathrm{AIC}_\\mathrm{G} \\rvert \\le \\delta$，返回 $2$。其中 $\\delta = 2$ 是一个固定的容差，表示实际上的等效性。\n\n数据以包含四个嵌套样方数据集的测试套件形式提供。面积单位为公顷，物种计数无量纲：\n\n- 数据集 $1$：\n  - 面积（公顷）：[$1$, $2$, $4$, $8$, $16$, $32$]\n  - 物种计数：[$5$, $6$, $7$, $9$, $10$, $12$]\n\n- 数据集 $2$：\n  - 面积（公顷）：[$1$, $2$, $4$, $8$, $16$, $32$, $64$]\n  - 物种计数：[$8$, $10$, $12$, $15$, $16$, $19$, $21$]\n\n- 数据集 $3$：\n  - 面积（公顷）：[$1$, $4$, $16$]\n  - 物种计数：[$10$, $13$, $17$]\n\n- 数据集 $4$：\n  - 面积（公顷）：[$1$, $2$, $4$, $8$, $16$, $32$, $64$]\n  - 物种计数：[$3$, $4$, $5$, $6$, $7$, $7$, $8$]\n\n最终输出规范：\n- 您的程序应按上述顺序处理所有四个数据集，并输出一行包含四个整数的列表，每个整数根据上述决策规则对应一个数据集。也就是说，对于每个数据集 $i$，如果模型 P 更优，则输出 $0$；如果模型 G 更优，则输出 $1$；如果在容差 $\\delta$ 内它们实际上无法区分，则输出 $2$。\n- 最后一行必须打印为用方括号括起来的逗号分隔列表，例如：[$0$, $1$, $2$, $0$]。\n\n不涉及角度单位。除所述的以公顷为单位的面积外，没有出现其他物理单位。所有数值输出均为所述的整数。不需要用户输入；所有数据均按上述规定在您的程序中硬编码。请确保代码是确定性的、自包含的，并且只使用允许的库。", "solution": "问题陈述已经过严格评估，并被确定为有效。它在生态学理论和统计方法论方面有科学依据，所提供的信息完整，问题适定，并且其表述是客观的。我们将继续推导和实现解决方案。\n\n任务是为四个数据集拟合两个竞争的物种-面积关系 (SAR) 模型，并使用赤池信息准则 (AIC) 为每个数据集选择最合理的模型。\n\n**1. 统计框架与目标函数**\n\n问题陈述指出，在面积为 $A_i$ 的样方中观测到的物种丰富度 $s_i$ 是均值为 $\\mu_i = S(A_i)$ 的泊松随机变量的一个实现，其中 $S(A)$ 是真实的物种-面积关系。对于一组 $n$ 个独立观测值 $\\{(A_i, s_i)\\}_{i=1}^{n}$，其对数似然函数由下式给出：\n$$\n\\ell(\\theta) = \\sum_{i=1}^{n} \\left[ s_i \\ln \\mu_i(\\theta) - \\mu_i(\\theta) - \\ln(s_i!) \\right]\n$$\n其中 $\\theta$ 代表模型参数。\n\n最大似然估计 (MLE) 旨在寻找使 $\\ell(\\theta)$ 最大化的参数值 $\\hat{\\theta}$。这等效于最小化负对数似然 (NLL)。由于 $\\sum_{i=1}^{n} \\ln(s_i!)$ 项相对于 $\\theta$ 是一个常数，因此在优化过程中可以从目标函数中省略。我们定义要最小化的目标函数为：\n$$\nf(\\theta) = -\\sum_{i=1}^{n} \\left[ s_i \\ln \\mu_i(\\theta) - \\mu_i(\\theta) \\right] = \\sum_{i=1}^{n} \\left[ \\mu_i(\\theta) - s_i \\ln \\mu_i(\\theta) \\right]\n$$\n令 $\\hat{\\theta}$ 为最小化 $f(\\theta)$ 的参数，令 $f^* = f(\\hat{\\theta})$ 为该函数的最小值。\n\n**2. 物种-面积关系模型与参数估计**\n\n我们必须为每个数据集拟合两个模型。将使用 `scipy.optimize.minimize` 函数进行数值优化。一个小的常数 $\\varepsilon = 10^{-9}$ 将用于约束中的数值稳定性。\n\n**模型 P（幂律）：**\n期望物种丰富度由 Arrhenius 形式给出：\n$$\nS(A; c, z) = c A^z\n$$\n参数为 $\\theta_P = (c, z)$，约束条件为 $c > 0$ 和 $z > 0$。对于数值优化，这些约束实现为区间约束：$c \\ge \\varepsilon$ 和 $z \\ge \\varepsilon$。\n初始参数估计 $(c_0, z_0)$ 通过将模型线性化得到：$\\ln S = \\ln c + z \\ln A$。我们对 $\\ln s_i$ 与 $\\ln A_i$ 进行线性回归，`numpy.polyfit` 函数适用于此任务。\n\n**模型 G（Gleason 半对数）：**\n期望物种丰富度由 Gleason 形式给出：\n$$\nS(A; k, b) = k + b \\ln A\n$$\n参数为 $\\theta_G = (k, b)$。约束条件是对于所有观测面积，预测的均值必须为正，即 $k + b \\ln A_i > 0$。这通过 `scipy.optimize.LinearConstraint` 实现为一组线性不等式约束，$k + b \\ln A_i \\ge \\varepsilon$。\n初始参数估计 $(k_0, b_0)$ 通过对 $s_i$ 与 $\\ln A_i$ 进行线性回归得到。\n\n**3. 通过赤池信息准则 (AIC) 进行模型选择**\n\nAIC 定义为：\n$$\n\\mathrm{AIC} = 2p - 2\\ell(\\hat{\\theta})\n$$\n其中 $p$ 是自由参数的数量，$\\ell(\\hat{\\theta})$ 是最大化的对数似然。将 $\\ell(\\hat{\\theta})$ 和 $f^*$ 之间的关系代入：\n$$\n\\ell(\\hat{\\theta}) = -f^* - \\sum_{i=1}^{n} \\ln(s_i!)\n$$\nAIC 可以表示为：\n$$\n\\mathrm{AIC} = 2p - 2\\left(-f^* - \\sum_{i=1}^{n} \\ln(s_i!)\\right) = 2p + 2f^* + 2\\sum_{i=1}^{n} \\ln(s_i!)\n$$\n对于一个给定的数据集，$2\\sum \\ln(s_i!)$ 项对两个模型来说都是一个常数。在比较两个模型的 AIC 值时，这个常数会消去。模型 P 和模型 G 都有 $p=2$ 个参数。令 $f_P^*$ 和 $f_G^*$ 分别为幂律模型和 Gleason 模型的最小化 NLL 值。\n\n比较 $\\mathrm{AIC}_P  \\mathrm{AIC}_G$ 等价于 $2p_P + 2f_P^*  2p_G + 2f_G^*$。由于 $p_P = p_G = 2$，这可以简化为 $4 + 2f_P^*  4 + 2f_G^*$，即 $f_P^*  f_G^*$。\n\n问题指定了基于容差 $\\delta = 2$ 的决策规则。\n- **选择模型 P（输出 $0$）**：如果 $\\mathrm{AIC}_P + \\delta  \\mathrm{AIC}_G$。这等价于 $2p_P + 2f_P^* + \\delta  2p_G + 2f_G^*$，简化为 $f_P^* + \\delta/2  f_G^*$。当 $\\delta=2$ 时，条件为 $f_P^* + 1  f_G^*$。\n- **选择模型 G（输出 $1$）**：如果 $\\mathrm{AIC}_G + \\delta  \\mathrm{AIC}_P$。根据对称性，条件为 $f_G^* + 1  f_P^*$。\n- **无法区分（输出 $2$）**：如果 $|\\mathrm{AIC}_P - \\mathrm{AIC}_G| \\le \\delta$。这等价于 $|(2p_P + 2f_P^*) - (2p_G + 2f_G^*)| \\le \\delta$，简化为 $|f_P^* - f_G^*| \\le \\delta/2$。当 $\\delta=2$ 时，条件为 $|f_P^* - f_G^*| \\le 1$。\n\n这个过程将被系统地应用于四个提供的数据集，以确定最终的输出向量。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize, LinearConstraint\n\ndef solve():\n    \"\"\"\n    Fits power-law and semi-log species-area models to ecological data,\n    and performs model selection using AIC.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Dataset 1\n        {\n            \"areas\": np.array([1, 2, 4, 8, 16, 32], dtype=float),\n            \"counts\": np.array([5, 6, 7, 9, 10, 12], dtype=float),\n        },\n        # Dataset 2\n        {\n            \"areas\": np.array([1, 2, 4, 8, 16, 32, 64], dtype=float),\n            \"counts\": np.array([8, 10, 12, 15, 16, 19, 21], dtype=float),\n        },\n        # Dataset 3\n        {\n            \"areas\": np.array([1, 4, 16], dtype=float),\n            \"counts\": np.array([10, 13, 17], dtype=float),\n        },\n        # Dataset 4\n        {\n            \"areas\": np.array([1, 2, 4, 8, 16, 32, 64], dtype=float),\n            \"counts\": np.array([3, 4, 5, 6, 7, 7, 8], dtype=float),\n        },\n    ]\n\n    # Small constant for numerical stability in constraints.\n    EPS = 1e-9\n    \n    # Model P (Power-law): S(A) = c * A^z\n    def model_p(params, A):\n        c, z = params\n        return c * A**z\n\n    # Model G (Gleason/semi-log): S(A) = k + b*ln(A)\n    def model_g(params, A):\n        k, b = params\n        return k + b * np.log(A)\n\n    # Negative log-likelihood for Poisson distributed counts.\n    # The constant term sum(ln(s_i!)) is omitted as it cancels during AIC comparison.\n    def nll_poisson(params, model_func, A, s):\n        mu = model_func(params, A)\n        # Safeguard against non-positive means, though constraints should prevent this.\n        if np.any(mu = 0):\n            return np.inf\n        \n        # log-likelihood = s * log(mu) - mu\n        # negative log-likelihood = mu - s * log(mu)\n        return np.sum(mu - s * np.log(mu))\n\n    results = []\n    \n    for case in test_cases:\n        A = case[\"areas\"]\n        s = case[\"counts\"]\n\n        # --- Fit Model P (Power-law) ---\n        # Initial guess from log-log linear regression: log(s) ~ log(c) + z*log(A)\n        # np.polyfit returns [slope, intercept]\n        try:\n            # Handle cases where counts might be zero, which is not the case here.\n            valid_pts = s > 0\n            if np.sum(valid_pts) > 1:\n                z0, log_c0 = np.polyfit(np.log(A[valid_pts]), np.log(s[valid_pts]), 1)\n                c0 = np.exp(log_c0)\n            else: # Fallback initial guess\n                c0, z0 = np.mean(s), 0.25\n        except (np.linalg.LinAlgError, ValueError):\n            c0, z0 = np.mean(s), 0.25\n        x0_p = [c0, z0]\n        \n        # Parameter bounds: c > 0, z > 0\n        bounds_p = [(EPS, None), (EPS, None)]\n\n        res_p = minimize(\n            fun=nll_poisson,\n            x0=x0_p,\n            args=(model_p, A, s),\n            method='L-BFGS-B',\n            bounds=bounds_p\n        )\n        nll_p_min = res_p.fun\n\n        # --- Fit Model G (Gleason/semi-log) ---\n        # Initial guess from semi-log linear regression: s ~ k + b*log(A)\n        try:\n            b0, k0 = np.polyfit(np.log(A), s, 1)\n        except (np.linalg.LinAlgError, ValueError):\n            k0, b0 = np.mean(s), 1.0\n        x0_g = [k0, b0]\n\n        # Linear constraints: k + b*ln(A_i) >= EPS for all i\n        n = len(A)\n        constraint_matrix_g = np.vstack([np.ones(n), np.log(A)]).T\n        lb_g = np.full(n, EPS)\n        constraints_g = LinearConstraint(constraint_matrix_g, lb_g, np.inf)\n\n        res_g = minimize(\n            fun=nll_poisson,\n            x0=x0_g,\n            args=(model_g, A, s),\n            method='SLSQP',\n            constraints=constraints_g\n        )\n        nll_g_min = res_g.fun\n\n        # --- Model Selection ---\n        # Compare based on AIC difference, which simplifies to NLL difference\n        # Delta_AIC = AIC_P - AIC_G = 2*(NLL_P - NLL_G)\n        # Decision rule tolerance delta = 2, so NLL tolerance is delta/2 = 1.\n        nll_tolerance = 1.0\n        \n        if nll_p_min + nll_tolerance  nll_g_min:\n            results.append(0)  # Model P is preferred\n        elif nll_g_min + nll_tolerance  nll_p_min:\n            results.append(1)  # Model G is preferred\n        else:\n            results.append(2)  # Models are practically indistinguishable\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2816069"}, {"introduction": "在生态学调查中，由于物种探测的不完美性，原始的观测数据往往会低估真实的物种丰富度及群落间的多样性。本练习通过一系列推导和计算，深刻揭示了观测偏差的来源，并演示了如何利用占域模型（occupancy model）的基本原理来校正这些偏差。掌握这些技巧，您将能从不完美的观测数据中获得对物种丰富度和$\\beta$多样性更准确的估计，这是现代定量生态学研究的一项核心技能 [@problem_id:2816065]。", "problem": "一个集合群落 (metacommunity) 由一个大小为 $S$ 的物种库组成，这些物种可能占据两个生境斑块 ($j \\in \\{1,2\\}$)。每个物种在斑块 $j$ 有一个特定于斑块的占据概率 $\\,\\psi_{j}\\,$，该概率在物种间相同且相互独立。在一个短暂的时间窗口（种群封闭）内，每个斑块被调查 $K$ 次，每次访问的探测概率为 $p$，该概率在物种间和重复调查间相同，且没有假阳性（false positives）。由于探测不完美，存在于某个斑块的物种可能会在某些或所有访问中被漏掉。\n\n从占据和探测的基本定义出发，按以下步骤进行：\n\n1) 从 $K$ 次访问中探测的独立性以及至少有一次探测的指示变量出发，推导在斑块 $j$ 至少被探测到一次的物种的期望数量（记为 $X_{j}$），用 $S$、$\\psi_{j}$、$K$ 和 $p$ 表示。并以此解释为什么 $X_{j}$ 是真实斑块丰富度 $R_{j} = S \\psi_{j}$ 的一个向下偏倚的估计量。\n\n2) 使用第（1）部分的结果，推导 $R_{j}$ 和 $\\psi_{j}$ 的一个无偏估计量，用 $X_{j}$、$S$、$K$ 和 $p$ 表示。\n\n3) 假设对于任何给定的物种，在两个斑块的占据事件是独立的，概率分别为 $\\psi_{1}$ 和 $\\psi_{2}$，推导两个斑块之间真实 Jaccard 相异性的表达式，仅用 $\\psi_{1}$ 和 $\\psi_{2}$ 表示。回想一下，Jaccard 相异性是一减去物种集合的交集与并集之比。\n\n4) 在一项研究中，$S = 150$ 个物种，每个斑块进行 $K = 3$ 次重复调查，两个斑块的每次访问探测概率均为 $p = 0.4$。观测到的至少被探测到一次的物种数量分别为 $X_{1} = 68$ 和 $X_{2} = 74$。使用你的推导和上述独立性假设，计算两个斑块之间经过探测校正的 Jaccard 相异性，结果为一个小数。将你的答案四舍五入到四位有效数字。最终答案中不要包含单位。", "solution": "所提出的问题是数量生态学中一个定义明确的练习，具体涉及在探测不完美的情况下，如何从调查数据中估计群落参数。\n\n首先，需要对问题陈述进行验证。\n\n步骤1：提取已知条件。\n- 一个集合群落由一个大小为 $S$ 的物种库组成。\n- 有两个生境斑块，$j \\in \\{1,2\\}$。\n- 斑块 $j$ 的特定于斑块的占据概率为 $\\psi_{j}$，该概率在物种间相同且相互独立。\n- 每个斑块被调查 $K$ 次。\n- 每次访问的探测概率为 $p$，在物种间和重复调查间相同。\n- 没有假阳性。\n- $X_{j}$ 是在斑块 $j$ 至少被探测到一次的物种数量。\n- $R_{j} = S \\psi_{j}$ 是斑块 $j$ 的真实物种丰富度。\n- 对于任何给定的物种，在两个斑块的占据事件是独立的。\n- Jaccard 相异性是一减去物种集合的交集与并集之比。\n- 用于数值计算的数据：$S = 150$，$K = 3$，$p = 0.4$，$X_{1} = 68$，$X_{2} = 74$。\n\n步骤2：验证。\n该问题具有科学依据，采用了占据模型 (occupancy modeling) 的标准概念，这是现代生态学中处理观测误差的一个基本工具。所提出的框架（例如，参数 $\\psi$ 和 $p$，使用重复调查）是该领域的基石。该问题提法得当，逻辑结构清晰，并提供了足够的信息来推导出唯一的解。语言客观、精确，使用了既定的术语。它不包含科学或事实上的不健全之处，是可形式化的，并且与其所述主题相关，是完整和一致的，提出了实际的参数值，并且不是无足轻重的。\n\n步骤3：结论。\n该问题是有效的。将提供解答。\n\n该问题分四部分解答。\n\n1) 推导被探测物种的期望数量 $E[X_{j}]$，并解释其偏倚。\n让我们考虑单个斑块 $j$ 的单个物种 $i$。要使该物种在斑块 $j$ 被探测到，必须发生两个独立的事件：首先，该物种必须存在于斑块 $j$；其次，它必须在 $K$ 次调查中至少被探测到一次。\n\n存在的概率为 $P(\\text{present}) = \\psi_{j}$。\n给定物种存在，单次调查中探测到它的概率是 $p$。因此，单次调查中*未*探测到它的概率是 $1-p$。\n由于 $K$ 次调查是独立的，在*任何*一次调查中都未探测到一个存在物种的概率是 $(1-p)^{K}$。\n因此，至少探测到一个存在物种一次的概率是其补集，$P(\\text{detected }|\\text{ present}) = 1 - (1-p)^{K}$。\n\n在斑块 $j$ 探测到物种 $i$ 的无条件概率是这两个独立事件概率的乘积：\n$$P(\\text{species } i \\text{ detected at site } j) = P(\\text{detected }|\\text{ present}) \\times P(\\text{present}) = \\psi_{j} \\left( 1 - (1-p)^{K} \\right)$$\n在斑块 $j$ 探测到的物种总数（记为 $X_{j}$）是 $S$ 个物种中每个物种被探测到的指示变量之和。根据期望的线性性质以及所有物种的参数都假定相同的性质，被探测物种的期望数量是：\n$$E[X_{j}] = \\sum_{i=1}^{S} P(\\text{species } i \\text{ detected at site } j) = S \\psi_{j} \\left( 1 - (1-p)^{K} \\right)$$\n斑块 $j$ 的真实物种丰富度定义为 $R_{j} = S \\psi_{j}$。将此代入 $E[X_{j}]$ 的表达式中，得到：\n$$E[X_{j}] = R_{j} \\left( 1 - (1-p)^{K} \\right)$$\n为了证明 $X_{j}$ 是 $R_{j}$ 的一个向下偏倚的估计量，我们考察其乘法因子。鉴于要有探测可能性则 $0  p \\le 1$ 且 $K \\ge 1$，项 $1-p$ 的范围是 $0 \\le 1-p  1$。因此，$(1-p)^{K}$ 的范围是 $0 \\le (1-p)^{K}  1$。这意味着因子 $\\left( 1 - (1-p)^{K} \\right)$ 严格小于 1（除非 $p=1$，此时探测是完美的，没有偏倚）。\n因此，对于任何不完美探测的情况（$p1$），都有 $E[X_{j}]  R_{j}$。根据定义，一个期望值不等于其旨在估计的参数的估计量是有偏倚的。由于期望值系统地低于真实值，所以 $X_{j}$ 是 $R_{j}$ 的一个向下偏倚的估计量。\n\n2) 推导 $R_{j}$ 和 $\\psi_{j}$ 的无偏估计量。\n为了构建 $R_{j}$ 的一个无偏估计量，我们使用上面推导出的关系式 $E[X_{j}] = R_{j} \\left( 1 - (1-p)^{K} \\right)$。我们可以重新排列这个式子来解出 $R_{j}$。使用矩估计法，我们通过用观测值 $X_{j}$ 替换其期望值来提出一个估计量 $\\hat{R}_{j}$：\n$$\\hat{R}_{j} = \\frac{X_{j}}{1 - (1-p)^{K}}$$\n为确认该估计量是无偏的，我们取其期望：\n$$E[\\hat{R}_{j}] = E\\left[\\frac{X_{j}}{1 - (1-p)^{K}}\\right] = \\frac{1}{1 - (1-p)^{K}} E[X_{j}]$$\n代入 $E[X_{j}]$ 的表达式：\n$$E[\\hat{R}_{j}] = \\frac{1}{1 - (1-p)^{K}} \\left( R_{j} \\left( 1 - (1-p)^{K} \\right) \\right) = R_{j}$$\n因为 $E[\\hat{R}_{j}] = R_{j}$，所以该估计量是无偏的。\n\n接下来，我们推导 $\\psi_{j}$ 的一个无偏估计量。我们从定义 $R_{j} = S \\psi_{j}$ 开始，这意味着 $\\psi_{j} = R_{j} / S$。通过用无偏估计量 $\\hat{R}_{j}$ 替换 $R_{j}$，可以得到一个直观的估计量 $\\hat{\\psi}_{j}$：\n$$\\hat{\\psi}_{j} = \\frac{\\hat{R}_{j}}{S} = \\frac{1}{S} \\left( \\frac{X_{j}}{1 - (1-p)^{K}} \\right) = \\frac{X_{j}}{S \\left( 1 - (1-p)^{K} \\right)}$$\n该估计量的期望是：\n$$E[\\hat{\\psi}_{j}] = E\\left[\\frac{\\hat{R}_{j}}{S}\\right] = \\frac{1}{S} E[\\hat{R}_{j}] = \\frac{R_{j}}{S} = \\frac{S \\psi_{j}}{S} = \\psi_{j}$$\n这证实了 $\\hat{\\psi}_{j}$ 是 $\\psi_{j}$ 的一个无偏估计量。\n\n3) 推导真实的 Jaccard 相异性。\nJaccard 相异性 $J_{d}$ 定义为 $1 - J_{s}$，其中 $J_{s}$ 是 Jaccard 相似性。对于两个物种集合 $A_{1}$（斑块1的物种）和 $A_{2}$（斑块2的物种），相似性为 $J_{s} = \\frac{|A_{1} \\cap A_{2}|}{|A_{1} \\cup A_{2}|}$。我们关心的是真实的群落组成，因此我们使用从真实占据概率 $\\psi_{1}$ 和 $\\psi_{2}$ 推导出的期望集合大小。\n\n交集中的期望物种数 $E[|A_{1} \\cap A_{2}|]$ 是同时存在于两个斑块的物种的期望数量。鉴于对于任何给定物种，两个斑块的占据事件是独立的，一个物种同时存在于斑块1和斑块2的概率是 $\\psi_{1} \\psi_{2}$。因此，对于一个包含 $S$ 个物种的物种库：\n$$E[|A_{1} \\cap A_{2}|] = S \\psi_{1} \\psi_{2}$$\n并集的期望大小使用容斥原理求得：$E[|A_{1} \\cup A_{2}|] = E[|A_{1}|] + E[|A_{2}|] - E[|A_{1} \\cap A_{2}|]$。\n我们有 $E[|A_{1}|] = E[R_{1}] = S\\psi_{1}$ 和 $E[|A_{2}|] = E[R_{2}] = S\\psi_{2}$。\n$$E[|A_{1} \\cup A_{2}|] = S\\psi_{1} + S\\psi_{2} - S\\psi_{1}\\psi_{2} = S(\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2})$$\n真实的 Jaccard 相似性是这些期望值的比率：\n$$J_{s} = \\frac{E[|A_{1} \\cap A_{2}|]}{E[|A_{1} \\cup A_{2}|]} = \\frac{S \\psi_{1} \\psi_{2}}{S(\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2})} = \\frac{\\psi_{1} \\psi_{2}}{\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2}}$$\n因此，真实的 Jaccard 相异性是：\n$$J_{d} = 1 - J_{s} = 1 - \\frac{\\psi_{1} \\psi_{2}}{\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2}} = \\frac{(\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2}) - \\psi_{1}\\psi_{2}}{\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2}} = \\frac{\\psi_{1} + \\psi_{2} - 2\\psi_{1}\\psi_{2}}{\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2}}$$\n这就是所求的表达式。\n\n4) 计算经探测校正的 Jaccard 相异性。\n给定数据为 $S = 150$，$K = 3$，$p = 0.4$，$X_{1} = 68$ 和 $X_{2} = 74$。\n首先，我们计算占据概率的无偏估计值 $\\hat{\\psi}_{1}$ 和 $\\hat{\\psi}_{2}$。\n至少探测到一个存在物种一次的概率是：\n$$p' = 1 - (1-p)^{K} = 1 - (1-0.4)^{3} = 1 - (0.6)^{3} = 1 - 0.216 = 0.784$$\n使用第（2）部分的估计量：\n$$\\hat{\\psi}_{j} = \\frac{X_{j}}{S \\cdot p'}$$\n对于斑块1：\n$$\\hat{\\psi}_{1} = \\frac{68}{150 \\times 0.784} = \\frac{68}{117.6} \\approx 0.5782176...$$\n对于斑块2：\n$$\\hat{\\psi}_{2} = \\frac{74}{150 \\times 0.784} = \\frac{74}{117.6} \\approx 0.6292516...$$\n现在，我们将这些估计的概率代入第（3）部分的 Jaccard 相异性公式中。令 $\\psi_1 = \\hat{\\psi}_1$ 和 $\\psi_2 = \\hat{\\psi}_2$。\n和：$\\psi_{1} + \\psi_{2} \\approx 0.5782176 + 0.6292516 = 1.2074692$。\n积：$\\psi_{1} \\psi_{2} \\approx 0.5782176 \\times 0.6292516 = 0.3638367$。\nJaccard 相异性公式的分子是：\n$$\\psi_{1} + \\psi_{2} - 2\\psi_{1}\\psi_{2} \\approx 1.2074692 - 2 \\times 0.3638367 = 1.2074692 - 0.7276734 = 0.4797958$$\n该公式的分母是：\n$$\\psi_{1} + \\psi_{2} - \\psi_{1}\\psi_{2} \\approx 1.2074692 - 0.3638367 = 0.8436325$$\n经探测校正的 Jaccard 相异性是这两个量的比值：\n$$J_{d} = \\frac{0.4797958}{0.8436325} \\approx 0.5687054...$$\n四舍五入到四位有效数字，结果是 $0.5687$。", "answer": "$$\\boxed{0.5687}$$", "id": "2816065"}, {"introduction": "物种个体在空间中的分布格局蕴含着关于扩散、环境筛选和生物相互作用等生态过程的关键信息。本练习将指导您实现一种重要的空间统计工具——配对相关函数（Pair Correlation Function, PCF），用以分析和解释空间点格局。通过从第一性原理出发编写代码，您将学会如何量化在不同空间尺度下的聚集、抑制或随机分布模式，这是将观测格局与集合群落动态理论联系起来的基础 [@problem_id:2816062]。", "problem": "给定一组有限空间点格局，代表矩形生境窗口中的物种出现。您必须计算多个半径下的对相关函数 (PCF)，并将尺度依赖的空间结构划分为聚集、中性或抑制。生态学解释应基于集合群落动态，其中扩散限制和生物相互作用在空间点格局上留下印记，这些印记通过二阶统计量揭示。您的程序必须从第一性原理出发，实现一个符合数学原理的估计量，并为每个测试格局和空间尺度生成一个完全指定的分类结果。\n\n基本原理和定义：\n- 考虑在一个面积为 $A$（单位：平方米）、边长为 $L_x$ 和 $L_y$（单位：米）的矩形窗口中观测到的一个平稳且各向同性的空间点过程。\n- 设观测到的点数为 $n$，强度为 $\\lambda = n / A$（单位：点/平方米）。\n- 对相关函数 (PCF) $g(r)$ 对距离 $r$（单位：米）的定义为：在距离 $r$ 处邻近点的观测密度与完全空间随机性 (CSR) 下的期望密度之比。在 CSR 条件下，围绕一个焦点的半径为 $r$、厚度为 $\\Delta r$ 的圆环内，邻近点的期望数量为 $\\lambda \\cdot 2\\pi r \\Delta r$。对所有 $n$ 个焦点求和，同一圆环内的期望有序点对计数为 $n \\lambda 2\\pi r \\Delta r$。\n- 为避免边缘效应且无需进行复杂的校正，请在边长为 $L_x$ 和 $L_y$ 的矩形上使用环形（缠绕）度量。对于两个点 $(x_i,y_i)$ 和 $(x_j,y_j)$，计算 $\\Delta x = \\min(|x_i - x_j|, L_x - |x_i - x_j|)$ 和 $\\Delta y = \\min(|y_i - y_j|, L_y - |y_i - y_j|)$，然后计算 $d_{ij} = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2}$。\n- 对于一个以 $r$ 为中心、宽度为 $\\Delta r$ 的给定圆环，计算有序点对 $(i,j)$（其中 $i \\neq j$）的数量，这些点对的环形距离 $d_{ij}$ 落在半开区间 $[r - \\Delta r/2, r + \\Delta r/2)$ 内（若 $r - \\Delta r/2  0$，则下限截断为 $0$）。将观测到的有序点对计数除以 CSR 期望值 $n \\lambda 2\\pi r \\Delta r$ 进行归一化，以获得一个估计量 $\\widehat{g}(r)$，在窗口较大且满足同质性的 CSR 条件下，该估计量等于 $1$。\n\n分类规则：\n- 给定一个容差 $\\epsilon$（无量纲），按如下方式解释每个半径 $r$ 处的 $\\widehat{g}(r)$：\n  - 若 $\\widehat{g}(r) \\ge 1 + \\epsilon$，则为聚集；输出整数 $1$。\n  - 若 $\\widehat{g}(r) \\le 1 - \\epsilon$，则为抑制；输出整数 $-1$。\n  - 若 $1 - \\epsilon  \\widehat{g}(r)  1 + \\epsilon$，则为中性；输出整数 $0$。\n\n单位与数值约定：\n- 所有坐标 $(x,y)$ 单位为米。\n- 窗口边长 $L_x$ 和 $L_y$ 单位为米。\n- 半径 $r$ 和区间宽度 $\\Delta r$ 单位为米。\n- PCF $\\widehat{g}(r)$ 是无量纲的。\n- 角度，当通过 $2\\pi$ 隐式使用时，单位为弧度。\n- 容差 $\\epsilon$ 以十进制数（而非百分比）指定。\n\n实现要求：\n- 使用如上定义的环形距离。\n- 对每个测试用例，为每个指定的半径 $r$ 计算 $\\widehat{g}(r)$，使用给定的 $\\epsilon$ 和上述规则进行分类，并返回该测试用例的整数分类列表。\n- 使用区间 $[r - \\Delta r/2, r + \\Delta r/2)$，当下限为负时截断为 $0$。\n- 使用 $i \\neq j$ 的有序点对 $(i,j)$。\n\n测试套件：\n- 所有测试用例的矩形窗口均为 $L_x = 1.0$ 米和 $L_y = 1.0$ 米，因此 $A = 1.0$ 平方米。\n- 所有测试用例均使用共同的区间宽度 $\\Delta r = 0.05$ 米和容差 $\\epsilon = 0.5$。\n\n提供以下具有明确坐标的测试用例：\n\n测试用例 1 (聚集格局)：\n- 点（米）：$(0.240,0.250)$, $(0.245,0.255)$, $(0.250,0.245)$, $(0.255,0.250)$, $(0.245,0.245)$, $(0.255,0.255)$, $(0.740,0.750)$, $(0.745,0.755)$, $(0.750,0.745)$, $(0.755,0.750)$, $(0.745,0.745)$, $(0.755,0.755)$。\n- 半径（米）：$[0.015, 0.050, 0.100]$。\n\n测试用例 2 (抑制性格点状格局)：\n- 点（米）：所有 $(x,y)$ 的组合，其中 $x \\in \\{0.1, 0.3, 0.5, 0.7, 0.9\\}$ 且 $y \\in \\{0.1, 0.3, 0.5, 0.7, 0.9\\}$。\n- 半径（米）：$[0.050, 0.100, 0.200]$。\n\n测试用例 3 (近似均匀格局)：\n- 点（米）：$(0.014,0.729)$, $(0.085,0.337)$, $(0.112,0.912)$, $(0.143,0.521)$, $(0.175,0.118)$, $(0.206,0.803)$, $(0.237,0.441)$, $(0.268,0.965)$, $(0.299,0.059)$, $(0.330,0.633)$, $(0.361,0.286)$, $(0.392,0.847)$, $(0.423,0.473)$, $(0.454,0.995)$, $(0.485,0.154)$, $(0.516,0.702)$, $(0.547,0.327)$, $(0.578,0.921)$, $(0.609,0.516)$, $(0.640,0.089)$, $(0.671,0.754)$, $(0.702,0.365)$, $(0.733,0.978)$, $(0.764,0.428)$, $(0.795,0.011)$, $(0.826,0.682)$, $(0.857,0.297)$, $(0.888,0.934)$, $(0.919,0.508)$, $(0.950,0.145)$, $(0.041,0.659)$, $(0.072,0.278)$, $(0.103,0.886)$, $(0.134,0.463)$, $(0.165,0.037)$, $(0.196,0.710)$, $(0.227,0.352)$, $(0.258,0.952)$, $(0.289,0.401)$, $(0.320,0.020)$, $(0.351,0.777)$, $(0.382,0.388)$, $(0.413,0.984)$, $(0.444,0.451)$, $(0.475,0.070)$, $(0.506,0.629)$, $(0.537,0.240)$, $(0.568,0.895)$, $(0.599,0.553)$, $(0.630,0.132)$, $(0.661,0.820)$, $(0.692,0.309)$, $(0.723,0.907)$, $(0.754,0.479)$, $(0.785,0.068)$, $(0.816,0.744)$, $(0.847,0.335)$, $(0.878,0.999)$, $(0.909,0.569)$, $(0.940,0.210)$。\n- 半径（米）：$[0.050, 0.100, 0.200]$。\n\n测试用例 4 (稀疏格局，边界行为)：\n- 点（米）：$(0.100,0.100)$, $(0.900,0.100)$, $(0.500,0.900)$。\n- 半径（米）：$[0.050, 0.400, 0.500]$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素是对应一个测试用例的分类列表，该列表本身也用方括号括起来。例如，一个包含四个测试用例的输出可能看起来像 $[[1,-1,0],[-1,-1,1],[0,0,0],[-1,-1,-1]]$。", "solution": "问题陈述已经过严格评估，被认为是有效的。它具有科学依据、问题适定、客观且内部一致。它提出了空间点过程分析中的一个标准问题，特别是带有环形边缘校正的对相关函数 (PCF) 的计算。所有必要的定义、参数和数据均已提供，以推导出一个唯一的、可验证的解。我们现在将进行有原则的推导和实现。\n\n目标是为几种空间点格局计算对相关函数 $\\widehat{g}(r)$ 的估计量，并在指定的半径 $r$ 上对空间结构进行分类。\n\n**1. 基本定义**\n\n给定在面积为 $A = L_x \\times L_y$ 的矩形窗口内观测到的一组 $n$ 个点 $\\{P_k = (x_k, y_k)\\}_{k=1}^n$。强度，即单位面积的平均点数，由 $\\lambda = n/A$ 给出。\n\n对相关函数 $g(r)$ 量化了距离任意一点 $r$ 处的点的密度，该密度是相对于完全空间随机性 (CSR) 下的期望密度而言的。对于一个平稳且各向同性的过程，$g(r) > 1$ 表示在尺度 $r$ 上存在聚集，$g(r)  1$ 表示存在抑制或规则性，而 $g(r) = 1$ 与随机（泊松）过程一致。\n\n**2. PCF 估计量**\n\n我们使用以下公式估计 $g(r)$：\n$$\n\\widehat{g}(r) = \\frac{N_{obs}(r)}{N_{exp}(r)}\n$$\n其中 $N_{obs}(r)$ 是观测到的有序点对计数，$N_{exp}(r)$ 是在特定距离范围内基于 CSR 的期望计数。\n\n- **分箱与观测计数 $N_{obs}(r)$**：对于给定的半径 $r$ 和区间宽度 $\\Delta r$，我们考虑一个以 $r$ 为中心的圆环。距离集合由半开区间 $I_r = [r - \\Delta r/2, r + \\Delta r/2)$ 定义。问题指定下界必须为非负，因此我们使用区间 $[\\max(0, r - \\Delta r/2), r + \\Delta r/2)$。$N_{obs}(r)$ 是距离 $d_{ij}$ 落入此区间的有序点对 $(i, j)$（其中 $i \\neq j$）的总计数：\n$$\nN_{obs}(r) = \\sum_{i=1}^{n} \\sum_{j=1, j \\neq i}^{n} \\mathbf{1}(d_{ij} \\in I_r)\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。\n\n- **环形距离 $d_{ij}$**：为减轻边缘效应，距离在环面上计算。对于窗口 $[0, L_x] \\times [0, L_y]$ 中的两个点 $P_i=(x_i, y_i)$ 和 $P_j=(x_j, y_j)$，分量方向上的距离为 $\\Delta x = \\min(|x_i - x_j|, L_x - |x_i - x_j|)$ 和 $\\Delta y = \\min(|y_i - y_j|, L_y - |y_i - y_j|)$。环形距离则为：\n$$\nd_{ij} = \\sqrt{(\\Delta x)^2 + (\\Delta y)^2}\n$$\n\n- **期望计数 $N_{exp}(r)$**：在 CSR 条件下，点是均匀且独立分布的。任何面积为 $a$ 的区域内的期望点数为 $\\lambda a$。对于半径为 $r$、小宽度为 $\\Delta r$ 的圆环，其面积约为 $2\\pi r \\Delta r$。对于 $n$ 个焦点，它们组合圆环中其他点（来自 $\\lambda$ 背景）的总期望数给出了期望的有序点对数量：\n$$\nN_{exp}(r) = n \\cdot (\\lambda \\cdot 2\\pi r \\Delta r) = n \\lambda 2\\pi r \\Delta r\n$$\n\n**3. 空间结构的分类**\n\n对于指定的无量纲容差 $\\epsilon$，计算出的 $\\widehat{g}(r)$ 在每个半径 $r$ 处根据以下规则进行分类：\n- **聚集 (1)**：如果 $\\widehat{g}(r) \\ge 1 + \\epsilon$\n- **抑制 (-1)**：如果 $\\widehat{g}(r) \\le 1 - \\epsilon$\n- **中性 (0)**：如果 $1 - \\epsilon  \\widehat{g}(r)  1 + \\epsilon$\n\n**4. 算法实现**\n\n该解法作为一个遵循这些原则的 Python 程序实现。对每个测试用例：\n1. 确定点数 $n$ 和强度 $\\lambda$。\n2. 为所有 $n^2$ 个有序点对计算成对环形距离矩阵。\n3. 对测试集中的每个半径 $r$，执行以下步骤：\n    a. 建立分箱区间 $[r_{min}, r_{max})$。\n    b. 统计距离落入该区间的点对 $(i, j)$（其中 $i \\neq j$）的数量。在基于矩阵的实现中，这涉及对布尔矩阵 `(dist_matrix >= r_min)  (dist_matrix  r_max)`求和，并且如果该区间包含距离 $0$，则减去对角线上的 $n$ 个自身点对。\n    c. 计算期望点对数 $N_{exp}(r)$。\n    d. 计算 $\\widehat{g}(r)$，即观测计数与期望计数的比值。\n    e. 根据容差 $\\epsilon$ 将该值分类为 $1$、$0$ 或 $-1$。\n4. 存储一个测试用例中所有半径的分类列表。\n5. 将所有测试用例的结果汇总成所需的格式作为最终输出。\n\n该方法被系统地应用于所有提供的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_pcf_classification(points, Lx, Ly, radii, dr, epsilon):\n    \"\"\"\n    Computes the Pair Correlation Function (PCF) and classifies spatial structure.\n\n    Args:\n        points (np.ndarray): An (n, 2) array of point coordinates.\n        Lx (float): The width of the rectangular window.\n        Ly (float): The height of the rectangular window.\n        radii (list[float]): A list of radii at which to compute the PCF.\n        dr (float): The bin width for the PCF estimator.\n        epsilon (float): The tolerance for classification.\n\n    Returns:\n        list[int]: A list of classifications (1, 0, or -1) for each radius.\n    \"\"\"\n    n = points.shape[0]\n    if n  2:\n        return [0] * len(radii)\n\n    A = Lx * Ly\n    lambda_ = n / A\n\n    # Compute pairwise toroidal distances using numpy broadcasting\n    # points[:, np.newaxis, :] -> shape (n, 1, 2)\n    # points[np.newaxis, :, :] -> shape (1, n, 2)\n    # diff -> shape (n, n, 2), element [i, j] is (xi-xj, yi-yj)\n    diff = points[:, np.newaxis, :] - points[np.newaxis, :, :]\n    \n    # Absolute difference\n    abs_diff = np.abs(diff)\n    \n    # Toroidal correction\n    L_dims = np.array([Lx, Ly])\n    toroidal_diff = np.minimum(abs_diff, L_dims - abs_diff)\n    \n    # Squared distances\n    dist_sq = np.sum(toroidal_diff**2, axis=2)\n    \n    # Final distance matrix\n    dists = np.sqrt(dist_sq)\n\n    classifications = []\n    for r in radii:\n        # Define the bin\n        lower_bound = r - dr / 2.0\n        upper_bound = r + dr / 2.0\n        r_min_bin = max(0.0, lower_bound)\n\n        # Count observed ordered pairs in the bin\n        # The condition (dists >= r_min_bin)  (dists  upper_bound) creates a boolean matrix.\n        # np.sum() counts the True values.\n        observed_pair_count = np.sum((dists >= r_min_bin)  (dists  upper_bound))\n\n        # We must exclude self-pairs (i=j), which have distance 0.\n        # These are included in the count only if the bin includes 0.\n        if lower_bound = 0:\n            observed_pair_count -= n  # Subtract the n diagonal elements\n\n        # Calculate expected pair count under CSR\n        # Avoid division by zero if r or lambda is zero (though not expected in this problem)\n        if r > 0 and lambda_ > 0:\n            expected_pair_count = n * lambda_ * 2.0 * np.pi * r * dr\n            if expected_pair_count > 0:\n                g_hat = observed_pair_count / expected_pair_count\n            else:\n                # If expected is 0, but observed > 0, g_hat is infinite (clustering)\n                # If both are 0, g_hat is ambiguous, we can treat as neutral.\n                g_hat = 1.0 if observed_pair_count == 0 else np.inf\n        else:\n            g_hat = 1.0 if observed_pair_count == 0 else np.inf\n\n        # Classify the spatial structure\n        if g_hat >= 1 + epsilon:\n            classifications.append(1)\n        elif g_hat = 1 - epsilon:\n            classifications.append(-1)\n        else:\n            classifications.append(0)\n            \n    return classifications\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Common parameters for all test cases\n    Lx = 1.0\n    Ly = 1.0\n    dr = 0.05\n    epsilon = 0.5\n\n    # Test case 1 (clustered pattern)\n    points1 = np.array([\n        (0.240, 0.250), (0.245, 0.255), (0.250, 0.245), (0.255, 0.250),\n        (0.245, 0.245), (0.255, 0.255), (0.740, 0.750), (0.745, 0.755),\n        (0.750, 0.745), (0.755, 0.750), (0.745, 0.745), (0.755, 0.755)\n    ])\n    radii1 = [0.015, 0.050, 0.100]\n\n    # Test case 2 (inhibited lattice-like pattern)\n    x_coords = [0.1, 0.3, 0.5, 0.7, 0.9]\n    y_coords = [0.1, 0.3, 0.5, 0.7, 0.9]\n    points2 = np.array([(x, y) for x in x_coords for y in y_coords])\n    radii2 = [0.050, 0.100, 0.200]\n\n    # Test case 3 (approximately homogeneous pattern)\n    points3 = np.array([\n        (0.014, 0.729), (0.085, 0.337), (0.112, 0.912), (0.143, 0.521),\n        (0.175, 0.118), (0.206, 0.803), (0.237, 0.441), (0.268, 0.965),\n        (0.299, 0.059), (0.330, 0.633), (0.361, 0.286), (0.392, 0.847),\n        (0.423, 0.473), (0.454, 0.995), (0.485, 0.154), (0.516, 0.702),\n        (0.547, 0.327), (0.578, 0.921), (0.609, 0.516), (0.640, 0.089),\n        (0.671, 0.754), (0.702, 0.365), (0.733, 0.978), (0.764, 0.428),\n        (0.795, 0.011), (0.826, 0.682), (0.857, 0.297), (0.888, 0.934),\n        (0.919, 0.508), (0.950, 0.145), (0.041, 0.659), (0.072, 0.278),\n        (0.103, 0.886), (0.134, 0.463), (0.165, 0.037), (0.196, 0.710),\n        (0.227, 0.352), (0.258, 0.952), (0.289, 0.401), (0.320, 0.020),\n        (0.351, 0.777), (0.382, 0.388), (0.413, 0.984), (0.444, 0.451),\n        (0.475, 0.070), (0.506, 0.629), (0.537, 0.240), (0.568, 0.895),\n        (0.599, 0.553), (0.630, 0.132), (0.661, 0.820), (0.692, 0.309),\n        (0.723, 0.907), (0.754, 0.479), (0.785, 0.068), (0.816, 0.744),\n        (0.847, 0.335), (0.878, 0.999), (0.909, 0.569), (0.940, 0.210)\n    ])\n    radii3 = [0.050, 0.100, 0.200]\n\n    # Test case 4 (sparse pattern, boundary behavior)\n    points4 = np.array([\n        (0.100, 0.100), (0.900, 0.100), (0.500, 0.900)\n    ])\n    radii4 = [0.050, 0.400, 0.500]\n\n    test_cases = [\n        (points1, radii1),\n        (points2, radii2),\n        (points3, radii3),\n        (points4, radii4),\n    ]\n\n    all_results = []\n    for points, radii in test_cases:\n        result = calculate_pcf_classification(points, Lx, Ly, radii, dr, epsilon)\n        all_results.append(result)\n\n    # Format output as a string representation of a list of lists.\n    result_str = \",\".join(str(res) for res in all_results).replace(\" \", \"\")\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2816062"}]}