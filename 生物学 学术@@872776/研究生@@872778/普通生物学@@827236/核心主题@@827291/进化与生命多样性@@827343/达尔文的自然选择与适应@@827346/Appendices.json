{"hands_on_practices": [{"introduction": "育种家方程是数量遗传学的基石，为预测进化变化提供了强有力的工具。第一个练习将这一基本原理应用于一个具体场景，要求你计算一个数量性状对选择的预期响应。通过解决这个问题 ([@problem_id:2791233])，你将巩固对遗传力（$h^2$）和选择微分（$S$）如何共同决定从一代到下一代的适应步伐的理解。", "problem": "一个一年生植物的大型、随机交配、泛交群体表现出一个以毫克（mg）为单位的量化性状 $z$（种子质量）。假设以下生物学条件成立：基因作用为加性，无显性或上位性，无基因型与环境的交互作用，无传递偏差，以及除了基因介导的相似性外，亲子之间没有由环境诱导的相似性。选择作用于繁殖前的成年表型，繁殖成功率与绝对适合度成正比。加性遗传方差为 $V_{A} = 0.5 \\text{ mg}^2$，表型方差为 $V_{P} = 1.0 \\text{ mg}^2$，亲代中的表型选择差为 $S = 1.2$ mg。当前种群的平均种子质量为 $\\bar{z}_{0} = 23.17$ mg。\n\n从数量遗传学和进化论的基本原理出发，包括将狭义遗传力 $h^2$ 定义为加性遗传方差与表型方差之比，以及将表型选择差 $S$ 定义为被选择亲本的平均表型与整个种群平均表型之差，推导在所述假设下，子代平均值对选择的预期响应。然后使用所提供的值计算预测的下一代平均种子质量。\n\n将最终答案表示为一个以毫克为单位的数字。将您的答案四舍五入到四位有效数字。", "solution": "该问题提出了数量遗传学中的一个标准情景，并且是有效的。它内容自洽，科学上基于进化论的原理，并且问题陈述清晰。所有必要的数据和假设都已提供，以推导出唯一且有意义的解。\n\n目标是预测经过一轮选择后下一代的平均种子质量，记为 $\\bar{z}_{1}$。出发点是进化数量遗传学的基本原理。\n\n种群平均表型从一代到下一代的变化被定义为选择响应 $R$。它是子代平均表型 $\\bar{z}_{1}$ 与选择前亲代平均表型 $\\bar{z}_{0}$ 之间的差值。\n$$R = \\bar{z}_{1} - \\bar{z}_{0}$$\n\n育种家方程提供了选择响应 $R$、狭义遗传力 $h^2$ 和选择差 $S$ 之间的预测关系。\n$$R = h^2 S$$\n问题中陈述的假设——加性基因作用、无显性或上位性、无基因型与环境的交互作用——正是预期这种线性关系成立的条件。\n\n该问题要求我们从该方程各组成部分的定义出发。\n狭义遗传力 $h^2$ 被定义为总表型方差 $V_{P}$ 中可归因于基因加性效应的部分，由加性遗传方差 $V_{A}$ 表示。\n$$h^2 = \\frac{V_{A}}{V_{P}}$$\n这个量度量了个体间的表型差异在多大程度上能可靠地传递给它们的后代，并且它是决定一个种群对选择作出响应潜力的关键因素。\n\n选择差 $S$ 被定义为被选作亲本的个体的平均表型 $\\bar{z}_{\\text{sel}}$ 与选择前整个亲代种群的平均表型 $\\bar{z}_{0}$ 之间的差值。\n$$S = \\bar{z}_{\\text{sel}} - \\bar{z}_{0}$$\n它量化了一代内作用于表型的定向选择的强度。\n\n通过将 $R$ 和 $h^2$ 的定义代入育种家方程，我们得到了一个用于计算下一代预期平均值的综合表达式。\n首先，我们用基本方差和选择差来表示选择响应 $R$：\n$$R = \\left(\\frac{V_{A}}{V_{P}}\\right)S$$\n然后，我们使用 $R$ 的定义来求解下一代的平均值 $\\bar{z}_{1}$：\n$$\\bar{z}_{1} - \\bar{z}_{0} = \\left(\\frac{V_{A}}{V_{P}}\\right)S$$\n$$\\bar{z}_{1} = \\bar{z}_{0} + \\left(\\frac{V_{A}}{V_{P}}\\right)S$$\n这是从指定的基本原理推导出的最终解析表达式。\n\n现在，我们将问题陈述中提供的数值代入此方程：\n- 当前种群平均值：$\\bar{z}_{0} = 23.17$ mg\n- 加性遗传方差：$V_{A} = 0.5 \\text{ mg}^2$\n- 表型方差：$V_{P} = 1.0 \\text{ mg}^2$\n- 选择差：$S = 1.2$ mg\n\n首先，我们计算狭义遗传力 $h^2$：\n$$h^2 = \\frac{0.5 \\text{ mg}^2}{1.0 \\text{ mg}^2} = 0.5$$\n遗传力是一个无量纲的量。\n\n接下来，我们计算选择响应 $R$：\n$$R = h^2 S = (0.5) \\times (1.2 \\text{ mg}) = 0.6 \\text{ mg}$$\n\n最后，我们计算下一代预测的平均种子质量 $\\bar{z}_{1}$：\n$$\\bar{z}_{1} = \\bar{z}_{0} + R = 23.17 \\text{ mg} + 0.6 \\text{ mg} = 23.77 \\text{ mg}$$\n\n问题要求最终答案四舍五入到四位有效数字。计算出的值 $23.77$ 已恰好包含四位有效数字。因此，无需进一步四舍五入。", "answer": "$$\\boxed{23.77}$$", "id": "2791233"}, {"introduction": "生物体是相互关联性状的复杂集合，选择很少孤立地作用于单个特征。这个练习 ([@problem_id:2791234]) 超越了单性状的视角，探索了更真实的多元选择情景。你将学会区分作用于一个性状的总选择（选择微分，$s$）和直接作用于其上的选择力量（选择梯度，$\\beta$），当性状在表型上相关时，这是一个至关重要的区分。", "problem": "在一个随机交配种群中，测量了其两个连续表型性状和一代内的相对适合度。设个体的性状向量为 $\\mathbf{z} = (z_{1}, z_{2})^{\\top}$，相对适合度为 $w$。假设相对适合度已被归一化，使其在种群中的均值为 $1$。给定 $n=5$ 个个体的观测数据，这些个体被视为整个种群（因此所有的矩都是以 $n$ 为除数的种群矩）：\n\n- 个体 $1$：$(z_{1}, z_{2}, w) = (0, 0, 0.8)$\n- 个体 $2$：$(z_{1}, z_{2}, w) = (1, 2, 1.0)$\n- 个体 $3$：$(z_{1}, z_{2}, w) = (2, 1, 1.2)$\n- 个体 $4$：$(z_{1}, z_{2}, w) = (3, 3, 1.1)$\n- 个体 $5$：$(z_{1}, z_{2}, w) = (4, 2, 0.9)$\n\n从连接进化变化与表型和相对适合度之间协方差的第一性原理（Price方程）以及表型方差-协方差的定义出发，按以下步骤进行：\n\n1) 使用协方差的种群定义，推导并计算该种群两个性状的选择差异向量。\n\n2) 使用 $(z_{1}, z_{2})$ 的表型方差-协方差矩阵，并将方向性选择梯度解释为在保持其他性状不变的情况下（在多元回归的意义上）每个性状对相对适合度的偏效应，从第一性原理推导获得方向性选择梯度向量所需的关系式，并为该种群计算此向量。\n\n3) 结合你的数值计算结果，简要解释当性状存在表型相关时，为什么 $z_{1}$ 的选择差异与其选择梯度不同。\n\n作为你的最终答案，报告选择梯度的第一个分量（与 $z_{1}$ 相关的分量）的精确值。请以精确分数形式给出你的最终答案。", "solution": "该问题要求计算一个大小为 $n=5$ 的种群的选择差异和选择梯度。问题陈述已经过验证，被认为是科学上合理、提法得当且客观的。我将开始解答。\n\n为 $n=5$ 个个体提供的数据如下：\n个体 $1$：$(z_{1}, z_{2}, w) = (0, 0, 0.8)$\n个体 $2$：$(z_{1}, z_{2}, w) = (1, 2, 1.0)$\n个体 $3$：$(z_{1}, z_{2}, w) = (2, 1, 1.2)$\n个体 $4$：$(z_{1}, z_{2}, w) = (3, 3, 1.1)$\n个体 $5$：$(z_{1}, z_{2}, w) = (4, 2, 0.9)$\n\n首先，我们计算性状和适合度的均值。所有种群矩的除数指定为 $n=5$。\n性状 $z_1$ 的均值为：\n$$ \\bar{z}_1 = \\frac{1}{n} \\sum_{i=1}^{n} z_{1i} = \\frac{0+1+2+3+4}{5} = \\frac{10}{5} = 2 $$\n性状 $z_2$ 的均值为：\n$$ \\bar{z}_2 = \\frac{1}{n} \\sum_{i=1}^{n} z_{2i} = \\frac{0+2+1+3+2}{5} = \\frac{8}{5} = 1.6 $$\n给定平均相对适合度归一化为 $1$，我们可以验证这一点：\n$$ \\bar{w} = \\frac{1}{n} \\sum_{i=1}^{n} w_{i} = \\frac{0.8+1.0+1.2+1.1+0.9}{5} = \\frac{5}{5} = 1 $$\n\n1) 选择差异向量 $\\mathbf{s}$ 衡量了作用于每个性状上的总选择。性状 $z_k$ 的选择差异，记为 $s_k$，是由于选择导致该性状的均值在一代内的变化。它被定义为选择后平均表型（$\\bar{z}_k'$）与选择前平均表型（$\\bar{z}_k$）之间的差值。\n选择前的平均表型是 $\\bar{z}_k$。选择后的平均表型是通过用每个个体的相对适合度对其表型进行加权来计算的：\n$$ \\bar{z}_k' = \\frac{\\sum_{i=1}^{n} w_i z_{ki}}{\\sum_{i=1}^{n} w_i} = \\frac{\\frac{1}{n}\\sum_{i=1}^{n} w_i z_{ki}}{\\frac{1}{n}\\sum_{i=1}^{n} w_i} = \\frac{\\mathbb{E}[w z_k]}{\\bar{w}} $$\n由于平均相对适合度 $\\bar{w}=1$，这可以简化为 $\\bar{z}_k' = \\mathbb{E}[w z_k] = \\frac{1}{n}\\sum w_i z_{ki}$。\n那么选择差异为 $s_k = \\bar{z}_k' - \\bar{z}_k = \\mathbb{E}[w z_k] - \\bar{z}_k$。\n这个表达式等价于性状与相对适合度之间的种群协方差，因为 $\\text{cov}(w, z_k) = \\mathbb{E}[w z_k] - \\bar{w}\\bar{z}_k$，且 $\\bar{w}=1$。\n因此，选择差异由 $s_k = \\text{cov}(w, z_k)$ 给出。\n\n我们现在计算 $\\mathbf{s}$ 的分量：\n对于 $z_1$，选择差异 $s_1$ 是：\n$$ s_1 = \\text{cov}(w, z_1) = \\left(\\frac{1}{5} \\sum_{i=1}^{5} w_i z_{1i}\\right) - \\bar{w}\\bar{z}_1 $$\n$$ \\sum w_i z_{1i} = (0.8)(0) + (1.0)(1) + (1.2)(2) + (1.1)(3) + (0.9)(4) = 0 + 1.0 + 2.4 + 3.3 + 3.6 = 10.3 $$\n$$ s_1 = \\frac{10.3}{5} - (1)(2) = 2.06 - 2 = 0.06 = \\frac{6}{100} = \\frac{3}{50} $$\n对于 $z_2$，选择差异 $s_2$ 是：\n$$ s_2 = \\text{cov}(w, z_2) = \\left(\\frac{1}{5} \\sum_{i=1}^{5} w_i z_{2i}\\right) - \\bar{w}\\bar{z}_2 $$\n$$ \\sum w_i z_{2i} = (0.8)(0) + (1.0)(2) + (1.2)(1) + (1.1)(3) + (0.9)(2) = 0 + 2.0 + 1.2 + 3.3 + 1.8 = 8.3 $$\n$$ s_2 = \\frac{8.3}{5} - (1)(1.6) = 1.66 - 1.6 = 0.06 = \\frac{3}{50} $$\n选择差异向量为 $\\mathbf{s} = \\begin{pmatrix} 3/50 \\\\ 3/50 \\end{pmatrix}$。\n\n2) 方向性选择梯度向量 $\\boldsymbol{\\beta}$ 衡量了作用于每个性状上的直接选择，同时考虑了与其他性状的相关性。它是从相对适合度 $w$ 对性状 $z_1$ 和 $z_2$ 的多元回归中推导出来的：\n$$ w = \\alpha + \\beta_1 z_1 + \\beta_2 z_2 + \\epsilon $$\n其中 $\\beta_1$ 和 $\\beta_2$ 是偏回归系数，$\\epsilon$ 是残差，根据定义，它与预测变量 $z_1$ 和 $z_2$ 不相关。\n为了推导这种关系，我们计算回归方程两边与每个性状 $z_k$ 的协方差：\n$$ \\text{cov}(w, z_k) = \\text{cov}(\\alpha + \\beta_1 z_1 + \\beta_2 z_2 + \\epsilon, z_k) $$\n利用协方差算子的线性性质以及 $\\text{cov}(\\text{constant}, z_k)=0$ 和 $\\text{cov}(\\epsilon, z_k)=0$ 的事实：\n$$ \\text{cov}(w, z_k) = \\beta_1\\text{cov}(z_1, z_k) + \\beta_2\\text{cov}(z_2, z_k) $$\n这给了我们一个由两个线性方程组成的方程组：\n$$ \\text{cov}(w, z_1) = \\beta_1\\text{cov}(z_1, z_1) + \\beta_2\\text{cov}(z_2, z_1) $$\n$$ \\text{cov}(w, z_2) = \\beta_1\\text{cov}(z_1, z_2) + \\beta_2\\text{cov}(z_2, z_2) $$\n设 $s_k = \\text{cov}(w, z_k)$ 为选择差异，$P_{ij} = \\text{cov}(z_i, z_j)$ 为表型方差-协方差矩阵 $\\mathbf{P}$ 的元素。该方程组可以写成矩阵形式：\n$$ \\begin{pmatrix} s_1 \\\\ s_2 \\end{pmatrix} = \\begin{pmatrix} P_{11}  P_{12} \\\\ P_{21}  P_{22} \\end{pmatrix} \\begin{pmatrix} \\beta_1 \\\\ \\beta_2 \\end{pmatrix} \\quad \\text{或} \\quad \\mathbf{s} = \\mathbf{P}\\boldsymbol{\\beta} $$\n为了求得选择梯度向量 $\\boldsymbol{\\beta}$，我们必须计算 $\\mathbf{P}$，然后求解 $\\boldsymbol{\\beta} = \\mathbf{P}^{-1}\\mathbf{s}$。\n\n表型方差-协方差矩阵 $\\mathbf{P}$ 的元素是：\n$$ P_{11} = \\text{var}(z_1) = \\left(\\frac{1}{5} \\sum z_{1i}^2\\right) - \\bar{z}_1^2 = \\frac{0^2+1^2+2^2+3^2+4^2}{5} - 2^2 = \\frac{30}{5} - 4 = 6-4=2 $$\n$$ P_{22} = \\text{var}(z_2) = \\left(\\frac{1}{5} \\sum z_{2i}^2\\right) - \\bar{z}_2^2 = \\frac{0^2+2^2+1^2+3^2+2^2}{5} - (1.6)^2 = \\frac{18}{5} - 2.56 = 3.6 - 2.56 = 1.04 = \\frac{104}{100} = \\frac{26}{25} $$\n$$ P_{12} = \\text{cov}(z_1, z_2) = \\left(\\frac{1}{5} \\sum z_{1i}z_{2i}\\right) - \\bar{z}_1\\bar{z}_2 = \\frac{(0)(0)+(1)(2)+(2)(1)+(3)(3)+(4)(2)}{5} - (2)(1.6) = \\frac{21}{5} - 3.2 = 4.2 - 3.2 = 1 $$\n所以表型方差-协方差矩阵是 $\\mathbf{P} = \\begin{pmatrix} 2  1 \\\\ 1  26/25 \\end{pmatrix}$。\n$\\mathbf{P}$ 的行列式是 $\\det(\\mathbf{P}) = (2)(\\frac{26}{25}) - (1)(1) = \\frac{52}{25} - \\frac{25}{25} = \\frac{27}{25}$。\n其逆矩阵是：\n$$ \\mathbf{P}^{-1} = \\frac{1}{\\det(\\mathbf{P})} \\begin{pmatrix} P_{22}  -P_{12} \\\\ -P_{21}  P_{11} \\end{pmatrix} = \\frac{25}{27} \\begin{pmatrix} 26/25  -1 \\\\ -1  2 \\end{pmatrix} $$\n现在我们计算 $\\boldsymbol{\\beta}$：\n$$ \\boldsymbol{\\beta} = \\mathbf{P}^{-1}\\mathbf{s} = \\frac{25}{27} \\begin{pmatrix} 26/25  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 3/50 \\\\ 3/50 \\end{pmatrix} = \\frac{25}{27} \\frac{3}{50} \\begin{pmatrix} 26/25  -1 \\\\ -1  2 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n$$ \\boldsymbol{\\beta} = \\frac{1}{18} \\begin{pmatrix} \\frac{26}{25} - 1 \\\\ -1 + 2 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 1/25 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1/450 \\\\ 1/18 \\end{pmatrix} $$\n因此，方向性选择梯度向量是 $\\boldsymbol{\\beta} = \\begin{pmatrix} 1/450 \\\\ 1/18 \\end{pmatrix}$。第一个分量是 $\\beta_1 = 1/450$。\n\n3) $z_1$ 的选择差异是 $s_1 = 3/50 = 0.06$，而其选择梯度是 $\\beta_1 = 1/450 \\approx 0.0022$。这两个值不同是因为性状 $z_1$ 和 $z_2$ 是表型相关的。\n关系式 $s_1 = P_{11}\\beta_1 + P_{12}\\beta_2$ 阐明了这一点。选择差异 $s_1$ 代表了性状 $z_1$ 与适合度之间的总关联。这个总关联由两部分组成：\ni) 选择对 $z_1$ 的直接效应，这与选择梯度 $\\beta_1$ 有关。这部分是 $P_{11}\\beta_1$。\nii) 选择对 $z_1$ 的间接效应，这是因为 $z_1$ 与 $z_2$ 相关，而 $z_2$ 也受到选择。这部分是 $P_{12}\\beta_2$。\n根据我们的计算，$P_{12} = \\text{cov}(z_1, z_2) = 1$，这表明两个性状之间存在正相关。我们还发现两个性状都受到直接的正选择（$\\beta_1 > 0$ 和 $\\beta_2 > 0$）。\n让我们代入数值：\n$$ s_1 = (2)\\left(\\frac{1}{450}\\right) + (1)\\left(\\frac{1}{18}\\right) = \\frac{2}{450} + \\frac{25}{450} = \\frac{27}{450} = \\frac{3}{50} $$\n这证实了我们对 $s_1$ 的计算。项 $P_{12}\\beta_2 = 1 \\times (1/18) = 1/18 \\approx 0.0556$ 是由于选择作用于相关性状 $z_2$ 而对 $z_1$ 的选择产生的间接贡献。项 $P_{11}\\beta_1 = 2 \\times (1/450) = 1/225 \\approx 0.0044$ 则源于对 $z_1$ 的直接选择。\n在这个具体案例中，作用于性状 $z_1$ 的总选择（选择差异 $s_1$）的绝大部分实际上是强选择作用于正相关性状 $z_2$ 的间接后果。对 $z_1$ 的直接选择（由梯度 $\\beta_1$ 衡量）非常弱。如果性状不相关（$P_{12}=0$），那么 $s_1$ 将等于 $P_{11}\\beta_1$，选择差异将成为对该性状本身选择强度的直接度量（经其方差缩放）。", "answer": "$$\\boxed{\\frac{1}{450}}$$", "id": "2791234"}, {"introduction": "虽然理论模型使我们能够预测进化轨迹，但进化生物学的一个关键挑战是从经验数据中推断选择的力量。这最后一个练习 ([@problem_id:2791293]) 让你沉浸在这一过程中，指导你从等位基因频率的时间序列数据中估算选择系数。通过应用广义线性模型 (GLM)，你将在确定性群体遗传学理论与现代数据分析的统计现实之间架起一座桥梁。", "problem": "给你一个从单个双等位基因座抽样的独立等位基因计数时间序列，该基因座在具有恒定相对适应度的单倍体育性选择下，以离散不重叠的世代进行演化。假设衍生等位基因的相对适应度为 $1+s$，祖先等位基因的相对适应度为 $1$，其中 $s > -1$。假设没有突变、没有迁移，且环境恒定。在抽样世代 $t_i$，你在一个包含 $n_i$ 条染色体的样本中观察到 $x_i$ 个衍生等位基因。在 Wright-Fisher 框架下，以种群等位基因频率 $p_{t_i}$ 为条件，观测模型为二项分布：$x_i \\sim \\mathrm{Binomial}(n_i, p_{t_i})$。在选择作用下，$p_t$ 的确定性期望可由相对适应度的定义和标准的离散世代频率更新方法推导出。你的任务是：\n\n- 推导出一个由每代恒定相对适应度 $1+s$ 所蕴含的确定性轨迹的可估计、参数线性的表示形式（经过适当变换），并从一个未知的初始条件开始。\n- 将 $\\{p_{t_i}\\}$ 视为你推导的表示形式所规定的均值函数，为观测值 $\\{(t_i, x_i, n_i)\\}_{i=1}^m$ 构建二项对数似然。\n- 关于参数最大化此似然函数，然后将拟合的参数映射回去，以获得选择系数 $s$ 的最大似然估计。\n\n科学真实性约束：你必须通过似然函数（等价地，通过使用标准连接的广义线性模型公式）来考虑每个时间点的二项抽样方差。你必须确保预测的均值对所有 $i$ 都满足 $0  p_{t_i}  1$。\n\n数值约束和输出规范：\n- 实现一个算法，该算法需保证对所提供的数据集能产生有限的估计值（例如，通过对二项似然使用标准 logistic 连接函数，并采用带有保障措施的迭代重加权最小二乘法程序，以确保 $p_{t_i}$ 严格保持在 $(0,1)$ 区间内）。\n- 对于下面的每个数据集，计算最大似然估计值 $\\hat{s}$（作为一个实数）。报告每个 $\\hat{s}$，四舍五入到恰好 $6$ 位小数。\n- 你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[0.123456,-0.000001,0.500000]$。\n\n测试套件（时间单位为世代；无物理单位需要报告）：\n- 案例 1（一般正常路径，多个时间点）：$t = [0,1,2,3]$, $n = [100,110,125,118]$, $x = [20,30,45,54]$。\n- 案例 2（中性选择的边界条件）：$t = [0,1,2,3]$, $n = [70,140,91,77]$, $x = [20,40,26,22]$。\n- 案例 3（负选择）：$t = [0,1,2,3]$, $n = [80,140,190,106]$, $x = [30,40,40,16]$。\n- 案例 4（时间点最少且间距不等的边缘案例）：$t = [0,5]$, $n = [20,371]$, $x = [4,243]$。\n\n最终输出格式要求：\n- 产生单行输出，该行是一个有效的 Python 列表字面量，包含四个浮点数，每个浮点数均四舍五入到恰好 $6$ 位小数，并按案例 1 到案例 4 的顺序排列，例如 $[\\hat{s}_1,\\hat{s}_2,\\hat{s}_3,\\hat{s}_4]$。", "solution": "该问题已经过严格验证，并被认定为有效。这是一个统计群体遗传学中的良态问题，其基础是既定的科学原理。我们可以着手提供一个解决方案。\n\n目标是从等位基因计数的时间序列数据中，推导出选择系数 $s$ 的最大似然估计。这项任务包含三个主要部分：首先，推导等位基因频率变化的确定性方程；其次，将其置于适合计数数据的统计框架内进行表述；第三，实现一个用于参数估计的数值程序。\n\n设 $p_t$ 为第 $t$ 代衍生等位基因的频率，$q_t = 1 - p_t$ 为祖先等位基因的频率。衍生等位基因的相对适应度为 $w_1 = 1+s$，祖先等位基因的相对适应度为 $w_0 = 1$。在一个具有离散世代的单倍体选择模型下，第 $t$ 代种群的平均适应度为 $\\bar{w}_t = p_t w_1 + q_t w_0 = p_t(1+s) + (1-p_t)(1) = 1 + s p_t$。\n\n在下一代中，衍生等位基因的频率 $p_{t+1}$ 由其在选择后对基因库的贡献比例给出：\n$$p_{t+1} = \\frac{p_t w_1}{\\bar{w}_t} = \\frac{p_t(1+s)}{1+sp_t}$$\n祖先等位基因的频率也同样更新：\n$$q_{t+1} = \\frac{q_t w_0}{\\bar{w}_t} = \\frac{q_t}{1+sp_t}$$\n为了找到频率轨迹的一个易于处理且可线性化的表达式，我们考察等位基因频率之比 $R_t = p_t / q_t$。该比率的递推关系是：\n$$\\frac{p_{t+1}}{q_{t+1}} = \\frac{p_t(1+s)}{q_t} = (1+s)\\left(\\frac{p_t}{q_t}\\right)$$\n这揭示了等位基因频率之比每代都以 $1+s$ 的因子呈几何级数增长。从初始世代 $t=0$ 开始迭代这个关系，得到：\n$$R_t = R_0 (1+s)^t$$\n其中 $R_0 = p_0 / (1-p_0)$。为了使这个关系相对于时间 $t$ 线性化，我们取自然对数：\n$$\\ln(R_t) = \\ln(R_0) + t \\ln(1+s)$$\n项 $\\ln(R_t) = \\ln(p_t / (1-p_t))$ 是等位基因频率 $p_t$ 的 logit 变换，记为 $\\text{logit}(p_t)$。因此，我们推导出了变换后等位基因频率的线性模型：\n$$\\text{logit}(p_t) = \\beta_0 + \\beta_1 t$$\n其中待估计的参数是 $\\beta_0 = \\text{logit}(p_0)$ 和 $\\beta_1 = \\ln(1+s)$。这就是所要求的确定性轨迹的参数线性表示形式。\n\n观测数据的统计模型必须考虑抽样过程。在每个时间点 $t_i$，我们在一个包含 $n_i$ 条染色体的样本中观察到 $x_i$ 个衍生等位基因。这个过程由二项分布建模：\n$$x_i \\sim \\mathrm{Binomial}(n_i, p_{t_i})$$\n其中 $p_{t_i}$ 是第 $t_i$ 代真实的种群等位基因频率。完整的数据集是 $\\{(t_i, x_i, n_i)\\}_{i=1}^m$。\n\n这个结构正是广义线性模型（GLM）的结构。其组成部分是：\n1.  **随机部分**：观测值 $x_i$ 服从二项分布。响应变量可以看作是比例 $y_i = x_i/n_i$。\n2.  **系统部分**：线性预测变量 $\\eta_i$ 是协变量的线性函数。在这种情况下，唯一的协变量是时间 $t_i$。线性预测变量是 $\\eta_i = \\beta_0 + \\beta_1 t_i$。\n3.  **连接函数**：一个函数 $g(\\cdot)$ 将响应的期望值 $\\mu_i = \\mathbb{E}[y_i] = p_{t_i}$ 与线性预测变量关联起来：$g(\\mu_i) = \\eta_i$。我们的推导表明这是 logit 函数，$g(p_{t_i}) = \\text{logit}(p_{t_i})$。\n\nlogit 连接是二项分布族的标准连接函数，这提供了理论和计算上的优势。整个数据集的对数似然函数，用参数 $\\beta_0$ 和 $\\beta_1$ 表示为：\n$$L(\\beta_0, \\beta_1) = \\sum_{i=1}^{m} \\left( \\ln\\binom{n_i}{x_i} + x_i \\ln(p_{t_i}) + (n_i - x_i) \\ln(1 - p_{t_i}) \\right)$$\n将 $p_{t_i} = \\text{logit}^{-1}(\\eta_i) = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}}$（其中 $\\eta_i = \\beta_0 + \\beta_1 t_i$）代入，我们得到需要就 $\\beta = (\\beta_0, \\beta_1)^T$ 进行最大化的似然函数。\n\n最大化过程通过数值方法，使用迭代重加权最小二乘（IRLS）算法来执行，该算法对于标准 GLM 而言等价于 Fisher 评分法。该算法如下：\n1.  初始化参数向量 $\\boldsymbol{\\beta}^{(0)}$，例如，设为 $\\boldsymbol{\\beta}^{(0)} = \\mathbf{0}$。\n2.  对于迭代 $k=0, 1, 2, \\dots$，直到收敛：\n    a.  为每个观测值计算线性预测变量：$\\boldsymbol{\\eta}^{(k)} = \\mathbf{X}\\boldsymbol{\\beta}^{(k)}$，其中 $\\mathbf{X}$ 是行向量为 $[1, t_i]$ 的 $m \\times 2$ 设计矩阵。\n    b.  计算当前的拟合概率（均值）：$\\boldsymbol{\\mu}^{(k)} = g^{-1}(\\boldsymbol{\\eta}^{(k)})$，其中 $g^{-1}$ 是 logistic 函数。\n    c.  构建工作响应向量 $\\mathbf{z}^{(k)}$：$z_i^{(k)} = \\eta_i^{(k)} + \\frac{y_i - \\mu_i^{(k)}}{\\mu_i^{(k)}(1-\\mu_i^{(k)})}$，其中 $y_i = x_i/n_i$。\n    d.  构建对角权重矩阵 $\\mathbf{W}^{(k)}$，其元素为 $W_{ii}^{(k)} = n_i \\mu_i^{(k)}(1-\\mu_i^{(k)})$。\n    e.  通过求解加权最小二乘方程来更新参数：$\\boldsymbol{\\beta}^{(k+1)} = (\\mathbf{X}^T \\mathbf{W}^{(k)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(k)} \\mathbf{z}^{(k)}$。\n3.  当两次迭代之间 $\\boldsymbol{\\beta}$ 的变化小于指定的容差时，该过程终止。为确保数值稳定性，拟合概率 $\\mu_i^{(k)}$ 通过将其值从边界截断（例如，对于一个很小的 $\\epsilon>0$，截断到 $[\\epsilon, 1-\\epsilon]$ 范围内）来约束，以使其严格保持在 $(0, 1)$ 区间内。\n\n收敛后，该算法产生最大似然估计 $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0, \\hat{\\beta}_1)^T$。根据我们最初的推导，我们有关系式 $\\hat{\\beta}_1 = \\ln(1+\\hat{s})$。因此，选择系数 $s$ 的最大似然估计是：\n$$\\hat{s} = e^{\\hat{\\beta}_1} - 1$$\n此程序为从给定的时间序列数据中估计选择系数提供了一个完整且稳健的方法。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fit_selection_glm(t, x, n, tol=1e-8, max_iter=25, epsilon=1e-10):\n    \"\"\"\n    Computes the maximum likelihood estimate of the selection coefficient 's'\n    using an Iteratively Reweighted Least Squares (IRLS) algorithm for a\n    Binomial GLM with a logit link.\n\n    Args:\n        t (np.ndarray): Array of time points (generations).\n        x (np.ndarray): Array of derived allele counts.\n        n (np.ndarray): Array of sample sizes.\n        tol (float): Convergence tolerance for the beta parameters.\n        max_iter (int): Maximum number of iterations.\n        epsilon (float): Small value to prevent probabilities of 0 or 1.\n\n    Returns:\n        float: The maximum likelihood estimate of the selection coefficient, s.\n    \"\"\"\n    # Design matrix X, with an intercept column and a time column.\n    X = np.vstack([np.ones(len(t)), t]).T\n    \n    # Observed proportions\n    y = x / n\n    \n    # Initial guess for beta (b0, b1)\n    beta = np.zeros(X.shape[1])\n    \n    for i in range(max_iter):\n        # Linear predictor eta = b0 + b1*t\n        eta = X @ beta\n        \n        # Mean response (probabilities) from the inverse link function (logistic)\n        mu = 1.0 / (1.0 + np.exp(-eta))\n        \n        # Safeguard: clip probabilities to avoid division by zero or log(0)\n        mu = np.clip(mu, epsilon, 1.0 - epsilon)\n        \n        # Derivative of the link function, g'(mu) = 1/(mu*(1-mu))\n        g_prime_mu = 1.0 / (mu * (1.0 - mu))\n        \n        # Working response (adjusted dependent variable) z\n        z = eta + (y - mu) * g_prime_mu\n        \n        # Weights for IRLS\n        # For Binomial GLM, W_ii = n_i * V(mu_i) * (g'(mu_i))^2, where V is variance function\n        # For canonical logit link, g'(mu) = 1/V(mu), so W_ii = n_i * V(mu_i)\n        # V(mu) for Binomial/Bernoulli is mu*(1-mu)\n        w = n * mu * (1.0 - mu)\n        W = np.diag(w)\n        \n        # Update beta by solving the weighted least squares problem:\n        # beta_new = (X^T * W * X)^-1 * X^T * W * z\n        try:\n            # Equivalent to np.linalg.inv(X.T @ W @ X) @ X.T @ W @ z but more stable\n            beta_new = np.linalg.solve(X.T @ W @ X, X.T @ W @ z)\n        except np.linalg.LinAlgError:\n            print(\"Error: Singular matrix encountered in IRLS. The data may be uninformative.\")\n            return np.nan\n\n        # Check for convergence\n        if np.linalg.norm(beta_new - beta)  tol:\n            beta = beta_new\n            break\n            \n        beta = beta_new\n\n    # The estimated coefficient for time is beta[1]\n    # We have beta_1 = log(1+s)\n    beta_1_hat = beta[1]\n    s_hat = np.exp(beta_1_hat) - 1.0\n    \n    return s_hat\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general happy path, multiple time points)\n        {'t': [0, 1, 2, 3], 'n': [100, 110, 125, 118], 'x': [20, 30, 45, 54]},\n        # Case 2 (boundary condition of neutrality)\n        {'t': [0, 1, 2, 3], 'n': [70, 140, 91, 77], 'x': [20, 40, 26, 22]},\n        # Case 3 (negative selection)\n        {'t': [0, 1, 2, 3], 'n': [80, 140, 190, 106], 'x': [30, 40, 40, 16]},\n        # Case 4 (edge case with minimal time points and unequal spacing)\n        {'t': [0, 5], 'n': [20, 371], 'x': [4, 243]}\n    ]\n\n    results = []\n    for case in test_cases:\n        t_arr = np.array(case['t'], dtype=float)\n        x_arr = np.array(case['x'], dtype=float)\n        n_arr = np.array(case['n'], dtype=float)\n        \n        s_hat = fit_selection_glm(t_arr, x_arr, n_arr)\n        results.append(s_hat)\n    \n    # Format the output as a list of floats rounded to 6 decimal places\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "2791293"}]}