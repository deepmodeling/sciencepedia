## 引言
转录组学通过[大规模并行测序](@entry_id:189534)技术，以前所未有的广度和深度揭示了基因表达的动态图景，已成为现代分子与细胞生物学研究的基石。然而，随着技术的飞速发展，从传统的[批量RNA测序](@entry_id:203183)（bulk [RNA-seq](@entry_id:140811)）到高分辨率的单细胞（scRNA-seq）和[空间转录组学](@entry_id:270096)（spatial transcriptomics），研究者面临着日益复杂的技术选择和数据分析挑战。准确理解每种方法的原理、[适用范围](@entry_id:636189)及内在局限性，是确保实验设计合理、数据解读可靠的关键，但这其中存在着显著的知识鸿沟。

本文旨在系统性地梳理转录组学的核心方法与分析策略，为读者构建一个从理论基础到前沿应用的完整知识体系。在“原理与机制”一章中，我们将深入剖析从RNA样本到量化表达值的全过程，涵盖文库制备、测序读数比对、[数据标准化](@entry_id:147200)以及[差异表达分析](@entry_id:266370)背后的[统计模型](@entry_id:165873)。接着，在“应用与跨学科[交叉](@entry_id:147634)”一章，我们将通过丰富的实例展示这些技术如何被应用于解析[细胞异质性](@entry_id:262569)、重建发育轨迹、绘制组织空间图谱，并与其他学科[交叉](@entry_id:147634)融合以解决复杂的生物学问题。最后，“动手实践”部分将提供具体的计算练习，帮助读者巩固关键的分析技能。通过这一结构化的学习路径，本文将引导您深入理解并有效利用转录组学这一强大的研究工具。

## 原理与机制

本章旨在深入探讨[转录组学](@entry_id:139549)研究中的核心原理与关键机制。我们将从基本的实验技术出发，逐步解析数据处理流程、[统计建模](@entry_id:272466)方法，并最终扩展到前沿的单细胞与[空间转录组学](@entry_id:270096)技术。本章假设读者已具备分子生物学的基本知识，并已阅读前序的“引言”章节。我们的目标是构建一个系统性的知识框架，使读者能够理解从生物样本到生物学洞见的全过程，并能批判性地评估不同技术策略的优缺点。

### 从[生物分子](@entry_id:176390)到数字计数：转录组测序的测量过程

[转录组学](@entry_id:139549)的核心任务是将细胞内瞬息万变的 RNA 分[子群](@entry_id:146164)体转化为可量化、可分析的[数字信号](@entry_id:188520)。这一过程涉及一系列精密的实验步骤和计算分析，每一步都蕴含着影响最终结果质量的关键选择。

#### 文库制备：选择性捕获转录本

细胞内的总 RNA 绝大多数（约 80-90%）是[核糖体](@entry_id:147360) RNA（rRNA），而研究者通常更关注信使 RNA（mRNA），因为它们编码蛋白质，直接反映了基因的表达活性。因此，RNA 测序（RNA-seq）的文库制备步骤必须首先富集我们感兴趣的 RNA 分子，或去除高丰度的 rRNA，以有效利用测序资源。

目前主要有两种策略 [@problem_id:2967152]：

1.  **Poly(A) 尾选择法**：该方法利用大多数真核生物成熟 mRNA 在 3' 端都有一条由[多聚腺苷酸聚合酶](@entry_id:272632)添加的 Poly(A) 尾巴这一结构特征。实验中，使用固定的寡[核苷酸](@entry_id:275639) dT（oligo-dT）探针，通过[碱基互补配对](@entry_id:139633)原则“钓”取带有 Poly(A) 尾的 mRNA。这种方法的优点是能高效富集 mRNA，但其局限性也同样明显。它会丢失所有不含 Poly(A) 尾的 RNA 分子，例如复制依赖性的[组蛋白](@entry_id:164675) mRNA、相当一部分长链非编码 RNA（[lncRNA](@entry_id:194588)）以及所有环状 RNA（[circRNA](@entry_id:191128)）。此外，对于部分降解的 RNA 样本（如福尔马林固定石蜡包埋，即 FFPE 样本），RNA 分子可能在 3' 端断裂，导致 Poly(A) 尾丢失，从而无法被捕获。即便捕获成功，由于逆转录通常从 3' 端的 oligo-dT 引物开始，也会导致测序读数严重偏向转录本的 3' 端，形成所谓的 **3' 偏好性（3' bias）**。

2.  **rRNA 去除法**：这是一种“减法”策略。它使用与 rRNA 序列互补的特异性探针，这些探针与 rRNA 杂交后，通过特定方式（如利用 RNase H 酶降解 RNA-DNA 杂合链中的 RNA，或磁珠纯化）将 rRNA 从总 RNA 中去除。剩余的 RNA 组分则被用于后续的文库构建。这种方法的优势在于它保留了更为完整的转录组信息，包括所有类型的 mRNA（无论是否含有 Poly(A) 尾）、非编码 RNA 和前体 mRNA。对于降解的 RNA 样本，rRNA 去除法表现更为稳健，因为它不依赖于转录本 3' 端的完整性，能够提供更均匀的基因体覆盖度。其代价是，测序读数会被分配到更广泛的 RNA 类型上，可能导致分配到编码区的读数比例相对较低。

#### 利用独特分子标识符（UMI）校正扩增偏好

为了获得足够的 DNA 进行测序，文库制备过程中必须包含[聚合酶链式反应](@entry_id:142924)（PCR）扩增步骤。然而，PCR 扩增并非一个完美的过程，不同的 DNA 分子其扩增效率可能存在差异。这种随机的、非均一的扩增会引入技术噪音，导致测序产生的读数（reads）数量不能精确地反映起始样本中 RNA 分子的真实数量。

为了解决这个问题，**独特分子标识符（Unique Molecular Identifier, UMI）** 技术应运而生 [@problem_id:2967149]。UMI 是一小段（通常为 6-12 个碱基）的随机[核苷酸](@entry_id:275639)序列。在逆转录步骤中，它与[细胞条形码](@entry_id:171163)（cell barcode）和引物一起被连接到每一个原始的 RNA（或其逆转录的 cDNA）分子上。关键在于，这一标记过程发生在任何 PCR 扩增之前。这样，源于同一个原始 RNA 分子的所有扩增拷贝都将带有完全相同的 UMI。在数据分析时，我们可以将具有相同[细胞条形码](@entry_id:171163)和相同 UMI 的所有测序读数“去重”（deduplication），只计数为一个 UMI 计数。这样，我们统计的不再是经过扩增的读数数量，而是扩增前的原始分子数量，从而极大地消除了 PCR 扩增偏好带来的噪音。

我们可以通过一个简化的数学模型来理解 UMI 的作用。假设一个基因起始有 $M$ 个分子，每个分子在 PCR 和测序后产生的读数数量 $R_i$ 是一个独立的、均值为 $\lambda$ 的泊松过程。那么，总的读数 $R = \sum_{i=1}^{M} R_i$ 的[方差](@entry_id:200758)为 $\mathrm{Var}(R) = M\lambda$，这个[方差](@entry_id:200758)与扩增效率 $\lambda$ 直接相关。而 UMI 计数 $U$ 统计的是产生了至少一个读数的原始分子数量。对于每个分子，被检测到的概率为 $p = 1 - \exp(-\lambda)$。因此，$U$ 是 $M$ 次伯努利实验的总和，其[方差](@entry_id:200758)为 $\mathrm{Var}(U) = M p (1-p) = M \exp(-\lambda)(1 - \exp(-\lambda))$。

从读数计数到 UMI 计数的[方差缩减](@entry_id:145496)比例为：
$$
\rho(\lambda) \equiv \frac{\mathrm{Var}(U)}{\mathrm{Var}(R)} = \frac{e^{-\lambda}(1 - e^{-\lambda})}{\lambda}
$$
例如，当平均每个原始分子产生 $\lambda=2$ 个读数时，[方差比](@entry_id:162608) $\rho(2) \approx 0.0585$，这意味着通过 UMI 计数，我们将技术[方差](@entry_id:200758)降低了超过 94%。这清晰地表明，UMI 通过将每个分子的扩增过程从一个计数的泊松过程转变为一个检测/未检测的伯努利过程，有效地移除了扩增效率 $\lambda$ 对计数[方差](@entry_id:200758)的主要影响。

### 从原始读数到有意义的表达值

获得测序仪产出的海量短读数（reads）后，我们需要通过一系列[生物信息学](@entry_id:146759)处理，才能将其转化为能够反映基因表达水平的有意义的数值。

#### 将读数分配给基因：比对与伪比对

核心的计算任务是将每一条短读数精确地定位到其在基因组或[转录组](@entry_id:274025)上的来源。目前主要有两大类计算策略 [@problem_id:2967130]：

1.  **[剪接](@entry_id:181943)感知型基因组比对（Splice-aware Genome Alignment）**：这类算法（如 STAR, HISAT2）将测序读数直接与参考基因组进行比对。由于真核基因包含[外显子](@entry_id:144480)（exon）和内含子（intron），成熟的 mRNA 是由[外显子](@entry_id:144480)拼接而成，因此来源于跨越两个外显子的读数在基因组上会表现为被一个巨大的内含子序列隔开。[剪接](@entry_id:181943)感知型比对工具能够识别这种“跨[内含子](@entry_id:144362)”的比对，从而精确地将读数定位到其基因组坐标。其输出通常是标准的 SAM/BAM 格式文件，记录了每个读数的详细比对信息，包括位置、错配、插入/删除和跨越的[内含子](@entry_id:144362)。这类方法的巨大优势在于，它们能够发现新的、未在[基因注释](@entry_id:164186)中记录的[剪接](@entry_id:181943)事件，并且是进行[等位基因特异性表达](@entry_id:178721)分析、RNA 编辑分析和[变异检测](@entry_id:177461)等高级分析的基础。

2.  **[转录组](@entry_id:274025)伪比对（Transcriptome Pseudoalignment）**：这类算法（如 kallisto, salmon）为了追求极高的计算速度，采取了不同的策略。它们不进行传统的、逐个碱基的动态规划比对，而是首先对所有已知的转录本序列构建一个索引（通常是基于 **[k-mer](@entry_id:166084)**，即长度为 k 的短序列）。然后，对于每一条测序读数，算法快速地查询其包含的 [k-mer](@entry_id:166084)，从而确定这条读数与哪些转录本是“兼容”的。它并不计算具体的比对位置，而是输出每个读数所兼容的转录本集合，这个集合被称为一个 **等价类（equivalence class）**。伪比对的计算成本极低，速度比传统比对快几个[数量级](@entry_id:264888)。当研究目标主要是对已知转录本进行丰度定量时，伪比对是一个极其高效且准确的选择。然而，由于它依赖于一个预先定义的转录本集合，并且不产生碱基级别的比对信息，因此它无法用于发现新的[剪接](@entry_id:181943)位点或进行[变异检测](@entry_id:177461)。

#### 比较计数的挑战：标准化

无论是通过比对还是伪比对，我们最终都会得到每个基因或转录本的 **原始计数（raw counts）**。这些原始计数值代表了映射到该基因的读数（或 UMI）的数量。然而，原始计数在不同样本或不同基因之间不具有直接可比性，主要原因有两个：

*   **[测序深度](@entry_id:178191)差异**：不同的测序文库产生的总读数数量不同。一个[测序深度](@entry_id:178191)更高的样本，其所有基因的原始计数都会系统性地偏高。
*   **基因长度差异**：在没有 UMI 的情况下，即使两个基因的表达丰度（分子浓度）相同，更长的基因也会因为能产生更多的测序片段而获得更高的原始计数。

为了校正这些偏差，必须进行 **[标准化](@entry_id:637219)（normalization）** [@problem_id:2967170]。

*   **RPKM/FPKM**：早期广泛使用的[标准化](@entry_id:637219)方法是 **每千碱基转录本每百万映射读数（Reads Per Kilobase of transcript per Million mapped reads, RPKM）**，或用于[双端测序](@entry_id:272784)的等价概念 **FPKM**。其计算公式为：
    $$
    RPKM_{i} = \frac{10^{9} \cdot C_{i}}{L_{i} \cdot R}
    $$
    其中，$C_i$ 是基因 $i$ 的原始读数，$L_i$ 是其长度（以碱基为单位），$R$ 是该样本的总映射读数。这个公式的逻辑是同时对基因长度（除以 $L_i/1000$）和[测序深度](@entry_id:178191)（除以 $R/10^6$）进行校正。

*   **[TPM](@entry_id:170576)**：尽管 RPKM/FPKM 在直觉上很合理，但它存在一个严重的统计缺陷：一个样本中所有基因的 RPKM 值之和并不固定，这使得跨样本比较基因表达比例变得不准确。为了解决这个问题，**每百万转录本（Transcripts Per Million, TPM）** 被提出。TPM 的计算分为两步：
    1.  首先，仅对基因长度进行校正，计算每个基因的“丰度率”：$r_i = C_i / L_i$。
    2.  然后，将这些率归一化，使其总和为一百万。
    $$
    TPM_{i} = \frac{\frac{C_{i}}{L_{i}}}{\sum_{j} \frac{C_{j}}{L_{j}}} \cdot 10^{6}
    $$
    [TPM](@entry_id:170576) 保证了每个样本中所有基因的 [TPM](@entry_id:170576) 值之和都等于 $10^6$，这使得它在概念上更优越，因为它直接反映了每个基因的转录本在总 mRNA 池中的相对摩尔分数。

举一个简单的例子可以说明[标准化](@entry_id:637219)的必要性。假设在一个[测序深度](@entry_id:178191)为 $2 \times 10^7$ 的样本中，我们观察到三个基因 A, B, C 的原始计数都是 1000，但它们的长度分别为 $L_A=2000$ bp, $L_B=1000$ bp, $L_C=500$ bp。尽管原始计数相同，但它们的 RPKM 值分别为 25, 50, 100。这表明，最短的基因 C 具有最高的表达丰度，这与我们的直觉相符。TPM 也会得出同样的定性结论。这个例子突显了忽略基因长度会导致对基因表达水平的严重误判。

### 转录组数据的统计推断

获得了标准化的表达矩阵后，下一个核心任务是从数据中提取生物学意义，最常见的就是进行[差异表达分析](@entry_id:266370)，即找出在不同条件下表达水平有显著变化的基因。这需要建立合适的[统计模型](@entry_id:165873)。

#### 建模计数变异性：负二项分布

[RNA-seq](@entry_id:140811) 数据本质上是计数数据。一个简单的模型是假设计数产生于一个 **泊松过程（Poisson process）**，其特点是[方差](@entry_id:200758)等于均值。然而，当我们在生物学重复样本之间比较基因的计数值时，我们几乎总是观察到 **过离散（overdispersion）** 现象，即实际观察到的[方差](@entry_id:200758)远大于均值。

这种过离散现象的根源在于生物学变异 [@problem_id:2967182]。我们可以构建一个层级模型来理解这一点：在单个生物样本内部，技术性的分子抽样过程可以近似为[泊松分布](@entry_id:147769)，其均值 $\lambda c$ 由该样本中该基因的真实丰度 $\lambda$ 和一个固定的捕获效率 $c$ 决定。然而，在不同的生物学重复（例如，来自不同个体或不同批次的细胞）之间，基因的真实丰度 $\lambda$ 本身就是一个[随机变量](@entry_id:195330)，它会因为遗传背景、微环境和细胞状态的差异而波动。

一个在数学上十分方便且生物学上合理的假设是，丰度 $\lambda$ 的变异遵循 **伽马[分布](@entry_id:182848)（Gamma distribution）**。当泊松分布的[率参数](@entry_id:265473)本身是一个遵循伽马[分布](@entry_id:182848)的[随机变量](@entry_id:195330)时，其最终产生的计数的[边际分布](@entry_id:264862)就是 **负二项分布（Negative Binomial, NB）**。

通过[全方差公式](@entry_id:177482)，我们可以推导出[负二项分布](@entry_id:262151)的[方差](@entry_id:200758)结构：
$$
\mathrm{Var}(X) = \mathbb{E}[\mathrm{Var}(X|\lambda)] + \mathrm{Var}(\mathbb{E}[X|\lambda]) = \mathbb{E}[\lambda c] + \mathrm{Var}(\lambda c) = c\mu + c^2 \mathrm{Var}(\lambda)
$$
若 $\mathrm{Var}(\lambda) = \mu^2 / k$，则[方差](@entry_id:200758)为：
$$
\mathrm{Var}(X) = c\mu + \frac{c^2\mu^2}{k}
$$
这个公式清晰地揭示了过离散的来源：总[方差](@entry_id:200758)等于技术[方差](@entry_id:200758)（泊松抽样[方差](@entry_id:200758)，与均值 $c\mu$ 成正比）加上生物学[方差](@entry_id:200758)（由 $\lambda$ 的变异传来，与均值的平方 $c^2\mu^2$ 成正比）。其中 $1/k$（或记为 $\phi$）被称为 **离散度参数（dispersion parameter）**，它量化了生物学变异的程度。

#### 用于[差异表达分析](@entry_id:266370)的负二项[广义线性模型](@entry_id:171019)

**[广义线性模型](@entry_id:171019)（Generalized Linear Model, GLM）** 为分析负二项分布的计数数据提供了一个强大而灵活的框架。一个用于 [RNA-seq](@entry_id:140811) [差异表达分析](@entry_id:266370)的标准 NB-GLM 模型由三个部分定义 [@problem_id:2967126]：

1.  **随机部分**：每个基因 $g$ 在样本 $i$ 中的计数 $Y_{ig}$ 遵循负二项分布，即 $Y_{ig} \sim \mathrm{NB}(\mu_{ig}, \phi_g)$。[离散度](@entry_id:168823)参数 $\phi_g$ 通常被认为是基因特异性的。

2.  **系统部分与[连接函数](@entry_id:636388)**：我们希望将计数的[期望值](@entry_id:153208) $\mu_{ig}$ 与实验设计中的[协变](@entry_id:634097)量（如样本条件、批次等）联系起来。由于基因表达的调控效应通常被认为是乘性的，使用 **[对数连接函数](@entry_id:163146)（log link）** 是自然的选择。同时，我们需要考虑[测序深度](@entry_id:178191)的差异，这通过一个称为 **偏移量（offset）** 的项来实现。最终的模型形式为：
    $$
    \log(\mu_{ig}) = x_i^{T}\beta_g + \log(s_i)
    $$
    在这里，$x_i$ 是样本 $i$ 的协变量向量（例如，编码样本是“病例”还是“对照”），$\beta_g$ 是基因 $g$ 对应的效应大小（我们希望估计的系数），而 $s_i$ 是一个预先计算好的、代表样本 $i$ 有效文库大小的 **大小因子（size factor）**。将 $\log(s_i)$ 作为偏移量（即其系数固定为1），等价于在原始尺度上 $\mu_{ig} = s_i \cdot \exp(x_i^{T}\beta_g)$，这精确地表达了[期望计数](@entry_id:162854)与文库大小成正比、并受协变量[乘性](@entry_id:187940)影响的思想。

3.  **均值-[方差](@entry_id:200758)关系**：如前所述，负二项分布的[方差](@entry_id:200758)与均值呈二次关系：
    $$
    \mathrm{Var}(Y_{ig}) = \mu_{ig} + \phi_g \mu_{ig}^{2}
    $$

通过拟合这个模型，我们可以估计系数 $\beta_g$，并对其进行统计检验，从而判断在控制了文库大小和其它协变量后，某个基因是否在不同条件下存在显著的表达差异。

#### 处理混杂因素：批次效应与实验设计

在实际研究中，除了我们感兴趣的生物学变量外，总会有一些技术因素引入系统性的、非生物学的变异，这些变异被称为 **批次效应（batch effects）** [@problem_id:2967162]。它们可能来源于在不同时间、使用不同批次的试剂、由不同实验员操作或在不同测序仪上运行样本。

一个灾难性的实验设计是，将所有“病例”样本在一个批次中处理，而将所有“对照”样本在另一个批次中处理。这种情况下，生物学条件与技术批次 **完全混杂（perfectly confounded）**。任何观察到的差异都无法归因于是生物学原因还是技术原因。此外，一些可测量的 **技术协变量**，如 RNA 完整性数（RIN）、基因的 GC 含量、样本的比对率等，如果它们在不同实验组之间存在系统性差异，同样会成为混杂因素，导致[差异表达分析](@entry_id:266370)结果的严重偏倚。

应对这些挑战的策略包括：

1.  **优良的实验设计**：这是最重要也是最有效的方法。核心原则是 **[随机化](@entry_id:198186)（randomization）**，即将不同实验条件的样本随机、均衡地分配到各个技术批次中。这打破了生物学变量和技术变量之间的相关性，使得它们的效应在统计上可以被区分开。

2.  **统计学校正**：在 GLM 的[设计矩阵](@entry_id:165826)中，明确地包含代表批次的变量（如 `batch` 因子）、可测量的技术[协变](@entry_id:634097)量（如 RIN），或使用 **替代变量分析（Surrogate Variable Analysis, SVA）** 等方法从数据中估计出的未被观察到的潜在技术变异因子。通过在模型中对这些不期望的变异来源进行校正，我们可以更准确地估计出真正由生物学条件驱动的表达变化。

### 解析[细胞异质性](@entry_id:262569)：单细胞与空间方法

传统的“块状”（bulk）RNA-seq 测量的是数千到数百万个细胞的平均表达谱，这会掩盖组织内不同细胞类型之间的异质性。单细胞和空间转录组学技术的出现，使我们能够以前所未有的分辨率来解析这种复杂性。

#### 将组织分解为单细胞：[scRNA-seq](@entry_id:155798)

单细胞 RNA 测序（scRNA-seq）技术能够在单个细胞水平上量化基因表达。目前主要有两大类技术平台，它们在设计哲学和性能上存在显著的权衡 [@problem_id:2967127]。

*   **基于微液滴的方法（Droplet-based Methods）**：以 10x Genomics 平台为代表，该技术利用微流控技术将单个细胞和带有独特条形码的凝胶珠（gel bead）包裹在数以万计的油包水微滴中。这种大规模并行化的方式使得它具有 **极高的通量**，一次实验可以分析数千至数万个细胞。然而，在固定的总测序预算下，高细胞通量意味着分配到 **每个细胞的[测序深度](@entry_id:178191)较低**，导致对低丰度基因的检测 **灵敏度相对较低**。其文库构建策略通常只捕获转录本的 3' 或 5' 端，产生 **末端标签式（end-tagged）** 的读数，这对于基因表达计数是高效的，但无法用于分析[可变剪接](@entry_id:142813)和转录本异构体。UMI 是这类技术的标配，对准确量化至关重要。

*   **基于孔板的方法（Plate-based Methods）**：以 SMART-Seq2 方案为代表，该技术首先通过流式细胞分选（FACS）等方法将单个细胞物理隔离到 96 孔或 384 孔板的单个孔中。其通量受限于孔板大小，通常在 **数百到上千个细胞** 的量级。由于细胞数量少，每个细胞可以获得 **非常高的[测序深度](@entry_id:178191)**，因此具有 **极高的灵敏度**，能检测到更多的基因。SMART-Seq2 的化学原理（特别是模板转换机制）能够捕获 **全长（full-length）** 的转录本信息，这使其非常适合用于研究[可变剪接](@entry_id:142813)和发现新的转录本异构体。传统的 SMART-Seq2 方案不包含 UMI，因此定量依赖于读数计数，更容易受 PCR 偏好影响。

简而言之，基于微液滴的方法是“广度优先”，适合用于构建[细胞图谱](@entry_id:270083)、发现新的细胞类型；而基于孔板的方法是“深度优先”，适合对特定、稀有的细胞群体进行深入的功能和转录本结构研究。

此外，scRNA-seq 数据，特别是基于微液滴的数据，存在一些独特的需要警惕和校正的技术赝象 [@problem_id:2967141]：

*   **双细胞（Doublets）**：两个（或多个）细胞被错误地包裹在同一个微滴中，共享同一个[细胞条形码](@entry_id:171163)。其表达谱表现为两个细胞的混合体，常常会导致本应在不同细胞类型中特异表达的标记基因出现“共表达”的假象。
*   **环境 RNA 污染（Ambient RNA Contamination）**：在制备单细胞悬液时，一些细胞会破裂，释放出其 mRNA 到溶液中。这些游离的“环境 RNA”可以被微滴中的凝胶珠捕获，从而污染真正来自完整细胞的信号。这会导致所有细胞都或多或少地带上一些高丰度环境 RNA（如红细胞或应激细胞的基因）的“背景噪音”，模糊了细胞类型之间真实的表达差异。
*   **条形码交换（Barcode Swapping / Index Hopping）**：在对多个文库进行混合测序（multiplexing）时，由于测序仪的某些特性，样本索引（sample index）可能被错误地分配，导致一个样本的读数被错误地标记为属于另一个样本。这会造成样本间的交叉污染，减弱样本间的真实生物学差异。

#### 将表达置于背景中：空间转录组学

[单细胞测序](@entry_id:198847)告诉我们“有哪些细胞”，而[空间转录组学](@entry_id:270096)则更进一步，旨在揭示“这些细胞在组织中的什么位置”，从而将基因表达与组织的空间结构和细胞间的相互作用联系起来。同样，[空间转录组学](@entry_id:270096)也主要分为两大技术[范式](@entry_id:161181) [@problem_id:2967147]。

*   **基于捕获的方法（Capture-based / Sequencing-based）**：以 10x Visium 和 [Slide-seq](@entry_id:263993) 为代表，这类技术的核心是一张覆盖有[空间条形码](@entry_id:267996)阵列的载玻片。组织切片被放置在这张载玻片上，经过透化处理后，组织中的 mRNA 会原位[扩散](@entry_id:141445)并被下方对应的、带有空间位置信息的 oligo-dT 探针捕获。随后，通过[逆转录](@entry_id:141572)将[空间条形码](@entry_id:267996)整合到 cDNA 上，最后通过高通量测序读出基因身份和其对应的空间位置。这类方法的本质是 **测序**。
    *   **优点**：它们是 **全转录组（whole-transcriptome）** 范围的，能够无偏地检测所有带 Poly(A) 尾的转录本。
    *   **缺点**：其 **空间分辨率** 受限于[空间条形码](@entry_id:267996)特征的尺寸（Visium 中为约 55 微米的斑点，[Slide-seq](@entry_id:263993) 中为约 10 微米的微珠）以及 mRNA 在透化过程中的[扩散](@entry_id:141445)距离。因此，其分辨率通常在 **细胞级到多细胞级**，难以达到亚细胞水平。

*   **基于成像的方法（Imaging-based）**：以 [MERFISH](@entry_id:191159) 和 seqFISH 为代表，这类技术的核心是 **成像**。它们利用[荧光原位杂交](@entry_id:272648)（FISH）的原理，但通过巧妙的[组合编码](@entry_id:152954)和多轮成像策略，极大地扩展了可同时检测的基因数量。实验中，为每个目标基因设计一套特异性的探针，并为每个基因分配一个独特的二进制“条形码”。在多轮成像中，每一轮通过杂交不同的荧光探针组合，来“点亮”条形码中对应位为“1”的基因。通过解码每个荧光点在多轮成像中的亮灭模式，就可以确定该分子的基因身份和其在细胞内的精确位置。
    *   **优点**：它们能够达到 **亚细胞级的空间分辨率**（由光学衍射极限决定，约 200 纳米），可以对单个 RNA 分子进行定位。
    *   **缺点**：这类方法是 **靶向的（targeted）**，需要预先设计[并合](@entry_id:147963)成针对特定基因集的探针，虽然目前可检测的基因数量已达数千甚至上万，但仍非全[转录组](@entry_id:274025)。此外，多轮的液体操作和高分辨率成像非常耗时，对于大面积组织（如平方厘米级）的通量是其主要瓶颈。

总结来说，基于捕获的方法以较低的分辨率提供了全[转录组](@entry_id:274025)的广度，而基于成像的方法则以极高的分辨率提供了对靶向基因集的深度窥探。这两种技术各有千秋，共同推动着我们对生命过程空间维度认识的革命。