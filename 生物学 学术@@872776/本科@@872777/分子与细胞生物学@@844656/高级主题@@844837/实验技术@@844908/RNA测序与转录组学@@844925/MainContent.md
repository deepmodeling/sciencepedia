## 引言
[RNA测序](@entry_id:178187)（RNA-seq）已经彻底改变了我们研究基因表达的方式，成为现代[分子生物学](@entry_id:140331)和基因组学研究的基石。通过对细胞内所有RNA转录本进行高通量测序，这项技术为我们提供了一个前所未有的、关于生命活动在特定时刻的动态快照。然而，从一个生物学问题出发，到最终获得可靠的转录组学结论，需要跨越一系列复杂的实验和计算步骤。许多研究者对于如何正确设计实验、处理原始数据以及解读其背后丰富的生物学信息感到困惑，这构成了从数据到知识的转化障碍。

本文旨在系统性地梳理[RNA测序](@entry_id:178187)与[转录组学](@entry_id:139549)分析的全过程。在“原理与机制”一章中，我们将详细拆解从样本制备到[数据标准化](@entry_id:147200)的每一个关键步骤。随后的“应用与跨学科连接”将展示该技术在[功能基因组学](@entry_id:155630)、单细胞生物学乃至生态学中的强大应用。最后，“动手实践”部分将通过具体问题，巩固您在实验设计和数据解读方面的核心技能。通过遵循这一结构，读者将建立起对[RNA测序](@entry_id:178187)从理论到实践的全面理解，为开展自己的[转录组学](@entry_id:139549)研究打下坚实的基础。

## 原理与机制

本章节将深入探讨[RNA测序](@entry_id:178187)（RNA-seq）的核心原理和机制。我们将遵循一个典型的[RNA-seq](@entry_id:140811)实验流程，从实验设计和样本制备开始，经过数据生成和生物信息学处理，最终到达[数据标准化](@entry_id:147200)的关键步骤。通过理解每一步的科学基础，研究者可以确保其转录组学研究的严谨性和结果的可靠性。

### 实验设计的基石：生物学重复与样本质量

在启动任何测序实验之前，周密的实验设计和严格的样本质量控制是确保最终数据具有统计学意义和生物学[可解释性](@entry_id:637759)的先决条件。这两个初步阶段的决策将直接影响研究结论的有效性。

#### 实验设计的重要性：[生物学重复与技术重复](@entry_id:199856)

转录组学研究的主要目标之一是鉴定在不同条件下（例如，药物处理与[对照组](@entry_id:747837)）表达水平发生显著变化的基因。为了以统计学置信度达成这一目标，正确的实验重复策略至关重要。设想一位研究者，Dr. Evans，计划研究一种新药对癌细胞基因表达的影响，她需要决定如何分配有限的测序样本资源 [@problem_id:2336621]。

她面临两种选择：
1.  **生物学重复 (Biological Replicates)**：培养多个独立的细胞培养瓶，一部分作为[对照组](@entry_id:747837)，另一部分用药物处理。从每个独立的培养瓶中提取RNA，制备测序文库。例如，三个独立的对照组培养和三个独立的处理组培养。
2.  **技术重复 (Technical Replicates)**：仅培养一个大的对照组细胞培养瓶和一个大的处理组细胞培养瓶。从每个培养瓶中提取RNA后，将每个RNA样本分成几份，然后分别对每一份进行后续的文库制备和测序。

对于鉴定[差异表达](@entry_id:748396)基因这一目标而言，**生物学重复**是必不可少的，其设计远优于技术重复。原因是，基因表达本身存在固有的**生物学变异 (biological variability)**。即使在完全相同的培养条件下，不同批次或不同培养皿的细胞其基因表达谱也存在细微差异。生物学重复能够捕获并量化这种组内（within-group）的自然变异。统计检验（如[t检验](@entry_id:272234)或更复杂的负二项分布模型）的本质，就是判断组间（between-group）的差异（例如，由药物引起的差异）是否显著大于组内的随机变异。没有生物学重复，就无法估计真实的生物学变异，任何观察到的差异都可能仅仅是偶然，从而无法得出具有统计学意义的结论。

相比之下，技术重复主要衡量的是实验流程本身引入的噪音，例如在文库制备或测序过程中的[随机误差](@entry_id:144890)。虽然减少技术噪音可以提高单次测量的[精确度](@entry_id:143382)，但这对于推断药物是否对一个[生物系统](@entry_id:272986)产生普遍性效应几乎没有帮助。在[差异表达分析](@entry_id:266370)中，生物学变异通常远大于技术变异，因此，将资源投入到生物学重复中，以获得对群体变异的[稳健估计](@entry_id:261282)，是更为关键的策略。将技术重复误认为是生物学重复是一种被称为**[伪重复](@entry_id:176246) (pseudoreplication)** 的严重统计错误，它会导致假阳性结果的急剧增加。

#### 从细胞到测序仪：RNA提取与质量控制

选定实验设计后，下一步是从生物样本中提取RNA。然而，细胞内的总RNA并非我们主要关注的对象。在典型的人类细胞中，总RNA按质量计，约80-90%是**核糖体RNA (rRNA)**，只有1-5%是我们通常旨在研究的**[信使RNA](@entry_id:262893) (mRNA)**，其余为转移RNA (tRNA) 和其他[非编码RNA](@entry_id:268179) [@problem_id:2336624]。

由于rRNA占据绝对主导地位，如果在文库制备前不将其去除，测序资源将绝大部分被浪费在测定rRNA序列上，而这些序列对于大多[数基](@entry_id:634389)因表达研究来说[信息量](@entry_id:272315)很低。因此，[RNA-seq](@entry_id:140811)的标准流程包含一个关键步骤：去除rRNA或富集mRNA。常用的方法包括：
1.  **rRNA去除 (rRNA depletion)**：使用与rRNA序列互补的探针，将rRNA分子捕获并移除。
2.  **mRNA富集 (poly(A) selection)**：利用大多数成熟mRNA分子在3'端都有一条多聚[腺苷](@entry_id:186491)酸（poly-A）尾的特性，使用与poly-A结合的寡[核苷酸](@entry_id:275639)（oligo-dT）磁珠来特异性地捕获mRNA。

如果研究者因疏忽跳过了这一步骤，那么最终得到的数百万条测序读长（reads）中，绝大多数将来源于rRNA，导致对mRNA的[测序深度](@entry_id:178191)严重不足，无法准确量化基因表达。

在进行昂贵的文库制备和测序之前，评估提取出的RNA的完整性至关重要。RNA分子，特别是mRNA，非常容易被**[核糖核酸酶](@entry_id:136536) (RNase)** 降解。一个广泛使用的质量控制指标是**RNA完整性数 (RNA Integrity Number, RIN)**。该数值通过自动化[毛细管电泳](@entry_id:171495)系统（如Agilent Bioanalyzer）分析总RNA样本后计算得出，范围从1（完全降解）到10（完全完整）。RIN算法主要基于18S和28S rRNA峰的形态、比例和基线信号。对于一个健康的、高质量的RNA样本，[电泳](@entry_id:173548)图谱会显示出两个清晰、尖锐的rRNA峰，且峰下面区域的“涂抹”状信号（代表降解的RNA片段）很少。

如果一个样本的RIN值为4.0，这表明RNA已发生严重降解 [@problem_id:2336628]。在[电泳](@entry_id:173548)图谱上，这通常表现为18S和28S rRNA峰的消失或显著减小，以及在峰左侧（小分子量区域）出现大量的降解产物。使用这种高度降解的RNA进行标准的m[RNA测序](@entry_id:178187)，会导致严重的**3'偏好性 (3' bias)**，因为只有靠近poly-A尾的RNA片段更有可能被成功捕获和测序。这使得对基因全长转录本的表达水平进行准确定量变得不可能。因此，对于大多数标准的[RNA-seq](@entry_id:140811)应用，通常要求样本的RIN值大于7或8，以确保数据的可靠性。

### 数据的生成：测序与原始数据格式

经过严格的质量控制后，合格的RNA样本进入文库制备和高通量测序阶段。这一过程将[生物分子](@entry_id:176390)转化为数字信息，其原始输出格式的结构和含义是后续所有分析的基础。

#### 文库制备与测序

简而言之，文库制备过程包括以下核心步骤：
1.  **片段化 (Fragmentation)**：将长链的mRNA或去除了rRNA的RNA分子随机打断成较短的片段（通常为200-500个碱基）。
2.  **[逆转录](@entry_id:141572) (Reverse Transcription)**：使用[逆转录酶](@entry_id:137829)将RNA片段合成为更稳定的互补DNA（cDNA）。
3.  **接头连接 (Adapter Ligation)**：在cDNA片段的两端连接上已知的短DNA序列，即**测序接头 (sequencing adapters)**。这些接头含有与测序仪流动槽（flow cell）上的寡[核苷酸](@entry_id:275639)互补的序列、用于扩增的引物结合位点以及用于区分不同样本的条形码（barcode）序列。
4.  **扩增 (Amplification)**：通过PCR技术对连接了接头的cDNA片段进行扩增，形成足够数量的DNA分子，构成一个**测序文库 (sequencing library)**。

最后，将文库加载到高通量测序仪上进行测序，生成数百万到数十亿个短DNA序列读长。

#### 解读原始测[序数](@entry_id:150084)据：[FASTQ](@entry_id:201775)格式

测序仪输出的原始数据通常以**[FASTQ](@entry_id:201775)格式**存储。[FASTQ](@entry_id:201775)文件中的每一条测序读长都由四行文本组成，这四行包含了序列本身及其质量信息。以下是一个典型的[FASTQ](@entry_id:201775)条目示例 [@problem_id:2336587]：

```
@SRR12345.1 flowcell1:lane2:tile3:x4:y5/1
GATTACA
+
B?>=A@
```

这四行的含义分别是：
1.  **第一行 (Identifier Line)**：以 `@` 符号开头，是这条读长的唯一标识符。它通常包含测序仪的运行信息，如仪器ID、运行编号、流动槽信息、在流动槽上的物理坐标等。
2.  **第二行 (Sequence Line)**：这是测序得到的原始碱基序列。
3.  **第三行 (Separator Line)**：以 `+` 符号开头，作为序列和质量值之间的分隔符。有时在 `+` 后面会重复第一行的标识符。
4.  **第四行 (Quality Score Line)**：这一行包含了与第二行序列中每个碱基相对应的质量得分。每个字符代表一个质量值，其长度必须与第二行的序列长度完全相同。

#### 量化置信度：Phred质量值

第四行的质量字符串并非随机字符，而是对每个碱基测序准确性的量化编码，这个编码系统被称为**Phred质量值 (Phred quality score)**，用 $Q$ 表示。$Q$ 值与碱基检出错误的概率 $P$ 之间通过对数关系进行转换：

$Q = -10 \log_{10}(P)$

或者，反过来计算错误概率：

$P = 10^{-Q/10}$

例如，一个碱基的 $Q$ 值为10，意味着[错误概率](@entry_id:267618)为 $10^{-10/10} = 0.1$（即90%的准确率）；$Q$ 值为20，[错误概率](@entry_id:267618)为 $10^{-20/10} = 0.01$（99%的准确率）；$Q$ 值为30，错误概率为 $10^{-30/10} = 0.001$（99.9%的准确率）。

为了将数值型的 $Q$ 分数用单个[ASCII](@entry_id:163687)字符表示以节省空间，[FASTQ](@entry_id:201775)文件采用了特定的编码方案。目前最常用的是**Phred+33编码**，即字符的[ASCII](@entry_id:163687)十[进制](@entry_id:634389)值等于其所代表的Phred质量值 $Q$ 再加上33。

让我们回到上面的例子 [@problem_id:2336587]，其质量字符串为 `B?>=A@`。我们可以通过解码来计算整条读长的平均错误概率。
-   字符 'B' 的[ASCII](@entry_id:163687)值是66。根据Phred+33编码，其对应的 $Q$ 值为 $66 - 33 = 33$。因此，该碱基的错误概率 $P_1 = 10^{-33/10} = 10^{-3.3}$。
-   字符 '?' 的[ASCII](@entry_id:163687)值是63，对应的 $Q$ 值为 $63 - 33 = 30$，[错误概率](@entry_id:267618) $P_2 = 10^{-3.0}$。
-   以此类推，我们可以解码整条质量字符串，得到每个碱基的错误概率，然后计算其平均值：

$\bar{P} = \frac{1}{7} \sum_{i=1}^{7} P_i = \frac{1}{7} (10^{-3.3} + 10^{-3.0} + 10^{-2.9} + 10^{-2.7} + 10^{-2.8} + 10^{-3.2} + 10^{-3.1})$

计算结果约为 $0.00111$。这意味着，对于这条长度为7个碱基的读长，平均每个碱基被错误识别的概率约为0.111%。在进行下游分析前，通常会根据这些质量值对读长进行过滤和修剪，去除低质量的碱基或整条读长。

### 从Reads到Counts：生物信息学分析流程

获得了高质量的测序读长后，下一步是通过一系列计算步骤，将这些短序列片段还原到其在基因组上的来源，并最终量化每个基因的表达水平。

#### RNA Reads比对的挑战：[剪接](@entry_id:181943)

将测序读长定位回参考基因组的过程称为**比对 (alignment)** 或 **映射 (mapping)**。然而，将RNA-seq读长比对到基因组上，比处理[DNA测序](@entry_id:140308)数据面临一个独特的、根本性的挑战：**[RNA剪接](@entry_id:147807) (RNA splicing)** [@problem_id:2336595]。

在包括人类在内的真核生物中，基因的结构并非连续。它们由**[外显子](@entry_id:144480) (exons)**（编码蛋白质或成为成熟RNA一部分的序列）和**[内含子](@entry_id:144362) (introns)**（插入[外显子](@entry_id:144480)之间的非[编码序列](@entry_id:204828)）组成。当基因被转录时，首先产生的是一个包含[外显子和内含子](@entry_id:261514)的[前体mRNA](@entry_id:137517)（pre-mRNA）。随后，一个名为剪接体（spliceosome）的细胞机器会精确地切除内含子，并将外显子连接在一起，形成成熟的mRNA。

[RNA-seq](@entry_id:140811)测序的对象是这些成熟的、经过[剪接](@entry_id:181943)的mRNA。因此，相当一部分测序读长会跨越两个外显子连接形成的**[剪接](@entry_id:181943)点 (exon-exon junction)**。例如，一条100个碱基的读长可能前半部分来自[外显子](@entry_id:144480)1的末端，后半部分来自外显子2的开端。

当一个为[DNA测序](@entry_id:140308)设计的标准比对工具（如早期的Bowtie）试图将这样一条“跨[剪接](@entry_id:181943)点”的读长比对到参考基因组上时，问题就出现了。在参考基因组序列中，[外显子](@entry_id:144480)1和[外显子](@entry_id:144480)2之间被一个完整的[内含子](@entry_id:144362)序列隔开，这个[内含子](@entry_id:144362)的长度可能从几十个碱基到数万个碱基不等。比对工具会发现读长的前半部分可以完美匹配基因组的某个位置（外显子1），但后半部分却出现在基因组上数千个碱基之外的另一个位置（[外显子](@entry_id:144480)2）。对于标准比对工具来说，这表现为一个巨大的“缺口”或“删除”，远远超出了其设计的容错范围（通常只能处理几个碱基的插入或删除）。因此，它无法为这条读长找到一个连续的、合法的比对，最终只能将其判定为“未比对上”。

由于[剪接](@entry_id:181943)是真核生物基因表达的普遍现象，使用非[剪接](@entry_id:181943)感知的比对工具会导致大量有效的测序读长被丢弃，从而严重低估基因表达水平。为了解决这个问题，[生物信息学](@entry_id:146759)家开发了**[剪接感知比对](@entry_id:175766)工具 (splice-aware aligners)**，如STAR和HISAT2。这些工具经过专门设计，能够识别出一条读长可以被拆分成两部分（或更多），并分别比对到基因组的不同位置，只要这两部分之间的距离和方向符合已知的[剪接](@entry_id:181943)模式（例如，符合GT-AG[剪接](@entry_id:181943)信号）。

#### 将Reads分配至基因：基因组注释的作用

即使读长被成功地比对到了基因组的正确位置，我们还需要一个“地图”来告诉我们这些位置属于哪个基因。这个地图就是**基因组注释文件 (genome annotation file)**，常用的格式有**GTF (Gene Transfer Format)** 或 **GFF (General Feature Format)** [@problem_id:2336605]。

这个文件是一个简单的文本文件，其中每一行都定义了一个基因组特征（feature），如基因、转录本或外显子。每一行都包含了该特征的详细信息，包括：
-   所在的[染色体](@entry_id:276543)或序列名称。
-   特征的类型（例如，`gene`、`transcript`、`exon`）。
-   在[染色体](@entry_id:276543)上的起始和终止坐标。
-   所在的链（正链 `+` 或负链 `-`）。
-   一组属性，如 `gene_id`、`transcript_id` 等，将该特征与特定的基因和转录本关联起来。

在读长比对完成后，定量软件（如featureCounts）会执行下一步操作：将比对上的读长分配给基因。其核心功能是，对于每一条比对上的读长，检查其在基因组上的坐标是否与GTF文件中定义的[外显子](@entry_id:144480)坐标发生重叠。如果一条读长落在了某个基因的外显子区域内，那么这条读长就会被计数到该基因名下。通过这个过程，软件可以遍历所有比对上的读长，最终统计出每个基因对应的总读长数。没有基因组注释文件，我们就只有读长在基因组上的位置，而无法知道它们究竟属于哪个基因，也就无法完成基因表达的定量。

#### 一种更快的替代方案：伪比对

传统的[剪接感知比对](@entry_id:175766)虽然解决了[剪接](@entry_id:181943)问题，但仍然是一个计算密集型且耗时的过程。近年来，一类被称为**伪比对 (pseudo-alignment)** 的新方法极大地提升了定量速度，其[代表性](@entry_id:204613)工具是Kallisto和Salmon [@problem_id:2336630]。

伪比对的核心思想是，为了定量，我们实际上不需要知道每条读长在基因组或转录本上的确切碱基级比对位置。我们只需要知道这条读长**可能来源于哪些转录本**。伪比对通过以下方式实现这一目标：

1.  **索引构建**：在分析开始前，工具会首先对一个**参考转录组**（包含所有已知转录本序列的[FASTA](@entry_id:267943)文件）进行处理。它将所有转录本序列分解成许多短的、固定长度的[子序列](@entry_id:147702)，称为 **[k-mer](@entry_id:166084)s**（例如，长度为31的序列片段）。然后，它构建一个高效的索引（如[哈希表](@entry_id:266620)或[de Bruijn图](@entry_id:263552)），该索引记录了每个[k-mer](@entry_id:166084)出现在哪些转录本中。

2.  **兼容性确定**：当分析测序读长时，工具并不进行传统的比对。相反，它从每条读长中提取出其包含的[k-mer](@entry_id:166084)s，并使用索引快速查找这些[k-mer](@entry_id:166084)s分别与哪些转录本兼容。通过对一条读长中所有[k-mer](@entry_id:166084)s的兼容转录本集合进行求交集或其它组合操作，工具可以迅速确定出这条读长与哪些转录本是**兼容的 (compatible)**。这个兼容集被称为一个**[等价类](@entry_id:156032) (equivalence class)**。

3.  **丰度估计**：在处理完所有读长后，工具会得到许多[等价类](@entry_id:156032)以及每个[等价类](@entry_id:156032)包含的读长数目。最后，通过一个统计模型（如[期望最大化算法](@entry_id:165054)，Expectation-Maximization algorithm），它根据这些[等价类](@entry_id:156032)的信息来推断出每个转录本的最可能丰度。

由于伪比对方法避免了逐个碱基进行比对的复杂计算，而是依赖于极快的[k-mer](@entry_id:166084)查找，其速度比传统比对方法快了几个[数量级](@entry_id:264888)，通常只需几分钟即可完成对一个样本的定量，而传统方法可能需要数小时。

### 从原始Counts到有意义的表达值：[标准化](@entry_id:637219)

无论通过传统比对还是伪比对，定量的最终产物都是一个**Counts矩阵 (count matrix)**。然而，这些原始计数值（raw counts）并不能直接用于比较不同样本或不同基因间的表达水平，必须经过**标准化 (normalization)** 校正系统性技术偏差。

#### 定量的产物：Counts矩阵

在定量步骤结束时，生物信息学家会生成一个核心的[数据结构](@entry_id:262134)——Counts矩阵。这是一个简单的表格，其结构和内容有非常明确的常规定义 [@problem_id:2336581]：
-   **行 (Rows)**：代表**基因**（或转录本）。每一行对应一个唯一的基因，例如TP53或GAPDH。
-   **列 (Columns)**：代表**独立的样本**。每一列对应一个独立的生物学样本，例如“Control_1”、“Control_2”、“Treated_1”等。
-   **单元格值 (Cell Values)**：在特定基因（行）和特定样本（列）[交叉](@entry_id:147634)处的数值，是归属于该基因的**原始测序读长计数**。这是一个未经[标准化](@entry_id:637219)的整数。

这个Counts矩阵是所有下游[差异表达分析](@entry_id:266370)的起点。它的每一列都是对一个样本转录组的“快照”，而我们的任务就是比较这些快照，找出有意义的变化。

#### 校正“[测序深度](@entry_id:178191)”：文库大小的[标准化](@entry_id:637219)

直接比较不同样本中某个基因的原始计数值是错误的，因为它忽略了一个最主要的技术偏差：**[测序深度](@entry_id:178191) (sequencing depth)**，也称为**文库大小 (library size)**。不同样本的测序总读长数几乎总是不一样的。一个样本测序产生的总读长数越多，那么分配到每个基因的读长数也倾向于越多，但这并不代表基因的生物学表达水平就更高。

让我们看一个具体的例子 [@problem_id:2336607]。假设我们有两个样本：
-   **样本Alpha ([对照组](@entry_id:747837))**：总测序读长数（文库大小）为1500万。基因TRX的原始计数值为3,000。
-   **样本Beta (处理组)**：总测序读长数为4500万。基因TRX的原始计数值为6,000。

如果只看原始计数值，人们可能会错误地得出结论，认为基因TRX在处理组中的表达量是“上调”的，因为6,000是3,000的两倍。然而，正确的做法是计算该基因的读长数占各自文库总大小的**相对比例**。
-   在样本Alpha中，基因TRX的相对丰度约为： $\frac{3,000}{15,000,000} = 2 \times 10^{-4}$
-   在样本Beta中，基因TRX的相对丰度约为： $\frac{6,000}{45,000,000} \approx 1.33 \times 10^{-4}$

经过文库大小标准化后，我们得出了完全相反的结论：基因TRX在处理组（Beta）中的相对表达水平实际上是**低于**对照组（Alpha）的。这个简单的例子凸显了[标准化](@entry_id:637219)的必要性。最简单的标准化方法之一是**每百万读长计数 (Counts Per Million, CPM)**，即 $CPM = \frac{\text{raw count}}{\text{total reads}} \times 10^6$。更高级的[差异表达分析](@entry_id:266370)工具（如[DESeq2](@entry_id:167268)和edgeR）使用更稳健的[标准化](@entry_id:637219)因子，但其核心目的都是为了校正[测序深度](@entry_id:178191)的差异。

#### 校正“基因长度”：基因长度的标准化

除了[测序深度](@entry_id:178191)，另一个影响原始计数值的因素是**基因长度**。在RNA被片段化时，一个更长的转录本自然会产生更多的片段，因此在相同的表达水平下，它会“捕获”到更多的测序读长。因此，当我们需要**在同一个样本内比较不同基因的表达水平**时，必须对基因长度进行标准化。

一个早期的、直观的[标准化](@entry_id:637219)单位是**RPKM (Reads Per Kilobase of transcript per Million mapped reads)**，其定义为 [@problem_id:2336576]：

$\mathrm{RPKM} = \frac{C \times 10^9}{N \times L}$

其中：
-   $C$ 是映射到该基因的原始读长数。
-   $N$ 是该样本的总映射读长数（以百万为单位的文库大小）。
-   $L$ 是该基因转录本的长度（以千碱基为单位）。

公式中的 $10^9$ 是为了同时校正以“百万”为单位的读长总数 ($10^6$) 和以“千碱基”为单位的基因长度 ($10^3$) 所引入的缩放因子。

例如，假设一个实验中，总映射读长数 $N$ 为2150万。我们关注的基因Gene-27B，其转录本长度 $L$ 为850个碱基（即0.85千碱基），观察到其原始计数值 $C$ 为4,150。我们可以计算其RPKM值：

$\mathrm{RPKM} = \frac{4,150 \times 10^9}{(21.5 \times 10^6) \times 850} = \frac{4,150 \times 1000}{21.5 \times 850} \approx 227$

这个值为227的RPKM值，理论上可以与其他基因的RPKM值在同一个样本内进行比较。一个长度是Gene-27B两倍但RPKM值同为227的基因，其原始读长数应约为8,300。

需要注意的是，虽然RPKM和其变体FPKM（Fragments Per Kilobase...，用于[双端测序](@entry_id:272784)）在概念上很直观，但它们在统计学上存在一些缺陷，例如在样本间的可比性不佳。因此，在现代的[差异表达分析](@entry_id:266370)中，研究者通常使用原始Counts矩阵和专门为此设计的统计模型（如[DESeq2](@entry_id:167268)），这些模型在内部处理标准化问题。然而，理解RPKM背后的原理——即同时校正[测序深度](@entry_id:178191)和基因长度——对于正确解读[转录组](@entry_id:274025)数据仍然至关重要。