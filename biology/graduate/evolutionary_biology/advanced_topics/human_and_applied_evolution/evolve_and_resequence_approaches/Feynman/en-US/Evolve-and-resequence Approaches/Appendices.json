{
    "hands_on_practices": [
        {
            "introduction": "A successful Evolve-and-Resequence study begins not in the lab, but on the drawing board with careful planning. This practice guides you through a fundamental component of experimental design: statistical power analysis. By learning to derive the required number of replicate populations, $R$, you will gain an appreciation for the interplay between selection strength ($s$), genetic drift (governed by $N_e$), and measurement noise from pooled sequencing, ensuring your future experiments are built on a solid statistical foundation .",
            "id": "2711888",
            "problem": "An experimental evolution study uses an Evolve and Resequence (E&R) design with $R$ independent replicate populations, each of constant effective population size $N_{e}$, initiated from the same base population with a focal single-nucleotide polymorphism (SNP) at initial derived-allele frequency $p_{0}$. Each replicate evolves for $T$ discrete generations under genic selection favoring the derived allele with selection coefficient $s$ in a diploid Wright–Fisher population. At generation $0$ and generation $T$, pooled whole-population sequencing is performed with per-site coverage $C$ in each replicate, and the derived-allele frequency is estimated at both timepoints in each replicate from the sequencing reads. Assume that across timepoints and across replicates, sequencing read sampling is independent and follows a binomial model. \n\nYou will design a one-sided test of the null hypothesis $H_{0}: \\Delta = 0$ versus the alternative $H_{1}: \\Delta > 0$, where $\\Delta$ denotes the derived-allele frequency change between generation $T$ and generation $0$. Use a Wald $Z$-test at significance level $\\alpha$. Base your derivation on the following well-tested foundations:\n\n- The diffusion approximation for Wright–Fisher drift without selection gives the variance of allele frequency after $T$ generations as $\\operatorname{Var}(p_{T}\\mid p_{0}) \\approx p_{0}(1-p_{0})\\left(1-\\exp\\!\\left(-\\frac{T}{2 N_{e}}\\right)\\right)$, which you may use to approximate the among-replicate variance contribution from genetic drift to the change $\\Delta$.\n- Under weak selection, the expected deterministic trajectory for genic selection in continuous time satisfies $\\frac{d p}{d t} = s\\,p(1-p)$, whose solution implies the expected allele frequency after $T$ generations is $p_{T} \\approx \\frac{1}{1 + \\left(\\frac{1-p_{0}}{p_{0}}\\right)\\exp(-s T)}$.\n- Pool-sequencing at coverage $C$ yields an unbiased estimator of allele frequency at each timepoint with binomial sampling variance $p(1-p)/C$, independent across timepoints and replicates.\n\nAssume independence of drift and sequencing contributions and of all replicates, and approximate the sampling distribution of the replicate-mean change by a normal distribution. Derive from first principles an analytic expression for the minimal number of replicates $R$ required to achieve statistical power $1-\\beta$ under $H_{1}$, expressed in terms of $s$, $p_{0}$, $T$, $N_{e}$, $C$, $\\alpha$, and $\\beta$. Then, using the parameters $s = 0.02$, $p_{0} = 0.10$, $T = 30$, $N_{e} = 1000$, $C = 100$, $\\alpha = 0.05$, and target power $1-\\beta = 0.80$, compute the minimal integer $R$ that satisfies this requirement. State the final $R$ as an integer with no units. If intermediate numerical approximations are needed, carry them out to at least $4$ significant figures; the final $R$ must be the minimal integer meeting the criterion and does not require rounding.",
            "solution": "The problem requires the derivation of the minimal number of replicates, $R$, for an Evolve and Resequence experiment to achieve a desired statistical power. The problem is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. It is therefore valid.\n\nWe begin by establishing the statistical framework. The hypothesis test concerns the mean change in derived-allele frequency, $\\Delta = p_T - p_0$. The null hypothesis is $H_0: \\Delta = 0$, and the one-sided alternative is $H_1: \\Delta > 0$. We use a Wald $Z$-test based on the mean estimated frequency change over $R$ replicates, denoted by $\\bar{\\hat{\\Delta}}$.\n\nLet $\\hat{p}_{i,0}$ and $\\hat{p}_{i,T}$ be the estimated allele frequencies in replicate $i$ at generation $0$ and $T$, respectively. The estimated change for replicate $i$ is $\\hat{\\Delta}_i = \\hat{p}_{i,T} - \\hat{p}_{i,0}$. The test statistic is based on the average of these estimates across all $R$ replicates:\n$$ \\bar{\\hat{\\Delta}} = \\frac{1}{R} \\sum_{i=1}^{R} \\hat{\\Delta}_i $$\nBy the central limit theorem, for sufficiently large $R$, the sampling distribution of $\\bar{\\hat{\\Delta}}$ is approximately normal.\n\nThe Wald Z-statistic is given by:\n$$ Z = \\frac{\\bar{\\hat{\\Delta}} - E[\\bar{\\hat{\\Delta}} | H_0]}{\\sqrt{\\operatorname{Var}(\\bar{\\hat{\\Delta}} | H_0)}} $$\nUnder the null hypothesis $H_0$, there is no selection ($s=0$), so the expected allele frequency does not change. Thus, $E[p_T|H_0] = p_0$, and the expected change is $E[\\bar{\\hat{\\Delta}} | H_0] = 0$.\n\nTo construct the test and perform the power analysis, we must determine the variance of $\\bar{\\hat{\\Delta}}$ under both the null ($H_0$) and the alternative ($H_1$) hypotheses. The variance of the mean estimate is $\\operatorname{Var}(\\bar{\\hat{\\Delta}}) = \\frac{1}{R} \\operatorname{Var}(\\hat{\\Delta}_i)$. We must first find the variance for a single replicate, $\\sigma_{\\hat{\\Delta}}^2 = \\operatorname{Var}(\\hat{\\Delta}_i)$.\n\nThe total variance in the estimated change $\\hat{\\Delta}_i$ arises from two independent processes: genetic drift over $T$ generations and binomial sampling of reads during sequencing at two time points. Since the sequencing estimates at generation $0$ and $T$ are independent, we have:\n$$ \\operatorname{Var}(\\hat{\\Delta}_i) = \\operatorname{Var}(\\hat{p}_{i,T} - \\hat{p}_{i,0}) = \\operatorname{Var}(\\hat{p}_{i,T}) + \\operatorname{Var}(\\hat{p}_{i,0}) $$\nThe initial frequency $p_0$ is fixed, so the variance of its estimator is purely from sequencing:\n$$ \\operatorname{Var}(\\hat{p}_{i,0}) = \\frac{p_0(1-p_0)}{C} $$\nThe frequency $p_{i,T}$ in replicate $i$ at generation $T$ is a random variable due to drift. We use the law of total variance to find $\\operatorname{Var}(\\hat{p}_{i,T})$:\n$$ \\operatorname{Var}(\\hat{p}_{i,T}) = E[\\operatorname{Var}(\\hat{p}_{i,T} | p_{i,T})] + \\operatorname{Var}(E[\\hat{p}_{i,T} | p_{i,T}]) $$\nGiven the true frequency $p_{i,T}$, the sequencing estimator is unbiased, $E[\\hat{p}_{i,T} | p_{i,T}] = p_{i,T}$, and its variance is $\\operatorname{Var}(\\hat{p}_{i,T} | p_{i,T}) = \\frac{p_{i,T}(1-p_{i,T})}{C}$.\nThe expression for $\\operatorname{Var}(\\hat{p}_{i,T})$ becomes:\n$$ \\operatorname{Var}(\\hat{p}_{i,T}) = E\\left[\\frac{p_{i,T}(1-p_{i,T})}{C}\\right] + \\operatorname{Var}(p_{i,T}) $$\nWe approximate the first term using the expected value of $p_{i,T}$. Let $p_T^{\\text{exp}} = E[p_{i,T}]$. Then $E\\left[\\frac{p_{i,T}(1-p_{i,T})}{C}\\right] \\approx \\frac{p_T^{\\text{exp}}(1-p_T^{\\text{exp}})}{C}$. The second term, $\\operatorname{Var}(p_{i,T})$, is the variance due to genetic drift, which the problem provides as $\\operatorname{Var}(p_T | p_0) \\approx p_0(1-p_0)\\left(1-\\exp\\left(-\\frac{T}{2N_e}\\right)\\right)$.\n\nThe total per-replicate variance is therefore:\n$$ \\sigma_{\\hat{\\Delta}}^2 = \\operatorname{Var}(\\hat{\\Delta}_i) \\approx p_0(1-p_0)\\left(1-\\exp\\left(-\\frac{T}{2N_e}\\right)\\right) + \\frac{p_T^{\\text{exp}}(1-p_T^{\\text{exp}})}{C} + \\frac{p_0(1-p_0)}{C} $$\nUnder $H_0$, $s=0$, so $p_T^{\\text{exp}} = p_0$. The variance under the null, $\\sigma_0^2$, simplifies to:\n$$ \\sigma_0^2 = p_0(1-p_0)\\left(1-\\exp\\left(-\\frac{T}{2N_e}\\right)\\right) + \\frac{2p_0(1-p_0)}{C} = p_0(1-p_0)\\left[1-\\exp\\left(-\\frac{T}{2N_e}\\right) + \\frac{2}{C}\\right] $$\nUnder $H_1$, with selection coefficient $s > 0$, the expected frequency is $p_T^{\\text{exp}} \\approx \\frac{1}{1 + \\left(\\frac{1-p_0}{p_0}\\right)\\exp(-sT)}$. The variance under the alternative, $\\sigma_1^2$, is:\n$$ \\sigma_1^2 = p_0(1-p_0)\\left(1-\\exp\\left(-\\frac{T}{2N_e}\\right)\\right) + \\frac{p_T^{\\text{exp}}(1-p_T^{\\text{exp}})}{C} + \\frac{p_0(1-p_0)}{C} $$\nThe expected change under the alternative is $\\mu_{\\Delta} = E[\\bar{\\hat{\\Delta}}|H_1] = p_T^{\\text{exp}} - p_0$.\n\nFor a one-sided test at significance level $\\alpha$, we reject $H_0$ if $Z > z_{\\alpha}$, where $z_{\\alpha}$ is the upper $\\alpha$-quantile of the standard normal distribution. This is equivalent to rejecting if $\\bar{\\hat{\\Delta}} > z_{\\alpha}\\sqrt{\\sigma_0^2/R}$.\n\nStatistical power, $1-\\beta$, is the probability of rejecting $H_0$ given $H_1$ is true:\n$$ 1-\\beta = P\\left(\\bar{\\hat{\\Delta}} > z_{\\alpha}\\sqrt{\\frac{\\sigma_0^2}{R}} \\;\\middle|\\; H_1\\right) $$\nUnder $H_1$, $\\bar{\\hat{\\Delta}} \\sim N(\\mu_{\\Delta}, \\sigma_1^2/R)$. We standardize the inequality:\n$$ 1-\\beta = P\\left( \\frac{\\bar{\\hat{\\Delta}} - \\mu_{\\Delta}}{\\sqrt{\\sigma_1^2/R}} > \\frac{z_{\\alpha}\\sqrt{\\sigma_0^2/R} - \\mu_{\\Delta}}{\\sqrt{\\sigma_1^2/R}} \\right) $$\nThe left side is a standard normal variable. For the probability to be $1-\\beta$, the threshold on the right must be $-z_{\\beta}$, where $z_{\\beta}$ is the upper $\\beta$-quantile.\n$$ -z_{\\beta} = \\frac{z_{\\alpha}\\sqrt{\\sigma_0^2} - \\mu_{\\Delta}\\sqrt{R}}{\\sqrt{\\sigma_1^2}} $$\nSolving for $\\sqrt{R}$:\n$$ \\mu_{\\Delta}\\sqrt{R} = z_{\\alpha}\\sqrt{\\sigma_0^2} + z_{\\beta}\\sqrt{\\sigma_1^2} $$\n$$ \\sqrt{R} = \\frac{z_{\\alpha}\\sqrt{\\sigma_0^2} + z_{\\beta}\\sqrt{\\sigma_1^2}}{\\mu_{\\Delta}} $$\nThis leads to the analytical expression for the required number of replicates:\n$$ R = \\left( \\frac{z_{\\alpha}\\sqrt{\\sigma_0^2} + z_{\\beta}\\sqrt{\\sigma_1^2}}{\\mu_{\\Delta}} \\right)^2 $$\n\nNow, we compute the numerical value for $R$ using the provided parameters:\n$s=0.02$, $p_0=0.10$, $T=30$, $N_e=1000$, $C=100$, $\\alpha=0.05$, $1-\\beta=0.80$.\nThe corresponding quantiles are $z_{\\alpha} = z_{0.05} \\approx 1.6449$ and $z_{\\beta} = z_{0.20} \\approx 0.8416$.\n\n1.  Calculate expected frequency and change under $H_1$:\n    $p_T^{\\text{exp}} = \\frac{1}{1 + \\left(\\frac{1-0.10}{0.10}\\right)\\exp(-0.02 \\times 30)} = \\frac{1}{1 + 9\\exp(-0.6)} \\approx \\frac{1}{1 + 9(0.54881)} \\approx 0.16837$.\n    $\\mu_{\\Delta} = p_T^{\\text{exp}} - p_0 \\approx 0.16837 - 0.10 = 0.06837$.\n\n2.  Calculate variance under $H_0$:\n    $\\frac{T}{2N_e} = \\frac{30}{2000} = 0.015$.\n    $\\sigma_0^2 = 0.1(0.9)\\left[1-\\exp(-0.015) + \\frac{2}{100}\\right] \\approx 0.09[1 - 0.98511 + 0.02] = 0.09[0.01489 + 0.02] = 0.09(0.03489) \\approx 0.0031401$.\n    $\\sqrt{\\sigma_0^2} \\approx 0.056037$.\n\n3.  Calculate variance under $H_1$:\n    Drift component: $0.1(0.9)(1-\\exp(-0.015)) \\approx 0.0013401$.\n    Sequencing component at time $0$: $\\frac{0.1(0.9)}{100} = 0.0009$.\n    Sequencing component at time $T$: $\\frac{p_T^{\\text{exp}}(1-p_T^{\\text{exp}})}{C} \\approx \\frac{0.16837(1-0.16837)}{100} \\approx \\frac{0.14002}{100} = 0.0014002$.\n    $\\sigma_1^2 \\approx 0.0013401 + 0.0014002 + 0.0009 = 0.0036403$.\n    $\\sqrt{\\sigma_1^2} \\approx 0.060335$.\n\n4.  Calculate $R$:\n    $R = \\left( \\frac{1.6449 \\times 0.056037 + 0.8416 \\times 0.060335}{0.06837} \\right)^2$\n    $R \\approx \\left( \\frac{0.092174 + 0.050786}{0.06837} \\right)^2 = \\left( \\frac{0.14296}{0.06837} \\right)^2 \\approx (2.0910)^2 \\approx 4.372$.\n\nSince the number of replicates must be an integer, we take the ceiling of this value to ensure the power requirement is met.\n$R = \\lceil 4.372 \\rceil = 5$.\nThe minimal integer number of replicates required is $5$.",
            "answer": "$$\n\\boxed{5}\n$$"
        },
        {
            "introduction": "After collecting sequencing data, our first task is to translate raw reads into accurate allele frequency estimates. However, technical artifacts such as reference mapping bias can systematically skew these estimates, as reads carrying the alternate allele may map less efficiently than those with the reference allele. This exercise demonstrates how to construct a maximum likelihood framework to correct for such allele-specific detection biases, a critical data processing step to ensure the validity of any downstream evolutionary inferences .",
            "id": "2711877",
            "problem": "You are analyzing allele frequency estimates from pooled sequencing (pool-seq) in an evolve-and-resequence experiment. Due to reference-mapping bias and base-calling errors, the probability that a true reference or alternate chromosome produces a correctly mapped and called read can differ between alleles. Your goal is to implement a principled correction for this bias grounded in population genetic sampling and sequencing error models, and to compute the corrected maximum likelihood estimate of the true alternate allele frequency for a set of specified test cases.\n\nStart from the following foundational base:\n- Sequencing reads are sampled independently and, conditional on being from a true reference or alternate chromosome, have allele-specific detection probabilities. Let $p_{\\mathrm{ref}} \\in (0,1]$ and $p_{\\mathrm{alt}} \\in (0,1]$ denote the probabilities that a true reference or alternate chromosome, respectively, yields a mapped read that is correctly called as its true allele.\n- Given a true alternate allele frequency $f \\in [0,1]$, the probability that a mapped read supports the alternate allele is\n$$\nq(f) \\;=\\; \\frac{f \\, p_{\\mathrm{alt}}}{f \\, p_{\\mathrm{alt}} + (1-f)\\, p_{\\mathrm{ref}}} \\, .\n$$\n- Conditional on $q(f)$ and a total mapped read depth $D \\in \\mathbb{N}$ at a site, the observed number of alternate-supporting reads $k \\in \\{0,1,\\ldots,D\\}$ follows a Binomial distribution with parameter $q(f)$.\n- In test cases where only recalibrated Phred base qualities are provided, convert a recalibrated Phred quality $Q$ to an error probability $e(Q)$ using $e(Q) = 10^{-Q/10}$, and then set the per-allele detection probability to $p = 1 - e(Q)$ for the corresponding allele.\n\nFor each test case, you are given:\n- Either direct synthetic-mapping-based allele-specific detection probabilities $(p_{\\mathrm{ref}}, p_{\\mathrm{alt}})$, or recalibrated base qualities $(Q_{\\mathrm{ref}}, Q_{\\mathrm{alt}})$ from which you must compute $(p_{\\mathrm{ref}}, p_{\\mathrm{alt}})$.\n- The total mapped read depth $D$ and the number of alternate-supporting reads $k$.\n\nYour task:\n- Using only the foundational base above, derive and implement the maximum likelihood estimate $\\hat{f}$ of the true alternate allele frequency $f$ given $(D,k)$ and $(p_{\\mathrm{ref}}, p_{\\mathrm{alt}})$. In tests with only $(Q_{\\mathrm{ref}}, Q_{\\mathrm{alt}})$, first compute $(p_{\\mathrm{ref}}, p_{\\mathrm{alt}})$ as specified, then estimate $\\hat{f}$.\n- Numerical stability requirements: handle boundary observations $k=0$ and $k=D$ in a manner consistent with the limiting behavior of the likelihood.\n- Report each $\\hat{f}$ rounded to $6$ decimal places as a standard decimal (not a fraction).\n\nTest suite (each item is a tuple specifying a method and parameters):\n- Synthetic mapping (SM) cases, with $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}})$:\n  1. SM: $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,40,0.95,0.85)$\n  2. SM: $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,40,0.90,0.90)$\n  3. SM: $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,40,0.95,0.50)$\n  4. SM: $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,40,0.80,0.95)$\n  5. SM (boundary): $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,0,0.90,0.80)$\n  6. SM (boundary): $(D,k,p_{\\mathrm{ref}},p_{\\mathrm{alt}}) = (100,100,0.90,0.80)$\n- Base-quality recalibration (BQSR) cases, with $(D,k,Q_{\\mathrm{ref}},Q_{\\mathrm{alt}})$ and $p_{\\mathrm{ref}}=1-10^{-Q_{\\mathrm{ref}}/10}$, $p_{\\mathrm{alt}}=1-10^{-Q_{\\mathrm{alt}}/10}$:\n  7. BQSR: $(D,k,Q_{\\mathrm{ref}},Q_{\\mathrm{alt}}) = (200,80,30,28)$\n  8. BQSR: $(D,k,Q_{\\mathrm{ref}},Q_{\\mathrm{alt}}) = (200,80,35,20)$\n  9. BQSR: $(D,k,Q_{\\mathrm{ref}},Q_{\\mathrm{alt}}) = (10,1,40,10)$\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each result rounded to $6$ decimal places, in the same order as the test suite, for example: \"[0.123456,0.234567,0.345678]\".",
            "solution": "The problem requires the derivation and implementation of a maximum likelihood estimate (MLE) for the true alternate allele frequency, $f$, in a pool-seq experiment, accounting for differential detection probabilities of reference and alternate alleles. The provided model is a standard framework for addressing such measurement biases.\n\nLet us begin by formalizing the likelihood function. The data consist of the number of reads supporting the alternate allele, $k$, out of a total of $D$ mapped reads. The problem posits that the sampling of reads follows a Binomial distribution, conditional on the total depth $D$ and the probability $q(f)$ that a randomly sampled mapped read supports the alternate allele. The likelihood function $L(f; D, k)$ is therefore given by:\n$$\nL(f; D, k) = P(k | D, f) = \\binom{D}{k} [q(f)]^k [1 - q(f)]^{D-k}\n$$\nThe probability $q(f)$ is a function of the true allele frequency $f \\in [0,1]$ and the allele-specific detection probabilities $p_{\\mathrm{ref}} \\in (0,1]$ and $p_{\\mathrm{alt}} \\in (0,1]$:\n$$\nq(f) = \\frac{f \\, p_{\\mathrm{alt}}}{f \\, p_{\\mathrm{alt}} + (1-f)\\, p_{\\mathrm{ref}}}\n$$\nTo find the MLE, $\\hat{f}$, we maximize $L(f; D, k)$ with respect to $f$. It is computationally and analytically more convenient to maximize the log-likelihood function, $\\ell(f; D, k) = \\ln L(f; D, k)$:\n$$\n\\ell(f) = \\ln\\binom{D}{k} + k \\ln[q(f)] + (D-k) \\ln[1-q(f)]\n$$\nThe term $\\ln\\binom{D}{k}$ is constant with respect to $f$ and can be disregarded during maximization. The MLE, $\\hat{f}$, is the value of $f$ in the interval $[0,1]$ that maximizes the function. We find this by setting the derivative of the log-likelihood with respect to $f$ to zero. Using the chain rule, $\\frac{d\\ell}{df} = \\frac{d\\ell}{dq} \\frac{dq}{df}$:\n$$\n\\frac{d\\ell}{df} = \\left( \\frac{k}{q(f)} - \\frac{D-k}{1-q(f)} \\right) \\frac{dq}{df} = 0\n$$\nThe derivative $\\frac{dq}{df}$ is calculated as:\n$$\n\\frac{dq}{df} = \\frac{d}{df} \\left( \\frac{f p_{\\mathrm{alt}}}{f(p_{\\mathrm{alt}} - p_{\\mathrm{ref}}) + p_{\\mathrm{ref}}} \\right) = \\frac{p_{\\mathrm{alt}} p_{\\mathrm{ref}}}{(f(p_{\\mathrm{alt}} - p_{\\mathrm{ref}}) + p_{\\mathrm{ref}})^2}\n$$\nGiven that $p_{\\mathrm{ref}} \\in (0,1]$ and $p_{\\mathrm{alt}} \\in (0,1]$, the numerator $p_{\\mathrm{alt}} p_{\\mathrm{ref}}$ is strictly positive. The denominator is a squared term and is also strictly positive for $f \\in [0,1]$. Thus, $\\frac{dq}{df} > 0$, which signifies that $q(f)$ is a strictly monotonically increasing function of $f$. Consequently, the log-likelihood function is concave and has a unique maximum.\nFor the derivative $\\frac{d\\ell}{df}$ to be zero, the term in parentheses must be zero:\n$$\n\\frac{k}{q(f)} - \\frac{D-k}{1-q(f)} = 0 \\quad \\implies \\quad k(1 - q(f)) = (D-k)q(f)\n$$\nSolving for $q(f)$ yields:\n$$\nk = D \\cdot q(f) \\quad \\implies \\quad q(f) = \\frac{k}{D}\n$$\nThis demonstrates the invariance property of maximum likelihood estimators: the MLE of a function of a parameter is that function of the MLE of the parameter. Here, the MLE of $q(f)$ is the observed frequency of alternate reads, $\\hat{q} = k/D$.\n\nTo find $\\hat{f}$, we must now solve the equation $q(\\hat{f}) = \\hat{q}$ for $\\hat{f}$:\n$$\n\\frac{\\hat{f} \\, p_{\\mathrm{alt}}}{\\hat{f} \\, p_{\\mathrm{alt}} + (1-\\hat{f})\\, p_{\\mathrm{ref}}} = \\frac{k}{D}\n$$\nRearranging the terms to isolate $\\hat{f}$:\n$$\nD \\cdot \\hat{f} \\cdot p_{\\mathrm{alt}} = k \\cdot (\\hat{f} \\, p_{\\mathrm{alt}} + (1-\\hat{f})\\, p_{\\mathrm{ref}})\n$$\n$$\nD \\cdot \\hat{f} \\cdot p_{\\mathrm{alt}} = k \\cdot \\hat{f} \\cdot p_{\\mathrm{alt}} + k \\cdot p_{\\mathrm{ref}} - k \\cdot \\hat{f} \\cdot p_{\\mathrm{ref}}\n$$\n$$\n\\hat{f} (D \\cdot p_{\\mathrm{alt}} - k \\cdot p_{\\mathrm{alt}} + k \\cdot p_{\\mathrm{ref}}) = k \\cdot p_{\\mathrm{ref}}\n$$\n$$\n\\hat{f} (p_{\\mathrm{alt}}(D-k) + p_{\\mathrm{ref}}k) = k \\cdot p_{\\mathrm{ref}}\n$$\nThis yields the final expression for the maximum likelihood estimate of the true alternate allele frequency:\n$$\n\\hat{f} = \\frac{k \\, p_{\\mathrm{ref}}}{k \\, p_{\\mathrm{ref}} + (D-k) \\, p_{\\mathrm{alt}}}\n$$\nThis estimator is well-defined and constrained to the valid interval $[0,1]$. For the boundary cases:\n- If $k=0$, $\\hat{f} = \\frac{0 \\cdot p_{\\mathrm{ref}}}{0 + D \\cdot p_{\\mathrm{alt}}} = 0$.\n- If $k=D$, $\\hat{f} = \\frac{D \\cdot p_{\\mathrm{ref}}}{D \\cdot p_{\\mathrm{ref}} + 0 \\cdot p_{\\mathrm{alt}}} = 1$.\nThese results are logical: observing zero alternate reads implies a frequency of zero, and observing only alternate reads implies a frequency of one. If there is no detection bias, i.e., $p_{\\mathrm{ref}} = p_{\\mathrm{alt}} = p$, the formula correctly simplifies to the uncorrected estimate:\n$$\n\\hat{f} = \\frac{k \\, p}{k \\, p + (D-k) \\, p} = \\frac{k \\, p}{D \\, p} = \\frac{k}{D}\n$$\nFor test cases involving recalibrated Phred base qualities $(Q_{\\mathrm{ref}}, Q_{\\mathrm{alt}})$, the detection probabilities are first computed using the standard formula $p = 1 - e(Q)$, where $e(Q) = 10^{-Q/10}$ is the error probability:\n$$\np_{\\mathrm{ref}} = 1 - 10^{-Q_{\\mathrm{ref}}/10} \\quad \\text{and} \\quad p_{\\mathrm{alt}} = 1 - 10^{-Q_{\\mathrm{alt}}/10}\n$$\nThese computed probabilities are then used in the derived formula for $\\hat{f}$. The implementation will apply this derived expression to each test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the maximum likelihood estimate of the true alternate allele frequency\n    for a series of test cases, accounting for allele-specific detection bias.\n    \"\"\"\n\n    test_cases = [\n        # Synthetic mapping (SM) cases: (type, D, k, p_ref, p_alt)\n        ('SM', 100, 40, 0.95, 0.85),\n        ('SM', 100, 40, 0.90, 0.90),\n        ('SM', 100, 40, 0.95, 0.50),\n        ('SM', 100, 40, 0.80, 0.95),\n        ('SM', 100, 0, 0.90, 0.80),\n        ('SM', 100, 100, 0.90, 0.80),\n        # Base-quality recalibration (BQSR) cases: (type, D, k, Q_ref, Q_alt)\n        ('BQSR', 200, 80, 30, 28),\n        ('BQSR', 200, 80, 35, 20),\n        ('BQSR', 10, 1, 40, 10),\n    ]\n\n    results = []\n\n    def calculate_f_hat(D, k, p_ref, p_alt):\n        \"\"\"\n        Calculates the MLE of the alternate allele frequency f.\n        \n        The formula is derived from setting the derivative of the log-likelihood to zero.\n        f_hat = (k * p_ref) / (k * p_ref + (D - k) * p_alt)\n        \n        Args:\n            D (int): Total mapped read depth.\n            k (int): Number of alternate-supporting reads.\n            p_ref (float): Detection probability for the reference allele.\n            p_alt (float): Detection probability for the alternate allele.\n        \n        Returns:\n            float: The maximum likelihood estimate of f.\n        \"\"\"\n        # Numerically stable handling of boundary cases k=0 and k=D is inherent\n        # in the formula, but explicit checks can clarify the logic.\n        if k == 0:\n            return 0.0\n        if k == D:\n            return 1.0\n\n        numerator = k * p_ref\n        denominator = k * p_ref + (D - k) * p_alt\n        \n        # Denominator is guaranteed to be positive because p_ref, p_alt > 0\n        # and k, (D-k) are non-negative and not simultaneously zero.\n        return numerator / denominator\n\n    for case in test_cases:\n        case_type = case[0]\n        D, k = case[1], case[2]\n\n        if case_type == 'SM':\n            p_ref, p_alt = case[3], case[4]\n        elif case_type == 'BQSR':\n            Q_ref, Q_alt = case[3], case[4]\n            # Convert Phred quality scores to detection probabilities\n            p_ref = 1.0 - 10**(-Q_ref / 10.0)\n            p_alt = 1.0 - 10**(-Q_alt / 10.0)\n        else:\n            # This case should not be reached with the given test suite.\n            raise ValueError(f\"Unknown test case type: {case_type}\")\n\n        f_hat = calculate_f_hat(D, k, p_ref, p_alt)\n        results.append(f_hat)\n\n    # Format the final output string as a comma-separated list\n    # with each result rounded to 6 decimal places.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "The ultimate goal of an E&R experiment is to illuminate the dynamics of adaptation. With clean, time-series allele frequency data in hand, we can move beyond simply identifying selected loci to testing specific hypotheses about the adaptive process. This practice introduces a powerful model selection approach using the Bayesian Information Criterion (BIC) to formally distinguish between a simple, single-lineage sweep and a more complex scenario involving competing beneficial lineages, providing quantitative evidence for the mode of adaptation .",
            "id": "2711890",
            "problem": "In an Evolve-and-resequence (E&R) experiment with an asexual population, two single-nucleotide variants (SNVs) at distinct positions, denoted lineage markers $A$ and $B$, tag two potentially competing beneficial lineages arising on different haplotypes. At sampling times $t_{i}$ for $i \\in \\{1,\\dots,T\\}$, short-read sequencing yields, for each lineage marker $\\ell \\in \\{A,B\\}$, a count $x_{i\\ell}$ of reads supporting the lineage-specific allele out of $n_{i\\ell}$ total reads at that locus and time. Assume that conditional on the true underlying population frequency $p_{i\\ell}$ of the lineage-specific allele at time $t_{i}$, the read counts satisfy $x_{i\\ell} \\sim \\mathrm{Binomial}(n_{i\\ell},p_{i\\ell})$ independently across $(i,\\ell)$ given $(p_{i\\ell})$.\n\nFor early to intermediate phases of an adaptive sweep under constant selection in a large population, assume a deterministic logistic trajectory for each lineage’s allele frequency so that the log-odds evolves approximately linearly with time: $\\mathrm{logit}(p_{i\\ell}) = \\alpha_{\\ell} + s_{\\ell} t_{i}$, where $\\alpha_{\\ell} \\in \\mathbb{R}$ is a lineage-specific intercept and $s_{\\ell} \\in \\mathbb{R}$ is an effective selection coefficient on the log-odds scale.\n\nConsider the following nested models:\n- Model $\\mathcal{M}_{1}$ (single-sweep): lineage $A$ is beneficial with free parameters $(\\alpha_{A}, s_{A})$, and lineage $B$ is non-increasing on the log-odds scale with $s_{B} = 0$ and free intercept $\\alpha_{B}$. Thus $\\mathcal{M}_{1}$ has $k_{1} = 3$ free parameters.\n- Model $\\mathcal{M}_{2}$ (multi-sweep): both lineages are potentially beneficial with free parameters $(\\alpha_{A}, s_{A}, \\alpha_{B}, s_{B})$. Thus $\\mathcal{M}_{2}$ has $k_{2} = 4$ free parameters.\n\nUsing the binomial sampling model and the logit-linear frequency model as stated, propose a principled method to detect the presence of two competing beneficial lineages by selecting between $\\mathcal{M}_{1}$ and $\\mathcal{M}_{2}$. Formalize this as an explicit model selection criterion using the Bayesian Information Criterion (BIC), taking the number of independent observations to be $I = 2T$ (one binomial observation for each lineage at each of $T$ time points). Let $\\widehat{p}_{i\\ell}^{(m)}$ denote the fitted probabilities under model $\\mathcal{M}_{m}$ at time $t_{i}$ for lineage $\\ell$, obtained by maximum likelihood. Derive a closed-form analytical expression, in terms of $(x_{i\\ell}, n_{i\\ell})$, $(\\widehat{p}_{i\\ell}^{(1)}, \\widehat{p}_{i\\ell}^{(2)})$, $T$, and standard functions, for the BIC difference\n$\\Delta \\mathrm{BIC} \\equiv \\mathrm{BIC}(\\mathcal{M}_{2}) - \\mathrm{BIC}(\\mathcal{M}_{1})$\nthat would be used to decide whether the data support a multi-sweep scenario over a single-sweep scenario. Your final answer must be a single, closed-form expression. Do not report any intermediate values. No numerical approximation or rounding is required. Express logarithms using the natural logarithm.",
            "solution": "The problem as stated is scientifically sound, well-posed, and objective. It presents a standard model selection task in statistical genomics. I will proceed with the derivation.\n\nThe Bayesian Information Criterion (BIC) for a model $\\mathcal{M}$ is given by the formula:\n$$ \\mathrm{BIC}(\\mathcal{M}) = k \\ln(N) - 2 \\hat{\\mathcal{L}} $$\nwhere $k$ is the number of free parameters in the model, $N$ is the total number of independent observations, and $\\hat{\\mathcal{L}}$ is the maximized value of the log-likelihood function for the model.\n\nThe problem defines two nested models, $\\mathcal{M}_{1}$ and $\\mathcal{M}_{2}$.\nFor model $\\mathcal{M}_{1}$ (single-sweep), the number of free parameters is $k_{1} = 3$, corresponding to $(\\alpha_{A}, s_{A}, \\alpha_{B})$ with the constraint $s_{B} = 0$.\nFor model $\\mathcal{M}_{2}$ (multi-sweep), the number of free parameters is $k_{2} = 4$, corresponding to $(\\alpha_{A}, s_{A}, \\alpha_{B}, s_{B})$.\nThe total number of independent observations is given as $N = I = 2T$, since there is one binomial observation for each of the $2$ lineages at each of the $T$ time points.\n\nUsing these definitions, the BIC for each model is:\n$$ \\mathrm{BIC}(\\mathcal{M}_{1}) = k_{1} \\ln(I) - 2 \\hat{\\mathcal{L}}_{1} = 3 \\ln(2T) - 2 \\hat{\\mathcal{L}}_{1} $$\n$$ \\mathrm{BIC}(\\mathcal{M}_{2}) = k_{2} \\ln(I) - 2 \\hat{\\mathcal{L}}_{2} = 4 \\ln(2T) - 2 \\hat{\\mathcal{L}}_{2} $$\nwhere $\\hat{\\mathcal{L}}_{m}$ is the maximized log-likelihood under model $\\mathcal{M}_{m}$.\n\nThe problem asks for the difference $\\Delta \\mathrm{BIC} \\equiv \\mathrm{BIC}(\\mathcal{M}_{2}) - \\mathrm{BIC}(\\mathcal{M}_{1})$. We compute this as:\n$$ \\Delta \\mathrm{BIC} = (4 \\ln(2T) - 2 \\hat{\\mathcal{L}}_{2}) - (3 \\ln(2T) - 2 \\hat{\\mathcal{L}}_{1}) $$\n$$ \\Delta \\mathrm{BIC} = (4 - 3) \\ln(2T) - 2 (\\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1}) $$\n$$ \\Delta \\mathrm{BIC} = \\ln(2T) - 2 (\\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1}) $$\n\nTo complete this expression, we must find the difference between the maximized log-likelihoods. The data consist of read counts $x_{i\\ell}$ from a total of $n_{i\\ell}$ reads for lineage $\\ell \\in \\{A, B\\}$ at time $t_{i}$ for $i \\in \\{1, \\dots, T\\}$. The sampling model is given as $x_{i\\ell} \\sim \\mathrm{Binomial}(n_{i\\ell}, p_{i\\ell})$. The probability mass function for a single observation is:\n$$ P(X_{i\\ell} = x_{i\\ell} | n_{i\\ell}, p_{i\\ell}) = \\binom{n_{i\\ell}}{x_{i\\ell}} p_{i\\ell}^{x_{i\\ell}} (1 - p_{i\\ell})^{n_{i\\ell} - x_{i\\ell}} $$\nThe log-likelihood for this single observation is:\n$$ \\ln P(X_{i\\ell} = x_{i\\ell}) = \\ln\\binom{n_{i\\ell}}{x_{i\\ell}} + x_{i\\ell} \\ln(p_{i\\ell}) + (n_{i\\ell} - x_{i\\ell}) \\ln(1 - p_{i\\ell}) $$\nSince the observations are independent across all $i$ and $\\ell$, the total log-likelihood is the sum over all $2T$ observations:\n$$ \\mathcal{L} = \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ \\ln\\binom{n_{i\\ell}}{x_{i\\ell}} + x_{i\\ell} \\ln(p_{i\\ell}) + (n_{i\\ell} - x_{i\\ell}) \\ln(1 - p_{i\\ell}) \\right] $$\nThe maximized log-likelihood for model $\\mathcal{M}_{m}$, denoted $\\hat{\\mathcal{L}}_{m}$, is found by substituting the fitted probabilities $\\widehat{p}_{i\\ell}^{(m)}$ obtained from maximum likelihood estimation:\n$$ \\hat{\\mathcal{L}}_{m} = \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ \\ln\\binom{n_{i\\ell}}{x_{i\\ell}} + x_{i\\ell} \\ln(\\widehat{p}_{i\\ell}^{(m)}) + (n_{i\\ell} - x_{i\\ell}) \\ln(1 - \\widehat{p}_{i\\ell}^{(m)}) \\right] $$\nNow we compute the difference $\\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1}$. The term $\\ln\\binom{n_{i\\ell}}{x_{i\\ell}}$ is a constant with respect to the model parameters and thus cancels out in the difference.\n$$ \\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1} = \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ \\left( x_{i\\ell} \\ln(\\widehat{p}_{i\\ell}^{(2)}) + (n_{i\\ell} - x_{i\\ell}) \\ln(1 - \\widehat{p}_{i\\ell}^{(2)}) \\right) - \\left( x_{i\\ell} \\ln(\\widehat{p}_{i\\ell}^{(1)}) + (n_{i\\ell} - x_{i\\ell}) \\ln(1 - \\widehat{p}_{i\\ell}^{(1)}) \\right) \\right] $$\nGrouping terms by $x_{i\\ell}$ and $(n_{i\\ell} - x_{i\\ell})$:\n$$ \\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1} = \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ x_{i\\ell} \\left(\\ln(\\widehat{p}_{i\\ell}^{(2)}) - \\ln(\\widehat{p}_{i\\ell}^{(1)})\\right) + (n_{i\\ell} - x_{i\\ell}) \\left(\\ln(1 - \\widehat{p}_{i\\ell}^{(2)}) - \\ln(1 - \\widehat{p}_{i\\ell}^{(1)})\\right) \\right] $$\nUsing the logarithmic identity $\\ln(a) - \\ln(b) = \\ln(a/b)$, we obtain:\n$$ \\hat{\\mathcal{L}}_{2} - \\hat{\\mathcal{L}}_{1} = \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ x_{i\\ell} \\ln\\left(\\frac{\\widehat{p}_{i\\ell}^{(2)}}{\\widehat{p}_{i\\ell}^{(1)}}\\right) + (n_{i\\ell} - x_{i\\ell}) \\ln\\left(\\frac{1 - \\widehat{p}_{i\\ell}^{(2)}}{1 - \\widehat{p}_{i\\ell}^{(1)}}\\right) \\right] $$\nFinally, we substitute this expression for the difference in log-likelihoods back into our equation for $\\Delta \\mathrm{BIC}$:\n$$ \\Delta \\mathrm{BIC} = \\ln(2T) - 2 \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ x_{i\\ell} \\ln\\left(\\frac{\\widehat{p}_{i\\ell}^{(2)}}{\\widehat{p}_{i\\ell}^{(1)}}\\right) + (n_{i\\ell} - x_{i\\ell}) \\ln\\left(\\frac{1 - \\widehat{p}_{i\\ell}^{(2)}}{1 - \\widehat{p}_{i\\ell}^{(1)}}\\right) \\right] $$\nThis is the required closed-form analytical expression for the BIC difference between the multi-sweep and single-sweep models. A negative value for $\\Delta \\mathrm{BIC}$ would constitute statistical evidence in favor of model $\\mathcal{M}_{2}$.",
            "answer": "$$ \\boxed{ \\ln(2T) - 2 \\sum_{i=1}^{T} \\sum_{\\ell \\in \\{A, B\\}} \\left[ x_{i\\ell} \\ln\\left(\\frac{\\widehat{p}_{i\\ell}^{(2)}}{\\widehat{p}_{i\\ell}^{(1)}}\\right) + (n_{i\\ell} - x_{i\\ell}) \\ln\\left(\\frac{1 - \\widehat{p}_{i\\ell}^{(2)}}{1 - \\widehat{p}_{i\\ell}^{(1)}}\\right) \\right] } $$"
        }
    ]
}