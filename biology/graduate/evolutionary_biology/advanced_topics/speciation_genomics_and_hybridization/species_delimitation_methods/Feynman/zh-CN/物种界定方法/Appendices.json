{
    "hands_on_practices": [
        {
            "introduction": "现代物种界定研究严重依赖于如 RAD-seq 等基因组数据，但由于物理连锁，这些数据集常常违反位点独立性的假设。本实践旨在探讨如何通过一种基于相关性衰减统计模型的数据稀疏化策略，来解决连锁不平衡（LD）问题。通过亲手实现这个过程，您将学到一种量化且实用的方法来控制数据中的非独立性，从而确保依赖于位点平均统计量的下游分析结果更为稳健。",
            "id": "2752737",
            "problem": "您将获得用于物种界定分析的限制性酶切位点关联DNA测序（RAD-seq）单核苷酸多态性（SNP）数据集，但SNP的物理排序未知，因此相邻SNP之间的连锁不平衡（LD）程度不确定。为了控制那些假定各位点独立的汇总统计量中方差的膨胀，您将实施一种稀疏化策略，该策略按索引顺序保留每第$t$个SNP（将SNP视为索引序列，不要求物理位置）。您的设计必须能控制有效独立位点数，并在一个最小且广泛使用的相关性模型下，明确量化稀疏化对方法差估计的影响。\n\n基本和建模假设：\n1. 每个位点被建模为一个随机变量，具有共同方差 $\\sigma^2$ 和弱平稳性（均值恒定且自协方差仅依赖于滞后）。\n2. 按索引顺序，相邻位点间滞后为$k$的相关性被建模为 $\\rho_k = r^k$，其中 $0 \\le r < 1$，即基于索引的一阶自回归（AR(1)）相关结构。当物理距离未知时（这在RAD-seq重叠群中很常见），该模型可作为一个保守的替代模型。\n3. 对于长度为 $n$、滞后相关为 $\\rho_k$ 的平稳弱相关序列，样本均值的方差满足 $\\mathrm{Var}(\\bar{X}) \\approx \\sigma^2 / n_{\\mathrm{eff}}$，其中有效样本量（有效独立位点数）为\n$$\nn_{\\mathrm{eff}} \\approx \\frac{n}{1 + 2 \\sum_{k=1}^{\\infty} \\rho_k}.\n$$\n该近似是相关观测值统计学中的一个标准结果，并广泛用于时间序列和基因组LD区块。\n4. 如果您以步长 $t \\in \\{1,2,\\dots\\}$ 进行稀疏化，保留第一个SNP，然后保留其后每第$t$个SNP，则保留的数量为\n$$\nn' = \\left\\lceil \\frac{M}{t} \\right\\rceil,\n$$\n其中 $M$ 是稀疏化前的SNP总数。在AR(1)索引相关模型下，保留位点间的滞后为$k$的相关性为 $\\rho_k' = (r^t)^k$，因此\n$$\n\\sum_{k=1}^{\\infty} \\rho_k' = \\frac{r^t}{1 - r^t} \\quad \\text{for } 0 \\le r < 1.\n$$\n因此，在保留的数据集中，有效独立位点数为\n$$\nn_{\\mathrm{eff}}(t) \\approx n' \\cdot \\frac{1 - r^t}{1 + r^t}.\n$$\n对于保留的数据集，相对于独立性的方差膨胀因子为\n$$\n\\mathrm{VIF}(t) = \\frac{n'}{n_{\\mathrm{eff}}(t)} = \\frac{1 + r^t}{1 - r^t}.\n$$\n\n您的编程任务：\n给定一个由元组 $(M, r, L_{\\mathrm{target}})$ 组成的测试套件，其中 $M$ 是SNP数量，$r$ 是相邻位点相关性参数（$0 \\le r < 1$），$L_{\\mathrm{target}}$ 是稀疏化后有效独立位点数的期望下限。请设计一种算法来选择稀疏化步长 $t$，在满足有效位点约束的同时最大化稀疏程度（即最大化$t$）：\n- 如果存在至少一个 $t \\in \\{1,2,\\dots,M\\}$ 使得 $n_{\\mathrm{eff}}(t) \\ge L_{\\mathrm{target}}$，则选择满足此条件的最大 $t$（即，仍能满足目标的的最粗略的稀疏化）。\n- 如果不存在这样的 $t$，则报告目标不可行，方法是将选定的步长设为 $-1$，并改为选择在 $t \\in \\{1,2,\\dots,M\\}$ 上能使 $n_{\\mathrm{eff}}(t)$ 最大化的 $t$；将此 $t$ 作为使用的步长，并报告其对应的 $n_{\\mathrm{eff}}$ 和 $\\mathrm{VIF}$。\n\n对于每个测试用例，您的程序必须输出一个包含四个条目的列表：\n- 选定的步长 $t_{\\mathrm{choice}}$（一个整数，如果目标不可行则为 $-1$），\n- 用于确定报告指标的步长 $t_{\\mathrm{used}}$（如果可行，则等于 $t_{\\mathrm{choice}}$；如果不可行，则为 $n_{\\mathrm{eff}}(t)$ 的最大值参数），\n- 有效位点数 $n_{\\mathrm{eff}}(t_{\\mathrm{used}})$，四舍五入到三位小数，\n- 方差膨胀因子 $\\mathrm{VIF}(t_{\\mathrm{used}})$，四舍五入到三位小数。\n\n科学现实性与基本原理：\n- 与使用所有位点并对LD进行恰当建模相比，稀疏化不能增加总信息量，但它可以为那些假定独立的分析降低方差膨胀因子，从而使在跨位点进行汇总的物种界定流程中，方差估计更保守、更稳健。\n- 对于 $r = 0$ 的情况，您必须将 $r^t$ 视为 $0$，此时 $n_{\\mathrm{eff}}(t) = n'$ 且 $\\mathrm{VIF}(t) = 1$。\n\n角度单位不适用。没有需要报告的物理单位。输出中的所有浮点数都必须四舍五入到三位小数。\n\n测试套件：\n按顺序使用以下五个用例作为输入：\n1. $(M, r, L_{\\mathrm{target}}) = (1000, 0.2, 300)$\n2. $(M, r, L_{\\mathrm{target}}) = (1000, 0.8, 100)$\n3. $(M, r, L_{\\mathrm{target}}) = (500, 0.0, 400)$\n4. $(M, r, L_{\\mathrm{target}}) = (75, 0.5, 20)$\n5. $(M, r, L_{\\mathrm{target}}) = (50, 0.95, 5)$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，列表中的每个元素是上述特定案例的列表。例如：\n\"[[t_choice_case1,t_used_case1,neff_case1,VIF_case1],[t_choice_case2,t_used_case2,neff_case2,VIF_case2],...]\"\n\n不需要用户输入；程序必须硬编码上述测试套件并按指定格式打印结果。",
            "solution": "我们被要求为物理连锁未知的限制性酶切位点关联DNA测序（RAD-seq）单核苷酸多态性（SNP）数据集设计一种稀疏化策略，方法是在一个纯数学模型中进行研究，并量化其对估计量方差的影响。我们从基本且经过广泛测试的定义开始。\n\n基本原理：\n1. 设 $\\{X_i\\}_{i=1}^n$ 为弱平稳序列，其 $\\mathbb{E}[X_i] = \\mu$，$\\mathrm{Var}(X_i) = \\sigma^2$，$滞后-k$ 相关性为 $\\rho_k = \\mathrm{Corr}(X_i, X_{i+k})$。对于样本均值 $\\bar{X}_n = n^{-1} \\sum_{i=1}^n X_i$，其方差在弱相关性条件下满足\n$$\n\\mathrm{Var}(\\bar{X}_n) = \\frac{\\sigma^2}{n} \\left(1 + 2 \\sum_{k=1}^{n-1} \\left(1 - \\frac{k}{n}\\right) \\rho_k \\right).\n$$\n对于大的 $n$ 和可和的相关性，这可以很好地近似为\n$$\n\\mathrm{Var}(\\bar{X}_n) \\approx \\frac{\\sigma^2}{n_{\\mathrm{eff}}}, \\quad n_{\\mathrm{eff}} \\approx \\frac{n}{1 + 2 \\sum_{k=1}^{\\infty} \\rho_k}.\n$$\n这个有效样本量捕获了信息上等价的独立观测数量，并且是时间序列和基因组学中处理存在相关性时的标准工具。\n\n2. 在一阶自回归（AR(1)）索引相关模型下，参数为 $r \\in [0,1)$，我们有 $\\rho_k = r^k$。于是\n$$\n\\sum_{k=1}^{\\infty} \\rho_k = \\sum_{k=1}^{\\infty} r^k = \\frac{r}{1 - r},\n$$\n因此\n$$\nn_{\\mathrm{eff}} \\approx \\frac{n}{1 + 2 \\cdot \\frac{r}{1 - r}} = n \\cdot \\frac{1 - r}{1 + r}.\n$$\n\n稀疏化及其效果：\n我们以步长 $t \\in \\{1,2,\\dots\\}$ 进行稀疏化，保留第一个位点及其后每第 $t$ 个位点。这样得到的保留数量为\n$$\nn' = \\left\\lceil \\frac{M}{t} \\right\\rceil,\n$$\n其中 $M$ 是稀疏化前的总位点数。由于保留的子序列是在索引顺序上以滞后 $t$ 采样的，其滞后为 $k$ 的相关性变为\n$$\n\\rho_k' = \\mathrm{Corr}(X_i, X_{i+kt}) = r^{kt} = (r^t)^k,\n$$\n这又是一个参数为 $r^t$ 的AR(1)模型。因此，\n$$\n\\sum_{k=1}^{\\infty} \\rho_k' = \\frac{r^t}{1 - r^t}, \\quad n_{\\mathrm{eff}}(t) \\approx n' \\cdot \\frac{1 - r^t}{1 + r^t}.\n$$\n保留集相对于独立性（即相对于方差 $\\sigma^2/n'$）的方差膨胀因子（VIF）为\n$$\n\\mathrm{VIF}(t) = \\frac{n'}{n_{\\mathrm{eff}}(t)} = \\frac{1 + r^t}{1 - r^t}.\n$$\n当 $r = 0$ 时，对所有 $t$ 都有 $r^t = 0$，得到 $n_{\\mathrm{eff}}(t) = n'$ 和 $\\mathrm{VIF}(t) = 1$，这与独立位点的情况相符。\n\n优化准则：\n我们被要求通过稀疏化来控制有效位点数。给定一个目标 $L_{\\mathrm{target}}$，约束条件是\n$$\nn_{\\mathrm{eff}}(t) = \\left\\lceil \\frac{M}{t} \\right\\rceil \\cdot \\frac{1 - r^t}{1 + r^t} \\ge L_{\\mathrm{target}}.\n$$\n如果可行，我们要在该约束下最大化 $t$，即\n$$\nt_{\\mathrm{choice}} = \\max \\left\\{ t \\in \\{1,2,\\dots,M\\} : \\left\\lceil \\frac{M}{t} \\right\\rceil \\cdot \\frac{1 - r^t}{1 + r^t} \\ge L_{\\mathrm{target}} \\right\\}.\n$$\n如果可行集为空，我们必须通过输出 $t_{\\mathrm{choice}} = -1$ 来声明不可行，并改为选择\n$$\nt_{\\mathrm{used}} \\in \\arg\\max_{t \\in \\{1,2,\\dots,M\\}} \\left( \\left\\lceil \\frac{M}{t} \\right\\rceil \\cdot \\frac{1 - r^t}{1 + r^t} \\right).\n$$\n然后，报告的有效数量和VIF是在 $t_{\\mathrm{used}}$ 处计算的。\n\n算法步骤：\n1. 对于每个测试用例 $(M, r, L_{\\mathrm{target}})$，将 $t$ 从 $1$ 迭代到 $M$：\n   - 使用整数算术计算 $n' = \\left\\lceil \\frac{M}{t} \\right\\rceil$ 为 $n' = \\left\\lfloor \\frac{M + t - 1}{t} \\right\\rfloor$。\n   - 计算 $r^t$；如果 $r = 0$，则直接将 $r^t$ 视为 $0$。\n   - 计算因子 $f(t) = \\frac{1 - r^t}{1 + r^t}$ 和 $n_{\\mathrm{eff}}(t) = n' \\cdot f(t)$。\n   - 跟踪满足 $n_{\\mathrm{eff}}(t) \\ge L_{\\mathrm{target}}$ 的可行 $t$ 的集合；如果非空，则取其最大值作为 $t_{\\mathrm{choice}}$。\n   - 跟踪能使 $n_{\\mathrm{eff}}(t)$ 最大化的 $t$，以便在不可行的情况下提供 $t_{\\mathrm{used}}$。\n2. 如果可行集非空，则设置 $t_{\\mathrm{used}} = t_{\\mathrm{choice}}$ 并计算 $\\mathrm{VIF}(t_{\\mathrm{used}}) = \\frac{1 + r^{t_{\\mathrm{used}}}}{1 - r^{t_{\\mathrm{used}}}}$；否则，设置 $t_{\\mathrm{choice}} = -1$ 并使用最大值参数 $t_{\\mathrm{used}}$ 及相应的 $n_{\\mathrm{eff}}$ 和 $\\mathrm{VIF}$。\n3. 将报告的 $n_{\\mathrm{eff}}(t_{\\mathrm{used}})$ 和 $\\mathrm{VIF}(t_{\\mathrm{used}})$ 四舍五入到三位小数。\n\n科学依据：\n- 用于索引相关的AR(1)模型提供了LD随索引滞后而保守衰减的模式，这对于RAD-seq中未知排序的情况是合理的；虽然它是一个近似，但它捕捉到了以步长 $t$ 进行稀疏化能将短程相关性降低到 $r^t$，从而改善了保留位点的独立性近似。\n- 有效独立位点数 $n_{\\mathrm{eff}}(t)$ 通过 $\\mathrm{Var}(\\bar{X}) \\approx \\sigma^2 / n_{\\mathrm{eff}}(t)$ 直接控制了物种界定方法中常用的位点平均汇总统计量（例如，基于位点频率的统计量、溯祖汇总统计量）的方差。\n- 方差膨胀因子 $\\mathrm{VIF}(t)$ 量化了保留位点间的残余相关性；稀疏化会使 $\\mathrm{VIF}(t)$ 随 $t$ 单调递减，因为 $r^t$ 随 $t$ 递减，这确保了在独立性假设下能得到更可靠的方差估计。\n\n应用于指定的测试套件：\n- 用例 (1000, 0.2, 300)：当 $t = 3$ 时，$n' = \\lceil 1000/3 \\rceil = 334$，$r^t = 0.2^3 = 0.008$，$f(3) = \\frac{1 - 0.008}{1 + 0.008} \\approx 0.984127$，得到 $n_{\\mathrm{eff}}(3) \\approx 328.26 \\ge 300$，而 $t = 4$ 时得到 $n_{\\mathrm{eff}}(4) \\approx 249.2 < 300$，所以 $t_{\\mathrm{choice}} = 3$ 且 $\\mathrm{VIF}(3) \\approx 1.016$。\n- 用例 (1000, 0.8, 100)：使 $n_{\\mathrm{eff}}(t) \\ge 100$ 的最大 $t$ 是 $5$，此时 $n' = 200$，$r^5 = 0.32768$，$f(5) \\approx 0.506521$，$n_{\\mathrm{eff}}(5) \\approx 101.304$，且 $\\mathrm{VIF}(5) \\approx 1.975$。\n- 用例 (500, 0.0, 400)：各位点独立，因此 $n_{\\mathrm{eff}}(t) = n'$。使 $n' \\ge 400$ 的最大 $t$ 是 $1$（因为 $t=2$ 时 $n'=250$），因此 $t_{\\mathrm{choice}} = 1$，$n_{\\mathrm{eff}} = 500$，$\\mathrm{VIF} = 1$。\n- 用例 (75, 0.5, 20)：$t = 2$ 时得到 $n' = 38$，$r^2 = 0.25$，$f(2) = 0.6$，所以 $n_{\\mathrm{eff}}(2) = 22.8 \\ge 20$；$t = 3$ 时得到 $n_{\\mathrm{eff}}(3) \\approx 19.444 < 20$，因此 $t_{\\mathrm{choice}} = 2$ 且 $\\mathrm{VIF}(2) = 1.666\\ldots$。\n- 用例 (50, 0.95, 5)：目标不可行，因为对于 $t \\in \\{1,\\dots,50\\}$，$n_{\\mathrm{eff}}(t)$ 永远达不到 $5$。因此，我们设置 $t_{\\mathrm{choice}} = -1$ 并选择能使 $n_{\\mathrm{eff}}(t)$ 最大化的 $t_{\\mathrm{used}}$。直接搜索表明，最大值在 $t = 24$ 附近，此时 $n' = \\lceil 50/24 \\rceil = 3$，$r^{24} \\approx 0.29199$，$f(24) \\approx 0.5480$，得到 $n_{\\mathrm{eff}}(24) \\approx 1.644$ 且 $\\mathrm{VIF}(24) \\approx 1.825$。\n\n程序将精确实现这些步骤，计算最优步长，并按照指定格式将各用例结果打印出来，保留三位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef effective_loci_and_vif(M: int, r: float, t: int):\n    \"\"\"\n    Compute n_eff(t) and VIF(t) for given M, r, and thinning stride t.\n    n' = ceil(M / t)\n    r_t = r**t\n    n_eff(t) = n' * (1 - r_t) / (1 + r_t)\n    VIF(t) = (1 + r_t) / (1 - r_t)\n    Special case: if r == 0.0, then r_t = 0.0, so n_eff = n' and VIF = 1.0\n    \"\"\"\n    n_retained = (M + t - 1) // t  # ceil division\n    if r <= 0.0:\n        r_t = 0.0\n    else:\n        r_t = r ** t\n    # Numerical safety: if r_t is extremely close to 1, cap within (0,1)\n    if r_t >= 1.0:\n        r_t = 1.0 - 1e-15\n    if r_t == 0.0:\n        n_eff = float(n_retained)\n        vif = 1.0\n    else:\n        factor = (1.0 - r_t) / (1.0 + r_t)\n        n_eff = n_retained * factor\n        vif = (1.0 + r_t) / (1.0 - r_t)\n    return n_eff, vif\n\ndef choose_thinning_stride(M: int, r: float, L_target: float):\n    \"\"\"\n    Choose the largest t in {1, ..., M} such that n_eff(t) >= L_target.\n    If no such t exists, return t_choice = -1 and t_used = argmax n_eff(t).\n    Returns (t_choice, t_used, n_eff_used, vif_used).\n    \"\"\"\n    feasible_t = None  # largest feasible t\n    best_t = 1\n    best_neff = -1.0\n\n    for t in range(1, M + 1):\n        n_eff, vif = effective_loci_and_vif(M, r, t)\n        # Track best n_eff across all t\n        if n_eff > best_neff + 1e-12:\n            best_neff = n_eff\n            best_t = t\n        # Check feasibility\n        if n_eff >= L_target - 1e-12:  # allow small tolerance\n            feasible_t = t  # since we iterate increasing t, this will end up as largest feasible\n\n    if feasible_t is not None:\n        # Use the largest feasible t\n        t_choice = feasible_t\n        t_used = feasible_t\n        n_eff_used, vif_used = effective_loci_and_vif(M, r, t_used)\n    else:\n        # Infeasible: use the t that maximizes n_eff\n        t_choice = -1\n        t_used = best_t\n        n_eff_used, vif_used = effective_loci_and_vif(M, r, t_used)\n\n    # Round as specified: three decimals\n    n_eff_used_rounded = round(n_eff_used + 1e-12, 3)\n    vif_used_rounded = round(vif_used + 1e-12, 3)\n    return [t_choice, t_used, n_eff_used_rounded, vif_used_rounded]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (M, r, L_target)\n    test_cases = [\n        (1000, 0.2, 300.0),\n        (1000, 0.8, 100.0),\n        (500, 0.0, 400.0),\n        (75, 0.5, 20.0),\n        (50, 0.95, 5.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        M, r, L_target = case\n        result = choose_thinning_stride(M, r, L_target)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Print as a single-line string representation of the list of lists.\n    # Ensure no extra spaces beyond commas to match the \"comma-separated list\" spirit.\n    def list_to_string(lst):\n        # Convert nested list of primitives to string without spaces after commas\n        if isinstance(lst, list):\n            return \"[\" + \",\".join(list_to_string(x) for x in lst) + \"]\"\n        else:\n            return str(lst)\n\n    print(list_to_string(results))\n\nsolve()\n```"
        },
        {
            "introduction": "在遗传数据被广泛应用之前，物种界定通常依赖于使用统计方法分析形态差异。本练习要求您从第一性原理出发，基于多变量正态（MVN）模型，实现经典的统计分类技术——线性判别分析（LDA）。这项编码挑战将加深您对分类方法统计基础的理解，并通过交叉验证来学习模型评估，以及量化物种分配中的不确定性。",
            "id": "2752812",
            "problem": "您有一项基于形态测量的物种界定任务。请按如下方式，用纯数学和统计学术语来描述该问题。假设每个假定物种对应一个类别标签，并且形态测量被表示为 $\\mathbb{R}^d$ 中的向量。假设在给定类别 $k \\in \\{1,\\dots,K\\}$ 的条件下，观测值 $\\mathbf{x} \\in \\mathbb{R}^d$ 服从一个多元正态分布 (MVN)，其均值为特定于类别的 $\\boldsymbol{\\mu}_k \\in \\mathbb{R}^d$，协方差矩阵为类别无关的正定矩阵 $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}$。假设类别先验概率为 $\\pi_k$，满足 $\\sum_{k=1}^K \\pi_k = 1$ 且 $\\pi_k \\in (0,1)$。\n\n基本假设和定义：\n- 生成模型下后验概率的 Bayes 法则：后验概率 $p(y=k \\mid \\mathbf{x})$ 与先验概率和类别条件密度的乘积成正比，即 $p(y=k \\mid \\mathbf{x}) \\propto \\pi_k f_k(\\mathbf{x})$，其中 $f_k$ 是类别 $k$ 的 MVN 密度。\n- 最大后验概率分类将 $\\mathbf{x}$ 分配给使 $p(y=k \\mid \\mathbf{x})$ 最大化的类别。\n- 留一法交叉验证 (LOOCV) 通过对每个观测值 $i$ 使用除 $i$ 之外的所有观测值来拟合模型参数，然后用拟合好的模型预测其类别，从而估计泛化性能。\n\n您的程序必须在 MVN-共享协方差假设下实现线性判别分析 (LDA)，并使用 LOOCV 来估计样本外性能和量化分类不确定性。对于每个留出的观测值 $i$，使用训练集（除 $i$ 之外的所有观测值）来估计：\n- 类别均值 $\\widehat{\\boldsymbol{\\mu}}_k$，作为类别 $k$ 内的经验均值。\n- 一个合并的类内协方差 $\\widehat{\\boldsymbol{\\Sigma}}$，其计算方法为类内散布之和除以训练自由度，并进行正则化处理为 $\\widehat{\\boldsymbol{\\Sigma}} + \\lambda \\mathbf{I}_d$（其中 $\\lambda = 10^{-6}$）以确保数值稳定性。\n- 类别先验 $\\widehat{\\pi}_k$，作为训练集中的经验频率。\n\n然后，对于每个带有测量值 $\\mathbf{x}_i$ 的留出观测值 $i$，计算由 MVN 密度和经验先验导出的后验类别概率 $p(y=k \\mid \\mathbf{x}_i)$，并通过最大后验概率来预测类别。收集：\n- 错分指示符（预测类别是否与真实类别匹配）。\n- 该观测值被分配类别的后验概率。\n- 后验熵 $H(\\mathbf{x}_i) = -\\sum_{k=1}^K p(y=k \\mid \\mathbf{x}_i)\\log p(y=k \\mid \\mathbf{x}_i)$，以自然单位（纳特）计量。\n\n对所有观测值，计算：\n- 总体错分率 $\\hat{p}$，作为错分指示符的平均值。\n- 一个置信水平为 $0.95$ 的 Wilson 得分置信区间，用于对应错分概率的二项分布参数，该区间基于 $n$ 次独立的伯努利试验和观测到的比例 $\\hat{p}$。\n- 在所有 LOOCV 折上平均的、被分配类别的平均后验概率。\n- 在所有 LOOCV 折上平均的、以纳特为单位的平均后验熵。\n\n测试套件。您的程序必须使用以下三个合成测试用例来实现上述过程，每个用例都由类别数 $K$、维度 $d$、公共类内协方差矩阵 $\\boldsymbol{\\Sigma}$、类别均值 $\\{\\boldsymbol{\\mu}_k\\}_{k=1}^K$、类别样本量 $\\{n_k\\}_{k=1}^K$ 以及一个固定的伪随机种子定义。对于每个用例，从 $\\mathcal{N}(\\boldsymbol{\\mu}_k,\\boldsymbol{\\Sigma})$ 中为类别 $k$ 独立抽取 $n_k$ 个样本，然后按照规定执行 LOOCV LDA。\n\n- 案例 A（理想路径，类别区分良好）：$K=2$，$d=2$，$\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1 & 0.3 \\\\ 0.3 & 1 \\end{bmatrix}$，$\\boldsymbol{\\mu}_1 = [0,0]$，$\\boldsymbol{\\mu}_2 = [3,3]$，$n_1 = 30$，$n_2 = 30$，种子 $= 7$。\n- 案例 B（边界条件，类别重叠）：$K=2$，$d=2$，$\\boldsymbol{\\Sigma} = \\begin{bmatrix} 1 & 0.7 \\\\ 0.7 & 1 \\end{bmatrix}$，$\\boldsymbol{\\mu}_1 = [0,0]$，$\\boldsymbol{\\mu}_2 = [0.8,0.8]$，$n_1 = 40$，$n_2 = 40$，种子 $= 13$。\n- 案例 C（边缘用例，三类别，小样本，中等分离度）：$K=3$，$d=3$，$\\boldsymbol{\\Sigma} = 0.5 \\mathbf{I}_3$，$\\boldsymbol{\\mu}_1 = [0,0,0]$，$\\boldsymbol{\\mu}_2 = [2.5,0,2.5]$，$\\boldsymbol{\\mu}_3 = [0,2.5,2.5]$，$n_1 = 8$，$n_2 = 7$，$n_3 = 9$，种子 $= 101$。\n\n输出规格。对于每个案例，返回一个包含五个浮点数值的列表：\n- 错分率 $\\hat{p}$。\n- $\\hat{p}$ 的 Wilson $0.95$ 置信区间的下界。\n- $\\hat{p}$ 的 Wilson $0.95$ 置信区间的上界。\n- 被分配类别的平均后验概率。\n- 以纳特为单位的平均后验熵。\n\n将每个值四舍五入到恰好 $4$ 位小数。您的程序应生成单行输出，其中包含一个列表的列表形式的结果，不含空格，格式完全如下：\n$[[a_1,a_2,a_3,a_4,a_5],[b_1,b_2,b_3,b_4,b_5],[c_1,c_2,c_3,c_4,c_5]]$，\n其中每个 $a_j$、$b_j$ 和 $c_j$ 分别是案例 A、B 和 C 的四舍五入后的值。\n\n此问题不涉及物理单位。所有角度均无关。置信水平必须表示为小数 $0.95$。",
            "solution": "该问题要求使用留一法交叉验证 (LOOCV) 实现并评估线性判别分析 (LDA)。整个过程必须在统计分类理论的框架内进行，其基础假设是：每个类别的数据都从一个多元正态分布 (MVN) 中抽取，该分布具有特定于类别的均值但共享一个公共的协方差矩阵。\n\n解决方案按以下算法步骤进行：\n\n1.  **数据生成**：对于三个测试用例中的每一个，我们根据提供的规格生成合成数据。对于每个类别 $k \\in \\{1, \\dots, K\\}$，我们使用由指定种子初始化的伪随机数生成器，从多元正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma})$ 中抽取 $n_k$ 个样本。这样就创建了一个包含 $N = \\sum_{k=1}^K n_k$ 个观测值的完整数据集，每个观测值都有一个已知的类别标签。\n\n2.  **留一法交叉验证 (LOOCV)**：为了估计 LDA 分类器的泛化性能，我们采用 LOOCV。这涉及进行 $N$ 次迭代。在每次迭代 $i = 1, \\dots, N$ 中，第 $i$ 个观测值 $(\\mathbf{x}_i, y_i)$ 被指定为测试集，其余的 $N-1$ 个观测值构成训练集。\n\n3.  **参数估计**：在每个 LOOCV 折中，从训练数据（大小为 $N_{train} = N-1$ 的集合）中估计生成模型的参数。\n    -   **先验 ($\\widehat{\\pi}_k$)**：每个类别 $k$ 的先验概率估计为其在训练集中的经验频率：$\\widehat{\\pi}_k = N_k^{train} / N_{train}$，其中 $N_k^{train}$ 是类别 $k$ 中的训练观测值数量。\n    -   **均值 ($\\widehat{\\boldsymbol{\\mu}}_k$)**：每个类别 $k$ 的均值向量通过属于该类别的所有训练观测值的样本均值来估计。\n    -   **合并协方差 ($\\widehat{\\boldsymbol{\\Sigma}}$)**：估计一个单一的、共享的协方差矩阵。首先，计算每个类别的类内散布矩阵：$S_k = \\sum_{\\mathbf{x}_j \\in \\text{class } k} (\\mathbf{x}_j - \\widehat{\\boldsymbol{\\mu}}_k)(\\mathbf{x}_j - \\widehat{\\boldsymbol{\\mu}}_k)^T$。将这些矩阵相加，形成总的类内散布矩阵 $S_W = \\sum_{k=1}^K S_k$。然后，合并协方差估计量为 $\\widehat{\\boldsymbol{\\Sigma}}_{\\text{pooled}} = S_W / (N_{train} - K)$。分母对应于自由度。按照规定，对此矩阵进行正则化，以确保其为正定且适于求逆：$\\widehat{\\boldsymbol{\\Sigma}} = \\widehat{\\boldsymbol{\\Sigma}}_{\\text{pooled}} + \\lambda \\mathbf{I}_d$，其中 $\\lambda = 10^{-6}$。\n\n4.  **对留出样本的预测和评估**：使用估计出的参数对留出的观测值 $\\mathbf{x}_i$ 进行分类。\n    -   **后验概率计算**：根据 Bayes 定理，观测值 $\\mathbf{x}_i$ 属于类别 $k$ 的后验概率为 $p(y=k \\mid \\mathbf{x}_i) \\propto \\widehat{\\pi}_k f_k(\\mathbf{x}_i)$，其中 $f_k$ 是参数为 $(\\widehat{\\boldsymbol{\\mu}}_k, \\widehat{\\boldsymbol{\\Sigma}})$ 的 MVN 密度。为确保数值稳定性，我们计算对数后验。对数似然 $\\log f_k(\\mathbf{x}_i)$ 从 MVN 概率密度函数获得。每个类别的未归一化对数后验为 $L_k = \\log \\widehat{\\pi}_k + \\log f_k(\\mathbf{x}_i)$。这些值通过 log-sum-exp 变换被归一化为概率：$p_k = \\exp(L_k) / \\sum_j \\exp(L_j)$。\n    -   **分类**：$\\mathbf{x}_i$ 的预测类别是具有最大后验概率的类别（MAP 规则）：$\\widehat{y}_i = \\arg\\max_k p(y=k \\mid \\mathbf{x}_i)$。\n    -   **指标收集**：对于每个折 $i$，我们记录：\n        a. 错分指示符：如果 $\\widehat{y}_i \\neq y_i$则为 $1$，否则为 $0$。\n        b. 被分配类别的后验概率：$\\max_k p(y=k \\mid \\mathbf{x}_i)$。\n        c. 后验香农熵：$H(\\mathbf{x}_i) = -\\sum_{k=1}^K p(y=k \\mid \\mathbf{x}_i) \\log p(y=k \\mid \\mathbf{x}_i)$，使用自然对数计算（以纳特为单位）。\n\n5.  **结果汇总**：在完成 LOOCV 的所有 $N$ 个折之后，将收集到的指标进行汇总，以生成该测试用例的最终汇总统计数据。\n    -   **错分率 ($\\hat{p}$)**：所有 $N$ 个折的错分指示符的简单平均值。\n    -   **Wilson 得分置信区间**：对于估计的错分率 $\\hat{p}$，我们计算真实二项比例的一个 $95\\%$ 置信区间。给定 $N$ 次试验和比率 $\\hat{p}$，该区间由以下公式给出：\n        $$ \\frac{1}{1+z^2/N} \\left( \\hat{p} + \\frac{z^2}{2N} \\pm z \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N} + \\frac{z^2}{4N^2}} \\right) $$\n        其中 $z \\approx 1.96$ 是来自标准正态分布的 $95\\%$ 置信水平的临界值。\n    -   **平均后验指标**：通过在所有 $N$ 个折上对被分配类别的后验概率和后验熵的各自值进行平均，来计算它们的平均值。\n\n最后，将每个测试用例得到的五个浮点数值四舍五入到四位小数，并格式化为指定的列表的列表结构。整个过程被封装在一个使用 `numpy` 和 `scipy` 库的 Python 程序中。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import multivariate_normal, norm\n\ndef perform_loocv_lda(case):\n    \"\"\"\n    Performs Linear Discriminant Analysis using Leave-One-Out Cross-Validation.\n\n    Args:\n        case (tuple): A tuple containing problem parameters:\n            K (int): Number of classes.\n            d (int): Dimensionality of data.\n            Sigma (np.ndarray): Common covariance matrix.\n            mus (list of np.ndarray): List of class mean vectors.\n            ns (list of int): List of sample sizes for each class.\n            seed (int): Seed for the pseudo-random number generator.\n\n    Returns:\n        list: A list of five floats containing the aggregated performance metrics.\n    \"\"\"\n    K, d, Sigma, mus, ns, seed = case\n    lambda_reg = 1e-6\n\n    # 1. Generate synthetic data\n    rng = np.random.default_rng(seed)\n    X_list = []\n    y_list = []\n    for k_idx in range(K):\n        data_k = rng.multivariate_normal(mus[k_idx], Sigma, size=ns[k_idx])\n        X_list.append(data_k)\n        y_list.append(np.full(ns[k_idx], k_idx))\n\n    X = np.vstack(X_list)\n    y = np.concatenate(y_list)\n    n_total = X.shape[0]\n\n    # Lists to store results from each LOOCV fold\n    misclass_indicators = []\n    posterior_probs_assigned = []\n    entropies = []\n\n    # 2. LOOCV loop\n    for i in range(n_total):\n        # Define training and test sets for this fold\n        X_test = X[i, :]\n        y_test = y[i]\n        X_train = np.delete(X, i, axis=0)\n        y_train = np.delete(y, i, axis=0)\n        n_train = X_train.shape[0]\n\n        # 3. Parameter estimation on the training set\n        classes, counts = np.unique(y_train, return_counts=True)\n        K_train = len(classes)\n\n        # Estimate class priors\n        pi_hats = counts / n_train\n        \n        # Estimate class means\n        mu_hats = np.array([np.mean(X_train[y_train == k], axis=0) for k in classes])\n\n        # Estimate pooled covariance matrix\n        S_W = np.zeros((d, d))\n        for k_idx, k in enumerate(classes):\n            X_k = X_train[y_train == k]\n            mu_k_hat = mu_hats[k_idx]\n            diff = X_k - mu_k_hat\n            S_W += diff.T @ diff\n        \n        df = n_train - K_train\n        Sigma_pooled = S_W / df\n        Sigma_hat = Sigma_pooled + lambda_reg * np.eye(d)\n\n        # 4. Predict on the left-out test point\n        log_posteriors = np.zeros(K_train)\n        for k_idx, k in enumerate(classes):\n            log_lk = multivariate_normal.logpdf(X_test, mean=mu_hats[k_idx], cov=Sigma_hat)\n            log_posteriors[k_idx] = np.log(pi_hats[k_idx]) + log_lk\n\n        # Normalize to get posterior probabilities using log-sum-exp trick\n        max_log = np.max(log_posteriors)\n        log_sum_exp = max_log + np.log(np.sum(np.exp(log_posteriors - max_log)))\n        post_probs = np.exp(log_posteriors - log_sum_exp)\n\n        # Collect metrics for this fold\n        pred_class_idx = np.argmax(post_probs)\n        pred_class = classes[pred_class_idx]\n        \n        misclass_indicators.append(1 if pred_class != y_test else 0)\n        posterior_probs_assigned.append(post_probs[pred_class_idx])\n\n        valid_probs = post_probs[post_probs > 0]\n        entropy = -np.sum(valid_probs * np.log(valid_probs))\n        entropies.append(entropy)\n\n    # 5. Aggregate results across all folds\n    p_hat = np.mean(misclass_indicators)\n    n = n_total\n    z = norm.ppf(1 - 0.05 / 2) # z for 0.95 CI\n\n    # Wilson score confidence interval\n    denominator = 1 + z**2 / n\n    center = (p_hat + z**2 / (2 * n)) / denominator\n    width = (z / denominator) * np.sqrt((p_hat * (1 - p_hat)) / n + z**2 / (4 * n**2))\n    wilson_lower = center - width\n    wilson_upper = center + width\n\n    mean_post_prob = np.mean(posterior_probs_assigned)\n    mean_entropy = np.mean(entropies)\n\n    return [p_hat, wilson_lower, wilson_upper, mean_post_prob, mean_entropy]\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 2, np.array([[1, 0.3], [0.3, 1]]), [np.array([0, 0]), np.array([3, 3])], [30, 30], 7),\n        (2, 2, np.array([[1, 0.7], [0.7, 1]]), [np.array([0, 0]), np.array([0.8, 0.8])], [40, 40], 13),\n        (3, 3, 0.5 * np.eye(3), [np.array([0, 0, 0]), np.array([2.5, 0, 2.5]), np.array([0, 2.5, 2.5])], [8, 7, 9], 101)\n    ]\n\n    results = []\n    for case in test_cases:\n        case_results = perform_loocv_lda(case)\n        rounded_results = [round(val, 4) for val in case_results]\n        results.append(rounded_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\".replace(\" \", \"\"))\n\nsolve()\n\n```"
        },
        {
            "introduction": "现代基于溯祖理论的物种界定方法能够形式化地检验相互竞争的假说（例如，将两个种群合并为一个物种，或将其拆分为两个物种）。这些分析的输出通常是每个模型的边际似然值。本练习聚焦于贝叶斯模型比较的最后关键一步：如何从模型似然值计算贝叶斯因子，以量化支持不同假说的证据强度。掌握这项直接而重要的计算，将使您能够准确解读复杂软件的输出结果，并就物种边界得出统计上可靠的结论。",
            "id": "2752783",
            "problem": "在用于物种界定的多物种溯祖框架中，针对一个焦点分支，我们考虑了两个相互竞争的模型：模型 $\\mathcal{M}_{A}$（合并两个候选谱系）和模型 $\\mathcal{M}_{B}$（将它们分裂）。通过使用垫脚石抽样的热力学积分方法，您获得了以下模型证据，其以边际似然的自然对数形式报告：$\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A}) = -17890.432$ 和 $\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) = -17882.932$，其中 $\\mathcal{D}$ 表示多位点序列数据集。假设在两个模型中使用了相同的先验和数据处理方法，因此这些值可以直接作为模型证据进行比较。\n\n使用边际似然和贝叶斯因子的基本定义，计算支持模型 $\\mathcal{M}_{B}$ 相对于 $\\mathcal{M}_{A}$ 的贝叶斯因子。然后，使用以下预先设定的标度（Kass–Raftery 风格，适用于直接贝叶斯因子 $\\mathrm{BF}$）来解释支持 $\\mathcal{M}_{B}$ 的证据强度：\n\n- $1 \\le \\mathrm{BF} < 3.2$：不值得一提，\n- $3.2 \\le \\mathrm{BF} < 10$：实质性的，\n- $10 \\le \\mathrm{BF} < 100$：强，\n- $\\mathrm{BF} \\ge 100$：决定性的。\n\n以纯数字形式报告贝叶斯因子，并四舍五入至四位有效数字。不要包含任何单位。您可以在推理过程中提供解释，但最终报告的答案必须仅为贝叶斯因子的值。",
            "solution": "在贝叶斯框架中，比较两个统计模型 $\\mathcal{M}_{A}$ 和 $\\mathcal{M}_{B}$ 的基本量是贝叶斯因子。贝叶斯因子，表示为 $\\mathrm{BF}_{B,A}$，量化了数据 $\\mathcal{D}$ 支持模型 $\\mathcal{M}_{B}$ 优于模型 $\\mathcal{M}_{A}$ 的证据。它被定义为它们边际似然的比率：\n$$\n\\mathrm{BF}_{B,A} = \\frac{p(\\mathcal{D} \\mid \\mathcal{M}_{B})}{p(\\mathcal{D} \\mid \\mathcal{M}_{A})}\n$$\n边际似然 $p(\\mathcal{D} \\mid \\mathcal{M})$ 表示在给定模型 $\\mathcal{M}$ 的情况下观测到数据 $\\mathcal{D}$ 的概率，该概率是在模型的整个参数空间上积分得到的。在实践中，这些值通常非常小，因此计算时使用它们的自然对数，正如题目中所提供的那样。\n\n已知的对数边际似然如下：\n$$\n\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A}) = -17890.432\n$$\n$$\n\\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) = -17882.932\n$$\n为了从这些对数值计算贝叶斯因子，我们利用了对数的性质，即一个比率的对数等于对数的差：\n$$\n\\ln(\\mathrm{BF}_{B,A}) = \\ln\\left(\\frac{p(\\mathcal{D} \\mid \\mathcal{M}_{B})}{p(\\mathcal{D} \\mid \\mathcal{M}_{A})}\\right) = \\ln p(\\mathcal{D} \\mid \\mathcal{M}_{B}) - \\ln p(\\mathcal{D} \\mid \\mathcal{M}_{A})\n$$\n这个量 $\\ln(\\mathrm{BF}_{B,A})$ 通常被称为对数贝叶斯因子。代入给定的值：\n$$\n\\ln(\\mathrm{BF}_{B,A}) = -17882.932 - (-17890.432) = -17882.932 + 17890.432 = 7.500\n$$\n为了获得贝叶斯因子 $\\mathrm{BF}_{B,A}$ 本身，我们必须对对数贝叶斯因子取指数：\n$$\n\\mathrm{BF}_{B,A} = \\exp(\\ln(\\mathrm{BF}_{B,A})) = \\exp(7.500)\n$$\n计算此值：\n$$\n\\mathrm{BF}_{B,A} \\approx 1808.0424\n$$\n问题要求将此值四舍五入至四位有效数字。前四位有效数字是 $1$、$8$、$0$ 和 $8$。随后的数字是 $0$，所以不进行进位。该值为 $1808$。\n\n最后一步是使用提供的标度解释这一结果。计算出的贝叶斯因子为 $\\mathrm{BF}_{B,A} = 1808$。由于 $1808 \\ge 100$，支持模型 $\\mathcal{M}_{B}$（分裂模型）优于模型 $\\mathcal{M}_{A}$（合并模型）的证据被归类为“决定性的”。这表明，两个候选谱系代表不同物种的假说获得了非常强的支持。",
            "answer": "$$\\boxed{1808}$$"
        }
    ]
}