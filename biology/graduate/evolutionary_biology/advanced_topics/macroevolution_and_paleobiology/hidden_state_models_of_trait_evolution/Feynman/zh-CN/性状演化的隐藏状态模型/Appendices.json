{
    "hands_on_practices": [
        {
            "introduction": "在构建和比较任何统计模型时，一个基本步骤是确定其复杂性。这通常通过计算模型中的“自由参数”数量来完成，这些参数是需要从数据中估计的。这个练习将引导你分析一个典型的隐藏状态模型的结构，并精确计算其参数数量，这是后续进行模型选择（例如使用 $AIC$）和假设检验的关键第一步。",
            "id": "2722636",
            "problem": "一个关于固定且经时间校准的系统发育树上离散性状演化的隐藏状态模型被表述为连续时间马尔可夫链 (CTMC)。观测到的性状有 $k$ 个离散状态，其演化取决于一个有 $H$ 个水平的未观测（隐藏）分类变量。因此，联合过程有 $kH$ 个复合状态，每个状态由一个有序对 $(i,h)$ 表示，其中 $i \\in \\{1,\\dots,k\\}$ 且 $h \\in \\{1,\\dots,H\\}$。假设以下建模选择，这些选择在基于 CTMC 的系统发育性状模型中都是标准的：\n\n1. 在每个隐藏类别 $h$ 内部，观测性状在 $k$ 个观测状态之间的转换遵循等速率 (ER) 模型。也就是说，对于给定的隐藏类别 $h$，从任何观测状态 $i$ 到任何其他观测状态 $j \\neq i$ 的瞬时速率等于一个特定于该类别的常数 $\\alpha_{h} > 0$。ER 速率常数 $\\alpha_{h}$ 允许在不同隐藏类别之间有所不同。\n2. 隐藏状态的转换独立于观测状态发生，并且不改变观测状态。也就是说，从 $(i,h)$ 到 $(i,h')$（其中 $h' \\neq h$）的转换由一个无对称性约束的通用 $H \\times H$ 隐藏状态速率矩阵控制，并且不允许观测状态和隐藏状态同时发生变化。\n3. 完整的 $kH \\times kH$ 联合速率矩阵的对角线元素由 CTMC 定义所蕴含的行和为零的约束确定。\n4. 系统发育树及其枝长以绝对时间单位固定，参数在这些单位下是可识别的。根部分布被假定为联合 CTMC 的平稳分布，因此没有为初始状态频率分配自由参数。\n\n在这些假设下，确定需要估计的自由速率参数总数，作为 $k$ 和 $H$ 的函数，然后针对 $k=3$ 和 $H=2$ 的具体情况计算该数值。仅报告 $k=3$ 和 $H=2$ 的最终计数，形式为单个整数，不带单位。无需取整。",
            "solution": "所述问题具有科学依据，提法明确，并包含足够的信息以得出唯一解。我们开始进行分析。\n\n该系统由一个在包含 $kH$ 个复合状态的状态空间上的连续时间马尔可夫链 (CTMC) 描述。设一个状态由有序对 $(i, h)$ 表示，其中 $i \\in \\{1, \\dots, k\\}$ 是观测状态，而 $h \\in \\{1, \\dots, H\\}$ 是隐藏状态。该系统的演化由一个 $kH \\times kH$ 的瞬时速率矩阵（我们称之为 $Q$）控制。对于 $(i_1, h_1) \\neq (i_2, h_2)$，矩阵项 $Q_{(i_1, h_1), (i_2, h_2)}$ 代表从状态 $(i_1, h_1)$ 到状态 $(i_2, h_2)$ 的瞬时转换速率。对角线元素由每行和为零的约束定义。我们的任务是计算自由的、非零的、非对角线速率参数的数量。\n\n我们根据给定的假设来分析矩阵 $Q$ 的结构。\n\n1.  **观测性状的转换：**根据假设1，在任何给定的隐藏类别 $h$ 内， $k$ 个观测状态之间的转换遵循等速率 (ER) 模型。这意味着从任何观测状态 $i$ 到任何其他状态 $j \\neq i$ 的转换速率是一个常数 $\\alpha_h > 0$。这个常数的值仅取决于隐藏类别 $h$。\n    $$Q_{(i, h), (j, h)} = \\alpha_h \\quad \\text{for } i \\neq j$$\n    由于这些速率允许在 $H$ 个隐藏类别之间有所不同，这就引入了一组参数 $\\{\\alpha_1, \\alpha_2, \\dots, \\alpha_H\\}$。因为每个 $\\alpha_h$ 都是一个独立的参数，所以该假设为模型贡献了恰好 $H$ 个自由参数。\n\n2.  **隐藏状态的转换：**根据假设2，隐藏状态的转换发生时，观测状态 $i$ 保持不变。从隐藏状态 $h$ 到另一个隐藏状态 $h'$ 的转换速率由一个通用的 $H \\times H$ 速率矩阵（我们记为 $R$）的元素给出。设 $R$ 的非对角线元素为 $r_{hh'}$（其中 $h \\neq h'$）。问题指出这些转换独立于观测状态 $i$。因此，对于任何 $i$：\n    $$Q_{(i, h), (i, h')} = r_{hh'} \\quad \\text{for } h \\neq h'$$\n    问题指定了一个无对称性约束的通用 $H \\times H$ 隐藏状态速率矩阵。对于这样一个矩阵，所有 $H(H-1)$ 个非对角线元素都是自由参数。这为模型贡献了 $H(H-1)$ 个自由参数。\n\n3.  **同时转换：**假设2还明确禁止观测状态和隐藏状态同时发生变化。这意味着：\n    $$Q_{(i_1, h_1), (i_2, h_2)} = 0 \\quad \\text{for } i_1 \\neq i_2 \\text{ and } h_1 \\neq h_2$$\n    此规则不引入新参数；它将大量潜在的速率设置为零。\n\n4.  **对角线元素：**假设3指出，对角线元素由行和为零的约束确定。对于任何状态 $(i, h)$，其对角线元素是该行所有非对角线速率之和的负值：\n    $$Q_{(i, h), (i, h)} = - \\sum_{(j, h') \\neq (i, h)} Q_{(i, h), (j, h')}$$\n    $$Q_{(i, h), (i, h)} = - \\left( \\sum_{j \\neq i} Q_{(i, h), (j, h)} + \\sum_{h' \\neq h} Q_{(i, h), (i, h')} \\right)$$\n    代入我们上面分析得出的速率：\n    $$Q_{(i, h), (i, h)} = - \\left( (k-1)\\alpha_h + \\sum_{h' \\neq h} r_{hh'} \\right)$$\n    这证实了对角线元素是已定义的非对角线速率的函数，不会引入新的自由参数。\n\n5.  **根部频率：**假设4指定，根部状态分布是 CTMC 的平稳分布。这意味着根部状态频率由速率矩阵 $Q$ 决定，其本身不是自由参数。\n\n**自由参数总数：**\n自由速率参数的总数 $N_{\\text{params}}$ 是来自观测性状转换的参数和来自隐藏状态转换的参数之和。\n$$N_{\\text{params}}(k, H) = (\\text{Number of } \\alpha_h \\text{ parameters}) + (\\text{Number of } r_{hh'} \\text{ parameters})$$\n$$N_{\\text{params}}(k, H) = H + H(H-1)$$\n$$N_{\\text{params}}(k, H) = H + H^2 - H$$\n$$N_{\\text{params}}(k, H) = H^2$$\n值得注意的是，自由参数的数量与观测状态的数量 $k$ 无关。这是因为在每个隐藏类别内对观测性状采用 ER 模型所带来的直接结果，因为这使得每个类别只需要一个参数 ($\\alpha_h$)，而与 $k$ 的大小无关。\n\n**特定情况的评估：**\n问题要求计算 $k=3$ 和 $H=2$ 情况下的参数数量。使用推导出的公式：\n$$N_{\\text{params}}(3, 2) = 2^2 = 4$$\n自由参数是 $\\alpha_1$、$\\alpha_2$、$r_{12}$ 和 $r_{21}$。总数为 $4$。",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "理解了模型的数学结构后，我们面临一个更深层次的挑战：如何解释模型的结果。这个思想实验揭示了一个关于模型可识别性的关键问题，即在何种情况下，两种截然不同的生物学情景——两个性状之间的相关演化，和单个隐藏速率类别驱动的性状演化——在数学上是不可区分的。通过这个练习，你将深入理解为何统计上的“最佳拟合”模型并不总能指向唯一的因果解释。",
            "id": "2722560",
            "problem": "考虑两个二元观测性状，记为 $X \\in \\{0,1\\}$ 和 $Y \\in \\{0,1\\}$，它们在某一谱系上根据一个连续时间马尔可夫链 (CTMC) 联合演化。该 CTMC 的状态空间为 $\\{00,01,10,11\\}$，其中第一位是 $X$，第二位是 $Y$。相关模型的无穷小生成元（速率矩阵）$Q_{\\mathrm{dep}}$ 的参数化方式如下：(i) 不允许 $X$ 和 $Y$ 同时翻转；(ii) $X$ 的翻转速率取决于 $Y$ 的当前值；(iii) $Y$ 的翻转速率取决于 $X$ 的当前值。具体而言，当状态排序为 $(00,01,10,11)$ 时，\n$$\nQ_{\\mathrm{dep}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0}) & r_{0} & a & 0 \\\\\nr_{0} & -(b + r_{0}) & 0 & b \\\\\na & 0 & -(a + r_{1}) & r_{1} \\\\\n0 & b & r_{1} & -(b + r_{1})\n\\end{pmatrix},\n$$\n其中 $a>0$ 和 $b>0$ 分别是当 $Y=0$ 和 $Y=1$ 时 $X$ 的翻转速率，而 $r_{0}>0$ 和 $r_{1}>0$ 分别是当 $X=0$ 和 $X=1$ 时 $Y$ 的翻转速率。\n\n现在，转而考虑一个单一的可观测二元性状 $Z \\in \\{0,1\\}$，它随着隐速率类别 $H \\in \\{\\mathrm{A},\\mathrm{B}\\}$ 演化（一个隐状态模型）。联合隐状态过程的状态空间为 $\\{0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B}\\}$，其无穷小生成元 $Q_{\\mathrm{hid}}$ 具有以下解释：(i) 在隐类别 $\\mathrm{A}$ 中，$Z$ 的翻转速率为 $a$，在隐类别 $\\mathrm{B}$ 中，其翻转速率为 $b$；(ii) 当 $Z=0$ 时，隐类别 $H$ 的翻转速率为 $r_{0}$，当 $Z=1$ 时，其翻转速率为 $r_{1}$；(iii) 不允许 $Z$ 和 $H$ 同时翻转。当状态排序为 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 时，\n$$\nQ_{\\mathrm{hid}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0}) & r_{0} & a & 0 \\\\\nr_{0} & -(b + r_{0}) & 0 & b \\\\\na & 0 & -(a + r_{1}) & r_{1} \\\\\n0 & b & r_{1} & -(b + r_{1})\n\\end{pmatrix}.\n$$\n因此，在 $00 \\leftrightarrow 0\\mathrm{A}$、$01 \\leftrightarrow 0\\mathrm{B}$、$10 \\leftrightarrow 1\\mathrm{A}$ 和 $11 \\leftrightarrow 1\\mathrm{B}$ 的重新标记下，$Q_{\\mathrm{dep}} = Q_{\\mathrm{hid}}$。\n\n设该谱系为一条长度为 $t>0$ 的单一分支，从根部一个已知的祖先状态演化至一个已观测的末端。假设在相关模型下，根部的祖先状态为 $00$，而在隐状态模型下为 $0\\mathrm{A}$（即上述重新标记下的对应状态）。在末端，相关模型下的观测状态为 $11$，隐状态模型下的观测状态为 $1\\mathrm{B}$（同样，在重新标记下是对应的）。你可以使用的基本依据包括：(i) CTMC 的定义，其中无穷小生成元为 $Q$，转移矩阵为 $P(t) = \\exp(Qt)$，$\\exp(\\cdot)$ 表示矩阵指数；(ii) 在长度为 $t$ 的单一分支上，观测到从已知初始状态 $i$ 到已知最终状态 $j$ 的转移的似然是 $P(t)$ 的 $(i,j)$ 元。\n\n仅使用这些基础，且不引入或假设任何额外的捷径，请确定对于指定的单分支观测，相关模型与隐状态模型之间的对数似然差，并将其表示为 $t$、$a$、$b$、$r_{0}$ 和 $r_{1}$ 的函数。你的最终答案必须是单一实数或单一的封闭形式解析表达式。无需单位。如果你发现表达式可以简化为一个精确的常数，请报告该常数。最后，在计算出所要求的差值后，请用文字简要解释这种等价性对于在更大数据树上进行推断的可识别性后果。\n\n你最终报告的量应为针对指定观测的 $\\ln L_{\\mathrm{dep}} - \\ln L_{\\mathrm{hid}}$ 的单一值。无需四舍五入。",
            "solution": "我们从连续时间马尔可夫链 (CTMC) 的基本原理开始。一个在有限状态空间上、无穷小生成元（速率矩阵）为 $Q$ 的 CTMC，其随时间 $t>0$ 变化的转移概率矩阵由 $P(t) = \\exp(Qt)$ 给出，其中 $\\exp(\\cdot)$ 是由收敛级数 $\\exp(Qt) = \\sum_{k=0}^{\\infty} \\frac{(Qt)^{k}}{k!}$ 定义的矩阵指数。对于沿长度为 $t$ 的单一分支，从已知初始状态 $i$ 到已知最终状态 $j$ 的观测，其观测似然为 $[P(t)]_{ij}$，即 $P(t)$ 的 $(i,j)$ 元。\n\n在本问题中，相关模型 $Q_{\\mathrm{dep}}$ 在四个状态 $(00,01,10,11)$ 上的定义如下：\n$$\nQ_{\\mathrm{dep}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0}) & r_{0} & a & 0 \\\\\nr_{0} & -(b + r_{0}) & 0 & b \\\\\na & 0 & -(a + r_{1}) & r_{1} \\\\\n0 & b & r_{1} & -(b + r_{1})\n\\end{pmatrix}.\n$$\n隐状态单性状模型 $Q_{\\mathrm{hid}}$ 在四个状态 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 上的指定如下：\n$$\nQ_{\\mathrm{hid}} \\;=\\;\n\\begin{pmatrix}\n-(a + r_{0}) & r_{0} & a & 0 \\\\\nr_{0} & -(b + r_{0}) & 0 & b \\\\\na & 0 & -(a + r_{1}) & r_{1} \\\\\n0 & b & r_{1} & -(b + r_{1})\n\\end{pmatrix}.\n$$\n根据构造，一旦我们确定了重新标记 $00 \\leftrightarrow 0\\mathrm{A}$、$01 \\leftrightarrow 0\\mathrm{B}$、$10 \\leftrightarrow 1\\mathrm{A}$ 和 $11 \\leftrightarrow 1\\mathrm{B}$，这两个矩阵就是相同的。更一般地，如果排序不同，则会存在一个置换矩阵 $S$ 使得 $Q_{\\mathrm{hid}} = S^{\\top} Q_{\\mathrm{dep}} S$，这意味着对于所有 $t \\ge 0$，$\\exp(Q_{\\mathrm{hid}} t) = S^{\\top} \\exp(Q_{\\mathrm{dep}} t) S$，因为矩阵指数在相似变换下保持不变。\n\n对于指定的长度为 $t$ 的单一分支，在相关模型下观测到从已知根状态 $00$ 到末端状态 $11$ 的转移的似然为\n$$\nL_{\\mathrm{dep}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right)\\right]_{(00),(11)}.\n$$\n在隐状态模型下，观测是从已知根状态 $0\\mathrm{A}$ 到末端状态 $1\\mathrm{B}$，其似然为\n$$\nL_{\\mathrm{hid}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right)\\right]_{(0\\mathrm{A}),(1\\mathrm{B})}.\n$$\n因为在将 $(00,01,10,11)$ 按相同顺序映射到 $(0\\mathrm{A},0\\mathrm{B},1\\mathrm{A},1\\mathrm{B})$ 的重新标记下，$Q_{\\mathrm{hid}}$ 和 $Q_{\\mathrm{dep}}$ 是相同的，所以我们有\n$$\n\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right) \\;=\\; \\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right),\n$$\n当状态排序对齐时，它们逐元相等。因此，\n$$\nL_{\\mathrm{hid}} \\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{hid}} \\, t\\right)\\right]_{(0\\mathrm{A}),(1\\mathrm{B})}\n\\;=\\; \\left[\\exp\\!\\left(Q_{\\mathrm{dep}} \\, t\\right)\\right]_{(00),(11)}\n\\;=\\; L_{\\mathrm{dep}}.\n$$\n取自然对数，\n$$\n\\ln L_{\\mathrm{dep}} - \\ln L_{\\mathrm{hid}} \\;=\\; \\ln\\!\\left(\\frac{L_{\\mathrm{dep}}}{L_{\\mathrm{hid}}}\\right) \\;=\\; \\ln(1) \\;=\\; 0.\n$$\n这个等式对所有 $t>0$ 以及所有正速率参数 $a$、$b$、$r_{0}$ 和 $r_{1}$ 均成立，因为这是生成元精确相等（或置换相似）以及矩阵指数在相似性下的不变性的结果。\n\n可识别性后果。这个构造的例子表明，同一个四状态 CTMC 既可以解释为两个观测二元性状 $(X,Y)$ 之间相关演化的模型，也可以解释为单个观测二元性状 $Z$ 随两个隐速率类别 $H$ 演化的模型。在任何系统发育树上，从该四状态过程计算出的似然仅取决于生成元 $Q$ 和观测到的末端状态；一个保持 $Q$ 不变的状态重新标记会使似然保持不变。因此，在没有外部约束的情况下，数据不足以识别该四状态过程的第二个分量是代表一个观测性状还是一个隐速率类别：在生成 CTMC 的层面上，这两种解释在观测上是等价的。在实践中，这意味着两个性状之间相关演化的明显证据，可以被单个性状中的隐速率异质性所模拟，从而导致因果解释的不可识别性，除非有额外的信息、约束或实验设计元素打破这种等价性（例如，通过约束特定的非对角线速率相等、固定或检验嵌套子模型，或利用独立的隐过程数据源）。此外，在隐状态模型表述中，存在一种固有的隐类别标签交换对称性，这会产生多个具有相同似然的参数化方案，从而进一步强调了进行仔细的可识别性分析的必要性。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "现在，我们将理论和思想实验付诸实践，解决一个完整的谱系数据分析问题。这个综合性练习展示了一个经典情景：一个性状的演化看起来与物种多样化速率相关，但这种关联实际上是伪相关。你将通过编程实现并拟合两种模型——一个简单的非谱系模型和一个考虑了谱系与隐藏状态的模型——并使用赤池信息准则（Akaike Information Criterion, $AIC$）进行比较，从而揭示这种伪相关是如何被未观察到的演化速率异质性所驱动的。",
            "id": "2722598",
            "problem": "您的任务是构建并分析一个模拟的系统发育场景，以证明在树末端观察到的二元性状与一个多样化速率代理指标之间的表观相关性，可以完全由在树上演化的隐藏速率类别来解释。您将实现两个基于似然的模型，并使用赤池信息准则 (Akaike Information Criterion, AIC) 对它们进行比较。\n\n基本原理与定义：\n- 一个二元连续时间马尔可夫链 (CTMC)，其速率矩阵为 $Q=\\begin{pmatrix} -q_{01} & q_{01} \\\\ q_{10} & -q_{10} \\end{pmatrix}$，在长度为 $t$ 的分支上产生转移矩阵 $P(t)=\\exp(Qt)$。对于一个二态 CTMC，当 $q_{01}+q_{10}>0$ 时，其平稳分布为 $\\boldsymbol{\\pi}=(\\pi_0,\\pi_1)$，其中 $\\pi_0=\\dfrac{q_{10}}{q_{01}+q_{10}}$ 且 $\\pi_1=\\dfrac{q_{01}}{q_{01}+q_{10}}$。\n- 树上的隐马尔可夫模型 (HMM) 使用 Felsenstein 的剪枝算法，通过对内部节点的隐藏状态进行积分来计算末端数据的似然。对于每个具有观测数据 $y_i$ 的末端，在隐藏状态 $s\\in\\{0,1\\}$ 下的发射密度由一个均值为 $\\mu_s$、标准差为 $\\sigma$ 的高斯密度 $\\phi(y_i\\mid \\mu_s,\\sigma)$ 给出。对于一个内部节点，其条件似然向量通过使用沿每个分支的 CTMC 转移概率合并子节点的似然来计算。整棵树的似然是使用平稳分布 $\\boldsymbol{\\pi}$ 对根节点的条件似然向量进行加权求和。\n\n您将对所提供的测试集拟合并比较以下两个模型：\n\n- 模型 A（仅考虑性状的无系统发育高斯混合模型）：树末端观察到的二元性状 $X_i\\in\\{0,1\\}$ 将末端数据 $y_i$ 划分为两组。似然是所有末端上 $\\phi(y_i\\mid \\mu_{X_i},\\sigma)$ 的乘积，参数为 $(\\mu_0,\\mu_1,\\sigma)$。您必须计算 $(\\mu_0,\\mu_1,\\sigma)$ 的最大似然估计和最大化对数似然 $\\ell_A$。赤池信息准则为 $\\mathrm{AIC}_A=2k_A-2\\ell_A$，其中 $k_A=3$。\n\n- 模型 B（基于树的隐藏状态高斯 HMM）：一个具有速率 $(q_{01},q_{10})$ 的二态隐藏 CTMC 在树上演化。每个末端的多样化速率代理指标 $y_i$ 由一个高斯分布发射，其均值为 $\\mu_{H_i}$，标准差为 $\\sigma$，其中 $H_i\\in\\{0,1\\}$ 是该末端未被观察到的隐藏状态。参数为 $(\\mu_0,\\mu_1,\\sigma,q_{01},q_{10})$。您必须使用 Felsenstein 的剪枝算法计算最大化对数似然 $\\ell_B$，并计算 $\\mathrm{AIC}_B=2k_B-2\\ell_B$，其中 $k_B=5$。\n\n决策标准：对于每个测试用例，返回一个布尔值，指示是否 $\\mathrm{AIC}_B<\\mathrm{AIC}_A$。\n\n树的规格（所有测试用例通用）：\n- 有根的、严格二叉树，末端节点索引为 $0$ 到 $7$，内部节点索引为 $8$ 到 $14$。所有分支长度均为 $0.5$。有向边 $(\\text{父节点},\\text{子节点},\\ell)$ 如下：\n  - $(14,12,0.5)$, $(14,13,0.5)$,\n  - $(12,10,0.5)$, $(12,11,0.5)$,\n  - $(10,0,0.5)$, $(10,1,0.5)$, $(11,2,0.5)$, $(11,3,0.5)$,\n  - $(13,9,0.5)$, $(13,8,0.5)$,\n  - $(9,4,0.5)$, $(9,5,0.5)$, $(8,6,0.5)$, $(8,7,0.5)$.\n- 根节点为节点 $14$。\n\n三个测试用例的数据：\n- 用例 1 （隐藏速率聚类产生表观性状相关性）：\n  - 按末端索引 $i=0,\\dots,7$ 的观测性状向量：$X^{(1)}=[0,0,1,1,1,1,0,1]$。\n  - 按末端索引的多样化速率代理指标（实值）：$y^{(1)}=[0.45,0.55,0.52,0.48,1.22,1.18,1.25,1.15]$。\n\n- 用例 2 （末端之间无实际差异）：\n  - 观测性状向量：$X^{(2)}=[0,1,0,1,1,0,1,0]$。\n  - 多样化速率代理指标：$y^{(2)}=[1.02,0.98,1.01,1.00,0.99,1.03,1.00,0.97]$。\n\n- 用例 3 （频繁的隐藏状态切换；与性状几乎对齐但存在不匹配）：\n  - 观测性状向量：$X^{(3)}=[0,1,0,1,0,1,1,1]$。\n  - 多样化速率代理指标：$y^{(3)}=[0.49,1.21,0.52,1.19,0.51,1.18,0.50,1.22]$。\n\n您的任务：\n1. 实现模型 A 的最大似然估计，以获得 $\\ell_A$ 和 $\\mathrm{AIC}_A$。\n2. 在给定的树上使用 Felsenstein 的剪枝算法实现模型 B 的最大似然估计，以获得 $\\ell_B$ 和 $\\mathrm{AIC}_B$。\n3. 对于每个用例 $j\\in\\{1,2,3\\}$，返回一个布尔值 $\\mathrm{AIC}_B<\\mathrm{AIC}_A$。\n\n最终输出规格：\n- 您的程序应生成单行输出，其中包含三个布尔结果，以逗号分隔并用方括号括起，例如 `[True,False,True]`。\n\n测试集覆盖范围预期：\n- 用例 1 是一个“理想路径”，其中隐藏速率模型应被优先选择，因为隐藏状态在系统发育上是聚类的并驱动了多样化速率代理指标，从而产生了一种表观的性状相关性，而当对系统发育和隐藏状态进行建模时，这种相关性是虚假的。\n- 用例 2 是一个没有显著差异的边界情况；出于简约性原则，仅考虑性状的模型不应被更复杂的隐藏状态模型超越。\n- 用例 3 通过频繁的隐藏状态切换和与性状的几乎对齐来对算法进行压力测试；当树结构在性状划分之外提供的解释力有限时，由于对额外参数的惩罚，隐藏状态模型可能不会被优先选择。\n\n本问题中的所有数值都是无单位的实数。不使用角度。不出现百分比。所请求的输出是布尔值。",
            "solution": "所提出的问题要求比较两种统计模型，用于解释一个二元性状、一个连续性状和系统发育之间的关系。首先评估问题陈述的有效性。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n- **模型 A (仅考虑性状的高斯混合模型)**:\n  - 数据：在末端 $i$ 观察到的二元性状 $X_i \\in \\{0,1\\}$ 和连续代理指标 $y_i$。\n  - 似然：高斯密度 $\\phi(y_i|\\mu_{X_i}, \\sigma)$ 的乘积。\n  - 参数：$(\\mu_0, \\mu_1, \\sigma)$，共 $k_A=3$ 个。\n  - 准则：赤池信息准则，$\\mathrm{AIC}_A = 2k_A - 2\\ell_A$，其中 $\\ell_A$ 是最大化对数似然。\n\n- **模型 B (基于树的隐藏状态高斯 HMM)**:\n  - 模型：一个在树上演化的、具有速率 $(q_{01}, q_{10})$ 的二态隐藏连续时间马尔可夫链 (CTMC)。\n  - 发射：$y_i$ 从 $\\phi(y_i|\\mu_{H_i}, \\sigma)$ 中抽取，其中 $H_i \\in \\{0,1\\}$ 是隐藏状态。\n  - 参数：$(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$，共 $k_B=5$ 个。\n  - 准则：$\\mathrm{AIC}_B = 2k_B - 2\\ell_B$，其中 $\\ell_B$ 通过 Felsenstein 的剪枝算法最大化。\n\n- **CTMC 定义**:\n  - 速率矩阵：$Q=\\begin{pmatrix} -q_{01} & q_{01} \\\\ q_{10} & -q_{10} \\end{pmatrix}$。\n  - 转移矩阵：$P(t) = \\exp(Qt)$。\n  - 平稳分布：$\\boldsymbol{\\pi}=(\\pi_0, \\pi_1)$，其中当 $q_{01}+q_{10}>0$ 时，$\\pi_0=\\frac{q_{10}}{q_{01}+q_{10}}$ 且 $\\pi_1=\\frac{q_{01}}{q_{01}+q_{10}}$。\n\n- **树结构**:\n  - 一个固定的、有根的、二叉树，有 8 个末端（索引 0-7）和内部节点 8-14。\n  - 根节点：节点 14。所有分支长度均为 0.5。\n  - 拓扑由有向边给出：$(14,12,0.5), (14,13,0.5), (12,10,0.5), (12,11,0.5), (10,0,0.5), (10,1,0.5), (11,2,0.5), (11,3,0.5), (13,9,0.5), (13,8,0.5), (9,4,0.5), (9,5,0.5), (8,6,0.5), (8,7,0.5)$。\n\n- **测试数据**：提供了三种情况，每种情况都有一个观测性状向量 $X$ 和连续代理指标 $y$。\n  - 情况 1：$X^{(1)}=[0,0,1,1,1,1,0,1]$, $y^{(1)}=[0.45,0.55,0.52,0.48,1.22,1.18,1.25,1.15]$。\n  - 情况 2：$X^{(2)}=[0,1,0,1,1,0,1,0]$, $y^{(2)}=[1.02,0.98,1.01,1.00,0.99,1.03,1.00,0.97]$。\n  - 情况 3：$X^{(3)}=[0,1,0,1,0,1,1,1]$, $y^{(3)}=[0.49,1.21,0.52,1.19,0.51,1.18,0.50,1.22]$。\n\n- **任务**：对于每种情况，确定是否 $\\mathrm{AIC}_B < \\mathrm{AIC}_A$。\n\n**步骤 2：使用提取的信息进行验证**\n- **科学依据**：该问题利用了计算系统发育学中的既定概念，包括 CTMC、树上的隐马尔可夫模型、Felsenstein 的剪枝算法以及用于模型比较的 AIC。这些都是标准工具。该问题在科学上是合理的。\n- **良态问题**：模型、数据、树结构和目标都得到了明确定义。该任务需要通过数值优化来寻找最大似然估计，这对此类问题是标准做法，并不会使其成为一个病态问题。每个用例都期望得到一个唯一的布尔值答案。\n- **客观性**：问题以精确的数学和算法术语陈述，没有主观性。“测试用例预期”可作为预期行为的指南，但不会改变客观任务本身。\n- **完整性和一致性**：问题提供了构建解决方案所需的所有必要组件。没有矛盾之处。\n\n**步骤 3：结论与行动**\n此问题被判定为**有效**。这是一个定义明确的练习，涉及实现和比较系统发育统计模型。因此，有必要提供完整的解决方案。\n\n### 基于原理的解决方案设计\n\n问题的核心是计算并比较两个模型的赤池信息准则 (AIC)。\n$\\mathrm{AIC} = 2k - 2\\ell_{max}$，其中 $k$ 是参数数量，$\\ell_{max}$ 是最大对数似然。\n\n**模型 A：仅考虑性状的高斯混合模型**\n该模型假设连续数据 $y_i$ 来自两个高斯分布之一，具体由观察到的二元性状 $X_i$ 决定。系统发育被忽略。对数似然为：\n$$ \\ell_A(\\mu_0, \\mu_1, \\sigma) = \\sum_{i=0}^{N-1} \\log \\phi(y_i | \\mu_{X_i}, \\sigma) $$\n其中 $N=8$ 是末端数量，$\\phi(y | \\mu, \\sigma)$ 是高斯概率密度函数。参数有 $k_A=3$ 个：$(\\mu_0, \\mu_1, \\sigma)$。\n\n这些参数的最大似然估计 (MLE) 具有解析解。令 $S_s = \\{y_i | X_i = s\\}$ 且 $n_s = |S_s|$，其中 $s \\in \\{0,1\\}$。\n均值的 MLE 是每组的样本均值：\n$$ \\hat{\\mu}_0 = \\frac{1}{n_0} \\sum_{y \\in S_0} y, \\quad \\hat{\\mu}_1 = \\frac{1}{n_1} \\sum_{y \\in S_1} y $$\n方差 $\\sigma^2$ 的 MLE 是合并样本方差：\n$$ \\hat{\\sigma}^2 = \\frac{1}{N} \\left( \\sum_{y \\in S_0} (y - \\hat{\\mu}_0)^2 + \\sum_{y \\in S_1} (y - \\hat{\\mu}_1)^2 \\right) $$\n将这些 MLE 代入对数似然函数即可获得最大化对数似然 $\\ell_A$。一种数值稳定的计算方法是：\n$$ \\ell_A = \\sum_{y \\in S_0} \\log \\phi(y | \\hat{\\mu}_0, \\hat{\\sigma}) + \\sum_{y \\in S_1} \\log \\phi(y | \\hat{\\mu}_1, \\hat{\\sigma}) $$\n最后，$\\mathrm{AIC}_A = 2(3) - 2\\ell_A = 6 - 2\\ell_A$。\n\n**模型 B：基于树的隐藏状态高斯 HMM**\n该模型假设连续数据 $y_i$ 由一个高斯分布发射，其均值由一个隐藏的二元状态 $H_i$ 决定，该状态根据 CTMC 沿系统发育树演化。参数有 $k_B=5$ 个：$(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$。\n\n对数似然 $\\ell_B$ 没有闭式解，必须通过数值方法进行最大化。对于给定的参数集，似然使用 Felsenstein 的剪枝算法计算。\n\n1.  **转移概率**：沿长度为 $t$ 的分支从状态 $i$ 转移到状态 $j$ 的概率由矩阵 $P(t) = \\exp(Qt)$ 给出。对于二态模型，设 $\\lambda = q_{01} + q_{10}$：\n    $$ P(t) = \\frac{1}{\\lambda} \\begin{pmatrix} q_{10} + q_{01}e^{-\\lambda t} & q_{01}(1 - e^{-\\lambda t}) \\\\ q_{10}(1 - e^{-\\lambda t}) & q_{01} + q_{10}e^{-\\lambda t} \\end{pmatrix} $$\n    本问题中所有分支长度均为 $t=0.5$。\n\n2.  **Felsenstein 的剪枝算法**：该算法通过对树进行后序遍历来计算末端数据的似然。令 $L_u(s)$ 为在节点 $u$ 处于状态 $s$ 的条件下，由节点 $u$ 向下衍生的进化枝中数据的似然。\n    - **初始化（末端）**：对于一个末端节点 $i$，其似然向量由发射概率给出：\n      $$ \\mathbf{L}_i = [L_i(0), L_i(1)] = [\\phi(y_i | \\mu_0, \\sigma), \\phi(y_i | \\mu_1, \\sigma)] $$\n    - **递归（内部节点）**：对于一个内部节点 $u$，其子节点为 $v$ 和 $w$，通过长度为 $t_v$ 和 $t_w$ 的分支连接，其似然向量通过合并其子节点的似然来计算：\n      $$ L_u(s) = \\left( \\sum_{s_v=0}^1 P(t_v)_{s,s_v} L_v(s_v) \\right) \\times \\left( \\sum_{s_w=0}^1 P(t_w)_{s,s_w} L_w(s_w) \\right) $$\n      写成矩阵形式为 $\\mathbf{L}_u = (P(t_v)^T \\mathbf{L}_v) \\odot (P(t_w)^T \\mathbf{L}_w)$，其中 $\\odot$ 是逐元素乘积。\n    - **终止（根节点）**：在根节点 $r$，总似然是使用平稳分布 $\\boldsymbol{\\pi}$ 对根似然向量进行加权求和：\n      $$ \\mathcal{L} = \\boldsymbol{\\pi} \\cdot \\mathbf{L}_r = \\pi_0 L_r(0) + \\pi_1 L_r(1) $$\n    由于许多小概率的乘积，该计算容易出现数值下溢。因此有必要进行缩放处理。计算每个 $\\mathbf{L}_u$ 后，用其总和对其进行重新缩放，并累加缩放因子的对数。最终的对数似然是所有对数缩放因子之和，再加上根部最终缩放似然的对数。\n\n3.  **优化**：使用数值优化器（例如 `scipy.optimize` 中的 Nelder-Mead）对函数 $-\\ell_B(\\mu_0, \\mu_1, \\sigma, q_{01}, q_{10})$ 进行最小化。通过对其对数进行优化来处理 $\\sigma, q_{01}, q_{10}$ 的正性约束。模型 A 的 MLEs 为 $\\mu_0, \\mu_1, \\sigma$ 提供了良好的初始猜测值。\n\n一旦找到最大化对数似然 $\\ell_B$，AIC 的计算公式为 $\\mathrm{AIC}_B = 2(5) - 2\\ell_B = 10 - 2\\ell_B$。\n\n每个测试用例的最后一步是比较两个 AIC 值，并返回 $\\mathrm{AIC}_B < \\mathrm{AIC}_A$ 的布尔结果。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the fitting of Model A and Model B, compares their AIC values,\n    and prints the final results in the specified format.\n    \"\"\"\n    # Tree specification, fixed for all cases\n    tree_spec = {\n        'children': {\n            14: [12, 13], 13: [9, 8], 12: [10, 11], 11: [2, 3],\n            10: [0, 1], 9: [4, 5], 8: [6, 7]\n        },\n        'post_order': [0, 1, 10, 2, 3, 11, 4, 5, 9, 6, 7, 8, 12, 13, 14],\n        'tips': list(range(8)),\n        'branch_length': 0.5,\n        'root': 14\n    }\n\n    test_cases = [\n        {\n            \"X\": [0, 0, 1, 1, 1, 1, 0, 1],\n            \"y\": [0.45, 0.55, 0.52, 0.48, 1.22, 1.18, 1.25, 1.15]\n        },\n        {\n            \"X\": [0, 1, 0, 1, 1, 0, 1, 0],\n            \"y\": [1.02, 0.98, 1.01, 1.00, 0.99, 1.03, 1.00, 0.97]\n        },\n        {\n            \"X\": [0, 1, 0, 1, 0, 1, 1, 1],\n            \"y\": [0.49, 1.21, 0.52, 1.19, 0.51, 1.18, 0.50, 1.22]\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        y, X = case[\"y\"], case[\"X\"]\n        \n        # Fit Model A\n        aic_A, model_A_params = _fit_model_A(y, X)\n        \n        # Fit Model B\n        aic_B = _fit_model_B(y, tree_spec, model_A_params)\n\n        results.append(aic_B  aic_A)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef _fit_model_A(y, X):\n    \"\"\"\n    Computes AIC and MLE parameters for Model A.\n    \"\"\"\n    k_A = 3\n    y = np.array(y)\n    X = np.array(X)\n\n    y_0 = y[X == 0]\n    y_1 = y[X == 1]\n    n_0 = len(y_0)\n    n_1 = len(y_1)\n    N = n_0 + n_1\n\n    if n_0 == 0 or n_1 == 0:\n        mu = np.mean(y)\n        sigma2 = np.var(y)\n        if sigma2  1e-12: sigma2 = 1e-12\n        sigma = np.sqrt(sigma2)\n        ll = np.sum(norm.logpdf(y, loc=mu, scale=sigma))\n        k_A = 2\n        aic_A = 2 * k_A - 2 * ll\n        # Assign means to avoid unpacking error, though one is irrelevant\n        mu_0 = mu if n_1 == 0 else 0.0\n        mu_1 = mu if n_0 == 0 else 0.0\n        return aic_A, (mu_0, mu_1, sigma)\n\n    mu_0 = np.mean(y_0)\n    mu_1 = np.mean(y_1)\n\n    ss_0 = np.sum((y_0 - mu_0)**2)\n    ss_1 = np.sum((y_1 - mu_1)**2)\n    sigma2 = (ss_0 + ss_1) / N\n    if sigma2  1e-12: sigma2 = 1e-12\n    sigma = np.sqrt(sigma2)\n    \n    ll_0 = np.sum(norm.logpdf(y_0, loc=mu_0, scale=sigma))\n    ll_1 = np.sum(norm.logpdf(y_1, loc=mu_1, scale=sigma))\n    ll_A = ll_0 + ll_1\n    \n    aic_A = 2 * k_A - 2 * ll_A\n    return aic_A, (mu_0, mu_1, sigma)\n\n\ndef _fit_model_B(y_data, tree, initial_params):\n    \"\"\"\n    Computes AIC for Model B using numerical optimization.\n    \"\"\"\n    k_B = 5\n    y = np.array(y_data)\n    \n    def neg_log_likelihood(params, y, tree_spec):\n        mu0, mu1, log_sigma, log_q01, log_q10 = params\n        sigma = np.exp(log_sigma)\n        q01 = np.exp(log_q01)\n        q10 = np.exp(log_q10)\n\n        # Numerical stability checks\n        if sigma  1e-9: return np.inf\n\n        # CTMC calculations\n        q_sum = q01 + q10\n        if q_sum  1e-9:\n            pi = np.array([0.5, 0.5])\n            P_t = np.identity(2)\n        else:\n            pi = np.array([q10 / q_sum, q01 / q_sum])\n            exp_term = np.exp(-q_sum * tree_spec['branch_length'])\n            P_t = np.array([\n                [pi[0] + pi[1] * exp_term, pi[1] * (1 - exp_term)],\n                [pi[0] * (1 - exp_term), pi[1] + pi[0] * exp_term]\n            ])\n        \n        # Felsenstein's pruning algorithm with scaling\n        likelihood_vectors = {}\n        total_log_scale = 0.0\n\n        for node in tree_spec['post_order']:\n            if node in tree_spec['tips']:\n                log_L0 = norm.logpdf(y[node], mu0, sigma)\n                log_L1 = norm.logpdf(y[node], mu1, sigma)\n                L_node = np.array([np.exp(log_L0), np.exp(log_L1)])\n            else:\n                child1, child2 = tree_spec['children'][node]\n                L1 = likelihood_vectors[child1]\n                L2 = likelihood_vectors[child2]\n                L_prime1 = P_t.T @ L1\n                L_prime2 = P_t.T @ L2\n                L_node = L_prime1 * L_prime2 # Element-wise product\n            \n            scale = np.sum(L_node)\n            if scale > 1e-300: # Prevent underflow\n                likelihood_vectors[node] = L_node / scale\n                total_log_scale += np.log(scale)\n            else:\n                return np.inf\n\n        # Final likelihood at root\n        L_root = likelihood_vectors[tree_spec['root']]\n        final_L = pi @ L_root\n        \n        if final_L = 1e-300: return np.inf\n\n        log_L = np.log(final_L) + total_log_scale\n        return -log_L\n\n    # Initial guess for optimization from Model A's results\n    mu0_init, mu1_init, sigma_init = initial_params\n    x0 = np.array([mu0_init, mu1_init, np.log(sigma_init), np.log(1.0), np.log(1.0)])\n\n    # Run optimizer\n    result = minimize(\n        neg_log_likelihood, \n        x0, \n        args=(y, tree), \n        method='Nelder-Mead', \n        options={'maxiter': 2000, 'adaptive': True}\n    )\n\n    max_ll_B = -result.fun\n    aic_B = 2 * k_B - 2 * max_ll_B\n    return aic_B\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}