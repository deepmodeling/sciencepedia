{
    "hands_on_practices": [
        {
            "introduction": "To study phenotypic plasticity quantitatively, we must first measure it. The reaction norm, which describes the phenotype of a genotype across a range of environments, is the central tool for this task. This foundational exercise  will guide you through the process of estimating the parameters of a simple linear reaction norm, $z(E) = a + bE$, directly from experimental data. By applying the principle of least squares, you will derive and compute the intercept ($a$) and slope ($b$), and in doing so, translate raw measurements into biologically meaningful quantities that represent the baseline phenotype and the degree of plasticity.",
            "id": "2741824",
            "problem": "A single genotype is assayed for a quantitative trait under two thermal environments, and the phenotype is modeled by a linear reaction norm. Let the environment variable be defined as temperature deviation in degrees Celsius from a baseline of $25$ degrees Celsius, so that $E = 0$ corresponds to $25$ degrees Celsius. The observed data for this genotype are: at environment $E_1 = -5$ (i.e., $20$ degrees Celsius), the phenotype is $z_1 = 6.4$ milligrams, and at environment $E_2 = +5$ (i.e., $30$ degrees Celsius), the phenotype is $z_2 = 5.2$ milligrams. Assume the linear reaction norm\n$$\nz(E) = a + b E + \\varepsilon,\n$$\nwhere $a$ and $b$ are genotype-specific parameters and $\\varepsilon$ is a residual with mean zero. Starting from the definitions of linear regression and the least squares principle, derive the least-squares estimates $\\hat{a}$ and $\\hat{b}$ using these two observations, compute their numerical values, and interpret the biological meaning of $\\hat{a}$ and $\\hat{b}$ in terms of phenotypic plasticity. Express $\\hat{a}$ in milligrams and $\\hat{b}$ in milligrams per degree Celsius. Report the final numerical estimates for $a$ and $b$ in that order, using exact decimal values with no rounding.",
            "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extract Givens**\n- Model for phenotype: linear reaction norm, $z(E) = a + b E + \\varepsilon$.\n- Environmental variable $E$: Temperature deviation in degrees Celsius from a baseline of $25$ degrees Celsius. $E=0$ corresponds to $25^\\circ\\text{C}$.\n- Observation 1: At $E_1 = -5$, the phenotype is $z_1 = 6.4$ milligrams.\n- Observation 2: At $E_2 = 5$, the phenotype is $z_2 = 5.2$ milligrams.\n- Parameters $a$ and $b$ are genotype-specific.\n- Residual $\\varepsilon$ has a mean of zero.\n- Task: Derive least-squares estimates $\\hat{a}$ and $\\hat{b}$ from first principles, compute their values, and interpret their biological meaning.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, utilizing the standard linear reaction norm model from quantitative genetics to describe phenotypic plasticity. It is well-posed; with two data points, there exists a unique linear function that fits them perfectly, and the method of least squares will yield this unique solution. The given data are complete and consistent for determining the two parameters of the linear model. The values are physically realistic. The problem is objective and formalizable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full derivation and solution will be provided.\n\nThe principle of least squares dictates that the estimates for the parameters $a$ and $b$, denoted $\\hat{a}$ and $\\hat{b}$, are the values that minimize the sum of squared residuals, $S$. The residual for an observation $(E_i, z_i)$ is $\\varepsilon_i = z_i - (a + b E_i)$. The sum of squared residuals for the two given observations is:\n$$\nS(a, b) = \\sum_{i=1}^{2} \\left[z_i - (a + b E_i)\\right]^2 = \\left[z_1 - (a + b E_1)\\right]^2 + \\left[z_2 - (a + b E_2)\\right]^2\n$$\nTo find the minimum of this function, we must compute its partial derivatives with respect to $a$ and $b$ and set them to zero. This yields a system of two linear equations known as the normal equations.\n\nFirst, the partial derivative with respect to $a$:\n$$\n\\frac{\\partial S}{\\partial a} = \\frac{\\partial}{\\partial a} \\left( [z_1 - a - b E_1]^2 + [z_2 - a - b E_2]^2 \\right) = 2(z_1 - a - b E_1)(-1) + 2(z_2 - a - b E_2)(-1)\n$$\nSetting $\\frac{\\partial S}{\\partial a} = 0$:\n$$\n-2(z_1 - \\hat{a} - \\hat{b} E_1) - 2(z_2 - \\hat{a} - \\hat{b} E_2) = 0\n$$\n$$\n(z_1 + z_2) - 2\\hat{a} - \\hat{b}(E_1 + E_2) = 0\n$$\n$$\n2\\hat{a} + \\hat{b}(E_1 + E_2) = z_1 + z_2 \\quad \\quad (1)\n$$\n\nSecond, the partial derivative with respect to $b$:\n$$\n\\frac{\\partial S}{\\partial b} = \\frac{\\partial}{\\partial b} \\left( [z_1 - a - b E_1]^2 + [z_2 - a - b E_2]^2 \\right) = 2(z_1 - a - b E_1)(-E_1) + 2(z_2 - a - b E_2)(-E_2)\n$$\nSetting $\\frac{\\partial S}{\\partial b} = 0$:\n$$\n-2E_1(z_1 - \\hat{a} - \\hat{b} E_1) - 2E_2(z_2 - \\hat{a} - \\hat{b} E_2) = 0\n$$\n$$\n-E_1z_1 + \\hat{a}E_1 + \\hat{b}E_1^2 - E_2z_2 + \\hat{a}E_2 + \\hat{b}E_2^2 = 0\n$$\n$$\n\\hat{a}(E_1 + E_2) + \\hat{b}(E_1^2 + E_2^2) = E_1z_1 + E_2z_2 \\quad \\quad (2)\n$$\n\nNow we solve the system of normal equations (1) and (2) for $\\hat{a}$ and $\\hat{b}$. We substitute the given environmental values: $E_1 = -5$ and $E_2 = 5$.\nA significant simplification arises from the fact that the environments are symmetric about zero:\n$$\nE_1 + E_2 = -5 + 5 = 0\n$$\nSubstituting this into equation (1):\n$$\n2\\hat{a} + \\hat{b}(0) = z_1 + z_2 \\implies 2\\hat{a} = z_1 + z_2\n$$\nThis gives the estimator for the intercept:\n$$\n\\hat{a} = \\frac{z_1 + z_2}{2}\n$$\nThe estimator $\\hat{a}$ is simply the arithmetic mean of the observed phenotypes. This is a direct consequence of the experimental design where the mean of the environmental variables, $\\bar{E} = (E_1+E_2)/2$, is zero.\n\nNext, we substitute $E_1+E_2=0$ into equation (2):\n$$\n\\hat{a}(0) + \\hat{b}(E_1^2 + E_2^2) = E_1z_1 + E_2z_2 \\implies \\hat{b}(E_1^2 + E_2^2) = E_1z_1 + E_2z_2\n$$\nThis gives the estimator for the slope:\n$$\n\\hat{b} = \\frac{E_1z_1 + E_2z_2}{E_1^2 + E_2^2}\n$$\nIt is a useful check to show this is equivalent to the standard formula for the slope of a line passing through two points, $\\frac{z_2 - z_1}{E_2 - E_1}$. Since $E_1 = -E_2$, let $E_2 = E_0 = 5$. Then $E_1 = -E_0 = -5$.\n$$\n\\hat{b} = \\frac{(-E_0)z_1 + E_0 z_2}{(-E_0)^2 + E_0^2} = \\frac{E_0(z_2 - z_1)}{2E_0^2} = \\frac{z_2 - z_1}{2E_0}\n$$\nAnd since $E_2 - E_1 = E_0 - (-E_0) = 2E_0$, the formula is indeed identical. The derivation from the least squares principle is thus confirmed.\n\nNow we compute the numerical values using the given data: $z_1 = 6.4$ and $z_2 = 5.2$.\n$$\n\\hat{a} = \\frac{6.4 + 5.2}{2} = \\frac{11.6}{2} = 5.8\n$$\n$$\n\\hat{b} = \\frac{z_2 - z_1}{E_2 - E_1} = \\frac{5.2 - 6.4}{5 - (-5)} = \\frac{-1.2}{10} = -0.12\n$$\n\nThe biological interpretation of these parameters is as follows:\n- $\\hat{a}$: This is the intercept of the reaction norm, which is the predicted phenotypic value when the environmental variable $E$ is zero. In this problem, $E=0$ corresponds to the baseline temperature of $25$ degrees Celsius. Therefore, $\\hat{a} = 5.8$ milligrams is the estimated mass of the genotype when it develops at $25^\\circ \\text{C}$. It represents the phenotype in the central or reference environment of the study.\n\n- $\\hat{b}$: This is the slope of the reaction norm. It quantifies the sensitivity of the phenotype to changes in the environment, which is the definition of phenotypic plasticity. The value $\\hat{b} = -0.12$ milligrams per degree Celsius indicates that for every $1^\\circ \\text{C}$ increase in temperature from the baseline, the phenotype (mass) is predicted to decrease by $0.12$ milligrams. The fact that $\\hat{b}$ is non-zero demonstrates that the genotype is phenotypically plastic for this trait. The negative sign specifies the direction of this plasticity—a decrease in mass with an increase in temperature, a common pattern known as the temperature-size rule in many ectotherms.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 5.8  -0.12 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Measuring a reaction norm is the first step, but understanding its adaptive significance is the crucial next one. Plasticity is not universally beneficial; its value depends on producing the correct phenotype for a given environment. This practice  explores this concept by modeling a dramatic ecological scenario: the vulnerability of a \"naive\" prey to a novel, invasive predator. You will integrate a mechanistic model of a plastic defensive trait with a fitness function to see how an organism's evolved sensory limitations can lead to a fatal mismatch between its phenotype and the environment, providing a concrete example of maladaptive plasticity.",
            "id": "1871587",
            "problem": "A species of marine gastropod, having co-evolved with a native predatory crab, exhibits a phenotypically plastic defense mechanism. In the presence of chemical cues (kairomones) from the predator, the gastropod thickens its shell. This response is well-described by a Hill-like reaction norm for the final shell thickness, $T$, as a function of the perceived kairomone concentration, $C_p$:\n\n$$T(C_p) = T_0 + \\Delta T \\frac{C_p^n}{K_m^n + C_p^n}$$\n\nHere, $T_0$ is the basal shell thickness without predators, $\\Delta T$ is the maximum inducible increase in thickness, $K_m$ is the kairomone concentration that elicits a half-maximal response, and $n$ is the Hill coefficient describing the sensitivity of the response.\n\nRecently, a novel, invasive crab species has been introduced into the gastropod's habitat. The gastropods are considered \"naive\" to this new predator, as their chemoreceptors are not well-adapted to the invasive species' kairomones. The perceived concentration of the invasive kairomone is only a fraction, $\\epsilon$, of its true environmental concentration.\n\nThe probability of a gastropod surviving a single crushing attack from a crab, $P_s$, is determined by its shell thickness $T$ and the predator's claw strength $F$, given by the logistic function:\n\n$$P_s(T, F) = \\frac{1}{1 + \\exp(-\\gamma(T - F))}$$\n\nwhere $\\gamma$ is a parameter that defines the sharpness of the survival threshold.\n\nAssume the environmental concentration of kairomones is identical for both predator types when they are present, at a value of $C_{env}$. The native predator has a claw strength of $F_N$, while the more formidable invasive predator has a strength of $F_I$.\n\nGiven the following parameters:\n- Basal shell thickness, $T_0 = 2.0$ mm\n- Maximum inducible thickness increase, $\\Delta T = 1.5$ mm\n- Half-maximal response concentration, $K_m = 5.0$ ng/L\n- Hill coefficient, $n = 2$\n- Environmental kairomone concentration, $C_{env} = 10.0$ ng/L\n- Naivete factor (receptor inefficiency), $\\epsilon = 0.05$\n- Survival threshold sharpness, $\\gamma = 4.0$ mm$^{-1}$\n- Native predator claw strength, $F_N = 3.0$ mm\n- Invasive predator claw strength, $F_I = 3.2$ mm\n\nCalculate the ratio of the gastropod's survival probability against the invasive predator to its survival probability against the native predator, $P_{s,I} / P_{s,N}$. Round your final answer to three significant figures.",
            "solution": "The problem asks for the ratio of survival probabilities, $P_{s,I} / P_{s,N}$. To calculate this, we must first determine the shell thickness of the gastropod in the presence of each predator, and then use those thicknesses to find the respective survival probabilities.\n\n**Step 1: Calculate the shell thickness in the presence of the native predator ($T_N$).**\nThe native predator's kairomone is recognized effectively. Therefore, the perceived concentration $C_p$ is equal to the environmental concentration $C_{env}$.\n$$C_{p,N} = C_{env} = 10.0 \\text{ ng/L}$$\nWe use the reaction norm equation to find the induced shell thickness $T_N$:\n$$T_N = T_0 + \\Delta T \\frac{C_{p,N}^n}{K_m^n + C_{p,N}^n}$$\nSubstituting the given values:\n$$T_N = 2.0 + 1.5 \\frac{(10.0)^2}{(5.0)^2 + (10.0)^2} = 2.0 + 1.5 \\frac{100}{25 + 100} = 2.0 + 1.5 \\frac{100}{125}$$\n$$T_N = 2.0 + 1.5 \\times 0.8 = 2.0 + 1.2 = 3.2 \\text{ mm}$$\n\n**Step 2: Calculate the shell thickness in the presence of the invasive predator ($T_I$).**\nDue to the \"naivete\" of the gastropod, the perceived concentration of the invasive kairomone is only a fraction $\\epsilon$ of the environmental concentration.\n$$C_{p,I} = \\epsilon \\times C_{env} = 0.05 \\times 10.0 = 0.5 \\text{ ng/L}$$\nWe use the reaction norm equation again with this new perceived concentration to find the shell thickness $T_I$:\n$$T_I = T_0 + \\Delta T \\frac{C_{p,I}^n}{K_m^n + C_{p,I}^n}$$\nSubstituting the values:\n$$T_I = 2.0 + 1.5 \\frac{(0.5)^2}{(5.0)^2 + (0.5)^2} = 2.0 + 1.5 \\frac{0.25}{25 + 0.25} = 2.0 + 1.5 \\frac{0.25}{25.25}$$\n$$T_I = 2.0 + 1.5 \\times 0.00990099... \\approx 2.0 + 0.014851... \\approx 2.01485 \\text{ mm}$$\n\n**Step 3: Calculate the survival probability against the native predator ($P_{s,N}$).**\nThe survival probability depends on the shell thickness $T_N$ and the native predator's claw strength $F_N$.\n$$P_{s,N} = \\frac{1}{1 + \\exp(-\\gamma(T_N - F_N))}$$\nUsing the values $T_N = 3.2$ mm, $F_N = 3.0$ mm, and $\\gamma = 4.0$ mm$^{-1}$:\n$$P_{s,N} = \\frac{1}{1 + \\exp(-4.0(3.2 - 3.0))} = \\frac{1}{1 + \\exp(-4.0 \\times 0.2)} = \\frac{1}{1 + \\exp(-0.8)}$$\n\n**Step 4: Calculate the survival probability against the invasive predator ($P_{s,I}$).**\nThe survival probability depends on the shell thickness $T_I$ and the invasive predator's claw strength $F_I$.\n$$P_{s,I} = \\frac{1}{1 + \\exp(-\\gamma(T_I - F_I))}$$\nUsing the values $T_I \\approx 2.01485$ mm, $F_I = 3.2$ mm, and $\\gamma = 4.0$ mm$^{-1}$:\n$$P_{s,I} = \\frac{1}{1 + \\exp(-4.0(2.01485 - 3.2))} = \\frac{1}{1 + \\exp(-4.0 \\times -1.18515)} = \\frac{1}{1 + \\exp(4.7406)}$$\n\n**Step 5: Calculate the final ratio $P_{s,I} / P_{s,N}$.**\nWe now compute the ratio of the two probabilities:\n$$\\frac{P_{s,I}}{P_{s,N}} = \\frac{\\frac{1}{1 + \\exp(4.7406)}}{\\frac{1}{1 + \\exp(-0.8)}} = \\frac{1 + \\exp(-0.8)}{1 + \\exp(4.7406)}$$\nNow, we evaluate the exponential terms:\n$$\\exp(-0.8) \\approx 0.449329$$\n$$\\exp(4.7406) \\approx 114.496$$\nSubstitute these values back into the ratio expression:\n$$\\frac{P_{s,I}}{P_{s,N}} \\approx \\frac{1 + 0.449329}{1 + 114.496} = \\frac{1.449329}{115.496} \\approx 0.0125487$$\nRounding the result to three significant figures gives 0.0125.",
            "answer": "$$\\boxed{0.0125}$$"
        },
        {
            "introduction": "Having learned to measure plasticity and assess its fitness consequences, we now turn to the ultimate question: how do reaction norms evolve? This advanced practice  challenges you to step into the role of a theoretical evolutionary biologist. You will derive the conditions for an optimal *nonlinear* reaction norm by modeling the balance between the benefits of matching an environmental optimum and the potential costs of maintaining plasticity. By translating this theory into a computational algorithm, you will explore how the very shape of environmental variation—from a simple bell curve to a bimodal distribution—profoundly influences the evolution of reaction norm curvature.",
            "id": "2741861",
            "problem": "You are asked to formalize and analyze a model of phenotypic plasticity where a genotype expresses a nonlinear reaction norm across an environmental gradient. The expressed phenotype in environment $e$ is given by the quadratic reaction norm $z(e) = a + b e + c e^2$, where $a$, $b$, and $c$ are the intercept, slope, and curvature, respectively. The environment-dependent optimal phenotype is $\\phi(e) = \\phi_0 + \\phi_1 e + \\phi_2 e^2$. Viability selection acts through stabilizing selection on the deviation between $z(e)$ and $\\phi(e)$ with width $\\sigma_s$, and there are costs associated with maintaining $a$, $b$, and $c$.\n\nFundamental base and assumptions to use:\n- Natural selection increases mean Malthusian fitness. Assume genotypes are rare enough and mutational steps are small enough that, on the relevant timescale, the resident reaction norm parameters $(a,b,c)$ evolve by maximizing the expected log fitness $\\mathbb{E}_e[\\ln W(e)]$.\n- The instantaneous fitness in environment $e$ is \n$$\nW(e) = \\exp\\!\\left(-\\frac{(z(e) - \\phi(e))^2}{2\\sigma_s^2}\\right)\\,\\exp\\!\\left(-\\kappa_a a^2 - \\kappa_b b^2 - \\kappa_c c^2\\right),\n$$\nwhere $\\sigma_s  0$ and $\\kappa_a,\\kappa_b,\\kappa_c \\ge 0$.\n- The environmental variable $e$ is a real-valued random variable drawn independently in each generation from a fixed distribution with finite raw moments up to order $4$, i.e., $m_k = \\mathbb{E}[e^k]$ exists for $k \\in \\{1,2,3,4\\}$.\n\nYour tasks:\n- Starting only from the definitions above and the principle that evolution under the stated assumptions maximizes $\\mathbb{E}_e[\\ln W(e)]$, derive the first-order conditions that characterize stationary values $(a^\\star,b^\\star,c^\\star)$ in terms of the environmental moments $m_1, m_2, m_3, m_4$, the selection width $\\sigma_s$, the cost coefficients $\\kappa_a,\\kappa_b,\\kappa_c$, and the optimal phenotype coefficients $\\phi_0,\\phi_1,\\phi_2$.\n- Using those first-order conditions, design an algorithm that, given $(m_1,\\dots,m_4)$, $(\\phi_0,\\phi_1,\\phi_2)$, $(\\kappa_a,\\kappa_b,\\kappa_c)$, and $\\sigma_s$, returns the stationary curvature $c^\\star$.\n\nThe answer must be a complete, runnable program that evaluates $c^\\star$ for each of the following test cases. There are no physical units; all quantities are dimensionless. Angles do not appear. Your program must implement the exact environmental raw moments $m_k = \\mathbb{E}[e^k]$ for the specified distributions.\n\n- Test case $1$ (happy path):\n  - Environment: Gaussian with mean $0$ and variance $1$, denoted $\\mathcal{N}(0,1)$.\n  - Parameters: $(\\phi_0,\\phi_1,\\phi_2) = (0, 1, 0.2)$, $(\\kappa_a,\\kappa_b,\\kappa_c) = (0.01, 0.01, 0.01)$, $\\sigma_s = 0.5$.\n- Test case $2$ (different spread and tails):\n  - Environment: Uniform on $[-1,1]$.\n  - Parameters: $(\\phi_0,\\phi_1,\\phi_2) = (0, 1, 0.2)$, $(\\kappa_a,\\kappa_b,\\kappa_c) = (0.01, 0.01, 0.01)$, $\\sigma_s = 0.5$.\n- Test case $3$ (bimodality):\n  - Environment: Symmetric bimodal mixture $\\tfrac{1}{2}\\mathcal{N}(-1, 0.2^2) + \\tfrac{1}{2}\\mathcal{N}(1, 0.2^2)$.\n  - Parameters: $(\\phi_0,\\phi_1,\\phi_2) = (0, 0, 0.2)$, $(\\kappa_a,\\kappa_b,\\kappa_c) = (0.01, 0.01, 0.01)$, $\\sigma_s = 0.5$.\n- Test case $4$ (boundary condition: extremely narrow environment):\n  - Environment: Gaussian with mean $0$ and variance $0.1^2$, i.e., $\\mathcal{N}(0, 0.01)$.\n  - Parameters: $(\\phi_0,\\phi_1,\\phi_2) = (0, 1, 0.2)$, $(\\kappa_a,\\kappa_b,\\kappa_c) = (0.01, 0.01, 0.01)$, $\\sigma_s = 0.5$.\n- Test case $5$ (boundary condition: very high curvature cost with opposite-sign optimum curvature):\n  - Environment: Gaussian with mean $0$ and variance $1$, denoted $\\mathcal{N}(0,1)$.\n  - Parameters: $(\\phi_0,\\phi_1,\\phi_2) = (0, 1, -0.3)$, $(\\kappa_a,\\kappa_b,\\kappa_c) = (0.01, 0.01, 5.0)$, $\\sigma_s = 0.5$.\n\nEnvironmental raw moments to be used by your program:\n- If $e \\sim \\mathcal{N}(\\mu,\\sigma^2)$, then $m_1 = \\mu$, $m_2 = \\mu^2 + \\sigma^2$, $m_3 = \\mu^3 + 3\\mu\\sigma^2$, $m_4 = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4$.\n- If $e \\sim \\text{Uniform}[L,U]$, then $m_k = \\dfrac{U^{k+1} - L^{k+1}}{(k+1)(U-L)}$ for $k \\in \\{1,2,3,4\\}$.\n- If $e$ is the symmetric mixture $\\tfrac{1}{2}\\mathcal{N}(-\\mu,\\sigma^2) + \\tfrac{1}{2}\\mathcal{N}(\\mu,\\sigma^2)$, then $m_1 = 0$, $m_2 = \\mu^2 + \\sigma^2$, $m_3 = 0$, $m_4 = \\mu^4 + 6\\mu^2\\sigma^2 + 3\\sigma^4$.\n\nFinal output specification:\n- For each test case in the order given above, compute the stationary curvature $c^\\star$ as a floating-point number.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, e.g., $[x_1,x_2,x_3,x_4,x_5]$, where each $x_i$ is $c^\\star$ for test case $i$, rounded to exactly $6$ decimal places.",
            "solution": "The problem statement is valid. It is scientifically grounded in the theory of phenotypic plasticity, well-posed, objective, and provides all necessary information for a unique solution. I will proceed with the derivation and solution.\n\nThe task is to find the stationary values $(a^\\star, b^\\star, c^\\star)$ of the reaction norm parameters that maximize the expected log-fitness, $\\mathbb{E}_e[\\ln W(e)]$.\n\nThe fitness function in environment $e$ is given by:\n$$W(e) = \\exp\\!\\left(-\\frac{(z(e) - \\phi(e))^2}{2\\sigma_s^2}\\right)\\,\\exp\\!\\left(-\\kappa_a a^2 - \\kappa_b b^2 - \\kappa_c c^2\\right)$$\nwhere the reaction norm is $z(e) = a + b e + c e^2$ and the optimal phenotype is $\\phi(e) = \\phi_0 + \\phi_1 e + \\phi_2 e^2$. The parameters $\\kappa_a, \\kappa_b, \\kappa_c \\ge 0$ represent costs of plasticity and $\\sigma_s  0$ defines the strength of stabilizing selection.\n\nThe logarithm of the fitness is:\n$$ \\ln W(e) = -\\frac{(z(e) - \\phi(e))^2}{2\\sigma_s^2} - \\kappa_a a^2 - \\kappa_b b^2 - \\kappa_c c^2 $$\nWe must maximize the expectation of this quantity over the environmental distribution of $e$, denoted by $F(a, b, c) = \\mathbb{E}_e[\\ln W(e)]$. By linearity of expectation:\n$$ F(a,b,c) = \\mathbb{E}_e\\left[ -\\frac{(z(e) - \\phi(e))^2}{2\\sigma_s^2} \\right] - \\mathbb{E}_e\\left[\\kappa_a a^2 + \\kappa_b b^2 + \\kappa_c c^2\\right] $$\nThe cost parameters and reaction norm parameters are constant with respect to $e$, so the expectation of the cost term is the term itself.\n$$ F(a,b,c) = -\\frac{1}{2\\sigma_s^2} \\mathbb{E}_e\\left[ (z(e) - \\phi(e))^2 \\right] - \\kappa_a a^2 - \\kappa_b b^2 - \\kappa_c c^2 $$\nLet the deviation between the phenotype and the optimum be $\\Delta(e) = z(e) - \\phi(e)$. Substituting the polynomials for $z(e)$ and $\\phi(e)$, we get:\n$$ \\Delta(e) = (a - \\phi_0) + (b - \\phi_1)e + (c - \\phi_2)e^2 $$\nWe expand the squared deviation term:\n$$ \\Delta(e)^2 = \\left((a - \\phi_0) + (b - \\phi_1)e + (c - \\phi_2)e^2\\right)^2 $$\n$$ \\Delta(e)^2 = (a - \\phi_0)^2 + (b - \\phi_1)^2 e^2 + (c - \\phi_2)^2 e^4 + 2(a - \\phi_0)(b - \\phi_1)e + 2(a - \\phi_0)(c - \\phi_2)e^2 + 2(b - \\phi_1)(c - \\phi_2)e^3 $$\nNow, we take the expectation of $\\Delta(e)^2$ over the distribution of $e$. Using the definition of raw moments $m_k = \\mathbb{E}[e^k]$, and noting that $m_0 = \\mathbb{E}[e^0] = 1$:\n$$ \\mathbb{E}_e[\\Delta(e)^2] = (a-\\phi_0)^2 m_0 + (b-\\phi_1)^2 m_2 + (c-\\phi_2)^2 m_4 + 2(a-\\phi_0)(b-\\phi_1)m_1 + 2(a-\\phi_0)(c-\\phi_2)m_2 + 2(b-\\phi_1)(c-\\phi_2)m_3 $$\nSubstituting this back into the expression for $F(a,b,c)$:\n$$ F(a,b,c) = -\\frac{1}{2\\sigma_s^2} \\left[ (a-\\phi_0)^2 + \\dots \\right] - \\kappa_a a^2 - \\kappa_b b^2 - \\kappa_c c^2 $$\nTo find the stationary point $(a^\\star, b^\\star, c^\\star)$, we set the partial derivatives of $F(a, b, c)$ with respect to $a$, $b$, and $c$ to zero.\n\nThe partial derivative with respect to $a$ is:\n$$ \\frac{\\partial F}{\\partial a} = -\\frac{1}{2\\sigma_s^2} \\left[ 2(a-\\phi_0) + 2(b-\\phi_1)m_1 + 2(c-\\phi_2)m_2 \\right] - 2\\kappa_a a = 0 $$\nMultiplying by $-\\sigma_s^2$ and rearranging for the stationary values yields the first first-order condition:\n$$ (a^\\star-\\phi_0) + (b^\\star-\\phi_1)m_1 + (c^\\star-\\phi_2)m_2 + 2\\sigma_s^2 \\kappa_a a^\\star = 0 $$\n$$ a^\\star(1 + 2\\sigma_s^2 \\kappa_a) + b^\\star m_1 + c^\\star m_2 = \\phi_0 + \\phi_1 m_1 + \\phi_2 m_2 $$\n\nThe partial derivative with respect to $b$ is:\n$$ \\frac{\\partial F}{\\partial b} = -\\frac{1}{2\\sigma_s^2} \\left[ 2(b-\\phi_1)m_2 + 2(a-\\phi_0)m_1 + 2(c-\\phi_2)m_3 \\right] - 2\\kappa_b b = 0 $$\nRearranging gives the second condition:\n$$ (a^\\star-\\phi_0)m_1 + (b^\\star-\\phi_1)m_2 + (c^\\star-\\phi_2)m_3 + 2\\sigma_s^2 \\kappa_b b^\\star = 0 $$\n$$ a^\\star m_1 + b^\\star(m_2 + 2\\sigma_s^2 \\kappa_b) + c^\\star m_3 = \\phi_0 m_1 + \\phi_1 m_2 + \\phi_2 m_3 $$\n\nThe partial derivative with respect to $c$ is:\n$$ \\frac{\\partial F}{\\partial c} = -\\frac{1}{2\\sigma_s^2} \\left[ 2(c-\\phi_2)m_4 + 2(a-\\phi_0)m_2 + 2(b-\\phi_1)m_3 \\right] - 2\\kappa_c c = 0 $$\nRearranging gives the third condition:\n$$ (a^\\star-\\phi_0)m_2 + (b^\\star-\\phi_1)m_3 + (c^\\star-\\phi_2)m_4 + 2\\sigma_s^2 \\kappa_c c^\\star = 0 $$\n$$ a^\\star m_2 + b^\\star m_3 + c^\\star(m_4 + 2\\sigma_s^2 \\kappa_c) = \\phi_0 m_2 + \\phi_1 m_3 + \\phi_2 m_4 $$\n\nThese three linear equations for $(a^\\star, b^\\star, c^\\star)$ can be written in matrix form $\\mathbf{M} \\mathbf{x} = \\mathbf{v}$, where $\\mathbf{x} = [a^\\star, b^\\star, c^\\star]^T$. The coefficient matrix $\\mathbf{M}$ is:\n$$\n\\mathbf{M} = \\begin{pmatrix}\n1 + 2\\sigma_s^2 \\kappa_a  m_1  m_2 \\\\\nm_1  m_2 + 2\\sigma_s^2 \\kappa_b  m_3 \\\\\nm_2  m_3  m_4 + 2\\sigma_s^2 \\kappa_c\n\\end{pmatrix}\n$$\nThe vector $\\mathbf{v}$ on the right-hand side is:\n$$\n\\mathbf{v} = \\begin{pmatrix}\n\\phi_0 + \\phi_1 m_1 + \\phi_2 m_2 \\\\\n\\phi_0 m_1 + \\phi_1 m_2 + \\phi_2 m_3 \\\\\n\\phi_0 m_2 + \\phi_1 m_3 + \\phi_2 m_4\n\\end{pmatrix}\n$$\nThe matrix $\\mathbf{M}$ is symmetric. Since the moment matrix is a Gram matrix and thus positive semi-definite, and the cost matrix is diagonal with non-negative entries (strictly positive for the test cases), $\\mathbf{M}$ is positive definite and thus invertible, guaranteeing a unique solution.\n\nThe algorithm to find $c^\\star$ is:\n$1$. For each test case, compute the environmental moments $m_1, m_2, m_3, m_4$.\n$2$. Construct the $3 \\times 3$ matrix $\\mathbf{M}$ and the $3 \\times 1$ vector $\\mathbf{v}$ using the derived formulas.\n$3$. Solve the linear system $\\mathbf{M} \\mathbf{x} = \\mathbf{v}$ for the vector of stationary parameters $\\mathbf{x} = [a^\\star, b^\\star, c^\\star]^T$.\n$4$. The result is the third component of the solution vector, $c^\\star$.\nThis constitutes the complete theoretical basis for the computational solution.",
            "answer": "```python\nimport numpy as np\n\ndef get_gaussian_moments(mu, sigma_sq):\n    \"\"\"\n    Calculates the first four raw moments for a Gaussian distribution \n    N(mu, sigma_sq).\n    \"\"\"\n    m1 = mu\n    m2 = mu**2 + sigma_sq\n    m3 = mu**3 + 3 * mu * sigma_sq\n    m4 = mu**4 + 6 * mu**2 * sigma_sq + 3 * sigma_sq**2\n    return m1, m2, m3, m4\n\ndef get_uniform_moments(L, U):\n    \"\"\"\n    Calculates the first four raw moments for a Uniform distribution on [L, U].\n    \"\"\"\n    moments = []\n    for k in range(1, 5):\n        if abs(U - L)  1e-12: # Handles the case of a point mass\n            mk = L**k\n        else:\n            mk = (U**(k + 1) - L**(k + 1)) / ((k + 1) * (U - L))\n        moments.append(mk)\n    return tuple(moments)\n\ndef get_bimodal_gaussian_moments(mu, sigma_sq):\n    \"\"\"\n    Calculates the first four raw moments for a symmetric bimodal Gaussian \n    mixture distribution 0.5*N(-mu, sigma_sq) + 0.5*N(mu, sigma_sq).\n    \"\"\"\n    m1 = 0.0\n    m2 = mu**2 + sigma_sq\n    m3 = 0.0\n    m4 = mu**4 + 6 * mu**2 * sigma_sq + 3 * sigma_sq**2\n    return m1, m2, m3, m4\n\ndef solve_for_c_star(phi, kappa, sigma_s, moments):\n    \"\"\"\n    Solves the linear system for the stationary reaction norm parameters \n    and returns the curvature c_star.\n    \"\"\"\n    phi0, phi1, phi2 = phi\n    kappa_a, kappa_b, kappa_c = kappa\n    m1, m2, m3, m4 = moments\n    m0 = 1.0\n    \n    sigma_s_sq = sigma_s**2\n\n    # Construct the matrix M based on the first-order conditions\n    M = np.array([\n        [m0 + 2 * sigma_s_sq * kappa_a, m1, m2],\n        [m1, m2 + 2 * sigma_s_sq * kappa_b, m3],\n        [m2, m3, m4 + 2 * sigma_s_sq * kappa_c]\n    ], dtype=np.float64)\n\n    # Construct the vector v based on the first-order conditions\n    v = np.array([\n        phi0 * m0 + phi1 * m1 + phi2 * m2,\n        phi0 * m1 + phi1 * m2 + phi2 * m3,\n        phi0 * m2 + phi1 * m3 + phi2 * m4\n    ], dtype=np.float64)\n\n    # Solve the system M * x = v for x = [a_star, b_star, c_star]\n    try:\n        x = np.linalg.solve(M, v)\n        c_star = x[2]\n        return c_star\n    except np.linalg.LinAlgError:\n        # This case is not expected given the problem's constraints\n        return np.nan\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (happy path)\n        {'phi': (0.0, 1.0, 0.2), 'kappa': (0.01, 0.01, 0.01), 'sigma_s': 0.5, 'env': ('gaussian', {'mu': 0.0, 'sigma_sq': 1.0})},\n        # Test case 2 (different spread and tails)\n        {'phi': (0.0, 1.0, 0.2), 'kappa': (0.01, 0.01, 0.01), 'sigma_s': 0.5, 'env': ('uniform', {'L': -1.0, 'U': 1.0})},\n        # Test case 3 (bimodality)\n        {'phi': (0.0, 0.0, 0.2), 'kappa': (0.01, 0.01, 0.01), 'sigma_s': 0.5, 'env': ('bimodal', {'mu': 1.0, 'sigma_sq': 0.2**2})},\n        # Test case 4 (boundary condition: extremely narrow environment)\n        {'phi': (0.0, 1.0, 0.2), 'kappa': (0.01, 0.01, 0.01), 'sigma_s': 0.5, 'env': ('gaussian', {'mu': 0.0, 'sigma_sq': 0.1**2})},\n        # Test case 5 (boundary condition: very high curvature cost)\n        {'phi': (0.0, 1.0, -0.3), 'kappa': (0.01, 0.01, 5.0), 'sigma_s': 0.5, 'env': ('gaussian', {'mu': 0.0, 'sigma_sq': 1.0})},\n    ]\n\n    results = []\n    for case in test_cases:\n        env_type, env_params = case['env']\n        \n        if env_type == 'gaussian':\n            moments = get_gaussian_moments(**env_params)\n        elif env_type == 'uniform':\n            moments = get_uniform_moments(**env_params)\n        elif env_type == 'bimodal':\n            moments = get_bimodal_gaussian_moments(**env_params)\n        else:\n            # Should not be reached with the defined test cases\n            raise ValueError(f\"Unknown environment type: {env_type}\")\n            \n        c_star = solve_for_c_star(case['phi'], case['kappa'], case['sigma_s'], moments)\n        results.append(c_star)\n        \n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}