{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze evolutionary patterns within the fossil record, we must first establish a reliable timeline. This practice grounds you in the fundamental principles of radiometric dating, the cornerstone of modern geochronology. By working through a hypothetical scenario involving the Rubidium-Strontium (Rb-Sr) isotopic system, you will apply the core radioactive decay equation to calculate an absolute age and use stratigraphic principles to constrain the age of overlying fossils .",
            "id": "2706735",
            "problem": "A volcanic ash bed that lies directly beneath a fossil-bearing sedimentary unit within a conformable stratigraphic succession has been analyzed using the rubidium–strontium (Rb–Sr) system. The measured present-day isotopic ratios for a whole-rock aliquot from the ash are ${}^{87}\\text{Rb}/{}^{87}\\text{Sr} = 0.25$ and ${}^{87}\\text{Sr}/{}^{86}\\text{Sr} = 0.7100$. An independent isochron constructed from co-genetic minerals constrains the initial strontium isotopic composition of the ash at the time of deposition to be ${}^{87}\\text{Sr}/{}^{86}\\text{Sr} = 0.6990$. The radioactive decay constant for ${}^{87}\\text{Rb}$ is $\\lambda = 1.42 \\times 10^{-11}\\,\\mathrm{yr}^{-1}$. Using only fundamental radioactive decay principles and isotope mass-balance relative to a stable reference isotope, compute the crystallization age of the ash bed. State, based on superposition, whether this absolute age constrains a maximum or a minimum age for the overlying fossil-bearing unit, and justify your choice in one sentence. Round your numerical age to $2$ significant figures and express the age in gigayears (Ga). Your final reported answer must be only the numerical value in Ga.",
            "solution": "The problem requires the calculation of the crystallization age of a volcanic ash bed using the rubidium-strontium (Rb-Sr) radiometric dating method and an analysis of its stratigraphic relationship to an overlying fossil-bearing unit.\n\nThe fundamental principle is the radioactive decay of the parent isotope ${}^{87}\\text{Rb}$ to the daughter isotope ${}^{87}\\text{Sr}$ via beta decay. The number of parent atoms remaining at a time $t$, denoted $N_{^{87}\\text{Rb}}(t)$, is related to the initial number of atoms $N_{^{87}\\text{Rb}}(0)$ by the exponential decay law:\n$$ N_{^{87}\\text{Rb}}(t) = N_{^{87}\\text{Rb}}(0) \\exp(-\\lambda t) $$\nwhere $\\lambda$ is the decay constant for ${}^{87}\\text{Rb}$.\n\nThe number of radiogenic daughter atoms, $D^*$ (${}^{87}\\text{Sr}_{\\text{rad}}$), produced by this decay is the decrease in parent atoms:\n$$ D^* = N_{^{87}\\text{Rb}}(0) - N_{^{87}\\text{Rb}}(t) $$\nBy rearranging the decay law, $N_{^{87}\\text{Rb}}(0) = N_{^{87}\\text{Rb}}(t) \\exp(\\lambda t)$, we can express $D^*$ in terms of the present-day number of parent atoms:\n$$ D^* = N_{^{87}\\text{Rb}}(t) \\exp(\\lambda t) - N_{^{87}\\text{Rb}}(t) = N_{^{87}\\text{Rb}}(t)(\\exp(\\lambda t) - 1) $$\n\nThe total number of ${}^{87}\\text{Sr}$ atoms present today, $N_{^{87}\\text{Sr}}(t)$, is the sum of the initially present ${}^{87}\\text{Sr}$ atoms, $N_{^{87}\\text{Sr}}(0)$, and the radiogenic atoms $D^*$ produced since crystallization:\n$$ N_{^{87}\\text{Sr}}(t) = N_{^{87}\\text{Sr}}(0) + N_{^{87}\\text{Rb}}(t)(\\exp(\\lambda t) - 1) $$\n\nIn isotope geochemistry, it is standard practice to normalize these absolute abundances to a stable, non-radiogenic isotope of strontium, ${}^{86}\\text{Sr}$, whose abundance $N_{^{86}\\text{Sr}}$ is constant over time. Dividing the equation by $N_{^{86}\\text{Sr}}$ yields the standard isochron equation in terms of measurable isotope ratios:\n$$ \\frac{N_{^{87}\\text{Sr}}(t)}{N_{^{86}\\text{Sr}}} = \\frac{N_{^{87}\\text{Sr}}(0)}{N_{^{86}\\text{Sr}}} + \\frac{N_{^{87}\\text{Rb}}(t)}{N_{^{86}\\text{Sr}}} (\\exp(\\lambda t) - 1) $$\nUsing a more compact notation where $(\\cdot)_p$ indicates the present-day ratio and $(\\cdot)_0$ indicates the initial ratio at time $t=0$, this becomes:\n$$ \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p = \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0 + \\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p (\\exp(\\lambda t) - 1) $$\nThe problem provides the following data:\nThe present-day measured ratio $(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}})_p = 0.7100$.\nThe initial ratio $(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}})_0 = 0.6990$.\nThe decay constant $\\lambda = 1.42 \\times 10^{-11}\\,\\text{yr}^{-1}$.\nThe present-day measured ratio $(\\frac{^{87}\\text{Rb}}{^{87}\\text{Sr}})_p = 0.25$.\n\nThe isochron equation requires the present-day parent-to-stable-daughter-isotope ratio, $(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}})_p$. This can be derived from the given ratios through algebraic manipulation:\n$$ \\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p = \\left(\\frac{^{87}\\text{Rb}}{^{87}\\text{Sr}}\\right)_p \\times \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p $$\nSubstituting the numerical values:\n$$ \\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p = 0.25 \\times 0.7100 = 0.1775 $$\nNow we have all necessary components to solve for the age, $t$. Let's rearrange the isochron equation to isolate $t$:\n$$ \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p - \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0 = \\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p (\\exp(\\lambda t) - 1) $$\n$$ \\frac{\\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p - \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0}{\\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p} = \\exp(\\lambda t) - 1 $$\n$$ 1 + \\frac{\\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p - \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0}{\\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p} = \\exp(\\lambda t) $$\nTaking the natural logarithm of both sides:\n$$ \\ln\\left(1 + \\frac{\\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p - \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0}{\\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p}\\right) = \\lambda t $$\nFinally, solving for $t$:\n$$ t = \\frac{1}{\\lambda} \\ln\\left(1 + \\frac{\\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_p - \\left(\\frac{^{87}\\text{Sr}}{^{86}\\text{Sr}}\\right)_0}{\\left(\\frac{^{87}\\text{Rb}}{^{86}\\text{Sr}}\\right)_p}\\right) $$\nSubstituting the numerical values into this expression:\n$$ t = \\frac{1}{1.42 \\times 10^{-11}\\,\\text{yr}^{-1}} \\ln\\left(1 + \\frac{0.7100 - 0.6990}{0.1775}\\right) $$\n$$ t = \\frac{1}{1.42 \\times 10^{-11}\\,\\text{yr}^{-1}} \\ln\\left(1 + \\frac{0.011}{0.1775}\\right) $$\n$$ t = \\frac{1}{1.42 \\times 10^{-11}\\,\\text{yr}^{-1}} \\ln(1 + 0.0619718...) $$\n$$ t = \\frac{1}{1.42 \\times 10^{-11}\\,\\text{yr}^{-1}} \\ln(1.0619718...) $$\n$$ t = \\frac{0.060126...}{1.42 \\times 10^{-11}\\,\\text{yr}^{-1}} \\approx 4.234 \\times 10^9\\,\\text{years} $$\nThe problem requires the age to be expressed in gigayears (Ga), where $1\\,\\text{Ga} = 10^9\\,\\text{years}$, and rounded to $2$ significant figures.\n$$ t \\approx 4.2\\,\\text{Ga} $$\nRegarding the stratigraphic constraint, the principle of superposition states that in a conformable sequence of strata, any given layer is younger than the one upon which it was deposited. Since the fossil-bearing sedimentary unit lies directly on top of the dated volcanic ash bed, the fossils must be younger than the ash. Therefore, the absolute age of the ash bed provides a maximum age for the overlying fossils.\n\nThe justification is as follows: The principle of superposition dictates that the overlying fossil-bearing unit is younger than the dated ash bed beneath it, thus the ash's age sets a maximum boundary for the age of the fossils.",
            "answer": "$$\\boxed{4.2}$$"
        },
        {
            "introduction": "The fossil record archives long-term sequences of morphological data, enabling us to test specific hypotheses about the *mode* of evolution. This exercise challenges you to compare two competing models for a trait time-series: stasis, where a trait fluctuates around a stable mean ($\\mu$), and an unbiased random walk, where changes accumulate over time. You will use the Akaike Information Criterion (AIC) to select the best-fitting model, a core practice in quantitative paleobiology for moving from description to rigorous hypothesis testing .",
            "id": "2706707",
            "problem": "You are given stratigraphically ordered time-series of mean shell size measurements of a single lineage, measured in millimeters and sampled at known stratigraphic ages measured in millions of years (Myr). You must implement two evolutionary models for trait change between successive stratigraphic horizons and select the model with the better fit based on the Akaike Information Criterion (AIC). The two models are defined as follows.\n\nModel S (stasis): Each observation $x_i$ is an independent realization from a Normal distribution with unknown constant mean $\\mu$ and variance $\\sigma^2$, that is, $x_i \\sim \\mathcal{N}(\\mu,\\sigma^2)$ for $i=1,\\dots,n$.\n\nModel RW (unbiased random walk in continuous time): The increments $d_i = x_i - x_{i-1}$ are independent and Normally distributed with mean $0$ and variance proportional to the elapsed time between samples, that is, $d_i \\sim \\mathcal{N}\\!\\left(0, v \\,\\Delta t_i\\right)$ for $i=2,\\dots,n$, where $\\Delta t_i = t_i - t_{i-1} > 0$ is the time between samples in Myr and $v$ is the unknown diffusion variance per Myr.\n\nAssume no additional observation error. Use Maximum Likelihood to estimate parameters for each model given the data. Use the Akaike Information Criterion (AIC), defined as $\\mathrm{AIC} = 2k - 2\\ln\\hat{L}$ where $k$ is the number of estimated parameters and $\\hat{L}$ is the maximized likelihood under the model, to select the better model (smaller AIC is better). For Model S, treat $k$ as $k_S = 2$ for parameters $\\mu$ and $\\sigma^2$. For Model RW, treat $k$ as $k_{RW} = 1$ for the diffusion variance $v$; the initial observation $x_1$ is treated as given (not a parameter).\n\nIn the event that the two AIC values are equal to within an absolute tolerance of $10^{-9}$, select the model with fewer parameters (that is, Model RW). Otherwise, select the model with the smaller AIC. You do not need to report parameter estimates; only report which model is selected per test case.\n\nAll physical quantities associated with input data carry units as specified, but your output is unitless. Ensure all logarithms are natural logarithms.\n\nImplement a program that evaluates the following test suite. For each test case, compute which model is preferred by AIC and output an integer code: output $0$ to indicate Model S (stasis) is selected, and output $1$ to indicate Model RW (unbiased random walk) is selected.\n\nTest suite:\n- Case $1$ (equal spacing): shell sizes (in mm) $[10, 10, 11, 10, 12, 12, 12, 13, 13, 13]$ at equally spaced stratigraphic levels separated by $\\Delta t = 0.5$ Myr. That is, times (in Myr) $t = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5]$ and $x = [10, 10, 11, 10, 12, 12, 12, 13, 13, 13]$.\n- Case $2$ (near-stasis, modest noise): times (in Myr) $t = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4]$ and shell sizes (in mm) $x = [10.0, 10.2, 9.9, 10.1, 10.0, 10.1, 9.95, 10.05]$.\n- Case $3$ (boundary length, two points): times (in Myr) $t = [0.0, 1.0]$ and shell sizes (in mm) $x = [5.0, 7.0]$.\n- Case $4$ (variable spacing, near-stasis): times (in Myr) $t = [0.0, 0.1, 0.6, 1.6, 2.6]$ and shell sizes (in mm) $x = [100.0, 100.1, 100.05, 100.0, 100.05]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above. For example, an output of the form $[m_1,m_2,m_3,m_4]$ where each $m_i \\in \\{0,1\\}$ indicates the selected model for case $i$.\n\nThe final output is a single line with the list of integers and no additional text.",
            "solution": "The problem presented is a valid exercise in statistical model selection, a fundamental task in the quantitative sciences. It requires the comparison of two standard models for evolutionary time-series data—stasis and unbiased random walk—using the Akaike Information Criterion (AIC). The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution. We will proceed by deriving the maximum likelihood estimators and AIC expressions for each model.\n\nLet the data be a time-series of $n$ trait measurements $\\mathbf{x} = \\{x_1, x_2, \\dots, x_n\\}$ at corresponding time points $\\mathbf{t} = \\{t_1, t_2, \\dots, t_n\\}$.\n\n**Model S: Stasis**\n\nThis model posits that the trait values are independent and identically distributed random draws from a single Normal distribution with a constant mean $\\mu$ and variance $\\sigma^2$. The model is expressed as:\n$$ x_i \\sim \\mathcal{N}(\\mu, \\sigma^2) \\quad \\text{for } i = 1, \\dots, n $$\nThe likelihood function $L_S(\\mu, \\sigma^2; \\mathbf{x})$ is the product of the individual probability densities:\n$$ L_S(\\mu, \\sigma^2; \\mathbf{x}) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right) $$\nThe log-likelihood function is therefore:\n$$ \\ln L_S(\\mu, \\sigma^2; \\mathbf{x}) = -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i - \\mu)^2 $$\nTo find the maximum likelihood estimators (MLEs) for $\\mu$ and $\\sigma^2$, we take the partial derivatives of $\\ln L_S$ with respect to each parameter and set them to zero. This procedure yields the sample mean as the MLE for $\\mu$ and the sample variance (with denominator $n$) as the MLE for $\\sigma^2$:\n$$ \\hat{\\mu} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n$$ \\hat{\\sigma}^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\hat{\\mu})^2 $$\nSubstituting these estimators back into the log-likelihood function gives the maximized log-likelihood, $\\ln\\hat{L}_S$:\n$$ \\ln \\hat{L}_S = -\\frac{n}{2}\\ln(2\\pi\\hat{\\sigma}^2) - \\frac{1}{2\\hat{\\sigma}^2} \\sum_{i=1}^{n}(x_i - \\hat{\\mu})^2 = -\\frac{n}{2}\\ln(2\\pi\\hat{\\sigma}^2) - \\frac{n\\hat{\\sigma}^2}{2\\hat{\\sigma}^2} $$\n$$ \\ln \\hat{L}_S = -\\frac{n}{2} \\left[ \\ln(2\\pi\\hat{\\sigma}^2) + 1 \\right] $$\nThe number of estimated parameters for this model is $k_S = 2$ (for $\\mu$ and $\\sigma^2$). The AIC is calculated as:\n$$ \\mathrm{AIC}_S = 2k_S - 2\\ln\\hat{L}_S = 4 - 2\\ln\\hat{L}_S $$\n\n**Model RW: Unbiased Random Walk**\n\nThis model describes the increments between successive observations, $d_i = x_i - x_{i-1}$, as independent random draws from a Normal distribution with mean $0$ and variance proportional to the time elapsed, $\\Delta t_i = t_i - t_{i-1}$. The model is:\n$$ d_i \\sim \\mathcal{N}(0, v\\Delta t_i) \\quad \\text{for } i = 2, \\dots, n $$\nHere, $v$ is the diffusion variance parameter. The likelihood function $L_{RW}(v; \\mathbf{d})$ is constructed from the $n-1$ increments:\n$$ L_{RW}(v; \\mathbf{d}) = \\prod_{i=2}^{n} \\frac{1}{\\sqrt{2\\pi v\\Delta t_i}} \\exp\\left(-\\frac{d_i^2}{2v\\Delta t_i}\\right) $$\nThe log-likelihood function is:\n$$ \\ln L_{RW}(v; \\mathbf{d}) = \\sum_{i=2}^{n} \\left[ -\\frac{1}{2}\\ln(2\\pi v\\Delta t_i) - \\frac{d_i^2}{2v\\Delta t_i} \\right] $$\n$$ \\ln L_{RW}(v; \\mathbf{d}) = -\\frac{n-1}{2}\\ln(v) - \\frac{1}{2v} \\sum_{i=2}^{n} \\frac{d_i^2}{\\Delta t_i} - \\frac{1}{2} \\sum_{i=2}^{n} \\ln(2\\pi\\Delta t_i) $$\nDifferentiating with respect to $v$ and setting the result to zero gives the MLE for $v$:\n$$ \\hat{v} = \\frac{1}{n-1} \\sum_{i=2}^{n} \\frac{d_i^2}{\\Delta t_i} = \\frac{1}{n-1} \\sum_{i=2}^{n} \\frac{(x_i - x_{i-1})^2}{t_i - t_{i-1}} $$\nThe maximized log-likelihood, $\\ln\\hat{L}_{RW}$, is obtained by substituting $\\hat{v}$ back into the log-likelihood function. This can be expressed in several forms; a direct computational form is:\n$$ \\ln \\hat{L}_{RW} = \\sum_{i=2}^{n} \\left[ -\\frac{1}{2}\\ln(2\\pi\\hat{v}\\Delta t_i) - \\frac{d_i^2}{2\\hat{v}\\Delta t_i} \\right] $$\nA simplified analytical form, useful for verification, is:\n$$ \\ln \\hat{L}_{RW} = -\\frac{n-1}{2}(1 + \\ln(2\\pi\\hat{v})) - \\frac{1}{2}\\sum_{i=2}^{n}\\ln(\\Delta t_i) $$\nThe number of estimated parameters is $k_{RW} = 1$ (for $v$, as $x_1$ is given). The AIC is:\n$$ \\mathrm{AIC}_{RW} = 2k_{RW} - 2\\ln\\hat{L}_{RW} = 2 - 2\\ln\\hat{L}_{RW} $$\n\n**Model Selection**\n\nThe preferred model is the one with the lower AIC value. In the case of a tie, defined as $|\\mathrm{AIC}_S - \\mathrm{AIC}_{RW}| \\le 10^{-9}$, the principle of parsimony dictates selecting the model with fewer parameters. Since $k_{RW} = 1 < k_S = 2$, Model RW is chosen in a tie. This leads to the following decision rule: select Model S if and only if its AIC score is significantly lower than that of Model RW; otherwise, select Model RW. Computationally, this is:\n- If $\\mathrm{AIC}_S < \\mathrm{AIC}_{RW} - 10^{-9}$, select Model S (output $0$).\n- Otherwise, select Model RW (output $1$).\n\nThe provided test cases will be evaluated according to these derived formulae.",
            "answer": "[1,0,1,0]"
        },
        {
            "introduction": "Apparent changes in species richness over geological time can be deeply misleading if sampling intensity varies between rock units. This hands-on computational problem introduces Shareholder Quorum Subsampling (SQS), a powerful method for standardizing diversity measures based on sample completeness ($q$) rather than raw specimen counts. By implementing this algorithm, you will gain practical experience in creating more robust and equitable comparisons of biodiversity that account for the pervasive biases inherent in the fossil record .",
            "id": "2706734",
            "problem": "You are studying diversity dynamics across stratigraphic intervals in the fossil record, where differences in sampling intensity bias raw species richness. A principled way to control for this is Shareholder Quorum Subsampling (SQS), which targets a fixed coverage (the cumulative share of individuals belonging to the species already detected) rather than a fixed number of sampled individuals. Your task is to implement a deterministic, expected-value variant of SQS suitable for reproducible computation.\n\nStart from the following foundational bases:\n- Sampling in paleontological assemblages is incomplete and uneven across stratigraphic intervals. The probability of detecting a species is related to its relative frequency in the assemblage.\n- Define species counts as a multiset of nonnegative integers $\\{x_1,\\dots,x_S\\}$ representing the observed abundance of each species in a given stratigraphic interval, with total individuals $N = \\sum_{i=1}^{S} x_i$ and relative frequencies $p_i = x_i / N$ for all species with $x_i &gt; 0$.\n- Define coverage, in the sense of Good's concept of sample coverage, as the probability mass of the assemblage accounted for by species already detected. In SQS, a quorum $q \\in [0,1)$ specifies the target coverage to be attained.\n\nDeterministic expected SQS algorithm to implement:\n- Given a multiset of counts $\\{x_i\\}$, remove any zero counts to retain species with $x_i &gt; 0$.\n- Compute $N = \\sum_{i} x_i$ and the corresponding relative frequencies $p_i = x_i / N$.\n- Sort $\\{p_i\\}$ in descending order to form a sequence $(p_{(1)}, p_{(2)}, \\dots, p_{(S')})$, where $S'$ is the number of species with $x_i &gt; 0$.\n- Initialize cumulative coverage $c \\leftarrow 0$ and subsampled diversity $R \\leftarrow 0$.\n- Traverse the sorted list. For each $p_{(j)}$:\n  - If $c + p_{(j)} \\le q$, then set $c \\leftarrow c + p_{(j)}$ and $R \\leftarrow R + 1$ (include the species completely).\n  - Otherwise, include a fractional component of the last species: set the fraction $f \\leftarrow (q - c)/p_{(j)}$ with $f \\in (0,1)$, then set $R \\leftarrow R + f$ and $c \\leftarrow q$, and stop.\n- The algorithm returns the subsampled diversity $R$ and the estimated coverage $\\widehat{C} = c$. By construction, $\\widehat{C} = q$ when $q \\in [0,1)$ and at least one species is present. If $q = 0$, then $R = 0$ and $\\widehat{C} = 0$. If the input has no individuals (that is, $N = 0$), return $R = 0$ and $\\widehat{C} = 0$.\n\nImplement the algorithm as a program that, for each test case below, computes and returns:\n- The subsampled diversity $R$ (a real number that can be fractional due to the partially included last species).\n- The estimated coverage $\\widehat{C}$.\n\nImportant requirements:\n- The quorum $q$ must be a real number in $[0,1)$. All species counts must be nonnegative integers. Zero-count species must be ignored in the computation of $N$ and $p_i$.\n- There are no physical units. All outputs must be numerical real values.\n- The final output must be a single line string representation of a Python list containing all results for all test cases, flattened in order, with each value rounded to six decimal places. Specifically, for each test case output two values in sequence: first $R$, then $\\widehat{C}$.\n\nTest suite to implement and evaluate:\n- Case A (general assemblage and mid-quorum): counts $\\{20,10,5,3,1,1\\}$ with $q = 0.7$.\n- Case B (same assemblage, zero quorum boundary): counts $\\{20,10,5,3,1,1\\}$ with $q = 0.0$.\n- Case C (same assemblage, near-complete quorum): counts $\\{20,10,5,3,1,1\\}$ with $q = 0.999$.\n- Case D (equal-abundance assemblage): counts $\\{1,1,1,1,1,1,1,1,1,1\\}$ with $q = 0.35$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[rA,cA,rB,cB,rC,cC,rD,cD]\"), where each $r$ is the subsampled diversity $R$ and each $c$ is the estimated coverage $\\widehat{C}$ for the corresponding case, each rounded to six decimal places.",
            "solution": "The problem statement is subject to rigorous validation.\n\nStep 1: Extract Givens.\n- Data: Species counts as multisets of nonnegative integers $\\{x_1, \\dots, x_S\\}$.\n    - Case A: counts $\\{20,10,5,3,1,1\\}$ with quorum $q = 0.7$.\n    - Case B: counts $\\{20,10,5,3,1,1\\}$ with quorum $q = 0.0$.\n    - Case C: counts $\\{20,10,5,3,1,1\\}$ with quorum $q = 0.999$.\n    - Case D: counts $\\{1,1,1,1,1,1,1,1,1,1\\}$ with quorum $q = 0.35$.\n- Definitions:\n    - Total individuals: $N = \\sum_{i=1}^{S} x_i$.\n    - Relative frequencies: $p_i = x_i / N$ for species with $x_i > 0$.\n    - Quorum: A target coverage level $q \\in [0,1)$.\n    - Subsampled diversity: $R$.\n    - Estimated coverage: $\\widehat{C}$.\n- Algorithm for deterministic expected Shareholder Quorum Subsampling (SQS):\n    1. Given $\\{x_i\\}$, discard all entries where $x_i = 0$. Let the number of remaining species be $S'$.\n    2. Compute the total number of individuals $N = \\sum_{i=1}^{S'} x_i$.\n    3. Compute the relative frequencies $p_i = x_i / N$.\n    4. Sort the frequencies in descending order to form the sequence $(p_{(1)}, p_{(2)}, \\dots, p_{(S')})$.\n    5. Initialize cumulative coverage $c \\leftarrow 0$ and subsampled diversity $R \\leftarrow 0$.\n    6. Iterate through the sorted frequencies $p_{(j)}$ for $j=1, \\dots, S'$.\n       - If the current cumulative coverage plus the next frequency does not exceed the quorum, $c + p_{(j)} \\le q$, then the species is included fully: update $c \\leftarrow c + p_{(j)}$ and $R \\leftarrow R + 1$.\n       - Otherwise, the quorum level is reached within this species. Calculate the required fraction $f \\leftarrow (q - c)/p_{(j)}$ of this species to meet the quorum exactly. Update diversity by this fraction, $R \\leftarrow R + f$, set the final coverage to the quorum, $c \\leftarrow q$, and terminate the procedure.\n- Special Conditions:\n    - If the quorum $q = 0$, then $R = 0$ and $\\widehat{C} = 0$.\n    - If there are no individuals in the sample, $N = 0$, then $R = 0$ and $\\widehat{C} = 0$.\n- Output Specification: A single-line string representation of a Python list, containing the sequence of results $[R_A, \\widehat{C}_A, R_B, \\widehat{C}_B, \\dots]$, with each numerical value rounded to six decimal places.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is evaluated against the required criteria.\n- **Scientifically Grounded:** The problem describes Shareholder Quorum Subsampling, a standard technique in quantitative paleobiology for correcting for sampling bias in fossil assemblages. It is based on the well-established statistical concept of sample coverage. The premise is scientifically sound.\n- **Well-Posed:** The problem specifies a deterministic algorithm with clearly defined inputs, sequential steps, and unique outputs. It is self-contained and free of ambiguity.\n- **Objective:** The language is formal and quantitative, describing a mathematical algorithm. It is devoid of subjective or opinion-based content.\n- **Flaw Check:** The problem does not violate any fundamental principles, is not metaphorical, is complete and consistent, presents realistic data, is well-structured, is non-trivial, and its results are verifiable.\n\nStep 3: Verdict and Action.\nThe problem is valid. It is scientifically sound, well-posed, and complete. A solution will be provided.\n\nThe objective is to implement the deterministic Shareholder Quorum Subsampling (SQS) algorithm. This method standardizes biodiversity samples not by the number of individuals (rarefaction), but by the completeness of the sample, termed coverage. The target coverage is specified by a quorum, $q$. The algorithm calculates the expected species richness, $R$, at this target coverage level.\n\nThe algorithm proceeds as follows. First, we process the input species counts $\\{x_i\\}$. Any species with a count of $x_i = 0$ is ignored. The total number of individuals, $N$, is the sum of the positive counts. The relative frequency of each species, $p_i = x_i / N$, represents its proportional abundance in the assemblage. These frequencies are then sorted in descending order, $(p_{(1)}, p_{(2)}, \\dots, p_{(S')})$, where $S'$ is the number of species with positive counts. This sorting ensures that the most common species, which contribute most to coverage, are considered first.\n\nThe core of the algorithm is an iterative accumulation of coverage. We initialize subsampled richness $R \\leftarrow 0$ and cumulative coverage $c \\leftarrow 0$. We then iterate through the sorted frequencies. For each frequency $p_{(j)}$, we check if adding it in its entirety would exceed the target quorum $q$.\n- If $c + p_{(j)} \\le q$, the species is fully included. We increment the richness by one, $R \\leftarrow R + 1$, and add its frequency to the cumulative coverage, $c \\leftarrow c + p_{(j)}$.\n- If $c + p_{(j)} > q$, we have found the last species to be included. However, we only need a fraction of this species' contribution to reach the quorum exactly. This fraction is $f = (q - c) / p_{(j)}$. We add this fractional value to the richness, $R \\leftarrow R + f$. The cumulative coverage is now precisely the quorum, $c \\leftarrow q$, and the algorithm terminates.\n\nThe returned values are the calculated richness $R$ (which may be fractional) and the final coverage $\\widehat{C}$, which by construction is equal to $q$ (unless $q$ is larger than the total sample coverage, a case not tested here, or if the initial conditions $N=0$ or $q=0$ apply).\n\nLet us demonstrate with Case A: counts $\\{20,10,5,3,1,1\\}$ and quorum $q = 0.7$.\n1.  All counts are positive. Total individuals $N = 20+10+5+3+1+1 = 40$.\n2.  The relative frequencies $\\{p_i\\}$ are $\\{20/40, 10/40, 5/40, 3/40, 1/40, 1/40\\}$, which is $\\{0.5, 0.25, 0.125, 0.075, 0.025, 0.025\\}$.\n3.  The frequencies are already sorted in descending order: $(p_{(1)}, \\dots, p_{(6)}) = (0.5, 0.25, 0.125, 0.075, 0.025, 0.025)$.\n4.  Initialize $R \\leftarrow 0$ and $c \\leftarrow 0$. The quorum is $q = 0.7$.\n5.  Iteration $j=1$: $p_{(1)} = 0.5$. The condition $c + p_{(1)} = 0 + 0.5 = 0.5 \\le 0.7$ is true. Update $R \\leftarrow 1$ and $c \\leftarrow 0.5$.\n6.  Iteration $j=2$: $p_{(2)} = 0.25$. The condition $c + p_{(2)} = 0.5 + 0.25 = 0.75 \\le 0.7$ is false.\n7.  The loop terminates. We calculate the fraction for this last species: $f = (q - c) / p_{(2)} = (0.7 - 0.5) / 0.25 = 0.2 / 0.25 = 0.8$.\n8.  Update richness: $R \\leftarrow R + f = 1 + 0.8 = 1.8$.\n9.  Set final coverage: $\\widehat{C} \\leftarrow q = 0.7$.\nThe result for Case A is $R = 1.8$ and $\\widehat{C} = 0.7$. This procedure is applied systematically to all test cases to derive the final output.",
            "answer": "[1.800000,0.700000,0.000000,0.000000,5.960000,0.999000,3.500000,0.350000]"
        }
    ]
}