{
    "hands_on_practices": [
        {
            "introduction": "A foundational step in studying isolation by distance is to statistically test for a positive association between genetic and geographic distances. The Mantel test is the classic tool for this purpose, but its results must be interpreted with precision. This exercise  will sharpen your ability to draw accurate conclusions from Mantel test output, helping you distinguish between statistical correlation, its significance, and the nuances of causation.",
            "id": "1942014",
            "problem": "A team of population geneticists is studying a species of island-dwelling gecko, *Gekko insularis*, distributed across a small archipelago. They hypothesize that gene flow between populations is limited by the ocean, a pattern known as Isolation by Distance (IBD), where populations that are farther apart geographically are also more genetically distinct. To test this, the researchers collect tissue samples from individuals in several distinct populations. They calculate pairwise genetic distances using a set of neutral genetic markers and measure the straight-line geographic distances in kilometers between the islands. A Mantel test is then performed to assess the correlation between the genetic distance matrix and the geographic distance matrix. The test yields a correlation coefficient of $r = 0.60$ and a p-value of $p = 0.002$.\n\nBased on these statistical results, which of the following is the most accurate conclusion?\n\nA. The population is panmictic, meaning individuals mate randomly across the entire archipelago, and there is no significant population structure.\n\nB. The results prove that the geographic distance between islands is the direct and sole cause of the observed genetic differences.\n\nC. There is a statistically significant, positive correlation between genetic and geographic distance, which is consistent with the hypothesis of isolation by distance.\n\nD. The p-value of $0.002$ indicates that there is a 0.2% probability that the correlation between genetic and geographic distance occurred by random chance.\n\nE. 60% of the variation in genetic distance among populations is explained by the geographic distance between them.",
            "solution": "We are given the output of a Mantel test comparing a genetic distance matrix and a geographic distance matrix: a correlation coefficient $r = 0.60$ and a p-value $p = 0.002$. The Mantel test evaluates the null hypothesis $H_{0}$ that there is no association between the two distance matrices, typically assessed by permutation to obtain $p$ as the probability, under $H_{0}$, of obtaining a correlation as extreme as or more extreme than the observed $r$.\n\nStep 1: Interpret the correlation coefficient.\n- The statistic $r = 0.60$ is a positive correlation of moderate-to-strong magnitude between genetic and geographic distances. This indicates that, in the sample, pairs of populations that are farther apart geographically tend also to be more genetically distinct.\n\nStep 2: Interpret the p-value in relation to $H_{0}$.\n- The p-value $p = 0.002$ is the probability, under $H_{0}$ (no association between matrices), of obtaining a correlation at least as extreme as $r = 0.60$ by random permutation. Since $0.002$ is smaller than common significance levels (for example, $\\alpha = 0.05$), we reject $H_{0}$ and conclude that the observed positive association is statistically significant.\n\nStep 3: Evaluate each option against the correct statistical interpretations.\n- Option A claims panmixia (random mating across the archipelago) and no structure. A positive and statistically significant Mantel correlation contradicts this; isolation by distance implies structure, not panmixia. Therefore A is incorrect.\n- Option B asserts causation from distance alone. The Mantel test establishes association, not causation; unmeasured covariates or spatial autocorrelation could contribute. Therefore B is incorrect.\n- Option C states that there is a statistically significant, positive correlation between genetic and geographic distance, consistent with isolation by distance. This matches the interpretation of $r = 0.60$ with $p = 0.002$. Therefore C is correct.\n- Option D interprets the p-value as the probability that the observed correlation occurred by random chance. Formally, the p-value is $\\Pr(\\text{data as or more extreme} \\mid H_{0})$, not $\\Pr(H_{0} \\mid \\text{data})$. Stating the probability that the observed correlation “occurred by random chance” conflates these and is a common but incorrect interpretation. Therefore D is incorrect.\n- Option E asserts that $60$ out of $100$ units of genetic variation are explained by geographic distance. Even in standard Pearson correlation, the fraction of variance explained would be $r^{2} = 0.36$, not $0.60$. Moreover, with a Mantel correlation on distance matrices, interpreting $r^{2}$ as explained variance is not appropriate. Therefore E is incorrect.\n\nConclusion: The only accurate statement is that there is a statistically significant, positive correlation between genetic and geographic distance consistent with isolation by distance.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "A significant isolation by distance pattern is not just a qualitative observation; it contains quantitative information about demography and dispersal. Under the classic Wright-Malécot theory, the slope of the regression of genetic distance against the logarithm of geographic distance is inversely related to the neighborhood size, $N_b$. In a two-dimensional landscape, neighborhood size is defined by key demographic parameters as $N_b = 4 \\pi D \\sigma^2$. This practice  challenges you to derive and apply this relationship to estimate the dispersal standard deviation, $\\sigma$, a critical life-history parameter, from empirical data.",
            "id": "2727650",
            "problem": "A continuous panmictic adult population occupies a large two-dimensional habitat at drift–migration equilibrium in the sense of the Wright–Malécot isolation-by-distance framework. Let the adult density be $D$ (adults per square kilometer), and let parent–offspring dispersal be a bivariate normal with radial standard deviation $\\sigma$ (kilometers per generation). The neighborhood size is defined as $N_{b} = 4 \\pi D \\sigma^{2}$. Empirically, you compute a standardized pairwise genetic distance that is asymptotically linear in $\\ln(r)$ for inter-individual separation $r$ and fit an ordinary least squares regression of that standardized distance on $\\ln(r)$, obtaining an estimated slope $\\hat{b}$. Under the classical two-dimensional isolation-by-distance theory for large habitats and distances where local pedigree structure does not dominate, the slope is inversely related to the neighborhood size.\n\nStarting from the definition of neighborhood size and the asymptotic two-dimensional isolation-by-distance relationship described above (without invoking any additional shortcuts), derive a closed-form estimator $\\hat{\\sigma}$ in terms of $D$ and $\\hat{b}$. Then, using $D = 12$ adults per square kilometer and $\\hat{b} = 0.0085$, compute the numerical value of $\\hat{\\sigma}$.\n\nExpress your final numerical answer in kilometers per generation and round to four significant figures. The final answer must be a single number.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard problem in population genetics based on the Wright–Malécot theory of isolation by distance (IBD). We shall proceed with the derivation and calculation.\n\nThe problem requires the derivation of an estimator for the parent–offspring dispersal standard deviation, $\\hat{\\sigma}$, from the estimated slope of a regression of genetic distance on the logarithm of geographic distance. The fundamental principles are provided in the problem statement.\n\nFirst, the problem states that for a large, two-dimensional habitat at drift-migration equilibrium, the slope of a regression of a specific standardized pairwise genetic distance against the natural logarithm of the inter-individual separation distance, $\\ln(r)$, is inversely related to the neighborhood size, $N_b$. In the classical Wright–Malécot theory for a $2$D continuum, this relationship is precisely:\n$$ b = \\frac{1}{N_{b}} $$\nwhere $b$ is the theoretical slope. The problem provides an empirically estimated slope, $\\hat{b}$, from an ordinary least squares regression. We use this estimate to construct an estimator for the neighborhood size, $\\hat{N}_b$, by inverting the relationship:\n$$ \\hat{N}_{b} = \\frac{1}{\\hat{b}} $$\n\nSecond, the problem provides the definition of neighborhood size, $N_b$, in terms of the adult population density, $D$, and the radial standard deviation of parent-offspring dispersal, $\\sigma$:\n$$ N_{b} = 4 \\pi D \\sigma^{2} $$\nThis definition corresponds to the number of individuals within a circle of area $4 \\pi \\sigma^{2}$, which has a radius of $2 \\sigma$.\n\nTo derive an estimator for $\\sigma$, we equate the two expressions for the neighborhood size. We substitute the estimator $\\hat{N}_b$ for $N_b$ and the estimator $\\hat{\\sigma}$ for $\\sigma$:\n$$ \\hat{N}_{b} = 4 \\pi D \\hat{\\sigma}^{2} $$\nNow, we substitute the expression for $\\hat{N}_b$ in terms of $\\hat{b}$:\n$$ \\frac{1}{\\hat{b}} = 4 \\pi D \\hat{\\sigma}^{2} $$\nOur objective is to find a closed-form expression for $\\hat{\\sigma}$. We rearrange the equation to isolate $\\hat{\\sigma}^{2}$:\n$$ \\hat{\\sigma}^{2} = \\frac{1}{4 \\pi D \\hat{b}} $$\nTaking the square root of both sides yields the estimator for the radial dispersal standard deviation:\n$$ \\hat{\\sigma} = \\sqrt{\\frac{1}{4 \\pi D \\hat{b}}} = \\frac{1}{\\sqrt{4 \\pi D \\hat{b}}} $$\nThis is the required closed-form estimator for $\\sigma$ in terms of $D$ and $\\hat{b}$.\n\nNext, we must compute the numerical value of $\\hat{\\sigma}$ using the provided data:\n- Adult density, $D = 12$ adults per square kilometer.\n- Estimated slope, $\\hat{b} = 0.0085$.\n\nSubstituting these values into our derived estimator:\n$$ \\hat{\\sigma} = \\frac{1}{\\sqrt{4 \\pi (12) (0.0085)}} $$\nWe perform the calculation for the term inside the square root:\n$$ 4 \\times \\pi \\times 12 \\times 0.0085 = 48 \\times 0.0085 \\times \\pi = 0.408 \\pi $$\nUsing a more precise value for $\\pi \\approx 3.14159265$:\n$$ 0.408 \\times 3.14159265 \\approx 1.2817698 $$\nNow we compute $\\hat{\\sigma}$:\n$$ \\hat{\\sigma} \\approx \\frac{1}{\\sqrt{1.2817698}} \\approx \\frac{1}{1.1321527} \\approx 0.8832745 \\text{ km} $$\nThe units of $D$ were given in adults per square kilometer, so the resulting unit for $\\hat{\\sigma}$ is kilometers. The time frame for this dispersal distance is per generation, as specified for $\\sigma$.\n\nThe problem requires the final answer to be rounded to four significant figures.\n$$ \\hat{\\sigma} \\approx 0.8833 \\text{ km} $$\nThis is the final numerical value for the estimated radial standard deviation of dispersal.",
            "answer": "$$\\boxed{0.8833}$$"
        },
        {
            "introduction": "In practice, patterns of genetic differentiation can be ambiguous; a seemingly continuous cline might arise from unresolved discrete clusters, or vice-versa. This exercise  introduces a powerful, contemporary approach to this problem: formal model selection based on predictive accuracy. You will implement a cross-validation framework to quantitatively compare a continuous isolation by distance model against a discrete two-cluster model, a core skill for rigorously interpreting complex spatial genetic data.",
            "id": "2727647",
            "problem": "You are given three small synthetic datasets consisting of labeled individuals, their two-dimensional geographic coordinates, and an observed symmetric matrix of pairwise genetic distances with zero diagonal. Your task is to implement a deterministic cross-validation model selection procedure that chooses between a discrete two-cluster model and a continuous Isolation by Distance (IBD) linear model, based solely on out-of-sample predictive accuracy of pairwise genetic distances.\n\nStart from the following fundamental base:\n\n- Restricted dispersal and genetic drift produce a spatial pattern where expected genetic distance tends to increase with geographic distance under Isolation by Distance (IBD). In its simplest linearized form, the expected genetic distance between two individuals increases approximately linearly with their geographic distance in a homogeneous landscape.\n- Discrete population structure produces step-like patterns in genetic distances, with smaller distances within clusters and larger distances between clusters.\n- Predictive model selection should rely on out-of-sample error, estimated by cross-validation, to avoid overfitting and to reflect generalization.\n\nYou must implement and compare the following two models:\n\n- Continuous IBD-linear model: For each unordered pair of individuals $(i,j)$, the predicted genetic distance is $\\hat{D}_{ij} = \\hat{\\alpha} + \\hat{\\beta} \\cdot \\Delta_{ij}$, where $\\Delta_{ij}$ is the Euclidean geographic distance between individuals $i$ and $j$ computed from their coordinates, and $(\\hat{\\alpha}, \\hat{\\beta})$ are obtained by ordinary least squares on the training pairs only.\n\n- Discrete two-cluster model: Each individual $i$ is assigned a cluster label $c_i \\in \\{0,1\\}$, with the constraint $c_0 = 0$ to remove label symmetry, and both clusters must be non-empty. For a fixed assignment $c$, the model predicts $\\hat{D}_{ij} = \\hat{w}$ if $c_i = c_j$ and $\\hat{D}_{ij} = \\hat{b}$ if $c_i \\neq c_j$, where $(\\hat{w}, \\hat{b})$ are the means of the observed distances of the training pairs falling within the corresponding categories (within-cluster and between-cluster) for that assignment. For model fitting, search over all valid assignments and choose the assignment that minimizes the training mean squared error, then compute validation predictions using $\\hat{w}$ and $\\hat{b}$ estimated from the training set under that best assignment.\n\nDefine $N$ labeled individuals $\\{0,1,\\dots,N-1\\}$ and let $M = N(N-1)/2$ be the number of unordered pairs $(i,j)$ with $i<j$. For a given number of folds $F$ and a nonnegative integer seed $s$, assign each pair $(i,j)$ to a deterministic fold index\n$$\n\\phi(i,j) = \\big((i \\cdot N + j) + s\\big) \\bmod F,\n$$\nwith $i<j$. For fold $f \\in \\{0,1,\\dots,F-1\\}$, the training set is all pairs with $\\phi(i,j) \\neq f$, and the validation set is all pairs with $\\phi(i,j) = f$.\n\nFor each model and each fold, fit the model parameters using only the training pairs of that fold and compute the validation mean squared error\n$$\n\\mathrm{MSE}_f = \\frac{1}{|H_f|}\\sum_{(i,j)\\in H_f}\\big(D_{ij} - \\hat{D}_{ij}\\big)^2,\n$$\nwhere $H_f$ is the validation set for fold $f$. The cross-validated error is the average of $\\mathrm{MSE}_f$ across folds. Choose the model with the smaller cross-validated error. If the absolute difference between cross-validated errors is less than or equal to a tolerance $\\varepsilon = 10^{-9}$, prefer the IBD-linear model as the simpler model.\n\nAll distance quantities are pure numbers without physical units; no unit conversion is required. Angles are not involved. Report the final decision for each dataset as an integer: output $1$ if the IBD-linear model is preferred, and $0$ if the discrete two-cluster model is preferred.\n\nTest suite. Apply the above procedure to the following three datasets. In each dataset, you are given $N$, the number of folds $F$, the seed $s$, the coordinates $\\{(x_i,y_i)\\}_{i=0}^{N-1}$, and the observed symmetric distance matrix $D = [D_{ij}]$ with $D_{ii} = 0$.\n\n- Dataset A (IBD-like linear pattern, zero noise):\n  - $N=6$, $F=3$, $s=7$.\n  - Coordinates $(x_i,y_i)$ for $i=0,\\dots,5$: $(0,0)$, $(1,0)$, $(2,0)$, $(3,0)$, $(4,0)$, $(5,0)$.\n  - Observed pairwise genetic distances $D_{ij} = 0$ if $i=j$ and, for $i<j$,\n    $$\n    D_{ij} = 0.1 + 0.2 \\cdot |x_i - x_j|.\n    $$\n    Explicitly, for $i<j$, the nonzero entries are: $D_{01}=0.3$, $D_{02}=0.5$, $D_{03}=0.7$, $D_{04}=0.9$, $D_{05}=1.1$, $D_{12}=0.3$, $D_{13}=0.5$, $D_{14}=0.7$, $D_{15}=0.9$, $D_{23}=0.3$, $D_{24}=0.5$, $D_{25}=0.7$, $D_{34}=0.3$, $D_{35}=0.5$, $D_{45}=0.3$.\n\n- Dataset B (discrete two-cluster pattern, zero noise):\n  - $N=6$, $F=3$, $s=11$.\n  - Coordinates $(x_i,y_i)$ for $i=0,\\dots,5$: $(0,0)$, $(3,0)$, $(1,0)$, $(0.5,0)$, $(2,0)$, $(3.5,0)$.\n  - True clusters are $\\{0,1,2\\}$ and $\\{3,4,5\\}$, with within-cluster distance $0.1$ and between-cluster distance $0.6$. The observed distances satisfy $D_{ij} = 0$ if $i=j$, $D_{ij}=0.1$ if $i\\neq j$ and $i,j$ are in the same cluster, and $D_{ij}=0.6$ otherwise.\n\n- Dataset C (no structure, constant distances):\n  - $N=5$, $F=3$, $s=3$.\n  - Coordinates $(x_i,y_i)$ for $i=0,\\dots,4$: $(0,0)$, $(1,0)$, $(0,1)$, $(1,1)$, $(2,0)$.\n  - Observed distances $D_{ij} = 0$ if $i=j$ and $D_{ij} = 0.3$ if $i\\neq j$.\n\nYour program must produce a single line of output containing the results for the three datasets as a comma-separated list enclosed in square brackets, in the same order A, B, C. For each dataset, output $1$ if the IBD-linear model is preferred and $0$ if the discrete two-cluster model is preferred. For example, an output should look like \"[1,0,1]\" if datasets A and C prefer IBD-linear and dataset B prefers the discrete model.",
            "solution": "The problem requires the implementation of a deterministic cross-validation procedure to select between two competing models for describing the relationship between geographic and genetic distances among a set of individuals. The two models are a continuous Isolation by Distance (IBD) linear model and a discrete two-cluster model. The selection is based on out-of-sample predictive accuracy, quantified by the mean squared error (MSE).\n\nThe procedure is implemented as follows. For each dataset, defined by the number of individuals $N$, number of cross-validation folds $F$, a seed $s$, a set of geographic coordinates $\\{ (x_i, y_i) \\}_{i=0}^{N-1}$, and a matrix of pairwise genetic distances $D=[D_{ij}]$, we first process all unique unordered pairs of individuals $(i, j)$ where $i < j$. For each pair, its Euclidean geographic distance $\\Delta_{ij}$ is computed. Each pair is then deterministically assigned to a fold index $f \\in \\{0, 1, \\dots, F-1\\}$ using the given formula $\\phi(i,j) = \\big((i \\cdot N + j) + s\\big) \\bmod F$.\n\nThe cross-validation proceeds by iterating through each fold $f$. The set of all pairs is partitioned into a training set, comprising all pairs $(i,j)$ for which $\\phi(i,j) \\neq f$, and a validation set $H_f$, consisting of pairs where $\\phi(i,j) = f$. For each fold, both models are fitted on the training set and their predictive performance is evaluated on the validation set.\n\nThe first model is the continuous IBD-linear model, described by the equation $\\hat{D}_{ij} = \\hat{\\alpha} + \\hat{\\beta} \\cdot \\Delta_{ij}$. For each training set, the parameters $(\\hat{\\alpha}, \\hat{\\beta})$ are estimated using ordinary least squares (OLS). This is computationally implemented by constructing a design matrix from the training pairs' geographic distances and solving the resulting linear system, for which `numpy.linalg.lstsq` provides a robust solution. This function finds the coefficients $(\\hat{\\alpha}, \\hat{\\beta})$ that minimize the sum of squared residuals $\\sum (D_{ij} - \\hat{D}_{ij})^2$ over the training pairs. The fitted model is then used to predict genetic distances for the pairs in the validation set $H_f$. The mean squared error for the fold, $\\mathrm{MSE}_f^{\\text{IBD}}$, is calculated as $\\frac{1}{|H_f|}\\sum_{(i,j)\\in H_f}\\big(D_{ij} - \\hat{D}_{ij}\\big)^2$.\n\nThe second model is the discrete two-cluster model. Its fitting process within each fold is more complex. It requires an exhaustive search for the optimal partition of the $N$ individuals into two non-empty clusters. To ensure uniqueness and satisfy the problem constraints, we enforce that individual $0$ is always in cluster $0$ ($c_0=0$) and that both clusters are non-empty. This is equivalent to testing all $2^{N-1}-1$ ways to assign the remaining $N-1$ individuals to one of two clusters such that at least one individual is assigned to cluster $1$. For each of these candidate cluster assignments, the model parameters $(\\hat{w}, \\hat{b})$ are estimated from the training data. $\\hat{w}$ is the mean of genetic distances $D_{ij}$ for training pairs where individuals $i$ and $j$ are in the same cluster, and $\\hat{b}$ is the mean for pairs where they are in different clusters. The training MSE is then computed for this assignment. The cluster assignment that results in the minimum training MSE is selected as the optimal one for the current fold, and its corresponding parameters, denoted $(\\hat{w}_f, \\hat{b}_f)$, are retained. These parameters are then used to predict distances for the validation pairs: a validation pair $(i,j)$ is predicted as $\\hat{w}_f$ if $i$ and $j$ are in the same cluster under the optimal assignment, and as $\\hat{b}_f$ otherwise. The validation MSE, $\\mathrm{MSE}_f^{\\text{cluster}}$, is then calculated for the fold. In the special case where a training set for a given assignment lacks pairs of a certain type (e.g., no within-cluster pairs), the mean of all genetic distances in the training set is used as a robust estimate for the corresponding parameter.\n\nAfter iterating through all $F$ folds, the overall cross-validated error for each model is computed as the average of its fold-specific MSEs: $\\mathrm{CV\\_MSE} = \\frac{1}{F} \\sum_{f=0}^{F-1} \\mathrm{MSE}_f$.\n\nThe final model selection is based on these cross-validated errors. The IBD-linear model is preferred if its error is lower than or equal to the cluster model's error, considering a tolerance $\\varepsilon = 10^{-9}$. That is, if $\\mathrm{CV\\_MSE}_{\\text{IBD}} - \\mathrm{CV\\_MSE}_{\\text{cluster}} \\le \\varepsilon$, the output for the dataset is $1$. Otherwise, the discrete two-cluster model is preferred, and the output is $0$. This entire procedure is applied to each of the three provided datasets to produce the final list of results.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a deterministic cross-validation model selection procedure to choose\n    between a continuous IBD-linear model and a discrete two-cluster model for\n    three synthetic datasets.\n    \"\"\"\n\n    def process_dataset(N, F, s, coords_list, D_matrix):\n        \"\"\"\n        Processes a single dataset to determine the preferred model.\n\n        Returns:\n            int: 1 if the IBD-linear model is preferred, 0 otherwise.\n        \"\"\"\n        coords = np.array(coords_list, dtype=float)\n        D = np.array(D_matrix, dtype=float)\n\n        # 1. Generate all unique pairs and assign them to folds.\n        pairs = []\n        for i in range(N):\n            for j in range(i + 1, N):\n                geo_dist = np.linalg.norm(coords[i] - coords[j])\n                gen_dist = D[i, j]\n                fold_idx = ((i * N + j) + s) % F\n                pairs.append({'i': i, 'j': j, 'geo_dist': geo_dist, 'gen_dist': gen_dist, 'fold': fold_idx})\n        \n        # 2. Calculate cross-validated MSE for the IBD-linear model.\n        ibd_mse = calculate_ibd_cv_mse(pairs, F)\n        \n        # 3. Calculate cross-validated MSE for the discrete two-cluster model.\n        cluster_mse = calculate_cluster_cv_mse(pairs, F, N)\n        \n        # 4. Compare model errors and make a selection.\n        if ibd_mse - cluster_mse <= 1e-9:\n            return 1\n        else:\n            return 0\n\n    def calculate_ibd_cv_mse(pairs, F):\n        \"\"\"Calculates the cross-validated MSE for the IBD-linear model.\"\"\"\n        fold_mses = []\n        for f in range(F):\n            train_pairs = [p for p in pairs if p['fold'] != f]\n            valid_pairs = [p for p in pairs if p['fold'] == f]\n            \n            if not valid_pairs:\n                continue\n            \n            # Handle empty training set (unlikely for problems' parameters)\n            if not train_pairs:\n                all_gen_dists = np.array([p['gen_dist'] for p in pairs])\n                mean_gen_dist = np.mean(all_gen_dists) if len(all_gen_dists) > 0 else 0\n                valid_gen_dists = np.array([p['gen_dist'] for p in valid_pairs])\n                mse = np.mean((valid_gen_dists - mean_gen_dist)**2) if len(valid_gen_dists) > 0 else 0\n                fold_mses.append(mse)\n                continue\n\n            train_geo = np.array([p['geo_dist'] for p in train_pairs])\n            train_gen = np.array([p['gen_dist'] for p in train_pairs])\n            \n            # Fit OLS model using numpy.linalg.lstsq for robustness.\n            A = np.vstack([train_geo, np.ones(len(train_geo))]).T\n            try:\n                beta, alpha = np.linalg.lstsq(A, train_gen, rcond=None)[0]\n            except np.linalg.LinAlgError:\n                alpha = np.mean(train_gen) if len(train_gen) > 0 else 0\n                beta = 0\n\n            # Predict on validation set and compute MSE.\n            valid_geo = np.array([p['geo_dist'] for p in valid_pairs])\n            valid_gen = np.array([p['gen_dist'] for p in valid_pairs])\n            pred_gen = beta * valid_geo + alpha\n            mse = np.mean((valid_gen - pred_gen)**2)\n            fold_mses.append(mse)\n            \n        return np.mean(fold_mses) if fold_mses else 0\n\n    def calculate_cluster_cv_mse(pairs, F, N):\n        \"\"\"Calculates the cross-validated MSE for the discrete two-cluster model.\"\"\"\n        fold_mses = []\n        \n        # Generate all valid cluster assignments (c_0=0, both clusters non-empty).\n        num_assignments_to_check = 2**(N - 1)\n        assignments = []\n        for i in range(1, num_assignments_to_check):\n            assignment = [0] * N\n            for j in range(1, N):\n                if (i >> (j - 1)) & 1:\n                    assignment[j] = 1\n            assignments.append(tuple(assignment))\n\n        for f in range(F):\n            train_pairs = [p for p in pairs if p['fold'] != f]\n            valid_pairs = [p for p in pairs if p['fold'] == f]\n            \n            if not valid_pairs:\n                continue\n            \n            # Handle empty training set.\n            if not train_pairs:\n                all_gen_dists = np.array([p['gen_dist'] for p in pairs])\n                mean_gen_dist = np.mean(all_gen_dists) if len(all_gen_dists) > 0 else 0\n                valid_gen_dists = np.array([p['gen_dist'] for p in valid_pairs])\n                mse = np.mean((valid_gen_dists - mean_gen_dist)**2) if len(valid_gen_dists) > 0 else 0\n                fold_mses.append(mse)\n                continue\n                \n            train_gen_dists_all = [p['gen_dist'] for p in train_pairs]\n            overall_train_mean = np.mean(train_gen_dists_all)\n\n            min_train_mse = float('inf')\n            best_params = (overall_train_mean, overall_train_mean)\n            best_assignment = assignments[0] if assignments else tuple([0] * N)\n            \n            # Find the best assignment by minimizing training MSE.\n            for c in assignments:\n                train_within = [p['gen_dist'] for p in train_pairs if c[p['i']] == c[p['j']]]\n                train_between = [p['gen_dist'] for p in train_pairs if c[p['i']] != c[p['j']]]\n                \n                w_hat = np.mean(train_within) if train_within else overall_train_mean\n                b_hat = np.mean(train_between) if train_between else overall_train_mean\n\n                train_sq_err = 0\n                for p in train_pairs:\n                    pred = w_hat if c[p['i']] == c[p['j']] else b_hat\n                    train_sq_err += (p['gen_dist'] - pred)**2\n                \n                current_train_mse = train_sq_err / len(train_pairs)\n                \n                if current_train_mse < min_train_mse:\n                    min_train_mse = current_train_mse\n                    best_params = (w_hat, b_hat)\n                    best_assignment = c\n            \n            w_hat_f, b_hat_f = best_params\n            c_f = best_assignment\n            \n            # Predict on validation set and compute MSE.\n            valid_sq_err = 0\n            if valid_pairs:\n                for p in valid_pairs:\n                    pred = w_hat_f if c_f[p['i']] == c_f[p['j']] else b_hat_f\n                    valid_sq_err += (p['gen_dist'] - pred)**2\n                mse = valid_sq_err / len(valid_pairs)\n            else:\n                mse = 0\n            \n            fold_mses.append(mse)\n            \n        return np.mean(fold_mses) if fold_mses else 0\n\n    # Define Test Cases\n    # Dataset A\n    N_A = 6\n    coords_A = [(float(i), 0.0) for i in range(N_A)]\n    D_A = np.zeros((N_A, N_A))\n    for i in range(N_A):\n        for j in range(i + 1, N_A):\n            dist = 0.1 + 0.2 * abs(coords_A[i][0] - coords_A[j][0])\n            D_A[i, j] = D_A[j, i] = dist\n    \n    # Dataset B\n    N_B = 6\n    coords_B = [(0.0, 0.0), (3.0, 0.0), (1.0, 0.0), (0.5, 0.0), (2.0, 0.0), (3.5, 0.0)]\n    clusters_B = {0: 0, 1: 0, 2: 0, 3: 1, 4: 1, 5: 1} # True clusters for D generation\n    D_B = np.zeros((N_B, N_B))\n    for i in range(N_B):\n        for j in range(i + 1, N_B):\n            dist = 0.1 if clusters_B[i] == clusters_B[j] else 0.6\n            D_B[i, j] = D_B[j, i] = dist\n\n    # Dataset C\n    N_C = 5\n    coords_C = [(0.0, 0.0), (1.0, 0.0), (0.0, 1.0), (1.0, 1.0), (2.0, 0.0)]\n    D_C = np.full((N_C, N_C), 0.3)\n    np.fill_diagonal(D_C, 0)\n\n    test_cases = [\n        (6, 3, 7, coords_A, D_A),  # Dataset A\n        (6, 3, 11, coords_B, D_B), # Dataset B\n        (5, 3, 3, coords_C, D_C)   # Dataset C\n    ]\n\n    results = []\n    for case in test_cases:\n        result = process_dataset(*case)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}