{
    "hands_on_practices": [
        {
            "introduction": "We begin with the fundamental principle of reciprocal altruism: an act that is costly to the donor but beneficial to the recipient can be favored by selection if the probability of reciprocation is sufficiently high. This exercise provides a quantitative foundation for this idea, asking you to calculate the expected fitness change for individuals in a simple, probabilistic exchange. Mastering this core calculus is the first step in moving from a qualitative concept to a testable mathematical model of cooperation. ",
            "id": "1877294",
            "problem": "In studies of animal behavior, reciprocal altruism is a model used to explain cooperative acts between unrelated individuals. Consider a simplified model of blood-sharing in a colony of vampire bats, where fitness gains and losses are quantified in abstract 'energy units'. The cost to a donor bat for sharing a blood meal is denoted by $c$. The benefit to the recipient, which is often near starvation, is denoted by $b$.\n\nNow, consider a single interaction sequence between two unrelated bats, Bat A and Bat B. Bat A is known to be a 'cooperator' and initiates the sequence by sharing its meal with Bat B. Bat B, however, does not always reciprocate. For any given act of kindness it receives, the probability that Bat B will reciprocate in a future encounter is $p$. Assume the act of reciprocation, if it occurs, involves the same cost and benefit values.\n\nGiven the following parameters:\n- Cost of donation, $c = 8$ energy units\n- Benefit of reception, $b = 30$ energy units\n- Probability of reciprocation, $p = 0.75$\n\nCalculate the expected net fitness change for Bat A and the expected net fitness change for Bat B from this entire interaction sequence, which is initiated by Bat A. Express your answer as a pair of numerical values, in energy units, representing the expected net change for Bat A followed by the expected net change for Bat B.\n\n",
            "solution": "The problem asks for the expected net fitness change for each of the two bats, Bat A and Bat B. The expected value of a quantity that depends on probabilistic outcomes is calculated by summing the products of each possible outcome's value and its probability of occurrence.\n\nFirst, let's analyze the expected net fitness change for Bat A. The interaction sequence involves two parts for Bat A: the initial definitive cost and the potential future benefit.\n1.  Bat A initiates the sharing. This is a certain event. The cost to Bat A is $c$, so its fitness changes by $-c$.\n2.  Bat B may or may not reciprocate later. The benefit to Bat A depends on Bat B's action.\n    -   With probability $p$, Bat B reciprocates, and Bat A receives a benefit of $b$.\n    -   With probability $(1-p)$, Bat B does not reciprocate, and Bat A receives no benefit (a change of 0).\nThe expected benefit for Bat A from this probabilistic event is the sum of (value of outcome $\\times$ probability of outcome):\n$$E[\\text{Benefit for A}] = (b \\times p) + (0 \\times (1-p)) = pb$$\nThe total expected net fitness change for Bat A, denoted $E_A$, is the sum of the initial cost and the expected future benefit:\n$$E_A = -c + pb$$\nSubstituting the given values:\n$$E_A = -8 + (0.75)(30) = -8 + 22.5 = 14.5$$\nSo, the expected net fitness change for Bat A is 14.5 energy units.\n\nNext, let's analyze the expected net fitness change for Bat B. The interaction sequence also involves two parts for Bat B: the initial definitive benefit and the potential future cost.\n1.  Bat B receives the shared meal from Bat A. This is a certain event. The benefit to Bat B is $b$, so its fitness changes by $+b$.\n2.  Bat B may or may not reciprocate later. The cost to Bat B depends on its own action.\n    -   With probability $p$, Bat B reciprocates, incurring a cost of $c$. The fitness change associated with this cost is $-c$.\n    -   With probability $(1-p)$, Bat B does not reciprocate, incurring no cost (a change of 0).\nThe expected fitness change for Bat B from its own potential action is:\n$$E[\\text{Cost for B}] = (-c \\times p) + (0 \\times (1-p)) = -pc$$\nThe total expected net fitness change for Bat B, denoted $E_B$, is the sum of the initial benefit and the expected future cost:\n$$E_B = b - pc$$\nSubstituting the given values:\n$$E_B = 30 - (0.75)(8) = 30 - 6 = 24$$\nSo, the expected net fitness change for Bat B is 24 energy units.\n\nThe final answer is the pair of expected net fitness changes for Bat A and Bat B, respectively.",
            "answer": "$$\\boxed{\\begin{pmatrix} 14.5 & 24 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Building on the simple exchange model, we now embed reciprocity within a population context using the framework of the Iterated Prisoner's Dilemma. This practice explores a crucial question in evolutionary biology: how can a cooperative strategy like \"Tit-for-Tat\" gain a foothold in a population dominated by defectors? By deriving the conditions for its invasion, you will unveil the critical roles of repeated interactions ($w$) and non-random social structures ($k$) in fostering the emergence of cooperation. ",
            "id": "1877275",
            "problem": "In evolutionary game theory, the emergence of cooperative behavior in populations of self-interested individuals is a central puzzle. The structure of the game being played is critical. Consider a scenario modeled by an iterated game where in each round, two players can either Cooperate (C) or Defect (D). The payoffs for a player are given by the following matrix, where the player's move is on the row and the opponent's move is on the column:\n- Payoff for (C, C): $R$ (Reward)\n- Payoff for (C, D): $S$ (Sucker)\n- Payoff for (D, C): $T$ (Temptation)\n- Payoff for (D, D): $P$ (Punishment)\n\nThe game is a Prisoner's Dilemma if $T > R > P > S$. After each round, there is a constant probability $w$ that another round of the game will be played between the same two individuals. The total expected payoff is the sum of payoffs over all rounds.\n\nConsider a large population composed almost entirely of individuals playing the \"Always Defect\" (ALLD) strategy. A small group of mutants playing the \"Tit-for-Tat\" (TFT) strategy is introduced. A TFT player cooperates on the first move and thereafter copies its opponent's move from the previous round.\n\nDue to social structuring or kinship, the mutant TFT players may interact with each other more frequently than expected by random chance. Let $k$ be the coefficient of assortment, defined as the probability that an interaction for a TFT individual is with another TFT individual. Consequently, a TFT player interacts with a random member of the vast ALLD population with probability $1-k$.\n\nFor cooperation to emerge, the TFT strategy must be able to invade the ALLD population. This requires the expected payoff for a TFT individual to be greater than the expected payoff for an ALLD individual.\n\nGiven the Prisoner's Dilemma payoffs $T=4$, $R=2$, $P=1$, and $S=0$, and a probability of future interaction $w=0.5$, calculate the minimum coefficient of assortment, $k_{crit}$, required for the TFT strategy to invade the ALLD population. Express your answer as a single fraction.\n\n",
            "solution": "In each iterated match, the probability that round $t+1$ occurs is $w^{t}$, so the expected total payoff equals the sum over rounds of the stage payoff weighted by $w^{t}$. Using the geometric series $\\sum_{t=0}^{\\infty} w^{t} = \\frac{1}{1-w}$ for $0<w<1$, compute the expected payoffs for the relevant pairings:\n\n- TFT vs TFT: both play $C$ forever, so every round yields $R$:\n$$\nV_{\\text{TFT},\\text{TFT}}=\\sum_{t=0}^{\\infty} w^{t} R=\\frac{R}{1-w}.\n$$\n\n- TFT vs ALLD: the sequence is $(C,D)$ in round $1$ (payoff $S$ to TFT), then $(D,D)$ thereafter (payoff $P$ to TFT). Hence\n$$\nV_{\\text{TFT},\\text{ALLD}}=S+\\sum_{t=1}^{\\infty} w^{t} P=S+\\frac{wP}{1-w}.\n$$\n\n- ALLD vs ALLD: every round is $(D,D)$, yielding\n$$\nV_{\\text{ALLD},\\text{ALLD}}=\\sum_{t=0}^{\\infty} w^{t} P=\\frac{P}{1-w}.\n$$\n\nWith assortment $k$, a rare TFT individual meets another TFT with probability $k$ and an ALLD with probability $1-k$, so its expected payoff is\n$$\n\\Pi_{\\text{TFT}}=k\\,V_{\\text{TFT},\\text{TFT}}+(1-k)\\,V_{\\text{TFT},\\text{ALLD}}.\n$$\nA resident ALLD in an ALLD population (mutants rare) meets ALLD almost surely, so\n$$\n\\Pi_{\\text{ALLD}}=V_{\\text{ALLD},\\text{ALLD}}.\n$$\nThe invasion condition is $\\Pi_{\\text{TFT}}>\\Pi_{\\text{ALLD}}$, i.e.\n$$\nk\\frac{R}{1-w}+(1-k)\\left(S+\\frac{wP}{1-w}\\right)>\\frac{P}{1-w}.\n$$\nMultiplying both sides by $(1-w)$ and rearranging,\n$$\nkR+(1-k)\\left(S(1-w)+wP\\right)>P,\n$$\n$$\nk\\left[R-\\left(S(1-w)+wP\\right)\\right]>P-\\left(S(1-w)+wP\\right).\n$$\nThus the critical assortment threshold is\n$$\nk_{\\text{crit}}=\\frac{P-\\left(S(1-w)+wP\\right)}{R-\\left(S(1-w)+wP\\right)}=\\frac{(1-w)(P-S)}{(R-S)-w(P-S)}.\n$$\nSubstitute $R=2$, $P=1$, $S=0$, $w=0.5$:\n$$\nk_{\\text{crit}}=\\frac{(1-0.5)(1-0)}{(2-0)-0.5(1-0)}=\\frac{0.5}{2-0.5}=\\frac{1}{3}.\n$$\nTherefore, the minimum coefficient of assortment required is the fraction $\\frac{1}{3}$.",
            "answer": "$$\\boxed{\\frac{1}{3}}$$"
        },
        {
            "introduction": "Our previous exercises focused on the dynamics of specific, named strategies. This culminating practice challenges you to generalize this understanding by deriving a universal formula for the long-run payoff of any memory-1 strategy pitted against another. By modeling the interaction as a Markov chain and leveraging the power of linear algebra, you will construct a powerful analytical result that reveals the deep mathematical structure of these strategic encounters, providing a tool applicable to a vast range of theoretical investigations into cooperation. ",
            "id": "2747583",
            "problem": "In the Iterated Prisoner’s Dilemma (IPD), two individuals repeatedly play the standard Prisoner’s Dilemma stage game with payoffs $\\{T,R,P,S\\}$ satisfying $T>R>P>S$, where $T$ is the temptation payoff, $R$ is the mutual cooperation reward, $P$ is the mutual defection punishment, and $S$ is the sucker’s payoff. Consider two arbitrary memory-$1$ strategies for the row player and the column player, respectively. Each strategy is specified by a vector of conditional cooperation probabilities given the previous round’s outcome: for the row player, $\\mathbf{p}=(p_{CC},p_{CD},p_{DC},p_{DD})$, and for the column player, $\\mathbf{q}=(q_{CC},q_{CD},q_{DC},q_{DD})$. Assume all eight conditional probabilities lie strictly in the open interval $(0,1)$ so that the induced Markov chain is ergodic.\n\nModel the repeated interaction as a time-homogeneous Markov chain on the four states $\\{CC,CD,DC,DD\\}$, where the first letter denotes the row player’s action and the second letter the column player’s action. Let the long-run stationary distribution over these four states be $\\boldsymbol{\\pi}=(\\pi_{CC},\\pi_{CD},\\pi_{DC},\\pi_{DD})$.\n\nStarting only from:\n- the definition of the Markov transition kernel generated by independent conditional cooperation choices in each state,\n- the definition of a stationary distribution $\\boldsymbol{\\pi}$ satisfying $\\boldsymbol{\\pi}=\\boldsymbol{\\pi} \\mathbf{M}$ and $\\sum_{s}\\pi_{s}=1$, and\n- the definition of the row player’s long-run expected payoff as the stationary average of stage payoffs,\n\nderive a closed-form analytic expression for the row player’s stationary expected payoff as a function of $(p_{CC},p_{CD},p_{DC},p_{DD})$, $(q_{CC},q_{CD},q_{DC},q_{DD})$, and $(T,R,P,S)$.\n\nYour final answer must be a single closed-form analytic expression. Do not provide any numerical approximation or rounding.",
            "solution": "The problem asks for a closed-form analytic expression for the stationary expected payoff of the row player in an Iterated Prisoner's Dilemma, modeled as a Markov chain. The derivation must proceed from first principles.\n\nLet the four states of the Markov chain be the outcomes of a single round: $s_1 = CC$, $s_2 = CD$, $s_3 = DC$, and $s_4 = DD$. The first letter denotes the action of the row player and the second, the column player. Let $\\boldsymbol{\\pi} = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$ be the stationary distribution over these states, where $\\pi_1 = \\pi_{CC}$, $\\pi_2 = \\pi_{CD}$, $\\pi_3 = \\pi_{DC}$, and $\\pi_4 = \\pi_{DD}$.\n\nThe row player's strategy is given by the vector of conditional cooperation probabilities $\\mathbf{p} = (p_1, p_2, p_3, p_4) = (p_{CC}, p_{CD}, p_{DC}, p_{DD})$, where $p_i$ is the probability that the row player cooperates given the previous outcome was state $s_i$. Similarly, the column player's strategy is $\\mathbf{q} = (q_1, q_2, q_3, q_4) = (q_{CC}, q_{CD}, q_{DC}, q_{DD})$. The players' choices are independent, conditional on the previous state.\n\nThe transition probability from state $s_i$ to $s_1=CC$ is $p_i q_i$. The probability to transition to $s_2=CD$ is $p_i (1-q_i)$. To $s_3=DC$ is $(1-p_i) q_i$. To $s_4=DD$ is $(1-p_i) (1-q_i)$. The transition matrix $\\mathbf{M}$ is a $4 \\times 4$ matrix where $M_{ij}$ is the probability of transitioning from state $s_i$ to $s_j$.\nThe stationary distribution $\\boldsymbol{\\pi}$ is the unique left eigenvector of $\\mathbf{M}$ with eigenvalue $1$, satisfying $\\boldsymbol{\\pi} \\mathbf{M} = \\boldsymbol{\\pi}$ and the normalization condition $\\sum_{i=1}^{4} \\pi_i = 1$.\n\nIn the stationary state, various properties must be constant over time.\n1. The probability that the row player cooperates, $u_C^{\\text{row}}$, must be stationary. The probability of the row player having cooperated in the previous round is $\\pi_1 + \\pi_2$. The probability of cooperating in the next round is $\\sum_{i=1}^{4} \\pi_i p_i$. In equilibrium, these must be equal:\n$$ \\pi_1 + \\pi_2 = \\sum_{i=1}^{4} \\pi_i p_i $$\nThis can be rewritten as a linear equation for $\\boldsymbol{\\pi}$:\n$$ \\pi_1 (1-p_1) + \\pi_2 (1-p_2) - \\pi_3 p_3 - \\pi_4 p_4 = 0 $$\n\n2. Similarly, the probability that the column player cooperates, $u_C^{\\text{col}}$, must be stationary. The probability of having cooperated previously is $\\pi_1 + \\pi_3$, and the probability of cooperating next is $\\sum_{i=1}^{4} \\pi_i q_i$.\n$$ \\pi_1 + \\pi_3 = \\sum_{i=1}^{4} \\pi_i q_i $$\nThis yields another linear equation:\n$$ \\pi_1 (1-q_1) - \\pi_2 q_2 + \\pi_3 (1-q_3) - \\pi_4 q_4 = 0 $$\n\n3. The probability of mutual cooperation, $\\pi_1 = \\pi_{CC}$, must also be stationary. The probability of achieving mutual cooperation in the next round is $\\sum_{i=1}^{4} \\pi_i p_i q_i$.\n$$ \\pi_1 = \\sum_{i=1}^{4} \\pi_i p_i q_i $$\nThis provides a third linear equation:\n$$ \\pi_1 (1-p_1q_1) - \\pi_2 p_2q_2 - \\pi_3 p_3q_3 - \\pi_4 p_4q_4 = 0 $$\n\n4. The sum of probabilities must be one:\n$$ \\pi_1 + \\pi_2 + \\pi_3 + \\pi_4 = 1 $$\n\nLet us define four vectors in $\\mathbb{R}^4$:\n$$ \\mathbf{v}_p = (1-p_1, 1-p_2, -p_3, -p_4) $$\n$$ \\mathbf{v}_q = (1-q_1, -q_2, 1-q_3, -q_4) $$\n$$ \\mathbf{v}_{pq} = (1-p_1q_1, -p_2p_2q_2, -p_3q_3, -p_4q_4) $$\n$$ \\mathbf{1} = (1,1,1,1) $$\nThe four linear equations can be written as dot products with the stationary distribution vector $\\boldsymbol{\\pi} = (\\pi_1, \\pi_2, \\pi_3, \\pi_4)$:\n$$ \\boldsymbol{\\pi} \\cdot \\mathbf{v}_p = 0 $$\n$$ \\boldsymbol{\\pi} \\cdot \\mathbf{v}_q = 0 $$\n$$ \\boldsymbol{\\pi} \\cdot \\mathbf{v}_{pq} = 0 $$\n$$ \\boldsymbol{\\pi} \\cdot \\mathbf{1} = 1 $$\nThis is a system of linear equations for $\\boldsymbol{\\pi}$. Let $\\mathbf{A}$ be the $4 \\times 4$ matrix whose rows are these four vectors. In column vector notation, the system is $\\mathbf{A} \\boldsymbol{\\pi}^T = (0,0,0,1)^T$.\n\nThe long-run expected payoff for the row player, $E_{\\text{row}}$, is the average of the stage game payoffs, weighted by the stationary probabilities of the corresponding outcomes. Let the payoff vector be $\\mathbf{P} = (R, S, T, P)$, where $R$, $S$, $T$, and $P$ are the payoffs for outcomes $CC$, $CD$, $DC$, and $DD$ respectively.\n$$ E_{\\text{row}} = \\pi_1 R + \\pi_2 S + \\pi_3 T + \\pi_4 P = \\boldsymbol{\\pi} \\cdot \\mathbf{P} $$\n\nTo find $E_{\\text{row}}$, we can solve an adjoint linear system. Let $\\mathbf{y} = (y_1, y_2, y_3, y_4)^T$ be a vector such that $\\mathbf{A}^T \\mathbf{y} = \\mathbf{P}^T$. Then $\\mathbf{y}^T \\mathbf{A} = \\mathbf{P}$. Multiplying by $\\boldsymbol{\\pi}^T$ on the right gives $\\mathbf{y}^T \\mathbf{A} \\boldsymbol{\\pi}^T = \\mathbf{P} \\boldsymbol{\\pi}^T = E_{\\text{row}}$. Since $\\mathbf{A} \\boldsymbol{\\pi}^T = (0,0,0,1)^T$, we have $\\mathbf{y}^T (0,0,0,1)^T = E_{\\text{row}}$, which simplifies to $y_4 = E_{\\text{row}}$.\n\nSo, we must solve for $y_4$ from the system $\\mathbf{A}^T \\mathbf{y} = \\mathbf{P}^T$:\n$$ \\begin{pmatrix}\n(1-p_1) & (1-q_1) & (1-p_1q_1) & 1 \\\\\n(1-p_2) & -q_2 & -p_2q_2 & 1 \\\\\n-p_3 & (1-q_3) & -p_3q_3 & 1 \\\\\n-p_4 & -q_4 & -p_4q_4 & 1\n\\end{pmatrix}\n\\begin{pmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ y_4 \\end{pmatrix}\n=\n\\begin{pmatrix} R \\\\ S \\\\ T \\\\ P \\end{pmatrix} $$\nUsing Cramer's rule to find $y_4$:\n$$ y_4 = \\frac{\\det(\\mathbf{A}^T_{y_4})}{\\det(\\mathbf{A}^T)} $$\nwhere $\\mathbf{A}^T_{y_4}$ is the matrix $\\mathbf{A}^T$ with its fourth column replaced by the payoff vector $\\mathbf{P}^T$. Since $\\det(\\mathbf{A}^T) = \\det(\\mathbf{A})$, we have our final expression.\n\nThe numerator is the determinant of the matrix formed by the vectors $\\mathbf{v}_p^T, \\mathbf{v}_q^T, \\mathbf{v}_{pq}^T$ and $\\mathbf{P}^T$:\n$$ \\text{Numerator} = \\det \\begin{pmatrix}\n1-p_1 & 1-q_1 & 1-p_1q_1 & R \\\\\n1-p_2 & -q_2 & -p_2q_2 & S \\\\\n-p_3 & 1-q_3 & -p_3q_3 & T \\\\\n-p_4 & -q_4 & -p_4q_4 & P\n\\end{pmatrix} $$\nThe denominator is the determinant of the matrix formed by $\\mathbf{v}_p^T, \\mathbf{v}_q^T, \\mathbf{v}_{pq}^T$ and $\\mathbf{1}^T$:\n$$ \\text{Denominator} = \\det \\begin{pmatrix}\n1-p_1 & 1-q_1 & 1-p_1q_1 & 1 \\\\\n1-p_2 & -q_2 & -p_2q_2 & 1 \\\\\n-p_3 & 1-q_3 & -p_3q_3 & 1 \\\\\n-p_4 & -q_4 & -p_4q_4 & 1\n\\end{pmatrix} $$\nIn these matrices, $p_1=p_{CC}, p_2=p_{CD}, p_3=p_{DC}, p_4=p_{DD}$, and $q_1=q_{CC}, q_2=q_{CD}, q_3=q_{DC}, q_4=q_{DD}$. The final closed-form expression for the row player's stationary expected payoff is the ratio of these two determinants.",
            "answer": "$$ \\boxed{ \\frac{\\det \\begin{pmatrix}\n1-p_{CC} & 1-q_{CC} & 1-p_{CC}q_{CC} & R \\\\\n1-p_{CD} & -q_{CD} & -p_{CD}q_{CD} & S \\\\\n-p_{DC} & 1-q_{DC} & -p_{DC}q_{DC} & T \\\\\n-p_{DD} & -q_{DD} & -p_{DD}q_{DD} & P\n\\end{pmatrix}}{\\det \\begin{pmatrix}\n1-p_{CC} & 1-q_{CC} & 1-p_{CC}q_{CC} & 1 \\\\\n1-p_{CD} & -q_{CD} & -p_{CD}q_{CD} & 1 \\\\\n-p_{DC} & 1-q_{DC} & -p_{DC}q_{DC} & 1 \\\\\n-p_{DD} & -q_{DD} & -p_{DD}q_{DD} & 1\n\\end{pmatrix}} } $$"
        }
    ]
}