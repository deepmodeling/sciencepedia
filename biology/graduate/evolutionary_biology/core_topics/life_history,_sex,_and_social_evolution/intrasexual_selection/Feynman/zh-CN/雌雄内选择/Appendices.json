{
    "hands_on_practices": [
        {
            "introduction": "为了理解为何在种内竞争中，攻击性的“守护者”和机会主义的“偷袭者”等不同竞争策略能够共存，我们可以运用演化博弈论。本练习将提供一个模拟这些互作的实践机会，其中一个策略的适应度收益是频率依赖的。通过计算演化稳定策略（Evolutionarily Stable Strategy, ESS），你将揭示在理论上允许种群内行为多态性得以稳定维持的条件。",
            "id": "2727329",
            "problem": "在一个充分混合的无限大种群中，雄性个体通过性内竞争来争夺每次竞赛中的单个交配机会，个体可以采取两种替代性繁殖策略之一：“守卫”或“偷袭”。互动是成对发生的，收益代表每次相遇的期望受精数，其中包含了竞赛和特定策略行为的收益与成本。假设适应度与期望收益成正比，并且在随机匹配的条件下，选择是频率依赖性的。\n\n假设一个使用策略 $i \\in \\{\\text{guard}, \\text{sneak}\\}$ 的焦点个体对抗一个使用策略 $j \\in \\{\\text{guard}, \\text{sneak}\\}$ 的对手时，其收益由以下矩阵给出（矩阵元素为焦点个体每次相遇的期望受精数）：\n$$\n\\begin{pmatrix}\na & b \\\\\nc & d\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.2 & 0.8 \\\\\n0.3 & 0.5\n\\end{pmatrix},\n$$\n其中，行代表焦点个体的策略，列代表对手的策略。例如，$a=0.2$ 是一个“守卫”者与另一个“守卫”者匹配时的期望收益，$c=0.3$ 是一个“偷袭”者与一个“守卫”者匹配时的期望收益。\n\n仅使用以下基本原理：(i) 适应度与期望收益成正比；(ii) 在频率依赖性选择下，一个同时存在两种策略的混合策略均衡要求这些策略在种群中的期望适应度相等；(iii) 在一个大种群中，随机匹配产生的期望收益是关于对手频率的平均值，请从第一性原理推导出“守卫”和“偷袭”的混合策略均衡频率。请将您的最终答案表示为一个单行矩阵，按顺序包含“守卫”和“偷袭”的均衡频率。如果均衡是内部的，请提供精确值，不要四舍五入。如果不存在内部均衡，请提供在这些假设下与进化稳定性一致的边界构成。\n\n无需单位。最终答案必须是指定的单行矩阵格式。",
            "solution": "该问题已经过验证，被认为是科学上可靠、提法恰当且客观的。它提出了一个进化博弈论中的标准问题，为严谨求解提供了所有必要的参数和假设。不存在逻辑矛盾或事实错误。我们可以继续。\n\n设 $p$ 为种群中“守卫”策略的频率，$q$ 为“偷袭”策略的频率。由于只有这两种策略，它们的频率之和必须为1：\n$$p + q = 1$$\n因此，$q = 1 - p$。\n\n问题陈述，在一个无限大的充分混合种群中，互动是成对的且匹配是随机的。个体的适应度与其期望收益成正比。我们可以将每种策略的期望收益（“守卫”记为 $W_G$，“偷袭”记为 $W_S$）表示为“守卫”者频率 $p$ 的函数。\n\n使用“守卫”策略的焦点个体的期望收益是其对抗“守卫”者和“偷袭”者的收益的加权平均值，权重为这些策略在种群中的频率：\n$$W_G(p) = p \\cdot \\text{Payoff(Guard, Guard)} + (1-p) \\cdot \\text{Payoff(Guard, Sneak)}$$\n使用给定的收益矩阵值 $a = 0.2$ 和 $b = 0.8$，这变为：\n$$W_G(p) = p(0.2) + (1-p)(0.8)$$\n\n同样，使用“偷袭”策略的焦点个体的期望收益是：\n$$W_S(p) = p \\cdot \\text{Payoff(Sneak, Guard)} + (1-p) \\cdot \\text{Payoff(Sneak, Sneak)}$$\n使用给定的收益矩阵值 $c = 0.3$ 和 $d = 0.5$，这变为：\n$$W_S(p) = p(0.3) + (1-p)(0.5)$$\n\n根据频率依赖性选择的基本原理，一个稳定的混合策略均衡（其中两种策略在种群中共存，即一个内部均衡，其中 $0 < p < 1$）要求每种策略的期望适应度（收益）相等。设“守卫”者的均衡频率为 $p^*$。在此均衡点，我们必须有：\n$$W_G(p^*) = W_S(p^*)$$\n\n代入期望收益的表达式：\n$$p^*(0.2) + (1-p^*)(0.8) = p^*(0.3) + (1-p^*)(0.5)$$\n\n我们现在求解这个关于 $p^*$ 的线性方程。\n首先，展开各项：\n$$0.2p^* + 0.8 - 0.8p^* = 0.3p^* + 0.5 - 0.5p^*$$\n合并两边包含 $p^*$ 的项：\n$$0.8 - 0.6p^* = 0.5 - 0.2p^*$$\n现在，我们将含有 $p^*$ 的项分离到一边，常数项分离到另一边：\n$$0.8 - 0.5 = 0.6p^* - 0.2p^*$$\n$$0.3 = 0.4p^*$$\n求解 $p^*$：\n$$p^* = \\frac{0.3}{0.4} = \\frac{3}{4}$$\n\n这是“守卫”策略的均衡频率。由于 $0 < \\frac{3}{4} < 1$，这是一个内部均衡。“偷袭”策略的均衡频率 $q^*$ 为：\n$$q^* = 1 - p^* = 1 - \\frac{3}{4} = \\frac{1}{4}$$\n\n为了使这个混合均衡是进化稳定的，一个稀有策略必须能够侵入一个由另一种策略主导的种群。这对应于条件 $c > a$ （“偷袭”者侵入“守卫”者种群）和 $b > d$ （“守卫”者侵入“偷袭”者种群）。\n让我们用给定的收益来检查这些条件：\n1. 是否 $c > a$？即 $0.3 > 0.2$？是的，此条件成立。\n2. 是否 $b > d$？即 $0.8 > 0.5$？是的，此条件也成立。\n由于两个条件都满足，计算出的内部不动点是一个进化稳定策略（ESS）。\n\n“守卫”的均衡频率为 $p^* = \\frac{3}{4}$，“偷袭”的均衡频率为 $q^* = \\frac{1}{4}$。问题要求答案为按此顺序包含这些频率的单行矩阵。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{4} & \\frac{1}{4}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "博弈论解释了策略多样性“为何”存在，但我们同样需要工具来衡量真实种群中的选择强度。本练习聚焦于量化交配成功与适应度之间的关系，这是性选择理论的基石。通过从第一性原理推导性选择机会（$I_s$）和贝特曼梯度（$\\beta_{ss}$），你将学会如何将繁殖结果的原始数据转化为衡量选择强度的基本指标。",
            "id": "2727284",
            "problem": "您正在研究一个性别内的性内选择，该性别中的个体为争夺配偶而竞争。设求偶成功率为随机变量 $m$（个体在单个繁殖期内获得的配偶数量），其样本均值为 $\\bar{m}=2.0$，样本方差为 $\\mathrm{Var}(m)=3.0$。个体繁殖成功率（绝对适合度）建模为 $w=1+0.8\\,m+\\varepsilon$，其中 $\\varepsilon$ 是一个均值为零的残差，代表围绕线性均值的、具有泊松误差结构的随机人口统计噪声。假设 $m$ 和 $\\varepsilon$ 相互独立，并且对于给定的 $m$，$w$ 的条件均值的回归设定是正确的。\n\n仅从性选择理论和回归分析的核心定义出发，且不使用任何现成的公式，完成以下任务：\n\n1) 定义相对求偶成功率 $\\tilde{m}$ 和相对适合度 $\\tilde{w}$，并从第一性原理出发，将性选择机会 $I_{s}$ 推导为相对求偶成功率的方差。然后根据所提供的汇总统计数据计算 $I_{s}$。\n\n2) 将特定性别的贝特曼梯度 $\\beta_{ss}$ 定义为目标性别内相对适合度对相对求偶成功率的线性回归斜率。从给定的 $w$ 的条件均值模型和相对量的定义出发，推导出以回归和样本矩表示的 $\\beta_{ss}$ 表达式，并根据所提供的信息计算其数值。\n\n明确陈述您所需的任何假设，并从基本的统计恒等式（如期望的性质、尺度变换下的方差以及线性回归斜率与条件期望之间的关系）出发，证明每个代数步骤的合理性。将您的最终数值答案四舍五入至四位有效数字，并以无量纲小数形式报告。",
            "solution": "所述问题具有科学依据，论述清晰且客观。它基于演化生物学的既定原则，特别是性选择的定量分析。所有必要的数据和定义均已提供，不存在任何会妨碍得出严谨、唯一解的矛盾或模糊之处。该问题要求从第一性原理进行推导，而非应用现成公式，这是一项有效的学术练习。因此，我将开始解答。\n\n主要假设是，为本次分析之目的，所提供的样本矩，即均值 $\\bar{m}$ 和方差 $\\mathrm{Var}(m)$，被视作其背后分布的真实参数。所有推导都将依赖于基本的统计恒等式。\n\n第一部分：性选择机会 $I_{s}$\n\n首先，我们定义相对量。相对求偶成功率 $\\tilde{m}$ 是个体的求偶成功率 $m$ 除以该性别的平均求偶成功率 $\\bar{m}$。\n$$ \\tilde{m} = \\frac{m}{\\bar{m}} $$\n同样，相对适合度 $\\tilde{w}$ 是个体的适合度 $w$ 除以该性别的平均适合度 $\\bar{w}$。\n$$ \\tilde{w} = \\frac{w}{\\bar{w}} $$\n性选择机会 $I_{s}$ 定义为相对求偶成功率的方差。\n$$ I_{s} = \\mathrm{Var}(\\tilde{m}) $$\n我们从此定义推导出 $I_{s}$ 的表达式。使用尺度变换下的方差性质 $\\mathrm{Var}(aX) = a^2 \\mathrm{Var}(X)$，其中 $a$ 是一个常数。在此背景下，$\\bar{m}$ 是该种群样本的一个常数标量。\n$$ I_{s} = \\mathrm{Var}\\left(\\frac{m}{\\bar{m}}\\right) = \\left(\\frac{1}{\\bar{m}}\\right)^2 \\mathrm{Var}(m) = \\frac{\\mathrm{Var}(m)}{\\bar{m}^2} $$\n问题提供了值 $\\bar{m} = 2.0$ 和 $\\mathrm{Var}(m) = 3.0$。将这些值代入推导出的表达式：\n$$ I_{s} = \\frac{3.0}{(2.0)^2} = \\frac{3.0}{4.0} = 0.75 $$\n作为一个保留四位有效数字的无量纲小数，该值为 $0.7500$。\n\n第二部分：特定性别的贝特曼梯度 $\\beta_{ss}$\n\n特定性别的贝特曼梯度 $\\beta_{ss}$ 定义为相对适合度 $\\tilde{w}$ 对相对求偶成功率 $\\tilde{m}$ 的线性回归斜率。简单线性回归斜率的公式是两个变量的协方差除以预测变量的方差。\n$$ \\beta_{ss} = \\frac{\\mathrm{Cov}(\\tilde{m}, \\tilde{w})}{\\mathrm{Var}(\\tilde{m})} $$\n分母是我们已经推导出的性选择机会 $I_{s}$。\n$$ \\mathrm{Var}(\\tilde{m}) = I_{s} = \\frac{\\mathrm{Var}(m)}{\\bar{m}^2} $$\n我们现在必须推导分子 $\\mathrm{Cov}(\\tilde{m}, \\tilde{w})$ 的表达式。使用性质 $\\mathrm{Cov}(aX, bY) = ab \\, \\mathrm{Cov}(X, Y)$：\n$$ \\mathrm{Cov}(\\tilde{m}, \\tilde{w}) = \\mathrm{Cov}\\left(\\frac{m}{\\bar{m}}, \\frac{w}{\\bar{w}}\\right) = \\frac{1}{\\bar{m}\\bar{w}} \\mathrm{Cov}(m, w) $$\n为了继续，我们需要 $\\bar{w}$ 和 $\\mathrm{Cov}(m, w)$ 的表达式。\n绝对适合度的模型是 $w = 1 + 0.8m + \\varepsilon$。平均适合度 $\\bar{w}$ 是 $w$ 的期望值。\n$$ \\bar{w} = E[w] = E[1 + 0.8m + \\varepsilon] $$\n根据期望的线性性质：\n$$ \\bar{w} = E[1] + 0.8E[m] + E[\\varepsilon] $$\n鉴于 $\\varepsilon$ 是一个均值为零的残差，所以 $E[\\varepsilon]=0$。我们使用样本均值 $\\bar{m}$作为 $E[m]$的估计量。\n$$ \\bar{w} = 1 + 0.8\\bar{m} $$\n接下来，我们确定 $\\mathrm{Cov}(m, w)$。\n$$ \\mathrm{Cov}(m, w) = \\mathrm{Cov}(m, 1 + 0.8m + \\varepsilon) $$\n使用协方差的双线性性质：\n$$ \\mathrm{Cov}(m, w) = \\mathrm{Cov}(m, 1) + \\mathrm{Cov}(m, 0.8m) + \\mathrm{Cov}(m, \\varepsilon) $$\n与常数的协方差为零，所以 $\\mathrm{Cov}(m, 1) = 0$。一个变量与其自身尺度变换后的协方差为 $\\mathrm{Cov}(m, 0.8m) = 0.8\\mathrm{Cov}(m,m) = 0.8\\mathrm{Var}(m)$。问题陈述 $m$ 和 $\\varepsilon$ 是独立的随机变量。独立性的一个关键性质是独立变量之间的协方差为零。因此，$\\mathrm{Cov}(m, \\varepsilon) = 0$。\n结合这些结果可得：\n$$ \\mathrm{Cov}(m, w) = 0.8\\mathrm{Var}(m) $$\n请注意，关于 $\\varepsilon$ 的泊松误差结构的信息意味着异方差性，即 $\\mathrm{Var}(\\varepsilon|m) = 1+0.8m$。这对于评估回归斜率的精度很重要，但如此处所示，它不影响斜率点估计本身的计算。\n\n现在我们组合出 $\\beta_{ss}$ 的表达式：\n$$ \\beta_{ss} = \\frac{\\mathrm{Cov}(\\tilde{m}, \\tilde{w})}{\\mathrm{Var}(\\tilde{m})} = \\frac{\\frac{1}{\\bar{m}\\bar{w}} \\mathrm{Cov}(m, w)}{\\frac{\\mathrm{Var}(m)}{\\bar{m}^2}} = \\frac{\\bar{m}}{\\bar{w}} \\frac{\\mathrm{Cov}(m, w)}{\\mathrm{Var}(m)} $$\n代入我们关于 $\\mathrm{Cov}(m, w)$ 和 $\\bar{w}$ 的表达式：\n$$ \\beta_{ss} = \\frac{\\bar{m}}{1 + 0.8\\bar{m}} \\frac{0.8\\mathrm{Var}(m)}{\\mathrm{Var}(m)} $$\n$\\mathrm{Var}(m)$ 项相互抵消，前提是 $\\mathrm{Var}(m) \\neq 0$，而 $\\mathrm{Var}(m)=3.0$ 满足该条件。这得出了贝特曼梯度的最终推导表达式：\n$$ \\beta_{ss} = \\frac{0.8\\bar{m}}{1 + 0.8\\bar{m}} $$\n最后，我们使用 $\\bar{m} = 2.0$ 计算数值：\n$$ \\beta_{ss} = \\frac{0.8(2.0)}{1 + 0.8(2.0)} = \\frac{1.6}{1 + 1.6} = \\frac{1.6}{2.6} = \\frac{16}{26} = \\frac{8}{13} $$\n作为一个无量纲小数，该值约为 $0.6153846...$。四舍五入到四位有效数字，结果是 $0.6154$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.7500 & 0.6154\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "自然种群受到选择、遗传漂变和环境波动等多种力量的复杂相互作用，这是简单的分析模型通常无法完全捕捉的。这项综合性练习将挑战你构建一个基于个体的模拟（Individual-Based Model, IBM），这是一个探索此类复杂性的强大现代工具。通过在随机环境中对密度和频率依赖的收益进行建模，你将在评估这些综合因素如何影响替代性繁殖策略的长期持续性方面，获得宝贵的实践经验。",
            "id": "2727271",
            "problem": "您将实现、运行并总结一个体化模拟，以评估在性内竞争中，当收益受密度依赖时，环境随机性如何影响替代性繁殖策略 (ARTs) 的存续性。请使用以下基于达尔文适应度以及频率和密度依赖性选择等核心原则的设定。\n\n定义与基本原理：\n- 性内选择是由同性个体之间为争夺交配机会而产生的选择。替代性繁殖策略 (ARTs) 是指同一性别内的个体为获得配偶而采用的不同行为或形态策略。个体化模型 (IBM) 随时间推移明确地追踪个体及其特征。\n- 达尔文适应度是个体贡献给下一代的存活后代的期望数量。在具有不重叠世代的离散时间模型中，选择通过差异性繁殖成功率来运作。\n- 当一种策略的成功与否取决于每个交配机会的竞争水平时，就会产生密度依赖性收益；当收益取决于策略频率时，就会产生频率依赖性选择。\n\n模型描述：\n- 种群结构：一个雄性种群，拥有两种策略：守卫者 (表示为 $G$) 和偷袭者 (表示为 $S$)。在第 $t$ 代，雄性总数为 $N_t = n_{G,t} + n_{S,t}$。设雄性最大数量为一个固定的环境承载量 $K$。下一代通过密度调节形成，规模为 $K$ (从后代中进行 Wright–Fisher 抽样)。\n- 交配机会的环境随机性：在第 $t$ 代，环境调节交配机会的数量 $R_t$。从均值为 $1$、变异系数为 $c_{\\mathrm{env}}$ 的对数正态分布中抽取一个环境乘数 $E_t$。然后抽取 $R_t \\sim \\mathrm{Poisson}(E_t \\, \\bar{R})$。如果 $R_t = 0$，则设置 $R_t \\leftarrow 1$，以避免后续计算中出现除以零的错误。\n- 竞争指数：定义每个交配机会的竞争为 $q_t = \\dfrac{N_t}{R_t}$。当每个机会的雄性数量很多（单位资源的密度高）时，该指数高；当环境为每个雄性提供很多机会时，该指数低。\n- 密度依赖的策略权重：每个雄性的竞争权重取决于 $q_t$：\n  - 守卫者：$W_G(q_t) = \\dfrac{\\alpha_G}{1 + \\beta_G \\, q_t}$。\n  - 偷袭者：$W_S(q_t) = \\dfrac{\\alpha_S \\, q_t}{1 + \\beta_S \\, q_t}$。\n  此处 $\\alpha_G,\\beta_G,\\alpha_S,\\beta_S > 0$ 是策略特有的参数。低 $q_t$ 有利于 $G$ 策略，而高 $q_t$ 有利于 $S$ 策略。\n- 每次交配的竞争成功率：对于 $R_t$ 个交配机会中的每一个，都从当前雄性种群中选择一个获胜者。在给定的一代中，假设策略内部对称，获胜者属于 $S$ 策略的概率为\n  \n$$\n  p_{S,t} \\;=\\; \\frac{n_{S,t} \\, W_S(q_t)}{n_{S,t} \\, W_S(q_t) \\;+\\; n_{G,t} \\, W_G(q_t)} \\,,\n  $$\n\n  而获胜者属于 $G$ 策略的概率为 $1 - p_{S,t}$。在确定获胜策略后，获胜个体在该策略的雄性中被均匀选择（基于个体的分配）。\n- 突变（策略转换）：后代继承父代的策略，但会以每个后代 $\\mu$ 的速率发生 $G \\leftrightarrow S$ 之间的对称突变。\n- 密度调节 (Wright–Fisher 抽样)：设 $O_{S,t}$ 和 $O_{G,t}$ 分别为（突变后）$S$ 和 $G$ 策略后代的总数。下一代的大小为 $K$，通过多项式抽样形成，其概率分别为 $O_{S,t}/(O_{S,t}+O_{G,t})$ 和 $O_{G,t}/(O_{S,t}+O_{G,t})$。\n- 初始化：在第 $t = 0$ 代开始，设置 $n_{S,0} = \\lfloor f_{S,0} \\, K \\rfloor$ 和 $n_{G,0} = K - n_{S,0}$。\n\n目标：\n- 对于下方测试套件中的每一组参数，模拟 $R$ 次独立的重复实验，每个实验进行 $T$ 代，并计算在最终第 $T$ 代时两种策略都存在的重复实验所占的比例（以小数表示），即 $n_{S,T} \\ge 1$ 且 $n_{G,T} \\ge 1$。这个比例即为估算的存续概率。\n\n必须遵循的实现细节：\n- 对数正态环境乘数 $E_t$ 的参数化：为实现均值 $1$ 和变异系数 $c_{\\mathrm{env}}$，使用一个正态分布 $\\mathcal{N}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$，其参数为\n  \n$$\n  \\sigma_{\\ln} \\;=\\; \\sqrt{\\ln(1 + c_{\\mathrm{env}}^2)} \\,, \\quad\n  \\mu_{\\ln} \\;=\\; -\\frac{1}{2}\\,\\sigma_{\\ln}^2 \\,,\n  $$\n\n  并设置 $E_t = \\exp(Z_t)$, 其中 $Z_t \\sim \\mathcal{N}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$。\n- 在每一代 $t$，给定 $n_{S,t}, n_{G,t}, q_t$，首先计算 $p_{S,t}$。然后，抽样 $S$ 策略获胜者的数量 $W_{S,t} \\sim \\mathrm{Binomial}(R_t, p_{S,t})$，并设置 $W_{G,t} = R_t - W_{S,t}$。接着，在给定 $W_{S,t}$ 和 $n_{S,t}$ 的条件下，通过一个概率相等的 ($1/n_{S,t}$) 多项式分布将胜利分配给单个 $S$ 策略雄性（如果 $n_{S,t} > 0$；否则 $W_{S,t} = 0$）。对 $G$ 策略执行类似步骤。通过抽样策略翻转的数量 $M_{S\\to G,t} \\sim \\mathrm{Binomial}(W_{S,t}, \\mu)$ 和 $M_{G\\to S,t} \\sim \\mathrm{Binomial}(W_{G,t}, \\mu)$ 来应用突变，然后设置\n  \n$$\n  O_{S,t} \\;=\\; W_{S,t} - M_{S\\to G,t} + M_{G\\to S,t}, \\quad\n  O_{G,t} \\;=\\; W_{G,t} - M_{G\\to S,t} + M_{S\\to G,t}.\n  $$\n\n  最后，通过抽样 $n_{S,t+1} \\sim \\mathrm{Binomial}\\!\\left(K, \\dfrac{O_{S,t}}{O_{S,t}+O_{G,t}}\\right)$ 来形成第 $t+1$ 代，并设置 $n_{G,t+1} = K - n_{S,t+1}$。\n- 所有的随机抽样在重复实验和世代之间必须是独立的。\n\n测试套件：\n实现您的程序，使其能精确运行以下四个测试用例。对于每个用例，输出估算的存续概率，并四舍五入到三位小数。\n- 用例 A (基线变异性)：\n  - $K = 200$, $\\bar{R} = 100$, $c_{\\mathrm{env}} = 0.3$, $T = 200$, $R = 60$, $f_{S,0} = 0.5$,\n  - $\\alpha_G = 1.0$, $\\beta_G = 0.6$, $\\alpha_S = 0.9$, $\\beta_S = 0.2$, $\\mu = 1\\times 10^{-5}$。\n- 用例 B (除人口统计学机会外无环境变异性)：\n  - 与用例 A 相同，但 $c_{\\mathrm{env}} = 0.0$。\n- 用例 C (高环境变异性)：\n  - 与用例 A 相同，但 $c_{\\mathrm{env}} = 1.0$。\n- 用例 D (资源贫乏环境)：\n  - 与用例 A 相同，但 $\\bar{R} = 50$ 且 $c_{\\mathrm{env}} = 0.3$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，内有四个存续概率估算值，按 $[A,B,C,D]$ 的顺序排列，并用方括号括起来。每个估算值必须是四舍五入到三位小数的浮点数。例如：$[0.517,0.433,0.602,0.128]$。",
            "solution": "该问题已经过严格验证，并被证实具有科学有效性。这是一个在计算进化生物学领域中的适定问题，构建于种群遗传学和进化博弈论的既定原则之上。所有参数和流程都已足够清晰地指定，足以实现唯一的算法。我们将着手解决此问题。\n\n该问题要求实现一个随机模拟，以研究在一个固定大小的雄性种群中，两种被称为守卫者 ($G$) 和偷袭者 ($S$) 的替代性繁殖策略 (ARTs) 的存续性。其进化动力学由四个关键过程的相互作用所支配：密度和频率依赖性选择、环境随机性、遗传漂变和突变。\n\n**1. 科学原理**\n\n该模型基于以下达尔文原则：\n\n- **密度和频率依赖性选择**：个体策略的繁殖成功率（或适应度）并非一个内在常数，而是取决于当下的生态和社会条件。这通过特定策略的竞争权重 $W_G(q_t)$ 和 $W_S(q_t)$ 来建模，它们是竞争指数 $q_t = N_t/R_t$ 的函数。该指数代表每个交配机会 ($R_t$) 的竞争雄性数量 ($N_t$，固定为环境承载量 $K$）。\n  - 守卫者权重 $W_G(q_t) = \\frac{\\alpha_G}{1 + \\beta_G \\, q_t}$ 是竞争指数 $q_t$ 的一个单调递减函数。当竞争程度低时（即资源相对于竞争者而言是丰富的），守卫者表现优异。\n  - 偷袭者权重 $W_S(q_t) = \\frac{\\alpha_S \\, q_t}{1 + \\beta_S \\, q_t}$ 是一个随竞争指数 $q_t$ 增加而增长的饱和函数。当守卫者之间的高度竞争为偷袭创造了机会时，偷袭者策略会蓬勃发展。\n  这种权衡可导致负频率依赖性选择：当一种策略变得过于普遍时，其成功率会下降，从而对较稀有的策略有利。这是维持多态性的经典机制。\n\n- **环境随机性**：交配机会的数量 $R_t$ 不是恒定的，而是在各代之间随机波动。这通过从一个泊松分布中抽取 $R_t$ 来建模，该分布的均值由一个环境乘数 $E_t$ 调节，而 $E_t$ 本身是从一个对数正态分布中抽取的。这种随机性直接影响竞争指数 $q_t$，导致选择环境从一代到下一代发生变化。这种波动既可能促进共存（例如，通过存储效应），也可能通过将系统推向极端状态而增加灭绝风险。\n\n- **遗传漂变**：种群大小是有限的，为 $K$。从一代到下一代的过渡被建模为一个 Wright-Fisher 过程，其中下一代的 $K$ 个个体是从当前代的后代池中抽样得出的。这个抽样过程纯粹由于偶然性引入了策略频率的随机波动，这种现象被称为遗传漂变。漂变是一种强大的力量，尤其在小种群中，即使某个等位基因或策略受到选择青睐，也可能导致其随机丢失。\n\n- **突变**：一个非零的突变率 $\\mu$ 使得后代有可能从其亲代继承一个不同的策略 ($G \\leftrightarrow S$)。突变作为一种微弱但持久的力量，可以在一个策略因漂变而丢失后重新引入它，从而阻止（等位基因）固定并促进长期存续。\n\n目标是计算存续概率，定义为在独立的模拟重复实验中，到最终第 $T$ 代时两种策略（$n_S > 0$ 且 $n_G > 0$）都存在的实验所占的比例。该指标量化了在指定的时间范围内，共存对抗遗传漂变和环境变异等随机力量的稳健性。\n\n**2. 算法实现**\n\n该模拟通过追踪在离散世代中每种策略的雄性数量 $n_{S,t}$ 和 $n_{G,t}$ 来进行。对于每组参数，模拟 $R$ 次独立的重复实验，每次模拟 $T$ 代。\n\n单次重复实验的算法如下：\n\n1.  **初始化 ($t=0$):**\n    根据初始频率 $f_{S,0}$ 和环境承载量 $K$ 设置初始种群构成：\n    $$ n_{S,0} = \\lfloor f_{S,0} \\cdot K \\rfloor $$\n    $$ n_{G,0} = K - n_{S,0} $$\n\n2.  **世代循环：** 对于从 $0$ 到 $T-1$ 的每一代 $t$：\n    a. 雄性总种群大小为 $N_t = n_{S,t} + n_{G,t} = K$。\n    b. **抽取环境状态：**\n       - 如果变异系数 $c_{\\mathrm{env}} > 0$，计算对数正态乘数所对应的正态分布的参数：\n         $$ \\sigma_{\\ln} = \\sqrt{\\ln(1 + c_{\\mathrm{env}}^2)} \\quad \\text{和} \\quad \\mu_{\\ln} = -\\frac{1}{2}\\,\\sigma_{\\ln}^2 $$\n         抽取 $Z_t \\sim \\mathcal{N}(\\mu_{\\ln}, \\sigma_{\\ln}^2)$ 并设置环境乘数 $E_t = \\exp(Z_t)$。\n       - 如果 $c_{\\mathrm{env}} = 0$，则设置 $E_t = 1$。\n    c. **确定交配机会：**\n       从泊松分布中抽取交配机会的数量 $R_t$：\n       $$ R_t \\sim \\mathrm{Poisson}(E_t \\cdot \\bar{R}) $$\n       为防止除以零，如果抽样结果为 $R_t = 0$，则将其设置为 $R_t = 1$。\n    d. **计算适应度分量：**\n       计算竞争指数 $q_t = K/R_t$ 和特定策略的竞争权重 $W_G(q_t)$ 与 $W_S(q_t)$。\n    e. **确定后代产量：**\n       某次交配由偷袭者获胜的概率为：\n       $$ p_{S,t} = \\frac{n_{S,t} \\cdot W_S(q_t)}{n_{S,t} \\cdot W_S(q_t) + n_{G,t} \\cdot W_G(q_t)} $$\n       来自偷袭者父亲的后代总数，记为 $W_{S,t}$，是从一个二项分布中抽取的，代表了 $R_t$ 次独立竞争的结果：\n       $$ W_{S,t} \\sim \\mathrm{Binomial}(R_t, p_{S,t}) $$\n       来自守卫者父亲的后代数量则为 $W_{G,t} = R_t - W_{S,t}$。这两个计数 $W_{S,t}$ 和 $W_{G,t}$ 代表了每种策略在突变前产生的后代总数。\n    f. **应用突变：**\n       因突变而转换策略的后代数量是从二项分布中抽取的：\n       $$ M_{S\\to G,t} \\sim \\mathrm{Binomial}(W_{S,t}, \\mu) $$\n       $$ M_{G\\to S,t} \\sim \\mathrm{Binomial}(W_{G,t}, \\mu) $$\n       每种类型的最终后代计数为：\n       $$ O_{S,t} = W_{S,t} - M_{S\\to G,t} + M_{G\\to S,t} $$\n       $$ O_{G,t} = W_{G,t} - M_{S\\to G,t} + M_{S\\to G,t} $$\n       后代总数仍为 $R_t = O_{S,t} + O_{G,t}$。\n    g. **形成下一代 (Wright-Fisher 抽样)：**\n       后代池中偷袭者类型后代的比例是 $p_{O,S} = O_{S,t} / R_t$。下一代中偷袭者的数量是从一个二项分布中抽取的，这模拟了从庞大的后代池中随机抽样 $K$ 个个体的过程：\n       $$ n_{S,t+1} \\sim \\mathrm{Binomial}(K, p_{O,S}) $$\n       守卫者的数量则为 $n_{G,t+1} = K - n_{S,t+1}$。这些新的计数成为第 $t+1$ 代的状态。\n\n3.  **计分与汇总：**\n    经过 $T$ 代后，评估最终状态 $(n_{S,T}, n_{G,T})$。如果 $n_{S,T} \\ge 1$ 且 $n_{G,T} \\ge 1$，则该次重复实验被计为“存续”。整个过程重复 $R$ 次。最终估算的存续概率是存续的重复实验总数除以 $R$。对测试套件中指定的每组参数都执行此流程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(K, R_bar, c_env, T, num_replicates, f_S0, alpha_G, beta_G, alpha_S, beta_S, mu):\n    \"\"\"\n    Runs an individual-based simulation for a given set of parameters.\n\n    Args:\n        K (int): Carrying capacity.\n        R_bar (float): Mean number of mating opportunities.\n        c_env (float): Coefficient of variation for environmental stochasticity.\n        T (int): Number of generations to simulate.\n        num_replicates (int): Number of independent simulation replicates.\n        f_S0 (float): Initial frequency of Sneaker tactic.\n        alpha_G, beta_G (float): Parameters for Guarder weight function.\n        alpha_S, beta_S (float): Parameters for Sneaker weight function.\n        mu (float): Symmetric mutation rate.\n\n    Returns:\n        float: The estimated persistence probability.\n    \"\"\"\n    persistent_replicates = 0\n\n    # Pre-calculate lognormal parameters if c_env > 0\n    if c_env > 0:\n        sigma_ln_sq = np.log(1 + c_env**2)\n        mu_ln = -0.5 * sigma_ln_sq\n        sigma_ln = np.sqrt(sigma_ln_sq)\n    else: # c_env == 0, deterministic environment\n        mu_ln, sigma_ln = 0.0, 0.0\n\n    for _ in range(num_replicates):\n        # Initialization\n        n_S = int(np.floor(f_S0 * K))\n        n_G = K - n_S\n\n        for _ in range(T):\n            # 1. Environmental Stochasticity\n            if c_env > 0:\n                E_t = np.exp(np.random.normal(mu_ln, sigma_ln))\n            else:\n                E_t = 1.0\n            \n            # 2. Mating Opportunities\n            mean_opportunities = E_t * R_bar\n            R_t = np.random.poisson(mean_opportunities)\n            if R_t == 0:\n                R_t = 1\n\n            # 3. Competition Index and Tactic Weights\n            q_t = K / R_t\n            W_G_t = alpha_G / (1.0 + beta_G * q_t)\n            W_S_t = (alpha_S * q_t) / (1.0 + beta_S * q_t)\n\n            # 4. Contest Success Probability\n            total_S_weight = n_S * W_S_t\n            total_G_weight = n_G * W_G_t\n            denominator = total_S_weight + total_G_weight\n            \n            p_S_t = total_S_weight / denominator if denominator > 0 else 0.0\n\n            # 5. Offspring Production (pre-mutation)\n            # Number of wins for each tactic\n            W_S_wins = np.random.binomial(R_t, p_S_t)\n            W_G_wins = R_t - W_S_wins\n\n            # 6. Mutation\n            mut_S_to_G = np.random.binomial(W_S_wins, mu)\n            mut_G_to_S = np.random.binomial(W_G_wins, mu)\n\n            # 7. Offspring Pool (post-mutation)\n            O_S_t = W_S_wins - mut_S_to_G + mut_G_to_S\n            # O_G_t = W_G_wins - mut_G_to_S + mut_S_to_G\n            # Total offspring O_total is always R_t\n            \n            total_offspring = O_S_t + (W_G_wins - mut_G_to_S + mut_S_to_G)\n            if total_offspring > 0:\n                p_offspring_S = O_S_t / total_offspring\n            else: \n                p_offspring_S = 0.5 \n\n            # 8. Wright-Fisher Sampling (next generation)\n            n_S = np.random.binomial(K, p_offspring_S)\n            n_G = K - n_S\n            \n            # If one tactic is lost, it can only be reintroduced by mutation.\n            # We can stop early if drift is strong and mu is 0, but here mu > 0.\n            if n_S == 0 or n_G == 0:\n                # If mu were 0, we could break here, but we must continue.\n                pass\n\n        # End of a replicate: check for persistence\n        if n_S >= 1 and n_G >= 1:\n            persistent_replicates += 1\n\n    return persistent_replicates / num_replicates\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    base_params = {\n        \"K\": 200, \"R_bar\": 100, \"c_env\": 0.3, \"T\": 200, \"num_replicates\": 60,\n        \"f_S0\": 0.5, \"alpha_G\": 1.0, \"beta_G\": 0.6, \"alpha_S\": 0.9, \n        \"beta_S\": 0.2, \"mu\": 1e-5\n    }\n    \n    # Note: For reproducibility, a seed should ideally be set.\n    # However, since the problem doesn't specify one, we will not set it.\n    # The results will vary slightly on each run.\n    # The provided example output is just one possible outcome.\n    # np.random.seed(42) # Example of setting a seed\n\n    test_cases = {\n        \"A\": base_params,\n        \"B\": {**base_params, \"c_env\": 0.0},\n        \"C\": {**base_params, \"c_env\": 1.0},\n        \"D\": {**base_params, \"R_bar\": 50, \"c_env\": 0.3}\n    }\n\n    results = []\n    for case_id in [\"A\", \"B\", \"C\", \"D\"]:\n        params = test_cases[case_id]\n        persistence_prob = run_simulation(**params)\n        results.append(f\"{persistence_prob:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\n# solve() # The function is not called to prevent execution in this environment, but the code is complete.\n# To generate the answer, one would run the solve() function.\n# For example, a possible output might be: [0.933,1.000,0.617,0.033]\n# The specific numbers will vary. The code itself is the verifiable answer.\n```"
        }
    ]
}