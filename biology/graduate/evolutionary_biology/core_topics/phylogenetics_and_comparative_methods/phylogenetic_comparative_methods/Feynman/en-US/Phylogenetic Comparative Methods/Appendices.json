{
    "hands_on_practices": [
        {
            "introduction": "A foundational challenge in comparative biology is the non-independence of species due to shared ancestry. Felsenstein's method of phylogenetically independent contrasts (PICs) was a landmark solution, transforming species data into a set of statistically independent values. This first exercise  will guide you through the manual calculation of a contrast, providing a concrete understanding of how raw trait values and branch lengths are used to account for phylogenetic relationships.",
            "id": "1761373",
            "problem": "An evolutionary biologist is studying the evolution of body size in a small group of scarab beetles. She has constructed a phylogeny and collected body size data for three species: *Rhinoceps ferox*, *Goliathus parvus*, and *Chalcosoma medius*. The phylogenetic relationships are as follows: *R. ferox* and *G. parvus* are sister species, and their common ancestor represents a clade that is sister to *C. medius*.\n\nThe branch lengths, representing evolutionary time in millions of years (Myr), are given:\n- The branch from the common ancestor of *R. ferox* and *G. parvus* to the present-day *R. ferox* is 2 Myr.\n- The branch from the common ancestor of *R. ferox* and *G. parvus* to the present-day *G. parvus* is 2 Myr.\n- The branch from the root of the three-species tree to the common ancestor of *R. ferox* and *G. parvus* is 3 Myr.\n- The branch from the root of the tree to the present-day *C. medius* is 5 Myr.\n\nThe average adult body lengths for these species are:\n- *Rhinoceps ferox*: 45.5 mm\n- *Goliathus parvus*: 52.1 mm\n- *Chalcosoma medius*: 38.0 mm\n\nTo prepare for a comparative analysis, one must compute the phylogenetically independent contrasts for the body length trait. Using the standard algorithm for this method, calculate the numerical value of the independent contrast computed at the root of this three-species tree. Assume a Brownian motion model of trait evolution. Express your answer rounded to three significant figures.",
            "solution": "The problem asks for the calculation of the phylogenetically independent contrast at the root of a three-species tree. We will use Felsenstein's algorithm, which proceeds from the tips of the tree down to the root.\n\nLet's denote the species and their traits and branch lengths with symbols for clarity.\nLet species A be *Rhinoceps ferox*, species B be *Goliathus parvus*, and species C be *Chalcosoma medius*.\nThe trait values (body length) are:\n$x_A = 45.5$ mm\n$x_B = 52.1$ mm\n$x_C = 38.0$ mm\n\nThe branch lengths are:\n- The terminal branch leading to A, $v_A = 2$ Myr.\n- The terminal branch leading to B, $v_B = 2$ Myr.\n- The terminal branch leading to C, $v_C = 5$ Myr.\n- The internal branch leading to the common ancestor of A and B, which we'll call Node 1, has length $v_{1, \\text{stem}} = 3$ Myr.\n\nThe algorithm consists of two main parts for this tree: first, calculating the contrast between the sister species A and B and estimating the state at their common ancestor (Node 1); second, calculating the contrast between Node 1 and species C.\n\n**Step 1: Calculate the contrast between sister species A and B.**\nThe first independent contrast, $C_1$, is the difference in trait values between A and B, scaled by the square root of the sum of their branch lengths. The order of subtraction is arbitrary; we will compute $x_B - x_A$.\n$$\nC_1 = \\frac{x_B - x_A}{\\sqrt{v_A + v_B}}\n$$\nSubstituting the values:\n$$\nC_1 = \\frac{52.1 - 45.5}{\\sqrt{2 + 2}} = \\frac{6.6}{\\sqrt{4}} = \\frac{6.6}{2} = 3.3\n$$\n\n**Step 2: Estimate the trait value at the common ancestor (Node 1).**\nThe trait value at Node 1, $x_1$, is estimated as a weighted average of the trait values of its descendants, where the weights are the inverse of the respective branch lengths.\n$$\nx_1 = \\frac{\\frac{1}{v_A}x_A + \\frac{1}{v_B}x_B}{\\frac{1}{v_A} + \\frac{1}{v_B}}\n$$\nSince $v_A = v_B = 2$, this simplifies to the arithmetic mean:\n$$\nx_1 = \\frac{x_A + x_B}{2} = \\frac{45.5 + 52.1}{2} = \\frac{97.6}{2} = 48.8\n$$\nSo, the estimated body length of the ancestor at Node 1 is 48.8 mm.\n\n**Step 3: Update the branch length for Node 1.**\nNode 1 now acts like a tip for the next calculation. Its branch length needs to be adjusted to account for the variance introduced by the estimation in Step 2. The new branch length, $v'_1$, is its original stem branch length plus a term related to the lengths of the branches descending from it.\n$$\nv'_1 = v_{1, \\text{stem}} + \\frac{v_A v_B}{v_A + v_B}\n$$\nSubstituting the values:\n$$\nv'_1 = 3 + \\frac{2 \\times 2}{2 + 2} = 3 + \\frac{4}{4} = 3 + 1 = 4\n$$\nThe adjusted branch length for Node 1 is 4 Myr.\n\n**Step 4: Calculate the contrast at the root.**\nThe final step is to calculate the contrast at the root of the tree. This contrast, $C_{\\text{root}}$, is between the newly characterized Node 1 and the remaining species, C. We use their respective trait values ($x_1$ and $x_C$) and branch lengths ($v'_1$ and $v_C$).\n$$\nC_{\\text{root}} = \\frac{x_1 - x_C}{\\sqrt{v'_1 + v_C}}\n$$\nSubstituting the calculated and given values:\n$$\nC_{\\text{root}} = \\frac{48.8 - 38.0}{\\sqrt{4 + 5}} = \\frac{10.8}{\\sqrt{9}} = \\frac{10.8}{3} = 3.6\n$$\nThe value of the independent contrast computed at the root is 3.6.\n\n**Step 5: Final rounding.**\nThe problem asks for the answer to be rounded to three significant figures. The calculated value is 3.6, which when expressed with three significant figures is 3.60.",
            "answer": "$$\\boxed{3.60}$$"
        },
        {
            "introduction": "While calculating contrasts is fundamental, modern comparative analyses often employ the more flexible Phylogenetic Generalized Least Squares (PGLS) framework. However, fitting a model is only half the battle; we must also critically evaluate its performance. This practice  confronts a common scenario: what does it mean when your model's residuals still show phylogenetic signal? Answering this question is crucial for robust scientific inference and points the way toward improving your evolutionary hypotheses.",
            "id": "1761351",
            "problem": "A team of evolutionary biologists is investigating the allometric scaling of gut length in herbivorous mammals. They hypothesize that a species' gut length, a key trait for digesting plant matter, is primarily a function of its body mass. To test this, they gather data on the average body mass and average gut length for 85 species of herbivores and construct a robust molecular phylogeny for these species.\n\nThey decide to use a Phylogenetic Generalized Least Squares (PGLS) model to account for the statistical non-independence of species due to shared ancestry. The model is specified as:\n$$ \\ln(\\text{Gut Length}) = \\beta_0 + \\beta_1 \\ln(\\text{Body Mass}) + \\epsilon $$\nwhere $\\epsilon$ is the error term. The PGLS procedure estimates the model parameters ($\\beta_0$, $\\beta_1$) while simultaneously estimating Pagel's lambda ($\\lambda$), a measure of phylogenetic signal that structures the expected variance-covariance of the error term $\\epsilon$.\n\nAfter fitting the model, the team obtains statistically significant estimates for the intercept $\\beta_0$ and the slope $\\beta_1$. As a standard diagnostic check, they extract the residuals from the fitted model. They then test these residuals for the presence of phylogenetic signal and find a statistically significant result (e.g., using a likelihood ratio test, they find $\\lambda_{\\text{residuals}} = 0.65$ with $p < 0.01$).\n\nWhich of the following is the most likely and direct interpretation of the finding that significant phylogenetic signal remains in the residuals of the PGLS model?\n\nA. The PGLS model has successfully accounted for all relevant phylogenetic effects, and the observed residual signal is a statistical artifact of the test used.\n\nB. The relationship between body mass and gut length is an example of pure Brownian motion evolution, meaning the PGLS model is the perfect and final model for these data.\n\nC. The model is misspecified, most likely because an important predictor variable that itself is phylogenetically patterned has been omitted.\n\nD. The significant slope $\\beta_1$ is spurious, and there is, in fact, no evolutionarily meaningful relationship between body mass and gut length.\n\nE. The phylogenetic tree used for the analysis is incorrect, and constructing a new tree from different genetic markers would eliminate the signal in the residuals.",
            "solution": "Let $y_{i}=\\ln(\\text{Gut Length}_{i})$ and $x_{i}=\\ln(\\text{Body Mass}_{i})$, and write the PGLS model in matrix form as\n$$\n\\mathbf{y}=\\mathbf{X}\\boldsymbol{\\beta}+\\boldsymbol{\\epsilon},\n$$\nwith $\\boldsymbol{\\epsilon}\\sim \\mathcal{N}\\!\\left(\\mathbf{0},\\,\\sigma^{2}\\mathbf{V}_{\\lambda}\\right)$, where $\\mathbf{X}$ has a column of ones and the predictor $x$, and $\\mathbf{V}_{\\lambda}$ is the phylogenetic variance-covariance matrix parameterized by Pagel’s $\\lambda$. A common specification is\n$$\n\\mathbf{V}_{\\lambda}=\\lambda \\mathbf{V}+(1-\\lambda)\\mathbf{D},\n$$\nwhere $\\mathbf{V}$ is the Brownian-motion covariance on the tree and $\\mathbf{D}=\\operatorname{diag}(\\mathbf{V})$, so that off-diagonal covariances are scaled by $\\lambda$ while the diagonal variances are preserved.\n\nGiven $\\lambda$, the generalized least squares estimator is\n$$\n\\hat{\\boldsymbol{\\beta}}=\\left(\\mathbf{X}^{\\top}\\mathbf{V}_{\\lambda}^{-1}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{\\top}\\mathbf{V}_{\\lambda}^{-1}\\mathbf{y}.\n$$\nDefine the residuals $\\mathbf{r}=\\mathbf{y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}}$. Under a correctly specified mean model $\\mathbf{X}\\boldsymbol{\\beta}$, the residuals should represent noise structured exactly as modeled by $\\mathbf{V}_{\\lambda}$; equivalently, after appropriate GLS whitening, no remaining phylogenetic structure should be detectable. Operationally, testing for phylogenetic signal in $\\mathbf{r}$ amounts to comparing models\n$$\n\\mathbf{r}\\sim \\mathcal{N}\\!\\left(\\mathbf{0},\\,\\sigma^{2}\\mathbf{V}_{\\lambda_{r}}\\right)\n\\quad \\text{versus} \\quad\n\\mathbf{r}\\sim \\mathcal{N}\\!\\left(\\mathbf{0},\\,\\sigma^{2}\\mathbf{I}\\right),\n$$\nand a significant estimate $\\hat{\\lambda}_{\\text{residuals}}>0$ indicates that residual covariance aligns with the tree beyond what would be expected if the predictor(s) fully captured phylogenetically patterned mean differences.\n\nThe empirical finding $\\hat{\\lambda}_{\\text{residuals}}=0.65$ with small $p$-value therefore implies that, after accounting for the fitted relationship $y=\\beta_{0}+\\beta_{1}x$, there remains systematic variation along the phylogeny. The most direct interpretation is model misspecification of the mean structure: an omitted predictor (or incorrect functional form) that is itself phylogenetically conserved causes residuals to inherit phylogenetic signal. This does not imply that the significant slope $\\beta_{1}$ is spurious; rather, it indicates that additional phylogenetically patterned predictors (e.g., fermentation strategy, diet composition, habitat, clade-specific intercepts/slopes, or nonlinearities) are needed. It also does not follow that the PGLS fully succeeded (contradicting option A), that the model is perfect under Brownian motion (contradicting option B), or that the tree must be incorrect (option E is not the most direct inference given the residual pattern).\n\nThus, the most likely and direct interpretation is that the model is misspecified due to omitted phylogenetically patterned predictors.",
            "answer": "$$\\boxed{C}$$"
        },
        {
            "introduction": "Beyond fitting a single model, a key task in modern evolutionary biology is to compare competing hypotheses about the evolutionary process itself. For example, has a trait evolved randomly like a 'random walk' (Brownian Motion), or has it been pulled towards an optimal value (Ornstein-Uhlenbeck)? This final, advanced practice  challenges you to build a simulation pipeline to explore these questions. By generating data under known conditions and then fitting models to it, you will gain deep insights into model selection, statistical power, and the fundamental behavior of our most important comparative tools.",
            "id": "2742906",
            "problem": "You are asked to implement a complete simulation-and-inference pipeline for phylogenetic comparative methods to evaluate the ability to detect phylogenetic signal and to distinguish evolutionary models. Specifically, you will simulate continuous traits evolving along an ultrametric, perfectly balanced, rooted binary phylogeny under the Ornstein–Uhlenbeck (OU) process with varying strength of stabilizing selection, and then assess (i) the power to detect non-zero phylogenetic signal via Pagel’s lambda ($\\lambda$) using a likelihood ratio test, and (ii) the frequency with which the OU model is preferred over Brownian Motion (BM) using the Akaike Information Criterion (AIC). The statistical estimation will be performed via Phylogenetic Generalized Least Squares (PGLS) specialized to the case of an intercept-only model.\n\nDefinitions and fundamental base:\n- Brownian Motion (BM): A continuous-time Gaussian process with independent increments. Along a branch of length $t$, the variance added is $\\sigma^2 t$, and the covariance between two tips equals $\\sigma^2$ times the time from the root to their most recent common ancestor (MRCA).\n- Ornstein–Uhlenbeck (OU) process: The stochastic differential equation is $dX_t = -\\alpha (X_t - \\theta)\\,dt + \\sigma\\,dB_t$, where $\\alpha \\ge 0$ is the attraction strength to the optimum $\\theta$, $\\sigma > 0$ is the diffusion rate, and $B_t$ is standard Brownian motion. On an ultrametric tree of height $T$, with root mean $\\mu$ and assuming a constant optimum, the tip vector is multivariate normal with mean vector $\\,\\mu \\mathbf{1}\\,$ and a covariance structure implied by the OU process.\n- Pagel’s lambda ($\\lambda$): A scalar that rescales the off-diagonal elements of the BM phylogenetic covariance matrix while keeping diagonal elements unchanged. Under an intercept-only model, estimation of $\\lambda$ is performed by maximizing the multivariate normal likelihood of the trait vector under the covariance $\\Sigma(\\lambda)$.\n- Phylogenetic Generalized Least Squares (PGLS): A generalized least squares framework where the error covariance $\\Sigma$ is the phylogenetic covariance implied by an evolutionary model. For an intercept-only model, the maximum likelihood estimates of the mean and variance parameters are obtained by generalized least squares using $\\Sigma$.\n- Akaike Information Criterion (AIC): For a model with maximized log-likelihood $\\ell$ and $k$ free parameters, $\\mathrm{AIC} = 2k - 2\\ell$. Smaller AIC indicates a preferred model.\n\nTree and covariance construction:\n- Consider an ultrametric, perfectly balanced, rooted binary tree with $n = 2^D$ tips, total height $T = 1$, and equal branch length $1/D$ per level, where $D = \\log_2 n$. For two tips $i$ and $j$, let $t_{ij}$ be the time from the root to their MRCA. On this tree, $t_{ij}$ equals the depth (in levels) of their least common ancestor divided by $D$.\n- Under BM with diffusion parameter $\\sigma^2$, the covariance between tips $i$ and $j$ is $\\Sigma^{\\mathrm{BM}}_{ij} = \\sigma^2 t_{ij}$ for $i \\ne j$, and the variance is $\\Sigma^{\\mathrm{BM}}_{ii} = \\sigma^2 T$.\n- Under OU with parameters $(\\alpha, \\sigma^2)$ on an ultrametric tree with height $T$, for $i \\ne j$,\n  $$\\Sigma^{\\mathrm{OU}}_{ij} = \\frac{\\sigma^2}{2\\alpha} \\exp\\!\\big(-\\alpha (2T - 2 t_{ij})\\big)\\,\\big(1 - e^{-2\\alpha t_{ij}}\\big),$$\n  and\n  $$\\Sigma^{\\mathrm{OU}}_{ii} = \\frac{\\sigma^2}{2\\alpha} \\big(1 - e^{-2\\alpha T}\\big).$$\n  For $\\alpha \\to 0$, this converges to BM with covariance as above.\n\nLikelihood and estimation:\n- Let $\\mathbf{y} \\in \\mathbb{R}^n$ denote the simulated trait vector and $\\mathbf{1}$ the $n$-vector of ones. For a given positive definite matrix $V$ and a positive scale parameter $s^2$, suppose $\\Sigma = s^2 V$. Under the multivariate normal likelihood with mean $\\mu \\mathbf{1}$, the generalized least squares estimators at fixed $V$ are:\n  $$\\hat{\\mu} = \\frac{\\mathbf{1}^\\top V^{-1} \\mathbf{y}}{\\mathbf{1}^\\top V^{-1} \\mathbf{1}}, \\quad \\hat{s}^2 = \\frac{1}{n}(\\mathbf{y} - \\hat{\\mu}\\mathbf{1})^\\top V^{-1} (\\mathbf{y} - \\hat{\\mu}\\mathbf{1}).$$\n  The corresponding profile log-likelihood is\n  $$\\ell(V \\mid \\mathbf{y}) = -\\frac{1}{2} \\left[n \\log(2\\pi) + n \\log\\!\\left(\\frac{1}{n}(\\mathbf{y} - \\hat{\\mu}\\mathbf{1})^\\top V^{-1} (\\mathbf{y} - \\hat{\\mu}\\mathbf{1})\\right) + \\log|V| + n \\right].$$\n- For BM, take $V^{\\mathrm{BM}}$ with $V^{\\mathrm{BM}}_{ii} = T$ and $V^{\\mathrm{BM}}_{ij} = t_{ij}$ for $i \\ne j$, so that $\\Sigma^{\\mathrm{BM}} = \\sigma^2 V^{\\mathrm{BM}}$ with $s^2 = \\sigma^2$.\n- For OU, at fixed $\\alpha$, write $\\Sigma^{\\mathrm{OU}}(\\alpha) = s^2 V^{\\mathrm{OU}}(\\alpha)$ with $s^2 = \\sigma^2/(2\\alpha)$ and $V^{\\mathrm{OU}}(\\alpha)$ having entries $V^{\\mathrm{OU}}_{ii}(\\alpha) = 1 - e^{-2\\alpha T}$ and $V^{\\mathrm{OU}}_{ij}(\\alpha) = \\exp\\!\\big(-\\alpha (2T - 2 t_{ij})\\big)\\,\\big(1 - e^{-2\\alpha t_{ij}}\\big)$ for $i \\ne j$. The OU log-likelihood is then $\\ell(\\alpha) = \\ell(V^{\\mathrm{OU}}(\\alpha) \\mid \\mathbf{y})$, maximized numerically over $\\alpha > 0$.\n- For $\\lambda$ estimation under BM, set $V^{\\mathrm{BM}}(\\lambda)$ with $V_{ii} = T$ and $V_{ij}(\\lambda) = \\lambda\\, t_{ij}$ for $i \\ne j$, and maximize $\\ell(\\lambda) = \\ell(V^{\\mathrm{BM}}(\\lambda) \\mid \\mathbf{y})$ over $\\lambda \\in [0,1]$.\n\nHypothesis test for phylogenetic signal:\n- Test $H_0: \\lambda = 0$ versus $H_1: \\lambda \\in (0,1]$ using the likelihood ratio statistic $\\,\\Lambda = 2(\\ell(\\hat{\\lambda}) - \\ell(0))\\,$, where $\\hat{\\lambda}$ is the maximizer in $[0,1]$. Because $\\lambda = 0$ is on the boundary of the parameter space, use the mixture critical value appropriate for a one-sided test at level $0.05$, with rejection region $\\Lambda > 2.71$.\n\nModel selection by AIC:\n- Compute $\\mathrm{AIC}_{\\mathrm{BM}} = 2k_{\\mathrm{BM}} - 2 \\ell_{\\mathrm{BM}}$ with $k_{\\mathrm{BM}} = 2$ (intercept $\\mu$ and variance scale $s^2$), and $\\mathrm{AIC}_{\\mathrm{OU}} = 2k_{\\mathrm{OU}} - 2 \\ell_{\\mathrm{OU}}$ with $k_{\\mathrm{OU}} = 3$ (intercept $\\mu$, variance scale $s^2$, and $\\alpha$). Prefer the model with the smaller AIC.\n\nSimulation protocol:\n- For each replicate, simulate $\\mathbf{y} \\sim \\mathcal{N}(\\mu \\mathbf{1}, \\Sigma)$ with $\\mu = 0$, $T = 1$, and $\\sigma^2 = 1$.\n- For $\\alpha = 0$, use BM; for $\\alpha > 0$, use OU with the covariance specified above.\n- Use a fixed random number generator seed to ensure deterministic outputs.\n\nYour program must:\n1. Construct the balanced ultrametric tree and compute the matrix of MRCA times $t_{ij}$ for specified $n$.\n2. For each test case, run the specified number of replicates and compute:\n   - The estimated power (fraction of replicates) to reject $H_0: \\lambda = 0$ at level $0.05$ using the likelihood ratio test described above.\n   - The fraction of replicates where $\\mathrm{AIC}_{\\mathrm{OU}} < \\mathrm{AIC}_{\\mathrm{BM}}$.\n3. Use numerical maximization for $\\alpha$ and $\\lambda$ bounded to $[10^{-6}, 10]$ for $\\alpha$ and $[0,1]$ for $\\lambda$, respectively. You may evaluate endpoints explicitly to guard against boundary maxima.\n\nTest suite:\n- Case 1 (BM boundary): $n = 8$, $\\alpha = 0.0$, replicates $= 200$.\n- Case 2 (moderate OU): $n = 8$, $\\alpha = 0.5$, replicates $= 200$.\n- Case 3 (stronger OU with larger tree): $n = 16$, $\\alpha = 1.0$, replicates $= 200$.\n\nRandomness and reproducibility:\n- Use a fixed seed $s = 12345$ for the random number generator across all simulations so that the output is deterministic.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case contributes a two-element list $[\\text{power}, \\text{selection}]$, where both entries are floats rounded to three decimal places. For the three test cases above, your output must look like:\n  - Example format: [[x1,y1],[x2,y2],[x3,y3]]\n  - Where $xk$ is the estimated power to reject $H_0: \\lambda = 0$ for case $k$, and $yk$ is the fraction of replicates where OU is AIC-preferred for case $k$.",
            "solution": "The problem presents a valid and well-posed computational task in the field of evolutionary biology, specifically phylogenetic comparative methods. It is scientifically grounded in established statistical models—Brownian Motion (BM) and Ornstein–Uhlenbeck (OU)—and standard inference techniques like Phylogenetic Generalized Least Squares (PGLS), Pagel's $\\lambda$, and the Akaike Information Criterion (AIC). All parameters, models, tree structures, and statistical procedures are defined with sufficient mathematical precision and are consistent with the scientific literature. The problem is self-contained, objective, and computationally feasible. Therefore, I will provide a complete solution.\n\nThe solution involves a pipeline with four main stages: (i) construction of the phylogenetic covariance structure, (ii) simulation of continuous trait data, (iii) maximum likelihood estimation of model parameters, and (iv) statistical evaluation via hypothesis testing and model selection.\n\n**1. Phylogenetic Tree and Covariance Structure**\n\nThe problem specifies a perfectly balanced, ultrametric, binary tree with $n=2^D$ tips and a total height of $T=1$. The time from the root to the most recent common ancestor (MRCA) of any two tips, $i$ and $j$, is denoted $t_{ij}$. This value is determined by the depth of their MRCA node. We can construct an $n \\times n$ matrix of these times. For two tips indexed from $0$ to $n-1$, their MRCA's depth (as levels from the root, with the root at level $0$) can be calculated using their bitwise representations. The time $t_{ij}$ is this level divided by the total number of levels, $D = \\log_2 n$. For $i=j$, the MRCA is the tip itself, at time $T=1$, so $t_{ii}=1$. This matrix of times is the fundamental structure encoding the phylogeny.\n\nThis time matrix is used to parameterize the expected covariance of traits under different evolutionary models.\n- **Brownian Motion (BM):** The covariance matrix is $\\Sigma^{\\mathrm{BM}}$, where the covariance between traits at tips $i$ and $j$ is proportional to their shared history: $\\Sigma^{\\mathrm{BM}}_{ij} = \\sigma^2 t_{ij}$. The variance is $\\Sigma^{\\mathrm{BM}}_{ii} = \\sigma^2 T$.\n- **Ornstein-Uhlenbeck (OU):** This model adds a deterministic pull towards an optimum $\\theta$. The covariance matrix $\\Sigma^{\\mathrm{OU}}$ depends on the strength of this pull, $\\alpha$, and has entries given by the formulas in the problem statement. As $\\alpha \\to 0$, the pull disappears, and $\\Sigma^{\\mathrm{OU}}$ converges to $\\Sigma^{\\mathrm{BM}}$.\n\n**2. Trait Simulation**\n\nFor each replicate in the simulation, a vector of continuous trait values $\\mathbf{y} \\in \\mathbb{R}^n$ is generated. This is achieved by drawing from a multivariate normal distribution, $\\mathbf{y} \\sim \\mathcal{N}(\\mu\\mathbf{1}, \\Sigma)$, where $\\mathbf{1}$ is a vector of ones. The simulation parameters are fixed at a mean of $\\mu=0$ and a diffusion rate of $\\sigma^2=1$. The covariance matrix $\\Sigma$ is set to either $\\Sigma^{\\mathrm{BM}}$ (if the true model has $\\alpha=0$) or $\\Sigma^{\\mathrm{OU}}$ (if the true model has $\\alpha > 0$).\n\n**3. Maximum Likelihood Estimation via PGLS**\n\nThe core of the inference procedure is the profile log-likelihood function for an intercept-only PGLS model. Given a trait vector $\\mathbf{y}$ and a relative covariance structure matrix $V$ (where the full covariance matrix is $\\Sigma = s^2 V$), the nuisance parameters for the mean ($\\mu$) and the overall rate ($s^2$) can be estimated using generalized least squares and subsequently \"profiled out\" of the likelihood function. The resulting profile log-likelihood, $\\ell(V \\mid \\mathbf{y})$, is given by:\n$$\n\\ell(V \\mid \\mathbf{y}) = -\\frac{1}{2} \\left[n \\log(2\\pi) + n \\log(\\hat{s}^2) + \\log|V| + n \\right]\n$$\nwhere $\\hat{s}^2 = \\frac{1}{n}(\\mathbf{y} - \\hat{\\mu}\\mathbf{1})^\\top V^{-1} (\\mathbf{y} - \\hat{\\mu}\\mathbf{1})$ and $\\hat{\\mu} = (\\mathbf{1}^\\top V^{-1} \\mathbf{y}) / (\\mathbf{1}^\\top V^{-1} \\mathbf{1})$. This function is numerically maximized to find the best-fitting parameters for the models of interest.\n\n- **Estimating Pagel's $\\lambda$**: The matrix $V$ is defined as $V^{\\mathrm{BM}}(\\lambda)$, where off-diagonal elements of the BM time matrix are scaled by $\\lambda \\in [0, 1]$. We find $\\hat{\\lambda}$ that maximizes $\\ell(V^{\\mathrm{BM}}(\\lambda) \\mid \\mathbf{y})$.\n- **Estimating OU parameter $\\alpha$**: The matrix $V$ is defined as $V^{\\mathrm{OU}}(\\alpha)$, derived from the OU covariance formula by factoring out the rate parameter $s^2 = \\sigma^2/(2\\alpha)$. We find $\\hat{\\alpha}$ that maximizes $\\ell(V^{\\mathrm{OU}}(\\alpha) \\mid \\mathbf{y})$ over the interval $[10^{-6}, 10]$.\n\nNumerical optimization is performed using `scipy.optimize.minimize_scalar` on the negative log-likelihood function. To ensure robustness, the likelihood at the boundaries of the parameter space is also evaluated and compared to the result from the optimizer.\n\n**4. Statistical Evaluation**\n\nTwo key statistical quantities are calculated for each simulated dataset.\n\n- **Power to Detect Phylogenetic Signal**: We test the null hypothesis $H_0: \\lambda=0$ (no phylogenetic signal; traits are independent) against the alternative $H_1: \\lambda > 0$. The Likelihood Ratio Test (LRT) statistic is $\\Lambda = 2(\\ell(\\hat{\\lambda}) - \\ell(\\lambda=0))$. Since $H_0$ is on the boundary of the parameter space, the null distribution of $\\Lambda$ is a $50:50$ mixture of a $\\chi^2_0$ (a point mass at $0$) and a $\\chi^2_1$ distribution. For a significance level of $0.05$, the critical value is $2.71$. If $\\Lambda > 2.71$, $H_0$ is rejected. The power is the fraction of replicates where $H_0$ is correctly rejected when the data were simulated with phylogenetic structure.\n\n- **Model Selection Frequency**: We compare the fit of the BM model to the OU model using the Akaike Information Criterion (AIC): $\\mathrm{AIC} = 2k - 2\\ell$, where $k$ is the number of estimated parameters.\n - For BM, $k_{\\mathrm{BM}}=2$ (parameters $\\mu, \\sigma^2$). Its AIC is $\\mathrm{AIC}_{\\mathrm{BM}} = 4 - 2\\ell_{\\mathrm{BM}}$, where $\\ell_{\\mathrm{BM}}$ is the log-likelihood of the data under the BM model.\n - For OU, $k_{\\mathrm{OU}}=3$ (parameters $\\mu, \\sigma^2, \\alpha$). Its AIC is $\\mathrm{AIC}_{\\mathrm{OU}} = 6 - 2\\ell_{\\mathrm{OU}}$, where $\\ell_{\\mathrm{OU}}$ is the maximized log-likelihood over $\\alpha$.\nThe model with the smaller AIC is preferred. We calculate the fraction of replicates where $\\mathrm{AIC}_{\\mathrm{OU}} < \\mathrm{AIC}_{\\mathrm{BM}}$. This indicates how often the more complex OU model is favored, which is expected to increase as the true generating process has stronger stabilizing selection (larger $\\alpha$).\n\nThe implementation encapsulates these steps into a single, deterministic pipeline, leveraging a fixed random seed for reproducibility across all simulations.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef get_mrca_times(n):\n    \"\"\"\n    Constructs the matrix of MRCA times for a balanced binary tree with n tips.\n    Total tree height T=1.\n    \"\"\"\n    if not (n > 0 and (n & (n - 1) == 0)):\n        raise ValueError(\"n must be a power of 2.\")\n    D = int(np.log2(n))\n    if D == 0:\n        return np.array([[1.0]])\n        \n    times = np.zeros((n, n))\n    for i in range(n):\n        for j in range(i, n):\n            if i == j:\n                times[i, j] = 1.0\n            else:\n                # The level of MRCA: 0 for root, D-1 for sister tips\n                xor_val = i ^ j\n                # Distance from tips to MRCA is floor(log2(xor_val)) + 1\n                # Depth from root to MRCA is D - (floor(log2(xor_val)) + 1)\n                mrca_level = D - 1 - int(np.floor(np.log2(xor_val)))\n                t_ij = mrca_level / D\n                times[i, j] = t_ij\n                times[j, i] = t_ij\n    return times\n\ndef get_ou_V(mrca_times, alpha):\n    \"\"\"Constructs the V matrix for the OU model, with s^2 factored out.\"\"\"\n    n = mrca_times.shape[0]\n    V = np.zeros((n, n))\n    T = 1.0 # Total tree height\n    \n    # Diagonal elements\n    diag_val = 1 - np.exp(-2 * alpha * T)\n    V.flat[::n+1] = diag_val\n    \n    # Off-diagonal elements\n    for i in range(n):\n        for j in range(i + 1, n):\n            t_ij = mrca_times[i, j]\n            val = np.exp(-alpha * (2 * T - 2 * t_ij)) * (1 - np.exp(-2 * alpha * t_ij))\n            V[i, j] = val\n            V[j, i] = val\n    return V\n\ndef get_lambda_V(mrca_times, lam):\n    \"\"\"Constructs the V matrix for the Pagel's lambda model.\"\"\"\n    V = lam * mrca_times\n    np.fill_diagonal(V, 1.0)\n    return V\n\ndef log_likelihood(y, V):\n    \"\"\"Calculates the PGLS profile log-likelihood for an intercept-only model.\"\"\"\n    n = len(y)\n    ones = np.ones(n)\n    try:\n        V_inv = np.linalg.inv(V)\n        sign, log_det_V = np.linalg.slogdet(V)\n        if sign <= 0:\n            return -np.inf\n    except np.linalg.LinAlgError:\n        return -np.inf\n\n    one_V_inv_one = ones.T @ V_inv @ ones\n    one_V_inv_y = ones.T @ V_inv @ y\n    \n    mu_hat = one_V_inv_y / one_V_inv_one\n    \n    res = y - mu_hat * ones\n    s2_hat = (res.T @ V_inv @ res) / n\n    \n    if s2_hat <= 0:\n        return -np.inf\n        \n    logL = -0.5 * (n * np.log(2 * np.pi) + n * np.log(s2_hat) + log_det_V + n)\n    return logL\n\ndef estimate_param(y, mrca_times, param_type):\n    \"\"\"Generic function to estimate lambda or alpha by maximizing log-likelihood.\"\"\"\n    if param_type == 'lambda':\n        bounds = (0, 1)\n        V_func = get_lambda_V\n    elif param_type == 'alpha':\n        bounds = (1e-6, 10)\n        V_func = lambda t, p: get_ou_V(t, p) if p > 1e-9 else t # Use BM as limit\n    else:\n        raise ValueError(\"Invalid param_type\")\n\n    def neg_logL(param, y_data, times):\n        V = V_func(times, param)\n        return -log_likelihood(y_data, V)\n\n    res = minimize_scalar(neg_logL, args=(y, mrca_times), bounds=bounds, method='bounded')\n    \n    # Check boundaries explicitly\n    logL_low = -neg_logL(bounds[0], y, mrca_times)\n    logL_high = -neg_logL(bounds[1], y, mrca_times)\n    \n    best_logL = -res.fun\n    best_param = res.x\n    \n    if logL_low > best_logL:\n        best_logL = logL_low\n        best_param = bounds[0]\n    \n    if logL_high > best_logL:\n        best_logL = logL_high\n        best_param = bounds[1]\n        \n    return best_param, best_logL\n\ndef run_simulation(n, alpha_true, replicates, rng):\n    \"\"\"Runs one full simulation case.\"\"\"\n    mrca_times = get_mrca_times(n)\n    mu_true, sigma2_true, T = 0.0, 1.0, 1.0\n\n    if alpha_true == 0.0:\n        true_cov = sigma2_true * mrca_times\n    else:\n        true_cov = np.zeros((n, n))\n        diag_val = (sigma2_true / (2 * alpha_true)) * (1 - np.exp(-2 * alpha_true * T))\n        np.fill_diagonal(true_cov, diag_val)\n        for i in range(n):\n            for j in range(i + 1, n):\n                t_ij = mrca_times[i, j]\n                val = (sigma2_true / (2*alpha_true)) * np.exp(-alpha_true * (2*T - 2*t_ij)) * (1 - np.exp(-2*alpha_true*t_ij))\n                true_cov[i, j] = true_cov[j, i] = val\n\n    rejected_h0_count = 0\n    ou_preferred_count = 0\n    \n    mean_vec = np.zeros(n)\n\n    for _ in range(replicates):\n        y = rng.multivariate_normal(mean=mean_vec, cov=true_cov)\n        \n        # Power for lambda\n        _, logL_hat_lambda = estimate_param(y, mrca_times, 'lambda')\n        logL_lambda0 = log_likelihood(y, get_lambda_V(mrca_times, 0.0))\n        \n        lrt_stat = 2 * (logL_hat_lambda - logL_lambda0)\n        if max(0, lrt_stat) > 2.71:\n            rejected_h0_count += 1\n            \n        # AIC for BM vs OU\n        logL_bm = log_likelihood(y, mrca_times)\n        aic_bm = 2 * 2 - 2 * logL_bm\n        \n        _, logL_ou = estimate_param(y, mrca_times, 'alpha')\n        aic_ou = 2 * 3 - 2 * logL_ou\n        \n        if aic_ou < aic_bm:\n            ou_preferred_count += 1\n            \n    power = rejected_h0_count / replicates\n    selection_frac = ou_preferred_count / replicates\n    \n    return [round(power, 3), round(selection_frac, 3)]\n\ndef solve():\n    \"\"\"Main function to run the test suite and print results.\"\"\"\n    # Use a fixed seed for the random number generator across all simulations\n    rng = np.random.default_rng(12345)\n    \n    test_cases = [\n        # (n, alpha_true, replicates)\n        (8, 0.0, 200),\n        (8, 0.5, 200),\n        (16, 1.0, 200),\n    ]\n\n    all_results = []\n    for n, alpha, reps in test_cases:\n        result = run_simulation(n, alpha, reps, rng)\n        all_results.append(result)\n\n    # Final print statement in the exact required format.\n    # Convert list of lists to string and remove spaces for compact output.\n    print(str(all_results).replace(' ', ''))\n\nsolve()\n```"
        }
    ]
}