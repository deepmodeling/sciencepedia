{
    "hands_on_practices": [
        {
            "introduction": "对于线性的随机系统，诸如均值这样矩的动力学方程是简洁且自洽的。然而，生物系统，例如基因调控网络，充满了非线性相互作用。本练习  将引导你为一个经典的自激活基因线路推导其蛋白质平均水平的演化方程，让你亲手揭示非线性是如何导致“矩封闭问题”（moment closure problem）的——这是随机建模中的一个核心挑战。",
            "id": "3931985",
            "problem": "考虑一个用于合成基因回路中自激活蛋白的单物种随机生物化学模型。设 $X(t) \\in \\mathbb{N}_{0}$ 表示在时间 $t$ 的蛋白质拷贝数，其变化由一个具有两个反应通道的连续时间马尔可夫链控制：一个使 $X$ 增加 $+1$ 的生成（合成）反应和一个使 $X$ 减少 $-1$ 的消亡（降解）反应。生成倾向函数由希尔函数 $a(x)=\\alpha \\frac{x^{n}}{K^{n}+x^{n}}$ 给出，其中参数 $\\alpha0$，$K0$，希尔系数 $n \\in \\mathbb{N}$；降解倾向函数为 $b(x)=\\mu x$，其中 $\\mu0$。假设动力学由化学主方程（CME）描述，且该过程是非爆炸性的，并且对于所有 $t \\ge 0$ 都具有所有阶的有限矩。\n\n从第一性原理出发——即化学主方程（CME）和生灭过程的无穷小生成元的定义——推导控制平均拷贝数 $m(t)=E[X(t)]$ 时间演化的常微分方程（ODE）。在您的推导中，请阐明化学计量变化和倾向函数如何进入生成元，并利用此来获得精确形式的平均值方程，而不使用任何闭合近似。\n\n然后，对为何得到的平均值方程依赖于 $m(t)$ 之外的统计量提供一个简要的机理上的解释，并讨论希尔倾向函数中的非线性在产生这种依赖性中的作用。如果需要，您可以引用希尔函数到实数轴的光滑扩展来证明矩展开的合理性，但您最终的平均值方程表达式必须是精确的。\n\n您最终报告的答案必须是 $\\frac{d}{dt}E[X(t)]$ 关于模型参数和期望值的完全简化的精确解析表达式。不要提供数值。最终表达式中不要包含任何单位。",
            "solution": "该问题要求推导控制一个随机自激活基因回路中平均蛋白质拷贝数 $m(t)=E[X(t)]$ 时间演化的精确常微分方程（ODE）。推导必须从化学主方程（CME）或其算子等价物——无穷小生成元出发，且不作任何闭合近似。\n\n该系统被描述为状态空间 $\\mathbb{N}_{0}=\\{0, 1, 2, \\dots\\}$ 上的一个连续时间马尔可夫链，其中状态 $x$ 表示蛋白质分子的数量。其动力学由两个反应通道控制：\n1.  生成（合成）：$X \\to X+1$，倾向函数为 $a(x) = \\alpha \\frac{x^{n}}{K^{n}+x^{n}}$。状态变化为 $s_1=+1$。\n2.  消亡（降解）：$X \\to X-1$，倾向函数为 $b(x) = \\mu x$。状态变化为 $s_2=-1$。\n\n概率分布 $P(x, t) = \\text{Prob}(X(t)=x)$ 的时间演化由CME给出。然而，一条更直接获得矩演化的途径是通过马尔可夫过程的无穷小生成元。生成元，记作 $\\mathcal{L}$，描述了从状态 $x$ 开始，状态的任意函数 $f(x)$ 的期望变化率。对于一个生灭过程，它对函数 $f: \\mathbb{N}_{0} \\to \\mathbb{R}$ 的作用定义为：\n$$ (\\mathcal{L}f)(x) = a(x)[f(x+1) - f(x)] + b(x)[f(x-1) - f(x)] $$\n此表达式对每个反应的倾向函数与函数 $f$ 的相应变化的乘积进行求和。\n\n任意可观测量 $f(X(t))$ 的期望值的时间演化由 Dynkin 公式给出，为我们的目的，可表述为：\n$$ \\frac{d}{dt}E[f(X(t))] = E[(\\mathcal{L}f)(X(t))] $$\n该方程是 CME 的一个直接推论，并提供了微观随机动力学与宏观期望值演化之间的基本关系。\n\n为了推导平均拷贝数 $m(t) = E[X(t)]$ 的 ODE，我们选择函数 $f(x) = x$。我们首先计算生成元 $\\mathcal{L}$ 对 $f(x)=x$ 的作用：\n$$ (\\mathcal{L}x)(x) = a(x)[(x+1) - x] + b(x)[(x-1) - x] $$\n方括号中的项分别代表了生成和消亡反应的化学计量变化 $+1$ 和 $-1$。\n$$ (\\mathcal{L}x)(x) = a(x)(1) + b(x)(-1) = a(x) - b(x) $$\n\n现在，我们将此结果代入期望值的演化方程中：\n$$ \\frac{d}{dt}E[X(t)] = E[(\\mathcal{L}X)(X(t))] = E[a(X(t)) - b(X(t))] $$\n期望算子 $E[\\cdot]$ 是线性的，因此我们可以将各项分开：\n$$ \\frac{d}{dt}E[X(t)] = E[a(X(t))] - E[b(X(t))] $$\n\n接下来，我们将倾向函数 $a(x)$ 和 $b(x)$ 的具体形式代入此方程。\n对于降解项，倾向函数 $b(x) = \\mu x$ 是 $x$ 的线性函数。因此，其期望值为：\n$$ E[b(X(t))] = E[\\mu X(t)] = \\mu E[X(t)] $$\n对于合成项，倾向函数 $a(x) = \\alpha \\frac{x^{n}}{K^{n}+x^{n}}$ 是一个非线性希尔函数。其期望值为：\n$$ E[a(X(t))] = E\\left[\\alpha \\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right] = \\alpha E\\left[\\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right] $$\n结合这些结果，我们得到平均蛋白质拷贝数 $m(t)=E[X(t)]$ 的精确 ODE：\n$$ \\frac{d}{dt}E[X(t)] = \\alpha E\\left[\\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right] - \\mu E[X(t)] $$\n\n这个方程是精确的，并且是在没有任何近似的情况下推导出来的。该结果的一个关键特征是它不闭合。一阶矩的变化率 $\\frac{d}{dt}E[X(t)]$ 不仅依赖于一阶矩 $E[X(t)]$ 本身，还依赖于 $X(t)$ 的一个非线性函数的期望值。这个期望值 $E\\left[\\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right]$ 无法仅表示为 $E[X(t)]$ 的简单函数。根据定义，它是对时间 $t$ 的整个概率分布的平均值：\n$$ E\\left[\\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right] = \\sum_{x=0}^{\\infty} \\left(\\frac{x^{n}}{K^{n}+x^{n}}\\right) P(x,t) $$\n这种对完整分布的依赖性意味着一阶矩的方程与高阶统计矩耦合在一起。\n\n这种耦合的机理原因在于生成倾向函数 $a(x)$ 的非线性。为了说明这一点，考虑非线性函数 $h(x) = \\frac{x^{n}}{K^{n}+x^{n}}$ 在平均值 $m = E[X(t)]$ 附近的泰勒级数展开：\n$$ h(X(t)) \\approx h(m) + h'(m)(X(t)-m) + \\frac{1}{2!}h''(m)(X(t)-m)^{2} + \\dots $$\n对两边取期望可得：\n$$ E[h(X(t))] \\approx E[h(m)] + E[h'(m)(X(t)-m)] + E\\left[\\frac{1}{2}h''(m)(X(t)-m)^{2}\\right] + \\dots $$\n利用期望的线性性质以及均值和方差的定义（$\\text{Var}(X(t)) = \\sigma^{2}(t) = E[(X(t)-m)^{2}]$），我们发现：\n$$ E[h(X(t))] \\approx h(m) + \\frac{1}{2}h''(m)\\sigma^{2}(t) + \\dots $$\n$E[h(X(t))]$ 这一项依赖于均值 $m(t)$、方差 $\\sigma^{2}(t)$ 以及所有更高阶的中心矩（来自展开式中的后续项）。因此，均值的方程与方差的方程耦合，而方差的方程又与三阶矩耦合，依此类推，形成了一个无限、不闭合的矩方程组。这是具有非线性反应速率的随机系统的一个普遍特征。由希尔函数建模的协同自激活机制中固有的非线性是这个矩闭合问题的直接原因。如果生成倾向函数是线性的，例如 $a(x) = \\beta x$，那么 $E[a(X(t))] = E[\\beta X(t)] = \\beta E[X(t)] = a(E[X(t)])$，平均值的方程将是一个简单的、闭合的线性 ODE：$\\frac{d}{dt}E[X(t)] = (\\beta - \\mu)E[X(t)]$。",
            "answer": "$$\\boxed{\\alpha E\\left[\\frac{X(t)^{n}}{K^{n}+X(t)^{n}}\\right] - \\mu E[X(t)]}$$"
        },
        {
            "introduction": "理解了矩封闭问题之后，我们该如何对系统行为进行定量预测呢？这个编码实践  将向你介绍几种常用的矩封闭近似方法。你将通过编程实现并比较平均场 (mean-field)、高斯 (Gaussian) 和对数正态 (log-normal) 三种封闭方案，来预测一个负反馈基因线路的稳态统计特性，从而评估不同方法在不同参数区域下的表现和局限。",
            "id": "3931963",
            "problem": "考虑一个由生灭过程控制的蛋白质 $X$ 的单物种随机基因回路。其生成倾向是一个抑制性希尔函数 $a(X) = \\dfrac{k}{1 + \\left(\\dfrac{X}{K}\\right)^{n}}$，表示 $X$ 对其自身产生的负反馈；其消亡倾向是线性的 $b(X) = \\gamma X$。假设系统是充分混合的，并服从马尔可夫化学主方程（CME）。\n\n从CME和统计矩的定义出发，推导 $X$ 的一阶矩和二阶矩的耦合稳态方程，即 $E[X]$ 和 $E[X^{2}]$ 的稳态条件，不得引入任何特设公式。展示非线性倾向 $a(X)$ 如何通过 $E[a(X)]$ 以及诸如 $E[X\\,a(X)]$ 的混合项将各阶矩耦合起来。\n\n实现三种矩封闭方法来获得一个封闭系统，并预测稳态均值 $E[X]$ 和方差 $Var[X] = E[X^{2}] - (E[X])^{2}$：\n- 平均场封闭：将 $E[a(X)]$ 近似为 $a(E[X])$，将 $E[X\\,a(X)]$ 近似为 $E[X]\\,a(E[X])$。\n- 通过德尔塔方法实现的二阶正态（高斯）封闭：对于平滑函数 $f$，使用近似 $E[f(X)] \\approx f(E[X]) + \\dfrac{1}{2} f''(E[X])\\,Var[X]$，并将其应用于 $f(X) = a(X)$ 和 $f(X) = X\\,a(X)$。解析计算所需的导数。\n- 对数正态封闭：假设 $X$ 近似服从对数正态分布，其参数的选择应与给定的均值 $m = E[X]$ 和方差 $v = Var[X]$ 相匹配。使用求积法在该分布下评估 $E[a(X)]$ 和 $E[X\\,a(X)]$，并施加稳态条件以自洽地求解 $m$ 和 $v$。\n\n所有计算都必须以无量纲形式表示；不需要物理单位。不涉及角度。不涉及百分比。\n\n你的程序应针对下面测试套件中的每一组参数，计算每种封闭方法对 $E[X]$ 和 $Var[X]$ 的稳态预测。对于需要解非线性方程的封闭方法，应使用稳健的数值求根方法。如果中间计算产生无效状态（例如，负方差），则进行最小正则化以继续计算，同时在你的推理中注明此类行为。\n\n为以下参数集 $(k, \\gamma, K, n)$ 的测试套件提供结果，这些参数集用于探测不同的区间：\n- 情况 $1$（一般情况，中等强度抑制）：$(k, \\gamma, K, n) = (50, 1, 100, 2)$。\n- 情况 $2$（弱反馈极限）：$(k, \\gamma, K, n) = (50, 1, 10000, 2)$。\n- 情况 $3$（强反馈，高协同性）：$(k, \\gamma, K, n) = (50, 1, 10, 4)$。\n- 情况 $4$（较低产出，较快降解）：$(k, \\gamma, K, n) = (10, 2, 20, 3)$。\n\n你的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。对于每种情况，按以下顺序输出六个浮点数：$[E[X]_{\\text{MF}}, Var[X]_{\\text{MF}}, E[X]_{\\text{GA}}, Var[X]_{\\text{GA}}, E[X]_{\\text{LN}}, Var[X]_{\\text{LN}}]$，其中下标表示平均场（MF）、高斯（GA）和对数正态（LN）封闭。将所有情况的结果按顺序聚合到一个扁平列表中，例如 $[r_{1,1}, r_{1,2}, \\dots, r_{4,6}]$，其中 $r_{i,j}$ 是情况 $i$ 的第 $j$ 个结果。",
            "solution": "该问题陈述具有科学依据、内容自洽且提法明确。它描述了随机系统生物学中的一个典型模型——一个带有非线性反馈的生灭过程——并要求使用矩封闭近似进行标准分析。所有必需的参数和定义均已提供，该任务是数学建模和数值分析的有效应用。因此，这里给出一个完整的解法。\n\n分子数 $X$ 的概率分布 $P(x, t)$ 的时间演化由化学主方程（CME）控制。对于生灭过程，CME为：\n$$ \\frac{dP(x, t)}{dt} = [a(x-1)P(x-1, t) - a(x)P(x, t)] + [b(x+1)P(x+1, t) - b(x)P(x, t)] $$\n其中 $a(x)$ 是生成倾向，$b(x)$ 是消亡倾向。当变量为负时，这些项定义为零（例如，$P(-1, t) = 0$）。在此问题中，生成倾向由抑制性希尔函数给出，消亡倾向为线性降解：\n$$ a(X) = \\frac{k}{1 + \\left(\\frac{X}{K}\\right)^{n}} \\quad \\text{and} \\quad b(X) = \\gamma X $$\n\n我们可以直接从CME推导任意函数 $f(X)$ 的期望值（记作 $E[f(X)] = \\langle f(X) \\rangle$）的时间演化：\n$$ \\frac{d\\langle f(X) \\rangle}{dt} = \\sum_{x=0}^{\\infty} f(x) \\frac{dP(x, t)}{dt} $$\n代入CME并对求和变元重新索引，可得到矩动力学的一般关系式：\n$$ \\frac{d\\langle f(X) \\rangle}{dt} = \\langle a(X) [f(X+1) - f(X)] \\rangle + \\langle b(X) [f(X-1) - f(X)] \\rangle $$\n为了找到前两阶矩的方程，我们设 $f(X)=X$ 和 $f(X)=X^2$。\n\n对于一阶矩，$f(X) = X$：\n$f(X+1) - f(X) = (X+1) - X = 1$\n$f(X-1) - f(X) = (X-1) - X = -1$\n均值 $E[X] = \\langle X \\rangle$ 的动力学方程为：\n$$ \\frac{d\\langle X \\rangle}{dt} = \\langle a(X) \\cdot 1 \\rangle + \\langle \\gamma X \\cdot (-1) \\rangle = \\langle a(X) \\rangle - \\gamma \\langle X \\rangle $$\n\n对于二阶矩，$f(X) = X^2$：\n$f(X+1) - f(X) = (X+1)^2 - X^2 = 2X+1$\n$f(X-1) - f(X) = (X-1)^2 - X^2 = -2X+1$\n二阶矩 $E[X^2] = \\langle X^2 \\rangle$ 的动力学方程为：\n$$ \\frac{d\\langle X^2 \\rangle}{dt} = \\langle a(X)(2X+1) \\rangle + \\langle \\gamma X (-2X+1) \\rangle = 2\\langle Xa(X) \\rangle + \\langle a(X) \\rangle - 2\\gamma \\langle X^2 \\rangle + \\gamma \\langle X \\rangle $$\n\n在稳态下，时间导数为零。令 $m = E[X]$ 和 $m_2 = E[X^2]$。稳态条件是一个包含两个方程的方程组：\n$$ (1) \\quad \\langle a(X) \\rangle - \\gamma m = 0 $$\n$$ (2) \\quad 2\\langle Xa(X) \\rangle + \\langle a(X) \\rangle - 2\\gamma m_2 + \\gamma m = 0 $$\n倾向函数 $a(X)$ 的非线性意味着 $\\langle a(X) \\rangle \\neq a(\\langle X \\rangle)$。项 $\\langle a(X) \\rangle$ 和 $\\langle Xa(X) \\rangle$ 依赖于 $X$ 的整个概率分布，将一阶矩的方程与二阶矩耦合，二阶矩与三阶矩耦合，依此类推，形成一个无限的层级结构。矩封闭近似用于截断此层级结构。我们可以通过将第一个方程代入第二个方程来简化它：\n$$ 2\\langle Xa(X) \\rangle + (\\gamma m) - 2\\gamma m_2 + \\gamma m = 0 \\implies \\langle Xa(X) \\rangle + \\gamma m - \\gamma m_2 = 0 $$\n需要为 $m$ 和 $v = Var[X] = m_2 - m^2$ 求解的方程组是：\n$$ (A) \\quad \\langle a(X) \\rangle = \\gamma m $$\n$$ (B) \\quad \\langle Xa(X) \\rangle = \\gamma (m_2 - m) = \\gamma(v + m^2 - m) $$\n\n我们现在应用三种不同的封闭方案来近似期望项。\n\n**1. 平均场（MF）封闭**\n这是最简单的封闭方法，我们将非线性函数的期望近似为期望的函数：$\\langle a(X) \\rangle \\approx a(m)$ 和 $\\langle Xa(X) \\rangle \\approx m a(m)$。\n方程 (A) 变为：$a(m) - \\gamma m = 0$，这是一个关于均值 $m$ 的非线性方程：\n$$ \\frac{k}{1 + (m/K)^n} = \\gamma m $$\n方程 (B) 变为：$m a(m) = \\gamma(v + m^2 - m)$。将第一个方程的 $a(m) = \\gamma m$ 代入，得到：\n$$ m(\\gamma m) = \\gamma(v + m^2 - m) \\implies \\gamma m^2 = \\gamma v + \\gamma m^2 - \\gamma m \\implies v = m $$\n平均场封闭预测法诺因子 $v/m = 1$，这是泊松过程的特征。我们首先数值求解 $m$，然后令 $v=m$。\n\n**2. 二阶正态（高斯，GA）封闭**\n该封闭方法使用函数 $f(X)$ 在均值 $m=E[X]$ 附近的二阶泰勒展开，然后取期望。\n$f(X) \\approx f(m) + f'(m)(X-m) + \\frac{1}{2}f''(m)(X-m)^2$\n$\\langle f(X) \\rangle \\approx f(m) + \\frac{v}{2}f''(m)$, 其中 $v = Var[X]$。\n我们将此方法应用于 $a(X)$ 和 $h(X) = Xa(X)$。我们需要二阶导数 $a''(X)$ 和 $h''(X)$。\n$a(X)$ 的导数是：\n$a'(X) = -\\frac{nk}{K} \\frac{(X/K)^{n-1}}{(1+(X/K)^n)^2}$\n$a''(X) = \\frac{nk X^{n-2}}{K^n(1+(X/K)^n)^3} \\left[ (n+1)\\left(\\frac{X}{K}\\right)^n - (n-1) \\right]$\n$h(X)$ 的二阶导数是 $h''(X) = 2a'(X) + Xa''(X)$。\n期望的近似值为：\n$\\langle a(X) \\rangle \\approx a(m) + \\frac{v}{2}a''(m)$\n$\\langle Xa(X) \\rangle \\approx h(m) + \\frac{v}{2}h''(m) = m a(m) + \\frac{v}{2}(2a'(m) + m a''(m)) = m a(m) + v a'(m) + \\frac{vm}{2}a''(m)$\n将这些近似代入稳态系统 (A) 和 (B) 中，得到一个关于 $(m, v)$ 的耦合非线性系统：\n$$ (A_{GA}) \\quad a(m) + \\frac{v}{2}a''(m) - \\gamma m = 0 $$\n$$ (B_{GA}) \\quad m a(m) + v a'(m) + \\frac{vm}{2}a''(m) - \\gamma(v + m^2 - m) = 0 $$\n这个系统必须通过数值方法求解 $m$ 和 $v$。平均场封闭的结果可以作为一个良好的初始猜测。如果求解器产生负方差 $v$，则将其正则化为一个小的正值，因为负方差是不符合物理实际的。\n\n**3. 对数正态（LN）封闭**\n此方法假设 $X$ 服从对数正态分布。对数正态分布由两个参数 $\\mu$ 和 $\\sigma^2$ 定义，它们是其底层的正态变量 $\\ln(X)$ 的均值和方差。这些参数可以与 $X$ 本身的均值 $m$ 和方差 $v$ 相关联：\n$m = e^{\\mu + \\sigma^2/2}$\n$v = (e^{\\sigma^2}-1)e^{2\\mu+\\sigma^2} = (e^{\\sigma^2}-1)m^2$\n求解 $\\mu$ 和 $\\sigma^2$：\n$\\sigma^2 = \\ln(v/m^2 + 1)$\n$\\mu = \\ln(m) - \\sigma^2/2$\n这要求 $m  0$ 且 $v \\ge 0$。\n期望 $\\langle a(X) \\rangle$ 和 $\\langle Xa(X) \\rangle$ 是通过对对数正态概率密度函数进行积分来计算的，该积分使用高斯-埃尔米特求积法进行数值计算。\n函数 $f(X)$ 的期望由下式给出：\n$$ \\langle f(X) \\rangle = \\int_0^{\\infty} f(x) p_{LN}(x; \\mu, \\sigma^2) dx = \\int_{-\\infty}^{\\infty} f(e^{\\mu + \\sigma z}) \\phi(z) dz $$\n其中 $\\phi(z)$ 是标准正态概率密度函数（PDF）。该积分通过求积法近似为：\n$$ \\langle f(X) \\rangle \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N_{quad}} w_i f(e^{\\mu + \\sigma \\sqrt{2} u_i}) $$\n其中 $u_i$ 和 $w_i$ 是高斯-埃尔米特求积法的节点和权重。\n该封闭方法需要找到 $(m,v)$，使其自洽地满足系统 (A) 和 (B)，其中期望是使用此求积法计算的。这同样需要一个数值求根算法，并对 $m$ 和 $v$ 施加正值约束。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import root, root_scalar\nfrom scipy.special import hermite\nimport math\n\ndef solve():\n    \"\"\"\n    Computes steady-state mean and variance for a stochastic gene expression\n    model using three different moment closure approximations.\n    \"\"\"\n\n    test_cases = [\n        # (k, gamma, K, n)\n        (50, 1, 100, 2),\n        (50, 1, 10000, 2),\n        (50, 1, 10, 4),\n        (10, 2, 20, 3)\n    ]\n\n    all_results = []\n    \n    # Quadrature setup for log-normal closure\n    N_QUAD = 64\n    herm_nodes, herm_weights = np.polynomial.hermite.hermgauss(N_QUAD)\n\n    for params in test_cases:\n        k, gamma, K, n = params\n\n        # 1. Mean-Field (MF) Closure\n        m_mf, v_mf = solve_mf(k, gamma, K, n)\n        all_results.extend([m_mf, v_mf])\n\n        initial_guess = (m_mf, v_mf)\n\n        # 2. Gaussian (GA) Closure\n        m_ga, v_ga = solve_ga(k, gamma, K, n, initial_guess)\n        all_results.extend([m_ga, v_ga])\n\n        # 3. Log-Normal (LN) Closure\n        m_ln, v_ln = solve_ln(k, gamma, K, n, initial_guess, herm_nodes, herm_weights)\n        all_results.extend([m_ln, v_ln])\n\n    print(f\"[{','.join(f'{x:.6f}' for x in all_results)}]\")\n\ndef solve_mf(k, gamma, K, n):\n    \"\"\"\n    Solves for mean and variance using mean-field closure.\n    \"\"\"\n    # Equation to solve: a(m) - gamma*m = 0\n    def mf_residual(m):\n        if m  0:\n            return k # Large penalty for negative mean\n        return k / (1.0 + (m / K)**n) - gamma * m\n\n    # The mean must be between 0 and k/gamma\n    sol = root_scalar(mf_residual, bracket=[0, k / gamma + 1], method='brentq')\n    \n    if sol.converged:\n        mean = sol.root\n        variance = mean  # For MF closure, v = m\n        return mean, variance\n    else:\n        return np.nan, np.nan\n\ndef solve_ga(k, gamma, K, n, initial_guess):\n    \"\"\"\n    Solves for mean and variance using second-order normal (Gaussian) closure.\n    \"\"\"\n    def a(x):\n        return k / (1.0 + (x / K)**n)\n\n    def a_prime(x):\n        if x = 0: x = 0\n        term_x_k = (x / K)\n        denom = (1.0 + term_x_k**n)**2\n        return -n * k / K * (term_x_k**(n - 1)) / denom if denom > 0 else 0\n\n    def a_double_prime(x):\n        if x = 0: return 0\n        term_x_k_n = (x/K)**n\n        denom = (1.0 + term_x_k_n)**3\n        term1 = (n + 1) * term_x_k_n\n        term2 = (n - 1)\n        \n        factor = n * k * x**(n - 2) / (K**n)\n        \n        return factor * (term1 - term2) / denom if denom > 0 else 0\n        \n    def ga_residuals(vars):\n        m, v = vars\n        \n        # Regularization: variance must be non-negative\n        if m  0 or v  0:\n            return [1e6, 1e6]\n            \n        am = a(m)\n        a1m = a_prime(m)\n        a2m = a_double_prime(m)\n        \n        # This is E[a(X)] using second order approximation\n        E_aX = am + 0.5 * v * a2m\n        \n        # This is E[X*a(X)] using second order approximation\n        h_double_prime_m = 2*a1m + m*a2m\n        E_XaX = m * am + 0.5 * v * h_double_prime_m\n        \n        res1 = E_aX - gamma * m\n        res2 = E_XaX - gamma * (v + m**2 - m)\n        \n        return [res1, res2]\n\n    sol = root(ga_residuals, initial_guess, method='hybr')\n    \n    if sol.success:\n        mean, variance = sol.x\n        # Final regularization if variance is slightly negative due to numerical precision\n        variance = max(0.0, variance)\n        return mean, variance\n    else:\n        return np.nan, np.nan\n\ndef solve_ln(k, gamma, K, n, initial_guess, herm_nodes, herm_weights):\n    \"\"\"\n    Solves for mean and variance using log-normal closure with Gauss-Hermite quadrature.\n    \"\"\"\n    def ln_residuals(vars):\n        m, v = vars\n        \n        # Regularization: mean and variance must be positive.\n        if m = 1e-9 or v = 1e-9:\n            return [1e6, 1e6]\n\n        # Map (m, v) to log-normal parameters (mu, sigma)\n        try:\n            sigma2 = math.log(v / m**2 + 1.0)\n            mu = math.log(m) - 0.5 * sigma2\n            sigma = math.sqrt(sigma2)\n        except ValueError:\n            return [1e6, 1e6]  # Invalid parameters\n\n        # Quadrature points for standard normal distribution\n        z_nodes = np.sqrt(2.0) * herm_nodes\n        x_eval = np.exp(mu + sigma * z_nodes)\n\n        a_vals = k / (1.0 + (x_eval / K)**n)\n        xa_vals = x_eval * a_vals\n\n        # Compute expectations via quadrature\n        E_aX = np.sum(herm_weights * a_vals) / np.sqrt(np.pi)\n        E_XaX = np.sum(herm_weights * xa_vals) / np.sqrt(np.pi)\n\n        res1 = E_aX - gamma * m\n        res2 = E_XaX - gamma * (v + m**2 - m)\n\n        return [res1, res2]\n\n    sol = root(ln_residuals, initial_guess, method='hybr')\n    \n    if sol.success:\n        mean, variance = sol.x\n        # Final regularization\n        mean = max(1e-9, mean)\n        variance = max(0.0, variance)\n        return mean, variance\n    else:\n        # Fallback to MF if LN fails to converge\n        return initial_guess\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "基于矩的方法是进行模型推断和分析的强大工具，但它们并非没有局限。本练习  通过一个发人深省的思想实验，揭示了一个根本性的模糊之处：截然不同的概率分布可以产生完全相同的前几阶矩。通过构建两个具有相同均值、方差和偏度的不同分布，你将更深刻地理解模型推断中的不可识别性（non-identifiability）问题，以及批判性审视模型假设的重要性。",
            "id": "3931938",
            "problem": "考虑一个随机基因表达系统，其稳态由化学主方程 (CME) 建模，其中可观测量是蛋白质拷贝数 $X$。假设单细胞测量仅提供了前三阶矩，并揭示了均值 $E[X]=\\mu=10$，方差 $\\operatorname{Var}(X)=\\sigma^{2}=25$，以及三阶中心矩 $E[(X-\\mu)^{3}]=0$。在许多合成生物学推断流程中，矩匹配被用于拟合模型；然而，有限的矩可能不足以识别潜在的分布。\n\n你的任务是通过为 $X$ 构建两个共享相同前三阶原点矩的不同候选稳态分布，来证明从高达三阶的矩推断的不可识别性：\n- 分布 A：一个均值为 $\\mu$、方差为 $\\sigma^{2}$ 的单一正态分布。\n- 分布 B：一个具有相等权重的对称双组分正态混合分布。两个组分的均值分别为 $\\mu+m$ 和 $\\mu-m$，并且具有相等的组分方差 $s^{2}$。\n\n假设一项独立的动态测量约束了状态间分离度与状态内变异性之比，使得 $m^{2}/s^{2}=16/9$。仅使用第一性原理（矩的定义和条件化），完成以下任务：\n1. 用 $\\mu$ 和 $\\sigma^{2}$ 推导分布 A 的前三阶原点矩。\n2. 用 $\\mu$、 $m$ 和 $s^{2}$ 推导分布 B 的前三阶原点矩。\n3. 施加约束 $E[X]=10$、 $\\operatorname{Var}(X)=25$、 $E[(X-\\mu)^{3}]=0$ 和 $m^{2}/s^{2}=16/9$，以确定使分布 B 在三阶矩及以下与分布 A 相匹配的 $m$ 和 $s^{2}$ 的明确值。\n\n使用标准数学符号将你的最终答案表示为单行矩阵中的数对 $(m,s^{2})$。无需四舍五入，也无需单位。在你的推理中验证，这两个分布是不同的，同时它们共享高达三阶的相同矩集。",
            "solution": "在尝试解答之前，对问题陈述的有效性进行评估。\n\n### 步骤 1：提取已知条件\n-   系统：一个处于稳态的随机基因表达系统。\n-   可观测量：蛋白质拷贝数，$X$。\n-   提供的单细胞测量矩：\n    -   均值：$E[X] = \\mu = 10$。\n    -   方差：$\\operatorname{Var}(X) = \\sigma^{2} = 25$。\n    -   三阶中心矩：$E[(X-\\mu)^{3}] = 0$。\n-   任务：证明从高达三阶的矩推断的不可识别性。\n-   待构建的候选分布：\n    -   分布 A：一个单一正态分布，$X_A \\sim \\mathcal{N}(\\mu, \\sigma^2)$。\n    -   分布 B：一个具有相等权重（$1/2$）的对称双组分正态混合分布。其组分为 $\\mathcal{N}(\\mu+m, s^2)$ 和 $\\mathcal{N}(\\mu-m, s^2)$，具有相等的方差 $s^2$。\n-   约束：状态间分离度与状态内变异性之比是固定的，$m^{2}/s^{2}=16/9$。\n-   目标：\n    1.  用 $\\mu$ 和 $\\sigma^{2}$ 推导分布 A 的前三阶原点矩。\n    2.  用 $\\mu$、 $m$ 和 $s^{2}$ 推导分布 B 的前三阶原点矩。\n    3.  确定使分布 B 的前三阶矩与给定数据相匹配的 $m$ 和 $s^{2}$ 的明确值。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在科学和数学上是合理的。它在合成生物学的有效科学背景下，探讨了统计建模中的一个基本概念——从有限集合的矩中无法唯一确定一个分布（不可识别性）。使用正态分布和混合正态分布作为模型是标准做法。该问题是适定的，提供了足够的信息和约束来确定参数 $m$ 和 $s^2$ 的唯一解。其语言客观而精确。所提供的数据（$\\mu=10$，$\\sigma^2=25$，三阶中心矩为 $0$）是相互一致且合理的。该问题没有违反任何数学或科学的基本原则，并且可以直接形式化和求解。\n\n### 步骤 3：结论与行动\n问题是有效的。将提供完整的解答。\n\n目标是找到分布 B 的参数 $m$ 和 $s^{2}$，使其前三阶矩与由给定实验数据定义的分布 A 的矩相匹配。\n\n**1. 分布 A 的矩的推导**\n设分布 A 的随机变量为 $X_A \\sim \\mathcal{N}(\\mu, \\sigma^2)$。我们需要求其前三阶原点矩，$E[X_A]$、$E[X_A^2]$ 和 $E[X_A^3]$。\n\n-   第一阶原点矩是均值，由参数 $\\mu$ 给出：\n    $$E[X_A] = \\mu$$\n\n-   第二阶原点矩与方差相关，$\\operatorname{Var}(X_A) = E[X_A^2] - (E[X_A])^2 = \\sigma^2$。整理可得：\n    $$E[X_A^2] = \\operatorname{Var}(X_A) + (E[X_A])^2 = \\sigma^2 + \\mu^2$$\n\n-   第三阶原点矩与三阶中心矩 $E[(X_A - \\mu)^3]$ 相关。对于任何对称分布，包括正态分布，所有奇数阶中心矩均为零。因此，$E[(X_A - \\mu)^3] = 0$。我们可以展开此表达式：\n    $$E[(X_A - \\mu)^3] = E[X_A^3 - 3\\mu X_A^2 + 3\\mu^2 X_A - \\mu^3] = 0$$\n    利用期望的线性性质：\n    $$E[X_A^3] - 3\\mu E[X_A^2] + 3\\mu^2 E[X_A] - \\mu^3 = 0$$\n    解出 $E[X_A^3]$ 并代入低阶矩的表达式：\n    $$E[X_A^3] = 3\\mu E[X_A^2] - 3\\mu^2 E[X_A] + \\mu^3$$\n    $$E[X_A^3] = 3\\mu(\\sigma^2 + \\mu^2) - 3\\mu^2(\\mu) + \\mu^3$$\n    $$E[X_A^3] = 3\\mu\\sigma^2 + 3\\mu^3 - 3\\mu^3 + \\mu^3 = \\mu^3 + 3\\mu\\sigma^2$$\n\n所以，对于分布 A，其前三阶原点矩为：$E[X_A] = \\mu$，$E[X_A^2] = \\sigma^2 + \\mu^2$ 和 $E[X_A^3] = \\mu^3 + 3\\mu\\sigma^2$。\n\n**2. 分布 B 的矩的推导**\n设分布 B 的随机变量为 $X_B$。其概率密度函数是两个正态分布的混合：\n$f_{X_B}(x) = \\frac{1}{2}\\mathcal{N}(x; \\mu-m, s^2) + \\frac{1}{2}\\mathcal{N}(x; \\mu+m, s^2)$。\n设两个组分随机变量为 $Y_1 \\sim \\mathcal{N}(\\mu-m, s^2)$ 和 $Y_2 \\sim \\mathcal{N}(\\mu+m, s^2)$。$X_B$ 的矩可以使用全期望定律计算：$E[X_B^k] = \\frac{1}{2}E[Y_1^k] + \\frac{1}{2}E[Y_2^k]$。\n\n-   第一阶原点矩为：\n    $$E[X_B] = \\frac{1}{2}E[Y_1] + \\frac{1}{2}E[Y_2] = \\frac{1}{2}(\\mu-m) + \\frac{1}{2}(\\mu+m) = \\frac{\\mu}{2} - \\frac{m}{2} + \\frac{\\mu}{2} + \\frac{m}{2} = \\mu$$\n\n-   第二阶原点矩为：\n    使用公式 $E[Y^2] = \\operatorname{Var}(Y) + (E[Y])^2$：\n    $E[Y_1^2] = s^2 + (\\mu-m)^2 = s^2 + \\mu^2 - 2\\mu m + m^2$。\n    $E[Y_2^2] = s^2 + (\\mu+m)^2 = s^2 + \\mu^2 + 2\\mu m + m^2$。\n    $$E[X_B^2] = \\frac{1}{2}(E[Y_1^2] + E[Y_2^2]) = \\frac{1}{2}((s^2 + \\mu^2 - 2\\mu m + m^2) + (s^2 + \\mu^2 + 2\\mu m + m^2))$$\n    $$E[X_B^2] = \\frac{1}{2}(2s^2 + 2\\mu^2 + 2m^2) = \\mu^2 + m^2 + s^2$$\n\n-   第三阶原点矩为：\n    对于一个正态变量 $Y \\sim \\mathcal{N}(\\mu_Y, \\sigma_Y^2)$，使用公式 $E[Y^3] = \\mu_Y^3 + 3\\mu_Y\\sigma_Y^2$：\n    $E[Y_1^3] = (\\mu-m)^3 + 3(\\mu-m)s^2 = (\\mu^3 - 3\\mu^2 m + 3\\mu m^2 - m^3) + (3\\mu s^2 - 3ms^2)$。\n    $E[Y_2^3] = (\\mu+m)^3 + 3(\\mu+m)s^2 = (\\mu^3 + 3\\mu^2 m + 3\\mu m^2 + m^3) + (3\\mu s^2 + 3ms^2)$。\n    $$E[X_B^3] = \\frac{1}{2}(E[Y_1^3] + E[Y_2^3])$$\n    对 $E[Y_1^3]$ 和 $E[Y_2^3]$ 的各项求和，$m$ 的奇次幂项会消去：\n    $$E[Y_1^3] + E[Y_2^3] = 2\\mu^3 + 6\\mu m^2 + 6\\mu s^2$$\n    $$E[X_B^3] = \\frac{1}{2}(2\\mu^3 + 6\\mu m^2 + 6\\mu s^2) = \\mu^3 + 3\\mu m^2 + 3\\mu s^2 = \\mu^3 + 3\\mu(m^2+s^2)$$\n\n所以，对于分布 B，其前三阶原点矩为：$E[X_B] = \\mu$，$E[X_B^2] = \\mu^2 + m^2 + s^2$ 和 $E[X_B^3] = \\mu^3 + 3\\mu(m^2+s^2)$。\n\n**3. $m$ 和 $s^2$ 的确定**\n我们现在必须施加给定的约束来求 $m$ 和 $s^{2}$。约束条件是分布 B 的矩必须与实验数据相匹配：$E[X] = \\mu = 10$，$\\operatorname{Var}(X) = \\sigma^2 = 25$ 和 $E[(X-\\mu)^3] = 0$。\n\n-   分布 B 的均值为 $E[X_B] = \\mu = 10$。这一点通过构造已经满足。\n\n-   分布 B 的方差必须等于 $\\sigma^2=25$：\n    $$\\operatorname{Var}(X_B) = E[X_B^2] - (E[X_B])^2 = (\\mu^2 + m^2 + s^2) - \\mu^2 = m^2 + s^2$$\n    因此，我们得到第一个方程：\n    $$m^2 + s^2 = 25$$\n\n-   分布 B 的三阶中心矩必须为 $0$。让我们来验证这一点。由于混合组分围绕 $\\mu$ 对称，所得到的分布也围绕 $\\mu$ 对称。对称分布的所有奇数阶中心矩都为零。为了完整起见，我们显式地计算它：\n    $$E[(X_B - \\mu)^3] = E[X_B^3] - 3\\mu E[X_B^2] + 3\\mu^2 E[X_B] - \\mu^3$$\n    $$= (\\mu^3 + 3\\mu(m^2+s^2)) - 3\\mu(\\mu^2 + m^2 + s^2) + 3\\mu^2(\\mu) - \\mu^3$$\n    $$= (\\mu^3 - 3\\mu^3 + 3\\mu^3 - \\mu^3) + (3\\mu(m^2+s^2) - 3\\mu(m^2+s^2)) = 0$$\n    这个条件被分布 B 的对称结构自动满足，并没有为 $m$ 或 $s^2$ 提供新的约束。\n\n我们有一个方程 $m^2 + s^2 = 25$ 和两个未知数。问题提供了从独立测量中得出的第二个约束：\n$$m^2/s^2 = 16/9$$\n这给了我们一个关于 $m^2$ 和 $s^2$ 的二元方程组。从第二个方程中，我们将 $m^2$ 用 $s^2$ 表示：\n$$m^2 = \\frac{16}{9}s^2$$\n将此代入第一个方程：\n$$\\frac{16}{9}s^2 + s^2 = 25$$\n$$\\left(\\frac{16}{9} + 1\\right)s^2 = 25$$\n$$\\left(\\frac{16+9}{9}\\right)s^2 = 25$$\n$$\\frac{25}{9}s^2 = 25$$\n这可以简化为：\n$$s^2 = 9$$\n现在我们可以通过将 $s^2=9$ 代回 $m^2$ 的表达式来求出 $m^2$：\n$$m^2 = \\frac{16}{9}(9) = 16$$\n由于 $m$ 代表分布均值之间距离的一半，我们取正根，$m=4$。\n\n这两个分布确实是不同的。分布 A 是一个单峰正态分布 $\\mathcal{N}(10, 25)$。分布 B 是一个双峰分布，其密度为 $\\frac{1}{2}\\mathcal{N}(x; 6, 9) + \\frac{1}{2}\\mathcal{N}(x; 14, 9)$，峰值位于 $x=6$ 和 $x=14$。尽管它们的形状不同，但它们的前三阶矩完全相同。这证明了从有限集合的矩中无法唯一确定潜在概率分布（不可识别性）。\n\n所求的数对是 $(m, s^2)$。由于 $m=4$ 且 $s^2=9$，该数对为 $(4, 9)$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 4  9 \\end{pmatrix}}\n$$"
        }
    ]
}