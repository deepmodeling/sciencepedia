{
    "hands_on_practices": [
        {
            "introduction": "To build a solid understanding of the Linear Noise Approximation (LNA), we begin with a foundational model of constitutive gene expression. This exercise guides you through deriving the exact stochastic properties of a simple birth-death process directly from the Chemical Master Equation. You will then apply the LNA to the same system, allowing for a direct comparison that reveals the LNA is exact for systems with purely linear propensities. This practice provides a crucial benchmark and builds intuition for the LNA's underlying assumptions and its performance in an ideal scenario.",
            "id": "3936470",
            "problem": "Consider a single-species stochastic biochemical reaction system modeling a synthetic gene product with copy number $X(t) \\in \\{0,1,2,\\dots\\}$. The system consists of a zero-order synthesis reaction $\\varnothing \\rightarrow X$ with rate constant $\\alpha$ (in molecules per unit time) and a first-order decay reaction $X \\rightarrow \\varnothing$ with rate constant $\\gamma$ (in per unit time). The mesoscopic dynamics are governed by the Chemical Master Equation (CME), and the macroscopic mean-field dynamics are described by the deterministic rate equation.\n\nUsing only fundamental definitions and laws appropriate to stochastic chemical kinetics, carry out the following:\n\n1. Starting from the steady-state CME for the birth–death process, derive the exact stationary distribution and compute the exact stationary variance $\\mathrm{Var}[X]$ of the molecule count in terms of $\\alpha$ and $\\gamma$. Your derivation should proceed from the master equation and the normalization of probabilities, without invoking black-box formulas for this particular distribution.\n\n2. Starting from the deterministic rate equation $\\mathrm{d}\\phi/\\mathrm{d}t=\\alpha-\\gamma \\phi$ and its steady state $\\phi^{\\ast}$, perform the linearization about $\\phi^{\\ast}$ and derive the Linear Noise Approximation (LNA) equations for the fluctuation variable. From these, compute the stationary variance predicted by the LNA and show how it compares to the exact stationary variance from part 1. Your derivation should start from the macroscopic rate equation, construct the linearized stochastic dynamics for fluctuations, and solve for the steady-state variance without assuming any pre-known “shortcut” variance formulas.\n\n3. Briefly explain, based on first-principles reasoning about the assumptions of the Linear Noise Approximation, under what modeling conditions for synthetic biological reaction networks the LNA fails to reproduce the exact stationary variance or yields qualitatively incorrect distributional features, even if it reproduces the first two moments in some linear cases.\n\nExpress your final answer as a single closed-form analytic expression for the exact stationary variance $\\mathrm{Var}[X]$ in terms of $\\alpha$ and $\\gamma$. No numerical approximation or rounding is required. Express the variance in molecule counts.",
            "solution": "The supplied problem statement is subjected to validation prior to any attempt at a solution.\n\n### Step 1: Extract Givens\n-   **System**: A single-species stochastic biochemical reaction system.\n-   **Species**: Molecule count $X(t)$, with state space $X(t) \\in \\{0, 1, 2, \\dots\\}$.\n-   **Reactions and Rates**:\n    1.  Synthesis (zero-order): $\\varnothing \\rightarrow X$, with rate constant $\\alpha$ (molecules per unit time).\n    2.  Decay (first-order): $X \\rightarrow \\varnothing$, with rate constant $\\gamma$ (per unit time).\n-   **Dynamics**:\n    -   Mesoscopic: Chemical Master Equation (CME).\n    -   Macroscopic: Deterministic rate equation $\\mathrm{d}\\phi/\\mathrm{d}t = \\alpha - \\gamma \\phi$.\n-   **Tasks**:\n    1.  From the steady-state CME, derive the exact stationary distribution $P_n$ and compute the exact stationary variance $\\mathrm{Var}[X]$. The derivation must be from first principles.\n    2.  From the deterministic rate equation, derive the Linear Noise Approximation (LNA) for the fluctuations and compute the stationary variance predicted by the LNA.\n    3.  Explain the conditions under which the LNA fails to provide accurate results for variance or distributional features.\n-   **Required Output**: A single expression for the exact stationary variance $\\mathrm{Var}[X]$ in terms of $\\alpha$ and $\\gamma$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n-   **Scientifically Grounded**: The problem describes a birth–death process, a canonical model in stochastic chemical kinetics. The Chemical Master Equation, the deterministic rate equation, and the Linear Noise Approximation are fundamental and well-established theoretical frameworks for modeling such systems. The premises are scientifically sound.\n-   **Well-Posed**: The problem is clearly defined, with all necessary parameters ($\\alpha$, $\\gamma$) and reaction channels specified. It requests specific, sequential derivations leading to a defined calculable quantity. A unique, stable solution for the variance is expected to exist.\n-   **Objective**: The problem is stated in precise, technical language, free from ambiguity or subjective content.\n-   **Completeness and Consistency**: The problem statement is self-contained and internally consistent. The reactions described correspond directly to the given deterministic rate equation. There are no missing or contradictory data.\n-   **Realism and Feasibility**: The model is a standard and physically plausible representation of constitutive gene expression, a common motif in synthetic biology.\n-   **Other Flaws**: The problem is a standard, fundamental derivation that tests first-principles understanding. It is not trivial, ill-posed, or unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Solution\n\nThe problem addresses the stochastic dynamics of a simple gene expression model, comparing an exact solution from the Chemical Master Equation (CME) with an approximate solution from the Linear Noise Approximation (LNA).\n\n**1. Exact Stationary Variance from the Chemical Master Equation**\n\nThe system is a birth–death process with state variable $n \\in \\{0, 1, 2, \\dots\\}$ representing the number of molecules of species $X$. The reactions are:\n-   Birth: $\\varnothing \\xrightarrow{\\alpha} X$ (propensity $w_b = \\alpha$)\n-   Death: $X \\xrightarrow{\\gamma} \\varnothing$ (propensity $w_d(n) = \\gamma n$)\n\nLet $P(n, t)$ be the probability of having $n$ molecules at time $t$. The CME for this system is:\n$$ \\frac{dP(n,t)}{dt} = \\alpha P(n-1,t) + \\gamma (n+1) P(n+1,t) - (\\alpha + \\gamma n) P(n,t) \\quad \\text{for } n \\geq 1 $$\n$$ \\frac{dP(0,t)}{dt} = \\gamma P(1,t) - \\alpha P(0,t) $$\nAt steady state, $\\frac{dP(n,t)}{dt} = 0$ for all $n$. Let $P_n$ denote the stationary probability $P(n, t \\to \\infty)$. The steady-state CME becomes a set of algebraic equations. A simpler approach is to use the principle of detailed balance for one-dimensional systems, which states that the net flux between any two adjacent states must be zero at steady state. The flux from state $n-1$ to $n$ (birth) must equal the flux from state $n$ to $n-1$ (death).\n$$ \\text{Flux}(n-1 \\to n) = \\alpha P_{n-1} $$\n$$ \\text{Flux}(n \\to n-1) = \\gamma n P_n $$\nEquating these gives the recurrence relation:\n$$ \\alpha P_{n-1} = \\gamma n P_n $$\nThis can be rearranged to express $P_n$ in terms of $P_{n-1}$:\n$$ P_n = \\frac{\\alpha}{n \\gamma} P_{n-1} $$\nWe can solve this relation by iteration:\n$$ P_1 = \\frac{\\alpha}{1 \\cdot \\gamma} P_0 $$\n$$ P_2 = \\frac{\\alpha}{2 \\gamma} P_1 = \\frac{\\alpha}{2 \\gamma} \\left(\\frac{\\alpha}{1 \\cdot \\gamma} P_0\\right) = \\frac{1}{2!} \\left(\\frac{\\alpha}{\\gamma}\\right)^2 P_0 $$\nBy induction, the general form is:\n$$ P_n = \\frac{1}{n!} \\left(\\frac{\\alpha}{\\gamma}\\right)^n P_0 $$\nTo find $P_0$, we use the normalization condition $\\sum_{n=0}^{\\infty} P_n = 1$:\n$$ \\sum_{n=0}^{\\infty} \\frac{1}{n!} \\left(\\frac{\\alpha}{\\gamma}\\right)^n P_0 = 1 $$\n$$ P_0 \\sum_{n=0}^{\\infty} \\frac{(\\alpha/\\gamma)^n}{n!} = 1 $$\nThe sum is the Taylor series for the exponential function, $\\sum_{k=0}^{\\infty} x^k/k! = \\exp(x)$. Therefore:\n$$ P_0 \\exp\\left(\\frac{\\alpha}{\\gamma}\\right) = 1 \\implies P_0 = \\exp\\left(-\\frac{\\alpha}{\\gamma}\\right) $$\nSubstituting this back into the expression for $P_n$, we obtain the exact stationary distribution:\n$$ P_n = \\frac{(\\alpha/\\gamma)^n}{n!} \\exp\\left(-\\frac{\\alpha}{\\gamma}\\right) $$\nThis is a Poisson distribution with parameter $\\lambda = \\alpha/\\gamma$.\n\nFor a Poisson distribution with parameter $\\lambda$, the mean and variance are both equal to $\\lambda$. We confirm this from first principles.\nThe mean is $\\langle X \\rangle = \\sum_{n=0}^{\\infty} n P_n = \\lambda = \\alpha/\\gamma$.\nThe variance is $\\mathrm{Var}[X] = \\langle X^2 \\rangle - \\langle X \\rangle^2$. We compute the second moment $\\langle X^2 \\rangle$:\n$$ \\langle X^2 \\rangle = \\langle X(X-1) + X \\rangle = \\langle X(X-1) \\rangle + \\langle X \\rangle $$\n$$ \\langle X(X-1) \\rangle = \\sum_{n=0}^{\\infty} n(n-1) P_n = \\exp(-\\lambda) \\sum_{n=2}^{\\infty} n(n-1) \\frac{\\lambda^n}{n!} = \\exp(-\\lambda) \\sum_{n=2}^{\\infty} \\frac{\\lambda^n}{(n-2)!} $$\nLet $k=n-2$. Then $n=k+2$:\n$$ \\langle X(X-1) \\rangle = \\exp(-\\lambda) \\sum_{k=0}^{\\infty} \\frac{\\lambda^{k+2}}{k!} = \\lambda^2 \\exp(-\\lambda) \\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!} = \\lambda^2 \\exp(-\\lambda) \\exp(\\lambda) = \\lambda^2 $$\nThus, $\\langle X^2 \\rangle = \\lambda^2 + \\lambda$. The exact stationary variance is:\n$$ \\mathrm{Var}[X] = (\\lambda^2 + \\lambda) - \\lambda^2 = \\lambda = \\frac{\\alpha}{\\gamma} $$\n\n**2. Stationary Variance from the Linear Noise Approximation**\n\nThe Linear Noise Approximation (LNA) linearizes the system dynamics around the macroscopic, deterministic trajectory. We start with the macroscopic rate equation for the mean concentration $\\phi(t)$:\n$$ \\frac{d\\phi}{dt} = \\alpha - \\gamma \\phi $$\nThe steady state $\\phi^{\\ast}$ is found by setting $\\frac{d\\phi}{dt} = 0$:\n$$ \\alpha - \\gamma \\phi^{\\ast} = 0 \\implies \\phi^{\\ast} = \\frac{\\alpha}{\\gamma} $$\nThe LNA describes the dynamics of the fluctuation variable $\\epsilon(t) = X(t) - \\phi^{\\ast}$, where $X(t)$ is the stochastic molecule count. The evolution of $\\epsilon(t)$ is approximated by a linear stochastic differential equation (an Ornstein-Uhlenbeck process):\n$$ \\frac{d\\epsilon}{dt} = J \\epsilon + \\sqrt{D} \\xi(t) $$\nwhere $\\xi(t)$ is a Gaussian white noise process. The matrix $J$ is the Jacobian of the deterministic rate function, and $D$ is the diffusion matrix.\nFor this single-variable system:\nThe deterministic rate function is $F(\\phi) = \\alpha - \\gamma\\phi$.\nThe Jacobian is the scalar $J = \\frac{dF}{d\\phi}\\bigg|_{\\phi=\\phi^{\\ast}} = -\\gamma$.\n\nThe diffusion matrix $D$ is given by $D = S \\cdot \\text{diag}(W(\\phi^{\\ast})) \\cdot S^T$, where $S$ is the stoichiometry matrix and $W(\\phi^{\\ast})$ is the vector of reaction propensities evaluated at the steady state.\nThe stoichiometry matrix for reactions $[\\varnothing \\to X, X \\to \\varnothing]$ is $S = \\begin{pmatrix} 1 & -1 \\end{pmatrix}$.\nThe propensity vector is $W(\\phi) = \\begin{pmatrix} \\alpha \\\\ \\gamma\\phi \\end{pmatrix}$.\nEvaluated at the steady state $\\phi^{\\ast} = \\alpha/\\gamma$:\n$$ W(\\phi^{\\ast}) = \\begin{pmatrix} \\alpha \\\\ \\gamma(\\alpha/\\gamma) \\end{pmatrix} = \\begin{pmatrix} \\alpha \\\\ \\alpha \\end{pmatrix} $$\nThe diffusion term $D$ is a scalar in this case:\n$$ D = \\begin{pmatrix} 1 & -1 \\end{pmatrix} \\begin{pmatrix} \\alpha & 0 \\\\ 0 & \\alpha \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} \\alpha & -\\alpha \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = (1)(\\alpha)(1) + (-1)(\\alpha)(-1) = 2\\alpha $$\nThe LNA equation for the fluctuation $\\epsilon$ is:\n$$ \\frac{d\\epsilon}{dt} = -\\gamma \\epsilon(t) + \\sqrt{2\\alpha} \\xi(t) $$\nThe variance of the fluctuations, $\\Sigma = \\mathrm{Var}[\\epsilon] = \\langle \\epsilon^2 \\rangle$, evolves according to the continuous-time Lyapunov equation:\n$$ \\frac{d\\Sigma}{dt} = J\\Sigma + \\Sigma J^T + D $$\nAt steady state, $\\frac{d\\Sigma}{dt} = 0$, so we solve the algebraic Lyapunov equation:\n$$ J\\Sigma + \\Sigma J^T + D = 0 $$\nSubstituting the scalar values $J=-\\gamma$, $\\Sigma = \\sigma^2_{\\epsilon}$, and $D=2\\alpha$:\n$$ (-\\gamma)\\sigma^2_{\\epsilon} + \\sigma^2_{\\epsilon}(-\\gamma) + 2\\alpha = 0 $$\n$$ -2\\gamma\\sigma^2_{\\epsilon} = -2\\alpha $$\n$$ \\sigma^2_{\\epsilon} = \\frac{\\alpha}{\\gamma} $$\nThe variance predicted by the LNA, $\\mathrm{Var}[X]_{\\text{LNA}}$, is $\\sigma^2_{\\epsilon}$.\n$$ \\mathrm{Var}[X]_{\\text{LNA}} = \\frac{\\alpha}{\\gamma} $$\nIn this particular case, the LNA result for the stationary variance is identical to the exact result derived from the CME. This is a special property of systems where all reaction propensities are at most linear functions of the species concentrations.\n\n**3. Limitations of the Linear Noise Approximation**\n\nThe LNA is fundamentally an approximation based on a system-size expansion, which rests on the assumption that fluctuations are small relative to the mean. It linearizes system dynamics and consequently approximates the stationary distribution of fluctuations as a Gaussian. The LNA fails or yields qualitatively incorrect results under several conditions:\n-   **Low Molecule Numbers**: The LNA is a continuous approximation that assumes a large number of molecules. When molecule counts are low (e.g., if $\\alpha/\\gamma \\ll 10$), the discrete nature of the chemical species becomes dominant. The true distribution (e.g., Poisson) is discrete and skewed, whereas the LNA predicts a continuous, symmetric Gaussian distribution. The LNA can also unphysically predict a non-zero probability for negative molecule numbers.\n-   **Nonlinear Reaction Kinetics**: The LNA linearizes the propensity functions. If the system contains nonlinear reactions (e.g., dimerization, $2X \\to Y$, with propensity $\\propto X(X-1)$), this linearization is an approximation. Such nonlinearities can give rise to non-Gaussian features in the true probability distribution, such as skewness or heavy tails, which the LNA cannot capture.\n-   **Multimodality**: In systems capable of bistability or multistability (e.g., a genetic toggle switch), the deterministic dynamics possess multiple stable steady states. The true stationary probability distribution is multimodal, with peaks centered near these states. The LNA is constructed by linearizing around a single deterministic state. Consequently, it predicts a unimodal Gaussian distribution and is structurally incapable of describing the global multimodal nature of the state space or the noise-induced transitions between stable states.\n-   **Proximity to Bifurcations**: Near a bifurcation point in the parameter space of the deterministic model, one or more eigenvalues of the Jacobian matrix $J$ approach zero. The linear term in the dynamics becomes weak, and higher-order nonlinear terms, which the LNA neglects, become dominant. The LNA formally predicts a divergent variance as an eigenvalue approaches zero, signaling the breakdown of the approximation.\n\nIn summary, while the LNA exactly reproduces the first two moments for the linear birth-death process, this is an exceptional case. For the majority of synthetic biological circuits, which often feature nonlinear feedback and low copy numbers of key regulators, the LNA serves as a useful but potentially inaccurate approximation.",
            "answer": "$$ \\boxed{\\frac{\\alpha}{\\gamma}} $$"
        },
        {
            "introduction": "Real biological systems are rich with nonlinear interactions, such as proteins dimerizing to form active complexes. This practice moves beyond linear systems to address how the LNA handles such nonlinearities. By focusing on a simple dimerization reaction, you will learn how to construct the key components of the LNA—the stoichiometry matrix $S$ and the state-dependent Jacobian matrix $J$—demonstrating how the approximation linearizes the dynamics around a specific state. Mastering this step is fundamental to applying the LNA to more complex and realistic models of gene circuits.",
            "id": "3936455",
            "problem": "Consider a synthetic gene circuit module in which a transcription factor $X$ homodimerizes to form a complex $Y$ via the reaction $2X \\to Y$. Assume the macroscopic rate law for this single reaction is $a(x) = k x^2$, where $x$ denotes the concentration of $X$ and $k$ is a positive rate constant. Let the species ordering be $[X, Y]$, and let the stoichiometry matrix be denoted by $S$ with one column corresponding to this reaction. Under the Linear Noise Approximation (LNA), one constructs the deterministic drift from the stoichiometry and the reaction rate, and then constructs the Jacobian matrix $J$ of the drift with respect to the state.\n\nWhich option correctly specifies the single reaction column of $S$ for this network and correctly characterizes how the nonlinearity in $a(x)$ enters the Jacobian $J$?\n\nA. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is state dependent through the derivative of $a(x)$, yielding $J = \\begin{bmatrix} -4 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix}$.\n\nB. The column of $S$ is $\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$, and the Jacobian is $J = \\begin{bmatrix} -2 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix}$.\n\nC. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is independent of state because the nonlinearity does not enter $J$, yielding $J = \\begin{bmatrix} -2 k & 0 \\\\ k & 0 \\end{bmatrix}$.\n\nD. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian entries are proportional directly to $a(x)$, yielding $J = \\begin{bmatrix} -k x^2 & 0 \\\\ k x^2 & 0 \\end{bmatrix}$.\n\nE. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is $J = \\begin{bmatrix} -4 k & 0 \\\\ 2 k & 0 \\end{bmatrix}$ because the derivative of $a(x)$ with respect to $x$ is constant.",
            "solution": "The user has requested an exacting analysis of a problem concerning the Linear Noise Approximation (LNA) in the context of synthetic biology modeling. The process begins with a formal validation of the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Reaction:** A transcription factor $X$ homodimerizes to form a complex $Y$ via the reaction $2X \\to Y$.\n- **Species:** The species are $X$ and $Y$.\n- **State Vector Ordering:** The species are ordered as $[X, Y]$.\n- **Macroscopic Rate Law:** The rate for the single reaction is given as $a(x) = k x^2$, where $x$ is the concentration of species $X$ and $k$ is a positive rate constant.\n- **Quantities to Determine:** The problem asks for the single column of the stoichiometry matrix $S$ and the Jacobian matrix $J$ of the deterministic drift, along with a characterization of how the nonlinearity of $a(x)$ affects $J$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is subjected to a rigorous check for validity.\n\n- **Scientific Groundedness:** The problem is scientifically sound. It describes a standard dimerization reaction, $2X \\to Y$, which is a fundamental process in biochemistry and molecular biology. The macroscopic rate law $a(x)=kx^2$ is consistent with the law of mass action for this second-order reaction. The concepts of a stoichiometry matrix, deterministic drift, and the Jacobian matrix are standard, well-defined mathematical tools used in chemical kinetics and systems biology, particularly in the derivation of the Linear Noise Approximation.\n- **Well-Posedness:** The problem is well-posed. The information provided (the reaction equation, the species ordering, and the rate law) is necessary and sufficient to uniquely determine the stoichiometry matrix column and the Jacobian matrix.\n- **Objectivity:** The problem is stated in precise, objective, and unambiguous mathematical and scientific terms.\n\n**Step 3: Verdict and Action**\nThe problem statement is free of scientific flaws, ambiguities, or contradictions. It is a valid, well-posed problem from the field of chemical kinetics and systems biology. Therefore, I will proceed with the derivation of the solution.\n\n### Solution Derivation\n\nThe solution requires the determination of the stoichiometry matrix $S$ and the Jacobian matrix $J$ for the given system.\n\n**1. Stoichiometry Matrix ($S$)**\n\nThe state vector of the system represents the concentrations of the species, ordered as $[X, Y]$. Let's denote this vector as $\\mathbf{c} = \\begin{bmatrix} x \\\\ y \\end{bmatrix}$. The stoichiometry matrix $S$ describes the net change in the number of molecules (or concentration, in a macroscopic view) of each species for each reaction. For the single reaction $2X \\to Y$:\n- The number of molecules of species $X$ decreases by $2$.\n- The number of molecules of species $Y$ increases by $1$.\n\nThe change vector, which forms the single column of the stoichiometry matrix $S$, is therefore:\n$$ S = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} $$\n\n**2. Deterministic Drift and Jacobian Matrix ($J$)**\n\nThe Linear Noise Approximation is a linearization around the solution of the deterministic (macroscopic) rate equations. The deterministic drift vector, $F(\\mathbf{c})$, describes the rate of change of the concentrations. It is calculated as the product of the stoichiometry matrix and the vector of reaction rates. Here, there is only one reaction with rate $a(x) = kx^2$.\n\n$$ \\frac{d\\mathbf{c}}{dt} = F(\\mathbf{c}) = S \\cdot a(x) $$\nSubstituting the expressions for $S$ and $a(x)$:\n$$ F(\\mathbf{c}) = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} (k x^2) = \\begin{bmatrix} -2 k x^2 \\\\ k x^2 \\end{bmatrix} $$\nThe two components of the drift vector are $F_x(x,y) = -2 k x^2$ and $F_y(x,y) = k x^2$.\n\nThe Jacobian matrix $J$ is the matrix of all first-order partial derivatives of the drift vector $F(\\mathbf{c})$ with respect to the state variables $x$ and $y$.\n$$ J = \\frac{\\partial F}{\\partial \\mathbf{c}} = \\begin{bmatrix} \\frac{\\partial F_x}{\\partial x} & \\frac{\\partial F_x}{\\partial y} \\\\ \\frac{\\partial F_y}{\\partial x} & \\frac{\\partial F_y}{\\partial y} \\end{bmatrix} $$\nWe compute each entry:\n- $\\frac{\\partial F_x}{\\partial x} = \\frac{\\partial}{\\partial x}(-2 k x^2) = -2k \\cdot (2x) = -4 k x$\n- $\\frac{\\partial F_x}{\\partial y} = \\frac{\\partial}{\\partial y}(-2 k x^2) = 0$\n- $\\frac{\\partial F_y}{\\partial x} = \\frac{\\partial}{\\partial x}(k x^2) = k \\cdot (2x) = 2 k x$\n- $\\frac{\\partial F_y}{\\partial y} = \\frac{\\partial}{\\partial y}(k x^2) = 0$\n\nAssembling these entries gives the Jacobian matrix:\n$$ J = \\begin{bmatrix} -4 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix} $$\n\nThe entries of the Jacobian matrix $J$ are clearly dependent on the state variable $x$. This state dependence arises because the drift $F(\\mathbf{c})$ is a nonlinear function of $x$. Specifically, the nonlinearity of the rate law $a(x) = k x^2$ enters the Jacobian through its derivative, $\\frac{da}{dx} = 2kx$. The Jacobian can be expressed more generally as $J = S \\frac{\\partial a}{\\partial \\mathbf{c}}$, which in this case is $J = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} \\frac{da}{dx} & \\frac{da}{dy} \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} 2kx & 0 \\end{bmatrix} = \\begin{bmatrix} -4kx & 0 \\\\ 2kx & 0 \\end{bmatrix}$.\n\n### Option-by-Option Analysis\n\n**A. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is state dependent through the derivative of $a(x)$, yielding $J = \\begin{bmatrix} -4 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix}$.**\n- The column of $S$ is correctly identified as $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$.\n- The Jacobian matrix $J$ is correctly calculated as $\\begin{bmatrix} -4 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix}$.\n- The characterization is correct: the Jacobian is state-dependent, and this dependence arises from the derivative of the nonlinear rate function $a(x)$.\n- **Verdict: Correct.**\n\n**B. The column of $S$ is $\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$, and the Jacobian is $J = \\begin{bmatrix} -2 k x & 0 \\\\ 2 k x & 0 \\end{bmatrix}$.**\n- The column of $S$ is $\\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$, which is incorrect. The stoichiometry of the reaction $2X \\to Y$ requires a change of $-2$ for species $X$.\n- **Verdict: Incorrect.**\n\n**C. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is independent of state because the nonlinearity does not enter $J$, yielding $J = \\begin{bmatrix} -2 k & 0 \\\\ k & 0 \\end{bmatrix}$.**\n- The column of $S$ is correct.\n- The claim that the Jacobian is independent of state is incorrect. As derived, $J$ depends on $x$. The provided matrix $J = \\begin{bmatrix} -2 k & 0 \\\\ k & 0 \\end{bmatrix}$ is also incorrect. This seems to mistake the rate law for a linear function, which it is not.\n- **Verdict: Incorrect.**\n\n**D. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian entries are proportional directly to $a(x)$, yielding $J = \\begin{bmatrix} -k x^2 & 0 \\\\ k x^2 & 0 \\end{bmatrix}$.**\n- The column of $S$ is correct.\n- The proposed Jacobian is incorrect. It is proportional to the drift vector $F(\\mathbf{c})$, not the Jacobian matrix $J$. The Jacobian involves derivatives of the drift, not the drift itself. The statement that Jacobian entries are proportional to $a(x) = kx^2$ is false; they are proportional to its derivative $\\frac{da}{dx} = 2kx$.\n- **Verdict: Incorrect.**\n\n**E. The column of $S$ is $\\begin{bmatrix} -2 \\\\ 1 \\end{bmatrix}$, and the Jacobian is $J = \\begin{bmatrix} -4 k & 0 \\\\ 2 k & 0 \\end{bmatrix}$ because the derivative of $a(x)$ with respect to $x$ is constant.**\n- The column of $S$ is correct.\n- The reasoning is fundamentally flawed. The derivative of $a(x)=kx^2$ is $\\frac{da}{dx}=2kx$, which is a function of $x$ and is not constant. The proposed Jacobian is therefore incorrect, as it assumes a constant derivative.\n- **Verdict: Incorrect.**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "This final practice is a capstone exercise that bridges theory and practical implementation by tackling a critical challenge in modeling biochemical networks: conservation laws. Many biological systems are closed to the exchange of certain molecular components, leading to conserved quantities (e.g., a fixed total number of gene copies) that must be handled correctly. This coding exercise guides you through the complete computational workflow, from identifying conserved quantities using linear algebra to projecting the system dynamics into a reduced space before applying the LNA. Completing this task will equip you with a robust, algorithm-driven approach to analyzing complex, constrained biological systems.",
            "id": "3936475",
            "problem": "Consider a well-mixed chemical reaction network modeled at the mesoscopic scale, where the state is a vector of molecule counts $x \\in \\mathbb{R}_{\\ge 0}^{n}$ and dynamics arise from reactions with stoichiometry matrix $S \\in \\mathbb{R}^{n \\times m}$. Each reaction $j$ has a mass-action propensity $a_j(x)$ with rate constant $k_j \\ge 0$ and reactant stoichiometry exponents collected in a matrix $R \\in \\mathbb{R}_{\\ge 0}^{n \\times m}$, where $R_{i j}$ denotes the number of molecules of species $i$ consumed by reaction $j$. The deterministic mean-field dynamics are given by $f(x) = S a(x)$, where $a(x) = \\left(a_1(x), \\dots, a_m(x)\\right)^\\top$, and are consistent with the Chemical Master Equation and its system-size expansion. Before applying the Linear Noise Approximation (LNA), conservation laws must be handled by projecting the dynamics to a reduced space where conserved combinations are removed.\n\nStarting from the fundamental base of the Chemical Master Equation and mass-action kinetics, implement the following steps for each provided test case:\n1. Given $S$, compute a basis of the nullspace of $S^\\top$ to identify conserved linear combinations of species. Let $C \\in \\mathbb{R}^{n \\times \\ell}$ be a matrix whose columns form an orthonormal basis of $\\mathrm{Null}(S^\\top)$. The conserved quantities satisfy $C^\\top x = \\text{constant}$.\n2. If a target conserved-total vector $x_{\\text{goal}} \\in \\mathbb{R}^n$ is provided, set $b = C^\\top x_{\\text{goal}} \\in \\mathbb{R}^\\ell$ and choose a particular state $x_0 = C b$ that satisfies the conservation constraints. Construct an orthonormal basis $V \\in \\mathbb{R}^{n \\times r}$, $r = n - \\ell$, for the subspace orthogonal to the columns of $C$ (that is, $C^\\top V = 0$). Parameterize the state by $x = x_0 + V y$, where $y \\in \\mathbb{R}^r$ are reduced coordinates.\n3. In reduced coordinates, find a steady state by solving $V^\\top f(x_0 + V y) = 0$ for $y$. If there are no conservation laws (that is, $\\ell = 0$), directly solve $f(x) = 0$ for $x$.\n4. At the steady state $x^\\star$, compute the Jacobian matrix $J = \\frac{\\partial f}{\\partial x}\\big|_{x^\\star}$ and the diffusion matrix $D = S \\,\\mathrm{diag}\\big(a(x^\\star)\\big)\\, S^\\top$, both implied by the system-size expansion underlying the Linear Noise Approximation (LNA). Project these to reduced coordinates: $J_{\\text{red}} = V^\\top J V$ and $D_{\\text{red}} = V^\\top D V$.\n5. Solve the steady-state covariance in reduced coordinates $\\Sigma_y$ from the continuous-time Lyapunov equation implied by LNA in the reduced space, and reconstruct the species-space covariance $\\Sigma_x = V \\Sigma_y V^\\top$. If $r = 0$, set $\\Sigma_x = 0$ by definition.\n6. Report, for each test case, the following quantifiable outputs:\n   - The integer number of conservation laws $\\ell$.\n   - The integer numerical rank of $\\Sigma_x$ under a tolerance of $10^{-10}$.\n   - The float maximum absolute violation of conservation in the covariance, defined as $\\max\\big|C^\\top \\Sigma_x\\big|$ (use $0.0$ if $\\ell = 0$).\n   - The float trace of $\\Sigma_x$.\n   - The float sum of steady-state species, $\\sum_i x_i^\\star$.\n\nYou must implement mass-action propensities $a_j(x) = k_j \\prod_{i=1}^n x_i^{R_{i j}}$ and their partial derivatives consistently with the fundamental definitions of mass-action kinetics. All calculations are dimensionless.\n\nYour program must process the following test suite, which is designed for coverage across scenarios:\n\n- Test case $1$ (reversible conversion with one conservation law):\n  - Species count $n = 2$, reactions $m = 2$.\n  - Stoichiometry matrix $S = \\begin{bmatrix} -1 & 1 \\\\ 1 & -1 \\end{bmatrix}$.\n  - Reactant exponents $R = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$.\n  - Rate constants $k = \\begin{bmatrix} 3.0 \\\\ 1.0 \\end{bmatrix}$.\n  - Target conserved totals encoded by $x_{\\text{goal}} = \\begin{bmatrix} 100.0 \\\\ 0.0 \\end{bmatrix}$ (this enforces $x_1 + x_2 = 100.0$ through the projection $b = C^\\top x_{\\text{goal}}$).\n\n- Test case $2$ (birth–death, no conservation law):\n  - Species count $n = 1$, reactions $m = 2$.\n  - Stoichiometry matrix $S = \\begin{bmatrix} 1 & -1 \\end{bmatrix}$.\n  - Reactant exponents $R = \\begin{bmatrix} 0 & 1 \\end{bmatrix}$.\n  - Rate constants $k = \\begin{bmatrix} 20.0 \\\\ 0.5 \\end{bmatrix}$.\n  - No $x_{\\text{goal}}$ provided.\n\n- Test case $3$ (two independent reversible conversions with two conservation laws):\n  - Species count $n = 4$, reactions $m = 4$.\n  - Stoichiometry matrix $S = \\begin{bmatrix}\n      -1 & 1 & 0 & 0 \\\\\n      1 & -1 & 0 & 0 \\\\\n      0 & 0 & -1 & 1 \\\\\n      0 & 0 & 1 & -1\n    \\end{bmatrix}$.\n  - Reactant exponents $R = \\begin{bmatrix}\n      1 & 0 & 0 & 0 \\\\\n      0 & 1 & 0 & 0 \\\\\n      0 & 0 & 1 & 0 \\\\\n      0 & 0 & 0 & 1\n    \\end{bmatrix}$.\n  - Rate constants $k = \\begin{bmatrix} 2.0 \\\\ 1.0 \\\\ 4.0 \\\\ 1.0 \\end{bmatrix}$.\n  - Target conserved totals encoded by $x_{\\text{goal}} = \\begin{bmatrix} 50.0 \\\\ 0.0 \\\\ 20.0 \\\\ 0.0 \\end{bmatrix}$ (this enforces $x_1 + x_2 = 50.0$ and $x_3 + x_4 = 20.0$).\n\n- Test case $4$ (no reactions, fully constrained state):\n  - Species count $n = 2$, reactions $m = 0$.\n  - Stoichiometry matrix $S$ is the $2 \\times 0$ empty matrix.\n  - Reactant exponents $R$ is the $2 \\times 0$ empty matrix.\n  - Rate constants $k$ is the empty vector.\n  - Target conserved totals encoded by $x_{\\text{goal}} = \\begin{bmatrix} 3.0 \\\\ 7.0 \\end{bmatrix}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of five values in the order specified above (for example, $\\left[ [\\ell, \\mathrm{rank}, \\mathrm{viol}, \\mathrm{trace}, \\mathrm{sum}], \\dots \\right]$). No additional text should be printed.",
            "solution": "The Chemical Master Equation (CME) describes the stochastic time evolution of molecule counts in a well-mixed reaction system. For large system sizes, the van Kampen system-size expansion provides a principled approximation that decomposes the state into a deterministic component and stochastic fluctuations. The deterministic component obeys the mean-field ordinary differential equation $d x / d t = f(x)$, where $f(x) = S a(x)$, and $a(x)$ collects the reaction propensities. Under mass-action kinetics, the propensity of reaction $j$ is $a_j(x) = k_j \\prod_{i=1}^n x_i^{R_{i j}}$, consistent with the fundamental definition that each reactant contributes multiplicatively according to its molecularity.\n\nConservation laws in chemical reaction networks arise from linear combinations of species that remain invariant under the stoichiometry, that is, there exist nonzero vectors $c \\in \\mathbb{R}^n$ such that $c^\\top S = 0^\\top$. The set of all such $c$ forms the left nullspace of $S$, equivalently the nullspace of $S^\\top$. Let $C \\in \\mathbb{R}^{n \\times \\ell}$ be an orthonormal basis of $\\mathrm{Null}(S^\\top)$, where $\\ell$ is the number of independent conservation laws. For any trajectory $x(t)$ of the deterministic dynamics, $C^\\top x(t)$ is constant, since $\\frac{d}{d t}\\left(C^\\top x\\right) = C^\\top \\frac{d x}{d t} = C^\\top S a(x) = 0$.\n\nTo correctly apply the Linear Noise Approximation (LNA), one must remove these conserved directions before linearization, otherwise the deterministic Jacobian will be singular and the covariance equation will be ill-posed. This is done by parameterizing the state within an affine subspace satisfying the conservation constraints. If a desired conserved-total vector is provided as $x_{\\text{goal}} \\in \\mathbb{R}^n$, define $b = C^\\top x_{\\text{goal}} \\in \\mathbb{R}^\\ell$ and pick any particular solution $x_0$ of $C^\\top x = b$. Because $C$ is orthonormal, a minimal-norm choice is $x_0 = C b$. Then construct $V \\in \\mathbb{R}^{n \\times r}$, an orthonormal basis of the subspace orthogonal to the columns of $C$, where $r = n - \\ell$. This ensures $C^\\top V = 0$ and every state satisfying the constraints can be written as $x = x_0 + V y$ for some reduced coordinates $y \\in \\mathbb{R}^r$.\n\nThe reduced dynamics in $y$ are obtained by projecting the full vector field: define $g(y) = V^\\top f(x_0 + V y)$. A steady state in reduced coordinates satisfies $g(y^\\star) = 0$, yielding $x^\\star = x_0 + V y^\\star$. If there are no conservation laws (that is, $\\ell = 0$), then $V$ is the identity matrix and one solves $f(x^\\star) = 0$ directly.\n\nThe Linear Noise Approximation (LNA) characterizes the covariance of fluctuations around a deterministic steady state from first principles. Specifically, the linearization of the CME under the system-size expansion yields a Gaussian process for fluctuations $\\eta$ with drift given by the Jacobian $J = \\frac{\\partial f}{\\partial x}\\big|_{x^\\star}$ and diffusion proportional to the reaction shot noise, summarized by $D = S \\,\\mathrm{diag}\\big(a(x^\\star)\\big)\\, S^\\top$. Both $J$ and $D$ are derived from the fundamental properties of the system: $f$ captures the mean-field flow, while $D$ encodes the intrinsic reaction noise resulting from Poissonian firing in each channel. In reduced coordinates, the drift and diffusion matrices become $J_{\\text{red}} = V^\\top J V$ and $D_{\\text{red}} = V^\\top D V$. The steady-state covariance in reduced coordinates $\\Sigma_y$ solves the continuous-time Lyapunov equation implied by linear Gaussian dynamics:\n$$\nJ_{\\text{red}} \\Sigma_y + \\Sigma_y J_{\\text{red}}^\\top + D_{\\text{red}} = 0,\n$$\nwhich has a unique positive semidefinite solution when $J_{\\text{red}}$ is Hurwitz (all eigenvalues have negative real part), as guaranteed by stability of the reduced deterministic dynamics near $x^\\star$. The species-space covariance is reconstructed as\n$$\n\\Sigma_x = V \\Sigma_y V^\\top,\n$$\nwhich is automatically consistent with the conservation constraints, since $\\Sigma_x$ has support only within the subspace spanned by $V$ and $C^\\top V = 0$ implies $C^\\top \\Sigma_x = 0$.\n\nFor mass-action kinetics, computing the Jacobian $J$ from first principles proceeds by differentiating the propensities. The vector field is $f(x) = S a(x)$, so the Jacobian is\n$$\nJ = \\frac{\\partial f}{\\partial x} = S \\frac{\\partial a}{\\partial x}.\n$$\nThe partial derivatives of each propensity component are\n$$\n\\frac{\\partial a_j}{\\partial x_i}(x) = \n\\begin{cases}\nk_j R_{i j} \\, x_i^{R_{i j} - 1} \\prod\\limits_{\\ell \\ne i} x_\\ell^{R_{\\ell j}}, & \\text{if } R_{i j} > 0, \\\\\n0, & \\text{if } R_{i j} = 0,\n\\end{cases}\n$$\nwhich follows directly from differentiating the mass-action monomial $k_j \\prod_{\\ell} x_\\ell^{R_{\\ell j}}$ with respect to $x_i$.\n\nThe algorithmic steps to implement are therefore:\n- Compute $C$ from the nullspace of $S^\\top$ and determine $\\ell$.\n- Construct $V$ as an orthonormal basis of the orthogonal complement of the columns of $C$; if $\\ell = 0$, set $V$ to the identity.\n- If $x_{\\text{goal}}$ is provided, compute $b = C^\\top x_{\\text{goal}}$ and set $x_0 = C b$; otherwise set $x_0 = 0$.\n- Solve $V^\\top f(x_0 + V y) = 0$ for $y^\\star$ (or $f(x^\\star) = 0$ directly when $\\ell = 0$) using a robust nonlinear solver, then set $x^\\star = x_0 + V y^\\star$.\n- Compute $a(x^\\star)$, $\\frac{\\partial a}{\\partial x}(x^\\star)$, $J = S \\frac{\\partial a}{\\partial x}$, and $D = S \\,\\mathrm{diag}(a(x^\\star))\\, S^\\top$.\n- Project to reduced coordinates and solve the Lyapunov equation for $\\Sigma_y$, then reconstruct $\\Sigma_x$.\n- Report the five outputs: $\\ell$, numerical rank of $\\Sigma_x$ under tolerance $10^{-10}$, $\\max |C^\\top \\Sigma_x|$ (or $0.0$ if $\\ell = 0$), $\\mathrm{trace}(\\Sigma_x)$, and $\\sum_i x_i^\\star$.\n\nThe provided test suite exercises several facets:\n- A reversible two-species system with one conservation law, confirming detection of $\\ell = 1$, proper projection, and nontrivial covariance rank equal to the reduced dimension.\n- A birth–death process with no conservation laws, confirming that $\\ell = 0$, projection reduces to identity, and the Lyapunov equation is solvable in full space.\n- Two independent reversible pairs with two conservation laws, confirming multi-constraint handling and block-structured projection.\n- A system with no reactions, yielding $\\ell = n$ and $r = 0$, confirming that the covariance is the zero matrix and the steady state is exactly the constrained $x_0$.\n\nThe final program follows these steps and outputs the requested per-case diagnostics in the specified single-line format.",
            "answer": "```python\nimport numpy as np\nfrom numpy.linalg import svd\nfrom scipy import linalg, optimize\n\ndef nullspace(A, rtol=1e-12):\n    \"\"\"\n    Compute an orthonormal basis for the nullspace of A using SVD.\n    Returns matrix whose columns span Null(A).\n    \"\"\"\n    # SVD of A\n    U, s, Vh = linalg.svd(A, full_matrices=True)\n    # Determine tolerance relative to largest singular value\n    tol = rtol * (s[0] if s.size > 0 else 1.0)\n    # Nullspace corresponds to singular values ~ 0; rows of Vh with s <= tol\n    if s.size == 0:\n        # A has shape (0, n): full nullspace of R^n\n        # Vh is identity of size n\n        n = A.shape[1]\n        return np.eye(n)\n    rank = np.sum(s > tol)\n    # Vh is (k x n), where k = number of singular vectors = n if full_matrices\n    # Nullspace basis consists of rows of Vh corresponding to zero singular values\n    ns = Vh[rank:].conj().T\n    return ns\n\ndef mass_action_propensity(x, k, R):\n    \"\"\"\n    Compute mass-action propensities a_j(x) = k_j * prod_i x_i^{R_{i j}}.\n    \"\"\"\n    if R.size == 0:\n        return np.zeros((0,), dtype=float)\n    x = np.asarray(x, dtype=float)\n    k = np.asarray(k, dtype=float)\n    n, m = R.shape\n    a = np.zeros(m, dtype=float)\n    for j in range(m):\n        # product over species\n        prod = 1.0\n        for i in range(n):\n            exp = R[i, j]\n            if exp == 0:\n                continue\n            prod *= x[i] ** exp\n        a[j] = k[j] * prod\n    return a\n\ndef dpropensity_dx(x, k, R):\n    \"\"\"\n    Compute the Jacobian of propensities: G[j, i] = d a_j / d x_i.\n    For mass-action: if R_{i j} > 0:\n        d/dx_i ( k_j * prod_l x_l^{R_{l j}} ) = k_j * R_{i j} * x_i^{R_{i j} - 1} * prod_{l != i} x_l^{R_{l j}}\n    else:\n        0\n    Returns G of shape (m, n).\n    \"\"\"\n    if R.size == 0:\n        return np.zeros((0, len(x)), dtype=float)\n    x = np.asarray(x, dtype=float)\n    k = np.asarray(k, dtype=float)\n    n, m = R.shape\n    G = np.zeros((m, n), dtype=float)\n    # Precompute full monomials to speed up\n    # For each reaction j, compute prod_l x_l^{R_{l j}}\n    monomials = np.ones(m, dtype=float)\n    for j in range(m):\n        prod = 1.0\n        for i in range(n):\n            exp = R[i, j]\n            if exp == 0:\n                continue\n            prod *= x[i] ** exp\n        monomials[j] = prod\n    for j in range(m):\n        for i in range(n):\n            exp = R[i, j]\n            if exp > 0:\n                # Replace one factor x_i^{exp} with exp * x_i^{exp - 1}\n                if x[i] <= 0 and exp - 1 < 0:\n                    # Avoid invalid derivative at zero with negative exponent; in mass-action,\n                    # this case corresponds to zero propensity and zero derivative.\n                    term = 0.0\n                else:\n                    # monomials[j] includes x_i^{exp}; divide out x_i^{exp} then multiply exp*x_i^{exp-1}\n                    base = monomials[j] / (x[i] ** exp if x[i] != 0 else (0.0 if exp > 0 else 1.0))\n                    term = k[j] * exp * (x[i] ** (exp - 1)) * base\n                G[j, i] = term\n            else:\n                G[j, i] = 0.0\n    return G\n\ndef steady_state_reduced(S, R, k, C, V, x0):\n    \"\"\"\n    Solve for steady state in reduced coordinates: find y such that V^T f(x0 + V y) = 0.\n    If V has zero columns (r = 0), return x = x0.\n    \"\"\"\n    n, m = S.shape\n    r = V.shape[1] if V.size > 0 else 0\n    if r == 0:\n        return x0.copy()\n    # Define reduced vector field\n    def g(y):\n        x = x0 + V @ y\n        a = mass_action_propensity(x, k, R)\n        f = S @ a\n        return V.T @ f\n    y0 = np.zeros(r, dtype=float)\n    sol = optimize.root(g, y0, method='hybr')\n    if not sol.success:\n        # Try another method\n        sol = optimize.root(g, y0, method='lm')\n    ystar = sol.x\n    xstar = x0 + V @ ystar\n    return xstar\n\ndef lna_covariance(S, R, k, xstar, V):\n    \"\"\"\n    Compute LNA steady-state covariance in species space:\n    J = S * d a / d x; D = S diag(a) S^T.\n    Project: J_red = V^T J V; D_red = V^T D V.\n    Solve Lyapunov: J_red Sigma_y + Sigma_y J_red^T + D_red = 0.\n    Reconstruct Sigma_x = V Sigma_y V^T.\n    \"\"\"\n    n, m = S.shape\n    r = V.shape[1] if V.size > 0 else 0\n    if r == 0:\n        return np.zeros((n, n), dtype=float)\n    a = mass_action_propensity(xstar, k, R)\n    G = dpropensity_dx(xstar, k, R)  # shape (m, n)\n    J = S @ G  # shape (n, n)\n    D = S @ np.diag(a) @ S.T  # shape (n, n)\n    J_red = V.T @ J @ V\n    D_red = V.T @ D @ V\n    # Solve continuous Lyapunov: A X + X A^T + Q = 0 -> X = solve_continuous_lyapunov(A, -Q)\n    Sigma_y = linalg.solve_continuous_lyapunov(J_red, -D_red)\n    Sigma_x = V @ Sigma_y @ V.T\n    return Sigma_x\n\ndef numerical_rank(M, tol=1e-10):\n    \"\"\"\n    Numerical rank based on SVD with tolerance relative to maximum singular value.\n    \"\"\"\n    if M.size == 0:\n        return 0\n    s = svd(M, compute_uv=False)\n    smax = s.max() if s.size > 0 else 0.0\n    thr = tol * (smax if smax > 0 else 1.0)\n    return int(np.sum(s > thr))\n\ndef solve():\n    # Define test cases as tuples: (S, R, k, x_goal)\n    # Case 1: reversible A <-> B with one conservation law\n    S1 = np.array([[-1.0, 1.0],\n                   [ 1.0,-1.0]], dtype=float)\n    R1 = np.array([[1.0, 0.0],\n                   [0.0, 1.0]], dtype=float)\n    k1 = np.array([3.0, 1.0], dtype=float)\n    x_goal1 = np.array([100.0, 0.0], dtype=float)\n\n    # Case 2: birth-death, no conservation law\n    S2 = np.array([[1.0, -1.0]], dtype=float)  # n=1, m=2\n    R2 = np.array([[0.0, 1.0]], dtype=float)\n    k2 = np.array([20.0, 0.5], dtype=float)\n    x_goal2 = None\n\n    # Case 3: two independent reversible pairs with two conservation laws\n    S3 = np.array([[-1.0,  1.0,  0.0,  0.0],\n                   [ 1.0, -1.0,  0.0,  0.0],\n                   [ 0.0,  0.0, -1.0,  1.0],\n                   [ 0.0,  0.0,  1.0, -1.0]], dtype=float)\n    R3 = np.array([[1.0, 0.0, 0.0, 0.0],\n                   [0.0, 1.0, 0.0, 0.0],\n                   [0.0, 0.0, 1.0, 0.0],\n                   [0.0, 0.0, 0.0, 1.0]], dtype=float)\n    k3 = np.array([2.0, 1.0, 4.0, 1.0], dtype=float)\n    x_goal3 = np.array([50.0, 0.0, 20.0, 0.0], dtype=float)\n\n    # Case 4: no reactions, fully constrained\n    S4 = np.zeros((2, 0), dtype=float)\n    R4 = np.zeros((2, 0), dtype=float)\n    k4 = np.zeros((0,), dtype=float)\n    x_goal4 = np.array([3.0, 7.0], dtype=float)\n\n    test_cases = [\n        (S1, R1, k1, x_goal1),\n        (S2, R2, k2, x_goal2),\n        (S3, R3, k3, x_goal3),\n        (S4, R4, k4, x_goal4),\n    ]\n\n    results = []\n    for (S, R, k, x_goal) in test_cases:\n        n, m = S.shape\n        # Compute conservation basis C as Null(S^T)\n        C = nullspace(S.T, rtol=1e-12)\n        ell = C.shape[1]\n        # Compute V as Null(C^T) if ell > 0, else identity\n        if ell > 0:\n            V = nullspace(C.T, rtol=1e-12)\n        else:\n            V = np.eye(n)\n\n        # Particular solution x0 satisfying constraints\n        if ell > 0:\n            if x_goal is None:\n                # If constraints exist but no goal provided, set b = 0 (default totals)\n                b = np.zeros(ell, dtype=float)\n            else:\n                b = C.T @ x_goal\n            x0 = C @ b\n        else:\n            x0 = np.zeros(n, dtype=float)\n\n        # Steady state in reduced coordinates\n        xstar = steady_state_reduced(S, R, k, C, V, x0)\n\n        # LNA covariance\n        Sigma_x = lna_covariance(S, R, k, xstar, V)\n\n        # Numerical rank\n        rank_cov = numerical_rank(Sigma_x, tol=1e-10)\n\n        # Conservation violation in covariance\n        if ell > 0:\n            viol = np.max(np.abs(C.T @ Sigma_x))\n        else:\n            viol = 0.0\n\n        # Trace of covariance\n        trace_cov = float(np.trace(Sigma_x))\n\n        # Sum of steady-state species\n        sum_x = float(np.sum(xstar))\n\n        results.append([int(ell), int(rank_cov), float(viol), float(trace_cov), float(sum_x)])\n\n    # Final output: single line with list of per-case results\n    print(str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}