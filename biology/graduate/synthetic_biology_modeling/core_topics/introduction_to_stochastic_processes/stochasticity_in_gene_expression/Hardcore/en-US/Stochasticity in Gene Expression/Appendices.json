{
    "hands_on_practices": [
        {
            "introduction": "In synthetic biology, designing a circuit is not just about achieving a target average output; it's also about controlling the cell-to-cell variability, or noise, in that output. Different genetic architectures can produce the same mean expression level but result in dramatically different population heterogeneity. This exercise  presents a classic design trade-off, challenging you to determine whether a \"high transcription, low translation\" or \"low transcription, high translation\" strategy is better for minimizing noise, thereby building deep intuition about the origins of stochasticity in the two-stage process of gene expression.",
            "id": "2071130",
            "problem": "A synthetic biologist is designing a genetic circuit in bacteria to produce a fluorescent protein. The goal is to achieve a specific mean level of protein expression across a cell population, but with the lowest possible cell-to-cell variability. The expression of the protein is governed by a simple two-stage model: DNA is transcribed into messenger RNA (mRNA) at a rate $k_m$, and each mRNA molecule is then translated into protein at a rate $k_p$. The mRNA molecules degrade at a rate $\\gamma_m$, and the protein molecules degrade at a rate $\\gamma_p$. The transcription rate $k_m$ is determined by the promoter strength, and the translation rate $k_p$ is determined by the strength of the Ribosome Binding Site (RBS).\n\nThe biologist has two constructs to choose from, labeled Construct Alpha and Construct Beta. Both constructs use the same gene for the fluorescent protein and are expressed in the same bacterial strain, so their mRNA and protein degradation rates, $\\gamma_m$ and $\\gamma_p$, are identical. The constructs differ only in their promoters and RBS sequences.\n\n- **Construct Alpha** uses a strong promoter and a weak RBS.\n- **Construct Beta** uses a weak promoter and a strong RBS.\n\nThe strengths are tuned such that the product of the transcription rate and the translation rate is identical for both constructs, ensuring they produce the same mean number of protein molecules per cell at steady state. Specifically, let the rates for Construct Alpha be $k_{m,A}$ and $k_{p,A}$, and for Construct Beta be $k_{m,B}$ and $k_{p,B}$. The following relationships hold: $k_{m,A} > k_{m,B}$, $k_{p,A} < k_{p,B}$, and $k_{m,A} k_{p,A} = k_{m,B} k_{p,B}$.\n\nAssume that the protein is much more stable than the mRNA (i.e., $\\gamma_p \\ll \\gamma_m$). Which construct should the biologist choose to achieve lower cell-to-cell variability in protein levels?\n\nA. Construct Alpha will have lower variability.\n\nB. Construct Beta will have lower variability.\n\nC. Both constructs will have the same variability because their mean expression levels are identical.\n\nD. The variability cannot be determined without the specific numerical values for the degradation rates $\\gamma_m$ and $\\gamma_p$.",
            "solution": "We model expression with the standard two-stage birth-death process. mRNA is produced at rate $k_{m}$ and degraded at rate $\\gamma_{m}$; protein is produced from mRNA at rate $k_{p}$ and degraded at rate $\\gamma_{p}$. At steady state,\n$$\n\\bar{M} = \\frac{k_{m}}{\\gamma_{m}}, \\qquad \\bar{P} = \\mu = \\frac{k_{p}}{\\gamma_{p}} \\bar{M} = \\frac{k_{m} k_{p}}{\\gamma_{m} \\gamma_{p}}.\n$$\nTo compare cell-to-cell variability, we compute the steady-state variance of protein from the exact moment equations of the linear reaction network. Let $M$ and $P$ denote the random copy numbers of mRNA and protein, respectively. Using the chemical master equation for linear reactions, the steady-state equations for second moments yield:\n- For mRNA, since it is a simple birth-death process, $\\operatorname{Var}(M) = \\bar{M} = \\frac{k_{m}}{\\gamma_{m}}$ and $E[M^{2}] = \\operatorname{Var}(M) + \\bar{M}^{2} = \\frac{k_{m}}{\\gamma_{m}} + \\frac{k_{m}^{2}}{\\gamma_{m}^{2}}$.\n- For the cross moment $E[MP]$, the steady-state equation is\n$$\n0 = k_{m} \\bar{P} + k_{p} E[M^{2}] - (\\gamma_{m} + \\gamma_{p}) E[MP],\n$$\nso\n$$\nE[MP] = \\frac{k_{m} \\mu + k_{p} E[M^{2}]}{\\gamma_{m} + \\gamma_{p}} = \\frac{k_{p}}{\\gamma_{m} + \\gamma_{p}} \\left( \\frac{k_{m}^{2}}{\\gamma_{m} \\gamma_{p}} + \\frac{k_{m}}{\\gamma_{m}} + \\frac{k_{m}^{2}}{\\gamma_{m}^{2}} \\right).\n$$\n- For $E[P^{2}]$, the steady-state equation gives\n$$\n0 = 2 k_{p} E[MP] + k_{p} \\bar{M} - 2 \\gamma_{p} E[P^{2}] + \\gamma_{p} \\mu,\n$$\nhence\n$$\nE[P^{2}] = \\frac{1}{2 \\gamma_{p}} \\left( 2 k_{p} E[MP] + k_{p} \\bar{M} + \\gamma_{p} \\mu \\right).\n$$\nSubstituting the expressions above and simplifying is facilitated by introducing the standard burst parameters\n$$\nb \\equiv \\frac{k_{p}}{\\gamma_{m}}, \\qquad f \\equiv \\frac{k_{m}}{\\gamma_{p}}, \\qquad r \\equiv \\frac{\\gamma_{p}}{\\gamma_{m}},\n$$\nso that $\\mu = \\bar{P} = b f$. One finds after algebraic simplification\n$$\nE[P^{2}] = b^{2} f^{2} + b f + \\frac{b^{2} f}{1 + r}.\n$$\nTherefore the variance of protein is\n$$\n\\operatorname{Var}(P) = E[P^{2}] - \\mu^{2} = \\mu + \\frac{b \\mu}{1 + r} = \\mu \\left( 1 + \\frac{b}{1 + r} \\right).\n$$\nEquivalently, the Fano factor is\n$$\n\\frac{\\operatorname{Var}(P)}{\\mu} = 1 + \\frac{b}{1 + r},\n$$\nand the squared coefficient of variation is\n$$\n\\operatorname{CV}^{2} = \\frac{\\operatorname{Var}(P)}{\\mu^{2}} = \\frac{1}{\\mu} \\left( 1 + \\frac{b}{1 + r} \\right).\n$$\nUnder the stated condition that protein is much more stable than mRNA, $\\gamma_{p} \\ll \\gamma_{m}$, so $r \\ll 1$ and\n$$\n\\frac{\\operatorname{Var}(P)}{\\mu} \\approx 1 + b, \\qquad \\operatorname{Var}(P) \\approx \\mu (1 + b).\n$$\nFor a fixed mean $\\mu = b f$, the variability increases monotonically with $b = \\frac{k_{p}}{\\gamma_{m}}$ and decreases with $f = \\frac{k_{m}}{\\gamma_{p}}$. Hence, to minimize variability at fixed mean, one should choose smaller $k_{p}$ and larger $k_{m}$, i.e., stronger promoter and weaker RBS.\n\nGiven $k_{m,A} > k_{m,B}$, $k_{p,A} < k_{p,B}$, and $k_{m,A} k_{p,A} = k_{m,B} k_{p,B}$, it follows that $b_{A} = \\frac{k_{p,A}}{\\gamma_{m}} < b_{B} = \\frac{k_{p,B}}{\\gamma_{m}}$ while $\\mu$ is the same for both constructs. Therefore Construct Alpha has lower cell-to-cell variability.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "A key goal of stochastic modeling is to connect the microscopic kinetics of molecular processes to the macroscopic, measurable distributions of molecules across a cell population. This practice  offers a masterclass in this fundamental skill by deriving one of the most important results in the study of gene expression: the Negative Binomial distribution for mRNA counts. Starting from first principles of bursty transcription and molecular degradation, you will use the powerful formalisms of the Chemical Master Equation and probability generating functions to rigorously demonstrate how these simple kinetic assumptions give rise to this characteristic statistical pattern.",
            "id": "3932900",
            "problem": "Consider a bursty transcription model for messenger ribonucleic acid (mRNA) production in a single cell under steady-state conditions. Bursts of transcription initiate as a homogeneous Poisson process with rate $k_{b}$ (bursts per unit time). Within a burst, transcripts are produced sequentially: each potential transcript production attempt occurs with rate $k_{s}$ and the burst terminates with rate $k_{t}$. Due to the memoryless property of exponential waiting times, the number of transcripts $B$ produced per burst is geometrically distributed on $\\{0,1,2,\\dots\\}$, determined by the competition between continuation and termination at each step. Each mRNA molecule degrades independently with first-order kinetics at rate $\\gamma$.\n\nStarting from first principles appropriate to stochastic chemical kinetics (including the Chemical Master Equation (CME) for a birth–death process with batch arrivals, the definition and properties of the homogeneous Poisson process, and the probability generating function for discrete random variables), derive the steady-state probability mass function for the mRNA count $N$ in this model. Express the distribution in closed form and identify its parameters explicitly in terms of the kinetic rates $k_{b}$, $k_{s}$, $k_{t}$, and $\\gamma$. Your final answer must be a single closed-form analytical expression for $P(N=n)$ as a function of $n$ and the kinetic rates. No numerical evaluation or rounding is required, and no units should be included in the final expression.",
            "solution": "We model an mRNA count process with two mechanisms: bursty synthesis and first-order degradation. Bursts arrive according to a homogeneous Poisson process with rate $k_{b}$, and each burst instantaneously increases the mRNA count by a random integer amount $B \\in \\{0,1,2,\\dots\\}$. Between bursts, each of the $n$ extant molecules degrades independently at rate $\\gamma$, yielding standard linear death dynamics.\n\nFirst, we characterize the burst size distribution. Within a burst, the system repeatedly faces a competition between two independent exponential events: produce the next transcript with rate $k_{s}$ versus terminate the burst with rate $k_{t}$. At each step, the probability of termination before another transcript is\n$$\np \\equiv \\frac{k_{t}}{k_{s} + k_{t}},\n$$\nand the probability of continuation (i.e., producing one more transcript and attempting again) is\n$$\n1 - p = \\frac{k_{s}}{k_{s} + k_{t}}.\n$$\nBecause each step is memoryless and identically distributed, the number of transcripts $B$ produced in a burst is geometric on $\\{0,1,2,\\dots\\}$ with parameter $p$, i.e.,\n$$\n\\Pr(B = m) = p \\,(1-p)^{m}, \\quad m = 0,1,2,\\dots,\n$$\nwith mean $\\mathbb{E}[B] = \\frac{1-p}{p} = \\frac{k_{s}}{k_{t}}$. The probability generating function (pgf) of $B$ is\n$$\nF_{B}(z) \\equiv \\mathbb{E}[z^{B}] = \\sum_{m=0}^{\\infty} p\\,(1-p)^{m} z^{m} = \\frac{p}{1 - (1-p) z}, \\quad |(1-p)z| < 1.\n$$\n\nNext, we write the Chemical Master Equation (CME) for the probability $P_{n}(t)$ of having $n$ mRNA molecules at time $t$. With first-order degradation at rate $\\gamma$ per molecule and burst arrivals at rate $k_{b}$ that add $m$ molecules distributed as above, the CME is\n$$\n\\frac{d}{dt} P_{n}(t) = \\gamma \\big[(n+1) P_{n+1}(t) - n P_{n}(t)\\big] + k_{b} \\left[\\sum_{m=0}^{n} \\Pr(B=m)\\, P_{n-m}(t) - P_{n}(t)\\right].\n$$\nDefine the pgf for $N(t)$ as $G(z,t) \\equiv \\sum_{n=0}^{\\infty} P_{n}(t) z^{n}$. Multiply the CME by $z^{n}$ and sum over $n \\geq 0$. Using standard identities for generating functions of linear death and batch immigration processes, we obtain\n$$\n\\frac{\\partial}{\\partial t} G(z,t) = \\gamma (1 - z)\\, \\frac{\\partial}{\\partial z} G(z,t) + k_{b} \\big( F_{B}(z) - 1 \\big) G(z,t).\n$$\nAt steady state, $\\frac{\\partial}{\\partial t} G(z,t) = 0$, so the stationary pgf $G(z)$ satisfies\n$$\n\\gamma (1 - z)\\, \\frac{d}{dz} G(z) + k_{b} \\big( F_{B}(z) - 1 \\big) G(z) = 0.\n$$\nSubstitute $F_{B}(z) = \\frac{p}{1 - (1-p)z}$ and rearrange:\n$$\n\\frac{d}{dz} \\ln G(z) = - \\frac{k_{b}}{\\gamma} \\frac{F_{B}(z) - 1}{1 - z} = - \\frac{k_{b}}{\\gamma} \\frac{\\frac{p}{1 - (1-p)z} - 1}{1 - z}.\n$$\nCompute the ratio explicitly:\n$$\n\\frac{F_{B}(z) - 1}{1 - z} = \\frac{\\frac{p}{1 - (1-p)z} - 1}{1 - z} = \\frac{p - \\big(1 - (1-p)z\\big)}{(1 - (1-p)z)(1 - z)} = \\frac{(1-p)(z - 1)}{(1 - (1-p)z)(1 - z)} = - \\frac{1 - p}{1 - (1-p) z}.\n$$\nThus,\n$$\n\\frac{d}{dz} \\ln G(z) = \\frac{k_{b}}{\\gamma} \\frac{1 - p}{1 - (1-p) z}.\n$$\nIntegrate from $z=1$ (where $G(1) = 1$ by normalization) to a general $z$:\n$$\n\\ln G(z) - \\ln G(1) = \\frac{k_{b}}{\\gamma} \\int_{1}^{z} \\frac{1 - p}{1 - (1-p) u}\\, du = \\frac{k_{b}}{\\gamma} \\Big[ - \\ln\\big(1 - (1-p) z\\big) + \\ln\\big(1 - (1-p)\\cdot 1\\big) \\Big].\n$$\nNote $1 - (1-p) = p$, hence\n$$\n\\ln G(z) = \\frac{k_{b}}{\\gamma} \\ln \\left( \\frac{p}{1 - (1-p) z} \\right),\n$$\nand therefore\n$$\nG(z) = \\left( \\frac{p}{1 - (1-p) z} \\right)^{\\frac{k_{b}}{\\gamma}}.\n$$\nThis is the pgf of a negative binomial distribution with shape parameter $r \\equiv \\frac{k_{b}}{\\gamma}$ and success parameter $p$. To extract the probability mass function, write\n$$\nG(z) = p^{r} \\big[ 1 - (1-p) z \\big]^{-r}.\n$$\nUsing the generalized binomial series $(1 - x)^{-r} = \\sum_{n=0}^{\\infty} \\frac{\\Gamma(n + r)}{\\Gamma(r)\\, n!} x^{n}$ for $|x| < 1$, the coefficient of $z^{n}$ yields\n$$\nP(N = n) = \\frac{\\Gamma(n + r)}{\\Gamma(r)\\, n!} (1 - p)^{n} p^{r}, \\quad n = 0,1,2,\\dots,\n$$\nwith $r = \\frac{k_{b}}{\\gamma}$ and $p = \\frac{k_{t}}{k_{s} + k_{t}}$ (hence $1 - p = \\frac{k_{s}}{k_{s} + k_{t}}$). This expresses the negative binomial steady-state mRNA count distribution entirely in terms of the kinetic rates $k_{b}$, $k_{s}$, $k_{t}$, and $\\gamma$.\n\nIn summary, the closed-form analytical expression is\n$$\nP(N = n) = \\frac{\\Gamma\\!\\left(n + \\frac{k_{b}}{\\gamma}\\right)}{\\Gamma\\!\\left(\\frac{k_{b}}{\\gamma}\\right)\\, n!} \\left( \\frac{k_{s}}{k_{s} + k_{t}} \\right)^{n} \\left( \\frac{k_{t}}{k_{s} + k_{t}} \\right)^{\\frac{k_{b}}{\\gamma}}.\n$$",
            "answer": "$$\\boxed{\\frac{\\Gamma\\!\\left(n + \\frac{k_{b}}{\\gamma}\\right)}{\\Gamma\\!\\left(\\frac{k_{b}}{\\gamma}\\right)\\, n!}\\left(\\frac{k_{s}}{k_{s}+k_{t}}\\right)^{n}\\left(\\frac{k_{t}}{k_{s}+k_{t}}\\right)^{\\frac{k_{b}}{\\gamma}}}$$"
        },
        {
            "introduction": "The true power of theoretical models is realized when they are confronted with experimental data. This final practice  bridges the gap between theory and application, placing you in the role of a quantitative cell biologist analyzing time-lapse microscopy data. Your task is to infer a key biophysical parameter—the stochasticity of protein partitioning during cell division—from lineage measurements. By implementing maximum likelihood estimation and constructing an exact confidence interval, you will engage in the essential work of using statistical inference to make quantitative, uncertainty-aware statements about biological processes.",
            "id": "3932921",
            "problem": "Consider a lineage-based stochastic gene expression model in which a single cell lineage is tracked through successive divisions. Let $X(t)$ denote the molecular copy number of a reporter protein in the tracked cell at time $t$. Between divisions, $X(t)$ evolves as a continuous-time birth-death process, representing synthesis and degradation, with synthesis rate $k_s$ and degradation rate $k_d$. At discrete division times $t = T_i$, the tracked cell divides into two daughters, and the pre-division molecular count in the mother cell is denoted by $N_i = X(T_i^{-})$. Immediately after division, one daughter is arbitrarily selected to continue the lineage. The molecules are partitioned into the tracked daughter according to independent Bernoulli trials: each of the $N_i$ molecules independently ends up in the tracked daughter with probability $r \\in (0,1)$, which we call the partitioning parameter. Consequently, the tracked daughter’s immediate post-division molecular count $Y_i = X(T_i^{+})$ is conditionally distributed given $N_i$ as a Binomial random variable.\n\nSuppose that time-lapse single-cell measurements provide, for each division event along the lineage, the pair $(N_i, Y_i)$ consisting of the pre-division molecular count and the immediate post-division molecular count in the tracked daughter. Assume that, conditional on $N_i$, the partitioning events across different divisions are independent and identically distributed with the same parameter $r$.\n\nTasks:\n1. Starting from the definition of independent Bernoulli trials at division, derive the likelihood of $r$ given the observed sequence $\\{(N_i, Y_i)\\}_{i=1}^m$, and from it obtain the maximum likelihood estimator of $r$ expressed as a function of the observed counts. Justify why the birth-death dynamics between divisions do not affect the conditional distribution of $Y_i$ given $N_i$ at the moment of division.\n2. Construct a two-sided confidence interval for $r$ at confidence level $1 - \\alpha$ with $\\alpha = 0.05$, using an exact method based on inverting the Binomial distribution without relying on normal approximations. Clearly specify how to handle boundary cases where the total number of successes equals $0$ or equals the total number of trials.\n\nYour program must implement these tasks for the following test suite. For each test case, you are given a list of pre-division counts $[N_1,\\dots,N_m]$ and a corresponding list of post-division tracked-daughter counts $[Y_1,\\dots,Y_m]$:\n\n- Test Case 1 (general case): $[104,87,96,110]$ and $[58,46,51,62]$.\n- Test Case 2 (near symmetry): $[50,50,50,50,50]$ and $[25,26,24,22,28]$.\n- Test Case 3 (asymmetric partitioning): $[60,55,70]$ and $[10,9,12]$.\n- Test Case 4 (boundary at zero): $[3,2,1]$ and $[0,0,0]$.\n- Test Case 5 (boundary at one): $[4,3,1,2]$ and $[4,3,1,2]$.\n- Test Case 6 (large counts): $[1000,1200,900,800]$ and $[550,660,495,440]$.\n\nFor each test case:\n- Compute the maximum likelihood estimate $\\hat r$.\n- Compute the lower and upper endpoints $(r_{\\text{L}}, r_{\\text{U}})$ of the two-sided exact confidence interval at confidence level $1 - \\alpha$ with $\\alpha = 0.05$.\n- Round each numeric result to six decimal places.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case’s result is the list $[\\hat r, r_{\\text{L}}, r_{\\text{U}}]$. For example, the output must look like $[[\\hat r_1, r_{\\text{L},1}, r_{\\text{U},1}],[\\hat r_2, r_{\\text{L},2}, r_{\\text{U},2}],\\dots]$ with no spaces.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded in standard models of stochastic gene expression, mathematically well-posed, objective, and contains all necessary information to derive a unique and meaningful solution.\n\nThe task is to perform statistical inference on the partitioning parameter $r$ in a lineage-based model of gene expression. This involves two parts: first, deriving the maximum likelihood estimator (MLE) for $r$, and second, constructing an exact confidence interval for $r$.\n\n**1. Maximum Likelihood Estimator (MLE) of the Partitioning Parameter $r$**\n\nThe problem states that at each division $i$, a mother cell with $N_i$ molecules partitions them into a tracked daughter cell such that each molecule is inherited independently with probability $r$. This is the definition of a sequence of $N_i$ Bernoulli trials, where \"success\" is a molecule ending up in the tracked daughter. The total number of successes, $Y_i$, therefore follows a Binomial distribution conditional on the number of trials, $N_i$. The probability mass function (PMF) is:\n$$P(Y_i = y_i | N_i = n_i, r) = \\binom{n_i}{y_i} r^{y_i} (1-r)^{n_i-y_i}$$\nwhere $\\binom{n_i}{y_i}$ is the binomial coefficient.\n\nWe are given a sequence of $m$ independent observations $\\{(N_i, Y_i)\\}_{i=1}^m$. The independence of partitioning events across different divisions allows us to write the total likelihood of the parameter $r$ given the observed data as the product of the individual conditional probabilities:\n$$L(r; \\{ (N_i, Y_i) \\}) = P(\\{Y_i\\} | \\{N_i\\}, r) = \\prod_{i=1}^{m} P(Y_i | N_i, r)$$\nSubstituting the Binomial PMF, we get:\n$$L(r) = \\prod_{i=1}^{m} \\binom{N_i}{Y_i} r^{Y_i} (1-r)^{N_i-Y_i}$$\nTo find the MLE, $\\hat{r}$, we maximize this likelihood function with respect to $r$. It is computationally simpler to maximize the log-likelihood function, $\\ell(r) = \\ln L(r)$, as the logarithm is a monotonic function.\n$$\\ell(r) = \\ln\\left( \\prod_{i=1}^{m} \\binom{N_i}{Y_i} r^{Y_i} (1-r)^{N_i-Y_i} \\right) = \\sum_{i=1}^{m} \\ln\\left( \\binom{N_i}{Y_i} r^{Y_i} (1-r)^{N_i-Y_i} \\right)$$\n$$\\ell(r) = \\sum_{i=1}^{m} \\left( \\ln\\binom{N_i}{Y_i} + Y_i \\ln r + (N_i - Y_i) \\ln(1-r) \\right)$$\nTo find the maximum, we compute the derivative of $\\ell(r)$ with respect to $r$ and set it to zero:\n$$\\frac{d\\ell(r)}{dr} = \\sum_{i=1}^{m} \\left( \\frac{Y_i}{r} - \\frac{N_i - Y_i}{1-r} \\right) = 0$$\n$$\\frac{1}{r} \\sum_{i=1}^{m} Y_i - \\frac{1}{1-r} \\sum_{i=1}^{m} (N_i - Y_i) = 0$$\nLet $Y_{\\text{tot}} = \\sum_{i=1}^{m} Y_i$ be the total number of molecules observed in the tracked daughters post-division, and $N_{\\text{tot}} = \\sum_{i=1}^{m} N_i$ be the total number of molecules in the mother cells pre-division. The equation becomes:\n$$\\frac{Y_{\\text{tot}}}{\\hat{r}} = \\frac{N_{\\text{tot}} - Y_{\\text{tot}}}{1-\\hat{r}}$$\nSolving for $\\hat{r}$:\n$$Y_{\\text{tot}}(1-\\hat{r}) = \\hat{r}(N_{\\text{tot}} - Y_{\\text{tot}})$$\n$$Y_{\\text{tot}} - Y_{\\text{tot}}\\hat{r} = N_{\\text{tot}}\\hat{r} - Y_{\\text{tot}}\\hat{r}$$\n$$Y_{\\text{tot}} = N_{\\text{tot}}\\hat{r}$$\nThus, the maximum likelihood estimator for $r$ is:\n$$\\hat{r} = \\frac{\\sum_{i=1}^{m} Y_i}{\\sum_{i=1}^{m} N_i} = \\frac{Y_{\\text{tot}}}{N_{\\text{tot}}}$$\nThis result is intuitive: the best estimate for the partitioning probability is the ratio of the total observed successes to the total number of trials.\n\nThe birth-death dynamics (synthesis rate $k_s$, degradation rate $k_d$) that govern the protein count $X(t)$ between divisions determine the probability distribution of $N_i$. However, the task is to find the MLE of $r$ based on the conditional probability $P(Y_i | N_i, r)$. By the definition of conditional probability, we are analyzing the system under the condition that the pre-division count is already known to be $N_i$. The stochastic process that led to this state is irrelevant for the subsequent, independent physical process of partitioning. The partitioning mechanism is defined to depend only on the number of molecules present at the moment of division, $N_i$, and the parameter $r$. Therefore, the inter-division dynamics do not influence the conditional likelihood of $r$ given the observed pairs $(N_i, Y_i)$.\n\n**2. Exact Two-Sided Confidence Interval for $r$**\n\nA key property of the Binomial distribution is its additivity for a fixed success probability. Since each $Y_i \\sim \\text{Binomial}(N_i, r)$ and the divisions are independent, their sum $Y_{\\text{tot}} = \\sum_{i=1}^m Y_i$ also follows a Binomial distribution with parameters equal to the sum of the number of trials and the same success probability:\n$$Y_{\\text{tot}} \\sim \\text{Binomial}(N_{\\text{tot}}, r)$$\nwhere $N_{\\text{tot}} = \\sum_{i=1}^m N_i$. The problem of finding a confidence interval for $r$ given the set of observations $\\{ (N_i, Y_i) \\}_{i=1}^m$ is therefore equivalent to finding the confidence interval for the success probability $r$ of a single Binomial experiment with $N_{\\text{tot}}$ trials and $Y_{\\text{tot}}$ observed successes.\n\nThe problem requires an exact method, which refers to the Clopper-Pearson interval. This method is based on inverting two one-sided hypothesis tests. For a given number of trials $n = N_{\\text{tot}}$ and successes $k = Y_{\\text{tot}}$, a $1-\\alpha$ confidence interval $[r_{\\text{L}}, r_{\\text{U}}]$ is constructed such that:\nThe lower bound $r_{\\text{L}}$ is the value of $r$ for which the probability of observing $k$ or more successes is $\\alpha/2$:\n$$P(X \\ge k | r = r_{\\text{L}}) = \\sum_{j=k}^{n} \\binom{n}{j} r_{\\text{L}}^j (1-r_{\\text{L}})^{n-j} = \\frac{\\alpha}{2}$$\nThe upper bound $r_{\\text{U}}$ is the value of $r$ for which the probability of observing $k$ or fewer successes is $\\alpha/2$:\n$$P(X \\le k | r = r_{\\text{U}}) = \\sum_{j=0}^{k} \\binom{n}{j} r_{\\text{U}}^j (1-r_{\\text{U}})^{n-j} = \\frac{\\alpha}{2}$$\nThese equations can be solved numerically. A direct relationship exists between the Binomial cumulative distribution function (CDF) and the regularized incomplete Beta function, which simplifies computation. The bounds are given by quantiles of the Beta distribution:\n$r_{\\text{L}}$ is the $\\alpha/2$ quantile of a Beta distribution with parameters $(k, n-k+1)$:\n$$r_{\\text{L}} = \\text{Beta}(\\alpha/2; k, n-k+1)$$\n$r_{\\text{U}}$ is the $1-\\alpha/2$ quantile of a Beta distribution with parameters $(k+1, n-k)$:\n$$r_{\\text{U}} = \\text{Beta}(1-\\alpha/2; k+1, n-k)$$\nwhere $\\text{Beta}(q; a, b)$ denotes the $q$-th quantile (inverse CDF) of the Beta distribution with shape parameters $a$ and $b$. The specified confidence level is $1-\\alpha = 0.95$, so $\\alpha=0.05$ and $\\alpha/2 = 0.025$.\n\nBoundary cases must be handled correctly:\n- If $k = 0$ (no successes, e.g., Test Case 4), the MLE is $\\hat{r}=0$. The lower bound is naturally $r_{\\text{L}} = 0$. The upper bound is found by solving $P(X \\le 0 | r=r_{\\text{U}}) = (1-r_{\\text{U}})^n = \\alpha/2$, which gives $r_{\\text{U}} = 1 - (\\alpha/2)^{1/n}$. This corresponds to $\\text{Beta}(1-\\alpha/2; 1, n)$.\n- If $k = n$ (all trials are successes, e.g., Test Case 5), the MLE is $\\hat{r}=1$. The upper bound is naturally $r_{\\text{U}} = 1$. The lower bound is found by solving $P(X \\ge n | r=r_{\\text{L}}) = r_{\\text{L}}^n = \\alpha/2$, which gives $r_{\\text{L}} = (\\alpha/2)^{1/n}$. This corresponds to $\\text{Beta}(\\alpha/2; n, 1)$.\n\nThe computational procedure for each test case is to first calculate $N_{\\text{tot}} = \\sum N_i$ and $Y_{\\text{tot}} = \\sum Y_i$, then compute $\\hat{r} = Y_{\\text{tot}}/N_{\\text{tot}}$, and finally compute $r_{\\text{L}}$ and $r_{\\text{U}}$ using the Beta distribution quantiles with $n = N_{\\text{tot}}$ and $k = Y_{\\text{tot}}$, respecting the boundary conditions.\n\n```python\nimport numpy as np\nfrom scipy.stats import beta\n\ndef solve():\n    \"\"\"\n    Solves the stochastic gene expression partitioning problem for multiple test cases.\n\n    For each case, it calculates the Maximum Likelihood Estimate (MLE) of the partitioning\n    parameter r and its 95% exact confidence interval (Clopper-Pearson).\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (general case)\n        {'N': [104, 87, 96, 110], 'Y': [58, 46, 51, 62]},\n        # Test Case 2 (near symmetry)\n        {'N': [50, 50, 50, 50, 50], 'Y': [25, 26, 24, 22, 28]},\n        # Test Case 3 (asymmetric partitioning)\n        {'N': [60, 55, 70], 'Y': [10, 9, 12]},\n        # Test Case 4 (boundary at zero)\n        {'N': [3, 2, 1], 'Y': [0, 0, 0]},\n        # Test Case 5 (boundary at one)\n        {'N': [4, 3, 1, 2], 'Y': [4, 3, 1, 2]},\n        # Test Case 6 (large counts)\n        {'N': [1000, 1200, 900, 800], 'Y': [550, 660, 495, 440]},\n    ]\n\n    results = []\n    alpha = 0.05\n\n    for case in test_cases:\n        N_list = case['N']\n        Y_list = case['Y']\n\n        # Calculate total pre-division and post-division counts\n        N_tot = np.sum(N_list)\n        Y_tot = np.sum(Y_list)\n\n        # Task 1: Calculate the Maximum Likelihood Estimator (MLE)\n        if N_tot == 0:\n            # Handle the undefined case, although not expected from test data\n            r_hat = np.nan\n        else:\n            r_hat = Y_tot / N_tot\n\n        # Task 2: Calculate the exact (Clopper-Pearson) confidence interval\n        n = N_tot\n        k = Y_tot\n        \n        r_L = 0.0\n        r_U = 1.0\n\n        if n > 0: # Proceed only if there are trials\n            # Lower bound\n            if k == 0:\n                r_L = 0.0\n            else:\n                # r_L is the alpha/2 quantile of Beta(k, n-k+1)\n                r_L = beta.ppf(alpha / 2, k, n - k + 1)\n            \n            # Upper bound\n            if k == n:\n                r_U = 1.0\n            else:\n                # r_U is the 1-alpha/2 quantile of Beta(k+1, n-k)\n                r_U = beta.ppf(1 - alpha / 2, k + 1, n - k)\n        else: # Case where N_tot is 0\n            r_L = np.nan\n            r_U = np.nan\n\n        # Format results to six decimal places\n        # Using f-string formatting ensures trailing zeros and rounding\n        formatted_r_hat = f\"{r_hat:.6f}\"\n        formatted_r_L = f\"{r_L:.6f}\"\n        formatted_r_U = f\"{r_U:.6f}\"\n\n        results.append(f\"[{formatted_r_hat},{formatted_r_L},{formatted_r_U}]\")\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```",
            "answer": "[[0.546600,0.495267,0.597380],[0.500000,0.438258,0.561742],[0.167568,0.117180,0.228962],[0.000000,0.000000,0.459303],[1.000000,0.691503,1.000000],[0.550000,0.534571,0.565355]]"
        }
    ]
}