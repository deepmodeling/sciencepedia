{
    "hands_on_practices": [
        {
            "introduction": "Understanding the inherent stochasticity of gene expression begins with mastering the analysis of its simplest representation: the birth-death process. While the full probability distribution described by the Chemical Master Equation (CME) is often intractable, we can extract crucial statistical information by analyzing its moments. This first exercise  guides you through the fundamental technique of deriving the steady-state mean and variance directly from the CME, providing a quantitative measure of the average protein level and the magnitude of its fluctuations.",
            "id": "1517880",
            "problem": "Consider a simplified model for the stochastic production and degradation of a single type of protein, denoted by $X$, within a cell. Molecules of $X$ are produced one at a time through a process that can be modeled with a constant probability rate. The probability of a single production event occurring in an infinitesimal time interval $dt$ is given by $k_1 dt$, where $k_1$ is the production rate constant. Simultaneously, each existing molecule of $X$ has a constant probability of degrading in the same time interval $dt$. This probability is given by $k_2 dt$ for each molecule, where $k_2$ is the degradation rate constant. Therefore, if there are $n$ molecules of $X$ present, the total probability of one degradation event occurring in the interval $dt$ is $n k_2 dt$.\n\nAfter a sufficiently long time, the system reaches a statistical steady state, where the probability distribution of the number of molecules, $P(n)$, no longer changes with time. For this steady-state distribution, determine the variance, defined as $\\text{Var}(n) = \\langle n^2 \\rangle - \\langle n \\rangle^2$.\n\nExpress your answer as a closed-form analytic expression in terms of the constants $k_1$ and $k_2$.",
            "solution": "We model the system as a birth-death process with constant birth rate $k_{1}$ and per-molecule death rate $k_{2}$. Let $n$ be the number of molecules. For any function $f(n)$, the chemical master equation implies the evolution of its expectation:\n$$\n\\frac{d\\langle f(n)\\rangle}{dt}=\\left\\langle k_{1}\\left[f(n+1)-f(n)\\right]+n k_{2}\\left[f(n-1)-f(n)\\right]\\right\\rangle.\n$$\n\nFirst, choose $f(n)=n$. Using $(n+1)-n=1$ and $(n-1)-n=-1$, we obtain\n$$\n\\frac{d\\langle n\\rangle}{dt}=\\left\\langle k_{1}\\cdot 1+n k_{2}\\cdot(-1)\\right\\rangle=k_{1}-k_{2}\\langle n\\rangle.\n$$\nAt steady state, $d\\langle n\\rangle/dt=0$, so\n$$\n\\langle n\\rangle=\\frac{k_{1}}{k_{2}}.\n$$\n\nNext, choose $f(n)=n^2$. Using $(n+1)^2-n^2=2n+1$ and $(n-1)^2-n^2=-2n+1$, we get\n$$\n\\frac{d\\langle n^2\\rangle}{dt}=\\left\\langle k_{1}(2n+1)+n k_{2}(-2n+1)\\right\\rangle=2k_{1}\\langle n\\rangle+k_{1}-2k_{2}\\langle n^2\\rangle+k_{2}\\langle n\\rangle.\n$$\nRearranging,\n$$\n\\frac{d\\langle n^2\\rangle}{dt}=-2k_{2}\\langle n^2\\rangle+(2k_{1}+k_{2})\\langle n\\rangle+k_{1}.\n$$\nAt steady state, $d\\langle n^2\\rangle/dt=0$, so\n$$\n\\langle n^2\\rangle=\\frac{(2k_{1}+k_{2})\\langle n\\rangle+k_{1}}{2k_{2}}.\n$$\nSubstituting $\\langle n\\rangle=k_{1}/k_{2}$ gives\n$$\n\\langle n^2\\rangle=\\frac{(2k_{1}+k_{2})\\frac{k_{1}}{k_{2}}+k_{1}}{2k_{2}}=\\frac{k_{1}^{2}}{k_{2}^{2}}+\\frac{k_{1}}{k_{2}}.\n$$\n\nTherefore, the variance is\n$$\n\\text{Var}(n)=\\langle n^2\\rangle-\\langle n\\rangle^2=\\left(\\frac{k_{1}^{2}}{k_{2}^{2}}+\\frac{k_{1}}{k_{2}}\\right)-\\left(\\frac{k_{1}}{k_{2}}\\right)^{2}=\\frac{k_{1}}{k_{2}}.\n$$",
            "answer": "$$\\boxed{\\frac{k_{1}}{k_{2}}}$$"
        },
        {
            "introduction": "While linear models provide a crucial foundation, many essential biological processes, such as protein dimerization or receptor-ligand binding, involve non-linear reaction kinetics. This non-linearity introduces significant mathematical challenges when moving from deterministic rate equations to the stochastic framework of the CME. This practice  explores the consequences of a simple dimerization reaction, where you will derive the time evolution for the first two moments and uncover the moment closure problem—a fundamental concept explaining why an exact, finite description of moment dynamics is often impossible for non-linear systems.",
            "id": "1471904",
            "problem": "Consider an irreversible dimerization reaction $2X \\to Y$ taking place in a well-mixed system of constant volume. The state of the system can be characterized by the number of molecules of species X, denoted by $n_X$. Due to the stochastic nature of chemical reactions at the molecular level, $n_X$ is a random variable. The probability per unit time of a single dimerization event occurring is given by the propensity function $a(n_X) = c \\frac{n_X(n_X-1)}{2}$, where $c$ is the stochastic rate constant. The time evolution of the probability distribution $P(n_X, t)$ is governed by the Chemical Master Equation.\n\nWe are interested in the statistical properties of the number of molecules of X. Let the mean number of molecules be $\\mu(t) = \\langle n_X \\rangle$, and define the $k$-th central moment as $\\mu_k(t) = \\langle (n_X - \\mu)^k \\rangle$. Note that the variance is $\\sigma^2 = \\mu_2$.\n\nDerive the system of ordinary differential equations for the time evolution of the mean, $\\frac{d\\mu}{dt}$, and the variance, $\\frac{d\\mu_2}{dt}$. Express your final answer in terms of the rate constant $c$, the mean $\\mu$, the variance $\\mu_2$, and the third central moment $\\mu_3$. Provide your two expressions as a row matrix, with the first entry being the expression for $\\frac{d\\mu}{dt}$ and the second being for $\\frac{d\\mu_2}{dt}$.",
            "solution": "Let $n \\equiv n_{X}$ and note that the single reaction $2X \\to Y$ changes $n$ by $v=-2$ when it fires. The propensity is $a(n)=c\\,\\frac{n(n-1)}{2}$. From the Chemical Master Equation (CME), for any function $f(n)$ the time evolution of its expectation is\n$$\n\\frac{d\\langle f(n)\\rangle}{dt}=\\left\\langle\\left[f(n+v)-f(n)\\right]a(n)\\right\\rangle.\n$$\nFor the mean, take $f(n)=n$. Then $f(n+v)-f(n)=(n-2)-n=-2$, so\n$$\n\\frac{d\\mu}{dt}=\\frac{d\\langle n\\rangle}{dt}=\\left\\langle(-2)\\,a(n)\\right\\rangle=-2\\left\\langle c\\,\\frac{n(n-1)}{2}\\right\\rangle=-c\\langle n(n-1)\\rangle.\n$$\nUsing $\\langle n(n-1)\\rangle=\\langle n^2\\rangle-\\langle n\\rangle=(\\mu_2+\\mu^2)-\\mu$, we obtain\n$$\n\\frac{d\\mu}{dt}=-c\\left(\\mu_2+\\mu^2-\\mu\\right).\n$$\n\nFor the variance $\\mu_2=\\langle(n-\\mu)^2\\rangle=\\langle n^2\\rangle-\\mu^2$, differentiate to get\n$$\n\\frac{d\\mu_2}{dt}=\\frac{d\\langle n^2\\rangle}{dt}-2\\mu\\frac{d\\mu}{dt}.\n$$\nCompute $d\\langle n^2\\rangle/dt$ by taking $f(n)=n^2$, so $f(n+v)-f(n)=(n-2)^2-n^2=-4n+4$, hence\n$$\n\\frac{d\\langle n^2\\rangle}{dt}=\\left\\langle(-4n+4)\\,a(n)\\right\\rangle=\\left\\langle(-4n+4)\\,c\\,\\frac{n(n-1)}{2}\\right\\rangle\n=c\\left\\langle(-2n+2)\\,n(n-1)\\right\\rangle.\n$$\nExpanding $(-2n+2)\\,n(n-1)=(-2n+2)(n^2-n)=-2n^3+4n^2-2n$ gives\n$$\n\\frac{d\\langle n^2\\rangle}{dt}=c\\left[-2\\langle n^3\\rangle+4\\langle n^2\\rangle-2\\langle n\\rangle\\right].\n$$\nExpress raw moments in terms of central moments: $\\langle n\\rangle=\\mu$, $\\langle n^2\\rangle=\\mu_2+\\mu^2$, and $\\langle n^3\\rangle=\\mu_3+3\\mu\\mu_2+\\mu^3$. Substituting yields\n$$\n\\frac{d\\langle n^2\\rangle}{dt}=c\\left[-2(\\mu_3+3\\mu\\mu_2+\\mu^3)+4(\\mu_2+\\mu^2)-2\\mu\\right].\n$$\nUsing the mean equation $\\frac{d\\mu}{dt}=-c(\\mu_2+\\mu^2-\\mu)$, we obtain\n$$\n\\frac{d\\mu_2}{dt}=c\\left[-2\\mu_3-6\\mu\\mu_2-2\\mu^3+4\\mu_2+4\\mu^2-2\\mu\\right]+2c\\mu(\\mu_2+\\mu^2-\\mu).\n$$\nCollecting like terms gives\n$$\n\\frac{d\\mu_2}{dt}=c\\left[-2\\mu_3-4\\mu\\mu_2+4\\mu_2+2\\mu^2-2\\mu\\right]\n=2c\\left[-\\mu_3-2\\mu\\mu_2+2\\mu_2+\\mu^2-\\mu\\right].\n$$\n\nTherefore, the required system expressed in terms of $c$, $\\mu$, $\\mu_2$, and $\\mu_3$ is\n$$\n\\frac{d\\mu}{dt}=-c\\left(\\mu_2+\\mu^2-\\mu\\right),\\qquad\n\\frac{d\\mu_2}{dt}=c\\left(-2\\mu_3-4\\mu\\mu_2+4\\mu_2+2\\mu^2-2\\mu\\right).\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}-c\\left(\\mu_2+\\mu^2-\\mu\\right) & c\\left(-2\\mu_3-4\\mu\\mu_2+4\\mu_2+2\\mu^2-2\\mu\\right)\\end{pmatrix}}$$"
        },
        {
            "introduction": "Analytical solutions to the CME, even for moments, are only feasible for the simplest systems. For realistic models in synthetic biology, we rely on computational methods to explore system dynamics. The Gillespie Stochastic Simulation Algorithm (SSA) provides an exact numerical method for simulating trajectories of a stochastic chemical system. This capstone exercise  bridges theory and practice by having you both derive the time-dependent analytical moments for the birth-death process and implement the Gillespie algorithm to verify your theoretical results against computational experiments, a core workflow in modern systems biology.",
            "id": "4392582",
            "problem": "Consider a single-species gene expression birth–death process modeled as a continuous-time, discrete-state Markov jump process under the Chemical Master Equation (CME). Let $X(t) \\in \\mathbb{N}_0$ denote the molecule copy number at time $t$. The system has two reaction channels: synthesis (birth) with constant propensity $a_1(n) = k_b$ modeled as the reaction $\\emptyset \\to X$, and degradation (death) with propensity $a_2(n) = k_d n$ modeled as the reaction $X \\to \\emptyset$. The initial copy number is $X(0) = x_0$. Time is measured in seconds, rates in $\\mathrm{s^{-1}}$, and copy numbers are unitless counts.\n\nStarting only from the CME and the definition of expectation and variance, you must:\n1. Implement Gillespie’s direct stochastic simulation algorithm for the above birth–death process to generate trajectories $X(t)$ until a fixed terminal time $T$.\n2. Simulate $M$ independent trajectories and record the ensemble molecule counts at time $T$, $\\{X_i(T)\\}_{i=1}^M$.\n3. Compute the empirical mean $\\hat{m}(T)$ and empirical variance $\\hat{v}(T)$ of $\\{X_i(T)\\}_{i=1}^M$.\n4. Independently derive, from the CME, closed-form expressions for the first and second moments at time $T$, namely the exact mean $m(T)$ and variance $v(T)$, for arbitrary nonnegative parameters $k_b$, $k_d$, $x_0$, and $T$.\n5. Verify consistency between simulation and CME-derived moments by checking whether both the absolute relative error in the mean and the absolute relative error in the variance are each less than or equal to a fixed tolerance $\\varepsilon$, that is, whether\n$$\n\\frac{\\lvert \\hat{m}(T) - m(T) \\rvert}{\\max(m(T), 10^{-12})} \\le \\varepsilon\n\\quad \\text{and} \\quad\n\\frac{\\lvert \\hat{v}(T) - v(T) \\rvert}{\\max(v(T), 10^{-12})} \\le \\varepsilon.\n$$\n\nUse Gillespie’s direct method with exact exponential waiting times and reaction-channel selection based on propensities. Use a fixed pseudorandom seed equal to $12345$ for reproducibility. Use $M = 6000$ trajectories per test case and $\\varepsilon = 0.05$.\n\nImplement your program to handle the following test suite of parameter sets, covering typical behavior and boundary cases. For each case, the synthesis rate is $k_b$ in $\\mathrm{s^{-1}}$, the degradation rate is $k_d$ in $\\mathrm{s^{-1}}$, the initial count is $x_0$ in molecules, and the terminal time is $T$ in seconds:\n- Case 1 (typical): $k_b = 5.0$, $k_d = 1.0$, $x_0 = 0$, $T = 3.0$.\n- Case 2 (no synthesis): $k_b = 0.0$, $k_d = 0.7$, $x_0 = 50$, $T = 1.5$.\n- Case 3 (slow degradation, long time): $k_b = 2.0$, $k_d = 0.1$, $x_0 = 0$, $T = 20.0$.\n- Case 4 (fast degradation, moderate synthesis): $k_b = 9.0$, $k_d = 3.0$, $x_0 = 0$, $T = 1.0$.\n- Case 5 (nonzero initial condition): $k_b = 4.0$, $k_d = 0.5$, $x_0 = 20$, $T = 2.0$.\n- Case 6 (no degradation): $k_b = 1.5$, $k_d = 0.0$, $x_0 = 3$, $T = 4.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is a boolean indicating whether the corresponding case passes the tolerance check for both moments, in the order listed above (for example, “[True,False,True,True,True,False]”).",
            "solution": "The problem requires the derivation of the time-dependent mean and variance for a single-species birth-death process from the Chemical Master Equation (CME), and the verification of these analytical results against stochastic simulations using Gillespie's direct method. The problem is well-posed, scientifically grounded, and provides all necessary parameters for a complete solution.\n\n### 1. Derivation of Exact Moments from the Chemical Master Equation\n\nThe system consists of two reactions for a species $X$ with copy number $n$:\n1.  Synthesis (birth): $\\emptyset \\xrightarrow{k_b} X$, with propensity $a_1(n) = k_b$.\n2.  Degradation (death): $X \\xrightarrow{k_d n} \\emptyset$, with propensity $a_2(n) = k_d n$.\n\nLet $P(n,t)$ be the probability that the system has $n$ molecules at time $t$. The CME, which governs the time evolution of $P(n,t)$, is:\n$$\n\\frac{dP(n,t)}{dt} = k_b P(n-1,t) + k_d(n+1)P(n+1,t) - (k_b + k_d n)P(n,t)\n$$\nfor $n \\ge 1$, with a special form for $n=0$: $\\frac{dP(0,t)}{dt} = k_d P(1,t) - k_b P(0,t)$. The general form holds for all $n \\in \\mathbb{N}_0$ if we define $P(-1, t)=0$.\n\n#### 1.1. Mean Molecule Number\n\nThe mean (or first moment) of the molecule count is defined as $m(t) = \\langle n \\rangle(t) = \\sum_{n=0}^{\\infty} n P(n,t)$. The time evolution of the mean is found by taking the time derivative and using the CME:\n$$\n\\frac{dm(t)}{dt} = \\sum_{n=0}^{\\infty} n \\frac{dP(n,t)}{dt}\n$$\nSubstituting the CME and evaluating the sum term by term:\n$$\n\\frac{dm(t)}{dt} = \\sum_{n=0}^{\\infty} n \\left[ k_b P(n-1,t) + k_d(n+1)P(n+1,t) - (k_b + k_d n)P(n,t) \\right]\n$$\n$$\n\\frac{dm(t)}{dt} = k_b \\sum_{n=1}^{\\infty} n P(n-1,t) + k_d \\sum_{n=0}^{\\infty} n(n+1)P(n+1,t) - k_b \\sum_{n=0}^{\\infty} n P(n,t) - k_d \\sum_{n=0}^{\\infty} n^2 P(n,t)\n$$\nBy re-indexing the sums (e.g., letting $j=n-1$ in the first sum), we get:\n$$\n\\frac{dm(t)}{dt} = k_b \\sum_{j=0}^{\\infty} (j+1) P(j,t) + k_d \\sum_{j=1}^{\\infty} (j-1)j P(j,t) - k_b \\langle n \\rangle - k_d \\langle n^2 \\rangle\n$$\n$$\n\\frac{dm(t)}{dt} = k_b (\\langle n \\rangle + 1) + k_d (\\langle n^2 \\rangle - \\langle n \\rangle) - k_b \\langle n \\rangle - k_d \\langle n^2 \\rangle\n$$\n$$\n\\frac{dm(t)}{dt} = k_b \\langle n \\rangle + k_b + k_d \\langle n^2 \\rangle - k_d \\langle n \\rangle - k_b \\langle n \\rangle - k_d \\langle n^2 \\rangle\n$$\nThis simplifies to a first-order linear ordinary differential equation (ODE) for the mean $m(t)$:\n$$\n\\frac{dm(t)}{dt} = k_b - k_d m(t)\n$$\nGiven the initial condition $m(0) = X(0) = x_0$, we can solve this ODE.\n- If $k_d > 0$: The solution is\n  $$\n  m(t) = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) e^{-k_d t}\n  $$\n- If $k_d = 0$: The ODE becomes $\\frac{dm(t)}{dt} = k_b$, which integrates to\n  $$\n  m(t) = x_0 + k_b t\n  $$\n\n#### 1.2. Variance of Molecule Number\n\nThe variance is $v(t) = \\langle n^2 \\rangle - \\langle n \\rangle^2$. We first derive an ODE for the variance. The time derivative of the variance is $\\frac{dv}{dt} = \\frac{d\\langle n^2 \\rangle}{dt} - 2\\langle n \\rangle \\frac{d\\langle n \\rangle}{dt}$.\nWe need the ODE for the second moment, $\\langle n^2 \\rangle = \\sum_{n=0}^{\\infty} n^2 P(n,t)$. Similarly to the mean, we find:\n$$\n\\frac{d\\langle n^2 \\rangle}{dt} = \\sum_{n=0}^{\\infty} n^2 \\frac{dP(n,t)}{dt} = (2k_b + k_d)m(t) + k_b - 2k_d \\langle n^2 \\rangle\n$$\nSubstituting this and the ODE for $m(t)$ into the expression for $\\frac{dv}{dt}$:\n$$\n\\frac{dv}{dt} = \\left[ (2k_b + k_d)m(t) + k_b - 2k_d \\langle n^2 \\rangle \\right] - 2m(t) (k_b - k_d m(t))\n$$\n$$\n\\frac{dv}{dt} = 2k_b m(t) + k_d m(t) + k_b - 2k_d \\langle n^2 \\rangle - 2k_b m(t) + 2k_d m(t)^2\n$$\n$$\n\\frac{dv}{dt} = k_b + k_d m(t) - 2k_d (\\langle n^2 \\rangle - m(t)^2)\n$$\nThis yields an ODE for the variance $v(t)$:\n$$\n\\frac{dv(t)}{dt} = k_b + k_d m(t) - 2k_d v(t)\n$$\nWith the initial condition $v(0)=0$ (since the initial state $x_0$ is deterministic), we can solve this ODE by substituting the solution for $m(t)$.\n- If $k_d > 0$:\n  $$\n  \\frac{dv}{dt} + 2k_d v = k_b + k_d \\left[ \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) e^{-k_d t} \\right] = 2k_b + (k_d x_0 - k_b) e^{-k_d t}\n  $$\n  Solving this linear first-order ODE with $v(0)=0$ gives:\n  $$\n  v(t) = \\frac{k_b}{k_d} + \\left(x_0 - \\frac{k_b}{k_d}\\right) e^{-k_d t} - x_0 e^{-2k_d t}\n  $$\n  This can be conveniently rewritten as:\n  $$\n  v(t) = \\frac{k_b}{k_d}(1 - e^{-k_d t}) + x_0 e^{-k_d t}(1 - e^{-k_d t})\n  $$\n- If $k_d = 0$: The ODE for variance becomes $\\frac{dv}{dt} = k_b$. With $v(0)=0$, this integrates to\n  $$\n  v(t) = k_b t\n  $$\n\n### 2. Stochastic Simulation and Verification\n\nGillespie's Stochastic Simulation Algorithm (SSA), specifically the direct method, is used to generate exact numerical realizations of the Markov process.\n\n#### 2.1. Algorithm\nFor a single trajectory starting with $n=x_0$ at $t=0$, until $t \\ge T$:\n1.  Calculate propensities: $a_1 = k_b$, $a_2 = k_d n$.\n2.  Calculate total propensity: $a_{tot} = a_1 + a_2$.\n3.  If $a_{tot} = 0$, the state is absorbing. The simulation time is advanced to $T$ and the trajectory ends.\n4.  Generate two random numbers $r_1, r_2$ from a uniform distribution $U(0,1)$.\n5.  Calculate the time to the next reaction: $\\tau = \\frac{1}{a_{tot}} \\ln(\\frac{1}{r_1})$.\n6.  If $t+\\tau \\ge T$, the trajectory ends; the state remains $n$.\n7.  Otherwise, advance time: $t \\leftarrow t + \\tau$.\n8.  Select the reaction: if $r_2 \\cdot a_{tot} < a_1$, it is a synthesis ($n \\leftarrow n+1$); otherwise, it is a degradation ($n \\leftarrow n-1$).\n9.  Repeat from Step 1.\n\n#### 2.2. Verification\nThis process is repeated for $M=6000$ independent trajectories for each parameter set, using a fixed pseudorandom number generator seed of $12345$ for reproducibility. The ensemble of final molecule counts $\\{X_i(T)\\}_{i=1}^M$ is collected.\n\nThe empirical mean $\\hat{m}(T)$ and empirical variance $\\hat{v}(T)$ are computed from this ensemble:\n$$\n\\hat{m}(T) = \\frac{1}{M}\\sum_{i=1}^{M} X_i(T) \\qquad \\hat{v}(T) = \\frac{1}{M}\\sum_{i=1}^{M} (X_i(T) - \\hat{m}(T))^2\n$$\nConsistency is checked by comparing these empirical moments to the analytical moments $m(T)$ and $v(T)$ derived above. The check passes if both the absolute relative error for the mean and for the variance are less than or equal to the tolerance $\\varepsilon=0.05$:\n$$\n\\frac{\\lvert \\hat{m}(T) - m(T) \\rvert}{\\max(m(T), 10^{-12})} \\le \\varepsilon\n\\quad \\text{and} \\quad\n\\frac{\\lvert \\hat{v}(T) - v(T) \\rvert}{\\max(v(T), 10^{-12})} \\le \\varepsilon\n$$\nThe value $10^{-12}$ is used as a floor for the denominator to prevent division by zero or near-zero values.\n\nThe implementation will apply these steps to each test case, producing a boolean result indicating whether the consistency check passed.",
            "answer": "[True,True,True,True,True,True]"
        }
    ]
}