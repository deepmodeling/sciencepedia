{
    "hands_on_practices": [
        {
            "introduction": "Before we can analyze the performance of a homeostatic system, we must first be confident that it possesses a stable set-point to begin with. This exercise  delves into a canonical model of negative autoregulation, where a protein represses its own production, to explore this fundamental question. By analyzing the system's nonlinear dynamics using a nullcline approach, you will prove that this architecture inherently leads to a single, stable steady state, providing a robust basis for homeostasis.",
            "id": "3923020",
            "problem": "Consider a single-gene autoregulatory module in a synthetic biological circuit in which the protein concentration $x(t)$ negatively feeds back on its own transcription through a cooperative Hill-type repression. Assume well-mixed conditions and deterministic dynamics. The mass balance for $x(t)$ is modeled by the ordinary differential equation\n$$\n\\frac{dx}{dt} \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} \\;-\\; \\delta x,\n$$\nwhere $\\alpha  0$ is the maximal synthesis rate, $K  0$ is the repression threshold (often called the dissociation constant), $n \\geq 1$ is the Hill coefficient representing cooperativity in repression, and $\\delta  0$ is the first-order loss rate due to dilution and degradation. The Hill repression function is widely used to model cooperative binding and is a decreasing function of $x$ for $n \\geq 1$.\n\nUsing the nullcline condition $\\frac{dx}{dt} = 0$ and a slope-based argument grounded in mass balance and monotonicity properties of the Hill function and first-order loss, determine whether this system can exhibit multistability (more than one stable steady state) or only monostable homeostasis (exactly one stable steady state). In particular, analyze the number of intersections of the production curve\n$$\np(x) \\;=\\; \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}}\n$$\nwith the loss curve\n$$\n\\ell(x) \\;=\\; \\delta x,\n$$\nby examining the sign of the derivative of the difference $f(x) = p(x) - \\ell(x)$ over $x \\geq 0$. Your analysis must begin from the stated model and fundamental properties (mass balance, monotonicity of Hill repression, and linear loss) without invoking any ad hoc shortcut formulas.\n\nReport your final answer as the maximum possible number of distinct steady states $N_{\\mathrm{ss}}$ that the model admits over all positive parameter values $\\alpha$, $K$, $n \\geq 1$, and $\\delta$ (i.e., the supremum over parameter space of the number of solutions to $p(x) = \\ell(x)$ with $x \\geq 0$). No rounding is required. Express your final answer as a single number without units.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It represents a canonical model in synthetic biology for analyzing homeostasis under negative autoregulation. All parameters and conditions are clearly defined, allowing for a rigorous mathematical analysis. The problem is therefore valid.\n\nThe steady states of the system, denoted by $x^*$, are the non-negative concentrations $x$ for which the rate of change is zero. This is the nullcline condition, $\\frac{dx}{dt} = 0$. From the given ordinary differential equation, this condition is:\n$$\n\\frac{\\alpha}{1 + \\left(\\frac{x^*}{K}\\right)^{n}} - \\delta x^* = 0\n$$\nThis equation can be rewritten as an equality between the production rate and the loss rate:\n$$\np(x^*) = \\ell(x^*)\n$$\nwhere the production curve is $p(x) = \\frac{\\alpha}{1 + (x/K)^n}$ and the loss curve is $\\ell(x) = \\delta x$. The number of distinct steady states, $N_{\\mathrm{ss}}$, is the number of non-negative solutions to this equation.\n\nTo determine the number of solutions, we follow the prescribed method of analyzing the function $f(x) = p(x) - \\ell(x)$ for $x \\geq 0$. The steady states are the roots of the equation $f(x) = 0$.\n$$\nf(x) = \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} - \\delta x\n$$\nWe analyze the properties of $f(x)$ over its physical domain, $x \\geq 0$.\n\nFirst, we evaluate $f(x)$ at the boundary $x=0$:\n$$\nf(0) = \\frac{\\alpha}{1 + \\left(\\frac{0}{K}\\right)^{n}} - \\delta(0) = \\frac{\\alpha}{1} - 0 = \\alpha\n$$\nGiven that the maximal synthesis rate $\\alpha  0$, we have $f(0)  0$.\n\nNext, we examine the asymptotic behavior of $f(x)$ as $x \\to \\infty$:\n$$\n\\lim_{x\\to\\infty} f(x) = \\lim_{x\\to\\infty} \\left( \\frac{\\alpha}{1 + \\left(\\frac{x}{K}\\right)^{n}} - \\delta x \\right)\n$$\nAs $x \\to \\infty$, the term $(x/K)^n \\to \\infty$ since $K0$ and $n \\geq 1$. Consequently, the denominator of the first term $1 + (x/K)^n \\to \\infty$, causing the fraction to approach $0$. The second term, $-\\delta x$, approaches $-\\infty$ since the loss rate $\\delta  0$.\n$$\n\\lim_{x\\to\\infty} f(x) = 0 - \\infty = -\\infty\n$$\nSince $f(x)$ is a continuous function for $x \\geq 0$, and it transitions from a positive value $f(0) = \\alpha$ to negative infinity, the Intermediate Value Theorem guarantees the existence of at least one root $x^*  0$ such that $f(x^*) = 0$.\n\nTo determine the uniqueness of this root, we analyze the monotonicity of $f(x)$ by computing its derivative, $f'(x)$. A strictly monotonic function can cross the axis at most once.\n$$\nf'(x) = \\frac{d}{dx}f(x) = \\frac{d}{dx} \\left( p(x) - \\ell(x) \\right) = p'(x) - \\ell'(x)\n$$\nThe derivative of the loss curve $\\ell(x) = \\delta x$ is a constant:\n$$\n\\ell'(x) = \\delta\n$$\nThe derivative of the production curve $p(x) = \\alpha \\left(1 + K^{-n}x^n\\right)^{-1}$ is found using the chain rule:\n$$\np'(x) = \\alpha (-1) \\left(1 + K^{-n}x^n\\right)^{-2} \\cdot \\frac{d}{dx}\\left(1 + K^{-n}x^n\\right)\n$$\n$$\np'(x) = -\\alpha \\left(1 + \\left(\\frac{x}{K}\\right)^n\\right)^{-2} \\cdot \\left(n K^{-n} x^{n-1}\\right)\n$$\n$$\np'(x) = - \\frac{\\alpha n K^{-n} x^{n-1}}{\\left(1 + (x/K)^n\\right)^2} = - \\frac{\\alpha n x^{n-1}}{K^n \\left(1 + (x/K)^n\\right)^2}\n$$\nThe parameters are given as $\\alpha  0$, $K  0$, and $n \\geq 1$. For any $x  0$, all terms in the expression for $p'(x)$ are positive, hence $p'(x)$ is strictly negative. For $x=0$, if $n1$, $p'(0)=0$; if $n=1$, $p'(0) = -\\alpha/K  0$. In all cases for $x \\geq 0$, the derivative of the production function is non-positive, $p'(x) \\leq 0$. This is a direct consequence of the negative feedback (repression), where an increase in $x$ leads to a decrease in its own production.\n\nNow we assemble the derivative of $f(x)$:\n$$\nf'(x) = p'(x) - \\delta\n$$\nWe have established that $p'(x) \\leq 0$ for all $x \\geq 0$. We are also given that $\\delta  0$. Therefore, $f'(x)$ is the sum of a non-positive term and a strictly negative term:\n$$\nf'(x) = (\\text{non-positive value}) - (\\text{positive value})  0\n$$\nThus, $f'(x)$ is strictly negative for all $x \\geq 0$. This proves that $f(x)$ is a strictly monotonically decreasing function over its entire domain.\n\nIn summary:\n1. $f(x)$ is continuous for $x \\geq 0$.\n2. $f(0)  0$.\n3. $\\lim_{x\\to\\infty} f(x) = -\\infty$.\n4. $f(x)$ is strictly monotonically decreasing for all $x \\geq 0$.\n\nA continuous, strictly decreasing function that starts from a positive value and tends to negative infinity must cross the horizontal axis exactly once. This means there is a unique solution $x^*  0$ to the equation $f(x) = 0$.\n\nThis conclusion holds for all valid parameter values ($\\alpha0, K0, n\\geq1, \\delta0$). Therefore, the system can only exhibit monostable homeostasis; it always possesses exactly one steady state. The maximum possible number of distinct steady states, $N_{\\mathrm{ss}}$, is $1$. The inability to exhibit multistability is a hallmark of this canonical negative feedback architecture, as the monotonically decreasing production function can only intersect the monotonically increasing linear loss function at a single point.",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "Once we establish that a system is stable, the next critical question is about its dynamic performance: how quickly and smoothly does it return to its set-point after a perturbation? This practice  transitions to a linearized framework, where the powerful tools of control theory can be applied. You will learn to define and derive key performance metrics such as settling time and overshoot, and connect them directly to the system's pole locations, gaining intuition for how mathematical structure dictates the observable dynamic behavior of a gene circuit.",
            "id": "3923022",
            "problem": "A transcriptional negative feedback controller is implemented to maintain a protein concentration, denoted by $x(t)$, at a homeostatic set-point in the face of a step change in desired expression level (the set-point), denoted by $r(t)$. Linearization of the closed-loop dynamics around the homeostatic steady state yields a stable linear time-invariant system with output $y(t) = x(t)$ and input $r(t)$, with a rational transfer function whose poles $\\{p_i\\}$ determine the step response shape.\n\nConsider a unit step in the set-point, $r(t) = u(t)$, and assume the closed-loop system has unity steady-state gain, so that $y(\\infty) = 1$. You may take as a model for the dominant closed-loop dynamics either a real dominant pole or a complex-conjugate dominant pole pair. Use only fundamental principles of linear time-invariant system theory, ordinary differential equations, and the Central Dogma of molecular biology (transcription and translation yielding protein dynamics that can be linearized near a steady state).\n\n1. Provide precise definitions for the following standard step-response metrics in biochemical homeostasis:\n   - Settling time $T_{s}(\\varepsilon)$ for a given error band fraction $\\varepsilon \\in (0,1)$, as the smallest time after which $|y(t) - y(\\infty)| \\leq \\varepsilon$ for all subsequent time.\n   - Overshoot $M_{p}$, as the maximum positive deviation of $y(t)$ above $y(\\infty)$ normalized by the steady-state change.\n   - Rise time $T_{r}(\\alpha,\\beta)$ for given fractions $0  \\alpha  \\beta  1$, as the time it takes for $y(t)$ to increase from $\\alpha$ to $\\beta$ of its total change.\n   - Error band $\\pm \\varepsilon$, as the closed interval about $y(\\infty)$ to which the trajectory must converge and remain thereafter.\n\n2. Starting from the linear ordinary differential equation for a second-order underdamped system with natural frequency $\\omega_{n}  0$ and damping ratio $\\zeta \\in (0,1)$, and using the homogeneous solution structure determined by the poles $p_{1,2} = -\\zeta \\omega_{n} \\pm \\mathrm{i}\\,\\omega_{n}\\sqrt{1-\\zeta^{2}}$, derive how the settling time, overshoot, and rise time depend on the pole locations. Your derivation should:\n   - Connect the real parts of the poles to exponential decay rates governing settling behavior.\n   - Connect the imaginary parts of complex poles to oscillation frequency and overshoot.\n   - Justify the form of the rise time dependence on the pole locations by solving for threshold-crossing times $y(t)=\\alpha$ and $y(t)=\\beta$.\n   - Explain how an additional faster real pole $p_{3}$ with $\\Re(p_{3}) \\ll \\Re(p_{1,2})$ affects the metrics and under what conditions it can be neglected (dominance of the slowest mode).\n\n3. Under the assumption that the underdamped complex-conjugate pole pair is dominant and the closed-loop has unity steady-state gain, derive an exact, closed-form expression for the settling time $T_{s}(\\varepsilon,\\zeta,\\omega_{n})$ that guarantees $|y(t)-1| \\leq \\varepsilon$ for all $t \\geq T_{s}$ by using a rigorous envelope bound on the transient component of the unit-step response. Express your final result in symbolic form as a function of $\\varepsilon$, $\\zeta$, and $\\omega_{n}$ only. Do not substitute numerical values, do not round, and do not include physical units in your final expression.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is based on established principles of linear control theory applied to the standard practice of modeling biochemical networks. All necessary information is provided, and the task is a clear, formal derivation. We may proceed with the solution.\n\nThe problem asks for definitions of performance metrics, an analysis of how these metrics relate to system poles, and the derivation of a specific expression for settling time for a second-order underdamped system.\n\n**Part 1: Definitions of Step-Response Metrics**\n\nThe problem considers a system with output $y(t)$ responding to a unit step input such that the final steady-state value is $y(\\infty)=1$. We assume the initial condition is $y(0)=0$.\n\n- **Error band $\\pm \\varepsilon$**: The error band is the symmetric closed interval $[y(\\infty) - \\varepsilon, y(\\infty) + \\varepsilon]$ around the final steady-state value $y(\\infty)$. For a unit step response where $y(\\infty)=1$, this interval is $[1 - \\varepsilon, 1 + \\varepsilon]$. The system response $y(t)$ is said to have settled once it enters this band and remains within it for all subsequent time.\n\n- **Settling time $T_{s}(\\varepsilon)$**: The settling time for a given error band fraction $\\varepsilon \\in (0,1)$ is the minimum time $T_s$ such that the response $y(t)$ remains within the error band for all $t \\ge T_s$. Formally, it is defined as:\n$$T_{s}(\\varepsilon) = \\min \\{ t_0 \\ge 0 \\mid |y(t) - y(\\infty)| \\le \\varepsilon y(\\infty) \\text{ for all } t \\ge t_0 \\}$$\nGiven $y(\\infty)=1$, this simplifies to:\n$$T_{s}(\\varepsilon) = \\min \\{ t_0 \\ge 0 \\mid |y(t) - 1| \\le \\varepsilon \\text{ for all } t \\ge t_0 \\}$$\n\n- **Overshoot $M_{p}$**: The overshoot is the maximum fractional amount by which the response exceeds its final value, expressed as a ratio of the peak deviation to the total steady-state change. Let $y_{\\max} = \\max_{t \\ge 0} y(t)$. The overshoot is:\n$$M_{p} = \\frac{y_{\\max} - y(\\infty)}{y(\\infty) - y(0)}$$\nFor a unit step response with $y(0)=0$ and $y(\\infty)=1$, this simplifies to:\n$$M_{p} = y_{\\max} - 1$$\nIf $y(t)$ never exceeds $y(\\infty)$, the overshoot is $M_p=0$.\n\n- **Rise time $T_{r}(\\alpha,\\beta)$**: The rise time for given fractions $0  \\alpha  \\beta  1$ is the duration required for the response to rise from a fraction $\\alpha$ to a fraction $\\beta$ of its total change. Let $t_{\\alpha}$ be the first time at which $y(t_{\\alpha}) = \\alpha y(\\infty)$ and $t_{\\beta}$ be the first time at which $y(t_{\\beta}) = \\beta y(\\infty)$. The rise time is:\n$$T_{r}(\\alpha, \\beta) = t_{\\beta} - t_{\\alpha}$$\nCommon choices for $(\\alpha, \\beta)$ are $(0.1, 0.9)$ or $(0.05, 0.95)$.\n\n**Part 2: Dependence of Metrics on Pole Locations**\n\nWe consider a standard second-order underdamped system with unity DC gain, described by the transfer function:\n$$H(s) = \\frac{\\omega_{n}^{2}}{s^{2} + 2\\zeta\\omega_{n}s + \\omega_{n}^{2}}$$\nwhere $\\omega_n  0$ is the natural frequency and $\\zeta \\in (0,1)$ is the damping ratio. The poles are a complex-conjugate pair $p_{1,2} = -\\zeta\\omega_{n} \\pm \\mathrm{i}\\,\\omega_{n}\\sqrt{1-\\zeta^{2}}$. We define the decay rate $\\sigma = \\zeta\\omega_{n}$ and the damped (or oscillation) frequency $\\omega_d = \\omega_{n}\\sqrt{1-\\zeta^{2}}$. The poles are thus $p_{1,2} = -\\sigma \\pm \\mathrm{i}\\,\\omega_d$. Note that $\\sigma = -\\Re(p_{1,2})$ and $\\omega_d = |\\Im(p_{1,2})|$.\n\nThe unit step response is the inverse Laplace transform of $Y(s) = H(s)/s$:\n$$y(t) = 1 - \\frac{\\exp(-\\sigma t)}{\\sqrt{1-\\zeta^{2}}} \\sin(\\omega_d t + \\phi)$$\nwhere $\\phi = \\arccos(\\zeta)$.\n\n- **Settling Time and the Real Part of the Poles**: The transient part of the response, $y(t) - 1$, is modulated by the exponential term $\\exp(-\\sigma t) = \\exp(-\\zeta\\omega_{n}t) = \\exp(\\Re(p_{1,2}) t)$. The envelope of the transient response decays as $\\exp(-\\sigma t)$. The settling time $T_s$ is the time it takes for this envelope to shrink to the specified error $\\varepsilon$. Therefore, $T_s$ is inversely proportional to the decay rate $\\sigma$. A larger decay rate (i.e., poles with a more negative real part) leads to a faster decay of transients and a shorter settling time. Specifically, $T_s \\approx \\frac{1}{\\sigma} \\ln(\\text{const.}/\\varepsilon)$. The settling behavior is fundamentally governed by the real part of the dominant poles.\n\n- **Overshoot, Oscillation, and the Imaginary Part of the Poles**: The oscillatory part of the response is $\\sin(\\omega_d t + \\phi)$, with frequency $\\omega_d = |\\Im(p_{1,2})|$. This oscillation is what causes the response to overshoot the setpoint. The time to the first peak, $t_p$, where the maximum overshoot occurs, is found by setting $y'(t)=0$. This occurs when $\\omega_d t_p = \\pi$, so $t_p = \\pi/\\omega_d$. Substituting $t_p$ into the expression for $y(t)$ yields the peak value $y(t_p) = 1 + \\exp(-\\sigma \\pi / \\omega_d)$. The overshoot $M_p$ is then:\n$$M_p = \\exp\\left(-\\frac{\\sigma \\pi}{\\omega_d}\\right) = \\exp\\left(-\\frac{\\zeta\\omega_n \\pi}{\\omega_n\\sqrt{1-\\zeta^2}}\\right) = \\exp\\left(-\\frac{\\pi\\zeta}{\\sqrt{1-\\zeta^2}}\\right)$$\nThis shows that $M_p$ depends only on the damping ratio $\\zeta$. Geometrically, $\\zeta = \\cos(\\theta)$, where $\\theta$ is the angle of the pole vector from the negative real axis. Thus, overshoot is determined by the angle of the poles, while the frequency of these oscillations is determined by the imaginary part of the poles.\n\n- **Rise Time and Pole Locations**: The rise time $T_r$ is found by solving for the times $t_\\alpha$ and $t_\\beta$ where $y(t)$ crosses the thresholds $\\alpha$ and $\\beta$. For example, solving $y(t_\\alpha)=\\alpha$ gives:\n$$\\alpha = 1 - \\frac{\\exp(-\\sigma t_\\alpha)}{\\sqrt{1-\\zeta^{2}}} \\sin(\\omega_d t_\\alpha + \\phi)$$\nThis is a transcendental equation for $t_\\alpha$ and has no general closed-form solution. However, we can analyze the scaling properties. The entire time evolution of the response scales with $\\omega_n$. If we define a normalized time $\\tau = \\omega_n t$, the response becomes a function of $\\tau$ and $\\zeta$ only. Thus, all time-based metrics, including rise time, are inversely proportional to $\\omega_n$: $T_r \\propto 1/\\omega_n$. A larger natural frequency (moving poles further from the origin radially for a fixed $\\zeta$) leads to a faster response and shorter rise time. The dependence on $\\zeta$ is more complex as it affects both the exponential decay and the argument of the sine function.\n\n- **Effect of an Additional Faster Pole**: Let there be an additional real pole $p_3$ such that $\\Re(p_3) \\ll \\Re(p_{1,2})$, meaning $|p_3| \\gg \\sigma = \\zeta\\omega_n$. The system's response will contain an additional transient term of the form $C\\exp(p_3 t)$. Because $|p_3|$ is large, this term decays much more rapidly than the transients from the dominant complex pair. This pole can be neglected (i.e., the second-order approximation is valid) if its transient term becomes negligible before the dominant dynamics have significantly evolved. This condition is met when $|p_3| \\gg \\sigma$. While this fast pole does not significantly affect overshoot or settling time (which are determined by later parts of the response), it can slightly increase the rise time. A system with a third pole has a transfer function with relative degree 3, meaning $y(0)=y'(0)=y''(0)=0$, leading to a slower initial takeoff compared to the pure second-order system where $y'(0)=0$ but $y''(0)=\\omega_n^2  0$.\n\n**Part 3: Derivation of Settling Time $T_s(\\varepsilon,\\zeta,\\omega_{n})$**\n\nWe seek a closed-form expression for the settling time $T_s$ that guarantees $|y(t) - 1| \\le \\varepsilon$ for all $t \\ge T_s$. This guarantee is achieved by analyzing the envelope of the transient response.\nThe unit-step response is:\n$$y(t) = 1 - \\frac{\\exp(-\\zeta\\omega_{n}t)}{\\sqrt{1-\\zeta^{2}}} \\sin(\\omega_{n}\\sqrt{1-\\zeta^{2}} t + \\arccos \\zeta)$$\nThe deviation from the final value is:\n$$y(t) - 1 = - \\frac{\\exp(-\\zeta\\omega_{n}t)}{\\sqrt{1-\\zeta^{2}}} \\sin(\\omega_{n}\\sqrt{1-\\zeta^{2}} t + \\arccos \\zeta)$$\nWe require $|y(t) - 1| \\le \\varepsilon$. Taking the absolute value:\n$$|y(t) - 1| = \\left| - \\frac{\\exp(-\\zeta\\omega_{n}t)}{\\sqrt{1-\\zeta^{2}}} \\sin(\\omega_{n}\\sqrt{1-\\zeta^{2}} t + \\arccos \\zeta) \\right| = \\frac{\\exp(-\\zeta\\omega_{n}t)}{\\sqrt{1-\\zeta^{2}}} |\\sin(\\omega_d t + \\phi)|$$\nSince $|\\sin(\\cdot)| \\le 1$, we can establish a rigorous upper bound on the deviation:\n$$|y(t) - 1| \\le \\frac{\\exp(-\\zeta\\omega_{n}t)}{\\sqrt{1-\\zeta^{2}}}$$\nThis expression on the right is the decay envelope of the transient. To guarantee that $|y(t) - 1| \\le \\varepsilon$, it is sufficient to require that the envelope itself be less than or equal to $\\varepsilon$. The settling time $T_s$ is the time at which the envelope enters and remains within the $\\varepsilon$ boundary. We find this time by setting the envelope expression equal to $\\varepsilon$:\n$$\\frac{\\exp(-\\zeta\\omega_{n}T_s)}{\\sqrt{1-\\zeta^{2}}} = \\varepsilon$$\nNow, we solve for $T_s$. First, isolate the exponential term:\n$$\\exp(-\\zeta\\omega_{n}T_s) = \\varepsilon\\sqrt{1-\\zeta^{2}}$$\nTake the natural logarithm of both sides:\n$$-\\zeta\\omega_{n}T_s = \\ln\\left(\\varepsilon\\sqrt{1-\\zeta^{2}}\\right)$$\nFinally, solve for $T_s$:\n$$T_s = -\\frac{1}{\\zeta\\omega_{n}}\\ln\\left(\\varepsilon\\sqrt{1-\\zeta^{2}}\\right)$$\nUsing the property $\\ln(1/x) = -\\ln(x)$, we can write this in a more intuitive form:\n$$T_s = \\frac{1}{\\zeta\\omega_{n}}\\ln\\left(\\frac{1}{\\varepsilon\\sqrt{1-\\zeta^{2}}}\\right)$$\nThis is the desired closed-form expression for the settling time based on the decay envelope, expressed as a function of $\\varepsilon$, $\\zeta$, and $\\omega_n$. It represents a conservative but guaranteed time after which the system response will remain within the $\\pm\\varepsilon$ error band around the setpoint.",
            "answer": "$$\\boxed{\\frac{1}{\\zeta\\omega_{n}}\\ln\\left(\\frac{1}{\\varepsilon\\sqrt{1-\\zeta^{2}}}\\right)}$$"
        },
        {
            "introduction": "While negative feedback is the cornerstone of homeostasis, a universal challenge in biological systems is the presence of time delays in regulatory pathways. This exercise  examines how such delays can destabilize an otherwise stable system, potentially leading to unwanted oscillations. Using frequency-domain analysis and the Nyquist stability criterion, you will determine the maximum feedback gain a system with a time delay can tolerate, revealing a fundamental trade-off between the strength of regulation and the risk of instability.",
            "id": "3923012",
            "problem": "A synthetic gene circuit implements homeostasis via integral negative feedback, such as in antithetic integral feedback (AIF), which robustly drives an output concentration to a set-point by integrating the error over time. Consider the linear time-invariant (LTI) approximation of the circuit near the homeostatic set-point, where the controlled molecular concentration is $x(t)$ and the actuator command is $u(t)$. To capture the core homeostatic integral action with transcriptional-translational delay, the closed-loop dynamics are modeled as a retarded delay differential equation (DDE):\n$$\n\\frac{d x(t)}{d t} = u(t), \\quad u(t) = -k\\,x(t-\\tau),\n$$\nwhere $k0$ is the loop gain and $\\tau0$ is the total feedback delay arising from sensing, transcription, translation, and processing. Assume unity negative feedback around the loop, no open-loop unstable poles, and that the linearization is valid in the neighborhood of the operating point.\n\nUsing the Nyquist stability criterion starting from first principles of frequency-domain analysis of LTI systems and the definition of the Laplace transform, determine the maximum permissible loop gain $k_{\\max}$ as an explicit function of the delay $\\tau$ such that the closed-loop system remains stable. Your final answer must be a single symbolic expression in terms of $\\tau$. No numerical rounding is required. Express the final answer without units.",
            "solution": "The objective is to determine the maximum permissible loop gain $k_{\\max}$ for the given closed-loop system to remain stable. The system is described by the linear time-invariant (LTI) retarded delay differential equation (DDE):\n$$\n\\frac{d x(t)}{d t} = u(t), \\quad u(t) = -k\\,x(t-\\tau)\n$$\nwhere $k0$ and $\\tau0$. We will use the Nyquist stability criterion, grounded in the principles of the Laplace transform and frequency-domain analysis.\n\nFirst, we derive the characteristic equation of the system. We substitute the expression for the actuator command $u(t)$ into the dynamic equation for the concentration $x(t)$:\n$$\n\\frac{d x(t)}{d t} = -k\\,x(t-\\tau)\n$$\nTo analyze the stability of this LTI system, we apply the Laplace transform. Let $X(s) = \\mathcal{L}\\{x(t)\\}$. Using the differentiation property $\\mathcal{L}\\{\\frac{dx}{dt}\\} = sX(s) - x(0)$ and the time-delay property $\\mathcal{L}\\{x(t-\\tau)\\} = e^{-s\\tau}X(s)$, and assuming zero initial conditions for transfer function analysis (i.e., $x(0)=0$), the transformed equation is:\n$$\nsX(s) = -k e^{-s\\tau} X(s)\n$$\nRearranging the terms to find the characteristic equation, we get:\n$$\n(s + k e^{-s\\tau}) X(s) = 0\n$$\nFor a non-trivial solution ($X(s) \\neq 0$), the term in the parenthesis must be zero. This gives the characteristic equation of the closed-loop system:\n$$\ns + k e^{-s\\tau} = 0\n$$\nThe roots of this equation are the poles of the closed-loop system. The system is stable if and only if all roots have negative real parts.\n\nTo apply the Nyquist stability criterion, we first identify the open-loop transfer function, $L(s)$. The standard form of a characteristic equation for a unity negative feedback system is $1 + L(s) = 0$. We can write our characteristic equation in this form:\n$$\n1 + \\frac{k e^{-s\\tau}}{s} = 0\n$$\nThus, the open-loop transfer function is:\n$$\nL(s) = \\frac{k e^{-s\\tau}}{s}\n$$\nThe Nyquist stability criterion relates the stability of the closed-loop system to the frequency response of the open-loop system. The criterion is given by the formula $Z = P + N$, where:\n- $Z$ is the number of unstable (right-half plane) poles of the closed-loop system. For stability, we require $Z=0$.\n- $P$ is the number of unstable (right-half plane) poles of the open-loop system $L(s)$.\n- $N$ is the number of clockwise encirclements of the critical point $-1+j0$ by the Nyquist contour of $L(s)$.\n\nThe open-loop transfer function $L(s)$ has a single pole at $s=0$. This pole lies on the imaginary axis, not in the right-half plane. Therefore, the number of open-loop unstable poles is $P=0$.\nFor stability ($Z=0$), the Nyquist criterion simplifies to $N=0$. This means the Nyquist plot of $L(s)$ must not encircle the point $-1+j0$.\n\nTo construct the Nyquist plot, we evaluate $L(s)$ along the imaginary axis by setting $s=j\\omega$, where $\\omega$ is the angular frequency.\n$$\nL(j\\omega) = \\frac{k e^{-j\\omega\\tau}}{j\\omega}\n$$\nWe analyze the magnitude and phase of $L(j\\omega)$:\nThe magnitude is:\n$$\n|L(j\\omega)| = \\left| \\frac{k e^{-j\\omega\\tau}}{j\\omega} \\right| = \\frac{|k| |e^{-j\\omega\\tau}|}{|j\\omega|} = \\frac{k}{\\omega} \\quad (\\text{since } k0 \\text{ and for } \\omega0)\n$$\nThe phase angle is:\n$$\n\\angle L(j\\omega) = \\angle(k) + \\angle(e^{-j\\omega\\tau}) - \\angle(j\\omega) = 0 - \\omega\\tau - \\frac{\\pi}{2} \\quad (\\text{radians})\n$$\nThe system is on the verge of instability, or marginally stable, when the Nyquist plot passes through the critical point $-1+j0$. At this point, the magnitude is $1$ and the phase is $-\\pi$ (or any odd multiple of $-\\pi$).\nWe first find the phase crossover frequency, $\\omega_{pc}$, which is the frequency at which the phase of $L(j\\omega)$ is equal to $-\\pi$.\n$$\n\\angle L(j\\omega_{pc}) = -\\omega_{pc}\\tau - \\frac{\\pi}{2} = -\\pi\n$$\nSolving for $\\omega_{pc}$:\n$$\n-\\omega_{pc}\\tau = -\\pi + \\frac{\\pi}{2} = -\\frac{\\pi}{2}\n$$\n$$\n\\omega_{pc} = \\frac{\\pi}{2\\tau}\n$$\nThis is the lowest positive frequency at which the plot crosses the negative real axis.\n\nNext, we evaluate the magnitude of $L(j\\omega)$ at this frequency:\n$$\n|L(j\\omega_{pc})| = \\frac{k}{\\omega_{pc}} = \\frac{k}{\\frac{\\pi}{2\\tau}} = \\frac{2k\\tau}{\\pi}\n$$\nFor the system to be marginally stable, this magnitude must be exactly equal to $1$. This condition defines the maximum permissible loop gain, $k_{\\max}$.\n$$\n|L(j\\omega_{pc})| = 1\n$$\n$$\n\\frac{2k_{\\max}\\tau}{\\pi} = 1\n$$\nSolving for $k_{\\max}$:\n$$\nk_{\\max} = \\frac{\\pi}{2\\tau}\n$$\nFor any gain $k  k_{\\max}$, the magnitude $|L(j\\omega_{pc})|$ will be less than $1$, meaning the Nyquist plot will cross the negative real axis between $0$ and $-1$. In this case, the number of encirclements $N$ of the point $-1+j0$ is zero, and the closed-loop system is stable. If $k  k_{\\max}$, the magnitude will be greater than $1$, the point $-1+j0$ will be encircled, and the system will be unstable.\n\nTherefore, the maximum permissible loop gain for stability is $k_{\\max} = \\frac{\\pi}{2\\tau}$.",
            "answer": "$$\\boxed{\\frac{\\pi}{2\\tau}}$$"
        }
    ]
}