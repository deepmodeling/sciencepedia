{
    "hands_on_practices": [
        {
            "introduction": "Before relying on software packages, a firm grasp of a methodâ€™s foundations is essential. This exercise challenges you to compute Sobol' indices analytically for a synthetic biology-inspired test function . By manually performing the functional ANOVA decomposition and calculating the partial variances for parameters like promoter strength ($P$), ribosome binding site strength ($R$), and inducer concentration ($I$), you will gain a concrete understanding of how these indices partition a model's output variance.",
            "id": "3914470",
            "problem": "Consider a synthetic biology gene expression model in which the dimensionless variables $P$, $R$, and $I$ represent scaled promoter strength, ribosome binding site strength, and inducer concentration, respectively. Assume $P$, $R$, and $I$ are mutually independent and identically distributed as $\\mathrm{Uniform}(0,1)$. A test function is constructed to capture additive effects and pairwise synergies in transcription and translation with a baseline offset:\n$$\nf(P,R,I) \\;=\\; c_{0} \\;+\\; a_{P}\\,(P-\\tfrac{1}{2}) \\;+\\; a_{R}\\,(R-\\tfrac{1}{2}) \\;+\\; a_{I}\\,(I-\\tfrac{1}{2}) \\;+\\; b_{PR}\\,(P-\\tfrac{1}{2})(R-\\tfrac{1}{2}) \\;+\\; b_{PI}\\,(P-\\tfrac{1}{2})(I-\\tfrac{1}{2}) \\;+\\; b_{RI}\\,(R-\\tfrac{1}{2})(I-\\tfrac{1}{2}),\n$$\nwith coefficients $c_{0} \\in \\mathbb{R}$, $a_{P} = 2$, $a_{R} = 1$, $a_{I} = 3$, $b_{PR} = 3$, $b_{PI} = 2$, and $b_{RI} = 1$. There is no three-way interaction term. Use the definitions of the Sobol variance-based sensitivity indices derived from the functional Analysis of Variance (ANOVA) decomposition. Compute exactly, in closed analytic form, the following Sobol indices:\n- the first-order indices $S_{P}$, $S_{R}$, $S_{I}$,\n- the second-order indices $S_{PR}$, $S_{PI}$, $S_{RI}$,\n- the total-order indices $S_{T_P}$, $S_{T_R}$, $S_{T_I}$.\n\nBegin from the core definitions of variance and independence for $\\mathrm{Uniform}(0,1)$ random variables and the ANOVA-based Sobol index definitions. Express each index as an exact fraction and do not approximate numerically. Since sensitivity indices are dimensionless, no units are required, and values must be presented as fractions (not with a percentage sign). The final answer must be given as a single row matrix containing the nine indices in the order $\\big(S_{P},\\,S_{R},\\,S_{I},\\,S_{PR},\\,S_{PI},\\,S_{RI},\\,S_{T_P},\\,S_{T_R},\\,S_{T_I}\\big)$.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It is a standard problem in global sensitivity analysis based on well-defined mathematical principles. All necessary information is provided to compute a unique, meaningful solution. The constant $c_0$ does not affect variance-based sensitivity indices, as they are invariant to constant offsets in the model output.\n\nThe solution proceeds by first transforming the input variables to simplify the analysis, then performing the functional Analysis of Variance (ANOVA) decomposition of the given function, calculating the total variance and partial variances, and finally computing the Sobol indices from these variances.\n\nThe input variables $P$, $R$, and $I$ are independent and identically distributed according to $\\mathrm{Uniform}(0,1)$. Let us define a new set of centered and scaled variables:\n$$x_P = P - \\frac{1}{2}, \\quad x_R = R - \\frac{1}{2}, \\quad x_I = I - \\frac{1}{2}$$\nThese new variables $x_P$, $x_R$, and $x_I$ are independent and identically distributed as $\\mathrm{Uniform}(-\\frac{1}{2}, \\frac{1}{2})$. The expected value and variance of a generic variable $u \\sim \\mathrm{Uniform}(-\\frac{1}{2}, \\frac{1}{2})$ are:\n$$E[u] = \\int_{-1/2}^{1/2} z \\, dz = \\left[ \\frac{z^2}{2} \\right]_{-1/2}^{1/2} = 0$$\n$$V(u) = E[u^2] - (E[u])^2 = \\int_{-1/2}^{1/2} z^2 \\, dz - 0^2 = \\left[ \\frac{z^3}{3} \\right]_{-1/2}^{1/2} = \\frac{1}{3}\\left(\\left(\\frac{1}{2}\\right)^3 - \\left(-\\frac{1}{2}\\right)^3\\right) = \\frac{1}{3}\\left(\\frac{1}{8} + \\frac{1}{8}\\right) = \\frac{1}{12}$$\nThus, for our transformed variables, we have $E[x_P] = E[x_R] = E[x_I] = 0$ and $V(x_P) = V(x_R) = V(x_I) = \\frac{1}{12}$.\n\nThe function $f(P,R,I)$ can be rewritten in terms of these new variables:\n$$f(x_P, x_R, x_I) = c_0 + a_P x_P + a_R x_R + a_I x_I + b_{PR} x_P x_R + b_{PI} x_P x_I + b_{RI} x_R x_I$$\nThis form of the function is its own functional ANOVA decomposition. The ANOVA decomposition of a function $f(\\mathbf{X})$ is given by:\n$$f(\\mathbf{X}) = f_0 + \\sum_i f_i(X_i) + \\sum_{i<j} f_{ij}(X_i, X_j) + \\dots$$\nwhere the terms are defined to be orthogonal. In our case, the terms are:\n- Zeroth-order term: $f_0 = E[f] = E[c_0 + \\dots] = c_0$, since the expectation of all other terms is zero due to $E[x_i]=0$.\n- First-order terms: $f_P = a_P x_P$, $f_R = a_R x_R$, $f_I = a_I x_I$.\n- Second-order terms: $f_{PR} = b_{PR} x_P x_R$, $f_{PI} = b_{PI} x_P x_I$, $f_{RI} = b_{RI} x_R x_I$.\n- The problem states there is no three-way interaction, so $f_{PRI} = 0$.\n\nThe orthogonality of these terms (e.g., $E[f_i f_j] = 0$ for $i \\neq j$) is guaranteed because the input variables are independent and the terms are constructed from products of variables with zero mean. Due to this orthogonality, the total variance of the function, $D = V(f)$, is the sum of the variances of the individual ANOVA terms (partial variances). The constant term $c_0$ has zero variance.\n$$D = V(f_P) + V(f_R) + V(f_I) + V(f_{PR}) + V(f_{PI}) + V(f_{RI})$$\nLet us calculate these partial variances, denoted $V_u$.\nFor the first-order terms:\n$V_P = V(a_P x_P) = a_P^2 V(x_P) = a_P^2 \\left(\\frac{1}{12}\\right)$.\n$V_R = V(a_R x_R) = a_R^2 V(x_R) = a_R^2 \\left(\\frac{1}{12}\\right)$.\n$V_I = V(a_I x_I) = a_I^2 V(x_I) = a_I^2 \\left(\\frac{1}{12}\\right)$.\n\nFor the second-order terms, variance is $V(Y) = E[Y^2] - (E[Y])^2$. Since $E[f_{ij}]=0$:\n$V_{PR} = V(b_{PR} x_P x_R) = E[(b_{PR} x_P x_R)^2] = b_{PR}^2 E[x_P^2]E[x_R^2] = b_{PR}^2 V(x_P) V(x_R) = b_{PR}^2 \\left(\\frac{1}{12}\\right)^2 = \\frac{b_{PR}^2}{144}$.\nSimilarly:\n$V_{PI} = \\frac{b_{PI}^2}{144}$, and $V_{RI} = \\frac{b_{RI}^2}{144}$.\n\nSubstituting the given coefficient values: $a_P=2$, $a_R=1$, $a_I=3$, $b_{PR}=3$, $b_{PI}=2$, $b_{RI}=1$:\n$V_P = \\frac{2^2}{12} = \\frac{4}{12}$\n$V_R = \\frac{1^2}{12} = \\frac{1}{12}$\n$V_I = \\frac{3^2}{12} = \\frac{9}{12}$\n$V_{PR} = \\frac{3^2}{144} = \\frac{9}{144}$\n$V_{PI} = \\frac{2^2}{144} = \\frac{4}{144}$\n$V_{RI} = \\frac{1^2}{144} = \\frac{1}{144}$\n\nThe total variance $D$ is:\n$$D = \\left(\\frac{4}{12} + \\frac{1}{12} + \\frac{9}{12}\\right) + \\left(\\frac{9}{144} + \\frac{4}{144} + \\frac{1}{144}\\right) = \\frac{14}{12} + \\frac{14}{144} = \\frac{14 \\times 12}{144} + \\frac{14}{144} = \\frac{168 + 14}{144} = \\frac{182}{144} = \\frac{91}{72}$$\n\nThe Sobol indices are defined as the ratio of the partial variances to the total variance.\nFirst-order indices, $S_i = V_i / D$:\n$S_P = \\frac{V_P}{D} = \\frac{4/12}{91/72} = \\frac{1}{3} \\cdot \\frac{72}{91} = \\frac{24}{91}$\n$S_R = \\frac{V_R}{D} = \\frac{1/12}{91/72} = \\frac{1}{12} \\cdot \\frac{72}{91} = \\frac{6}{91}$\n$S_I = \\frac{V_I}{D} = \\frac{9/12}{91/72} = \\frac{3}{4} \\cdot \\frac{72}{91} = \\frac{3 \\cdot 18}{91} = \\frac{54}{91}$\n\nSecond-order indices, $S_{ij} = V_{ij} / D$:\n$S_{PR} = \\frac{V_{PR}}{D} = \\frac{9/144}{91/72} = \\frac{1}{16} \\cdot \\frac{72}{91} = \\frac{9 \\cdot 8}{2 \\cdot 8 \\cdot 91} = \\frac{9}{182}$\n$S_{PI} = \\frac{V_{PI}}{D} = \\frac{4/144}{91/72} = \\frac{1}{36} \\cdot \\frac{72}{91} = \\frac{2}{91} = \\frac{4}{182}$\n$S_{RI} = \\frac{V_{RI}}{D} = \\frac{1/144}{91/72} = \\frac{1}{144} \\cdot \\frac{72}{91} = \\frac{1}{2 \\cdot 91} = \\frac{1}{182}$\n\nThe total-order index $S_{T_i}$ for an input $X_i$ is the sum of all sensitivity indices involving $X_i$.\n$S_{T_P} = S_P + S_{PR} + S_{PI} = \\frac{24}{91} + \\frac{9}{182} + \\frac{4}{182} = \\frac{48}{182} + \\frac{9}{182} + \\frac{4}{182} = \\frac{61}{182}$\n$S_{T_R} = S_R + S_{PR} + S_{RI} = \\frac{6}{91} + \\frac{9}{182} + \\frac{1}{182} = \\frac{12}{182} + \\frac{9}{182} + \\frac{1}{182} = \\frac{22}{182} = \\frac{11}{91}$\n$S_{T_I} = S_I + S_{PI} + S_{RI} = \\frac{54}{91} + \\frac{4}{182} + \\frac{1}{182} = \\frac{108}{182} + \\frac{4}{182} + \\frac{1}{182} = \\frac{113}{182}$\n\nThe nine requested indices are:\n$S_P = \\frac{24}{91}$, $S_R = \\frac{6}{91}$, $S_I = \\frac{54}{91}$\n$S_{PR} = \\frac{9}{182}$, $S_{PI} = \\frac{4}{182}$, $S_{RI} = \\frac{1}{182}$\n$S_{T_P} = \\frac{61}{182}$, $S_{T_R} = \\frac{11}{91}$, $S_{T_I} = \\frac{113}{182}$\nThese values will be placed in a row matrix as the final answer.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{24}{91} & \\frac{6}{91} & \\frac{54}{91} & \\frac{9}{182} & \\frac{4}{182} & \\frac{1}{182} & \\frac{61}{182} & \\frac{11}{91} & \\frac{113}{182}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The Morris method provides a computationally efficient way to screen for important parameters, but its true power lies in interpreting its summary statistics. This practice focuses on a common and insightful scenario where a parameter's mean elementary effect, $\\mu_i$, is nearly zero, yet its mean absolute effect, $\\mu_i^*$, is large . Understanding this pattern is key to correctly identifying parameters with strong non-monotonic or interactive effects that must be retained for further analysis.",
            "id": "3914499",
            "problem": "In a global sensitivity analysis of a synthetic gene circuit model, the steady-state reporter level $y$ is modeled as a deterministic function $f(\\mathbf{x})$ of $p$ dimensionless input factors $\\mathbf{x} = (x_1,\\dots,x_p)$ scaled to $[0,1]^p$, where $x_i$ includes an inducer feed concentration that participates in both activation and repression through feedback. You perform the Morris screening method, which constructs one-at-a-time (OAT) trajectories on a $p$-dimensional grid and computes, for each factor $x_i$, a set of elementary effects defined by the core finite-difference sensitivity notion: for a step size $\\Delta \\in (0,1)$ and the $i$-th standard basis vector $\\mathbf{e}_i$, the elementary effect at a base point $\\mathbf{x}$ is $d_i(\\mathbf{x}) = \\big(f(\\mathbf{x} + \\Delta \\mathbf{e}_i) - f(\\mathbf{x})\\big)/\\Delta$. The Morris summary statistics for factor $x_i$ are the mean $\\mu_i = \\mathbb{E}[d_i(\\mathbf{x})]$ across random trajectories, the mean absolute effect $\\mu_i^* = \\mathbb{E}[|d_i(\\mathbf{x})|]$, and the standard deviation $\\sigma_i = \\sqrt{\\mathbb{V}[d_i(\\mathbf{x})]}$, where the expectations are with respect to the random base points and trajectory orientations.\n\nIn this study, you observe, for one particular factor $x_i$, that the empirical $\\mu_i$ is near $0$ while $\\mu_i^*$ is large compared to most other factors. The corresponding $\\sigma_i$ is also non-negligible. Assume model evaluations are noise-free and the OAT design uses a sufficiently fine grid and many trajectories to approximate the above expectations.\n\nWhich statements best explain why $\\mu_i \\approx 0$ but $\\mu_i^*$ is large can occur in this setting, and what the implications are for screening decisions and subsequent analysis?\n\nA. The pattern $\\mu_i \\approx 0$ with large $\\mu_i^*$ indicates that $f$ is monotone in $x_i$, so the elementary effects have a consistent sign and small magnitude; thus $x_i$ is unimportant and can be dropped from further analysis.\n\nB. The pattern is consistent with nonmonotonic dependence of $f$ on $x_i$ and/or strong interactions, producing positive and negative elementary effects that cancel in $\\mu_i$ while $\\mu_i^*$ remains large; $x_i$ should be retained for further analysis, for example by estimating variance-based total-effect Sobol indices $S_{T_i}$.\n\nC. The discrepancy between $\\mu_i$ and $\\mu_i^*$ arises only from numerical noise; with more trajectories, both statistics must converge to the same nonzero value for influential factors.\n\nD. If $\\mu_i \\approx 0$ and $\\mu_i^*$ is large, then all second-order effects involving $x_i$ are necessarily zero, so there is no evidence of interactions with other factors.\n\nE. A large $\\mu_i^*$ with small $\\mu_i$ can coincide with a large $\\sigma_i$, signaling either pronounced nonlinearity or interactions across the input domain. For screening, $x_i$ should not be discarded; instead, one may use second-order Morris designs or compute $S_{T_i}$ to quantify the total contribution including interactions.\n\nSelect all that apply.",
            "solution": "## Problem Validation\n\n### Step 1: Extract Givens\n- The system output is a steady-state reporter level $y=f(\\mathbf{x})$, where $f$ is a deterministic function.\n- The input factors are $\\mathbf{x} = (x_1, \\dots, x_p)$, scaled to the domain $[0,1]^p$.\n- One input factor $x_i$ represents an inducer concentration involved in both activation and repression.\n- The analysis method is the Morris screening method, using one-at-a-time (OAT) trajectories.\n- The elementary effect for factor $x_i$ at point $\\mathbf{x}$ is defined as $d_i(\\mathbf{x}) = \\frac{f(\\mathbf{x} + \\Delta \\mathbf{e}_i) - f(\\mathbf{x})}{\\Delta}$, for a step size $\\Delta \\in (0,1)$.\n- The Morris summary statistics for factor $x_i$ are:\n    - Mean: $\\mu_i = \\mathbb{E}[d_i(\\mathbf{x})]$\n    - Mean absolute effect: $\\mu_i^* = \\mathbb{E}[|d_i(\\mathbf{x})|]$\n    - Standard deviation: $\\sigma_i = \\sqrt{\\mathbb{V}[d_i(\\mathbf{x})]}$\n- The expectations are taken over random base points $\\mathbf{x}$ and trajectory orientations.\n- The observation for a particular factor $x_i$ is: $\\mu_i \\approx 0$, $\\mu_i^*$ is large compared to other factors, and $\\sigma_i$ is non-negligible.\n- Assumptions: Model evaluations are noise-free; the OAT design uses a sufficiently fine grid and many trajectories to approximate the expectations accurately.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded (Critical)**: The problem is firmly grounded in the established field of global sensitivity analysis (GSA) and its application to systems biology models (synthetic gene circuits). The Morris screening method is a standard, widely used technique in GSA. The definitions of the elementary effect, $\\mu_i$, $\\mu_i^*$, and $\\sigma_i$ are correct and standard in the literature on the Morris method. The scenario of an inducer participating in both activation and repression biochemically motivates the potential for non-monotonic responses, which is a core theme of the question.\n2.  **Well-Posed**: The problem is well-posed. It presents a specific, well-documented result from a Morris analysis ($\\mu_i \\approx 0$, large $\\mu_i^*$) and asks for its interpretation and implications. This scenario has a clear and standard explanation in the GSA literature.\n3.  **Objective (Critical)**: The problem is stated in precise, objective language. It uses standard mathematical definitions and avoids subjective or ambiguous terminology.\n4.  **No other flaws detected**: The problem is not incomplete, contradictory, unrealistic, ill-posed, trivial, or unverifiable. It describes a classic case study in the interpretation of Morris screening results.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. I will proceed with the solution derivation and option analysis.\n\n---\n\n## Solution Derivation\n\nThe Morris method is a global sensitivity analysis technique used for screening, which aims to distinguish influential input factors from non-influential ones in a computationally efficient manner. It relies on the computation of elementary effects, $d_i(\\mathbf{x})$, which are finite-difference approximations of the partial derivative of the output function $f$ with respect to an input factor $x_i$ at various points $\\mathbf{x}$ in the input space.\n\nThe key statistics derived from the distribution of elementary effects for each factor $x_i$ are:\n1.  **The mean, $\\mu_i = \\mathbb{E}[d_i(\\mathbf{x})]$**: This measures the average overall effect of $x_i$ on the output. If a factor has a predominantly positive (or negative) effect across the input space (i.e., the function is largely monotonic with respect to $x_i$), then $\\mu_i$ will have a large magnitude.\n2.  **The mean of absolute values, $\\mu_i^* = \\mathbb{E}[|d_i(\\mathbf{x})|]$**: This measures the average magnitude of the effect, regardless of its direction. A large $\\mu_i^*$ indicates that $x_i$ is an influential factor, as it causes significant changes in the output, on average.\n3.  **The standard deviation, $\\sigma_i = \\sqrt{\\mathbb{V}[d_i(\\mathbf{x})]}$**: This measures the spread or variability of the elementary effects. A large $\\sigma_i$ indicates that the effect of $x_i$ is not constant; it changes depending on the location $\\mathbf{x}$ in the input space. This variability can arise from two sources: (a) non-linear dependence of the output on $x_i$, or (b) interactions between $x_i$ and other factors $x_j$ (where $j \\neq i$).\n\nThe problem presents a specific scenario where, for a factor $x_i$, the empirical results show $\\mu_i \\approx 0$ while $\\mu_i^*$ is large. Let us analyze this.\n\n-   A large $\\mu_i^*$ signifies that the factor $x_i$ has a substantial impact on the output $y$. The magnitude of the change in $y$ caused by a change in $x_i$ is, on average, large. This immediately implies that factor $x_i$ is important and should not be screened out.\n\n-   A value of $\\mu_i \\approx 0$ indicates that the average of the elementary effects is close to zero. Given that the individual effects are large in magnitude (as per large $\\mu_i^*$), the only way their average can be near zero is if there is a cancellation between large positive effects and large negative effects. This means that for some points $\\mathbf{x}$ in the input space, increasing $x_i$ increases $y$ (i.e., $d_i(\\mathbf{x}) > 0$), while for other points, increasing $x_i$ decreases $y$ (i.e., $d_i(\\mathbf{x}) < 0$).\n\nThis pattern of positive and negative effects is a classic sign of either:\n-   **Non-monotonicity**: The function $f$ is not monotonic with respect to $x_i$. For example, an optimal value might exist, where the response first increases and then decreases as $x_i$ increases. This is plausible for an inducer involved in both activation and repression.\n-   **Strong interactions**: The sign of the effect of $x_i$ depends on the values of other factors $x_j$. For instance, $x_i$ might be an activator when $x_j$ is low, but an inhibitor when $x_j$ is high.\n\nA non-negligible $\\sigma_i$ is consistent with and reinforces this conclusion. The variance is defined as $\\sigma_i^2 = \\mathbb{V}[d_i(\\mathbf{x})] = \\mathbb{E}[d_i(\\mathbf{x})^2] - (\\mathbb{E}[d_i(\\mathbf{x})])^2 = \\mathbb{E}[d_i^2] - \\mu_i^2$. Since $\\mu_i \\approx 0$, we have $\\sigma_i^2 \\approx \\mathbb{E}[d_i^2]$. By Jensen's inequality, for any non-negative random variable $|Z|$, $\\mathbb{E}[Z^2] \\ge (\\mathbb{E}[Z])^2$. Applying this to $|d_i|$, we have $\\mathbb{E}[d_i^2] = \\mathbb{E}[|d_i|^2] \\ge (\\mathbb{E}[|d_i|])^2 = (\\mu_i^*)^2$. Thus, a large $\\mu_i^*$ implies a large lower bound on $\\sigma_i^2$, explaining why $\\sigma_i$ is also non-negligible or large. A large $\\sigma_i$ is the primary indicator of non-linearity and/or interactions in the Morris method.\n\nThe implication for analysis is that $x_i$ is an influential factor whose effect is complex. It should be retained for more detailed, quantitative analysis. Variance-based methods, such as calculating Sobol' indices, are the appropriate next step. The total-effect Sobol' index, $S_{T_i}$, is particularly relevant as it quantifies the total contribution of $x_i$ to the output variance, including its first-order effect and all its interactions.\n\nNow we evaluate the given options.\n\n### Option-by-Option Analysis\n\n**A. The pattern $\\mu_i \\approx 0$ with large $\\mu_i^*$ indicates that $f$ is monotone in $x_i$, so the elementary effects have a consistent sign and small magnitude; thus $x_i$ is unimportant and can be dropped from further analysis.**\n-   This statement is incorrect on multiple grounds. If $f$ were monotone in $x_i$, the elementary effects $d_i(\\mathbf{x})$ would have a consistent sign (all positive or all negative). In this case, $\\mu_i^* = \\mathbb{E}[|d_i(\\mathbf{x})|] \\approx |\\mathbb{E}[d_i(\\mathbf{x})]| = |\\mu_i|$, which contradicts the given condition that $\\mu_i \\approx 0$ while $\\mu_i^*$ is large. A large $\\mu_i^*$ indicates the effects have large, not small, magnitude on average. A factor with a large $\\mu_i^*$ is by definition influential, not unimportant.\n-   Verdict: **Incorrect**.\n\n**B. The pattern is consistent with nonmonotonic dependence of $f$ on $x_i$ and/or strong interactions, producing positive and negative elementary effects that cancel in $\\mu_i$ while $\\mu_i^*$ remains large; $x_i$ should be retained for further analysis, for example by estimating variance-based total-effect Sobol indices $S_{T_i}$.**\n-   This statement accurately describes the situation. The cancellation of positive and negative elementary effects explains why $\\mu_i \\approx 0$ despite large individual effect magnitudes (leading to large $\\mu_i^*$). This pattern is the hallmark of non-monotonicity and/or interactions. The conclusion that $x_i$ is an important factor to be retained is correct. Suggesting the estimation of total-effect Sobol' indices $S_{T_i}$ is the standard and appropriate next step for quantitatively assessing such a complex factor.\n-   Verdict: **Correct**.\n\n**C. The discrepancy between $\\mu_i$ and $\\mu_i^*$ arises only from numerical noise; with more trajectories, both statistics must converge to the same nonzero value for influential factors.**\n-   This is incorrect. The problem explicitly assumes noise-free evaluations and sufficient sampling, so the result is a feature of the function $f$, not a numerical artifact. Furthermore, $\\mu_i = \\mathbb{E}[d_i]$ and $\\mu_i^* = \\mathbb{E}[|d_i|]$ are fundamentally different statistics. They are equal only if the random variable $d_i$ is always non-negative or always non-positive. For a factor with non-monotonic/interactive effects, they will converge to different values, specifically with $\\mu_i$ potentially being zero and $\\mu_i^*$ being large and non-zero.\n-   Verdict: **Incorrect**.\n\n**D. If $\\mu_i \\approx 0$ and $\\mu_i^*$ is large, then all second-order effects involving $x_i$ are necessarily zero, so there is no evidence of interactions with other factors.**\n-   This statement is the opposite of the correct interpretation. As discussed, a large discrepancy between $\\mu_i$ and $\\mu_i^*$ (often accompanied by a large $\\sigma_i$) is strong evidence *for* the presence of interactions or non-linear effects. It in no way implies that second-order effects (interactions) are zero.\n-   Verdict: **Incorrect**.\n\n**E. A large $\\mu_i^*$ with small $\\mu_i$ can coincide with a large $\\sigma_i$, signaling either pronounced nonlinearity or interactions across the input domain. For screening, $x_i$ should not be discarded; instead, one may use second-order Morris designs or compute $S_{T_i}$ to quantify the total contribution including interactions.**\n-   This statement is also correct and provides a more complete picture. It correctly links the given pattern to a large $\\sigma_i$, which is mathematically sound ($\\sigma_i^2 \\approx \\mathbb{E}[d_i^2] \\ge (\\mu_i^*)^2$ when $\\mu_i \\approx 0$). It correctly interprets a large $\\sigma_i$ as a signal of nonlinearity or interactions. It correctly concludes that the factor should not be discarded. The suggested follow-up actions, using second-order Morris designs (which are designed to better estimate interaction effects) or computing $S_{T_i}$, are both advanced and appropriate strategies for dealing with such a factor.\n-   Verdict: **Correct**.",
            "answer": "$$\\boxed{BE}$$"
        },
        {
            "introduction": "In practical synthetic biology modeling, computational cost is a major constraint, making a full Sobol' analysis of every parameter often infeasible. This problem demonstrates the value of a strategic, two-stage GSA workflow that combines Morris screening with Sobol' analysis . By calculating the expected reduction in model evaluations, you will quantify the efficiency gains of using a screening method to focus computational effort on the most influential parameters.",
            "id": "3914469",
            "problem": "A synthetic gene circuit is modeled by a system of ordinary differential equations (ODEs) with $k = 25$ uncertain kinetic parameters. You plan a two-stage Global Sensitivity Analysis (GSA) workflow: first, One-at-a-Time (OAT) Morris screening to filter negligible parameters, then estimation of first-order and total Sobol' indices using Saltelli's sampling only for the retained parameters. For Morris screening, use $r = 20$ trajectories. For Sobol' estimation, use a base Monte Carlo (MC) sample size of $N = 4000$. Assume, based on prior behavior in modular biological networks, that the expected fraction of parameters retained after Morris is $p = 0.2$, and that retained parameters are then the only parameters for which Sobol' indices are computed.\n\nDefine computational cost as the number of model evaluations. Starting from the standard OAT Morris trajectory structure and the Saltelli construction for Sobol' indices, compute the expected reduction in computational cost of the two-stage workflow relative to conducting Sobol' estimation for all $k$ parameters without screening. Express the reduction as the decimal fraction of cost saved relative to the full Sobol' run. Round your answer to four significant figures.",
            "solution": "The user wants me to solve the following problem:\nA synthetic gene circuit is modeled by a system of ordinary differential equations (ODEs) with $k = 25$ uncertain kinetic parameters. You plan a two-stage Global Sensitivity Analysis (GSA) workflow: first, One-at-a-Time (OAT) Morris screening to filter negligible parameters, then estimation of first-order and total Sobol' indices using Saltelli's sampling only for the retained parameters. For Morris screening, use $r = 20$ trajectories. For Sobol' estimation, use a base Monte Carlo (MC) sample size of $N = 4000$. Assume, based on prior behavior in modular biological networks, that the expected fraction of parameters retained after Morris is $p = 0.2$, and that retained parameters are then the only parameters for which Sobol' indices are computed.\n\nDefine computational cost as the number of model evaluations. Starting from the standard OAT Morris trajectory structure and the Saltelli construction for Sobol' indices, compute the expected reduction in computational cost of the two-stage workflow relative to conducting Sobol' estimation for all $k$ parameters without screening. Express the reduction as the decimal fraction of cost saved relative to the full Sobol' run. Round your answer to four significant figures.\n\n### Step 1: Extract Givens\n-   Number of uncertain parameters: $k = 25$\n-   Number of Morris screening trajectories: $r = 20$\n-   Base Monte Carlo sample size for Sobol' estimation: $N = 4000$\n-   Expected fraction of parameters retained after screening: $p = 0.2$\n-   Screening method: One-at-a-Time (OAT) Morris screening\n-   Quantitative GSA method: First-order and total Sobol' indices via Saltelli's sampling\n-   Computational cost: The number of model evaluations\n-   Objective: Compute the expected relative reduction in computational cost\n\n### Step 2: Validate Using Extracted Givens\nThe problem statement is analyzed for validity.\n\n-   **Scientifically Grounded**: The problem describes a standard, widely-used methodology in computational systems and synthetic biology. Morris screening is a common technique for factor screening (identifying influential parameters), and Sobol' indices estimated via Saltelli sampling represent a gold standard for variance-based global sensitivity analysis. The use of a two-stage approach to manage the computational burden for a model with a moderate number of parameters ($k=25$) is a realistic and sound scientific strategy. The specified numerical values for $k$, $r$, $N$, and $p$ are plausible within this context.\n-   **Well-Posed**: The problem is well-posed. It provides all necessary data and methodological specifications to calculate a unique numerical answer. The objective is clearly defined.\n-   **Objective**: The problem is stated in precise, quantitative terms, free from ambiguity or subjective claims.\n\nThe problem is self-contained, scientifically sound, and well-posed. There are no contradictions, missing data, or violations of scientific principles.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Solution\nThe objective is to compute the expected relative reduction in computational cost, denoted by $R$, for a two-stage sensitivity analysis workflow compared to a full Sobol' analysis on all parameters. The cost is defined as the number of model evaluations.\n\nThe relative cost reduction $R$ is given by the formula:\n$$\nR = \\frac{C_{\\text{full}} - C_{\\text{workflow}}}{C_{\\text{full}}} = 1 - \\frac{C_{\\text{workflow}}}{C_{\\text{full}}}\n$$\nwhere $C_{\\text{full}}$ is the cost of the full Sobol' analysis on all $k$ parameters, and $C_{\\text{workflow}}$ is the expected total cost of the two-stage workflow.\n\nWe must first determine the cost of each component.\n\n**1. Cost of the Full Sobol' Analysis ($C_{\\text{full}}$)**\nThe estimation of both first-order and total-order Sobol' indices for a model with $d$ parameters using Saltelli's sampling method requires the evaluation of the model for a base sample matrix $A$ (size $N \\times d$), a second independent sample matrix $B$ (size $N \\times d$), and $d$ additional matrices where the $i$-th column is taken from $B$ and all other columns are taken from $A$. This results in a total of $N + N + d \\times N = N(d+2)$ model evaluations.\nFor the full analysis, the number of parameters is $d=k$. Therefore, the cost is:\n$$\nC_{\\text{full}} = N(k+2)\n$$\n\n**2. Expected Cost of the Two-Stage Workflow ($C_{\\text{workflow}}$)**\nThe total cost of the workflow is the sum of the cost of the Morris screening stage and the expected cost of the subsequent Sobol' analysis on the reduced set of parameters.\n$$\nC_{\\text{workflow}} = C_{\\text{Morris}} + \\text{E}[C_{\\text{Sobol', reduced}}]\n$$\n\n**2.1. Cost of OAT Morris Screening ($C_{\\text{Morris}}$)**\nThe One-at-a-Time (OAT) Morris screening method involves generating $r$ random trajectories in the parameter space. Each trajectory consists of a starting point and $k$ subsequent points, each generated by perturbing one of the $k$ parameters. Thus, each trajectory requires $(k+1)$ model evaluations. For $r$ trajectories, the total cost is:\n$$\nC_{\\text{Morris}} = r(k+1)\n$$\n\n**2.2. Expected Cost of the Reduced Sobol' Analysis ($\\text{E}[C_{\\text{Sobol', reduced}}]$)**\nAfter screening, a reduced number of parameters, let's call it $k'$, will be retained for the more expensive Sobol' analysis. The problem states that the expected fraction of retained parameters is $p$. Thus, the expected number of retained parameters is:\n$$\n\\text{E}[k'] = kp\n$$\nThe cost of the Sobol' analysis on these $k'$ parameters is $N(k'+2)$. By the linearity of expectation, the expected cost is:\n$$\n\\text{E}[C_{\\text{Sobol', reduced}}] = \\text{E}[N(k'+2)] = N(\\text{E}[k'] + 2) = N(kp+2)\n$$\n\n**2.3. Total Workflow Cost**\nCombining the costs from both stages, the total expected cost of the workflow is:\n$$\nC_{\\text{workflow}} = C_{\\text{Morris}} + \\text{E}[C_{\\text{Sobol', reduced}}] = r(k+1) + N(kp+2)\n$$\n\n**3. Calculation of the Relative Cost Reduction ($R$)**\nNow we can substitute the expressions for $C_{\\text{full}}$ and $C_{\\text{workflow}}$ into the formula for $R$:\n$$\nR = 1 - \\frac{r(k+1) + N(kp+2)}{N(k+2)}\n$$\nWe are given the following values:\n-   $k = 25$\n-   $r = 20$\n-   $N = 4000$\n-   $p = 0.2$\n\nFirst, let's calculate the numerical values for the costs.\nThe cost of the full Sobol' analysis is:\n$$\nC_{\\text{full}} = 4000 \\times (25+2) = 4000 \\times 27 = 108000\n$$\nThe expected number of retained parameters is:\n$$\n\\text{E}[k'] = 25 \\times 0.2 = 5\n$$\nThe cost of the Morris screening stage is:\n$$\nC_{\\text{Morris}} = 20 \\times (25+1) = 20 \\times 26 = 520\n$$\nThe expected cost of the reduced Sobol' analysis is:\n$$\n\\text{E}[C_{\\text{Sobol', reduced}}] = 4000 \\times (5+2) = 4000 \\times 7 = 28000\n$$\nThe total expected cost of the two-stage workflow is:\n$$\nC_{\\text{workflow}} = 520 + 28000 = 28520\n$$\nFinally, we compute the relative reduction $R$:\n$$\nR = \\frac{108000 - 28520}{108000} = \\frac{79480}{108000}\n$$\n$$\nR \\approx 0.7359259...\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nR \\approx 0.7359\n$$",
            "answer": "$$\\boxed{0.7359}$$"
        }
    ]
}