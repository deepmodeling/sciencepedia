{
    "hands_on_practices": [
        {
            "introduction": "掌握模型选择标准的第一步是能够为基本模型计算其数值。本练习将通过一个合成生物学中的常见场景——单分子荧光原位杂交 (smFISH) 的mRNA计数——来指导你完成这个过程。通过为一个简单的泊松分布模型计算最大似然估计、对数似然值，并最终得到AIC和BIC值，你将巩固从原始数据到模型选择标准的完整计算路径 。",
            "id": "3919160",
            "problem": "在用于合成生物学建模的单分子荧光原位杂交 (smFISH) 实验中，我们观察了不同独立细胞中某个基因的单细胞信使RNA (mRNA) 计数。假设一个生成模型，其中每个细胞的计数都是来自一个未知率参数为 $\\lambda$ 的泊松分布的独立抽样。这种设置通常用于评估在同质条件下基因的转录活性。您观察到 $n = 12$ 个细胞的计数如下：\n$$\ny = \\{0, 1, 2, 4, 3, 5, 2, 0, 1, 3, 4, 2\\}.\n$$\n从泊松概率质量函数的定义和抽样的独立性出发，推导该数据集的最大似然估计 $\\hat{\\lambda}$ 和最大化对数似然 $\\ell(\\hat{\\lambda})$。然后，使用将赤池信息量准则 (AIC) 与预期库尔贝克-莱布勒散度相关联、将贝叶斯信息准则 (BIC) 与对数边缘似然的大样本近似相关联的第一性原理定义，确定对于一个具有 $k = 1$ 个自由参数和给定样本量 $n$ 的模型，$\\hat{\\lambda}$ 和 $\\ell(\\hat{\\lambda})$ 如何进入这些准则。计算所提供数据集的 $\\hat{\\lambda}$、$\\ell(\\hat{\\lambda})$、$\\mathrm{AIC}$ 和 $\\mathrm{BIC}$ 的数值。将所有数值结果四舍五入到四位有效数字。将您的最终答案表示为 $\\mathrm{pmatrix}$ 格式的行向量 $(\\hat{\\lambda}, \\ell(\\hat{\\lambda}), \\mathrm{AIC}, \\mathrm{BIC})$。",
            "solution": "问题陈述经验证是完整的、一致的、有科学依据且定义明确的。该任务涉及将最大似然估计和模型选择理论标准地应用于定量生物学中的一个常见问题。\n\n解题过程如下：\n首先，我们推导泊松分布参数 $\\lambda$ 的最大似然估计 (MLE)。设观察到的 mRNA 计数为 $y = \\{y_1, y_2, \\ldots, y_n\\}$，其中 $n=12$。对于来自率参数为 $\\lambda$ 的泊松分布的单个观测值 $y_i$，其概率质量函数 (PMF) 为：\n$$ P(Y=y_i | \\lambda) = \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!} $$\n由于观测值是独立同分布的 (i.i.d.)，整个数据集的似然函数 $L(\\lambda | y)$ 是各个概率的乘积：\n$$ L(\\lambda | y) = \\prod_{i=1}^{n} P(Y=y_i | \\lambda) = \\prod_{i=1}^{n} \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!} $$\n为了简化最大化过程，我们使用对数似然函数 $\\ell(\\lambda | y) = \\ln(L(\\lambda | y))$：\n$$ \\ell(\\lambda | y) = \\ln \\left( \\prod_{i=1}^{n} \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!} \\right) = \\sum_{i=1}^{n} \\ln \\left( \\frac{\\lambda^{y_i} \\exp(-\\lambda)}{y_i!} \\right) $$\n利用对数的性质，上式可简化为：\n$$ \\ell(\\lambda | y) = \\sum_{i=1}^{n} (y_i \\ln(\\lambda) - \\lambda - \\ln(y_i!)) = (\\ln \\lambda) \\sum_{i=1}^{n} y_i - n\\lambda - \\sum_{i=1}^{n} \\ln(y_i!) $$\n为了求得 MLE $\\hat{\\lambda}$，我们将 $\\ell(\\lambda | y)$ 对 $\\lambda$ 求导，并令其为零：\n$$ \\frac{d\\ell}{d\\lambda} = \\frac{d}{d\\lambda} \\left( (\\ln \\lambda) \\sum_{i=1}^{n} y_i - n\\lambda - \\sum_{i=1}^{n} \\ln(y_i!) \\right) = \\frac{1}{\\lambda} \\sum_{i=1}^{n} y_i - n $$\n将导数设为零并求解 $\\lambda$，得到 MLE $\\hat{\\lambda}$：\n$$ \\frac{1}{\\hat{\\lambda}} \\sum_{i=1}^{n} y_i - n = 0 \\implies \\hat{\\lambda} = \\frac{\\sum_{i=1}^{n} y_i}{n} = \\bar{y} $$\n泊松分布率参数的 MLE 是观测值的样本均值。对于给定的数据集 $y = \\{0, 1, 2, 4, 3, 5, 2, 0, 1, 3, 4, 2\\}$，样本量为 $n=12$，计数总和为：\n$$ \\sum_{i=1}^{12} y_i = 0 + 1 + 2 + 4 + 3 + 5 + 2 + 0 + 1 + 3 + 4 + 2 = 27 $$\n因此，MLE 的数值为：\n$$ \\hat{\\lambda} = \\frac{27}{12} = 2.25 $$\n接下来，我们通过将 $\\hat{\\lambda}$ 代回对数似然函数来计算最大化对数似然 $\\ell(\\hat{\\lambda})$：\n$$ \\ell(\\hat{\\lambda}) = (\\ln \\hat{\\lambda}) \\sum_{i=1}^{n} y_i - n\\hat{\\lambda} - \\sum_{i=1}^{n} \\ln(y_i!) $$\n代入数值 $\\sum y_i = 27$、$n=12$ 和 $\\hat{\\lambda}=2.25$：\n$$ \\ell(\\hat{\\lambda}) = 27 \\ln(2.25) - (12)(2.25) - \\sum_{i=1}^{12} \\ln(y_i!) = 27 \\ln(2.25) - 27 - \\sum_{i=1}^{12} \\ln(y_i!) $$\n项 $\\sum \\ln(y_i!)$ 根据数据计算得出：\n$$ \\sum_{i=1}^{12} \\ln(y_i!) = 2\\ln(0!) + 2\\ln(1!) + 3\\ln(2!) + 2\\ln(3!) + 2\\ln(4!) + 1\\ln(5!) $$\n因为 $0! = 1$ 且 $1! = 1$，所以 $\\ln(0!) = \\ln(1) = 0$。\n$$ \\sum_{i=1}^{12} \\ln(y_i!) = 3\\ln(2) + 2\\ln(6) + 2\\ln(24) + \\ln(120) $$\n$$ \\sum_{i=1}^{12} \\ln(y_i!) \\approx 3(0.693147) + 2(1.791759) + 2(3.178054) + 4.787492 \\approx 16.806581 $$\n现在，我们计算 $\\ell(\\hat{\\lambda})$：\n$$ \\ell(\\hat{\\lambda}) \\approx 27 \\ln(2.25) - 27 - 16.806581 \\approx 27(0.810930) - 27 - 16.806581 $$\n$$ \\ell(\\hat{\\lambda}) \\approx 21.895116 - 27 - 16.806581 = -21.911465 $$\n现在我们来看模型选择准则。赤池信息量准则 ($\\mathrm{AIC}$) 从第一性原理定义，作为拟合模型与真实潜在生成过程之间预期库尔贝克-莱布勒散度的估计量。对于一个有 $k$ 个自由参数的模型，其标准形式为：\n$$ \\mathrm{AIC} = -2\\ell(\\hat{\\theta}) + 2k $$\n其中 $\\hat{\\theta}$ 表示 MLE 参数的向量。在我们的例子中，模型只有一个自由参数 $\\lambda$，所以 $k=1$。项 $-2\\ell(\\hat{\\theta})$ 与拟合优度有关，而 $2k$ 是对模型复杂度的惩罚。\n$$ \\mathrm{AIC} = -2\\ell(\\hat{\\lambda}) + 2(1) \\approx -2(-21.911465) + 2 = 43.82293 + 2 = 45.82293 $$\n贝叶斯信息准则 ($\\mathrm{BIC}$) 是通过对边缘似然（或模型证据）的对数进行大样本近似得出的。其定义为：\n$$ \\mathrm{BIC} = -2\\ell(\\hat{\\theta}) + k \\ln(n) $$\n其中 $n$ 是样本量。当 $n \\ge 8$ 时，惩罚项 $k\\ln(n)$ 比 $\\mathrm{AIC}$ 的惩罚更严厉。对于我们的问题，$k=1$ 且 $n=12$。\n$$ \\mathrm{BIC} = -2\\ell(\\hat{\\lambda}) + (1)\\ln(12) \\approx 43.82293 + \\ln(12) $$\n$$ \\ln(12) \\approx 2.484907 $$\n$$ \\mathrm{BIC} \\approx 43.82293 + 2.484907 = 46.307837 $$\n最后，我们将计算值四舍五入到四位有效数字：\n- $\\hat{\\lambda} = 2.250$\n- $\\ell(\\hat{\\lambda}) = -21.91$\n- $\\mathrm{AIC} = 45.82$\n- $\\mathrm{BIC} = 46.31$",
            "answer": "$$ \\boxed{\\begin{pmatrix} 2.250  -21.91  45.82  46.31 \\end{pmatrix}} $$"
        },
        {
            "introduction": "在比较模型时，一个核心问题是：增加一个参数所带来的模型复杂性是否值得？本练习将超越简单的数值计算，探讨模型比较的本质。通过推导在嵌套模型中，AIC和BIC各自要求多大的对数似然改进才能支持更复杂的模型，你将能够量化并直观地理解这两种标准对模型复杂度的“惩罚”有何不同 。",
            "id": "3919103",
            "problem": "一个合成生物学团队正在对诱导条件下启动子产生的单细胞信使核糖核酸（$\\mathrm{mRNA}$）计数进行建模。他们为 $n$ 个独立细胞比较了两个关于转录爆发的嵌套随机模型：一个参数维度为 $k_{S}$ 的较简单模型 $\\mathcal{M}_{S}$，以及一个参数维度为 $k_{C} = k_{S} + 1$ 的较复杂模型 $\\mathcal{M}_{C}$，后者增加了一个具有生物学可解释性的参数，用于捕捉依赖于诱导的爆发规模。设 $\\ln \\hat{L}_{S}$ 和 $\\ln \\hat{L}_{C}$ 分别表示这两个模型在其各自的最大似然估计（MLEs）下计算出的最大化对数似然。定义复杂模型相对于简单模型的对数似然改进为 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$，对于通过最大似然法拟合的嵌套模型，有 $\\Delta \\ln \\hat{L} \\geq 0$。\n\n从赤池信息准则（AIC）和贝叶斯信息准则（BIC）作为结合了拟合优度项和复杂度惩罚项的惩罚准则的标准定义出发，并仅使用上述假设，推导在给定样本量 $n$ 的情况下，根据每个准则，复杂模型 $\\mathcal{M}_{C}$ 优于简单模型 $\\mathcal{M}_{S}$ 所需的 $\\Delta \\ln \\hat{L}$ 的最小阈值。将您的最终答案表示为两个关于 $n$ 的精确解析表达式，以单行矩阵 $[\\Delta_{\\mathrm{AIC}} \\quad \\Delta_{\\mathrm{BIC}}]$ 的形式呈现，其中 $\\Delta_{\\mathrm{AIC}}$ 和 $\\Delta_{\\mathrm{BIC}}$ 分别是使复杂模型受到赤池信息准则和贝叶斯信息准则青睐的 $\\Delta \\ln \\hat{L}$ 的最小值。最终表达式中不要求四舍五入，也不应使用任何单位。",
            "solution": "该问题是有效的。它具有科学依据，问题阐述清晰，是客观的，并包含了得出唯一解所需的所有信息。我们开始进行推导。\n\n目标是确定对数似然改进 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$ 的最小阈值，该阈值是根据赤池信息准则（AIC）和贝叶斯信息准则（BIC），较复杂的模型 $\\mathcal{M}_{C}$ 优于较简单的模型 $\\mathcal{M}_{S}$ 所必需的。\n\n对于像 AIC 和 BIC 这样的模型选择准则，准则值较低的模型更优。因此，如果 $\\text{AIC}(\\mathcal{M}_{C})  \\text{AIC}(\\mathcal{M}_{S})$ 和 $\\text{BIC}(\\mathcal{M}_{C})  \\text{BIC}(\\mathcal{M}_{S})$，则模型 $\\mathcal{M}_{C}$ 分别优于 $\\mathcal{M}_{S}$。阈值对应于等号成立的点。\n\n设 $k$ 为模型中估计参数的数量，$\\hat{L}$ 为模型似然函数的最大化值，$n$ 为数据点的数量（在本例中为独立细胞的数量）。\n\n**1. 赤池信息准则（AIC）的推导**\n\nAIC 的标准定义是：\n$$ \\text{AIC} = 2k - 2\\ln \\hat{L} $$\n\n对于我们的两个模型 $\\mathcal{M}_{S}$ 和 $\\mathcal{M}_{C}$，AIC 值分别为：\n$$ \\text{AIC}_{S} = 2k_{S} - 2\\ln \\hat{L}_{S} $$\n$$ \\text{AIC}_{C} = 2k_{C} - 2\\ln \\hat{L}_{C} $$\n\n当 $\\text{AIC}_{C}  \\text{AIC}_{S}$ 时，复杂模型 $\\mathcal{M}_{C}$ 优于简单模型 $\\mathcal{M}_{S}$。我们可以将此不等式写为：\n$$ 2k_{C} - 2\\ln \\hat{L}_{C}  2k_{S} - 2\\ln \\hat{L}_{S} $$\n\n为了找到关于对数似然改进的条件，我们重排不等式，将似然项和参数数量项分组：\n$$ 2\\ln \\hat{L}_{C} - 2\\ln \\hat{L}_{S} > 2k_{C} - 2k_{S} $$\n$$ 2(\\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}) > 2(k_{C} - k_{S}) $$\n\n使用问题中的定义 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$，我们得到：\n$$ 2\\Delta \\ln \\hat{L} > 2(k_{C} - k_{S}) $$\n$$ \\Delta \\ln \\hat{L} > k_{C} - k_{S} $$\n\n问题指出，复杂模型的参数维度比简单模型多一，即 $k_{C} = k_{S} + 1$，这意味着 $k_{C} - k_{S} = 1$。将此代入不等式，得到：\n$$ \\Delta \\ln \\hat{L} > 1 $$\n\n使 $\\mathcal{M}_{C}$ 更受青睐所需的 $\\Delta \\ln \\hat{L}$ 的最小值是此不等式的阈值。因此，AIC 的最小阈值是：\n$$ \\Delta_{\\text{AIC}} = 1 $$\n\n**2. 贝叶斯信息准则（BIC）的推导**\n\nBIC 的标准定义是：\n$$ \\text{BIC} = k\\ln(n) - 2\\ln \\hat{L} $$\n其中 $n$ 是样本量。\n\n对于我们的两个模型，BIC 值分别为：\n$$ \\text{BIC}_{S} = k_{S}\\ln(n) - 2\\ln \\hat{L}_{S} $$\n$$ \\text{BIC}_{C} = k_{C}\\ln(n) - 2\\ln \\hat{L}_{C} $$\n\n当 $\\text{BIC}_{C}  \\text{BIC}_{S}$ 时，复杂模型 $\\mathcal{M}_{C}$ 优于简单模型 $\\mathcal{M}_{S}$：\n$$ k_{C}\\ln(n) - 2\\ln \\hat{L}_{C}  k_{S}\\ln(n) - 2\\ln \\hat{L}_{S} $$\n\n我们再次重排以分离出对数似然改进项：\n$$ 2\\ln \\hat{L}_{C} - 2\\ln \\hat{L}_{S} > k_{C}\\ln(n) - k_{S}\\ln(n) $$\n$$ 2(\\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}) > (k_{C} - k_{S})\\ln(n) $$\n\n代入 $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$：\n$$ 2\\Delta \\ln \\hat{L} > (k_{C} - k_{S})\\ln(n) $$\n\n再次，我们使用 $k_{C} - k_{S} = 1$ 这一事实：\n$$ 2\\Delta \\ln \\hat{L} > \\ln(n) $$\n$$ \\Delta \\ln \\hat{L} > \\frac{1}{2}\\ln(n) $$\n\n在 BIC 准则下，使 $\\mathcal{M}_{C}$ 更受青睐所需的 $\\Delta \\ln \\hat{L}$ 的最小值是此条件的边界值。因此，BIC 的最小阈值是：\n$$ \\Delta_{\\text{BIC}} = \\frac{1}{2}\\ln(n) $$\n\n最终答案由两个推导出的阈值 $\\Delta_{\\text{AIC}}$ 和 $\\Delta_{\\text{BIC}}$ 组成，以行矩阵的形式呈现。",
            "answer": "$$\n\\boxed{\\begin{bmatrix} 1  \\frac{1}{2}\\ln(n) \\end{bmatrix}}\n$$"
        },
        {
            "introduction": "虽然AIC和BIC在形式上相似，但它们的理论基础截然不同：AIC源于信息论，而BIC植根于贝叶斯推断。本练习将深入探讨BIC的贝叶斯基础，指导你从边际似然的拉普拉斯近似推导出BIC的表达式。通过计算和解释BIC差异 ($\\Delta \\mathrm{BIC}$) 与贝叶斯因子之间的关系，你将学会如何在贝叶斯框架下进行模型证据的比较 。",
            "id": "3919110",
            "problem": "考虑一项合成生物学建模研究，研究对象是一个受抑制的基因线路，其中信使核糖核酸（mRNA）的产生被一个转录因子所抑制。将两个嵌套模型拟合到一个数据集上，该数据集包含在重复实验中，稳态条件下对 mRNA 浓度的 $n$ 次独立测量结果。较简单的模型 $\\mathcal{M}_{0}$ 假设为非协同抑制，并有 $k_{0}$ 个自由参数（转录速率、降解速率和解离常数），而较复杂的模型 $\\mathcal{M}_{1}$ 通过希尔系数（Hill coefficient）允许协同抑制，并有 $k_{1}$ 个自由参数。这两个模型是嵌套的，因为当希尔系数等于 $1$ 时，$\\mathcal{M}_{1}$ 会简化为 $\\mathcal{M}_{0}$。最大似然估计分别得出模型 $\\mathcal{M}_{0}$ 和 $\\mathcal{M}_{1}$ 的最大化似然值 $\\hat{L}_{0}$ 和 $\\hat{L}_{1}$。\n\n从似然函数 $p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M})$ 和边际似然 $p(\\mathbf{y}\\mid \\mathcal{M})=\\int p(\\mathbf{y}\\mid \\boldsymbol{\\theta}, \\mathcal{M})\\,p(\\boldsymbol{\\theta}\\mid \\mathcal{M})\\,\\mathrm{d}\\boldsymbol{\\theta}$ 的定义出发，并以大样本拉普拉斯近似（Laplace approximation）为基础，推导用于拟合 $n$ 个观测值的具有 $k$ 个参数的模型的模型选择准则，即贝叶斯信息准则（Bayesian Information Criterion, BIC）。然后，对于所述的两个嵌套模型，用 $n$、$k_{0}$、$k_{1}$ 以及最大化似然值 $\\hat{L}_{0}$ 和 $\\hat{L}_{1}$ 来推导 BIC 差值 $\\Delta \\mathrm{BIC}=\\mathrm{BIC}_{1}-\\mathrm{BIC}_{0}$ 的表达式。使用此表达式计算以下经验获得量的 $\\Delta \\mathrm{BIC}$ 数值：\n- $n=150$,\n- $k_{0}=3$,\n- $k_{1}=4$,\n- $\\hat{L}_{0}=1.2\\times 10^{-180}$,\n- $\\hat{L}_{1}=3.6\\times 10^{-175}$.\n\n最后，解释 $\\Delta \\mathrm{BIC}$ 如何近似于比较模型 $\\mathcal{M}_{1}$ 与 $\\mathcal{M}_{0}$ 的贝叶斯因子（Bayes factor）的 $2\\ln$ 值，并指出 $\\Delta \\mathrm{BIC}$ 的符号所暗示的证据方向。将您计算的 $\\Delta \\mathrm{BIC}$ 值四舍五入到四位有效数字。在您的推导中必须明确区分赤池信息准则（Akaike Information Criterion, AIC）和贝叶斯信息准则（Bayesian Information Criterion, BIC）；计算应专注于 BIC。",
            "solution": "该问题要求推导贝叶斯信息准则（BIC），将其应用于合成生物学中的一个模型选择问题，并解释结果。\n\n首先，我们根据问题陈述中列出的原则推导 BIC。贝叶斯模型选择的目标是根据给定数据 $\\mathbf{y}$ 的模型后验概率 $p(\\mathcal{M} \\mid \\mathbf{y})$ 来比较模型。使用贝叶斯定理，模型 $\\mathcal{M}$ 的后验概率为 $p(\\mathcal{M} \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}) p(\\mathcal{M})}{p(\\mathbf{y})}$。当比较两个具有相等先验概率 $p(\\mathcal{M}_{0}) = p(\\mathcal{M}_{1})$ 的模型 $\\mathcal{M}_{0}$ 和 $\\mathcal{M}_{1}$ 时，比较可简化为评估它们的边际似然之比，也称为贝叶斯因子（Bayes factor），即 $B_{10} = p(\\mathbf{y} \\mid \\mathcal{M}_{1}) / p(\\mathbf{y} \\mid \\mathcal{M}_{0})$。边际似然（或称模型证据）由似然函数在参数 $\\boldsymbol{\\theta}$ 的先验分布上的积分给出：\n$$p(\\mathbf{y} \\mid \\mathcal{M}) = \\int p(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\mathcal{M}) \\, p(\\boldsymbol{\\theta} \\mid \\mathcal{M}) \\, \\mathrm{d}\\boldsymbol{\\theta}$$\n设 $L(\\boldsymbol{\\theta}) = p(\\mathbf{y} \\mid \\boldsymbol{\\theta}, \\mathcal{M})$ 为似然，$\\pi(\\boldsymbol{\\theta}) = p(\\boldsymbol{\\theta} \\mid \\mathcal{M})$ 为先验。该积分为 $\\int L(\\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta}) \\, \\mathrm{d}\\boldsymbol{\\theta}$。通常处理被积函数的对数更为方便。我们定义 $S(\\boldsymbol{\\theta}) = \\ln(L(\\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta}))$。那么边际似然为 $p(\\mathbf{y} \\mid \\mathcal{M}) = \\int \\exp(S(\\boldsymbol{\\theta})) \\, \\mathrm{d}\\boldsymbol{\\theta}$。\n\n我们使用拉普拉斯近似来评估此积分，当后验分布集中在其众数周围的一个小区域时，这种方法是有效的。我们在 $S(\\boldsymbol{\\theta})$ 的最大值点，即最大后验（MAP）估计 $\\tilde{\\boldsymbol{\\theta}}$ 周围进行二阶泰勒级数展开：\n$$S(\\boldsymbol{\\theta}) \\approx S(\\tilde{\\boldsymbol{\\theta}}) + (\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})^T \\nabla S(\\tilde{\\boldsymbol{\\theta}}) + \\frac{1}{2}(\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})^T H(\\tilde{\\boldsymbol{\\theta}}) (\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})$$\n其中 $H$ 是 $S$ 的海森矩阵（Hessian matrix）。根据最大值的定义，梯度 $\\nabla S(\\tilde{\\boldsymbol{\\theta}})$ 为零。设 $A = -H(\\tilde{\\boldsymbol{\\theta}})$ 为众数处的负海森矩阵，它是一个正定矩阵。展开式简化为：\n$$S(\\boldsymbol{\\theta}) \\approx S(\\tilde{\\boldsymbol{\\theta}}) - \\frac{1}{2}(\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})^T A (\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})$$\n将此代回边际似然的积分中：\n$$p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\int \\exp\\left(S(\\tilde{\\boldsymbol{\\theta}}) - \\frac{1}{2}(\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})^T A (\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})\\right) \\, \\mathrm{d}\\boldsymbol{\\theta} = \\exp(S(\\tilde{\\boldsymbol{\\theta}})) \\int \\exp\\left(-\\frac{1}{2}(\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})^T A (\\boldsymbol{\\theta} - \\tilde{\\boldsymbol{\\theta}})\\right) \\, \\mathrm{d}\\boldsymbol{\\theta}$$\n该积分是均值为 $\\tilde{\\boldsymbol{\\theta}}$、协方差矩阵为 $A^{-1}$ 的多元正态分布的核。其值为 $(2\\pi)^{k/2}(\\det A)^{-1/2}$，其中 $k$ 是 $\\boldsymbol{\\theta}$ 的维度（自由参数的数量）。因此，\n$$p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\exp(S(\\tilde{\\boldsymbol{\\theta}})) (2\\pi)^{k/2} (\\det A)^{-1/2} = L(\\tilde{\\boldsymbol{\\theta}})\\pi(\\tilde{\\boldsymbol{\\theta}}) (2\\pi)^{k/2} (\\det A)^{-1/2}$$\n对于大量的独立观测值 $n$，可以做出以下几点近似：\n1. 最大后验（MAP）估计 $\\tilde{\\boldsymbol{\\theta}}$ 收敛于最大似然估计（MLE） $\\hat{\\boldsymbol{\\theta}}$。\n2. 与似然项相比，$\\pi(\\tilde{\\boldsymbol{\\theta}})$ 项变得可以忽略不计。\n3. 矩阵 $A = -H(\\tilde{\\boldsymbol{\\theta}})$ 主要由对数似然的海森矩阵决定，该海森矩阵近似于观测到的费雪信息矩阵（Fisher information matrix） $I(\\hat{\\boldsymbol{\\theta}})$。对于大的 $n$，我们有 $I(\\hat{\\boldsymbol{\\theta}}) \\approx n \\cdot i(\\hat{\\boldsymbol{\\theta}})$，其中 $i(\\hat{\\boldsymbol{\\theta}})$ 是单个观测值的费雪信息。行列式的尺度关系为 $\\det(A) \\approx \\det(n \\cdot i(\\hat{\\boldsymbol{\\theta}})) = n^k \\det(i(\\hat{\\boldsymbol{\\theta}}))$。\n\n对边际似然取对数：\n$$\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\ln L(\\hat{\\boldsymbol{\\theta}}) + \\ln\\pi(\\hat{\\boldsymbol{\\theta}}) + \\frac{k}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\det A)$$\n代入 $\\det A$ 的近似值：\n$$\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\ln L(\\hat{\\boldsymbol{\\theta}}) + \\ln\\pi(\\hat{\\boldsymbol{\\theta}}) + \\frac{k}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(n^k \\det(i(\\hat{\\boldsymbol{\\theta}})))$$\n$$\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\ln L(\\hat{\\boldsymbol{\\theta}}) - \\frac{k}{2}\\ln n + \\left( \\ln\\pi(\\hat{\\boldsymbol{\\theta}}) + \\frac{k}{2} \\ln(2\\pi) - \\frac{1}{2} \\ln(\\det(i(\\hat{\\boldsymbol{\\theta}}))) \\right)$$\n当 $n \\to \\infty$ 时，$\\ln L(\\hat{\\boldsymbol{\\theta}})$ 项的尺度为 $O(n)$，而 $\\frac{k}{2}\\ln n$ 项的尺度为 $O(\\ln n)$。括号中的项是 $O(1)$ 阶的。只保留随 $n$ 增长的项，我们得到大样本近似：\n$$\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\approx \\ln L(\\hat{\\boldsymbol{\\theta}}) - \\frac{k}{2}\\ln n$$\n按照惯例，贝叶斯信息准则（BIC）的定义是将此式乘以 $-2$，使其与赤池信息准则（AIC）等偏差统计量处于同一尺度上。设 $\\hat{L} = L(\\hat{\\boldsymbol{\\theta}})$ 为最大化似然值。\n$$\\mathrm{BIC} = -2\\ln\\hat{L} + k\\ln n$$\n该准则对模型的复杂性（较大的 $k$）进行惩罚，并对拟合优度（较大的 $\\hat{L}$）进行奖励。它应与 AIC 相区别，AIC 定义为 $\\mathrm{AIC} = -2\\ln\\hat{L} + 2k$。对于任何样本量 $n > \\exp(2) \\approx 7.4$ 的情况（本例即是如此），BIC 的惩罚项 $k\\ln n$ 比 AIC 的惩罚项 ($2k$) 更为严格。\n\n接下来，我们为两个嵌套模型 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{0}$ 推导 BIC 差值的表达式 $\\Delta\\mathrm{BIC} = \\mathrm{BIC}_{1} - \\mathrm{BIC}_{0}$。\n使用推导出的 BIC 公式：\n$$\\mathrm{BIC}_{0} = -2\\ln\\hat{L}_{0} + k_{0}\\ln n$$\n$$\\mathrm{BIC}_{1} = -2\\ln\\hat{L}_{1} + k_{1}\\ln n$$\n差值为：\n$$\\Delta\\mathrm{BIC} = \\mathrm{BIC}_{1} - \\mathrm{BIC}_{0} = (-2\\ln\\hat{L}_{1} + k_{1}\\ln n) - (-2\\ln\\hat{L}_{0} + k_{0}\\ln n)$$\n整理各项得：\n$$\\Delta\\mathrm{BIC} = -2(\\ln\\hat{L}_{1} - \\ln\\hat{L}_{0}) + (k_{1} - k_{0})\\ln n$$\n这可以用似然比的形式写出：\n$$\\Delta\\mathrm{BIC} = -2\\ln\\left(\\frac{\\hat{L}_{1}}{\\hat{L}_{0}}\\right) + (k_{1} - k_{0})\\ln n$$\n\n现在，我们使用给定的量计算 $\\Delta\\mathrm{BIC}$ 的数值：\n$n=150$, $k_{0}=3$, $k_{1}=4$, $\\hat{L}_{0}=1.2\\times 10^{-180}$, $\\hat{L}_{1}=3.6\\times 10^{-175}$.\n首先，计算似然比 $\\frac{\\hat{L}_{1}}{\\hat{L}_{0}}$：\n$$\\frac{\\hat{L}_{1}}{\\hat{L}_{0}} = \\frac{3.6 \\times 10^{-175}}{1.2 \\times 10^{-180}} = \\frac{3.6}{1.2} \\times 10^{-175 - (-180)} = 3.0 \\times 10^{5}$$\n接下来，我们计算 $\\Delta\\mathrm{BIC}$ 表达式中的两项：\n对数似然比项为：\n$$-2\\ln\\left(\\frac{\\hat{L}_{1}}{\\hat{L}_{0}}\\right) = -2\\ln(3.0 \\times 10^{5}) = -2(\\ln(3.0) + 5\\ln(10)) \\approx -2(1.09861 + 5 \\times 2.30259) \\approx -2(12.61156) = -25.22312$$\n惩罚项为：\n$$(k_{1} - k_{0})\\ln n = (4 - 3)\\ln(150) = \\ln(150) \\approx 5.010635$$\n将这两项合并：\n$$\\Delta\\mathrm{BIC} = -25.22312 + 5.010635 = -20.212485$$\n将结果四舍五入到四位有效数字，我们得到 $\\Delta\\mathrm{BIC} \\approx -20.21$。\n\n最后，我们解释 $\\Delta\\mathrm{BIC}$ 和贝叶斯因子之间的关系。支持模型 $\\mathcal{M}_{1}$ 相对于 $\\mathcal{M}_{0}$ 的贝叶斯因子是 $B_{10} = \\frac{p(\\mathbf{y} \\mid \\mathcal{M}_{1})}{p(\\mathbf{y} \\mid \\mathcal{M}_{0})}$。根据我们的推导，$\\ln p(\\mathbf{y} \\mid \\mathcal{M}) \\approx -\\frac{1}{2}\\mathrm{BIC}$。因此，贝叶斯因子的对数的两倍是：\n$$2\\ln B_{10} = 2(\\ln p(\\mathbf{y} \\mid \\mathcal{M}_{1}) - \\ln p(\\mathbf{y} \\mid \\mathcal{M}_{0})) \\approx 2\\left(-\\frac{1}{2}\\mathrm{BIC}_{1} - \\left(-\\frac{1}{2}\\mathrm{BIC}_{0}\\right)\\right) = -(\\mathrm{BIC}_{1} - \\mathrm{BIC}_{0}) = -\\Delta\\mathrm{BIC}$$\n因此，$\\Delta\\mathrm{BIC}$ 近似于 $-2\\ln B_{10}$。问题要求将 $\\Delta\\mathrm{BIC}$ 与“贝叶斯因子的 $2\\ln$ 值”联系起来，最精确的表述是 $\\Delta\\mathrm{BIC} \\approx -2\\ln B_{10}$，或等价地 $\\Delta\\mathrm{BIC} \\approx 2\\ln B_{01}$，其中 $B_{01} = 1/B_{10}$ 是支持模型 $\\mathcal{M}_{0}$ 相对于 $\\mathcal{M}_{1}$ 的贝叶斯因子。\n\n$\\Delta\\mathrm{BIC}$ 的符号表明哪个模型更受偏好。使用 BIC 进行模型选择旨在找到具有最小 BIC 值的模型。\n- 如果 $\\Delta\\mathrm{BIC} = \\mathrm{BIC}_{1} - \\mathrm{BIC}_{0}  0$，那么 $\\mathrm{BIC}_{1}  \\mathrm{BIC}_{0}$，证据支持更复杂的模型 $\\mathcal{M}_{1}$。\n- 如果 $\\Delta\\mathrm{BIC} > 0$，那么 $\\mathrm{BIC}_{1} > \\mathrm{BIC}_{0}$，证据支持更简单的模型 $\\mathcal{M}_{0}$。\n在这种情况下，$\\Delta\\mathrm{BIC} \\approx -20.21$。这是一个很强的负值。这表明有非常强的证据支持更复杂的模型 $\\mathcal{M}_{1}$（协同抑制）优于更简单的模型 $\\mathcal{M}_{0}$（非协同抑制）。差异的幅度（$> 10$）通常被解释为支持偏好模型的“非常强”的证据。由额外参数（希尔系数）带来的拟合优度提升远超过了模型复杂度增加所带来的惩罚。",
            "answer": "$$\\boxed{-20.21}$$"
        }
    ]
}