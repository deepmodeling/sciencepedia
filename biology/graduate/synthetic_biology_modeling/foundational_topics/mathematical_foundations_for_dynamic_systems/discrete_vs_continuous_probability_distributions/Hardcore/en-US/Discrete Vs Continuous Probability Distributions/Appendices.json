{
    "hands_on_practices": [
        {
            "introduction": "Many real-world measurements involve converting a continuous physical quantity into a discrete digital reading, a process known as quantization. This exercise provides a concrete example, showing how the probability distribution of an underlying continuous variable dictates the probability mass function of the observed discrete values. By working through this problem , you will gain hands-on experience in bridging the gap between a continuous probability density function (PDF) and a discrete probability mass function (PMF).",
            "id": "1896422",
            "problem": "A digital environmental sensor is designed to monitor temperatures within a laboratory chamber. The true temperature $T$, in degrees Celsius, is a continuous random variable that, due to controlled environmental fluctuations, follows a uniform distribution over the interval $[20.2, 23.6]$. The sensor's display, however, shows a discrete reading $R$ which is the value of $T$ rounded to the nearest integer. The rounding rule specifies that values exactly at a half-integer (e.g., 21.5) are rounded up to the next integer.\n\nDetermine the probability mass function for the displayed reading $R$. Present the probabilities for all possible values of $R$, ordered from smallest to largest, as a row matrix. Express all probabilities as fractions in their simplest form.",
            "solution": "Let $T$ be uniformly distributed on $[20.2,23.6]$. Write the endpoints as fractions: $a=20.2=\\frac{101}{5}$ and $b=23.6=\\frac{118}{5}$. Then the density of $T$ is\n$$\nf_{T}(t)=\\frac{1}{b-a}=\\frac{1}{\\frac{118}{5}-\\frac{101}{5}}=\\frac{1}{\\frac{17}{5}}=\\frac{5}{17}, \\quad t\\in\\left[\\frac{101}{5},\\frac{118}{5}\\right].\n$$\nThe rounding rule is to the nearest integer with half-integers rounded up. Hence, for an integer $r$, the event $\\{R=r\\}$ corresponds to $T\\in[r-\\frac{1}{2},r+\\frac{1}{2})$, except that the intersection with $[a,b]$ must be taken. The attainable integer readings are $r\\in\\{20,21,22,23,24\\}$, with the following intervals and lengths:\n- For $r=20$: $\\left[\\max\\!\\left(\\frac{101}{5},20-\\frac{1}{2}\\right),\\min\\!\\left(\\frac{118}{5},20+\\frac{1}{2}\\right)\\right)=\\left[\\frac{101}{5},\\frac{41}{2}\\right)$, length $\\frac{41}{2}-\\frac{101}{5}=\\frac{3}{10}$.\n- For $r=21$: $\\left[\\frac{41}{2},\\frac{43}{2}\\right)$, length $\\frac{43}{2}-\\frac{41}{2}=1$.\n- For $r=22$: $\\left[\\frac{43}{2},\\frac{45}{2}\\right)$, length $\\frac{45}{2}-\\frac{43}{2}=1$.\n- For $r=23$: $\\left[\\frac{45}{2},\\frac{47}{2}\\right)$, length $\\frac{47}{2}-\\frac{45}{2}=1$.\n- For $r=24$: $\\left[\\frac{47}{2},\\frac{118}{5}\\right]$, length $\\frac{118}{5}-\\frac{47}{2}=\\frac{1}{10}$.\n\nLet $L=b-a=\\frac{17}{5}$. For each $r$, $P(R=r)=\\text{length}/L$. Therefore,\n$$\nP(R=20)=\\frac{\\frac{3}{10}}{\\frac{17}{5}}=\\frac{3}{10}\\cdot\\frac{5}{17}=\\frac{3}{34},\\quad\nP(R=21)=\\frac{1}{\\frac{17}{5}}=\\frac{5}{17},\n$$\n$$\nP(R=22)=\\frac{1}{\\frac{17}{5}}=\\frac{5}{17},\\quad\nP(R=23)=\\frac{1}{\\frac{17}{5}}=\\frac{5}{17},\\quad\nP(R=24)=\\frac{\\frac{1}{10}}{\\frac{17}{5}}=\\frac{1}{10}\\cdot\\frac{5}{17}=\\frac{1}{34}.\n$$\nThese probabilities sum to $1$ and are expressed in simplest fractional form. Ordered from $r=20$ to $r=24$, the row matrix is\n$$\n\\begin{pmatrix}\n\\frac{3}{34}  \\frac{5}{17}  \\frac{5}{17}  \\frac{5}{17}  \\frac{1}{34}\n\\end{pmatrix}.\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}\\frac{3}{34}  \\frac{5}{17}  \\frac{5}{17}  \\frac{5}{17}  \\frac{1}{34}\\end{pmatrix}}$$"
        },
        {
            "introduction": "In biological modeling, we often analyze the ratio of two quantities, such as the expression levels of two different genes, to normalize data or understand relative dynamics. This practice explores how the mathematical treatment of such ratios differs profoundly depending on whether the quantities are modeled as continuous intensities or discrete counts. You will first derive the distribution for a ratio of continuous variables and then confront the fundamental challenges, like division by zero, that arise with discrete variables , illuminating critical distinctions between continuous and discrete models.",
            "id": "3911740",
            "problem": "In a synthetic biology experiment, two constitutive promoters drive reporter proteins whose continuous fluorescence intensities are denoted by $C_{1}$ and $C_{2}$. Due to multiplicative biophysical variability and shared instrumentation noise, it is reasonable to model these intensities as independent Gamma-distributed random variables with a common scale parameter: $C_{1} \\sim \\text{Gamma}(\\alpha_{1}, \\theta)$ and $C_{2} \\sim \\text{Gamma}(\\alpha_{2}, \\theta)$, where the shape parameters are $\\alpha_{1}  0$ and $\\alpha_{2}  0$, and the scale parameter is $\\theta  0$. Define the ratio $R = C_{1} / C_{2}$. Using only fundamental definitions of independence, the joint probability density function (PDF), and the change-of-variables formula with an appropriate Jacobian, derive the continuous Probability Density Function (PDF) $f_{R}(r)$ for $r  0$. Express your final result in a closed form that is fully simplified in terms of the Gamma function and the Beta function.\n\nThen, consider an analogous setup for discrete molecular counts: let $N_{1} \\sim \\text{Poisson}(\\lambda_{1})$ and $N_{2} \\sim \\text{Poisson}(\\lambda_{2})$ be independent counts of messenger ribonucleic acid (mRNA) molecules from the same two promoters, with $\\lambda_{1}  0$ and $\\lambda_{2}  0$. Define $Q = N_{1}/N_{2}$. Briefly explain, from first principles of discrete probability, why defining a probability mass function for $Q$ requires careful handling of the support and integer constraints, including the event $N_{2} = 0$.\n\nYour final answer should be the closed-form expression for the continuous PDF $f_{R}(r)$ of the ratio $R$, for $r  0$. No numerical rounding is required, and no physical units should be included in the final expression.",
            "solution": "The problem statement is critically evaluated for validity before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Continuous Case:**\n  - $C_{1}$ and $C_{2}$ are continuous random variables representing fluorescence intensities.\n  - $C_{1}$ and $C_{2}$ are independent.\n  - $C_{1} \\sim \\text{Gamma}(\\alpha_{1}, \\theta)$ with shape $\\alpha_{1}  0$ and scale $\\theta  0$.\n  - $C_{2} \\sim \\text{Gamma}(\\alpha_{2}, \\theta)$ with shape $\\alpha_{2}  0$ and scale $\\theta  0$.\n  - The ratio is defined as $R = C_{1} / C_{2}$.\n  - The task is to derive the Probability Density Function (PDF) $f_{R}(r)$ for $r  0$.\n  - The derivation must use the change-of-variables formula with a Jacobian.\n  - The result must be simplified in terms of the Gamma and Beta functions.\n- **Discrete Case:**\n  - $N_{1}$ and $N_{2}$ are discrete random variables representing mRNA molecule counts.\n  - $N_{1}$ and $N_{2}$ are independent.\n  - $N_{1} \\sim \\text{Poisson}(\\lambda_{1})$ with rate $\\lambda_{1}  0$.\n  - $N_{2} \\sim \\text{Poisson}(\\lambda_{2})$ with rate $\\lambda_{2}  0$.\n  - The ratio is defined as $Q = N_{1} / N_{2}$.\n  - The task is to briefly explain the challenges in defining a probability mass function for $Q$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n\n- **Scientifically Grounded:** The problem is well-grounded in the context of synthetic biology modeling. Gamma distributions are frequently used to model continuous, positive quantities subject to multiplicative noise, such as protein or fluorescence levels. Poisson distributions are the canonical model for discrete counting processes, such as the number of mRNA molecules produced in a given time. The question addresses a standard and important task in stochastic modeling: deriving the distribution of a ratio of random variables.\n- **Well-Posed:** The problem is well-posed. The derivation of the PDF for the ratio of two independent Gamma variables is a standard exercise in mathematical statistics with a unique, well-defined solution. The second part asks for a conceptual explanation of mathematical difficulties, which is also a precise and answerable question.\n- **Objective:** The problem is stated using clear, precise, and unbiased mathematical language. No subjective or opinion-based statements are present.\n- **Completeness and Consistency:** All necessary information (distributions, parameters, independence) is provided. There are no contradictions.\n- **Other criteria:** The problem is not unrealistic, ill-posed, trivial, or unverifiable.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Derivation of the Continuous PDF $f_{R}(r)$\nWe are given two independent random variables, $C_{1} \\sim \\text{Gamma}(\\alpha_{1}, \\theta)$ and $C_{2} \\sim \\text{Gamma}(\\alpha_{2}, \\theta)$. The probability density function for a variable $X \\sim \\text{Gamma}(\\alpha, \\theta)$ is given by:\n$$f_{X}(x) = \\frac{x^{\\alpha-1} \\exp(-x/\\theta)}{\\theta^{\\alpha} \\Gamma(\\alpha)}, \\quad \\text{for } x > 0$$\nwhere $\\Gamma(\\alpha)$ is the Gamma function.\n\nThe individual PDFs for $C_{1}$ and $C_{2}$ are:\n$$f_{C_{1}}(c_{1}) = \\frac{c_{1}^{\\alpha_{1}-1} \\exp(-c_{1}/\\theta)}{\\theta^{\\alpha_{1}} \\Gamma(\\alpha_{1})}, \\quad c_{1} > 0$$\n$$f_{C_{2}}(c_{2}) = \\frac{c_{2}^{\\alpha_{2}-1} \\exp(-c_{2}/\\theta)}{\\theta^{\\alpha_{2}} \\Gamma(\\alpha_{2})}, \\quad c_{2} > 0$$\n\nSince $C_{1}$ and $C_{2}$ are independent, their joint PDF is the product of their individual PDFs:\n$$f_{C_{1}, C_{2}}(c_{1}, c_{2}) = f_{C_{1}}(c_{1}) f_{C_{2}}(c_{2}) = \\frac{c_{1}^{\\alpha_{1}-1} c_{2}^{\\alpha_{2}-1} \\exp(-(c_{1}+c_{2})/\\theta)}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})}$$\nfor $c_{1} > 0$ and $c_{2} > 0$.\n\nWe seek the PDF of the ratio $R = C_{1} / C_{2}$. We use the change of variables method. Let us introduce an auxiliary variable, for instance, $S = C_{2}$. The transformation is from $(C_{1}, C_{2})$ to $(R, S)$.\nThe inverse transformation is:\n$$C_{1} = RS$$\n$$C_{2} = S$$\nThe domain $c_{1} > 0, c_{2} > 0$ maps to the domain $r > 0, s > 0$.\n\nNext, we compute the Jacobian of this inverse transformation. The Jacobian determinant $J$ is:\n$$J = \\det \\begin{pmatrix} \\frac{\\partial c_{1}}{\\partial r}  \\frac{\\partial c_{1}}{\\partial s} \\\\ \\frac{\\partial c_{2}}{\\partial r}  \\frac{\\partial c_{2}}{\\partial s} \\end{pmatrix} = \\det \\begin{pmatrix} s  r \\\\ 0  1 \\end{pmatrix} = (s)(1) - (r)(0) = s$$\nThe absolute value of the Jacobian is $|J| = |s| = s$, since $s=c_{2}>0$.\n\nThe joint PDF of the new variables $(R, S)$ is given by $f_{R,S}(r,s) = f_{C_{1}, C_{2}}(rs, s) |J|$.\n$$f_{R,S}(r,s) = \\frac{(rs)^{\\alpha_{1}-1} s^{\\alpha_{2}-1} \\exp(-(rs+s)/\\theta)}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\cdot s$$\nGrouping the terms:\n$$f_{R,S}(r,s) = \\frac{r^{\\alpha_{1}-1} s^{\\alpha_{1}-1} s^{\\alpha_{2}-1} s^{1} \\exp(-s(r+1)/\\theta)}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})}$$\n$$f_{R,S}(r,s) = \\frac{r^{\\alpha_{1}-1} s^{\\alpha_{1}+\\alpha_{2}-1} \\exp(-s(r+1)/\\theta)}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})}$$\nfor $r>0$ and $s>0$.\n\nTo find the marginal PDF of $R$, $f_{R}(r)$, we integrate the joint PDF $f_{R,S}(r,s)$ with respect to the auxiliary variable $s$ over its entire support $(0, \\infty)$.\n$$f_{R}(r) = \\int_{0}^{\\infty} f_{R,S}(r,s) \\, ds = \\int_{0}^{\\infty} \\frac{r^{\\alpha_{1}-1} s^{\\alpha_{1}+\\alpha_{2}-1} \\exp(-s(r+1)/\\theta)}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\, ds$$\nWe can separate the terms that do not depend on $s$:\n$$f_{R}(r) = \\frac{r^{\\alpha_{1}-1}}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\int_{0}^{\\infty} s^{(\\alpha_{1}+\\alpha_{2})-1} \\exp\\left(-\\frac{s(r+1)}{\\theta}\\right) \\, ds$$\nThe integral has the form of the kernel of a Gamma distribution. We use the identity derived from the Gamma function definition: $\\int_0^\\infty x^{A-1} e^{-x/B} dx = B^A \\Gamma(A)$.\nIn our case, the parameters for this identity are:\n- Shape: $A = \\alpha_{1}+\\alpha_{2}$\n- Scale: $B = \\frac{\\theta}{r+1}$\n\nThe integral evaluates to:\n$$\\int_{0}^{\\infty} s^{(\\alpha_{1}+\\alpha_{2})-1} \\exp\\left(-\\frac{s}{\\theta/(r+1)}\\right) \\, ds = \\left(\\frac{\\theta}{r+1}\\right)^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}+\\alpha_{2})$$\nSubstituting this result back into the expression for $f_{R}(r)$:\n$$f_{R}(r) = \\frac{r^{\\alpha_{1}-1}}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\left[ \\left(\\frac{\\theta}{r+1}\\right)^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}+\\alpha_{2}) \\right]$$\n$$f_{R}(r) = \\frac{r^{\\alpha_{1}-1}}{\\theta^{\\alpha_{1}+\\alpha_{2}} \\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\frac{\\theta^{\\alpha_{1}+\\alpha_{2}}}{(r+1)^{\\alpha_{1}+\\alpha_{2}}} \\Gamma(\\alpha_{1}+\\alpha_{2})$$\nThe term $\\theta^{\\alpha_{1}+\\alpha_{2}}$ cancels out, which is expected as the ratio of two variables with a common scale parameter should be independent of that scale.\n$$f_{R}(r) = \\frac{\\Gamma(\\alpha_{1}+\\alpha_{2})}{\\Gamma(\\alpha_{1}) \\Gamma(\\alpha_{2})} \\frac{r^{\\alpha_{1}-1}}{(r+1)^{\\alpha_{1}+\\alpha_{2}}}$$\nThe problem asks for the result to be expressed in terms of the Beta function, $B(x,y)$, which is defined as $B(x,y) = \\frac{\\Gamma(x)\\Gamma(y)}{\\Gamma(x+y)}$. Therefore, the pre-factor is equal to $1/B(\\alpha_{1}, \\alpha_{2})$.\nThe final expression for the PDF of $R$ is:\n$$f_{R}(r) = \\frac{1}{B(\\alpha_{1}, \\alpha_{2})} \\frac{r^{\\alpha_{1}-1}}{(r+1)^{\\alpha_{1}+\\alpha_{2}}}, \\quad \\text{for } r > 0$$\nThis is the PDF of a Beta prime distribution, also known as the beta distribution of the second kind.\n\n### Discussion of the Discrete Case\nFor the discrete case, we are given two independent random variables, $N_{1} \\sim \\text{Poisson}(\\lambda_{1})$ and $N_{2} \\sim \\text{Poisson}(\\lambda_{2})$. The probability mass function (PMF) for a variable $K \\sim \\text{Poisson}(\\lambda)$ is $P(K=k) = \\frac{\\lambda^{k} \\exp(-\\lambda)}{k!}$ for $k \\in \\{0, 1, 2, \\dots\\}$. We wish to define a PMF for the ratio $Q = N_{1}/N_{2}$. This task presents two fundamental challenges.\n\nFirst, and most critically, is the issue of **division by zero**. The support of $N_{2}$ includes $0$. The probability of this event is non-zero:\n$$P(N_{2}=0) = \\frac{\\lambda_{2}^{0} \\exp(-\\lambda_{2})}{0!} = \\exp(-\\lambda_{2})$$\nSince $\\lambda_{2}>0$, we have $P(N_{2}=0) > 0$. When the event $\\{N_{2}=0\\}$ occurs, the ratio $Q = N_{1}/N_{2}$ is mathematically undefined. A rigorous definition of the random variable $Q$ would require a special rule for this case, such as assigning it to a symbolic value like $\\infty$ (if $N_{1}>0$) or treating it as a failure of the measurement, thus restricting the sample space. This conditioning on $N_{2} \\neq 0$ would mean the variables are no longer governed by a simple Poisson distribution, but by a zero-truncated Poisson distribution, which complicates the analysis. In the continuous case, this was not an issue because the probability of $C_{2}$ being exactly zero is $P(C_2=0)=0$.\n\nSecond, is the nature of the **support of the random variable $Q$**. Even if we condition on $N_{2} \\ge 1$, the possible values of $Q$ are non-negative rational numbers of the form $n_{1}/n_{2}$ where $n_{1} \\in \\{0, 1, 2, \\dots\\}$ and $n_{2} \\in \\{1, 2, 3, \\dots\\}$. While this set is countable, allowing for a PMF to be defined in principle, it is not a simple lattice of integers. It is a dense subset of the non-negative real numbers. To compute the probability for a specific rational value $q=a/b$ (in lowest terms), one must sum over all possible integer multiples $(ka, kb)$:\n$$P(Q = q) = \\sum_{k=1}^{\\infty} P(N_{1}=ka, N_{2}=kb)$$\nDue to independence, this becomes:\n$$P(Q = q) = \\sum_{k=1}^{\\infty} P(N_{1}=ka) P(N_{2}=kb) = \\sum_{k=1}^{\\infty} \\left( \\frac{\\lambda_{1}^{ka} \\exp(-\\lambda_{1})}{(ka)!} \\right) \\left( \\frac{\\lambda_{2}^{kb} \\exp(-\\lambda_{2})}{(kb)!} \\right)$$\n$$P(Q = q) = \\exp(-(\\lambda_{1}+\\lambda_{2})) \\sum_{k=1}^{\\infty} \\frac{\\lambda_{1}^{ka} \\lambda_{2}^{kb}}{(ka)! (kb)!}$$\nThis infinite series is computationally intensive and generally lacks a simple closed-form expression. The complexity of both the support and the calculation of probabilities makes the distribution of the ratio of discrete Poisson variables substantially more difficult to handle than its continuous Gamma-distributed counterpart.",
            "answer": "$$\\boxed{\\frac{1}{B(\\alpha_{1}, \\alpha_{2})} \\frac{r^{\\alpha_{1}-1}}{(r+1)^{\\alpha_{1}+\\alpha_{2}}}}$$"
        },
        {
            "introduction": "For systems with many molecules, it is often computationally convenient to approximate discrete stochastic dynamics with continuous stochastic differential equations (SDEs). However, this approximation can fail, especially when molecule numbers are low, leading to unphysical results. This computational exercise  challenges you to quantify the breakdown of the widely used Chemical Langevin Equation by tracking the emergence of negative concentrations, a direct consequence of applying a continuous model to a fundamentally discrete process.",
            "id": "3911726",
            "problem": "Consider a single-species birth-death system in synthetic biology modeling where discrete copy numbers evolve according to a jump process governed by the Chemical Master Equation (CME). The Stochastic Simulation Algorithm (SSA) is the exact discrete simulator, while the Chemical Langevin Equation (CLE) provides a continuous-valued Stochastic Differential Equation (SDE) approximation valid when copy numbers are not too small. Let Stochastic Simulation Algorithm (SSA) denote the exact discrete method, and Chemical Langevin Equation (CLE) denote the continuous SDE approximation. Let Euler-Maruyama denote the time discretization method for the CLE. The system has birth propensity $k_b$ and death propensity $k_d x$, where $x$ is the current copy number. The CLE for this system has drift $k_b - k_d x$ and diffusion intensity determined by the sum of propensities, reflecting the fundamental connection between the CME and CLE for well-mixed reaction systems with moderate counts.\n\nYour task is to compare, in purely mathematical terms, the Euler-Maruyama one-step update distribution against the SSA, and to quantify a regime where the continuous approximation breaks down. The breakdown must be assessed via a bound on the expected negative counts produced by the Euler-Maruyama steps. Use the following fundamental bases: the definition of the jump process from the CME, the construction of the CLE for mesoscopic reaction systems, and the Euler-Maruyama discretization of an SDE. From first principles, derive the probability that a single Euler-Maruyama step yields a negative state and derive a formula for the expected magnitude of the negative part of the state after a single step. Aggregate these quantities over a fixed number of time steps by summing per-step probabilities to obtain a union bound on the probability of any negative occurrence across the steps, and by summing per-step expected negative magnitudes to obtain a bound on the cumulative expected negative mass created by the continuous approximation. The SSA cannot produce negative counts by construction, so it serves as a discrete baseline in which the expected negative mass is zero.\n\nFormulate the Euler-Maruyama step from an initial deterministic state $x_n$ at discrete time $t_n$ with step size $\\Delta t$ as a random variable with a Gaussian law determined by the CLE drift and diffusion evaluated at $x_n$. Then, using only fundamental definitions of the Gaussian distribution and properties of truncated expectations, derive:\n- the probability that this Gaussian step produces a negative state, expressed in terms of the step’s mean and standard deviation, and\n- the expected magnitude of the negative part of the step’s state, defined as the expectation of the positive part of the deficit below zero.\n\nUse a deterministic recursion for the CLE mean to define the sequence $x_{n+1}$ used to parameterize each subsequent Euler-Maruyama step, namely $x_{n+1} = x_n + (k_b - k_d x_n)\\Delta t$, which is the Euler forward method applied to the CLE drift. At step $n$, evaluate the diffusion scale from the CLE intensity at $x_n$. For each step, compute the probability of negativity and the expected negative magnitude; then sum these over all steps to obtain two aggregate bounds:\n- the union bound on negativity across steps, equal to the sum of stepwise negativity probabilities, and\n- the cumulative expected negative mass, equal to the sum of stepwise expected negative magnitudes.\n\nDefine a breakdown criterion that flags the continuous approximation as breaking down if either the union bound across steps exceeds a probability threshold $\\varepsilon$ or the cumulative expected negative mass exceeds a molecule-count threshold $\\theta$. Use $\\varepsilon = 0.05$ and $\\theta = 0.5$.\n\nYour program must implement these computations for the following test suite, each specified by $(x_0, k_b, k_d, \\Delta t, N)$:\n- Test $1$: $(x_0 = 50, k_b = 20, k_d = 0.4, \\Delta t = 0.1, N = 25)$.\n- Test $2$: $(x_0 = 1, k_b = 0.1, k_d = 1.8, \\Delta t = 0.5, N = 10)$.\n- Test $3$: $(x_0 = 100, k_b = 60, k_d = 0.3, \\Delta t = 0.01, N = 1000)$.\n- Test $4$: $(x_0 = 0, k_b = 0, k_d = 1.0, \\Delta t = 0.2, N = 5)$.\n\nFor each test, your program should:\n- initialize $x_0$,\n- iterate $N$ steps using the deterministic CLE mean recursion for $x_n$ to parameterize each step’s Euler-Maruyama Gaussian law,\n- at each step compute the negativity probability and expected negative magnitude from the step’s Gaussian law,\n- sum these quantities across all steps to obtain the union bound and the cumulative expected negative mass, and\n- compare against the thresholds $\\varepsilon$ and $\\theta$ to produce the breakdown boolean.\n\nThe final output for each test must be a list $[p_{\\mathrm{ub}}, m_{\\mathrm{cum}}, \\mathrm{break}]$, where $p_{\\mathrm{ub}}$ is the union bound as a float, $m_{\\mathrm{cum}}$ is the cumulative expected negative mass as a float, and $\\mathrm{break}$ is a boolean. Your program should produce a single line of output containing all test results as a comma-separated list enclosed in square brackets, where each test result is itself a bracketed list. For example, the output format must be exactly like $[[p_1,m_1,b_1],[p_2,m_2,b_2],[p_3,m_3,b_3],[p_4,m_4,b_4]]$ with floats in decimal form and booleans as literal $\\mathrm{True}$ or $\\mathrm{False}$. No physical units are involved in this problem.",
            "solution": "We consider a single-species birth-death system commonly used in synthetic biology modeling. The exact discrete dynamics are governed by the Chemical Master Equation (CME), and the Stochastic Simulation Algorithm (SSA) produces sample paths that respect integer counts and non-negativity. The Chemical Langevin Equation (CLE) provides a continuous-valued approximation for moderate copy numbers. For a single species with constant birth propensity and linear death propensity, the CLE has drift and diffusion derived from propensities: births at rate $k_b$ and deaths at rate $k_d x$, yield drift $k_b - k_d x$ and diffusion intensity $k_b + k_d x$. The CLE increments over a small time step $\\Delta t$ have Gaussian fluctuations induced by the diffusion term.\n\nWe formalize the Euler-Maruyama discretization of the CLE. Let Chemical Langevin Equation (CLE) denote the SDE\n$$\ndX_t = (k_b - k_d X_t)\\,dt + \\sqrt{k_b + k_d X_t}\\, dW_t,\n$$\nwhere $W_t$ is a standard Wiener process. The Euler-Maruyama scheme yields\n$$\nX_{n+1} = X_n + (k_b - k_d X_n)\\Delta t + \\sqrt{(k_b + k_d X_n)\\Delta t}\\, Z_n,\n$$\nwhere $Z_n \\sim \\mathcal{N}(0,1)$ is standard normal and independent across steps. Conditional on $X_n = x_n$ being deterministic, the distribution of $X_{n+1}$ is Gaussian with mean\n$$\n\\mu_{n+1} = x_n + (k_b - k_d x_n)\\Delta t\n$$\nand variance\n$$\n\\sigma_{n+1}^2 = (k_b + k_d x_n)\\Delta t.\n$$\nThis follows from the definition of the Euler-Maruyama method for an SDE with affine drift and square-root diffusion, and from the property that the increment $\\sqrt{(k_b + k_d x_n)\\Delta t} Z_n$ is Gaussian with zero mean and variance $(k_b + k_d x_n)\\Delta t$.\n\nWe seek a bound on the expected negative counts created by the continuous approximation. For a single step, with $Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$, the probability of a negative post-step state is\n$$\n\\mathbb{P}\\{Y  0\\} = \\Phi\\!\\left(-\\frac{\\mu}{\\sigma}\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function. This formula follows from the fundamental definition of the Gaussian distribution: the standardized variable $Z = (Y - \\mu)/\\sigma$ is standard normal, and $Y  0$ is equivalent to $Z  -\\mu/\\sigma$, hence using the standard normal cumulative distribution function yields the stated probability.\n\nNext, we derive the expected magnitude of the negative part of the step’s state. Define the negative part operator by $(u)_- = \\max(-u, 0)$, equivalently the positive part of the deficit below zero, $(-Y)_+$. We require\n$$\n\\mathbb{E}\\left[(-Y)_+\\right] = \\int_{-\\infty}^0 (0 - y)\\, f_Y(y)\\, dy,\n$$\nwhere $f_Y$ is the Gaussian density with mean $\\mu$ and standard deviation $\\sigma$. This truncated expectation can be evaluated using classical properties of the Gaussian distribution. By substituting $y = \\mu + \\sigma z$ with $z$ standard normal, and recognizing integrals of $z$ against the Gaussian density and cumulative distribution, one obtains the closed-form expression\n$$\n\\mathbb{E}\\left[(-Y)_+\\right] = \\sigma \\,\\varphi\\!\\left(\\frac{\\mu}{\\sigma}\\right) - \\mu \\,\\Phi\\!\\left(-\\frac{\\mu}{\\sigma}\\right),\n$$\nwhere $\\varphi$ is the standard normal probability density function. This identity can be established by splitting the integral into the expectation of $-\\mu$ over the event $\\{Y0\\}$ and the expectation of $-(Y-\\mu)$ over the same event, then using the fact that the truncated moments of a Gaussian are expressible via $\\varphi$ and $\\Phi$. For the degenerate case $\\sigma = 0$, $Y$ is deterministically equal to $\\mu$, and the formula reduces to\n$$\n\\mathbb{E}\\left[(-Y)_+\\right] = \\max(-\\mu, 0), \\quad \\mathbb{P}\\{Y0\\} = \\mathbf{1}_{\\{\\mu0\\}},\n$$\nwhere $\\mathbf{1}$ is the indicator function.\n\nTo apply these per-step quantities across multiple steps, we use a deterministic recursion for the CLE mean to define the sequence of $x_n$ used to parameterize each subsequent Euler-Maruyama step:\n$$\nx_{n+1} = x_n + (k_b - k_d x_n)\\Delta t.\n$$\nAt step $n$ we evaluate the variance parameter using $x_n$:\n$$\n\\sigma_{n+1}^2 = (k_b + k_d x_n)\\Delta t.\n$$\nThis recursion is simply the Euler forward method for the deterministic ordinary differential equation (ODE) corresponding to the CLE drift. It provides a consistent baseline trajectory around which the stochastic fluctuations are assessed.\n\nFor each step $n = 0, 1, \\dots, N-1$, we compute:\n- the negativity probability $p_n = \\Phi\\!\\left(-\\mu_{n+1}/\\sigma_{n+1}\\right)$ (or its degenerate counterpart when $\\sigma_{n+1} = 0$), and\n- the expected negative magnitude $b_n = \\sigma_{n+1}\\,\\varphi\\!\\left(\\mu_{n+1}/\\sigma_{n+1}\\right) - \\mu_{n+1}\\,\\Phi\\!\\left(-\\mu_{n+1}/\\sigma_{n+1}\\right)$ (or $\\max(-\\mu_{n+1}, 0)$ when $\\sigma_{n+1} = 0$).\n\nAggregating over steps, the union bound on the probability of any negative occurrence across the $N$ steps is\n$$\np_{\\mathrm{ub}} = \\sum_{n=0}^{N-1} p_n,\n$$\nwhich is a standard consequence of the union bound $\\mathbb{P}\\{\\cup A_n\\} \\le \\sum \\mathbb{P}\\{A_n\\}$ applied to the events $A_n = \\{Y_{n+1}0\\}$. The cumulative expected negative mass is\n$$\nm_{\\mathrm{cum}} = \\sum_{n=0}^{N-1} b_n,\n$$\nsince expectation is linear. The SSA produces no negative counts; hence, the baseline expected negative mass is zero, and any nonzero $m_{\\mathrm{cum}}$ is purely an artifact of the continuous approximation.\n\nWe define the breakdown criterion for the continuous approximation: the regime is flagged as breaking down if either\n$$\np_{\\mathrm{ub}} \\ge \\varepsilon \\quad \\text{or} \\quad m_{\\mathrm{cum}} \\ge \\theta,\n$$\nwith thresholds $\\varepsilon = 0.05$ and $\\theta = 0.5$. These thresholds represent a tolerance on the probability of any negative occurrence and on the cumulative expected negative deficit across the simulated horizon. The outputs for each test case are the triple $[p_{\\mathrm{ub}}, m_{\\mathrm{cum}}, \\mathrm{break}]$.\n\nAlgorithmic plan:\n- Initialize $x_0$ for each test.\n- For $n$ from $0$ to $N-1$:\n  - Compute $\\mu_{n+1} = x_n + (k_b - k_d x_n)\\Delta t$ and $\\sigma_{n+1} = \\sqrt{(k_b + k_d x_n)\\Delta t}$.\n  - If $\\sigma_{n+1} > 0$, compute $p_n$ using the standard normal cumulative distribution function and $b_n$ using the truncated expectation identity involving $\\varphi$ and $\\Phi$. If $\\sigma_{n+1} = 0$, set $p_n = \\mathbf{1}_{\\{\\mu_{n+1}0\\}}$ and $b_n = \\max(-\\mu_{n+1}, 0)$.\n  - Update $x_{n+1} = \\mu_{n+1}$ for the next step.\n- Sum $p_n$ and $b_n$ across steps to obtain $p_{\\mathrm{ub}}$ and $m_{\\mathrm{cum}}$.\n- Set $\\mathrm{break}$ to $\\mathrm{True}$ if $p_{\\mathrm{ub}} \\ge \\varepsilon$ or $m_{\\mathrm{cum}} \\ge \\theta$, otherwise $\\mathrm{False}$.\n\nWe then apply this procedure to the provided test suite:\n- Test $1$: $(x_0 = 50, k_b = 20, k_d = 0.4, \\Delta t = 0.1, N = 25)$.\n- Test $2$: $(x_0 = 1, k_b = 0.1, k_d = 1.8, \\Delta t = 0.5, N = 10)$.\n- Test $3$: $(x_0 = 100, k_b = 60, k_d = 0.3, \\Delta t = 0.01, N = 1000)$.\n- Test $4$: $(x_0 = 0, k_b = 0, k_d = 1.0, \\Delta t = 0.2, N = 5)$.\n\nThe final output must be a single line in the format $[[p_1,m_1,b_1],[p_2,m_2,b_2],[p_3,m_3,b_3],[p_4,m_4,b_4]]$, where $p_i$ and $m_i$ are floats and $b_i$ is a boolean.",
            "answer": "[[0.000000,0.000000,False],[2.964720,2.378951,True],[0.000000,0.000000,False],[0.000000,0.000000,False]]"
        }
    ]
}