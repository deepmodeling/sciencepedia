{
    "hands_on_practices": [
        {
            "introduction": "Metropolis-Hastings 算法的核心是接受概率，它决定了模拟是移动到一个新的提议状态还是停留在当前状态。第一个练习  提供了一个对 Metropolis 算法（一种对称提议分布的特殊情况）接受概率的具体计算，帮助您建立采样器如何探索目标分布的直观理解。",
            "id": "1371728",
            "problem": "一位数据科学家正在实现一个马尔可夫链蒙特卡洛（MCMC）模拟，以从参数 $x$ 的后验概率分布中抽取样本。目标分布 $\\pi(x)$ 与该参数的负绝对值的指数成正比，即 $\\pi(x) \\propto \\exp(-|x|)$。\n\n该科学家使用 Metropolis 算法，其提议分布 $q(x'|x)$ 是对称的，即在给定当前状态 $x$ 的条件下提议新状态 $x'$ 的概率等于在给定 $x'$ 的条件下提议 $x$ 的概率（即 $q(x'|x) = q(x|x')$）。\n\n假设在模拟的某一步中，链的当前状态为 $x = 1.5$。然后，算法提议移动到一个新的候选状态 $x' = 2.0$。\n\n计算这个特定移动的接受概率。您的答案应该是一个无量纲实数。将最终答案四舍五入到四位有效数字。",
            "solution": "对于从 $x$ 移动到 $x'$，在对称提议分布 $q(x'|x)=q(x|x')$ 的情况下，Metropolis 接受概率为\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\frac{\\pi(x')q(x|x')}{\\pi(x)q(x'|x)}\\right)=\\min\\left(1,\\frac{\\pi(x')}{\\pi(x)}\\right).\n$$\n给定目标分布 $\\pi(x)\\propto \\exp(-|x|)$，该比率可简化为\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\frac{\\exp(-|x'|)}{\\exp(-|x|)}=\\exp\\!\\left(-\\left(|x'|-|x|\\right)\\right).\n$$\n当 $x=1.5$ 且 $x'=2.0$ 时，我们有 $|x|=1.5$ 和 $|x'|=2.0$，所以\n$$\n\\frac{\\pi(x')}{\\pi(x)}=\\exp\\!\\left(-\\left(2.0-1.5\\right)\\right)=\\exp(-0.5).\n$$\n因此，\n$$\n\\alpha(x \\to x')=\\min\\left(1,\\exp(-0.5)\\right)=\\exp(-0.5).\n$$\n数值上，$\\exp(-0.5)\\approx 0.6065$（四舍五入到四位有效数字）。",
            "answer": "$$\\boxed{0.6065}$$"
        },
        {
            "introduction": "虽然 Metropolis-Hastings 是一个通用框架，但当从完整的条件分布中采样较为容易时，Gibbs 采样提供了一种强大的替代方案。这个练习  要求您推导 Gibbs 采样器的一个关键组成部分——给定另一个变量时一个变量的条件期望，这是理解和实现该方法的关键一步。",
            "id": "791698",
            "problem": "考虑一个系统，其中有两个离散随机变量 $X$ 和 $Y$，它们都可以在集合 $\\{1, 2, 3\\}$ 中取值。这些变量的联合概率质量函数 (PMF) 由下式给出：\n$$\nP(X=i, Y=j) = \\frac{1}{Z} \\exp\\left(-\\alpha (i-j)^2\\right)\n$$\n对于 $i, j \\in \\{1, 2, 3\\}$，其中 $\\alpha$ 是一个正实数参数，$Z$ 是归一化常数（配分函数），确保所有概率之和为 1。\n\n从这类分布中抽样的一种常用方法是吉布斯抽样 (Gibbs sampling)。该算法通过从全条件分布（在本例中为 $P(X | Y=j)$ 和 $P(Y | X=i)$）中抽样来迭代生成样本。分析或实现此抽样器的一个关键步骤是推导出这些条件分布及其性质。\n\n推导在已观测到随机变量 $Y$ 为 1 的条件下，随机变量 $X$ 的条件期望，即求 $E[X | Y=1]$。请将你的答案表示为参数 $\\alpha$ 的函数。",
            "solution": "给定 $Y=1$ 时 $X$ 的条件 PMF 为\n$$P(X=i\\mid Y=1)=\\frac{\\exp\\bigl(-\\alpha(i-1)^2\\bigr)}{\\sum_{k=1}^3\\exp\\bigl(-\\alpha(k-1)^2\\bigr)}\\,. $$ \n因此，条件期望为\n$$E[X\\mid Y=1]=\\sum_{i=1}^3 i\\,P(X=i\\mid Y=1)\n=\\frac{\\sum_{i=1}^3 i\\,\\exp\\bigl(-\\alpha(i-1)^2\\bigr)}{\\sum_{k=1}^3\\exp\\bigl(-\\alpha(k-1)^2\\bigr)}\\,. $$\n计算求和得到\n$$\\sum_{i=1}^3 i\\,\\exp\\bigl(-\\alpha(i-1)^2\\bigr)\n=1+2e^{-\\alpha}+3e^{-4\\alpha},\\quad\n\\sum_{k=1}^3\\exp\\bigl(-\\alpha(k-1)^2\\bigr)\n=1+e^{-\\alpha}+e^{-4\\alpha}. $$\n因此\n$$E[X\\mid Y=1]=\\frac{1+2e^{-\\alpha}+3e^{-4\\alpha}}{1+e^{-\\alpha}+e^{-4\\alpha}}\\,. $$",
            "answer": "$$\\boxed{\\frac{1+2\\exp(-\\alpha)+3\\exp(-4\\alpha)}{1+\\exp(-\\alpha)+\\exp(-4\\alpha)}}$$"
        },
        {
            "introduction": "我们最后的实践是一项综合性的顶点练习 ，它将所有概念整合到生物和医学建模中常见的实际应用中。您将设计并实现一个完整的 Metropolis-Hastings 采样器来执行贝叶斯逻辑回归，这项任务涉及指定模型、处理数据和解释后验结果，是 MCMC 在现代统计推断中强大功能的体现。",
            "id": "4809452",
            "problem": "考虑医学中的病例-对照数据的独立二元结果，其中对于每个受试者 $i$，观察到一个响应 $y_i \\in \\{0,1\\}$，指示其为病例（$y_i = 1$）或对照（$y_i = 0$），以及协变量 $\\mathbf{x}_i \\in \\mathbb{R}^p$。假设一个使用标准 logit 链接函数的逻辑斯谛回归模型，其中在给定协变量的情况下，一个病例的条件概率为 $p(y_i = 1 \\mid \\mathbf{x}_i, \\boldsymbol{\\beta}) = \\sigma(\\eta_i)$，其中 $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$ 且 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$。在独立观测的假设下，似然是伯努利概率的乘积。假设一个贝叶斯模型，其中回归系数 $\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ 具有独立的​​正态先验，均值为 $\\boldsymbol{\\mu}$，对角方差为 $\\operatorname{diag}(\\boldsymbol{\\sigma}^2)$。\n\n根据贝叶斯定理，后验密度与似然和先验的乘积成正比。在马尔可夫链蒙特卡洛（MCMC）框架内，设计一个 Metropolis-Hastings（MH）采样器，其中提议值从以当前状态为中心、具有指定对称协方差的多元正态随机游走中抽取。使用数值稳定的计算来评估逻辑斯谛似然。对于下述每个测试用例，实现 MH 采样器，运行指定的迭代次数，丢弃老化期（burn-in）的样本，并对链进行稀疏化。报告接受率（以小数形式）、每个系数的后验均值，以及在后验分布下针对指定新协变量向量的后验预测概率。\n\n使用的基本原理：\n- 伯努利似然：对于 $y_i \\in \\{0,1\\}$，$P(y_i \\mid \\eta_i) = \\sigma(\\eta_i)^{y_i} \\left(1 - \\sigma(\\eta_i)\\right)^{1 - y_i}$。\n- 逻辑斯谛函数定义：$\\sigma(z) = \\frac{1}{1 + e^{-z}}$。\n- 贝叶斯定理：$\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) \\propto L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) \\, \\pi(\\boldsymbol{\\beta})$。\n- 正态先验密度：对于独立分量，$\\pi(\\boldsymbol{\\beta}) = \\prod_{j=1}^p \\mathcal{N}(\\beta_j \\mid \\mu_j, \\sigma_j^2)$。\n\n您必须解决以下三个测试用例。在每个用例中，使用提供的随机种子和分布规范，确定性地构建病例-对照数据集。在所有用例中都包含一个截距项，因此 $\\mathbf{x}_i = (1, x_{i1}, x_{i2})^\\top$ 且 $p = 3$。对于病例-对照数据，病例设为 $y_i = 1$，对照设为 $y_i = 0$。\n\n测试用例 A（均衡，典型）：\n- 数据生成种子：$314159$。\n- 病例数：50；对照数：50。\n- 协变量 $x_{1}$（二元“暴露”）：对于病例 $x_{1} \\sim \\operatorname{Bernoulli}(0.6)$；对于对照 $x_{1} \\sim \\operatorname{Bernoulli}(0.3)$。\n- 协变量 $x_{2}$（连续“年龄z分数”）：对于病例 $x_{2} \\sim \\mathcal{N}(0.3, 1^2)$；对于对照 $x_{2} \\sim \\mathcal{N}(-0.3, 1^2)$。\n- 先验均值和方差：$\\boldsymbol{\\mu} = (0, 0, 0)$，$\\boldsymbol{\\sigma}^2 = (25, 9, 9)$。\n- 提议协方差（随机游走 MH）：$\\operatorname{diag}(0.05^2, 0.05^2, 0.05^2)$。\n- MCMC 提议种子：$271828$。\n- 迭代次数：$12000$；老化期：$6000$；稀疏化：$6$。\n- 用于后验预测的新协变量：$\\mathbf{x}_{\\text{new}} = (1, 1, 0.5)$。\n\n测试用例 B（近似分离，强信号）：\n- 数据生成种子：$161803$。\n- 病例数：40；对照数：40。\n- 协变量 $x_{1}$（连续“生物标志物”）：对于病例 $x_{1} \\sim \\mathcal{N}(2.5, 0.7^2)$；对于对照 $x_{1} \\sim \\mathcal{N}(-2.5, 0.7^2)$。\n- 协变量 $x_{2}$（二元“治疗”）：对于病例 $x_{2} \\sim \\operatorname{Bernoulli}(0.9)$；对于对照 $x_{2} \\sim \\operatorname{Bernoulli}(0.1)$。\n- 先验均值和方差：$\\boldsymbol{\\mu} = (0, 0, 0)$，$\\boldsymbol{\\sigma}^2 = (25, 4, 4)$。\n- 提议协方差（随机游走 MH）：$\\operatorname{diag}(0.02^2, 0.02^2, 0.02^2)$。\n- MCMC 提议种子：$141421$。\n- 迭代次数：$16000$；老化期：$8000$；稀疏化：$8$。\n- 用于后验预测的新协变量：$\\mathbf{x}_{\\text{new}} = (1, 0, 1.0)$。\n\n测试用例 C（小样本边界）：\n- 数据生成种子：$123457$。\n- 病例数：8；对照数：12。\n- 协变量 $x_{1}$（二元“暴露”）：对于病例 $x_{1} \\sim \\operatorname{Bernoulli}(0.5)$；对于对照 $x_{1} \\sim \\operatorname{Bernoulli}(0.4)$。\n- 协变量 $x_{2}$（连续“标志物”）：对于病例 $x_{2} \\sim \\mathcal{N}(0.1, 1^2)$；对于对照 $x_{2} \\sim \\mathcal{N}(-0.1, 1^2)$。\n- 先验均值和方差：$\\boldsymbol{\\mu} = (0, 0, 0)$，$\\boldsymbol{\\sigma}^2 = (100, 16, 16)$。\n- 提议协方差（随机游走 MH）：$\\operatorname{diag}(0.08^2, 0.08^2, 0.08^2)$。\n- MCMC 提议种子：$57721$。\n- 迭代次数：$10000$；老化期：$5000$；稀疏化：$5$。\n- 用于后验预测的新协变量：$\\mathbf{x}_{\\text{new}} = (1, 1, -0.2)$。\n\n算法要求：\n- 使用数值稳定的表达式计算对数似然。特别地，如果 $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$，则计算 $\\log L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\operatorname{softplus}(\\eta_i) \\right)$，其中 $\\operatorname{softplus}(z) = \\log(1 + e^{z})$ 以稳定方式计算。\n- 对每个分量使用独立的​​正态先验：$\\log \\pi(\\boldsymbol{\\beta}) = \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right)$。\n- 采用对称的多元正态随机游走提议：$\\boldsymbol{\\beta}^{\\ast} = \\boldsymbol{\\beta}^{(t)} + \\mathbf{z}$，其中 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$。接受概率为 $\\alpha = \\min\\left\\{1, \\exp\\left[ \\log \\pi(\\boldsymbol{\\beta}^{\\ast} \\mid \\mathbf{y}, \\mathbf{X}) - \\log \\pi(\\boldsymbol{\\beta}^{(t)} \\mid \\mathbf{y}, \\mathbf{X}) \\right] \\right\\}$，因为提议分布是对称的。\n- 采样后，计算接受率（接受的提议数占总迭代次数的比例）、每个系数在保存样本上的后验均值，以及后验预测概率 $E\\left[ \\sigma(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}) \\mid \\mathbf{y}, \\mathbf{X} \\right]$，通过样本均值进行估计。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按顺序包含测试用例 A、然后是测试用例 B、然后是测试用例 C 的结果：接受率、$\\beta_0$（截距）的后验均值、$\\beta_1$ 的后验均值、$\\beta_2$ 的后验均值，以及 $\\mathbf{x}_{\\text{new}}$ 的后验预测概率；然后为下一个测试用例重复这五个量，以此类推。例如，输出格式为 $[r_{A}, m_{A0}, m_{A1}, m_{A2}, p_{A}, r_{B}, m_{B0}, m_{B1}, m_{B2}, p_{B}, r_{C}, m_{C0}, m_{C1}, m_{C2}, p_{C}]$，其中每个符号代表一个实数。",
            "solution": "我们为病例-对照数据构建贝叶斯逻辑斯谛回归模型，从基本原理出发指定似然和先验，并在马尔可夫链蒙特卡洛（MCMC）框架内推导 Metropolis-Hastings（MH）采样方案。\n\n首先，定义逻辑斯谛函数 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 以及线性预测变量 $\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$，适用于每个具有协变量 $\\mathbf{x}_i$ 和系数 $\\boldsymbol{\\beta}$ 的受试者 $i$。单个观测的伯努利似然为 $P(y_i \\mid \\eta_i) = \\sigma(\\eta_i)^{y_i} \\left(1 - \\sigma(\\eta_i)\\right)^{1 - y_i}$。对于独立观测，联合似然是所有 $i$ 的乘积。在病例-对照设计中，$y_i$ 表示病例状态，但条件模型 $P(y_i \\mid \\mathbf{x}_i, \\boldsymbol{\\beta})$ 保持了伯努利-logit 形式；截距项吸收了任何抽样比例效应，协变量的回归系数仍然可以解释为对数优势比（log-odds ratios），这在医学证据综合中是核心。\n\n为了数值稳定性，避免直接计算 $\\log \\left(1 - \\sigma(\\eta_i)\\right)$，而应使用恒等式\n$$\n\\log L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\log\\left(1 + e^{\\eta_i}\\right) \\right) = \\sum_{i=1}^n \\left( y_i \\eta_i - \\operatorname{softplus}(\\eta_i) \\right),\n$$\n其中函数 $\\operatorname{softplus}(z) = \\log(1 + e^{z})$ 应通过数值稳定的分支来计算：\n$$\n\\operatorname{softplus}(z) = \n\\begin{cases}\nz + \\log(1 + e^{-z}),  z  0, \\\\\n\\log(1 + e^{z}),  z \\le 0.\n\\end{cases}\n$$\n这样做可以避免当 $|z|$ 很大时 $e^{z}$ 发生上溢或下溢。\n\n为每个系数指定独立的​​正态先验，\n$$\n\\pi(\\boldsymbol{\\beta}) = \\prod_{j=1}^p \\mathcal{N}(\\beta_j \\mid \\mu_j, \\sigma_j^2),\n$$\n其对数先验为\n$$\n\\log \\pi(\\boldsymbol{\\beta}) = \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right).\n$$\n根据贝叶斯定理，后验分布满足\n$$\n\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) \\propto L(\\mathbf{y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}) \\, \\pi(\\boldsymbol{\\beta}),\n$$\n因此对数后验为\n$$\n\\log \\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X}) = \\sum_{i=1}^n \\left( y_i \\mathbf{x}_i^\\top \\boldsymbol{\\beta} - \\operatorname{softplus}(\\mathbf{x}_i^\\top \\boldsymbol{\\beta}) \\right) + \\sum_{j=1}^p \\left( -\\frac{1}{2} \\log(2\\pi \\sigma_j^2) - \\frac{(\\beta_j - \\mu_j)^2}{2\\sigma_j^2} \\right) + C,\n$$\n其中 $C$ 是一个与比例无关的加法常数。\n\n为了从 $\\pi(\\boldsymbol{\\beta} \\mid \\mathbf{y}, \\mathbf{X})$ 中采样，我们实现带有对称多元正态随机游走提议的 Metropolis-Hastings 算法：\n- 在第 $t$ 次迭代时，提议 $\\boldsymbol{\\beta}^{\\ast} = \\boldsymbol{\\beta}^{(t)} + \\mathbf{z}$，其中 $\\mathbf{z} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q})$，$\\mathbf{Q}$ 是指定的提议协方差矩阵，为简单起见通常为对角阵。\n- 计算接受概率\n$$\n\\alpha = \\min\\left\\{1, \\exp\\left( \\log \\pi(\\boldsymbol{\\beta}^{\\ast} \\mid \\mathbf{y}, \\mathbf{X}) - \\log \\pi(\\boldsymbol{\\beta}^{(t)} \\mid \\mathbf{y}, \\mathbf{X}) \\right) \\right\\}。\n$$\n由于提议的对称性，Hastings 修正项相互抵消。以概率 $\\alpha$ 接受提议；否则，保留 $\\boldsymbol{\\beta}^{(t)}$。\n\n从 $\\boldsymbol{\\beta}^{(0)} = \\mathbf{0}$ 开始初始化。运行指定的迭代次数。丢弃老化期（burn-in）的迭代以减轻初始状态的影响，然后通过保留每第 $k$ 个样本来稀疏化链以减少自相关；尽管从理论上讲，稀疏化并非绝对必要，但它有助于计算摘要并确保保存的样本数量是可管理的。将接受率计算为接受的提议数占总迭代次数的比例。\n\n对于后验摘要：\n- 每个系数的后验均值通过在保存的抽样上计算样本均值来估计，$\\hat{E}[\\beta_j \\mid \\mathbf{y}, \\mathbf{X}] = \\frac{1}{M} \\sum_{m=1}^M \\beta_{j}^{(m)}$。\n- 在新协变量向量 $\\mathbf{x}_{\\text{new}}$ 处的后验预测概率通过下式来估计\n$$\n\\hat{E}\\left[ \\sigma(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}) \\mid \\mathbf{y}, \\mathbf{X} \\right] = \\frac{1}{M} \\sum_{m=1}^M \\sigma\\left(\\mathbf{x}_{\\text{new}}^\\top \\boldsymbol{\\beta}^{(m)}\\right),\n$$\n其中 $\\boldsymbol{\\beta}^{(m)}$ 是经过老化和稀疏化后保存的抽样。\n\n对于每个测试用例，使用提供的种子和分布确定性地构建数据。具体来说，给定病例数 $n_{\\text{cases}}$ 和对照数 $n_{\\text{controls}}$ 以及协变量分布，使用数据生成种子为病例和对照独立抽样协变量，为病例设置 $y_i = 1$，为对照设置 $y_i = 0$，并将所有受试者堆叠起来形成带有截距列的矩阵 $\\mathbf{X}$。使用指定的先验参数 $(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2)$、提议协方差 $\\mathbf{Q}$、MCMC 提议种子、总迭代次数、老化期和稀疏化参数。按顺序计算接受率、$\\beta_0$ 的后验均值、$\\beta_1$ 的后验均值、$\\beta_2$ 的后验均值，以及在指定 $\\mathbf{x}_{\\text{new}}$ 处的后验预测概率。\n\n最后，将测试用例 A、测试用例 B 和测试用例 C 的结果汇总到一个用方括号括起来的逗号分隔列表中，按要求格式化。此设计测试了典型行为、通过先验进行正则化来处理近似分离问题，以及小样本的稳健性，反映了医学证据中的现实场景，在这些场景中，针对病例-对照数据的逻辑斯谛回归非常普遍，而贝叶斯正则化则在具有挑战性的环境中稳定了推断过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef softplus(x):\n    # Numerically stable softplus\n    # softplus(x) = log(1 + exp(x))\n    return np.where(x  0, x + np.log1p(np.exp(-x)), np.log1p(np.exp(x)))\n\ndef sigmoid(x):\n    # Numerically stable logistic function\n    # If x = 0: 1/(1+exp(-x)) ; else: exp(x)/(1+exp(x))\n    return np.where(x = 0, 1.0 / (1.0 + np.exp(-x)), np.exp(x) / (1.0 + np.exp(x)))\n\ndef log_posterior(beta, X, y, mu, sigma2):\n    # beta: (p,)\n    # X: (n, p), y: (n,)\n    eta = X @ beta\n    ll = np.sum(y * eta - softplus(eta))  # stable log-likelihood\n    # Independent normal priors\n    lp = -0.5 * np.sum(np.log(2.0 * np.pi * sigma2)) - 0.5 * np.sum(((beta - mu) ** 2) / sigma2)\n    return ll + lp\n\ndef metropolis_hastings(initial_beta, X, y, mu, sigma2, proposal_cov, n_iter, rng):\n    p = initial_beta.shape[0]\n    beta = initial_beta.copy()\n    samples = np.zeros((n_iter, p))\n    accept_count = 0\n    current_logpost = log_posterior(beta, X, y, mu, sigma2)\n    # Cholesky of proposal covariance for efficient sampling\n    chol = np.linalg.cholesky(proposal_cov)\n    for t in range(n_iter):\n        z = rng.normal(size=p)\n        proposal = beta + chol @ z\n        proposal_logpost = log_posterior(proposal, X, y, mu, sigma2)\n        log_alpha = proposal_logpost - current_logpost\n        if np.log(rng.uniform())  log_alpha:\n            beta = proposal\n            current_logpost = proposal_logpost\n            accept_count += 1\n        samples[t, :] = beta\n    return samples, accept_count\n\ndef generate_case_control(seed, n_cases, n_controls, dist_cases, dist_controls):\n    \"\"\"\n    dist_cases/controls: dict with keys 'x1', 'x2' specifying distributions:\n      For Bernoulli: ('bern', p)\n      For Normal: ('norm', mu, sigma)\n    Returns X (n,3) with intercept, y (n,)\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # Cases\n    if dist_cases['x1'][0] == 'bern':\n        x1_cases = rng.binomial(1, dist_cases['x1'][1], size=n_cases).astype(float)\n    else:\n        x1_cases = rng.normal(dist_cases['x1'][1], dist_cases['x1'][2], size=n_cases)\n    if dist_cases['x2'][0] == 'bern':\n        x2_cases = rng.binomial(1, dist_cases['x2'][1], size=n_cases).astype(float)\n    else:\n        x2_cases = rng.normal(dist_cases['x2'][1], dist_cases['x2'][2], size=n_cases)\n    y_cases = np.ones(n_cases, dtype=float)\n    # Controls\n    if dist_controls['x1'][0] == 'bern':\n        x1_controls = rng.binomial(1, dist_controls['x1'][1], size=n_controls).astype(float)\n    else:\n        x1_controls = rng.normal(dist_controls['x1'][1], dist_controls['x1'][2], size=n_controls)\n    if dist_controls['x2'][0] == 'bern':\n        x2_controls = rng.binomial(1, dist_controls['x2'][1], size=n_controls).astype(float)\n    else:\n        x2_controls = rng.normal(dist_controls['x2'][1], dist_controls['x2'][2], size=n_controls)\n    y_controls = np.zeros(n_controls, dtype=float)\n    # Stack\n    x1 = np.concatenate([x1_cases, x1_controls])\n    x2 = np.concatenate([x2_cases, x2_controls])\n    y = np.concatenate([y_cases, y_controls])\n    intercept = np.ones_like(y)\n    X = np.column_stack([intercept, x1, x2])\n    return X, y\n\ndef posterior_predictive_prob(samples, x_new):\n    # samples: (m, p)\n    # x_new: (p,)\n    eta = samples @ x_new\n    probs = sigmoid(eta)\n    return float(np.mean(probs))\n\ndef summarize_chain(samples, burn_in, thin):\n    # Return thinned samples after burn-in\n    post = samples[burn_in:]\n    if thin  1:\n        post = post[::thin]\n    return post\n\ndef run_test_case(X, y, mu, sigma2, prop_cov, n_iter, burn_in, thin, mcmc_seed, x_new):\n    rng = np.random.default_rng(mcmc_seed)\n    initial_beta = np.zeros(X.shape[1], dtype=float)\n    samples, accept_count = metropolis_hastings(initial_beta, X, y, mu, sigma2, prop_cov, n_iter, rng)\n    post = summarize_chain(samples, burn_in, thin)\n    accept_rate = accept_count / n_iter\n    beta_mean = np.mean(post, axis=0)\n    p_pred = posterior_predictive_prob(post, x_new)\n    return accept_rate, beta_mean, p_pred\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Test Case A\n    X_A, y_A = generate_case_control(\n        seed=314159,\n        n_cases=50, n_controls=50,\n        dist_cases={'x1': ('bern', 0.6), 'x2': ('norm', 0.3, 1.0)},\n        dist_controls={'x1': ('bern', 0.3), 'x2': ('norm', -0.3, 1.0)}\n    )\n    mu_A = np.array([0.0, 0.0, 0.0])\n    sigma2_A = np.array([25.0, 9.0, 9.0])\n    prop_cov_A = np.diag([0.05**2, 0.05**2, 0.05**2])\n    n_iter_A, burn_A, thin_A = 12000, 6000, 6\n    mcmc_seed_A = 271828\n    x_new_A = np.array([1.0, 1.0, 0.5])\n\n    # Test Case B\n    X_B, y_B = generate_case_control(\n        seed=161803,\n        n_cases=40, n_controls=40,\n        dist_cases={'x1': ('norm', 2.5, 0.7), 'x2': ('bern', 0.9)},\n        dist_controls={'x1': ('norm', -2.5, 0.7), 'x2': ('bern', 0.1)}\n    )\n    mu_B = np.array([0.0, 0.0, 0.0])\n    sigma2_B = np.array([25.0, 4.0, 4.0])\n    prop_cov_B = np.diag([0.02**2, 0.02**2, 0.02**2])\n    n_iter_B, burn_B, thin_B = 16000, 8000, 8\n    mcmc_seed_B = 141421\n    x_new_B = np.array([1.0, 0.0, 1.0])\n\n    # Test Case C\n    X_C, y_C = generate_case_control(\n        seed=123457,\n        n_cases=8, n_controls=12,\n        dist_cases={'x1': ('bern', 0.5), 'x2': ('norm', 0.1, 1.0)},\n        dist_controls={'x1': ('bern', 0.4), 'x2': ('norm', -0.1, 1.0)}\n    )\n    mu_C = np.array([0.0, 0.0, 0.0])\n    sigma2_C = np.array([100.0, 16.0, 16.0])\n    prop_cov_C = np.diag([0.08**2, 0.08**2, 0.08**2])\n    n_iter_C, burn_C, thin_C = 10000, 5000, 5\n    mcmc_seed_C = 57721\n    x_new_C = np.array([1.0, 1.0, -0.2])\n\n    results = []\n\n    # Run A\n    acc_A, beta_mean_A, p_pred_A = run_test_case(\n        X_A, y_A, mu_A, sigma2_A, prop_cov_A, n_iter_A, burn_A, thin_A, mcmc_seed_A, x_new_A\n    )\n    results.extend([acc_A, beta_mean_A[0], beta_mean_A[1], beta_mean_A[2], p_pred_A])\n\n    # Run B\n    acc_B, beta_mean_B, p_pred_B = run_test_case(\n        X_B, y_B, mu_B, sigma2_B, prop_cov_B, n_iter_B, burn_B, thin_B, mcmc_seed_B, x_new_B\n    )\n    results.extend([acc_B, beta_mean_B[0], beta_mean_B[1], beta_mean_B[2], p_pred_B])\n\n    # Run C\n    acc_C, beta_mean_C, p_pred_C = run_test_case(\n        X_C, y_C, mu_C, sigma2_C, prop_cov_C, n_iter_C, burn_C, thin_C, mcmc_seed_C, x_new_C\n    )\n    results.extend([acc_C, beta_mean_C[0], beta_mean_C[1], beta_mean_C[2], p_pred_C])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}