{
    "hands_on_practices": [
        {
            "introduction": "为了设计能有效区分模型的实验，我们首先需要一种量化它们之间差异的方法。Kullback-Leibler ($D_{KL}$) 散度是信息论中的一个基本概念，它衡量了两个概率分布之间的“距离”。本练习将指导您从第一性原理出发，为两个相互竞争的泊松模型推导出 $D_{KL}$，这在合成生物学中是模拟分子计数的常见情景。",
            "id": "3924552",
            "problem": "一个合成基因表达系统被设计出来，它带有一个光遗传学转录激活因子，该激活因子在一个固定的测定窗口内以可控的强度（设计）$d>0$被照亮。对于给定的$d$，记录单细胞信使核糖核酸（mRNA）的计数$Y_d$。两个相互竞争的模型$\\mathcal{M}_0$和$\\mathcal{M}_1$假设$Y_d$分别遵循均值为$\\lambda_0(d)$和$\\lambda_1(d)$的泊松分布，其中对于所有允许的$d$，$\\lambda_0(d)>0$且$\\lambda_1(d)>0$。假设在每个模型下，计数的概率质量函数为 $p_j(y\\mid d)=\\exp(-\\lambda_j(d))\\,\\lambda_j(d)^y/y!$，其中 $y\\in\\{0,1,2,\\ldots\\}$ 且 $j\\in\\{0,1\\}$。仅使用Kullback–Leibler（KL）散度的基本定义和泊松概率质量函数，推导从$\\mathcal{M}_0$到$\\mathcal{M}_1$的Kullback–Leibler散度$D_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right)$的闭式解析表达式。该表达式应为$d$的函数，且仅用$\\lambda_0(d)$和$\\lambda_1(d)$表示。请以闭式形式提供您的最终表达式。无需进行数值评估，也无需四舍五入。最终答案必须是单一的解析表达式，且不得包含单位。",
            "solution": "该问题是有效的，因为它具有科学依据、提法明确、客观，并包含唯一数学推导所需的所有必要信息。所描述的场景是信息论在定量生物学中用于模型判别的标准应用。\n\n目标是推导从模型$\\mathcal{M}_0$到模型$\\mathcal{M}_1$的Kullback–Leibler（KL）散度的闭式表达式，记为$D_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right)$。这些模型描述了离散随机变量$Y_d$（mRNA计数）的概率分布，该变量可以在非负整数集合 $y \\in \\{0, 1, 2, \\ldots\\}$ 中取值。\n\n对于定义在同一样本空间$\\mathcal{Y}$上的两个离散概率质量函数（PMF）$p_0(y)$和$p_1(y)$，Kullback–Leibler散度的基本定义由下式给出：\n$$\nD_{KL}(P_0 \\,\\|\\, P_1) = \\sum_{y \\in \\mathcal{Y}} p_0(y) \\ln\\left(\\frac{p_0(y)}{p_1(y)}\\right)\n$$\n在此表达式中，$\\ln(\\cdot)$表示自然对数。求和是对所有可能的结果$y$进行的。\n\n对于给定问题，两个分布是$P_0(\\cdot\\mid d)$和$P_1(\\cdot\\mid d)$，分别对应于模型$\\mathcal{M}_0$和$\\mathcal{M}_1$。两者都是泊松分布，其各自的概率质量函数为：\n$$\np_0(y \\mid d) = \\frac{\\exp(-\\lambda_0(d))\\,\\lambda_0(d)^y}{y!}\n$$\n$$\np_1(y \\mid d) = \\frac{\\exp(-\\lambda_1(d))\\,\\lambda_1(d)^y}{y!}\n$$\n样本空间为$\\mathcal{Y}=\\{0, 1, 2, \\ldots\\}$。应用KL散度的定义，我们得到：\n$$\nD_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right) = \\sum_{y=0}^{\\infty} p_0(y \\mid d) \\ln\\left(\\frac{p_0(y \\mid d)}{p_1(y \\mid d)}\\right)\n$$\n首先，我们分析对数内的项，即两个概率质量函数的比率：\n$$\n\\frac{p_0(y \\mid d)}{p_1(y \\mid d)} = \\frac{\\frac{\\exp(-\\lambda_0(d))\\,\\lambda_0(d)^y}{y!}}{\\frac{\\exp(-\\lambda_1(d))\\,\\lambda_1(d)^y}{y!}}\n$$\n阶乘项$y!$相互抵消。我们可以重新整理剩余的项：\n$$\n\\frac{p_0(y \\mid d)}{p_1(y \\mid d)} = \\frac{\\exp(-\\lambda_0(d))}{\\exp(-\\lambda_1(d))} \\cdot \\frac{\\lambda_0(d)^y}{\\lambda_1(d)^y} = \\exp(\\lambda_1(d) - \\lambda_0(d)) \\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)^y\n$$\n接下来，我们取该比率的自然对数。使用对数的性质 $\\ln(ab) = \\ln(a) + \\ln(b)$ 和 $\\ln(a^b) = b\\ln(a)$：\n$$\n\\ln\\left(\\frac{p_0(y \\mid d)}{p_1(y \\mid d)}\\right) = \\ln\\left(\\exp(\\lambda_1(d) - \\lambda_0(d))\\right) + \\ln\\left(\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)^y\\right)\n$$\n$$\n\\ln\\left(\\frac{p_0(y \\mid d)}{p_1(y \\mid d)}\\right) = (\\lambda_1(d) - \\lambda_0(d)) + y \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)\n$$\n条件$\\lambda_0(d) > 0$和$\\lambda_1(d) > 0$确保了对数的参数是良定义且为正的。\n\n现在，我们将此表达式代回到KL散度的求和公式中：\n$$\nD_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right) = \\sum_{y=0}^{\\infty} p_0(y \\mid d) \\left[ (\\lambda_1(d) - \\lambda_0(d)) + y \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right) \\right]\n$$\n我们可以分配$p_0(y \\mid d)$项，并利用求和的线性性质将表达式分为两部分：\n$$\nD_{KL} = \\sum_{y=0}^{\\infty} p_0(y \\mid d) (\\lambda_1(d) - \\lambda_0(d)) + \\sum_{y=0}^{\\infty} p_0(y \\mid d) \\cdot y \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)\n$$\n我们分别评估每个求和。对于第一项，因子$(\\lambda_1(d) - \\lambda_0(d))$相对于求和指数$y$是一个常数：\n$$\n\\sum_{y=0}^{\\infty} p_0(y \\mid d) (\\lambda_1(d) - \\lambda_0(d)) = (\\lambda_1(d) - \\lambda_0(d)) \\sum_{y=0}^{\\infty} p_0(y \\mid d)\n$$\n根据定义，一个概率质量函数在其整个样本空间上的总和等于$1$。因此，$\\sum_{y=0}^{\\infty} p_0(y \\mid d) = 1$。第一项简化为：\n$$\n\\lambda_1(d) - \\lambda_0(d)\n$$\n对于第二项，因子$\\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)$相对于$y$也是一个常数：\n$$\n\\sum_{y=0}^{\\infty} p_0(y \\mid d) \\cdot y \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right) = \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right) \\sum_{y=0}^{\\infty} y \\cdot p_0(y \\mid d)\n$$\n求和$\\sum_{y=0}^{\\infty} y \\cdot p_0(y \\mid d)$是在分布$P_0(\\cdot \\mid d)$下随机变量$Y_d$的期望值（或均值）的定义。对于参数为$\\lambda_0(d)$的泊松分布，其均值恰好是$\\lambda_0(d)$。因此：\n$$\n\\sum_{y=0}^{\\infty} y \\cdot p_0(y \\mid d) = \\mathbb{E}_{Y_d \\sim P_0}[Y_d] = \\lambda_0(d)\n$$\n第二项简化为：\n$$\n\\lambda_0(d) \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)\n$$\n将两个简化部分合并，得到KL散度的最终表达式：\n$$\nD_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right) = (\\lambda_1(d) - \\lambda_0(d)) + \\lambda_0(d) \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right)\n$$\n为清晰起见，重新排列各项，得到最终的闭式解析表达式：\n$$\nD_{KL}\\!\\left(P_0(\\cdot\\mid d)\\,\\|\\,P_1(\\cdot\\mid d)\\right) = \\lambda_0(d) \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right) - \\lambda_0(d) + \\lambda_1(d)\n$$\n此表达式通过模型预测的均值$\\lambda_0(d)$和$\\lambda_1(d)$成为设计参数$d$的函数，符合题目要求。",
            "answer": "$$\n\\boxed{\\lambda_0(d) \\ln\\left(\\frac{\\lambda_0(d)}{\\lambda_1(d)}\\right) - \\lambda_0(d) + \\lambda_1(d)}\n$$"
        },
        {
            "introduction": "一个为最优地估计模型参数而设计的实验（例如，D-最优设计）可能并非区分该模型与竞争模型的最佳选择。这个练习旨在阐明这个关键且违反直觉的概念。您将发现，对于两个常见的希尔函数模型，能够提供关于某一关键参数最多信息的实验条件，恰好也是这两个模型完全无法区分的点。",
            "id": "3924608",
            "problem": "考虑用于一个在单一胞外诱导剂浓度下、于稳态时进行测量的合成基因表达模块的两个候选动态输入-输出模型。输出信号使用加性高斯噪声进行建模。设实验设计包括选择一个诱导剂水平 $x \\in (0,\\infty)$，并对潜均值输出 $\\mu(x)$ 进行一次含噪测量，得到 $y^{\\mathrm{obs}}$。该噪声是独立同分布的高斯噪声，其方差 $\\sigma^{2}$ 已知。\n\n这两个候选模型是 Hill 型输入-输出映射，具有相同的最大活性 $V$ 和半激活参数 $K$，但 Hill 系数不同。模型 $M_{1}$（Michaelis-Menten 形式，Hill 系数 $n=1$）为\n$$\n\\mu_{1}(x;V,K) \\;=\\; \\frac{V\\,x}{K + x},\n$$\n模型 $M_{2}$（立方 Hill 形式，Hill 系数 $n=3$）为\n$$\n\\mu_{2}(x;V,K) \\;=\\; \\frac{V\\,x^{3}}{K^{3} + x^{3}}.\n$$\n\n测量模型为 $y^{\\mathrm{obs}}(x) = \\mu_{j}(x;V,K) + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$ 且 $j \\in \\{1,2\\}$ 表示所用模型。假设标称参数值 $V_{0} = 1$ 和 $K_{0} = 1$ 是准确的，并且实验设计是在这些标称值处进行局部选择的。\n\n使用的定义如下：\n- 在高斯噪声下，对于标量参数 $\\theta$ 的费雪信息矩阵 (FIM) 为 $I(\\theta;x) = \\frac{1}{\\sigma^{2}}\\left(\\frac{\\partial \\mu(x;\\theta)}{\\partial \\theta}\\right)^{2}$。对于单个参数，行列式最优性 (D-最优性) 简化为关于 $x$ 最大化 $I(\\theta;x)$。\n- 从一个均值为 $\\mu_{a}(x)$ 的高斯模型到另一个均值为 $\\mu_{b}(x)$ 且方差均为 $\\sigma^{2}$ 的高斯模型的 Kullback-Leibler (KL) 散度为 \n$$\nD_{\\mathrm{KL}}(a\\parallel b;x) \\;=\\; \\frac{1}{2\\,\\sigma^{2}}\\left(\\mu_{a}(x) - \\mu_{b}(x)\\right)^{2}.\n$$\n\n任务：\n1. 从这些定义出发，确定在 $(V_{0},K_{0})$ 处、通过单次观测来估计模型 $M_{1}$ 中标量参数 $K$ 的局部行列式最优设计 $x^{\\mathrm{D}}$。\n2. 使用相同的标称值，在 $x^{\\mathrm{D}}$ 处评估 KL 散度 $D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x)$，并论证该设计是最大化还是最小化了模型的可区分性。\n3. 在 $(V_{0},K_{0})$ 条件下，给出一个明确的输入 $x \\in (0,\\infty)$，使得 $D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x) > 0$。\n4. 在 $(V_{0},K_{0})$ 条件下，设 $x^{\\mathrm{KL}}$ 表示任意一个能使 KL 散度相对于 $x^{\\mathrm{D}}$ 处的值严格增加的输入。计算比率\n$$\nR \\;=\\; \\frac{D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{D}})}{D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{KL}})}.\n$$\n\n将 $R$ 的最终值作为你的答案。无需单位。如果得到数值，除非另有说明，否则不要进行四舍五入；精确值优先。",
            "solution": "该问题被验证为自洽的、有科学依据的、且定义明确的。这些问题，尽管揭示了实验设计中的一个微妙之处，但在形式上是明确的，并且存在一个唯一的、可验证的解。我们按顺序处理每个任务来求解。\n\n两个候选模型由以下均值输出函数给出：\n$$\n\\mu_{1}(x;V,K) \\;=\\; \\frac{V\\,x}{K + x}\n$$\n$$\n\\mu_{2}(x;V,K) \\;=\\; \\frac{V\\,x^{3}}{K^{3} + x^{3}}\n$$\n标称参数值为 $V_{0} = 1$ 和 $K_{0} = 1$。测量噪声是均值为 $0$、方差为 $\\sigma^2$ 的高斯噪声。\n\n首先，我们解决在模型 $M_{1}$ 中为估计参数 $K$ 而确定局部行列式最优设计 $x^{\\mathrm{D}}$ 的问题。对于单个参数，D-最优性等价于最大化费雪信息。参数 $K$ 的费雪信息由下式给出：\n$$\nI(K;x) = \\frac{1}{\\sigma^{2}}\\left(\\frac{\\partial \\mu_{1}(x;V,K)}{\\partial K}\\right)^{2}\n$$\n我们必须首先计算 $\\mu_{1}$ 对 $K$ 的偏导数：\n$$\n\\frac{\\partial \\mu_{1}}{\\partial K} = \\frac{\\partial}{\\partial K}\\left(\\frac{V\\,x}{K + x}\\right) = V\\,x \\cdot \\frac{\\partial}{\\partial K}\\left((K+x)^{-1}\\right) = V\\,x \\cdot (-1)(K+x)^{-2} = -\\frac{V\\,x}{(K+x)^{2}}\n$$\n将此代入费雪信息的表达式中，得到：\n$$\nI(K;x) = \\frac{1}{\\sigma^{2}}\\left(-\\frac{V\\,x}{(K+x)^{2}}\\right)^{2} = \\frac{V^{2}x^{2}}{\\sigma^{2}(K+x)^{4}}\n$$\n为了找到局部最优设计，我们在标称参数值 $V_{0}=1$ 和 $K_{0}=1$ 处评估此表达式：\n$$\nI(K;x)\\big|_{V=1,K=1} = \\frac{1^{2}x^{2}}{\\sigma^{2}(1+x)^{4}} = \\frac{1}{\\sigma^{2}}\\frac{x^{2}}{(1+x)^{4}}\n$$\n为了关于输入 $x \\in (0, \\infty)$ 最大化 $I(K;x)$，我们需要最大化函数 $f(x) = \\frac{x^{2}}{(1+x)^{4}}$，因为 $\\frac{1}{\\sigma^2}$ 是一个正常数。我们通过将 $f(x)$ 的一阶导数设为零来找到临界点：\n$$\nf'(x) = \\frac{d}{dx}\\left(\\frac{x^{2}}{(1+x)^{4}}\\right) = \\frac{2x(1+x)^{4} - x^{2} \\cdot 4(1+x)^{3}}{((1+x)^{4})^{2}} = \\frac{2x(1+x) - 4x^{2}}{(1+x)^{5}}\n$$\n对于 $x>0$，将分子设为零：\n$$\n2x(1+x) - 4x^{2} = 0\n$$\n$$\n2x + 2x^{2} - 4x^{2} = 0\n$$\n$$\n2x - 2x^{2} = 0\n$$\n$$\n2x(1-x) = 0\n$$\n因为 $x \\in (0,\\infty)$，唯一的临界点是 $x=1$。为了确认这是一个最大值，我们可以检查 $f'(x)$ 的符号。对于 $x > 0$，分母 $(1+x)^{5}$ 是正的。分子 $2x(1-x)$ 在 $x \\in (0,1)$ 时为正，在 $x \\in (1,\\infty)$ 时为负。因此，$f(x)$ 在 $x<1$ 时递增，在 $x>1$ 时递减，这证实了 $x=1$ 是一个局部最大值。因此，局部 D-最优设计为 $x^{\\mathrm{D}} = 1$。\n\n其次，我们在这个最优设计点 $x^{\\mathrm{D}}=1$ 处评估 Kullback-Leibler (KL) 散度 $D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x)$。KL 散度的定义为：\n$$\nD_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x) = \\frac{1}{2\\sigma^{2}}(\\mu_{1}(x) - \\mu_{2}(x))^{2}\n$$\n我们在标称参数 $(V_{0}=1, K_{0}=1)$ 和设计点 $x^{\\mathrm{D}}=1$ 处评估模型输出：\n$$\n\\mu_{1}(x=1; V=1, K=1) = \\frac{1 \\cdot 1}{1+1} = \\frac{1}{2}\n$$\n$$\n\\mu_{2}(x=1; V=1, K=1) = \\frac{1 \\cdot 1^{3}}{1^{3}+1^{3}} = \\frac{1}{1+1} = \\frac{1}{2}\n$$\n在 $x=1$ 处，两个模型的输出是相同的。将这些值代入 KL 散度公式：\n$$\nD_{\\mathrm{KL}}(M_{1}\\parallel M_{2}; x^{\\mathrm{D}}=1) = \\frac{1}{2\\sigma^{2}}\\left(\\frac{1}{2} - \\frac{1}{2}\\right)^{2} = \\frac{1}{2\\sigma^{2}}(0)^{2} = 0\n$$\nKL 散度是当一个模型被用来近似另一个模型时信息损失的度量；它量化了两个概率模型的可区分性。KL 散度为 0 表示在给定的实验条件下，这两个模型是不可区分的。因此，设计 $x^{\\mathrm{D}}=1$ 虽然对于在模型 $M_1$ 中估计参数 $K$ 是最优的，但同时它也是用于区分模型 $M_1$ 和模型 $M_2$ 的最差设计，因为它完全最小化了它们的可区分性。\n\n第三，我们必须给出一个明确的输入 $x \\in (0,\\infty)$，使得 $D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x) > 0$。KL 散度为零当且仅当 $\\mu_{1}(x) = \\mu_{2}(x)$。在标称参数下，这等价于：\n$$\n\\frac{x}{1+x} = \\frac{x^{3}}{1+x^{3}}\n$$\n对于 $x>0$，我们可以两边同乘以 $(1+x)(1+x^3)$ 并除以 $x$：\n$$\n1+x^{3} = x^{2}(1+x) \\implies 1+x^{3} = x^{2}+x^{3} \\implies 1 = x^{2}\n$$\n由于 $x \\in (0,\\infty)$，唯一的解是 $x=1$。因此，对于任何满足 $x \\neq 1$ 的 $x \\in (0,\\infty)$，模型输出将会不同，且 KL 散度将严格为正。作为一个明确的例子，我们可以选择 $x=2$：\n$$\n\\mu_{1}(2) = \\frac{2}{1+2} = \\frac{2}{3}\n$$\n$$\n\\mu_{2}(2) = \\frac{2^{3}}{1+2^{3}} = \\frac{8}{9}\n$$\n由于 $\\mu_{1}(2) \\neq \\mu_{2}(2)$，KL 散度为正：$D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};2) = \\frac{1}{2\\sigma^{2}}(\\frac{2}{3}-\\frac{8}{9})^2 > 0$。\n\n第四，我们计算比率 $R = \\frac{D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{D}})}{D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{KL}})}$。\n我们已经求得分子为：\n$$\nD_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{D}}) = 0\n$$\n问题将 $x^{\\mathrm{KL}}$ 定义为任意一个能使 KL 散度相对于 $x^{\\mathrm{D}}$ 处的值严格增加的输入，这意味着：\n$$\nD_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{KL}}) > D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{D}})\n$$\n代入分子的值，该条件变为：\n$$\nD_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{KL}}) > 0\n$$\n根据我们分析的第三部分，我们知道这样的 $x^{\\mathrm{KL}}$ 是存在的；除 $x=1$ 外，任何 $x \\in (0,\\infty)$ 都满足此条件。对于任何这样的 $x^{\\mathrm{KL}}$ 选择，比率 $R$ 的分母都是一个严格为正的数。因此，该比率为：\n$$\nR = \\frac{0}{D_{\\mathrm{KL}}(M_{1}\\parallel M_{2};x^{\\mathrm{KL}})} = 0\n$$\n这个结果与 $x^{\\mathrm{KL}}$ 的具体选择无关，只要它满足给定的条件。$R$ 的最终值为 $0$。",
            "answer": "$$\n\\boxed{0}\n$$"
        },
        {
            "introduction": "在实践中，我们区分模型的能力不仅受其平均预测值差异的影响，也受到测量噪声和未知参数所带来的不确定性的限制。本练习通过构建一个基于灵敏度的判别分数，将这些现实因素整合起来。您将通过计算该分数来选择最优的实验条件，以最大化两个模型预测值之间的分离程度与其总不确定性的比值。",
            "id": "3924566",
            "problem": "一个合成基因线路在浓度为 $u$ (单位为纳摩尔) 的小分子诱导下表达一个荧光报告基因。两个相互竞争的稳态模型 $M_{1}$ 和 $M_{2}$ 描述了在诱导后固定采样时间的报告基因强度 $y$ (单位为任意单位 (a.u.))。每个模型 $M_{i}$ 都有一个单一的不确定增益参数 $\\alpha_{i}$，以及在 $u \\in \\{\\,20, 50, 100\\,\\}$ 纳摩尔浓度下已知的标称平均预测值 $\\mu_{i}(u)$，同时还有在相同 $u$ 值下的局部灵敏度 $s_{i}(u) = \\partial y_{i}/\\partial \\alpha_{i}$。参数先验为高斯分布，其方差分别为 $\\operatorname{Var}(\\alpha_{1}) = 2500$ a.u.² 和 $\\operatorname{Var}(\\alpha_{2}) = 3600$ a.u.²。测量噪声为零均值高斯分布，其方差为 $\\sigma^{2} = 900$ a.u.²。所有不确定性来源在模型间和测量中都是相互独立的。\n\n在候选设计点上的标称均值和灵敏度如下：\n- 在 $u = 20$ 纳摩尔时：$\\mu_{1}(20) = 300$ a.u.，$\\mu_{2}(20) = 260$ a.u.， $s_{1}(20) = 0.30$， $s_{2}(20) = 0.28$。\n- 在 $u = 50$ 纳摩尔时：$\\mu_{1}(50) = 700$ a.u.，$\\mu_{2}(50) = 550$ a.u.， $s_{1}(50) = 0.70$， $s_{2}(50) = 0.61$。\n- 在 $u = 100$ 纳摩尔时：$\\mu_{1}(100) = 900$ a.u.，$\\mu_{2}(100) = 800$ a.u.， $s_{1}(100) = 0.90$， $s_{2}(100) = 0.82$。\n\n使用关于标称 $\\alpha_{i}$ 的一阶（线性）不确定性传播方法，将每个 $y_{i}(u)$ 建模为均值为 $\\mu_{i}(u)$，方差由局部灵敏度和参数方差确定并加上测量方差的高斯分布。基于这些基础和独立高斯变量的性质，构建一个基于灵敏度的标量区分分数，该分数用模型均值之差的不确定性来标准化模型均值分离度的平方。并在每个候选浓度 $u \\in \\{\\,20, 50, 100\\,\\}$ 纳摩尔下计算此分数。选择能使该分数最大化的诱导剂浓度 $u$（单位为纳摩尔）。报告所选的 $u$ 值（单位为纳摩尔）。除了使用所提供的值进行精确算术运算外，无需进行舍入。",
            "solution": "该问题要求选择一个最优实验设计，即诱导剂浓度 $u$，以最大化区分两个竞争模型 $M_{1}$ 和 $M_{2}$ 的能力。区分的标准是一个分数，该分数将模型预测的差异与这些预测的总不确定性联系起来。分析过程分三步进行：首先，量化每个模型预测的总不确定性；其次，构建区分分数；第三，为每个候选设计计算此分数以找出最大值。\n\n在诱导剂浓度为 $u$ 时，模型 $M_{i}$ 预测的报告基因强度 $y_{i}(u)$ 的总不确定性来自两个独立的来源：模型参数 $\\alpha_{i}$ 的不确定性和测量噪声。\n\n首先，我们使用围绕标称参数值的一阶泰勒级数近似，将参数 $\\alpha_{i}$ 的不确定性传播到输出 $y_{i}$。模型输出近似为：\n$$y_{i} \\approx \\mu_{i}(u) + s_{i}(u) (\\alpha_{i} - \\bar{\\alpha}_{i})$$\n其中 $\\mu_{i}(u)$ 是标称平均预测值，$s_{i}(u) = \\partial y_{i}/\\partial \\alpha_{i}$ 是局部灵敏度，$\\bar{\\alpha}_{i}$ 是参数 $\\alpha_{i}$ 的标称值。那么，由参数不确定性 $\\operatorname{Var}(\\alpha_{i})$ 引起的 $y_{i}$ 的方差由下式给出：\n$$\\operatorname{Var}(y_{i})_{\\text{param}} = \\operatorname{Var}\\left(s_{i}(u) (\\alpha_{i} - \\bar{\\alpha}_{i})\\right) = s_{i}(u)^{2} \\operatorname{Var}(\\alpha_{i})$$\n\n其次，模型 $M_{i}$ 下一次测量的总方差，记为 $\\sigma_{i}^{2}(u)$，是传播的参数方差和测量噪声方差 $\\sigma^{2}$ 的和，因为题中说明这些来源是独立的。\n$$\\sigma_{i}^{2}(u) = \\operatorname{Var}(y_{i})_{\\text{param}} + \\sigma^{2} = s_{i}(u)^{2} \\operatorname{Var}(\\alpha_{i}) + \\sigma^{2}$$\n因此，每个模型在给定 $u$ 时的预测被视为一个高斯随机变量，$y_{i}(u) \\sim \\mathcal{N}(\\mu_{i}(u), \\sigma_{i}^{2}(u))$。\n\n问题指定了一个区分分数，我们称之为 $J(u)$，它“用模型均值之差的不确定性来标准化模型均值分离度的平方”。均值分离度的平方是 $(\\mu_{1}(u) - \\mu_{2}(u))^{2}$。模型预测之差是随机变量 $d(u) = y_{1}(u) - y_{2}(u)$。由于所有不确定性来源在模型间是独立的，变量 $y_{1}(u)$ 和 $y_{2}(u)$ 是独立的。因此，它们差值的方差是它们各自方差的和：\n$$\\operatorname{Var}(d(u)) = \\operatorname{Var}(y_{1}(u) - y_{2}(u)) = \\operatorname{Var}(y_{1}(u)) + \\operatorname{Var}(y_{2}(u)) = \\sigma_{1}^{2}(u) + \\sigma_{2}^{2}(u)$$\n那么，区分分数为：\n$$J(u) = \\frac{(\\mu_{1}(u) - \\mu_{2}(u))^{2}}{\\sigma_{1}^{2}(u) + \\sigma_{2}^{2}(u)} = \\frac{(\\mu_{1}(u) - \\mu_{2}(u))^{2}}{s_{1}(u)^{2} \\operatorname{Var}(\\alpha_{1}) + s_{2}(u)^{2} \\operatorname{Var}(\\alpha_{2}) + 2\\sigma^{2}}$$\n我们已知以下常数：\n$\\operatorname{Var}(\\alpha_{1}) = 2500$ a.u.²\n$\\operatorname{Var}(\\alpha_{2}) = 3600$ a.u.²\n$\\sigma^{2} = 900$ a.u.²\n\n现在我们为每个候选浓度 $u \\in \\{20, 50, 100\\}$ 计算 $J(u)$。\n\n对于 $u = 20$ 纳摩尔：\n$\\mu_{1}(20) = 300$， $\\mu_{2}(20) = 260$， $s_{1}(20) = 0.30$， $s_{2}(20) = 0.28$。\n分子是 $(\\mu_{1}(20) - \\mu_{2}(20))^{2} = (300 - 260)^{2} = 40^{2} = 1600$。\n分母是 $s_{1}(20)^{2} \\operatorname{Var}(\\alpha_{1}) + s_{2}(20)^{2} \\operatorname{Var}(\\alpha_{2}) + 2\\sigma^{2}$：\n$$(0.30)^{2}(2500) + (0.28)^{2}(3600) + 2(900)$$\n$$= (0.09)(2500) + (0.0784)(3600) + 1800$$\n$$= 225 + 282.24 + 1800 = 2307.24$$\n所以，$J(20) = \\frac{1600}{2307.24} \\approx 0.6935$。\n\n对于 $u = 50$ 纳摩尔：\n$\\mu_{1}(50) = 700$， $\\mu_{2}(50) = 550$， $s_{1}(50) = 0.70$， $s_{2}(50) = 0.61$。\n分子是 $(\\mu_{1}(50) - \\mu_{2}(50))^{2} = (700 - 550)^{2} = 150^{2} = 22500$。\n分母是 $s_{1}(50)^{2} \\operatorname{Var}(\\alpha_{1}) + s_{2}(50)^{2} \\operatorname{Var}(\\alpha_{2}) + 2\\sigma^{2}$：\n$$(0.70)^{2}(2500) + (0.61)^{2}(3600) + 2(900)$$\n$$= (0.49)(2500) + (0.3721)(3600) + 1800$$\n$$= 1225 + 1339.56 + 1800 = 4364.56$$\n所以，$J(50) = \\frac{22500}{4364.56} \\approx 5.1552$。\n\n对于 $u = 100$ 纳摩尔：\n$\\mu_{1}(100) = 900$， $\\mu_{2}(100) = 800$， $s_{1}(100) = 0.90$， $s_{2}(100) = 0.82$。\n分子是 $(\\mu_{1}(100) - \\mu_{2}(100))^{2} = (900 - 800)^{2} = 100^{2} = 10000$。\n分母是 $s_{1}(100)^{2} \\operatorname{Var}(\\alpha_{1}) + s_{2}(100)^{2} \\operatorname{Var}(\\alpha_{2}) + 2\\sigma^{2}$：\n$$(0.90)^{2}(2500) + (0.82)^{2}(3600) + 2(900)$$\n$$= (0.81)(2500) + (0.6724)(3600) + 1800$$\n$$= 2025 + 2420.64 + 1800 = 6245.64$$\n所以，$J(100) = \\frac{10000}{6245.64} \\approx 1.6011$。\n\n比较这些分数：\n$J(20) \\approx 0.6935$\n$J(50) \\approx 5.1552$\n$J(100) \\approx 1.6011$\n最大分数在 $u = 50$ 纳摩尔时获得。这个浓度提供了模型预测之间相对于其组合不确定性的最大分离度，使其成为旨在区分 $M_{1}$ 和 $M_{2}$ 的实验的最优选择。",
            "answer": "$$\\boxed{50}$$"
        }
    ]
}