{
    "hands_on_practices": [
        {
            "introduction": "在自动化的模型发现流程中，一个核心任务是在众多候选模型结构中进行比较和排序。本练习介绍了贝叶斯模型证据（Bayesian model evidence），这是一种用于此任务的原则性方法。通过这个理论推导和计算，您将揭示“奥卡姆因子”（Occam factor）的概念，它在数学上惩罚了过于复杂的模型，为模型选择提供了坚实的理论基础。",
            "id": "3906825",
            "problem": "在一个用于合成生物学的自动化模型发现流程中，贝叶斯模型证据被用来对质量作用动力学下的生化反应网络的候选动力学模型进行排序。考虑一个单一基因产物浓度 $x(t)$ 的候选模型，该模型由常微分方程 $dx/dt = k_1 - k_2 x$ 控制，其中参数向量为 $k = [k_1, k_2]^{\\top}$，$k_1$ 是生成速率，$k_2$ 是降解速率。设 $y = \\{y_i\\}_{i=1}^{N}$ 是在时间点 $\\{t_i\\}_{i=1}^{N}$ 对 $x(t)$ 的带噪声观测值，其观测噪声为独立的、方差已知的 $\\sigma^2$ 的高斯噪声。这个自动化模型发现任务在一个参数的高斯先验 $p(k \\mid \\mathcal{M}) = \\mathcal{N}(\\mu_0, \\Sigma_0)$ 下，评估边际似然（模型证据）$p(y \\mid \\mathcal{M})$。\n\n使用贝叶斯定理和在最大后验估计 $k^{\\ast}$ 附近的对数后验密度的二阶泰勒展开，推导模型证据 $p(y \\mid \\mathcal{M})$ 的拉普拉斯近似，用对数似然、对数先验以及在 $k^{\\ast}$ 处的负对数后验的海森矩阵表示。从此推导中，分离出奥卡姆因子（Occam factor），该因子通过从先验到后验的参数空间体积收缩来惩罚模型复杂度。将此奥卡姆因子完全用先验协方差 $\\Sigma_0$ 和从局部高斯近似获得的后验协方差 $\\Sigma_{\\text{post}}$ 表示。\n\n然后，对于一个使用 $d=2$ 个参数的流程的具体实例，假设先验协方差和在 $k^{\\ast}$ 处的负对数似然的海森矩阵（从设计和噪声模型计算得出）由下式给出：\n$$\n\\Sigma_0 = \\begin{pmatrix} 0.25  0 \\\\ 0  0.04 \\end{pmatrix}, \n\\qquad\nH_{\\text{LL}} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix}.\n$$\n假设后验负对数曲率满足 $H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1}$ 并且局部高斯近似的协方差为 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$，根据你推导的定义计算奥卡姆因子。将你的最终答案表示为一个无量纲的实数，并四舍五入到四位有效数字。",
            "solution": "该问题要求完成两个主要任务：首先，推导贝叶斯模型证据的拉普拉斯近似，并分离出代表参数空间体积收缩的奥卡姆因子；其次，为一个具体的数值实例计算这个奥卡姆因子的值。\n\n### 第1部分：拉普拉斯近似与奥卡姆因子的推导\n\n贝叶斯模型证据，或称边际似然，$p(y \\mid \\mathcal{M})$，通过将数据 $y$ 和参数 $k$ 的联合概率在整个参数空间上进行边际化来定义：\n$$p(y \\mid \\mathcal{M}) = \\int p(y, k \\mid \\mathcal{M}) dk = \\int p(y \\mid k, \\mathcal{M}) p(k \\mid \\mathcal{M}) dk$$\n其中 $k \\in \\mathbb{R}^d$ 是维度为 $d$ 的参数向量。\n\n为了计算这个积分，我们采用拉普拉斯近似。我们首先定义一个“能量”函数 $E(k)$ 作为被积函数的负对数：\n$$E(k) = -\\ln[p(y \\mid k, \\mathcal{M}) p(k \\mid \\mathcal{M})] = -\\ln p(y \\mid k, \\mathcal{M}) - \\ln p(k \\mid \\mathcal{M})$$\n注意，$E(k)$ 在相差一个加性常数的情况下，是负对数后验概率。证据积分可以重写为：\n$$p(y \\mid \\mathcal{M}) = \\int \\exp(-E(k)) dk$$\n拉普拉斯近似基于 $E(k)$ 在其最小值点附近的二阶泰勒展开。$E(k)$ 的最小值对应于后验概率的最大值，即最大后验（MAP）估计，记为 $k^{\\ast}$。在该点，$E(k)$ 的梯度为零：$\\nabla_k E(k) |_{k=k^{\\ast}} = 0$。\n\n$E(k)$ 在 $k^{\\ast}$ 附近的泰勒展开为：\n$$E(k) \\approx E(k^{\\ast}) + (k - k^{\\ast})^{\\top} (\\nabla_k E(k) |_{k=k^{\\ast}}) + \\frac{1}{2} (k - k^{\\ast})^{\\top} (H_{\\text{post}}) (k - k^{\\ast})$$\n其中 $H_{\\text{post}}$ 是 $E(k)$ 在 $k^{\\ast}$ 处计算的海森矩阵：\n$$H_{\\text{post}} = \\nabla_k^2 E(k) |_{k=k^{\\ast}}$$\n如问题所述，该海森矩阵是负对数后验在其最大值处的曲率。由于在 $k^{\\ast}$ 处的梯度为零，展开式简化为：\n$$E(k) \\approx E(k^{\\ast}) + \\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})$$\n将此近似代回证据积分中：\n$$p(y \\mid \\mathcal{M}) \\approx \\int \\exp\\left(-E(k^{\\ast}) - \\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk$$\n$$p(y \\mid \\mathcal{M}) \\approx \\exp(-E(k^{\\ast})) \\int \\exp\\left(-\\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk$$\n该积分是一个标准的多维高斯积分。被积函数与一个均值为 $k^{\\ast}$、协方差矩阵为 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$ 的高斯概率密度函数成正比。该积分的值由下式给出：\n$$\\int \\exp\\left(-\\frac{1}{2} (k - k^{\\ast})^{\\top} H_{\\text{post}} (k - k^{\\ast})\\right) dk = (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n代入此结果，我们得到模型证据的拉普拉斯近似：\n$$p(y \\mid \\mathcal{M}) \\approx \\exp(-E(k^{\\ast})) (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n现在，我们展开 $\\exp(-E(k^{\\ast}))$ 项：\n$$\\exp(-E(k^{\\ast})) = \\exp(-\\ln p(y \\mid k^{\\ast}, \\mathcal{M}) - \\ln p(k^{\\ast} \\mid \\mathcal{M})) = p(y \\mid k^{\\ast}, \\mathcal{M}) p(k^{\\ast} \\mid \\mathcal{M})$$\n所以，证据为：\n$$p(y \\mid \\mathcal{M}) \\approx p(y \\mid k^{\\ast}, \\mathcal{M}) p(k^{\\ast} \\mid \\mathcal{M}) (2\\pi)^{d/2} |\\det(H_{\\text{post}})|^{-1/2}$$\n项 $p(y \\mid k^{\\ast}, \\mathcal{M})$ 是最佳拟合似然，它衡量模型解释数据的好坏程度。余下的项构成了奥卡姆因子，它对模型复杂度进行惩罚。\n问题要求分离出代表“从先验到后验的参数空间体积收缩”的奥卡姆因子。这被解释为后验和先验概率分布的特征体积之比。对于高斯分布，该体积与协方差矩阵行列式的平方根成正比。\n\n后验分布被局部近似为一个高斯分布 $\\mathcal{N}(k^{\\ast}, \\Sigma_{\\text{post}})$，其中 $\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$。其特征体积与 $|\\det(\\Sigma_{\\text{post}})|^{1/2}$ 成正比。先验分布给定为高斯分布 $\\mathcal{N}(\\mu_0, \\Sigma_0)$，所以其特征体积与 $|\\det(\\Sigma_0)|^{1/2}$ 成正比。\n\n代表体积收缩的奥卡姆因子，我们称之为 $O_{\\text{vol}}$，是这些体积的比率：\n$$O_{\\text{vol}} = \\frac{\\text{后验体积}}{\\text{先验体积}} \\propto \\frac{|\\det(\\Sigma_{\\text{post}})|^{1/2}}{|\\det(\\Sigma_0)|^{1/2}} = \\sqrt{\\frac{\\det(\\Sigma_{\\text{post}})}{\\det(\\Sigma_0)}}$$\n如题所求，该表达式完全用先验协方差 $\\Sigma_0$ 和后验协方差 $\\Sigma_{\\text{post}}$ 来表示奥卡姆因子。\n\n### 第2部分：数值计算\n\n对于一个 $d=2$ 的参数问题，我们有以下给定值：\n- 先验协方差：$\\Sigma_0 = \\begin{pmatrix} 0.25  0 \\\\ 0  0.04 \\end{pmatrix}$\n- 在 $k^{\\ast}$ 处的负对数似然的海森矩阵：$H_{\\text{LL}} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix}$\n- 后验曲率：$H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1}$\n- 后验协方差：$\\Sigma_{\\text{post}} = H_{\\text{post}}^{-1}$\n\n我们需要计算 $O_{\\text{vol}} = \\sqrt{\\frac{\\det(\\Sigma_{\\text{post}})}{\\det(\\Sigma_0)}}$。\n使用性质 $\\det(A^{-1}) = (\\det(A))^{-1}$，我们可以写出 $\\det(\\Sigma_{\\text{post}}) = (\\det(H_{\\text{post}}))^{-1}$。奥卡姆因子变为：\n$$O_{\\text{vol}} = \\sqrt{\\frac{1}{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}} = \\frac{1}{\\sqrt{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}}$$\n这种形式在计算上更直接。\n\n首先，我们计算先验协方差矩阵 $\\Sigma_0$ 的行列式：\n$$\\det(\\Sigma_0) = (0.25) \\times (0.04) = 0.01$$\n\n接下来，我们求先验协方差矩阵的逆矩阵 $\\Sigma_0^{-1}$。由于 $\\Sigma_0$ 是对角矩阵，其逆矩阵是对角元素倒数组成的矩阵：\n$$\\Sigma_0^{-1} = \\begin{pmatrix} 1/0.25  0 \\\\ 0  1/0.04 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  25 \\end{pmatrix}$$\n\n现在，我们计算后验曲率矩阵 $H_{\\text{post}}$：\n$$H_{\\text{post}} = H_{\\text{LL}} + \\Sigma_0^{-1} = \\begin{pmatrix} 400  -120 \\\\ -120  50 \\end{pmatrix} + \\begin{pmatrix} 4  0 \\\\ 0  25 \\end{pmatrix} = \\begin{pmatrix} 404  -120 \\\\ -120  75 \\end{pmatrix}$$\n\n然后我们计算 $H_{\\text{post}}$ 的行列式：\n$$\\det(H_{\\text{post}}) = (404 \\times 75) - (-120 \\times -120) = 30300 - 14400 = 15900$$\n\n最后，我们将这些行列式代入奥卡姆因子的表达式中：\n$$O_{\\text{vol}} = \\frac{1}{\\sqrt{\\det(H_{\\text{post}}) \\det(\\Sigma_0)}} = \\frac{1}{\\sqrt{15900 \\times 0.01}} = \\frac{1}{\\sqrt{159}}$$\n现在我们计算数值：\n$$O_{\\text{vol}} = \\frac{1}{\\sqrt{159}} \\approx \\frac{1}{12.60952021} \\approx 0.07930501...$$\n将结果四舍五入到四位有效数字，得到 $0.07931$。",
            "answer": "$$\\boxed{0.07931}$$"
        },
        {
            "introduction": "在选定一个有前景的模型结构后，我们必须确保其参数能够从数据中被可靠地估计，这就是参数可辨识性（parameter identifiability）问题。本练习将使用剖面似然法（profile likelihood method）来解决这一关键问题。通过这个编码练习，您将学会如何诊断实验设计是否足以约束模型的参数，这是任何建模者都必须掌握的关键技能。",
            "id": "3906800",
            "problem": "给定一个基因调控场景，其由一个基于热力学结合平衡的希尔（Hill）激活函数建模。令 $I$ 表示诱导剂浓度（单位为 $\\mu$M），令 $y$ 表示测得的表达水平（单位为无量纲的相对荧光单位），令 $n$ 表示希尔系数。表达的经典希尔激活模型为\n$$\ny(I;\\beta_0,\\beta,K,n) \\;=\\; \\beta_0 \\;+\\; \\beta \\,\\frac{I^n}{K^n + I^n},\n$$\n其中 $\\beta_0 \\ge 0$ 是基础表达水平，$\\beta \\ge 0$ 是最大可诱导振幅， $K > 0$ 是半激活浓度。假设存在加性高斯测量噪声，这与正态模型下的最大似然估计（MLE）一致，即对于浓度 $I$ 下的每次测量 $y_{\\text{obs}}$，\n$$\ny_{\\text{obs}} \\;=\\; y(I;\\beta_0,\\beta,K,n) \\;+\\; \\varepsilon,\\quad \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2),\n$$\n其中噪声标准差 $\\sigma$ 已知。对于数据集 $\\{(I_i,y_{\\text{obs},i})\\}_{i=1}^{N}$，在独立高斯误差的假设下，忽略加性常数后，其对数似然与负的残差平方和（RSS）成正比，\n$$\n\\ell(\\beta_0,\\beta,K,n) \\;=\\; -\\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}\\left[y_{\\text{obs},i} - y(I_i;\\beta_0,\\beta,K,n)\\right]^2.\n$$\n希尔系数 $n$ 的剖面对数似然定义为\n$$\n\\ell_{\\text{prof}}(n) \\;=\\; \\max_{\\beta_0 \\ge 0,\\, \\beta \\ge 0,\\, K > 0}\\; \\ell(\\beta_0,\\beta,K,n),\n$$\n该方法通过对每个固定的 $n$ 在其他无关参数上进行最大化来消除它们。在使用机器学习（ML）进行自动化模型发现时，这种剖面分析可指导可辨识性分析并为实验设计选择提供信息：$\\ell_{\\text{prof}}(n)$ 在很宽的 $n$ 值范围内都很平坦，表明在当前数据和设计下，$n$ 是不可辨识的。\n\n你的任务是实现一个完整的程序，该程序针对每个提供的测试用例，在一系列网格化的 $n$ 值上计算归一化的剖面对数似然 $\\ell_{\\text{prof}}(n)$，并判断该剖面是否表现出平坦区域，从而指示其不可辨识性。请使用以下基于原则的规则：\n\n1. 对于指定网格上的每个固定 $n$，通过最小化残差平方和来对 $(\\beta_0,\\beta,K)$ 进行最大似然估计，同时遵守约束条件 $\\beta_0 \\ge 0$、$\\beta \\ge 0$ 和 $K > 0$。将此最小化过程解释为在已知 $\\sigma$ 的高斯噪声下的最大似然估计。\n\n2. 计算剖面 $\\ell_{\\text{prof}}(n)$ 并通过减去其最大值进行归一化，使其峰值为 $0$：\n$$\n\\tilde{\\ell}_{\\text{prof}}(n) \\;=\\; \\ell_{\\text{prof}}(n) - \\max_{n}\\ell_{\\text{prof}}(n).\n$$\n\n3. 通过两个互补的度量来量化平坦度：\n   - 峰值周围的二次曲率宽度：在最大化点 $\\hat{n}$ 的一个小邻域内，对 $\\tilde{\\ell}_{\\text{prof}}(n)$ 拟合一个二次模型以获得曲率 $a$（即 $(n-\\hat{n})^2$ 的系数）。使用单参数似然比近似，定义 $95\\%$ 的下降水平为 $d = 1.92$，并估计在该下降水平上的全宽 $w$ 由下式给出：\n   $$ w = \\begin{cases} 2\\sqrt{\\frac{d}{|a|}}  \\text{if } a  0 \\\\ +\\infty  \\text{if } a \\ge 0 \\end{cases} $$\n   - 全局下降幅度：计算 $\\Delta \\;=\\; \\left|\\min_{n}\\tilde{\\ell}_{\\text{prof}}(n)\\right|$。\n\n4. 如果 $w > 1.5$ 或 $\\Delta  0.8$，则将希尔系数 $n$ 分类为不可辨识。否则，分类为可辨识。每个测试用例返回一个布尔值：$True$ 表示不可辨识，$False$ 表示可辨识。\n\n程序必须使用从 $0.5$到 $5.0$、步长为 $0.05$ 的 $n$ 值网格来实现上述过程，尊重 $I$ 的单位 $\\mu$M，并将 $y$ 视为无量纲。所有优化都必须在允许的运行时环境中进行，并遵守对库的限制。\n\n测试套件：\n使用以下四个合成测试用例（所有用例均由您的程序内部使用固定的随机种子生成，以确保可复现性）：\n\n- 案例1（设计良好，低噪声；预期为可辨识）： \n  - 真实参数：$\\beta_0 = 0.1$, $\\beta = 1.0$, $K = 10.0$, $n_{\\text{true}} = 2.0$。\n  - 浓度 $I$（单位 $\\mu$M）：$N=20$ 个值，在 $0.1$ 到 $100.0$ 之间对数均匀分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例2（仅饱和区设计，低噪声；预期为不可辨识）：\n  - 真实参数：$\\beta_0 = 0.1$, $\\beta = 1.0$, $K = 10.0$, $n_{\\text{true}} = 2.0$。\n  - 浓度 $I$（单位 $\\mu$M）：$N=10$ 个值，在 $100.0$ 到 $200.0$ 之间线性均匀分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例3（仅亚阈值区设计，低噪声；预期为不可辨识）：\n  - 真实参数：$\\beta_0 = 0.1$, $\\beta = 1.0$, $K = 10.0$, $n_{\\text{true}} = 2.0$。\n  - 浓度 $I$（单位 $\\mu$M）：$N=10$ 个值，在 $0.01$ 到 $0.20$ 之间线性均匀分布。\n  - 噪声标准差：$\\sigma = 0.02$。\n\n- 案例4（设计良好但高噪声；预期为不可辨识）：\n  - 真实参数：$\\beta_0 = 0.1$, $\\beta = 1.0$, $K = 10.0$, $n_{\\text{true}} = 2.0$。\n  - 浓度 $I$（单位 $\\mu$M）：$N=8$ 个值，在 $0.1$ 到 $100.0$ 之间对数均匀分布。\n  - 噪声标准差：$\\sigma = 0.20$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result_1,result_2,result_3,result_4]$），其中每个 $result_i$ 是一个布尔值，指示在指定分类规则下，相应案例的希尔系数 $n$ 是否不可辨识。不应打印任何其他文本。",
            "solution": "问题陈述已经过仔细验证，并被确定为科学上合理、定义明确且客观。它在合成生物学建模和自动化模型发现领域提出了一个正式且可验证的任务。因此，我们可以着手提供一个完整的解决方案。\n\n问题的核心是从实验数据中评估希尔系数 $n$ 的可辨识性。如果现有数据足以将其值约束在一个狭窄的范围内，则该参数被认为是可辨识的。剖面对数似然为此评估提供了一个严谨的统计工具。一个尖锐的峰值剖面表明可辨识性高，而一个在宽参数值范围内平坦的剖面则表明不可辨识。该任务要求实现一种算法，以针对不同的实验场景计算和分析此剖面。\n\n解决方案分为四个主要阶段：\n1.  为每个测试用例生成合成实验数据。\n2.  在一系列网格化的 $n$ 值上计算剖面对数似然 $\\ell_{\\text{prof}}(n)$。\n3.  分析归一化的剖面 $\\tilde{\\ell}_{\\text{prof}}(n)$，以使用两个度量来量化其平坦度。\n4.  基于定量阈值将 $n$ 分类为可辨识或不可辨识。\n\n**1. 合成数据生成**\n\n对于每个测试用例，我们首先生成模拟实验测量的合成数据。真实的底层过程由希尔激活函数描述：\n$$\ny(I;\\beta_0,\\beta,K,n) \\;=\\; \\beta_0 \\;+\\; \\beta \\,\\frac{I^n}{K^n + I^n}\n$$\n其中 $I$ 是诱导剂浓度，$\\beta_0$ 是基础表达，$\\beta$ 是可诱导振幅， $K$ 是半激活浓度， $n$ 是希尔系数。\n\n对于一组诱导剂浓度 $\\{I_i\\}_{i=1}^{N}$，使用每个案例提供的真实参数值计算出真实的表达水平 $\\{y_{\\text{true},i}\\}_{i=1}^{N}$。通过向真实值添加独立同分布的高斯噪声来模拟实验测量值 $y_{\\text{obs},i}$：\n$$\ny_{\\text{obs},i} \\;=\\; y(I_i;\\beta_{0,\\text{true}},\\beta_{\\text{true}},K_{\\text{true}},n_{\\text{true}}) \\;+\\; \\varepsilon_i,\\quad \\text{where } \\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n$$\n每个案例的噪声标准差 $\\sigma$ 是已知的。所有数据生成都使用固定的随机种子进行，以确保可复现性。\n\n**2. 剖面对数似然计算**\n\n对于 $n$ 的剖面对数似然 $\\ell_{\\text{prof}}(n)$，是通过对每个固定的 $n$ 值在无关参数 $(\\beta_0, \\beta, K)$ 上最大化对数似然函数来找到的。假设存在独立高斯噪声，最大化对数似然等同于最小化残差平方和（RSS）：\n$$\n\\text{RSS}(\\beta_0,\\beta,K) \\;=\\; \\sum_{i=1}^{N}\\left[y_{\\text{obs},i} - y(I_i;\\beta_0,\\beta,K,n)\\right]^2\n$$\n因此，对于预定义网格上从 $0.5$ 到 $5.0$ 的每个 $n$，我们求解以下约束优化问题：\n$$\n\\text{RSS}_{\\min}(n) \\;=\\; \\min_{\\beta_0 \\ge 0,\\, \\beta \\ge 0,\\, K  0} \\text{RSS}(\\beta_0,\\beta,K)\n$$\n这是一个非线性最小二乘问题。我们采用 `L-BFGS-B` 算法，该算法可通过 `scipy.optimize.minimize` 使用，非常适合此类问题，因为它能处理参数所需的箱式约束（即下界）：$\\beta_0 \\ge 0$、$\\beta \\ge 0$ 和 $K  0$。为了数值稳定性，对 $K$ 的约束实现为 $K \\ge \\epsilon$，其中 $\\epsilon$ 是一个很小的正数。\n\n一旦网格中的每个 $n$ 都找到了对应的 $\\text{RSS}_{\\min}(n)$，相应的剖面对数似然值计算如下：\n$$\n\\ell_{\\text{prof}}(n) \\;=\\; -\\frac{\\text{RSS}_{\\min}(n)}{2\\sigma^2}\n$$\n\n**3. 剖面分析与可辨识性分类**\n\n为了便于在不同数据集和模型之间进行比较，通过减去其最大值来对剖面进行归一化：\n$$\n\\tilde{\\ell}_{\\text{prof}}(n) \\;=\\; \\ell_{\\text{prof}}(n) - \\max_{n'}\\ell_{\\text{prof}}(n')\n$$\n这个归一化剖面的峰值位于 $0$ 处，对应于希尔系数的最大似然估计 $\\hat{n}$。然后使用两个度量来量化此剖面的平坦度：\n\n-   **二次曲率宽度 ($w$)**：剖面在其峰值 $\\hat{n}$ 附近的形状可以通过一个二次函数 $p(n) = a(n-\\hat{n})^2 + b(n-\\hat{n}) + c$ 来近似。曲率 $a$ 是二次项的系数。这通过对 $\\tilde{\\ell}_{\\text{prof}}(n)$ 峰值周围的一个小邻域内的点拟合一个二阶多项式来获得。基于似然比理论，可以从该曲率估计一个置信区间。在下降 $d = 1.92$（对应于单参数的 95% 置信区间）处的剖面全宽由下式给出：\n    $$ w = \\begin{cases} 2\\sqrt{\\frac{d}{|a|}}  \\text{if } a  0 \\\\ +\\infty  \\text{if } a \\ge 0 \\end{cases} $$\n    在最大值处的向上曲率（$a \\ge 0$）意味着一个极其平坦或性状不良的剖面，表明不可辨识性，这通过无限宽度来体现。\n\n-   **全局下降幅度 ($\\Delta$)**：此度量捕获了在整个评估的 $n$ 范围内对数似然的总下降量。它被定义为归一化剖面最小值的绝对值：\n    $$\n    \\Delta \\;=\\; \\left|\\min_{n}\\tilde{\\ell}_{\\text{prof}}(n)\\right|\n    $$\n    一个小的 $\\Delta$ 表示即使远离最优的 $\\hat{n}$，其他 $n$ 值也几乎同样合理，这是不可辨识性的一个标志。\n\n最后，如果剖面根据指定阈值过宽或过浅，则希尔系数 $n$ 被分类为不可辨识：\n$$\n\\text{如果 } (w  1.5) \\text{ 或 } (\\Delta  0.8) \\text{，则不可辨识}\n$$\n对于不可辨识的情况返回布尔值 `True`，否则返回 `False`。\n\n**4. 实现**\n\n所述算法使用 Python 实现，利用 `numpy` 进行高效的数值计算，并使用 `scipy.optimize.minimize` 进行剖面似然计算核心的约束非线性优化。一个主函数会遍历四个指定的测试用例，每个用例都由一组真实参数和一个实验设计（浓度范围和采样）定义。对于每个案例，它会生成数据、计算剖面、分析剖面并确定可辨识性，然后将最终的布尔结果附加到一个列表中。程序最后以指定格式打印此列表。这种系统化的方法将统计可辨识性分析的原则直接转化为具体的计算工作流。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the identifiability problem for all test cases.\n    \"\"\"\n    # Set a single fixed random seed for reproducibility across all cases.\n    np.random.seed(42)\n\n    # Define the four test cases as specified in the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case 1: Well-designed, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0), # beta0, beta, K, n\n            \"I_config\": {\"type\": \"log\", \"N\": 20, \"start\": 0.1, \"end\": 100.0},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 2: Saturated-only, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"lin\", \"N\": 10, \"start\": 100.0, \"end\": 200.0},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 3: Subthreshold-only, low noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"lin\", \"N\": 10, \"start\": 0.01, \"end\": 0.20},\n            \"sigma\": 0.02\n        },\n        {\n            \"name\": \"Case 4: Well-designed, high noise\",\n            \"true_params\": (0.1, 1.0, 10.0, 2.0),\n            \"I_config\": {\"type\": \"log\", \"N\": 8, \"start\": 0.1, \"end\": 100.0},\n            \"sigma\": 0.20\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        is_non_identifiable = analyze_case(case)\n        results.append(is_non_identifiable)\n\n    # Print the final results in the required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef hill_function(params, I, n):\n    \"\"\"Calculates the Hill activation function response.\"\"\"\n    beta0, beta, K = params\n    # Use numerically stable form: 1 / ( (K/I)^n + 1 )\n    # Handle potential division by zero if I can be 0, though problem constraints avoid this.\n    with np.errstate(divide='ignore', invalid='ignore'):\n        term = 1.0 / (1.0 + (K / I)**n)\n    # If I is very small, (K/I)^n can be inf, and term becomes 0, which is correct.\n    term[np.isinf(I)] = 1.0 # If I is infinite, term is 1.\n    term[I == 0] = 0.0 # If I is zero, term is 0.\n    return beta0 + beta * term\n\n\ndef rss_objective(params, I, y_obs, n):\n    \"\"\"Calculates the Residual Sum of Squares (RSS) for the Hill model.\"\"\"\n    y_model = hill_function(params, I, n)\n    return np.sum((y_obs - y_model)**2)\n\n\ndef analyze_case(case_spec):\n    \"\"\"\n    Performs the full identifiability analysis for a single test case.\n    \"\"\"\n    # 1. Generate synthetic data\n    beta0_true, beta_true, K_true, n_true = case_spec[\"true_params\"]\n    I_config = case_spec[\"I_config\"]\n    sigma = case_spec[\"sigma\"]\n\n    if I_config[\"type\"] == 'log':\n        I = np.logspace(np.log10(I_config[\"start\"]), np.log10(I_config[\"end\"]), I_config[\"N\"])\n    else: # 'lin'\n        I = np.linspace(I_config[\"start\"], I_config[\"end\"], I_config[\"N\"])\n\n    y_true = hill_function((beta0_true, beta_true, K_true), I, n_true)\n    noise = np.random.normal(0, sigma, size=I_config[\"N\"])\n    y_obs = y_true + noise\n\n    # 2. Compute profile log-likelihood\n    n_grid = np.arange(0.5, 5.0 + 1e-9, 0.05)\n    l_prof = np.zeros_like(n_grid)\n    \n    # Heuristic initial guess for optimizer\n    beta0_guess = np.min(y_obs) if np.min(y_obs) > 0 else 1e-3\n    beta_guess = np.max(y_obs) - beta0_guess if (np.max(y_obs) - beta0_guess) > 0 else 0.1\n    mid_y_range = beta0_guess + 0.5 * beta_guess\n    k_guess_idx = np.argmin(np.abs(y_obs - mid_y_range))\n    k_guess = I[k_guess_idx]\n    x0 = [beta0_guess, beta_guess, k_guess]\n\n    bounds = [(0, None), (0, None), (1e-9, None)]\n\n    for i, n_val in enumerate(n_grid):\n        opt_result = minimize(\n            rss_objective,\n            x0,\n            args=(I, y_obs, n_val),\n            bounds=bounds,\n            method='L-BFGS-B'\n        )\n        min_rss = opt_result.fun\n        l_prof[i] = -min_rss / (2 * sigma**2)\n\n    # 3. Analyze the profile\n    if np.all(np.isinf(l_prof)) or np.all(np.isnan(l_prof)):\n        return True # Profile computation failed, indicates extreme non-identifiability\n\n    l_prof_norm = l_prof - np.max(l_prof)\n\n    # Metric 1: Global drop magnitude\n    delta = np.abs(np.min(l_prof_norm))\n\n    # Metric 2: Quadratic-curvature width\n    idx_max = np.argmax(l_prof_norm)\n    \n    # Define neighborhood for quadratic fit, handling edges\n    width_pts = 3\n    start_idx = max(0, idx_max - width_pts)\n    end_idx = min(len(n_grid), idx_max + width_pts + 1)\n    \n    if (end_idx - start_idx)  3:\n        # Not enough points for a quadratic fit, implies a pathological profile (e.g., max at edge)\n        w = np.inf\n    else:\n        n_hood = n_grid[start_idx:end_idx]\n        l_prof_hood = l_prof_norm[start_idx:end_idx]\n        \n        # Fit a 2nd-degree polynomial: a*n^2 + b*n + c\n        coeffs = np.polyfit(n_hood, l_prof_hood, 2)\n        a = coeffs[0]\n\n        d = 1.92\n        if a >= -1e-9: # Curvature is non-negative (or very close to zero)\n            w = np.inf\n        else:\n            w = 2 * np.sqrt(d / np.abs(a))\n\n    # 4. Classify based on thresholds\n    is_non_identifiable = (w > 1.5) or (delta  0.8)\n    return is_non_identifiable\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "基于前一个练习中的诊断工具，这最后一个练习将我们从诊断引向解决方案。当模型参数不可辨识时，我们通常可以通过设计信息更丰富的实验来解决问题。这个高级练习将指导您使用费雪信息（Fisher information）来计算设计一个最优的输入激励，从而最大化我们对目标参数所能获取的信息量。",
            "id": "3906793",
            "problem": "在合成生物学中，自动化模型发现通常需要选择信息丰富的输入激励，以便从含噪声的时间序列数据中估计潜在的生物物理参数。考虑一个最小的、基于机理的转录-翻译模块，该模块被建模为一个由标量输入激励驱动的一阶线性系统。动态状态 $x(t)$（可观测的报告基因水平）遵循常微分方程 $dx/dt = -k_2 x(t) + k_1 u(t)$，初始条件为零，其中 $k_1$ 和 $k_2$ 是未知的正参数，$u(t)$ 是一个可以打开和关闭的外部控制输入激励。测量值 $y_i$ 在离散时间 $t_i = i \\Delta t$（$i = 0,1,\\dots,N-1$）进行记录，并带有零均值、方差为 $\\sigma^2$ 的独立加性高斯测量噪声。仅观测报告基因 $y_i = x(t_i)$。在标准激励下，有序对 $(k_1,k_2)$ 可能难以辨识，但比率 $\\phi = k_1/k_2$ 是主要关注点。\n\n从线性系统定义、 $x(t)$ 的卷积表示以及独立高斯噪声的性质出发，为比率 $\\phi$ 推导一个基于费雪信息 (Fisher information) 的标量目标函数。使用以下基本事实作为起点：(i) 线性时不变系统的叠加和卷积，(ii) 对于具有加性独立高斯噪声的模型，费雪信息矩阵 (FIM) 为 $F = \\sigma^{-2} S^\\top S$，其中 $S$ 是灵敏度矩阵，其条目是模型输出相对于参数的偏导数，以及 (iii) delta 方法意味着对于标量变换 $\\phi = g(\\theta)$，其中 $\\theta = (k_1,k_2)$，$\\phi$ 的费雪信息为 $I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$。你不能假设任何预设的激励；相反，你必须在一个受约束的族内通过计算来优化输入模式，以最大化 $I_\\phi$。\n\n假设存在以下实验设计空间：$u(t)$ 被约束为单个连续的矩形脉冲，幅值为 $u_{\\max}$，持续时间为 $L \\Delta t$，从某个网格索引 $s \\in \\{0,1,\\dots,N-L\\}$ 开始，其中 $L$ 从一个有限的允许集合 $\\mathcal{L} \\subset \\{0,1,\\dots,N\\}$ 中选择。如果 $L=0$，则输入恒为零。对于给定的 $(k_1,k_2,\\Delta t,N,\\sigma,u_{\\max},\\mathcal{L})$，你的任务是搜索所有可行的脉冲长度 $L \\in \\mathcal{L}$ 和起始索引 $s$，以找到使比率 $\\phi = k_1/k_2$ 的费雪信息 $I_\\phi$ 最大化的输入。你必须使用上述基于费雪信息的标准，通过与离散采样网格一致的黎曼和 (Riemann sum) 近似，来精确计算 $I_\\phi$。\n\n你的程序必须为每个测试用例实现以下步骤：\n- 构建采样时间 $t_i = i \\Delta t$，其中 $i=0,\\dots,N-1$。\n- 对于一个由 $(L,s)$ 表征、幅值为 $u_{\\max}$ 的候选脉冲，构建离散输入序列 $u_j$，$j=0,\\dots,N-1$，其中当 $j \\in \\{s,\\dots,s+L-1\\}$ 时 $u_j = u_{\\max}$，否则 $u_j = 0$（如果 $L=0$，则对所有 $j$ 都有 $u_j=0$）。\n- 使用卷积表示和黎曼和计算每个采样时间的灵敏度：\n  - $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\sum_{j=0}^{i} u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n  - $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\sum_{j=0}^{i} (t_i - t_j) u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n- 构建灵敏度矩阵 $S \\in \\mathbb{R}^{N \\times 2}$，其列为 $s_{\\cdot,1}$ 和 $s_{\\cdot,2}$，然后计算费雪信息矩阵 $F = \\sigma^{-2} S^\\top S$。\n- 对于 $\\phi = k_1/k_2$，计算 $\\nabla_\\theta g(\\theta) = \\left[\\frac{\\partial \\phi}{\\partial k_1}, \\frac{\\partial \\phi}{\\partial k_2}\\right]^\\top = \\left[\\frac{1}{k_2}, -\\frac{k_1}{k_2^2}\\right]^\\top$，然后计算 $I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$。\n- 返回所有可接受的脉冲设计中最大的 $I_\\phi$。\n\n测试套件：\n对于每个案例，搜索整个可接受的设计族，并报告找到的单个最大 $I_\\phi$ 值。整个程序所需的最终输出是包含一个浮点数列表的单行，每个浮点数对应一个测试用例，四舍五入到六位小数，用方括号括起来并用逗号分隔（例如，“[1.234000,0.000000]”）。\n\n- 案例 1 (正常路径)：\n  - $k_1 = 2.0$, $k_2 = 0.8$, $\\Delta t = 0.5$, $N = 20$, $\\sigma = 0.1$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{2,4,6\\}$。\n- 案例 2 (边界情况，不允许输入)：\n  - $k_1 = 1.2$, $k_2 = 0.6$, $\\Delta t = 0.5$, $N = 20$, $\\sigma = 0.1$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{0\\}$。\n- 案例 3 (快速衰减边缘情况)：\n  - $k_1 = 1.5$, $k_2 = 3.0$, $\\Delta t = 0.2$, $N = 30$, $\\sigma = 0.2$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{3,6\\}$。\n- 案例 4 (高噪声，较长时间范围)：\n  - $k_1 = 1.0$, $k_2 = 1.0$, $\\Delta t = 0.5$, $N = 25$, $\\sigma = 1.0$, $u_{\\max} = 1.0$, $\\mathcal{L} = \\{5,10\\}$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用逗号分隔的列表，该列表用方括号括起来。列表中的每个条目是对应测试用例的最大 $I_\\phi$ 值，按上述案例顺序排列，并四舍五入到六位小数。不应打印任何其他输出。",
            "solution": "用户提供的问题陈述已经过严格评估，并被确定为 **有效**。\n\n### 问题验证\n\n**步骤 1：提取的已知条件**\n\n- **动力学系统**：一阶线性常微分方程 (ODE) $dx/dt = -k_2 x(t) + k_1 u(t)$，初始条件 $x(0) = 0$。\n- **参数**：未知的正参数 $k_1$ 和 $k_2$。\n- **输入激励**：$u(t)$ 是一个外部控制的输入。\n- **测量模型**：$y_i = x(t_i) + \\epsilon_i$，其中测量在离散时间 $t_i = i \\Delta t$（$i = 0,1,\\dots,N-1$）进行。\n- **噪声模型**：测量噪声 $\\epsilon_i$ 是独立同分布 (i.i.d.) 的高斯噪声，均值为零，方差为 $\\sigma^2$。\n- **目标参数**：比率 $\\phi = k_1/k_2$。\n- **实验设计空间**：\n    - $u(t)$ 是单个连续的矩形脉冲。\n    - 幅值：$u_{\\max}$。\n    - 持续时间：$L \\Delta t$，其中长度参数 $L$ 从一个有限集合 $\\mathcal{L} \\subset \\{0,1,\\dots,N\\}$ 中选择。如果 $L=0$，$u(t)=0$。\n    - 起始索引：$s \\in \\{0,1,\\dots,N-L\\}$。\n- **数学工具与公式**：\n    - **费雪信息矩阵 (FIM)**：$F = \\sigma^{-2} S^\\top S$，其中 $S$ 是灵敏度矩阵。\n    - **灵敏度矩阵条目 ($S_{i,j}$)**：$S_{ik} = \\frac{\\partial x(t_i)}{\\partial \\theta_k}$，其中 $\\theta = (k_1, k_2)$。\n    - **灵敏度近似（黎曼和）**：\n        - $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\sum_{j=0}^{i} u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n        - $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\sum_{j=0}^{i} (t_i - t_j) u_j \\exp\\!\\left(-k_2 (t_i - t_j)\\right) \\Delta t$。\n        - 其中 $u_j$ 是输入激励在时间 $t_j$ 的值。\n    - **变换后参数的信息（Delta 方法）**：$I_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)$，对于 $\\phi = g(\\theta)$。\n    - **变换的梯度**：对于 $\\phi = k_1/k_2$，$\\nabla_\\theta g(\\theta) = \\left[\\frac{1}{k_2}, -\\frac{k_1}{k_2^2}\\right]^\\top$。\n- **任务**：对于给定的参数集，找到能使 $I_\\phi$ 最大化的输入脉冲设计 $(L,s)$。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n问题是 **有效** 的。\n- **科学上合理**：该问题建立在系统理论（线性 ODE、卷积）、统计推断（费雪信息）和数值方法（黎曼和）的基础原则之上。该模型是简单生化过程（如转录和翻译）的标准表示，这是合成生物学中的常见主题。\n- **良构的**：问题定义了一个清晰的标量目标函数 ($I_\\phi$)，该函数将在一个有限且明确定义的实验设计搜索空间上被最大化。这种结构保证了解（一个最大值）的存在。\n- **目标明确**：问题使用精确的数学和科学语言陈述，没有主观性或歧义。\n- **自洽且一致**：为每个测试用例提供了所有必需的参数、方程和约束。数学公式内部一致，并源自标准原理。明确给出了灵敏度的离散近似，消除了计算中的任何歧义。\n\n**步骤 3：结论与行动**\n\n问题有效。将提供完整的解决方案。\n\n### 解决方案推导与算法策略\n\n目标是从一个受约束的函数族中找到一个最优的输入激励 $u(t)$，以最大化参数比率 $\\phi = k_1/k_2$ 的费雪信息 $I_\\phi$。输入激励是由长度 $L$ 和起始索引 $s$ 表征的矩形脉冲。\n\n变换后参数 $\\phi$ 的费雪信息由 delta 方法给出：\n$$\nI_\\phi = \\nabla_\\theta g(\\theta)^\\top F \\nabla_\\theta g(\\theta)\n$$\n这里，$\\theta = (k_1, k_2)$ 是模型参数的向量，$g(\\theta)=k_1/k_2$ 是标量变换。此表达式的各组成部分如下：\n\n1.  **变换的梯度，$\\nabla_\\theta g(\\theta)$**：\n    $\\phi$ 相对于 $k_1$ 和 $k_2$ 的偏导数是：\n    $$\n    \\frac{\\partial \\phi}{\\partial k_1} = \\frac{1}{k_2}\n    $$\n    $$\n    \\frac{\\partial \\phi}{\\partial k_2} = -\\frac{k_1}{k_2^2}\n    $$\n    因此，梯度向量为 $\\nabla_\\theta g(\\theta) = \\begin{bmatrix} 1/k_2   -k_1/k_2^2 \\end{bmatrix}^\\top$。对于任何给定的测试用例，$k_1$ 和 $k_2$ 的值是已知的，所以这个向量是一个常数。\n\n2.  **费雪信息矩阵， $F$**：\n    对于具有加性独立同分布高斯噪声的模型，参数 $\\theta$ 的 FIM 为：\n    $$\n    F = \\frac{1}{\\sigma^2} S^\\top S\n    $$\n    项 $\\sigma^2$ 是噪声方差，对于每个测试用例都是一个已知常数。矩阵 $S$ 是灵敏度矩阵，它捕捉了模型输出如何随参数变化。其条目为 $S_{ik} = \\frac{\\partial x(t_i)}{\\partial \\theta_k}$。\n\n3.  **灵敏度矩阵， $S$**：\n    灵敏度矩阵 $S$ 是一个 $N \\times 2$ 的矩阵，其中第一列包含相对于 $k_1$ 的灵敏度，第二列包含相对于 $k_2$ 的灵敏度，这些都在 $N$ 个采样时间点上进行评估。\n    $$\n    S = \\begin{bmatrix}\n    \\frac{\\partial x(t_0)}{\\partial k_1}  \\frac{\\partial x(t_0)}{\\partial k_2} \\\\\n    \\frac{\\partial x(t_1)}{\\partial k_1}  \\frac{\\partial x(t_1)}{\\partial k_2} \\\\\n    \\vdots  \\vdots \\\\\n    \\frac{\\partial x(t_{N-1})}{\\partial k_1}  \\frac{\\partial x(t_{N-1})}{\\partial k_2}\n    \\end{bmatrix}\n    $$\n    关键的洞见是，灵敏度矩阵 $S$ 是 $I_\\phi$ 表达式中唯一依赖于输入激励 $u(t)$ 的部分。因此，我们的优化问题简化为找到输入 $u(t)$（即脉冲 $(L,s)$），使得涉及 $S^\\top S$ 的二次型尽可能大。\n\n问题提供了灵敏度值的显式黎曼和近似：\n-   $s_{i,1} = \\frac{\\partial x(t_i)}{\\partial k_1} \\approx \\Delta t \\sum_{j=0}^{i} u_j e^{-k_2 (t_i - t_j)}$\n-   $s_{i,2} = \\frac{\\partial x(t_i)}{\\partial k_2} \\approx -k_1 \\Delta t \\sum_{j=0}^{i} (t_i - t_j) u_j e^{-k_2 (t_i - t_j)}$\n\n这些求和必须对每个时间点 $i \\in \\{0, \\dots, N-1\\}$ 进行计算。\n\n### 计算搜索过程\n\n最优设计是通过系统地搜索所有允许的离散输入脉冲空间来找到的。每个测试用例的算法如下：\n\n1.  将变量 `max_I_phi` 初始化为 $0.0$，因为信息是非负的。$L=0$ 的情况（零输入）会得到 $I_\\phi = 0$。\n2.  定义采样时间 $t_i = i \\Delta t$，其中 $i=0, \\dots, N-1$。\n3.  遍历每个允许的脉冲长度 $L \\in \\mathcal{L}$。\n4.  对于每个 $L > 0$，遍历所有可能的起始索引 $s \\in \\{0, 1, \\dots, N-L\\}$。\n5.  对于每个候选设计 $(L,s)$：\n    a. 构建离散输入向量 $u \\in \\mathbb{R}^N$。对于 $j \\in \\{s, \\dots, s+L-1\\}$，设置 $u_j = u_{\\max}$，否则 $u_j = 0$。\n    b. 计算 $N \\times 2$ 的灵敏度矩阵 $S$。这需要两个嵌套循环：一个外层循环用于时间索引 $i$ 从 $0$ 到 $N-1$，一个内层循环用于求和索引 $j$ 从 $0$ 到 $i$。在循环内部，根据公式计算 $s_{i,1}$ 和 $s_{i,2}$ 的项。\n    c. 计算 $2 \\times 2$ 矩阵 $S^\\top S$。\n    d. 计算 FIM $F = \\sigma^{-2} S^\\top S$。\n    e. 计算梯度向量 $\\nabla_\\theta g(\\theta)$。\n    f. 计算标量费雪信息 $I_\\phi = (\\nabla_\\theta g(\\theta))^\\top F (\\nabla_\\theta g(\\theta))$。\n    g. 如果新计算的 $I_\\phi$ 更大，则更新 `max_I_phi`：`max_I_phi = max(max_I_phi, I_phi)`。\n6.  在评估完所有 $(L,s)$ 对后，`max_I_phi` 将持有在给定实验约束下可实现的最大信息。该值将作为该测试用例的结果存储。\n\n对问题中指定的每个测试用例执行此过程，并按要求格式化最终结果。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_max_fisher_information(k1, k2, dt, N, sigma, u_max, L_set):\n    \"\"\"\n    Computes the maximum Fisher information for the ratio phi = k1/k2 by searching\n    over a space of rectangular pulse experimental designs.\n\n    Args:\n        k1 (float): Parameter k1.\n        k2 (float): Parameter k2.\n        dt (float): Time step delta_t.\n        N (int): Number of time points.\n        sigma (float): Standard deviation of measurement noise.\n        u_max (float): Amplitude of the input pulse.\n        L_set (set): Set of allowed pulse lengths L (in grid units).\n\n    Returns:\n        float: The maximum Fisher information I_phi found.\n    \"\"\"\n    t = np.arange(N) * dt\n    max_I_phi = 0.0\n\n    # The gradient of phi = k1/k2 w.r.t. theta = (k1, k2) is constant for a given case.\n    # grad_g = [d(phi)/dk1, d(phi)/dk2] = [1/k2, -k1/k2^2]\n    grad_g = np.array([1 / k2, -k1 / (k2**2)])\n\n    # Handle the L=0 case separately. If L=0, u is always zero, so S=0, F=0, I_phi=0.\n    # Since max_I_phi is initialized to 0.0, this case is implicitly handled.\n    if 0 in L_set and len(L_set) == 1:\n        return 0.0\n        \n    for L in L_set:\n        if L == 0:\n            continue\n        \n        # Iterate over all possible start times for a pulse of length L\n        for s in range(N - L + 1):\n            # 1. Construct the input signal u for the current design (L, s)\n            u = np.zeros(N)\n            u[s : s + L] = u_max\n\n            # 2. Compute the sensitivity matrix S\n            S = np.zeros((N, 2))\n            for i in range(N):\n                sum1 = 0.0  # For sensitivity wrt k1\n                sum2 = 0.0  # For sensitivity wrt k2\n                \n                # The summation is from j=0 to i, as specified.\n                for j in range(i + 1):\n                    if u[j] > 0:\n                        time_diff = t[i] - t[j]\n                        exp_term = np.exp(-k2 * time_diff)\n                        \n                        # From problem: s_i1 = sum(u_j * exp(...) * dt)\n                        sum1 += u[j] * exp_term\n                        \n                        # From problem: s_i2 = -k1 * sum((t_i-t_j) * u_j * exp(...) * dt)\n                        sum2 += (time_diff * u[j] * exp_term)\n\n                S[i, 0] = sum1 * dt\n                S[i, 1] = -k1 * sum2 * dt\n\n            # 3. Compute the Fisher Information Matrix (FIM) for theta=(k1, k2)\n            # F = (1/sigma^2) * S^T * S\n            F = (1 / sigma**2) * (S.T @ S)\n\n            # 4. Compute Fisher information for phi\n            # I_phi = grad_g^T * F * grad_g\n            I_phi = grad_g.T @ F @ grad_g\n            \n            # 5. Update the maximum I_phi found\n            if I_phi > max_I_phi:\n                max_I_phi = I_phi\n                \n    return max_I_phi\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        # Case 1: happy path\n        {'k1': 2.0, 'k2': 0.8, 'dt': 0.5, 'N': 20, 'sigma': 0.1, 'u_max': 1.0, 'L_set': {2, 4, 6}},\n        # Case 2: boundary, no input allowed\n        {'k1': 1.2, 'k2': 0.6, 'dt': 0.5, 'N': 20, 'sigma': 0.1, 'u_max': 1.0, 'L_set': {0}},\n        # Case 3: fast decay edge case\n        {'k1': 1.5, 'k2': 3.0, 'dt': 0.2, 'N': 30, 'sigma': 0.2, 'u_max': 1.0, 'L_set': {3, 6}},\n        # Case 4: high noise, longer horizon\n        {'k1': 1.0, 'k2': 1.0, 'dt': 0.5, 'N': 25, 'sigma': 1.0, 'u_max': 1.0, 'L_set': {5, 10}},\n    ]\n\n    results = []\n    for params in test_cases:\n        max_I_phi = calculate_max_fisher_information(**params)\n        results.append(max_I_phi)\n\n    # Format the final output string exactly as required.\n    output_str = f\"[{','.join([f'{r:.6f}' for r in results])}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}