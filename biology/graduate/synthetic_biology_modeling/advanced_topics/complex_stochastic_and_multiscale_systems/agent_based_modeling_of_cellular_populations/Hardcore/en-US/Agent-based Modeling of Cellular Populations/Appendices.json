{
    "hands_on_practices": [
        {
            "introduction": "A robust agent-based model begins with a foundation of physical and logical consistency. This practice introduces property-based testing, a powerful technique to verify that the fundamental invariants of your model hold true across a wide range of randomly generated configurations. Before simulating complex dynamics, you will ensure that your cellular agents respect basic constraints such as spatial containment and plausible packing densities, thereby building confidence in the structural integrity of your simulation's state space .",
            "id": "3905502",
            "problem": "Consider a two-dimensional Agent-Based Modeling (ABM) representation of a cellular population confined to a rectangular domain. Each cell is modeled as a circular agent with center positions and radii. Let the domain be a rectangle with side lengths $L_x$ and $L_y$ measured in micrometers ($\\mu$m). Let there be $N$ agents with centers $(x_i, y_i)$ and radii $r_i$, for $i \\in \\{1,\\dots,N\\}$. Define the following model-invariants grounded in first principles:\n\n1. Packing fraction invariant: The occupied area fraction (packing fraction) $\\phi$ equals the area of the union of agent disks divided by the domain area $L_x L_y$. It must satisfy $0 \\le \\phi \\le \\phi_{\\max}$ for a prescribed model parameter $\\phi_{\\max}$, where $\\phi_{\\max} \\le 1$ is chosen to reflect a biologically plausible maximum packing constraint. In practice, compute $\\phi$ by rasterizing the domain on a square grid of spacing $\\Delta$ (in $\\mu$m), counting grid points that lie inside at least one disk, and forming the ratio of occupied points to total grid points.\n\n2. Energy positivity invariant: Define the pairwise mechanical overlap energy as\n$$\nE = \\sum_{1 \\le i  j \\le N} \\frac{k}{2}\\,\\left[\\max\\!\\left(0,\\, r_i + r_j - d_{ij}\\right)\\right]^2,\n$$\nwhere $k$ has units of piconewton per micrometer (pN/$\\mu$m), $d_{ij}$ is the Euclidean distance between centers $(x_i, y_i)$ and $(x_j, y_j)$ in $\\mu$m, and the overlap amount is $\\max(0, r_i + r_j - d_{ij})$ in $\\mu$m. The energy $E$ thus has units of piconewton-micrometer, which equals attojoules (aJ). The invariant requires $E \\ge 0$ in aJ.\n\n3. Containment invariant: All agents must lie entirely within the domain, meaning $0 \\le x_i \\le L_x$ and $0 \\le y_i \\le L_y$ for all $i$.\n\nFundamental base and realism justification: The occupied area fraction bound arises because the union area of disks cannot exceed the finite area of the domain, so $0 \\le \\phi \\le 1$, and a model-imposed upper bound $\\phi_{\\max} \\le 1$ encodes experimentally observed crowding limits. The energy positivity follows because each term is a nonnegative constant times a square of a nonnegative overlap, ensuring $E \\ge 0$ by construction. Containment follows from the definition of the domain as the physical confining region.\n\nTask: Write a complete, runnable program that performs property-based tests. For each parameter set in the test suite below, generate $M$ random agent states using deterministic pseudorandom seeds and check the three invariants above for each state. A parameter set passes if and only if all generated states satisfy all three invariants. Use the following deterministic randomization protocol: for case index $c$ (starting at $0$) and state index $s$ (starting at $0$), set the seed to $S_0 + 1000\\,c + s$, where $S_0 = 12345$.\n\nRandom state generation details:\n- Positions $(x_i,y_i)$ are independently sampled uniformly from $[0, L_x] \\times [0, L_y]$ in $\\mu$m.\n- Radii $r_i$ are sampled from either a uniform distribution on $[r_{\\min}, r_{\\max}]$ or a lognormal distribution with parameters $(\\mu,\\sigma)$, then truncated to $[r_{\\min}, r_{\\max}]$. For the lognormal case, draw $z \\sim \\mathcal{N}(\\mu,\\sigma^2)$ and set $r = \\exp(z)$ in $\\mu$m, followed by truncation to the specified interval.\n\nNumerical specification:\n- Compute the packing fraction $\\phi$ by rasterization on a square grid of spacing $\\Delta$ in $\\mu$m, using the point-in-disk test at grid points.\n- Check energy positivity in attojoules (aJ).\n- Use a numerical tolerance of $\\varepsilon = 10^{-3}$ for the packing fraction check, i.e., accept $\\phi \\le \\phi_{\\max} + \\varepsilon$ to accommodate discretization error.\n- All angles are irrelevant in this two-dimensional circular agent model.\n- All percentage-like quantities must be handled as decimal fractions (for example, a packing bound of $0.70$ is a fraction, not a percentage sign).\n\nTest suite (five cases):\nCase $1$:\n- $L_x = 100$, $L_y = 100$ $\\mu$m, $N = 50$, radii uniform on $[1.5, 2.5]$ $\\mu$m, $\\phi_{\\max} = 0.70$, $k = 50$ pN/$\\mu$m, grid spacing $\\Delta = 1.0$ $\\mu$m, $M = 32$ states.\n\nCase $2$ (boundary condition of zero agents):\n- $L_x = 50$, $L_y = 50$ $\\mu$m, $N = 0$, radii uniform on $[1.0, 1.0]$ $\\mu$m, $\\phi_{\\max} = 1.00$, $k = 50$ pN/$\\mu$m, grid spacing $\\Delta = 1.0$ $\\mu$m, $M = 8$ states.\n\nCase $3$ (small domain with many small agents):\n- $L_x = 10$, $L_y = 10$ $\\mu$m, $N = 30$, radii uniform on $[0.5, 0.6]$ $\\mu$m, $\\phi_{\\max} = 0.60$, $k = 80$ pN/$\\mu$m, grid spacing $\\Delta = 0.5$ $\\mu$m, $M = 32$ states.\n\nCase $4$ (moderate domain with moderate radii):\n- $L_x = 20$, $L_y = 20$ $\\mu$m, $N = 40$, radii uniform on $[0.8, 1.2]$ $\\mu$m, $\\phi_{\\max} = 0.35$, $k = 60$ pN/$\\mu$m, grid spacing $\\Delta = 1.0$ $\\mu$m, $M = 32$ states.\n\nCase $5$ (lognormal radii, truncated):\n- $L_x = 100$, $L_y = 100$ $\\mu$m, $N = 120$, radii lognormal with $(\\mu, \\sigma) = (\\ln(1.5), 0.2)$, then truncated to $[0.5, 3.0]$ $\\mu$m, $\\phi_{\\max} = 0.50$, $k = 40$ pN/$\\mu$m, grid spacing $\\Delta = 2.0$ $\\mu$m, $M = 32$ states.\n\nFinal output specification:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element corresponds to one case and must be a boolean indicating whether all $M$ states in that case satisfy all three invariants. For example, the output should look like `[r_1,r_2,r_3,r_4,r_5]` with each $r_i$ equal to either True or False.",
            "solution": "The user has provided a valid, well-posed problem. The task is to write a program that performs property-based testing on an Agent-Based Model (ABM) of a cellular population. For several test cases, a number of random system states are generated, and for each state, three model invariants are checked. A test case passes if and only if all its generated states satisfy all three invariants. The process is deterministic, relying on a specified pseudorandom seeding protocol.\n\nThe three invariants to be tested are:\n1.  **Containment Invariant**: Each agent's center $(x_i, y_i)$ must remain within the rectangular domain, i.e., $0 \\le x_i \\le L_x$ and $0 \\le y_i \\le L_y$.\n2.  **Energy Positivity Invariant**: The total pairwise mechanical overlap energy, $E$, must be non-negative. The energy is defined as:\n    $$\n    E = \\sum_{1 \\le i  j \\le N} \\frac{k}{2}\\,\\left[\\max\\!\\left(0,\\, r_i + r_j - d_{ij}\\right)\\right]^2 \\ge 0\n    $$\n    where $k > 0$ is a stiffness constant, $r_i$ and $r_j$ are the radii of agents $i$ and $j$, and $d_{ij}$ is the Euclidean distance between their centers.\n3.  **Packing Fraction Invariant**: The area fraction occupied by the agents, $\\phi$, must not exceed a specified maximum, $\\phi_{\\max}$. The condition is $\\phi \\le \\phi_{\\max} + \\varepsilon$, where $\\varepsilon = 10^{-3}$ is a numerical tolerance.\n\nThe core of the solution is to implement a procedure that, for each test case, iterates through a specified number of states, $M$. For each state, it generates agent positions and radii according to the given random distributions and then executes the three checks.\n\n### Algorithmic Design and Implementation\n\nThe overall program is structured to process a list of test cases. For each case, a master loop runs $M$ times to generate and check each random state.\n\n**State Generation**\nFor each state, agent properties are generated following a deterministic protocol. The random number generator is seeded with $S_0 + 1000c + s$, where $S_0 = 12345$, $c$ is the zero-indexed case number, and $s$ is the zero-indexed state number.\n-   Agent center positions $(x_i, y_i)$ for $i=1, \\dots, N$ are drawn from a continuous uniform distribution over the domain $[0, L_x] \\times [0, L_y]$.\n-   Agent radii $r_i$ are drawn from either a uniform or a truncated lognormal distribution, as specified per test case.\n\n**Invariant Verification**\nThree functions are designed to check the invariants for a given state.\n\n1.  **Containment Check**: This function verifies that for all agents $i$, the center coordinates satisfy $0 \\le x_i \\le L_x$ and $0 \\le y_i \\le L_y$. As the state generation protocol samples positions from precisely this interval, this invariant is expected to hold by construction. The check serves as a validation of the position generation logic.\n\n2.  **Energy Positivity Check**: This function calculates the total energy $E$. The implementation involves a double loop over all unique pairs of agents $(i, j)$ with $i  j$. For each pair, the distance $d_{ij}$ between their centers is computed. The overlap is $\\delta_{ij} = \\max(0, r_i + r_j - d_{ij})$. The energy contribution from this pair is $\\frac{k}{2} \\delta_{ij}^2$. These contributions are summed to obtain the total energy $E$. The invariant $E \\ge 0$ must hold. Since $k>0$ and $\\delta_{ij}^2 \\ge 0$, every term in the sum is non-negative, and thus $E$ is guaranteed to be non-negative mathematically. This check validates the correct implementation of the energy formula, guarding against potential floating-point artifacts or programming errors.\n\n3.  **Packing Fraction Check**: This is the only check not guaranteed by construction and thus represents the principal test of the system's physical properties. The packing fraction $\\phi$ is computed via a rasterization method:\n    -   A two-dimensional grid of points is established over the domain $[0, L_x] \\times [0, L_y]$ with a uniform spacing of $\\Delta$. The number of grid points along each axis is $N_x = \\lfloor L_x/\\Delta \\rfloor + 1$ and $N_y = \\lfloor L_y/\\Delta \\rfloor + 1$. The total number of grid points is $N_{\\text{grid}} = N_x \\times N_y$.\n    -   A boolean mask, representing the grid, is initialized to `False`.\n    -   For each agent $i$ with center $(x_i, y_i)$ and radius $r_i$, all grid points $(g_x, g_y)$ satisfying the point-in-disk condition $(g_x - x_i)^2 + (g_y - y_i)^2 \\le r_i^2$ are identified. The corresponding entries in the boolean mask are set to `True`. This is done cumulatively for all agents using a logical OR operation.\n    -   The number of occupied points, $N_{\\text{occ}}$, is the total count of `True` values in the final mask.\n    -   The packing fraction is calculated as $\\phi = N_{\\text{occ}} / N_{\\text{grid}}$.\n    -   Finally, the condition $\\phi \\le \\phi_{\\max} + \\varepsilon$ is verified.\n\nA test case is deemed to have passed (result: `True`) only if every one of its $M$ generated states passes all three invariant checks. If any state fails any check, the evaluation for that case stops, and the result is `False`. The boolean outcomes for all test cases are then compiled into a list for the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other non-standard libraries are used.\n\ndef solve():\n    \"\"\"\n    Main function to run the property-based tests for the ABM of\n    a cellular population.\n    \"\"\"\n    # Global constants defined in the problem\n    S0 = 12345\n    EPSILON = 1e-3\n\n    def generate_state(params, seed):\n        \"\"\"\n        Generates a single random state (agent positions and radii)\n        for a given set of parameters and a seed.\n        \"\"\"\n        np.random.seed(seed)\n        \n        N = params['N']\n        Lx, Ly = params['Lx'], params['Ly']\n        r_dist = params['r_dist']\n        \n        # Generate positions using a uniform distribution over [0, L] x [0, L]\n        # np.random.uniform generates from [low, high), which satisfies the\n        # containment invariant 0 = pos = L.\n        positions = np.random.uniform(low=[0.0, 0.0], high=[Lx, Ly], size=(N, 2))\n        \n        # Generate radii based on the specified distribution\n        if N == 0:\n            radii = np.array([])\n        elif r_dist['type'] == 'uniform':\n            r_min, r_max = r_dist['params']\n            radii = np.random.uniform(r_min, r_max, size=N)\n        elif r_dist['type'] == 'lognormal_truncated':\n            mu, sigma, r_min, r_max = r_dist['params']\n            # Draw z from N(mu, sigma^2)\n            z = np.random.normal(loc=mu, scale=sigma, size=N)\n            # Radii are exp(z), then truncated (clipped)\n            radii = np.exp(z)\n            radii = np.clip(radii, r_min, r_max)\n        \n        return positions, radii\n\n    def check_containment(positions, Lx, Ly):\n        \"\"\"Checks the containment invariant.\"\"\"\n        if positions.shape[0] == 0:\n            return True\n        return np.all((positions >= 0)  (positions = [Lx, Ly]))\n\n    def check_energy_positivity(positions, radii, k):\n        \"\"\"Checks the energy positivity invariant.\"\"\"\n        N = positions.shape[0]\n        if N  2:\n            return True  # Energy is 0 for 0 or 1 agent\n        \n        energy = 0.0\n        for i in range(N):\n            for j in range(i + 1, N):\n                dist_sq = np.sum((positions[i] - positions[j])**2)\n                d_ij = np.sqrt(dist_sq)\n                overlap = radii[i] + radii[j] - d_ij\n                if overlap > 0:\n                    energy += (k / 2.0) * (overlap**2)\n        \n        return energy >= 0.0\n\n    def check_packing_fraction(positions, radii, Lx, Ly, delta, phi_max):\n        \"\"\"Checks the packing fraction invariant using rasterization.\"\"\"\n        N = positions.shape[0]\n        if N == 0:\n            return 0.0 = phi_max + EPSILON\n\n        nx = int(np.floor(Lx / delta)) + 1\n        ny = int(np.floor(Ly / delta)) + 1\n        \n        x_coords = np.linspace(0, Lx, nx)\n        y_coords = np.linspace(0, Ly, ny)\n        grid_x, grid_y = np.meshgrid(x_coords, y_coords)\n        \n        total_points = grid_x.size\n        if total_points == 0:\n            return (1.0 if N > 0 else 0.0) = phi_max + EPSILON\n\n        occupied_mask = np.zeros_like(grid_x, dtype=bool)\n\n        for i in range(N):\n            center_x, center_y = positions[i]\n            r_sq = radii[i]**2\n            dist_sq = (grid_x - center_x)**2 + (grid_y - center_y)**2\n            occupied_mask |= (dist_sq = r_sq)\n            \n        occupied_points = np.sum(occupied_mask)\n        phi = occupied_points / total_points\n        \n        return phi = phi_max + EPSILON\n\n    # Test suite definition\n    test_cases = [\n        {'Lx': 100, 'Ly': 100, 'N': 50, 'r_dist': {'type': 'uniform', 'params': (1.5, 2.5)}, 'phi_max': 0.70, 'k': 50, 'delta': 1.0, 'M': 32},\n        {'Lx': 50, 'Ly': 50, 'N': 0, 'r_dist': {'type': 'uniform', 'params': (1.0, 1.0)}, 'phi_max': 1.00, 'k': 50, 'delta': 1.0, 'M': 8},\n        {'Lx': 10, 'Ly': 10, 'N': 30, 'r_dist': {'type': 'uniform', 'params': (0.5, 0.6)}, 'phi_max': 0.60, 'k': 80, 'delta': 0.5, 'M': 32},\n        {'Lx': 20, 'Ly': 20, 'N': 40, 'r_dist': {'type': 'uniform', 'params': (0.8, 1.2)}, 'phi_max': 0.35, 'k': 60, 'delta': 1.0, 'M': 32},\n        {'Lx': 100, 'Ly': 100, 'N': 120, 'r_dist': {'type': 'lognormal_truncated', 'params': (np.log(1.5), 0.2, 0.5, 3.0)}, 'phi_max': 0.50, 'k': 40, 'delta': 2.0, 'M': 32},\n    ]\n\n    results = []\n    \n    for c, params in enumerate(test_cases):\n        case_passed = True\n        for s in range(params['M']):\n            seed = S0 + 1000 * c + s\n            positions, radii = generate_state(params, seed)\n            \n            # Check invariants for the generated state\n            inv1_ok = check_containment(positions, params['Lx'], params['Ly'])\n            inv2_ok = check_energy_positivity(positions, radii, params['k'])\n            inv3_ok = check_packing_fraction(positions, radii, params['Lx'], params['Ly'], params['delta'], params['phi_max'])\n            \n            # If any invariant fails, the case fails, and we can break early.\n            if not (inv1_ok and inv2_ok and inv3_ok):\n                case_passed = False\n                break\n        \n        results.append(case_passed)\n        \n    # Format and print the final output exactly as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Testing a model with stochastic components presents a unique challenge, as its output varies from run to run. This exercise demonstrates how to create deterministic unit tests for stochastic simulations, a critical skill for ensuring reproducibility and correctness. You will learn to fix random number generator seeds and, more importantly, to derive and apply mathematically justified tolerance bands based on probability theory to verify that your model's statistical behavior aligns precisely with analytical predictions .",
            "id": "3905541",
            "problem": "You are asked to construct deterministic unit tests for a stochastic agent-based model by fixing random seeds and defining mathematically justified tolerance bands. Consider a single-step Agent-Based Model (ABM) of a cellular population in synthetic biology modeling, where each of $N_0$ cells independently undergoes one of three outcomes in a synchronous update: division, apoptosis (programmed cell death), or no change. For each cell $j$, define a random variable $Y_j$ taking values $+1$ for division with probability $p_{\\text{div}}$, $-1$ for death with probability $p_{\\text{die}}$, and $0$ for no change with probability $1 - p_{\\text{div}} - p_{\\text{die}}$, with $0 \\le p_{\\text{div}} \\le 1$, $0 \\le p_{\\text{die}} \\le 1$, and $p_{\\text{div}} + p_{\\text{die}} \\le 1$. The final cell count after one step in a single simulation replicate is\n$$\nN_1 \\;=\\; N_0 + \\sum_{j=1}^{N_0} Y_j.\n$$\nYou will run $R$ independent replicates using a fixed pseudo-random seed, compute the sample mean $\\bar{N}_1$, and automatically accept or reject the run by comparing $\\bar{N}_1$ against a mathematically justified tolerance band around the analytical mean. The acceptance criterion must be deterministic for a given seed and must be justified using first-principles probability results.\n\nFundamental base and facts to use:\n- Independence of per-cell outcomes and the Multinomial model for $(X_{\\text{div}}, X_{\\text{die}}, X_{\\text{stay}})$ over $N_0$ trials with probabilities $(p_{\\text{div}}, p_{\\text{die}}, 1-p_{\\text{div}}-p_{\\text{die}})$.\n- The mean and variance for sums of independent and identically distributed (i.i.d.) variables and the Central Limit Theorem (CLT) for sample means.\n- Hoeffding’s inequality for bounded independent variables to produce a non-asymptotic tolerance bound.\n\nDerive the analytical mean and variance for $N_1$, then derive a two-sided tolerance band for the sample mean of $R$ replicates that combines:\n1. A normal approximation band from the Central Limit Theorem (CLT), using the $(1-\\alpha/2)$ quantile of the standard normal distribution.\n2. A non-asymptotic band from Hoeffding’s inequality applied to the average over $R$ replicates.\n\nFormally, let $\\mu = \\mathbb{E}[N_1]$ and $\\sigma^2 = \\mathrm{Var}(N_1)$ for one replicate, and let $\\bar{N}_1$ be the sample mean over $R$ replicates. Define the CLT-based band half-width\n$$\nT_{\\mathrm{CLT}}(\\alpha) \\;=\\; z_{1-\\alpha/2}\\,\\sqrt{\\frac{\\sigma^2}{R}},\n$$\nwhere $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$ quantile of the standard normal distribution. Also define the Hoeffding-based band half-width\n$$\nT_{\\mathrm{H}}(\\alpha) \\;=\\; \\sqrt{\\frac{2\\,N_0\\,\\ln(2/\\alpha)}{R}}.\n$$\nUse the conservative combined tolerance\n$$\nT(\\alpha) \\;=\\; \\max\\left(T_{\\mathrm{CLT}}(\\alpha),\\,T_{\\mathrm{H}}(\\alpha)\\right).\n$$\nAccept the run if and only if\n$$\n\\left|\\bar{N}_1 - \\mu\\right| \\le T(\\alpha).\n$$\nAll probabilities must be expressed as decimals or fractions, not with a percentage sign. Counts are in units of cells; no other physical units are involved.\n\nImplement a program that:\n- For each test case, validates that $p_{\\text{div}} + p_{\\text{die}} \\le 1$ and $p_{\\text{div}}, p_{\\text{die}} \\in [0,1]$. If invalid, produce a boolean rejection for that case.\n- Uses the given fixed random seed to generate $R$ replicates via a Multinomial sampler over $N_0$ cells for each replicate.\n- Computes $\\bar{N}_1$, $\\mu$, $\\sigma^2$, $T_{\\mathrm{CLT}}(\\alpha)$, $T_{\\mathrm{H}}(\\alpha)$, $T(\\alpha)$, and returns the acceptance boolean.\n\nTest suite (each case is $(N_0, p_{\\text{div}}, p_{\\text{die}}, R, \\alpha, \\text{seed})$):\n1. $(1000, 0.2, 0.1, 800, 0.01, 314159)$\n2. $(50, 0.49, 0.49, 5000, 0.05, 271828)$\n3. $(5, 0.2, 0.1, 10000, 0.001, 123456)$\n4. $(200, 0.0, 0.0, 200, 10^{-6}, 789)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each result is a boolean indicating acceptance for the corresponding test case.",
            "solution": "The supplied problem is assessed to be valid. It is scientifically grounded in probability theory and statistics, well-posed with all necessary information provided, and objective in its formulation. The task is to construct a deterministic test for a stochastic model by deriving and applying statistical bounds, which represents a sound and standard practice in computational science. We shall now proceed with the solution, which involves three primary steps: derivation of the analytical moments of the cell population count, justification of the provided statistical bounds, and the design of the computational implementation.\n\n### Step 1: Analytical Mean and Variance of the Final Cell Population\n\nLet $N_0$ be the initial number of cells. For each cell $j \\in \\{1, \\dots, N_0\\}$, the change in population is represented by a random variable $Y_j$. This variable takes the value $+1$ (division) with probability $p_{\\text{div}}$, $-1$ (death) with probability $p_{\\text{die}}$, and $0$ (stasis) with probability $p_{\\text{stay}} = 1 - p_{\\text{div}} - p_{\\text{die}}$. The variables $Y_j$ are independent and identically distributed (i.i.d.).\n\nFirst, we compute the mean and variance of a single variable $Y_j$.\nThe expected value of $Y_j$ is:\n$$\n\\mathbb{E}[Y_j] = (+1) \\cdot p_{\\text{div}} + (-1) \\cdot p_{\\text{die}} + (0) \\cdot p_{\\text{stay}} = p_{\\text{div}} - p_{\\text{die}}\n$$\nTo find the variance, we first compute the second moment, $\\mathbb{E}[Y_j^2]$:\n$$\n\\mathbb{E}[Y_j^2] = (+1)^2 \\cdot p_{\\text{div}} + (-1)^2 \\cdot p_{\\text{die}} + (0)^2 \\cdot p_{\\text{stay}} = p_{\\text{div}} + p_{\\text{die}}\n$$\nThe variance of $Y_j$ is then given by $\\mathrm{Var}(Y_j) = \\mathbb{E}[Y_j^2] - (\\mathbb{E}[Y_j])^2$:\n$$\n\\mathrm{Var}(Y_j) = (p_{\\text{div}} + p_{\\text{die}}) - (p_{\\text{div}} - p_{\\text{die}})^2\n$$\nThe final cell count after one step, $N_1$, is defined as $N_1 = N_0 + \\sum_{j=1}^{N_0} Y_j$.\n\nThe analytical mean of $N_1$, denoted $\\mu$, is derived using the linearity of expectation:\n$$\n\\mu = \\mathbb{E}[N_1] = \\mathbb{E}\\left[N_0 + \\sum_{j=1}^{N_0} Y_j\\right] = N_0 + \\sum_{j=1}^{N_0} \\mathbb{E}[Y_j]\n$$\nSince the $Y_j$ are identically distributed, $\\mathbb{E}[Y_j]$ is the same for all $j$:\n$$\n\\mu = N_0 + N_0 \\cdot \\mathbb{E}[Y_j] = N_0 + N_0(p_{\\text{div}} - p_{\\text{die}}) = N_0(1 + p_{\\text{div}} - p_{\\text{die}})\n$$\nThe analytical variance of $N_1$, denoted $\\sigma^2$, is derived using the properties of variance for sums of independent random variables. The constant $N_0$ does not contribute to the variance.\n$$\n\\sigma^2 = \\mathrm{Var}(N_1) = \\mathrm{Var}\\left(N_0 + \\sum_{j=1}^{N_0} Y_j\\right) = \\mathrm{Var}\\left(\\sum_{j=1}^{N_0} Y_j\\right)\n$$\nSince the $Y_j$ are independent:\n$$\n\\sigma^2 = \\sum_{j=1}^{N_0} \\mathrm{Var}(Y_j) = N_0 \\cdot \\mathrm{Var}(Y_j) = N_0 \\left[ (p_{\\text{div}} + p_{\\text{die}}) - (p_{\\text{div}} - p_{\\text{die}})^2 \\right]\n$$\nThese expressions for $\\mu$ and $\\sigma^2$ are the exact analytical moments for a single replicate of the simulation.\n\n### Step 2: Derivation and Justification of the Tolerance Bands\n\nThe test compares the sample mean over $R$ replicates, $\\bar{N}_1$, to the analytical mean $\\mu$. The tolerance band is constructed from two sources.\n\nThe Central Limit Theorem (CLT) states that for large $R$, the distribution of the sample mean $\\bar{N}_1$ is approximately normal with mean $\\mu$ and variance $\\sigma^2/R$. A confidence interval is therefore justified. The half-width of this interval for a significance level $\\alpha$ is:\n$$\nT_{\\mathrm{CLT}}(\\alpha) = z_{1-\\alpha/2}\\,\\sqrt{\\frac{\\sigma^2}{R}}\n$$\nwhere $z_{1-\\alpha/2}$ is the $(1-\\alpha/2)$ quantile of the standard normal distribution. This is a standard asymptotic result.\n\nThe second bound is non-asymptotic and is derived from Hoeffding's inequality. The provided formula, $T_{\\mathrm{H}}(\\alpha) = \\sqrt{\\frac{2\\,N_0\\,\\ln(2/\\alpha)}{R}}$, requires careful justification. Let us apply Hoeffding's inequality not to the $R$ replicate outcomes $N_{1,i}$, but to the total set of $N_0 \\times R$ individual cell-level outcomes.\n\nLet $Y_{i,j}$ be the outcome for cell $j$ in replicate $i$. These are $N_0 \\times R$ i.i.d. random variables, each bounded on the interval $[-1, 1]$. The range is $b-a = 1 - (-1) = 2$.\nLet $\\bar{Y} = \\frac{1}{N_0 R} \\sum_{i=1}^R \\sum_{j=1}^{N_0} Y_{i,j}$ be the grand-average outcome over all cells in all replicates. Applying Hoeffding's inequality to this average of $M = N_0 R$ variables:\n$$\nP(|\\bar{Y} - \\mathbb{E}[\\bar{Y}]| \\ge \\epsilon') \\le 2 \\exp\\left(-\\frac{2M(\\epsilon')^2}{(b-a)^2}\\right) = 2 \\exp\\left(-\\frac{2(N_0 R)(\\epsilon')^2}{2^2}\\right) = 2 \\exp\\left(-\\frac{N_0 R (\\epsilon')^2}{2}\\right)\n$$\nSetting this probability to $\\alpha$ and solving for the deviation $\\epsilon'$:\n$$\n\\alpha = 2 \\exp\\left(-\\frac{N_0 R (\\epsilon')^2}{2}\\right) \\implies \\ln(\\alpha/2) = -\\frac{N_0 R (\\epsilon')^2}{2} \\implies (\\epsilon')^2 = \\frac{2\\ln(2/\\alpha)}{N_0 R}\n$$\nThe deviation we are interested in is $|\\bar{N}_1 - \\mu|$. We can express this in terms of $\\bar{Y}$:\n$$\n\\bar{N}_1 = \\frac{1}{R}\\sum_{i=1}^R N_{1,i} = \\frac{1}{R}\\sum_{i=1}^R \\left(N_0 + \\sum_{j=1}^{N_0} Y_{i,j}\\right) = N_0 + \\frac{1}{R}\\sum_{i=1}^R\\sum_{j=1}^{N_0} Y_{i,j} = N_0 + N_0 \\bar{Y}\n$$\nSimilarly, $\\mu = N_0 + N_0 \\mathbb{E}[\\bar{Y}]$. Therefore:\n$$\n|\\bar{N}_1 - \\mu| = |(N_0 + N_0 \\bar{Y}) - (N_0 + N_0 \\mathbb{E}[\\bar{Y}])| = N_0|\\bar{Y} - \\mathbb{E}[\\bar{Y}]|\n$$\nThe bound on this quantity, which we will call $T_{\\mathrm{H}}(\\alpha)$, is $N_0 \\epsilon'$:\n$$\nT_{\\mathrm{H}}(\\alpha) = N_0 \\epsilon' = N_0 \\sqrt{\\frac{2\\ln(2/\\alpha)}{N_0 R}} = \\sqrt{N_0^2 \\frac{2\\ln(2/\\alpha)}{N_0 R}} = \\sqrt{\\frac{2 N_0 \\ln(2/\\alpha)}{R}}\n$$\nThis derivation confirms the correctness of the formula provided in the problem statement. The final tolerance $T(\\alpha) = \\max(T_{\\mathrm{CLT}}(\\alpha), T_{\\mathrm{H}}(\\alpha))$ is a conservative choice, ensuring the bound is robust for both large and small sample sizes.\n\n### Step 3: Algorithmic Strategy\n\nThe implementation will proceed as follows for each test case $(N_0, p_{\\text{div}}, p_{\\text{die}}, R, \\alpha, \\text{seed})$:\n1.  **Parameter Validation**: Check the constraints $0 \\le p_{\\text{div}} \\le 1$, $0 \\le p_{\\text{die}} \\le 1$, and $p_{\\text{div}} + p_{\\text{die}} \\le 1$. If violated, the case is rejected.\n2.  **Analytical Calculation**: Compute $\\mu$ and $\\sigma^2$ using the derived formulas.\n3.  **Stochastic Simulation**:\n    a. Initialize a pseudo-random number generator with the given `seed`.\n    b. For each of the $R$ replicates, simulate the outcomes for $N_0$ cells. This is efficiently done by drawing one sample of size $R$ from a Multinomial distribution with parameters $n=N_0$ and probabilities $[p_{\\text{div}}, p_{\\text{die}}, 1-p_{\\text{div}}-p_{\\text{die}}]$.\n    c. For each replicate's outcome `[n_div, n_die, n_stay]`, calculate the final cell count $N_1 = N_0 + n_{\\text{div}} - n_{\\text{die}}$.\n    d. Compute the sample mean $\\bar{N}_1$ over the $R$ resulting values of $N_1$.\n4.  **Tolerance Calculation**:\n    a. Find the normal quantile $z_{1-\\alpha/2}$ using `scipy.stats.norm.ppf`.\n    b. Compute $T_{\\mathrm{CLT}}(\\alpha)$ and $T_{\\mathrm{H}}(\\alpha)$.\n    c. Set $T(\\alpha) = \\max(T_{\\mathrm{CLT}}(\\alpha), T_{\\mathrm{H}}(\\alpha))$.\n5.  **Acceptance Decision**: Evaluate the boolean expression $|\\bar{N}_1 - \\mu| \\le T(\\alpha)$. This is the result for the test case.\n\nThe final output will be a list of these boolean results.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nimport math\n\ndef solve():\n    \"\"\"\n    Executes a series of deterministic unit tests for a stochastic agent-based model\n    of cell population dynamics. For each test case, it simulates the model with a fixed\n    random seed and checks if the sample mean falls within a mathematically justified\n    tolerance band around the analytical mean.\n    \"\"\"\n    test_cases = [\n        (1000, 0.2, 0.1, 800, 0.01, 314159),\n        (50, 0.49, 0.49, 5000, 0.05, 271828),\n        (5, 0.2, 0.1, 10000, 0.001, 123456),\n        (200, 0.0, 0.0, 200, 1e-6, 789),\n    ]\n\n    results = []\n    for case in test_cases:\n        N0, p_div, p_die, R, alpha, seed = case\n\n        # Step 1: Validate input parameters.\n        if not (0 = p_div = 1 and 0 = p_die = 1 and p_div + p_die = 1):\n            results.append(False)\n            continue\n\n        p_stay = 1.0 - p_div - p_die\n\n        # Step 2: Calculate analytical mean (mu) and variance (sigma^2) for one replicate.\n        mu = N0 * (1.0 + p_div - p_die)\n        \n        # Variance of a single cell's outcome Y_j\n        # Var(Y_j) = E[Y_j^2] - (E[Y_j])^2\n        # E[Y_j] = p_div - p_die\n        # E[Y_j^2] = p_div + p_die\n        var_Yj = (p_div + p_die) - (p_div - p_die)**2\n        # Variance of N_1 = N_0 + sum(Y_j) is Var(sum(Y_j)) = N_0 * Var(Y_j)\n        sigma2 = N0 * var_Yj\n\n        # Step 3: Run R replicates of the simulation with a fixed seed.\n        rng = np.random.default_rng(seed)\n        \n        # Generate the number of divisions, deaths, and stays for all R replicates at once.\n        # The result 'counts' is an (R, 3) array.\n        counts = rng.multinomial(N0, [p_div, p_die, p_stay], size=R)\n        \n        # Calculate the final population N1 for each of the R replicates.\n        # N1 = N0 + (number of divisions) - (number of deaths)\n        N1_replicates = N0 + counts[:, 0] - counts[:, 1]\n        \n        # Compute the sample mean over R replicates.\n        N1_bar = np.mean(N1_replicates)\n\n        # Step 4: Calculate the tolerance band T(alpha).\n        # CLT-based tolerance band half-width\n        z_quantile = norm.ppf(1.0 - alpha / 2.0)\n        # Handle case where R is 0 or sigma2 is negative, though not expected here.\n        if R > 0 and sigma2 >= 0:\n            T_clt = z_quantile * math.sqrt(sigma2 / R)\n        else:\n            T_clt = float('inf')\n\n        # Hoeffding-based tolerance band half-width\n        if R > 0:\n            T_h = math.sqrt((2.0 * N0 * math.log(2.0 / alpha)) / R)\n        else:\n            T_h = float('inf')\n        \n        # Use the more conservative (larger) of the two bands.\n        T_alpha = max(T_clt, T_h)\n\n        # Step 5: Perform the acceptance test.\n        is_accepted = abs(N1_bar - mu) = T_alpha\n        results.append(is_accepted)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "With a validated modeling framework, you can begin to investigate fundamental scientific questions. This practice dives into a classic problem in cell biology: how do cells know when to divide? You will implement and simulate three competing hypotheses for cell size control—the 'sizer,' 'adder,' and 'timer' models—and discover how a simple analysis of the relationship between cell size at birth and division can serve as a powerful signature to distinguish between these mechanisms .",
            "id": "3905570",
            "problem": "You are tasked with designing and implementing a complete, runnable program that compares three canonical single-cell division control hypotheses in agent-based modeling of cellular populations: the sizer, the adder, and the timer. Your program must (i) derive and simulate the expected steady-state size distributions at birth and at division for each control model from first principles, (ii) compute a quantitative criterion to identify which model best matches a provided dataset of single-cell sizes generated under known parameters, and (iii) output a single line containing the predicted model identifiers for a set of test cases. The three models are defined by the way cells determine when to divide, under exponential growth with constant growth rate. The foundational base is the standard biological growth law and stochastic partitioning:\n- Exponential growth law: a cell with birth size $s_b$ grows as $s(t) = s_b \\exp(g t)$ with constant growth rate $g$.\n- Stochastic partitioning at division: when a cell divides at size $s_d$, the daughter birth sizes are $f s_d$ and $(1-f) s_d$, where $f \\in (0,1)$ is a random partition fraction sampled independently at each division from a Beta distribution with parameters $(\\alpha,\\beta)$.\n\nThe division control models are defined as follows:\n- Sizer: the cell divides when its size reaches a noisy threshold, $s_d = S_c \\exp(\\eta)$, where $S_c$ is a constant and $\\eta \\sim \\mathcal{N}(0,\\sigma_\\eta^2)$ captures threshold noise.\n- Adder: the cell divides after adding a noisy size increment, $s_d = s_b + \\Delta$, where $\\Delta = \\Delta_0 \\exp(\\eta)$, with $\\Delta_0$ constant and $\\eta \\sim \\mathcal{N}(0,\\sigma_\\eta^2)$.\n- Timer: the cell divides after a noisy timer duration, $T \\sim \\mathcal{N}(T_0,\\sigma_T^2)$, under exponential growth $s_d = s_b \\exp(g T)$, where $T_0$ is a constant mean division time.\n\nYour task is to derive, from the above foundation without shortcut formulas, the expected shape of the steady-state distributions $p(s_b)$ and $p(s_d)$ under each model and then implement an agent-based simulation to approximate these distributions and compute a robust statistic for model identification from the dataset. The program must:\n1. Simulate a single-cell lineage for a fixed number of generations $n_{\\text{gen}}$ using the provided parameters to generate two arrays: birth sizes $\\{s_b^{(i)}\\}_{i=1}^{n_{\\text{gen}}}$ and division sizes $\\{s_d^{(i)}\\}_{i=1}^{n_{\\text{gen}}}$.\n2. For identification, compute a linear regression slope $\\hat{m}$ between $s_d^{(i)}$ and $s_b^{(i)}$ over the simulated dataset, and compare this slope to the theoretically expected slopes for each model, defined in terms of $g$ and $T_0$. Specifically, the expected slopes are: sizer $\\approx 0$, adder $\\approx 1$, timer $\\approx \\exp(g T_0)$. The model minimizing the absolute deviation $|\\hat{m} - m_{\\text{model}}|$ is the predicted match.\n3. For each test case, return the predicted model identifier as an integer, where sizer is $0$, adder is $1$, and timer is $2$.\n\nNo physical units are required; sizes are in arbitrary units (a.u.) and times are in arbitrary time units. Angles are not used. All outputs must be numeric.\n\nTest Suite:\nUse the following parameter sets and random seeds to generate the datasets. For each case, simulate $n_{\\text{gen}}$ divisions as a single lineage starting from initial birth size $s_b^{(0)} = 0.8$. For reproducibility, set the random number generator seed to the given integer.\n\n- Case $1$ (happy path, sizer-generated dataset):\n  - True model: sizer ($0$)\n  - $g = 0.02$\n  - $S_c = 1.0$\n  - $\\sigma_\\eta = 0.1$\n  - $\\alpha = 50$, $\\beta = 50$\n  - $T_0 = \\ln(2)/g$ (used only to define the timer expectation for comparison)\n  - $\\sigma_T = 3.0$\n  - $n_{\\text{gen}} = 3000$\n  - Seed $= 42$\n\n- Case $2$ (happy path, adder-generated dataset):\n  - True model: adder ($1$)\n  - $g = 0.02$\n  - $\\Delta_0 = 0.5$\n  - $\\sigma_\\eta = 0.1$\n  - $\\alpha = 50$, $\\beta = 50$\n  - $T_0 = \\ln(2)/g$\n  - $\\sigma_T = 3.0$\n  - $n_{\\text{gen}} = 3000$\n  - Seed $= 43$\n\n- Case $3$ (edge case, timer-generated dataset with asymmetric partitioning):\n  - True model: timer ($2$)\n  - $g = 0.02$\n  - $T_0 = \\ln(2)/g$\n  - $\\sigma_T = 3.0$\n  - $\\alpha = 5$, $\\beta = 5$\n  - $S_c = 1.0$\n  - $\\Delta_0 = 0.5$\n  - $\\sigma_\\eta = 0.1$\n  - $n_{\\text{gen}} = 3000$\n  - Seed $= 44$\n\n- Case $4$ (boundary case, adder-generated dataset with nearly deterministic division and symmetric partitioning):\n  - True model: adder ($1$)\n  - $g = 0.02$\n  - $\\Delta_0 = 0.7$\n  - $\\sigma_\\eta = 10^{-6}$\n  - $\\alpha = 500$, $\\beta = 500$\n  - $T_0 = \\ln(2)/g$\n  - $\\sigma_T = 3.0$\n  - $n_{\\text{gen}} = 2000$\n  - Seed $= 45$\n\nImplementation and Output Requirements:\n- Your program must be a single, self-contained, runnable Python $3.12$ script using only the standard library plus NumPy ($1.23.5$) and SciPy ($1.11.4$) if needed.\n- For each test case, you must:\n  1. Generate the dataset by simulating the lineage under the specified true model and parameters.\n  2. Compute the regression slope $\\hat{m}$ between $s_d$ and $s_b$.\n  3. Compute the expected slopes for sizer ($0$), adder ($1$), and timer ($\\exp(g T_0)$).\n  4. Predict the model by minimizing the absolute deviation between $\\hat{m}$ and these expected slopes, and return the identifier ($0$, $1$, or $2$).\n- Final Output Format: Your program should produce a single line of output containing the predicted model identifiers for all test cases as a comma-separated list enclosed in square brackets (e.g., \"[$m_1,m_2,m_3,m_4$]\"), where each $m_i$ is an integer in $\\{0, 1, 2\\}$.\n\nYour program must not require any user input or external files and must run deterministically using the provided seeds. The only output must be the final list of model predictions in the required format.",
            "solution": "The problem posed is a well-defined task in computational biology, specifically in the field of synthetic biology modeling. It requires the implementation of an agent-based simulation to distinguish between three canonical models of cell size control. The problem is scientifically grounded, self-contained, and algorithmically specified. All parameters are provided, and the objective is clear. Therefore, the problem is valid and a solution can be formulated.\n\nThe core of the problem lies in understanding how different division control strategies manifest in observable correlations between cell size at birth, $s_b$, and cell size at division, $s_d$. We will first formally define the models and the simulation framework, then derive the theoretical basis for the identification criterion, and finally outline the algorithmic procedure.\n\n**Foundational Principles: Cell Growth and Division**\n\nThe simulation is based on two fundamental assumptions for a single cell lineage:\n1.  **Exponential Growth:** A cell with birth size $s_b$ grows exponentially over time $t$ with a constant rate $g$. Its size is given by the function $s(t) = s_b \\exp(g t)$.\n2.  **Stochastic Partitioning:** Upon division at size $s_d$, the cell splits into two daughters. The birth size of the daughter cell we follow in the lineage is $s_b' = f \\cdot s_d$, where $f$ is a random fraction. This fraction $f$ is sampled from a Beta distribution, $f \\sim \\text{Beta}(\\alpha, \\beta)$, for each division event. The Beta distribution is defined on the interval $(0, 1)$ and is appropriate for modeling partitioning ratios. The parameters $\\alpha$ and $\\beta$ control the shape of the distribution; symmetric partitioning (mean $0.5$) occurs when $\\alpha = \\beta$.\n\n**Division Control Models**\n\nThe decision to divide is governed by one of three distinct models, each introducing stochasticity in a different manner.\n\n1.  **Sizer Model:** Division is triggered when the cell's size $s$ reaches a specific threshold. This threshold is not fixed but is subject to biological noise. The division size $s_d$ is independent of the birth size $s_b$ and is determined by:\n    $$s_d = S_c \\exp(\\eta)$$\n    where $S_c$ is a characteristic size constant and $\\eta$ is a noise term drawn from a normal distribution $\\mathcal{N}(0, \\sigma_\\eta^2)$. The use of a log-normal distribution for size ensures $s_d$ is always positive.\n\n2.  **Adder Model:** Division is triggered after the cell has added a certain amount of size, $\\Delta$, to its birth size $s_b$. This added size is noisy. The division size is given by:\n    $$s_d = s_b + \\Delta$$\n    where the added size $\\Delta = \\Delta_0 \\exp(\\eta)$, with $\\Delta_0$ being a characteristic size increment and $\\eta \\sim \\mathcal{N}(0, \\sigma_\\eta^2)$ representing noise.\n\n3.  **Timer Model:** Division is triggered after a specific duration of time, $T$, has passed since birth. This duration is noisy. Given exponential growth, the division size is:\n    $$s_d = s_b \\exp(g T)$$\n    where the division time $T$ is drawn from a normal distribution $T \\sim \\mathcal{N}(T_0, \\sigma_T^2)$, with $T_0$ being the mean division time.\n\n**Derivation of the Identification Criterion**\n\nThe problem proposes using the slope of a linear regression between the division sizes $\\{s_d^{(i)}\\}$ and birth sizes $\\{s_b^{(i)}\\}$ as the criterion for model identification. Let the linear regression model be $\\hat{s}_d = \\hat{m} s_b + \\hat{c}$. We can derive the theoretically expected slope, $m_{\\text{model}}$, for each case.\n\n-   **Sizer:** In this model, $s_d = S_c \\exp(\\eta)$. The division size $s_d$ is determined independently of the birth size $s_b$. Therefore, there is no expected correlation between $s_b$ and $s_d$. A linear regression on data generated by a sizer mechanism should yield a slope close to zero.\n    $$m_{\\text{sizer}} \\approx 0$$\n\n-   **Adder:** The model is defined by the linear relationship $s_d = s_b + \\Delta$. In a regression of $s_d$ on $s_b$, this corresponds to a line with a slope of exactly $1$ and an intercept equal to the average added size, $\\langle \\Delta \\rangle$. The noise term $\\eta$ affects the intercept, not the slope. Thus, the expected slope is precisely one.\n    $$m_{\\text{adder}} = 1$$\n\n-   **Timer:** The model is $s_d = s_b \\exp(gT)$. The relationship between $s_d$ and $s_b$ is multiplicative. The slope $\\hat{m}$ of a linear regression is given by $\\hat{m} = \\text{Cov}(s_b, s_d) / \\text{Var}(s_b)$. Substituting the model equation, we get $\\text{Cov}(s_b, s_b \\exp(gT))$. At steady state, the birth size $s_b$ of a generation is determined by the division time $T$ of the previous generation, introducing a complex correlation. However, a common and effective approximation is to assume that $s_b$ and $T$ of the same generation are approximately independent. Under this assumption, $\\text{Cov}(s_b, s_b \\exp(gT)) \\approx \\text{Var}(s_b) E[\\exp(gT)]$. The slope is then $m \\approx E[\\exp(gT)]$. For $T \\sim \\mathcal{N}(T_0, \\sigma_T^2)$, the term $gT$ is normally distributed as $gT \\sim \\mathcal{N}(gT_0, g^2\\sigma_T^2)$. The expectation of the resulting log-normal variable is $E[\\exp(gT)] = \\exp(gT_0 + g^2\\sigma_T^2/2)$. The problem specifies using the simpler approximation, which is valid for small noise or as a first-order characterization:\n    $$m_{\\text{timer}} \\approx \\exp(g T_0)$$\n    For the given parameters where $gT_0 = \\ln(2)$, this evaluates to $m_{\\text{timer}} \\approx 2$. This value is clearly distinct from $0$ and $1$, making the slope a robust identifier.\n\n**Simulation and Analysis Algorithm**\n\nFor each test case provided:\n1.  **Initialization:** The simulation parameters ($g$, $S_c$, $\\sigma_\\eta$, etc.), true model type, number of generations $n_{\\text{gen}}$, and random seed are specified. We initialize a random number generator with the given seed. We create two lists to store the sequences of birth sizes, $\\{s_b^{(i)}\\}$, and division sizes, $\\{s_d^{(i)}\\}$. The simulation begins with the first cell at generation $i=0$ having the specified initial birth size, $s_b^{(0)} = 0.8$.\n\n2.  **Generational Loop:** A loop runs for $n_{\\text{gen}}$ generations, from $i=0$ to $n_{\\text{gen}}-1$. In each iteration $i$:\n    a. The current birth size is $s_b^{(i)}$.\n    b. Based on the `true_model` for the test case, the corresponding division rule is applied to calculate the division size $s_d^{(i)}$. This involves sampling from the relevant noise distribution ($\\mathcal{N}(0, \\sigma_\\eta^2)$ for size noise or $\\mathcal{N}(T_0, \\sigma_T^2)$ for time noise).\n    c. The pair $(s_b^{(i)}, s_d^{(i)})$ is recorded.\n    d. The birth size for the next generation, $s_b^{(i+1)}$, is calculated by simulating partition. A random fraction $f$ is drawn from $\\text{Beta}(\\alpha, \\beta)$, and the next birth size is set to $s_b^{(i+1)} = f \\cdot s_d^{(i)}$.\n\n3.  **Model Identification:** After completing the simulation:\n    a. The recorded lists of birth and division sizes are converted to numerical arrays.\n    b. A simple linear regression of $s_d$ on $s_b$ is performed to compute the sample slope, $\\hat{m}$.\n    c. The three theoretical slopes are calculated: $m_0 = 0$, $m_1 = 1$, and $m_2 = \\exp(g T_0)$.\n    d. The absolute deviations $|\\hat{m} - m_0|$, $|\\hat{m} - m_1|$, and $|\\hat{m} - m_2|$ are computed.\n    e. The model corresponding to the minimum deviation is chosen as the predicted model. The result is its integer identifier ($0$ for sizer, $1$ for adder, $2$ for timer).\n\nThis entire procedure is repeated for each of the four test cases, and the resulting list of identifiers is formatted as the final output.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the cell division model identification problem for a suite of test cases.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1 (happy path, sizer-generated dataset)\n        {\n            \"true_model\": 0, \"g\": 0.02, \"S_c\": 1.0, \"sigma_eta\": 0.1,\n            \"alpha\": 50, \"beta\": 50, \"T_0_factor\": np.log(2), \"sigma_T\": 3.0,\n            \"delta_0\": 0.5, \"n_gen\": 3000, \"seed\": 42\n        },\n        # Case 2 (happy path, adder-generated dataset)\n        {\n            \"true_model\": 1, \"g\": 0.02, \"delta_0\": 0.5, \"sigma_eta\": 0.1,\n            \"alpha\": 50, \"beta\": 50, \"T_0_factor\": np.log(2), \"sigma_T\": 3.0,\n            \"S_c\": 1.0, \"n_gen\": 3000, \"seed\": 43\n        },\n        # Case 3 (edge case, timer-generated dataset with asymmetric partitioning)\n        {\n            \"true_model\": 2, \"g\": 0.02, \"T_0_factor\": np.log(2), \"sigma_T\": 3.0,\n            \"alpha\": 5, \"beta\": 5, \"S_c\": 1.0, \"delta_0\": 0.5,\n            \"sigma_eta\": 0.1, \"n_gen\": 3000, \"seed\": 44\n        },\n        # Case 4 (boundary case, adder-generated dataset with low noise)\n        {\n            \"true_model\": 1, \"g\": 0.02, \"delta_0\": 0.7, \"sigma_eta\": 1e-6,\n            \"alpha\": 500, \"beta\": 500, \"T_0_factor\": np.log(2), \"sigma_T\": 3.0,\n            \"S_c\": 1.0, \"n_gen\": 2000, \"seed\": 45\n        }\n    ]\n\n    results = []\n    initial_s_b = 0.8\n\n    for case in test_cases:\n        # Set seed for reproducibility\n        np.random.seed(case[\"seed\"])\n\n        # Unpack parameters\n        true_model = case[\"true_model\"]\n        g = case[\"g\"]\n        n_gen = case[\"n_gen\"]\n        alpha = case[\"alpha\"]\n        beta = case[\"beta\"]\n        sigma_eta = case[\"sigma_eta\"]\n        S_c = case[\"S_c\"]\n        delta_0 = case[\"delta_0\"]\n        # T_0 is specified relative to g\n        T_0 = case[\"T_0_factor\"] / g\n        sigma_T = case[\"sigma_T\"]\n\n        s_b_data = []\n        s_d_data = []\n        \n        current_s_b = initial_s_b\n\n        # Simulation loop for a single lineage\n        for _ in range(n_gen):\n            s_b = current_s_b\n            s_d = 0.0\n\n            # Apply the true model to determine division size s_d\n            if true_model == 0:  # Sizer\n                eta = np.random.normal(0, sigma_eta)\n                s_d = S_c * np.exp(eta)\n            elif true_model == 1:  # Adder\n                eta = np.random.normal(0, sigma_eta)\n                s_d = s_b + delta_0 * np.exp(eta)\n            elif true_model == 2:  # Timer\n                T = np.random.normal(T_0, sigma_T)\n                # Ensure time is non-negative, though highly unlikely to be negative\n                if T  0: T = 0\n                s_d = s_b * np.exp(g * T)\n\n            # Store the data for the current generation\n            s_b_data.append(s_b)\n            s_d_data.append(s_d)\n\n            # Calculate birth size for the next generation via partitioning\n            f = np.random.beta(alpha, beta)\n            current_s_b = f * s_d\n\n        # Convert lists to NumPy arrays for analysis\n        s_b_array = np.array(s_b_data)\n        s_d_array = np.array(s_d_data)\n\n        # Perform linear regression to find the slope\n        # np.polyfit(x, y, 1) returns [slope, intercept]\n        m_hat = np.polyfit(s_b_array, s_d_array, 1)[0]\n\n        # Define the theoretical slopes for comparison\n        m_sizer = 0.0\n        m_adder = 1.0\n        m_timer = np.exp(g * T_0)\n        \n        theoretical_slopes = [m_sizer, m_adder, m_timer]\n\n        # Calculate deviations and find the model with the minimum deviation\n        deviations = [np.abs(m_hat - m_model) for m_model in theoretical_slopes]\n        predicted_model_id = np.argmin(deviations)\n        \n        results.append(predicted_model_id)\n\n    # Print the final result in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}