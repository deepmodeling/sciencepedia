{
    "hands_on_practices": [
        {
            "introduction": "The Fokker-Planck equation provides a powerful mesoscopic description of a system's probability distribution, but it is fundamentally derived from the microscopic dynamics of individual stochastic trajectories. This exercise solidifies the connection between the particle-level Langevin equation and the population-level Fokker-Planck equation, a crucial step in building intuition for stochastic modeling. By analyzing a particle in a harmonic trap—a common physical analogy for gene expression levels near a stable state—you will derive the probability current that governs the flow of probability density .",
            "id": "2001798",
            "problem": "A microscopic dielectric bead is held in an optical trap, which can be modeled as a one-dimensional harmonic potential well described by the potential energy $V(x) = \\frac{1}{2}kx^2$, where $k$ is the trap stiffness and $x$ is the displacement from the center of the trap. The bead is immersed in a fluid at a constant absolute temperature $T$, causing it to undergo Brownian motion. In the overdamped regime, where inertial effects are negligible, the bead's motion along the $x$-axis is governed by the Langevin equation:\n$$\n\\gamma \\frac{dx}{dt} = -kx + \\xi(t)\n$$\nHere, $\\gamma$ is the viscous drag coefficient. The term $\\xi(t)$ represents the stochastic thermal force from the surrounding fluid molecules. It is modeled as Gaussian white noise with statistical properties $\\langle \\xi(t) \\rangle = 0$ and $\\langle \\xi(t)\\xi(t') \\rangle = 2D\\gamma^2 \\delta(t-t')$, where $D$ is the diffusion coefficient of the bead.\n\nThe time evolution of the probability density function $P(x, t)$ of finding the bead at position $x$ at time $t$ is described by a continuity equation of the form:\n$$\n\\frac{\\partial P(x, t)}{\\partial t} = -\\frac{\\partial J(x, t)}{\\partial x}\n$$\nwhere $J(x, t)$ is the probability current. Based on the provided Langevin equation and the properties of the noise, determine the expression for this probability current $J(x, t)$. Your expression should be in terms of $x$, the probability density $P(x,t)$ and its spatial derivative, and the physical parameters $k$, $\\gamma$, and $D$.",
            "solution": "We start from the overdamped Langevin equation\n$$\n\\gamma \\frac{dx}{dt} = -k x + \\xi(t),\n$$\nwith noise statistics $\\langle \\xi(t) \\rangle = 0$ and $\\langle \\xi(t)\\xi(t') \\rangle = 2 D \\gamma^{2} \\delta(t-t')$. Introduce a standard Gaussian white noise $\\eta(t)$ with $\\langle \\eta(t) \\rangle = 0$ and $\\langle \\eta(t)\\eta(t') \\rangle = \\delta(t-t')$ by writing\n$$\n\\xi(t) = \\gamma \\sqrt{2D}\\,\\eta(t).\n$$\nDividing the Langevin equation by $\\gamma$ gives\n$$\n\\frac{dx}{dt} = -\\frac{k}{\\gamma} x + \\sqrt{2D}\\,\\eta(t).\n$$\nIn Itō form, this is the stochastic differential equation\n$$\ndx = a(x)\\,dt + b\\,dW_{t},\n$$\nwith drift $a(x) = -\\frac{k}{\\gamma}x$ and diffusion amplitude $b = \\sqrt{2D}$, where $W_{t}$ is a Wiener process.\n\nThe corresponding Fokker-Planck equation for the probability density $P(x,t)$ is\n$$\n\\frac{\\partial P}{\\partial t} = -\\frac{\\partial}{\\partial x}\\!\\left[a(x) P\\right] + \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}\\!\\left[b^{2} P\\right].\n$$\nSince $b$ is constant and $b^{2} = 2D$, this becomes\n$$\n\\frac{\\partial P}{\\partial t} = -\\frac{\\partial}{\\partial x}\\!\\left[-\\frac{k}{\\gamma} x\\, P\\right] + D \\frac{\\partial^{2} P}{\\partial x^{2}}.\n$$\nWriting this in continuity form,\n$$\n\\frac{\\partial P}{\\partial t} = -\\frac{\\partial J}{\\partial x},\n$$\nwe identify the probability current $J(x,t)$ by matching terms:\n$$\n-\\frac{\\partial J}{\\partial x} = -\\frac{\\partial}{\\partial x}\\!\\left[a(x) P\\right] + D \\frac{\\partial^{2} P}{\\partial x^{2}} = -\\frac{\\partial}{\\partial x}\\!\\left[a(x) P - D \\frac{\\partial P}{\\partial x}\\right].\n$$\nTherefore,\n$$\nJ(x,t) = a(x) P(x,t) - D \\frac{\\partial P(x,t)}{\\partial x}.\n$$\nSubstituting $a(x) = -\\frac{k}{\\gamma} x$ yields\n$$\nJ(x,t) = -\\frac{k}{\\gamma} x\\, P(x,t) - D \\frac{\\partial P(x,t)}{\\partial x}.\n$$\nThis expression is in terms of $x$, $P(x,t)$ and its spatial derivative, and the parameters $k$, $\\gamma$, and $D$, as required.",
            "answer": "$$\\boxed{-\\frac{k}{\\gamma}x\\,P(x,t)-D\\,\\frac{\\partial P(x,t)}{\\partial x}}$$"
        },
        {
            "introduction": "Once we have a Fokker-Planck equation, we often want to understand the system's bulk properties without solving for the full probability distribution, which can be difficult. The method of moments is a primary analytical tool for this purpose, allowing us to derive the dynamics of statistical quantities like the mean and variance. This practice focuses on the Ornstein-Uhlenbeck process, a cornerstone model in stochastic calculus, to demonstrate how to derive and solve the differential equations for the first and second moments, providing a complete picture of how the system's position distribution evolves over time .",
            "id": "1103843",
            "problem": "The dynamics of a particle undergoing an Ornstein-Uhlenbeck process in one dimension are described by the following Fokker-Planck equation for the probability density function $P(x, t)$:\n$$\n\\frac{\\partial P(x, t)}{\\partial t} = \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P(x, t)\\right) + D \\frac{\\partial^2 P(x, t)}{\\partial x^2}\n$$\nHere, $x$ is the position of the particle, $t$ is time, $\\tau > 0$ is the relaxation time constant, and $D > 0$ is the diffusion coefficient.\n\nConsider a particle that is sharply localized at the origin at time $t=0$. This initial condition is represented by the initial probability distribution $P(x, 0) = \\delta(x)$, where $\\delta(x)$ is the Dirac delta function.\n\nBy analyzing the time evolution of the moments of the position, derive an expression for the time-dependent variance, $\\sigma_x^2(t) = \\langle x^2(t) \\rangle - \\langle x(t) \\rangle^2$. Assume that the probability density $P(x,t)$ and its spatial derivatives vanish sufficiently fast as $x \\to \\pm\\infty$ for all $t > 0$.",
            "solution": "The goal is to compute the variance $\\sigma_x^2(t) = \\langle x^2(t) \\rangle - \\langle x(t) \\rangle^2$. We will achieve this by deriving and solving ordinary differential equations for the first two moments, $\\langle x(t) \\rangle$ and $\\langle x^2(t) \\rangle$.\n\nThe $n$-th moment of the position $x$ is defined as:\n$$\n\\langle x^n(t) \\rangle = \\int_{-\\infty}^{\\infty} x^n P(x, t) \\, dx\n$$\nThe time derivative of the $n$-th moment is:\n$$\n\\frac{d \\langle x^n(t) \\rangle}{dt} = \\int_{-\\infty}^{\\infty} x^n \\frac{\\partial P(x, t)}{\\partial t} \\, dx\n$$\nSubstituting the given Fokker-Planck equation for $\\frac{\\partial P}{\\partial t}$:\n$$\n\\frac{d \\langle x^n \\rangle}{dt} = \\int_{-\\infty}^{\\infty} x^n \\left[ \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P\\right) + D \\frac{\\partial^2 P}{\\partial x^2} \\right] dx\n$$\nWe will evaluate this expression for $n=1$ and $n=2$ using integration by parts. The boundary terms will vanish because we assume $P(x,t)$ and its derivatives go to zero at $x \\to \\pm\\infty$.\n\n**1. Time evolution of the first moment, $\\langle x(t) \\rangle$**\n\nFor $n=1$:\n$$\n\\frac{d \\langle x \\rangle}{dt} = \\int_{-\\infty}^{\\infty} x \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P\\right) dx + D \\int_{-\\infty}^{\\infty} x \\frac{\\partial^2 P}{\\partial x^2} dx\n$$\nLet's evaluate each integral separately using integration by parts, $\\int u \\, dv = [uv] - \\int v \\, du$.\n\nFor the first integral (drift term): let $u=x$ and $dv = \\frac{\\partial}{\\partial x} (\\frac{x}{\\tau} P) dx$.\n$$\n\\int_{-\\infty}^{\\infty} x \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P\\right) dx = \\left[ x \\left(\\frac{x}{\\tau} P\\right) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} \\left(\\frac{x}{\\tau} P\\right) dx = 0 - \\frac{1}{\\tau} \\int_{-\\infty}^{\\infty} x P \\, dx = -\\frac{1}{\\tau} \\langle x \\rangle\n$$\n\nFor the second integral (diffusion term): let $u=x$ and $dv = \\frac{\\partial^2 P}{\\partial x^2} dx$.\n$$\n\\int_{-\\infty}^{\\infty} x \\frac{\\partial^2 P}{\\partial x^2} dx = \\left[ x \\frac{\\partial P}{\\partial x} \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} \\frac{\\partial P}{\\partial x} dx = 0 - [P]_{-\\infty}^{\\infty} = 0\n$$\n\nCombining the terms, we get the ODE for the first moment:\n$$\n\\frac{d \\langle x \\rangle}{dt} = -\\frac{1}{\\tau} \\langle x \\rangle\n$$\nThe initial condition is $P(x,0)=\\delta(x)$, so $\\langle x(0) \\rangle = \\int_{-\\infty}^{\\infty} x \\delta(x) dx = 0$.\nThe solution to this ODE with the given initial condition is $\\langle x(t) \\rangle = 0$ for all $t \\ge 0$.\n\n**2. Time evolution of the second moment, $\\langle x^2(t) \\rangle$**\n\nFor $n=2$:\n$$\n\\frac{d \\langle x^2 \\rangle}{dt} = \\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P\\right) dx + D \\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial^2 P}{\\partial x^2} dx\n$$\nAgain, we evaluate each integral using integration by parts.\n\nFor the first integral (drift term): let $u=x^2$ and $dv = \\frac{\\partial}{\\partial x} (\\frac{x}{\\tau} P) dx$.\n$$\n\\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial}{\\partial x} \\left(\\frac{x}{\\tau} P\\right) dx = \\left[ x^2 \\left(\\frac{x}{\\tau} P\\right) \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} 2x \\left(\\frac{x}{\\tau} P\\right) dx = 0 - \\frac{2}{\\tau} \\int_{-\\infty}^{\\infty} x^2 P \\, dx = -\\frac{2}{\\tau} \\langle x^2 \\rangle\n$$\n\nFor the second integral (diffusion term): let $u=x^2$ and $dv = \\frac{\\partial^2 P}{\\partial x^2} dx$.\n$$\n\\int_{-\\infty}^{\\infty} x^2 \\frac{\\partial^2 P}{\\partial x^2} dx = \\left[ x^2 \\frac{\\partial P}{\\partial x} \\right]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} 2x \\frac{\\partial P}{\\partial x} dx = -2 \\int_{-\\infty}^{\\infty} x \\frac{\\partial P}{\\partial x} dx\n$$\nWe integrate by parts again: let $u=x$ and $dv = \\frac{\\partial P}{\\partial x} dx$.\n$$\n-2 \\int_{-\\infty}^{\\infty} x \\frac{\\partial P}{\\partial x} dx = -2 \\left( [xP]_{-\\infty}^{\\infty} - \\int_{-\\infty}^{\\infty} P \\, dx \\right) = -2(0 - 1) = 2\n$$\nThe integral $\\int P dx = 1$ because probability is conserved.\n\nCombining the terms, we get the ODE for the second moment:\n$$\n\\frac{d \\langle x^2 \\rangle}{dt} = -\\frac{2}{\\tau} \\langle x^2 \\rangle + 2D\n$$\nThis is a first-order linear inhomogeneous differential equation. The initial condition is $\\langle x^2(0) \\rangle = \\int_{-\\infty}^{\\infty} x^2 \\delta(x) dx = 0$.\nTo solve the ODE, we find the homogeneous solution and a particular solution. The homogeneous equation $\\frac{dy_h}{dt} + \\frac{2}{\\tau} y_h = 0$ has the solution $y_h(t) = C e^{-2t/\\tau}$. For the particular solution, we try a constant $y_p = A$. Substituting into the ODE gives $0 + \\frac{2}{\\tau} A = 2D$, so $A = D\\tau$.\nThe general solution is $\\langle x^2(t) \\rangle = C e^{-2t/\\tau} + D\\tau$.\nUsing the initial condition $\\langle x^2(0) \\rangle = 0$:\n$$\n0 = C e^0 + D\\tau \\implies C = -D\\tau\n$$\nSo, the solution for the second moment is:\n$$\n\\langle x^2(t) \\rangle = D\\tau - D\\tau e^{-2t/\\tau} = D\\tau \\left(1 - e^{-2t/\\tau}\\right)\n$$\n\n**3. Calculation of the Variance**\n\nFinally, we compute the variance $\\sigma_x^2(t)$:\n$$\n\\sigma_x^2(t) = \\langle x^2(t) \\rangle - \\langle x(t) \\rangle^2\n$$\nSubstituting the expressions we found for the moments:\n$$\n\\sigma_x^2(t) = D\\tau \\left(1 - e^{-2t/\\tau}\\right) - (0)^2\n$$\nThus, the time-dependent variance is:\n$$\n\\sigma_x^2(t) = D\\tau \\left(1 - e^{-2t/\\tau}\\right)\n$$",
            "answer": "$$\n\\boxed{D\\tau \\left(1 - e^{-2t/\\tau}\\right)}\n$$"
        },
        {
            "introduction": "While linear models like the Ornstein-Uhlenbeck process are analytically tractable, most systems in synthetic biology involve nonlinear interactions, such as Hill-type gene regulation. For these systems, the hierarchy of moment equations is not closed, meaning the equation for the $n$-th moment depends on the $(n+1)$-th moment. This problem introduces the critical technique of moment closure, specifically a Gaussian closure approximation, to obtain a finite, solvable system of equations for the mean and variance. This is a powerful method for approximating the behavior of complex, nonlinear stochastic biological circuits .",
            "id": "3934987",
            "problem": "Consider a single-gene regulation model in synthetic biology where the protein concentration is described by a continuous-state stochastic process with probability density $p(x,t)$ obeying the Fokker-Planck equation\n$$\n\\frac{\\partial}{\\partial t} p(x,t) \\;=\\; -\\frac{\\partial}{\\partial x}\\!\\left[a(x)\\,p(x,t)\\right] \\;+\\; \\frac{1}{2}\\,\\frac{\\partial^{2}}{\\partial x^{2}}\\!\\left[b(x)\\,p(x,t)\\right],\n$$\nwhere the drift $a(x)$ represents synthesis minus degradation and the diffusion $b(x)$ captures intrinsic birth–death noise at finite system size. Assume a Hill-type repression for synthesis and first-order degradation,\n$$\na(x) \\;=\\; f(x) \\;-\\; \\gamma\\,x,\\qquad f(x) \\;=\\; \\frac{\\alpha}{1+\\left(\\frac{x}{K}\\right)^{n}},\\qquad b(x) \\;=\\; \\frac{f(x)+\\gamma\\,x}{\\Omega},\n$$\nwith parameters $\\alpha>0$, $\\gamma>0$, $K>0$, $n\\geq 1$, and system size $\\Omega>0$. Let the mean and variance of $x$ at time $t$ be $\\mu(t)=\\mathbb{E}[x]$ and $\\sigma^{2}(t)=\\mathbb{E}\\!\\left[(x-\\mu)^{2}\\right]$. Starting from the Fokker-Planck equation and standard moment definitions, derive ordinary differential equations for $\\mu(t)$ and $\\sigma^{2}(t)$ in terms of $\\mu(t)$, $\\sigma^{2}(t)$, and derivatives of $f(x)$ evaluated at $x=\\mu(t)$. To close the system, construct a Gaussian moment closure in which third-order moments that appear are approximated by their Gaussian values. Write the resulting closed ordinary differential equations for $\\mu(t)$ and $\\sigma^{2}(t)$ explicitly in terms of $\\alpha$, $\\gamma$, $K$, $n$, $\\Omega$, $\\mu(t)$, and $\\sigma^{2}(t)$, using $f(\\mu)$, $f'(\\mu)$, and $f''(\\mu)$ where needed.\n\nFinally, report the Gaussian-closed expression for the third raw moment $\\mathbb{E}[x^{3}]$ in terms of the mean $\\mu$ and variance $\\sigma^{2}$. Provide this expression as your final answer. Do not include units. If you choose to simplify any composite fractions, ensure algebraic exactness; no rounding is required.",
            "solution": "We begin by deriving the ordinary differential equations (ODEs) for the mean $\\mu(t) = \\mathbb{E}[x]$ and the variance $\\sigma^{2}(t) = \\mathbb{E}[(x-\\mu)^{2}]$. The time evolution of the expectation of a general function $g(x)$ is given by\n$$\n\\frac{d}{dt}\\mathbb{E}[g(x)] \\;=\\; \\int g(x) \\frac{\\partial p(x,t)}{\\partial t} dx.\n$$\nSubstituting the Fokker-Planck equation, we have\n$$\n\\frac{d}{dt}\\mathbb{E}[g(x)] \\;=\\; \\int g(x) \\left( -\\frac{\\partial}{\\partial x}[a(x)p(x,t)] + \\frac{1}{2}\\frac{\\partial^{2}}{\\partial x^{2}}[b(x)p(x,t)] \\right) dx.\n$$\nIntegrating the first term by parts once and the second term by parts twice, and assuming that $p(x,t)$ and its derivatives vanish at the boundaries ($x \\rightarrow \\pm\\infty$), we obtain the general formula for moment dynamics:\n$$\n\\frac{d}{dt}\\mathbb{E}[g(x)] \\;=\\; \\mathbb{E}\\left[a(x)g'(x)\\right] + \\frac{1}{2}\\mathbb{E}\\left[b(x)g''(x)\\right].\n$$\n\nFirst, we derive the ODE for the mean $\\mu(t)$. Let $g(x)=x$. Then $g'(x)=1$ and $g''(x)=0$. Applying the formula gives\n$$\n\\frac{d\\mu}{dt} \\;=\\; \\frac{d}{dt}\\mathbb{E}[x] \\;=\\; \\mathbb{E}[a(x)\\cdot 1] + \\frac{1}{2}\\mathbb{E}[b(x)\\cdot 0] \\;=\\; \\mathbb{E}[a(x)].\n$$\nSubstituting the given expression for the drift $a(x) = f(x) - \\gamma x$:\n$$\n\\frac{d\\mu}{dt} \\;=\\; \\mathbb{E}[f(x) - \\gamma x] \\;=\\; \\mathbb{E}[f(x)] - \\gamma \\mathbb{E}[x] \\;=\\; \\mathbb{E}[f(x)] - \\gamma \\mu.\n$$\nThis equation is not closed as it depends on $\\mathbb{E}[f(x)]$. To close the system, we approximate this term by Taylor-expanding $f(x)$ around the mean $\\mu$:\n$$\nf(x) \\;=\\; f(\\mu) + f'(\\mu)(x-\\mu) + \\frac{1}{2}f''(\\mu)(x-\\mu)^{2} + \\frac{1}{6}f'''(\\mu)(x-\\mu)^{3} + \\dots\n$$\nTaking the expectation of both sides:\n$$\n\\mathbb{E}[f(x)] \\;=\\; f(\\mu) + f'(\\mu)\\mathbb{E}[x-\\mu] + \\frac{1}{2}f''(\\mu)\\mathbb{E}[(x-\\mu)^{2}] + \\frac{1}{6}f'''(\\mu)\\mathbb{E}[(x-\\mu)^{3}] + \\dots\n$$\nBy definition, $\\mathbb{E}[x-\\mu]=0$ and $\\mathbb{E}[(x-\\mu)^{2}]=\\sigma^{2}$. The Gaussian moment closure assumes that the distribution $p(x,t)$ is approximately Gaussian, for which all cumulants of order three and higher are zero. In particular, the third central moment is zero: $\\mathbb{E}[(x-\\mu)^{3}]=0$. Truncating the series at this order, we obtain the approximation\n$$\n\\mathbb{E}[f(x)] \\;\\approx\\; f(\\mu) + \\frac{1}{2}f''(\\mu)\\sigma^{2}.\n$$\nSubstituting this back into the equation for $\\frac{d\\mu}{dt}$, we get the first closed ODE:\n$$\n\\frac{d\\mu}{dt} \\;=\\; f(\\mu) - \\gamma\\mu + \\frac{1}{2}f''(\\mu)\\sigma^{2}.\n$$\n\nNext, we derive the ODE for the variance $\\sigma^{2}(t)$. We start with the second raw moment $m_{2}(t) = \\mathbb{E}[x^{2}]$. Let $g(x)=x^{2}$. Then $g'(x)=2x$ and $g''(x)=2$. The dynamics are\n$$\n\\frac{dm_{2}}{dt} \\;=\\; \\mathbb{E}[a(x)\\cdot(2x)] + \\frac{1}{2}\\mathbb{E}[b(x)\\cdot 2] \\;=\\; 2\\mathbb{E}[x a(x)] + \\mathbb{E}[b(x)].\n$$\nThe variance is $\\sigma^{2} = m_{2} - \\mu^{2}$. Differentiating with respect to time:\n$$\n\\frac{d\\sigma^{2}}{dt} \\;=\\; \\frac{dm_{2}}{dt} - 2\\mu\\frac{d\\mu}{dt} \\;=\\; (2\\mathbb{E}[x a(x)] + \\mathbb{E}[b(x)]) - 2\\mu\\mathbb{E}[a(x)].\n$$\nThis can be simplified:\n$$\n\\frac{d\\sigma^{2}}{dt} \\;=\\; 2(\\mathbb{E}[x a(x)] - \\mu\\mathbb{E}[a(x)]) + \\mathbb{E}[b(x)] \\;=\\; 2\\mathbb{E}[(x-\\mu)a(x)] + \\mathbb{E}[b(x)].\n$$\nNow we apply the closure approximations to the two terms on the right-hand side. For the first term, we substitute $a(x) = f(x) - \\gamma x$:\n$$\n\\mathbb{E}[(x-\\mu)a(x)] \\;=\\; \\mathbb{E}[(x-\\mu)(f(x) - \\gamma x)] \\;=\\; \\mathbb{E}[(x-\\mu)f(x)] - \\gamma\\mathbb{E}[(x-\\mu)x].\n$$\nThe second part is $\\mathbb{E}[(x-\\mu)x] = \\mathbb{E}[x^{2}-\\mu x] = \\mathbb{E}[x^{2}] - \\mu\\mathbb{E}[x] = m_{2} - \\mu^{2} = \\sigma^{2}$. To approximate $\\mathbb{E}[(x-\\mu)f(x)]$, we use the same Taylor series for $f(x)$:\n$$\n\\mathbb{E}[(x-\\mu)f(x)] \\;\\approx\\; \\mathbb{E}\\left[(x-\\mu)\\left(f(\\mu) + f'(\\mu)(x-\\mu) + \\frac{1}{2}f''(\\mu)(x-\\mu)^{2}\\right)\\right].\n$$\n$$\n\\mathbb{E}[(x-\\mu)f(x)] \\;=\\; f(\\mu)\\mathbb{E}[x-\\mu] + f'(\\mu)\\mathbb{E}[(x-\\mu)^{2}] + \\frac{1}{2}f''(\\mu)\\mathbb{E}[(x-\\mu)^{3}].\n$$\nUsing $\\mathbb{E}[x-\\mu]=0$, $\\mathbb{E}[(x-\\mu)^{2}]=\\sigma^{2}$, and the Gaussian closure $\\mathbb{E}[(x-\\mu)^{3}]=0$, this simplifies to\n$$\n\\mathbb{E}[(x-\\mu)f(x)] \\;\\approx\\; f'(\\mu)\\sigma^{2}.\n$$\nThus, the first term in the variance equation is\n$$\n2\\mathbb{E}[(x-\\mu)a(x)] \\;\\approx\\; 2(f'(\\mu)\\sigma^{2} - \\gamma\\sigma^{2}) \\;=\\; 2(f'(\\mu)-\\gamma)\\sigma^{2}.\n$$\nFor the second term in the variance equation, $\\mathbb{E}[b(x)]$, we substitute $b(x) = (f(x)+\\gamma x)/\\Omega$:\n$$\n\\mathbb{E}[b(x)] \\;=\\; \\frac{1}{\\Omega}\\left(\\mathbb{E}[f(x)] + \\gamma\\mathbb{E}[x]\\right) \\;=\\; \\frac{1}{\\Omega}\\left(\\mathbb{E}[f(x)]+\\gamma\\mu\\right).\n$$\nUsing our previous approximation for $\\mathbb{E}[f(x)]$:\n$$\n\\mathbb{E}[b(x)] \\;\\approx\\; \\frac{1}{\\Omega}\\left(f(\\mu) + \\frac{1}{2}f''(\\mu)\\sigma^{2} + \\gamma\\mu\\right).\n$$\nCombining the approximated terms, we obtain the second closed ODE for the variance:\n$$\n\\frac{d\\sigma^{2}}{dt} \\;=\\; 2\\left(f'(\\mu)-\\gamma\\right)\\sigma^{2} + \\frac{1}{\\Omega}\\left(f(\\mu) + \\gamma\\mu + \\frac{1}{2}f''(\\mu)\\sigma^{2}\\right).\n$$\n\nFinally, we find the Gaussian-closed expression for the third raw moment, $\\mathbb{E}[x^{3}]$. The Gaussian closure approximation is fundamentally based on setting the third central moment to zero:\n$$\n\\mathbb{E}[(x-\\mu)^{3}] \\;=\\; 0.\n$$\nWe expand the central moment in terms of raw moments:\n$$\n\\mathbb{E}[(x-\\mu)^{3}] \\;=\\; \\mathbb{E}[x^{3} - 3x^{2}\\mu + 3x\\mu^{2} - \\mu^{3}].\n$$\nBy linearity of expectation, this becomes:\n$$\n\\mathbb{E}[x^{3}] - 3\\mu\\mathbb{E}[x^{2}] + 3\\mu^{2}\\mathbb{E}[x] - \\mu^{3} \\;=\\; 0.\n$$\nSubstituting the definitions $\\mathbb{E}[x]=\\mu$ and $\\mathbb{E}[x^{2}]=m_{2}$:\n$$\n\\mathbb{E}[x^{3}] - 3\\mu m_{2} + 3\\mu^{2}\\mu - \\mu^{3} \\;=\\; 0,\n$$\n$$\n\\mathbb{E}[x^{3}] - 3\\mu m_{2} + 2\\mu^{3} \\;=\\; 0.\n$$\nSolving for $\\mathbb{E}[x^{3}]$:\n$$\n\\mathbb{E}[x^{3}] \\;=\\; 3\\mu m_{2} - 2\\mu^{3}.\n$$\nTo express this in terms of the variance $\\sigma^{2}$, we use the relation $m_{2} = \\sigma^{2} + \\mu^{2}$:\n$$\n\\mathbb{E}[x^{3}] \\;=\\; 3\\mu(\\sigma^{2}+\\mu^{2}) - 2\\mu^{3} \\;=\\; 3\\mu\\sigma^{2} + 3\\mu^{3} - 2\\mu^{3}.\n$$\nThis simplifies to the final expression for the third raw moment under Gaussian closure:\n$$\n\\mathbb{E}[x^{3}] \\;=\\; \\mu^{3} + 3\\mu\\sigma^{2}.\n$$\nThis expression is the answer requested by the problem.",
            "answer": "$$\n\\boxed{\\mu^{3} + 3\\mu\\sigma^{2}}\n$$"
        }
    ]
}