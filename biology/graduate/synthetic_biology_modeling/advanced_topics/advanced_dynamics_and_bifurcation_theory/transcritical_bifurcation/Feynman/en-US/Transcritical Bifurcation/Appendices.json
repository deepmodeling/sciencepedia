{
    "hands_on_practices": [
        {
            "introduction": "To truly understand a transcritical bifurcation, we begin with its \"normal form,\" the simplest equation that captures its essential dynamics. This practice guides you through the analysis of $\\dot{x} = rx - x^2$, the canonical model for this phenomenon. By finding the fixed points and determining their stability, you will directly observe the characteristic exchange of stability that occurs as the parameter $r$ crosses the critical value of zero.",
            "id": "1724873",
            "problem": "Consider the one-dimensional dynamical system described by the differential equation:\n$$ \\frac{dx}{dt} = rx - x^2 $$\nHere, $x = x(t)$ represents a state variable of the system, and $r$ is a real-valued control parameter. This equation serves as the normal form for a common type of bifurcation and can model phenomena where a single parameter influences both growth and saturation effects.\n\nYour task is to analyze the fixed points (also known as equilibrium points) of this system and their linear stability as the parameter $r$ is varied across the real numbers. Based on your analysis, which of the following statements provides the most accurate description of the system's behavior?\n\nA. For $r  0$, the system has one stable fixed point at $x=0$. For $r  0$, this fixed point becomes unstable and two new stable fixed points appear symmetrically around $x=0$.\n\nB. For $r  0$, the system has no real fixed points. At $r=0$, a single fixed point appears, which then splits into a stable and an unstable fixed point for $r  0$.\n\nC. For all non-zero $r$, the system possesses two fixed points. For $r  0$, the fixed point at $x=0$ is unstable and the fixed point at $x=r$ is stable. This stability pattern is reversed for $r  0$.\n\nD. For all non-zero $r$, the system possesses two fixed points. For $r  0$, the fixed point at $x=0$ is stable and the fixed point at $x=r$ is unstable. This stability pattern is reversed for $r  0$.\n\nE. The system always has a stable fixed point at $x=r$ and an unstable fixed point at $x=0$ for all non-zero values of $r$.",
            "solution": "To determine the correct description of the system's behavior, we need to find the fixed points and analyze their stability as a function of the parameter $r$. The dynamical system is given by $\\dot{x} = f(x, r)$, where $f(x, r) = rx - x^2$.\n\n**Step 1: Find the fixed points**\n\nFixed points, denoted by $x^*$, are the values of $x$ for which the system is in equilibrium, i.e., $\\dot{x} = 0$.\nWe set the given differential equation to zero:\n$$ rx^* - (x^*)^2 = 0 $$\nFactoring the expression, we get:\n$$ x^*(r - x^*) = 0 $$\nThis equation yields two solutions for the fixed points:\n1.  $x_1^* = 0$\n2.  $x_2^* = r$\n\nThese two fixed points exist for any real value of $r$. Note that when $r=0$, the two fixed points coincide, $x_1^* = x_2^* = 0$. For any $r \\ne 0$, there are two distinct fixed points.\n\n**Step 2: Analyze the stability of the fixed points**\n\nThe linear stability of a fixed point $x^*$ for a one-dimensional system $\\dot{x} = f(x)$ is determined by the sign of the derivative $f'(x) = \\frac{df}{dx}$ evaluated at that fixed point.\n- If $f'(x^*)  0$, the fixed point is linearly stable.\n- If $f'(x^*)  0$, the fixed point is linearly unstable.\n- If $f'(x^*) = 0$, the linear stability analysis is inconclusive, and a higher-order analysis is required. This point typically corresponds to a bifurcation.\n\nFirst, we compute the derivative of $f(x, r) = rx - x^2$ with respect to $x$:\n$$ f'(x, r) = \\frac{d}{dx}(rx - x^2) = r - 2x $$\n\nNow, we evaluate this derivative at each of the two fixed points.\n\n**Stability of the fixed point $x_1^* = 0$:**\nWe substitute $x=0$ into the expression for $f'(x, r)$:\n$$ f'(0, r) = r - 2(0) = r $$\nThe stability of $x_1^*=0$ depends directly on the sign of $r$:\n- If $r  0$, then $f'(0, r)  0$, which means the fixed point $x_1^*=0$ is **stable**.\n- If $r  0$, then $f'(0, r)  0$, which means the fixed point $x_1^*=0$ is **unstable**.\n- If $r = 0$, then $f'(0, 0) = 0$, which is the bifurcation point.\n\n**Stability of the fixed point $x_2^* = r$:**\nWe substitute $x=r$ into the expression for $f'(x, r)$:\n$$ f'(r, r) = r - 2(r) = -r $$\nThe stability of $x_2^*=r$ depends on the sign of $-r$:\n- If $r  0$, then $-r  0$, so $f'(r, r)  0$. This means the fixed point $x_2^*=r$ is **unstable**.\n- If $r  0$, then $-r  0$, so $f'(r, r)  0$. This means the fixed point $x_2^*=r$ is **stable**.\n- If $r = 0$, then $f'(0, 0) = 0$, which is the bifurcation point where $x_2^* = x_1^*$.\n\n**Step 3: Summarize the results and select the correct option**\n\nLet's compile our findings:\n- **For $r  0$:** We have two fixed points. $x_1^* = 0$ is stable, and $x_2^* = r$ is unstable.\n- **For $r = 0$:** We have one fixed point at $x^*=0$. This is the bifurcation point where the two fixed points meet.\n- **For $r  0$:** We have two fixed points. $x_1^* = 0$ is now unstable, and $x_2^* = r$ is now stable.\n\nAt the bifurcation point $r=0$, the two fixed points $x_1^*$ and $x_2^*$ collide and exchange their stability. This is the definition of a transcritical bifurcation.\n\nNow let's evaluate the given options:\n- A. Describes a supercritical pitchfork bifurcation, which is incorrect.\n- B. Describes a saddle-node bifurcation, which is incorrect as we have two fixed points for $r0$.\n- C. This states that for $r0$, $x=0$ is unstable and $x=r$ is stable. This is the opposite of what we found.\n- D. This states that for $r0$, $x=0$ is stable and $x=r$ is unstable. For $r0$, it states that $x=0$ becomes unstable and $x=r$ becomes stable. This exactly matches our analysis.\n- E. This claims fixed stability roles for all $r$, which is incorrect as the stability changes at $r=0$.\n\nTherefore, the correct statement is D.",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "While graphical analysis of bifurcation diagrams is intuitive, a rigorous classification of bifurcations relies on formal mathematical conditions. This exercise challenges you to apply these conditions by examining why the system $\\dot{x} = \\mu x - x^3$ undergoes a pitchfork bifurcation, not a transcritical one. By evaluating the partial derivatives of the system's function at the bifurcation point, you will pinpoint the precise mathematical property that differentiates these two fundamental types of bifurcations. ",
            "id": "1724860",
            "problem": "Consider a one-dimensional dynamical system defined by the differential equation $\\dot{x} = f(x, \\mu)$, where $x(t)$ is the state variable and $\\mu$ is a real-valued parameter. A fixed point $x^*$ of the system satisfies $f(x^*, \\mu) = 0$. A bifurcation occurs at a parameter value $\\mu_c$ if the qualitative behavior of the system, such as the number or stability of its fixed points, changes as $\\mu$ passes through $\\mu_c$.\n\nThe normal form for a transcritical bifurcation occurring at the origin $(x^*, \\mu_c) = (0, 0)$ is given by $\\dot{x} = \\mu x - x^2$. For a general system $\\dot{x} = f(x, \\mu)$ to undergo a transcritical bifurcation at a point $(x^*, \\mu_c)$, certain conditions on the partial derivatives of $f(x, \\mu)$ evaluated at this point must be met.\n\nNow, consider the specific system given by the equation:\n$$ \\dot{x} = \\mu x - x^3 $$\nIt can be verified that $x^* = 0$ is a fixed point for all values of $\\mu$, and that a bifurcation involving this fixed point occurs at the critical parameter value $\\mu_c = 0$. However, this bifurcation is not a transcritical bifurcation.\n\nWhich of the following statements provides the precise mathematical reason why the bifurcation at $(x^*, \\mu_c)=(0,0)$ for the system $\\dot{x} = \\mu x - x^3$ fails to be a transcritical bifurcation? Let $f(x, \\mu) = \\mu x - x^3$.\n\nA. The fixed point $x^*=0$ does not exist for all values of $\\mu$.\n\nB. The stability of the fixed point $x^*=0$ does not change as $\\mu$ passes through $\\mu_c=0$.\n\nC. The partial derivative $\\frac{\\partial f}{\\partial \\mu}$ evaluated at $(0,0)$ is non-zero.\n\nD. The second partial derivative $\\frac{\\partial^2 f}{\\partial x^2}$ evaluated at $(0,0)$ is zero.\n\nE. The partial derivative $\\frac{\\partial^2 f}{\\partial x \\partial \\mu}$ evaluated at $(0,0)$ is zero.",
            "solution": "We seek the precise condition that fails for a transcritical bifurcation at $(x^{*},\\mu_{c})=(0,0)$ for the system $\\dot{x}=f(x,\\mu)=\\mu x - x^{3}$.\n\nFor a transcritical bifurcation at $(0,0)$ in the one-dimensional system $\\dot{x}=f(x,\\mu)$, the standard nondegeneracy and transversality conditions require:\n1) $f(0,0)=0$,\n2) $f_{x}(0,0)=0$,\n3) $f_{xx}(0,0)\\neq 0$,\n4) $f_{x\\mu}(0,0)\\neq 0$,\nand (in many standard formulations) also $f_{\\mu}(0,0)=0$ so that the leading parameter dependence at the fixed point is captured by the mixed derivative.\n\nCompute the necessary derivatives for $f(x,\\mu)=\\mu x - x^{3}$:\n- Value at the candidate bifurcation point:\n$$\nf(0,0)=\\mu\\cdot 0 - 0^{3}=0.\n$$\n- First derivative with respect to $x$:\n$$\nf_{x}(x,\\mu)=\\frac{\\partial}{\\partial x}(\\mu x - x^{3})=\\mu - 3x^{2},\\quad f_{x}(0,0)=0.\n$$\n- Second derivative with respect to $x$:\n$$\nf_{xx}(x,\\mu)=\\frac{\\partial^{2}}{\\partial x^{2}}(\\mu x - x^{3})=-6x,\\quad f_{xx}(0,0)=0.\n$$\n- Mixed derivative:\n$$\nf_{x\\mu}(x,\\mu)=\\frac{\\partial}{\\partial\\mu}(\\mu - 3x^{2})=1,\\quad f_{x\\mu}(0,0)=1\\neq 0.\n$$\n- First derivative with respect to $\\mu$:\n$$\nf_{\\mu}(x,\\mu)=\\frac{\\partial}{\\partial\\mu}(\\mu x - x^{3})=x,\\quad f_{\\mu}(0,0)=0.\n$$\n\nThus, at $(0,0)$ the conditions $f(0,0)=0$, $f_{x}(0,0)=0$, $f_{x\\mu}(0,0)\\neq 0$, and $f_{\\mu}(0,0)=0$ are satisfied. However, the crucial nondegeneracy condition for a transcritical bifurcation, $f_{xx}(0,0)\\neq 0$, fails because $f_{xx}(0,0)=0$. Therefore, the precise mathematical reason the bifurcation is not transcritical is that the second partial derivative with respect to $x$ vanishes at $(0,0)$.\n\nAmong the given options, this corresponds exactly to statement D.",
            "answer": "$$\\boxed{D}$$"
        },
        {
            "introduction": "In many real-world modeling scenarios, particularly in synthetic biology, we interact with complex systems through simulations without having access to their underlying analytical equations. This advanced practice bridges the gap between theory and computation by asking you to verify the nondegeneracy conditions for a transcritical bifurcation using only simulated data. You will implement a numerical method to estimate the key partial derivatives, a skill essential for analyzing \"black-box\" models common in modern research. ",
            "id": "3939176",
            "problem": "Consider a one-dimensional ordinary differential equation modeling homeostatic cell density in a well-mixed compartment, where the state $x$ denotes a dimensionless cell density and the parameter $\\mu$ denotes the net proliferation drive, with a quadratic saturation arising from contact inhibition. The dynamics are given by the initial value problem $\\frac{dx}{dt} = f(x,\\mu;k)$, where $f$ is smooth in a neighborhood of $(x,\\mu)=(0,0)$ and is specified in simulation form by an explicit Euler step over a small time increment $\\Delta t$: starting from $x(0)=x_0$, produce $x(\\Delta t)=x_0 + \\Delta t\\, f(x_0,\\mu;k)$. Assume $k$ is a nonnegative real parameter capturing the strength of self-limitation.\n\nIn biomedical systems modeling, a transcritical bifurcation occurs when two equilibrium branches intersect and exchange stability. The nondegeneracy conditions for a generic transcritical bifurcation at $(x,\\mu)=(0,0)$ require that $f_{x\\mu}(0,0)\\neq 0$ and $f_{xx}(0,0)\\neq 0$, where subscripts denote partial derivatives. Your task is to develop a numerical method that, given only simulated short-time data from the explicit Euler step described above, estimates $f_{x\\mu}(0,0)$ and $f_{xx}(0,0)$ and then uses these estimates to test the transcritical nondegeneracy conditions.\n\nStarting from core definitions in calculus and dynamical systems, implement an algorithm that:\n- Estimates the right-hand side $f(x,\\mu;k)$ at specified $(x,\\mu)$ by simulating one explicit Euler step of size $\\Delta t$ from $x(0)=x$ and computing the finite difference $(x(\\Delta t)-x)/\\Delta t$.\n- Uses finite differencing around $(x,\\mu)=(0,0)$ with small symmetric perturbations $h_x$ and $h_\\mu$ to numerically approximate $f_{x\\mu}(0,0)$ and $f_{xx}(0,0)$ from the estimated values of $f(x,\\mu;k)$ at the perturbed points.\n- Declares the transcritical nondegeneracy test as satisfied if both $|f_{x\\mu}(0,0)|\\epsilon$ and $|f_{xx}(0,0)|\\epsilon$, for a specified tolerance $\\epsilon0$.\n\nUse the following test suite of parameter sets $(k,h_x,h_\\mu,\\Delta t,\\epsilon)$:\n- Case $1$: $k=1.0$, $h_x=10^{-4}$, $h_\\mu=10^{-4}$, $\\Delta t=10^{-6}$, $\\epsilon=10^{-6}$.\n- Case $2$: $k=0.0$, $h_x=10^{-4}$, $h_\\mu=10^{-4}$, $\\Delta t=10^{-6}$, $\\epsilon=10^{-6}$.\n- Case $3$: $k=2.5$, $h_x=5\\times 10^{-5}$, $h_\\mu=2\\times 10^{-4}$, $\\Delta t=5\\times 10^{-7}$, $\\epsilon=10^{-6}$.\n- Case $4$: $k=10^{-12}$, $h_x=10^{-4}$, $h_\\mu=10^{-4}$, $\\Delta t=10^{-6}$, $\\epsilon=10^{-6}$.\n\nAssume the biomedical simulatorâ€™s underlying $f$ is consistent with contact-limited proliferation, specifically $f(x,\\mu;k)=\\mu x - k x^2$ in a neighborhood of the origin, but you must not use this closed-form to compute derivatives; you must estimate $f$ from the simulated data as described.\n\nYour program must produce, for each test case, a list of three values: the numerical estimates of $f_{x\\mu}(0,0)$ and $f_{xx}(0,0)$ as floating-point numbers, followed by a boolean indicating whether the transcritical nondegeneracy test is satisfied under the tolerance $\\epsilon$. Aggregate the results for all test cases into a single line of output containing a comma-separated list enclosed in square brackets, for example, $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4]]$, where each $a_i$ and $b_i$ are floats and each $c_i$ is a boolean. No physical units are required for the output, and angles are not involved. The final output format must be exactly one line as specified.",
            "solution": "The problem requires the numerical verification of the nondegeneracy conditions for a transcritical bifurcation at the origin $(x, \\mu) = (0, 0)$ for a dynamical system described by the ordinary differential equation $\\frac{dx}{dt} = f(x,\\mu;k)$. The nondegeneracy conditions are given by $f_{x\\mu}(0,0) \\neq 0$ and $f_{xx}(0,0) \\neq 0$, where subscripts denote partial derivatives. The function $f$ itself is not given in a closed form for analysis; instead, it must be estimated from a simulated explicit Euler step.\n\nThe algorithmic approach comprises three main stages: first, defining a numerical estimator for the function $f(x, \\mu; k)$; second, using this estimator within finite difference formulas to approximate the partial derivatives $f_{xx}(0,0)$ and $f_{x\\mu}(0,0)$; and third, applying a tolerance $\\epsilon$ to the magnitudes of these estimated derivatives to test the nondegeneracy conditions.\n\nThe first stage is the estimation of the function $f(x,\\mu;k)$. The problem provides access to the system's dynamics through a simulator that performs a single explicit Euler step. For an initial condition $x(0) = x_0$, the state at time $\\Delta t$ is given by:\n$$ x(\\Delta t) = x_0 + \\Delta t \\cdot f(x_0, \\mu; k) $$\nBy algebraically rearranging this equation, we can construct an estimator for the function $f$ at the point $(x_0, \\mu)$:\n$$ \\hat{f}(x_0, \\mu; k) = \\frac{x(\\Delta t) - x_0}{\\Delta t} $$\nThe problem specifies that the underlying dynamics, used by the simulator, follow the model $f(x,\\mu;k) = \\mu x - k x^2$. While our algorithm must not use this analytical form to compute derivatives, we must use it to define the simulator. Substituting this into the Euler step gives:\n$$ x(\\Delta t) = x_0 + \\Delta t (\\mu x_0 - k x_0^2) $$\nThis function represents the simulation oracle from which we estimate $f$.\n\nThe second stage is the numerical approximation of partial derivatives. We employ central finite difference formulas to estimate the second-order and mixed partial derivatives at the bifurcation point $(x, \\mu) = (0, 0)$, using small symmetric perturbations $h_x$ and $h_\\mu$. The approximation of $f_{xx}(0,0)$ uses the three-point central difference formula:\n$$ f_{xx}(0,0) \\approx \\frac{\\hat{f}(h_x, 0; k) - 2\\hat{f}(0, 0; k) + \\hat{f}(-h_x, 0; k)}{h_x^2} $$\nThe required function values are obtained through our estimator $\\hat{f}$: $\\hat{f}(h_x, 0; k)$ is computed by simulating from $x(0) = h_x$ with $\\mu=0$; $\\hat{f}(0, 0; k)$ is computed from $x(0) = 0$ with $\\mu=0$; and $\\hat{f}(-h_x, 0; k)$ is computed from $x(0) = -h_x$ with $\\mu=0$. The approximation of $f_{x\\mu}(0,0)$ uses the four-point central difference formula:\n$$ f_{x\\mu}(0,0) \\approx \\frac{\\hat{f}(h_x, h_\\mu; k) - \\hat{f}(h_x, -h_\\mu; k) - \\hat{f}(-h_x, h_\\mu; k) + \\hat{f}(-h_x, -h_\\mu; k)}{4 h_x h_\\mu} $$\nThis requires four evaluations of our function estimator $\\hat{f}$ at the corners of a small rectangle centered at the origin in the $(x, \\mu)$ plane. For instance, $\\hat{f}(h_x, h_\\mu; k)$ is computed by simulating from the initial condition $x(0) = h_x$ with the parameter value $\\mu = h_\\mu$.\n\nThe third and final stage is the nondegeneracy test. With the numerical estimates for the derivatives, denoted $\\hat{f}_{xx}(0,0)$ and $\\hat{f}_{x\\mu}(0,0)$, the nondegeneracy conditions are tested against a given positive tolerance $\\epsilon$. The test is declared satisfied if and only if both of the following inequalities hold:\n$$ |\\hat{f}_{xx}(0,0)| > \\epsilon \\quad \\text{and} \\quad |\\hat{f}_{x\\mu}(0,0)| > \\epsilon $$\nThis procedure is then applied to each of the provided test cases. For the given underlying function $f(x, \\mu; k) = \\mu x - k x^2$, the true derivatives are $f_{xx}(0,0) = -2k$ and $f_{x\\mu}(0,0) = 1$. Our numerical estimates should be exceptionally close to these analytical values because the finite difference formulas are exact for polynomials of low degree. The test for nondegeneracy effectively becomes a check on whether $|-2k| > \\epsilon$ and $|1| > \\epsilon$. Given $\\epsilon$ is small (e.g., $10^{-6}$), the second condition is practically always met, and the test hinges on whether the parameter $k$ is sufficiently large in magnitude.",
            "answer": "```python\nimport numpy as np\n\ndef _hidden_simulator_step(x0, mu, k, dt):\n    \"\"\"\n    This function represents the \"black box\" biomedical simulator.\n    It computes x(t+dt) from x(t) using one explicit Euler step.\n    The problem specifies the underlying ODE is dx/dt = mu*x - k*x**2.\n    The algorithm must treat this as an oracle and not use its internal formula\n    to compute analytical derivatives.\n    \"\"\"\n    f_val = mu * x0 - k * x0**2\n    return x0 + dt * f_val\n\ndef estimate_f(x0, mu, k, dt):\n    \"\"\"\n    Estimates f(x0, mu; k) by simulating one explicit Euler step of size dt\n    from x(0)=x0 and computing the finite difference (x(dt)-x0)/dt,\n    as required by the problem statement.\n    \"\"\"\n    x_at_dt = _hidden_simulator_step(x0, mu, k, dt)\n    f_estimate = (x_at_dt - x0) / dt\n    return f_estimate\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    # Test suite of parameter sets (k, h_x, h_mu, dt, epsilon)\n    test_cases = [\n        # Case 1: k=1.0, h_x=10^-4, h_mu=10^-4, dt=10^-6, epsilon=10^-6\n        (1.0, 1e-4, 1e-4, 1e-6, 1e-6),\n        # Case 2: k=0.0, h_x=10^-4, h_mu=10^-4, dt=10^-6, epsilon=10^-6\n        (0.0, 1e-4, 1e-4, 1e-6, 1e-6),\n        # Case 3: k=2.5, h_x=5x10^-5, h_mu=2x10^-4, dt=5x10^-7, epsilon=10^-6\n        (2.5, 5e-5, 2e-4, 5e-7, 1e-6),\n        # Case 4: k=10^-12, h_x=10^-4, h_mu=10^-4, dt=10^-6, epsilon=10^-6\n        (1e-12, 1e-4, 1e-4, 1e-6, 1e-6),\n    ]\n\n    results = []\n    for case in test_cases:\n        k, h_x, h_mu, dt, epsilon = case\n\n        # Estimate f_xx(0,0) using a central difference formula.\n        # This requires three calls to the f-estimator.\n        f_plus_x = estimate_f(h_x, 0.0, k, dt)\n        f_zero = estimate_f(0.0, 0.0, k, dt)\n        f_minus_x = estimate_f(-h_x, 0.0, k, dt)\n        est_f_xx = (f_plus_x - 2.0 * f_zero + f_minus_x) / (h_x**2)\n\n        # Estimate f_xmu(0,0) using a central difference formula.\n        # This requires four calls to the f-estimator.\n        f_pp = estimate_f(h_x, h_mu, k, dt)   # Point (+h_x, +h_mu)\n        f_pm = estimate_f(h_x, -h_mu, k, dt)  # Point (+h_x, -h_mu)\n        f_mp = estimate_f(-h_x, h_mu, k, dt)  # Point (-h_x, +h_mu)\n        f_mm = estimate_f(-h_x, -h_mu, k, dt) # Point (-h_x, -h_mu)\n        est_f_xmu = (f_pp - f_pm - f_mp + f_mm) / (4.0 * h_x * h_mu)\n\n        # Perform the transcritical nondegeneracy test.\n        is_nondegenerate = abs(est_f_xmu) > epsilon and abs(est_f_xx) > epsilon\n\n        results.append([est_f_xmu, est_f_xx, is_nondegenerate])\n\n    # Format the final output string exactly as specified: [[...],[...],...]\n    # Using str() on a list of lists creates the required formatting.\n    # Capitalized True/False from Python's str() is the standard representation.\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}