{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of developing and verifying any numerical solver is to test it against problems with known analytical solutions. This practice focuses on one of the most fundamental kinetic instabilities in plasma physics: the two-stream instability. By linearizing the Vlasov-Poisson system and deriving the instability's growth rate from first principles , you will obtain a precise benchmark that any accurate continuum Vlasov solver must be able to reproduce in the appropriate limit.",
            "id": "4184922",
            "problem": "Consider a one-dimensional, one-velocity electrostatic Vlasov–Poisson system, representative of a continuum (Eulerian) Vlasov solver used in fusion plasma turbulence simulation benchmarks. The species are electrons and a neutralizing immobile ion background. The unperturbed electron distribution is a sum of two equal-density shifted Maxwellians at the same temperature and opposite drift speeds:\n$$\nf_{0}(v) \\;=\\; \\frac{n_{0}}{2}\\,\\frac{1}{\\sqrt{\\pi}\\,v_{te}}\\,\\exp\\!\\Big(-\\frac{(v-U_{d})^{2}}{v_{te}^{2}}\\Big) \\;+\\; \\frac{n_{0}}{2}\\,\\frac{1}{\\sqrt{\\pi}\\,v_{te}}\\,\\exp\\!\\Big(-\\frac{(v+U_{d})^{2}}{v_{te}^{2}}\\Big),\n$$\nwhere $n_{0}$ is the total electron density, $U_{d}0$ is the drift speed magnitude, and $v_{te}=\\sqrt{2 T_{e}/m_{e}}$ is the electron thermal speed with $T_{e}$ the electron temperature and $m_{e}$ the electron mass. The full system is governed by the electrostatic Vlasov equation,\n$$\n\\frac{\\partial f}{\\partial t} \\;+\\; v\\,\\frac{\\partial f}{\\partial x} \\;-\\; \\frac{e}{m_{e}}\\,E\\,\\frac{\\partial f}{\\partial v} \\;=\\; 0,\n$$\nand Poisson’s equation,\n$$\n\\frac{\\partial E}{\\partial x} \\;=\\; \\frac{e}{\\varepsilon_{0}}\\Big(n_{i}-\\int_{-\\infty}^{\\infty} f\\,dv\\Big),\n$$\nwith a uniform immobile ion density $n_{i}=n_{0}$. Linearize about the homogeneous equilibrium $f_{0}(v)$ with perturbations proportional to $\\exp(i k x - i \\omega t)$, and use first principles to obtain the linear dispersion relation. Then, take the cold limit $v_{te}\\to 0$ at fixed $U_{d}$ to obtain a closed-form analytic expression for the linear growth rate $\\gamma(k)=\\operatorname{Im}(\\omega)$ in terms of $k$, $U_{d}$, and the electron plasma frequency $\\omega_{pe}=\\sqrt{n_{0} e^{2}/(\\varepsilon_{0} m_{e})}$. Define the dimensionless parameter $\\kappa = k U_{d}/\\omega_{pe}$ and assume $0\\kappa1$ (an unstable mode). Express your final answer as a single closed-form expression for the dimensionless growth rate $\\gamma/\\omega_{pe}$ in terms of $\\kappa$. Do not round; provide the exact analytic form without units.",
            "solution": "The problem requires the derivation of the linear growth rate for a one-dimensional electrostatic two-stream instability in the cold plasma limit. The derivation proceeds by linearizing the Vlasov-Poisson system.\n\nFirst, we linearize the system of equations. The distribution function $f$ and electric field $E$ are perturbed about a homogeneous equilibrium ($f_0(v)$, $E_0=0$):\n$$f(x, v, t) = f_0(v) + f_1(x, v, t)$$\n$$E(x, t) = E_1(x, t)$$\nwhere $f_1$ and $E_1$ are small first-order perturbations.\n\nThe Vlasov equation is\n$$\n\\frac{\\partial f}{\\partial t} \\;+\\; v\\,\\frac{\\partial f}{\\partial x} \\;-\\; \\frac{e}{m_{e}}\\,E\\,\\frac{\\partial f}{\\partial v} \\;=\\; 0\n$$\nSubstituting the perturbed forms and retaining only first-order terms gives the linearized Vlasov equation:\n$$\n\\frac{\\partial f_1}{\\partial t} \\;+\\; v\\,\\frac{\\partial f_1}{\\partial x} \\;-\\; \\frac{e}{m_{e}}\\,E_1\\,\\frac{\\partial f_0}{\\partial v} \\;=\\; 0\n$$\nNote that the term $\\frac{e}{m_e}E_1 \\frac{\\partial f_1}{\\partial v}$ is second-order and is neglected.\n\nPoisson's equation is\n$$\n\\frac{\\partial E}{\\partial x} \\;=\\; \\frac{e}{\\varepsilon_{0}}\\Big(n_{i}-\\int_{-\\infty}^{\\infty} f\\,dv\\Big)\n$$\nWith the immobile ion background density $n_i=n_0$ and the equilibrium electron density $\\int f_0 dv = n_0$, the linearized Poisson's equation becomes:\n$$\n\\frac{\\partial E_1}{\\partial x} \\;=\\; \\frac{e}{\\varepsilon_{0}}\\Big(n_{0}-\\int_{-\\infty}^{\\infty} (f_0+f_1)\\,dv\\Big) \\;=\\; -\\frac{e}{\\varepsilon_{0}}\\int_{-\\infty}^{\\infty} f_1\\,dv\n$$\n\nWe assume plane wave solutions for the perturbations, proportional to $\\exp(i k x - i \\omega t)$. This transforms the partial derivatives as $\\frac{\\partial}{\\partial t} \\to -i\\omega$ and $\\frac{\\partial}{\\partial x} \\to ik$. Let the Fourier amplitudes of the perturbations be $\\tilde{f}_1(v)$ and $\\tilde{E}_1$. The linearized equations in Fourier space are:\n$$\n(-i\\omega + ikv)\\tilde{f}_1 - \\frac{e}{m_e}\\tilde{E}_1\\frac{\\partial f_0}{\\partial v} = 0\n$$\n$$\nik\\tilde{E}_1 = -\\frac{e}{\\varepsilon_0}\\int_{-\\infty}^{\\infty} \\tilde{f}_1\\,dv\n$$\n\nFrom the Vlasov equation, we solve for $\\tilde{f}_1$:\n$$\n\\tilde{f}_1 = \\frac{e}{m_e} \\frac{\\tilde{E}_1}{i(kv-\\omega)} \\frac{\\partial f_0}{\\partial v} = \\frac{ie}{m_e} \\frac{\\tilde{E}_1}{\\omega-kv} \\frac{\\partial f_0}{\\partial v}\n$$\nSubstituting this expression for $\\tilde{f}_1$ into the Fourier-transformed Poisson's equation gives:\n$$\nik\\tilde{E}_1 = -\\frac{e}{\\varepsilon_0}\\int_{-\\infty}^{\\infty} \\left( \\frac{ie}{m_e} \\frac{\\tilde{E}_1}{\\omega-kv} \\frac{\\partial f_0}{\\partial v} \\right) dv\n$$\nFor a non-trivial solution ($\\tilde{E}_1 \\neq 0$), we can divide by $i\\tilde{E}_1$:\n$$\nk = -\\frac{e^2}{\\varepsilon_0 m_e} \\int_{-\\infty}^{\\infty} \\frac{1}{\\omega-kv}\\frac{\\partial f_0}{\\partial v} dv\n$$\nThis equation can be rewritten using the electron plasma frequency $\\omega_{pe} = \\sqrt{n_0 e^2/(\\varepsilon_0 m_e)}$ to obtain the general linear dispersion relation for longitudinal electrostatic waves:\n$$\n1 + \\frac{\\omega_{pe}^2}{n_0 k} \\int_{-\\infty}^{\\infty} \\frac{\\partial f_0/\\partial v}{\\omega/k - v} dv = 0\n$$\nThis is often expressed as $\\epsilon(\\omega, k) = 0$, where $\\epsilon$ is the dielectric function. An alternative, often more convenient form is obtained by integrating by parts:\n$$\n1 = \\frac{\\omega_{pe}^2}{n_0 k^2} \\int_{-\\infty}^{\\infty} \\frac{f_0(v)}{(v - \\omega/k)^2} dv\n$$\nNow, we take the cold limit, $v_{te} \\to 0$. In this limit, each of the shifted Maxwellian distributions in $f_0(v)$ becomes a Dirac delta function. The normalized Maxwellian profile converges to a delta function:\n$$ \\frac{1}{\\sqrt{\\pi}v_{te}} \\exp\\left(-\\frac{(v-U)^2}{v_{te}^2}\\right) \\to \\delta(v-U) \\quad \\text{as } v_{te} \\to 0 $$\nThus, the equilibrium distribution function $f_0(v)$ becomes:\n$$\nf_0(v) \\to \\frac{n_0}{2}\\Big( \\delta(v-U_d) + \\delta(v+U_d) \\Big)\n$$\nSubstituting this cold distribution into the dispersion relation:\n$$\n1 = \\frac{\\omega_{pe}^2}{n_0 k^2} \\int_{-\\infty}^{\\infty} \\frac{\\frac{n_0}{2}\\left(\\delta(v-U_d) + \\delta(v+U_d)\\right)}{(v - \\omega/k)^2} dv\n$$\nUsing the sifting property of the delta function, $\\int g(v)\\delta(v-a)dv = g(a)$, we evaluate the integral:\n$$\n1 = \\frac{\\omega_{pe}^2}{2k^2} \\left( \\frac{1}{(U_d - \\omega/k)^2} + \\frac{1}{(-U_d - \\omega/k)^2} \\right)\n$$\nMultiplying by $k^2$ and simplifying:\n$$\n1 = \\frac{\\omega_{pe}^2}{2} \\left( \\frac{1}{(kU_d - \\omega)^2} + \\frac{1}{(kU_d + \\omega)^2} \\right)\n$$\nThis is the dispersion relation for the cold two-stream instability. To find the growth rate $\\gamma = \\operatorname{Im}(\\omega)$, we solve for $\\omega$. Combining the terms on the right-hand side:\n$$\n1 = \\frac{\\omega_{pe}^2}{2} \\frac{(kU_d + \\omega)^2 + (kU_d - \\omega)^2}{((kU_d)^2 - \\omega^2)^2} = \\frac{\\omega_{pe}^2}{2} \\frac{2((kU_d)^2+\\omega^2)}{((kU_d)^2-\\omega^2)^2}\n$$\n$$\n((kU_d)^2 - \\omega^2)^2 = \\omega_{pe}^2((kU_d)^2 + \\omega^2)\n$$\nThis is a quadratic equation for $\\omega^2$. Let $X = \\omega^2$:\n$$\n((kU_d)^2 - X)^2 = \\omega_{pe}^2((kU_d)^2 + X)\n$$\n$$\n(kU_d)^4 - 2(kU_d)^2 X + X^2 = \\omega_{pe}^2(kU_d)^2 + \\omega_{pe}^2 X\n$$\n$$\nX^2 - (2(kU_d)^2 + \\omega_{pe}^2)X + ((kU_d)^4 - \\omega_{pe}^2(kU_d)^2) = 0\n$$\nThe solutions for $X = \\omega^2$ are given by the quadratic formula:\n$$\n\\omega^2 = \\frac{1}{2} \\left[ (2(kU_d)^2 + \\omega_{pe}^2) \\pm \\sqrt{(2(kU_d)^2 + \\omega_{pe}^2)^2 - 4((kU_d)^4 - \\omega_{pe}^2(kU_d)^2)} \\right]\n$$\nThe discriminant simplifies to:\n$$\n\\Delta = 4(kU_d)^4 + 4(kU_d)^2\\omega_{pe}^2 + \\omega_{pe}^4 - 4(kU_d)^4 + 4(kU_d)^2\\omega_{pe}^2 = 8(kU_d)^2\\omega_{pe}^2 + \\omega_{pe}^4 = \\omega_{pe}^2(8(kU_d)^2 + \\omega_{pe}^2)\n$$\nSo the solutions for $\\omega^2$ are:\n$$\n\\omega^2 = \\frac{1}{2} \\left[ 2(kU_d)^2 + \\omega_{pe}^2 \\pm \\omega_{pe}\\sqrt{8(kU_d)^2 + \\omega_{pe}^2} \\right]\n$$\nAn instability exists if $\\omega^2  0$, which implies that $\\omega$ has an imaginary part $\\gamma \\neq 0$. For $\\omega^2$ to be negative, the term with the minus sign must be chosen, and its value must be negative. This occurs when:\n$$\n2(kU_d)^2 + \\omega_{pe}^2  \\omega_{pe}\\sqrt{8(kU_d)^2 + \\omega_{pe}^2}\n$$\nSquaring both sides (which are positive) yields $4(kU_d)^4 + 4(kU_d)^2\\omega_{pe}^2 + \\omega_{pe}^4  8(kU_d)^2\\omega_{pe}^2 + \\omega_{pe}^4$, which simplifies to $(kU_d)^2  \\omega_{pe}^2$, or $kU_d  \\omega_{pe}$. The problem defines $\\kappa = kU_d/\\omega_{pe}$ and assumes $0  \\kappa  1$, which is precisely the condition for instability.\nFor an unstable mode, $\\omega$ is purely imaginary, $\\omega = i\\gamma$, so $\\omega^2 = -\\gamma^2$. The growth rate $\\gamma$ is given by $\\gamma^2 = -\\omega^2_-$:\n$$\n\\gamma^2 = -\\frac{1}{2} \\left[ 2(kU_d)^2 + \\omega_{pe}^2 - \\omega_{pe}\\sqrt{8(kU_d)^2 + \\omega_{pe}^2} \\right]\n$$\n$$\n\\gamma^2 = \\frac{1}{2} \\left[ \\omega_{pe}\\sqrt{8(kU_d)^2 + \\omega_{pe}^2} - (2(kU_d)^2 + \\omega_{pe}^2) \\right]\n$$\nTo express this in terms of the dimensionless parameter $\\kappa$, we divide by $\\omega_{pe}^2$:\n$$\n\\left(\\frac{\\gamma}{\\omega_{pe}}\\right)^2 = \\frac{1}{2} \\left[ \\frac{1}{\\omega_{pe}}\\sqrt{8(kU_d)^2 + \\omega_{pe}^2} - \\frac{2(kU_d)^2}{\\omega_{pe}^2} - 1 \\right]\n$$\n$$\n\\left(\\frac{\\gamma}{\\omega_{pe}}\\right)^2 = \\frac{1}{2} \\left[ \\sqrt{8\\left(\\frac{kU_d}{\\omega_{pe}}\\right)^2 + 1} - 2\\left(\\frac{kU_d}{\\omega_{pe}}\\right)^2 - 1 \\right]\n$$\nSubstituting $\\kappa = kU_d/\\omega_{pe}$:\n$$\n\\left(\\frac{\\gamma}{\\omega_{pe}}\\right)^2 = \\frac{1}{2} \\left( \\sqrt{8\\kappa^2 + 1} - 2\\kappa^2 - 1 \\right)\n$$\nThe dimensionless growth rate is the positive square root of this expression:\n$$\n\\frac{\\gamma}{\\omega_{pe}} = \\sqrt{\\frac{1}{2} \\left( \\sqrt{8\\kappa^2 + 1} - 2\\kappa^2 - 1 \\right)}\n$$\nThis is the final closed-form expression for the dimensionless growth rate.",
            "answer": "$$\\boxed{\\sqrt{\\frac{1}{2}\\left(\\sqrt{8\\kappa^{2} + 1} - 2\\kappa^{2} - 1\\right)}}$$"
        },
        {
            "introduction": "A particle distribution function, $f$, is inherently non-negative, representing a probability density in phase space. However, high-order numerical schemes used in continuum solvers to achieve accuracy can sometimes violate this physical constraint, producing unphysical negative values. This exercise  guides you through the process of constructing a test case with sharp gradients designed to provoke such errors and implementing a positivity-preserving limiter, a critical technique for ensuring the stability and physical realism of your simulation.",
            "id": "4184958",
            "problem": "Consider the one-dimensional, velocity-space form of the Vlasov equation for a species with a constant acceleration due to a uniform electric field, which in a spatially homogeneous setting reduces to the linear advection equation in velocity space, namely $\\partial_t f + a \\, \\partial_v f = 0$, where $ f(v,t) $ is the distribution function, $ v $ is the velocity variable, and $ a $ is the constant advection speed in $ v $-space. In the continuum (Eulerian) setting, semi-Lagrangian updates along characteristics are widely used to avoid restrictive time-step constraints, but high-order polynomial interpolation during characteristic tracing may introduce negative undershoots when $ f(v,t) $ has sharp gradients or discontinuities. Such violations of non-negativity are unphysical in distribution functions and must be controlled by limiters that preserve positivity while attempting to retain accuracy.\n\nYour task is to construct a scientifically sound test that challenges positivity under strong $ v $-space advection and to algorithmically evaluate a positivity-preserving limiter. The test is defined on a periodic velocity domain $ v \\in [v_{\\min}, v_{\\max}) $ with $ v_{\\min} = -6 $, $ v_{\\max} = 6 $, resolved by a uniform grid of $ N = 256 $ points with spacing $ \\Delta v = (v_{\\max} - v_{\\min})/N $. The initial condition is a composite, strictly non-negative distribution designed to have sharp features:\n- A top-hat component of amplitude $ A_1 = 1 $ centered at $ v_c = 0 $ with half-width $ w = 1 $, i.e., $ f_{\\text{hat}}(v) = A_1 $ for $ |v - v_c| \\le w $ and $ f_{\\text{hat}}(v) = 0 $ otherwise.\n- A narrow Gaussian bump $ f_{\\text{bump}}(v) = A_2 \\exp\\!\\big(-\\tfrac{(v - v_b)^2}{2 \\sigma_b^2}\\big) $ with $ A_2 = 0.5 $, $ v_b = 2.7 $, and $ \\sigma_b = 0.06 $.\nThe full initial condition is $ f_0(v) = f_{\\text{hat}}(v) + f_{\\text{bump}}(v) $, which is continuous except for the top-hat edges at $ v = \\pm 1 $.\n\nUse a semi-Lagrangian characteristic update for a single time step $ \\Delta t $: the exact solution after one step is the shifted function $ f(v, \\Delta t) = f_0(v - a \\Delta t) $. Implement two numerical update variants mapping $ f_0 $ to $ f^{n+1} $ at the grid nodes by interpolating $ f^n $ to the characteristic feet:\n- A high-order cubic (four-point) Catmull–Rom interpolation for $ f_{\\text{HO}}(v_i) $ that may overshoot and produce $ f_{\\text{HO}}(v_i)  0 $ at sharp features.\n- A low-order linear interpolation for $ f_{\\text{LO}}(v_i) $ that is monotone between adjacent grid values and preserves non-negativity provided both endpoints are non-negative.\n\nDesign and evaluate a positivity-preserving limiter constructed as a convex combination between the high-order and low-order updates to ensure $ f(v_i) \\ge \\varepsilon $ with $ \\varepsilon = 10^{-14} $ while deviating minimally from $ f_{\\text{HO}} $. That is, for each grid point, select a convex weight in $ [0,1] $ that blends $ f_{\\text{HO}} $ and $ f_{\\text{LO}} $ only when necessary to enforce non-negativity. The evaluation must quantify:\n- The minimum value $ \\min_i f^{n+1}_i $,\n- The absolute mass error $\\big|\\sum_i f^{n+1}_i \\Delta v - \\sum_i f^n_i \\Delta v \\big|$,\n- The relative $ L^1 $ error $\\frac{\\sum_i | f^{n+1}_i - f_{\\text{exact}}(v_i) | \\Delta v}{\\sum_i | f_{\\text{exact}}(v_i) | \\Delta v}$,\nwith $ f_{\\text{exact}}(v) = f_0(v - a \\Delta t) $. All quantities are dimensionless.\n\nImplement the above in a single program that carries out one time step for each test case in the following test suite:\n- Case $ 1 $ (happy path near the stability boundary): $ a = 5 $, choose $ \\Delta t $ such that the characteristic shift equals $0.9 \\, \\Delta v$, i.e., $a \\Delta t = 0.9 \\, \\Delta v$.\n- Case $ 2 $ (strong advection across multiple cells): $ a = 5 $, choose $ \\Delta t $ such that the shift equals $3.7 \\, \\Delta v$, i.e., $a \\Delta t = 3.7 \\, \\Delta v$.\n- Case $ 3 $ (very strong advection with substantial wrap-around): $ a = 17 $, choose $ \\Delta t $ such that the shift equals $15.3 \\, \\Delta v$, i.e., $a \\Delta t = 15.3 \\, \\Delta v$.\n\nFor each case, compute the three metrics above for the un-limited high-order update and for the positivity-limited update. Your program should produce a single line of output containing all results aggregated as a comma-separated list enclosed in square brackets, in the order:\n$ [ \\min_{\\text{no}}, \\min_{\\text{lim}}, \\text{massErr}_{\\text{no}}, \\text{massErr}_{\\text{lim}}, L^1_{\\text{no}}, L^1_{\\text{lim}}, \\ldots ] $\nfor the three cases concatenated sequentially. All outputs must be floating-point numbers without units, using the dimensionless normalization defined above.",
            "solution": "The problem statement has been critically examined and is determined to be **valid**. It presents a well-posed, scientifically grounded numerical experiment that is directly relevant to the field of computational plasma physics, specifically concerning continuum Vlasov solvers. All parameters, methods, and evaluation criteria are defined with sufficient precision to permit a unique and verifiable solution.\n\nThe core of the problem is to solve the one-dimensional linear advection equation in velocity space,\n$$\n\\partial_t f + a \\, \\partial_v f = 0\n$$\nwhere $f(v, t)$ is the particle distribution function, $v$ is velocity, $t$ is time, and $a$ is a constant acceleration. This equation describes the evolution of a spatially homogeneous plasma under a uniform electric field. The domain is periodic in velocity, $v \\in [v_{\\min}, v_{\\max})$.\n\nThe exact solution to this equation can be found using the method of characteristics. The characteristic curves are lines in the $(v,t)$-plane defined by $\\frac{dv}{dt} = a$, which integrate to $v(t) = v_0 + at$. Along these characteristics, the distribution function is constant: $f(v(t), t) = f(v_0, 0)$. Thus, the exact solution at time $\\Delta t$ is a simple rigid shift of the initial profile $f_0(v)$:\n$$\nf(v, \\Delta t) = f_0(v - a \\Delta t)\n$$\n\nThe numerical task involves implementing a semi-Lagrangian scheme on a uniform grid $v_i = v_{\\min} + i \\Delta v$ for $i=0, \\dots, N-1$, where $\\Delta v = (v_{\\max} - v_{\\min})/N$. At each time step, the new values $f_i^{n+1}$ on the grid are computed by tracing the characteristics backward in time by one step, $\\Delta t$, from each grid point $v_i$. The new value is the value of the distribution at the previous time, $f^n$, evaluated at the characteristic foot, $v_i - a \\Delta t$.\n$$\nf_i^{n+1} = f^n(v_i - a \\Delta t)\n$$\nSince the foot $v_p = v_i - a \\Delta t$ does not generally coincide with a grid point, its value must be obtained by interpolating the known grid values $\\{f_j^n\\}$. The periodic boundary conditions are handled by wrapping the coordinate of any characteristic foot that falls outside $[v_{\\min}, v_{\\max})$ back into the domain.\n\nWe will implement and compare two interpolation schemes:\n1.  **Low-Order (LO) Linear Interpolation**: For a point $v_p$ between grid nodes $v_j$ and $v_{j+1}$, the value is a weighted average: $f_{\\text{LO}}(v_p) = (1-\\alpha)f_j + \\alpha f_{j+1}$, where $\\alpha = (v_p - v_j)/\\Delta v$. This scheme is inherently positivity-preserving if the original data points $f_j$ and $f_{j+1}$ are non-negative, as $\\alpha \\in [0,1]$.\n2.  **High-Order (HO) Catmull–Rom Interpolation**: This is a four-point cubic interpolation scheme that offers higher accuracy but is not guaranteed to be monotone. It can introduce spurious oscillations (overshoots and undershoots) near sharp gradients, potentially leading to unphysical negative values for $f$. For a point $v_p$ between $v_j$ and $v_{j+1}$ with fractional distance $\\alpha$, the interpolated value is given by the polynomial:\n    $$\n    f_{\\text{HO}}(v_p) = c_3 \\alpha^3 + c_2 \\alpha^2 + c_1 \\alpha + c_0\n    $$\n    where the coefficients are functions of the four grid values $f_{j-1}, f_j, f_{j+1}, f_{j+2}$:\n    $c_0 = f_j$, $c_1 = \\frac{1}{2}(-f_{j-1} + f_{j+1})$, $c_2 = f_{j-1} - \\frac{5}{2}f_j + 2f_{j+1} - \\frac{1}{2}f_{j+2}$, and $c_3 = -\\frac{1}{2}f_{j-1} + \\frac{3}{2}f_j - \\frac{3}{2}f_{j+1} + \\frac{1}{2}f_{j+2}$.\n\nTo rectify the non-negativity violation of the high-order scheme, a positivity-preserving limiter is designed. The limiter constructs a new solution, $f_{\\text{lim}}$, as a convex combination of the high-order and low-order solutions, $f_{\\text{HO}}$ and $f_{\\text{LO}}$. The goal is to enforce $f_{\\text{lim}, i} \\ge \\varepsilon$ at every grid point $v_i$, where $\\varepsilon = 10^{-14}$ is a small positive floor, while deviating minimally from the more accurate $f_{\\text{HO}, i}$.\n\nThe algorithmic logic for the limiter at each grid point $v_i$ is as follows:\n1.  Compute both $f_{\\text{HO}, i}$ and $f_{\\text{LO}, i}$.\n2.  If $f_{\\text{HO}, i} \\ge \\varepsilon$, no correction is needed. We retain the high-order result: $f_{\\text{lim}, i} = f_{\\text{HO}, i}$.\n3.  If $f_{\\text{HO}, i}  \\varepsilon$, a correction is necessary. We must find a value on the line segment between $f_{\\text{LO}, i}$ and $f_{\\text{HO}, i}$ that satisfies the positivity constraint and is closest to $f_{\\text{HO}, i}$.\n    - If $f_{\\text{LO}, i} \\ge \\varepsilon$, a range of valid convex combinations exists. The minimal correction that satisfies the constraint sets the limited value to be exactly the floor: $f_{\\text{lim}, i} = \\varepsilon$. This corresponds to finding the minimal blend of $f_{\\text{LO}}$ required to lift the negative $f_{\\text{HO}}$ value up to $\\varepsilon$.\n    - If $f_{\\text{LO}, i}  \\varepsilon$, even the \"safe\" low-order scheme fails to meet the threshold. In this case, no convex combination of $f_{\\text{HO}, i}$ and $f_{\\text{LO}, i}$ can be greater than or equal to $\\varepsilon$ (assuming $f_{\\text{HO}, i} \\le f_{\\text{LO}, i}$ or that $f_{HO}$ represents an undershoot). The most reasonable action is to accept the monotone, low-order result as a fallback: $f_{\\text{lim}, i} = f_{\\text{LO}, i}$.\n\nThis procedure defines the final limited solution $f_{\\text{lim}}$. The performance of the unlimited high-order scheme and the limited scheme will be evaluated using three metrics, calculated after a single time step from the initial condition $f_0(v)$:\n1.  **Minimum value**: $\\min_i f_i^{n+1}$. This directly tests the positivity-preserving property.\n2.  **Absolute mass error**: $|\\sum_i f_i^{n+1} \\Delta v - \\sum_i f_i^n \\Delta v|$. The exact advection conserves mass ($\\int f dv$), so this metric quantifies the numerical scheme's conservation property.\n3.  **Relative $L^1$ error**: $\\frac{\\sum_i |f_i^{n+1} - f_{\\text{exact}}(v_i)| \\Delta v}{\\sum_i |f_{\\text{exact}}(v_i)| \\Delta v}$. This measures the accuracy of the numerical solution against the known exact solution, $f_{\\text{exact}}(v) = f_0(v - a \\Delta t)$.\n\nThe following program implements this entire procedure for the three specified test cases, computing and reporting the six requested quantities for each case.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a positivity-preserving limiter for a semi-Lagrangian\n    Vlasov solver in 1D velocity space.\n    \"\"\"\n\n    # --- Problem Constants and Grid Setup ---\n    V_MIN = -6.0\n    V_MAX = 6.0\n    N = 256\n    EPSILON = 1e-14\n    DV = (V_MAX - V_MIN) / N\n    V_GRID = np.linspace(V_MIN, V_MAX, N, endpoint=False)\n\n    def initial_condition(v: np.ndarray) - np.ndarray:\n        \"\"\"Computes the initial distribution function f_0(v).\"\"\"\n        # Top-hat component\n        A1 = 1.0\n        vc = 0.0\n        w = 1.0\n        f_hat = np.where(np.abs(v - vc) = w, A1, 0.0)\n\n        # Gaussian bump component\n        A2 = 0.5\n        vb = 2.7\n        sigma_b = 0.06\n        f_bump = A2 * np.exp(-(v - vb)**2 / (2 * sigma_b**2))\n\n        return f_hat + f_bump\n\n    def linear_interp_advect(f_n: np.ndarray, shift_val: float) - np.ndarray:\n        \"\"\"Advects f_n using semi-Lagrangian scheme with linear interpolation.\"\"\"\n        feet_v = V_GRID - shift_val\n        # Normalize coordinates to grid index units and handle periodicity\n        feet_s = ((feet_v - V_MIN) / DV) % N\n        \n        j0 = np.floor(feet_s).astype(int)\n        alpha = feet_s - j0\n        j1 = (j0 + 1) % N\n        \n        f_next = (1.0 - alpha) * f_n[j0] + alpha * f_n[j1]\n        return f_next\n\n    def catmull_rom_interp_advect(f_n: np.ndarray, shift_val: float) - np.ndarray:\n        \"\"\"Advects f_n using semi-Lagrangian scheme with Catmull-Rom interpolation.\"\"\"\n        feet_v = V_GRID - shift_val\n        # Normalize coordinates to grid index units and handle periodicity\n        feet_s = ((feet_v - V_MIN) / DV) % N\n\n        j1 = np.floor(feet_s).astype(int)\n        alpha = feet_s - j1\n\n        # Get the 4 required points with periodic boundaries\n        j0 = (j1 - 1 + N) % N\n        j2 = (j1 + 1) % N\n        j3 = (j1 + 2) % N\n\n        p0, p1, p2, p3 = f_n[j0], f_n[j1], f_n[j2], f_n[j3]\n\n        # Catmull-Rom polynomial evaluation\n        alpha2 = alpha * alpha\n        alpha3 = alpha2 * alpha\n        \n        c0 = p1\n        c1 = 0.5 * (-p0 + p2)\n        c2 = p0 - 2.5 * p1 + 2.0 * p2 - 0.5 * p3\n        c3 = -0.5 * p0 + 1.5 * p1 - 1.5 * p2 + 0.5 * p3\n        \n        f_next = c3*alpha3 + c2*alpha2 + c1*alpha + c0\n        return f_next\n        \n    def apply_positivity_limiter(f_ho: np.ndarray, f_lo: np.ndarray) - np.ndarray:\n        \"\"\"Applies a positivity-preserving limiter to the high-order solution.\"\"\"\n        f_lim = np.copy(f_ho)\n        \n        # Identify points where the high-order solution violates positivity\n        needs_limiting = f_ho  EPSILON\n        \n        if np.any(needs_limiting):\n            # For points needing a fix, check the low-order solution\n            f_lo_at_limited_pts = f_lo[needs_limiting]\n            \n            # If f_lo is also below threshold, fallback to f_lo.\n            # Otherwise, blend just enough to reach the epsilon floor.\n            limiter_values = np.where(f_lo_at_limited_pts  EPSILON, f_lo_at_limited_pts, EPSILON)\n            f_lim[needs_limiting] = limiter_values\n\n        return f_lim\n\n    # --- Test Case Execution ---\n    test_cases = [\n        (5.0, 0.9),    # Case 1\n        (5.0, 3.7),    # Case 2\n        (17.0, 15.3),  # Case 3\n    ]\n\n    results = []\n\n    # Initial condition and its mass\n    f0 = initial_condition(V_GRID)\n    mass0 = np.sum(f0) * DV\n\n    for a, shift_in_dv in test_cases:\n        shift_val = shift_in_dv * DV\n\n        # Calculate exact solution at t=dt for error comparison\n        f_exact = initial_condition(V_GRID - shift_val)\n        l1_norm_exact = np.sum(np.abs(f_exact)) * DV\n        # Prevent division by zero if f_exact is identically zero\n        if l1_norm_exact == 0:\n            l1_norm_exact = 1.0\n\n        # 1. High-order (unlimited) solution\n        f_ho = catmull_rom_interp_advect(f0, shift_val)\n\n        # 2. Low-order solution (for the limiter)\n        f_lo = linear_interp_advect(f0, shift_val)\n\n        # 3. Limited solution\n        f_lim = apply_positivity_limiter(f_ho, f_lo)\n        \n        # --- Metrics for High-Order (no limiter) Solution ---\n        min_ho = np.min(f_ho)\n        mass_ho = np.sum(f_ho) * DV\n        mass_err_ho = np.abs(mass_ho - mass0)\n        l1_err_ho = np.sum(np.abs(f_ho - f_exact)) * DV / l1_norm_exact\n\n        # --- Metrics for Limited Solution ---\n        min_lim = np.min(f_lim)\n        mass_lim = np.sum(f_lim) * DV\n        mass_err_lim = np.abs(mass_lim - mass0)\n        l1_err_lim = np.sum(np.abs(f_lim - f_exact)) * DV / l1_norm_exact\n        \n        results.extend([min_ho, min_lim, mass_err_ho, mass_err_lim, l1_err_ho, l1_err_lim])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{x:.12f}' for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Simulations of magnetically confined fusion plasmas in devices like tokamaks necessitate the use of curvilinear coordinate systems aligned with the magnetic field. A naive translation of equations from Cartesian to general coordinates can introduce significant errors if the geometry, captured by metric terms like the Jacobian, is not handled correctly. This practice  involves designing a verification test to isolate these metric-induced errors, demonstrating the crucial importance of a conservative formulation for achieving coordinate-invariant and thus physically reliable results.",
            "id": "4185000",
            "problem": "You are asked to design and implement a coordinate-invariance test that isolates metric-induced errors in continuum (Eulerian) Vlasov solvers by comparing the same physical advection problem in Cartesian and in a simple field-aligned curvilinear coordinate system. The goal is to demonstrate that, for an incompressible Hamiltonian flow underlying the collisionless Vlasov dynamics, a correct conservative formulation in general coordinates preserves a uniform distribution function, while an implementation that neglects metric factors generates a spurious residual. Your program must compute and report a scalar diagnostic for several test cases.\n\nStart from the following fundamental base:\n- The collisionless Vlasov equation for a passive distribution function $f$ on a phase-space domain with flow $\\boldsymbol{a}$ is the conservative transport equation $\\partial f / \\partial t + \\nabla \\cdot (\\boldsymbol{a} f) = 0$, where $\\nabla \\cdot \\boldsymbol{a} = 0$ for incompressible Hamiltonian flow.\n- In general curvilinear coordinates $u^i$, the divergence of a physical vector field with contravariant components $a^i$ and Jacobian $J$ that maps $u^i$-space volume to physical volume is given by $\\nabla \\cdot \\boldsymbol{a} = \\dfrac{1}{J} \\partial_i (J a^i)$.\n\nConsider a two-dimensional configuration-space analog that isolates metric effects without invoking self-consistent fields. Let $(x,y)$ denote Cartesian coordinates and $(\\xi,\\eta)$ denote field-aligned coordinates connected by the smooth, strictly monotone mapping\n$$\nx(\\xi,\\eta) = \\xi,\\qquad y(\\xi,\\eta) = h(\\xi)\\,\\eta,\n$$\nwith\n$$\nh(\\xi) = 1 + \\alpha \\cos\\left(\\dfrac{2\\pi}{L_x}\\,\\xi\\right),\\qquad 0 \\le \\alpha  1,\\quad L_x  0.\n$$\nAssume periodic boundary conditions in both directions, $\\xi \\in [0,L_x)$ and $\\eta \\in [0,L_y)$. The Jacobian determinant (metric volume factor) of this mapping is $J(\\xi,\\eta) = h(\\xi)$. Let the physical advection velocity be uniform and constant in Cartesian coordinates,\n$$\n\\boldsymbol{U} = (U_x, U_y),\n$$\nso that the physical flow is incompressible, $\\nabla \\cdot \\boldsymbol{U} = 0$. For a uniform initial distribution $f_0$, the exact right-hand side residual $R = -\\nabla \\cdot (\\boldsymbol{U} f_0)$ must be identically zero in any coordinate system when the divergence is formulated correctly.\n\nDefine three discrete residual fields on a uniform grid of size $N_x \\times N_y$ in $(\\xi,\\eta)$-space, using second-order centered finite differences with periodic boundary conditions:\n- $R_{\\mathrm{cart}}$: the residual computed in Cartesian coordinates on the same uniform computational grid (interpreted directly as $(x,y)$) for the constant flux $\\boldsymbol{U} f_0$.\n- $R_{\\mathrm{curv,correct}}$: the residual computed in curvilinear coordinates using the conservative divergence with the correct metric factor and contravariant components,\n$$\nR_{\\mathrm{curv,correct}}(\\xi,\\eta) = -\\dfrac{1}{J(\\xi,\\eta)}\\left[ \\partial_\\xi\\left(J(\\xi,\\eta)\\,a^\\xi(\\xi,\\eta)\\,f_0\\right) + \\partial_\\eta\\left(J(\\xi,\\eta)\\,a^\\eta(\\xi,\\eta)\\,f_0\\right) \\right].\n$$\nHere $\\boldsymbol{a} = (a^\\xi,a^\\eta)$ are the contravariant components of $\\boldsymbol{U}$ in the $(\\xi,\\eta)$ basis defined by the mapping above.\n- $R_{\\mathrm{curv,naive}}$: the residual computed in curvilinear coordinates by a naive divergence that ignores the metric factor,\n$$\nR_{\\mathrm{curv,naive}}(\\xi,\\eta) = -\\left[\\partial_\\xi a^\\xi(\\xi,\\eta) + \\partial_\\eta a^\\eta(\\xi,\\eta)\\right] f_0.\n$$\n\nThe test that isolates metric-induced errors is to compare the root-mean-square (RMS) amplitude of $R_{\\mathrm{curv,naive}}$ against the vanishing values of $R_{\\mathrm{cart}}$ and $R_{\\mathrm{curv,correct}}$ for the same physical setup. A nonzero RMS of $R_{\\mathrm{curv,naive}}$ in cases with nontrivial metric variation or nonzero $U_x$ indicates purely metric-induced error. This comparison demonstrates the necessity of the Jacobian-weighted divergence in continuum (Eulerian) Vlasov solvers written in curvilinear coordinates.\n\nYour tasks:\n1. Derive the contravariant components $a^\\xi(\\xi,\\eta)$ and $a^\\eta(\\xi,\\eta)$ of the constant Cartesian velocity $\\boldsymbol{U}$ in the $(\\xi,\\eta)$ coordinate basis induced by the mapping above.\n2. Implement second-order centered finite-difference approximations for $\\partial_\\xi$ and $\\partial_\\eta$ with periodic boundary conditions on a uniform computational grid $(\\xi_i,\\eta_j)$, $i=0,\\dots,N_x-1$, $j=0,\\dots,N_y-1$ with spacings $\\Delta \\xi = L_x/N_x$ and $\\Delta \\eta = L_y/N_y$.\n3. For each test case, compute the RMS of $R_{\\mathrm{curv,naive}}$ over the grid, defined as\n$$\n\\mathrm{RMS}(R) = \\left( \\dfrac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} R(\\xi_i,\\eta_j)^2 \\right)^{1/2}.\n$$\nYou may take $f_0 = 1$ without loss of generality.\n\nTest suite:\nProvide results for the following parameter sets $(\\alpha, N_x, N_y, U_x, U_y, L_x, L_y)$:\n- Case A (happy path): $(0.3, 64, 64, 1.0, 0.5, 2\\pi, 2\\pi)$.\n- Case B (boundary, no metric variation): $(0.0, 32, 32, 1.0, 0.0, 2\\pi, 2\\pi)$.\n- Case C (edge, flow aligned with $\\eta$ so $U_x = 0$): $(0.3, 48, 96, 0.0, 1.0, 2\\pi, 2\\pi)$.\n- Case D (edge, anisotropic grid and strong variation): $(0.5, 16, 128, 1.0, 0.0, 2\\pi, 2\\pi)$.\n- Case E (refined resolution): $(0.3, 128, 128, 1.0, 0.5, 2\\pi, 2\\pi)$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one floating-point number per test case in the same order as above, representing $\\mathrm{RMS}(R_{\\mathrm{curv,naive}})$ for each case, for example, \"[0.123,0.0,0.0,0.456,0.078]\". All quantities are nondimensional; no physical units are required. Angles, where present, are in radians. Percentages must not be used.",
            "solution": "The problem requires the design and implementation of a coordinate-invariance test for a continuum Vlasov solver. This test is designed to isolate and quantify numerical errors that arise from neglecting metric tensor components in a curvilinear coordinate system. The core of the task is to compute a scalar diagnostic, the root-mean-square (RMS) of a \"naively\" computed residual, for a simple incompressible flow field.\n\nThe analysis proceeds in three main steps:\n1.  Derivation of the contravariant components of the advection velocity in the specified curvilinear coordinate system.\n2.  Specification of the numerical algorithm to compute the residual field using finite differences.\n3.  Calculation of the RMS diagnostic for the provided test cases.\n\n### 1. Derivation of Contravariant Velocity Components\n\nWe are given a transformation from a curvilinear coordinate system $(\\xi, \\eta)$ to a Cartesian system $(x,y)$:\n$$\nx(\\xi,\\eta) = \\xi\n$$\n$$\ny(\\xi,\\eta) = h(\\xi)\\,\\eta\n$$\nwhere $h(\\xi) = 1 + \\alpha \\cos\\left(\\frac{2\\pi}{L_x}\\xi\\right)$.\n\nThe Cartesian velocity components $(U_x, U_y) = (\\dot{x}, \\dot{y})$ are related to the time derivatives of the curvilinear coordinates $(\\dot{\\xi}, \\dot{\\eta})$ by the chain rule:\n$$\n\\begin{pmatrix} \\dot{x} \\\\ \\dot{y} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi}  \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi}  \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix} \\begin{pmatrix} \\dot{\\xi} \\\\ \\dot{\\eta} \\end{pmatrix}\n$$\nThe contravariant components of the velocity vector are, by definition, $a^\\xi = \\dot{\\xi}$ and $a^\\eta = \\dot{\\eta}$. The matrix in the equation above is the Jacobian matrix of the transformation, $\\mathbf{J}_{map}$. We must compute its components:\n$$\n\\frac{\\partial x}{\\partial \\xi} = 1\n$$\n$$\n\\frac{\\partial x}{\\partial \\eta} = 0\n$$\n$$\n\\frac{\\partial y}{\\partial \\xi} = \\frac{dh}{d\\xi}\\eta = h'(\\xi)\\eta\n$$\n$$\n\\frac{\\partial y}{\\partial \\eta} = h(\\xi)\n$$\nSubstituting these into the matrix equation:\n$$\n\\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ h'(\\xi)\\eta  h(\\xi) \\end{pmatrix} \\begin{pmatrix} a^\\xi \\\\ a^\\eta \\end{pmatrix}\n$$\nTo find the contravariant components $(a^\\xi, a^\\eta)$, we invert the Jacobian matrix:\n$$\n\\mathbf{J}_{map}^{-1} = \\frac{1}{\\det(\\mathbf{J}_{map})} \\begin{pmatrix} h(\\xi)  0 \\\\ -h'(\\xi)\\eta  1 \\end{pmatrix} = \\frac{1}{h(\\xi)} \\begin{pmatrix} h(\\xi)  0 \\\\ -h'(\\xi)\\eta  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ -\\frac{h'(\\xi)\\eta}{h(\\xi)}  \\frac{1}{h(\\xi)} \\end{pmatrix}\n$$\nNote that the determinant, $\\det(\\mathbf{J}_{map}) = h(\\xi)$, is the Jacobian $J$ of the coordinate transformation, as given in the problem statement.\n\nNow, we solve for the contravariant components:\n$$\n\\begin{pmatrix} a^\\xi \\\\ a^\\eta \\end{pmatrix} = \\mathbf{J}_{map}^{-1} \\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ -\\frac{h'(\\xi)\\eta}{h(\\xi)}  \\frac{1}{h(\\xi)} \\end{pmatrix} \\begin{pmatrix} U_x \\\\ U_y \\end{pmatrix}\n$$\nThis matrix multiplication yields the explicit expressions for the contravariant velocity components:\n$$\na^\\xi(\\xi, \\eta) = U_x\n$$\n$$\na^\\eta(\\xi, \\eta) = -\\frac{h'(\\xi)\\eta}{h(\\xi)}U_x + \\frac{1}{h(\\xi)}U_y = \\frac{U_y - U_x h'(\\xi)\\eta}{h(\\xi)}\n$$\nwhere $h'(\\xi) = \\frac{dh}{d\\xi} = -\\alpha \\frac{2\\pi}{L_x} \\sin\\left(\\frac{2\\pi}{L_x}\\xi\\right)$. These expressions are essential for calculating the residual.\n\n### 2. Discretization and Residual Calculation\n\nThe problem asks to compute the \"naive\" residual, which ignores metric factors. For a uniform distribution $f_0=1$, this is:\n$$\nR_{\\mathrm{curv,naive}}(\\xi,\\eta) = -\\left(\\frac{\\partial a^\\xi}{\\partial \\xi} + \\frac{\\partial a^\\eta}{\\partial \\eta}\\right)\n$$\nWe evaluate this on a uniform computational grid $(\\xi_i, \\eta_j)$ where $\\xi_i = i \\Delta\\xi$ for $i=0,\\dots,N_x-1$ and $\\eta_j = j \\Delta\\eta$ for $j=0,\\dots,N_y-1$, with grid spacings $\\Delta\\xi = L_x/N_x$ and $\\Delta\\eta = L_y/N_y$.\n\nThe partial derivatives are approximated using second-order centered finite differences with periodic boundary conditions. For a generic grid function $F_{i,j} = F(\\xi_i, \\eta_j)$:\n$$\n\\left(\\frac{\\partial F}{\\partial \\xi}\\right)_{i,j} \\approx \\frac{F_{i+1,j} - F_{i-1,j}}{2\\Delta\\xi}\n$$\n$$\n\\left(\\frac{\\partial F}{\\partial \\eta}\\right)_{i,j} \\approx \\frac{F_{i,j+1} - F_{i,j-1}}{2\\Delta\\eta}\n$$\nPeriodicity implies that $F_{N_x, j} = F_{0, j}$, $F_{-1, j} = F_{N_x-1, j}$, and similarly for the $j$ index.\n\nLet's apply these operators to our contravariant components $a^\\xi$ and $a^\\eta$.\nFirst, for $\\partial a^\\xi / \\partial \\xi$:\nSince $a^\\xi(\\xi, \\eta) = U_x$ is a constant, its derivative with respect to any variable is analytically zero. The centered difference operator also gives zero exactly:\n$$\n\\frac{\\partial a^\\xi}{\\partial \\xi} \\approx \\frac{U_x - U_x}{2\\Delta\\xi} = 0\n$$\nNext, for $\\partial a^\\eta / \\partial \\eta$:\nThe component $a^\\eta$ is a linear function of $\\eta$. The centered difference operator is exact for polynomials of degree up to $2$, so it will be exact here.\n$$\n\\left(\\frac{\\partial a^\\eta}{\\partial \\eta}\\right)_{i,j} \\approx \\frac{a^\\eta(\\xi_i, \\eta_{j+1}) - a^\\eta(\\xi_i, \\eta_{j-1})}{2\\Delta\\eta} = \\frac{1}{2\\Delta\\eta} \\left[ \\frac{U_y - U_x h'(\\xi_i)\\eta_{j+1}}{h(\\xi_i)} - \\frac{U_y - U_x h'(\\xi_i)\\eta_{j-1}}{h(\\xi_i)} \\right]\n$$\n$$\n= \\frac{-U_x h'(\\xi_i)}{2\\Delta\\eta h(\\xi_i)} (\\eta_{j+1} - \\eta_{j-1}) = \\frac{-U_x h'(\\xi_i)}{2\\Delta\\eta h(\\xi_i)} (2\\Delta\\eta) = -\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\n$$\nThe numerical derivative is identical to the analytical derivative $\\frac{\\partial}{\\partial \\eta} \\left(\\frac{U_y}{h(\\xi)} - \\frac{U_x h'(\\xi) \\eta}{h(\\xi)}\\right) = -\\frac{U_x h'(\\xi)}{h(\\xi)}$.\n\nCombining these results, the numerically computed residual at each grid point is:\n$$\nR_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j) = -\\left(0 - \\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right) = \\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\n$$\nThis expression shows that the residual is independent of $\\eta$ and is non-zero if and only if $U_x \\neq 0$ and $h'(\\xi_i) \\neq 0$. The latter is true if $\\alpha \\neq 0$ and $\\sin\\left(\\frac{2\\pi}{L_x}\\xi_i\\right) \\neq 0$. This residual is a direct consequence of neglecting the metric Jacobian $J=h(\\xi)$ inside the divergence operator, confirming the premise of the problem.\n\n### 3. RMS Diagnostic Calculation\n\nThe final task is to compute the RMS value of the residual field over the entire grid:\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x N_y} \\sum_{i=0}^{N_x-1} \\sum_{j=0}^{N_y-1} \\left(R_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j)\\right)^2 \\right)^{1/2}\n$$\nSince the residual $R_{\\mathrm{curv,naive}}(\\xi_i, \\eta_j)$ only depends on the index $i$, we can simplify the double summation:\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x N_y} \\sum_{j=0}^{N_y-1} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2} = \\left( \\frac{N_y}{N_x N_y} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2}\n$$\n$$\n\\mathrm{RMS}(R_{\\mathrm{curv,naive}}) = \\left( \\frac{1}{N_x} \\sum_{i=0}^{N_x-1} \\left(\\frac{U_x h'(\\xi_i)}{h(\\xi_i)}\\right)^2 \\right)^{1/2}\n$$\nThis final expression is implemented for each test case. The implementation will follow the numerical differentiation steps as required, although we have shown it simplifies to this analytical form. The code calculates the array of residual values `R_naive` on the 2D grid and then computes its RMS value directly.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the coordinate-invariance test problem for continuum Vlasov solvers.\n    \n    This function calculates the RMS of a naively computed residual for several\n    test cases to demonstrate metric-induced errors in a curvilinear \n    coordinate system.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (alpha, Nx, Ny, Ux, Uy, Lx, Ly) - Happy path\n        (0.3, 64, 64, 1.0, 0.5, 2 * np.pi, 2 * np.pi),\n        # Case B: alpha=0, no metric variation\n        (0.0, 32, 32, 1.0, 0.0, 2 * np.pi, 2 * np.pi),\n        # Case C: Ux=0, flow aligned with eta-coordinate\n        (0.3, 48, 96, 0.0, 1.0, 2 * np.pi, 2 * np.pi),\n        # Case D: Anisotropic grid, strong metric variation\n        (0.5, 16, 128, 1.0, 0.0, 2 * np.pi, 2 * np.pi),\n        # Case E: Refined resolution of Case A\n        (0.3, 128, 128, 1.0, 0.5, 2 * np.pi, 2 * np.pi),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        alpha, Nx, Ny, Ux, Uy, Lx, Ly = case\n        \n        f0 = 1.0\n\n        # 1. Set up the computational grid in (xi, eta) space.\n        # Grid points are cell centers for a finite volume interpretation,\n        # but the problem implies a node-based grid up to L_x, L_y (exclusive).\n        #linspace endpoint=False creates an array of N points from start to stop-step.\n        xi_1d = np.linspace(0, Lx, Nx, endpoint=False)\n        eta_1d = np.linspace(0, Ly, Ny, endpoint=False)\n        xi_grid, eta_grid = np.meshgrid(xi_1d, eta_1d)\n\n        # Grid spacings\n        D_xi = Lx / Nx\n        D_eta = Ly / Ny\n\n        # 2. Calculate metric-related functions h(xi) and h'(xi).\n        # These are functions of xi only, but we broadcast them to the full grid size.\n        k = (2 * np.pi) / Lx\n        h_grid = 1.0 + alpha * np.cos(k * xi_grid)\n        h_prime_grid = -alpha * k * np.sin(k * xi_grid)\n\n        # 3. Derive the contravariant components of the velocity field.\n        # These components, a^xi and a^eta, are defined on the (xi, eta) grid.\n        # a_xi is constant.\n        a_xi_grid = Ux * np.ones_like(xi_grid)\n        \n        # a_eta depends on xi and eta.\n        # To avoid division by zero if h_grid should ever be zero (prevented by alpha  1).\n        with np.errstate(divide='raise', invalid='raise'):\n             a_eta_grid = (Uy - Ux * h_prime_grid * eta_grid) / h_grid\n\n        # 4. Compute partial derivatives using 2nd-order centered differences\n        # with periodic boundary conditions.\n        # np.roll provides an efficient way to implement periodic shifts.\n        # axis=1 corresponds to xi (columns), axis=0 corresponds to eta (rows).\n        \n        # d(a_xi)/d_xi\n        d_xi_a_xi = (np.roll(a_xi_grid, -1, axis=1) - np.roll(a_xi_grid, 1, axis=1)) / (2 * D_xi)\n        \n        # d(a_eta)/d_eta\n        d_eta_a_eta = (np.roll(a_eta_grid, -1, axis=0) - np.roll(a_eta_grid, 1, axis=0)) / (2 * D_eta)\n\n        # 5. Compute the naive residual field, R_curv_naive.\n        # R_naive = - (d(a^xi)/d_xi + d(a^eta)/d_eta) * f0\n        R_naive = -(d_xi_a_xi + d_eta_a_eta) * f0\n\n        # 6. Calculate the Root-Mean-Square (RMS) of the residual field.\n        rms_val = np.sqrt(np.mean(R_naive**2))\n        results.append(rms_val)\n\n    # Format the final output string as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}