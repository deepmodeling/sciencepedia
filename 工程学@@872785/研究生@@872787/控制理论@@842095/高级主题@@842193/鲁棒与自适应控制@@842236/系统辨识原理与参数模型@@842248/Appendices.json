{"hands_on_practices": [{"introduction": "ARX模型是系统辨识中最基本的参数模型之一，通常使用最小二乘法进行估计。然而，仅仅获得参数的点估计是不够的；我们还需要量化其不确定性。本练习将引导你推导最小二乘估计量的渐近协方差矩阵，这是评估估计质量和构造置信区间的理论基础。[@problem_id:2751642]", "problem": "考虑由下式给出的$\\left(2,1\\right)$阶带外源输入的自回归（ARX）模型\n$$\ny(k) \\;=\\; -a_{1}\\,y(k-1)\\;-\\;a_{2}\\,y(k-2)\\;+\\;b_{1}\\,u(k-1)\\;+\\;e(k),\n$$\n其中$e(k)$是一个零均值、独立同分布（i.i.d.）的扰动，其方差为$\\sigma_{e}^{2}$，并且独立于回归量过程。定义参数向量 $\\theta_{0}=\\begin{pmatrix}a_{1}  a_{2}  b_{1}\\end{pmatrix}^{\\top}$ 和回归量 $\\varphi(k)=\\begin{pmatrix}-y(k-1)  -y(k-2)  u(k-1)\\end{pmatrix}^{\\top}$，从而有 $y(k)=\\varphi(k)^{\\top}\\theta_{0}+e(k)$。基于$N$个样本的最小二乘（LS）估计量为\n$$\n\\hat{\\theta}_{N} \\;=\\; \\arg\\min_{\\theta}\\sum_{k=1}^{N}\\big(y(k)-\\varphi(k)^{\\top}\\theta\\big)^{2}.\n$$\n假设用于带随机回归量的线性回归中最小二乘法的一致性和渐近正态性的标准正则性条件成立：输入$u(k)$是平稳的且至少为3阶持续激励，联合过程$\\{\\varphi(k),e(k)\\}$是平稳遍历的，$\\mathbb{E}\\big[\\varphi(k)\\,e(k)\\big]=0$，并且$\\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}=R_{\\varphi}$存在且为正定矩阵。\n\n1) 从最小二乘估计量的定义和这些假设出发，推导尺度化估计误差$\\sqrt{N}\\big(\\hat{\\theta}_{N}-\\theta_{0}\\big)$的渐近协方差，并证明其等于\n$$\n\\Sigma_{\\theta} \\;=\\; \\sigma_{e}^{2}\\,R_{\\varphi}^{-1}.\n$$\n解释如何使用一个考虑了估计参数数量的无偏方差估计量，从残差$\\hat{e}(k)=y(k)-\\varphi(k)^{\\top}\\hat{\\theta}_{N}$中估计$\\sigma_{e}^{2}$。\n\n2) 在一个有$N=1000$个样本和$n_{p}=3$个估计参数的实验中，假设极限$R_{\\varphi}=\\lim_{N\\to\\infty}\\frac{1}{N}\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}$已知为\n$$\nR_{\\varphi} \\;=\\;\n\\begin{pmatrix}\n2.0  0.5  0.0\\\\\n0.5  1.5  0.2\\\\\n0.0  0.2  3.0\n\\end{pmatrix},\n$$\n并且残差平方和为$\\sum_{k=1}^{N}\\hat{e}(k)^{2}=997$。使用你所描述的无偏残差方差估计量，计算尺度化误差$\\sqrt{N}\\big(\\hat{\\theta}_{N}-\\theta_{0}\\big)$的渐近协方差$\\Sigma_{\\theta}$的数值矩阵。将最终矩阵的每个元素四舍五入到四位有效数字。以单个无单位矩阵的形式提供最终答案。", "solution": "所给问题是动态系统（特别是ARX模型）最小二乘估计量渐近分析的一个标准练习。该问题具有科学依据，提法恰当，并包含了所有必要信息。问题是有效的。我们分两部分进行求解。\n\n第1部分：渐近协方差和无偏方差估计量的推导。\n\n最小二乘估计量$\\hat{\\theta}_{N}$最小化了误差平方和 $J(\\theta) = \\sum_{k=1}^{N}(y(k)-\\varphi(k)^{\\top}\\theta)^{2}$。最小化的一阶条件是$\\nabla_{\\theta}J(\\theta)|_{\\theta=\\hat{\\theta}_{N}} = 0$。这给出了正规方程组：\n$$\n\\sum_{k=1}^{N}\\varphi(k)\\big(y(k)-\\varphi(k)^{\\top}\\hat{\\theta}_{N}\\big) \\;=\\; 0\n$$\n$$\n\\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)\\hat{\\theta}_{N} \\;=\\; \\sum_{k=1}^{N}\\varphi(k)y(k)\n$$\n真实系统由$y(k)=\\varphi(k)^{\\top}\\theta_{0}+e(k)$给出。将其代入正规方程组：\n$$\n\\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)\\hat{\\theta}_{N} \\;=\\; \\sum_{k=1}^{N}\\varphi(k)\\big(\\varphi(k)^{\\top}\\theta_{0}+e(k)\\big)\n$$\n$$\n\\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)\\hat{\\theta}_{N} \\;=\\; \\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)\\theta_{0} \\;+\\; \\sum_{k=1}^{N}\\varphi(k)e(k)\n$$\n重新整理各项以分离出估计误差$\\hat{\\theta}_{N}-\\theta_{0}$：\n$$\n\\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)(\\hat{\\theta}_{N}-\\theta_{0}) \\;=\\; \\sum_{k=1}^{N}\\varphi(k)e(k)\n$$\n$$\n\\hat{\\theta}_{N}-\\theta_{0} \\;=\\; \\left(\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)^{-1}\\left(\\sum_{k=1}^{N}\\varphi(k)e(k)\\right)\n$$\n为了分析渐近分布，我们将误差按$\\sqrt{N}$进行尺度化：\n$$\n\\sqrt{N}(\\hat{\\theta}_{N}-\\theta_{0}) \\;=\\; \\left(\\frac{1}{N}\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)^{-1}\\left(\\frac{1}{\\sqrt{N}}\\sum_{k=1}^{N}\\varphi(k)e(k)\\right)\n$$\n我们分析当$N\\to\\infty$时右侧的两项。\n对于第一项，根据过程是遍历的且极限存在的假设，大数定律意味着：\n$$\n\\frac{1}{N}\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top} \\;\\xrightarrow{p}\\; \\mathbb{E}\\big[\\varphi(k)\\varphi(k)^{\\top}\\big] \\;=\\; R_{\\varphi}\n$$\n其中$\\xrightarrow{p}$表示依概率收敛。由于矩阵求逆是一个连续函数，根据连续映射定理可得：\n$$\n\\left(\\frac{1}{N}\\sum_{k=1}^{N}\\varphi(k)\\varphi(k)^{\\top}\\right)^{-1} \\;\\xrightarrow{p}\\; R_{\\varphi}^{-1}\n$$\n对于第二项，我们考虑和$S_{N} = \\frac{1}{\\sqrt{N}}\\sum_{k=1}^{N}\\varphi(k)e(k)$。根据假设，向量过程$v(k)=\\varphi(k)e(k)$的均值为零，即$\\mathbb{E}[v(k)] = \\mathbb{E}[\\varphi(k)e(k)] = 0$。此外，对于由$\\{e(j), u(j)\\}_{j \\le k-1}$生成的$\\sigma$-代数流$\\mathcal{F}_{k-1}$，$v(k)$是一个鞅差序列，因为$\\mathbb{E}[v(k) | \\mathcal{F}_{k-1}] = \\varphi(k)\\mathbb{E}[e(k) | \\mathcal{F}_{k-1}] = \\varphi(k)\\cdot 0 = 0$。\n鞅差序列的中心极限定理指出，$S_{N}$依分布收敛到一个均值为零、协方差矩阵为$Q$的正态分布随机向量：\n$$\n\\frac{1}{\\sqrt{N}}\\sum_{k=1}^{N}\\varphi(k)e(k) \\;\\xrightarrow{d}\\; \\mathcal{N}(0, Q)\n$$\n其中$\\xrightarrow{d}$表示依分布收敛，协方差矩阵$Q$由下式给出：\n$$\nQ \\;=\\; \\lim_{N\\to\\infty} \\frac{1}{N}\\sum_{k=1}^{N}\\mathbb{E}\\big[(\\varphi(k)e(k))(\\varphi(k)e(k))^{\\top}\\big] \\;=\\; \\mathbb{E}\\big[\\varphi(k)\\varphi(k)^{\\top}e(k)^{2}\\big]\n$$\n由于$e(k)$独立于回归量$\\varphi(k)$（它依赖于过去的数据），我们可以将期望分离：\n$$\nQ \\;=\\; \\mathbb{E}\\big[\\varphi(k)\\varphi(k)^{\\top}\\big]\\,\\mathbb{E}\\big[e(k)^{2}\\big] \\;=\\; R_{\\varphi}\\,\\sigma_{e}^{2}\n$$\n使用斯卢茨基(Slutsky)定理结合这两个结果，我们得到尺度化估计误差的渐近分布：\n$$\n\\sqrt{N}(\\hat{\\theta}_{N}-\\theta_{0}) \\;\\xrightarrow{d}\\; R_{\\varphi}^{-1} \\cdot \\mathcal{N}(0, \\sigma_{e}^{2}R_{\\varphi})\n$$\n$\\sqrt{N}(\\hat{\\theta}_{N}-\\theta_{0})$的渐近协方差是所得正态分布的协方差。令$X \\sim \\mathcal{N}(0, \\sigma_{e}^{2}R_{\\varphi})$。$R_{\\varphi}^{-1}X$的协方差为：\n$$\n\\text{Cov}(R_{\\varphi}^{-1}X) \\;=\\; R_{\\varphi}^{-1}\\,\\text{Cov}(X)\\,(R_{\\varphi}^{-1})^{\\top} \\;=\\; R_{\\varphi}^{-1}(\\sigma_{e}^{2}R_{\\varphi})(R_{\\varphi}^{-1})^{\\top}\n$$\n由于$R_{\\varphi}$是对称的，所以$R_{\\varphi}^{-1}$也是对称的，因此$(R_{\\varphi}^{-1})^{\\top} = R_{\\varphi}^{-1}$。\n$$\n\\Sigma_{\\theta} \\;=\\; \\sigma_{e}^{2}R_{\\varphi}^{-1}R_{\\varphi}R_{\\varphi}^{-1} \\;=\\; \\sigma_{e}^{2}R_{\\varphi}^{-1}\n$$\n这就完成了推导的第一部分。\n\n对于第二部分，我们必须找到噪声方差$\\sigma_{e}^{2}$的无偏估计量。残差平方和（SSR）是$\\sum_{k=1}^{N}\\hat{e}(k)^{2}$，其中$\\hat{e}(k)=y(k)-\\varphi(k)^{\\top}\\hat{\\theta}_{N}$。一个朴素的估计量$\\frac{1}{N}\\sum_{k=1}^{N}\\hat{e}(k)^{2}$是有偏的。无偏估计量对从数据中估计的参数数量$n_{p}$进行了校正。SSR的期望是$\\mathbb{E}\\big[\\sum_{k=1}^{N}\\hat{e}(k)^{2}\\big] = (N-n_{p})\\sigma_{e}^{2}$。这是线性回归理论中的一个标准结果，其中$n_{p}$表示拟合模型参数所消耗的自由度。因此，$\\sigma_{e}^{2}$的一个无偏估计量是：\n$$\n\\hat{\\sigma}_{e}^{2} \\;=\\; \\frac{1}{N-n_{p}}\\sum_{k=1}^{N}\\hat{e}(k)^{2}\n$$\n\n第2部分：数值计算。\n\n我们已知以下数值：\n样本数$N=1000$。\n参数数量$n_{p}=3$。\n残差平方和$\\sum_{k=1}^{N}\\hat{e}(k)^{2} = 997$。\n回归量协方差矩阵给定为：\n$$\nR_{\\varphi} \\;=\\;\n\\begin{pmatrix}\n2.0  0.5  0.0\\\\\n0.5  1.5  0.2\\\\\n0.0  0.2  3.0\n\\end{pmatrix}\n$$\n首先，我们使用上面推导的公式计算噪声方差$\\sigma_{e}^{2}$的无偏估计：\n$$\n\\hat{\\sigma}_{e}^{2} \\;=\\; \\frac{\\sum_{k=1}^{N}\\hat{e}(k)^{2}}{N-n_{p}} \\;=\\; \\frac{997}{1000-3} \\;=\\; \\frac{997}{997} \\;=\\; 1\n$$\n现在，我们计算渐近协方差矩阵$\\Sigma_{\\theta} = \\hat{\\sigma}_{e}^{2}R_{\\varphi}^{-1} = 1 \\cdot R_{\\varphi}^{-1}$。我们需要求$R_{\\varphi}$的逆矩阵。对于一个$3 \\times 3$矩阵$A$，其逆矩阵为$A^{-1} = \\frac{1}{\\det(A)}\\text{adj}(A)$。\n$R_{\\varphi}$的行列式为：\n$$\n\\det(R_{\\varphi}) \\;=\\; 2.0\\big((1.5)(3.0)-(0.2)(0.2)\\big) - 0.5\\big((0.5)(3.0)-(0.2)(0.0)\\big) + 0.0\\big(\\dots\\big)\n$$\n$$\n\\det(R_{\\varphi}) \\;=\\; 2.0(4.5-0.04) - 0.5(1.5) \\;=\\; 2.0(4.46) - 0.75 \\;=\\; 8.92 - 0.75 \\;=\\; 8.17\n$$\n伴随矩阵$\\text{adj}(R_{\\varphi})$是代数余子式矩阵的转置。由于$R_{\\varphi}$是对称的，其代数余子式矩阵也是对称的，因此$\\text{adj}(R_{\\varphi})$就是代数余子式矩阵本身。\n代数余子式为：\n$C_{11} = +(1.5 \\cdot 3.0 - 0.2 \\cdot 0.2) = 4.46$\n$C_{12} = -(0.5 \\cdot 3.0 - 0.2 \\cdot 0.0) = -1.5$\n$C_{13} = +(0.5 \\cdot 0.2 - 1.5 \\cdot 0.0) = 0.1$\n$C_{21} = C_{12} = -1.5$\n$C_{22} = +(2.0 \\cdot 3.0 - 0.0 \\cdot 0.0) = 6.0$\n$C_{23} = -(2.0 \\cdot 0.2 - 0.5 \\cdot 0.0) = -0.4$\n$C_{31} = C_{13} = 0.1$\n$C_{32} = C_{23} = -0.4$\n$C_{33} = +(2.0 \\cdot 1.5 - 0.5 \\cdot 0.5) = 2.75$\n所以，伴随矩阵为：\n$$\n\\text{adj}(R_{\\varphi}) \\;=\\;\n\\begin{pmatrix}\n4.46  -1.5  0.1\\\\\n-1.5  6.0  -0.4\\\\\n0.1  -0.4  2.75\n\\end{pmatrix}\n$$\n现在，我们求$R_{\\varphi}^{-1}$：\n$$\nR_{\\varphi}^{-1} \\;=\\; \\frac{1}{8.17}\n\\begin{pmatrix}\n4.46  -1.5  0.1\\\\\n-1.5  6.0  -0.4\\\\\n0.1  -0.4  2.75\n\\end{pmatrix}\n$$\n$$\nR_{\\varphi}^{-1} \\;=\\;\n\\begin{pmatrix}\n\\frac{4.46}{8.17}  \\frac{-1.5}{8.17}  \\frac{0.1}{8.17}\\\\\n\\frac{-1.5}{8.17}  \\frac{6.0}{8.17}  \\frac{-0.4}{8.17}\\\\\n\\frac{0.1}{8.17}  \\frac{-0.4}{8.17}  \\frac{2.75}{8.17}\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n0.5458996\\dots  -0.1835985\\dots  0.0122399\\dots\\\\\n-0.1835985\\dots  0.7343941\\dots  -0.0489596\\dots\\\\\n0.0122399\\dots  -0.0489596\\dots  0.3366009\\dots\n\\end{pmatrix}\n$$\n将每个元素四舍五入到四位有效数字，得到$\\Sigma_{\\theta}$的最终矩阵：\n$$\n\\Sigma_{\\theta} \\;=\\;\n\\begin{pmatrix}\n0.5459  -0.1836  0.01224\\\\\n-0.1836  0.7344  -0.04896\\\\\n0.01224  -0.04896  0.3366\n\\end{pmatrix}\n$$\n这就是渐近协方差矩阵的最终数值结果。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.5459  -0.1836  0.01224 \\\\\n-0.1836  0.7344  -0.04896 \\\\\n0.01224  -0.04896  0.3366\n\\end{pmatrix}\n}\n$$", "id": "2751642"}, {"introduction": "当噪声项存在自相关时，需要使用更通用的模型，例如ARMAX模型。与ARX不同，ARMAX模型的估计通常涉及对预测误差准则的迭代优化。本练习聚焦于这一过程的核心计算步骤：针对一组给定的模型参数，如何通过级联滤波器的思想高效地计算一步预测误差序列，这正是现代系统辨识软件工具箱中实现的核心算法。[@problem_id:2751638]", "problem": "考虑一个由下式给出的标量、离散时间、线性时不变系统的带有外生输入的自回归移动平均 (ARMAX) 模型\n$$\nA(q^{-1})\\,y(t) \\;=\\; B(q^{-1})\\,q^{-n_k}\\,u(t) \\;+\\; C(q^{-1})\\,e(t),\n$$\n其中 $q^{-1}$ 是后向移位算子，$A(q^{-1}) = 1 + a_{1} q^{-1} + \\cdots + a_{n_a} q^{-n_a}$ 和 $C(q^{-1}) = 1 + c_{1} q^{-1} + \\cdots + c_{n_c} q^{-n_c}$ 是首一稳定多项式，其所有零点都严格位于单位圆内，$B(q^{-1}) = b_{1} q^{-1} + \\cdots + b_{n_b} q^{-n_b}$ 是一个不含常数项的多项式，而 $n_k \\in \\mathbb{Z}_{\\ge 0}$ 是一个已知的输入延迟。给定一个有限数据集 $\\{u(t),y(t)\\}_{t=1}^{N}$ 和一个初始参数向量 $\\theta^{(0)} = \\{a_i^{(0)}\\}_{i=1}^{n_a} \\cup \\{b_j^{(0)}\\}_{j=1}^{n_b} \\cup \\{c_\\ell^{(0)}\\}_{\\ell=1}^{n_c}$，使得 $A(\\cdot)$ 和 $C(\\cdot)$ 如上所述是可逆的。\n\n从上述定义方程以及线性时不变滤波和移位算子的基本性质出发，完成以下任务：\n\n- 构建一种计算方法，在给定 $\\theta^{(0)}$ 的情况下，通过级联稳定的因果滤波器和移位，生成所有 $t \\in \\{1,\\dots,N\\}$ 的单步预测误差 $\\varepsilon(t,\\theta^{(0)})$，而无需构建任何稠密回归矩阵或通过多项式长除法执行任何显式反卷积。\n- 在一个成本模型下，该模型只计算标量乘法，将加/减法和内存访问视为无成本，并且每个因果滤波器都以直接形式实现，具有与 $t$ 无关的固定循环边界，推导出计算 $\\{\\varepsilon(t,\\theta^{(0)})\\}_{t=1}^{N}$ 所需的标量乘法总数的精确表达式，作为 $N$、$n_a$、$n_b$ 和 $n_c$ 的函数。假设在测量窗口之外的初始条件为零，并且不执行与 $A(\\cdot)$ 和 $C(\\cdot)$ 中首一系数（即系数 1）的乘法。\n\n请以 $N$、$n_a$、$n_b$ 和 $n_c$ 的单一闭式表达式形式提供最终结果。不需要进行数值计算或四舍五入。最终答案必须仅为该表达式。", "solution": "问题要求为带有外生输入的自回归移动平均 (ARMAX) 模型构建一种计算单步预测误差的方法，并推导其以标量乘法计的计算成本。本分析将从第一性原理出发。\n\nARMAX 模型由以下方程给出：\n$$\nA(q^{-1})\\,y(t) \\;=\\; B(q^{-1})\\,q^{-n_k}\\,u(t) \\;+\\; C(q^{-1})\\,e(t)\n$$\n其中 $y(t)$ 是系统输出，$u(t)$ 是外生输入，$e(t)$ 是一个白噪声序列。多项式 $A(q^{-1})$、$B(q^{-1})$ 和 $C(q^{-1})$ 定义如下：\n$$\nA(q^{-1}) = 1 + a_{1} q^{-1} + \\cdots + a_{n_a} q^{-n_a}\n$$\n$$\nB(q^{-1}) = b_{1} q^{-1} + \\cdots + b_{n_b} q^{-n_b}\n$$\n$$\nC(q^{-1}) = 1 + c_{1} q^{-1} + \\cdots + c_{n_c} q^{-n_c}\n$$\n单步预测误差，记作 $\\varepsilon(t, \\theta)$，是使用给定参数向量 $\\theta$ 计算出的新息 $e(t)$ 的值。对于本问题，我们使用指定的初始参数向量 $\\theta^{(0)}$。为了在推导中简化符号，我们将用 $\\varepsilon(t)$ 表示 $\\varepsilon(t, \\theta^{(0)})$，并使用来自 $\\theta^{(0)}$ 的系数 $\\{a_i\\}, \\{b_j\\}, \\{c_\\ell\\}$。\n\n为了找到 $\\varepsilon(t)$ 的表达式，我们重排模型方程以求解 $e(t)$:\n$$\nC(q^{-1})\\,e(t) \\;=\\; A(q^{-1})\\,y(t) \\;-\\; B(q^{-1})\\,q^{-n_k}\\,u(t)\n$$\n问题陈述多项式 $C(q^{-1})$ 是稳定的，这意味着其所有根都严格位于单位圆内。这保证了其逆 $C(q^{-1})^{-1}$ 表示一个稳定且因果的线性时不变滤波器。因此，我们可以正式地写出：\n$$\n\\varepsilon(t) = e(t) = \\frac{1}{C(q^{-1})} \\left( A(q^{-1})\\,y(t) - B(q^{-1})\\,q^{-n_k}\\,u(t) \\right)\n$$\n这个表达式将 $\\varepsilon(t)$ 的计算描述为一个滤波操作。问题指定了一种基于级联稳定滤波器的方法。该表达式的一种直接且计算高效的实现方式是，首先计算括号内的信号，然后应用滤波器 $1/C(q^{-1})$。这利用了算子的线性性质来避免冗余计算，特别是避免了将滤波器 $1/C(q^{-1})$ 分别应用于 $y(t)$ 和 $u(t)$。\n\n该计算方法被构造为一个两阶段的级联：\n阶段1：计算一个中间信号，我们称之为 $v(t)$，它是将 FIR 滤波器 $A(q^{-1})$ 和 $B(q^{-1})$ 分别应用于信号 $y(t)$ 和 $u(t-n_k)$ 的结果。\n$$\nv(t) = A(q^{-1})\\,y(t) - B(q^{-1})\\,u(t-n_k)\n$$\n阶段2：通过将 IIR 滤波器 $1/C(q^{-1})$ 应用于中间信号 $v(t)$ 来计算预测误差 $\\varepsilon(t)$。\n$$\n\\varepsilon(t) = \\frac{1}{C(q^{-1})} v(t)\n$$\n我们现在将这两个阶段展开为其显式的递归形式，以分析计算成本。\n\n对于阶段1，我们展开多项式算子：\n$$\nv(t) = \\left(1 + \\sum_{i=1}^{n_a} a_i q^{-i}\\right) y(t) - \\left(\\sum_{j=1}^{n_b} b_j q^{-j}\\right) u(t-n_k)\n$$\n应用后向移位算子 $q^{-k}x(t) = x(t-k)$ 的定义，我们得到 $v(t)$ 的计算公式：\n$$\nv(t) = y(t) + \\sum_{i=1}^{n_a} a_i y(t-i) - \\sum_{j=1}^{n_b} b_j u(t-n_k-j)\n$$\n对于阶段2，关系式 $\\varepsilon(t) = v(t)/C(q^{-1})$ 等价于 $C(q^{-1})\\varepsilon(t) = v(t)$。将其展开得到：\n$$\n\\left(1 + \\sum_{\\ell=1}^{n_c} c_\\ell q^{-\\ell}\\right) \\varepsilon(t) = v(t)\n$$\n求解 $\\varepsilon(t)$ 得到第二阶段的递归公式：\n$$\n\\varepsilon(t) = v(t) - \\sum_{\\ell=1}^{n_c} c_\\ell \\varepsilon(t-\\ell)\n$$\n现在，我们根据所提供的仅计算标量乘法的模型来确定计算成本。我们假设对于 $t \\le 0$ 初始条件为零，并且滤波器实现对 $t \\in \\{1, \\dots, N\\}$ 使用固定的循环边界。\n\n在每个时间步 $t$，成本如下：\n1.  **计算 $v(t)$ 的成本**：表达式为 $v(t) = y(t) + \\sum_{i=1}^{n_a} a_i y(t-i) - \\sum_{j=1}^{n_b} b_j u(t-n_k-j)$。\n    - 第一个求和 $\\sum_{i=1}^{n_a} a_i y(t-i)$ 涉及 $n_a$ 个 $a_i \\times y(t-i)$ 形式的乘积。这需要 $n_a$ 次标量乘法。$y(t)$ 项对应于 $A(q^{-1})$ 的首一部分，根据规则，乘以 1 的操作不计入。\n    - 第二个求和 $\\sum_{j=1}^{n_b} b_j u(t-n_k-j)$ 涉及 $n_b$ 个 $b_j \\times u(t-n_k-j)$ 形式的乘积。这需要 $n_b$ 次标量乘法。\n    计算 $v(t)$ 的总乘法次数为 $n_a + n_b$。\n\n2.  **计算 $\\varepsilon(t)$ 的成本**：表达式为 $\\varepsilon(t) = v(t) - \\sum_{\\ell=1}^{n_c} c_\\ell \\varepsilon(t-\\ell)$。\n    - 求和 $\\sum_{\\ell=1}^{n_c} c_\\ell \\varepsilon(t-\\ell)$ 涉及 $n_c$ 个 $c_\\ell \\times \\varepsilon(t-\\ell)$ 形式的乘积。这需要 $n_c$ 次标量乘法。$v(t)$ 项与 $C(q^{-1})$ 的首一部分相关，在此步骤中不涉及乘法。\n    从 $v(t)$ 计算 $\\varepsilon(t)$ 的总乘法次数为 $n_c$。\n\n每个时间步 $t$ 的标量乘法总数是两个阶段成本的总和：\n$$\n\\text{每步乘法次数} = (n_a + n_b) + n_c = n_a + n_b + n_c\n$$\n对于从 $t=1$ 到 $t=N$ 的每个时间步，此成本是恒定的，因为问题指定了滤波器实现的固定循环边界。输入延迟 $n_k$ 影响使用 $u(t)$ 的哪些数据点，但不会改变乘法的次数。\n\n为了找到计算整个序列 $\\{\\varepsilon(t)\\}_{t=1}^{N}$ 所需的标量乘法总数，我们将每步成本乘以总步数 $N$。\n$$\n\\text{总乘法次数} = N \\times (n_a + n_b + n_c)\n$$\n这是总计算成本的最终闭式表达式。", "answer": "$$\n\\boxed{N (n_a + n_b + n_c)}\n$$", "id": "2751638"}, {"introduction": "系统辨识不仅是被动地分析已有数据，更可以主动地设计实验以获取信息最丰富的数据。本练习将探讨实验设计的基本思想，即选择合适的输入信号以最大化关于未知参数的信息。你将使用Cramér-Rao下界和Fisher信息矩阵来寻找最优的输入信号频率，从而最小化特定参数的估计方差，这揭示了输入信号设计在辨识精度中的关键作用。[@problem_id:2751657]", "problem": "考虑一个单输入单输出离散时间自回归外源输入 (ARX) 模型\n$$\ny(t) = -a\\,y(t-1) + b_{0}\\,u(t) + b_{1}\\,u(t-1) + e(t),\n$$\n其中 $a$ 已知，$b_{0}$ 和 $b_{1}$ 是待估计的未知常数，$\\{e(t)\\}$ 是一个独立同分布的零均值高斯随机变量序列，其方差为 $\\sigma^{2}$。您可以设计输入 $u(t)$，但需满足以下约束：$u(t)$ 是一个单谐波\n$$\nu(t) = A \\cos\\!\\big(\\omega t + \\phi\\big),\n$$\n其相位 $\\phi$ 任意，且其长期平均功率等于一个指定的常数 $P>0$，即，\n$$\n\\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{t=1}^{N} u(t)^{2} = P.\n$$\n\n仅使用线性高斯回归的统计估计基本原理以及平稳正弦过程的标准性质，完成以下任务：\n\n- 从 $\\{e(t)\\}$ 的对数似然定义和含高斯噪声的参数线性模型中参数的费雪信息出发，在给定的功率约束下，推导当 $b_{0}$ 和 $b_{1}$ 被联合估计时，$b_{1}$ 的任何无偏估计量方差的渐近克拉默-拉奥下界，作为 $\\omega$ 的函数。\n\n- 通过恰当选择 $u(t)$ 的频率成分，确定角频率 $\\omega^{\\star} \\in [0,\\pi]$（单位：弧度/样本）的值，以最小化该下界。\n\n请将您的最终答案表示为 $\\omega^{\\star}$ 的单一值，单位为弧度/样本。不需要提供中间表达式。答案无需四舍五入。", "solution": "所提供的问题经评估有效。它具有科学依据，提法明确，客观，并包含足够的信息以获得唯一解。该任务是系统辨识中最优实验设计的标准练习。\n\n问题要求推导最优输入频率 $\\omega^{\\star}$，该频率能最小化参数 $b_1$ 估计值方差的克拉默-拉奥下界 (CRLB)。系统由自回归外源输入 (ARX) 模型描述：\n$$\ny(t) = -a\\,y(t-1) + b_{0}\\,u(t) + b_{1}\\,u(t-1) + e(t)\n$$\n其中 $a$ 已知，$\\theta = \\begin{pmatrix} b_0 \\\\ b_1 \\end{pmatrix}$ 是未知参数向量，$e(t)$ 是均值为 $0$、方差为 $\\sigma^2$ 的独立同分布 (i.i.d.) 高斯随机变量。\n\n首先，我们重排模型方程以分离出包含未知参数的项。由于 $a$ 是已知的，我们可以定义一个新信号 $y_f(t) = y(t) + a\\,y(t-1)$。这个信号可以由时刻 $t$ 和 $t-1$ 的测量值 $y(t)$ 计算得出。模型于是变为：\n$$\ny_f(t) = b_{0}\\,u(t) + b_{1}\\,u(t-1) + e(t)\n$$\n这是一个标准线性回归模型，形式为 $z(t) = \\varphi(t)^T \\theta + e(t)$，其中观测值为 $z(t) = y_f(t)$，回归向量为 $\\varphi(t) = \\begin{pmatrix} u(t) \\\\ u(t-1) \\end{pmatrix}$，参数向量为 $\\theta = \\begin{pmatrix} b_0 \\\\ b_1 \\end{pmatrix}$。\n\n对于一个具有独立同分布高斯噪声 $e(t) \\sim \\mathcal{N}(0, \\sigma^2)$ 的线性模型，其 $N$ 个观测值的对数似然函数为：\n$$\n\\ln L(\\theta) = -\\frac{N}{2} \\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{t=1}^{N} (y_f(t) - \\varphi(t)^T \\theta)^2\n$$\n$\\theta$ 的费雪信息矩阵 (FIM) 由 $I_N(\\theta) = -E\\left[ \\frac{\\partial^2 \\ln L(\\theta)}{\\partial \\theta \\partial \\theta^T} \\right]$ 给出。其二阶导数为：\n$$\n\\frac{\\partial^2 \\ln L(\\theta)}{\\partial \\theta \\partial \\theta^T} = -\\frac{1}{\\sigma^2} \\sum_{t=1}^{N} \\varphi(t)\\varphi(t)^T\n$$\n由于该表达式不依赖于数据 $y_f(t)$，期望算子没有影响。对于 $N$ 个样本，费雪信息矩阵为 $I_N(\\theta) = \\frac{1}{\\sigma^2} \\sum_{t=1}^{N} \\varphi(t)\\varphi(t)^T$。每个样本归一化后的渐近费雪信息矩阵为：\n$$\n\\bar{I}(\\theta) = \\lim_{N\\to\\infty} \\frac{1}{N} I_N(\\theta) = \\frac{1}{\\sigma^2} \\lim_{N\\to\\infty} \\frac{1}{N} \\sum_{t=1}^{N} \\varphi(t)\\varphi(t)^T\n$$\n该矩阵项是回归向量的渐近协方差矩阵，$\\bar{R}_{\\varphi\\varphi} = \\lim_{N\\to\\infty} \\frac{1}{N} \\sum_{t=1}^{N} \\varphi(t)\\varphi(t)^T$。当 $\\varphi(t) = \\begin{pmatrix} u(t) \\\\ u(t-1) \\end{pmatrix}$ 时，此矩阵为：\n$$\n\\bar{R}_{\\varphi\\varphi} = \\begin{pmatrix} \\lim_{N\\to\\infty} \\frac{1}{N}\\sum u(t)^2  \\lim_{N\\to\\infty} \\frac{1}{N}\\sum u(t)u(t-1) \\\\ \\lim_{N\\to\\infty} \\frac{1}{N}\\sum u(t)u(t-1)  \\lim_{N\\to\\infty} \\frac{1}{N}\\sum u(t-1)^2 \\end{pmatrix} = \\begin{pmatrix} R_u(0)  R_u(1) \\\\ R_u(1)  R_u(0) \\end{pmatrix}\n$$\n其中 $R_u(k)$ 是输入信号 $u(t)$ 的时间自相关函数。\n\n输入信号为 $u(t) = A \\cos(\\omega t + \\phi)$。其平均功率被约束为 $P$。\n根据定义，$R_u(0)$ 项是平均功率，所以 $R_u(0) = P$。\n我们必须找到振幅 $A$ 和功率 $P$ 之间的关系。对于一个离散时间正弦波，其长期平均功率为：\n$$\nP = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{t=1}^{N} A^2 \\cos^2(\\omega t + \\phi) = \\lim_{N \\to \\infty} \\frac{A^2}{N} \\sum_{t=1}^{N} \\frac{1 + \\cos(2\\omega t + 2\\phi)}{2}\n$$\n对于 $\\omega \\in (0,\\pi)$，余弦项的时间平均值为零。因此，$P = \\frac{A^2}{2}$。\n接下来，我们计算 $R_u(1)$：\n$$\nR_u(1) = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{t=1}^{N} A \\cos(\\omega t + \\phi) \\cdot A \\cos(\\omega(t-1) + \\phi)\n$$\n使用恒等式 $\\cos(X)\\cos(Y) = \\frac{1}{2}(\\cos(X-Y)+\\cos(X+Y))$，我们得到：\n$$\nu(t)u(t-1) = \\frac{A^2}{2} [ \\cos(\\omega) + \\cos(2\\omega t - \\omega + 2\\phi) ]\n$$\n取时间平均值，并再次注意到对于 $\\omega \\in (0, \\pi)$，时变余弦项的平均值为零，我们发现：\n$$\nR_u(1) = \\frac{A^2}{2} \\cos(\\omega)\n$$\n代入 $A^2 = 2P$，我们得到 $R_u(1) = P \\cos(\\omega)$。\n\n因此，对于 $\\omega \\in (0, \\pi)$，回归向量的协方差矩阵为：\n$$\n\\bar{R}_{\\varphi\\varphi} = \\begin{pmatrix} P  P\\cos(\\omega) \\\\ P\\cos(\\omega)  P \\end{pmatrix} = P \\begin{pmatrix} 1  \\cos(\\omega) \\\\ \\cos(\\omega)  1 \\end{pmatrix}\n$$\n渐近费雪信息矩阵是：\n$$\n\\bar{I}(\\theta) = \\frac{P}{\\sigma^2} \\begin{pmatrix} 1  \\cos(\\omega) \\\\ \\cos(\\omega)  1 \\end{pmatrix}\n$$\n克拉默-拉奥定理指出，任何无偏估计量 $\\hat{\\theta}$ 的协方差矩阵都受限于费雪信息矩阵的逆。缩放后协方差的渐近下界是 $\\bar{I}(\\theta)^{-1}$。我们计算这个逆矩阵：\n$$\n\\bar{I}(\\theta)^{-1} = \\left( \\frac{P}{\\sigma^2} \\right)^{-1} \\frac{1}{1 - \\cos^2(\\omega)} \\begin{pmatrix} 1  -\\cos(\\omega) \\\\ -\\cos(\\omega)  1 \\end{pmatrix} = \\frac{\\sigma^2}{P \\sin^2(\\omega)} \\begin{pmatrix} 1  -\\cos(\\omega) \\\\ -\\cos(\\omega)  1 \\end{pmatrix}\n$$\n该矩阵必须是正定的，这要求其行列式为正。这意味着 $P^2(1-\\cos^2\\omega) > 0$，所以 $\\sin^2(\\omega) \\neq 0$，即 $\\omega \\neq 0$ 且 $\\omega \\neq \\pi$。在这些边界频率上，回归量 $u(t)$ 和 $u(t-1)$ 变得线性相关，费雪信息矩阵变为奇异矩阵，参数不可辨识，从而导致无穷大的估计方差。\n\n$b_1$ 估计量方差的 CRLB，记为 $\\text{var}(\\hat{b}_1)$，由矩阵 $\\frac{1}{N} \\bar{I}(\\theta)^{-1}$ 的 $(2,2)$ 元素给出。此下界中依赖于 $\\omega$ 的渐近部分为：\n$$\nV(\\omega) = \\left[ \\bar{I}(\\theta)^{-1} \\right]_{22} = \\frac{\\sigma^2}{P \\sin^2(\\omega)}\n$$\n为了优化实验设计，我们必须关于 $\\omega \\in (0, \\pi)$ 最小化函数 $V(\\omega)$。项 $\\sigma^2$ 和 $P$ 是正常数。因此，最小化 $V(\\omega)$ 等价于最大化其分母 $\\sin^2(\\omega)$。\n函数 $f(\\omega) = \\sin^2(\\omega)$ 在区间 $\\omega \\in (0, \\pi)$ 上的唯一最大值在 $\\sin(\\omega)$ 取最大值时达到。$\\sin(\\omega)$ 的最大值为 $1$，这发生在 $\\omega = \\frac{\\pi}{2}$ 时。\n\n因此，最小化 $b_1$ 估计方差界的最优频率 $\\omega^{\\star}$ 是 $\\frac{\\pi}{2}$ 弧度/样本。在此频率下，回归量 $u(t)$ 和 $u(t-1)$ 是正交的，从而将 $b_0$ 和 $b_1$ 的估计解耦，并获得最佳精度。", "answer": "$$\n\\boxed{\\frac{\\pi}{2}}\n$$", "id": "2751657"}]}