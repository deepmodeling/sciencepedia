{"hands_on_practices": [{"introduction": "精确的测量是科学研究的基石，而在原子力显微镜（AFM）中，对光电二极管电压与悬臂梁偏转之间关系的校准是一项至关重要的常规任务。本练习将引导你超越简单的线性拟合，进入贝叶斯推断的框架，从而不仅能找到最可能的校准灵敏度，还能严格地量化其不确定性。通过这项实践，你将掌握如何实现贝叶斯线性回归，并将其应用于真实的仪器校准问题，包括在更换悬臂梁等条件变化时，如何传递并评估不确定性。[@problem_id:2777620]", "problem": "原子力显微镜（AFM）的偏转灵敏度校准，是将在刚性参考表面上光电二极管电压与垂直压电位移关联起来的过程。您将使用带有已知高斯噪声的贝叶斯线性回归构建概率校准曲线，然后量化从源悬臂切换到目标悬臂时的校准传递不确定性。建模假设和任务如下。\n\n建模假设：\n- 测量模型是线性的：表面接近位移（单位为纳米，记作 $z$，单位 $\\mathrm{nm}$）与光电二极管电压（单位为伏特，记作 $V$，单位 $\\mathrm{V}$）通过 $z = \\alpha + \\beta V + \\epsilon$ 相关联，其中 $\\epsilon$ 是已知的加性零均值高斯噪声，其方差为 $\\sigma^2$，单位为 $\\mathrm{nm}^2$。这里，$\\alpha$ 是截距，单位为 $\\mathrm{nm}$，$\\beta$ 是偏转灵敏度，单位为 $\\mathrm{nm/V}$。\n- 对 $\\theta = [\\alpha,\\beta]^T$ 设置高斯先验：$\\theta \\sim \\mathcal{N}(m_0, V_0)$，其中 $m_0 \\in \\mathbb{R}^2$ 且 $V_0 \\in \\mathbb{R}^{2 \\times 2}$ 为正定矩阵。\n- 切换悬臂时，目标悬臂的参数 $\\theta_t$ 被建模为源悬臂后验参数 $\\theta_s$ 的高斯扰动：$\\theta_t = \\theta_s + \\delta$，其中 $\\delta \\sim \\mathcal{N}(0, T)$ 且 $T \\in \\mathbb{R}^{2 \\times 2}$ 为半正定矩阵。这意味着目标悬臂的传递先验为 $\\theta_t \\sim \\mathcal{N}(m_s, V_s + T)$，其中 $(m_s, V_s)$ 是源的后验均值和协方差。\n\n每个测试用例的计算任务：\n1. 使用指定的先验和提供的源数据集 $(V_s, z_s)$ 计算 $(\\alpha,\\beta)$ 的后验均值和协方差，从而构建源悬臂的校准曲线。报告 $\\beta$ 的后验均值（单位 $\\mathrm{nm/V}$）作为校准曲线的源偏转灵敏度估计值。\n2. 对于目标悬臂，使用传递先验 $\\mathcal{N}(m_s, V_s + T)$ 和目标数据集 $(V_t, z_t)$ 来计算后验。对于每个指定的查询电压 $V^\\star$，计算 $z$ 的后验预测均值（单位 $\\mathrm{nm}$）。\n3. 按如下方式量化每个 $V^\\star$ 处的校准传递不确定性。令 $\\mathrm{Var}_T(z^\\star)$ 为在 $V^\\star$ 处使用包含切换协方差 $T$ 的传递先验计算出的后验预测方差，令 $\\mathrm{Var}_0(z^\\star)$ 为使用相同的目标数据但将 $T$ 设置为零矩阵（即无切换不确定性，使用源后验作为先验）计算出的后验预测方差。将校准传递不确定性定义为\n$U(V^\\star) = \\sqrt{\\max\\{0, \\mathrm{Var}_T(z^\\star) - \\mathrm{Var}_0(z^\\star)\\}}$（单位 $\\mathrm{nm}$）。\n\n您的程序必须使用任何现代编程语言实现上述内容，并使用以下测试套件和参数。将已知噪声标准差 $\\sigma$ 视为每个案例的指定值。所有案例均使用相同的先验 $(m_0, V_0)$。所有数组都已明确给出，必须按原样使用，不得修改。\n\n所有案例的通用先验：\n- $m_0 = [0.0, 40.0]^T$\n- $V_0 = \\mathrm{diag}([100.0, 100.0])$\n\n测试用例 1：\n- 源数据 $(V_s, z_s)$:\n  - $V_s = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]$（单位 $\\mathrm{V}$）\n  - $z_s = [0.52, 10.02, 19.75, 29.27, 38.94, 48.48]$（单位 $\\mathrm{nm}$）\n- 目标数据 $(V_t, z_t)$:\n  - $V_t = [0.15, 0.5, 0.9]$（单位 $\\mathrm{V}$）\n  - $z_t = [7.76, 25.32, 45.29]$（单位 $\\mathrm{nm}$）\n- 已知噪声：$\\sigma = 0.3$（单位 $\\mathrm{nm}$）\n- 切换协方差 $T = \\mathrm{diag}([0.5^2, 3.0^2])$，单位为 $\\mathrm{nm}^2$ 和 $(\\mathrm{nm/V})^2$\n- 查询电压：$V^\\star \\in \\{0.3, 1.2\\}$（单位 $\\mathrm{V}$）\n\n测试用例 2：\n- 源数据 $(V_s, z_s)$:\n  - $V_s = [0.0, 0.5, 1.0, 1.5]$（单位 $\\mathrm{V}$）\n  - $z_s = [0.01, 7.52, 15.02, 22.57]$（单位 $\\mathrm{nm}$）\n- 目标数据 $(V_t, z_t)$:\n  - $V_t = [0.2]$（单位 $\\mathrm{V}$）\n  - $z_t = [3.02]$（单位 $\\mathrm{nm}$）\n- 已知噪声：$\\sigma = 0.2$（单位 $\\mathrm{nm}$）\n- 切换协方差 $T = \\mathrm{diag}([0.2^2, 1.5^2])$\n- 查询电压：$V^\\star \\in \\{0.2, 1.0\\}$（单位 $\\mathrm{V}$）\n\n测试用例 3：\n- 源数据 $(V_s, z_s)$:\n  - $V_s = [0.0, 0.25, 0.5, 0.75]$（单位 $\\mathrm{V}$）\n  - $z_s = [-1.00, 12.70, 26.56, 40.21]$（单位 $\\mathrm{nm}$）\n- 目标数据 $(V_t, z_t)$:\n  - $V_t = [0.1, 0.7]$（单位 $\\mathrm{V}$）\n  - $z_t = [5.53, 41.48]$（单位 $\\mathrm{nm}$）\n- 已知噪声：$\\sigma = 0.25$（单位 $\\mathrm{nm}$）\n- 切换协方差 $T = \\mathrm{diag}([0.8^2, 5.0^2])$\n- 查询电压：$V^\\star \\in \\{0.0, 0.5, 1.0\\}$（单位 $\\mathrm{V}$）\n\n要求的输出和单位：\n- 对于每个测试用例，输出一个列表，其第一个元素是源偏转灵敏度 $\\beta$ 的后验均值（单位 $\\mathrm{nm/V}$），其后是针对每个 $V^\\star$ 的 $z$ 的后验预测均值（单位 $\\mathrm{nm}$）和校准传递不确定性 $U(V^\\star)$（单位 $\\mathrm{nm}$）的配对，顺序与上面提供的 $V^\\star$值的顺序相同。\n- 所有数值输出必须以指定的单位表示，并精确到六位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例对应一个如上所述的、用方括号括起来的逗号分隔子列表。例如：“[[case1_item1,case1_item2,...],[case2_item1,...],[case3_item1,...]]”。确保每个浮点数小数点后正好有六位数字。", "solution": "所提出的问题是应用贝叶斯统计学中一个标准的、适定的练习，具体涉及线性回归。它在纳米力学领域原子力显微镜的校准方面有坚实的科学基础。我们将按规范的解法进行。\n\n问题的核心在于将贝叶斯推断应用于线性模型。光电二极管电压 $V$ 和压电位移 $z$ 之间的关系由以下线性方程给出：\n$$\nz = \\alpha + \\beta V + \\epsilon\n$$\n其中 $\\theta = [\\alpha, \\beta]^T$ 是模型参数（截距和灵敏度），$\\epsilon$ 是加性高斯噪声，其均值为零，方差 $\\sigma^2$ 已知，即 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n这可以用矩阵表示法表达。对于一组 $N$ 个观测值 $(V_i, z_i)$，我们可以写成 $z_i = \\phi_i^T \\theta + \\epsilon_i$，其中 $\\phi_i = [1, V_i]^T$。整个数据集 $D = \\{(V_i, z_i)\\}_{i=1}^N$ 的似然函数为：\n$$\np(z | \\theta, X, \\sigma^2) = (2\\pi\\sigma^2)^{-N/2} \\exp\\left(-\\frac{1}{2\\sigma^2}(z - X\\theta)^T(z - X\\theta)\\right)\n$$\n其中 $z = [z_1, ..., z_N]^T$ 是位移测量值的向量，$X$ 是一个 $N \\times 2$ 的设计矩阵，其行向量为 $\\phi_i^T$。\n\n参数 $\\theta$ 服从高斯先验分布 $\\theta \\sim \\mathcal{N}(m_0, V_0)$。根据贝叶斯定理，后验分布与似然函数和先验分布的乘积成正比：$p(\\theta|D) \\propto p(z|\\theta)p(\\theta)$。对于共轭的高斯先验和似然函数，$\\theta$ 的后验分布也是高斯分布，即 $\\theta | D \\sim \\mathcal{N}(m_N, V_N)$，其后验均值 $m_N$ 和协方差 $V_N$ 由以下公式给出：\n$$\nV_N = \\left( V_0^{-1} + \\frac{1}{\\sigma^2} X^T X \\right)^{-1}\n$$\n$$\nm_N = V_N \\left( V_0^{-1} m_0 + \\frac{1}{\\sigma^2} X^T z \\right)\n$$\n这些公式提供了在观测数据后更新我们对参数 $\\theta$ 的信念的机制。\n\n计算任务按如下步骤执行：\n\n1.  **源悬臂校准**：我们首先计算源悬臂参数 $\\theta_s = [\\alpha_s, \\beta_s]^T$ 的后验分布。我们使用指定的通用先验 $(m_0, V_0)$ 和源数据集 $(V_s, z_s)$。我们从 $V_s$ 构建源设计矩阵 $X_s$，并应用更新方程来找到源后验均值 $m_s$ 和协方差 $V_s$。估计的源偏转灵敏度是后验均值向量 $m_s$ 的第二个分量。\n\n2.  **目标悬臂后验预测均值**：切换到目标悬臂时，假定其参数是源参数的扰动。这通过目标参数 $\\theta_t$ 的一个传递先验来建模：\n    $$\n    \\theta_t \\sim \\mathcal{N}(m_s, V_s + T)\n    $$\n    其中 $T$ 是指定的切换协方差矩阵。然后使用目标数据集 $(V_t, z_t)$ 更新这个新的先验，以获得目标后验分布 $\\theta_t | D_t \\sim \\mathcal{N}(m_t, V_t)$。对于一个新的查询电压 $V^\\star$，我们构建一个设计向量 $\\phi^\\star = [1, V^\\star]^T$。相应位移 $z^\\star$ 的后验预测分布是一个高斯分布。其均值，即我们的预测值，由下式给出：\n    $$\n    E[z^\\star | D_t, V^\\star] = (\\phi^\\star)^T m_t\n    $$\n\n3.  **校准传递不确定性**：此量度量了由悬臂切换过程引入的额外不确定性，该不确定性由矩阵 $T$ 捕捉。我们在两种条件下计算 $z^\\star$ 的后验预测方差。\n    首先，在使用包含 $T$ 的完整传递先验时，方差为：\n    $$\n    \\mathrm{Var}_T(z^\\star) = \\sigma^2 + (\\phi^\\star)^T V_t \\phi^\\star\n    $$\n    此处，$V_t$ 是使用先验协方差 $V_s + T$ 计算出的目标后验协方差。$\\sigma^2$ 项表示新测量的观测噪声。\n    其次，我们通过将 $T$ 设置为零矩阵来计算基线方差 $\\mathrm{Var}_0(z^\\star)$。这对应于切换没有带来额外不确定性的情况；源后验直接用作目标的先验。此计算产生一个不同的目标后验协方差，我们称之为 $V_{t,0}$，方差为：\n    $$\n    \\mathrm{Var}_0(z^\\star) = \\sigma^2 + (\\phi^\\star)^T V_{t,0} \\phi^\\star\n    $$\n    校准传递不确定性随后定义并计算为：\n    $$\n    U(V^\\star) = \\sqrt{\\max\\{0, \\mathrm{Var}_T(z^\\star) - \\mathrm{Var}_0(z^\\star)\\}} = \\sqrt{\\max\\{0, (\\phi^\\star)^T (V_t - V_{t,0}) \\phi^\\star\\}}\n    $$\n实现将针对每个指定的测试用例系统地应用这些矩阵计算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the AFM calibration problem using Bayesian linear regression\n    for the provided test cases.\n    \"\"\"\n\n    # Common prior parameters\n    m0 = np.array([0.0, 40.0])\n    V0 = np.diag([100.0, 100.0])\n\n    test_cases = [\n        {\n            \"Vs\": np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]),\n            \"zs\": np.array([0.52, 10.02, 19.75, 29.27, 38.94, 48.48]),\n            \"Vt\": np.array([0.15, 0.5, 0.9]),\n            \"zt\": np.array([7.76, 25.32, 45.29]),\n            \"sigma\": 0.3,\n            \"T\": np.diag([0.5**2, 3.0**2]),\n            \"V_star\": [0.3, 1.2],\n        },\n        {\n            \"Vs\": np.array([0.0, 0.5, 1.0, 1.5]),\n            \"zs\": np.array([0.01, 7.52, 15.02, 22.57]),\n            \"Vt\": np.array([0.2]),\n            \"zt\": np.array([3.02]),\n            \"sigma\": 0.2,\n            \"T\": np.diag([0.2**2, 1.5**2]),\n            \"V_star\": [0.2, 1.0],\n        },\n        {\n            \"Vs\": np.array([0.0, 0.25, 0.5, 0.75]),\n            \"zs\": np.array([-1.00, 12.70, 26.56, 40.21]),\n            \"Vt\": np.array([0.1, 0.7]),\n            \"zt\": np.array([5.53, 41.48]),\n            \"sigma\": 0.25,\n            \"T\": np.diag([0.8**2, 5.0**2]),\n            \"V_star\": [0.0, 0.5, 1.0],\n        },\n    ]\n\n    def bayesian_update(prior_mean, prior_cov, V_data, z_data, sigma2):\n        \"\"\"\n        Computes the posterior mean and covariance for a linear model.\n        \"\"\"\n        X_data = np.vstack((np.ones_like(V_data), V_data)).T\n        prior_cov_inv = np.linalg.inv(prior_cov)\n        \n        # Posterior covariance\n        post_cov_inv = prior_cov_inv + (1.0 / sigma2) * X_data.T @ X_data\n        post_cov = np.linalg.inv(post_cov_inv)\n        \n        # Posterior mean\n        post_mean = post_cov @ (prior_cov_inv @ prior_mean + (1.0 / sigma2) * X_data.T @ z_data)\n        \n        return post_mean, post_cov\n\n    all_results = []\n    for case in test_cases:\n        Vs, zs = case[\"Vs\"], case[\"zs\"]\n        Vt, zt = case[\"Vt\"], case[\"zt\"]\n        sigma = case[\"sigma\"]\n        T = case[\"T\"]\n        V_star_list = case[\"V_star\"]\n        sigma2 = sigma**2\n        \n        case_outputs = []\n\n        # 1. Source cantilever calibration\n        ms_post, Vs_post = bayesian_update(m0, V0, Vs, zs, sigma2)\n        source_beta_mean = ms_post[1]\n        case_outputs.append(source_beta_mean)\n        \n        # 2.  3. Target cantilever posterior and uncertainty\n        \n        # Compute target posterior with transfer uncertainty T\n        mt_post_T, Vt_post_T = bayesian_update(ms_post, Vs_post + T, Vt, zt, sigma2)\n        \n        # Compute target posterior without transfer uncertainty (T=0)\n        # The prior covariance is just the source posterior covariance Vs_post.\n        _ , Vt_post_0 = bayesian_update(ms_post, Vs_post, Vt, zt, sigma2)\n        \n        for v_star in V_star_list:\n            phi_star = np.array([1.0, v_star])\n            \n            # Posterior predictive mean\n            pred_mean = phi_star @ mt_post_T\n            \n            # Predictive variances for uncertainty calculation\n            pred_var_T_component = phi_star.T @ Vt_post_T @ phi_star\n            pred_var_0_component = phi_star.T @ Vt_post_0 @ phi_star\n            \n            # Calibration transfer uncertainty\n            variance_diff = pred_var_T_component - pred_var_0_component\n            uncertainty = np.sqrt(max(0, variance_diff))\n            \n            case_outputs.append(pred_mean)\n            case_outputs.append(uncertainty)\n            \n        all_results.append(case_outputs)\n\n    # Format output string\n    formatted_results = []\n    for result_list in all_results:\n        formatted_list = [f\"{x:.6f}\" for x in result_list]\n        formatted_results.append(f\"[{','.join(formatted_list)}]\")\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2777620"}, {"introduction": "纳米力学中的许多现象（如摩擦）受复杂的物理机制支配，缺乏简单的解析模型，使得大规模模拟或参数优化变得不切实际。为了应对这一挑战，我们可以利用机器学习创建由数据驱动的“代理”模型，这些模型在保持高精度的同时运行速度极快。本练习将指导你使用高斯过程（GP）这一强大的非参数贝叶斯方法，来学习表面形貌与摩擦力之间的复杂映射关系，并分析模型预测对于输入参数的敏感度。[@problem_id:2777669]", "problem": "您将要完成一个代理建模任务，该任务的动因是纳米力学中正弦表面的摩擦响应。考虑一个由 $z(x) = A \\sin\\!\\left(2\\pi x / L\\right)$ 定义的一维正弦形貌，其中 $A$ 是纹理振幅，$L$ 是纹理波长。在固定的法向载荷 $N$ 下，切向摩擦力 $F$ 可以建模为 $(A, L)$ 的函数，但该映射没有已知的闭式解。在实践中，可以使用机器学习代理模型（例如高斯过程(GP)）根据训练数据从 $(A, L)$ 预测 $F$。您的任务是使用一个合成的但物理上合理的数据生成器，为 $F(A, L)$ 实现一个高斯过程代理模型，然后计算GP后验均值预测相对于 $A$ 和 $L$ 的梯度（灵敏度）。您必须使用中心有限差分法来验证这些灵敏度。\n\n在以下物理上一致的设定下工作：\n- 输入变量：纹理振幅 $A$ 和波长 $L$，单位为纳米；在进行任何计算前，内部需将其转换为米。\n- 法向载荷：$N = 10\\,\\mu\\text{N}$；内部使用 $N = 10^{-5}\\,\\text{N}$。\n- 仅用于构建训练集（不用于测试预测）的合成基准真相生成器定义为\n  $$\n  F_{\\text{true}}(A,L;N) \\;=\\; N \\left[ \\mu_0 \\;+\\; \\alpha \\,\\frac{\\left(\\dfrac{A}{L}\\right)^2}{1 + \\left(\\dfrac{A}{L_c}\\right)^2} \\;+\\; \\beta \\,\\frac{A}{A + A_0}\\,\\frac{L_{\\mathrm{ref}}}{L} \\right],\n  $$\n  其中所有量均采用国际单位制 (SI)。使用常数 $\\mu_0 = 0.2$, $\\alpha = 0.6$, $\\beta = 0.05$, $L_c = 50\\,\\text{nm}$, $A_0 = 1\\,\\text{nm}$, 以及 $L_{\\mathrm{ref}} = 100\\,\\text{nm}$。该模型反映了增加的粗糙度振幅和减小的波长倾向于增加耗散，同时在非常大的振幅尺度上达到饱和；该模型在量纲上是一致的，因为方括号中的每一项都是无量纲的，并与 $N$ 相乘。\n\n按如下方式构建高斯过程 (GP) 代理模型：\n- 使用一个带有自动相关性确定 (ARD) 平方指数协方差核的零均值GP先验\n  $$\n  k(\\mathbf{x}, \\mathbf{x}') \\;=\\; \\sigma_f^2 \\exp\\!\\left(-\\tfrac{1}{2}\\sum_{j=1}^{2}\\frac{(x_j - x_j')^2}{\\ell_j^2}\\right),\n  $$\n  其中 $\\mathbf{x} = [A, L]^\\top$，两个分量均以米为单位。使用超参数 $\\sigma_f = 2\\times 10^{-6}\\,\\text{N}$，对于 $A$ 使用 $\\ell_1 = 5\\times 10^{-9}\\,\\text{m}$，对于 $L$ 使用 $\\ell_2 = 5\\times 10^{-8}\\,\\text{m}$。向训练输出中添加标准差为 $\\sigma_n = 10^{-8}\\,\\text{N}$ 的独立高斯观测噪声。\n\n训练数据：\n- 构建一个训练输入网格 $(A, L)$，其中 $A \\in \\{2, 5, 10, 15, 18\\}\\,\\text{nm}$ 且 $L \\in \\{20, 50, 80, 120, 160\\}\\,\\text{nm}$。对于每一对，计算在 $N = 10\\,\\mu\\text{N}$ 时的无噪声 $F_{\\text{true}}$，然后将观测值建模为 $y = F_{\\text{true}}$（噪声仅通过协方差矩阵中的 $\\sigma_n$ 进入GP模型）。\n\n预测与梯度：\n- 对于一个测试输入 $\\mathbf{x}_\\star = [A_\\star, L_\\star]^\\top$（以米为单位），GP后验均值为 $m(\\mathbf{x}_\\star) = \\mathbf{k}_\\star^\\top \\mathbf{\\alpha}$，其中 $\\mathbf{k}_\\star$ 是 $\\mathbf{x}_\\star$ 与每个训练输入之间的核函数求值向量，$\\mathbf{\\alpha}$ 通过求解 $(\\mathbf{K} + \\sigma_n^2 \\mathbf{I}) \\mathbf{\\alpha} = \\mathbf{y}$ 得到，其中 $\\mathbf{K}$ 是训练核矩阵。后验均值相对于 $\\mathbf{x}_\\star$ 的梯度可以通过对核函数进行微分得到闭式解，\n  $$\n  \\nabla_{\\mathbf{x}_\\star} m(\\mathbf{x}_\\star) \\;=\\; \\sum_{i} \\alpha_i \\,\\nabla_{\\mathbf{x}_\\star} k(\\mathbf{x}_\\star,\\mathbf{x}_i),\n  $$\n  其中每个分量都使用了应用于ARD平方指数核的链式法则。您的程序必须实现这个解析梯度。\n\n通过有限差分进行验证：\n- 使用步长 $h_A = 5\\times 10^{-13}\\,\\text{m}$ 和 $h_L = 5\\times 10^{-12}\\,\\text{m}$，将解析梯度与中心有限差分 (FD) 近似进行比较验证。在FD评估中使用相同的GP后验均值 $m(\\cdot)$；不要在验证中使用基准真相生成器。通过以下方式计算有限差分梯度分量\n  $$\n  \\frac{\\partial m}{\\partial A}(\\mathbf{x}_\\star) \\approx \\frac{m([A_\\star + h_A, L_\\star]) - m([A_\\star - h_A, L_\\star])}{2 h_A},\n  $$\n  $$\n  \\frac{\\partial m}{\\partial L}(\\mathbf{x}_\\star) \\approx \\frac{m([A_\\star, L_\\star + h_L]) - m([A_\\star, L_\\star - h_L])}{2 h_L}.\n  $$\n\n测试套件：\n- 对所有测试使用法向载荷 $N = 10\\,\\mu\\text{N}$。\n- 评估解析梯度与中心有限差分梯度之间的最大分量绝对差异，\n  $$\n  \\Delta(\\mathbf{x}_\\star) \\;=\\; \\max\\!\\left(\\left|\\frac{\\partial m}{\\partial A}\\Big|_{\\text{analytic}} - \\frac{\\partial m}{\\partial A}\\Big|_{\\text{FD}}\\right|, \\left|\\frac{\\partial m}{\\partial L}\\Big|_{\\text{analytic}} - \\frac{\\partial m}{\\partial L}\\Big|_{\\text{FD}}\\right|\\right),\n  $$\n  单位为 $\\text{N}/\\text{m}$。\n- 使用以下四个测试输入，以纳米为单位给出，内部转换为米：\n  - 情况 1：$A_\\star = 8\\,\\text{nm}$, $L_\\star = 60\\,\\text{nm}$。\n  - 情况 2：$A_\\star = 1.5\\,\\text{nm}$, $L_\\star = 200\\,\\text{nm}$。\n  - 情况 3：$A_\\star = 18\\,\\text{nm}$, $L_\\star = 30\\,\\text{nm}$。\n  - 情况 4：$A_\\star = 2\\,\\text{nm}$, $L_\\star = 20\\,\\text{nm}$。\n\n要求输出：\n- 您的程序应生成单行输出，包含一个包含4个浮点值的列表，每个值等于相应测试用例的 $\\Delta(\\mathbf{x}_\\star)$，单位为 $\\text{N}/\\text{m}$。输出必须是一个用方括号括起来的逗号分隔列表，例如 $[d_1,d_2,d_3,d_4]$，其中每个 $d_i$ 是一个浮点数。", "solution": "我们从摩擦力的定义 $F_t = \\mu N$ 开始，其中 $\\mu$ 是由表面形貌、材料响应和载荷决定的有效摩擦系数，$N$ 是施加的法向载荷。对于正弦表面 $z(x) = A \\sin(2\\pi x/L)$，在纳米力学和表面科学中已经公认，增加的振幅 $A$ 和减小的波长 $L$ 通常通过增强的犁耕效应或额外的微凸体相互作用来增加摩擦耗散。这启发我们构建一个量纲一致的合成生成器 $F_{\\text{true}}(A,L;N) = N \\left[ \\mu_0 + \\alpha \\frac{(A/L)^2}{1 + (A/L_c)^2} + \\beta \\frac{A}{A + A_0}\\frac{L_{\\mathrm{ref}}}{L} \\right]$，其中方括号中的每一项都是无量纲的，$N$ 带有力的单位。我们仅使用此生成器创建训练数据；测试用例的预测由学习到的机器学习代理模型做出。\n\n为了从数据中近似未知映射 $(A, L) \\mapsto F$，我们使用高斯过程 (GP)，这是一种在函数上设置先验的贝叶斯非参数模型。在带有自动相关性确定 (ARD) 平方指数核的零均值GP先验\n$$\nk(\\mathbf{x}, \\mathbf{x}') = \\sigma_f^2 \\exp\\!\\left(-\\tfrac{1}{2}\\sum_{j=1}^{2}\\frac{(x_j - x_j')^2}{\\ell_j^2}\\right),\n$$\n以及方差为 $\\sigma_n^2$ 的独立高斯观测噪声下，训练输出 $\\mathbf{y}$ 和在测试输入 $\\mathbf{x}_\\star$ 处的函数值的联合分布是多元高斯分布。通过条件化得到后验均值（我们将用其作为点预测）\n$$\nm(\\mathbf{x}_\\star) = \\mathbf{k}_\\star^\\top \\mathbf{\\alpha}, \\quad \\text{其中} \\quad \\mathbf{\\alpha} = (\\mathbf{K} + \\sigma_n^2 \\mathbf{I})^{-1} \\mathbf{y},\n$$\n$\\mathbf{K}$ 是训练协方差矩阵，其元素为 $K_{ij} = k(\\mathbf{x}_i, \\mathbf{x}_j)$，$\\mathbf{k}_\\star$ 是元素为 $k(\\mathbf{x}_\\star, \\mathbf{x}_i)$ 的向量。我们通过对 $\\mathbf{K} + \\sigma_n^2 \\mathbf{I}$ 进行Cholesky分解，使用数值稳定的线性求解方法来计算 $\\mathbf{\\alpha}$。\n\n我们需要GP后验均值预测相对于输入的灵敏度，即 $\\nabla_{\\mathbf{x}_\\star} m(\\mathbf{x}_\\star)$。利用链式法则和微分的线性性质，并注意到 $m(\\mathbf{x}_\\star)$ 是核函数求值的线性组合，我们得到\n$$\n\\nabla_{\\mathbf{x}_\\star} m(\\mathbf{x}_\\star) = \\sum_{i} \\alpha_i \\,\\nabla_{\\mathbf{x}_\\star} k(\\mathbf{x}_\\star,\\mathbf{x}_i).\n$$\n对于ARD平方指数核，关于 $\\mathbf{x}_\\star$ 的第 $j$ 个分量的偏导数是\n$$\n\\frac{\\partial}{\\partial x_{\\star,j}} k(\\mathbf{x}_\\star,\\mathbf{x}_i) = k(\\mathbf{x}_\\star,\\mathbf{x}_i)\\left(-\\frac{x_{\\star,j} - x_{i,j}}{\\ell_j^2}\\right).\n$$\n因此，梯度是向量的加权和，这些向量的分量是上述表达式在 $j=1$（振幅 $A$）和 $j=2$（波长 $L$）时的值。\n\n为了验证解析梯度，我们将其与直接应用于GP后验均值 $m(\\cdot)$（而非基准真相）的中心有限差分 (FD) 近似进行比较。给定步长 $h_A$ 和 $h_L$，中心有限差分近似为\n$$\n\\frac{\\partial m}{\\partial A}(\\mathbf{x}_\\star) \\approx \\frac{m([A_\\star + h_A, L_\\star]) - m([A_\\star - h_A, L_\\star])}{2 h_A}, \\quad\n\\frac{\\partial m}{\\partial L}(\\mathbf{x}_\\star) \\approx \\frac{m([A_\\star, L_\\star + h_L]) - m([A_\\star, L_\\star - h_L])}{2 h_L}.\n$$\n在光滑性条件下，这些近似的截断误差为 $\\mathcal{O}(h_A^2)$ 和 $\\mathcal{O}(h_L^2)$ 阶，并且平方指数核是无限可微的，这保证了 $m(\\cdot)$ 的高阶光滑性。我们选择 $h_A = 5\\times 10^{-13}\\,\\text{m}$ 和 $h_L = 5\\times 10^{-12}\\,\\text{m}$，这些值相对于核长度尺度和输入范围来说很小，但又不足以小到在双精度下被浮点舍入误差主导，特别是因为我们是通过稳定的线性代数方法来评估 $m(\\cdot)$ 的。\n\n程序实现的算法步骤：\n- 将训练网格 $A \\in \\{2, 5, 10, 15, 18\\}\\,\\text{nm}$ 和 $L \\in \\{20, 50, 80, 120, 160\\}\\,\\text{nm}$ 转换为米，形成所有配对，并为每个配对计算在 $N = 10^{-5}\\,\\text{N}$ 时的 $F_{\\text{true}}$，从而得到训练目标 $\\mathbf{y}$。\n- 使用ARD平方指数核组装协方差矩阵 $\\mathbf{K}$，其中 $\\sigma_f = 2\\times 10^{-6}\\,\\text{N}$，$\\ell_1 = 5\\times 10^{-9}\\,\\text{m}$，$\\ell_2 = 5\\times 10^{-8}\\,\\text{m}$，并加上 $\\sigma_n^2 \\mathbf{I}$，其中 $\\sigma_n = 10^{-8}\\,\\text{N}$。\n- 通过使用Cholesky分解求解 $(\\mathbf{K} + \\sigma_n^2 \\mathbf{I}) \\mathbf{\\alpha} = \\mathbf{y}$ 来计算 $\\mathbf{\\alpha}$。\n- 对于测试套件中的每个测试输入 $(A_\\star, L_\\star)$，从纳米转换为米，并计算：\n  - 通过对所有训练点求和 $\\alpha_i \\nabla_{\\mathbf{x}_\\star} k(\\mathbf{x}_\\star,\\mathbf{x}_i)$ 来计算解析梯度 $\\nabla_{\\mathbf{x}_\\star} m(\\mathbf{x}_\\star)$。\n  - 使用步长为 $h_A$ 和 $h_L$ 的中心差分法，应用于 $m(\\cdot)$，计算有限差分梯度。\n  - 最大分量绝对差异 $\\Delta(\\mathbf{x}_\\star)$，单位为 $\\text{N}/\\text{m}$。\n- 输出对应于四个测试用例的列表 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4]$。\n\n科学真实性与一致性：\n- 摩擦力生成器由一个基准系数 $\\mu_0$ 加上依赖于 $A/L$ 和 $L$-缩放的无量纲修正项构成；总力与 $N$ 成正比，这与 $F_t = \\mu N$ 一致。\n- 带有平方指数核的高斯过程适用于平滑映射。ARD长度尺度反映了在纳米尺度上，摩擦力随振幅的变化可能比随波长的变化更快，因此有 $\\ell_1  \\ell_2$。\n- 计算中统一使用SI单位。梯度分量的单位是 $\\text{N}/\\text{m}$，因为它们是力对长度的导数。\n\n有限差分验证了我们的解析灵敏度表达式已正确实现。对于精心选择的步长和数值稳定的求解，差异 $\\Delta(\\mathbf{x}_\\star)$ 应该非常小，主要受限于浮点舍入误差和 $\\mathcal{O}(h^2)$ 阶的截断误差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef ground_truth_F(A_m, L_m, N):\n    \"\"\"\n    Synthetic physically plausible friction force generator.\n    Inputs are in SI units: meters for A, L; Newtons for N.\n    Returns force in Newtons.\n    \"\"\"\n    mu0 = 0.2\n    alpha = 0.6\n    beta = 0.05\n    Lc = 50e-9      # 50 nm in meters\n    A0 = 1e-9       # 1 nm in meters\n    Lref = 100e-9   # 100 nm in meters\n\n    term1 = mu0\n    term2 = alpha * ( (A_m / L_m)**2 ) / (1.0 + (A_m / Lc)**2 )\n    term3 = beta * (A_m / (A_m + A0)) * (Lref / L_m)\n    mu_eff = term1 + term2 + term3\n    return N * mu_eff\n\ndef ard_sqexp_kernel(X1, X2, sigma_f, ell):\n    \"\"\"\n    ARD squared-exponential kernel between two sets of inputs.\n    X1: (n1, d), X2: (n2, d)\n    ell: (d,) lengthscales\n    Returns: (n1, n2) covariance matrix\n    \"\"\"\n    # Scale inputs by lengthscales for ARD\n    X1s = X1 / ell\n    X2s = X2 / ell\n    # Squared Euclidean distances\n    # (x - x')^2 summed over dimensions\n    dists_sq = (\n        np.sum(X1s**2, axis=1, keepdims=True)\n        + np.sum(X2s**2, axis=1, keepdims=True).T\n        - 2.0 * (X1s @ X2s.T)\n    )\n    return (sigma_f**2) * np.exp(-0.5 * dists_sq)\n\ndef gp_train_alpha(X_train, y_train, sigma_f, ell, sigma_n, jitter=1e-18):\n    \"\"\"\n    Compute alpha = (K + sigma_n^2 I)^(-1) y using Cholesky.\n    \"\"\"\n    K = ard_sqexp_kernel(X_train, X_train, sigma_f, ell)\n    K[np.diag_indices_from(K)] += sigma_n**2 + jitter\n    # Cholesky factorization\n    L = np.linalg.cholesky(K)\n    # Solve L * z = y\n    z = np.linalg.solve(L, y_train)\n    # Solve L.T * alpha = z\n    alpha = np.linalg.solve(L.T, z)\n    return alpha, L  # Return L to enable predictive variance if needed\n\ndef gp_predict_mean_and_grad(x_star, X_train, alpha, sigma_f, ell):\n    \"\"\"\n    Compute GP posterior mean and its gradient at x_star.\n    x_star: (d,) in SI units (meters)\n    X_train: (n, d)\n    alpha: (n,)\n    Returns: mean (scalar), grad (d,)\n    \"\"\"\n    # Compute kernel vector k_star and mean\n    # We compute kernel via the same ARD mechanism\n    x_star_2d = x_star[None, :]  # shape (1, d)\n    k_star = ard_sqexp_kernel(x_star_2d, X_train, sigma_f, ell).ravel()  # (n,)\n    mean = float(k_star @ alpha)\n\n    # Gradient of kernel w.r.t x_star for ARD SE:\n    # d/dx_j k(x, x_i) = k(x, x_i) * (-(x_j - x_i_j)/ell_j^2)\n    diff = (x_star - X_train)  # (n, d)\n    grad_components = k_star[:, None] * ( - diff / (ell**2) )  # (n, d)\n    grad = grad_components.T @ alpha  # (d,)\n    return mean, grad\n\ndef central_fd_grad(x_star, fun, h):\n    \"\"\"\n    Central finite difference gradient of scalar function fun at x_star.\n    fun: function that maps x -> scalar\n    h: step sizes array (d,)\n    Returns: grad (d,)\n    \"\"\"\n    d = x_star.size\n    grad = np.zeros(d, dtype=float)\n    for j in range(d):\n        e = np.zeros(d, dtype=float)\n        e[j] = 1.0\n        xp = x_star + h[j] * e\n        xm = x_star - h[j] * e\n        fp = fun(xp)\n        fm = fun(xm)\n        grad[j] = (fp - fm) / (2.0 * h[j])\n    return grad\n\ndef solve():\n    # Constants and hyperparameters\n    N_load = 1e-5  # 10 microNewtons in N\n    sigma_f = 2e-6  # Signal std in N\n    ell = np.array([5e-9, 5e-8], dtype=float)  # lengthscales for A and L in meters\n    sigma_n = 1e-8  # Noise std in N\n\n    # Training grid in nanometers, then convert to meters\n    A_nm_list = np.array([2.0, 5.0, 10.0, 15.0, 18.0], dtype=float)\n    L_nm_list = np.array([20.0, 50.0, 80.0, 120.0, 160.0], dtype=float)\n    A_m_vals = A_nm_list * 1e-9\n    L_m_vals = L_nm_list * 1e-9\n\n    # Build training set\n    X_train = []\n    y_train = []\n    for A_m in A_m_vals:\n        for L_m in L_m_vals:\n            X_train.append([A_m, L_m])\n            y_train.append(ground_truth_F(A_m, L_m, N_load))\n    X_train = np.array(X_train, dtype=float)\n    y_train = np.array(y_train, dtype=float)\n\n    # Train GP (compute alpha and store Cholesky if needed)\n    alpha, L_factor = gp_train_alpha(X_train, y_train, sigma_f, ell, sigma_n, jitter=1e-18)\n\n    # Define prediction function for finite differences (posterior mean only)\n    def gp_mean_fun(x):\n        mean, _ = gp_predict_mean_and_grad(x, X_train, alpha, sigma_f, ell)\n        return mean\n\n    # Test suite: inputs in nm -> convert to meters\n    test_cases_nm = [\n        (8.0, 60.0),\n        (1.5, 200.0),\n        (18.0, 30.0),\n        (2.0, 20.0),\n    ]\n    test_cases = [(A * 1e-9, L * 1e-9) for (A, L) in test_cases_nm]\n\n    # Finite difference step sizes in meters\n    h_vec = np.array([5e-13, 5e-12], dtype=float)  # for A and L respectively\n\n    results = []\n    for (A_m, L_m) in test_cases:\n        x_star = np.array([A_m, L_m], dtype=float)\n        mean, grad_analytic = gp_predict_mean_and_grad(x_star, X_train, alpha, sigma_f, ell)\n        grad_fd = central_fd_grad(x_star, gp_mean_fun, h_vec)\n        discrepancy = np.max(np.abs(grad_analytic - grad_fd))\n        results.append(discrepancy)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2777669"}, {"introduction": "纳米力学的一个核心目标是从实验数据中推断材料的基本物理属性，例如粘附能 $W$。通常，这些参数隐藏在复杂的非线性物理模型背后，使得直接求解成为一个具有挑战性的逆问题（inverse problem）。本练习将采用哈密顿蒙特卡洛（HMC）算法——一种先进的马尔可夫链蒙特卡洛（MCMC）方法——来执行贝叶斯推断，从而完整地描绘出粘附能的后验分布。通过将成熟的物理理论（如JKR理论和Bell-Evans模型）与现代统计计算相结合，你将能够从含噪数据中提取出深刻的物理见解。[@problem_id:2777678]", "problem": "实现一个完整的、可运行的程序，该程序使用哈密顿蒙特卡洛 (HMC) 方法，根据纳米尺度接触中动态加载下的含噪声拉脱力数据，推断单位面积粘附能的后验分布，并计算在新的加载速率下，拉脱力的后验预测均值。请基于以下基本原理构建推导过程和算法。\n\n假设一个半径为 $R$ 的球形针尖与一个平面基底之间存在轴对称的纳米尺度接触，其中在零加载速率下的准静态拉脱力遵循 Johnson–Kendall–Roberts (JKR) 理论的预测。JKR 接触力学给出的零速率拉脱力与单位面积的粘附功 $W$ 成正比，关系如下：\n$$\nF_{0}(W) = \\frac{3}{2}\\pi R W .\n$$\n在动态加载条件下，遵循动态力谱学的 Bell–Evans 模型，引入一个与加载速率 $r$ 的自然对数成比例的热激活修正项，得到期望的拉脱力：\n$$\n\\mu(W, r) = F_{0}(W) + \\frac{k_{\\mathrm{B}} T}{x_{\\mathrm{b}}} \\ln\\!\\left(\\frac{r}{r_{\\mathrm{ref}}}\\right) ,\n$$\n其中 $k_{\\mathrm{B}}$ 是玻尔兹曼常数，$T$ 是绝对温度，$x_{\\mathrm{b}}$ 是有效键长，$r_{\\mathrm{ref}}$ 是参考加载速率。设在加载速率 $r_{i}$ 下观测到的拉脱力 $F_{i}$ 可被建模为：\n$$\nF_{i} \\mid W \\sim \\mathcal{N}\\!\\big(\\mu(W, r_{i}), \\sigma_{n}^{2}\\big) ,\n$$\n其中带有标准差为 $\\sigma_{n}$ 的已知独立高斯噪声。\n\n为确保 $W$ 的正性，使用 $\\theta = \\ln W$ 进行重参数化。对 $\\theta$ 设置一个高斯先验：\n$$\n\\theta \\sim \\mathcal{N}(m_{\\theta}, s_{\\theta}^{2}) .\n$$\n您的程序必须：\n- 根据上述定义，推导并实现负对数后验概率 $U(\\theta)$ 及其梯度 $\\nabla_{\\theta} U(\\theta)$（不使用自动微分）。\n- 实现一个使用蛙跳积分器和单位质量的哈密顿蒙特卡洛方法，从后验分布 $p(\\theta \\mid \\{(r_{i}, F_{i})\\})$ 中采样。\n- 使用 $\\theta$ 的后验样本，通过对后验分布求期望，计算在指定的新加载速率 $r_{\\star}$ 下的后验预测平均力。由于观测噪声的均值为零，在 $r_{\\star}$ 处的后验预测均值为\n$$\n\\mathbb{E}\\left[F_{\\star} \\mid \\{(r_{i}, F_{i})\\}\\right] = \\mathbb{E}_{\\theta \\mid \\text{data}}\\left[\\mu\\!\\left(e^{\\theta}, r_{\\star}\\right)\\right] .\n$$\n\n始终使用国际单位制 (SI)。所有力都必须以牛顿 (Newton) 为单位报告。不涉及角度。不涉及百分比。最终的数值输出必须是以牛顿为单位的浮点数。\n\n所有测试用例使用的常量：\n- 玻尔兹曼常数 $k_{\\mathrm{B}} = 1.380649\\times 10^{-23}\\ \\mathrm{J/K}$。\n- 温度 $T = 298\\ \\mathrm{K}$。\n- 有效键长 $x_{\\mathrm{b}} = 1.0\\times 10^{-10}\\ \\mathrm{m}$。\n- 参考加载速率 $r_{\\mathrm{ref}} = 1.0\\ \\mathrm{N/s}$。\n- 针尖半径 $R = 3.0\\times 10^{-8}\\ \\mathrm{m}$。\n- $\\theta$ 的先验均值和标准差：$m_{\\theta} = \\ln(0.25)$ 和 $s_{\\theta} = 0.5$。\n- HMC 超参数：步长 $\\epsilon = 0.01$，蛙跳步数 $L = 25$，预烧期采样数 $N_{\\mathrm{burn}} = 1000$，后验采样数 $N_{\\mathrm{samples}} = 3000$，单位质量。\n\n每个测试用例的数据生成协议：\n- 对每个案例，首先计算无噪声均值 $\\mu(W_{\\mathrm{true}}, r_{i})$，然后使用指定的数据生成随机种子，添加标准差为 $\\sigma_{n}$ 的独立高斯噪声，从而生成合成的观测力。为保证可复现性，请使用提供的固定随机数生成器种子。\n\n后验采样协议：\n- 在 $\\theta_{0} = m_{\\theta}$ 处初始化 HMC。\n- 使用指定的 HMC 随机种子对动量变量进行采样并执行接受/拒绝步骤。\n\n后验预测协议：\n- 对每个测试用例，使用 $\\theta$ 的后验样本，计算在三个新的加载速率 $r_{\\star} \\in \\{10^{0}, 10^{3}, 10^{6}\\}\\ \\mathrm{N/s}$ 下的后验预测均值。\n\n测试套件：\n- 案例 1：\n  - 真实粘附能 $W_{\\mathrm{true}} = 0.20\\ \\mathrm{J/m^{2}}$。\n  - 噪声标准差 $\\sigma_{n} = 2.0\\times 10^{-10}\\ \\mathrm{N}$。\n  - 加载速率 $r_{i} \\in \\{10^{-1}, 10^{0}, 10^{1}, 10^{2}, 10^{3}, 10^{4}, 10^{5}, 10^{6}\\}\\ \\mathrm{N/s}$。\n  - 数据生成种子 $s_{\\mathrm{data}} = 12345$。\n  - HMC 种子 $s_{\\mathrm{hmc}} = 24680$。\n- 案例 2：\n  - 真实粘附能 $W_{\\mathrm{true}} = 0.15\\ \\mathrm{J/m^{2}}$。\n  - 噪声标准差 $\\sigma_{n} = 5.0\\times 10^{-10}\\ \\mathrm{N}$。\n  - 加载速率 $r_{i} \\in \\{10^{0}, 10^{6}\\}\\ \\mathrm{N/s}$。\n  - 数据生成种子 $s_{\\mathrm{data}} = 54321$。\n  - HMC 种子 $s_{\\mathrm{hmc}} = 13579$。\n- 案例 3：\n  - 真实粘附能 $W_{\\mathrm{true}} = 0.35\\ \\mathrm{J/m^{2}}$。\n  - 噪声标准差 $\\sigma_{n} = 3.0\\times 10^{-10}\\ \\mathrm{N}$。\n  - 加载速率 $r_{i} \\in \\{10^{-2}, 10^{-1}, 10^{0}, 10^{3}, 10^{5}, 10^{7}\\}\\ \\mathrm{N/s}$。\n  - 数据生成种子 $s_{\\mathrm{data}} = 2023$。\n  - HMC 种子 $s_{\\mathrm{hmc}} = 97531$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表的列表。对于按顺序排列的每个测试用例（$\\text{Case }1$、$\\text{Case }2$、$\\text{Case }3$），按顺序输出一个包含三个浮点数的列表，这些浮点数等于在新的加载速率 $r_{\\star} \\in \\{10^{0}, 10^{3}, 10^{6}\\}\\ \\mathrm{N/s}$ 下的后验预测均值（单位为牛顿）。将这三个按案例划分的列表聚合到一个外部列表中。例如，一个语法正确的输出如下所示：\n$$\n[[f_{11},f_{12},f_{13}],[f_{21},f_{22},f_{23}],[f_{31},f_{32},f_{33}]],\n$$\n其中每个 $f_{jk}$ 是一个以牛顿为单位的浮点数。打印的行必须仅包含此带方括号和逗号分隔符的列表。", "solution": "该问题已经过验证，被认为是有效的。它在科学上基于接触力学（Johnson–Kendall–Roberts 理论）和动态力谱学（Bell–Evans 模型）的既定原理。该问题在数学上是适定的，提供了一个完整且一致的贝叶斯推断框架。所有参数、常数和程序步骤都已明确指定，使得问题毫不含糊且内容完备。从合成数据中推断物理参数的哈密顿蒙特卡洛采样器的实现任务，是计算物理和统计学领域一个标准且有深度的问题。我现在开始解答。\n\n问题的核心是从含噪声的拉脱力测量值中推断粘附功 $W$ 的后验分布，然后使用该后验分布来预测在新的加载速率下的力。为确保正性，我们使用重参数化的变量 $\\theta = \\ln W$。\n\n### 1. 贝叶斯模型构建\n\n给定观测数据 $D = \\{(r_i, F_i)\\}_{i=1}^N$，$\\theta$ 的后验分布由贝叶斯定理给出：\n$$\np(\\theta \\mid D) \\propto p(D \\mid \\theta) p(\\theta)\n$$\n其中 $p(D \\mid \\theta)$ 是似然函数，$p(\\theta)$ 是先验概率。\n\n**似然函数**：观测力 $F_i$ 被建模为独立的、以平均力 $\\mu(W, r_i)$ 为中心、方差为 $\\sigma_n^2$ 的高斯随机变量。通过代换 $W = e^\\theta$，单个数据点 $(r_i, F_i)$ 的似然函数为：\n$$\np(F_i \\mid \\theta) = \\mathcal{N}\\big(F_i; \\mu(e^\\theta, r_i), \\sigma_n^2\\big) = \\frac{1}{\\sqrt{2\\pi\\sigma_n^2}} \\exp\\left(-\\frac{(F_i - \\mu(e^\\theta, r_i))^2}{2\\sigma_n^2}\\right)\n$$\n平均力 $\\mu(e^\\theta, r_i)$ 由下式给出：\n$$\n\\mu(e^\\theta, r_i) = \\frac{3}{2}\\pi R e^\\theta + \\frac{k_{\\mathrm{B}} T}{x_{\\mathrm{b}}} \\ln\\left(\\frac{r_i}{r_{\\mathrm{ref}}}\\right)\n$$\n由于观测是相互独立的，总似然函数是各个似然函数的乘积：\n$$\np(D \\mid \\theta) = \\prod_{i=1}^N p(F_i \\mid \\theta)\n$$\n\n**先验概率**：对 $\\theta$ 设置一个高斯先验：\n$$\np(\\theta) = \\mathcal{N}(\\theta; m_\\theta, s_\\theta^2) = \\frac{1}{\\sqrt{2\\pi s_\\theta^2}} \\exp\\left(-\\frac{(\\theta - m_\\theta)^2}{2s_\\theta^2}\\right)\n$$\n\n**后验概率**：对数后验是对数似然和对数先验之和。忽略与 $\\theta$ 无关的常数项：\n$$\n\\ln p(\\theta \\mid D) \\propto -\\sum_{i=1}^N \\frac{(F_i - \\mu(e^\\theta, r_i))^2}{2\\sigma_n^2} - \\frac{(\\theta - m_\\theta)^2}{2s_\\theta^2}\n$$\n\n### 2. 用于 HMC 的势能及其梯度\n\n哈密顿蒙特卡洛 (HMC) 需要定义一个势能函数 $U(\\theta)$，即负对数后验概率。\n$$\nU(\\theta) = - \\ln p(\\theta \\mid D) = \\frac{1}{2\\sigma_n^2} \\sum_{i=1}^N (F_i - \\mu(e^\\theta, r_i))^2 + \\frac{1}{2s_\\theta^2} (\\theta - m_\\theta)^2\n$$\nHMC 算法还需要势能函数关于参数 $\\theta$ 的梯度，记作 $\\nabla_\\theta U(\\theta) = \\frac{dU}{d\\theta}$。应用链式法则：\n$$\n\\frac{dU}{d\\theta} = \\frac{1}{2\\sigma_n^2} \\sum_{i=1}^N 2(F_i - \\mu(e^\\theta, r_i)) \\cdot \\left(-\\frac{d\\mu(e^\\theta, r_i)}{d\\theta}\\right) + \\frac{1}{2s_\\theta^2} \\cdot 2(\\theta - m_\\theta)\n$$\n我们需要计算 $\\mu(e^\\theta, r_i)$ 关于 $\\theta$ 的导数：\n$$\n\\frac{d\\mu(e^\\theta, r_i)}{d\\theta} = \\frac{d}{d\\theta} \\left( \\frac{3}{2}\\pi R e^\\theta + \\frac{k_{\\mathrm{B}} T}{x_{\\mathrm{b}}} \\ln\\left(\\frac{r_i}{r_{\\mathrm{ref}}}\\right) \\right) = \\frac{3}{2}\\pi R e^\\theta\n$$\n将此代回梯度表达式可得：\n$$\n\\frac{dU}{d\\theta} = -\\frac{1}{\\sigma_n^2} \\sum_{i=1}^N (F_i - \\mu(e^\\theta, r_i)) \\left(\\frac{3}{2}\\pi R e^\\theta\\right) + \\frac{\\theta - m_\\theta}{s_\\theta^2}\n$$\n这可以改写为：\n$$\n\\frac{dU}{d\\theta} = \\frac{1}{\\sigma_n^2} \\left[ \\sum_{i=1}^N (\\mu(e^\\theta, r_i) - F_i) \\right] \\left(\\frac{3}{2}\\pi R e^\\theta\\right) + \\frac{\\theta - m_\\theta}{s_\\theta^2}\n$$\n为了运行 HMC 采样器，需要对 $U(\\theta)$ 和 $\\frac{dU}{d\\theta}$ 的这些表达式进行数值实现。\n\n### 3. 哈密顿蒙特卡洛算法\n\nHMC 是一种马尔可夫链蒙特卡洛方法，它使用哈密顿动力学在参数空间中提出新的移动。状态由位置 $\\theta$ 和一个虚拟动量 $p$ 描述。哈密顿量为 $H(\\theta, p) = U(\\theta) + K(p)$，其中 $K(p) = p^2/(2m)$ 是动能。对于本问题，我们使用单位质量，即 $m=1$。\n\n生成一个样本的算法如下：\n1.  **动量采样**：从标准正态分布中抽取一个新的动量值 $p \\sim \\mathcal{N}(0, 1)$。\n2.  **蛙跳积分**：从当前位置 $\\theta_{\\text{curr}}$ 和新动量 $p$ 开始，用步长 $\\epsilon$ 模拟 $L$ 步动力学过程。蛙跳积分器将哈密顿方程离散化：\n    a. 动量半步更新：$p \\leftarrow p - (\\epsilon/2) \\nabla_\\theta U(\\theta)$\n    b. 位置全步更新：$\\theta \\leftarrow \\theta + \\epsilon \\cdot p$\n    c. 重复 $L-1$ 次：\n        i. 动量全步更新：$p \\leftarrow p - \\epsilon \\nabla_\\theta U(\\theta)$\n        ii. 位置全步更新：$\\theta \\leftarrow \\theta + \\epsilon \\cdot p$\n    d. 最终动量半步更新：$p \\leftarrow p - (\\epsilon/2) \\nabla_\\theta U(\\theta)$\n    此序列产生一个提议状态 $(\\theta_{\\text{prop}}, p_{\\text{prop}})$。\n3.  **Metropolis-Hastings 接受**：根据哈密顿量的变化来接受或拒绝该提议，以确保细致平衡。接受概率 $\\alpha$ 为：\n    $$\n    \\alpha = \\min\\left(1, \\exp\\left(H(\\theta_{\\text{curr}}, p) - H(\\theta_{\\text{prop}}, p_{\\text{prop}})\\right)\\right)\n    $$\n    抽取一个随机数 $u \\in [0, 1]$。如果 $u  \\alpha$，则新状态为 $\\theta_{\\text{next}} = \\theta_{\\text{prop}}$；否则，状态保持不变，$\\theta_{\\text{next}} = \\theta_{\\text{curr}}$。\n\n这个过程重复 $N_{\\text{burn}} + N_{\\text{samples}}$ 次迭代。前 $N_{\\text{burn}}$ 个样本（预烧期）被丢弃，以使马尔可夫链收敛到平稳分布，随后的 $N_{\\text{samples}}$ 个样本则作为后验分布 $p(\\theta \\mid D)$ 的样本被保留。\n\n### 4. 后验预测推断\n\n一旦我们获得后验样本 $\\{\\theta^{(j)}\\}_{j=1}^{N_{\\text{samples}}}$，我们就可以计算在新加载速率 $r_\\star$ 下的新观测值 $F_\\star$ 的后验预测分布。问题要求计算后验预测均值 $\\mathbb{E}[F_\\star \\mid D]$。由于观测噪声模型 $\\mathcal{N}$ 的均值为零，该期望可简化为对均值函数 $\\mu$ 的后验期望：\n$$\n\\mathbb{E}[F_\\star \\mid D] = \\mathbb{E}_{\\theta \\mid D}\\left[\\mu(e^\\theta, r_\\star)\\right]\n$$\n该期望通过对后验样本进行蒙特卡洛平均来近似：\n$$\n\\mathbb{E}[F_\\star \\mid D] \\approx \\frac{1}{N_{\\text{samples}}} \\sum_{j=1}^{N_{\\text{samples}}} \\mu(e^{\\theta^{(j)}}, r_\\star)\n$$\n其中\n$$\n\\mu(e^{\\theta^{(j)}}, r_\\star) = \\frac{3}{2}\\pi R e^{\\theta^{(j)}} + \\frac{k_{\\mathrm{B}} T}{x_{\\mathrm{b}}} \\ln\\left(\\frac{r_\\star}{r_{\\mathrm{ref}}}\\right)\n$$\n对每个指定的新加载速率 $r_\\star$ 都执行此计算。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    # Global constants (SI units)\n    K_B = 1.380649e-23  # Boltzmann constant [J/K]\n    T = 298.0  # Temperature [K]\n    X_B = 1.0e-10  # Effective bond length [m]\n    R_REF = 1.0  # Reference loading rate [N/s]\n    R_TIP = 3.0e-8  # Tip radius [m]\n    M_THETA = np.log(0.25)  # Prior mean for theta\n    S_THETA = 0.5  # Prior std dev for theta\n    \n    # HMC hyperparameters\n    EPSILON = 0.01\n    L_STEPS = 25\n    N_BURN = 1000\n    N_SAMPLES = 3000\n\n    # Calculated constants\n    THERMAL_FORCE_CONST = K_B * T / X_B\n    JKR_CONST = 1.5 * np.pi * R_TIP\n\n    test_cases = [\n        {\n            \"W_true\": 0.20, \"sigma_n\": 2.0e-10,\n            \"r_i\": np.array([1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5, 1e6]),\n            \"s_data\": 12345, \"s_hmc\": 24680,\n        },\n        {\n            \"W_true\": 0.15, \"sigma_n\": 5.0e-10,\n            \"r_i\": np.array([1e0, 1e6]),\n            \"s_data\": 54321, \"s_hmc\": 13579,\n        },\n        {\n            \"W_true\": 0.35, \"sigma_n\": 3.0e-10,\n            \"r_i\": np.array([1e-2, 1e-1, 1e0, 1e3, 1e5, 1e7]),\n            \"s_data\": 2023, \"s_hmc\": 97531,\n        },\n    ]\n\n    r_predict = np.array([1e0, 1e3, 1e6])\n    all_results = []\n\n    for case in test_cases:\n        # Generate synthetic data\n        rng_data = np.random.default_rng(case[\"s_data\"])\n        \n        def mean_force_model(W, r):\n            return JKR_CONST * W + THERMAL_FORCE_CONST * np.log(r / R_REF)\n\n        mu_true = mean_force_model(case[\"W_true\"], case[\"r_i\"])\n        noise = rng_data.normal(0, case[\"sigma_n\"], size=mu_true.shape)\n        F_obs = mu_true + noise\n\n        # Define potential energy and its gradient\n        F_obs_data, r_obs_data, sigma_n_sq = F_obs, case[\"r_i\"], case[\"sigma_n\"]**2\n        s_theta_sq = S_THETA**2\n        \n        def U_potential(theta):\n            W = np.exp(theta)\n            mu = mean_force_model(W, r_obs_data)\n            log_likelihood_term = np.sum((F_obs_data - mu)**2) / (2.0 * sigma_n_sq)\n            log_prior_term = (theta - M_THETA)**2 / (2.0 * s_theta_sq)\n            return log_likelihood_term + log_prior_term\n\n        def grad_U_potential(theta):\n            W = np.exp(theta)\n            mu = mean_force_model(W, r_obs_data)\n            d_mu_d_theta = JKR_CONST * W\n            \n            grad_log_likelihood = np.sum(mu - F_obs_data) * d_mu_d_theta / sigma_n_sq\n            grad_log_prior = (theta - M_THETA) / s_theta_sq\n            return grad_log_likelihood + grad_log_prior\n\n        # Run HMC\n        rng_hmc = np.random.default_rng(case[\"s_hmc\"])\n        theta_current = M_THETA\n        samples = []\n\n        for i in range(N_BURN + N_SAMPLES):\n            p_current = rng_hmc.normal(0, 1)\n            q_proposal, p_proposal = theta_current, p_current\n\n            # Leapfrog integration\n            p_proposal -= 0.5 * EPSILON * grad_U_potential(q_proposal)\n            for _ in range(L_STEPS - 1):\n                q_proposal += EPSILON * p_proposal\n                p_proposal -= EPSILON * grad_U_potential(q_proposal)\n            q_proposal += EPSILON * p_proposal\n            p_proposal -= 0.5 * EPSILON * grad_U_potential(q_proposal)\n            \n            p_proposal = -p_proposal\n\n            # Metropolis-Hastings acceptance step\n            H_current = U_potential(theta_current) + 0.5 * p_current**2\n            H_proposal = U_potential(q_proposal) + 0.5 * p_proposal**2\n            \n            alpha = min(1.0, np.exp(H_current - H_proposal))\n\n            if rng_hmc.random()  alpha:\n                theta_current = q_proposal\n\n            if i >= N_BURN:\n                samples.append(theta_current)\n        \n        theta_samples = np.array(samples)\n\n        # Posterior predictive mean\n        W_samples = np.exp(theta_samples)\n        case_predictive_means = []\n        for r_p in r_predict:\n            predictive_forces = mean_force_model(W_samples, r_p)\n            case_predictive_means.append(np.mean(predictive_forces))\n        \n        all_results.append(case_predictive_means)\n\n    print(str(all_results).replace(\" \", \"\"))\n\n\nsolve()\n```", "id": "2777678"}]}