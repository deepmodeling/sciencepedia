## 引言
为复杂的动态系统构建精确的数学模型是现代工程与科学研究的基石，尤其在设计高性能[反馈控制](@entry_id:272052)器时更是不可或缺。然而，当系统在闭环条件下运行时，辨识过程会面临独特的挑战。反馈机制在[稳定系统](@entry_id:180404)的同时，也引入了输入信号与[过程噪声](@entry_id:270644)之间的相关性，这使得直接应用传统辨识方法极易产生错误和有偏的模型。与此同时，如何确定一个既能准确捕捉系统行为又不过于复杂的模型（即模型阶次选择），是所有辨识任务中普遍存在的难题。本文旨在系统性地解决这两个相互关联的核心问题：[闭环辨识](@entry_id:199122)与模型阶次选择。

本文将带领读者深入理解这些挑战背后的根本原因，并掌握解决这些问题的实用方法与理论工具。在“原理与机制”一章中，我们将剖析反馈如何导致辨识偏差，并详细介绍[预测误差法(PEM)](@entry_id:194537)等一致性估计策略的内在机理，同时阐明[赤池信息准则](@entry_id:139671)(AIC)和[贝叶斯信息准则](@entry_id:142416)(BIC)等工具是如何帮助我们量化和解决模型选择中的[偏差-方差权衡](@entry_id:138822)问题。接着，在“应用与[交叉](@entry_id:147634)学科联系”一章中，我们将把理论付诸实践，展示一个从实验设计到[模型验证](@entry_id:141140)的完整工作流程，并探讨这些技术在控制工程、[纳米科学](@entry_id:182334)乃至生理学等前沿领域的具体应用。最后，“动手实践”部分将提供一系列练习，帮助读者巩固所学知识，将理论转化为可操作的技能。通过这三个章节的层层递进，读者将建立起对模型阶次选择与[闭环辨识](@entry_id:199122)的全面而深刻的理解。

## 原理与机制

在上一章介绍性讨论的基础上，本章深入探讨了模型阶次选择和[闭环辨识](@entry_id:199122)的核心科学原理和关键机制。[系统辨识](@entry_id:201290)的目标是利用测量数据构建数学模型，而在闭环（即[反馈控制](@entry_id:272052)）条件下进行这一过程会带来独特的挑战和一系列必须精确应用的复杂解决方案。本章将系统性地阐述这些挑战的根源、克服这些挑战的方法论，以及确保所选模型既准确又简洁的定量工具。

### [闭环辨识](@entry_id:199122)的基本挑战：反馈引起的偏差

在开环系统中，输入信号 $u(t)$ 的设计独立于系统的任何扰动，这极大地简化了辨识过程。然而，在闭环系统中，控制器会根据包含扰动影响的系统输出来调整输入信号。这种反馈机制是控制系统的本质，但它也引入了一个根本性的辨识难题：输入信号与过程噪声之间产生相关性。

考虑一个由以下方程描述的典型闭环系统：

$y(t) = G_0(q) u(t) + v(t)$

$u(t) = K(q) (r(t) - y(t))$

其中 $y(t)$ 是系统输出，$u(t)$ 是系统输入，$r(t)$ 是外部参考信号，$v(t) = H_0(q) e(t)$ 是由[白噪声](@entry_id:145248) $e(t)$ 经噪声滤波器 $H_0(q)$ 生成的输出扰动。$G_0(q)$ 是待辨识的真实系统（“被控对象”），$K(q)$ 是已知的控制器。

为了理解相关性是如何产生的，我们可以求解 $u(t)$ 与外部信号 $r(t)$ 和 $e(t)$ 之间的关系。将第一个方程代入第二个方程：

$u(t) = K(q) (r(t) - [G_0(q) u(t) + H_0(q) e(t)])$

整理后得到：

$(1 + G_0(q) K(q)) u(t) = K(q) r(t) - K(q) H_0(q) e(t)$

引入**[灵敏度函数](@entry_id:271212)** $S_0(q) \triangleq (1 + G_0(q) K(q))^{-1}$，我们可以将输入 $u(t)$ 表示为：

$u(t) = S_0(q) K(q) r(t) - S_0(q) K(q) H_0(q) e(t)$

这个表达式是[闭环辨识](@entry_id:199122)中所有挑战的核心。它清楚地表明，输入 $u(t)$ 不仅依赖于外部参考信号 $r(t)$，还依赖于噪声 $e(t)$ 的一个滤波版本。由于 $u(t)$ 的一部分是由 $e(t)$ 驱动的，因此 $u(t)$ 通常与噪声过程 $v(t)$ 相关。

这种相关性直接破坏了许多基本辨识方法的假设。例如，一个看似简单的方法是使用[普通最小二乘法](@entry_id:137121) (OLS) 来拟合一个**[有限脉冲响应](@entry_id:192542) (FIR)** 模型 $y(t) = \sum_{k=1}^{n} g_k u(t-k) + \varepsilon(t)$。OLS 估计的无偏性和一致性的一个基本前提是回归量（在这里是过去的输入 $u(t-k)$）与方程误差 $\varepsilon(t)$ 不相关。然而，在闭环中，真实的方程误差是 $v(t)$，而回归量 $u(t-k)$ 与 $v(t)$ 相关。因此，直接应用 OLS 会导致对系统参数 $G_0(q)$ 的**有偏**且**不一致**的估计。一个常见的误解是，一个功率足够大且[频谱](@entry_id:265125)足够丰富的参考信号 $r(t)$ 就足以克服这个问题。虽然这样的信号对于激励系统动力学至关重要（我们稍后将讨论**[持续激励](@entry_id:263834)**），但它并不能消除由反馈路径引起的内生相关性。因此，估计偏差依然存在。[@problem_id:2883900]

### 系统辨识的[参数化](@entry_id:272587)模型结构

为了系统地解决[闭环辨识](@entry_id:199122)问题，我们需要一个用于描述[系统动力学](@entry_id:136288)和噪声特性的标准化语言。这通[过参数化模型](@entry_id:637931)结构来实现。这些结构都是广义模型 $y(t) = G(q) u(t) + H(q) e(t)$ 的特例，其中 $G(q)$ 是被控对象模型，$H(q)$ 是[噪声模型](@entry_id:752540)。[@problem_id:2883893]

最常见的模型结构包括：

*   **ARX 模型 (AutoRegressive with eXogenous input)**：
    $A(q) y(t) = B(q) u(t) + e(t)$
    在这种结构中，$G(q) = \frac{B(q)}{A(q)}$ 且 $H(q) = \frac{1}{A(q)}$。ARX 模型的主要特点是过程模型和[噪声模型](@entry_id:752540)共享相同的极点（由 $A(q)$ 的根决定）。这是一种结构上的简化，使得模型可以用[线性回归](@entry_id:142318)方法（如[最小二乘法](@entry_id:137100)）进行估计，计算效率高，但这种约束可能与现实不符。

*   **ARMAX 模型 (AutoRegressive Moving-Average with eXogenous input)**：
    $A(q) y(t) = B(q) u(t) + C(q) e(t)$
    在这种结构中，$G(q) = \frac{B(q)}{A(q)}$ 且 $H(q) = \frac{C(q)}{A(q)}$。与 ARX 类似，ARMAX 模型也假设过程和噪声共享相同的极点，但通过引入一个移动平均多项式 $C(q)$ 为[噪声模型](@entry_id:752540)增加了额外的自由度。

*   **OE 模型 (Output-Error)**：
    $y(t) = \frac{B(q)}{F(q)} u(t) + e(t)$
    在这种结构中，$G(q) = \frac{B(q)}{F(q)}$ 且 $H(q) = 1$。OE 模型假设输出扰动是[白噪声](@entry_id:145248)，即[噪声模型](@entry_id:752540)是平凡的。这使得过程模型 $G(q)$ 的参数估计不受噪声动态的影响。

*   **BJ 模型 (Box-Jenkins)**：
    $y(t) = \frac{B(q)}{F(q)} u(t) + \frac{C(q)}{D(q)} e(t)$
    在这种结构中，$G(q) = \frac{B(q)}{F(q)}$ 且 $H(q) = \frac{C(q)}{D(q)}$。BJ 模型是最灵活的结构，它为过程模型和[噪声模型](@entry_id:752540)提供了完全独立的参数化。这种灵活性使其能够描述更广泛的系统，但也带来了更高的计算复杂性。

选择哪种模型结构是辨识过程中的一个关键决策，它体现了对系统先验知识的假设。

### 闭环系统的一致性估计策略

为了在存在反馈的情况下获得一致的[参数估计](@entry_id:139349)，研究人员已经发展出多种策略。这些策略的核心思想都是以某种方式正确处理或规避输入与噪声之间的相关性。[@problem_id:2883929]

#### [预测误差法](@entry_id:169550) (PEM)

**[预测误差法](@entry_id:169550) (Prediction Error Method, PEM)** 是最通用和最强大的方法之一。PEM 的核心思想是调整模型参数 $\theta$，以最小化**一步预测误差**的[方差](@entry_id:200758)。对于一般模型 $y(t) = G(q, \theta)u(t) + H(q, \theta)e(t)$，一步预测 $\hat{y}(t|\theta)$ 是基于直到时间 $t-1$ 的所有可用信息对 $y(t)$ 的最优预测。相应的[预测误差](@entry_id:753692)（或称**新息**）为：

$\varepsilon(t, \theta) = y(t) - \hat{y}(t|\theta) = H(q, \theta)^{-1} (y(t) - G(q, \theta)u(t))$

PEM 的[目标函数](@entry_id:267263)是 $J(\theta) = \sum_{t=1}^{N} \varepsilon(t, \theta)^2$。

[噪声模型](@entry_id:752540) $H(q, \theta)$ 在此扮演了至关重要的角色。它充当一个**白化滤波器**。如果模型结构选择得当，使得对于某组真参数 $\theta_0$，有 $G(q, \theta_0) = G_0(q)$ 和 $H(q, \theta_0) = H_0(q)$，那么在 $\theta_0$ 处计算的预测误差恰好就是底层的白噪声序列 $e(t)$：

$\varepsilon(t, \theta_0) = H_0(q)^{-1} (G_0(q)u(t) + H_0(q)e(t) - G_0(q)u(t)) = e(t)$

由于[白噪声](@entry_id:145248) $e(t)$ 与所有过去信号（包括构成回归量的 $u(t-k)$ 和 $y(t-k)$）不相关，这就满足了一致性估计所需的不相关条件。因此，通过正确地对噪声动态进行建模，PEM 能够有效地“消除”反馈引起的偏差问题。这解释了为什么像 ARMAX 和 BJ 这样包含可调[噪声模型](@entry_id:752540)的结构在[闭环辨识](@entry_id:199122)中特别有效。[@problem_id:2883905]

#### 辨识策略分类

基于如何处理闭[环数](@entry_id:267135)据，我们可以将辨识方法分为三类：

1.  **直接法 (Direct Approach)**：该方法直接将辨识算法（如 PEM）应用于在闭环中测得的输入-输出数据对 $(u(t), y(t))$。它通过在模型结构中同时对被控对象 $G(q)$ 和噪声 $H(q)$ 进行参数化来处理相关性问题。上面讨论的基于 ARMAX 或 BJ 模型的 PEM 就是直接法的典范。

2.  **间接法 (Indirect Approach)**：该方法分两步进行。第一步，它辨识一个[闭环传递函数](@entry_id:275480)，其输入是与[过程噪声](@entry_id:270644)不相关的外部信号。例如，它可以辨识从参考信号 $r(t)$ 到输出 $y(t)$ 的[传递函数](@entry_id:273897) $T_{ry}(q) = \frac{G(q)K(q)}{1+G(q)K(q)}$。由于 $r(t)$ 和 $v(t)$ 是独立的，这个辨识问题可以看作是开环的。第二步，利用已知的控制器 $K(q)$ 和已辨识出的 $\hat{T}_{ry}(q)$，通过代数运算求解出被控对象模型 $\hat{G}(q)$。

3.  **联合法 (Joint Approach)**：此方法将系统视为一个多输入多输出 (MIMO) 系统，其中外部信号（如 $r(t)$ 和 $e(t)$）是输入，而内部信号（如 $u(t)$ 和 $y(t)$）是输出。通过对整个 MIMO 系统的[传递函数矩阵](@entry_id:271746)进行[参数化](@entry_id:272587)（这些[传递函数](@entry_id:273897)都依赖于未知的 $G(q)$ 和 $H(q)$），可以同时对所有参数进行估计。

#### [工具变量法](@entry_id:204495) (Instrumental Variable, IV)

作为 PEM 的一种替代方法，**[工具变量法](@entry_id:204495) (IV)** 通过引入一个辅助信号——即**工具变量** $z(t)$——来解决偏差问题。一个有效的工具变量必须满足两个条件：(1) 它必须与回归量（如 $u(t-k)$）相关；(2) 它必须与噪声项 $v(t)$ 不相关。在[闭环系统](@entry_id:270770)中，一个极好的[工具变量](@entry_id:142324)来源是外部参考信号 $r(t)$ 的过去值。由于 $r(t)$ 驱动着 $u(t)$（满足条件1），并且根据设计它与噪声 $e(t)$ 独立（满足条件2），使用 $r(t)$ 的过去值作为[工具变量](@entry_id:142324)可以得到对 $G_0(q)$ 的一致估计。[@problem_id:2883900]

### 模型阶次选择原理

在选择了模型结构和辨识方法之后，下一个关键步骤是确定模型的**阶次**——即模型的复杂度。模型的阶次是什么？从根本上说，一个系统的阶次是描述其动态行为所需的状态变量的最小数量。对于一个由[互质](@entry_id:143119)多项式构成的单输入单输出 (SISO) [传递函数](@entry_id:273897) $G(z) = N(z)/D(z)$，其阶次就是分母多项式 $D(z)$ 的次数。对于多输入多输出 (MIMO) 系统，这个概念被推广为**麦克米伦阶 (McMillan degree)**，它是在所有可能的[状态空间实现](@entry_id:166670)中最小的状态维数。一个[状态空间实现](@entry_id:166670)是**最小的**，当且仅当它是**完全可控**和**完全可观**的。这些定义为我们讨论模型选择提供了一个坚实的理论基础。[@problem_id:2883889]

模型阶次选择的核心在于**[偏差-方差权衡](@entry_id:138822) (bias-variance trade-off)**。
*   如果模型阶次过低（**欠参数化**），它将无法捕捉系统的真实动态，导致**系统性偏差**。
*   如果模型阶次过高（**过[参数化](@entry_id:272587)**），模型会开始拟合数据中的随机噪声，而不仅仅是潜在的信号。这虽然会减少训练数据上的拟合误差，但会导致[模型参数估计](@entry_id:752080)的**[方差](@entry_id:200758)**增大，并且其在新数据上的预测性能（泛化能力）会下降。

我们的目标是选择一个既能充分描述系统动态（低偏差）又不过于复杂（低[方差](@entry_id:200758)）的阶次。[信息准则](@entry_id:636495)为此提供了一个定量的框架。

### 用于[模型选择](@entry_id:155601)的[信息准则](@entry_id:636495)

[信息准则](@entry_id:636495)通过在一个单一的度量中结合模型的[拟合优度](@entry_id:637026)（通常基于[最大似然](@entry_id:146147)）和模型的复杂度（参数数量）来形式化[偏差-方差权衡](@entry_id:138822)。选择的目标是最小化[信息准则](@entry_id:636495)的值。

#### [赤池信息准则 (AIC)](@entry_id:193149)

**[赤池信息准则](@entry_id:139671) (Akaike Information Criterion, AIC)** 源于对模型预测性能的深刻洞察。我们真正关心的是模型在**新**数据上的表现，而不是它在用于训练的**样本内**数据上的表现。一个模型的样本内最大化对数似然值 $\ell(\hat{\theta})$ 是对其期望的样本外对数似然值的一个**有偏**估计。具体来说，它过于乐观了。可以证明，这种**乐观度**的[期望值](@entry_id:153208)近似等于模型中自由参数的数量 $k$。[@problem_id:2883894]

$\mathbb{E}[\ell_{\text{in-sample}}(\hat{\theta}) - \ell_{\text{out-of-sample}}(\hat{\theta})] \approx k$

因此，为了得到一个对样本外性能的近似无偏估计，我们必须从样本内[对数似然](@entry_id:273783)中减去这个偏差。AIC 通常以偏差（$-2 \times \text{对数似然}$）的形式表示，其定义为：

$\text{AIC} = -2\ell(\hat{\theta}) + 2k$

这里的 $2k$ 项就是一个偏差修正项。在[闭环辨识](@entry_id:199122)中，只要使用了像 PEM 这样能够产生一致估计的方法，并且正确计算了模型中所有被估计参数的总数（包括过程模型和[噪声模型](@entry_id:752540)中的参数），这个准则同样适用。[@problem_id:2883894]

#### [贝叶斯信息准则 (BIC)](@entry_id:181959)

**[贝叶斯信息准则](@entry_id:142416) (Bayesian Information Criterion, BIC)**，也称为**[最小描述长度 (MDL)](@entry_id:751999)** 准则，采用了不同的惩罚项：

$\text{BIC} = -2\ell(\hat{\theta}) + k \ln(N)$

其中 $N$ 是数据点的数量。BIC 的一个关键特性是**选择一致性**。这意味着当数据量 $N \to \infty$ 时，如果真实模型存在于候选模型集中，BIC 将以趋近于 1 的概率选择具有正确阶次的模型。[@problem_id:2883901]

这是因为 BIC 的惩罚项 $k \ln(N)$ 随着数据量的增加而增长。相比之下，当一个过参数化的模型（例如，比真实模型多一个不必要的参数）被拟合时，其[对数似然](@entry_id:273783)的改进量由[威尔克斯定理](@entry_id:169826)可知，服从一个 $\chi^2$ [分布](@entry_id:182848)，其大小在概率上是有界的（即 $O_p(1)$）。由于 $\ln(N)$ 的增长速度超过了 $O_p(1)$，因此对于足够大的 $N$，BIC 的惩罚项将压倒增加一个不必要参数所带来的微小似然增益，从而迫使选择更简洁的真实模型。例如，可以计算出，为了让 BIC 有至少 95% 的把握拒绝一个不必要的参数，样本量 $N$ 需要达到约 47。[@problem_id:2883901]

#### 实用[信息准则](@entry_id:636495)总结

在实践中，多种[信息准则](@entry_id:636495)被广泛使用。以下是一些关键准则的定义，其中 $k$ 是参数数量，$N$ 是样本数量，$\hat{\sigma}^2$ 是残差[方差](@entry_id:200758)的估计：[@problem_id:2883908]

*   **AIC**: $N \ln(\hat{\sigma}^2) + 2k$
*   **AICc** (修正的AIC，适用于小样本): $N \ln(\hat{\sigma}^2) + 2k + \frac{2k(k+1)}{N-k-1}$
*   **BIC/MDL**: $N \ln(\hat{\sigma}^2) + k \ln(N)$
*   **HQ** (Hannan-Quinn): $N \ln(\hat{\sigma}^2) + 2k \ln(\ln N)$

AIC 的目标是找到渐近意义上最优的预测模型，它倾向于选择阶次稍高的模型。而 BIC 的目标是找到一致的阶次估计，它对[模型复杂度](@entry_id:145563)的惩罚更重，倾向于选择更简洁的模型。

### 实践考量与高级主题

#### [持续激励](@entry_id:263834)的重要性

模型参数能够被唯一且可靠地辨识的一个必要条件是输入信号具有足够的**[持续激励](@entry_id:263834)性 (Persistent Excitation, PE)**。一个输入信号 $u(t)$ 被称为是**n阶[持续激励](@entry_id:263834)**的，如果由其过去值构成的回归向量 $\phi(t) = [u(t), \dots, u(t-n+1)]^T$ 的自[相关矩阵](@entry_id:262631)是正定的。直观上，这意味着输入信号的[频谱](@entry_id:265125)必须在至少 $n/2$ 个不同的频率点上是“丰富”的，从而能够激励起模型中所有 $n$ 个[自由模](@entry_id:152514)式。[@problem_id:2883939]

在闭环中，被控对象实际看到的输入 $u(t)$ 是外部参考信号 $r(t)$ 经过闭环滤波器 $K(q)S(q)$ 作用后的结果。如果这个滤波器在其通带内有“陷波”或深度衰减，它可能会消除 $r(t)$ 在某些频率上的激励分量，从而降低到达被控对象的有效激励阶次。因此，在设计[闭环辨识](@entry_id:199122)实验时，不仅要考虑参考信号本身，还必须考虑它如何被[反馈回路](@entry_id:273536)所“塑造”。[@problem_id:2883939]

#### [噪声模型](@entry_id:752540)阶次选择的微妙之处

在[闭环辨识](@entry_id:199122)中，[噪声模型](@entry_id:752540) $H(q)$ 的选择对被控对象模型 $G(q)$ 的估计质量有着直接影响。这是一个微妙但至关重要的实践问题。[@problem_id:2883928]

*   **[噪声模型](@entry_id:752540)欠[参数化](@entry_id:272587)**：如果[噪声模型](@entry_id:752540) $H(q)$ 的阶次过低，无法准确描述真实的噪声动态 $H_0(q)$，那么 PEM 过程中的[预测误差](@entry_id:753692)将不会是[白噪声](@entry_id:145248)。这将导致回归量与误差之间存在残余相关性，从而使被控对象参数 $\hat{\theta}$ 的估计产生**偏差**。
*   **[噪声模型](@entry_id:752540)过参数化**：反之，如果选择一个阶次过高的[噪声模型](@entry_id:752540)，虽然它有足够的能力捕捉 $H_0(q)$ 并因此减少 $\hat{\theta}$ 的偏差，但这也意味着整个模型有更多的参数需要估计。对于有限的数据集，这会增加参数估计的**[方差](@entry_id:200758)**。

这种权衡引出了一种先进的辨识策略：
1.  首先，为了确保被控对象估计的偏差最小，可以故意选择一个高阶的[噪声模型](@entry_id:752540) $H(q)$。
2.  在此高阶[噪声模型](@entry_id:752540)固定的情况下，使用[信息准则](@entry_id:636495)（如 BIC）来选择被控对象模型 $G(q)$ 的最佳阶次。
3.  最后，在确定了 $G(q)$ 的阶次后，再反过来对[噪声模型](@entry_id:752540) $H(q)$ 进行降阶，再次使用[信息准则](@entry_id:636495)，并结合**[残差分析](@entry_id:191495)**——检查最终模型的[预测误差](@entry_id:753692)是否是白的，以及是否与输入不相关——来确定一个更简洁的[噪声模型](@entry_id:752540)。

#### [模型验证](@entry_id:141140)

任何辨识过程的最后一步都是**[模型验证](@entry_id:141140)**。无论模型阶次是如何选择的，都必须检验最终模型是否与数据和假设相容。核心的验证工具是[残差分析](@entry_id:191495)。如果模型是准确的，其一步[预测误差](@entry_id:753692)（新息）序列 $\varepsilon(t, \hat{\theta})$ 应该近似于一个[白噪声过程](@entry_id:146877)。这意味着：
1.  残差的[自相关函数](@entry_id:138327)应该在所有非零延迟上都接近于零。
2.  残差与所有过去输入之间的[互相关函数](@entry_id:147301)也应该接近于零。

如果这些检验失败，则表明模型是失配的，需要重新审视模型结构或阶次的选择。[@problem_id:2883905]