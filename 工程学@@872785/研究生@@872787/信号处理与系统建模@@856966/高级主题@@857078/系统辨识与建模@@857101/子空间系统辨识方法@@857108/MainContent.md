## 引言
[子空间系统辨识](@entry_id:190551)方法是现代数据驱动建[模的基](@entry_id:156416)石，为获取动态系统的[状态空间表示](@entry_id:147149)提供了一条稳健且数值稳定的路径。在系统与控制领域，一个根本性的挑战是如何仅利用外部测量的输入输出数据，尤其是在数据被[噪声污染](@entry_id:188797)的情况下，可靠且高效地推导出系统动态的精确内部模型。传统方法往往在处理复杂性或数值敏感性方面遇到困难。本文旨在填补这一认知鸿沟，为[子空间辨识](@entry_id:188076)提供一份全面的指南。

在本文的探索之旅中，读者将首先深入学习“原理与机制”章节，我们将在此解构从将数据构建为汉克尔矩阵，到利用几何投影和奇异值分解（SVD）提取模型的全过程。接着，在“应用与跨学科连接”章节中，我们将探索这些方法在随机系统、[闭环控制](@entry_id:271649)和[频域](@entry_id:160070)辨识等挑战性场景中的灵活性与强大功能。最后，“动手实践”部分将通过具体问题帮助您巩固所学知识。

现在，让我们从奠定理论基础开始，深入探讨使[子空间辨识](@entry_id:188076)成为工程师和科学家工具箱中强大工具的基本原理与核心机制。

## 原理与机制

本章深入探讨[子空间系统辨识](@entry_id:190551)方法的核心原理与基本机制。在前一章介绍其背景与重要性的基础上，我们将系统地剖析这些方法如何从原始输入输出数据中提取[状态空间模型](@entry_id:137993)。我们将从构建数据方程开始，逐步揭示投影在线性代数和[统计估计](@entry_id:270031)中的核心作用，并阐明如何通过[奇异值分解](@entry_id:138057)来确定系统阶次以及最终求解出[系统矩阵](@entry_id:172230)。本章旨在为读者提供一个严谨而清晰的理论框架，辅以具体示例，以理解[子空间方法](@entry_id:200957)为何如此强大且在实践中广为应用。

### 数据方程：从时间序列到汉克尔矩阵

[子空间辨识](@entry_id:188076)方法的出发点是将收集到的离散时间输入输出数据序列重新[排列](@entry_id:136432)成一种具有特殊结构的矩阵形式，即**块汉克尔矩阵（block Hankel matrices）**。这种结构化表示是揭示系统内部动态特性的关键。

考虑一个多输入多输出（MIMO）的线性时不变（LTI）系统，其[状态空间表示](@entry_id:147149)为：
$$
\begin{align}
x_{k+1} = A x_k + B u_k \\
y_k = C x_k + D u_k + v_k
\end{align}
$$
其中 $x_k \in \mathbb{R}^n$ 是[状态向量](@entry_id:154607)，$u_k \in \mathbb{R}^m$ 是输入向量，$y_k \in \mathbb{R}^p$ 是输出向量，$v_k$ 是测量噪声。矩阵 $A, B, C, D$ 分别是状态矩阵、输入矩阵、输出矩阵和前馈矩阵，其维度与输入、输出和状态向量的维度相匹配。我们的目标是从可观测的输入序列 $\{u_k\}$ 和输出序列 $\{y_k\}$ 中估计出这些矩阵以及系统的阶次 $n$。

为了实现这一目标，我们首先定义两个关键参数：**过去视界（past horizon）** $i$ 和**未来[视界](@entry_id:746488)（future horizon）** $i$。为简化表示，我们在此采用相同的[视界](@entry_id:746488)长度，这在许多算法中是常见的做法。然后，我们将数据分段并堆叠成四个主要的块汉克尔矩阵。假设我们有 $N$ 个数据点，我们可以定义 $j = N - 2i + 1$ 个数据窗口。

**过去数据矩阵**包含在时刻 $k$ 之前的 $i$ 个输入和输出：
$$
U_p = \begin{pmatrix} u_0  u_1  \cdots  u_{j-1} \\ u_1  u_2  \cdots  u_j \\ \vdots  \vdots  \ddots  \vdots \\ u_{i-1}  u_i  \cdots  u_{i+j-2} \end{pmatrix} \in \mathbb{R}^{(mi) \times j}
\quad
Y_p = \begin{pmatrix} y_0  y_1  \cdots  y_{j-1} \\ y_1  y_2  \cdots  y_j \\ \vdots  \vdots  \ddots  \vdots \\ y_{i-1}  y_i  \cdots  y_{i+j-2} \end{pmatrix} \in \mathbb{R}^{(pi) \times j}
$$
这里，下标 $p$ 代表“过去”（past）。

**未来数据矩阵**包含从时刻 $k$ 开始的 $i$ 个输入和输出：
$$
U_f = \begin{pmatrix} u_i  u_{i+1}  \cdots  u_{i+j-1} \\ u_{i+1}  u_{i+2}  \cdots  u_{i+j} \\ \vdots  \vdots  \ddots  \vdots \\ u_{2i-1}  u_{2i}  \cdots  u_{N-1} \end{pmatrix} \in \mathbb{R}^{(mi) \times j}
\quad
Y_f = \begin{pmatrix} y_i  y_{i+1}  \cdots  y_{i+j-1} \\ y_{i+1}  y_{i+2}  \cdots  y_{i+j} \\ \vdots  \vdots  \ddots  \vdots \\ y_{2i-1}  y_{2i}  \cdots  u_{N-1} \end{pmatrix} \in \mathbb{R}^{(pi) \times j}
$$
这里，下标 $f$ 代表“未来”（future）。

通过反复迭代[状态空间方程](@entry_id:266994)，我们可以推导出连接过去和未来的基本数据方程。未来输出 $Y_f$ 可以表示为：
$$
Y_f = \mathcal{O}_i X_i + \mathcal{T}_i U_f + V_f
$$
其中，$X_i = \begin{pmatrix} x_i  x_{i+1}  \cdots  x_{i+j-1} \end{pmatrix}$ 是**状态序列矩阵**，$\mathcal{O}_i$ 是**扩展可观测矩阵**，$\mathcal{T}_i$ 是一个下三角的**块托普利兹矩阵**，由系统的马尔可夫参数构成，$V_f$ 是未来噪声的汉克尔矩阵。

这个方程是[子空间方法](@entry_id:200957)的核心。它表明，未来输出 $Y_f$ 是三个部分的和：一部分来自系统状态 $X_i$（由 $\mathcal{O}_i X_i$ 描述），一部分来自未来输入 $U_f$（由 $\mathcal{T}_i U_f$ 描述），以及噪声部分 $V_f$。我们的任务是从这个混合的信号中分离出状态信息 $\mathcal{O}_i X_i$。

### 核心原理：投影与状态信息

直接从上述数据方程求解状态序列 $X_i$ 是不可能的，因为它是一个未知的内部变量。此外，噪声 $V_f$ 的存在使得简单的最小二乘法会产生有偏估计。[子空间方法](@entry_id:200957)通过一个精妙的几何操作——**投影（projection）**——来解决这个问题。

其基本思想是找到一个与噪声和（部分）输入不相关的“工具”，然后将数据投影到由这个工具所定义的空间中。这类似于在统计学中使用**[工具变量](@entry_id:142324)（Instrumental Variables, IV）**来处理[回归模型](@entry_id:163386)中解释变量与误差项相关的问题。

我们可以通过一个简单的例子来理解[工具变量法](@entry_id:204495)的精髓。考虑一个单输入单输出（SISO）[有限脉冲响应](@entry_id:192542)（FIR）系统：$y(k) = g u(k-1) + v(k)$，其中 $v(k)$ 是与过去输入 $u$ 无关的零均值噪声。我们的目标是估计参数 $g$。如果我们将所有数据点写成向量形式 $Y_f = U_p g + V$，直接使用[普通最小二乘法](@entry_id:137121)（OLS）求解 $\hat{g} = (U_p^T U_p)^{-1} U_p^T Y_f$ 是有偏的，因为输出 $y(k)$ 中包含的噪声 $v(k)$ 可能会反馈到未来的输入中，导致 $U_p$ 和 $V$ 相关。

[工具变量法](@entry_id:204495)引入一个与噪声 $V$ 不相关但与回归量 $U_p$ 相关的工具向量 $Z$。通过强制残差 $Y_f - U_p \hat{g}_{\mathrm{IV}}$ 与工具 $Z$ 正交，即 $Z^T(Y_f - U_p \hat{g}_{\mathrm{IV}}) = 0$，我们可以得到一个[无偏估计](@entry_id:756289)。在许多情况下，过去的输入本身就是一个很好的[工具变量](@entry_id:142324)。例如，在问题 [@problem_id:2908761] 中，我们就选择 $Z = U_p$，因为问题设定噪声与过去输入无关。求解该[正交性条件](@entry_id:168905)可得IV估计量：
$$
\hat{g}_{\mathrm{IV}} = (Z^T U_p)^{-1} Z^T Y_f = (U_p^T U_p)^{-1} U_p^T Y_f
$$
在这个特定例子中，它与OLS形式相同，但其背后的统计假设和保证是不同的，并且在更复杂的情况下（例如包含[输出反馈](@entry_id:271838)时），$Z$ 的选择会与 $U_p$ 不同。[@problem_id:2908761]

[子空间辨识](@entry_id:188076)方法将这一思想推广到MIMO[状态空间模型](@entry_id:137993)。它们将过去的数据（$U_p, Y_p$）组合成一个[工具变量](@entry_id:142324)矩阵 $W_p$，并利用它来从 $Y_f$ 中分离出与未来输入 $U_f$ 无关的部分。这个操作在几何上等价于将 $Y_f$ 的行[向量投影](@entry_id:147046)到一个特定的[子空间](@entry_id:150286)上。投影后的数据将主要包含状态信息，即 $\mathcal{O}_i X_i$ 的估计。

### 主要[子空间](@entry_id:150286)算法：MOESP 和 [N4SID](@entry_id:187363)

在[子空间方法](@entry_id:200957)的大家族中，MOESP和[N4SID](@entry_id:187363)是两种主流的算法，它们的主要区别在于投影方式，即它们选择的工具变量空间不同。[@problem_id:2908772]

- **MOESP (Multivariable Output-Error State sPace)** 系列算法：MOESP的目标是估计一个与未来输入 $U_f$ 正交的未来输出分量。它通常使用过去数据 $W_p = \begin{pmatrix} U_p \\ Y_p \end{pmatrix}$ 作为工具变量。其核心步骤是计算 $Y_f$ 在 $U_f$ 的[正交补](@entry_id:149922)空间上的投影，记为 $Y_f / U_f^\perp$。这个投影消除了未来输入 $U_f$ 的直接影响，留下的主要是状态的贡献。

- **[N4SID](@entry_id:187363) (Numerical algorithms for Subspace State Space System Identification)** 系列算法：[N4SID](@entry_id:187363)采用了一个更具包容性的投影。它将未来输出 $Y_f$ 投影到过去和未来输入 $(U_p, U_f)$ 共同张成的空间的正交补上。这相当于使用了一个更“纯净”的过去信息，即 $W_p = \begin{pmatrix} U_p \\ U_f \\ Y_p \end{pmatrix}$。通过将 $Y_f$ 投影到 $W_p$ 的行空间上，可以得到一个关于状态信息的估计。

虽然这些方法的具体代数步骤不同，但它们的共同目标都是分离出包含扩展可观测矩阵 $\mathcal{O}_i$ 和状态序列 $X_i$ 信息的项。这个投影后的矩阵是后续阶次确定和系统参数估计的基础。

### 通过SVD进行系统阶次和状态序列估计

一旦通过投影得到了一个净化后的数据矩阵（我们称之为 $\mathcal{Y}$），接下来的关键一步就是确定系统的阶次 $n$。一个核心的理论结果是，在无噪声的情况下，这个[矩阵的秩](@entry_id:155507)（rank）恰好等于系统的最小阶次 $n$。
$$
\mathrm{rank}(\mathcal{Y}) = \mathrm{rank}(\mathcal{O}_i X_i) = n
$$
这个性质源于 $\mathcal{O}_i$ 是一个高瘦矩阵（$pi \times n$），$X_i$ 是一个扁胖矩阵（$n \times j$），并且在输入[持续激励](@entry_id:263834)和系统最小化的假设下，两者都是满秩的。

在实践中，由于噪声和有限数据的影响，投影后的矩阵 $\mathcal{Y}$ 几乎总是满秩的。因此，我们需要一个稳健的工具来估计其“有效秩”。**[奇异值分解](@entry_id:138057)（Singular Value Decomposition, SVD）** 正是完成此任务的理想工具。SVD将矩阵 $\mathcal{Y}$ 分解为：
$$
\mathcal{Y} = U \Sigma V^T = \begin{pmatrix} U_1  U_2 \end{pmatrix} \begin{pmatrix} \Sigma_1  0 \\ 0  \Sigma_2 \end{pmatrix} \begin{pmatrix} V_1^T \\ V_2^T \end{pmatrix}
$$
其中 $U$ 和 $V$ 是[正交矩阵](@entry_id:169220)，$\Sigma$ 是一个[对角矩阵](@entry_id:637782)，其对角线上的元素 $\sigma_1 \ge \sigma_2 \ge \dots \ge 0$ 称为**[奇异值](@entry_id:152907)**。

理论上，对于一个 $n$ 阶系统，在无噪声时，只有前 $n$ 个[奇异值](@entry_id:152907)非零。在有噪声的情况下，[奇异值](@entry_id:152907)会分为两组：前 $n$ 个较大的[奇异值](@entry_id:152907)，对应于系统的动态；以及其余较小的[奇异值](@entry_id:152907)，主要由噪声贡献。因此，通过观察[奇异值](@entry_id:152907)的大小，我们可以估计系统阶次。通常绘制的奇异值“[碎石图](@entry_id:143396)”（scree plot）会显示一个明显的“拐点”，这个[拐点](@entry_id:144929)的位置就是阶次的估计值。

更重要的是，SVD不仅给出了阶次，还提供了状态信息的估计。与前 $n$ 个最大奇异值 $\Sigma_1$ 对应的[左奇异向量](@entry_id:751233) $U_1$ 张成了一个与扩展可观测矩阵 $\mathcal{O}_i$ 的[列空间](@entry_id:156444)相同的[子空间](@entry_id:150286)。因此，我们可以得到 $\mathcal{O}_i$ 的一个估计（相差一个非奇异变换）：
$$
\hat{\mathcal{O}}_i = U_1 \Sigma_1^{1/2}
$$

### 模型阶次选择的实践挑战

在理论和实践之间，阶次选择是一座充满挑战的桥梁。噪声的存在模糊了系统[奇异值](@entry_id:152907)与噪声[奇异值](@entry_id:152907)之间的界限，使得“拐点”不总是清晰可辨。因此，需要更系统化的方法来选择模型阶次 $n$。问题 [@problem_id:2908765] 探讨了几种常用策略的有效性，特别是它们的**[渐近一致性](@entry_id:176716)（asymptotic consistency）**，即当数据量 $N \to \infty$ 时，估计的阶次 $\hat{n}$ 收敛到真实阶次 $n_\star$ 的概率是否为1。

1.  **启发式方法（不一致）**：
    - **固定阈值法**：选择所有大于某个固定绝对阈值 $\tau$ 的[奇异值](@entry_id:152907)数量作为阶次。这种方法不可靠，因为噪声奇异值的量级取决于未知的噪声[方差](@entry_id:200758)，一个固定的阈值无法普适。
    - **最大[奇异值](@entry_id:152907)间隙法**：选择使奇异值间隙 $\sigma_k - \sigma_{k+1}$ 最大的索引 $k$ 作为阶次。这是一种流行的启发式方法，但它不保证一致性。例如，系统可能有两个非常接近的模态，导致对应的[奇异值](@entry_id:152907)间隙很小，甚至小于噪声引起的间隙。[@problem_id:2908765]

2.  **基于[信息准则](@entry_id:636495)的方法（部分一致）**：
    - **AIC（Akaike Information Criterion）**：$AIC(n) = -2\ln(\mathcal{L}_n) + 2 p_n$，其中 $\mathcal{L}_n$ 是模型的[最大似然](@entry_id:146147)， $p_n$ 是参数数量。AIC不是一致的阶次估计器，因为它对[模型复杂度](@entry_id:145563)的惩罚力度不够，随着数据量的增加，它有非零的概率选择一个过参数化的模型（$\hat{n} > n_\star$）。
    - **BIC（Bayesian Information Criterion）**：$BIC(n) = -2\ln(\mathcal{L}_n) + p_n \ln(N)$。BIC是**一致的**。其惩罚项随数据量 $N$ 的对数增长，这足以在 $N$ 很大时抑制过参数化。当模型阶次 $n \ge n_\star$ 时，[似然](@entry_id:167119)的增加不足以抵消惩罚项的增长，因此BIC倾向于选择最简约的正确模型。[@problem_id:2908765]

3.  **稳定图（Stabilization Diagrams）**：
    这是一种强大的图形化工具。通过对一系列候选阶次 $n$ 估计模型，并绘制出每个模型的极点（[系统动力学](@entry_id:136288)模式）。真实系统的物理极点应该在所有 $n \ge n_\star$ 的模型中稳定出现，而由噪声过拟合产生的“伪”极点则会随着 $n$ 的变化而剧烈跳动。如果将这种视觉检查形式化为一个统计检验，并且其[显著性水平](@entry_id:170793) $\alpha_N$ 随着 $N \to \infty$ 而趋于零，那么这种方法也是**一致的**。[@problem_id:2908765]

### 实现：从[子空间](@entry_id:150286)到[状态空间](@entry_id:177074)矩阵

在确定了系统阶次 $n$ 并获得了扩展可观测矩阵的估计 $\hat{\mathcal{O}}_i$ 之后，最后一步就是求解[状态空间](@entry_id:177074)矩阵 $(A, B, C, D)$。这个过程称为**系统实现（system realization）**。

1.  **估计 $C$**：扩展可观测矩阵的第一块行就是输出矩阵 $C$。因此，$\hat{C}$ 就是 $\hat{\mathcal{O}}_i$ 的前 $p$ 行。

2.  **估计 $A$**：这一步利用了 $\mathcal{O}_i$ 的**[移位不变性](@entry_id:754776)（shift-invariance property）**。$\mathcal{O}_i$ 的结构为 $\begin{pmatrix} C \\ CA \\ \vdots \\ CA^{i-1} \end{pmatrix}$。如果我们移除它的第一块行，得到 $\underline{\mathcal{O}}_i = \begin{pmatrix} CA \\ \vdots \\ CA^{i-1} \end{pmatrix}$；如果我们移除它的最后一块行，得到 $\overline{\mathcal{O}}_i = \begin{pmatrix} C \\ \vdots \\ CA^{i-2} \end{pmatrix}$。显然，它们之间满足关系 $\overline{\mathcal{O}}_i A = \underline{\mathcal{O}}_i$。因此，我们可以通过求解一个最小二乘问题来估计 $A$：
    $$
    \hat{A} = (\overline{\hat{\mathcal{O}}}_i^\dagger) \underline{\hat{\mathcal{O}}}_i
    $$
    其中 $\dagger$ 表示[伪逆](@entry_id:140762)。

3.  **估计 $B$ 和 $D$**：一旦获得了 $\hat{A}$ 和 $\hat{C}$，我们可以回到原始的[状态空间方程](@entry_id:266994)。通过将状态序列 $X_i$ 也从子[空间分解](@entry_id:755142)中估计出来（例如，$\hat{X}_i = \hat{\mathcal{O}}_i^\dagger Y_f^{\text{proj}}$），整个系统方程 $Y_f = \mathcal{O}_i X_i + \mathcal{T}_i U_f$ 就变成了一个关于 $B$ 和 $D$（它们隐含在 $\mathcal{T}_i$ 中）的超定线性方程组。这个问题同样可以通过一个全局[最小二乘法](@entry_id:137100)来求解。

### 与脉冲响应和马尔可夫参数的联系

[子空间方法](@entry_id:200957)与经典的基于脉冲响应的实现理论（如[Ho-Kalman算法](@entry_id:167035)）有着深刻的联系。系统的**马尔可夫参数（Markov parameters）** $\{G_k\}_{k=0}^\infty$ 就是其脉冲响应序列，它们与[状态空间](@entry_id:177074)矩阵的关系为：
$$
G_0 = D, \quad G_k = C A^{k-1} B \quad \text{for } k \ge 1
$$
如问题 [@problem_id:2908763] 所示，系统辨识可以分两步进行：
1.  **估计马尔可夫参数**：将系统近似为一个高阶[有限脉冲响应](@entry_id:192542)（FIR）模型 $y_t \approx \sum_{k=0}^{L-1} G_k u_{t-k}$。然后，可以通过对输入输出数据进行线性[最小二乘拟合](@entry_id:751226)来估计前 $L$ 个马尔可夫参数 $\{\hat{G}_k\}$。
2.  **系统实现**：利用估计出的马尔可夫参数构建一个块汉克尔矩阵 $H(\hat{G})$。根据Ho-Kalman理论，这个矩阵的秩等于系统阶次 $n$。然后，可以从这个汉克尔矩阵中分解出 $\mathcal{O}_i$ 和 $\mathcal{C}_i$（[可控性矩阵](@entry_id:271824)），并最终求解出 $(A, B, C)$。[@problem_id:2908763]

直接的[子空间方法](@entry_id:200957)（如[N4SID](@entry_id:187363)）可以看作是对这个两步过程的改进。它们不显式地计算马尔可夫参数，而是通过对输入输出数据的汉克尔矩阵进行一次投影和SVD，直接得到状态[子空间](@entry_id:150286)，这在数值上通常更为稳健和高效。然而，理解这种联系有助于从更广阔的视角把握[子空间辨识](@entry_id:188076)的本质。

### 算法实现与计算复杂度

将理论转化为可靠的数值软件时，算法的选择和[计算效率](@entry_id:270255)至关重要。问题 [@problem_id:2908772] 深入探讨了不同[子空间](@entry_id:150286)算法变体的计算成本。主要的设计选择涉及如何执行核心的投影操作，以及如何选择窗口长度 $i$。

**投影的实现**：

- **基于[QR分解](@entry_id:139154)的方法**：这种方法通过对工具变量矩阵进行QR分解来获得一个[正交基](@entry_id:264024)，然后用这个基来执行投影。QR分解以其优越的**数值稳定性**而著称，尤其是在处理[病态问题](@entry_id:137067)时。其计算成本主要由[QR分解](@entry_id:139154)和正交变换矩阵的应用主导。对于一个 $a \times b$ 的矩阵（假设 $a \ge b$），QR分解的浮点运算（flop）次数约为 $O(ab^2)$。[@problem_id:2908772]

- **基于正规方程的方法**：这种方法首先形成[工具变量](@entry_id:142324)矩阵的[格拉姆矩阵](@entry_id:203297)（Gram matrix），例如 $W_p W_p^T$，然后通过[求解线性方程组](@entry_id:169069)（通常使用[Cholesky分解](@entry_id:147066)）来应用[投影算子](@entry_id:154142)。当数据长度 $j$ 远大于工具变量的行数 $r$ 时（$j \gg r$），这种方法通常比QR分解**计算速度更快**。然而，它的一个主要缺点是[数值稳定性](@entry_id:146550)较差，因为计算[格拉姆矩阵](@entry_id:203297)会使问题的**[条件数](@entry_id:145150)平方**，可能放大数值误差。[@problem_id:2908772]

**设计参数的影响**：

窗口长度 $i$ 是一个关键的设计参数。它不仅影响辨识的精度（$i$ 必须足够大以包含系统的所有动态，通常要求 $i \ge n$），还直接影响计算的复杂度。如问题 [@problem_id:2908772] 中的分析所示，增大 $i$ 会增加汉克尔矩阵的行数（$mi, pi$）和[工具变量](@entry_id:142324)的行数 $r$，但会减少列数 $j = N - 2i + 1$。这会对QR分解、SVD等步骤的计算量产生复杂的影响。因此，在实践中，选择最优的算法变体和参数 $i$ 需要在精度、稳定性和计算成本之间进行权衡。对这些成本进行建模和分析，是设计高效系统辨识流程的重要组成部分。