## 引言
在我们的日常世界和科学探索中，我们常常面对的是混合在一起的信号，而非纯净的源。想象一下，在嘈杂的鸡尾酒会中分辨出特定某人的谈话声，或从孕妇腹部的微弱电信号中提取胎儿的心跳——这些都是典型的[信号分离](@entry_id:754831)挑战。[盲源分离](@entry_id:196724)（Blind Source Separation, BSS），特别是其核心方法[独立成分分析](@entry_id:261857)（ICA），提供了一套强大的统计学框架，能够在对源信号或混合过程知之甚少（即“盲”）的情况下，从观测到的混[合数](@entry_id:263553)据中恢复出隐藏的原始信号。其重要性不言而喻，它使得我们能够揭示原本被掩盖在复杂数据背后的、具有物理或生理意义的深层结构。

本文将带领读者系统性地探索BSS与ICA的理论与实践。我们的旅程将分为三个部分：
- 在第一章**“原则与机理”**中，我们将深入其数学核心，探讨[统计独立性](@entry_id:150300)、非高斯性等基本原则，理解算法为何以及何时能够成功，并剖析包括非高斯性最大化和最大似然估计在内的关键算法机制。
- 接着，在第二章**“应用与跨学科连接”**中，我们将把视野投向现实世界，展示BSS/ICA如何在[声学](@entry_id:265335)处理、[生物医学工程](@entry_id:268134)和神经科学等多个前沿领域解决实际问题，并介绍为应对更复杂场景而发展的理论变体。
- 最后，在第三章**“动手实践”**中，您将通过具体的计算任务，将理论知识转化为解决问题的实践能力，加深对BSS/ICA性能评估与内在局限性的理解。

通过这一系列的学习，您将不仅掌握BSS/ICA的核心思想，更能洞悉其在现代信号处理和数据科学中的强大威力与广阔前景。

## 原则与机理

在上一章引言的基础上，本章将深入探讨[盲源分离](@entry_id:196724)（BSS）和[独立成分分析](@entry_id:261857)（ICA）背后的核心科学原则与关键机制。我们将从问题的数学基石——[统计独立性](@entry_id:150300)出发，逐步揭示该问题何时有解（即可辨识性），并详细阐述两种主要的[算法设计](@entry_id:634229)思路：非高斯性最大化和最大似然估计。此外，我们还将讨论一个至关重要的预处理技术——白化，并最终将视野拓展到标准模型之外，探讨当观测数量少于信源数量时的欠定情况及其解决方法。

### 问题的数学核心：[统计独立性](@entry_id:150300)

[独立成分分析](@entry_id:261857)的核心假设是，构成混合信号的各个源信号（即“独立成分”）在统计上是[相互独立](@entry_id:273670)的。理解这一概念的精确含义，并将其与相关但较弱的统计性质区分开来，是掌握ICA的先决条件。

**[统计独立性](@entry_id:150300) (Statistical Independence)** 的正式定义是，一组[随机变量](@entry_id:195330) $s_1, \dots, s_n$ 是相互独立的，当且仅当它们的[联合概率密度函数](@entry_id:267139) (joint probability density function, PDF) 等于各自边缘[概率密度函数](@entry_id:140610) (marginal PDF) 的乘积。若记 $s = (s_1, \dots, s_n)^\top$ 为信源向量，则其联合密度 $p_{\mathbf{s}}(s_1, \dots, s_n)$ 满足：

$$
p_{\mathbf{s}}(s_1, \dots, s_n) = \prod_{i=1}^{n} p_{s_{i}}(s_{i})
$$

其中 $p_{s_{i}}(s_{i})$ 是第 $i$ 个信源的边缘密度。一个等价的、在理论分析中同样重要的判据是通过特征函数 (characteristic function) 来表述。若 $\varphi_{\mathbf{s}}(\mathbf{t}) = \mathbb{E}[\exp(i\mathbf{t}^{\top}\mathbf{s})]$ 是联合[特征函数](@entry_id:186820)，$\varphi_{s_{i}}(t_{i}) = \mathbb{E}[\exp(it_{i}s_{i})]$ 是边缘[特征函数](@entry_id:186820)，则[统计独立性](@entry_id:150300)等价于联合[特征函数](@entry_id:186820)的[因式分解](@entry_id:150389) [@problem_id:2855427]：

$$
\varphi_{\mathbf{s}}(\mathbf{t}) = \prod_{i=1}^{n} \varphi_{s_{i}}(t_{i})
$$

为了在实践中度量和利用独立性，我们常常需要借助更高阶的统计量。**[累积量](@entry_id:152982) (Cumulants)** 在此扮演了关键角色。累积量是通过[累积量生成函数](@entry_id:748109) $K_{\mathbf{s}}(\mathbf{t}) = \ln \varphi_{\mathbf{s}}(\mathbf{t})$ 的[泰勒展开](@entry_id:145057)系数定义的。对于独立的[随机变量](@entry_id:195330)，其联合[累积量生成函数](@entry_id:748109)是边缘[累积量生成函数](@entry_id:748109)的和：

$$
K_{\mathbf{s}}(\mathbf{t}) = \ln\left(\prod_{i=1}^{n} \varphi_{s_{i}}(t_{i})\right) = \sum_{i=1}^{n} \ln \varphi_{s_{i}}(t_{i}) = \sum_{i=1}^{n} K_{s_{i}}(t_{i})
$$

这个和的形式意味着，联合[累积量生成函数](@entry_id:748109)的泰勒展开中不存在包含不同变量的交叉项（如 $t_i t_j$，$i \neq j$）。因此，一个至关重要的结论是：**一组[随机变量](@entry_id:195330)相互独立的充分必要条件是，它们的所有混合阶[累积量](@entry_id:152982) (mixed-order cumulants) 均为零**。混合阶累积量是指阶数至少为2，且涉及至少两个不同[随机变量](@entry_id:195330)的累积量，例如 $\operatorname{cum}(s_i, s_j)$ 或 $\operatorname{cum}(s_i, s_j, s_k)$ 其中 $i, j, k$ 不全相同 [@problem_id:2855427]。

相比之下，**不相关性 (Uncorrelatedness)** 是一个远为宽松的条件。两个零均值[随机变量](@entry_id:195330) $s_i$ 和 $s_j$ ($i \neq j$) 被称为不相关，如果它们的协[方差](@entry_id:200758)为零，即 $\operatorname{Cov}(s_i, s_j) = \mathbb{E}[s_i s_j] - \mathbb{E}[s_i]\mathbb{E}[s_j] = 0$。对于零均值变量，这简化为 $\mathbb{E}[s_i s_j] = 0$。如果一个随机向量的所有成分两两不相关，则其[协方差矩阵](@entry_id:139155)是对角阵。从[累积量](@entry_id:152982)的角度看，两个变量不相关意味着它们的二阶混合累积量为零：$\operatorname{cum}(s_i, s_j) = 0$。[统计独立性](@entry_id:150300)要求所有阶数的混合累积量都为零，因此独立性必然蕴含不相关性。然而，反之不成立——存在大量[随机变量](@entry_id:195330)，它们彼此不相关，但并非[相互独立](@entry_id:273670) [@problem_id:2855427]。

我们可以将不相关性的概念推广到更高阶。称一组[随机变量](@entry_id:195330)**最高 $k$ 阶不相关**，如果它们所有阶数从 $2$ 到 $k$ 的混合累积量都为零。即便如此，对于任何有限的 $k$，最高 $k$ 阶不相关仍然是一个比[统计独立性](@entry_id:150300)弱的条件。总能构造出这样一组[随机变量](@entry_id:195330)，它们的依赖关系仅体现在 $k+1$ 阶或更高阶的累积量中 [@problem_id:2855427] [@problem_id:2855427]。因此，ICA所追求的“独立”目标，在数学上是比仅仅消除[二阶相关](@entry_id:190427)性（如[主成分分析PCA](@entry_id:173144)所做的）或高阶相关性远为严格和强大的约束。

为了更具体地理解累积量，我们以四阶[累积量](@entry_id:152982)为例。对于零均值[随机变量](@entry_id:195330) $y_i, y_j, y_k, y_\ell$，它们的四阶联合累积量可以通过矩 (moments) 来表示。通过对[累积量生成函数](@entry_id:748109)求四次偏导，可以推导出如下关系式 [@problem_id:2855507]：

$$
\operatorname{cum}(y_i, y_j, y_k, y_\ell) = \mathbb{E}[y_i y_j y_k y_\ell] - \mathbb{E}[y_i y_j]\mathbb{E}[y_k y_\ell] - \mathbb{E}[y_i y_k]\mathbb{E}[y_j y_\ell] - \mathbb{E}[y_i y_\ell]\mathbb{E}[y_j y_k]
$$

这个公式清晰地展示了累积量是如何衡量[高阶统计量](@entry_id:193349)偏离独立性假设下[期望值](@entry_id:153208)的程度。如果这些变量是[相互独立](@entry_id:273670)的，那么 $\mathbb{E}[y_i y_j y_k y_\ell]$ 将会根据变量的配对情况分解为二阶矩的乘积，从而使得整个表达式为零。例如，如果 $i, j, k, \ell$ 两两不同，独立性意味着 $\mathbb{E}[y_i y_j y_k y_\ell] = \mathbb{E}[y_i]\mathbb{E}[y_j]\mathbb{E}[y_k]\mathbb{E}[y_\ell] = 0$，且所有二阶矩的期望也都为零，因此累积量为零。

### 可辨识性问题：我们能解决这个问题吗？

在确立了[统计独立性](@entry_id:150300)的核心地位之后，下一个自然的问题是：在 noiseless [线性混合模型](@entry_id:139702) $x = A s$ 中，仅根据观测数据 $x$ 和源信号 $s$ 的独立性假设，我们是否能够唯一地确定混合矩阵 $A$ 并恢复源信号 $s$？这个问题被称为 **[可辨识性](@entry_id:194150) (identifiability)** 问题。

答案是肯定的，但有两个重要的前提条件，并且存在固有的模糊性。首先，我们无法确定源信号的真实幅度和符号。这是因为，对于任何可逆的对角矩阵 $D$ 和[置换矩阵](@entry_id:136841) $P$，我们可以将模型重写为：

$$
x = A s = (A P D) (D^{-1} P^\top s) = A' s'
$$

新的混合矩阵是 $A' = A P D$，新的源信号是 $s' = D^{-1} P^\top s$。由于 $s$ 的分量是[相互独立](@entry_id:273670)的，$s'$ 的分量（只是对 $s$ 的分量进行了重新排序和缩放）也同样是相互独立的。因此，从观测数据 $x$ 来看，$A'$ 和 $s'$ 与原始的 $A$ 和 $s$ 是无法区分的。这意味着ICA的解最多只能在不确定的**[置换](@entry_id:136432) (permutation)** 和 **尺度 (scaling)** 意义下是唯一的 [@problem_id:2855517]。

更关键的第二个前提条件与源信号的[概率分布](@entry_id:146404)有关。这一条件源于一个深刻的统计学事实，即高斯分布的特殊性。可辨识性的核心结论是：**在线性瞬时混合模型中，若要使ICA问题可辨识（在[置换](@entry_id:136432)和尺度模糊性之外），则最多只能有一个源信号是[高斯分布](@entry_id:154414)的** [@problem_id:2855517]。

这一结论的根源在于[高斯随机向量](@entry_id:635820)的[旋转不变性](@entry_id:137644)。一个由多个独立标准[高斯变量](@entry_id:276673)构成的向量，在经过任意[正交变换](@entry_id:155650)（旋转或反射）后，其结果仍然是一个由多个独立标准[高斯变量](@entry_id:276673)构成的向量。

我们可以通过一个具体的例子来阐明这一点。假设我们有一个三维的混合系统，其中两个源信号 $s_1, s_2$ 是独立的标准[高斯分布](@entry_id:154414)，而第三个源信号 $s_3$ 是非[高斯分布](@entry_id:154414)。假设混合矩阵是单位阵，即观测值等于源信号 $x = s$。现在，考虑一个在 $(s_1, s_2)$ [子空间](@entry_id:150286)中的任意旋转：

$$
M(\theta) = \begin{pmatrix} \cos(\theta) & -\sin(\theta) & 0 \\ \sin(\theta) & \cos(\theta) & 0 \\ 0 & 0 & 1 \end{pmatrix}
$$

我们定义一组新的源信号 $s' = M(\theta) s$。由于 $s_1, s_2$ 的联合分布具有旋转对称性，新的分量 $s'_1, s'_2$ 依然是[相互独立](@entry_id:273670)的标准[高斯变量](@entry_id:276673)。同时，$s'_3 = s_3$ 保持不变，且由于它与 $(s_1, s_2)$ 独立，它也与 $(s'_1, s'_2)$ 独立。因此，对于任意旋转角度 $\theta$，我们都得到了一组新的、完全合法的独立成分 $s'$。这意味着原始的观测 $x$ 可以被分解为 $x = M(\theta)^{-1} s'$。这表明存在无穷多个有效的混合矩阵（由 $A'(\theta) = M(\theta)^{-1}$ 参数化），这与可辨识性的要求相悖 [@problem_id:2855457]。

这个例子揭示了一个普遍的规律：由多个[高斯源](@entry_id:271482)张成的[子空间](@entry_id:150286)内部存在旋转模糊性，无法被ICA分解。然而，非[高斯源](@entry_id:271482)所张成的[子空间](@entry_id:150286)与[高斯源](@entry_id:271482)所张成的[子空间](@entry_id:150286)是可以被分离开的。因此，即使在存在[高斯源](@entry_id:271482)的情况下，ICA仍然可以识别出非[高斯源](@entry_id:271482)所在的方向（[子空间](@entry_id:150286)）以及[高斯源](@entry_id:271482)作为一个整体所占据的[子空间](@entry_id:150286) [@problem_id:2855457]。

总结来说，**非高斯性 (non-Gaussianity)** 是ICA能够工作的根本原因。正是由于非[高斯分布](@entry_id:154414)在混合下会改变其统计特性，我们才得以找到一种“逆转”混合的方法。

### 算法原理 I：非高斯性最大化

既然非高斯性是[可辨识性](@entry_id:194150)的关键，一个自然的算法思路就是去寻找一种线性变换，使得变换后得到的信号分量“尽可能地非高斯”。这一思想被称为 **非高斯性最大化 (maximization of non-Gaussianity)**。

这个原理的理论基石是 **[中心极限定理](@entry_id:143108) (Central Limit Theorem, CLT)**。CLT告诉我们，大量独立的[随机变量](@entry_id:195330)之和（经过适当的标准化后），其[分布](@entry_id:182848)会趋向于高斯分布，无论[原始变量](@entry_id:753733)的[分布](@entry_id:182848)是什么。在ICA的背景下，一个混合信号 $x_i = \sum_{j=1}^n a_{ij} s_j$ 正是多个独立源信号 $s_j$ 的[线性组合](@entry_id:154743)。因此，根据CLT的精神，混合信号 $x_i$ 的[分布](@entry_id:182848)通常会比任何一个原始的非[高斯源](@entry_id:271482)信号 $s_j$ 的[分布](@entry_id:182848)“更接近”[高斯分布](@entry_id:154414) [@problem_id:2855467]。

反过来思考，如果我们找到了一个投影方向 $w$，使得投影后的信号 $y = w^\top x$ 的[分布](@entry_id:182848)是所有可能投影中最“非高斯”的，那么这个 $y$ 很有可能就对应着某一个原始的源信号 $s_i$。

为了将这个思想转化为算法，我们需要一个量化的非高斯性度量，也称为 **对比函数 (contrast function)**。常用的度量有两个：

1.  **[峰度](@entry_id:269963) (Kurtosis)**：峰度是四阶[标准化](@entry_id:637219)累积量，记作 $\operatorname{kurt}(y)$。对于一个零均值、单位[方差](@entry_id:200758)的[随机变量](@entry_id:195330) $y$，其[峰度](@entry_id:269963)定义为 $\operatorname{kurt}(y) = \mathbb{E}[y^4] - 3$。[高斯分布](@entry_id:154414)的峰度恰好为0。因此，[峰度](@entry_id:269963)的[绝对值](@entry_id:147688) $| \operatorname{kurt}(y) |$ 可以作为非高斯性的一个简单度量。对于独立源 $s_i$ 的[线性组合](@entry_id:154743) $y = \sum_i b_i s_i$（其中 $\sum b_i^2 = 1$），其峰度具有加权求和的性质：$\operatorname{kurt}(y) = \sum_i b_i^4 \operatorname{kurt}(s_i)$。由于 $\sum b_i^4 \le (\sum b_i^2)^2 = 1$（仅当一个 $b_i$ 为 $\pm 1$ 时取等），混合信号的绝对峰度总是不超过所有源信号中的最大绝对[峰度](@entry_id:269963)。因此，通过寻找使投影信号绝对[峰度](@entry_id:269963)最大化的方向，我们就能找到其中一个源信号 [@problem_id:2855467]。

2.  **[负熵](@entry_id:194102) (Negentropy)**：[负熵](@entry_id:194102)是一个源于信息论的、更为稳健的非高斯性度量。一个[随机变量](@entry_id:195330) $y$ 的[微分熵](@entry_id:264893)定义为 $H(y) = -\int p_y(u) \ln p_y(u) du$。信息论的一个基本结论是：在所有具有相同[方差](@entry_id:200758)的[随机变量](@entry_id:195330)中，[高斯变量](@entry_id:276673)的[微分熵](@entry_id:264893)最大。基于此，[负熵](@entry_id:194102) $J(y)$ 定义为同[方差](@entry_id:200758)[高斯变量](@entry_id:276673)的熵与 $y$ 的熵之差：$J(y) = H(y_{\text{gauss}}) - H(y)$。[负熵](@entry_id:194102)恒为非负，且当且仅当 $y$ 是高斯分布时为零。因此，[负熵](@entry_id:194102)越大，非高斯性越强。与[峰度](@entry_id:269963)类似，混合会使得信号更接近高斯分布，从而降低[负熵](@entry_id:194102)。因此，ICA的目标可以设定为寻找使[负熵](@entry_id:194102)最大化的投影 [@problem_id:2855467]。

直接计算[负熵](@entry_id:194102)需要估计整个概率密度函数，这在实践中非常困难。因此，人们通常使用其近似。对于接近高斯分布的信号（即其偏度为零，[峰度](@entry_id:269963) $\kappa$ 很小），可以推导出[负熵](@entry_id:194102)与[峰度](@entry_id:269963)的平方成正比。更一般地，[负熵](@entry_id:194102)可以通过基于非二次对比函数 $G(y)$ 的期望来近似。例如，可以构建一个代理指标 $\widehat{J}_{G}(y) = (\mathbb{E}\{G(y)\} - \mathbb{E}\{G(\nu)\})^2$，其中 $\nu$ 是标准[高斯变量](@entry_id:276673)。对于特定的 $G(y)$，例如 $G(y) = y^4/4$，可以证明当偏度为零时，这个代理指标与 $\kappa^2$ 成正比，即 $\widehat{J}_{G}(y) \sim c \cdot \kappa^2$。例如，对于 $G(y)=y^4/4$，该比例系数为 $c=1/16$ [@problem_id:2855463]。实际算法（如FastICA）中，会根据源信号的[峰度](@entry_id:269963)符号（超高斯，$\kappa>0$ 或亚高斯，$\kappa0$）选择合适的对比函数 $G$ 以获得最佳性能。

### 算法原理 II：[最大似然估计](@entry_id:142509)

除了优化非高斯性度量，ICA问题还可以从一个更具统计基础的角度来解决，即 **最大似然估计 (Maximum Likelihood Estimation, MLE)**。这种方法旨在找到一个解混矩阵 $W$，使得在给定模型假设下，观测数据出现的概率最大。

假设我们已知（或假设）源信号 $s_i$ 的概率密度函数 $p_i$。我们的目标是估计解混矩阵 $W$，使得输出 $y = Wx$ 的分量 $y_i$ [相互独立](@entry_id:273670)，且其[分布](@entry_id:182848)与 $p_i$ 相匹配。根据[可逆线性变换](@entry_id:149915)的变量代换公式，观测数据 $x$ 的概率密度函数 $p_x(x)$ 可以由输出 $y$ 的密度 $p_y(y)$ 导出：

$$
p_x(x; W) = p_y(Wx) |\det W|
$$

由于我们假设输出 $y$ 的分量是独立的，其联合密度是各边缘密度的乘积：$p_y(y) = \prod_{i=1}^n p_i(y_i)$。代入上式，我们得到单个数据点 $x_t$ 的[似然函数](@entry_id:141927)：

$$
p_x(x_t; W) = \left( \prod_{i=1}^n p_i((Wx_t)_i) \right) |\det W|
$$

对于一个包含 $T$ 个[独立同分布](@entry_id:169067)样本的数据集 $\{x_t\}_{t=1}^T$，其总[对数似然函数](@entry_id:168593) $\ell(W)$ 为 [@problem_id:2855514]：

$$
\ell(W) = \sum_{t=1}^T \left( \sum_{i=1}^n \ln p_i((Wx_t)_i) + \ln|\det W| \right)
$$

最大似然估计的目标就是找到使 $\ell(W)$ 最大化的矩阵 $W$。这个目标函数由两部分组成：第一部分 $\sum \ln p_i((Wx_t)_i)$ 鼓励输出 $y_t=Wx_t$ 的[分布](@entry_id:182848)与假设的源信号[分布](@entry_id:182848)相匹配；第二部分是雅可比行列式项 $\ln|\det W|$。

这个 **[雅可比](@entry_id:264467)项 (Jacobian term)** $\ln|\det W|$ 在MLE框架中起着至关重要的作用。它是一个正则化项，可以防止算法陷入平凡解。例如，如果 $W$ 趋向于[零矩阵](@entry_id:155836)，那么所有输出 $y_i$ 都会集中在零附近，如果源信号的PDF在零点处有峰值，这可能会使得第一项增大。然而，当 $W \to 0$ 时，$\det W \to 0$，导致 $\ln|\det W| \to -\infty$。这个无穷大的惩罚项有效地排除了 $W=0$ 或任何其他奇异矩阵作为解的可能性 [@problem_id:2855500]。

通过对[对数似然函数](@entry_id:168593)求梯度，我们可以得到用于梯度上升优化的更新规则。$\ell(W)$ 关于 $W$ 的梯度（或称[得分函数](@entry_id:164520)）为 [@problem_id:2855514]：

$$
\nabla_W \ell(W) = T (W^{-1})^\top + \sum_{t=1}^T g(Wx_t) x_t^\top
$$

其中 $g(y)$ 是一个向量，其元素是 $g_i(y_i) = \frac{d \ln p_i(y_i)}{dy_i}$，即源信号对[数密度](@entry_id:268986)的[得分函数](@entry_id:164520)。在梯度[更新过程](@entry_id:273573)中，[雅可比](@entry_id:264467)项贡献的梯度项 $(W^{-1})^\top$ 在 $W$ 接近奇异时会发散，从而产生一股强大的“排斥力”，将优化过程推离[奇异矩阵](@entry_id:148101)区域，保证了算法的稳定性 [@problem_id:2855500]。

### 一个关键的[预处理](@entry_id:141204)步骤：白化

在应用大多数ICA算法之前，一个标准且极其有用的预处理步骤是 **白化 (whitening)** 或球化 (sphering)。白化的目标是 对观测数据 $x$ 进行[线性变换](@entry_id:149133)，得到一个新的向量 $z = V x$，使得 $z$ 的协方差矩阵为[单位矩阵](@entry_id:156724) $I$，即 $\mathbb{E}[z z^\top] = I$。这意味着 $z$ 的各个分量是不相关的，并且[方差](@entry_id:200758)为1。

白化对ICA问题有深刻的影响。假设源信号 $s$ 本身也是白的（即 $\mathbb{E}[s s^\top] = I$，这可以通过尺度归一化实现），那么观测信号的协方差矩阵为 $C_x = \mathbb{E}[x x^\top] = \mathbb{E}[A s s^\top A^\top] = A A^\top$。[白化变换](@entry_id:637327) $z = Vx$ 满足：

$$
\mathbb{E}[z z^\top] = V \mathbb{E}[x x^\top] V^\top = V (A A^\top) V^\top = (V A) (V A)^\top = I
$$

令 $Q = VA$，上式表明矩阵 $Q$ 是一个 **[正交矩阵](@entry_id:169220) (orthogonal matrix)**，即 $Q Q^\top = I$。这意味着，经过白化之后，原始的、任意的、可逆的混合矩阵 $A$ 被转化为了一个未知的正交矩阵 $Q$。整个ICA问题从寻找一个任意的[可逆矩阵](@entry_id:171829) $W$ 来解混 $x$，简化为在白化空间中寻找一个正交矩阵 $U$ (即 $W=UV$) 来解混 $z = Qs$，使得 $y = Uz = UQs$ 的分量相互独立。由于 $U$ 和 $Q$ 都是[正交矩阵](@entry_id:169220)，它们的乘积 $UQ$ 也必须是一个[置换](@entry_id:136432)和符号变换矩阵，这意味着 $U$ 必须是 $Q^\top$（在[置换](@entry_id:136432)和符号模糊性之外）。

白化带来的好处是多方面的 [@problem_id:2855515]：
1.  **简化问题**：将寻找一个有 $n^2$ 个自由度的任意[可逆矩阵](@entry_id:171829)的问题，简化为寻找一个只有 $n(n-1)/2$ 个自由度的[正交矩阵](@entry_id:169220)的问题，大大降低了问题的复杂性。
2.  **改善优化**：算法可以直接在正交矩阵构成的[特殊几何](@entry_id:194564)空间（Stiefel[流形](@entry_id:153038)）上进行优化，这通常能带来更快的[收敛速度](@entry_id:636873)和更好的[数值稳定性](@entry_id:146550)。
3.  **简化目标函数**：当解混矩阵被约束为正交时，其[行列式](@entry_id:142978)的[绝对值](@entry_id:147688)恒为1。因此，在最大似然估计的目标函数中，[雅可比](@entry_id:264467)项 $\ln|\det W|$ 变为常数0，可以被忽略。这样，算法只需关注与源信号[分布](@entry_id:182848)相关的项，而防止[奇异解](@entry_id:172996)的任务则由正交性约束本身完成 [@problem_id:2855500]。

### 标准模型之外：欠定情况与[稀疏性](@entry_id:136793)

经典ICA框架假设观测信号的数量 $m$ 大于或等于源信号的数量 $n$（即 $m \ge n$）。但是，在许多实际应用中，我们面临的是 **欠定 (underdetermined)** 情况，即传感器数量少于信源数量（$m  n$）。

在这种情况下，经典ICA方法会彻底失效。从线性代数的角度看，混合矩阵 $A$ 是一个 $m \times n$ 的“宽”矩阵。我们希望找到一个 $n \times m$ 的解混矩阵 $W$，使得 $WA$ 恢复单位阵（或[置换](@entry_id:136432)阵）。然而，由于 $\operatorname{rank}(WA) \le \min(\operatorname{rank}(W), \operatorname{rank}(A)) \le m  n$，乘积 $WA$ 必然是奇异的，不可能恢复出所有 $n$ 个独立的信源。从几何上看，$n$ 维的源信号空间被 $A$ 投影到了一个更低的 $m$ 维观测空间，这个过程是不可逆的，信息被永久性地丢失了 [@problem_id:2855448]。

要解决欠定BSS问题，必须引入比[统计独立性](@entry_id:150300)更强的先验假设。当前最成功的方法是利用 **稀疏性 (sparsity)**，这催生了 **[稀疏成分分析](@entry_id:192059) (Sparse Component Analysis, SCA)**。SCA的核心思想是，尽管源信号本身在时域可能不是稀疏的，但它们在某个变换域（如[傅里叶变换](@entry_id:142120)、[小波变换](@entry_id:177196)或其它学习到的字典 $\Psi$）中可能具有稀疏的表示。即 $s(t) = \Psi \alpha(t)$，其中系数向量 $\alpha(t)$ 在大多数时刻 $t$ 只有少数几个非零项。

SCA的解决思路通常分为两步 [@problem_id:2855448]：
1.  **混合矩阵估计**：利用[稀疏性](@entry_id:136793)来估计混合矩阵 $A$。一个关键的观察是，如果在某个时刻 $t$，只有一个源信号是活跃的（即 $\alpha(t)$ 是1-稀疏的），那么观测向量 $x(t)$ 将会与 $A$ 的某一列成正比。通过收集大量这样的观测数据点，对它们进行归一化后，这些点会在[单位球](@entry_id:142558)面上形成若干个聚类，每个[聚类](@entry_id:266727)的中心就对应着混合矩阵 $A$ 的一列（经过归一化）。通过[聚类算法](@entry_id:146720)，就可以估计出整个混合矩阵。
2.  **源[信号恢复](@entry_id:195705)**：一旦混合矩阵 $\widehat{A}$ 被估计出来，对于每一个时刻 $t$，我们需要求解一个欠定的线性方程组 $x(t) = \widehat{A} s(t)$。由于我们假设 $s(t)$ 是稀疏的，我们可以通过求解一个 $\ell_1$-范数最小化问题（称为[基追踪](@entry_id:200728)，Basis Pursuit）来找到最稀疏的解：
    $$
    \min_{\alpha(t)} \|\alpha(t)\|_1 \quad \text{subject to} \quad x(t) = \widehat{A} \Psi \alpha(t)
    $$
    得到稀疏系数 $\widehat{\alpha}(t)$ 后，再通过[逆变](@entry_id:192290)换 $\widehat{s}(t) = \Psi \widehat{\alpha}(t)$ 恢复出源信号。

SCA的成功依赖于严格的数学条件，这些条件关联了源信号的稀疏度 $k$（即非零项的最大数量）与有效混合矩阵 $A\Psi$ 的性质（如其spark或[相互相干性](@entry_id:188177)）。例如，如果 $k  \operatorname{spark}(A\Psi)/2$，则[稀疏解](@entry_id:187463)是唯一的。这保证了在足够稀疏的假设下，即使在欠定情况下也能够唯一地恢复源信号 [@problem_id:2855448]。