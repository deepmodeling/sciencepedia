{"hands_on_practices": [{"introduction": "本练习旨在探讨隐马尔可夫模型（HMM）中两种主要解码方法之间的根本区别。维特比解码（Viterbi decoding）旨在寻找概率最高的单一隐状态序列，即一条全局最优路径。相比之下，后验解码（posterior decoding）在每个独立的时间点上识别最可能的状态，但这些状态组成的序列未必是有效的或全局最优的。本练习通过一个精心设计的场景，具体展示了这两种方法为何会产生不同的结果，从而澄清了在正确应用隐马尔可夫模型时一个至关重要的概念 [@problem_id:2875854]。", "problem": "考虑一个离散时间隐马尔可夫模型 (HMM)，其具有两个隐藏状态 $S_1$ 和 $S_2$ 以及离散观测字母表 $\\{x,y\\}$。该模型由初始分布 $\\boldsymbol{\\pi}$、状态转移矩阵 $A$ 和发射概率 $B$ 指定。根据马尔可夫性质和发射的条件独立性，隐藏路径 $z_{1:T}=(z_1,\\dots,z_T)$ 和观测序列 $o_{1:T}=(o_1,\\dots,o_T)$ 的联合分布可分解为\n$$\np(z_{1:T},o_{1:T}) \\;=\\; \\pi_{z_1}\\, b_{z_1}(o_1)\\, \\prod_{t=2}^{T} a_{z_{t-1},z_t}\\, b_{z_t}(o_t),\n$$\n其中 $a_{i,j}=\\mathbb{P}(z_t=S_j\\mid z_{t-1}=S_i)$ 且 $b_i(o)=\\mathbb{P}(o_t=o\\mid z_t=S_i)$。Viterbi 解码是对隐藏轨迹的最大后验序列估计，而后验解码则是在每个时间点 $t$ 选择一个状态，该状态在给定整个观测序列的情况下能最大化 $z_t$ 的边际后验概率，这可以通过 Baum-Welch 估计算法中期望步骤所使用的前向-后向递归来获得。\n\n给定以下模型参数：\n- 初始分布：$\\boldsymbol{\\pi}=[\\pi_{S_1},\\pi_{S_2}] = [\\,0.4,\\,0.6\\,]$。\n- 转移矩阵：\n$$\nA=\\begin{bmatrix}\na_{11}  a_{12}\\\\\na_{21}  a_{22}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0.99  0.01\\\\\n0.01  0.99\n\\end{bmatrix}.\n$$\n- 发射概率：\n$$\nb_{S_1}(x)=0.99,\\quad b_{S_1}(y)=0.01,\\qquad b_{S_2}(x)=0.01,\\quad b_{S_2}(y)=0.99.\n$$\n对于长度为 $T=2$ 的观测序列 $o_{1:2}=(x,y)$，请选择能够正确且精确地区分 Viterbi 解码与后验解码，并正确识别本例中两种解码状态序列的选项。\n\nA. Viterbi 解码寻找给定观测序列下最可能的整个隐藏轨迹，而后验解码则在每个时间点选择给定完整序列下具有最大边际后验概率的状态。对于指定模型下的 $o_{1:2}=(x,y)$，Viterbi 返回 $(S_2,S_2)$，而后验解码返回 $(S_1,S_2)$。\n\nB. Viterbi 解码和后验解码优化相同的准则，因此结果总是一致。对于 $o_{1:2}=(x,y)$，两者都返回 $(S_2,S_2)$。\n\nC. 后验解码最大化整个隐藏轨迹的后验概率，而 Viterbi 解码最大化每个时间点的边际后验概率。对于 $o_{1:2}=(x,y)$，Viterbi 返回 $(S_1,S_2)$，而后验解码返回 $(S_2,S_2)$。\n\nD. Viterbi 解码寻找最可能的整个隐藏轨迹，而后验解码寻找每个时间点的最大化器，但对于 $o_{1:2}=(x,y)$，Viterbi 返回 $(S_1,S_1)$，而后验解码返回 $(S_1,S_2)$。", "solution": "对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- **模型类型**：离散时间隐马尔可夫模型 (HMM)。\n- **隐藏状态**：$S_1$，$S_2$。\n- **观测字母表**：$\\{x, y\\}$。\n- **模型参数**：\n    - 初始分布：$\\boldsymbol{\\pi} = [\\pi_{S_1}, \\pi_{S_2}] = [0.4, 0.6]$。\n    - 状态转移矩阵：\n    $$\n    A = \\begin{bmatrix} a_{11}  a_{12} \\\\ a_{21}  a_{22} \\end{bmatrix} = \\begin{bmatrix} 0.99  0.01 \\\\ 0.01  0.99 \\end{bmatrix}.\n    $$\n    - 发射概率：\n    $b_{S_1}(x) = 0.99$, $b_{S_1}(y) = 0.01$。\n    $b_{S_2}(x) = 0.01$, $b_{S_2}(y) = 0.99$。\n- **观测序列**：$o_{1:2} = (o_1, o_2) = (x, y)$，长度为 $T=2$。\n- **解码定义**：\n    - **Viterbi 解码**：寻找最可能的整个隐藏轨迹，即 $\\arg\\max_{z_{1:T}} p(z_{1:T} | o_{1:T})$。\n    - **后验解码**：在每个时间点 $t$ 选择使边际后验概率最大化的状态，即 $z_t^* = \\arg\\max_{z_t} p(z_t | o_{1:T})$。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题基于隐马尔可夫模型的标准理论，这是信号处理、统计学和机器学习中的一个核心课题。所有定义和公式都是标准且正确的。\n2.  **适定性**：模型被完全指定。所有必要的参数（$\\boldsymbol{\\pi}, A, B$）和观测序列都已提供。任务是对此特定实例应用两种明确定义的算法，即 Viterbi 解码和后验解码。每种解码方法都存在唯一解。\n3.  **客观性**：问题以精确的数学和数值定义陈述，没有歧义或主观解释。\n4.  **无缺陷**：该问题不违反任何科学原理。概率是非负的，并且在需要时（$A$ 的行、每个状态的发射概率）总和为一。设置是完整、一致且科学合理的。\n\n### 步骤 3：结论与行动\n问题有效。将推导出严谨的解。\n\n### 求解推导\n\n该问题要求我们为给定的 HMM 和观测序列 $o_{1:2}=(x,y)$ 计算两种不同解码方法的结果。\n\n**1. Viterbi 解码**\n\nViterbi 解码寻找单一最可能的隐藏状态序列 $z_{1:2}^* = (z_1^*, z_2^*)$，该序列最大化联合概率 $p(z_{1:2}, o_{1:2})$。这等同于最大化 $p(z_{1:2}|o_{1:2})$，因为对于所有路径，$p(o_{1:2})$ 是一个常数因子。长度为 $T=2$ 的序列的联合概率公式为：\n$$p(z_1, z_2, o_1, o_2) = \\pi_{z_1} b_{z_1}(o_1) a_{z_1, z_2} b_{z_2}(o_2)$$\n我们必须在给定 $o_1=x$ 和 $o_2=y$ 的情况下，为所有四种可能的路径 $z_{1:2} \\in \\{(S_1,S_1), (S_1,S_2), (S_2,S_1), (S_2,S_2)\\}$ 计算这个值。\n\n-   路径 $z_{1:2} = (S_1, S_1)$:\n    $p(S_1, S_1, x, y) = \\pi_{S_1} b_{S_1}(x) a_{11} b_{S_1}(y) = (0.4)(0.99)(0.99)(0.01) = 0.0039204$。\n\n-   路径 $z_{1:2} = (S_1, S_2)$:\n    $p(S_1, S_2, x, y) = \\pi_{S_1} b_{S_1}(x) a_{12} b_{S_2}(y) = (0.4)(0.99)(0.01)(0.99) = 0.0039204$。\n\n-   路径 $z_{1:2} = (S_2, S_1)$:\n    $p(S_2, S_1, x, y) = \\pi_{S_2} b_{S_2}(x) a_{21} b_{S_1}(y) = (0.6)(0.01)(0.01)(0.01) = 0.0000006$。\n\n-   路径 $z_{1:2} = (S_2, S_2)$:\n    $p(S_2, S_2, x, y) = \\pi_{S_2} b_{S_2}(x) a_{22} b_{S_2}(y) = (0.6)(0.01)(0.99)(0.99) = 0.0058806$。\n\n比较这些概率：\n$p(S_2, S_2, x, y) = 0.0058806$ 是最大值。\n因此，Viterbi 解码的结果是路径 $(S_2, S_2)$。\n\n**2. 后验解码**\n\n后验解码寻找状态序列 $(z_1^*, z_2^*)$，其中每个状态 $z_t^*$ 是在给定整个观测序列的情况下，在时间 $t$ 单独最可能的状态。\n$$z_t^* = \\arg\\max_{z_t \\in \\{S_1, S_2\\}} p(z_t | o_1, o_2)$$\n为了找到这个序列，我们必须计算边际后验概率 $p(z_t=S_i | o_1, o_2) = \\frac{p(z_t=S_i, o_1, o_2)}{p(o_1, o_2)}$。\n\n首先，我们通过对所有可能路径的联合概率求和来计算观测序列的总概率 $p(o_1, o_2)$：\n$$p(x, y) = \\sum_{z_1, z_2} p(z_1, z_2, x, y) = 0.0039204 + 0.0039204 + 0.0000006 + 0.0058806 = 0.013722$$\n\n现在，我们为每个时间步计算边际后验概率。\n\n-   对于 $t=1$:\n    我们需要比较 $p(z_1=S_1 | x, y)$ 和 $p(z_1=S_2 | x, y)$。\n    联合概率 $p(z_1=S_1, x, y)$ 是所有以 $S_1$ 开始的路径的概率之和：\n    $p(z_1=S_1, x, y) = p(S_1, S_1, x, y) + p(S_1, S_2, x, y) = 0.0039204 + 0.0039204 = 0.0078408$。\n    联合概率 $p(z_1=S_2, x, y)$ 是所有以 $S_2$ 开始的路径的概率之和：\n    $p(z_1=S_2, x, y) = p(S_2, S_1, x, y) + p(S_2, S_2, x, y) = 0.0000006 + 0.0058806 = 0.0058812$。\n    因为 $p(z_1=S_1, x, y)  p(z_1=S_2, x, y)$，所以相应的后验概率也更大。因此，$z_1^* = S_1$。\n\n-   对于 $t=2$:\n    我们需要比较 $p(z_2=S_1 | x, y)$ 和 $p(z_2=S_2 | x, y)$。\n    联合概率 $p(z_2=S_1, x, y)$ 是所有以 $S_1$ 结束的路径的概率之和：\n    $p(z_2=S_1, x, y) = p(S_1, S_1, x, y) + p(S_2, S_1, x, y) = 0.0039204 + 0.0000006 = 0.003921$。\n    联合概率 $p(z_2=S_2, x, y)$ 是所有以 $S_2$ 结束的路径的概率之和：\n    $p(z_2=S_2, x, y) = p(S_1, S_2, x, y) + p(S_2, S_2, x, y) = 0.0039204 + 0.0058806 = 0.009801$。\n    因为 $p(z_2=S_2, x, y)  p(z_2=S_1, x, y)$，所以相应的后验概率也更大。因此，$z_2^* = S_2$。\n\n因此，后验解码的结果是路径 $(S_1, S_2)$。\n\n### 逐项分析\n\n-   **A.** 此选项正确陈述了定义：Viterbi 寻找最可能的序列，而后验解码寻找逐个状态的最大化器序列。它也正确报告了计算出的序列：Viterbi 返回 $(S_2, S_2)$，而后验解码返回 $(S_1, S_2)$。\n    **结论：正确。**\n\n-   **B.** 此选项错误地声称两种解码方法优化相同的准则并且总是一致。我们的计算提供了一个直接的反例。它也错误地陈述了两种方法都返回 $(S_2, S_2)$。\n    **结论：错误。**\n\n-   **C.** 此选项错误地交换了 Viterbi 解码和后验解码的定义。它也错误地报告了两种方法的结果。\n    **结论：错误。**\n\n-   **D.** 此选项提供了对两种方法的正确描述，但错误地将 Viterbi 解码结果报告为 $(S_1, S_1)$。尽管它正确地识别了后验解码的结果，但 Viterbi 结果的错误使整个选项无效。\n    **结论：错误。**\n\n分析证实，只有选项 A 在其定义和计算方面完全正确。", "answer": "$$\\boxed{A}$$", "id": "2875854"}, {"introduction": "在解码概念的基础上，本练习将深入探讨驱动隐马尔可夫模型推断的数值计算核心。您将亲手执行维特比算法，以找出最可能路径的概率，并运用前向算法（forward algorithm）计算观测序列的总似然。通过这项动手计算，您将清晰地理解生成数据的单一最佳路径的概率与所有可能路径的总概率质量之间的关键区别 [@problem_id:2875864]。", "problem": "考虑一个离散时间隐马尔可夫模型 (HMM)，它具有两个隐状态 $s_1$ 和 $s_2$，一个观测字母表 $\\mathcal{X} = \\{0,1\\}$，以及以下参数：\n- 初始分布 $\\pi$：$\\pi_1 = 0.55$，$\\pi_2 = 0.45$。\n- 状态转移矩阵 $A = [a_{ij}]$，其中 $a_{11} = 0.65$，$a_{12} = 0.35$，$a_{21} = 0.25$，$a_{22} = 0.75$。\n- 发射概率 $b_i(x) = p(x \\mid s_i)$：\n  - 对于状态 $s_1$：$b_1(0) = 0.60$，$b_1(1) = 0.40$。\n  - 对于状态 $s_2$：$b_2(0) = 0.20$，$b_2(1) = 0.80$。\n\n您观测到一个长度为4的序列 $x_{1:4} = (1,0,1,1)$。请仅使用隐马尔可夫模型 (HMM) 的基本定义、马尔可夫性质和条件发射模型所隐含的独立性假设（并且不使用任何缩放），完成以下任务：\n- 为 $x_{1:4}$ 数值化地构建维特比网格，并回溯以获得最可能的隐状态路径及其概率（维特比路径概率）。\n- 单独地，通过对所有隐状态路径求和，利用从模型基本定义推导出的前向递归来计算边际似然 $p(x_{1:4})$。\n- 计算比率 $R = \\dfrac{\\text{维特比路径概率}}{p(x_{1:4})}$。\n\n仅报告 $R$ 的值作为您的最终答案。将您的最终答案四舍五入至五位有效数字。不需要单位。", "solution": "我们首先验证问题陈述。\n\n步骤1：提取给定信息。\n问题为离散时间隐马尔可夫模型 (HMM) 提供了以下参数：\n- 隐状态：$s_1$，$s_2$。\n- 观测字母表：$\\mathcal{X} = \\{0,1\\}$。\n- 初始分布 $\\pi$：$\\pi_1 = 0.55$，$\\pi_2 = 0.45$。\n- 状态转移矩阵 $A = [a_{ij}]$：$a_{11} = 0.65$，$a_{12} = 0.35$，$a_{21} = 0.25$，$a_{22} = 0.75$。\n- 发射概率 $b_i(x) = p(x \\mid s_i)$：\n  - $b_1(0) = 0.60$，$b_1(1) = 0.40$。\n  - $b_2(0) = 0.20$，$b_2(1) = 0.80$。\n- 观测序列：$x_{1:4} = (1,0,1,1)$。\n\n步骤2：使用提取的给定信息进行验证。\n该问题具有科学依据，是适定且客观的。为一个标准的HMM提供了所有参数。初始概率之和为1：$\\pi_1 + \\pi_2 = 0.55 + 0.45 = 1$。每个状态的转移概率（代表矩阵 $A$ 的行）之和为1：$a_{11} + a_{12} = 0.65 + 0.35 = 1$ 且 $a_{21} + a_{22} = 0.25 + 0.75 = 1$。每个状态的发射概率之和为1：$b_1(0) + b_1(1) = 0.60 + 0.40 = 1$ 且 $b_2(0) + b_2(1) = 0.20 + 0.80 = 1$。该问题是自洽、一致的，并为 HMM 提出了一套标准的计算任务（维特比解码、前向算法）。它没有违反任何无效标准。\n\n步骤3：结论与行动。\n问题有效。我们开始求解。\n\n求解过程需要三个顺序计算：给定观测序列的维特比路径概率、序列的边际似然，以及这两个值的比率。\n\n第1部分：维特比路径概率\n维特比算法为观测序列 $x_{1:T} = (x_1, \\dots, x_T)$ 寻找最可能的隐状态序列 $q_{1:T} = (q_1, \\dots, q_T)$。它通过找到具有最大概率的单一状态路径来实现这一点。令 $\\delta_t(i)$ 为任意长度为 $t$、结束于状态 $s_i$ 且生成观测序列 $x_{1:t}$ 的路径的最大概率。\n递归定义如下：\n- 初始化 ($t=1$)：$\\delta_1(i) = \\pi_i b_i(x_1)$\n- 递归 ($t  1$)：$\\delta_t(j) = \\left( \\max_{i} [\\delta_{t-1}(i) a_{ij}] \\right) b_j(x_t)$\n我们将此递归应用于观测序列 $x_{1:4} = (1,0,1,1)$。\n\n时间 $t=1$，观测 $x_1=1$：\n- $\\delta_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\delta_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\n时间 $t=2$，观测 $x_2=0$：\n- $\\delta_2(1) = \\max(\\delta_1(1)a_{11}, \\delta_1(2)a_{21}) \\times b_1(0) = \\max(0.22 \\times 0.65, 0.36 \\times 0.25) \\times 0.60 = \\max(0.143, 0.09) \\times 0.60 = 0.143 \\times 0.60 = 0.0858$\n- $\\delta_2(2) = \\max(\\delta_1(1)a_{12}, \\delta_1(2)a_{22}) \\times b_2(0) = \\max(0.22 \\times 0.35, 0.36 \\times 0.75) \\times 0.20 = \\max(0.077, 0.27) \\times 0.20 = 0.27 \\times 0.20 = 0.054$\n\n时间 $t=3$，观测 $x_3=1$：\n- $\\delta_3(1) = \\max(\\delta_2(1)a_{11}, \\delta_2(2)a_{21}) \\times b_1(1) = \\max(0.0858 \\times 0.65, 0.054 \\times 0.25) \\times 0.40 = \\max(0.05577, 0.0135) \\times 0.40 = 0.05577 \\times 0.40 = 0.022308$\n- $\\delta_3(2) = \\max(\\delta_2(1)a_{12}, \\delta_2(2)a_{22}) \\times b_2(1) = \\max(0.0858 \\times 0.35, 0.054 \\times 0.75) \\times 0.80 = \\max(0.03003, 0.0405) \\times 0.80 = 0.0405 \\times 0.80 = 0.0324$\n\n时间 $t=4$，观测 $x_4=1$：\n- $\\delta_4(1) = \\max(\\delta_3(1)a_{11}, \\delta_3(2)a_{21}) \\times b_1(1) = \\max(0.022308 \\times 0.65, 0.0324 \\times 0.25) \\times 0.40 = \\max(0.0145002, 0.0081) \\times 0.40 = 0.0145002 \\times 0.40 = 0.00580008$\n- $\\delta_4(2) = \\max(\\delta_3(1)a_{12}, \\delta_3(2)a_{22}) \\times b_2(1) = \\max(0.022308 \\times 0.35, 0.0324 \\times 0.75) \\times 0.80 = \\max(0.0078078, 0.0243) \\times 0.80 = 0.0243 \\times 0.80 = 0.01944$\n\n最可能路径的概率是最后一个时间步的最大值：\n$$P(\\text{维特比路径}) = \\max_i \\delta_4(i) = \\max(0.00580008, 0.01944) = 0.01944$$\n\n第2部分：使用前向递归计算边际似然\n边际似然 $p(x_{1:T})$ 是所有可能生成该观测序列的隐状态路径的概率之和。它是使用前向算法计算的。令 $\\alpha_t(i) = p(x_{1:t}, q_t=s_i)$ 为前向变量，它是在时间 $t$ 观测到前 $t$ 个输出且处于状态 $s_i$ 的联合概率。\n递归定义如下：\n- 初始化 ($t=1$)：$\\alpha_1(i) = \\pi_i b_i(x_1)$\n- 递归 ($t  1$)：$\\alpha_t(j) = \\left( \\sum_{i} \\alpha_{t-1}(i) a_{ij} \\right) b_j(x_t)$\n- 终止：$p(x_{1:T}) = \\sum_i \\alpha_T(i)$\n\n我们将此递归应用于相同的序列 $x_{1:4} = (1,0,1,1)$。\n\n时间 $t=1$，观测 $x_1=1$：\n- $\\alpha_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\alpha_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\n时间 $t=2$，观测 $x_2=0$：\n- $\\alpha_2(1) = (\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}) \\times b_1(0) = (0.22 \\times 0.65 + 0.36 \\times 0.25) \\times 0.60 = (0.143 + 0.09) \\times 0.60 = 0.233 \\times 0.60 = 0.1398$\n- $\\alpha_2(2) = (\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}) \\times b_2(0) = (0.22 \\times 0.35 + 0.36 \\times 0.75) \\times 0.20 = (0.077 + 0.27) \\times 0.20 = 0.347 \\times 0.20 = 0.0694$\n\n时间 $t=3$，观测 $x_3=1$：\n- $\\alpha_3(1) = (\\alpha_2(1)a_{11} + \\alpha_2(2)a_{21}) \\times b_1(1) = (0.1398 \\times 0.65 + 0.0694 \\times 0.25) \\times 0.40 = (0.09087 + 0.01735) \\times 0.40 = 0.10822 \\times 0.40 = 0.043288$\n- $\\alpha_3(2) = (\\alpha_2(1)a_{12} + \\alpha_2(2)a_{22}) \\times b_2(1) = (0.1398 \\times 0.35 + 0.0694 \\times 0.75) \\times 0.80 = (0.04893 + 0.05205) \\times 0.80 = 0.10098 \\times 0.80 = 0.080784$\n\n时间 $t=4$，观测 $x_4=1$：\n- $\\alpha_4(1) = (\\alpha_3(1)a_{11} + \\alpha_3(2)a_{21}) \\times b_1(1) = (0.043288 \\times 0.65 + 0.080784 \\times 0.25) \\times 0.40 = (0.0281372 + 0.020196) \\times 0.40 = 0.0483332 \\times 0.40 = 0.01933328$\n- $\\alpha_4(2) = (\\alpha_3(1)a_{12} + \\alpha_3(2)a_{22}) \\times b_2(1) = (0.043288 \\times 0.35 + 0.080784 \\times 0.75) \\times 0.80 = (0.0151508 + 0.060588) \\times 0.80 = 0.0757388 \\times 0.80 = 0.06059104$\n\n总边际似然是最后一个时间步的前向变量之和：\n$$p(x_{1:4}) = \\sum_i \\alpha_4(i) = \\alpha_4(1) + \\alpha_4(2) = 0.01933328 + 0.06059104 = 0.07992432$$\n\n第3部分：计算比率 $R$\n最后一步是计算维特比路径概率与总边际似然的比率 $R$。\n$$R = \\frac{P(\\text{维特比路径})}{p(x_{1:4})} = \\frac{0.01944}{0.07992432} \\approx 0.24322900$$\n根据问题陈述的要求，四舍五入到五位有效数字，得到：\n$$R \\approx 0.24323$$\n这个比率量化了单一最可能路径相对于所有可能路径的总概率质量的主导程度。", "answer": "$$\\boxed{0.24323}$$", "id": "2875864"}, {"introduction": "在学习了如何使用给定的隐马尔可夫模型进行推断之后，下一个自然的步骤是理解模型的参数如何从数据中学习得到。本练习将揭开鲍姆-韦尔奇算法（Baum-Welch algorithm）的神秘面纱，该算法是训练隐马尔可夫模型的标准期望最大化（Expectation-Maximization, EM）方法。通过引导您完成一个完整的迭代周期——包括E步（计算期望充分统计量）和M步（重新估计参数）——本练习将使您对HMM如何通过迭代优化其参数以更好地拟合观测数据获得具体的认识 [@problem_id:2875785]。", "problem": "一个离散时间系统中的二进制传感器由一个双状态（$2$）离散隐马尔可夫模型（HMM）建模。两个隐藏状态表示为 $S_1$ 和 $S_2$，观测字母表为 $\\{0,1\\}$。HMM 参数包括初始状态分布 $\\boldsymbol{\\pi}$、状态转移矩阵 $\\boldsymbol{A}$ 和观测（发射）概率 $\\boldsymbol{B}$，根据定义，给定隐藏状态的发射条件独立性和马尔可夫性质均成立。具体来说，该模型为\n$$\n\\boldsymbol{\\pi} = \\begin{pmatrix}0.6  0.4\\end{pmatrix},\\quad\n\\boldsymbol{A} = \\begin{pmatrix}0.7  0.3\\\\ 0.4  0.6\\end{pmatrix},\\quad\n\\boldsymbol{B} =\n\\begin{pmatrix}\nP(O=0\\mid S_1)  P(O=1\\mid S_1)\\\\\nP(O=0\\mid S_2)  P(O=1\\mid S_2)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.5  0.5\\\\\n0.8  0.2\n\\end{pmatrix}.\n$$\n在时间 $t=1,2,3$ 时，您观测到长度为 $3$ 的序列 $\\boldsymbol{O}=(1,0,1)$。\n\n仅使用离散隐马尔可夫模型（HMM）的基本定义、从马尔可夫性质和条件独立性推导出的前向-后向递推、贝叶斯法则以及标准的期望最大化（EM）框架，执行一次完整的 Baum-Welch EM 迭代，如下所示：\n\n1. 计算所有 $t\\in\\{1,2,3\\}$ 和 $i\\in\\{1,2\\}$ 的前向概率 $\\alpha_t(i)=P(O_1,\\dots,O_t,X_t=S_i)$ 和后向概率 $\\beta_t(i)=P(O_{t+1},\\dots,O_T\\mid X_t=S_i)$，以及序列似然 $P(\\boldsymbol{O})$。\n\n2. 基于这些值，计算状态后验概率 $\\gamma_t(i)=P(X_t=S_i\\mid \\boldsymbol{O})$ 和双切片后验概率 $\\xi_t(i,j)=P(X_t=S_i,X_{t+1}=S_j\\mid \\boldsymbol{O})$，其中 $t\\in\\{1,2\\}$，$i,j\\in\\{1,2\\}$。\n\n3. 在归一化约束下，使用 EM 的最大化步骤获得重新估计的参数 $\\boldsymbol{\\pi}'$、$\\boldsymbol{A}'$ 和 $\\boldsymbol{B}'$。\n\n仅报告从状态 $S_1$ 到状态 $S_2$ 的重新估计的转移概率，记为 $a'_{12}$，以一个简化的分数形式表示。不提供单位。不要四舍五入；以最简分数形式表示答案。", "solution": "问题陈述经过验证。\n\n### 第 1 步：提取给定条件\n- 一个具有 $N=2$ 个隐藏状态 $S_1$ 和 $S_2$ 的离散隐马尔可夫模型（HMM）。\n- 观测字母表为 $\\{0,1\\}$。\n- 观测序列的长度为 $T=3$。\n- 观测序列为 $\\boldsymbol{O}=(O_1, O_2, O_3) = (1,0,1)$。\n- 初始状态分布为 $\\boldsymbol{\\pi} = \\begin{pmatrix} \\pi_1  \\pi_2 \\end{pmatrix} = \\begin{pmatrix} 0.6  0.4 \\end{pmatrix}$。\n- 状态转移概率矩阵为 $\\boldsymbol{A} = \\begin{pmatrix} a_{11}  a_{12} \\\\ a_{21}  a_{22} \\end{pmatrix} = \\begin{pmatrix} 0.7  0.3\\\\ 0.4  0.6 \\end{pmatrix}$。\n- 观测（发射）概率矩阵为 $\\boldsymbol{B}$，其中 $b_j(k) = P(O_t=k \\mid X_t=S_j)$。给定为 $\\boldsymbol{B} = \\begin{pmatrix} b_1(0)  b_1(1) \\\\ b_2(0)  b_2(1) \\end{pmatrix} = \\begin{pmatrix} 0.5  0.5\\\\ 0.8  0.2 \\end{pmatrix}$。\n- 任务是执行 Baum-Welch 算法的一次迭代以重新估计模型参数，并报告单一值 $a'_{12}$。\n\n### 第 2 步：使用提取的给定条件进行验证\n- **科学依据：** 该问题是隐马尔可夫模型中 Baum-Welch 算法的标准应用，是信号处理和机器学习的基石。它在科学上和数学上都是合理的。\n- **适定性：** 该问题是适定的。所有必要的参数（$\\boldsymbol{\\pi}, \\boldsymbol{A}, \\boldsymbol{B}$）和观测序列 $\\boldsymbol{O}$ 都已提供。目标明确陈述。一次迭代存在唯一解。所提供的概率分布均已正确归一化（$\\boldsymbol{\\pi}$、$\\boldsymbol{A}$ 和 $\\boldsymbol{B}$ 的行和为 $1$）。\n- **客观性：** 问题以客观、数学的术语陈述，没有歧义或主观内容。\n- **完整性和一致性：** 问题是自洽的，没有矛盾之处。\n\n### 第 3 步：结论和行动\n问题是 **有效的**。将推导解答。\n\nBaum-Welch 算法是期望最大化（EM）算法的一个实例。一次迭代包括一个期望（E）步骤和一个最大化（M）步骤。\n\n**E-步骤：计算前向、后向和后验概率**\n\n模型参数的分数形式为：\n$\\boldsymbol{\\pi} = \\begin{pmatrix} \\frac{3}{5}  \\frac{2}{5} \\end{pmatrix}$，$\\boldsymbol{A} = \\begin{pmatrix} \\frac{7}{10}  \\frac{3}{10}\\\\ \\frac{2}{5}  \\frac{3}{5} \\end{pmatrix}$，$\\boldsymbol{B} = \\begin{pmatrix} \\frac{1}{2}  \\frac{1}{2}\\\\ \\frac{4}{5}  \\frac{1}{5} \\end{pmatrix}$。\n观测序列为 $\\boldsymbol{O}=(1,0,1)$。\n\n**1. 前向概率 $\\alpha_t(i) = P(O_1, \\dots, O_t, X_t=S_i \\mid \\boldsymbol{\\lambda})$**\n前向变量 $\\alpha_t(i)$ 是递归计算的。\n- **初始化 ($t=1$)：** $\\alpha_1(i) = \\pi_i b_i(O_1)$。此处 $O_1 = 1$。\n$$ \\alpha_1(1) = \\pi_1 b_1(1) = \\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10} $$\n$$ \\alpha_1(2) = \\pi_2 b_2(1) = \\frac{2}{5} \\times \\frac{1}{5} = \\frac{2}{25} $$\n- **递推 ($t=2$)：** $\\alpha_2(j) = \\left[ \\sum_{i=1}^2 \\alpha_1(i) a_{ij} \\right] b_j(O_2)$。此处 $O_2 = 0$。\n$$ \\alpha_2(1) = \\left[ \\alpha_1(1)a_{11} + \\alpha_1(2)a_{21} \\right] b_1(0) = \\left[ \\frac{3}{10}\\frac{7}{10} + \\frac{2}{25}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{21}{100} + \\frac{4}{125} \\right] \\frac{1}{2} = \\left[ \\frac{105+16}{500} \\right] \\frac{1}{2} = \\frac{121}{1000} $$\n$$ \\alpha_2(2) = \\left[ \\alpha_1(1)a_{12} + \\alpha_1(2)a_{22} \\right] b_2(0) = \\left[ \\frac{3}{10}\\frac{3}{10} + \\frac{2}{25}\\frac{3}{5} \\right] \\frac{4}{5} = \\left[ \\frac{9}{100} + \\frac{6}{125} \\right] \\frac{4}{5} = \\left[ \\frac{45+24}{500} \\right] \\frac{4}{5} = \\frac{69}{500}\\frac{4}{5} = \\frac{276}{2500} = \\frac{69}{625} $$\n- **递推 ($t=3$)：** $\\alpha_3(j) = \\left[ \\sum_{i=1}^2 \\alpha_2(i) a_{ij} \\right] b_j(O_3)$。此处 $O_3 = 1$。\n$$ \\alpha_3(1) = \\left[ \\alpha_2(1)a_{11} + \\alpha_2(2)a_{21} \\right] b_1(1) = \\left[ \\frac{121}{1000}\\frac{7}{10} + \\frac{69}{625}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{847}{10000} + \\frac{138}{3125} \\right] \\frac{1}{2} = \\left[ \\frac{4235+2208}{50000} \\right] \\frac{1}{2} = \\frac{6443}{100000} $$\n$$ \\alpha_3(2) = \\left[ \\alpha_2(1)a_{12} + \\alpha_2(2)a_{22} \\right] b_2(1) = \\left[ \\frac{121}{1000}\\frac{3}{10} + \\frac{69}{625}\\frac{3}{5} \\right] \\frac{1}{5} = \\left[ \\frac{363}{10000} + \\frac{207}{3125} \\right] \\frac{1}{5} = \\left[ \\frac{1815+3312}{50000} \\right] \\frac{1}{5} = \\frac{5127}{50000}\\frac{1}{5} = \\frac{5127}{250000} $$\n- **序列概率 $P(\\boldsymbol{O})$：** 这是最终前向变量的和。\n$$ P(\\boldsymbol{O}) = \\alpha_3(1) + \\alpha_3(2) = \\frac{6443}{100000} + \\frac{5127}{250000} = \\frac{32215+10254}{500000} = \\frac{42469}{500000} $$\n\n**2. 后向概率 $\\beta_t(i) = P(O_{t+1}, \\dots, O_T \\mid X_t=S_i, \\boldsymbol{\\lambda})$**\n后向变量 $\\beta_t(i)$ 是通过后向递推计算的。\n- **初始化 ($t=3$)：**\n$$ \\beta_3(1) = 1, \\quad \\beta_3(2) = 1 $$\n- **递推 ($t=2$)：** $\\beta_2(i) = \\sum_{j=1}^2 a_{ij} b_j(O_3) \\beta_3(j)$。此处 $O_3=1$。\n$$ \\beta_2(1) = a_{11}b_1(1)\\beta_3(1) + a_{12}b_2(1)\\beta_3(2) = \\frac{7}{10}\\frac{1}{2}(1) + \\frac{3}{10}\\frac{1}{5}(1) = \\frac{7}{20} + \\frac{3}{50} = \\frac{35+6}{100} = \\frac{41}{100} $$\n$$ \\beta_2(2) = a_{21}b_1(1)\\beta_3(1) + a_{22}b_2(1)\\beta_3(2) = \\frac{2}{5}\\frac{1}{2}(1) + \\frac{3}{5}\\frac{1}{5}(1) = \\frac{1}{5} + \\frac{3}{25} = \\frac{5+3}{25} = \\frac{8}{25} $$\n- **递推 ($t=1$)：** $\\beta_1(i) = \\sum_{j=1}^2 a_{ij} b_j(O_2) \\beta_2(j)$。此处 $O_2=0$。\n$$ \\beta_1(1) = a_{11}b_1(0)\\beta_2(1) + a_{12}b_2(0)\\beta_2(2) = \\frac{7}{10}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{10}\\frac{4}{5}\\frac{8}{25} = \\frac{287}{2000} + \\frac{96}{1250} = \\frac{1435+768}{10000} = \\frac{2203}{10000} $$\n$$ \\beta_1(2) = a_{21}b_1(0)\\beta_2(1) + a_{22}b_2(0)\\beta_2(2) = \\frac{2}{5}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{5}\\frac{4}{5}\\frac{8}{25} = \\frac{41}{500} + \\frac{96}{625} = \\frac{205+384}{2500} = \\frac{589}{2500} $$\n作为一致性检查，$P(\\boldsymbol{O})$ 也可以在 $t=1$ 时计算：\n$$ P(\\boldsymbol{O}) = \\sum_{i=1}^2 \\alpha_1(i)\\beta_1(i) = \\frac{3}{10}\\frac{2203}{10000} + \\frac{2}{25}\\frac{589}{2500} = \\frac{6609}{100000} + \\frac{1178}{62500} = \\frac{33045+9424}{500000} = \\frac{42469}{500000} $$\n结果匹配，证实了前向和后向计算的正确性。\n\n**3. 后验概率**\n状态后验概率 $\\gamma_t(i)$ 和双切片后验概率 $\\xi_t(i,j)$ 为：\n$$ \\gamma_t(i) = P(X_t=S_i \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i)\\beta_t(i)}{P(\\boldsymbol{O})} $$\n$$ \\xi_t(i,j) = P(X_t=S_i, X_{t+1}=S_j \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i) a_{ij} b_j(O_{t+1}) \\beta_{t+1}(j)}{P(\\boldsymbol{O})} $$\n\n**M-步骤：参数的重新估计**\n转移概率 $a'_{ij}$ 的重新估计公式为：\n$$ a'_{ij} = \\frac{\\text{从 } S_i \\text{ 到 } S_j \\text{ 的期望转移次数}}{\\text{从 } S_i \\text{ 出发的期望转移次数}} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)} $$\n对于 $a'_{12}$，当 $T=3$ 时：\n$$ a'_{12} = \\frac{\\xi_1(1,2) + \\xi_2(1,2)}{\\gamma_1(1) + \\gamma_2(1)} $$\n公分母 $P(\\boldsymbol{O})$ 会被消掉，所以我们可以直接使用 $\\xi$ 和 $\\gamma$ 的分子进行计算。\n令 $Num = (\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2)) + (\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2))$。\n令 $Den = (\\alpha_1(1) \\beta_1(1)) + (\\alpha_2(1) \\beta_2(1))$。\n那么 $a'_{12} = \\frac{Num}{Den}$。\n\n- **计算分子之和：**\n项 1 ($t=1$)：$\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2) = \\frac{3}{10} \\times \\frac{3}{10} \\times \\frac{4}{5} \\times \\frac{8}{25} = \\frac{288}{12500} = \\frac{72}{3125}$。\n项 2 ($t=2$)：$\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2) = \\frac{121}{1000} \\times \\frac{3}{10} \\times \\frac{1}{5} \\times 1 = \\frac{363}{50000}$。\n$$ Num = \\frac{72}{3125} + \\frac{363}{50000} = \\frac{72 \\times 16 + 363}{50000} = \\frac{1152+363}{50000} = \\frac{1515}{50000} $$\n\n- **计算分母之和：**\n项 1 ($t=1$)：$\\alpha_1(1) \\beta_1(1) = \\frac{3}{10} \\times \\frac{2203}{10000} = \\frac{6609}{100000}$。\n项 2 ($t=2$)：$\\alpha_2(1) \\beta_2(1) = \\frac{121}{1000} \\times \\frac{41}{100} = \\frac{4961}{100000}$。\n$$ Den = \\frac{6609}{100000} + \\frac{4961}{100000} = \\frac{11570}{100000} = \\frac{1157}{10000} $$\n\n- **计算 $a'_{12}$ 的最终比率：**\n$$ a'_{12} = \\frac{Num}{Den} = \\frac{1515/50000}{1157/10000} = \\frac{1515}{50000} \\times \\frac{10000}{1157} = \\frac{1515}{5 \\times 1157} = \\frac{303}{1157} $$\n通过将分子和分母同时除以 $5$ 来简化分数。为了检查 $\\frac{303}{1157}$ 是否可以进一步化简，我们找出它们的质因数。\n$303 = 3 \\times 101$。\n$1157$ 不能被 $3$（数字和为 $14$）或 $101$ 整除。\n$1157 = 13 \\times 89$。\n由于没有公质因数，该分数是最简分数。", "answer": "$$\\boxed{\\frac{303}{1157}}$$", "id": "2875785"}]}