{"hands_on_practices": [{"introduction": "在粒子滤波中，权重退化是一个核心挑战，即随着时间推移，少数粒子会占据绝大部分权重，导致粒子集对后验分布的表示失效。为了量化这一问题并采取纠正措施，我们引入了有效样本量（Effective Sample Size, ESS）这一关键指标。这个练习将引导你通过计算给定权重下的ESS，并基于此决定是否触发重采样步骤，从而深入理解重采样的时机与必要性。[@problem_id:2890403]", "problem": "考虑一个用于非线性和非高斯状态空间模型的序贯蒙特卡洛粒子滤波器，在时间索引 $t$ 处，滤波分布由 $N$ 个带权粒子表示。给定 $N = 8$ 个粒子，其归一化重要性权重为\n$$\n\\big(w_{1},w_{2},\\ldots,w_{8}\\big) = \\big(0.35,\\;0.20,\\;0.15,\\;0.10,\\;0.08,\\;0.06,\\;0.04,\\;0.02\\big),\n$$\n这些权重满足 $\\sum_{i=1}^{8} w_{i} = 1$。重采样准则由一个阈值 $\\tau N$ 定义，其中 $\\tau \\in (0,1)$ 且 $\\tau = 0.60$。\n\n从重要性采样的基本定义以及权重退化会增加加权估计量方差这一概念出发，推导粒子系统的有效样本量（ESS）与归一化权重的关系式，然后根据给定的权重计算其数值。根据你计算出的 ESS，判断是否应根据阈值规则（若 $\\text{ESS} \\le \\tau N$ 则触发）来触发重采样。\n\n将有效样本量的最终数值四舍五入到四位有效数字。仅报告有效样本量作为你的最终数值答案（无量纲）。不要在最终数值答案中包含任何单位。", "solution": "所提出的问题具有科学依据、提法恰当且客观。这是序贯蒙特卡洛方法（特别是粒子滤波）领域的一个标准练习。所有必要的数据都已提供，所要求的任务——推导、计算和决策——是清晰的，并且从前提出发是合乎逻辑的。该问题是有效的。\n\n核心任务是评估粒子滤波器中重采样的必要性。重采样是用于对抗*权重退化*问题的机制。权重退化是一种现象，即在粒子滤波器多次迭代后，重要性权重的方差会增加。这会导致少数粒子拥有显著权重，而大多数粒子的权重接近于零。因此，粒子集对目标分布的表示变得很差，并且由此导出的任何估计量的方差都会增加。\n\n有效样本量（记为 $N_{\\text{eff}}$）是用于量化权重退化严重程度的启发式度量。相对于总粒子数 $N$ 而言，较低的 $N_{\\text{eff}}$ 值表明存在显著的退化。该问题要求推导 $N_{\\text{eff}}$ 的标准公式。\n\n对于一组满足 $\\sum_{i=1}^N w_i = 1$ 的归一化重要性权重 $\\{w_i\\}_{i=1}^N$，有效样本量的一个广泛接受的近似公式是：\n$$\nN_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^{N} w_i^2}\n$$\n这个公式的合理性来自于它在极限情况下的表现。\n1.  **理想情况（无退化）**：如果所有粒子同等重要，它们的权重是均匀的，即对所有 $i \\in \\{1, \\dots, N\\}$ 都有 $w_i = \\frac{1}{N}$。权重的平方和为 $\\sum_{i=1}^N w_i^2 = \\sum_{i=1}^N \\left(\\frac{1}{N}\\right)^2 = N \\cdot \\frac{1}{N^2} = \\frac{1}{N}$。将此代入公式可得 $N_{\\text{eff}} = \\frac{1}{1/N} = N$。在这种最优情况下，有效样本量等于总粒子数。\n2.  **最坏情况（完全退化）**：如果某个粒子（比如粒子 $k$）的权重为 $w_k = 1$，而所有其他粒子的权重 $w_i = 0$ ($i \\ne k$)，则粒子集已经完全坍缩。权重的平方和为 $\\sum_{i=1}^N w_i^2 = 1^2 + \\sum_{i \\ne k} 0^2 = 1$。公式给出 $N_{\\text{eff}} = \\frac{1}{1} = 1$。这正确地反映了整个粒子表示都依赖于单个粒子。\n\n由于 $N_{\\text{eff}}$ 的公式在最佳情况值 $N$ 和最坏情况值 $1$ 之间进行了正确的插值，因此它可作为一个衡量权重退化的鲁棒且计算简单的度量。\n\n现在我们对给定问题进行数值计算。给定 $N=8$ 个粒子，其归一化权重为：\n$$\n\\big(w_{1},w_{2},\\ldots,w_{8}\\big) = \\big(0.35,\\;0.20,\\;0.15,\\;0.10,\\;0.08,\\;0.06,\\;0.04,\\;0.02\\big)\n$$\n首先，我们计算这些权重的平方和：\n$$\n\\sum_{i=1}^{8} w_i^2 = 0.35^2 + 0.20^2 + 0.15^2 + 0.10^2 + 0.08^2 + 0.06^2 + 0.04^2 + 0.02^2\n$$\n$$\n\\sum_{i=1}^{8} w_i^2 = 0.1225 + 0.0400 + 0.0225 + 0.0100 + 0.0064 + 0.0036 + 0.0016 + 0.0004\n$$\n$$\n\\sum_{i=1}^{8} w_i^2 = 0.2070\n$$\n利用这个和，我们计算有效样本量：\n$$\nN_{\\text{eff}} = \\frac{1}{\\sum_{i=1}^{8} w_i^2} = \\frac{1}{0.2070} \\approx 4.83091787...\n$$\n题目要求将结果四舍五入到四位有效数字。\n$$\nN_{\\text{eff}} \\approx 4.831\n$$\n最后，我们必须判断是否应触发重采样。重采样准则由规则 $\\text{trigger if } N_{\\text{eff}} \\le \\tau N$ 给出。给定阈值参数 $\\tau = 0.60$ 和粒子数 $N = 8$。重采样阈值为：\n$$\n\\tau N = 0.60 \\times 8 = 4.8\n$$\n现在我们必须检查计算出的 $N_{\\text{eff}}$ 是否满足条件：\n$$\n4.831 \\le 4.8\n$$\n这个不等式不成立。由于有效样本量（$4.831$）大于阈值（$4.8$），权重退化程度不被认为是严重的。因此，不应触发重采样。最终要求回答的只是有效样本量的数值。", "answer": "$$\n\\boxed{4.831}\n$$", "id": "2890403"}, {"introduction": "粒子滤波器的核心机制是根据新观测数据迭代更新粒子权重，从而反映每个粒子所代表状态的可能性。本练习将指导你为一个具有非线性动态和非高斯噪声的系统实现单步序贯重要性采样（SIS）更新。你将亲手编写代码，在对数域中处理权重计算以确保数值稳定性，并探索不同提议分布对权重更新公式的影响。[@problem_id:2890404]", "problem": "考虑一个具有非线性动力学和非线性观测的标量状态空间模型，该模型针对离散时间索引 $t \\in \\mathbb{N}$ 由以下方程定义：\n$$\nx_t = x_{t-1}^2 + v_t, \\quad y_t = \\sin(x_t) + e_t,\n$$\n其中 $x_t \\in \\mathbb{R}$ 是潜状态，$y_t \\in \\mathbb{R}$ 是观测值。假设 $\\sin(\\cdot)$ 使用以弧度为单位的角度。设过程噪声 $v_t$ 根据均值为零、尺度为 $b_v  0$ 的拉普拉斯分布独立同分布，观测噪声 $e_t$ 根据均值为零、尺度为 $b_e  0$ 的拉普拉斯分布独立同分布。位置为 $\\mu \\in \\mathbb{R}$、尺度为 $b  0$ 的拉普拉斯概率密度函数为\n$$\n\\mathrm{Laplace}(z \\mid \\mu, b) = \\frac{1}{2 b} \\exp\\!\\left(-\\frac{|z - \\mu|}{b}\\right).\n$$\n\n您需要为此模型实现一个单步序列重要性采样（SIS）更新。序列重要性采样（SIS）通过维护一组粒子和权重 $\\{(x_{t-1}^{(i)}, w_{t-1}^{(i)})\\}_{i=1}^N$ 来近似时间 $t-1$ 的滤波分布。给定一个提议分布 $q(x_t \\mid x_{t-1}, y_t)$ 和提议样本 $\\{x_t^{(i)}\\}_{i=1}^N$，对于每个粒子索引 $i \\in \\{1,\\dots,N\\}$，增量重要性权重更新定义为（在一个共同的比例常数内）：\n$$\n\\tilde{w}_t^{(i)} \\propto w_{t-1}^{(i)} \\cdot \\frac{p(y_t \\mid x_t^{(i)}) \\, p(x_t^{(i)} \\mid x_{t-1}^{(i)})}{q(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t)}.\n$$\n那么归一化权重为\n$$\nw_t^{(i)} = \\frac{\\tilde{w}_t^{(i)}}{\\sum_{j=1}^N \\tilde{w}_t^{(j)}}.\n$$\n您的实现必须使用模型定义的转移密度\n$$\np(x_t \\mid x_{t-1}) = \\mathrm{Laplace}\\!\\left(x_t \\,\\middle|\\, x_{t-1}^2, \\, b_v\\right),\n$$\n和模型定义的似然\n$$\np(y_t \\mid x_t) = \\mathrm{Laplace}\\!\\left(y_t \\,\\middle|\\, \\sin(x_t), \\, b_e\\right),\n$$\n并结合以下提议分布之一 $q(x_t \\mid x_{t-1}, y_t)$ 来计算精确的增量权重因子：\n- 情况 A（先验提议）：$q_A(x_t \\mid x_{t-1}, y_t) = p(x_t \\mid x_{t-1})$，\n- 情况 B（高斯提议）：$q_B(x_t \\mid x_{t-1}, y_t) = \\mathcal{N}\\!\\left(x_t \\,\\middle|\\, x_{t-1}^2, \\, \\sigma_q^2\\right)$，其中 $\\mathcal{N}$ 表示方差为 $\\sigma_q^2  0$ 的高斯密度。高斯密度为\n$$\n\\mathcal{N}(z \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\!\\left( -\\frac{(z - \\mu)^2}{2 \\sigma^2} \\right).\n$$\n\n您的程序必须：\n- 接受一组固定的粒子状态 $\\{x_{t-1}^{(i)}\\}_{i=1}^N$、先前的权重 $\\{w_{t-1}^{(i)}\\}_{i=1}^N$、提议的状态 $\\{x_t^{(i)}\\}_{i=1}^N$、一个观测值 $y_t$、噪声尺度 $b_v$ 和 $b_e$，以及（如果适用）高斯提议的标准差 $\\sigma_q$。\n- 使用上述为指定提议所给出的精确增量权重表达式，计算归一化权重 $\\{w_t^{(i)}\\}_{i=1}^N$。\n- 所有权重计算必须在对数域中进行，并使用 log-sum-exp 归一化以确保数值稳定性。\n- 如果提供的 $\\{w_{t-1}^{(i)}\\}_{i=1}^N$ 未被归一化，您的程序必须在应用 SIS 更新之前对其进行内部归一化。\n\n测试套件。为以下三个独立情况实现您的解决方案。对于每种情况，按所提供的粒子索引顺序返回归一化权重的列表。在所有情况下，均使用弧度制角度。\n\n- 情况 1（先验提议）：\n  - $N = 4$，\n  - $b_v = 0.5$, $b_e = 0.2$，\n  - $y_t = 0.2$，\n  - $x_{t-1}^{(i)} = [\\,0.0, \\,0.5, \\,-0.5, \\,1.0\\,]$，\n  - $w_{t-1}^{(i)} = [\\,0.25, \\,0.25, \\,0.25, \\,0.25\\,]$，\n  - $x_t^{(i)} = [\\,0.1, \\,0.2, \\,0.25, \\,0.8\\,]$，\n  - 提议：$q_A$。\n- 情况 2（高斯提议）：\n  - $N = 3$，\n  - $b_v = 0.7$, $b_e = 0.5$, $\\sigma_q = 0.3$，\n  - $y_t = -1.0$，\n  - $x_{t-1}^{(i)} = [\\,0.2, \\,-0.7, \\,1.3\\,]$，\n  - $w_{t-1}^{(i)} = [\\,0.2, \\,0.5, \\,0.3\\,]$，\n  - $x_t^{(i)} = [\\,0.14, \\,0.29, \\,1.69\\,]$，\n  - 提议：$q_B$。\n- 情况 3（具有极端似然的先验提议；测试 log-sum-exp 鲁棒性）：\n  - $N = 2$，\n  - $b_v = 0.3$, $b_e = 0.01$，\n  - $y_t = 3.0$，\n  - $x_{t-1}^{(i)} = [\\,1.5, \\,-1.5\\,]$，\n  - $w_{t-1}^{(i)} = [\\,1000.0, \\,1.0\\,]$，\n  - $x_t^{(i)} = [\\,2.25, \\,2.0\\,]$，\n  - 提议：$q_A$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个含三个元素的列表，每个元素本身是对应情况下归一化权重的列表，其粒子顺序与所提供的顺序相同。该行必须格式化为用方括号括起来的逗号分隔列表，不含空格，例如：\n\"[ [w_case1], [w_case2], [w_case3] ]\" 但不含任何空格，即：\n\"[[w11,w12,...],[w21,w22,...],[w31,w32,...]]\"。", "solution": "该问题要求为序列重要性采样（SIS）粒子滤波器实现单步权重更新。该状态空间模型由非线性状态转移和非线性观测模型定义，两者都受到非高斯（拉普拉斯）噪声的干扰。\n\nSIS 算法的核心是权重更新规则。对于一组近似时间 $t-1$ 滤波分布的粒子 $\\{ (x_{t-1}^{(i)}, w_{t-1}^{(i)}) \\}_{i=1}^N$，以及从提议分布 $q(x_t \\mid x_{t-1}, y_t)$ 中抽取的一组新的提议粒子 $\\{ x_t^{(i)} \\}_{i=1}^N$，时间 $t$ 的未归一化权重 $\\tilde{w}_t^{(i)}$ 由下式给出：\n$$\n\\tilde{w}_t^{(i)} \\propto w_{t-1}^{(i)} \\cdot \\frac{p(y_t \\mid x_t^{(i)}) \\, p(x_t^{(i)} \\mid x_{t-1}^{(i)})}{q(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t)}\n$$\n此表达式中的项是先验权重（$w_{t-1}^{(i)}$）、似然（$p(y_t \\mid x_t^{(i)})$）、状态转移概率（$p(x_t^{(i)} \\mid x_{t-1}^{(i)})$）和提议分布密度（$q(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t)$）。\n\n这种更新的乘法性质可能导致数值下溢，尤其是在处理低概率事件或大量粒子时。为确保数值稳定性，计算必须在对数域中进行。对更新规则取对数，得到未归一化的对数权重：\n$$\n\\log \\tilde{w}_t^{(i)} = \\log w_{t-1}^{(i)} + \\log p(y_t \\mid x_t^{(i)}) + \\log p(x_t^{(i)} \\mid x_{t-1}^{(i)}) - \\log q(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t) + C\n$$\n其中 $C$ 是一个对所有粒子都相同的任意常数，在归一化时会被抵消。\n\n这个问题的具体对数密度函数是：\n1.  **对数似然**：基于 $y_t = \\sin(x_t) + e_t$，其中 $e_t \\sim \\mathrm{Laplace}(0, b_e)$。对数似然 $\\log p(y_t \\mid x_t)$ 从拉普拉斯 PDF 导出：\n    $$\n    \\log p(y_t \\mid x_t) = \\log\\left( \\mathrm{Laplace}(y_t \\mid \\sin(x_t), b_e) \\right) = -\\log(2) - \\log(b_e) - \\frac{|y_t - \\sin(x_t)|}{b_e}\n    $$\n2.  **对数转移**：基于 $x_t = x_{t-1}^2 + v_t$，其中 $v_t \\sim \\mathrm{Laplace}(0, b_v)$。对数转移概率 $\\log p(x_t \\mid x_{t-1})$ 为：\n    $$\n    \\log p(x_t \\mid x_{t-1}) = \\log\\left( \\mathrm{Laplace}(x_t \\mid x_{t-1}^2, b_v) \\right) = -\\log(2) - \\log(b_v) - \\frac{|x_t - x_{t-1}^2|}{b_v}\n    $$\n\n提议分布 $q(x_t \\mid x_{t-1}, y_t)$ 决定了对数权重更新中的最后一项：\n-   **情况 A（先验提议）**：此处，$q_A(x_t \\mid x_{t-1}, y_t) = p(x_t \\mid x_{t-1})$。对数转移项和对数提议项相互抵消，将更新简化为：\n    $$\n    \\log \\tilde{w}_t^{(i)} = \\log w_{t-1}^{(i)} + \\log p(y_t \\mid x_t^{(i)})\n    $$\n-   **情况 B（高斯提议）**：此处，$q_B(x_t \\mid x_{t-1}, y_t) = \\mathcal{N}(x_t \\mid x_{t-1}^2, \\sigma_q^2)$。对数提议密度从高斯 PDF 导出：\n    $$\n    \\log q_B(x_t \\mid x_{t-1}, y_t) = \\log\\left(\\mathcal{N}(x_t \\mid x_{t-1}^2, \\sigma_q^2)\\right) = -\\frac{1}{2}\\log(2\\pi\\sigma_q^2) - \\frac{(x_t - x_{t-1}^2)^2}{2\\sigma_q^2}\n    $$\n    在这种情况下，必须使用完整的更新表达式。\n\n问题指出，输入权重 $\\{w_{t-1}^{(i)}\\}$ 可能未被归一化。第一步是将其归一化。在对数域中，这意味着计算 $\\log w_{t-1, \\text{norm}}^{(i)} = \\log w_{t-1}^{(i)} - \\log(\\sum_j w_{t-1}^{(j)})$。\n\n在为所有粒子计算出未归一化的对数权重 $\\log \\tilde{w}_t^{(i)}$ 后，必须将它们归一化，使其总和为一。这可以通过使用 log-sum-exp 技巧来稳健地实现。设 $S = \\sum_j \\tilde{w}_t^{(j)}$。则归一化权重为 $w_t^{(i)} = \\tilde{w}_t^{(i)} / S$。在对数域中：\n$$\n\\log w_t^{(i)} = \\log \\tilde{w}_t^{(i)} - \\log S = \\log \\tilde{w}_t^{(i)} - \\log\\left(\\sum_j \\exp(\\log \\tilde{w}_t^{(j)})\\right)\n$$\n项 $\\log(\\sum_j \\exp(\\log \\tilde{w}_t^{(j)}))$ 计算为 `logsumexp`$(\\{\\log \\tilde{w}_t^{(j)}\\})$。设 $m = \\max_j(\\log \\tilde{w}_t^{(j)})$。则 $\\text{logsumexp} = m + \\log(\\sum_j \\exp(\\log \\tilde{w}_t^{(j)} - m))$。这可以防止中间指数运算中的上溢和下溢。\n最后，通过对归一化的对数权重取指数来获得归一化的权重：$w_t^{(i)} = \\exp(\\log w_t^{(i)})$。\n\n算法流程如下：\n1.  接收粒子集 $\\{x_{t-1}^{(i)}\\}$、$\\{x_t^{(i)}\\}$、先验权重 $\\{w_{t-1}^{(i)}\\}$ 和模型参数。\n2.  将输入转换为数值数组。\n3.  计算先验权重的对数 $\\log w_{t-1}^{(i)}$，并使用 log-sum-exp 技巧将其归一化，得到 $\\log w_{t-1, \\text{norm}}^{(i)}$。\n4.  为所有粒子计算对数似然项 $\\log p(y_t \\mid x_t^{(i)})$。\n5.  根据指定的提议分布：\n    -   如果是先验提议，则未归一化的对数权重为 $\\log \\tilde{w}_t^{(i)} = \\log w_{t-1, \\text{norm}}^{(i)} + \\log p(y_t \\mid x_t^{(i)})$。\n    -   如果是高斯提议，则额外计算对数转移 $\\log p(x_t^{(i)} \\mid x_{t-1}^{(i)})$ 和对数提议 $\\log q_B(\\dots)$ 项，并将它们组合以获得 $\\log \\tilde{w}_t^{(i)}$。\n6.  使用 log-sum-exp 技巧对得到的未归一化对数权重集 $\\{\\log \\tilde{w}_t^{(i)}\\}$ 进行归一化，以获得归一化的对数权重 $\\log w_t^{(i)}$。\n7.  取指数以获得最终的归一化权重 $\\{w_t^{(i)}\\}$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import laplace, norm\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Solves the SIS weight update problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"case_id\": 1,\n            \"N\": 4,\n            \"b_v\": 0.5,\n            \"b_e\": 0.2,\n            \"y_t\": 0.2,\n            \"x_prev\": [0.0, 0.5, -0.5, 1.0],\n            \"w_prev\": [0.25, 0.25, 0.25, 0.25],\n            \"x_t\": [0.1, 0.2, 0.25, 0.8],\n            \"proposal\": \"A\",\n        },\n        {\n            \"case_id\": 2,\n            \"N\": 3,\n            \"b_v\": 0.7,\n            \"b_e\": 0.5,\n            \"sigma_q\": 0.3,\n            \"y_t\": -1.0,\n            \"x_prev\": [0.2, -0.7, 1.3],\n            \"w_prev\": [0.2, 0.5, 0.3],\n            \"x_t\": [0.14, 0.29, 1.69],\n            \"proposal\": \"B\",\n        },\n        {\n            \"case_id\": 3,\n            \"N\": 2,\n            \"b_v\": 0.3,\n            \"b_e\": 0.01,\n            \"y_t\": 3.0,\n            \"x_prev\": [1.5, -1.5],\n            \"w_prev\": [1000.0, 1.0],\n            \"x_t\": [2.25, 2.0],\n            \"proposal\": \"A\",\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Extract and convert parameters to numpy arrays for vectorized operations\n        y_t = case[\"y_t\"]\n        b_v = case[\"b_v\"]\n        b_e = case[\"b_e\"]\n        x_prev = np.array(case[\"x_prev\"])\n        w_prev = np.array(case[\"w_prev\"])\n        x_t = np.array(case[\"x_t\"])\n\n        # Step 1: Normalize previous weights w_{t-1} in the log domain\n        # The use of np.log on potentially zero weights is safe if they are not present\n        # in the test cases, which they are not. A more robust implementation would\n        # handle w_prev=0 by assigning -inf to the log-weight.\n        log_w_prev_unnorm = np.log(w_prev)\n        log_sum_w_prev = logsumexp(log_w_prev_unnorm)\n        log_w_prev_norm = log_w_prev_unnorm - log_sum_w_prev\n\n        # Step 2: Calculate log-likelihood component\n        # p(y_t | x_t) = Laplace(y_t | sin(x_t), b_e)\n        log_likelihood = laplace.logpdf(y_t, loc=np.sin(x_t), scale=b_e)\n        \n        # Step 3: Calculate unnormalized log weights based on proposal type\n        if case[\"proposal\"] == \"A\":\n            # Proposal q_A = p(x_t | x_{t-1}), so transition and proposal terms cancel.\n            log_w_t_unnorm = log_w_prev_norm + log_likelihood\n        elif case[\"proposal\"] == \"B\":\n            sigma_q = case[\"sigma_q\"]\n            # Proposal q_B = N(x_t | x_{t-1}^2, sigma_q^2)\n            # Log transition density: p(x_t | x_{t-1}) = Laplace(x_t | x_{t-1}^2, b_v)\n            log_transition = laplace.logpdf(x_t, loc=x_prev**2, scale=b_v)\n            \n            # Log proposal density: q(x_t | ...) = N(x_t | x_{t-1}^2, sigma_q^2)\n            # scipy.stats.norm uses standard deviation (scale), not variance.\n            log_proposal = norm.logpdf(x_t, loc=x_prev**2, scale=sigma_q)\n            \n            log_w_t_unnorm = log_w_prev_norm + log_likelihood + log_transition - log_proposal\n        else:\n            # This path should not be reached with the given test cases\n            raise ValueError(f\"Unknown proposal type: {case['proposal']}\")\n\n        # Step 4: Normalize the new log weights using log-sum-exp\n        log_sum_w_t = logsumexp(log_w_t_unnorm)\n        log_w_t_norm = log_w_t_unnorm - log_sum_w_t\n\n        # Step 5: Convert back from log domain to get final weights\n        w_t = np.exp(log_w_t_norm)\n        \n        results.append(w_t.tolist())\n    \n    # Format the final output string exactly as specified\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, res))}]' for res in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2890404"}, {"introduction": "在掌握了权重更新和重采样决策等核心概念后，现在是时候将它们整合到一个完整的滤波周期中了。“自举”粒子滤波器（bootstrap particle filter）是最基础但完整的粒子滤波算法，它集成了粒子传播、权重更新、ESS评估和重采样等所有关键步骤。这个综合性练习要求你为一个复杂的非线性、非高斯系统实现“自举”滤波器的单次完整迭代，从而巩固对粒子滤波器各部分如何协同工作的理解。[@problem_id:2890374]", "problem": "考虑以下离散时间状态空间模型，该模型旨在对用于非线性和非高斯系统的序贯蒙特卡洛 (SMC) 方法进行压力测试。潜状态 $x_t \\in \\mathbb{R}$ 根据非线性动力学演化\n$$\nx_t = g(x_{t-1}, t) + v_t,\n$$\n其中\n$$\ng(x, t) = \\frac{1}{2} x + \\frac{25 x}{1 + x^2} + 8 \\cos(1.2 t),\n$$\n并且过程噪声 $v_t$ 服从独立同分布，其分布为位置是 $0$、尺度是 $b_v$ 的拉普拉斯分布，记为 $v_t \\sim \\mathrm{Laplace}(0, b_v)$，其概率密度函数为\n$$\np_{V}(v) = \\frac{1}{2 b_v} \\exp\\!\\left(-\\frac{|v|}{b_v}\\right).\n$$\n标量观测 $y_t \\in \\mathbb{R}$ 由以下非线性测量模型给出\n$$\ny_t = \\arctan(x_t) + e_t,\n$$\n其中测量噪声 $e_t$ 服从独立同分布，其分布为位置是 $0$、尺度是 $b_e$ 的拉普拉斯分布，记为 $e_t \\sim \\mathrm{Laplace}(0, b_e)$，其概率密度函数为\n$$\np_{E}(e) = \\frac{1}{2 b_e} \\exp\\!\\left(-\\frac{|e|}{b_e}\\right).\n$$\n所有角度均以弧度为单位。函数 $\\arctan(\\cdot)$ 表示反正切主值。\n\n您需要实现自举粒子滤波器（Bootstrap Particle Filter，也称为采样重要性重采样滤波器）从时间 $t-1$ 到时间 $t$ 的单次迭代，具体如下：从时间 $t-1$ 时滤波分布的一个先验粒子近似 $\\{(x_{t-1}^{(i)}, w_{t-1}^{(i)})\\}_{i=1}^N$ 开始，该近似包含 $N$ 个粒子，其中 $w_{t-1}^{(i)} \\ge 0$ 且 $\\sum_{i=1}^N w_{t-1}^{(i)} = 1$：\n\n1. 传播（提议分布等于转移先验）：对每个粒子 $i \\in \\{1,\\dots,N\\}$，进行采样\n$$\nx_t^{(i)} \\sim p(x_t \\mid x_{t-1}^{(i)}) = \\mathrm{Laplace}\\!\\left(g\\!\\left(x_{t-1}^{(i)}, t\\right),\\, b_v\\right).\n$$\n\n2. 使用测量似然和先验权重进行权重更新：\n$$\n\\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \\, p\\!\\left(y_t \\,\\middle|\\, x_t^{(i)}\\right), \\quad\np\\!\\left(y_t \\,\\middle|\\, x_t\\right) = \\frac{1}{2 b_e} \\exp\\!\\left(-\\frac{|y_t - \\arctan(x_t)|}{b_e}\\right).\n$$\n然后归一化得到 $w_t^{(i)} = \\tilde{w}_t^{(i)} \\Big/ \\sum_{j=1}^N \\tilde{w}_t^{(j)}$。\n\n3. 计算有效样本量（ESS, Effective Sample Size），其定义为\n$$\n\\mathrm{ESS}_t = \\frac{1}{\\sum_{i=1}^N \\left(w_t^{(i)}\\right)^2}.\n$$\n\n4. 重采样决策与执行：给定一个阈值比率 $\\tau \\in [0, 1]$，如果 $\\mathrm{ESS}_t \\le \\tau N$，则执行系统重采样，生成一个重采样后的粒子集 $\\{\\bar{x}_t^{(i)}\\}_{i=1}^N$，其权重均等，为 $\\bar{w}_t^{(i)} = 1/N$。如果未触发重采样，则保留 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$。\n\n对于这次单次迭代，在重采样决策后，后验估计定义如下：\n- 如果发生了重采样，使用重采样后的等权重粒子 $\\{\\bar{x}_t^{(i)}\\}_{i=1}^N$ 计算后验均值和方差，即标准的无权样本均值和方差。\n- 如果没有发生重采样，使用加权粒子集 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$ 计算后验均值和方差，即加权均值和加权方差。\n\n您实现的程序必须：\n- 通过对 $i \\in \\{1,\\dots,N\\}$ 独立采样 $x_{t-1}^{(i)} \\sim \\mathcal{N}(m_0, s_0^2)$ 来初始化先验粒子，并使用均匀先验权重 $w_{t-1}^{(i)} = 1/N$。\n- 对每个测试用例使用固定的伪随机种子，以确保确定性行为。\n- 对权重使用数值稳定的计算方法（例如，通过对数权重稳定化）。\n- 实现系统重采样。\n\n您的程序必须处理以下测试套件，其中每个元组指定了 $(N, \\mathrm{seed}, t, y_t, m_0, s_0, b_v, b_e, \\tau)$:\n- 测试 $1$：$(200, 42, 1, 0.3, 0.0, 1.0, 0.5, 0.2, 0.5)$。\n- 测试 $2$：$(200, 314, 5, 1.2, 0.0, 2.0, 0.5, 1.0, 0.9)$。\n- 测试 $3$：$(150, 123, 3, -0.5, 0.0, 1.0, 0.2, 0.05, 0.9)$。\n- 测试 $4$：$(100, 777, 2, 2.0, 0.0, 1.0, 0.3, 0.001, 0.0)$。\n\n对于每个测试，在完成一次完整的自举滤波迭代（包括重采样决策）后，报告：\n- $x_t$ 的后验均值，四舍五入到6位小数，\n- $x_t$ 的后验方差，四舍五入到6位小数，\n- 有效样本量 $\\mathrm{ESS}_t$，四舍五入到6位小数（在任何重采样之前计算），\n- 重采样指示符，其中整数 $1$ 表示进行了重采样，整数 $0$ 表示未进行重采样。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个类JSON格式的结果列表，每个测试用例一个结果，每个结果本身是包含上述四个值的列表，并按此确切顺序排列。例如，输出应如下所示：\n$$\n\\big[\\,[m_1, v_1, \\mathrm{ESS}_1, r_1],\\,[m_2, v_2, \\mathrm{ESS}_2, r_2],\\,\\dots\\,\\big],\n$$\n其中每个 $m_k$、$v_k$ 和 $\\mathrm{ESS}_k$ 都是四舍五入到6位小数的十进制数，每个 $r_k$ 是 $0$ 或 $1$。除了指明角度以弧度为单位外，不需要任何物理单位。程序不得读取任何输入，并且必须是自包含的。", "solution": "对问题陈述进行分析后，认定其有效。它构成了非线性状态估计领域中的一个适定问题，为实现自举粒子滤波器的单次迭代提供了完整且一致的规范。所有必要的模型、参数和算法都得到了明确的定义。我们着手进行求解。\n\n任务是为一个给定的非线性、非高斯状态空间模型实现序贯蒙特卡洛方法的一次迭代，具体来说是自举粒子滤波器。该过程从时间 $t-1$ 开始，到时间 $t$ 的重采样决策后结束。\n\n**1. 系统模型规范**\n状态空间模型由两个方程定义：\n状态转移方程：\n$$x_t = g(x_{t-1}, t) + v_t$$\n其中非线性函数为 $g(x, t) = \\frac{1}{2} x + \\frac{25 x}{1 + x^2} + 8 \\cos(1.2 t)$，过程噪声为 $v_t \\sim \\mathrm{Laplace}(0, b_v)$。\n\n测量方程：\n$$y_t = \\arctan(x_t) + e_t$$\n其中测量噪声为 $e_t \\sim \\mathrm{Laplace}(0, b_e)$。\n\n**2. 自举粒子滤波器迭代**\n该算法通过几个步骤进行，从一个近似后验分布 $p(x_{t-1} | y_{1:t-1})$ 的粒子集 $\\{x_{t-1}^{(i)}, w_{t-1}^{(i)}\\}_{i=1}^N$ 开始。\n\n**步骤 0：在时间 $t-1$ 进行初始化**\n按照规定，为此单次迭代初始化先验粒子集。状态 $x_{t-1}^{(i)}$ 从高斯分布 $x_{t-1}^{(i)} \\sim \\mathcal{N}(m_0, s_0^2)$ 中独立抽取，其中 $i=1, \\dots, N$。初始权重是均匀的，$w_{t-1}^{(i)} = 1/N$ 对所有 $i$ 成立。\n\n**步骤 1：传播（预测）**\n每个粒子根据状态转移模型随时间向前传播。对于自举滤波器，提议分布就是转移先验本身。这意味着，对每个粒子 $i$，我们从分布 $p(x_t | x_{t-1}^{(i)})$ 中采样一个新的状态 $x_t^{(i)}$。这通过以下方式完成：\n1.  计算状态演化的确定性部分：$\\mu_t^{(i)} = g(x_{t-1}^{(i)}, t)$。\n2.  从过程噪声分布中采样一个噪声项 $v_t^{(i)}$：$v_t^{(i)} \\sim \\mathrm{Laplace}(0, b_v)$。\n3.  组合这些以获得新的粒子状态：$x_t^{(i)} = \\mu_t^{(i)} + v_t^{(i)}$。\n\n**步骤 2：权重更新（校正）**\n在接收到测量值 $y_t$ 后，传播后的粒子的重要性权重被更新，以反映每个粒子对观测值的解释程度。更新后的未归一化权重 $\\tilde{w}_t^{(i)}$ 是先验权重与给定粒子状态下测量值的似然的乘积：\n$$\\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \\, p(y_t | x_t^{(i)})$$\n似然函数 $p(y_t | x_t)$ 是从测量模型和测量噪声 $e_t$ 的分布中导出的：\n$$p(y_t | x_t) = p_{E}(y_t - \\arctan(x_t)) = \\frac{1}{2 b_e} \\exp\\left(-\\frac{|y_t - \\arctan(x_t)|}{b_e}\\right)$$\n由于先验权重 $w_{t-1}^{(i)}$ 是均匀的（$1/N$），它们对所有粒子都是常数，在归一化过程中可以忽略。因此，未归一化的权重与似然成正比：$\\tilde{w}_t^{(i)} \\propto p(y_t | x_t^{(i)})$。\n\n为了数值稳定性，计算在对数域中进行。粒子 $i$ 的对数似然为：\n$$\\log p(y_t | x_t^{(i)}) = -\\log(2 b_e) - \\frac{|y_t - \\arctan(x_t^{(i)})|}{b_e}$$\n令 $l_i = \\log p(y_t | x_t^{(i)})$。我们找到最大对数似然 $l_{\\max} = \\max_i \\{l_i\\}$。然后使用 log-sum-exp 技巧计算归一化的权重 $w_t^{(i)}$，以防止数值下溢：\n$$w_t^{(i)} = \\frac{\\exp(l_i - l_{\\max})}{\\sum_{j=1}^N \\exp(l_j - l_{\\max})}$$\n粒子集 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$ 现在代表了滤波分布 $p(x_t | y_{1:t})$ 的一个近似。\n\n**步骤 3：有效样本量 (ESS) 计算**\n粒子集的退化程度由有效样本量 $\\mathrm{ESS}_t$ 来量化。一个低的 ESS 表示少数几个粒子具有非常高的权重，近似效果很差。其计算公式为：\n$$\\mathrm{ESS}_t = \\frac{1}{\\sum_{i=1}^N (w_t^{(i)})^2}$$\n$\\mathrm{ESS}_t$ 的值范围从 $1$（完全退化）到 $N$（均匀权重）。\n\n**步骤 4：重采样决策与执行**\n重采样是一种通过复制高权重粒子和丢弃低权重粒子来减轻粒子退化现象的机制。通过将 ESS 与一个阈值 $\\tau N$ 进行比较来决定是否重采样，其中 $\\tau \\in [0, 1]$ 是一个用户定义的比率。\n- 如果 $\\mathrm{ESS}_t \\le \\tau N$，则执行重采样。问题指定了系统重采样。该算法从当前的离散分布 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$ 中抽取 $N$ 个粒子，形成一个新的集合 $\\{\\bar{x}_t^{(i)}\\}_{i=1}^N$，其中每个新粒子的权重都相等，为 $\\bar{w}_t^{(i)}=1/N$。\n- 如果 $\\mathrm{ESS}_t  \\tau N$，则不采取任何行动。粒子集保持为 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$。\n\n如果发生了重采样，重采样指示符 $r_t$ 被设为 $1$，否则为 $0$。\n\n**步骤 5：后验统计量计算**\n最后一步是从得到的粒子集中计算 $x_t$ 的后验分布的均值和方差。所用公式取决于是否执行了重采样。\n- **如果发生了重采样 ($r_t=1$)**：后验分布由等权重的粒子 $\\{\\bar{x}_t^{(i)}\\}_{i=1}^N$ 来近似。均值和方差是标准的无权样本均值和方差：\n  $$\\hat{x}_t = \\frac{1}{N} \\sum_{i=1}^N \\bar{x}_t^{(i)}$$\n  $$\\hat{V}_t = \\frac{1}{N} \\sum_{i=1}^N (\\bar{x}_t^{(i)} - \\hat{x}_t)^2$$\n- **如果没有发生重采样 ($r_t=0$)**：后验分布由加权的粒子 $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$ 来近似。均值和方差是加权样本均值和方差：\n  $$\\hat{x}_t = \\sum_{i=1}^N w_t^{(i)} x_t^{(i)}$$\n  $$\\hat{V}_t = \\sum_{i=1}^N w_t^{(i)} (x_t^{(i)} - \\hat{x}_t)^2$$\n\n这些计算出的值——后验均值、后验方差、ESS 和重采样指示符——构成了滤波器一次迭代所需的输出。", "answer": "```python\nimport numpy as np\n\ndef g(x, t):\n    \"\"\"The nonlinear state transition function.\"\"\"\n    return 0.5 * x + 25.0 * x / (1.0 + x**2) + 8.0 * np.cos(1.2 * t)\n\ndef particle_filter_step(N, seed, t, yt, m0, s0, bv, be, tau):\n    \"\"\"\n    Performs a single iteration of a bootstrap particle filter.\n    Returns posterior mean, variance, ESS, and resampling indicator.\n    \"\"\"\n    # Initialize the random number generator for reproducibility.\n    rng = np.random.default_rng(seed)\n\n    # Step 0: Initialize prior particles at time t-1.\n    # The weights w_{t-1} are uniform (1/N) for all particles.\n    xt_prev = rng.normal(loc=m0, scale=s0, size=N)\n\n    # Step 1: Propagation (Prediction) to time t.\n    # The proposal is the transition prior p(x_t|x_{t-1}).\n    mu_t = g(xt_prev, t)\n    # Sample from Laplace(mu_t, bv) which is mu_t + Laplace(0, bv)\n    xt = mu_t + rng.laplace(loc=0.0, scale=bv, size=N)\n\n    # Step 2: Weight update using the measurement y_t.\n    # We work with log-weights for numerical stability.\n    # The log-likelihood is log p(y_t|x_t^(i)).\n    log_likelihood = -np.log(2.0 * be) - np.abs(yt - np.arctan(xt)) / be\n\n    # Since w_{t-1} are uniform, log(w_{t-1}) is a constant offset\n    # that cancels during normalization. So, log_tilde_wt is proportional\n    # to the log_likelihood.\n    # We use the log-sum-exp trick for normalization.\n    log_wt_max = np.max(log_likelihood)\n    wt_unnorm = np.exp(log_likelihood - log_wt_max)\n    wt = wt_unnorm / np.sum(wt_unnorm)\n\n    # Step 3: Compute Effective Sample Size (ESS).\n    # This is calculated before any resampling.\n    ess = 1.0 / np.sum(wt**2)\n\n    # Step 4: Resampling decision and execution.\n    resampling_occurred = 0\n    # The threshold condition ESS = tau * N might be sensitive to floating-point\n    # issues, but for typical values, direct comparison is acceptable.\n    # Note: ESS is always >= 1. If tau*N  1, resampling will not trigger.\n    if ess = tau * N:\n        resampling_occurred = 1\n        \n        # Perform systematic resampling.\n        csw = np.cumsum(wt)\n        csw[-1] = 1.0  # Ensure the sum is exactly 1\n        u0 = rng.random()\n        positions = (np.arange(N) + u0) / N\n        \n        indices = np.searchsorted(csw, positions)\n        \n        # The new particles are copies of the old ones based on indices.\n        xt = xt[indices]\n        # After resampling, all weights are reset to uniform 1/N.\n        wt = np.full(N, 1.0 / N)\n\n    # Step 5: Compute posterior mean and variance.\n    if resampling_occurred == 1:\n        # Use unweighted sample statistics for the resampled set.\n        post_mean = np.mean(xt)\n        post_var = np.var(xt) # np.var uses 1/N denominator\n    else:\n        # Use weighted sample statistics.\n        post_mean = np.sum(wt * xt)\n        post_var = np.sum(wt * (xt - post_mean)**2)\n\n    return [\n        round(post_mean, 6),\n        round(post_var, 6),\n        round(ess, 6),\n        resampling_occurred\n    ]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # (N, seed, t, y_t, m_0, s_0, b_v, b_e, tau)\n        (200, 42, 1, 0.3, 0.0, 1.0, 0.5, 0.2, 0.5),\n        (200, 314, 5, 1.2, 0.0, 2.0, 0.5, 1.0, 0.9),\n        (150, 123, 3, -0.5, 0.0, 1.0, 0.2, 0.05, 0.9),\n        (100, 777, 2, 2.0, 0.0, 1.0, 0.3, 0.001, 0.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = particle_filter_step(*case)\n        results.append(result)\n\n    # Format the final output string as a JSON-like list of lists.\n    # f'{val:.6f}' is used to ensure 6 decimal places and avoid scientific notation.\n    inner_strings = []\n    for res_list in results:\n        m, v, e, r = res_list\n        inner_strings.append(f\"[{m:.6f},{v:.6f},{e:.6f},{r}]\")\n    \n    final_output = f\"[{','.join(inner_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2890374"}]}