{"hands_on_practices": [{"introduction": "本练习旨在探讨系统内部状态空间表示与其外部输入输出行为（由传递函数描述）之间的根本联系。我们将看到，相似变换虽然保持传递函数不变，但对于分析系统的内部结构（例如识别“隐藏”的不可控或不可观测模态）至关重要。通过这个练习 [@problem_id:2905021]，您将阐明为什么最小实现的概念对于理解系统的真实动态至关重要。", "problem": "在一个单输入单输出线性时不变状态空间模型中，输入与输出之间的传递函数定义为 $G(s) = C\\,(sI - A)^{-1} B + D$，其中 $A \\in \\mathbb{R}^{n \\times n}$，$B \\in \\mathbb{R}^{n \\times 1}$，$C \\in \\mathbb{R}^{1 \\times n}$，以及 $D \\in \\mathbb{R}$。一个相似变换是形如 $x = T \\,\\bar{x}$ 的任意坐标变换，其中 $T \\in \\mathbb{R}^{n \\times n}$ 是可逆的，得到变换后的实现 $(\\bar{A}, \\bar{B}, \\bar{C}, \\bar{D}) = (T^{-1}AT, T^{-1}B, CT, D)$。一个实现被称为是最小的，当且仅当它既是能控的又是能观的，这等价于传递函数的麦克米兰阶数等于状态维数。\n\n考虑具有以下参数的实现\n$$\nA = \\mathrm{diag}(-1,-2,-3),\\quad\nB = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix},\\quad\nC = \\begin{bmatrix}1  0  0\\end{bmatrix},\\quad\nD = 0.\n$$\n仅使用传递函数和相似变换的定义，并根据能控性和能观性的性质进行推理，判断下列哪个陈述是正确的。\n\nA. 给定实现的传递函数是 $G(s) = \\dfrac{1}{s+1} + \\dfrac{1}{s+3}$，因此没有内部对消。\n\nB. 对于任何可逆矩阵 $T$，$(\\bar{A}, \\bar{B}, \\bar{C}, \\bar{D})$ 的传递函数等于 $G(s)$；因此，对于给定的实现，存在于 $G(s)$ 中的任何极点-零点对消都不能通过相似变换消除，被对消的极点也不能重新出现。\n\nC. 存在一个可逆矩阵 $T$，使得能控性秩增加，且变换后的实现产生一个三阶传递函数，从而消除了内部对消。\n\nD. 存在一个可逆矩阵 $T$，可将该实现进行分解，将最小的能控且能观部分与互补的不能控和/或不能观部分分离开来，并且传递函数仅等于最小部分的传递函数。\n\nE. 对于任何实现，$G(s)$ 的麦克米兰阶数都等于 $A$ 的维数，因此与上述 $A$ 相关联的传递函数必须是三阶的。\n\n选择所有适用的选项。你的推理必须依赖于所述定义和相似变换的既定不变性质，并且你应该使用给定的实现来说明内部对消发生在哪里。", "solution": "我们从传递函数的基本定义开始：\n$$\nG(s) = C\\,(sI - A)^{-1} B + D.\n$$\n使用可逆矩阵 $T$ 的相似变换将 $(A,B,C,D)$ 映射到 $(\\bar{A},\\bar{B},\\bar{C},\\bar{D}) = (T^{-1}AT, T^{-1}B, CT, D)$。使用恒等式\n$$\n(sI - T^{-1}AT)^{-1} = T\\,(sI - A)^{-1} T^{-1},\n$$\n该恒等式可通过两边同乘以 $(sI - T^{-1}AT)$ 并利用 $TT^{-1}=I$ 得到，我们计算变换后的传递函数：\n$$\n\\bar{G}(s) = \\bar{C}\\,(sI - \\bar{A})^{-1} \\bar{B} + \\bar{D}\n= (C T) \\bigl( T (sI - A)^{-1} T^{-1} \\bigr) (T^{-1} B) + D\n= C\\,(sI - A)^{-1} B + D = G(s).\n$$\n因此，传递函数在相似变换下是不变的。\n\n接下来，我们计算给定实现的传递函数以识别内部对消。因为 $A$ 是对角矩阵，我们有\n$$\n(sI - A)^{-1} = \\mathrm{diag}\\Bigl(\\frac{1}{s+1},\\,\\frac{1}{s+2},\\,\\frac{1}{s+3}\\Bigr).\n$$\n因此，\n$$\nG(s) = C\\,(sI - A)^{-1} B\n= \\begin{bmatrix}1  0  0\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{1}{s+1}  0  0 \\\\\n0  \\frac{1}{s+2}  0 \\\\\n0  0  \\frac{1}{s+3}\n\\end{bmatrix}\n\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}\n= \\begin{bmatrix}1  0  0\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{1}{s+1} \\\\\n0 \\\\\n\\frac{1}{s+3}\n\\end{bmatrix}\n= \\frac{1}{s+1}.\n$$\n所以传递函数在 $s=-1$ 处有一个单极点。名义状态维数是 $3$，但 $G(s)$ 的麦克米兰阶数是 $1$，这表明存在内部对消。具体来说，$s=-2$ 处的模态是不能控的，因为 $B$ 的第二个元素是 $0$；而 $s=-3$ 处的模态是不能观的，因为 $C$ 的第三个元素是 $0$。这些内部模态不以 $G(s)$ 的极点形式出现。\n\n我们还回顾相似变换下的基本不变性质：\n- 能控性矩阵 $[\\,B\\; AB\\; A^{2}B\\;\\cdots\\; A^{n-1}B\\,]$ 的秩在相似变换下是不变的，因为用 $(T^{-1}AT,T^{-1}B)$ 替换 $(A,B)$ 会在每个块列 $A^{k}B$ 上左乘一个 $T^{-1}$，这不改变秩。\n- 能观性矩阵 $\\begin{bmatrix} C^{\\top}  (CA)^{\\top}  \\cdots  (CA^{n-1})^{\\top} \\end{bmatrix}^{\\top}$ 的秩同样是不变的，因为用 $(T^{-1}AT,CT)$ 替换 $(A,C)$ 会在 $CA^{k}$ 上右乘一个 $T$，这不改变秩。\n\n因此，相似变换不能改变能控性或能观性，不能改变最小性，也不能改变传递函数中的麦克米兰阶数或极零点对消结构。相似变换能做的是通过一种分解（例如卡尔曼分解）来揭示其结构，这种分解将能控/能观的动态特性与不能控和/或不能观的动态特性分离开来。在这种形式下，传递函数与能控且能观的子块的传递函数一致。\n\n现在，我们评估每个选项。\n\n选项A：该选项声称 $G(s) = \\dfrac{1}{s+1} + \\dfrac{1}{s+3}$。我们的直接计算得出 $G(s) = \\dfrac{1}{s+1}$。$s=-3$ 处的模态是不能观的，不贡献极点。因此这个陈述是不正确的。\n\n选项B：我们证明了对于任何可逆矩阵 $T$，都有 $\\bar{G}(s) = G(s)$。因此，$G(s)$ 中存在的任何极零点对消都会保留下来；不能通过相似变换使被对消的极点消失或重新出现。这个陈述是正确的。\n\n选项C：这个选项断言某个 $T$ 可以增加能控性秩并产生一个三阶传递函数。能控性和能观性秩在相似变换下是不变的，麦克米兰阶数也是如此。因此，没有相似变换能将 $G(s)$ 的阶数从 $1$ 变为 $3$。这个陈述是不正确的。\n\n选项D：存在一个相似变换，能将该实现变换为一种分解形式，将能控且能观的部分与其余部分（不能控和/或不能观的部分）分离开来（即卡尔曼分解）。在这种形式下，传递函数等于能控且能观子块的传递函数。这是一个公认的结果，并与本例相符，本例中有两个模态被内部对消了。这个陈述是正确的。\n\n选项E：该选项声称麦克米兰阶数总是等于状态维数。这仅对最小实现成立。我们的例子中状态维数是 $3$，而麦克米兰阶数是 $1$。因此这个陈述是不正确的。\n\n因此，正确的选项是B和D。", "answer": "$$\\boxed{BD}$$", "id": "2905021"}, {"introduction": "虽然可对角化的系统易于分析，但许多现实世界中的系统是“亏损的”(defective)，即由于存在重特征值而无法对角化。本练习 [@problem_id:2905080] 深入探讨了如何构造 Jordan 范式——适用于任何线性系统的最通用的范式。通过完整地经历寻找广义特征向量和构建 Jordan 链的过程，您将对如何将任何系统矩阵分解为其基本构造块获得扎实的实践理解。", "problem": "一位工程师正在为一个单输入单输出线性时不变 (LTI) 状态空间系统建模，该系统的状态转移矩阵具有重极点。考虑由下式给出的实矩阵 $A \\in \\mathbb{R}^{5 \\times 5}$：\n$$\nA \\;=\\;\n\\begin{pmatrix}\n2  0  0  1  0 \\\\\n0  2  0  0  0 \\\\\n0  0  2  0  0 \\\\\n0  1  0  2  0 \\\\\n0  0  1  0  2\n\\end{pmatrix}.\n$$\n从特征值、特征向量、广义特征向量的定义以及若尔当标准型 (JCF) 的定义出发，完成以下任务：\n\n- 确定矩阵 $A$ 的特征值及其代数重数和几何重数。利用根子空间，构造一个广义特征向量基，从而得到一个若尔当链分解，并由此得到 $A$ 的一个若尔当标准型 $J$。\n- 构建相似变换矩阵 $S$，其列是您构造的广义特征向量，使得 $S^{-1} A S = J$。\n- 利用相似性和矩阵指数的定义，计算 $\\exp(A)$。\n\n最后，报告 $\\exp(A)$ 在位置 $(1,2)$ 处的标量元素的值，以精确的封闭形式解析表达式表示。请勿四舍五入；无需单位。", "solution": "问题要求对于给定的矩阵 $A$，求出矩阵指数 $\\exp(A)$ 在位置 $(1,2)$ 处的元素。必须通过首先求出 $A$ 的若尔当标准型来推导出解。\n\n给定的矩阵是：\n$$\nA =\n\\begin{pmatrix}\n2  0  0  1  0 \\\\\n0  2  0  0  0 \\\\\n0  0  2  0  0 \\\\\n0  1  0  2  0 \\\\\n0  0  1  0  2\n\\end{pmatrix}\n$$\n\n首先，我们确定 $A$ 的特征值。特征方程为 $\\det(A - \\lambda I) = 0$。\n$$\nA - \\lambda I =\n\\begin{pmatrix}\n2-\\lambda  0  0  1  0 \\\\\n0  2-\\lambda  0  0  0 \\\\\n0  0  2-\\lambda  0  0 \\\\\n0  1  0  2-\\lambda  0 \\\\\n0  0  1  0  2-\\lambda\n\\end{pmatrix}\n$$\n行列式通过沿第一行进行代数余子式展开来计算：\n$$\n\\det(A - \\lambda I) = (2-\\lambda) \\det \\begin{pmatrix} 2-\\lambda  0  0  0 \\\\ 0  2-\\lambda  0  0 \\\\ 1  0  2-\\lambda  0 \\\\ 0  1  0  2-\\lambda \\end{pmatrix} - 1 \\cdot \\det \\begin{pmatrix} 0  2-\\lambda  0  0 \\\\ 0  0  2-\\lambda  0 \\\\ 0  1  0  0 \\\\ 0  0  1  2-\\lambda \\end{pmatrix}\n$$\n第二个行列式为零，因为它的第一列全为零。剩下的 $4 \\times 4$ 矩阵是下三角矩阵，因此其行列式是其对角元素的乘积。\n$$\n\\det(A - \\lambda I) = (2-\\lambda) (2-\\lambda)^4 = (2-\\lambda)^5\n$$\n因此，存在一个单一特征值 $\\lambda = 2$，其代数重数为 $m_a = 5$。\n\n接下来，我们求几何重数 $m_g$，即特征空间 $E_2 = \\ker(A - 2I)$ 的维数。\n$$\nA - 2I = \\begin{pmatrix}\n0  0  0  1  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  1  0  0  0 \\\\\n0  0  1  0  0\n\\end{pmatrix}\n$$\n一个特征向量 $v = (x_1, x_2, x_3, x_4, x_5)^T$ 满足 $(A-2I)v = 0$，这给出了方程组 $x_4=0$，$x_2=0$ 和 $x_3=0$。变量 $x_1$ 和 $x_5$ 是自由变量。特征空间由向量 $(1, 0, 0, 0, 0)^T$ 和 $(0, 0, 0, 0, 1)^T$ 张成。特征空间的维数是 $2$，所以几何重数是 $m_g=2$。\n由于 $m_g  m_a$，矩阵 $A$ 不可对角化。对于 $\\lambda=2$ 的若尔当块的数量是 $m_g=2$。\n\n为了确定这两个若尔当块的大小，我们分析 $(A-2I)$ 的幂的零度。令 $N = A-2I$。\n$d_1 = \\dim(\\ker(N)) = 2$。\n$$\nN^2 = (A-2I)^2 = \\begin{pmatrix}\n0  0  0  1  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  1  0  0  0 \\\\\n0  0  1  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  0  0  1  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  1  0  0  0 \\\\\n0  0  1  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  1  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0\n\\end{pmatrix}\n$$\n$N^2$ 的零空间由 $x_2=0$ 定义，其维数为 $4$。所以，$d_2 = \\dim(\\ker(N^2)) = 4$。\n$$\nN^3 = N^2 N = \\begin{pmatrix}\n0  1  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  0  0  1  0 \\\\\n0  0  0  0  0 \\\\\n0  0  0  0  0 \\\\\n0  1  0  0  0 \\\\\n0  0  1  0  0\n\\end{pmatrix} = 0_{5 \\times 5}\n$$\n$N^3$ 的零空间是 $\\mathbb{R}^5$。所以，$d_3 = \\dim(\\ker(N^3))=5$。大小为 $k$ 的若尔当块的数量由 $N_k = (d_k - d_{k-1}) - (d_{k+1} - d_k) = 2d_k - d_{k-1} - d_{k+1}$ 给出。\n$N_3 = 2d_3 - d_2 - d_4 = 2(5) - 4 - 5 = 1$。（因为 $d_4=5$）\n$N_2 = 2d_2 - d_1 - d_3 = 2(4) - 2 - 5 = 1$。\n$N_1 = 2d_1 - d_0 - d_2 = 2(2) - 0 - 4 = 0$。\n所以有一个大小为 $3$ 的块和一个大小为 $2$ 的块。若尔当标准型 $J$ 是：\n$$\nJ = \\begin{pmatrix}\n2  1  0  0  0 \\\\\n0  2  1  0  0 \\\\\n0  0  2  0  0 \\\\\n0  0  0  2  1 \\\\\n0  0  0  0  2\n\\end{pmatrix}\n$$\n现在，我们构造广义特征向量基。我们需要一个长度为 $3$ 的链和一个长度为 $2$ 的链。\n对于长度为 $3$ 的链，我们需要一个向量 $u_3 \\in \\ker(N^3) \\setminus \\ker(N^2)$。$\\ker(N^2)$ 由 $x_2=0$ 的向量组成。我们可以选择 $u_3 = (0,1,0,0,0)^T = e_2$。\n链则为 $\\{u_1, u_2, u_3\\}$，其中 $u_2 = N u_3$ 且 $u_1 = N u_2 = N^2 u_3$。\n$u_2 = N u_3 = (A-2I)e_2 = (0,0,0,1,0)^T = e_4$。\n$u_1 = N u_2 = (A-2I)e_4 = (1,0,0,0,0)^T = e_1$。\n第一个链是 $\\{u_1, u_2, u_3\\}$。为了与 $J$ 的形式匹配，变换矩阵 $S$ 的列应为若尔当链的向量，但顺序相反，即 $S_i v_k = v_{k-1} + \\lambda v_k$。因此，列应该是 $\\{u_1, u_2, u_3\\}$。\n\n对于长度为 $2$ 的链，我们需要一个向量 $w_2 \\in \\ker(N^2) \\setminus \\ker(N)$，它与第一个链中已有的向量在投影到 $\\ker(N^2)/\\ker(N)$ 上是线性无关的。$\\ker(N^2)$ 的一组基是 $\\{e_1, e_3, e_4, e_5\\}$。$\\ker(N)$ 的一组基是 $\\{e_1, e_5\\}$。来自第一个链的向量 $u_2=e_4$ 在 $\\ker(N^2) \\setminus \\ker(N)$ 中。我们可以选择 $w_2=e_3=(0,0,1,0,0)^T$，它在 $\\ker(N^2) \\setminus \\ker(N)$ 中，并且与 $e_4$ 在模 $\\ker(N)$ 的意义下线性无关。\n链是 $\\{w_1, w_2\\}$，其中 $w_1 = N w_2$。\n$w_1 = N w_2 = (A-2I)e_3 = (0,0,0,0,1)^T = e_5$。\n第二个链是 $\\{w_1, w_2\\}$。\n\n相似矩阵 $S$ 由这些广义特征向量按链的顺序列为列构成：$S = [u_1 | u_2 | u_3 | w_1 | w_2]$。\n$$\nS = [e_1 | e_4 | e_2 | e_5 | e_3] = \\begin{pmatrix}\n1  0  0  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  0  1 \\\\\n0  1  0  0  0 \\\\\n0  0  0  1  0\n\\end{pmatrix}\n$$\n这是一个置换矩阵，因此它是正交的，其逆矩阵是其转置：$S^{-1} = S^T$。\n$$\nS^{-1} = S^T = \\begin{pmatrix}\n1  0  0  0  0 \\\\\n0  0  0  1  0 \\\\\n0  1  0  0  0 \\\\\n0  0  0  0  1 \\\\\n0  0  1  0  0\n\\end{pmatrix}\n$$\n我们要计算 $\\exp(A) = S \\exp(J) S^{-1}$。首先，计算 $\\exp(J)$。\n$J$ 是块对角矩阵，所以 $\\exp(J) = \\text{diag}(\\exp(J_3(2)), \\exp(J_2(2)))$。\n对于一个若尔当块 $J_k(\\lambda)$，其矩阵指数在 $t=1$ 时为 $\\exp(J_k(\\lambda)) = e^{\\lambda} \\sum_{i=0}^{k-1} \\frac{1}{i!} (J_k(\\lambda)-\\lambda I)^i$。\n$$\n\\exp(J_3(2)) = \\exp(2) \\left(I + N_3 + \\frac{1}{2}N_3^2\\right) = \\exp(2) \\begin{pmatrix} 1  1  1/2 \\\\ 0  1  1 \\\\ 0  0  1 \\end{pmatrix}\n$$\n$$\n\\exp(J_2(2)) = \\exp(2) \\left(I + N_2\\right) = \\exp(2) \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}\n$$\n因此，\n$$\n\\exp(J) = \\exp(2) \\begin{pmatrix}\n1  1  1/2  0  0 \\\\\n0  1  1  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  1  1 \\\\\n0  0  0  0  1\n\\end{pmatrix}\n$$\n接下来，我们计算 $S \\exp(J)$：\n$$\nS \\exp(J) = \\exp(2) \\begin{pmatrix}\n1  0  0  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  0  1 \\\\\n0  1  0  0  0 \\\\\n0  0  0  1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n1  1  1/2  0  0 \\\\\n0  1  1  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  1  1 \\\\\n0  0  0  0  1\n\\end{pmatrix}\n= \\exp(2) \\begin{pmatrix}\n1  1  1/2  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  0  1 \\\\\n0  1  1  0  0 \\\\\n0  0  0  1  1\n\\end{pmatrix}\n$$\n最后，我们计算 $\\exp(A) = (S \\exp(J)) S^{-1}$：\n$$\n\\exp(A) = \\exp(2) \\begin{pmatrix}\n1  1  1/2  0  0 \\\\\n0  0  1  0  0 \\\\\n0  0  0  0  1 \\\\\n0  1  1  0  0 \\\\\n0  0  0  1  1\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0  0  0  0 \\\\\n0  0  0  1  0 \\\\\n0  1  0  0  0 \\\\\n0  0  0  0  1 \\\\\n0  0  1  0  0\n\\end{pmatrix}\n$$\n我们只需要元素 $(\\exp(A))_{1,2}$。这对应于 $(S \\exp(J))$ 的第一行与 $S^{-1}$ 的第二列的点积。\n$(S \\exp(J))$ 的第一行（不含因子 $\\exp(2)$）是 $(1, 1, 1/2, 0, 0)$。\n$S^{-1}$ 的第二列是 $(0, 0, 0, 1, 0)^T$。\n$$\n(\\exp(A))_{1,2} = \\exp(2) \\cdot \\left( 1 \\cdot 0 + 1 \\cdot 0 + \\frac{1}{2} \\cdot 0 + 0 \\cdot 1 + 0 \\cdot 0 \\right) = 0\n$$\n等等，我的 $S^{-1}$ 列索引错了。$S^{-1}$ 的第二列是 $e_4$ 的转置 $(0,0,0,1,0)^T$。\n$S \\exp(J)$ 的第一行是 $[\\exp(2), \\exp(2), \\frac{1}{2}\\exp(2), 0, 0]$。\n$S^{-1}$ 的第二列是 $[0,0,0,1,0]^T$。\n点积是 $\\exp(2) \\cdot (1 \\cdot 0 + 1 \\cdot 0 + 1/2 \\cdot 0 + 0 \\cdot 1 + 0 \\cdot 0) = 0$。\n让我们重新检查 $S^{-1} = S^T$。\n$S = [e_1, e_4, e_2, e_5, e_3]$. $S e_1=e_1, S e_2=e_4, S e_3=e_2, S e_4=e_5, S e_5=e_3$.\n$S^{-1} e_1=e_1, S^{-1} e_4=e_2, S^{-1} e_2=e_3, S^{-1} e_5=e_4, S^{-1} e_3=e_5$.\n$S^{-1}$ 的第二列是 $S^{-1} e_2 = e_3 = (0,0,1,0,0)^T$。\n所以点积应该是: $\\exp(2) \\cdot (1 \\cdot 0 + 1 \\cdot 1 + 1/2 \\cdot 0 + 0 \\cdot 0 + 0 \\cdot 0)$.\n等等，这是 $(S \\exp J)$ 的第一行乘以 $S^{-1}$ 的第二列。\n第一行是 $(\\exp(2), \\exp(2), \\frac{1}{2}\\exp(2), 0, 0)$\n第二列是 $(0, 0, 1, 0, 0)^T$.\n点积是 $\\exp(2) \\cdot (1 \\cdot 0 + 1 \\cdot 0 + \\frac{1}{2}\\exp(2) \\cdot 1) = \\frac{1}{2}\\exp(2)$.\n这个计算在原始解答中是正确的，但我自己检查时犯了错。\n让我再仔细检查一次。\n$\\exp(A) = (S\\exp(J)) S^{-1}$.\n$(\\exp(A))_{1,2}$ 是 $(S\\exp(J))$ 的第一行乘以 $S^{-1}$ 的第二列。\n$(S\\exp(J))$ 的第一行是 $(\\exp(2) \\cdot 1, \\exp(2) \\cdot 1, \\exp(2) \\cdot 1/2, 0, 0)$.\n$S^{-1}$ 是将 $S$ 的行和列对换的置换矩阵。\n$S$ maps $(1,2,3,4,5) \\to (1,4,2,5,3)$.\n$S^{-1}$ maps $(1,4,2,5,3) \\to (1,2,3,4,5)$. i.e. $1\\to1, 2\\to3, 3\\to5, 4\\to2, 5\\to4$.\n$S^{-1}$ 的第二列是 $e_3 = (0,0,1,0,0)^T$.\n$S\\exp(J)$ 的 $(1,3)$ 元素是 $\\frac{1}{2}\\exp(2)$.\nSo the final element $(exp(A))_{1,2}$ is the (1,3) element of $S \\exp(J)$, which is $\\frac{1}{2}\\exp(2)$.\nThe original solution is correct. No changes needed here.\nMy re-check of dot product `(1*0 + 1*0 + 1/2*1 + 0*0 + 0*0)` was wrong.\n`exp(A)[1,2]` is `(S exp(J) S_inv)[1,2]`\n= `sum_k (S exp(J))[1,k] * (S_inv)[k,2]`\n= `(S exp(J))[1,1]*(S_inv)[1,2] + (S exp(J))[1,2]*(S_inv)[2,2] + (S exp(J))[1,3]*(S_inv)[3,2] + ...`\n$S^{-1}$ 的第二列是 $e_3$. 所以 $(S^{-1})_{k,2}$ is 1 for $k=3$ and 0 otherwise.\nSo the result is `(S exp(J))[1,3] * 1`.\nThe (1,3) element of $S \\exp(J)$ is $\\exp(2) \\cdot 1/2$. The solution is correct. I will not change it.\nMy check using $\\exp(N)$ was also correct and much simpler.\n$\\exp(A) = e^2 \\exp(N) = e^2 (I+N+\\frac{1}{2}N^2)$.\nThe $(1,2)$ element is $e^2 (\\frac{1}{2}N^2)_{1,2} = e^2 \\cdot \\frac{1}{2} \\cdot 1 = \\frac{1}{2}e^2$. Correct.\nThe original solution is fine. No scientific error.", "answer": "$$\\boxed{\\frac{1}{2}\\exp(2)}$$", "id": "2905080"}, {"introduction": "在实际工程中，我们经常会为同一个系统得到多个状态空间模型，这些模型可能来自不同的实验或辨识方法。一个关键问题随之而来：这些模型在数学上是否等价，仅仅是坐标系不同？本练习 [@problem_id:2905067] 将理论与计算相结合，指导您开发一个数值算法来求解相似变换矩阵，并使用严格的标准来判断两个实现是否代表同一个底层系统。", "problem": "给定两个具有相同维度的离散时间线性时不变 (LTI) 状态空间实现，由四元组 $(A,B,C,D)$ 表示，其中 $A \\in \\mathbb{R}^{n \\times n}$，$B \\in \\mathbb{R}^{n \\times m}$，$C \\in \\mathbb{R}^{p \\times n}$，$D \\in \\mathbb{R}^{p \\times m}$。当且仅当存在一个可逆矩阵 $T \\in \\mathbb{R}^{n \\times n}$，使得以下关系成立时，两个实现 $(A_1,B_1,C_1,D_1)$ 和 $(A_2,B_2,C_2,D_2)$ 被称为相似的（即状态空间等价）：\n$$\nA_2 = T^{-1} A_1 T, \\quad B_2 = T^{-1} B_1, \\quad C_2 = C_1 T, \\quad D_2 = D_1.\n$$\n你的任务是编写一个完整的程序，对于每个提供的测试用例，通过从相似关系所蕴含的矩阵等式中，在最小二乘意义下求解 $T$，来判断两个给定的实现是否相似。按如下方式处理该问题：\n\n- 从等式 $A_1 T - T A_2 = 0$，$T B_2 - B_1 = 0$ 和 $C_1 T - C_2 = 0$ 所蕴含的关于 $T$ 的未知元素的线性方程组出发，在最小二乘意义下求解 $T$。使用任何数学上合理的方法将这些矩阵等式转换为关于 $T$ 未知元素的线性系统。\n- 通过计算以下弗罗贝尼乌斯范数残差来评估拟合程度：\n  - $r_A = \\|A_1 T - T A_2\\|_F$，\n  - $r_B = \\|T B_2 - B_1\\|_F$，\n  - $r_C = \\|C_1 T - C_2\\|_F$，\n  - $r_D = \\|D_2 - D_1\\|_F$。\n- 当且仅当以下所有条件都满足时，判定两个实现是相似的：\n  - $r_A \\le \\tau_{\\text{res}}$，$r_B \\le \\tau_{\\text{res}}$，$r_C \\le \\tau_{\\text{res}}$，以及 $r_D \\le \\tau_{\\text{res}}$，\n  - $T$ 的最小奇异值至少为 $\\tau_{\\sigma}$（以证明 $T$ 在数值上是可逆的）。\n- 使用数值阈值 $\\tau_{\\text{res}} = 1\\times 10^{-6}$ 和 $\\tau_{\\sigma} = 1\\times 10^{-8}$。\n\n本问题不涉及物理单位。如果出现任何角度，都应视为无量纲实数。\n\n测试套件：\n\n对于下面的每一种情况，你必须应用上述判定规则并输出一个布尔结果。这五种情况旨在覆盖精确相似、小扰动下的近似相似、不相似、亏损但相似的情况，以及一个欠定边界情况。\n\n- 情况 1（精确相似，$n=3$，$m=1$，$p=1$）：给定\n$$\nA_1^{(1)}=\\begin{bmatrix}0  1  0\\\\ -2  -3  0\\\\ 0  0.5  -1\\end{bmatrix},\\;\nB_1^{(1)}=\\begin{bmatrix}0\\\\ 1\\\\ 1\\end{bmatrix},\\;\nC_1^{(1)}=\\begin{bmatrix}1  0  1\\end{bmatrix},\\;\nD_1^{(1)}=\\begin{bmatrix}0\\end{bmatrix},\n$$\n和\n$$\nT^{(1)}=\\begin{bmatrix}2  0  0\\\\ 0  1  1\\\\ 0  0  1\\end{bmatrix}.\n$$\n构造\n$$\nA_2^{(1)} = \\left(T^{(1)}\\right)^{-1} A_1^{(1)} T^{(1)},\\quad\nB_2^{(1)} = \\left(T^{(1)}\\right)^{-1} B_1^{(1)},\\quad\nC_2^{(1)} = C_1^{(1)} T^{(1)},\\quad\nD_2^{(1)} = D_1^{(1)}.\n$$\n\n- 情况 2（小扰动下的近似相似）：从情况 1 出发，对第二个实现进行如下扰动\n$$\nE_A=\\begin{bmatrix}0  0  0\\\\ 1\\times 10^{-7}  -1\\times 10^{-7}  2\\times 10^{-7}\\\\ 0  0  -1\\times 10^{-7}\\end{bmatrix},\\;\nE_B=\\begin{bmatrix}1\\times 10^{-7}\\\\ 0\\\\ 0\\end{bmatrix},\\;\nE_C=\\begin{bmatrix}0  -1\\times 10^{-7}  0\\end{bmatrix}.\n$$\n使用\n$$\nA_2^{(2)} = A_2^{(1)} + E_A,\\quad B_2^{(2)} = B_2^{(1)} + E_B,\\quad C_2^{(2)} = C_2^{(1)} + E_C,\\quad D_2^{(2)} = D_2^{(1)}.\n$$\n保持 $(A_1^{(2)},B_1^{(2)},C_1^{(2)},D_1^{(2)})=(A_1^{(1)},B_1^{(1)},C_1^{(1)},D_1^{(1)})$ 完全相同。\n\n- 情况 3（不相似，$n=2$，$m=1$，$p=1$）：定义\n$$\nA_1^{(3)}=\\begin{bmatrix}0  0\\\\ 0  1\\end{bmatrix},\\;\nB_1^{(3)}=\\begin{bmatrix}1\\\\ 0\\end{bmatrix},\\;\nC_1^{(3)}=\\begin{bmatrix}1  1\\end{bmatrix},\\;\nD_1^{(3)}=\\begin{bmatrix}0\\end{bmatrix},\n$$\n和\n$$\nA_2^{(3)}=\\begin{bmatrix}0  0\\\\ 0  2\\end{bmatrix},\\;\nB_2^{(3)}=\\begin{bmatrix}1\\\\ 0\\end{bmatrix},\\;\nC_2^{(3)}=\\begin{bmatrix}1  1\\end{bmatrix},\\;\nD_2^{(3)}=\\begin{bmatrix}0\\end{bmatrix}.\n$$\n\n- 情况 4（亏损但相似，$n=3$，$m=1$，$p=1$）：给定\n$$\nA_1^{(4)}=\\begin{bmatrix}2  1  0\\\\ 0  2  0\\\\ 0  0  3\\end{bmatrix},\\;\nB_1^{(4)}=\\begin{bmatrix}1\\\\ 0\\\\ 1\\end{bmatrix},\\;\nC_1^{(4)}=\\begin{bmatrix}0  1  1\\end{bmatrix},\\;\nD_1^{(4)}=\\begin{bmatrix}0\\end{bmatrix},\n$$\n和\n$$\nT^{(4)}=\\begin{bmatrix}1  1  0\\\\ 0  1  0\\\\ 1  0  1\\end{bmatrix}.\n$$\n构造\n$$\nA_2^{(4)} = \\left(T^{(4)}\\right)^{-1} A_1^{(4)} T^{(4)},\\quad\nB_2^{(4)} = \\left(T^{(4)}\\right)^{-1} B_1^{(4)},\\quad\nC_2^{(4)} = C_1^{(4)} T^{(4)},\\quad\nD_2^{(4)} = D_1^{(4)}.\n$$\n\n- 情况 5（欠定边界情况；实现相同但变换不唯一，$n=2$，$m=1$，$p=1$）：定义\n$$\nA_1^{(5)}=A_2^{(5)}=\\begin{bmatrix}1  0\\\\ 0  1\\end{bmatrix},\\;\nB_1^{(5)}=B_2^{(5)}=\\begin{bmatrix}0\\\\ 0\\end{bmatrix},\\;\nC_1^{(5)}=C_2^{(5)}=\\begin{bmatrix}0  0\\end{bmatrix},\\;\nD_1^{(5)}=D_2^{(5)}=\\begin{bmatrix}0\\end{bmatrix}.\n$$\n注意，在这种欠定场景中，最小化残差的最小二乘解可能会返回一个奇异的 $T$。根据上述判定规则，这种情况必须被判定为不相似，因为恢复的 $T$ 未能证明其为一个数值上可逆的变换。\n\n程序要求：\n\n- 实现一个求解器，对于每种情况，构造并求解 $T$ 的最小二乘问题，计算 $r_A$、$r_B$、$r_C$、$r_D$，检查 $T$ 的最小奇异值，并使用阈值 $\\tau_{\\text{res}} = 1\\times 10^{-6}$ 和 $\\tau_{\\sigma} = 1\\times 10^{-8}$ 对每种情况返回一个布尔决策。\n- 你的程序应产生单行输出，其中包含情况 1 到 5 的五个布尔结果，形式为用方括号括起来的、不含空格的逗号分隔列表，并使用精确字面量 $\\texttt{True}$ 和 $\\texttt{False}$（例如，$\\texttt{[True,False,True,False,True]}$）。", "solution": "所呈现的问题是计算线性系统理论中一个明确定义的练习，具体涉及状态空间相似性的概念。它具有科学依据、客观，并包含了进行唯一、可验证求解所需的所有必要信息。因此，这是一个有效的问题。\n\n问题的核心是确定两个离散时间 LTI 状态空间实现 $(A_1, B_1, C_1, D_1)$ 和 $(A_2, B_2, C_2, D_2)$ 是否相似。两个实现被定义为相似，如果存在一个可逆的变换矩阵 $T \\in \\mathbb{R}^{n \\times n}$ 使得：\n$$\nA_2 = T^{-1} A_1 T, \\quad B_2 = T^{-1} B_1, \\quad C_2 = C_1 T, \\quad D_2 = D_1\n$$\n这里，$A \\in \\mathbb{R}^{n \\times n}$，$B \\in \\mathbb{R}^{n \\times m}$，$C \\in \\mathbb{R}^{p \\times n}$，以及 $D \\in \\mathbb{R}^{p \\times m}$。问题指示我们通过构建和求解一个关于矩阵 $T$ 未知元素的线性方程组来验证这些条件。\n\n首先必须将相似性条件重新整理成关于 $T$ 的一组线性方程。分别在第一个和第二个方程的左侧乘以 $T$，我们得到待解的系统：\n1.  $A_1 T - T A_2 = 0$\n2.  $T B_2 = B_1$\n3.  $C_1 T = C_2$\n\n这些是矩阵方程，必须被转换为一个标准形式 $\\mathcal{A} \\vec{t} = \\vec{b}$ 的向量-矩阵线性系统，其中 $\\vec{t}$ 包含 $T$ 的元素。这可以通过使用向量化算子 $\\text{vec}(\\cdot)$ 来完成，该算子将矩阵的列堆叠成一个单独的列向量。令 $\\vec{t} = \\text{vec}(T) \\in \\mathbb{R}^{n^2 \\times 1}$。\n\n我们使用克罗内克积 ($\\otimes$) 的基本恒等式：$\\text{vec}(AXB) = (B^T \\otimes A)\\text{vec}(X)$。将此应用于每个方程得到：\n\n1.  对于 $A_1 T - T A_2 = 0$：\n    这是一个西尔维斯特方程。我们可以将其写作 $A_1 T I_n - I_n T A_2 = 0$。向量化后得到：\n    $$\n    \\text{vec}(A_1 T I_n) - \\text{vec}(I_n T A_2) = \\vec{0}\n    $$\n    $$\n    (I_n^T \\otimes A_1)\\text{vec}(T) - (A_2^T \\otimes I_n)\\text{vec}(T) = \\vec{0}\n    $$\n    $$\n    \\underbrace{(I_n \\otimes A_1 - A_2^T \\otimes I_n)}_{\\mathcal{A}_A} \\vec{t} = \\vec{0}_{n^2 \\times 1}\n    $$\n    这给出了一个 $n^2 \\times n^2$ 的系数矩阵 $\\mathcal{A}_A$。\n\n2.  对于 $T B_2 = B_1$：\n    这可以写作 $I_n T B_2 = B_1$。向量化后得到：\n    $$\n    \\text{vec}(I_n T B_2) = \\text{vec}(B_1)\n    $$\n    $$\n    \\underbrace{(B_2^T \\otimes I_n)}_{\\mathcal{A}_B} \\vec{t} = \\underbrace{\\text{vec}(B_1)}_{\\vec{b}_B}\n    $$\n    这给出了一个 $nm \\times n^2$ 的系数矩阵 $\\mathcal{A}_B$ 和一个 $nm \\times 1$ 的向量 $\\vec{b}_B$。\n\n3.  对于 $C_1 T = C_2$：\n    这可以写作 $C_1 T I_n = C_2$。向量化后得到：\n    $$\n    \\text{vec}(C_1 T I_n) = \\text{vec}(C_2)\n    $$\n    $$\n    \\underbrace{(I_n \\otimes C_1)}_{\\mathcal{A}_C} \\vec{t} = \\underbrace{\\text{vec}(C_2)}_{\\vec{b}_C}\n    $$\n    这给出了一个 $pn \\times n^2$ 的系数矩阵 $\\mathcal{A}_C$ 和一个 $pn \\times 1$ 的向量 $\\vec{b}_C$。\n\n通过堆叠系数矩阵和右侧向量，这三个系统被组合成一个单一的、可能超定的系统 $\\mathcal{A} \\vec{t} = \\vec{b}$：\n$$\n\\mathcal{A} = \\begin{bmatrix} \\mathcal{A}_A \\\\ \\mathcal{A}_B \\\\ \\mathcal{A}_C \\end{bmatrix}, \\quad \\vec{b} = \\begin{bmatrix} \\vec{0}_{n^2 \\times 1} \\\\ \\vec{b}_B \\\\ \\vec{b}_C \\end{bmatrix}\n$$\n所得矩阵 $\\mathcal{A}$ 的维度为 $(n^2 + nm + pn) \\times n^2$。\n\n因为问题可能涉及不相似的系统或数值噪声，我们不期望得到精确解。相反，我们在最小二乘意义下求解此系统，找到最小化欧几里得范数 $\\|\\mathcal{A} \\vec{t} - \\vec{b}\\|_2$ 的向量 $\\vec{t}$。然后将得到的向量 $\\vec{t}$ 重塑为候选变换矩阵 $T \\in \\mathbb{R}^{n \\times n}$。\n\n最终的相似性判定基于两个标准：\n1.  **残差分析**：所获得的矩阵 $T$ 必须近似满足原始的相似性方程。我们计算残差的弗罗贝尼乌斯范数：\n    - $r_A = \\|A_1 T - T A_2\\|_F$\n    - $r_B = \\|T B_2 - B_1\\|_F$\n    - $r_C = \\|C_1 T - C_2\\|_F$\n    - $r_D = \\|D_2 - D_1\\|_F$\n    所有四个残差必须小于或等于指定的容差，$r_i \\le \\tau_{\\text{res}} = 1 \\times 10^{-6}$。\n\n2.  **可逆性检查**：相似性变换必须是可逆的。我们通过计算 $T$ 的奇异值来在数值上验证这一点，并确保最小奇异值 $\\sigma_{\\min}(T)$ 高于某个阈值：$\\sigma_{\\min}(T) \\ge \\tau_{\\sigma} = 1 \\times 10^{-8}$。此条件证明了矩阵 $T$ 是良态的且不是数值奇异的。\n\n当且仅当残差和可逆性标准都满足时，一对状态空间实现被判定为相似。这个稳健的流程能正确处理精确情况、有小数值扰动的情况，以及根本不相似的情况，包括那些最小二乘问题是欠定的并产生一个奇异的变换矩阵的情况。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    TAU_RES = 1e-6\n    TAU_SIGMA = 1e-8\n\n    def check_similarity(A1, B1, C1, D1, A2, B2, C2, D2):\n        \"\"\"\n        Checks if two state-space realizations are similar based on the problem's criteria.\n\n        Args:\n            A1, B1, C1, D1: Matrices for the first realization.\n            A2, B2, C2, D2: Matrices for the second realization.\n\n        Returns:\n            A boolean indicating whether the systems are deemed similar.\n        \"\"\"\n        n = A1.shape[0]\n        m = B1.shape[1]\n        p = C1.shape[0]\n        \n        # Identity matrix of size n\n        In = np.identity(n)\n\n        # 1. Formulate the linear system A_ls @ t_vec = b_ls for T\n        # based on the standard similarity relations:\n        # A1*T - T*A2 = 0\n        # T*B2 - B1 = 0\n        # C1*T - C2 = 0\n\n        # Equation from A1*T - T*A2 = 0 (Sylvester equation)\n        A_A = np.kron(In, A1) - np.kron(A2.T, In)\n        \n        # Equation from T*B2 = B1\n        A_B = np.kron(B2.T, In)\n        b_B = B1.flatten(order='F')\n        \n        # Equation from C1*T = C2\n        A_C = np.kron(In, C1)\n        b_C = C2.flatten(order='F')\n        \n        # Stack the matrices and vectors to form the full system\n        A_ls = np.vstack([A_A, A_B, A_C])\n        b_ls = np.concatenate([np.zeros(n * n), b_B, b_C])\n\n        # 2. Solve for t_vec in the least-squares sense\n        t_vec, _, _, _ = np.linalg.lstsq(A_ls, b_ls, rcond=None)\n        \n        # Reshape the solution vector t_vec into the matrix T\n        T = t_vec.reshape((n, n), order='F')\n\n        # 3. Evaluate the fit and invertibility\n        # Compute residuals using the equations solved for\n        r_A = np.linalg.norm(A1 @ T - T @ A2, 'fro')\n        r_B = np.linalg.norm(T @ B2 - B1, 'fro')\n        r_C = np.linalg.norm(C1 @ T - C2, 'fro')\n        r_D = np.linalg.norm(D2 - D1, 'fro')\n        \n        # Compute the smallest singular value of T\n        # Use try-except in case T is not square or has issues\n        try:\n            s = np.linalg.svd(T, compute_uv=False)\n            min_sv = np.min(s)\n        except np.linalg.LinAlgError:\n            min_sv = 0.0\n\n        # 4. Make the decision\n        is_similar = (r_A = TAU_RES and\n                      r_B = TAU_RES and\n                      r_C = TAU_RES and\n                      r_D = TAU_RES and\n                      min_sv >= TAU_SIGMA)\n                      \n        return is_similar\n\n    results = []\n\n    # Case 1: Exact similarity\n    A1_1 = np.array([[0, 1, 0], [-2, -3, 0], [0, 0.5, -1]])\n    B1_1 = np.array([[0], [1], [1]])\n    C1_1 = np.array([[1, 0, 1]])\n    D1_1 = np.array([[0]])\n    T_1 = np.array([[2, 0, 0], [0, 1, 1], [0, 0, 1]])\n    T_1_inv = np.linalg.inv(T_1)\n    A2_1 = T_1_inv @ A1_1 @ T_1\n    B2_1 = T_1_inv @ B1_1\n    C2_1 = C1_1 @ T_1\n    D2_1 = D1_1\n    results.append(check_similarity(A1_1, B1_1, C1_1, D1_1, A2_1, B2_1, C2_1, D2_1))\n\n    # Case 2: Approximately similar under small perturbations\n    E_A = np.array([[0, 0, 0], [1e-7, -1e-7, 2e-7], [0, 0, -1e-7]])\n    E_B = np.array([[1e-7], [0], [0]])\n    E_C = np.array([[0, -1e-7, 0]])\n    A2_2 = A2_1 + E_A\n    B2_2 = B2_1 + E_B\n    C2_2 = C2_1 + E_C\n    D2_2 = D2_1\n    results.append(check_similarity(A1_1, B1_1, C1_1, D1_1, A2_2, B2_2, C2_2, D2_2))\n\n    # Case 3: Not similar\n    A1_3 = np.array([[0, 0], [0, 1]])\n    B1_3 = np.array([[1], [0]])\n    C1_3 = np.array([[1, 1]])\n    D1_3 = np.array([[0]])\n    A2_3 = np.array([[0, 0], [0, 2]])\n    B2_3 = np.array([[1], [0]])\n    C2_3 = np.array([[1, 1]])\n    D2_3 = np.array([[0]])\n    results.append(check_similarity(A1_3, B1_3, C1_3, D1_3, A2_3, B2_3, C2_3, D2_3))\n\n    # Case 4: Defective but similar\n    A1_4 = np.array([[2, 1, 0], [0, 2, 0], [0, 0, 3]])\n    B1_4 = np.array([[1], [0], [1]])\n    C1_4 = np.array([[0, 1, 1]])\n    D1_4 = np.array([[0]])\n    T_4 = np.array([[1, 1, 0], [0, 1, 0], [1, 0, 1]])\n    T_4_inv = np.linalg.inv(T_4)\n    A2_4 = T_4_inv @ A1_4 @ T_4\n    B2_4 = T_4_inv @ B1_4\n    C2_4 = C1_4 @ T_4\n    D2_4 = D1_4\n    results.append(check_similarity(A1_4, B1_4, C1_4, D1_4, A2_4, B2_4, C2_4, D2_4))\n\n    # Case 5: Underdetermined boundary case\n    A1_5 = np.array([[1, 0], [0, 1]])\n    B1_5 = np.array([[0], [0]])\n    C1_5 = np.array([[0, 0]])\n    D1_5 = np.array([[0]])\n    A2_5 = A1_5\n    B2_5 = B1_5\n    C2_5 = C1_5\n    D2_5 = D1_5\n    results.append(check_similarity(A1_5, B1_5, C1_5, D1_5, A2_5, B2_5, C2_5, D2_5))\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2905067"}]}