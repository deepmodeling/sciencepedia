## 引言
[Lempel-Ziv](@article_id:327886) 78 (LZ78) [算法](@article_id:331821)是现代[数据压缩](@article_id:298151)的基石之一，它为一个根本性挑战提供了一个优雅的解决方案：我们如何在没有任何关于信息结构或统计特性的先验知识的情况下，高效地压缩信息？许多压缩技术需要预先分析数据，而 LZ78 则在处理过程中动态学习，通过建立一个动态字典来识别和编码重复模式。本文深入探讨了这种通用[算法](@article_id:331821)的巧妙设计和深远影响。在“原理与机制”部分，我们将剖析 LZ78 的核心机制，探索它如何使用索引字典来解析和压缩数据，并触及其确保最优性能的理论保证。随后，“应用与跨学科联系”部分将揭示这种压缩方法如何超越计算机科学，成为一个强大的工具，用于衡量从生物信息学到纯粹数学等多个领域的复杂性。

## 原理与机制

想象一下，你收到一条用完全陌生的外星语言写成的信息。你没有字典，没有语法书，什么都没有。你会如何开始理解它？你可能会先从识别单个符号开始。然后，你可能会注意到某些符号经常一起出现，形成似乎是“单词”的东西。随着你看到更多的文本，你会发现越来越长的重复短语。本质上，你会在处理过程中即时构建这门新语言的字典，边学边用。这正是 [Lempel-Ziv](@article_id:327886) 78 (LZ78) [算法](@article_id:331821)的精神所在。它是一种压缩方法，能够在没有任何关于数据统计特性先验知识的情况下，学习它正在处理的数据的“语言”。

### 机器核心：一个字典和一条简单规则

LZ78 的核心工作方式是解析输入的数据流（例如一个文本字符串），并为其遇到过的短语建立一个显式的、带索引的**字典**。该[算法](@article_id:331821)的美妙之处在于其输出的简洁性。对于它发现的每个新短语，它都会生成一个值对：`(i, c)`。

这个值对是一条极其紧凑的指令。它的意思是：“取出我已经编入目录的、位于字典**索引** $i$ 处的短语，并在其末尾追加单个**字符** $c$。” 由此产生的新短语随后会被添加到字典中，并分配下一个可用的索引，从而扩展我们已学习的词汇库。

但这引出了一个巧妙的问题：如果我们的字典最初是空的，没有“先前见过的短语”可以引用，那么该如何编码消息的第一个字符呢？解决方案既优雅又对[算法](@article_id:331821)的设计至关重要。我们设想字典在开始时就有一个特殊的条目，位于索引 0。这个条目不代表‘A’或‘B’或任何其他字符；它代表**空字符串**，即一个长度为零的“短语” [@problem_id:1666860]。

有了这个巧妙的技巧，我们的规则就具有了普适性。要编码第一个字符，比如 `B`，我们取出索引 0 处的短语（即空字符串），在其后追加 `B`，得到新短语 `B`。因此，输出为 `(0, B)`，并且 `B` 被作为条目 1 添加到我们的字典中。我们遇到的下一个字符，比如 `A`，将被编码为 `(0, A)` 并作为条目 2 添加。这个过程就这样开始了。

### 编码与解码之旅

让我们看看这台机器是如何运作的。假设我们想压缩字符串 `BANANA_RAMA`。以下是 LZ78 逐一解析它的步骤 [@problem_id:1617538]：

1.  **初始状态：** 字典为 `{0: ""}`。字符串为 `BANANA_RAMA`。
2.  **`B`**：字典中最长的前缀是 `""`（索引 0）。下一个字符是 `B`。我们输出 `(0, B)` 并将 `B` 作为条目 1 添加到字典中。
3.  **`A`**：同样，最长的前缀是 `""`（索引 0）。下一个是 `A`。输出 `(0, A)`。将 `A` 作为条目 2 添加。
4.  **`N`**：最长的前缀是 `""`（索引 0）。下一个是 `N`。输出 `(0, N)`。将 `N` 作为条目 3 添加。
5.  **`AN`**：现在变得有趣了。剩下的字符串是 `ANA_RAMA`。[算法](@article_id:331821)会寻找它已知的最长前缀。它不认识 `AN` 或 `ANA`。等等，它*确实*认识 `A`！它是条目 2。所以，已知的最长前缀是 `A`（索引 2）。随后的字符是 `N`。[算法](@article_id:331821)输出 `(2, N)` 并将新短语 `AN` 作为条目 4 添加。
6.  **`A_`**：过程继续。最长的前缀是 `A`（索引 2），后面是 `_`。输出 `(2, _)`。将 `A_` 作为条目 5 添加。

这个过程一直持续到整个字符串被消耗完毕。最终的压缩表示是这些值对的序列：`(0, B)`, `(0, A)`, `(0, N)`, `(2, N)`, `(2, _)` , `(0, R)`, `(2, M)`, ...。

解码过程同样直截了当，是编码过程的完美镜像。当解码器接收到像 `(2, N)` 这样的值对时，它知道必须检索索引 2 处的短语（它已经重建了该短语），在其后追加 `N`，然后将这个新短语添加到自己字典的下一个可用位置。通过按顺序遵循这些指令，解码器可以完美地重建原始字符串，其字典的增长与[编码器](@article_id:352366)的字典完全同步 [@problem_id:1617525]。

### 对比定义：[Lempel-Ziv](@article_id:327886) 家族

要真正欣赏 LZ78 的设计，有助于将其与其著名的亲戚 LZ77 和 LZW 进行比较。

-   **LZ78 vs. LZ77：** 主要区别在于“字典”的性质 [@problem_id:1617536]。LZ78 建立一个**显式的、带索引的**短语字典，就像一本正式的词汇书。相比之下，LZ77 使用一个**滑动窗口**，将最近看到的原始数据作为*隐式*字典。其输出通常是一个三元组 `(offset, length, character)`，意思是“在窗口中向后移动 `offset` 个字符，从那里复制 `length` 个字符，然后添加这个新字符。” LZ77 的方法只需要一个固定大小的缓冲区作为其窗口，而 LZ78 的字典原则上可以无限增长，这对内存使用有不同的影响 [@problem_id:1617524]。

-   **LZ78 vs. LZW：** [Lempel-Ziv-Welch](@article_id:334467) (LZW) [算法](@article_id:331821)是 LZ78 的一个巧妙改进。其关键创新在于输出格式 [@problem_id:1666842]。LZ78 输出一个 `(index, character)` 对，而 LZW 只输出一个**索引流**。它是如何做到这一点的呢？LZW 巧妙地构建其过程，使得解码器可以通过查看它解码的*下一个*短语的开头来*推断*出下一个字符。这是一个稍微复杂些的协作过程，但它产生了一个更紧凑的、完全由整数组成的输出流。

### 比特与字节的真实世界

到目前为止，我们得到的是一个抽象的值对序列。这究竟如何节省空间呢？魔力发生在我们把这些值对转换成二进制位时。一个字符，比如 `A` 或 `B`，可能需要固定数量的位来表示（例如，在 ASCII 中为 8 位）。然而，索引的情况则不同。

当字典很小，比如只有 8 个条目时，我们只需要 $\lceil \log_2(8) \rceil = 3$ 位就可以指定任何索引。当字典增长到，比如说 1000 个条目时，我们每个索引将需要 $\lceil \log_2(1000) \rceil = 10$ 位。随着我们词汇量的扩大，指向我们已学习短语的成本也会增加。

让我们考虑用 $\{A, B, C\}$ 这个字母表来压缩字符串 `ABABBCABCABA`。每个字符的成本是 $\lceil \log_2(3) \rceil = 2$ 位。让我们追踪压缩输出的总比特成本 [@problem_id:1666907]：

-   **`A`**：字典有 1 个条目（空字符串）。输出为 `(0, A)`。成本：$\lceil \log_2(1) \rceil + 2 = 0 + 2 = 2$ 位。
-   **`B`**：字典有 2 个条目。输出为 `(0, B)`。成本：$\lceil \log_2(2) \rceil + 2 = 1 + 2 = 3$ 位。
-   **`AB`**：字典有 3 个条目。输出为 `(1, B)`。成本：$\lceil \log_2(3) \rceil + 2 = 2 + 2 = 4$ 位。
-   ......以此类推。

[总压](@article_id:328999)缩大小是这些成本的总和。对于短的、重复的字符串，这个总和通常远小于存储原始数据的成本。这种权衡——花费比特在指针上以节省重复长序列的比特——是基于字典的压缩的精髓。

### 通用性的奇迹

我们现在来到了 LZ78 最深刻的特性。它实现了这种压缩，*而无需事先了解任何关于数据的信息*。它处理英文文本的效果和处理 DNA 序列或金融数据一样好。这就是为什么它被称为**通用**[算法](@article_id:331821)。

对于任何给定的信息源，其可被压缩的程度都有一个理论极限，这个值由其**熵**（用 $H$ 表示）给出。你可以将熵看作是每个符号的“真实”信息量，是任何人所能[期望](@article_id:311378)达到的绝对最佳压缩率。像 Huffman 编码这样的[算法](@article_id:331821)可以达到这个极限，但前提是必须事先给出每个符号的精确概率。

LZ78 不需要这样的“神谕”。它从一无所知开始，但随着处理越来越多的数据，其自适应字典会学习到底层的 statistical structure。Jacob Ziv 和 Abraham Lempel 证明了一个非凡的结果：当输入字符串的长度趋于无穷大时，LZ78 的压缩率（每个原始符号的比特数）会渐近地接近熵 $H$。

当然，对于任何有限序列，都会存在一个小的“压缩开销”，代表学习过程本身的成本 [@problem_id:1666867]。但它保证最终能学习并接近*任何*良好行为源的最优压缩率，这一事实正是该[算法](@article_id:331821)如此强大和优美的原因。

这个理论保证背后有一个优雅的数学性质作为支撑。人们可以分析 LZ78 在一个“病态”字符串上的性能，这个字符串是通过连接所有不断增长长度的唯一二进制字符串（例如 `0`、`1`、`00`、`01`、`10`、`11` 等）来构造的，使其尽可能难以压缩。即使对于这样一个几乎每个新解析出的块都是全新短语的字符串，一个深刻的结果表明，对于长度为 $n$ 的字符串，生成的短语数量 $c(n)$ 的数量级约为 $n / \log(n)$ [@problem_id:1617515]。

这可能看起来很抽象，但它有一个惊人的启示：解析出的短语的平均长度，即 $n / c(n)$，必定以 $\log(n)$ 的数量级增长。这意味着该[算法](@article_id:331821)在看到更多数据时，*在数学上保证*会找到越来越长的重复模式。它不可能不学习。正是这种内置的、不可避免的学习支撑着该[算法](@article_id:331821)的通用性，并确保了它作为现代信息论基石之一的地位。