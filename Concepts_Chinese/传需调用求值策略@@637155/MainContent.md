## 引言
在编程世界里，计算机如何以及何时决定执行其工作，是一项具有深远影响的基础性选择。大多数主流语言遵循一个简单的原则：立即执行工作。当一个函数被调用时，它的所有输入在函数开始执行前都已被完全计算。这种“及早”（eager）的方法简单直接，但可能极其低效，迫使机器执行可能永远不会被用到的昂贵计算。是否存在一种更智能、更具策略性的方式来管理计算量呢？

本文深入探讨的就是这样一种策略：**传需调用 (pass-by-need)**，这通常被称为**[惰性求值](@entry_id:751191) (lazy evaluation)** 背后的复杂引擎。它是一种“智能拖延”的哲学：非到万不得已，不执行任何工作；并且，永远不要重复计算同一件事。这个简单的理念开启了更高层次的表达能力，为那些用及早求值难以解决甚至无法解决的复杂问题，提供了优雅的解决方案。

在接下来的两节中，我们将深入探讨这个迷人的概念。首先，在**“原理与机制”**一节中，我们将剖析传需调用在底层是如何工作的，探索 thunk、[记忆化](@entry_id:634518)和[图归约](@entry_id:750018)等概念，并了解它如何使得创建无限[数据结构](@entry_id:262134)成为可能。然后，在**“应用与跨学科联系”**一节中，我们将发现这个看似抽象的理论如何在从[编译器设计](@entry_id:271989)、用户界面到[操作系统](@entry_id:752937)和区块链技术等各个领域中产生具体而强大的应用。

## 原理与机制

想象一下，你是一家盛大宴会的总厨，菜单上列满了复杂的菜肴。你会不会在一开始就把菜单上的每一道菜都做好，堆在厨房里，以防有客人点餐？这种我们可称之为**及早求值 (eager evaluation)** 的方法看似勤勉，实则极其浪费。万一没人点舒芙蕾呢？所有的努力都白费了。如果某道菜需要数小时准备，并因此耽误了其他所有事情呢？

有一种更聪明的方法。你可以把每道菜的食谱写下来，甚至做一些准备工作。然后，你等待。只有当客人点了某道特定的菜时，你才拿出食谱来烹饪。这就是**[惰性求值](@entry_id:751191) (lazy evaluation)**，或者更正式地称为**传需调用 (pass-by-need)** 的精髓。它是一种“非到万不得已，不执行工作”的哲学。在编程世界里，这个简单的理念带来了深刻而优美的结果。

### 拖延的艺术：[Thunk](@entry_id:755964)

让我们把总厨的比喻转换成计算语言。那种“及早”的策略被称为**[传值调用](@entry_id:753240) (call-by-value)**。当你调用一个函数时，计算机做的第一件事就是完全求值你传递给它的所有参数，甚至在查看函数本身之前。这是最常见的策略，用于 C++、Java 和 Python 等语言。它简单且可预测。

而[惰性求值](@entry_id:751191)则不同。当你调用一个函数时，参数不会被求值。取而代de，计算机会将每个参数的表达式打包成一个“承诺”或“食谱”，用于以后计算其值。这个承诺是一个特殊的对象，我们称之为 **thunk**。thunk 是一个被暂停的计算，静静地等待着它大放异彩的时刻。

这揭示了策略上的深刻差异，这种差异通过一个计算领域的经典思想实验 [@problem_id:3649660] 而变得尤为明显。想象我们有一个函数，无论给定什么输入，它总是返回数字 42。我们将其写作 $(\lambda x. 42)$。现在，我们用一个表示不可能、永不终止的计算的参数来调用这个函数——一个我们称之为 $\Omega$ 的计算[黑洞](@entry_id:158571)。完整的表达式是 $(\lambda x. 42)\,\Omega$。

在[传值调用](@entry_id:753240)下，计算机首先尝试求值参数 $\Omega$。它一头扎进[黑洞](@entry_id:158571)，再也没有回来。程序陷入了无限循环。

在传需调用下，计算机不会求值 $\Omega$。它创建一个 thunk——一个承诺在需要时计算 $\Omega$ 的对象——并将这个 thunk 传递给函数。函数 $(\lambda x. 42)$ 接着执行。它查看自己的函数体，发现只需要返回 42，并意识到它根本不需要知道参数 $x$ 的值。因此，它从未“兑现”那个承诺。$\Omega$ 的 thunk 从未被强制求值，危险的计算从未开始，程序愉快地返回 42。

这就是惰性的第一个超能力：**避免不必要的工作**。如果一个结果从未使用过，计算它的工作就永远不会执行。在一个像 `let x = expensive_computation in 1` 这样的简单例子中，会为 `expensive_computation` 创建一个 thunk，但因为最终结果只是 `1`，`x` 的 thunk 从未被强制求值。最终，程序的垃圾回收器注意到这个未兑现、不需要的承诺，并简单地将其丢弃，从而在未做任何工作的情况下回收内存 [@problem_id:3649679]。

### 共享即关怀：[记忆化](@entry_id:634518)的力量

避免工作固然很好，但如果我们需要多次使用同一个值会发生什么？最早的[惰性求值](@entry_id:751191)形式，称为**[传名调用](@entry_id:753236) (call-by-name)**，就像一位厨师，每次接到订单时都从头重新阅读食谱并烹饪整道菜，即使这已经是第五次点同一道菜了。这可能非常低效。

**传需调用 (Call-by-need)** 引入了一个至关重要的优化：**[记忆化](@entry_id:634518) (memoization)**。当一个 thunk 第一次被强制求值时，它的结果会被计算出来然后*保存*下来。该 thunk 会被原地更新为最[终值](@entry_id:141018)。之后任何时候需要这个值，计算机只需检索已保存的结果，而无需重新计算。

让我们通过一个简单的函数 `f(y) = y + (y * y)` [@problem_id:3675810] 来看看它的实际作用。假设我们给它传递一个有副作用的参数，比如“增加一个计数器并返回新值”。假设计数器从 0 开始。

- 在**[传名调用](@entry_id:753236)**（无共享）下，表达式 `y + (y * y)` 会三次请求 `y` 的值。每次，参数都会被重新求值。
    1. 第一个 `y`被求值：计数器变为 1，值为 1。表达式现在是 $1 + (y * y)$。
    2. 第二个 `y`被求值：计数器变为 2，值为 2。表达式现在是 $1 + (2 * y)$。
    3. 第三个 `y`被求值：计数器变为 3，值为 3。表达式现在是 $1 + (2 * 3)$。
    最终结果是 $1 + 6 = 7$，计数器增加了三次。

- 在**传需调用**（有共享）下，情况则大不相同。
    1. 第一个 `y`被求值：计数器变为 1，值为 1。这个结果 1，现在被存储在 `y` 的 thunk 中。表达式现在是 $1 + (y * y)$。
    2. 需要第二个 `y`。计算机检查 thunk，找到了存储的值 1，并使用它。没有重新求值，没有副作用。表达式现在是 $1 + (1 * y)$。
    3. 需要第三个 `y`。同样，使用存储的值 1。表达式现在是 $1 + (1 * 1)$。
    最终结果是 $1 + 1 = 2$，计数器只增加了一次。

这种共享机制，通常通过一种称为**[图归约](@entry_id:750018) (graph reduction)** 的技术实现，不仅仅是为了处理副作用的正确性；它具有巨大的性能影响 [@problem_id:3649661]。想象一个将其参数加倍的函数 `G(x) = x + x`。现在考虑重复应用这个函数，比如 `G(G(G(...G(1)...)))`。如果没有共享，工作量会呈指数级增长，就像一个家族树，每个祖先的工作都必须为每个孩子重做一遍。有了共享，每一步完成的工作都被复用，总工作量仅线性增长。这将一个棘手的指数级计算爆炸转变为一个可管理的线性过程 [@problem_id:3649722]。

### 无限的魔力

所以，[惰性求值](@entry_id:751191)避免了不必要的工作，并使重复的工作变得高效。我们可以用这些能力构建什么呢？答案是计算机科学中最优雅的思想之一：**无限[数据结构](@entry_id:262134) (infinite data structures)**。

你怎么可能在一台有限的计算机里存储一个无限的数字列表呢？你不需要。你只需存储一个如何生成它的“食谱”。[惰性求值](@entry_id:751191)允许我们定义概念上无限的[数据结构](@entry_id:262134)，因为我们只计算我们实际需要查看的有限部分。

经典的例子是[斐波那契数](@entry_id:267966)的无限流 [@problem_id:3649681]。[斐波那契数列](@entry_id:272223)是 $0, 1, 1, 2, 3, \dots$，其中每个数是前两个数之和。我们可以用一个优美的[自指](@entry_id:153268)方程来定义它：

`fibStream = [0, 1] ++ zipWith(+) fibStream (tail fibStream)`

起初这看起来毫无道理。它用 `fibStream` 自己来定义 `fibStream`！但让我们看看[惰性求值](@entry_id:751191)是如何解开它的。这个定义创建了一个 thunk。`fibStream` 是一个承诺，它以 0 开始，接着是 1，而流的其余部分 (`...`) 是另一个承诺：`zipWith(+) fibStream (tail fibStream)`。
- 如果你请求第一个元素，你会得到 0。很简单。
- 如果你请求第二个元素，你会得到 1。仍然很简单。
- 如果你请求第三个元素，你强制求值 `zipWith` thunk。它需要将 `fibStream` 的第一个元素（即 0）与 `tail fibStream` 的第一个元素（即 1）相加。结果是 1。
- 如果你请求第四个元素，`zipWith` thunk 继续执行。它将 `fibStream` 的第二个元素（1）与 `tail fibStream` 的第二个元素（即 `fibStream` 的*第三个*元素，我们刚刚计算出是 1）相加。结果是 2。

计算是按需展开的。这个流是一个知道如何生成自身的“对象”，并且只有当我们“拉动”它时它才会这样做。我们可以请求前 10 个或前 1000 个元素，程序将会终止，只计算了被请求的部分 [@problem_id:3213525]。一个及早的、[传值调用](@entry_id:753240)的语言会试图先构建整个无限列表，陷入无限循环，然后崩溃。

### 警示之言：惰性的代价

这种能力并非没有代价。[惰性求值](@entry_id:751191)引入了它自己的一系列挑战，需要一种不同的思维方式。

首先，对性能进行推理变得棘手。在及早求值的语言中，你知道代码何时运行：就在你写它的地方。在惰性语言中，thunk 的执行被推迟到程序中某个未知的、稍后的时间点。这可能使调试和性能分析更加困难。

其次，像打印到屏幕或写入文件这样的副作用成了一个雷区 [@problem_id:3649634]。想象一个表达式 `print("A") + print("B")`。由于加法是可交换的，一个惰性编译器可能会认为它可以自由地以任一顺序求值这两个 `print` 语句，导致一次运行输出 "AB"，另一次输出 "BA"。这种不确定性是不可接受的。为了解决这个问题，像 Haskell 这样的惰性函数式语言付出了巨大的努力，将纯粹的数学计算与有副作用的动作分离开来，通常使用一种称为 **monad** 的数学结构来为所有副作用强制执行一个严格的、可预测的序列。

最后，也是最臭名昭著的，[惰性求值](@entry_id:751191)可能导致**空间泄漏 (space leaks)**。一个 thunk，我们未求值的承诺，会占用内存。它必须存储要计算的表达式以及它所需要的上下文。如果你的程序构建了大量这样的 thunk 并持有它们，却从不强制求值它们，你可能会耗尽内存。一个经典的例子是从列表的左侧反复追加 [@problem_id:3251977]。在惰性语言中，像 `((list1 ++ list2) ++ list3)` 这样的表达式实际上并不执行追加操作。它创建了一个 thunk，表示“当你需要我时，我会是 `list2` 追加到 `list1` 的结果，然后再将 `list3` 追加到那个结果上”。如果你构建了一个非常长的这样的链，你就会创建一长串未求值的 thunk，为一个甚至尚未计算的结果消耗大量内存。

计算与内存之间、能力与风险之间的这种微妙平衡，正是[惰性求值](@entry_id:751191)成为一个如此迷人话题的原因。它不仅仅是一个技术实现细节；它是一种从根本上不同的计算结构哲学，只要我们小心行事，它就能开辟[表达能力](@entry_id:149863)的新世界。

