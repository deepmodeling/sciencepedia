## 应用与跨学科联系

从一个如此简单的起点——对稀有且[独立事件](@article_id:339515)的计数——演化出、并且正在演化出无穷无尽最美丽、最奇妙的形式，这种概率观何其宏伟。如果你允许我对 Darwin 的话稍作改编，你就会明白我的意思。泊松分布不仅仅是统计学教科书里一个尘封的公式；它是一条线索，一旦你开始拉动它，就会解开并连接起科学领域中一系列惊人的现象。它是一种特殊随机性的标志，一旦你学会识别它，你将无处不见它的身影。

让我们从一个简单而强大的想法开始我们的旅程。想象一台机器，一台流式细胞仪，将一束细胞逐一射过激光束。如果细胞悬浮液混合均匀且流速稳定，那么每个细胞到达激光处的事件都与其他所有事件无关。它们以某个平均速率到达，比如说每秒$\lambda$个细胞，但任何一个细胞的确切到达时间是随机的。这是**泊松过程**的经典标志。如果我们打开“快门”[持续时间](@article_id:323840)$T$，我们计数的细胞总数将是一个随机数，遵循均值为$\lambda T$的泊松分布。

现在，让我们做些更有趣的事情。当每个细胞通过时，机器测量其荧光并将其分拣到几个容器之一。也许容器1用于“暗”细胞，容器2用于“亮”细胞。如果一个细胞有$p_1$的概率是暗的，我们能对容器1中计数的[细胞数](@article_id:313753)量说些什么？一个优美的数学结果，有时被称为[泊松过程](@article_id:303434)的“稀疏化”，告诉我们一个非凡的事实：暗细胞流*也*是一个泊松过程，但其新的、较慢的速率为$\lambda p_1$。在我们的观察时间$T$内，该容器中的计数将是一个泊松变量，均值为$(\lambda p_1) T$。亮细胞也是如此。更重要的是，你在暗细胞容器中计数的细胞数量与你在亮细胞容器中计数的数量在统计上是独立的！这个优雅的原理是分析现代生物学中大量数据的统计基础，从[流式细胞术](@article_id:324076)到[染色体](@article_id:340234)上突变的分布，无不如此[@problem_id:2381114]。

这个简单的图景已经包含了一个关键的微妙之处。如果我们不是让机器运行固定时间，而是决定收集恰好$N=1000$个细胞呢？现在，总数不再是随机的。如果我们发现800个细胞落入了“亮”容器，我们就能确定有200个落入了“暗”容器。这些计数不再独立；它们被一个硬性约束联系在一起。这里真正的分布不是[泊松分布](@article_id:308183)，而是[二项分布](@article_id:301623)（或者，如果有很多容器，则是[多项分布](@article_id:323824)）。然而，如果我们的某个容器是为极其稀有的细胞准备的——比如说，带有特定突变的细胞，其概率$p_i$非常小——而我们的总样本$N$非常大，那么我们在这个稀有容器中找到的细胞数量，在极好的近似下，是一个均值为$N p_i$的泊松变量。这就是著名的[泊松近似](@article_id:328931)二项分布，一个连接这两种基本计数方式的统计学主力[@problem_id:2381114]。

### 从简单计数到复杂系统：[广义线性模型](@article_id:323241)

当然，世界很少像一个恒定、稳定的速率那么简单。某个软件的错误报告率可能取决于使用它的人数。细胞中某个基因的[转录](@article_id:361745)率取决于细胞所处的环境。当我们将泊松分布的均值，即[速率参数](@article_id:329178)$\lambda$，不视为一个常数，而是一个*其他变量的函数*时，它的威力才真正绽放。这就是**[广义线性模型](@article_id:323241)（GLM）**背后的革命性思想。

我们不再只是说“技术支持工单的数量遵循[泊松分布](@article_id:308183)”，而是可以建立一个模型，说“*预期*的工单数量取决于用户的订阅计划、他们的活动水平以及一天中的时间”。我们通常将速率的对数$\log(\lambda)$建模为这些预测变量的[线性组合](@article_id:315155)。对数连接（log link）是很自然的；它确保速率$\lambda = \exp(\text{predictors})$永远是正的，并且它将速率上的乘法效应转化为我们模型中可管理的加法项[@problem_id:1919859]。

这个框架已成为现代[基因组学](@article_id:298572)的数字显微镜。[RNA测序](@article_id:357091)实验，其核心是一个计数实验：我们通过计算信使RNA分子来了解哪些基因是活跃的。我们为一个基因计数的读数数量$Y_g$可以被看作一个泊松变量。但它的[期望值](@article_id:313620)$\mu_g$取决于很多事情。它取决于基因的潜在生物学表达水平，这是我们想知道的。但它也取决于技术因素，比如样本的总[测序深度](@article_id:357491)——我们“付了多少钱”来测序。一个[测序深度](@article_id:357491)两倍的样本，在其他条件相同的情况下，每个基因产生的读数也会是两倍。

GLM用一种称为**偏移量（offsets）**的方法，以惊人的优雅处理了这个问题。我们可以这样对预期计数建模：
$$ \log(\mathbb{E}[Y_{ig}]) = \underbrace{(\alpha_g + \mathbf{Z}_s^T \boldsymbol{\beta}_g)}_\text{The Biology} + \underbrace{\log(L_s)}_\text{The Technology} $$
“生物学”部分模拟了基因的基线表达（$\alpha_g$）如何随我们感兴趣的协变量（$\mathbf{Z}_s$）变化，比如细胞是否用药物处理过。“技术”部分$\log(L_s)$是文库大小的对数，这是一个我们直接加到方程中的已知量。GLM随后可以估计生物学效应，同时完美地解释[测序深度](@article_id:357491)的技术性变异[@problem_id:2967126]。

我们还可以更进一步。在空间转录组学中，我们图像中的每个“像素”或点都包含少数几个细胞。如果我们想知道*每个细胞*的表达率，我们可以简单地为该点中的细胞数量$N_s$添加另一个偏移量。我们的模型就变成：
$$ \log(\mathbb{E}[Y_{gs}]) = \text{log(per-cell rate)} + \log(N_s) + \log(L_s) $$
通过将$\log(N_s)$和$\log(L_s)$都作为偏移量包含进来，模型会自动求解“log(per-cell rate)”（每细胞速率的对数）这一项。我们构建了一个统计显微镜，它能窥探到点内部，并同时对[细胞数](@article_id:313753)量和测序工作量进行[归一化](@article_id:310343)，所有这些都在同一个统一的框架内完成[@problem_id:2890084]。

### 驯服“狂野”：过度离散与随机性层次

这里有一个问题。纯粹的泊松分布有一个决定性属性：其方差等于其均值。如果我们[期望](@article_id:311378)看到10个事件，[标准差](@article_id:314030)就是$\sqrt{10} \approx 3.16$。但当我们观察真实的生物学数据时，比如不同人群的基因计数，我们几乎总是发现方差*远大于*均值。这种现象被称为**过度离散**，它是一个明确的信号，表明我们简单的模型中遗漏了某些东西。

额外的混乱通常来自第二层随机性。想象一家软件公司推出了几款新产品。每款产品一周内的错误数量可能服从泊松分布，但并非每款产品都同样容易出错。每款产品$i$都有其固有的错误率$\lambda_i$。这些速率本身可能被认为是从某个反映公司整体工程质量的全公司范围的分布中抽取的。这是一个**[分层模型](@article_id:338645)**：对于给定的产品，其产生错误的过程存在随机性；在不同产品之间，其错误率也存在随机性[@problem_id:1920810]。

这种双层随机性，或者说一个[速率参数](@article_id:329178)$\lambda$本身就是一个[随机变量](@article_id:324024)的泊松过程，会产生一个新的分布。如果速率$\lambda_i$遵循伽马分布（Gamma distribution），那么最终的计数将遵循**负二项分布**。该分布有第二个参数来控制其离散程度，允许方差远大于均值。这就是为什么负二项GLM，而不是泊松GLM，是[基因组学](@article_id:298572)等领域的主力军；它源于对复杂生物系统中随机性如何运作的更现实、更具层次性的看法[@problem_id:2764669]。

这种分层思维也帮助我们避免一个普遍存在的统计学“原罪”：**[伪重复](@article_id:355232)**。假设我们正在测试一种药物对基因表达的影响，使用了三名接受治疗的捐赠者和三名对照组捐赠者的细胞。人们很容易从每位捐赠者身上测[序数](@article_id:312988)千个细胞，并将每个细胞视为一个独立的数据点。这是一个严重的错误。来自同一捐赠者的细胞不是独立的；它们共享相同的遗传背景、相同的免疫史、相同的环境。它们彼此之间的相似性要高于与其他捐赠者的细胞。忽略这种相关性会导致对真实方差的严重低估，产生荒谬的小p值，以及大量的假阳性发现[@problem_id:2837380]。

解决方案是直接将层次结构构建到我们的模型中。我们使用**广义线性混合效应模型（GLMM）**。这是一种带有一个额外项的GLM：为每个捐赠者设置一个“随机效应”。这个项在数学上捕捉了这样一个事实：来自特定捐赠者的所有细胞都共享一个偏离群体平均水平的共同随机偏差。通过明确地为这种[依赖结构](@article_id:325125)建模，我们得到了对不确定性的诚实估计和值得信赖的科学结论。

### 前沿：模拟不可见之物

这些思想最神奇的延伸或许在于模拟我们甚至无法看见的事物。在生态学中，当你调查一个森林地块并发现某种鸟类的计数为零时，这意味着什么？这可能意味着该物种确实在该地块中不存在（一个“结构性零”）。或者，也可能意味着鸟类其实存在，但它们躲藏了起来，而你未能探测到它们（一个“抽样零”）。你怎么可能区分这两种情况？

如果你有远见地对该地块进行多次调查，你就可以。通过构建一个称为**[N-混合模型](@article_id:375396)**的[分层模型](@article_id:338645)，你可以创建两个相互关联的子模型。一个模型描述该地点鸟类的真实、*潜在*（未被观察到的）丰度，这可能是一个由栖息地质量驱动的负二项过程。第二个模型描述观察过程：假设该地点有$N_i$只鸟，探测到其中任何一只的概率是多少？这可能取决于天气或一天中的时间。通过将这个组合模型拟合到[重复计数](@article_id:313399)数据上，数学方法可以奇迹般地将潜在丰度与不完美的探测分离开来，为你提供对两者的独立估计[@problem_id:2816090]。

这就是泊松框架的力量。它始于一个关于计数随机、[独立事件](@article_id:339515)的简单观察。但通过允许速率变化，通过层层叠加随机性，以及通过构建反映我们实验结构的层次结构，它为我们提供了工具来模拟我们周围世界丰富、复杂且常常隐藏的现实。从激光下单细胞的闪光，到我们整个基因组的调控，再到森林中鸟类的寂静存在，稀有之舞遵循着一种我们可以理解、预测和欣赏的节奏。