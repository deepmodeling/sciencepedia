## 应用与跨学科联系

在我们探索了化学领域预测模型构建原理之后，一个至关重要的问题出现了：我们如何知道这些模型是否真的好用？仅仅构建一个能给出答案的机器是远远不够的。我们必须毫不留情地质疑这个答案，测试它的极限，并理解我们何时可以信任它。正是在这里，一个看似简单的数据拆分技术细节，[升华](@entry_id:139006)为一个深刻的[科学诚信](@entry_id:200601)原则，其影响深远，遍及药物发现及更广泛的领域。

想象一下你正在教一个学生[药物化学](@entry_id:178806)。你给了他一千个如何修改阿司匹林结构以改善其性质的例子。然后，在期末考试中，你要求他设计另一个略有不同的阿司匹林衍生物。他很可能会做得很好。但是，他真的学会了药物化学吗？还是只学会了阿司匹林家族的局部规则？

这正是我们使用朴素的“随机拆分”数据时所陷入的陷阱。当我们有一个庞大的分子集合，其中通常包含“同类物系列”（即围绕一个共同构架核心构建的化合物家族）时，仅仅像洗牌一样将它们打乱并分入训练集和测试集，无异于自欺欺人。[测试集](@entry_id:637546)中会充满模型在训练中已见过分子的近亲。模型只需在这些几乎重复的样本之间进行内插，就能获得高分，而根本无需学习化学结构如何决定生物功能的更深层次、更具普适性的规则。这导致我们对模型性能的估计产生危险的“乐观偏见”，这是为药物优化构建有效的定量[结构-活性关系](@entry_id:178339)（QSAR）模型时的一个核心问题 [@problem_id:5025868]。

### 提高标准：测试真正的创新能力

为了真正测试学生的知识，我们应该问他一个关于完全不同类别分子的问题，比如说[青霉素](@entry_id:171464)。这将测试他是否掌握了超越任何单一化学家族的基本原理。在[计算化学](@entry_id:143039)中，与此类似的方法就是**骨架拆分**。

分子的“骨架”，例如标准的 Bemis-Murcko 骨架，可以被看作是其核心骨架——即它的环系和连接它们的连接体。我们不是拆分单个分子，而是首先按骨架家族将所有分子分组。然后，我们将整个家族分配到[训练集](@entry_id:636396)或测试集，确保在训练期间见过的骨架绝不会出现在[测试集](@entry_id:637546)中。

这个简单的操作从根本上改变了我们向模型提出的问题。我们不再是问：“你能在已经见过的东西上做个小调整吗？”我们问的是：“你能把你学到的知识应用到一个全新的结构背景中吗？”这是对*外推*能力的测试，而非内插。这也是我们衡量模型真正创新潜力的方法，即“骨架跃迁”（scaffold hopping）的能力——这是[药物化学](@entry_id:178806)中一种宝贵的能力，指从一个已知的化学系列跃迁到一个保留或改善了所需生物活性的全新系列。

### 诚实度的层级

骨架拆分是一个强大的工具，但它是一系列评估策略中的一部分，每种策略代表了不同程度的严谨性。我们可以将其视为一个诚实度的层级，一个我们可以攀登的阶梯，以更接近地理解我们的模型在混乱、不可预测的现实世界中将如何表现 [@problem_id:4599718]。

*   **随机拆分（简单的考试）：** 这是最宽松的测试。通过允许结构相似的分子同时存在于[训练集](@entry_id:636396)和测试集中，我们创造了一个近乎独立同分布（IID）的场景。这是一个有用的初步健全性检查，但它产生的性能指标——如低误差或高相关性——几乎总是被夸大的。

*   **骨架拆分（严格的期末考）：** 这个测试要难得多。它引入了机器学习从业者所说的*[协变量偏移](@entry_id:636196)*：输入（分子结构 $x$）的分布在训练集和[测试集](@entry_id:637546)之间被刻意弄得不同。我们正在测试[模型泛化](@entry_id:174365)到化学空间新区域的能力，这是任何发现项目的关键任务。

*   **时间拆分（时间的考验）：** 这通常是最严酷也最现实的评估。我们在某个时间点之前收集的所有数据上训练模型，并在之后收集的所有数据上进行测试。这模拟了前瞻性部署的实际过程。时间拆分不仅捕捉了*[协变量偏移](@entry_id:636196)*（随着研究项目的演变，化学家自然会随时间探索新的骨架），还捕捉了潜在的*概念漂移*。随着时间的推移，生成数据的过程本身可能发生变化：实验方法得到改进，仪器得到升级，甚至用于[分子对接](@entry_id:166262)等基于物理计算的软件也可能更新。这意味着结构和活性之间的潜在关系 $P(y|x)$ 本身可能正在改变。模型在时间拆分上的表现通常令人清醒，但却是其未来真实效用的宝贵代表。

### 无泄露的普适原则

其核心思想——防止关于实体“类型”的信息从[训练集](@entry_id:636396)泄露到[测试集](@entry_id:637546)——是一个普适原则，其应用远远超出了简单的 QSAR。它对于评估现代人工智能在广泛科学应用中的可信赖性至关重要。

#### 教会 AI 进行创造

考虑一下生成模型这个激动人心的领域，我们训练人工智能来设计全新的分子。一个关键问题是，模型是真正具有创造力，还是仅仅在对其训练数据进行巧妙的混搭。骨架拆分为此提供了答案。我们可以测量当模型看到一个具有新颖骨架的分子时，它有多“惊讶”（一个由[负对数似然](@entry_id:637801)捕获的量）。一个真正强大的[生成模型](@entry_id:177561)应该能够识别出一个结构合理的分子，即使其核心结构是新的。正如一项假设性分析所示，模型在测试熟悉的骨架时可能显得非常自信（例如，平均惊讶分数为 $1.56$），但当面对新颖骨架时，它的困惑就显而易见了（分数可能跃升至 $3.0$） [@problem_id:4567941]。这个差距衡量了它的泛化能力——从模仿走向类似发明的飞跃。

#### 绘制相互关联的生命网络

当我们处理更复杂的系统时，这一原则变得更加强大。生物学中的一个巨大挑战是预测药物-靶点相互作用（DTI）——即在庞大的生命网络中，哪些小分子会与哪些[蛋白质相互作用](@entry_id:271521)。在这里，[信息泄露](@entry_id:155485)可能以两种方式发生。有*化学泄露*，即测试药物与训练药物共享一个骨架。但也有*生物学泄露*，即测试蛋白质是模型已经训练过的蛋白质的近亲进化同源物。

要声称一个模型能够真正帮助发现针对新生物靶点的新药，我们必须防范这两种类型的泄露。对此的黄金标准是“双冷”或“两端皆冷”的评估协议。在这种设置中，一个测试相互作用对由一个骨架新颖的药物*和*一个家族（例如，由[序列同源性](@entry_id:169068)定义）新颖的[蛋白质组](@entry_id:150306)成 [@problem_id:4570133]。这是一个极具挑战性的测试，但通过它能让我们相信，我们的模型已经学到了支配生命本身的[分子识别](@entry_id:151970)的深刻、可迁移的理解。

#### 鉴定未知物

最后，考虑从实验数据（如质谱）中鉴定未知化合物的分析任务。我们可以构建强大的机器学习模型，如[图神经网络](@entry_id:136853)，来学习从谱图指纹到分子结构的映射。但要使这样的工具在真实世界的实验室中有用，它必须能够识别出它从未见过的骨架的化合物。通过使用严格的骨架拆分来评估不同的模型架构，我们可以严谨地确定哪种方法更好地学习了化学和物理学的基本原理，从而确定当面对真正的未知物时我们可以信任哪种方法 [@problem_id:3693991]。

总而言之，骨架拆分及其概念上的近亲不仅仅是技术细节。它们是将科学方法应用于机器学习的体现。它们是思想诚实的工具，迫使我们区分简单的内插和困难的外推，区分死记硬背和真正的理解。通过设计我们的计算实验来提出最困难、最诚实的问题，我们确保我们没有自欺欺人，并且我们得到的答案是那些能够真正推动发现的答案。