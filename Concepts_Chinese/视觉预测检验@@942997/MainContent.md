## 引言
我们如何确定一个数学模型，尤其是一个用于在医学或科学领域做出关键决策的模型，是否真正可靠？模型做出单次正确预测的能力是不足够的；其真正价值在于它能够捕捉现实世界中固有的变异性和不确定性的全部范围。这就提出了一个根本性的挑战：我们如何验证模型对现实的描述不仅在平均水平上是准确的，而且在其所有可能性的范围内都是准确的？

本文探讨了一种旨在回答这个问题的强大图形化方法：视觉预测检验（VPC）。VPC是一种基于模拟的诊断工具，它允许模型根据其旨在描述的数据本身来进行评判，从而对其性能提供直观而稳健的评估。通过阅读本文，您将对这一重要的模型评估技术有全面的了解。

我们将从**原理与机制**一章开始，深入探讨核心概念，解释VPC是如何构建的——从“数据工厂”的基本思想到像预测校正VPC（pcVPC）这样处理复杂、异质性数据的先进解决方案。我们还将探讨分层的重要性以及如何考虑不同类型的不确定性。随后，**应用与跨学科联系**一章将把这些原理应用于现实世界，展示VPC如何在药代动力学和药效动力学分析中充当侦探工具，以诊断模型问题、比较竞争模型，并处理如删失数据等实际挑战。

## 原理与机制

我们如何知道一个科学模型是否足够好？毕竟，模型只是我们讲述世界如何运作的一个故事——在我们的案例中，是一个数学故事。它可能预测药物如何在体内转运，疾病如何传播，或者恒星如何演化。但单次正确的预测是不够的。一个坏掉的钟一天也能准两次。要真正信任我们的模型，我们需要知道它是否不仅捕捉了单一结果，而是捕捉了所有可能性的交响乐，即自然界所展现的全部变异和随机性范围。我们需要一种方法来检验我们唯一真实的现实——我们实际收集的数据——看起来是否像是我们的模型所能生成的虚构现实家族中一个合乎情理的、普通的成员。

这就是被称为**基于模拟的检验**的一类诊断工具背后那个优美而简单的思想，而其最著名的成员就是**视觉预测检验（VPC）**。这是一种让模型自我评判的方法。

### 基本思想：数据工厂

想象一下，你建立了一个模型来预测药物在血液中随时间变化的浓度。你同时也有一些来自临床试验的真实数据。VPC的流程就像在你的计算机内部运行数千次虚拟临床试验一样 [@problem_id:4601333]。

1.  **启动工厂**：你采用最终拟合好的模型，并将其用作一个“数据工厂”。你让它在与原始试验完全相同的条件下，模拟一个全新的数据集——比如说，1000个虚拟研究。这意味着受试者数量相同，给药剂量相同，测量时间点也相同。关键的是，每次模拟都包含了你的模型所描述的所有随机性来源：人与人之间的变异（我们称之为**个体间变异**）以及个体内的随机测量噪声或波动（**残差不可解释变异**）。

2.  **描绘可能性之河**：对于任何给定的时间点，你现在拥有的不是一个，而是1000个模拟的浓度值。这个点云代表了模型对世界的看法。从这个点云中，我们可以描绘出模型认为“正常”的范围边界。我们通常会在每个时间点[计算模拟](@entry_id:146373)数据的第5、第50（[中位数](@entry_id:264877)）和第95百[分位数](@entry_id:178417)。当你将这些百分位线连接起来时，你就创造出了一条仿佛流经图表的河流。第50百分位数构成了中心主流，而第5和第95百分位数则构成了河岸。这就是模型的**[预测区间](@entry_id:635786)**——模型预期90%的未来数据会落入的区域。

3.  **与现实比较**：最后决定性的一步是将你的*真实*观测数据点叠加到这条模拟的河流上。现在你可以直观地看到你的模型表现如何。观测数据点是否舒适地落在河岸之内？真实数据的中位数是否与模拟[中位数](@entry_id:264877)的中心主流轨迹一致？如果模型是好的，情况就应该如此。这告诉我们[模型校准](@entry_id:146456)得很好，正确地捕捉了数据的**集中趋势**和**[离散度](@entry_id:168823)**（即分布范围）[@problem_id:4581454]。然而，如果真实数据系统性地偏向河流的一侧，或者显示出更宽或更窄的分布范围，那么VPC就标记出了一个问题。

### 现实中的一个难题：异质性问题

当研究人群相对均一时，这种简单的VPC效果非常好。但如果不是呢？真实世界的研究往往是混乱且异质的。想象一项研究包含两组人：一组体重较轻，接受低剂量药物；另一组体重较重，接受高剂量药物 [@problem_id:4581479]。

如果我们在一个标准的VPC中将他们混为一谈，我们就会造成统计上的混乱。这就像试图描述一个既有老鼠又有大象的动物园里的“平均”动物一样。这个平均值毫无意义。高剂量组的受试者自然会比低剂量组的受试者有高得多的药物浓度。一个标准的VPC图会显示出一条巨大、模糊的预测“河流”，使其几乎无法解读。观测数据与模拟数据之间的不匹配可能并不意味着模型对变异的描述是错误的；它可能只是特定时间窗口内恰好抽样到哪些受试者所造成的一种假象 [@problem_id:4581454]。这张图被研究设计本身所混淆。

### 一个优雅的解决方案：预测校正的视觉预测检验 (pcVPC)

为了解决这个难题，我们需要一种更巧妙的方法：**预测校正的视觉预测检验（pcVPC）**。其指导原则很简单：如果不能直接比较原始数据，那就先对其进行归一化。

pcVPC的机制是一套优雅的统计推理。对于每一个数据点，无论是真实观测值还是模拟值，我们都进行一次校正。我们取浓度值，并根据模型对该*特定个体*（具有其特定剂量、体重等）在该*特定时间*的*典型*浓度预测值对其进行归一化 [@problem_id:4567775]。

对于一个[随机误差](@entry_id:144890)被认为与浓度成正比的模型，这种校正就是一个简单的除法：
$$
Y^{\mathrm{pc}}_{ij} = \frac{Y_{ij}}{f_{ij}}
$$
其中 $Y_{ij}$ 是个体 $i$ 在时间 $j$ 的观测（或模拟）浓度，而 $f_{ij}$ 是模型对该个体在该时间的典型预测值。对于一个加性误差模型，校正则变为减法：$Y^{\mathrm{pc}}_{ij} = Y_{ij} - f_{ij}$ [@problem_id:4567775]。

这就像根据学生所参加考试的难度来调整他们的考试分数。我们不是将简单测试的90分原始分与困难测试的70分进行比较，而是可以比较每个学生在他们各自的测试中*相对于平均分*的表现如何。归一化后，1.0分（对于加性情况是0分）意味着“完全平均”，我们就可以有意义地比较不同测试中分数的分布范围。

pcVPC对我们的药代动力学数据做的正是这件事。通过归一化，我们去除了由剂量和其他协变量引起的可预测差异，从而分离出我们真正想要检验的随机变异。pcVPC提出了一个更精细的问题：不是“模型是否预测了正确的浓度？”，而是“模型是否正确描述了*围绕*预期个体趋势的变异性？”[@problem_id:4581454]。可以说，这使我们能够合并来自老鼠和大象的数据，并生成一个单一、可解读的诊断图。

同样地，这种校正原则还可以进一步扩展。一种称为**变异校正的VPC（vcVPC）**的先进技术，还可以对数据*分布范围*本身随时间或浓度变化的情况进行归一化。这对于处理复杂的误差结构或[删失数据](@entry_id:173222)（例如，浓度低到无法测量）尤其有用 [@problem_id:4567652]。

### 作为侦探工具的VPC

VPC不仅仅是对模型的一个简单的“通过/不通过”的评分；它是一个能提供深刻见解的强大侦探工具。一个总体的pcVPC图可能看起来完全可以接受，表明模型在“平均水平”上运行良好。但平均值可能具有欺骗性。当我们使用**分层VPC**时，其真正的威力才会显现出来。

想象一下，我们的药物由一种受个人基因控制的酶代谢。有些人可能是“慢代谢者”（PMs），清除药物的速度很慢；而另一些人则是“超快代谢者”（UMs），清除药物的速度非常快。如果我们的模型忽略了这一遗传信息，它会将所有人混在一起，并预测一个“平均”的清除率。

现在，让我们对VPC进行分层：我们为PMs单独创建一张图，为UMs创建另一张图。结果可能会非常显著 [@problem_id:4374307]。对于PM组，我们可能会看到他们的真实浓度系统性地*高于*模型的预测河流——模型低估了他们的药物暴露量。对于UM组，他们的真实浓度系统性地*低于*河流——模型高估了他们的药物暴露量。

分层VPC精确地指出了缺陷所在：模型对一个关键的生物学因素视而不见。在总图中，方向相反的偏倚相互抵消了，但通过分层却暴露无遗。补救措施很明确：我们必须回到模型中，并纳入遗传信息，例如，使[药物清除率](@entry_id:151181)参数依赖于基因型。这种构建、检验和优化的迭代循环正是优秀建模的精髓。

由于VPC依赖于从模型估计的群体分布中模拟新数据，因此它们对于某些可能困扰其他诊断方法的统计问题（如**eta-shrinkage**）表现出显著的稳健性。当个体数据稀疏时，就会发生收缩现象，导致其估计的个体参数向群体平均值“收缩”。这会使许多诊断图变得不可靠。而VPC不依赖于这些收缩后的个体估计值，因此即使在这些具有挑战性的情况下，它仍然是一个值得信赖的工具 [@problem_id:4568905]。

### 不确定性的两个方面

当我们建立模型时，会面临两种不确定性，对VPC的深入理解要求我们区分它们 [@problem_id:4601275]。

首先是**[偶然不确定性](@entry_id:154011)**。这是世界固有的、不可简化的随机性——就像掷骰子一样。在我们的情境中，它指的是人与人之间自然的生物学变异以及我们测量中的随机噪声。这是我们通过随机效应和残差误差项构建*到*模型中的不确定性。一个标准的VPC使用一组固定的“最佳猜测”参数，主要检验我们是否正确描述了这种[偶然不确定性](@entry_id:154011) [@problem_id:4601275]。

但还有第二种更微妙的不确定性：**认知不确定性**。这是源于我们自身无知的不确定性。我们模型的参数（如群体平均清除率）并非神圣真理；它们是从有限的、带有噪声的数据中得出的*估计值*。我们永远无法百分之百确定它们的真实值。

一个更忠实、更稳健的VPC应该承认这种认知不确定性。我们可以采取更巧妙的做法，而不是用我们单一的最佳猜测参数集来模拟所有1000次虚拟试验。对于每一次新的模拟，我们可以首先从描述我们对其不确定性的[统计分布](@entry_id:182030)中，抽取一组略有不同但仍然合理的参数。这可以通过假设参数基于[模型拟合](@entry_id:265652)结果服从正态分布来实现，或者更稳健地，通过使用像**[自助法](@entry_id:139281) (bootstrap)** 这样的技术来生成参数的[经验分布](@entry_id:274074) [@problem_id:4601269] [@problem_id:4601275]。

当我们纳入[参数不确定性](@entry_id:264387)时，VPC上产生的“河流”自然会变得更宽。这条更宽的河流代表了对模型预测能力更完整的描绘，因为它不仅考虑了世界上的随机性，也考虑了我们对它认知上的不确定性。

### 最后的警告：偷看的危险

VPC是一个强大的工具，但像任何工具一样，它也可能被滥用。其统计有效性建立在一条神圣的规则之上：检验的程序必须在看到结果*之前*就确定下来 [@problem_id:4567692]。

对于我们如何定义用于计算百[分位数](@entry_id:178417)的时间轴上的“区间”或间隔，这一点尤其重要。想象一下，一个政治民意调查员不断地按年龄、收入和地区对选民进行重新分组，直到最终找到一个能显示他们所支持的候选人正在获胜的分组方式。那不是分析，那是作弊。

VPC也存在同样的诱惑。如果你不喜欢图的样子，你可能会忍不住去调整区间的边界，直到观测数据更整齐地落入预测河流之内。这是一种自我欺骗的形式，它会使诊断失效。你为了得到想要的答案而做了假账。

对抗这种认知陷阱的唯一防御是严格的**预先指定**。在VPC生成之前编写的正式分析计划中，建模者必须定义要使用的确切分箱策略。甚至可以预先指定一个主要策略和一个次要策略，以检验稳健性。通过事先承诺遵守游戏规则，我们确保VPC能作为我们模型性能的公正评判者，从而维护科学过程的完整性 [@problem_id:4567692]。在科学中，知道我们的模型何时是错的，与知道它们何时是对的同样重要。

