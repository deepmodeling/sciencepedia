## 引言
将某物移至更佳位置，是人类创造秩序与效率最基本的策略之一。当我们整理凌乱的书架，将书籍挪到一起为新书腾出空间时，我们就在运用这一策略。这个简单直观的行为背后，隐藏着一个深刻而强大的原则，而这个原则出人意料地正是数字世界的核心。在计算领域，这一原则被称为重定位，它是对抗一个顽固问题——[内存碎片](@entry_id:635227)——的关键工具。[内存碎片](@entry_id:635227)问题即便在系统有大量可用空间时，也可能使其无法使用。本文将深入探讨重定位这一概念。首先，在“原理与机制”一节中，我们将深入探究计算机中使重定位成为可能的美妙“骗局”——程序所见的与物理上实际存在的之间的区别——并探讨其中涉及的复杂机制和隐藏成本。随后，在“应用与跨学科关联”一节中，我们将超越计算机科学的界限，去发现这同一个为特定目的而移动事物的基本原则，如何在生物学、物理学和社会学等不同领域中反复出现，从而揭示其作为一种适应与组织的普适性行为动词。

## 原理与机制

### 拥挤书架的寓言

让我们从一个你肯定遇到过的情境开始。想象一个巨大的、刚整理好的书架。你开始使用它，添加和移除各种尺寸的书籍。一本小小的平装书被一本大教科书取代。一套三卷本的丛书被借出。久而久之，书架变成了一片由书籍和空隙组成的零碎拼图。这时，一位朋友送给你一本华丽的大开本艺术书，但当你准备把它放到书架上时，一个令人沮丧的问题出现了：你总共的可用空间足够多，但都碎成了许多无用的小空隙。没有一个单独的空隙足够大，能放下你的新书。

这本质上就是计算领域一个经典的问题，称为**[外部碎片](@entry_id:634663)**。你计算机的主内存就像那个书架，运行中的程序就是那些书。随着程序的启动和停止，它们会留下各种大小的空洞。最终，系统可能无法启动一个新的大型程序，即使总的可用内存绰绰有余，仅仅因为没有一个足够大的连续内存块。[@problem_id:3656314]

你的书架该如何解决这个问题？显而易见：你把书都挨着排在一起，将所有小空隙整合成一个大的连续空间。这个移动整理的行为，就是计算机科学家所说的**紧凑化**，而使其得以实现的基本操作就是**重定位**。这看似简单，但在计算的世界里，将一个运行中的程序从一个地方移动到另一个地方，是一种深刻而美妙的骗术。

### 地址是个谎言（一个必要而美妙的谎言）

对于一个计算机程序来说，内存地址感觉像是一个绝对的、物理的现实——就像街上的门牌号。如果一个程序在地址1000处存储了一份数据，它就期望在地址1000处找到它。如果我们物理上将程序的数据从，比如说，一个起始于地址1000的块移动到一个起始于5000的块，程序会立刻崩溃。它所有关于其数据存放位置的内部假设都将是错误的。那么紧凑化怎么可能行得通呢？

秘密在于，程序所看到的地址是一个美妙的谎言。它不是一个真实的物理地址，而是一个**[逻辑地址](@entry_id:751440)**。当程序试图访问这个[逻辑地址](@entry_id:751440)时，一个特殊的硬件——**[内存管理单元](@entry_id:751868)（MMU）**——会介入，将其翻译成一个物理地址。实现这一点的最简单机制之一是为每个程序段配备一对寄存器：一个**基址寄存器**和一个**界限寄存器**。基址寄存器存储该段的起始物理地址，而界限寄存器存储其大小。物理地址随后便简单地通过公式 $physical\_address = base + logical\_address$ 计算得出。界限寄存器则用来确保程序不会试图访问其分配段之外的内存。[@problem_id:3656314]

这一层间接性是关键。为了重定位整个程序段，[操作系统](@entry_id:752937)（OS）可以执行一个看似不可能的壮举。它暂停程序，将其整个内存块从旧的物理位置复制到一个新的位置，然后——这便是魔力所在——它只更新一个数字：基址寄存器中的值。当程序恢复运行时，它继续使用和以前一样的[逻辑地址](@entry_id:751440)。但现在，当MMU翻译这些地址时，它们指向了新的物理位置。程序完全没有意识到它的整个世界都被移动了。这就是重定位的核心原则：内存的逻辑视图与其物理现实之间的分离，一个赋予系统巨大灵活性的骗局。

### 新家的代价

这种重定位内存的能力并非没有代价，而且这些代价比你想象的要更深。最明显的代价是复制数据的蛮力工作。将千兆字节的内存从一处移到另一处会消耗宝贵的时间和内存带宽，可能减慢其他所有活动程序的速度。[@problem_id:3628316] 但真正有趣的代价是那些隐藏的代价，即拆除和重建一个程序物理家园所带来的微妙副作用。

其中一个代价，我们或可称之为“大脑混乱”。为了加速地址翻译，CPU维持着一个名为**转译后备缓冲器（TLB）**（或称**快表**）的特殊缓存，它存储了最近的逻辑到物理地址的映射。当我们重定位一个程序段时，它在TLB中所有缓存的条目瞬间失效。[操作系统](@entry_id:752937)必须明确告知CPU使这些陈旧的条目无效。在现代多核处理器上，它必须将这个失效命令发送给*每一个核*。这个过程，有时被称为“[TLB击落](@entry_id:756023)（TLB shootdown）”，是一项显著的开销。在规划紧凑化时，一个聪明的[操作系统](@entry_id:752937)可能会试图通过选择一个重定位最少独立进程所属段的方案来最小化这个成本。[@problem_id:3626118]

当计算机与外部世界交互时，会出现一个更关键的约束。想象一个网卡正在将传入的数据直接写入内存，这个操作称为**直接内存访问（DMA）**。[操作系统](@entry_id:752937)已经告诉了网卡缓冲区的*物理地址*。如果[操作系统](@entry_id:752937)在传输中途重定位了那个缓冲区，网卡对此变化毫不知情，就会继续向旧的、现在已无效的位置写入数据。结果将是[数据损坏](@entry_id:269966)或系统崩溃。为了防止这种情况，[操作系统](@entry_id:752937)必须**锁定**（pin）这些内存区域，将它们标记为在硬件操作完成之前暂时不可移动。[@problem_id:3628316] 每当一个具有重定位功能的系统需要与一个要求稳定物理地址的外部组件（例如，从托管语言调用本地代码时）交互时，这种锁定的概念是一个至关重要的安全机制。[@problem_id:3630310]

### 并非所有指针生而平等

到目前为止，我们讨论了移动程序的数据。但程序的代码本身呢？在拥有**即时（JIT）**编译器的现代系统中，代码常常是动态生成的，并且可能为了优化而被重定位。这就引出了一个有趣的问题：当你移动一段机器码时，那段代码内部的指针和引用会失效吗？

答案美妙地在于“视情况而定”。这完全取决于地址是如何在指令中编码的。

- **绝对地址**：一条指令可能包含一个完整的64位绝对地址。如果这个地址指向一个*外部*的、不移动的位置（比如一个固定的系统库函数），那么即使包含它的[代码移动](@entry_id:747440)了，这个地址仍然有效。指针本身不需要改变。[@problem_id:3654627]

- **相对地址**：一种更为优雅的方法是使用**[PC相对寻址](@entry_id:753265)**。一条指令可能被编码为意指“从*下一条*指令的地址向前跳转100字节”。如果整块代码被移动，[跳转指令](@entry_id:750964)和其目标之间的相对距离保持不变。代码对于其内部引用是**位置无关**的。无需修补！[@problem_id:3654627]

当这两个概念混合时，情况就复杂了。当一条PC相对指令需要调用一个*外部*的、固定的函数时会发生什么？现在，当代码块移动时，相对跳转的起点（[程序计数器](@entry_id:753801)，或PC）改变了，但绝对目标地址保持不变。相对位移变得不正确。为了修复这个问题，[JIT编译](@entry_id:750967)器必须执行一个重定位补丁，根据代码的新位置重新计算位移：$d' = T - (B' + s + \ell)$，其中 $T$ 是绝对目标地址，而 $(B' + s + \ell)$ 是移动后下一条指令的地址。[@problem_id:3648498] 这揭示了一个深刻的真理：重定位迫使我们精确地定义一个地址指向的是什么——是内部的、一同移动的东西，还是外部的、固定的东西——以及这个引用是如何表示的。

### 作为超能力的重定位：垃圾收集的世界

在像C/C++这样的非托管语言世界里，程序员负责内存，而[操作系统](@entry_id:752937)提供粗粒度的重定位工具。但在像Java、C#或Python这样的托管语言中，重定位被提升为一种由运行时的**垃圾收集器（GC）**所挥舞的超能力。

一种特别强大的GC类型是**[复制收集器](@entry_id:635800)**。在一个收集周期中，它找到所有“存活”的对象（那些程序仍然可以访问的对象），并将它们从当前碎片化的内存区域（称为“from-space”）移动到一个全新的、完全紧凑的区域（“to-space”）。整个from-space，现在只包含垃圾和已移动对象的残影，可以被瞬间清空。

GC如何能做到这一点而不破坏程序呢？因为，与[操作系统内核](@entry_id:752950)不同，托管运行时有一个关键优势：它知道*每一个*指向每个对象的引用（或指针）的位置。当它移动一个对象时，它会一丝不苟地找到并更新每一个引用，使其指向新的地址。这种执行精确、全面重定位的能力是革命性的。它不仅消除了[外部碎片](@entry_id:634663)，还提供了一种强大的安全防御。通过不断移动对象，一个移动式GC可以在攻击者利用悬空指针发起**[释放后使用](@entry_id:756383)（use-after-free）**攻击之前，就使这些由bug留下的指针失效。[@problem_id:3643325]

然而，这项超能力也有其局限性。它之所以在托管运行时中有效，也正是它在操作系统内核中通常不可行的原因。用C语言编写的内核不跟踪也无法跟踪指向其内部[数据结构](@entry_id:262134)的每一个指针。一个指针可能在线程的栈上，在CPU寄存器里，或者像我们看到的，被编程进硬件用于DMA。没有能力找到并更新所有引用，移动一个对象就是不安全的。这个根本性的约束解释了为什么内核内存管理器，比如**[slab分配器](@entry_id:635042)**，通常不能使用移动式紧凑化，而必须依赖其他策略来管理碎片。[@problem_id:3683579] 重定位的能力，建立在知晓一切的能力之上。

### 最小移动的艺术

既然重定位是一项昂贵的操作，一个自然而重要的问题随之产生：我们最少可以移动多少？我们并不总是需要执行一次**完全紧凑化**内存。如果我们只需要一个160 KiB的块，也许一次小型的、外科手术式的**部分紧凑化**就足够了。[@problem_id:3626125]

这让重定位从一个简单的整理动作，变成了一个丰富的算法和策略设计领域。它成了一个[优化问题](@entry_id:266749)。满足一个请求所需的最小移动集合是什么？我们想要最小化的“成本”可以有不同的定义：
- 复制的数据总量，以最小化对[内存带宽](@entry_id:751847)的影响。[@problem_id:3626125]
- 被移动段所属的独立进程数量，以最小化昂贵的TLB失效次数。[@problem_id:3626118]
- 针对未来一系列请求的预期总成本，权衡不同大小请求的概率。[@problem_id:3674844]

通过分析当前的[内存布局](@entry_id:635809)以及与每次潜在移动相关的成本，[操作系统](@entry_id:752937)可以做出智能决策。也许移动一个大进程比移动三个小进程更便宜。也许现在移动一个进程来整合空闲空间，将能避免未来一次更昂贵的重定位。在书架上移动书本这个简单的动作，当被转译到计算领域时，绽放出了一场关于预测、优化和权衡的复杂而迷人的舞蹈。

