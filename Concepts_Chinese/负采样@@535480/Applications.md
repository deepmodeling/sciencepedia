## 应用与跨学科联系

在我们之前的讨论中，我们揭示了[负采样](@article_id:638971)的优雅技巧。我们视其为一个解决不可能计算问题的巧妙方案：我们不将一个正确答案与*宇宙中所有其他可能的答案*进行比较，而是简单地教模型从少数几个错误答案中分辨出正确答案。这似乎只是一个计算上的捷过，一个巧妙的工程技巧。但正如我们即将看到的，这个单一、简单的想法远比这深刻得多。它是一个统一的学习原理，回响在众多令人惊叹的科学和技术领域，从解码我们自身的生物学到构建我们最先进人工智能的大脑。这是一段揭示“学习某物*不是*什么”是理解它“*是*什么”之秘诀的旅程。

### 学习世界的语言

现代人工智能的核心，很大程度上在于学习*表示*——将文字、图像甚至基因等混乱的现实世界概念，翻译成计算机可以理解的数字语言。[负采样](@article_id:638971)是解锁这种翻译的大师钥匙之一。

当然，经典的例子是在人类语言中。像 `word2vec` 这样的模型通过学习预测通常出现在某个词（比如“king”）周围的词语（比如“queen”、“royal”或“throne”）来学习这个词的含义。[负采样](@article_id:638971)目标教导模型，“king”和“queen”向量的[点积](@article_id:309438)应该很高，而“king”和少数几个随机选择的“负”样本词（如“cabbage”、“rocket”或“sandal”）的[点积](@article_id:309438)应该很低。通过数百万次地玩这个简单的“这是我的邻居吗？”的游戏，模型雕刻出一个丰富的几何空间，其中含义相近的词最终成为邻居。

真正非凡的是，同样的技术可以用来学习生命本身的语言。我们的DNA是一个用四字母字母表（A、C、G、T）书写的长序列。就像词语构成句子一样，固定长度的短DNA“词”，称为 $k$-mers，构成了我们基因组的功能性“句子”。通过将完全相同的带[负采样](@article_id:638971)的skip-gram逻辑应用于大量的DNA序列语料库，我们可以为每个可能的 $k$-mer 学习一个密集的[向量表示](@article_id:345740)。这使我们能够将基因组的语法翻译成一个数学空间，在这个空间里，功能相似的 $k$-mers（例如，[蛋白质结合](@article_id:370568)位点的部分）会聚集在一起。为了使这一点更加强大，我们可以融入基本的生物学原理。由于DNA是双螺旋结构，一条链上的序列在另一条链上有一个携带相同生物信息的“反向互补”伙伴。通过强制一个 $k$-mer 及其反向互补序列共享相同的[向量表示](@article_id:345740)，我们将这种物理[不变性](@article_id:300612)直接构建到我们的模型中，使学习更高效、更稳健[@problem_id:2479909]。那个为我们带来聊天机器人大脑的想法，现在正帮助我们破译生命的蓝图。

“邻居”的概念不仅限于线性序列。想想社交网络，或者细胞中错综复杂的[蛋白质-蛋白质相互作用](@article_id:335218)（PPI）网络。我们可以通过应用相同的逻辑来学习每个人或每个蛋白质的表示：两个相连的节点应该有相似的向量。为了训练这样一个模型，我们向它提供正样本（已知的相互作用）和负样本（不相互作用的蛋白质对）。但在这里我们遇到了一个微妙而关键的问题：我们应该如何选择负样本？简单地挑选两个不相互作用的随机蛋白质是一个糟糕的策略。绝大多数蛋白质对不相互作用，所以一个随机的负样本几乎总是一个“简单”的负样本。模型很快就能学会区分一个真实的相互作用和一个（比如说）细胞核中的蛋白质与细胞膜中的蛋白质之间的相互作用，因为它们从不在同一个地方。

真正的挑战是区分真实的相互作用和“差一点就成功”的情况。考虑两个蛋白质 $P_i$ 和 $P_j$，它们彼此不相互作用，但都与一个共同的中心蛋白质 $H$ 相互作用。从模型的角度来看，$P_i$ 和 $P_j$ 是“相似的”，因为它们共享一个邻居。这对 $(P_i, P_j)$ 就是一个**困难负样本**。这是模型最有可能误认为是正样本的那种配对。一个成功的[负采样](@article_id:638971)策略必须刻意包含这些困难负样本，以迫使模型学习相互作用的精细规则，而不仅仅是网络中微不足道的大尺度特征[@problem_id:1436726]。

### 选择你的“敌人”的艺术：困难负样本挖掘

这让我们有了更深的理解。负样本的选择不仅仅是一个细节；它正是学习任务的本质所在。一个模型是由它被迫做出的区分来定义的。如果我们只给它提供简单的负样本，它将学到一个懒惰、肤浅的解决方案。

这一教训在像 BERT 这样的大型语言模型的演进中表现得最为清晰。最初的 BERT 模型在两个任务上进行了[预训练](@article_id:638349)：一个是[掩码语言建模](@article_id:641899)（填空），另一个是下一句预测（NSP）。在 NSP 中，模型会看到两个句子 A 和 B，并必须预测 B 是否是 A 在文本中的实际下一句（正样本），还是从不同文档中随机抽取的一个句子（负样本）。结果证明这个任务是有缺陷的。负样本*太容易*被识别出来了。模型不必理解语法或[连贯性](@article_id:332655)；它只需学会如果句子 A 和句子 B 是关于不同的话题，那么它们就是一个负样本对。它学会了成为一个话题匹配器，而不是一个连贯性检测器。

后来的模型，如 ALBERT，用句子顺序预测（SOP）取代了 NSP。在这里，模型总是看到来自同一文档的两个连续句子，但对于负样本，它们的顺序是颠倒的。现在，话题是相同的。模型成功的唯一方法是学习语言中那些区分连贯叙述和杂乱无章叙述的微妙逻辑和因果流。SOP 是一种**困难负样本挖掘**的形式：负样本被精心制作得与正样本尽可能相似，从而迫使模型学习真正重要的特征[@problem_id:3102444]。

这个原则是普适的。想象一下训练一台计算机识别基因组中的[启动子区域](@article_id:346203)——基因的“开关”。我们有一组正样本（已知的[启动子](@article_id:316909)）。我们应该用什么作为负样本呢？我们可以使用随机的“垃圾DNA”片段，但这太容易了。[启动子](@article_id:316909)通常具有特定的属性，比如位于“开放染色质”区域并且具有高[GC含量](@article_id:339008)。一个懒惰的模型可能只会学会识别开放的、富含GC的DNA。为了构建一个更智能的模型，我们必须使用更智能的[负采样](@article_id:638971)策略。理想的“困难负样本”是那些*也*来自开放染色质并且*也*具有高[GC含量](@article_id:339008)，但我们确切知道它们不是[启动子](@article_id:316909)的序列（例如，通过使用其他实验数据）。通过训练模型区分[启动子](@article_id:316909)和这些几乎相同的“诱饵”，我们迫使它发现真正定义[启动子](@article_id:316909)的特定功能性[序列基序](@article_id:356365)[@problem_id:2429087]。同样的逻辑也适用于预测视频序列的未来：下一帧最困难的负样本不是来自另一部电影的某一帧，而是来自同一场景几秒钟后的某一帧[@problem_id:3122293]。

### 从简单比较到校准世界

到目前为止，我们一直将[负采样](@article_id:638971)视为创建简单二元选择的一种方式：这个或不是这个？但这个框架可以扩展到解决涉及偏见和[分布式系统](@article_id:331910)的更微妙问题。

考虑一个电影[推荐引擎](@article_id:297640)。它的目标是预测你——用户——会喜欢哪些电影。我们有隐式数据：你看过的电影（正样本）。其他所有东西都是一个未标记的负样本海洋。为了训练模型，我们可以从中采样一些未看过的电影作为负样本。但应该选哪些呢？一个简单的策略是采样热门电影作为负样本，因为这可以作为一种困难负样本挖掘（模型必须学习你的独特品味，而不仅仅是向每个人推荐大片）。但这引入了一个危险的偏见。模型会因为推荐热门电影而受到过度惩罚，即使你可能喜欢它。采样策略污染了学习信号。

解决方案是一段优美的统计推理。我们可以通过调整模型的内部分数来纠正这种采样偏差。如果我们采样一个比平均水平受欢迎 $N$ 倍的负样本电影，我们就给模型一个“让步”，告诉它：“别太担心这个；我知道你经常看到它是因为它很受欢迎。”在数学上，这是通过在其分数上增加一个与该项目流行度对数成正比的项 $\log(p_j)$ 来完成的。这种去偏处理让模型能够学习到你真实的潜在偏好，使其与全球流行趋势的噪音分离开来[@problem_id:3110081]。

在现代的[联邦学习](@article_id:641411)[范式](@article_id:329204)中，[负采样](@article_id:638971)*分布*的重要性变得更加关键。想象一下，在数百万部智能手机上训练一个模型，而用户的数据永远不会离开他们的设备。我们可以尝试让每部手机仅使用自己的照片作为负样本来进行[对比学习](@article_id:639980)。但这会导致灾难。你手机上的模型可能会学会区分你的狗和你的猫，但它永远学不会区分你的狗和你邻居的狗，因为它从未见过你邻居的照片。每部手机都学习了一个关于自己小世界的好模型，但“全局”模型（所有模型的平均值）却是一个支离破碎的烂摊子。

解决方案是让手机共享它们的负样本，或者至少是它们的[向量表示](@article_id:345740)。通过维护一个从所有设备中提取的共享“记忆库”负样本，每部手机都可以对照一个更能代表整个世界数据的样本来训练其模型。即使这些共享的负样本由于[通信延迟](@article_id:324512)而略有陈旧，使用一个分布更佳的“敌人”集合的好处也远远超过了它们陈旧的成本。这使得联邦系统能够学习一个单一、连贯的表示空间，在这个空间里，你的狗与其他狗相近，并且全局上远离所有的猫[@problem_id:3124674]。

### 一个统一的原理

从词语到基因，从推荐电影到连接一个去中心化的设备世界，[负采样](@article_id:638971)的原理已被证明是一个惊人多功能的工具。其基本概念可以用[基于能量的模型](@article_id:640714)（EBMs）的语言进行优雅地阐述。在这种观点下，模型的目标是学习一个覆盖所有可能性的“能量景观”，为合理的结局赋予低能量，为不合理的结局赋予高能量[@problem_id:3173654]。用[负采样](@article_id:638971)进行训练是塑造这个景观的一种方式。每个正样本将该点的能量表面向下拉，创造一个[稳定谷](@article_id:306305)。每个负样本将表面向上推，创造一座山脉来围住山谷。通过精心选择我们的负样本——尤其是困难负样本——我们不仅仅是在训练一个分类器；我们是在一次又一次的比较中，雕刻一个精细、准确的现实模型。这是一个美丽的证明，展示了学习的力量，不仅来自于什么是正确的，也来自于什么是微妙的、几乎正确但又不完全正确的。