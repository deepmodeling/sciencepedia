## 应用与跨学科联系

我们花了一些时间来了解我们故事中的角色：[认知不确定性](@article_id:310285)，即我们自身无知的阴影；以及[随机不确定性](@article_id:314423)，即世界本身不可简化的模糊性。乍一看，这似乎有点像哲学上的吹毛求疵。只要我们知道自己不确定，*为什么*不确定真的重要吗？事实证明，答案是响亮的“是”。区分这两种疑虑的能力不仅仅是一项学术活动；它是将简单的预测工具转变为智慧的合作者、科学发现的向导和高风险决策中的守护者的秘密成分。它是一台只给出答案的机器与一台理解自身知识局限的机器之间的区别。让我们在现代科学和工程的几个领域中走一遭，看看这个原理的实际应用。

### 智能科学家的指南針

科学发现的行为本身就是一场对抗无知的战斗。我们不断地问自己：接下来我应该做什么实验？我应该在哪里寻找以学到最多？传统上，这一直是人类直觉的领域，是经验、理论和 serendipity 的混合体。但是通过教导我们的模型识别它们自己的认知不确定性，我们可以给它们一个指南针，来导航广阔、未知的知识领域。

想象一下，我们正在寻找一种新材料来制造更好的电池，一种具有高[离子电导率](@article_id:316808)的新型固态[电解质](@article_id:297653) [@problem_id:1312281]。我们有一个机器学习模型，它在一百种已知材料上进行了训练，能够预测一种新的、假设的成分的[电导率](@article_id:308242)。该模型标记了两个有希望的候选物 A 和 B，两者都有很高的预测电导率。但它们的不确定性截然不同。对于候选物 B，模型对其预测相当确定，但报告了高的[随机不确定性](@article_id:314423)；这意味着候选物 B 位于我们“化学地图”中一个经过充分探索的区域，但该区域的测量本身就存在噪声。对于候选物 A，情况则相反：模型报告了非常高的认知不确定性。它在告诉我们：“我预测这会很好，但我身处未知的领域。我以前从未见过类似的东西。”

如果我们的目标是*立即*找到一种可用的材料，我们可能会选择更“安全”的候选物 B。但如果我们的目标是*学习*并改进我们未来所有搜索的模型，选择是明确的：我们必须合成并测试候选物 A。探测高认知不确定性的区域就像派一名侦察兵进入一个未探索的山谷；我们得到的反馈信息，无论好坏，都填补了我们地图上的一个空白点。这种策略，被称为[主动学习](@article_id:318217)或[贝叶斯实验设计](@article_id:348602)，从根本上是由量化然后寻求减少认知不确定性来驱动的。

为什么这如此有效？从信息论的角度来看，最有价值的实验是那个能最大限度地减少我们对 underlying reality 的无知的实验。这并不仅仅是去总不确定性最高的地方。在高随机噪声区域进行的实验可能高度不确定，但它不会教会我们很多我们不知道的东西——那只是一个嘈杂的区域。真正的“[信息增益](@article_id:325719)”来自于在我们模型最困惑的区域进行一次干净的测量。理想的实验是认知不确定性与[随机不确定性](@article_id:314423)之比最高的那个 [@problem_id:2749090]。我们想问一个我们的模型迫切想知道答案，并且答案可能很明确的问题。

同样的原理让我们能将模型的困惑转化为真正的发现。考虑一下现代[蛋白质结构预测](@article_id:304741)的奇迹，以 [AlphaFold2](@article_id:347490) [@problem_id:2107945] 等模型为例。当这样的模型预测蛋白质的三维形状时，它也会报告其置信度。假设对于蛋白质的一个长片段，[置信度](@article_id:361655)分数 stubbornly 低。是模型失败了吗？还是它在告诉我们一些深刻的东西？我们可以通过进行一个计算实验来诊断这个问题：我们向模型提供越来越多的进化数据（更深的[多序列比对](@article_id:323421)）。如果低[置信度](@article_id:361655)是认知的——如果模型只是数据不足——那么随着我们提供更多信息，它的置信度应该会上升，预测的结构应该会收敛。但是如果[置信度](@article_id:361655)保持很低，并且即使有大量数据，模型仍然预测出多样化的形状集合，这是一个[随机不确定性](@article_id:314423)的迹象。模型没有失败；它发现该蛋白质片段没有固定的结构。它是一个内在无序区（IDR），是蛋白质的一个灵活、动态的部分，其形状变化本身就是其生物功能的关键。模型的 uncertainty，一旦被正确解释，就反映了一种物理现实。

### 诚实的工程

除了纯粹的发现，区分不确定性对于构建稳健可靠的工程系统也至关重要。当我们构建一个世界模型时，无论是原子的模拟还是语言翻译器，它都是一个近似。诚实地面对其不完善的本质是管理它们的第一步。

在计算化学中，科学家们建立机器学习模型来近似那些支配分子行为的极其复杂的量子力学计算 [@problem_id:2648582]。这些模型从一组参考计算中学习原子间的力。但是当模型对某个力不确定时会发生什么？知道*原因*至关重要。如果是高[认知不确定性](@article_id:310285)，这意味着模型遇到了它没有训练过的原子[排列](@article_id:296886)；解决方案是在该配置中为其提供更多训练数据。如果是高随机不確定性，原因可能是参考计算本身存在噪声（某些高端但随机的量子方法的特征），或者我们正在使用一个“粗粒度”模型，我们已经平均掉了一些细节，从而引入了固有的随机性。在第一种情况下，我们改进我们的训练数据；在第二种情况下，我们必须接受并正确地建模系统的内在随机性。

同样的逻辑也适用于工程生命本身。在合成生物学中，我们可能会设计一个 DNA 序列来充当基因的“调光开关”，旨在达到特定的[蛋白质表达](@article_id:303141)水平 [@problem_id:2749107]。但生物学是出了名的嘈杂。即使是相同环境下基因相同的细胞也会显示出不同的表达水平（[随机不确定性](@article_id:314423)）。我们的测量工具又增加了一层噪声（也是随机的）。除此之外，我们关于 DNA 序列如何映射到表达的模型是不完整的（[认知不确定性](@article_id:310285)）。一个智能[优化算法](@article_id:308254)必须能够区分这些。为了有效地搜索最佳 DNA 序列，它必须优先探索*认知*不确定性高的序列，而不是在那些本质上 просто 嘈杂的区域重复采样。

也许最直观的例子来自于我们日常互动的人工智能领域：语言。想象一个神经机器翻译系统，任务是翻译一个英语句子 [@problem_id:3197070]。如果源句子包含模糊词“bank”，模型可能不确定是翻译成法语的“banque”（金融机构）还是“rive”（河岸）。这种不确定性是随机的；它根植于输入的模糊性。一个完美的模型，即使有无限的训练数据，在没有更多上下文的情况下也应该保持不确定。现在，考虑一个包含罕见技术术语的不同句子，比如“anisognathous”。一个典型的模型也可能不确定，但原因不同。[神经网络](@article_id:305336)的不同部分，基于它們的随机初始化和训练期间的不同经历，可能会提供相互冲突但各自自信的建议。这种[分歧](@article_id:372077)是[认知不确定性](@article_id:310285)的标志。模型实际上是在说：“我真的不知道，所以这里有一些胡乱的猜测。”对于模糊的“bank”，解决方案是尋求更多上下文。对于罕见的“anisognathous”，解决方案是为模型提供更多训练数据。

### 高风险决策与[算法](@article_id:331821)伦理

当风险最高——当模型的预测影响到人类健康和安全的决策时——这种区别的清晰之光最为耀眼。在这里，“我不知道”不是一个单一的陈述，而是一套丰富的、可操作的诊断。

考虑一个旨在帮助医生从医学图像中诊断罕见疾病的[深度学习](@article_id:302462)模型 [@problem_id:3197096]。处理患者的扫描图后，模型必须提出建议。
- **情景 1：高认知不確定性。** 模型输出一个预测，但其内部的随机[前向传播](@article_id:372045)“委员会”完全陷入混乱。有些部分尖叫“疾病”，另一些部分低语“健康”。这是一个明确的信号，表明患者的案例不寻常，超出了模型的可靠知识库。模型是在说：“我超出了我的能力范围。”应对措施不是相信预测，也不是要求重新扫描，而是**上报给人类专家**。模型已经认识到了自己的无知。
- **情景 2：高随机不確定性。** 模型的内部委员会达成了一致，但他们的共識是一种不確定性。他们都同意预测结果是一半一半，可能是因为图像模糊或包含模棱两可的特征。模型是在说：“你给我的数据不清楚。”应对措施是**要求重新扫描**。需要更好的测量来解决这种模棱两可。
- **情景 3：低总不確定性。** 模型的预测既自信又一致。它知道自己看到了什么，并且对此很有把握。在这里，也只有在这里，我们才能信任模型的输出进行自动诊断。

这种提供自身不确定性的鉴别诊断的能力，将模型从一个黑箱提升为一个透明且值得信赖的临床伙伴。它知道自己知道什么，知道自己不知道什么，也知道什么时候世界太模糊而无法做出判断。

这就把我们带到了最后一个，也许是最重要的领域：公共安全。想象一下，部署一个人工智能来预测沿海社区的风暴潮危险 [@problem_id:3117035]。仅仅发布一个单一的数字——“浪涌将是 3.1 米”——在科学上是不诚实的，在伦理上是疏忽的。它隐藏了全部真相。一个负责任的系统必须量化并传达两种形式的不确定性。它应该能够陈述其[认知不确定性](@article_id:310285)（“我们对这个预测不太确定，因为风暴正在沿着一条我们数据有限的异常路径行进”）和[随机不确定性](@article_id:314423)（“即使对于一条我们很了解的路径，海洋的[湍流](@article_id:318989)性質也意味着浪涌可能轻易地比我们的最佳猜测高或低半米”）。

最终的输出不应该是一个单一的数字，而是一个校准过的概率：“浪涌超过 4 米防洪堤的可能性有 30%。”这赋予了市政官员、应急响应人员和公众做出自己知情的、基于风险的决策的能力。它尊重他们的能动性并建立信任。因此，对不确定性的谨慎、有原则的分离和沟通，不仅仅是好的科学。它是[算法](@article_id:331821)时代新伦理的一个基本原则。它确保了在我们构建日益强大的工具来预测未来时，我们能以科学一直以来所要求的谦逊和理智的诚实来做到这一点。