## 引言
在为我们的世界建立模型的科学探索中，不确定性是一个不可避免的现实。它是我们的预测与自然真实状态之间的差距。然而，将所有不确定性视为一个单一、模糊的概念是一个严重的疏忽。这种做法掩盖了我们疑虑的真正来源，阻碍了科学进步，并使我们无法构建真正稳健和可信的智能系统。关键在于理解并非所有不确定性都是相同的。两种类型之间存在着根本的区别：[随机不确定性](@article_id:314423)，即系统固有的随机性；以及认知不确定性，源于我们自身知识的缺乏。

本文对这一重要区别进行了全面探讨。第一章“原理与机制”将阐述[随机不确定性](@article_id:314423)和[认知不确定性](@article_id:310285)的核心定义，揭示那些能让我们将总[不确定性分解](@article_id:362623)为这两个组成部分的深层数学定律。我们将探讨这种分解在回归和分类问题中的实际应用。在这一理论基础之上，“应用与跨学科联系”一章将展示为何这种分离不仅仅是学术上的练习，而是一种实践上的必需，展示其在[材料科学](@article_id:312640)、合成生物学乃至为医学和公共安全开发安全且合乎伦理的人工智能等领域带来的变革性影响。

## 原理与机制

在我们理解和预测世界的探索中，我们不断面临不确定性。它如同迷雾，遮蔽了从因到果的路径。但并非所有的迷雾都一样。有些是景观本身固有的浓密、持久的薄雾，而有些则是晨曦中的薄靄，随着知识的太阳升得更高而消散。科学的核心，正是在这片迷雾中航行的艺术，而关键的第一步是识别其不同形式。两种基本不确定性类型——**[随机不确定性](@article_id:314423) (aleatoric)** 和 **[认知不确定性](@article_id:310285) (epistemic)**——之间的区别，不仅仅是一个哲学上的注脚；它是一个深刻的数学原理，塑造了我们构建模型、解释数据以及在从工程到医学的各个领域中做出决策的方式。

### 疑虑的两面：我们不知道的 vs. 我们无法知道的

想象一下，你正试图预测一粒尘埃在阳光中舞动的确切位置。它的运动中存在某种固有的、[抖动](@article_id:326537)的随机性，这是由无数次与空气分子的碰撞引起的。即使对物理学有完美的理解，你也永远无法预测它的确切路径。这种系统的不可簡化、內建的可變性，我们称之为**[随机不确定性](@article_id:314423)**。这个词源于拉丁语中的 *alea*，意为“骰子”——这便是宇宙在掷骰子。它代表了原则上我们*无法*知道的事情。

现在，想象你是一名计算工程师，正在模拟一座桥梁对风的响应 [@problem_id:2448433]。阵风有一个随机、[湍流](@article_id:318989)的成分；那是[随机不确定性](@article_id:314423)。但也可能你不知道所用钢材的精确刚度。你有一个来自制造商手册的数值，但那是一个通用规格，而不是对你桥梁中所用批次的直接测量。这种不确定性是不同的。它源于*知识的缺乏*。如果你对特定的钢材进行更多测试，你就可以缩小其刚度值的范围，这部分不确定性就会减小。这就是**认知不turkey性**，源于希腊语 *episteme*，意为“知识”。它代表了我们目前还*不知道*的事情。

简而言之：
- **[随机不确定性](@article_id:314423)**（或*统计不确定性*）是系统中固有的随机性。它是数据生成过程本身的属性。你无法通过收集更多同[类数](@article_id:316572)据来减少它，但你可以[期望](@article_id:311378)用[概率分布](@article_id:306824)来描述它。
- **[认知不确定性](@article_id:310285)**（或*[系统不确定性](@article_id:327659)*）是我们对世界模型的不确定性。这是我们自身的无知。原则上，它可以通过收集更多数据、改进我们的模型，或者正如我们将看到的，通过整合更多知识来减少 [@problem_id:3197079]。

### 伟大的分解：不确定性的普适定律

如果这种区别仅仅是一个有用的心智模型，那它就不会成为一个深刻的数学真理。事实证明，在正确的数学框架下，预测中的总不确定性可以被 neatly 分解为这两个独立的部分。这不是一个近似；这是一个基本的概率定律，如同[万有引力](@article_id:317939)定律一样深刻和普适。

#### 通过[方差分解](@article_id:335831)

让我们首先通过方差的视角来看待这个问题，方差是回归问题中衡量离散度或不确定性的常用指标，我们用它来预测一个数值。假设我们有一个模型（如[神经网络](@article_id:305336)），其参数为 $\theta$，试图从输入 $X$ 预测输出 $Y$。我们的[认知不确定性](@article_id:310285)体现在我们不知道唯一的真实 $\theta$；相反，我们有一个关于它的 plausbile 值的分布。**全方差定律**为我们提供了一个惊人优雅的总预测方差公式：

$$
\mathrm{Var}(Y \mid X) = \underbrace{\mathbb{E}_{\theta}[\mathrm{Var}(Y \mid X, \theta)]}_{\text{随机部分}} + \underbrace{\mathrm{Var}_{\theta}(\mathbb{E}[Y \mid X, \theta])}_{\text{认知部分}}
$$

让我们来解读一下。左边的项是我们预测中的总不确定性。它是两部分之和。

第一项，$\mathbb{E}_{\theta}[\mathrm{Var}(Y \mid X, \theta)]$，是**随机**部分。它表示：“对于我们模型的每个可能版本 $\theta$，结果中都存在一些固有的噪声或方差，即 $\mathrm{Var}(Y \mid X, \theta)$。让我们在我们认为 plausbile 的所有模型上平均这个[固有噪声](@article_id:324909)。”这是我们[期望](@article_id:311378)看到的不可简化的随机性，无论哪个特定模型是正确的 [@problem_id:3184726]。

第二项，$\mathrm{Var}_{\theta}(\mathbb{E}[Y \mid X, \theta])$，是**认知**部分。它表示：“对于每个可能的模型 $\theta$，都有一个平均预测，即 $\mathbb{E}[Y \mid X, \theta]$。当我们让 $\theta$ 在所有 plausbile 模型中变化时，这些平均预测之间的差异有多大？”如果我们所有可能的模型都做出相同的平均预测，则此项为零。如果它们差异很大，则此项很大。这实际上是由我们对模型本身的不确定性引起的方差 [@problem_id:3180557] [@problem_id:66026]。

这种分解不仅仅是理论上的。在现代机器学习中，像[贝叶斯神经网络](@article_id:300883)或[深度集成](@article_id:640657)这样的方法明确地估计了这两项，为理解模型*为何*不确定提供了一种有原则的方法 [@problem_id:2479717]。

#### 通过熵分解

这个原理是如此基础，以至于它也出现在其他数学语言中。在信息论中，即比特和知识的语言，我们使用**香农熵**找到了一个类似的分解，它衡量分类问题中的不确定性。给定输入 $X$ 时，预测 $Y$ 的总不确定性可以分解为：

$$
H(Y \mid X) = \underbrace{\mathbb{E}_{\theta}[H(Y \mid X, \theta)]}_{\text{随机部分}} + \underbrace{I(Y; \theta \mid X)}_{\text{认知部分}}
$$

这里，$H(Y \mid X, \theta)$ 是*特定*模型 $\theta$ 的结果的熵（不确定性）。在所有模型上对此进行平均，得到[随机不确定性](@article_id:314423)。认知项 $I(Y; \theta \mid X)$ 是预测与模型参数之间的**互信息**。它量化了如果有人告诉我们真实的参数 $\theta$，我们将获得多少关于预测的信息。换句话说，它是我们[模型不确定性](@article_id:329244)的直接度量 [@problem_id:1608607]。

### 不确定性图集：疑虑的样貌

在实践中看到这两种不确定性，使得这种区别变得非常清晰。想象一个分类器，它是使用像[蒙特卡洛丢弃](@article_id:640595)这样的技术构建的，试图将一张图片分类到三个类别之一。它不是给出一个预测，而是给我们一组预测，近似我们对模型的不确定性。让我们来看一个诊断测试套件中的几个典型案例 [@problem_id:3174139]：

*   **低不确定性：** 委员会意见高度一致，且每个成员都很有信心。例如，每个预测都接近 `[0.99, 0.005, 0.005]`。在这里，[随机不确定性](@article_id:314423)和认知不确定性都很低。模型很确定，并且模型的所有版本都确定的是同一件事。

*   **高[随机不确定性](@article_id:314423)，低认知不確定性：** 委员会成员都同意，但他们同意的是不确定性！每个预测都接近 `[0.33, 0.34, 0.33]`。模型对于*预测什么*并不困惑；它自信地预测结果是在三个类别之间随机选择。这是纯粹的[随机不确定性](@article_id:314423)。输入本身在根本上是模棱两可的。

*   **低[随机不确定性](@article_id:314423)，高[认知不确定性](@article_id:310285)：** 在这里，每个委员会成员都非常有信心，但他们彼此不同意。一个预测 `[0.95, 0.03, 0.02]`，另一个预测 `[0.02, 0.96, 0.02]`，第三个预测 `[0.02, 0.03, 0.95]`。每个单独的预测都有低熵（它很自信），所以随机部分很低。但是它们之间的分歧巨大，表明认知不确定性很高。模型知道答案是明确的，但它不知道*哪个*明确的答案是正确的。当我们要求模型预测远离其训练数据的东西时，通常会发生这种情况。

### 驯服和理解不确定性

认识到疑虑的两面性使我们能够制定策略。我们不能用同樣的方式对抗它们。

[认知不确定性](@article_id:310285)是我们的朋友，因为它告诉我们模型的弱点在哪里。我们可以积极努力减少它。最明显的方法是收集更多数据。当我们向贝叶斯模型提供更多数据时，其参数的[后验分布](@article_id:306029)会变得更加尖锐，“模型委员会”会达成更强的共识，分解中的认知项也会缩小 [@problem_id:3180557]。一个更强大的工具是整合领域知识。想象一下我们正在拟合一条线到数据，但我们从物理学中知道这条线*必须*通过原点。强制执行这个约束就像为线的截距提供了无限强的证据，完全消除了与该参数相关的认知不确定性，并减少了总预测不确定性 [@problemid:3197079]。

另一方面，[随机不确定性](@article_id:314423)是我们必须接受和尊重的世界特征。我们无法减少它，但我们可以也必须正确地对其建模。如果数据中的[固有噪声](@article_id:324909)不是一个简单的、方差恒定的钟形曲线，我们的模型必须反映这一点。例如，在[材料科学](@article_id:312640)中，计算出的属性的误差对于不太稳定的材料可能会更大。一个好的模型会学习这种**异方差**噪声，为那些输入预测更高的[随机不确定性](@article_id:314423) [@problem_id:2479717]。更深刻的是，有时随机性根本不是一个简单的钟形曲线。如果一个过程可能导致两个不同的结果（[双峰分布](@article_id:345692)），试图用单一的高斯似然来拟合它注定会失败。再多的数据或认知建模也无法修复这种根本性的不匹配。模型会错误地报告一个单一、宽泛的不确定性分布，而不是两个独立的、更窄的可能性。为了捕捉这种复杂的随机结构，我们需要一个更灵活的[似然](@article_id:323123)模型，比如[高斯混合模型](@article_id:638936) [@problem_id:3197060]。

### 变化的边界：当知识改变随机性

这个故事最美的部分或许是，[随机和](@article_id:329707)认知之间的界限并不总是固定的。看似不可简化的随机性，在更深的洞察下，可能会揭示出它只是伪装的知识缺乏。

考虑一个分类问题，对于给定的输入，结果似乎是 50/50 的抛硬币。这被记录为最大的[随机不确定性](@article_id:314423)：整整一比特的熵。系统看起来完全是随机的。但假设我们发现了一个我们没有意识到的隐藏背景，一个[隐变量](@article_id:310565)。比方说，如果这个[隐变量](@article_id:310565)是 'A'，结果有 90% 的可能性是 '类别 1'，如果它是 'B'，结果有 90% 的可能性是 '类别 2'。

通过发现这种潜在结构，我们减少了我们对*过程*的[认知不确定性](@article_id:310285)。这样做，我们也极大地减少了结果的表面[随机不确定性](@article_id:314423)！抛硬币毕竟不是随机的；它只是依赖于一个我们不知道的因素。在数学上，这是[熵的凹性](@article_id:298497)和[琴生不等式](@article_id:304699)的直接结果：平均值的不确定性总是大于或等于不确定性的平均值 [@problem_id:3197075]。

这最后的转折揭示了知识与随机性之间的动态舞蹈。随着我们更多地了解宇宙隐藏的齿轮，一些随机机会的迷雾消散了，转变为认知理解的清晰景观。因此，区分这两种不确定性不仅仅是一项技术练习；它正是科学进步的引擎，让我们能够削弱我们所不知道的，同时学会尊重和描述我们所居住的世界的基本随机性。

