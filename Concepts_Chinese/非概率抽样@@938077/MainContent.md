## 引言
当我们想要了解一个大群体时——无论是某个城市的人口还是某个社交网络的用户——通常不可能研究每一个个体。我们必须选择一个样本，即一个代表全体的较[小群](@entry_id:198763)体。而抽取样本所用的方法是决定我们的发现是真实反映总体情况还是扭曲幻象的唯一最重要因素。然而，许多研究人员误解了不同方法之间的关键权衡，特别是非概率抽样的风险和适当用途。这可能导致有重大现实后果的错误结论。

本文全面概述了非概率抽样，旨在阐明其原理和正确应用。首先，在“原理与机制”一章中，我们将剖析概率抽样和非概率抽样的核心区别。我们将探讨普遍存在的[选择偏差](@entry_id:172119)威胁，解释为何大样本无法解决这个问题，并揭示基于网络的抽样中隐藏的偏差。我们还将涉及用于缓解这些问题的统计学“校正艺术”。随后，“应用与跨学科联系”一章将重点从妥协转向策略。它展示了非概率[抽样方法](@entry_id:141232)不仅是一种次优选择，而且在回答特定科学问题时，往往是最强大和最精确的工具，从揭示定量结果背后的“为什么”到触及最[边缘化](@entry_id:264637)的社区。

## 原理与机制

想象一下，你是一位厨师，任务是发现一大锅汤的真正“味道”。你当然不能喝掉整锅汤。你唯一的选择是尝一勺。你如何舀取那一勺，决定了你能得出的一切结论。如果你把汤彻底搅拌均匀，然后从任何地方舀一勺，你可以相当自信地认为你的小尝代表了整锅汤。但如果你只从顶层的一层油中啜饮呢？你可能会得出结论，这锅汤是纯脂肪。如果你只从底部烧焦的部分刮取呢？你可能会认为这是一场烹饪灾难。

这个简单的类比正是抽样的核心所在。当我们想了解一大群人——整个城市、一个国家，或一个社交网络的所有用户——我们无法研究每一个人。我们必须抽取一个样本，即人口的“一勺”。我们用来抽取该样本的方法是决定我们的发现是反映整体的真实情况，还是扭曲、有偏见的幻象的唯一最重要因素。

### 两种样本的故事：已知与未知

在统计学世界里，[抽样方法](@entry_id:141232)大致分为两大类：概率抽样和非概率抽样。它们之间的区别，就像公平的彩票和被操纵的游戏之间的区别一样至关重要。

**概率抽样**是黄金标准，是那锅被彻底搅拌过的汤。其定义性特征是，目标总体中的每一个个体都有一个*已知*的、非零的被选中概率。为实现这一点，我们首先需要一个我们目标总体中所有人的完整列表，这个名册被称为**抽样框** [@problem_id:4400327]。想象一下，把一个城市里每个居民的名字都写在一张单独的票上。要进行简单随机抽样，我们把所有的票都放进一个巨大的滚筒里，转动摇柄，然后抽出几百个名字。每个公民都有一个相等且已知的机会。

这种对入选概率的了解是极其强大的。它是一个数学上的保证，让我们能够利用概率定律从我们的样本推广到整个总体。它不仅让我们能够估计一个特征，比如平均身高，还能计算我们对该估计的不确定性——也就是你在政治民意调查中听到的“[误差范围](@entry_id:169950)”。

现在考虑另一种选择：**非概率抽样**。顾名思义，这里的入选概率是未知的。我们没有一个装满票的大滚筒；相反，我们走捷径。我们可能站在一个繁忙的街角，调查前500名路过的人；这被称为**[方便抽样](@entry_id:175175)**。或者我们可能找到几个人，请他们招募他们的朋友和同事，然后这些人再招募他们自己的朋友，这个过程称为**雪球抽样**。这些方法通常比创建抽样框和进行概率抽样这样艰苦的工作更快、更便宜、更容易。但这种方便是以一个高昂且常常是隐藏的代价换来的。

### 偏差的幽灵：为什么更容易并非更好

我们为非概率抽样的便利所付出的代价是**[选择偏差](@entry_id:172119)**。因为被纳入样本的机会是未知且不受控制的，某些类型的个体被系统性地更有可能进入我们的样本，从而扭曲了我们对总体的看法。

让我们把这一点具体化。想象一下，一个公共卫生部门想要估计未确诊高血压的患病率。他们决定通过在当地一家初级保健诊所招募患者来进行[方便抽样](@entry_id:175175)。假设在总人口中，20%的人是吸烟者，80%是非吸烟者。吸烟者中未确诊高血压的真实患病率（30%）高于非吸烟者（10%）。快速计算显示，人口中的真实总体患病率为 $(0.20 \times 0.30) + (0.80 \times 0.10) = 0.14$，即14%。

然而，吸烟者比非吸烟者更可能去诊所。假设在这家诊所，吸烟者被纳入样本的可能性是非吸烟者的两倍。因此，样本将不再是20%的吸烟者，而是不成比例地充满了他们。样本中吸烟者的新比例变为 $\frac{0.20 \times 2}{(0.20 \times 2) + (0.80 \times 1)} \approx 0.33$，即33%。如果我们从这个有偏的样本中计算患病率，我们会得到 $(0.33 \times 0.30) + (0.67 \times 0.10) \approx 0.167$，即16.7% [@problem_id:4570382]。我们的估计是系统性错误的，不是因为运气不好，而是因为我们的[抽样方法](@entry_id:141232)本身就有缺陷。我们把油腻顶层的味道误认为是整锅汤的味道了。

一个普遍而危险的误解是，这种偏差可以通过简单地收集一个非常大的样本来克服。这是错误的。一个大的有偏样本只会给你一个非常精确、非常自信的错误答案 [@problem_id:4400327]。[大数定律](@entry_id:140915)确保样本平[均值收敛](@entry_id:269534)于*被抽样总体*的平均值，而不是目标总体的平均值。如果你一直从油层啜饮，喝一千口也不会让你更了解底部的蔬菜。

### 连接的隐藏架构：网络中的偏差

当我们研究的不仅仅是个体的集合，而是相互连接的网络时，[选择偏差](@entry_id:172119)的机制可能更加微妙和深刻。这引出了一个被称为“友谊悖论”的奇特现象：平均而言，你的朋友比你有更多的朋友。

这不是社交失败的标志；这是网络的一个数学属性，揭示了关于抽样的一个深刻真理。当你从人群中“抽样”朋友时，你不是在随机挑选人。你是通过遍历社交网络的边缘来发现他们的。一个有100个朋友的人有100条路径通向他们，而一个有2个朋友的人只有2条。因此，你更有可能“遇到”并与一个高度连接的人交朋友。

这正是**雪球抽样**中起作用的机制。通过追踪联系——友谊、协作或沟通——我们被系统性地引向网络的中心节点。一个节点被包含在我们样本中的概率变得与其连接数（其度数，$k$）成正比。因此，我们在样本中观察到的度数分布不是真实的分布 $p_k$，而是一个更接近于 $k \cdot p_k$ 的**规模偏倚分布** [@problem_id:4262483]。

这不仅仅是一个统计学上的奇事；它具有巨大的现实世界后果。想象一下，使用雪球抽样来研究一个通信网络以了解其脆弱性。你的样本将充满高度数中心节点，使得网络看起来比真实情况更加集中化，并且被这些中心节点主导。结果，你可能会得出结论，该网络极其脆弱，移除几个关键个体就可能使其崩溃。你有偏的[抽样方法](@entry_id:141232)创造了一个比现实更不平等、更脆弱的网络幻象 [@problem_id:4301047]。

### 校正的艺术：我们能修复一个有缺陷的样本吗？

如果非概率抽样充满了危险，它们是否就毫无用处？不一定。这就是统计学家的独创性发挥作用的地方，从而产生了“校正的艺术”。其核心思想是**加权**。如果我们能弄清楚我们的样本是*如何*产生偏差的，我们或许就能对其进行校正。

这在某些形式的概率抽样中是直接的。想象一个“同一个健康”研究，旨在调查人类、家畜和环境站点中的一种病毒 [@problem_id:2539149]。我们可能决定有意地对一个高风险群体进行过抽样，比如活禽市场中的鸡。这是一种称为**基于风险的**或不等比例[分层抽样](@entry_id:138654)的概率抽样形式。入选概率是不相等的，但它们仍然是*已知*的。为了得到一个无偏的[总体估计](@entry_id:200993)，我们只需在最终计算中对过抽样的鸡进行降权。每个观测值都按其被纳入概率的倒数进行加权。这个强大而优雅的工具被称为**[逆概率](@entry_id:196307)加权**估计量，或Horvitz–Thompson估计量 [@problem_id:4637105]。只要我们知道游戏规则，我们就能对它们进行解释。

但是对于非概率抽样，其规则——入选概率——是未知的，该怎么办呢？这是一个难得多的问题，它将我们推向了现代统计学的前沿。其中一个最强大的想法是使用一个高质量的概率样本作为基准。

想象你有两个数据集 [@problem_id:4938661]：
1. 一个大型、廉价的非概率样本（例如，来自一个移动应用），其中有关于人们的人口统计学信息（$X$）和你关心的生物标志物（$Y$）的数据。
2. 一个昂贵、高质量的概率样本（例如，一项全国性调查），其中有相同的人口统计学信息（$X$），但不幸的是，没有生物标志物 $Y$ 的数据。

诀窍是利用这两个数据集来建模一个具有特征 $X$ 的人自愿参加非概率样本的“倾向”。这被称为**倾向性得分**。一旦我们对非概率样本中的每个人都有一个估计的概率（倾向），我们就可以使用其倒数作为权重。实质上，我们重新加权有偏的样本，使其[人口统计学](@entry_id:143605)特征与我们黄金标准概率样本中的原始特征[完美匹配](@entry_id:273916)。

然而，这种统计炼金术依赖于几个重大的、无法检验的假设。最重要的是**可忽略性**，它假设我们已经测量了所有影响一个人是否在样本中以及其生物标志物 $Y$ 值的[混杂变量](@entry_id:199777) $X$。如果存在某个未测量的因素，比如“健康意识”，同时影响这两者，我们的校正就会失败。我们还必须假设**正值性**，即总体中每种类型的人至少都有一些机会被纳入我们的非概率样本。

这些方法表明，虽然我们有时可以调整非概率数据中的偏差，但我们是在用真实概率样本的基于设计的确定性来换取一种基于模型的希望。概率抽样的美妙之处在于，保证是内置在设计本身之中的。非概率抽样的挑战在于，任何关于代表性的主张都建立在统计假设的摇摇欲坠的基础之上。理解这种权衡，是在一个充满汤勺的世界里——有些是搅拌均匀的，有些是从顶层撇取的——成为一个明智的数据消费者的第一步，也是最重要的一步。

