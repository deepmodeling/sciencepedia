## 引言
在医学诊断中，某些事件很常见，而另一些则极为罕见。这个简单的现实，即[类别不平衡](@entry_id:636658)，是开发可靠人工智能所面临的最重大挑战之一。一个在疾病罕见的数据上训练的人工智能模型，仅通过学习将每个病例都分类为“健康”，就能达到近乎完美的准确率，但这使其在临床上毫无用处，并且具有危险的欺骗性。这种表面性能与实际效用之间的鸿沟，削弱了人工智能在医学领域的核心前景。

本文直面类别不平衡的挑战，为研究人员和从业者提供了一份指南。它不仅解释了使用*什么*技术，更解释了这些技术*为什么*有效，并将其植根于基本的统计学和机器学习概念。读者将对该问题及其解决方法获得深刻、直观的理解。我们将首先探讨核心的“原理与机制”，剖析传统指标为何失效，并详细介绍在数据层面和算法层面恢[复平衡](@entry_id:204586)的策略。随后，在“应用与跨学科联系”部分，我们将看到这个单一的统计问题如何产生涟漪效应，影响从模型架构、数据采集策略到人工智能伦理的方方面面。

## 原理与机制

想象一下，你是一名医生，正在筛查一种罕见但严重的疾病，每一千人中只有一人患病。市场上出现了一款新的人工智能诊断工具，号称准确率高达99.9%。你应该为此感到惊叹吗？让我们思考一下。如果这个人工智能只是学会了最懒惰的策略：它将每一位患者都判断为健康。在1000人中，它对999名健康者的判断是正确的，对那一名患病者的判断是错误的。其准确率为 $\frac{999}{1000}$，即99.9%！然而，它完全没有用；它永远也发现不了一个病例。

这个简单的思想实验鲜明地揭示了[医学影像](@entry_id:269649)中[类别不平衡](@entry_id:636658)的核心挑战：“多数类的暴政”。当一种疾病罕见时，模型可以通过只关注绝大多数的“健康”类别，在**准确率**等表面指标上取得优异表现，但同时在其最重要的任务——检测罕见的“疾病”类别上，却会灾难性地失败。为了构建真正有用的工具，我们必须超越这些幼稚的指标，建立一个更深刻、更直观的理解，关于如何在一个我们所寻找的目标如大海捞针般的世界里，评估、训练和验证模型。

### 概率之舞：两条曲线的故事

为了更清晰地看待这个问题，我们需要一种比简单准确率更好的语言。在机器学习中，我们经常使用**[混淆矩阵](@entry_id:635058)**来讨论模型的性能，它告诉我们四种可能的结果：

-   **真正例 (TP)**：患者患病，模型正确地做出判断。
-   **真负例 (TN)**：患者健康，模型正确地做出判断。
-   **假正例 (FP)**：患者健康，但模型错误地发出了警报。这是一个“假警报”。
-   **假负例 (FN)**：患者患病，但模型错过了。这是一个“漏检”。

基于这些，我们可以定义两个关键比率。首先是**真正例率 (TPR)**，也称为**召回率 (Recall)** 或灵敏度 (Sensitivity)。它回答了这个问题：“在所有实际患病的人中，我们找到了多大比例？”

$$ \mathrm{TPR} = \mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}} $$

其次是**假正例率 (FPR)**。它回答了：“在所有健康的人中，我们错误地标记为患病的比例是多少？”

$$ \mathrm{FPR} = \frac{\mathrm{FP}}{\mathrm{FP} + \mathrm{TN}} $$

一种流行的可视化分类器性能的方法是**[受试者工作特征](@entry_id:634523) (ROC) 曲线**，它在我们从非常严格到非常宽松地改变模型决策阈值时，绘制TPR与FPR的关系。一个理想的模型将位于左上角，TPR为1（找到所有患病患者），FPR为0（没有假警报）。[ROC曲线](@entry_id:182055)下面积（**[AUROC](@entry_id:636693)**）通常被用作一个单一数值来总结这一性能。ROC曲线的一个巨大优势是它不受疾病患病率的影响；因为它的两个轴都是在每个类别*内部*进行归一化的，所以无论疾病是罕见还是常见，曲线的形状都不会改变 [@problem_id:4542146]。它告诉我们模型*区分*两个类别的内在能力。

但这种对患病率的“免疫力”也是它最大的弱点。作为一名临床医生或患者，你有一个更紧迫的问题：“测试结果是阳性。我实际患病的概率是多少？”这个问题关乎**精确率 (Precision)**，也称为阳性预测值 (PPV)。

$$ \mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}} $$

请注意这里发生了什么。分母是阳性警报的总数，包括正确的和不正确的。与TPR和FPR不同，精确率不是在单个类别内归一化的。它混合了患病和健康的人群，因此，它对疾病的患病率极为敏感。

让我们看看这是如何发生的。利用植根于[贝叶斯定理](@entry_id:151040)的一些概率技巧，我们可以用ROC坐标（TPR, FPR）和疾病患病率（我们称之为 $\pi$）来表示精确率 [@problem_id:4871532]。一次阳性测试的概率是真正例警报和假正例警报的总和。一个真正例警报的概率是患病的概率（$\pi$）乘以测试能检测到它的概率（TPR）。一个假正例警报的概率是健康的概率（$1-\pi$）乘以发生假警报的概率（FPR）。那么，精确率就是真正例警报与所有警报的比率：

$$ \mathrm{Precision} = \frac{\pi \cdot \mathrm{TPR}}{\pi \cdot \mathrm{TPR} + (1-\pi) \cdot \mathrm{FPR}} $$

让我们代入一个真实场景的数字 [@problem_id:4542146]。假设我们有一个模型，其TPR为$0.90$（找到了90%的患病者），FPR为$0.10$（仅错误标记了10%的健康者），这两个指标都相当不错。再假设该疾病很罕见，患病率 $\pi = 0.01$。那么我们的精确率是多少？

$$ \mathrm{Precision} = \frac{0.01 \cdot 0.90}{0.01 \cdot 0.90 + (1-0.01) \cdot 0.10} = \frac{0.009}{0.009 + 0.099} = \frac{0.009}{0.108} \approx 0.083 $$

结果是惊人的。即使模型很好，也只有大约8.3%的阳性警报是正确的！每产生一个真正例，模型大约会产生十一个假正例 [@problem_id:4542146]。为什么？因为健康人群的基数是如此巨大（是患病人群的$99 \times$），即使一个很小的假正例*率*（$10\%$）也会产生绝对*数量*巨大的假警报，从而淹没了真正例。[ROC曲线](@entry_id:182055)因其对患病率不敏感的特性，掩盖了这个残酷的现实。

这就是为什么对于不平衡问题，我们转向**精确率-召回率（PR）曲线**。它绘制了精确率与召回率（TPR）的关系，直接展示了我们面临的痛苦权衡。它讲述了一个更诚实、更具临床相关性的故事。一个关键的洞见是，对于一个随机、无用的分类器，其AUPRC（PR曲线下面积）的基线就是类别患病率 $\pi$ [@problem_id:5223927]。因此，如果你的疾病患病率为1%，你必须构建一个AUPRC远高于0.01的模型，才能声称取得了任何成功。

### 变动的沙丘：[决策边界](@entry_id:146073)与不可约减的不确定性

为了从最根本的层面理解这个问题，我们必须问：模型究竟学到了什么？想象一下，我们使用单一的生物标志物 $X$ 进行诊断。健康患者的数据聚集在较低的值附近，而患病患者的数据聚集在较高的值附近，但它们的分布存在重叠。在这个重叠区域，即使对于一个完美的模型，诊断也存在固有的、不可约减的不确定性。这被称为**[偶然不确定性](@entry_id:154011) (aleatoric uncertainty)** [@problem_id:5174257]。

模型的工作是学习一个**[决策边界](@entry_id:146073)**，即一个 $X$ 的阈值，高于该阈值，模型就将患者判断为患病。如果两个类别完全平衡，且犯错的代价相等，那么最优边界应该恰好在重叠区的中间，那里患病或健康的概率是50/50。但当疾病罕见时会发生什么？模型必须更加保守。先验信念是任何给定的人都是健康的。为了克服这个先验信念，模型需要来自生物标志物 $X$ 的非常强的证据。这意味着[决策边界](@entry_id:146073)必须从重叠区的中间移开，更深地进入患病类别的领域 [@problem_id:5174257]。

这种边界的移动带来了深远的影响。高不确定性区域现在位于患病患者密度更高的地方。这意味着，更大部分的实际患病患者的生物标志物值将落在这个混淆区域附近。他们的诊断本身就更不确定。不平衡的本质放大了我们最关心的那个类别的不确定性。这不是模型的缺陷，而是问题本身一个无法逃避的特征。

### 恢[复平衡](@entry_id:204586)：从数据到算法

理解问题是成功的一半，另一半则是反击。广义上讲，应对类别不平衡的策略可分为两大类：修改数据（数据层面）或修改学习算法（算法层面）。

#### 在数据层面：采样的艺术

如果问题在于数据集不平衡，一个直接的解决方案就是使其平衡。我们可以**[欠采样](@entry_id:272871)**多数类（通过丢弃健康患者的数据），或者**过采样**少数类（通过复制患病患者的数据）。这些方法虽然简单，但各有缺点：[欠采样](@entry_id:272871)可能会丢弃有价值的信息，而过采样可能导致模型对少数重复的样本产生过拟合。

一个更巧妙的想法是确保学习过程稳定，并且总能看到有代表性的样本。在使用bagging等方法时，模型会在数据的多个[自助重采样](@entry_id:139823)样本上进行训练，而标准的自助采样可能偶然创建一个只有很少甚至没有少数类样本的[重采样](@entry_id:142583)集。这使得训练过程不稳定。**分层自助采样**通过从每个类别中单独抽样来解决这个问题，确保每一个自助采样副本都保留了原始的类别比例 [@problem_id:4559774]。通过消除每批次中少数类样本数量的随机性，我们降低了训练过程的方差，从而得到更稳定、更可靠的模型。这是[全方差定律](@entry_id:184705)的一个绝佳应用：通过减少一个内部的随机性来源，我们降低了结果的整体随机性。

#### 在算法层面：教会模型“关心”什么

除了改变数据，我们还可以改变模型所关心的内容。这通过**[损失函数](@entry_id:136784)**来实现，它量化了模型在训练中犯错的惩罚。

-   **加权交叉熵：** 标准的**[二元交叉熵](@entry_id:636868)**损失对每个错误都一视同仁。这就是为什么它会被成千上万个易于分类的健康患者所“淹没”。最简单的解决方法是为在少数类上犯的错误分配更高的权重。这就像告诉模型：“漏掉一个患病患者比一个假警报糟糕十倍，所以请把你的注意力集中在那里！”[@problem_id:4534203]。

-   **基于区域的损失（例如，Dice损失）：** 在[图像分割](@entry_id:263141)任务中（例如勾勒病灶轮廓），不平衡可能非常极端（一个小肿瘤可能只占图像体素的不到0.1%）。我们可以不按体素逐个累加错误，而是使用一个衡量预测区域和真实病灶区域几何重叠度的[损失函数](@entry_id:136784)，比如**Dice相似系数**。**Dice损失** ($1 - \text{Dice}$) 天生会忽略大量被正确识别的背景体素，而只关注前景预测的质量，使其自然地对不平衡问题具有稳健性 [@problem_id:4534203]。

-   **Focal损失：** 一种更聪明的方法是**Focal损失**。它在训练过程中动态地降低易于分类、分类正确的样本的贡献权重。想象一位老师，他会减少对已经掌握概念的学生的关注，而集中精力帮助那些仍在挣扎的学生。Focal损失对模型做同样的事情，迫使其将精力集中在难以分类的样本上，而这些样本通常包括罕见的少数类 [@problem_id:4534203]。

-   **Tversky损失：** 为了实现终极控制，**Tversky损失**作为Dice损失的一种泛化，允许你分别调整对假正例和假负例的惩罚 [@problem_id:4535917]。当这两种错误的临床代价不同时，这种方法非常强大——例如，当漏诊一个癌症病例（FN）比因假警报（FP）而进行活检的后果要灾难性得多的时候。

### 科学家的护栏：严格验证与隐藏的危险

最后，构建一个好的模型还不够；我们必须证明它有效，并且不能自欺欺人。

首先，必须明智地选择评估指标。正如我们所见，准确率具有误导性。为了获得全面的视角，应该报告一套指标：像**[AUROC](@entry_id:636693)**和**AUPRC**这样的无阈值指标，用以评估模型的整体判别能力；以及像**[平衡准确率](@entry_id:634900)**或**[马修斯相关系数](@entry_id:176799)（MCC）**这样的依赖阈值的指标，用以描述在特定、具有临床意义的操作点上的性能 [@problem_id:5174257] [@problem_id:4918262]。对于输出概率的模型，应使用**校准**诊断和**合适的评分规则**来检查其可靠性 [@problem_id:4918262]。

其次，验证过程本身必须稳健。当数据具有分组结构时（例如，来自同一患者的多张图像），我们必须防止**数据泄露**，方法是确保来自同一患者的所有数据都落在[交叉验证](@entry_id:164650)的同一折中（**分组k折[交叉验证](@entry_id:164650) (Group k-Fold CV)**）。为了确保我们的罕见病例在每一折中都有代表，我们必须使用**分层 (stratification)**。黄金标准通常是**嵌套、分层、分组k折[交叉验证](@entry_id:164650) (Nested, Stratified, Group k-Fold Cross-Validation)** 方案，它能在恰当调整模型超参数的同时，为模型在未见患者上的性能提供一个无偏的估计 [@problem_id:4543124]。

最后，我们必须警惕隐藏的相互作用。想象一个多中心研究，其中一个医院碰巧主要治疗患病患者，而另一个医院主要治疗健康患者。如果我们试图应用一种标准的“协调”技术（如ComBat）来消除扫描仪特定的效应，算法可能会感到困惑。它可能会错误地将生物学上的“疾病”信号解释为技术上的“医院”信号，并将其“校正”掉，从而有效地抹去了我们想要检测的模式 [@problem_id:4543160]。解决方案是**分层协调 (stratified harmonization)**——在每个类别内部分别执行校正。这有力地提醒我们，类别不平衡不是一个孤立的问题；它是我们数据的一个基本属性，可以与分析流程的每个阶段相互作用并破坏它。对其原理的深刻和直观的理解不仅仅是一项学术练习，它更是任何致力于构建可靠、能拯救生命的医疗工具的科学家的重要护栏。

