## 引言
想象一下，在一个雨夜，你的车在距离碰撞仅几英寸的地方停了下来。你心跳加速，但安然无恙。虽然我们的本能是迅速忘记这样的时刻，但这些“侥幸脱险”正是安全科学家所称的**近失**。它们是免费的教训——无需付出任何代价便得到的严厉警告，掌握着预防未来灾难的关键。在像医疗保健这样的高风险环境中，理解并从这些事件中学习不仅是有益的，更是一项基本责任。然而，组织常常陷入只关注灾难性失败的陷阱，从而忽略了能够使其系统更具韧性的海量数据。

本文深入探讨这些事件的深远重要性。在第一章**“原则与机制”**中，我们将为安全事件建立清晰的词汇体系，探索解释失败如何发生的理论，并揭示为何近失是预防未来伤害的信息金矿。随后的**“应用与跨学科联系”**将展示这一强大概念如何在从医院床边到人工智能开发的各个领域付诸实践，阐明其在驾驭复杂性和风险方面的普遍重要性。

## 原则与机制

想象你正在一个雨夜开车。突然，前方的汽车猛踩刹车。你睁大眼睛，脚踩刹车踏板，轮胎发出刺耳的尖叫声，最终在距离对方汽车保险杠仅一英寸的地方停下。你心跳加速，但安然无恙。坏事没有发生。但真的*什么*都没发生吗？当然不是。一系列事件已经启动，本可能以撞车告终。但在最后一刻，你快速的反应——一次成功的防御——中断了它。这个令人心跳加速的“差一点”时刻，就是安全科学家所说的**近失**。这是一堂免费的课，一个严厉的警告，却无需付出扭曲的金属和伤害的代价。

在利害关系无限高的复杂医疗世界里，这些“免费的教训”不仅有趣，它们是一个能够学习、适应并变得更安全的系统的基石。要理解其深远的重要性，我们必须首先学会像安全科学家一样看世界，仔细区分所发生的各种事件。

### 问题的分类：绘制错误图景

当医院里出问题时，它很少是一个单一、简单的事件。它是一连串的事件，一个正在展开的故事。为了理解它，我们需要一个清晰的词汇体系。让我们思考几个每天在世界各地医院发生的场景。

首先，想象一个药品供应室。它杂乱无章，外观和名称相似的药物被并排存放在拥挤、标签不清的货架上 [@problem_id:4377474]。这个凌乱的房间本身并不是一个错误。还没有人做错任何事。它是一种**[不安全状态](@entry_id:756344)**——一个等待发生的潜伏性危害，就像冬日路面上的一片黑冰。

现在，一位护士在压力之下去那个房间，拿错了药瓶。这个动作——选择了不正确的药物——是一个**错误**。它偏离了预期的治疗计划。错误已经发生，但它的故事还没结束。

当护士准备给药时，她用条形码扫描仪扫描了病人的腕带和药瓶。警报响起——不匹配！系统捕捉到了这个错误。护士停下来，拿来了正确的药物，病人从未接触到错误的药物。这整个序列，即一个错误发生但在造成伤害前被拦截，就是一个**近失** ([@problem_id:4384208])。

但如果没有条形码扫描仪呢？如果错误未被发现，错误的药物被给予，病人出现了严重的过敏反应，需要紧急干预呢？这个结果，即错误到达病人并造成伤害，就是一个**不良事件** [@problem_id:4377474]。

我们可以让这些区分更加清晰。假设当一个事件*到达*病人时 $R=1$，如果被拦截则 $R=0$。假设病人*受到伤害*时 $H=1$，没有伤害则 $H=0$ [@problem_id:4882048]。

*   **[不安全状态](@entry_id:756344)**是风险的设置，在任何特定事件序列开始之前。
*   **近失**是一个错误被拦截的序列。事件没有到达病人 ($R=0$)，因此没有伤害发生 ($H=0$)。在术前“暂停”期间发现的错位手术是一个典型且令人不寒而栗的高风险近失例子 [@problem_id:4672069]。
*   **无伤害事件**是一个微妙但重要的类别，其中错误*确实*到达了病人 ($R=1$)，但幸运的是，没有造成伤害 ($H=0$)。例如，一个病人接受了一剂他们不过敏的抗生素，但那不是针对他们感染的正确抗生素。这与近失不同，因为系统的防御失败了。
*   **不良事件**是我们都害怕的结果：一个错误到达病人 ($R=1$) 并造成伤害 ($H=1$)。

最具破坏性的不良事件的一个子集——那些导致死亡或严重、永久性伤害的事件——被称为**哨兵事件**。这些事件，比如手术海绵的意外滞留，是如此严重，以至于会触发强制性的、深入的调查 [@problem_id:4672069] [@problem_id:4488771]。

这种分类不仅仅是学术上的吹毛求疵。它是学习的根本基础，因为它让我们看到近失和不良事件并非不同种类的现象。事实上，它们是兄弟，诞生于同一风险家族。

### 失效轨迹：瑞士奶酪与潜伏性危险

为什么会发生错误？一个常见且有严重缺陷的本能是归咎于犯下最后错误的人——拿错药瓶的护士，点错按钮的医生。这就是“坏苹果”理论。但安全科学向我们表明，这种观点几乎总是错误的。

心理学家James Reason提出了一个更强大的模型来理解失败。他将系统的防御想象成一系列叠在一起的瑞士奶酪片。每一片——一项政策、一项技术、一个培训项目、一个人检查另一个人的工作——都是一道旨在阻止危害的屏障。但每道屏障都有弱点，即“洞”。这些洞不是静止的；它们在不断地打开、关闭和移动。一个危害，就像一条失效轨迹，只有在能够穿过所有奶酪片上一组对齐的洞时，才能导致不良事件 [@problem_id:4384208]。

关键的洞见在于两种洞的区别。由一线人员——医疗的“尖峰端”——犯下的错误是**主动失效**。它们就像轨迹最后、可见的部分。但这些主动失效几乎总是由**潜伏性条件**塑造和引发的：这些是系统中由远离床边的设计师、管理者和领导者造成的隐藏弱点。令人困惑的药品包装、有缺陷的用户界面、长期的人员短缺、频繁触发以至于人们开始忽略的警报（“警报疲劳”）——这些就是奶酪片上的洞。它们是潜伏的病原体，是等待发生的事故 [@problem_id:4384208]。

在这个模型中，近失仅仅是失效轨迹被最后一片奶酪挡住的情况。最初的危害存在，潜伏性条件排列使其通过了几层，但最后一道防御坚守住了。这意味着一个近失和一个不良事件共享*完全相同的根本原因*——同一组潜伏性条件。唯一的区别是结果，而结果往往只取决于运气。

### 看不见的金矿：为何“什么都没发生”才是一切

这把我们带到了所有安全科学中最优美和最反直觉的思想。如果近失和不良事件有相同的原因，我们应该研究哪一个来学习如何使我们的系统更安全？显而易见的答案似乎是不良事件——那些撞车、那些悲剧。它们引人注目，吸引我们的注意力，并要求我们做出回应。但这是一个陷阱，一个由**结果偏见**——我们倾向于根据最终结果来判断一个过程质量的好坏——所造成的认知错觉。

事实是，近失是学习的更强大、更可靠的来源。这有两个深层的原因。

首先是简单的数量力量。在任何复杂系统中，近失的频率远高于不良事件。想象一个外科部门进行了$10,000$次手术。仔细的分析可能会显示，有$490$次近失——即被发现的错误——但只有$10$次导致病人伤害的不良事件 [@problem_id:4676830]。如果我们只调查这$10$个悲剧，我们就扔掉了$98\%$的数据！这$490$次近失是$490$个免费的教训，$490$个机会去发现我们系统中的潜伏性条件，而无需病人付出代价。只关注罕见的灾难，就像试图只研究致命车祸来理解交通安全，而忽略每天发生的成千上万的轻微碰撞和侥幸脱险。

第二个原因更为微妙，它触及了无偏见学习的核心。从系统失效到实际病人伤害的最后一步，往往包含一个偶然因素——病人的特定生理状况、他们的恢复能力、他们的脆弱性。考虑两个相同的医院单元，使用完全相同的有缺陷的药物订购系统 [@problem_id:4395197]。该系统有一个潜伏缺陷，导致$1\%$的时间会订购错误的剂量。现在，假设X单元是一个癌症病房，病人非常脆弱，而Y单元是一个普通病房，病人更健壮。因为X单元的病人更脆弱，同样的用药错误更有可能对他们造成伤害。

如果我们只计算不良事件，我们可能会看到X单元有$9$个不良事件，而Y单元只有$2$个。我们可能会得出结论，X单元的过程安全性差得多。但我们错了。底层的系统——错误的来源——是相同的。结果的差异是由于病人的脆弱性，这是一个与过程安全性无关的因素。现在，如果我们计算近失呢？有缺陷的系统产生错误随后被发现的次数在两个单元中将是相同的——比如说，每个单元$82$次近失。近失率给了我们一个关于*系统*健康状况的纯粹、稳定且无偏见的信号，剥离了最终结果的随机噪音 [@problem_id:4395197]。它让我们在防御崩溃之前看到裂缝。

### 发现的人类引擎：从恐惧到心理安全

如果近失是信息的金矿，那么核心挑战就变成了挖掘。我们如何将这些事件从阴影中带到阳光下，以便进行分析？答案不是一项技术或政策，而是一种文化。

想象你是一名临床医生，刚刚发现了自己的一个错误——一次近失。你面临一个选择：报告它还是保持沉默。这个计算中包含哪些因素？有为学习做出贡献的好处，但也有成本：填写报告的时间和精力，以及最强大的，对指责、羞辱或惩罚的恐惧 [@problem_id:5198124]。

在传统的惩罚性文化中——有时被称为“合规文化”——被指责的感知成本可能非常高。理性的选择，特别是如果近失很严重且更可能被视为严重失误时，是隐藏它。这造成了一个毁灭性的悖论：指责文化系统性地过滤掉了最有价值的数据。系统对其最大的风险变得盲目，因为一线人员太害怕而不敢说出来。

解毒剂是**心理安全**。这是团队内部的一种共同信念，即承担人际风险是安全的——可以直言不讳、提出问题、承认错误、报告近失，而不用担心被羞辱或报复。培养这种环境是**公正文化**的目标。公正文化不是“无指责”文化。它认识到，虽然大多数错误是系统引起的，但某些行为代表了对安全的有意识漠视（鲁莽行为），必须区别对待。它为无可指责的人为错误、需要指导的高风险行为以及可能需要制裁的鲁莽行为之间提供了清晰、公平和预先商定的界限 [@problem_id:4852050]。

通过创造心理安全，公正文化改变了报告的计算方式。它降低了被指责的感知成本，使得临床医生报告所有近失，特别是严重的近失，变得理性和容易。只有创造出这种发现的人类引擎，组织才可能利用近失的丰富[数据流](@entry_id:748201)，真正开始学习。

### 最后的闭环：透明、信任与学习的责任

一次近失的旅程并不止于一份内部报告。它把我们带到一个最后的、非常个人化的问题：我们应该告诉病人吗？错误发生了，但被发现了。病人没有受到伤害。告诉他们可能只会引起不必要的焦虑。保持沉默不是更仁慈吗？

这个问题迫使我们权衡我们的道德责任。**不伤害原则**（do no harm）建议我们应该避免引起焦虑。但**尊重自主权原则**（respect for autonomy）认为，一个有能力的病人有权知道发生在他们身上的事，包括关于他们安全风险的信息。隐藏近失，即使是出于好意，也是一种家长式作风，会破坏信任。

此外，**行善原则**（beneficence）和**公正原则**（justice）都指向透明。正如我们所见，从近失中学习是保护未来病人的方法。一种保密的文化，即使是围绕“无害”事件，也会腐蚀我们试图建立的开放、学习文化的根基。事实上，有证据表明，坦诚披露的行为本身可以成为系统变革的强大催化剂，导致未来风险的可衡量减少 [@problem_id:4889868]。

因此，伦理和实践上的前进道路是完全透明。向病人披露近失——解释发生了什么，它是如何被发现的，以及正在采取什么措施来防止它再次发生——不是承认失败。它是展示对学习的承诺。它关闭了最后的闭环，将一个潜在的伤害时刻转变为建立信任的行为，不仅强化了照顾病床上病人的责任，也强化了为所有未来的病人不断、不懈地改善系统安全的责任。近失那令人心跳加速的时刻，变成了一个更安全系统平稳的心跳。

