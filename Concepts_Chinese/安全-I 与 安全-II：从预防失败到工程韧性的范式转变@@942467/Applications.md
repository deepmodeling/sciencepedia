## 应用与跨学科联系

从一种思维方式转变为另一种，是一次深刻的转变。从关注预防失败的安全-I 世界，到探索理解成功的安全-II 世界，这一转变远不止是学术上的重新包装。这是一场悄然的革命，正在以切实的方式重塑我们的世界。它改变了我们管理最关键机构的方式，改变了我们在危机时刻彼此交谈的方式，也改变了我们设计智能机器的方式——这些机器正成为我们工作和生活中的伙伴。这是一段从失败的历史学家到韧性建筑师的旅程。让我们踏上这片新领域的探索之旅，看看我们讨论过的原则是如何在实践中应用的。

### 人为因素：重写工作的故事

或许，安全-II 理念最直接、最深刻的应用，在于我们如何理解和沟通人类的工作，尤其是在出现差错时。想象一下医院里的一次侥幸事件：一种强效药物差点给错了病人，但护士的最后核对发现了错误。虽然没有造成伤害，但风险是真实存在的。现在，团队必须向病人及其家属披露这一事件。

传统的安全-I 方法会将此事件界定为一次失败。核心问题将是：“哪里出错了？谁该负责？”随后的调查会寻找“根本原因”，并常常以个人失误作为结论。对病人的信息披露，如果能透明地进行，将会是对错误的道歉，然后承诺进行再培训或制定更严格的程序——这是一个关于失败和纠正的故事。

安全-II 的视角则讲述了一个完全不同且丰富得多的故事 [@problem_id:4855586]。它承认最初的错误确实发生了，但立刻提出了一个更具力量的问题：“是什么做对了，从而避免了一场灾难？”焦点从那一件出错的事情，转移到许多做对了的事情上。故事不再是关于一次单一的失败，而是关于吸收了这次失败的系统的韧性。披露对话也因此转变。它变成了一场关于医疗保健实际如何运作的讨论——它不是一台完美无瑕的机器（“想象中的工作”，即 $W_I$），而是一项动态的人类活动，技术娴熟的人们在其中不断适应变化的条件（“实际完成的工作”，即 $W_D$）。

在这场新的对话中，团队可以解释，理想化计划与混乱现实之间的差距 $\Delta W = W_D - W_I$ 正是风险与韧性共存之处。护士的最后核对不仅仅是遵守规则，更是一种韧性的表现，一次成功的适应，它保障了系统的安全。对病人的承诺不再只是惩罚错误，而是要加强韧性的来源——让人们更容易进行那些至关重要的核对，改善沟通，建立一个让成功不仅可能、而且很可能发生的系统。这是从指责文化向学习与信任的“公正文化”的转变，也是寻找并珍视成功的直接结果。

### 管理者的视角：改变安全的衡量标准

如果我们要珍视成功，我们必须首先学会看到它。而要看到它，我们必须衡量它。这就把我们带到了下一个重要的应用领域：质量与安全领域的衡量科学。

安全-I 的世界痴迷于计算失败次数。它追踪感染率、事故数量和不良事件。任何统计学家都会告诉你，问题在于，当一个系统已经相当安全时，失败就变得罕见。试图通过观察一个几乎总是为零的数字来检测改进，就像盯着冰川五分钟想判断它是否在移动一样。数据实在太稀疏，无法成为行动的灵敏指南 [@problem_id:5198070]。一家医院的镇静服务可能在一千次操作中只有少数几例严重并发症。月度并发症率图表将主要显示为零，偶尔才会出现一个“1”的突增。这告诉你坏事有时会发生，但它并不能告诉你你的安全努力是否真的有效。

安全-II 提供了解决方案：如果失败太罕见以至于难以观察，那就别再盯着它们，开始衡量无处不在的成功。我们不应只追踪伤害这类滞后指标，而应衡量韧性的领先指标。对于我们的儿科镇静服务来说，这意味着我们要提出新的问题 [@problem_id:5198070]。我们执行术前安全简报的可靠性如何？在多大比例的病例中，高级呼吸监护仪是在给予第一剂药物*之前*就启动的？当警报响起时，团队响应的速度有多快？我们的团队在模拟应急演练中表现如何？

这些是衡量能力和可靠性的指标。它们为每一位病人生成数据，而不仅仅是千分之一出问题的病人。它们让组织能够实时了解其安全基础是否坚固。通过对比两种范式的基本分析单位，可以精美地捕捉到这种衡量方式的转变 [@problem_id:4852056]。安全-I 计算失败率：

$$ \text{Safety-I Metric} = \frac{\text{Number of Adverse Events}}{\text{Total Exposure}} $$

相比之下，安全-II 寻找扰动——即系统受到挑战的时刻——并衡量系统成功适应的频率：

$$ \text{Safety-II Metric} = \frac{\text{Number of Successful Adaptations}}{\text{Total Number of Disturbances}} $$

我们只是选择关注一个不同的分子。通过将我们的视线从罕见的失败事件转移到常见的成功适应事件上，我们获得了一个强大的新视角，用以审视和改进我们的系统。

### 工程师的蓝图：将韧性铸入代码

这场革命并不仅限于人员和流程。安全-II 理念最具前瞻性的应用体现在我们技术的设计中，尤其是在医学等领域部署的复杂人工智能 (AI) 系统。我们如何构建不仅能避免错误，而且能主动创造成功的系统？

#### 成功的知识库

首先，我们可以构建能明确从成功中学习的系统。在任何复杂环境中，从医院病房到飞机驾驶舱，专家从业者都在不断地即兴发挥。他们开发出巧妙的变通方法和新颖的策略来处理意外问题。安全-I 的思维模式可能将这些偏离规程的行为视为应被根除的违规行为。而安全-II 的思维模式则将它们视为自适应智慧的宝贵宝库。挑战在于如何捕捉这种智慧并安全地分享它。

这就是医学信息学和数据科学发挥作用的地方 [@problem_id:4852084]。我们可以设计“学习系统”，这些系统不仅记录错误，还仔细记录成功的适应行为。对于每一次成功，系统不仅会记录个人做了*什么*，还会记录他们所处的*情境*——病人的状况、技术的特性、人员配置水平。通过收集大量此类事件，我们可以使用[贝叶斯更新](@entry_id:179010)等统计方法来估计特定适应行为在特定情境下成功的概率。这就创建了一个活的“韧性知识库”，一个知识库，让面临新问题的临床医生能够看到其他人是如何成功应对类似挑战的，并附带对该策略再次奏效可能性的诚实评估。

#### 韧性机器

其次，我们可以改变对“好”AI的定义。传统上，AI模型是在一个干净、静态的数据集上训练以求准确。这就像一个新手司机只在完美、干燥的赛道上练习过。他们的性能是针对单一的、标称的条件进行优化的。安全-I 的AI安全方法侧重于在这些标称条件下最小化失败概率 $P(F)$ [@problem_id:5202941]。

但现实世界不是一个无尘室；它是一个充满“扰动”($\delta$)的混乱、不可预测的地方。数据是嘈杂的，病人的状况可能突然改变，医院的实验室系统可能宕机。一个只为标称条件（$\delta=0$）优化的脆弱AI，在面对最轻微的现实世界意外时，也可能灾难性地失败。

韧性工程，作为安全-II的实践分支，重新定义了目标。我们不想要一个新手AI；我们想要一个能处理雨天、油污路面和意外绕路的大师级司机。目标是内置“[适应能力](@entry_id:194789)”，以便系统在一系列广泛的合理扰动（$\delta \in \Delta$）中保持成功。新的目标不仅仅是让 $P(F \mid \delta=0)$ 变低，而是要确保成功的概率 $P(S \mid \delta)$ 无论世界给它带来什么都能保持高水平。一个正式表达此目标的方式是，要求在*最坏的合理情境*下，成功的概率仍然高于一个可接受的阈值：

$$ \inf_{\delta \in \Delta} P(S \mid \delta) \ge \tau $$

这迫使我们设计的系统能够监控其环境，识别自己何时“偏离轨道”，能够优雅地降级而不是突然崩溃，并能与人类伙伴无缝协作以应对不确定性。

#### 自我改进的系统

这引出了最终的应用：构建能够从自身在现实世界中展示的成功中安全地学习和改进的AI系统。想象一个部署在急诊室的AI脓毒症警报系统 [@problem_id:5203073]。起初，它在严格的“护栏”下运行——它提出的每一个建议都必须由人类医生确认。它没有自主权。

然而，该系统也是一台学习机器。它看到的每一个案例都是一个学习的机会。它不断观察情境 ($X$) 和最终结果——这是否是一次团队和AI共同努力取得良好结果（$Y=1$）的成功案例？通过使用一个复杂的贝叶斯监控框架，系统可以开始构建一幅关于自身能力的详细地图。例如，它学会了在具有典型症状和完整实验数据的情况下，其建议的成功率为99.9%，并且它能对这一事实变得高度确定。在其他更模糊的情况下，它则保持不确定。

一个自适应的护栏策略可以利用这种自我认知。在AI已经严格证明具有非常高成功概率的情境中（例如，其成功的后验[可信区间](@entry_id:176433)的下限高于一个严格的安全阈值），系统可以被授予更多的自主权。也许它可以自行下达诊断指令。在模糊的情境中，护栏则保持紧绷。这就创造了一个真正的学习型健康系统，一个与其环境共同演进，通过展示成功而非仅仅避免有记录的失败来赢得信任和责任的系统。

从医患对话的亲密无间到自适应AI的复杂逻辑，从安全-I 到安全-II 的转变是一个统一的原则。它是一种更有希望、更动态、更现实地与我们世界的复杂性互动的方式。它提醒我们，安全不是威胁的缺席，而是成功能力的在场。