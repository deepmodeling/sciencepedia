## 引言
在我们日益复杂的世界中，我们如何确保医院、发电厂和交通网络等关键系统的安全？几十年来，被称为“安全-I”的主流方法一直将安全视为没有事故。这种理念指导我们寻找故障，识别其根本原因，并设置障碍以防再次发生。然而，当面对现代复杂适应性系统中混乱、不可预测的现实时，这个模型开始动摇，在这些系统中，“想象中的工作”很少与“实际完成的工作”相符。这一差距凸显了纯粹关注失败的思维方式的局限性，并为一种新的思维方式打开了大门。

本文探讨了从安全-I 到安全-II 的范式转变，这是一种革命性的观点，它将安全重新定义为保证事情顺利进行的能力。我们将从一个执着于预防负面结果的世界，走向一个专注于理解和增强正面结果的世界。在第一章 **“原则与机制”** 中，我们将剖析这两种方法的核心理念，对比它们在人为错误、系统行为和分析方法上的观点。随后，**“应用与跨学科联系”** 章节将揭示安全-II 不仅仅是一种理论，更是一种实践力量，它正在改变我们管理团队、衡量成功以及在从医疗保健到人工智能等领域设计韧性技术的方式。

## 原则与机制

想象一下，你是一名工程师，任务是确保一个复杂系统——比如一座化工厂或一家医院——的安全。你会做的第一件事是什么？你那经过一生修理东西磨练出的直觉，很可能会告诉你去寻找坏掉的部分。你会查找过去的事故，追寻其原因，并设置障碍以确保它们不再发生。如果一个阀门失灵，你会换一个更好的。如果一名操作员犯了错，你会制定更严格的规定或增加一个警示灯。

这种非常自然的方法，是我们现在称之为 **安全-I** 的安全理念的核心。其逻辑简单而有力：安全就是**没有负面结果**。安全就是没有事故。因此，我们的工作是找到失败的原因并消除它们。这种世界观假设系统在某个部件——无论是硬件还是人——失效之前，基本上是安全的。事故被看作是一系列线性事件链的终点，而我们首选的分析工具就类似于逆向追踪这条链，以找到引发一切的单一“根本原因”，这种方法就是著名的**根本原因分析 (RCA)** [@problem_id:4375933]。

### 错误的剖析

在这种世界观中，“人为因素”通常被视为一种负累，一个不可靠的来源。为了管理这一点，安全-I 精细地对人为错误进行分类。让我们以我们化工厂的一位控制室操作员为例 [@problem_id:4226375]。

*   如果操作员打算按“ACK”按钮确认警报，却不小心碰到了旁边外观相似的“RST”按钮，这是一种**滑动 (slip)**。意图是正确的，但执行出了错。
*   如果操作员在执行一个五步程序时被打断，回来后忘记了第三步，直接从第四步开始，这是一种**失误 (lapse)**。这是记忆的失败。
*   如果操作员相信了一个计算机模型的错误建议，故意采取了不适合当前情况的行动，这是一种**错误 (mistake)**。计划本身从一开始就是错的，即使执行得完美无缺。

从安全-I 的角度来看，每种错误类型都需要不同的修正方法：重新设计按钮以防止滑动，添加核对清单以防止失误，改进培训或决策辅助工具以防止错误。总体目标是最小化绩效可变性，并降低失败的概率，我们可以将其表示为 $\mathbb{P}(F)$。我们通过统计越来越少的不良事件来衡量我们的成功 [@problem_id:4401948]。

### 当模型失效：现实的混乱

在很长一段时间里，这是无可争议的安全范式。它逻辑清晰、井然有序，并且对于简单的机械系统非常有效。但是，当我们将它应用于真正复杂的系统——如急诊室、空中交通管制中心或现代金融市场——时，我们开始看到其基础上的裂痕。

这些环境并非整洁的线性链条。它们是科学家所称的**复杂适应性系统 (CAS)** [@problem_id:4377446]。其特点是巨大的不确定性、持续的变化和相互冲突的目标。在繁忙的医院病房里，程序和规程永远无法覆盖所有意外情况。程序手册中“想象中的工作”与床边混乱、动态的“实际完成的工作”相比，只是一个苍白的影子。

革命性的洞见在于：要在这些环境中完成工作，人们*必须*偏离计划。他们必须适应、即兴发挥、走捷径和做出权衡。这种在安全-I 中被视为错误来源的**绩效可变性**，实际上正是绝大多数时候事情能顺利进行的原因。找到巧妙方法绕过设计拙劣流程的护士，不是风险的来源，而是韧性的来源。根据对天气的直觉调整进近方式的飞行员，并非偏离计划，而是在主动创造安全。

这带来了一种深刻的视角逆转。如果我们只调查失败，我们研究的是最罕见的事件。那么，如果我们研究成功呢？我们会发现，在罕见的失败案例中存在的人类适应行为，与在绝大多数成功结果中存在的适应行为是完全相同的。人不是需要被约束的问题，而是需要被赋能的解决方案。

### 一种新理念：安全-II 的世界

这就是 **安全-II** 的曙光。安全-II 将安全重新定义为*不是负面因素的缺席*，而是**正面因素的存在**。安全是系统在不同条件下取得成功的能力。它是在不可避免的复杂性和意外情况面前，让事情一次又一次顺利进行的能力。

目标从预防失败转向理解和增强**韧性**。韧性不仅仅是在事故后恢复原状。它是一种建立在四大支柱上的动态能力：**预期**未来挑战的能力、**监测**细微变化的能力、**响应**突发事件的能力，以及从所有经验——无论是成功还是失败——中**学习**的能力 [@problem_id:4401948] [@problem_id:4391555]。

这种新理念需要新工具。安全-II 的实践者可能不会使用线性的 RCA，而是采用类似**功能共振分析方法 (FRAM)** 的工具。F[RAM](@entry_id:173159) 不会去寻找单一的损坏部件，而是描绘系统中不同功能的正常、日常绩效可变性如何以意想不到的方式耦合和相互作用。有时，这些相互作用会抑制可变性，使事情顺利进行。但偶尔，它们会相互放大，产生一种“共振”，导致令人意外的结果——要么是巨大的成功，要么是灾难性的失败 [@problem_id:4375933]。这个模型的美妙之处在于其对称性：成功和失败源于完全相同的原因。

### 构建韧性系统

我们如何将安全-II付诸实践？这需要我们在衡量、学习和领导方式上进行根本性的转变。

#### 衡量重要之事

首先，我们改变我们的衡量指标。我们不再仅仅统计不良事件（一种安全-I 的指标），而是开始衡量适应能力。例如，在医院里，我们可以衡量“需求激增（如病人突然大量涌入）后功能恢复的中位时间”，或者我们可以追踪“在需求激增期间维持的目标吞吐量比例” [@problem_id:4401948]。这些指标告诉我们的不是失败的缺席，而是韧性的存在。

这种区别可以用优美的数学形式来捕捉 [@problem_id:4375931]。安全-I 的目标是找到一个策略 $\pi$，以最小化系统进入不良状态 $A$ 的概率：$\min_{\pi} \mathbb{P}(s \in A)$。而安全-II 的目标是找到一个策略，即使在最坏的条件下也能最大化系统的性能 $r(s)$。它寻求在所有情境下最大化*保证的最低*性能：$\max_{\pi} \inf_{x} \mathbb{E}[r(s)]$。这就像是避开特定的坑洼和制造一辆能应对任何地形的车辆之间的区别。

#### 从万事万物中学习

其次，我们扩展了对学习机会的定义。造成伤害的事故是一场悲剧，但它是一个糟糕的数据来源，因为它太罕见了。一个更丰富的信息来源是**侥幸事件 (near miss)**——即发生错误但在造成伤害前被发现的事件 [@problem_id:4377474]。

想象一下，一名护士正要给病人用错药，但条形码扫描系统标记了不匹配。没有造成伤害。从安全-I 的角度来看，人们可能只会说“系统起作用了”。而从安全-II 的角度来看，这次侥幸事件是一次黄金机会，一堂“免费的课”。它揭示了用药流程中的一个弱点，这个弱点在另一天可能导致真正的悲剧。侥幸事件是系统发出的关于其隐藏脆弱性的信号，比如那个杂乱、未标记的药房，它本身就容易导致混淆——这是一个典型的**[不安全状态](@entry_id:756344)**或潜在危害 [@problem_id:4377474]。通过系统地报告和分析侥幸事件，我们可以主动地增强系统的韧性。

#### 公正文化的基础

最后，也是最重要的一点，如果没有心理安全的基础，这一切都不可能实现。如果报告一个错误——甚至是一次侥幸事件——会导致指责和惩罚，人们就会选择隐瞒。这就是为什么安全-II 的原则与**公正文化 (Just Culture)** 的理念密不可分 [@problem_id:4378708]。

公正文化不是“无责备”文化，而是一种公平和问责的文化。它提供了一个清晰的框架来区分：
*   **人为错误**：无心之失，应予以支持并着重于改进系统。
*   **风险行为**：未认识到风险或错误地认为风险是合理的选择（例如，采用变通方法），应予以辅导。
*   **鲁莽行为**：有意识地无[视重](@entry_id:173983)大风险，可能需要纪律处分。

通过创造这种公平透明的环境，公正文化鼓励开放报告和坦诚对话，这是真正理解工作如何完成所必需的。它是驱动学习、增强韧性的引擎。掌握了这一点的组织——通常被称为**高可靠性组织 (HROs)**——并非通过消除人类的可变性来取得成功，而是通过利用它，通过尊重前线专家的意见，以及即便在成功中也始终保持对失败可能性的警惕和关注 [@problem_id:4391555]。他们明白，安全不是一个要达到的状态，而是一种必须日复一日培养的动态能力。

