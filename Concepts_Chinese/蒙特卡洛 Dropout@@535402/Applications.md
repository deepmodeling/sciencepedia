## 应用与跨学科联系

我们已经看到，一个简单甚至近乎异想天开的想法——在预测时保持 Dropout “开启”——如何为我们提供了一个窥探[神经网](@entry_id:276355)络“思想”的窗口。这不仅仅是技术上的好奇心；它是通往构建不仅强大而且智慧的模型的门户。在这种背景下，智慧是认识到自身知识局限的能力。一个能说“我不知道”的智能系统，通常比一个提供自信但错误答案的系统更有价值。现在，让我们踏上一段旅程，穿越科学和工程的各个领域，看看蒙特卡洛 Dropout 这一深刻概念如何重塑我们与人工智能的关系，将其从一个“黑箱”神谕转变为探索发现中的合作伙伴。

### 两种不确定性的故事

在我们能使用不确定性之前，我们必须首先理解它的本质。想象一下，你是一位生物学家，正试图在显微镜下测量单个细菌的位置。由于热运动，这个细菌在不停地[抖动](@entry_id:200248)——这是你试图测量的事物中一种固有的、不可减少的随机性。这就是**偶然不确定性**。现在，假设你的显微镜镜头稍微失焦。这引入了另一层不确定性，它源于你测量工具的局限性。这就是**认知不确定性**。如果你能得到一台更好的显微镜，你就可以减少这第二种不确定性，但无论你的设备多好，你都无法阻止细菌的[抖动](@entry_id:200248)。

在机器学习中，我们的模型面临着这两种不确定性。偶然不确定性来自数据本身——固有的噪声、测量误差或被建模系统中的基本随机性。认知不确定性来自模型——它反映了模型未能从有限的训练数据中学到的东西。这是模型的“失焦”镜头，是它对未曾见过的问题空间区域缺乏了解。

[蒙特卡洛](@entry_id:144354) Dropout 是我们用来窥探模型[认知不确定性](@entry_id:149866)的工具。但我们如何将两者分开呢？[全方差定律](@entry_id:184705)，概率论的基石，提供了答案。对于任何预测 $y$，其总[方差](@entry_id:200758)可以被完美地分解。让我们考虑一个模型，对于给定的输入，它不仅预测均值 $\mu$，还预测数据噪声的[方差](@entry_id:200758) $\sigma^2$ [@problem_id:3344945]。我们预测的总[方差](@entry_id:200758)由下式给出：

$$ \mathrm{Var}(y) = \mathbb{E}[\sigma^2] + \mathrm{Var}(\mu) $$

这个优雅的公式是关键。第一项 $\mathbb{E}[\sigma^2]$ 是模型预测的数据噪声在其所有可能参数配置上的平均值；这是我们的偶然不确定性。第二项 $\mathrm{Var}(\mu)$ 是模型自身均值预测的[方差](@entry_id:200758)；这是我们的认知不确定性 [@problem_id:38596] [@problem_id:3344945]。

当我们运行蒙特卡洛 Dropout 时，我们生成一组预测 $\{\mu^{(m)}, \sigma^{2,(m)}\}_{m=1}^{M}$。然后，我们可以直接从这个样本中估计不确定性的两个组成部分。偶然部分大约是预测[方差](@entry_id:200758)的平均值，即 $\frac{1}{M}\sum \sigma^{2,(m)}$。认知部分是预测均值的样本[方差](@entry_id:200758)，它捕捉了不同“子网络”之间[分歧](@entry_id:193119)的程度 [@problem_id:3500210]。这种分解不仅仅是数学上的精妙之处；它具有深刻的实用性。认知不确定性告诉我们模型在哪里需要更多数据，而[偶然不确定性](@entry_id:154011)告诉我们可预测性的基本极限是什么。

### 构建更智能、更安全的人工智能

了解不确定性的*类型*使我们能够设计出更智能、更可靠的系统。如果一个模型的不确定性很高，它应该怎么做？答案取决于它*为什么*不确定。

考虑**主动学习**，这是一个模型可以请求标记新数据的过程。如果一个模型遇到一个新的数据点并且具有很高的*认知*不确定性，它实际上是在说：“我不知道这是什么；学习它的真实标签对我会有很大帮助。”这是一个信号，表明标记这个数据点是对人类专家时间的宝贵利用。我们甚至可以通过估计标记一个新数据点预期会减少多少模型的后验不确定性，来量化这种“信息的价值”。MC Dropout 提供了一种直接估算该量的方法，使我们能为主动学习循环建立一个停止标准：当预期的知识增益降至某个阈值以下时，我们停止为新标签付费 [@problem_id:3321134]。

现在，考虑一个部署用于关键任务的模型，比如医学图像分析或自动驾驶。如果模型不确定，我们可能根本不希望它做出决定。我们希望它**拒绝预测**。但什么时候拒绝呢？如果不确定性主要是偶然性的，那么数据本身就是模糊的，再多的模型训练也无济于事。但如果是不确定性是认知性的，那么模型就超出了其能力范围。一个复杂的拒绝预测策略可以利用这种区别：首先，对所有认知不确定性超过某个预算的预测（“未知的未知”）进行拒绝。然后，在剩余的预测中，对那些偶然不确定性过高的预测（“已知的未知”）进行拒绝 [@problem_id:3125763]。这创造了一个安全阀，使人工智能系统能够谨慎操作，并在最需要的时候精确地请求人类干预。

不确定性也可以被融入到算法的结构中，使其更加鲁棒。在计算机视觉中，[目标检测](@entry_id:636829)器通常必须为单个物体筛选多个重叠的候选框。标准方法，即[非极大值抑制](@entry_id:636086)（NMS），通常保留分类得分最高的框。但是，如果模型对一个框的类别非常自信，但对其精确位置非常不确定呢？一种基于贝叶斯决策理论的、能感知不确定性的方法可以创建一个修正后的分数，该分数在分类置信度与高定位不确定性的惩罚之间取得平衡。这会带来更可靠、更准确的检测结果，因为最终的选择不仅基于模型的想法，还基于它对这些想法的确信程度 [@problem_id:3146116]。

### 科学发现的指南针

[蒙特卡洛](@entry_id:144354) Dropout 最令人兴奋的前沿领域或许是它作为科学发现引擎的角色。在许多科学领域，我们使用机器学习来构建复杂、昂贵的模拟或实验的模型，即“代理模型”。这些模型学习从一些输入参数到输出的映射，例如根据分子的结构预测其毒性 [@problem_id:1436718] 或根据材料的原子构型预测其能量 [@problem_id:3394138]。

所有可能的分子或材料的空间是天文数字般的浩瀚。我们永远无法希望能探索其全部。在这里，[认知不确定性](@entry_id:149866)成为我们的指南针。当我们要求模型对一个新的、未见过的配置进行预测时，高的[不确定性估计](@entry_id:191096)告诉我们，我们正处于*未知领域*。这不是模型的失败；这是一个特性！它准确地告诉科学家模型的知识在哪些地方薄弱，因此，下一次实验或高保真模拟最有可能在哪些地方产生最令人惊讶和信息最丰富的结果。这就是[贝叶斯优化](@entry_id:175791)的核心原则，这是一种强大的策略，用于设计新的分子、材料和[生物序列](@entry_id:174368)，其指导思想是模型自身量化的无知 [@problem_id:2749052]。

这种[范式](@entry_id:161181)延伸到了物理学的前沿。[物理信息神经网络](@entry_id:145229)（[PINNs](@entry_id:145229)）是一种卓越的新工具，它通过将物理定律直接整合到其训练损失中来学习[求解偏微分方程](@entry_id:138485)。但是我们如何能信任它们的解呢？通过使用 MC Dropout，我们不仅可以向 PINN 索要例如[热方程](@entry_id:144435)的解，还可以索要其不确定性的[分布](@entry_id:182848)图。如果在特定的时空区域不确定性很高，这可能预示着存在复杂的物理现象，如[冲击波](@entry_id:199561)或[湍流](@entry_id:151300)，而模型难以捕捉这些现象，或者它可能仅仅表明模型在何处需要更多数据来锚定其解 [@problem_id:3410639]。[不确定性估计](@entry_id:191096)将 PINN 从一个黑箱求解器转变为一个用于物理探究的交互式工具。

### 诚实的度量：关于校准

我们的故事还有最后、至关重要的一环。模型仅仅产生一个不确定性分数是不够的。这个分数必须是*诚实的*。如果一个模型的 95% [置信区间](@entry_id:142297)只在 50% 的时间内包含真实答案，那么它的[不确定性估计](@entry_id:191096)不仅是错误的，而且是危险的误导。模型声称的置信度与其经验准确率相匹配的这一特性被称为**校准**。

我们如何检查一个模型的诚实度？我们测试它。我们取一组模型从未见过的数据，对于每个数据点，我们检查已知的真实答案是否落在模型预测的[置信区间](@entry_id:142297)内。如果我们测试一个 95% 的置信区间，我们期望看到真实答案在大约 95% 的情况下落入其中。这个简单而优雅的过程，被称为经验覆盖率测试，是判断[不确定性估计](@entry_id:191096)是否可信的最终裁判 [@problem_id:3410639] [@problem_id:3394138]。另一种同样强大的检查方法是计算平方误差的平均值，其中每个误差都由其预测[方差](@entry_id:200758)进行归一化。对于一个校准良好的模型，这个比率应该接近于 1 [@problem_id:3394138]。

这些测试是基础性的。它们确保当一个模型表达怀疑时，这种怀疑是有意义的。它们是应用于我们的人工合作者身上的[科学诚信](@entry_id:200601)的数学体现。因此，蒙特卡洛 Dropout 不仅仅是为我们提供一个不确定性的数值；它为我们提供了一个框架，用于构建不仅知识渊博，而且在深刻且可验证的意义上，对其知识局限性保持诚实的模型。而在科学中，就像在生活中一样，没有比这更有价值的特质了。