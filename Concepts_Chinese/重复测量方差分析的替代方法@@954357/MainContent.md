## 引言
追踪同一个人在一段时间内的变化是科学探究的基石，从临床试验到心理学实验都是如此。几十年来，完成这项任务的标准工具一直是重复测量[方差分析 (ANOVA)](@entry_id:262372)，该方法因其能将受试者内变化与受试者间噪声分离开来而备受推崇。然而，这种经典方法的精妙之处建立在一些脆弱的假设之上，而这些假设在面对真实世界数据的复杂性时（如不规则测量、缺失值或非正态分布）往往会土崩瓦解。统计理论与实践现实之间的这种差距可能导致误导性甚至完全错误的结论。

本文旨在探讨为克服这些局限性而开发的各种现代替代方法，为寻求更稳健、更灵活的纵向数据分析方法的研究人员提供一份指南。首先，在“原理与机制”一章中，我们将解构经典[方差分析的假设](@entry_id:172018)，特别是经常被违背的球形性准则，并探讨 Friedman 检验和线性混合效应模型等替代方法的基础逻辑。随后，“应用与跨学科联系”一章将展示这些先进方法不仅是理论上的奇珍，更是在医学、心理学和公共政策等不同领域产生可靠见解的重要工具，最终促成更细致、更真实的科学发现。

## 原理与机制

想象一下，你是一位科学家，正在追踪一种新药对患者血压的疗效，持续数周。你每周一都为患者测量一次血压，持续一个月。这是一个经典的**重复测量**设计。其威力是直观的：通过追踪同一个人，你控制了大量的个体变异。John 的血压可能天生就比 Jane 高，但你关心的是 John 的血压如何**随周变化**，以及这种变化模式对 Jane 是否相似。这种设计过滤掉了“个体间”的噪声，从而更清晰地描绘出“个体内”的故事。

几十年来，完成这项工作的首选工具是**重复测量[方差分析 (ANOVA)](@entry_id:262372)**。[方差分析](@entry_id:275547)背后的核心思想极其精妙：它将数据中的总变异分解为不同的来源。这就像将一个复杂的声音分解成构成它的单个音符。在我们的例子中，方差分析将“个体内”的变异切分为两部分：我们可以解释的变异（药物随时间产生的效应）和我们无法解释的变异（随机误差）。然后，该检验会比较“可解释”变异与“不可解释”变异的大小。如果由时间引起的变异远大于随机噪声，我们便得出结论：发生了真实的变化。这一比较最终体现在著名的 **$F$-统计量**中。

但这个精妙的程序建立在一个出人意料的脆弱假设之上，这是一条在现实世界中常常被违背的细则。这个假设被称为**球形性 (sphericity)**。

### 球形性：一个公平比较的准则

那么，什么是球形性？它并非像通常被误解的那样，是假设重复测量是相互独立的。它们当然不是！John 第二周的血压很可能与他第一周的血压相关。球形性是一个关于这种依赖**模式**的更微妙的条件。它要求任意两次测量值之差的方差必须相同，无论你选择哪两次测量。

让我们用一个类比来说明。想象一个参加 4 圈赛跑的选手。球形性就好比是说，完成第 1 圈到第 2 圈所需时间的变异性，与完成第 3 圈到第 4 圈所需时间的变异性是相同的。但这往往不现实。选手在开始时可能精力充沛，所以第 1 圈和第 2 圈之间的差异是稳定的。但到了比赛末段，疲劳会引入更多不稳定的表现，因此第 3 圈和第 4 圈之间的差异可能会有更大的变异性。

在医学数据中，我们一直看到这种情况。今天和昨天测量的某个生物标志物之间的关系，可能比它与一年前的测量值之间的关系要强得多。这种相关性随时间衰减的常见模式违背了球形性。从数学上讲，球形性要求对于任意一对时间点 $i$ 和 $j$，其差值的方差 $\mathrm{Var}(Y_i - Y_j)$ 是恒定的 [@problem_id:4777665]。

当这个准则被打破时，标准的[方差分析](@entry_id:275547) $F$-检验会变得过于乐观。这就像一个裁判比应有的尺度更容易吹罚犯规。这会导致 **I 类错误的膨胀**，即我们发现了一个“显著”的效应，但实际上它并不存在 [@problem_id:4546892]。

统计学家为此问题开发了巧妙的补丁。最常见的是 **Greenhouse–Geisser (GG)** 和 **Huynh–Feldt (HF)** 校正。它们并不改变计算出的 $F$-统计量，而是调整宣告显著性的门槛。它们减少了检验的**自由度**，使其更加保守（更难通过）。调整量由一个称为 $\epsilon$ (epsilon) 的因子决定，其范围从 $1$（完全满足球形性）到一个下限 $\frac{1}{k-1}$（对于 $k$ 次测量），后者表示严重违背。Greenhouse–Geisser 校正以相当保守著称，而 Huynh–Feldt 则是一种更宽松的调整。一个常见的[经验法则](@entry_id:262201)是，当 GG 校正的估计值 $\hat{\epsilon}_{GG}$ 小于约 $0.75$ 时使用它，否则使用 HF 校正 [@problem_id:4546761]。这些校正是巧妙的修复，但它们只是在一个难以适应数据真实性质的系统上打补丁。

### 当数据不按规则出牌时：秩次与稳健性

经典[方差分析](@entry_id:275547)的麻烦不止于球形性。另一个也许更根本的假设是，数据（或更准确地说，是误差）遵循优美的钟形正态分布。如果它们不遵循呢？考虑一项研究，患者在一个从 0 到 10 的量表上评价他们的疼痛程度。很常见的情况是，许多患者报告 0 或 1 分，导致分布严重偏斜并“堆积”在低分端 [@problem_id:4946275]。或者想象在认知实验中测量反应时，大多数反应很快，但有少数反应极长，从而产生一个长长的离群值尾巴 [@problem_id:4946275]。

对于这些情况，将数据强行套入方差分析框架，就像试图把方榫硬塞进圆孔。一个优美的替代方法是 **Friedman 检验**。这是一种**非参数**检验，意味着它对数据分布的形状几乎没有假设。其精妙之处在于简单。它不分析原始的疼痛评分，而是为每个患者提出了一个更简单的问题：哪个治疗期间的疼痛程度最低，哪个次低，依此类推？它将数据**在每个受试者内部**转换为从 $1$ 到 $k$ 的秩次。

然后，该检验会查看所有患者，看是否存在某个条件持续获得比其他条件更低（或更高）的秩次。如果所有治疗都相同（**原假设**），那么每个人的秩次分配应该是随机的——任何一次测量都有同等可能获得秩次 1、2 或 3。这个原则被称为**[可交换性](@entry_id:263314) (exchangeability)** [@problem_id:4835999]。但如果某个治疗真的更好，它将在整个群体中系统性地获得最好的秩次。通过对秩次进行操作，Friedman 检验不受离群值和偏态的影响。一个巨大的离群值仍然只获得最高的秩次。此外，由于排序是在每个受试者内部进行的，该检验完全回避了球形性问题 [@problem_id:4797184]。当[方差分析的假设](@entry_id:172018)被违背时，Friedman 检验不仅更安全，而且在检测真实效应方面可能更具统计功效 [@problem_id:4797217]。

### 机器中的幽灵：缺失数据问题

还有一个幽灵困扰着真实世界的纵向研究：**缺失数据**。患者可能错过一次访视，血样可能丢失，或者参与者可能完全退出研究 [@problem_id:4948290]。经典的重复测量方差分析以一种粗暴而简单的方式处理这个问题：**[按行删除法](@entry_id:637836) (listwise deletion)**。如果一个受试者哪怕只缺失一个数据点，他/她的所有历史记录都将从分析中被丢弃。

这样做有两个问题。首先，这是对信息和[统计功效](@entry_id:197129)的巨大浪费。其次，更[隐蔽](@entry_id:196364)的是，它可能导致严重的偏倚性结论。如果缺失的原因与结果本身有关（例如，患者因病情恶化而退出），那么剩下的“完整”样本就不再能代表原始群体。这就是数据**[完全随机缺失](@entry_id:170286) (MCAR)**——缺失就像一次真正的随机抛硬币——与数据**[随机缺失](@entry_id:168632) (MAR)**——缺失的概率取决于其他*已观测*数据——之间的区别。[按行删除法](@entry_id:637836)只有在严格且通常不现实的 MCAR 假设下才能保证无偏倚 [@problem_id:4948309]。

### 一个更灵活的宇宙：混合效应模型的兴起

经典方差分析的局限性——其僵化的球形性假设、对非正态数据的不容忍以及对缺失值的不良处理——为一个更强大、更灵活的框架铺平了道路：**线性混合效应模型 (LMM)**。

LMM 不再假设球形性，而是允许研究人员直接对协方差结构进行**建模**。如果你认为测量值之间的时间间隔越远，相关性越弱，你可以指定一个**自回归 (autoregressive)** 结构。如果你对模式一无所知，你可以让数据自己说话，估计一个**非结构化 (unstructured)** 的协方差矩阵 [@problem_id:4965583]。通过对依赖关系进行建模而非假设，LMM 完全避免了球形性校正的需要。

更强大的是，当使用**[最大似然](@entry_id:146147) (ML)** 等方法进行估计时，LMM 可以优雅地处理[缺失数据](@entry_id:271026)。只要缺失是 MAR，这些模型就可以使用每个受试者的所有可用观测值，而无需丢弃任何人。这不仅提高了[统计功效](@entry_id:197129)，还防止了困扰[按行删除法](@entry_id:637836)的偏倚 [@problem_id:4948290]。

本质上，从重复测量[方差分析](@entry_id:275547)到混合效应模型的演进，反映了统计思维的一次深刻变革。我们从一个有着严格规则的、僵化的、理想化的世界，转向一个拥抱真实数据复杂性和混乱性的灵活框架。通过构建更贴近我们所研究过程真实本质的模型，我们可以得出更准确、更细致，并最终更优美的关于我们周围世界的结论。

