## 引言
如何在[计算机内存](@entry_id:170089)中组织数据是计算机科学中的一个基础性挑战。在最早、最直观的策略中，连续分配是其中之一，即为每个程序分配一个单一、不间断的内存块。这种方法因其简单性和硬件效率而备受青睐。然而，这种优雅的简单性背后隐藏着一个持久而复杂的问题：[内存碎片](@entry_id:635227)，即可用空间被分裂成微小、无法使用的间隙。本文将直面这一挑战。第一部分“原理与机制”将解构连续分配的机制，探讨[外部碎片](@entry_id:634663)和[内部碎片](@entry_id:637905)等不可避免的问题、放置策略之间的权衡，以及[内存紧缩](@entry_id:751850)这一激烈但强大的解决方案。随后的“应用与跨学科联系”部分将揭示这些看似经典的问题并非历史遗物，而是在当今依然至关重要，影响着从[磁盘性能](@entry_id:748541)、实时系统到现代视频游戏中图形的流畅渲染等方方面面。

## 原理与机制

想象一下，你是一个很长的书架的管理员，有各种各样的人来找你要空间存放他们的藏书。你能制定的最简单的规则是，每个人的藏书必须放在一起，占据书架上一个连续、不间断的部分。这就是**[连续内存分配](@entry_id:747801)**的本质。它简单、优雅，而且对于计算机硬件来说，管理起来效率极高。一个进程被赋予一个起始地址（“基地址”）和一个长度（“界限”），它就可以访问该单一块内的任何内容。但正如我们将看到的，这种美妙的简单性隐藏着一个深刻而持久的问题。

### 瑞士奶酪问题：[外部碎片](@entry_id:634663)

让我们继续用书架的比喻。一开始，一切都很好。你给 Alice 一个 3 英尺长的区段，给 Bob 一个 2 英尺长的区段，给 Carol 一个 4 英尺长的区段，它们都彼此相邻。但后来 Bob 读完了他的书，并移走了他的藏书，在 Alice 和 Carol 之间留下了一个 2 英尺的空隙。一个新人 Dave 来了，想要一个 5 英尺长的区段。你看了看你的书架，你总共有足够的空闲空间，但它们分散在一些微小、无法使用的间隙中。这里有一个 2 英尺的空隙，那里可能有一个 1 英尺的空隙。没有任何一个单独的空隙足够大，可以容纳 Dave 的 5 英尺藏书。尽管你有足够的空间，Dave 还是被拒绝了。

这就是**[外部碎片](@entry_id:634663)**这个令人烦恼的问题。它发生在空闲内存随着时间的推移被分裂成许多不连续的块，或称“空洞”。即使空闲空间的总和足以满足新的请求，但没有一个单独的空洞足够大。

让我们来看一个更具体的[计算机内存](@entry_id:170089)示例。假设我们有 1024 KiB 的内存，一段时间后，空闲空间是一些大小为 96、64、128、32 和 96 KiB 的空洞。总空闲内存是相当可观的 $96 + 64 + 128 + 32 + 96 = 416$ KiB。如果一个新进程到达并请求 200 KiB，它必须被拒绝。可用的最大单个空洞只有 128 KiB。系统总内存是足够的，但它的配置不正确。这是一个简单的连续分配方案中经典且不可避免的后果 [@problem_id:3628253]。[内存映射](@entry_id:175224)变得像一片瑞士奶酪，而我们的请求太大了，无法装入任何一个孔洞中。

### 物理地址的束缚

一个聪明的学生可能会问：“为什么我们不能假装这些分离的空洞是一个大块呢？[操作系统](@entry_id:752937)难道不能告诉进程去使用那个 96 KiB 的空洞和那个 128 KiB 的空洞，然后‘桥接’它们之间的间隙吗？”这是一个极好的问题，它切中了计算机实际工作方式的核心。

答案在于软件承诺与物理现实之间的区别。像 CPU 的内存访问单元，以及更关键的直接内存访问（DMA）设备这样的硬件组件，通常思维简单。它们被赋予一个起始物理地址和一个长度，然后它们就开始访问那个地址，然后是下一个，再下一个，以一种不懈的顺序方式进行。它们就像一个被告知要将包裹送到主街 1000 号到 2000 号地址的送货卡车司机；司机会试图访问该序列中的每一个地址号码。

如果[操作系统](@entry_id:752937)试图“桥接”一个间隙，它实际上是在告诉进程和硬件，“你的内存在地址 1000 到 2000”，而实际上，比如说，从 1500 到 1600 的内存属于别人。当硬件盲目地尝试访问地址 1550 时，它将覆盖另一个进程的数据，甚至[操作系统](@entry_id:752937)本身——这是一个灾难性的错误。[操作系统](@entry_id:752937)不能在每次内存访问时都进行干预来提供“填充字节”；硬件直接在物理地址空间上操作。一个地址不仅仅是一个数字；它是一个物理位置。你不能用数据来修补地址空间中的一个洞，就像你不能通过在两个分离的空地之间放一张草坪的图片来使它们变得连续一样 [@problem_id:3628311]。对连续性的要求通常是一个硬性的、物理上的要求。

### 选择安放之处：首次适应、最佳适应与碎片之舞

既然我们面临着一系列的空洞，[操作系统](@entry_id:752937)就需要一个策略，或称**放置策略**，来决定为新请求使用哪个空洞。有三种经典策略：

-   **首次适应（First-Fit）**：从头开始扫描空洞，并选择第一个足够大的空洞。它快速而简单。
-   **最佳适应（Best-Fit）**：扫描所有空洞，并选择足够大的空洞中最小的一个。这在直觉上似乎很明智，因为它留下的剩余碎片最小，大概也是最没用的。
-   **最差适应（Worst-Fit）**：扫描所有空洞，并选择最大的一个。这似乎很浪费，但其想法是留下最大，因此也是最有用的剩余碎片。

哪种最好？有趣的是，答案是“视情况而定”。人们可能会认为最佳适应在最小化浪费方面是冠军。然而，这种直觉可能会产生误导。通过反复选择“最佳”匹配，该策略可能导致“千刀万剐”般的死亡，使内存充满了微小、无法使用的空洞尘埃，这些空洞刚好对下一个请求来说太小。

想象一组初始空洞，大小为 $\langle 40, 20.6, 20.6, 20.6 \rangle$，以及一系列请求 $\langle 20.5, 20.6, 20.5, 20.6 \rangle$。对于第一个 20.5 的请求，最佳适应会选择一个 20.6 的空洞，留下一个大小为 0.1 的微小、无用的碎片。对于第二个 20.5 的请求，它会再次这样做。另一方面，首次适应可能会将第一个 20.5 的请求放入那个大的 40 的空洞中，留下一个仍然有用的 19.5 的空洞，并为以后的请求保留了大小恰好为 20.6 的空洞。在这种特定情景下，最佳适应最终比首次适应产生了更多无法使用的微小空洞浪费 [@problem_id:3627964]。

事实上，人们可以构建对抗性的请求序列，使最佳适应的表现明显差于最差适应。通过发出恰好能装入较小空洞的请求，最佳适应会消耗掉最理想的块，为未来更大的请求留下一个不良的空洞[分布](@entry_id:182848)。而最差适应，通过从最大的块中分割，可能会保留更多样化的空洞大小 [@problem_id:3628008]。这些简单算法的性能是策略与特定的请求和释放序列之间的一场复杂舞蹈。没有普遍最优的策略。

### 秩序的代价：[伙伴系统](@entry_id:637828)与[内部碎片](@entry_id:637905)

管理任意大小空洞的复杂性催生了更结构化的分配器。其中最著名的一个是**[伙伴系统](@entry_id:637828)**。该分配器不处理任何可能的大小，而只处理大小为 2 的幂次方（例如，4、8、16、32、64 KiB...）的块。当一个请求到达时，系统将其大小*向上*取整到最接近的 2 的幂，并分配一个该大小的块。如果需要一个 64 KiB 的块，但只有一个 128 KiB 的块是空闲的，那么这个 128 KiB 的块会被分裂成两个 64 KiB 的“伙伴”，一个被使用，另一个被添加到空闲列表中。当一个块被释放时，系统会检查它的伙伴是否也空闲；如果是，它们会立即合并成它们更大的父块。这使得分配和释放非常快速。

但是这种僵化的结构带来了另一种代价。如果一个进程请求 62 KiB，[伙伴系统](@entry_id:637828)会给它一个 64 KiB 的块。如果它请求 90 KiB，它会得到一个 128 KiB 的块。多出来的空间——在第一种情况下是 2 KiB，在第二种情况下是 38 KiB——是被分配块的一部分，但既不能被该进程使用，也不能被其他任何人使用。这种浪费的空间称为**[内部碎片](@entry_id:637905)**。它是*在*一个已分配分区内部的浪费。这是一个根本性的权衡：我们通过引入有序但有时浪费的[内部碎片](@entry_id:637905)税，减少了[外部碎片](@entry_id:634663)的混乱 [@problem_id:3628282]。

### 大[扫除](@entry_id:203205)：[内存紧缩](@entry_id:751850)与重定位

如果[外部碎片](@entry_id:634663)变得如此严重，以至于系统无法再有效运作，该怎么办？[操作系统](@entry_id:752937)有一个强大但激烈的解决方案：**[内存紧缩](@entry_id:751850)**。就像整理我们的书架一样，[操作系统](@entry_id:752937)可以暂停一切，并将所有已分配的块滑到内存的一端。这个过程挤出了所有的空洞，并将它们合并成一个单一、巨大、连续的空闲空间块 [@problem_id:36275]。

但这提出了一个关键问题。如果我们在物理内存中移动了一个进程的数据和代码，它内部所有的指针和内存引用不都会变得无效吗？如果一个程序有一个指向地址 16,384 处对象的指针，而我们将整个程序移动到从地址 32,768 开始，那么那个指针现在就指向了垃圾。

解决方案是硬件和软件之间一次美妙的协作：**[动态重定位](@entry_id:748749)**。现代 CPU 不允许进程直接使用原始物理地址。相反，进程在它自己的私有*[逻辑地址](@entry_id:751440)空间*中操作，该空间总是从 0 开始。进程生成的每个内存地址都是一个[逻辑地址](@entry_id:751440)。当该地址被发送到内存时，一个特殊的硬件——**[内存管理单元](@entry_id:751868)（MMU）**——会进行干预。MMU 为当前运行的进程保存着两个特殊的值：一个**基址寄存器**和一个**界限寄存器**。它首先检查[逻辑地址](@entry_id:751440)是否小于界限值（以防止进程访问其分配范围之外的内存）。如果检查通过，它会将基址寄存器的值加到[逻辑地址](@entry_id:751440)上，从而产生最终的物理地址。
$$ a_{\text{phys}} = a_{\text{base}} + a_{\text{logical}} $$
现在，紧缩的魔力就变得清晰了。要移动一个进程，[操作系统](@entry_id:752937)只需复制该内存块，然后简单地更新该进程的基址寄存器中的值。进程本身对此毫无察觉；它的代码和指针都使用[逻辑地址](@entry_id:751440)，保持不变且完全有效。硬件在运行时透明地将它们转换为新的物理位置 [@problem_id:36278]。然而，这个机制有一个关键的弱点。它只保护 CPU 生成的地址。如果一个物理地址被缓存在其他地方，例如用于编程一个 DMA 设备，那个缓存的地址将*不会*被更新，系统就会崩溃。

### 整洁的经济学

紧缩是一个强大的工具，但它不是免费的。它消耗宝贵的 CPU 时间来复制可能达兆字节或千兆字节的数据。那么，什么时候值得这样做呢？这是一个工程和经济问题。我们必须权衡紧缩的成本与其收益。

让我们建立一个简单的模型。紧缩的成本与需要移动的已分配内存量 $A$ 成正比。我们称这个成本为 $C_{\text{compaction}} = A \cdot c_m$，其中 $c_m$ 是移动一个字节所需的时间。紧缩的好处是未来的[内存分配](@entry_id:634722)会变得快得多。没有紧缩，为一个请求找到一个空洞可能需要扫描许多小的、不合适的空洞。假设这个搜索平均每次分配的成本为 $c_s/p$，其中 $c_s$ 是一个常数，而 $p$ 是一个随机空洞足够大的概率。紧缩之后，只有一个巨大的空洞，所以搜索成本降至仅仅 $c_s$。

在接下来的 $N$ 次分配中，总节省将是 $N \cdot (c_s/p - c_s)$。如果总节省超过初始成本，紧缩就是值得的。我们可以找到一个收支[平衡点](@entry_id:272705) $N^{\star}$，此时成本等于收益。一点代数运算表明，当以下条件成立时，就会发生这种情况：
$$ N^{\star} = \frac{A c_m p}{c_s (1-p)} $$
如果[操作系统](@entry_id:752937)预计在不久的将来会处理超过 $N^{\star}$ 次的分配，那么现在执行紧缩在经济上是合理的 [@problem_id:3628301]。这把讨论从关于原则的定性讨论转变为关于策略的定量讨论。

### 现代困境：局部性与碎片化

我们讨论的原则不仅仅是历史注脚；它们在现代计算机架构中以新的、有趣的方式体现出来。考虑一个具有**[非统一内存访问](@entry_id:752608)（NUMA）**的系统，其中机器有多个[内存控制器](@entry_id:167560)（节点）。访问与 CPU 在同一节点上的内存（“本地”内存）比访问不同节点上的内存（“远程”内存）快得多。

现在，我们的[分配问题](@entry_id:174209)增加了一个新的维度。一个在节点 0 上运行的进程需要一个 64 MiB 的连续块。节点 0 严重碎片化；其最大的空闲空洞只有 12 MiB。然而，节点 1 有一个原始的 80 MiB 空闲块。[操作系统](@entry_id:752937)应该怎么做？

1.  **远程分配：** 使用节点 1 上的块。这很简单，并保留了节点 0 的内存状态。但是进程对这个块的每次访问都会产生更高的远程延迟，这可能会累积成显著的性能损失。
2.  **本地分配，不进行紧缩：** 这不是一个选项，因为没有足够大的本地空洞。
3.  **本地分配，进行紧缩：** 在节点 0 上执行一次代价高昂的紧缩，以创建一个 64 MiB 的空间。这保证了快速的本地访问，但会产生巨大的[前期](@entry_id:170157)开销，并改变本地节点的碎片状态。

这个选择涉及到访问延迟、紧缩开销和碎片化潜在未来成本之间的复杂权衡。选择远程分配现在可能很快，但会减慢应用程序的运行时间。选择进行紧缩可能会导致明显的[停顿](@entry_id:186882)，但总体上可能会带来更好的性能。“最佳”决策取决于延迟、紧缩的确切成本，甚至未来请求需要在本地节点上获得空间的概率 [@problem_id:3628330]。在书架上寻找一个连续块这个简单古老的问题，已经演变成现代高性能计算核心的一个高风险、多维度的[优化问题](@entry_id:266749)。

