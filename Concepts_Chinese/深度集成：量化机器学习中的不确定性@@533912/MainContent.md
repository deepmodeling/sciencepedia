## 引言
在深度学习模型驱动科学、工程及更广泛领域决策的时代，一个关键问题依然存在：我们能在多大程度上信任它们的预测？来自单一、庞大AI的一个自信答案可能具有误导性，甚至危险，因为它缺乏对其自身不确定性的关键背景信息。预测与可靠性之间的这一鸿沟是现代人工智能最重大的挑战之一。本文介绍[深度集成](@article_id:640657)（Deep Ensembles），一种概念上简单但异常强大的方法，用以应对这一挑战。通过训练一个模型的“委员会”而非单个模型，[深度集成](@article_id:640657)提供了一种实用且稳健的方式来量化模型知道什么，更重要的是，量化它不知道什么。在接下来的章节中，您将首先深入探讨核心的“原理与机制”，探索集成如何将[不确定性分解](@article_id:362623)为不同且可操作的类型。随后，在“应用与跨学科联系”中，您将看到这种量化的不确定性如何成为科学发现的引擎、风险感知决策的工具以及高风险领域的安全机制。

## 原理与机制

想象一下，您需要做一个关键决策，比如预测一个新产品的销量。您会信任一个单一、自信的分析师，无论他多么才华横溢吗？还是您更愿意咨询一个由不同专家组成的委员会，听取他们各自的预测，并且，也许最重要的是，观察他们彼此之间的分歧有多大？常识告诉我们，委员会是更安全的选择。委员会内部的分歧程度给了我们一条至关重要的信息：衡量预测不确定性的一个尺度。当所有专家都同意时，我们感到自信。当他们的意见分散时，我们就知道要谨慎行事。

[深度集成](@article_id:640657)正是基于这一原理运作的。我们不是训练一个庞大的[神经网络](@article_id:305336)并将其答案奉为圭臬，而是训练一整个委员会——一个网络的**集成**。每个成员都独立训练，从不同的随机初始化开始，并且通常以不同的随机顺序看到训练数据。这鼓励它们为同一个问题找到不同但仍然有效的解决方案。它们成了一个数字专家小组，它们的集体智慧，尤其是它们的分歧，是解锁现代AI中最受追捧的特性之一：可靠的[不确定性量化](@article_id:299045)的关键。

### 两种无知：[偶然不确定性与认知不确定性](@article_id:364043)

在我们问一个AI“你有多不知道？”之前，我们必须首先认识到“不知道”有两种截然不同的类型。理解这种区别是所有现代[不确定性量化](@article_id:299045)的基石。

首先是**[偶然不确定性](@article_id:314423)**（aleatoric uncertainty）。这个名字来源于拉丁语中表示骰子的词 *alea*。这是数据本身固有的不确定性——世界上不可减少的随机性，任何模型，无论多么强大，都无法消除。想象一下测量一个[化学反应](@article_id:307389)的[产率](@article_id:301843)。即使有完美的仪器和对底层物理学的完美理解，也总会有来自热噪声、量子效应或其他[随机过程](@article_id:333307)的微小、随机的波动。这就是[偶然不确定性](@article_id:314423)。它是被测量系统的属性，而不是我们模型的缺陷。一个好的模型不应该试图消除这种不确定性；它应该学会识别并报告它 [@problem_id:2479744]。

其次，在许多方面更有趣的是**认知不确定性**（epistemic uncertainty）。这个术语来源于希腊语中表示知识的词 *episteme*。这是源于我们模型自身知识欠缺的不确定性。它产生于训练数据有限或模型不完全适合问题。在我们的委员会类比中，[认知不确定性](@article_id:310285)是专家之间的分歧。如果我们只向模型展示了某种分子的几个例子，当它们遇到该类型的新分子时，它们会做出截然不同的预测。这种不确定性与[偶然不确定性](@article_id:314423)不同，是可减少的。通过在问题空间的那个区域提供更多数据，我们可以帮助我们的“专家”达成共识，认知不确定性就会降低 [@problem_id:2837997]。

### 怀疑的数学：分解方差

这两种不确定性之间的哲学区别不仅仅是一个模糊的概念；它被**全方差定律**以优美的数学精度捕捉。这个定律为[深度集成](@article_id:640657)提供了动力引擎。

假设我们有一个包含 $M$ 个模型的集成。对于给定的输入 $x$，每个模型 $m$ 不仅给出一个单一的预测；它预测一个完整的[概率分布](@article_id:306824)。对于回归任务，这通常是一个均值为 $\mu_m(x)$、方差为 $\sigma_m^2(x)$ 的高斯分布。模型预测的方差 $\sigma_m^2(x)$ 是它对该特定输入的[偶然不确定性](@article_id:314423)的估计。

集成的最终预测是这些单个分布的混合。这个[混合分布](@article_id:340197)的总方差，代表了总的预测不确定性，可以被优雅地分解为两个部分 [@problem_id:3166725] [@problem_id:66099]：

$$
\text{Total Variance} = \underbrace{\frac{1}{M} \sum_{m=1}^{M} \sigma_m^2(x)}_{\text{Aleatoric}} + \underbrace{\frac{1}{M} \sum_{m=1}^{M} (\mu_m(x) - \bar{\mu}(x))^2}_{\text{Epistemic}}
$$

其中 $\bar{\mu}(x)$ 是所有单个均值的平均值。

让我们来解析一下。它比看起来要简单。

1.  **偶然项**：第一部分，$\frac{1}{M} \sum_{m=1}^{M} \sigma_m^2(x)$，就是*单个模型预测方差的平均值*。它回答了这样一个问题：“平均而言，委员会认为数据在这一点上的内在噪声有多大？”这是我们对[偶然不确定性](@article_id:314423)的估计。

2.  **认知项**：第二部分，$\frac{1}{M} \sum_{m=1}^{M} (\mu_m(x) - \bar{\mu}(x))^2$，是*委员会均值预测的方差*。它直接衡量了单个模型之间相互分歧的程度。这是我们对认知不确定性的估计。

为了让这个概念更具体，我们来看一个简单的数值例子 [@problem_id:3166725]。假设我们有一个由 $M=5$ 个模型组成的集成来预测一个值。它们的均值预测为 $\{1.0, 1.5, 2.0, 2.5, 3.0\}$，它们对数据噪声（偶然方差）的单独估计为 $\{0.5, 0.6, 0.4, 0.7, 0.3\}$。

-   **[偶然不确定性](@article_id:314423)**：我们对单个噪声估计值求平均：$\frac{1}{5}(0.5+0.6+0.4+0.7+0.3) = 0.5$。
-   **[认知不确定性](@article_id:310285)**：我们计算均值预测的方差。平均预测值为 $\frac{1}{5}(1.0+1.5+2.0+2.5+3.0) = 2.0$。围绕这个平均值的方差是 $\frac{1}{5}((1.0-2.0)^2 + (1.5-2.0)^2 + \dots + (3.0-2.0)^2) = 0.5$。

总预测方差是两项之和：$0.5 (\text{偶然}) + 0.5 (\text{认知}) = 1.0$。数学完美地反映了我们的直觉：总不确定性是世界内在随机性与我们模型自身无知的总和。同样的逻辑也适用于分类任务，其中[分歧](@article_id:372077)被衡量为每个类别预测概率的方差 [@problem_id:2479707]。

### 从不确定性到行动：校准与风险

如果我们不对不确定性采取行动，那么了解它就毫无用处。[深度集成](@article_id:640657)给了我们构建更稳健、更可信赖的系统的工具。

最重要的应用之一是做出**风险感知决策**。想象一下在两个模型之间选择：模型A平均来说稍微准确一些，但模型B的[认知不确定性](@article_id:310285)要低得多（其集成成员高度一致）。一个规避风险的用户可能更喜欢模型B，认为其可靠性比原始性能的微小提升更有价值。我们甚至可以用一个像 $R_{\kappa} = \text{MSE} + \kappa \cdot \overline{\text{Var}}$ 这样的分数来形式化这种权衡，其中我们明确地惩罚模型的平均认知方差，因子 $\kappa$ 控制我们对不确定性的规避程度 [@problem_id:3168849]。

在科学发现中，认知不确定性不是麻烦，而是向导。在[材料科学](@article_id:312640)或[药物发现](@article_id:324955)中，我们使用模型来筛选庞大的候选分子库。我们应该在哪里进行下一次昂贵的实验室实验？答案通常是：在模型认知不确定性最高的地方。这是模型“最困惑”的地方，因此在这里一个新的数据点将提供最多的信息，帮助集成成员解决他们的分歧并迅速改进模型。这是**[贝叶斯优化](@article_id:323401)**和[主动学习](@article_id:318217)背后的核心思想 [@problem_id:2749052]。

然而，要让[不确定性估计](@article_id:370131)值得信赖，它必须是**校准过的**。一个良好校准的模型是一个“诚实”的模型。如果它对一组预测赋予80%的置信度，那么它在这些预测上的正确率应该在80%左右。我们可以通过创建**可靠性图**来衡量这种诚实度，该图绘制了经验准确率与预测置信度的关系。与完美诚实度的偏差可以通过一个名为**预期校准误差（ECE）**的指标来概括 [@problem_id:2479707]。[深度集成](@article_id:640657)不仅以产生低误差预测而闻名，还以产生良好校准的预测而著称，这使得它们特别可靠。

最后一个微妙的点是委员会应该如何商议。他们是就最终结果投票（平均概率），还是平均他们底层的推理（平均**logits**，即最终概率转换前的原始输出）？事实证明，平均logits通常更受青睐，因为它倾向于产生更自信和校准得更好的预测。这是更深层次商议过程的数学等价物 [@problem_id:3166242]。

### 知识的脆弱性：[集成方法](@article_id:639884)何时失效

尽管[深度集成](@article_id:640657)功能强大，但至关重要的是要理解它们并非万无一失。它们是一个深刻的工具，但它们有一个关键的弱点：它们可能被真正未知的事物所欺骗。

集成的[不确定性估计](@article_id:370131)只有在它看到的新数据来自与其训练数据相同或非常相似的分布时才是可靠的。当面对一个完全**分布外（OOD）**的样本时，整个集成可能会失效，而且可能是灾难性地**自信地出错**。

想象一个被训练来预测只含碳、氢、氮和氧的分子属性的集成。当我们给它一个含卤素（如氯）的分子时会发生什么？一种称为**特征空间[混叠](@article_id:367748)**的致命失效模式可能会发生 [@problem_id:2903786]。模型的[特征提取器](@article_id:641630)——网络中将原始分子转化为数字列表的部分——可能不知道如何表示氯。它可能为含氯分子生成一个数值表示，这个表示看起来与其训练集中一个熟悉的、无害的有机分子完全相同。

当这种情况发生时，输入对于网络来说看起来是“分布内的”。委员会中的所有专家都被一同欺骗了。他们看到一个看起来熟悉的输入，并且都自信地应用了他们为那个熟悉输入学到的规则。他们的预测将紧密聚集，[认知不确定性](@article_id:310285)将接近于零，模型将以高置信度宣告一个完全荒谬的预测。

这就是AI的“未知的未知”。模型不知道它不知道什么。这突显了没有任何AI系统是神奇的黑匣子。负责任的部署需要持续的警惕，使用统计测试来检测部署数据何时开始偏离训练数据，并且永远不要盲目相信一个预测，无论它看起来多么自信。[深度集成](@article_id:640657)给了我们一个非凡的镜头来观察机器的心智，不仅揭示了它知道什么，还揭示了其知识的纹理和局限。

