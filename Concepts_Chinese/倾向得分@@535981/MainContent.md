## 引言
确定一项干预措施是否真正导致某个结果是科学研究的核心目标，但“金标准”——随机对照试验（RCT）——通常无法实施。在现实世界的观察性数据中，由于混杂因素的存在，对不同组别进行比较充满了风险。这就是所谓的“苹果和橘子”问题，即结果的差异可能是由组间预先存在的差异导致的，而非治疗本身。本文通过介绍倾向性评分来应对这一根本性挑战，这是一种强大的统计工具，旨在在非随机化研究中实现公平比较。它揭示了这种巧妙的方法如何让研究人员利用观察性数据来近似模拟实验条件。在接下来的章节中，您将首先探索使倾向性评分发挥作用的核心统计学“原理与机制”，从“平衡特性”到匹配和加权等主要方法。随后，“应用与跨学科联系”一章将展示这些技术如何应用于医学、流行病学和数据科学等不同领域，以在复杂的世界中揭示因果真相。

## 原理与机制

### 苹果与橘子的困境

想象一个医生团队想知道一种新的、高风险的外科手术是否比标准药物更能治疗严重的心脏病。他们查看了数千名患者的数据，发现了一个惊人的结果：接受手术的患者比服用药物的患者更有可能出现并发症。他们应该就此断定手术是失败的吗？

别那么快下结论。一个好的科学家，就像一个好的侦探，必须总是问：“还有其他什么可能的原因呢？”谁会接受手术？通常是那些病情最危重的患者——那些标准药物已不再是选项的患者。而接受药物治疗的患者，可能一开始就比较健康。因此，最初的分析并不是一个公平的比较。它比较的是病情较重的“苹果”（手术组）与较健康的“橘子”（药物组）。这个根本性问题，即一个隐藏因素既与治疗相关又与结果相关，被称为**混杂**。在这个案例中，疾病的严重程度就是混杂因素。它使得我们无法将治疗的效果与患者初始健康状况的效果区分开来。[@problem_id:5106024]

几十年来，这个“苹果与橘子”问题对于那些试图从现实世界的、无法进行完美实验的观察性数据中了解因果关系科学家来说，一直是个巨大的难题。进行公平比较的黄金标准是**随机对照试验（RCT）**，即通过抛硬币的方式将患者分配去接受手术或药物治疗。随机化像魔法一样，能确保平均而言，除了接受的治疗不同外，两组在所有可以想象的方面——无论是已知的还是未知的——都是相同的。它强制让比较在苹果和苹果之间进行。但是，当RCT不道德、不切实际或已错过时机时，我们能做什么呢？我们如何才能在混乱的、非随机的数据中找到真相？

### 一种统计学上的巧妙手法：倾向性评分

这时，一个极其巧妙的想法应运而生，这是20世纪末最重要的统计学发展之一。在20世纪80年代初，统计学家Paul Rosenbaum和Donald Rubin提出了一个简单而深刻的问题：一个混乱的观察性研究和一个干净的随机试验之间的关键区别是什么？他们的答案是，在试验中，每个人接受治疗的概率是固定且已知的（通常为50%），无论他们是病是健。在我们关于心脏病的[观察性研究](@entry_id:174507)中，这个概率并非固定的。一个病得很重的患者可能有90%的机会被建议进行手术，而一个较健康的患者可能只有10%的机会。

这个概率——在给定一组基线特征的情况下接受治疗的概率——就是他们所称的**倾向性评分**。形式上，如果$A=1$代表接受治疗，而$X$是所有相关的治疗前患者特征（如年龄、性别、疾病严重程度、实验室检查值等）的集合，那么倾向性评分是：

$$e(X) = P(A=1 \mid X)$$

乍一看，这似乎没什么大不了。但这是一个天才之举。它将一个可能包含数十个特征的庞大、笨拙的列表——统计学家称之为高维问题——压缩成一个*单一的数值*。这一个数值，即倾向性评分，充当了患者接受特定治疗的所有已测量原因的摘要。它本质上是一个关于混杂的单一汇总分数。[@problem_id:5054453]

### 伟大的均衡器：平衡特性

真正的魔力在这里发生。Rosenbaum和Rubin证明了一个被称为倾向性评分的**平衡特性**的卓越定理。该定理指出，如果你选取一组倾向性评分*完全相同*的患者，那么在该组内，接受治疗者和未接受治疗者之间所有基线特征（$X$）的分布将是相同的。[@problem_id:4364942]

让我们停下来体会一下这是多么令人惊叹。假设我们找到一组倾向性评分均为$0.75$的患者。这意味着根据他们特定的年龄、疾病严重程度和其他因素的组合，他们都有75%的机会接受手术。他们中的一些人确实接受了手术，而另一些人由于某种原因最终接受了药物治疗。平衡特性保证了在这个75%概率的群体中，手术患者和药物患者在$X$中的所有特征上平均而言是完全可比的。他们的平均年龄将是相同的，他们的平均疾病严重程度将是相同的，依此类推。这就像是我们在我们数据的一小部分中创造了一个微型随机实验！[@problem_g_id:4515359]

通过以这个单一数值为条件，我们同时在数十个变量上实现了平衡。我们在统计上将我们的[观察性研究](@entry_id:174507)中的苹果和橘子变成了可比较的组。这是使倾向性评分分析成为可能的核心原理。

### 因果推断工具箱：匹配、分层与加权

一旦我们有了这个强大的工具，我们如何用它来估计治疗效果呢？主要有三种策略，每种都有其自身的特点。

**1. 匹配（Matching）：** 这是最直观的方法。对于每个接受治疗的患者，我们在未接受治疗的患者池中搜索他们的“统计双生子”——一个倾向性评分完全相同或非常相似的个体。然后我们形成治疗和未治疗个体的配对，并直接比较他们的结果。通过只比较这些匹配的双生子，我们正在进行公平的比较。这种方法通常估计的是**受治疗者的平均治疗效应（ATT）**，它回答了这样一个问题：“在实际接受手术的患者中，与他们如果接受药物治疗会发生的情况相比，手术的效果是什么？” [@problem_id:5054453] [@problem_id:4541636]

**2. 分层（Stratification）：** 这是匹配的一个稍显粗略但更简单的方法。我们不是寻找单个的双生子，而是根据倾向性评分将整个研究人群分成几个组或“层”。例如，我们可以创建五个分层：评分在$0$到$0.2$之间的患者，在$0.2$到$0.4$之间的患者，依此类推。在每个分层内，治疗组和未治疗组现在大致是平衡的。我们可以在每个分层中计算治疗效果，然后将这些效果平均以获得一个[总体估计](@entry_id:200993)。[@problem_id:5054453]

**3. [逆概率](@entry_id:196307)治疗加权（IPTW）：** 这是最抽象但可以说是最强大的方法。其思想是创建一个新的、合成的“伪群体”，在这个群体中混杂已不复存在。它通过对研究中的每个人进行加权来实现这一点。

-   一个接受了根据其特征来看*不太可能*接受的治疗的患者（例如，一个非常健康的人接受了高风险手术），会被赋予一个*较大*的权重。他们在统计上“代表”了所有其他未接受手术的类似健康人群。

-   一个接受了*很可能*接受的"治疗的患者（例如，一个病得很重的人接受了手术），会被赋予一个*较小*的权重，因为他们已经能代表他们所在的群体。

权重就是他们实际接受治疗的概率的倒数。对于一个接受治疗的人，权重是 $w = 1/e(X)$；对于一个未接受治疗的人，权重是 $w = 1/(1-e(X))$。当我们应用这些权重时，我们创造了一个新的、平衡的伪群体，其中治疗组和未治疗组的特征是相同的。在这个合成的世界里，就好像治疗是随机分配的，我们可以估计整个群体的**平均治疗效应（ATE）**。[@problem_id:4576147] [@problem_id:4364942]

### 游戏规则：假设与陷阱

这个强大的工具箱并非没有代价。其有效性依赖于几个关键且无法检验的假设。诚实的科学要求我们清楚地陈述它们。

-   **条件[可交换性](@entry_id:263314)（无未测量的混杂因素）：** 这是最重要的一条。倾向性评分只能平衡我们已经测量并包含在模型（$X$）中的混杂因素。如果存在某个*未测量*的因素，它既影响治疗选择又影响结果——比如，患者的积极性或我们没有检测的特定基因标记——倾向性评分无法解决这个问题。我们必须能够假设，在考虑了我们测量的协变量$X$之后，相对于[潜在结果](@entry_id:753644)而言，治疗分配实际上是随机的。[@problem_id:5106024] [@problem_id:4515359] 这是一个深刻的要求；它意味着即使某些混杂因素数据缺失，我们也必须使用复杂的方法来填补空白，而这些方法本身必须知晓治疗和结果，以避免破坏我们试图研究的微妙关系网。[@problem_id:4817024]

-   **正性（或重叠）：** 对于任何给定的特征集，接受任一治疗的概率都必须非零。在我们的例子中，如果*所有*肾功能极低（例如，$eGFR  30$）且有大出血史的患者都接受了药物治疗，而*没有一个*接受手术，那么我们就没有关于这类患者如果接受手术会发生什么的数据。没有可以与他们比较的对象。这严重违反了正性。在实践中，我们经常面临“接近违规”的情况，即某些个体的倾向性评分非常接近$0$或$1$。这表明组间缺乏重叠，并可能导致严重问题，例如在IPTW分析中产生大得不可能的权重。[@problem_id:4984021]

-   **一致性和SUTVA：** 这些是更技术性的假设，基本上是说治疗是明确定义的，并且一个个体的结果不受其他任何人治疗的影响。[@problem_id:5106024]

此外，构建倾向性评分模型本身也需要谨慎。它不是一个简单的预测任务。包含一个能强有力预测治疗但与结果无关的变量（“工具变量”），并不会减少偏倚，反而可能通过产生更极端的倾向性评分而显著增加你估计值的方差。一个致命的错误是包含了任何在*治疗开始后*测量的变量，因为这会引入严重的偏倚。[@problem_id:4364942] [@problem_id:4515359]

### 驾驭现实世界：诊断与勤勉

研究人员如何负责任地使用这些方法？这需要勤勉和愿意检查他们的工作。

首先，你如何知道你的倾向性评分模型是否好？目标是**平衡**，而不是预测。一个能完美预测谁接受哪种治疗的模型意味着没有重叠，这使得因果推断变得不可能！所以，研究人员不应检查分类准确率之类的指标，而必须检查他们选择的方法（匹配或加权）是否真正在协变量上实现了平衡。他们通过比较调整前后的每个协变量的**标准化均数差（SMD）**来做到这一点。一个好的模型将导致调整后的SMD都接近于零。[@problem_id:4576154]

其次，如果你发现缺乏重叠（一个实际的正性问题）怎么办？统计学家已经发展出许多策略：

-   **修剪或限制：** 你可以简单地排除那些倾向性评分极端、难以进行公平比较的个体。例如，在匹配分析中，找不到合适“双生子”的个体会被排除。这会产生一个更可靠的估计，但只适用于一个更受限的人群。你回答了一个略有不同但更易回答的问题。[@problem_id:4984021] [@problem_id:4541636]

-   **权重截断：** 在使用IPTW时，你可以为极大的权重设置上限，以防止它们破坏整个分析的稳定性。这会引入微量的偏倚，但可以大幅减少估计的方差，这通常是值得的权衡。[@problem_id:4984021] [@problem_id:4576154]

-   **重叠加权：** 一种更优雅的现代方法涉及一种不同的加权方案，它给予那些“摇摆不定”的人——倾向性评分接近$0.5$的人——最大的权重。这些人是治疗选择最不确定的人，也是治疗组和未治疗组之间有最自然重叠的地方。这种方法对极端倾向性评分具有高度的稳健性，并针对一个定义明确且通常具有临床相关性的因果效应。[@problem_g_id:4639155] [@problem_id:4984021]

倾向性评分不是一根能将所有观察性数据都点石成金的魔杖。它是一个锋利而强大的工具，当以对其原理的深刻理解和对其假设的健康尊重来使用时，能让我们在一个完美实验通常是我们无法负担的奢侈品的世界里，更接近关于因果关系的真相。它证明了统计推理在复杂性中寻找清晰和秩序的力量。

