## 引言
当我们无法进行完美的实验时，如何确定一种新药、一项新政策或一项新技术是否真正有效？在现实世界中，我们常常面对观测数据，其中我们想要比较的群体从一开始就存在根本差异——这个问题被称为“混杂”（confounding）。简单地比较接受“处理”者和未接受“处理”者的结果，可能会得出极具误导性的结论，就像比较苹果和橘子一样。虽然[随机对照试验](@article_id:346404)（Randomized Controlled Trial, RCT）是建立因果关系的黄金标准，但它往往不切实际或不符合伦理。然而，一种强大的统计工具为我们指明了前进的道路。本文将介绍[倾向得分](@article_id:640160)（propensity score），这是一种在观测研究中控制混杂的精妙方法。

接下来的章节将引导您了解这一[因果推断](@article_id:306490)的关键技术。首先，在“原理与机制”中，我们将探讨混杂这一核心问题，并引入[倾向得分](@article_id:640160)作为一种将多个变量压缩为单一变量的“平衡得分”（balancing score）。我们将详细介绍用于模拟实验的匹配、加权和分层等主要方法。然后，在“应用与跨学科联系”中，我们将看到这些原理的实际应用，展示[倾向得分](@article_id:640160)如何在医学、[保护科学](@article_id:380610)乃至现代[算法公平性](@article_id:304084)审查等不同领域提供关键见解。

## 原理与机制

### 混杂的诅咒：苹果与橘子的比较

想象一下，你是一位农民，听说了一种神奇的新肥料。你在自己的一块田里试用了它，到了收获时节，产量惊人。而你的邻居，一位坚持使用老方法的农民，收成则差得多。这种新肥料是奇迹吗？也许是。但也许你也是一位经验更丰富、土壤更肥沃、灌溉系统更好的农民，而且你恰好是那种愿意尝试新产品、思想前卫的人。很可能，你的田地无论如何都会有更高的产量。

这就是从我们所观察到的世界中得出结论时面临的基本困境。我们想知道某件事物——肥料、新药、职业培训项目——对某个结果的**因果效应**（causal effect）。但是，接受“处理”的群体和未接受“处理”的群体从一开始就在许多其他方面存在差异。在统计学中，我们称这些差异为**混杂变量**（confounders），它们制造了一个棘手的问题。当我们比较[作物产量](@article_id:345994)时，我们比较的不是“有肥料”与“无肥料”，而是“技术娴熟、思想前卫、土壤肥沃的农民 *加上* 新肥料”与“其他人”。我们比较的是苹果和橘子。

在理想世界中，我们会进行一项**[随机对照试验](@article_id:346404)**（Randomized Controlled Trial, RCT）。我们会选取一大群农场，随机将一半分配给新肥料，另一半则照旧。这种随机分配的行为如同魔法：它能确保，在平均意义上，两个组在所有特征上都是平衡的，既包括我们可以测量的特征（如土壤质量），也包括我们无法测量的特征（如农民的天赋）。这样，两组之间产量的任何差异都可以自信地归因于肥料。

但是，RCT往往不切实际、成本高昂，甚至完全不符合伦理。我们不能随机分配一些人吸烟而另一些人不吸烟；我们也很难将整个景观[随机化](@article_id:376988)来研究森林破碎化对野生动物的影响 [@problem_id:2538639]。我们常常只能使用**观测数据**（observational data），并且必须找到一种方法来驯服混杂的诅咒。

### [倾向得分](@article_id:640160)：统计学的魔法石

我们如何才能让我们“苹果与橘子”的比较更像“苹果与苹果”的比较？直观的答案是，将被处理的个体与和他们非常相似的未被处理的个体进行比较。对于每一个使用了新肥料的农场，我们可以尝试找到一个未使用新肥料但土壤质量、降雨量、农民经验等都相同的农场。

这是一个好主意，但很快就会变得不可能。如果我们有十个特征需要匹配，“维度灾难”（curse of dimensionality）就会降临。要为一个45岁、有20年经验、拥有黏壤土、农学博士学位且积极性高的农民找到一个精确的匹配，就像大海捞针一样毫无希望。

这时，由 Paul Rosenbaum 和 Donald Rubin 提出的现代统计学中最精妙的思想之一前来救场。我们不必尝试匹配几十个协变量 $X$，而是将它们全部压缩成一个神奇的数字，这个数字就是**[倾向得分](@article_id:640160)**。

**[倾向得分](@article_id:640160)**，通常写作 $e(X)$，简而言之，就是一个单元（unit）在给定其观测到的处理前特征集合 $X$ 的条件下，接受处理的概率。

$$ e(X) = \mathbb{P}(T=1 \mid X) $$

对于我们的农民来说，这代表了根据我们在播种季节开始前所知道的关于他们及其农场的一切信息，他们选择使用新肥料的概率。这是一个介于0和1之间的数字。

这个得分之所以如此强大，源于一个美妙得近乎神奇的结论：它是一个**平衡得分**（balancing score）。这意味着，如果我们取任意两个具有完全相同[倾向得分](@article_id:640160)的单元——比如说，一个被处理，一个未被处理——那么构成该得分的所有协变量 $X$ 在它们之间的分布将是相同的。换句话说，如果一个被处理的农场和一个未被处理的农场都有70%的倾向使用新肥料，那么在平均意义上，它们在所有决定这一倾向的方面都是相似的。通过对这一个数字进行条件化，我们已经隐含地对整个混杂变量向量进行了条件化。我们在统计意义上，重现了随机实验的平衡性 [@problem_id:2497319]。

### 付诸实践：匹配、加权与分层

一旦我们拥有了[倾向得分](@article_id:640160)这个强大的新工具，我们该如何用它来估计因果效应呢？主要有三种策略。

1.  **匹配（Matching）**：这是最直观的方法。对于处理组中的每个个体，我们在对照组中找到一个（或多个）[倾向得分](@article_id:640160)最接近的个体。我们丢弃所有不匹配的个体，剩下的就是一个新的、更小的数据集。在这个数据集中，处理组和对照组根据构造在[倾向得分](@article_id:640160)上非常相似，因此在协变量上也达到了平衡。然后，我们只需比较这个新构建的平衡样本中的平均结果即可 [@problem_id:1908000] [@problem_id:2497319]。

2.  **[逆概率](@article_id:375172)加权（Inverse Probability Weighting, IPW）**：这种方法不丢弃数据，而是使用所有数据，但给每个人赋予不同的权重。可以这样理解：一个非常*不可能*接受处理（[倾向得分](@article_id:640160)低）但最终却接受了处理的人，是一个非常令人意外且[信息量](@article_id:333051)丰富的案例。为了使他们能够代表一个处理是随机分配的群体，我们必须“上调”他们的权重。他们的权重是其[倾向得分](@article_id:640160)的倒数，即 $1/e(X)$。类似地，一个非常*可能*接受处理（[倾向得分](@article_id:640160)高）但未被处理的人也同样令人意外。我们通过 $1/(1-e(X))$ 来上调他们的权重。通过应用这些权重，我们创建了一个“伪群体”（pseudo-population），在这个群体中，处理和协变量不再相关，再次模拟了RCT [@problem_id:1936677]。

3.  **分层（Stratification）**：这是一种混合方法。我们根据[倾向得分](@article_id:640160)将人群切分成几个层（strata）（比如五个区间）。例如，所有得分在0到0.2之间的个体进入第一个区间，0.2到0.4的进入第二个，依此类推。在每个区间内，[倾向得分](@article_id:640160)是相似的，因此我们可以假设单元之间大致是平衡的。我们在每个层内计算[处理效应](@article_id:640306)，然后计算这些效应的[加权平均](@article_id:304268)值，以得到一个总体的估计 [@problem_id:3110492]。

### [讨厌参数](@article_id:350944)的艺术：正确获得得分

当然，[倾向得分](@article_id:640160)不会凭空出现。我们必须用我们的数据来估计它，通常使用像逻辑回归这样的统计模型。这个估计出的得分在统计学上被称为**[讨厌参数](@article_id:350944)**（nuisance parameter）——它是我们分析中必不可少的脚手架，但我们并不关心它本身的数值。我们的真正目标是估计因果效应。

这里存在一个微妙而极其重要的转折，常常让初学者感到惊讶。在构建模型以估计[倾向得分](@article_id:640160)时，我们的目标*不是*构建一个能最好地预测谁会接受处理的模型。这是标准机器学习预测任务与因果推断任务之间的关键区别 [@problem_id:3148913]。

考虑一项研究，试图确定一个STEM（科学、技术、工程和数学）强化项目是否能提高考试成绩。研究人员可能会构建两个不同的模型来估计报名参加该项目的倾向。模型A很复杂，并且非常擅长预测谁会报名（它有很高的AUC，一种衡量预测能力的指标）。模型B更简单，预测准确性较低。我们应该用哪个模型？答案出人意料，可能是模型B。

一个[倾向得分](@article_id:640160)模型唯一重要的标准是它**平衡协变量**的效果有多好。在使用该得分对数据进行匹配或加权后，处理组和[对照组](@article_id:367721)在处理前特征（如之前的学业表现和动机）上是否真的变得相似了？我们通过诊断工具来检查这一点，最常用的是**标准化均数差**（Standardized Mean Difference, SMD）。对于每个协变量，SMD衡量两组均值之间的差异，并按标准差进行缩放。一个普遍的经验法则是，绝对SMD低于0.1表示不平衡可以忽略不计。

在我们一个教学问题探讨的场景中，一个预测AUC较低的模型实际上产生了远为更好的协变量平衡（平均SMD为0.07，而另一个为0.16），使其成为因果分析的更优选择 [@problem_id:1936677]。目标是平衡，而不是预测。如果未能实现平衡，研究人员必须返回并完善[倾向得分](@article_id:640160)模型——也许通过添加平方项或交互项——在一个迭代过程中进行，所有这些都必须在查看最终结果数据之前完成，以避免偏倚 [@problem_id:2538639]。

### 规避陷阱：当好的得分变坏时

[倾向得分](@article_id:640160)方法功能强大，但并非万无一失。它们建立在一些假设之上，当这些假设被违反，或者方法被草率应用时，结果可能具有误导性。

-   **[模型设定错误](@article_id:349522)（Model Misspecification）**：整个事业都依赖于我们估计的[倾向得分](@article_id:640160)的质量。如果我们的[模型设定错误](@article_id:349522)——例如，我们假设了一个简单的线性关系，而真实世界是高度非线性的——那么得分就会是错误的。如果得分是错误的，平衡属性就会失效。我们将留下**残余混杂**（residual confounding），我们的因果估计将会有偏，有时甚至非常严重 [@problem-id:3166589] [@problem-id:3110492]。

-   **正值假设（The Positivity Assumption）**：[倾向得分](@article_id:640160)的逻辑要求，对于任何给定的特征集 $X$，被处理和不被处理的概率都必须非零。这被称为**正值**（positivity）或**共同支撑**（common support）假设。如果这个假设被违反——例如，如果所有拥有最肥沃土壤的农民都使用了新肥料，导致[对照组](@article_id:367721)中没有可比较的对象——该方法就会失效。在实践中，当[倾向得分](@article_id:640160)非常接近0或1时，我们可能会遇到麻烦。如果一个人的[倾向得分](@article_id:640160)为0.999但处于对照组，其IPW权重将变为 $1/(1-0.999)=1000$。这一个个体就可能使我们估计的方差爆炸，使其变得高度不稳定 [@problem_id:3148544]。

-   **确定性的幻觉（The Illusion of Certainty）**：一次[倾向得分](@article_id:640160)分析会得出一个单一的[处理效应](@article_id:640306)数值。但这个数字是一个估计值，它具有不确定性。这种不确定性不仅来自于最初的人群随机样本，也来自于估计和匹配过程本身。为了恰当地量化这一点，我们可以使用像**自助法**（bootstrap）这样的计算方法。通过对原始数据进行重复[重采样](@article_id:303023)，并重复运行*整个*过程——重新估计[倾向得分](@article_id:640160)模型、重新[匹配数](@article_id:337870)据、重新计算效应——数千次，我们可以生成一个可能效应的分布。这个分布使我们能够构建一个稳健的[置信区间](@article_id:302737)，反映我们不确定性的全部范围 [@problem_id:1959370]。

### 前沿一瞥：双重稳健性

故事并未就此结束。对处理过程（[倾向得分](@article_id:640160)）建模和对结果过程建模之间的[张力](@article_id:357470)，催生了更加精妙的统计机制。如果我们同时对两者进行建模会怎样？

1.  我们为[倾向得分](@article_id:640160) $e(X)$ 建立一个模型。
2.  我们为结果本身建立一个模型，根据协变量 $X$ 和处理 $T$ 预测 $Y$。

一种称为**增广[逆概率](@article_id:375172)加权**（Augmented Inverse Probability Weighted, AIPW）估计量的先进技术巧妙地结合了这两个模型。并且它拥有一个被称为**双重稳健性**（double robustness）的非凡特性。

如果*[倾向得分](@article_id:640160)模型设定正确*，*或者* *结果模型设定正确*，AIPW估计量就能给出因果效应的一致、无偏的估计。你不需要两者都正确！这给了研究人员两次机会来正确建模，为对抗[统计建模](@article_id:336163)不可避免的不确定性提供了一个优雅而强大的安全网 [@problem_id:3106777]。它是该领域独创性的证明，将两种不同的方法结合起来，创造出比任何单一方法都更强大、更可靠的东西。

