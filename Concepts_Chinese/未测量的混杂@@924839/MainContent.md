## 引言
许多科学研究的最终目标是超越纯粹的相关性，识别出真正的因果关系。在理想世界中，我们可以通过完美控制的实验来实现这一目标，确保各组之间唯一的区别就是我们正在研究的干预措施。然而，在许多领域，特别是在公共卫生、医学和社会科学中，研究人员必须处理观测数据，像侦探一样从充满复杂性的世界中拼凑出因果关系。这项工作中的最大挑战是混杂问题，即第三个变量在我们感兴趣的暴露和结局之间制造出一种误导性的关联。

本文探讨了这一挑战中一个尤其棘手的问题：未测量的混杂。当[混杂变量](@entry_id:199777)是我们未能测量，或者甚至不知道其存在时，会发生什么？这个“机器中的幽灵”可能导致有偏倚的结果和不正确的结论，无论我们的数据集有多大。本文将直面此问题。首先，在“原理与机制”部分，我们将探讨未测量混杂的统计学基础，解释为什么标准调整是不够的，以及为量化和对抗这种偏倚而发展出的方法背后的巧妙逻辑。然后，在“应用与跨学科联系”部分，我们将看到这些方法的实际应用，展示不同学科的研究人员如何利用它们来加强其因果主张，并在不确定性面前推动科学知识的进步。

## 原理与机制

在完美的世界里，科学家就像剧作家，控制着舞台上的每一个变量。要看一种新肥料是否能让植物长得更高，我们可以取两颗相同的种子，将它们种在相同的土壤里，给予完全相同的水和阳光，只改变肥料这一项。这就是**随机对照试验**的美妙之处：通过随机分配处理，我们确保平均而言，两组在*除了*我们正在研究的那一件事之外的所有方面都是相同的。我们看到的任何差异都可以自信地归因于我们的干预。

但我们并不总是有这种奢侈。我们常常必须像侦探一样，到达世界本来的样子，试图从观测数据中拼凑出因果关系。在这里，我们面临一个挥之不去的幽灵：**混杂因素**。混杂因素是一个隐藏的变量，一个第三方，它既影响我们所谓的“因”（暴露），也影响我们所谓的“果”（结局），从而制造出虚假的关联或掩盖了真实的关联。想象一下，我们观察到携带打火机的人更容易患上肺癌。不是打火机导致癌症；而是第三个因素——吸烟，导致人们既携带打火机又患上癌症。吸烟就是混杂因素。

在我们的研究中，我们努力测量并调整所有我们能想到的混杂因素——年龄、性别、已有的健康状况。但如果我们漏掉了一个呢？或者如果我们的测量不完美呢？这时，我们就遇到了**未测量的混杂**问题。

### 机器中的幽灵

调整混杂因素的目标是达到一种**条件可交换性**的状态。这是一个比较专业的说法，意思是，在任何一组在我们的已测协变量上相似的个体中（例如，60岁的非吸烟男性），碰巧接受暴露的组和没有接受暴露的组，在所有意图和目的上都是可以互换的。如果我们能交换他们，他们的结局不会系统性地改变。

当我们的调整不完整时，这种[可交换性](@entry_id:263314)就被打破了，我们就会面临**残余混杂**。这是一种系统性误差，一种偏倚，无论我们的数据集变得多大，它都依然存在。它通常以两种方式产生[@problem_id:4640818]。首先，我们对一个已知混杂因素的测量可能有缺陷。例如，调整自我报告的吸烟状况，与调整真实的吸烟状况是不同的，因为有些人可能会误报他们的习惯。这就像试图用一个模糊的镜头来对焦相机；你无法完全消除失真。其次，也是更令人烦恼的，可能存在我们根本没有测量的混杂因素——也许是由于成本、可行性，或者仅仅是缺乏远见。在一项关于空气污染和心脏病的研究中，像一个人的饮食或接触绿色空间的机会这样的因素，可能就是未测量的混杂因素，它们既影响一个人居住的地方（从而影响其污染暴露），也影响其心血管健康。这些未测量的因素就是我们统计机器中的幽灵。

### 虚假的平静：“平衡”数据的错觉

在观测研究中，一个常见的做法是检查“协变量平衡”。在调整我们的数据之后，我们创建表格，显示已测量的特征（年龄、性别等）现在在处理组和未处理组之间达到了完美的平衡。看到这种平衡，人们很容易松一口气，以为我们已经成功地模拟了一项随机实验。

这种宽慰往往是一种错觉。

在*已观测*变量上的完美平衡，完全不能告诉你任何关于*未观测*变量平衡的信息。让我们构建一个简单的、虚构的世界来看看为什么这一点如此具有毁灭性[@problem_id:4789001]。假设我们正在研究一种处理，其真实的因果效应恰好是$1$。也就是说，该处理使结局增加一个单位，不多也不少。然而，存在一个未测量的混杂因素，我们称之为$U$，它使人们更有可能接受该处理，并且也独立地增加了他们的结局分数。

一位分析师，对$U$一无所知，细致地收集了关于一个已观测协变量$X$的数据。使用复杂的统计方法，他们在处理组和[对照组](@entry_id:188599)之间实现了$X$的完美平衡。$X$在两组中的分布是完全相同的。所有标准的诊断性检查都会顺利通过。这位分析师会得到什么结果呢？在这个特定的、构建的世界中，他们会计算出[处理效应](@entry_id:636010)为$\frac{49}{34}$，约等于$1.44$。他们的估计值向上偏倚了$44\%$，这是一个显著的误差。已观测数据上的完美平衡提供了一种虚假的安全感，完全掩盖了潜伏在表面之下的未测量混杂因素所带来的偏倚。

这引导我们进入统计学中一个深刻而令人不安的概念：**可识别性**[@problem_id:4936338]。如果一个参数原则上可以从无限多的数据中确定其真实值，那么它就是可识别的。我们在数据中观察到的关联性差异是可识别的——随着样本量的增加，我们可以越来越精确地测量它。但*因果*效应不是。正如我们所见，可以构建多个不同的“真实”潜在现实，每个现实都有不同的因果效应，但它们都产生完全相同的可观测数据。如果不做出[超越数](@entry_id:154911)据本身的进一步假设，我们就无法区分这些可能性。仅凭数据本身无法完全确定因果真相。

### 与阴影搏斗

如果未测量的混杂是一个看不见的幽灵，我们怎么可能与它斗争呢？我们看不见它，测不到它，它还能骗过我们标准的诊断工具。虽然我们可能永远无法完全驱逐这个幽灵，但我们已经发展出非常巧妙的方法来应对它的影响。

#### 量化疑虑：敏感性分析

第一步是从模糊的担忧转向定量的评估。这就是**[敏感性分析](@entry_id:147555)**的目标。指导性问题是：“假设存在一个混杂因素，它需要多强才能改变我的结论？”

一种形式化的方法是**定量偏倚分析（Quantitative Bias Analysis, QBA）**[@problem_id:4624445]。我们可以想象，我们观察到的关联，例如一个风险比（$RR_{\text{obs}}$），并不是真实的因果效应（$RR_{\text{true}}$），而是真实效应与一个偏倚因子（$BF$）的乘积：
$$
RR_{\text{obs}} = RR_{\text{true}} \times BF
$$
这个偏倚因子取决于未测量混杂因素的属性：它与结局的关联（$RR_{UY}$）以及它在暴露组（$p_1$）和非暴露组（$p_0$）之间的患病率差异。虽然我们不知道这些值，但我们可以代入一些合理的数字，看看偏倚因子可能有多大。例如，如果我们观察到的风险比为$1.8$，但怀疑一个混杂因素使结局风险加倍（$RR_{UY} = 2.5$），并且在暴露组中常见一倍（例如，$p_1=0.4$ vs $p_0=0.2$），那么偏倚因子将约为$1.23$。校正后的，或真实的，风险比则为$\frac{1.8}{1.23} \approx 1.46$。效应仍然存在，但显著减小了。

这类分析可能很复杂，但有一个非常简单的汇总指标叫做**[E值](@entry_id:177316)**[@problem_id:4364904]。E值回答了一个简单的问题：“一个未测量的混杂因素，需要与暴露和结局都存在多强（以风险比为尺度）的关联，才能完全解释掉观测到的效应？”

例如，如果一项研究发现一种新药降低了中风的风险，观测到的风险比为$0.70$，计算出的[E值](@entry_id:177316)为$2.21$。这给了我们一个具体的陈述：“要将这一整个保护效应归因于一个未测量的混杂因素（比如‘基线虚弱程度’），那么这个混杂因素需要与服用新药和发生中风都存在至少为$2.21$的风险比关联，即便在我们已经调整了其他所有因素之后。”这是一个很高的门槛。如此量级的混杂因素将是一个强大的因子，我们可能会争辩说，这样一个强的混杂因素不太可能被遗漏。一个大的[E值](@entry_id:177316)让我们更有信心我们的结果是稳健的；一个小的[E值](@entry_id:177316)则告诉我们，我们的发现是脆弱的，很可能仅仅是由于中等程度的混杂造成的。

#### 幼稚“修复”的危险：偏倚放大

如果我们找到了一个变量，它不是未测量的混杂因素本身，但可以作为它的一个不错的代理变量呢？例如，如果“虚弱程度”是我们未测量的混杂因素，也许像“过去一年看医生的次数”这样的变量可以作为代理。一种诱人但极其危险的冲动是简单地将这个代理变量加入我们的[统计模型](@entry_id:755400)，希望“吸收”掉一些混杂。

在一个说明因果关系微妙之处的惊人转折中，这有时会使情况变得*更糟*。这种现象被称为**偏倚放大**[@problem_id:4640676]。它发生在一种特定但常见的[因果结构](@entry_id:159914)下。假设我们的代理变量受到我们正在研究的暴露*和*未测量的混杂因素的*双重*影响。例如，也许接受新疗法（$A$）会导致副作用，从而导致更多的医生就诊（$Z$），而基线虚弱程度（$U$）也独立地导致更多的医生就诊。在这种情况下，代理变量$Z$是一个**对撞因子**——一个有两支箭头指向它的变量（$A \rightarrow Z \leftarrow U$）。

当我们调整一个对撞因子时，我们会在它的原因之间制造出一种虚假的[统计关联](@entry_id:172897)。这就像看到一个明星四分卫和一个明星物理学家都在和名人约会。如果你只看正在和名人约会的人群（即你“调整”了名人约会状态），运动才能和学术天赋可能会突然显得负相关，因为其中一个解释了“为什么”他们在你选择的群体中，从而使得另一个可能性降低。通过调整我们的代理变量$Z$，我们可能无意中在处理$A$和未测量的混杂因素$U$之间创造了一个新的人为关联通道，从而加强了整体混杂，并增加了我们效应估计中的偏倚。在这种情况下，治疗比疾病更糟糕。

#### 聪明的侦探：阴性对照的逻辑

一种更优雅的探测混杂的方法是使用**阴性对照**[@problem_id:4804274]。其逻辑简单而优美，就像一个精心设计的实验。我们不试图去测量无法测量的东西，而是去检验一个我们有充分理由相信应该为零的关联。如果我们发现一个非零的关联，这就是一个“阳性”结果，表明存在混杂结构。

主要有两种类型：
1.  **阴性对照结局：**我们选择一个暴露不可能导致的结局。例如，如果我们正在研究一种新的[他汀类药物](@entry_id:167025)对心脏病发作的影响，我们可以测试它与意外伤害的关联。没有合理的生物学理由表明他汀类药物会影响伤害率。如果我们发现一个[统计关联](@entry_id:172897)，它不可能是因果的。它必定是由于混杂——也许更健康、更谨慎的人更可能服用他汀类药物，也更不容易受伤。发现这种关联，让我们对心脏病发作的主要发现的有效性产生怀疑，因为同样的混杂机制很可能也在起作用。

2.  **阴性对照暴露：**我们选择一个不可能导致我们感兴趣的结局的暴露，但它可能受到同样的混杂影响。例如，在研究抗抑郁药对骨折的影响时，人们可能会担心抑郁症患者的生活方式会独立增加骨折风险。作为阴性对照，可以研究抗焦虑药物（也用于治疗精神健康问题，但对骨骼没有已知影响）与骨折之间的关联。如果抗焦虑药物也似乎“导致”骨折，这表明这种关联并非药理学上的，而是由于患者潜在健康状况的混杂所致。

发现这些“不可能的”关联并不能修复偏倚，但它起到了一个至关重要的警报作用，警告我们机器中的幽灵是活跃的，我们应该以极大的谨慎来解释我们的主要结果。

### 揭开面纱：用于识别的高级策略

几十年来，未测量的混杂似乎是一个不可逾越的障碍。然而，近年来，因果推断的先驱们已经发展出非凡的方法，这些方法在非常具体和强有力的假设下，能够穿透混杂的面纱，识别出真正的因果效应。

其中一种方法是**[工具变量](@entry_id:142324)（IV）分析**[@problem_id:4612664]。其思想是找到一个变量——[工具变量](@entry_id:142324)——它像一个自然的随机分配器。一个[工具变量](@entry_id:142324)必须满足三个严格的条件：它必须是相关的（它影响暴露），它必须满足排他性限制（它*只*通过暴露影响结局），并且它必须独立于未测量的混杂因素。一个经典的例子是使用医生的处方偏好作为工具变量。一些医生更喜欢开新药，而另一些则坚持用旧药。这种偏好影响了病人得到哪种药物，但（人们可能认为）它与病人自身的健康状况无关，并且对他们的结局没有直接影响。通过使用这种“仿佛随机”的分配，我们可以分离出药物的因果效应，而不受患者层面混杂因素的污染。

另一个优美但更为奇特的方法是**[前门准则](@entry_id:636516)**[@problem_id:4845612]。这适用于当暴露对结局的影响完全通过一个单一、完美测量的变量进行中介的情况。在这种情况下，即使存在一个直接影响暴露和结局的未测量混杂因素，我们仍然可以通过分别分析旅程的两段来识别因果效应：暴露对中介变量的影响，以及中介变量对结局的影响。

这些方法不是万能药。它们的假设很强，且常常无法检验。但它们代表了逻辑和因果推理的胜利，表明只要有足够的创造力，我们有时甚至可以从世界给我们的凌乱、不完美的数据中学习到因果关系。

### 知识问题

最终，未测量混杂的挑战迫使我们更深入地思考不确定性本身的性质[@problem_id:5174225]。在科学中，我们处理两种类型的不确定性。第一种是**任意不确定性**，即世界固有的随机性，就像掷骰子一样。这是统计方法旨在处理的不确定性。通过更大的样本量，我们可以减少这种不确定性并获得更精确的估计；我们的[置信区间](@entry_id:138194)会变窄。

第二种是**认知不确定性**，它源于对世界真实状态——在我们的案例中，是真实的[因果结构](@entry_id:159914)——的知识缺乏。未测量的混杂是认知不确定性的一个来源。它引起的偏倚是一种系统性误差。增加样本量无济于事；它只会给我们一个对错误答案的越来越精确的估计。

这是一个令人谦卑的教训。它提醒我们，数据本身不会说话。它们是通过一个模型——我们对世界如何运作的一套假设——的镜头来解释的。当我们的模型因为我们看不见的因素而错误时，我们的结论就可能是有缺陷的。因此，与未测量混杂的斗争不仅仅是一个统计练习；它是科学事业的一个基本组成部分，旨在建立更好的现实模型，诚实地面对我们知识的局限，并利用我们掌握的每一种工具来更接近真相。

