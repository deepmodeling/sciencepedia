## 引言
现代科学越来越依赖复杂的[计算模拟](@entry_id:146373)器来模拟从[星系形成](@entry_id:160121)到细胞过程的一切。这些“正向模型”可以根据一组给定的参数生成合成数据，但是当我们试图逆转这个过程时，一个根本性的挑战就出现了：从观测数据中推断出潜在的参数。这个[逆问题](@entry_id:143129)常常被“难以处理之墙”所阻挡——对于许多模拟器而言，作为经典贝叶斯推断基石的似然函数是无法计算的。本文通过引入[无似然推断](@entry_id:190479)这一[范式](@entry_id:161181)来解决这一关键的知识空白。接下来的章节将探讨[近似贝叶斯计算](@entry_id:746494)和[似然比估计](@entry_id:751279)等方法如何巧妙地规避了对显式似然的需求，审视如何验证这些方法，并展示这些强大的技术如何在不同领域彻底改变科学发现。

## 原理与机制

为了真正领会[无似然推断](@entry_id:190479)的力量与精妙之处，我们必须踏上一段旅程。这段旅程始于一道看似不可逾越的高墙，找到一种巧妙的方法绕过它，并最终在统计推断和机器学习之间建立起深刻的联系。在此过程中，我们必须开发工具以确保我们没有迷失方向，并直面一个令人谦卑的现实：我们对世界的科学描绘在某种意义上永远是近似的。

### 黑箱与难以处理之墙

现代科学的核心是模拟器。无论我们是模拟星系的形成、大型强子对撞机中粒子的碰撞、疾病的传播，还是物种的进化，我们通常都有一个计算过程，它体现了我们对世界的最佳理解[@problem_id:3536602]。我们可以向这个模拟器输入一组参数 $\theta$——我们模型宇宙的[基本常数](@entry_id:148774)——它就会产生合成数据 $x$，看起来就像我们在现实中可能观察到的一样。模拟器作为一个生成模型：给定 $\theta$，我们可以得到样本 $x \sim p(x | \theta)$。

推断的目标是逆转这个过程。我们观察到了一个单一、珍贵的真实世界数据点 $x_{obs}$，并且我们想知道哪些参数 $\theta$ 最有可能产生它。经典的方法是通过[贝叶斯法则](@entry_id:275170)：

$$
p(\theta | x_{obs}) \propto p(x_{obs} | \theta) p(\theta)
$$

项 $p(x_{obs} | \theta)$ 是**似然**——在给定一组特定参数的情况下，观察到我们特定数据的概率。在这里，我们撞上了一堵墙。对于大多数复杂的模拟器，这个[似然函数](@entry_id:141927)是**难以处理的**。我们可以正向运行模拟，但我们无法写出一个简洁的数学公式来表示特定输出的概率。

为什么会这样呢？想象一下，模拟器接收我们的参数 $\theta$ 和一个巨大的内部随机数向量 $u$（代表[量子涨落](@entry_id:154889)、随机[初始条件](@entry_id:152863)等），并计算出一个输出 $x = g(\theta, u)$ [@problem_id:3489611]。通常，随机输入 $u$ 的空间远大于输出 $x$ 的空间。这就像将一个丰富的高维物体投影到一个低维屏幕上。它投下的“影子”——可能输出的[分布](@entry_id:182848)——可能是一个极其错综复杂的丝状结构。在这个低维空间中，落在任何单个点 $x_{obs}$ 上的概率在数学上可能为零，尽管其*附近*的点是可能的。在这种情况下，依赖于关于某个标准测度的[拉东-尼科迪姆导数](@entry_id:158399)存在的似然密度函数，根本就不存在 [@problem_id:3489611]。我们有一个可以操作但其内部数学运作过于复杂以至于无法写在纸上的黑箱。我们陷入了困境。

### “足够接近”的艺术：[近似贝叶斯计算](@entry_id:746494)

当我们无法精确时，我们该如何推理？我们进行近似。这是第一类无[似然](@entry_id:167119)方法背后美丽而简单的思想：**[近似贝叶斯计算](@entry_id:746494)（ABC）**。如果我们无法计算模拟出我们*确切*数据的概率，那我们问一个稍微不同的问题：“哪些参数能产生与我们观察到的数据*相似*的数据？”[@problem_id:2521316]。

ABC最基本的形式是一种简单的拒绝算法，几乎就像常识一样：

1.  从[先验分布](@entry_id:141376) $p(\theta)$ 中选择一个候选参数值 $\theta^*$。
2.  用这个 $\theta^*$ 运行你的模拟器，生成一个合成数据集 $x_{sim}$。
3.  将模拟数据 $x_{sim}$ 与你的真实观测数据 $x_{obs}$进行比较。如果它们“足够接近”，你就保留 $\theta^*$。否则，你就扔掉它。
4.  重复这个过程数百万次。你保留下来的参数集合构成了你期望的后验分布 $p(\theta | x_{obs})$ 的一个近似。

这非常直观。但它隐藏了两个关键问题：“足够接近”是什么意思？以及我们如何比较复杂的[高维数据](@entry_id:138874)，比如来自[对撞机](@entry_id:192770)事件的粒子的完整[四动量](@entry_id:264378)[@problem_id:3536609]或一个种群的完整DNA序列[@problem_id:2521316]？

比较原始的[高维数据](@entry_id:138874)通常是不可能的（维度灾难）。取而代之的是，我们比较少数几个**摘要统计量** $s(x)$，它们是数据的低维表示。例如，在研究像[伊辛模型](@entry_id:139066)这样的物理系统时，我们可能不会比较两个完整的 $20 \times 20$ 的原子自旋网格，而只是比较它们的总磁化强度和平均邻居[相互作用能](@entry_id:264333)[@problem_id:3288800]。然后，如果我们的真实数据的摘要与模拟数据的摘要之间的距离小于某个小容差 $\epsilon$，我们就接受 $\theta^*$：

$$
\rho(s(x_{sim}), s(x_{obs})) \le \epsilon
$$

ABC的“近似”性质就在于此。我们面临两个误差来源。首先，如果我们的摘要统计量不是**充分的**——意味着它们没有捕捉到原始数据中关于 $\theta$ 的所有信息——我们就会丢失信息。这会损害我们参数的**可识别性**，使得难以区分那些本可以使用完整数据分开的不同 $\theta$ 值[@problem_id:3536609] [@problem_id:2521316]。其次，我们对容差 $\epsilon$ 的选择很重要。一个微小的 $\epsilon$ 会得到很好的近似，但可能需要天文数字般的模拟次数才能获得任何被接受的样本。一个大的 $\epsilon$ 速度快，但会得到一个粗糙、有偏的近似。ABC的艺术在于驾驭这种权衡。

### 从似然到分类器：一种现代炼金术

ABC很直观，但它对摘要统计量的依赖及其通常较低的接受率促使科学家寻求更有效的方法。这导致了一个惊人而富有创造性的见解：我们可以将推断问题转化为[分类问题](@entry_id:637153)。

想象一下，我们和一个机器学习算法（比如一个[神经网](@entry_id:276355)络）玩一个游戏。我们将创建两种类型的 $(\theta, x)$ 对，并要求分类器将它们区分开来[@problem_id:3489622]。

*   **类别1（真实对）：** 我们从先验 $p(\theta)$ 中抽取一个参数 $\theta$，然后运行我们的模拟器以得到一个相应的数据点 $x \sim p(x|\theta)$。这对是“一致的”；数据是由该参数真实产生的。其[分布](@entry_id:182848)是联合分布，$p(x, \theta) = p(x|\theta)p(\theta)$。

*   **类别0（混合对）：** 我们从先验 $p(\theta)$ 中抽取一个参数 $\theta$，并独立地从数据的[边际分布](@entry_id:264862) $p(x)$ 中抽取一个数据点 $x$。（在实践中，我们可以通过获取“真实对”并将 $x$ 和 $\theta$ 打乱来得到这些）。这对是“不一致的”。其[分布](@entry_id:182848)是[边际分布](@entry_id:264862)的乘积，$p(x)p(\theta)$。

我们在这个游戏上训练分类器。它必须学习什么才能成功？它必须学习对于给定的参数 $\theta$，哪些数据 $x$ 看起来是合理的。通过这样做，它含蓄地学习了关于似然的信息。其数学原理是优美的：一个完美训练的分类器 $q(y=1|x, \theta)$ 的输出与推断的圣杯——[似然比](@entry_id:170863)——直接相关[@problem_id:3489622] [@problem_id:3536670]。更具体地说，对于[似然](@entry_id:167119)与证据的比值 $r(x, \theta) = p(x|\theta)/p(x)$，最优分类器学习到：

$$
q(y=1|x, \theta) = \frac{r(x, \theta)}{1 + r(x, \theta)}
$$

我们可以简单地重新[排列](@entry_id:136432)这个方程来求解[似然](@entry_id:167119)-证据比，这正是我们应用[贝叶斯法则](@entry_id:275170)并找到后验分布所需要的！这是一种现代炼金术：我们将[分类任务](@entry_id:635433)这个贱金属变成了贝叶斯后验这个黄金。这类方法，通常被称为**[似然比估计](@entry_id:751279)（LRE）**，利用了[现代机器学习](@entry_id:637169)的全部力量，通常直接在[高维数据](@entry_id:138874)上工作而无需手工挑选的摘要统计量，并且模拟效率极高。

### 检验我们的仪器：在没有真实基准的世界中进行校准

ABC和LRE都很强大，但它们也是复杂的机器，有许多活动部件——近似、[神经网络架构](@entry_id:637524)、统计量的选择。我们如何能确定我们最终的后验分布是可信的？我们无法将其与“真实”的后验进行比较，因为那正是我们一开始就试图避免的难以处理的对象。

解决方案是一个优美而简洁的[自洽性](@entry_id:160889)检查，称为**基于模拟的校准（SBC）** [@problem_id:3536623]。其理念是：如果我们的推断机器工作正常，那么从长远来看，它在统计上应该是“公平的”。它产生的一个答案是高估的可能性不应大于低估的可能性。

该过程如下：
1.  假装你是大自然。从你的先验 $p(\theta)$ 中抽取一个“真实基准”参数 $\theta_{true}$。
2.  在你的模拟器中使用这个 $\theta_{true}$ 来生成一个“伪”观测数据集，$x_{fake} \sim p(x|\theta_{true})$。
3.  现在，再次戴上你科学家的帽子。取 $x_{fake}$ 并将其输入到你的LFI（[无似然推断](@entry_id:190479)）机制中，以计算一个近似的后验 $p_{approx}(\theta | x_{fake})$。
4.  最后，检查你已知的“真实基准” $\theta_{true}$ 在你刚刚为它计算的后验分布中的位置。例如，你可以计算它在来自后验的一千个样本中的排位。

如果你多次重复这整个过程，并且你的推断机器是良好校准的，那么这些排位的[分布](@entry_id:182848)应该是完全均匀的。真实参数应该有10%的时间位于其自身后验的底部10%区间内，10%的时间位于其后验的顶部10%区间内，依此类推。如果你看到排位在某一端堆积，或者呈U形[分布](@entry_id:182848)，这是一个[危险信号](@entry_id:195376)：你的机器存在系统性偏差，产生的[后验分布](@entry_id:145605)过窄、过宽或发生了偏移[@problem_id:3536602]。SBC是一个不可或缺的诊断工具，它让我们能够在一个没有标准答案的世界里建立对我们结果的信任。

### 当地图不是领土时：设定错误问题

我们必须面对最后一个令人谦卑的真相。到目前为止，我们所有的讨论都假设我们的模拟器，即我们对世界的模型，是根本正确的。我们假设存在某个“真实”参数 $\theta_{true}$，当它被代入我们的模拟器时，能够完美地再现真实世界的统计特性。

但如果这不是真的呢？如果现实的数据生成过程 $p^*(x)$ 根本不属于我们的模拟器可以产生的[分布](@entry_id:182848)族 $\{p(x|\theta)\}$ 呢？这就是**[模型设定错误](@entry_id:170325)**的问题。

在这种情况下，[无似然推断](@entry_id:190479)（实际上，任何基于模型的推断）并不会束手无策而失败。相反，它会做它能做的最合理的事情：找到使模拟器的输出尽可能接近真实世界输出的参数值。它收敛到的参数集被称为**伪真参数** $\theta^{\dagger}$。它是最小化从真实[分布](@entry_id:182848)到模型族的库尔贝克-莱布勒（KL）散度的参数——这是衡量两个[分布](@entry_id:182848)之间“距离”的一种度量[@problem_id:3489671]。

$$
\theta^{\dagger} \equiv \arg\min_{\theta} \mathrm{KL}(p^{\ast}(x) \, \Vert \, p(x | \theta))
$$

这是一个深刻而关键的观点。我们的推断的好坏取决于我们的模型。当我们的模型是现实的简化时——正如所有模型都是一样——LFI会找到现实到我们简化地图上的最佳投影。它为我们有缺陷的模型提供了最有用的参数，但它无法修复模型本身的缺陷。无[似然](@entry_id:167119)方法为我们提供了前所未有的能力，将复杂的模拟与数据联系起来，但它们也提醒我们，科学的最终目标不仅仅是推断参数，而是不断挑战和改进模型本身。

