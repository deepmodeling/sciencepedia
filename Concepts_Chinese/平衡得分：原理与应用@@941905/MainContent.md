## 引言
当我们无法进行完美的实验时，如何确定一种新药是否真正能拯救生命，或一项公共政策是否有效？这个问题是因果推断的核心。虽然随机对照试验（RCT）是金标准，但其应用常常受到伦理、实践或财务上的限制。这使得研究人员只能依赖大量的观察性数据，这些数据信息丰富，但充满了严峻的挑战：混杂。在现实世界中比较不同组别时，预先存在的差异，而非处理本身，可能会扭曲我们的发现。本文通过介绍一种强大的统计工具——平衡得分，来正面解决这个问题。**原理与机制**部分揭开了因果推断核心概念的神秘面纱，解释了混杂问题，并介绍了倾向性得分——一种从不公平的数据中创造公平比较的绝妙方法。在这一理论基础之上，**应用与跨学科联系**部分展示了这一优雅思想如何被应用于解决从医学、药理学到公共卫生等领域的复杂问题，揭示了其多功能性和影响力。

## 原理与机制

### 看不见的反事实：因果探索的核心

想象一下，你是一名医生，面对一位患有严重疾病的病人。你可以开一种新的强效药物，或者继续使用标准疗法。你选择了新药，谢天谢地，病人康复了。但你心中留下了一个令人遐想的问题：如果当初选择了标准疗法，会发生什么？病人是否同样会康复？会康复得更慢吗？还是根本不会康复？

这种“如果……会怎样”的情景，就是我们所说的**反事实**（counterfactual）。它是看不见的、无法观测的，并且永远无法触及。对于任何个体，我们只能观察到一个现实——我们所做选择的结果。我们永远无法同时看到我们*未曾*做出的选择所带来的结果。这就是**因果推断的基本问题**（fundamental problem of causal inference）[@problem_id:4599527]。我们想要将现实世界与一个可能存在但未发生的世界进行比较，但我们只能窥见其中之一。那么，我们究竟如何才能了解处理与结局之间真正的因果关系呢？

### 科学家的梦想：随机化的力量

解决这个难题的经典方案，也是科学证据的金标准，就是**随机对照试验**（randomized controlled trial, RCT）。在RCT中，我们选取一大群符合条件的患者，通过抛硬币（或其复杂的计算机等效方法），将他们随机分配到接受新药或标准疗法的组中。

为什么这种方法如此强大？因为随机化是一个伟大的均衡器。只要样本量足够大，它能确保在治疗开始前，处理组和[对照组](@entry_id:188599)这两组在平均意义上，在所有可以想象的方面都几乎是相同的。他们的年龄、疾病严重程度、遗传倾向、生活习惯，甚至是我们尚未想到去测量的因素，其分布都将相似。这两个组在统计意义上是**可交换的**（exchangeable）。由于它们之间唯一的系统性差异就是所接受的处理，因此它们结局上的任何差异都可以被确信地归因于处理本身。随机化使得[对照组](@entry_id:188599)可以作为处理组反事实的可靠替代。

### 混乱的现实世界：观察性数据中的混杂

但是，RCT并非总是可行。它们可能成本高昂、耗时漫长，或在伦理上存在问题。因此，我们常常必须转向**观察性数据**——那些从电子健康记录、患者登记库或公共卫生调查等现实世界中收集的海量信息[@problem_id:4362663]。在这里，没有随机化。医生根据他们的临床判断做决定；患者根据自身情况做选择。

这时，事情就变得复杂了。在一项关于新型心脏药物的[观察性研究](@entry_id:174507)中，病情较重的患者可能更有可能接受这种新的、更具进攻性的治疗，而较健康的患者则坚持使用标准疗法。如果我们天真地比较这两组的结局，我们可能会错误地得出结论，认为新药有害，而这仅仅是因为接受新药的群体一开始病情就更重。这种一个变量（疾病严重程度）同时与处理和结局纠缠在一起的现象，被称为**混杂**（confounding）。我们这种天真的比较被这种**选择偏倚**（selection bias）严重地带偏了。这两个组不再是可交换的。

### 必要的一步：无混杂性假设

为了取得任何进展，我们必须做出一个大胆且根本上无法检验的假设。我们必须假设我们已经成功识别并测量了*所有*重要的[混杂变量](@entry_id:199777) $X$——即所有同时影响处理决策和结局的因素的完整集合。这可能包括患者的年龄、合并症、基因组标记等等[@problem_id:4599459]。

如果我们拥有这套完整的混杂因素，我们就可以提出**条件可交换性**（conditional exchangeability）的假设，该假设也被称为**无混杂性**（unconfoundedness）或**强可忽略性**（strong ignorability）[@problem_id:4599459] [@problem_id:4541636]。它指出，在共享所有混杂因素 $X$ 相同值的任何特定患者亚组内部（例如，65岁、不吸烟、具有特定合并症评分的女性），处理的选择实际上是随机的。在这些细粒度的分层中，处理分配机制“如同随机化”一般[@problem_id:4599459]。这个假设是我们试图通过计算来重现随机化免费提供的平衡性。这是一个巨大的信念飞跃，而且至关重要的是，要记住没有任何统计方法（包括倾向性得分）能够校正未被测量的混杂因素[@problem_id:4150010]。

### 天才之举：倾向性得分

所以，我们已经测量了所有的混杂因素。现在该怎么办？如果我们只有少数几个混杂因素，比如年龄和性别，我们可以简单地对数据进行分层。我们可以比较60多岁的处理组男性和非处理组男性，70多岁的处理组女性和非处理组女性，以此类推。但如果我们有几十个甚至几百个混杂因素，就像在拥有转录组谱的现代医学数据中那样常见，该怎么办[@problem_id:4599527]？“[维度灾难](@entry_id:143920)”降临了：随着我们创建越来越具体的亚组，每个亚组中的人数会锐减至零。我们可能无法找到一个65岁、不吸烟、具有特定基因谱和Charlson合并症指数为3的女性，来与她接受治疗的对应者匹配，因为这样的人可能在我们的数据集中根本不存在。

这时，统计学家 Paul Rosenbaum 和 Donald Rubin 的一个绝妙见解应运而生。他们问道：我们能否将来自混杂因素 $X$ 的所有高维信息压缩成一个单一的数字？他们提出了**倾向性得分**（propensity score）。倾向性得分 $e(X)$ 的定义看似简单，实则巧妙：它是一个具有给定特征集 $X$ 的人接受处理的[条件概率](@entry_id:151013)[@problem_id:4150010]。
$$
e(X) = \Pr(T=1 \mid X)
$$
重要的是不要将其与*预后得分*（prognostic score）混淆，后者是基于协变量 $X$ 预测临床*结局*（$Y$）的模型[@problem_id:4830483]。倾向性得分完全关乎*处理分配*（$T$）。它回答的问题是：“对于这样一个的人，他们有多大可能性会得到新药？”

### 平衡的魔力

这就是倾向性得分的“魔术”。Rosenbaum 和 Rubin 证明了它是一种**平衡得分**（balancing score）。这意味着，如果你取任意两个拥有*完全相同倾向性得分*的个体，一个接受了处理，一个未接受处理，那么在平均意义上，用于计算该得分的所有协变量 $X$ 的分布在他们之间将是相同的[@problem_id:4830483]。

想一想这意味着什么。一个倾向性得分很高（比如 $0.9$）的患者，其特征使他们极有可能接受治疗。一个得分很低（比如 $0.1$）的患者，则极不可能接受治疗。如果我们找到一个接受治疗的人和一个未接受治疗的人，他们的倾向性得分都是（比如说）$0.7$，我们就找到了两个对于他们而言，治疗决策可能性相等的人。$X$ 中所有促使医生倾向于治疗的因素星座，都在他们之间达到了平衡。倾向性得分，这个单一的数字，就像一个统计指纹，让我们能从混乱的观察性数据中找到一个合适的反事实比较对象。它优雅地解决了维度灾难，因为它表明，如果在给定所有 $X$ 的条件下无混杂性成立，那么在仅给定一维倾向性得分 $e(X)$ 的条件下，无混杂性也同样成立[@problem_id:4599459]。

### 将得分付诸实践：匹配、加权与分层

一旦我们为研究中的每个个体估算出了倾向性得分，我们就可以用几种方式来使用它，以估计处理的因果效应[@problem_id:5051579] [@problem_id:4542298]。

*   **匹配（Matching）：** 这是最直观的方法。对于每个接受治疗的个体，我们找到一个或多个倾向性得分非常相似的未接受治疗的个体。这样就创建了一个新的、更小的数据集，其中匹配对的观察协变量得到了很好的平衡，非常像一个随机试验。然后，我们只需比较这个匹配样本中处理组成员和非处理组成员的结局。这种方法通常估计的是**处理组平均[处理效应](@entry_id:636010)（ATT）**，即对于那些实际接受了治疗的人群类型所产生的效应[@problem_id:4542298]。

*   **分层（Stratification）或亚组分析（Subclassification）：** 一种稍显粗略但通常很稳健的方法。我们根据倾向性得分将人群切分成几个层次（例如，五个组，即五[分位数](@entry_id:178417)）。在每个层次内，个体的倾向性得分大致相似，因此协变量也近似平衡。我们在每个层次内计算处理效应，然后计算所有层次的加权平均值。

*   **逆概率处理加权（Inverse Probability of Treatment Weighting, IPTW）：** 这是一个更强大但不那么直观的思想。它通过统计加权来创建一个“伪人群”（pseudo-population）。想象一个接受了治疗但倾向性得分非常低（$e(X)=0.1$）的人，这意味着他本不太可能得到治疗。这个人很稀有，提供了宝贵的信息。在IPTW中，我们给他一个很大的权重（与 $1/0.1 = 10$ 成正比）。相反，一个接受了治疗且很可能得到治疗（$e(X)=0.9$）的人则不足为奇；他得到的权重很小（与 $1/0.9 \approx 1.1$ 成正比）。通过给每个个体赋予其接受实际所受处理的概率的倒数作为权重，我们创建了一个合成样本，其中协变量不再与处理相关联。这打破了混杂，从而可以直接比较加权平均结局，以估计整个人群中的**平均[处理效应](@entry_id:636010)（ATE）**[@problem_id:4542298] [@problem_id:5051579]。

### 补充说明：基本规则与现实陷阱

倾向性得分的力量并非绝对。它关键性地依赖于另外几个条件。

首先是**正性**（positivity）假设，也称为**共同支撑**（common support）假设[@problem_id:4599459] [@problem_id:4610007]。这意味着对于任何一组协变量 $X$，被处理和不被处理的概率都必须非零。如果某一类型的患者（例如，病情最重的患者）*总是*接受新药，他们的倾向性得分就是1。我们没有特征相似的未处理个体可以与之比较。对于这个群体，不存在“共同支撑”。当这种情况发生时，匹配变得不可能，而在IPTW中，权重（$1/e(X)$ 或 $1/(1-e(X))$）会趋向无穷大，导致估计值极不稳定[@problem_id:4830511]。在实践中，我们常常面临“近似违规”，即倾向性得分非常接近0或1。一个常见的解决方案是**修剪**（trim）样本，将我们的分析限制在倾向性得分有良好重叠的人群子集上。这使我们的估计更可靠，但代价是牺牲了**可移植性**（transportability）；我们现在估计的是一个更有限的“重叠人群”中的效应，而不是整个原始队列[@problem_id:4541636] [@problem_id:4362663]。

其次是**稳定单元处理值假设（SUTVA）**。这个拗口的术语意味着两个简单的事情：无干扰（一个人的处理不影响他人的结局）和一致性（处理是明确定义的，并且对每个人都相同）[@problem_id:4599527]。例如，如果一个诊所的患者共享同一位社工，为一名患者提供的强化护理计划可能会“溢出”并使其他人受益，这就违反了无干扰假设[@problem_id:4362663]。

最后，倾向性得分必须被正确估计。如果我们的倾向性得分模型被**错误设定**（misspecified）——例如，当真实关系高度复杂时，我们却使用了一个简单的[线性模型](@entry_id:178302)——我们估计出的得分将无法恰当地平衡协变量，留下残余的混杂[@problem_id:4830511]。这促使研究人员使用更灵活的机器学习方法来估计倾向性得分。然而，这些强大的方法有时在预测上可能*过于*出色，导致许多倾向性得分非常接近0或1，这又带回了正性违规的实际问题[@problem_id:4830511]。这揭示了因果推断中一个深刻而有趣的权衡：在控制混杂和维持一个可以进行比较的人群之间的张力。

