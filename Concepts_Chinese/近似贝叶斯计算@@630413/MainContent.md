## 引言
在理解世界的探索中，贝叶斯推断是一块基石，它允许科学家根据新数据更新他们对模型参数的信念。这一过程的核心在于似然函数——一个量化在给定一组特定模型参数的情况下，我们观测到的数据有多大概率出现的数学表达式。对于简单的系统，这个函数很容易定义。然而，当我们的模型为了反映自然的真实复杂性而变得越来越复杂时，从一个物种的遗传历史到宇宙的演化，[似然函数](@entry_id:141927)常常变成一个数学怪物，复杂到无法计算。这种“似然的暴政”构成了一个巨大的障碍，似乎使得许多最有趣的科学问题无法进行[贝叶斯分析](@entry_id:271788)。

那么，当贝叶斯定理的核心组成部分我们无法掌握时，我们如何进行推断呢？本文将介绍近似贝叶斯计算（ABC），一类优雅地回避了这一问题的革命性方法。ABC代表了一种哲学上的转变：如果你无法解析地计算出你的数据的概率，但你可以模拟产生数据的过程，那么你仍然可以进行推断。这是一种强大的、基于模拟的方法，开辟了新的发现前沿。

本文将引导您进入[无似然推断](@entry_id:190479)的世界。在第一章“原理与机制”中，我们将剖析ABC的核心逻辑，探索它如何通过巧妙的近似，将一个难以处理的数学问题转变为一个可通过计算解决的挑战。随后的“应用与跨学科联系”一章将带您游览各个科学学科，展示ABC如何被用作一个强大的透镜，以重构过去并理解当今的复杂系统。

## 原理与机制

### 似然的暴政

科学家的目标常常是扮演侦探的角色。我们手头有数据——即“线索”——以及一系列嫌疑对象，也就是我们的科学模型可能产生这些线索的不同方式。在贝叶斯推断中，我们的“模型”是一个由一组参数定义的数学机器，我们称之为$\theta$。这些参数是我们机器上的旋钮和刻度盘——可以想象成宇宙学模型中的[引力](@entry_id:175476)强度，或[遗传模型](@entry_id:750230)中的[突变率](@entry_id:136737)。我们的工作是利用观测到的数据，我们称之为$D_{obs}$，来判断哪些$\theta$值是合理的，哪些不是。[贝叶斯定理](@entry_id:151040)是我们解决这个问题的万能钥匙，它优雅地指出，在看到数据*之后*我们参数的合理性（即**后验分布**，$p(\theta | D_{obs})$）与它们在看到数据*之前*的合理性（即**先验分布**，$p(\theta)$）成正比，再乘以一个关键项：**[似然](@entry_id:167119)**，$p(D_{obs} | \theta)$。

似然是问题的核心。它提出了一个简单的问题：“如果宇宙的真实参数是$\theta$，那么观测到我们实际得到的数据$D_{obs}$的概率会是多少？”对于简单的模型，我们可以写下一个漂亮、简洁的[似然](@entry_id:167119)公式。但当我们的模型变得和现实本身一样复杂和混乱时，会发生什么呢？

想象一下，试图写出一个鸟类种群中数百万个DNA字母特定[排列](@entry_id:136432)的精确概率，同时要考虑到它们的迁徙模式、历史上的[种群瓶颈](@entry_id:154577)、自然选择以及数千代基因的随机重组[@problem_id:2521316] [@problem_id:2618227]。这个[似然](@entry_id:167119)的公式将是一个数学怪物，一个在令人难以置信的浩瀚可能祖先历史空间上的积分。这就是数学家所说的**难以处理**（intractable）——一个表示“无法计算”的委婉说法。在科学前沿的一大类问题中，从[流行病学](@entry_id:141409)到天体物理学，我们能够写下我们模型的规则，但却无法写出其[似然函数](@entry_id:141927)。我们似乎陷入了僵局。如果[贝叶斯定理](@entry_id:151040)的核心部分我们无法掌握，我们又怎么可能进行[贝叶斯推断](@entry_id:146958)呢？

### 一个哲学技巧：如果你能模拟它，你就能推断它

正是在这里，一个极其简单、近乎哲学的视角转变为我们提供了解决方案。这个想法是：如果我们根本不需要*计算*似然函数呢？我们有一个模型，一台我们完全理解其规则的机器。我们或许无法写出它产出的公式，但我们可以*运行*它。我们可以模拟它。这就是**近似贝叶斯计算（ABC）**的核心洞见。

让我们用一个类比来说明。假设你是一家烘焙比赛的评委。一位参赛者给了你一个蛋糕（$D_{obs}$），但你弄丢了食谱（$\theta$）。你无法“反向烘焙”这个蛋糕来找出食谱（这就是我们难以处理的似然）。但面包师还在厨房。你可以让他们用各种尝试的食谱（$\theta^*$）来烘焙新的蛋糕（$D_{sim}$）。你的策略很简单：

1.  猜测一个食谱（从你关于好蛋糕的[先验信念](@entry_id:264565)中抽取一个参数$\theta^*$）。
2.  让面包师用那个食谱烘焙一个蛋糕（从模型$p(D | \theta^*)$中模拟一个数据集$D_{sim}$）。
3.  将新蛋糕与原始蛋糕进行比较。如果它们非常匹配，你便认为这个尝试的食谱不错，并保留下来。
4.  重复这个过程成千上万次，甚至数百万次。

你最终保留下来的食谱集合构成了[后验分布](@entry_id:145605)的一个近似。你没有写下任何烘焙的物理和化学原理，就推断出了可能的食谱。这就是为什么ABC常被称为**无[似然](@entry_id:167119)**（likelihood-free）方法。它用计算上的暴力模拟取代了困难的解析计算[@problem_id:3288743]。

举一个科学上的例子，考虑推断一个种群中某个基因受到的自然选择强度[@problem_id:2374716]。我们可以创建一个计算机模拟，模拟一个根据一套规则（[Wright-Fisher模型](@entry_id:148998)）生存、繁殖和死亡的生物种群。我们可以设置选择强度参数$s$，并观察一个基因的频率如何随世代变化。为了进行ABC，我们会反复猜测一个$s$值，运行模拟，然后看我们模拟种群的最终遗传构成是否与我们在野外观察到的相似。

### 近似的艺术

当然，凡事皆有代价。上面描述的简单程序有一个致命的缺陷。模拟出一个与观测蛋糕*完全相同*，连最后一粒面包屑都一样的蛋糕的概率几乎为零。我们将在厨房里永远等待，拒绝每一个蛋糕。为了使这个想法变得可行，ABC依赖于三个巧妙的近似。

#### 摘要统计量：将数据提炼至其精华

我们不比较整个、极其复杂的数据集，而是比较少数几个精心挑选的特征，即**摘要统计量**。我们不逐个面包屑地比较蛋糕，而是比较它们的重量、高度、含糖量。在遗传学中，我们可能不比较整个基因组，而是比较一些统计数据，比如个体间的平均遗传差异数，或者种群间的[遗传分化](@entry_id:163113)程度[@problem_id:2521316]。

这是第一个近似来源。通过对数据进行摘要，我们不可避免地会丢弃一些信息。关键在于选择能够捕捉到与我们关心的参数最相关信息的统计量。如果一个统计量捕捉到了*所有*相关信息，它就被称为**充分的**（sufficient）。有了充分统计量，我们就不会损失任何东西。在现实世界中，为一个复杂模型找到一个低维度的充分统计量集合是极其罕见的[@problem_id:2618227]。因此，我们ABC推断的质量从根本上受到我们选择摘要统计量的智慧的限制[@problem_id:3429464]。如果我们试图推断一个主要影响基因间连[锁模](@entry_id:266596)式的参数，但我们只使用一个忽略连锁的摘要统计量（比如[位点频率谱](@entry_id:163689)），那么无论我们投入多少计算能力，我们的推断都会很差[@problem_id:2618227]。

#### 容忍度：定义“足够接近”

第二个近似是，即使对于摘要统计量，我们也不要求完全匹配。我们引入一个**[距离度量](@entry_id:636073)**$\rho$，来衡量模拟摘要$s(D_{sim})$与观测摘要$s(D_{obs})$之间的差距。然后我们定义一个**容忍度**$\epsilon$，如果距离在这个容忍度之内，我们就接受这个参数提议：$\rho(s(D_{sim}), s(D_{obs})) \le \epsilon$。[@problem_id:2521316]

这个容忍度$\epsilon$是控制准确性与速度之间权衡的旋钮。如果$\epsilon$很大，我们会接受很多提议，计算速度很快，但我们对后验分布的近似就很粗糙。如果我们将$\epsilon$缩小到零，我们的近似会越来越好。在$\epsilon = 0$的理论极限下，ABC给出了基于我们摘要统计量的精确后验[@problem_id:3308872]。但随着$\epsilon$的缩小，我们的接受率会骤降，所需的模拟次数可能变得天文数字般巨大[@problem_id:3096799]。

我们可以非常直观地看到这个容忍度的效果。在一个真实[似然](@entry_id:167119)是高斯分布（钟形曲线）的简单案例中，使用高斯形状的接受规则和容忍度$\epsilon$进行ABC，在数学上等同于进行精确的[贝叶斯推断](@entry_id:146958)，但作用于一个“模糊化”的似然上[@problem_id:3288811]。ABC[似然](@entry_id:167119)的[方差](@entry_id:200758)变成了真实[方差](@entry_id:200758)与一个和$\epsilon^2$相关的额外项之和。容忍度实际上模糊了[似然](@entry_id:167119)，而模糊的程度则由我们控制。好消息是，由此引入的误差通常与$\epsilon^2$成比例地缩小，这意味着随着我们收紧标准，近似会相当快地变好[@problem_id:3414065]。

#### [距离度量](@entry_id:636073)：比较的规则

第三个关键选择是[距离度量](@entry_id:636073)$\rho$本身。我们应该如何衡量摘要之间的“距离”？如果我们的摘要向量有多个分量——比如说，一个统计量在0到1之间变化，另一个在100到1,000,000之间变化——一个简单的[欧几里得距离](@entry_id:143990)将完全被后者主导。算法会将其所有精力集中在匹配那个数值大、噪声也大的统计量上，而忽略了来自较小统计量的可能更有[信息量](@entry_id:272315)的信号[@problem_id:2400312]。

距离的选择定义了我们接受区域的几何形状，并直接塑造了我们最终的后验分布。一种更复杂的方法是，用每个摘要统计量的标准差来对其进行缩放，或者更好的方法是，使用**[马氏距离](@entry_id:269828)**（Mahalanobis distance）。这种高级度量方法会自动考虑统计量的不同尺度以及它们之间的任何相关性。这就像戴上了一副定制的眼镜，让算法能够恰当地权衡来自每一条信息的证据，从而得到更高效、更准确的结果[@problem_id:2400312]。

### 穿越计算迷宫

有了这些原理，ABC就变成了一场在权衡中进行的强大而精妙的舞蹈。最大的挑战之一是**[维度灾难](@entry_id:143920)**。人们很容易认为，添加越来越多的摘要统计量总会通过让我们更接近充分性来改善我们的推断。但每个新的统计量都为我们测量距离的空间增加了一个维度。高维空间的体积是出了名的反直觉；随着维度数量的增长，“接受区域”（一个半径为$\epsilon$的超球面）在总体积中所占的比例变得无限小。这意味着我们的接受率会崩溃，计算成本会爆炸式增长[@problem_id:3429464]。ABC的艺术在于选择少量但信息量极高的统计量。

为了应对巨大的计算成本，研究人员已经开发出了一些巧妙的策略。例如，**序贯ABC**（sequential ABC）使用一个多阶段的过滤过程。它首先使用一个计算成本低、较粗略的摘要来快速拒绝最离谱的参数提议，只对更有希望的候选者进行昂贵的、完整的模拟和比较。这可以显著提高效率[@problem_id:3096799]。其他技术则将ABC近似嵌入到更复杂的采样算法中，如[马尔可夫链蒙特卡洛](@entry_id:138779)（MCMC），创造出强大的[混合方法](@entry_id:163463)[@problem_id:3288743]。

尽管有所有这些近似，ABC仍然建立在坚实的理论基础之上。其最强大的特性之一是**一致性**（consistency）。即使我们的摘要统计量对于有限的数据量不是充分的，但如果选择的统计量使得随着数据量增长到无穷大，它们会为每个可能的参数收敛到一个唯一的值，那么ABC后验将集中在真实的参数值上[@problem_id:3429464]。这给了我们信心，对于现代科学的海量数据集，ABC正在引导我们走向正确的方向。通过让我们能够拟合以前无法触及的模型，近似贝叶斯计算开辟了全新的发现途径，将难以处理的数学问题转变为可通过模拟和计算解决的挑战。这是人类智慧在面对自然复杂性时的一个美丽典范。

