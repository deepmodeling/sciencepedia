## 引言
有限的物理内存（RAM）是计算领域最基本的限制之一。当 RAM 耗尽时，系统会诉诸“交换”（swapping）——将数据移动到像硬盘或 SSD 这样的慢速存储设备上，这会导致显著的性能下降。这造成了一个关键瓶颈，迫使系统在可运行的应用程[序数](@entry_id:150084)量和其响应速度之间做出权衡。这就提出了一个关键问题：我们如何在不增加昂贵硬件的情况下克服这种物理限制？

本文探讨了一个极其巧妙的解决方案：zram。zram 并非将数据移动到缓慢的外部设备，而是利用 CPU 的处理能力来压缩不活跃的内存页，并将它们存储在 RAM 内部一个预留的区域中。这创造出了一种内存比物理上存在的更多的“幻觉”。我们将首先深入探讨“原理与机制”，探索 CPU 周期与内存访问之间权衡背后的优雅物理学和数学。随后，“应用与跨学科联系”部分将揭示这个简单的想法如何产生深远的影响，从优化智能手机的电池续航，到为高性能计算带来新的效率，甚至影响抽象算法的设计。

## 原理与机制

想象一下你在书桌前工作。你的桌面空间有限——这就是你的主内存，即**随机存取存储器（[RAM](@entry_id:173159)）**。你的书籍和文件就是你的程序和数据。只要你需要的一切都在桌面上，你的工作就快速而高效。但当空间用完时会发生什么？传统的答案是，把你暂时不用的文件放到走廊尽头的档案柜里——也就是你的硬盘或[固态硬盘](@entry_id:755039)（SSD）。这被称为**交换（swapping）**。问题在于，与伸手从桌上拿东西相比，去档案柜的路程痛苦而缓慢。每当你需要从那个柜子里取东西时，你都得停下手中的工作，走到走廊，找到文件，再把它拿回来。这种延迟是计算机性能的祸根。

但如果有一种更聪明的方法呢？与其把文件搬到遥远的档案柜，不如想办法把它们缩小，以便在桌面上占用更少的空间？你可以使用一种特殊的机器，它能拿取一张完整的纸，通过一些巧妙的折叠和编码，将其所有信息呈现在一张小纸片上。你无法直接阅读这张小纸片，但可以把它放回机器中，还原出原始的页面。这就是 **zram** 的精髓。我们利用计算机自身的处理能力（CPU）作为我们的“压缩机”，来压缩内存页，并将它们保存在 [RAM](@entry_id:173159) 的一个特殊的预留区域中，从而避免了前往磁盘的缓慢旅程。

然而，这个简单的想法取决于一个绝妙的权衡。运行压缩机（压缩）和解压机（解压缩）所花费的时间值得吗？

### 核心权衡：CPU 与内存的赛跑

让我们像物理学家一样思考这个问题。当[操作系统](@entry_id:752937)需要移走一个数据页时，它有两个选择。它可以简单地将一个大小为 $S$ 的页面从内存的一个部分复制到另一个部分。这个操作所需的时间很直观：页面大小除以复制速度，即内存带宽 $b$。所以，时间是 $T_{\text{copy}} = \frac{S}{b}$。

第二个选择是先压缩页面。假设我们的压缩算法非常高效，处理原始页面的每个字节需要 $c$ 个 CPU 周期。在一个频率为 $f$ 周期/秒的 CPU 上，压缩该页面的时间是 $T_{\text{cpu}} = \frac{c S}{f}$。压缩后，页面变得小得多。我们可以定义一个**[压缩比](@entry_id:136279)** $R$，即原始大小与压缩后大小的比值。$R=4$ 的[压缩比](@entry_id:136279)意味着我们将页面缩小到其原始大小的四分之一，即 $S/R$。现在我们复制这个更小的页面，需要时间 $T_{\text{compressed_copy}} = \frac{S/R}{b}$。这种“压缩并复制”策略的总时间是这两个步骤的总和：$T_{\text{zram}} = T_{\text{cpu}} + T_{\text{compressed_copy}} = \frac{c S}{f} + \frac{S}{R b}$。

那么，什么时候压缩更快呢？当 $T_{\text{zram}} < T_{\text{copy}}$ 时，压缩更快。最有趣的是“盈亏[平衡点](@entry_id:272705)”，即两者时间完全相等。这为我们提供了一个[压缩比](@entry_id:136279)的阈值，从纯粹延迟的角度来看，要达到这个阈值才能使我们的努力物有所值 [@problem_id:3639713]。
$$
\frac{c S}{f} + \frac{S}{R b} = \frac{S}{b}
$$
注意到页面大小 $S$ 出现在每一项中！我们可以把它约掉——这是一个漂亮的简化。这个基本的权衡并不取决于页面有多大，而只取决于硬件本身的特性。重新整理方程以求解盈亏平衡[压缩比](@entry_id:136279) $R_{\text{break-even}}$，我们得到：
$$
R_{\text{break-even}} = \frac{1}{1 - \frac{bc}{f}}
$$
这个小小的方程式蕴含着深刻的洞见。$\frac{bc}{f}$ 这一项是一个[无量纲数](@entry_id:136814)，代表了 CPU相对于内存总线的处理能力。它是在 CPU 处理单个字节的时间内，内存总线本可以传输的字节数的比率。如果这个数字很大（接近 1），意味着相对于总线来说 CPU 很慢，我们需要一个极高的[压缩比](@entry_id:136279)才能达到盈亏平衡。如果这个数字很小，意味着 CPU 速度极快，即使很小的压缩（$R$ 仅略大于 1）也能给我们带来速度优势。这一个表达式就抓住了决策的基本物理原理。

### 真正的奖赏：更多内存的幻象

虽然在延迟竞赛中获胜很好，但 zram 的主要目标通常是更神奇的东西：创造出比物理上拥有更多内存的幻象。这正是[压缩比](@entry_id:136279) $R$ 真正大放异彩的地方。

想象一下，你将总 RAM $C_{\text{RAM}}$ 的一部分（比例为 $f$）专用于 zram 设备。这块物理大小为 $f C_{\text{RAM}}$ 的空间，可以容纳相当于 $R \times f C_{\text{RAM}}$ 的*未压缩*数据。你的其余内存，$(1-f)C_{\text{RAM}}$，则存放正常的、未压缩的页面。那么，你的内存总“有效”容量是多少呢？它是两部分之和 [@problem_id:3684449]：
$$
C_{\text{eff}} = (1-f)C_{\text{RAM}} + R f C_{\text{RAM}} = C_{\text{RAM}} + (R-1)f C_{\text{RAM}}
$$
看！[有效容量](@entry_id:748806)是你的原始 RAM 加上 $(R-1)f C_{\text{RAM}}$ 的额外奖励。你凭空扩展了你的内存。如果你的[压缩比](@entry_id:136279)为 $R=2.6$，并且你将 3 GiB 的 RAM 区域专用于 zram，那么该区域不仅仅能容纳 3 GiB 的数据；它能容纳*有效* 7.8 GiB 的未压缩数据 [@problem_id:3685368]。你凭空变出了额外的 4.8 GiB 内存，代价仅仅是 CPU 周期。

当然，现实世界从不如此简单。实际上，存在一些小的开销。每个压缩页面都需要一点**[元数据](@entry_id:275500)（metadata）**来跟踪它，而且将许多小的、大小可变的压缩页面打包到更大的、固定大小的内存帧中的过程并非完美高效，会因**碎片化（fragmentation）**而导致一些空间浪费。一个智能的[操作系统](@entry_id:752937)知道这一点，只有当最终的压缩大小加上其开销确实小于原始页面大小时，它才会压缩一个页面 [@problem_id:3668031]。即便有这些实际考量，容量的增加仍然是显著的，常常使系统能够处理那些否则会让其陷入停滞的工作负载。

### 真正的竞争者：走廊尽头的档案柜

到目前为止，我们已经看到 zram 可以比简单的内存复制更快，并且可以扩展内存容量。但它真正的目的是取代那个缓慢的档案柜——磁盘交换。让我们来分析这场竞争。驱逐一个页面需要付出代价，如果之后我们再次需要该页面，取回它又需要另一个代价。

-   **磁盘交换：**驱逐意味着将页面写入磁盘，需要时间 $t_{\text{disk}}$。之后取回它意味着将其读回，又需要时间 $t_{\text{disk}}$。
-   **zram：**驱逐意味着压缩页面并在 RAM 内复制它，需要时间 $t_{\text{compress}} + t_{\text{mem_copy}}$。取回它意味着将其复制回来并解压缩，需要时间 $t_{\text{mem_copy}} + t_{\text{decompress}}$。

关键的洞见是，一个页面被驱逐后，我们不一定总是会再次需要它。假设一个被驱逐的页面将再次被引用的概率为 $p$。这个概率是程序**[引用局部性](@entry_id:636602)（locality of reference）**的一种度量。如果我们在交换到磁盘或 zram 之间做选择，我们想知道哪一个的预期总时间成本更低，这个成本要同时考虑驱逐和概率性地取回。

通过为每个操作的时间建模，我们可以推导出 zram 是更优选择的条件。事实证明，这个决定可能取决于许多因素：页面大小、磁盘速度、内存速度和 CPU 成本 [@problem_id:3664022] [@problem_id:3685159]。一个更深刻的审视方式是：对于给定的硬件配置，使两种策略成本相等的再访问概率阈值 $p^*$ 是多少？

通过仔细建模 CPU 压缩/解压缩以及对现代 NVMe 驱动器进行 I/O 的延迟，人们可以推导出这个阈值 [@problem_id:3687868]。结果在概念上惊人地简单：
$$
p^* = \frac{t_{\text{write}} - t_{\text{comp}}}{t_{\text{read}} - t_{\text{decomp}}}
$$
在这里，$t$ 值代表了将一个页面交换到驱动器（$t_{\text{write}}$）、压缩它（$t_{\text{comp}}$）、解压缩它（$t_{\text{decomp}}$）以及从驱动器读回它（$t_{\text{read}}$）的时间。如果一个程序重用一个页面的实际概率 $p$ 大于这个 $p^*$，那么花费 CPU 周期来压缩页面并将其保留在 zram 中是值得的。如果 $p$ 小于 $p^*$，那么该页面基本上是“冷”数据，最好直接将其写入缓慢但空间充裕的磁盘然后忘记它。这表明，最优的内存管理策略并非一成不变；它是一个动态决策，取决于其上运行的软件的行为。

### 全局影响：俯瞰视角

当我们把视野拉远，审视整个系统的性能时，zram 的好处才真正显现出来。在[操作系统](@entry_id:752937)中，一个关键指标是**[有效访问时间](@entry_id:748802)（EAT）**——执行单次内存引用所需的平均时间。大多数引用命中 RAM，速度非常快。一小部分，即[缺页率](@entry_id:753068)，需要缓慢地访问交换设备。

Zram 就像一个位于慢速磁盘前的大型快速缓存。当发生[缺页中断](@entry_id:753072)时，系统首先检查页面是否在 zram 中。如果在（“zram 命中”），它会被迅速解压缩。如果不在（“zram 未命中”），系统就必须访问磁盘。假设在发生缺页中断的情况下，zram 命中的概率为 $q$。

系统 EAT 的改善结果呈现出一种优美而简单的形式 [@problem_id:3663136]。总共节省的时间 $\Delta EAT$ 是：
$$
\Delta EAT = p_{\text{fault}} \cdot q \cdot (T_{\text{disk}} - T_{\text{zram}})
$$
其中 $p_{\text{fault}}$ 是总的[缺页率](@entry_id:753068)，$q$ 是 zram 命中率，最后一项是每次命中节省的时间。这个方程式讲述了一个强有力的故事。zram 的好处不仅仅在于解压缩有多快；它是三个因素的乘积。在缺页较为频繁（$p_{\text{fault}}$ 不为零）、zram 缓存足够大且有效以捕获大部分缺页（高 $q$），以及底层磁盘比 zram 服务时间慢得多的系统中，zram 最为有效。

### 压缩的艺术：多样化的选择

我们一直在谈论“压缩”，好像它是一个单一的东西。但实际上，它是一种艺术形式，拥有一系列算法。一些算法，如 **LZ4**，速度极快，但可能只能实现中等的[压缩比](@entry_id:136279)。另一些，如 **Zstandard (ZSTD)**，速度较慢，但能更有效地压缩数据。

这给[操作系统](@entry_id:752937)带来了另一个引人入胜的[优化问题](@entry_id:266749)。想象一下，你每秒钟可以用于压缩的 CPU 时间有一个有限的“预算”。你应该使用哪种算法？是那个能让你处理更多页面但节省空间较少的快速算法？还是那个能节省更多空间但如果页面需要太快地被换出可能会造成瓶颈的慢速算法？

你可以将此建模为一个资源分配问题 [@problem_id:3685283]。通过将平均换出延迟定义为使用每种算法压缩的页面比例的函数，并受 CPU 预算的限制，你可以找到最优的组合。通常，目标是最小化延迟。由于更快的压缩（如 LZ4）对延迟的贡献较小，最佳策略通常是使用尽可能快的算法，只要这样做不会完全耗尽你的 CPU 预算。这表明现代[操作系统](@entry_id:752937)不仅仅是遵循固定的规则；它们实时地解决[优化问题](@entry_id:266749)，以适应系统负载。

### 最后的优雅：软件管理的时钟

让我们以最后一个细节来结束，它揭示了[操作系统](@entry_id:752937)设计的极致巧妙。如果 zram 区域本身变满了，我们需要从中驱逐一个压缩页面（很可能是将其写入实际的磁盘）。我们应该驱逐哪一个？我们应该驱逐“[最近最少使用](@entry_id:751225)”的那个。一个常用的算法是**二次机会或[时钟算法](@entry_id:754595)（second-chance or clock algorithm）**，它为每个页面使用一个硬件“引用”位（$R$）。CPU 在每次访问页面时会自动将 $R$ 设置为 1。[操作系统](@entry_id:752937)会周期性地扫描页面，给任何 $R=1$ 的页面第二次机会（并清除其位），同时驱逐它找到的第一个 $R=0$ 的页面。

但有一个问题：zram 中的页面只是一堆数据块。它们没有以 CPU 能理解的方式被“映射”，所以硬件无法为它们设置[引用位](@entry_id:754187)。[操作系统](@entry_id:752937)怎么可能知道哪些压缩页面正在被使用呢？

解决方案是一项精妙的软件创新 [@problem_id:3679230]。[操作系统](@entry_id:752937)意识到，“使用”一个压缩页面的唯一方式是访问它，这会触发一个[缺页中断](@entry_id:753072)。而[操作系统](@entry_id:752937)自己处理这个中断！这个软件事件——为特定压缩页面调用[缺页](@entry_id:753072)处理程序——是硬件引用的完美替代品。因此，[操作系统](@entry_id:752937)可以为每个压缩页面维护自己的、*基于软件的*[引用位](@entry_id:754187)。当一个页面因[缺页中断](@entry_id:753072)而被解压缩时，[操作系统](@entry_id:752937)将其软件 $R$ 位置为 1。当[时钟算法](@entry_id:754595)需要在 zram 中寻找一个牺牲者时，它会查看这些软件位。

这是计算机科学统一性的完美例证。一个硬件限制（未映射数据没有[引用位](@entry_id:754187)）被巧妙的软件设计无缝克服，利用其已有的信息（[缺页中断](@entry_id:753072)事件）来维护一个高级算法的完整性。正是在这些细节中，揭示了计算原理的真正美感和深刻结构。

