## 引言
在科学研究中，尤其是在医学和流行病学等领域，确定因果关系的黄金标准是随机对照试验。然而，现实和伦理上的限制常常迫使我们依赖观察性数据，此时我们会遇到“苹果与橘子”的问题：接受不同处理的组别从一开始就存在根本性差异。这个问题被称为混杂（confounding），它可能导致危险的误导性结论，例如，一种能挽救生命的药物仅仅因为它被用于病情最重的患者，而显得似乎有害。这就产生了一个关键的知识鸿沟：我们如何从现实世界中混乱、非随机的数据中得出可靠的因果结论？

本文将深入探讨一种应对此挑战的强大统计解决方案：倾向性得分分层。在接下来的章节中，我们将剖析这种精妙的方法。首先，“原理与机制”一章将解释因果推断的核心概念，介绍作为“一维奇迹”的倾向性得分，并详细阐述分层和平衡性检验的逐步过程。随后，“应用与跨学科联系”一章将展示该方法的卓越通用性，探讨它如何揭示医学中的悖论、为处理选择提供合乎伦理的研究方法，甚至为药物化学中的分子设计提供新的工具包。我们将从直面观察性科学的核心难题开始，并引入为解决此问题而设计的巧妙构思。

## 原理与机制

### “苹果与橘子”困境

想象一下，我们是一群试图弄清一种新心脏病药物是否能挽救生命的科学家。我们不能总是进行完美的随机对照试验——医学的黄金标准。相反，我们常常不得不依赖于观察现实世界中发生的事情，使用来自卫生系统中成千上万名患者的数据。在这里，我们立刻会遇到一个困扰着许多观察性科学的难题，一种“苹果与橘子”的问题。

在现实世界中，医生并不会通过抛硬币来决定谁该使用新药。他们出于最好的意图，运用自己的临床判断。他们通常更可能给那些看起来病情更重、预后不良风险更高的患者开出强效的新疗法 [@problem_id:4640738]。而那些症状较轻、较健康的患者，则可能继续接受标准治疗。

现在，如果我们只看原始数据，可能会发现服用新药的患者组的结局比未服药的患者组更差。是药物造成了伤害吗？还是那些患者从一开始就处于更高的风险之中？我们正在比较一群接受了治疗的病情非常严重的“苹果”和一群未接受治疗的病情较轻的“橘子”。他们结局的差异是任何真实药物效应与他们初始健康状况差异的混乱混合。这种效应的根本性混合被称为**混杂（confounding）**，在这种特定的临床背景下，它通常被称为**指示混杂（confounding by indication）**。作为严谨的科学家，我们的任务是找到一种方法，使比较变得公平——即实现“苹果对苹果”的比较。

### 反事实之梦

为了清晰地思考这个问题，让我们进行一个小小的思想实验，这是现代因果推断的核心概念。对于我们研究中的每一个人，我们可以想象两个平行宇宙。在一个宇宙中，这个人接受了新疗法（$T=1$），我们观察到他们的结局，我们称之为 $Y(1)$。在另一个宇宙中，完全相同的这个人*没有*接受该疗法（$T=0$），我们观察到他们的结局 $Y(0)$ [@problem_id:4599486]。这些是他们的**潜在结局（potential outcomes）**。对那个人而言，该疗法的真实个体因果效应就是这两个潜在结局之间的差异：$Y(1) - Y(0)$。

当然，这只是一个梦想。在现实中，我们永远无法同时看到两个宇宙。对于任何给定的个体，我们只能观察到他们实际接受的处理所对应的结局。另一个结局，即未选择那条路所对应的结局，将永远不为人知。它是**反事实的（counterfactual）** [@problem_id:4599486]。这就是统计学家所称的**因果推断的根本问题（fundamental problem of causal inference）**。

由于我们无法知道任何人的个体因果效应，我们的目标更为温和：**平均处理效应（Average Treatment Effect, ATE）**，即 $\tau = \mathbb{E}[Y(1) - Y(0)]$。这是整个群体中所有个体因果效应的平均值。它回答了这样一个问题：“平均而言，如果我们将这种疗法给予群体中的每个人，与不给任何人相比，其效应会是什么？”有时，我们可能对另一个问题感兴趣，比如**处理组平均处理效应（Average Treatment Effect on the Treated, ATT）**，它探讨的是在现实世界中选择接受治疗的那部分人群中的特定效应 [@problem_id:4845551]。现在，让我们专注于 ATE。我们的挑战是，如何使用处理组和未处理组从一开始就不可比的数据来估计这个平均效应。

### 一维奇迹：倾向性得分

我们如何构建一个“公平比较”的组？一个直观的想法是，为每个接受治疗的人找到一个在所有重要方面——年龄、性别、疾病严重程度等——都相同的未接受治疗的“双胞胎”。如果我们有一个包含这些特征的大向量，我们称之为 $X$，我们可以尝试根据人们的整个特征档案进行匹配。但随着特征数量的增加，这变得不可能。“[维度灾难](@entry_id:143920)”意味着在高维空间中，每个人都是独一无二的，寻找完美的双胞胎是一项无望的任务。

这时，来自统计学家 Paul Rosenbaum 和 Donald Rubin 的一个美妙、近乎神奇的想法前来解救。他们问道：能够总结一个人最终进入治疗组的全部原因的那个数字是什么？它就是**倾向性得分（propensity score）**，定义为在给定所有基线特征 $X$ 的条件下，接受治疗的概率。

$$e(X) = \mathbb{P}(T=1 \mid X)$$

这个得分是一个介于0和1之间的单一数字，它将一个人完整的高维特征档案（$X$）浓缩为他们接受治疗可能性的一个一维摘要。奇迹就在于此：Rosenbaum 和 Rubin 证明，如果你比较两个具有*相同倾向性得分*的人，其中一人接受了治疗而另一人没有，他们的基线特征 $X$ 在他们之间将平均[达到平衡](@entry_id:170346) [@problem_id:4638380]。这就是倾向性得分的**平衡性（balancing property）**。它表明，在倾向性得分的条件下，协变量 $X$ 与处理分配 $T$ 是独立的。用符号表示为 $X \perp T \mid e(X)$。

为什么会这样呢？让我们直观地思考一下。如果你的倾向性得分是，比如说，0.3，这意味着你属于一个特定的亚组，这个亚组的人的综合特征使他们有30%的可能性接受治疗 [@problem_id:4501622]。任何其他具有相同0.3得分的人，无论他们最终是否接受治疗，也都属于同一个亚组。通过以该得分为条件，我们实际上隔离出了这种特定“类型”的人。在该群体的狭窄切片内，处理的分配就像是抛掷一枚加权硬币，有30%的概率正面朝上（接受治疗）。导致混杂的系统性差异已经被“条件化”消除了。这个单一的数字一次性完成了平衡 $X$ 中所有协变量的工作。

### 从得分到分层：方法的实际操作

既然我们有了这个强大的一维摘要，我们如何用它来估计因果效应呢？最直接和直观的方法是**倾向性得分分层（propensity score stratification）**。这个想法很简单：如果我们不能精确地以倾向性得分的某个值作为条件，那我们就根据得分将人群切分成几个箱子，或称**分层（strata）**。

例如，我们可以使用整个研究人群中估计的倾向性得分的五[分位数](@entry_id:178417)来创建五个分层 [@problem_id:4830519]。
-   第1层：倾向性得分最低的20%的人（例如，$e(X)$ 从 $0$ 到 $0.15$）。这些人是最不可能接受治疗的。
-   第2层：接下来的20%（例如，$e(X)$ 从 $0.15$ 到 $0.30$）。
-   ...以此类推，直到...
-   第5层：倾向性得分最高的20%的人（例如，$e(X)$ 从 $0.80$ 到 $1$）。这些人是最有可能接受治疗的。

平衡性的魔力表明，*在这五个分层中的每一个内部*，处理组和未处理组的基线特征 $X$ 现在应该更加相似。最初的“苹果与橘子”问题已在很大程度上被解决，分解为五个更小、更易于管理的“大部分是苹果与大部分是苹果”的比较。

一旦我们有了这些分层，估计[处理效应](@entry_id:636010)就成了一个两步过程 [@problem_id:5221151]：

1.  **估计每个分层内的效应**：在每个分层 $k$ 内部，我们回到了一个看起来几乎像是随机实验的情境。我们可以简单地计算该分层中处理组和未处理组之间平均结局的差异。我们称之为层特异性效应，$\hat{\tau}_k$。例如，在一项关于降压药的研究中，我们可能会发现在低倾向性分层中，治疗使血压平均降低了 $3.7$ mmHg [@problem_id:4830519]。我们对所有 $K$ 个分层都这样做。

2.  **合并各分层的效应**：我们现在有 $K$ 个不同的[处理效应](@entry_id:636010)，每个对应于人群的一个切片。为了得到一个单一的平均[处理效应](@entry_id:636010)（ATE）的[总体估计](@entry_id:200993)，我们需要将它们合并起来。我们不能简单地取一个[算术平均值](@entry_id:165355)。我们必须计算一个**加权平均值**，其中每个分层效应的权重就是该分层在总人口中所占的比例。如果我们五个分层中的每一个都包含20%的人，我们最终的ATE估计是：

    $$ \hat{\tau}_{ATE} = \sum_{k=1}^{K} \frac{N_k}{N} \hat{\tau}_k $$

    其中 $N_k$ 是分层 $k$ 中的人数，而 $N$ 是总人口规模。这一步是[全期望定律](@entry_id:265946)的一个漂亮应用；我们通过拼接其组成部分的效应来重构整个人群的平均效应 [@problem_id:5221151]。

### 成功了吗？检查平衡性

执行完这个过程后，一个关键问题依然存在：我们的分层真的起作用了吗？它成功地平衡了协变量吗？我们必须检查我们的工作。用于此目的的主要工具是**标准化均数差（Standardized Mean Difference, SMD）**。

对于我们原始集合 $X$ 中的每个协变量（如年龄、基线疾病严重程度等），我们计算分层前后的SMD。SMD是一个无单位的度量，它表示处理组和[对照组](@entry_id:188599)之间协变量平均值的差异，并用该协变量的[合并标准差](@entry_id:198759)进行缩放 [@problem_id:4599524]。

$$ SMD = \frac{\bar{X}_{1} - \bar{X}_{0}}{s_{p}} $$

在调整之前，我们可能会发现很大的SMD，表明存在严重的失衡。在分层之后，我们希望看到这些SMD显著缩小。根据[经验法则](@entry_id:262201)，SMD的绝对值小于0.1被认为表明失衡程度可以忽略不计、是可接受的 [@problem_id:4599524]。绘制调整前后的这些SMD，可以为我们提供一个清晰的视觉诊断，展示我们的“苹果对苹果”比较在多大程度上得以实现。

### 附加条款：假设与局限性

像任何强大的工具一样，倾向性得分方法并非炼金术。它们依赖于关键的假设，其魔力也有其极限。

首先是**正性假设（positivity assumption）**，它指出对于任何一组特征 $X$，同时被处理和不被处理的概率都必须不为零（$0  e(X)  1$） [@problem_id:5221092]。这完全合乎逻辑：如果某种类型的患者*总是*被给予治疗（因此$e(X)=1$），或者*从不*被给予治疗（因此$e(X)=0$），我们就完全没有关于他们反事实结局的数据。例如，如果一家医院的电子健康记录有一个硬性规定，禁止为肾衰竭患者使用某种药物，那么对于这群患者，其倾向性得分就恰好为0。对他们进行因果推断是不可能的；我们无法知道这种药物会产生什么效果，因为没有像他们这样的人接受过这种药物 [@problem_id:5221092]。

其次，我们并不知道*真实*的倾向性得分。我们必须用数据来估计它，通常使用像逻辑回归这样的[统计模型](@entry_id:755400)。如果我们的模型设定不当——例如，模型过于简单，遗漏了临床医生做决策时使用的重要因素——那么我们估计的得分就不会是真正的平衡得分，残余混杂可能依然存在 [@problem_id:4830511]。人们可能会尝试使用高度灵活的机器学习模型来获得更准确的估计。这可以减少偏倚，但也伴随着其自身的风险。一个非常强大的模型可能会识别出重叠非常有限的亚组，产生极度接近0或1的估计倾向性得分。这种“实际上的正性”违背可能导致估计值极不稳定 [@problem_id:4830511]。有时，研究人员通过剔除得分极端的受试者来解决这个问题，这虽然稳定了分析，但也意味着最终的估计值仅适用于那些更具模糊性的“重叠人群” [@problem_id:4830511]。

最后，整个过程都建立在**条件可交换性（conditional exchangeability）**（或“无未测量混杂”）这一关键假设之上。我们假设，通过测量和控制协变量集合 $X$，我们已经捕捉了所有在处理组和未处理组之间存在差异的重要因素。如果存在某个重要的未测量混杂因素——比如我们没有记录的患者的积极性或社会经济地位——它同时影响了治疗和结局，那么倾向性得分方法就无法对其进行控制，我们的估计值仍将是有偏的 [@problem_id:4638380]。

因此，倾向性得分分层并非万能灵药。它是一种精妙而强大的策略，用以从观察中解开因果关系，将有偏的“苹果与橘子”的比较转变为一系列更可信、更平衡的比较。它完美地诠释了现代统计学中蕴含的深邃思想——一种[概率推理](@entry_id:273297)、巧妙简化以及对支撑我们认识世界的假设抱持健康尊重的融合。

