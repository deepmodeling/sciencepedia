## 应用与跨学科联系

“我能够接受怀疑、不确定和未知。我认为，活在未知中比拥有可能是错误的答案有趣得多。” Richard Feynman 的这句优美表达，正是科学探究的灵魂。但是，尽管我们可以与不确定性共存，我们仍然必须行动。我们必须做出决策。那么，核心问题就是，当并非掌握所有事实时，如何做出*尽可能好的决策*？

在上一章中，我们揭示了一个深刻的数学原理来做到这一点：**[次线性遗憾](@article_id:640217)**。我们发现，可以为在时间跨度 $T$ 内的重复决策设计策略，这些策略在非常精确的意义上是“保证能学习”的。虽然我们不可避免地会犯一些错误，但这些错误的总成本——我们的累积遗憾——可以被控制得增长得如此之慢，以至于我们的每轮平均遗憾 $\frac{1}{T} \sum_{t=1}^T (\text{loss}_{\text{our},t} - \text{loss}_{\text{oracle},t})$ 会随着时间的推移而消失。我们的表现变得与一个从一开始就知道正确答案的神话般的“神谕”无法区分。

这是一个强有力的论断。但这仅仅是一个局限于抽象方程世界的理论奇珍吗？还是说这个原理正在我们周围的世界中发挥作用？我们已经锻造了一把万能钥匙。现在，让我们带着它去散散步，看看它究竟能打开多少扇不同的门。我想你会发现，结果是相当惊人的。

### 我们栖身的数字世界

让我们从你可能几分钟前刚经历过的事情开始：个性化的互联网。每当你打开一个新闻应用、一个流媒体服务或一个社交媒体[信息流](@article_id:331691)，一个决策正在被做出。在一个包含 $n$ 篇文章、视频或帖子的宇宙中，应该向*你*呈现哪 $k$ 个项目？服务提供商并不完全了解你的品味。它面临一个巨大的“多臂赌博机”问题。每一条内容都是一个“老虎机”，而你的点击就是“头奖”。它应该如何选择向你展示什么呢？

如果它只根据过去的行为（纯利用）向你展示它*认为*你喜欢的东西，它可能会错过一个你本会爱上的全新类型。如果它只向你展示随机的东西来了解你（纯探索），你的[信息流](@article_id:331691)会感觉混乱和不相关。要取得成功，服务必须平衡这种权衡。而做得最好的[算法](@article_id:331821)，恰恰是那些保证[次线性遗憾](@article_id:640217)的[算法](@article_id:331821)。它们使用像“面对不确定性时的乐观主义”这样的原则来智能地探索，确保总遗憾——他们获得的互动量与他们*本可以*通过完美了解你的品味而获得的互动量之间的累积差异——呈次线性增长。这意味着随着时间的推移，系统会成为你的专家，而其最初无知的成本变得可以忽略不计 [@problem_id:3257114]。我们现在习以为常的流畅、个性化的体验，在很多方面，都是[次线性遗憾](@article_id:640217)实践力量的证明。

### 计算本身的艺术

也许更令人惊讶的是，这种学习原理不仅用于优化我们*与*计算机的互动；计算机也可以用它来优化*自身*。思考一个基本任务，比如乘以两个非常大的 $n$ 位数。有不同的方法可以做到。我们在学校学到的方法很简单，但很慢。Karatsuba [算法](@article_id:331821)更快，其复杂度大约为 $O(n^{\log_2 3})$。对于真正巨大的数字，基于[快速傅里叶变换 (FFT)](@article_id:306792) 的[算法](@article_id:331821)甚至更快，大约为 $O(n \log n)$。

一个软件库应该使用哪一种？答案取决于数字的大小。存在一些“[交叉](@article_id:315017)点”，在这些点上一个[算法](@article_id:331821)变得比另一个更好。我们可以尝试手动找出这些点，但如果我们把它框定为一个学习问题呢？我们可以将每个可能的[交叉](@article_id:315017)点视为一个给我们建议的“专家”。每当程序需要做一次乘法时，它在某种意义上可以询问专家。通过使用像乘法权重更新法这样的简单[次线性遗憾](@article_id:640217)[算法](@article_id:331821)，程序可以听取这些专家的意见，看看他们的建议表现如何，并动态更新对他们的信任。在很短的时间内，系统学会了信任哪个专家——也就是说，它根据其在运行机器上的实际性能自动找到了最佳的[交叉](@article_id:315017)点。其花费的总时间保证几乎与一个神谕从一开始就告诉它最佳设置一样好 [@problem_id:3229124]。

这个想法可以被进一步推进。一个任务的最佳[算法](@article_id:331821)可能不依赖于像输入大小这样简单的事情，而是依赖于数据本身更微妙的结构特性，比如它的[香农熵](@article_id:303050) $H(P)$。通过将在“运行中”估计这些属性的[流式算法](@article_id:332915)与学习框架相结合，我们可以构建自适应程序，实时为工作选择最佳工具，同样地，为其做出错误选择的遗憾被证明是最小的 [@problem_id:3203360]。机器学会了如何学习。

### 科学发现的新引擎

到目前为止，我们看到的应用都非常了不起，但它们都存在于计算机内部。当我们采取的“行动”不是选择比特，而是操纵原子时，会发生什么？同样的原则也适用，其后果对科学是变革性的。

考虑定向进化的挑战，这是一种用于为药物或工业酶工程改造新蛋白质的技术。科学家创造了巨大的突变基因库，然后面临着找到少数具有所需特性的“命中”的艰巨任务。实验预算总是有限的。你应该测试哪些突变体？这又是一个多臂赌博机问题，但这次是在宏大的生物学尺度上。每个变体库都是老虎机的一个臂。一次实验测试就是拉动一次臂。一个成功的新蛋白质就是头奖。像 UCB（[置信上界](@article_id:357032)）和 Thompson 抽样这样的[次线性遗憾](@article_id:640217)[算法](@article_id:331821)为分配宝贵的实验预算提供了一个正式的方案。它们规定了一种精确的方式来平衡测试当前最有希望的变体（利用）和探索那些被忽视的奇怪变体（探索）。这种数学指导极大地加速了生物技术领域的发现步伐 [@problem_id:2591026]。

这一[范式](@article_id:329204)延伸到了生物学最前沿的领域。想象一下，你想通过删除所有非必需基因为细菌创建一个“[最小基因组](@article_id:323653)”，这是合成生物学中的一个核心挑战。或者，你正试图找到数十种生长因子的完美组合，以诱导干细胞形成复杂的[类器官](@article_id:313414)，比如培养皿中的微型大脑。在这两种情况下，可能性的空间都大得惊人，而且每个实验都极其昂贵和耗时。

这些不再是简单的赌博机问题，因为选择不是独立的。删除一个基因可能与删除其在[染色体](@article_id:340234)上的邻居有相似的效果。一种生长因子的效果平滑地依赖于另一种的浓度。在这里，我们可以使用更复杂的学习模型，如高斯过程，来捕捉这些相关性。但核心哲学保持不变。[算法](@article_id:331821)为未知景观建立一个概率性的“代理”地图。然后它使用一个[采集函数](@article_id:348126)——UCB 思想的直系后代——来决定下一步在哪里采样，明确地在利用已知高产区域和探索高不确定性区域之间进行权衡。这一系列技术，被称为[贝叶斯优化](@article_id:323401)，是[次线性遗憾](@article_id:640217)思维方式的直接应用。它使科学家能够在几十次实验中找到最佳的基因设计或分化方案，而暴力方法可能需要数百万次 [@problem_-id:2741561] [@problem_id:2622457]。它是科学发现的新引擎，将不确定性从障碍变成了向导。

### 学习系统的无形统一

到目前为止，你可能已经感受到了这个想法的普遍性。它似乎无处不在。让我们通过几个例子来结束，揭示它作为一个深刻、统一的原则的角色。

首先，考虑我们经常面临的复杂的组合选择。它并不总是关于挑选一个最佳选项，而是关于选择一个选项*团队*来完成一项工作——比如一个物流公司选择一组每日的送货路线来覆盖所有目的地，而每条路线上的交通状况是未知且波动的。这是一个“组合赌博机”问题。在这里，“面对不确定性时的乐观主义”原则也可以被扩展，以引导公司走向一个接近最优的路线策略，其总成本被证明与一个无所不知的神谕相近 [@problem_id:3180685]。

接下来，让我们转向博弈论。想象一下两个玩家在一场竞争性的[零和博弈](@article_id:326084)中。他们不知道对方的策略。他们应该如何玩？一个引人入胜的结果表明，如果两个玩家都使用一个[次线性遗憾](@article_id:640217)[算法](@article_id:331821)来根据过去几轮的结果更新他们的策略，整个系统将收敛到一个[纳什均衡](@article_id:298321)——一个稳定的状态，其中没有玩家有单方面改变策略的动机。每个玩家的累积遗憾直接关系到游戏离这个均衡有多远。这是一个在复杂系统中寻找平衡的美妙的、去中心化的机制。甚至学习[算法](@article_id:331821)的几何结构——无论是用[欧几里得距离](@article_id:304420)还是信息论散度来思考——也巧妙地影响着通往均衡的路径，这是一个优美理论中的优美细节 [@problem_id:3131686]。这不仅适用于棋盘游戏，也适用于理解拍卖、[金融市场](@article_id:303273)甚至[生态竞争](@article_id:348863)中的动态。

最后，也许是最深刻的，考虑一下[卡尔曼滤波器](@article_id:305664)。半个多世纪以来，这个[算法](@article_id:331821)一直是工程和应用科学的基石。它是 GPS 接收器、[天气预报](@article_id:333867)模型和[航天器导航](@article_id:351544)背后幕后的数学奇才。它是一种通过不断地将物理模型的预测与嘈杂的测量值相融合来跟踪动态变化系统（如卫星位置）的方法。它是[数据同化](@article_id:313959)的黄金标准。

另一方面，[在线学习](@article_id:642247)领域的发展在很大程度上是独立的，专注于机器学习任务的遗憾最小化。然而，如果你深入研究，会发现两者之间有着深刻的联系。[卡尔曼滤波器](@article_id:305664)的核心数学更新可以被证明等同于解决一个特定的[在线学习](@article_id:642247)问题：一个在线版本的岭回归。在被跟踪的系统实际上是静态的特殊情况下，卡尔曼滤波器的性能保证可以用[次线性遗憾](@article_id:640217)的语言重新解读。事实证明，这个著名的工程工具，在某种意义上，一直都是一个伪装的[次线性遗憾](@article_id:640217)[算法](@article_id:331821) [@problem_id:3116068]。还有什么比这更能震撼地展示科学思想的统一性呢？两个不同的社群，从不同的问题出发——跟踪导弹与预测用户点击——最终得到了相同的基本数学结构。

从个性化我们的新闻推送，到优化我们的[算法](@article_id:331821)，到发现新药，到在游戏中找到平衡，再到在轨道上跟踪卫星——[次线性遗憾](@article_id:640217)的原则是一条共同的线索。它是一种关于乐观主义和好奇心的形式化理论。它教导我们，虽然我们无法消除不确定性，但我们可以智能地与之互动，确保我们在未知中的旅程是高效的。对[次线性遗憾](@article_id:640217)的追求，无非就是如何学习的数学形式化。