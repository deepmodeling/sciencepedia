## 引言
科学过程常常涉及比较相互竞争的模型，以确定哪个模型能最好地解释我们的数据。在[贝叶斯推断](@entry_id:146958)领域，这种比较通过一个称为[边际似然](@entry_id:636856)（或[模型证据](@entry_id:636856)）的关键量来正式处理。这个值是衡量模型性能的最终分数，但其计算构成了一个重大的计算障碍，通常需要求解一个困难的[高维积分](@entry_id:143557)。

这一挑战催生了各种估计技术的出现。其中最著名也最臭名昭著的，是[调和平均](@entry_id:750175)估计量（HME），它承诺能从标准的 MCMC 输出中几乎“免费”地得到一个估计值。然而，其诱人的简单性背后隐藏着深层次的统计问题，这些问题可能使科学结论失效。本文将剖析调和平均估计量，全面审视其失败的原因。首先，“原理与机制”一章将揭示它所依据的优美恒等式，以及使其不可靠的统计谬误（如[无限方差](@entry_id:637427)）。随后，在“应用与跨学科联系”中，我们将探讨这种不稳定性对科学[模型选择](@entry_id:155601)的现实后果，将其失败与其它领域的概念联系起来，并简要介绍更稳健的替代方法。通过理解这种流行方法为何会如此惨败，我们能更深刻地体会到可靠[统计推断](@entry_id:172747)的原则。

## 原理与机制

在我们通过[贝叶斯推断](@entry_id:146958)的视角来理解世界的旅程中，我们常常需要在一系列相互竞争的理论或模型之间做出选择。哪个模型能更好地解释我们观测到的数据？贝叶斯的答案在于一个极其重要的量：**[边际似然](@entry_id:636856)**（**marginal likelihood**），或称**[模型证据](@entry_id:636856)**（**model evidence**）。对于一个给定的模型 $M$ 和数据 $y$，证据 $p(y|M)$ 告诉我们，在所有可能的参数值 $\theta$ 上进行平均后，在该模型下观测到该数据的概率。它是[模型比较](@entry_id:266577)的最终裁判。

证据 $p(y)$ 在贝叶斯定理中也扮演着至关重要的角色，作为[归一化常数](@entry_id:752675)，确保后验分布 $p(\theta|y)$ 是一个积分归一的合规[概率分布](@entry_id:146404) [@problem_id:3319143]。

$$
p(\theta | y) = \frac{p(y | \theta) \, p(\theta)}{p(y)}
$$

然而，计算这个量通常是一项艰巨的挑战，需要我们求解一个[高维积分](@entry_id:143557)。这促使科学家们设计出巧妙的方法，从模拟中估计它。其中最著名，或许也是最声名狼藉的方法之一，就是[调和平均](@entry_id:750175)估计量。它的故事是一个关于数学优雅、统计现实和计算中隐藏陷阱之间相互作用的引人入胜的教训。

### 一个简单恒等式的诱惑

乍一看，调和平均估计量似乎是天才之作。它源于对贝叶斯定理的一个简单而优美的重排。让我们从一个直接来自期望定义的恒等式开始。*[似然](@entry_id:167119)倒数*（$1/p(y|\theta)$）在*后验*[分布](@entry_id:182848) $p(\theta|y)$ 下的[期望值](@entry_id:153208)是：

$$
\mathbb{E}_{p(\theta|y)}\left[\frac{1}{p(y|\theta)}\right] = \int \frac{1}{p(y|\theta)} p(\theta|y) \, d\theta
$$

现在，如果我们代入后验的定义，$p(\theta|y) = p(y|\theta)p(\theta)/p(y)$，奇妙的事情发生了：

$$
\int \frac{1}{p(y|\theta)} \frac{p(y|\theta)p(\theta)}{p(y)} \, d\theta = \frac{1}{p(y)} \int p(\theta) \, d\theta
$$

由于先验分布 $p(\theta)$ 的积分必须为 1，我们得到了一个惊人简单的结果：

$$
\mathbb{E}_{p(\theta|y)}\left[\frac{1}{p(y|\theta)}\right] = \frac{1}{p(y)}
$$

这个恒等式是**调和平均估计量（HME）**的核心。它告诉我们，要估计证据的倒数 $1/p(y)$，我们只需在后验样本上平均似然的倒数即可。由于现代[贝叶斯分析](@entry_id:271788)依赖于提供数千个后验样本的 MCMC 方法，这似乎让我们免费获得了证据的估计值！我们取后验样本 $\theta_1, \dots, \theta_n$，计算[似然](@entry_id:167119)倒数的样本均值，然后取该结果的倒数，便得到我们对 $p(y)$ 的估计 [@problem_id:3311581]。

$$
\hat{p}(y)_{\mathrm{HM}} = \left( \frac{1}{n} \sum_{i=1}^{n} \frac{1}{p(y|\theta_i)} \right)^{-1}
$$

这似乎好得令人难以置信。而我们即将发现，事实确实如此。

### 第一道裂缝：系统性偏差

当我们考虑 HME 是否为[无偏估计量](@entry_id:756290)时，麻烦的第一个迹象出现了。我们知道似然倒数的样本均值 $\bar{X} = \frac{1}{n}\sum \frac{1}{p(y|\theta_i)}$ 是 $1/p(y)$ 的一个[无偏估计量](@entry_id:756290)。但 HME 并非 $\bar{X}$，而是 $1/\bar{X}$。

这里我们遇到了统计学的一个基本法则：一个[随机变量](@entry_id:195330)的[非线性](@entry_id:637147)函数的期望不等于其期望的函数。也就是说，$\mathbb{E}[g(X)] \neq g(\mathbb{E}[X])$，除非 $g$ 是一条直线。

这里的函数是 $g(x) = 1/x$。这个函数不是线性的，它是一条曲线。具体来说，对于正值，它是一个**[凸函数](@entry_id:143075)**——它像碗一样向上弯曲。一个优美的数学结果，即**琴生不等式**（**Jensen's inequality**），告诉我们，对于任何凸函数 $g$，$\mathbb{E}[g(X)] \ge g(\mathbb{E}[X])$。

将此应用于我们的估计量，我们发现：

$$
\mathbb{E}[\hat{p}(y)_{\mathrm{HM}}] = \mathbb{E}\left[\frac{1}{\bar{X}}\right] \ge \frac{1}{\mathbb{E}[\bar{X}]} = \frac{1}{1/p(y)} = p(y)
$$

这揭示了[调和平均](@entry_id:750175)估计量存在系统性的*向上*偏差 [@problem_id:3311601]。事实证明，这种偏差的程度与 $\bar{X}$ 的变异性有关。[泰勒展开](@entry_id:145057)表明，偏差近似地与 $\bar{X}$ 的[方差](@entry_id:200758)成正比 [@problem_id:3311544]。更大的变异性意味着更大的偏差。这是我们得到的第一个线索，表明这个估计量的稳定性可能是一个严重问题。

### [无限方差](@entry_id:637427)的灾难

偏差是个问题，但真正的灾难在于[方差](@entry_id:200758)。让我们思考一下我们正在平均的量：$1/p(y|\theta)$。[后验分布](@entry_id:145605) $p(\theta|y)$ 的本质是集中在那些能使数据 $y$ 变得很可能的参数 $\theta$ 区域——也就是[似然](@entry_id:167119) $p(y|\theta)$ 较高的区域。

然而，后验分布并不会在其他所有地方都消失。它通常有“尾巴”，延伸到参数空间中那些在先验下看似合理但与[数据拟合](@entry_id:149007)非常差的区域。在这些区域，似然 $p(y|\theta)$ 可能非常小。当我们的 MCMC 采样器在其参数空间的[随机游走](@entry_id:142620)中，踏入其中一个区域时，会发生什么？

如果 $p(y|\theta)$ 是，比如说，$10^{-50}$，它的倒数就是 $10^{50}$——一个天文数字。来自这样一个区域的单个样本可以产生一个如此巨大的值，以至于它完全压倒所有其他“正常”值的总和。这使得样本均值，以及最终的估计值，变得极不稳定。

这不仅仅是一个假设性的担忧。在许多常见情况下，这是一个数学上的必然。我们可以证明，对于一个简单的模型，比如用正态[先验估计](@entry_id:186098)正态分布的均值，[似然](@entry_id:167119)倒数的[方差](@entry_id:200758)是有限的*当且仅当*先验比后验更集中（具有更小的[方差](@entry_id:200758)） [@problem_id:1316598]。这个条件在实践中我们几乎从不希望或满足；我们通常希望先验比数据提供的信息更少。在大多数现实场景中，我们试图平均的量具有**[无限方差](@entry_id:637427)**。

一个基于具有[无限方差](@entry_id:637427)的量的估计量，在统计学上是一场噩梦。这意味着无论我们收集多少样本，估计值都永远不会稳定下来。它将永远受到由罕见的极端事件引起的灾难性跳跃的影响。

### 当常规法则失效时

使用一个[无限方差](@entry_id:637427)的估计量意味着我们所有通常的统计直觉和工具都失效了。

作为如此多统计学基石的**[中心极限定理](@entry_id:143108)（CLT）**告诉我们，许多[独立随机变量](@entry_id:273896)的平均值将具有一个看起来像优美的钟形高斯曲线的[分布](@entry_id:182848)。但 CLT 有一个关键要求：这些变量必须具有[有限方差](@entry_id:269687)。当[方差](@entry_id:200758)为无限时，CLT 不再适用。我们的估计量的[分布](@entry_id:182848)不会收敛到一个行为良好的高斯分布。相反，它会收敛（如果收敛的话）到一个更狂野、[重尾](@entry_id:274276)的对象，称为 **alpha-[稳定分布](@entry_id:194434)** [@problem_id:3311610]。这意味着极端的、无意义的估计值不仅是可能的，而且是该估计量[分布](@entry_id:182848)的固有特征。

这种失效带来了严重的实际后果。我们计算置信区间或标准误的标准方法都基于 CLT。对于 HME，这些方法是无效的。它们给了我们一种虚假的确信感。

甚至我们用于 MCMC 模拟的诊断工具也可能受到影响。例如，**[有效样本量](@entry_id:271661)（ESS）**是评估 MCMC 采样器效率的标准指标。它告诉我们相关的 MCMC 链相当于多少个[独立样本](@entry_id:177139)。但 ESS 的计算依赖于自相关的存在，而自相关是根据[方差](@entry_id:200758)定义的。如果[方差](@entry_id:200758)是无限的，自相关这个概念本身就变得没有定义。我们的诊断工具建立在一个 HME 违背的假设之上，这使得它们在评估其稳定性方面毫无用处 [@problem_id:3311548]。

### 从糟糕到更糟：采样器的作用

[调和平均](@entry_id:750175)估计量从根本上就是有缺陷的。但在实践中，我们使用 MCMC 生成样本的方式可能会使情况变得更糟。

MCMC 采样器产生一个相关的抽样序列。**正[自相关](@entry_id:138991)**意味着采样器倾向于在参数空间的同一邻域停留几步，然后再移动。如果一个混合缓慢的采样器游荡到那些危险的低似然区域之一，它可能会在那里“卡住”一段时间，不仅产生一个，而是一整串灾难性的 $1/p(y|\theta)$ 值。这在有限数量的样本中极大地夸大了估计值的变异性 [@problem_id:3311576]。

当[模型参数化](@entry_id:752079)不佳，为采样器创造了具有挑战性的几何形状时，这个问题尤其严重。一个著名的例子是“Neal's funnel”，这是一个分层模型，其中一个[尺度参数](@entry_id:268705)与其他参数强耦合。一个朴素的（“中心化”）[参数化](@entry_id:272587)会产生一个漏斗形的后验，标准 MCMC 算法 notoriously 难以探索，导致高自相关。一个巧妙的重参数化（“非中心化”）可以打破这些依赖关系，让采样器混合得更自由。虽然更好的混合可以通过防止采样器卡住来减少实际的、有限样本的损害，但重要的是要记住，它无法修复 HME 根本的[无限方差](@entry_id:637427)问题。它只是让一个糟糕的情况变得稍微不那么糟糕 [@problem_id:3311604]。

### 最后的讽刺：精确计算的谎言

这个故事还有一个最后的、优美而讽刺的转折。正如我们所见，HME 要求我们对诸如 $\exp(-\ell_i)$ 这样的数值求和，其中 $\ell_i$ 是[对数似然](@entry_id:273783)。如果一个[似然](@entry_id:167119)值极小，其对数似然就是一个很大的负数，而 $-\ell_i$ 就变成了一个很大的正数。直接计算 $\exp(-\ell_i)$ 会立即在计算机上导致数值[溢出](@entry_id:172355)。

为了解决这个问题，程序员使用一种称为**log-sum-exp 技巧**的聪明技术。这是一种完全在对数域中重构计算的方法，通过使用一个常数[移位](@entry_id:145848)来确保没有任何中间值会[溢出](@entry_id:172355)。这个技巧使我们能够高精度地计算[调和平均](@entry_id:750175)估计量的最终值，而不管所涉及数值的大小 [@problem_id:3311572]。

讽刺之处就在于此。我们可以构建一个完全稳定、数值上稳健的机器来计算调和平均估计量的值。但是，由于该估计量无限的统计[方差](@entry_id:200758)，这台机器产生的数字基本上是无意义的。我们成功地制造了一个测量幻影的精密仪器。数值解的优雅只是为了凸显统计谬误的深度。调和平均估计量是一个警示故事，一个美丽的构想在与现实接触时粉碎，它教会我们关于数学恒等式与可靠统计工具之间差异的深刻一课。

