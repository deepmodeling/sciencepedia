## 应用与跨学科联系

我们花了一些时间来理解神经普通[微分方程](@article_id:327891)的机制——它们如何学习一个连续的流，以及我们如何使用一些巧妙的微积分来训练它们。但在物理学以及所有科学中，真正的乐趣并非源于凝视方程，而是透过方程看世界。所以，现在我们提出一个关键问题：[神经ODE](@article_id:305498)到底*有什么用*？为什么用连续时间思考的能力会成为如此深刻的优势？

简而言之，答案是科学的语言——从行星的轨道到分子的复杂舞蹈——就是[微分方程](@article_id:327891)的语言。通过将这种语言作为我们学习机器的核心，我们在人工智能的数据驱动世界与科学定律的原理驱动世界之间建立了一种深刻而强大的联系。这种联系不仅能产生更精确的模型，还[能带](@article_id:306995)来更鲁棒、更具[可解释性](@article_id:642051)的模型，并最终使模型与自然界的实际运作方式更加一致。让我们通过几个引人入胜的例子，踏上一段旅程，见证这一美妙思想的实际应用。

### 拥抱现实世界的不规则性

你可能遇到的大多数时间序列模型，如[循环神经网络](@article_id:350409)（RNN），都按固定的节奏运行。它们[期望](@article_id:311378)数据以完全规则的间隔到达，就像节拍器的节拍一样。但现实世界并非如此井然有序。医生不会每分每秒都测量病人的生命体征；股票在买卖双方达成一致时才进行交易；我们碰巧在观测时才能看到超新星。我们世界的数据从根本上就是不规则的。

传统模型如何处理这种情况？通常，它会作弊。它可能会假装缺失的数据点是零，或者尝试猜测它们的值。但这有点像试图理解一场每隔一个词就含糊不清的对话——你失去了真正的动态。

这时，[神经ODE](@article_id:305498)的连续时间视角就大放异彩了。对[神经ODE](@article_id:305498)来说，不规则的时间步长不是问题，而是世界上最自然的事情。如果它在时间 $t_i$ 拥有系统的状态，而下一个数据点在 $t_{i+1}$ 到达，它只需在*确切*的区间 $\Delta_i = t_{i+1} - t_i$ 上求解其学到的[微分方程](@article_id:327891)。没有猜测，没有填充，没有对时间的扭曲。它精确地根据需要的时间长度来积分这个流。这使得它能以更高的保真度对底层的连续过程进行建模，优雅地处理了现实世界测量中杂乱、异步的特性 [@problem_id:2886119]。这是一个简单的视角转变，但它让我们从对时间的僵化、离散的看法，转向了反映现实本身的流动、连续的看法。

### 搭建通往[第一性原理](@article_id:382249)的桥梁：科学人工智能的兴起

或许，[神经ODE](@article_id:305498)最激动人心的前沿在于它们与科学原理的融合。几个世纪以来，科学通过发现基本定律（通常以[微分方程](@article_id:327891)的形式表达）而进步。机器学习则通过在数据中发现模式而发展。当我们将这两种探索结合起来时，会发生什么？

想象一下，你是一位物理学家，试图预测一种材料在[相变](@article_id:297531)附近的行为，比如一块磁铁被加热到失去磁性的[临界点](@article_id:305080)以上 [@problem_id:2410517]。你有很多关于低温有序相的数据，但没有关于高温无序相的数据。如果你用这些数据训练一个标准的“黑箱”[神经网络](@article_id:305336)，它会完美地学会描述低温世界。但如果你让它预测当你越过临界温度时会发生什么，它将彻底失败。它学到的是一种相关性，而不是底层的定律。

现在，考虑一种不同的方法。我们从物理学中知道，这种[相变](@article_id:297531)附近的动力学通常由一个能量函数（“[朗道自由能](@article_id:307019)”）的梯度所支配。如果我们构建一个[神经ODE](@article_id:305498)，其架构本身就反映了这一定律，会怎么样？我们可以设计网络，使其学到的[向量场](@article_id:322515)*必须*是一个势的梯度，并且该势*必须*具有物理系统的对称性。网络的任务不再是盲目地模仿数据，而是学习物理定律本身的参数——具体来说，就是能量函数的系数如何随温度变化。在这个低温数据上训练后，这个[物理信息](@article_id:312969)模型学会了游戏的*规则*。因为它学会了规则，所以它可以进行外推。它正确地预测出，随着温度升高，能量景观的形状会改变，从而导致磁性丧失。它不仅仅是拟合数据，它理解了数据背后的*原因*。这种超越训练数据范围进行[外推](@article_id:354951)的能力是[科学建模](@article_id:323273)的圣杯，而[神经ODE](@article_id:305498)为我们提供了一把强大的新钥匙。

这种“教网络守规矩”的想法可以有无数种应用方式。考虑模拟[原子力显微镜](@article_id:342830)探针与表面相互作用时的精细舞蹈 [@problem_id:2777707]。我们确信两件事：系统必须耗散能量（它不能无中生有地产生运动），原子间的力也不是无限的。一个朴素的[神经网络](@article_id:305336)既不知道这些，也可能学到一个完全不符合物理规律的模型，能量会奇迹般地出现。

但是，利用[神经ODE](@article_id:305498)，我们可以将这些约束直接构建到架构中。例如，我们可以使用像`softplus`这样的函数来参数化阻尼项，该函数只能产生正值，从而保证相应的力总是与运动方向相反并耗散能量。我们可以使用像`tanh`这样的函数来[参数化](@article_id:336283)恢复力，该函数本质上是有界的，确保它永远不会变得无穷大。通过做出这些架构选择，我们不仅在帮助网络，更是在禁止它给出任何物理上荒谬的答案。

这种协同作用是双向的。不仅物理学可以为我们的模型提供信息，模型也可以帮助我们学习物理学。在系统生物学或[材料科学](@article_id:312640)等领域，我们通常有一个机理模型——一组描述酶促反应或催化等过程的ODE——但参数（如[反应速率](@article_id:303093)）是未知的 [@problem_id:1443761]。此外，我们的实验数据可能稀疏、嘈杂或间接，比如来自反应化学混合物的复杂光谱时间序列 [@problem_id:77144]。

在这里，物理信息神经网络（PINN），作为[神经ODE](@article_id:305498)的近亲，可以充当一个主综合器。网络被训练来同时做两件事：首先，它的预测必须与我们拥有的实验数据一致。其次，它的预测必须*在任何地方*都遵守已知的[微分方程](@article_id:327891)，即使在我们没有数据的时间点。ODE本身成为损失函数的一部分。网络会因违反动力学定律而受到惩罚。这个强大的思想使我们能够从有限的信息中推断出隐藏的参数并重建整个动态路径，将数据的稀疏真理与物理定律的普适真理融合在一起。

### 警示故事与建模艺术

就像任何强大的工具一样，使用[神经ODE](@article_id:305498)必须保持智慧和健康的怀疑态度。它们极高的灵活性有时可能成为粗心者的陷阱。

想象一个“混合模型”，你将一个理解透彻的机理方程与一个灵活的[神经ODE](@article_id:305498)部分结合起来，希望后者能捕捉到你所不理解的复杂细节。这听起来很有希望，但可能导致一个被称为“实践中的不可辨识性”的奇怪问题 [@problem_id:1459448]。可能会发生的情况是，那个超级灵活的[神经网络](@article_id:305336)部分学会了当替罪羊。如果模型的机理部分稍有错误，[神经网络](@article_id:305336)可以调整自己来完美地抵消这个错误。最终的模型完美地拟合了数据，但你什么也没学到。事实上，你可能会发现，用一个完全不同的物理参数值也能得到同样好的拟合，因为[神经网络](@article_id:305336)只是适应性地进行了补偿。这给我们一个至关重要的教训：对数据的良好拟合不等于一个正确的模型。我们模型的结构和我们数据的质量决定了我们能真正学到什么。

另一个微妙之处出现在模拟复杂[振荡系统](@article_id:328507)时，例如著名的Belousov-Zhabotinsky[化学反应](@article_id:307389) [@problem_id:2949169]。这些系统是“[远离平衡态](@article_id:364583)”动力学的典型例子，由能量和物质的持续流动维持。当试图将模型拟合到嘈杂的[振荡](@article_id:331484)数据时，很容易对波动进行[过拟合](@article_id:299541)。防止过拟合的常用方法是添加一个惩罚复杂性的[正则化](@article_id:300216)器。但是用哪种正则化器呢？有人可能会天真地尝试强制执行平衡[热力学](@article_id:359663)中的一个条件，比如细致平衡。这将是一场灾难！细致平衡只在平衡态下成立，那是一种死寂的状态。强制执行它会扼杀我们试图建模的[振荡](@article_id:331484)本身。

正确的方法是使用尊重系统真实性质的正则化。这可能包括设置符合物理原理的[反应速率](@article_id:303093)上限（它们不能比扩散速度还快！），或者使用反映你测量设备已知局限性的平滑惩罚。这就是[科学建模](@article_id:323273)的艺术：选择与所研究系统的物理现实相协调的工具和约束。

### 迈向因果推理

我们已经看到，[神经ODE](@article_id:305498)可以构建强大的预测模型。但是科学，乃至所有理性的决策，都渴望不仅仅是预测。我们想理解因果关系。我们不仅想知道高烧与疾病相关，我们还想知道*降低*体温是否会*导致*病人好转。

这是[因果推断](@article_id:306490)的领域。标准的机器学习擅长在观测数据中发现相关性，但在因果关系上却出了名的困难。正是在这里，当从因果关系的角度看待时，[神经ODE](@article_id:305498)开启了一种惊人的新可能性 [@problem_id:2857201]。

考虑一下为眼睛中的[免疫系统建模](@article_id:364752)的挑战，这是一个特殊的“免疫特权”部位，炎症通常被抑制。当这种特权被打破时，可能导致严重损害。我们可以收集许多因素的数据：抗原负荷、血-眼屏障的完整性、像[TGF-β](@article_id:371743)这样的调节分子，以及浸润的效应细胞。一个标准的模型可能会学到，大量的效应细胞可以预测损伤。

但是一个因果模型，也许可以被构建为一个生物学启发的[神经ODE](@article_id:305498)，它能做得更多。它编码了已知的机制：[TGF-β](@article_id:371743) *抑制*效应细胞的浸润，而效应细胞*导致*损伤。通过构建因果机制的模型，我们可以超越被动的预测，开始提出主动的、“如果……会怎样”的问题。我们可以模拟一种干预：如果我们能用药物阻断TGF-β会发生什么？或者，如果我们能神奇地清除所有效应细胞，组织损伤会怎样？这就像预报天气和理解[气象学](@article_id:327738)到足以提出如果我们能改变洋流会发生什么的差别。通过表示变化的机制，[神经ODE](@article_id:305498)不仅可以成为[函数逼近](@article_id:301770)器，还可以成为因果推理和科学发现的引擎。

### 统一的愿景

从缺失数据的实际问题到因果推断的宏大挑战，[神经ODE](@article_id:305498)提供了一个统一的框架。它们不仅仅是机器学习工具箱中的又一个工具。它们代表了一种哲学上的转变，一种有意识地将数据驱动和原理驱动的建模传统重新整合的举动。通过在学习数据的同时使用动力学的语言，它们使我们能够创造出不仅更智能，而且更智慧的模型——反映了对我们周围世界更深层次、更具机理性的理解。而这，无疑是一段值得踏上的旅程。