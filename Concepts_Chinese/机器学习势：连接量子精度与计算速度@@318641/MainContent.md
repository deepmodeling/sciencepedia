## 引言
原子尺度下物质的行为由一个复杂的高维[能量景观](@article_id:308140)所支配，这个景观被称为[势能面](@article_id:307856)（Potential Energy Surface, PES）。几十年来，科学家在绘制这一地形时一直面临一个根本性的两难选择：是依赖计算成本高昂但高度精确的量子力学方法，如密度泛函理论（Density Functional Theory, DFT），还是使用快速但近似的[经典力场](@article_id:369501)。这种在精度和速度之间的权衡限制了[分子模拟](@article_id:362031)的范围和规模。[机器学习势](@article_id:362354)（Machine-learned potentials, MLPs）作为一种革命性的第三条道路应运而生，它提供了一种构建模型的方法，该模型具有量子力学的精度，而[计算成本](@article_id:308397)则接近经典势。本文将深入探讨这项变革性技术。接下来的章节将探索使MLP得以实现的核心概念及其在各科学领域的深远影响。我们首先探讨“原理与机制”，揭示物理定律如何引导机器学习创建出物理上一致且功能强大的模型。随后，“应用与跨学科联系”一节将展示这些势如何被用于解决化学、[材料科学](@article_id:312640)及其他领域的实际问题。

## 原理与机制

想象一下，你正试图在完全黑暗中穿越一片广阔无形的群山。你唯一的工具是一个能告诉你当前海拔的[高度计](@article_id:328590)，以及一个能告诉你脚下斜坡方向和陡峭程度的特殊装置。简而言之，这就是一个原子的世界。这片无形的景观就是**[势能面](@article_id:307856)（Potential Energy Surface, PES）**，一个由量子力学定律雕琢而成的宏伟、高维的地形。海拔就是势能，而决定运动方向的斜坡就是力。化学的全部故事——键如何形成与断裂，分子如何扭曲与折叠，反应如何发生——都写在这片表面的地理构造之中。

几十年来，科学家主要有两种方法来绘制这片景观。我们可以运用量子力学的全部威力，如**[密度泛函理论](@article_id:299475)（Density Functional Theory, DFT）**，这就像拥有一幅完美的高分辨率卫星地图。地图精确至极，但生成哪怕一小块区域的计算成本都如此高昂，以至于绘制整个山脉是不可想象的。或者，我们可以使用简化的**[经典力场](@article_id:369501)**，它们就像对景观粗略的手绘卡通画。它们用简单的弹簧和球代替了复杂的量子山丘和峡谷。这些地图使用起来快得令人难以置信，但它们往往很笨拙，并且忽略了那些使化学变得有趣的微妙而美丽的细节。

这就给我们留下了一个巨大的两难境地：我们是想要只能用于少数几个原子的惊人精度，还是想要以牺牲物理真实性为代价的闪电般的速度？这就是[机器学习势](@article_id:362354)（MLP）登场的时刻，它不是一个混乱的妥协，而是一种优雅的综合。它们提供了第三条道路：一种创建地图的方法，其精度几乎与量子神谕相当，而速度几乎与经典卡通画一样快。让我们层层剥开，看看这一非凡的壮举是如何完成的。数字本身就说明了问题：对于一个包含100个原子的中等体系，一次力的计算使用经典模型可能需要大约3万次操作，而使用DFT则需要惊人的1000亿次操作。MLP恰好位于两者之间，需要数百万次操作——这是成本与质量之间的一个美妙的[平衡点](@article_id:323137)[@problem_id:2457423]。

### 智能的架构：局域性与对称性

一个计算机程序，一套“愚笨”的指令，怎么可能学习深奥的量子物理定律呢？秘密不在于教它薛定谔方程，而在于教它识别模式，并由几个深刻的物理原理引导。

#### 物质的“短视性”

第一个也是最重要的原理是**局域性（locality）**。在液体和固体的密集世界中，一个原子有点像拥挤房间里的一个人；它主要与其直接邻居相互作用。房间另一侧的原子对它的影响可以忽略不计。电子物质的这种“短视性”是一份礼物。它使我们能够为一个庞大系统的总能量$E$建立模型，不是通过一次性观察所有事物，而是通过将每个独立原子的贡献相加，其中每个原子的能量仅由其局域邻域决定[@problem_id:2648609]。

$$
E = \sum_{i=1}^{N} E_i(\text{environment of atom } i)
$$

这个看起来简单的求和功能非常强大。它意味着我们的模型是**广延的（extensive）**：如果我们把系统的大小加倍，能量也会加倍，正如物理学所要求的那样。它还意味着模型是**可迁移的（transferable）**：如果我们在一小块材料中发现的[局域原子环境](@article_id:361081)上训练我们的模型，我们就可以自信地用它来预测一大块材料的性质，因为大系统只是更多相同局域环境的拼接[@problem_id:2648609]。这就是我们如何摆脱“全局”模型的陷阱，这些模型需要在训练期间看到所有可能大小的系统，以避免对新系统做出荒谬的预测。

#### 原子的语言：不变描述符

所以，我们需要向神经网络描述一个原子的局域环境。但是如何做呢？我们不能简单地给它一个邻近原子坐标的列表。为什么不行？因为如果你只是在空间中转动分子，那个列表就会改变，而分子的能量不可能取决于它朝向哪个方向！宇宙没有一个偏好的“上”或“下”。这就是**[旋转不变性](@article_id:298095)（rotational invariance）**的原理。同样，如果我们只是在空间中移动整个系统（**平移不变性，translational invariance**），或者如果我们任意地重新标记两个相同的原子（**[置换](@article_id:296886)[不变性](@article_id:300612)，permutational invariance**），能量也不能改变。

原子环境的描述，即**描述符（descriptor）**，必须从一开始就尊重这些对称性。它必须是一个数学函数，接收邻居的坐标，并产生一个对这些变换不敏感的环境的独特指纹。如果我们在这一点上失败了，我们的模型就建立在沙滩之上。想象一个不具备[旋转不变性](@article_id:298095)的有缺陷的描述符。如果我们在一个方向上训练模型，当我们简单地旋转分子时，它会做出一个完全不同且错误的预测，导致不符合物理的力和一个无用的模型[@problem_id:91044]。

此外，描述符必须真正捕捉到重要的几何形状！在一个滑稽但富有启发性的例子中，想象一个只计算碳原子和氢原子数量的描述符。如果你试图训练这样一个模型来预测丁烷绕其中心键旋转时的能量，它会彻底失败。由于原子数量在旋转过程中不改变，模型将预测一个恒定的能量，完全忽略了旋转能垒。预测的能垒将为零，无论真实的能垒是多少，因为模型从未被给予成功所需的信息[@problem_id:2457435]。

现代MLP使用两种主要哲学来应对这一挑战[@problem_id:2648619]。开创性的**Behler-Parrinello**方法使用一组固定的、手工制作的数学函数（称为[对称函数](@article_id:356066)），这些函数被巧妙地设计为不变的。它们明确地编码了局域邻域内的二体距离和[三体](@article_id:329664)角度。一种更新的方法，见于**[消息传递](@article_id:340415)[神经网络](@article_id:305336)（Message Passing Neural Networks, MPNNs）**，则采取了不同的途径。它将分[子表示](@article_id:301536)为一个图，其中原子是节点，键是边。网络通过在相邻原子之间“传递消息”来学习自己的描述性特征。在每一步中，一个原子通过聚合来自其邻居的信息来更新其状态。经过几步之后，原子的表示包含了关于扩展邻域的信息。这种学习到的表示通常比固定的描述符更灵活、更具表达力，尽管它可能需要更多的数据来有效训练。

### 训练方案：关键在于力

一旦我们有了描述原[子环](@article_id:314606)境的方法，我们就需要训练神经网络将这种描述映射到能量上。我们从哪里获得“基准”数据呢？当然是从我们昂贵但精确的量子神谕那里。我们对一组有代表性的原子构型进行多次DFT计算。但是我们应该让MLP学习什么呢？

仅仅训练网络去匹配每个构型的DFT能量似乎是显而易见的。但这是一个错失的机会。还记得那个无形的景观吗？能量只是几个点的海拔。而*力*是这些点的斜率。力告诉我们关于PES形状的信息，这才是真正支配动力学的东西。对于每一个有$N$个原子的原子构型，我们只得到一个总能量值，但我们得到$3N$个力分量（每个原子的x、y、z方向各一个）。在力上进行训练，可以从同样数量的昂贵DFT数据中为我们提供关于该景观的更多信息[@problem_id:2648619]。

这就引出了**力匹配（force-matching）**方法[@problem_id:2759514]。训练的目标，或者说**[损失函数](@article_id:638865)（loss function）**，是最小化MLP的预测与DFT参考值在能量和力上的差异。一个设计良好的损失函数有几个关键特征：
1. 它最小化预测力*矢量*与参考力*矢量*之间的平方差。只尝试匹配力的大小是一个致命的错误——一个指向错误方向的力是完全错误的，即使它的长度是正确的！
2. 它考虑到绝对能量是任意的。只有能量*差*才重要。因此，[损失函数](@article_id:638865)在比较能量时允许一个浮动的偏移量。
3. 它结合了能量和力的误差，通常使用权重来优先保证力的正确性。

一组训练构型的典型损失函数如下所示：
$$
L = \sum_{k} \left[ w_E \left( E_{\text{MLP}}^{(k)} - E_{\text{DFT}}^{(k)} - b \right)^2 + w_F \sum_{i=1}^{N_k} \left\| \vec{F}_{\text{MLP}, i}^{(k)} - \vec{F}_{\text{DFT}, i}^{(k)} \right\|^2 \right]
$$
这里，$w_E$和$w_F$是权重，$b$是可学习的能量偏移量[@problem_id:2759514]。

当然，训练的质量取决于数据本身。如果我们想模拟一个[化学反应](@article_id:307389)，我们的训练数据必须不仅包括稳定的反应物和产物，还必须包括位于它们之间路径上的高能量、短寿命的**[过渡态](@article_id:313517)（transition states）**。一个简单的模拟很少会访问这些关键区域。因此，构建一个好的[训练集](@article_id:640691)需要复杂的**[主动学习](@article_id:318217)（active learning）**策略，即模型本身帮助决定哪些新的DFT计算对于弥补其自身的弱点最为需要[@problem_id:2457428]。

### 一致性之美：一台保守的机器

经过所有这些工作，我们得到了一个训练好的MLP。它接收一个原子构型，计算描述符，将它们通过[神经网络](@article_id:305336)，然后输出一个能量。这个过程的一个显著特性是我们可以免费获得力。因为整个模型只是一系列可微的数学运算，我们可以利用微积分的魔力（具体来说是[自动微分](@article_id:304940)）来计算能量相对于每个原子位置的解析梯度。

$$
\vec{F}_i = -\nabla_{\vec{r}_i} E_{\text{MLP}}
$$

这不是一个近似值；这是模型结构的一个精确的数学结果。它具有深刻的物理意义。任何作为[标量势](@article_id:339870)梯度的[力场](@article_id:307740)，根据定义，都是一个**[保守力场](@article_id:343706)（conservative force field）**。这意味着当我们使用我们的MLP运行[分子动力学模拟](@article_id:321141)时，模型的总能量（MLP的势能加上动能）在连续时间极限下是完全守恒的[@problem_id:2457457]。

这是一个优美的结果。训练过程决定了势的*真实性*——它与真实的量子景观匹配得有多好。但模型的架构本身保证了其*内部一致性*。无论MLP是基于能量、力还是两者进行训练，只要模拟中的力是作为其解析梯度导出的，动力学过程就会保守模型自身的能量。在实际模拟中看到的任何能量漂移都来自于数值时间步进[算法](@article_id:331821)的微小误差，而不是势本身的任何缺陷。

### 视野：承认局限

尽管这些局域MLP功能强大，但它们有一个致命弱点：它们的短视性。虽然[化学反应](@article_id:307389)在很大程度上是局域的，但并非*完全*局域。[长程力](@article_id:361141)，如带电离子之间的[静电相互作用](@article_id:345679)（$1/r$ 衰减）和将分子聚集在一起的微妙的范德华[色散力](@article_id:313615)（$1/r^6$ 衰减），其作用范围远远超出典型的MLP[截断半径](@article_id:297161)（5–10 Å）。一个严格的局域模型对这种物理现象是盲目的，无法描述诸如分子解离到大距离或极性液体的集体[介电响应](@article_id:300590)等过程[@problem_id:2796824]。

这是否意味着整个事业注定要失败？完全不是。它指明了前进的方向。该领域的前沿在于创建结合了两全其美的[混合模型](@article_id:330275)。这些模型使用MLP来学习复杂的、短程的量子力学相互作用，这是它的长处。然后，它们明确地加回已知的长程物理函数形式，其参数（如原子[电荷](@article_id:339187)或极化率）本身也由[神经网络](@article_id:305336)以一种依赖于几何构型的方式预测。

这是一种成熟而强大的方法。它不要求机器从头重新发现[库仑定律](@article_id:299808)。相反，它以已知的物理定律为支架，让机器学习来描绘出复杂的、量子力学的细节。这是人类知识与机器智能之间的合作，共同努力构建我们有史以来最准确、最高效、物理上最合理的原子世界地图。