## 引言
在数据世界里，计数和测量之间存在着根本的区别。我们可以计算诊所就诊次数等离散项目，但科学和医学中许多最重要的问题都涉及我们测量的量：血压、肿瘤大小或污染物浓度。这些是**连续性结局**，即可以在一个范围内取任何值的变量，为我们观察世界提供了丰富而细致的视角。然而，这种丰富性也带来了挑战。我们如何才能在不丢失其内在细节的情况下，恰当地总结、比较和解释这些数据？简化的诱惑——例如，粗略地将患者标记为“有效”或“无效”——普遍存在，但这往往导致错误的结论和资源的浪费。

本文旨在指导读者理解和有效处理连续性结局。它 aborda 了常见的陷阱，并阐明了使用适当统计方法的强大之处。第一章**“原理与机制”**将通过定义连续性数据、探索其描述方法以及介绍衡量变化和效应的关键方法来奠定基础。我们还将直面与二分法相关的严重问题以及不[完美数](@entry_id:636981)据的现实。随后的**“应用与跨学科联系”**一章将展示这些原理在现实世界中的应用，从设计更高效的临床试验、设定更安全的环境标准，到解开复杂的因果关系和从医学图像中提取信息。通过拥抱连续性，我们可以获得对现实更清晰、更有力、更真实的看法。

## 原理与机制

### 测量与计数的艺术

在我们探索世界的过程中，我们不断面临两种基本活动：计数和测量。我们可以数一个狼群中有多少只郊狼，或者一只蜥蜴在求偶时做了多少个俯卧撑。这些都是离散的——你可以有2只或3只郊狼，但不能有$2.5$只。答案都是整数。但如果我们想知道一只郊狼的体重呢？或者一条河里污染物的浓度？这时，我们不是在计数，而是在**测量**。

一只郊狼的体重并不仅限于恰好是$15$公斤或$16$公斤。它可能是$15.3$公斤，或$15.32$公斤，或$15.3218...$公斤，其精度仅受我们磅秤的限制。这就是**连续性结局**的本质。原则上，它可以在给定范围内取任何值。可以把它想象成楼梯和坡道的区别。在楼梯上，你只能站在离散的台阶上。而在坡道上，你可以站在其长度上的任何位置。

自然界充满了连续性结局。患者收缩压的变化、血液中生物标志物的浓度、田野里蜜蜂的丰度、树木的高度——所有这些都是我们测量而非计数的量。在一项关于郊狼的引人入胜的生态学研究中，研究人员记录了几种类型的数据[@problem_id:1848160]。捕获地点（“城市”、“郊区”、“乡村”）是一个**分类**变量；这些只是标签，就像把东西放进不同的盒子里。从1到5的恐惧评分是一个**有序**变量；存在顺序（5比4更恐惧），但1和2之间的“距离”可能与4和5之间的距离不同。但是，以公斤为单位测量的郊狼体重，则是一个经典的连续变量。

有趣的是，即使是一些计数，比如一窝幼崽的数量，在统计分析中也常常被当作连续变量处理，尤其是在数值较大时。虽然你不能有半只幼崽，但为连续性数据设计的数学工具通常足够强大和稳健，可以为此类计数数据提供出色的近似和深刻的见解[@problem_id:1848160]。

### 万物中心：描述一个连续的世界

好了，我们测量了一百个人的血压。我们得到了一百个数字的列表。现在怎么办？一长串数字并不是知识。我们需要一种方法来总结它，来抓住它的本质。我们需要找到它的“中心”。思考这个问题有几种绝妙的方式。

最常见的是**均值**，即平均数。你知道计算方法：将所有值相加，然后除以值的数量。样本均值，记作$\bar{x}$，是我们根据数据对真实的、潜在的总体均值（用希腊字母$\mu$表示）的最佳猜测。[总体均值](@entry_id:175446)$\mu$是一个深刻的概念；它是我们测量值的“[期望值](@entry_id:150961)”$\mathbb{E}[X]$，是所有可[能值](@entry_id:187992)分布的重心[@problem_id:4545927]。如果你把血压的分布想象成一个用木头雕刻出来的物体，均值就是它能完美平衡的点。

但均值可能会被欺骗。想象一下我们这一百人中，有一个人的血压异常高。这一个极端值会把均值向上拉，使其不再像是“典型”的中心。在这种情况下，我们可能更倾向于使用**[中位数](@entry_id:264877)**。[中位数](@entry_id:264877)就是中间的那个值：一半的人血[压比](@entry_id:137698)它高，一半的人比它低。它很稳健；它不关心异常值有多极端，只关心它们是在一侧还是另一侧。它是将总体一分为二的值$m$，满足低于$m$的概率最多为$\frac{1}{2}$，且等于或低于$m$的概率至少为$\frac{1}{2}$的条件[@problem_id:4545927]。

然后是**众数**，也就是最常见或“最流行”的值。对于像诊所就诊次数这样的离散计数，这很容易找到。但对于像血压这样真正连续的变量，最常见的值是什么呢？由于我们可以测量到越来越精细的精度，可能没有两个人的血压*完全*相同。连续性数据中众数的概念要微妙一些；它是分布的峰值，是测量值最密集聚集的那个值[@problem_id:4545927]。

### 衡量变化：效应的本质

科学很少是关于描述单个群体；它关乎比较群体以理解因果关系。一种新药是否降低了血压？一项保护措施是否增加了[授粉](@entry_id:140665)昆虫的丰度？我们在寻找一种变化，一种“效应”。我们衡量这种效应的方式必须尊重我们连续性结局的性质。

#### 加性世界：均值之差

比较两组最直接的方法是看它们均值的差异。在一项针对新型降压药的临床试验中，我们可以测量治疗组的平均血压变化，并与[对照组](@entry_id:188599)的平均变化进行比较。这给了我们**平均处理效应（ATE）** [@problem_id:4964369]。用潜在结局的语言来说，对于任何个体，如果他们接受治疗，会有一个潜在结局$Z(1)$，如果他们接受对照，则有另一个潜在结局$Z(0)$。ATE是这个差异的平均值，即$\mathbb{E}[Z(1) - Z(0)]$。因为试验是随机的，我们可以简单地通过减去两组的样本均值来估计它。

ATE的美妙之处在于其[可解释性](@entry_id:637759)。如果收缩压的ATE为$-5$ mmHg，这意味着，平均而言，该治疗比对照能多降低5 mmHg的血压。效应的度量单位与结局本身的单位相同。它说着临床的语言。

#### [乘性](@entry_id:187940)世界：比率与对数

有时，自然界不是做加减法，而是做乘除法。一种杀虫剂可能不是将蜜蜂数量减少一个固定的数目，而是减少某个*百分比*。一个栖息地恢复项目可能会使花卉的密度翻倍。在这些情况下，均值的比率比差值更有意义。

为了比较治疗组均值$\bar{X}_T$和[对照组](@entry_id:188599)均值$\bar{X}_C$，我们可以看比率$\bar{X}_T / \bar{X}_C$。然而，比率有一些棘手的统计特性。比率为$2$（翻倍）感觉上与比率为$0.5$（减半）相反，但在数轴上，$2$离$1$的距离比$0.5$离$1$的距离要远得多。为了修正这种不对称性以及出于其他良好的统计原因，我们经常取自然对数。这给了我们**对数响应比（LRR）**，即$\ln(\bar{X}_T / \bar{X}_C) = \ln(\bar{X}_T) - \ln(\bar{X}_C)$ [@problem_id:2522822]。对数将[乘性](@entry_id:187940)效应转化为加性效应。翻倍（$\ln(2) \approx 0.69$）和减半（$\ln(0.5) \approx -0.69$）现在在零点周围完美对称。这是一个研究诸如花卉资源密度等我们预期会发生乘性变化的事物的优雅工具[@problem_id:2522822]。

#### 通用货币：标准化均值差

如果我们想比较一种药物对血压的影响和一种教学方法对考试分数的影响，该怎么办？单位（mmHg vs. 分数）完全不同。我们如何判断哪个效应“更大”？我们需要一种通用的、无量纲的货币。这就是**标准化均值差（SMD）**，通常称为Hedges' g。我们不看均值的原始差异，而是将其除以结局的标准差：$(\bar{X}_T - \bar{X}_C) / S_p$，其中$S_p$是[合并标准差](@entry_id:198759)[@problem_id:2522822]。

SMD告诉我们均值移动了多少个标准差。效应量为$1.0$意味着治疗组的平均值比[对照组](@entry_id:188599)的平均值高出一个完整的标准差。这是一种比较“苹果和橘子”的强大方法，也是Meta分析领域的基石，该领域将来自许多不同研究的结果结合起来。

### 简单的诱惑：[二分法](@entry_id:140816)的危害

连续性结局，以其无穷的灰度，可能让人感觉复杂。人们有一种巨大的诱惑去简化它们，将它们强行塞进一个二元的、非黑即白的世界。我们可以宣布，如果患者的血压下降至少$10$ mmHg，则为“有效”，否则为“无效”。这个过程称为**[二分法](@entry_id:140816)**。

这种简化似乎提供了一个奖品：一个易于理解的指标，称为**需治数（NNT）**。二分后，我们得到治疗组（$p_T$）和[对照组](@entry_id:188599)（$p_C$）中“有效”者的比例。其差值$p_T - p_C$是绝对风险降低（ARR）。NNT就是$1/\text{ARR}$ [@problem_id:4615070]。如果NNT是7，解释就非常简单：“你需要用这种药物治疗7名患者，才能让额外一人获得疗效。”

但这种简单是以巨大的代价换来的。[二分法](@entry_id:140816)丢弃了大量信息。一个血压下降了$30$ mmHg的患者和一个血压下降了$10.1$ mmHg的患者被同等对待。一个血压下降了$9.9$ mmHg的患者和一个根本没有变化的患者也被同等对待。这种信息损失削弱了我们的[统计功效](@entry_id:197129)，意味着我们需要更大规模的研究才能检测到同样大小的效应[@problem_id:4615070] [@problem_id:4558282]。这就像把一张丰富、细节十足的照片简化成一个单一的黑色或白色像素。

更麻烦的是，结果对所选的阈值高度敏感。如果我们把“有效”定义为血压下降$8$ mmHg或$12$ mmHg，我们会得到不同的有效比例、不同的ARR和不同的NNT [@problem_id:4615070]。答案取决于一个通常是武断的决定。

更糟糕的是，这种“简化”会主动误导我们。想象两种药物在连续尺度上没有相互作用；它们的效果是纯粹相加的。如果你对结局进行二分，你可能会在二元尺度上制造出一种“虚假”的统计学[交互作用](@entry_id:164533)。这种虚假[交互作用](@entry_id:164533)的存在与否及其大小完全取决于你划定的界限在哪里[@problem_id:4583893]。看似简化，实际上却创造了一个更复杂、更具欺骗性的画面。虽然NNT对于天然的二元结局是一个有用的概念，但仅仅为了计算它而将丰富的连续性结局转化为贫乏的二元结局是一条危险的道路。

### 直面现实：不完美的测量

到目前为止，我们的旅程都假设我们的测量是完美的。在现实世界中，它们从来都不是。

首先，我们的测量工具可靠吗？如果我们两次测量同一个东西，会得到相同的答案吗？这就是**可靠性**的问题。我们可以通过让病情稳定的患者相隔两周填写同一份抑郁量表来评估其**重测信度**[@problem_id:4993154]。我们可以通过让多名技术人员测量同一个血液样本来检查**评分者间信度**。对于这样的连续性数据，通常使用一种称为**组内相关系数（ICC）**的统计量。这些检查至关重要；一个结论的确定性不会超过其所依据的测量的确定性。

其次，当我们根本无法获得测量值时会发生什么？在一项为期一年的研究中，人们会搬家、厌倦参与或因其他原因退出。这就造成了**[缺失数据](@entry_id:271026)**，这是每个现实世界研究人员都头疼的问题。最坏的情况称为**[非随机缺失](@entry_id:163489)（MNAR）**。当缺失的原因与你试图测量的数值有关时，就会发生这种情况。例如，在一项减肥研究中，那些节食失败的人最有可能退出。仅仅分析留下的人会得出一个对节食效果过于乐观的假象。

我们无法确切知道人们为什么退出。但我们不能视而不见。相反，我们可以进行**[敏感性分析](@entry_id:147555)**。使用一个称为**[模式混合](@entry_id:197206)模型**的框架，我们可以建立一个数学模型，明确陈述我们对缺失数据的假设[@problem_id:4812736]。我们可以说，“让我们假设缺失人群的平均结局比我们观察到的人群差$\delta$个单位。”参数$\delta$是我们的“怀疑旋钮”。它不是从数据中估计出来的，而是由我们选择的。然后我们可以看到，当我们转动这个旋钮时，我们研究的结论会如何变化。如果我们假设[缺失数据](@entry_id:271026)要差很多（$\delta$是一个大的负数），而我们的主要结论仍然成立，那么我们的发现就是稳健的。如果只要我们假设一个极小的负$\delta$值，结论就消失了，那么我们的发现就是脆弱的。这是一种诚实而有力的方式，来面对我们在研究这个连续、混乱而又美丽的世界时不可避免的不确定性。

