## 应用与跨学科联系

在掌握了赋予学术中介人原则活力的各项原则之后，我们现在踏上一段旅程，去看看它在实践中的应用。如同科学或法律中任何真正基本的原则一样，其美妙之处不在于抽象的陈述，而在于它为复杂多变的世界带来清晰度的力量。我们将从熟悉的医生办公室出发，走向人工智能的前沿，甚至深入生命本身的蓝图，探索这个单一而优雅的理念如何帮助我们理清现代医学中错综复杂的责任网络。

### 船长

想象一家药品制造商就像一个造船商。他们建造了一艘船——一种新药——专为特定目的而设计。他们知道它的优点、速度和载货能力。但他们也知道它隐藏的危险：它在暴风雨中的表现、结构弱点以及可能失灵的条件。造船商不可能知道每艘船将航行的具体水域或将面临的每场风暴的独特性质。那么，他们的责任是什么呢？他们编写一本全面的手册，详细说明所有已知的风险和操作参数，然后交给一位专家：船长。

这位船长就是医生。病人是珍贵的货物，他们特定的疾病是要航行的海洋。医生，作为“学术中介人”，拿着制造商的手册，但将这些知识与自己的专业知识相结合，最重要的是，结合他们对病人独特状况、病史和需求的深入了解。最终由医生决定是否起航，规划何种航线，以及向乘客发出关于前方旅程的具体警告。

学术中介人原则的核心正是尊重这种分工。制造商的责任是给医生一本诚实而完整的手册。如果他们做到了，而医生运用其专业判断做出导致伤害的决定——例如，推荐药物的“标签外”使用，用于手册中未列明但有新兴研究支持的病症——那么该判断的责任就在于医生。制造商受到保护。然而，这种保护并非豁免权；它是有条件的。医生对病人的责任，即知情同意的责任，是一项独立而神圣的责任。它需要的是一次对话，而不仅仅是一张处方。医生必须解释所选择的航线、其原因、所涉及的风险（尤其是在未知水域航行时），以及可供选择的其他路线。该原则保护了编写了良好手册的造船商，但它从未免除船長明智导航和清晰沟通的责任[@problem_id:4509250]。

### 车间与流水线

医学界很少像一个制造商、一个医生和一种药片那么简单。以一个现代牙冠为例。材料制造商可能会生产一块高科技氧化锆块，并附有详细的使用说明，包括针对某些可能削弱其强度的程序的关键警告。这块材料随后被送到牙科实验室，该实验室作为次级制造商，将其研磨和[烧结](@entry_id:140230)成特定病人的定制牙冠。最后，成品牙冠到达牙医手中，由牙医进行最终调整并安装在病人口中。

如果牙冠失效并造成伤害，会发生什么？学术中介人原则帮助我们理清这条责任链。如果牙医，或许是依赖于某次会议上学到的新技术，无视制造商的明确警告，用禁忌化学品处理了牙冠，他们就破坏了正确使用的链条。他们不再是一个简单的中介，而成为了产品的积极改造者。在这种情况下，他们的责任并非源于销售有缺陷的产品，而是源于专业疏忽——即未能遵守护理标准。实验室也不仅仅是一个管道；通过执行像烧结这样的关键制造步骤，它为其过程中的部分承担了制造商的责任。因此，该原则显示了其灵活性，区分了那些*制造*物品的人（他们受到产品责任标准的约束）和那些提供*服务*的人（他们受到专业疏忽标准的约束）[@problem_id:4759270]。

### 机器中的幽灵

现在，我们转向该原则在一个世纪以来面临的最深刻挑战：人工智能的崛起。当一个人工智能系统协助诊断时，谁是学术中介人？答案远非简单，因为责任分散在整个数字供应链中。

想象一个人工智能诊断工具未能在胸部X光片上发现危及生命的病症。病人受到了伤害。在调查中，我们发现了一连串的失误。人工智能的开发者知道该模型在处理来自某些扫描仪的图像时准确性较低，但推迟了补丁更新。另一家将该人工智能集成到医院系统中的公司调整了其设置以减少滋扰性警报，无意中增加了漏掉真实发现的风险，并且未能根据医院的特定设备重新验证它。医院方面，由于官僚主义的积压，数月未应用开发者的补丁，也未能对其员工进行关于人工智能已知局限性的适当培训。最后，临床医生在一个繁忙的班次中，由于“自动化偏见”，简单地相信了人工智能的“一切正常”信息，而没有按照医院政策进行独立的审查[@problem_id:4400488]。

在这里，学术中介人原则被推到了极限。开发者可能会争辩说它警告了“中介”，但那是谁？医院？集成商？临床医生？如果警告只是埋藏在仅发送给IT部门的技术手册中，从未到达数字化的第一线的临床医生手中，那么这个警告就是不充分的[@problem_id:4494857]。如果医院收到了警告但主动压制它，也许是为了避免让用户界面因警报而混乱呢？[@problem_id:4436682] 在这些情况下，清晰的责任界限变得模糊。简单的“造船商-船长”类比失效了，取而代之的是一个共同的过错模型，其中开发者、集成商、医院和临床医生都可能承担部分责任。

当人工智能供应商采取两种现代做法时，该原则进一步受到侵蚀。第一是使用难以理解的最终用户许可协议（EULA）试图免除所有责任。作为一个基本的公共政策问题，供应商与医院之间的合同不能简单地抹去受伤病人寻求赔偿的权利。病人不是该合同的一方，他们的安全不能在细则中被交易掉。当供应商故意隐瞒缺陷时，例如人工智能模型在特定患者亚组中表现不佳，这一点尤其适用[@problemid:4400484]。

第二是该原则的一个老对手的回归：直接面向消费者的广告。经典的原则依赖于医生作为信息的守门人。但当人工智能供应商的网站宣称“请您的医生使用 MedPredict AI 进行更安全的诊断！”时会发生什么？通过直接向公众营销，供应商故意绕过了中介。当他们积极通过患者需求来影响医生的判断时，他们不能再声称完全依赖医生的判断。这样做，他们创造了一个直接警告患者的新平行责任，学术中介人原则的保护罩也随之消失[@problem_id:4494882]。同样的逻辑也适用于供应商将其人工智能宣传为“自主的”的情况，这实际上鼓励临床医生放弃他们作为机器制衡者的角色，从而破坏了该原则所依据的根本基础[@problem_id:4486718]。

### 编辑我们的未来

最后，我们来到了生物学本身的前沿：[生殖系基因编辑](@entry_id:271207)。一个为药片和手术刀而制定的法律原则，能适用于一种可以改变人类物种的技术吗？答案出人意料地是肯定的。其根本逻辑一如既往地强大。

设想一家公司生产用于生育诊所的[CRISPR](@entry_id:143814)试剂。这些试剂是终极的“仅限处方”产品，需要极高的专业知识。制造商知道潜在的风险——脱靶编辑、嵌合现象，甚至是在临床前数据中看到的未来健康问题的微妙信号[@problem_id:4485789] [@problem_id:4863323]。根据学术中介人原则，他们的责任是向生育诊所提供一份极其诚实的“手册”，详细说明所有已知和可预见的风险。

诊所的医生随后成为最深远意义上的中介。他们进行的对话不仅关系到一个人的健康，而且关系到一个未来人类及其所有后代的蓝图。如果干预不是为了治疗一种可怕的疾病，而是为了“增强”——将某个特征增强到超出典型范围——那么伦理上的风险将被极大地放大。对于选择性的增强，风险的容忍度必须接近于零。医生确保真正知情同意的责任变得巨大，他们必须清楚地区分[治疗与增强](@entry_id:190473)，并讨论巨大的、跨代的未知因素[@problem_id:4863323]。如果诊所在这一责任上失职，他们的责任是明确的。但如果制造商在给诊所的警告中未能披露一个可预见的风险，它就不能躲在诊所的失誤后面。制造商仍然要承担责任。

### 不变的原则

从普通药物的标签外使用，到我们自身基因组的可遗传编辑，学术中介人原则展现的不是一个静态的规则，而是一个动态的推理原则。它是在一个充满专业知识的世界里分配责任的框架。它提醒我们，巨大的权力伴随着巨大而具体的责任。创造者的责任是告知专家。专家的责任是为了他们手中掌握的生命，运用明智的判断。在我们日益复杂的技术世界里，这种优雅的责任分工比以往任何时候都更加重要。它是一项法律原则，是的，但它也是一项信任原则，而这是一项永恒的原则。