## 应用与跨学科联系

我们的生活伴随着时钟的滴答声，我们也习惯了以同样的方式看待数据——如同一串整齐有序的点，每一点之间都隔着均匀的时间间隔。我们以每秒44,100次的频率对声波进行采样，以每秒24帧的频率对电影进行采样。这种规律性令人安心；它是我们信号数学大部分内容的基础。快速傅里叶变换，这个[数字信号处理](@entry_id:263660)的强大引擎，正是这种有序世界所带来的强大功能和效率的证明。

但如果滴答声不规律会怎样？如果数据点断断续续地到来，中间夹杂着长久的沉默呢？事实证明，大自然很少如此井然有序。来自遥远恒星的光被飘过的云层阻挡，偏远森林中的传感器只有在太阳能电池充电时才会传输数据，医生只在病人看起来不舒服时才开具验血单。这就是不规则或*非相干*采样的世界。而最迷人的是，这同一个概念以两种截然不同的面貌呈现在我们面前。一方面，它是一项艰巨的挑战，是一头我们必须学会驯服的混乱猛兽。另一方面，它是一种超能力，是我们用来制造能完成昔日不可能任务的机器的秘钥。

### 作为超能力的非相干采样：以少见多的艺术

想象一下，你正躺在医院里，即将进入一台[磁共振成像](@entry_id:153995)（MRI）机器。它是一台了不起的设备，但它也很慢。一次扫描可能需要漫长而嘈杂的几分钟。原因在于，从某种意义上说，这台机器正试图逐个像素，或者更准确地说，逐个频率地“拍摄”你身体内部的“照片”。它通过以规则的、逐行的方式收集信息来细致地构建图像。而彻底改变了医学成像的问题是：非得如此吗？

解剖图像，像大多数自然世界的图片一样，具有一个特殊属性：它们是*稀疏*的。这并不意味着它们大部分是空的，而是指它们可以用惊人少的信息量来描述。想象一幅简单的线条画；你不需要指定页面上的每一个白点，只需要指定黑色的线条。以一种更复杂的方式，医学图像在[小波变换](@entry_id:177196)等数学域中是稀疏的。它们是由少数几个基本的“笔触”构成的，而不是一团由随机值组成的混乱。

压缩感知是一个美妙的想法，即如果一个信号是稀疏的，你不需要测量它的全部信息就能知道它是什么。但这里有一个关键点，而且非常重要。如果你只是以规则的方式跳过测量——比如，每隔一行测量一次——你会得到可怕的、幽灵般的伪影。诀窍，也是问题的核心，在于进行*非相干*采样。MRI机器被编程为以伪随机、分散的模式跳跃式地测量频率，而不是遵循一个规则的模式。

为什么这能行得通？通过非相干采样，那些原本会是结构化且致命的伪影，被涂抹成了看起来像随机的、低水平的噪声。现在，奇迹发生了。我们有两样东西：一幅微弱、充满噪声的[欠采样](@entry_id:272871)图像，以及一条先验知识——*真实*的图像是稀疏且清晰的。一个强大的优化算法便可以扮演侦探的角色。它实质上是在说：“请找到与我实际获取的少数测量值相符的最[稀疏图](@entry_id:261439)像。”该算法有效地对图像进行[去噪](@entry_id:165626)，并在此过程中，完美地填补了我们从未测量过的大量信息 [@problem_id:4891211]。这不是近似；在适当的数学条件下——即稀疏性、非[相干性](@entry_id:268953)以及一个相关的概念“有限等距性质”——重建可以被证明是精确的。结果呢？MRI扫描速度提高数倍，这对焦虑的患者、繁忙的医院和哭泣的儿童来说是一项巨大的益处。

故事还有更精彩的后续。这种超能力可以与其他能力相结合。在[并行成像](@entry_id:753125)中，我们使用一个由多个接收线圈组成的阵列，每个线圈都像一只独立的“眼睛”，拥有自己独特的空间视角。每个线圈“看到”的细微差别提供了另一层信息编码。当这与[压缩感知](@entry_id:197903)的非相干采样相结合时，其协同效应是显著的。线圈的多样性有助于进一步解开混叠伪影，从而实现比单一技术更激进的[欠采样](@entry_id:272871)和更快的扫描速度 [@problem_id:4870658]。

我们还可以更进一步，从拍摄静态图片到拍摄动态影片。在动态成像中，我们希望看到过程随时间展开，例如注射造影剂后血液在大脑中的流动。这里的目标不仅是获得清晰的图像，更是获得信号强度如何逐刻变化的*定量准确*的测量。这对于计算血流量和诊断中风至关重要。通过在空间和时间上（`k-t`采样）进行非相干采样来加速这些扫描是可能的，但这需要精细的处理。如果重建算法在其对时间上的“稀疏性”或平滑性的假设上过于激进，它可能会人为地削平我们正试图测量的动态峰值，导致制作出的影像虽然精美，但给出的答案却是危险的错误 [@problem_id:4906235]。这是一个深刻的提醒：能力越大，责任越大；我们不仅必须了解我们的工具如何工作，还必须了解它们可能出现故障的微妙方式。

### 自然的挑战：驯服野生数据

到目前为止，我们一直是主宰者，为我们的利益设计非相干采样。但当我们无法控制时，会发生什么？如果世界给我们的是本身就不规则的数据呢？这不再是我们挥舞的工具，而是观测的根本挑战。在这里，我们对非[相干性](@entry_id:268953)的思考必须从设计转向分析。

#### 在混沌中洞见节律

想象一位神经科学家正在倾听少数脑细胞微弱的电信号交流，或是一位[古气候学](@entry_id:178800)家正在钻探古老的[冰芯](@entry_id:184831)。他们都在寻找隐藏的周期，这些周期性可能揭示思想的节律或地球古气候的脉动。然而，他们的数据一团糟。神经记录中充满了丢失的数据包；任何给定冰层的年龄都是不确定的，样本是在不均匀的深度采集的。

如果他们将这些不规则间隔的数据输入像[快速傅里叶变换](@entry_id:143432)这样的标准工具，结果将毫无意义。FFT是规则网格的产物；其数学上的完美性依赖于在均匀间隔[上采样](@entry_id:275608)的[正弦波和余弦波](@entry_id:181281)的严格正交性。在不规则网格上，这种正交性被打破，一个频率的能量会“泄露”到整个[频谱](@entry_id:276824)中，造成一团扭曲的混乱 [@problem_id:4073688]。

解决方案是一种非常优雅的算法，称为[Lomb-Scargle周期图](@entry_id:181077)。Lomb-Scargle方法不是通过插值（这个过程本身会产生伪影）将数据强制放到一个均匀网格上，而是根据数据自身的条件来处理数据。对于它想要测试的每个频率，它直接对分散的、不规则的数据点进行正弦波的完全[最小二乘拟合](@entry_id:751226)。它会问：“一个*特定频率*的正弦波能在多大程度上解释我实际拥有的数据，无论这些数据点位于何处？”通过对一系列频率执行此操作，它可以构建一个对数据间隙和不规则间距具有鲁棒性的[功率谱](@entry_id:159996)。这与神经科学家分析脑电波和天体物理学家分析变星闪烁光芒所面临的基本问题是相同的，而这个解决方案揭示了在广阔的科学领域中，信号处理原理的深层统一性 [@problem_id:4138565]。

#### 跨越间隙

让我们从频域转向时域。假设我们正在追踪一个变化的系统——患者血液中药物的浓度，或是一颗经常被云层遮挡的卫星所观测到的远方森林的健康状况 [@problem_id:3799307]。我们有一个数学模型，一组[微分](@entry_id:158422)方程，告诉我们系统*应该*如何表现。但我们的测量是不规则的。我们如何更新我们的知识并在数据间隙中追踪系统？

答案在于一种处理不确定性的原则性方法。[卡尔曼滤波器](@entry_id:145240)（Kalman filter）为此提供了一个完美的框架 [@problem_id:3895455]。把它想象成在茫茫雾海中追踪一艘船。当我们得到一次测量（瞬间瞥见船只）时，我们更新对其位置的估计。在下一次瞥见之前的漫长雾霭中，我们使用船的动力学模型和洋流来预测它的新位置。但我们也知道，随着时间的流逝，我们的预测变得越来越不确定；船只位置周围的不确定性圈子越来越大。[卡尔曼滤波器](@entry_id:145240)将这种直觉形式化。用于传播系统状态及其协方差（我们的不确定性）的方程明确地依赖于时间间隔$\Delta t$。对于我们数据中每一个独特、不规则的间隙，我们都重新计算我们的不确定性增长了多少，为下一次测量做准备。

同样的想法也回响在[现代机器学习](@entry_id:637169)的世界里。高斯过程（Gaussian Process, GP）是一种强大的工具，它不是用一个固定的方程来为时间序列建模，而是通过在一个由所有可能的[光滑函数](@entry_id:267124)构成的宇宙上设置一个概率分布来进行建模 [@problem_id:5199845]。当输入不规则数据时，GP可以做出优雅的、具有不确定性意识的预测。但这种灵活性带来了巨大的计算成本。缺乏规则网格破坏了实现快速计算的数学结构，导致算法的计算复杂度随数据量的增加而急剧恶化。然而，在一个思想交汇的美妙例子中，加速某些高斯过程的最有效方法之一，是认识到它们可以被重塑为[状态空间模型](@entry_id:137993)——这又把我们带回了卡尔曼滤波器！这是一个惊人的例子，说明了来自控制理论的旧思想如何为解锁人工智能新方法的力量提供了关键。

#### 最深的挑战：从随机到意义

我们到达了旅程的最后、最深刻的层面。如果采样不仅是不规则的，而且是*信息性*的呢？如果数据间隙的原因，或样本的放置位置，本身就是故事的一部分呢？

考虑一项新药的临床试验。科学家们必须决定何时从患者身上抽血以测量药物浓度。一种天真的方法可能是每小时采样一次。一种更好的方法是考虑其 underlying 过程。浓度起初会迅速变化，然后变得更慢。为了最好地捕捉这条曲线并估计其参数（如药物的半衰期），应该在开始时更频繁地采样，之后则减少[采样频率](@entry_id:264884)。这是一种设计好的不规则采样形式，是优化实验设计的核心原则，即智能地选择采样模式以最大化知识获取 [@problem_id:5199799]。

但真正令人费解的挑战在于，当采样模式不是我们的选择，而是由我们试图观察的系统本身驱动时。这是分析电子健康记录（EHR）的日常现实。医生不会在随机的时间间隔内安排检查。他们安排检查是因为病人看起来病了。当血糖高到危险时，他们会更频繁地测量血糖。在这个世界里，采样过程与患者潜在的健康状况深度纠缠在一起 [@problem_id:5177997]。

这种“信息性观测”是一个因果雷区。如果我们不小心，可能会得出非常错误的结论。例如，如果我们分析数据发现频繁的血糖测量与更差的结局相关，我们可能会天真地得出结论，认为测量血糖是有害的。当然，事实恰恰相反：恶化的病情*导致*了频繁的测量和不良的结局。用因果推断的语言来说，仅将我们的分析局限于数据被收集的那些时刻，会引入一种有害的选择偏见。解开这些结需要更高层次的精细技巧，将信号处理与因果发现的深刻而微妙的逻辑相结合。

从一个巧妙的工程技巧到一个[科学推断](@entry_id:155119)的根本挑战，非相干采样的概念迫使我们超越均匀网格所带来的舒适幻觉。它推动我们发明更快的医疗扫描仪，设计出新的方法来聆听大脑和地球的节律，并在现实世界混乱、不规则而又美丽的数据中，直面关于因果关系的最深层问题。