## 引言
在许多科学和工程领域，我们都面临着从不完整的测量数据中重建信号或图像的挑战。[稀疏恢复](@entry_id:199430)的突破性进展表明，如果我们寻求的信号具有简单的结构——即仅由少数几个基本元素构成——这是可能实现的。但这也带来了一个关键问题：我们如何能确定我们的测量过程能够唯一地识别出这少数几个元素，而不会被模糊性所迷惑？本文通过引入一个基础概念来填补这一知识空白：[基于相干性的恢复](@entry_id:747455)保证。

接下来的章节将引导您深入了解这一强大的思想。在“原理与机制”一章中，我们将从数学上定义[互相关性](@entry_id:188177)，探讨这个衡量测量向量之间“差异性”的简单度量如何为成功的[信号恢复](@entry_id:195705)带来具体、可证明的保证。我们将揭示[相干性](@entry_id:268953)与矩阵更深层次性质（如 spark）之间的优雅联系。然后，在“应用与跨学科联系”一章中，我们将看到该理论的实际应用，见证相干性如何为从[单像素相机](@entry_id:754911)的设计、科学传感器的最优布置，到机器学习中高级[字典学习](@entry_id:748389)算法的开发等各个方面提供指导。

## 原理与机制

想象一下，你是一名侦探，正在处理一桩奇特的案件。你唯一的证据是一张模糊的现场监控照片，照片上显示了几个涉案人员重叠的影子。你的任务是从一大群嫌疑人中找出他们。如果所有潜在的嫌疑人几乎都是同卵双胞胎，这个任务就不可能完成。他们影子的模糊组合什么信息也提供不了。但是，如果人群中的每个人都截然不同——一个高而瘦，一个矮而胖，第三个戴着一顶巨大的帽子——那么你就有机会了。即使从他们重叠模糊的影子里，你也可能推断出投下影子的究竟是哪些人的独特组合。

这正是我们在[稀疏恢复](@entry_id:199430)中试[图实现](@entry_id:270634)的核心目标。我们的“模糊照片”就是测量数据集 $y$。“嫌疑人”则是构成我们信号的基本特征，即**原子**。这些原子是我们测量矩阵 $A$ 的列向量 $a_j$。我们想要恢复的信号 $x$ 告诉我们*哪些*嫌疑人在场（非零项）以及他们的“量”是多少（这些项的值）。核心假设，也是使不可能变为可能的信念飞跃，是实际上只有少数几个嫌疑人在现场。我们称这个信号是**稀疏的**。

我们的核心挑战是设计一组尽可能彼此不同的“嫌疑人”——即我们的测量矩阵 $A$。我们需要一个系统，其中任何一个原子都不会轻易地被误认为是另一个原子，或者其他原子的组合。捕获这种“差异性”概念的简单、优雅且强大的思想就是**相干性**。

### 衡量“差异性”的数值：定义[互相关性](@entry_id:188177)

我们如何从数学上捕捉原子（它们只是高维空间中的向量）的“差异性”这一概念？最自然的工具是**[内积](@entry_id:158127)**（或[点积](@entry_id:149019)）。对于两个向量，[内积](@entry_id:158127)衡量它们指向同一方向的程度。

在开始比较之前，有一个关键的整理步骤。一个高个子嫌疑人和一个矮个子嫌疑人是不同的，但如果其中一个只是另一个的放大版呢？为了确保对它们的基本形状进行公平比较，我们必须首先将它们归一化到相同的“尺寸”。在向量术语中，我们强制矩阵的每一列 $a_j$ 都具有单位长度，具体来说是单位 **$\ell_2$-范数**：$\|a_j\|_2 = 1$。这一步不仅仅是为了数学上的便利，它是至关重要的。如果我们使用像 $\ell_1$-范数这样的非加权惩罚来寻找“最简单”的解，未归一化的列会隐式地使我们的搜索产生偏好，偏爱范数较大的原子，因为它们需要较小的系数来解释数据 [@problem_id:3433076]。归一化，或使用精心加权的目标函数，确保我们对“稀疏”的定义是公平且无偏的 [@problemid:3433076]。

当所有原子都归一化为单位长度后，它们的[内积](@entry_id:158127) $\langle a_i, a_j \rangle$ 的值就在 $-1$ 和 $1$ 之间。值为 $0$ 意味着它们完全**正交**——尽可能地不同。值为 $1$ 或 $-1$ 意味着它们相同（或方向完全相反），使它们无法区分。

现在我们可以定义一个单一的数字来表征我们整个测量系统。我们查看所有可能的不同原子对，并找到*最*相似的那一对。这种最坏情况下的相似性被称为矩阵 $A$ 的**[互相关性](@entry_id:188177)**，记作 $\mu(A)$：

$$
\mu(A) \triangleq \max_{i \neq j} |\langle a_i, a_j \rangle|
$$

较小的 $\mu(A)$ 意味着我们所有的原子都很好地相互分离；这个字典是**非相干的**。较大的 $\mu(A)$ 意味着我们至少有一对原子危险地相似，这使得我们的侦探工作更加困难 [@problem_id:3435269], [@problem_id:3472196]。

### 保证：非相干性如何确保成功

那么，我们设计了一个具有极小相干性 $\mu(A)$ 的测量矩阵 $A$。这给我们带来了什么？它给我们带来了一个**保证**。一个保证，即如果真实信号 $x_0$ 足够稀疏，那么像**[基追踪](@entry_id:200728)（BP）**（寻找具有最小 $\ell_1$-范数的解）或**[正交匹配追踪](@entry_id:202036)（OMP）**（一种贪婪的迭代方法）这样的算法将能精确地找到它。

将[相干性](@entry_id:268953)与恢复联系起来的优美而著名的结果是一个简单的不等式。如果信号中的非零项数量，即其稀疏度 $k$，满足

$$
k < \frac{1}{2}\left(1 + \frac{1}{\mu(A)}\right)
$$

那么恢复就得到了保证 [@problem_id:3494428], [@problem_id:3472196]。

让我们来解读一下这个不等式。如果我们的字典完全非相干，即所有原子都是正交的，那么 $\mu(A) = 0$。不等式的右边会趋于无穷大，这告诉我们可以恢复任何稀疏度的信号，这是合理的，因为这只是一个标准基。更实际地看，如果 $\mu(A)$ 很小，比如 $\mu(A)=0.01$，那么 $1/\mu(A)=100$，我们可以恢复稀疏度高达 $k < \frac{1}{2}(101) = 50.5$ 的信号。因此，任何具有 50 个或更少非零项的信号都保证能被找到。如果[相干性](@entry_id:268953)很差，比如 $\mu(A)=0.5$，那么 $k < \frac{1}{2}(1+2) = 1.5$，这意味着我们只能保证恢复 1-稀疏信号。

举一个具体的例子，考虑一个简单的 $3 \times 3$ 矩阵，其[相干性](@entry_id:268953)为 $\mu(A) = \frac{1}{4}$ [@problem_id:3435269], [@problem_id:3387260]。条件变为 $k < \frac{1}{2}\left(1 + \frac{1}{1/4}\right) = \frac{1}{2}(1+4) = 2.5$。这个凭证以数学上的确定性告诉我们，任何用该系统测量的 1-稀疏或 2-稀疏信号都可以被完美恢复。

### 幕后原理：相干性技巧為何有效

这个不等式并非魔法；它是通往我们测量矩阵几何学更深层次真理的一条巧妙捷径。确保一个 $k$-稀疏向量是 $y=Ax$ 的唯一最[稀疏解](@entry_id:187463)的真实条件是一个[组合性](@entry_id:637804)条件。它涉及到一个称为矩阵**spark**的属性，记作 $\mathrm{spark}(A)$。spark 是指 $A$ 中线性相关的列的最小数量。

为保证任意两个不同的 $k$-稀疏向量 $x_1$ 和 $x_2$ 產生不同的測量結果（即 $Ax_1 \neq Ax_2$），你需要确保它们的差 $x_1 - x_2$（最多是 $2k$-稀疏的）不在 $A$ 的零空间中。如果 $A$ 的任意 $2k$ 列都是[线性无关](@entry_id:148207)的，这一点就能得到保证。换句话说，你需要 $\mathrm{spark}(A) > 2k$。

这是一个绝佳且直观的条件。问题在于，计算 spark 是一项极其艰巨的任务，形式上是 NP-hard 问题。它需要检查所有 $s=1, 2, \dots$ 的 $\binom{n}{s}$ 个列[子集](@entry_id:261956)的线性相关性。对于任何有实际意义大小的矩阵来说，这在计算上都是不可行的。

这正是相干性之美闪耀之处。虽然计算 spark 很困难，但计算[互相关性](@entry_id:188177)却很简单——它只涉及计算[内积](@entry_id:158127)。而且关键的是，两者之间有直接的联系：

$$
\mathrm{spark}(A) \ge 1 + \frac{1}{\mu(A)}
$$

这个不等式为难以找到的 spark 提供了一个易于计算的下界。现在我们看到了[恢复保证](@entry_id:754159)背后的逻辑。通过要求 $k < \frac{1}{2}\left(1 + \frac{1}{\mu(A)}\right)$，我们确保了 $2k < 1 + \frac{1}{\mu(A)}$。将其与 spark 不等式结合，我们得到 $2k < \mathrm{spark}(A)$。因此，这个易于检查的[相干性](@entry_id:268953)条件作为一个实用的替代品，一个充分条件，服务于那个真实但难以处理的 spark 条件 [@problem_id:3494428]。

### [相干性](@entry_id:268953)的最好与最坏：双城记之矩阵版

[相干性](@entry_id:268953)是一个强大而直观的工具，但它有一个关键特征：它是一个**最坏情况**的度量。它基于字典中相关性最高的一对原子来评判整个字典。这有时可能过于悲观。

考虑一下我们在现代[压缩感知](@entry_id:197903)中喜欢使用的大型**随机矩阵**。对于这些矩阵，可以证明其[互相关性](@entry_id:188177)通常在 $\mu(A) \approx \sqrt{\frac{\log n}{m}}$ 的量级 [@problem_id:3472196]。将此代入我们可靠的恢复公式，表明我们只能恢复稀疏度上限为 $k \approx \sqrt{m/\log n}$ 的信号。这不错，但并不算好。可恢复元素的数量仅随测量次数 $m$ 的平方根增长。事实证明，这是一种悲观的看法。一种更复杂的分析方法，即**[限制等距性质](@entry_id:184548)（RIP）**，它研究列组的集体行为，表明这些相同的[随机矩阵](@entry_id:269622)实际上可以恢复稀疏度高达 $k \approx m/\log n$ 的信号 [@problem_id:3434240], [@problem_id:3474596]。这是一种近線性的關係，要好得多。对于[随机矩阵](@entry_id:269622)，简单的成对相干性保证并不能反映全貌。

但相干性的观点总是悲观的吗？惊人的是，并非如此。存在一些高度结构化的确定性矩阵，对于这些矩阵，基于相干性的保证不僅好，而且是**完全紧密的**。一个很好的例子是**正单纯形框架**，它由 $\mathbb{R}^m$ 中的 $m+1$ 个向量组成，这些向量之间的距离尽可能远。对于这种构造，[相干性](@entry_id:268953)为 $\mu(A) = 1/m$。我们的保证预测对于 $k < \frac{1}{2}(1+m)$ 的情况可以恢复。同时，已知该矩阵的 spark 恰好是 $\mathrm{spark}(A) = m+1$。基于 spark 的基本限制是 $2k < m+1$，即 $k < \frac{1}{2}(m+1)$。这两个条件是相同的！对于这个特殊的矩阵，简单易算的[相干性](@entry_id:268953)揭示了该矩阵恢复能力的全部、未经修饰的真相 [@problem_id:3435268]。

这揭示了一个深刻的原理：保证的质量取决于它所描述的对象。对于随机、非结构化的系统，最坏情况下的成对分析通常过于保守。而对于高度结构化、对称的系统，同样的分析可能精确无比。我们还有**[Welch界](@entry_id:756691)**，这是一个基本定理，指出对于任何 $m \times n$ 矩阵，其[相干性](@entry_id:268953)永远不会小于 $\sqrt{\frac{n-m}{m(n-1)}}$ [@problem_id:3472196]。这为“差异性”设定了一个硬性下限，并告诉我们，从一个*仅仅*基于[互相关性](@entry_id:188177)的保证中，我们所能期望的最好结果就是 $k \approx \sqrt{m}$ 的尺度关系 [@problem_id:3472184]。

### 超越成对分析：一种更精细的视角

对于[随机矩阵](@entry_id:269622)而言，成对[相干性](@entry_id:268953)是悲观的，这一事实表明，成对地看待原子过于简单化了。如果我们考察小组的集体行为会怎样？这引出了[相干性](@entry_id:268953)的一个自然扩展。

与其问“任意两个原子间的最大相关性是多少？”，我们可以问“一个原子与另外 $s$ 个原子组成的*集合*之间的最大总相关性是多少？”。这就引出了**累积[相干性](@entry_id:268953)**（也称为巴别函数），$\mu_1(s)$:

$$
\mu_1(s) \triangleq \max_{\Lambda, |\Lambda|=s} \max_{j \notin \Lambda} \sum_{i \in \Lambda} |\langle a_i, a_j \rangle|
$$

这个函数衡量了集合 $\Lambda$ 外部的一个原子 $a_j$ 可能从该集合内部 $s$ 个原子组成的群组接收到的最大“干扰”。这带来了一个更强的恢复条件。例如，对于[正交匹配追踪](@entry_id:202036)（OMP），如果 $\mu_1(s-1) < 1$，则保证可以恢复一个 s-稀疏信号。

这种更精细的度量可以更清晰地描绘出矩阵的能力。考虑一个仅含有一[对相关](@entry_id:203353)原子，而所有其他原子都正交的矩阵。成对相干性只看到那一个高相关性，并给出一个悲观的保证。然而，累积相干性看到的是，这种相关性是孤立的，且集体干扰很低。在一个具体例子中，一个[相干性](@entry_id:268953)为 $\mu(A)=0.4$ 的矩阵，其可恢复稀疏度的保证可能从[互相关性](@entry_id:188177)条件下的 $s=1$ 跃升到累积[相干性](@entry_id:268953)条件下的 $s=4$ [@problem_id:3435272]。这告诉我们，通过对我们测量系统的几何结构提出更复杂的问题，我们可以得到更强大、更准确的答案，从而为更深入地理解使[稀疏性](@entry_id:136793)发挥作用的美妙数学铺平道路。

