## 引言
视觉 [Transformer](@article_id:334261) (Vision Transformer, ViT) 代表了计算机视觉领域的一次[范式](@article_id:329204)转变，它借鉴了[自然语言处理](@article_id:333975)领域的强大架构，在图像识别方面取得了顶尖成果。但是，一个最初为理解句子序列性而设计的模型，如何学会解释图像的空间二维世界呢？这个问题揭示了一个根本性的挑战：如何弥合文本与像素之间的鸿沟。本文将揭开视觉 Transformer 的神秘面纱，清晰地介绍其内部工作原理及其带来的变革性影响。

接下来的章节将引导您踏上一段从核心理论到实际应用的旅程。在“原理与机制”一章中，我们将解构 ViT，审视其每一个组成部分——从其将图像视为“图像块”的创新方法，到实现全局“对话”的[自注意力机制](@article_id:642355)——这些组件使其能够建立对视觉内容的整体理解。随后，在“应用与跨学科联系”一章中，我们将探索这一架构惊人的多功能性，见证它如何推动计算机视觉的边界，并成为医学成像、气候科学和抽象推理等不同领域的强大工具。

## 原理与机制

既然我们已经打开了通往视觉 [Transformer](@article_id:334261) 世界的大门，现在就让我们步入其中，审视其内部构造。一台为处理语言而生的机器，是如何学会“看见”的？答案并非源于灵光一现，而在于一系列优雅且环环相扣的思想。我们将一步步构建这个卓越的引擎，揭示其强大能力背后所蕴含的物理直觉和数学之美。

### 从像素到图像块：一种新的“看见”方式

对于计算机而言，一张图像就是一个巨大的像素网格。一张标准的一百万像素照片，如果展开成一维序列，对于语言模型来说会过长而难以处理。视觉 Transformer 的第一个天才之举就是根本不去尝试这样做。ViT 并非观察单个像素，而是将图像看作一幅马赛克。

图像被切割成一个由更小的、不重叠的正方形**图像块 (patches)** 组成的网格，就像马赛克中的瓷砖一样。一个典型的图像块大小可能是 $16 \times 16$ 像素。然后，每个图像块被展平为一个向量，并线性投影到特定的维度，成为我们新的视觉语言中的一个“令牌 (token)”或“单词 (word)”。一张图像不再是一个像素网格，而是一个图像块-令牌的序列。

这种分块操作是一种深刻的权衡。它使问题在计算上变得可行，但也付出了代价：损失了精细的细节。想象一个比单个图像块還小的物体。当图像块被处理时——例如通过平均其像素来形成一个令牌——小物体的独特信号会与其背景混合在一起。如果该物体的强度对比不够强，或者被像素噪声淹没，它就可能变得对模型完全不可见。这里存在一个基本的检测极限：一个物体的可检测性取决于其相对于图像块大小的尺寸、信号强度 ($\Delta I$) 和噪声水平 ($\sigma$) [@problem_id:3199228]。这不仅仅是一个技术细节，更是一种物理约束，类似于望远镜的分辨能力。通过选择以图像块的方式“看见”，我们有意地选择了一定程度的模糊性。

### 我在哪里？[位置编码](@article_id:639065)之谜

我们已经将图像變成了一个“圖像塊袋 (bag of patches)”。但这导致了一个关键问题。[Transformer](@article_id:334261) 的核心机制——[自注意力机制](@article_id:642355)——是**[置换](@article_id:296886)不变 (permutation-invariant)** 的。它将图像块-令牌序列视为一个无序集合。如果你像洗牌一样打乱图像块的顺序，[注意力机制](@article_id:640724)本身会对每个图像块产生完全相同的输出。图像固有的几何结构——“天空”图像块在“树”图像块之上这一事实——就丢失了。

为了解决这个问题，我们必须重新引入空间信息。这通过**[位置编码](@article_id:639065) (positional encodings)** 来实现。在图像块-令牌被送入 [Transformer](@article_id:334261) 之前，一个代表其位置的向量被加到每个令牌上。最简单的版本是**绝对[位置编码](@article_id:639065)**，这就像给每块马赛克瓷磚盖上其网格坐标（例如，“第 3 行，第 5 列”）。

为了理解这為何如此关键，不妨考虑一个极簡的思想实验。想象一个 $2 \times 2$ 的网格，其中有两个“A”图像块和两个“B”图像块。假设我们想训练一个模型来识别“A”在主对角线上的[排列](@article_id:296886)。具有这种[排列](@article_id:296886)的图像和“A”在反对角线上的图像包含完全相同的图像块集合。没有位置信息，ViT 从根本上无法分辨其中的差异。但通过添加位置向量，模型可以学会提出诸如“在位置 (0,0) 是否有一个‘A’类型的图像块，并且在位置 (3,3) 是否有另一个‘A’类型的图像块？”这样的问题。[位置编码](@article_id:639065)为模型提供了一个空间模板，使其能够推理物体的*[排列](@article_id:296886)*，而不仅仅是它们的存在 [@problem_id:3199205]。更复杂的模型甚至会学习**相对位置偏置 (relative positional biases)**，这种偏置以一种与绝对位置无关的方式编码了“在左边”或“下方三个图像块”等空间关系，从而赋予模型更灵活的几何感 [@problem_id:3192573]。

### 全局对话：运行中的[自注意力机制](@article_id:642355)

当我们的图像块被正确排序后，我们便来到了这个机器的核心：**[自注意力机制](@article_id:642355) (self-attention)**。这个机制允许每个图像块观察并与图像中的所有其他图像块进行交流。这场“全局对话”是通过每个图像块-令牌生成的三个关键向量来协调的：一个**查询 (Query, $Q$)**、一个**键 (Key, $K$)** 和一个**值 (Value, $V$)**。

你可以这样理解：
-   **查询 (Query)** 是一个图像块在问：“鉴于我自己的内容，哪些其他图像块与我最相关？”
-   **键 (Key)** 是一个图像块在宣告：“这就是我。如果你在寻找像我一样的东西，这是我的键。”
-   **值 (Value)** 是一个图像块在提供：“这是我包含的信息。如果你觉得我相关，这就是你会得到的内容。”

对于每个图像块，其查询向量会与所有其他图像块（包括其自身）的键向量进行比较。这种比较，即[点积](@article_id:309438)运算，会产生一个相似度或“注意力”得分。然后，这些分数通过一个 Softmax 函数进行[归一化](@article_id:310343)，成为总和为一的权重。最后，每个图像块通过对其余所有图像块的值向量进行加权求和来更新其表示。一个“相关”的图像块会获得高权重；一个不相关的图像块会获得接近零的权重。

这个机制令人难以置信的强大之处在于，这些连接不是固定的。与在整个图像上应用相同局部滤波器的[卷积神经网络 (CNN)](@article_id:303143) 不同，ViT 根据图像的实际内容动态地确定连接性。一个人的“头部”可以注意到他们的“脚部”，即使它们位于图像的两端。

然而，这场全局对话的代价极其高昂。注意力机制的[计算成本](@article_id:308397)随图像块数量 $L$ 呈二次方增长。成本主要由一个与 $L^2 D$ 成正比的项决定，其中 $D$ 是[嵌入维度](@article_id:332658)。如果你将图像的高度和宽度加倍，你会得到四倍的图像块 ($L \to 4L$)，而注意力计算成本将爆炸性地增长 16 倍！这个二次方瓶颈是 ViT 的致命弱点，使其在处理高分辨率图像时非常 demanding [@problem_id:3199246]。

即使有这种全局触及能力，其影响也并非总是均匀的。当你堆叠多个注意力层时，一个输出令牌的有效“感受野”可以被可视化。一种称为**注意力 rollout (attention rollout)** 的技术表明，输入图像块对最终输出图像块的影响通常会变得集中，这在精神上类似于 CNN 的感受野，但关键在于，其形状和焦点是动态的，并由图像内容本身决定 [@problem_id:3199184]。

### 幕后英雄：[残差](@article_id:348682)与归一化

拥有一个强大的[注意力机制](@article_id:640724)是一回事；堆叠数十个这样的层来构建一个深度有效的网络则是另一回事。两个简单但至关重要的组件使这成为可能：[残差连接](@article_id:639040)和[层归一化](@article_id:640707)。

**[残差连接](@article_id:639040) (residual connection)**（或跳跃连接）是一种架构上的捷径。它将一个层的输入直接加到该层的输出上。想象一下，将一条[消息传递](@article_id:340415)给一长队人，每个人都会翻译并重述它。[残差连接](@article_id:639040)就像是将原始未经触动的消息副本直接发送到队伍的末尾。这确保了无论经过多少次变换，原始信号都不会丢失。在 ViT 中，这产生了一个 fascinating 的效果。[自注意力](@article_id:640256)块可以被建模为一种高通滤波器，专注于图像块之间的差异和细节。而[残差连接](@article_id:639040)通过加回原始输入，起到低通滤波器的作用，确保来自输入的粗略、“宏观”信息始终被保留并通过网络传播 [@problem_id:3199211]。

**[层归一化](@article_id:640707) (Layer Normalization)** 是第二个英雄。当信号穿过许多层时，它们的幅度要么会缩小到无（[梯度消失](@article_id:642027)），要么会[失控增长](@article_id:320576)（[梯度爆炸](@article_id:640121)）。[层归一化](@article_id:640707)就像是为每个令牌的[特征向量](@article_id:312227)设置了音量控制，在每一步重新校准其均值和方差。这种[归一化](@article_id:310343)的*位置*至关重要。早期的 Transformer 将其置于[残差](@article_id:348682)相加*之后* (post-LN)，这可能导致不稳定。信号的幅度可能会像[复利](@article_id:308073)一样逐层几何级数增长。一个简单而深刻的修正是将其移到注意力块*之前* (pre-LN)。这在输入被处理*之前*对其进行[归一化](@article_id:310343)，从而抑制了爆炸的可能。信号的幅度现在以算术方式增长——就像单利一样——这要稳定得多，并允许训练更深的模型 [@problem_id:3199138]。

### 最后的定论与未来的展望

在经过所有编码器层之后，模型如何做出最终的分类？一种常见的策略是在初始的图像块-令牌序列中添加一个特殊的**类别令牌 (class token)**。这个令牌扮演着指定代表的角色。它参与全局注意力对话，从所有图像块中收集信息，最后，只有它的最终输出向量被用于做出分类决策。这种设计的一个有趣后果是，在最终分类步骤中，梯度信号只直接[反向传播](@article_id:302452)到类别令牌，而不传播到图像块令牌。图像块令牌随后通过早期层中的[自注意力机制](@article_id:642355)间接更新 [@problem_id:3199169]。另一种方法是**[平均池化](@article_id:639559) (mean pooling)**，即将所有图像块令牌的输出平均在一起，形成一个全局图像表示。

视觉 [Transformer](@article_id:334261) 的旅程并未在此结束。为了克服限制其处理低分辨率图像的二次方复杂度，**分层视觉 Transformer (Hierarchical Vision Transformers)** 被开发出来。这些模型，如 Swin Transformer，重新引入了类似 CNN 的层次结构。它们首先在小窗口内局部计算注意力，然后在更深的层次上逐渐合并图像块并扩大注意力窗口。这种金字塔结构极大地降低了[计算成本](@article_id:308397)，使 [Transformer](@article_id:334261) 能够高效处理高分辨率图像，并在广泛的视觉任务上取得顶尖性能 [@problem_id:3199139]。从一个简单、优雅的核心出发，视觉 [Transformer](@article_id:334261) 不断进化，将注意力的全局视角与局部层次结构的效率相融合，并在此过程中，不断重新定义[计算机视觉](@article_id:298749)的边界。

