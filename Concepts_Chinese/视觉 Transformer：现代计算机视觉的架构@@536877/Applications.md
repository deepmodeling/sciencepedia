## 应用与跨学科联系

既然我们已经拆解了视觉 [Transformer](@article_id:334261)，看清了其齿轮和杠杆如何运作，你可能会好奇：“所有这些复杂的机械究竟是*为了*什么？” 这是一个合理的问题。畢竟，一个优美的理论或一个巧妙的工程设计，只有当我们看到它在实际行动中解决真实问题，并且（如果我们幸运的话）揭示出关于世界的新事物时，才真正令人满意。

视觉 [Transformer](@article_id:334261) 的奇妙之处在于，它的核心思想——将一个问题分解成碎片，并让每个碎片与其他所有碎片对话——不仅仅是图像分类的一个新技巧。它是一个深刻普适且强大的原则。事实证明，许多问题，其中一些与猫狗图片相去甚远，都可以用这种方式来思考。当我们退后一步，通过 [Transformer](@article_id:334261) 的视角看待世界时，我们发现自己踏上了一段旅程，它将我们从[医学影像](@article_id:333351)的微观细节带到地球气候广阔、旋转的模式，甚至进入了逻辑推理的抽象领域。让我们开始这段旅程吧。

### 既见森林 *又* 见树木：高级视觉任务

我们从 ViT 的起点——[计算机视觉](@article_id:298749)领域——开始，但我们将把它推向超越简单分类的范畴。考虑像[图像分割](@article_id:326848)这样的任务，其目标不仅是说出物体的名称，还要逐像素地画出其精确的轮廓。传统的[卷积神经网络 (CNN)](@article_id:303143) 从局部特征（如边缘和纹理）逐步建立对物体的理解，就像艺术家在看到整体形态前先勾勒草图一样。这有时会使其难以将物体与杂乱的背景分开，尤其是在边界处。

而 ViT 凭借其全局[自注意力机制](@article_id:642355)，以不同的方式处理这个问题。每个图像块可以一次性从整个图像中收集信息。想象一下斑马边缘的一个图像块。为了判断它属于斑马还是其背后的草地，它可以“询问”其他图像块。它可能会发现与包含黑白条纹的其他图像块（即使是那些在动物另一侧的图像块）有很强的一致性，而与绿色和黄色的草地图像块幾乎没有共同点。这种全局共识使得模型能够形成一个更连贯、更整体的物体理解。事实上，研究人员已经探讨了注意力的“锐度”——即一个图像块是将其目光狭窄地聚焦于少数几个其他图像塊，还是广泛地分散开来——与描绘清晰、准确物体边界的能力之间的关系 [@problem_id:3199195]。

当物体的部分被隐藏或[遮挡](@article_id:370461)时，这种全局视角变得更加关键。假设你正试图识别一只部分被树枝遮挡的鸟。依赖于一连串局部观察的 CNN 可能会因为像鸟喙这样的关键特征被隐藏而感到困惑。它的“[有效感受野](@article_id:642052)”——它能够实际连接的图像区域——可能不够大，无法跨越这个缺口。然而，ViT 不存在这样的限制。显示鸟翅膀的图像块可以直接与显示其尾羽的图像块通信，完全忽略中间的树枝。这种从遥远、不相连的区域拼接证据的能力是一种超能力。它使得 ViT 能够解决那些需要从稀疏的部件集合中识别物体的视觉难题，而在这类任务中，CNN 的局部性可能是一个重大障碍 [@problem_id:3199235]。

### 超越平面：新的维度与模态

ViT 架构真正的优雅之处在于其灵活性。输入仅仅是一个“令牌序列”。虽然我们最初使用的是图像块，但构成“令牌”的内容仅受我们想象力的限制。

如果我们的数据不是平面的 2D 图像，而是 3D 体数据呢？这在医学成像领域是现实，CT 和 MRI 扫描会产生丰富的三维数据集。我们可以应用同样的原则：只需将 3D 体数据切割成一个个小立方体或“体素 (voxels)”的网格，并将每一个视为一个令牌。心脏病专家可以使用这样的模型来分析跳动心脏的 3D 扫描，[Transformer](@article_id:334261) 可以学会将瓣膜的运动与远处心壁的收缩联系起来。

当然，这里有一个问题：[计算成本](@article_id:308397)。[自注意力机制](@article_id:642355)的复杂度随令牌数量的平方增长。一个 $256 \times 256$ 的图像，使用 $16 \times 16$ 的图像块，有 $256$ 个令牌。而一个 $256 \times 256 \times 128$ 的 MRI 扫描，使用 $16 \times 16 \times 16$ 的图像块，有 $2048$ 个令牌！注意力计算量呈爆炸式增长。但在这里，Transformer 原则的美妙之处启发了一个聪明的解决方案：**轴向注意力 (axial attention)**。我们不必一次性计算所有 $2048$ 个令牌间的注意力，而是可以一次只在一个维度或轴上进行。首先，沿所有行（x 轴）计算注意力，然后沿所有列（y 轴），最后沿所有深度管（z 轴）。这种分解极大地降低了计算负担，使得将 [Transformer](@article_id:334261) 的强大能力应用于高分辨率体数据成为可能 [@problem_id:3199168]。

我们还可以加上时间维度。视频畢竟只是一系[列图像](@article_id:311207)。我们可以通过为每一帧创建图像块，然后将它们全部串联成一个长序列来对视频进行令牌化：第 1 帧的图像块，然后是第 2 帧的图像块，依此类推。ViT 随后可以学习[时空](@article_id:370647)关系。来自第 10 帧显示揮舞的网球拍的图像块的查询，可以注意到第 9 帧中球所在位置的图像块，以及第 11 帧中球将要到达位置的图像块。模型可以通过分析注意力模式在空间和时间上的分布来学习运动物理学、人类行为的语法以及事件的叙事 [@problem_id:3199225]。

### 作为科学仪器的 [Transformer](@article_id:334261)

这种对[时空](@article_id:370647)[复杂系统建模](@article_id:324256)的能力，为使用视觉 [Transformer](@article_id:334261) 作为科学发现工具开启了激动人心的前景。

以气候科学领域为例。我们星球的气候是复杂全球系统的典型例子。世界某一部分的事件，如赤道太平洋的厄尔尼诺现象，可以在数千公里之外产生深远且可预测的影响——这种现象被称为**遥相关 (teleconnection)**。对这些[长程依赖](@article_id:361092)关系进行建模是一个核心挑战。ViT 架构天然适合这项任务。我们可以将全球海面温度图视为一张图像，将经纬度网格上的每个点视为一个令牌。全局[自注意力机制](@article_id:642355)原则上可以直接从数据中学习这些遥相关。太平洋的一个令牌可以学会密切关注印度次大陆上空的一个令牌。通过融入地球几何学的知识——例如，通过根据点之间的真实[测地距离](@article_id:320086)为注意力分数添加偏置——我们可以创建出能够尊重其所建模系统底层物理学的强大模型 [@problem_id:3199147]。

也许最令人脑洞大开的应用是使用 Transformer 来学习物理定律本身。许多物理系统由[偏微分方程](@article_id:301773) (PDE) 描述，例如控制温度如何在材料中传播的[热方程](@article_id:304863)。传统上，我们通过使用[有限差分法](@article_id:307573)等[数值方法](@article_id:300571)来模拟这些系统，即下一时刻某一点的值是根据当前时刻其紧邻点的值（一个“模板 (stencil)”）计算出来的。

但如果我们换一种方式来构建这个问题呢？我们可以将时间 $t$ 时的值网格视为一组令牌。任务是预测时间 $t+1$ 时的值网格。可以训练一个 ViT 来完成这个任务。通过设计一个只依赖于令牌相对位置的注意力机制，模型实际上学习了一个通用的模板。它学会了组合一个单元邻居信息以预测其未来状态的最佳方式。在一个非凡的转折中，诞生于自然语言世界的注意力机制，变成了一个能够近似物理系统基本更新规则的“神经算子 (neural operator)” [@problem_id:3199194]。

### 抽象推理的曙光

这段从像素到物理学的旅程表明，ViT 不仅仅是在识别模式，它似乎在学习关系。这暗示了一条通往更抽象、认知任务的道路。

为了清楚地看到这一点，让我们考虑一个简单的谜题。想象一张图片，其中包含几对相距很远的相同形状，以及几个单独的、未配对的形状。任务是计算*配对*的数量。CNN 会完全迷失方向；它会局部地看到每个形状并计算所有形状。然而，ViT 可以轻松解决这个问题。每个形状都变成一个令牌。通过[自注意力](@article_id:640256)，代表一对中一半的令牌可以“环顾”整个图像并找到其相同的伙伴。通过识别这些相互吸引的关系，模型可以忽略单个的形状，并正确地计算出配对的数量 [@problem_id:3199150]。

我们可以更进一步。考虑一个“找不同”的谜题，场景中有四个物体，其中三个共享一个属性（例如，它们都是圆形），而第四个不同（例如，一个正方形）。更复杂的是，这些物体可能还有其他干扰属性，比如不同的颜色。我们可以设计一个 ViT，使其注意力机制可以被“指示”只关注相关属性，比如形状。代表三个圆形的令牌会相互强烈关注，形成一个紧密的 clique（小团体）。而那个孤零零的正方形，由于找不到其他同类，将在关系上被孤立。模型可以通过找到从同伴那里接收到最少传入注意力的物体来识别出那个不同的物体。这是一项了不起的成就：模型不仅仅是在看形状和颜色，而是在基于抽象关系执行逻辑操作 [@problem_id:3199180]。

### 从理论到实践：关于模型适配的尾声

这些令人难以置信的应用固然鼓舞人心，但人们如何才能真正将 ViT 应用于一个新问题呢？一个在像 ImageNet 这样的大型数据集上[预训练](@article_id:638349)的模型已经学会了一套丰富的视觉语法。对于许多任务，我们不需要改变这种底层的知识。我们可以简单地冻结 Transformer 的主体部分，并在其强大的[嵌入](@article_id:311541)之上训练一个新的、轻量级的分类器。这被称为**线性探测 (linear probing)**。

然而，如果我们的新任务与[预训练](@article_id:638349)数据截然不同，或者需要微妙的新特征，我们可能需要进行**全量微调 (full fine-tuning)**，允许模型的所有参数进行调整。这两种策略之间的选择取决于[预训练](@article_id:638349)特征的“可迁移性 (transferability)”。如果特征已经非常适合新任务——意味着它们为新类别形成了良好分离的簇——那么简单的线性探测就足够了。如果特征混杂在一起，就需要更广泛的微调来重塑[嵌入空间](@article_id:641450)本身。这种权衡是大型模型实际应用中的一个核心主题 [@problem_id:3199207]。此外，现实世界的数据很少以完全统一的尺寸出现。在[医学成像](@article_id:333351)等领域应用 ViT 需要巧妙的工程设计来处理可变的输入维度，例如通过使用非方形图像块或复杂的填充和[位置编码](@article_id:639065)[插值方法](@article_id:305952) [@problem_id:3199220]。

从勾画细胞轮廓到为整个地球建模，视觉 [Transformer](@article_id:334261) 已被证明是一个具有惊人广度的架构。其简单、可扩展的全局[自注意力](@article_id:640256)原则提供了一种描述关系的新语言——不仅是句子中的单词之间或图像中的图像块之间，而且是我们选择的任何离散元素集合之间。它证明了伟大思想的统一力量，也让我们得以一窥未来智能系统的 tantalizing  glimpse。