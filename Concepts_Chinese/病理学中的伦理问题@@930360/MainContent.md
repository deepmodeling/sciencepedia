## 引言
病理学领域正在经历一场深刻的变革。它曾一度局限于显微镜下，如今则站在基因组学、大数据和人工智能的十字路口，为我们揭示人类疾病前所未有的见解。然而，这种快速发展也引发了远超实验室范围的复杂伦理问题。当患者的组织能够为无数未来研究提供动力时，我们如何尊重其自主权？当诊断得到“黑箱”算法的辅助时，责任应归于何处？本文通过建立一个清晰的伦理框架来应对这些关键挑战。首先，文章探讨了尊重个人、行善和公正的核心原则及其所衍生的机制，从同意模式到人工智能问责制。然后，文章阐述了这些原则在实践中如何应用，探讨了病理学、外科学、遗传学和患者护理之间错综复杂的联系。通过追溯一份患者样本从活检到数字数据的历程，我们可以为实现伦理上健全且科学上先进的医疗实践指明道路。

## 原则与机制

病理学的核心在于个体与科学界之间深刻的关系。它始于一小块用于诊断的组织，即活检样本，但其旅程可以延伸到数据和算法的广阔数字世界，从而塑造医学的未来。要驾驭这段旅程，我们并不需要为每一种新技术都制定一套复杂的新规则。相反，我们发现一些简单而有力的原则——就像音阶中的音符一样——可以组合成一个优雅而稳健的伦理框架。这些原则，主要是**尊重个人**、**行善**和**公正**，是我们不变的指南。

### 一份献给科学的礼物：人体组织 stewardship（管理责任）

让我们从那第一块组织开始。病理医生检查它，作出诊断，病人接受治疗。但剩下的组织，即保存在小蜡块中的材料，会怎么样呢？几十年来，这种剩余组织只不过被看作是一份记录，一个存档标本。然而，其中锁定了疾病的分子秘密。伦理之旅始于一个简单的认识：这个组织不是被遗弃的财产；它是一个人永久的联结。因此，将其用于研究不是一项权利，而是一种特权。这就是**stewardship（管理责任）**原则。

病理医生及其机构成为这份生物学馈赠的管理者。他们的首要职责是行善——即做好事——在这种情况下，这意味着最大化组织的科学潜力以造福社会。但这必须与不伤害的职责[相平衡](@entry_id:136822)。这包括保护患者的诊断材料，确保研究不会耗尽可能需要用于未来临床测试的蜡块 [@problem_id:4355040]。这是一种微妙的平衡，既要将每个标本视为珍贵的发现资源，也要将其视为个人病历中不可或缺的一部分。

### 许可的谱系：从“不”到“如果…就同意”

如果我们要将此组织用于研究，就必须获得许可。这是**尊重个人**的核心，它尊重个体的自主权。最直接的方法是为每一项研究都请求特定的同意。然而，想象一下一个拥有数十年来收集的数十万份标本的病理学档案库。如果科学家想要创建一个包含200个病例的大型数据集，例如组织微阵列（TMA），以研究癌症的长期结局，重新联系每一位患者或其家人将是一项巨大甚至不可能完成的任务 [@problem_id:4355040]。一个要求逐项研究获得同意的系统将使现代医学研究的大部分陷入停滞，从而损害行善原则。

为了解决这个难题，伦理框架不断演进。一个巧妙的解决方案是**广泛同意**。在临床护理时，可以征求患者许可，同意将其剩余组织用于未来未指定的研究。这不是一张空白支票。一个精心设计的广泛同意框架提供了分层选择：患者可能同意用于癌症研究，但不同意用于其他疾病的研究；或者同意在有临床重要发现时被重新联系，但在其他情况下保持匿名 [@problem_id:4352851] [@problem_id:4391629]。它通过提供选择来尊重自主权，同时使生物样本库的巨大科学效用成为可能。

但是，对于在广泛同意普及之前收集的大量组织档案库该怎么办呢？在这里，另一种机制发挥了作用：由机构审查委员会（IRB）监督的**免除知情同意**。如果研究风险极小，免除同意不会对患者权利产生不利影响，并且没有免除同意研究将不切实际，IRB可以免除征得知情同意的需要。为了管理这种情况下的隐私风险，机构通常使用**“诚实中间人”**模型。这个受信任的、独立的中间人掌握着将匿名研究代码与患者身份联系起来的钥匙。研究团队只获得编码数据，而诚实中间人则执行必要的链接，例如链接到癌症登记处以了解患者结局。这个系统巧妙地将科学工作与患者身份分开，在保护隐私的同时，使至关重要的大规模回顾性研究成为可能 [@problem_id:4355040]。

### 数字幽灵：当组织变成信息

在我们的现代世界里，物理组织仅仅是个开始。它所包含的信息——其微观外观、基因密码、分子表达——被转换成数据。一张玻璃载玻片变成了一张十亿像素的全玻片[数字图像](@entry_id:275277)（WSI）[@problem_id:4339561]；一小片组织通过测序仪，生成大量的基因组数据文件 [@problem_id:4435060]。这个创造组织“数字幽灵”的过程带来了新的、微妙的伦理挑战。

人们可能认为，简单地移除患者姓名和病历号——一个称为**去标识化**的过程——就足以确保隐私。但这是一个危险的简单化观点。根据《健康保险流通与责任法案》（HIPAA）等法规，真正的去标识化需要剥离18个特定的标识符，包括日期、具体地点以及任何其他可能被合理用来识别某人的信息 [@problem_id:4339561]。即便如此，“幽灵”仍可能重现。一张全玻片图像可能无意中包含原始玻片标签的照片。更微妙的是，一个包含罕见肿瘤形态或独特基因组谱的数据集，当与其他公开信息结合时，可能会被追溯到单个个体 [@problem_id:4326081]。

这引出了一个关键概念：**持续的管理责任**。一个机构的责任并不会在它与合作者共享“去标识化”数据时结束。伤害的可能性，无论多么小，都持续存在。因此，伦理义务也持续存在。这通过治理检查点来实施。数据访问委员会（DAC）审查使用数据的请求。签署具有法律[约束力](@entry_id:170052)的数据使用协议（DUA），该协议限制合作者可以用数据做什么，禁止试图重新识别个人，并限制任何进一步的共享。这个框架承认风险是情境性的，并且问责制是一个不能在第一环就断裂的链条 [@problem_id:4326081]。

### 黑箱与医生：人工智能时代的问责制

我们患者数据的旅程现在进入了最富未来感的一步：它被用来训练人工智能（AI）模型。一个算法从成千上万张图像中学习识别癌症，或者从基因组数据中预测预后。这些工具拥有巨大的潜力，但它们也代表了终极的“黑箱”。当我们不完全理解机器的推理过程时，我们如何能信任一个决定？

问責制这一伦理原则提供了答案：无论机器提出什么建议，临床团队，即人类病理医生，仍然对最终诊断负责 [@problem_id:4339531]。这一不可妥协的原则迫使我们去问，一个医生需要什么才能负责任地使用AI工具。他们不需要成为计算机科学家，但他们确实需要**透明度**。

透明度并非指查看代码；它关乎理解工具的特性和局限性。这促成了**模型卡**和**数据集说明书**的开发——可以把它们看作AI的“营养标签” [@problem_id:4326091]。一份说明书详细说明了“成分”：训练数据来自何处、患者是谁、样本如何制备，以及数据中存在哪些已知的偏见。一张模型卡描述了最终的“产品”：其预期用途、在不同患者亚组中的性能指标（如敏感性和特异性），以及其已知的局限性或“盲点”。

这份文档不是官僚主义的练习；它直接应用了我们的核心伦理原则。**公正**原则要求我们了解一个模型是否对所有人群都同样有效。如果一个算法主要在来自某一祖源群体的数据上进行训练，它在其他人群上的表现可能会很差，从而导致健康差异 [@problem_s_id:4435060] [@problem_id:4339531]。没有数据集说明书和模型卡，这种危及生命的偏见将仍然隐藏。透明度和问责制是我们确保AI公正、安全地为医学服务的机制。

### 说出真相：不确定性的伦理

旅程最终 culminating 在一个关键的行动中：将发现结果传达给临床医生和患者。假设一个复杂的人工智能模型，输入了患者的肿瘤数据，估计其$5$-年复发概率为$p = 0.18$ [@problem_id:4439098]。报告这个单一的数字很诱人——它听起来精确而权威。但这样做是说一个危险的谎言。

每个测量、每个模型都有不确定性。那个“18%”仅仅是可能性范围中最可能的一点。模型的真实输出可能是一个$95\%$的[置信区间](@entry_id:138194)，比如说，$(0.12, 0.25)$。这意味着患者的实际风险可能低至12%，也可能高达25%。这个范围并非模型有缺陷的标志；它是对预测局限性的诚实反映。以“不想让患者困惑”的家长式姿态隐瞒这种不确定性，是对他们自主权的严重侵犯。它剥夺了他们参与决策的能力——例如，是否为一个可能更接近12%而非18%的风险接受积极的化疗。

伦理沟通要求我们呈现全部真相：估计值、其不确定性及其背景。这意味着要解释该模型是**预后性的**（估计疾病的自然病程），而不一定是**预测性的**（估计对特定治疗的反应）。这意味着要指出模型的局限性，例如它是在不同的患者群体上训练的 [@problem_id:4439098]。

最后，我们发现了一种美妙的统一性。从物理组织蜡块的管理责任到算法不确定性的透明报告，同样的原则都在适用。良好的伦理就是良好的科学，并将其体现出来。它是一种严谨的诚实，承认我们知道什么，我们不知道什么，以及我们对那个使其所有知识成为可能的数据来源——人——所应有的尊重。

