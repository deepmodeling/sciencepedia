## 引言
我们如何衡量学习？虽然我们通常将其理解为获取事实，但一个更根本的定义是减少不确定性。每当我们做出一个消除模糊性的观察——从抛硬币到进行复杂的科学实验——我们都在获取信息。这个简单而深刻的思想为知识提供了一种通用货币，将能量的物理定律与计算的逻辑以及发现过程本身联系起来。然而，核心挑战在于如何将这一概念从直观的认知转变为可用于做出最优决策的量化工具。

本文全面概述了信息增益——这一用于衡量不确定性减少的正式方法。在接下来的章节中，我们将首先探讨信息增益的**原理与机制**，揭示其与[热力学熵](@entry_id:155885)的深层联系，并从 [Claude Shannon](@entry_id:137187) 的信息论视角对其进行定义。然后，我们将遍历其多样的**应用与跨学科联系**，揭示最大化信息增益这一单一原则如何赋能[机器学习算法](@entry_id:751585)、指导前沿科学研究，甚至解释从混乱中创造秩序的[生物过程](@entry_id:164026)。

## 原理与机制

真正学会某件事意味着什么？我们可能会说这是关于获取新知识，但更深层次的思考方式是将其视为不确定性的减少。在你抛硬币之前，你对结果是不确定的。硬币落地后，你的不确定性消失了。你*获得了信息*。这个看似简单的想法是现代科学中最深刻的概念之一，它将热与能量的物理学与计算机的逻辑以及发现的本质联系在一起。它是我们衡量知识本身的标尺。

### 知识的货币：什么是信息？

让我们从最简单的情况开始。想象一位实验物理学家有一个[非偏振光](@entry_id:176162)源和一个可以测量单个光子并确定其偏振是“水平”还是“垂直”的设备 [@problem_id:1978336]。在测量之前，两种结果的概率各为50/50。这是一种最大不确定性的状态。测量之后，结果是确定的——比如说，“水平”。不确定性消失了。在这个过程中，我们获得了信息论学者所说的一**比特**信息。

这不仅仅是一个哲学上的说法。在20世纪60年代，物理学家 Rolf Landauer 证明了获取信息具有真实的物理后果。他指出，在计算系统中擦除一比特信息，至少必须以热量的形式向环境中耗散一定量的能量。反过来看，获取一比特信息对应于存储该信息的[记忆系统](@entry_id:273054)的[热力学熵](@entry_id:155885)可能达到的最小减小量。对于我们物理学家的探测器来说，成功记录光子状态会使其记忆体的熵减少 $k_{B}\ln 2$，其中 $k_B$ 是连接原子微观世界与温度宏观世界的著名玻尔兹曼常数。事实证明，[信息是物理的](@entry_id:276273)。

这个基本单位——比特——产生于一个有两种[等可能结果](@entry_id:191308)的情境。如果有更多可能呢？假设一个未来的纳米级设备通过将一个粒子定位到20个可能状态之一来存储信息 [@problem_id:1666616]。在写入操作之前，粒子可能以相等的概率处于20个状态中的任何一个。通过将其强制置于一个特定状态，我们消除了这种不确定性。我们获得了多少信息？

信息量是通过可能性的数量的对数来衡量的。对数的底数仅仅定义了我们使用的单位，就像我们可以用米或英尺来测量长度一样。
-   如果我们使用以2为底的对数，信息以**比特**（bits）为单位：$I = \log_{2}(20)$ 比特。
-   如果我们使用自然对数（以 $e$ 为底），单位是**奈特**（nats）：$I = \ln(20)$ 奈特。
-   如果我们使用以10为底的对数，单位是**哈特利**（hartleys）：$I = \log_{10}(20)$ 哈特。

“奈特”是与物理学联系的自然单位。[热力学熵](@entry_id:155885)减少 $\Delta S$ 对应于信息增益 $I_{\text{nats}} = \Delta S / k_B$。因此，对于我们这个有20个状态的设备，$\ln(20)$ 奈特的信息增益对应于 $k_B \ln(20)$ 的[热力学熵](@entry_id:155885)减少 [@problem_id:1666616]。原理是相同的：我们消除的可能性越多，我们获得的信息就越多。

### 发现的引擎：作为不确定性减少的信息增益

在现实世界中，我们很少一步就从完全不确定走向绝对确定。更多时候，我们是逐渐减少我们的无知。一次观察会使某些可能性变得更小，而另一些可能性变得更大。这种不确定性的*减少*就是我们所说的**信息增益**。

为了量化这一点，我们需要一种衡量不确定性本身的方法。这个工具就是**[香农熵](@entry_id:144587)**，用字母 $H$ 表示。以“信息论之父” [Claude Shannon](@entry_id:137187) 的名字命名，熵是一个捕捉概率分布中固有的不可预测性或“惊奇”程度的数字。对于一个可以取不同状态的变量，如果所有状态或多或少都等可能，那么熵就高。如果某个状态的概率非常高，而其他状态的可能性很小，那么熵就很低。例如，一枚99%时间正面朝上的不均匀硬币的熵，远低于一枚均匀硬币的熵。

有了这个工具，我们得出了核心定义：

**信息增益 = 观察前的熵 – 观察后的熵**

这个定义是贝叶斯推断的引擎，这是一个根据新证据更新我们信念的正式框架。想象一下，科学家们正在研究一个复杂的环境系统，比如一个河流集水区。他们有一个包含某些未知参数 $\theta$（例如，土壤属性）的模型。他们对这些参数的初始信念由一个**先验概率分布** $p(\theta)$ 描述，该分布具有一定的熵 $H(\theta)$ [@problem_id:3928015]。这个熵代表了他们最初的不确定性。

然后，他们收集一些数据 $y$——比如说，河流[流量测量](@entry_id:272047)值。利用贝叶斯规则，他们将[信念更新](@entry_id:266192)为一个**后验概率分布** $p(\theta \mid y)$，这个分布现在有了一个新的、希望是更小的熵 $H(\theta \mid y)$。从这个特定观察 $y$ 中获得的信息增益就是熵的减少量：$\Delta H = H(\theta) - H(\theta \mid y)$。

这里出现了一个有趣的微妙之处。一次观察有没有可能*增加*我们的不确定性？令人惊讶的是，答案是肯定的！假设你几乎确定你的朋友在家。你关于他们位置的先验熵非常低。然后，你收到一条来自他们的奇怪、乱码的短信，似乎暗示他们可能去了另一个国家旅行。这个“令人惊讶”的观察可能会粉碎你的信心，迫使你考虑更多的可能性。你关于他们位置的后验分布会变得宽泛得多，你的熵实际上会*增加* [@problem_id:3928015]。

然而，虽然单个数据点可能具有误导性，但收集数据的过程*平均而言*不会让我们变得更无知。在一个实验可能产生的所有可能结果上取平均，[期望信息增益](@entry_id:749170)总是大于或等于零。这个期望增益是一个具有根本重要性的量，被称为**互信息**，$I(\theta; Y)$。它表示我们通过观察 $Y$ 获得的关于 $\theta$ 的平均不确定性减少量。它也具有优美的对称性：它同样也是我们通过知道 $\theta$ 获得的关于 $Y$ 的平均不确定性减少量。它量化了两个变量共享的信息量。

### 将信息付诸实践：从分类器到实验

最大化信息增益的概念不仅仅是一个理论上的精巧构思；它是一个强大而实用的工具，用于做出最优决策。

#### 提出正确问题的艺术（[决策树](@entry_id:265930)）

考虑一个金融机构，试图建立一个简单的模型来预测新申请人是否会拖欠贷款 [@problem_id:2386919]。他们有一个包含过去客户的大型数据集，包括他们的财务细节（特征）和他们最终是否违约（类别标签）。目标是创建一个流程图——一个**[决策树](@entry_id:265930)**——通过一系列简单的问题来引导预测。

它应该先问哪个问题？“申请人的收入是否大于50,000美元？”还是“申请人是否有现有抵押贷款？”最好的问题是那个信息最*丰富*的问题——即那个本身最能区分违约者和非违约者的问题。换句话说，我们应该选择那个能提供关于类别标签的最大**信息增益**的问题。

其工作原理如下：
1.  我们从树的“根”节点开始，使用整个数据集。我们计算类别标签（违约 vs. 非违约）的香农熵。这是我们初始的不确定性。
2.  对于一个候选问题，比如“收入 > 5万美元？”，我们将数据集分成两组：“是”和“否”。
3.  我们分别为每个组计算熵。
4.  分割后的最终熵是两个子组熵的加权平均值。
5.  这个问题的信息增益是初始熵减去这个最终的加权平均熵。
6.  我们对所有可能的问题重复这个过程，并选择信息增益最高的那一个。然后在每个新节点上递归地重复这个过程，从而构建树。

在实践中，决策树通常使用熵的一个近亲，称为**[基尼不纯度](@entry_id:147776)**。[基尼不纯度](@entry_id:147776)有一个很好的概率解释：如果你从一个节点中随机选择两项，它们具有不同标签的概率 [@problem_id:2386919]。像熵一样，它衡量一个节点的“混乱”程度，目标是选择能最大化其减少量的分割。

这种方法还必须应对现实世界数据的缺陷。在[高能物理](@entry_id:181260)等领域，数据集可能存在严重的类别不平衡（例如，每有一个潜在的信号事件，就有数百万个背景事件），并且必须对事件进行加权以反映其重要性 [@problem_id:3524152]。在其他情况下，训练数据中的标签可能有噪声或不正确 [@problem_id:3168105]。有趣的是，[基尼不纯度](@entry_id:147776)和熵的数学特性使它们在这些棘手情况下的行为略有不同。例如，[基尼不纯度](@entry_id:147776)受对称[标签噪声](@entry_id:636605)影响的方式是一个简单的缩放，这意味着最佳分割的选择保持不变。而对于熵，影响更为复杂，原则上可以改变最优分割，揭示了度量选择与学习[算法鲁棒性](@entry_id:635315)之间的深层联系 [@problem_id:3168105]。

#### 智能实验的科学

最大化信息增益的力量远远超出了构建分类器的范畴。它甚至可以告诉我们首先应该进行哪些实验。这就是**[贝叶斯最优实验设计](@entry_id:746727)**的领域。

假设我们有一个带有未知参数 $\theta$ 的科学模型，并且我们想设计一个实验 $d$ 来了解它们 [@problem_id:3380352] [@problem_id:3736284]。“设计”可以是我们控制的任何东西：温度、压力、我们采样的位置或我们施加的电压。不同的设计将产生不同的数据，其中一些会比其他的信息丰富得多。我们甚至在进行实验之前如何选择最佳设计呢？

我们选择我们*期望*能给我们最多信息的设计。也就是说，我们选择最大化**[期望信息增益](@entry_id:749170) (EIG)** 的设计，这只是互信息 $I(\theta; Y \mid d)$ 的另一个名称。

这个框架对两种不确定性做了关键区分 [@problem_id:3380352]：
-   **[认知不确定性](@entry_id:149866)**：这是我们对模型参数 $\theta$ 真实值缺乏了解。这是我们想要减少的不确定性。
-   **[偶然不确定性](@entry_id:154011)**：这是系统中固有的、不可简化的随机性或测量噪声。

信息增益是*认知*不确定性减少的度量。进行更好的实验有助于我们了解 $\theta$。然而，它并不能改变宇宙的基本噪声水平。事实上，在更嘈杂的环境中进行实验（增加[偶然不确定性](@entry_id:154011)）自然会*减少*我们希望获得的关于参数的信息量 [@problem_id:3380352]。这与我们的直觉完全吻合。该框架也尊重常识：如果我们已经完全了解一个参数（先验不确定性为零），或者如果我们的实验结果与该参数完全无关，则[期望信息增益](@entry_id:749170)为零 [@problem_id:3380352]。

### 知识的基本极限

这段旅程将我们带到了一个统一这些思想的、美丽的终点。我们已经看到，[信息是物理的](@entry_id:276273)。它是通过减少不确定性获得的，我们可以优化这个过程来做出决策和设计实验。但是，我们能知道多少，是否存在基本限制？

考虑一个受麦克斯韦著名妖精启发的思想实验 [@problem_id:1640661]。这个纳米级引擎观察气体粒子以获取其速度信息。但让我们想象一下，引擎的记忆是不完美的。它无法以无限精度记录真实速度 $v$；它只能存储一个表示 $\hat{v}$，其精确度受限于某个平均均方误差，或称**失真**，$D$。

气体中粒子的速度遵循[钟形曲线](@entry_id:150817)（高斯）分布，具有一定的方差 $\sigma^2$ 代表初始不确定性。考虑到其测量受到失真 $D$ 的限制，妖精最多能获得关于[粒子速度](@entry_id:196946)的多少信息？

答案来自一个名为[率失真理论](@entry_id:138593)的领域，而且非常优雅。可能的最大信息增益（以奈特为单位）是：

$$I_{\text{max}} = \frac{1}{2} \ln\left(\frac{\sigma^2}{D}\right)$$

[热力学熵](@entry_id:155885)的减少量就是这个值乘以 $k_B$。这个单一的方程讲述了一个深刻的故事。信息增益取决于我们初始不确定性（$\sigma^2$）与最终测量误差（$D$）的比率。如果我们的测量非常精确（$D$ 很小），我们可以获得大量信息。如果我们的初始不确定性非常高（$\sigma^2$ 很大），信息增益的*潜力*也很大。但要获得完美的知识（$D \to 0$）将需要获得无限量的信息，这在物理上是不可能的。

知识不是免费的。它是一种有限的资源，需要在精确度之间权衡，并受物理世界的约束。信息增益的概念为这种权衡提供了货币。它给了我们一种通用语言来描述学习的过程，从单个神经元的放电到庞大粒子加速器的建造，揭示了我们探求理解世界过程中深刻而优雅的统一性。

