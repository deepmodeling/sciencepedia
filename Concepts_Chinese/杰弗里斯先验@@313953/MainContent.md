## 引言
在贝叶斯统计中，我们根据新证据更新信念的能力取决于一个关键的起点：先验分布。当专家知识可用时，[主观先验](@article_id:353468)非常强大，但当没有专家知识时，一个基本问题便产生了：我们如何选择一个能够表达真正无知、让数据自己说话的先验？寻求这种“客观”或“无信息”先验的过程充满了悖论，因为看似简单的假设可能隐藏着意想不到的偏见。本文旨在探讨一种有原则的解决方案来应对这一挑战。

第一章“原理与机制”深入探讨了[杰弗里斯先验](@article_id:343961)的理论基础，解释了[重参数化不变性](@article_id:376357)问题，以及 Sir Harold Jeffreys 如何利用费雪信息来解决它。我们将看到这个优雅的原则如何为生成先验提供一个一致的规则。随后，“应用与跨学科联系”一章将展示该先验在不同领域的实际效用，从基础物理学和临床医学到工程学和天体物理学，揭示它作为[科学推理](@article_id:315530)中一个统一的概念。

## 原理与机制

在我们进入[贝叶斯推理](@article_id:344945)世界的旅程中，我们已经到达了一个关键的转折点。我们有了[贝叶斯定理](@article_id:311457)，一个用于更新我们信念的宏伟引擎。但要启动这个引擎，我们需要燃料：一个**[先验分布](@article_id:301817)**。这个先验代表了我们在看到任何数据之前所处的知识状态——或无知状态。如果我们有强大的专家知识，我们可以将其编码为一个“主观”先验，就像一位经验丰富的医生对一种新药的功效有着充分根据的预感一样 [@problem_id:1940910]。但如果我们没有呢？如果我们想以尽可能少的先入之见来处理一个问题，让数据自己说话呢？

这就是对**客观**或**无信息**先验的追求。这个名字有点用词不当；任何先验都包含*一些*信息。一个更好的术语可能是“[参考先验](@article_id:350587)”——一个标准的、默认的起点。最显而易见的选择似乎是简单地假设所有可能性都是等同的。如果我们不知道一个参数的值，我们可能会为所有可能的值分配一个平坦、均匀的概率。但正如我们将看到的，这个看似简单的想法是一个非常棘手的问题。

### 标签的暴政：参数化悖论

想象一下，我们正试图确定一种材料的物理特性，但我们不确定是用其电阻 $R$ 来描述，还是用其[电导](@article_id:325643) $C = 1/R$ 来描述。我们对这两者都一无所知。一个自然的第一步可能是为电阻赋予一个均匀先验，比如说在一个很大的范围内：$\pi(R) \propto 1$。这条平坦的线似乎在说：“我对 $R$ 的任何特定值都没有偏好。”

但这对于我们关于[电导](@article_id:325643) $C$ 的信念意味着什么呢？[概率法则](@article_id:331962)告诉我们如何进行[变量替换](@article_id:301827)：$C$ 的概率密度必须通过 $\pi(C) = \pi(R) |\frac{dR}{dC}|$ 与 $R$ 的密度相关联。由于 $R=1/C$，其[导数](@article_id:318324)为 $dR/dC = -1/C^2$。因此，我们对[电导](@article_id:325643)的先验变成了 $\pi(C) \propto 1 \cdot |-1/C^2| = 1/C^2$。

看看发生了什么！我们对电阻的“完全无知”状态，即 $\pi(R) \propto 1$，奇迹般地转变为一个关于[电导](@article_id:325643)的非常具体、[信息量](@article_id:333051)极大的信念，即 $\pi(C) \propto 1/C^2$。这个新的先验远非平坦；它表明极小的[电导](@article_id:325643)值比大的[电导](@article_id:325643)值可能性大得多。我们所谓的客观性原来是一种幻觉，完全取决于我们为参数选择的任意标签——电阻或[电导](@article_id:325643)。

这是一个深刻而令人不安的悖论。如果我们表达无知的方式取决于我们用来描述问题的语言，那么它根本就不是真正的无知。我们需要一种更有原则的方法，一种定义先验的方法，无论我们如何对问题进行参数化，都能给出一致、客观的结果。我们需要一个**[重参数化](@article_id:355381)不变**的先验。

### [费雪信息](@article_id:305210)：统计空间的标尺

这个谜题的解决方案来自杰出的思想家 Sir Harold Jeffreys，他建立在另一位巨擘 Sir Ronald Fisher 的工作之上。Jeffreys 的想法是停止将参数空间看作一条简单的平坦直线，而是开始思考它的几何形状。他意识到，统计模型本身——即[似然函数](@article_id:302368)——为参数定义了一种“景观”。这个景观的某些区域陡峭崎岖，而其他区域则平坦缓和。

这个景观的曲率由一个称为**费雪信息**的量来衡量，记为 $I(\theta)$。直观地说，费雪信息告诉你，单个数据点预计能为未知参数 $\theta$ 提供多少信息。

可以这样想：想象你正试图通过观察[对数似然函数](@article_id:347839)来找到参数的值，该函数在最可能的值处达到峰值。如果峰值极其尖锐狭窄，像一根针，那么即使是极少量的数据也能让你非常精确地定位参数。此时信息量很高。如果峰值宽而圆，像一座平缓的小山，那么数据就没那么有用了；宽范围内的参数值都几乎同样合理。此时信息量很低。在数学上，费雪信息是[对数似然函数](@article_id:347839)二阶[导数](@article_id:318324)的负[期望值](@article_id:313620)：这是对其预期曲率的度量。

$$
I(\theta) = -E\left[\frac{\partial^2}{\partial \theta^2} \ln f(X|\theta)\right]
$$

这个量就是我们的标尺。它是模型本身的属性，告诉我们在参数空间的不同位置，我们的推断对参数值变化的敏感程度。

### [杰弗里斯先验](@article_id:343961)：不变性原则

这就是 Jeffreys 的神来之笔。他提出了一个与**费雪信息的平方根**成正比的[先验分布](@article_id:301817)：

$$
\pi_J(\theta) \propto \sqrt{I(\theta)}
$$

为什么是这种特定形式？因为它拥有我们一直在寻找的神奇[不变性](@article_id:300612)。当你改变参数时，比如从 $\theta$ 变为一个新参数 $\phi$，[费雪信息](@article_id:305210)会根据一个精确的规则进行转换：$I(\phi) = I(\theta) \left(\frac{d\theta}{d\phi}\right)^2$。现在，如果我们对两边取平方根，我们得到 $\sqrt{I(\phi)} = \sqrt{I(\theta)} |\frac{d\theta}{d\phi}|$。

这与概率密度函数的转换方式完全相同！因此，通过将我们的先验定义为与 $\sqrt{I(\theta)}$ 成正比，我们确保了*规则本身*无论我们使用哪种[参数化](@article_id:336283)都保持不变。电阻的[杰弗里斯先验](@article_id:343961)，在转换后，会得到[电导](@article_id:325643)的[杰弗里斯先验](@article_id:343961)。悖论得以解决。

这个直觉是优美的。[杰弗里斯先验](@article_id:343961)在[费雪信息](@article_id:305210)低的地方（即似然函数平坦、数据信息量少的地方）分配更多的先验密度，而在信息高的地方（即[似然函数](@article_id:302368)尖锐、数据[信息量](@article_id:333051)大的地方）分配更少的先验密度。这是一个谦逊的先验；它会退后一步，恰恰在那些数据可能保持沉默的地方“提高音量”，确保我们的后验信念是由证据驱动的，而不是由我们对标签的选择驱动的。

### 先验一览

让我们看看这个原则在实践中的应用。[杰弗里斯先验](@article_id:343961)的函数形式完全取决于统计模型。

**硬币投掷（伯努利参数 $p$）：**
我们对硬币正面朝上的概率 $p$ 的[先验信念](@article_id:328272)是什么？计算伯努利试验的[费雪信息](@article_id:305210)得到 $I(p) = \frac{1}{p(1-p)}$ [@problem_id:694655]。因此，[杰弗里斯先验](@article_id:343961)是：

$$
\pi_J(p) \propto \sqrt{\frac{1}{p(1-p)}} = p^{-1/2}(1-p)^{-1/2}
$$

这是一种特定类型的贝塔分布，即 $\text{Beta}(1/2, 1/2)$ [@problem_id:1379701]。它看起来是什么样子？它是一条U形曲线，将概率集中在 $p=0$ 和 $p=1$ 附近。这可能看起来很奇怪——为什么偏爱不公平的硬币？原因很微妙。要区分一个 $p=0.999$ 的硬币和一个 $p=0.9999$ 的硬币，比区分一个 $p=0.5$ 的硬币和一个 $p=0.6$ 的硬币要困难得多。数据在极端情况下的信息量较少，因此先验通过在这些地方提高其“音量”来进行补偿。对于一个 $k$ 面骰子的投掷，这优美地推广到所有参数都等于 $1/2$ 的[狄利克雷分布](@article_id:338362)，其中先验与 $\prod_{i=1}^{k} p_{i}^{-1/2}$ 成正比 [@problem_id:1940926]。

**位置与尺度：**
当我们考虑不同类型的参数时，一个深刻的区别出现了。

*   **[位置参数](@article_id:355451)：** 这类参数，如[正态分布](@article_id:297928)的均值 $\mu$ 或 Gumbel 分布的位置 $\mu$，指定了数轴上的一个位置。对于许多这样的参数，费雪信息结果是恒定的——无论分布中心在哪里，数据的信息量都是相同的。这导致了[杰弗里斯先验](@article_id:343961) $\pi_J(\mu) \propto 1$ [@problem_id:1922095]。这是我们最初猜测的平坦先验，但现在它建立在坚实的理论基础上。它表达了对位置的无知。这样的先验通常是**非正常的**（improper），意味着它在其无限定义域 $(-\infty, \infty)$ 上的积分不是一个有限数。这不是一个缺陷；这是一个特性，正确地捕捉了在一个无界范围内的完全不确定性。

*   **[尺度参数](@article_id:332407)：** 这类参数描述大小或尺度，如[激光二极管](@article_id:364964)的失效率 $\lambda$ [@problem_id:1624948] 或总体的[标准差](@article_id:314030) $\sigma$。对尺度的无知不同于对位置的无知。从尺度1变为2的感觉与从100变为200的“比例”跳跃是相同的。这表明我们应该在对数尺度上是均匀的。[杰弗里斯先验](@article_id:343961)自然地发现了这一点。对于指数分布的率参数 $\lambda$，$I(\lambda) = 1/\lambda^2$，所以先验是 $\pi_J(\lambda) \propto 1/\lambda$ [@problem_id:1624948]。类似地，对于[泊松分布](@article_id:308183)的率参数，先验是 $\pi_J(\lambda) \propto 1/\sqrt{\lambda}$ [@problem_id:815072]。对于像 $\sigma$ 这样的纯[尺度参数](@article_id:332407)，先验通常是 $\pi_J(\sigma) \propto 1/\sigma$。这也被称为“对数均匀”先验，它是[尺度不变性](@article_id:320629)的数学表达。

### 错综复杂的多参数

当我们同时对多个参数（比如[正态分布](@article_id:297928)的均值 $\mu$ 和标准差 $\sigma$）都一无所知时，会发生什么？这个概念可以延伸，但带来了引人入胜的新微妙之处。我们现在有一个**[费雪信息矩阵](@article_id:331858)**，[杰弗里斯先验](@article_id:343961)与其[行列式](@article_id:303413)的平方根成正比：$\pi(\boldsymbol{\theta}) \propto \sqrt{\det(I(\boldsymbol{\theta}))}$。

对于一个[正态分布](@article_id:297928) $N(\mu, \sigma^2)$，直接计算显示联合[杰弗里斯先验](@article_id:343961)是：

$$
\pi(\mu, \sigma) \propto \frac{1}{\sigma^2}
$$

值得注意的是，对于截然不同的、重尾的柯西分布，其位置和[尺度参数](@article_id:332407)的联合[杰弗里斯先验](@article_id:343961)也恰好是 $\pi(\mu, \sigma) \propto 1/\sigma^2$ [@problem_id:1902477]。这指向了[位置-尺度族](@article_id:342766)所共有的更深层次的结构。

但这里有最后一个重要的教训。如果我们分别推导 $\mu$ （假设 $\sigma$ 已知）和 $\sigma$ （假设 $\mu$ 已知）的[杰弗里斯先验](@article_id:343961)，我们会得到 $\pi(\mu) \propto 1$ 和 $\pi(\sigma) \propto 1/\sigma$。它们的乘积是 $1/\sigma$，这*不等于*我们找到的联合先验 $1/\sigma^2$ [@problem_id:1940948]。这是什么意思？这意味着在多维空间中构建一个“客观”先验，并不像孤立地处理每个参数那么简单。完整的杰弗里斯法则，使用[行列式](@article_id:303413)，尊重了参数空间的联合几何结构，并且仍然是不变性的黄金标准。

[杰弗里斯先验](@article_id:343961)并非万能药。它可能难以计算，其解释也需要谨慎。但它的深远贡献在于，它将选择“无信息”先验建立在一个基本原则之上：对我们描述语言的[不变性](@article_id:300612)。它提供了一个有原则的、即使不总是完美的起点，使我们能够以尽可能客观的方式进行[贝叶斯分析](@article_id:335485)，让我们的数据所讲述的故事占据中心舞台。