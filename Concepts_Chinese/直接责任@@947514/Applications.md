## 应用与跨学科联系

在探讨了直接责任的基本机制——义务、控制与行动之间优雅的相互作用——之后，我们可能会想将这些理念局限于法庭或法律图书馆。但这就像研究了万有引力定律却从不仰望星空一样。这些原则并非枯燥的法律条文；它们是责任的语法本身，一种帮助我们驾驭最复杂的道德和技术图景的通用语言。适用于一场车祸的基本逻辑，可以被放大以指导我们创造人造生命、管理全球大流行病或设计一个公正的社会。在本章中，我们将踏上一段旅程，去见证这一原则在实践中的应用，目睹它在广阔的人类奋斗领域中惊人的延展性和统一的力量。

### 控制的所在地：科学与研究中的责任

我们的旅程始于一个发现之地：研究实验室。正是在这里，直接责任的概念以其最直接和个人化的形式出现。想象一位科学家，通过[CRISPR基因编辑](@entry_id:148804)的革命性力量，创造了一个新的实验小鼠品系。为某一目的设计的实验，却产生了一个完全意想不到的可怕结果：这些动物开始遭受严重、使人衰弱的癫痫发作。该怎么办？在这里，没有任何模棱两可之处。首席研究员，即启动实验并对实验室拥有权威的人，负有直接且不可推卸的注意义务。这份义务不是对数据负责，也不是对项目的成功负责，而是对处于其控制之下的生命负责。负责任的行动方案是立即的：寻求兽医护理，向批准该研究的伦理委员会报告这一未预见的结果，并建立清晰、人道的标准以结束动物的痛苦([@problem_id:2336013])。责任是直接的，因为控制是直接的。

但是，当我们的现代网络化世界开始延伸和复杂化这些控制线时，会发生什么？想象一下，我们的科学家是一位加州的计算生物学家，他在电脑上设计了一个遗传回路。DNA由德国的合作者合成，而实际的实验——将DNA插入细菌——由德克萨斯州的一个自动化“云实验室”（一家收费进行实验的公司）执行。如果出了问题，谁对[生物安全](@entry_id:187330)负责？是提出想法的科学家，还是在另一个州实际处理材料的公司？美国国立卫生研究院（NIH）的指导方针，对此类研究有规定，其答案异常清晰。责任以及[机构生物安全委员会](@entry_id:203906)的正式监督，附属于拥有物理控制权的实体。德克萨斯州的云实验室，即那个亲手操作试管的实体，承担审查和批准的主要责任([@problem_id:2050723])。原则依然成立：责任跟随有效控制的所在地，即使跨越大陆，穿过多层分包。这是一个强有力的提醒：你无法[外包](@entry_id:262441)责任。

### 创造的前沿：新技术的责任

当我们从仅仅观察世界转向主动重新设计世界时，这一原则变得更加关键。考虑“基因驱动”的出现，这是一项惊人的技术，可以迫使特定遗传性状在整个野生种群中迅速传播。想象一家公司开发了一种[基因驱动](@entry_id:153412)技术，使玉米具有[抗旱性](@entry_id:276606)，并将其出售给一位农民。这位农民遵守了所有安全规则，种植了缓冲区以遏制转基因作物。然而，这项技术比预防措施更强大。风将转基因花粉带到邻近的有机农场，污染了一种珍稀的传统作物，并摧毁了其价值。谁来为损失买单？遵守规则的农民？风？答案植根于深刻的伦理逻辑，指向了创造者。设计、获利于并将这种强大的、改变生态系统的技术引入世界的公司，在其自身的遏制方案失败时，承担主要责任([@problem_id:2036459])。这就是“生产者责任”，一种直接责任的形式，其中注意义务源于创造一种新的风险。谁创造了力量，谁就为其遏制承担首要和最大的责任。

当创造的对象是人类生命本身时，赌注上升到可以想象的最高水平。在一个假设但具有至关重要伦理意义的思想实验中，考虑一个在允许人类生殖性克隆的司法管辖区内的诊所，该诊所遵循严格的规则。其中一条规则是“终止阈值”：如果一种危险的医学综合征（我们称之为$p$）的概率超过某个值，比如$T=0.10$，则必须停止程序。一次尝试开始时，初步风险为$p_{\text{pre}}=0.08$，低于阈值。但随着过程的展开，新数据显示风险已攀升至$p=0.18$，远超危险区。然而，主导临床医生继续进行，不幸的是，一个孩子出生时恰好患有这种综合征。在随后的法律和道德清算中，主要责任在哪里？它完全在于临床医生。父母的同意是无效的，因为他们没有被告知急剧上升的风险。监管机构没有过错，因为他们的规则被违反了。临床医生，那个对继续或停止的决定拥有直接控制权、知道风险已变得不可接受、并选择违反规则的唯一个体，违背了他们最基本的注意义务和不伤害原则([@problem_id:4865617])。即使在创造生命的前沿，古老而简单的直接责任规则依然牢固。

也许没有哪个前沿比人工智能进步得更快。当人工智能帮助医生做出关乎生死的决定时，我们的责任框架是否开始瓦解？恰恰相反，它变得比以往任何时候都更加重要。医学领域伦理人工智能的目标不是创造一个取代人类判断的神谕，而是构建在“有意义的人类控制”下运行的工具([@problem_id:4850231])。这意味着人类临床医生必须保留理解人工智能输出、指导其使用以及——至关重要的是——为最终决定承担责任的能力。

当临床医生面对一个令人信服的人工智能建议时，屈服于“自动化偏见”并推翻自己更好的判断，从而导致病人受到伤害时，这一原则就受到了考验。在这种屡见不鲜的情况下，临床医生通常不能指着机器为自己开脱。根据一个长期存在的法律原则，即“有学识的中介”原则，临床医生是站在工具和病人之间的专家。他们的注意义务是运用自己的专业判断，将人工智能的输出作为众多数据之一来整合。盲目听从算法是违反该义务的行为，临床决定的主要责任仍然在人，并延伸至其所在机构([@problem_-id:4427458])。

但在这里，控制原则揭示了其优美的微妙之处。如果系统被*设计*成使人类监督成为一种幻觉呢？想象一个败血症警报人工智能，它会自动填充一份抗生素订单。医生理论上可以覆盖它，但这样做需要通过六个复杂步骤在一个笨拙的界面上操作，耗时$T_o = 45$秒。然而，医院自己的质量指标却要求医生在$T_w = 30$秒的时间窗口内最终确定订单。在这种环境下，当覆盖时间大于允许的决策时间（$T_o > T_w$）时，医生真的在控制之中吗？法律，以其智慧，会说不。当一个系统的设计使“人在回路中”在实践上不可能时，“有效控制”已经转移。由默认建议导致的坏结果的责任，可以转移回设计了不合理危险界面的供应商和实施了强制性工作流程的机构([@problem_id:4494845])。因此，直接责任并非要找一个替罪羊；它是要诚实地识别出，在真实、混乱、时间紧迫的世界里，谁真正拥有做出不同选择的权力。

### 从个人到集体：全球范围内的责任

这个关于控制和义务的优雅原则不仅在个人及其工具的层面上运作，它还扩展到整个社会的层面。思考一下全球城市中数以百万计的非正规工人——如拾荒者或街头小贩——他们暴露在有毒烟雾和锐器等严重的职业危害中。这些工人通常没有正式受雇，他们工作的空间由各种私营行为体拼凑控制。难道没有人为他们的安全负责吗？人权法给出了一个明确的答案：国家本身负有*直接保护义务*。它拥有最终的控制权，通过其立法、监管和检查的权力。一个国家不能通过声称伤害是由“第三方”造成的来推卸责任。它负有直接的责任，去创建和执行一个规则体系，保护其管辖范围内每个人的健康和安全，无论其就业状况如何([@problem_id:5004782])。在这里，不作为——即未能监管——本身就是违反义务的行为。

最后，我们来到了全球舞台，在这里，单个实体的作为或不作为都可能影响全人类。根据具有法律[约束力](@entry_id:170052)的《国际卫生条例》，当一个国家发现具有大流行潜力的新型病毒爆发——持续的人际传播和逃避现有免疫力的能力——它负有立即且无条件的义务。在24小时内，它*必须*通知世界卫生组织并分享所有可用的公共卫生数据([@problem_id:2101948])。这不是一个礼貌的请求。这是直接责任的终极体现。“注意义务”是对全世界的，而“控制”是主权国家对其境内事件的独特知情权。为了避免经济恐慌或获得战略优势而隐瞒信息，是对这一全球义务的灾难性违背。在这种背景下，直接责任是使对生存威胁进行协调一致的全球响应成为可能的关键机制。

从科学家对受苦动物的庄严义务，到一个国家对世界的责任，我们看到了同样的[基本模式](@entry_id:165201)在重复。直接责任不是一个固定或僵化的规则，而是一个动态的原则，它寻找有效控制的所在地，并追问附属于该控制的注意义务是否得到履行。它是我们用以分配责任、从失败中学习和构建更安全系统的框架。它提醒我们，在一个由分布式网络、自动化代理和全球化风险构成的世界里，对自己行为直接负责的简单、人性化概念，仍然是我们最重要和最具统一性的指南。