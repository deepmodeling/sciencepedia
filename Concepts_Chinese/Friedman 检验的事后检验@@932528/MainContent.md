## 引言
当使用非参数数据比较三个或更多相关组别时——例如，评估同一组用户对多个[用户界面设计](@entry_id:756387)的反应，或在多个时间点上追踪患者症状——Friedman 检验是一种宝贵的统计工具。它通过分析它们的秩次，优雅地确定各条件之间是否存在总体上的显著差异。然而，它的作用如同一个守门人；一个显著的结果告诉我们某个地方存在有意义的差异，但并未指明具体是哪些组别之间存在差异。这种模糊性带来了一个关键的知识空白：我们如何精确定位变异的来源，同时避免陷入统计陷阱？

本文正是为了回答这个问题，为 Friedman 检验的[事后检验](@entry_id:171973)提供了一份全面的指南。它解决了被称为[多重比较问题](@entry_id:263680)的关键挑战，在这种情况下，进行大量检验会增加错误发现的风险。读者将学会通过严谨的统计策略来应对这个问题。首先，在“原理与机制”部分，我们将探讨错误控制的核心概念，将保守的族系误差率 (FWER) 与更具统计效力的错误发现率 (FDR) 进行对比。我们还将剖析和比较 Nemenyi、Dunn 和 Conover 检验等具体的事后程序，并强调其优缺点。随后，“应用与跨学科联系”一章将展示这些工具如何在从临床试验到机器学习等不同领域中应用，提供关于解读和报告结果的实用建议，并强调实验设计在获得有效科学结论方面不可或缺的作用。

## 原理与机制

想象一下，你是一场有数名选手的才艺表演的评委。在看完所有表演后，你有一种普遍的感觉，即某些表演肯定比其他的好，但你还没有宣布具体的赢家或输家。Friedman 检验就像那种最初的感觉；它是一种“总体”检验，一种宏大、全面的判断。当你进行一项研究，比较多种处理对相同受试者的影响时——例如，在十名用户组上评估四种新的[用户界面设计](@entry_id:756387) [@problem_id:1924573]，或在同一名患者身上测试几种药物方案 [@problem_id:4835999]——Friedman 检验可以告诉你，这些处理在总体上是否存在*任何*显著差异。它通过忽略原始分数，只关注**秩次**来优雅地做到这一点：在每个受试者内部，哪种处理效果最好、第二好，依此类推。

如果评委（受试者）在他们的排名中表现出惊人的一致性——即高度的“[协同性](@entry_id:147884)”——Friedman 检验将产生一个显著的结果 [@problem_id:4946316]。这告诉我们，观察到的模式不太可能是由偶然因素造成的。但这才是我们真正工作的开始。这个检验就像一个烟雾报警器；它尖锐地宣告了火灾的存在，但没有告诉我们是哪个房间在燃烧。具体是哪个[用户界面设计](@entry_id:756387)比另一个更受欢迎？哪种药物真的比其替代品更有效？要回答这些具体问题，我们必须抛开总体检验，进入**[事后检验](@entry_id:171973)**的世界。

### 研究者的困境：多重问题带来的难题

起初，这似乎很简单。如果我们有四种处理（A, B, C, D），为什么不为所有可能的配对进行单独的检验呢？我们可以比较 A vs. B, A vs. C, A vs. D, B vs. C, B vs. D, 和 C vs. D。这种看似无害的方法存在一个微妙但深刻的问题，即**[多重比较问题](@entry_id:263680)**。

可以这样想。在科学中，我们通常将我们的意外阈值，即显著性水平 $\alpha$，设为 $0.05$。这意味着对于任何单次检验，我们愿意接受 $5\%$ 的概率出现假警报——即在没有差异时得出存在差异的结论。这就像持有一张彩票，有 $1/20$ 的机会“赢得”一个错误发现。如果你只买一张彩票，假赢的机会很低。但如果你买十张呢？或一百张呢？你手中至少有一张“中奖”的错误发现彩票的概率会急剧上升。

当我们进行多次统计检验，每次都有其自身的假警报风险时，我们在检验“族系”中犯下至少一次错误发现的总体机会——即**族系误差率 (FWER)**——会急剧膨胀。简单地进行所有两两比较而不做任何校正，就像声称你有一大堆惊人的发现，却忽略了你只是买了足够多的彩票，使得一些假赢几乎不可避免。要进行严谨的科学研究，我们必须控制这种错误。[事后检验](@entry_id:171973)程序就是那些严谨的策略，它让我们能够提出多个问题的同时，将总体的假警报风险控制在一定范围内。

### 两种错误控制理念

那么，我们该如何管理这种膨胀的风险呢？统计学家们发展出了两种主要理念来驾驭多重比较这片危险的水域。让我们用一个具体的例子来探讨它们：在一次显著的 Friedman 检验后，一位研究者对 $k=5$ 种处理进行了两两检验，得到了 10 个未经校正的 $p$ 值，分别对应不同的比较 [@problem_id:4946267]。

#### 控制族系误差率 (FWER)

最经典、最保守的方法是控制 FWER。其目标是将整个检验族系中哪怕只犯*一个*错误发现的概率，保持在我们期望的水平（例如 $5\%$）或以下。

一种简单但通常过于严格的方法是 Bonferroni 校正，它将你的显著性水平 $\alpha$ 除以检验次数。一种更智能、更强大的方法是 **Holm 逐步下降程序**。它按顺序工作。首先，你将你的 $p$ 值从小到大排序。

1.  最小的 $p$ 值与最严格的阈值 $\alpha/10$ 进行比较。在我们的例子中 [@problem_id:4946267]，最小的 $p$ 值是 $0.003$。由于 $0.003 \lt (0.05/10 = 0.005)$，这个结果被宣布为显著。
2.  然后我们移至下一个最小的 $p$ 值，$0.009$，并与一个稍微宽松的阈值 $\alpha/9$ 进行比较。由于 $0.009 \gt (0.05/9 \approx 0.0056)$，这个结果*不*显著。
3.  程序到此停止。一旦我们未能拒绝一个假设，我们也就不能拒绝所有后续具有更大 $p$ 值的假设。

在 Holm 方法的严格 FWER 控制下，只有一个比较（$T_1$ vs. $T_2$）被认为是统计显著的。这种方法让我们对我们的发现不是侥幸充满信心，但这可能是以牺牲发现其他更微妙效应为代价的。

#### 控制错误发现率 (FDR)

一种更现代、通常也更强大的理念是控制**错误发现率 (FDR)**，尤其是在基因组学等领域，成千上万次检验是常态。它的目标不是试图避免哪怕一个[假阳性](@entry_id:635878)，而是控制在你宣布为显著的所有发现中，[假阳性](@entry_id:635878)的*期望比例*。如果你以 $5\%$ 的 FDR 宣布 100 个发现是显著的，你期望平均而言其中只有大约 5 个是错误发现。这是一个更宽松的标准，通常能给我们更多发现真实效应的统计效力。

最常用的方法是 **[Benjamini-Hochberg](@entry_id:269887) (BH) 程序**。我们同样对 $p$ 值进行排序。然后，我们找到满足条件 $p_{(j)} \le (j/m) \times q$ 的最大 $p$ 值 $p_{(j)}$，其中 $j$ 是 $p$ 值的秩次， $m$ 是检验总数，$q$ 是我们期望的 FDR 水平（例如 $0.05$）。所有小于或等于这个值的 $p$ 值都被宣布为显著。

将此方法应用于我们的例子 [@problem_id:4946267]，我们发现第三小的 $p$ 值 $p_{(3)} = 0.014$ 是最后一个满足标准的（$0.014 \le (3/10) \times 0.05 = 0.015$）。因此，我们宣布第一、第二和第三个比较是显著的。BH 程序识别出了三个显著差异，而 Holm 程序只发现了一个！这说明了 FDR 方法的强大之处：通过接受一种不同类型的风险，我们常常可以提高我们的发现率。

### 统计学家的工具箱：[事后检验](@entry_id:171973)巡礼

知道如何为[多重检验](@entry_id:636512)进行调整只是故事的一半。我们还需要选择正确的底层统计检验来生成那些初始的 $p$ 值。对于 Friedman 检验，有几种专门的选项，每种都有其独特的特点。

*   **Nemenyi 检验：** 这是一种单步程序，类似于针对秩次的 Tukey 检验。它计算一个临界差异值；任何一对处理，其平均秩次差异大于此值，即被宣布为显著 [@problem_id:1924573]。它简单明了，但通常**保守**，意味着它过于谨慎，可能会检测不到真实的差异，尤其是在比较多个处理或数据中存在秩次相同时 [@problem_id:4797220]。

*   **Dunn 检验：** 这是一种流行的方法，它实质上是执行基于秩次的两两检验，然后对得到的 $p$ 值应用校正（如 Bonferroni 或 Holm）。这是一种稳健而灵活的方法。

*   **Conover 检验：** 这被广泛认为是最强大和可靠的选项之一 [@problem_id:4797193]。其真正的精妙之处在于它如何估计数据中的随机“噪音”。Conover 检验不是一次只看两种处理，而是使用来自*所有*处理和*所有*受试者的秩次信息，计算一个单一的**[合并方差](@entry_id:173625)估计量**。通过汇集所有这些信息，它能得到一个更稳定、更精确的对潜在变异性的估计。这种精度的提高使其[检验统计量](@entry_id:167372)更加敏感，从而有更强的统计效力来检测其他检验可能错过的真实差异。

那么你应该选择哪一个呢？在许多情况下，将用于两两比较的 **Conover 检验**与用于控制 FWER 的 **Holm 程序**相结合，可以在统计效力和严格的错误控制之间提供极佳的平衡 [@problem_id:4946256, @problem_id:4797220]。当样本量小或处理数量多时——恰恰是统计效力最被需要的情况——这种组合尤其具有优势。

### 看不见的基础：设计的神圣性

所有这些复杂的统计工具都建立在一个简单、优美且不可妥协的基础之上：良好的实验设计。Friedman 检验的核心假设是**可交换性**。这意味着，如果处理真的没有效果，我们为某个受试者的测量值附加的标签就是任意的；我们可以打乱它们而不会改变结果的可能性。

但如果某个隐藏因素系统性地影响了结果呢？考虑一个测试四种药物剂量的实验，其中每个参与者都按相同的固定顺序接受剂量 [@problem_id:4946278]。如果存在**学习效应**——参与者随着时间的推移，在任务上表现得越来越好——他们的分数会从第一次实验到最后一次系统性地增加。Friedman 检验看到这种完美的分数排序，很可能会宣布一个显著的“剂量效应”，而实际上它只是检测到了时间的流逝。剂量效应与时间效应完全**混淆**了。

事后再多的巧妙统计调整也无法修复这个根本性的设计缺陷。解决方案不在于分析，而在于设计本身。通过使用**随机化**（为每个参与者随机分配剂量顺序）或**平衡法**（使用像拉丁方阵这样的结构化设计，以确保每种剂量在每个时间段出现的频率相同），我们打破处理与潜在混杂因素之间的联系。这些设计原则确保任何时间趋势或学习效应都能均匀地分布在所有处理中并相互抵消，从而维护了[可交换性](@entry_id:263314)假设的神圣性。这才是使有效[科学推断](@entry_id:155119)成为可能的真正“原理与机制”：实验本身巧妙而审慎的设计。

