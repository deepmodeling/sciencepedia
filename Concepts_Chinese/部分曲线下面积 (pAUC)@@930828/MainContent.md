## 引言
在评估诊断测试和[机器学习模型](@entry_id:262335)的性能时，我们常常寻求一个单一、明确的数字。几十年来，ROC [曲线下面积 (AUC)](@entry_id:634359) 一直是无可争议的王者，它提供了一个分类器区分不同类别能力的全局性总结。然而，依赖于这样一个包罗万象的平均值可能具有欺骗性。如果“全局”性能包含了临床上或实践中不相关的区域，该怎么办？这正是[部分曲线下面积](@entry_id:635326) (pAUC) 所要解决的关键知识缺口，它为高风险场景提供了一种更聚焦、更有意义的度量方法。

本文将探讨 pAUC 的理论和实践。在第一章 **原理与机制** 中，我们将剖析完整 AUC 的局限性，并建立 pAUC 的正式定义和数学基础。我们将展示在性能仅在特定范围（如低假阳性率）内具有相关性的情境下，pAUC 如何提供更优越的评估。接下来的 **应用与跨学科联系** 章节将带领我们见证 pAUC 的实际应用。我们将看到这个有针对性的指标如何在从医学、高能物理到神经科学和人工智能公平性等领域中不可或缺，以及它如何不仅用于评估，还能作为构建更好、更安全、更有效模型的强大目标。

## 原理与机制

### 单一数字的诱惑与专制

我们人类热爱简洁。我们内心深处渴望将复杂的现实提炼成一个单一、易于理解的数字。我们会问一部电影的十分制评分、一个学生的平均绩点，或者一辆汽车的马力。这是一种方便的简写。在评估诊断测试或机器学习模型的世界里，单一数字总结指标的无可争议的王者是 **[曲线下面积 (AUC)](@entry_id:634359)**。

分类器性能的全貌由 **[受试者工作特征](@entry_id:634523) (ROC) 曲线** 展现。想象你有一个能给出连续分数的测试——比如一个从 0 到 100 的数字，表示患病的可能性。你需要选择一个阈值；任何得分高于此阈值的人都会被标记为“阳性”。如果你把阈值设得很高，你只会错误地捕捉到极少数健康人（低 **假阳性率**，即 **FPR**），但你也会漏掉许多真正的病人（低 **[真阳性率](@entry_id:637442)**，即 **TPR**）。如果你把阈值设得很低，你会捕捉到大多数病人（高 TPR），但你也会错误地标记许多健康人（高 FPR）。ROC 曲线是一张优美的图，它绘制了*所有可能阈值*下的 TPR 与 FPR 的关系。它展示了完整的权衡过程。

因此，AUC 就是整条曲线下的总面积。它有一个非常直观的含义：AUC 是一个随机选择的患病个体的测试分数高于一个随机选择的非患病个体分数的概率。AUC 为 $1.0$ 意味着完美区分；AUC 为 $0.5$ 意味着该测试不比抛硬币好。几十年来，更高的 AUC 一直是“更好”模型的黄金标准。

但事实果真如此吗？这个诱人而简单的数字有时是否会变成一个暴君，迫使我们考虑我们根本不关心的信息，从而误导我们？如果实际上只有图景中的一小部分才重要呢？

### 当全局信息成为干扰

让我们想象一个真实场景。一个公共卫生部门正在为一种严重癌症设计新的筛查项目 [@problem_id:4568377]。该筛查测试会给出一个风险评分。筛查结果“阳性”并不意味着一个人患有癌症；它意味着他们需要接受后续检查，比如侵入性的结肠镜检查或活检。这种后续检查费用高昂，本身带有医疗风险，并给患者带来巨大的焦虑 [@problem_id:4918244]。

由于[假阳性](@entry_id:635878)带来的高昂成本，该卫生部门制定了一项严格政策：他们采纳的任何筛查测试*必须*在一个能将[假阳性率](@entry_id:636147)保持在（比如说）5% 以下（$FPR \le 0.05$）的阈值下运行。这是不可协商的。这项政策对我们优美的 ROC 曲线意味着什么？它在 $FPR = 0.05$ 处画了一条垂直线，并宣布该线右侧的整个区域为“[禁区](@entry_id:175956)”。任何会导致更高 FPR 的阈值在临床上都是无关紧要的，永远不会被使用。

那么，关键问题来了：如果我们永远不会在 $FPR > 0.05$ 的区域运行我们的测试，为什么该测试在那个[禁区](@entry_id:175956)的性能要影响我们的决策？完整的 AUC 是在从 0 到 1 的*整个* FPR 范围内对性能进行平均。一个模型可能因为在我们刚刚宣布无关的高 FPR 区域表现出色而获得高 AUC，但在我们真正关心的那个狭小的高特异性窗口内却表现平平。

这就是单一数字的专制变得显而易见的地方。考虑两个相互竞争的测试，测试 X 和测试 Y。它们的 ROC 曲线显示，它们的完整 AUC几乎相同，都在 $0.82$ 左右。一个只看这个单一数字的管理者可能会得出结论，认为它们同样好。但仔细观察会发现一个不同的故事。在从 $0$ 到 $0.05$ 的关键低 FPR 区域，测试 X 始终比测试 Y 获得更高的真阳性率。对于*这个特定的临床应用*来说，它显然是更优越的测试。如果只关注完整的 AUC，我们就会错过这个至关重要的区别 [@problem_id:4568377]。这就是关注**[部分曲线下面积](@entry_id:635326) (pAUC)** 的动机所在。我们刻意选择只测量图表中重要部分的面积。

### 深入探究：定义和测量部分面积

让我们更正式一点。如果 ROC 曲线由一个函数 $TPR(FPR)$ 描述，该函数给出给定假阳性率下的[真阳性率](@entry_id:637442)，那么在特定的 FPR 区间（比如从 $\alpha$ 到 $\beta$）上的部分 AUC 就是简单的积分：

$$ \mathrm{pAUC}(\alpha, \beta) = \int_{\alpha}^{\beta} TPR(FPR) \, dFPR $$

从几何上看，这只是位于 $FPR=\alpha$ 和 $FPR=\beta$ 两条垂直线之间的那部分 ROC 曲线下的面积。

我们如何实际计算它呢？在现实世界中，我们没有一个完美的、平滑的 ROC 曲线数学函数。我们拥有一组数据点——研究中观察到的 TPR 和 FPR 值。估算该面积最简单的方法是用直线连接这些点，并计算所形成的梯形的面积 [@problem_id:4568376]。

假设一项研究在我们的目标区域内给了我们三个点：$(FPR, TPR)$ 对分别为 $(0,0)$、$(0.05, 0.4)$ 和 $(0.10, 0.6)$ [@problem_id:4918296]。我们想要计算区间 $[0, 0.10]$ 上的 pAUC。我们有两个梯形：
1.  第一个位于 $FPR=0$ 和 $FPR=0.05$ 之间。它的“高”是 TPR 值 $0$ 和 $0.4$。面积是 $\text{base} \times \text{average height} = (0.05 - 0) \times \frac{0 + 0.4}{2} = 0.01$。
2.  第二个位于 $FPR=0.05$ 和 $FPR=0.10$ 之间。它的高是 $0.4$ 和 $0.6$。面积是 $(0.10 - 0.05) \times \frac{0.4 + 0.6}{2} = 0.025$。

总的部分 AUC 是两部分之和：$0.01 + 0.025 = 0.035$。就这么简单。我们刚刚测量了分类器在我们关心的确切窗口内的性能。

### 无用但有用的分类器：一个令人惊讶的案例

完整 AUC 和部分 AUC 之间的区别可以带来一些真正令人惊讶的见解。让我们构建一个奇特、近乎悖论的场景来阐明这一点 [@problem_id:4946979]。

想象有两个测试，模型 A 和模型 B。当我们分析它们时，我们发现它们的完整 AUC 都恰好是 $0.5$。根据传统标准，这两个模型都完全无用——不比随机抛硬币好。我们可能会想把它们都扔进垃圾桶。

但是等等！别那么草率。我们还记得关于临床背景的教训。假设我们再次只关心高特异性区域的性能，比如说 FPR 在 $0$ 和 $0.2$ 之间。我们计算两个模型在这个特定区间内的 pAUC。对于模型 A，我们得到的 pAUC 是 $\frac{1}{50} = 0.02$。对于模型 B，我们得到的 pAUC 是 $\frac{9}{1250} \approx 0.0072$。

看！在我们关心的区域内，模型 A明显优于模型 B。尽管从全局平均来看，两个模型都毫无用处，但模型 A 却成功地将其（微薄的）区分能力集中在临床相关的确切区域。完整的 AUC 通过对整个范围进行平均，完全掩盖了这一关键的局部优势。这有力地证明了，一个模型的全局性能可能是一个糟糕的、甚至具有误导性的代理，无法代表其在特定应用中的价值。

### 相关性的数学：归一化与解释

所以我们计算出了一个 pAUC 值——比如，在 FPR 范围 $[0, 0.10]$ 上为 $0.0651$ [@problem_id:5221394]。这个数字意味着什么？与完整 AUC（其范围方便地在 $0.5$ 到 $1.0$ 之间）不同，pAUC 的取值范围取决于区间的宽度。在 $[0, 0.10]$ 上的最大可能 pAUC 不是 $1.0$，而是 $0.10$（一个宽为 $0.10$、高为 $1.0$ 的矩形）。这使得在不同区间宽度上比较 pAUC 值变得困难。

我们需要一种方法来将其标准化。最直接的方法是将 pAUC 除以 FPR 区间的宽度 [@problem_id:4604301]。在我们的例子中，这将是 $0.0651 / 0.10 = 0.651$。这个归一化后的值有一个优美而直观的解释：它是分类器在该特定 FPR 范围内实现的**平均真阳性率（或平均灵敏度）** [@problem_id:5221394]。因此，我们的测试在将[假阳性率](@entry_id:636147)保持在 10% 或以下的同时，提供了 65.1% 的平均灵敏度。这是一个具有临床意义且可比较的数字。

我们甚至可以做得更复杂。一种常见的标准化方法是重新缩放 pAUC，使得一个完全随机的分类器得分为 0，一个完美的分类器得分为 1，*在该特定范围内*。这个标准化 pAUC 的公式是 [@problem_id:4138852]：

$$ \mathrm{spAUC}(\alpha, \beta) = \frac{\mathrm{pAUC}(\alpha, \beta) - \text{Area of Random Classifier}}{\text{Area of Perfect Classifier} - \text{Area of Random Classifier}} $$

这给了我们一个通用的衡量标准，它是为我们特定的目标区域量身定制的。同样值得注意的是，与完整 AUC 一样，pAUC 是**患病率无关的**，并且**对于分数的任何严格单调递增变换都是不变的** [@problem_id:4604301]。这些是稳健的数学特性，使其成为一个可靠的度量指标。

### 最优选择：经济学与几何学的交汇

到目前为止，我们选择关注高特异性区域的动机是基于临床政策。但是否有更深层、更根本的原因呢？答案是肯定的，而且这个答案奇妙地来自于经济学与 ROC 曲线几何学的结合。

让我们回到医院管理者的角色。他们必须平衡两种成本：[假阳性](@entry_id:635878)的成本 $c_{FP}$（例如，不必要的活检），和假阴性的成本 $c_{FN}$（漏诊，这可能是灾难性的）。目标是选择一个决策阈值，以最小化患者群体的总期望成本，该群体的疾病患病率为 $\pi$。

通过微积分和决策理论的魔力，可以证明一个非凡的结论。最小化总成本的阈值对应于 ROC 曲线上的一点，该点的斜率恰好等于 [@problem_id:4951960] [@problem_id:5221394]：

$$ \text{Slope}_{\text{optimal}} = \frac{c_{FP}}{c_{FN}} \times \frac{1-\pi}{\pi} $$

让我们为一个筛查测试代入一些实际的数字：低患病率 $\pi = 0.01$，[假阳性](@entry_id:635878)成本 $c_{FP} = \$5000$，以及非常高的假阴性成本 $c_{FN} = \$50000$。最优斜率是：

$$ \text{Slope}_{\text{optimal}} = \frac{5000}{50000} \times \frac{1-0.01}{0.01} = 0.1 \times 99 = 9.9 $$

在 ROC 曲线上哪里能找到如此陡峭的斜率呢？曲线总是从左上角开始，急剧上升，然后向右移动时逐渐变平。一个高达 $9.9$ 的斜率必然会在曲线的最初始部分，即[假阳性率](@entry_id:636147)非常低的区域被找到！

这是一个深刻的结论。成本优化的冷酷逻辑自然地迫使我们在高特异性区域进行操作。我们对该区域 pAUC 的关注不仅仅是一种偏好；它是从经济和临床角度寻求最佳决策的直接结果。pAUC 正是在理性决策引导我们到达的那个点上衡量性能的指标。

### 几句忠告：现实的复杂性

与任何工具一样，pAUC 必须被明智地使用。现实世界是复杂的。当我们从有限的数据集估算 pAUC 时，我们面临两个最终的挑战：估计和不确定性。

首先，现实世界的经验 ROC 曲线并不总是表现得那么完美。由于采样噪声，它们可能会出现奇怪的“凹陷”或局部凸起 [@problem_id:4824316]。这就产生了一个两难的境地。我们是应该使用简单的[梯形法则](@entry_id:145375)，它对我们拥有的数据“忠实”，无论数据好坏？还是我们应该使用一个[统计模型](@entry_id:755400)（如双正态模型），它假设真实的 ROC 是平滑且凹的，从而有效地“熨平”这些皱褶？前者是非参数的，如果奇怪的形状是真实的，它就是无偏的；后者是[参数化](@entry_id:265163)的，变异性较小，但如果平滑假设是错误的，它就可能是有偏的。这是在整个科学领域都存在的经典[偏差-方差权衡](@entry_id:138822)。

其次，任何从数据中计算出的数字都只是一个估计值。如果我们用一组新的患者再次进行研究，我们会得到一个略有不同的 pAUC 值。我们对我们的数字有多大信心？为了回答这个问题，我们可以使用一种强大的计算技术，称为 **bootstrap (自助法)** [@problem_id:4568376]。本质上，我们通过从原始数据中重采样来创建数千个新的“伪数据集”，并为每一个数据集重新计算 pAUC。这数千个 pAUC 值的分布给了我们一个**[置信区间](@entry_id:138194)**——一个我们有（比如说）95% 的把握确定*真实* pAUC 所在的范围。这是诚实和稳健科学的标志：不仅提供一个单一的数字，而且还要量化我们对它的不确定性。

最后，探索部分 AUC 的旅程，是一个从一个诱人但有时具有误导性的全局总结，转向一个聚焦的、感知上下文的、最终更有意义的性能度量的故事。它教导我们，在科学中，如同在生活中一样，知道该忽略什么，往往和知道该关注什么同样重要。

