## 引言
海量的关键信息被锁定在电子健康记录的自由文本注释中，这些文本以一种复杂、充满术语的语言写成，为人类专家进行了优化，但却令计算机费解。生物医学领域的自然语言处理（NLP）应运而生，迎接这一挑战，提供了将这种混乱文本转化为结构化、可操作知识的强大方法。这种转变为加速研究、改善患者结局以及创建一个能从自身经验中学习的医疗保健系统提供了关键。本文旨在弥合临床记录的原始语言与现代医疗智能所需的结构化数据之间的鸿沟。

这一转变之旅将在两个主要部分中进行探讨。首先，我们将深入探讨核心的“原则与机制”，揭示如何一步步教会机器阅读医学文本，从识别概念、理解上下文到提取关系。接下来，在“应用与跨学科联系”部分，我们将见证这些基础技术如何彻底改变医疗保健，从放大单个患者的叙述到综合全球科学知识。

## 原则与机制

想象一下，你是一位刚刚发掘出一座巨大图书馆的考古学家。但这不是一个普通的图书馆。这些文本并非以工整、流畅的散文写成，而是专家速记、匆忙笔记、个人缩写和刻板预印模板的混乱混合体。有些部分术语密集，其他部分则只是测量数据的列表。这就是我们尝试教计算机阅读和理解病历时所面临的挑战。在电子健康记录（EHR）的自由文本注释中发现的医学语言自成一个世界，它为人类专家的精确性和速度而优化，但对机器来说却异常复杂 [@problem_id:4841459]。

我们的目标是将这美丽而混乱的文本转化为结构化、可操作的知识。这段旅程证明了将语言学、逻辑学和统计学的基本原则应用于人类生命中最重要的领域之一所具有的强大力量。这是一个逐层揭示文本内部隐藏秩序的过程。

### 医学语言：自成一派的世界

如果说一篇新闻报道像一首精心编排的交响乐，那么一份临床记录则更像一位艺术大师的即兴爵士乐表演。它有结构，但也有自由，并且它假设听者是专家。一篇关于心脏病的健康新闻报道会使用完整、语法完美的句子。而医生的记录可能只会简单地写道：“Pt c/o SOB x 2d, MI r/o。”这不仅仅是拼写错误的集合，而是一种不同的语言“方言”。

对机器而言，这种“电报式”风格是一场噩梦。功能词如“the”、“a”和“is”常常缺失。标点符号不一致。同一个概念可以用无数种方式表达。“Heart attack”、“myocardial infarction”、“MI”或一个特定的计费代码都可能指代同一个临床事件。此外，记录通常被组织成带有标题的部分，如**现病史（HPI）**、**系统回顾（ROS）**和**评估与计划（A）**，每一部分都有其自身的文体惯例 [@problem_id:4841459]。

要构建一个能阅读这种文本的机器，我们不能使用为网页或书籍设计的现成工具。我们必须构建专门的工具，并以临床文本独特的**词汇**（使用什么词）、**句法**（词语如何排列）和**语篇**（文档如何组织）特性为指导。

### 从词语到概念：第一次转换

我们的首要任务是教会机器识别文本中提到的关键医学“事物”。这是一个两步过程，构成了生物医学NLP的基石：找到实体，然后给它们一个单一、明确的名称。

首先，我们必须将文本分解成有意义的片段，这个过程称为**分词（tokenization）**。这听起来简单，但对于医学领域来说，这是一门精细的艺术。考虑一个术语“TNF-α”。如果我们简单地按标点符号分割，就会得到三个独立的词元：“TNF”、“-”和“α”。这个分子的基本统一性就丢失了。像**SentencePiece**这样的现代方法则更为巧妙。它们不依赖于僵化的规则，而是从数据本身中学习，发现“TNF-α”是一个频繁出现的、有意义的单位，应该保持完整。它们在原始文本上操作，甚至将空格和符号都视为待学习语言的一部分，这对于保持复杂生物医学术语的完整性至关重要 [@problem_id:5191099]。

文本分词后，我们进行**命名实体识别（NER）**。这项任务是找到并分类重要的名词：疾病、药物、基因、蛋白质、症状和实验室检查。当机器读到“Patients with breast carcinoma exhibiting HER2 overexpression received trastuzumab”时，一个NER系统就像一组荧光笔，将“breast carcinoma”标记为**疾病（DISEASE）**，将“HER2 overexpression”标记为对一种**蛋白质（PROTEIN）**的引用，将“trastuzumab”标记为一种**药物（DRUG）** [@problem_id:4577604]。

但仅仅高亮标记是不够的。我们需要解决歧义。这就是**标准化（normalization）**发挥作用的地方。标准化是将一个概念的无数种文本变体映射到一个单一、唯一标识符的神奇技巧。可以把它想象成在一部通用百科全书中创建一个权威条目。记录中的字符串“MI”和教科书中的术语“Myocardial Infarction”都被映射到同一个**概念唯一标识符（CUI）**，例如，在**统一医学语言系统（UMLS）**中的 `C0027051` [@problem_id:4849534]。

这之所以成为可能，得益于UMLS，这是一个巨大的资源，扮演着生物医学领域的罗塞塔石碑的角色。它有三个协同工作的关键部分 [@problem_id:4862346]：
*   **Metathesaurus**（元叙词表）是伟大的聚合器，它是一部巨大的词典，将来自200多种不同词汇表（如日常用语、计费代码和研究术语）的术语链接到一个共享的CUI。它知道“heart attack”和“myocardial infarction”是同义词。
*   **Semantic Network**（语义网络）是医学概念的语法。它提供了一个高层次的[组织结构](@entry_id:146183)，为每个概念分配一个宽泛的类型，如“疾病或综合征”或“药理物质”，并定义了它们之间的有效关系（例如，一种物质*治疗*一种疾病）。
*   **SPECIALIST Lexicon**（专门词典）是一个处理真实语言混乱性的工具。它知道“attacks”是“attack”的复数形式，并提供工具将单词解析为其组成部分，从而帮助弥合从原始文本到Metathesaurus中概念的鸿沟。

NER和标准化共同作用，将一片模糊的词语海洋转化为一组精确定义、结构化的概念。现在我们有了我们的成分列表。

### 理解上下文：超越仅仅命名事物

知道提到了“chest pain”是没用的，除非我们知道*患者是否真的有*。上下文就是一切。这就是确定**断言状态（assertion status）**的任务：这个概念是被肯定的（存在）、否定的（不存在）、可能的、假设的，还是在家庭成员的语境中提到的？ [@problem_id:5054471]。

否定是其中最有趣也最具挑战性的方面之一。对“no”或“not”进行简单的关键词搜索注定会失败。考虑一个来自临床记录的句子：“Patient denies chest pain or shortness of breath but reports dizziness and nausea.” [@problem_id:4857565]。

一个简单的系统可能会看到“denies”就只否定“chest pain”，或者更糟，在“shortness of breath”前没有看到明确的否定词就将其标记为肯定。但人类语言是按逻辑原则运作的。动词“denies”就像一个逻辑非运算符 $\neg$，其[影响范围](@entry_id:166501)或称**作用域（scope）**，延伸到它的整个语法宾语：短语“chest pain or shortness of breath”。该子句的逻辑形式是 $\neg(\text{chest pain} \lor \text{shortness of breath})$。

在这里，一条19世纪的美妙逻辑——De Morgan定律——为我们提供了帮助。其中一条定律指出 $\neg(p \lor q)$ 等价于 $(\neg p \land \neg q)$。否定一个析取（“A或B”）等同于分别否定每个部分。因此，这句话意味着患者没有胸痛“并且”没有呼吸急促。“denies”的作用域分布在“or”之上。系统还必须识别出单词“but”起到了屏障作用，阻止了否定的作用域影响到“dizziness”和“nausea”，后者被正确地肯定了。因此，一个真正智能的系统必须既是优秀的句法学家，也是优秀的逻辑学家，理解语法如何塑造意义的流动 [@problem_id:4857565]。

### 编织知识之网：从概念到关系

我们有了成分，也知道了它们的状态。理解的最后一步是找到配方——连接这些概念的关系。这就是**关系提取（Relation Extraction）**的任务。我们想要找到连接我们命名实体的动词。在句子“trastuzumab was shown to inhibit HER2”中，我们不只想知道提到了一个药物和一个蛋白质；我们想提取出三元组：`(trastuzumab, inhibits, HER2)`。

通过从数百万份文档中提取成千上万个这样的关系，我们可以构建一个**生物医学知识图谱**。这是一个巨大的网络，其中的节点是标准化的概念（疾病、药物、基因），边是连接它们的关系（治疗、导致、抑制、上调）。这个图谱是医学知识的机器可读表示，是发现新药靶点、理解疾病机制和构建更智能的临床决策支持系统的强大工具。

我们如何提取这些关系呢？多年来，这是通过**基于模式的系统**完成的，由人类专家编写精确的语法规则来寻找关系。这些系统透明且精度高，但很脆弱；句子结构的微小变化就可能破坏规则。如今，该领域由**神经方法**主导，特别是大型transformer模型。这些模型通过在大量文本上进行训练，学会从上下文中识别关系。它们要灵活和强大得多，但这种强大是有代价的。它们可能是“黑箱”，使得我们难以理解它们做出特定决策的原因，并且它们可能对数据的变化很敏感——一个在正式科学论文上训练的模型可能难以处理临床记录中的俚语，这个问题被称为**领[域漂移](@entry_id:637840)（domain shift）** [@problem_id:4577515]。

### 理解的引擎：构建特定领域的人工智能

这些强大的神经模型，如**BERT**，是驱动现代NLP的引擎。它们的力量来自于**预训练（pretraining）**。它们首先在巨大的文本语料库（如整个维基百科）上进行训练，目标很简单：猜测句子中缺失的单词。通过这个过程，它们学到了对语法、句法和语义的极其细致的理解——一种关于语言如何运作的“[归纳偏置](@entry_id:137419)”。

要为医学创建一个模型，我们有一个选择 [@problem_id:5191126]。我们是仅使用生物医学语料库从头开始训练一个模型？还是我们拿一个通用的、已经精通语言之道的模型，然后简单地在医学文本上继续其训练？后一种方法，**持续预训练（continual pretraining）**，是[迁移学习](@entry_id:178540)的一种形式。这就像决定是从大学第一天开始培养一名医生，还是找一位经验丰富的物理学家来教他们医学。物理学家已经知道[科学方法](@entry_id:143231)和如何批判性思考；他们有巨大的领先优势。同样，一个持续预训练的模型带来了其庞大的通用语言知识，使其能够更高效、更有效地学习医学领域的细节 [@problem_id:5191126] [@problem_id:5054471]。

### 机器中的幽灵：公平与偏见

伴随这种巨大力量而来的是巨大的责任。一个N[LP模](@entry_id:170761)型是一面镜子，反映了它所训练的数据，包括所有缺点。如果我们的历史数据包含社会偏见，模型将会学习，甚至可能放大这些偏见。这就引出了**[人口统计学](@entry_id:143605)偏见（demographic bias）**这一关键问题 [@problem_id:4588713]。

想象一下，我们训练一个模型从临床记录中检测一种疾病。我们的训练数据包含来自A组1000名患者的记录，但只有来自B组的200名患者的记录。一个不加思考的算法会优化其在多数群体上的表现，可能导致其在B组上的表现差得多。这不仅仅是数据点较少的问题；它可能导致**模型引发的差异（model-induced disparity）**。该模型可能根本无法学习到B组特有的语言模式，即使在完美平衡的数据集上进行测试，也会导致该组的错误率更高。

我们如何测试这一点？我们使用科学方法。我们可以在一个精心匹配的测试集上评估模型，其中每个群体都有同等的代表性。如果在这个[平衡集](@entry_id:276801)上，群体间的性能差距仍然存在，我们就知道问题不仅仅是测试数据的产物；偏见已经固化在模型本身之中。然后我们可以尝试修复这个问题，例如通过重新加权训练数据，给予少数群体更多的重要性。但正如数据经常显示的那样，这些偏见可能很顽固。发现一个模型对某些人群的准确性较低是一个深刻而令人谦卑的发现。它提醒我们，在医学领域追求人工智能不仅是一项技术挑战，更是一项深刻的人文和伦理挑战 [@problem_id:4588713]。从混乱的文本到结构化知识的旅程也必须是走向公平和公正的旅程。

