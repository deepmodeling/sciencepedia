## 引言
在对性能的不懈追求中，现代计算机处理器采用了一系列复杂的[优化技术](@entry_id:635438)，其中 CPU 缓存是提升速度的基石。这些小而快的存储体弥合了处理器与[主存](@entry_id:751652)之间巨大的性能鸿沟。然而，正是这种优化引入了一个微妙但深刻的安全漏洞。缓存的状态，作为近期计算活动的残留物，可以被其他程序观察到，从而产生一个泄露信息的“[侧信道](@entry_id:754810)”。本文旨在探讨这些性能特性如何演变为安全缺陷，即所谓的缓存攻击。

本探讨的结构旨在对这一复杂主题提供全面的理解。首先，在“原理与机制”部分，我们将剖析缓存的工作方式，以及攻击者如何通过基于争用和[推测执行](@entry_id:755202)的攻击来利用其特性。然后，在“应用与跨学科联系”部分，我们将考察这些漏洞对密码学和云计算等领域的实际影响，并探究在软件、[操作系统](@entry_id:752937)和硬件层面正在开发的各层防御措施。

## 原理与机制

要理解缓存攻击的工作原理，你首先必须认识到关于现代计算机的一个基本事实：它们为速度而生，而速度源于巧妙的“作弊”。现代处理器不是一个一次只做一件事的简单顺序机器。它是一个狂热、并行的宇宙，充满了预测、推测和优化，所有这些都旨在隐藏外部世界的巨大迟缓。最大的瓶颈是内存。你的处理器可以以闪电般的速度执行计算，但从主存（[RAM](@entry_id:173159)）中获取计算所需的数据，就像要求一位奥运短跑选手去另一个城市的图书馆取一本书。这是对时间的巨大浪费。

为了解决这个问题，架构师们创造了**缓存**：位于处理器核心旁边的小型、极快的存储体。可以把它想象成你身边的个人办公桌（`L1` 缓存）、你办公室里稍大一点的书架（`L2` 缓存），以及一个部门阅览室（`L3` 或末级缓存），所有这些都在你必须去主图书馆（RAM）之前。当处理器需要一条数据时，它首先检查它的办公桌。如果数据在那里（**缓存命中**），只需几个周期即可获得。如果不在（**缓存未命中**），它会检查书架，然后是阅览室，最后才踏上前往主图书馆的缓慢旅程。这个层次结构之所以工作得非常出色，是因为程序倾向于重用它们刚刚使用过的数据和指令——这个原则被称为**[引用局部性](@entry_id:636602)**。

但问题就在这里。为了效率，许多这些资源，尤其是较大的末级缓存（LLC），在同一芯片上运行的不同程序之间——甚至不同用户之间——是共享的。而这种共享中隐藏着一个秘密。缓存的状态——里面有什么，没有什么——并非随机的垃圾。它是近期活动的反映。如果一个程序能够微妙地观察或影响另一个程序留下的缓存状态，它就能了解到关于那个程序秘密操作的一些信息。为性能而设计的缓存，在不经意间成为了告密者。这就是**缓存[侧信道](@entry_id:754810)**的本质。

### 沙滩上的足迹：基于争用的攻击

想象两个人，一个攻击者和一个受害者，在一个只有一个共享工作台的办公室里工作，这个工作台只能放几件工具。这个工作台就是我们的缓存组。攻击者想知道受害者正在使用哪个工具，但不能直接看。他们该怎么做呢？

一种巧妙的方法就是我们所说的 **Prime+Probe** 攻击。该攻击分三步进行：

1.  **填塞 (Prime)：** 攻击者首先将自己的一套工具放到工作台上，完全占满它。他们确切地知道那里有什么以及在什么位置。用计算机术语来说，攻击者访问一组特定的内存地址，称为**驱逐集**，这些地址都映射到*同一个缓存组*，从而填满其所有的**路**（组中的槽位）。

2.  **受害者访问 (Victim Access)：** 允许受害者工作。如果受害者需要一个映射到同一工作台（我们的缓存组）的工具，他们必须腾出空间。他们会选择一个工具移除，然后放上自己的工具。

3.  **探测 (Probe)：** 攻击者回到工作台，并测量取回他们每个原始工具所需的时间。大多数工具会仍在原位（快速的缓存命中）。但如果有一个工具不见了，需要从主工具箱里取回（缓慢的缓存未命中），攻击者就知道受害者一定使用了那个位置。他们不是通过看到秘密本身，而是通过看到对共享资源的*争用*来检测到受害者的活动。

这种“足迹”的可预测性关键取决于受害者选择移除哪个工具。如果规则是总是移除**[最近最少使用](@entry_id:751225) (LRU)** 的工具，攻击就会变得确定性且高度可靠。攻击者可以把他们的“间谍”工具放在 LRU 的位置，并确信如果*任何*驱逐发生，他们的工具就会是被移除的那个。然而，如果替换策略是**随机**的，攻击者只知道他们的间谍工具有一定的概率被驱逐（例如，对于一个 $A$ 路的组，概率为 $1/A$）。攻击仍然有效，但会变得嘈杂，需要更多的测量才能确定 [@problem_id:3626329]。

与此密切相关的是 **Evict+Reload**。在这种攻击中，攻击者和受害者共享*特定*的一段数据（比如一个共享软件库中的函数）。攻击者通过制造争用来将共享数据从缓存中驱逐出去，然后等待。稍后，他们“重新加载”该数据。如果重新加载速度快，说明受害者在此期间访问了它，将其带回了缓存。如果速度慢，说明受害者处于空闲状态。这是一种强大的技术，特别是因为它不需要著名的 `CLFLUSH` 指令（一个显式清空缓存行的命令），使其即使在通常为安全而禁用此类指令的虚拟化环境中也变得可行 [@problem_id:3676132]。仅仅访问足够多的、映射到同一缓存组的其他数据就足以引起驱逐。

### 机器中的幽灵：[推测执行](@entry_id:755202)

多年来，缓存攻击虽然巧妙，但在某种程度上是有限的。后来，研究人员发现了一种方法，可以将其与现代 CPU 最强大的性能特性之一：**[推测执行](@entry_id:755202)**相结合。这一发现将一个巧妙的技巧转变为一个深远的安全威胁，催生了像 Spectre 和 Meltdown 这样的漏洞。

现代 CPU 就像一家高速餐厅里的通灵厨师。当它遇到一个选择（代码中的“分支”，比如一个 `if` 语句）时，它不会等待看程序究竟会走哪条路。那样太慢了。相反，它的**分支预测单元 (BPU)** 会做出猜测，并开始“推测性地”执行预测路径上的指令。如果猜对了，恭喜你，节省了宝贵的时间。如果猜错了（**错误预测**），CPU 必须撤销所有推测性工作，丢弃结果，然后从正确的路径重新开始。

从程序的角度——即**架构状态**——来看，就好像错误预测的路径从未被执行过。所有的寄存器和内存都恢复到它们正确的状态。但是**[微架构](@entry_id:751960)状态**呢？那些留在缓存中的足迹呢？它们并不总是被清理干净。

这就是关键的洞见。攻击者可以故意触发一次分支错误预测，来诱骗 CPU 推测性地执行一小段代码——一个“gadget”（代码片段）——而这段代码在架构上是永远不被允许运行的。这个 gadget 可以从受保护的内存位置读取一个秘密值，然后用这个秘密值以一种特定的方式触碰缓存。

例如，假设一个秘密字节的值是 $S=100$。这个推测性 gadget 可能会执行指令 `access(probe_array[S])`。这条指令会瞬态地访问一个数组的第 100 个元素。片刻之后，CPU 意识到自己的错误，分支错误预测被检测到，整个操作被撤销。`access` 的结果被丢弃。但损害已经造成：`probe_array[100]` 的缓存行现在位于 L1 缓存中。攻击者随后可以使用简单的计时测量来检查 `probe_array` 的哪个元素现在在缓存中，通过找到加载速度快的那个，他们就发现了秘密值是 $100$。

这种“[瞬态执行](@entry_id:756108)”强大到足以绕过基本的安全边界。
*   它可以将数据从[操作系统](@entry_id:752937)的内核泄露给用户程序。
*   它甚至可以绕过[虚拟化](@entry_id:756508)的[硬件保护](@entry_id:750157)。一个客户[虚拟机](@entry_id:756518)可以被诱骗去推测性地访问属于虚拟机监控程序（hypervisor）的内存，从而泄露云提供商自身的秘密。其中一个有趣的方面是，这种泄露通常只有在秘密数据已经存在于最快的 L1 [数据缓存](@entry_id:748188)中时才可能发生；如果 CPU 需要去更远的地方获取它，权限错误通常在数据被瞬态使用之前就被捕获了 [@problem_id:3657995]。
*   攻击面出人意料地广。即使在看似不可能的情况下，[推测执行](@entry_id:755202)也能留下痕迹。对一个完全未映射的内存地址进行推测性访问，在架构上会导致一个**页错误**。但在该错误被记录之前，CPU 可能已经尝试执行[地址转换](@entry_id:746280)，瞬态地将系统**页表**的条目加载到缓存中。攻击者可以检测到这一点，从而了解到受害者的[内存布局](@entry_id:635809) [@problem_id:3666428]。仅仅是提出一个被禁止的问题，其行为本身就留下了回响。

这些瞬态窗口很小——通常只有几十个周期——但一个 CPU 每个周期可以发射多条指令。一个运行数百万次但有可预测分支错误预测的简[单循环](@entry_id:176547)，可以打开成千上万个这样的推测窗口，每个窗口泄露几个比特。随着时间的推移，涓涓细流汇成洪水。攻击者可以计算出总的潜在泄露量；例如，一个有 $2.5 \times 10^6$ 次迭代且每 $400$ 次迭代发生一次错误预测的循环，可以创造 $6250$ 次瞬态机会，可能泄露数千字节的秘密数据 [@problem_id:3679355]。

### 噪声中的信号：信息论视角

从本质上讲，缓存[侧信道](@entry_id:754810)是一个通信信道，可以用信息论的优美工具来分析。

“信号”是缓存命中和缓存未命中之间的时间差。对于一个典型的 L1 缓存，一次命中可能需要 $t_{h} \approx 4$ 个周期，而一次需要访问[主存](@entry_id:751652)的未命中可能需要 $t_{m} \approx 200$ 个周期或更多。攻击者试图测量的就是这个差值 $\Delta t$。但这个信号被埋藏在“噪声”中——来自其他系统活动、[操作系统调度](@entry_id:753016)和虚拟化开销的随机波动。

为了测量这个信号，攻击者需要一个非常好的秒表。现代 CPU 提供了一个**时间戳计数器 (TSC)**，这是一个随每个周期递增的高分辨率计时器。这个计时器足够精确，可以轻松区分命中和未命中。因此，对抗此类攻击的第一道防线之一，就是降低计时器的可用性。例如，[操作系统](@entry_id:752937)可以故意为用户程序粗化计时器，增加如此多的[量化噪声](@entry_id:203074)，以至于信号 $\Delta t$ 被淹没 [@problem_id:3673107]。

泄露的[信息量](@entry_id:272315)取决于攻击的粒度。如果攻击者能确定受害者访问了单个缓存行中的 $L$ 个字节中的哪一个，他们就创建了一个无噪声信道，每次成功的攻击周期可以传输 $\log_2(L)$ 比特的信息 [@problem_id:3679374]。对于一个典型的 64 字节缓存行，那就是 $\log_2(64) = 6$ 比特每次观测！

即使受害者行为与攻击者观测之间的物理耦合很弱，攻击仍然可以成功。我们可以用一个简单的方程来模拟整个复杂系统：观测到的时间 $T$ 是一个基线 $T_0$，加上一个代表依赖于秘密的信号 $S$ 的项，该项由一个“[交叉](@entry_id:147634)[耦合系数](@entry_id:273384)” $\chi$ 缩放，再加上随机噪声 $\varepsilon$：$T = T_0 + \chi S + \varepsilon$。这个系数 $\chi$ 捕捉了受害者的活动有多少“泄露”到了攻击者的测量中。值得注意的是，即使 $\chi$ 非常小，并且在存在显著噪声的情况下，攻击者通过简单地重复测量多次并取平均值，仍然可以达到非常低的错误率。一个微弱的信号，经由统计学放大，可以变成一条清晰的信息 [@problem_id:3646913]。

这个原理——任何状态受秘密影响且可被他人观察的共享资源都是一个潜在的[侧信道](@entry_id:754810)——是普适的。它不仅适用于[数据缓存](@entry_id:748188)，也适用于[指令缓存](@entry_id:750674)、分支预测器，甚至存储[地址转换](@entry_id:746280)的专用缓存，如**[页表遍历](@entry_id:753086)缓存 (PWC)** [@problem_id:3663681]。每一次优化，每一个共享的捷径，都创造了一个潜在的隐蔽信道。缓存攻击的故事，就是发现这些源于对性能不懈追求的隐藏路径的故事。

