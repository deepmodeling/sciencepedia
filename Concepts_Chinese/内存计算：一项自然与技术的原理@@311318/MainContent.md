## 引言
在计算领域，一场悄无声息的革命正在挑战一个主导了70多年的设计：处理与存储的[分离](@article_id:370248)。这种传统的冯·诺依曼架构中，数据需要不断地来回传输，造成了被称为“冯·诺依曼瓶颈”的根本性交通拥堵，限制了[速度](@article_id:349980)并消耗大量能源。[内存计算](@article_id:378320)通过将计算直接织入存储单元的结构中，提供了一种彻底的解决方案。但如果这个“新”想法根本不新呢？本文探讨[内存计算](@article_id:378320)，不仅将其视为一项技术创新，更将其看作一个从自然界中重新发现的普适原理。我们将首先深入核心的“原理与机制”，审视[信息物理学](@article_id:339626)以及存储的真实成本。随后，在“应用与跨学科联系”部分，我们将拓宽[视野](@article_id:354700)，去发现生物系统乃至宇宙早已是这种优雅设计的践行者，为我们自身的技术未来提供了深刻的启示。

## 原理与机制

要真正理解[内存计算](@article_id:378320)这场革命，我们必须首先像一位好奇的物理学家一样，踏上一段旅程，并提出一些基本问题。究竟什么是记忆？使用它、改变它、*遗忘*它，需要付出什么代价？而自然界本身又是如何处理这些完全相同的问题的？答案不仅存在于[电路](@article_id:334707)图中，也蕴含在物理学、[信息论](@article_id:307403)乃至生物学的原理之中。

### 我们所说的“记忆”是什么意思？

在我们讨论在“记忆”中进行计算之前，让我们先剥离“记忆”这个词与[硅](@article_id:308041)芯片的常见联想，然后问一个更基本的问题：什么是一个有记忆的系统？在物理学和工程学领域，其定义异常简洁：如果一个系统在任何时刻的输出都依赖于过去（甚至未来！）的输入，那么该系统就被称为拥有**记忆**。如果输出*只*依赖于同一瞬间的输入，那么该系统就是**无记忆**的。

考虑一个简单的设备，其设计目的是将一系列数字快照（或称采样点）转换为平滑的连续信号——这个任务在你的手机音频系统中每秒钟发生无数次。实现这一目标的一种方法是使用**[一阶保持器](@article_id:333041) (First-Order Hold)**。这个设备会查看当前采样点 $x[n]$ 的值和*下一个*采样点 $x[n+1]$ 的值，并在这两点之间画一条直线。在两个采样点之间的任何时间 $t$，输出值都是这条线上的一点。那么，这个系统是无记忆的吗？在采样点 $x[n]$ 到达的瞬间，输出就是 $x[n]$。但在那之后的任何时刻，输出都同时依赖于过去的值 $x[n]$ 和未来的值 $x[n+1]$。由于其行为受到非当前时刻输入的影响，我们称这个系统是**动态的 (dynamic)**——它具有记忆 [@problem_id:1719687]。它“记得”它来自何处，也“知道”它要去向何方来绘制路径。

这个抽象概念是第一个关键点。记忆不仅仅是一个场所，它是一种动态特性。它是历史对现在产生影响的[印记](@article_id:302202)。我们将看到，这种影响会以最令人惊讶的方式出现。

### 遗忘的物理成本：信息、能量与[熵](@article_id:301185)

如果一个系统有记忆，它必然持有信息。而在物理宇宙中，信息并非抽象的柏拉图式理念；它被[热力学定律](@article_id:321145)束缚于现实。在20世纪60年代，一位名叫 Rolf Landauer 的物理学家取得了一项深刻的发现，将信息与能量直接联系起来。

其核心是**[熵](@article_id:301185) (entropy)** 的概念，你可以将其理解为我们对一个[系统不确定性](@article_id:334243)的[度量](@article_id:297065)，或者等效地，看作是“[缺失](@article_id:309529)信息”的数量。一个标准的[二进制](@article_id:319514)比特，其值为‘0’或‘1’的概率相等，具有一定的不确定性。我们不知道它的状态。要“擦除”这个比特——也就是，将其重置为一个已知状态，比如‘0’——我们必须消除这种不确定性。兰道尔原理 (Landauer's principle) 指出，这种擦除信息的行为存在一个不可避免的最低能量成本。对于单个比特，在温度为 $T$ 的环境中以热量形式[耗散](@article_id:304931)的最小能量为：

$E_{\min} = k_B T \ln 2$

此处，$k_B$ 是著名的[玻尔兹曼常数](@article_id:302824)，是[连接原子](@article_id:342120)微观世界与温度宏观世界的桥梁。$\ln 2$ 这一项直接来源于我们将两种可能性（‘0’和‘1’）压缩为一种的事实 [@problem_id:1636467]。你正在为减少系统的[熵](@article_id:301185)而支付能量税。

如果我们的擦除器很粗心呢？想象一个有缺陷的重置过程，它成功的概率只有 $p$，而以 $1-p$ 的概率使比特处于错误状态。我们是否仍然付出了全部代价？不。由于最终状态仍然不确定，我们并没有减少那么多的[熵](@article_id:301185)。[耗散](@article_id:304931)的最小热量会更少，由一个优美的公式给出：$Q_{\min} = k_B T (\ln 2 + p \ln p + (1-p) \ln(1-p))$，其中第二部分恰好是最终不确定状态[熵](@article_id:301185)的负值 [@problem_id:1975900]。能量成本与你实际销毁的[信息量](@article_id:336012)成正比。

这一原理可以扩展到任何信息处理过程。考虑经典的**[麦克斯韦妖](@article_id:302897) (Maxwell's Demon)** [思想实验](@article_id:328281)：一个小小的精灵将快速和慢速的分子分拣到两个独立的腔室中，凭空创造出温差，看似违反了[热力学第二定律](@article_id:303170)。这个问题的解决方案

