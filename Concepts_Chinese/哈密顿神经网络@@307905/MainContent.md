## 引言
机器学习模型，特别是[神经网络](@article_id:305336)，在直接从数据中学习复杂动力学方面取得了显著成功。然而，[标准模型](@article_id:297875)通常是“盲目的钟表匠”，它们学习的是相关性，而并不理解支配系统的基本物理原理。这导致了关键的知识鸿沟：模型可能会违反[能量守恒](@article_id:300957)等基本定律，从而产生物理上不合理的长期预测。我们如何才能构建出既能预测、又尊重物理世界基本结构的模型呢？

本文深入探讨[哈密顿神经网络](@article_id:301139)（HNNs），这是一类旨在解决上述问题的[物理信息](@article_id:312969)模型。通过将经典力学原理整合到[神经网络架构](@article_id:641816)中，HNNs 为科学建模提供了一种强大的新[范式](@article_id:329204)。第一章**“原理与机制”**将探讨 HNNs 如何超越学习任意动力学的范畴，转而学习一个单一、统一的量——系统的能量，即哈密顿量。您将了解到这种方法如何在数学上保证[能量守恒](@article_id:300957)，以及如何扩展它来处理摩擦等现实世界中的复杂情况。第二章**“应用与跨学科联系”**将展示这种方法在分子和[材料模拟](@article_id:355484)、量子领域探索以及[复杂网络](@article_id:325406)结构揭示等不同科学领域带来的变革性影响。

## 原理与机制

假设你想预测天气。你可以构建一个巨大而复杂的机器学习模型，喂给它几十年的大气数据，然后让它预测明天的温度。只要数据足够多、计算机足够强大，它的预测结果可能还不错。但它是否*理解*[热力学](@article_id:359663)、[流体动力学](@article_id:319275)和[辐射传输](@article_id:318852)的原理？很可能不理解。它将是一个“盲目的钟表匠”，是相关性分析的大师，却是因果关系探索的新手。这正是从数据中学习动力学所带来的希望与风险。

### 盲目的钟表匠：缺乏洞见的动力学学习

学习动力学的现代方法通常始于一种名为**神经普通[微分方程](@article_id:327891)（Neural Ordinary Differential Equation, Neural ODE）**的模型。假设我们是生物学家，试图为一个[基因调控网络](@article_id:311393)中蛋白质的复杂相互作用建立模型，但它们相互作用的基本规则完全是个谜 [@problem_id:1453811]。我们可以将蛋白质的浓度表示为一个[状态向量](@article_id:315019) $\mathbf{x}$，然后训练一个神经网络来学习该状态的时间[导数](@article_id:318324)，即 $\frac{d\mathbf{x}}{dt} = \text{NN}(\mathbf{x}, \theta)$。这个拥有数百万参数 $\theta$ 的网络，变成了一个[通用函数逼近器](@article_id:642029)，能够仅通过观察系统随时间的行为，就学会几乎任何动力学系统。

这是一个极其强大的想法。它使我们不必去猜测相互作用的数学形式，而这通常是一项不可能完成的任务。神经网络只需学习[矢量场](@article_id:322515)——即在[状态空间](@article_id:323449)的每一点上告诉系统下一步该走向何方的箭头。

但这种能力是有代价的。网络是一块白板，它对自然界的基本法则一无所知。它不知道[能量守恒](@article_id:300957)、[动量守恒](@article_id:321373)或[质量守恒](@article_id:331706)。如果你训练它预测行星的运动，它可能会学出一条让行星缓慢螺旋式坠入太阳的轨道，或者无中生有地获得能量并飞向星际空间。它没有内在地尊重物理学的基石原理。对于许多应用来说，这或许可以接受。但对于物理学家而言，这令人深感不满。自然并非任意规则的集合，它拥有深刻的内在结构。我们能教会我们的模型尊重这种结构吗？

### 物理学家的恳求：结构的神圣性

物理定律建立在对称性之上。如果你把一个孤立的分子向左移动几英尺，它的内能不会改变。如果你旋转它，它的能量也不会改变。如果这个分子是水（$\text{H}_2\text{O}$），并且你交换了两个氢原子，它仍然是完全相同的分子，具有完全相同的能量 [@problem_id:2908405]。这不仅仅是方便的事实，它们是基本的**对称性**——在平移、旋转和全同粒子[置换](@article_id:296886)下的[不变性](@article_id:300612)。

一个在[笛卡尔坐标](@article_id:323143)上训练的通用神经网络对这些对称性一无所知。如果没有明确的指令，它可能会预测分子的能量取决于它在实验室中的朝向，这意味着存在不符合物理规律的力和力矩，会导致分子无中生有地开始旋转 [@problem_id:2908409]。要构建一个物理系统的忠实模型，我们必须将这些对称性“植入”其中。我们必须设计一种架构，从其构造上就保证遵守这些规则。这可以通过使用本身就是[不变量](@article_id:309269)的输入（如原子间距离）或设计对这些变换具有数学[等变性](@article_id:640964)的网络层来实现 [@problem_id:2908414]。

但是，经典力学中最深刻的结构不仅仅关乎这些[几何对称性](@article_id:368160)。它关乎一个单一的、包罗万象的量，它支配着整个系统的演化：**能量**。

### 哈密顿的启示：学习能量，而非行为

在18世纪末和19世纪初，数学家 Joseph-Louis Lagrange 和 [William Rowan Hamilton](@article_id:376162) 发现了一种革命性的方式来重构经典力学。他们发现，可以用一个单一的标量函数来描述宇宙，而无需考虑力和加速度（$F=ma$）。对于一个[保守系统](@article_id:323146)，这个函数就是总能量——动能和势能之和——他们将其命名为**哈密顿量**，记作 $H$。

这是一个惊人的视角转变。如果我们能只学习这个简单的标量能量函数，而不是直接学习复杂、矢量值的运动规律呢？想象一个系统的状态由其广义坐标 $q$（如位置）及其[共轭动量](@article_id:351333) $p$（质量乘以速度）来描述。哈密顿量 $H(q, p)$ 是定义在这个“相空间”上的一个[能量景观](@article_id:308140)。[哈密顿力学](@article_id:306622)的绝妙之处在于，如果你知道了这个[能量景观](@article_id:308140)的形状，你就知道了系统将如何随时间演化的一切。你不需要单独指定动力学；动力学本身就*编码*在哈密顿量之中。

### 运动的秘方：[能量景观](@article_id:308140)如何引导宇宙

那么，哈密顿能量景观是如何决定运动的呢？通过一组优美对称的方程，即**哈密顿方程**：

$$
\dot{q} = \frac{\partial H}{\partial p}, \qquad \dot{p} = -\frac{\partial H}{\partial q}
$$

让我们稍作[停顿](@article_id:639398)，体会一下这个方程的含义。第一个方程告诉我们，位置的变化率（$\dot{q}$，即速度）由能量相对于动量的变化方式给出。第二个方程告诉我们，动量的变化率（$\dot{p}$，即力）由能量相对于位置变化的*负值*给出。由于力是势能的负梯度，这完全合情合理。对于没有摩擦的系统，这两个看似简单的方程是所有经典力学的引擎。

这就是**[哈密顿神经网络](@article_id:301139)（HNN）**背后的原理。我们不再训练一个网络直接学习 $\dot{q}$ 和 $\dot{p}$ 的复杂函数，而是用一个神经网络来学习一个单一、更简单的标量函数：哈密顿量 $H_{\theta}(q, p)$ [@problem_id:2410539]。一旦我们得到了学习到的[能量景观](@article_id:308140)，我们就不再需要网络来告诉我们如何运动了。我们使用[哈密顿方程](@article_id:316621)这个久经考验的铁律来[计算动力学](@article_id:383119)。网络学习“是什么”（能量），而物理定律提供“怎么做”（[运动方程](@article_id:349901)）。

这是机器学习与物理学的完美结合。但真正的魔力，即整个事业如此深刻的原因，在于一个隐藏的数学性质，它保证了[能量守恒](@article_id:300957)。

### 不可违背的誓言：结构如何保证守恒

让我们用更紧凑的形式来写[哈密顿方程](@article_id:316621)。设[状态向量](@article_id:315019)为 $x = (q, p)$。那么[哈密顿方程](@article_id:316621)可以写成一个单一的[矩阵方程](@article_id:382321)：

$$
\dot{x} = \begin{pmatrix} \dot{q} \\ \dot{p} \end{pmatrix} = \begin{pmatrix} 0 & I \\ -I & 0 \end{pmatrix} \begin{pmatrix} \frac{\partial H}{\partial q} \\ \frac{\partial H}{\partial p} \end{pmatrix} = \mathbf{J} \nabla_x H
$$

这里，$\mathbf{J}$ 是著名的**[辛矩阵](@article_id:303144)**。它有一个非常特殊的性质：它是**反对称**的，即其转置等于其负值（$\mathbf{J}^{\top} = -\mathbf{J}$）。这一个小小的性质是所有一切的关键。

让我们看看，当系统根据这些动力学演化时，我们学习到的能量 $H_{\theta}$ 会发生什么。能量的变化率由链式法则给出：

$$
\frac{dH_{\theta}}{dt} = (\nabla_x H_{\theta})^{\top} \dot{x}
$$

现在，代入我们为 $\dot{x}$ 构造的方程：

$$
\frac{dH_{\theta}}{dt} = (\nabla_x H_{\theta})^{\top} (\mathbf{J} \nabla_x H_{\theta})
$$

这个表达式，一个向量的转置乘以一个矩阵再乘以原向量，是一个标量。标量永远等于它自身的转置。所以让我们对整个表达式进行转置：

$$
((\nabla_x H_{\theta})^{\top} \mathbf{J} \nabla_x H_{\theta})^{\top} = (\nabla_x H_{\theta})^{\top} \mathbf{J}^{\top} (\nabla_x H_{\theta})
$$

但由于 $\mathbf{J}$ 是反对称的，$\mathbf{J}^{\top} = -\mathbf{J}$。所以我们发现：

$$
\frac{dH_{\theta}}{dt} = - \frac{dH_{\theta}}{dt}
$$

唯一一个等于其自身负值的数是零。因此，我们证明了：

$$
\frac{dH_{\theta}}{dt} = 0
$$

这不是一个近似。它不是“平均而言”或仅在我们训练所用数据上才成立的。它是一个数学上的确定性，是由方程本身的结构所强制执行的、不可违背的誓言 [@problem_id:2410539] [@problem_id:2886099]。通过强制我们的神经网络预测哈密顿量，然后将其代入这个**辛结构**，我们构建了一个*保证*能够守恒其所学能量的模型，无论网络的[权重和偏置](@article_id:639384)是什么。这个模型已经学会了一条基本的物理定律。

### 驯服真实世界：耗散与[开放系统](@article_id:308259)

当然，现实世界并非一个完美、无摩擦的天堂。物体会因摩擦而减速，系统也常常受到外力的作用。我们这个优雅的哈密顿框架能处理这种混乱吗？

答案是肯定的，而且非常精彩。该框架可以扩展为所谓的**端口哈密顿系统**。动力学方程被修改以包含耗散（能量损失）和外部端口（能量输入/输出）的项 [@problem_id:2886099]：

$$
\dot{x} = \big(\mathbf{J} - \mathbf{R}(x)\big)\,\nabla_x H(x) + \mathbf{G}(x)\,u
$$

让我们来分解这个方程。
- $\mathbf{J}\nabla_x H$ 是我们的老朋友，即在不改变总能量的情况下重新分配能量的保守部分。
- $-\mathbf{R}(x)\nabla_x H$ 是**耗散**项。矩阵 $\mathbf{R}(x)$ 被约束为**半正定**，这意味着它总是起到移除能量或保持能量不变的作用，就像摩擦一样。它总是将系统推向能量景观的“下坡”方向。
- $\mathbf{G}(x)u$ 是**端口**。它描述了外部控制或力 $u$ 如何向系统注入或从中抽取能量。

现在，我们的[神经网络](@article_id:305336)不仅可以学习哈密顿量 $H$，还可以学习耗散矩阵 $\mathbf{R}$ 和输入矩阵 $\mathbf{G}$。通过对这些矩阵施加数学约束（$\mathbf{J}$ 的反对称性，$\mathbf{R}$ 的[半正定性](@article_id:308134)），我们可以构建出在构造上就保证具有[无源性](@article_id:323267)和稳定性的模型，完美地描述真实世界中的机器、电路和机器人的物理特性。

### 保存机器中的幽灵：从方程到[算法](@article_id:331821)

我们已经构建了一个存在于微积分连续世界中的优美数学对象。但我们的计算机生活在一个由有限时间步长构成的离散世界中。当我们模拟 HNN 时，我们必须用一系列离散的跳跃来代替时间的平滑流动。这能保留其魔力吗？

答案是斩钉截铁的“取决于你如何跳跃！” 如果我们使用一个现成的标准[数值积分](@article_id:302993)器，比如常见的四阶龙格-库塔（RK4）方法，辛结构就会被破坏。[积分器](@article_id:325289)产生的离散时间映射不是辛的，我们精心守恒的能量将开始随时间漂移 [@problem_id:2410535]。

为了保留物理特性，我们需要使用一种同样尊重问题结构的数值方法。这些方法被称为**辛积分器**。其中最著名的是**[速度Verlet](@article_id:297498)**[算法](@article_id:331821)，它是分子动力学领域的主力。[辛积分器](@article_id:306972)并不会在每一步都守恒*精确*的哈密顿量 $H_{\theta}$。相反，它们精确地守恒一个邻近的“[影子哈密顿量](@article_id:299200)”$\tilde{H}$。由于这个[影子哈密顿量](@article_id:299200)是守恒的，真实的能量 $H_{\theta}$ 不会漂移走；它只是在一个常数值附近紧密[振荡](@article_id:331484)，从而带来了极佳的[长期稳定性](@article_id:306544) [@problem_id:2908432]。其他方法，例如使用由神经网络[参数化](@article_id:336283)的**生成函数**，也可以创建从一个时间步到下一个时间步的精确辛映射 [@problem_id:2410535]。

最终的教训是深刻的。要构建能够捕捉物理系统灵魂的机器学习模型，仅仅向它们展示数据是不够的。我们必须将物理学的基本原理和结构——从问题的对称性，到动力学的[哈密顿形式](@article_id:339920)，再到模拟[算法](@article_id:331821)本身的[辛性](@article_id:343816)质——注入其中。通过这样做，我们超越了盲目的钟表匠，开始创造出真正理解物理世界的模型。