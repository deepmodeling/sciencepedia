## 引言
一种新的[范式](@entry_id:161181)正在重塑科学探究，从模式识别转向对底层机制的更深层次理解。这就是基于模型的[深度学习](@entry_id:142022)的世界：在这里，算法学习的是一个系统的基本“物理学”或“语法”，而不仅仅是简单地记忆范例。几十年来，像[蛋白质折叠](@entry_id:136349)这样的复杂问题依赖于基于模板的方法，但在缺乏已知亲缘物种的情况下，这些方法便会失效。基于模型的[深度学习](@entry_id:142022)通过从海量数据中学习并推导出基于第一性原理的解决方案来弥补这一差距，这代表了从抄袭答案到真正理解问题的飞跃。

本文将通过两章来探讨这一革命性的转变。首先，在“原理与机制”一章中，我们将深入探讨驱动这些模型的核心思想，审视它们如何解释进化数据、转换几何问题以及模拟时间的连续流动。我们将看到它们如何学会以关系的方式思考，甚至表达对自己预测的信心。随后，“应用与跨学科联系”一章将展示这些原理的深远影响，从解码生命分子、设计新颖蛋白质，到与基因组学、[材料科学](@entry_id:152226)和实验研究建立联系，最终拓展科学发现的疆界。

## 原理与机制

要真正领会基于模型的深度学习所带来的革命，我们必须深入其内部一探究竟。其关键不在于记忆答案，而在于发现游戏的基本规则。想象一下，你正在尝试解决一个复杂的拼图。一种方法是找到一个相似的、已解决的拼图，并复制其解决方案。这种方法很有效，但前提是存在相似的拼图。另一种方法是研究成千上万个不同的已解拼图，不是为了复制它们，而是为了推断出拼图碎块必须如何组合在一起的基本原则。这正是基于模型的[深度学习](@entry_id:142022)的核心：它致力于直接从庞大的范例库中学习一个系统的“物理学”或“语法”。

### 学习规则，而非名单

让我们以生物学中最宏大的谜题之一为例：一条长链状的氨基酸——蛋白质——如何将自己折叠成一个独特而复杂的三维机器。几十年来，一个主流策略是**同源建模**。如果你想知道一种新蛋白质的结构，你会去寻找一个已知的亲缘体，即“同源物”，其结构已在实验室中被 painstakingly 解决。然后，你会将这个已知结构用作模板，将你的新序列拉伸并压缩到它上面。如果你找到了一个近亲，这种方法效果非常好，但如果你的蛋白质是一个“孤儿”，属于一个没有任何已知亲缘的全新家族呢？这种方法就完全失效了；你没有模板可以复制 [@problem_id:1460283]。

在这里，以 [AlphaFold](@entry_id:153818) 这样的奇迹为代表的深度学习方法，采取了一条截然不同的路径。它不寻找单一的模板。相反，它在几乎整个公开的实验确定结构库——**蛋白质数据银行 (PDB)** 上进行训练 [@problem_id:2107894]。通过检查数十万个结构，模型不是在记忆形状，而是在学习支配折叠的基本生物物理和统计原理。它学习什么使蛋白质结构“貌似合理”。

其最强大的老师之一是进化。通过将一个蛋白质的序列与其在**多重[序列比对](@entry_id:172191) (MSA)** 中的进化表亲进行比较，模型可以发现那些在三维空间上相距甚远，但在亿万年间始终一同突变的氨基酸对。这种协同进化是跨越时间的幽灵般的低语，暗示着这两个残基在最终的三维结构中很可能手拉手。通过学习解读这些低语，并结合氨基酸的基本化学语法，模型可以从头开始构建一个结构，即使对于一个没有模板可用的全新家族的蛋白质也是如此 [@problem_id:1460283]。这就是从复制答案到从第一性原理——或者更准确地说，从数据中学习到的原理——推导答案的区别。

### 一种新的关系几何学

那么，机器是如何“思考”一个三维形状的呢？如果你用其原子的 $(x, y, z)$ 坐标来描述一个蛋白质，你会立即遇到一个问题。如果你只是在空间中旋转蛋白质，所有的坐标都会改变，但蛋白质本身是完全相同的。[神经网](@entry_id:276355)络将很难学会在有无限多种同样有效的可能输出（所有旋转后的版本）时，产生一个单一的正确输出。问题不在于形状，而在于我们对它的描述。

突破在于将视角从绝对位置转向相对关系。我们不再问“原子 $i$ 在哪里？”，而是问“原子 $i$ 和原子 $j$ 之间的距离是多少？”这个距离是一个**[不变量](@entry_id:148850)**——无论你如何在空间中翻滚蛋白质，它都不会改变 [@problem_id:2107912]。

这些强大模型的早期版本并不试图直接预测三维坐标。相反，它们预测一个**距离图 (distogram)**，这是一个二维图，其中每个像素 $(i, j)$ 代表残基 $i$ 和残基 $j$ 之间的预测距离。这个绝妙的中间步骤将一个困难的几何问题转化为一个更易于管理的二维图像预测任务，而这正是[神经网](@entry_id:276355)络所擅长的。通过预测一个完整的内部距离和方向网络，模型提供了一组约束，从而可以自信地组装出三维结构。它学会了关注蛋白质的内在几何结构，而不是其在空间中的任意朝向。

### 发现的引擎：编织信息

有了这个新视角，让我们来看看驱动这些预测的现代引擎。像 [AlphaFold2](@entry_id:168230) 或 RoseTTAFold 这样的系统架构，是一曲优美的信息处理交响乐。它始于两个主要的信息流：一个携带关于序列中每个残基信息的[一维表示](@entry_id:136509)，以及一个编码残基对之间关系（距离图的继承者）的二维表示。

在 [AlphaFold2](@entry_id:168230) 架构中，这两个流进行深入的对话。信息来回流动。[一维流](@entry_id:269448)可能会“告诉”[二维流](@entry_id:266853)，“残基5是一个庞大的[疏水性](@entry_id:185618)氨基酸。”[二维流](@entry_id:266853)可能会回答，“我的进化数据显示残基5靠近残基98。让我们更新我们对它们关系的理解。”这种迭代交换使模型能够完善其假设，让序列级信息和配对信息相互通知、相互纠正。

RoseTTAFold 模型为这一主题引入了一个更为优雅的变体：**三轨网络** [@problem_id:2107940]。它不仅让一维和二维表示对话，还增加了第三条[轨道](@entry_id:137151)：一个真实的、不断演化的三维结构。从一开始，信息就在这三者之间同时流动。新出现的三维结构可以向二维图提供反馈（“你预测的这些距离在真实的三维空间中不太行得通，让我们调整一下”），这反过来又会完善一维特征。这是一个整体过程，序列、关系图和物理对象同时被塑造，每一个都在约束和引导着其他部分，朝向一个最终的、连贯的解决方案。

### 超越静态形状：模拟生命之舞

这个核心思想——学习一个系统的基本规则——并不仅限于静态的[蛋白质结构](@entry_id:140548)。它为描述随时间变化的系统提供了一种通用语言。考虑模拟一个生物过程，比如血液中药物的浓度。测量通常是在不规则、不方便的时间点进行的：上午8:05，上午11:30，下午4:42。

像**[循环神经网络 (RNN)](@entry_id:143880)** 这样的传统时间序列模型以离散的步骤思考。它被构建为在时间 $t$ 接收输入，并预测时间 $t+1$ 的输出。为了处理不规则的数据，你必须笨拙地将你的测量值强制放入一个固定的网格中，也许是通过猜测“缺失”时间点的值。

**[神经常微分方程](@entry_id:143187) (Neural ODE)** 提供了一个更深刻的解决方案 [@problem_id:1453831]。它不是学习一个步进的转换，而是学习底层的动力学本身。它学习一个函数 $f$，该函数代表系统瞬时变化率，即对其在任何时刻“速度”的数学描述：
$$
\frac{d \boldsymbol{h}(t)}{dt} = f(\boldsymbol{h}(t), t)
$$
在这里，$\boldsymbol{h}(t)$ 是你系统在时间 $t$ 的状态（例如，蛋白质浓度）。[神经网](@entry_id:276355)络*就是*函数 $f$。一旦模型学会了这个基本的变化规则，你就可以使用一个标准的 ODE 求解器，从任何起点将其在时间上向前或向后积分到任何其他任意时间。你不再受离散步骤的束缚。你拥有一个过程的[连续模](@entry_id:158807)型，这是一种更自然、更强大的方式来表示现实的流动、连续的本质。就像处理蛋白质一样，我们已经从描述一系列状态转变为学习支配它们的法则。同样的原则可以应用于不同领域，例如学习支配基因如何从原始 DNA 序列表达的“[剪接](@entry_id:181943)密码” [@problem_id:2932031]。

### 与机器对话：信心与谦逊

一个真正智能的系统不仅给出答案，它还知道自己知识的局限。这些模型最具有科学重要性的特征之一是它们能够报告其[置信度](@entry_id:267904)的能力。

[AlphaFold](@entry_id:153818) 提供一个名为 **pLDDT** (predicted Local Distance Difference Test) 的逐残基分数。一个残基的高分（例如，高于90）是模型在告诉你，“我非常有信心，该残基的局部环境——其直接邻居的位置——被正确预测了。”而一个低分（例如，低于50）则是谦逊的标志：“我对这个区域不确定。它可能是内在无序且柔性的，或者我只是缺乏足够的信息来确定它。” [@problem_id:2107913]。

为了理解对整体结构的信心，我们看另一个输出：**预测对齐误差 (PAE) 图** [@problem_id:2107947]。这张二维图告诉你，如果你将结构对齐到残基 $i$ 上，残基 $j$ 位置的预期误差。想象一个蛋白质，它有两个坚固、紧凑的域，由一条长而柔性的链连接。这个蛋白质的 PAE 图将会非常优美且信息丰富。你会看到沿对角线有两个深色的实心方块，表明每个域*内部*的误差非常低（高置信度）。但是连接两个域的非对角线区域会是浅色的，表明误差很高（低[置信度](@entry_id:267904)）。这不是失败！模型正确地告诉你，虽然它知道每个域各自的形状，但由于柔性连接体的存在，它们之间的相对朝向是不确定的。

这凸显了一个根本的局限性。这些模型的标准输出是一个单一的静态结构。它代表了寻找一个貌似合理、低能量状态的优化结果 [@problem_id:2107904]。但许多蛋白质是动态的机器。例如，一个**变构**酶通过在“关闭”和“开启”两种形状之间切换来发挥功能。一个单一的预测结构只能向你展示这部电影的一个快照，而不是定义其功能的、状态间的关键转变 [@problem_id:2107949]。同样，如果你用一个在训练数据中没有先例、也没有进化线索的全新、设计的拓扑序列来挑战模型，它很可能会正确地构建局部的[二级结构](@entry_id:138950)，但无法组装出全局折叠。它的置信度分数会诚实地反映这一点，局部螺旋和折叠片的 pLDDT 分数很高，但连接它们的环和界面的分数很低 [@problem_id:2107900]。

在与机器的这种对话中，低[置信度](@entry_id:267904)区域往往和高[置信度](@entry_id:267904)区域一样具有科学趣味。它们为我们指明了柔性区域，指明了模型知识的边界，以及等待新发现的激动人心的前沿。

