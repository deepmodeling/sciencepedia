## 应用与跨学科联系

在我们完成了对[信息熵](@article_id:336376)基本原理的探索之后，你可能会产生一种与 Claude Shannon 本人相似的感觉。杰出的数学家 [John von Neumann](@article_id:334056) 曾有名地告诉 Shannon，他应该把自己这个新的[不确定性度量](@article_id:334303)称为“熵”，不仅因为它的数学形式与[统计力](@article_id:373880)学中使用的形式相同，更带点嘲讽意味的是，因为“没人真正知道熵是什么，所以在辩论中你总能占上风。”

然而，这个玩笑最终却促成了现代科学中最深刻的统一之一。熵作为“缺失信息”的概念已经从其最初的[通信理论](@article_id:336278)容器中“泄漏”出来，[渗透](@article_id:361061)到几乎所有科学探究领域。它已经成为一种谈论不确定性、复杂性和信息本身的通用语言。在本章中，我们将探索这一思想的惊人传播，看看同一个方程如何帮助我们理解气体的行为、我们DNA的秘密、混沌的本质以及科学发现的艺术。

### 信息的物理核心：[热力学](@article_id:359663)与[统计力](@article_id:373880)学

最自然，也许也是最令人震惊的联系，存在于信息论与物理学之间。你在[热力学](@article_id:359663)课堂上可能学到的[吉布斯熵](@article_id:314565)，$S = -k_B \sum_i p_i \ln p_i$，看起来与香农的公式惊人地相似。在这里，$p_i$ 是一个[粒子系统](@article_id:355770)处于特定微观[排列](@article_id:296886)或“微观状态”的概率。这两个公式实际上在讲述同一个故事。它们是成正比的，通过一个简单的常数联系在一起：$S = (k_B \ln 2) H$，其中 $H$ 是以比特为单位的[香农熵](@article_id:303050)[@problem_id:1967976]。

这意味着什么？这意味着一个系统的[热力学熵](@article_id:316293)——一个支配着热流、[发动机效率](@article_id:307095)和[时间之矢](@article_id:304210)方向的量——不过是我们对该系统真实微观状态*缺失信息*的度量。玻尔兹曼常数 $k_B$ 只是一个转换因子，将抽象的“比特”单位转换为对物理学家来说方便的物理单位——能量/温度（[焦耳](@article_id:308101)/开尔文）。这并不比英寸和厘米之间的转换因子更神秘；长度这个基本概念是相同的。

让我们把这个概念具体化。想象一个中间有隔板的盒子。一边是气体A，另一边是气体B。我们确定地知道，左边的任何粒子都是A，右边的任何粒子都是B。我们关于随机选择一个粒子的身份的[香农熵](@article_id:303050)为零。现在，我们移开隔板[@problem_id:1632179]。气体混合在一起。如果我们现在从盒子中随机挑选一个粒子，我们不再确定它的身份。它可能是A或B。我们的不确定性——我们的[香农熵](@article_id:303050)——增加了。同时，物理学家会告诉你，[热力学](@article_id:359663)的“[混合熵](@article_id:321802)”也增加了。深刻的洞见在于，这并非两个独立的现象；它们是对同一事件的两种描述。物理熵的增加恰好与我们对系统[信息损失](@article_id:335658)的量成正比。看来，宇宙厌恶完全确知的状态，就像人们常说它厌恶真空一样。

### 生命的蓝图：生物学和遗传学中的信息

如果说物理学为[信息熵](@article_id:336376)提供了最深的根基，那么生物学则为其提供了最肥沃的土壤。毕竟，生命就是一场信息的博弈——存储信息、复制信息和执行信息。

在最基本的层面上，我们可以用熵来量化生命分子的结构复杂性。考虑一个由一组[单体](@article_id:297013)单元构成的长聚合物链，如DNA或蛋白质[@problem_id:1991853]。一个不断重复相同单元的链，`AAAAA...`，是完全有序和可预测的；它的熵为零。而一个其中单元以不同频率出现的链，则具有一定的结构随机性，其非零的熵可以量化其复杂性。

当我们审视细胞内的动态过程时，这个概念变得异常强大。我们DNA中的单个基因通常可以通过一种称为[可变剪接](@article_id:303249)的过程产生多种不同的蛋白质。通过选择将基因转录本的哪些部分拼接在一起，细胞可以从一个单一的蓝图创造出各种分子工具。产生每个版本的概率是可以测量的。根据这些概率，我们可以计算[剪接](@article_id:324995)过程的[香农熵](@article_id:303050)[@problem_id:1439027]。这个以比特为单位的数字告诉我们，该基因的调控中编码了多少“选择”或“灵活性”。一个高熵基因是一件多功能工具，而一个低熵基因则是一个专职专家。

从更大的尺度看，[信息熵](@article_id:336376)已成为[生物信息学](@article_id:307177)中不可或缺的工具，用于通过比较不同物种的基因和蛋白质来解码其功能[@problem_id:2412714]。当我们比对来自人类、小鼠、鱼类和果蝇的某种[蛋白质序列](@article_id:364232)时，我们发现氨基酸链中的某些位置在每个物种中几乎都是相同的。这些是高度保守的位点。其他位置则五花八门，出现了许多不同的氨基酸。保守位点的熵非常低；自然界通过数十亿年的进化，消除了这些位置的不确定性，因为确切的氨基酸对于蛋白质的功能至关重要。相比之下，高熵位点对突变更具耐受性。通过计算每个位置的熵，我们可以创建蛋白质功能景观图，突出其工作中最重要的区域，而无需实际观察蛋白质的活动。信息含量，定义为从完全随机序列中熵的减少量，直接指向了生物学上的重要性。

最后，我们可以将这些思想应用于整个生物系统。你的免疫系统维持着一个庞大而多样化的[T细胞](@article_id:360929)“库”，每个[T细胞](@article_id:360929)都有一个独特的受体，准备识别特定的病原体。免疫系统的健康状况取决于这个库的多样性。利用高通量测序，免疫学家可以计算不同类型的[T细胞受体](@article_id:364833)及其频率，将这个库视为一个[概率分布](@article_id:306824)。然后他们可以计算其香农熵，以及相关的多样性指标，如丰富度和均匀度[@problem_id:2861334]。这为免疫健康提供了量化指标。众所周知，衰老或[免疫衰老](@article_id:372037)的一个特征是这种多样性的下降。细胞库被少数几个扩增的细胞克隆所主导，导致丰富度和均匀度降低，从而导致熵值降低。因此，抽象的熵概念成为了衡量人类衰老过程中一个基本方面的具体生物标志物。

### 从混沌中见秩序，从噪声中见语言：复杂系统中的熵

熵也为观察迷人的复杂和[混沌系统](@article_id:299765)世界提供了一个新的视角。20世纪最惊人的发现之一是，简单的、确定性的数学规则可以产生实际上是随机的行为。

考虑著名的逻辑斯蒂映射，一个常用于模拟[种群动态](@article_id:296806)的简单迭代方程。对于某些参数值，其行为是完全混沌的[@problem_id:899392]。如果你绘制它生成的数值序列，它们似乎在不可预测地跳动，从不安定下来。虽然生成下一个值的规则是完全已知的，但你无法预测遥远未来的值。这个系统是一个“随机性生成器”。我们可以计算这些值分布的香农熵，并得到一个正数。这个熵量化了系统固有的不可预测性；它是系统在每个时间步长上产生新信息的速率，从而消除了我们进行长期预测的能力。在这种情况下，熵是混沌的代价。

许多现实世界的系统，从天气到股市再到语言，并不仅仅是独立事件的序列。现在发生的事情取决于之前发生的事情。对于这类可以建模为[马尔可夫过程](@article_id:320800)的系统，我们使用一个相关的概念，称为**[熵率](@article_id:327062)**[@problem_id:365091]。它衡量的是在给定系统历史的情况下，*每一步*的平均不确定性或信息内容。这是当你看到句子中的下一个词或旋律中的下一个音符时感到的平均“惊奇”度。例如，英语的[熵率](@article_id:327062)远低于随机字母序列的熵，因为语法和上下文的规则限制了我们的选择，但它远非零，这就是为什么语言可以传达新信息。有趣的是，对于一些具有无限词汇的理想化语言模型，整个语言的总熵可以是无限的，但[熵率](@article_id:327062)仍然是一个有限且有意义的量，表征了其结构和效率[@problem_id:1891711]。

### 提问的艺术：工程学和数据科学中的熵

[信息熵](@article_id:336376)最实用、最现代的应用或许在于从数据中学习的科学。每一次实验，从对金属棒进行的简单[拉伸测试](@article_id:364671)到复杂的[临床试验](@article_id:353944)，都是为了减少我们对世界的不确定性。但我们应该进行哪项实验呢？

信息论通过[贝叶斯推断](@article_id:307374)的框架，给了我们一个极为优雅的答案。想象一位工程师试图通过拉伸一根杆并测量其变形量来确定材料的刚度（[杨氏模量](@article_id:300873)，$E$）[@problem_id:2707586]。在实验之前，她对 $E$ 的了解由一个“先验”[概率分布](@article_id:306824)描述，该分布具有一定的[香农熵](@article_id:303050) $h(E)$。在她收集了一些数据 $\mathbf{Y}$ 之后，她将自己的知识更新为一个“后验”分布 $p(E|\mathbf{Y})$，这个分布有望更窄，并且具有更低的熵 $h(E|\mathbf{Y})$。对于该特定实验，不确定性的减少量是 $h(E) - h(E|\mathbf{Y})$。

但如果她还没有进行实验，而是在决定*如何*进行实验呢？她应该使用更精确的传感器吗？还是不同的载荷？她应该选择她*[期望](@article_id:311378)*能产生最大熵减少的实验设计。这个量——[期望](@article_id:311378)的不确定性减少量——有一个名字：未知参数与数据之间的**[互信息](@article_id:299166)**，$I(E;\mathbf{Y})$。它被定义为 $I(E;\mathbf{Y}) = h(E) - h(E|\mathbf{Y})$。这将实验设计从一门基于直觉的艺术转变为一门定量科学。我们可以使用[计算机模拟](@article_id:306827)来计算数十种潜在实验设置的互信息，并选择在数学上保证[信息量](@article_id:333051)最大的那一个。这一原则，被称为[贝叶斯实验设计](@article_id:348602)，正在从[材料科学](@article_id:312640)、机器学习到医学诊断等领域引发革命。

### 统一的观点

我们的旅程结束了。我们看到同一个数学概念，时而是支配宇宙的物理定律，时而是破译生命密码的工具，时而是衡量混沌不可预测性的尺度，时而是科学发现的指导原则。Von Neumann 的俏皮话最终既对又错。我们现在对熵是什么有了更清晰的认识：它是一种关于不确定性、选择和缺失信息的普适度量。但在某种程度上，他说得也对，它确实能在任何辩论中给人带来优势，因为它是迄今为止被构想出的最强大、最具统一性的概念之一，提供了一种通用语言来描述从原子到星系、从基因到大脑的世界运作方式。