## 应用与跨学科联系

在遍历了评估分类器的抽象原则——一个充满真与假、精确率与召回率的世界——之后，我们可能会问自己：“这一切都是为了什么？”这些指标仅仅是我们在计算机上玩的游戏中的数字，还是它们以一种深刻的方式与世界相连？答案，你会很高兴听到，是它们不仅与世界相连；它们正是我们用来理解世界、构建帮助我们的工具、以及思考我们创造物后果的语言。这正是这些思想真正美妙之处的体现。

### 首要问题：模型到底好不好？

想象你是一位正在寻找新药的科学家。可能的分子宇宙浩瀚无垠，如同宇宙级别的草堆。你的计算机模型，一个“对接算法”，不会对每个分子给出一个简单的“是”或“否”。相反，它给你一个*分数*，一个从最有希望到最没希望的排序列表。你无法测试每一个分子，所以你从列表顶部开始。关键问题是：模型是否成功地将那几根“针”——有效的候选药物——放在了这个巨大列表的顶端？

这就是我们那些与阈值无关的指标——ROC和[精确率-召回率曲线](@entry_id:637864)——变得不可或缺的地方。通过绘制这些曲线，我们不局限于任何一个单一的截断点。我们是在同时审视模型在*所有*可能截断点上的性能。然后，[曲线下面积](@entry_id:169174)（AUC）给了我们一个单一而优美的数字，总结了模型将好东西排在坏东西前面的能力 [@problem_id:3839980]。AUC为1.0意味着完美的排序；AUC为0.5意味着模型不比随机猜测好。

ROC曲线实际上向我们*展示*了什么？它给了我们一张分数分布之间分离情况的图片。想一个试图检测虚假产品评论的模型。一个好的模型会学会给虚假评论高分，给真实评论低分。这两组的分数会形成两个不同的“山丘”，即分布。这两个山丘分离得越开，就越容易在它们之间画一条线，AUC也就越高。如果你把这个模型应用到一个新的领域，比如说，餐厅评论而不是产品评论，你可能会发现模型会感到困惑。两个分数山丘会靠得更近，它们重叠得更多，AUC也会下降 [@problem_id:3167129]。[ROC曲线](@entry_id:182055)本质上就是这种分离情况的视觉总结。

### 权衡的艺术

生活很少只关乎一个单一的数字。更多的时候，它关乎在各种权衡中航行。正如我们所见，[F1分数](@entry_id:196735)是[精确率和召回率](@entry_id:633919)的[调和平均](@entry_id:750175)数。但为什么是这种特定的组合？答案在于犯错的*成本*。

考虑一个旨在读取电子健康记录中医生笔记并标记潜在药物不良反应的系统。它可能犯下哪些错误？

当系统将一个无害事件标记为不良反应时，就发生了**[假阳性](@entry_id:635878)**。这会产生一个警报，需要医生去调查。如果这类警报太多，你就会得到“警报疲劳”——医生开始忽略警告，甚至是真实的警告。这是一种“狼来了”的错误。

当系统漏掉一个真实的不良反应时，就发生了**假阴性**。一个病人可能会因为一个危险的模式未被检测到而受到伤害。这是一种本该大声呼喊时却保持沉默的错误。

显然，假阴性的成本比[假阳性](@entry_id:635878)的成本高得不成比例。在这种情况下，我们希望系统有非常高的召回率（找到所有真实病例），即使这意味着接受较低的精确率（以及更多需要医生核查的假警报）。[F1分数](@entry_id:196735)是一个起点，但在现实世界中，我们必须根据我们问题的独特后果来权衡[精确率和召回率](@entry_id:633919) [@problem_id:4588718]。

这种对排序列表顶部的关注，在[药物发现](@entry_id:261243)的[虚拟筛选](@entry_id:171634)等领域中更为极端。面对数百万种化合物，化学家们只能负担得起合成和测试其中极小一部分——也许是前1%。在这里，一个名为**富集因子**（$EF$）的专门指标经常被使用。$EF_{1\%}$告诉你，与随机选择相比，你列表中前1%的真正“命中物”的浓度高出多少。这是一种“早期识别”的度量。美妙的是，这个特定领域的指标并非什么外来概念；它与我们已经知道的直接相关。富集因子就是在那个截断点上你所达到的精确率，除以整个数据集中命中物的总体流行率 [@problem_id:4597618]。这是另一个为特定、重要任务量身定制的普适原则的例子。

### 从评估到行动

好了，我们理解了权衡。但在某个时刻，必须做出决定。一[位流](@entry_id:164631)行病学家有一个模型，可以生成一张关于寄生虫环境适宜性的连续地图。输出是一张美丽的彩色地图，红色阴影表示高风险，蓝色阴影表示低风险。但他们应该把有限的医疗用品和干预团队派往哪里？他们不能“大致”派往所有地方。他们需要画一条线，创建一个二元的风险地图：“高风险区”和“低风险区”。

这就是在ROC曲线上选择一个*[工作点](@entry_id:173374)*的问题。在那条权衡曲线上，我们希望处于哪个位置？一个优雅的选择方法是找到使**约登指数J**最大化的点，该指数就是$(\text{灵敏度} + \text{特异度} - 1)$。这个指标给予了正确识别正例（灵敏度）和正确识别负例（特异度）同等的权重。通过选择使该值最大化的阈值，流行病学家做出了一个有原则的选择，平衡了两种类型的正确性，将一个概率模型转化为一个具体的行动计划 [@problem_id:4790219]。

### 关于信任与可靠性的深层问题

一旦模型建立起来，一系列新的、更深层次的问题就会出现。我们测量的性能是真实的吗？它明天还会保持吗？它比旧模型更好吗？它甚至安全可用吗？我们的评估工具包也为回答这些问题提供了方法。

#### 关于稳健性与不平衡

许多现实世界的问题都存在严重的类别不平衡。想想试图预测一个庞大电网中的故障。这些事件极其罕见。一个总是预测“无故障”的懒惰模型可以达到超过99.9%的准确率，但它将完全无用。在这种情况下，准确率就是一个谎言。

像[F1分数](@entry_id:196735)这样的指标更好，因为它们关注稀有的正类。然而，F1完全忽略了真负例，而在电网监控系统中，这代表了绝大多数正确的决策。一个更稳健的指标是**[马修斯相关系数](@entry_id:176799)（MCC）**。MCC实际上就是真实标签和预测标签之间的皮尔逊相关系数。它产生一个介于-1和+1之间的值，其中+1是完美预测，0不比随机好，-1表示完全不一致。因为它是由[混淆矩阵](@entry_id:635058)的所有四个条目（$TP, TN, FP, FN$）计算得出的，所以它被认为是最均衡和最值得信赖的指标之一，尤其是在类别不平衡时 [@problem_id:4083465]。

但指标之王AUC又如何呢？它最引人注目——近乎神奇——的特性之一是其内在的**对[类别不平衡](@entry_id:636658)的不敏感性**。想象一个监控病人败血症的模型，这是一种危及生命的状况。医院里的败血症发生率可能会随季节变化（一种称为“标签漂移”的现象）。如果模型区分败血症患者数据和非败血症患者数据的潜在能力保持不变，那么即使流行率发生变化，其AUC也将保持不变。一个优雅的[数学证明](@entry_id:137161)表明，某些常见的AUC估计量在期望上完全不受类别比例变化的影响 [@problem_id:5182512]。这种惊人的稳健性是AUC在医学等领域被广泛使用和信赖的一个关键原因。

#### 关于不确定性与置信度

假设两家医院开发了用于从医学图像预测癌症的模型。A医院报告AUC为0.82，B医院报告AUC为0.80。A医院的模型更好吗？别那么快下结论。一个单一的数字隐藏了一个关键信息：不确定性。

如果A医院的结果是基于一个小规模研究得出的$0.82 \pm 0.15$，而B医院的结果来自一个大型试验，是$0.80 \pm 0.01$呢？突然间，我们的结论就反转了。B医院的模型要可靠得多。这就是为什么我们必须为我们的指标计算**[置信区间](@entry_id:138194)**。这些区间为我们提供了真实性能的一个合理值范围。有许多精妙的统计工具可以做到这一点，从理论驱动的方法如用于AUC-ROC的DeLong方法（利用了该指标的数学特性），到暴力计算方法如非[参数自举](@entry_id:178143)法，我们通过“靠自己的鞋带把自己拉起来”的方式模拟成千上万个新数据集，来估计像AUC-PR这样的指标的分布 [@problem_id:4531404]。报告一个指标而不带其[置信区间](@entry_id:138194)，就像报告一个测量值而不带[误差棒](@entry_id:268610)——这只是故事的一半。

#### 关于公平比较模型

这就引出了最终的比较。我们有两个分类器，A和B，用于根据神经元的形状识别其类型。在我们的[测试集](@entry_id:637546)上，B的[F1分数](@entry_id:196735)比A略高。它是真的更好，还是只是在这一批特定数据上运气好？

为了回答这个问题，我们求助于[统计假设检验](@entry_id:274987)的力量。因为两个模型都在*相同*的数据上进行测试，所以误差是配对的。我们可以使用像**[McNemar检验](@entry_id:166950)**这样的测试，它只关注[分歧](@entry_id:193119)之处——即一个模型正确而另一个模型错误的案例。如果在它们存在[分歧](@entry_id:193119)的例子上，模型B正确的次数显著多于模型A，我们就能相信B是真正更优的。我们也可以对我们数据的不同子集（交叉验证折叠）上的性能得分应用配对检验，如配对$t$检验，来看这种改进是否具有一致性。这些检验使我们能够为我们的结论赋予一个$p$值，量化观察到的差异仅仅是侥幸的概率。这是比较模型时科学严谨性的基石 [@problem_id:4004778]。

#### 关于隐私与社会契约

最后，我们的旅程超越了纯粹的性能，进入了技术与社会的交汇点。在医学领域，我们的模型是在敏感的病人数据上训练的。保护这些数据不仅是一项技术要求，更是一项伦理责任。最强大的保护措施之一是**[差分隐私](@entry_id:261539)（DP）**，它通过在过程中添加经过仔细校准的随机噪声来提供数学上的隐私保证。

但这种隐私是有代价的。向模型的分数中添加噪声不可避免地会降低其区分能力。曾经清晰分离的类别条件分数分布，随着噪声的增加开始更多地重叠。结果呢？[AUROC](@entry_id:636693)下降了。

我们第一次直接、数学化地掌握了隐私与效用之间的权衡。[差分隐私](@entry_id:261539)的方程式精确地告诉我们，为了达到由参数$\epsilon$度量的特定隐私水平，我们必须添加多少噪声方差。然后，ROC分析的方程式精确地告诉我们，对于该数量的噪声方差，我们的[AUROC](@entry_id:636693)将下降多少。我们现在可以提出并回答一些精确的问题，比如：“为了保证我们的罕见病检测器具有$(\epsilon, \delta)$-隐私，对其识别患病患者能力的影响是什么？” [@problem_id:4401103]。这不再是一个技术问题。这是一个由数学提供信息的伦理问题。

从曲线的抽象之美到临床医学的生死抉择，再到隐私的社会契约，[分类器评估](@entry_id:634242)的原则是一条强大而统一的线索。它们不仅仅是关于评判一个模型；它们是关于理解它、信任它并明智地使用它。