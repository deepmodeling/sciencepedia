## 引言
随机对照试验（RCTs）是临床证据的黄金标准，其设计旨在为治疗组和[对照组](@entry_id:188599)之间创造一个完全平衡的比较。通过随机化实现的这种平衡，使我们能够自信地将结局的差异归因于干预措施本身。然而，现实世界是复杂的；参与者会退出研究、错过访视或失访，从而在数据中造成空缺。这种[缺失数据](@entry_id:271026)不仅仅是一种麻烦——它是一种严重威胁，可能打破试验的基础对称性，引入偏倚，并导致极具误导性的结论。本文旨在解决如何科学地管理和解释不完整数据的关键知识空白。接下来的章节将引导您了解应对这一挑战的核心原则。首先，在“原则与机制”中，我们将探讨缺失数据的分类（MCAR、MAR 和 MNAR）及其如何产生偏倚。随后，“应用与跨学科联系”将展示如何应用从[多重插补](@entry_id:177416)到[敏感性分析](@entry_id:147555)等原则性统计方法，从不完美的数据集中挽救真相。

## 原则与机制

在理想世界中，随机对照试验（RCT）是一件完美无瑕的艺术品。通过将参与者随机分配到治疗组或[对照组](@entry_id:188599)，我们创造了两个在平均意义上于所有可想到的方面都相同的组——无论是我们能观察到的特征还是无法观察到的特征。这种神奇的随机化操作使我们能够将之后观察到的任何结局差异归因于治疗本身。这最接近物理学家的梦想：让宇宙运行两次，一次有干预，一次没有。

但我们并不生活在这个理想世界中。我们生活的世界里，有错过的预约、失访的电话，以及干脆决定不再参与研究的患者。当参与者的结局数据未能收集时，我们精心设计的数据集中便出现了一个漏洞。这不仅仅是不便；它对试验的根基构成了潜在威胁。由随机化创造的美好对称性可能被打破，如果我们不小心，我们得出的结论可能会极具误导性。理解这种“缺失性”的本质，是从不完美的实验中挽救真相的第一步。

### 缺失分类学：MCAR、MAR 和 MNAR

当一条数据缺失时，我们必须问的第一个问题是：*为什么？*答案决定了接下来的一切。统计学家为[缺失数据机制](@entry_id:173251)制定了一套关键的分类方法，堪称一部缺失现象的[分类学](@entry_id:172984)。

数据缺失最良性的原因是**[完全随机缺失](@entry_id:170286)（Missing Completely at Random, MCAR）**。这意味着数据缺失这一事实与该人的特征或其结局毫无关系。想象一下，一位实验室技术员不小心将几瓶血样掉在地上摔碎了。这些遭遇不幸的血样是随机的；它们的毁坏与它们属于谁、他们的基线健康状况或他们对治疗的反应无关。当数据是 MCAR 时，剩余的、已观测的数据仍然是原始较大群体的随机子样本。一种只包含完整病例的简单分析——称为**完整病例分析**——仍将产生对治疗效果的[无偏估计](@entry_id:756289)，尽管由于样本量变小，我们损失了统计功效[@problem_id:4639909]。

不幸的是，现实很少如此简单。一种更常见也更复杂的情况是数据**[随机缺失](@entry_id:168632)（Missing at Random, MAR）**。这个名字有点用词不当，因为缺失*并非*真正的随机；相反，数据缺失的概率取决于我们*已经*观测到的其他信息。例如，在一项新的心脏病药物试验中，我们可能会发现年轻患者比年长患者更有可能完成所有随访，这或许是由于他们行动更方便。如果我们记录了每位患者的年龄，那么缺失就不是一个完全的谜。它是可以根据一个已观测变量预测的。

此时，危险就显而易见了。假设年龄较大也与较差的结局相关。如果我们只分析完成了研究的患者，我们的样本将偏向于更年轻、更健康的个体。在完成者中，由随机化实现的精妙平衡被打破了。仅对完整病例进行分析现在可能会产生偏倚[@problem_id:4639909] [@problem_id:4828676]。幸运的是，由于缺失的原因可以通过已观测数据（如年龄）来理解，我们对这个问题有了一定的掌控。诸如**[多重插补](@entry_id:177416)（Multiple Imputation, MI）**或**[逆概率](@entry_id:196307)加权（Inverse Probability Weighting, IPW）**等复杂的统计方法可以利用已观测变量（本例中为年龄）来对分析进行统计学校正，纠正不平衡，并产生对治疗效果的无偏估计。这些方法本质上是试图重建原始随机化分组的美好对称性[@problem_id:4639909] [@problem_id:4828676]。

最具挑战性和危险性的类别是**[非随机缺失](@entry_id:163489)（Missing Not at Random, MNAR）**。在这种情况下，一个值缺失的概率取决于该值*本身*。数据不仅仅是缺失了；它是因某个原因而隐藏，而这个原因恰恰是我们试图测量的东西。考虑一项新的止痛药的临床试验[@problem_id:1936085]。一个感觉疼痛缓解甚微或毫无缓解的患者可能会变得灰心并退出研究。他们最终的疼痛评分之所以缺失，*是*因为它本会是一个高分。这被称为**信息性缺失**，是统计学家的噩梦。观察结局这一行为本身就与结局捆绑在一起。假设 MAR 的标准方法，如 MI 或 IPW，在这里会失效并产生有偏倚的结果，因为校正偏倚所需的信息——未被观测的结局本身——是不可用的[@problem_id:1936085]。

### 平均值的欺骗性：选择偏倚如何破坏证据

让我们看看这个过程究竟是如何产生偏倚的。想象一个试验，其中较高的结局值 $Y$ 表示更好。假设在治疗组，真实的平均结局是 $\mu_1 = 1.0$。现在，假设存在一个 MNAR 过程：结局较低（较差）的参与者更有可能退出。当我们去分析数据时，我们只看到那些留下来的参与者的结局。由于低分者已经选择性地消失了，剩余参与者的平均结局 $\mathbb{E}[Y \mid A=1, R=1]$ 将被人为地抬高——例如，可能达到 $1.5$。同样的现象可能也发生在[对照组](@entry_id:188599)，但程度可能不同。

这种对参与者的选择性移除产生了**选择偏倚**。“完成者”群体不再是原始群体的随机样本；它是一个“成功”的子集。当你比较治疗组完成者的平均值与[对照组](@entry_id:188599)完成者的平均值时，你比较的不是治疗的真实效果。你比较的是两个有偏倚的、不具代表性的群体。

我们一个教学练习中的[数值模拟](@entry_id:146043)很好地说明了这一点[@problem_id:5044570]。通过定义一个模型，其中被观察到的概率 $\mathbb{P}(R=1 \mid Y=y, A=a)$ 随着结局 $y$ 变好而增加（即 $\beta > 0$），我们可以精确计算出由此产生的偏倚。当对结局的依赖性在两组中相同时，偏倚仍然会出现。当这种依赖性因组而异时，偏倚可能变得更加显著和不可预测。

更令人惊讶的是，这种偏倚可能狡猾到凭空制造出“统计学上显著”的效果，甚至夸大一个真实的效果，使其看起来比实际更重要。考虑一个真实风险差为 $\Delta = 0.10$ 的试验。一个特定的 MNAR 机制——即两组中成功的患者都更有可能留在研究中——可能导致在完整病例分析中观察到的风险差为，比如说，$\Delta^{\mathrm{obs}} \approx 0.16$ [@problem_id:4579206]。这种被夸大的效应量，矛盾地，*增加*了检验的统计功效。该试验可能会报告一个具有很小 p 值的非常显著的结果，但这个胜利是空洞的。这一发现是缺失数据的产物，而不是药物疗效的真实度量。这强调了一个关键教训：一个来自有偏倚分析的统计学显著结果不仅是错误的，而且是危险的误导。

### 面对未知：“如果……会怎样？”情景的艺术

如果缺失机制是 MNAR，而我们又无法确定，因为关键信息是缺失的，我们能做什么呢？我们不能简单地假设最好的情况（MCAR），甚至方便的情况（MAR）。原则性的方法是进行**[敏感性分析](@entry_id:147555)**。

敏感性分析在统计学上等同于对一座桥梁进行压力测试。你不仅要检查桥梁能否承受正常交通；你还要让它承受极端的、假设的载荷，以找到它的[断裂点](@entry_id:157497)。同样，我们必须测试我们的试验结论对于关于[缺失数据](@entry_id:271026)的合理的悲观假设是否稳健。

一种简单直观的形式是**[最坏情况分析](@entry_id:168192)** [@problem_id:4603241]。假设我们有一个优效性试验，希望证明我们的新药比安慰剂好，并且较高的结局分数意味着成功。关于退出者，我们能做的最不利、最悲观的假设是什么？我们可以假设，治疗组中每一个退出的人都是失败者（$Y=0$），而安慰剂组中每一个退出的人都是成功者（$Y=1$）。然后我们重新计算治疗效果。如果即使在这种极端苛刻且不大可能的情景下，我们的治疗仍然显得优越，那么我们的结论就非常稳健。

更复杂的[敏感性分析](@entry_id:147555)使用一种称为**[模式混合](@entry_id:197206)模型**的框架 [@problem_id:4816959] [@problem_id:4839266]。这种方法不是单一的最坏情况，而是允许我们探索一系列“如果……会怎样”的情景。该模型明确允许结局 $Y$ 的分布在已观测组和缺失组之间是不同的。我们可以形式化地假设，缺失参与者的平均结局与已观测参与者的平均结局相差某个量 $\delta$。例如，在 $a$ 组中，我们可以假设：
$$ \mathbb{E}(Y_a \mid \text{Missing}) = \mathbb{E}(Y_a \mid \text{Observed}) + \delta_a $$
参数 $\delta_a$ 是**敏感性参数**。它是我们的“如果……会怎样”旋钮。我们无法从数据中估计 $\delta$——这是 MNAR 的根本挑战。但是我们可以代入不同的 $\delta_T$（治疗组）和 $\delta_C$（[对照组](@entry_id:188599)）的值，然后观察估计的治疗效果 $\Delta(\delta_T, \delta_C)$ 如何变化[@problem_id:4839266]。

这就引出了一个强大的想法，即**[临界点](@entry_id:142397)分析** [@problem_id:5044778] [@problem_id:4839266]。我们可以计算出能导致我们的结论“翻转”的 $\delta_T$ 和 $\delta_C$ 值的确切组合——例如，一个正向的治疗效果变为零或负。这在可能的 $\delta$ 值空间中定义了一个“[临界区](@entry_id:172793)域”。然后我们可以将此呈现给临床专家，并提问：“退出者与完成者之间存在如此大的差异，这在临床上是否合理？”这将一个抽象的[统计不确定性](@entry_id:267672)转化为一个具体的、可辩论的临床问题，使得证据及其潜在的脆弱性对所有人都是透明的。

### 为不完美而设计：从头开始构建稳健的试验

我们讨论的原则不仅仅是用于[事后分析](@entry_id:165661)的工具；它们真正的力量在于从一开始就塑造试验的设计。我们必须为缺失数据的必然性做好规划。

首先，这意味着在计算所需样本量时要考虑到信息的损失。如果我们预计有 20% 的退出率，我们不能简单地招募一个完整数据试验所需的样本量；我们必须增加样本量以确保我们保留足够的[统计功效](@entry_id:197129)。

更深刻的是，一个真正稳健的试验设计会将其功效计算直接纳入对潜在 MNAR 偏倚的考量中 [@problem_id:4839174]。如果我们有理由相信治疗组的退出者会比完成者差，我们可以预先指定一个合理的敏感性参数 $\delta_{\max}$，它代表一个悲观但现实的 MNAR 情景。然后我们可以计算出在这种情景下我们预期会看到的**衰减的治疗效果** $\theta^*$。例如，如果真实效果是 $\theta$，但治疗组中有比例为 $p_T$ 的患者退出，并且他们的结局比观察到的差 $\delta_{\max}$，那么我们实际上能够检测到的效果大约是 $\theta^* = \theta - p_T \delta_{\max}$。试验的功效设计就必须以检测这个较小的、衰减的效应量为目标。

这是原则性统计思维的巅峰。它承认现实世界的混乱，不是作为一个事后哀叹的问题，而是作为一个从一开始就要规划的实验基本参数。它将偏倚、功效和[敏感性分析](@entry_id:147555)的概念统一成一个单一、连贯的设计哲学。通过拥抱不完美并为其做好规划，我们可以设计出不仅[统计功效](@entry_id:197129)强大，而且在科学上诚实和稳健的试验，从而得出即使在数据不可避免地不完整时也值得我们信赖的结论。

