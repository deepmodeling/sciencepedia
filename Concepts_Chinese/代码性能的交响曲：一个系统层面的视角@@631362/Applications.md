## 应用与跨学科联系

科学世界有一种奇妙的统一性。支配行星轨道的原则与描述棒球飞行的原则并无太大不同。同样，代码性能的科学并非局限于计算机奇才的深奥世界的某种玄学。当你用正确的眼光看待它时，它美丽地反映了我们在周围随处可见的普遍原则——在经济学中，在工程学中，甚至在我们日常生活的流程中。性能并非关乎魔法；它关乎核算。处理器时间的每一纳秒，内存的每一字节，通过网络发送的每一比特数据，都是一种资源。性能的艺术是管理这些资源预算的科学，是为实现目标而做出明智权衡的科学。让我们踏上旅程，浏览其中一些联系，亲眼见证这种统一性。

### 编译器的困境：现在思考还是以后思考？

想象一下你正在翻译一本书。你有两个选择。你可以非常快地翻译，也许会产生一些略显笨拙但可以理解的措辞。或者，你可以花费大量时间，精心雕琢每一个句子，力求完美。哪一个更好？嗯，这要看情况！如果这本书只会被读一次然后扔掉，那么快速翻译更优。如果它注定要成为经典，被数百万人阅读，那么额外的努力肯定是值得的。

这正是将源代码翻译成机器母语的计算机程序所面临的困境。这个翻译器被称为编译器。它也必须决定在优化上投入多少精力。

在某些情况下，比如在手机上，所有的编译都必须是*提前*（AOT）完成的。你从应用商店下载的正是最终翻译好的应用程序。在这里，编译器可以选择创建一个“胖二进制”，为每一个函数都包含超优化的代码。但这有代价：应用程序会变得巨大，占用设备上宝贵的存储空间。应用程序所有者可能会施加一个预算，这是对二进制文件大小增加和性能增益之间的正式权衡。为了满足这个预算，编译器必须成为一名侦探。它不能优化所有东西。相反，它使用剖析数据或[静态分析](@entry_id:755368)来识别代码的“热”部分——即程序花费大部分时间的少数函数——并将优化预算集中在那里。这是一种定向投资策略，确保以最小的字节代价获得最大的性能提升 ([@problem_id:3620653])。

在其他场景中，比如在数据中心运行的服务器，编译器可以更加动态。它可以使用*即时*（JIT）编译，在程序执行时即时翻译代码。这开启了一个引人入胜的可能性。编译器可以先进行一次快速粗略的翻译（“基线”编译），然后在程序运行时进行观察。如果它观察到某个特定的循环被一遍又一遍地执行，它可以决定回去用更强大但更慢的优化重新编译那个特定的循环。

但它应该在什么时候进行转换呢？这是一个纯粹的[成本效益分析](@entry_id:200072)。编译器会产生一笔前期成本：执行重量级优化所花费的时间。好处是在该优化代码未来所有执行中累积节省的时间。只有当预期的总运行时节省大于编译成本时，追踪才是有价值的。通过对这种权衡建模，可以推导出一个最佳的“热度阈值”。编译器保留一个计数器，只有当循环的执行次数超过这个阈值时，它才会采取行动。这是一个简单而优雅的规则，源于经济学，让一个运行中的系统能够智能地、自动地自我提升 ([@problem_id:3623804])。

### 最慢者的暴政

任何参与过“水桶队”的人都明白一个自然界的基本法则：你的链条强度取决于其最薄弱的环节，而你的队伍速度取决于其最慢的人。在计算机科学中，这个思想通常被形式化为所谓的[阿姆达尔定律](@entry_id:137397)（Amdahl's Law）。整个系统的性能最终受限于其最慢组件的性能。改进任何其他部分都是在浪费精力。

我们在定制硬件加速器（例如基于[现场可编程门阵列](@entry_id:173712)（FPGA）构建的那些）的设计中，可以完美地看到这个原则。考虑转置一个巨大矩阵的任务。工程师可能会设计一个专门的电路来以惊人的速度完成这项工作。但如果这个电路一直因为数据供应不足而处于“饥饿”状态，那它就毫无用处。真正的挑战是创建一个平衡的系统，一个流水线，其中数据从主内存流出的速率、数据在芯片内部总线上传输的速率、以及核心处理数据的速率都[完美匹配](@entry_id:273916)。当达到这种状态时，系统会以其理论最大[吞吐量](@entry_id:271802)嗡嗡作响，没有任何组件空闲，也没有任何部分不堪重负。这是系统工程的杰作 ([@problem_id:3671140])。

然而，更多时候，系统是*不平衡*的。想象一位才华横溢的教授（CPU），他能以闪电般的速度解方程，但必须等待一位慢吞吞的图书管理员从尘土飞扬的档案馆里取书（硬盘）。教授的天才在长时间的等待中被浪费了。这正是在现代计算机中发生的情况，即*[请求分页](@entry_id:748294)*。当一个程序需要一块不在快速主内存（RAM）中的数据时，它会触发一次缺页中断，迫使[操作系统](@entry_id:752937)从一个慢得多的后备存储（如磁盘）中获取数据。

性能损失是惊人的。在一个[高性能计算](@entry_id:169980)场景中，仅仅将后备存储从远程并行文件系统切换到快速的本地 NVMe 驱动器，就可以极大地减少服务一次缺页中断的平均时间，以至于整体应用程序[吞吐量](@entry_id:271802)可以增加一个[数量级](@entry_id:264888) ([@problem_id:3633440])。我们甚至可以计算出一个精确的“延迟预算”。如果我们被迫使用网络上的远程磁盘作为我们的[交换空间](@entry_id:755701)，我们可以确定最大的可接受[网络延迟](@entry_id:752433)——也许只有几分之一毫秒——在此之上，我们应用程序的性能会下降到不可接受的程度 ([@problem_id:3685063])。

这把我们引向一个更极端的现象：完全的系统崩溃。考虑使用“后拷贝”策略对虚拟机进行实时迁移。[虚拟机](@entry_id:756518)的执行被移到一台新的物理服务器上，但其内存被留在了原地，需要时通过网络按需获取。切换之后，应用程序每次试图触及其内存的任何部分，都会触发一次缺页中断。如果应用程序以非常高的速率访问内存，它可能会引发一场“缺页风暴”，请求页面的速度远远超过网络所能供应的速度。

这是[排队论](@entry_id:274141)中的一个经典问题：到达率超过了服务率。待处理的页面请求队列无限增长，应用程序陷入停顿，性能一落千丈。系统变得不稳定。有趣的是，解决方案可能不仅仅是更快的网络。一个更聪明的方法可能是让应用程序自身意识到拥塞，使用超时和退避策略来减少自身的需求，从而让页面获取机制能够赶上。这将[性能工程](@entry_id:270797)与反馈和控制理论的世界联系起来 ([@problem_id:3689852])。

### 超越速度：确定性与正确性的代价

性能的目标总是更快吗？还是更准确？令人惊讶的答案是，通常两者都不是。真正的目标是以尽可能低的成本，*足够好*地完成手头的任务。

以[科学计算](@entry_id:143987)领域为例，比如计算流体力学（CFD）。假设我们想模拟一种气体的流动。我们可以从一系列物理模型中选择。一个高度详细的动力学模型，如[直接模拟蒙特卡洛](@entry_id:748473)（DSMC），跟踪[代表性](@entry_id:204613)分子并提供非常精确的图像，但其计算量巨大。一个基于 Navier-Stokes 方程的更简单的连续介质模型要快得多得多，但它基于一个假设——即流体是连续介质。当气体非常稀薄时，这个假设就会失效，这种情况的特征是高的 Knudsen 数 $Kn$。

聪明的[性能工程](@entry_id:270797)师不会盲目选择“最好”的模型。相反，她会问：“在我所处的物理条件下，满足我误差容忍度的最廉价模型是什么？”对于非常低的 $Kn$，简单的连续介质模型完全足够，而且极其廉价。随着 $Kn$ 的增加，其误差增大，可能需要切换到在边界处包含“滑移”效应的稍贵一些的连续介质模型。只有在非常高的 $Kn$ 值下，当两种连续介质模型都失效时，动力学模型的巨大成本才是合理的。艺术在于理解物理保真度与计算成本之间的权衡，并为工作选择正确的工具 ([@problem_id:3371934])。

这种付出代价的想法延伸到其他品质上，比如可靠性。你如何构建一个即使其某些组件是恶意的情况下也能被信任的系统？这是[拜占庭容错](@entry_id:747029)（BFT）的领域。为了确保接收方接受正确的[数据块](@entry_id:748187)并拒绝任何伪造品，即使在其 $p$ 条通信路径中有多达 $f$ 条被对手控制，我们也必须引入冗余。一个标准协议要求发送方将每个[数据块](@entry_id:748187)传输 $r = 2f+1$ 次。接收方在收到 $q = f+1$ 个相同的副本后才接受数据。这种冗余是信任的不可避免的代价。它对性能有直接影响：系统的最大[吞吐量](@entry_id:271802)从根本上受限于总带宽除以复制因子 $r$。正确性是有成本的，在分布式系统中，我们可以精确地计算它 ([@problem_id:3625181])。

也许最令人惊讶的是，我们关于什么使系统“快”的直觉可能是误导性的。考虑一个处理作业的服务器。我们可能认为减少等待队列的最佳方法是减少处理单个作业的平均时间。这当然有帮助！但[排队论](@entry_id:274141)中著名的 Pollaczek-Khinchine 公式揭示了一个更深的真理。队列的平均长度不仅取决于服务时间的均值，还取决于其二阶矩——这与其*[方差](@entry_id:200758)*有关。

这意味着一个服务时间高度*不一致*的系统，有时非常快但偶尔非常慢，其队列会比一个[平均速度](@entry_id:267649)相同但*可预测性*高得多的系统长得多。有时，提高性能的最佳方法不是优化平均情况，而是减少变异性。在给定固定预算的情况下，投资于使服务时间更一致可能比使它们平均更快更有效 ([@problem_id:1343990], [@problem_id:1344006])。一个稳定、可预测的系统往往胜过一个轻率、不稳定的系统。

### 统一的观点

在我们短暂的巡览中，我们看到了什么？我们从一个决定何时优化的编译器开始，到服务器队列中可预测性的惊人重要性结束。一路上，我们遇到了来自经济学、[硬件设计](@entry_id:170759)、[操作系统](@entry_id:752937)、[排队论](@entry_id:274141)、控制理论、科学建模和容错等领域的原则。

教训是：代码性能的研究不是一个狭隘的技术学科。它是一个汇集了来自科学和工程领域基本思想的交汇点。支配金融投资、平衡生产[线或](@entry_id:170208)确保桥[梁稳定性](@entry_id:188098)的相同逻辑，也同样支配着驱动我们世界的软件的速度和可靠性。理解性能就是欣赏支配所有复杂系统的原则中深刻而美丽的统一性。它是窥探我们宇宙奇妙互联本质的另一扇窗户。