## 应用与跨学科联系

现在我们已经探索了使用线性回归进行分类的机制，你可能会留下一个挥之不去的问题。我们已经看到它是一个有点笨拙的工具，理论上有缺陷，并且常常被那些真正为分类任务设计的模型所超越。那么，我们为什么要费这个劲呢？为什么要把时间花在一个乍一看似乎是“错误”使用工具的想法上呢？

答案，也是这段旅程如此有价值的原因，是当我们把一个简单的工具推向其预期用途之外时，我们会发现一片令人叹为观止的联系景观。我们开始看到那些深刻、统一的原则，它们将统计学、机器学习甚至社会科学等看似迥异的领域联系在一起。研究线性回归作为分类器的*失败*和*怪癖*，就像使用一个扭曲的镜头；它揭示了数据世界中隐藏的光路和基本结构，而一个完美的镜头只会聚焦而不多言。在本章中，我们将开始探索这些联系、应用和后果。

### 方枘圆凿：为何拟合常常不适

让我们首先面对显而易见的问题。线性模型画出的是一条直线（或在高维空间中的一个平面）。而分类任务需要画出一条边界，这条边界可能是弯曲的、扭曲的，甚至是断成几块的。当我们需要画的边界根本就不是一条直线时，会发生什么？

考虑著名的“异或”（XOR）问题。想象一个数据集，其中如果特征$x_1$值高*或*特征$x_2$值高，但*不是两者都高*，则标签为“真”。这会形成一个棋盘格状的类别分布。一条直线完全无力分离这些类别；无论你怎么画，你总会犯下大量的错误[@problem_id:3113048]。而像决策树这样的灵活模型可以轻松解决这个问题，只需做两个简单的、与坐标轴平行的切割，就能有效地隔离出这些区域。这是最根本的限制：线性模型仅适用于类别实际上是线性可分的情况。

但这种不适感比几何学本身更深。它触及了我们如何衡量“成功”的核心。在回归中，我们通常使用像$R^2$（“解释的方差比例”）这样的指标来衡量我们的线对数据的拟合程度。目标是最小化我们的预测值与真实值之间的平方距离。但对于一个二元的、是/否的结果，“方差”这个词到底意味着什么？

如果我们将[线性回归](@article_id:302758)直接应用于一个二元的$\{0, 1\}$目标——这种设置被称为线性概率模型（LPM）——我们常常会发现自己处于一种奇怪的境地。计算出的$R^2$可能非常低，比如说$0.01$，这表明拟合得很差。然而，如果我们使用模型的输出来进行分类，准确率可能相当可观。这是因为$R^2$回答的是一个错误的问题。它告诉我们，我们在预测$0$和$1$的精确值方面做得不好，而这本身就是一个奇怪的目标。一个合适的分类模型，比如逻辑斯谛回归，是使用似然性来优化的，这是衡量模型预测的概率对观察到的结果解释得有多好的一种度量——这对于问题本身来说是一个自然得多的拟合。将LPM得到的微不足道的调整后$R^2$与在相同数据上从[逻辑斯谛回归](@article_id:296840)得到的更有意义的伪$R^2$进行比较，常常会揭示回归框架根本就是在衡量错误的东西[@problem_id:3096430]。

这导致了最后一个关键问题：LPM的输出不是概率。一条直线可以轻易地超过$1$或低于$0$。预测的“概率”为$1.3$或$-0.2$到底意味着什么？它们未经校准且毫无意义。相比之下，一个校准良好的分类器提供的输出可以被信任为真实的概率：如果它预测有70%的降雨概率，那么在它做出该预测的日子里，大约应该有70%的日子会下雨。像[期望](@article_id:311378)校准误差（ECE）这样的指标就是为了衡量这种可信度而设计的，而在这方面，为分类构建的模型表现出色，而LPM通常会失败[@problem_id:3147786]。

### 以无监督之眼看有监督世界

[回归与分类](@article_id:641367)之间的不匹配可以通过一个涉及降维——简化复杂数据的艺术——的美丽类比来理解。想象一下你有很多特征的数据，你想把它减少到仅仅一两个维度，以便更容易处理。

其中一个最著名的工具是主成分分析（PCA）。PCA在其灵魂深处是一个具有回归思维的[算法](@article_id:331821)。它审视数据点的云团，并提问：“这个云团在哪个方向上变化最大？”它找到最大方差的轴，并将数据投影到这些轴上。这通常正是你在回归任务中所想要的，因为高方差的方向往往是包含最多关于结果信息的方向。

但对于分类呢？分类的目标不是解释方差；而是找到组与组之间的*分离*。如果区分两个类别的关键信息位于一个方差非常*低*的方向上呢？PCA，以其无监督的、回归思维的眼睛，会将这个方向视为不重要的“噪声”并丢弃它。这就像试图在一个嘈杂的房间里只听最响亮的声音来寻找一段低语的对话——你将完全错过信号。

相比之下，像[线性判别分析](@article_id:357574)（LDA）这样的有监督工具，则具有分类思维。它明确地寻找能够最好地分离类别均值，同时最小化每个类别内部方差的方向。它不关心这个方向在总方差方面是“响亮”还是“安静”；它只关心它是否具有判别力。

这个强有力的对比[@problem_id:3169355]为我们的主要话题提供了一个完美的寓言。将线性回归用于分类，就像将PCA用于面向分类的[降维](@article_id:303417)。它将一个回归目标——[最小化平方误差](@article_id:313877)，一个类似方差的量——强加于一个其真正目标是类别分离的问题上。有时这会因为巧合而奏效，但当变化的方向与分离的方向分道扬镳时，这种方法可能会惨败。

### 回响与类比：统一的原则

在这里，我们的旅程从批评转向欣赏。通过比较回归和分类的数学原理，我们发现了深刻的相似之处，揭示了[统计建模](@article_id:336163)世界中的深层统一性。

考虑模型“[置信度](@article_id:361655)”的概念。在[多类别分类](@article_id:639975)模型中，我们可能有一个“温度”参数$\tau$。当$\tau$较低时，模型预测的概率会变得非常尖锐和“自信”（例如，一个类别99%，其他类别为极小的分数）。当$\tau$较高时，概率会变得平滑和“不确定”，更接近于均匀猜测。降低温度会使损失函数的景观更陡峭、更弯曲，这可能使优化变得更棘手。

在线性回归中是否有此回响？令人惊讶的是，是的。在回归的概率视角中，我们通常假设数据点围绕着真实的线[散布](@article_id:327616)，并带有某个方差为$\sigma^2$的高斯（正态）噪声。这个$\sigma^2$是我们对数据不确定性的度量。如果$\sigma^2$很小，我们相信数据非常精确，紧靠着线。如果$\sigma^2$很大，我们相信数据是嘈杂的。

美妙的联系在于：分类中$1/\tau$的角色在数学上类似于回归中$1/\sigma^2$的角色。在回归中减小噪声方差$\sigma^2$就像在分类中降低温度$\tau$一样。这两个动作都表示对数据有更高的置信度，并且两者都对增加损失函数的曲率有完全相同的效果。这不仅仅是巧合；这是一个迹象，表明在[置信度](@article_id:361655)、不确定性和优化难度之间的基本权衡，在这些不同领域是共通的[@problem_id:3169404]。

当我们考虑重加权样本时，出现了另一个迷人的平行。
- 在回归中，如果我们有异方差数据——即一些数据点比其他数据点更嘈杂（方差更高）——我们可以使用一种称为[加权最小二乘法](@article_id:356456)（WLS）的技术。WLS给予那些嘈杂、不可靠的点*更少*的权重，以获得对回归线更*有效*和精确的估计。
- 现在考虑一个不同的问题。在一次分类调查中，某些人口群体可能不太可能回应，导致数据缺失。为了获得对全人口趋势的[无偏估计](@article_id:323113)，我们可以使用逆倾向加权（IPW），它给予来自[代表性](@article_id:383209)不足群体的已观察个体*更多*的权重，以纠正由[非随机缺失](@article_id:342903)造成的*偏差*。

在这两种情况下，我们都在对数据点进行重加权。但逻辑是相反的。WLS降低不可靠点的权重以提高*精度*。IPW增加观察不足点的权重以提高*准确性*（减少偏差）。这种比较突显了回归（估计效率）和与分类相关的[人口推断](@article_id:343659)（[偏差校正](@article_id:351285)）在目标上的微妙但关键的差异[@problem_id:3169413]。

### 从理论到实践：现实世界的纠葛

我们讨论过的概念性联系具有非常真实的实际后果。考虑一下[特征缩放](@article_id:335413)这个平凡的任务。在将特征输入模型之前，你是否应该将它们[标准化](@article_id:310343)为零均值和单位方差？

答案完全取决于模型。对于决策树来说，它只关心一个特征内值的排序，所以缩放是无关紧要的。但对于许多线性模型来说，这绝对是至关重要的。一个未[正则化](@article_id:300216)的线性或[逻辑斯谛回归](@article_id:296840)，或许令人惊讶地，对缩放是免疫的。模型可以简单地调整其系数来完美补偿。然而，一旦我们引入[正则化](@article_id:300216)——一种通过惩罚大系数值来防止过拟合的重要技术——缩放就变得至关重要。

一个标准的$\ell_2$惩罚项，$\lambda \sum w_j^2$，同等对待所有系数$w_j$。但是，如果特征$X_1$以米为单位（范围从0到1000），而特征$X_2$是一个0/1[指示变量](@article_id:330132)，那么为了产生相当的效果，$X_1$的任何系数自然会比$X_2$的系数小得多。[正则化](@article_id:300216)项，对这一事实视而不见，会不公平地惩罚模型使用特征$X_2$。标准化特征将它们置于一个公平的竞争环境中，让[正则化](@article_id:300216)能够正确地发挥其作用。这同样适用于正则化线性回归和其他流行的[线性分类器](@article_id:641846)，如[支持向量机](@article_id:351259)（SVM）[@problem_id:3170641]。

最后，让我们重新审视概率输出的想法。虽然简单的LPM无法产生有效的概率，但更复杂的回归框架可以。例如，一个[贝叶斯线性回归](@article_id:638582)模型，它不仅输出一个单一的预测；它可以输出一个完整的预测*分布*。这个分布不仅告诉我们最可能的结果，还告诉我们所有可能性的范围以及我们对此的不确定性。这是极其强大的。在像医疗诊断或金融这样的领域，错误的成本是不对称的。一个假阴性（漏诊）可能比一个[假阳性](@article_id:375902)（不必要的复查）灾难性得多。通过使用一个[量化不确定性](@article_id:335761)的回归框架，我们可以超越简单的分类，进入基于风险的决策领域，在那里我们可以根据潜在的错误成本而不仅仅是预测结果来设定决策阈值[@problem_id:3103087]。

### 更广阔的视角：社会影响

我们的旅程结束于一个似乎远离线条和平面数学的地方：伦理和公平的领域。我们建立的模型不是抽象的实体；它们越来越多地被用于做出关于人们生活的高风险决策——在招聘、贷款申请和刑事司法中。

当我们把一个简单的[线性模型](@article_id:357202)应用于一个存在历史偏见的社会数据时会发生什么？假设我们的特征——比如说，收入和信用历史——的统计属性由于系统性的不平等而在不同的人口群体中具有不同的分布。一个线性模型，作为一个纯粹的数学生物，会根据汇集的数据学习一个[决策边界](@article_id:306494)。因为输入分布不同，模型的预测$\hat{Y}$几乎肯定不会独立于敏感的群体属性$A$。例如，模型可能对两个群体有不同的正预测率，$P(\hat{Y}=1 | A=0) \neq P(\hat{Y}=1 | A=1)$，这违反了一个被称为[人口均等](@article_id:639589)的公平标准。

这不是[算法](@article_id:331821)的恶意行为；这是其对输入统计数据敏感性的直接数学后果。[算法公平性](@article_id:304084)领域正努力应对这一挑战。一个提议的策略涉及对数据本身进行[预处理](@article_id:301646)，在模型看到数据之前应用变换以对齐不同群体的特征分布。其目标是创建一个数据的“更公平”表示，在这种表示中，下游的分类器不太可能延续或放大现有的社会偏见[@problem_id:3120903]。

这让我们回到了原点。我们对使用[线性回归](@article_id:302758)进行分类这个看似简单、“错误”的想法的探索，将我们从几何学和度量标准带到了不同模型家族之间深刻的结构类比，并最终引向了我们这个时代一些最紧迫的伦理问题。它教会我们，最深刻的教训往往不是在我们的工具完美工作时学到的，而是在我们将它们推向极限并仔细研究它们如何以及为何会失效时学到的。