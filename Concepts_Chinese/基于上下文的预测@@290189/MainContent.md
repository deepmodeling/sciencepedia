## 引言
我们如何预测句子中的下一个词、基因的功能或药物的效果？答案在于一个普遍的科学原理：基于上下文的预测。一个物体的周围环境掌握着其身份和未来行为的关键，这一思想对于在复杂世界中减少不确定性至关重要。本文探讨了如何利用上下文这一核心挑战，从抽象信息转向强大的[预测模型](@article_id:383073)。在接下来的章节中，我们将首先探索基础的“原理与机制”，从信息论和像PPM这样的经典[算法](@article_id:331821)开始，然后推进到像[注意力机制](@article_id:640724)这样的现代人工智能技术。接着，我们将遍览“应用与跨学科联系”，见证这一思想如何彻底改变从基因组学和个性化医疗到我们对人脑理解的各个领域。

## 原理与机制

想象一下你在读一个故事：“轮船驶过广阔的蓝色……”下一个词会是什么？“海洋”？或许是“大海”？你几乎肯定不会想到“烤面包机”或“云彩”。你是怎么做到的？你利用了前面的词语——即*上下文*——来预测接下来可能出现的内容。这个简单、几乎是无意识的预测行为，是所有科学中最深刻、最强大的思想之一。它意味着过去为未来提供了线索，模式确实存在，通过理解上下文，我们可以减少对未来的不确定性。

本章将带你深入这一思想的核心。我们将探索如何构建能够利用上下文力量的“预测机器”，从最简单的原理开始，逐步构建到驱动现代人工智能的复杂机制。

### 惊喜的度量与上下文的价值

在我们构建机器之前，让我们先思考一下我们想要实现的目标。当我们进行预测时，我们试图减少惊喜。在信息论中，有一个优美的概念可以描述这一点：**熵**。你可以将熵视为不确定性或平均惊喜程度的正式度量。如果所有结果的可能性都相同（比如猜测抛硬币），那么熵就很高。如果某个结果几乎是确定的，那么熵就很低。

上下文的魔力在于它能降低熵。让我们考虑一个简单的通信[信道](@article_id:330097)，它可以处于两种状态之一：“空闲”(0)或“传输中”(1)[@problem_id:1601868]。如果我们只看一段长期的传输历史，我们可能会发现该[信道](@article_id:330097)有三分之二的时间是“空闲”的，三分之一的时间是“传输中”的。从这些总体频率计算出的熵，即边际熵 $H(X)$，为我们提供了一个衡量[信道](@article_id:330097)不可预测性的基准。

但如果我们知道*前一个*状态呢？如果我们知道空闲的[信道](@article_id:330097)倾向于保持空闲，而传输中的[信道](@article_id:330097)倾向于继续传输呢？这就是我们的上下文。如果[信道](@article_id:330097)刚才处于“空闲”状态，我们可以更有信心地认为它下一刻仍将是“空闲”的。通过使用这一点上下文——即紧邻的前一个符号——我们可以做出更好的预测。我们剩下的不确定性是**[条件熵](@article_id:297214)** $H(X_i | X_{i-1})$，即在*给定*前一个状态的情况下，当前状态的不确定性。事实证明，对于任何[有记忆的系统](@article_id:336750)，这个[条件熵](@article_id:297214)*总是*小于或等于边际熵。两者之差 $H(X) - H(X_i | X_{i-1})$，正是上下文所提供信息量的精确、量化度量。从本质上讲，一个基于上下文的[预测模型](@article_id:383073)就是一台用于捕获这种[信息增益](@article_id:325719)的机器。

### 构建预测机器：PPM [算法](@article_id:331821)

那么，我们如何构建一个能从上下文中学习的机器呢？让我们尝试从第一性原理出发来发明一个。我们称之为**[部分匹配预测](@article_id:336810) (PPM)** [算法](@article_id:331821)。

#### 完全无知状态：-1阶模型

想象我们遇到一种全新的语言，它有27个独特的字符。我们没有任何文本，没有数据，什么都没有。我们看到的第一个字符的概率是多少？在没有上下文、没有先验信息的情况下，我们只能做出一个合理的假设：任何字符出现的可能性都一样。我们的机器在这种完全无知的状态下，为每个字符分配了 $\frac{1}{27}$ 的[均匀概率](@article_id:331880)。这被称为 **-1阶模型**——它是最终的备用方案，是所有学习赖以建立的基础 [@problem_id:1647231]。

#### 通过计数学习与逃逸机制

随着我们的机器读取一个文本序列，它开始学习。它通过可以想象的最简单的方式进行学习：计数。如果它看到序列“AB”，它会记录下'A'后面可以跟'B'。如果它看到“ABRACADABRA”，它会学到上下文“AB”后面跟着'R'，之后又再次看到“AB”后面跟着'R'。上下文“BR”后面跟着'A'，依此类推。

这就引出了一个关键问题：我们应该使用多长的上下文？像“ABRA”这样的长上下文非常具体，可能具有很强的预测性。但它也很罕见。像“A”这样的短上下文则常见得多，但其预测能力较弱。PPM用一种优雅的策略解决了这个困境：从最长、最具体的上下文开始，如果失败了，就“逃逸”到一个较短的上下文。

让我们看看这个过程的实际运作。假设我们的模型最大上下文阶数为4，并且正在首次处理序列 `ABCDE` [@problem_id:1647219]。为了预测'E'，它首先查看4阶上下文：`ABCD`。但因为机器以前从未见过子串 `ABCD`，所以它没有关于这个子串的统计数据。它别无选择，只能生成一个**逃逸**信号，并回退到较短的3阶上下文 `BCD`。这个上下文也是新的，所以它再次逃逸到 `CD`，然后到 `D`，依此类推。逃逸的触发不是因为要预测的字符，而是因为上下文本身的新颖性。

一个完整的例子将这个级联过程展现得非常清晰 [@problem_id:1647176]。想象一下，我们的机器已经处理了字符串“ACADABCA”，现在需要预测下一个符号是'E'的概率。
1.  **2阶上下文：** 最后两个字符是“CA”。在过去，“CA”出现过一次，后面跟着'D'。没有记录显示它后面跟着'E'。模型在这里无法对'E'做出预测，所以它**逃逸**。
2.  **1阶上下文：** 模型回退到最后一个字符“A”。在过去，“A”后面曾跟着'C'、'D'和'B'。同样，从未跟着'E'。它必须再次**逃逸**。
3.  **0阶上下文：** 现在模型完全放弃上下文，只看迄今为止所有出现过的符号的总体频率。符号'A'、'B'、'C'和'D'都出现过，但'E'没有出现过。对于整个数据流来说，这是一个全新的符号。所以，它必须最后一次**逃逸**。
4.  **-1阶上下文：** 一路逃逸到底后，模型求助于它最后的备用方案。它知道字母表有5个符号（`A, B, C, D, E`），并且已经见过4个。还剩下1个未见过的符号。它为所有未见过的符号分配一个[均匀概率](@article_id:331880)。因为'E'是唯一一个，所以它从这个模型中得到概率为1。

'E'的最终概率是每一层[逃逸概率](@article_id:330414)的乘积。这种分层的逃逸机制是PPM强大功能的核心：它优雅地平衡了对具体、长程信息的需求与对来自较短、更常见上下文的稳健统计的需求。

有时，上下文是如此强大，以至于它消除了所有的不确定性。如果我们有序列 `0101`，并且我们想预测下一个比特，1阶上下文是 `1`。回顾过去，我们*唯一*一次看到`1`是在 `(1,0)` 这对组合中。因此，根据其经验，机器预测`1`后面总是跟着`0`，并为其分配概率1 [@problem_id:1647223]。在这种局部情况下，上下文使得未来变得确定。

### 上下文无处不在

利用局部信息来预测属性的思想并不仅限于字符序列。这是一个普适的原理，在截然不同的科学领域都有应用。

#### 关联推断：[生物网络](@article_id:331436)中的上下文

想象一下细胞内的一个基因。它的功能不是孤立确定的。它是一个与其他[基因相互作用](@article_id:339419)的复杂网络的一部分。我们可以构建一个**[基因共表达网络](@article_id:331508)**，其中基因是节点，如果两个基因的活性水平同步升降，则用一条边连接它们。这种连接就是一种上下文。

现在，假设我们有一个未注释的基因 `GENEX`。我们不知道它做什么。但我们发现，在我们的网络中，它与另外七个基因紧密相连。这些邻居中有四个已知与“[抗旱性](@article_id:340297)”有关，两个与“[开花时间](@article_id:342594)”有关，一个与“病原体响应”有关。利用一个称为**关联推断**的原则，我们可以做出有根据的猜测。它的邻居所提供的“上下文”强烈暗示 `GENEX` 最有可能也与[抗旱性](@article_id:340297)有关 [@problem_id:1443729]。在这里，上下文不是一个线性序列，而是一个关系网。

#### [邻近效应](@article_id:300378)：蛋白质结构中的上下文

类似地，考虑一个由氨基酸长链构成的蛋白质。这条链会折叠成复杂的三维形状，形成诸如螺旋和折叠片之类的结构。是什么决定了某个特定的氨基酸会成为螺旋的一部分？早期的预测方法，如[Chou-Fasman方法](@article_id:356587)，关注的是每种氨基酸类型的内在倾向——就好像在问：“丙氨酸有多‘喜欢’处于螺旋中，而不管它的邻居是什么？”这是一种无上下文的方法。

一种更强大的方法，即[GOR方法](@article_id:352365)，采取了不同的观点。它认识到一个氨基酸的命运在很大程度上受到其邻居——即其局部序列上下文——的影响。[GOR方法](@article_id:352365)计算一个[残基](@article_id:348682)处于螺旋中的概率，*前提是*给定了其周围窗口内氨基酸的身份。通过考虑邻近环境，GOR实现了更高的准确性。这种方法论上的历史性转变突显了一个基本教训：拥抱上下文能构建出更符合现实的模型 [@problem_id:2135722]。

### 现代视角：融合与关注

PPM简单的逃逸机制很强大，但有点僵化。当它遇到一个新颖的长上下文时，它会完全丢弃它。现代方法已经找到了更细致的方式来结合来自不同上下文长度的信息。

我们可以**融合**或**混合**来自多个长度的预测，而不是只选择一个上下文长度。想象一下，我们有来自一个长而具体的上下文的预测，和一个来自短而可靠的上下文的预测。我们可以取两者的[加权平均](@article_id:304268)值。这就是**上下文树加权 (CTW)** 等方法背后的思想。即使一个长上下文是新的，它所做的默认预测（例如，一个[均匀分布](@article_id:325445)）也包含一些信息，我们可以将少量该信息与来自较短上下文的更稳健的预测混合起来 [@problem_id:1666872]。这使得模型能够[对冲](@article_id:640271)其赌注，优雅地整合不同尺度的信息。

最先进的系统更进一步。在一个长而复杂的句子中，并非所有上下文词对预测下一个词都同等重要。一个复杂的模型应该能够找出应该关注上下文的哪些部分。这就是现代[深度学习](@article_id:302462)的一大突破——**注意力机制**背后的直觉。

想象一个强大的[神经网络](@article_id:305336)，一个Bi[LSTM](@article_id:640086)，被训练用于预测两种蛋白质是否会相互作用。该模型读取蛋白质的整个氨基酸序列，然后必须对其进行总结以做出决定。注意力机制允许模型创建一个加权摘要，给予最重要的氨基酸更多的权重。这里有一个真正美妙的结果：当科学家训练了这样一个模型，然后可视化它“关注”的位置时，他们发现注意力权重系统地集中在已知的**结合域**上——即蛋白质中负责相互作用的精确功能区域！[@problem_id:2425652]。模型在没有被明确告知的情况下，学会了潜在的生物学原理。它学会了找到正确的上下文。

从猜测句子中下一个词的简单行为，到[神经网络](@article_id:305336)发现蛋白质功能核心，其原理始终如一。上下文是解锁预测的关键。通过从过去发生的事情中学习——无论是上一个字母、一个邻近的基因，还是一个遥远但相关的词——我们可以驾驭不确定性，并窥见我们周围世界的结构。