## 应用与跨学科联系

现在我们已经掌握了相干性的原理，让我们踏上一段旅程，看看这个思想将我们引向何方。你可能会感到惊讶。我们一直在玩的似乎是一个相当抽象的数学概念——矩阵列之间[内积](@entry_id:158127)的最大值。但这有什么用呢？一个强大、基本思想的奇妙之处在于，它会一次又一次地出现在世界上最意想不到的角落。[相干性](@entry_id:268953)的概念不仅仅是数学家的工具；它是一个统一的原则，揭示了看似不相关的领域之间的深层联系，从处理一张数码照片到理解我们在一个生物细胞中能发现的极限。它本质上是辨别事物的科学。

### 分解世界：信号、图像和声音

让我们从一个熟悉的世界开始：信号和图像的世界。假设你有一个信号，它是两种不同事物的混合体。例如，想象一段录音，既包含了一声清脆、突然的拍手声，也包含了一段持续、纯粹的嗡嗡声。你如何将它们分离开来？关键在于认识到每个分量在其自己的语言中是“简单”的。拍手声在基于时间的语言中是简单的——它发生在单个瞬间。嗡嗡声在基于频率的语言中是简单的——它由一个单一、稳定的音高组成。

要分离它们，我们需要建立一个能说两种语言的“多语”字典。我们字典的一部分将由在时间上局部化的原子（如脉冲）组成，另一部分将由在频率上局部化的原子（如纯[正弦波](@entry_id:274998)）组成。解混问题的任务就变成了在这个组合字典中寻找我们混合信号的最[稀疏表示](@entry_id:191553)。但这能行吗？它能行，当且仅当这两种语言彼此足够不同。也就是说，如果任何“时间”原子与任何“频率”原子在根本上是不相似的。这种不相似性的度量恰恰就是我们的老朋友——[相互相干性](@entry_id:188177)。如果单位基（用于脉冲）和Hadamard基或[傅里叶基](@entry_id:201167)（用于[振荡](@entry_id:267781)）是高度非相干的，我们就可以完美地解开这个混合体 [@problem_id:3433137]。

这个思想在[图像处理](@entry_id:276975)中达到了其美学潜力的顶峰。一幅图像通常既包含“卡通”分量（大片平滑区域和锐利边缘），也包含“纹理”分量（精细、重复的图案）。卡通部分可以用[小波](@entry_id:636492)[稀疏表示](@entry_id:191553)，[小波](@entry_id:636492)非常擅长捕捉边缘和局部特征。纹理部分可以用傅里叶原子[稀疏表示](@entry_id:191553)，傅里叶原子擅长描述周期性现象。为了将图像分离成其有意义的卡通和纹理部分，我们可以构建一个由[小波](@entry_id:636492)和[正弦波](@entry_id:274998)组成的混合字典。这种分离（一种称为形态学成分分析的技术）的成功完全取决于[小波基](@entry_id:265197)和[傅里叶基](@entry_id:201167)之间的低[相干性](@entry_id:268953)。数学告诉我们，一个[小波](@entry_id:636492)原子和一个[正弦波](@entry_id:274998)看起来根本不怎么像，而正是这种低相干性使得我们的算法能够干净利落地将图像分解成其组成部分 [@problem_id:3493854]。

同样的原则也支配着我们在时频平面上“看见”事件的能力。在[地震分析](@entry_id:175587)等领域，我们通常不仅想知道信号中存在*哪些*频率，还想知道它们*何时*发生。信号可能由啁啾声（频率向上或向下扫描的音调）组成。我们的字典原子现在是Gabor函数，即在时间和频率上都局部化的小波包。为了得到精确的图像，我们可能会倾向于创建一个非常密集的字典，包含对应每一个可想象的时间和频率的原子。但这里我们遇到了一个基本的权衡，一种实践中的[海森堡不确定性原理](@entry_id:171099)。当我们把字典原子[排列](@entry_id:136432)得越来越紧密时，它们不可避免地开始越来越像它们的邻居。我们字典的相干性增加了。如果[相干性](@entry_id:268953)变得太高，像[匹配追踪](@entry_id:751721)这样的算法就会被混淆，无法区分两个独立但间隔很近的啁啾声 [@problem_id:3574625]。我们字典的相干性决定了我们在时间和频率上观察世界的分辨率。这甚至延伸到机器学习中现代卷积模型的设计，其中像滤波器的步幅和扩张率这样的实践选择，直接控制了底层特征字典的[相干性](@entry_id:268953)，从而影响其识别不同特征的能力 [@problem_id:3440949]。

### 聆听宇宙：从物理到工程

相干性的影响远远超出了我们创造的信号，延伸到对基本物理过程的测量。想象你正试图定位一条河流中污染物的来源。污染物通过[平流](@entry_id:270026)（被水流携带）和[扩散](@entry_id:141445)（自行散开）的过程[扩散](@entry_id:141445)开来。我们可以在下游放置传感器来测量浓度。在这种情况下，我们的“字典”是由物理学本身构建的：每个原子是我们传感器上会看到的理论浓度模式，假如源头位于某个特定的候选位置。这些模式由[平流-扩散方程](@entry_id:746317)的格林函数描述。

现在，物理学如何与[相干性](@entry_id:268953)联系起来？答案在于[佩克莱数](@entry_id:141791)（Peclet number），一个衡量平流与[扩散](@entry_id:141445)比率的无量纲量。当[扩散](@entry_id:141445)占主导时（低佩克莱数），来自任何源的污染物云都会[扩散](@entry_id:141445)成一个宽阔、平滑的斑块。来自两个不同潜在源位置的模式将是宽泛且高度重叠的——在我们的传感器看来它们会非常相似。我们字典的列将高度相关，[相互相干性](@entry_id:188177)将很大，几乎不可能区分这些源。相反，当[平流](@entry_id:270026)占主导时（高[佩克莱数](@entry_id:141791)），污染物被紧凑地携带到下游。来自不同源位置的模式是尖锐且分离良好的。字典原子几乎是正交的，[相干性](@entry_id:268953)很低，像[正交匹配追踪](@entry_id:202036)这样的算法可以轻松地精确定位源头。这难道不奇妙吗？一个来自[流体动力学](@entry_id:136788)的基本参数，佩克莱数，直接控制了我们[反问题](@entry_id:143129)的数学相干性，从而决定了我们找到唯一答案的能力 [@problem_id:3387255]。

同样的故事也发生在一个完全不同的领域：[阵列信号处理](@entry_id:197159)。[天线阵列](@entry_id:271559)被用来确定入射无线电信号的方向，这是雷达、声纳和[无线通信](@entry_id:266253)核心的技术。在这里，字典原子是“导向矢量”——[天线阵列](@entry_id:271559)对来自每个可能方向的信号的预期响应。为了提高精度，我们可能会设计一个非常密集的可能方向网格。但这造成了一个熟悉的困境。两个非常接近方向的导向矢量几乎是相同的。我们的字典变得高度相干。这使得解析两个彼此靠近的信号源变得极其困难。再一次，我们的字典网格的精度与高相干性引入的歧义之间存在权衡。像Sparse-MUSIC这样的复杂算法必须应对这个问题，有些甚至使用迭代重加权方案，旨在惩罚与邻居过于相似的原子，积极对抗[相干性](@entry_id:268953)的不良影响 [@problem_id:2908551]。

### 透视生命与物质

也许最令人惊讶的应用是在生命科学和[材料科学](@entry_id:152226)领域，在那里，[相干性](@entry_id:268953)决定了在分子和原子尺度上可观测的极限。

在[蛋白质组学](@entry_id:155660)中，科学家使用[质谱法](@entry_id:147216)来识别和量化生物样本中成千上万种蛋白质。在一种称为数据非依赖性采集（Data-Independent Acquisition, DIA）的现代技术中，仪器产生一个复杂的信号，它是混合物中所有肽（蛋白质的片段）的[碎片模式](@entry_id:201894)的线性叠加。那么，我们的字典就是一个包含每一种可能肽的已知碎片特征的巨大库。识别样本中存在哪些肽的问题就成了一个[稀疏恢复](@entry_id:199430)问题。但是许多肽在化学上是相似的，仅相差一个氨基酸。因此，它们的碎片特征也非常相似。这意味着我们的肽字典在本质上是高度相干的，而且往往是极其相干的。

这意味着什么？[稀疏恢复](@entry_id:199430)理论给了我们一个清晰且相当发人深省的答案。对于像OMP这样的算法，要在噪声和成千上万其他相似肽的“混淆”中正确识别一个肽，该肽的信号必须强于某个阈值。这个阈值直接取决于字典的[相互相干性](@entry_id:188177)。本质上，[相干性](@entry_id:268953)为能够被可靠检测到的肽的浓度设定了一个基本限制 [@problem_id:3311478]。一个矩阵的抽象数学属性直接转化为我们探测生命构件能力的硬性限制。

当我们放大到物质本身的结构时，同样的原则也适用。利用原子探针[断层扫描](@entry_id:756051)（Atom Probe Tomography）等技术，[材料科学](@entry_id:152226)家旨在重建样本中每个原子的三维位置。为了分析数据中的缺陷——比如一个缺失的原子（空位）或一个杂质——我们可以使用一个字典，其中每个原子代表由特定位置的特定缺陷引起的原子位移场。这个字典的相干性告诉我们，我们能多好地区分，比如说，A位置的空位和B位置的空位，或者一个空位和一个小的间隙[原子簇](@entry_id:193935)。值得注意的是，通过对这些缺陷的物理建模，我们甚至可以预测由此产生的字典的[相干性](@entry_id:268953)。例如，一个缺陷引起高频应变场的模型，使我们能够计算出所得字典的精确相干性，结果发现它是一个与晶体大小无关的常数 [@problem_id:38579]。[相干性](@entry_id:268953)成为连接缺陷物理性质与我们计算识别能力之间的桥梁。

### 追求完美字典

在我们的整个旅程中，[相干性](@entry_id:268953)常常以反派的形象出现——一个基本的障碍，一个不可避免的[歧义](@entry_id:276744)来源。那么一个自然的问题就出现了：如果高[相干性](@entry_id:268953)如此麻烦，我们能否设计出更好的字典？我们能否学习一种不仅准确而且无歧义的世界表示方法？

这就引出了[字典学习](@entry_id:748389)领域。我们不再使用像[傅里叶变换](@entry_id:142120)或小波变换这样的固定、预定义的字典，而是可以尝试直接从数据本身学习一个字典。在这里，我们可以变得很聪明。在学习过程中，我们可以添加一个明确惩罚[相干性](@entry_id:268953)的惩罚项。我们可以要求学习算法不仅要找到能很好地表示数据的原子，还要找到彼此之间尽可能不同的原子。一种优雅的方法是添加一个基于原子间[内积](@entry_id:158127)[绝对值](@entry_id:147688)总和的正则化器。在经典的最优方向法（Method of Optimal Directions, MOD）中，优化步骤是一个简单的[最小二乘拟合](@entry_id:751226)，而现在它变成了一个近端更新，对字典[格拉姆矩阵](@entry_id:203297)的非对角元素执行“[软阈值](@entry_id:635249)”操作。它 буквально地收缩了原子之间的[内积](@entry_id:158127)，迫使它们分开 [@problem_id:3444109]。我们正在主动地设计我们的测量系统，使其减少歧义。

这提出了最后一个优美的问题：我们到底能做到多好？一个字典的非[相干性](@entry_id:268953)是否存在理论上的极限？答案是肯定的，它由[Welch界](@entry_id:756691)给出。对于在维度为 $m$ 的空间中的任意数量的原子 $n$，[相互相干性](@entry_id:188177)有一个硬性的下限。你就是不能在一个空间里塞进太多的向量而不让它们中的一些变得亲密。达到这个界的字典是被称为[等角紧框架](@entry_id:749050)的特殊对象。它们代表了向量可能的最民主和最对称的[排列](@entry_id:136432)。例如，在二维平面中，由3个原子组成的“最佳”字典，是由三个彼此相隔120度的[单位向量](@entry_id:165907)组成，形成一个完美的星形。这个字典的相干性恰好是 $\frac{1}{2}$，这正是[Welch界](@entry_id:756691)预测的值 [@problem_id:3479324]。寻找用于表示我们世界的最优构建模块集合，最终将我们引向了纯粹而优美的几何问题。

从图片到蛋白质，从河流污染到[晶格结构](@entry_id:145664)，[相干性](@entry_id:268953)这个简单的思想被证明是一条深刻而统一的线索，揭示了我们测量、区分并最终理解我们周围世界的能力背后深层的联系。