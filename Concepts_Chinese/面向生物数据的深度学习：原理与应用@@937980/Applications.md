## 应用与跨学科联系

在探索了深度学习的原理和机制之后，我们可能会觉得仿佛一直在研究一个强大的新游戏的抽象规则。但这绝非简单的纸上谈兵。这些思想的真正美妙之处在于我们看到它们付诸实践之时，在于我们用它们来探究生命世界最深层的问题之时。我们即将见证这些诞生于数学和计算机科学的算法，如何成为我们生物学发现的伙伴。这是故事中抽象变为有形的部分，我们从描述生命的机制，转向预测其行为，理解其逻辑，以及最引人注目地，开始重新设计它。这是一段从阅读生命之书，到极其谨慎地开始书写我们自己句子的旅程。

### 解读基因组的“暗物质”

几十年来，我们认为基因组是一串字母，其中某些特殊的词——基因——承载了所有的意义。我们现在知道这种观点过于简单。基因组的绝大部分，即所谓的“暗物质”，根本不是沉寂的。它是一个繁忙的调控景观，一个复杂的交换台，告诉基因何时开启、何时关闭，以及以多大的声音“说话”。这是[表观基因组](@entry_id:272005)的领域，而深度学习已成为我们穿越其复杂地形的必备向导。

想象一下预测一个微小的化学标签——一个甲基基团——将被放置在DNA上的哪个位置的任务。这不是一个[随机过程](@entry_id:268487)；它由一套我们才刚刚开始理解的复杂规则所支配。我们可以给[机器学习模型](@entry_id:262335)提供大量局部信息：特定DNA序列的密度、染色质（DNA的包装结构）的开放程度，以及各种[组蛋白修饰](@entry_id:183079)——缠绕DNA的蛋白质上的化学标记——的存在。模型的任务是学习一个函数，将这些特征映射到最终的甲基化状态。通过仔细的实验，使用[梯度提升](@entry_id:636838)树或逻辑回归等策略，我们可以发现某些特征，如活性启动子标记 $\text{H3K4me3}$ 或增[强子](@entry_id:198809)标记 $\text{H3K27ac}$，是*未甲基化*DNA的强预测因子，而沉默染色质的标记 $\text{H3K9me3}$ 则预测相反的结果。但要正确地进行这项科学研究，我们必须格外小心，不要自欺欺人。由于基因组的相邻区域不是独立的，我们不能简单地将数据随机划分为[训练集](@entry_id:636396)和[测试集](@entry_id:637546)。我们必须预留出整个染色体，以确保我们的模型真正具有泛化能力，这是生物学中至关重要的统计严谨性的一课 [@problem_id:2560955]。

这种调控语法不仅决定了基因的开/关状态；它还编排了基因自身的构建过程。我们的大多数基因不是连续的区块，而是由称为外显子的片段组装而成，中间的内含子被剪接掉。这个剪接过程本身也受到调控。细胞如何决定包含哪些外显子？同样，我们可以求助于深度学习。我们可以将外显子周围的基因组区域视为一种一维图像。这个图像中的每个“像素”是一个DNA碱基，它有多个“颜色通道”：一个用于DNA序列本身，另一个用于来自ATAC-seq的染色质可及性，还有其他用于[组蛋白](@entry_id:196283)标记如 $\text{H3K36me3}$（与活跃转录相关）和 $\text{H3K27ac}$（标记附近的增[强子](@entry_id:198809)）。然后，一个[卷积神经网络](@entry_id:178973) (CNN)，也就是用于图像识别的那种模型，可以学会“读取”这个局部的基因组图像，并预测外显子将如何被剪接。这种方法精妙地洞察到，真正重要的是剪接位点周围的*局部模式*及其空间关系 [@problem_id:4331006]。

这种方法的顶峰是构建一个单一的、统一的模型，来预测任何遗传变异的功能，特别是那些位于广阔的非编码区的变异。想象一个具有并行流（或称塔）的架构，每个流都是一个专门的CNN，用于处理一种不同的数据类型：一个处理原始DNA序列，另一个处理[染色质可及性](@entry_id:163510)，第三个处理一组[组蛋白](@entry_id:196283)标记，还有一个处理DNA甲基化。这些流首先独立处理它们的信息，就像我们的大脑有独立的区域处理视觉和听觉信息一样。然后，在更高的层次上，像注意力这样的机制可以融合这些表示，学习在不同情境下哪些信号最重要。至关重要的是，通过向模型输入特定细胞类型的学习“嵌入”，可以使模型具有组织感知能力；通过运行模型两次——一次使用参考DNA碱基，一次使用变异碱基——可以使其具有等位基因特异性，从而预测该变化的精确因果影响。为了帮助模型学习更普适的原理，我们甚至可以给它一些辅助任务，比如仅从DNA序列预测[表观基因组](@entry_id:272005)状态。这不仅仅是一个模型；它是中心法则的计算表示，是生物学原理和深度学习工程的美妙综合 [@problem_id:4554243]。

### 数字显微镜：在细胞中看见不可见之物

生命不是一维的。要理解生物学，我们也必须观察它。几个世纪以来，显微镜一直是生物学家的眼睛，但来自高内涵筛选——即在细胞上测试数千种潜在药物——的现代成像数据的巨大体量已经让人类观察者应接不暇。深度学习提供了一个“数字显微镜”，能够以超人的速度、准确性和客观性进行观察。

分割任务——在一片拥挤的细胞中识别每个细胞核和细胞质的边界——是一个经典的挑战。当显微镜的光照不完全均匀时，像简单的强度阈值法这样的传统方法会失效。像分水岭变换这样的形态学方法倾向于将一个有噪声的细胞核错误地分割成许多片。而主动轮廓模型可能会卡住或“泄漏”到相互接触的细胞模糊不清的边界之外。[深度学习模型](@entry_id:635298)，通常是[U-Net架构](@entry_id:635581)，从生物学家手工标注的例子中学习。它学习“细胞核”看起来是什么样子，包括其在形状、纹理和亮度上的所有变异。它对许多困扰旧方法的问题都具有鲁棒性。然而，这种能力伴随着一个关键假设：测试图像必须看起来像训练图像。如果染色强度从一批实验到下一批发生漂移——一个被称为[域漂移](@entry_id:637840)的常见问题——模型的性能可能会灾难性地下降。理解这些失效模式与欣赏模型的强大能力同等重要 [@problem_id:5020623]。

### 从预测到实践：临床中的[深度学习](@entry_id:142022)

许多这些工具的最终目标不仅仅是推动基础科学，而是改善人类健康。这是风险最高的地方，也是对严谨性标准必须绝对严格的地方。

[医学遗传学](@entry_id:262833)中最大的挑战之一是解释在患者基因组中发现的数百万“[意义不明确的变异](@entry_id:269401)”(VUS)。一个特定的DNA变化是导致疾病还是无害的？为了帮助回答这个问题，我们现在可以在实验室中使用多重变异效应分析(MAVE)一次性测试成千上万个变异。这些实验为每个变异提供了一个定量的功能得分，这是训练监督式[深度学习模型](@entry_id:635298)的完美标签来源。模型学习从变异的特征（例如，[序列保守性](@entry_id:168530)、结构背景）到其预测功能得分的映射。然而，绝对关键的是要记住，这个分数衡量的是*特定于实验的分子功能*，而非*临床致病性*。一个低分是一条证据，但不是诊断。构建这些模型需要极高的统计谨慎性：预留[测试集](@entry_id:637546)，使用适当的度量标准，甚至根据每个数据点的测量不确定性来加权学习过程 [@problem_id:5049931]。

当一个模型的预测可能影响临床决策时，一个简单的点估计是不够的。我们需要知道模型有多自信。这就是[贝叶斯深度学习](@entry_id:633961)发挥作用的地方。总的预测不确定性可以被优雅地分解为两种类型。**[偶然不确定性](@entry_id:154011)**是数据本身固有的随机性或噪声——不可避免的生物变异和测量误差。即使有完美的模型，这种不确定性依然存在。**[认知不确定性](@entry_id:149866)**是模型自身的不确定性，是其由于训练数据有限或有偏而产生的无知。高的[认知不确定性](@entry_id:149866)告诉我们：“我不确定这个预测，因为我没有见过足够多这样的例子。” 高的[偶然不确定性](@entry_id:154011)则说：“这个系统本身就充满噪声且难以预测。” 当一个模型预测某个遗传变异的影响接近临床决策阈值时，高的认知不确定性是一个警示信号，提醒我们要谨慎并寻求更多证据。这是一个明智地知道自己所不知的模型 [@problem_id:4330961]。

这种预测能力延伸到患者的反应。在一项新的疟疾疫苗临床试验中，我们可以在志愿者接种疫苗后不久测量他们血液中数千个基因的表达水平和[细胞因子](@entry_id:204039)信号。这创造了一个典型的高维问题，其中特征数量（$p$）远大于患者数量（$n$）。我们能否找到一个早期特征来预测谁将受到保护？在这里，将像$\ell_1$惩罚逻辑回归这样能诱导稀疏性的模型与像*[嵌套交叉验证](@entry_id:176273)*这样严格的验证策略相结合至关重要。嵌套过程确保我们的[特征选择](@entry_id:177971)和模型调优不会“偷看”测试数据，从而防止我们报告一个过于乐观的结果。这种严谨的方法使我们能够找到一小组可解释的生物标志物，有朝一日可用于快速评估新的候选疫苗 [@problem_id:4819204]。

### 因果前沿：探问“如果……会怎样？”

标准的机器学习非常擅长发现相关性。它学习在给定$X$的情况下预测$Y$，即$p(y|x)$。但科学，尤其是医学，通常对一个更深层次的问题感兴趣：如果我*干预*并*改变*$X$，那么$Y$会发生什么？这是因果关系的问题，即预测$p(y|\mathrm{do}(x))$。

考虑一个简单的基因网络，其中[主调控因子](@entry_id:265566)$Z$同时影响中介因子$X$和目标$Y$，而$X$也影响$Y$。在观测数据中，$X$和$Y$之所以相关有两个原因：从$X$到$Y$的因果路径，以及[共同原因](@entry_id:266381)$Z$同时影响它们的“后门”路径。一个基于此数据训练的标准预测模型会学习到整体的相关性，并将其全部误认为是$X$对$Y$的影响。如果我们随后用这个模型来预测敲除基因$X$的[CRISPR](@entry_id:143814)实验的结果，预测将会是错误的。它被混淆了。一个具有因果意识的模型，一个明确表示潜在依赖关系图（结构因果模型）的模型，可以区分这些路径。通过在计算上“切断”指向$X$的箭头——模拟干预——它可以正确预测真实的因果效应。从相关性预测到干预性预测的这一飞跃是该领域最激动人心的前沿之一，有望将我们的模型从被动的观察者转变为实验设计的积极参与者 [@problem_id:3299375]。

### 创造性飞跃：[生成模型](@entry_id:177561)与[生物设计](@entry_id:162951)

到目前为止，我们主要讨论的是*预测*模型。但[深度学习](@entry_id:142022)一个更深远的应用在于*生成*模型——能够创造出前所未有的新型生物实体的机器。

生成模型不必是一个“黑箱”，它可以融入我们已有的知识。考虑一个在单细胞基因表达数据上训练的[变分自编码器](@entry_id:177996)(VAE)。标准的VAE假设每个基因的表达都是从某个潜码中独立生成的。但我们知道这是错误的；基因是在网络中运作的。我们可以构建一个更智能的VAE，其解码器受到一个已知的[基因调控网络](@entry_id:150976)的约束。如果该网络是一个[有向无环图](@entry_id:164045)，那么解码器的似然函数就可以分解为[条件概率](@entry_id:151013)的乘积，$p(x_i | z, x_{\text{parents}(i)})$，就像一个[贝叶斯网络](@entry_id:261372)一样。这创造了一个既能从数据中学习，又尊重我们已知结构的模型，是数据驱动与知识驱动科学的美妙结合 [@problem_id:3357990]。

[生成模型](@entry_id:177561)最引人注目的用途在于设计。模型能发明一种具有期望功能的新蛋白质吗？这现在已成为现实。在海量已知[蛋白质序列](@entry_id:184994)数据库上训练的模型学习了蛋白质语言的“语法”。然后可以提示它们生成新的序列。但我们如何知道模型是否真正在进行创造，还是仅仅在轻微修改它在训练中见过的蛋白质？答案再次在于极端的科学严谨性。为了验证一个[生成模型](@entry_id:177561)，我们必须极其仔细地划分数据，确保测试集中的任何蛋白质与[训练集](@entry_id:636396)中的任何蛋白质在序列、结构域甚至三维结构上都没有相似性。只有通过在真正新颖的问题上进行测试，我们才能确信我们的模型已经学会了[蛋白质折叠](@entry_id:136349)和功能的基本原理，并可以被信赖为一个创造性的伙伴 [@problem_id:4567914]。

### 终极统一：在硅基和碳基中学习

当我们使用这些[人工神经网络](@entry_id:140571)来理解生命的[生物网络](@entry_id:267733)时，一个有趣的问题出现了：我们发现的学习原理是普适的吗？在硅基中如此有效的算法，与在我们自己大脑这个碳基计算机中发生的学习，是否有任何相似之处？

这种联系比你想象的要深。考虑我们拥有的最简单的学习规则：[均方误差](@entry_id:175403)上的[梯度下降](@entry_id:145942)。对于单个线性神经元，权重更新规则最终与突触前输入乘以[预测误差](@entry_id:753692)成正比。这是一个“局部”学习规则。长期以来，大脑如何实现深度网络中使用的[反向传播算法](@entry_id:198231)一直是个谜，因为它似乎需要非局部信息和对称的反馈权重（即“权重传输问题”）。神经科学中的*[预测编码](@entry_id:150716)*理论提供了一个诱人的替代方案。它假设大脑是一个分层的预测机器，不断试图预测感官输入。高级皮层区域向下发送预测，而低级区域向上发送[预测误差](@entry_id:753692)。这些计算都是局部的，并且已经证明，在某些条件下，这个过程可以近似全局预测误差上的[梯度下降](@entry_id:145942)。在某种程度上，我们的大脑和我们的深度学习模型可能已经趋同于一个相似的、根本性的解决方案来解决从世界中学习的问题 [@problem_id:3148528]。

因此，[深度学习](@entry_id:142022)在生物学中的应用不是一条单行道。我们不仅仅是将一个工具应用于一个问题。生物数据的独特挑战——其复杂性、高维性、[因果结构](@entry_id:159914)——正在推动机器学习本身的边界。在努力构建能够学习生命逻辑的模型时，我们或许会发现一些关于学习本质的深刻见解，无论它发生在活细胞中、人脑中，还是在机器的核心里。