## 引言
单细胞 RNA 测序 (scRNA-seq) 以前所未有的高分辨率视角审视单个细胞，彻底改变了我们探索复杂生物系统的能力。然而，这项强大的技术产生的原始数据——以基因计数矩阵的形式存在——充满了技术噪声和系统性偏差。RNA 捕获效率和测序深度等因素的差异会掩盖真实的生物信号，使得细胞间的直接比较产生误导。这就提出了一个关键挑战：我们如何才能从这些技术性人为因素中区分出有意义的生物学变异？

答案在于标准化，这是一个至关重要的计算过程，是几乎所有下游[单细胞分析](@entry_id:274805)的基础。没有适当的标准化，我们识别细胞类型、发现差异表达基因或整合数据集的尝试都将存在根本性的缺陷。本文为 [scRNA-seq](@entry_id:155798) 标准化的理论和实践提供了全面的指南。

首先，在“原理与机制”一章中，我们将剖析核心的统计学挑战以及为应对这些挑战而设计的方法的演变。我们将从直观的缩放技术讲起，逐步深入到明确考虑单细胞计数数据独有特性的复杂基于模型的方法。然后，在“应用与跨学科联系”一章中，我们将探讨标准化的深远影响，展示它如何支持从基本的细胞群体识别到转化医学、多组学整合和空间生物学等高级应用。读完本文，您将理解为什么标准化不仅仅是一项技术性的杂务，而是单细胞时代生物学发现的基石。

## 原理与机制

想象你是一位制图师，任务是为新发现的群岛绘制一幅详细地图。你的原始数据是数千张航拍照片，每张都捕捉了一个岛屿。问题在于，这些照片是在不同高度、不同日期、用不同相机拍摄的。一个岛屿可能看起来小而稀疏，仅仅因为照片是从 30,000 英尺高空拍摄的；而另一个岛屿则显得大而细致，因为它是在 5,000 英尺处拍摄的。为了创建一幅能比较各岛屿特征的真实地图，你必须首先校正这些技术差异。

这正是我们在单细胞 RNA 测序 (scRNA-seq) 中面临的挑战。原始输出，一个**计数矩阵**，为我们提供了在每个细胞中检测到的每个基因的 RNA 分子数量。但是，一个细胞可能显示较少的分子，并非因为它生物学上活性较低，而仅仅是因为我们的“相机”——测序过程——在捕获其内容时效率较低。每个细胞在捕获效率和测序产出上的这种差异被称为其**测序深度**或**文库大小**。因此，标准化就是一门校正这些技术“高度”以揭示真实生物学景观的艺术。

### 初次近似：调整高度

校正不同文库大小最直观的方法就是简单地缩放每个细胞中的计数。如果一个细胞的总计数是另一个细胞的两倍，我们可能会推测它的测序“深度”是后者的两倍。为了使它们具有可比性，我们可以将每个细胞的原始计数转换为该细胞总计数的一部分。这就是**文库大小标准化**的本质。

在实践中，我们通常不使用微小的分数，而是将这些比例乘以一个恒定的缩放因子，比如一百万，以得到**每百万计数 (CPM)**，或者在 [scRNA-seq](@entry_id:155798) 中使用 10,000 以获得更方便的尺度。这个过程是一种**全局缩放**：我们为每个[细胞计算](@entry_id:267237)一个单一的校正因子，并将其统一应用于该细胞内的所有基因 [@problem_id:4377531]。

让我们具体说明。假设对于给定细胞中的一个特定基因，我们有一个原始 UMI 计数 $c_{ig} = 50$，而该细胞的总 UMI 计数是 $\sum_{g} c_{ig} = 5000$。一个标准的[标准化流](@entry_id:272573)程会首先将其缩放为“每 10,000 计数”，然后应用一个变换来稳定数据，我们稍后会回到这一点。完整的变换可能如下所示：
$$ \tilde{x}_{ig} = \log_{2}\left( \left( \frac{c_{ig}}{\sum_{g} c_{ig}} \right) \times 10^4 + 1 \right) $$
代入我们的数字，我们得到：
$$ \tilde{x}_{ig} = \log_{2}\left( \left( \frac{50}{5000} \right) \times 10^4 + 1 \right) = \log_{2}(100 + 1) \approx 6.658 $$
这个最终的数字，而不是原始的 50 计数，才是我们用来将这个基因的表达与其他细胞中该基因的表达进行比较的值 [@problem_id:4607704]。

你可能想知道其他因素，比如基因的物理长度。在某些类型的测序中，较长的基因仅仅因为目标较大而产生更多的信号。然而，在现代基于 UMI 的 [scRNA-seq](@entry_id:155798) 中，我们使用“标签”来计数单个分子，实际上是在计数分子而不是片段。基因的长度不影响其分子计数。因此，在大多数基于 UMI 的研究中校正基因长度不仅没有必要，而且实际上会引入偏差，混淆我们的测量结果 [@problem_id:4608284]。这是一个重要的提醒：我们的标准化策略必须与我们的测量技术物理原理相匹配。

### 均值的暴政：一个更深层次的问题

我们简单的缩放方法看起来很合理，但它隐藏着一个微妙而深刻的问题。即使我们将所有“照片”调整到相同的比例，计数数据的一个基本统计特性仍然存在，它可能会误导我们的分析工具。问题是：对于计数数据，一个基因的**方差**（其表达值在细胞间的波动程度）与其**均值**（其平均表达水平）内在地联系在一起。高表达的基因自然具有更高的方差。

这种现象被称为**[异方差性](@entry_id:136378)**。想象一下比较一个繁忙的市中心和一个安静的郊区街道。市中心的人数会每小时剧烈波动（高均值，高方差），而郊区街道上的人数则会更稳定（低均值，低方差）。许多强大的下游方法，如广泛使用的主成分分析 (PCA)，就像是假设“[测量噪声](@entry_id:275238)”在任何地方都相同的测量员。它们可能会被高表达基因的高方差所误导，将其解释为重要的生物学信号，而实际上，这只是它们高丰度所带来的预期统计现象 [@problem_id:1465869]。

为了驯服这种均值-方差关系，我们需要另一种变换。最常用的工具是**[对数变换](@entry_id:267035)**，如上式所示。通过对缩放后的计数取对数（加上一个小的“伪计数”，如 1，以避免 $\log(0)$ 的问题），我们压缩了数据的范围。其效果是显著的：它对高表达基因值的压缩程度大于低表达基因，从而有效地抑制了它们的方差。虽然这不是一个完美的解决方案，但这个 `log(counts + 1)` 步骤极大地[解耦](@entry_id:160890)了方差与均值的关系，使数据更适合标准的统计方法。

### 缩放因子的艺术：超越简单的求和

我们建立了一个可靠的两步过程：按文库大小缩放，然后进行对数变换。但是，一个细胞的总计数总是其技术“高度”的最佳度量吗？想象一种专门生产大量单一抗体的细胞类型。该抗体的基因将主导其总 RNA 含量。如果我们使用总计数作为其缩放因子，这个细胞将看起来具有非常大的文库大小。当我们用这个大数进行除法时，我们将人为地压低其所有*其他*基因的表观表达量。这被称为**组成偏差**：少数高表达基因的变化会扭曲所有其他基因的标准化结果 [@problem_id:3348563]。

为了克服这个问题，人们开发了更复杂的方法来估计缩放因子。其中最优雅的方法之一是**基于解卷积的方法**，在 `scran` 包中有著名的实现。其核心思想异常简单。我们不信任单个细胞的总计数，而是成对地比较细胞。其假设是，对于任何两个细胞（尤其是相似的细胞），*大多数*基因是不变的。通过观察这些稳定的“看家”基因的计数比率，我们可以更稳健地估计这两个细胞之间的相对技术差异。

该方法更进一步。为了应对单细胞数据中大量零计数（“稀疏性”）的问题，它首先将来[自相似](@entry_id:274241)细胞组的计数汇集起来，创建“伪细胞”。这些伪细胞具有更高的计数和更少的零值，使得表达比率的计算更加稳定。通过求解基于这些细胞池之间比较的大型[线性方程组](@entry_id:140416)，该算法可以从稳健的池级别缩放因子中“解卷积”出每个单细胞的高度准确的缩放因子 [@problem_id:3348563] [@problem_id:5157599]。即使在一个完全同质的单一细胞类型群体中，这种跨细胞[借力](@entry_id:167067)的策略也比简单地使用每个细胞自身的总文库大小提供了更稳定、更可靠的真实技术因子估计 [@problem_id:2429843]。

### 现代综合：通过建模消除噪声

到目前为止，我们将标准化视为一系列修正步骤：首先修正深度，然后修正方差。这很有效，但感觉像是在两个不同的地方修补漏水的管道。现代方法，如 **SCTransform**，则是建立一个统一的模型来*描述*噪声，然后从数学上减去它。

这种方法将每个基因的 UMI 计数视为遵循**负二项 (NB) 分布**的随机变量，这是一种灵活的计数数据模型，能够处理我们前面讨论的均值-方差关系。然后，对于每个基因，它拟合一个**[广义线性模型 (GLM)](@entry_id:749787)**。该模型明确地学习了基因的预期表达与技术变量（最重要的是细胞的[测序深度](@entry_id:178191)）之间的关系 [@problem_id:4991035]。用模型的语言来说，我们写作：
$$ \log(\text{mean expression}) \sim \log(\text{sequencing depth}) $$

这种方法的妙处在于，模型可以学习一种*基因特异性*的关系。它不像我们早期的方法那样，假设[测序深度](@entry_id:178191)以完全相同的乘法方式影响所有基因。它允许某些基因对[测序深度](@entry_id:178191)的变化比其他基因更敏感或不敏感的可能性 [@problem_id:4381636]。

一旦模型学习了基因表达基于技术因素“应该”如何表现，“标准化”的表达值就仅仅是**残差**——在减去技术预测后剩下的部分。这些不是普通的残差；它们是**皮尔逊残差**，经过精心构建，使其方差稳定在约等于 1，而不管基因原始的均值表达如何。

这种方法优雅地一次性解决了我们的两个主要问题。它消除了测序深度的混淆效应，并产生了适合下游分析的方差稳定值。这种方法的力量不仅是理论上的。在一个假设的测试中，简单的对数变换可能会使一个高变异基因的标准化[方差比](@entry_id:162608)一个稳定基因高出 26 倍以上。相比之下，一个理想化的基于模型的方法会使它们的标准化方差相等，实现完美的稳定化 [@problem_id:1465880]。这表明了明确建模数据属性而不是仅仅应用顺序校正的巨大力量。

最后，那些所有的零值怎么办？一个 70% 是零的矩阵是否意味着我们的细胞大部分是“关闭”的？完全不是。对于 UMI 数据，严谨的统计分析表明，这些零绝大多数是“抽样零值”。它们的出现仅仅是因为一个基因的表达水平较低，在捕获和测序分子的随机抽奖中，它恰好在该细胞中被错过了。SCTransform 中使用的负[二项模型](@entry_id:275034)完全能够解释这些丰富的零值，而无需引入一个独立的“零膨胀”过程。将这种固有的稀疏性误认为是一个更复杂的生物学现象是一个常见的陷阱，而这些有原则的模型帮助我们避免了它 [@problem_id:4562776]。

scRNA-seq 标准化的历程是[计算生物学](@entry_id:146988)史册中的一个美妙故事。它始于简单、直观的想法，并通过直面其局限性，演变成一个复杂的统计框架。我们已经从简单地“校正”我们的数据，发展到真正“理解”其生成过程。通过对技术性迷雾进行建模，我们现在可以将其减去，从而以惊人的清晰度揭示其下的生物学真理。

