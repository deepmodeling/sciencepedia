## 引言
[深度学习](@entry_id:142022)正在迅速重塑生物医学研究的格局，为破译生命与疾病的复杂机制提供了前所未有的能力。几个世纪以来，我们的理解建立在机理模型之上，这些模型虽然强大，但往往难以捕捉生物系统的巨大规模和错综复杂性。我们理论框架与生物学现实之间的这种差距，催生了对一种新范式的需求——一种能够直接从现有海量数据中学习的范式。本文旨在弥合这一差距，全面概述[深度学习](@entry_id:142022)在现代生物医学中的作用。

旅程始于第一章“原理与机制”，我们将在这里剖析驱动这些先进算法的核心概念。我们将探讨从基于模型的科学到数据驱动的科学的哲学转变，揭示机器“学习”的真正含义，并考察如何通过[归纳偏置](@entry_id:137419)赋予模型生物学直觉。随后，第二章“应用与跨学科联系”将展示这些原理如何被应用于解决现实世界的问题。从破译基因组的语言、设计新型药物，到为整个生理[系统建模](@entry_id:197208)、探索医学人工智能的伦理前沿，我们将看到[深度学习](@entry_id:142022)不仅是一种工具，更是一股推动跨学科发现的统一力量。

## 原理与机制

要真正领会[深度学习](@entry_id:142022)为生物医学带来的革命，我们必须超越新闻头条，掌握驱动这些强大工具的原理。这是一段从[科学建模](@entry_id:171987)的哲学基础，到单个预测所带来的关乎生死的实际后果的旅程。本着物理学家试图从第一性原理理解世界的精神，让我们层层剥茧，探究这些系统运转的奥秘。

### 建模的两种文化：从方程到经验

几个世纪以来，生物学和医学领域的理解金标准一直是**机理模型**。想象一下，要理解一种药物如何在肝脏中被处理。生物化学家会首先写下一组描述[反应速率](@entry_id:185114)、结合亲和力以及转运过程的[微分](@entry_id:158422)方程，所有这些都基于已确立的化学和物理定律。这是一种“基于模型”的方法：你从一个关于世界如何运作的理论开始，然后用数据来填充你理论中的具体数字（参数）[@problem_id:4332661]。

这些模型是优美的。它们的参数，例如[反应速率](@entry_id:185114) $k$，具有直接的物理意义。它们是可解释的。更重要的是，它们拥有一种预测的超能力：因为它们编码了*因果*机制，所以你可以提出“如果……会怎样？”的问题。如果我们将药物剂量加倍会怎样？如果患者的某个基因变异导致一种关键酶的活性减半会怎样？模型可以提供一个有理据的答案，使其能够**外推**到它所见过的确切条件之外。但问题在于，为一个真正复杂的系统——比如整个细胞，或响应感染的免疫系统——建立这样一个模型是极其困难的，甚至是不可能的。相互作用的网络过于庞大，而我们的知识又过于不完整。

这正是第二种文化——[深度学习](@entry_id:142022)的**数据驱动**方法——登场的时刻。一个深度学习模型，在其最纯粹的形式下，对底层机制的假设非常少。它不是被给予一组方程，而是被给予大量的经验——数据。它可能被输入数十万个分子结构及其测量属性，或数百万份患者记录及其结果。模型的工作不是验证一个预先写好的理论，而是学习一个函数，任何能成功将输入映射到输出的函数。它是一个通用逼近器，一个内插大师。对于数据中隐藏的任何模式，无论多么复杂或非线性，一个足够大的深度网络都能学会捕捉它[@problem_id:4332661]。

这种能力也伴随着一个权衡。模型的内部参数——在某些情况下多达数百万个——并不对应于我们能轻易理解的物理量。这导致了臭名昭著的“黑箱”问题。而且，由于模型学习的是相关性，而不一定是因果关系，当被要求外推时，它很容易被愚弄。如果在其训练数据中所有高溶解度的分子恰好都是红色的，它可能会学到“红色意味着可溶”这个伪规则，当它遇到第一个蓝色的可溶分子时，这个规则将彻底失效。

### 机器“学习”意味着什么？

“学习”这个词听起来很神秘，但其核心是一个非常简单的试错过程，并被精炼成一门艺术。想象你有一台复杂的机器，上面有数百万个微小的旋钮。你的目标是让这台机器拍摄一张细胞图片，然后输出“癌症”或“健康”的字样。你开始时将所有旋钮随机设置。你给它一张你知道是[癌变](@entry_id:166361)的图片，而处于随机状态的机器吐出了“健康”。这是一个错误。

“学习”仅仅是这样一个过程：弄清楚如何将那数百万个旋钮中的每一个都转动一点点，从而使误差变得小一些。这个过程由一个称为**目标函数**（或[损失函数](@entry_id:136784)）的数学配方指导，它只是一个衡量模型错误程度的分数。然后，算法使用微积分（具体来说，是一个名为反向传播的算法和一个像[随机梯度下降](@entry_id:139134)这样的优化器）来计算“梯度”——即误差地形上最陡峭的上升方向——并朝着相反的方向迈出一小步。用数百万个例子重复这个过程数百万次，这些旋钮就会被调整到能够最小化总体误差的值。

现在，一个关键的区别出现了。机器自己调整的旋钮被称为**模型参数**。这些是神经网络的权重和偏置。但是，还有一些其他的旋钮是我们科学家必须事先设置的。这些是**超参数**，它们定义了学习游戏本身的规则。算法在每一步应该迈多大的步子（学习率）？[网络架构](@entry_id:268981)应该多复杂？

一个完美的例子来自一个常见的组件，叫做批归一化（Batch Normalization）。在网络内部，它有两个可学习的参数，一个缩放因子（$\gamma$）和一个位移因子（$\beta$），它们在训练过程中像其他任何旋钮一样被调整。但它也有超参数，例如控制其如何随[时间平均](@entry_id:267915)统计数据的“动量”项 ($m$)，以及一个用于防止除零错误的微小数值“epsilon”($\varepsilon$)。我们在开始前设置 $\varepsilon$ 和 $m$；机器则在运行过程中学习 $\gamma$ 和 $\beta$ [@problem_id:5212765]。理解这一区别是揭开[深度学习](@entry_id:142022)神秘面纱的关键：它不是魔法，而是在一个精心设计的框架内，一个优美自动化的优化过程。

### 从生命未标记的图书馆中学习

生物医学领域最大的障碍之一是标记数据的稀缺性。一个病理学家团队可能需要数周时间来注释一千张组织切片，一个实验室可能需要数月时间来测量几百种化合物的结合亲和力。然而，我们拥有极其庞大的*未标记*数据文库：数十亿的[基因序列](@entry_id:191077)、数百万未经注释的医学图像、巨大的化学数据库。机器能从这个原始、未标记的世界中学习吗？

令人难以置信的是，答案是肯定的。这就是**[自监督学习](@entry_id:173394)**的魔力。模型自己设计学习任务。一个流行且强大的方法是**[对比学习](@entry_id:635684)**。想象你有一个分子。你为它创造了两个略有不同的“视图”——也许是通过稍微不同的计算方法来表示它，或者旋转其3D结构。这两个视图是一个“正例对”。你数据集中的所有其他分子都是“负例”。模型的任务很简单：学习一种表示（一个嵌入），使得同一个分子的两个视图在这个新的表示空间中彼此靠近，而所有其他分子则被推远[@problem_id:4332990]。这就像教一个孩子认识猫，你给他看同一只猫不同姿势的两张照片，说“这是一样的”，同时指着一张狗的照片说“这是不同的”。

在这个过程中，一个名为**温度**（$\tau$）的超参数扮演着一个有趣的角色。它控制着任务的难度。高温允许模型偷懒，将所有负例视为同样不相似。然而，低温则迫使模型更加努力。它锐化了正例对与“最难”负例——那些看起来与锚点极其相似的其他分子——之间的区别。通过成功完成这个困难的游戏，模型学会了对分子相似性的一种丰富而细致的理解，而所有这一切都从未被告知什么是“溶解度”或“毒性”[@problem_id:4332990]。

### 构建理解生物学规则的模型

科学领域最有效的深度学习模型并非通用的现成工具。它们是精湛的工程杰作，被注入了它们所要研究领域的基本原理。这种内置的知识被称为**[归纳偏置](@entry_id:137419)**，它将一个天真的[模式匹配](@entry_id:137990)器与一个能够产生真正科学见解的工具区分开来。

#### 蛋白质的语言

思考一下蛋白质，细胞的“主力军”。蛋白质是一串[氨基酸序列](@entry_id:163755)，是用20个字母的字母表写成的句子。这个序列折叠成一个复杂的三维结构，决定了它的功能。一个强大的想法是，将已知的海量蛋白质序列语料库视为一种语言，并训练一个**[蛋白质语言模型](@entry_id:188811) (PLM)**，这很像驱动ChatGPT等工具的[大型语言模型](@entry_id:751149)[@problem_id:4332980]。通过学习预测序列中被掩盖的氨基酸，模型含蓄地学习了蛋白质演化的语法——那些在序列上相距遥远但在折叠结构中聚集在一起的氨基酸之间微妙的共[演化关系](@entry_id:175708)。

但我们可以更深入。蛋白质的功能，比如它与药物结合的能力，取决于它的三维形状。这个功能对于蛋白质在空间中的位置和方向是**不变的**；无论你如何旋转分子，它的功能都一样。一个好的模型应该无需从头学习就知道这一点。这正是[物理学中的对称性](@entry_id:144576)原理发挥作用的地方。通过设计**SE(3)等变**的网络层，我们构建了一个天生就理解三维空间物理学的模型。一个等变层处理一个旋转过的输入，并产生一个相应旋转的表示。然后，一个最终的不变层可以读取这个表示来进行预测——比如结合亲和力——这个预测会正确地保持不变，无论蛋白质的姿态如何[@problem_id:4332980]。这不仅仅是优雅；它使学习效率大大提高。

#### 分子的社交网络

生物学是一个关于网络的故事。[基因调控](@entry_id:143507)其他基因。蛋白质与其他蛋白质相互作用。一个细胞是一个由相互连接的组件组成的繁华都市。因此，我们使用为处理网络或**图**而设计的模型似乎是很自然的。**[图神经网络 (GNN)](@entry_id:635346)** 通过在图中的连接节点之间传递消息来学习。例如，在[蛋白质-蛋白质相互作用](@entry_id:271521) (PPI) 网络中，每个蛋白质可以根据其直接邻居的特征来更新自己的表示[@problem_id:4349443]。

我们可以利用来自语言模型的突破性技术——**[注意力机制](@entry_id:636429)**——使这一点变得更加强大。**图Transformer**允许一个节点学习它的哪些连接，甚至是远距离的连接，对当前任务最重要。它计算节点对之间的“注意力分数”，以加权信息的流动。我们可以通过偏置这种注意力来注入更多的生物学现实。例如，我们可以在分数中添加一个基于网络中两个蛋白质之间**[最短路径距离](@entry_id:754797) (SPD)** 的项。这告诉模型，网络中结构上相近的两个蛋白质，即使它们不是直接邻居，也可能彼此更相关[@problem_id:4349443]。这是一个美丽的综合：数据驱动的注意力灵活性由[生物网络](@entry_id:267733)的结构知识来引导。

### 从预测到决策：犯错的代价

在生物医学领域，预测很少是故事的结局；它是一个决策的开始。而当决策涉及患者的健康时，我们评估模型的标准必须异常之高。

#### 衡量重要的事

想象一个旨在预测脓毒症的模型，这是一种罕见但致命的疾病，在ICU中的患病率约为2%。一个天真的模型可以通过对每位患者都预测“无脓毒症”来达到98%的准确率。这在统计上会令人印象深刻，但在临床上毫无价值。这就是为什么标准准确率往往是一个危险的误导性指标。

我们需要对类别不平衡的现实敏感的指标。**受试者工作特征曲线下面积 (AUROC)** 是一个常见的选择，但当事件罕见时，它仍然可能具有欺骗性的乐观。在这些情况下，一个信息量大得多的指标是**[精确率-召回率曲线](@entry_id:637864)下面积 (AUPRC)**。精确率回答了这样一个问题：“在我的模型标记为高风险的所有患者中，实际患有脓毒症的比例是多少？”对于一种罕见疾病，这通常是必须对警报采取行动的临床医生最关心的问题。AUPRC更好地总结了模型在我们非常关心的少数类别上的性能[@problem_id:4332660]。

此外，要使模型的预测具有可操作性，它需要是可信的。如果一个模型说一个病人有80%的风险发生不良事件，临床医生需要知道这个数字是有意义的。这个属性被称为**校准**。一个校准良好的模型，其预测的概率与现实世界中的频率相匹配。我们可以用**Brier分数**或**期望校准误差 (ECE)** 等工具来衡量这一点[@problem_id:4332660]。没有良好的校准，模型的输出只是一个任意的分数，而不是一个可以指导理性决策的概率。

#### 量化临床效用

我们可以更进一步，提出终极问题：使用这个模型是否能带来更好的临床结果？这就是**决策曲线分析 (DCA)** 的范畴。DCA从**净收益**的角度来构建问题。它权衡了正确治疗需要治疗的患者（真阳性）所带来的益处，与不必要地治疗不需要治疗的患者（[假阳性](@entry_id:635878)）所带来的危害。

DCA让我们能够将模型的性能与默认策略（如“治疗所有患者”或“不治疗任何人”）进行比较。它显示了模型在哪个风险阈值范围内能够增加价值。值得注意的是，两个具有完全相同[AUROC](@entry_id:636693)的模型可能具有截然不同的净收益。一个模型可能对一个只希望在极高风险时才干预的谨慎临床医生有用，而另一个模型可能更适合一个激进的策略。DCA将评估从统计性能的抽象领域转移到临床后果的具体世界，为模型与其在实践中的效用之间提供了直接的联系[@problem_id:4332658]。

### 直面未知：不确定性、缺失值与因果关系

在生物医学领域构建真正可信赖的人工智能的最后前沿，是教会我们的模型谦逊——让它们意识到自己不知道什么，并防止它们被数据中的幽灵所愚弄。

#### 模型有多自信？

一个负责任的模型不仅应提供一个预测，还应提供其[置信度](@entry_id:267904)的度量。这种预测不确定性可以分为两类。**[偶然不确定性](@entry_id:154011)**是数据本身固有的随机性或噪声——即使拥有完美的模型也无法消除的变异性。可以把它看作是世界不可简化的模糊性。另一方面，**[认知不确定性](@entry_id:149866)**是模型由于其训练数据有限而产生的不确定性。当模型遇到新的、不熟悉的事物，远离其在训练期间所见的内容时，认知不确定性就会很高[@problem_id:4332973]。

区分这两者至关重要。一个预测上的高[偶然不确定性](@entry_id:154011)告诉我们，其结果本身是不可预测的。高[认知不确定性](@entry_id:149866)则是一个警示信号；它告诉我们模型正在其舒适区之外运行，其预测不应被信任。像[深度集成](@entry_id:636362)（Deep Ensembles）或蒙特卡洛 Dropout（MC Dropout）这样的技术使我们能够估计这种认知不确定性，赋予我们的模型一个关键的声音来说：“我不知道。”

#### 数据中的幽灵

现实世界的生物医学数据是一团乱麻。它充满了漏洞。这些缺失背后的原因至关重要。如果数据是**[完全随机缺失](@entry_id:170286) (MCAR)**——比如说，一个试管被随机打碎了——那么剩余的数据仍然是一个无偏的样本。但如果数据是**[非随机缺失](@entry_id:163489) (MNAR)** 呢？例如，医生可能选择不对看起来非常健康的患者进行有风险的诊断测试。在这里，数据缺失这个事实本身就告诉你一些关于患者潜在状态的信息。简单地忽略[缺失数据](@entry_id:271026)，或天真地填补它，可能会导致模型结论出现严重偏差[@problem_id:4332669]。要以有原则的方式处理缺失数据，我们需要像侦探一样思考，并追问信息*为什么*会缺失。

#### 探寻因果之谜

也许最深刻的挑战是从相关性走向因果性。一个在多实验室[药物发现](@entry_id:261243)数据集上训练的天真深度学习模型可能会学到，具有某种化学特征的分子活性很高。但如果该特征只存在于A实验室合成的分子中，而A实验室的检测方法系统性地失准，导致读数偏高呢？模型学到的是一个虚假的相关性，一个数据收集过程中的**混淆**产物。当转移到新问题或用于B实验室的数据时，它就会失败。

这正是该领域前沿的动向：走向**因果深度学习**。一个强大的思想是**不变风险最小化 (IRM)**。其哲学简单而深刻：一个真正的因果关系应该在不同环境中是稳定和不变的。[分子形状](@entry_id:142029)对其溶解度的影响是化学定律；无论是在A实验室、B实验室还是C实验室测量，它都应该是一样的。然而，有缺陷的检测方法是A实验室特有的。IRM通过明确惩罚那些依赖于仅在某些环境中有预测性但在其他环境中没有的特征的模型来进行训练。通过迫使模型去发现普遍成立的预测因子，它鼓励模型去寻找潜在的、不变的因果机制[@problem_id:4333003]。这不仅仅是模式识别；这是向赋予我们的模型一种更深刻、更稳健，并最终更科学的世界理解迈出的一步。

