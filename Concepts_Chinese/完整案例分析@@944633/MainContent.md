## 引言
当面对不完整的数据集时，最直接的处理方法是什么？最简单的方法是移除任何有缺失的条目。这种方法被称为完整案例分析（Complete Case Analysis, CCA）或[列表删除法](@entry_id:637836)（listwise deletion），由于其直观的吸[引力](@entry_id:189550)——只分析你所拥有的完整数据——长期以来一直是一种默认做法。然而，这种简单性掩盖了一个深层次的统计问题。在不了解数据缺失*原因*的情况下就决定丢弃数据，可能会使分析误入歧途，产生不仅不精确，而且从根本上就是错误的结果。

本文深入探讨了完整案例分析的原理和陷阱。第一章“原理与机制”通过介绍缺失数据的关键分类——[完全随机缺失](@entry_id:170286)（MCAR）、[随机缺失](@entry_id:168632)（MAR）和[非随机缺失](@entry_id:163489)（MNAR）——奠定了理论基础。您将了解 CCA 在每种情况下的表现，从仅仅是低效到具有危险的偏差。接下来的章节“应用与跨学科联系”将从理论转向实践，探讨医学、心理学和基因组学等领域的真实案例。我们将看到，删除数据行这一看似无害的行为如何扭曲科学发现，以及为何现代、更复杂的方法对于进行真实的分析往往至关重要。

## 原理与机制

想象一下，你正在拼一个拼图，却发现有些碎片不见了。你能做什么？你可以尝试猜测缺失碎片的样子，或者干脆把拼图中任何不完整的部分放在一边，尝试用剩下的碎片拼出更小的、完整的图像。后一种方法在数据分析领域被称为**完整案例分析**（CCA），或者用一个更形象的术语——**[列表删除法](@entry_id:637836)**。这是处理有漏洞数据最直观，也是历史上最常见的方式。其逻辑简单得诱人：如果电子表格中的一行（代表一个人、一个样本或一次实验）哪怕只缺失一个值，你也要丢弃整行。然后，你用一个更小但完全完整的数据集继续分析。

这种方法带有一种诚实的气息。毕竟，你只使用了你实际观察到的数据，没有“编造”任何东西。几十年来，这是大多数统计软件的默认操作，是阻力最小的路径。但正如我们将看到的，这条路虽然直接，却铺满了隐藏的假设。忽视“缺失性”本身的性质，不仅会导致分析不够精确，还可能导致根本性的、危险的错误。核心问题不在于数据*是否*缺失，而在于*为何*缺失。

### 缺失的分类

要理解[列表删除法](@entry_id:637836)的后果，我们必须首先化身侦探，对数据中出现漏洞的原因进行分类。统计学家已将这些原因归纳为一个出人意料地强大的三部分框架。让我们以一项临床研究为例来探讨它，在该研究中，我们收集患者的[人口统计学](@entry_id:143605)信息（$X$）、生命体征（$V$）以及一项特定的实验室检测，如乳酸（$L$）[@problem_id:4431038]。

#### 良性情况：[完全随机缺失](@entry_id:170286)（MCAR）

这是最理想但也是最罕见的情况。如果一个值缺失的概率与所有数据（无论是观测到的还是未观测到的）完全无关，那么数据就是**[完全随机缺失](@entry_id:170286)（MCAR）**。想象一下，一名实验室技术人员不小心打碎了一支随机的试管，或者一个随机的硬件故障损坏了电子表格中的几个单元格 [@problem_id:1938759]。这其中没有任何规律或原因。缺失的条目实际上是一次随机抽奖。

在这种情况下，完整案例的样本是原始群体的一个完美的、尽管规模较小的随机子样本。如果你使用 CCA，你对均值、关系和[回归系数](@entry_id:634860)的估计将是**无偏**的。也就是说，平均而言，它们会给你正确的答案。

但是这是有代价的。通过扔掉不完整的行，你丢弃了有价值的信息。如果一个病人的生命体征被记录下来，但由于 MCAR 事件而缺少一个实验室值，你也会丢弃他们的生命体征数据。这减少了你的总样本量，从而降低了你研究的**[统计功效](@entry_id:197129)**。你的结论会变得更“嘈杂”，[置信区间](@entry_id:138194)更宽，检测细微效应的能力也会减弱 [@problem_id:1938774]。

这种效率损失有多严重？我们可以量化它。在估计均值的简单情况下，如果一个变量有比例为 $\gamma$ 的数据缺失，与[多重插补](@entry_id:177416)等更复杂的方法相比，CCA 估计的方差（衡量[统计不确定性](@entry_id:267672)的指标）会增大。CCA 的[相对效率](@entry_id:165851)大约为 $1-\gamma$。这意味着如果你的数据有 30% 缺失（$\gamma=0.3$），CCA 的效率大约只有 $1 - 0.3 = 0.70$，即其可能达到的效率的 70%。如果 50% 缺失（$\gamma=0.5$），效率会降至区区 50% [@problem_id:1938739]。你基本上扔掉了一半的[统计功效](@entry_id:197129)，随之而去的可能还有一半的研究预算。

因此，在 MCAR 条件下，CCA 是有效但低效的。它给你一幅无偏但模糊的图像，而本来你有可能得到一幅更清晰的图像。

#### 欺骗性情况：[随机缺失](@entry_id:168632)（MAR）

现在情况变得更有趣了。如果缺失的概率*仅依赖于观测到的数据*，那么数据就是**[随机缺失](@entry_id:168632)（MAR）**。这个名字是出了名的令人困惑。它并*不*意味着数据是以真正随机的方式缺失。它意味着一旦我们考虑了所有我们*能*看到的信息，缺失的原因就是随机的。

想象一下医院的脓毒症治疗方案，只有当患者观测到的生命体征（$V$）异常时，才会开具乳酸检测（$L$）[@problem_id:4431038]。或者考虑一项调查，为了鼓励参与，向高收入人群（$Y$）提供一个省略了关于他们受教育年限（$X$）问题的较短版本 [@problem_id:1938759]。在这两种情况下，缺失的原因并非完全是个谜；它是由我们已经记录的其他数据点决定的。

在这里，完整案例分析的危险变得尖锐起来。“完整案例”的样本不再是整体的一个随机子样本。在脓毒症的例子中，“完整案例”（那些有乳酸值的人）根据定义是病情更重的患者。如果你用 CCA 来计算平均乳酸水平，你将是在一个系统性地比普通患者群体病情更重的群体中取平均。你对平均乳酸水平的估计将会有严重的向上偏差。在调查的例子中，使用 CCA 研究教育和收入之间的关系意味着你分析的是一个系统性地偏向于低收入个体的样本。这种[选择偏差](@entry_id:172119)会扭曲你试图测量的关系本身，导致你得出教育对收入的影响比实际更弱（或更强）的结论。

在 MAR 条件下，CCA 不再仅仅是低效的；它通常是**有偏且不正确**的。删除数据行的简单行为创造了一个歪曲的、如同哈哈镜般的现实版本。

#### 危险情况：[非随机缺失](@entry_id:163489)（MNAR）

这是最危险的情况。如果缺失的原因取决于未观测到的值本身，或取决于另一个未观测到的变量，那么数据就是**[非随机缺失](@entry_id:163489)（MNAR）**。它有时也被称为“不可忽略”的缺失，因为我们根本无法在不招致灾难的情况下忽略其机制。

考虑一个高通量实验，筛选细菌突变体的生长速率。测量仪器系统性地对生长最慢的突变体产生故障并生成缺失值 [@problem_id:1437165]。如果分析师应用 CCA，他们将恰好丢弃最令人感兴趣的突变体——那些适应性低的突变体。他们最终的数据集将只包含相对健康的突变体，从而得出基因删除几乎没有影响的极其错误的结论。该分析将对其自身最重要的发现视而不见。

或者想象一项认知研究，测量受试者在口语测试（$D_V$）上的进步。由于软件故障，口语进步分数较低的受试者的完整记录被保存的概率会降低 [@problem_id:1921634]。对完整案例的分析将存在系统性偏差，使得训练项目看起来比实际更有效，因为它优先保留了高成就者的数据。在这样一个假设情景中，这种机制被证明会产生一个数据集，其中估计的平均口语进步被高估了 1.5 分——这是一个完全源于数据删除过程的巨大偏差。

有时 MNAR 机制极其微妙。在一项比较三种疗法的临床试验中，某个站点的排班错误可能意味着所有下午的测量数据都丢失了。如果结果存在自然的[昼夜节律](@entry_id:153946)——比如说，下午的血压更高——而一天中的时间信息没有记录在最终数据集中，那么情况就是 MNAR [@problem_id:4821638]。该治疗组的完整案例将只包含早上的测量数据，这些数据系统性地偏低。使用 CCA 的分析师会将这个组的“仅早上”结果与其他组的“早上和下午”混合结果进行比较。他们将是在比较苹果和橙子，他们发现的任何差异都可能是[缺失数据](@entry_id:271026)的产物，而不是真正的治疗效果。该分析将从根本上无效，可能导致关于医疗方法的危险结论。

### 删除的涟漪效应

CCA 的问题不仅限于简单的平均值。它们会向外扩散，影响更复杂的[统计模型](@entry_id:755400)。

当我们为多个变量估计一个**[相关矩阵](@entry_id:262631)**时，我们面临一个选择。我们可以使用[列表删除法](@entry_id:637836)，它提供了一个干净、内部一致的[相关矩阵](@entry_id:262631)，因为它是基于一个单一的、共享的受试者群体计算的。正如我们所见，其缺点是可能导致大量数据丢失和偏差。

另一种选择是**成对删除法**，即对每对变量，我们使用所有拥有*该特定对*数据的受试者。这使用了更多的数据，看起来不错。然而，它可能导致一个奇怪且令人不安的结果：最终的矩阵是根据不同子群逐片拼凑而成的，可能根本不是一个有效的[相关矩阵](@entry_id:262631)。它可能在数学上变得不连贯，或“非正定”[@problem_id:4906015]。这就像用三把不同的、扭曲的尺子测量一个三角形的三条边；你最终可能得到的边长 $a、b \text{ 和 } c$ 满足 $a + b  c$，这是不可能的。

这揭示了完整案例分析的一个微妙优点：虽然它可能有偏且低效，但其结果至少是内部一致的。然而，为了得到一个精确但错误的答案而冒风险，这种整洁性很少是值得的。理解数据缺失原因的原理是任何诚实数据分析中第一步，也是最关键的一步。事实证明，删除这条简单的路径往往是最危险的。

