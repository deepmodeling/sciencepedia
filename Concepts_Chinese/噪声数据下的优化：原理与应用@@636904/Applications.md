## 应用与跨学科联系

在了解了充满噪声的世界中优化的原理之后，您可能会想：这套数学理论和算法虽然精妙，但它在现实世界中究竟有何用武之地？它在何处改变我们看待世界或创造新事物的方式？事实证明，一旦你学会将世界看作一个被不确定性迷雾所遮蔽的可能性景观，你就会开始*处处*看到这个问题。我们讨论过的方法不仅仅是抽象的工具；它们是让科学家和工程师能够透过迷雾、做出明智选择的眼镜。

让我们来参观其中一些地方。你会看到，同样的基本思想一次又一次地出现，只是穿着不同学科的服装，这是科学思想统一性的一个美丽例证。

### [数字孪生](@entry_id:171650)：校准我们的现实模型

科学的伟大事业之一是建立世界的数学模型——一个物理系统的“[数字孪生](@entry_id:171650)”。我们写下我们认为支配着一切的方程，从活细胞中的[化学反应](@entry_id:146973)到桥梁在负载下的行为。但这些模型充满了我们不知道其值的参数——[速率常数](@entry_id:196199)、材料属性等等。我们必须从实验中推断它们，但实验总是充满噪声。

想象一下你是一位系统生物学家，试图理解细胞中的一个信号通路 ([@problem_id:3272097])。你的模型是一组描述蛋白质如何相互作用的常微分方程（ODE），但动力学速率（$k_{\text{act}}$、$k_{\text{deact}}$ 等）是未知的。你进行实验并测量最终产物随时间变化的浓度，但你的仪器不完美，细胞本身也有一些变异性。你的数据点并不完美地落在模型预测的任何一条曲线上。那么，动力学速率的真实值是什么？

你可以将此构建为一个[优化问题](@entry_id:266749)：找到一组参数 $\theta$，使得模型的预测与你的噪声数据之间的平[方差](@entry_id:200758)最小。但这里有个问题：要计算这个差值，对于每一个猜测的 $\theta$，你都必须数值求解 ODE！[目标函数](@entry_id:267263)本身就涉及复杂的计算。“先离散化后优化”策略是解决这个问题的一个强大方法。你用离散的[数值近似](@entry_id:161970)（例如，使用[龙格-库塔法](@entry_id:140014)）代替连续的 ODE，然后使用[基于梯度的优化](@entry_id:169228)器找到最佳参数。当你面对一个复杂的计算机模拟函数时，如何获得梯度呢？像[自动微分](@entry_id:144512)（AD）这样的现代奇迹允许计算机“对代码本身进行[微分](@entry_id:158718)”，为你提供导航参数景观所需的精确梯度，即使原始数据中存在噪声。

当机械工程师试图描述一种新材料在应力下如何产生内部损伤时，也适用完全相同的原则 ([@problem_id:2912568])。实验的应力-应变数据是有噪声的，原始数据甚至可能看似违反物理定律，例如损伤只能随时间增加的定律。通过建立一个[优化问题](@entry_id:266749)，该问题在满足[热力学](@entry_id:141121)施加的约束（如损伤不减少）的*前提下*最小化与数据的误差，我们可以找到一个能够看透噪声、具有物理意义的模型。这个过程，有时被称为保序回归（isotonic regression），将一团凌乱、非单调的数据点云变成一个清晰、物理上合理且单调的函数。

有趣的是，甚至在进行实验之前，我们通常就可以预测哪些参数最难确定。使用一种称为[全局敏感性分析](@entry_id:171355)（GSA）的技术，我们可以探索模型的输出对每个参数的敏感程度 ([@problem_id:1436442])。如果某个参数在很大范围内摆动时，输出几乎没有变化（即，它的 Sobol 指数很低），这告诉我们来自该参数的“数据信号”非常微弱。当我们后来试图从噪声测量中估计它时，就像试图在嘈杂的房间里听到耳语。该参数注定会有一个大的置信区间——我们的模型提前告诉我们不确定性的迷雾将在哪里最浓！

### 看见之术：从不完美数据中重建信号

在许多领域，我们的挑战不是找到几个参数，而是从既不完整又有噪声的测量中重建整个信号或图像。想象一位[地球物理学](@entry_id:147342)家试图绘制地下岩层，或一位医生试图通过 CT 扫描看到器官 ([@problem_id:1612136])。

假设我们的信号是一个向量 $x$，我们的测量设备给出一个向量 $y = Ax + \epsilon$，其中 $A$ 是我们的测量矩阵，$\epsilon$ 是噪声。通常，我们的测量次数远少于我们想要重建的像素数（$M \ll N$），所以问题似乎不可能解决。这就像试图从几个字母重建整个段落一样。

关键在于我们通常对我们正在寻找的信号的*结构*有一些先验知识。地质剖面不是随机的静电噪声；它是由不同、均匀的层组成的。这意味着它是“分段常数”的。虽然信号 $x$ 本身不是稀疏的，但它的梯度（相邻值之间的差异）非常稀疏——它在除了层与层之间边界外的任何地方都为零。

我们可以将这种知识编码到我们的[优化问题](@entry_id:266749)中。我们建立一场拉锯战。一边是“数据保真度”项，如 $\|Ax - y\|_2^2$，它将我们的解 $x$ 拉向与噪声测量一致。另一边是“正则化”项，如 $\lambda \|Dx\|_1$，它将我们的解拉向具有稀疏梯度的方向。这里，$D$ 是差分矩阵，而 $\ell_1$-范数是一个神奇的[凸函数](@entry_id:143075)，可以促进稀疏性。参数 $\lambda$ 控制这种拉力的强度。通过最小化这两项的和，我们找到了一个 $x$，它是一个美丽的折衷：它尊重我们的噪声数据，同时尊重我们期望看到的底层结构。这个通用思想，被称为[全变分最小化](@entry_id:756069)，使我们能够从看似无望的不足和噪声数据中变出一个清晰、结构化的图像。

这个概念可以扩展到更抽象的“图像”。考虑一个数据矩阵 $D$，可能代表一个安全视频的帧。我们可能相信这个数据是一个简单的低秩背景 $L$（静态场景）和一个稀疏的移动前景 $S$（一个走过的人）之和，所有这些都被一点密集的相机噪声所污染 ([@problem_id:3130460])。[鲁棒主成分分析](@entry_id:754394)（RPCA）问题通过求解如下[优化问题](@entry_id:266749)来分解数据：
$$ \min_{L, S} \|L\|_{*} + \lambda \|S\|_{1} $$
约束条件是 $L+S$ 接近我们的数据 $D$。在这里，[核范数](@entry_id:195543) $\|L\|_{*}$ 鼓励 $L$ 是低秩的，而 $\ell_1$-范数 $\|S\|_{1}$ 鼓励 $S$ 是稀疏的。这和之前的原理一样，只是选择了不同的范数来促进不同类型的结构，从而精美地解开了背景、前景和噪声。

### 智能实验者：自动化科学发现

也许这些思想最具革命性的应用来自一种[范式](@entry_id:161181)转变。与其被动地分析一组固定的噪声数据，如果我们能够主动决定下一步进行哪个实验，以便尽可能高效地学习，会怎么样？这就是[贝叶斯优化](@entry_id:175791)的世界，它正在改变实验科学。

典型的例子是调整机器学习模型的超参数 ([@problem_id:3147965])。找到最佳的[学习率](@entry_id:140210)、正则化强度或[网络深度](@entry_id:635360)是一个黑箱问题。任何超参数的选择都会给出一个验证分数，但由于随机的数据分割或[权重初始化](@entry_id:636952)，这个分数是有噪声的。每次评估都很昂贵，因为它需要训练一个完整的模型。[网格搜索](@entry_id:636526)是不可行的。这正是[贝叶斯优化](@entry_id:175791)的完美应用场景。我们从几个随机猜测开始，然后建立一个“性能景观”的概率代理模型（通常是高斯过程）。这个模型不仅给出新点的性能预测；它还给出*不确定性*。然后，[采集函数](@entry_id:168889)（如[期望提升](@entry_id:749168)）利用这一点来决定下一步在哪里采样，巧妙地平衡*利用*（去模型认为好的地方）和*探索*（去模型非常不确定的地方）。这使我们能够用非常少的昂贵训练次数找到优秀的超参数。

同样的逻辑也适用于我们是调整算法还是寻找新的物理对象。寻找具有最大[屈服强度](@entry_id:162154)的新型[高熵合金](@entry_id:141320) ([@problem_id:2475313])、优化用于生长[类器官](@entry_id:153002)的复杂生物协议 ([@problem_id:2622457])，甚至是自动化设计[神经网络架构](@entry_id:637524) ([@problem_id:3104287])，这些从根本上说都是同一个问题。我们正在优化的“函数”是材料的强度、类器官的质量或网络的准确性。“评估”是一次计算密集型的模拟或一次耗时数月的昂贵实验室实验。在所有这些情况下，实验的预算与搜索空间的浩瀚相比微不足道。[贝叶斯优化](@entry_id:175791)利用其迄今所学到的[统计模型](@entry_id:165873)来智能地导航这个空间的能力，代表了一种新的科学方法——一个智能的、自动化的实验者。

### 元视角：优化优化器本身

现在我们来看最后一个，有点令人费解的转折。我们能用这些思想来优化优化过程本身吗？答案是肯定的。

考虑强化学习中的一个标准算法，其中代理通过试错来学习。这通常涉及朝着一个告诉它如何改进其策略的“梯度”方向移动。但在复杂场景中，这个梯度只能被估计，而且估计值噪声很大。基于这种噪声梯度采取步骤会使学习过程缓慢且不稳定。

如果我们把*真实的、底层的梯度函数*当作一个我们试图学习的未知的[黑箱函数](@entry_id:163083)呢？我们可以使用我们的噪声[梯度估计](@entry_id:164549)作为数据点，并对它们拟合一个高斯过程 ([@problem_id:3122901])。现在，在每一步，我们不再使用最新的噪声梯度，而是可以使用 GP 的[后验均值](@entry_id:173826)——它在整合了所有过去信息后对真实梯度的最佳估计。这平滑了学习过程。但我们还可以更进一步！GP 还告诉我们它对[梯度估计](@entry_id:164549)的不确定性。在它非常不确定的区域，也许我们应该采取更小、更谨慎的步骤。我们可以使用 GP 的预测[方差](@entry_id:200758)来动态地自动调整我们的[学习率](@entry_id:140210)。

这是一个美丽的递归思想。我们正在使用一个复杂的[统计模型](@entry_id:165873)来“[去噪](@entry_id:165626)”并指导另一个学习过程。它表明，处理噪声和不确定性的原则不仅适用于分析一个静态的世界，也适用于构建更鲁棒、更智能的学习系统，这些系统能够自我适应和改进。从校准细胞模型到发现新材料，再到甚至改进算法的学习方式，面对噪声做出明智决策的挑战是贯穿所有现代科学和技术的一条深刻而统一的线索。