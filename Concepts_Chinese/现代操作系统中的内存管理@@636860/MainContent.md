## 引言
内存管理是现代[操作系统](@entry_id:752937)最关键、最巧妙的职责之一。在计算的早期，程序直接访问物理内存——这是一种混乱且不安全的方法，使得多任务处理几乎不可能。为了建立秩序并实现我们今天所依赖的复杂软件生态系统，[操作系统](@entry_id:752937)开发了一种强大的抽象：虚拟内存。这一基本概念创造了一个复杂的假象，为每个程序提供了自己的私有、巨大且安全的内存空间，同时高效、安全地管理有限的物理硬件。

本文将逐层揭开这一假象的面纱。它解决了如何在多个竞争程序之间安全、高效地共享有限物理内存这一根本问题。读完本文，您将理解使现代计算成为可能的硬件和软件之间错综复杂的协作。第一章 **“原理与机制”** 将揭开[虚拟内存](@entry_id:177532)核心组件的神秘面纱，包括分页、页表以及使其快速运行的硬件。随后的 **“应用与跨学科联系”** 章节将探讨如何利用这些基础思想来构建一切，从高效的[共享库](@entry_id:754739)和安全系统，到高性能应用程序，乃至虚拟化等更高级别的抽象。

## 原理与机制

要欣赏现代[内存管理](@entry_id:636637)的精妙之处，我们必须首先想象一个没有它的世界。想象一下，计算机的物理内存是一片广阔、开放的田野。几个程序，就像精力充沛的孩子，被告知去里面玩耍。没有规则，混乱随之而来。一个程序可能会意外地涂抹掉另一个程序的成果。一个恶意的程序可能会窥探另一个程序的秘密。如果一个程序非常大，它甚至可能一开始就无法容纳在这片田野里。这就是计算的早期状态——一个数字世界的“西部荒野”。[操作系统](@entry_id:752937)需要成为警长，为这片内存地带带来法律和秩序。它们设计的解决方案不仅仅是一个聪明的技巧，而是一种深刻而美丽的假象，称为**虚拟内存**。

### 宏大的假象：虚拟地址和[页表](@entry_id:753080)

其核心思想简单但具有革命性：停止让程序看到真实的物理内存。相反，给每个程序自己私有的、纯净的、巨大的活动空间。这个私有空间就是它的**[虚拟地址空间](@entry_id:756510)**。在现代64位系统上，这个空间是巨大的——$2^{64}$字节，比有史以来任何物理内存都要大数百万倍。从程序的角度来看，它拥有整个宇宙，从地址0开始，一直到一个天文数字。它可以在这里放置代码，在那里放置数据，在别处放置堆栈，完全不用担心与任何人发生冲突。

当[操作系统](@entry_id:752937)只有有限的物理内存时，它如何为每个程序创造这种假象呢？它通过一种称为**分页**的机制来实现。[操作系统](@entry_id:752937)和硬件协同工作，完成以下任务：它们将程序广阔的[虚拟地址空间](@entry_id:756510)分割成固定大小的块，通常是$4$ KiB，称为**页（page）**。它们对物理内存也做同样的事情，创建同样大小的块，称为**帧（frame）**。整个游戏的关键，就是将程序的虚拟页映射到可用的物理帧上。

当一个程序想要访问一个内存位置，比如 `0x12345678` 时，硬件不会直接使用该地址。它会将其分成两部分：一个**虚拟页号（VPN）**和一个**页内偏移（page offset）**。对于一个$4$ KiB（$2^{12}$字节）的页大小，较低的$12$位是偏移量——它们告诉我们字节在页内的*位置*。较高的位构成VPN——它们告诉我们程序想要*哪个*页。这样做的好处是偏移量是神圣的，它保持不变。硬件的唯一工作就是将虚拟页号转换为一个物理*帧*号。一旦找到正确的帧，它只需附加上原始的偏移量，即可得到最终的物理地址。

但是这些转换存储在哪里呢？在一个由[操作系统](@entry_id:752937)管理的特殊[数据结构](@entry_id:262134)中，称为**[页表](@entry_id:753080)（page table）**。可以把它想象成一本书的巨大索引。VPN是你查找的章节号，而该条目中的内容告诉你该章节从哪个物理页（帧）开始。这个表中的每个条目都是一个**[页表项](@entry_id:753081)（[PTE](@entry_id:753081)）**。

然而，一个PTE包含的不仅仅是转换信息。它是[操作系统](@entry_id:752937)控制和保护机制的核心。为了理解这一点，让我们看看一个典型的PTE内部[@problem_id:3622983]。为了在一个拥有例如$2^{20}$个帧（4GB [RAM](@entry_id:173159)，4KB页）的系统中映射到任何物理帧，PTE至少需要$20$位来存储**物理帧号（PFN）**。但真正的威力来自于一些额外的**控制位**。一个**存在位（Present bit）**表示这个页是否真的在物理内存中，还是当前“休眠”在磁盘上。一个**读/写位（Read/Write bit）**控制该页是否可以被修改。

最重要的是，有一个**用户/超级用户（U/S）位**。这一个比特位就是警长的徽章。它将整个内存世界分为两个[特权级别](@entry_id:753757)：用于[操作系统内核](@entry_id:752950)（超级用户）的页和用于普通程序（用户）的页。硬件——特别是执行[地址转换](@entry_id:746280)的芯片**[内存管理单元](@entry_id:751868)（MMU）**——会毫不留情地执行这条规则。想象一个用户程序试图访问一个虚拟地址，该地址被[操作系统](@entry_id:752937)映射到一个内核页，其U/S位被设置为`0`（仅限超级用户）。MMU在转换地址的过程中，会检查该位，发现违规，并立即发出警报。它会停止这次访问并触发一个“保护错误”，将控制权交给[操作系统](@entry_id:752937)。然后[操作系统](@entry_id:752937)可以终止这个行为不当的程序[@problem_id:3622985]。这就是[操作系统](@entry_id:752937)保护自身和其他程序免受窥探或损坏的方式——不是通过缓慢的软件检查，而是通过硬件闪电般的权威。

### 让它变快：缓存和局部性的艺术

我们有了一个用于转换和保护内存的优美系统。但是我们引入了一个可怕的新问题。[页表](@entry_id:753080)本身位于物理内存中。这意味着，要访问单个字节的数据，MMU首先必须从内存中读取正确的PTE，*然后*使用该信息来读取实际数据。我们刚刚使内存访问次数翻倍！这将使我们的计算机运行速度减半，这是一个完全无法接受的代价。

解决方案来自于一个关于程序行为的深刻而奇妙的真理：**局部性原理**。程序是习惯的生物。如果一个程序访问了一个内存位置，它很可能很快会再次访问它（**[时间局部性](@entry_id:755846)**）。如果它访问了一个内存位置，它很可能很快会访问附近的其他位置（**[空间局部性](@entry_id:637083)**）。

为了利用这一点，硬件设计者在MMU内部增加了一个小而极快的缓存，称为**转译后备缓冲器（TLB）**。TLB是一个微小的、专属的内存，存储了少量最近使用的VPN到PFN的转换。在去主存读取[PTE](@entry_id:753081)的长途跋涉之前，MMU首先检查TLB。如果转换在那里（**TLB命中**），它几乎可以立即获得PFN，整个过程就很快。如果不在那里（**TLB未命中**），MMU就必须进行缓慢的[页表遍历](@entry_id:753086)，但它会明智地在返回时将结果缓存到TLB中，希望很快会再次需要它。

你可能会认为，一个微小的TLB——也许只有64或128个条目——在一个程序使用数千个页面的情况下会毫无用处。但这就是局部性发挥其魔力的地方。由于空间局部性，一个程序通常会花费大量时间在*同一个*页面内进行多次访问。想想遍历一个数组。所有这些访问都共享相同的VPN。第一次访问可能会导致TLB未命中，但接下来对同一页面的数千次访问都将是极快的TLB命中[@problem_id:3622957]。一个行为良好、将其工作集中在一小组“工作集”页面中的程序，可以实现超过$99\%$的TLB命中率。

我们能否构建一个足够大的TLB来容纳*所有*可能的转换，并保证每次都命中呢？让我们考虑一个现代64位系统，使用$4$ KiB的页面。虚拟页的数量是一个惊人的$2^{64} / 2^{12} = 2^{52}$。构建一个拥有$2^{52}$个条目的缓存不仅昂贵，而且以当前的技术在物理上是不可能的。它将是天文数字般的大、慢和耗电[@problem_id:3620238]。TLB是工程权衡的一个完美例子：我们接受极小的概率发生一次缓慢的未命中，以换取几乎可以肯定会发生的快速命中，这一切都归功于我们程序的可预测性。

### 使其可扩展：驯服巨大的页表

TLB解决了速度问题，但[64位地址空间](@entry_id:746175)的巨大规模又带来了另一个危机：[页表](@entry_id:753080)本身的大小。如果一个单一的页表为$2^{52}$个虚拟页中的每一个都有一个条目，并且每个条目是$8$字节，那么一个*单一进程*的页表就需要$8 \times 2^{52}$字节的内存。那是32 PB（petabytes）！这是一个荒谬的浪费空间，特别是因为大多数程序只使用其广阔[虚拟地址空间](@entry_id:756510)的一小部分。

优雅的解决方案是让页表本身成为一棵树。这被称为**[多级页表](@entry_id:752292)**。我们不再使用一个巨大的线性表，而是使用多个级别的较小表。在典型的x86-64架构上，这是一个4级树。虚拟地址现在被分割成几个部分[@problem_id:3620218]。最高几位索第一级表。那里的[PTE](@entry_id:753081)不指向数据帧，而是指向一个第二级的[页表](@entry_id:753080)。虚拟地址的下一组位索引该表，该表指向一个第三级的表，以此类推。经过对这棵树的4步“遍历”后，我们最终到达一个叶子PTE，它为我们提供了我们正在寻找的PFN。

这种设计的精妙之处在于，我们只需要为程序实际使用的地址区域创建树的部分。如果一个程序只在低地址使用几个页面，在高地址使用几个页面，我们只需要在每个级别分配几个小的页表来将根连接到那些叶子。[虚拟地址空间](@entry_id:756510)中广阔的、空洞的区域对应于上层[页表](@entry_id:753080)中的`null`指针，完全不消耗内存。

这种层次结构引入了其自身的权衡。我们映射的粒度是页大小。如果一个程序请求一小块内存，比如1000字节，[操作系统](@entry_id:752937)必须给它一整页（例如4096字节）。未使用的$3096$字节是浪费的空间，这种现象被称为**[内部碎片](@entry_id:637905)**。更大的页大小会使这个问题更严重[@problem_id:3620262]。然而，对于大型、连续的[内存分配](@entry_id:634722)（比如视频帧缓冲区或大型数据库缓存），使用小的$4$ KiB页面效率也很低。映射一个256 MiB的段将需要超过65,000个[PTE](@entry_id:753081)，仅[页表结构](@entry_id:753084)就会消耗数百KB。为了解决这个问题，现代系统支持**大页**。页表树中更高一级的单个PTE可以被标记为叶子，直接映射一个大的2 MiB甚至1 GiB的内存块。这极大地减少了所需的页表数量，并使得该大区域的转换更有可能被缓存在单个TLB条目中，从而提高性能[@problem_id:3684845]。

### 按需的世界：虚拟内存最伟大的技巧

到目前为止，我们已经构建了一个受保护、快速且可扩展的内存系统。但它最强大的力量在于最后一个原则：**按需[分页](@entry_id:753087)**。[操作系统](@entry_id:752937)不需要在程序启动时就将其所有页面从磁盘加载到内存中。相反，它可以很“懒惰”。它设置好[页表](@entry_id:753080)，但将所有[PTE](@entry_id:753081)的“存在”位关闭。当程序第一次尝试访问一个页面时，MMU看到存在位为`0`，并触发一个**页错误**。

这不是一个错误。这是一个中断，告诉[操作系统](@entry_id:752937)：“程序需要这个页面。请去磁盘上找到它，将它加载到一个空闲的帧中，更新[PTE](@entry_id:753081)以标记它为存在，然后恢复程序。”这种按需加载意味着程序几乎可以立即启动，其内存占用仅随着它实际接触其代码和数据的不同部分而增长。

这个简单的机制催生了现代[操作系统](@entry_id:752937)中一些最强大的功能。
其中最绝妙的一个是**[写时复制](@entry_id:636568)（COW）**。当一个进程创建子进程（一个`[fork()](@entry_id:749516)`操作）时，[操作系统](@entry_id:752937)不需要费力地为子进程复制父进程的所有内存。这样做非常缓慢且浪费，特别是如果子进程只打算做少量修改。相反，[操作系统](@entry_id:752937)只是为子进程复制父进程的[页表](@entry_id:753080)，并关键性地将两个进程中的所有PTE标记为只读。父进程和子进程现在共享所有相同的物理内存帧。如果任一进程试图*写*入一个页面，就会发生保护错误。[操作系统](@entry_id:752937)此时介入，为进行写入的进程制作该单个页面的私有副本，更新其[PTE](@entry_id:753081)指向这个具有写权限的新副本，然后让它继续。所有其他页面仍然是共享的。这个简单的技巧可以使进程创建速度快上几个[数量级](@entry_id:264888)，并允许系统支持更多的进程，从而极大地提高吞吐量[@problem_id:3629096]。

按需分页还通过**[内存映射](@entry_id:175224)文件**（`mmap`）统一了文件I/O和内存管理。程序可以请求[操作系统](@entry_id:752937)将磁盘上的文件直接映射到其[虚拟地址空间](@entry_id:756510)。从该内存地址读取会导致页错误，[操作系统](@entry_id:752937)会自动将文件的相应块加载到一个帧中。向该内存写入会“弄脏”该页，[操作系统](@entry_id:752937)稍后会自动将其[写回](@entry_id:756770)文件。使用`MAP_SHARED`映射，这些写入对其他进程可见，并会被写回文件。使用`MAP_PRIVATE`映射，[操作系统](@entry_id:752937)使用[写时复制](@entry_id:636568)，因此任何修改都发生在一个私有的内存副本上，永远不会影响原始文件[@problem_id:3663191]。这将文件访问变成了简单的内存读写，是一种极其优雅和高效的抽象。

### 当假象破灭时：颠簸

[虚拟内存](@entry_id:177532)的假象很强大，但它也可能被打破。因为[操作系统](@entry_id:752937)可以将数据分页到磁盘，它可以向其运行的进程承诺比物理上拥有的更多的内存。这被称为**内存超售（overcommitment）**。只要所有进程活跃需要的页面总集——它们的组合**[工作集](@entry_id:756753)**——能容纳在可用的物理帧内，这种方式就能完美工作。

但当它无法容纳时会发生什么？系统会进入一种被称为**颠簸（thrashing）**的死亡螺旋[@problem_id:3688385]。想象一个进程需要页面A，但所有帧都满了。[操作系统](@entry_id:752937)选择一个牺牲品，比如页面B，并将其写入磁盘为A腾出空间。但紧接着下一条指令，进程又需要页面B！于是[操作系统](@entry_id:752937)必须驱逐另一个页面，也许是C，以换回B。然后进程又需要C。系统所有的时间都花在内存和磁盘之间疯狂地交换页面上，这个过程称为**换页**。CPU处于空闲状态，磁盘指示灯常亮，计算机运行停滞。页错误率飙升至接近$100\%$，没有任何有用的工作被完成。即使是最聪明的[页面置换算法](@entry_id:753077)（如[最近最少使用](@entry_id:751225)）也无法在内存需求从根本上超过供应时将系统从颠簸中拯救出来。这是一个严酷的提醒，虽然[虚拟内存](@entry_id:177532)提供了无限空间的宏伟假象，但它最终受制于物理现实的法则。

