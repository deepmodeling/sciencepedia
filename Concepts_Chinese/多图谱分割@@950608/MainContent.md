## 引言
在复杂的医学扫描中自动识别解剖结构是现代量化诊断的基石。虽然计算机可以尝试学习抽象规则，但一个更强大的方法是从样本中学习。然而，依赖单一的解剖蓝图——即单个图谱——充满了风险，因为一个个体的解剖结构可能无法代表所有人。这种脆弱性凸显了一个关键的缺口：我们如何才能构建一个对人类解剖结构巨大多样性具有鲁棒性、准确性和适应性的分割系统？

本文探讨了由多图谱分割提供的优雅解决方案。我们将从使用多个解剖图谱的基本概念，走向驱动现代实现的复杂统计框架。第一部分“原理与机制”将剖析其核心方法，从将图谱库配准到新的扫描图像，到关键的标签融合步骤，即如何将多个相互冲突的提议组合成一个单一、可靠的共识。随后，“应用与跨学科联系”部分将展示该方法在 PET/MRI 等具有挑战性的临床环境中的影响，并探索其与人工智能、工程学和生物统计学的联系。让我们从理解那些让我们能够利用群体智慧进行解剖学绘图的基本原理开始。

## 原理与机制

想象一下放射科医生或渴望辅助他们的计算机程序所面临的挑战：观察人体的三维扫描图像——一个由灰度像素构成的复杂单色世界，并精确地勾画出像肝脏这样的器官。这不仅仅是找到一个特定亮度的斑点。肝脏有其特有的形状、位置以及与邻近器官的关系。但这种形状和位置在每个人身上都存在细微的差异。我们究竟如何才能教会计算机“肝脏”这个抽象的*概念*？

答案，在于解剖学与数学的优美融合：从样本中学习。这是多图谱分割背后的指导哲学。我们不试图用抽象规则来定义肝脏，而是向计算机展示一个由专家标注的人体图谱库，并教它如何智能地将这些知识迁移到一个新的、未标注的扫描图像上。

### 解剖图谱制作的艺术

我们方法的核心是**图谱**（atlas）。一个图谱不仅仅是一张参考图像；它是一幅 meticulously 详细的解剖地图，专家已在其中描绘出重要结构的边界，为图像中的每个点或**体素**（voxel）分配了特定的标签。[@problem_id:4550534] 你可以把它看作是某个人解剖结构的完美主蓝图。

现在，假设我们有一个希望进行分割的新扫描图像——我们的目标图像。最简单的策略，即**单图谱分割**，是拿来我们唯一的这份主蓝图，并将其叠加到新的扫描图像上。当然，新的人会有不同的尺寸和形状，所以我们不能只是简单地把地图铺在上面。我们需要找到一个空间变换——一个数学函数，我们称之为$\phi$——它能扭曲、拉伸和弯曲我们的图谱，直到它与目标扫描图像中的解剖结构对齐。这个对齐过程被称为**图像配准**。一旦我们找到了最佳的变换$\phi$，我们只需将其应用于我们图谱的标签，瞧，我们就得到了目标图像的分割结果。

但这种方法是脆弱的。如果我们唯一的图谱来自一个肝脏形状异常的人怎么办？或者，如果配准算法（通常通过使两幅图像中的灰度模式看起来尽可能相似来工作）出错了怎么办？结果将是一个有缺陷的分割，它继承了我们单一图谱的所有偏见和配准的所有错误。[@problem_id:4550534] 这就像试图用旧金山的地图在纽约导航；虽然一些街道模式可能偶然对得上，但你肯定会迷路。

### 群体的智慧

一个远为更强大的想法是拥抱多样性。**多图谱分割**不依赖单一、可能不具代表性的图谱，而是采用一整个图谱库，每个图谱都来自不同的个体。我们将库中的*每一个图谱*都配准到目标图像上。这给了我们不是一个，而是大量的分割提议。在目标图像的单个体素处，一个图谱可能投票“肝脏”，另一个可能投票“肾脏”，而其他几个可能都同意“肝脏”。

这就引出了下一个关键步骤：**标签融合**。我们如何将这些多个、常常相互冲突的意见组合成一个单一、可靠的共识？

最简单的方法是民主投票。对于每个体素，我们分配得到已配准图谱集合中最多票数的标签。这就是**多数投票**。这种方法出奇地有效，因为来自单个配准的随机错误往往会相互抵消。

然而，我们可以做得更好。我们图谱库中的一些图谱在解剖学上自然会比其他图谱更接近我们的目标对象。给它们的投票赋予更高的权重似乎是明智的。这就是**加权投票**的原则。我们可以首先为每个图谱计算一个全局相似性分数（即配准后与目标图像的匹配程度），并为更相似的图谱分配更高的权重。

例如，假设我们有三个图谱，配准后，我们使用一个称为Dice系数的常用度量来衡量它们的质量，该系数范围从$0$（无重叠）到$1$（完美重叠）。假设Dice分数分别为$D_1=0.84$、$D_2=0.77$和$D_3=0.66$。我们可以决定用每个图谱Dice分数的平方来对其投票进行加权，这种方案会极大地奖励高质量的图谱。如果在某个特定体素上，图谱1和3投票“前景”（标签1），而图谱2投票“背景”（标签0），那么“前景”的加权投票结果就不是简单的2比1多数。相反，成为前景的概率将是前景投票者权重的总和（$0.84^2 + 0.66^2$）除以所有权重的总和（$0.84^2 + 0.77^2 + 0.66^2$）。这个计算得出的前景概率约为$0.6581$，这是一个比简单投票能提供的更细致的估计。[@problem_id:4550578]

### 概率视角：拥抱不确定性

当我们用概率的语言重新构建这个问题时，现代多图[谱方法](@entry_id:141737)的真正优雅之处便显现出来。我们不再仅仅考虑“投票”，而是开始思考“证据”和“信念”。

首先，我们可以将整个图谱库提炼成两个强大的构造。通过对齐所有图谱并在每个体素处平均它们的灰度值，我们可以创建一个**群体强度模板**——一个“模糊”但解剖学上平均的图像，代表了群体的典型外观。更深刻的是，通过统计所有对齐图谱在每个体素处的标签，我们可以构建一个**概率图谱**。这不是单一的地图，而是一组地图，每个解剖结构对应一张。每张地图在每一个体素处显示了找到该特定结构的概率。例如，在大脑皮层深处，灰质的概率可能是$0.99$，而在与白质的边界处，灰质的概率可能是$0.5$，白质的概率也可能是$0.5$，这优美地捕捉了解剖边界固有的不确定性。[@problem_id:4529205]

这个概率图谱是一个统计**先验**——我们对解剖结构可能位置的预设信念，它是从我们图谱库的集体智慧中锻造出来的。现在，我们可以使用科学中最强大的工具之一，[贝叶斯定理](@entry_id:151040)，将这个[先验信念](@entry_id:264565)与我们目标图像的实际证据结合起来。

$$
p(\text{label} \mid \text{image data}) \propto p(\text{image data} \mid \text{label}) \times p(\text{label})
$$

用通俗的话说，我们对一个体素标签的最终信念（**后验**）与给定该标签下观察到图像数据的似然度乘以我们对该标签的先验信念成正比。例如，对于一个强度值为$110$的体素，我们可以根据预先学习的每种组织类型的[统计模型](@entry_id:755400)，计算这个强度来自白质、灰质或脑脊液的似然度。然后，我们将这些似然度乘以我们在该特定位置对每种组织的先验概率。产生最高乘积的标签就是我们的最佳猜测。这个贝叶斯框架[@problem_id:4143473]使我们能够优雅地平衡来自新图像的证据与从图谱中提炼出的解剖知识。

我们甚至可以开发出同时学习“真实情况”和每个图谱可靠性的算法。**STAPLE**（Simultaneous Truth And Performance Level Estimation，真实情况与性能水平同步估计）算法正是这样做的。它通过一个迭代的期望-最大化过程进行操作——这是一场计算之舞。在第一步（期望），它根据图谱当前的可靠性估计，对真实分割做出最佳猜测。在第二步（最大化），它使用这个估计的“真实情况”来重新评估每个图谱的性能（敏感性和特异性）。这些新的性能指标随后被用来在下一轮中改进对真实分割的猜测。算法重复这个过程，直到收敛到一个稳定的、自洽的解决方案，此时共识分割和图谱性能估计达到和谐统一。[@problem_id:4550551]

### 现实世界是混乱的：挑战与改进

[医学影像](@entry_id:269649)的世界很少像我们理想化的模型那样干净。两大挑战威胁着任何基于图谱的方法的性能：域偏移和意外病理。

#### 苹果与橙子：域偏移问题

如果我们的图谱库是用GE扫描仪的图像创建的，而我们新的目标图像来自Siemens设备，会发生什么？即使是同一个人，生成的图像看起来也会不同。对比度、亮度和噪声特性都会改变。这被称为**域偏移**。[@problem_id:4529206]它违反了许多配准算法的一个基本假设：即相同组织在图谱和目标图像中应具有相同的强度。

对抗这个问题的一种方法是进行**强度归一化**。在尝试配准之前，我们可以应用变换来标准化所有图像的强度值。简单的**z-score归一化**（减去均值并除以标准差）可以校正基本的亮度和对比度偏移。更先进的方法，如**Nyul直方图标准化**，从一个训练集中学习一个共同的强度尺度，并将每个新图像的强度扭曲以匹配它，从而校正更复杂的非线性差异。[@problem_id:4529136]

一个更强大的想法是使用一种对这些强度偏移具有内在鲁棒性的“更智能”的相似性度量。与其测量强度值的原始差异（如欧几里得距离），我们可以使用**归一化[互相关](@entry_id:143353)（NCC）**。NCC不关心绝对亮度；它只关心强度的*模式*。例如，考虑一个目标图像块的强度为$[1, 2, 3]$。一个图谱图像块$[2, 4, 6]$是一个完美的[模式匹配](@entry_id:137990)，只是更亮。欧几里得距离会认为这是一个很大的误差。然而，NCC会识别出完美的线性关系，并报告一个完美的相似性分数$1$。相比之下，一个图谱图像块$[1, 2, 2]$在绝对值上更接近，但破坏了模式。NCC会正确地将其识别为一个较差的匹配。[@problem_id:4529203]通过关注局部模式，使用NCC的基于块的方法对域偏移的挑战具有更强的适应性。

#### 意外情况：处理病理

第二个，也是更深刻的挑战是病理。我们的图谱通常是基于健康受试者构建的。当我们试[图分割](@entry_id:152532)一个有大肿瘤的大脑，或者一个部分被手术切除的肝脏时，会发生什么？一个标准的基于图谱的方法，依赖于健康的先验知识，将会完全混淆。配准会试图将健康的图谱解剖结构强加到病理对象上，而先验知识会坚持认为肿瘤所在的位置应该是脑组织。这可能导致**标签幻觉**，即算法自信地分割出根本不存在的解剖结构。[@problem_id:4529201]

一个鲁棒的系统必须知道何时不信任自己的先验。有几种巧妙的方法可以实现这一点：

1.  **为未知建模：** 我们可以明确地在我们的模型中添加一个新的“病理”或“离群值”标签。这个标签被赋予一个非常灵活的[统计模型](@entry_id:755400)，使其能够解释任何不符合健康组织模型的奇怪强度值。这为算法提供了一个“逃生出口”，而不是强行给出一个不正确的解剖标签。[@problem-id:4529201]

2.  **自适应先验：** 我们可以使先验的强度$\lambda$在空间上自适应。在图像数据与图谱先验强烈矛盾的区域，算法可以自动降低$\lambda$，实际上是告诉自己：“这里的地图似乎是错的，我应该相信我在新扫描中看到的。”[@problem_id:4529201]

3.  **[量化不确定性](@entry_id:272064)：** 一个分割算法不仅应提供一个答案，还应提供对其答案的置信度估计。我们可以在每个体素处测量不确定性，例如，通过计算**后验熵**或查看不同图谱提出的概率的方差。[@problem_id:4529167] 图谱之间强烈[分歧](@entry_id:193119)或数据与先验冲突的区域将表现出高度不确定性。这张不确定性图谱非常宝贵，它突出了自动分割可能不可靠并需要人类专家复核的区域。[@problem_id:4529201]

### 从理论到实践

这整个过程，从将$K$个图谱配准到一个有$N$个体素的图像上，经过$T$次迭代，到融合结果，计算量都很大。总[时间复杂度](@entry_id:145062)大约与$O(KNT + KN)$成正比。[@problem_id:4529184] 考虑到这个成本，我们必须问，我们的方法是否不仅有效，而且有充分的理由。

在这里，我们发现了最后一点内在的美。流行的softmax加权方案，即对于相似度为$s_k$的图谱$k$，其权重由$w_k(\alpha) = \frac{\exp(\alpha s_k)}{\sum_{j} \exp(\alpha s_j)}$给出，这不仅仅是一个随意的公式。它可以从**最大熵原理**推导出来。这是与观察到的相似性分数一致的*最不偏不倚的权重分布*。参数$\alpha$控制我们对相似性的信任程度；随着$\alpha$的增加，权重会急剧集中在最佳匹配的图谱上。[@problem_id:4529193] 一个实际的工程选择能够植根于如此基本的信息论原理，这证明了该领域的深刻统一性。

从复制地图的简单想法开始，我们已经走到了一个复杂的、概率性的框架，它利用了群体的智慧，理解自身的不确定性，适应混乱的世界，并建立在优雅的理论基础之上。这就是多图谱分割的知识核心——一个强有力的证明，展示了先验知识和统计推断如何能够交织在一起，解决医学视觉领域中最具挑战性的一些问题。

