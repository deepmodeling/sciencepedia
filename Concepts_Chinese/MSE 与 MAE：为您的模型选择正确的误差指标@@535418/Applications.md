## 应用与跨学科联系

现在我们已经掌握了均方误差（MSE）和平均[绝对误差](@article_id:299802)（MAE）的数学特性，我们可以踏上一段旅程，去看看它们在实践中的表现。对物理学家来说，一个想法的真正考验不在于其抽象的优雅，而在于其描述世界的力量。这些衡量误差的不同方式会把我们引向何方？我们会发现，选择对误差进行平方还是取其[绝对值](@article_id:308102)，不仅仅是一个技术细节；它是一个关乎我们在模型中看重什么、我们对所测量的世界抱有何种信念，以及我们愿意犯下何种错误的深刻选择。从某种意义上说，这是一种哲学上的选择。

### [离群值](@article_id:351978)的暴政

想象一下，你正在为一个大型场馆管理安保工作，有两个相互竞争的AI系统用于在照片中清点人群。在一个典型的、人群稀少的日子里，你用10个不同的场景来测试它们。
-   **模型Q** 在每个场景中都稳定地偏差10人。虽不完美，但很可靠。
-   **模型P** 表现出奇地准确，在9个场景中仅偏差5人。但在其中一张人群非常密集的照片中，它犯下了一个巨大的错误，少计了50人。

哪个模型更好？回答这个问题迫使我们决定“更好”意味着什么。让我们来问问我们的两位朋友，MAE和MSE（或其更具直接可比性的平方根RMSE）。

平均绝对误差只是简单地平均了错误的大小。对于模型Q，MAE显然是10。对于模型P，它是 $\frac{9 \times 5 + 1 \times 50}{10} = 9.5$。根据这个指标，模型P更优越；它的那一次大失误被其在另外九个场景中的出色表现所抵消。

现在让我们来咨询均方根误差。对于模型Q，RMSE是 $\sqrt{\frac{10 \times 10^2}{10}} = 10$。对于模型P，它是 $\sqrt{\frac{9 \times 5^2 + 1 \times 50^2}{10}} = \sqrt{272.5} \approx 16.5$。突然之间，模型Q看起来好多了！发生了什么？MSE通过对误差进行平方，极大地加重了模型P那一次大错误的权重。50的误差比5的误差大10倍，但它对平方和的贡献（$50^2=2500$ vs $5^2=25$）却大了*100倍*。MSE对大误差有着根深蒂固的憎恨，它会对任何产生大误差的模型做出严厉的评判[@problem_id:3168872]。

当我们使用这些指标来*训练*模型时，这种敏感性会产生深远的影响。一个以最小化MSE为目标进行训练的模型，其行为会像一个拼命取悦一位非常苛刻的批评家的人。如果训练数据包含一个“[离群值](@article_id:351978)”——一个远离总体趋势的点，可能是由于测量错误或罕见事件——由MSE驱动的模型会扭曲自己以减小那一个巨大的平方误差，即使这意味着牺牲其对所有其他“行为良好”数据点的拟合度。

考虑一个简单的物理系统，比如一个[压力传感器](@article_id:377347)，其输出电压应与压力成正比[@problem_id:1595348]。我们收集了数据，但其中一次测量是错误的，产生了一个[离群值](@article_id:351978)。一个旨在[最小化平方误差](@article_id:313877)和（$L_2$损失）的模型会被这一个点带偏，就像一只被拴着的狗猛扑向一只松鼠。最终得到的直线歪曲了真实的物理关系。然而，一个旨在最小化绝对误差和（$L_1$损失）的模型则要坚定得多。它根据数据趋势的*中位数*找到解决方案，而[中位数](@article_id:328584)是众所周知的对离群值鲁棒的。它“看到”了那个[离群值](@article_id:351978)，但冷静地得出结论，认为它不代表整体，从而拟合出一条捕捉了大多数数据真实模式的直线。

这个基本原则——MSE与均值相关，MAE与[中位数](@article_id:328584)相关——是一个普适的真理，其适用范围远不止简单的直线。在更高级的技术中，如核回归（通过观察数据的“局部”邻域来拟合复杂曲线），基于MSE的估计是附近点的*[加权平均](@article_id:304268)值*，而基于MAE的估计则是鲁棒的*加权[中位数](@article_id:328584)*[@problem_id:3175060]。主题是相同的：平方误差是[离群值](@article_id:351978)的奴隶，而[绝对误差](@article_id:299802)不是。

### 使训练与现实对齐

这就引出了机器学习实践中一个极其微妙但至关重要的点。通常，平方误差在数学上更容易处理；它的[导数](@article_id:318324)平滑且表现良好，使得优化过程（寻找“最佳”模型参数）变得简单。因此，工程师们可能倾向于使用MSE来训练模型，即使他们的最终目标是部署一个具有最佳MAE性能的模型。这是一个我们可称之为“优化-评估不匹配”的典型案例——这就像为了参加国际象棋比赛而练习跳棋。

想象一个实验，我们生成了已知包含[离群值](@article_id:351978)的数据。我们训练两个模型：一个最小化MSE，另一个最小化MAE的一个巧妙、平滑的近似（如log-cosh损失）。当我们最终用我们真正关心的指标MAE在新数据上测试它们时，那个用类似MAE的目标训练的模型总是获胜[@problem_id:3168805]。教训很明确：为你将要参加的考试进行练习，你成功的可能性更大。

这个想法延伸到了防止复杂模型“过拟合”的最重要技术之一：提前停止。在训练模型时，我们通常会观察它在一个独立的验证数据集上的表现。误差通常会先下降，因为模型学习到了真实的模式；但如果我们训练太久，它会开始记忆训练数据中的噪声，验证误差就会开始上升。我们希望在这个“U形”曲线的底部停止。但底部在哪里？正如现在可能猜到的那样，曲线的形状——以及其最小值的位置——取决于你绘制的是什么！在一个有[离群值](@article_id:351978)的场景中，验证MSE可能会很早就开始增加，被模型试图解释这些奇怪点的行为所惊吓。而验证MAE，由于更具鲁棒性，可能会显示模型在大部分数据上的性能仍在提高[@problem_id:3168813]。选择你的指标不仅仅是最后一步；它是在整个训练过程中的一个积极的向导。

### [误差指标](@article_id:352352)向我们揭示了关于世界的什么信息

也许这个选择最引人入胜的后果是，它不仅能改变我们构建的模型，还能改变我们从中得出的结论。在许多科学领域，我们构建模型不仅仅是为了预测，更是为了*理解*——确定哪些因素是某个现象最重要的驱动力。

考虑一个[决策树](@article_id:299696)模型，它通过对输入特征提出一系列“是/否”问题来进行预测。为了决定在每一步问哪个问题最好，决策树会寻找能最大程度减少“不纯度”或误差的分[割点](@article_id:641740)。现在，假设我们试图预测某个生物标记。我们有两个候选特征。特征 $X_2$ 与该标记有真实但中等的关系。而特征 $X_1$ 则没有真正的关系，但由于测量过程中的一个怪癖，它与偶尔出现的、剧烈的、重尾的噪声相关联。

如果我们使用基于MSE的不纯度（方差）来构建我们的树，那么这棵树会痴迷于与 $X_1$ 相关的巨大误差。它会发现根据 $X_1$ 进行分割可以大幅减少方差，并宣布它是一个非常重要的特征。然后，科学家可能会被派去进行一场徒劳的追逐，调查一个不过是测量假象的“联系”。但是，一棵使用基于MAE的不纯度构建的树，将对那些剧烈的误差具有鲁棒性。它会很大程度上忽略来自 $X_1$ 的噪声，并正确地识别出 $X_2$ 才是真正解释了底层信号的特征[@problem_id:3121094]。在这里，指标的选择决定了是真正的发现还是被随机性所愚弄。

### 从实验室到宇宙

我们讨论的原则是如此基础，以至于它们会出现在最意想不到的地方，并根据每个领域的独特物理特性进行调整。让我们从微观的数据点世界走向宇宙的尺度。天文学家使用机器学习来估算遥远星系的红移 ($z$)，这个量告诉我们由于[宇宙膨胀](@article_id:320885)，它们正以多快的速度离我们远去。

我们可以使用简单的MAE，即 $|\hat{z} - z|$，来评估一个[红移](@article_id:320349)[预测模型](@article_id:383073)。但是，比如说 $\Delta z = 0.05$ 的误差，对于一个在 $z = 0.1$ 的近处星系和一个在 $z = 2.0$ 的极远星系来说，其严重程度是否相同？直观上，我们[期望](@article_id:311378)对于更远、更暗的天体，我们的测量会更不确定。一个好的[误差指标](@article_id:352352)应该反映这种物理现实。

天体物理学家经常使用一个归一化的[误差指标](@article_id:352352)，例如 $\frac{|\hat{z} - z|}{1+z}$ [@problem_id:3168815]。分母 $(1+z)$ 与星系光线发出时宇宙的尺度因子直接相关。通过除以这个项，该指标不再评判原始误差，而是相对于宇宙尺度的误差。它*降低*了高[红移](@article_id:320349)天体绝对误差的权重，实际上是说：“我们容忍更遥远星系有更大的绝对错误，只要[相对误差](@article_id:307953)很小就行。”

这可以完全改变我们认为哪个模型是最好的。一个在所有红移下都具有恒定[绝对误差](@article_id:299802)的模型可能具有较低的MAE。但另一个模型，其[绝对误差](@article_id:299802)实际上与 $(1+z)$ 成比例增长，可能具有更高的MAE，但其[归一化](@article_id:310343)误差却低得多（也更稳定）。天体物理学界通过将物理[期望](@article_id:311378)编码到其指标中，更偏爱那个误差行为与我们对宇宙的理解相匹配的模型。这是一个美丽的例子，展示了一个简单的统计工具在被注入领域知识后，如何成为一个复杂的科学探究工具。

从一个有故障的传感器到[宇宙膨胀](@article_id:320885)的宏伟画卷，MSE和MAE之间的选择是一个反复出现的主题。这是一个关于鲁棒性的选择，一个关于我们优先事项的声明，也是我们探求知识的向导。下一次，当你在一个方程中看到一个平方项时，也许你会停下来，体会那个简单运算背后隐藏的强大哲学立场：对单一灾难性错误的深刻而强烈的厌恶。