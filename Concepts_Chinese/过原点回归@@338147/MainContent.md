## 引言
自然界和科学中的许多基本关系都遵循一个简单而严格的规则：直接比例关系。在这些系统中，零输入产生零输出，原因加倍会导致结果精确加倍。对此类关系建模需要一种专门的统计工具来遵守这一约束。标准线性回归过于灵活，它允许存在可能没有物理意义的截距。这就引出了一个关键问题：我们如何正确地建模、解释和验证一个我们根据[第一性原理](@article_id:382249)知道必须通过零点的关系？

这就是**[过原点回归](@article_id:350016) (RTO)** 的领域，一个被约束通过点 (0,0) 的[线性模型](@article_id:357202)。虽然这看似一个微小的调整，但这个约束从根本上改变了模型的数学性质和解释。本文为这个强大但常被误解的方法提供了一个全面的指南。在“原理与机制”一章中，我们将剖析 RTO 的统计引擎，从其斜率的推导到衡量其[拟合优度](@article_id:355030)的独特挑战及其误用的严重后果。然后，在“应用与跨学科联系”一章中，我们将看到这些原理的实际应用，探索 RTO 如何在从[材料物理](@article_id:381379)和[分析化学](@article_id:298050)到进化生物学研究等不同领域提供关键见解。

## 原理与机制

想象一下一条极其简单的自然法则。无论如何，如果你没有某物，你就得不到另一物。原因加倍，结果也精确加倍。没有启动费，没有基线偏移。这就是直接比例关系的世界，一个既优雅又严格的概念。科学和工程中的许多基本关系都存在于这个世界。例如，一个理想电阻器在没有电流通过时，其两端的电压也为零——这就是欧姆定律的核心 [@problem_id:1919586]。拉伸一个理想弹簧时，零伸长需要零力。这就是我们研究**[过原点回归](@article_id:350016) (RTO)** 时所进入的世界。

与可以随意穿过纵轴的标准[线性回归](@article_id:302758)不同，RTO 模型被锚定或约束在通过点 $(0,0)$。这不仅仅是一个微小的调整；它从根本上改变了我们分析的特性，带来了一些优美的简洁性和一些危险的陷阱。我们建立的模型写下来看似简单：

$$Y_i = \beta x_i + \epsilon_i$$

这里，$Y_i$ 是我们的观测值，$x_i$ 是我们控制或测量的变量，$\epsilon_i$ 是不可避免的随机噪声或误差，而 $\beta$ 是我们想要发现的唯一且至关重要的参数：比例常数。

### 寻找“最佳”比例关系

假设我们有一组我们认为应该遵循这种比例定律的散点数据。我们如何画出穿过原点的*最佳*直线来代表它们呢？**最小二乘法**原则，这个我们在[回归分析](@article_id:323080)中信赖的向导，仍然适用。想象一条线像钟表的指针一样围绕原点转动。对于每个可能的角度（斜率），我们可以测量这条线在垂直方向上与每个数据点的偏离程度。这些偏离就是我们的[残差](@article_id:348682)。然后我们将每个[垂直距离](@article_id:355265)平方后全部相加。“最佳”直线就是使这个总平方和最小的那条线 [@problem_id:1935176]。

当我们对这个最小化问题运用微积分时，一个极其简洁的估计斜率公式便出现了，我们称之为 $\hat{\beta}$：

$$\hat{\beta} = \frac{\sum_{i=1}^{n} x_{i} Y_{i}}{\sum_{i=1}^{n} x_{i}^{2}}$$

乍一看，这可能像是一堆[求和符号](@article_id:328108)的混乱组合。但这里有一个很好的直觉。这个公式本质上是各个斜率 $Y_i/x_i$ 的**[加权平均](@article_id:304268)值**。$x_i$ 值较大的点会获得更大的权重——实际上，权重与 $x_i^2$ 成正比。这完全合乎情理！一个远离原点的点就像一个长杠杆，相比于挤在原点附近（即使是很小的[随机噪声](@article_id:382845) $\epsilon_i$ 也能使其个体斜率 $Y_i/x_i$ 剧烈摆动）的点，它能为我们提供关于真实斜率的更稳定、更可靠的指示。这种点的影响力被称为**杠杆作用 (leverage)**，我们稍后会再谈到它。

一旦我们得到了估计值，我们自然想知道它有多好。有两个关键特性非常突出。首先，我们的估计量是**无偏的 (unbiased)**。这意味着，如果我们重复实验无数次，我们计算出的所有 $\hat{\beta}$ 值的平均值将正好落在未知的真实 $\beta$ 上 [@problem_id:1948111]。我们的方法不会系统性地过高或过低估计。其次，我们[估计量的方差](@article_id:346512)——衡量在这些重复实验中 $\hat{\beta}$ 值会围绕真实值[抖动](@article_id:326537)多少的度量——也同样优美而简单：

$$\text{Var}(\hat{\beta}) = \frac{\sigma^2}{\sum_{i=1}^n x_i^2}$$

其中 $\sigma^2$ 是我们测量误差的方差。这个公式告诉了我们一些关于[实验设计](@article_id:302887)的深刻道理。为了获得非常精确的 $\beta$ 估计（即小方差），我们有两个杠杆可以操作：减少测量中的噪声（减小 $\sigma^2$），或者更实际地，通过使用远离零的预测变量 $x_i$ 值来使分母 $\sum x_i^2$ 尽可能大 [@problem_id:1948111]。

### 一种特殊的误差

在带有截距的标准回归中，[残差](@article_id:348682)——即实际值与预测值之间的差异——被构造成其简单和为零。截距项的作用是上下调整直线，直到正[负偏差](@article_id:322428)相互抵消。

但在 RTO 的世界里，没有截距来执行这种平衡操作。最小二乘准则只对[残差](@article_id:348682) $e_i = Y_i - \hat{\beta} x_i$ 施加一个条件：即它们整体上与预测变量不相关。在数学上，这就是[正交条件](@article_id:348142) $\sum x_i e_i = 0$ [@problem_id:2407170]。这确保了我们的直线有正确的倾斜度。然而，[残差](@article_id:348682)的简单和 $\sum e_i$ 并不被强制为零。它可能是，而且通常会是某个非零数 [@problem_id:1948111]。这看似一个小小的技术细节，但它会带来戏剧性且常被误解的后果。

### $R^2$ 幻觉

这些后果中最著名的一个与**[决定系数](@article_id:347412) (coefficient of determination)**，即 $R^2$ 有关。在标准回归中，$R^2$ 告诉我们模型“解释的方差比例”，并且它被整齐地限制在 0 和 1 之间。这是因为一个简洁的数学恒等式：$Y$ 的总变异 (SST) 可以完美地分解为[模型解释](@article_id:642158)的变异 (SSR) 和未解释的[残差](@article_id:348682)变异 (SSE)。

因为在 RTO 中[残差](@article_id:348682)和不为零，这个优美的恒等式 $SST = SSR + SSE$ 就不成立了。如果你对一个 RTO 模型盲目使用标准的 $R^2$ 公式，你可能会得到奇怪的结果，包括负的 $R^2$！[@problem_id:2407170]。一个负的 $R^2$ 仅仅意味着你的模型（被强制通过原点）对 $Y$ 值的预测效果比仅使用它们的简单平均值 $\bar{y}$ 还要差。

为了正确衡量 RTO 模型的[拟合优度](@article_id:355030)，我们必须使用**未中心化 (uncentered)** 的变异定义。我们依赖于一个对 RTO 模型*确实*成立的不同恒等式：$\sum Y_i^2 = \sum \hat{Y}_i^2 + \sum e_i^2$。这将总的未中心化平方和分解为由回归引起的部分和由误差引起的部分。这引出了**未中心化 $R^2_{uc}$**：

$$R^2_{uc} = 1 - \frac{\sum e_i^2}{\sum Y_i^2}$$

这个量总是在 0 和 1 之间，并正确反映了模型捕获的总未中心化变异的比例。教训是明确的：软件会很乐意报告一个标准的 $R^2$，但对于 RTO 模型，你很可能会被误导，除非你明白你正在看的是哪个 $R^2$ 以及为什么 [@problem_id:1904819]。

### [置信度](@article_id:361655)，而不仅仅是估计值

找到最佳估计值 $\hat{\beta}$ 仅仅是开始。我们还想量化我们的不确定性。我们有多大的把握确信真实的 $\beta$ 不是零？为此，我们需要构建一个**[枢轴量](@article_id:323163) (pivotal quantity)**——即我们估计量的一个[标准化](@article_id:310343)版本，其分布是已知的，且不依赖于真实的参数值。

如果我们足够幸运，知道真实的[误差方差](@article_id:640337) $\sigma^2$，我们可以构建一个标准正态 (Z) 统计量：

$$Z = \frac{(\hat{\beta} - \beta) \sqrt{\sum x_i^2}}{\sigma} \sim N(0,1)$$

这直接源于我们之前找到的 $\hat{\beta}$ 的均值和方差 [@problem_id:1944057]。然而，在现实世界中，$\sigma^2$ 几乎总是未知的。我们必须使用我们的[残差](@article_id:348682)从数据中估计它。[误差方差](@article_id:640337)的正确估计量是 $\hat{\sigma}^2 = \frac{SSE}{n-1}$。注意分母是 $n-1$。我们从 $n$ 个数据点开始，但用掉了一个“自由度”来估计单个参数 $\beta$。这与带有截距的标准简单回归有关键区别，后者估计了两个参数（$\beta_0$ 和 $\beta_1$），因此误差自由度为 $n-2$ [@problem_id:2407170]。

通过在[枢轴量](@article_id:323163)中用我们的估计值 $\hat{\sigma}^2$ 替代真实的 $\sigma^2$，我们得到了一个服从 t 分布的统计量：

$$T = \frac{\hat{\beta} - \beta}{\sqrt{\frac{\hat{\sigma}^2}{\sum x_i^2}}} = \frac{\hat{\beta} - \beta}{\sqrt{\frac{SSE}{(n-1)\sum x_i^2}}} \sim t_{n-1}$$

这个 T 统计量是在几乎所有实际应用中构建置信区间和检验关于 $\beta$ 的假设的主力工具 [@problem_id:1944068]。由此，人们还可以构建一个 F 检验来评估回归的整体显著性，对于这个简单的单[参数模型](@article_id:350083)，F 检验等价于 t 检验 [@problem_id:1895404]。

### 点的杠杆作用

我们已经提到，远离原点的点在决定斜率时有更大的发言权。让我们把这一点说得更精确。一个数据点的**杠杆作用 (leverage)**，$h_{ii}$，衡量了它自己的值 $Y_i$ 对其自身的预测值 $\hat{Y}_i$ 有多大影响。对于 RTO 模型，杠杆作用的公式非常优美 [@problem_id:1930452]：

$$h_{ii} = \frac{x_i^2}{\sum_{j=1}^n x_j^2}$$

这就说明了一切。一个点的影响力仅取决于其自身 $x$ 值的平方大小，相对于所有 $x$ 值[平方和](@article_id:321453)的比例。一个在 $x=10$ 处的点，其杠杆作用是一个在 $x=1$ 处的点的 *100 倍*。它对回归线确实有更大的拉力。这个简单的公式是一个强大的诊断工具，能立刻告诉我们哪些观测值正在主导我们的结果。

### 一个警示故事：当数据拒绝原点时

RTO 模型是一个功能强大且简单的工具，但它完全依赖于一个关键假设：真实关系确实通过原点。如果我们错了会怎样？如果真实关系有一个非零截距，$Y_i = \alpha + \beta x_i + \epsilon_i$ 且 $\alpha \neq 0$，但我们却愚蠢地拟合了一个 RTO 模型，会发生什么？

后果是严重的。我们拟合的直线现在被要求执行一项不可能的任务：在试图拟合具有不同“自然”起点的数据的同时，还要穿过原点。结果是斜率 $\beta$ 的有偏估计。为了折中，这条线被扭曲，偏离了其真实的斜率。

更隐蔽的是，我们对[误差方差](@article_id:640337)的估计 $\hat{\sigma}^2_*$ 变得正向有偏。由于模型从根本上不适合数据，来自错误设定模型的[残差](@article_id:348682)被系统性地夸大了。我们[方差估计](@article_id:332309)的[期望值](@article_id:313620)不是真实的方差 $\sigma^2$，而是某个更大的值 [@problem_id:1915698]：

$$E[\hat{\sigma}^2_*] = \sigma^2 + \text{一个正的偏差项}$$

这个偏差项的大小取决于我们错误忽略的真实截距 $\alpha$ 的大小。这意味着我们的统计检验将变得不可靠；我们会低估系数的精度，并可能无法发现显著的关系。

这个教训是深刻而发人深省的。强制回归通过原点的决定不能轻率做出。它不是一个可以优化的统计选择，而是一个必须由理论或先验[知识证明](@article_id:325932)的**科学假设**。在拟合 RTO 模型之前，必须先查看数据。一个简单的散点图是你最诚实的朋友。如果点云看起来不是直指原点，那么强迫你的线穿过那里就是一种统计上的暴力行为，而扭曲的结果将是犯罪的证据。