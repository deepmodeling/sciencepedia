## 应用与跨学科联系

既然我们已经探索了可废止推理的机制——它的齿轮和杠杆，以及它与[经典逻辑](@entry_id:264911)僵化完美的区别——我们可以提出那个最重要的问题：它到底有何*用处*？你会欣喜地发现，答案是：几乎无所不包。可废止推理并非逻辑学家的某种晦涩工具；它是我们实际生活的世界的逻辑。它是常识的框架，科学发现的引擎，以及道德智慧的支架。当我们处在最理性、最富创造力、最人性的状态时，我们就是这样思考的。

让我们踏上一段旅程，穿越几个不同的世界——从医院无菌的走廊到智能机器的硅心，再到历史上最伟大科学家布满灰尘的笔记本——去看看这种卓越的思维模式是如何运作的。

### 医学的艺术与判断的重负

如果说有哪个领域抗拒被塞进毫无例外的规则的僵硬盒子，那一定是医学。医生的格言“首先，不造成伤害”(*primum non nocere*)，不是一条简单的命令，而是一种深刻的、依赖情境的平衡艺术。在这里，可废止推理不仅有用，而且是不可或缺的。

考虑一下现代临床决策的挑战，其中大量新数据，例如来自患者基因组的数据，必须得到解释。一个由人工智能驱动的诊断系统可能有一条规则：“如果患者基因 $G$ 存在[功能获得](@entry_id:272922)性变异，则优先选择药物 $D$。”但它可能还有另一条规则：“如果同一患者基因 $L$ 存在[功能丧失](@entry_id:273810)性变异，则*避免*使用药物 $D$。”现在，当一个患者同时出现这*两种*变异时会发生什么？一个建立在经典单调逻辑上的系统将面临一个致命的矛盾。它将同时证明了“使用 $D$”和“不使用 $D$”。逻辑上的结果是一场爆炸，一种任何事情都为真的完全无用状态。系统将不得不因[歧义](@entry_id:276744)而停止运作，彻底瘫痪 [@problem_id:4324304]。

但是，一个用可废止推理设计的系统，其行为就像一位经验丰富的临床医生。它明白规则有不同的权重和特异性。它可能有一个更高阶的原则：“当规则冲突时，基于更具体或更危险状况的规则优先。”功能丧失性变异可能带来更大的风险，因此其对应的规则击败了更一般的规则。系统不会崩溃；它做出了一个有理有据、可以辩护的选择。它在面对新的、更有说服力的证据时，收回了最初的冲动。

同样的逻辑可以从人工智能算法扩展到最困难的人类伦理困境。想想在新生儿重症监护室里做出的那些痛苦的决定。一个基本规则当然是保护生命。但对于一个天生就有灾难性损伤，面临着严重且无法摆脱的痛苦一生的婴儿来说，又该如何呢？不惜一切代价僵硬地应用“保护生命”的规则，忽略了与之竞争的不伤害原则——即防止伤害的责任。一个更人道、更合乎伦理的框架将严重的痛苦视为一个强有力的、*初步的* (*prima facie*) 考虑限制生命维持治疗的理由。这是一个默认结论。但它是一个可废止的结论。这个结论可以被推翻——被击败——如果一系列特定条件得到满足：例如，如果存在过上有意义生活的现实机会，如果痛苦可以得到有效缓解，并且如果潜在的益处被判断为与治疗的负担相称 [@problem_id:4873013]。

这不是冷冰冰的计算；这是一种结构化的同情。这与我们在负责任的疼痛管理中看到的模式相同。一项指南可能会设定一个阿片类药物剂量的推定上限，以在群体层面上防止伤害。但对于一个已经用尽所有其他选择，并且在更高剂量下显示出清晰、客观功能改善的特定患者，那条通用规则在伦理上可以被推翻 [@problem_id:4874722]。患者个体的、有记录的成功，成为对通用规则的否决因素。

也许伦理学中最鲜明的例子就是所谓的“不知情权”。医生的默认责任是向患者披露所有临床上重要的信息。这基于尊重他们自主权的原则。但如果一个有能力的患者，在被充分告知其影响后，清晰明确地表示他们不希望被告知某些类型的结果呢？这一个单一的、具有道德显著性的事实——正是对同一自主原则的运用——击败了默认的责任。结论从“你必须告知”翻转为“你绝不能告知” [@problem_id:4851483]。伦理体系足够灵活，可以避免其自身规则的暴政。

### 构建智能且理性的机器

当我们试图制造能够思考的机器时，我们很快意识到必须赋予它们同样的灵活性。一个智能系统，无论是一个监控复杂工厂的[数字孪生](@entry_id:171650)，还是一辆在混乱街道上导航的自动驾驶汽车，都不能在拥有完整信息的假设下运行。

这就是计算机科学家所称的**开放世界假设**的美妙之处。一个建立在此原则上的人工智能系统明白，信息的缺失不等于缺失的信息。如果一个发电厂关键泵上的传感器没有报告高温读数，系统不会得出结论：“泵没问题。”它会得出结论：“我还不知道泵的状态” [@problem_id:4245052]。它的世界对新数据是开放的。“正常”状态是一个暂定的、可废止的假设，一旦[危险信号](@entry_id:195376)到达，就可以立即撤销。这可以防止系统基于不完整的知识犯下灾难性的错误。从某种意义上说，开放世界假设是一种设计内置的谦逊，一种对地图并非疆域的认识。

更广泛地说，[现代机器学习](@entry_id:637169)的整个架构就是一种高科技的决疑论，或称基于案例的推理。一个人工智能模型通过分析数百万个“案例”来学习——无论是图像、医疗记录还是国际象棋棋局。它学到的“规则”不是一个僵硬的逻辑陈述，而是一个复杂的、高维的概率曲面。它的输出是一种置信度，一个本质上可废止的临时判断。当一个新的证据出现时，人工智能在该曲面上的位置会发生变化，其信念也会更新 [@problem-id:4410993]。这个过程，当基于良好的数据和健全的统计原则（如校准和鲁棒性检查）时，允许人工智能做出可靠的、情境敏感的判断，这与从一个案例推断到下一个案例的古老艺术相呼应 [@problem-id:4411004]。

### 科学发现的逻辑

人们很容易认为科学是唯一一个拥有无例外、普适法则的领域。牛顿的万有引力定律、[麦克斯韦方程组](@entry_id:150940)——这些似乎是绝对的。但在生物科学和人文科学中，甚至在发现过程本身中，世界都远为混乱。科学史就是一个可废止推理的故事。

Aristotle，第一位伟大的生物学家，本能地知道这一点。他观察到，在生命世界中，概括只在“绝大多数情况下”(*hōs epi to polu*)成立。他会注意到一种模式——比如说，有肺的动物也倾向于有某种类型的心脏——并利用这种模式来产生和检验假说。他知道会有例外，但他不把它们视为规则的失败，而是视为可能导致更深刻理解的谜题。同样的精神激励着现代[比较生物学](@entry_id:166209)。一位科学家可能假设哺乳动物胆囊的有无与进食模式有关——连续进食的食草动物不需要胆汁储存器，而[间歇性](@entry_id:275330)进食的动物则需要。他们通过比较许多物种，并控制[共同祖先](@entry_id:175919)的影响来检验这一点。如果他们发现一个例外——一个没有胆囊的间歇性进食动物！——他们不会抛弃这个理论。相反，他们会问：“这只动物有什么特别之处？它进化出了什么其他机制？”例外成为最有趣的数据点，一个将原始、简单的规则提炼成更复杂规则的否决因素 [@problem_id:4739432]。

这正是医学史上最著名的一套标准之一——亨勒-[科赫法则](@entry_id:173273)（Henle-Koch postulates）的故事。为了证明一种特定的微生物导致一种特定的疾病，Robert Koch 提出了一个简短的条件列表：在所有疾病案例中都必须找到该微生物，它必须被分离并在纯培养基中生长，它必须在健康的宿主中重现该疾病，并且必须从那个新宿主中重新分离出来。一个世纪以来，这都是黄金标准。但这些法则是无例外的定律吗？完全不是。我们现在知道有[无症状携带者](@entry_id:172545)（携带微生物但没有疾病），这击败了第一条法则。我们知道有些微生物无法在培养基中生长，比如导致梅毒的细菌。我们还知道了病毒。这些发现并没有使 Koch 的框架失效；它们完善了它。它们被认为是显示了原始规则局限性的否决因素，迫使科学发展出对感染更细致的理解。这些法则是一个强大但最终是可废止的科学框架的经典例子 [@problem_id:4599243]。

从医生的诊室到人工智能的核心逻辑，再到科学家的工作台，模式都是相同的。我们从好的、通用的规则开始——我们尽最大努力捕捉世界的规律性。但我们轻轻地持有它们。我们随时准备在面对新的、有说服力的证据时修正、完善甚至推翻我们的结论。这不是思维有缺陷的标志。这正是智能的标志。这是发现过程中本质的、美丽的、可废止的舞蹈。