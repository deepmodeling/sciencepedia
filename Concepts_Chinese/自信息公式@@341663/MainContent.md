## 引言
在我们的日常生活中，“信息”是一个模糊的概念，但在科学和技术领域，它有着精确而强大的定义。我们如何衡量一条消息中的信息？一份可预测的每日报告与一则突发的意外警报，它们的信息量相同吗？直觉上，我们知道答案是否定的。意外的警报承载了更多的分量，更多的“惊奇”。20世纪中叶，Claude Shannon的开创性工作将这一直觉形式化，他试图创建一种通信的数学理论。他解决了我们对惊奇的定性感受与工程和科学的定量需求之间的根本差距。本文探讨了他理论的基石：[自信息公式](@article_id:325700)。首先，在“原理与机制”一节中，我们将剖析这个优美的公式，理解它如何量化惊奇度、其基本性质，以及它如何引出熵的概念。然后，在“应用与跨学科联系”一节中，我们将看到这一个简单的思想如何提供一个统一的视角，来审视人工智能、分子生物学和[热力学](@article_id:359663)等不同领域。

## 原理与机制

什么是信息？这是我们每天都在使用的词，但在科学意义上它到底意味着什么？一本字典充满了“信息”吗？一条来自朋友的紧急消息呢？你可能会觉得，那条紧急消息，特别是如果它出乎意料，不知何故比字典里随机的一页包含*更多*的信息。你是对的。

20世纪中叶，杰出的工程师和数学家Claude Shannon提出了一个革命性的见解。他意识到信息的基本‘通货’是**惊奇**。一个事件越令人惊讶，当我们得知它发生时，我们获得的信息就越多。一条“今天早上太阳升起了”的消息几乎不含任何信息，因为这是完全意料之中的事。而一条“东京发生了大地震”的消息则包含巨大的[信息量](@article_id:333051)，因为在任何一天，这都是一个不幸的罕见且出乎意料的事件。Shannon为我们提供了一种使这种直观想法变得精确的方法。

### 量化惊奇度

让我们想象一下，你正在一个热液喷口附近监测一个深海探测器。该探测器会发回一个简单的二进制信号：如果探测到罕见的生物事件，则为‘1’，否则为‘0’。根据历史数据，你知道这个事件非常罕见，发生的概率仅为 $p=0.05$。这意味着95%的时间里，你预计会收到‘0’。

当‘0’到达时，一切如常，没什么好惊讶的。但当屏幕上闪烁出‘1’时——那可是件大事！你学到了重要的东西。‘1’的信息内容远高于‘0’。Shannon的**[自信息](@article_id:325761)**（或称**惊奇度**）公式完美地捕捉了这一点：

$I(x) = -\log_{b} p(x)$

在这里，$p(x)$ 是事件 $x$ 发生的概率，对数底数 $b$ 决定了我们用来衡量信息的单位。负号至关重要：因为概率 $p(x)$ 总是一个介于0和1之间的数，其对数将是负数或零。公式中的负号将其反转，确保信息总是一个正量。

这个简单的公式有几个优美的性质：

-   **高概率，低信息：** 对于我们的深海探测器 [@problem_id:1657220]，‘无事件’的概率是 $p(0) = 0.95$。一个事件发生的概率是 $p(1) = 0.05$。观察到罕见事件所获得的信息远大于观察到常见事件的信息。惊奇度的差异恰好是 $\log_{2}((1-p)/p) = \log_{2}(19)$，这意味着观察罕见事件比观察常见事件多携带约4.25比特的信息。

-   **确定性不提供信息：** 如果一个事件保证会发生（$p=1$），其对数为0。公式告诉我们 $I(1) = -\log(1) = 0$。这完全合乎逻辑。如果你已经知道某事将要发生，它的发生不会提供任何新信息。

-   **信息不能为负：** 接收到负信息意味着什么呢？这将意味着观察一个事件实际上*增加*了你对世界的不确定性，这是荒谬的。这个公式保护我们免于这种情况。如果某个有缺陷的模型预测一个事件的概率大于1（这是不可能的），将其代入Shannon的公式将导致负信息 [@problem_id:1666609]。这个数学上的危险信号告诉我们，我们的初始假设从根本上就是错误的。观察一个事件总是减少不确定性，或者在最坏的情况下，保持不变（如果事件是确定的）。

### 选择你的度量单位：比特、奈特和哈特利

就像我们可以用米、英尺或英寸来测量长度一样，我们也可以用不同的单位来测量信息。单位的选择仅仅取决于我们在公式中使用的对数底数。

-   **比特（底为2）：** 这是计算和信息论中最常见的单位。一个**比特**是解决两个[等可能结果](@article_id:323895)之间不确定性所需的信息量，比如一次抛硬币。它是一个“是/否”问题中的信息量。例如，如果一个医疗设备有2500种等可能的配置，识别正在使用的特定配置所需的信息是 $\log_{2}(2500) \approx 11.29$ 比特 [@problem_id:1913643]。这大致相当于确定正确配置所需的“是/否”问题的数量。

-   **奈特（底为e）：** **奈特**（自然[信息单位](@article_id:326136)）使用自然对数（底为 $e \approx 2.718$）。这个单位自然出现在物理学和统计学的许多领域。例如，在[临床试验](@article_id:353944)中，“p值”代表在药物无效的情况下观察到当前结果的概率。一个小的p值，比如0.015，是一个令人惊讶的结果。这个结果的惊奇度，用奈特衡量，将是 $-\ln(0.015) \approx 4.20$ 奈特 [@problem_id:1666572]。

-   **哈特利（底为10）：** **哈特利**基于以10为底的对数，以另一位信息论先驱Ralph Hartley的名字命名。它对应于解决10个[等可能结果](@article_id:323895)之间不确定性所需的信息。[地震学](@article_id:382144)家可能会使用这个单位来量化大地震的罕见性。一个500年一遇的地震，其年发生概率为 $p=1/500$。在给定年份发生此类事件的惊奇度是 $\log_{10}(500) \approx 2.7$ 哈特利 [@problem_id:1657232]。

单位的选择不会改变信息的基本现实，就像用英寸测量桌子不会比用厘米测量使它变短一样 [@problem_id:1666589]。转换只是一个常数因子：$I_{\text{bits}} = I_{\text{nats}} / \ln(2)$。

### 信息的代数

对数的选择在这里真正揭示了其天才之处。对数的性质转化为一种强大而直观的“信息代数”。最重要的规则是**可加性**。

如果你有两个独立事件，两者同时发生的概率是它们各自概率的乘积。但信息又如何呢？多亏了对数，你从观察两个独立事件中获得的信息就是它们各[自信息](@article_id:325761)的**总和**。这是因为 $\log(p_1 \times p_2) = \log(p_1) + \log(p_2)$。这是一个非常有用的性质。这意味着我们可以分解复杂系统，并将其独立部分的信息相加。

这种代数性质也允许我们进行逆向推理。想象一个实验，我们只知道在“区域1”中找到一个粒子比在“区域2”中找到它要惊奇两倍。这告诉我们关于其背后物理学的什么信息？这不仅仅是一个模糊的陈述。用信息的语言来说，这是一个精确的方程：$I_1 = 2 \times I_2$。使用[自信息](@article_id:325761)的定义，这变成 $-\log_2(p_1) = 2 \times (-\log_2(p_2))$。对数法则让我们能够简化这个方程，从而找到概率之间的具体关系：$p_1 = p_2^2$ [@problem_id:1356019]。信息不仅仅是一个记分工具；它是一个揭示世界隐藏数学结构的透镜。

### 从惊奇到[期望](@article_id:311378)：熵的诞生

到目前为止，我们讨论的是单个特定消息的信息。但如果我们有一个信源——比如无线电发射器、股票行情自动收录器，甚至是一条DNA链——它不断地产生消息，每个消息都有自己的概率，那该怎么办？有些消息可能很常见，信息量很小，而另一些则很罕见，[信息量](@article_id:333051)很大。我们平均可以*[期望](@article_id:311378)*从每条消息中获得多少信息？

这个问题将我们引向整个科学中最基本的概念之一：**熵**。[期望](@article_id:311378)[自信息](@article_id:325761)是通过计算每个可能结果的[自信息](@article_id:325761)，乘以其发生的概率，然后将所有结果加总得到的。

考虑一个简单的二进制信源，它以概率 $p$ 发射‘1’，以概率 $1-p$ 发射‘0’[@problem_id:1622972]。每个符号的[期望信息](@article_id:342682)是：

$E[I(X)] = p \times I(1) + (1-p) \times I(0)$

代入[自信息](@article_id:325761)的公式，我们得到了著名的二进制信源的香农熵公式：

$H(X) = -p\log_{2}(p) - (1-p)\log_{2}(1-p)$

这个量 $H(X)$ 就是信源的**熵**。它代表了平均惊奇度、平均信息内容，或者从根本上说，是在每条消息到达之前对其结果的平均不确定性。

如果信源是一枚公平的硬币（$p=0.5$），熵达到最大值1比特。这是我们最不确定的时候。我们不知道会出现正面还是反面。如果硬币有很大的偏向，比如 $p=0.99$，熵就非常低。我们非常确定结果会是正面，所以平均而言几乎没有惊奇。

熵这个概念，诞生于量化电报信号中惊奇度的简单想法，结果却与[热力学](@article_id:359663)、[统计力](@article_id:373880)学，甚至生命本身的本质有着深刻的联系。这一切都始于那个优雅而强大的公式，它将惊奇的直观概念转变为现代科学的基石。