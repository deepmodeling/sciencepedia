## 应用与跨学科联系

我们已经探索了对抗性扰动的机制，学会了如何制造这些微小、恶意的低语，它们能让强大的人工智能误入歧途。人们很容易将此视为一个缺陷、一个需要修复的漏洞、一场需要赢得的战斗。但如果止步于此，就完全错失了要点。对物理学家来说，一个出人意料的实验结果不是失败，而是一个机会——一个来自大自然的线索，表明我们的理论尚不完备。本着同样的精神，对抗性扰动不仅是破坏模型的工具，更是一种理解它们的精密仪器。它是一个镜头，让我们能够探查人工智能“思维过程”的本质，揭示其隐藏的假设、逻辑捷径及其知识的边界。在本章中，我们将探讨这种强大的镜头如何在各学科中被使用，将我们与人工智能的关系从盲目信任转变为批判性的科学探究。

### 探查人工智能的架构核心

从根本上说，深度神经网络的行为是其架构——其层与连接的特定[排列](@entry_id:136432)——的结果。[对抗性攻击](@entry_id:635501)提供了一种独特的方式来对这些架构设计进行压力测试，揭示了现代人工智能构建模块中的根本性张力和脆弱性。

想象一个低语沿着一长队人传播。开头的一个小错误到最后可能会被极大地扭曲。深度网络中也可能发生类似现象。在深度[残差网络 (ResNet)](@entry_id:634329) 中，一个模块的输出是其输入与一个复杂的[非线性变换](@entry_id:636115)之和，模型化为 $y(x) = x + F(x)$。对输入 $x$ 的一个扰动 $\delta$ 导致的输出扰动，其界限为 $(1 + K_F)\|\delta\|$，其中 $K_F$ 是变换 $F$ 的[利普希茨常数](@entry_id:146583)。这个常数与层中权重矩阵的量级（特别是[谱范数](@entry_id:143091)）有关。这揭示了一个深刻的权衡：为了使网络更具表达力以学习复杂模式，我们可能需要更大的权重，但这反过来又增加了 $K_F$，使网络成为[对抗性噪声](@entry_id:746323)更强大的放大器。堆叠许多这样的模块可能导致这种敏感性随深度呈指数级增长，使得非常深的网络异常脆弱，除非采取措施约束其权重范数 [@problem_id:3170060]。

这种脆弱性并不仅限于图像分类器。考虑作为[大型语言模型](@entry_id:751149)引擎的 Transformer 架构。一个关键组件是“注意力”机制，它允许模型权衡输入序列不同部分的重要性。对于给定的查询 $q$，它会根据一组键 $\{k_i\}$ 计算得分来决定关注哪里。人们可能认为这种机制是鲁棒的，但它同样可以被操纵。一个添加到查询中的微小、精心设计的对抗性扰动 $\delta$ 就足以将排名第一的注意力从一个键翻转到另一个键，从而完全改变模型的[焦点](@entry_id:174388)，并因此改变其对数据的解释。实现这种翻转所需扰动的量级与注意力分数的初始余量直接相关——模型最初越自信，欺骗它所需的扰动就越大 [@problem_id:3100293]。这显示了对抗方如何利用[注意力机制](@entry_id:636429)本身的几何特性来重定向模型的“凝视”。

有趣的是，一些架构拥有能够与这些扰动相互作用的内在特性。在像[门控循环单元](@entry_id:636742) (GRU) 这样的[循环神经网络](@entry_id:171248)中，内部的“更新”门和“重置”门控制着信息随时间的流动。当面对受扰动的输入时，这些门可能会改变它们的状态，有时会以一种自然减轻攻击影响的方式改变信息流，起到一种隐式防御的作用 [@problem_id:3128142]。分析这些内部机制如何响应攻击，是理解和设计更鲁棒的序列模型的关键部分。

### 作为科学仪器的对抗性扰动

除了揭示工程上的权衡，对抗性扰动正演变为一种用于科学发现和验证的强大工具。通过根据领域知识约束攻击，我们可以提出关于模型真正学到了什么的高度具体的问题。

也许最引人注目的例子来自高风险的计算[病理学](@entry_id:193640)领域。想象一个被训练用来从[组织学](@entry_id:147494)图像中诊断癌症的人工智能。病理学家可以标记一张切片，标出具有诊断相关性的区域——细胞核、腺体结构——以及无关的“背景”。然后，我们可以发起一次带有关键约束的[对抗性攻击](@entry_id:635501)：扰动 $\delta$ 只被允许修改人类专家认为无关的背景区域中的像素。如果对这些背景像素的微小、难以察觉的改变能够将模型的诊断从“良性”翻转为“恶性”，这就提供了直接、不可否认的证据，表明该模型的行为不像一位训练有素的[病理学](@entry_id:193640)家。它正依赖于脆弱、不鲁棒且与诊断无关的“捷径”特征来做出其生死攸关的决定。这种使用受约束的[对抗性样本](@entry_id:636615)作为一种强大的调试器，使我们能够对人工智能的推理过程进行有针对性的交叉诘问 [@problem_id:2373351]。

同样的对抗性[交叉](@entry_id:147634)诘问原则从医院延伸到 CERN 的[高能物理](@entry_id:181260)实验室。物理学家使用[神经网](@entry_id:276355)络来分类碰撞中产生的粒子“射流”。物理学的一个核心原则是，有效的可观测量必须是“红外与共线 (IRC) 安全的”，这意味着它们对某些低能和[方向性](@entry_id:266095)效应不敏感。为了确保他们的人工智能模型学习的是真实的物理学，而不仅仅是它们所训练的模拟器的产物，物理学家可以分析其鲁棒性。通过理解最差情况的扰动如何影响模型的输出——一个受网络[利普希茨常数](@entry_id:146583)限制的变化——他们可以量化模型的稳定性。一个对微小输入变化过分脆弱的模型，可能并未学习到其设计初衷想要捕捉的鲁棒、潜在的物理原理 [@problem_id:3505065]。

### 扩展前沿：公平、不确定性与创造力

[对抗性攻击](@entry_id:635501)的概念阐明了现代人工智能中一些最深刻和最紧迫的挑战，将讨论推向了公平、自我意识甚至创造力的领域。

人工智能的公平性是一个关键目标，通常通过确保模型的预测与种族或性别等敏感属性没有[统计相关性](@entry_id:267552)来衡量。然而，基于互信息的分析揭示，这种公平性可能具有欺骗性的脆弱。对抗方可以设计一种在一个情境中是幻影，在另一个情境中却是怪物的扰动。利用精心设计的映射，可以改变模型的内部表示 $Z$，使其在完美保持预测效用——例如，保持表示与目标变量 $Y$ 之间的[互信息](@entry_id:138718) $I(Z;Y)$ 恒定——的同时，显著*增加*其与敏感属性 $S$ 的互信息 $I(Z;S)$。模型的准确率保持不变，但其公平性已被悄然颠覆。因此，对抗性思维提供了一种关键的压力测试，迫使我们追问模型的公平性是真实的，还是仅仅是训练数据的肤浅属性 [@problem_id:3149099]。

此外，对抗性扰动可以用来描绘模型自身知识的边界。在贝叶斯框架中，我们可以区分两种类型的不确定性。*偶然不确定性*是世界固有的随机性——就像骰子的滚动，即使是完美的模型也无法预测。另一方面，*[认知不确定性](@entry_id:149866)*是模型自身因数据有限和知识不完善而产生的不确定性。可以设计一种[对抗性攻击](@entry_id:635501)，其目的不是翻转预测，而是找到最大限度地混淆模型、将其认知不确定性推向顶峰的输入。攻击主动寻找模型理解中的盲点。通过应用旨在最大化认知[方差](@entry_id:200758)的扰动，我们可以识别出模型对其自身知识最不自信的具体输入，实际上是在问它：“告诉我你最不了解的是什么” [@problem_id:3197111]。

这些方法的[影响范围](@entry_id:166501)现在已超越分类，进入了创造领域。像驱动文本到图像系统的[扩散模型](@entry_id:142185)这样的[生成模型](@entry_id:177561)，通过迭代地将一个[随机场](@entry_id:177952)“去噪”成一幅连贯的画面来工作。在这里，[对抗性攻击](@entry_id:635501)呈现出一种新形式。攻击的目的不再是欺骗模型将猫看成狗，而是要毒化创造过程本身。通过在逆向[扩散过程](@entry_id:170696)的中间步骤扰动噪声输入 $\mathbf{x}_t$，对抗方可以操[纵模](@entry_id:164178)型的噪声预测 $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)$。这种定向的破坏会引导生成路径偏离航道，导致模型产生有缺陷或非预期的图像。这在对抗性研究中开辟了一个新战线，专注于生成式和创造性人工智能的鲁棒性 [@problem_id:3116002]。

正如我们所见，“扰动”的概念出人意料地深刻。它可以是针对单个测试图像的改变，旨在欺骗一个预测，也可以是对训练数据本身的微妙重新加权，这会扭曲模型学到的参数并影响所有后续的预测 [@problem_id:3148890]。两者都挑战我们模型的稳定性，但方式截然不同。因此，追求对抗性鲁棒性不是一场单一的战斗，而是一场宏大的战役，旨在构建不仅准确，而且稳定、公平、具有自我意识，并与它们旨在服务的世界原则相一致的人工智能。[对抗性样本](@entry_id:636615)，曾一度被视为纯粹的好奇之物，现已成为我们在这段旅程中最深刻的指引。