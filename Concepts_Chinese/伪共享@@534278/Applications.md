## 应用与跨学科关联

既然我们已经掌握了[伪共享](@article_id:638666)这种奇特的物理现象，现在就可以踏上一段旅程，去看看这个“机器中的幽灵”究竟栖身何处。你可能会倾向于认为这是一个深奥的问题，是设计计算机芯片的架构师们才会感兴趣的奇闻。但那就错了。[伪共享](@article_id:638666)是一个非常实际的问题，一个性能窃贼，潜伏在各种各样令人惊讶的地方，从科学计算的宏大模拟，到你每天使用的软件的根基。

我们探索的核心主题将是一个简单但深刻的脱节：我们程序所见的内存地图，并非硬件实际导航的疆域。我们将内存视为一条由单个字节大小的房屋组成的连续、无尽的街道。然而，处理器却将其视为一系列的城市街区，它称之为*缓存行*。它不移动单个房屋，而是一次性移动整个街区。[伪共享](@article_id:638666)就是当多个工人——每个工人都被指派去翻新一个不同的房屋——发现他们的房屋位于同一个街区，而规则又规定任何时候只有一个工人的团队能在一个街区上工作时所发生的混乱。这个街区被浪费地来回运送，而几乎没什么工作得以完成。

作为聪明的程序员和科学家，我们的任务是成为城市规划师——设计我们的程序和[数据结构](@article_id:325845)，以便我们的并行工人被分配到不同的街区，而不仅仅是不同的房屋。让我们看看这在不同领域是如何体现的。

### [科学计算](@article_id:304417)的宏大舞台

或许，最先遇到[伪共享](@article_id:638666)的自然场景是在高性能科学计算领域，我们通常会动用大量的线程来处理海量的数字数组。

想象一个简单但常见的任务：使用十六个线程对一个巨大的数字列表求和。一个天真的方法可能是创建一个包含十六个槽位的小数组，每个线程一个，用于存储它们的局部和。每个线程处理完自己那部分主列表后，会定期更新其个人槽位。问题在于，如果这十六个槽位在内存中是连续[排列](@article_id:296886)的，那么其中几个将不可避免地落在同一个缓存行上——同一个城市街区。对于[双精度](@article_id:641220)数（8字节）和典型的64字节[缓存](@article_id:347361)行，八个槽位将共享一个缓存行。当线程0写入其槽位时，它将缓存行拉到自己的核心。一纳秒后，当线程1写入*它的*槽位时，硬件会把整个缓存行猛地拽到线程1的核心，并使线程0的副本失效。这个缓存行在核心之间疯狂地“乒乓”，大部分时间都花在了[通信开销](@article_id:640650)上，而不是有效的计算上[@problem_id:3116481]。解决方案是什么？我们刻意在槽位之间插入空白空间——即填充——以确保每个线程的计数器都位于其自己的私有缓存行上。使用更多内存感觉很浪费，但通过消除争用所带来的性能提升是巨大的。

这个原则也延伸到更复杂的场景。考虑使用一个二维网格来模拟热量在金属板中的传导。一个常见的并行策略是按线程划分网格。但*如何*划分至关重要。如果网格是以[行主序](@article_id:639097)（row-major order，意味着一行的元素在内存中是连续的）存储的，那么当我们按列划分工作时会发生什么？线程0负责第0到255列，线程1负责第256到511列，依此类推。现在，看看边界。对于网格中的每一行，线程0将写入一个网格点，比如$A[i][255]$，而线程1则在写入$A[i][256]$。由于[行主序](@article_id:639097)的布局，这两个点在内存中是相邻的，几乎肯定会位于同一个[缓存](@article_id:347361)行上。结果是在线程之间的整个边界上产生了一堵巨大的[伪共享](@article_id:638666)之墙[@problem_id:2485959]。

显而易见的解决方法是改为按行划分网格。线程0负责一整块行，线程1负责下一块。现在它们工作之间的边界位于两个不同的行之间，而这两行在内存中相距甚远，因此位于不同的[缓存](@article_id:347361)行上。[伪共享](@article_id:638666)就此消失。这个基本见解——即你的工作分解必须尊重底层的[内存布局](@article_id:640105)——是高性能计算的基石之一[@problem_id:3267689]。它适用于从求解微分方程到[图像处理](@article_id:340665)的各种任务。它甚至出现在稀疏矩阵计算的优化中，这是图分析和物理模拟的关键组成部分，其中生成输出向量的工作必须以[缓存](@article_id:347361)行感知的块来划分，以防止线程干扰彼此的结果[@problem_id:3276545]。

### [并行算法](@article_id:335034)与[数据结构](@article_id:325845)的精妙艺术

[伪共享](@article_id:638666)不仅仅是大型、规整网格的问题。当我们在设计[并行算法](@article_id:335034)的基础构件时，它也会冒出来。

假设我们正在设计一个并行的[桶排序](@article_id:641683)。每个线程都为它找到的桶准备一个私有的计数器数组。如果我们分配一个大的内存块，然后为各个线程切分，让每个线程的计数器数组紧挨着前一个，我们就设置了一个雷区。线程0数组的最后几个计数器和线程1数组的头几个计数器很容易最终落在同一个[缓存](@article_id:347361)行上。如果被排序的数据导致对这些边界桶的频繁更新，性能将会骤降[@problem_id:3219381]。同样，解决方案是对齐：我们确保每个线程的私有数据结构都从一个新的[缓存](@article_id:347361)行边界开始。

一个更引人注目的例子是在并行化一个简单的数组操作时发现的，比如通过写入一个“墓碑”标志来标记要删除的元素。一个常见的并行模式是*条带化*（striping），即线程0处理元素0, 4, 8, ...，线程1处理1, 5, 9, ...，以此类推（假设有四个线程）。这看起来很公平，但却是一场性能灾难。在一个容纳64个标志的[缓存](@article_id:347361)行内，线程0、1、2和3将持续不断地同时写入它。[缓存](@article_id:347361)行在它们的核心之间激烈地[颠簸](@article_id:642184)。一个远为优越的策略是*块分配*（block assignment）：线程0处理数组的前四分之一，线程1处理第二部分，依此类推。这样，每个线程都在自己的内存邻域内工作，[伪共享](@article_id:638666)只在大块相交的少数几个点上成为一个小问题[@problem_id:3208560]。在条带化和分块之间的选择是无数[并行算法](@article_id:335034)中的一个基本设计决策。

也许最能启发人的例子是最微妙的那些。考虑一个线程安全的链表，它维护一个全局计数器来记录其大小。[链表](@article_id:639983)的头指针位于一个缓存行上。假设大小计数器，一个8字节的整数，位于另一个缓存行上。但如果第二个[缓存](@article_id:347361)行*也*包含一些其他完全不相关的数据——比如说，一个被其他线程频繁读取的配置标志呢？现在，每当一个线程从[链表](@article_id:639983)中删除一个节点时，它会获取一个锁，更新头指针（污染第一个[缓存](@article_id:347361)行），并递减大小计数器（污染第二个[缓存](@article_id:347361)行）。通过污染第二个缓存行，它使所有其他核心中的副本失效。这意味着任何只想读取那个无害的配置标志的线程现在都被迫停顿并重新获取整个[缓存](@article_id:347361)行，仅仅因为它不幸地与大小计数器成了邻居。这是一个由看似无害的数据共置引起的典型[伪共享](@article_id:638666)案例[@problem_id:3245614]。它教给我们一个至关重要的教训：问题不在于数组，而在于什么东西共享了一个64字节的内存块。

同样的原则也适用于更高级的[算法](@article_id:331821)。在计算生物学中，计算两个DNA序列之间的“[编辑距离](@article_id:313123)”是一项常见的任务，通过[动态规划](@article_id:301549)来解决。将其并行化需要让线程处理一个大型计算矩阵的不同部分。一个天真的并行化方案可能导致处理逻辑上分离的行的线程相互干扰，因为这些行在内存中被打包得太紧密。解决方案是一种巧妙的布局转换：通过将内存中每行的长度填充为[缓存](@article_id:347361)行大小的倍数，我们保证了每行的工作空间都位于不相交的缓存行集合上，从而完全消除了干扰[@problem_id:3231025]。

### 运行时和系统的无形世界

[伪共享](@article_id:638666)的幽灵甚至萦绕在使我们现代编程语言得以工作的隐藏基础设施中。如果你曾用Java、C#、Python或Go编写过代码，你就受益于自动[垃圾回收](@article_id:641617)器（GC）。

许多高性能GC使用一种称为“卡片标记写屏障”（card-marking write barrier）的技术来跟踪内存变化。本质上，内存堆被划分为“卡片”（card，比如512字节），并且有一个独立的“卡片表”（card table），为每个卡片分配一个字节。当你的程序写入一个指向对象的指针时，GC的写屏障会自动在卡片表中做一个标记，即向相应的条目写入一个字节。这告诉GC这张卡片是“脏”的，需要稍后扫描。

现在，想象一个多线程应用程序。多个线程都在并发地写入内存。这意味着多个线程也在并发地写入共享的卡片表。由于卡片表只是一个紧凑的字节数组，它成了[伪共享](@article_id:638666)的完美温床。两个线程在修改不同但邻近的卡片上的对象时，很容易最终试图在卡片表中的同一个缓存行上标记字节[@problem_id:3236478]。对于语言运行时的设计者来说，这是一个主要的性能挑战。

他们采用的一种优雅的解决方案是给每个线程自己的、私有的脏卡片日志。在正常执行期间，线程只写入它们的私有日志，这个操作不会引起跨线程的争用。只有在[垃圾回收](@article_id:641617)器需要运行时，所有线程才会被暂停，它们的私有日志被高效地合并到主共享卡片表中。这种技术，一种缓冲形式，用少量内存换取了争用的大幅减少，使得托管语言中的多线程代码能够快速运行。

### 统一的原则

从模拟宇宙到排序列表，从实现链表到设计[垃圾回收](@article_id:641617)器，一个单一、统一的原则浮现出来。程序员将内存视为简单[字节序](@article_id:639230)列的抽象视图是一个方便的谎言。底层的硬件是按块——缓存行——来操作的。[伪共享](@article_id:638666)就是因为编写的代码对这种基于块的现实一无所知而付出的性能代价。

解决方案，在其所有多样的形式中，总是关于*对齐*：将我们的[数据结构](@article_id:325845)和我们的劳动分工与硬件的底层架构对齐。有时这种对齐是空间的，通过添加填充或将数据划分为块来实现[@problem_id:3208560]。有时它关乎[算法](@article_id:331821)选择，比如逐行处理矩阵而不是逐列处理[@problem_id:2485959]。而有时，它是时间的，通过在本地缓冲写操作并分批合并来实现[@problem_id:3236478]。

即使在像矩阵乘法这样复杂的[算法](@article_id:331821)中，计算块边界处的[伪共享](@article_id:638666)可能与原始数据移动相比只是一个次要效应，但缓存感知设计的更广泛原则仍然至关重要。目标始终是为我们被迫移动的每一个[缓存](@article_id:347361)行，最大化其完成的有效算术工作量[@problem_id:3169795]。理解这一原则不仅仅是为了解决一个奇怪的性能问题。它是关于学习说机器的母语，并在此过程中，释放其[并行计算](@article_id:299689)的真正潜力。