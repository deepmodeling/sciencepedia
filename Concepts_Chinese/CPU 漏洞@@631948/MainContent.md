## 引言
现代中央处理器 (CPU) 被设计成坚固的堡垒，使用[特权级别](@entry_id:753757)和[内存保护](@entry_id:751877)等硬件强制规则，来安全地隔离程序与程序之间以及程序与[操作系统内核](@entry_id:752950)之间的关系。然而，对性能永不满足的需求导致了一些无意中造成了严重安全漏洞的设计选择。那些旨在让 CPU 更快的机制，特别是[推测执行](@entry_id:755202)和[乱序执行](@entry_id:753020)，催生了一类可以绕过这些传统芯片壁垒的新型漏洞。这迫使整个行业进行反思，将对速度的基本需求与同样关键的安全要求对立起来。

本文探讨了 CPU 漏洞这个深刻且常常充满悖论的世界。在接下来的章节中，我们将剖析性能与安全之间的核心冲突。“原理与机制”一节将解释 CPU 的安全堡垒是如何构建的，然后揭示[推测执行](@entry_id:755202)如何创造出“幽灵”——即留下可观察痕迹的瞬态计算，从而导致像 Spectre 和 Meltdown 这样的毁灭性攻击。随后，“应用与跨学科联系”一节将审视这些漏洞在现实世界中的影响、其缓解措施中涉及的昂贵权衡，以及它们与经典软件安全[范式](@entry_id:161181)的惊人联系，展示了相同的失效模式如何从芯片逻辑回响到高级程序设计。

## 原理与机制

要理解中央处理器 (CPU) 为何会存在漏洞，我们必须首先欣赏它被设计成的那个宏伟的安全堡垒。一台现代计算机不是一个单一、庞大的实体；它是一个熙熙攘攘的程序大都市，所有程序都在并发运行，每个程序都以为自己独占了整台机器。[操作系统](@entry_id:752937) (OS) 是市政府，应用程序是市民，而 CPU 则是这片土地的基本法则，由内置于芯片本身、不可腐蚀的警察部队来执行。

### 堡垒：芯片中的特权与保护

想象一下 CPU 第一次被唤醒的时刻。在这最初的几皮秒内，它处于其最强大、最特权的状态。它是一位神王，能够指挥系统的任何部分。但绝对的权力是危险的，尤其是当目标是为他人建造一个安全的城市时。这位神王的首要任务不是统治，而是建造自己的监狱——一套将限制自身权力以及所有后来者权力的规则。这就是**[安全启动](@entry_id:754616)**过程的精髓。

CPU 以其最高[特权模式](@entry_id:753755)（我们称之为 $P_0$）启动，必须首先为一个可能混乱的世界带来秩序。它通过屏蔽中断和停止其他硬件组件任何未经授权的直接内存访问 (DMA) 来消除所有外部干扰。在系统安静下来之后，它可以履行其最神圣的职责：验证即将加载的操作系统内核的身份，通常使用永久蚀刻在其[只读存储器](@entry_id:175074) (ROM) 中的加密公钥。一旦内核被验证，CPU 就开始建造堡垒的城墙。这是通过设置**页表**来完成的，页表充当所有内存的综合地图和规则手册 [@problem_id:3673061]。

这本规则手册由一个名为**[内存管理单元 (MMU)](@entry_id:751869)** 的关键硬件部件强制执行。可以把 MMU 想象成一个不知疲倦、廉洁正直的守门人，负责每一次内存访问。在任何指令可以从内存中读取、写入或获取另一条指令之前，它必须得到 MMU 的许可。页表告诉 MMU 谁拥有哪块内存，以及他们被允许对它做什么。属于内核的内存页被标记为**仅限监管者**；包含程序代码的页被标记为**读取-执行**；用于程序数据的页被标记为**读取-写入**，但至关重要的是，**不可执行 (NX)**，以防止攻击者诱骗 CPU 将恶意数据当作代码来运行。

一旦这些规则被写入，CPU 就会执行一次非凡的自我否定行为。它启用 MMU，使规则不可侵犯，然后在将控制权交给[操作系统内核](@entry_id:752950)之前，永久地将自己降级到一个较低的[特权级别](@entry_id:753757)（$P_1$，或监管者模式）。它自愿将自己锁在神级模式之外，确保即使是[操作系统](@entry_id:752937)也无法轻易撤销它已建立的基本保护。这就是**[最小权限原则](@entry_id:753740)**的实际应用。

这个系统运行得非常出色。如果一个运行在最低[特权级别](@entry_id:753757)（[用户模式](@entry_id:756388)）的用户应用程序试图访问属于内核的内存地址，MMU 守门人会立即介入。访问被阻止，不是因为软件检查，而是因为硬件本身禁止了它。该内核地址的 [PTE](@entry_id:753081)（页表条目）中有一个位，我们称之为 $u/s$ 位，被设置为“监管者”。MMU 看到[用户模式](@entry_id:756388)的请求和仅限监管者的页面，便会说：“访问被拒绝。”然后它会发出警报——一个**页错误**——通知内核这一越权行为。内核随后可以终止这个行为不当的应用程序。这不是一个错误；这是堡垒的防御系统在完美地工作 [@problem_id:3657694]。

然而，这个堡垒尽管坚固，却微妙地依赖于其最受信任的居住者——操作系统内核——的完整性。用户空间和内核空间之间的边界因合法原因被频繁跨越，通过[系统调用](@entry_id:755772)。这个转换过程必须处理得极其小心。想象一下内核将控制权交还给一个用户程序。它必须恢复用户的确切状态，包括一个名为**标志寄存器**的特殊寄存器。该寄存器包含控制 CPU 行为的位，例如用于调试的中断标志 ($IF$) 或陷阱标志 ($TF$)。如果内核在其退出序列中，在完成恢复所有其他寄存器*之前*恢复了用户的标志，它就创造了一个微小的漏洞窗口。在几条指令的时间里，内核代码在由用户控制的标志下执行。恶意用户可以设置 $IF$ 位，允许在内核处于不一致、部分恢复的状态时发生中断，从而导致崩溃。或者他们可以设置 $TF$ 位，引发一个调试陷阱，从而劫持内核的返回路径。[硬件保护](@entry_id:750157)是健全的，但软件的程序性失误仍然可能是致命的 [@problem_id:3640060]。

### 对速度的需求：与魔鬼的契约

如果我们的故事到此为止，CPU 会很安全，但也会非常慢。对性能的无情追求驱使 CPU 设计师们做出了一个浮士德式的交易。为了让程序运行得更快，他们制造的 CPU 不再是每次只执行一条指令。一个现代 CPU 核心是**并行性**的奇迹。即使只有一个软件线程在运行，硬件也可以同时处理多条指令，这一技巧被称为**[指令级并行 (ILP)](@entry_id:750672)**。如果一个程序有，比如说，100 条独立的指令，一个每周期可以执行两条指令的双发射 CPU 理论上可以在 50 个周期内完成工作，而不是 100 个周期，从而有效地将单个线程的性能提高一倍 [@problem_id:3627025]。

为了实现这一点，CPU 必须极其聪明。它会预先查看程序的指令流，并在指令的输入准备好时**[乱序](@entry_id:147540)**执行它们，而不是按照程序员编写的严格顺序。但最强大的技巧是**[推测执行](@entry_id:755202)**。

CPU 就像一位与时间对弈的国际象棋大师。它不能坐等对手的行动。它必须猜测最可能的走法，并提前分析多步之后的后果。这就是 CPU 在分支指令（`if-then-else` 语句）处所做的事情。它不知道条件会是真还是假。于是，它使用高度复杂的分支预测器进行预测，并**推测性地**执行预测路径下的指令。如果预测正确，它就节省了大量时间。如果预测错误，它只需丢弃推测性完成的工作，然后从正确的路径重新开始。在架构上，这就像什么都没发生过一样。处理器寄存器和内存的最终提交状态总是正确的。

这种丢弃“错误”工作的机制是关键。推测性计算是瞬态的；它们是幽灵，本应消失得无影无踪。现代 CPU 的漏洞在于一个单一的、毁灭性的事实：这些幽灵有时会留下脚印。

### 当幽灵留下足迹：[瞬态执行](@entry_id:756108)攻击

在[推测执行](@entry_id:755202)期间完成的工作，即使后来被清除，也可能对 CPU 的内部**[微架构](@entry_id:751960)**状态造成细微的改变。其中最重要的是**[缓存层次结构](@entry_id:747056)**。缓存是小而极快的存储体，用于存储最近使用的数据，以避免访问主内存的缓慢过程。当 CPU 推测性地执行一条从某个内存地址读取的指令时，该数据会被拉入缓存。如果后来发现推测是错误的，读取的结果会从架构寄存器中丢弃，但数据可能仍留在缓存中。

这就是脚印。攻击者可以使用**缓存[侧信道](@entry_id:754810)**来检测这个脚印。通过仔细地对内存访问进行计时，攻击者可以确定一块数据是在缓存中（访问速度快）还是在主内存中（访问速度慢）。如果攻击者能诱使 CPU 推测性地访问一个秘密内存位置，他们无法直接读取秘密，但他们可以使用一个“小工具”来执行*第二次*推测性访问，其地址依赖于秘密值。例如，他们可能会访问 `probe_array[secret_value]`。在 CPU 清除推测后，攻击者可以对 `probe_array` 的每个元素进行访问计时。那个访问速度异常快的元素就揭示了被用作其索引的秘密值 [@problem_id:3657995]。

这就是**[瞬态执行](@entry_id:756108)攻击**背后的一般原理。它们不是打破堡垒的城墙；而是诱骗一个幽灵穿墙而过，在另一边留下泥泞的脚印，然后他们可以从远处观察这些脚印。

### 两种漏洞的故事：Spectre 与 Meltdown

虽然它们都利用了[瞬态执行](@entry_id:756108)，但两种最著名的 CPU 漏洞，Spectre 和 Meltdown，在本质上是不同的生物。理解这一点的一个绝妙方法是想象一个拥有完美预测器的假想 CPU——一台其水晶球从不出错的机器 [@problem_id:3679342]。

**Spectre** 攻击通过毒化预测器来工作。例如，在 Spectre 变体 1（[边界检查](@entry_id:746954)绕过）中，攻击者反复使用一个有效的数组索引来调用一个函数，训练分支预测器预期索引会在边界内。然后，他们使用一个恶意的、越界的索引来调用它。预测器遵循其训练，推测检查会通过，并执行 `if` 块内的代码，瞬态地使用越界索引读取内存。这泄露了秘密。Spectre 从根本上说是一种对预测机制的攻击。在我们那个拥有完美预测器的假想世界里，误预测永远不会发生。CPU 永远不会推测性地走上错误的路径，因此，Spectre 将完全消失。

另一方面，**Meltdown** 即使在拥有完美预测器的 CPU 上也依然存在。Meltdown 并不利用误预测。它利用的是单条正确指令路径的[乱序执行](@entry_id:753020)中固有的[竞争条件](@entry_id:177665)。当一个用户程序试图读取一个仅限内核的内存地址时，CPU 为了急于完成任务，可能会在 MMU 的权限检查完全完成*之前*从内存中获取数据。在一个短暂的瞬态窗口内，秘密数据被转发给依赖它的指令。然后，权限检查完成，MMU 引发页错误，推测被清除。但为时已晚；幽灵已经触碰了缓存。根本原因在于硬件本身的操作顺序：为了性能，数据获取在权限检查最终确定之前就已启动。一个安全的设计会严格地先执行权限检查，阻止任何获取数据的尝试，但这会使 CPU 变慢 [@problem_id:3667139]。Meltdown 是一个因仓促而生的幽灵，而非因走错路而生。

理解这一区别有助于我们领会不同的缓解策略。针对 Spectre 的一种常见软件缓解措施是用一个**无分支**的等价物替换一个可预测的条件分支。例如，不用 `if (index  length)`，可以写成 `index = min(index, length - 1)`。这创造了一个**真数据依赖**。CPU 在 `min` 操作的结果可用之前，无法计算内存访问的地址。它被迫等待，从而防止了使用越界索引进行推测。这巧妙地将一个可被推测性绕过的[控制依赖](@entry_id:747830)换成了一个不可绕过的数据依赖。然而，这种缓解措施对 Meltdown 毫无作用，因为后者是一个正交的问题 [@problem_id:3679377]。

这些原理是普适的，即使在最复杂的环境中也同样适用。在虚拟化系统中，[虚拟机](@entry_id:756518)监控程序使用第二层页表（称为[扩展页表](@entry_id:749189)或 EPT）来相互隔离整个客户机[操作系统](@entry_id:752937)。然而，像 L1TF (Foreshadow) 这样的漏洞表明，如果秘密数据恰好在 L1 缓存中，[瞬态执行](@entry_id:756108)甚至可以绕过这些 EPT 保护，从而泄露来自主机或其他客户机的数据。事实证明，幽灵可以穿过一整套新维度的墙壁 [@problem_id:3657995]。

CPU 漏洞的故事并非源于粗制滥造。这是一个警世故事，讲述了在不懈追求性能的过程中引入的复杂性所带来的深刻且常常无法预见的后果。安全性的架构堡垒是坚固的，但萦绕在其殿堂中的[微架构](@entry_id:751960)幽灵已被证明是真实存在的，迫使我们重新思考我们构建快速且安全处理器的根本基础。

