## 应用与跨学科联系

理解了[控制组](@entry_id:747837)的原理和机制后，人们可能会想：这些仅仅是系统管理员的巧妙技巧，还是代表了更深层次的东西？答案是，cgroups 是现代计算的基石之一。它们是那种沉默、不起眼的机制，使得从您喜爱的网络服务的响应性能到全球云的宏观结构都成为可能。让我们踏上一段旅程，看看这个关于资源计量和限制的简单理念如何绽放出丰富的应用图景，横跨[性能工程](@entry_id:270797)、安全以及分布式系统的宏大挑战。

### 驯服单台机器的艺术

我们的旅程始于一台服务器，它是随处可见的资源争用挑战的缩影。想象一台服务器运行两种任务：白天，它处理交互式用户请求，速度至关重要；夜晚，它运行一个繁重的批处理作业，比如压缩一个大型数据库。没有任何控制，批处理作业很容易窃取资源，使交互式服务变得迟缓。我们如何执行一项明智的策略呢？

这就是[性能工程](@entry_id:270797)艺术与 cgroups 科学相遇的地方。我们可以将交互式任务放在一个 cgroup 中，将批处理作业放在另一个中。通过对交互式工作负载进行建模，或许可以利用排队论的原理，我们可以计算出满足特定性能目标（例如将平均响应时间保持在 $0.15$ 秒以下）所需的*确切* CPU 时间。然后，cgroup CPU 控制器就成为我们实施这一策略的工具，允许我们为交互式组分配精确的处​​理能力配额，从而保证其性能，而批处理作业则使用剩余的资源。Cgroups 将一个模糊的业务目标——“网站必须快”——转化为一个具体、可强制执行的数字 ([@problem_id:3623643])。

这种公平原则超越了 CPU。考虑一下“吵闹邻居”问题，这是多租户环境中的一个经典难题。一个容器可能会开始执行大量的磁盘操作，使存储设备饱和，导致所有其他容器的 I/O 资源饥饿。在这里，cgroups 再次提供了解决方案。I/O 控制器允许我们为不同的组分配权重。通过应用加权公平队列模型，我们可以为关键应用程序分配更高的权重，确保无论吵闹的邻居行为多么激进，它们都能获得公平的磁盘[吞吐量](@entry_id:271802)份额 ([@problem_id:3685789])。我们甚至可以设计一个策略，为我们的重要服务保证特定的吞吐量，将混乱的自由竞争转变为一个可预测且有序的系统。

但如果一个程序不仅仅是吵闹，而是恶意的呢？Cgroups 构成了关键的防线。想一想“fork 炸弹”，一个简单但恶劣的程序，它除了创建自己的副本外什么也不做，以指数方式消耗进程槽和内存，直到整个系统陷入停顿并崩溃。将不受信任的代码放入 cgroup 中，并使用 `pids.max` 控制器对其可以创建的进程数量设置严格限制，就能立即拆除这颗炸弹 ([@problem_id:3673328])。

威胁可能更微妙。攻击者可能会编写一个程序，分配大量内存然后快速访问所有这些内存，迫使[操作系统](@entry_id:752937)进入“交换[抖动](@entry_id:200248)”状态，即[操作系统](@entry_id:752937)把所有时间都花在 [RAM](@entry_id:173159) 和磁盘之间移动数据上。这能让一台强大的服务器瘫痪。如果允许攻击者使用[交换空间](@entry_id:755701)，一个简单的 cgroup 内存限制可能不足够。真正稳健的解决方案是使用 cgroups 创建一个密闭的牢笼：我们设置一个硬内存限制 (`memory.max`)，并且至关重要的是，将交换限制设为零 (`memory.swap.max=0`)。现在，当攻击者的内存使用达到其极限时，它无处可去。内核不会让整个系统不稳定，而是简单地终止其 cgroup 内的违规进程，使系统的其余部分不受伤害 ([@problem_id:3685397])。

这个单机堡垒的最后一层是 `devices` 控制器。一个容器应该只能与其绝对需要的设备交互。它没有理由从 `/dev/sda` 读取原始磁盘块或通过 `/dev/kmem` 访问内核内存。`devices` 控制器充当一个严格的守门人。通过遵循“默认拒绝”策略，并且只将少数几个基本设备列入白名单——比如用于丢弃输出的 `/dev/null` 或用于加密的 `/dev/urandom`——我们在硬件层面强制执行[最小权限原则](@entry_id:753740)，从而极大地缩小了容器的攻击面 ([@problem_id:3665396])。

### 现代云的诞生：编排与抽象

在单台机器上，cgroups 提供了秩序和安全。但当我们放大到数据中心的规模，一个由像 [Kubernetes](@entry_id:751069) 这样的容器编排器管理的[世界时](@entry_id:275204)，它们的真正威力才显现出来。编排器的主要工作是玩一场宏伟、持续的俄罗斯方块游戏：它接收成千上万个容器，每个都有自己的 CPU 和内存需求，并试图将它们装配到一组节点集群上。

这整个宏伟的事业都建立在一个单一、根本性的契约之上：调度器的决策必须是可强制执行的。当编排器将一个容器放置在一个节点上，并承诺给它 $2$ 个 CPU 核心和 $4$ GiB 内存时，必须有某种东西来确保这个承诺得到遵守。那个“东西”就是 cgroups。定义调度器[装箱问题](@entry_id:276828)的约束——例如，一个节点上分配给所有容器的 CPU 总和不能超过该节点的能力——不仅仅是抽象的数学；它们是对该节点上 cgroup 控制器将要强制执行的内容的直接建模 ([@problem_id:3628616])。Cgroups 提供了使集群编排的整个抽象成为可能的基准真相。

这种联系使我们能够将高层的业务策略转化为底层的现实。一个组织可能会为其应用程序定义优先级类别：“白金”、“黄金”、“白银”。当它们竞争时，“白金” pod 应始终比“黄金” pod 获得更多的 CPU 时间。编排器的开发者必须创建一个从这些抽象类别到具体[操作系统](@entry_id:752937)参数的映射。这变成了一个有趣的​​应用数学练习：找到一个将优先级映射到 cgroup `cpu.weight` 值的函数。该函数必须是单调的（更高优先级意味着更高权重），但它也必须满足公平性界限，确保高优先级作业不会完全饿死低优先级作业。例如，我们可能要求一个“白银” pod 在与单个“黄金” pod 竞争时，总能获得至少（比如说）30% 的 CPU。这个约束对权重之间的差距设置了数学上的限制 ([@problem_id:3671525])。

这种编排不仅用于运行应用程序；它对系统自身的生命周期也至关重要。当一台机器启动时，数十个服务必须以正确的顺序和正确的优先级启动。现代的 init 系统，如 `systemd`，广泛使用 cgroups 来管理这个复杂的舞蹈。它们将关键服务（如存储和网络）放在一个高优先级的“启动关键”切片中，而将可延迟的后台服务放在另一个切片中。通过调整 cgroup 控制器——为关键切片提供高 CPU 和 I/O 权重，用 `memory.low` 保护其内存工作集，并用 `memory.high` 温和地节流非关键服务——操作员可以确保最快、最可靠的启动过程 ([@problem_id:3686029])。

### 推动前沿：专用硬件与[分布](@entry_id:182848)式[不变量](@entry_id:148850)

cgroups 的影响范围甚至更广，延伸到硬件和[分布式计算](@entry_id:264044)的前沿。当一个容器需要访问标准 Linux 内核不管理的资源，比如图形处理单元（GPU）时，会发生什么？标准的内存和 CPU cgroups 对 GPU 的 V[RAM](@entry_id:173159) 及其流式多处理器是盲目的。

这就是 cgroup 模型作为一个更大生态系统一部分的灵活性所在。获得访问权需要一个合作之舞。一个了解 GPU 的专用容器运行时，必须将 NVIDIA 设备文件（例如 `/dev/nvidia0`）暴露到容器的命名空间中。然后，`devices` cgroup 控制器必须被配置为允许访问这些特定的字符设备。虽然标准 cgroups 无法限制容器的 VRAM 使用，但像 Multi-Instance GPU（MIG）这样的先进硬件功能可以将一个物理 GPU 分割成隔离的硬件实例。然后，专用运行时可以只将一个实例暴露给一个容器，提供一种与 cgroup 框架互补的强大隔离形式 ([@problem_id:3665357])。

也许 cgroups 最令人叹为观止的应用是在一个混乱的[分布](@entry_id:182848)式世界中执行全局规则。想象一个云提供商想要为一个客户强制执行一个全局 CPU 限制——比如，他们在全球数千台机器上的总使用量不得超过 $1000$ 个核心。没有任何一台机器能单独强制执行这个规则。这是一个分布式系统问题。解决方案是[操作系统](@entry_id:752937)级机制与共识理论的美妙结合。一个使用像 Raft 这样的协议的复制[状态机](@entry_id:171352)，充当中央大脑，对如何将全局 $1000$ 核心的预算分配给各个节点做出权威决策。

但如果一个节点因网络分区而暂时与网络断开连接怎么办？中央大脑可能会宣布它“死亡”，撤销其（比如说）$50$ 个核心的配额，并将其重新分配给另一个节点。被分区的节点仍然存活，它不会知道这一点，并将继续执行其 $50$ 核心的限制。如果新节点立即开始使用其更大的配额，全局限制就会被违反。解决方案是以有时限的*租约*形式授予资源。中央大脑使用共识机制，向一个节点提交一个只在特定时间窗口内有效的租约，例如从时间 $t_{start}$ 到 $t_{end}$。要重新分配配额，它必须等待旧租约在所有地方都过期。关键的是，为了安全起见，它必须考虑到机器之间的[时钟偏斜](@entry_id:177738)。新的租约只能在一个大于 $t_{end} + 2\Delta$ 的时间开始，其中 $\Delta$ 是最大[时钟偏斜](@entry_id:177738)。这个保护带保证了在时钟慢的分区节点上，旧租约在实时上已经过期，然后新租约才能在时钟快的节点上开始。在每台机器上，本地 cgroup 控制器是其当前有效租约所定义配额的最终、忠实的执行者 ([@problem_id:3627682])。同样的逻辑，即使用 cgroups 来执行[全局优化](@entry_id:634460)的策略，也适用于管理其他共享资源，比如系统的页面缓存，我们必须在容器间的公平性与系统整体效率的目标之间取得平衡 ([@problem_id:3668008])。

从一个简单的分区工具，cgroups 已经成为表达和执行资源策略的通用语言。它们是容器化、云编排和大规模[分布式系统](@entry_id:268208)这些宏伟建筑得以建立的基石。它们提供了控制的基本原语，使我们能够以先前难以想象的规模构建可靠、安全和高效的系统。