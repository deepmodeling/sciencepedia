## 应用与跨学科联系

在我们探索了多处理的基本原理之后，你可能会有一种整洁的感觉，仿佛置身于一座组织有序的理论殿堂。但物理学，乃至所有科学的真正乐趣，不仅在于欣赏这座殿堂，更在于推开大门，看它如何与广阔、纷繁、奇妙的现实世界相连。非对称多处理（Asymmetric multiprocessing, AMP）不仅仅是一种抽象的架构奇观，它是一种正在悄然重塑我们数字世界的设计哲学，从你口袋里的手机到支撑互联网的庞大数据中心。它的美在于它为一个基本事实提供了优雅的解决方案：并非所有的计算工作都是生而平等的。一个管弦乐队不是由80把相同的小提琴组成的，而是由弦乐、铜管、木管和打击乐器精心融合而成，每一种乐器都演奏着最适合自己的声部。同样，一个现代处理器也可以是一曲由专门化核心组成的交响乐。

### 攻克瓶颈的艺术

这正是 AMP 最初的应用方式。在许多计算任务中，尤其是在流式工作负载中，工作被分解为一系列顺序阶段的流水线。一个对称多处理（Symmetric multiprocessing, SMP）系统可能会将这些阶段分配给两个或多个相同的核心。但如果工作不能完美划分，一个核心将不可避免地承担更重的负载，成为整个流水线的瓶颈。然而，AMP 系统可以施展一个巧妙的技巧：它识别出这个瓶颈阶段，并将其分配给一个强大的“大”核。即使大核只是适度快一些，这种有针对性的加速也足以重新平衡流水线并提高整体[吞吐量](@entry_id:271802)，证明了智能资源分配可以比蛮力更有效 [@problem_id:3683239]。

这个原理从简单的数据流水线延伸到我们软件的根本结构。计算机科学中一个著名的观察，即[阿姆达尔定律](@entry_id:137397)（Amdahl's Law），告诉我们程序的加速比最终受限于其顽固的串行、不可并行的部分。这个串行部分是一个普遍的瓶颈。可以把它想象成一个狭窄的关口，所有交通都必须一次一辆车地通过。在软件中，这通常表现为“[临界区](@entry_id:172793)（critical section）”，即一段操作共享数据的代码，必须由一个锁来保护，一次只允许一个线程执行。当你增加越来越多的核心时，线程就会堆积起来，等待通过这个关口。系统性能无法扩展，只是造成了交通堵塞。

在这里，AMP 提供了一个绝妙的解决方案。智能调度器不是让线程在缓慢的通用核心上争夺锁，而是可以将所有临界区代码分派到一个单独的大核上。这个核心就像一个高效的收费站操作员。因为它执行串行代码的速度快得多，它极大地减少了在“关口”的服务时间，从而消除了等待线程的队列。其结果不仅仅是适度的加速，而是系统[可扩展性](@entry_id:636611)的根本性改变，将一个高竞争的交通堵塞变成了畅通无阻的高速公路 [@problem_id:3683313]。

### 专门化：为任务选择合适的工具

非对称性的力量远不止是简单地“更快”。大核可能不仅仅有更高的时钟速度，它可能在性质上就有所不同，拥有特殊的能力。考虑[网络路由](@entry_id:272982)器的任务，它必须在存储于内存中的一个巨大表格里查找数据包的目的地。这个任务的限制因素往往不是处理器的计算速度，而是[内存延迟](@entry_id:751862)——从遥远的内存芯片中获取数据所需的时间。一个标准核心可能会发出一个内存请求，然后闲置等待数据返回。然而，一个专门的“大”核可能被设计有深度缓冲区和复杂的逻辑，可以同时管理许多内存请求，这个特性被称为高[内存级并行](@entry_id:751840)性（$k$）。在等待一个请求的同时，它可以处理其他请求。它不仅仅是更快，它更擅长*隐藏延迟*。

用于网络处理器的 AMP 设计可以利用这一点，将这样一个大核专用于内存密集型的查找任务，而由一队更小、更节能的核心来处理计算密集型的报文解析和[分类任务](@entry_id:635433)。系统的吞吐量则由查找引擎获取数据的能力（$k/L$，其中 $L$ 是[内存延迟](@entry_id:751862)）和小核处理数据的能力（$S/t_c$，其中 $S$ 是小核数量，$t_c$ 是它们处理每个数据包的计算时间）之间的平衡所决定。这种功能上的分工是复杂、高性能[系统设计](@entry_id:755777)的标志 [@problem_id:3683250]。

我们可以将这种专门化的思想推向逻辑的极致，得到一个许多人都熟悉的东西：图形处理单元（Graphics Processing Unit, GPU）。一个同时拥有 CPU 和 GPU 的现代计算机系统是终极的非对称多处理器。GPU 是一个大规模并行的猛兽，对于某些类型的计算非常出色，但它位于一个相对较慢的总线之上。要使用它，你必须支付一种“税”：将数据传输到 GPU 的时间（$T_{H2D}$）和取回结果的时间（$T_{D2H}$）。将任务从 CPU 的大核卸载到 GPU 的决定归结为一个基本的不等式。GPU 巨大的速度优势 $k$ 是否足以克服总传输时间？这个盈亏[平衡点](@entry_id:272705)，即卸载时间等于大核执行时间的点，定义了 GPU 对于一个给定问题变得有用所需的最小速度因子 $k^{\star}$。这个简单的模型支配着整个[异构计算](@entry_id:750240)领域，从[科学模拟](@entry_id:637243)到视频游戏 [@problem_id:3683252]。

这种权衡正是现代人工智能的核心。训练一个机器学习模型涉及巨大的计算量，但这项工作的一大部分 $f_{\mathrm{BLAS}}$，通常集中在[标准化](@entry_id:637219)的线性代数运算（BLAS 内核）中。一种方法是在许多相同的 SMP 核心上[并行化](@entry_id:753104)这些内核。然而，协调这些核心会引入同步开销，这会蚕食[并行化](@entry_id:753104)的好处。另一种 AMP 策略是，将这些内核交给一个为这类数学运算优化的、强大的大核。如果大核的加速比 $k$ 足够大，且 SMP 线程的开销很显著，这种更简单的 AMP 方法可能会出人意料地胜出。这是一个绝佳的例子，说明了有时一个出色的独奏家可以胜过一个争吵不休的委员会 [@problem_id:3683296]。

### 当对称性反击时：一个警示故事

以免我们对非对称性过于着迷，我们必须牢记它并非万能药。一个考虑不周的 AMP 设计可能会产生新的问题，有时甚至会使事情变得更糟。以 MapReduce 等框架为代表的[大规模数据分析](@entry_id:165572)领域提供了一个极好的教训。一个典型的作业有一个“Map”阶段，其中输入数据被[并行处理](@entry_id:753134)；还有一个“Reduce”阶段，其中结果被聚合。

有人可能会天真地设计一个 AMP 系统，让一组小核处理易于并行的 Map 阶段，而一个强大的大核处理最后的 Reduce 阶段。这看起来很合乎逻辑。然而，这忽略了一个关键的中间步骤：“Shuffle”，即所有 mapper 的中间数据通过网络传输给 reducer。在我们的 AMP 设计中，只有那个单独的大核在拉取这些数据，从而造成了巨大的[网络瓶颈](@entry_id:167018)。而一个相应的 SMP 系统，虽然使用较慢的核心，但可能在所有核心上运行 reducer。每个 reducer 并行地拉取自己那份数据。在这种情况下，SMP 系统卓越的并行 I/O 能力可以完胜 AMP 系统，后者尽管拥有强大的大核，却只能等待数据通过单通道网络路径缓慢爬行。这是一个严峻的提醒：必须分析*整个*系统，包括计算、内存和网络，才能真正理解性能 [@problem_id:3683324]。

### 超越速度：构建更优的系统

也许 AMP 最深远的应用与原始速度关系不大，而更多地与构建更稳健、可预测和安全的系统有关。核心类型的物理分离为隔离提供了一个强大的工具。

考虑支撑着所有[云计算](@entry_id:747395)的[虚拟化](@entry_id:756508)世界。客户[虚拟机](@entry_id:756518)（VM）运行在 hypervisor 之上，但某些操作，如处理硬件中断，会强制触发“VM-exit”——一次到 hypervisor 的昂贵的[上下文切换](@entry_id:747797)。如果 hypervisor 的控制平面与客户机运行在相同的核心上，其活动可能会引发一场中断风暴，从而降低客户机的性能。AMP 架构允许我们将控制[虚拟机](@entry_id:756518)固定在一个专用的大核上。这为在其他核心上运行的客户[虚拟机](@entry_id:756518)创造了一个“安静的邻里”。它们经历的由外部中断引发的退出次数急剧下降，从而直接且可衡量地提高了它们的有效性能，具体表现为更低的[每指令周期数](@entry_id:748135)（Cycles Per Instruction, [CPI](@entry_id:748135)）[@problem_id:3683285]。

这种隔离原则在混合关键系统（mixed-criticality systems）中至关重要，例如汽车或飞机中的系统，其中生死攸关的任务与非关键任务并存。在 SMP 系统中，如果一个高优先级任务突然需要比预期更多的计算（即“过载”），它会窃取所有其他任务的周期，可能导致低优先级（但仍然重要）的任务错过其截止时间。AMP 提供了一个天然的防火墙。高关键性任务被固定在大核上，该核心有预留的容量余量。低关键性任务被放置在小核上。如果高关键性任务出现过载，它们会消耗其预留余量并可能使大核饱和，但它们无法触及小核。这种物理隔离保证了低关键性工作负载不受影响，提供了一种在纯对称系统中无法实现的的可预测性和安全性 [@problem_id:3683294]。

这种将一个核心专门用于关键系统服务的思想也出现在其他领域。高性能数据库依赖一种称为预写日志（Write-Ahead Logging, WAL）的技术来确保[数据完整性](@entry_id:167528)。在对数据库进行任何更改之前，更改记录会被写入一个稳定的日志中。这个过程涉及计算（准备日志记录）和 I/O（将其刷新到磁盘），可能会成为一个瓶颈。通过将所有 WAL 处理卸载到一个专用的大核上，我们实现了两件事。首先，我们加速了计算部分。更重要的是，我们创建了一个优美的两阶段流水线：大核准备日志记录 $N+1$ 的同时，存储设备正忙于写入记录 $N$。这种流水线操作将处理器与缓慢的 I/O 设备解耦，极大地提高了系统的整体事务[吞吐量](@entry_id:271802)，即使单个事务的延迟仅有适度改善 [@problem_id:3683274]。

最后，在安全威胁无处不在的时代，AMP 已成为一种安全架构。我们可以建立一项策略，即从互联网下载的不可信代码只被允许在“小”核上运行，这些小核可以设计有额外的沙箱和权限限制。一个强大的大核可能因漏洞导致系统级[权限提升](@entry_id:753756)的概率更高，为 $p_b$，而一个经过加固的小核则有低得多的概率 $p_s$。在一个 SMP 系统中，不可信代码可以落在任何核心上，总风险是一个加权平均值。而在一个强制执行这种隔离的 AMP 系统中，风险被限制在小核的较低水平。通过牺牲不可信代码的性能，我们可以确凿地降低发生灾难性系统泄露的概率，将硬件架构本身用作一道防线 [@problem_id:3683315]。

从攻克性能瓶颈到实现安全、可预测的[实时系统](@entry_id:754137)，非对称原理证明了专门化的力量。它标志着计算机架构从追求统一、蛮力的能力，转向一种更细致、更智能、更和谐的计算方法。