## 引言
在现代计算世界中，同时管理多个任务已非奢侈，而是必需。这一基本的并发挑战传统上是通过锁来解决的，这是一种线程必须排队等待以访问共享资源的机制。虽然概念简单，但这种方法充满了风险，如[死锁](@entry_id:748237)、性能瓶颈和[优先级反转](@entry_id:753748)（即高优先级任务可能被低优先级任务阻塞）。这些限制阻碍了我们构建真正可扩展和高响应性软件的能力。

本文探讨了一种更优雅、更强大的[范式](@entry_id:161181)：非阻塞并发。这是一种无需等待的协调哲学，在这种哲学中，进度总是可能的。通过利用硬件提供的特殊[原子指令](@entry_id:746562)，我们可以设计出能够抵御单个线程延迟和失败的算法，从而确保整个系统持续前进。接下来的章节将引导您深入了解这一[范式](@entry_id:161181)，从其基本概念到其在现实世界中的影响。

在“原理与机制”一章中，我们将解构构成非阻塞设计基础的核心原子操作和进度保证。我们还将直面由此产生的微妙但关键的挑战，如[内存管理](@entry_id:636637)和 ABA 问题等逻辑错误。随后，在“应用与跨学科联系”一章中，我们将看到这些原理的实际应用，探索非阻塞技术如何成为驱动一切的无形引擎——从[操作系统内核](@entry_id:752950)和高速网络，到组织世界信息的复杂数据库。

## 原理与机制

想象一下，几位钟表匠同时制造一块复杂的时钟。传统方法是执行一个简单的规则：一次只有一个人可以触摸时钟。他们必须拿到一个特殊的信物——一把“锁”——完成自己的部分，然后把信物放回去。这种方法安全，但速度慢。当一个人在小心翼翼地放置齿轮时，其他所有人都在等待。如果拿着信物的人去喝咖啡了怎么办？整个项目就会陷入[停顿](@entry_id:186882)。简而言之，这就是基于锁的并发世界，它充满了危险：[死锁](@entry_id:748237)、[优先级反转](@entry_id:753748)和可扩展性瓶颈。

非阻塞并发提供了一种截然不同，而且坦率地说更优美的哲学。如果每个钟表匠不是等待信物，而是可以直接走到时钟前，*尝试*安装自己的零件呢？如果他们需要的位置是空的，他们就能在一个瞬间完成的、单一的动作中将齿轮装入。如果不是——也许是因为其他人刚刚在那里装了一个齿轮——他们的尝试就会失败。他们不会等待，而只是看到时钟的新状态，然后重新思考下一步行动。没有人会阻塞任何人。整个系统不断取得进展。这就是非阻塞同步的核心。

### 并发不是并行

在我们深入探讨之前，必须澄清一个常见的混淆。让我们来谈谈一个在只有单核 CPU 的计算机上运行的事件驱动型 Web 服务器。该服务器正在处理三个客户端请求。每个请求都涉及从磁盘读取数据，然后进行一些计算。我们的服务器是单线程的；它一次只能执行一段代码。那么，它是否表现出并行性？不。**并行（Parallelism）**是指*同时做*多件事情。只有一个核心，你在任何一个瞬间只能*做*一件事。我们服务器代码的并行度严格为 1。

但它是否是并发的？当然是。**并发（Concurrency）**是指*同时管理*多件事情。当我们的服务器为客户端 A 发出一个非阻塞的磁盘读取请求时，它不会等待。[操作系统](@entry_id:752937)和磁盘控制器会在后台处理该任务。服务器立即可以为客户端 B 发出读取请求，然后再为客户端 C 发出请求。此时，服务器的单线程可能处于空闲状态，但三个不同的任务——A、B 和 C 的磁盘读取——都处于“进行中”。它们的生命周期是重叠的。服务器正在并发地处理三个请求。我们甚至可以量化这一点：如果我们测量一个时间间隔内处于活动状态（已到达但尚未完成）的平均请求数，我们可能会发现并发深度为 2.2，尽管 CPU 并行度仍然为 1 [@problem_id:3627060]。非阻塞技术就是让单个代理能够管理一个充满并发任务的世界的魔法。

### 原子工具箱

要构建这些非阻塞的奇迹，我们不能使用普通指令。我们需要特殊的、在 fleeting moment 内拥有至高无上权力的工具。这些就是**[原子操作](@entry_id:746564)（atomic operations）**，处理器保证它们会作为一个单一的、不可分割的步骤来执行。没有其他线程可以在中途打断它们。

其中最著名的是**[比较并交换](@entry_id:747528)（Compare-And-Swap）**，简称 **CAS**。你可以把它想象成一个谨慎而迅速的更新操作。你告诉处理器：“去看看内存地址 *P*。我期望在那里找到值 *E*。如果，且仅当你找到 *E* 时，才用我的新值 *N* 替换它。在一次不可中断的动作中完成这一切。”处理器会返回一个简单的“是”或“否”。如果是“是”，你就知道你的更改已生效。如果是“否”，则意味着在你工作时，有别人更改了 *P* 地址的值。你没有等待；你只是发现世界发生了变化，现在你必须做出反应——通常是用新的信息重新开始你的尝试。

我们工具箱中的另一个瑰宝是**取并加（Fetch-And-Add, FAA）**。想象一下面包店里的取号机。每个顾客取一个号码。`FetchAndAdd(Counter, 1)` 正是这样做的：它访问一个内存位置，将其值加 1，并且——这是关键部分——返回它被增加*之前*的值。这是一种完全公平、[原子化](@entry_id:155635)的方式来分发唯一的工作任务。如果十个线程在一个初始化为零的计数器上调用 FAA，它们将以某种顺序得到 0, 1, 2, ..., 9 这些数字，没有重复，也没有遗漏。这非常适合分发工作，比如告诉并发搜索中的线程接下来要检查哪个数组索引 [@problem_id:3244948]，或者构建一个简单、极速的共享计数器 [@problem_id:3664080]。

### 进度保证的层级

有了像 CAS 和 FAA 这样的工具，我们就可以设计出永远不需要锁的算法。但“非阻塞”并非单一的保证；它是一系列进度条件的集合，一个从弱到强的承诺阶梯。

#### 无阻碍
这是最基本的承诺：如果任何线程在隔离执行有限步数后，保证能完成其操作，那么该算法就是**无阻碍的（obstruction-free）**。这就像说：“如果你们都别来烦我，我保证能完成。”问题在于，它在竞争下不提供任何保证。想象两个线程 $T_1$ 和 $T_2$ 试图更新一个值。一个恶意的调度器可以让 $T_1$ 运行到快要完成时，然后抢占它并运行 $T_2$，而 $T_2$ 的操作会导致 $T_1$ 在恢复时尝试失败。调度器可以无限重复这种舞蹈，导致两个线程永远空转，无法取得进展。这种状态称为**[活锁](@entry_id:751367)（livelock）**。即使线程在忙于执行指令，也没有任何操作能完成 [@problem_id:3663978]。

#### 无锁
这是一个更有用的保证。如果在一个算法中，经过任意有限步数后，系统中至少有一个线程完成了操作，那么该算法就是**无锁的（lock-free）**。它保证了系统范围的进度。整个系统不会陷入[活锁](@entry_id:751367)状态。经典的 Michael-Scott 非阻塞队列就具有此属性 [@problem_id:3627064]。如果多个线程试图同时入队一个项目，它们都会尝试对 `tail` 指针执行 CAS 操作。只有一个会成功，但这次成功意味着*系统*取得了进展。

然而，无锁并不能保护单个线程。你的线程可能会病态地不幸，由于其他线程总是抢先一步，导致它的 CAS 尝试一次又一次地失败。这被称为**饥饿（starvation）**。因此，虽然系统是健康的，但你的线程可能永远无法完成其工作。在许多通用系统中，这是一个可接受的权衡。

#### [无等待](@entry_id:756595)
这是非阻塞进度的黄金标准。如果一个算法保证*每个*线程都能在有限的自身步数内完成其操作，而不管其他线程的速度或调度如何，那么它就是**[无等待](@entry_id:756595)的（wait-free）**。饥饿是不可能的。这是一个非常强的保证。

如何实现这一点？考虑更新一个向量时钟，其中 $N$ 个线程中的每个线程只负责递增自己的槽位 $C[i]$ [@problem_id:3663956]。如果线程 $i$ 使用单个 `FetchAndAdd(C[i], 1)` 来执行其更新，该操作就由一个原子的、硬件保证的步骤组成。它将在有限的时间内完成，无论其他 $N-1$ 个线程在做什么。它是[无等待](@entry_id:756595)的。与之对比的是一种将整个向量打包成一个字并使用 CAS 循环更新的方法。那种方法仅仅是无锁的，因为你的 CAS 可能会因为其他线程的更新而反复失败。

这些保证之间的区别具有深刻的实际意义。考虑一个硬实时系统，比如汽车的制动控制器，它必须满足严格的最[后期](@entry_id:165003)限。你可能会认为“非阻塞”堆栈比锁更好。但是一个无锁（但非[无等待](@entry_id:756595)）的堆栈并不能提供重试次数的上限，这意味着其最坏情况执行时间（WCET）是无限的！你无法用它来保证最[后期](@entry_id:165003)限。与直觉相反，一个设计良好的、带有[优先级继承](@entry_id:753746)的[互斥锁](@entry_id:752348)*可以*提供有界的阻塞时间，从而允许你计算出有限的 WCET 并保证最[后期](@entry_id:165003)限 [@problem_id:3663951]。非阻塞并非总是更好；具体的保证才重要。

### 机器中的幽霊

当我们逃脱了锁的明显危险时，我们会遇到一些更微妙、如同幽灵般困扰着非阻塞并发世界的问题。

#### ABA 问题
这是最著名的幻影。想象一个线程 $T_1$ 想要更新一个堆栈。它读取栈顶指针，该指针持有地址 `A`。然后它准备好新节点，准备执行 `CAS(top, A, new_node)`。但在它执行之前，调度器让它进入睡眠状态。

当 $T_1$ 沉睡时，线程 $T_2$ 出现了。它弹出地址为 `A` 的节点，推入一个新节点 `B`，然后——在一个关键的转折中——弹出 `B`。地址为 `A` 的节点现在是空闲的，[内存分配](@entry_id:634722)器将相同的地址 `A` 分配给一个全新的节点，然后 $T_2$（或其他某个线程）将这个新节点推入堆栈。从外部看，`top` 指针再次持有了值 `A`。

现在，$T_1$ 醒来。它执行 `CAS(top, A, new_node)`。比较 `top == A` 成功了！CAS 完成，$T_1$ 破坏了堆栈，因为它看到的 `A` 和现在存在的 `A` 代表了两个完全不同的节点。

解决方案是防止内存地址以这种方式“转世”。我们使用**版本戳（version stamping）**，也称为带标签的指针。我们不再只存储地址 `A`，而是存储一个对：$(A, \text{version})$。每次修改指针时，我们都增加版本号。现在的序列看起来是这样的：
1. $T_1$ 读取 $(A, v)$。
2. $T_2$ 弹出 `A`，推入 `B`，弹出 `B`，然后在地址 `A` 处推入一个新节点。`top` 指針现在是 $(A, v+k)$，其中 $k>0$。
3. $T_1$ 醒来并执行 `CAS(top, (A, v), ...)`。比较失败了，因为当前版本 $v+k$ 与其期望的版本 $v$ 不匹配。ABA 问题得以避免 [@problem_id:3244948] [@problem_id:3627064]。

#### 内存重排序与栅栏
现代处理器就像过分热心的助手：为了提高性能，它们经常对你的指令进行重排序。假设一个线程在搜索中找到了匹配项，其逻辑是：(1) `result = 42`；(2) `found = true`。另一个线程正在等待 `found` 变为 true，然后读取 `result`。如果处理器重排了写操作怎么办？第二个线程可能会在 `result` 中 `42` 这个值可见*之前*看到 `found` 变为 true。它会读取一个陈旧或未初始化的值，程序就会失败。

为了防止这种情况，我们需要建立栅栏。**[内存排序](@entry_id:751873)语义（Memory ordering semantics）**是给编译器和处理器的指令，禁止跨越“栅栏”进行某些类型的重排序。最常见的模式是**释放-获取（release-acquire）**。
- 一个线程在 `found` 标志上执行**写-释放（write-release）**。这告诉处理器：“确保我程序中在此之前的所有内存写入都已完成并可见，然后再使这个写-释放操作可见。”
- 另一个线程在 `found` 标志上执行**读-获取（read-acquire）**。这告诉处理器：“在远程写-释放的值可见之前，不要执行我程序中在此读-获取操作之后的任何内存操作。”

它们共同创建了一种“happens-before”关系。一旦读取线程看到 `found` 为 true，写入 `result` 的操作保证对它可见 [@problemid:3244948]。

### 清理小组：[内存回收](@entry_id:751879)

在一个[无锁数据结构](@entry_id:751418)中，当你删除一个节点时，你不能立即释放它的内存。为什么不呢？因为另一个线程可能刚刚读取了指向该节点的指针，并且正准备解引用它。释放内存会导致那个线程崩溃。这是实践中非阻塞设计最棘手的问题。我们需要一种安全的方法来知道一个被删除的节点何时不再被*任何*线程查看。两种主要策略应运而生 [@problem_id:3664164]。

#### 风险指针
想象每个线程都有一个小的、公共的公告板，比如说有两个槽（$k=2$）。在一个线程解引用一个指向节点的指针之前，它必须首先通过将该节点的地址写入其一个槽位来“声明一个风险”。这就像贴出一个告示：“我正在使用这个节点。别碰！”一个想要释放内存的线程成为“回收者”。它收集所有它已删除的节点，然后扫描*所有*线程的公告板。任何地址出现在任何公告板上的节点都是“有风险的”，不能被释放。任何不在列表上的节点都是安全的，可以回收。

- **优点：** 它很稳健。如果一个线程被阻塞，它只阻止它已声明为有风险的特定节点被回收。系统的其余部分可以继续回收内存。
- **缺点：** 它给每个读操作的快速路径增加了开销（你必须写入你的公告板）。随着线程数（$P$）和风险槽数（$k$）的增加，回收者的工作也变得更加困难，因为它必须扫描 $P \times k$ 个指针。

#### 基于纪元的回收 (EBR)
EBR 的工作方式像一个以“纪元（epochs）”为单位滴答作响的全局时钟。有三个纪元：当前纪元、前一个纪元和再前一个纪元。当一个线程想要访问共享[数据结构](@entry_id:262134)时，它只需将自己注册为在当前全局纪元中“活跃”。然后它可以自由地遍历结构。完成后，它将自己标记为不活跃。它删除的任何节点都被放入当前纪元的“待释放”列表中。

当全局纪元推进时，回收发生。要推进纪元，系统必须等待一个“宽限期”过去。这意味着在上一个纪元中活跃的每个线程都必须此后变得不活跃。一旦发生这种情况，我们就可以确定没有任何线程持有指向那个前一个纪元（或任何更早纪元）中节点的指针。那些旧的“待释放”列表上的所有节点都可以一次性大批量回收。

- **优点：** 读取端非常快。一个线程只需在开始操作时设置一个标志，这比风险指针的每个指针成本要低得多。
- **缺点：** 它很脆弱。如果单个线程变为活跃然后被无限期地阻塞或取消调度，它将永远不会变为不活跃。宽限期将永远不会结束。这会暂停*整个系统*的[内存回收](@entry_id:751879)，导致内存无限制增长。

这是一个经典的工程权衡：风险指针以快速路径性能为代价提供稳健性，而 EBR 则以全局[停顿](@entry_id:186882)的风险提供极快的快速路径。在它们之间进行选择取决于应用的具体需求，这是一个深刻的设计原理如何转化为现实世界性能和可靠性的绝佳例子。

