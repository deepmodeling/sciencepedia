## 引言
基因组常被称为生命的蓝图，但真正揭示一个生物体在任何特定时刻活跃*做什么*的，是[转录组](@entry_id:274025)——即 RNA 转录本的全集。这一动态的生物信息层因可变剪接而变得更为复杂。可变剪接是指单个基因可以产生多种不同的转录本变体（即异构体）的过程，每种异构体都可能具有独特的功能。理解这种复杂性对于破译细胞功能、发育和疾病至关重要。然而，准确识别每一种独特的异构体并量化其丰度，构成了一项重大的技术和计算挑战，是现代生物学中的一个关键知识空白。

本文为探索这个错综复杂的世界提供了一份全面的指南。首先，在“原理与机制”一章中，我们将剖析用于读取转录组的核心技术和计算策略。我们将探讨从生物样本到定量数据的全过程，对比短读长和长读长测序的理念以及计算组装的不同方法。随后，“应用与跨学科联系”一章将展示这些方法如何应用于解决医学领域的关键问题——从诊断癌症到验证致病性遗传变异，以及它们如何与其他领域（如蛋白质组学和单[细胞生物学](@entry_id:143618)）建立联系。我们将从审视使解读生命脚本成为可能的基本原理和机制开始我们的探索。

## 原理与机制

想象一下，细胞不是一张静态的蓝图，而是一座繁华的城市。这座城市的中央图书馆——基因组——保存着所有可能的结构、机器和工人的设计图。但在任何特定时刻，这些设计图中只有一小部分在使用。这些设计图的工作副本，从脱氧[核糖核酸](@entry_id:276298)（DNA）转录成[核糖[核](@entry_id:276298)酸](@entry_id:164998)（RNA），被称为转录本。在某一时刻，这座城市中所有这些活跃设计图的[全集](@entry_id:264200)就是**转录组**。它是一份动态的、鲜活的文档，告诉我们细胞在*做什么*，而不仅仅是它*能做什么*。

作为生物学家，我们的任务是成为这座城市里的间谍。我们想要截获这些信息，以了解其内部运作机制。哪些设计图正在被使用？每种设计图有多少份拷贝在流传？这里存在一个精妙的复杂层面：一份主设计图（一个基因）可以通过不同方式被加工，从而产生多个略有不同的工作副本（异构体）。这被称为**[可变剪接](@entry_id:142813)**。这就像一本食谱中的单个配方可以有多种变化：“加入坚果以获得酥脆口感”或“不加辣椒以获得温和口味”。发现这些异构体并量化它们的丰度，对于理解从基本细胞功能到导致疾病的复杂线路错误等一切事物都至关重要。本章将介绍我们为解读这套非凡、动态的生命脚本所发展的原理与机制。

### 从分子到数据：如何读取信息

你如何读取一座城市里那些你甚至看不见的信息呢？几十年来，我们所用的方法就像是使用一张预先印好的清单。例如，**DNA [微阵列](@entry_id:270888)**是点缀有已知基因序列的玻璃片。你可以将细胞的信息冲洗过这张玻片，看看哪些信息会附着在上面。这种方法很强大，但有一个根本的局限性：你只能找到你已经在寻找的东西。它不可能发现一个真正新颖的信息——一个不在你清单上的基因或异构体。

**[RNA测序](@entry_id:178187) (RNA-seq)** 带来了革命。RNA-seq 的理念不是检查已知的信息，而是简单地读取存在的*所有*信息，然后再弄清楚它们是什么。这种“思想开放”的方法使其成为一种发现工具。例如，如果你正在探索从[热液喷口](@entry_id:139453)新发现的生物的转录组，微阵列就毫无用处，因为你不知道该在清单上放哪些基因。然而，RNA-seq 会对那里的任何 RNA 进行测序，让你能够发现对在该极端环境中生存至关重要的全新基因 [@problem_id:1530911]。

但在我们进行测序之前，必须先准备样本。一个细胞的总 RNA 绝大多数是核糖体 RNA (rRNA)，即构建蛋白质的分子机器。它是转录组中无趣的“垃圾邮件”，占总质量的 80% 到 90%。为了找到有价值的信息——信使 RNA (mRNA)——我们需要对其进行过滤。在这里，我们面临第一[组选择](@entry_id:175784)，每种选择都有其自身的理念和偏见 [@problem_id:4378617]：

- **Poly(A) 筛选**：在真核生物中，大多数 mRNA 信息的末端都有一个特殊的“尾巴”，即一条由腺嘌呤碱基组成的长链，称为 poly(A) 尾。我们可以使用由[胸腺](@entry_id:183673)嘧啶碱基（oligo(dT)）制成的“钩子”来钓出这些带尾巴的信息。这种方法效率高，能富集行为良好的蛋白质编码转录本。缺点是什么？我们会错过任何因某种原因缺少这种特殊尾巴的信息，例如某些非编码 RNA 或[组蛋白](@entry_id:196283) mRNA。

- **rRNA 去除**：这是一种相反的理念。我们不是主动选择我们想要的，而是被动地去除我们不想要的。我们使用探针来寻找并移除无用的 rRNA，然后对剩下的一切进行测序。这为我们提供了更广阔的转录组视野，捕获了 mRNA 和许多其他非多腺苷酸化的 RNA。当研究降解样本时，例如来自临床档案的样本，其中 poly(A) 尾可能已经断裂，这种方法尤其有用。

- **3' 标签计数**：当你的主要目标仅仅是计算分子数量，而不必读取其全部内容时，这是一种巧妙的策略。该方法使用相同的 poly(A) 尾钩，但其设计目的是仅对每个转录本最末端的一个小“标签”进行测序。通过在任何扩增之前为每个分子赋予一个独特的条形码（**[唯一分子标识符](@entry_id:192673)**，或 UMI），它使我们能够以极高的准确性计算原始分子数量，避免了较长转录本可能因产生更多片段而显得更丰富的偏见。这就像是计算寄出的信件数量，而不是总页数。

- **基于捕获的富集**：这是专家的工具。如果你只对一组特定的基因（例如与癌症相关的 500 个基因）感兴趣，你可以设计定制探针来专门钓出这些转录本。这将你的测序能力集中在对你的假设最重要的地方，但代价是忽略了细胞中发生的一切其他事情。

这些最初的选择至关重要；它们塑造了我们将花费大量计算精力试图理解的数据的本质。另一个这样的选择是是否进行**链特异性 [RNA-seq](@entry_id:140811)**。这项技术保留了 RNA 是从哪条 DNA 链上复制而来的信息。在基因组这座密集的城市里，一些街道两旁都有建筑物（重叠基因）。非链特异性测序就像看一张照片，你分不清汽车在街道的哪一边。链特异性测序则为你提供了那个至关重要的方向信息，防止你将一条信息错误地归因于错误的基因 [@problem_id:4605759]。

### 巨大的分歧：短读长与长读长的理念

一旦我们准备好了信息文库，就必须读取它们。在这里，现代技术为我们提供了一个深刻的选择，一个介于两种强大理念之间的真正岔路口。

成熟的主力军是**短读长测序**。想象一下，把城市里的每一条信息都放进碎纸机，产生数十亿个微小的、像五彩纸屑一样的纸条，每条长约 $75$ 或 $150$ 个字符。这种方法的力量在于其惊人的规模和准确性。你得到数量庞大的纸条，而且每一条都是它所来自的那部分信息的高保真副本。当然，挑战在于将这些五彩纸屑般的纸条重新组装成原始的、全长的信息。

然后是革命性的新来者：**长读长测序**。这就像能够一次性读完一整个段落，甚至一整封信。你不需要粉碎信息。虽然你读到的每个字母的原始准确性可能稍低一些（更多的“拼写错误”），而且在相同成本下你无法读取同样多的总信息量，但它在发现信息*结构*方面的优势是惊人的 [@problem_id:2774602]。

对于**异构体发现**，长读长改变了游戏规则。可变剪接的核心挑战是弄清楚哪些外显子与哪些外显子相连。对于短读长，你必须从可能跨越一个或最多两个剪接点的微小片段中，通过计算来推断这种连接性。这是一个复杂的谜题。而对于一个从 5' 端到 3' 端跨越整个转录本的长读长来说，没有谜题需要解决。外显子的连接性在一份数据中一览无余 [@problem_id:2774602] [@problem_id:4382908]。

然而，在**定量**方面，出现了一种权衡。因为长读长，顾名思义，很长，所以固定的测序预算（读取的总碱基数）所产生的长读长数量将远少于短读长。可以这样想：你有一笔预算，可以校对 1 亿个单词（短读长），或者 1 百万个完整句子（长读长）。大量的短读长提供了对转录组更深度的采样，为我们计算每种转录本的拷贝数提供了更强的[统计功效](@entry_id:197129)和精度，特别是对于稀有信息 [@problem_id:2774602]。

这也导致了定量理论的精妙简化。对于短读长，一个较长的转录本自然会被切碎成更多的片段，产生一种我们必须校正的偏见。然而，在理想的长读长实验中，一个读长对应一个完整的转录本分子。定量变成了一个简单的分子计数行为。不同异构体的观测计数遵循一个直接的[多项分布](@entry_id:189072)，而一个异构体丰度的估计值就是其计数除以总计数——无需复杂的长度归一化 [@problem_id:4382908]。

一些长读长平台甚至允许**直接 RNA 测序**，完全避免了向 cDNA 的转化。这消除了酶促步骤（如[逆转录](@entry_id:141572)和 PCR）带来的偏见，甚至保留了天然的 RNA 修饰，为窥探“[表观转录组](@entry_id:204405)”打开了一扇窗。目前，其代价通常是较低的通量和较高的错误率，但这凸显了该领域快速、持续的演进 [@problem_id:2774602]。

### 理解片段：计算组装的艺术

无论我们的读长是短是长，它们都只是一串 A、C、G 和 T（或 U）。为了将它们转化为生物学知识，我们需要将它们映射回其来源。这是生物信息学的领域，在这里，不同的理念也在相互竞争。

第一个问题是：我们使用什么样的地图？我们可以使用整个城市的总蓝图（**[参考基因组](@entry_id:269221)**），或者已知建筑物的地图集（**参考[转录组](@entry_id:274025)**）。

#### 基因组[优先方法](@entry_id:150217)：通过比对进行发现

用于发现的最经典、最强大的方法是将读长比对到参考基因组上。**[剪接感知比对](@entry_id:175766)器**是一款非常出色的软件，它了解剪接过程。它明白一个读长可能匹配外显子 1 的一[部分和](@entry_id:162077)外显子 2 的另一部分，而这两部分在基因组图谱上由于中间内含子的存在而相隔数千个碱基。通过找到这些“分裂”比对，比对器可以精确定位剪接点的基因组坐标。

这是它的超能力：如果它发现一个分裂比对与我们注释文件中的任何已知剪接点都不对应，那么它就发现了一个**新的剪接点**。这使得基因组比对成为那些预期存在新异构体的研究（例如，剪接机制发生突变的癌细胞）中无可争议的冠军 [@problem_id:4378658]。这是一种开放世界、以发现为导向的方法。

当然，我们地图的质量很重要。如果我们有一个完美的、染色体级别的参考基因组，这就是黄金标准 [@problem_id:2848940]。但如果我们的地图质量很差，或者是为另一个完全不同的城市（一个远缘物种）准备的呢？那么，读长比对就会变得困难且带有偏见。如果我们根本没有地图，就像一个新发现的物种那样呢？在这种情况下，我们被迫进行**[从头组装](@entry_id:172264)**：仅仅根据它们的重叠序列来拼接那些被粉碎的信息，这项任务类似于在没有盒子封面图片的情况下完成一个巨大的拼图游戏。这是一项英勇的努力，但远比使用高质量地图更容易出错 [@problem_id:2848940]。

同样至重要的是，要区分基因组图谱和旅游指南——**[基因注释](@entry_id:164186)文件 (GTF)**。GTF 文件告诉比对器已知的基因和外显子在哪里。这可以帮助引导比对，但一个好的比对器不会把它当作金科玉律。如果你使用高质量的基因组，但用一个糟糕、过时的 GTF 文件，比对器仍然会将大多数读长放置在它们正确的基因组位置。*比对*本身没有问题。但随后的*按基因计数*读长的步骤将是一场灾难，因为你正试图将读长分配给一组毫无意义的特征。这将映射行为与基于注释的计数行为清晰地分开了 [@problem_id:2336623]。

#### [转录组](@entry_id:274025)[优先方法](@entry_id:150217)：通过伪比对实现高速

近年来，一种截然不同且速度快得多的理念应运而生：**伪比对**。像 Salmon 和 Kallisto 这样的工具不是将读长比对到庞大的基因组上，而是将它们比对到小得多的参考转录组——即所有已知转录本序列的集合上 [@problem_id:4605759]。

此外，它们甚至不执行完整的逐个碱基的比对。它们使用一种基于 **k-mers**（固定长度的短“词”，例如 31 个碱基）的巧妙捷径。它们通过简单地检查哪些转录本共享该读长的 k-mers 集合，来确定一个读长与哪组转录本*兼容*。其输出不是一个精确的比对文件（如 BAM 文件），而是一组**[等价类](@entry_id:156032)**，这些等价类将与同一组转录本兼容的读长分组在一起 [@problem_id:2967130]。

其优势是惊人的速度——通常比传统比对快几个数量级。权衡之处在于它完全依赖于已知的注释。伪比对在一个“封闭世界”中操作；它在物理上无法发现一个不在其所给定的参考[转录组](@entry_id:274025)中的新剪接点或异构体 [@problem_id:2967130] [@problem_id:4605759]。这使其成为大规模定量*已知*转录本表达的杰出工具，但不适合以发现为重点的项目 [@problem_id:4378658]。

### 最终计数：精确定量的挑战

在比对或伪比对之后，我们终于达到了定量的目标：每种转录本有多少拷贝？这比听起来要难，主要有两个挑战：偏见和模糊性。

短读长 [RNA-seq](@entry_id:140811) 中最根本的偏见是**长度偏好**。即使一个短转录本和一个长转录本在细胞中的丰度相同，较长的那个也会被切碎成更多的片段，从而产生更多的读长。为了比较基因间的表达水平，我们需要一个能够校正这一点的单位。一个广泛使用的单位是**每百万转录本数 ([TPM](@entry_id:170576))**。它是一个两步归一化过程：首先，它用每个转录本的长度来校正其读长计数，得出一个比率。然后，它在整个文库中对这些比率进行缩放，使它们总和为一百万。结果是一个直观的数字：“在这个样本的一百万个转录本中，有多少是这种特定类型的？”这使得 TPM 值在单个样本内的不同转录本之间具有可比性 [@problem_id:4566706]。

第二个挑战是**模糊性**。因为一个基因的不同异构体共享外显子，所以一个短读长可能与其中几个异构体兼容。我们该如何处理这个读长的“投票”呢？最简单的策略是丢弃它，但这会丢失有价值的信息，并系统性地低估具有许多相似异构体的基因 [@problem_id:2336623]。一个远为优雅的解决方案是使用[统计模型](@entry_id:755400)。现代的定量工具使用诸如**[期望最大化 (EM)](@entry_id:637213)** 算法之类的算法。这是一个迭代过程：它从对转录本丰度的粗略猜测开始，用这个猜测来概率性地分配模糊的读长，然后用这些分配来更新其丰度估计。它重复这个过程，直到数值收敛到一个稳定、自洽的解。这使我们能够利用每一个读长，无论是模糊的还是明确的，来得出最可能的定量真相 [@problem_g:4566706] [@problem_id:2967130]。

最后，我们常常希望在基因水平上总结我们的结果。但简单地将一个基因所有异构体的计数相加可能会产生误导，特别是当一个细胞从表达短异构体切换到长异构体时。这看起来可能像是基因表达的增加，而实际上只是异构体的使用发生了变化。存在一些复杂的方法可以创建对这类变化具有鲁棒性的基因水平摘要，为下游的统计分析提供更稳定的基础 [@problem_id:4566706]。

从细胞内繁华的城市到计算机上最终的数字表格，转录本发现和定量的旅程是科学智慧的证明。这是一个关于巧妙实验设计、革命性技术和优雅计算算法的故事，所有这些共同协作，以破译那些编排生命之舞的、活生生的、呼吸着的信息。

