## 引言
神经影像为我们观察大脑运作提供了一个前所未有的窗口，但其产生的原始数据远非一幅清晰的画面。这些数据充满了来自受试者运动、生理过程和硬件缺陷的噪声和伪影，它们可能掩盖或模仿真实的神经活动。这在原始[数据采集](@entry_id:273490)与有意义的科学发现之间造成了一道关键的鸿沟。本文通过全面概述神经影像预处理来弥合这道鸿沟。首先，在“原理与机制”部分，我们将深入探讨一系列至关重要的校正步骤——从时间和空间对齐到滤波和标准化——这些步骤能够净化和规范化数据。随后，“应用与跨学科联系”一章将揭示这种细致的准备工作如何在从临床神经学到[脑机接口](@entry_id:185810)等领域中催生深刻的见解，从而阐明将原始信号转化为可解释科学的变革性力量。

## 原理与机制

想象一下，你刚刚拿到了一台功能性[磁共振成像](@entry_id:153995)（fMRI）扫描仪的原始数据。你可能会把它想象成一部关于大脑活动的、水晶般清晰的三维电影。然而，现实要混乱得多。它不像一部纯净的好莱坞电影，更像是在暴风雨中摇晃的船上拍摄的视频，镜头如同哈哈镜一样扭曲着世界。扫描仪中的人不可避免地会移动头部，即使只有一毫米；他们的心跳和肺部扩张会 jostle 大脑；扫描仪硬件本身也不完美，其信号会随着时间慢慢漂移。图像采集的物理原理——逐层 painstakingly 采集——本身也引入了时间上的失真。

将这种原始数据用于科学研究，就像试图从一张模糊、倾斜的图像中判断冲刺终点的胜负。在我们能够提出关于大脑功能的有意义问题之前，我们必须首先踏上一段计算恢复的旅程。这段旅程被称为**预处理**，它是由一系列精心编排的校正组成的交响乐，每一步都基于物理学、数学和统计学。这个过程就是将那部充满噪声、扭曲的电影转变为一个足够干净、足以揭示心智微妙秘密的数据集。

### 校正的交响乐：预处理流程

预处理不是一堆随机的修复；它是一个流程，一个步骤顺序至关重要的序列。搞错顺序就像在烘烤蛋糕之前就尝试给它抹上糖霜——结果一团糟。每一步都为下一步准备数据，它们之间错综复杂的依赖关系揭示了该过程的深层逻辑 [@problem_id:4491649] [@problem_id:4163835]。

#### [时间问题](@entry_id:202825)：时间中的切片

我们的第一个挑战是，fMRI 对大脑的“快照”并非瞬时完成。为了创建一个三维体积，扫描仪会采集一系列二维切片。这可能需要几秒钟（即**重复时间**，或$TR$），这意味着第一个切片比最后一个切片“更旧”。如果一个神经事件发生，BOLD信号在不同切片中似乎会在不同时间上升，这仅仅是因为它们的测量时间不同 [@problem_id:4179407]。

这就是**时间层校正（STC）**所要解决的问题。它是一种[时间插值](@entry_id:755845)，一种巧妙的数学技巧，通过平移每个切片的数据，使其看起来好像整个大脑体积是在一个单一的参考时间点被捕获的。这对于将测量的BOLD信号的时序与我们的实验模型的时序对齐至关重要，例如，在同步脑电-功能[磁共振成像](@entry_id:153995)研究中对齐EEG衍生的回归量 [@problem_id:4179407]。

#### 空间问题：一个移动的目标

fMRI数据中最大的误差来源是头动。即使是一个合作的参与者，在扫描过程中也会轻微移动头部。当头部移动时，我们数据网格中给定的一个体素（一个三维像素）就不再对应于同一块脑组织。一个本应反映单个神经群体活动的时间序列，反而变成了一个被不同组织信号污染的混合体，因为这些组织在体素的固定位置上移动。

**头动校正**是将在时间序列中的每个体积重新对齐到一个共同参考体积的过程。这通常被建模为**[刚体变换](@entry_id:150396)**，即三个平移（沿x、y、z轴移动）和三个旋转（俯仰、翻滚、偏航）的组合。该算法会估计每个时间点的这$6$个参数，并用它们来“撤销”大脑图像的移动，从而创建一个空间上稳定的影像序列 [@problem_id:4179407]。

#### 最小干预原则

在这里，我们遇到了现代预处理中最优美和微妙的原则之一。头动校正和其他空间变换都需要对图像进行*[重采样](@entry_id:142583)*。[重采样](@entry_id:142583)意味着为我们的体素网格计算新的强度值，这不可避免地会引入少量的模糊和信息损失。这就像复印一份复印件；每一代都会变得更模糊一些。如果按顺序执行多个空间变换——例如，先校正扫描仪引起的失真，然后校正头动，再将大脑扭曲到标准空间——将需要多次[重采样](@entry_id:142583)步骤，从而逐步降低我们宝贵数据的质量。

优雅的解决方案，正如在fMRIPrep等现代工具中实现的，是将变换的*估计*与其*应用*分离开来。我们首先估计所有空间变换的参数：磁场失真、每个时间点的[刚体运动](@entry_id:193355)，以及到标准模板的扭曲。然后，我们将所有这些数学运算组合成一个单一、复杂的变换。这个单一的、最终的变换只被应用*一次*到经过时间层校正的原始数据上，使其直接进入其最终的、校正后的、标准空间的形式。这种“一次性”重采样最大限度地减少了[插值误差](@entry_id:139425)，尽可能地保持了数据的保真度 [@problem_id:4491649] [@problem_id:4163835]。这揭示了该过程中的一个深刻智慧：一次性考虑所有步骤，然后只行动一次。

### 从个体大脑到通用地图：标准化的力量

每个人的大脑都是独一无二的。就像面孔一样，它们都有相同的基本部分，但在大小、形状和皮层的复杂折叠模式上有所不同。为了比较一组受试者之间的大脑活动或将研究结果与标准化图谱联系起来，我们必须将每个个体的大脑转换到一个共同的坐标系中。这个过程被称为**空间标准化** [@problem_id:4163829]。

这种变换的目标是一个**标准模板**，例如流行的MNI152模板，它是许多个体大脑的平均值。变换本身是一个复杂的配准问题，通常包括两个阶段：

1.  **[仿射变换](@entry_id:144885)**：这是一种全局的、线性的变换，用于解释大脑在整体尺寸、位置和方向上的差异。它涉及12个参数，分别代表平移、旋转、缩放（缩放）和剪切。这就像找到最好的方法来拉伸、挤压和旋转一个大脑的橡胶模型，使其大致形状与模板匹配。

2.  **[非线性变换](@entry_id:636115)**：在仿射对齐使大脑进入大致正确的范围后，会估计一个高维度的、非线性的“扭曲”。这种变换模拟了个体解剖结构与模板之间的局部、空间变化的差异，例如脑回（[褶皱](@entry_id:199664)）和脑沟（沟槽）的具体路径。这是一个“数字雕刻”过程，精细地塑造大脑图像以匹配标准空间的解剖细节。

先进的配准算法甚至利用了关于解剖学的先验知识。例如，**基于边界的配准（BBR）**是一种巧妙的技术，用于将功能图像与结构图像对齐。它不仅仅是比较体素强度，而是首先在[高分辨率结构](@entry_id:197416)图像上识别白质和灰质之间的边界。然后，它调整对齐方式，以最大化功能图像中该特定边界处的强度对比度，利用解剖学知识以极高的精度引导配准 [@problem_id:4163872]。

这个扭曲过程不仅仅是一个必要的麻烦。扭曲场本身就是一个丰富的信息来源。变换在每个点的**[雅可比行列式](@entry_id:137120)**精确地告诉我们，为了适应模板，大脑的该部分需要在局部被拉伸或压缩多少。这些信息可以用来研究不同群体之间大脑结构的差异，这种技术被称为**基于体素的形态学分析** [@problem_id:4163829]。在这里我们看到了一个优美的统一：一个用于预处理功能数据的工具，同时为分析结构数据提供了一个强大的度量。

### 模糊的艺术：平滑的利弊

在所有这些为以剃刀般锋利的精度对齐图像而进行的艰苦工作之后，许多分析流程中的最后一步竟然是……故意将它们[模糊化](@entry_id:260771)。这听起来可能很疯狂，但这是一个经过计算的权衡，带来了深远的好处，被称为**[空间平滑](@entry_id:202768)** [@problem-id:4163868]。该过程涉及将图像与一个高斯核进行卷积，这实际上是对每个体素及其邻居进行加权平均。

为什么要这样做？主要有两个原因。

首先，它可以提高**[信噪比](@entry_id:271196)（SNR）**。真实的神经活动很少局限于单个体素；它通常延伸到皮层的一个小区域。而随机噪声则在体素之间独立变化。通过在一个小邻域内进行平均，随机噪声倾向于相互抵消，而共享的、潜在的[神经信号](@entry_id:153963)则得到增强。这就像在一个嘈杂的房间里试图听清微弱的耳语；通过平均一[小群](@entry_id:198763)站在一起的人发出的声音，不连贯的嘈杂声会减弱，但他们共同的耳语会变得更清晰。

其次，平滑有助于满足用于发现显著激活的统计方法的假设。**[随机场](@entry_id:177952)理论（RFT）**是一种常用于校正[脑图谱](@entry_id:165639)中[多重比较问题](@entry_id:263680)的框架，它要求数据（特别是噪声）在空间上是平滑的，并且其平滑度是已知的。平滑数据有助于强制执行此属性，使最终的[统计推断](@entry_id:172747)更加有效和稳健。关键是，数据的最终平滑度不仅仅是我们所应用的核的大小；它是应用平滑与数据自身内在平滑度的结合。为了获得准确的统计结果，这个最终平滑度必须从数据本身*估计*得出，通常是从[统计模型](@entry_id:755400)的残差中估计 [@problem_id:4163851]。

当然，这种好处是有代价的：空间特异性的损失。模糊可能会将两个邻近但不同的激活融合在一起，或者涂抹一个小的、局灶性的激活，使其精确位置变得模糊。这是fMRI分析中的一个[基本权](@entry_id:200855)衡：我们可以牺牲一些空间精度来换取统计功效和灵敏度。

### 清理时间线：滤波和回归

正如我们校正空间伪影一样，我们也必须在时间域上清理数据。来自MRI扫描仪的信号并非完全稳定；它在实验过程中表现出缓慢的**漂移**。这种低频噪声可能会掩盖我们正在寻找的与任务相关的信号。标准的解决方案是**高通滤波**，它去除低于某个[截止频率](@entry_id:276383)的频率，同时保留较高的频率 [@problem--id:4163848]。

这里蕴含着一个从盲目[启发式方法](@entry_id:637904)转向有原则分析的关键教训。许多软件包默认的高通[截止频率](@entry_id:276383)约为128秒。但是，如果你的实验使用了一个包含64秒任务块和64秒休息块的区组设计，会发生什么？总的周期是128秒，这意味着你与任务相关的信号的基频恰好是 $1/128 \, \mathrm{Hz}$。应用一个128秒的[高通滤波器](@entry_id:274953)会将你宝贵的信号当作噪声并将其移除！ [@problem_id:4155635]。原则是明确的：滤波器的选择必须始终与你的实验设计和噪声的特定[频谱](@entry_id:276824)特性相匹配，现代的数据自适应方法甚至可以自动做出这个选择 [@problem_id:4155635]。

其他噪声源更快。你的心跳和呼吸会产生生理伪影。因为我们通常对大脑的采样相当慢（例如，每两秒一次），这些更快的生理信号可能会受到**混叠**的影响——它们伪装成较慢的信号，恰好落入我们神经活动的频带内。这与在电影中使直升机快速旋转的叶片看起来旋转缓慢甚至倒转的效果相同 [@problem_id:4163848]。

对于像头动或混叠的生理信号这样具有复杂、非正弦模式的噪声源，简单的滤波是不够的。一个更强大的技术是**干扰回归**。我们将在重排过程中估计的运动参数或生理记录，作为“不感兴趣的回归量”包含在我们的[统计模型](@entry_id:755400)中。然后，模型会估计并移除数据中可以被这些干扰回归量解释的任何方差，从而对信号进行外科手术般的清理。

这种回归的思想引出了该领域最持久的争议之一：**全局信号回归（GSR）**。全局信号——大脑中所有体素的平均信号——不可否认地是广泛神经活动和广泛干扰伪影（如运动和呼吸）的混合体。将其回归掉是一种非常有效的[数据清理](@entry_id:748218)方法。然而，这种数学操作施加了一个约束，可能会人为地在区域之间引入负相关（“反相关”）。GSR究竟是一种揭示真实潜在网络结构的有效清理程序，还是一种产生虚假发现的危险扭曲，这是一个激烈且持续争论的话题。它有力地提醒我们，预处理不是一本已解决的食谱书；它是一个动态的研究领域，我们不断努力开发更有原则、更准确的方法来揭示大脑的真实活动 [@problem_id:4163834]。

