## 引言
随着人工智能日益融入我们的日常生活和关键决策过程，一个根本性问题浮出水面：我们能在多大程度上信任它的输出？人工智能系统看似自信的回答可能掩盖了其知识的严重匮乏，在感知的确定性与实际的可靠性之间造成了鸿沟。本文旨在解决这一关键问题，深入探讨[人工智能中的不确定性](@article_id:640151)概念，为理解和量化AI“知道什么”和“不知道什么”提供一个框架。

首先，在“原理与机制”部分，我们将探讨其理论基础，剖析两种基本的不确定性类型——[偶然不确定性](@article_id:314423)（aleatoric）和认知不确定性（epistemic）——以及用于衡量它们的实用方法。然后，在“应用与跨学科联系”部分，我们将看到这种理解如何将人工智能从一个黑箱转变为科学、工程和伦理领域中值得信赖的合作伙伴。读完本文，您将认识到，人工智能表达疑虑的能力并非缺陷，而是其实现负责任创新的最关键特征。

## 原理与机制

要真正把握现代人工智能的力量与风险，我们必须超越其看似神奇能力的表象，提出一个更深刻的问题：当人工智能给出答案时，我们应该在多大程度上信任它？关键在于理解不确定性。但事实证明，“不知道”有两种截然不同的类型。这种区分不仅是哲学上的好奇心，更是构建可靠、可信赖人工智能的根基。

### 两种“不知”：[偶然不确定性与认知不确定性](@article_id:364043)

让我们从一个类比开始。想象一位物理学家试图预测从电子枪发射的单个电子的路径。即使拥有最完美的理论——量子力学——和最精密的仪器，她也无法确定地预测电子会落在哪里。宇宙在这个尺度上存在一种固有的、不可简化的模糊性。这就是**[偶然不确定性](@article_id:314423)（aleatoric uncertainty）**。其名称源自拉丁语 *alea*，意为“骰子”——这好比是宇宙在掷骰子。它代表了系统中内在的随机性或噪声，无论增加多少数据或改进模型都无法消除。在人工智能领域，这可能是来自摄像头传感器的噪声、[金融市场](@article_id:303273)的随机性，或是模糊医学扫描中两种情况看起来确实相似的固有模糊性 [@problem_id:2784631]。这是关于*数据*本身的不确定性。

现在，想象一个不同的场景。我们请一位初出茅庐的物理系学生预测一颗靠近木星的彗星的轨迹，而这位学生只学过简单的行星轨道。该学生的模型是不完整的，没有考虑到木星巨大的引力。她的预测会是错误的，而她预测中的不确定性源于其模型的不足——源于她的知识欠缺。这就是**认知不确定性（epistemic uncertainty）**。其名称源自希腊语 *episteme*，意为“知识”。这是关于*模型*的不确定性。[认知不确定性](@article_id:310285)的奇妙之处在于它是可以减少的。通过给学生更多的数据——向她展示[三体](@article_id:329664)相互作用的例子，教她更高等的物理学——我们可以减少她的不确定性并改进她的模型。在人工智能领域，当模型被要求对一个与其训练数据截然不同的输入进行预测时，就会出现这种不确定性，例如，一个[机器学习势](@article_id:362354)能模型试图预测一个处于其从未见过的极端扭曲状态下的分子的能量 [@problem_id:2784631]。

### 一个困惑的专家委员会

为了建立更深的直观理解，让我们将人工智能拟人化。想象我们的人工智能不是一个单一的庞大脑，而是一个由许多专家模型组成的“委员会”，所有模型都在相同的数据上训练，但起点略有不同。现在，我们可以向这个委员会提问，不仅观察它们的集体答案，还观察它们达成共识的性质。

思考一个思想实验中的两种情景 [@problem_id:3166275]：

1.  **已知的未知（纯粹的[偶然不确定性](@article_id:314423)）：** 我们要求委员会预测一次公平硬币投掷的结果。委员会中的每一位专家都会举手，并充满信心地说：“正面朝上的概率恰好是 $0.5$。”注意这里发生了什么。委员会达成了完美的共识；它们内部的[分歧](@article_id:372077)，即**认知不确定性**，为零。对于这个问题，它们都知道正确的现实模型。然而，最终的预测 $p(\text{heads})=0.5$ 却是最大不确定的。这就是纯粹的[偶然不确定性](@article_id:314423)。人工智能精确地知道这个过程有多随机。

2.  **未知的未知（纯粹的认知不确定性）：** 现在，我们向委员会展示一张奇异、失焦的图片，它可能是一只猫，也可能是一只羊驼。我们要求它们给出结论。混乱爆发了。一半的专家，因为注意到一个像耳朵的尖锐形状，大喊：“是猫，我 $100\%$ 确定！”另一半，则因为盯着一块看似羊毛的区域，宣称：“是羊驼，我 $100\%$ 确定！”每个独立的专家都完全自信。它们各自的预测中[偶然不确定性](@article_id:314423)为零。但委员会却陷入了彻底的混乱。集体预测再次是 $50/50$ 的分裂，但这种分裂源于深刻的[分歧](@article_id:372077)。这就是纯粹的**[认知不确定性](@article_id:310285)**。对于这个奇怪的新数据，人工智能没有一个单一、连贯的模型。

这个“委员会”类比不仅是一个教学工具；它直接反映了一种强大的技术，称为**集成（ensembles）**，我们在实践中用它来衡量认知不确定性 [@problem_id:2837997]。

### 如何让AI紧张：探查其知识裂痕

通过观察当我们以不同方式“戳”人工智能的输入时其不确定性如何变化，我们可以学到很多。这就像机械师敲击引擎来诊断问题。

假设我们的人工智能被训练来识别图像中的物体。如果我们在鸟的图片上添加一些随机的、类似静电的噪声，使其看起来像一张略带颗粒感的照片，会发生什么？[@problem_id:3197058]。人工智能可能会变得不那么自信。“鸟”的概率可能会从 $0.99$ 降到 $0.85$。我们专家委员会的成员可能会一致同意这种[置信度](@article_id:361655)的下降。人工智能实际上是在说：“这张图片有噪声，所以我不太确定，但我仍然认为它是一只鸟。”不确定性增加了，但主要增加的是*偶然*不确定性部分——模型正在考虑它预期在现实世界中会看到的噪声。

现在来点更狡猾的。一个了解人工智能内部运作的对手，对图像进行了一个微小、精心设计的改动——这个改动小到[人眼](@article_id:343903)无法察觉。然而，对人工智能来说，这是一个巨大的冲击。这只鸟的图像可能突然被分类为“鸵鸟”、“烤面包机”或“汽车”，我们专家委员会的不同成员给出了截然不同的答案。总不确定性急剧飙升，但这一次，飙升的几乎完全是**认知**不确定性部分。这种[对抗性攻击](@article_id:639797)将输入推入了人工智能知识的“裂痕”中，即一个它从未被训练过的、其对世界的理解崩溃的广阔输入空间区域。模型不仅对有噪声的数据不确定，它对自己也深感不确定。

### 核心要素：量化疑虑

这种直观的图景植根于优美而精确的数学。一个预测的总方差可以被优雅地分解为我们之前讨论的两种不确定性。**全方差定律（Law of Total Variance）**提供了这个框架，告诉我们对于任何预测：

$$
\text{总方差} = \text{认知方差} + \text{偶然方差}
$$

在我们的人工智能委员会（模型集成）的背景下，这一点得到了完美的体现 [@problem_id:3166275]：

*   **[认知不确定性](@article_id:310285)**通过专家们各自预测值在委员会平均预测值周围的方差来衡量。它实际上就是衡量他们[分歧](@article_id:372077)的程度。如果所有模型都一致，这一项为零。

*   **[偶然不确定性](@article_id:314423)**通过每个独立专家预测的不确定性的平均值来衡量。这是委员会对于数据[固有噪声](@article_id:324909)程度的共识。

这种分解使我们能够构建可以量化两种不确定性的AI。除了用于捕捉模型[分歧](@article_id:372077)（[认知不确定性](@article_id:310285)）的[集成方法](@article_id:639884)外，我们还可以设计一个复杂的单一模型，它不仅学习预测答案，还学习预测该答案中固有的噪声。例如，这样一个**异方差模型（heteroscedastic model）**可以预测一个属性的均值和方差，从而让我们能直接处理任何给定输入的[偶然不确定性](@article_id:314423) [@problem_id:3179687]。

### 实践中的不确定性：从幻觉到更优的科学

掌握了这些原理，我们就可以开始揭开现代人工智能一些最令人费解行为的神秘面纱。当一个大型语言模型“产生幻觉”——自信地胡说八道时——它并非被创造力的恶魔附身。它只是在一个**认知不确定性**极高的区域做出预测，并且未能向你报告这种不确定性。这就像那个自信地算错彗星路径的学生。解决方案不是告诉AI停止产生幻觉，而是更科学地设计我们与它的互动方式。一个精心设计的提示不仅仅要求一个答案，它要求一个答案*和*一个严格的不确定性声明，遵循任何科学或工程学科中使用的相同标准 [@problem_id:2432413]。

当然，现实世界是复杂的。我们衡量不确定性的方法可能会受到我们训练选择的影响。例如，一种称为**[标签平滑](@article_id:639356)（label smoothing）**的常用[正则化技术](@article_id:325104)可以使模型产生校准得更好的概率，但其副作用是，它也可能减少测得的认知不确定性，从而可能掩盖模型无知的信号 [@problem_id:3197056]。这提醒我们，[不确定性量化](@article_id:299045)是一个充满活力的、持续进行的研究领域。

归根结底，理解和量化不确定性将人工智能从一个聪明的玩物提升为一个可靠的工具。这是人工智能用来告诉我们它知道什么、不知道什么以及什么是根本不可知的语言。对于科学家、工程师和医生来说，这至关重要。这是黑箱与值得信赖的发现伙伴之间的区别。

