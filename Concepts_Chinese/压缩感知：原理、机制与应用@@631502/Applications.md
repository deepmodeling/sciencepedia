## 应用与跨学科联系

我们已经了解了[压缩感知](@entry_id:197903)的基础原理，探索了[稀疏性](@entry_id:136793)、非[相干性](@entry_id:268953)和计算恢复之间优美的相互作用。你现在可能想知道，“这数学很优雅，但它在哪些方面改变了世界？”答案是：几乎无处不在。我们讨论的原理并非信号处理领域的小众技巧；它们代表了我们对数据、测量和发现的思考方式的根本性转变。这种新视角使我们能够在看似无关的领域之间建立桥梁，从量子物理到人工智能，所有这些都基于一个强大而单一的思想：结构是可压缩的。

让我们开始一场应用之旅，它不是一份枯燥的清单，而是一系列故事，展示了这一个思想如何绽放出众多革命性的工具。

### 科学测量的新视角

几个世纪以来，实验科学家的信条是尽可能准确地测量一切。压缩感知挑战了这一点，提出了一个更精炼的方法：智能地测量，而不仅仅是详尽地测量。

想象一位生物化学家试图理解蛋白质复杂的三维形状。[二维核磁共振](@entry_id:154897)（2D NMR）波谱学是这项工作的核心技术之一。在传统方法中，实验需要在时域空间的一个精细、均匀的网格上费力地采集数据点，对于复杂分子，这个过程可能需要数天甚至数周。为什么？为了满足古老的 Nyquist-Shannon [采样定理](@entry_id:262499)并避免信息丢失。但如果最终得到的[光谱](@entry_id:185632)——也就是科学家所追求的蛋白质结构图谱——大部分是空白，只有少数对应于原子相互作用的尖锐峰值呢？这正是我们一直在研究的那种[稀疏信号](@entry_id:755125)。

压缩感知为漫长的等待提供了一个绝妙的出路。实验不再对网格上的每个点进行采样，而是被编程为只采集一小部分随机选择的数据点。这种“[非均匀采样](@entry_id:752610)”（NUS）极大地缩短了实验时间。对这些不完整数据直接进行 Fourier 变换会得到一团糟，充满了类似噪声的伪影。但我们知道更好的方法。我们知道真实的[光谱](@entry_id:185632)是稀疏的。通过求解一个 $\ell_1$-最小化问题，重建算法能找到与我们采集的少量测量数据一致的最稀疏的[光谱](@entry_id:185632)。它有效地“[去噪](@entry_id:165626)”伪影并揭示真实的峰值，用一小部[分时](@entry_id:274419)间就达到了长达数天的实验所能达到的相同高分辨率 [@problem_id:3719410]。这不仅节省了时间；它还催生了全新类型的实验，可以研究以前根本无法研究的不稳定分子或复杂的生物系统。

这种[范式](@entry_id:161181)转变延伸到了物理世界的最基本层面。想象一下试图表征一个未知的[量子态](@entry_id:146142)，即量子力学中对一个粒子或系统的基本描述。一个[量子态](@entry_id:146142)由一个称为[密度矩阵](@entry_id:139892)的数学对象表示。要完全表征它，需要一个称为[量子态层析成像](@entry_id:141156)的程序，这涉及到对相同制备的系统进行许多不同的测量。对于一个存在于 $d$ 维空间中的系统，这可能需要[数量级](@entry_id:264888)为 $d^2$ 的测量次数。但如果这个态是“简单的”呢？一个简单的态，在量子术语中，是一个*[纯态](@entry_id:141688)*或*近[纯态](@entry_id:141688)*，它对应于一个低秩的密度矩阵。

在这里，[压缩感知](@entry_id:197903)再次提供了关键。通过利用低秩结构，我们可以用比以前认为可能的小得多的测量次数来重建密度矩阵。所需的测量次数不与系统巨大的环境维度成比例，而是与其微小的内在维度——即其秩——成比例。有趣的是，数学揭示了对于必须是半正定的[量子态](@entry_id:146142)，我们原则上看到的[核范数最小化](@entry_id:634994)问题等价于求解一个可行性问题。可识别性取决于我们选择的测量是否足以区分一个低秩态与另一个低秩态。这需要的测量次数与该态的真实自由度成比例，对于一个 $d$ 维空间中的秩为 $r$ 的态，大约是 $2dr - r^2$ [@problem_id:3471797]。本质上，我们是通过提出恰好足够的问题来确定[量子态](@entry_id:146142)，从而锁定其简单的潜在结构。

### 解码我们的数字与社交世界

揭示隐藏结构的力量在数据和信息世界中的变革性，不亚于其在自然科学中的作用。

想想一个静态场景的监控视频。一帧又一帧，背景几乎保持不变。这种时间上的冗余意味着，如果我们将视频帧堆叠成一个巨大的矩阵，背景部分高度相关，可以用一个低秩矩阵表示。现在，想象一个人走过场景。他的出现破坏了这种低秩结构，但在任何给定时间只在少数位置造成影响。移动的人代表一个叠加在静态背景之上的稀疏“误差”矩阵。整个视频是一个和：$M = L_0 + S_0$，一个低秩矩阵加一个[稀疏矩阵](@entry_id:138197)。

我们如何将它们分开？压缩感知一个优美的扩展，称为[稳健主成分分析](@entry_id:754394)（RPCA），通过寻找能叠加成观测视频的最佳低秩和稀疏分量来解决这个问题。它求解一个凸规划问题，同时最小化背景部分的[核范数](@entry_id:195543)（促进低秩）和前景部分的 $\ell_1$ 范数（促进稀疏）。在非相干条件下——意味着背景本身不是尖峰状或类稀疏的——这种方法可以完美地将静态世界与其中的动态角色分离开来，即使在事先不知道哪个是哪个的情况下也是如此 [@problem_id:3431812]。

这种将信号分解为其简单组成部分的想法在许多其他领域也得到了呼应。在[推荐系统](@entry_id:172804)中，你对电影或音乐的品味可以被建模为少数核心偏好的组合。你的“用户因子”向量在所有可能的类型和属性的广阔空间中很可能是稀疏的。这种潜在的[稀疏性](@entry_id:136793)使得公司仅凭你以往少数的评分就能预测你可能喜欢什么，通过为每个用户恢复稀疏因子来有效地“补全”所有用户评分的矩阵 [@problem_id:3473301]。

这些原理甚至触及了因果关系的复杂网络。在从经济学到神经科学的领域中，我们试图理解一个系统中的不同变量如何随时间相互影响。向量自回归（VAR）模型捕捉了这一点，其中系统在一个时刻的状态是其前一时刻状态的线性函数。如果我们假设每个变量只受少数其他变量的直接影响——一个稀疏的因果结构——我们能否从有限的观测中发现这个结构？这是一个压缩感知与因果发现相[交叉](@entry_id:147634)的前沿领域。如果我们足够幸运，处于系统状态本身是稀疏的情况下，并且我们可以在每一步恢复它，那么我们就可以使用[稀疏回归](@entry_id:276495)来找出系统的“规则”。然而，这是一个具有挑战性的领域，因为系统的动力学很容易破坏我们所依赖的简单[稀疏性](@entry_id:136793)，这需要超越基本原理的更先进的技术 [@problem_id:3479388]。

### 拓展感知的边界

[压缩感知](@entry_id:197903)的理念也激励我们设计新型传感器，并重新思考什么是信息。

最极端的测量形式是什么？也许是一个只能说“是”或“否”的传感器。这就是一位[压缩感知](@entry_id:197903)的世界。想象一下，你通过将信号 $x$ 投影到一个随机向量 $a_i$ 上来测量它，并且只记录符号：$y_i = \mathrm{sign}(\langle a_i, x \rangle)$。你已经丢弃了所有的幅度信息。这似乎毫无希望。然而，令人惊讶的是，如果原始信号是稀疏的，并且你收集了足够多的一位测量值，你仍然可以以惊人的准确度恢复信号的*方向*。恢复过程涉及求解一个凸规划问题，该问题找到与你收集的二[进制](@entry_id:634389)响应最一致的稀疏向量 [@problem_id:3482557]。这对设计在信息获取物理极限下运行的廉价、低[功耗](@entry_id:264815)传感器具有深远的影响。

此外，信号并非总是存在于简单的一维时间线或二维网格上。想一想大脑皮层复杂网络上的脑活动模式，或社交网络上信息的传播。压缩感知的原理可以推广到定义在图上的信号。在这里，“[相干性](@entry_id:268953)”的概念与图本身的结构相关联，由其 Laplacian 矩阵的[特征向量](@entry_id:151813)捕获。为了在图上重建一个稀疏的活动模式，你需要采样的节点数量取决于这个图的[相干性](@entry_id:268953)。这个优美的理论统一了信号处理、[图论](@entry_id:140799)和[稀疏恢复](@entry_id:199430)，使我们能够探究复杂的网络系统 [@problem_id:3486775]。

### 超越[稀疏性](@entry_id:136793)：与人工智能的新融合

也许最深刻的跨学科联系是最近的一个：[压缩感知](@entry_id:197903)与现代[深度学习](@entry_id:142022)的融合。“稀疏性”假设一直是我们的指路明灯。它是一个简单而强大的结构模型。但如果信号的结构更复杂怎么办？人脸图像在像素基中不稀疏，在 Fourier 或[小波基](@entry_id:265197)中也不稀疏。但它*是*高度结构化的。我们对于什么“看起来像人脸”有着强大的直觉。

现代人工智能通过[深度生成模型](@entry_id:748264)为我们提供了一种形式化这种直觉的方法。这些是在海量数据集（例如，人脸）上训练的[神经网](@entry_id:276355)络，它们学会成为一个“人脸制造机”。给定一个随机的低维种子向量 $z$，生成器 $G$ 会产生一个高维、逼真的人脸 $x = G(z)$。生成器所有可能输出的集合在所有图像的高维空间中形成一个低维[流形](@entry_id:153038)。

这为[压缩感知](@entry_id:197903)[范式](@entry_id:161181)提供了一个里程碑式的演进。我们不再通过寻找与测量一致的*最稀疏*信号来解决逆问题，而是可以寻找*可由我们的生成模型产生*且与测量一致的信号。从几何上看，我们不再是在稀疏[子空间](@entry_id:150286)的并集上寻找解，而是在深度网络学到的丰富、弯曲的[流形](@entry_id:153038)上寻找解 [@problem_id:3442853]。现在，恢复所需的测量次数不再与环境维度 $n$ 成比例，而是与[生成模型](@entry_id:177561)[潜空间](@entry_id:171820)的内在维度 $k$ 成比例，进一步打破了维度诅咒。

这让我们回到了原点。[压缩感知](@entry_id:197903)的惊人力量源于其利用结构的能力。一项理论计算表明，对于一个在$30,000,000$维空间中的信号，如果我们知道它只有$300$个非零项是稀疏的，我们可能只需要大约$20,000$次随机测量就能完美重建它——这是一个惊人的缩减 [@problem_id:3486642]。这不是魔术。这是拥有一个好的信号模型的回报。无论这个模型是简单的稀疏性，还是一个复杂的、[深度学习](@entry_id:142022)得到的先验，教训是相同的：在一个充满结构的世界里，少量数据，在良好假设的指导下，可以发挥巨大的作用。