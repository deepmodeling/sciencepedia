## 引言
数十年来，软件一直构建在一致性内存访问（UMA）这一优雅的简化模型之上，即任何内存位置的访问速度都是相同的。然而，随着计算机系统扩展到数百个核心，这种模型在物理上和经济上都变得不可持续。这催生了[非一致性内存访问](@entry_id:752608)（NUMA）架构的出现，这是一个根本性的转变，其中[内存访问时间](@entry_id:164004)取决于其相对于处理器的物理位置。这就创造了一个隐藏的性能版图，如果被忽视，可能会严重削弱应用程序的速度。本文旨在为 navigating 这个版图提供一份全面的指南。

我们将首先探讨NUMA的核心**原理与机制**，详细介绍[操作系统](@entry_id:752937)如何通过首次接触和线程亲和性等策略来管理这种硬件地理。随后，我们将在**应用与跨学科联系**一章中审视NUMA的深远影响，了解这些原则如何在科学计算、[操作系统](@entry_id:752937)设计以及云中[虚拟化](@entry_id:756508)的复杂性中发挥作用。通过理解这种物理现实，我们可以学会编写与硬件和谐共处的软件，从而释放其真正的性能潜力。

## 原理与机制

### 一致性的美丽幻象

当我们初学编程时，我们被教导了一个简单、优雅且非常有用的谎言。我们想象计算机的内存是一个单一、巨大的一维字节数组。你请求地址100，就得到位置100的字节。你请求地址50亿，就得到位置50亿的字节。获取一个字节所需的时间，在所有意图和目的上都是相同的，无论它在哪里。这就是**一致性内存访问**（**UMA**）的原则。

在很长一段时间里，计算机架构师们不遗余力地维护着这个美丽的幻象。在早期的[多处理器系统](@entry_id:752329)中，他们构建了极其复杂且昂贵的硬件，例如全连接的**[交叉](@entry_id:147634)开关**，其唯一目的就是以相同的延迟将每个处理器连接到每个内存库。在这样的系统中，理想的低负载条件下，访问内存的时间是一个常数，且该访问时间的[方差](@entry_id:200758)为零。它是完全一致的，完全可预测的。[@problem_id:3686994]

但这种完美是以爆炸性增长的成本为代价的。一个连接 $N$ 个处理器和 $M$ 个内存库的[交叉](@entry_id:147634)开关需要 $N \times M$ 个开关。当我们构建拥有数十或数百个处理器核心的机器时，这种方法在物理上和经济上都变得不可能。看来，大自然也是有预算的。那么，我们该怎么办？我们做了物理学家和工程师在面对不便的现实时总是会做的事：我们拥抱它。

### 拥抱硬件的地理学

现代高性能计算机不再是一个单一的、完美连接的系统，而是更像一个由相互连接的社区组成的集合。每个“社区”，通常是一个处理器插槽，拥有自己的一组核心和自己直接连接的“本地”内存。然后，这些社区通过高速互连（可能呈环形、网状或其他拓扑结构）连接在一起。

突然之间，地理位置变得重要起来。一个处理器核心访问其所在社区的内存速度很快。我们称之为**本地访问**。但如果该核心需要访问不同社区的数据，请求就必须跨越互连，可能需要经过几次“跳跃”才能到达目标内存库。这就是**远程访问**，它明显要慢得多。这就是**[非一致性内存访问](@entry_id:752608)**（**NUMA**）的世界。

这种非一致性不是一个缺陷；它是可扩展硬件的一个基本特征。关键的洞见在于，你等待内存的平均时间现在取决于你的数据*在何处*。我们可以用一个简单而强大的公式来表达这一点。如果你的内存访问中有 $f$ 的比例是远程的，那么你的平均延迟 $L_{\text{avg}}$ 是：

$$
L_{\text{avg}} = (1 - f) L_{\text{local}} + f L_{\text{remote}}
$$

在一台典型的服务器上，本地访问可能需要 $L_{\text{local}} = 80$ 纳秒，而远程访问可能是 $L_{\text{remote}} = 140$ 纳秒或更多。[@problem_id:3687018] 使用这些数字，公式变为 $L_{\text{avg}} = 80 + 60f$ 纳秒。你的应用程序性能现在与这个因子 $f$（远程访问的比例）直接线性相关。NUMA[性能优化](@entry_id:753341)的关键就是让 $f$ 尽可能接近于零。

“非一致性”还表现为延迟的更高*[方差](@entry_id:200758)*。理想的UMA[系统延迟](@entry_id:755779)[方差](@entry_id:200758)为零，而[NUMA系统](@entry_id:752769)的延迟是一个[随机变量](@entry_id:195330)，其值取决于到目标内存的距离或**跳数**。一个到相邻节点的请求可能需要一跳，而到一个位于机器另一端的节点的请求可能需要多跳，每一跳都会增加延迟。这些路径长度的[分布](@entry_id:182848)产生了[方差](@entry_id:200758)，使得性能可能变得不那么可预测。[@problem_id:3686994] 其中的挑战——也是乐趣所在——是教会我们的软件去学习机器的地理结构，并顺应其特性，而不是与之对抗。

### 作为地理学大师的[操作系统](@entry_id:752937)

[操作系统](@entry_id:752937)（OS）位于应用程序和硬件之间。它无法隐藏硬件的非一致性，但可以提供工具和策略来*管理*它。这种管理依赖于两个基本支柱：智能地放置数据和智能地放置线程。

#### 首次接触：一条简单而深刻的规则

当程序请求一个新的内存页面时，[操作系统](@entry_id:752937)必须决定使用哪个物理内存库。许多[操作系统](@entry_id:752937)使用的一个极其简单而有效的启发式方法是**首次接触策略**：页面被分配在*首次写入*它的线程所在的NUMA节点上。

这条简单的规则带来了深远的影响。考虑一个并行程序中的一个大数组。一种常见但幼稚的方法是让一个主线程在启动一组工作线程来处理数组之前，分配并初始化整个数组。采用首次接触策略，这个看似无害的行为会成为一场性能灾难。那个单一的初始化线程会导致数组的所有页面都被归属到它自己的NUMA节点上。随后，当并行工作者启动时，只有少数运行在同一节点上的工作者能获得快速的本地访问。其他所有位于其他节点上的工作者线程会发现，它们进行的每一次内存访问都是跨互连的缓慢远程访问。[@problem_id:2422586] 在一台双插槽的机器上，这一个错误就可能将可实现的内存带宽削减一半，将潜在的160 GB/s的本地带宽变成区区110 GB/s的混合本地和远程带宽。

解决方案既优雅，又如同问题本身一样微妙：**并行初始化**。不是由一个线程完成所有设置工作，而是将工作分散开。每个工作线程初始化它稍后将要处理的那部分数组。现在， благодаря 首次接触策略，数组的每一块都被本地分配给将要使用它的线程。通过这一个改变，我们恢复了局部性，最小化了远程访问，并释放了机器的全部[内存带宽](@entry_id:751847)。[@problem_id:2422586] [@problem_id:3208187] 这个原则——让工作者首先接触其数据——是在[NUMA系统](@entry_id:752769)上编写高性能代码最关键的模式之一。

#### 线程亲和性：将工作者置于正确的位置

正确放置数据只是成功的一半。线程本身也必须在正确的节点上。想象一个简单的两阶段流水线：一个生产者线程创建数据，一个消费者线程处理数据。如果我们不小心，[操作系统调度](@entry_id:753016)器可能会将生产者放在节点0上，而将消费者放在节点1上。如果共享数据由生产者首次接触，它就会驻留在节点0上。结果呢？消费者将耗费其全部生命周期跨越机器获取数据，在每一次操作上都付出远程访问的代价。

一旦你看到这个地理结构，解决方案就显而易见了：把它们放在一起！通过使用**线程亲和性**将生产者和消费者线程都固定到同一个节点（比如节点0），并确保它们的共享数据也在节点0上，每一次访问都变成了本地访问。这种简单的共置完全消除了消费者的远程访问惩罚。如果消费者对每个项目执行 $m_c$ 次内存访问，而远程惩罚是 $r$ 个周期，那么这个简单的固定操作为处理的每一个项目节省了 $m_c \times r$ 个周期。[@problem_id:3685214]

#### Cpusets：为可预测性能构建隔离墙

有时候，好的围栏能造就好的邻居。在一台运行多个应用的繁忙服务器上，你可能有一个对延迟敏感的应用，其性能必须受到保护，免受[操作系统](@entry_id:752937)守护进程等“嘈杂”后台任务的干扰。仅仅寄希望于最好的情况并非一种策略。

在这里，[操作系统](@entry_id:752937)提供了强大的工具，如Linux的**控制组（[cgroups](@entry_id:747258)）**和**cpusets**，让系统管理员可以在机器内部构建虚拟的墙。你可以划定一条界线，宣布一个NUMA节点——它的CPU和本地内存——成为你关键应用的专用“工作负载区”。所有其他进程，包括烦人的后台守护进程，都可以被限制在另一个节点上的独立“内务区”。[@problem_id:3687018]

这不仅仅是为了避免CPU周期的竞争。它是为了为最需要的应用程序保留整个本地环境——[内存控制器](@entry_id:167560)、互连带宽和缓存。对于一个有严格服务等级目标的应用，例如在我们示例的机器上要求平均[内存延迟](@entry_id:751862)低于100纳秒，我们可以计算出它至少需要75%的访问是本地访问。使用cpusets进行硬性分区是*保证*这种局部性和性能隔离水平的唯一方法。[@problem_id:3664553] 这将一台大型计算机变成了一组更小、隔离的子计算机，从而实现了否则不可能达到的性能确定性水平。

### 一个动态变化的世界

到目前为止，我们描绘了一幅静态的画面。但如果访问模式随时间变化怎么办？一个线程可能会迁移，或者一块数据可能会在另一个节点上被一组不同的线程“热捧”。一个真正感知NUMA的[操作系统](@entry_id:752937)可以通过执行**自动[页面迁移](@entry_id:753074)**来对此做出反应。它会监控访问情况，如果检测到一个页面正被从远程节点大量访问，它可以将整个页面移动到访问者的本地内存中。

然而，这种动态性也引入了其自身一系列有趣的权衡。

首先，**迁移不是免费的**。跨互连移动一个页面会消耗带宽。这种流量不仅包括页面的数据负载，还包括协议开销、控制头，甚至还有使源节点缓存中可能存在的数据副本失效的消息。高频率的[页面迁移](@entry_id:753074)会占用互连带宽的很大一部分，从而拖慢了它本想帮助的应用程序。[@problem_id:3621533]

其次，**迁移粒度很重要**。[操作系统](@entry_id:752937)以页为单位移动数据。如果我们从标准的4 KB页面切换到**[巨页](@entry_id:750413)**（例如2 MB），会发生什么？其后果是设计权衡的一个典型例子。
- **优点：** 使用[巨页](@entry_id:750413)显著提高了**TLB覆盖范围**。转换旁路缓冲（TLB）是一个小型缓存，用于存储最近的[虚拟到物理地址转换](@entry_id:756527)。使用2MB的[巨页](@entry_id:750413)，一个32项的TLB可以映射64MB的工作集，而使用4KB的页面，它只能映射128KB。对于拥有大型数据结构的应用程序，这种切换几乎可以消除[地址转换](@entry_id:746280)的开销。[@problem_id:3687023]
- **缺点：** [页面迁移](@entry_id:753074)变成了一个更粗粒度、更重的操作。如果一个2MB页面中只有一个微小的64字节缓存行是“热”的，[操作系统](@entry_id:752937)别无选择，只能迁移整个2MB的块。这种现象，被称为页面级别的**[伪共享](@entry_id:634370)**，会浪费大量带宽来移动“冷”数据和“热”数据。它甚至可能导致性能[振荡](@entry_id:267781)，即页面在节点之间反复“乒乓”。[@problem_id:3687023]

这种紧张关系一直延伸到[内存分配](@entry_id:634722)器。一个感知NUMA的分配器可能会维护每个节点的空闲列表。当一个线程需要内存时，它首先尝试其本地列表。但如果本地列表为空怎么办？它必须从另一个节点的列表进行一次代价高昂的“远程窃取”。这种情况发生的概率取决于内存是在本地归还还是远程归还的速率。这可以用[排队论](@entry_id:274141)来建模，其中本地命中率是线程亲和性维持得如何的直接函数。[@problem_id:3653454]

### 宏大的[优化问题](@entry_id:266749)

归根结底，所有这些原理和机制都可以归结为解决一个宏大的[优化问题](@entry_id:266749)。想象一下，你有一组线程[分布](@entry_id:182848)在机器的NUMA节点上。你还有一组共享数据对象。对于每个线程和每个对象，你知道（或可以测量）该线程将访问该对象的次数。你还被给定一个矩阵，其中包含从任何节点访问任何其他节点的延迟。

问题是：你应该将每个对象放在哪里，以最小化整个应用程序的总加权[内存访问时间](@entry_id:164004)？

这是一个可解的问题。对于每个对象，你可以通过将每个线程的访问次数乘以相应的[传输延迟](@entry_id:274283)并求和，来计算将其放置在节点1、节点2等位置的总访问成本。通过为每个对象独立选择成本最低的放置位置，你可以为你的数据找到最优的静态布局。[@problem_id:3636432]

我们讨论的所有策略——并行初始化、线程亲和性、[操作系统](@entry_id:752937)策略、[页面迁移](@entry_id:753074)——都只是帮助我们近似解决这个宏大[优化问题](@entry_id:266749)的工具和启发式方法，无论是在我们编写代码时静态地解决，还是在代码运行时动态地解决。理解NUMA是一段从一致性内存的简单幻象到现代硬件错综复杂的地理现实的旅程。它揭示了一个隐藏的结构层，其美妙之处不在于其一致性，而在于它为我们提供了一个机会，让我们能够将计算与物理机器和谐地安排在一起。

