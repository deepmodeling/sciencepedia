## 引言
在探索世界的过程中，科学总是在与不确定性作斗争。概率使我们能够基于已知模型预测未来结果的几率，但研究人员常常面临相反的问题：利用观测到的数据来推断世界背后的模型。这种从证据中学习的挑战属于统计推断的范畴，其核心是一个强大而优雅的概念：似然。基于似然的推断为量化证据支持、估计未知参数以及比较科学假说提供了一个统一而通用的框架。它解决了从观察现象到理解产生该现象的过程之间的根本鸿沟。

本文将通过两个全面的章节深入探讨基于似然的推断的理论与应用。在第一章**原理与机制**中，我们将探索从概率到似然性的哲学转变，定义最大似然估计（MLE），并审视深刻而富有争议的似然原理。我们将看到似然如何充当频率学派和贝叶斯范式之间的桥梁，并为处理[讨厌参数](@entry_id:171802)和[缺失数据](@entry_id:271026)等复杂问题提供原则性的方法。在这一理论基础之后，第二章**应用与跨学科联系**将展示似然在实践中的应用。我们将遍览其在生物统计学、生态学和[系统发育学](@entry_id:147399)等不同领域的应用，看它如何驾驭相依数据，克服不完整数据集的挑战，并作为现代因果推断探索中的关键引擎。

## 原理与机制

### 新视角：从概率到似然性

让我们从一个简单的问题开始我们的旅程，这类问题是赌博和机会游戏的基础。如果你有一枚均匀的硬币，连续抛掷十次，恰好得到七次正面的概率是多少？这是一个关于**概率**的问题。给定一个已知的世界模型（一枚均匀的硬币，其出现正面的概率 $\theta$ 为 $0.5$），我们预测未来数据的几率。计算过程简单明了，最终会得到一个单一的数值。

但科学常常面临相反的问题。我们并不知道世界的真实模型；我们试图去揭示它。想象一下，我们抛掷一枚神秘的硬币十次，并*观察*到七次正面。我们无法事先保证这枚硬币是均匀的。我们的问题不再是“这个结果的概率是多少？”，而是“这个结果告诉了我们关于这枚硬币的什么信息？”这是一个关于**推断**的问题。

这就是**似然**概念的用武之地，它代表了一种深刻的、近乎哲学的视角转变。为了构建[似然函数](@entry_id:141927)，我们采用与计算概率完全相同的公式，但我们将其反向应用。现在，数据——我们观察到的七次正面和三次反面——被视为固定的。而参数——硬币固有的正面概率 $\theta$——现在是变量。

[似然函数](@entry_id:141927)写作 $L(\theta; \text{data})$，它所问的是：“对于任何关于硬币的给定假说（例如，对于 $\theta$ 的某个特定值），我们实际看到的数据的概率是多少？”

对于我们的硬币，在 $n=10$ 次抛掷中得到 $k=7$ 次正面的概率由[二项分布公式](@entry_id:269272)给出：$P(\text{data} | \theta) = \binom{10}{7} \theta^7 (1-\theta)^3$。当把这个公式看作 $\theta$ 的函数时，它就是我们的似然函数。让我们尝试几个 $\theta$ 的值：
- 如果硬币是均匀的（$\theta = 0.5$），我们这个结果的概率本应是 $\binom{10}{7} (0.5)^7 (0.5)^3 \approx 0.117$。
- 如果硬币偏向正面，$\theta = 0.7$，概率将是 $\binom{10}{7} (0.7)^7 (0.3)^3 \approx 0.267$。
- 如果硬币偏向正面，$\theta = 0.9$，概率将是 $\binom{10}{7} (0.9)^7 (0.1)^3 \approx 0.057$。

比较这些值，$\theta=0.7$ 的假说比 $\theta=0.5$ 的假说使得我们观察到的数据更为合理（plausible）。事实上，如果我们画出这个函数在 $\theta$ 从0到1的所有可[能值](@entry_id:187992)上的图像，我们会看到它有一个峰值。这个峰值处的 $\theta$ 值就是使我们的数据最合理的那个值。这就是著名的**[最大似然估计](@entry_id:142509)（MLE）**。对于我们的硬币，MLE恰好是 $\hat{\theta} = \frac{7}{10} = 0.7$。它是最能解释我们所拥有数据的参数值。

至关重要的是要理解似然不是概率。[似然函数](@entry_id:141927)并没有告诉我们 $\theta$ 是 $0.7$ 的概率。它是一种证据支持的度量。在任何一点 $\theta$ 处，曲线的高度衡量了该特定参数值对数据的解释程度。绝对高度本身意义不大，但*相对*高度才是一切。我们可以自信地说，数据为 $\theta=0.7$ 提供的支持比为 $\theta=0.5$ 提供的支持更多，因为[似然比](@entry_id:170863) $L(0.7) / L(0.5)$ 大于一。

这种对比例的关注带来了一个显著的简化。注意我们公式中的 $\binom{10}{7}$ 这一项。这个数字告诉我们10次抛掷中得到7次正面有多少种方式，但它的值不依赖于 $\theta$。当我们比较两个不同 $\theta$ 值的似然时，这个常数项同时出现在比率的分子和分母中，因此它被消掉了。为了对 $\theta$ 进行推断，它是无关紧要的。这揭示了一个深刻的真理：所有关于 $\theta$ 的信息都包含在函数的形状中，特别是在依赖于 $\theta$ 的那部分。这就是为什么我们经常使用正比符号来写[似然函数](@entry_id:141927)，$L(\theta; \text{data}) \propto \theta^7 (1-\theta)^3$，从而捕捉函数的核心部分。将似然函数乘以任何不依赖于参数的常数，并不会改变峰值的位置或任何[似然比](@entry_id:170863)，因此，它不会改变我们的推断 [@problem_id:4849898]。

### 似然原理：唯有真相

只有[似然函数](@entry_id:141927)的形状才重要的这一观点，引出了一个强大而富有争议的原则：**似然原理（Likelihood Principle, LP）**。它指出，一次实验中关于参数 $\theta$ 的所有证据都包含在*实际观察到*的数据的[似然函数](@entry_id:141927)中。实验的任何其他方面，例如可能发生但未发生的其他结果，或者实验者的意图，都是无关的。

这听起来可能像是常识，但它与传统统计学中一些最常见的方法形成了鲜明对比。让我们用一个源自医学研究的经典场景来探讨这一点 [@problem_id:4969236] [@problem_id:5226665]。

想象一下，两个研究团队正在评估一种新的抗[病毒疗法](@entry_id:185013)。患者对该疗法产生反应的概率是 $\theta$。
- **团队1** 采用固定样本量设计。他们决定招募恰好 $n=20$ 名患者，并观察有多少人产生反应。他们发现有 $k=8$ 名患者产生反应。
- **团队2** 采用贯序设计。他们决定持续招募患者，直到观察到恰好 $r=8$ 名产生反应的患者为止。结果这总共需要 $N=20$ 名患者。

两种情况下的原始数据完全相同：一个包含8个反应和12个无反应的20名患者序列。但是实验计划——即*停止规则*——完全不同。这种意图上的差异是否应该影响我们对药物有效性 $\theta$ 的结论呢？

让我们看看[似然函数](@entry_id:141927)。
- 对于团队1，产生反应的患者数量服从[二项分布](@entry_id:141181)。其似然为 $L_1(\theta) = \binom{20}{8} \theta^8 (1-\theta)^{12}$。
- 对于团队2，患者总数服从负二项分布。其似然为 $L_2(\theta) = \binom{19}{7} \theta^8 (1-\theta)^{12}$。

注意到奇妙之处了吗？两个似然函数都与同一个核心表达式成正比：$\theta^8 (1-\theta)^{12}$。它们仅在一个不涉及 $\theta$ 的常数因子（$\binom{20}{8}$ vs. $\binom{19}{7}$）上有所不同。

根据似然原理，既然似然函数成正比，那么关于 $\theta$ 的证据就是相同的。两个团队应该得出完全相同的结论。停止规则是无关紧要的。

这是一个激进的观点，因为它直接挑战了像p值和显著性检验这样的频率学派方法。[p值](@entry_id:136498)是在原假设下观察到你的数据*或更极端情况*的概率。而“更极端”的定义取决于[样本空间](@entry_id:275301)——所有可能结果的集合。由于两个团队有不同的抽样计划，他们的样本空间是不同的，他们计算出的[p值](@entry_id:136498)也会不同！频率学派可能会得出证据不同的结论，而似然原理的实践者则会坚称证据是相同的。

这一点延伸到了臭名昭著的“选择性停止”问题 [@problem_id:4856304]。如果一个研究者在数据累积过程中反[复分析](@entry_id:144364)，仅当p值降到像 $0.05$ 这样的阈值以下时才停止，频率学派理论认为这会极大地增加[假阳性](@entry_id:635878)的机会。对频率学派来说，停止规则至关重要。而对于遵循似然原理的人来说，停止的原因是无关的；唯一重要的是最终数据的似然函数，无论它是如何获得的。

### 统一框架：学派之间的桥梁

似然函数不仅仅是某个统计学派的工具；它位于两大主要推断范式的核心，充当它们之间的桥梁。让我们看看它在频率推断和[贝叶斯推断](@entry_id:146958)中是如何运作的 [@problem_id:4922759]。

想象一位生物统计学家正在为每病人月的药物不良事件数量建模，该数量服从一个未知速率参数为 $\theta$ 的泊松分布。

在**频率推断**中，$\theta$ 被视为一个固定的、未知的常数。目标是利用数据来精确定位这个值。主要工具是[似然函数](@entry_id:141927) $L(\theta; \text{data})$。对 $\theta$ 的最佳猜测是最大似然估计 $\hat{\theta}_{MLE}$，即该函数的峰值。所有其他的频率学派工具——[置信区间](@entry_id:138194)、[假设检验](@entry_id:142556)——都是围绕这个估计量在假设性重复实验中的性质而构建的。似然函数告诉我们数据要说什么，然后我们用它来构建具有理想长期性质的程序。

在**贝叶斯推断**中，哲学则不同。我们将未知参数 $\theta$ 视为一个随机变量。在看到任何数据之前，我们对 $\theta$ 有一些预先存在的信念，这些信念被一个**[先验分布](@entry_id:141376)** $p(\theta)$ 所捕捉。当我们收集数据时，我们使用贝叶斯定理来更新我们的信念。结果是一个**后验分布** $p(\theta | \text{data})$，它代表了我们更新后的知识状态。驱动这次更新的引擎就是[似然函数](@entry_id:141927)。其关系异常简单：

$$
p(\theta | \text{data}) \propto L(\theta; \text{data}) \times p(\theta)
$$

**后验分布正比于似然乘以[先验分布](@entry_id:141376)。**

似然函数就像一个过滤器，它接收我们的先验信念，并根据每个可能的 $\theta$ 值解释观测数据的程度来重新加权它们。[参数空间](@entry_id:178581)中似然高的区域，其先验信念被放大；似然低的区域则被抑制。

这个公式表明，[贝叶斯推断](@entry_id:146958)自然地遵循了似然原理 [@problem_id:4856304] [@problem_id:4928124]。由于数据仅通过[似然函数](@entry_id:141927)进入计算，两个具有成比例似然的实验，在给定相同先验的情况下，将产生完全相同的后验分布。不改变似然的停止规则，同样也不会改变贝叶斯的结论。

### 驾驭复杂性：讨厌参数与[缺失数据](@entry_id:271026)

现实世界的科学模型很少像单次抛硬币那么简单。它们通常涉及许多参数，而并非所有参数都是我们感兴趣的。例如，在研究一个生物标志物时，我们可能对其平均水平 $\theta$ 感兴趣，但为了正确地建模数据，我们还需要考虑其变异性或方差 $\eta$。在这里，$\theta$ 是我们感兴趣的参数，而 $\eta$ 是一个**[讨厌参数](@entry_id:171802)** [@problem_id:4936395]。它之所以讨厌，是因为我们不直接关心它的值，但如果想对 $\theta$ 做出正确的推断，我们就不能忽略它。

似然理论如何处理这个问题？一个优雅的解决方案是**[剖面似然](@entry_id:269700)**。这个想法既巧妙又直观。我们为感兴趣的参数 $\theta$ 创建一个新的、简化的似然函数。对于我们正在考虑的每一个可能的 $\theta$ 值，我们问：“*给定这个 $\theta$ 值*，[讨厌参数](@entry_id:171802) $\eta$ 的什么值能让数据最可能出现？” 我们将这个最佳情况下的 $\eta$ 值代回完整的似然函数。结果是一个仅关于 $\theta$ 的函数 $L_p(\theta)$，它已经“剖析掉”了讨厌参数。这个新函数可以像一个常规的单参数[似然函数](@entry_id:141927)一样，用于对 $\theta$ 进行推断。

当我们面对数据分析中最持久的挑战之一：**[缺失数据](@entry_id:271026)**时，这种处理复杂性的能力就更加引人注目。当数据点缺失时，简单地忽略它们可能导致严重的偏误结论。似然理论为理解何时以及如何正确处理[缺失数据](@entry_id:271026)提供了一个原则性的框架。

关键在于**缺失机制**，即决定数据为何缺失的过程。一个有缺失值的数据集的完整似然必须同时考虑数据生成过程（由 $\theta$ [参数化](@entry_id:265163)）和缺失机制（由讨厌参数 $\psi$ [参数化](@entry_id:265163)）。然后，通过对缺失值的所有可能性进行积分，可以找到观测数据的似然 [@problem_id:4928096]。

如果数据是**[随机缺失](@entry_id:168632)（Missing At Random, MAR）**，就会发生一个神奇的简化。这个技术术语有一个简单的含义：一个值缺失的概率仅取决于我们*已经观察到*的信息，而不取决于缺失值本身。例如，在一项纵向研究中，如果患者之前观察到的血压较高，他可能更容易错过一次随访。在MAR（以及一个称为参数独立性的额外技术条件）下，观测数据的似然会奇迹般地分解为两个独立的部分：一部分只涉及 $\theta$ 和观测数据，另一部分只涉及 $\psi$ 和缺失模式 [@problem_id:4928096] [@problem_id:4928124]。因为它们是分开的，我们可以简单地最大化第一部分来对 $\theta$ 进行推断，而完全忽略缺失机制。该机制被称为是**可忽略的**。这为[多重插补](@entry_id:177416)等强大技术提供了理论基础。

如果数据是**[非随机缺失](@entry_id:163489)（Missing Not At Random, MNAR）**，情况会发生巨大变化 [@problem_id:4812777]。这种情况发生在缺失的概率取决于未观察到的值本身时。例如，如果病毒载量极高（且未测量）的患者病得太重而无法参加门诊预约，那么缺失就取决于缺失的信息本身。在这种情况下，似然函数无法分解。我们的科学模型的参数 $\theta$ 与缺失模型的参数 $\psi$ 在对[缺失数据](@entry_id:271026)进行积分时纠缠在一起。该机制是**不可忽略的**。我们不能简单地忽略它；我们必须明确且正确地对缺失[过程建模](@entry_id:183557)才能得到有效答案。因此，似然理论提供了一个清晰明确的警示信号，区分了我们可以相对轻松地进行处理的情况和需要极其谨慎处理的情况。

### 当数据好到失真：拯救似然

最大似然原理是绝对可靠的吗？不尽然。有时，数据对于模型来说可能在某种意义上*太好了*，导致MLE表现异常。一个经典的例子发生在[逻辑斯谛回归](@entry_id:136386)中，这是一种用于建模[二元结果](@entry_id:173636)（如疾病存在与否）的常用工具。

假设我们发现一个生物标志物能够完美地区分健康个体和患病个体：每个病人的生物标志物值都高于某个阈值，而每个健康人的值都低于该阈值。这是研究者的梦想！但如果你试图用标准的[逻辑斯谛回归模型](@entry_id:637047)来拟合这些数据，你会发现生物标志物效应的最大似然估计是无穷大 [@problem_id:4969335]。当你提出越来越强的效应时，似然函数会持续攀升，永远达不到一个有限的峰值。MLE不存在。

这正是似然框架灵活性的闪光之处。当原始似然导致荒谬的结论时，我们可以对其进行增强。这就是**惩罚似然**背后的思想。我们通过添加一个惩罚项来修改[对数似然函数](@entry_id:168593)，该惩罚项表达了对更“合理”参数值的偏好。
- **岭回归**添加一个惩罚项，抑制过大的参数值，有效地给它们套上“缰绳”，将它们拉向零。这确保了惩罚似然函数有一个唯一的、有限的峰值。
- **Firth回归**使用一种更复杂的惩罚，源于一个称为Jeffreys先验的概念。这种惩罚不仅解决了分离问题，而且还具有减少估计偏差的理想特性，尤其是在小样本中。

这些[惩罚方法](@entry_id:636090)并非临时抱佛脚的修补。它们是似然框架的原则性扩展，展示了其适应挑战性情况的能力。它们表明，似然不是僵硬的教条，而是一种强大而通用的、用数据进行推理的语言，这种语言不仅让我们能够表达数据所说的内容，还能表达什么构成了一个合理的答案。从其简单直观的核心，到其深刻的哲学意涵，再到其在复杂现代问题中的强大应用，似然原理为[科学推断](@entry_id:155119)的艺术提供了一个统一而优美的视角。

