## 应用与跨学科联系

你可能会认为，在理解一个科学模型的原理并付出了所有辛勤努力之后，最后一步——测试它——应该是直截了当的。你有数据，有模型。你只需把数据喂进去，看看模型是否能得到正确答案。这听起来很简单。的确如此，就像将航天器降落在遥远的月球上一样“简单”——原理很简单，但宇宙有上千种微妙的方式让你栽跟头。

将数据恰当地划分为训练集、[验证集](@article_id:640740)和测试集，是我们驾驭这些微妙之处的方法。它是公平竞争这一普适规则的科学体现：**不应偷看答案**。[测试集](@article_id:641838)就是那个答案，是期末考试试卷，被严加保管直到最后。[验证集](@article_id:640740)是我们的模拟考试，我们可以用它来调整我们的学习方法（我们模型的超参数）。训练集是我们的教科书、课堂笔记，是我们赖以学习的材料。本章是一次旅程，我们将探索这个简单而优美的规则如何在广阔的科学和工程领域中指引发现。这不仅仅是一项技术性的杂务；它是一个深刻的原则，迫使我们对自己究竟从世界中学到了什么保持诚实。

### 隐藏的结构：当“随机”出错时

想象一下，你是一名医学研究员，正在测试一个新模型，该模型通过几周内采集的一系列血液检测来预测患者的预后。你有成千上万个数据点。一个幼稚的方法是将所有这些数据点随机打乱并划分：$80\%$用于训练，20\%用于测试。模型表现出色！但当它部署到医院用于新患者时，却惨败了。问题出在哪里？

错误在于将每次血液检测都视为一个独立事件。实际上，多个测量值来自*同一个患者*。通过将这些测量值分散到[训练集](@article_id:640691)和[测试集](@article_id:641838)中，模型并没有学会关于疾病的知识；它只是学会了通过独特的生物指纹来识别“7号患者”或“42号患者”。测试的不是预测一个*新*人的预后，而是识别一个旧人。这是[数据泄露](@article_id:324362)的一种经典形式。要获得对模型在现实世界中表现的公正评估，唯一的方法是确保来自特定患者的所有数据要么都在训练集中，要么都在测试集中，但绝不能两者兼有。这被称为**按患者**或**按聚类**划分([@problem_id:3187568])。

这个观点——数据通常具有隐藏的群体结构——并非医学领域所独有。它是一个反复出现的普遍模式。随机划分几乎总是一种会泄露信息的划分，它会用一份虚假乐观的成绩单来欺骗你。诚实的方法是识别你研究中真正的、独立的“主体”，并在这个层面上划分你的数据。

- 在**计算化学**中，当我们构建模型来预测[分子性](@article_id:297339)质时，我们常常拥有同一个分子的许多不同空间构型，即**构象异构体 (conformers)** 的数据。要构建一个真正普适的化学模型，我们必须测试它预测全新*分子*性质的能力，而不仅仅是它已经见过的分子的新姿态。因此，划分必须在分子层面上进行，这种做法可以防止所谓的**构象异构体泄露** ([@problem_id:2625126] [@problem_id:2903800])。

- 在**基因组学**中，当设计用于编辑基因的[CRISPR指导RNA](@article_id:345206)时，我们的数据可能包含许多针对同一个**基因**的不同指导序列。基因的细胞环境——例如其[染色质可及性](@article_id:342924)——创造了一个共享的背景。要构建一个适用于任何基因的预测器，我们必须在*未见过的基因*上对其进行测试。划分必须按基因分组 ([@problem_id:2626131])。

- 在**蛋白质工程**中，我们可能对一个亲本**蛋白质**有数百个突变。一个在此数据上表现良好的模型可能只是在学习该蛋白质特有的[生物物理学](@article_id:379444)。真正的考验是预测突变对一个*新蛋白质*的影响。同样，我们必须按蛋白质标识符对数据进行分组 ([@problem_id:2383476])。

在这些领域中的每一个，原则都是相同的。“独立单元”不是单个测量值，而是患者、分子、基因或蛋白质。通过使用考虑了分组的划分来承认这种结构，是迈向[科学诚信](@article_id:379324)的第一步。

### 超越身份：按物理和族系划分

分组的思想甚至可以更深入。有时我们必须分离的“组”不是由一个简单的ID标签定义的，而是由该领域本身的基本原理定义的。

思考一下**[流体动力学](@article_id:319275)**的世界。工程师们希望建立模型来预测表面传热，这是设计从计算机芯片到喷气发动机等一切事物的关键任务。流体在表面上的流动可以存在于不同的物理状态或**[流态](@article_id:313232) (regimes)**中——平滑有序的**[层流](@article_id:309877) (laminar flow)**，或混乱旋转的**[湍流](@article_id:318989) (turbulent flow)**。这种转变由一个称为雷诺数的无量纲量$\mathrm{Re}_x$控制。一个仅在[层流](@article_id:309877)状态的数据上训练的模型，在面对[湍流](@article_id:318989)时可能完全不知所措。

那么，我们如何测试跨越这些物理[流态](@article_id:313232)的泛化能力呢？随机划分是无用的；它会把两种流[态混合](@article_id:308479)在一起。答案是让物理学来指导划分。我们通过创建一个仅由明确为层流的运行数据组成的[训练集](@article_id:640691)来设计我们的实验（例如，所有局部测量的$\mathrm{Re}_x  3 \times 10^5$）。我们从明确为[湍流](@article_id:318989)的运行数据中创建测试集（例如，所有局部测量的$\mathrm{Re}_x > 7 \times 10^5$）。至关重要的是，我们扔掉中间的、处于**过渡**区的数据，以确保我们的两个集合被清晰地分开。数据划分不再仅仅是一个划分；它是一个精心设计的、用以探究物理定律的计算实验 ([@problem_id:2503017])。

这个概念延伸到**合成生物学**，科学家们在这里设计新的酶。酶的功能由其氨基酸序列决定。但序列不是独立的；它们通过进化相互关联。两种蛋白质可以有非常不同的序列，但属于同一个“家族”并执行相似的功能。如果我们的目标是设计一个真正新颖的酶，我们的模型必须能够泛化到全新的蛋白质家族。

为了测试这一点，我们必须超越按单个蛋白质进行划分。我们使用[序列一致性](@article_id:352079)作为进化距离的度量。我们可以根据这种相似性将我们数据集中的所有蛋白质聚类成家族。因此，一个稳健的验证方案将是**留出[聚类](@article_id:330431)交叉验证 (leave-cluster-out)**。我们将整个蛋白质家族留作测试。这迫使模型在远离其所见过的、在序列空间的“暮光区”中做出预测，那里的关系很难被察觉。这是一个更困难，但对模型真正发现潜力的更诚实的测试 ([@problem_id:2749119])。

### 时间之箭与语境幽灵

在某些领域，数据点不仅是分组的，还是有序的。最突出的例子是时间。

在**[时间序列预测](@article_id:302744)**中，我们试图根据过去预测未来。最严重的错误是利用未来的信息来预测过去。这似乎显而易见，然而对带有时间戳的数据进行简单的随机划分恰恰就是这么做的！这是一种[时间旅行](@article_id:323799)，在科幻小说中或许有趣，但在数据科学中却是灾难性的。

唯一有效的方法是**时序划分**。我们必须在一个较早的时间段上训练我们的模型，在一个随后的时间段上验证它，最后在最近的时间段上测试它。我们甚至可以在这些时间段之间引入**间隙**，以模拟现实世界中接收数据和部署模型的延迟。这种设置尊重时间之箭，并给出了模型在面对真正未知的未来时表现如何的现实估计。它还正确地测试了模型对**模式转变 (regime changes)**的鲁棒性，即数据的底层模式随时间变化——这是从金融到气候科学等领域持续存在的挑战 ([@problem_id:3188604])。

类似的语境幽灵也困扰着**[自然语言处理 (NLP)](@article_id:641579)** 的世界。一份文档——一篇文章、一本书、一封电子邮件——不是一堆随机的词。它有连贯的主题、风格和词汇。如果我们训练一个模型来对文档进行分类（例如，垃圾邮件与非垃圾邮件），并且我们在词或句子级别上划分数据，我们就会陷入一个熟悉的陷阱。模型将在其训练集和[测试集](@article_id:641838)中都看到来自同一文档的句子。它会学习该文档的特定怪癖——其独特的词汇或措辞——并利用这些“泄露”的信息轻松地对测试句子进行分类。

模型没有学会理解主题；它学会了识别文档。由此产生的准确率将高得惊人且完全具有误导性。正确的方法是**文档级划分**。我们将整个文档留作测试。这迫使模型将其对主题的理解泛化到它从未遇到过的新文本上 ([@problem_id:3187509])。

### 划分定义了研究任务

我们由此得出了或许是最深刻的见解。选择划分策略不仅仅是为了避免偏差的技术细节。*它精确地、数学化地定义了你正在探索的科学问题。*

让我们看看**[材料发现](@article_id:319470)**这一宏伟挑战。科学家利用机器学习来寻找具有理想性质的新材料，如超强强度或[导电性](@article_id:308242)。一种材料由其化学**成分 (composition)**（包含哪些元素及其比例）和其晶体**结构 (structure)**（这些原子如何[排列](@article_id:296886)）来定义。

假设你有一个庞大的已知[材料数据库](@article_id:361753)。你应该如何划分它？答案完全取决于你的目标。

- 你是想为一个已充分理解的化学成分发现一种新的晶体**结构**吗？那么你应该使用**结构划分**，将某些已知的结构类型留作测试，同时允许模型在所有[化学成分](@article_id:299315)上进行训练。

- 或者，你是否在进行一项更宏伟的探索，以发现具有全新**化学特性**——前所未见的元素组合——的材料？那么你必须使用**成分划分**。你必须将整个化学体系留给[测试集](@article_id:641838)，迫使模型预测它没有任何直接先例的化合物的性质 ([@problem_id:2837998])。

一个独立同分布（i.i.d.）的随机划分无法回答这两个问题中的任何一个。它只能测试模型在已知材料空间[内插](@article_id:339740)值的效果如何，这与探索发现的前沿相去甚远。划分*即为*问题所在。它构建了假设，并定义了我们所说的“泛化”意味着什么。

### 公平竞争的前沿：大数据与现代人工智能

在海量、网络规模的数据集和拥有数万亿参数的模型的时代，这些公平竞争的原则比以往任何时候都更加关键——也更具挑战性。

想一想驱动现代人工智能的巨型**大语言模型 (LLMs)**。它们在互联网上的一大部分公开数据上进行了[预训练](@article_id:638349)。如果你为下游任务精心策划的“秘密”测试集，已经成为该[预训练](@article_id:638349)数据的一部分，会发生什么？模型实际上在其初始训练期间就已经看到了答案。它在你的测试集上的惊人表现可能完全是一种幻觉。这催生了一个全新的学科——**数据去污染**：一项大规模的取证工作，旨在从庞大的训练语料库中找到并移除潜在的测试数据，通常使用n-gram重叠等技术来检测污染 ([@problem_id:3194869])。这是一个行星尺度的侦探故事。

挑战甚至延伸到我们训练模型的方式。在**[自监督学习](@article_id:352490) (SSL)**中，模型通过从未标记数据中创建自己的**代理任务 (pretext tasks)**来学习，例如，通过获取一张图像，对其进行增强，然后尝试识别它仍然是同一张底层图像。但如果你的[数据增强](@article_id:329733)技术涉及到混合呢？如果你通过混合来[自训练](@article_id:640743)集的图像和来自测试集的图像来创建一个新的训练样本，你就打破了神圣的规则。你已经将测试[信息泄露](@article_id:315895)到了训练流程中。即使在最复杂的数据生成方案内部，也必须严格执行分离原则 ([@problem_id:3194813])。

从一个简单的[经验法则](@article_id:325910)，数据划分的概念已经发展成为一个支撑计算科学的复杂而深刻的原则。它迫使我们直面我们数据的结构、我们系统的物理特性，以及我们科学目标的本质。正是这个简单而强大的理念让我们保持诚实，确保当我们声称已经发现了关于世界的普遍真理时，我们不是通过记忆过去，而是通过展示预测未来的真正能力来做到的。