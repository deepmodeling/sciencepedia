## 应用与跨学科联系

芭蕾舞演员的旋转与计算机学习识别人脸，或者活细胞中分子的复杂舞蹈有什么共同之处？这似乎是个奇怪的问题，但答案揭示了复杂系统（无论是自然的还是人工的）在被控制和学习方式上一种深刻而优美的统一性。将这些世界联系在一起的数学线索，是最优控制与[反向传播算法](@article_id:377031)之间深刻的等价性。在探索了这种联系的原理之后，现在让我们踏上一段旅程，看看这个单一而优雅的思想如何在科学和工程领域绽放出绚丽多彩的应用。

### 有形世界：构建智能控制

我们的第一站是最直观的领域：物理运动的世界。想象你是一个木偶师，你的木偶是一个简单的摆。你的目标是将摆从静止状态移动到特定的角度，比如三十度，并让它在那里完美地停下来。你该如何拉动绳索——在这里是施加一连串的扭矩——以最少的力气实现这个目标？这是一个经典的*[最优控制](@article_id:298927)*问题。为你在每一瞬间如何调整拉力提供秘诀的“魔法”，是一种计算，它告诉你最终结果对你过去每一个行为的敏感度。正如我们所见，这种计算正是[随时间反向传播](@article_id:638196)，或者用控制理论的语言来说，是[伴随方法](@article_id:362078)。通过“向后播放动力学”，我们精确地发现了如何向前行动。

当然，世界比单个摆要复杂得多。一辆在城市中导航的[自动驾驶](@article_id:334498)汽车，或一个组装精密手表的机械臂又如何呢？同样的原理以惊人的力量扩展。对于一辆无法简单侧滑的类似汽车的机器人，我们可以计算出最佳的转向角和加速度序列，以遵循[期望](@article_id:311378)的路径，优雅地在弯道和直道中穿行。这种轨迹优化方法是现代机器人学背后许多成果的无声功臣。

然而，现实总是顽固地施加限制。电机不能产生无限的扭矩，汽车的轮子也只能转动那么多。一个理想的、无约束的解决方案可能会命令一个物理上不可能的动作。在这里，该框架再次以非凡的优雅处理了这个问题。一种称为*[投影梯度法](@article_id:348579)*的[算法](@article_id:331821)首先计算出理想的、无约束的更新，然后简单地将其“投影”回可行操作的集合上。这种数学投影有一个优美而直接的物理解释：[执行器饱和](@article_id:338274)。当[算法](@article_id:331821)将一个指令扭矩“裁剪”到其最大值时，它所做的正是一个真实世界的电机达到其物理极限时所做的事情。这使我们能够设计出不仅最优，而且深刻意识到自身物理形态的控制器。

### 抽象世界：教机器[学会学习](@article_id:642349)

现在让我们离开钢铁和齿轮的世界，进入硅和思想的世界。如果我们想要控制的“系统”不是一个机器人，而是人造大脑内部的[信息流](@article_id:331691)呢？[循环神经网络](@article_id:350409)（RNN）正是这样一个系统：它的[隐藏状态](@article_id:638657)根据其先前的状态和当前输入随[时间演化](@article_id:314355)，就像我们摆的角度和速度一样。训练一个RNN来执行像翻译句子这样的任务，其挑战在于找到正确的参数，以“引导”其内部状态沿着有意义的轨迹行进。

这正是这种联系成为一种启示的地方。使用[随时间反向传播](@article_id:638196)（BPTT）训练RNN在数学上与解决一个最优控制问题是相同的。困扰深度学习数十年的臭名昭著的“[梯度消失](@article_id:642027)和爆炸”问题，只不过是控制理论家经典稳定性问题的伪装。当系统的动力学使得微小的初始扰动随时间要么消失要么激增时，学习所需的梯度信号也遭受同样的命运。一个其状态转移雅可比矩阵 $A$ 的[谱半径](@article_id:299432) $\rho(A) \gt 1$ 的系统，既是一个爆炸性的控制器，也会产生[梯度爆炸](@article_id:640121)；一个 $\rho(A) \lt 1$ 的系统，既是一个稳定的控制器，也会产生[梯度消失](@article_id:642027)。这一单一的洞见统一了两个独立领域数十年的研究。

这种视角有力地延伸到了[强化学习](@article_id:301586)（RL），在[强化学习](@article_id:301586)中，一个智能体必须学会在规则未知的环境中行动。你如何在一个你不知道的动力学系统中进行[反向传播](@article_id:302452)？*Actor-Critic*框架提供了一个绝妙的答案。“Actor”（演员）是策略，即我们的控制器。“Critic”（评论家）是一个独立的[神经网络](@article_id:305336)，被训练来近似[价值函数](@article_id:305176)——即预期的未来回报。Actor不需要对真实世界进行[微分](@article_id:319122)，而是可以对其Critic对世界响应的光滑、学习到的近似进行微分。Critic[实质](@article_id:309825)上学习了一个可微的“未来成本”模型，而Actor通过它进行[反向传播](@article_id:302452)，以找出如何改进其行动。这就像让一个学生（Critic）为一个飞行员（Actor）构建一个完美的、可微分的飞行模拟器来训练。

有了这种深刻的理解，我们可以超越仅仅训练网络，而成为记忆本身的建筑师。考虑[长短期记忆](@article_id:642178)（[LSTM](@article_id:640086)）网络的复杂门控结构。通过将[LSTM](@article_id:640086)视为一个可控的动态系统，我们可以设计[正则化](@article_id:300216)器来塑造其行为。我们可以增加一个温和的惩罚，鼓励[遗忘门](@article_id:641715)在一个新数据段开始时迅速变为零，从而有效地“清空石板”。或者我们可以增加一个受生物物理启发的惩罚，鼓励[细胞状态](@article_id:639295)随时间平滑演化，网络通过将其[遗忘门](@article_id:641715)设置接近一、输入门设置接近零来学会实现这一点。我们不再只是优化一个黑箱；我们正在使用[最优控制](@article_id:298927)的原理来设计可解释且高效的内部学习机制。

### 统一的前沿：发现自然的[算法](@article_id:331821)

我们的旅程现在迎来了最激动人心的转折。到目前为止，我们一直在利用我们对动力学的知识来构建更好的学习机器。如果我们能利用学习机器来*发现*宇宙的动力学规律呢？这就是**神经[微分方程](@article_id:327891)（Neural ODEs）**革命性的前景。

在许多科学领域，如系统生物学，我们可以观察到一个系统如何随时间变化，但支配这些变化的精确数学方程是未知的或极其复杂的。例如，模拟糖酵解的[代谢网络](@article_id:323112)涉及几十种具有未知动力学定律的酶。传统的方法是猜测这些定律的形式。神经[微分方程](@article_id:327891)的方法则完全不同：它假设动力学由一个神经网络控制，$\frac{d\mathbf{y}}{dt} = f_{NN}(\mathbf{y}, t; \theta)$。网络的任务是直接从数据中学习将系统当前状态映射到其变化率的函数 $f$。那么参数 $\theta$ 是如何训练的呢？通过将误差反向传播通过数值ODE求解器本身，这一壮举通过连续时间[伴随方法](@article_id:362078)得以高效实现。我们正在利用[深度学习](@article_id:302462)的机制，不仅是为了模仿，更是为了揭示自然界的隐藏法则。

这把我们带到了我们最后的终点，我们所知的最复杂、最迷人的动态系统：大脑。当我们审视皮层的复杂布线时，我们发现大自然本身似乎就是控制理论的大师。大脑包含不同类别的抑制性[神经元](@article_id:324093)，一些靶向细胞体（胞体），另一些则靶向输入信号到达的远端[树突](@article_id:319907)分支。这不是随机布线。从控制的角度来看，这是一个绝妙的设计。

胞体周围抑制作用于输出生成的点，延迟最小，功能上像一个快速而强大的负反馈控制器，可除法性地调节[神经元](@article_id:324093)的整体增益。它就像调节[神经元](@article_id:324093)响应的音量旋钮。相比之下，远端树突抑制则在特定输入通路上局部作用。它充当一个[选择性过滤器](@article_id:316412)或门，能够在特定[信息流](@article_id:331691)有机会影响输出之前就否决它们。进化，通过对布线经济性和功能的不懈优化，已经收敛到了完美体现最优控制原理的解决方案上。

从机器人的优雅运动到驱动我们数字世界的深度学习，从生物法则的发现到我们大脑的结构本身，我们看到的是同一个原理在起作用。一个行动与其遥远后果之间的对话，由[链式法则](@article_id:307837)编织在一起，为控制、学习和发现提供了一种通用的语言。这是对科学思想的统一性与美感的绝佳证明。