## 引言
人类是如何仅凭口头描述就能认出一种他们从未见过的动物的？这种从已知概念推广到未知概念的非凡能力是智能的基石。几十年来，人工智能领域的一个重大挑战就是教会机器同样的技能：如何在没有先例的情况下识别物体、声音，乃至生物功能。本文将深入探讨旨在解决这一问题的[范式](@article_id:329204)——[零样本学习](@article_id:639506)（Zero-Shot Learning, ZSL）。我们将首先探索ZSL的基础“原理与机制”，揭示它如何创建一个共享的意义空间来连接不同类型的数据。然后，在“应用与跨学科联系”部分，我们将遍览其对从计算机视觉到医学等领域的变革性影响，展示这种强大的方法如何重塑科学发现。

## 原理与机制

当你听到一种你从未见过的动物的描述时——比如说，㺢㹢狓，被描述为有斑马的腿和长颈鹿的身体——你怎么能形成一个相当准确的心理图像？你并不需要照片。你施展了一种魔法，将已知的概念融合起来，合成了对未知事物的表征。这种“零样本”识别的行为是一项了不起的智能壮举，我们现在正将它传授给我们的机器。这种数字炼金术背后的原理不仅仅是巧妙的编程技巧；它们是关于知识、语言和感知本质的深刻思想。

### 核心思想：一个共享的意义空间

[零样本学习](@article_id:639506)（ZSL）的核心在于一个优美而简单的概念：创建一个公共基础，一个**语义[嵌入空间](@article_id:641450)**，在这里不同形式的信息可以相遇并进行比较。想象一个巨大的多维图书馆，每个概念都有一个特定的位置。在一个角落，你有狗的视觉表征，这是通过分析数千张狗的图片得出的。在另一个角落，你有*词语*“狗”的位置。ZSL模型的目标是学习一个通用的[坐标系](@article_id:316753)，使得狗的图片和词语“狗”能够紧挨在一起。

一旦这个空间建立起来，分类就变成了寻找最近邻居的练习。当模型看到一张新图片——比如一只猫，这是它从未被训练过的——它会将这张图片映射到图书馆中的一个点。为了弄清楚它是什么，模型只需查看它所知道的文本标签，如“猫”、“狗”和“汽车”，在同一个图书馆中找到它们的位置，然[后选择](@article_id:315077)离图片位置最近的标签。猫的图片自然会比词语“汽车”更接近词语“cat”。这就是基本机制，一个在高维意义空间中进行的游戏。

### 构建图书馆：两种哲学方法

我们如何构建这个神奇的图书馆？历史上，出现了两种主要的哲学，各有其优雅之处和挑战。

#### 图书管理员的方法：通过属性获取知识

一种方法是做一个一丝不苟的图书管理员，通过定义性特征或**属性**来明确地为每个概念编目。这是**基于属性的ZSL**的基础。我们教模型“老虎”具有诸如 `{是猫科动物, 有条纹, 是食肉动物}` 这样的属性，而“狮子”则具有 `{是猫科动物, 有鬃毛, 是食肉动物}`。

模型学习一个[从属](@article_id:336873)性的抽象世界到视觉特征的具体世界的映射，我们称之为 $W$。视觉特征由向量 $\phi(x)$ 表示。通过观察许多老虎的图片，它学习到“条纹”通常是什么样子；通过斑马的图片，它进一步完善了这种理解。它在学习将一个语义属性列表翻译成一个视觉原型。

为了识别一个未见过的类别，比如豹，我们提供它的属性列表：`{是猫科动物, 有斑点, 是食肉动物}`。模型使用其学到的翻译器 $W$ 为豹生成一个“想象中”的视觉[特征向量](@article_id:312227)：$W a_{\text{leopard}}$。然后，它将这个想象中的原型与未知图像的实际[特征向量](@article_id:312227) $\phi(x)$ 进行比较。最接近的匹配获胜。这种方法的成功取决于一个关键条件：*已见*类别的属性必须足够多样化，以覆盖整个属性“空间”。如果不是这样，模型就无法唯一地学习到翻译器 $W$，这个问题被称为不[可识别性](@article_id:373082)，这使得它无法可靠地泛化 [@problem_id:3125728]。

#### 语言学家的方法：从语言中获取知识

更现代、也可以说更强大的方法是像语言学家一样行事。我们不是费力地定义属性，而是利用人类语言中早已存在的巨大结构。这就是像CLIP（Contrastive Language-Image Pre-training，对比语言-图像[预训练](@article_id:638349)）这样的突破性模型背后的[范式](@article_id:329204)。

模型被赋予一个简单而艰巨的任务：使图像的[嵌入](@article_id:311541) $\phi(x)$ 和其对应文本描述的[嵌入](@article_id:311541) $g(t)$ 在共享的语义空间中尽可能接近。在对来自互联网的数亿个图像-文本对进行训练后，模型对语言如何映射到视觉世界产生了极其丰富的理解。

然后，分类变得异常直接。给定一张未知物体的图像，模型计算其[嵌入](@article_id:311541) $\phi(x)$。然后，它获取可能的类别名称的文本——“猫”、“狗”、“自行车”——并使用文本[编码器](@article_id:352366)计算它们的[嵌入](@article_id:311541)。预测的类别就是其文本[嵌入](@article_id:311541)与图像[嵌入](@article_id:311541)具有最高**[余弦相似度](@article_id:639253)**的那个 [@problem_id:3125810]。这个单一而优雅的原则使得模型能够对几乎无限的类别进行分类，只要这些类别可以用词语来描述。

### 魔鬼在细节：从原则到实践

虽然核心思想很优雅，但要使其可靠地工作，需要应对一系列有趣而微妙的挑战。

#### 提示的艺术

事实证明，仅仅使用像“猫”这样的单字标签并非最佳选择。文本[编码器](@article_id:352366)在给定一个更自然的句子时效果最好。这就催生了**提示工程**（prompt engineering）的艺术。我们可能使用提示“一张猫的照片”来代替“猫”。这个看似微小的改变提供了关键的上下文，从而得到更好的文本[嵌入](@article_id:311541)。

在现代语言模型中，这通常通过“填空”任务来实现。模型被给予一个模板，如“评论：[句子]。它是[MASK]。”并被要求预测`[MASK]`标记最可能的词。为了对情感进行分类，我们定义了**描述器**（verbalizers）：一组对应于每个类别的词（例如，`{"好", "很棒"}`代表正面，`{"差", "糟糕"}`代表负面）。我们根据正面词的总概率是否高于负面词的总概率来对句子进行分类。这揭示了一个关键的敏感性：将描述器从“很棒”改为“不错”可能会改变最终的决定，这凸显了这个过程的微妙之处 [@problem_id:3102497]。

这种提示的思想可以形式化为一个转换矩阵 $A_p$，它修改了基础的文本[嵌入](@article_id:311541)。[零样本学习](@article_id:639506)使用一个默认的“恒等”提示，而少量的样本可以用来*调整*提示，选择最佳的转换以提高准确性 [@problem_id:3178397]。这巧妙地弥合了[零样本学习](@article_id:639506)和[少样本学习](@article_id:640408)之间的差距。

#### 歧义的危险

语言是混乱的。许多词是多义的——它们有多种含义。以“bass”这个词为例。它可以指一种鱼，也可以指一种乐器。对“bass”的一个朴素的文本[嵌入](@article_id:311541)将是这两个不同概念的混乱平均值。一张大口黑鲈的图片与这个混乱的向量的相似度得分会很低，因为[嵌入](@article_id:311541)中的“乐器”部分把它拉远了。

解决方案是通过上下文消除歧义。我们可以使用一个简短的定义，如“bass，一种淡水鱼”，而不是标签“bass”。这提供了必要的上下文，产生一个精确聚焦于预期含义的文本[嵌入](@article_id:311541)，并显著提高分类准确性 [@problem_gdid:3125805]。

#### 用知识图谱连接点滴

现实世界中的类别不是孤立的岛屿；它们是相互关联的。猫与老虎有关，老虎又与狮子有关。我们能利用这种关系结构吗？是的，通过**知识图谱**。

想象一个图，其中每个类别是一个节点，边连接相关的类别。对于ZSL，我们从训练期间见过的类别的强大、可靠的[嵌入](@article_id:311541)开始，但未见过的类别开始时什么都没有——一个[零向量](@article_id:316597)。然后我们运行一个**[拉普拉斯平滑](@article_id:641484)**的过程，其中已见类别的[嵌入](@article_id:311541)会“泄漏”或沿着图的边传播到它们未见的邻居。未见的“豹猫”节点的[嵌入](@article_id:311541)将成为其已见邻居（如“猫”和“豹”）的混合体。这种平滑的强度由一个参数 $\beta$ 控制。当 $\beta=0$ 时，没有信息流动。随着 $\beta$ 的增加，更多的知识被共享，为未见类别提供一个有意义的初始表征 [@problem_id:3125725]。

### 在学习生态系统中的位置

[零样本学习](@article_id:639506)不是万能的，但它是更大学习[范式](@article_id:329204)生态系统中的一个强大工具。了解何时以及如何使用它与了解其机制同样重要。

#### 通过不确定性实现自我意识

我们应该多大程度上信任ZSL的预测？有些预测是自信的，而另一些则不过是猜测。我们可以使用**香农熵**来量化这种不确定性。集中在单个类别上的[概率分布](@article_id:306824)具有低熵（高[置信度](@article_id:361655)），而[均匀分布](@article_id:325445)在多个类别上的分布具有高熵（高不确定性）。

这种[不确定性度量](@article_id:334303)不仅仅是一个分数；它可以驱动行为。我们可以设计一个**熵感知**系统。例如，如果一个预测的熵高于某个阈值，表明存在混淆，模型可以触发一个特殊规则。它可能会提升未见类别的概率，这是一种启发式的推动，意思是：“当有疑问时，考虑新的东西。”这使得模型能够根据自身的[置信度](@article_id:361655)水平调整其策略 [@problem_id:3174144]。

#### 适应还是不适应？

当你有零个标记样本时（$k=0$），ZSL表现出色。但如果你获得了几个样本（$k>0$）呢？你应该使用这些样本来调整你的模型吗——这个过程称为**[少样本学习](@article_id:640408)（FSL）**？答案并不总是肯定的。如果新样本来自一个与模型原始训练数据非常不同的领域，试图适应实际上可能会损害性能。这种现象被称为**负迁移**。

为了防范这种情况，我们可以在适应之前计算一个**对齐分数**。这个分数衡量新数据平均表征与模型训练所用的基础数据平均表征之间的相似性。如果对齐度低，则表明存在负迁移的高风险。在这种情况下，最明智的策略是放弃FSL，坚持使用原始的、未经调整的ZSL模型 [@problem_id:3125802]。

最终，在零样本、少样本和完全微调之间的选择是一个权衡问题。每种方法都有不同的“[学习曲线](@article_id:640568)”，描述其性能如何随着更多数据而提高。ZSL在 $k=0$ 时给你一个基线。像上下文学习（In-Context Learning）这样的方法可能只需几个例子就能快速提升。微调可能需要更多数据才能启动，但可能达到更高的性能峰值。通过对这些曲线建模，我们可以确定一个**[范式](@article_id:329204)切换点** $k^{\star}$，即一种策略被证明优于另一种策略所需的样本数量 [@problem_id:3195216]。这为在[现代机器学习](@article_id:641462)的丰富领域中导航提供了一个有原则的框架，为手头的工作选择正确的工具。

