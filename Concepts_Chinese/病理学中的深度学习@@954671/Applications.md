## 应用与跨学科联系

窥探了病理学中深度学习模型的内部运作后，我们可能会倾向于认为我们的旅程已经结束。我们已经看到机器如何学习识别疾病的微妙纹理和形状。但这就像学会了国际象棋的规则却从未下过一盘棋。这项技术的真正美丽和力量只有在我们看到它在行动中展开时才会显现——当它离开计算机的原始世界，进入复杂、混乱且充满人性的医学 生态系统时。这才是真正乐趣的开始，因为病理学中的[深度学习](@entry_id:142022)并非一座孤岛；它是一座桥梁，连接着从分子生物学、临床肿瘤学到认知科学和道德哲学等众多领域。

### 教会机器观察的艺术与科学

在人工智能能够辅助病理学家之前，它必须首先成为一名学生。而教导它是一门植根于科学的艺术。我们不能简单地将一个图像库扔给机器，然[后期](@entry_id:165003)望得到最好的结果。我们必须以结构化的方式教它认识世界。

考虑一个基本事实：无论癌细胞在切片上的方向如何，它仍然是癌细胞。这对我们来说似乎显而易见，但一个天真的算法必须学习这一点。我们通过使用*数据增强*来帮助它，这是一个创建我们训练图像的修改副本的过程。我们可能会旋转图像、翻转它，或者更微妙地，改变它的颜色，以模仿苏木精和伊红 (H&E) 染色在不同实验室之间，甚至不同日期之间发生的真实世界变化。

但这不是一个[随机过程](@entry_id:268487)。每一个选择都是一个微妙的权衡。如果我们以任意角度旋转图像，比如 $37^\circ$，离散的像素网格需要插值，这可能会模糊我们希望模型看到的特征。轻微的高斯模糊可能有助于模型对轻微的对焦问题变得鲁棒，但过多的模糊会抹去对诊断至关重要的小[核仁](@entry_id:168439)。决定模糊多少可以严格地基于成像物理学和信号处理，确保我们保留与最小、最重要细胞结构相对应的高频信息 [@problem_id:4321289]。

有时，我们需要的数据根本无法收集。想象一下，我们想训练一个模型来执行“虚拟染色”——从一张未染色的、无标记的图像（也许是用[自发荧光](@entry_id:192433)捕获的）开始，预测组织用 H&E 染色后会是什么样子。理想的训练数据将是完美配准的图像对：一张未染色，一张染色，来自完全相同的组织切片。但染色过程会物理上改变和变形组织。获得完美的像素到像素匹配是一项艰巨的任务。

在这里，机器学习的一个绝妙想法来拯救了我们。我们不要求完美的*配对*数据，而是可以使用*非配对*数据集——一个未染色图像的集合和另一个完全独立的染色图像集合。一个简单的像素级比较将毫无意义；这就像试图通过比较随机的英语句子和随机的法语句子来学习法语一样。模型只会学会生成一个模糊的、看起来平均的图像。取而代之，我们使用更复杂的技术，如[生成对抗网络](@entry_id:634268) (GANs)，它们不比较单个像素，而是比较图像的整体*分布*。它们会问：“这个生成的 H&E 图像看起来像是从真实 H&E 图像集中抽取的吗？” 这种方法，通常与确保转换后的图像可以转换回其原始状态的“循环一致性”损失相结合，允许模型学习从一个域到另一个域的转换，而无需看到完美的配对 [@problem_id:4357357]。这是一个解决了非常实际问题的抽象飞跃。

### 数字病理学家的工具箱

一旦训练完成，这些模型就成为强大的工具。它们可以自动化繁琐的任务，揭示隐藏的模式，并提供以前无法获得的定量见解。

一个典型的挑战是计数[有丝分裂](@entry_id:143192)象，这是肿瘤增殖和分级的关键指标。人类病理学家扫描切片，但当肿瘤很厚并且被切成多个连续切片时会发生什么？同一个有丝分裂细胞可能出现在两个相邻的切片中。将其计数两次会人为地提高分级。解决方案在于一项作为计算机视觉基石的任务：*图像配准*。通过数字方式对齐相邻的组织切片，人工智能可以识别并合并跨切片的同一对象的检测结果，确保每个生物学事件只被计数一次。这将定性的观察任务转变为精确的三维定量分析 [@problem_id:4321811]。

也许最令人兴奋的前沿是人工智能在形态学（细胞的外观）和分子生物学（细胞内部发生的事情）之间架起桥梁的能力。生物学的中心法则告诉我们，基因型决定表型。像*异柠檬酸[脱氢酶](@entry_id:185854)* ($IDH$) 这样的[基因突变](@entry_id:166469)或*表皮生长因子受体* ($EGFR$) 基因的扩增，不仅改变了细胞的内部信号传导；它还改变了细胞的行为、新陈代谢，并最终改变了它的外观及其与邻近细胞的组织方式。训练有素的病理学家学会识别其中一些形态学上的关联。但人工智能可以以超人的敏感度学会观察它们。

通过在已知分子标签的 H&E 切片上训练模型，我们可以创建一个算法，直接从标准的、廉价的 H&E 图像中预测肿瘤的遗传状态。例如，它可能会学到胶质瘤中微妙的核均匀性和微囊性变化是潜在 $IDH$ 突变的低语，或者华丽的血管增生和坏死是 $EGFR$ 扩增的标志 [@problem_id:4328967]。这种“表型中的基因型”预测对于个性化医疗来说是颠覆性的，可能允许对[靶向治疗](@entry_id:261071)进行快速、低成本的筛选。

然而，这种巨大的力量伴随着对科学严谨性的巨大责任。人工智能是一个强大的相关性发现机器，但它没有常识。它不知道为什么两件事是相关的。假设一家医院的患者群体中有许多非吸烟者，而这些人已知有更高的 $EGFR$ 突变发生率。在这个医院的切片上训练的人工智能可能会学到，肺部*缺乏*与吸烟相关的黑色素是 $EGFR$ 突变的一个良好预测指标。这在训练数据中是一个真实的相关性，但它不是肿瘤本身的*因果*特征。这是一个人口统计学的混杂因素。当这个模型部署到另一个患者群体不同的医院时，其性能将崩溃。同样的问题也可能出现在技术伪影上，比如特定扫描仪的微妙色偏，甚至是切片上的水印，只要它们恰好与训练集中的标签相关 [@problem_id:2382936]。这迫使我们不仅要成为计算机科学家，还要成为流行病学家和因果推断的侦探，设计我们的研究以确保人工智能学习的是真正的生物学，而不仅仅是聪明的捷径。

除了诊断，这些工具还可以帮助预测患者的未来。通过分析肿瘤和免疫细胞的复杂空间模式，人工智能可以生成一个预测患者预后的特征向量 $x$。但这里我们进入了生物统计学的复杂世界。预测生存并不简单。癌症患者有*因*癌症死亡的风险，但也有因心脏病等其他原因死亡的风险——这是一个“[竞争风险](@entry_id:173277)”。这些事件类型不是独立的。对于研究特征对肿瘤的生物学效应的研究者（一个病因学问题），对*特定原因风险*进行建模可能是合适的，它代表了在一个将其他死因视为仅是删失的世界里，癌症死亡的瞬时风险。但对于希望知道未来五年内死于癌症的真实世界绝对概率的患者及其临床医生来说，这不是正确的工具。为此，我们需要对*子分布风险*进行建模，这是一个不同的统计量，它正确地考虑了因其他原因死亡会永久地将患者从癌症死亡风险中移除这一事实。选择正确的模型对于向患者提供准确的预后信息至关重要 [@problem_id:4322348]。

### 从算法到临床现实

一个经过验证的算法仍然只是一个算法。要产生影响，它必须被编织进临床工作流程的结构中。这本身就是一门学科，融合了健康信息学、决策理论和人因工程学。

首先，人工智能必须学会“说”医院信息系统的“语言”。它的输出——概率、分类标签、分割掩码——不能被困在研究文件夹里。它们必须安全、明确地传输到电子健康记录 (EHR)。这是通过像 HL7 FHIR 这样的[互操作性](@entry_id:750761)标准实现的。临床医生对人工智能分析的医嘱被编码为 `ServiceRequest`。人工智能的结构化输出，如癌症概率 $p$，被捕获为可计算的 `Observation` 资源。然后，这些资源与叙述性文本和图像附件一起被捆绑到一个 `DiagnosticReport` 中。这个高度结构化的过程确保了每一条数据都是机器可读、可审计的，并且与产生它的特定人工智能模型和版本相关联 [@problem_id:5203843]。

一旦整合，人工智能和人类病理学家就开始他们的二重奏。最有前途的模型之一是“第二次阅片”工作流程，其中人工智能扮演一个不知疲倦、警惕的助手。但应如何处理分歧？想象一下，病理学家说一个病例是良性的 ($H=0$)，但人工智能将其标记为可疑 ($A=1$)。这是否应该触发一次强制性的、昂贵的裁决审查？决策理论为我们提供了一个理性的框架。只有在*不*审查的预期成本超过审查本身的成本时，才应该触发审查。不审查的预期成本是人类出错的概率乘以该特定错误的成本。

在我们的例子中 ($H=0, A=1$)，错误是漏诊癌症（假阴性），其成本非常高，$C_{FN}$。我们应该在 $P(T=1 \mid H=0, A=1) \cdot C_{FN} \gt K_R$ 时进行审查，其中 $K_R$ 是审查的成本。在相反的情况下——病理学家说阳性，人工智能说阴性 ($H=1, A=0$)——潜在的错误是[假阳性](@entry_id:635878)，其成本要低得多，$C_{FP}$。规则变为 $P(T=0 \mid H=1, A=0) \cdot C_{FP} \gt K_R$。因为 $C_{FN}$ 通常远大于 $C_{FP}$，所以采取不对称策略可能是理性的：当人工智能标记了人类称为阴性的病例时总是审查，但反之则不一定 [@problem_id:5203872]。这不仅仅是关于准确性；这是关于设计一个明智分配资源以最小化伤害的系统。

此外，我们必须教临床医生如何解释人工智能的输出。模型的敏感性和特异性是固定属性，但其预测在真实世界中的意义并非如此。使用[贝叶斯定理](@entry_id:151040)，我们可以计算阳性预测值 ($PPV$)——即在人工智能给出阳性标记的情况下，患者实际患病的概率。这个值关键取决于被测试人群中疾病的患病率。对于罕见病，即使是高度准确的测试也会有惊人低的 $PPV$；大多数阳性标记将是假警报。负责任的部署要求传达这些根据当地患者群体校准的预测值，以便临床医生在最终判断中能恰当地权衡人工智能的建议 [@problem_id:4405413]。

### 更广阔的视角：伦理、认知和法律维度

将人工智能整合到病理学中，迫使我们面对远超技术范畴的问题。在开发用于为一种癌症分级的人工智能时，如果它偶然学会了发现一种完全不同、不相关但可治疗的疾病——一个*意外发现*，该怎么办？我们有义务报告这个吗？这里我们进入了生物伦理学的领域。行善原则（做好事的责任）和自主原则（尊重患者意愿）建议我们应该报告。不伤害原则（不造成伤害的责任）告诫我们不要报告一个未经证实的、可能引起焦虑并导致不必要检查的研究发现。法律，通过像 CLIA 这样的法规，禁止使用未经认证的实验室结果进行临床护理。在伦理和法律上稳妥的途径是一个经过机构审查委员会 (IRB) 批准的、严格管理的过程，该过程尊重患者事先就接收此类信息所作的同意，并要求任何研究发现在返回给患者之前必须在认证的临床实验室得到确认 [@problem_id:4326092]。

最后，我们必须考虑人工智能对病理学家自身的影响。一个普遍的担忧是*技能退化*——即通过依赖人工智能预筛选病例并标记可疑病例，病理学家将失去在大量阴性病例中发现罕见疾病的能力。这是一个植根于专业知识认知科学的真实担忧。技能是通过在有挑战性的案例上进行*刻意练习*并获得反馈来建立的。如果一个人工智能系统从病理学家的工作流程中移除了所有简单的阴性病例，它也移除了他们不断确认基线并保持敏锐的机会。这种现象被称为*认知卸载*。

然而，我们可以设计工作流程来减轻这种风险。我们可以确保病理学家仍然审查一部分由人工智能清除的病例的随机样本。更好的是，我们可以实施一种“影[子模](@entry_id:148922)式”，即在一小部分病例中，病理学家在看到人工智能的建议*之前*做出自己的诊断。这迫使他们动用全部的认知能力，之后人工智能的读片可以提供即时反馈——这是刻意练习的完美配方。通过仔细平衡人工智能的角色，我们可以创建一个系统，不仅对今天的患者更安全，而且还能成为未来病理学家的培训和技能维持平台 [@problem_id:4405491]。

从成像物理学到生物统计学的精妙之处，从[计算机视觉](@entry_id:138301)的逻辑到临床实践的伦理，病理学中的[深度学习](@entry_id:142022)证明了跨学科思维的力量。这是一个挑战我们的领域，不仅要构建更好的算法，还要构建更好、更安全、更智能的医疗保健系统。这段旅程揭示，最终目标不是取代人类，而是增强和协作，创造一个比任何一方单独所能看到的更多的伙伴关系。