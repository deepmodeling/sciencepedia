## 引言
每一天，全球医疗系统都在产生海量数据，但这些数据并非刻意的科学记录，而是其主要功能——患者护理和财务报销——的数字副产品。在这场数据洪流中，行政理赔（为计费和保险而创建的记录）构成了医疗接触的庞大纵向账本。这种“现成”数据为我们提供了一个前所未有的机会，让我们能够以前所未有的规模了解医疗干预在真实世界中的表现，这是传统临床试验无法想象的。然而，驾驭这种力量是一项深刻的科学挑战。因为这些数据是为支付而非研究而创建的，所以它是一面扭曲的临床现实之镜，充满了容易导致错误结论的偏倚。

本文旨在指导读者掌握将这些杂乱数据转化为可靠的真实世界证据（Real-World Evidence, RWE）的科学。它解决了拥有大型数据集与产生有效、可行的见解之间的关键知识鸿沟。通过两章内容，您将学习该领域的基本原理和实际应用。我们首先将深入探讨基础的“原理与机制”，探索理赔数据的独特性质、困扰其中的偏倚幽灵，以及流行病学家为驱除它们而使用的巧妙方法。随后，在“应用与跨学科联系”中，我们将看到这些方法的实际应用，展示 RWE 如何改变从药物安全监测、卫生政策到监管科学本身的方方面面。

## 原理与机制

想象一下，你不是一位研究古代生物的[古生物学](@entry_id:151688)家，而是一位研究现代医学的古生物学家。你没有时间机器去观察一种新药在成千上万人的日常生活中*实际上*如何影响他们。相反，你拥有一份庞大而奇特的化石记录：医疗系统留下的浩瀚的数字面包屑。这些并非来自有计划实验的整洁现场笔记；它们是一项完全不同活动——计费、保险和医院运营这一复杂机器——的偶然副产品。这份数字化的[化石记录](@entry_id:136693)就是我们所说的**真实世界数据（Real-World Data, RWD）**，而从中提取真相的科学是现代医学中最令人兴奋和最具挑战性的领域之一[@problem_id:4587700]。

本章的任务是理解支配这个数据世界的原理和机制。我们将学习解读其奇特的语言，识别萦绕在其走廊中的幽灵，并领会科学家们为将这些杂乱的“现成”数据转化为可靠的**真实世界证据（Real-World Evidence, RWE）**而设计的巧妙工具。

### 意图的阴影：三种数据源的故事

并非所有数据生而平等。其创建的原因深刻地塑造了它的特性。要理解行政理赔数据，我们必须首先将其置于上下文中，与它的表亲——电子健康记录（EHR）和随机对照试验（RCT）数据集——进行比较。

*   **为患者护理而生（EHR）：** 电子健康记录是患者的临床日记，由医生和护士书写。其主要目的是支持直接的患者护理。它包含丰富但有时混乱的叙述：临床笔记、详细的实验室结果、实时的生命体征以及临床医生的思维过程[@problem_id:4856391]。其语言可能复杂多变，混合了结构化术语（如用于诊断的 SNOMED CT）和非结构化的自由文本。其激励因素是临床文档记录和安全性。它旨在讲述*一个*病人的故事。

*   **为回答问题而生（RCT）：** 随机对照试验是为设计而生的数据。它的创建唯一目的就是回答一个特定的科学问题。患者被随机分配到不同的治疗组，数据根据严格的方案被一丝不苟地收集，环境受到控制。随机化是其神奇的成分；它旨在使比较组除了接受的治疗外，在所有方面都相同，从而分离出治疗的真实效果[@problem_id:4550458]。它是一个原始的、为特定目的构建的数据集。

*   **为获取报酬而生（行政理赔数据）：** 接下来就是我们的化石记录了。行政理赔数据是为报销而生成的。每当医生提供一项服务、医院接收一名患者或药房配发一种药物时，都会向保险公司发送一份理赔申请以获取支付。这份理赔是医疗接触的高度标准化、精简的摘要。它不包含医生的叙述或患者每分钟的血压。相反，它包含代码——一种计费速记。诊断使用**国际疾病分类（International Classification of Diseases, ICD）**进行记录，而操作则使用**现行程序术语（Current Procedural Terminology, CPT）**[@problem_id:4637124]。

“生成激励”决定了一切。其主要目标是财务。这意味着数据在告诉我们什么被计费方面非常出色，但它可能是临床现实的一面扭曲的镜子。一个能增加报销的病症可能会被勤奋地编码，而一个临床上重要但不可计费的细节可能付之阙如。这可能会夸大某些诊断在数据中的患病率，这是我们必须时刻铭记的一种偏倚[@problem_id:4856391]。其时间分辨率也较粗糙；一份理赔告诉你一个操作发生在某*天*，而不是某个具体的*分钟*。这使得它不适合研究快速的生理变化，但对于跨越整个卫生系统追踪多年的医疗接触却非常强大。

### 模拟一场幽灵试验

所以，我们有了这份庞大但不完美的[化石记录](@entry_id:136693)。我们如何用它来回答诸如“新药A在预防心脏病方面是否优于旧药B？”这样的问题呢？我们不能简单地计算服用药物A与药物B的人群中心脏病发作的次数。那太简单了，而且错得离谱。

使用RWD的核心挑战在于我们没有控制谁得到了哪种药物。是医生做的决定。而医生并不会通过抛硬币来分配治疗。他们会将某些药物给予病情更重的患者，另一些给予更健康的患者，还有一些给予先前治疗失败的患者。这在比较组开始治疗之前就造成了深刻的差异。

为了克服这一点，科学家们开发了一个强大的框架：**目标试验模拟（target trial emulation）**[@problem_id:5054571]。其思想是利用观察性数据来尽可能地模仿我们*希望*能够进行的随机试验。我们一丝不苟地规定试验的方案——入选标准、治疗策略、随访期、结局——然后我们将该方案应用于我们的数据，试图在事后重建该试验。这种严谨的方法是我们对抗机器中幽灵的主要防御手段。

### 机器中的幽灵：偏倚实地指南

因为我们处理的是“现成”数据，我们必须应对几种系统性偏倚——如果我们不小心，这些幽灵会误导我们。学会看到它们是驱除它们的第一步。

#### 原罪：适应证混杂

这是所有[观察性研究](@entry_id:174507)中最根本的偏倚。假设我们正在比较一种强效的新心脏药物（药物A）和一种较温和的旧药（药物B）。医生更有可能将药物A开给心脏病发作风险极高的患者。如果我们只看数据，我们可能会发现服用药物A的人中有更多的人心脏病发作！这不是因为药物A有害；而是因为接受它的人一开始就病情更重。这就是**适应证混杂（confounding by indication）**：开具药物的医学原因（适应证）同时也是结局的一个原因[@problem_id:4550458]。与RCT中随机化打破了这种联系不同，在RWD中，这种联系正是临床实践的本质。我们的任务是统计上调整这些基线差异，以试图恢复公平的比较。

#### 时间之矢 I：不[死时间](@entry_id:273487)偏倚

这是一个微妙而美丽的陷阱，一个时间本身的悖论。想象一个研究设计，我们把“暴露组”定义为接受了药物A并在诊断后存活了至少30天的患者。我们将他们与从诊断那一刻起的“非暴露组”进行比较。根据我们的定义，暴露组中没有人在最初的30天内死亡——他们的时间是“不死的”。这为暴露组创造了一个巨大的、人为的生存优势，而这与药物无关。

每当随访的开始与治疗的开始未对齐时，这种偏倚就会悄然而至。解决方案是现代药物流行病学的一个基石：**新使用者设计（new-user design）**。我们将每个患者的**指数日期（index date）**（时间零点）定义为他们开始新疗法的精确时刻。随访，或称**风险窗口（risk window）**，从那一刻开始。为确保他们是真正的“新”使用者，我们在指数日期前检查一个**回看期（look-back period）**，以确认他们之前没有使用过该药物[@problem_id:5054666]。这种正确定义时间零点的简单而优雅的纪律，斩杀了不[死时间](@entry_id:273487)的幽灵[@problem_id:5054571]。

#### 时间之矢 II：[路径依赖](@entry_id:138606)与动态混杂

情节变得更加复杂。当我们的变量不是静态的，而是随时间演变时会发生什么？真实世界的护理是一个动态过程。今天给予的治疗可以改变患者明天的健康状况，而这种健康状况的改变又可以影响下周选择的治疗。这被称为**[路径依赖](@entry_id:138606)（path dependence）**——你走过的路限制了你未来的步伐。

考虑一个心力衰竭患者开始使用[ACE抑制剂](@entry_id:149539)（$A_0$）。这种药物有一个已知的副作用，即有时会恶化肾功能（$L_1$）。一个月后，医生看到显示肾功能不佳的新实验室结果，决定停止[ACE抑制剂](@entry_id:149539)，并且不开始另一种药物（$A_1$）。肾脏问题现在是下一次治疗决策的混杂因素，但它也是由先前的治疗*引起*的。这创造了一个被称为**动态混杂（dynamic confounding）**的纠缠因果网络。标准的统计调整在这里会失败，因为如果我们调整肾脏问题，我们可能会意外地阻断我们想要研究的药物副作用的因果路径[@problem_id:5054512]。

#### 消失的行为：信息性删失

在一个完美的研究中，我们会在整个研究期间跟踪每一位患者。但在真实世界中，人们会从我们的数据中消失。他们可能会更换保险计划，搬到州外，或者去世。如果这种消失是随机的，那不是一个大问题。但如果不是呢？如果病情较重的患者更有可能失去工作和健康保险，从而从我们的理赔数据库中脱落呢？这被称为**信息性删失（informative censoring）**[@problem_id:5054594]。如果我们只分析留下的人，我们剩下的就是一个比原始群体更健康的“幸存者”队列，这会导致对治疗真实效果的偏倚看法。

#### 空白之处：当缺失数据会说话

最后，是缺失数据的问题。NT-proBNP的实验室值，一个心衰风险的关键预测因子，可能不在电子健康记录中。为什么？也许测试是在外部设施完成的。或者也许患者太健康了，医生甚至没有开这个检查。通常，数据缺失的原因本身就提供了信息。在一个引人注ulf的例子中，后来因心力衰竭住院（$Y=1$）的患者，可能*更*有可能进行并记录了该实验室测试，仅仅因为他们病情更重，接受了更密集的检查。这意味着暴露（$A$）的缺失与结局（$Y$）有关。简单地忽略有[缺失数据](@entry_id:271026)的患者（完全病例分析）将是一场灾难；我们将选择性地分析一个病情更重的偏倚子集，并得到错误的答案[@problem_id:5054789]。

### 工具一瞥

面对这一系列的偏倚，您可能会怀疑从RWD进行因果推断是否是一项无望的努力。并非如此。这只是一个需要极大谨慎、纪律和一套复杂统计方法工具箱的领域。虽然数学很深奥，但概念是直观的。

为了处理混杂，像**倾向性评分匹配（propensity score matching）**这样的方法可以帮助我们在治疗组和未治疗组中找到在基线时看起来非常相似的个体，从而创造一个公平的比较。对于随时间演变的更棘手的偏倚，如动态混杂和信息性删失，流行病学家使用强大的G方法。一个例子是通过**逆概率加权（Inverse Probability Weighting）**构建**边际结构模型（Marginal Structural Models）**。这种技术通过给个体加权，实质上创造了一个“伪人群”。每个人根据他们接受实际治疗和删失历史的概率的倒数进行加权。在这个重新加权的世界里，健康状况和后续治疗之间的联系被打破，从而可以无偏倚地估计治疗的效果[@problem_id:5054594]。

对于[缺失数据](@entry_id:271026)，我们不是丢弃它，而是可以使用像**[多重插补](@entry_id:177416)（Multiple Imputation）**这样的方法，根据我们在数据中观察到的关系，创建几个不同的合理的完整数据集。通过分析所有这些数据集并平均结果，我们可以将关于缺失值可能是什么的不确定性纳入考虑，从而给我们一个更诚实和准确的答案[@problem_id:5054789]。

这就是真实世界证据那美丽而错综复杂的舞蹈。它是一门关于阴影和回声的科学，关于解读一份从未为我们准备的化石记录的科学。它要求我们像物理学家一样思考系统，像侦探一样思考因果关系，像哲学家一样思考时间。通过这样做，我们可以将我们医疗系统平凡的数字副产品转化为拯救生命的深刻见解。

