## 应用与跨学科联系

在前面的讨论中，我们为[确定性计算](@article_id:335305)奠定了基石，将其视为一个充满完美秩序和可预测性的世界。但科学中的一个原理，其力量取决于它所建立的联系和解决的问题。因此，让我们暂时离开纯粹的理论世界，去探索当确定性这一理想与计算、科学乃至自然本身那混乱且常常看似随机的现实发生碰撞时，会发生什么。我们将发现，理解和驾驭确定性的追求不仅仅是一项学术活动；它是一段重塑我们解决问题能力的旅程，它支撑着现代科学探究的根基，甚至挑战着我们对“预测”未来的理解。

我们的指导性问题是：随机性是高效计算的根本要素，一种我们不可或缺的“秘方”吗？或者它仅仅是一个方便的工具，一个只要有足够的智慧就可以被纯粹确定性的钟表机制所取代的辅助工具？

### 驯服偶然的追求：计算机科学中的[去随机化](@article_id:324852)

当今已知的许多最聪明、最快速的[算法](@article_id:331821)都是“赌徒”。它们通过随机猜测来寻找解决方案，并且*在平均情况下*表现得出奇地好。一个典型的例子是测试一个非常大的数是否为素数——[概率算法](@article_id:325428)可以以惊人的速度完成这项任务，且出错的概率极小。这种对偶然性的依赖让理论家感到不安。我们能否在不掷骰子的情况下获得同样的速度和确定性？这就是*[去随机化](@article_id:324852)*的目标。

消除随机性最直接、尽管有些粗暴的方法是尝试所有可能性。如果一个[概率算法](@article_id:325428)依赖于一个，比如说，100位的随机比特串，那么一个确定性版本可以简单地将[算法](@article_id:331821)运行 $2^{100}$ 次，每次使用一个可能的随机串，然后统计结果。对于**BPP**类（可通过[概率算法](@article_id:325428)高效解决的问题）中的任何问题，这种暴力方法都能给出一个完全确定性且保证正确的[算法](@article_id:331821) [@problem_id:1450958]。然而，其代价通常是天文数字，将一个[多项式时间算法](@article_id:333913)转变为一个[指数时间](@article_id:329367)[算法](@article_id:331821)。这告诉了我们一些深刻的道理——随机性并非万能，因为它的效果可以被确定性地模拟——但这很难算是一个实际的胜利。

为了做得更好，我们需要的是智慧，而不仅仅是蛮力。这引出了现代计算机科学中最优美的思想之一：使用**[伪随机数生成器](@article_id:297609) (PRG)** 的*欺骗艺术*。PRG 是一个确定性过程，它接受一个短的、真正随机的字符串——即“种子”——并将其扩展成一个更长的字符串，这个长字符串虽然不是真正随机的，但却“足够随机”以欺骗特定的[算法](@article_id:331821)。想象一下，我们不再需要尝试所有 $2^{100}$ 个可能的随机串，而只需要尝试几千个能有效捕捉[算法](@article_id:331821)所关心的所有情景的“特殊”字符串。

这正是 PRG 让我们能够做到的。如果我们有一个 PRG，它能接受一个长度为，比如说 $c \log n$ 的短种子，并生成我们[算法](@article_id:331821)所需的那个长随机串，我们就可以通过简单地遍历*所有可能的种子*来创建一个确定性[算法](@article_id:331821) [@problem_id:1457795] [@problem_id:1420517]。由于种子的数量很少（$2^{c \log n} = n^c$，一个多项式级别的数量），整个过程仍然是高效的！我们已经在[多项式时间](@article_id:298121)内确定性地模拟了[概率算法](@article_id:325428)。这揭示了一个被称为“困难性与随机性”[范式](@article_id:329204)的惊人联系：那些*计算上困难*的函数（特别是像好的 PRG 那样难以求逆的函数）的存在，使我们能够消除[算法](@article_id:331821)中对随机性的需求。这一研究领域的最高奖项将是证明 **P = BPP**，这将保证对于任何可用随机性高效解决的问题，都存在一个同样高效且永远正确的确定性[算法](@article_id:331821) [@problem_id:1457830]。

还有另一条完全不同的通往确定性的路径，我们可以称之为*明智选择法*。我们不是模拟随机性，而是做出一些列局部最优的确定性选择，这些选择可被证明能导向一个全局良好的结果。这就是**条件期望法**。考虑将一个[网络划分](@article_id:337489)为两部分以最大化两部分之间连接数的问题——即[最大割问题](@article_id:331246)。一个简单的随机化方法——通过掷硬币将每个节点分配到一侧——产生的割集平均包含一半的边。为了[去随机化](@article_id:324852)，我们逐个处理节点。在每一步，对于一个给定的节点，我们计算如果将它放入集合 $S_1$ 与放入集合 $S_2$ 时，最终割集大小的*[期望值](@article_id:313620)*，这里假设所有后续决策都是随机做出的。然后，我们确定性地将该节点放入[期望值](@article_id:313620)较高的那个集合 [@problem_id:1481521]。通过总是选择更有希望的路径，我们确保最终确定性构建的割集至少与[随机化算法](@article_id:329091)的平均结果一样大。这种优雅的技术提供了一个具有保证性能比的确定性[算法](@article_id:331821)，这在工程和优化领域是一个至关重要的特性，因为在这些领域中，可预测的质量至高无上 [@problem_id:1481520]。

这种确定性与[非确定性](@article_id:328829)方法之间的[张力](@article_id:357470)不仅出现在时间复杂性中，也出现在内存（空间）复杂性中。著名的**路径问题 (PATH)**——判断图中两个节点之间是否存在路径——是 **NL** 类（[非确定性对数空间](@article_id:328476)）的基石。如果能发现一个解决**路径问题**的确定性[对数空间算法](@article_id:334558)，将产生巨大的影响：它将意味着整个 **NL** 类坍缩为 **L** 类（确定性对数空间），从而证明对于空间受限的计算，非确定性并不提供额外的能力 [@problem_id:1435014]。

### 确定性作为科学的基石：可复现性危机

让我们走出[复杂性理论](@article_id:296865)的世界，进入现代计算实验室。科学方法建立在一个神圣的原则之上：可复现性。一个实验必须能被他人重复，才能被认为是有效的。在一个实验越来越依赖于硅芯片的时代，“可重复”就意味着计算上的确定性。然而，许多科学家正面临一场“可复现性危机”，即在相同的数据上运行相同的代码，却得到了令人沮丧的不同结果。

罪魁祸首众多且常常隐藏。例如，在训练深度学习模型时，随机性无处不在：网络的初始随机权重、训练周期之间数据的随机打乱，甚至在 GPU 上进行的[并行计算](@article_id:299689)中，为了速度，某些操作被允许是[非确定性](@article_id:328829)的 [@problem_id:1463226]。在这里实现确定性不是一个理论游戏，而是一门细致的工程学科。它要求为流水线中的每个[随机数生成器](@article_id:302131)设置固定的种子——在 Python 中、在 NumPy 中、在深度学习框架中——并明确指示 GPU 使用速度较慢但确定性的[算法](@article_id:331821)。

为什么要费这么大劲呢？原因很深刻，可以通过统计学的视角来理解。一个模型的最终性能指标是一个[随机变量](@article_id:324024)。其总方差可以分解为两部分：来自非确定性选择（种子、硬件、软件版本）的方差，以及来自诸如[浮点数](@article_id:352415)[舍入误差](@article_id:352329)等因素的不可约方差。通过固定每一个[非确定性](@article_id:328829)来源——通过在容器中记录确切的软件版本、记录硬件信息、并在一个可验证的图中捕获整个工作流——我们迫使第一项，即每次运行间的变异性，降为零 [@problem_id:2479706]。这使得我们结果的方差收缩，让我们确信我们报告的准确率是对我们模型的真实度量，而不是[随机数生成器](@article_id:302131)带来的侥幸。在这种背景下，[确定性计算](@article_id:335305)是确保数字科学完整性和可审计性的工具。

### 超越随机性：确定性世界中的预测极限

我们在本章中致力于消除随机性，以使计算变得可预测。但如果一个系统是完全确定的——没有掷骰子，没有随机选择——而其未来在实践中仍然根本无法预测，那会怎样？这就是**[计算不可约性](@article_id:334547)**这个迷人而又令人谦卑的思想。

考虑一个简单的[元胞自动机](@article_id:328414)（CA），它是一排细胞，每个细胞在下一时刻的状态由其邻居的简单固定规则决定 [@problem_id:1421579]。这个系统正是确定性的定义本身。然而，对于某些规则，从一个简单的初始种子演化出的模式是惊人地复杂，看似混乱和随机。如果一个过程没有捷径来知晓其未来状态，那么它就被称为计算不可约的。你无法通过解一个方程或应用一个简单的公式来跳跃到未来；找出一百万步后会发生什么的唯一方法，就是一步一步、痛苦地运行一百万步的模拟。这个计算过程本身就是它自己最短的描述。

这带来了惊人的启示。如果一个生物过程，比如一个有机体从单个细胞（基因型）发育到其最终形态（表型）的过程，是计算不可约的，那么可能就没有办法在不模拟整个复杂的细胞发育之舞的情况下预测最终的有机体。这表明，即使拥有完整的生命“蓝图”和对确定性生物化学法则的全部知识，其结果可能仍然超出了预测计算的范围，只能通过观察过程的展开来知晓。

或许我们宇宙中一些最复杂的系统——天气、流体的[湍流](@article_id:318989)、经济的波动——就具有这种性质。它们受确定性定律支配，但其行为在计算上是如此之深，以至于它们的长期演化对我们来说是隐藏的，其原因不是偶然性，而是确定未来所需的纯粹的、不可约的计算工作量。

于是我们的旅程又回到了起点。我们开始时试图驯服偶然性，用可预测的[确定性计算](@article_id:335305)的钟表机制来取代它。我们发现了强大的理论工具来实现这一点，这些工具对于什么是可高效计算的有着深远的意义。然后我们看到，对确定性的同样追求，是严谨的现代科学的必要支柱。但最后，我们不禁思考这样一种可能性：宇宙本身，即使是完全确定的，也可能正在进行一场如此深刻的计算，以至于它的最终命运永远无法被预知，只能在它发生时被见证。宇宙可能不掷骰子，但这并不意味着它会轻易地交出它的秘密。