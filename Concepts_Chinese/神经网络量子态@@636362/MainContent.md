## 引言
量子力学为我们提供了支配微观世界的基本规则，但对于包含许多相互作用粒子的系统，求解其方程往往因“[维度灾难](@entry_id:143920)”而在计算上是不可能的。这一挑战长期以来阻碍了我们理解高温超导或[大分子](@entry_id:150543)行为等复杂现象。本文介绍了一种革命性的方法，它将量子物理与人工智能联系起来：[神经网](@entry_id:276355)络[量子态](@entry_id:146142)（NQS）。通过利用[神经网](@entry_id:276355)络作为系统[波函数](@entry_id:147440)的高度灵活的猜测所具有的表达能力，我们可以通过优化找到极其精确的近似解。本文将首先探讨NQS的核心“原理与机制”，详细说明[神经网](@entry_id:276355)络如何表示[波函数](@entry_id:147440)以及如何利用变分原理对其进行优化。随后，“应用与跨学科联系”一章将展示这一强大工具如何被用于解决凝聚态物理、[计算化学](@entry_id:143039)和核理论中的问题，从而推动科学发现的前沿。

## 原理与机制

量子力学的核心是薛定谔方程，这个规则手册原则上告诉我们关于一个系统的一切。对于一个围绕质子运动的单一电子，其解是优雅的杰作。但只要再增加几个粒子，这个优雅的方程就会膨胀成一个极其复杂的庞然大物。描述哪怕几十个相互作用粒子的[波函数](@entry_id:147440)所需的[信息量](@entry_id:272315)，也超过了地球上所有计算机的总和。这就是臭名昭著的**[维度灾难](@entry_id:143920)**，它是一道巨大的壁垒，阻碍了我们对许多迷人的量子现象（从高温超导到复杂分子的精妙之处）的完全理解。

那么，我们该如何继续？如果我们找不到精确的答案，或许我们可以找到一个非常非常好的近似。这就是[量子物理学](@entry_id:137830)中最强大的思想之一——**[变分原理](@entry_id:198028)**背后的哲学。

### 一种新的猜测：[变分原理](@entry_id:198028)

想象一下，你正试图在一个广阔而多雾的山谷中找到最低点。你看不到整个地貌，但你有一个高度计可以告诉你当前的海拔。变分原理就是我们的量子高度计。它陈述了一个非常简单的事实：你为*任何*对真实[基态](@entry_id:150928)[波函数](@entry_id:147440)的猜测（无论多么离谱）所计算出的能量，将永远大于或等于真实的基态能量。它给了我们一个上界。

这个简单的事实彻底改变了游戏规则。寻找*精确*解这一不可能的问题，变成了一个可控的（尽管具有挑战性的）[优化问题](@entry_id:266749)：为[波函数](@entry_id:147440)做出最灵活、最有根据的猜测，然后系统地调整它以降低其能量。当你调整你的猜测，你的“高度计”读数下降时，你就知道你正在接近真实的[基态](@entry_id:150928)。目标是在你所选择的函数族中找到最佳的猜测——那个能带你到[能量景观](@entry_id:147726)中最低点的猜测。

但什么才算是一个“好的猜测”？我们需要一种数学形式——一个**变分[拟设](@entry_id:184384)**——它既要足够紧凑以便处理，又要足够灵活以捕捉定义多体[量子态](@entry_id:146142)的、极其复杂的关联与纠缠之网。几十年来，物理学家们基于物理直觉设计了各种巧妙的[拟设](@entry_id:184384)。但是，如果我们能使用一种以能够以任意精度逼近任何函数而闻名的工具呢？

### 作为[波函数](@entry_id:147440)的[神经网](@entry_id:276355)络

革命由此开始。我们可以重新利用机器学习的机制，特别是[人工神经网络](@entry_id:140571)，来作为我们的变分[拟设](@entry_id:184384)。一个[神经网](@entry_id:276355)络，其核心不过是一个具有大量可调“旋钮”——即其**权重**和**偏置**——的高度灵活的数学函数。我们不再训练它识别图片中的猫，而是训练它来表示一个[量子波函数](@entry_id:261184)。

对于一个自旋系统，其中每个自旋可以是向上（$+1$）或向下（$-1$），系统的一个构型就是一串数字，如 $\boldsymbol{\sigma} = (\sigma_1, \sigma_2, \dots, \sigma_N)$。我们设计一个[神经网](@entry_id:276355)络，它以这个列表 $\boldsymbol{\sigma}$ 作为输入，并输出一个单一的数字：波[函数的振幅](@entry_id:160674) $\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})$。网络所有权重和偏置的集合构成了我们的变分参数集 $\boldsymbol{\theta}$。

具体的架构可以变化。它可以是一个简单的单层网络，就像一些基础研究中使用的那样，它计算自旋构型 $\boldsymbol{\sigma}$ 的[波函数](@entry_id:147440)，形式如 $\Psi(\boldsymbol{\sigma}) = \cosh(\sum_{i} W_i \sigma_i + b)$ [@problem_id:1212321] [@problem_id:1212420]。或者，它也可以是一个更复杂的多层感知机或[受限玻尔兹曼机](@entry_id:636627)（RBM），后者拥有巨大的[表示能力](@entry_id:636759) [@problem_id:2410566] [@problem_id:1212460]。对于一个RBM，可见构型 $\boldsymbol{\sigma}$ 的[波函数](@entry_id:147440)是通过对所有可能的内部“隐藏”单元状态求和得到的，从而产生一个能够描述长程关联的高度非平凡函数：

$$
\Psi(\boldsymbol{\sigma}; \boldsymbol{\theta}) = e^{\sum_{i=1}^N a_i \sigma_i} \prod_{j=1}^M 2 \cosh\left( b_j + \sum_{i=1}^N W_{ij} \sigma_i \right)
$$

这种方法的美妙之处在于其普适性。我们不再受限于我们预设的物理概念；我们让一个强大的、通用的[函数逼近](@entry_id:141329)器为我们找到[基态](@entry_id:150928)的结构。网络的参数 $\boldsymbol{\theta}$ 是定义我们在可能的[波函数](@entry_id:147440)这一广阔“山谷”中位置的坐标。现在，我们只需要弄清楚如何读取我们的高度计。

### 测量猜测[波函数](@entry_id:147440)的能量

根据量子力学的规则，一个态 $|\Psi\rangle$ 的能量由[哈密顿算符](@entry_id:144286) $\hat{H}$ 的[期望值](@entry_id:153208)给出。[哈密顿量](@entry_id:172864)是系统的能量规则手册。对于横场[伊辛模型](@entry_id:139066)，这个[量子磁性](@entry_id:145792)研究中的主力模型，其形式为：

$$
\hat{H} = -J \sum_{\langle i,j \rangle} \hat{\sigma}_i^z \hat{\sigma}_j^z - h \sum_{i=1}^{N} \hat{\sigma}_i^x
$$

第一项描述了相邻自旋倾向于对齐（如果 $J > 0$）的能量偏好，并且是“对角的”，意味着它只依赖于当前的自旋构型 $\boldsymbol{\sigma}$。第二项由[横向场](@entry_id:266489) $h$ 驱动，引入了量子魔法。$\hat{\sigma}^x$ 算符是“非对角的”；它作用于一个构型以*翻转一个自旋*，将其连接到另一个不同的构型。

为了找到我们的[神经网](@entry_id:276355)络猜测 $\Psi_{\boldsymbol{\theta}}$ 的总能量，我们必须计算[瑞利商](@entry_id:137794)：

$$
E(\boldsymbol{\theta}) = \frac{\langle \Psi_{\boldsymbol{\theta}} |\hat{H}| \Psi_{\boldsymbol{\theta}} \rangle}{\langle \Psi_{\boldsymbol{\theta}} | \Psi_{\boldsymbol{\theta}} \rangle} = \sum_{\boldsymbol{\sigma}} \frac{|\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})|^2}{\sum_{\boldsymbol{\sigma}'} |\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma}')|^2} \left[ \frac{(\hat{H}\Psi_{\boldsymbol{\theta}})(\boldsymbol{\sigma})}{\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})} \right]
$$

这个表达式揭示了一个至关重要的量：**局域能量** [@problem_id:1212321]。

$$
E_{\text{loc}}(\boldsymbol{\sigma}) = \frac{(\hat{H}\Psi_{\boldsymbol{\theta}})(\boldsymbol{\sigma})}{\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})}
$$

局域能量是与单个构型 $\boldsymbol{\sigma}$ 相关的“能量”。总变分能量 $E(\boldsymbol{\theta})$ 只是这个局域能量的平均值，由[概率分布](@entry_id:146404) $p(\boldsymbol{\sigma}) \propto |\Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})|^2$ 加权。计算 $E_{\text{loc}}$ 涉及到将[哈密顿量](@entry_id:172864)应用于我们的[拟设](@entry_id:184384)。对角部分很容易。非对角部分要求我们不仅在 $\boldsymbol{\sigma}$ 处评估我们的[神经网](@entry_id:276355)络，还要在所有通过自旋翻转连接的相邻构型 $\boldsymbol{\sigma}'$ 处进行评估 [@problem_id:2410566]。

对于小系统，我们可以精确地对所有 $2^N$ 个构型进行求和。对于[大系统](@entry_id:166848)，这是不可能的，我们转而使用蒙特卡洛方法：我们根据概率 $|\Psi_{\boldsymbol{\theta}}|^2$ 对构型进行采样，并对我们抽取的样本的局域能量进行平均。现在我们有了我们的高度计读数。下一步是找出下山的路。

### 下山的艺术：优化网络

我们想找到使能量函数 $E(\boldsymbol{\theta})$ 最小化的参数 $\boldsymbol{\theta}$。最直接的方法是**梯度下降**。对于每个参数 $\theta_k$（我们网络中的一个权重或偏置），我们计算导数 $\frac{\partial E}{\partial \theta_k}$。这告诉我们当我们微调该参数时能量如何变化。然后我们通过朝负梯度方向迈出一小步来更新参数：$\theta_k \leftarrow \theta_k - \eta \frac{\partial E}{\partial \theta_k}$。

这个梯度的推导是微积分的一个小奇迹，揭示了该方法深刻的内部工作原理。经过一些代数运算后，梯度以一种非常直观和优雅的形式出现 [@problem_id:1212321] [@problem_id:3170375]：

$$
\frac{\partial E}{\partial \theta_k} = 2 \, \text{Re} \left[ \langle O_k^* E_{\text{loc}} \rangle - \langle O_k^* \rangle \langle E_{\text{loc}} \rangle \right]
$$

这仅仅是局域能量 $E_{\text{loc}}$ 与一个新量 $O_k(\boldsymbol{\sigma}) = \frac{\partial \ln \Psi_{\boldsymbol{\theta}}(\boldsymbol{\sigma})}{\partial \theta_k}$ 之间**协[方差](@entry_id:200758)**的实部的两倍。这个项，即[波函数](@entry_id:147440)的**[对数导数](@entry_id:169238)**，衡量了对于给定的构型 $\boldsymbol{\sigma}$，我们的[波函数](@entry_id:147440)振幅（在对数尺度上）对参数 $\theta_k$ 变化的敏感度。

这个协[方差](@entry_id:200758)公式非常优美。它告诉我们，如果参数 $\theta_k$ 的“敏感度” $O_k$ 与局域能量强相关，那么该参数的梯度就很大。换句话说，为了降低总能量，优化过程会推动参数去增加具有低局域能量的构型的[波函数](@entry_id:147440)振幅 $|\Psi_{\boldsymbol{\theta}}|$，并减小具有高局域能量的构型的[波函数](@entry_id:147440)振幅。网络实际上是在学习重塑其概率景观，以偏好低能量的[量子态](@entry_id:146142)，从而有效地“学习”[基态](@entry_id:150928)[波函数](@entry_id:147440)。

### 导航量子景观：随机重构

标准的梯度下降就像在你多雾的山谷中行走，总是让你的脚指向最陡峭的方向。如果你在一个狭长的峡谷里，这可能会效率低下，因为你只会在两壁之间来回反弹。一个更聪明的方法是拥有一张局部地形图，以找到一条更直接的路径。

在我们的变分参数 $\boldsymbol{\theta}$ 的空间中，并非所有方向都生而平等。对一个权重的小改动可能几乎不改变物理状态，而对另一个权重的微小改变可能会使其完全转变。这种“地形”由一个称为**[量子几何](@entry_id:147695)张量**（QGT）的数学对象来描述，它也被称为 Fubini-Study 度量，或者在这种情况下，被称为费雪信息矩阵 [@problem_id:1212460]。其分量由[对数导数](@entry_id:169238)的协[方差](@entry_id:200758)给出：

$$
S_{kj} = \text{Re} \left( \langle O_k^* O_j \rangle - \langle O_k^* \rangle \langle O_j \rangle \right)
$$

QGT 是一个度量，它告诉我们两个无限接近的不同物理态 $|\Psi(\boldsymbol{\theta})\rangle$ 和 $|\Psi(\boldsymbol{\theta} + d\boldsymbol{\theta})\rangle$ 之间的“距离”。它定义了我们变分景观的几何结构。

**随机重构（SR）**方法利用这种几何信息来找到一个更好的更新方向 [@problem_id:1212420]。它不仅仅是沿着“力矢量”$\mathbf{F}$（其中 $F_k$ 是能量的梯度）前进，而是[求解线性系统](@entry_id:146035) $\mathbf{S} \Delta\boldsymbol{\theta} = -\eta \mathbf{F}$ 来找到参数更新量 $\Delta\boldsymbol{\theta}$。这是一种**自然[梯度下降](@entry_id:145942)**的形式。它通过[参数空间](@entry_id:178581)的局部几何结构来修正原始梯度，从而实现更快、更稳定地收敛到最小值。这就像是盲目地沿着斜坡滑下与拥有一个能理解山谷真实形状的GPS，引导你沿着最有效的路径到达谷底之间的区别。

这种方法也有深刻的物理意义：可以证明，它是在**虚时间**中演化状态的一种近似。在量子力学中，这是一种可靠的方法，可以投影掉所有[激发态](@entry_id:261453)，只留下[基态](@entry_id:150928)。通过将[神经网](@entry_id:276355)络的表达能力与复杂的、具有几何意识的[优化方法](@entry_id:164468)相结合，我们拥有了一个完整而强大的工具包，用以探索广阔而以前无法企及的[量子多体系统](@entry_id:141221)世界。

