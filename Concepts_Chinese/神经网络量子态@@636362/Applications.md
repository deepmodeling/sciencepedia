## 应用与跨学科联系

在我们之前的讨论中，我们打开了[神经网](@entry_id:276355)络[量子态](@entry_id:146142)（NQS）的“黑箱”，以理解其内部工作原理。我们看到了一个在数据和算法世界中锻造出来的工具——[神经网](@entry_id:276355)络，如何被塑造成能够表示量子系统复杂、高维[波函数](@entry_id:147440)的形式。但一个工具的好坏取决于它能解决的问题。现在，我们踏上征程，亲眼见证这个工具的实际应用。我们将从奇异的量子磁体世界探索到[原子核](@entry_id:167902)的炽热核心，在此过程中，我们将发现NQS及其概念上的近亲并非仅仅是新奇事物。它们是物理学家和化学家管弦乐队中强大的新乐器，使我们能够探索曾经被计算的黑暗所笼罩的量子宇宙的角落。

### 描绘材料的量子景观

NQS最自然的应用或许就是它最初被构想出来的目的：寻找[量子多体系统](@entry_id:141221)的[基态](@entry_id:150928)。想象一下，一个由大量微小、相互作用的量子粒子组成的集合，就像[固体中的电子](@entry_id:204682)一样。它们的集体行为催生了材料的奇妙特性——磁性、超导性等等。凝聚态物理的巨大挑战就是从量子力学的基本定律出发，预测这些特性。这相当于为系统求解薛定谔方程，对于除了最小数量的粒子之外的任何系统来说，这都是一项不可能完成的任务。

正如我们所见，[变分原理](@entry_id:198028)提供了一条前进的道路：我们猜测一个[试探波函数](@entry_id:142892)，并系统地改进它，以找到能量最低的状态。这正是NQS大放异彩的地方。考虑[量子磁性](@entry_id:145792)问题。材料的磁性源于其电子的量子“自旋”。我们可以想象一个原子[晶格](@entry_id:196752)，每个原子上都有一个可以指向上或向下的陀螺。这些自旋与它们的邻居相互作用，试图对齐或反对齐，形成一个复杂而受挫的舞蹈。[基态](@entry_id:150928)就是以能量最有利的方式解决这种挫折的特定自旋模式。

[神经网](@entry_id:276355)络如何学习这种模式？一种特别优雅的方法是使用一种能够反映物理系统本身的[神经网络架构](@entry_id:637524)。对于[晶格](@entry_id:196752)上的自旋系统，图神经网络（GNN）是一个完美的匹配。该网络实际上是建立在连接物理自旋的同一张连接图上的。信息通过网络的各层传播，使得每个节点能够收集关于其邻居、然后是其邻居的邻居等信息。通过这种方式，网络学习了描述真实[基态](@entry_id:150928)所需的自旋构型的复杂长程关联。网络的结构具有与它试图解决的问题相同的“[归纳偏置](@entry_id:137419)”——这是计算机科学与物理学的美妙结合 [@problem_id:1212352]。

利用[神经网](@entry_id:276355)络学习量子力学函数的思想远远超出了自旋[晶格](@entry_id:196752)的范围。NQS的一个近亲是[机器学习原子间势](@entry_id:751582)（MLIPs）领域，它已经彻底改变了计算化学和[材料科学](@entry_id:152226)。在这里，目标不是表示完整的[波函数](@entry_id:147440)，而是学习Born-Oppenheimer[势能面](@entry_id:147441)，即给出任何给定[原子核](@entry_id:167902)[排列](@entry_id:136432) $\mathbf{R}$ 的[基态](@entry_id:150928)电子能量的函数 $E(\mathbf{R})$。这个能量面是所有[化学反应](@entry_id:146973)展开的“舞台”；它的山丘和山谷决定了化学键、[分子结构](@entry_id:140109)和反应路径。

同样，深刻的物理原理指导着[神经网](@entry_id:276355)络的设计。对于许多系统，如绝缘体或室温下的分子，电子物质的“短视性”原理成立：特定原子的能量绝大多数由其直接的局部环境决定。房间另一端的原子几乎没有直接影响。这个物理事实使我们能够建立既准确又高效的模型。总能量被近似为原子贡献的总和，其中每个原子的能量由一个只观察有限[截断半径](@entry_id:136708)内邻居的[神经网](@entry_id:276355)络计算。这种局域性是使计算具有可扩展性的关键。计算成本不再是随[原子数](@entry_id:746561) $N$ 的平方 $N^2$ 增长，而是线性增长，为 $\mathcal{O}(N)$。这一突破使我们能够模拟数百万个原子，达到研究蛋白质折叠或晶体生长等复杂过程所需的尺度，其精度接近第一性原理[量子计算](@entry_id:142712)的精度 [@problem_id:2908380]。

### 超越绝对[零度](@entry_id:156285)：现实温度下的 NQS

许多量子理论是在绝对[零度](@entry_id:156285)的温度下发展的，此时系统会稳定在其单一的、能量最低的[基态](@entry_id:150928)。但我们的世界是温暖的。在任何有限温度下，[热涨落](@entry_id:143642)会不断地将系统踢到更高的能态。处于热平衡状态的系统不是处于单一的[纯态](@entry_id:141688)，而是许多状态的统计混合，由一个称为[密度矩阵](@entry_id:139892)的物体描述。

这对NQS形式主义提出了一个深远的挑战。[波函数](@entry_id:147440)，就其本质而言，描述的是一个[纯态](@entry_id:141688)。它怎么可能捕捉到有限温度下系统的概率性、混合性特征呢？事实证明，答案来自[量子信息论](@entry_id:141608)中一个巧妙而优美的思想：**纯化**。

这个想法既巧妙又简单。想象你有一个处于混乱[混合态](@entry_id:141568)的量子系统（我们称之为A）。纯化原理告诉我们，我们总是可以虚构一个[辅助系统](@entry_id:142219)（一个“辅助比特”，我们称之为B），使得组合系统A+B处于一个单一、明确定义的纯态。系统A的混合性现在被理解为其与[辅助系统](@entry_id:142219)B纠缠的结果。如果我们只看A，忽略B，它的状态看起来是混合的。但整个系统是纯的。

这将问题转化回NQS可以处理的形式。我们可以构建一个[神经网](@entry_id:276355)络来表示这个更大的、纯化系统的[波函数](@entry_id:147440)。然后，通过执行一个相当于“忽略”[辅助系统](@entry_id:142219)的数学操作，我们可以计算出我们原始系统的所有热力学性质——它的自由能、熵、热容等等。这一卓越的联系使我们能够将变分蒙特卡洛和NQS的力量从绝对[零度](@entry_id:156285)的原始寂静扩展到有限温度[统计力](@entry_id:194984)学的繁华动态世界，为从头开始模拟量子相变和其他温度依赖现象打开了大门 [@problem_id:2466737]。

### 教会学徒物理定律

一个在有限数据集上训练的[神经网](@entry_id:276355)络有点像一个通过简单模仿师傅的动作来学习手艺的学徒。它可能在复现它所见过的东西方面变得非常出色，但它缺乏对基本原理的更深层次的理解。当面对新情况时，它可能会犯一个经验丰富的手艺人绝不会犯的错误。要建立真正稳健和具有预测性的科学模型，我们必须超越单纯的模仿。我们必须教会我们的[神经网](@entry_id:276355)络学徒物理学的基本定律。

这可以通过两种主要方式来完成：将定律构建到网络的架构中，或在训练过程中强制执行它们。

考虑模拟两个[核子](@entry_id:158389)（质子或中子）之间相互作用力的挑战，这是[原子核](@entry_id:167902)的组成部分。这个力极其复杂，但它必须遵守某些不可侵犯的对称性。例如，无论你在空间中如何定向你的[坐标系](@entry_id:156346)，物理定律都是相同的；这就是[旋转不变性](@entry_id:137644)。此外，势必须是[厄米性](@entry_id:141899)的，这是量子力学要求的一个条件，以确保能量等[物理可观测量](@entry_id:154692)是实数。我们可以设计一个能自动尊重这些对称性的[神经网络势](@entry_id:752446)。通过选择其输入为[旋转不变量](@entry_id:170459)（如距离 $r=|\boldsymbol{r}|$、$r'=|\boldsymbol{r}'|$ 和[点积](@entry_id:149019) $\boldsymbol{r} \cdot \boldsymbol{r}'$ 等标量），并以一种明确对称的方式构造其输出，我们可以建立一个将[旋转不变性](@entry_id:137644)和[厄米性](@entry_id:141899)融入其结构的模型。它无法违反这些定律，因为它在结构上就没有能力这样做 [@problem_id:3571891]。这种方法使我们能够创建复杂量子对象的灵活而又物理上严谨的表示，甚至是奇异的“非局域势”，其中某一点的力取决于各处的[波函数](@entry_id:147440)。

第二种方法是直接将物理约束添加到训练目标中。假设我们正在训练一个势来再现[核子-核子散射](@entry_id:159513)数据。我们可能有它们在高能下如何散射的数据点。但我们也知道一个来自核理论的普适真理：在极低能量下，所有[短程相互作用](@entry_id:145678)都以一种简单、可预测的方式表现，这种方式由“[有效力程展开](@entry_id:137491)”描述。这是一条物理定律。我们可以在网络的损失函数中添加一个惩罚项，每当模型的低能预测偏离这个理论定律时，就对模型进行惩罚。这就像告诉学徒：“我希望你拟合这些数据点，但无论你做什么，你的最终结果*必须*与这个基本原则保持一致。”这个简单的技巧可以产生显著的效果，引导模型远离它否则可能找到的非物理解决方案。例如，一个仅在数据上训练的模型可能会发展出一种弱的、长程的吸[引力](@entry_id:175476)，从而产生虚假的、非物理的束缚态。强制执行正确的低能物理可以消除这些人为产物，从而得到一个更可靠、更具预测性的模型 [@problem_id:3571854]。

### 学徒的谦卑：量化不确定性

也许科学家学到的最重要的一课是谦卑：知道自己所不知道的。没有[误差棒](@entry_id:268610)的数字在科学上是无意义的。一个预测只有在附带置信度度量时才有用。我们能否教会我们的[神经网](@entry_id:276355)络学徒同样的谦卑？答案是肯定的，而且这标志着这些模型从“黑箱”预测器向真正的科学工具的转变。这就是[不确定性量化](@entry_id:138597)的领域。

在任何数据驱动的模型中，不确定性都来自两个不同的来源。为了理解它们，考虑通过一组点绘制一条平滑曲线的任务。

首先是**认知不确定性**，这是模型自身的无知。如果你只有几个数据点，你可以画出许多不同的曲线穿过它们。在远离任何数据的区域，你对真实曲线的位置非常不确定。这是由于缺乏知识而产生的不确定性，并且是可减少的：如果你添加更多的数据点，特别是在不确定的区域，你对曲线的估计将变得更加自信。

其次是**[偶然不确定性](@entry_id:154011)**，这是数据本身固有的模糊性。想象一下，你对数据点的测量是有噪声的。每个点都不是一个完美的点，而是一个模糊的斑点。这种数据生成过程中固有的随机性或噪声是无法减少的，无论你收集多少数据。

值得注意的是，我们可以设计和训练[神经网](@entry_id:276355)络来估计这两种不确定性。估计[认知不确定性](@entry_id:149866)的一个强大方法是训练不是一个，而是一个*模型集成*。每个网络以不同的随机初始权重开始，它们都会找到略有不同但都拟合数据的解。当我们要求这个“委员会”对一个新输入进行预测时，它们答案的[分布](@entry_id:182848)直接衡量了模型的[认知不确定性](@entry_id:149866)。如果集成中的所有模型都给出相似的答案，我们就可以对预测充满信心。如果它们的答案五花八门，这是一个明确的信号，表明模型正在外推到一个它知之甚少的区域。

偶然不确定性可以通过训练网络不仅预测一个值（如能量），而且预测一个值*和*一个相应的误差棒来捕捉。网络学会为与有噪声的训练数据点相似的输入预测更大的[误差棒](@entry_id:268610)。

[全方差定律](@entry_id:184705)是概率论的一个基本定理，它告诉我们总预测[方差](@entry_id:200758)就是认知[方差](@entry_id:200758)和偶然[方差](@entry_id:200758)之和。这为[不确定性分解](@entry_id:183314)提供了一个严谨的框架。通过使用每个都能预测均值和[方差](@entry_id:200758)的网络集成，我们可以分别估计这两种贡献 [@problem_id:3422785]。这是一个深刻的进步。它使我们的模型不仅能告诉我们“这是我的预测”，还能告诉我们“你应该在多大程度上相信它”。

基础物理学与机器学习之间的对话正在创造一种新的科学发现[范式](@entry_id:161181)。通过建立不仅是强大的逼近器，而且是物理上 principled（有原则的）、对称性感知、并意识到自身不确定性的模型，我们正在人类直觉与人工智能之间建立一种强大的伙伴关系。这种伙伴关系有望帮助我们驾驭广阔而复杂的量子力学景观，照亮通往理解物质世界最深层秘密的道路。