## 引言
将深度学习与物理定律融合的探索催生了物理信息神经网络 ([PINNs](@entry_id:145229))，它通过将[微分方程](@entry_id:264184)嵌入训练过程来求解这些方程。然而，当面临现实世界的复杂性——如不连续的材料、含噪声的数据或物理[奇异点](@entry_id:199525)——在这些情况下，控制方程难以在每一个点上强制执行，标准 PINNs 往往会遇到困难。这一局限性暴露了数学理想与实际应用之间的差距，亟需一种更鲁棒、更灵活的方法。

本文介绍变分物理信息神经网络 (v[PINNs](@entry_id:145229))，这是一种强大的演进，它通过从根本上改变我们要求[神经网](@entry_id:276355)络学习物理的方式来应对这些挑战。vPINNs 不再要求逐点精度，而是采用了一种源自经典力学和变分法的“更弱”的、基于积分的表述。本文将引导您深入了解这个优雅而强大的框架。首先，在“原理与机制”部分，我们将探讨从强形式到[弱形式](@entry_id:142897)的转变、[分部积分](@entry_id:136350)在[稳定训练](@entry_id:635987)中的作用，以及与[最小能量原理](@entry_id:178211)的深刻联系。接下来，在“应用与跨学科联系”部分，我们将看到这些原理如何使 v[PINNs](@entry_id:145229) 能够解决各种具有挑战性的问题，从工程[复合材料](@entry_id:139856)和障碍问题，到与传统求解器混合使用，以及在复杂的[逆问题](@entry_id:143129)中洞察未知。

## 原理与机制

要真正领会变分[物理信息神经网络](@entry_id:145229) (v[PINNs](@entry_id:145229)) 的精妙之处，我们必须首先退后一步，提出一个根本性问题：一个数学方程描述物理现实意味着什么？我们通常认为，像热流方程或弦[振动](@entry_id:267781)方程这样的物理定律，是一个在空间和时间的每一点都必须成立的陈述。这便是物理定律的**强形式**。

想象一下，你是一位工程师，任务是验证一座桥梁的稳定性。强形式方法就如同检查结构中每一个原子的应力和应变，这是一项要求高得不可能完成的任务。如果有一个尖角或微观裂缝怎么办？理论告诉我们，这种[奇异点](@entry_id:199525)处的应力可能是无穷大的。即使桥梁整体上非常稳定，逐点的检查也会失败。这正是传统**[物理信息神经网络](@entry_id:145229) ([PINNs](@entry_id:145229))** 所面临的挑战。它们通过尝试在大量离散点上使[偏微分方程](@entry_id:141332)的残差——即方程的“错误”程度——尽可能接近于零来学习。但对于许多现实世界的问题，这就像要求网络捕捉一个无穷大的应力，即便不是不可能，也是一项极其困难的任务 [@problem_id:2668902]。

物理学和数学以其深刻的智慧，提供了一种更强大、更优雅的替代方案。我们可以不进行局部的、逐点的质询，而是提出一个全局的、集体性的问题。这正是**[弱形式](@entry_id:142897)**的灵魂所在。

### 集体裁决：从逐点检查到全局测试

我们不再要求方程在每个点上都完美成立，而是要求整个系统给出一个“裁决”。我们可以通过“测试”方程来做到这一点。我们取物理定律，比如 $\mathcal{N}[u] - f = 0$，其中 $\mathcal{N}$ 是作用于场 $u$ 的某个[微分算子](@entry_id:140145)（如[拉普拉斯算子](@entry_id:146319) $\nabla^2$），$f$ 是一个源项。$\mathcal{N}[u] - f$ 这一项就是残差。我们将这个残差乘以一个“测试函数”（我们称之为 $v$），然后在整个域 $\Omega$ 上对这个乘积进行积分：

$$
\int_{\Omega} (\mathcal{N}[u] - f) v \, d\Omega = 0
$$

其神奇之处在于：如果这个积分不仅对于某个特定的测试函数为零，而且对于我们能想到的*任何*合理的测试函数 $v$ 都为零，那么残差本身必须处处为零。我们通过一条更为灵活的后门路径，恢复了强形式。

这个数学思想与力学中最优美的概念之一——**虚功原理**——紧密相连。一个物体处于平衡状态，是指对于我们施加于它的任何微小的、假想的（“虚”）位移，所有力所做的总功之和为零。我们的测试函数 $v$ 正是一个[虚位移](@entry_id:168781)场。该积分代表了总[虚功](@entry_id:176403)。因此，[弱形式](@entry_id:142897)不仅仅是检查某个点的力是否平衡；它是在确认整个系统处于一种能量和谐的状态 [@problem_id:3612728]。

变分 PINN 正是拥抱了这一哲学。它不是最小化逐点残差，而是力求使[弱形式](@entry_id:142897)残差——即对一整族测试函数进行测试得到的积分——尽可能小 [@problem_id:3408318]。从逐点检查到全局、基于积分的测试的转变，是其强大功能的第一个关键。

### 积分的魔力：分担重负

[弱形式](@entry_id:142897)有一个奇妙的技巧，一个具有深远物理意义的数学戏法：**分部积分**。在多维空间中，这被称为[格林恒等式](@entry_id:176369)或[散度定理](@entry_id:143110) [@problem_id:3431039]。

让我们考虑一个常见的二阶方程，比如用于描述[扩散](@entry_id:141445)的泊松方程：$-\nabla \cdot (k \nabla u) = f$ [@problem_id:3612728]。它的[弱形式](@entry_id:142897)涉及项 $\int -\nabla \cdot (k \nabla u) v \, d\Omega$。当我们应用[分部积分](@entry_id:136350)时，奇妙的事情发生了。一个导数从我们的候选解 $u$ “转移”到了测试函数 $v$ 上：

$$
-\int_{\Omega} (\nabla \cdot (k \nabla u)) v \, d\Omega = \int_{\Omega} (k \nabla u) \cdot (\nabla v) \, d\Omega - \int_{\partial\Omega} v (k \nabla u \cdot \boldsymbol{n}) \, dS
$$

注意右边的主要积分项。它现在只包含 $u$ 的[一阶导数](@entry_id:749425)（$\nabla u$）和 $v$ 的一阶导数（$\nabla v$）。我们降低了对解的求导阶数！

这不仅仅是数学上的便利，它改变了游戏规则 [@problem_id:3513303]。

1.  **降低求解门槛**：带有[二阶导数](@entry_id:144508)的强形式，隐含地要求我们的解非常光滑（属于像 $H^2$ 这样的空间）。而[弱形式](@entry_id:142897)，则只要求一阶导数是良态的（属于 $H^1$）。这使我们能够为具有[奇异点](@entry_id:199525)的问题找到有意义的解，例如裂纹尖端附近的应[力场](@entry_id:147325)或[尖点](@entry_id:636792)附近的[电场](@entry_id:194326)——这些问题中强形式会失效 [@problem_id:2668902]。

2.  **驯服梯度**：对于[神经网](@entry_id:276355)络而言，导数是通过[自动微分](@entry_id:144512)计算的。[二阶导数](@entry_id:144508)可能充满噪声且数值不稳定，导致训练过程混乱。通过将要求降低到一阶导数，变分方法为优化过程提供了更平滑、更稳定的梯度，使训练更加鲁棒 [@problem_id:3338014]。

3.  **对噪声的鲁棒性**：积分本身就是一种平滑操作。如果我们的数据（如[源项](@entry_id:269111) $f$）是含噪声的，一个试图在特定点上匹配它的强形式 PINN 可能会“过拟合”噪声，导致解的严重失真。弱形式中的积分可以平均掉这些局部差异，起到低通滤波器的作用，使得该方法对含噪声数据具有内在的鲁棒性 [@problem_id:3513303]。

### 自然的边界条件：本质与自然

[分部积分](@entry_id:136350)的过程留下了一份精美的礼物：边界项 $\int_{\partial\Omega} v (k \nabla u \cdot \boldsymbol{n}) \, dS$ [@problem_id:3431052]。这个项并非麻烦，而是物理规律的自我揭示。量 $k \nabla u \cdot \boldsymbol{n}$ 代表了场 $u$ 穿过边界 $\partial\Omega$ 的通量（例如，热流或化学通量）。

这引出了两种边界条件之间深刻而实用的区别 [@problem_id:3612728]：

-   **本质条件**：这些是关于场本身值的条件，比如在边界上设定一个固定温度 $u=T_0$。这些是定义可能[解空间](@entry_id:200470)的根本性约束。在 vPINN 中，我们必须刻意强制执行它们，要么通过设计网络架构来满足它们，要么在违反时向损失函数中添加惩罚项。

-   **自然条件**：这些是关于通量的条件，比如指定一个边界是绝热的（$k \nabla u \cdot \boldsymbol{n} = 0$）或有规定的流入量（$k \nabla u \cdot \boldsymbol{n} = g_N$）。这些条件通过分部积分提供的边界项，“自然地”被并入弱形式中。我们不需要强制它们；变分机制会为我们处理好 [@problem_id:3338014] [@problem_id:3431052]。

### 终极统一：[最小能量原理](@entry_id:178211)

还有一个更深层、更具统一性的原理在起作用。对于一大类物理系统，其控制性[偏微分方程](@entry_id:141332)仅仅是一个更基本定律的体现：系统会自行调整以**最小化其总[势能](@entry_id:748988)**。肥皂膜形成一个极小曲面，悬挂的链条呈现[悬链线](@entry_id:178436)形状——所有这些都是为了找到可能的最低能量状态。

我们推导出的[弱形式](@entry_id:142897)，恰好是寻找一个**能量泛函**最小值的数学条件 [@problem_id:3410637]。对于我们简单的[扩散](@entry_id:141445)问题，这个泛函是：

$$
\mathcal{E}[u] = \int_{\Omega} \left( \frac{1}{2} k |\nabla u|^2 - f u \right) d\Omega
$$

这里，$\frac{1}{2} k |\nabla u|^2$ 代表储存的内能（就像拉伸弹簧中的能量），而 $-fu$ 是源的势能。这个能量泛函的一阶变分 $\delta\mathcal{E}$，恰好是我们之前找到的弱形式残差。系统处于能量最小值的条件就是 $\delta\mathcal{E}=0$。

这为 v[PINNs](@entry_id:145229) 提供了一个令人豁然开朗的直观框架 [@problem_id:3612777]。我们要求[神经网](@entry_id:276355)络最小化的损失函数，可以就是系统本身的物理能量。训练过程不再仅仅是抽象的曲线拟合；它是对大自然自身优化过程的模拟。网络调整其参数，探索场 $u$ 的不同构型，直到找到那个具有最低可能能量的构型。

### 从完美定律到实用算法

为了使其具有实用性，我们必须采取最后两个步骤。首先，我们无法对无限多个测试函数进行测试。因此，我们选择一个有限但具有代表性的集合，比如一组简单的多项式[基函数](@entry_id:170178)。其次，能量或弱残差中的积分必须通过数值计算。这是通过**[数值积分](@entry_id:136578)**完成的，它通过在特定的“积分点”上对被积函数值进行加权求和来近似一个积分 [@problem_id:3431039]。

优雅的、连续的[弱形式](@entry_id:142897)变成了离散的、可计算的[损失函数](@entry_id:634569)——一个对我们选择的测试函数和积分点的求和 [@problem_id:3612777]。当然，这种近似必须小心处理。如果数值积分过于粗糙，我们就会犯下被趣称为**“变分犯罪”**的错误 [@problem_id:3460602]。我们最终解决的问题会与我们原本打算解决的问题略有不同。但是，只要有足够的数学严谨性，我们就能确保我们的离散系统是底层物理的忠实再现。

在这段从简单[偏微分方程](@entry_id:141332)到可训练[损失函数](@entry_id:634569)的旅程中，我们看到了变分方法的真正原理和机制。通过提出一个“更弱”的问题，我们解锁了解决更难问题的能力。通过“分担”导数的重负，我们获得了稳定性和鲁棒性。通过将方程视为对最小能量的寻求，我们将机器学习的抽象世界与物理宇宙最深刻的组织原则之一联系起来。

