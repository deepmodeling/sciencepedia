## 应用与跨学科联系

在我们之前的讨论中，我们打开了视觉 Transformer 的“黑匣子”，窥见了其内部的[自注意力机制](@entry_id:638063)，该机制使其能够将图像感知为一个由相互作用的图像块组成的社会，而非一个僵硬的像素网格。我们看到了它如何学习关系和上下文，从组成部分中汇集出整体视图。现在，我们从*如何做*转向*做什么*。我们能用这个强大的新工具*做些什么*？让我们踏上一段穿越现代数字化诊所和实验室的旅程，见证视觉 Transformer 不仅在改进旧任务，而且使我们能够对健康和疾病提出全新的问题。

### 一种新的观察方式：从局部细节到全局画面

多年来，[计算机视觉](@entry_id:138301)领域的卫冕冠军是卷积神经网络 (CNN)。CNN 的工作方式很像一位勤奋但近视的生物学家，用显微镜扫描载玻片。它将一组小的滤波器，或称“放大镜”，应用于整个图像，寻找特定的局部模式——这里一条边，那里一种纹理。通过堆叠层级，它逐渐构建出更大的画面，将边缘组合成形状，形状组合成物体。这种对**局部性**——即重要信息包含在小的相邻区域内——的内置假设，是一种极其强大的“[归纳偏置](@entry_id:137419)”。它给了 CNN 一个先发优势，使其能够从相对较小的数据集中高效学习，因为它不必去发现物体是局部的这一基本原则。

这在医学领域是一个巨大的优势，因为大型、经专家标记的数据集可能是一种奢侈品。当训练一个模型从几千张眼底图像中对糖尿病视网膜病变进行分类时，像 [ResNet](@entry_id:635402) 这样的 CNN 通常会胜过从零开始训练的视觉 Transformer (ViT)。CNN 对局部特征（如微小的微动脉瘤）的内在关注，以及其在图像任何位置都能识别这些特征的能力（这是其**[平移等变性](@entry_id:636340)**的效果），在数据稀缺时与任务[完美匹配](@entry_id:273916) [@problem_id:4655913]。

然而，这种优势也可能成为一种局限。如果诊断不依赖于单个局部特征，而是依赖于整个图像上许多特征的微妙、全局性排列呢？考虑检测由全视网膜光凝术（一种糖尿病视网膜病变的治疗方法）引起的微弱、广泛的瘢痕。或者想象一下，试图在 MRI 中分割一个脑肿瘤，其边界是由它与几个远处解剖标志的关系来定义的 [@problem_id:4535980]。CNN 必须逐层痛苦地建立起这种全局理解，其有效的“感受野”增长缓慢。

在这里，视觉 Transformer 提供了一种革命性的替代方案。从设计上讲，它的[自注意力机制](@entry_id:638063)从第一层开始就是全局的。每个图像块可以直接与所有其他图像块通信，计算它们彼此之间的相关性。它对局部性没有任何内置的偏见。这使得它“天生”就适合需要全局上下文的任务。当然，天下没有免费的午餐。这种灵活性意味着 ViT 有一个更大的“[假设空间](@entry_id:635539)”需要搜索；它必须*学习* CNN 免费获得的那些空间和局部性规则。这就是为什么，如果没有在海量数据集上进行预训练的指导，ViT 可能会在充满可能性的荒野中迷失方向，在小数据集上表现不佳。但是，当提供充足的数据——数十万张图像——并受益于预训练时，ViT 可以学习这些复杂的、长距离的依赖关系，并常常超越其卷积表亲，尤其是在“大局观”至关重要的任务上 [@problem_id:4655913]。因此，选择并非在于哪种架构“更好”，而在于哪种架构的[归纳偏置](@entry_id:137419)最符合您问题的性质和数据的现实。

### 两全其美：混合推理

如果 CNN 是局部专家，而 ViT 是全局通才，那么一个自然的问题就出现了：我们能否两全其美？答案是肯定的，并且它催生了一些计算病理学中最强大的模型。

考虑分析组织活检的全切片图像 (WSI) 的挑战。这些图像非常巨大，每个维度的像素常常超过十万。对于任何现有模型来说，一次性分析全分辨率图像在计算上都是不可想象的。病理学家通过无缝地放大和缩小，在高倍镜（$20\times$ 或 $40\times$）下检查细胞细节，在低倍镜（$5\times$）下观察[组织结构](@entry_id:146183)来应对这种复杂性。诊断往往来自于综合跨越这些尺度的观察结果。

这正是混合型 CNN-Transformer 架构大放异彩的地方 [@problem_id:4615268]。该策略优雅至极。首先，CNN 充当高效的“特征侦察员”。它被部署在从 WSI 中以不同放大倍率提取的较小图块上。在高倍镜下，它可能学会识别单个细胞核和纹理。在低倍镜下，它可能学会识别腺体结构。CNN 的工作是处理原始的高分辨率像素，并将它们提炼成一组紧凑而有意义的特征向量，即“令牌”。它有效地将像素的语言翻译成高级概念的语言。

然后，视觉 Transformer 登上中心舞台。它接收来自所有不同尺度的这些经专家总结的令牌。它的任务不再是理解数百万像素，而是对几百个高级概念进行推理。它使用其全局[自注意力](@entry_id:635960)来提出复杂的问题：“我在 $20\times$ 倍镜下看到的这种异常细胞类型的存在，与我在 $5\times$ 倍镜下不远处看到的无序[组织结构](@entry_id:146183)有何关联？”它可以直接建模这些长距离、[跨尺度](@entry_id:754544)的依赖关系，模仿人类病理学家的推理过程。这种协同作用是深刻的：CNN 处理它所擅长的局部[特征提取](@entry_id:164394)，极大地降低了问题的复杂性，而 Transformer 则执行其标志性的全局上下文推理。

### 超越图像：融合数据以实现整体诊断

医生很少仅根据单条信息做出诊断。他们综合来自多种来源的数据：X 射线或 CT 扫描的视觉证据，患者电子健康记录 (EHR) 中的结构化数据——年龄、合并症、实验室结果——以及临床笔记中的非结构化叙述。医学人工智能的未来在于其执行这种多模态融合的能力。

Transformer 是这一愿景的核心。当视觉 Transformer 处理图像时，像 BERT (Bidirectional Encoder Representations from Transformers) 这样的兄弟架构可以处理临床文本，其他模型可以处理结构化的 EHR 数据。挑战在于如何结合这些信息流 [@problem_id:5210120]。

一种方法是**早期融合**。在这里，我们将所有模态的特征向量——来自 ViT 的图像特征、来自 BERT 的文本嵌入、实验室数值——连接成一个长向量，并将其输入到一个单一的、强大的模型中。理论上，这个模型可以发现模态之间复杂的、隐藏的[交互作用](@entry_id:164533)。例如，它可能会学到，图像中某个特定的微妙模式只有在某个特定的实验室数值也存在时才表明疾病。

另一种方法是**晚期融合**。这更像一个专家委员会。我们用一个模型训练图像，另一个模型训练实验室数据，第三个模型训练文本。每个模型都做出自己独立的评估。然后，使用一个更简单的规则（如平均它们的预测分数或加权投票）来得出最终决定。这种方法通常更鲁棒，尤其是在数据有限或某个模态对特定患者缺失的情况下。例如，在假设数据源在给定疾病状态下条件独立的前提下，简单地将每个模型的“证据”（[对数似然比](@entry_id:274622)）相加在理论上是最佳的。

这些策略之间的权衡体现了机器学习中的一个深刻原则：[偏差-方差权衡](@entry_id:138822)。早期融合具有低偏差（它可以学习非常复杂的关系），但方差高（它很容易在小数据集上过拟合噪声）。晚期融合具有较高的偏差（它假设模态在很大程度上是独立的），但方差较低（它更稳定，从有限数据中泛化得更好）。Transformer 凭借其在各种类型数据中发现模式的能力，是这两种方法的关键使能技术，推动我们走向一个真正整体化和数据驱动的诊断范式。

### 机器中的幽灵：信任、鲁棒性与[可复现性](@entry_id:151299)

伴随这种巨大力量而来的是巨大的责任。一个能够从图像中诊断疾病的模型不仅必须准确，还必须值得信赖。在这里，我们遇到了现代人工智能一些最深刻和最令人不安的方面。视觉 Transformer，像所有[深度神经网络](@entry_id:636170)一样，容易受到**[对抗性样本](@entry_id:636615)**的攻击。

想象一个远程皮肤病学应用，它使用 ViT 来筛查黑色素瘤。攻击者可以对一个良性痣的图像像素进行微小、数学上精确的改变——这种改变是如此之小，以至于人眼完全无法察觉。然而，这种精心制作的噪声可能足以欺骗分类器，使其发出高优先级的黑色素瘤警报。反之，更危险的是，一个相似的、无法察觉的扰动可以被应用到一个真实黑色素瘤的图像上，导致人工智能将其误判为良性 [@problem_id:4496259]。

这些不是随机错误。它们是模型“观察”方式的漏洞利用。模型在高维空间中学习了一个复杂的[决策边界](@entry_id:146073)，而对手可以找到跨越该边界的最短路径。攻击可能是在图像文件上进行数字修改，操纵手机摄像头的色彩校正设置，甚至是在拍照前在病变附近贴上一个小的、特殊设计的物理贴纸 [@problem_id:4496259]。这种脆弱性凸显了一个关键的研究前沿：构建能够抵御此类攻击的模型，确保它们的决策在真实且有时是对抗性的世界中是可靠的。

这种对信任的追求超越了安全性，延伸到了[科学方法](@entry_id:143231)的基础。要使一个计算结果可信，它必须是**可复现的**。如果另一个团队使用我们完全相同的数据运行我们完全相同的代码，他们必须得到完全相同的结果。这听起来很简单，但在现代软件的复杂世界里，这绝非易事。仅仅共享代码和数据是不够的。我们还必须记录完整的计算环境：每个库的版本号、操作系统，甚至用于初始化过程中任何[随机数生成器](@entry_id:754049)的“种子” [@problem_id:4856357]。没有这个完整的“出处”，数值库中浮点运算实现的一个微小变化就可能导致不同的结果，将一个科学发现变成机器中无法复现的幽灵。

因此，视觉 Transformer 在医学领域的旅程，本身就是科学之旅的一个缩影。这是一个关于开发强大的新工具以新方式看世界的故事，一个关于结合不同证据流以构建更完整图景的故事，也是一个关于为确保我们所构建的不仅强大，而且可靠、鲁棒并值得我们信赖而不断付出的谦逊努力的故事。