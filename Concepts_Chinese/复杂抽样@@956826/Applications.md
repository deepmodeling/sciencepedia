## 应用与跨学科联系

现在我们已经掌握了复杂抽样的原理——权重、分层、整群——你可能会感觉有点像刚学会国际象棋规则的人。你知道棋子如何移动，但你还没有见证过可以下出的那些优美而惊人的棋局。毕竟，科学的真正魔力不在于规则本身，而在于将它们应用于我们所栖居的这个混乱、结构化且奇妙复杂的世界。

我们的世界不是一袋混合均匀的弹珠。人们生活在城镇和城市里；孩子们上学；病人去诊所。有些群体很容易找到，另一些则隐藏或被[边缘化](@entry_id:264637)。简单随机抽样，我们最初学习的理想化方法，假装这种结构不存在。复杂抽样则是我们用来诚实地看待世界、承认其结构并相应地校正我们视野的工具集。那么，让我们踏上一段旅程，看看这些工具在实践中的应用，去发现它们如何让我们描绘出更真实的世界图景，从绘制疾病的进程到衡量正义的弧线。

### 更真实的健康图景

也许复杂抽样最直接的用途是在公共卫生和医学领域，在这里，准确理解一个总体的健康状况是生死攸关的大事。

想象一下，我们想知道一个大型医疗系统中高血压患者的平均收缩压。这些患者分布在几十个诊所里。要访遍每个病人是不可能的。相反，我们可以随机选择一些诊所（我们的初级抽样单元，或 PSUs），然后在这些选定的诊所内抽样患者。这是一个经典的两阶段整群样本。

现在，如果我们简单地从样本中计算平均血压，我们对这个估计有多大的把握呢？如果我们使用初级统计学课程中教的标准公式，那我们就是在自欺欺人。为什么？因为同一诊所内的患者往往比其他诊所的患者更相似——他们可能有相同的医生、相同的局部环境或社会经济背景。这种“聚集性”意味着从一个诊所抽样十名患者，比从十个不同诊所各抽样一名患者，所提供的新信息要少。

这时，**设计效应** (DEFF) 的概念就成了我们的指南。设计效应是一个数字，它告诉我们复杂样本的方差（或不确定性）比同样大小的简单随机样本大多少。例如，一个 1.7 的 DEFF 告诉我们，样本[方差比](@entry_id:162608)我们天真预期的要大 $70\%$ [@problem_id:4820280]。它本质上是一个谦逊因子；它迫使我们对知识的精确度更加诚实。考虑到它会给我们一个更宽、更现实的[置信区间](@entry_id:138194)——一幅更真实的、关于我们实际所知的图景。

这种思维不仅用于分析，对*设计*也至关重要。思考一下为根除导致河盲症的寄生虫*盘尾丝虫*所做的英勇努力。公共卫生官员需要知道这种寄生虫是否真的从一个地区消失了。他们无法检测每个人，必须设计一项调查。但最佳策略是什么？是走访少数几个村庄并在每个村庄检测很多人，还是走访很多村庄但只检测少数人？答案取决于感染的“聚集性”，我们用**组内相关系数**（ICC 或 $\rho$）来衡量这个量。如果感染高度聚集（$\rho$ 很高），那么一旦你在一个村庄发现一例，再检测同村的另一个人提供的新信息就少了。在这种情况下，把资源花在前往一个新村庄上要好得多。如果感染分布均匀（$\rho$ 很低），你还不如待在原地检测更多人。针对疾病监测的现实世界调查设计是一个有趣的优化问题，它在[统计效率](@entry_id:164796)与旅行成本和后勤之间进行权衡，所有这些都由整群抽样的原则指导 [@problem_id:4803715]。

健康世界不仅仅关乎平均值。我们可能想知道血压的第一个[四分位数](@entry_id:167370)——即 $25\%$ 的人口都低于的那个值。估计一个[分位数](@entry_id:178417)是一项惊人地“非线性”的任务，这使得在复杂调查中为其方差写下一个简单的公式变得非常困难。这时，现代计算的原始力量以一个非常直观的想法来帮助我们：**[重复抽样](@entry_id:274194)法**。使用像[刀切法](@entry_id:174793)或平衡重复复制法 (BRR) 这样的技术，我们通过系统地剔除数据集的小部分并每次重新计算我们的统计量，来创建数千个我们数据集的“重复样本”。我们原始估计的方差，就是我们在所有这些重复样本估计中观察到的方差。这就好像我们在说：“我不知道理论上如何计算我的答案会‘摆动’多少，所以我就亲手‘摇晃’数据，看看它在实践中如何摆动！” [@problem_-id:4826275]。这种计算上的变通方法使我们几乎能为我们能想到的任何复杂统计量找到其不确定性。

### 从描述到建模

描绘总体的图景是至关重要的第一步，但科学很少止步于此。我们想了解该总体*内部*的关系。一个因素如何影响另一个因素？在这里，复杂抽样同样不仅仅是事后的考虑，而是整个机制的基础部分。

即使是一个简单的问题，如“用药依从性与患者性别之间是否存在关联？”，也会受到影响。在入门课程中，你会对一个列联表使用皮尔逊 $\chi^2$ 检验。但如果你的调查对男性进行了过抽样，你的原始样本计数将无法反映总体的真实情况。第一步是使用抽样权重来估计真实的总体列联表。但故事并未就此结束。样本中的整群意味着观测值不是独立的，这违反了 $\chi^2$ 检验的一个核心假设。如果你忽略这一点，你会过于频繁地发现“统计上显著”的关联。你的检验变得过于急切，或者说“反保守”。像 Rao 和 Scott 这样的统计学家开发了修正方法，可以调整 $\chi^2$ 统计量或其参考分布，让我们从一个复杂的世界中得到一个诚实的关联性检验 [@problem_id:4811253]。

当然，现代科学已经从简单的检验发展到复杂的建模。想象一下建立一个逻辑回归模型来预测医院再入院的风险。如果我们的样本是从医院记录中抽取的，它可能低估了来自某些社区或拥有某些类型保险的患者。如果我们在这个原始样本上建立模型，它将是有偏的。它将学习*样本*的模式，而不是我们关心的*总体*的模式。

解决方案是在估计过程中本身就使用抽样权重。这就是**伪似然估计**背后的思想。我们写下似然函数——我们的模型试图最大化的数学表达式——然后我们赋予每个人的贡献一个与其抽样权重成比例的“声音” [@problem_id:4807814]。一个被欠抽样的、代表着总体中许多像他们一样的人的个体，在估计中被赋予了更大的发言权。通过这样做，我们不再是寻找最适合我们奇特样本的模型；我们是在寻找一个能最好地拟合*整个总体*的模型的估计，如果我们能够进行一次普查的话 [@problem_id:4595222]。这一原则延伸到众多现代统计工具中，从用于分析随时间变化的相关数据的广义估计方程 (GEE) [@problem_id:4913874]，到用于生存分析的 Cox 模型，后者常用于因果推断的加权 [@problem_id:4578241]。权重是我们持续的系绳，将我们的模型从样本的特质拉回到总体的真相。

### 为更公正的社会服务的统计学

复杂抽样的旅程并不以更好的模型为终点。其最深刻的应用可能在于它能帮助我们建立一个更公平的社会。通过为我们提供一个真实的、包含其所有多样性和差异性的总体图景，这些方法成为促进社会正义的强大工具。

公共卫生领域最紧迫的问题之一是，干预措施是否惠及了最需要它们的人。一项新的预防服务是被所有人接受，还是只被富裕和人脉广的人接受？**集中指数**是一个旨在回答这个问题的绝妙工具。它衡量了像服务使用率这样的健康变量在富人或穷人中集中的程度。要计算它，我们必须首先将样本中的每个人从最低到最高社会经济地位进行排序。然后，利用我们的调查权重，我们可以计算出一个单一的数字 $C$，它告诉我们不平等的程度。负值意味着服务是“亲贫的”，正值意味着它是“亲富的”，而零值则表示完全平等 [@problem_id:4576512]。这不仅仅是一项学术活动；它是一份关于我们卫生系统公平性的量化成绩单。

这把我们带到了最后一个，也许也是最重要的联系：抽样本身的伦理。长久以来，研究，特别是在原住民和其他代表性不足的社区中，一直是榨取性的。研究人员飞来，收集数据，然后离开，对社区本身几乎没有益处。这种“直升机式研究”不仅在伦理上充满问题，而且常常产生基于不具代表性的方便样本的糟糕科学。

在这里，我们看到了最美丽的统一：良好的伦理和良好的统计学是一回事。**数据主权**的原则——例如 OCAP（所有权、控制权、访问权和占有权）和 CARE（集体利益、控制权、责任、伦理）框架——要求社区控制自己的数据。在这些原则下进行研究的最佳方式是与社区合作，利用他们自己的登记册建立一个适当的、基于概率的抽样框。通过让社区[数据管理](@entry_id:635035)者参与分层的、多阶段的抽样过程，我们可以确保样本真正具有代表性，纳入概率是已知的，并且结果是无偏的。原始数据可以保留在本地服务器上，通过[联邦学习](@entry_id:637118)方法进行分析，完全尊重社区的所有权。

在这种方法中，对明确定义的抽样框和已知纳入概率的统计要求不是一种负担，而是一个尊重合作的框架。它用一个尊重[社区结构](@entry_id:153673)并确保所有亚群都有发言权的系统化过程，取代了[方便抽样](@entry_id:175175)的随意性 [@problem_id:4330124]。它表明，复杂抽样的原则，起初看似仅仅是技术修正，实际上与追求真理、公平和正义紧密交织。它们不仅给了我们更清晰地看世界的工具，也给了我们更光荣地与世界互动的工具。