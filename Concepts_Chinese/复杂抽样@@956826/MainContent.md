## 引言
我们如何获得一个庞大而多样的人口的真实写照？虽然简单[随机抽样](@entry_id:175193)是教科书中的理想方法，但现实世界中预算、时间和后勤的限制常常使其无法实现。复杂抽样正是在这种统计理论与实践现实之间的鸿沟中应运而生——它是一套功能强大的方法，旨在智能、高效地收集代表性数据。本文将为理解和应用这些基本技术提供一份全面的指南。

第一部分，“原理与机制”，将揭开核心概念的神秘面纱。我们将探讨为什么简单随机抽样常常失败，并深入研究构成复杂设计主干的两种主要策略：分层和整群。您将了解到其中涉及的统计权衡（通过设计效应量化），并发现抽样权重如何作为统一的工具来纠正设计复杂性并产生无偏的结果。

随后，“应用与跨学科联系”部分将从理论转向实践。我们将看到这些方法在公共卫生和医学等领域如何不可或缺，从疾病监测到评估健康公平性无所不包。本节将阐释复杂抽样原则如何融入统计建模，并强调其与追求社会正义这一伦理追求的深厚联系，确保研究不仅准确，而且高尚。

## 原理与机制

想象一下，你想知道美国每个成年人的平均身高。这是一个看似简单的问题，但你该如何回答呢？你不可能测量全部 2.5 亿人。你必须进行抽样。最显而易见的方法，也是我们在第一堂统计课上学到的方法，是**简单随机抽样 (SRS)**。你会把每个成年人的名字放进一个巨大的帽子里，用力摇晃，然后抽出，比如说，1000 个名字。这种方法是统计理论的基石，因为它是完全无偏的。每个人被选中的[机会均等](@entry_id:637428)，因此，平均而言，你的样本将是整个总体的完美缩影。

但问题在于：在现实世界中，简单[随机抽样](@entry_id:175193)更像一个美丽的神话，而非实用的工具。并不存在一个装有每个人的“巨大帽子”。即使有，想象一下派遣调查员前往散布在从阿拉斯加的偏远岛屿到纽约市繁华街道的 1000 个随机地址进行调查，其成本和后勤方面的噩梦。有限的预算、时间和人力的现实迫使我们必须更加巧妙。这便是**复杂抽样**的诞生地。它是在“简单”方法不可行时，从一个总体中抽取[代表性样本](@entry_id:201715)的艺术和科学。

### 两种策略的故事：分层与整群

如果我们不能依赖纯粹随机性的蛮力，就必须利用我们对总体结构的知识来为己所用。这引出了两种强大但方向相反的策略：分层和整群。

#### “[分而治之](@entry_id:139554)”策略：[分层抽样](@entry_id:138654)

假设我们知道我们的总体是由彼此差异很大的不同群体组成的。例如，在一项健康调查中，我们可能知道疾病模式在城市、郊区和农村地区之间存在显著差异。如果我们进行简单[随机抽样](@entry_id:175193)，可能纯粹因为运气不好，抽到太多来自城市的人而太少来自农村的人，从而使我们的结果产生偏差。

**[分层抽样](@entry_id:138654)**是解决这个问题的优雅方案 [@problem_id:4624786]。我们不是把每个人都放进一个大帽子里，而是创建几个小帽子——每个群体或**层**一个。然后我们从*每个*帽子中抽取一个随机样本。这保证了我们的最终样本中包含了来自城市、郊区和农村地区的正确比例的人。

这种方法的美妙之处在于，我们主动消除了一个主要的潜在抽样误差来源。通过强制保证这些不同群体的代表性，我们的最终估计变得更加精确。我们估计的方差降低了。事实上，层与层之间的差异越大，而每层内部的人越相似，分层带来的精度提升就越大 [@problem_id:4570359]。这是一个利用智慧以同等努力获得更好答案的完美例子。

#### “实用捷径”策略：整群抽样

现在考虑成本这个实际问题。走访全国 1000 个不同的家庭是不可行的。选择 50 个城市，前往这些城市，然后在每个城市调查 20 个家庭，这样做要便宜得多。这就是**整群抽样**的精髓。总体已经存在于自然形成的群体或**群**中——城市、社区、学校、医院。我们不是抽样个体，而是首先抽样群，这些群成为我们的**初级抽样单元 (PSUs)**。然后，我们可以调查所选群中的每个人（**单阶段整群抽样**），或者在其中[随机抽样](@entry_id:175193)个体（**两阶段整群抽样**） [@problem_id:4830241]。

但这种实用性是有统计代价的。生活在同一社区、上同一所学校或去同一家诊所的人们，往往比普通人群中的其他人更彼此相似。他们可能共享社会经济地位、环境暴露或当地文化习惯。这意味着，在你访谈了一个来自某一群的成员后，来自*同*一群的下一个人提供的新信息，会少于从不同群中随机选择的另一个人所能提供的信息。这种冗余性，一种相关性的形式，意味着我们的样本多样性不如同样大小的真正简单随机样本。其后果是什么？我们估计的方差增加了 [@problem_id:4570359]。

### 便利的代价：设计效应

我们需要一种方法来量化整群抽样的统计成本。这就引出了一个至关重要的概念：**设计效应 (DEFF)**。DEFF 是一个简单的比率：

$$
\text{DEFF} = \frac{\text{我们复杂样本的方差}}{\text{同样大小的简单随机样本的方差}}
$$

如果我们的 DEFF 是 2.0，这意味着我们估计的方差是使用 SRS 时的两倍。换句话说，我们 1000 人的复杂样本的统计精度，仅相当于一个 500 人的 SRS 的精度。为了整群抽样的便利，我们实际上“损失”了一半的样本量。在规划调查时，我们必须通过增加所需样本量来弥补这一点：$n_{\text{complex}} = n_{\text{SRS}} \times \text{DEFF}$ [@problem_id:4583618]。

决定 DEFF 的主要因素是**组内相关系数 (ICC)**，记为 $\rho$。该系数衡量了群内单元的相似程度。如果 $\rho = 0$，群内单元的相似性不高于任意两个随机单元，DEFF 为 1——整群抽样没有统计成本。如果 $\rho > 0$，单元是相似的，DEFF 将大于 1。近似公式 $DEFF \approx 1 + (m-1)\rho$（其中 $m$ 是群大小）清楚地显示了個體间的相似性 ($\rho$) 和群的大小 ($m$) 是如何共同导致这种精度损失的 [@problem_id:4570359]。

### 伟大的统一者：权重的力量

在现实世界中，调查很少只使用一种策略。它们通常是**多阶段**的，结合了分层和整群。例如，一项全国性的健康调查可能首先将国家分层为地理区域，然后在每个区域内抽样县（PSUs），接着在这些县内抽样社区，最后在这些社区内抽样家庭。此外，我们可能有意**过抽样**某些虽小但很重要的群体（如特定的少数民族），以确保我们有足够的人来对该群体做出可靠的陈述。

面对所有这些复杂层次，我们如何才能将数据结合起来，得到一个对整个总体的单一、有效的估计呢？答案在于调查统计学中最优美和最基本的思想之一：**抽样权重**。

把样本中的每个人想象成一位代表。他们不仅仅代表自己；他们代表着总体中未被选中的一群相似的人。对第 $i$ 个人的抽样权重 $w_i$，就是他们所代表的人数。赋予这个权重最基本的原则是选择概率 $\pi_i$ 的倒数：

$$
w_i = \frac{1}{\pi_i}
$$

如果一个人来自我们大量过抽样的群体，他们的选择概率 $\pi_i$ 很高（比如，1/100），所以他们的权重 $w_i$ 很小（100）。他们代表的人较少。如果另一个人来自一个难以接触的群体，他们的选择概率 $\pi_i$ 很低（比如，1/5000），所以他们的权重 $w_i$ 很大（5000）。他们承载着许多人的声音。

当我们想计算任何总体数量时——一个患病率、一个均值，甚至拟合一个像逻辑回归这样的复杂模型——我们都使用这些权重。我们不是计算简单平均值，而是计算加权平均值。每个人的贡献都乘以他们的权重 [@problem_id:4974041]。这个单一而强大的机制，让我们能够纠正我们引入的所有复杂性——分层、整群、过抽样——并恢复一个对整个总体的无偏描绘。这就是**基于设计的推断**的核心。

### 调查的不确定性原理：计算真实置信度

得到一个准确的估计只是故事的一半。我们还需要知道这个估计的不确定性有多大。我们用**[置信区间](@entry_id:138194)**来表达这种不确定性。像 $\frac{\hat{p}(1-\hat{p})}{n}$ 这样的标准方差公式是建立在简单[随机抽样](@entry_id:175193)假设之上的。在复杂调查中，这些公式是错误的。由于整群抽样，我们的观测值不是独立的。使用标准公式会忽略 DEFF，并严重低估我们真实的不确定性。我们将产生过于狭窄的[置信区间](@entry_id:138194)，给人一种虚假的精确感。

那么，我们如何正确计算方差呢？

一种方法是通过复杂的解析公式，如**[泰勒级数](@entry_id:147154)线性化**，它利用微积分来近似方差，同时考虑到设计的分层和 PSU 结构 [@problem_id:4988969]。

另一种可能更直观的方法是**[重复抽样](@entry_id:274194)法**。这个想法非常直接：如果你想知道你的估计在不同可能样本中会如何变化，那就让我们创造出不同的可能样本！我们无法回到总体中去，但我们可以通过一种模拟原始复杂设计的方式，从我们*自己的样本*中[重复抽样](@entry_id:274194)来模拟这个过程。

*   在**[刀切法](@entry_id:174793)[重复抽样](@entry_id:274194)**中，我们通过每次剔除一个 PSU 并重新加权剩余数据以作补偿来创建重复样本。我们为每个重复样本计算我们的估计，并观察这些估计的波动情况。这种变异告诉我们真实的方差 [@problem_id:4957382] [@problem_id:4948641]。
*   在**平衡重复复制法 (BRR)**中（常用于每层有 2 个 PSU 的情况），我们通过从每层中重复选择一个 PSU 并将其权重加倍来创建重复样本 [@problem_id:4948641]。
*   **调查自助法**涉及在每个层内对 PSU 本身进行重抽样，以创建成百上千个新的重复样本 [@problem_id:4948641]。

在所有这些方法中，重复样本估计值的方差提供了一个稳健、诚实的度量我们不确定性的方法，它完全尊重了我们获取数据的复杂过程。

### 两种推断世界：一个哲学上的弯路

最后，我们对复杂抽样的探索将我们引向一个深刻的、近乎哲学性的问题：我们试图描述的现实的本质是什么？答案引出了两种不同的[统计推断](@entry_id:172747)世界。

第一个是**基于设计的框架**，这是我们迄今为止的指南。在这个世界里，总体是一个真实的、固定的、有限的实体。糖尿病的真实患病率是一个单一的、固定的数字。唯一随机的是抽样行为。我们的推断是关于这个具体的、有限的总体。它最大的优点是其稳健性；它依赖的假设非常少，除了抽样设计本身已知的机制之外 [@problem_id:4988969] [@problem_id:4957388]。

第二个是**基于模型的框架**。在这个世界里，我们看到的有限总体只是从一个无限的、抽象的**超总体**中抽取的一个样本，这个超总体由一个[统计模型](@entry_id:755400)（例如，一个产生疾病的[生物过程](@entry_id:164026)）所支配。目标是了解这个底层模型的参数，而不仅仅是描述我们碰巧看到的那个有限总体。在这里，随机性来自这个数据生成过程。如果我们能建立一个准确的模型，包含年龄、性别，甚至整群效应（例如，通过混合效应模型），那么抽样设计本身有时会变得次要 [@problem_id:4986890]。

这就形成了一个经典的权衡。如果模型是正确的，基于模型的方法可能更强大、更高效（产生更精确的估计）。但如果模型是错误的，其结论可能会有严重偏差。相比之下，基于设计的方法，即使我们的科学理解不完整，也依然保持诚实。它关于有限总体的结论受到已知的、随机化抽样设计的完整性的保护 [@problem_id:4957388]。

因此，“如何获得一个好样本”这个看似实际的问题，为我们打开了一扇通往统计真理本质的大门。复杂抽样不仅仅是一堆凌乱技术的集合；它是一个严谨而优美的框架，用于学习这个充满复杂性的世界，证明了我们有能力从不完整但经过智能收集的信息中得出可靠的结论。

