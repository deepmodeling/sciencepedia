## 应用与跨学科联系

既然我们已经熟悉了皮尔逊残差的机制，现在让我们踏上一段旅程，看看它们在实践中的应用。你可能会倾向于认为残差仅仅是统计的碎片——[模型拟合](@entry_id:265652)后剩下的边角料。但这是一个严重的错误。事实上，残差才是故事变得有趣的地方。它们是线索，是异常，是我们最初的模型未能捕捉到的更深层次现实的低语。就像侦探检查犯罪现场一样，科学家利用残差来寻找不合常理之处，并在此过程中常常偶然发现最深刻的发现。

### 归责的艺术：精确定位表格中的偏差

想象一项大规模的医学研究，旨在调查一种新的[他汀类药物](@entry_id:167025)与肌肉相关副作用（肌病）之间是否存在潜在联系。研究人员收集数据并将其整理成一个简单的[列联表](@entry_id:162738)，行代表“使用[他汀](@entry_id:167025)”和“不使用他汀”，列代表“无肌病”、“轻度肌病”和“重度肌病”。他们进行[卡方检验](@entry_id:174175)，得到一个单一的数字——一个 $p$ 值——告诉他们从整体上看，是否存在统计学上的显著关联。

但这是一个相当迟钝的工具。这就像听到房子里有噪音，知道有人在里面，却不知道他们在哪个房间。这种药物是与更多*重度*病例相关？还是与更少*轻度*病例相关？整体检验对此保持沉默。

这时，皮尔逊残差就派上用场了。通过为表格中的每个单元格计算一个残差，我们进行了一种统计学“尸检” [@problem_id:4905100]。“使用[他汀](@entry_id:167025)，轻度肌病”单元格的残差精确地告诉我们，该类别中观察到的患者数量与药物无效假设下的期望数量有何偏差。一个大的正残差就像一根指向的手指，告诉我们：“看这里！使用[他汀](@entry_id:167025)的患者中，轻度肌病的病例远比偶然预期的要多。”一个大的负残差则会表达相反的意思。

突然之间，我们不再处理一个模糊的、全局性的关联。我们可以精确定位是哪些单元格驱动了这一结果。这些残差的平方和甚至能完美地重构出原始的卡方统计量，表明整体证据是由这些特定于单元格的偏差构成的 [@problem_id:4811282]。将一个简单的计数表格转变为一张丰富的证据地图，这是皮尔逊残差的第一个神奇戏法。

### 适用于模型的通用显微镜

然而，残差的真正威力在我们超越简单的表格，进入[广义线性模型 (GLM)](@entry_id:749787) 的广阔世界时才得以释放。在这里，我们的“模型”不再仅仅是独立性的假设，而是一个复杂的、变量之间连续的关系。但原理保持不变：残差是我们逐点检查数据的显微镜。

#### 在公共卫生领域拉响警报

考虑一位正在追踪每周[流感](@entry_id:190386)病例的流行病学家。他们建立了一个复杂的模型，使用谐[波函数](@entry_id:201714)来解释可预测的季节性起伏。该模型为一年中任何一周提供了预期的病例数。但是，当一种新的、更具攻击性的流感毒株开始传播时会发生什么？观察到的病例数将突然飙升至模型预测之上。

通过逐周监测标准化皮尔逊残差，公共卫生官员可以创建一个自动化警报系统 [@problem_id:4836669]。一个超过特定阈值（比如，大于 3）的残差就是一个统计警报，标志着一次异常激增，需要立即进行调查。在这种高风险的背景下，残差不是学术上的好奇心；它是一个至关重要的、能拯救生命的早期预警信号。

#### [药物开发](@entry_id:169064)中的离群值检测

同样的原理在药理学中也必不可少。想象一项针对一种新癌症疗法的定量剂量反应实验，研究人员测试多个剂量水平，并记录每个剂量下产生反应的患者比例 [@problem_id:4586892]。他们拟合一个逻辑斯蒂[回归模型](@entry_id:163386)，该模型描述了一条平滑的 S 形曲线，关联了剂量与反应概率。

但是，如果某个剂量组显示出异常高或低的反应率，远远偏离了曲线，该怎么办？这可能是数据录入错误，一批受污染的药物，或者——最有趣的是——一种复杂的、非单调的生物效应的迹象。简单地观察图表可能会产生误导，特别是如果那个数据点具有高“杠杆值”（意味着它对回归曲线有超乎寻常的拉力，迫使曲线更靠近它，从而掩盖了它自身的奇特性）。

通过计算*标准化*皮尔逊残差，这些残差巧妙地针对这种[杠杆值](@entry_id:172567)进行了调整，我们可以给每个数据点一个公平的评估机会。一个大的[标准化残差](@entry_id:634169)会将该剂量组标记为真正的离群值，促使进一步调查。这使得科学家能够区分随机噪声和真正异常的结果，确保药物的安全性和有效性估计（如著名的 $ED_{50}$）是可靠的。

#### 生态侦探工作：失踪生物之谜

残差这台显微镜不仅能揭示意外的存在，也能揭示意外的缺失。一位研究不同栖息地物种数量的生态学家可能会拟合一个泊松模型，根据森林覆盖率来预测某种鸟类的丰度 [@problem_id:3176891]。在某个特定地点，模型预测他们平均应该能找到五只鸟。但他们观察到的是零。

这不寻常吗？在[期望值](@entry_id:150961)很低的情况下，观察到零是正常的。但在[期望值](@entry_id:150961)很高时观察到零就很可疑了。该地点零计数的大的*负*皮尔逊残差就是线索。它标志着一个“过量零值”——一个模型难以自洽解释的、远小于预期的数据点。这可能会引导生态学家发现该地点一个未被测量的因素，比如一个隐藏的捕食者、一种局部污染物或一种特定的疾病，这些因素正在将当地种群数量推向零。负残差就是机器中的幽灵，指向生态拼图中缺失的一块。

### 诊断模型的“疾病”

到目前为止，我们已经使用残差来审查单个数据点。但我们也可以将它们聚合起来，对整个模型进行健康检查。

简单[统计模型](@entry_id:755400)最常见的弊病之一是**过度离势**。想象一下，用一个泊松模型来拟合一种慢性病的住院人数 [@problem_id:4822307]。泊松分布的一个核心假设是数据的方差等于其均值。但实际上，生物和社会系统往往比这更混乱。一些患者就是比其他患者更容易出现病情恶化，这创造了比模型允许的更大的变异性。

我们如何检测到这一点？我们观察标准化皮尔逊残差。如果[模型拟合](@entry_id:265652)良好，这些残差应该表现得像来自[标准正态分布](@entry_id:184509)的[随机抽样](@entry_id:175193)，这意味着它们的方差应该约为 1。如果我们[计算模型](@entry_id:152639)的残差方差，发现它比如说为 2.1，这就是过度离势的明确症状。模型“发烧”了。这个诊断告诉我们，泊松模型过于僵化，我们需要一个更灵活的替代方案，比如负[二项模型](@entry_id:275034)，其结构明确允许方差的增长速度快于均值。

我们甚至可以将这种诊断形式化为一个强大的[拟合优度检验](@entry_id:267868)。Osius-Rojek 检验建立在一个优美的理论结果之上：在一个正确的模型下，标准化皮尔逊残差平方的均值应为 1。通过测量这个均值偏离 1 的程度，并对该偏差进行标准化，我们可以计算出一个正式的 p 值来评估整体[模型拟合](@entry_id:265652)，而无需诉诸于任意的数据分箱 [@problem_id:4775559]。

### 从线索到宝藏：作为数据的残差

这引出了残差最现代、或许也是最深刻的应用。我们一直将它们视为诊断工具——用来检查模型或寻找离群值。但是，如果残差在剥离了模型的假设和技术噪声之后，*本身*就是我们一直在寻找的数据呢？

这正是 SCTransform 背后的思想，一种用于归一化单细胞 RNA 测序 ([scRNA-seq](@entry_id:155798)) 数据的前沿方法 [@problem_id:4991035]。在 scRNA-seq 中，为每个基因计数的分子数量 (UMI) 受到技术变异性的困扰，尤其是每个细胞的[测序深度](@entry_id:178191)。一个测序更深的细胞会显示其所有基因的计数都更高，这是一个我们必须移除以观察潜在生物学的技术假象。

一个简单的方法，比如简单的对数转换，无法解决第二个问题：基因计数的方差强烈依赖于均值。高表达的基因也具有高变异性，这会扭曲下游分析。

SCTransform 方法采取了一种巧妙的策略。对于每个基因，它拟合一个负二项 GLM，其中基因的表达被建模为细胞[测序深度](@entry_id:178191)的函数。然后，它计算皮尔逊残差。想一想这个残差代表什么：它是一个基因的观测计数与其基于技术因素的[期望值](@entry_id:150961)之间的偏差。从本质上讲，这是*无法*用[测序深度](@entry_id:178191)来解释的变异。

这些残差成为了新的、“归一化”的表达值。由于它们的构造方式，它们不再与测序深度相关。而且，因为它们被基于模型的方差所缩放，它们自身的方差被稳定在约等于 1，无论基因是高表达还是低表达。残差不再是待调查的线索；它已成为宝藏本身——一个干净的、方差稳定的生物学表达度量，随时可用于发现细胞类型和疾病状态。

### 前沿与高级工具

故事并未就此结束。残差的概念是更高级统计工具的基石。

当我们需要为模型的估计构建[置信区间](@entry_id:138194)但又担心其假设时，我们可以求助于**[自助法](@entry_id:139281)**（bootstrap）。在残差[自助法](@entry_id:139281)中，我们将[标准化残差](@entry_id:634169)集合视为一个经验误差分布。我们可以从这个集合中有放回地抽样，用这些“新”误差生成数千个模拟数据集，并对每个数据集重新拟合我们的模型。这给了我们一个可能结果的分布，并提供了对不确定性的[稳健估计](@entry_id:261282)，而这一切都建立在我们初始拟合的普通残差之上 [@problem_id:4954589]。

当我们的模型变得如此复杂——包含多层次的层级结构和随机效应——以至于连标准化皮尔逊残差都开始表现异常时，我们该怎么办？我们转向模拟。例如，DHARMa 方法放弃了为完美残差寻找一个简单的解析公式。取而代之的是，对于每个观测数据点，它使用拟合的模型来模拟数百个可能的结果，从而创建一个[预测分布](@entry_id:165741)。最终的“残差”就是真实观测值在这个模拟云中的排序位置 [@problem_id:4949211]。如果模型是正确的，这些基于排序的残差将是完全均匀的。这种基于模拟的方法是我们旅程的逻辑终点——一个强大、灵活的工具，它体现了残差作为“意外程度”度量的基本精神。

从在简单的表格中进行归责，到成为前沿基因组学中的纯化数据，皮尔逊残差远非一个统计学的附属品。它是一个镜头，一个诊断器，一个警报器，也是一个指南针。它是我们拥有的最优雅、最通用的工具之一，用以审视我们的模型，并通过它们来审视世界。