## 引言
在比较三个或更多组别时，研究人员面临一个关键挑战：如何在不被随机性误导的情况下，识别出具体的差异。执行多个简单的比较，如 t 检验，会显著增加发现一个“显著”但并不真实的结果的风险——这种现象被称为[多重比较问题](@entry_id:263680)。当数据分布不佳，违反了像[方差分析 (ANOVA)](@entry_id:262372) 这样的标准方法的假设时，这个问题会变得更加复杂。这在医学或社会科学等领域是常见情况，因为在这些领域，测量值通常基于[序数](@entry_id:150084)量表或来自[偏态分布](@entry_id:175811)。

本文通过全面介绍 Dunn 检验来应对这一统计挑战，Dunn 检验是进行严谨的非参数比较的强大工具。本文解释了如何首先使用 [Kruskal-Wallis 检验](@entry_id:163863)来确定组间是否存在任何显著差异，然后如何正确使用 Dunn 检验来精确定位这些差异所在。本文将引导您完成从基本理论到实际应用的整个分析过程。

以下章节将揭开这种强大统计方法的神秘面纱。“原理与机制”部分将分解 Dunn 检验的工作原理，解释其基于秩次的公式、其对并列值的巧妙解决方案，以及控制错误率的基本技术。随后，“应用与跨学科联系”一章将展示该框架如何在现实世界的科学探究中应用，从设计稳健的临床试验到解读超越简单平均值的微妙结果。

## 原理与机制

想象一下，你是一位农业研究员，刚刚测试了五种新肥料。你的番茄植株长到了不同的高度，你急切地想知道哪种肥料（如果有的话）是最好的。粗略看一下数据，似乎某些肥料能让植株长得更高，但你如何确定这不只是侥幸，是随机性的把戏呢？

### 窥视的危险：为何比较多组数据很棘手

你的第一反应可能是将肥料两两比较。肥料 A 对比 B，A 对比 C，B 对比 C，依此类推。对于五种肥料，这总共有十次单独的比较！对于每次比较，你可能会使用标准的双样本检验（如 t 检验）。你决定，如果一个检验给出的“p 值”小于 $0.05$（即仅凭运气看到这种差异的几率为 5%），你就宣布一个胜者。

这里隐藏着一个微妙但深刻的陷阱。如果你为一次检验设置了 5% 的假警报风险，而你进行了十次独立的检验，那么至少出现一次假警报的几率就会急剧上升。这就像买十张彩票而不是一张；你中奖的几率会增加。在科学中，我们将这种“中奖”称为**[假阳性](@entry_id:635878)**，这是一场灾难。我们被随机性愚弄了。这就是**[多重比较问题](@entry_id:263680)**：你看得越多，就越有可能发现一些其实并不存在的东西。要进行恰当的分析，我们必须控制**族群错误率 (FWER)**，即在整个比较“族群”中犯下至少一次这种[假阳性](@entry_id:635878)错误的概率。

### 全局裁决：[Kruskal-Wallis 检验](@entry_id:163863)

在我们开始比较单个组对之前，我们需要一个“守门员”。我们需要一个单一的、总括性的检验来告诉我们，我们的组间是否存在*任何*值得研究的显著差异。这就是**总体检验 (omnibus test)** 的工作。如果你的数据分布良好（遵循经典的钟形“正态”分布），你可能会使用著名的[方差分析 (ANOVA)](@entry_id:262372)。

但如果你的数据分布不那么好呢？也许你有几棵长得特别高或特别矮的植株（异常值），或者你的测量是在一个简单的评级尺度上（比如 1 到 5 星）。在这些情况下，[ANOVA](@entry_id:275547) 的假设就不成立了。我们需要一个更稳健的工具，一个不依赖于实际数值，而是依赖于它们相对顺序的工具。这就是**[Kruskal-Wallis 检验](@entry_id:163863)** [@problem_id:1961624] 登场的时刻。

[Kruskal-Wallis 检验](@entry_id:163863)的巧妙之处在于，它首先忽略了植株的实际高度。相反，它将所有五个肥料组的所有植株汇集在一起，从最矮到最高排列。然后，它为每棵植株分配一个**秩次**：1 代表最矮的，2 代表次矮的，以此类推，直到植株总数 $N$。现在，该检验提出了一个简单的问题：“高秩次的植株是集中在某一个肥料组，而低秩次的植株集中在另一个组，还是说秩次在所有组中分布得相当均匀？”

如果一种肥料确实更优越，那么它的植株应该始终比其他植株有更高的秩次。[Kruskal-Wallis 检验](@entry_id:163863)计算一个单一的统计量，即 $H$ 统计量，它衡量秩次分布的不均匀程度。一个大的 $H$ 值表明各组的[中位数](@entry_id:264877)不完全相同，从而导致一个小的 p 值。如果这个 p 值低于我们的阈值（比如 $0.05$），我们就拒绝原假设——即所有肥料效果相同的平淡假设。我们现在可以有信心地得出结论：*某些事情*正在发生。至少有一种肥料与至少另一种不同 [@problem_id:1961638]。

[Kruskal-Wallis 检验](@entry_id:163863)是烟雾报警器。它刚刚响起，告诉我们五层楼的建筑里某处着火了。但它没有告诉我们火灾在哪一层。

### 调查开始：Dunn 检验

为了找出具体的差异，我们需要进行**[事后分析](@entry_id:165661)**（拉丁语为“在此之后”）。由于 [Kruskal-Wallis 检验](@entry_id:163863)是基于秩次的，其后续程序也必须基于完全相同的秩次。这就是**Dunn 检验**作为 [Kruskal-Wallis 检验](@entry_id:163863)的天然和逻辑伙伴登场的场景 [@problem_id:1961651]。它允许我们以一种严谨的方式执行所有期望的成对比较（A vs. B, A vs. C 等），同时尊重初始分析的秩次基础性质。

### 解构 Dunn 检验：信号、噪声和秩次

Dunn 检验的核心非常简单。对于任意两个组，比如说肥料 A 和肥料 B，它计算一个[检验统计量](@entry_id:167372)，该统计量具有所有统计检验的通用形式：

$$
Z_{ij} = \frac{\text{信号}}{\text{噪声}}
$$

“信号”是我们观察到的差异。在这种情况下，它是 $i$ 组植物的平均秩次（$\bar{R}_i$）与 $j$ 组植物的平均秩次（$\bar{R}_j$）之间的差异。“噪声”是[标准误](@entry_id:635378)——衡量这种差异仅由纯粹的随机性引起的变化程度。

因此，Dunn 检验的统计量是：

$$
Z_{ij} = \frac{|\bar{R}_i - \bar{R}_j|}{\sqrt{\frac{N(N+1)}{12} \left( \frac{1}{n_i} + \frac{1}{n_j} \right)}}
$$

让我们像物理学家一样看待这个公式。分子 $|\bar{R}_i - \bar{R}_j|$ 很直接：它是我们感兴趣的差异的大小。分母是魔术所在之处，它代表了我们比较中的不确定性。注意两个关键部分：

1.  **样本量（$n_i$, $n_j$）：** 项 $\left( \frac{1}{n_i} + \frac{1}{n_j} \right)$ 告诉我们一些我们的直觉已经知道的事情：涉及较小组的比较噪声更大，可靠性更低。随着样本量 $n_i$ 和 $n_j$ 变大，这一项变小，分母缩小，我们的 $Z$ 统计量变大，从而更容易检测到真正的差异。这对实验设计也有深远的影响。如果你的总样本量是固定的，通过使各组大小尽可能相等，你通常可以在所有比较中获得最一致的功效。高度不平衡的组大小意味着涉及最小组的比较将具有非常大的[标准误](@entry_id:635378)，因此功效非常低 [@problem_id:4921360]。

2.  **全局秩次方差：** 项 $\frac{N(N+1)}{12}$ 是从 $1$ 到 $N$ 的完整秩次集的一个属性。事实上，它与这组数字的方差成正比。它代表了可供分配给各组的秩次中的总变异量。对于给定的总样本量 $N$，它是一个常数。

想象一下，通过测量用户完成任务所需的时间来测试不同的用户界面 (UI) 设计。在发现一个显著的 Kruskal-Wallis 结果后，我们可以应用 Dunn 检验来查看哪些具体设计存在差异。我们会汇集所有的完成时间，对它们进行排序，计算每个设计组的平均秩次，然后将这些值代入我们想要比较的每对设计的公式中，例如设计 B 与设计 C 的比较 [@problem_id:1964680]。

### 并列值的现实：秩次中的一个皱褶

我们那个从 $1$ 到 $N$ 的唯一秩次的干净理论世界，很少能在现实中幸存。在使用严重程度量表或任何精度有限的测量的医学研究中，我们经常遇到**并列值**：多个观测值具有完全相同的值。我们如何对它们进行排序？

标准程序是使用**中间秩次**。如果三棵植株并列在第 5、第 6 和第 7 位，我们不能只选一个作为第 5。相反，我们给这三者它们所占据秩次的平均值：$(5+6+7)/3 = 6$。这是公平和对称的。

但这个优雅的解决方案带来了一个新的问题。通过迫使几个观测值共享相同的秩次，我们略微减少了秩次集的总变异性。现在的秩次集没有 $\{1, 2, ..., N\}$ 那么分散了。我们分母中的噪声项，原本假设没有并列值，现在有点偏大。使用它会使我们的检验过于保守——我们检测到真实差异的可能性会降低。

修正方法和问题本身一样优雅。我们引入一个**并列校正因子** $C_T$，它总是一个略小于 1 的数。你有的并列值越多，$C_T$ 就变得越小。我们新的、更准确的标准误变为：

$$
\text{SE}_{\text{tied}} = \sqrt{\frac{N(N+1)}{12} C_T \left( \frac{1}{n_i} + \frac{1}{n_j} \right)}
$$

校正因子的完整公式是 $C_T = 1 - \frac{\sum (t^3 - t)}{N^3 - N}$，其中我们对所有并列值组进行求和，$t$ 是一个并列组中的观测数量。你不需要记住它，但你应该理解它的作用：它系统地减少了估计的噪声，以精确地解释因并列值而损失的方差 [@problem_id:4921329]。这种调整确保了我们基于置换的推断保持有效，并且即使在处理混乱的真实世界数据时，我们的检验也具有正确的灵敏度 [@problem_id:4921331]。

### 为窥视付出代价：控制错误

我们为每一对都得到了[检验统计量](@entry_id:167372)。现在我们必须回到我们开始时提到的[多重比较问题](@entry_id:263680)。我们需要调整我们的显著性阈值来控制族群错误率。

最简单的方法是 **Bonferroni 校正**。它严格但有效：如果你正在进行 $m$ 次比较，并且你期望的总体错误率是 $\alpha$（例如 $0.05$），你只需用一个新的、更严格的阈值 $\alpha/m$ 来检验每个单独的比较 [@problem_id:1964680]。如果我们有 10 次比较，任何给定对的 p 值必须小于 $0.05/10 = 0.005$ 才能被宣布为显著。这是一个沉重的代价，有时可能会过于保守，导致我们错过真实但较小的效应。

幸运的是，有更聪明的方式来付出这个代价。**Holm-Bonferroni 方法**是一种“降阶”程序，它一致地比经典的 Bonferroni 更强大。它的工作原理如下：
1.  你对所有 $m$ 个成对比较运行 Dunn 检验，得到你的 $m$ 个未经调整的 p 值。
2.  你将这些 p 值从小到大排序：$p_{(1)}, p_{(2)}, ..., p_{(m)}$。
3.  你用 $\alpha/m$ 检验最小的 p 值 $p_{(1)}$。如果它显著，你宣布这对有差异并继续。
4.  你用一个稍微宽松的阈值 $\alpha/(m-1)$ 检验第二小的 p 值 $p_{(2)}$。如果显著，你继续。
5.  你继续这个过程，用 $\alpha/(m-j+1)$ 检验 $p_{(j)}$，直到你找到第一个*不*显著的 p 值。那一刻，你停止。你宣布所有先前检验过的对都显著，而所有剩余的对（包括刚刚失败的那个和所有更大的）都不显著。

这个序贯过程比简单的 Bonferroni 校正更宽容，同时仍然严格地将总体族群错误率控制在 $\alpha$ 水平 [@problem_id:4921336]。

### 检验的宇宙：Dunn 检验在家族中的位置

在 [Kruskal-Wallis 检验](@entry_id:163863)之后，Dunn 检验是一个强大且合乎逻辑的选择，但它不是唯一的选择。[非参数统计](@entry_id:174479)的世界充满了替代方案，每种方案对于如何估计“噪声”项都有其自己微妙的哲学。

例如，**Conover-Iman 检验**使用一种不同的方法来计算方差。它不是使用秩次的全局理论方差，而是汇集每个组*内部*的方差，很像标准的 [ANOVA](@entry_id:275547)。这有时可能导致一个更强大的检验，特别是当组大小不相等时 [@problem_id:4921344]。另一个经典方法是 **Nemenyi 程序**，它使用[学生化全距分布](@entry_id:169894)（类似于 ANOVA 中的 Tukey 检验），但当存在大量并列值时，它可能会过于保守，因为其标准公式没有对它们进行校正 [@problem_id:4797220]。

这些不同方法的存在并不意味着一个是“对”的，而其他是“错”的。相反，它反映了科学探究的持续、动态的本质。每个检验都代表了一套略有不同的假设，以及在功效、保守性和计算简便性之间的权衡。理解 Dunn 检验背后的原理——秩次的逻辑、对多重比较的诚实核算，以及对并列值的优雅校正——不仅让你能够使用一个工具，还能让你欣赏统计推理本身固有的美和统一性。

