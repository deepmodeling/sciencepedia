## 引言
从更快的单处理器到多核 CPU 的演进，预示着一个[并行性能](@entry_id:636399)的新时代。然而，简单地将任务分配到这些核心上——一种称为[负载均衡](@entry_id:264055)的策略——揭示了一个微妙但重大的性能瓶颈：数据访问的成本。当一个任务在核心之间移动时，它会失去其“暖缓存”，从而被迫从主内存进行耗时的读取。本文将直面这一挑战，探索缓存亲和性这一关键原则，即把计算及其[数据保留](@entry_id:174352)在同一个处理器核心上以最大化效率的实践。

首先，在“原理与机制”部分，我们将剖析缓存亲和性与负载均衡之间的根本冲突，审视由[操作系统调度](@entry_id:753016)器精心编排的微妙平衡。接着，在“应用与跨学科联系”部分，我们将看到这一原则如何成为高性能设计的基石，塑造了从网络包处理、存储设备架构到大规模科学模拟中使用的数据结构等方方面面。

## 原理与机制

在计算世界里，我们常把中央处理器（CPU）称为机器的“大脑”。几十年来，通往更快计算机的道路似乎很简单：只需构建一个更快的大脑。但物理学家和工程师最终遇到了根本性的限制。光速不仅是一个宇宙速度极限，它也是一个非常局部的极限。信号穿越一块微小硅芯片所需的时间成了一个瓶颈。因此，我们不再制造一个思考更快的单一大脑，而是开始给我们的机器多个能并行思考的大脑——即“核心”。

今天，即使是你口袋里的手机也可能有四核、六核甚至八核。数据中心的服务器可能有几十个核心。这有点像用一整个团队非常优秀的厨师替换掉一位快如闪电的主厨，让他们在同一个厨房里工作。乍一看，这似乎是一个直接的胜利。如果一个厨师在忙着切菜，另一个可以炒菜，第三个可以摆盘。主厨——我们的[操作系统](@entry_id:752937)**调度器**——只需把任务分发给任何有空的厨师。这种被称为**[负载均衡](@entry_id:264055)**的策略，似乎显然是正确的。其目标是让每个人都保持忙碌，并最大化完成的总工作量。但这个简单的画面隐藏了一个微妙而极其重要的成本：遗忘的成本。

### 个人工作台与冷启动的代价

想象一下，我们厨房里的每个厨师在他们的工位旁边都有一个小的个人工作台。这就是他们的**缓存**。他们在上面放着最常用的工具和配料：一把最喜欢的刀、一撮盐、一瓶橄榄油。从这个工作台上拿东西几乎是瞬时的。而存放其他所有东西的主储藏室在厨房的另一头。走到储藏室需要时间。这就是我们的**主内存**，或称 RAM。

现在，如果我们的主厨为了让每个人都忙碌而不断地在工位之间调动厨师，会发生什么？一个在 A 工位做沙拉的厨师被告知要移动到 C 工位去开始一项新任务。当他们到达 C 工位时，工作台是空的。他们最喜欢的刀和橄榄油都还在 A 工位。为了完成工作，他们必须慢悠悠地走到主储藏室去取所需的一切。通过立即开始新任务所获得的效率，完全被设置新工作区所浪费的时间所抵消。

这正是 CPU 内部发生的事情。当一个核心运行任务时，它会把所需的数据从慢速的主内存拉入其快速的本地缓存中。如果该任务再次在那个核心上运行，它会发现数据已经在等着了——一个**暖缓存**。工作会很快。如果调度器将任务迁移到*不同*的核心，新核心的缓存中没有所需的数据。必须再次从主内存中重新获取。这就是**缓存未命中**，而重新填充缓存的过程被称为**冷启动**。

性能损失非同小可。从本地缓存访问数据可能比从主内存获取快数百倍。让我们考虑一个简单的场景，有 320 个简短、相同的任务需要由 8 个核心处理。假设每个任务的大部[分工](@entry_id:190326)作都涉及从一个共享的 128 KiB 表中读取数据。如果调度器天真地分发任务，它可能会频繁地迁移它们，以至于每个任务到达一个核心时都是“冷”缓存，并且必须支付加载那个共享表的全部代价。但如果我们更聪明一点呢？如果我们把 40 个任务为一组“钉”在每个核心上呢？每个核心上的第一个任务需要付出代价来加载表以预热缓存。但该核心上接下来的 39 个任务会发现表已经在那里等着它们，随时可用。仅仅通过避免迁移并保持我们所谓的**缓存亲和性**，处理这批任务的总时间就可以显著减少——在现实场景中，这个简单的改变可以将[吞吐量](@entry_id:271802)提高超过 20% [@problem_id:3679722]。遗忘的代价是真实且高昂的。

### 调度器的困境：一场拉锯战

我们由此触及现代调度器设计的核心冲突：[负载均衡](@entry_id:264055)与缓存亲和性之间的拉锯战。一方面，我们希望让所有核心都保持忙碌以最大化吞吐量。另一方面，我们希望将任务保留在同一核心上以利用暖缓存并最大化效率。这两个目标在根本上是矛盾的。

要观察这种紧张关系，我们只需看看调度器最基本的工具之一：**时间量子**（或时间片）。在抢占式系统中，调度器允许一个任务运行一小段时间，即时间量子 $q$，然后停止它，让另一个任务运行。这确保了没有单个任务能独占 CPU，从而提供了公平性和响应性。

但是 $q$ 的正确值是什么？
- 如果我们选择一个非常小的 $q$（例如，几分之一毫秒），我们会得到极好的短期公平性。许多任务在短时间内都有机会运行。但这对缓存亲和性来说代价是灾难性的。随着每一次快速的上下文切换，一个新任务进入并用自己的数据污染缓存，驱逐了前一个任务的数据。当每个任务在每一轮运行时都几乎以冷缓存开始时，性能会急剧下降。
- 如果我们选择一个非常大的 $q$（例如，数百毫秒），每个任务都能长时间运行，预热缓存并高效执行。这对[缓存局部性](@entry_id:637831)非常有利。但对公平性和[系统响应](@entry_id:264152)性来说却很糟糕。一个交互式任务，比如你的网页浏览器，可能会被卡住，等待一个长时间运行的后台计算完成其漫长的时间片。

要设计出合适的实验来衡量这种权衡本身就是一项精细的科学任务。为了正确地看到效果，必须控制诸如 CPU 频率缩放之类的混淆变量，将竞争进程钉在同一个核心上以确保它们确实相互干扰对方的缓存，并使用数据集大小恰到好处的工作负载——小到可以单独放入缓存，但大到一起运行时会产生冲突 [@problem_id:3672177]。这场在公平性与局部性之间的持续斗争是每个[操作系统](@entry_id:752937)设计者都面临的困境。

### 一种审慎的方法：软亲和性与可调调度器

如果绝对的规则——“总是迁移到空闲核心”或“永不迁移”——都过于粗糙，那么答案或许在于一种更细致、概率性的方法。这就引出了**软亲和性**这个优雅的概念。软亲和性不是一道严格的命令，而是一个强烈的建议。调度器*倾向于*将任务保留在其上次使用的核心上，但如果[负载均衡](@entry_id:264055)的需求变得紧迫，它被允许推翻这一偏好。

这个简单的[启发式方法](@entry_id:637904)可以产生巨大影响。考虑一个高性能的键值存储，就像那些为社交媒体信息流和在线购物车提供动力的系统。许多请求将针对一小组“热”键。如果每个请求被随机分配给任何可用的核心，每个核心的缓存将包含一堆杂乱无章、几乎无用的键。缓存命中率将惨不忍睹。但如果调度器实现软亲和性策略——例如，确保对给定键的请求有 85% 的机会由处理该键上一个请求的同一核心处理——系统的行为就会改变。每个核心开始专精化，其缓存因特定的热键[子集](@entry_id:261956)而变暖。整体缓存命中率可以飙升，从而显著提高系统的吞吐量 [@problem_id:3672823]。

这不仅仅是一个理论上的想法；现实世界的调度器就是这样构建的。例如，Linux 内核的调度器不只是做一个二元决策。它会进行[成本效益分析](@entry_id:200072)。它有一个内部可调参数 `kernel.sched_migrate_cost_ns`，代表了迁移一个任务的性能损失的估计值，单位是纳秒。只有当平衡负载所带来的预期收益超过这个成本时，调度器才会移动一个任务。

这给了系统管理员一个强大的杠杆。如果你的延迟敏感型应用程序正遭受性能[抖动](@entry_id:200248)——完成时间的剧烈波动——并且你观察到频繁的迁移，你可以直接干预。通过增加 `sched_migrate_cost_ns` 的值，你等于在告诉调度器：“我认为缓存亲和性的价值比你目前认为的要高。在迁移这个任务时要更不情愿一些。” 这可以通过减少昂贵的缓存冷启动次数来稳定性能，通常代价只是轻微牺牲完美的负载[分布](@entry_id:182848) [@problem_id:3672775]。调度器的设计，从其基本的数据结构（每核心运行队列自然地促进亲和性）到其可调参数，都是这种局部性与负载均衡之间权衡的物理体现 [@problem_id:3685241]。

### 当好的亲和性变坏时

到目前为止，亲和性似乎是一个明确的好处，一个应尽可能追求的目标。但自然界很少如此简单。在一个情境中有益的原则，在另一个情境中可能是有害的。那么，我们对亲和性的渴望何时会变成一种诅咒呢？

考虑一个线程，它在短暂的计算爆发和等待慢速设备（如磁盘或网络连接）的长时间之间交替。这是 I/O 密集型任务的常见模式。假设该线程在核心 $C_0$ 上运行，然后阻塞以等待文件下载。如果这个等待时间 $d_{\text{IO}}$ 非常长，它在 $C_0$ 缓存中的任何数据都早被在此期间运行的其他任务所驱逐。无论如何，它的缓存都是冷的。当下载完成，我们的线程醒来时，假设它原来的核心 $C_0$ 现在正忙，但另一个核心 $C_1$ 是空闲的。

一个强制执行**硬亲和性**（一条严格规则）的调度器应该怎么做？它必须强迫该线程在一个队列中等待 $C_0$ 变为空闲。这个等待时间 $w$ 是纯粹的浪费。硬亲和性的好处——保持暖缓存——已经不复存在了。一个使用软亲和性的更聪明的调度器会认识到这一点。它会看到等待的成本 ($w$) 大于迁移的成本（一个它无论如何都必须支付的预热惩罚 $t_{\text{warm}}$）。它会立即将线程分派到空闲的核心 $C_1$。在这种情况下，亲和性是有害的，因为它存在的原始理由已经消失了 [@problem_id:3672763]。

情况可能变得更具病态性。想象一个错误的配置，一个低优先级的后台任务被硬亲和性地钉在与两个高优先级、总是在运行的前台任务相同的核心 $C_0$ 上。当核心 $C_1$、$C_2$ 和 $C_3$ 完全空闲时，这个低优先级任务却被困在 $C_0$ 上。因为高优先级任务总是抢占它，它永远没有机会运行。它被**饿死**了，等待着无限长的时间。在这里，对硬亲和性的盲目遵守导致了公平性和系统效率的灾难性失败。一个设计良好的调度器会实现一个“退避”规则：如果一个任务在其偏好的核心上等待了不合理长的时间，并且存在显著的负载不平衡，那么软亲和性偏好将被暂时忽略以防止饿死 [@problem_id:3672841]。亲和性，就像任何强大的工具一样，必须被智能地应用。

### 巨人之地：NUMA 系统上的亲和性

当我们从单个芯片的规模转向驱动互联网的大型服务器时，故事又进了一章。这些机器通常有多个独立的处理器插槽，每个插槽都有自己专用的[内存控制器](@entry_id:167560)。在我们的厨房比喻中，这不仅仅是一个厨房，而是两个或更多由走廊连接的独立厨房。这种架构被称为**[非统一内存访问 (NUMA)](@entry_id:752609)**，因为访问内存所需的时间不再是统一的。访问连接到自己插槽的内存（自己厨房里的储藏室）是快速的。访问连接到另一个插槽的内存（走过走廊到*另一个*厨房的储藏室）则明显更慢。

在 NUMA 系统上，将一个任务从插槽 0 上的核心迁移到插槽 1 上的核心是一场性能灾难。任务不仅失去了它的暖私有缓存，而且它在主内存中的整个工作数据集现在都变成了“远程”的。每一次内存访问现在都必须支付穿越插槽间互连的高延迟惩罚。

这对调度器的迁移策略提出了更高的要求。调度器通常采用两种主要策略进行[负载均衡](@entry_id:264055)：
- **推送迁移 (Push Migration)**：一个周期性任务运行，发现一个过载的核心，并将其中的一个任务“推送”到一个负载较轻的核心。这是主动的，但可能对 NUMA 拓扑结构是盲目的，有可能将任务推送到远程插槽。
- **拉取迁移 (Pull Migration)**：一个空闲的核心主动从一个繁忙核心的队列中“拉取”一个任务。这个策略通常实现得更智能。一个空闲的核心会首先尝试从*同一插槽*上的其他核心拉取任务，然后才会考虑从远程插槽进行代价高昂的拉取。

对于内存密集型工作负载，例如频繁访问页面缓存中的文件并产生许多次要缺页中断的工作负载，差异是显著的。一个激进的推送迁移策略可以轻易地将任务移离其数据所在的插槽，导致每次[缺页中断](@entry_id:753072)的延迟因远程内存访问而飙升。而一个更具局部性感知的拉取迁移策略可以避免这种惩罚，这表明性能差异并非来自推送与拉取的行为本身，而是来[自指](@entry_id:153268)导决策的亲和性启发式算法 [@problem_id:3674396]。

### 统一的原则

从[操作系统调度](@entry_id:753016)器的一个选择，到整个软件架构的设计，我们都看到了同样的基本原则在起作用。现代异步、事件驱动服务器的惊人效率——它们通常使用单个线程处理数千个 I/O 操作——直接源于最大化缓存亲和性。通过避免大规模多[线程模型](@entry_id:755945)中固有的上下文切换和缓存干扰，它们确保了核心的缓存始终保持着处理下一个事件所需的数据和逻辑的“热”状态 [@problem_id:3621609]。

局部性原理——将数据保持在需要它的计算附近——是简单、几乎显而易见的。然而，它的后果却贯穿于现代计算机系统的每一层。它迫使我们在将事物放在一个地方以便记忆，和移动它们以完成工作之间进行微妙的舞蹈。理解这种舞蹈，这种局部性与平衡之间的美妙张力，是释放我们周围并行机器真正潜能的关键。

