## 引言
描述[材料行为](@article_id:321825)的传统方法依赖于预定义的数学方程，这些方程往往难以捕捉真实世界材料的全部复杂性。一种新的[范式](@article_id:329204)——数据驱动[本构建模](@article_id:362678)——通过直接从实验或模拟数据中学习这些行为，提供了一种强大的替代方案。然而，一个重大的挑战随之而来：我们如何确保这些通过数据训练出来的、通常被视为“黑箱”的模型，能够遵守基本的物理定律？一个违反[能量守恒](@article_id:300957)或客观性等原则的模型不仅是不准确的，它在物理上也是不可能的。

本文通过全面概述如何构建物理一致的数据驱动[本构模型](@article_id:353764)来解决这一关键问题。您将学到将物理定律直接[嵌入](@article_id:311541)到机器学习框架中的核心策略，将它们从天真的模式发现者转变为复杂的建模工具。本文首先探讨基本规则以及如何强制执行它们，然后展示这些模型在科学和工程学科中带来的变革性影响。

第一章 **原理与机制** 深入探讨了来自[连续介质力学](@article_id:315536)和[热力学](@article_id:359663)的基本约束，如对称性和[能量守恒](@article_id:300957)，并研究了将这些定律融入模型架构和学习过程的技术。随后，**应用与跨学科联系** 章节阐述了这些复杂模型如何通过在仿真中充当高保真[代理模型](@article_id:305860)、在[多尺度建模](@article_id:315375)中连接不同尺度以及为理性材料设计铺平道路，从而彻底改变各个领域。

## 原理与机制

在上一章中，我们接触到了一个诱人的新想法：如果我们不从上而下地规定[材料行为](@article_id:321825)的法则，而是让材料自己说话，会怎么样？如果我们能用实验的原始数据来*发现*这些法则，又会如何？这正是数据驱动本构建模的核心承诺。我们可以将一个强大的函数近似器，比如一个[深度神经网络](@article_id:640465)，想象成一个全能的学生。我们给它输入成对的应变和应力测量值，它就能学习它们之间的映射关系：$\hat{\boldsymbol{\sigma}} = \mathcal{N}_{\theta}(\boldsymbol{\epsilon})$，其中 $\boldsymbol{\epsilon}$ 是应变，$\hat{\boldsymbol{\sigma}}$ 是预测的应力，而 $\theta$ 代表我们网络中大量的可调参数 [@problem_id:2656079]。

但是一个没有指导、没有[第一性原理](@article_id:382249)的学生，可能会学到各种各样的无稽之谈。神经网络在某种程度上是一个“黑箱”；它非常善于发现模式，但对物理世界没有天生的理解。如果我们只要求它最小化训练数据上的误差，它可能会学到一个“定律”，这个定律只对我们展示给它的特定实验有效，但在新情况下却会严重违反基本物理原理。它可能会预测一个物体会自发地开始旋转，或者能量可以无中生有。因此，我们的任务不仅仅是培养一个学生，更要做一个好老师。而我们必须教授的课程，就来自于力学和[热力学](@article_id:359663)的基石原理。

### 基本法则：施加物理一致性

宇宙并不关心我们的[神经网络](@article_id:305336)。它按照一套严格的规则运行，而我们构建的任何模型，若想有用，就必须遵守这些规则。幸运的是，我们可以将这些规则直接融入学习过程，将我们天真的学生转变为一个成熟的物理学家。

#### 平衡法则：为何物体不会自发旋转

想象一下，推一本放在桌上的书。如果你用同样大小的力向右推书的[上边缘](@article_id:319820)，同时向左推书的下边缘，书会滑动，而不会原地旋转。这个简单的观察体现了一个深刻的原理：**角动量守恒**。在连续介质力学的世界里，我们没有内部马达或微小的体耦合，这个定律要求 **Cauchy [应力张量](@article_id:309392)** $\boldsymbol{\sigma}$ 必须是**对称的**。也就是说, $\boldsymbol{\sigma} = \boldsymbol{\sigma}^{\mathsf{T}}$，在三维空间中，这意味着[应力分量](@article_id:373838) $\sigma_{12}$ 必须等于 $\sigma_{21}$，以此类推。

我们如何将这一点教给我们的模型呢？我们有两种主要策略 [@problem_id:2898846]。

第一种是通过**构造**来强制执行。一个通用的 $3 \times 3$ [张量](@article_id:321604)有九个分量。一个[对称张量](@article_id:308511)只有六个独立分量。因此，我们可以简单地设计我们的[神经网络](@article_id:305336)，让它输出一个包含六个数字的向量，然后用这些数字来构建对称张量。这样，模型在架构上就无法预测出非对称的应力。这就像造一辆方向盘被锁住的汽车——它保证只能直行。

第二种策略是使用**软约束**，或称惩罚项。我们让网络预测应力的所有九个分量，给予它更大的自由度。但是，我们在[损失函数](@article_id:638865)——即我们在训练中试图最小化的函数——中增加一个惩罚项，以惩罚任何偏离对称性的行为。这种惩罚项的一个常见选择是 $\mathcal{R}(\boldsymbol{\sigma}) = \beta \, \|\operatorname{skw}(\boldsymbol{\sigma})\|_{F}^{2}$，其中 $\operatorname{skw}(\boldsymbol{\sigma}) = \frac{1}{2}(\boldsymbol{\sigma}-\boldsymbol{\sigma}^{\mathsf{T}})$ 是应力的斜对称（或反对称）部分。如果应力是对称的，这个项就为零；否则，它就是一个正值。在训练过程中，优化器会自然地学会使应力对称以避免这种惩罚。这个惩罚项的梯度，也就是优化器所使用的信息，结果非常简洁：$\frac{\partial \mathcal{R}}{\partial \boldsymbol{\sigma}} = \beta(\boldsymbol{\sigma}-\boldsymbol{\sigma}^{\mathsf{T}})$ [@problem_id:2898846]。这就像教孩子走路；你不会在他们周围搭建一个机械支架，而是在他们快要摔倒时轻轻地扶正他们。

#### 视角法则：客观性与[材料对称性](@article_id:352907)

物理定律必须独立于观察者。这一原理被称为**[参考系无关性](@article_id:376074)**或**客观性**，意味着本构律不应仅仅因为你（观察者）决定转动你的头而改变。这是关于世界的陈述，而不是关于材料的。

与此不同的是**[材料对称性](@article_id:352907)**。材料本身可以具有内在的、固有的对称性。想象一块木板：它顺着纹理和横着纹理的性质是不同的。但如果你围绕垂直于纹理的轴线将其旋转 $180^\circ$，它的性质看起来是一样的。晶体根据其晶格结构，具有更复杂的[旋转对称](@article_id:297528)性。

这两个概念之间有一个优美而微妙的数学区别 [@problem_id:2658695]。客观性关系到当我们旋转观察变形的*空间[参考系](@article_id:345789)*时会发生什么。这表示为对变形梯度的左乘，$\mathbf{R}\mathbf{F}$。另一方面，[材料对称性](@article_id:352907)描述了当我们在变形前旋转*材料本身*时会发生什么。这是一个右乘，$\mathbf{F}\mathbf{Q}$，其中 $\mathbf{Q}$ 是[材料对称群](@article_id:365087) $G$ 中的一个旋转。

对于 Cauchy 应力，[材料对称性](@article_id:352907)的结果是一个简单而强大的不变性条件：$\boldsymbol{\sigma}(\mathbf{F}\mathbf{Q}) = \boldsymbol{\sigma}(\mathbf{F})$。用文字来说：如果你先将材料按其对称旋转之一 $\mathbf{Q}$ 进行旋转，然后施加一个变形 $\mathbf{F}$，所产生的应力应该与你只施加 $\mathbf{F}$ 而没有初始旋转时的应力*完全相同*。这为我们的模型提供了一个清晰、量化的测试：我们可以给模型输入一个变形 $\mathbf{F}$ 和一个[对称变换](@article_id:304834)后的变形 $\mathbf{F}\mathbf{Q}$，并检查预测的应力是否相同。任何偏差都表明我们的模型并未真正学到材料的特性 [@problem_id:2658695]。

#### [能量法](@article_id:362342)则：守恒与耗散

也许最深刻的约束来自[热力学](@article_id:359663)。对于一个简单的弹性材料，比如弹簧或橡皮筋，你拉伸它所做的功被储存为势能。当你放手时，所有的功都会被释放回来。这就是**[超弹性](@article_id:319760)**材料的概念。这种路径无关性意味着存在一个标量**[应变能密度](@article_id:378821)**函数 $\psi$，应力可以作为其梯度来导出：$\boldsymbol{\sigma} = \frac{\partial \psi}{\partial \boldsymbol{\epsilon}}$。

这带来了一个非凡的后果。[切线刚度](@article_id:345531)[张量](@article_id:321604) $\mathbb{C}_{ijkl} = \frac{\partial \sigma_{ij}}{\partial \epsilon_{kl}}$，它告诉我们应力如何随应变的微小变化而变化，必须具有**[主对称性](@article_id:377276)**：$\mathbb{C}_{ijkl} = \mathbb{C}_{klij}$ [@problem_id:2656012]。这是混合[二阶偏导数](@article_id:639509)相等的直接结果。

我们如何强制执行这一点？一种方法是，再次通过损失函数中的惩罚项。但一种远为优雅的方法是全心全意地拥抱物理学。与其直接训练网络预测应力 $\boldsymbol{\sigma}$，我们可以训练它学习标量势 $\psi$。然后，我们通过对网络输出相对于其输入的[导数](@article_id:318324)来计算应力，这是现代深度学习框架非常胜任的任务（一种称为[自动微分](@article_id:304940)的技术）。通过这一优美的设计，刚度的[主对称性](@article_id:377276)*通过构造*得到了保证 [@problem_id:2656012]。模型不仅在行为上是正确的，在结构上也是健全的。

当然，并非所有材料都是完美弹性的。如果你弯曲一个回形针，它会保持弯曲状态。你投入的能量没有完全恢复；一部分以热量的形式**耗散**掉了。热力学第二定律规定，这种耗散永远不能为负。你不可能有一个自发冷却并对其周围环境做功的过程。我们也能够并且必须强制执行这个条件。我们可以在各种虚拟实验中测试我们的模型，并对任何预测出负耗散的情况增加惩罚，确保我们的模型不会学会成为一个[永动机](@article_id:363664) [@problem_id:2656069]。

### 表示的艺术：细节至关重要

人们很容易认为，一旦我们理解了宏大的物理原理，剩下的就只是细节问题了。但在科学和工程领域，我们记录事物的方式的细节可能会产生深远的影响。考虑一下将一个对称的 $3 \times 3$ [张量](@article_id:321604)（这是一个矩阵）输入到一个通常[期望](@article_id:311378)简单向量的[神经网络](@article_id:305336)中所面临的挑战。我们需要将其展平。

一种朴素的方法，称为 **Voigt 表示法**，是简单地将六个独立分量列在一个向量中，例如 $(\sigma_{11}, \sigma_{22}, \sigma_{33}, \sigma_{23}, \sigma_{13}, \sigma_{12})$。这种方法可行，但它有一个隐藏的缺陷。在[张量](@article_id:321604)的世界里，“大小”或“量级”是通过 Frobenius 范数 $\|\boldsymbol{\sigma}\|_F^2 = \sum_{i,j} \sigma_{ij}^2$ 来测量的，这与能量有关。Voigt [向量空间](@article_id:297288)中的标准[欧几里得距离](@article_id:304420)并*不*对应于这个物理范数。

一种更巧妙的表示法，称为 **Mandel 表示法**，几乎与前者相同，但将非对角线（剪切）分量乘以一个因子 $\sqrt{2}$。为什么？因为这个简单的技巧确保了 Mandel 向量的欧几里得范数的平方*完全等于*[张量](@article_id:321604)的 Frobenius 范数的平方。它保留了[张量](@article_id:321604)空间的几何结构。当神经网络使用标准[欧几里得度量](@article_id:307612)计算其损失时，使用 Mandel 表示法的模型实际上是在使用比使用 Voigt 表示法更有物理意义的误差度量。一个看似微小的表示选择，却直接关系到底层的能量物理学 [@problem_id:2898837]。

### 从原理到预测

数据驱动[本构建模](@article_id:362678)的故事，就是机器学习无限的灵活性与物理学严谨、优美的约束之间美妙相互作用的故事。我们可以通过模型的架构或通过惩罚项来强制执行对称性，从而引导我们的模型 [@problem_id:2898846]。我们可以从一开始就用正确的“乐高积木”来构建我们的模型，例如，通过创建一个基于[应变不变量](@article_id:369570)的函数库，这些函数自动满足各向同性，然后让[算法](@article_id:331821)找到正确的组合 [@problem_id:2656022]。

也许最全面的愿景是将学习过程与力学的宏大[变分原理](@article_id:324104)结合起来。我们不只是匹配应力-应变数据点，而是可以构想一个目标，即我们寻求一个材料定律 $\psi_\theta$，当它被代入一个结构的完整仿真时，该结构的总势能被最小化 [@problem_id:2898847]。学习问题本身就变成了在系统层面寻找一个满足自然基本定律的法则的问题。

最终，构建这些模型只是战斗的一半。我们还必须无情地测试它们。我们必须区分**验证**（“我们是否正确地构建了模型？”）和**确认**（“我们是否构建了正确的模型？”） [@problem_id:2898917]。验证涉及检查我们的代码，确保我们的[算法](@article_id:331821)正确收敛，并通过数值健全性检查。确认意味着将我们模型的预测与新的实验数据进行比较，并证实它遵守了我们讨论过的所有物理定律。最后，整个过程必须被一丝不苟地记录和控制——从数据的确切版本到训练中使用的随机种子——以确保我们的结果能被其他科学家**复现** [@problem_id:2898881]。只有通过这种创造性建模、深刻物理洞察和不妥协的科学严谨性的结合，我们才能构建出不仅强大而且值得信赖的新工具。