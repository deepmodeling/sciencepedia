## 引言
在一个充斥着复杂数据的世界里，从错综复杂的蛋白质相互作用网络到浩瀚的互联网文本海洋，一个根本性的挑战始终存在：我们如何教会计算机理解“关联性”这一概念？我们如何量化一只猫比一辆汽车更像一只狗，或者两个没有直接相互作用的蛋白质却执行着相似的功能？答案在于一个强大而优雅的概念，它位于现代人工智能的核心：[嵌入](@article_id:311541)（embedding）。[嵌入](@article_id:311541)是一种[表示学习](@article_id:638732)的形式，它将抽象的关系转化为具体的几何语言，为每个对象分配一个数值向量——即高维空间中的一个坐标。本文深入探讨了使[嵌入](@article_id:311541)发挥作用的基础思想。第一章“原理与机制”将揭示用于构建这些几何地图的核心技术，例如从对象的局部上下文中学习以及主动塑造空间以强制实现相似性。随后，“应用与[交叉](@article_id:315017)学科联系”一章将带领读者穿越各个科学领域，见证这个通用翻译器如何彻底改变从生物学到经济学等领域的研究。

## 原理与机制

想象一下，你试图整理一个巨大的图书馆，不是按字母顺序，而是按书籍中的思想内容。关于量子物理学的书会聚集在一起，历史小说会形成自己的区域，或许，在它们之间，你会找到生活在历史剧变时期的物理学家的传记。书籍的空间布局本身就成了一张知识地图。这就是**[嵌入](@article_id:311541)**背后的核心思想：将“关联性”这一抽象概念转化为具体的几何语言。[嵌入](@article_id:311541)是一个数字向量——一个坐标——它为每个对象（无论是一个词、一个基因，还是一个完整的分子）在高维“地图空间”中分配一个特定的位置。这个思想的力量源于一个单一而优雅的目标：[排列](@article_id:296886)这些点，使它们在地图中的距离能够反映它们在现实世界中的相似性。

### 邻域原则：观其友，知其人

我们如何决定在这个地图上放置一个对象的位置？[现代机器学习](@article_id:641462)中最直观、最强大的思想之一是，一个对象的意义由其上下文或其邻居来定义。想想你自己在社交网络中的位置。你的身份由你的直接朋友塑造，也由你朋友的朋友等等塑造。你在社会结构中的独特定位正是这整个关系网络的结果。

[图神经网络](@article_id:297304)（GNNs）正是利用这种逻辑为网络中的节点（例如[蛋白质-蛋白质相互作用网络](@article_id:334970)中的蛋白质）构建[嵌入](@article_id:311541)。这个过程被称为**邻域聚合**，是迭代进行的。在第一步中，给定蛋白质的[嵌入](@article_id:311541)通过对其直接相互作用伙伴的初始特征进行平均来更新。在第二步中，这个新的[嵌入](@article_id:311541)再次通过对其邻居的[嵌入](@article_id:311541)进行平均来更新，而这些邻居的[嵌入](@article_id:311541)现在包含了来自*它们*邻居的信息。经过几轮（“跳”）这样的信息传递后，一个蛋白质的最终[嵌入](@article_id:311541)向量就成了一个关于其独特的局部网络环境的丰富、压缩的摘要。[@problem_id:1436666]

这种机制带来一个引人入胜且深刻的结果：两个没有直接相互作用但共享非常相似的相互作用伙伴（以及伙伴的伙伴）的蛋白质，最终会得到几乎相同的[嵌入](@article_id:311541)向量。GNN仅仅通过观察网络的连接图，就学会了这两个蛋白质扮演着相似的*结构角色*——就像一家大公司里两个互不相识但职位相同的人，因为他们向相似的经理汇报，并管理着相似的团队。[@problem_id:1436693]

### 学习生命语言

这个“邻域”原则不仅限于显式网络。它可以应用于任何顺序和邻近性很重要的序列，从书中的句子到蛋白质链中的氨基酸。语言学家 J.R. Firth 有句名言：“观其伴，知其义。”（You shall know a word by the company it keeps.）这是学习从大量原始、无标签的文本或[序列数据](@article_id:640675)中获取[嵌入](@article_id:311541)的一类[算法](@article_id:331821)的基础思想。

像 **Skip-Gram** 和 **连续[词袋模型](@article_id:640022)（CBOW）** 这样的模型，是在一个简单的自监督任务上进行训练的。对于[蛋白质序列](@article_id:364232)中的每一个氨基酸，模型被要求要么预测其相邻的氨基酸（即其“上下文”），要么反过来，根据上下文预测该氨基酸。[@problem_id:2373389] 这里没有标签，没有预定义的化学性质。模型通过在数百万个序列上反复玩这个预测游戏来学习。

其魔力在于其副作用。为了在这个游戏中表现出色，模型必须为20种氨基酸中的每一种创建一个内部的数值表示——即[嵌入](@article_id:311541)。这个[嵌入](@article_id:311541)必须包含预测附近可能出现哪些其他氨基酸所需的信息。结果，那些倾向于出现在相似化学或结构环境中的氨基酸（例如，在蛋白质的疏水核心中，或在表面的柔性环上）自然会被分配到在高维地图空间中彼此靠近的[嵌入](@article_id:311541)。在没有被教授任何生物学知识的情况下，模型纯粹从共现统计中学会了生命语言的“语法”。

### 塑造空间：[度量学习](@article_id:641198)的艺术

有时，我们需要更明确地教导模型“相似”意味着什么。想象一下，你想创建一张动物地图，其中不同种类的猫彼此靠近，但都与狗相距甚远。仅仅从共现中学习可能还不够。我们需要一种方法来主动塑造我们[嵌入空间](@article_id:641450)的几何形状。

这是**[度量学习](@article_id:641198)**的任务，其最优雅的工具之一是**三元组边距损失**。[@problem_id:65950] 这个过程非常直观。我们为模型提供一个由“三元组”组成的样本：一个“锚点”（anchor，例如某个特定激[酶蛋白](@article_id:357079)的[嵌入](@article_id:311541)），一个“正例”（positive，另一个相关激酶的[嵌入](@article_id:311541)），以及一个“负例”（negative，一个功能不相关的蛋白质，如胶原蛋白分子的[嵌入](@article_id:311541)）。[损失函数](@article_id:638865)的目标是确保锚点与正例的距离比它与负例的距离更近。在数学上，它通过移动[嵌入](@article_id:311541)，直到平方距离 $d(z_a, z_p)$ 比 $d(z_a, z_n)$ 小至少一个固定的量，这个量被称为边距 $\alpha$。

从数学中得出的更新规则尤其具有启发性。当损失被激活时，关于锚点[嵌入](@article_id:311541)的梯度 $\nabla_{z_a} L$ 就是简单的 $2(z_n - z_p)$。这个向量从正例[嵌入](@article_id:311541)指向负例[嵌入](@article_id:311541)。更新规则将锚点向梯度的*相反*方向移动，因此会将锚点[嵌入](@article_id:311541) $z_a$ 推离负例 $z_n$，并拉向正例 $z_p$。这完美地将“拉近朋友，推开敌人”的指令翻译成了数学语言。这一原理是驱动**孪生网络 (Siamese networks)** 的引擎，该网络使用两个相同且[参数共享](@article_id:638451)的编码器，将两个不同的蛋白质映射到这个精心塑造的空间中，使我们能够简单地通过测量它们之间的距离来确定其相似性。[@problem_id:2373375]

### 表示的物理学：[嵌入](@article_id:311541)与对称性

随着我们深入探讨，一个更基本的问题出现了：一个好的[嵌入](@article_id:311541)*应该*具备哪些属性？答案将计算机科学的这个抽象角落与具体的物理定律联系起来。一个真正鲁棒的[嵌入](@article_id:311541)必须尊重其所表示对象的基本**对称性**。[@problem_id:2749074]

考虑一个三维分子的[嵌入](@article_id:311541)。分子的内在属性，比如它的总能量，不会因为你旋转它或在空间中移动它而改变。因此，一个好的分子[嵌入](@article_id:311541)应该对这些变换（形式上，对[特殊欧几里得群](@article_id:299831) $SE(3)$ 的操作）是**不变的**。如果在计算机中旋转分子会改变其[嵌入](@article_id:311541)，那么这个[嵌入](@article_id:311541)就是有缺陷的，因为它编码的是一个任意的人为产物——分子的朝向——而不是其内在特性。

但对称性也告诉我们什么*不*该做。生物学中的许多分子是**手性的**（chiral），意味着它们与自己的镜像并非完全相同，就像你的左手和右手并不相同一样。例如，蛋白质是由L-氨基酸而非其[D-氨基酸](@article_id:377536)镜像异构体构成的。镜像反射将L-氨基酸转化为[D-氨基酸](@article_id:377536)，这在生物学背景下是完全不同的化学实体。因此，[嵌入](@article_id:311541)*绝不能*对镜像反射保持不变。它必须能够区分一个分子和它的镜像异构体。

同样，对于蛋白质序列，氨基酸的顺序定义了蛋白质。二肽丙氨酸-甘氨酸与[甘氨酸](@article_id:355497)-丙氨酸是不同的分子。因此，序列表示必须对其元素的顺序敏感，并且*不能*对[排列](@article_id:296886)保持不变。设计一个好的[嵌入](@article_id:311541)不仅仅是编写代码；它关乎正确识别并编码支配该系统的物理和化学定律。

### 一点提醒：规避陷阱

尽管[嵌入](@article_id:311541)功能强大，但它们并非魔法。了解它们的局限性与欣赏它们的优点同样重要。

首先，是**[过度平滑](@article_id:638645)**的问题。在深度GNN中，信息经过许多步的聚合，不断的平均会冲淡关键的局部细节。这就像一个谣言在广大的人群中传播；当它传到另一端时，尖锐的细节已经消失，每个人听到的都是相同模糊、被平均化的版本。一个层数过多的GNN可能会使得一个高度特化的激酶（其功能依赖于少数几个关键邻居）和一个全局[转录因子](@article_id:298309)（其整合来自整个网络的信号）的[嵌入](@article_id:311541)变得几乎无法区分，因为它们的[感受野](@article_id:640466)已经扩展到覆盖了网络中相同的一大片区域。[@problem_id:1436663] 最有效的解决方案非常直接：与其只使用最终的、[过度平滑](@article_id:638645)的[嵌入](@article_id:311541)，我们可以结合*所有*中间层的[嵌入](@article_id:311541)，以确保局部和全局信息都得以保留。

其次，是可视化的**平地错觉**。我们的大脑不善于理解1000维的空间，因此我们使用像UMAP和[t-SNE](@article_id:340240)这样的[算法](@article_id:331821)将我们的[嵌入](@article_id:311541)投影到我们可以看到的二维图上。这些图非常有用，但它们也是骗子。就像墨卡托投影的地球仪让格陵兰岛看起来比非洲还大一样，这些[算法](@article_id:331821)以严重扭曲全局距离和角度为代价来保留局部邻域。在二维UMAP图上，一个代表分化细胞“速度”的箭头可能看起来指向一个方向，而在真实的、高维的基因表达空间中，该细胞实际上正朝着一个完全不同的方向移动。[@problem_id:2427349] 其数学原因是，这个由局部**[雅可比矩阵](@article_id:303923)（Jacobian matrix）**定义的投影是一个非线性变换，它可以在地图上的每一点以不同的方式拉伸、收缩和旋转向量。我们必须永远记住，地图并非疆域。美丽的二维图像只是一个更丰富、更高维现实的扭曲投影。