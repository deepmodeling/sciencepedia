## 应用与跨学科联系

掌握了并发和并行之间的本质区别后，我们现在可以开始一段旅程，去看看这些概念在实际中的应用。你会发现这不仅仅是一项学术活动；这些思想正是数字世界的构建师。它们决定了你笔记本电脑的速度，互联网的响应能力，以及解码宇宙奥秘的超级计算机的力量。物理学的美在于少数几个基本原理如何能解释广泛的现象，这里也是如此。我们即将看到，交错执行和同时执行之间的简单舞蹈如何塑造了我们使用的几乎每一项技术。

### 机器的核心：[操作系统](@entry_id:752937)

让我们从最中心的地方开始：[操作系统](@entry_id:752937)（OS），这个管理着机器所有资源的幽灵。其最关键的工作之一是调度——决定众多竞争任务中哪一个可以使用处理器。

想象一个农场上的一台水泵，必须灌溉几块田地。这是一个完美的类比，单核处理器是泵，许多程序是田地。水泵一次只能给一块田地浇水，但通过在它们之间切换，它可以让所有田地都取得进展。这是最纯粹形式的并发。农场经理必须决定一个时间片$\Delta$，即在切换前给每块田地浇水多长时间。如果$\Delta$非常大，水泵效率很高，因为它大部[分时](@entry_id:274419)间都在抽水，很少时间花在切换的开销上。但这意味着一些田地可能要等很长时间才能得到第一滴水！相反，一个非常小的$\Delta$让系统感觉响应迅速——每块田地都很快得到水——但如此多的时间浪费在切换上，以至于输送的水的总[吞吐量](@entry_id:271802)急剧下降。这是每个OS设计者都面临的吞吐量和延迟之间的基本权衡。通过增加第二台水泵，农场可以同时为两块田地浇水——这是真正的并行，它从根本上增加了系统的容量。[@problem_id:3627014]

但是OS如何决定接下来运行哪个任务，特别是当一些任务比其他任务更重要时？考虑一个紧急调度中心，它有有限数量的救护车（并行单元）和并发涌入的严重程度不同的来电。一个简单的规则——“总是派往最严重的呼叫”——似乎合乎逻辑。但如果心脏病发作的电话不断打来，一个断腿的电话会怎样？断腿的呼叫可能永远等待，这种现象称为饿死。一个优美而简单的解决方案，被用于许多[实时操作系统](@entry_id:754133)中，是“老化”。当一个任务等待时，它的优先级会慢慢增加。最终，即使是优先级最低的任务也会因为等待了太长时间，其优先级会上升到超过所有其他任务，从而保证它最终会被服务。这个优雅的机制确保了公平性并防止了饿死，这是可靠系统的一个关键属性。[@problem_id:3627044]

这种设计理念深入到OS的内部。当一个程序中的多个线程都需要向OS请求内存时，一个天真的设计可能会用一个单一的全局锁来保护[内存分配](@entry_id:634722)器的[数据结构](@entry_id:262134)。在多核机器上，这是一场灾难！即使有8个或16个核心准备工作，一次也只有一个核心可以分配内存；其他核心则在空闲等待。并行的硬件被一个软件瓶颈搞得毫无用处。解决方案是从一个集中的、并发的模型转向一个分散的、并行的模型。高性能分配器给每个线程一小块私有的内存块缓存。大多数时候，线程可以从它们的本地缓存中获取内存而无需等待。只有当缓存用尽时，它们才需要去全局分配器那里批量补充。这极大地减少了对全局锁的争用，释放了并行硬件的力量。[@problem_id:3627017]

### 构建并运行我们的数字世界

并发和并行的原则对于运行在OS之上的软件同样至关重要。想一想从源代码构建一个大型应用程序的过程，这是软件开发人员每天都要做的一项任务。第一步，编译数千个独立的文件，是“易于并行”的——我们可以投入几十个[CPU核心](@entry_id:748005)来处理它，它会更快完成。但最后一步，将所有编译好的部分链接成一个单一的可执行文件，通常是一个固有的串行任务。无论你有多少核心，总的构建时间将永远受限于那一个最终的、顺序步骤的速度。这是[阿姆达尔定律](@entry_id:137397)的一个深刻而实际的展示：一个程序的加速比最终受限于其串行部分。[@problem_id:3627020]

我们在[文件系统](@entry_id:749324)和数据库中也看到了同样的模式。为了防止因崩溃而导致数据丢失，许多系统使用日志记录：在更改数据之前，它们首先将关于预期更改的说明写入日志或“journal”。将这个journal提交到磁盘的行为通常是一个串行瓶颈，因为每次提交都有固定的开销。一个提高性能的巧妙技巧是批处理。系统不是单独提交每一个微小的写入，而是收集一批写入并一次性提交它们。这将固定开销分摊到许多操作上，从而显著提高[吞吐量](@entry_id:271802)。代价是什么？延迟。你个人的写入现在必须等待批次的其他部分组装完毕才能被保存，这是我们一次又一次遇到的经典权衡。[@problem_id:3627008]

有时，这些串行瓶颈并非问题所固有，而是我们自己软件设计的产物。想象两个程序更新一个共享的日志文件。如果我们使用一个保护整个文件的单一、“粗粒度”锁，那么一次只有一个程序可以写入，即使它们正在写入文件的完全不同部分！我们创造了一个本不该存在的瓶颈。解决方案是使用“细粒度”锁定，其中锁只保护正在被修改的特定记录或区域。这允许两个程序同时写入文件的不同部分，将人为的并发转变为真正的并行。[@problem_id:3627070]

### 宏大尺度：从云到宇宙

再放大来看，同样的原则也支配着地球上最大型计算机系统的行为。现代云应用由许多小的、独立的“[微服务](@entry_id:751978)”构建而成。考虑一个请求流经前端服务、中间服务再到后端服务的管道。每个服务都有一定数量的副本，这决定了其并行处理能力。如果流量激增超出了中间服务的能力，请求队列就开始形成。这不仅增加了延迟，还对前端施加了“背压”，而前端本身可能对其可以“在途”处理的请求数量有并发限制。理解这种相互作用——在系统中流动的请求的并发性与服务的并行能力之间——是构建可扩展、有弹性的分布式系统，使其在压力下不会崩溃的关键。[@problem_id:3627051]

在高性能计算（HPC）领域，这些思想被推向了它们的绝对极限。在一个大规模的金融模拟中，你可能会并行运行数百万个独立的[蒙特卡洛](@entry_id:144354)路径。最后一步是聚合结果——例如，通过将它们求和。天真的方法是，成千上万的核心中的每一个都获取一个锁来将其结果添加到一个单一的全局总和中，这会造成巨大的交通堵塞。一种优越得多的方法是并行树归约。核心被配对起来对它们的本地结果求和。然后，这些结果对再被求和，依此类推，直到最终的总和在与核心数量的对数成正比的步数内计算出来。这是一个完全避免了串行瓶颈的优美算法。[@problem_id:3627052]

对于真正复杂的问题，比如模拟飞机机翼的[流体动力学](@entry_id:136788)，科学家现在使用[性能可移植性](@entry_id:753342)框架。这些是编程模型，允许他们为其[并行算法](@entry_id:271337)编写单一的、抽象的描述。然后，一个复杂的编译器将这个抽象描述翻译成针对不同类型并行硬件的高度优化代码——无论是一个拥有少数强大核心的CPU，还是一个拥有数千个较简单核心的GPU。这可能涉及自动改变内存中的数据布局或填充数据结构，以确保内存访问针对特定架构是完美“合并”的，这证明了抽象算法与物理硬件之间深刻而复杂的联系。[@problem_id:3287354]

### 超越核心：并行的物理极限

最后，令人谦卑的是，要记住并行不仅仅是计算机科学的一个抽象概念，它从根本上受到物理定律的约束。我们可能想象一个拥有$N$个核心的处理器给了我们$N$路并行。但考虑一个功率预算至上的深空探测器。每个活动的[CPU核心](@entry_id:748005)都从[太阳能电池](@entry_id:138078)板或放射性同位素[发电机](@entry_id:270416)中消耗宝贵的瓦特。系统可能有12个物理核心，但如果[瞬时功率](@entry_id:174754)预算只允许5个同时活动，那么系统的真正并行度就被限制在5，无论芯片上蚀刻了多少核心。即使有8个重要任务要运行，OS也必须在5个可用的“功率插槽”上并发地调度它们。这是一个惊人的提醒，我们的数字机器是物理对象，它们的最终性能受能量和热量等资源支配，而不仅仅是逻辑门和[时钟周期](@entry_id:165839)。[@problem_id:3627000]

从在单个核心上调度任务到协调全球服务器网络，并发和并行之间的对话无处不在。它存在于吞吐量和延迟之间的权衡中，存在于与饿死和瓶颈的斗争中，也存在于设计能够利用并行硬件力量的软件的持续努力中。理解这场对话，就是理解使我们的现代世界成为可能的无形工程。