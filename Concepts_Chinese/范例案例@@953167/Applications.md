## 应用与跨学科联系

如果说上一章是关于学习制图学原理——如何绘制道德推理的地图——那么本章就是关于探索本身的冒险。地图是美丽而优雅的，但其真正目的只有在用于穿越真实、险恶且往往未知的地形时才能显现。我们已经看到范例案例如何在我们伦理地图上充当必不可少的地标和地形特征。现在，我们将看到这种被称为决疑论的推理方法，如何成为临床医生、政策制定者、律师甚至人工智能架构师手中可靠的指南针。这将是一段旅程，带我们从医院床边的宁静私密，走向公共政策的复杂机器，再到21世纪的数字前沿。

### 临床医生的伴侣：穿行于床边的迷宫

对实践智慧的需求，没有哪里比日常医疗实践中更为迫切。像“不伤害”这样的抽象原则是北极星，但它们并不能告诉你如何穿越特定患者生命中曲折狭窄的通道。正是在这里，范例案例成为不可或缺的伴侣。

思考一下医生的保密责任，这是医学伦理的基石。它不是一条绝对的规则。但何时可以打破它？面临这一困境的医生不会凭空创造答案。相反，她会查阅一个由清晰案例组成的心理图书馆。有疑似虐待儿童的范例，在这种情况下，向保护服务机构报告的法律和道德责任是明确的。有患有活动性肺结核患者的范例，此时保护公众健康的责任至高无上。还有患者对特定人士做出直接、可信的伤害威胁的范例，此时可能会产生警告责任。与这些相对的是，一个病人承认了过去不检点的行为但不会造成持续风险的范例，在这种情况下，保密是理应绝对的。

当一个不确定的新案例出现时——比如说，一个患有不受控制的癫痫症的商业巴士司机，坚持下周要开车——临床医生会将其置于这个道德图景中 [@problem_id:4880679]。这个案例与任何单一范例都不完全相同，但通过分析其特征——潜在伤害的严重性、其紧迫性、受风险者身份的可识别性——可以清楚地看到，它与公共卫生和警告责任范例的共同点，多于与绝对隐私范例的共同点。适当的途径不是大声宣扬，而是向唯一能够减轻伤害的权威机构——机动车牌照管理机构——进行最低限度的、有针对性的披露。范例并没有提供一键式的答案，但它们照亮了道路并为选择提供了理由。

这种方法也揭示了法律与伦理之间关键且有时令人惊讶的差距。想象一位职业小提琴家，她的生计依赖于手指的精妙敏感度。她接受了一项常见的择期手术，但没有被告知存在一种罕见的、$1\%$ 的轻微感觉障碍风险——这个风险对大多数人来说只是小麻烦，但对她来说却是职业生涯的终结 [@problem_id:4851467]。在一个法律责任基于医生 *通常* 披露内容的司法管辖区，外科医生可能没有违反任何法律。然而，我们的伦理指南针告诉我们有些不对劲。通过将其与一个范例案例——比如一位接受眼科手术的职业画家，没有被告知有$0.1\%$的[色彩感知](@entry_id:171832)改变风险——进行比较，我们看到了核心问题。伦理责任不仅仅是背诵一份标准的风险清单，而是要理解你面前这个人的特定价值观和脆弱性。对于小提琴家和画家来说，“微小”的风险实际上是灾难性的。这种类比阐明了一条深刻的伦理准则：真正尊重一个人的自主性，需要根据对 *他们* 而言重要的内容来调整对话。法律可能沉默，但伦理言之凿凿。

通过收集和分析这类案例，临床医生和机构可以为反复出现的困境建立完整的框架。例如，在青少年医学中，一个范例分类体系——从低风险、保密的避孕要求到涉及可信自杀计划的高风险情况——可以帮助提供者在青少年的隐私需求与安全和父母参与的责任之间找到微妙的平衡 [@problem_id:4851486]。这不是一个僵化的流程图，而是一个结构化的推理指南，它在促进一致性的同时，对每个年轻人情况的独特性保持敏感。

### 委员会与准则：铸就共识与政策

案例推理的力量超越了个体决策者。对于那些在面对深刻伦理冲突时，负责铸就共识或制定政策的团体、委员会和机构来说，它是一个强大的工具。

考虑一个临床伦理委员会（CEC）被召集来解决一个令人心碎的生命末期纠纷 [@problem_id:4884614]。一个家庭意见[分歧](@entry_id:193119)，临床医生心烦意乱，前方的道路被悲伤和不确定性所笼罩。委员会的角色不是强加一个裁决，而是促进一种共同的理解。他们通过借鉴自己的案例库来做到这一点。他们可能会将当前情况与两个有力的范例进行对比。一方面，是“生理无效”的案例，即提议的治疗根本无法实现其生物学目标，比如为患有无脑畸形的婴儿使用机械通气。在这种情况下，职业诚信要求不提供这种无益的干预。另一方面，是“不确定性”的范例，即患者病危但有一条通往有意义康复的合理（尽管狭窄）的道路。在这里，限时尝试重症监护通常是最合乎伦理的方法。

通过将这个新的、困难的案例与这两个地标进行比较，CEC可以帮助所有相关人员更清晰地看清其轮廓。这种情况是更像希望渺茫的那一个，还是像有理由进行谨慎限时尝试的那一个？这种类比推理将一场意志之战转变为一场共同寻求最恰当伦理回应的探索。

这种方法可以进一步扩展，从解决单个案例到为数百万人制定公共政策。在大流行期间，一个社会应如何分配像呼吸机这样稀缺的救生资源？有人可能提出“功利优先”规则：总是把呼吸机给生存机会最大的人。另一个人可能主张“最差者优先”规则：总是把它给病情最重的人。决疑论提供了一种方法来对这些抽象原则进行具体现实的压力测试 [@problem_id:4851506]。

我们可以构建一系列测试案例。在一个案例中，我们必须在一个生存机会为$10\%$的患者和一个生存机会为$70\%$的患者之间做出选择。“功利优先”规则在这里似乎很有说服力；反其道而行之感觉就像浪费宝贵的资源。但第二个案例呢？我们必须在一个来自弱势背景、生存机会为$55\%$的患者和一个来自优越背景、生存机会为$60\%$的患者之间做出选择。在这里，功利上的微小收益似乎被我们对公正和公平的承诺所压倒。通过让这些相互竞争的准则经受一系列精心选择的范例的考验，它们的弱点暴露无遗。纯粹的功利或纯粹的优先都不能完美运作。这个过程迫使我们综合出一个更复杂、混合的规则：一个通常寻求最大化效益，但受到最低有效性底线和在结果差异较小时对最差者的特别关注所约束的规则。范例案例不仅帮助分类情况，它们还帮助我们 *构建了一个更好的规则*。

### 机器中的幽灵：驯服人工智能的伦理

这似乎与古希腊和罗马的道德学家相去甚远，但同样是这种案例推理的方法，在应对我们这个时代的决定性技术——人工智能——时，正被证明是不可或缺的。随着我们越来越多地将复杂的决策委托给算法，我们必须找到确保它们合乎伦理地运行的方法。决疑论提供了这些工具。

想象一下，一家医院部署了一个人工智能工具来帮助分配稀缺的ICU床位。该工具旨在最大化生存率，但一次审计揭示了一个可怕的模式：它系统性地为非英语患者分配较低的优先级，并非出于恶意，而是因为他们的电子健康记录往往不够详细，导致算法低估了他们的康复机会 [@problem_id:4410953]。我们如何诊断这种伦理失误？我们可以求助于我们的范例。这主要是一个不可避免的分诊案例，一种疏忽的形式，还是别的什么？通过将其与“差异性影响”的经典法律和伦理范例——即一个看似中立的规则系统性地使特定群体处于不利地位——进行比较，我们可以为这种不公正命名。主要的道德伤害不是做出了选择，而是选择的体系根本上不公平。决疑论为我们提供了诊断算法伦理病理的语言。

更强大的是，决疑论可以帮助我们从头开始构建合乎伦理的人工智能。这个过程被称为 **规范化**（specification）：将像“不伤害”这样模糊、高层次的原则转化为精确、可操作的代码行的关键任务 [@problem_id:4410990]。假设工程师们正在构建一个用于检测败血症早期迹象的人工智能。该AI会产生一个风险评分。分数达到多少时应该向医疗团队发出紧急警报？如果阈值设得太低，你会造成“警报疲劳”，即大量的错误警报导致临床医生忽略真实的警报。如果设得太高，你又会错过需要帮助的患者。

你如何找到最佳点？你使用决疑论。设计团队会检查一个范例案例库：警报明确挽救了生命的案例，警报明显是分散注意力的噪音的案例，以及介于两者之间的模糊案例。通过分析这些案例的特征并进行类比推理，他们可以迭代地完善并论证一个特定的阈值。他们不仅仅是在优化一条统计曲线，而是在将一系列理性的伦理判断嵌入到机器的逻辑本身之中。

### 实践智慧的严谨性

正如我们的旅程所示，范例案例的应用并非是对直觉的无纪律诉求。它是一种结构化且严谨的推理形式。一个站得住脚的决疑论判断不是脆弱的；它必须是稳健的。使用这种方法的伦理学家通常会故意对他们的结论进行“压力测试” [@problem_id:4851521]。他们会问：如果我们改变一个关键事实，结论还成立吗？当面对一个原则相互冲突的对抗性案例时，它的表现如何？这个过程确保最终的判断不是偶然情况的产物，而是一块有韧性的实践智慧。

从医生与忧心忡忡的青少年的悄声交谈 [@problem_id:4851486]，到关于大流行分诊的公开辩论，再到医疗人工智能的代码审查，其基本的推理模式是相同的。这证明了一个简单思想的持久力量：即导航未来的最可靠方式，是从我们积累经验的地标出发进行审慎推理。案例在变，技术在发展，但人类对明智和富有同情心的判断的追求依然存在。