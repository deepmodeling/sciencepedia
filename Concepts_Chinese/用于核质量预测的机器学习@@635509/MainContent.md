## 引言
预测[原子核](@entry_id:167902)的质量是[核物理](@entry_id:136661)学中的一个根本性挑战，它对理解恒星演化和元素起源具有深远影响。虽然理论模型为这种预测提供了框架，但它们往往难以在整个[核物理](@entry_id:136661)版图上达到高精度。相反，纯粹由数据驱动的机器学习模型可能像“黑盒”一样，在实现高精度的同时却无法提供物理洞见。本文旨在弥合这两种方法之间的知识鸿沟，探讨如何构建智能的“玻璃盒”模型，将机器学习的预测能力与物理学的解释能力融为一体。

本文将引导您了解这一跨学科领域的原理和应用。在“原理与机制”部分，我们将深入探讨构建物理知识启发模型的核心概念，从设计尊重[基本对称性](@entry_id:161256)的特征到量化预测的不确定性。随后，“应用与跨学科联系”部分将展示这些复杂的模型如何转变为强大的科学仪器，用于评估实验数据、指导寻找新[原子核](@entry_id:167902)，并加深我们对核力的理解。我们首先从探索如何构建一个融合了物理原理的机器学习模型开始。

## 原理与机制

想象一下，你想盖一栋房子。理论上，你可以随机堆砌砖块，然后期待最好的结果。只要有足够的时间和砖块，你或许能偶然创造出某个有点像住所的东西。这是对机器学习的一种讽刺性描绘：一个在不理解的情况下寻找模式的“黑盒”。然而，科学的方法，就像一位优秀建筑师的方法一样，是不同的。建筑师理解重力、应力和材料的原理。他们运用这些原理来设计一个不仅功能齐全，而且优雅而坚固的结构。

我们的任务与此非常相似。我们希望根据[原子核](@entry_id:167902)所含质子数 ($Z$) 和中子数 ($N$) 来预测它的一个基本属性——[结合能](@entry_id:143405)，即将其维系在一起的“胶水”。我们不会随意堆砌数据砖块，而是像建筑师一样，将物理学原理注入我们的[机器学习模型](@entry_id:262335)中。我们将构建一个“玻璃盒”，其内部结构反映物理定律，在此过程中，我们将看到机器学习如何成为一种强大的新型科学探究工具。

### 从完美宇宙中学习

让我们从一个思想实验开始。假如我们生活在一个“完美”的宇宙中，每个[原子核](@entry_id:167902)的[结合能](@entry_id:143405)都可以用一个已知的简单公式精确描述，那会怎样？一个优美且非常成功的公式就是**[半经验质量公式](@entry_id:155138) (SEMF)**，即[液滴模型](@entry_id:751355)。它将[原子核](@entry_id:167902)视为一个微小的液滴，[结合能](@entry_id:143405)源于几个简单直观的项：

-   **体积项** ($a_v A$)，表示[核子](@entry_id:158389)越多 ($A = Z+N$)，形成的键就越多。
-   **表面项** ($-a_s A^{2/3}$)，修正了表面[核子](@entry_id:158389)邻居较少的事实，就像水滴表面的分子一样。
-   **库仑项** ($-a_c \frac{Z(Z-1)}{A^{1/3}}$)，解释了带正电的质子之间的[静电排斥](@entry_id:162128)，这种排斥力试图使[原子核](@entry_id:167902)分裂。
-   **不对称项** ($-a_a \frac{(N-Z)^2}{A}$)，捕捉了一种量子力学效应：当质子和中子数量相近时，[原子核](@entry_id:167902)最稳定。
-   **对偶项** ($\delta(A,Z,N)$)，解释了质子和中子倾向于形成对的现象。

现在，让我们提出一个问题：如果我们使用这个精确公式生成一个包含 $(Z, N)$ 对及其相应[结合能](@entry_id:143405)的完美数据集，机器学习模型能“发现”这个公式吗？[@problem_id:2410513]

如果我们只给模型输入原始数字 $Z$ 和 $N$，它可能会举步维艰。这就像只给它一串半径和面积的列表，就让它发现圆面积的公式一样。但如果我们更聪明一点呢？如果我们不只提供 $(Z,N)$，而是给模型一组**物理知识启发的特征**呢？我们可以自己计算[液滴模型](@entry_id:751355)各项的数学形式——$A$, $A^{2/3}$, $\frac{Z(Z-1)}{A^{1/3}}$ 等——然后让模型找到组合它们的最佳方式。

当我们这样做时，奇妙的事情发生了。一个简单的[线性回归](@entry_id:142318)模型能够以惊人的精度学习到 SEMF 的系数 ($a_v, a_s, \dots$)。模型不仅仅是记住了数据；它学习到了物理定律的底层结构。这是我们的第一个，也是最重要的教训：[机器学习模型](@entry_id:262335)在物理学中的表现，关键取决于其特征的质量。好的特征是那些能够编码好的物理规律的特征。

### [特征工程](@entry_id:174925)的艺术与科学

当然，现实世界比我们完美的[液滴模型](@entry_id:751355)要复杂得多。为了预测真实的实验质量，我们需要更进一步。这就是**[特征工程](@entry_id:174925)**——设计模型输入的过程——的用武之地。这个过程是物理学和计算机科学之间的一支精妙舞蹈。

例如，我们知道 $A = Z+N$。如果我们将三者（$Z$、$N$ 和 $A$）都作为特征输入到一个简单的[线性模型](@entry_id:178302)中，我们就会引入一种完美的[线性依赖](@entry_id:185830)关系，这种情况称为**多重共線性**。这会使模型感到困惑，无法确定 $Z$ 和 $N$ 对最终预测的独特贡献。这就像试图用一个方程解两个未知数一样。我们必须明智地选择特征，使其相互独立。[@problem_id:3568172]

此外，特征的函数形式也很重要。[不对称能](@entry_id:160056)取决于中子-质子不平衡度的平方，其标度关系为 $I^2$，其中 $I = (N-Z)/A$。如果我们只向线性模型提供 $I$ 作为特征，我们就是在要求它用一个线性函数来拟合一个二次定律。它会失败，不是因为模型不好，而是因为我们给了它错误的工具。我们必须给它特征 $I^2$，才能让它捕捉到正确的物理规律。[@problem_id:3568172]

这种思路引出了一个更深刻的想法：将[基本对称性](@entry_id:161256)构建到我们的模型中。产生大部分结合能的强核力在很大程度上对质子和中子之间的差异视而不见。这是**[同位旋对称性](@entry_id:146063)**的一种体现。因此，强核力对[原子核](@entry_id:167902) $(Z,N)$ 及其“镜像”[原子核](@entry_id:167902) $(N,Z)$ 的[结合能](@entry_id:143405)的贡献应该几乎相同。我们可以通过确保模型中代表[强核力](@entry_id:159198)的部分只使用在交换 $Z$ 和 $N$ 时保持对称的特征，例如[质量数](@entry_id:142580) $A=Z+N$ 或不对称度的平方 $(N-Z)^2$，来将这种对称性直接构建到模型中。[@problem_id:3568212]

当然，宇宙并非完全[同位旋](@entry_id:199830)对称。电磁力打破了这种对称性，因为质[子带](@entry_id:154462)电而中子不带电。这就是为什么[原子核](@entry_id:167902) $(Z,N)$ 的质量与 $(N,Z)$ 的质量*不*相同。我们可以通过向模型提供非对称特征，最显著的是代表[库仑排斥](@entry_id:181876)的特征（它仅依赖于 $Z$），来让模型学习这种**对称性破缺**。因此，一个真正复杂的模型架构可以分为一个学习[强核力](@entry_id:159198)贡献的对称[部分和](@entry_id:162077)一个学习库仑修正的非对称部分。模型的结构本身开始反映自然界的[基本对称性](@entry_id:161256)。

### 从不完美世界中学习

到目前-为止，我们都假设有一个完美的物理模型。实际上，我们最好的理论——即便是像密度泛函理论 (DFT) 这样复杂的理论——也存在误差。同时，我们的实验数据也并非完美；每一次测量都有其不确定性。我们如何最好地将一个强大但不完美的理论与充满噪声但真实的数据结合起来？

一个非常有效的策略是**[残差学习](@entry_id:634200)**。[@problem_id:3568197] 我们不要求[机器学习模型](@entry_id:262335)从头预测整个结合能，而是让它预测一个更小、更简单的量：我们最佳物理模型的*误差*。最终的预测变为：

$M_{predicted} = M_{physics\_theory} + g_{ML}(\text{features})$

在这里，$g_{ML}$ 是学习残差或修正的[机器学习模型](@entry_id:262335)。这种方法利用了两个世界的优势。我们依靠物理理论来捕捉现象的主体部分，并使用灵活的、数据驱动的机器学习模型来[学习理论](@entry_id:634752)出错的那些微妙且结构化的误差。

但数据中的噪声又该如何处理呢？在任何实验数据集中，比如原子质量评估（Atomic Mass Evaluation），一些核质量的精度非常高，而另一些（特别是对于奇特的、短寿命的[原子核](@entry_id:167902)）则有很大的不确定性。一个朴素的模型会同等对待所有这些数据点。但我们的物理直觉告诉我们，我们应该更多地关注高精度测量。

这种直觉可以通过**最大似然**原理来形式化。如果我们假设[实验误差](@entry_id:143154)是[高斯分布](@entry_id:154414)的，那么最大化观测到当前数据的概率等价于最小化一种特殊的误差函数：**逆[方差](@entry_id:200758)加权损失**。[@problem_id:3568161]

$\text{Loss} = \sum_{i} \frac{1}{\sigma_i^2} (y_i - \hat{y}_i)^2$

在这里，$y_i$ 是测量质量，$\hat{y}_i$ 是模型的预测值，而 $\sigma_i$ 是[原子核](@entry_id:167902) $i$ 的实验不确定性。每个平方误差都除以测量的[方差](@entry_id:200758)。这意味着不确定性小（精度高）的数据点对损失函数的贡献要大得多，从而迫使模型更紧密地拟合它们。不确定性大的数据点则被降权，模型不必太在意完美拟合它们。这是统计严谨性与实验现实的美妙结合。机器正在以一种有原则的方式，学习去相信我们拥有的最佳数据。

### [核物理](@entry_id:136661)版图的形状

当我们想到数据时，我们常常会想到一个整齐的表格或网格。像[卷积神经网络](@entry_id:178973)（CNN）这样以图像识别闻名的模型，在这样的规则网格上表现出色。但是[核素图](@entry_id:161758)——$(Z,N)$ 平面上所有已知[原子核](@entry_id:167902)的地图——并非一个整齐的矩形。它是一个锯齿状的半岛，其边界是“滴线”，在那里[原子核](@entry_id:167902)变得极其不稳定，会瞬间衰变。

如果我们试图将这种不规则形状强加于一个矩形网格以便使用 CNN，我们就必须为那些不存在的[原子核](@entry_id:167902)创造数据，这个过程称为填充（padding）。这在[核素图](@entry_id:161758)最关键、物理上最有趣的边界引入了虚假信息，不可避免地会使我们的模型产生偏差。[@problemid:3568201]

一个远为自然和优雅的表示方法是**图**。我们可以将每个存在的[原子核](@entry_id:167902)看作一个节点，并在它与其直接邻居——那些仅相差一个质子或一个中子的[原子核](@entry_id:167902)——之间画一条边。这种[图表示](@entry_id:273102)完美地捕捉了[核物理](@entry_id:136661)版图真实的、不规则的拓扑结构。通过使用专为图结构设计的模型，即**[图神经网络](@entry_id:136853)（GNN）**，我们可以让信息只在物理上存在的[原子核](@entry_id:167902)之间传播。模型从数据的真实结构中学习，尊重其自然边界。这是选择正确的数学结构以反映物理现实的典范。

### 确定性、怀疑与知识的边缘

一个没有不确定性声明的科学预测是毫无意义的。一个好的机器学习模型不仅应该给我们一个预测，还应该告诉我们它有多自信。我们的模型必须处理两种[基本类](@entry_id:158335)型的不确定性。[@problem_id:3568165]

1.  **[偶然不确定性](@entry_id:154011)**：这是系统中固有的随机性，任何模型都无法克服。在我们的例子中，它对应于实验[测量误差](@entry_id:270998)。这是世界的属性，而非模型的属性。

2.  **[认知不确定性](@entry_id:149866)**：这是模型由于其知识有限而产生的不确定性。它源于训练数据的数量有限。在[核素图](@entry_id:161758)中数据稀少或没有数据的区域，这种不确定性很高。

当我们在**外推**时——即当我们使用在已知稳定[原子核](@entry_id:167902)上训练的模型来预测靠近滴线的奇异、未知[原子核](@entry_id:167902)的性质时——这种区别至关重要。当我们的模型进入这些未探索的领域时，其[认知不确定性](@entry_id:149866)应该会急剧上升。一个构建良好的模型，特别是那种学习参数可能[分布](@entry_id:182848)而非单一最佳拟合的**贝叶斯**模型，会有效地举手示意：“警告：我现在处于一个我知之甚少的区域。我的预测高度不确定。” 这不是模型的失败，而是它的成功。它精确地告诉我们知识的终点在哪里，以及最需要进行新实验的地方在哪里。[@problem_id:3568221]

这也警示了我们[科学机器学习](@entry_id:145555)中最大的危险：**[模型设定错误](@entry_id:170325)偏差**。如果我们的模型的基础结构（其特征、其架构）从根本上无法描述奇异[原子核](@entry_id:167902)的物理性质，那么再多来自稳定区的数据也无法修复它。平均多个模型（一种称为套袋法（bagging）的技术）可以减少由于数据有限而产生的模型[方差](@entry_id:200758)，但它无法治愈其设计中根本性的偏差。[@problem_id:3568221]

### 打开玻璃盒

在完成了所有这些工作——设计尊重对称性的特征、构建学习残差的模型、根据[数据质量](@entry_id:185007)加权数据、以及[量化不确定性](@entry_id:272064)——之后，我们可能拥有了一个高精度的预测器。但它仅仅是一个复杂的黑盒，还是它学到了具有物理意义的东西？

这就是最后关键一步——**可解释性**——发挥作用的地方。使用像**SHAP（SHapley Additive exPlanations）**这样的技术，我们可以要求模型为其预测提供理由。[@problem_id:3568234] 对于任何给定的[原子核](@entry_id:167902)，我们可以将模型的预测分解为来自每个输入特征的加性贡献。我们可以问：“你对钙-54结合能的预测因为它是[幻数](@entry_id:154251)核而改变了多少？其中有多少是由于它的形变造成的？”

这些解释让我们能够打开模型，看看其内部的“推理”是否与物理原理一致。如果模型始终将壳层结构特征的重要性归因于幻数附近的[原子核](@entry_id:167902)，我们就能更有信心地认为它学到了正确的物理知识。有时，我们甚至可能发现模型以我们意想不到的方式重视某个特征，这可能为我们指明新的、尚未被发现的物理关联。

从一个重新发现教科书公式的简单线性模型，到一个能够告诉我们何时不确定的复杂图网络，构建用于核物理的机器学习模型的旅程本身就是科学过程的一个缩影。这是一个假说（特征设计）、实验（训练）和分析（解释）的循环，每一步都由物理原理引导。其结果不是物理学家的替代品，而是一种新型的合作者——一个能帮助我们探索[原子核](@entry_id:167902)广阔而复杂版图的合作者。

