## 引言
如何教会一个擅长语言的模型去理解一幅图画？Vision Transformer (ViT) 以一种[范式](@article_id:329204)转换的方法回答了这个问题，重新定义了[计算机视觉](@article_id:298749)领域。ViT 并非从零开始设计一个全新的[视觉系统](@article_id:311698)，而是巧妙地将图像转化为强大的 [Transformer](@article_id:334261) 架构能够理解的语言。这个简单而深刻的想法开启了前所未有的能力，超越了传统的卷积方法。本文将引导您深入了解 Vision Transformer 的内部工作原理。在第一章“原理与机制”中，我们将剖析其架构的核心组成部分——从图像分块和[位置编码](@article_id:639065)到关键的[自注意力机制](@article_id:642355)。随后，在“应用与跨学科联系”中，我们将探讨该模型的深远影响，追溯其从高级图像识别到在视频分析、[气候科学](@article_id:321461)乃至基础物理学中新颖应用的历程。让我们从揭示 ViT 如何学习图像语言开始吧。

## 原理与机制

想象一下，你是一位杰出的计算机科学家，刚刚发明了一台能够以无与伦比的技巧阅读和理解人类语言的革命性机器。它能翻译、总结，甚至写诗。现在，一位朋友向你挑战：“这太神奇了，但你能让它*看见*吗？”你会如何着手？你不会把原始图像文件直接扔给你的语言机器；你必须首先将图片翻译成它能理解的语言。这正是 Vision [Transformer](@article_id:334261) (ViT) 背后的基本思想。它不是要从零开始发明一种新的视觉方式，而是要教一位“阅读”专家——[Transformer](@article_id:334261)——图像的语言。让我们层层剥开，看看这个非凡的翻译过程是如何发生的。

### 从像素到词语：分块的艺术

对于计算机而言，图像是一个巨大的像素网格，一张典型的照片可能包含数百万个像素。而语言模型处理的则是一个由离散单元或“词元”（本质上就是词语）组成的序列。ViT 的第一步也是最关键的一步，就是将图像分解成一个可管理的词元序列。这个策略非常简单：我们将图像切成一个个较小的、不重叠的方块网格，就像把一张照片切成拼图一样。这些小方块中的每一个都称为一个**图像块 (patch)**。

一旦我们得到了图像块的集合，就需要将每个图像块转换成一个向量——即模型可以处理的数字列表。这被称为**图像块[嵌入](@article_id:311541) (patch embedding)**。最直接的方法就是简单地将每个图像块的像素展平成一个长向量，然后使用标准的线性投影（[矩阵乘法](@article_id:316443)）将其缩小到[期望](@article_id:311378)的[嵌入维度](@article_id:332658)，比如 $D$。这个过程将我们的 $H \times W$ 图像转换成一个包含 $L$ 个词元的序列，其中 $L$ 是图像块的数量，每个词元都是 $D$ 维空间中的一个点。

但是，这种简单的展平和投影是*最好*的方式吗？在这里，我们遇到了一个贯穿整个科学领域的美妙原则：你选择的表示方法至关重要。它带有一种固有的“偏好”，也就是我们所说的**[归纳偏置](@article_id:297870) (inductive bias)**。一个思想实验有助于澄清这一点 [@problem_id:3199214]。想象两种创建图像块[嵌入](@article_id:311541)的方法。一种是我们刚才描述的简单线性投影。另一种是使用一个小卷积，这是一种借鉴自[卷积神经网络 (CNN)](@article_id:303143) 的技术，它在图像块上滑动一个小滤波器。

如果我们在[频域](@article_id:320474)——这个由描述不同尺度模式的正弦和余弦组成的世界——中分析这些方法，我们会发现它们具有不同的特性。小卷积倾向于具有**低通频率偏置**。这意味着它自然会更关注图像块内部平滑、大尺度的模式（如天空的均匀颜色），而较少关注尖锐、高频的细节（如织物的纹理）。另一方面，简单的线性投影更像一块白板，能够根据数据学习关注高频或低频信息。这揭示了一个深层的联系：我们模型设计的第一步就如同选择一副眼镜。有些眼镜可能会锐化精细的细节，而另一些则可能模糊它们以强调宽泛的形状。没有唯一的“正确”选择；这是一个设计决策，它塑造了模型此后学习的一切。

### 位置感：[位置编码](@article_id:639065)的作用

现在我们有了一个由“图像块-词语”组成的“句子”。但我们丢失了至关重要的信息：空间[排列](@article_id:296886)。如果我们只有一个“图像块集合”，模型就无从知晓哪个图像块来自左上角，哪个来自右下角。它无法区分一张人脸和同一张脸的打乱版本。[Transformer](@article_id:334261) 的核心机制，即[自注意力](@article_id:640256)，天然是**[置换](@article_id:296886)不变的 (permutation-invariant)**——打乱输入序列，你只会得到一组同样被打乱的输出。

为了解决这个问题，我们必须明确地给予模型一种“位置感”。我们通过向每个图像块[嵌入](@article_id:311541)中添加另一个向量来实现这一点：一个**[位置编码](@article_id:639065) (positional encoding)**。这个向量唯一地标识了图像块在图像网格中的原始位置。例如，位置 $(0,0)$ 的图像块得到一个特定的向量，位置 $(0,1)$ 的图像块得到另一个，依此类推。

让我们通过一个极简实验来看看这是如何工作的 [@problem_id:3199205]。想象一个微小的 $2 \times 2$ 图像，包含四个图像块。图像中总是有两个“A”图像块和两个“B”图像块。唯一改变的是它们的[排列](@article_id:296886)方式。假设我们的任务是分类“A”图像块是否在主对角线上。我们假定“A”图像块的值为 $+1$，“B”图像块的值为 $-1$。

注意力机制通过一个**查询 (query)** 向量（我们称之为 $q$）来工作，它“寻找”一种模式。我们可以设计一个专门关注对角线位置的查询，比如 $q = [1, 0, 0, 1]^\top$。这个查询给予位置 0 和 3（对角线）很高的重要性，而给予位置 1 和 2 零重要性。然后，模型根据这个查询与每个图像块的**键 (key)** 向量的[点积](@article_id:309438)来计算注意力权重。如果键只包含图像块的内容，模型就会迷失方向。但是，如果我们让键等于[位置编码](@article_id:639065)本身（例如，对于位置 0 使用像 $[1,0,0,0]^\top$ 这样的独热向量），那么[点积](@article_id:309438) $q^\top k_i$ 就会直接挑选出查询对位置 $i$ 的偏好。

因此，注意力权重对于角线位置将是最高的。最终的输出是图像块*值*（$+1$ 和 $-1$）的加权平均。如果“A”图像块（$+1$）在对角线上，它们会获得高权重，输出为正。如果“B”图像块（$-1$）在对角线上，它们会获得高权重，输出为负。模型现在可以解决这个任务了！这个简单的构造优美地展示了注意力的三元本质：查询（$q$）问“我应该看哪里？”，键（$k_i$）中的位置信息提供了地图，而值（$v_i$）中的内容提供了答案。没有[位置编码](@article_id:639065)，这张地图就是一片空白。

### 伟大的对话：运行中的[自注意力](@article_id:640256)

[Transformer](@article_id:334261) 的核心是**[自注意力](@article_id:640256) (self-attention)** 机制。你可以把它想象成一个动态且民主的过程。对于我们序列中的每个图像块，模型会计算三个不同的向量：一个**查询 (Query, Q)**，一个**键 (Key, K)**，和一个**值 (Value, V)**。
- **查询**是一个图像块在提问：“根据我的身份，哪些其他图像块与我相关？”
- 来自另一个图像块的**键**回应道：“这是我能提供的信息；这就是我。”
- 来自那个图像块的**值**则说：“如果你觉得我相关，这就是我将分享的信息。”

模型计算一个图像块的查询与所有其他图像块的键之间的得分。然后，这些得分被转换成注意力权重（使用 softmax 函数），这些权重决定了每个图像块的值在多大程度上被融入当前图像块的新表示中。这个过程对每个图像块并行发生。这是一场“伟大的对话”，图像中的每个图像块都可以直接与任何其他图像块通信，实时权衡它们的重要性。

这导致了 ViT 与传统 CNN 之间最深刻的区别之一。CNN 通过一个小的、局部的窗口（其核）来看世界，信息通过层层缓慢传播以建立更广阔的视野。相比之下，[自注意力](@article_id:640256)从第一层就提供了**全局感受野 (global receptive field)**。原则上，任何图像块都可以影响任何其他图像块。我们甚至可以将其可视化！一种称为**注意力展开 (attention rollout)** 的技术可以追踪注意力如何在各层之间流动。通过将每一层的注意力矩阵相乘，我们可以计算出一个有效的“感受野”，显示哪些输入图像块对最终输出图像块的影响最大 [@problem_id:3199184]。与 CNN 固定的矩形[感受野](@article_id:640466)不同，ViT 的[感受野](@article_id:640466)是动态的、依赖于内容的、并且是全局的。

然而，这场全局对话的代价是高昂的。成对的查询-键比较次数随着图像块数量 $L$ 的增加而呈二次方增长。如果将[图像分辨率](@article_id:344511)加倍，图像块数量会变为四倍，导致注意力的[计算成本](@article_id:308397)大约增加十六倍！注意力机制的复杂度主要有两部分：一部分随 $\mathcal{O}(L^2 D)$ 扩展（来自 Q-K [点积](@article_id:309438)和 V-加权），另一部分随 $\mathcal{O}(L D^2)$ 扩展（来自创建 Q、K、V 的线性投影）。对于高分辨率图像，$L$ 变得非常大，$\mathcal{O}(L^2 D)$ 项很快成为瓶颈 [@problem_id:3199246]。内存使用是一个更大的问题。为了在训练期间计算梯度，必须存储巨大的 $L \times L$ 注意力矩阵，导致内存成本为 $\mathcal{O}(L^2)$ [@problem_id:3199141]。这种二次方缩放是标准 [Transformer](@article_id:334261) 的阿喀琉斯之踵，这也是为什么像**激活检查点 (activation checkpointing)** 这样的技术——在[反向传播](@article_id:302452)过程中重新计算中间结果而不是存储它们——对于在大型图像上训练大型模型至关重要。

### 架构决定命运：堆叠模块以实现稳定性和强大性能

一个 Vision [Transformer](@article_id:334261) 不仅仅是单一的[自注意力机制](@article_id:642355)；它是一个由相同模块深度堆叠而成的结构。每个模块包含一个[自注意力](@article_id:640256)层和一个简单的逐位置前馈网络。但是，将这些模块粘合在一起的“胶水”与模块本身同样重要：**[残差连接](@article_id:639040) (residual connections)** 和**[层归一化](@article_id:640707) (layer normalization)**。这些不仅仅是工程技巧；它们是决定深度网络是否能够学习的关键设计原则。

**[残差连接](@article_id:639040)**是一个简单而巧妙的想法：在一个模块对其输入 $x$ 计算某个函数 $F(x)$ 后，它将其结果加回到原始输入中，产生 $x + F(x)$。这种“跳跃连接 (skip connection)”就像一条信息高速公路，让原始信号能够直接流过网络。一项精彩的分析 [@problem_id:3199211] 揭示了其更深层的作用。如果我们将注意力模块建模为一个简单的滤波器（比如检测边缘的[拉普拉斯算子](@article_id:334415)），我们会发现，通过[残差连接](@article_id:639040)堆叠这些模块会创建一个强大的**[低通滤波器](@article_id:305624)**。零频率分量（“直流”或平均值）的增益恰好为 1，意味着它能无损通过。而较高频率的分量则被衰减。在一个非常深的网络中，这确保了图像的基本、大尺度信息得以保留，而不会被数十次变换冲刷掉。

最后，我们需要保持网络内部数值的良好行为。当信号通过许多层时，它们的量级可能会爆炸到无穷大或缩小到零。为了防止这种情况，我们使用**[层归一化](@article_id:640707) (Layer Normalization, LN)**。此操作独立地重新缩放*每个图像块词元*的特征，使其均值为零，标准差为一。这使得模型对每个图像块的整体对比度和亮度不那么敏感 [@problem_id:3138581]。

但是，架构中一个微妙的选择——将 LayerNorm 放在*哪里*——对训练稳定性有着巨大的影响 [@problem_id:3199138]。早期的 [Transformer](@article_id:334261) 使用“后置 LN (post-LN)”设计，在[残差](@article_id:348682)相加后应用[归一化](@article_id:310343)。一个简单的分析表明，这可能导致信号范数的不稳定、**[几何级数](@article_id:318894)增长**，即在每一层都会乘以一个大于一的因子。这严重限制了模型在激活值爆炸前可以拥有的层数。现代的“前置 LN (pre-LN)”设计，被用于 ViT 中，它在注意力模块*之前*应用[归一化](@article_id:310343)。这驯服了这头野兽：增长变为**算术级数增长**，每层只增加一个小的常数。这使得训练过程稳定得多，从而能够构建出那些取得了非凡成果的、真正庞大的、百层深度的模型。这是一个核心教训的完美展示：架构决定命运。

