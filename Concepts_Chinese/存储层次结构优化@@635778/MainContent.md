## 引言
现代处理器惊人的速度常常受到一个根本瓶颈的束缚：相对缓慢的主内存访问。这种被称为“[内存墙](@entry_id:636725)”的差异是实现峰值计算性能所面临的最大挑战之一。我们如何设计软硬件来弥合这一差距，让我们快如闪电的处理器无需持续等待数据呢？本文深入探讨了一种优雅的解决方案：[存储层次结构](@entry_id:755484)，并全面探索了用于管理这一复杂系统的原理和技术。在第一章“原理与机制”中，我们将揭示缓存和局部性的基本概念，使用像 AMAT 这样的指[标量化](@entry_id:634761)性能，并审视关键的硬件和软件优化。随后，“应用与跨学科联系”一章将展示这些原理如何付诸实践，影响着从[编译器设计](@entry_id:271989)和[循环优化](@entry_id:751480)到数据库架构和大规模[科学模拟](@entry_id:637243)的方方面面。读完本文，您将不仅理解内存感知[性能工程](@entry_id:270797)的“是什么”，更能明白其“为什么”。

## 原理与机制

想象一位大师级厨师在一个巨大的厨房里工作。这位厨师能以超人般的速度切配食材，但存放食材的储藏室却在一英里之外。无论厨师有多快，整个烹饪过程都将被往返储藏室的缓慢乏味过程所主导。这正是现代计算核心的困境。我们的处理器（厨师）快得惊人，每秒能执行数十亿次操作。但我们的主内存，即 DRAM（储藏室），却相对迟缓。这种速度差异，通常被称为**[内存墙](@entry_id:636725)**，是计算机性能面临的最大挑战。

我们如何解决这个问题？我们不能把储藏室搬到厨师旁边，但我们可以更聪明一些。如果我们在厨师工作台旁边放一个小冰箱，里面只放接下来几分钟会用到的食材呢？这就是[存储层次结构](@entry_id:755484)背后的核心思想。我们在快速的处理器和缓慢的主内存之间构建一系列更小、更快、也更昂贵的存储区域，称为**缓存**。但要使其奏效，我们需要一种方法来预测厨师接下来会需要哪些食材。幸运的是，程序并非随机运行；它们遵循一种可预测的模式，这一极其重要的原则被称为**局部性**。

### 局部性的魔力

局部性原理是整个缓存系统得以运作的魔力所在。它是一种观察，即程序倾向于重用它们最近使用过的数据和指令。这种倾向有两种形式：时间和空间。

**[时间局部性](@entry_id:755846)**，或称时间上的局部性，是指如果你现在使用了某个东西，你很可能很快会再次使用它。可以将其看作是懒惰的美德。如果你从工具箱里拿出一把锤子，你不会在敲一下之后就立刻把它放回去。你会把它放在工作台上，因为你可能还会再用到它。在计算机中，如果处理器请求一块数据，我们会将它的一个副本放入快速缓存中，赌它很快会被再次需要。

**[空间局部性](@entry_id:637083)**，或称空间上的局部性，是指如果你使用了某个东西，你很可能很快会使用位于它附近的东西。当你需要一把十字螺丝刀时，你可能会顺手把整盒螺丝刀都拿过来。你不能确定是否会用到一字螺丝刀，但这很可能，而且一次性把它们都拿过来很高效。计算机利用这一点，从主内存中获取数据时不是单个字节地取，而是以称为**缓存行**（或缓存块）的连续[数据块](@entry_id:748187)为单位。一个典型的缓存行可能是 64 字节长。当你请求一个字节时，系统会将该字节及其 63 个邻居一同带入缓存，期望你接下来会用到它们。

这对我们如何编写代码产生了巨大影响。考虑遍历一个二维数据网格，比如图像中的像素，它以我们所说的**[行主序](@entry_id:634801)**（意味着行在内存中是连续[排列](@entry_id:136432)的）存储。如果你的代码逐行处理网格，你就是在完全按照[内存布局](@entry_id:635809)的方式遍历。你对某行中第一个元素的访问会导致一次缓存未命中，但系统会取回包含该元素及其邻居的整个缓存行。你随后的访问将是对那些邻居的闪电般的命中。这是利用空间局部性的一个绝佳例子。

但如果你逐*列*遍历网格会怎样？一列中的每个元素在内存中都由一整行的长度隔开。如果这个步长大于缓存行大小，那么每一次访问都将访问一个新的、不同的缓存行。随第一个元素带入的数据对于访问第二个元素毫无用处。结果是一连串的缓存未命中，处理器大部分时间都在等待“储藏室小弟”。一种称为**[循环交换](@entry_id:751476)**的简单[编译器优化](@entry_id:747548)，仅仅通过交换循环顺序，使遍历从逐列变为逐行，就能通过恢复空间局部性来显著提升性能。这个简单的改变可以将慢速 D[RAM](@entry_id:173159) 访问的次数减少一个[数量级](@entry_id:264888)，从而带来巨大的速度提升，甚至显著的节[能效](@entry_id:272127)果 [@problem_id:3652928]。

### 存储金字塔与 AMAT 标尺

为了对抗[内存墙](@entry_id:636725)，我们不只构建一个缓存，而是构建一个完整的[缓存层次结构](@entry_id:747056)，形成一个金字塔。

-   在金字塔顶端，最接近处理器的是**一级（L1）缓存**。它们非常小（几十千字节），但速度极快，通常只需几个 CPU 周期即可访问。通常有独立的 L1 缓存用于指令和数据。
-   其下是**二级（L2）缓存**。它更大（数百千字节到几兆字节），比 L1 稍慢。
-   再往下是**三级（L3）缓存**，它更大（许多兆字节）且更慢，通常由芯片上的所有核心共享。
-   最后，在金字塔的底部，是广阔的**主内存（DRAM）**，再往后是更慢的存储设备，如[固态硬盘](@entry_id:755039)。

当处理器需要一块数据时，它首先检查 L1。如果在（即 **L1 命中**），太好了！如果不在（即 **L1 未命中**），它会检查 L2。L2 命中比 L1 慢，但比访问主内存快得多。如果是 L2 未命中，它会检查 L3，依此类推。每向金字塔下方移动一步，都是在上一层的“未命中”，并会产生显著的时间惩罚。

我们如何量化这个金字塔的性能？我们使用一个称为**[平均内存访问时间](@entry_id:746603)（AMAT）**的指标。它回答了这样一个问题：“平均而言，一次内存访问需要多长时间？”我们可以根据常识构建这个公式。所需时间是一级缓存的命中时间，*加上*未命中时你支付的惩罚。这个惩罚是从下一级获取数据所需的时间，而且它只在一小部分时间（未命中率）内发生。所以，对于一个简单的单缓存系统：

$AMAT = \text{命中时间} + (\text{未命中率} \times \text{未命中惩罚})$

对于我们完整的金字塔，这变成了一个嵌套方程。L1 的“未命中惩罚”就是 L2 的 AMAT，以此类推。这个简单而强大的公式使我们能够对性能权衡进行推理。例如，想象一个程序，其代码高效、紧凑，但以随机模式访问一个巨大的数据集。指令访问的未命中率会非常低（“热代码”），而数据访问的未命中率会非常高（“冷数据”）。通过分别计算两者的 AMAT，我们可以看到，即使对已经很好的指令局部性进行巨大改进，也只会带来微乎其海外的整体效益。相比之下，对糟糕的[数据局部性](@entry_id:638066)进行适度改进（或许通过重组[数据结构](@entry_id:262134)），可能会带来巨大的速度提升。AMAT 告诉我们，要把精力集中在最痛的地方 [@problem_id:3668515]。

### 工程师的工具箱：驯服层次结构

知道原理是一回事，应用它们是另一回事。几十年来，计算机架构师和程序员已经开发出一套出色的硬件和软件技术来优化[存储层次结构](@entry_id:755484)。

#### 第二次机会的缓存：[受害者缓存](@entry_id:756499)

有时，发生未命中并不是因为缓存已满（**[容量未命中](@entry_id:747112)**）或这是我们第一次看到该数据（**[强制性未命中](@entry_id:747599)**），而是纯粹因为运气不好。**[冲突未命中](@entry_id:747679)**发生在你需要的两块不同数据恰好映射到缓存中的同一位置时。它们最终会陷入一个令人沮丧的循环，相互驱逐，即使缓存的其余部分是空的。这被称为**[抖动](@entry_id:200248)**。

一个优雅的解决方案是**[受害者缓存](@entry_id:756499)**。它是一个小型的、全相联的缓存，位于 L1 缓存旁边。它的工作是保存最后几行被“牺牲”的缓存行——即从 L1 中被驱逐出去的行。如果处理器试图访问这些最近被驱逐的行之一，它不会触发缓慢的 L2 访问，而是在[受害者缓存](@entry_id:756499)中获得一次非常快速的命中。然后[受害者缓存](@entry_id:756499)会将该行交换回 L1 缓存中。这个简单的硬件增加充当了一个安全网，极大地减少了[冲突未命中](@entry_id:747679)的惩罚 [@problem_id:3665808]。

#### 窥探未来：预取

如果我们知道一个程序正在顺序访问内存（利用空间局部性），为什么还要等它请求呢？**[硬件预取](@entry_id:750156)器**是一个监视内存地址流的组件。当它检测到一个模式，比如在内存中稳定地前进时，它会在 CPU 请求之前主动获取接下来的几个缓存行。当 CPU 最终请求时，数据已经等在缓存中——一次未命中被神奇地转换成了一次命中。

但这种能力必须明智地使用。一个过于激进的预取器可能会“污染”缓存，带入无用的数据，并驱逐程序[工作集](@entry_id:756753)中有用的行。这导致了一个有趣的权衡：存在一个最大预取深度，超过这个深度，[缓存污染](@entry_id:747067)的危害将超过预取的好处。有趣的是，[受害者缓存](@entry_id:756499)在这里也能提供帮助，通过捕获那些被过于热情的预取器错误驱逐的有用行，展示了这些不同的优化如何协同工作 [@problem_id:3625689]。

#### 无形的缓存：地址翻译与 TLB

有一层缓存是如此基础，以至于几乎不可见。我们程序使用的地址（**虚拟地址**）与内存硬件使用的地址（**物理地址**）不同。每一次内存访问都需要从虚拟地址到物理地址的翻译。这个翻译是通过在内存中查找一系列称为**页表**的数据结构来完成的。如果每次访问都必须这样做，性能将是灾难性的。

解决方案是什么？又一个缓存！**转译后备缓冲器（TLB）**是一个小型的专用缓存，用于存储最近的虚拟到物理地址的翻译。TLB 命中非常快。然而，TLB 未命中代价高昂。它迫使硬件执行一次**[页表遍历](@entry_id:753086)**，即一系列依赖的内存读取来找到正确的翻译 [@problem_id:3626813]。这揭示了我们的[存储层次结构](@entry_id:755484)不仅用于数据，也用于关于数据位置的[元数据](@entry_id:275500)。

#### 通用解决方案：[缓存无关算法](@entry_id:635426)

大多数优化都需要针对特定的硬件进行调整。例如，为了使[矩阵乘法](@entry_id:156035)对缓存友好，程序员可能会将[矩阵分解](@entry_id:139760)成大小恰好能放入 L1 缓存的块。但是，当你在具有不同缓存大小的机器上运行相同的代码时会发生什么？它会变得次优。

这就是**[缓存无关算法](@entry_id:635426)**如此优美和深刻的原因。这些算法是使用递归的、分治的方法设计的。问题被递归地分解成越来越小的子问题。最终，子问题变得如此之小，以至于它们自然而然地适合 L1 缓存，无论其大小如何。到那时，所有的访问都是快速的缓存命中。因为这在存储金字塔的每一层都会自动发生——问题最终会适合 L2，然后是 L3，等等——该算法在整个层次结构中实现了近乎最优的性能，而无需知道缓存的大小或缓存行的长度 [@problem_id:3625045]。这是一个纯粹的算法解决方案，具有普遍的效率，是抽象推理战胜暴力调优的胜利。

#### 现代的公平性与检测

今天的芯片不是单一实体，而是由多个处理器核心组成的繁忙社区。这些核心通常共享资源，比如 L3 缓存。这个共享缓存应该如何划分？天真的平均分配很少是最佳的。有些程序是“缓存饥饿”的，而另一些则不是。一个真正公平和高效的划分不是给每个人相同的份额；而是以一种能最小化所有核心*总减速*的方式来分配缓存资源。这将一个[硬件设计](@entry_id:170759)问题转变为一个有趣的约束优化问题，其目标是最大化整个系统的[吞吐量](@entry_id:271802) [@problem_id:3660660]。

面对所有这些复杂、相互作用的层次，程序员如何找出他们的代码为什么慢？这是性能侦探的工作。现代 CPU 配备了**性能监控计数器（PMCs）**，这些特殊寄存器可以计算[微架构](@entry_id:751960)事件。工程师可以配置这些计数器来跟踪 L1 未命中、L2 未命中、TLB 未命中、分支预测错误等等。通过收集这些数据并使用一个合理的归因模型——一个能正确处理层次结构并避免重复计算[停顿](@entry_id:186882)的模型——工程师可以诊断出瓶颈的根本原因。程序是否遭受[冲突未命中](@entry_id:747679)？[工作集](@entry_id:756753)是否对于缓存来说太大了？是 TLB 问题吗？通过回答这些问题，工程师可以从优化工具箱中部署正确的工具，从而完成从基本原理到真实世界[性能工程](@entry_id:270797)的闭环 [@problem_id:3654056]。[存储层次结构](@entry_id:755484)，诞生于一个隐藏延迟的简单技巧，已经演变成一个深刻而优美的研究领域，其中优雅的原理和巧妙的工程协同工作，以弥合处理器和内存之间的巨大鸿沟。

