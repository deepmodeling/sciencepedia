## 应用与跨学科联系

想象你是一位雕塑家，面对一块巨大的大理石。你的任务不是添加更多的材料，而是凿去多余的部分，切除不必要的东西，以揭示隐藏在其中的优雅形态。前一章给了我们凿子和锤子背后的原理——结构化[正则化](@article_id:300216)的数学。现在，我们将看到这门艺术的实践。我们将浏览一系列应用，观察这同一个强大的理念如何不仅雕塑我们计算机的人工大脑，还帮助我们以新的、深刻的方式理解世界。我们将看到，[结构化剪枝](@article_id:641749)不仅仅是优化的一个技巧；它是寻找事物本质的基本原则。

### 雕塑现代神经网络

我们的第一站是最显而易见的：现代[深度学习](@article_id:302462)中庞大而复杂的架构。在这里，模型可以有数十亿个参数，简直是一座大理石山。[结构化剪枝](@article_id:641749)是我们从中发现雕像的工具。

#### 为效率而剪枝：Inception 的案例

考虑像谷歌的 Inception 网络这样的架构，它以其“Inception 模块”而闻名。这些模块像一个专家委员会一样工作。输入被同时送入多个并行路径——一条带有小卷积滤波器，一条带有中等大小的，一条带有大的，等等。然后网络将它们的输出结合起来。但是，如果对于给定的任务，这些专家中的一些是多余的呢？如果“中等滤波器”专家一直被忽略怎么办？

这正是[结构化剪枝](@article_id:641749)大放异彩的地方。我们不把每个单独的权重都当作一个独立的参数来剪枝，而是可以将属于单个路径的所有权重归为一个“组”。然后我们施加一个惩罚——我们称之为 Group [Lasso](@article_id:305447) 正则化器——不是针对单个权重，而是针对*整个组*。优化过程被迫为每个路径做出“全有或全无”的决定。如果一个路径的贡献不足以克服惩罚，它的整个权重组将被精确地设置为零。这个专家被解雇了，这条路径消失了。

这个过程，由一个简单而优雅的、称为块[软阈值](@article_id:639545)的数学更新驱动，使我们能够自动发现并移除像 GoogLeNet 这样的网络中的整个计算分支，从而得到一个更小、更快、更高效的模型，而准确率没有显著损失 [@problem_id:3130715]。

#### 为可解释性而剪枝：理清 [DenseNet](@article_id:638454)s

效率是一个美好的目标，但理解呢？剪枝能帮助我们窥探神经网络的“黑箱”吗？让我们看看另一个著名的架构，[密集连接](@article_id:638731)网络，或称 [DenseNet](@article_id:638454)。在 [DenseNet](@article_id:638454) 中，每一层都从*所有*前面的层接收直接连接。这创造了一个纠缠不清的信息流网络。

通过在这里应用[结构化剪枝](@article_id:641749)，我们可以提出一个有趣的问题：这些[密集连接](@article_id:638731)中哪些是真正至关重要的？我们可以将从某个特定早期层到所有后续层的出站连接分组，并应用我们的组惩罚。如果惩罚迫使这组连接归零，这意味着这个早期层的特征最终对网络的更深层部分没有用处。

剪枝后，我们得到一个稀疏的“[依赖图](@article_id:338910)”，一个清晰地展示了信息真实流动的蓝图。例如，我们可以看到，来自第3层的[特征检测](@article_id:329562)器对于在第20层做出的决定至关重要，而来自第4层的则无关紧要。[结构化剪枝](@article_id:641749)将一个纠缠的网络转变为一个可解释的电[路图](@article_id:338292) [@problem_id:3114033]。

#### 超越简单剪枝：混合结构

“组”的概念可以比仅仅是权重的集合更复杂。想想卷积层中的滤波器。在数学上，它们可以表示为矩阵。我们从线性代数中知道，一些矩阵具有非常简单的结构；它们是“低秩”的。一个[低秩矩阵](@article_id:639672)可以被紧凑地表示为更小矩阵的乘积，从而节省大量参数。

我们可以设计混合惩罚项，既鼓励组稀疏性（使整个滤波器矩阵为零），又鼓励非零滤波器内部的低秩性。一种这样的惩罚项可能会结合 Frobenius 范数（鼓励整个组收缩）和[核范数](@article_id:374426)（矩阵[奇异值](@article_id:313319)之和），后者是矩阵秩的一个优美的凸代理。这使我们能够找到一个在粗粒度上是稀疏的、在细粒度上具有简单低秩组件的压缩模型，为我们提供了一个平衡[模型容量](@article_id:638671)和压缩的强大工具 [@problem_id:3169322]。

#### 当架构本身进行剪枝时

有时，结构不是我们强加的，而是我们发现的。在像 [EfficientNet](@article_id:640108) 这样的前沿架构中，有一些叫做 Squeeze-and-Excitation (SE) 模块的巧妙组件。一个 SE 模块会查看通过一层的所有信息通道，“挤压”它们成一个小的摘要，然后通过为每个通道计算一组重要性分数[或门](@article_id:347862)控值来“激发”它们。

这种[门控机制](@article_id:312846)实际上是一种动态的、依赖于输入的[结构化剪枝](@article_id:641749)。如果 SE 模块判定某个通道对于特定输入是无关的，它可以为其分配一个接近零的门控值，从而有效地使其静默。通过分析这些门控在许多不同输入上的行为，我们可以识别出持续被抑制的通道。这些通道非常适合被永久移除，这表明架构本身在告诉我们[稀疏性](@article_id:297245)在哪里 [@problem_id:3119622]。这是显式设计与涌现功能之间的一场美妙对话。

### 超越像素：[结构化稀疏性](@article_id:640506)在更广阔的世界

这个想法的力量远远超出了深度学习和图像识别的领域。在其核心，[结构化剪枝](@article_id:641749)是将先验知识编码到一个优化问题中。而在所有科学领域，我们都拥有丰富的先验知识。

#### 在数据中发现知识：层次化[特征选择](@article_id:302140)

想象你是一名[数据科学](@article_id:300658)家，正在使用一个表格数据集来预测房价。你的特征可能有一个自然的层次结构：你有`国家`，然后是`州`，然后是`城市`，然后是`街道`。如果发现`城市`完全不相关，那么考虑它所在的`街道`就没有意义了。

我们可以使用树状结构惩罚项将这种知识直接编码到我们的模型中。这是一种重叠[组套索](@article_id:350063)的形式，其中组由我们的特征树中的节点定义。例如，加利福尼亚州下的所有特征构成一个组。但`加利福尼亚`本身是`美国`国家节点下与其他州一起组成的更大组的一部分。惩罚项被应用于所有这些嵌套的组。结果是神奇的：[优化算法](@article_id:308254)不能选择一个特征（树中的一个叶子），除非它的整个祖先路径——`街道`、`城市`、`州`、`国家`——也都被选中。它强制执行一个从粗到精的发现过程，尊重世界的逻辑结构，并产生不仅稀疏而且在深层直观上可解释的模型 [@problem_id:3124184]。

#### 基础：[压缩感知](@article_id:376711)与恢复的保证

这些想法从何而来？其中许多都深深植根于信号处理领域，特别是在[压缩感知](@article_id:376711)理论中。[压缩感知](@article_id:376711)回答了一个看似不可能的问题：我们能否仅从图像的一小部分像素完美地重建出高分辨率图像？令人惊讶的答案是肯定的，*如果*我们知道图像具有结构（即，它不是随机噪声）。大多数图像在某个域（如[频域](@article_id:320474)）中是“稀疏”的。

该理论为我们提供了保证，如受限等距性质（Restricted Isometry Property, RIP）。直观地说，RIP 指出，如果我们的测量过程（采样少量像素）保留了不同稀疏信号之间的距离，那么我们就可以保证完美恢复。令人兴奋的是，如果我们对信号的结构了解得更多——例如，其非零元素出现在连续的块中或树中——我们可以构建一个“基于模型的RIP”。该理论告诉我们，与恢复具有任意稀疏结构的信号相比，恢复具有已知结构的信号需要更少的测量 [@problem_id:2905682]。这就是为什么编码先验知识如此强大的根本原因。

更重要的是，用于解决信号处理中这些恢复问题的数学机制，通常与我们在[深度学习](@article_id:302462)中使用的完全相同。我们看到的用于剪枝神经网络的“组[软阈值](@article_id:639545)”操作 [@problem_id:3130715]，正是从压缩测量中恢[复结构](@article_id:332830)化信号的[算法](@article_id:331821)中使用的核心步骤 [@problem_id:3122415]。这种跨越看似不同领域的数学统一性是科学的伟大之美之一。

### 结构作为原则：驯服动态系统中的模糊性

我们的最后一站也许是最抽象的，但它显示了我们原则的深刻哲学深度。在这里，结构不仅关乎效率或[可解释性](@article_id:642051)，而且关乎科学发现的可能性本身。

#### 识别不可见之物：状态空间模型中的[结构化稀疏性](@article_id:640506)

在从经济学到[机器人学](@article_id:311041)的许多科学和工程学科中，我们使用[状态空间模型](@article_id:298442)来建模系统。我们想象一个系统有一些隐藏的内部“状态”，它随时间演变，而我们只能看到该状态的一些带噪声的测量值。想象一下，仅仅通过观察钟面上指针的运动（测量值）来试图理解其复杂的发条装置（隐藏状态）。

这里的一个根本挑战是“可辨识性”。通常情况下，许多不同的内部发条装置都可能产生完全相同的指针运动。从外部看，真实的内部结构是模糊的。我们如何希望能发现真正的模型？

答案再次是结构。通过在控制输入如何影响隐藏状态以及[隐藏状态](@article_id:638657)如何产生输出的矩阵上施加结构化稀疏模式，我们可以极大地减少这种模糊性。例如，如果我们有先验知识，知道某些输入应该只影响内部状态的某些部分，我们可以通过将输入矩阵中的相应条目设置为零来强制执行这一点。这个约束消除了所有不尊重这种已知局部性的“不切实际”的内部模型。任何剩余的模糊性都被限制在更小、更易于管理的子空间内。通过编码我们所知道的关于系统结构的信息，我们使得识别我们所不知道的东西成为可能 [@problem_id:2886200]。

### 事物的本质

我们的旅程完成了。我们从削减庞大的[深度学习](@article_id:302462)模型以使其更快开始。然后我们发现，我们的凿子也可以揭示它们的内部逻辑。我们看到这同一个工具可以根据数据集中的特征的自然层次来组织它们。我们退后一步，欣赏了我们方法在信号处理中的深刻理论基础。最后，我们看到了结构如何成为解决[动态系统建模](@article_id:306323)中基本模糊性的关键。

[结构化剪枝](@article_id:641749)，以其多种形式，远不止是一种技术技巧。它是一种强大的科学原则的体现：即简单性、结构和先验知识是我们追求建立不仅具有预测性，而且高效、可解释，并最终更真实地反映它们所寻求理解的世界的模型的最大盟友。这是发现本质的艺术。