## 应用与跨学科联系

在上一章中，我们在沙地上画了一条看似简单的线：回归预测数字，分类分配标签。这是一个很好的开始，就像学习凿子用来削，锯子用来割一样。但对于一位大师级工匠来说，它们不仅仅是工具，而是他们意志的延伸，用以将一块木头变成美丽或有用的东西。回归和分类也是如此。它们真正的力量不在于其定义，而在于它们如何成为科学家、工程师和思想家手中发现的工具。

现在，让我们踏上一段旅程，看看这些简单的思想如何在人类探究的广阔领域中绽放出深刻的应用。我们将看到，它们之间的界线常常变得模糊，而它们最伟大的胜利往往来自于协同使用，使我们能够对世界提出极其复杂的问题。

### 揭示自然法则

科学的核心是与自然的一场宏大对话。我们提出一个故事——一个假说——关于世界某个部分的运作方式。然后，我们收集数据并提问：“我的故事与事实相符吗？”回归和分类是我们进行这场质询所使用的主要语言。

想象你是一位[材料物理学](@article_id:381379)家，刚刚创造出一种新颖的[半导体](@article_id:301977)。你想要理解电流是如何在其中流动的。理论提供了几个相互竞争的故事。在一个故事中，电子是“[能带](@article_id:306995)状的”（band-like），像高速公路上的汽车一样[自由流](@article_id:319910)动。在另一个故事中，它们是“[小极化子](@article_id:305530)”（small polarons），像一个人在拥挤的房间里穿行一样从一个位置跳到另一个位置。第三个故事涉及“[变程跳跃](@article_id:298502)”（variable-range hopping），这是一种在无序景观中更复杂的跳跃。每个故事都预测了温度与材料[电导率](@article_id:308242)（$\sigma$）和塞贝克系数（$S$）——一种由温差产生的电压的度量——之间不同的数学关系。

那么，你该怎么做？你不能只靠猜测。你把每个故事都变成一个[回归模型](@article_id:342805)。对于[能带](@article_id:306995)状的故事，你可以绘制电导率的对数与[逆温](@article_id:300532)（$1/T$）的关系图，并[期望](@article_id:311378)得到一条直线。对于[变程跳跃](@article_id:298502)的故事，你会将它与 $T^{-1/4}$ 作图并寻找线性关系。你对所有三个故事、对[电导率](@article_id:308242)和塞贝克系数都这样做。然后，你只需问：哪组图最直？最能“拉直”数据的故事就是自然告诉你的那个。最终的答案是一个分类问题——“是模型A、B还是C？”——但你是通过一场回归模型的大混战得出的结论，其中每个模型都代表一个不同的物理理论 [@problem_id:2857922]。

这种“通过回归竞赛进行分类”的精神在整个科学界回响。化学家可能会通过观察反应的[表观活化能](@article_id:365884)——一个通过回归求得的值——如何随压力变化来区分两种反应机理 [@problem_id:2624188]。一位[发育生物学](@article_id:302303)家，凝视着一个微小的胚胎，可能会提出一个困扰了动物界几个世纪的问题：它的口是由第一个开口（胚孔）形成的，还是次级形成的？这两条发育途径，区分了[原口动物](@article_id:307231)（如昆虫）和[后口动物](@article_id:308279)（如我们），预测了未来口的形成位置有不同的轨迹。一个故事预测了与胚孔的距离呈指数衰减，另一个则预测了更线性或稳定的路径。通过将衰减的回归模型和线性运动的[回归模型](@article_id:342805)都拟合到数据上，生物学家可以使用像 Akaike Information Criterion (AIC) 这样的统计标准来决定哪个故事更合理，从而将该生物体归入生命之树的某个伟大分支 [@problem_id:2556442]。在每种情况下，回归都是工具，但最终目标是对系统进行深刻的、分类上的理解。

### 一次一预测，构筑未来

当我们中的一些人用这些工具来破译宇宙的法则时，另一些人则用它们来构建宇宙。在这里，焦点从解释转向了预测和控制。

考虑一下股票市场的动荡不休或天气的日常节奏。对于这类时间序列数据，我们可以提出两种问题。“明天中午的温度会是多少？”是一个回归问题。“明天会比今天热吗？”则是一个分类问题。同样的基础数据流可以用于任一任务。有时，分类问题不仅更容易回答，而且也更有用。知道一个组件的温度将超过一个[临界阈值](@article_id:370365)（分类）可能比知道它的确切值（回归）更重要 [@problem_id:3169429]。

但我们可以比这更聪明。在金融世界，仅仅预测单只股票的价格是出了名的困难；在很大程度上，它是一个[随机游走](@article_id:303058)。但如果我们能找到两只倾向于同步波动的股票，就像两个被无形绳索拴在一起的舞者呢？虽然每个舞者的路径都不可预测，但他们之间的距离可能非常稳定。我们可以使用回归来找到完美的“[对冲](@article_id:640271)比率”——即两种股票的精确组合，使这个距离或“价差”尽可能稳定。这个价差只不过是回归的[残差](@article_id:348682)！我们设计了一种新的、人造的资产，其行为根据设计变得更具可预测性。

然后我们可以问：它的可预测性有多强？它是否倾向于回归到零？我们可以通过应用*另一次*回归来回答这个问题，这次是基于昨天的价差值来建模今天的价差值。第二次回归的斜率告诉我们价差[均值回归](@article_id:343763)的速度有多快。如果它回归得快，并且我们设计的价差的方差很小，我们可能就找到了一个统计套利的机会 [@problem_id:2394931]。这是一个更深层原理的优美例证：回归不仅用于被动预测；它还是一个主动建模和设计系统以使其具有理想属性的工具。

### 表征的艺术：说自然的语言

一个模型，无论是用于回归还是分类，其好坏取决于提供给它的信息。建模过程中一个关键且常被忽视的部分是选择如何向机器表征世界。世界并非自带一个方便的“特征”列表；我们必须构建它们。

让我们回到生物学。基因的[启动子](@article_id:316909)是一段DNA，其作用就像[转录](@article_id:361745)的“启动”按钮。它的活性——即它按动按钮的强度——由其A、C、G和T的序列决定。如果我们想从一个[启动子](@article_id:316909)的序列预测其活性，我们面临一个选择。我们应该要求一个连续的活性值（回归），还是简单地将其标记为“开启”或“关闭”（分类）？通常，连续值包含的信息远多于此，将其武断地分箱到类别中是对来之不易的实验数据的浪费。

但更深层的问题是，我们如何将DNA序列输入到模型中？我们不能只输入字母。答案在于将我们的生物学知识编码到特征中。我们知道，被称为“基序”（motifs）的短而特定的模式是蛋白质识别的东西。因此，我们可以使用像[卷积神经网络](@article_id:357845)（CNNs）这样旨在寻找局部模式的模型来扫描序列。我们还知道，一个基序的功能关键取决于其相对于基因起点的*位置*。位于-35位置的基序与位于-100位置的基序是不同的。这告诉我们，我们的模型*不应该*是位置不变的；我们必须构建一种方式，让它知道自己沿着DNA链的位置。这些选择——使用回归而非分类，以及内置局部性和位置依赖性的知识——被称为“[归纳偏置](@article_id:297870)”（inductive biases）。它们是我们为引导模型走向合理解决方案而做出的假设，也是在复杂的基因组学世界中构建真正有效模型的关键 [@problem_id:2723607]。

选择正确表征方式的想法甚至可以更深入。假设我们正在建模[作物产量](@article_id:345994)与肥料用量 $x$ 的函数关系。我们的模型应该直接使用 $x$，还是应该使用 $x$ 的对数 $\ln(x)$？这不仅仅是一个技术细节。这是一个关于关系本质的深刻问题。使用 $x$ 意味着每增加一公斤肥料都会产生一个加性效应。使用 $\ln(x)$ 意味着将肥料量*加倍*会产生一个一致的效果（一种乘性关系）。选择正确的变换，就是将我们模型的数学原理与我们正在研究的系统的逻辑相匹配，无论是在经济学、生物学还是物理学中 [@problem_id:3123647]。

### 反观自身：理解我们自己的工具

也许所有应用中最迷人的是，当我们把这些强大的工具反过来用于它们自身时，即使用回归和分类来分析我们自己创建的[算法](@article_id:331821)。

想象一下，你在[数值分析](@article_id:303075)中设计了一种新[算法](@article_id:331821)来计算函数的二阶[导数](@article_id:318324)。基于 Taylor 展开的理论告诉你，你的方法的误差应该随着步长 $h$ 按照一个[幂律](@article_id:320566)减少：$\text{Error} \propto h^p$。指数 $p$ 是你方法的“阶数”——衡量其质量的一个指标。你如何通过实验来验证这一点？你可以用几个不同的步长运行你的[算法](@article_id:331821)并测量误差。然后，通过绘制误差的对数与步长的对数的关系图，你应该看到一条斜率恰好为 $p$ 的直线。你可以使用线性回归从你的数值实验中估计这个斜率！最终的问题可能是一个分类问题：“我的方法的阶数是否至少为2？是或否”，但答案是通过使用回归作为一种经验验证工具找到的 [@problem_id:3106954]。

我们甚至可以将这种思维应用于机器学习本身。当我们训练像神经网络这样的复杂模型时，训练过程是在一个巨大、高维的“损失”景观中寻找最低点。事实证明，并非所有的谷底都是生而平等的。一些谷底极其尖锐和狭窄，而另一些则是宽阔、平坦的盆地。越来越多的证据表明，最终落入“平坦”最小值的模型往往能更好地泛化到新的、未见过的数据上。

那么，我们如何描述我们找到的某个最小值处的景观特征呢？景观的曲率由一个称为[Hessian矩阵](@article_id:299588)的数学对象来描述。该矩阵的[特征值](@article_id:315305)告诉我们山谷在每个方向上的陡峭程度。因此，我们可以构建一个新问题：我们可以对[Hessian矩阵](@article_id:299588)的关键属性（如其最大[特征值](@article_id:315305)）进行*回归*，以获得一个锐度的量化度量。并且我们可以根据该[特征值](@article_id:315305)是否超过某个阈值，将该最小值*分类*为“平坦”或“尖锐” [@problem_id:3106969]。我们正在使用回归和分类对我们自己的学习过程进行基础科学研究，试图理解它们为什么有效以及如何使它们变得更好。

从原子的核心到生命的进化，从我们经济的逻辑到我们自己[算法](@article_id:331821)的逻辑，回归和分类不仅仅是技术。它们是定量推理的[基本模式](@article_id:344550)。它们为我们提供了一种语言，用以构建和检验我们关于宇宙的故事，预测和塑造其未来，并最终理解我们自己。