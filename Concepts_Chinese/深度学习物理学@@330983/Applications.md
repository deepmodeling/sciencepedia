## 应用与跨学科联系

我们花时间探讨了连接物理学世界与深度学习架构的原理和机制。我们已经看到能量景观、[自旋玻璃](@article_id:304423)和对称性等概念如何为理解这些复杂[算法](@article_id:331821)的学习方式提供一个强大的视角。但物理学家从不满足于纯理论。真正的乐趣来自于看到这些思想变为现实，看着它们解决实际问题并开辟科学的新前沿。因此，让我们走出抽象，进入车间、实验室以及生命细胞的核心，见证这些思想不可思议的影响力。

### 从控制室到宇宙：学习运动规则

物理学和工程学中最古老的一个追求是理解和控制物体的运动。从行星的天体之舞到火箭着陆的精妙艺术，一切都归结于动力学。传统上，我们写下牛顿定律，考虑每一种力——重力、摩擦力、[空气阻力](@article_id:348198)——然后求解方程。但是当系统过于复杂，或者某些力未知时，会发生什么？如果你需要控制现实世界中的某个东西，而现实世界总是比我们纯净的模拟要混乱得多，那又该怎么办？

这正是[深度学习](@article_id:302462)提供一个引人入胜的新方法的地方。想象一个经典的物理难题：在移动的小车上平衡一根杆子。这个系统是出了名的不稳定；稍有差错，整个系统就会崩溃。我们可以训练一个[神经网络](@article_id:305336)作为控制器，在没有摩擦或[空气阻力](@article_id:348198)的完美[计算机模拟](@article_id:306827)中，通过数百万次试验进行学习。现在，一个问题出现了。是使用一个具有单一巨大[神经元](@article_id:324093)层的“浅层”网络更好，还是使用一个具有许多较小层的“深层”网络更好？事实证明，架构本身就体现了一种物理直觉。深层网络倾向于以分层的方式学习。第一层可能学会识别运动的简单特征，接下来的层将这些特征组合起来以理解更复杂的模式，而顶层则做出最终决定。当您将其从纯净的模拟世界转移到一个真实的、带有各种不可预测的摩擦和摆动的物理“车-杆”系统时，这种分层结构通常会使控制器表现出惊人的鲁棒性。深层网络学到了一种更通用、更“物理”的平衡行为表示，当现实偏离教科书模型时，这种表示不会崩溃 [@problem_id:1595316]。这个原理远远超出了简单的玩具。它正被用于控制聚变反应堆中的[湍流](@article_id:318989)等离子体，优化风力涡轮机叶片上的气流，以及在混乱的城市街道环境中导航[自动驾驶](@article_id:334498)车辆。在每一种情况下，深度学习不仅仅是在记忆解决方案，而是在学习它所控制系统的直观物理学。

### 炼金术士的梦想：设计和发现新材料

现在，让我们将视野从杆子和小车缩小到原子和电子的世界，即化学和[材料科学](@article_id:312640)的领域。几个世纪以来，新材料的发现都是偶然事件，是炼金术与不懈试错的结合。今天，我们梦想着在计算机上从头开始设计材料，指定我们想要的属性——比如，一种在室温下工作的[超导体](@article_id:370061)，或一种能净化我们水源的[催化剂](@article_id:298981)——然后让计算机告诉我们该使用哪些原子以及如何[排列](@article_id:296886)它们。

深度学习正在使这个梦想成为可触及的现实。我们可以用已知的庞大[材料数据库](@article_id:361753)来训练一个模型，以预测诸如[电子带隙](@article_id:331619)之类的属性，该属性决定了材料是导体、绝缘体还是[半导体](@article_id:301977)。但在这里，我们发现了一个美丽而又发人深省的故事。假设我们训练了这样一个模型，它对数千种材料都表现出色，但只要涉及元素“碲”（Tellurium），它就系统性地失败，总是预测出比实验测量值更高的[带隙](@article_id:331619)。发生了什么？是模型坏了吗？不，模型正在告诉我们一些深刻的东西。碲是一种[重元素](@article_id:336210)。对于[重元素](@article_id:336210)，绕[核运动](@article_id:364718)的电子速度如此之快，以至于爱因斯坦的[狭义相对论](@article_id:339245)效应变得重要。其中一种效应，称为自旋-轨道耦合，对电子结构有显著影响，并且通常会*减小*[带隙](@article_id:331619)。我们那个只被喂入[原子序数](@article_id:299848)等基本特征的简单模型，对[相对论](@article_id:327421)一无所知！它对支配这些原子的深层物理学视而不见，因此总是得出错误的答案 [@problem_id:1312296]。这是一个有力的教训：要想让AI成为科学发现的真正伙伴，它不能对物理学一无所知。

确实，最激动人心的发展不是要取代物理模型，而是要增强它们。例如，在[分子动力学模拟](@article_id:321141)中，描述原子间相互推拉的“[力场](@article_id:307740)”是基于简化的物理方程。这些方程中的参数，如[化学键](@article_id:305517)的刚度或分子扭转的能垒，都是经过艰苦校准的。现在，机器学习可以通过直接从高保真度的量子力学计算中学习，来生成远为准确和精细的参数。它在这样做的时候，还能尊重系统的基本物理约束，比如一个扭转的分子键必须遵守的周期性和对称性 [@problem_id:2452448]。

这种教AI理解自然界对称性的思想，是物理学和深度学习之间最深刻的联系之一。物理学家早就知道，最基本的定律就是关于对称性的陈述。例如，[能量守恒](@article_id:300957)定律是物理定律不随时间变化的直接结果。同样，实验的结果不应取决于你在房间里的位置或你面朝的方向——这是一种[平移和旋转](@article_id:348766)下的对称性。我们现在正在构建“等变”（equivariant）神经网络，这些对称性被直接融入其架构中。在模拟潜在药物分子与受体蛋白之间的相互作用时，这些模型不是在任意[坐标系](@article_id:316753)中处理相互作用，而是根据相对距离和方向，构建对旋转或平移具有内禀[不变性](@article_id:300612)的特征 [@problem_id:2455116]。在预测原子界面处材料的机械强度时，这些模型不是将原子[位置编码](@article_id:639065)为简单的坐标列表，而是使用一种能自然尊重三维空间对称性的语言——[张量](@article_id:321604)和[球谐函数](@article_id:357279)的数学——来编码 [@problem_id:2777670]。通过教我们的人工智能像物理学家一样看待世界，我们构建的模型不仅更准确，而且泛化能力也更好，因为它们学会了游戏的基本规则。

### 解开生命之书：折叠与功能的物理学

也许，物理学启发的深度学习最引人注目的应用是在生物学领域。每个生物都由蛋白质构成，这些微小的分子机器执行着生命中所有关键任务。而蛋白质的功能由其复杂的三维形状决定。蛋白质是一条长长的氨基酸链，半个世纪以来的巨大挑战，就是预测这条链如何自发地“折叠”成一个独特的、有功能的结构。一条氨基酸链可能折叠的方式数量，比宇宙中的原子数量还要多出天文数字量级。然而，在我们的身体里，它们在不到一秒的时间内就能正确折叠。这是怎么做到的？

几十年来，我们最好的计算方法是“[同源建模](@article_id:355618)”：如果你想知道你的蛋白质的结构，你首先必须找到一个具有已知结构的相关蛋白质作为模板。这就像试图建造一个新的汽车引擎，但只允许使用来自另一个旧引擎的蓝图。如果你的蛋白质来自一个完全新的、没有已知亲缘的家族，那你就束手无策了 [@problem_id:1460283]。

随后，一场以 [AlphaFold](@article_id:314230) 等系统为代表的革命到来了。这些深度学习模型完成了许多人认为不可能完成的任务。其核心是一种深刻的物理洞察力，并被数据的力量所放大。这种洞察力就是协同进化。如果蛋白质链中的两个氨基酸在序列上相距很远，但在最终折叠结构中却始终紧密接触，那么它们必须以一种相关的方式[共同进化](@article_id:312329)。一个氨基酸的突变如果破坏了这种接触，通常必须由另一个氨基酸的突变来补偿，以维持蛋白质的功能。通过在[多序列比对](@article_id:323421)（MSA）中分析同一个蛋白质在数千个不同物种中的序列，AI可以检测到这些[统计相关性](@article_id:331255)。这些相关性是折叠物理学的幽灵般的回响，提供了一组成对的距离约束——就好像蛋白质的进化史在低声提示哪些氨基酸是邻居 [@problem_id:2592987]。

但这只是故事的一半。然后，AI将这些线索输入到第二个模块中，该模块就像一位杰出的虚拟物理学家。这个模块知道化学的基本规则：键长是固定的，键角是受约束的，原子不能重叠。它拥有一个氨基酸链的几何表示，该表示是完全“可微的”，这意味着整个结构构建过程可以通过梯度下降进行优化。该系统通过寻找能最好地同时满足来自MSA的进化线索和[立体化学](@article_id:345415)基本定律的原子[排列](@article_id:296886)，来基本上“三角测量”出最终的3D结构 [@problem_id:2592987] [@problem_id:1460283]。

这种方法的力量令人叹为观止。它可以解决旧方法完全无法处理的问题。考虑一种本质上无序的蛋白质——一条松软、摇摆的链——只有在与伴侣[蛋白质结合](@article_id:370568)时才会形成稳定的形状。像刚体对接这样的经典方法，试图将两个预先存在的刚性结构像拼图一样拼在一起，但这种方法会完全失败，因为无序蛋白质一开始就*没有*刚性结构。然而，一种[协同折叠](@article_id:342197)方法仅需两种蛋白质的序列，就能预测最终复合物的结构，在将一个蛋白质对接到另一个蛋白质上的同时进行折叠，这正反映了真实的物理过程 [@problem_id:2107923]。

然而，这次旅程以一个来自合成生物学领域的、关于科学谦逊的最后且至关重要的一课结束。想象一下，我们想改造一种细菌来生产一种有用的蛋白质。蛋白质的生产速率由一个叫做[核糖体结合位点](@article_id:363051)（RBS）的短[基因序列](@article_id:370112)控制。我们可以用数千个RBS序列来训练一个深度神经网络，以预测它们的强度。这个网络变得异常出色，在与其训练数据相似的序列上达到了非常高的准确率。同时，我们也可以基于该过程的物理化学原理——即遗传信息与[核糖体](@article_id:307775)之间的结合能——建立一个简单得多的“机理”模型。这个基于物理的模型在初始数据上的准确性较低。但是现在，我们在一些真正新颖的、以AI从未见过的方式设计的RBS序列上测试这两个模型。结果是惊人的：那个全能的深度网络惨败，准确率暴跌。它学到的是表面的统计模式——“捷径”——而这些并非因果关系。那个更简单、基于物理的模型，虽然不那么华丽，却被证明要稳健得多，因为它捕捉到了相互作用的实际因果物理。它的预测经受住了考验，因为物理定律不会改变 [@problem_id:2773028]。

而这也许是最重要的领悟。[深度学习的物理学](@article_id:306928)，不是一个新技术取代旧科学的故事。它是一个强大而激动人心的对话的故事。物理学提供了基准真相、原理、对称性和约束。深度学习提供了一个前所未有的强大工具包，用以发现模式和解决我们以前无法解决的方程。发现的未来不在于二选一，而在于将它们编织在一起，形成一种全新且更强大的理解宇宙的方式。