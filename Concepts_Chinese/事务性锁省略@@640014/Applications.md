## 应用与跨学科联系

在我们之前的讨论中，我们揭示了事务性锁省略背后的巧妙原理：一种下注的艺术。我们不再是每次都支付传统锁的代价，而是推测性地执行一段临界区代码，赌一把没有其他线程会来干扰。如果我们赌赢了，就能获得丰厚的性能回报。如果我们输了，硬件会优雅地中止我们的尝试，不留任何痕迹，然后我们回退到更安全、更传统的方法。

这个想法，一种乐观与实用主义之间的优美舞蹈，远不止是理论上的好奇。它是一个强大的工具，在整个计算机科学领域掀起了涟漪，改变了我们构建软件基础的方式。在本章中，我们将穿越这些不同的领域——从[操作系统](@entry_id:752937)的引擎室到[数据结构](@entry_id:262134)的优雅蓝图，再到现代编译器的自动化工厂——去看看这个单一而强大的概念是如何被应用的。我们将看到，这项技术的真正天才之处不仅在于乐观的快速路径，还在于当我们赌博失败时，那些接住我们的回退机制的深思熟虑的工程设计。

### 引擎室：[操作系统](@entry_id:752937)与[内核设计](@entry_id:750997)

没有什么地方比[操作系统](@entry_id:752937)（OS）的核心更能体现并发的挑战了。内核是一个熙熙攘攘的线程大都市，所有线程都在争夺共享资源——调度器队列、[内存映射](@entry_id:175224)、网络缓冲区。在这里，每一纳秒的同步开销都至关重要，这使其成为事务性锁省略的天然试验场。

[并发编程](@entry_id:637538)中的一个经典难题是**[读者-写者问题](@entry_id:754123)**。想象一个共享信息，许[多线程](@entry_id:752340)需要读取，但只有少数需要写入。传统的解决方案，即[读写锁](@entry_id:754120)，允许多个读者并发进行，但确保任何写者都拥有独占访问权。虽然这比简单的[互斥锁](@entry_id:752348)要好，但读者仍然必须执行获取和释放读锁的仪式，这本身就带有开销。

事务性锁省略提供了一个惊人优雅的解决方案。为什么那些不改变任何东西的读者，还要费心去处理锁呢？取而代之的是，每个读者可以开始一个事务，读取数据，然后提交。这个过程快如闪电，并且不需要与其他读者进行显式协调。读者推测失败的唯一情况是当一个写者出现时。为了让这行得通，写者的加锁协议必须与读者的事务集成。标准模式是写者首先获取一个传统的写锁。一个关键细节是，[推测执行](@entry_id:755202)的读者必须在其事务中读取这个锁变量的状态。这个动作将读者“订阅”到这个锁上；如果一个写者随后修改了这个锁，硬件会检测到读者事务读集上的冲突，并自动中止读者的事务。然后，读者回退到传统的、较慢的获取读锁的路径，该路径会正确地等待写者完成。[@problem_id:3675658]

但是，在读者泛滥的情况下会发生什么？如果一个写者到达，它可能会被迫等待，因为源源不断的新读者在其回退路径上获取它们的锁。为了防止这种“写者饿死”，一个健壮的系统必须在其回退路径中使用一个*公平的*、基于队列的锁，以保证一旦有写者在等待，它最终会得到执行的机会。[@problem_id:3687724]

同样这种“推测并回退”的哲学几乎可以扩展到内核中的任何短临界区。考虑一个需要更新共享计数器或修改小型[数据结构](@entry_id:262134)的系统调用。内核可以将此更新包装在一个事务中。如果成功，锁就被“省略”了，操作很快。如果由于争用而中止，该怎么办？无限重试？那将是一场灾难。在高争用下，线程可能会陷入“[活锁](@entry_id:751367)”，永远在中止对方的事务而无法取得任何进展。

解决方案是**有界重试策略**。系统可能会尝试该事务，比如说，三次。如果所有尝试都失败了，它就放弃推测，回退到获取[自旋锁](@entry_id:755228)。性能模型显示，少量的重试次数通常是最佳的。它给了系统一个赢得推测赌注的机会，而如果争用真的很高，又不会浪费太多时间。[@problem_id:3663946] 更先进的实现甚至使用一个共享的“回退中”标志。当一个线程被迫走慢速的、加锁的路径时，它会设置这个标志。推测性事务被设计为读取此标志，如果它被设置，就立即中止，从而防止它们在锁被持有时无用地空转，并帮助系统更快地消除争用风暴。[@problem_id:3663946]

无论是保护内核路由表[@problem_id:3663949]还是一个简单的计数器，模式都保持不变，并揭示了一个深刻的真理：不要在事务*内部*获取锁，因为这有死锁的风险。相反，事务路径和加锁路径必须是两个截然不同的世界，通过让快速路径推测性地读取慢速路径所写入的锁变量来进行协调。

### 架构师：编译器与运行时

一个聪明的内核程序员手工打造这些事务模式是一回事；而让这个过程自动化则是另一回事。这是编译器和语言运行时的领域，它们扮演着架构师的角色，自动生成和优化我们编写的代码。

一个执行[自动并行化](@entry_id:746590)的现代编译器可以分析一个程序，找到一个循环，其中每次迭代大部分是独立的，但包含一个由锁保护的小临界区，并自动对其进行转换。它不是生成简单的加锁代码，而是可以生成 TLE 的复杂重试并回退逻辑。编译器甚至可以建立一个性能模型，估算事务中止的概率（$p$）以及成功（$c+b$）、中止（$a$）和回退（$l$）的成本。利用这些，它可以计算[并行化](@entry_id:753104)循环的预期吞吐量，并决定这种转换是否值得。[@problem_id:3622654]

这个概念在自适应的、即时（JIT）编译器的世界中达到了顶峰，这些编译器存在于像 Java [虚拟机](@entry_id:756518)或 .NET Core 运行时这样的托管运行时中。这些系统不是静态的；它们是活的。它们在程序运行时观察它。它们可以部署轻量级的性能分析钩子来测量特定锁上的真实世界争用率（$\kappa$）。利用这些实时数据，运行时可以动态地进行[成本效益分析](@entry_id:200072)。

TLE 尝试的预期成本是成功和失败场景的混合：$E_{\text{SLE}} = (1 - \kappa) \cdot t_{\text{tx}} + \kappa \cdot (t_{\text{abort}} + t_{\text{lock}})$，其中 $t_{\text{tx}}$、$t_{\text{abort}}$ 和 $t_{\text{lock}}$ 分别是成功事务、中止事务和回退锁路径的成本。运行时可以求解出 $E_{\text{SLE}}  t_{\text{lock}}$ 的盈亏[平衡点](@entry_id:272705)。对于一组实际的时间数据，此计算表明只有当争用率 $\kappa$ 低于 $0.2$ 时，TLE 才是有利可图的。[@problem_id:3639169]

如果运行时观察到某个“热”锁的争用率已降至此阈值以下，它可以触发动态重编译。它会生成一个使用 TLE 的新的、优化的代码版本，并使用一种称为[栈上替换](@entry_id:752907)（On-Stack Replacement, OSR）的技术，无缝地将正在运行的线程切换到这个新版本。为防止“颠簸”——过于频繁地来回切换——它使用滞后效应，为去优化设置一个稍高的阈值。如果它检测到某个锁行为不当（例如，导致过多中止或包含非事务安全的操作），它可以立即去优化回安全的加锁版本，甚至将该锁“列入黑名单”，禁止未来的 TLE 尝试。这种动态的、数据驱动的方法是智能系统设计的缩影。

### 基础：高级[数据结构](@entry_id:262134)

让我们更深入地探讨，研究那些构建我们数据的算法本身。[并发数据结构](@entry_id:634024)的设计以其正确性的难以保证而臭名昭著。为确保像[平衡树](@entry_id:265974)这样的复杂结构的正确性所需的加锁协议可能复杂到令人费解。

考虑 B 树，大多数数据库和文件系统背后的主力。一次插入操作可能需要一次“节点分裂”，这是一项复杂的手术，涉及修改节点本身、其父节点以及创建一个新的兄弟节点。以并发方式执行此操作的传统方法涉及在遍历树时采用一种谨慎的“锁耦合”或“手递手”加锁纪律，这既复杂又可能限制并发性。

[硬件事务内存](@entry_id:750162)提供了一个诱人地简单的替代方案。为什么不把整个操作——向下遍历树、可能的分裂以及对父节点的更新——都放在一个单一的、巨大的事务中呢？[@problem_id:3211713] 如果事务提交，这个复杂的多步更新对系统的其余部分来说，就表现为一个单一、不可分割的原子事件。这种纯粹的概念上的简单性是一个巨大的胜利。多个细粒度锁的复杂舞蹈被一对简单的 `XBEGIN`/`XEND` 所取代。

当然，这个赌注可能并不总是能赢。这样大的事务可能会与另一个事务冲突，或者可能超出硬件跟踪推测状态的能力。因此，一个健壮的设计仍然必须包括一个回退路径。如果宏大的事务策略在几次尝试后失败，线程必须恢复到一种更悲观但保证能工作的策略——比如获取整个树的单个全局锁，并以老式的方式执行插入。这种双管齐下的方法让我们两全其美：在争用低时享有事务的性能和简单性，在争用高时则有全局锁的正确性保证。

### 了解局限：失败模式与系统交互

对任何技术的深刻理解不仅来自于知道它能做什么，还来自于欣赏它*不能*做什么。[事务内存](@entry_id:756098)功能强大，但并非魔法。它的局限性界定了其应用范围，并迫使我们进行更巧妙的设计。

一个硬性限制是**容量**。跟踪事务推测性读写的硬件是有限的。一个复杂[状态机](@entry_id:171352)中的状态转换可能需要更新[分布](@entry_id:182848)在许多缓存行上的数十个内存位置。如果这个内存足迹超过了硬件的容量，事务将确定性地中止，每次都是如此。重试是徒劳的。唯一正确的设计是检测到这种持续的失败，放弃推测，并回退到传统锁。[@problem_id:3645914]

一个更根本的限制是**不可撤销性**。事务可以回滚对内存的更改，但它无法回滚与外部世界的交互。你无法“取消发送”一个网络数据包或“取消写入”一个设备寄存器。任何 I/O 操作或系统调用对事务来说都是一剂毒丸。如果被执行，它会使事务的效果不可逆转，从而打破原子性保证。

处理这个问题的正确模式有两种。最简单的是仅在事务成功提交*之后*执行 I/O。一种更复杂的方法是**延迟 I/O**。事务不是直接执行 I/O，而是简单地将一个请求写入共享的内存中队列。这是一个纯粹的内存操作，并且是完全事务性的。然后，一个独立的、专门的工作线程可以安全地从队列中取出这些请求并执行实际的 I/O，与事务完全[解耦](@entry_id:637294)。[@problem_id:3645914]

最后，我们必须考虑到我们的程序并非在真空中运行。硬件本身还有其他层次，比如**硬件虚拟化**。当在[虚拟机](@entry_id:756518)内运行的客户机[操作系统](@entry_id:752937)试图使用事务性锁省略时会发生什么？[虚拟机](@entry_id:756518)管理程序（hypervisor）或[虚拟机监视器](@entry_id:756519)（virtual machine monitor）调节着客户机对物理硬件的访问。在原生机器上可能微不足道的事件，如定时器中断或页错误，可能会导致“VM 退出”——一个从客户机到[虚拟机](@entry_id:756518)管理程序的重量级转换。至关重要的是，从处理器的角度来看，VM 退出是一个必须处理的不可中断事件。处理器的规则很简单：在处理此类事件之前，任何活动事务都必须中止。其后果是深远的：在虚拟机内运行会引入一个新的、隐藏的事务中止源。例如，频繁的定时器中断会严重破坏事务性工作负载的性能，将一个稳赢的赌注变成一个持续的亏损。[@problem_id:3646299] 这揭示了虚拟化并非一个完全透明的层；它的存在可能对高级硬件特性产生微妙而显著的性能影响。

### 优雅的赌博

我们的旅程表明，事务性锁省略不仅仅是一个单一的技巧；它是一种设计哲学。它认识到在许多并发场景中，冲突是例外，而非规则。通过对这种良好状况进行乐观的赌注，我们可以构建更简单、更快、更具可扩展性的系统。

然而，真正的美在于其二元性。乐观的快速路径的力量与悲观回退的稳健、有原则的工程设计相匹配。正是这种理解，即你必须限定重试次数，你需要一个公平的锁来防止饿死，I/O 必须被延迟，以及你的[事务内存](@entry_id:756098)足迹不能是无限的。正是这种在推测与保证、乐观与悲观之间的舞蹈，代表了构建高性能并发系统的艺术。这是硬件和软件如何协同进化的完美例证，为[并行化](@entry_id:753104)的根本挑战提供了越来越优雅的解决方案。