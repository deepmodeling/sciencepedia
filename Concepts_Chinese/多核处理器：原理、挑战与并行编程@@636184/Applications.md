## 应用与跨学科联系

我们已经穿越了支配多核世界的原理，一个并行思维的世界。但这一切究竟是为了什么？这种新架构是否只是像更大的引擎使汽车更快一样，让我们的计算机变得更快？你可能会惊讶地发现，答案是一个响亮的“不”。多核处理器不是一个更大的引擎；它是一种完全不同类型的交通工具。它不像一辆直线加速赛车，而更像一个管弦乐队。一个独奏大师可以演奏得惊人地快，但一个管弦乐队可以创造出一部交响曲。就像管弦乐队一样，多核处理器的力量不是通过简单地告诉每个人都演奏得更快来实现的；它需要一位杰出的指挥家——一个聪明的算法——来协调演奏者，管理他们的互动，并从许多独立的努力中引导出一个美丽、连贯的成果。

本章是关于那种指挥的艺术和科学。我们将看到并行的挑战如何迫使我们以全新的方式看待问题，从安排医院手术到模拟星系的舞蹈。我们将发现，多核计算的原理并不仅限于计算机科学；它们反映了关于组织、瓶颈和效率的基本真理，这些真理在我们周围随处可见。

### 调度艺术：下一个是谁？

想象你正在管理一家拥有几间顶级手术室的医院。你需要执行许多手术，但有一个问题：你只有一套特定且不可或缺的机器人手术系统。这个系统是一个共享资源，一次只有一个手术能使用它。手术室是你的“核心”，手术是你的“线程”，而机器人系统是保护“临界区”的“锁”。即使有三间手术室，如果你安排的所有五台手术都同时需要机器人，那么将有四台手术会闲置等待。整个医院的效率突然之间不再取决于房间的数量，而是取决于那台机器人的排队情况。这就是**竞争**的幽灵，也是[并行编程](@entry_id:753136)的第一个巨大挑战。

所以，作为管理者，你必须决定顺序。你应该让最长的手术先做，以“把它了结”吗？或者也许是最短的？这不仅仅是一个后勤难题；它是[操作系统](@entry_id:752937)设计中的一个经典问题。事实证明，如果你的目标是最小化每位患者等待手术完成的平均时间，[最优策略](@entry_id:138495)被证明是总是安排**[最短作业优先](@entry_id:754796)**。通过清理掉快速的任务，你可以减少队列中所有其他任务累积的总等待时间。这个简单而强大的思想，被称为[最短作业优先](@entry_id:754796)（SJF）调度，是[操作系统](@entry_id:752937)如何管理对共享资源（从文件到网卡）的竞争的基石之一 [@problem_id:3659902]。

当然，现实世界要混乱得多。一个任务不仅仅需要“时间”；它需要特定数量的内存，一定的网络带宽等等。将[任务调度](@entry_id:268244)到核心上变成了一个多维度的谜题。这类似于经典的“[装箱问题](@entry_id:276828)”：你如何将一堆不同大小和重量的物品装入有限数量的箱子里？[操作系统调度程序](@entry_id:636258)每天都面临这个问题，试图将具有不同内存占用和执行时间需求的人物，装配到具有固定内存和时间预算的核心上。为了解决这个问题，[调度程序](@entry_id:748550)通常使用聪明的[启发式方法](@entry_id:637904)，比如“最佳适应递减”——首先处理最大、最耗费资源的任务，并尝试将它们放在能够留下最少剩余、碎片化资源的核心上。这是管理现代计算机复杂资源景观的一种实用、有效的策略 [@problem_id:3251662]。

### 驯服依赖：无形的编排

到目前为止，我们的图景假设任务是独立的，就像一系列不相关的手术。但如果一个任务的输出是另一个任务的输入呢？如果你在建好墙壁之前无法建造屋顶怎么办？世界充满了这样的依赖关系，它们形成了一种无形的编排，我们的[并行算法](@entry_id:271337)必须遵守。

计算机科学家使用**[有向无环图 (DAG)](@entry_id:748452)**来可视化这些关系，其中每个节点是一个任务，从任务A到任务B的每个箭头意味着“A必须在B开始之前完成”。在多核处理器上调度任务就变成了一个遍历这个图的游戏。[调度程序](@entry_id:748550)可以执行任何其前驱任务都已完成的任务。一个常见而有效的策略是*[列表调度](@entry_id:751360)*，我们首先创建一个尊重依赖关系的所有任务的有序列表（一个“[拓扑排序](@entry_id:156507)”），然后随着核心变为空闲，贪婪地从这个列表中分配任务给它们 [@problem_id:2399303]。

这个概念不仅仅是一个抽象；它是高性能科学计算的日常。考虑解决一个包含数百万个[线性方程](@entry_id:151487)的系统的艰巨任务，这是从天气预报到飞机设计等一切事物的核心问题。像[高斯消元法](@entry_id:153590)这样的算法可以被分解成一个复杂的小操作的DAG [@problem_id:3135924]。这个DAG的结构不是任意的；它*就是*算法的结构。高性能计算的真正艺术在于重新构造这些经典算法，以创建具有更短“关键路径”（最长的依赖链）和在每个阶段有更多独立任务的DAG，从而暴露出更多可以并行完成的工作。

### 重新思考算法：发现内在的并行性

多核革命最深远的影响在于算法本身的设计。我们不能再仅仅发明一个串行配方，然后希望[调度程序](@entry_id:748550)能找到一种并行运行它的方法。我们必须问一个更深层次的问题：这个问题*本质上*是并行的吗？

考虑找到连接一组城市的最便宜道路网络的问题——一个[最小生成树 (MST)](@entry_id:261663)。一个经典的方法，[Prim算法](@entry_id:276305)，是根本上串行的：它从一个城市开始，贪婪地一次一条边地扩展网络。这就像从一个单一的种子开始生长晶体。但另一种方法，[Borůvka算法](@entry_id:264999)，采用了一种奇妙的并行方法。它以每个城市作为其自己的孤立组件开始，并在每个阶段指示每个组件找到其连接到*不同*组件的最便宜的连接。所有这些连接都同时被添加，合并组件。这就像让几十个晶体同时生长，然后让它们融合在一起。关键在于，在每个阶段，每个组件所做的工作都完全独立于其他组件，使得该算法天然适合并行执行 [@problem_id:1484812]。

这种并行迭代的[范式](@entry_id:161181)无处不在。想象一下，在一个庞大的社交网络中识别朋友集群（寻找连通分量）。一个优美的并行方法是让每个人都以自己独特的ID作为他们的“集群ID”开始。然后，在同步的回合中，每个人都查看他们直接朋友的集群ID，并采用他们看到的最小ID。这种“八卦”重复进行。关于集群中最小ID的信息像波一样在其中传播，最终，同一集群中的每个人都会就同一个最小ID达成一致。这种迭代的、局部通信的、[全局收敛](@entry_id:635436)的过程是在并行机器上解决大规模图问题的强大模式 [@problem-id:3223789]。

然而，并行性很少是全有或全无的事情。当我们[并行化](@entry_id:753104)一个经典算法如`build_heap`（[堆排序](@entry_id:636560)的关键部分）时，我们发现可用并行量随着算法的运行而变化。在概念树结构的底层，有许多独立的子问题可以同时处理。但随着我们向根部推进，问题合并，依赖增加，工作变得更加串行。这揭示了[阿姆达尔定律](@entry_id:137397)的一个实际方面：任何[并行算法](@entry_id:271337)的加速比最终都受其最串行部分的限制 [@problem_id:3239850]。

### 现代科学的交响曲：融会贯通

这些概念在计算科学的宏大挑战中最为关键，也被最巧妙地结合在一起。考虑一个分子动力学模拟，它通过计算数百万个单个原子的力和运动来模拟材料的行为。这是一个复杂度惊人的问题，解决它需要并行技术的交响乐 [@problem_id:2422641]。

*   **在最精细的层面上**，根据作用在每个原子上的力来更新其位置的简单行为是一个**[数据并行](@entry_id:172541)**任务。相同的计算被应用于数百万个原子，这是单个核心内SIMD（单指令，多数据）单元的完美工作，它就像一个对整个数据排 barking 单一命令的教官。

*   **在下一个层面上**，计算力要困难得多。一个原子上的力取决于其邻居的位置。虽然对每对原子的计算是一个独立的**任务**，但许多这样的任务需要更新*同一个*原子上的总力，从而产生竞争条件。这让我们回到了医院的类比：我们需要[原子操作](@entry_id:746564)或其他同步方案来确保最终的力被正确求和。

*   **在最宏大的尺度上**，如果模拟对于一台计算机来说太大了，3D空间被划分为[子域](@entry_id:155812)，每个[子域](@entry_id:155812)被分配给集群中的不同计算机。这些机器并行运行，通过**消息传递**接口（如MPI）定期通信关于其边界附近原子的信息。

这种多层次的方法——同时利用[数据并行](@entry_id:172541)、[任务并行](@entry_id:168523)和[分布](@entry_id:182848)式并行——是我们解决当今最大科学问题的方式。底层[数值算法](@entry_id:752770)的选择也至关重要。在许多模拟中，需要[求解大型线性系统](@entry_id:145591)。在这里，像分块[Householder QR分解](@entry_id:750388)这样的算法比基于[Givens旋转](@entry_id:167475)的算法要受欢迎得多。这并不是因为一个比另一个“更并行”，而是因为它具有更高的**计算强度**。它被设计为对从内存中提取的每个字节数据执行许多浮点运算。在现代CPU和GPU上，计算速度快但内存访问慢，这是性能的秘诀。这样的算法就像一个厨师，精心计划以最大限度地减少去食品储藏室的次数，用台面上已有的食材做尽可能多的工作 [@problem_id:3549918]。

最后，这首交响曲的指挥必须着眼于硬件的物理现实。当[操作系统调度](@entry_id:753016)工作时，它不仅必须考虑速度，还必须考虑[功耗](@entry_id:264815)。将一个作业分散到许多核心上可能看起来很有效，但这可能需要让它们全部以低效的低频率运行。有时，将任务仅在少数核心上以较高频率运行，并将其他核心置于深度睡眠状态，可能更节能。这个决定涉及在开关晶体管消耗的*动态[功耗](@entry_id:264815)*和它们仅仅因为通电而浪费的*泄漏功耗*之间的微妙权衡。在某些情况下，一个临界的泄漏功耗阈值决定了是整合工作还是分散工作更好 [@problem_id:3639071]。这使我们的旅程回到了起点，从抽象的算法思想回到电子在硅中流动的物理学，提醒我们，在多核处理器的世界里，指挥家不仅要懂音乐，还要懂乐器本身。