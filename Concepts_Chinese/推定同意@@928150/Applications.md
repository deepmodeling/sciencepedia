## 应用与跨学科联系

在探寻了推定同意的哲学和法律基础之后，我们可能会倾向于将其视为一个简洁、抽象的原则。但科学不仅仅是原则的集合；它是一种观察世界运作的方式。像推定同意这样的概念，其真正的美妙之处并非体现在教科书的定义中，而是在于它塑造我们生活的那些凌乱、复杂且往往深刻的方式中。它是一种工具，一个社会用来处理个人自主权与集体利益交汇处一些最棘手问题的伦理框架。现在，让我们来探索这个理念在现实生活中的应用，从它最著名的应用领域走向技术和人工智能的前沿。

### 生命之礼：器官捐献

推定同意最经典且争议最广的应用是在死后器官捐献领域。在这里，这一原则受到了最直接的考验：一个社会是否可以推定个人愿意捐献其器官以拯救他人生命，除非该个人已明确表示反对？

不同国家对此问题的回答各不相同，从而在法律和伦理领域形成了一场引人入胜的自然实验。许多国家，如德国，实行“选择加入”或明确同意的原则。在这里，默认设置为不捐献。个人必须采取积极步骤——如携带捐献卡或加入登记系统——才能成为捐献者。这种模式将最高度的重视置于明确的个人授权之上，与那些强调身体完整性神圣不可侵犯、要求在任何死后干预前必须有明确许可的伦理和宗教传统紧密契合[@problem_id:4853080]。

相比之下，像西班牙这样的国家长期以来实行“推定同意”或“选择退出”的原则。在这个体系中，每位公民默认被视为潜在的捐献者。行动的责任发生了转移：一个人必须登记其反对意见才可被排除在外。然而，事实比表面看起来更为微妙。西班牙享誉世界的成功并非建立在一个“硬性”选择退出系统之上，即国家的推定可以压倒一切。相反，它是一种“软性”选择退出模式。在实践中，医疗团队总是会与悲痛的家属进行协商。虽然家属可能没有正式的法律否决权，但他们的意愿几乎总是受到尊重。这种法律上推定支持捐献与充满同情、以家庭为中心的沟通相结合的方式，被证明非常有效[@problem_g_id:4475902]。英国近来也遵循了这条路径，其组成国采取了类似的“软[性选择](@entry_id:138426)退出”或“被视为同意”的框架，并为未成年人、缺乏决策能力者和近期访客制定了具体的排除条款[@problem_id:4475902] [@problem_id:4853080]。

这些模式之间的张力在医院病床边变得尤为突出。想象一下，一位病患根据推定同意法从未选择退出捐献。他同时拥有一份具有法律[约束力](@entry_id:170052)的预立医疗指示，声明希望避免长期的生命支持。他的家属在悲痛之中坚称，这位病患从不希望成为捐献者。正确的做法是什么？最符合伦理和法律的方法是“分开处理”这两个决定。病患关于其自身医疗护理的意愿，如其预立医疗指示中所述，是至高无上的，必须首先得到尊重。撤除生命维持治疗的决定必须完全独立于任何器官捐献的可能性。只有在做出该决定之后，才能由训练有素的专家进行一次独立的、精心管理的关于捐献的对话，他可以解释法律、倾听家属的意见，并寻找任何关于病患意愿的真实证据，同时确保捐献过程绝不主导神圣的临终关怀过程[@problem_id:4359251]。

### 从身体到大数据：数字时代的公共卫生

你可能认为推定同意的逻辑仅限于生与死的深刻领域。但仔细观察，你会在一个完全不同且极其现代的领域看到同样的思想基因在起作用：公共卫生数据。

考虑一下在疫情爆发期间追踪新疫苗有效性的挑战。为此，公共卫生机构需要知道谁接种了疫苗，以及谁后来因感染而住院。答案在于连接两个独立的数据库：免疫接种登记系统和医院入院记录。这个过程，即数据关联，如果没有在个体层面上匹配记录是不可能完成的。但如何在不征求每个人明确许可的情况下做到这一点呢？在公共卫生紧急情况下，这项任务在后勤上是不可能完成的。

在这里，我们看到了一个与器官捐献惊人相似的框架的出现。虽然明确同意（选择加入）是许多数据使用的黄金标准，但公共卫生法通常允许另外两种依据。一种是“选择退出”系统，即公民被告知他们的数据将为了公共卫生监测而被关联，并被给予一个清晰、便捷的拒绝方式。另一种是“公共利益”依据，即如果法律授权、为保护群体健康所严格必需，且合乎比例（即公共利益远大于隐私风险），则可以在没有个人同意的情况下进行关联。为确保合乎比例，强有力的保障措施至关重要，例如使用隐私保护技术来加密标识符、进行正式的影响评估，并寻求伦理监督[@problem_id:4569730]。这表明，一个默认行动（在此案例中，为共同利益进行数据关联）与拒绝权（选择退出）相平衡，或由更高的集体需求来证明其合理性的核心理念，为现代预防医学提供了至关重要的工具。

### 前沿领域：智慧城市与人工智能伦理

推定同意的影响范围甚至更广，延伸到我们日益数字化和自动化世界的结构之中。它的原则正在我们城市的设计以及帮助运营我们医院的人工智能中经受压力测试。

想象一个公共广场配备了信息物理系统——一个由传感器和执行器组成的网络，用于监测人群流量和声音水平，并调节灯光和扬声器以提高公共安全和舒适度。该系统使用摄像头进行总体人群计数（而非面部识别），并使用蓝牙信标来追踪设备密度。这些数据被输入一个“数字孪生”，即一个用于模拟的广场虚拟模型。你仅仅身处广场之中就足以构成同意吗？对于像为安全而进行的总体人群计数这样最小化的、非识别性的功能，可以认为同意已由情境所默示，或者更正式地说，该处理在合法的公共利益下是正当的[@problem_id:4220276]。

然而，当同一系统使用你手机的蓝牙信号进行微定向广告时，伦理立场就发生了巨大变化。在这里，“选择退出”模式面临着一个严峻的挑战。如果选择退出的唯一方法是绕行十分钟，这种选择真的是自由的吗？如果一个“参与”的开关将必要的安全功能与侵入性的广告捆绑在一起，这种同意真的是具体且知情的吗？根据像GDPR这样的现代数据保护法，答案是否定的。对于像广告这样敏感、非必要的处理，需要明确的、细化的、选择加入的同意。选择退出系统在法律上或伦理上都不是一个有效的替代方案[@problem_id:4220276]。这阐明了一个关键的边界条件：选择退出框架只有在默认行动明确是为了公共利益，且拒绝的能力简单且无重大不利后果时，才是可辩护的。

这引领我们走向这些思想的终极综合，体现在医学人工智能的伦理学中。一家医院希望部署一个在后台静默运行的人工智能系统，分析患者数据以预测临床恶化。该系统将对所有患者默认开启，患者可以选择退出。这在伦理上是否可以接受？

答案并非简单的“是”或“否”。相反，它是一个严格的伦理演算。带有选择退出选项的默示同意可以被证明是正当的，但*前提是*必须满足一套严格的条件。首先，必须证明该人工智能能提供净临床效益，且风险不超过最小风险，这不仅针对普通患者，也针对所有人口亚群（公正原则）。其次，对于选择退出的患者，必须存在一个真实、可行的人工替代方案，以确保他们的选择不会导致次等的医疗服务（自主原则）。第三，选择退出的过程必须简单且低阻力。最后，所使用的数据必须仅用于临床护理，未经单独、明确的同意，不得用于如训练不相关的商业模型等次要用途[@problem_id:4436674]。

在这里，在人工智能伦理的前沿，我们看到所有线索汇集在一起。选择退出模式不是一个漏洞或捷径。它是一个被审慎界定的社会契约。它可以成为促进善举的强大工具，无论是实现拯救生命的器官移植、促进至关重要的公共卫生研究，还是驱动一个安全网式的人工智能。但它只有在建立在已被证明的效益、最小的风险、真实的选择和对个人坚定不移的尊重的基础之上时，才是合法的。从一张器官捐献卡到一个人工智能算法的旅程，揭示了这个简单而深刻理念的持久力量：我们作为一个社会，如何平衡个体的选择与多数人的需求。