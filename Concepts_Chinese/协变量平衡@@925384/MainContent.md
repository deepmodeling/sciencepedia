## 引言
在几乎所有实证科学领域，最终目标都是理解因果关系。虽然[随机对照试验 (RCT)](@entry_id:167109) 是建立因果关系的黄金标准，但执行起来往往不切实际或不符合伦理。因此，研究人员必须依赖观测数据，而观测数据存在一个根本性问题：我们希望比较的群体往往从一开始就有所不同。这个问题被称为混杂 (confounding)，它会严重偏倚我们的结论，使我们无法区分[处理效应](@entry_id:636010)与个体间预先存在的差异。本文直面因果推断中的这一核心挑战，探讨了通过实现协变量平衡，从混乱的真实世界数据中创造“公平比较”所使用的原则和方法。

首先，在“原则与机制”部分，我们将深入探讨混杂问题，并引入倾向性得分作为一种巧妙的解决方案，解释匹配和加权等技术如何近似 RCT 的平衡状态。我们还将介绍评估平衡是否真正实现的关键且常被误解的过程。随后，在“应用与跨学科联系”部分，我们将看到这些原则的实际应用，展示对协变量平衡的追求如何在临床医学、基因组学和社会科学等不同领域成为一个统一的主题，使研究人员能够得出更可信的因果结论。

## 原则与机制

### 寻求公平比较：混杂与理想实验

假设我们想知道一个新的工作场所戒烟计划是否真的能帮助人们戒烟。一个简单的方法是比较参加该计划的员工与未参加者的戒烟率。但稍加思索就会发现一个深层问题。谁最有可能报名参加这样的计划？也许是那些最积极主动的人，他们本来就更有可能戒烟。或者，也许是烟瘾最重的人，他们迫切需要帮助，但戒烟难度也最大。无论哪种情况，这两个群体——计划参与者和非参与者——很可能从一开始就不同。这种初始差异是我们数据中的一种污染，是可能扭曲我们结果的“机器中的幽灵”。统计学家称之为 **混杂 (confounding)**。

我们如何驱除这个幽灵？科学界的黄金标准是 **随机对照试验 (Randomized Controlled Trial, RCT)**。在 RCT 中，我们不会让员工自己选择，而是通过随机分配（或许通过抛硬币）的方式，将他们分到接受计划组或不接受计划组。为什么这种方法如此强大？因为硬币不关心你是否有动力、是否烟瘾重、是年轻还是年老。随机化起到了巨大的均衡作用。在一个足够大的群体中，它能确保，在平均意义上，两个群体在所有可以想象的方面——无论是我们可以测量的特征（如年龄和吸烟史），还是我们无法测量的特征（如毅力或家庭支持）——都几乎是彼此完美的镜像。它们是 **平衡的 (balanced)**。有了平衡的组，研究结束时出现的任何戒烟率差异，我们都可以自信地归因于计划本身，而不是某些预先存在的差异。

但我们不能总是进行随机化。这可能不道德、不切实际或成本太高。我们常常必须处理 **观测数据 (observational data)**，即真实世界中人们自行做出选择所产生的混乱数据。因此，核心挑战是巨大的：当我们无法进行随机化时，如何近似 RCT 的魔力并实现公平比较？我们如何从不平衡中创造平衡？

### 倾向性得分：一个统领全局的数字

一个最初的想法可能是寻找成对的人，一个参加了计划，一个没有，他们在所有基线特征上都完全相同。我们可以尝试将计划组中一个 42 岁、烟瘾重、积极性高的男性，与非计划组中一个 42 岁、烟瘾重、积极性高的男性进行匹配。但如果还需要匹配饮食、锻炼、收入以及其他几十个因素呢？这些特征的数量，我们可以称之为协变量向量 $X$，可能非常庞大。“[维度灾难](@entry_id:143920)”很快就会使我们无法为任何人找到精确的匹配。

这时，由 Paul Rosenbaum 和 Donald Rubin 提出的一个绝妙想法应运而生。与其尝试匹配 $X$ 中的几十个协变量，不如将所有这些信息压缩成一个强大的单一数字？这个数字就是 **倾向性得分 (propensity score)**。倾向性得分，通常表示为 $e(X)$，就是具有一组给定特征 $X$ 的人接受处理的概率。在我们的例子中，它是 $e(X) = \mathbb{P}(T=1 \mid X)$，其中 $T=1$ 表示他们参加了该计划。[@problem_id:4957132]

这个得分并不能告诉我们某人*是否*会接受处理；它告诉我们他们接受处理的*可能性*有多大。现在，考虑两个人，一个参加了计划，一个没有，但他们都有完全相同的倾向性得分，比如 $0.3$。这意味着，根据我们所知的关于他们的一切，他们两人最终进入计划的几率都是 30%。这就像命运为他们每个人都抛了一枚有偏的硬币，只是恰好一个“正面朝上”，另一个“反面朝上”。如果他们接受处理的概率相同，那么有理由认为，他们的潜在特征 $X$ 在平均上也必然是相同的。

这就是著名的倾向性得分的 **平衡性质 (balancing property)**：在一组具有相同倾向性得分的受试者中，原始协变量 $X$ 的分布与处理状态 $T$ 是独立的。形式上，这写作 $X \perp T \mid e(X)$。[@problem_id:4585343] 这个单一的数字 $e(X)$，完成了看似不可能的任务。它打破了协变量与处理之间的联系，有效地平衡了两个组，就像随机化一样。从这个意义上说，它是一个平衡得分。

### 从理论到实践：实现与评估平衡

拥有这个理论工具是一回事；使用它则是另一回事。倾向性得分为几种调整混杂的强大技术提供了基础：

*   **匹配 (Matching)：** 我们可以找到具有非常相似倾向性得分的处理组和未处理组个体配对，从而创建一个新的、更小但平衡良好的数据集。

*   **分层 (Stratification)：** 我们可以根据倾向性得分将我们的总体分成（例如）五个层次（如 0-0.2、0.2-0.4 等），并在每个层次内分析[处理效应](@entry_id:636010)，此时受试者更具可比性。

*   **逆概率处理加权 (Inverse Probability of Treatment Weighting, IPTW)：** 这是一种特别巧妙的方法，允许我们使用整个样本。它通过加权创建一个实现了平衡的“伪总体”。想象一个积极性很高的人，他很可能加入计划（比如 $e(X)=0.9$）并且确实加入了。他的出现并不令人意外。但另一个积极性很高的人（同样 $e(X)=0.9$），出于某种原因*没有*加入，情况又如何呢？他的出现就非常令人意外！这个人在未处理组中代表性不足。为了创造平衡，我们必须在分析中给予这个人更大的权重。这个权重是接受其所受处理的概率的倒数。对于一个处理组的人 ($T=1$)，权重是 $\frac{1}{e(X)}$；对于一个未处理组的人 ($T=0$)，权重是 $\frac{1}{1-e(X)}$。这个方案给“令人意外”的个体赋予更高权重，给“意料之中”的个体赋予更低权重，通过这样做，它迫使两组的协变量分布趋于一致。[@problem_id:4957132] [@problem_id:4979362]

在这里出现了一个关键点，这也是一个常见的困惑来源。什么才是一个“好”的倾向性得分模型？由于得分是处理的概率，人们可能会认为目标是建立一个最能*预测*谁会接受处理的模型。我们可以使用标准的统计指标，如 AIC 或 AUC（也称为 c-statistic），来选择“最佳”模型。这是一个陷阱！[@problem_id:1936677] 在因果推断中，倾向性得分的目标 **不是预测，而是平衡**。

想象一下，我们的模型非常出色，以至于它能完美预测谁会加入计划。它的 AUC 值为 1.0。这意味着它找到了一组能够将处理组和未处理组完美分开的特征。这远非一件好事，对于因果推断来说，这是一场灾难。它意味着两个组差异如此之大，以至于它们的特征没有任何重叠！我们在未处理组中找不到任何一个看起来像处理组中任何一个人的个体，这使得比较变得不可能。这严重违反了 **正性 (positivity)** 假设，该假设要求对于任何给定的特征集，个体被分到任一组的概率都必须非零。[@problem_id:4979362] [@problem_id:4943097] 一个在预测上“过于出色”的倾向性得分模型，可能只是突显了我们数据中 **重叠 (overlap)**（正性假设的有限样本版本）的致命缺失。

那么，我们如何知道我们选择的方法——无论是匹配、加权还是其他方法——是否真的奏效了呢？我们必须检查我们的工作。我们必须进行 **平衡性评估 (balance assessment)**。思路很简单：比较调整后的处理组和[控制组](@entry_id:188599)中每个协变量 $X$ 的分布，看看它们是否相似。要完成这项任务，我们需要正确的工具。人们可能想使用标准的统计检验，比如 t 检验，来看一个协变量的均值在两组之间是否存在“显著差异”。这是另一个陷阱。[@problem_id:4973495]

这类检验得出的 p 值极度依赖于样本量。在一项有数千人的研究中，即使一个协变量存在微不足道的、无关紧要的不平衡（比如平均年龄相差 0.1 岁），也会被标记为“统计显著”，让你白费力气去修正一个不存在的问题。相反，在一个小规模研究中，一个巨大且真正重要的不平衡可能因为统计功效低而“不显著”，从而给你一种虚假的安全感。

合适的工具是那种能够衡量不平衡*程度*，且不受样本量影响的工具。最常用的这类工具是 **标准化均值差异 (Standardized Mean Difference, SMD)**。对于一个给定的协变量，它是处理组和[控制组](@entry_id:188599)之间的均值差，除以一个合并的标准差。例如，在一项比较两种疗法的医学研究中，我们可能发现在匹配后，处理组中糖尿病患者的比例是 $0.38$，而[控制组](@entry_id:188599)是 $0.36$。原始差异很小，但 SMD 将其置于一个通用尺度上。在这种情况下，SMD 大约是 $0.04$，一个非常小的数字。[@problem_id:4973495] 一个广泛使用的经验法则是，绝对 SMD 值低于 $0.1$ 表示不平衡可以忽略不计。一个良好平衡性评估的完整蓝图是一个迭代过程：预先指定你的混杂因素，建立你的倾向性得分模型，应用你的调整方法，然后使用 SMD 和可视化图表检查所有协变量的平衡性。如果未[达到平衡](@entry_id:170346)，你需要完善你的模型再试一次，所有这些都必须在查看结果数据*之前*完成。[@problem_id:4515363]

### 更深层的目的：从[统计平衡](@entry_id:186577)到因果推断

让我们退一步问：为什么如此执着于平衡？答案将我们带到因果推断的核心。要从观测数据中提出因果主张，我们需要做的基本假设被称为 **条件[可交换性](@entry_id:263314) (conditional exchangeability)**。它指出，在混杂因素 $X$ 的各个层级内，处理的分配与潜在结果是独立的。形式上，即 $Y(a) \perp A \mid X$。这意味着，如果我们能够比较，比如说，一组接受处理的 42 岁吸烟者和一组未接受处理的 42 岁吸烟者，这将是一个公平的、“如同随机”的比较。

倾向性得分的真正魔力在于，它证明了如果条件可交换性在给定（通常是高维的）向量 $X$ 的情况下成立，那么它在给定（一维的）倾向性得分 $e(X)$ 的情况下*也*成立。也就是说，$Y(a) \perp A \mid e(X)$。[@problem_id:4582780] 这是一个巨大的简化！通过基于倾向性得分进行匹配或加权来实现协变量平衡，我们创造出的组不仅在协变量 $X$ 上是平衡的，而且也是可交换的。我们创造了一个公平的比较。这些现在已经平衡的组之间，在结果 $Y$ 上存在的任何差异，都可以归因于处理的真实因果效应，而不是混杂。其目标从来就不是简单地消除一个[统计关联](@entry_id:172897)，而是为得出一个有效的因果结论创造条件。

### 当平衡难以实现时：先进与自动化的平衡方法

当平衡仍然难以实现时会发生什么？我们可能会尝试在倾向性得分模型中加入更复杂的项（如交互项或平方项）并重新检查平衡，但有时，这些组就是难以对齐。这引发了思想上的一个重要演变：如果我们的目标是平衡，为什么不使用一种明确设计用来实现平衡的方法呢？

这就是 **协变量平衡倾向性得分 (Covariate Balancing Propensity Score, CBPS)** 背后的逻辑。[@problem_id:4501657] 像逻辑回归这样的标准方法通过最大化预测准确性（似然）来估计倾向性得分。CBPS 采取了不同的途径。它通过直接强制满足平衡条件来估计倾向性得分的参数。它被构建为一个 **[广义矩估计](@entry_id:140147) (Generalized Method of Moments, GMM)** 估计器，用于求解一个方程组。这个系统不仅包括拟合预测模型的常规方程，还增加了一组至关重要的[平衡方程](@entry_id:172166)。这些附加方程明确要求，每个协变量的加权平均值在处理组和未处理组中必须相等。[@problem_id:5221093]

从本质上讲，CBPS 告诉估计过程：“你的首要任务不是完美地预测处理分配。你的任务是找到能够产生一个平衡的伪总体的倾向性得分。”这种双重目标的方法——同时考虑[模型拟合](@entry_id:265652)和协变量平衡——提供了一种更稳健、更自动化的方式，以从混乱的真实世界数据中实现创造公平比较这一基本目标。它代表了一种美妙的综合，将因果推断的最终目标——平衡——直接嵌入到统计工具本身的机制之中。

