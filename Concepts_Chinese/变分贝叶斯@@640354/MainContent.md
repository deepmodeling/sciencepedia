## 引言
[贝叶斯推理](@entry_id:165613)方法，即根据新证据更新我们的信念，为[统计建模](@entry_id:272466)提供了一个强大的框架。它为量化不确定性和从数据中学习提供了一种有原则的方法。然而，这一前景常常被一个巨大的数学障碍所阻挡：[后验分布](@entry_id:145605)的计算，这通常需要解决一个棘手的、高维的积分。这个计算瓶颈催生了近似这一理想后验的方法的发展，从而形成了两大思想流派：基于采样的方法和基于优化的方法。

本文侧重于后者，探讨了功能强大且日益流行的变分贝叶斯（Variational Bayes, VB）技术。变分贝叶斯并非试图完美地描绘真实后验的复杂景观，而是将推断问题重新构建为一个[优化问题](@entry_id:266749)：从一系列更简单的、可解的[分布](@entry_id:182848)中，找到最佳的“蓝图”。我们将看到，这种优雅的视角转变为处理规模和复杂性巨大的模型提供了可能。接下来的“原理与机制”一节将首先揭示该方法背后的核心思想，从基础的[KL散度](@entry_id:140001)（Kullback-Leibler divergence）和[证据下界](@entry_id:634110)（ELBO）到驱动其在深度学习中应用的现代机制。之后，“应用与跨学科联系”一节将展示这一思想如何为解决科学领域中各种多样且具影响力的问​​题提供一个统一的框架。

## 原理与机制

要真正领会变分贝叶斯，我们必须首先回到现代统计学的核心：一个优美简单却又极其强大的陈述，即[贝叶斯法则](@entry_id:275170)。它是从经验中学习的数学体现。其本质在于，它告诉我们如何在面对新证据时更新我们的信念。

让我们想象一下，我们正在为一个[复杂系统建模](@entry_id:203520)。这个系统可能是整个地球的气候，包含大气碳和海洋营养物等变量 [@problem_id:2494925]；也可能是一个病人对新药的反应；或是[深度神经网络](@entry_id:636170)中错综复杂的权重网络。我们从对模型参数的一些初始信念开始，我们称之为**先验**[分布](@entry_id:182848)，$p(x)$。然后，我们收集一些数据，即我们的观测值 $y$。**[似然](@entry_id:167119)** $p(y|x)$ 告诉我们，在模型参数的特定设置下，我们的观测值有多大的可能性。

[贝叶斯法则](@entry_id:275170)给予我们最终的奖赏：**后验**[分布](@entry_id:182848) $p(x|y)$。这是我们在看到数据*之后*对参数的更新、更精确的信念。它是我们先验知识和[观测信息](@entry_id:165764)中所含信息的完美融合。这个法则本身很优雅：

$$
p(x|y) = \frac{p(y|x) p(x)}{p(y)}
$$

这其中既蕴含着[贝叶斯推断](@entry_id:146958)的梦想，也隐藏着其噩梦。分子很简单，就是我们的模型。分母 $p(y) = \int p(y|x)p(x)dx$ 则是我们故事中的“反派”。这一项，被称为**边缘[似然](@entry_id:167119)**或**证据**，要求我们对模型参数的*每一种可能配置*下观测数据的概率进行求和。除了最简单的模型外，这个积分都是一个巨大的、高维的计算，在计算上是无法解决的。我们所寻求的后验分布，就被锁在这个棘手的积分后面。

我们如何描绘一个我们无法完全计算的景观呢？两大思想流派应运而生：一个基于漫游，另一个基于工程。第一种，马尔可夫链蒙特卡洛（MCMC），就像派一个测量员在后验景观中进行漫长而曲折的行走；他们最常访问的区域对应于高概率区域。这种方法细致入微，如果你等待足够长的时间，通常能保证得到一张精确的地图，但“足够长”可能意味着永恒。变分贝叶斯则提供了一种截然不同的方法。

### 工程师的蓝图：作为优化的推断

变分贝叶斯（VB）不像漫游者，它更像一位工程师。它说：“我无法计算真实、复杂的后验景观，但我可以近似它。”我们从选择一个简单、行为良好的[分布](@entry_id:182848)族——我们的“蓝图”——开始。一个常见的选择是高斯（钟形曲线）[分布](@entry_id:182848)族。我们将我们的蓝图[分布](@entry_id:182848)称为 $q(x)$。变分贝叶斯的目标就是从我们选择的[分布](@entry_id:182848)族中找到*最佳蓝图* $q(x)$，使其最接近真实、棘手的后验 $p(x|y)$。

这将积分问题转化为一个**优化**问题。我们不再是采样，而是在寻找我们简单[分布](@entry_id:182848) $q(x)$ 的最优参数，使其成为复杂真实情况 $p(x|y)$ 的最佳替代品。

但“最佳”意味着什么？我们如何衡量两个[分布](@entry_id:182848)的“接近程度”？为此，我们需要一个特殊工具：[KL散度](@entry_id:140001)（Kullback-Leibler divergence）。

### 接近度的两面性：[KL散度](@entry_id:140001)

[KL散度](@entry_id:140001) $D_{\mathrm{KL}}(q || p)$ 衡量了当我们使用近似[分布](@entry_id:182848) $q$ 来表示真实[分布](@entry_id:182848) $p$ 时所损失的[信息量](@entry_id:272315)。它不是一个真正的距离——$D_{\mathrm{KL}}(q || p)$ 与 $D_{\mathrm{KL}}(p || q)$ 是不相等的——而这种不对称性正是变分贝叶斯最典型特征的来源 [@problem_id:3430110]。

我们来看看这两种形式：

1.  **“正向”[KL散度](@entry_id:140001)，$D_{\mathrm{KL}}(p || q) = \int p(x) \log \frac{p(x)}{q(x)} dx$：** 为防止这个值爆炸，我们必须确保我们的近似[分布](@entry_id:182848) $q(x)$ 在真实[分布](@entry_id:182848) $p(x)$ 不为零的任何地方都不为零。这迫使 $q(x)$ 扩展自己以覆盖 $p(x)$ 的整个支撑集。如果真实的后验有多个峰（即是多峰的），这种“质量覆盖”行为会导致一个覆盖所有峰值的近似，将它们平均化，并常常高估不确定性。

2.  **“反向”KL散度，$D_{\mathrm{KL}}(q || p) = \int q(x) \log \frac{q(x)}{p(x)} dx$：** 这是标准变分贝叶斯中使用​​的形式。为防止*这个*值爆炸，我们必须确保我们的近似[分布](@entry_id:182848) $q(x)$ 在真实[分布](@entry_id:182848) $p(x)$ 为零的任何地方都为零。这种“零强制”行为意味着，如果我们简单的单峰 $q(x)$ 试图近似一个多峰的 $p(x)$，它无法跨越峰值之间的低概率山谷。相反，它被迫选择一个峰，并紧紧地拟合在其中。这被称为**模式寻求**（mode-seeking）行为。

变分贝叶斯选择最小化 $D_{\mathrm{KL}}(q || p)$ 意味着它会找到[后验分布](@entry_id:145605)的一个模式并对其进行近似，可能完全忽略其他模式。这使得变分贝叶斯的近似以其**过度自信**（有时是危险的）而闻名，系统性地低估了真实的后验[方差](@entry_id:200758)。

为什么选择这条路？原因纯粹是实践上的。反向[KL散度](@entry_id:140001) $D_{\mathrm{KL}}(q || p)$ 可以被重排成一个可计算的目标函数，而正向[KL散度](@entry_id:140001)则需要我们从那个我们正试图避免的棘手后验中进行采样 [@problem_id:3430110] [@problem_id:2568220]。这个实际可行的目标函数就是著名的[证据下界](@entry_id:634110)。

### 攀登者指南：[证据下界](@entry_id:634110)（ELBO）

整个[变分推断](@entry_id:634275)的机制都建立在一个优美的恒等式上，这个恒等式连接了棘手的证据、我们的近似 $q(x)$ 和[KL散度](@entry_id:140001)：

$$
\log p(y) = \underbrace{\mathbb{E}_{q}[\log p(y, x)] - \mathbb{E}_{q}[\log q(x)]}_{\text{ELBO}} + D_{\mathrm{KL}}(q(x) || p(x|y))
$$

这个方程是变分贝叶斯（VB）的“罗塞塔石碑” [@problem_id:3430189]。左边的项 $\log p(y)$ 是我们想计算但无法计算的（对数）证据。在右边，我们有衡量我们近似有多差的[KL散度](@entry_id:140001)，以及一个称为**[证据下界](@entry_id:634110)（Evidence Lower Bound, ELBO）**的新量。

由于KL散度总是非负的（$D_{\mathrm{KL}} \ge 0$），这个恒等式告诉我们ELBO总是对数证据的一个*下界*。最大化ELBO就像将一个地板向上推向一个固定的天花板；当地板越来越高，它就越来越接近天花板。因为天花板 $\log p(y)$ 对于我们给定的模型是固定的，所以最大化ELBO完[全等](@entry_id:273198)同于最小化KL散度。我们找到了我们的可计算[目标函数](@entry_id:267263)！

ELBO本身有一个非常直观的结构：

$$
\text{ELBO}(q) = \underbrace{\mathbb{E}_{q(x)}[\log p(y|x)]}_{\text{Data Fit}} - \underbrace{D_{\mathrm{KL}}(q(x) || p(x))}_{\text{Regularization}}
$$

最大化ELBO涉及到一个根本性的权衡。第一项，即期望[对数似然](@entry_id:273783)，推动我们的近似 $q(x)$ 去寻找能很好解释数据的参数。第二项，即我们的近似与*先验*之间的[KL散度](@entry_id:140001)，充当正则化项，将近似[拉回](@entry_id:160816)到我们最初的信念。这种张力是[变分推断](@entry_id:634275)的戏剧性核心。

### 运行中的机制：假设与近似

我们实际上如何执行这个优化呢？我们从对蓝图 $q(x)$ 的一个猜测开始，然后迭代地完善它。最简单、最著名的蓝图是**[平均场近似](@entry_id:144121)**。它做出了一个激进的假设，即所有参数的后验分布可以分解为独立的[分布](@entry_id:182848)的乘积，每个参数（或参数组）一个：

$$
q(x) = \prod_{j=1}^{n} q_j(x_j)
$$

这就像通过分别描述每个人的方式来描述一张全家福，完全忽略了他们是如何一起摆姿势的。这个假设破坏了我们近似中变量之间的任何**后验相关性** [@problem_id:3430124]。这是平均场变分贝叶斯低估不确定性的一个主要原因。如果两个参数在真实后验中强相关，平均场变分贝叶斯对这一事实视而不见，将它们视为独立的，并缩小了各自的不确定性。

这种简化假设的影响可能非常显著。想象一个简单的[非线性模型](@entry_id:276864)，其中观测值为 $y=x^2$ 加上一些噪声。$x$ 的真实后验景观在其峰值处会有一定的曲率，反映了数据提供的信息。[拉普拉斯近似](@entry_id:636859)是另一种在后验峰值处拟合[高斯分布](@entry_id:154414)的方法，它正确地使用对数后验的[二阶导数](@entry_id:144508)来捕捉这种曲率。然而，标准的变分贝叶斯高斯方法在推导过程中可能会将函数 $x^2$ 线性化。如果近似以 $x=0$ 为中心，那么导数为零，线性化后的模型似乎完全不依赖于 $x$。由此产生的变分贝叶斯对变异数的近似结果可能会惊人地恢复到先验变异数，就好像它完全没有从数据中学到关于不确定性的任何信息一样，这表明近似的具体细节可能会产生巨大的后果 [@problem_id:3430120]。

### 为VB增压：现代引擎

多年来，这些简化的假设和复杂的更新规则限制了变分贝叶斯的[适用范围](@entry_id:636189)。然而，深度学习的革命带来了新的技术，将变分贝叶斯转变为大规模建模的强大工具。

-   **[随机变分推断](@entry_id:635911)（Stochastic Variational Inference, SVI）：** ELBO是所有数据点的总和。这一洞见意味着我们不必使用整个数据集来取得进展。就像在标准深度学习中一样，我们可以使用一小**批（mini-batch）**数据来近似我们的目标函数。这使得变分贝叶斯能够扩展到海量数据集，从数百万张图像到[全基因组](@entry_id:195052)表观遗传数据的分析 [@problem_id:2568220]。

-   **[重参数化技巧](@entry_id:636986)（The Reparameterization Trick）：** 最大的突破是找到了如何利用[反向传播](@entry_id:199535)的力量。ELBO中的数据拟合项 $\mathbb{E}_{q(x)}[\log p(y|x)]$ 涉及一个期望，这意味着需要采样。你如何对一个采样过程求梯度？[重参数化技巧](@entry_id:636986)提供了一个聪明的解决方案。我们不从[分布](@entry_id:182848) $q_\phi(z)$ 中采样变量 $z$，而是将 $z$ 重新表示为参数 $\phi$ 和一个独立噪声源 $\epsilon$ 的确定性函数。对于[高斯分布](@entry_id:154414)，我们不从 $z \sim \mathcal{N}(\mu, \sigma^2)$ 中抽取，而是可以写成 $z = \mu + \sigma \times \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, 1)$。现在，随机性是外部的，我们可以通过确定性路径[反向传播](@entry_id:199535)梯度到 $\mu$ 和 $\sigma$。这个技巧是著名的**[变分自编码器](@entry_id:177996)（Variational Autoencoder, VAE）**背后的引擎，并使得变分贝叶斯能够与[深度学习](@entry_id:142022)框架无缝集成 [@problem_id:3191567]。

-   **摊销推断（Amortized Inference）：** 对于许多问题，我们希望为每个数据点推断其潜变量。我们可以训练一个单一的[神经网](@entry_id:276355)络——一个**识别模型**——来学习将观测值 $y_i$ 直接映射到其对应近似 $q(z_i)$ 的参数，而不是为每个数据点单独运行优化。在一次性的训练成本之后，对新数据点的推断变得异常迅速——只需通过网络进行一次[前向传播](@entry_id:193086)。这就在整个数据集上摊销了推断的成本 [@problem_id:2568220]。

### 诊断的艺术：解读信号

变分贝叶斯是一个强大的工具，但它是一种近似，而不是魔杖。理解其行为至关重要。考虑训练一个[贝叶斯神经网络](@entry_id:746725)。我们观察到我们的[目标函数](@entry_id:267263)ELBO稳步攀升。成功了！但接着我们查看模型的实际性能——它的预测准确率——却发现它完全停滞不前。

发生了什么？我们必须记住ELBO内部的张力：`[数据拟合](@entry_id:149007) - 正则化`。优化器发现，继续增加ELBO的最简单方法不是更努力地去拟合数据，而是简单地让近似 $q(x)$ 更像先验 $p(x)$，这会缩小[KL散度](@entry_id:140001)惩罚项。模型被如此严重地正则化，以至于它开始“忘记”数据，而倾向于满足先验。预测变得更不确定（高熵），模型的[置信度](@entry_id:267904)变得校准不准。这不是经典的[过拟合](@entry_id:139093)；这是该方法特有的一种病态，有时被称为**变分[欠拟合](@entry_id:634904)**（variational underfitting）[@problem_id:3115483]。它严酷地提醒我们，我们不只是在优化一个数字；我们正在驾驭近似贝叶斯推断中固有的复杂而优美的权衡。

