## 引言
为什么有些研究得出的结果似乎违背逻辑，或在事后被证明是错误的？通常，罪魁祸首并非简单的错误，而是我们在收集证据的方式上存在更深层、更系统性的扭曲。这种扭曲被称为选择偏倚，它是任何依赖数据的领域（从医学到机器学习）所面临的一个根本性挑战。当我们选择研究的受试者群体不能忠实代表我们希望了解的更大人群时，选择偏倚便会产生，从而导致可能具有误导性甚至危险性的结论。本文将直面这一对真理的无形威胁。首先，我们将探讨选择偏倚的核心**原理与机制**，通过[对撞机](@entry_id:192770)分层等概念揭示其运作方式，并将其与其他类型的[统计误差](@entry_id:755391)区分开来。然后，我们将进入现实世界，通过审视其在临床困境、历史不公以及人工智能新兴挑战中的作用，见证其**应用与跨学科联系**的深远影响。

## 原理与机制

要理解自然，我们必须首先学会如何向它提问。我们进行实验，我们展开调查，我们观察世界。但如果观察行为本身——即选择研究现实的哪一部分——系统性地扭曲了我们得到的答案，那该怎么办？这正是**选择偏倚**的核心所在。它不是随机或运气不佳的问题，不是那种可以通过收集越来越多数据来消除的误差。相反，它是我们观察世界的镜头出现了系统性的扭曲，就像一个哈哈镜，可以扭曲、放大甚至颠倒我们所寻求的真相。要成为更好的科学家——乃至更好的思想家——我们必须理解这种扭曲发生的美妙而有时又微妙的机制。

### 原罪：样本非全体

想象一下，我们的目标是了解某种暴露（我们称之为 $E$，可能是一种生活方式选择或一种新药）与某种结局（比如患上某种疾病，我们称之为 $D$）之间的关系。这种真实、未经修饰的关系存在于一个广大的“目标人群”之中——即我们问题所适用的每一个人。但我们几乎永远无法研究每一个人。我们必须抽取一个**样本**。

如果我们的样本只是目标人群的一个较小的、随机的缩影，那情况还不错。由于偶然性——统计学家称之为**[抽样误差](@entry_id:182646)**——我们对关系的估计可能会有点模糊，但它将以真实情况为中心。我们的随机样本越大，我们的焦点就越清晰 [@problem_id:4830217]。

但选择偏倚犯下了一个更根本的罪。它确保了我们的样本*不是*一个随机的缩影。选择过程本身受到了污染。它根据与我们所提问题相关的特征，有偏好地挑选个体。

让我们具体说明这一点。假设在现实世界中，一种暴露使患病风险增加一倍，即真实风险比（RR）为 $2$。现在，设想我们正在进行一项研究，但由于各种原因，那些既有暴露*又*患病的人更有可能被选入我们的分析中。也许他们所在的医院善于识别这类病例。与此同时，那些没有暴露但患病的人则更难找到。如一个假设但现实的情景所示，这种看似无害的选择动态可能会产生巨大的后果。一个真实的风险比 $2$ 在数据集中可能被放大到观察到的风险比接近 $4$，这纯粹是由于谁最终进入样本而造成的人为结果 [@problem_id:4541231]。我们最终得到了一个精确、有统计学意义且完全错误的结论。在这里增加样本量只会让我们对自己的错误更加确信。

这就是选择偏倚的核心：将研究单位选入我们分析的过程（$S=1$）同时依赖于我们研究的暴露（$E$）和结局（$D$）。我们观察到的关系，即以被选入样本为条件（$P(D=1|E, S=1)$），不再是人群中真实关系（$P(D=1|E)$）的忠实代表 [@problem_id:4602747]。

### 无形的[对撞机](@entry_id:192770)：通往谬误的欺骗性路径

也许选择偏倚最精妙、最[隐蔽](@entry_id:196364)的机制是**[对撞机](@entry_id:192770)分层偏倚**。这个名字很拗口，但其思想却惊人地简单，并且具有深远的影响，尤其是在大数据和人工智能时代。

首先，什么是**对撞机**？在因果图的语言中，对撞机是另外两个变量的共同*效应*。想象一条简单的路径：暴露 $E$ 导致某事，疾病 $Y$ 也导致同一件事。我们称那件“事”为 $S$。图示看起来像 $E \rightarrow S \leftarrow Y$。这里，$S$ 就是一个对撞机。

在总人群中，如果 $E$ 和 $Y$ 没有其他联系，它们是独立的。知道某人的暴露状态并不能告诉你任何关于他们疾病状态的信息。但当我们**对对撞机进行条件限制**——也就是说，当我们只观察 $S$ 的某个特定水平时——奇妙的事情发生了。

可以这样想：进入一所精英学院（$S=1$）需要非凡的艺术才能（$E=1$）或非凡的运动才能（$Y=1$）。在总人群中，艺术才能和运动才能是无关的。但如果我们*只看这所学院的学生*，我们就会发现两者之间存在一种虚假的*负*相关。为什么？因为如果学院里的一个学生不是伟大的运动员，那么他们*必须*是伟大的艺术家才能被录取。知道他们缺乏一种品质，就能给你提供关于另一种品质的信息，但这只在这个被选择的群体内成立。

这正是在许多现实世界数据集中发生的情况。考虑一个人工智能模型，它被训练用于根据一个人是否是关键岗位工作者（$E$）来预测其是否感染（$Y$）[@problem_id:4402820]。训练数据仅包含接受了检测的人（$S=1$）。但人们为什么会去检测？通常是因为他们是关键岗位工作者（作为筛查计划的一部分）*或*因为他们有症状（由感染引起）。检测的决定，$S$，是一个[对撞机](@entry_id:192770)：$E \rightarrow S \leftarrow Y$。

假设在现实中，作为关键岗位工作者对感染率没有影响；比值比为 $1$。然而，通过仅在接受检测的人群中训练模型，我们实际上是在对一个对撞机进行条件限制。基于实际概率的计算表明，这会产生一种强大的、虚假的关联。在这样一个情景中，数据会欺骗人工智能，使其得出结论：作为关键岗位工作者具有很强的*保护性*，比值比为 $0.25$！[@problem_id:4402820]。一个基于这种数据训练的模型将是危险的错误，部署它可能导致不公正的政策，比如降低关键岗位工作者获得防护装备的优先级，而这一切都源于一个微妙的统计学人为现象 [@problem_id:4402820]。当医院的分诊系统根据严重程度评分（$Z$）选择患者进入研究时，也会出现同样的结构，而这个评分（$Z$）本身是由患者的潜在疾病（$Y$）和他们的临床体征（$X$）共同引起的，从而 tạo thành 一条对撞路径 $Y \rightarrow Z \leftarrow X$ [@problem_id:5187849]。

### 偏倚众生相

对撞机机制是一种深层结构，但选择偏倚在实践中以多种面目出现。了解它们有助于我们在现实世界中发现它们。

*   **覆盖误差与健康工人效应**：通常，我们潜在的参与者名单——即**抽样框**——并不能覆盖整个目标人群。一项通过医院电子健康记录（EHR）招募的研究将错过没有保险的人或在别处就医的人 [@problem_id:5039024]。这就是**覆盖误差** [@problem_id:4830217]。一个经典的例子是**健康工人效应**：从工作场所招募的研究会系统性地排除那些因病重而无法工作的人。这使得样本从一开始就比一般人群更健康，从而扭曲了任何与之的比较 [@problem_id:5039024]。

*   **志愿者偏倚**：即使有完美的抽样框，我们也无法强迫人们参与。志愿参与本身就是一种行为。选择参加健康研究的人（一个称为**自我选择**的过程）可能与那些不参加的人有系统性差异。他们可能更关注健康、更焦虑，或有家族病史。他们参与的决定受到与潜在暴露和结局相关的因素的影响，从而为选择偏倚创造了一条经典的途径 [@problem_id:4635626]。

*   **发表偏倚**：选择偏倚甚至可以发生在整个研究的层面。科学期刊更倾向于发表那些显示出激动人心、有统计学意义结果的研究，而不是那些显示没有效应的研究。这种**发表偏倚**意味着，一篇综合已发表文献的[荟萃分析](@entry_id:263874)，实际上是在审阅一个从所有已进行的研究中挑选出来的、有偏倚的样本。其结果是一个回声室效应，它能使微弱的效应看起来很强，错误的线索看起来很有希望 [@problem_id:4943822]。

### 区分嫌疑：此偏倚非彼偏倚

要战胜敌人，我们必须精确地了解它。将选择偏倚与其臭名昭著的近亲——信息偏倚和混杂——区分开来至关重要。

*   **选择偏倚 vs. 信息偏倚**：选择偏倚关乎*谁进入了样本*。信息偏倚关乎对那些已经在样本中的人*获取了错误的信息*。如果一个有缺陷的实验室检测将患病者错误地分类为健康者，那就是信息偏倚。它从内部污染了数据。相比之下，选择偏倚是在入口处就破坏了样本 [@problem_id:4602747] [@problem_id:4541231]。

*   **选择偏倚 vs. 混杂偏倚**：这是一个更微妙但关键的区别。当一个外部变量 $C$ 是暴露 $E$ 和结局 $Y$ 的共同原因时，就会发生**混杂**。例如，年龄可能导致人们服用某种药物，同时也增加了他们患某种疾病的风险。随机化是临床试验的金标准，它是消除混杂的强大工具，因为它打破了任何基线因素 $C$ 与暴露 $E$ 之间的联系 [@problem_id:4941138]。然而，随机化本身并不能阻止在试验开始*后*发生的选择偏倚，例如当人们中途退出时。此外，选择偏倚最精妙的形式来自于对*共同效应*（对撞机）进行条件限制，而混杂则涉及*共同原因*。

这一区别揭示了一个绝佳的干预点。在随机对照试验（RCT）中，选择偏倚最大的威胁在于前门：入组的那一刻。如果负责招募参与者的人知道下一个治疗分配（例如，“新药”），他们可能会有意识或无意识地将某些类型的患者引导到该组。这打破了随机性，并引入了选择偏倚。解决方案是一个程序上的杰作，称为**分配隐藏**：确保招募参与者的人在做出入组决定且不可撤销之前，无法知道即将进行的分配。这种隐藏未来的简单行为，是在试验开始时抵御选择偏倚的强大护盾 [@problem_id:4593154]。它与**设盲**不同，后者发生在随机化*之后*，以防止人们根据自己所在的分组来改变他们的行为或评估。

理解选择偏倚的原理和机制，就像学习一场与真理的捉迷藏大游戏的规则。偏倚是聪明的，它就藏在明处——在我们的数据集里，在我们的研究设计中，以及我们科学共同体的结构本身。但通过识别它的特征，我们可以设计出更智能的研究，构建更公平的算法，并向着如实地看待现实更近一步。

