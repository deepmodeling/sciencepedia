## 引言
科学事业是持续不断地建立模型来解释和预测我们周围世界行为的努力。然而，没有一个模型能完美反映现实；模型是一种近似，而我们模型与真相之间的鸿沟便是不确定性的范畴。未能正确理解和考虑这种不确定性，不仅是技术上的疏忽，更可能导致错误的结论、过于自信的预测和糟糕的决策。问题在于，“不确定性”常常被视为一个单一的概念，而实际上它是一个由不同种类“未知”构成的复杂景观，每一种“未知”都有其独特的属性和含义。本文旨在为探索这一景观提供一份指南。

首先，在“原理与机制”一章中，我们将剖析不确定性的基本性质。我们将确立[偶然不确定性](@article_id:314423)（世界固有的随机性）和[认知不确定性](@article_id:310285)（我们知识的局限性）之间的关键区别。接着，我们将探索我们无知的不同方面——从模型参数的不确定性到模型结构本身的不确定性——并研究支配不确定性如何从原始数据传播到我们科学结论的数学原理。在此之后，“应用与跨学科联系”一章将展示这些原理不仅是理论性的，而且正在积极地改变科学实践。我们将涉猎药理学、生态学和[毒理学](@article_id:334857)等不同领域，以了解对不确定性的严格量化如何带来更可靠的预测、更有效的[实验设计](@article_id:302887)，并最终成就一门更诚实、更强大的科学。

## 原理与机制

认识世界、建立理论和做出预测，就如同在已知与未知之间永恒地走钢丝。科学并非一成不变的事实的集合，而是一个通过与不确定性搏斗来提炼我们理解的过程。但，不确定性*是*什么？事实证明，这不是一个简单的问题。这个词本身就像一个手提箱，当我们打开它时，会发现里面装满了各种迥然不同的“未知”。在任何领域，从工程学到生态学再到[法医学](@article_id:349693)，理解这些差异是迈向做出可靠预测和稳健决策的第一个巨大飞跃。

### 两种不确定性的故事

让我们从一个看似简单的系统开始我们的旅程：水在管道中流动。想象一下，你是一名工程师，任务是预测这段管道的压降。你立即会面临两种未知。

首先，即使你完美地控制了平均流速，流动本身也是[湍流](@article_id:318989)。入口处的速度不是一个恒定的数值，而是一种混乱、旋转的舞蹈，时时刻刻都在变化。如果你进行两次“相同”的实验，这些[湍流](@article_id:318989)涡旋的确切模式每次都会不同。这种物理过程固有的、不可简化的随机性，我们称之为**[偶然不确定性](@article_id:314423)**（aleatory uncertainty）。这个词来自拉丁语 *alea*，意为“骰子”——它就像掷骰子一样充满不确定性。你可以描述它，可以知道赔率，但你永远无法确定下一次投掷的结果。这是**系统本身**的一个基本属性。

其次，你可能不知道管道内表面的确切粗糙度。它是完全光滑的，还是在制造过程中留下了一些微观纹理？这种粗糙度是*你这根特定管道*的一个固定属性。它不会时时刻刻变化。它有一个单一的、真实的值；只是你不知道它是什么。这就是**[认知不确定性](@article_id:310285)**（epistemic uncertainty），来自希腊语 *epistēmē*，意为“知识”。它不是系统动力学的属性，而是*你对系统知识*的局限。

这种区分不仅仅是哲学上的吹毛求疵，它具有深远的实践意义[@problem_id:2536824]。你可以减少[认知不确定性](@article_id:310285)。原则上，你可以把管道拿来，切开，用高倍显微镜测量其粗糙度。更实际的做法是，你可以测量压降，并用你的模型来推断粗糙度参数最可能的值。数据越多，你的无知就越少。但是，关于这根管道的再多数据也无法告诉你*下一次*实验中[湍流](@article_id:318989)的确切模式。你可以更好地描述[湍流](@article_id:318989)的统计特性，但你永远无法消除骰子的随机性。

同样的情形在各处上演。一位研究[能量收支](@article_id:379735)的生态学家也面临着同样两个角色[@problem_id:2483751]。由于不可预测的天气，草的年生长量存在真实的年际波动，这是[偶然不确定性](@article_id:314423)，生态学家称之为**过程变异性**（process variability）。但生态学家对一个固定参数——比如蜗牛从它吃的草中吸收能量的确切比例——的知识不完备，这是认知不确定性。同样属于[认知不确定性](@article_id:310285)的还有他们仪器的误差，这模糊了他们对世界真实状态的看法；这就是**测量误差**（measurement error）。过程变异性是现实的一个特征；[参数不确定性](@article_id:328094)和测量误差是我们观察现实时的特征。

### 不确定性动物园：参数、模型和问题

认知不确定性——我们的无知——本身也是一头多样的野兽。我们对一个具体数字，即一个**参数**（parameter），缺乏了解，仅仅是个开始。

现在想象一下，你正在进行一项[生命周期评估](@article_id:310401)（LCA），以决定材料 P 和材料 Q 在其生命周期中哪个更环保[@problem_id:2527820]。你当然会面临[参数不确定性](@article_id:328094)：你不知道电网的确切碳强度，我们可以称这个参数为 $\beta$。但你也可能面临一个更深层次的问题：你甚至不确定支配该系统的正确数学方程是什么。也许能源使用量随产品年龄线性增长，$E = aL + b$。或者它遵循一个幂律，如 $E = aL^{0.7} + b$。这就是**[模型不确定性](@article_id:329244)**（model uncertainty）。你不仅缺少一个数字，你还缺少物理教科书中正确的章节。

不确定性还可以更深。作为一名评估犯罪现场 DNA 证据的法医学家，你计算出的似然比（LR）关键取决于你正在比较的命题[@problem_id:2810928]。控方的命题（$H_p$）是嫌疑人是DNA的贡献者，而辩方的命题（$H_d$）是一个不相关的未知人士是贡献者吗？或者，如果辩方提出贡献者是嫌疑人的兄弟呢？改变问题——即被比较的假设——可以极大地改变答案。这就是**假设不确定性**（hypothesis uncertainty）。

因此，我们有了一个怀疑的层级。有世界不可简化的随机性（[偶然不确定性](@article_id:314423)）。然后是我们可减少的无知（[认知不确定性](@article_id:310285)），它至少有三种类型：关于模型中数字的不确定性（**[参数不确定性](@article_id:328094)**），关于模型中方程的不确定性（**[模型不确定性](@article_id:329244)**），以及关于我们所提问题的根本不确定性（**假设不确定性**）。承认所有这些不确定性是迈向[科学诚信](@article_id:379324)的第一步。

### 从数据到不确定性：传播的艺术

那么，我们有了一个带参数的模型，我们有了数据。我们数据中的不确定性是如何转化为我们估计的参数的不确定性的呢？你可能会认为，如果你的数据点有，比如说，5%的误差，那么你的参数也必然有5%的不确定性。这是一个令人惊讶地普遍且危险的错误假设。

真相要有趣得多。假设我们通过最小化加权[误差平方和](@article_id:309718)——一个称为**$\chi^2$（卡方）拟合**的著名过程——来将模型 $f(x; \boldsymbol{\theta})$ 拟合到一组数据点 $(x_i, y_i)$ 上[@problem_id:2370449]。我们最终的最佳拟合参数 $\boldsymbol{\theta}$ 的不确定性取决于三个不同的因素：

1.  **数据中的噪声：** 这是最显而易见的。你的数据点上的[误差棒](@article_id:332312)（$\sigma_i$）越大，你从中推导出的参数的不确定性就越大。事实上，如果你将数据上所有的[误差棒](@article_id:332312)加倍，你拟合的参数上的[误差棒](@article_id:332312)也会加倍[@problem_id:2370449]。

2.  **数据量：** “5%输入，5%输出”这个简单的误区忽略了一个关键因素：平均的力量。如果你正在将一个简单的常数值拟合到 $N$ 个数据点上，每个点都有5%的误差，那么你对该常数的最终估计的不确定性将接近 $5\% / \sqrt{N}$。数据越多，你的知识就越精确。

3.  **模型的敏感性（杠杆作用）：** 这是最微妙也最美妙的一点。一个数据点只有在模型对该点的参数敏感时，才能约束该参数。想象一下试图确定一条直线的斜率。如果你所有的测量都在相同或接近的 $x$ 值处进行，那么无论你的单个测量有多精确，你对斜率的估计都会很糟糕！你需要在不同的 $x$ 值处测量，才能给你的拟合提供杠杆作用。在一个模型预测随参数微调几乎不变的位置上的数据点，几乎不提供关于该参数的任何信息。相反，在一个高敏感性点上的单个精确测量，其价值可能超过在不敏感点上的一百次测量[@problem_id:2370449]。

这种优雅的相互作用可以用一个强大的统计公式来捕捉。如果我们用[协方差矩阵](@article_id:299603) $\boldsymbol{\Sigma}_{\theta}$ 表示[参数不确定性](@article_id:328094)，用其[雅可比矩阵](@article_id:303923) $\mathbf{J}$（输出对参数的[导数](@article_id:318324)矩阵）表示模型的敏感性，那么由此产生的预测不确定性 $\boldsymbol{\Sigma}_{y}$ 近似由下式给出：
$$ \boldsymbol{\Sigma}_{y} \approx \mathbf{J} \boldsymbol{\Sigma}_{\theta} \mathbf{J}^{\top} $$
这就是著名的**“delta方法”**[@problem_id:2699332]。它告诉我们，[参数不确定性](@article_id:328094)被模型的局部敏感性过滤、旋转和放大，从而产生预测不确定性。你的模型是塑造其自身预测不确定性的积极参与者。

### 不[可识别性](@article_id:373082)的深渊与“草率”宇宙

有时，无论你收集多少数据，你都无法确定参数的值。这不是数据有噪声的问题；这是模型本身的一个基本属性。

考虑一个简单的[化学反应](@article_id:307389)，其中物质A可以通过两条不同的平行路径转化为B，速率常数分别为 $k_1$ 和 $k_2$。总[反应速率](@article_id:303093)仅由速率之和 $k_{\Sigma} = k_1 + k_2$ 决定。如果你只测量A或B随时间变化的浓度，你所能了解的只是这个总和 $k_{\Sigma}$ 的值。你永远无法分辨速率是 $k_1=0.5, k_2=0.5$ 还是 $k_1=0.1, k_2=0.9$，或是任何其他加起来等于1的组合。单个参数 $k_1$ 和 $k_2$ 是**结构上不可识别的**（structurally non-identifiable）[@problem_id:2692492]。该模型是**过度[参数化](@article_id:336283)的**（overparameterized）；它可供调整的旋钮比数据可能约束的要多。对于这些单个参数，不确定性实际上是无限的。

事实证明，这并非某些病态的边缘案例。这才是常态。生物学、[气候科学](@article_id:321461)和经济学中的大多数复杂模型都是科学家们所说的**“草率”的**（"sloppy"）[@problem_id:2660930]。当你分析它们的参数敏感性时，你会发现数据非常严格地约束了某些参数组合——这些是“刚性”方向。但有更多的参数组合可以被极大地改变，而几乎不影响模型的预测——这些是“草率”方向。

想象一个团队试图移动一根很长很重的木头。木头的前进运动（预测）由团队的集体努力（“刚性”参数组合）决定。但个体可以通过多种方式重新安排他们的位置和力量（沿“草率”方向的变化），从而对木头产生完全相同的合力。试图从木头的运动中推断出每个人的确切力量是一项毫无希望的任务。

这种“草率性”是一个深刻而统一的原则。它揭示了许多复杂系统的宏观行为对微观细节是稳健的。它解释了为什么具有不同底层参数的不同模型常常能做出相同的预测。关键不是因为我们无法知道每个参数而绝望，而是要庆幸我们能够识别出那些真正支配我们所关心行为的**涌现参数**——即“刚性”组合。这使得有原则的[模型简化](@article_id:348965)成为可能，并帮助我们避免过度解释数据根本无法解析的单个参数的值[@problem_id:2660930] [@problem_id:2692492]。

### 驯服不确定性：实用工具与发人深省的教训

那么，在实践中我们如何驾驭这个复杂的不确定性景观呢？目标不是消除不确定性——这是一项不可能的任务——而是理解它，量化它，并做出在其存在下**稳健**的决策。

当面对不可识别或“草率”的模型时，一个强有力的策略是**[重参数化](@article_id:355381)**（reparameterization）——根据模型的刚性和草率分量重写模型[@problem_id:2692492]。我们让数据对刚性部分大声说话，而对于数据沉默的草率部分，我们可以使用**正则化**（regularization）。这项技术就像增加了一只温柔的引导之手，通常通过假设微观参数应尽可能简单（例如，我们的平行[反应速率](@article_id:303093) $k_1$ 和 $k_2$ 应该相似），除非数据强烈反对。

为了量化复杂非线性模型中的不确定性，我们可以求助于像**自助法**（bootstrap）[@problem_id:2565014]和**交叉验证**（cross-validation）[@problem_id:2810935]这样的计算主力。[自助法](@article_id:299286)分析就像为你的数据集创建一个“镜厅”。通过重复[重采样](@article_id:303023)你自己的数据并重新运行拟合，你可以生成数千个合理的替代参数集。这些集合的分布为你提供了一个直接的、通常是可视化的[不确定性度量](@article_id:334303)，自然地捕捉了简单公式可能遗漏的不对称性和相关性。

这次进入不确定性核心的旅程给我们留下了一些发人深省但对任何实践科学家都至关重要的教训：

-   **谨防过度自信。** 最常见的错误是低估不确定性。当你忽略了不确定性的某个来源时，就会发生这种情况，例如，将一个“讨厌”参数固定为单个值，而不是考虑其自身的不确定性。这总是会使你的结果看起来比实际更精确[@problem_id:2565014]。

-   **尊重相关性。** 在许多模型中，参数并非独立起作用。它们是相关的，意味着它们可以相互补偿。试图增加一个参数可能会被另一个参数的减少所抵消，导致一个宽阔的“良好”拟合谷。这意味着每个单独参数的不确定性比你单独考虑它们时所猜测的要大得多[@problem_id:2565014]。

-   **好的拟合并不保证好的参数。** 一个模型可以完美地追踪数据点（一个低的 $\chi^2$ 值），但其参数可能很“草率”且难以确定。[拟合优度](@article_id:355030)告诉你你的模型与数据是*一致的*，而不是你已经唯一地锁定了底层机制[@problem_id:2565014]。

最终，对不确定性的严格量化并非科学成果的软弱标志，恰恰是其力量与诚信的体现。它界定了我们知识的边界，并迫使我们清楚地说明我们能声称什么和不能声称什么。正是在这种对我们自身无知的谦逊而清醒的承认中，[科学方法](@article_id:303666)的真正力量和完整性得以体现。