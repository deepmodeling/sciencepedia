## 引言
在贝叶斯推断的世界里，每一个结论都始于一个[先验信念](@article_id:328272)。但如果我们想尽可能不带偏见地处理一个问题，让证据引导我们的理解，该怎么办？对公正性的追求引出了**[客观先验](@article_id:347252)**的概念，这是一个让数据为自己发声的基础工具。然而，核心挑战在于，在一种情境下看似“无信息”的先验，在另一种情境下可能具有很强的影响力，这是一个被称为参数化的视角问题。我们如何才能以一种一致、有原则且普遍适用的方式来定义无知呢？

本文深入探讨了这一统计学难题的优雅解决方案。我们将探索[客观先验](@article_id:347252)背后的原理，重点关注 Harold Jeffreys 爵士的开创性工作。你将学习到统计信息本身的几何结构——由费雪信息量化——如何为构建对参数标记方式不变的先验提供方法。在接下来的章节中，我们将首先揭示 Jeffreys 先验背后的“原理与机制”，其[不变性](@article_id:300612)属性，以及它在常见参数类型上的应用。然后，我们将通过其“应用与跨学科联系”进行一次旅行，见证这一单一的统计学原理如何在工程、[数据科学](@article_id:300658)和天体物理学等不同领域为客观推理提供一种通用语言。

## 原理与机制

想象一下，你是一名到达犯罪现场的侦探。你没有嫌疑人，也没有任何先入为主的观念。你希望尽可能让证据自己说话。在科学和统计学的世界里，这就是**[客观先验](@article_id:347252)**所扮演的角色。当我们使用贝叶斯推断从数据中学习时，我们必须从一个关于我们试图估计的参数的“[先验信念](@article_id:328272)”开始。但如果我们希望我们的初始信念尽可能中立，尽可能“无知”，以便最终的结论几乎完全由数据塑造，该怎么办？这就是对客观性的追求，它远比初看起来要微妙得多。

### 先验问题：一个视角问题

你可能会认为，最客观的起点是平等地对待所有可能性。如果你正在估计一枚硬币正面朝上的概率 $p$，为什么不直接假设一个平坦的、均匀的先验，即 $p$ 从 0 到 1 的每个值都是同样可能的？这被称为拉普拉斯的“理由不充分原则”。这听起来很合理，但它隐藏着一个深层次的问题。

这个问题是一个视角问题，或者数学家所说的**参数化**问题。我们可以用成功的概率 $p$ 来描述硬币的偏倚。但我们也可以同样容易地用成功的赔率 $\omega = p / (1-p)$ 来描述它。或者是对数赔率 $\ln(\omega)$。如果我们在 $p$ 上设置一个均匀先验，那么赔率 $\omega$ 上的先验就*不是*均匀的。在一个描述中看似“无信息”的选择，在另一个描述中就变得有信息了。那么，哪种描述是“正确”的呢？没有“正确”的描述。我们的无知原则不应依赖于我们用来描述问题的语言。

我们需要一个无论如何标记参数都保持一致的原则。我们需要一个规则，无论我们讨论的是放射性衰变*率* $\lambda$ 还是其倒数，即*平均寿命* $\tau = 1/\lambda$，都能给出相同的根本答案 ([@problem_id:1925889])。这个难题的答案来自杰出的地球物理学家和统计学家 Harold Jeffreys 爵士。

### 信息即几何：Jeffreys 的洞见

Jeffreys 有一个深刻的想法。他建议，[无信息先验](@article_id:351542)不应基于参数值本身，而应基于*数据能提供的关于该参数的信息*。指导原则应该是：如果一个先验不偏好数据能提供更多信息的参数值，那么它就是无信息的。

为了使这个想法具体化，他使用了一个名为**费雪信息**的统计学工具，记为 $\mathcal{I}(\theta)$。你可以将[费雪信息](@article_id:305210)看作是衡量实验“灵敏度”的指标。它量化了单个数据点为你提供关于未知参数 $\theta$ 的[信息量](@article_id:333051)。如果[费雪信息](@article_id:305210) $\mathcal{I}(\theta)$ 很大，意味着似然函数曲线很陡峭，数据可以非常精确地确定 $\theta$ 的值。如果它很小，[似然函数](@article_id:302368)就很平坦，数据提供的帮助就较少。在某种意义上，[费雪信息](@article_id:305210)在参数空间上定义了一种“距离”或“几何”。

Jeffreys 提出了一个通用方法：参数 $\theta$ 的[先验概率](@article_id:300900)，我们称之为 $\pi_J(\theta)$，应与费雪信息的平方根成正比。

$$
\pi_J(\theta) \propto \sqrt{\mathcal{I}(\theta)}
$$

为什么是平方根？这是一个数学细节，但这正是实现[不变性](@article_id:300612)这一奇妙特性的关键。

### [不变性](@article_id:300612)的魔力

**Jeffreys 先验**真正的美在于其**[重参数化不变性](@article_id:376357)**。这意味着，如果你遵循 Jeffreys 的规则，无论你选择哪种参数化方式，你的结论都将是一致的。

让我们看看这个魔术是如何运作的。考虑一位工程师正在研究[激光二极管](@article_id:364964)的故障，其寿命遵循指数分布 ([@problem_id:1624948])。她可以用故障*率* $\lambda$ 来建模。通过计算费雪信息，她发现 $\mathcal{I}(\lambda) = 1/\lambda^2$。于是 Jeffreys 先验为：

$$
\pi_J(\lambda) \propto \sqrt{\frac{1}{\lambda^2}} = \frac{1}{\lambda}
$$

现在，假设她的同事更喜欢用故障前的*平均寿命* $\theta = 1/\lambda$ 来思考 ([@problem_id:1925871])。如果他为他的参数 $\theta$ 计算 Jeffreys 先验，他会发现费雪信息是 $\mathcal{I}(\theta) = 1/\theta^2$。所以他的先验是：

$$
\pi_J(\theta) \propto \sqrt{\frac{1}{\theta^2}} = \frac{1}{\theta}
$$

看！函数形式是相同的。一个与 $1/\lambda$ 成正比的率的先验，与一个与 $1/\theta$ 成正比的平均寿命的先验是完全等价的。通过概率变换规则，一个可以推导出另一个。不存在矛盾。Jeffreys 先验提供了一种自洽的方式来表达无知。

### 位置和[尺度参数](@article_id:332407)的通用方法

这个原则为我们在科学中遇到的两种最常见的参数类型提供了一些非常简单和通用的规则。

#### [位置参数](@article_id:355451)：它在哪里？

想象一个参数，它只是将一个分布向左或向右平移，而不改变其形状。这被称为**[位置参数](@article_id:355451)**。[正态分布](@article_id:297928)的均值 $\mu$（当方差已知时）是一个经典的例子。或者，在[气候科学](@article_id:321461)中使用的 Gumbel 分布的峰值位置 $\mu$ ([@problem_id:1922095])。其概率密度的一般形式是 $f(x-\theta)$。

对于这样一个参数 $\theta$，Jeffreys 的规则对我们的无知说了些什么？它告诉我们，费雪信息 $\mathcal{I}(\theta)$ 是一个常数 ([@problem_id:1925905])。它不依赖于分布的位置。因此，Jeffreys 先验也是常数：

$$
\pi_J(\theta) \propto \sqrt{\text{constant}} \propto 1
$$

这是一个在整个[实数线](@article_id:308695)上的平坦、均匀的先验。它表示我们没有理由相信分布的中心在这里而不是在那里。这可能看起来很奇怪，因为如果你将一个常数从 $-\infty$ 积分到 $\infty$，你会得到无穷大，而不是 1。这样的先验被称为**非正常先验**。但别担心！虽然它本身不是一个真正的[概率分布](@article_id:306824)，但它是一个完全有效的工具。一旦我们将其与数据结合以获得后验分布，后验几乎总是一个正常的、行为良好的分布。

#### [尺度参数](@article_id:332407)：它有多大？

现在考虑一个拉伸或压缩分布的参数，比如[正态分布](@article_id:297928)的标准差 $\sigma$ 或指数分布的平均寿命 $\theta$。这被称为**[尺度参数](@article_id:332407)**。其一般密度形式为 $\frac{1}{\sigma}f(x/\sigma)$。

对于任何这样的[尺度参数](@article_id:332407) $\sigma$，Jeffreys 先验总是相同的 ([@problem_id:1925891])：

$$
\pi_J(\sigma) \propto \frac{1}{\sigma}
$$

这个先验也是非正常的。为什么是这种形式？它将我们对尺度的无知应该在对数尺度上的想法形式化了。$\sigma$ 从 1 变到 2 的变化，应该与从 10 变到 20，或从 100 变到 200 的变化同等重要。重要的是*百分比*变化，而不是绝对变化。这个先验为所有[数量级](@article_id:332848)分配了相等的概率。这个规则适用于[正态分布](@article_id:297928)的标准差 $\sigma$，也适用于其方差 $\sigma^2$。一个快速的计算表明，如果 $\pi(\sigma) \propto 1/\sigma$，那么方差 $\theta = \sigma^2$ 的先验是 $\pi(\theta) \propto 1/\theta$，这与我们直接计算[正态分布](@article_id:297928)方差的 Jeffreys 先验时得到的结果完全相同 ([@problem_id:1925894])。这种一致性是美妙的。

即使对于抛硬币这样简单的问题，Jeffreys 先验也给出了一个不那么直观的结果 ([@problem_id:1379701])。对于成功概率 $p$，先验不是均匀的，而是与 $p^{-1/2}(1-p)^{-1/2}$ 成正比，这是一个 U 形的 $\text{Beta}(1/2, 1/2)$ 分布。这个先验表明，我们应该对接近 0.5 的 $p$ 值更加怀疑，而对接近 0 或 1 的值则不那么惊讶，直到我们看到一些数据。它反映了这样一个事实：数据更难区分 $p=0.5$ 和 $p=0.51$，相比于区分 $p=0.01$ 和 $p=0.02$。

### 复杂性与改进：故事仍在继续

统计学的世界，就像物理学一样，充满了美丽的理论，但当你仔细观察时，它们会变得更加微妙。Jeffreys 先验是一项胜利，但它并不是最终的定论，尤其是在同时处理多个未知参数时。

考虑一个经典的[正态分布](@article_id:297928)案例，其中*均值* $\mu$（一个[位置参数](@article_id:355451)）和*标准差* $\sigma$（一个[尺度参数](@article_id:332407)）都未知。我们基于单参数规则的直觉可能是简单地将各个先验相乘：$\pi(\mu, \sigma) \propto \pi(\mu) \cdot \pi(\sigma) \propto 1 \cdot \frac{1}{\sigma} = \frac{1}{\sigma}$。

然而，当我们应用正式的多元 Jeffreys 法则（它使用[费雪信息矩阵](@article_id:331858)的[行列式](@article_id:303413)）时，我们得到了一个不同的答案 ([@problem_id:1940948])：

$$
\pi_J(\mu, \sigma) \propto \frac{1}{\sigma^2}
$$

这种差异一直是许多争论的根源。事实证明，原始的用于多参数的 Jeffreys 法则有时会产生具有不良性质的先验。这提醒我们，即使是最优雅的原则也可能产生令人惊讶的后果。

这导致了进一步的改进，其中最著名的是由 José-Miguel Bernardo 和 James Berger 开发的**[参考先验](@article_id:350587)**。[参考先验](@article_id:350587)是一种更复杂的[算法](@article_id:331821)，旨在最大化实验的预期[信息增益](@article_id:325719)。它通常需要区分“感兴趣的参数”和其它的“[讨厌参数](@article_id:350944)”。对于[正态分布](@article_id:297928)问题，如果我们声明均值 $\mu$ 是我们的主要兴趣，而 $\sigma$ 是一个[讨厌参数](@article_id:350944)，[参考先验](@article_id:350587)[算法](@article_id:331821)给出的结果是 ([@problem_id:1925853])：

$$
\pi_R(\mu, \sigma) \propto \frac{1}{\sigma}
$$

这与我们最初的直觉相符！对一个真正“客观”先验的追求是一个持续的故事，是原则、数学和哲学之间美妙的相互作用。它展示了科学如何通过理解旧思想的局限性并在其强大的基础上进行建设来取得进步，而不是抛弃它们。Jeffreys 的不变性原则仍然是一个核心里程碑，是我们让数据尽可能清晰地说话的旅程中的一个指路标。