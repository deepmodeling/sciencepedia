## 引言
在理解和预测我们这个复杂世界的探索中，[科学建模](@entry_id:171987)长期以来一直在两种哲学之间摇摆不定：一种是基于物理的模拟所追求的严格准确性，另一种是数据驱动的机器学习所拥有的灵活能力。传统的模拟器以理论为基础，但在面对未知的物理现象或巨大的计算成本时却力不从心。相反，标准的[机器学习模型](@entry_id:262335)虽然强大，却是“黑箱”，在遇到训练数据之外的情况时可能会彻底失效，因为它们对现实缺乏任何基本的理解。这种差距催生了一种新方法的需求，即能够融合二者之长的方法。

本文介绍了物理信息学习（PIML），一个实现了这种综合的革命性范式。我们将通过两个主要部分来探讨[科学建模](@entry_id:171987)的这“第三条道路”。“原理与机制”一章将剖析PIML的工作原理，详细说明物理定律如何被编码到神经网络的训练中，以创建既准确又符合物理一致性的模型。随后的“应用与跨学科联系”一章将展示这种方法的深远影响，揭示其在众多科学和工程领域解决一度棘手的问题的能力。为开启我们的旅程，让我们深入探究驱动物理与人工智能融合的精妙机制。

## 原理与机制

要真正领会[物理信息](@entry_id:152556)学习的力量，我们必须超越表面，探索使其运转的精妙机制。我们究竟如何能向一个由数字和抽象函数构成的神经网络，传授自然法则——那些支配宇宙亿万年的根本原理？答案不在于蛮力，而在于新旧思想的美妙综合，在于物理学家对第一性原理根深蒂固的尊重与计算机科学家强大的优化工具的结合。

### 第三条道路：数据与物理的结合

长期以来，[科学建模](@entry_id:171987)领域分为两大阵营。一方是传统的物理学家和工程师，他们基于牛顿定律或[纳维-斯托克斯方程](@entry_id:142275)等基本定律，从零开始构建复杂的模拟器。这些模型建立在坚实的理论基础上，但可能极其复杂且计算成本高昂。它们就像一个背下了整本教科书却从未见过实际问题的学生；其知识是纯粹的，但缺乏处理现实复杂性的灵活性，尤其是在部分物理原理未知或过于复杂而无法建模时。

另一方是现代机器学习的纯数据驱动方法。在这里，模型被视为一个“黑箱”。我们向它展示大量示例——输入及其对应的输出——它从中学习它们之间的[统计相关性](@entry_id:267552)。这种方法非常强大和灵活，但有一个危险的缺陷：它对底层现实毫无概念。一个纯数据驱动的模型，如果被训练来预测球的路径，对于成千上万的例子可能表现得非常出色，但如果它从未见过在月球上抛球的情景，它将完全不知所措。它不懂[引力](@entry_id:189550)，只知道它所见过的东西。这就像一个通过背诵旧考卷来应付考试的学生；他们能完美回答熟悉的问题，但面对需要真正理解的新问题时就会迷失方向。

[物理信息](@entry_id:152556)机器学习（PIML）提供了第三条道路。它创造了理想的学生——既学习教科书，*又*从已解的示例中学习。它结合了两个世界的优点。一个PIML模型像标准神经网络一样，在可用数据上进行训练，但同时也被训练来遵守物理定律。数据使模型植根于现实，而物理学则提供了一种强大的“[归纳偏置](@entry_id:137419)”——一套指导模型学习过程的基本规则，使其能够泛化到远超其所见过的数据的范围[@problem_id:3843244]。这种协同作用使我们能够构建不仅准确而且物理上一致的模型，即使在数据稀疏或不完整的情况下也是如此。

### 机器之心：通过[损失函数](@entry_id:136784)传授物理知识

那么，我们如何向神经网络“传授”物理知识呢？我们不能让它坐在报告厅里听课。相反，我们将物理定律编码到网络的训练目标，即其**[损失函数](@entry_id:136784)**中。可以把[损失函数](@entry_id:136784)想象成一位给网络表现打分的老师。在标准的机器学习设置中，这位老师只关心一件事：网络预测值与真实数据点之间的差距。这部分损失，即**数据损失**，通常是[均方误差](@entry_id:175403)：

$$
\mathcal{L}_{\text{data}}(\theta) = \frac{1}{N_d} \sum_{i=1}^{N_d} \left(u_\theta(\mathbf{x}_i,t_i) - y_i\right)^2
$$

这里，$u_\theta$ 是网络在点 $(\mathbf{x}_i,t_i)$ 的预测值，$y_i$ 是测量的数据值，求和遍历所有 $N_d$ 个数据点。训练的目标是找到使该损失尽可能小的网络参数 $\theta$。

PIML的革命始于我们给这位老师布置了第二个同等重要的任务：根据网络对物理学的遵守程度来评分。我们在[损失函数](@entry_id:136784)中加入第二项，即**物理损失**。假设一个物理定律由一个[偏微分](@entry_id:194612)方程（PDE）描述，我们可以将其写成一般形式 $\mathcal{N}[u] = 0$。例如，对于一个反应[扩散过程](@entry_id:170696)，这可能是 $u_t - D \nabla^2 u - R(u) = 0$。$\mathcal{N}[u]$ 的值被称为**残差**。如果函数 $u$ 完美地满足物理定律，那么残差在任何地方都为零。

现在我们可以问我们的神经网络 $u_\theta$，它满足该定律的程度如何。我们计算网络输出的残差 $\mathcal{N}[u_\theta]$。如果网络是一个完美的解，这个残差将为零。否则，它将是某个非零值。然后，我们可以将物理损失定义为均方残差，在一大批散布在问题域内的随机点（称为**[配置点](@entry_id:169000)**）上进行评估：

$$
\mathcal{L}_{\text{phys}}(\theta) = \frac{1}{N_p} \sum_{j=1}^{N_p} \left\|\mathcal{N}[u_\theta(\mathbf{x}_j,t_j)]\right\|^2
$$

总[损失函数](@entry_id:136784)成为数据损失和物理损失的加权和 [@problem_id:3337920]：

$$
\mathcal{L}_{\text{total}}(\theta) = \mathcal{L}_{\text{data}}(\theta) + \lambda_p \mathcal{L}_{\text{phys}}(\theta)
$$

现在，当我们训练网络以最小化 $\mathcal{L}_{\text{total}}$ 时，它被迫进行一场精妙的平衡。它必须努力拟合数据（以使 $\mathcal{L}_{\text{data}}$ 变小），*同时*遵守物理定律（以使 $\mathcal{L}_{\text{phys}}$ 变小）。

你可能会想：对于一个极其复杂的神经网络函数，我们怎么可能计算出算子 $\mathcal{N}$ 内部的导数（如 $u_t$ 或 $\nabla^2 u$）呢？这时，一个名为**[自动微分](@entry_id:144512)（AD）**的出色工具就派上用场了。因为神经网络只是一长串简单的基本运算（如加法、乘法和[激活函数](@entry_id:141784)），我们可以利用微积分的[链式法则](@entry_id:190743)，自动且精确地计算网络输出相对于其*任何*输入（如空间 $x$ 或时间 $t$）的导数。这使我们能够以[机器精度](@entry_id:756332)计算物理残差，而无需借助不准确的[数值近似方法](@entry_id:169303)[@problem_id:3337920]。AD是使整个PIML事业成为可能的沉默而强大的引擎。

### 游戏规则：从局部定律到全局对称性

物理定律不仅仅是一个单一的方程；它们是由各种约束构成的丰富织锦。PIML提供了将其中许多约束直接融入学习过程的灵活性。

#### 边界条件和初始条件

一个物理问题的解，若不指定其在区域边界和初始时刻的情况，则是没有意义的。有两种主要方法来强制施加这些条件。

第一种是**软施加**，它遵循与物理损失相同的理念。我们只需在[损失函数](@entry_id:136784)中增加更多的惩罚项，以应对在边界或初始时间的任何不匹配[@problem_id:3807969]。这就像告诉我们的学生：“如果你的答案在这个边界上不是100°C，你就会被扣分。”

第二种更优雅的方法是**硬施加**。在这里，我们巧妙地设计[网络架构](@entry_id:268981)，使其*通过构造*就满足这些条件。例如，假设我们需要在边界 $\partial\Omega$ 上施加一个[狄利克雷边界条件](@entry_id:173524) $T(\mathbf{x}) = g_D(\mathbf{x})$。我们可以定义一个函数 $d(\mathbf{x})$，它在边界上为零，在其他地方非零（[符号距离函数](@entry_id:754834)是一个不错的选择）。然后，我们可以将网络输出表示为：

$$
\hat{T}(\mathbf{x}) = g_D(\mathbf{x}) + d(\mathbf{x}) N_\theta(\mathbf{x})
$$

其中 $N_\theta(\mathbf{x})$ 是一个标准的神经网络。注意会发生什么：在边界上，$d(\mathbf{x})=0$，所以第二项消失，我们得到 $\hat{T}(\mathbf{x}) = g_D(\mathbf{x})$。无论神经网络 $N_\theta$ 输出什么，条件都完美满足！这个技巧将物理约束直接嵌入到模型的DNA中，使优化器只需专注于在内部区域满足控制PDE即可[@problem_id:2502961]。对于其他边界条件，如诺伊曼和[罗宾条件](@entry_id:153384)，也可以进行类似的构造，尽管它们可能会变得更复杂。

#### 全局守恒定律

物理学中一些最深刻的原理不是关于单一点发生什么的局部陈述，而是关于整个系统的全局陈述——守恒定律。一个[孤立系统](@entry_id:159201)的总能量、质量或动量必须保持恒定。我们也可以向神经网络传授这些全局原理。

除了惩罚局部PDE残差，我们还可以通过在整个域上对网络预测进行积分来计算一个全局量，比如系统的总能量。对于一个能量 $E$ 必须守恒的系统，物理定律是 $\frac{\mathrm{d}E}{\mathrm{d}t} = 0$。我们可以定义一个新的损失项，惩罚网络预测的总能量的任何变化：

$$
\mathcal{L}_{\text{energy}} = \left( \frac{\mathrm{d}\hat{E}}{\mathrm{d}t} \right)^2
$$

其中 $\hat{E}$ 是从网络输出计算出的总能量。通过将其添加到我们的总损失中，我们告诉网络，它的解不仅在每一点上看起来都正确，还必须尊重系统的全局预算[@problem_id:3807977]。

更进一步，我们可以将这些守恒定律与自然界的基本对称性联系起来，**诺特定理**优美地描述了这种联系。该定理告诉我们，对于一个系统拉格朗日量（描述其动力学的量）中的每一个[连续对称性](@entry_id:137257)，都有一个相应的[守恒量](@entry_id:161475)。例如，如果一个系统的物理特性不随其在空间中的旋转而改变（旋转对称性），那么它的角动量就必须守恒。我们可以推导出这个[守恒量](@entry_id:161475)的数学形式——例如，对于[中心势](@entry_id:148563)场中的一个粒子，其角动量为 $J = m(x\dot{y} - y\dot{x})$——然后添加一个损失项，惩罚该值与其初始状态的任何偏差[@problem_id:4235665]。这也许是[物理信息](@entry_id:152556)学习最深刻的形式：我们不仅仅是告诉网络一个特定的方程，而是在教它宇宙本身深层、根本的对称性。

### 可能性的艺术：训练、信任与不确定性

拥有一个复杂的[损失函数](@entry_id:136784)是一回事；成功地将其最小化是另一回事。训练PINN是一门艺术，也带来了独特的挑战。

最大的障碍之一是**平衡损失项**。我们的总[损失函数](@entry_id:136784)是数据、PDE残差、边界条件以及可能还有全局守恒定律等项的总和。这些项可能具有不同的物理单位，其量级可能相差许多数量级。如果物理损失比数据损失大一百万倍，网络就会忽略数据。如果数据损失占主导地位，网络就会忽略物理。一个有原则的方法始于**无量纲化**——使用问题的特征尺度来缩放变量，使所有项都变为无量纲。这是物理学和工程学的标准做法，对于稳健的PIML至关重要。即便如此，在训练过程中，各项的相对重要性也可能发生剧烈变化。这催生了**[自适应加权](@entry_id:638030)**方案的开发，其中权重 $\lambda_p$ 不是一个固定的数字，而是动态更新的。一个有力的想法是，用每个损失项方差的倒数来对其加权。这在统计学上是合理的：方差高的项更“不确定”，因此我们应该更少地信任它们[@problem_id:4235651]。

除了得到单一答案，一个真正有用的模型还应该告诉我们它对其预测的置信度有多高。这就引出了**不确定性量化**的关键概念。在建模中，不确定性有两种类型[@problem_id:4235621]。
1.  **[偶然不确定性](@entry_id:154011)（Aleatoric Uncertainty）**：这是系统中固有的随机性或噪声，如传感器噪声或不可预测的[湍流](@entry_id:158585)。它是世界本身的“模糊性”。你无法通过增加同等质量的数据来减少它。
2.  **认知不确定性（Epistemic Uncertainty）**：这是由于我们自身知识的缺乏而产生的不确定性。它源于数据有限或模型不完美。这是我们理解上的“模糊性”。

PIML与不确定性之间有着奇妙的关系。通过融入物理定律，我们为模型提供了大量关于解*应该*如何表现的信息，即使在我们没有数据的区域也是如此。这起到了强大的正则化作用，极大地缩小了可能解的空间，从而降低了模型对真实函数的不确定性。换句话说，**物理约束减少了认知不确定性**[@problem_id:4226920] [@problem_id:4235621]。虽然来自噪声传感器的[偶然不确定性](@entry_id:154011)依然存在，但模型对其插值和外推变得更有信心，因为它知道游戏规则。使用[贝叶斯神经网络](@entry_id:746725)或[深度集成](@entry_id:636362)等技术，我们可以训练出不仅能输出预测值，还能输出代表这种综合不确定性的[可信区间](@entry_id:176433)的PINN。

### 未来的曙光：学习自然法则

到目前为止，我们一直假设我们知道控制PDE，并用它来指导特定解的学习。但是，如果我们能退后一步，学习控制定律本身呢？这就是**[算子学习](@entry_id:752958)**的前沿领域。

[算子学习](@entry_id:752958)的目标不是学习一个将时空中的点映射到一个值（例如，$T(x,t)$）的函数，而是学习整个解*算子*——这个抽象的数学规则 $\mathcal{G}$，它将一个完整的输入函数（如一个力项或材料属性场）映射到一个完整的输出解函数。我们正在学习无限维[函数空间](@entry_id:136890)之间的映射：$u(\cdot) = \mathcal{G}(f(\cdot))$。

像**[深度算子网络](@entry_id:748262)（[DeepONet](@entry_id:748262)）**和**[傅里叶神经算子](@entry_id:189138)（FNO）**这样的架构就是为此任务设计的[@problem_id:4235622]。[DeepONet](@entry_id:748262)通过学习一组输出的基函数和一个根据输入函数计算这些基函数系数的网络来实现这一点。而FNO则在频域中工作，学习如何将输入函数的傅里叶[模式转换](@entry_id:197482)为输出函数的傅里叶模式。

这种方法的潜力非同寻常。通过学习算子本身，我们创建了一个速度极快且通用性强的代理模型。它不再受限于单一的力项或特定的网格分辨率。它已经学会了底层的物理“规则”。一旦训练完成，它几乎可以瞬间为一个*新的*输入函数[求解PDE](@entry_id:138485)，而这项任务用传统求解器则需要一次全新的、漫长的模拟。这是许多[数字孪生](@entry_id:171650)的终极目标：一个不仅记住了某个答案，而且真正学会了物理学的模型。

