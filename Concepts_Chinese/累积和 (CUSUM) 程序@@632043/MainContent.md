## 引言
在许多现实世界的系统中，从工厂生产线到复杂的数字网络，最危险的变化不是突然的冲击，而是缓慢而持续的漂移。一个标准的[控制图](@entry_id:184113)可能会漏掉一台逐渐失校的机器，或者一个以几乎难以察觉的速率消耗资源的恶意软件。这就提出了一个关键问题：我们如何才能在这些微小、累积的偏移造成重大问题之前可靠地检测到它们？答案在于一种强大的统计方法，即累积和（CUSUM）程序。本文全面概述了这一精妙的技术。在第一部分“原理与机制”中，我们将深入探讨 CUSUM 背后的直观逻辑，探索其在序贯假设检验中的深厚统计基础，并理解支配其性能的[基本权](@entry_id:200855)衡。随后，“应用与跨学科联系”部分将展示 CUSUM 惊人的多功能性，追溯其从工业质量控制的起源到其在[环境科学](@entry_id:187998)、[网络安全](@entry_id:262820)、基因组学乃至机器学习算法优化中的现代应用。

## 原理与机制

想象一下，你是一家大型、安静博物馆的保安。你的工作不是检测那些喧闹、明显的砸抢盗贼，而是一种更微妙的威胁：一个窃贼每小时都将一幅无价的画作稍微移动一点，希望每一次微小的位移都不会被注意到。单次测量可能说明不了什么。画作向左移动了一毫米？这可能是光线造成的错觉，也可能是[测量误差](@entry_id:270998)。但如果你对这些微小且方向一致的移动进行持续记录，你很快就会有压倒性的证据证明这是一种蓄意行为。这就是累积和（**CUSUM**）程序的精髓。它关乎的不是单个事件的冲击，而是对微小线索的耐心积累。

### 记忆的守护者：CUSUM 的工作原理

CUSUM 图的核心是一个简单但功能强大的记忆守护者。让我们走进一个制药实验室，那里有一台机器应该生产活性成分浓度为 250 mg/L 的药物。我们逐一进行测量。我们如何判断机器是否已经漂移，现在生产的溶液浓度略高？

CUSUM 程序为我们提供了一个直截了当的方法。我们维持一个运行分数，称之为“怀疑分数”$C_t^+$。我们从零怀疑开始：$C_0^+ = 0$。在每次新测量 $X_t$ 之后，我们使用一个简单的规则来更新我们的分数 [@problem_id:1954143]：

$$C_t^+ = \max(0, C_{t-1}^+ + X_t - K)$$

让我们来分解这个公式。$C_{t-1}^+$ 是我们上一步的怀疑分数——即记忆。$X_t$ 是新的证据。而 $K$ 是一个关键参数，一种“容差”或“让步值”。可以把 $K$ 看作一个略高于我们目标均值的值。在我们的药物浓度示例中，目标是 $\mu_0 = 250$ mg/L，但我们可能将参考值 $K$ 设为，比如说，254 mg/L。

$X_t - K$ 这一项代表了来自当前样本的新证据。如果我们的测量值 $X_t$ 大于 $K$，这一项为正，我们的怀疑分数就会增长。如果 $X_t$ 小于 $K$，这一项为负，我们的怀疑分数就会减少。

但 $\max(0, \dots)$ 这部分是什么意思呢？这也许是最巧妙的特性。它是一个“重置”按钮。如果反对我们假设的证据不断增加——也就是说，如果测量值持续低于 $K$ 并且我们的怀疑分数变为负数——我们不会累积“信用”。我们不希望一系列好的测量结果掩盖了后来出现的真实问题。相反，我们只是将怀疑分数重置为零。这使得 CUSUM 能够随时准备好检测可能在任何时刻开始的偏移。它记住可疑的，但忘记无罪的。

最后一部分是决策阈值 $H$。我们让我们的怀疑分数 $C_t^+$ 随着每次测量上下波动。当它穿过这个阈值 $H$ 的那一刻，警报就会响起。在一个真实的场景中，一连串的测量值，如 253.1, 248.5, ..., 260.4, 257.8 等，最初可能会使怀疑分数在零附近徘徊。但随着持续偏移的发生，分数会稳步攀升：0.2, 6.6, 10.4, 21.5, ... 直到最终超过一个比如为 40 的阈值，发出过程失控的信号 [@problem_id:1954143]。

### 问题的核心：两个似然的故事

这个简单的递归方法很精妙，但它从何而来？它仅仅是一种巧妙的[启发式方法](@entry_id:637904)吗？答案是响亮的“不”。CUSUM 程序植根于统计学中最深刻、最强大的思想之一：**似然比**。

想象一下，对于每一个新的观测，我们都在试图在两个相互竞争的故事或假设之间做出决定 [@problem_id:1283976]：
-   **假设 $H_0$（“受控”故事）：** 过程如预期般运行。例如，一台机器生产有缺陷电路的概率很低，$p_0=0.05$。
-   **假设 $H_1$（“失控”故事）：** 过程已经发生偏移。现在这台机器生产缺陷的概率更高，$p_1=0.15$。

对于我们测试的每一个新电路（它是否有缺陷？），我们可以问：在 $H_1$ 假设下，这个结果比在 $H_0$ 假设下出现的可能性大多少？这些概率之比，$P(\text{data}|H_1) / P(\text{data}|H_0)$，就是似然比。为了让计算变为加法，我们取其对数。这个**[对数似然比 (LLR)](@entry_id:266384)** 是证据的[基本单位](@entry_id:148878)。正的 LLR 支持 $H_1$，而负的 LLR 支持 $H_0$。

CUSUM 统计量在其最基本的形式中，不过是这些 LLR 增量的累积和，并带有我们之前看到的“在零处重置”的规则 [@problem_id:2706777]：

$$C_n = \max(0, C_{n-1} + S_n)$$

其中 $S_n = \ln\left(\frac{P(X_n | H_1)}{P(X_n | H_0)}\right)$ 是第 $n$ 次观测的[对数似然比](@entry_id:274622)。这是一个深刻的结果。它告诉我们，CUSUM 程序不仅仅是某个随意的规则；事实上，它是用于在两个假设之间做出决策的*最优*序贯检验。它以最有效的方式处理信息。

那么，这如何与我们简单的公式 $X_t - K$ 联系起来呢？当数据被假定为服从正态（高斯）[分布](@entry_id:182848)时——这在许多物理过程中很常见——均值从 $0$ 偏移到 $\mu$ 的单一样本[对数似然比](@entry_id:274622)恰好是观测值 $r_k$ 的一个线性函数 [@problem_id:2706777]：

$$S_k = \frac{\mu}{\sigma^2} r_k - \frac{\mu^2}{2\sigma^2}$$

仔细看！这正是我们的观测值 $r_k$ 乘以一个因子，再减去一个常数。这与我们简单的增量 $X_t - K$ 的形式完全相同。CUSUM 程序统一了这两个世界：一方面是简单、直观的厨房配方，另一方面是深刻、有原则的最优统计检验。

### 通往真相的赌徒漫步

我们可以将 CUSUM 统计量 $C_t$ 的历程想象成一种“赌徒漫步”。该统计量是我们的赌徒，从零美元开始。在每一步，它接收到一份新证据（LLR 增量）并将其加到总额中。赌场有一条特殊规则：如果赌徒的总额低于零，庄家就将其重置为零（一个反射壁）。在房间的另一端，有一条标有 $H$ 的线，线后是巨奖。如果赌徒的财富曾越过这条线（一个吸收壁），游戏就停止，警报就会响起。

这场漫步的行为完全取决于哪个“故事”是真的。

如果过程**受控（$H_0$）**，LLR 增量平均来说将是负的 [@problem_id:2706777]。我们的赌徒正在玩一个输钱的游戏。漫步具有负向漂移，不断被向下拉并重置为零。穿过高阈值 $H$ 是可能的，但这需要一连串非常不幸的误导性证据。这就是一次**误报**。这种情况发生的频率如何？直到发生误报的平均步数称为**误报平均游程长度**，或 **$ARL_0$**。在一些简单的情况下，例如对于抛硬币的过程，$ARL_0$ 可以被精确计算 [@problem_id:694700]。更一般地，一个优美而有力的结果表明，$ARL_0$ 随阈值 $h$ *指数*增长：$ARL_0 \asymp \exp(h)$ [@problem_id:2706777]。这意味着，只需稍微提高我们的阈值，我们就可以使误报变得极其罕见。

如果过程**失控（$H_1$）**，LLR 增量将有一个正的平均值。我们的赌徒现在正在玩一个赢钱的游戏！漫步具有正向漂移，稳步向阈值 $H$ 前进。穿过它的平均时间是**平均检测延迟**。那么是什么决定了这次前进的速度呢？是**库尔贝克-莱布勒 (KL) 散度**，$D = \mathbb{E}_1[S_n]$，也就是在“失控”假设下 LLR 的平均值 [@problem_id:1283976]。KL 散度是衡量两个统计故事 $H_0$ 和 $H_1$ 之间“距离”或“可区分性”的基本度量。偏移越大，KL 散度越大，向阈值攀升得越陡。检测延迟在一阶近似下，就是 $h/D$。

这就把我们带到了统计学中最精妙的权衡之一 [@problem_id:2706794]。通过结合我们的两个结果，我们可以消除任意的阈值 $h$，并直接关联两个性能指标：

$$\text{平均检测延迟} \approx \frac{\ln(\text{误报平均游程长度})}{D(\text{受控 } || \text{ 失控})}$$

这个非凡的公式支配着任何试图检测变化的人的生活。它告诉你没有免费的午餐。如果你想让误报变得极其罕见（一个大的 $ARL_0$），你必须接受一个对数级更长的等待时间来检测一个真实的变化。而你检测任何变化的能力，从根本上受限于“之后”状态与“之前”状态的可区分性，这种可区分性由 KL 散度 $D$ 来衡量。

### 基础之上：实践智慧与精妙扩展

CUSUM 框架的美在于它融合了理论上的最优性和实践上的灵活性。但要明智地应用它，需要理解其假设。

**均值 vs. [方差](@entry_id:200758)：** 标准的 CUSUM 检验是一个专家。它对过程中**均值的**微小、持续**偏移**极其敏感。然而，它对其他参数的变化，如[方差](@entry_id:200758)，基本上是盲目的。如果一台机器变得更加不稳定（[方差](@entry_id:200758)更高），但其平均输出保持不变，残差的 CUSUM 将不会显示出系统性的漂移。为此，我们需要一个不同的工具，即**平方累积和 (CUSUMSQ)**，顾名思义，它累积的是平方残差，专门用于检测[方差](@entry_id:200758)的变化 [@problem_id:2884946]。

**独立性的神圣性：** 整个[对数似然](@entry_id:273783)推导及其所带来的最优性，都建立在一个关键假设之上：证据的增量是**独立同分布 (i.i.d.)** 的。如果我们的数据是相关的，比如股价，今天的价值取决于昨天的价值，那会发生什么？直接将 CUSUM 应用于这种“有色”噪声会违反假设并破坏最优性。解决方案非常巧妙：我们首先对数据进行“[预白化](@entry_id:185911)”。我们建立一个小模型（如 `AR(1)` 模型）来根据过去预测当前值，然后我们将 CUSUM 应用于预测误差流，即**新息**。这些新息，根据设计，是 i.i.d. 的，从而恢复了 CUSUM 发挥其魔力的条件 [@problem_id:2707658]。这表明 CUSUM 框架并不脆弱；通过与其他建模工具结合，它可以适应复杂的现实世界系统。出于同样的原因，当使用 CUSUM 检查一个复杂系统模型是否仍然有效时，将其应用于模型的单步[预测误差](@entry_id:753692)（或**递归残差**）比应用于简单的 OLS 残差要好得多，因为如果模型正确，前者被设计为独立的 [@problem_id:2884946]。

CUSUM 图远不止是质量[控制图](@entry_id:184113)上的一条线。它是序贯[假设检验](@entry_id:142556)的化身，是有目的的[随机游走](@entry_id:142620)，是累积证据力量的证明。它教导我们，通过耐心倾听数据的低语，我们最终能够检测到周围世界中最微妙的变化。

