## 应用与跨学科联系

在学习了[子空间](@entry_id:150286)嵌入的原理之后，我们现在可能感觉自己有点像一个刚学会国际象棋规则的学生。我们理解了棋子的走法、特性以及游戏的目标。但是国际象棋真正的美，它的灵魂，只有在我们看到大师对弈时才会显现——当规则转变为策略、惊喜和艺术时。[子空间](@entry_id:150286)嵌入也是如此。它的原理虽然优雅，但只有当我们看到它在行动中解决实际问题，并在不同科学和工程领域之间建立起意想不到的联系时，才真正焕发生机。在这里，抽象变得具体，巧妙的技巧揭示了它作为一个深刻而多功能工具的本质。

### 驯服数据洪流

在当今世界，我们正被数据淹没。从社交媒体网络产生的海量信息流，到天文学调查传回的PB级数据，再到环境传感器的持续读数，我们生成数据的能力已经远远超过了我们常规存储和分析数据的能力。大规模计算的主要瓶颈往往不是处理器的速度，而是将数据从庞大、缓慢的存储（如硬盘或[分布式文件系统](@entry_id:748590)）移动到处理器进行实际工作的小而快的内存中所花费的时间。这就像试图在一个小厨房里准备一顿盛宴，而冰箱却在一公里之外；你花在来回取食材上的时间会比实际烹饪的时间还多。

这是[子空间](@entry_id:150286)嵌入诞生之初要解决的第一个也是最基本的问题。想象你有一个巨大的矩阵$A$，代表着，比如说，数千名顾客的数百万次购买记录。这个矩阵太“高”了，无法放入你电脑的快速内存中。经典的最小二乘分析——也许是为了找到最佳定价模型——将需要对数据进行繁琐、重复的扫描，以高昂的通信成本从慢速存储中获取[数据块](@entry_id:748187)[@problem_id:3537901]。

[子空间](@entry_id:150286)嵌入，我们神奇的透镜，允许我们将这个巨大的矩阵$A$投影到一个微小、可管理的矩阵$SA$上。这个[草图矩阵](@entry_id:754934)非常小，可以舒适地放在快速内存的“厨房”里。现在，我们可以利用处理器的全部能力和数值稳定、久经考验的算法（如[QR分解](@entry_id:139154)）对这个小矩阵进行分析，而无需再回到“冰箱”去[@problem_id:3572870]。神奇之处在于，我们从这个小的、草图化的问题中得到的解，以极高的概率，是我们将从原始的、庞大的问题中获得的解的近乎完美的近似。这一原理是现代算法背后的主力，这些算法能够单遍分析流式数据，在信息飞速掠过时理解其含义，而无需将其全部存储[@problem_id:3570147]。

### 仓促的代价：统计学上的权衡

这听起来好得令人难以置信，不是吗？我们以极小的成本解决了一个巨大的问题。肯定有什么代价吧。确实有，但这个代价本身也极具启发性。世界不仅仅是数据；它是由[噪声污染](@entry_id:188797)的数据。统计学和机器学习的一个核心目标是在这些噪声数据中找到隐藏的真实、潜在的信号。

让我们考虑一个简单的、理想化的情景来获得一些直觉[@problem_id:3570146]。想象一下我们的数据来自一个完美的线性模型，但每个观测值都混杂了一些随机的高斯噪声。传统的[普通最小二乘法](@entry_id:137121)（OLS）给了我们真实参数的一个“无偏”估计——这意味着如果我们重复实验很多次，我们估计的平均值会正好落在真实值上。然而，由于噪声，任何单次估计都会有一定偏差；这种“[抖动](@entry_id:200248)”由[估计量的方差](@entry_id:167223)来量化。

那么，我们的草图估计量会发生什么呢？值得注意的是，在这些理想化的条件下，草图估计量也是无偏的！它不会系统性地将我们引向错误的方向。然而，它的[方差](@entry_id:200758)高于[OLS估计量](@entry_id:177304)的[方差](@entry_id:200758)。通过使用大小为$m$的草图而不是全部$n$个数据点，我们实际上将[方差](@entry_id:200758)放大了大约$n/m$倍。这是对偏差-方差权衡的一个优美而清晰的阐述。我们用计算资源换取了统计上的确定性。我们更快地得到答案，但这个答案更不确定一些，更“[抖动](@entry_id:200248)”一些。[子空间](@entry_id:150286)嵌入给了我们一个可以调节的旋钮：我们可以选择愿意付出多少[方差](@entry_id:200758)来换取一定水平的计算速度。

### “美丽”的错误：作为[隐式正则化](@entry_id:187599)的草图法

这把我们带向一个真正美妙而令人惊讶的联系。如果一个更小的草图会增加[方差](@entry_id:200758)，那么如果我们使用一个*太小*的草图——比理论要求的忠实嵌入所需的尺寸还小——会发生什么？这个方法会简单地失败并产生无稽之谈吗？

答案是响亮的“不”，而且这是该领域最美的洞见之一。当我们面临一个非常“病态”的问题——信号弱而噪声强的问题——传统的最小二-乘解可能会极度不稳定。它如此努力地去拟合噪声数据，以至于抓住了虚假的关联，导致一个[方差](@entry_id:200758)极高的解。一种经典的统计技术来对抗这种情况叫做*[Tikhonov正则化](@entry_id:140094)*，它有意地引入少量偏差来稳定解，有效地抑制了对数据中噪声大、不可靠部分的响应。

一个“尺寸不足”的草图做了非常相似的事情，但原因完全不同[@problem_id:3570178]。一个小的[随机投影](@entry_id:274693)没有足够的能力捕捉原始数据的所有特征。就像一个漫画家必须选择强调脸部的哪些特征一样，草图会自然地保留数据中最强、最主要的模式（高能量的[奇异向量](@entry_id:143538)），而弱的、充满噪声的和不可靠的模式则被减弱或完全丢失。

结果是，来自尺寸不足的草图的解偏向于数据的主成分，并且其[方差](@entry_id:200758)大大降低，因为噪声方向已被滤除。换句话说，纯粹计算性的、过于激进的草图操作，与刻意进行的[统计正则化](@entry_id:637267)行为具有相同的定性效果。这是数学统一性的一个惊人例子，一个计算捷径无意中重新发现了一个深刻的统计原理。

### 应对复杂世界的多功能工具箱

草图法的威力远远超出了简单的[最小二乘问题](@entry_id:164198)。它是一种通用工具，可以集成到大量更复杂的计算流程中。

数据分析的基石之一是[奇异值分解](@entry_id:138057)（SVD），这是一种强大的矩阵分解方法，能揭示数据集的隐藏结构或“骨架”。它是人脸识别、推荐系统和文本主题建模背后的引擎。然而，计算一个大矩阵的SVD成本高得令人望而却步。在这里，草图法同样能派上用场。通过首先创建矩阵[列空间](@entry_id:156444)的一个小草图，我们可以将问题简化为计算一个更小矩阵的SVD，从而极大地加速了这些隐藏模式的发现[@problem_id:3569838]。

此外，许多现实世界的问题并非无约束的。工程设计必须尊重物理定律，金融投资组合必须遵守预算，机器人的路径必须避开障碍物。这些都是*约束优化*问题。[子空间](@entry_id:150286)嵌入也可以巧妙地应用于此。诀窍是将问题分为两部分：*必须*满足的硬约束，以及我们希望最小化的[目标函数](@entry_id:267263)。我们可以使用经典技术，如[零空间法](@entry_id:752757)，来从数学上强制执行约束，将问题转化为一个新的、在更低维空间中的无约束问题。然后，我们对这个更简单、无约束的问题应用我们的草图工具，以找到一个近似最优解，这个解由于其构造方式，完美地满足了原始约束[@problem_id:3570186]。

### 助力现代科学与人工智能的引擎

也许[子空间](@entry_id:150286)嵌入最激动人心的应用是在科学和人工智能的前沿。现代机器学习由一种称为[自动微分](@entry_id:144512)（AD）的技术驱动，这是像PyTorch和TensorFlow这样的框架内部的算法引擎。AD使我们能够高效地计算训练大型[神经网](@entry_id:276355)络所需的梯度（导数）。在许多科学应用中，如天气预报或地质反演，类似的技术被用来解决庞大的[优化问题](@entry_id:266749)。

通常，这些方法需要使用雅可比矩阵进行计算，该矩阵包含模型的所有[偏导数](@entry_id:146280)。对于一个深度神经网络或高分辨率气候模型，这个[雅可比矩阵](@entry_id:264467)可能大得惊人。将其具体化是完全不可能的。在这里，草图法提供了一个惊人优雅的解决方案。我们不是要求我们的AD系统计算复杂函数$f(x)$的导数，而是要求它计算一个*草图化*函数$S f(x)$的导数[@problem_id:3416440]。微积分的链式法则发挥其魔力，AD系统自动为我们提供了草图化的[雅可比矩阵](@entry_id:264467)$S J(x)$，而无需形成完整的$J(x)$。这可以将训练的内存需求降低几个[数量级](@entry_id:264888)，使我们能够构建和探索以前无法想象的规模和复杂性的模型。在像Gauss-Newton这样的迭代求解器中，这些草图算子可以“无矩阵”地应用，结合前向和反向模式AD来隐式地、一步步地解决大规模[线性系统](@entry_id:147850)。

故事甚至还没有结束。这个[随机化](@entry_id:198186)工具箱是自引用的。我们甚至可以用一个草图来让后续的草图变得更好！对于某些数据集，某些行或列在几何上比其他行或列更“重要”。一个初步的、快速的草图可以用来快速估计这些“杠杆分数”，识别出我们数据的关键部分。然后我们可以执行第二次、更仔细的草图，更多地关注这些重要部分[@problem_id:3570154]。或者，我们可以应用一个随机化的“预处理器”，在进行草图之前将数据混合起来，使其更均匀，从而用更少的样本就“更容易”忠实地嵌入[@problem_id:3416481]。这就像在使用长焦镜头之前，先用广角镜头勘察场景一样。

从一个缩小矩阵的简单技巧开始，我们经历了一系列统计权衡，偶然发现了与正则化的深刻联系，并抵达了人工智能的前沿。[子空间](@entry_id:150286)嵌入是一个美丽的证明，展示了找到正确视角的力量——一幅简单的图画，却保留了复杂现实的本质真理。这是一个正在重塑我们计算世界的原则。