## 引言
如果能让计算机只在绝对必要时才执行工作，会怎么样？这种“按需计算”的策略，即所谓的[惰性求值](@entry_id:751191)（lazy evaluation），是许多[函数式编程](@entry_id:636331)语言的基石，它通过避免不必要的计算来承诺极高的效率。然而，这个简单的承诺背后隐藏着一个复杂且影响深远的世界，尤其是当纯函数这个纯净的世界与改变状态的程序这一混乱现实——即所谓的副作用（side effects）——发生碰撞时。正是在这个交汇点，[惰性求值](@entry_id:751191)的真正力量和潜在风险才得以显现。

本文将揭开这个关键主题的神秘面纱。首先，在“原理与机制”部分，我们将剖析其核心概念，对比“健忘的”[传名调用](@entry_id:753236)（call-by-name）策略与“高效的”传需调用（call-by-need）方法。我们将探讨 thunk 和[记忆化](@entry_id:634518)（memoization）等概念的工作原理，并见证当副作用介入时所引发的混乱。然后，在“应用与跨学科联系”部分，我们将看到这些思想如何转化为强大的工具，从高性能日志记录和无限数据结构，到与机器学习、金融建模等领域的惊人相似之处，无所不包。让我们从探索这个将工作推迟到绝对必要时才执行的简单思想开始吧。

## 原理与机制

想象一下，你请一位才华横溢但古怪的数学家为你计算一个值，比如说，第 10000 个素数。你写下请求，递给她，并说：“我正在研究一个公式，之后会需要这个答案。”你不是现在就需要，只是最终会用到。你刚刚完成了一次[惰性求值](@entry_id:751191)。你没有强迫工作立即完成，而是为这个值创建了一张“承诺票据”。在计算机科学中，这张承诺票据被称为 **thunk**——一个被打包好的计算，静静地等待着被告知：“轮到你了。求值！”这种将工作推迟到绝对必要时才执行的简单思想，正是[惰性求值](@entry_id:751191)的核心。它承诺了极高的效率：为什么要计算一些你可能永远不会用到的东西呢？但正如我们将看到的，这个承诺伴随着一些有趣而深远的后果，特别是当我们的纯净数学世界与一个变化万千的混乱现实发生碰撞时。

### 健忘的学生 vs. 高效的学生

让我们进一步完善这个类比。假设要计算的不是素数，而是一个你命名为 $x$ 的更简单的表达式。而你的公式需要多次使用这个值，比如在表达式 $x + x$ 中。我们的数学家有两种方式来处理这个问题。

第一种方式是**[传名调用](@entry_id:753236)（call-by-name）**。可以把它想象成一种“健忘学生”的方法。为了计算加法的第一部分，你请求 $x$ 的值。学生勤奋地执行计算并把答案给你。片刻之后，为了计算加法的第二部分，你再次请求 $x$。由于完全忘记了之前的结果，学生把*完全相同的计算*又做了一遍。如果你的公式是 $x + x \times x$，这个可怜的学生将需要重新计算 $x$ 三次。

第二种更聪明的方式是**传需调用（call-by-need）**，这也是大多数人所说的“[惰性求值](@entry_id:751191)”。这是一种“高效学生”的方法。第一次你请求 $x$ 时，学生执行计算，把答案给你，但同时也在笔记本上记下了这个结果。之后每一次你请求 $x$ 时，学生只需瞥一眼笔记本，然后把答案读给你。昂贵的计算工作只做一次。这种缓存结果的技巧被称为**[记忆化](@entry_id:634518)（memoization）**。

对于纯粹的数学计算，这两种方法之间唯一的区别在于性能。如果一个值被使用超过一次，传需调用显然更快。但当计算本身会产生后果时，会发生什么呢？

### 当惰性遇见现实：副作用的混乱

让我们想象一下，计算 $x$ 不仅仅是得到一个数字，而是一个动作：“去黑板前，把你在那里看到的数字加一，然后告诉我新的数字。”这种改变黑板的行为就是一个**副作用（side effect）**——计算不再是私事；它影响了一个共享的、公共的状态。

现在，让我们来求表达式 $y + (y \times y)$ 的值，其中 $y$ 就是我们那个会修改黑板的计算。我们从黑板上的数字 $0$ 开始。

在我们健忘的学生（**[传名调用](@entry_id:753236)**）那里，故事的展开出人意料 [@problem_id:3675810]。
1. 为了计算这个和，我们首先需要最左边 $y$ 的值。学生走到黑板前，看到 $0$，擦掉它，写下 $1$，然后报告：“值是 $1$。”
2. 表达式现在是 $1 + (y \times y)$。为了计算乘积，我们需要下一个 $y$。学生已经忘了一切，又回到黑板前。黑板上现在是 $1$。学生擦掉它，写下 $2$，然后报告：“值是 $2$。”
3. 表达式现在是 $1 + (2 \times y)$。我们需要最后一个 $y$。学生走到黑板前，看到 $2$，擦掉它，写下 $3$，然后报告：“值是 $3$。”
4. 最终的计算是 $1 + (2 \times 3)$，等于 $7$。黑板上最终显示的是 $3$。

结果很奇怪。每次我们请求 $y$ 的“值”，它都在变！这就是将重复求值与副作用结合起来的危险之处。

现在，让我们看看我们高效的学生（**传需调用**）是如何驯服这种混乱的 [@problem_id:3675810] [@problem_id:3675813]。
1. 对于第一个 $y$，学生走到黑板前，把 $0$ 改成 $1$，然后报告：“值是 $1$。”关键是，学生还在自己的私人笔记本上记下了“结果：1”。
2. 对于第二个 $y$，你再次请求。学生只是看了看笔记本，然后说：“值是 $1$。”黑板没有被触碰。
3. 对于第三个 $y$，同样如此。笔记本上写着 $1$。黑板没有被触碰。
4. 最终的计算是 $1 + (1 \times 1)$，等于 $2$。黑板上最终显示的是 $1$。

通过[记忆化](@entry_id:634518)结果，传需调用确保了计算——及其副作用——最多只发生一次。它提供了一个稳定、可预测的世界，在这个世界里，一个表达式只有一个值和一个效果，无论你请求它多少次。

### 看不见的顺序：日常代码中的惰性

这种“只求值必要部分”的原则并不仅仅适用于深奥的编程语言。它通过**短路求值（short-circuit evaluation）**被内建于你日常使用的大多数语言的逻辑之中。

考虑表达式 $a \land b \lor c$（或 `a  b || c`）。当程序求值这个表达式时，它首先检查 $a$。如果 $a$ 是假，那么子表达式 `a  b` 就是假，因此对 $b$ 的求值会被跳过，程序会转而去求值 $c$。类似地，如果先对 $a$ 再对 $b$ 求值后发现它们都为真，那么子表达式 `a  b` 为真。接着，因为 `true || anything` 总是为真，对 $c$ 的求值就会被跳过 [@problem_id:3633662]。

这就是[惰性求值](@entry_id:751191)的实际应用！$b$ 和 $c$ 的求值被暂停，取决于 $a$ 的结果。如果这些检查涉及到副作用，比如发出网络请求或记录一条消息，这种惰性将决定这些副作用是否会发生。这揭示了一种美妙的统一性：[惰性求值](@entry_id:751191)并非怪癖；它是一种融入计算结构的基本优化策略。

### 不可预测性的危险

我们已经看到，传需调用通过确保副作用最多运行一次来驯服它们。但它们*何时*运行呢？对于像 `print("A") + print("B")` 这样的表达式，严格的 `+` 运算符在相加之前需要两个值。它必须强制两个 thunk 求值。但它先强制哪一个呢？

如果语言没有指定顺序，[运行时系统](@entry_id:754463)就可以自由选择。它可能先求值左边，产生输出 `AB`。也可能先求值右边，产生 `BA`。这就是**非确定性（non-determinism）**——同一个程序运行两次可能会产生不同的结果。对于构建可靠的软件来说，这是一个可怕的前景 [@problem_id:3649634]。

为了恢复理智，语言设计者有两条主要路径。第一条很简单：强制规定[求值顺序](@entry_id:749112)。例如，总是从左到右求值 `+` 的参数。这使得副作用变得可预测。

第二条路径更为深刻，也是像 Haskell 这样的纯函数式语言所选择的路径。它认为副作用与纯计算是如此不同，以至于它们应该被完全分开。像 `print("A")` 这样的表达式不仅仅产生一个值；它产生一个*动作*。然后，你可以使用特殊的组[合子](@entry_id:146894)（通常在一个称为**单子 (monad)** 的结构内）将这些动作显式地排序成一个单一的、确定性的与世界交互的“配方”。这种设计优雅地分离了“是什么”（纯计算，可以按任何顺序[惰性求值](@entry_id:751191)）和“怎么做”（动作的序列，是固定的和可预测的）。

### 机器中的幽灵：它究竟是如何工作的

[惰性求值](@entry_id:751191)的优雅背后，隐藏着一台在幕后工作的复杂机器。理解其机制能揭示更多关于所涉及的权衡。

#### 用 `let` 控制工作

在一种传需调用的语言中，你如何告诉编译器你想要共享一个计算？你可以使用 `let` 绑定。考虑以下两个程序之间的区别：
1. `expensive() + expensive()`
2. `let x = expensive() in x + x`

在第一个程序中，编译器看到了 `expensive()` 的两次不同出现。它创建了两个独立的 thunk，昂贵的计算被执行了两次。在第二个程序中，`let` 绑定告诉编译器：“有一个东西，名为 $x$，由 `expensive()` 定义。请共享它。”编译器为 $x$ 创建一个单一的 thunk。当和式中的第一个 $x$ 被求值时，thunk 被强制执行，结果被[记忆化](@entry_id:634518)。当需要第二个 $x$ 时，会立即使用[记忆化](@entry_id:634518)的值。`let` 关键字成为了一个控制性能的强大工具，它明确地区分了重新计算表达式和重用其结果 [@problem_id:3649637]。

#### 囤积的 [Thunk](@entry_id:755964) 与[内存泄漏](@entry_id:635048)

一个 thunk 必须记住两件事：要计算的表达式和它完成计算所需的**环境**。这个环境包含了表达式可能需要的所有变量的值（或位置）。一种天真的实现，即环境只是一个指向 thunk 创建时整个上下文的指针，可能会导致一个灾难性的副作用，称为**空间泄漏（space leak）**。

想象一个函数为表达式 $x + 1$ 创建了一个微小的 thunk。这个 thunk 只需要知道 $x$。但环境中还有两个巨大的、数兆字节的数组，$y$ 和 $z$。如果这个 thunk 被保存以供日后使用，在该函数结束后，[垃圾回收](@entry_id:637325)器会看到这个 thunk 仍然存活。通过跟踪 thunk 的环境指针，它会断定*整个原始上下文*，包括那些巨大的数组，仍然是需要的。这个 thunk，就像一只囤积癖的老鼠，持有了它永远不会使用的数GB内存 [@problem_id:3675800]。

解决方案是一项精妙的[编译器优化](@entry_id:747548)技术：**环境裁剪（environment trimming）**。编译器分析 thunk 的表达式（$x+1$），看到唯一的**[自由变量](@entry_id:151663)**是 $x$，于是构建一个量身定制的、最小化的环境，只包含访问 $x$ 所需的信息。这使得巨大的数组可以被[垃圾回收](@entry_id:637325)，解决了空间泄漏问题。这通常还涉及到将变量 $x$ 从其在程序栈上的临时住所**提升（lifting）**到堆上一个更永久的居所，以确保它的生命周期和需要它的 thunk 一样长。像未使用的 thunk 这样的死代码可以被完全消除，进一步改善空间行为 [@problem_id:3636200]。

#### 规则的例外

传需调用中的[记忆化](@entry_id:634518)原则非常一致，即使在出错时也是如此。如果强制一个 thunk 求值没有产生一个值，而是抛出了一个异常呢？thunk 会[记忆化](@entry_id:634518)*异常本身*。任何后续尝试强制同一个 thunk 求值的操作都不会重新运行失败的计算；它会立即重新抛出缓存的异常。这确保了求值一个表达式的结果，无论是一个值还是一个错误，都是稳定的，并且只被决定一次 [@problem_id:3661397]。这与[传名调用](@entry_id:753236)形成鲜明对比，在[传名调用](@entry_id:753236)中，如果全局状态发生了变化，第二次重新求值表达式可能会成功。

### 纯粹的代价

这整个[惰性求值](@entry_id:751191)系统在**纯[函数式编程](@entry_id:636331)**中找到了它最自然的家园，而纯[函数式编程](@entry_id:636331)建立在**引用透明性（referential transparency）**的基石之上。这个原则指出，你可以用任何表达式的值来替换该表达式，而不会改变程序的含义。就像在[数学证明](@entry_id:137161)中你可以用 $4$ 替换 $2+2$ 一样，你也应该能够在你的代码中做同样的事情。

然而，一个真正的指针恒等运算符 `idEq`，它检查两个参数是否是内存中完全相同的对象，可能会打破这种幻象 [@problem_id:3675841]。在一个惰性世界里，表达式 `let x = expensive() in idEq(x,x)` 的求值结果会是 `true`，因为两个参数都指向为 $x$ 创建的那个单一 thunk。但语义上等价的表达式 `idEq(expensive(), expensive())` 的求值结果会是 `false`，因为编译器为每个参数创建了两个不同的 thunk。突然之间，我们能够区分两个本应意义相同的表达式。引用透明性被打破了。

这种冲突揭示了关于语言设计的深刻真理。为了保持数学上的纯粹性，你必须遵守纪律。你要么禁止这样的运算符，要么将其重新定义为关于值相等（从而保持纯粹性），或者——在最复杂的解决方案中——将其隔离起来。你承认观察内存是一种“不纯”的动作，并使用类型系统（也许就是我们之前看到的同样的单子机制）在纯粹的、永恒的值世界和不纯的、有状态的内存地址世界之间建立一堵墙。

从一个简单的承诺——“非到必需，不动算盘”——展开了一幅由权衡与技术构成的丰富画卷，触及性能、程序正确性、[内存管理](@entry_id:636637)，以及程序“纯粹”意味着什么的哲学本身。它向我们展示，计算机科学中最简单的思想往往引出最深刻和最美丽的复杂性。

