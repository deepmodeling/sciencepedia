## 引言
在科学研究中，一个常见的挑战是比较多种处理的效果，这些处理可以是从不同的药物到新的软件界面。然而，受试者——无论是患者、农场还是数据集——之间固有的变异性可能会掩盖真实的效果，使得直接比较产生误导。当每项处理都在独特的条件下进行测试时，我们如何才能公平地评估它们呢？这个从噪声中分离信号的问题是数据分析中的一个根本性障碍。

弗里德曼检验提供了一个优雅而强大的解决方案。它是一种[非参数方法](@entry_id:138925)，专为对相同受试者进行多次测量的实验而设计。该检验不纠结于原始数值，而是通过将复杂的测量值转换为简单的秩来简化问题。本文将揭开弗里德曼检验的神秘面纱，引导您了解其核心逻辑和实际应用。“原理与机制”部分将解析该检验的统计引擎，解释区组化和秩转换如何控制变异性。“应用与跨学科联系”部分将展示该检验的多功能性，探索其在农业、医学和机器学习等不同领域中的应用。

## 原理与机制

想象一下，你是一场才艺表演的评委。你有几位参赛者，但他们表演的条件千差万别。一个在安静的录音室里唱歌，另一个在嘈杂的街角，第三个则在雷暴中。你如何公平地判断谁是最有才华的歌手？比较他们的原始录音是没有意义的；背景噪音——即“无关变异”——会淹没真正的才华。你不会比较绝对的分贝水平；你会*在每位表演者各自的情境中*聆听，然后问：“在这些条件下，他们表现得如何？”你可能会给他们排序：“街角的那位最令人印象深刻，其次是在雷暴中的那位，最后是录音室里的那位。”

这种基于情境的简单排序行为，正是弗里德曼检验核心的深刻见解。

### 驯服混乱：区组化的力量

在科学和医学领域，我们一直面临着这种“才艺表演”问题。假设我们想比较三种降低血压的新药。我们可以将药物 A 给一组人，药物 B 给另一组，药物 C 给第三组。这是一个简单的设计，但它有一个巨大的缺陷。人与人之间并不相同。一组人可能碰巧年龄更大、饮食不同，或者基线血压更高。如果那一组表现出最好的结果，是因为药物，还是因为他们本身就是这样？我们这是在拿苹果和橘子作比较。

一个更巧妙的实验设计方法是让*每个人*都服用*每一种*药物，并在两次用药之间设置“洗脱期”，让一种药物的效果在开始下一种药物之前消退。这被称为**重复测量**或**交叉**设计。在这种设置中，每个人都作为自己的对照。我们不再是比较服用药物 A 的 1 号受试者和服用药物 B 的 2 号受试者；我们是在 1 号受试者内部比较药物 A、B 和 C，然后在 2 号受试者内部单独比较，以此类推。

用统计学术语来说，每个人都是一个**区组**。一个区组是一组实验单元，这些单元彼此之间的相似性高于与其他区组中的单元。通过在这些区组内进行比较，我们可以驯服个体变异性带来的混乱，并分离出我们感兴趣的处理的真实效果。这是需要像 [Kruskal-Wallis 检验](@entry_id:163863)（用于独立组）这样的检验与需要弗里德曼检验（用于区组化、相关组）的设计之间的根本区别[@problem_id:1961672] [@problem_id:4921308]。

### 伟大的均衡器：从测量值到秩

现在，我们有了数据。对于每个人，我们都有每种药物对应的血压测量值。但是，1 号患者可能天生血压高（比如读数在 150 mmHg 左右），而 2 号患者天生血压低（读数在 110 mmHg 左右）。140 mmHg 的读数对 1 号患者来说是很大的改善，但对 2 号患者来说却是糟糕的结果。绝对数值具有误导性。

这时，一个优美而简化的步骤出现了。在每个区组——即每个人——内部，我们只对结果进行**排序**。我们不问“血压是多少？”我们问：“哪种药对这个人效果最好？”我们可能会将产生最低血压的药物赋予秩 1，次低的赋予秩 2，依此类推。

让我们来看一个实际例子。考虑一项研究，比较 $k=4$ 种不同酶（A, B, C, D）在来自 $b=6$ 个不同受试者的样本中的活性。每个受试者都是一个区组。对于 1 号受试者，测得的活性可能是 $A=12.3$，$B=10.5$，$C=15.2$ 和 $D=13.8$。我们不用这些数值，而是对它们进行排序。最低的是 $10.5$（B），所以它获得秩 1。接下来是 $12.3$（A），秩 2。然后是 $13.8$（D），秩 3。最后是 $15.2$（C），秩 4。我们对六个受试者中的每一个都单独进行这样的操作[@problem_id:4919568]。

这个排序过程是一个伟大的均衡器。它是一种**非参数**方法，意味着它对我们数据的分布形状不做任何假设。测量值可能严重偏斜或充满异常值；秩对此并不在意。数据可能完全是**序数**标度（比如从“轻微”到“严重”的疼痛评分），在这种情况下计算平均值毫无意义；而秩非常适合这种情况[@problem_id:4546895]。这个简单的转换丢弃了充满噪声、特定于区组的信息，而保留了我们唯一关心的东西：处理在每个区组内的相对表现。

如果出现结值（ties）怎么办？例如，在一项对四个数据处理流程进行基准测试的研究中，一个捐赠者可能从两个流程中获得相同的分数。很简单：它们共享秩。如果流程 B 和 C 并列第二和第三名，我们不掷硬币决定。我们给它们两者平均秩 $2.5$。逻辑保持不变[@problem_id:4546875]。

### 纯粹随机的世界：零假设

现在，让我们扮演一下“魔鬼的代言人”。如果所有处理的效果完全相同呢？如果我们只是在测试四种不同颜色的糖丸呢？这就是我们的**零假设 ($H_0$)**：处理之间没有系统性差异。

如果零假设为真，那么对于任何给定的患者，他们产生的一组成果只是一组数字。我们附加的标签——“药物 A”、“药物 B”、“药物 C”——是毫无意义的。将秩分配给这些标签的任何方式都纯粹是随机偶然的结果。对于 $k$ 种处理，秩 $\{1, 2, ..., k\}$ 在每个区组内只是被随机打乱和分发。这就是**可交换性**原则[@problem_id:4835999]。

如果秩是随机分配的，那么在许多区组（患者）中，每种处理应该都会得到高低不一的秩。如果我们把处理 A 的所有秩加起来，然后对 B、C 和 D 做同样的操作，我们期望这些**秩和**（$R_A, R_B, R_C, R_D$）会彼此非常接近。巨大的差异——比如说，处理 C 持续获得高秩（表示表现差），而处理 A 持续获得低秩（表示表现好）——会让我们产生怀疑。这将是反对纯粹随机世界的证据。

### 弗里德曼统计量：量化意外

我们如何将这种“怀疑”转化为一个数字？我们需要一种正式的方法来衡量我们观察到的秩和与零假设下[期望值](@entry_id:150961)的偏离程度。这个数字就是**弗里德曼统计量**，通常表示为 $Q$。

首先，任何处理的期望秩和是*什么*？对于 $k$ 种处理，秩为 $\{1, 2, ..., k\}$。平均秩就是 $\frac{k+1}{2}$。由于我们有 $b$ 个区组（患者），任何处理的期望秩和就是 $E[R_j] = b \frac{k+1}{2}$。

[检验统计量](@entry_id:167372) $Q$ 本质上是衡量我们观察到的秩和 $R_j$ 与这个[期望值](@entry_id:150961)之间总平方距离的度量。其标准公式如下[@problem_id:4945342]：

$$ Q = \frac{12}{b k(k+1)} \sum_{j=1}^{k} \left(R_j - b\frac{k+1}{2}\right)^2 $$

这可能看起来令人生畏，但[求和符号](@entry_id:264401)内的部分正是我们讨论过的：`(观察到的秩和 - 期望的秩和)²`。我们对每种处理都这样做，然后将它们相加。前面的项 $\frac{12}{b k(k+1)}$ 是一个缩放因子。选择它的原因非常巧妙，我们稍后会看到，它确保我们最终得到的数字 $Q$ 可以用一个标准参考来解释。一个更简单的计算版本也经常被使用[@problem_id:4945342]：

$$ Q = \frac{12}{b k(k+1)} \sum_{j=1}^{k} R_j^2 - 3b(k+1) $$

让我们将此付诸实践。在一个有 $b=8$ 名受试者和 $k=4$ 种处理的交叉试验中，在对每个受试者内的数据进行排序（并通过平均秩处理结值）后，我们可能会发现处理 A、B、C 和 D 的总秩和分别为 $R_A=24$、$R_B=18$、$R_C=23$ 和 $R_D=15$ [@problem_id:4920241]。如果所有处理都相同，我们期望每个和都接近 $8 \times \frac{4+1}{2} = 20$。这些偏差是否大到有意义？将这些数字代入公式（并对数据中的结值进行小幅校正）得到一个约 5.311 的 $Q$ 值。现在，我们用这个数字做什么呢？

### 从计数到曲线：[卡方分布](@entry_id:165213)的启示

一个 5.311 的统计量在真空中是毫无意义的。它算大还是小？为了回答这个问题，我们需要知道在我们的“纯粹随机的世界”中，我们期望看到什么样的 $Q$ 值。

对于一个非常小的实验，我们实际上可以用手算出来！想象一个只有 $b=2$ 个患者和 $k=3$ 种处理的初步研究[@problem_id:4836012]。在每个患者内部，有 $3! = 6$ 种可能的方式来分配秩 $\{1, 2, 3\}$。由于患者是独立的，整个实验的秩表有 $6 \times 6 = 36$ 种同样可能的可能结果。我们可以列出这 36 种可能性中的每一种，计算每种的 $Q$ 统计量，并构建一个**精确概率分布**。我们可能会发现，例如，一个 $Q$ 值为 4 的情况在 36 种情况中出现 6 次（概率为 $1/6$），一个 $Q$ 值为 3 的情况出现 12 次（$1/3$），依此类推。这个过程揭示了随机的全部景观，表明统计学没有魔法——它只是仔细的计数。

但是对于任何实际规模的实验，这种枚举都是不可能的。可能性的数量会爆炸式增长。这时，统计学中最神奇的思想之一向我们伸出了援手。随着区组数 $b$ 的增长，我们的弗里德曼统计量 $Q$ 的概率分布会变形为一个非常具体、著名的形状：**卡方（$\chi^2$）分布**。$Q$ 的公式中的缩放因子就是为了实现这一点而巧妙选择的。

这个 $\chi^2$ 分布就是我们的启示。它告诉我们，在一个只有随机性在起作用的世界里，什么样的 $Q$ 值是常见的，什么样的值是罕见的。我们使用的 $\chi^2$ 分布的具体“风格”取决于其**自由度**，对于弗里德曼检验，自由度就是 $k-1$，比处理数少一。对于我们有 4 种处理的例子，我们会参考一个具有 $3$ 个自由度的 $\chi^2$ 分布。我们在这个分布的图上查找我们计算出的 $Q$ 值（比如 5.311）。如果它落在一个“常见”值的区域，我们得出结论，我们的结果很可能归因于随机。如果它远远地落在尾部，在“罕见”事件的区域（通常是最罕见的 5%），我们就拒绝零假设，并宣布处理之间存在[统计显著性](@entry_id:147554)差异。

这就是为什么弗里德曼检验是像**重复测量[方差分析](@entry_id:275547)**这样的参数检验的完美、稳健的替代品。[方差分析](@entry_id:275547)功能强大，但有点“挑剔”；它要求数据满足严格的假设，如正态性和一个称为**球形性**的复杂条件。当诊断显示这些假设被严重违反时——这在现实世界的医学数据中很常见——方差分析可能会给出误导性的结果。而弗里德曼检验，凭借其简单、优雅的排序过程，巧妙地回避了这些要求，并提供了一个值得信赖的答案[@problem_id:4546895]。

### 当设计被打破：处理[缺失数据](@entry_id:271026)

经典的弗里德曼检验很优美，但它依赖于一个整洁、完整的设计：每个受试者必须为每一种处理提供一个测量值。在现实世界中，当一个病人在研究中途错过一次访视或退出时会发生什么？我们平衡的区组变得凌乱和不完整[@problem_id:4834095]。

在这种情况下，标准的弗里德曼检验就不再有效。它的数学机制是建立在完整区组的基础上的。但是，其核心思想——在区组内使用秩来进行公平比较——太好了，不能扔掉。这就是统计科学进步的地方。研究人员开发了一种称为**Skillings–Mack 检验**的泛化方法。它是同样思想的一个更复杂但更强大的版本，旨在处理不平衡、不完整的区组设计。它巧妙地利用所有可用的数据，适当地加权信息，并提供一个有效的处理全局比较。它证明了一个检验的基本原则如何能够被扩展以解决更混乱、更现实的问题。

