## 应用与跨学科联系

在我们的穿越人工智能偏见原理与机制的旅程之后，您可能会留下这样的印象：这是一个相当抽象，甚至纯粹是技术性的事务。没有什么比这更偏离事实了。我们讨论过的思想并不仅限于计算机实验室的无菌环境；它们涌入人类活动的几乎每一个领域，从我们管理经济的方式到我们探索自然世界的方式，甚至到我们如何寻找爱情。理解[人工智能中的偏见](@article_id:638672)不仅仅是理解[算法](@article_id:331821)；它是关于理解我们为自己建造的一面新的、强大的镜子，并学会看清它——以及我们自己——的扭曲。

让我们从一个与偏见斗争了数百年的领域——分析化学——的类比开始。当一位化学家设计一种生物传感器来测量血液中一种关键蛋白质，比如心脏病发作的标志物时，他们最大的恐惧是缺乏特异性。如果传感器在检测目标蛋白质的同时，也与另一种恰好结构相似的良性蛋白质发生部分反应，那该怎么办？仪器将系统性地报告比实际浓度更高的值。这种[系统误差](@article_id:302833)被称为*偏见*[@problem_id:1423516]。它不是恶意的；它是测量设备的物理局限性。类似地，一种用于量化治疗性肽的仪器可能会根据其操作模式产生持续不同的结果，揭示了其中一种测量技术固有的偏见[@problem_id:1423562]。从深刻的意义上说，人工智能模型也是一种测量设备。它测量贷款违约的可能性、一张图片包含猫的概率，或者一个肿瘤是恶性的机会。那么，这些计算仪器也可能存在偏见，又有什么好奇怪的呢？

然而，这个类比只[能带](@article_id:306995)我们走这么远。化学家的传感器受到物理定律和[分子相互作用](@article_id:327474)的偏见影响。而一个根据我们世界的数据训练出来的人工智能，其偏见往往源于社会结构本身。考虑一下批准贷款的高风险决策。几十年来，这一直是人类信贷员的工作。我们知道，人类尽管怀有最好的意图，也可[能带](@article_id:306995)有有意识和无意识的偏见。现在，假设我们建立一个人工智能来接管这项任务，用几十年的历史贷款申请数据来训练它。人工智能将学习数据中的模式。如果在过去，某些人口群体被不公平地拒绝了贷款，数据将反映这段历史。人工智能在寻求模式识别的过程中，将会学习并延续这种历史偏见。它成为我们自身社会失败的一面镜子。

但有趣之处就在这里。与人类头脑中微妙且常常未被察觉的偏见不同，[算法](@article_id:331821)的偏见可以被严格地审计和量化。我们可以选取两组人，比较人工智能的表现。它对每个群体的*[假阳性率](@article_id:640443)*是多少——也就是说，它多大频率地错误地将一个有信誉的人标记为未来的违约者？它的*假阴性率*是多少——它多大频率地未能发现一个实际会违约的人？通过跨群体比较这些比率，我们可以构建一个[算法偏见](@article_id:642288)的数值指数。然后，我们可以对人类信贷员做同样的事情，看看谁更公平[@problem_id:2438791]。其目标不一定是证明人工智能比人类“更好”或“更差”，而是将对话从模糊的怀疑提升到定量科学的层面。人工智能不仅仅是一面镜子；它是一面*校准过的*镜子，迫使我们直面它所反映的不平等的精确程度。

故事并不仅仅以人工智能反映我们现有的偏见而告终。它还可能成为创造全[新形式](@article_id:378361)的歧视和社会分层的力量。想象一个未来的约会应用程序，它通过将用户与具有不同免疫系统基因（即主要组织相容性复合体，MHC）的人进行匹配，来承诺“生物学优化的关系”。该[算法](@article_id:331821)遵循一个简单的、“科学中立”的规则：最大化MHC的相异性。现在，一个其MHC图谱在人群中非常普遍的人会怎么样？根据定义，对他们来说，具有不同基因的“最佳”伴侣池很小。他们发现自己的匹配对象非常少，在这个新的社交市场中被系统性地置于不利地位，不是因为他们的种族、性别或收入，而是因为他们不可改变的基因构成[@problem_id:1486454]。[算法](@article_id:331821)在其单一目标的优化过程中，无意中助长了一种[遗传决定论](@article_id:336525)，并创造了一个新的[社会等级](@article_id:311012)。这是一个深刻的教训：我们的工具不仅仅存在于我们的社会世界中；它们还主动地重塑它。

人类与人工智能之间的关系是一支复杂的舞蹈，偏见可以在两个方向上流动。考虑一下[公民科学](@article_id:362650)的奇妙世界，成千上万的志愿者帮助生态学家从数百万张相机陷阱照片中分类物种。为了辅助这一过程，部署了一个人工智能来为每张图片建议一个物种。但这个有用的建议带有一个隐藏的代价：人类的*锚定偏见*心理现象。如果人工智能建议“这看起来像一只狐狸”，人类志愿者的判断会不自觉地被拉向那个建议，即使他们本来可能将其识别为一只郊狼。人工智能的意见作为一个认知锚点，很难被克服。科学家如何衡量这种效应的程度？答案在于科学方法的一个漂亮应用：[随机对照试验](@article_id:346404)（RCT）。对于任何一个正在看图片的志愿者，都会抛掷一枚虚拟硬币。正面，他们看到人工智能的建议；反面，他们看不到。通过比较这两种情况下志愿者的最终分类，生态学家可以精确地测量人工智能建议对人类准确性和决策的因果效应[@problem_id:2476147]。这揭示了一个新的前沿领域：将耦合的人类-人工智能系统作为一个单一实体来研究，它有其自己独特且涌现的偏见。

到目前为止，我们主要谈论的是源于输入给人工智能的数据或对其人类用户的心理影响的偏见。但一个[算法](@article_id:331821)是否可能因其自身的内部结构而“从内部”产生偏见？答案是响亮的“是”。这通常被称为*建模偏见*或*[模型设定错误](@article_id:349522)偏见*。想象一个被设计用来玩复杂策略游戏的人工智能。它的创造者在过度简化的情况下，将所有对手都建模为纯粹的攻击性。人工智能学会了成为对抗攻击的大师。一个聪明的人类玩家可以利用这一点。他们可以伪装一个攻击性的开局，导致人工智能采取防御姿态，然后转向一个人工智能完全没有准备的、出乎意料的不同策略[@problem_id:3252659]。人工智能在这里的偏见不是社会性的；它是一个有缺陷的世界观，一个对其环境过于简单的模型，这使得它变得可预测并最终脆弱。这种类型的偏见可能更加微妙。如果学习[算法](@article_id:331821)没有经过理论上的保障设计，它所训练的数据的结构本身就可能将其推入特定的失败模式，例如在解决优化问题时陷入无限循环[@problem_id:3117208]。

也许最深刻的内部偏见形式是所谓的*隐式[算法偏见](@article_id:642288)*。想象一下两种不同的[优化算法](@article_id:308254)——我们称之为Adam和SGD——用来训练一个[神经网络](@article_id:305336)。两者都可能能够将网络训练到在训练数据上达到近乎完美的准确率。然而，它们最终产生的模型可能具有非常不同的属性，并且以不同的方式泛化到新的、未见过的数据。为什么？因为[算法](@article_id:331821)本身有一种“风格”或“偏好”。即使存在许多解决方案，[算法](@article_id:331821)在可能模型的高维景观中穿行的路径本身，也会使其偏向于找到一种解决方案而不是另一种[@problem_id:3187346]。这就像两个登山者攀登同一座山；即使他们到达了同一个山顶，他们选择的路径——一个偏爱陡峭的攀登，另一个偏爱平缓的斜坡——决定了他们沿途的风景和他们在山顶上最终停留的确切位置。这种[隐式偏见](@article_id:642291)是机器中的幽灵，是一种[嵌入](@article_id:311541)在学习逻辑本身中的偏好。

这次对偏见多面性的巡礼可能看起来令人沮丧，像是一长串不可避免的缺陷清单。但这里恰恰是这个领域真正的美妙和力量所在。因为我们可以定义和测量偏见，我们也可以开始设计解决方案。我们不是有偏见[算法](@article_id:331821)的被动受害者；我们是它们的创造者，也可以是它们的监管者。

让我们回到我们的贷款例子。我们可以构建一个合成世界，在这个世界里，我们确切地知道申请人的邻里与他们的贷款结果存在虚假关联，但并非真正的原因。一个标准的[逻辑回归模型](@article_id:641340)在这些数据上训练后，会愚蠢地学会使用邻里作为一个强有力的预测因子，从而创造一个不公平的系统。但如果我们改变人工智能的游戏规则呢？我们可以修改它的学习目标，增加一个惩罚项，即：“你的目标是尽可能准确，*但是*你每依赖一点这个敏感的‘邻里’特征，我就会惩罚你。”这被称为*公平性正则化*。我们明确地告诉模型要找到一个既准确又公平的解决方案。而且它确实有效。通过应用这个惩罚，我们可以训练出一个学会忽略虚假关联并专注于真实因果特征的模型。然后，我们可以使用可解释性工具来验证我们的成功，看到模型现在对敏感特征的归因重要性大大降低，并通过测试反事实——如果同一个人住在不同的邻里，模型会做出什么预测？我们可以测量到预测变化的急剧减少，证实我们的模型确实更公平了[@problem_id:3153155]。

这是一个革命性的想法。公平性不必仅仅是一个伦理准则或一个后处理补丁。它可以被编织到学习过程的数学结构中。通过理解偏见的起源和机制——无论是来自社会的数据、人类心理学，还是[算法](@article_id:331821)自身的内部逻辑——我们获得了抵消它的力量。我们可以从诊断走向治愈。因此，对人工智能偏见的研究不仅仅是计算机科学的一个子领域。它是一个跨学科的交汇点，统计学、社会学、法学、哲学和工程学在此汇合，为我们提供了一套新的、强大的工具，不仅用以构建更好的机器，也用以更好地理解，甚至可能改善我们自己。