## 引言
从医学到工程学，在众多领域中，我们常常关注特定事件发生的时间：病人康复、产品失效或顾客做出决定。这属于[事件时间分析](@entry_id:268670)的范畴。然而，现实世界的研究受到时间和资源的限制，这意味着我们很少能观察到每一个事件。我们经常面对不完整的观测数据，其中我们只知道在我们的观察期结束时，某个事件*尚未*发生。这种常见而富有挑战性的情况产生了右删失数据，而理解如何正确处理它对于得出准确的结论至关重要。

本文为分析右[删失数据](@entry_id:173222)的原则和应用提供了全面的指南。在第一部分“原理与机制”中，我们将定义什么是[右删失](@entry_id:164686)，展示为何简单化的方法会失败，并介绍使我们能够从事件和非事件中学习的优雅统计框架——基于似然的方法和著名的 Kaplan-Meier 估计量。随后，在“应用与跨学科联系”中，我们将探讨这些方法卓越的通用性，展示同样的核心思想如何为解决临床试验、材料科学、生物学和前沿机器学习中的问题提供一种共通的语言。

## 原理与机制

想象我们正在观察一个宏大故事的展开——一个关于新软件功能及其用户、一种新药及其患者，或一个新引擎部件及其使用寿命的故事。我们的目标是理解一个关键事件的发生时间：用户首次点击该功能的时刻、患者疾病进展的时间，或部件发生故障的瞬间。在理想世界中，我们会跟踪我们故事中的每一个角色，直到他们的个人故事达到高潮。但现实世界并非如此井然有序。研究有预算和截止日期；人们会搬家、改变主意或干脆从视野中消失。我们常常只得到不完整的故事。这就是**右删失数据**的世界。

### 我们数据中的阴影：什么是[右删失](@entry_id:164686)？

让我们用一个简单而具体的例子来说明。一家科技公司推出了一项新功能，并决定跟踪 100 名新用户 90 天，以观察他们需要多长时间才会试用该功能 [@problem_id:1911727]。这里的“事件”是首次使用该功能。

- 用户 1 在第 30 天使用了该功能。我们有了一个完整的故事。事件时间是 30 天。

- 用户 2 在第 90 天时仍在使用该软件，但没有接触过新功能。研究结束了。我们不知道他们何时会使用，甚至不知道他们是否会使用。我们只知道他们的事件时间，无论是什么，都*大于 90 天*。他们的数据点是**[右删失](@entry_id:164686)**的。这种由于研究设计而结束的特定类型，被称为**行政删失**。

- 用户 3 在第 60 天取消了订阅，从未用过该功能。我们又得到了一个不完整的故事。他们可能在第 61 天使用，也可能永远不会。我们只能说他们的事件时间*大于 60 天*。这也是右删失，但属于另一种类型，通常称为**失访**。

这些删失观测值就像我们数据中的阴影。它们不揭示确切的事件时间，但它们告诉了我们一些极其重要的事情：在一定时期内的生存，或事件未发生。

为了更精确地思考这个问题，像数学家一样，我们可以将真实、潜在的事件时间定义为 $T$。这是我们希望总能看到的变量。我们还有一个删失时间 $C$，它可能是研究的固定结束时间，也可能是某人随机退出的时间。实际上，我们只能观察到两件事之一：要么事件在我们在我们失去对该人的追踪之前发生，要么我们先失去对他们的追踪。我们实际记录的是观测时间 $Y = \min(T, C)$ 和一个简单的标志 $\delta$，它告诉我们观测到的是真实事件（$\delta=1$）还是删失（$\delta=0$）[@problem_id:4806041]。生存分析的全部艺术就在于学习如何正确解读这些 $(Y, \delta)$ 对所构成的交响乐。

虽然我们的重点是[右删失](@entry_id:164686)（知道 $T > Y$），但值得注意的是，信息的不完整性还有其他形式。有时我们有**[左删失](@entry_id:169731)**（我们只知道事件在某个时间*之前*发生，$T \le Y$）或**[区间删失](@entry_id:636589)**（我们知道事件在两个时间点之间发生，$L  T \le R$）。每一种阴影都需要其独特的工具来使潜在的图像变得清晰 [@problem_id:4806041]。

### 视而不见的危险：为何朴素方法会失败

面对这些不完整的数据点，一种朴素的冲动可能是“清理”数据集。如果我们把所有删失的观测值都扔掉会怎么样？或者，也许我们可以假设事件在删失时发生？这两条路都会导致灾难。

让我们想一想。如果我们从软件研究中丢弃被删失的用户，我们实际上是在选择性地移除那些最晚采用该功能的用户。我们剩下的将只有那些快速采纳者，这将导致我们得出一个愚蠢乐观的结论，即每个人都立即喜欢上了这个新功能。相反，如果我们将删失时间视为事件时间（例如，假设用户 2 在第 90 天使用了该功能），我们就在系统性地缩短真实但未被观察到的事件时间。这将导致悲观的结论，即采纳速度比实际要慢。

这不仅仅是有点偏差的问题。这种偏差可能非常严重，并完全改变我们的结论。想象一下，你试图估计一种新型机械部件的[平均寿命](@entry_id:195236)，但你的实验只运行固定的时间 $T$。任何寿命超过 $T$ 的部件都被记录为寿命为 $T$。当你根据这些数据计算平均值和方差时，你人为地砍掉了分布的整个上尾。你对平均寿命的估计会过低，对寿命变异性的估计也会被严重低估 [@problem_id:1953212]。你可能会基于关于材料的错误信息去建造一座桥或一个心脏起搏器。

所以，我们处在一个有趣的困境中。我们不能忽视[删失数据](@entry_id:173222)，也不能将其视为完整数据。删失观测值不是噪音；它们是信号。它们携带了*生存*的关键信息。挑战——也是其美妙之处——在于开发出既能倾听事件的声音，也能倾听删失的沉默的方法。

### 倾听沉默：如何从不完整数据中学习

面对这一挑战，统计学家们发展出了两种非常优雅的方法。一种是基于假设生存故事的整体形态，并利用概率论来填充细节。另一种则不做此类假设，而是让数据一步一步地构建故事。

#### 似然法：概率的交响曲

第一种方法植根于**似然**原理。其思想是，对于我们收集到的确切数据，给定关于潜在过程的某个假设，写下一个数学表达式来表示观测到这些数据的概率。然后，我们调整假设的参数，直到这个概率达到最大。

让我们看看这在混合了完整数据和[删失数据](@entry_id:173222)的情况下是如何运作的 [@problem_id:4920644]。假设我们的假设由一组参数 $\theta$ 描述。
- 对于在时间 $t_i$ 发生事件的用户（因此 $\delta_i=1$），其对总概率的贡献是事件恰好在该时刻发生的概率*密度*。我们称之为 $f(t_i; \theta)$。
- 对于在时间 $t_i$ 被删失的用户（因此 $\delta_i=0$），我们知道他们真实的事件时间大于 $t_i$。其对总概率的贡献是生存*超过*时间 $t_i$ 的概率。这正是生存函数 $S(t_i; \theta)$ 的定义。

我们整个数据集的总似然是这些单个贡献的乘积，因为我们假设每个人的故事是独立的：

$$ L(\theta) = \prod_{i=1}^{n} [f(t_i; \theta)]^{\delta_i} [S(t_i; \theta)]^{1-\delta_i} $$

看这个方程！它美得不可方物。小小的 $\delta_i$ 标志就像一个完美的开关。如果事件发生（$\delta_i = 1$），$S(t_i)$ 项消失，$f(t_i)$ 项被包含进来。如果发生删失（$\delta_i = 0$），$f(t_i)$ 项消失，$S(t_i)$ 项被包含进来。这个公式毫不费力且优雅地将来自事件和非事件的信息编织在一起。

这个框架非常强大。例如，如果我们将事件时间建模为服从简单的[指数分布](@entry_id:273894)（意味着恒定的事件率 $\lambda$），该率的最大似然估计结果非常直观：

$$ \hat{\lambda} = \frac{\text{Total number of events}}{\text{Total time at risk}} = \frac{\sum \delta_i}{\sum t_i} $$

总风险时间是所有观测时间的总和，无论它们是因事件结束还是因删失结束 [@problem_id:4577984]。这正是你在医学研究中听到的“每人年事件数”的概念，它直接源于这个美妙的原理。

包含[删失数据](@entry_id:173222)不仅仅是为了避免偏差；它还能主动改善我们的估计。通过包含来自删失患者的“生存”信息，我们增加了证据，表明事件率可能更低，这减少了我们对真实值的不确定性。一个包含删失数据的仔细分析将产生比一个丢弃这些数据的朴素分析更精确的估计（在贝叶斯术语中，是一个更窄的[可信区间](@entry_id:176433)）[@problem_id:4953846]。沉默并非空无一物；它饱含信息。

#### Kaplan-Meier 方法：通往生存的阶梯

但是，如果我们不想为我们的生存曲线假设一个特定的形状呢？如果我们想让数据自己来描绘这幅图景呢？这就是非参数 **[Kaplan-Meier](@entry_id:169317) 估计量**背后的哲学，它是整个统计学中最著名的工具之一。

其逻辑非常简单 [@problem_id:4545940]。我们从研究中的所有人开始，此时生存概率是 100%。然后，我们沿着时间线从一个事件移动到下一个事件。在每个事件时间点，我们问一个简单的问题：“在这一刻之前仍在研究中的人（即‘风险集’），有多少比例的人幸存过了这次事件？”

估计的生存曲线 $\hat{S}(t)$ 是直到时间 $t$ 为止的这些条件生存概率的乘积：

$$ \hat{S}(t) = \prod_{j | t_j \le t} \left(1 - \frac{d_j}{n_j}\right) $$

这里，$t_j$ 是唯一的事件时间，$d_j$ 是在时间 $t_j$ 发生的事件数，而 $n_j$ 是在时间 $t_j$ 之前风险集中的人数。

最终的图形是一条“通往生存的阶梯”[@problem_id:4805965]。曲线保持平坦，然后*仅*在事件发生时垂直下降。那么删失观测值呢？它们不引起下降。相反，当一个人被删失时，他们只是被安静地从下一次计算的风险集（$n_j$）中移除。在图上，我们通常用曲线上的一个小刻度标记这些删失时间。这种视觉语言非常巧妙：下降告诉你风险，而刻度告诉你信息的丢失。

从这条曲线中，我们可以估计出关键的量，如**[中位生存时间](@entry_id:634182)**：即一半人群已经经历事件的时间点。我们通过寻找 Kaplan-Meier 曲线首次下降到 0.5 或以下的时间点来找到它 [@problem_id:4545940]。如果因为研究结束得太早，曲线从未达到 0.5 怎么办？那么我们必须诚实。我们无法报告一个[中位数](@entry_id:264877)。我们只能说它大于我们研究中最长的随访时间。这种学术上的诚实是该方法的一个核心特征 [@problem_id:4805965]。

### 附加条款：一个关键假设

这些强大的方法看似神奇，但它们依赖于一个巨大而关键的假设：删失是**非信息性**的。简单来说，这意味着一个观测值被删失的原因与该个体发生事件的潜在风险无关 [@problem_id:4920644]。

- **行政删失**是非信息性删失的典型例子。一项临床试验在 12 月 31 日对所有人结束。日历对任何单个患者的健康状况一无所知，因此删失与他们的预后无关 [@problem_id:4962152]。

- 然而，**失访**总是可疑的。如果感觉病情更重的患者更有可能退出研究，那么他们的删失就与他们的预后直接相关。这是**信息性删失**，它破坏了我们的标准方法。剩余的样本会变得人为地健康，使我们的结果偏向于看起来比实际更好。

当然，世界是复杂的。有时删失并非严格独立，但可以通过考虑另一个变量使其独立。想象一个生物标志物 $M$，它既能预测事件，也能预测退出的可能性。删失和事件时间是相关的。但是，如果我们对 $M$ 进行调整——例如，通过对 $M$ 值高和低的患者分别进行分析——删失可能在*每个组内*变得非信息性。这个假设，即删失在给定一些观测到的协变量的条件下是独立的，是现代生存分析的基石，它使我们能够处理许多复杂的情景 [@problem_id:3107061]。

最终，信息性删失的可能性提醒我们要保持谦逊。当我们怀疑我们的假设可能被违反时，我们可以进行[敏感性分析](@entry_id:147555)，问自己“如果删失在某种程度上是信息性的，我的结论会有多大不同？”这个质疑我们的假设并测试我们发现的稳健性的过程，正是优秀科学的精髓。它确保了当我们倾听数据中的沉默时，我们听到的是真实的信号，而不仅仅是我们自身偏见的的回声。

