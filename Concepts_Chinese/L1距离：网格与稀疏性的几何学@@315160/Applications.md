## 应用与跨学科联系

我们花了一些时间来了解$L_1$距离，这种奇特的测量分离的方式，起初感觉不如我们在学校学到的直线欧几里得距离那么“自然”。你可能会想把它当作一个纯粹的数学奇观，是“真实”世界几何学的一个奇怪表亲而置之不理。但这样做将是一个巨大的错误。因为正是在这种“非自然性”中蕴含着它的力量。$L_1$距离不仅仅是一种替代方案；它是一面透镜，揭示了隐藏的结构，并为那些表面上看起来毫无关联的领域中的问题提供了优雅的解决方案。它是一条统一的线索，通过追溯它，我们可以在科学和技术领域进行一次迷人的旅行。

### 网格上的世界：从城市街区到[随机游走](@article_id:303058)

理解$L_1$距离最直观的方式是想象一个像曼哈顿那样布局在完美网格上的城市。如果你想从一个点到另一个点，你不能像鸟一样飞行（欧几里得或$L_2$路径）。你必须沿着街道，东西向和南北向行进。你能走的最短距离是你必须穿过的水平和垂直街区的总和——这正是[曼哈顿距离](@article_id:340687)，或$L_1$距离。

这不仅仅是一个可爱的类比；它对我们如何设计和理解网络有着深远的影响。想象在一个简化的城市模型中放置三个基础设施节点。如果我们说两个节点在它们之间的距离小于某个阈值时是“连接”的，那么距离度量的选择——鸟飞式（$L_2$）与城市街区式（$L_1$）——可能会导致完全不同的连接网络。两个节点之间的距离可能足够近，可以建立直接的无线电链接，但对于必须沿街行驶的送货机器人来说可能太远了[@problem_id:1552588]。这种几何视角的简单转变改变了我们对物流、电信和城市规划的思考方式。

我们甚至可以将这个网格世界带入经典力学的领域。想象一个粒子在二维平面上移动。我们知道它的速度$v$和它的行进方向$\theta$。它与原点的直线距离的变化率很容易计算。但是它与原点的*出租车距离*$d_1 = |x| + |y|$的变化率呢？一点微积分揭示了一个令人愉快的结果：该变化率为$v(\cos\theta + \sin\theta)$（假设它在第一[象限](@article_id:352519)）[@problem_id:2196482]。这个值不是恒定的！它取决于运动方向。如果粒子平行于坐标轴移动（$\theta=0$或$\theta=\pi/2$），变化率就是$v$。但如果它沿对角线移动（$\theta=\pi/4$），变化率是$v\sqrt{2}$。就好像在出租车世界中沿对角线移动能更“高效”地增加你与起点的距离。

这种基于网格的观点可以优美地延伸到概率和随机性的世界。考虑两个被随机投放到一个正方形城市核心区的自主送货机器人。它们之间的[期望](@article_id:311378)距离是多少？如果它们能飞，我们会计算[期望](@article_id:311378)的[欧几里得距离](@article_id:304420)。但由于它们受限于街道，我们必须使用[曼哈顿距离](@article_id:340687)。数学向我们展示了如何在这个世界中计算[统计平均值](@article_id:314269)，为管理者提供了关键信息，用于管理电池寿命或预测送货时间等任务[@problem_id:1347786]。我们可以更进一步，模拟一个粒子在网格上随机行走的路径。平均来说，粒子需要走多少步才能距离起点，比如说，10个街区？这是一个经典的“[随机游走](@article_id:303058)”问题，用[曼哈顿距离](@article_id:340687)来构建这个问题是提出问题和找到答案最自然的方式[@problem_id:849768]。

### 一种新的数据语言：量化生物和材料差异

当我们从物理空间转向现代数据的抽象高维空间时，$L_1$度量的威力才真正显现出来。在这里，我们的“点”不再是城市中的位置，而是由一长串数字——向量——描述的复杂状态。

想想系统生物学。一个细胞的状态可以通过数千个基因的表达水平来描述。当我们敲除一个基因时，细胞的状态会改变；许多其他基因的表达水平会发生变化。我们如何捕捉这种变化的总*量级*？我们可以将“之前”和“之后”的[状态表示](@article_id:301643)为高维“基因表达空间”中的两个向量。这两个向量之间的[曼哈顿距离](@article_id:340687)给我们一个单一的数字，量化了基因敲除的总[体效应](@article_id:325186)[@problem_id:1423399]。它的计算方法很简单，就是将每个基因表达的绝对变化量相加。

在这里，$L_1$和$L_2$距离之间的比较变成了一个具有深刻解释差异的故事。假设我们测量了给药后细胞中几种代谢物浓度的变化。我们有一个这些变化的向量。这个向量的$L_1$范数（变化的[绝对值](@article_id:308102)之和）代表了*总代谢周转率*——所有浓度上升和下降的总和。它将十个代谢物的微小变化视为等同于一个代谢物的巨大变化。而$L_2$范数则在求和前对变化进行平方。这意味着它对最大的变化更为敏感。一个代谢物的单一、剧烈的峰值将主导$L_2$范数。那么，哪个更好呢？都不是！它们在讲述同一事件的不同故事。$L_1$范数告诉我们反应的总体规模，而$L_2$范数则突出了最剧烈的影响[@problem_id:1477170]。

同样的逻辑也完美地适用于[材料科学](@article_id:312640)。我们如何教计算机理解两种原子[排列](@article_id:296886)之间的差异，比如说，一个由三个原子组成的线性链与一个等边三角形？在机器学习中，我们首先为每个原子计算一个“指纹”——一个用数值描述其局部环境的向量。然后，为了比较两个不同的环境，我们只需计算它们指纹向量之间的距离。$L_1$距离提供了一种简单而稳健的方法来衡量两种原子结构的“不同”程度，构成了现代[材料信息学](@article_id:376250)的一块基石，使我们能够搜索庞大的化合物数据库以寻找具有所需性质的材料[@problem_id:90972] [@problem_id:98325]。

### [稀疏性](@article_id:297245)的力量：L1如何构建更简单、更好的模型

或许，$L_1$距离最著名和最具变革性的应用是在优化和机器学习领域。在这里，它是解开现代[数据科学](@article_id:300658)中最令人向往的属性之一——**[稀疏性](@article_id:297245)**的关键。

想象一下，你正在尝试预测房价。你有一个庞大的数据集，其中包含每栋房子的数百个特征：平方英尺、卧室数量、房龄、前门的颜色、到最近咖啡店的距离、七月份的平均降雨量等等。这些特征中很多可能都是无用的。一个好的模型不仅应该准确，还应该*简单*。它应该识别出真正重要的少数几个特征，并丢弃其余的。换句话说，我们想要一个大多数特征系数都恰好为零的模型。这就是所谓的[稀疏模型](@article_id:353316)。

这正是$L_1$的魔力所在。一种名为LASSO（最小绝对收缩和选择算子）的著名技术通过同时做两件事来构建模型：很好地拟合数据（通常的目标）并保持模型系数向量的$L_1$范数较小。这第二部分，即$L_1$[正则化](@article_id:300216)，具有惊人的效果。虽然它的近亲$L_2$正则化倾向于将所有系数都向零收缩，但它很少能将它们*恰好*推到零。一个$L_2$正则化的模型通常是稠密的。与此形成鲜明对比的是，$L_1$正则化会主动迫使许多不太重要的系数变得精确为零[@problem_id:2197169]。它自动为我们执行了[特征选择](@article_id:302140)！

为什么会发生这种情况？原因纯粹是几何上的，而且非常优美。想想每种度量的“单位球”——距离原点为1的所有点的集合。对于二维空间中的$L_2$范数，这是一个圆。它处处光滑。对于$L_1$范数，它是一个旋转了45度的正方形。它有尖锐的角，或顶点，位于坐标轴上。当我们使用优化算法来寻找最佳模型系数时，这些“角”就像引力井。优化过程自然地被吸引到这些角上，在那里其中一个系数为零。

我们甚至可以看到这个机制的运作过程。最小化像$L_1$范数这样的函数的过程使用了一个叫做次梯度的概念。在任何光滑点，只有一个最陡下降方向。但在不可微的“[拐点](@article_id:305354)”处——比如在$L_1$范数中坐标$x_i$为零的地方——存在一整套可能的“下坡”方向。[算法](@article_id:331821)有一个选择。至关重要的是，其中一个选择允许[算法](@article_id:331821)沿着其他轴移动，同时将$x_i$坐标牢牢地锁定在零[@problem_id:2207137]。$L_2$范数的光滑表面没有提供这样的锚点。正是$L_1$范数的尖锐、多角的特性赋予了它这种强大的“选择和丢弃”能力，这一特性已经彻底改变了从[统计遗传学](@article_id:324392)到[图像处理](@article_id:340665)等多个领域。

从我们城市的网格状街道到我们数据的抽象高维景观，$L_1$距离提供了一种强大而统一的视角。它证明了一个事实，即在数学中，就像在所有科学中一样，选择正确的工具——看待世界的正确方式——可以带来天壤之别，将复杂的混乱转变为优雅简洁的结构。