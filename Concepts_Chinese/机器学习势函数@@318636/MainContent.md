## 引言
理解原子和分子如何相互作用是化学、物理学和[材料科学](@article_id:312640)的基础。控制这些相互作用的规则由[势能面 (PES)](@article_id:323827) 定义，这是一个错综复杂的高维景观。几十年来，科学家们面临一个艰难的选择：要么使用快速但通常不准确的[经典力场](@article_id:369501)，要么使用高度准确但[计算成本](@article_id:308397)高昂的量子力学方法。这一差距限制了我们在有意义的时间尺度上模拟复杂系统的能力，阻碍了新材料的发现和对化学过程的理解。

[机器学习势](@article_id:362354)函数 (MLP) 已成为解决这一长期问题的革命性方案。通过将机器学习的预测能力与量子物理的严谨性相结合，MLP 学会以量子的精度重现 PES，而计算成本仅为其一小部分。它们如同原子世界的“快进”按钮，为科学探索开辟了新的前沿。

本文将深入探讨这些强大工具背后的核心概念。在“原理与机制”一节中，我们将揭示 MLP 如何构建以遵循基本物理定律，以及它们如何利用量子力学数据进行训练。随后，“应用与跨学科联系”一章将探讨 MLP 的变革性影响，展示它们如何加速模拟并在广泛的科学学科中催生新发现。

## 原理与机制

想象一下，你是一位探险家，任务是为一片广阔、未知的陆地绘制终极地图集。这片陆地不是由岩石和土壤构成，而是由物质中原子所有可能的[排列](@article_id:296886)方式组成。这片景观中任何一点的“海拔高度”就是它的势能。这片景观的形态——即[势能面 (PES)](@article_id:323827)——支配着一切：一种材料是固态还是液态，一个[化学反应](@article_id:307389)如何进行，一个蛋白质如何折叠。几个世纪以来，我们对这片景观的地图，即所谓的[经典力场](@article_id:369501)，就像是路线图：对于在稳定的山谷（处于[平衡态](@article_id:347397)的分子）周围的常规路径导航非常有用，但在其他地方则大片空白。[机器学习势](@article_id:362354)函数 (MLP) 代表了一种革命性的新制图学，其目标是绘制整个崎岖、高维的荒野。

### 一种描绘原子世界的新型地图集

那么，MLP 究竟是什么？如果说[经典力场](@article_id:369501)像一个简单的泰勒级数——一个围绕单点的局域近似——那么它的机器学习对应物是什么？人们很自然地会想到熟悉的数学工具。它是像傅里叶级数那样，由正弦和余弦函数构成的宏大组合吗？或许是一系列局域化的小波？答案更为深刻。一个[高维神经网络势](@article_id:347586)函数最好被理解为**一种学习得到的、非线性的、高维的[基函数](@article_id:307485)展开** [@problem_id:2456343]。

让我们来剖析一下这个概念。想象一下建造一个复杂的雕塑。[傅里叶级数](@article_id:299903)就像只拥有标准的、预制的[正弦曲线](@article_id:338691)形状的积木。[小波变换](@article_id:356146)为你提供了不同尺寸的预制积木。而 MLP 则像一台神奇的机器，它能学会为你想要建造的任何雕塑制造出形状完美的定制砖块。这个网络不依赖于一组固定的数学函数（一个“基”）。相反，通过其相互连接的[神经元](@article_id:324093)层和非线性[激活函数](@article_id:302225)，它*学习*出自己的内部表示——自己的基——这套基最适合捕捉[势能面](@article_id:307856)的复杂细节。正是这种学习自己描述性语言的能力，使得 MLP 成为一个“[通用函数逼近器](@article_id:642029)”，能够绘制出比其任何前辈都远为准确和灵活的地图。

### 不可违背的景观法则

任何物理领域的地图都必须遵守基本的物理定律。原子景观也不例外。如果你只是将一个原子系统拿起并移动它（平移不变性），在空间中旋转它（[旋转不变性](@article_id:298095)），或者交换两个相同原子的标签，比如水分子中的两个氢原子（[置换](@article_id:296886)不变性），系统的能量是不会改变的 [@problem_id:2760102]。

这些对称性并非仅仅是建议；它们是绝对的约束。一种天真的方法可能是简单地将所有 $N$ 个原子的 $x, y, z$ 坐标输入一个大型神经网络。这将是一个灾难性的错误。网络将面临一项不可能完成的任务：从有限的样本集中从头学习这些[基本对称性](@article_id:321660)。对于一个拥有 $n$ 个相同原子的系统，有 $n!$ (n 的阶乘) 种等效的标记方式。即使是对于像甲烷 (CH$_4$) 这样一个简单的分子，由于有四个相同的氢原子，也有 $4! = 24$ 种[置换](@article_id:296886)。对于一个小的水团簇，这个数字会达到数千。[期望](@article_id:311378)一个网络能为每一种[置换](@article_id:296886)都推断出 $E(\mathbf{R}) = E(\mathbf{P}\mathbf{R})$，在计算上是毫无希望的 [@problem_id:2952097]。

唯一可行的路径是，将这些对称性直接构建到我们模型的架构中。我们不要求模型去*学习*物理定律；我们构建一个*不可能*违反这些定律的模型。

### 局域视野的智慧

构建一个符合物理学原理的 MLP 的突破，源于一个深刻的量子力学洞见与一个巧妙的架构选择相结合。这个洞见就是**电子物质的短视原理** (principle of nearsightedness of electronic matter) [@problem_id:2908380]。简单来说，一个原子的能量主要由其紧邻的局域环境决定。就像一个在拥挤房间里的人，一个原子非常“关心”与它直接相互作用的原子，但对于材料远端的原子却毫不知情。对于像绝缘体和[半导体](@article_id:301977)这样具有[电子带隙](@article_id:331619)的材料来说，尤其如此。

这个原理让我们能够做出一个强有力的简化假设：我们可以将系统的总[能量分解](@article_id:372528)为单个原子能量贡献的总和，其中每个原子的能量仅依赖于其在某个**[截断半径](@article_id:297161)** $r_c$ 内的邻居原子的[排列](@article_id:296886)。

$E_{\text{total}} = \sum_{i=1}^{N} E_i(\text{local environment of atom } i)$

这种“原子民主”对计算带来了惊人的好处。要计算总能量，我们只需访问每个原子一次，考察其局域邻域（其大小平均是固定的），然后将结果相加。这意味着[计算成本](@article_id:308397)与原子数成线性关系，即 $\mathcal{O}(N)$。这正是 MLP 能够模拟包含数百万个原子的系统的原因，这一壮举对于底层的量子力学方法来说是完全不可能的 [@problem_id:2908380]。

但是，原子如何以一种尊重对称性的方式“看到”它的环境呢？这就是**描述符** (descriptor) 的魔力所在。描述符是一个数学向量——一个指纹——它用数值描述了[局域原子环境](@article_id:361081)。一个精心设计的描述符是 MLP 的关键。为了满足物理定律，它必须符合几个严格的标准 [@problem_id:2475277]：

1.  **平移和旋转[不变性](@article_id:300612)**：描述符必须由在平移或旋转下不变的量构成。自然的选择是使用原子间距离和原子三元组之间的角度。

2.  **[置换](@article_id:296886)不变性**：中心原子的描述符必须对其邻居原子的标记不敏感。通过对所有邻居的贡献求和，可以优雅地实现这一点。$\{a, b, c\}$ 的和与 $\{c, a, b\}$ 的和是相同的。这类描述符的著名例子包括 Behler-Parrinello [对称函数](@article_id:356066)和 Smooth Overlap of Atomic Positions (SOAP) 功率谱，它们都利用了这种求和原理来保证局域环境的[置换](@article_id:296886)不变性 [@problem_id:2475277] [@problem_id:2952097]。最后对原子能量的求和，$E = \sum_i E_i$，则确保了对于中心原子本身的[置换](@article_id:296886)[不变性](@article_id:300612)。

3.  **平滑性**：当一个原子移动时，能量和力必须平滑变化。其中一个关键部分是截断。如果一个原子的能量贡献在其穿过截断边界时突然出现或消失，就会在力上产生一个不符合物理规律的、不连续的“跳变”。为了防止这种情况，我们使用一个平滑的截断函数，它确保一个原子的影响在接近[截断半径](@article_id:297161)时会平缓地衰减至零 [@problem_id:2908380] [@problem_id:2475277]。

最终的架构堪称精美：每个原子的局域环境被编码成一个对称不变的描述符。然后这个描述符被输入到一个小型的、通用的神经网络（对于相同化学元素的所有原子，其权重是相同的）中，以产生该原子的能量贡献。总能量就是所有这些贡献的总和。对称性不是学来的；它们是被硬编码的。

### 向量子[预言机](@article_id:333283)学习

有了这个优雅的、尊重物理学的架构，我们如何教它预测准确的能量呢？我们需要一个“基准真相”，一个能为我们提供一系列原子构型正确答案的预言机。这个[预言机](@article_id:333283)就是量子力学，通常以**[密度泛函理论 (DFT)](@article_id:365703)** 的形式出现。

为了使这个过程有效，我们必须能够信任来自我们预言机的数据。具体来说，我们需要知道它提供的力确实是能量的负梯度：$\mathbf{F} = -\nabla E$。具有此性质的[力场](@article_id:307740)称为**保守**[力场](@article_id:307740)。**Hellmann-Feynman 定理**以及对诸如以原子为中心的[基组](@article_id:320713)（Pulay 力）等因素的关键实践修正，恰好提供了这一保证。只要 DFT 计算正确执行（即完全自洽），所得到的力就是该特定模型下 DFT [势能面](@article_id:307856)的精确梯度 [@problem_id:2837976]。

有了这些可靠的数据，我们使用一种称为**力匹配** (force matching) 的技术来训练 MLP [@problem_id:2759514]。虽然我们可以只训练模型来匹配能量，但让它同时匹配力要强大得多。为什么？每个构型只给我们一个总能量值，但它提供了 $3N$ 个力分量（每个 $N$ 个原子在 $x,y,z$ 方向上各一个）。力是[导数](@article_id:318324)；它们告诉模型能量景观的*斜率*，为约束拟合提供了远为丰富的信息。

训练过程包括最小化一个[损失函数](@article_id:638865)，其形式通常如下：

$L(\boldsymbol{\theta}) = \sum_{k} \left[ w_E \left( E_{\text{MLP}}^{(k)} - E_{\text{ref}}^{(k)} - b \right)^2 + w_F \sum_{i} \left\| \mathbf{F}_{\text{MLP}, i}^{(k)} - \mathbf{F}_{\text{ref}, i}^{(k)} \right\|^2 \right]$

这个方程旨在同时最小化能量的平方误差（允许一个浮动偏移量 $b$，因为绝对能量是任意的）和力向量的平方误差 [@problem_id:2759514]。权重 $w_E$ 和 $w_F$ 用来平衡能量和力准确性的重要性。通过最小化这个损失，我们调整[神经网络](@article_id:305336)的参数 $\boldsymbol{\theta}$，直到其在训练数据上的预测与量子[预言机](@article_id:333283)相匹配。

### 窥探地平线之外：长程力与未知领域

我们基于局域视觉原理构建的 MLP 功能极其强大。但它最大的优点也正是其致命弱点。根据设计，它是“短视”的。那么那些本质上是长程的物理现象呢？离子间的静电吸引或排斥遵循库仑定律，以 $1/r$ 的形式缓慢衰减。微妙而普遍存在的范德华力或[伦敦色散力](@article_id:299058)，它们将像氮气这样的分子维系在液体中，以 $1/r^6$ 的形式衰减。一个在比如 6 埃斯特朗处有严格截断的模型，对于更长距离的这些相互作用是完全“盲目”的 [@problem_id:2908380]。

解决方案是机器学习与经典物理学的美妙结合。我们将[能量分解](@article_id:372528)为：

$E_{\text{total}} = E_{\text{short-range}}^{\text{MLP}} + E_{\text{long-range}}^{\text{physics}}$

MLP 负责它最擅长的事情：模拟短程范围内复杂的、混乱的、量子力学性质的相互作用。然后我们再添加明确的、物理上正确的项来处理长程物理。例如，我们可以让 MLP 同时预测依赖于环境的原子[电荷](@article_id:339187)，然后将这些[电荷](@article_id:339187)用于经典的库仑定律求和，以捕捉长程静电作用 [@problem_id:2796824]。这种混合方法在保留 MLP 对复杂短程世界灵活性的同时，恢复了正确的渐进行为。

最后的挑战是未知问题。当我们的模拟进入一个远离其任何训练数据的原子景观区域时会发生什么？MLP 被迫进行[外推](@article_id:354951)，其预测可能变得极不符合物理规律。我们可能会发现模拟预测的过渡态能量和力完全不一致，或者[力场](@article_id:307740)不再是保守的 [@problem_id:2796832]。

应对这种危险的关键是**[不确定性量化](@article_id:299045)**。我们不是只训练一个 MLP，而是训练一个**集成** (ensemble) 模型，其中每个模型从不同的随机初始化开始，或者看到略有不同的数据子集。当我们要求这个模型委员会对一个新区域进行预测时，如果它们都同意，我们可以相当自信。但如果它们的预测大相径庭，这就是一个巨大的警示信号，表明模型正在[外推](@article_id:354951)——这被称为**[认知不确定性](@article_id:310285)** (epistemic uncertainty)，即由于缺乏知识而产生的不确定性 [@problem_id:2456317]。

这种分歧本身可以被用于一种强大的策略，称为**[主动学习](@article_id:318217)** (active learning) [@problem_id:2796832]。我们让模拟使用 MLP 集成模型运行。我们不断监测模型分歧最大的地方。当分歧超过一个阈值时，我们暂停模拟，取那个不确定的构型，然后将其发送给我们昂贵的“量子预言机”(DFT) 以获得基准真相计算。然后，我们将这个新的、高价值的数据点添加到我们的训练集中，并重新训练模型。这就像派遣一名测量员去绘制景观中最未知的区域，迭代地使我们的地图集更加完整和可靠。这就形成了一个闭环，将 MLP 从一个静态模型转变为一个动态的、不断改进的科学发现工具。