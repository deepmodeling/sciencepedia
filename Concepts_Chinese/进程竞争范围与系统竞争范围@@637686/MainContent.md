## 引言
在现代[操作系统](@entry_id:752937)中，管理成千上万个并发线程竞争有限的 CPU 资源是一项关键挑战。[操作系统](@entry_id:752937)为此任务采用的策略，即[线程调度](@entry_id:755948)，从根本上决定了系统的性能、公平性和响应能力。本文探讨了两种对立哲学之间的关键设计选择：进程竞争范围（PCS）和系统竞争范围（SCS）。这一选择体现了局部效率与全局控制之间的核心矛盾，是系统设计者必须应对的难题。读者将首先探索 PCS 和 SCS 的基本“原理与机制”，剖析它们在开销、公平性和硬件交互方面的影响。随后，“应用与跨学科联系”一章将审视这些模型在[实时系统](@entry_id:754137)和[云计算](@entry_id:747395)等不同领域的实际影响，揭示理想选择如何完全取决于手头的任务。

## 原理与机制

想象一下，你是一个拥有数十名表演者的大型马戏团的总监。你如何决定谁能获得聚光灯，以及能持续多久？你可以扮演一个全能的、唯一的马戏团指挥，逐一喊出每个杂技演员、小丑和魔术师的名字。或者，你也可以授权。你可以为每个表演团队分配一束聚光灯，让团队负责人来决定自己成员的表演顺序。

这个简单的类比直击[操作系统](@entry_id:752937)中最基本的设计选择之一的核心：如何调度线程。线程是可由调度器独立管理的最小编程指令序列。当你运行一个应用程序时，它可能由许多并行工作的线程组成。[操作系统](@entry_id:752937)的内核是最终的马戏团指挥，决定哪个线程可以在物理 CPU 核心上运行。我们想象的这两种策略对应着两种截然不同的哲学：**系统竞争范围（System-Contention Scope, SCS）**和**进程竞争范围（Process-Contention Scope, PCS）**。理解它们之间的权衡，就像学习决定你电脑上所有软件性能的秘密编排。

### 巨大分野：两种调度器的故事

让我们说得更精确一些。在**系统竞争范围**模型中，内核可以看到整个系统中的每一个线程。如果你有十个应用程序在运行，每个程序有二十个线程，那么内核的调度器需要管理一个包含 200 个线程的列表。它从这个全局池中进行选择，使其成为唯一的、中央的马戏团指挥。这在概念上很简单，并提供了对系统需求的全局视图。

在**进程竞争范围**模型中，结构分为两层。内核只知道进程（或分配给一个进程的少量“[内核级线程](@entry_id:750994)”）。它调度这些进程，而不是它们内部的单个线程。在每个进程内部，一个独立的、用户级的调度器——作为应用程序运行时库一部分的代码——管理着属于该进程的许多“[用户级线程](@entry_id:756385)”。这就是我们的马戏团类比：内核调度表演团队（进程），而团队负责人（用户级调度器）调度表演者（[用户级线程](@entry_id:756385)）。

这种两级舞蹈对公平性和性能有着深远的影响。让我们想象一个简单的系统，它只有一个 CPU，并使用公平的[轮询调度](@entry_id:634193)策略，给予每个竞争者一个长度为 $q$ 的小时间片，即“量子”。

在 SCS 下，每个线程都在一个大型的“全校集会”中竞争。如果总共有 $L_{\text{school}}$ 个线程，每个线程平均获得 $\frac{1}{L_{\text{school}}}$ 的 CPU 份额。其两次运行之间的间隔时间大约是 $q \cdot L_{\text{school}}$。

在 PCS 下，计算是嵌套的。假设内核看到 $L_{\text{school}}$ 个进程。你的进程获得 $\frac{1}{L_{\text{school}}}$ 的 CPU 份额。现在，如果你的进程有 $L_{\text{group}}$ 个[用户级线程](@entry_id:756385)，你的用户级调度器会在它们之间分配该份额。因此，一个特定线程最终的 CPU 份额是这些分数的乘积：$\frac{1}{L_{\text{school}}} \times \frac{1}{L_{\text{group}}}$。等待时间也相应地急剧增加，大约为 $q \cdot L_{\text{school}} \cdot L_{\text{group}}$ [@problem_id:3672424]。这个简单的乘法揭示了一个关键的见解：在 PCS 中，一个线程的性能不仅是系统负载的函数，还取决于它在自己进程内部与多少个兄弟线程竞争。

这可能看起来不公平。为什么一个[多线程](@entry_id:752340)进程中的线程比一个单线程进程中的线程获得的 CPU 时间要少？这是一个核心矛盾。SCS 在线程间提供全局公平性，而 PCS 在进程间提供公平性。为了量化这一点，我们可以使用像 Jain 公平性指数这样的度量标准，其取值范围从接近 0（非常不公平）到 1（完全公平）。在一个假设场景中，如果一个 PCS 用户级调度器将其进程的所有时间都分配给少数几个“高优先级”的内部线程，那么全局公平性可能会急剧下降。在这样一个模型中，切换到 SCS，让每个线程都获得相等的份额，可以极大地提高公平性指数，例如，从 $\frac{4}{7}$ 提高到完美的 $1$ [@problem_id:3672427]。

### 内核调用的代价

如果 PCS 可能不太公平，为什么还会有人使用它呢？答案是速度。从你的程序转换到操作系统内核是一个相对重量级的操作。这就像一个团队负责人必须为每一个小决定都停下表演，跑到总监的办公室去。另一方面，用户级调度器完全存在于进程内部。两个[用户级线程](@entry_id:756385)之间的“上下文切换”可以非常快——有时只需几十条机器指令来保存一些 CPU 寄存器[并指](@entry_id:276731)向一个不同的栈。

让我们对此进行建模。一个用户级 PCS 调度器的开销可能是一个很小的常数时间，比如 $t_0$。相比之下，内核的 SCS 调度器可能需要管理一个复杂的、包含所有线程的全系统数据结构。其开销可能有一个固定部分 $s_0$，外加一个随着线程数 $N$ 增加而增长的部分 $s_1N$。起初，对于少量线程，内核可能更快。但随着 $N$ 的增长，线性项 $s_1N$ 最终将占据主导地位。存在一个[交叉点](@entry_id:147634)。例如，使用真实的计时参数，我们可能会发现，对于任何超过 8 个线程的情况，SCS 的调度开销就变得比 PCS 的开销更大 [@problem_id:3672494]。这使得 PCS 对于拥有成千上万甚至数百万线程的应用程序极具吸[引力](@entry_id:175476)，例如高流量的 Web 服务器或大规模科学模拟。

唤醒一个休眠线程的延迟也说明了类似的情况。在 SCS 下唤醒一个线程，你总是需要通过内核。而在 PCS 下，如果一个线程想要唤醒*同一进程中*的另一个线程，并且该进程已经在运行，有时用户级调度器几乎可以立即处理，完全无需任何内核干预。这可以显著降低进程内通信的平均延迟。当然，如果该进程没有在运行，你就得回头等待内核，你甚至可能需要等待*两次*：一次是等待内核调度你的进程，第二次是等待你的用户级调度器调度你的线程 [@problem_id:3672487]。

### 阿喀琉斯之踵：当一个阻塞所有

简单的 PCS 模型有一个灾难性的缺陷，通常被称为“阻塞问题”。内核只知道进程级的实体。如果任何一个[用户级线程](@entry_id:756385)发出了*阻塞式系统调用*——例如，从慢速硬盘读取数据——内核会将整个进程实体置于休眠状态。它无法知道同一进程中还有数百个其他线程已经准备好并且愿意做有用的工作。整个表演团队都因为一个表演者去拿道具而被强制下场。

性能影响是毁灭性的。考虑一个包含多个计算密集型线程和一个 I/O 线程的进程。如果 I/O 线程发出一个耗时 $0.12$ 秒的阻塞调用，所有其他线程在这整个期间都会被冻结。完成所有工作的总时间是阻塞时间*加上*计算时间。

现代系统通过使用**非阻塞**或**异步 I/O**来解决这个问题。线程不是等待读取完成，而是告诉内核：“请开始这个读取操作，完成后通知我。”内核启动 I/O 操作并立即将控制权返回给进程。然后，用户级调度器可以运行其他线程。当 I/O 完成时，内核发送一个通知，用户级调度器可以运行原始线程来处理数据。这将一个串行的“等待-然后-计算”过程转变为一个并行的“等待与计算重叠”的过程。在上述场景中，这个简单的改变可以将总执行时间从 $0.467$ 秒减少到 $0.351$ 秒，性能提升了 $0.116$ 秒，这几乎完全是通过消除空闲阻塞时间实现的 [@problem_id:3672527]。这种复杂性是现代高性能运行时的关键，例如 Go、Erlang 以及许多语言中的异步框架。

### 系统中的涟漪：同步与硬件

调度范围的选择会在整个系统中产生涟漪效应，影响从[线程同步](@entry_id:755949)方式到它们与物理硬件交互方式的方方面面。

#### 竞争区

当多个线程需要访问共享资源时，比如内存中的一段数据，它们会使用**锁**来确保一次只有一个线程可以访问。这就产生了一个竞争点。你在和谁竞争？在 PCS 下，一个线程只与同一进程内的兄弟线程竞争锁。在 SCS 下，该锁可能是一个由来自许多不同进程的线程共享的内核对象。竞争者的池子要大得多。使用一个简单的概率模型，我们可以看到从 PCS 转换到 SCS 会显著增加线程必须等待锁的概率。在一个现实的模型中，这种竞争概率的增加可能相当可观，达到 0.04468，即接近 5% [@problem_id:3672523]。

#### 翻译中的失落：[优先级反转](@entry_id:753748)

PCS 的信息隐藏可能导致一个特别棘手的问题，称为**[优先级反转](@entry_id:753748)**。想象一下，一个 PCS 进程中的高优先级用户线程 $U_H$ 需要一个由另一个进程中的低优先级线程 $K_L$ 持有的资源。现在，一个中等优先级的线程 $K_M$ 变为可运行状态。内核调度器只看到三件事：包含 $U_H$ 的进程（该进程被阻塞，并且假设具有中等内核优先级）、低优先级线程 $K_L$ 和中等优先级线程 $K_M$。由于 $K_M$ 的优先级高于 $K_L$，内核会运行 $K_M$。但这阻止了 $K_L$ 运行并释放高优先级线程 $U_H$ 正在等待的资源！$U_H$ 的高优先级在“翻译中失落”了，因为内核不知道它的存在。解决方案是**[优先级继承](@entry_id:753746)**，即 $K_L$ 临时继承它所阻塞的线程的高优先级。但要让这在 PCS 系统中起作用，用户级调度器必须有一个特殊的机制来告诉内核等待中的用户线程的“真实”优先级。在具有依赖链的复杂场景中，这个优先级必须沿着链中的每一个环节传播 [@problem_id:3672488]。这表明，PCS 的整洁抽象有时可能成为正确性的一个危险障碍。

#### 局部性的物理现实

也许 PCS/SCS 权衡最精妙的例证来自于它与硬件架构的交互。一个 CPU 核心有一个小的、极其快速的内存，称为**缓存**。当一个线程运行时，它会将其数据拉入缓存。如果它很快再次在同一个核心上运行，它的数据仍然在那里（一个“热”缓存），执行速度就很快。

PCS 就其本质而言，倾向于将一个进程的所有线程保持在一个核心或一组固定的核心上。这促进了良好的**[缓存局部性](@entry_id:637831)**。而 SCS 为了追求全局公平性，可能会在每次运行时将[线程迁移](@entry_id:755946)到不同的核心。这意味着线程到达一个“冷”缓存，必须再次从主内存中缓慢获取其所有数据。这种持续的迁移会增加显著的开销。一个模型显示，迁移可能会引入额外的 $0.03750$ 的未命中率——意味着仅仅因为调度策略，你近 4% 的内存访问变成了缓慢的未命中 [@problem_id:3672531]。

在具有**[非统一内存访问](@entry_id:752608)（NUMA）**的现代服务器上，这种效应更为显著。这些机器由多个插槽构成，每个插槽都有自己的核心和本地内存。访问本地内存速度快；访问连接到另一个插槽的内存则慢得多。一个智能的、支持 NUMA 的 PCS 用户级调度器可以确保线程与其数据保持在同一个插槽上。而一个旨在实现全系统负载均衡的 SCS 调度器，可能会将[线程迁移](@entry_id:755946)到另一个插槽，迫使其所有内存访问都走缓慢的远程路径。性能差异并非理论上的；单次远程内存访问的代价是一个可测量的量，例如，每次访问会额外增加 $5.00 \times 10^{1}$ 纳秒 [@problem_id:3672496]。

归根结底，PCS 和 SCS 之间的选择体现了一个经典的工程权衡：局部效率与全局控制。SCS 以可伸缩性和局部性为代价，提供了简单性和全局公平性。PCS 提供了极快的速度和良好的局部性，但需要极高的复杂性来克服其固有的缺陷。[操作系统](@entry_id:752937)的发展历程是一场漫长而迷人的探索，旨在寻找完美的[平衡点](@entry_id:272705)，创造出能让我们两全其美的混合系统——这证明了指导百万微小表演者如何起舞的持久魅力与复杂性。

