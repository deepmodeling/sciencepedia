## 引言
在构建能够理解物理世界并与之互动的智能系统的探索中，一个根本性的挑战浮出水面：我们如何教机器，让它明白物理定律在任何地方、任何方向都是相同的？一个标准的[神经网络](@article_id:305336)在看到一个分子时，或许能学会预测其能量；但如果给它看同一个分子稍[微旋转](@article_id:363623)后的样子，它会将其视为一个全新的问题。这种低效凸显了一个关键的知识鸿沟：许多学习模型缺乏内在的物理一致性。

SE(3) [等变性](@article_id:640964)通过将三维刚体运动的对称性——旋转和平移——直接[嵌入](@article_id:311541)到模型的架构中，提供了一个强有力的解决方案。这确保了模型的预测无论物体的朝向如何，都能以物理上正确的方式进行变换。本文旨在探索这一深刻的概念，从其基本原理到其革命性的应用。

首先，“原理与机制”部分将解析使我们能够构建这些具有物理意识的模型的优美对称性数学。随后，“应用与跨学科联系”部分将展示这同一个思想如何正在改变从计算化学、[材料科学](@article_id:312640)到[机器人学](@article_id:311041)和控制理论等多个领域。

## 原理与机制

想象一下，你正试图教一台计算机关于物理世界的知识。你希望它能预测，比如说，一个分子的能量或作用在其原子上的力。你必须教给它的第一课，也是最根本的一课，就是关于对称性。在我们日常的世界里，物理定律不依赖于你身在何处、面朝何方，也不依赖于你是直接观察世界还是通过镜子观察世界（大多数情况下是这样！）。如果一个水分子漂浮在太空中，无论它是在你的实验室里还是在半人马座阿尔法星旁，它的内能都是相同的。无论它朝上、朝下还是朝侧面，能量也都是一样的。这就是对称性的核心。要让我们的智能机器成为一名优秀的物理学家，它必须学会不仅是近似地，而是精确地遵守这一原则。本章将探讨那个优美的数学框架，它允许我们将这些对称性直接植入我们学习机器的核心。

### 与对称性的契约：游戏规则

让我们说得更精确一些。当我们旋转一个分子时，某些性质保持不变，而另一些则以一种非常具体、可预测的方式发生变化。总势能是一个单一的数字（一个**标量**），它完全不发生变化。我们称这种性质为**不变性**。另一方面，作用在每个原子上的力是矢量——它们既有大小也有方向。如果你旋转分子，每个原子上的力矢量也会随之旋转。它们并非保持不变，而是以一种与我们施加的旋转完全耦合的方式进行变换。我们称这种性质为**[等变性](@article_id:640964)**。

这种“与对称性的契约”可以用一个简洁优美的方程来概括。假设我们有一个函数，即我们的机器学习模型，我们称之为 $f$。这个函数接收一个物理系统作为输入，比如所有原子的坐标 $X$。它输出某个性质 $f(X)$。现在，让我们对输入施加一个[对称变换](@article_id:304834) $g$。这个 $g$ 可以是旋转、平移或两者的组合——即“[特殊欧几里得群](@article_id:299831)” $SE(3)$ 中的一个元素。变换后的输入是 $g \cdot X$。[等变性](@article_id:640964)条件表述为：

$$
f(g \cdot X) = \mathcal{D}(g) f(X)
$$

这个方程值得我们花点时间凝视 [@problem_id:2784668]。它表明，先对输入进行变换再应用函数，与先应用函数再对输出进[行变换](@article_id:310184)，得到的结果是相同的。关键在于 $\mathcal{D}(g)$ 这一项，它是变换 $g$ 的一个表示。它告诉我们输出应该如何变换的“规则手册”。

-   如果输出是像能量这样的**标量**，它不会改变。所以 $\mathcal{D}(g)$ 就是数字 1。方程变为 $f(g \cdot X) = f(X)$，这正是不变性的定义。
-   如果输出是[像力](@article_id:335844)这样的**矢量**集合 $\mathbf{F}$，那么 $\mathcal{D}(g)$ 就是[旋转矩阵](@article_id:300745)本身，我们称之为 $\mathbf{R}$。方程变为 $\mathbf{F}( \mathbf{R} X ) = \mathbf{R} \mathbf{F}(X)$，意味着新的力就是旧的力经过旋转之后的结果。

让我们把这个概念具体化。想象一个简单的分子，有三个原子，位置分别是 $\mathbf{r}_1 = (0,0,0)$、$\mathbf{r}_2 = (1,0,0)$ 和 $\mathbf{r}_3 = (0,1,0)$ [@problem_id:2648608]。假设我们计算出作用在这些原子上的力是 $\mathbf{F}_1, \mathbf{F}_2, \mathbf{F}_3$。现在，我们将整个分子绕 z 轴旋转 $90$ 度。新的位置是 $\mathbf{r}'_1, \mathbf{r}'_2, \mathbf{r}'_3$。如果我们将这些新位置输入我们的模型，[等变性](@article_id:640964)原则保证它预测出的新力 $\mathbf{F}'_1, \mathbf{F}'_2, \mathbf{F}'_3$ 将精确地是原始的力同样绕 z 轴旋转 $90$ 度的结果。一个等变模型不需要在新的朝向下从头学习物理学；它*知道*物理学如何变换，因为我们已经将规则内建其中。

### [不变性](@article_id:300612)的盲点：“手性”的故事

你可能会问：“这一切都很优美，但何必这么麻烦呢？为什么不直接用那些对旋转已经不变的性质来描述我们的分子，比如所有原子对之间的距离？”这是一个非常聪明的想法，对于预测能量来说，它效果很好。毕竟，如果能量是不变的，距离也是不变的，那么学习一个从距离映射到能量的函数似乎很自然 [@problem_id:2908414]。

但这种方法有一个致命的盲点。对于任何具有[方向性](@article_id:329799)的性质，它都会失效。考虑[电偶极矩](@article_id:321676)，这是一个从分子中负电荷中心指向正[电荷中心](@article_id:330769)的矢量。现在，让我们想一个**手性**分子——即具有“手性”，像我们的左手和右手一样。一个手性分子和它的镜像（它的**对映异构体**）是不同的，无法通过任何旋转使之重合。然而，它们两者所有原子间的距离集合是完全相同的！[@problem_id:2903829]

如果我们的模型只将距离作为输入，它就从根本上无法分辨左手性和右手性版本的分子。那么，它又怎么可能预测偶极矩的方向呢？如果它预测左[手性分子](@article_id:368528)的偶极矩指向一个方向，那么一致性要求它对右手性分子预测相同的偶极矩，因为输入（距离）是相同的。但我们从物理学上知道，镜像分子的偶极矩应该是原始偶极矩的镜像！模型要解决这个悖论并对所有可能的旋转保持一致，唯一的办法就是放弃，并预测两者的偶极矩都为零 [@problem_id:2903829]。这是唯一不会让它陷入麻烦的答案。

这个优美的例子表明，为了捕捉物理学的全部丰富性，我们的模型需要看到比不变性量更多的东西。它们需要处理具有方向和朝向的信息——它们需要用矢量及其推广形式——**[张量](@article_id:321604)**——来思考。

### 几何之舞：用等变模块构建

那么，我们如何构建一个能够用[张量](@article_id:321604)“思考”的机器呢？答案是从头开始，使用遵循几何规则的操作来构建它。这些网络，通常是[图神经网络](@article_id:297304)（GNN）的一种形式，将分子视为一个图，其中原子是节点，它们之间传递的“信息”不仅仅是数字，而是几何对象。

这种方法的核心思想是，任何[张量](@article_id:321604)都可以被分解为一系列被称为**[不可约表示](@article_id:298633)**（irreps）的基[本构建模](@article_id:362678)块之和。你可以把这想象成[声波](@article_id:353278)在[傅里叶级数](@article_id:299903)中被分解为纯[正弦波](@article_id:338691)之和。对于[旋转群](@article_id:383013) $SO(3)$，这些[不可约表示](@article_id:298633)由一个非负整数 $l$ 标记：

-   **$l=0$**：这些是**标量**。它们对旋转是不变的。
-   **$l=1$**：这些是**矢量**。它们就像三维空间中的箭头一样旋转。
-   **$l=2$**：这些是**四极**[张量](@article_id:321604)（对称、迹为零的 $3 \times 3$ 矩阵）。它们描述更复杂的形状，并以更复杂的方式变换。
-   ……对于更高的 $l$ 值，以此类推。

一个[等变网络](@article_id:304312)为每个原子维护的特征是这些不可约表示的集合 [@problem_id:2479740]。当两个原子相互作用时，网络以一种有原则的方式组合它们的[张量](@article_id:321604)特征。这种组合遵循量子力学中角动量的规则，使用所谓的**克莱布施-戈登系数**。两个不可约表示（比如 $l_1$ 和 $l_2$）的这种“[张量积](@article_id:301137)”会产生一系列新的不可约表示，其类型范围从 $|l_1 - l_2|$ 到 $l_1 + l_2$。例如，组合两个矢量（$l=1$）可以产生一个标量（$l=0$）、另一个矢量（$l=1$，对应于叉积）和一个[四极张量](@article_id:339779)（$l=2$）。

关于相互作用的方向信息，即原子 $i$ 和 $j$ 之间的键矢量 $\mathbf{r}_{ij}$，是通过**球谐函数** $Y_{lm}(\hat{\mathbf{r}}_{ij})$ 来编码的。这些数学函数本身就是类型为 $l$ 的不可约表示的基。相互作用的强度取决于距离 $\|\mathbf{r}_{ij}\|$，由一个常规的、可学习的函数（称为**径向函数**）处理。

整个过程可以被描绘成一支几何之舞。在网络的每一层，附着在原子上的[张量](@article_id:321604)与其邻居的方向信息相结合。这会创建新的[张量](@article_id:321604)，然后传递下去。整个构建过程都受到严格的几何规则约束，确保如果你旋转输入的分子，网络每一层的每一个[张量](@article_id:321604)都会完美[同步](@article_id:339180)地旋转，最终得到一个完全按照应有方式变换的输出。

### 全景图：从旋转到所有[刚体运动](@article_id:329499)

我们的宇宙不仅仅是关于旋转的。我们还有平移和反射。

**平移**是容易处理的部分。一个孤立分子的物理性质不应取决于它是在这里还是在隔壁房间。我们通过设计模型，使其只看到原子的*相对*位置，即[位移矢量](@article_id:326490) $\mathbf{r}_{ij} = \mathbf{r}_j - \mathbf{r}_i$，来强制执行这一点。由于如果我们给所有位置加上一个常数矢量（$\mathbf{r}_i \to \mathbf{r}_i + \mathbf{t}$），这个差值保持不变，所以网络自动地对平移免疫。这种平移不变性与旋转[等变性](@article_id:640964)的结合，给了我们完全的 **$SE(3)$ [等变性](@article_id:640964)**。

**反射**则更为微妙。当我们包含反射（或通过原点的反演）时，我们从[特殊欧几里得群](@article_id:299831) $SE(3)$ 移动到完全的欧几里得群 $E(3)$。大多数力学和[电磁学](@article_id:363853)的基本定律对反射是对称的。但自然界确实有手性——例如，[弱核力](@article_id:317984)对一个粒子及其镜像的表现就不同。

为了处理反射，我们用一个**宇称**标签 $p \in \{+1, -1\}$ 来升级我们的[不可约表示](@article_id:298633) [@problem_id:2479740]。一个特征现在变换为 $(l, p)$。一个“真”标量（如能量）是 $(0,+)$，而一个“真”矢量（如力）是 $(1,+)$。在反射下会获得一个负号的对象被称为“伪”对象。一个**[伪标量](@article_id:375548)** $(0,-)$ 是一个在镜子中看时会翻转符号的数字。一个经典的例子是三个矢量的[三重积](@article_id:374758) $\mathbf{a} \cdot (\mathbf{b} \times \mathbf{c})$，它测量了它们形成的平行六面体的有符号体积。这个量对于区分[手性分子](@article_id:368528)至关重要 [@problem_id:2903829]。一个**[伪矢量](@article_id:375163)** $(1,-)$，比如角动量，在反射下的行为也与真矢量不同。通过构建一个能够追踪宇称的网络，我们可以创建尊重反射对称性 ($E(3)$) 的模型，或者在需要时，创建能够区分手性状态 ($SE(3)$) 的模型。

### 回报：物理保证与普适能力

在构建一个对称机器的所有这些工作之后，回报是什么？回报是巨大的。

首先也是最重要的，我们得到了**物理保证**。物理学中最重要的原则之一是[能量守恒](@article_id:300957)。如果我们设计模型先预测一个不变的标量能量 $\hat{E}$，然后通过取其负梯度 $\hat{\mathbf{F}} = -\nabla \hat{E}$ 来推导力，我们就能免费得到两样东西。能量通过设计保证是不变的。并且因为一个不变标量的梯度总是一个等变的[矢量场](@article_id:322515)，所以力也保证是等变的 [@problem_id:2784654]。最美妙的是，从势能推导出的[力场](@article_id:307740)自动是**保守的**。这意味着当我们在分子动力学模拟中使用这些力时，能量将完美守恒，防止出现分子自发升温或降温等不切实际的行为。一个试图直接学习力的模型，即使它是等变的，也没有这样的保证，并且可能会遭受这些守恒误差 [@problem_id:2784654]。

其次，你可能会担心，通过施加如此多的结构，我们是否限制了模型的能力或**表达能力**。这些对称网络是否可能过于僵硬，无法捕捉[势能面](@article_id:307856)的真实复杂性？奇妙的答案是否定的。**[通用近似定理](@article_id:307394)**已经被证明适用于这些架构 [@problem_id:2908414]。这些定理指出，通过使[等变网络](@article_id:304312)足够大（足够宽和深），它可以近似任何具有相同对称性的[连续函数](@article_id:297812)。我们没有牺牲神经网络的任何普适能力；我们只是引导它们在物理上合理的[函数空间](@article_id:303911)内搜索解决方案。

这种利用对称性指导学习的思想是一个统一的原则，其应用远不止[分子物理学](@article_id:369924)。例如，在生成模型中，可以构建一个[变分自编码器](@article_id:356911)（VAE），其解码器是 $SE(2)$ 等变的。这种结构使模型能够学习一个**[解耦](@article_id:641586)**的[潜空间](@article_id:350962)，其中特定的[潜变量](@article_id:304202)控制生成图像的旋转，而其他[潜变量](@article_id:304202)控制平移，从而提供一种高度可解释和可控的方式来创建和操纵视觉数据 [@problem_id:3100694]。

最终，通过拥抱自然世界的对称性，我们并没有约束我们的模型。相反，我们解放了它们。我们将它们从为每一个新的朝向和构型从头学习这些基本原理的不可能任务中解放出来，转而让它们将全部学习能力集中在物理定律本身错综复杂的、非平凡的模式上。这不仅仅是更好的工程实践；这是一种更深刻、更优美的科学方式。

