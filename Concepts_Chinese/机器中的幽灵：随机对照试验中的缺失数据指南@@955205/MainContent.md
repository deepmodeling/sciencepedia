## 引言
随机对照试验（RCTs）是确立因果效应的黄金标准，因其能通过随机化创建可比较的组而备受赞誉。然而，这种方法论上的纯粹性常常被一个普遍存在的现实问题所破坏：缺失数据。当参与者退出研究导致其结局数据丢失时，各组间的初始平衡可能被打破，从而威胁到试验结论的有效性，并可能导致对治疗效果的错误推断。本文旨在应对这一关键挑战，为理解和管理随机对照试验中的[缺失数据](@entry_id:271026)提供一个全面的框架。

首先，在 **原理与机制** 部分，我们将剖析[缺失数据](@entry_id:271026)的基础理论，探讨[完全随机缺失](@entry_id:170286)（MCAR）、[随机缺失](@entry_id:168632)（MAR）和[非随机缺失](@entry_id:163489)（MNAR）之间的关键区别。我们将审视为何这种“缺失分类法”如此重要，以及它如何决定了恰当的分析方法，并引入[敏感性分析](@entry_id:147555)的概念以应对最具挑战性的情景。然后，在 **应用与跨学科联系** 部分，我们将从理论转向实践，展示如何运用统计方法校正偏倚，敏感性分析如何为监管科学中的高风险决策提供信息，以及对这一问题的深刻理解如何能从一开始就促成更稳健的临床试验设计。

## 原理与机制

一项完美的随机对照试验（RCT）之美在于其近乎神奇的简洁性。通过将个体随机分配到治疗组或[对照组](@entry_id:188599)，我们创造了两个平行宇宙。平均而言，这两个组在所有可以想象的方面——无论是我们能测量的特征（如年龄和性别），还是我们无法测量的特征（如遗传倾向或纯粹的意志力）——在起始时都是相同的。这些宇宙之间唯一的系统性差异就是治疗本身。因此，研究结束时其结局的任何差异都可以自信地归因于治疗。这是医学因果推断的基石，一种从人类生物学和行为的[复杂网络](@entry_id:261695)中分离出干预效果的纯粹方法。

但这种美好的简洁性是脆弱的。它依赖于一个关键假设：我们能够追踪每个人直到实验结束并测量其结局。在现实世界中，这种情况很少发生。参与者可能搬家、忘记预约、退出研究或干脆停止回应。当他们的结局数据消失时，我们就称之为**缺失数据**。这种现象，也称为**受试者流失**（attrition），不仅仅是一种不便；它能击碎我们平行宇宙的镜子。留下来的群体不再是我们开始时那个纯粹的随机化群体，我们推断的基础也开始出现裂痕[@problem_id:4567983]。我们必须提出的核心问题是一个侦探式的问题：数据*为什么*会缺失？答案决定了一切。

### 缺失的分类

要理解这种威胁，我们必须首先对其进行分类。统计学家们用一些相当枯燥但有用的术语，将缺失数据分为三大类。理解它们就像学习区分无害的划痕、可治疗的感染和危及生命的疾病。

#### [完全随机缺失](@entry_id:170286)（MCAR）：无害的意外

想象一下，一位实验室技术员在搬运我们试验中的一架血样时，不小心绊倒，摔碎了整盘样本。这些破碎的样本瓶代表了我们参与者中一个纯粹随机的子集，其损失与他们是否接受治疗、他们的年龄或他们在研究中的状况完全无关。这就是缺失数据的统计学理想状态，称为**[完全随机缺失](@entry_id:170286)（MCAR）**。

形式上，MCAR意味着某个数据点缺失的概率与我们研究中的所有变量（无论是观测到的还是未观测到的）都无关。如果我们用 $R$ 表示一个[指示变量](@entry_id:266428)，当结局 $Y$ 被观测到时为 $1$，缺失时为 $0$；用 $A$ 表示治疗分配，用 $X$ 表示基线特征，那么MCAR意味着被观测到的概率不依赖于任何这些因素：$P(R=1 \mid Y, A, X) = P(R=1)$。

在MCAR条件下，留在我们分析中的参与者——即所谓的“完整病例”——仍然是原始分组的一个随机样本。由于样本量变小，我们的统计功效会降低，但组间比较仍然是公平的。仅包含有观测数据的参与者的简单分析，平均而言，会给出正确的治疗效应估计[@problem_id:4627966]。

#### [随机缺失](@entry_id:168632)（MAR）：可预测的消失

不幸的是，生活很少像一盘掉落的试管那样随机。让我们考虑一个治疗慢性疼痛的新镇痛药的RCT，其中我们每周测量疼痛评分。年长的参与者可能更难前往诊所，因此更有可能错过预约，这是合乎情理的。同样合乎情理的是，年龄可能与疼痛的严重程度有关。在这里，缺失并非完全随机——它与年龄有关。然而，关键在于我们在试验开始时*观测*到了参与者的年龄。

这就是**[随机缺失](@entry_id:168632)（MAR）**机制的本质。形式上，MAR指出，在给定*已观测*数据的条件下，缺失的概率与*未观测*的结局无关。在我们的例子中，如果我们知道一个参与者的年龄、治疗组别以及过去的疼痛评分，他们退出的原因就与他们本周*本应有*的疼痛评分无关。这种缺失可以用我们手头的信息来解释[@problem_id:4639909]。数学上，这可以写作 $P(R=1 \mid Y, A, X) = P(R=1 \mid A, X)$。

在MAR条件下，简单的完整病例分析不再可信。为什么？因为留下来的参与者群体是经过“选择”的。例如，如果在疼痛程度较高的人群中，安慰剂组的退出更为常见（这一事实可由他们的已观测特征预测），那么剩下的安慰剂组受试者平均看起来会比原始的安慰剂组更健康。这种选择偏倚会扭曲比较，并可能导致对治疗效果的错误结论。

好消息是，由于缺失的原因被我们已观测的数据所捕捉，我们可以用统计方法对其进行调整。诸如**[多重插补](@entry_id:177416)（MI）**或**[逆概率](@entry_id:196307)加权（IPW）**等复杂方法正是为这种情况设计的。它们使用已观测数据（$A$ 和 $X$）以有原则的方式填补缺失值（MI），或重新加权已观测的参与者，使他们能正确代表原始的随机化群体（IPW）。如果MAR假设成立且我们的[统计模型](@entry_id:755400)设定正确，这些方法可以提供对真实治疗效应的无偏估计[@problem_id:4627966] [@problem_id:4639909]。这是一个漂亮的统计修正：我们用已知的信息来对未知的信息做出有效推断。一个常见的现实世界例子是，在纵向研究中，患者退出的概率可以通过他们最后一次观测到的症状评分很好地预测；由于该评分是已知的，这种情况很可能属于MAR[@problem_id:4812780]。

#### [非随机缺失](@entry_id:163489)（MNAR）：令人困惑的谜团

现在我们来到了最具挑战性的情景。想象一个关于新型抗抑郁药的RCT。一些参与者不再来进行随访。他们的治疗师可能会怀疑，这是因为他们感到过于抑郁而无法出门，这是治疗无效的直接后果。在这种情况下，数据缺失的原因——他们抑郁的严重程度——正是我们想要测量的结局 $Y$，而这个结局现在是未观测到的。

这就是**[非随机缺失](@entry_id:163489)（MNAR）**。缺失的概率依赖于未[观测信息](@entry_id:165764)本身，即使在考虑了我们所有已观测的信息之后也是如此。像完整病例分析、IPW或基于MAR的[多重插补](@entry_id:177416)等标准方法将会失效，而且常常是灾难性地失效。这些方法建立在一个假设之上，即已观测数据能完全解释数据缺失的原因，而根据定义，MNAR恰恰违反了这一假设。

为了理解这有多危险，让我们考虑一个基于心理治疗试验的思想实验[@problem_id:4728417]。假设一项新疗法的真实效果是将自残事件的平均次数从 $10$ 次减少到 $8$ 次。现在，假设在两个组中，结局较差的患者都更有可能退出，但这种效应在新疗法组中要强得多（也许是因为该疗法更具挑战性）。仅对观测数据进行的简单分析可能会显示，[对照组](@entry_id:188599)的平均值从 $10$ 下降到 $9.35$（因为情况最差的患者缺失了），而治疗组的平均值则从 $8$ 暴跌至 $5.4$（因为情况最差的患者中有更大部分缺失了）。这种幼稚的完整病例分析会报告一个 $5.4 - 9.35 = -3.95$ 的治疗效应，几乎是真实效应 $-2$ 的两倍。该分析不仅是错误的，而且是反保守的，极大地夸大了疗法的益处。这就是忽视数据缺失背后“原因”的危害。

### 直面谜团：敏感性分析的艺术与科学

如果缺失机制是MNAR，我们是否就束手无策了？试验的结果是否就无法知晓了？不完全是。我们无法仅从数据中发现唯一的“真实”答案，因为关键信息已经消失了。然而，我们可以做次优的选择：我们可以探索不确定性的全貌。这就是**敏感性分析**的目的。

我们不是只做一个无法检验的假设（如MAR），而是探索一系列关于缺失性质的合乎情理的假设。我们提出一系列“如果……会怎样”的问题。如果退出治疗组的患者平均比留下来的患者病情严重5个点会怎样？如果他们病情严重10个点又会怎样？我们可以设定一个数学模型，将这些假设代入，观察治疗效应的估计值如何随之变化。

一种常见且强大的方法是使用**[模式混合](@entry_id:197206)模型（pattern-mixture model）**[@problem_id:4627950]。我们分别对已观测和缺失的数据“模式”进行建模。我们可以直接估计每个组中已观测受试者的平均结局 $\bar{Y}_a^{\mathrm{obs}}$。对于未观测的受试者，我们可以假设他们的平均结局与已观测者相差某个量 $\delta_a$，这个量就是我们的敏感性参数：
$$
\mathbb{E}(Y_a \mid \text{Missing}) = \mathbb{E}(Y_a \mid \text{Observed}) + \delta_a
$$
于是，$a$ 组的[总体平均值](@entry_id:175446)就是已观测平均值和假设的缺失平均值的加权平均。调整后的治疗效应 $\Delta(\delta_T, \delta_C)$ 就成为一个由观测效应（$\Delta_{\mathrm{obs}}$）、每组的缺失数据比例（$p_T, p_C$）和我们的敏感性参数（$\delta_T, \delta_C$）组成的简洁而优雅的函数[@problem_id:4839266]：
$$
\Delta(\delta_T, \delta_C) = \Delta_{\mathrm{obs}} + p_T \delta_T - p_C \delta_C
$$
这个优美的公式将整个问题剖析得一清二楚。它精确地展示了偏倚如何依赖于我们的假设。我们现在可以在一系列临床上合理的数值范围内改变 $\delta_T$ 和 $\delta_C$，观察 $\Delta$ 如何变化。另一种相关的方法是使用**选择模型（selection models）**，它直接将退出[概率建模](@entry_id:168598)为未观测结局 $Y$ 和一个敏感性参数的函数[@problem_id:4781679]。

这引出了一个强大的概念——**引爆点分析（tipping-point analysis）**。我们可以系统地增加敏感性参数的值，找到研究结论发生“引爆”（即逆转）的确切点——例如，一个统计上显著的结果变为不显著的点。如果这个引爆点对应于一个极不合理的情景（例如，“只有当我们假设所有退出的患者都死亡时，我们的结论才会改变”），那么我们的结果就是稳健的。如果结论在一个非常小的、合理的假设下就发生了逆转，那么我们的结果就是脆弱的，应极为谨慎地加以解释[@problem_id:4781679] [@problem_id:4839266]。

在现代临床科学中，一份诚实的报告不会躲藏在源于一个无法检验的假设的单一数字背后。它会呈现一个主要分析（通常基于乐观的MAR假设），然后附上一系列这样的敏感性分析。这可能包括探索一系列 $\delta$ 值，检验特定的临床锚定情景（例如，假设中断新疗法的患者其结局与接受常规治疗的患者相似），甚至计算最差和最佳情况的界限[@problem_id:4839187]。这种透明的方法，也可以扩展到处理与不依从性等问题的复杂[交互作用](@entry_id:164533)[@problem_id:4840399]，它不会给我们带来单一确定答案的慰藉。相反，它提供了一些更有价值的东西：一种有原则且诚实的描述，阐明了我们知道什么，我们不知道什么，以及我们的结论对于每个真实世界实验中都不可避免的、如幽灵般存在的缺失数据的敏感程度。

