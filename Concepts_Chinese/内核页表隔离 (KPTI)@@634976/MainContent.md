## 引言
对性能的持续追求使得现代处理器成为了复杂性的奇迹，但这种复杂性可能隐藏着微妙的安全漏洞。计算机[系统工程](@entry_id:180583)中的一个根本性挑战是在不牺牲用户期望的速度的情况下确保强大的安全性。随着 Meltdown 等漏洞的发现，这种矛盾变得尤为突出。在这些漏洞中，那些为速度而设计的优化措施（如[推测执行](@entry_id:755202)）本身就可能被利用，以泄露系统最敏感的秘密。这揭示了传统[内存保护](@entry_id:751877)模型中的一个关键缺陷，证明了仅仅将内核内存标记为不可访问已不再足够。

本文深入探讨了内核[页表](@entry_id:753080)隔离 (KPTI)，这是一种为应对此威胁而开发的强大但代价高昂的防御机制。在第一章“原理与机制”中，我们将探究传统[内存模型](@entry_id:751871)中的缺陷，并详细说明 KPTI 如何通过完全隔离内核内存来构建一堵更坚固的墙。随后，“应用与跨学科联系”一章将量化这种隔离的性能成本，审视用于缓解该成本的巧妙硬件和软件技术，并讨论 KPTI 在更广泛的系统安全生态系统中的地位。

## 原理与机制

要理解现代计算机中性能与安全之间优雅而时而剧烈的博弈，我们必须首先深入机器的心脏：处理器及其与内存的关系。从本质上讲，[操作系统](@entry_id:752937)在进行一场英勇的杂耍表演，为您管理着无数任务，同时确保它们不会相互干扰，更糟糕的是，不会干扰系统自身的关键操作。这种分离的关键在于**虚拟内存**的概念。

### 一道虚设的长城

想象一个广袤的王国。其中心是国王戒备森严的城堡——**内核**。内核掌握着国家的所有机密，并控制着整个王国。城堡周围是臣民们熙熙攘攘的城镇村庄——**用户进程**，比如您的网页浏览器或文字处理器。为了王国的稳定，任何村民都不应能随意闯入国王的私人寝宫。这种分离是根本性的。

在计算机中，这种分离是由硬件强制执行的。每个进程都有自己私有的世界地图，即其**[虚拟地址空间](@entry_id:756510)**，处理器的**[内存管理单元 (MMU)](@entry_id:751869)** 会将其翻译成真实的物理内存位置。为了区分城堡和村庄，地图上的每一页内存都有一个特殊的标志，一个**用户/管理者 (U/S) 位**。当处理器运行内核代码时（处于“管理者模式”），它就是国王，可以访问任何页面。但当它运行您的应用程序时（处于“[用户模式](@entry_id:756388)”），它就是一个平民，只能访问专门标记为“用户”的页面。用户进程任何试图触及“仅限管理者”页面的行为都会立即导致一个异常——这在数字世界中相当于被皇家卫兵逮捕。这是这片土地的体系结构法则。

在计算机发展的数百年间，一种巧妙的优化是常态。为了让向内核发出的请求（称为**[系统调用](@entry_id:755772)**）变得快速，内核的城堡被映射到了*每个*村民的私有地图中。它总是在那里，位于地址空间的高端区域，一个众所周知的位置。当然，它被那道 U/S 位的“墙”所包围，使其在体系结构上对用户进程不可访问。这种设计避免了每次村民需要向国王请求小服务时都得更换整个世界地图的昂贵操作。它很高效，而且在很长一段时间里，被认为是完全安全的。

### 机器中的幽灵

问题源于一个幽灵。现代处理器为了无休止地追求速度，并不耐心。它们就像一个过于热切的助手，在您思考下一步该做什么时，会推测性地提前行动，为您*可能*会请求的事情获取文档并准备结果。这被称为**[推测执行](@entry_id:755202)**。如果猜测正确，就节省了时间。如果猜测错误——比如，您最终决定不打开那份文档——处理器被设计为能够干净利落地丢弃推测结果，就像什么都没发生过一样。没有体系结构规则被破坏。

但如果这个幽灵般的助手在其推测性的匆忙中，读取了一份来自国王寝宫的文档呢？如果它推测性地绕过了 U/S 位的检查呢？从体系结构上讲，处理器最终会意识到自己的错误并使该操作无效。被禁止的数据永远不会交付给用户程序。然而，幽灵留下了足迹。仅仅是获取那个秘密数据的行为，即使是推测性的，也 subtly 改变了[处理器共享](@entry_id:753776)资源的状态，比如它的[数据缓存](@entry_id:748188)。一个在[用户模式](@entry_id:756388)下运行的恶意程序随后可以执行**旁道攻击**：通过计时访问不同内存位置所需的时间，它可以检测到这些足迹，并推断出被推测性读取的秘密。

事实证明，这道长城对幽灵而言是千疮百孔的。这类漏洞，最著名的例子是“Meltdown”，揭示了共享映射从根本上是不安全的。用于防止从数据页执行代码的“不可执行 (NX)”位毫无用处；攻击是读取数据，而不是执行它。将内核页面标记为只读也同样无效，因为攻击*就是*一次读取 [@problem_id:3620236]。唯一真正的防御是让内核的秘密变得不可见。

### 建造一堵更好的墙：隔离原则

如果一个可见但受保护的城堡不安全，那么解决方案很简单， وإن كانت جذرية：让城堡从村民的地图上完全消失。这就是**内核[页表](@entry_id:753080)隔离 (KPTI)** 背后的原则。

通过 KPTI，[操作系统](@entry_id:752937)维护两套独立的页表。当一个用户进程运行时，CPU 使用一个“用户页表”，其中*只*包含该进程的映射。广阔的内核内存根本不存在于这张地图上。从用户的角度来看，内核不存在。如果攻击者的代码试图推测性地读取一个内核地址，处理器甚至无法开始解析它——没有它的翻译条目。攻击被当场阻止。

当系统调用或中断发生，内核必须接管时，CPU 会切换到第二个“内核页表”，其中包含完整的[内存映射](@entry_id:175224)，包括内核和用户进程。

但这引发了一个悖论：用户进程如何能调用一个不在其地图上的内核？解决方案是一个小型的、明确定义的网关。一小段必不可少的内核代码——一个入口和出口的**跳板**——仍然映射在用户[页表](@entry_id:753080)中。这段代码的唯一目的是处理转换：进入内核时，它的第一个动作就是命令 CPU 切换到完整的内核[页表](@entry_id:753080)。退出时，它在返回控制权之前切换回用户[页表](@entry_id:753080)。这个跳板必须极其小心地编写。如果在页表切换完成之前，它推测性地触及任何秘密内核数据，它可能会重新打开它本应修复的那个漏洞 [@problem_id:3620236]。

### 安全的代价

这堵新的、更坚固的墙是有代价的：性能。在每一次[系统调用](@entry_id:755772)和中断时都切换两套完整的世界地图并非小事。这个“KPTI 税”包含几个我们可以测量和建模的组成部分。

首先，切换页表基址寄存器（在 x86 架构上是 `CR3` 寄存器）的指令有固定的周期成本，$c_{\text{sw}}$ [@problem_id:3689810]。但远超于此的成本来自于对**翻译后备缓冲器 (TLB)** 的毁灭性影响。TLB 是处理器必不可少的高速缓存，用于缓存虚拟到物理地址的翻译——它的小抄。没有它，CPU 将不得不为*每一次内存访问*在[主存](@entry_id:751652)中执行缓慢、多步骤的**[页表遍历](@entry_id:753086)**。

当我们切换[页表](@entry_id:753080)时，旧的 TLB 小抄立刻变得过时。CPU 必须刷写它并从头开始建立一个新的。这意味着在一次切换后的最初几次内存访问中——比如说，内核触及的前 $N_k$ 个页面和用户进程返回时触及的前 $N_u$ 个页面——CPU 将遭遇必然的 TLB 未命中，每次都会触发一次代价高昂的[页表遍历](@entry_id:753086) [@problem_id:3689810]。

我们可以精确地量化这个成本。一次[页表遍历](@entry_id:753086)可能涉及遍历 4 级页表，每一步都涉及一次内存访问，其延迟取决于数据是在快速的 L1 缓存中还是在遥远缓慢的主存中。通过计算这些访问的预期延迟，我们发现单次内核转换的总开销可以轻易增加数百纳秒 [@problem_id:3629525]。当一个工作负载每秒进行数百万次[系统调用](@entry_id:755772)时，这个开销累积起来会占到 CPU 总处理能力的很大一部分—— slowdown 很容易达到两位数。对于一个特定的基准测试，这可能意味着 $11\%$ 的性能损失 [@problem_id:3685757]。

这提出了一个经典的工程权衡。这种性能下降是否值得换取安全性？正如一个场景所示，那 $11\%$ 的 slowdown 可能会将潜在的信息泄漏从不可接受的 $200$ 位减少到可管理的 $16$ 位，从而满足系统的安全预算 [@problem_id:3685757]。KPTI 税虽然高昂，但通常是值得付出的代价。确切的相对开销也取决于工作负载。对于一个进行大量[系统调用](@entry_id:755772)但上下文切换较少的系统，相对惩罚要高于一个频繁进行[上下文切换](@entry_id:747797)的系统，因为 KPTI 对上下文切换的惩罚相对于其对[系统调用](@entry_id:755772)的惩罚来说可能成比例地更小 [@problemid:3639752]。

### 更智能的硬件，更轻量的隔离墙

故事并未以速度与安全之间的痛苦选择而告终。安全与性能之间的猫鼠游戏推动着创新。硬件架构师提供了一个强大的工具来减轻 KPTI 的冲击：**进程上下文标识符 (PCID)**。

PCID 就像允许 TLB 同时持有多个小抄，每个都用一个 ID 标记。[操作系统](@entry_id:752937)可以为用户进程分配一个 ID，为内核分配另一个。当从用户态切换到内核态时，CPU 不会刷写 TLB；它只是简单地从使用“PCID 1”切换到“PCID 2”。用户的翻译条目在 TLB 中保持休眠但完好无损。返回时，它只需切换回来。这优雅地避免了每次转换时的灾难性 TLB 刷写。作为直接结果，KPTI 引起的刷写事件数量可以从每秒数百万次降至几乎为零 [@problem_id:3685728]，从而极大地减少了 KPTI 的开销。

另一个优化与 TLB 本身的效率有关。TLB 是一个小型而宝贵的资源。KPTI 增加了它的压力，因为它迫使它管理两个独立地址空间的翻译。这就是**大页**发挥作用的地方。一个 TLB 条目可以映射一个标准的 $4\,\text{KiB}$ 页面，或者在硬件支持下，一个“巨大”的 $2\,\text{MiB}$ 页面。例如，映射一个大的、连续的 $64\,\text{MiB}$ 内存缓冲区，使用标准页面将需要惊人的 $16,384$ 个 TLB 条目。而使用大页，同样的缓冲区仅需 $32$ 个条目即可覆盖 [@problem_id:3684846]。通过为像内核直接映射区这样的大而稳定的内存区域使用大页，[操作系统](@entry_id:752937)可以释放数千个 TLB 槽位，使整个系统对 KPTI 的压力更具弹性。

这段旅程——从一个简单但有缺陷的保护模型，到一个强力隔离，再到一个精妙的、硬件辅助的优化——完美地展示了定义计算机[系统工程](@entry_id:180583)的美丽而动态的相互作用。这是一场对平衡的不断探寻，其中微体系结构的幽灵迫使我们建造更坚固的墙，而我们自己的独创性又找到了使这些墙更轻、更快的方法。

