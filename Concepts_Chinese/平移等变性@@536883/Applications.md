## 应用与跨学科联系

我们花了一些时间来理解[平移等变性](@article_id:640635)原理，即原因的平移会引起结果的相应平移。你可能会倾向于认为这是一个巧妙的数学技巧，是为计算机科学包装的一点[抽象代数](@article_id:305640)。但事实远非如此。这个原理不仅仅是某些函数的深奥属性；它是关于世界本质的一个深刻而强大的假设，将其构建到我们的模型中是现代计算科学中最深刻的思想之一。它是一种信念，即物理定律——或者猫的身份——不依赖于你碰巧站在哪里。当我们赋予我们的[人工神经网络](@article_id:301014)这种对称性时，我们不仅仅是在优化一段代码；我们是在教机器一个关于现实的基本真理。

现在，让我们踏上一段旅程，看看这个思想如何在从视觉和声音的数字世界到物理定律的根本构造等广阔的学科领域中开花结果。

### 数字世界：用[等变性](@article_id:640964)来看和听

最自然的起点是我们自己的感官，或者至少是它们的数字对应物。当你看着一张照片时，无论你的朋友是在画面的中央还是偏向一侧，你都能认出他们的脸。[卷积神经网络 (CNN)](@article_id:303143) 的设计初衷就是为了做到这一点。它的卷积滤波器就像小小的模式探测器，在整个图像上滑动，寻找边缘、纹理或角落等特征。因为在所有地方都使用同一个探测器，网络找到一个特征的能力与其位置无关。

但是，当我们在这一简单思想之上构建复杂系统时，会发生什么呢？考虑一个[目标检测](@article_id:641122)器，一个在图像中物体周围画框的程序。我们当然希望它是平移等变的。一个能在道路左侧找到汽车的系统，也应该能在右侧找到它。然而，在实践中，这种完美是难以企及的。许多现代检测器，如 YOLO 或 SSD，将图像划分为一个网格，并让每个网格单元负责检测中心位于其中的物体。如果一个物体移动了仅仅一个像素并越过了单元格边界，检测它的责任就会突然从一组预测器转移到另一组。这可能导致预测的[边界框](@article_id:639578)“闪烁”或[置信度](@article_id:361655)分数跳动，这是破坏我们所追求的平滑、完美[等变性](@article_id:640964)的直接后果 [@problem_id:3146159]。理解[等变性](@article_id:640964)在何处以及为何被破坏，是构建更稳健系统的第一步。

有时，数据本身的结构似乎与[等变性](@article_id:640964)相悖，我们必须巧妙应对。在数码相机中，传感器不会在每个像素上捕捉完整的颜色。相反，它使用一个棋盘状的彩色滤光阵列 (CFA)，最常见的是拜耳模式，该模式在红色、绿色和蓝色传感器之间交替。为了重建一幅全彩图像——一个称为去马赛克的过程——网络必须学会推断缺失的颜色。如果我们把原始的拜耳模式平移一个像素，整个颜色的[排列](@article_id:296886)就会改变。一个标准的 CNN 会完全迷失方向。解决方案是一个绝妙的工程设计：我们可以首先通过将不同颜色位置分离到它们自己的通道中来*提升*图像。一个对平移和这些新通道的[排列](@article_id:296886)都等变的网络，便可以学会对图像进行去马赛克，并且最终结果将对原始传感器数据的位移表现出适当的[等变性](@article_id:640964) [@problem_id:3196066]。我们通过在更高维度的空间中思考，恢复了对称性。

同样的原理也适用于声音。音频信号可以表示为谱图，这是一个二维图像，其中一轴是时间，另一轴是频率。一段旋律是这个图像中的一个模式。如果我们用一个标准的二维 CNN 来处理它，我们就内置了对时间和频率的[等变性](@article_id:640964)。这意味着模型假定一段旋律，无论是现在播放还是五秒后播放（[时间平移](@article_id:334500)），无论是以 C 调还是 G 调演奏（频率平移，或音高变换），都是“相同”的。但这总是我们想要的吗？也许绝对音高很重要。我们可以转而设计一个一维 CNN，它只沿着时间轴进行卷积，将每个频率箱视为一个独立的、独特的通道。这个模型对[时间平移](@article_id:334500)是等变的，但对音高变换则不是。架构的选择编码了对你试图解决问题的物理特性的一个基本假设 [@problem_id:3139440]。

### 物理世界：从触摸到原子

让我们走出数字世界，进入物理世界。想象一个皮肤上布满触觉传感器的机器人。它需要通过触摸来识别物体的纹理。它用手掌的左侧还是右侧接触物体应该无关紧要。*砂纸*的感觉应该是一样的。一个处理机器人皮肤*触觉图*的 CNN 恰好提供了这种能力。通过内置[平移等变性](@article_id:640635)，机器人可以以一种通用的方式学习识别纹理和压力，而不必为身体上的每一个传感器都单独学习一遍 [@problem_id:3196034]。

我们可以将这个想法一直推到原子尺度。在计算化学中，我们希望预测一个原子系统的能量和力。例如，一个水分子的能量取决于其原子的相对位置，而不是其在空间中的绝对位置或朝向。[神经网络势](@article_id:351133) (NNP) 就是为此设计的。与 CNN 的*等变*滤波器不同，像 Behler-Parrinello NNP 这样的模型使用称为[原子中心对称函数](@article_id:353833) (ACSF) 的描述符。如果原子是像素，这些 ACSF 就像是[特征检测](@article_id:329562)器，根据其数学构造，它们对旋转、平移，甚至相同邻近原子的交换都完全*不变* [@problem_id:2456307]。它们捕捉了一个原子局部环境的基本几何形状。

然后，为了得到整个系统的总能量，NNP 简单地将每个原子的能量贡献相加。这种求和，$E = \sum_{i} E_{i}$，是一种池化形式。它不关心你相加能量的顺序。这在概念上与 CNN 末端的[全局平均池化](@article_id:638314)层相同，后者对所有空间位置的特征激活进行平均，以得到一个最终的、[排列](@article_id:296886)不变的摘要。在这两种情况下，我们都看到了一个两步过程：首先，提取局部特征（等变或不变地），其次，将它们聚合成一个全局的、[排列](@article_id:296886)不变的量 [@problem_id:2456307]。

### 生物世界：解读生命密码

事实证明，大自然也是这一原理的拥护者。我们细胞中的 DNA 包含以[核苷酸](@article_id:339332)序列编码的指令。某些短的模式，或称基序，充当细胞机器的信号。例如，一个[转录因子](@article_id:298309)可能与特定的 DNA 基序结合以开启或关闭一个基因。这个基序通常无论出现在基因组的哪个位置都能正常发挥作用。

这是一维 CNN 的完美用武之地。通过沿着 DNA 序列滑动其滤波器，它可以学会在不考虑绝对位置的情况下检测这些功能性基序——这是[平移等变性](@article_id:640635)的直接应用。这种方法有一个内置的假设：模型是一个“基序袋”，其中基序的存在比它们的[排列](@article_id:296886)更重要。但如果生物功能取决于几个基序的精确顺序和间距呢？在这种情况下，一个按顺序处理序列并维持对其所见内容的“记忆”的 RNN，可能是一个更好的模型。在[基因组学](@article_id:298572)任务中选择 CNN 还是 RNN，不仅仅是一个技术细节；它是关于所建模的底层生物机制的一个假设。这个过程是依赖于位置无关的特征（CNN），还是依赖于有序的、序列性的信息（RNN）？[@problem_id:2373413]

### 扩展视野：超越平面和简单平移

到目前为止，我们讨论的都是在平坦的线或平面上平移模式。但如果我们的数据存在于一个[曲面](@article_id:331153)上，比如地球呢？想想天气模式、气候数据，或者[宇宙微波背景](@article_id:306934)辐射的图像。我们不能简单地把地球展开成一张平坦的地图，然后运行一个标准的 CNN。为什么不行？因为球面上的旋转并不对应于地图上的简单平移；它会产生复杂的、非线性的扭曲，尤其是在两极附近。一个只对平移等变的标准的 CNN 会被完全迷惑。

这迫使我们推广我们的思维。平面的[对称群](@article_id:306504)是平移群。球体的[对称群](@article_id:306504)是[旋转群](@article_id:383013)，$SO(3)$。为了正确处理球面数据，我们需要发明“球面 CNN”，其操作本质上是对旋转等变的。这个被称为[几何深度学习](@article_id:640767)的领域，就是关于构建尊重非[欧几里得空间](@article_id:298501)内在对称性的网络 [@problem_id:3126236]。[平移等变性](@article_id:640635)只是一个更宏大思想的一个特例：对一个变换群的[等变性](@article_id:640964)。

这把我们带到了我们最深刻的例子。在基础物理学中，最深刻的原理之一是[规范对称性](@article_id:296892)。你可以把它想象成[时空](@article_id:370647)中每一点上的一种内部的、抽象的对称性。物理定律，如[电磁学](@article_id:363853)或核力的定律，必须在这些内部[坐标系](@article_id:316753)的局部“重新定向”下保持不变。当物理学家在离散的格子上研究这些理论时，他们必须处理尊重这种规范对称性的数据。

我们能设计一个同样遵循这一原则的神经网络吗？答案是肯定的。规范等变 CNN 是一种卓越的构造，它将这一基本物理原理构建到其核心架构中。为了比较一个格点上的特征与相邻格点上的特征，它不能简单地将它们相减。它必须使用存在于格点之间连接上的变量——*规范连接*——来将信息从一个格点*平行输运*到另一个格点。这确保了比较在物理上是有意义的，并且与任意的局域坐标选择无关。网络的层被设计用来处理[协变变换](@article_id:377190)的*带电*特征，并且它通过观察闭合回路来构造规范不变的量，就像物理学家所做的那样。这是思想的惊人融合，机器学习中的一个概念完美地反映了粒子物理学[标准模型](@article_id:297875)的基石 [@problem_id:2410578]。

### 一个实践的尾声：[等变性](@article_id:640964)的效率

在这样一次抽象的飞跃之后，让我们以一个完全实际的注解结束。将[等变性](@article_id:640964)构建到模型中，不仅仅是为了优雅或更好的泛化能力，也关乎原始的计算效率。

假设你需要将一个检测器应用于一张非常大的高分辨率图像的每一个像素。天真的方法是围绕每个像素提取一个小块，然后逐个对该小块运行你的 CNN。对于一张数百万像素的图像，这意味着数百万次独立的、冗余的[前向传播](@article_id:372045)。但如果你的 CNN 是平移等变的，你就不必这么做。你可以在整个大图像上*一次性*运行网络。在生成的特征图中，任何给定像素处的输出，都与你将一个小块以该像素为中心并对其运行网络所得到的结果完全相同。得益于[等变性](@article_id:640964)，一次大规模的[并行计算](@article_id:299689)取代了数百万次微小的串行计算。唯一的例外是在图像的边缘，那里的网络*[感受野](@article_id:640466)*会超出图像范围。对于这些少数的边界像素，由于填充效应，等价性被打破，你可能需要退回到较慢的分块方法。但对于图像广阔的内部区域，速度的提升可能是巨大的 [@problem_id:3196098]。

从识别一只猫，到解读 DNA，再到探索物理学的基本定律，[平移等变性](@article_id:640635)原理——以及它对其他对称性的推广——是一条金线。它简化了我们的模型，使它们更加稳健，而且最重要的是，使它们与我们试图理解的世界的深层结构保持一致。