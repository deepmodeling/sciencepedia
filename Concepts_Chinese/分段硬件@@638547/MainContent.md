## 引言
现代计算机是如何在运行众多应用程序的同时，确保它们互不干扰的？每个程序似乎都在其各自的私有内存空间中运行，然而它们却共享着同一个物理 [RAM](@entry_id:173159)。这种隔离的幻象并非魔法，而是由 CPU 的[内存管理单元](@entry_id:751868)（MMU）完成的一项工程壮举，而分段（segmentation）正是其基石技术之一。本文旨在揭开分段硬件的神秘面纱，阐明处理器如何强制设定边界，并在[共享内存](@entry_id:754738)的混沌中建立秩序。

在接下来的章节中，您将全面理解这一强大的架构概念。第一章“原理与机制”深入探讨了分段的核心组件，解释了基址和界限寄存器如何定义受保护的内存区域，以及特权环如何建立[操作系统](@entry_id:752937)与应用程序之间的信任层级。随后，“应用与跨学科联系”一章将探讨这些机制的实际影响，从构建进程、防止安全漏洞，到它们在虚拟化和实时系统等领域的惊人现代应用。读完本文，您将看到一个诞生于早期计算时代的概念如何持续塑造着当今的数字世界。

## 原理与机制

当我们开始探索机器的核心时，会遇到一个深刻的问题：一台同时处理着数十个程序和[操作系统](@entry_id:752937)自身任务的计算机，是如何让每个程序都产生一种独占整个内存的错觉？您的网页浏览器、音乐播放器、代码编辑器——每一个都在其自己的私有世界里运行，一个从地址零开始、延伸数千兆字节的、干净的[线性空间](@entry_id:151108)。然而在现实中，所有这些程序都被塞进物理 RAM 芯片中，一个混乱且共享的空间。处理器是如何维持秩序，防止一个有缺陷的程序涂抹另一个程序的数据，或者更糟，涂抹[操作系统内核](@entry_id:752950)的数据？

答案在于现代 CPU 的一个关键部分——**[内存管理单元](@entry_id:751868)（MMU）**——所施展的一种硬件魔法。而**分段（segmentation）**是其最优雅且具历史意义的工具之一。

### 标尺与栅栏：定义私有空间

让我们想象内存不是一条连续的线，而是一系列逻辑块的集合。一个程序不仅仅是一大块字节；它有一个代码块、一个数据块、一个用于存放临时变量的栈等等。分段硬件允许[操作系统](@entry_id:752937)将这些块中的每一个都视为一个独立的实体，即一个**段（segment）**。

为了管理一个段，硬件只需要两个基本信息：一个**基地址（base address）**和一个**界限（limit）**。

**基地址**就像一把标尺。它告诉 CPU，该段在广阔的物理内存真实版图中的*起始位置*。当您的程序请求其[逻辑地址](@entry_id:751440) `100` 处的数据时，硬件并不会去访问物理地址 `100`。相反，它会计算出真实地址：
$$
\text{physical address} = \text{base} + \text{logical address}
$$
这个简单的加法操作将您程序的私有内存视图重定位到它在 [RAM](@entry_id:173159) 中的实际位置。

**界限**则是一道栅栏。它告诉 CPU 该段的大小。在访问任何内存之前，硬件会执行一次关键检查：
$$
\text{logical address} \le \text{limit}
$$
如果您试图越过栅栏——如果您的程序有 bug 并试图写入超出其分配的数据数组末尾的位置——硬件会立即发出警报，即处理器故障（processor fault），在造成任何损害之前阻止这次越权访问。这种[边界检查](@entry_id:746954)是最基本的[内存保护](@entry_id:751877)形式。

硬件是极其精确的。考虑一个边界情况：一个段的界限为 $L$。那么偏移量恰好为 $L$ 的那个字节是否可以访问？答案是可以。检查允许访问直至并*包括*由界限定义的最后一个字节 [@problem_id:3680517]。栅栏设在您领地的最边缘，而不是向内一步的位置。

但如果一个段非常大，比如几兆字节，仅仅为了存储一个大的界限值而要求一个巨大的描述符字段就太低效了。架构师们设计了一个巧妙的技巧：**粒度位（granularity bit, $G$）**。如果此位被设置，硬件会将界限值解释为更大的单位，通常是 $4 \, \mathrm{KiB}$ 大小的页，而不是单个字节。对于描述符中给定的界限值 $L$，实际可寻址的字节数可以扩展到 $(L+1) \times 4096$。这使得一个小的 20 位界限字段能够定义高达 $4 \, \mathrm{GiB}$ 的段，就像用公里而不是毫米来测量长途旅行一样 [@problem_id:3680504]。

### 世界的目录：描述符与选择子

一个基地址和一个界限对于单个段来说是足够的，但一个真实的程序有好几个段。我们需要一种方式来管理所有这些段。基地址和界限不是硬编码在 CPU 中，而是存储在内存中的一个特殊表中，称为**描述符表（Descriptor Table）**。此表中的每个条目，即一个**[段描述符](@entry_id:754633)（segment descriptor）**，包含了一个段的基地址、界限以及其他重要信息。

程序如何指定它想要使用哪个段呢？它使用一个**段选择子（segment selector）**。您可以将选择子想象成一张门禁卡。当您的程序进行内存访问时，它向 CPU 出示一个选择子。CPU 使用选择子中的索引在表中查找相应的描述符，获取基地址和界限，然后执行[地址转换](@entry_id:746280)和[边界检查](@entry_id:746954)。因此，一个[逻辑地址](@entry_id:751440)不再是单个数字，而是一个数对：`(selector, offset)`。

这种机制比早期处理器中的原始分段功能强大得多。例如，在旧的 16 位“实模式”下，线性地址是通过一个简单的公式计算出来的：`(segment_value  4) + offset`。这个方案在当时很巧妙，因为它允许使用 16 位寄存器访问 1MB 的内存，但它没有提供真正的保护。[保护模式](@entry_id:753820)对描述符表的使用，是向一个稳健的、由硬件强制隔离的世界的飞跃 [@problem_id:3680510]。

就像任何优秀的系统一样，这个系统也有内置的安全特性。那么索引为 `0` 的门禁卡呢？这对应于**空描述符（null descriptor）**。它是一个故意设置的无效条目。硬件允许程序将一个空选择子加载到数据段寄存器中；这就像把一张空门禁卡放进口袋。然而，一旦程序试图*使用*该选择子进行内存访问，CPU 就会发出警报——一个通用保护故障（General Protection fault）——并向[操作系统](@entry_id:752937)报告错误码 `0`，表明故障不是由配置错误的段引起的，而是试图使用“无”这个概念 [@problem_id:3680519]。这是对深思熟虑的硬件设计的证明。

### 天鹅绒隔离带：特权与[保护环](@entry_id:275307)

现在我们来到了分段中最优美、最强大的思想：**特权级（privilege levels）**。并非所有代码生而平等。[操作系统内核](@entry_id:752950)是机器的主宰，需要不受限制地访问所有硬件。而用户应用程序则应该被限制在容器内。

分段硬件使用**[保护环](@entry_id:275307)（protection rings）**来实现这种层级结构，通常编号为 $0$（最高特权）到 $3$（最低特权）。内核运行在环 0，应用程序运行在环 3。每个[段描述符](@entry_id:754633)都有一个**描述符特权级（DPL）**，指定访问它所需的最低特权。CPU 在任何时候都知道其**当前特权级（CPL）**，即它当前正在执行的代码段的 DPL。

当一个环 3 的程序试图访问一个数据段时，硬件会强制执行一条严格的规则。仅仅 CPL 拥有足够高的特权是不够的。选择子本身也带有一个**请求者特权级（RPL）**。硬件会检查 CPL 和 RPL 中*特权最低*（数值最大）的一方是否被允许访问该段。检查规则是：
$$
\max(CPL, RPL) \le DPL
$$
想象一个用户应用程序（$CPL=3$）试图读取一个 DPL 为 0 的关键[操作系统](@entry_id:752937)[数据结构](@entry_id:262134)。即使它使用 RPL 为 0 的选择子，检查也变为 $\max(3, 0) \le 0$，即 $3 \le 0$。这是不成立的，硬件会立即触发一个故障 [@problem_id:3680456]。这个 `max` 函数是对“困惑的代理人”（confused deputy）攻击的绝妙防御，这种攻击中，低特权应用程序可能会试图欺骗高特权代码片段代其执行危险操作。

这种严格的分离也适用于控制流。用户程序不能简单地跳转到内核代码中。然而，某些代码，如高度优化的数学库，需要对所有人都可访问，而又不授予他们额外的特权。为此，该架构提供了**一致性代码段（conforming code segments）**。当程序调用一个一致性段时，特权检查会放宽：只要调用者的[特权级别](@entry_id:753757)*相同或更低*（$CPL \ge DPL$），转移就是允许的。关键是，调用之后，CPU 的[特权级别](@entry_id:753757)*不会改变*。一个环 3 的应用程序调用一个环 0 的一致性段后，将继续在环 3 执行 [@problem_id:3680523]。它可以使用这个房间，但拿不到主钥匙。

### 两种保护的故事：段与页

凭借其面向对象的内存视图和复杂的特权模型，分段似乎是一个完整的解决方案。但硬件的演进产生了另一个平行的思想：**[分页](@entry_id:753087)（paging）**。

分段考虑的是逻辑上大小可变的对象（代码、数据、栈），而分页则更务实、更统一。它将整个线性地址空间切成固定大小的块，称为**页（pages）**（例如，$4 \, \mathrm{KiB}$），并单独管理它们。其主要关注点是有效地将这些虚拟页映射到物理内存帧，并以页为单位实施访问权限。

这两种机制是多余的吗？完全不是。它们是两种不同的保护哲学，它们的优点是互补的。一个绝佳的例子阐明了这种二元性 [@problem_id:3673090]：

-   **场景 1：分[段表](@entry_id:754634)现出色。** 想象一个 $8192$ 字节的缓冲区。我们可以定义一个界限精确为 $8191$ 的段。如果一个有 bug 的循环试图写入第 $8192$ 个字节，分段硬件将立即捕获这个[溢出](@entry_id:172355)。而[分页](@entry_id:753087)机制则可能错过它。如果紧邻缓冲区的内存恰好位于另一个也被映射且可写的页上，分页硬件将愉快地允许这次写入，从而破坏相邻的数据。在这里，分段保护*逻辑对象*的能力更为优越。

-   **场景 2：分页表现出色。** 现在想象这个缓冲区只是一个大型堆的一小部分，而这个堆被定义为一个数兆字节的单一分段。这个段的界限太粗糙，无法检测到小的溢出。此时，[操作系统](@entry_id:752937)可以利用分页的一个技巧：它可以分配缓冲区的页，然后将地址空间中紧随其后的页标记为“不存在”。一旦有 bug 的代码试图写入缓冲区末尾之后的一个字节，它就会触及未映射的“保护页”（guard page），分页硬件就会触发一个页错误（page fault）。在这里，分页在细粒度*地址空间*级别控制访问的能力提供了分段所未能提供的保护。

这两个系统以一个优美的顺序协同工作。对于每一次内存访问，分段单元首先行动。它检查段是否存在以及偏移量是否在其边界内，从而产生一个**线性地址**。然后，这个线性地址被传递给分页单元，分页单元将其转换为最终的物理地址，并执行其自己的逐页权限检查 [@problem_id:3688171]。

### 分段的幽灵：现代遗产

在当今的 64 位计算世界中，人们可能认为分段是一种过时的遗物。在很大程度上，像 Linux 和 Windows 这样的现代[操作系统](@entry_id:752937)采用了**近乎平坦的[内存模型](@entry_id:751871)**。它们将主代码段和数据段的基地址设为 $0$，界限设为最大可[能值](@entry_id:187992)（或者，在 64 位模式下，硬件对大多数段直接忽略这些值）。结果是，对于大多数内存，`线性地址 = [逻辑地址](@entry_id:751440)`。隔离、保护和[虚拟内存](@entry_id:177532)的繁重工作几乎完全交给了更灵活的[分页](@entry_id:753087)硬件 [@problem_id:3680258]。这在性能上也是合理的，因为每一层硬件检查都会给每次内存访问增加微小的延迟，几个时钟周期 [@problem_id:3680424]。

但分段并未消亡。它找到了一个全新而绝妙的用途。虽然主段是平坦的，但两个特殊的段寄存器 `FS` 和 `GS` 仍然完全可用。[操作系统](@entry_id:752937)可以为每个执行线程的 `FS` 或 `GS` 分配一个不同的、非零的基地址。这个基地址指向一个称为**线程本地存储（Thread-Local Storage, TLS）**的独特内存块。当一个线程需要访问其私有数据——它自己的 `errno` 变量或一个唯一的事务 ID——它可以通过一个 `FS` 相对地址来完成。当[操作系统](@entry_id:752937)执行[上下文切换](@entry_id:747797)到另一个线程时，它只需要执行一条快如闪电的指令来更新 `FS` 基址寄存器，使其指向新线程的 TLS 块。

对一个经典特性的这种重新利用，是计算机体系结构中持久之美的完美典范。一个源于在简单机器中构建和保护内存需求的思想，经过演变、适应，找到了新的生命，安静而高效地解决着一个现代问题，如同一个仍在执行其重要工作的机器中的幽灵。

