## 应用与跨学科联系

有一个精彩的故事，或许是杜撰的，说一个学生问伟大的物理学家 Enrico Fermi，他如何能如此迅速地估算出几乎任何问题的答案。据说 Fermi 回答说，物理学不是要记住所有公式，而是要了解哪些数字大，哪些数字小。在许多方面，科学的艺术就是知道该忽略什么的艺术。它是看着一团旋转、混乱的信息，并从中挑出少数几个讲述真实故事的关键特征的艺术。

几个世纪以来，这门艺术一直是人类思维的专属领域，需要多年的学习和直觉来磨练。一个生物学家，看着一个蛋白质，会知道要考虑它的[电荷](@entry_id:275494)和对水的亲和力来猜测它的行为 [@problem_id:2047852]。一个工程师，观察一根[振动](@entry_id:267781)的弦，会知道要测量它的阻尼比和周期的稳定性来分类它的运动 [@problem_id:2038021]。他们通过手工进行[特征工程](@entry_id:174925)，将复杂的现实简化为少数几个有意义的数字。

但是，如果我们能把这门艺术教给机器呢？如果机器能够靠自己学会如何看待世界——如何找到那些重要的特征呢？这就是特征学习的承诺，而这个承诺正在悄然重塑科学和工程的版图。

### 从手工特征到自动发现

经典方法尽管取得了种种成功，但也有其局限性。当我们手工制作特征时，我们将自己的偏见和有限的理解嵌入到模型中。我们可能会错过一些关键的东西，一些我们的理论尚未捕捉到的微妙相互作用。超越这一步的第一步是变得更加系统化。

想象一下试图预测一条 RNA 链将如何与一个蛋白质相互作用。传统方法可能涉及对两个分子之间所有可能[排列](@entry_id:136432)进行复杂且计算成本高昂的模拟，这个过程可能需要很长时间 [@problem_id:2370247]。一种更聪明、基于特征的方法是简单地计算 RNA 和蛋白质中所有短[子序列](@entry_id:147702)（称为 `$k$-mers`）的频率。这为我们提供了每个分子的固定大小的“指纹”。然后我们可以用这些指纹来训练一个机器学习模型，这样效率要高得多。我们不再进行缓慢的、成对的舞蹈，而是对两个静态的轮廓进行快速比较。我们仍然在告诉机器要寻找什么——在这里是 `$k$-mers`——但我们是以一种更全面、更自动化的方式来做的。

我们可以将类似的想法应用于随时间变化的数据。我们不仅可以观察系统的最终状态，还可以创建描述其动态的特征。对于一个时间序列，我们可以使用一个优美的数学工具，即[均差](@entry_id:138238)（divided differences），来系统地计算其局部的“速度”和“加速度” [@problem_id:3254714]。这些成为捕捉系统轨迹而不仅仅是其快照的特征。在这两个例子中，我们已经从手工挑选几个“黄金”特征转向算法生成一整本特征词典。这是一个强有力的进步，但真正的革命在于迈出下一步：让机器编写自己的词典。

### [深度学习](@entry_id:142022)革命：学会观察

现代深度学习的突破在于，我们可以设计出能够直接从原始或最少处理的数据中学习特征的网络。网络架构本身变成了一台用于观察的机器。

思考药物发现的巨大挑战。我们有一个目标蛋白，可能与某种疾病有关，还有一个候选药物分子。它们会结合吗？结合强度如何？这是一个生死攸关的问题，也是一个极其复杂的问题。蛋白质是一长串一维的[氨基酸序列](@entry_id:163755)；药物是一个复杂的三维原子和[化学键](@entry_id:138216)图。机器如何从如此不同的对象中学习？

答案是一种“多模态”架构，一个有两只眼睛的网络 [@problem_id:1426763]。一个分支，一个一维[卷积神经网络](@entry_id:178973)（1D CNN），沿着蛋白质序列滑动，学习识别形成结合位点的关键氨基酸模式和基序。另一个分支，一个[图卷积网络](@entry_id:194500)（GCN），沿着药物分子的化学键“行走”，学习每个原子的化学环境。每个分支为其特定的模态发展出自己的内部表示——自己学习到的特征。然后，这两个丰富的[特征向量](@entry_id:151813)被汇集、连接在一起，并输入到网络的最后一部分，由它做出最终预测：一个表示结合亲和力的单一数值。机器没有被告知[疏水性](@entry_id:185618)或[电荷](@entry_id:275494)；它从数据本身、从头开始学习了相关概念。

这种学习表示的能力不仅限于现实世界的物体；它还可以用于导航[科学模拟](@entry_id:637243)的抽象世界。许多科学问题，从设计飞机机翼到预测天气，都依赖于可能极其昂贵的计算机模拟。一个高分辨率模拟可能需要在超级计算机上运行数周。一个低分辨率的模拟可能在笔记本电脑上只需几分钟，但其结果不太准确。我们能两全其美吗？

在这里，特征学习通过一种称为[迁移学习](@entry_id:178540)的策略提供了一个卓越的解决方案 [@problem_id:3369122]。我们可以用大量廉价、低保真度的模拟数据来训练一个深度神经网络。这样做时，网络不仅仅是在记忆输入和输出；它在学习物理学的底层“语言”——流动、压力和几何的基本特征。一旦这种表示被学习到，我们就可以用极少数昂贵、高保真度的模拟来“微调”这个网络。网络将其知识从廉价世界转移到昂贵世界，有效地学习了从低保真度到高保真度所需的*修正*。它学会了像物理学家一样看待问题，利用廉价数据建立直觉，利用昂贵数据确定精确细节。

现代特征学习中最深刻的想法或许是，最好的特征不仅对一个任务有好处，而且对许多任务都有好处。一个真正好的世界表示应该能预测世界。这一见解正被用来增强[强化学习](@entry_id:141144)，即训练智能体做出最优决策的人工智能领域。在一个复杂的环境中，如果行动与未来奖励之间的联系很微弱，智能体可能难以学会哪些行动能带来奖励。为了帮助它，我们可以给它一个“辅助任务” [@problem_id:3163613]。在学习预测奖励的同时，我们还让智能体预测它接下来会看到什么。为了同时完成这两项任务，智能体被迫构建一个更丰富、更通用的环境内部表示。它不仅学习通往目标的路径，还学习了整个区域的地图。这个过程，通常被称为[自监督学习](@entry_id:173394)，正使智能体能够更有效地学习，通过简单地尝试理解自己的感官体验来构建稳健的特征。

### 指导机器：物理学与数据的协同作用

这是否意味着科学家的直觉现在已经过时了？远非如此。最激动人心的前沿是人类知识与机器学习相遇的地方。我们可以利用我们对世界的理解为学习过程提供护栏，确保机器的发现尊重基本定律。

物理学中最强大的指导原则之一是*不变性*。物理定律不依赖于观察者的视角。描述材料如何变形的本构律必须是客观的；它不能依赖于你选择用来书写它的[坐标系](@entry_id:156346)。如果材料具有内部对称性——例如，如果它是由[纤维增强](@entry_id:194439)的[复合材料](@entry_id:139856)，所有纤维都指向一个方向——那么该定律也必须尊重这种对称性。

我们可以利用这些原则自己来构建特征，而不是将原始数据扔给机器并期望得到最好的结果 [@problem_id:2656081]。对于纤维材料，[连续介质力学](@entry_id:155125)的数学告诉我们，任何有效的材料定律都可以表示为五个特定标量（或称“[不变量](@entry_id:148850)”）的函数。这五个数字（$I_1, \dots, I_5$）构成一个完整的、基于物理学的特征集。通过将这些[不变量](@entry_id:148850)输入我们的机器学习模型，我们保证其预测将自动是客观的，并与材料的对称性一致。这是第一性原理理论与数据驱动灵活性的完美结合，一个站在 Cauchy 和 Green 等巨人肩膀上、同时从数据中学习的模型。

物理原则和数据驱动方法之间的这种深度相互作用出现在最意想不到的地方。考虑一下像大型强子对撞机这样的粒子加速器中发生的剧烈碰撞。物理学家们试图从产生的粒子碎片（或称“喷注”）中重建原始事件。这个喷注被软的、大角度的辐射所污染——这些噪声掩盖了核心的硬散射信号。为了清理它，他们使用像 SoftDrop 这样的“修饰”（grooming）程序。

这里可以做一个惊人的类比。修饰一个喷注就像修剪一个[神经网](@entry_id:276355)络 [@problem_id:3519310]。SoftDrop 会移除远离喷注核心的低能量粒子。这在概念上类似于深度学习中的 $L_1$ 正则化或[幅度剪枝](@entry_id:751650)，后者鼓励或强制不重要连接的权重变为零。在这两种情况下，我们都在移除低信号的贡献以简化模型并增加其鲁棒性。

但这个类比还可以更深入。[粒子物理学](@entry_id:145253)中任何合理的可观测量的一个关键要求是它必须是“红外和共线（IRC）安全的”。这意味着如果一个无限软的粒子被添加到系统中，或者如果一个粒子分裂成两个完全共线的粒子，该[可观测量](@entry_id:267133)不应改变。这是一个稳定性原则。SoftDrop 被明确设计用来保持修饰后喷注可观测量的 IRC 安全性。修剪一个[神经网](@entry_id:276355)络没有这样内置的物理保证。但是，[神经网](@entry_id:276355)络中与 IRC 安全性类似的概念会是什么样的呢？这将意味着网络的输出应该对添加零范数特征不敏感，也应该对将一个特征分裂成多个部分但其总和与原始特征相等不敏感 [@problem_id:3519310]。标准网络不具备这个属性，但提出这个问题促使我们思考设计新的、具备这种属性的架构——一种不仅强大，而且在物理学家会认可和信任的意义上具有根本鲁棒性的人工智能。

### 一种新的科学研究方式

从药物发现和计算流体力学，到力学和[粒子物理学](@entry_id:145253)的基本定律，特征学习正成为一个不可或缺的工具。它使我们能够构建更强大、更高效、更具洞察力的模型。然而，正如我们所见，这不是一个盲目的、自动化的过程。在每个阶段，人类的创造力都发挥着作用：在设计能够实现学习的架构时，在制定指导学习的辅助任务时，以及在嵌入约束学习的[基本对称性](@entry_id:161256)时。

而且，就像在任何科学事业中一样，严谨性至关重要。如果一个复杂的模型训练或验证不当，那它就是无用的。整个[预处理](@entry_id:141204)、[特征提取](@entry_id:164394)和建模过程必须封装在一个单一的、可复现的流程中，并经过仔细验证，以防止任何信息从测试集“泄漏”到训练过程中 [@problem_id:3711419]。这是一个微妙但至关重要的点。科学过程的完整性要求信息的守恒，确保我们对模型性能的评估是诚实和无偏的。

观察的艺术正在被改变。我们正在建造不仅能计算，而且能学会感知的机器。通过将数据的原始、未经修饰的力量与科学的深刻、有原则的理解相结合，我们正在创造一种向宇宙提问的新方式，并找到那些真正重要的特征。