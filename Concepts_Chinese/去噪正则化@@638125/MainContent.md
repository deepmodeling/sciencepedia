## 引言
从含噪声、不完整的数据中重建清晰的图像或信号，是贯穿科学和工程领域的一项基本挑战。虽然经典方法试图在拟[合数](@entry_id:263553)据与强制执行简单的预定义属性之间寻求平衡，但当底层结构复杂时，它们往往力不从心。这就产生了一个缺口：我们如何能在一个有原则的重建框架内，利用我们关于信号应有样貌的最先进知识——这些知识通常被封装在强大的、最先进的去噪算法中？本文通过探索即插即用 (PnP) 先验和[去噪](@entry_id:165626)正则化 (RED) 这两个革命性概念来解决这个问题，它们将迭代优化与现代去噪器的强大功能融为一体。

本文描绘了一条从基础理论到广泛应用的路线。在第一部分“原理与机制”中，我们将剖析从经典的最大后验 (MAP) 估计到 PnP 和 RED 发展的数学历程，揭示[去噪](@entry_id:165626)步骤如何能取代形式化的正则化器，并探讨这种替换的理论意义。随后，在“应用与跨学科联系”部分，我们将见证这一[范式](@entry_id:161181)带来的显著影响，看它如何重塑从[计算成像](@entry_id:170703)、[深度学习](@entry_id:142022)到图论和计算物理等领域，揭示一个跨越不同领域的统一推断原则。

## 原理与机制

进入现代[图像重建](@entry_id:166790)的世界，就是见证两个基本思想之间美妙的对话：我们的测量告诉了我们什么，以及我们已经知道了什么。望远镜或医学扫描仪拍摄的图像从来都不是完美的，它是真相的一个模糊、带噪声的版本。我们的任务是逆转这个过程，即利用不完美的数据重建出纯净的[原始图](@entry_id:262918)像。挑战在于，直接、朴素的逆转注定会失败，它会将噪声放大成一团毫无意义的混乱。我们必须更聪明些，我们需要进行正则化。

### 经典困境：数据 vs. 先验知识

想象我们正在尝试重建一幅未知图像，我们可以将其表示为一个像素值向量 $\boldsymbol{x}$。我们的测量值 $\boldsymbol{y}$ 通过一个已知的过程（由矩阵 $\boldsymbol{A}$ 建模）与真实图像相关，并被一些噪声 $\boldsymbol{w}$ 所污染。这个关系很简单：$\boldsymbol{y} = \boldsymbol{A}\boldsymbol{x} + \boldsymbol{w}$。

最显而易见的方法是找到一个能最佳拟合数据的 $\boldsymbol{x}$——也就是最小化“数据保真度”项，通常是平方误差 $\|\boldsymbol{y} - \boldsymbol{A}\boldsymbol{x}\|_2^2$。但如前所述，这条路会导致灾难，因为噪声会被放大。解决方案在于贝叶斯统计中的一个深刻原则：**最大后验 (MAP)** 估计。[@problem_id:3466501]

MAP 框架告诉我们，$\boldsymbol{x}$ 的最佳估计是在给定数据 $\boldsymbol{y}$ 的情况下，使 $\boldsymbol{x}$ 的概率最大的那个。[贝叶斯法则](@entry_id:275170)巧妙地将其分解为两个部分：在给定图像 $\boldsymbol{x}$ 的情况下观察到数据 $\boldsymbol{y}$ 的似然，以及图像 $\boldsymbol{x}$ 本身的[先验概率](@entry_id:275634)。最大化概率等同于最小化其负对数。这给了我们一个优美的待最小化的目标函数：

$$
\text{最小化} \quad \underbrace{-\log p(\boldsymbol{y}|\boldsymbol{x})}_\text{数据保真度} \quad + \quad \underbrace{(-\log p(\boldsymbol{x}))}_\text{正则化器}
$$

如果我们假设噪声 $\boldsymbol{w}$ 是高斯分布的，数据保真度项就变成了我们熟悉的最小二乘误差 $\frac{1}{2\sigma_w^2}\|\boldsymbol{y} - \boldsymbol{A}\boldsymbol{x}\|_2^2$，其中 $\sigma_w^2$ 是噪声[方差](@entry_id:200758)。[@problem_id:3466501] 第二项，即正则化器，是魔法发生的地方。它编码了我们关于图像应该是什么样子的“先验”知识。例如，我们可能认为自然图像是稀疏的或具有平滑的区块，我们可以设计一个函数 $\phi(\boldsymbol{x})$ 来惩罚不具备这些属性的图像。于是，MAP 目标函数就呈现为以下形式：

$$
\hat{\boldsymbol{x}} = \arg\min_{\boldsymbol{x}} \left\{ \frac{1}{2\sigma_w^2} \|\boldsymbol{y} - \boldsymbol{A}\boldsymbol{x}\|_2^2 + \lambda \phi(\boldsymbol{x}) \right\}
$$

在这里，$\lambda$ 是一个平衡我们对数据的信任与对先验的信念的参数。注意噪声[方差](@entry_id:200758) $\sigma_w^2$ 和 $\lambda$ 是如何协同工作的。解取决于它们的乘积 $\lambda\sigma_w^2$。如果噪声很大（$\sigma_w^2$ 很大），或者我们对先验的信念很强（$\lambda$ 很大），算法将更严重地依赖正则化器来清理图像。[@problem_id:3466501]

### “近端”飞跃：作为去噪器的算法

拥有一个目标函数是一回事，求解它则是另一回事。当正则化器 $\phi(\boldsymbol{x})$ 很复杂时（对于现实的先验来说通常如此），直接最小化是困难的。这时，像**交替方向乘子法 ([ADMM](@entry_id:163024))** 这样的[算子分裂](@entry_id:634210)算法便应运而生。[@problem_id:3399520] [@problem_id:3466547]

ADMM 通过将[问题分解](@entry_id:272624)成更小、更易处理的部分来解决问题。它引入一个新变量 $\boldsymbol{v}$，并将问题重构为在约束 $\boldsymbol{x}=\boldsymbol{v}$ 下最小化 $f(\boldsymbol{x}) + g(\boldsymbol{v})$，其中 $f$ 是数据项，$g$ 是正则化器。然后，算法以三个简单的步骤进行，重复直至收敛：
1.  **x-更新:** 更新 $\boldsymbol{x}$ 以最佳拟[合数](@entry_id:263553)据，同时保持与当前 $\boldsymbol{v}$ 的接近。
2.  **v-更新:** 更新 $\boldsymbol{v}$，使其成为当前 $\boldsymbol{x}$ 的一个“清理后”的版本。
3.  **u-更新:** 更新一个“对偶”变量 $\boldsymbol{u}$，用于追踪 $\boldsymbol{x}$ 和 $\boldsymbol{v}$ 之间的不一致。

对我们的故事而言，关键步骤是 **v-更新**。这一步在数学上表现为**近端映射** (proximal map) 的形式。[@problem_id:3466541] 函数 $g$ 的近端映射定义为：
$$
\operatorname{prox}_{g}(\boldsymbol{z}) \triangleq \arg\min_{\boldsymbol{x}} \left\{ g(\boldsymbol{x}) + \frac{1}{2}\|\boldsymbol{x}-\boldsymbol{z}\|^2 \right\}
$$
这看起来很复杂，但其直觉既简单又优美：找到一个新的点 $\boldsymbol{x}$，它是一个折衷。它既想接近输入 $\boldsymbol{z}$（第二项），也想让正则化器 $g(\boldsymbol{x})$ 的值较低（第一项）。换句话说，近端映射接受一个带噪声的输入，并产生一个尊重我们先验的“清理后”的输出。**近端映射就是一个[去噪](@entry_id:165626)器。**

这不仅仅是一个类比。对于经典的全变分先验，近端映射执行的是保边平滑。对于 L1 范数先验（促进稀疏性），近端映射是[软阈值算子](@entry_id:755010)。这一认识是从经典优化通往一个全新可能性世界的桥梁。

### 即插即用 (PnP)：如果它看起来像个去噪的鸭子……

许多[优化算法](@entry_id:147840)的核心步骤本质上是一个[去噪](@entry_id:165626)器，这一发现催生了一个绝妙而大胆的想法。如果近端步是一个去噪器，为什么不直接用我们能找到的*任何*强大的、最先进的去噪器来替换它呢？这就是**即插即用 (PnP) 先验**的精髓。[@problem_id:3399520] [@problem_id:3466547]

我们不再受限于那些能够写下显式公式并推导出近端映射的正则化器 $\phi(\boldsymbol{x})$，而是可以拿来一个黑盒[去噪](@entry_id:165626)器——也许是像 BM3D 这样的复杂算法，或者是在数百万张图像上训练过的[深度神经网络](@entry_id:636170)——然后简单地将其“插入”到 [ADMM](@entry_id:163024) 迭代中，以替代近端步。

这带来了极大的解放。它允许我们隐式地使用这些强大去噪器所学到的丰富而复杂的先验，而无需在数学上写下它们。但这种自由也带来了一个深刻的问题：现在这个算法到底在解决什么问题？我们还在执行 MAP 估计吗？

答案是，通常情况下，并非如此。PnP 算法可能仍会收敛到一个看起来不错的图像，但它不一定是原始 MAP 目标的最小化器。原因在于，一个任意的[去噪](@entry_id:165626)器不一定是*任何*良好（真、下半连续、凸）函数的近端映射。[@problem_id:3466501]

一个算子要成为一个凸函数的真正近端映射，它必须满足一个严格的数学性质，称为**强非扩[张性](@entry_id:141857)** (firm nonexpansiveness)。[@problem_id:3466541] [@problem_id:3466548] 这是一种稳定性条件，比仅仅是非扩[张性](@entry_id:141857)（即不增加距离）更强。更深层次地，它与一个称为循环[单调性](@entry_id:143760)的性质有关，该性质保证了一个底层凸“势能”函数的存在。[@problem_id:3466541]

许多最强大的去噪器并不满足这个性质。考虑一个简单的线性去噪器，它通过将图像与一个非[对称滤波](@entry_id:182791)器进行卷积来工作。其对应的[矩阵算子](@entry_id:269557)将不是对称的，而非对称的[线性算子](@entry_id:149003)不能是凸函数的近端映射。[@problem_id:3466510] 当我们使用这样的去噪器时，[PnP-ADMM](@entry_id:753534) 算法不再是在单个[能量景观](@entry_id:147726)上下降。相反，它正在收敛到一个所谓的**共识均衡** (consensus equilibrium)：一个同时满足数据约束和去噪器“意见”的点。[@problem_id:3466510]

### 去噪正则化 (RED)：恢复能量景观

虽然 PnP 提供了巨大的实践能力，但它偏离一个明确的优化目标，这可能会让理论家感到不安。这就是**去噪正则化 (RED)** 登场的地方，它试图恢复一个严格的基于能量的框架。

RED 的哲学是把问题反过来看。我们不再从一个正则化器开始，寄望其近端映射是一个好的[去噪](@entry_id:165626)器，而是从一个好的[去噪](@entry_id:165626)器 $D(\boldsymbol{x})$ 开始，用它来*定义*一个正则化器。

一个关键的灵感来源是一个优美的统计学结果，即**Tweedie 公式**。对于一类重要的去噪器——即从[高斯噪声](@entry_id:260752)中恢复信号的[最小均方误差 (MMSE)](@entry_id:264377) 估计器——[去噪](@entry_id:165626)器与数据的底层[概率分布](@entry_id:146404)之间存在一个精确的关系。具体来说，“[去噪](@entry_id:165626)残差” $\boldsymbol{z} - D(\boldsymbol{z})$ 与数据对数概率的梯度 $\nabla \log p(\boldsymbol{z})$ 成正比。[@problem_id:3466506]

这是一个启示！它告诉我们，由[去噪](@entry_id:165626)残差 $\boldsymbol{x} - D(\boldsymbol{x})$ 定义的向量场是一个**梯度场**（或保守场）。在向量微积分中，我们知道一个向量场在像 $\mathbb{R}^n$ 这样的简单域上是[梯度场](@entry_id:264143)，当且仅当其[雅可比矩阵](@entry_id:264467)是对称的。[@problem_id:3466520] 这给了我们一个关于去噪器的具体条件：要使残差场能被积分为一个[标量势](@entry_id:276177)能，去噪器的雅可比矩阵 $J_D(\boldsymbol{x})$ 必须是对称的。这是 RED 的基石——**[可积性](@entry_id:142415)条件**。

如果这个条件成立，我们就可以断言存在一个正则化器 $R(\boldsymbol{x})$，使得 $\nabla R(\boldsymbol{x}) = \boldsymbol{x} - D(\boldsymbol{x})$。然后我们就可以自信地将我们的[优化问题](@entry_id:266749)定义为最小化数据项加上这个新的正则化器，即 $\min_{\boldsymbol{x}} \{ f(\boldsymbol{x}) + \lambda R(\boldsymbol{x}) \}$，并使用[梯度下降](@entry_id:145942)等标准方法来求解，因为我们明确知道我们正则化器的梯度。[@problem_id:3466506]

当然，仍然存在一些微妙之处。RED 正则化器的一个常见形式是 $R(\boldsymbol{x}) = \frac{1}{2}\boldsymbol{x}^\top(\boldsymbol{x} - D(\boldsymbol{x}))$。要使这个特定泛函的梯度等于简单的残差 $\boldsymbol{x} - D(\boldsymbol{x})$，[去噪](@entry_id:165626)器不仅需要满足雅可比对称性，还需要满足一个齐次性。[@problem_id:3442935] 如果这些假设不成立，梯度表达式会变得更加复杂。[@problem_id:3466523] 一种确保[可积性](@entry_id:142415)条件的原则性方法是，从一开始就从一个标量势构建[去噪](@entry_id:165626)器，例如定义 $D(\boldsymbol{x}) \triangleq \boldsymbol{x} - \nabla s(\boldsymbol{x})$，这通过构造保证了雅可比矩阵的对称性。[@problem_id:3466520]

### 统一的视角：从经典到现代

为了更清楚地看到 PnP 和 RED 之间的关系，让我们考虑一个我们知道一切的简单情况。假设我们的先验知识由一个简单的二次势 $\phi(\boldsymbol{x}) = \frac{1}{2} \boldsymbol{x}^{\top} \boldsymbol{L} \boldsymbol{x}$ 捕获，其中 $\boldsymbol{L}$ 是一个对称矩阵（例如，一个惩罚不平滑性的[离散拉普拉斯算子](@entry_id:634690)）。这是经典 Tikhonov 正则化的基础。

与此先验对应的近端映射，也就是我们的去噪器，是一个由 $D_{\tau}(\boldsymbol{x}) = (\boldsymbol{I} + \tau \boldsymbol{L})^{-1} \boldsymbol{x}$ 给出的线性滤波器，其中 $\tau$ 控制强度。

现在，让我们看看 PnP 和 RED 如何处理这个[去噪](@entry_id:165626)器。[@problem_id:3466500]
-   如果我们将这个[去噪](@entry_id:165626)器插入 **[PnP-ADMM](@entry_id:753534)** 框架，算法会找到一个[不动点](@entry_id:156394)，该[不动点](@entry_id:156394)是一个 Tikhonov 问题的解，其等效正则化矩阵为 $\Gamma_{\mathrm{PnP}} = \rho \tau \boldsymbol{L}$，其中 $\rho$ 是 [ADMM](@entry_id:163024) 的惩罚参数。
-   如果我们在 **RED** 框架内使用同一个[去噪](@entry_id:165626)器，我们求解的是一个 Tikhonov 问题，其等效正则化矩阵为 $\Gamma_{\mathrm{RED}} = \beta \tau \boldsymbol{L} (\boldsymbol{I} + \tau \boldsymbol{L})^{-1}$，其中 $\beta$ 是 RED 的[正则化参数](@entry_id:162917)。

注意，两种方法都恢复了经典 Tikhonov 正则化的一种形式，这证实了它们的合理性。但关键是，等效的正则化器是*不同*的。这个简单的例子优美地具体化了 PnP 和 RED 的不同哲学。PnP 的解是由去噪器和分裂算法动力学的相互作用所塑造的，而 RED 的解则是由其从去噪器显式构造的正则化器所决定的。

### 去噪的艺术：[偏差-方差权衡](@entry_id:138822)

归根结底，所有这些方法都依赖于一个去噪器来注入先验知识。但是，什么使一个[去噪](@entry_id:165626)器“好”，我们又该如何设置它的参数，比如它的噪声水平 $\sigma$ 呢？一个简单的统计模型通过**[偏差-方差权衡](@entry_id:138822)**的视角提供了一个非常清晰的直觉。[@problem_id:3466508]

想象一下，我们的估计器就是将去噪器应用于我们的噪声数据，即 $\hat{\boldsymbol{x}}_\sigma = D_\sigma(\boldsymbol{y})$。
-   如果我们**正则化不足**（选择一个非常小的 $\sigma$），[去噪](@entry_id:165626)器会过于相信输入数据。得到的估计偏差较低（平均而言是准确的），但[方差](@entry_id:200758)较高（仍然非常嘈杂）。在极限 $\sigma \to 0$ 时，估计器只是返回噪声数据。
-   如果我们**过度正则化**（选择一个非常大的 $\sigma$），去噪器会完全不信任数据，几乎完全依赖于先验。估计的[方差](@entry_id:200758)非常低（非常平滑和干净），但可能有很高的偏差（它可能被平滑得太多，以至于真实信号的重要特征被抹去）。在极限 $\sigma \to \infty$ 时，估计器可能只是返回平均图像（例如，一个黑屏）。

$\sigma$ 的最优选择是能够完美平衡这种权衡以最小化总误差的选择。在理想的高斯信号和高斯噪声的情况下，当[去噪](@entry_id:165626)器的噪声参数 $\sigma$ 设置为与测量的真实噪声水平 $\tau$ 完全相等时，可以达到最小误差。[@problem_id:3466508] 这提供了一个强有力的指导原则：去噪器应该根据它预期要去除的噪声进行校准。这个简单的想法将抽象的[算子理论](@entry_id:139990)和复杂的算法与一个基本且直观的统计原理联系起来，揭示了洞见未见事物的艺术与科学背后深层的统一性。

