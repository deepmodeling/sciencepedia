## 引言
人工智能的世界正被日益庞大的神经网络所主导，一些模型甚至包含数万亿个连接。如此巨大的规模释放了惊人的能力，但也提出了一个根本性问题：所有这些复杂性真的都是必需的吗？对效率的追求带来了一项引人入胜的发现，它挑战了我们对[深度学习](@article_id:302462)工作方式的理解。本文将介绍彩票假说，这是一个革命性的思想，它表明网络成功的秘诀不在于其整体规模，而在于隐藏在其中的微小、预先存在的子网络。我们将踏上理解这一概念的旅程，从其核心原理开始。第一部分“原理与机制”将使用我们熟悉的彩票类比，来解析这些“中奖彩票”的数学和概念基础。随后的“应用与跨学科联系”部分将展示这一思想如何改变人工智能模型的优化，并揭示其在生物学和计算机科学等不同领域中令人惊讶的相似之处。

## 原理与机制

既然我们已经接触到了在人工智能这场巨大彩票中“中奖彩票”这一诱人的想法，那就让我们卷起袖子，一探究竟。这一切是如何运作的呢？为了建立我们的理解，我们不会从最复杂的事情开始。相反，我们将从我们都能直观理解的东西开始：一种简单的日常彩票。通过理解支配它的原理，我们会发现自己出乎意料地能够很好地掌握彩票假说背后的深刻思想。

### 彩票的剖析

想象一场慈善抽奖。一个大鼓里装满了彩票，编号从 101 到 250。你买了一张。你中奖的机会有多大？嗯，这取决于你所说的“中奖”是什么意思。也许中奖号码必须是 7 的倍数，或者它的各位数字之和必须是 10。你如何计算你的机会？

这是一个经典的概率问题。首先，你数出所有可能性。鼓里有 $250 - 101 + 1 = 150$ 张彩票。这是我们的**样本空间**——所有可能结果的集合。然后，你数出“有利”的结果。你会数出是 7 的倍数的彩票数量，数出各位数字之和为 10 的彩票数量，并小心不要重复计算任何同时满足两个条件的彩票。这就是容斥原理的核心，一个基本的计数工具 [@problem_id:1396913]。概率就是有利结果数与总结果数的比值。这是一个计数的博弈。

但现实中的彩票很少这么简单。考虑一种国家彩票，从 40 个数字中抽取 6 个不重复的数字。你买了一张有自己 6 个数字的彩票。你恰好匹配中奖号码中 3 个的概率是多少？彩票从 40 个球中抽出 6 个的方式有 $\binom{40}{6}$ 种，这是一个相当大的数字：3,838,380。要找到你恰好匹配 3 个数字的方式数量，你必须在你选的 6 个数字中选择 3 个作为中奖数字（$\binom{6}{3}$），另外 3 个作为未中奖数字，从未中奖的 34 个球中抽取（$\binom{34}{3}$）。实现这种部分中奖的总方式数为 $\binom{6}{3} \binom{34}{3} = 20 \times 5984 = 119,680$。

你恰好匹配 3 个数字的概率就是 $\frac{119,680}{3,838,380}$，可以简化为 $\frac{5984}{191919}$，约等于 3% [@problem_id:1793]。注意数字变得多么天文般巨大。可能性的空间是浩瀚的，要找到一个“中奖”组合，即使是部分中奖的组合，也无异于大海捞针。

那么，买彩票到底是不是个“好”主意？这就引出了**[期望值](@article_id:313620)**这个关键概念。想象一个慈善筹款彩票，售卖 5000 张彩票，每张 5 美元。设有一个 1000 美元的大奖和十个 50 美元的安慰奖。如果你买一张彩票，你的平均净收益是多少？你有 $\frac{1}{5000}$ 的微小机会获得 995 美元的利润，有 $\frac{10}{5000}$ 的稍大机会获得 45 美元的利润，还有 $\frac{4989}{5000}$ 的极大机会损失 5 美元。[期望值](@article_id:313620) $E[X]$ 是每个结果乘以其概率的总和：

$$E[X] = (\$995) \left(\frac{1}{5000}\right) + (\$45) \left(\frac{10}{5000}\right) + (-\$5) \left(\frac{4989}{5000}\right) = -\$4.70$$

平均而言，你每次玩都会预期损失 4.70 美元 [@problem_id:1916095]。那么为什么人们还要玩呢？答案在于**方差**。方差衡量的是结果的分布或风险。对于一个奖金为 $W$、中奖概率为 $p$ 的简单彩票，利润的方差可以表示为一个非常简单的表达式：$\text{Var}(X) = p(1-p)W^2$ [@problem_id:18048]。注意到奖金 $W$ 是平方的！这意味着拥有巨额奖金的彩票具有极大的方差。大多数人只损失一点点，但有一个人会赢得很多。正是这种高方差——这种改变人生的微小可能性——使得这个游戏尽管[期望值](@article_id:313620)为负，却在心理上如此引人入胜。

### 从纸质彩票到[神经通路](@article_id:313535)：宏大的类比

现在，让我们进行一次飞跃。这跟神经网络有什么关系呢？彩票假说提出了一个优美而深刻的类比：

*   一个巨大的、随机初始化的神经网络就像那个装满彩票的大鼓。
*   一张**“彩票”**不是一张纸，而是一个特定的**子网络**——[嵌入](@article_id:311541)在更大网络中的一小组连接（权重）。
*   **“奖金”**不是现金，而是在给定任务（如正确识别图像）上，网络经过训练后获得的高性能。
*   **“抽奖”**就是训练过程本身，通常使用像[随机梯度下降](@article_id:299582)（SGD）这样的[算法](@article_id:331821)。

该假说指出，在这个庞大的潜在[子网](@article_id:316689)络集合中，存在着少数特殊的“中奖彩票”。这些[子网](@article_id:316689)络从它们随机诞生（初始化）的那一刻起，就具有独特的结构，能够有效地学习。如果你能找到一个，你就可以只训练那个稀疏的子网络，并达到与整个、[计算成本](@article_id:308397)高昂的[密集网络](@article_id:638454)一样好，甚至更好的性能。

这是一个惊人的论断。它表明，过[参数化](@article_id:336283)——即拥有的权重远超你表面上所需要的数量——不仅仅是关于蛮力，而是关于创造一个足够丰富的子网络“原始汤”，从中可以诞生一个胜利者。[密集网络](@article_id:638454)不是解决方案；它是包含解决方案的*彩票*。

### 搜寻的原理

我们该如何着手形式化地寻找中奖彩票呢？让我们建立一个简单的数学模型，一个“玩具宇宙”，来理解其中涉及的原理 [@problem_id:3166653]。

想象一个网络包含 $m$ 个潜在的“中奖子网络”，每个子网络需要一组特定的 $r$ 个参数处于激活状态。我们可以将随机剪枝网络的[过程建模](@article_id:362862)为一系列独立的抛硬币：每个参数以概率 $s$（“存活率”或密度）被保留，否则被丢弃。

对于我们候选的[子网](@article_id:316689)络中的任何一个要存活下来，其所有 $r$ 个参数都必须被保留。这个概率是 $s^r$。由于这通常是一个非常小的数，该子网络*未*被找到的概率是 $1 - s^r$。

如果我们假设我们的 $m$ 个候选[子网](@article_id:316689)络是不相交的（它们不共享参数），那么它们的存活事件是独立的。*没有一个*在剪枝中存活下来的概率是 $(1 - s^r)^m$。因此，*至少有一个*存活下来的概率就是一减去这个值：$P(\text{至少有一个存活}) = 1 - (1 - s^r)^m$。

最后，仅仅拥有正确的结构并不能保证胜利。训练过程本身可能是不稳定的。假设*如果*我们找到了一个有效的子网络，它有概率 $a$ 成功训练到高准确率。那么，找到并成功训练一个中奖彩票的总概率是：

$$ \mathbb{P}(\text{中奖彩票}) = a \left[1 - (1 - s^r)^m\right] $$

这个简单的公式极富洞察力。它告诉我们，成功的机会关键取决于网络的密度（$s$）、解的复杂性（$r$）、可能解的数量（$m$）以及我们训练[算法](@article_id:331821)的稳定性（$a$）。它将“搜寻”这个模糊的概念转化为了一个定量的关系。

但是，这个谜题还有另一个关键部分：初始化。LTH 声称，仅仅找到正确的网络结构是不够的；你必须从其*原始*的初始权重开始训练。这引出了**回溯**（rewinding）的概念。你训练完整的网络，通过剪枝找到一个好的子网络，然后将该子网络的权重“回溯”到训练早期某个时间点的值。

但是回溯到哪个点呢？一个引人入胜的模型表明，最终准确率 $A$ 取决于两个因素：经过 $k$ 次训练迭代后的训练进度 $P(k)$，以及网络的剩余容量 $C(s)$，它取决于其稀疏度 $s$。一个合理的模型可能看起来像这样：$A(k, s) = A_{\text{dense}} \cdot P(k) \cdot C(s)$ [@problem_id:3188011]。例如，$P(k)$ 可能是一个饱和函数，如 $1 - e^{-k/\tau}$，而 $C(s)$ 是一个幂律函数，如 $(1-s)^\beta$。为了达到一个目标准确率，比如 $A_{\text{dense}} - \epsilon$，我们可以解出最小的回溯迭代次数 $k^\star$。这种分析常常揭示，最佳的回溯点不是第零次迭代，而是在训练开始后不久，给权重足够的“动量”以走上正确的轨道。

### 是什么让一张彩票“中奖”？揭示其机制

我们已经确定了这些中奖彩票的存在，并且它们的初始状态是关键。但是*为什么*？中奖彩票的初始权重到底有什么特别之处？仅仅是随机运气吗？证据指向了更深层次的东西。

一个主要的假说是关于**符号保留**（sign preservation）。想象一下，对于一个给定的学习问题，存在一个“理想”的最终权重集。学习过程的一个重要部分是确定每个权重应该是正还是负。如果一个中奖彩票的初始随机权重，纯粹出于偶然，其大部分连接已经具有*正确的符号*呢？如果是这样，训练过程就不必浪费时间去翻转符号；它可以完全专注于调整权重的*大小*。

这是一个可检验的想法。在一个使用简单线性模型的受控实验中，可以从相同的初始化开始训练一个密集模型和一个剪枝后的“彩票”。然后我们可以测量两个模型中保持其原始符号的权重比例，我们称之为 $\rho_{\text{dense}}$ 和 $\rho_{\text{ticket}}$。实验常常表明，当中奖彩票达到“中奖”性能时，其符号保留率大于或等于密集模型（$\rho_{\text{ticket}} \ge \rho_{\text{dense}}$）[@problem_id:3188003]。这表明初始符号构成了最终解决方案的一个粗略的、低频的蓝图。中奖彩票不仅仅是一个随机的子网络；它的初始结构已经与问题的解空间景观相对齐。

最后，一个真正的中奖彩票应该不仅仅是一次性的侥幸。它应该代表一条通往解决方案的稳健且稳定的路径。现代神经网络的训练是一个[随机过程](@article_id:333307)，深受数据小批量（minibatch）随机顺序的影响。如果一个子网络真的是“中奖者”，它应该对这种随机性相对不敏感。我们可以通过多次从相同的初始化训练同一个彩票，只改变数据洗牌顺序，并测量最终准确率的方差来检验这一点。一个好的彩票应该表现出低方差。实验表明，这种稳定性也与训练中使用的[批量大小](@article_id:353338)（batch size）有关；更大的批量减少了[梯度估计](@article_id:343928)中的噪声，导致更具确定性的训练和更低的方差，正如人们可能预期的那样 [@problem_id:3188038]。对于全批量更新（其中梯度是在整个数据集上计算的），由于过程完全是确定性的，不同运行间的方差变为零。

所以，我们从一个简单的抽奖活动，一路探索到了人工智能的前沿。这些原理惊人地统一。在这两个世界里，我们都在一个巨大的可能性空间中寻找一种罕见的配置。但与国家彩票不同，神经网络中的中奖彩票似乎并非完全随机。它们是“生来幸运”的[子网](@article_id:316689)络，被赋予了一种初始结构——也许是其权重的符号——使它们特别擅长学习。找到它们不仅仅是为了让我们的模型更小更快；更是为了理解神经网络学习的本质。

