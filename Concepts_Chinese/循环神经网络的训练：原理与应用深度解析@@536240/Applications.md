## 应用与跨学科联系

我们花了一些时间来理解训练[循环神经网络](@article_id:350409)的复杂机制——时间[反向传播](@article_id:302452)的精妙舞蹈，以及[梯度消失](@article_id:642027)和爆炸的险峻悬崖。但一台机器的趣味取决于它能做什么。一个原理的深刻性取决于它能解释的世界。现在，我们将踏上一段远超[算法](@article_id:331821)本身限制的旅程，去看看这个卓越的思想——从历史中学习的能力——如何在人类活动的广阔领域中产生共鸣，从工程、生物学到经济学，甚至混沌理论的研究。我们将发现，训练 RNN 不仅仅是计算机科学家工具箱里的一个孤立技巧；它是一种深刻而统一的原则的回响，自然界和科学界已在多种伪装下运用这一原则。

### 学习系统语言

从本质上讲，RNN 是一种学习理解过程而非静态对象的机器。它学习的是故事，而不仅仅是快照。这种能力使其成为一个无与伦比的工具，用以破译任何随时间演变的系统的“语言”或“语法”。

#### 数字孪生：物理世界中的记忆

想象一个简单的机电执行器，它是机器人或生产线上的一个组件。一个简单的模型可能会假设它的响应仅取决于你当前施加的电压。但如果执行器在使用中发热了呢？它的响应可能会变得迟缓。它的内部“状态”——它的温度——取决于其近期的活动历史。一个没有记忆的简单前馈网络，会永远对这种行为感到惊讶。它试图在不断基于一个它看不见的隐藏变量而变化的点云中画出一条固定的直线。

然而，RNN 非常适合这种情况。它的隐藏状态 $h_t$ 可以学会充当执行器不可观察的内部状态的代理，比如它的温度或累积的应力。通过处理过去的输入序列，RNN 可以学习这个内部状态的动态——它是如何累积和如何消散的。它可以学到，一系列高压输入将导致一个“热”状态，在该状态下响应会有所不同。从本质上讲，RNN 成为了物理设备的“[数字孪生](@article_id:323264)”，不仅捕捉其即时的输入输出行为，还捕捉了塑造其现状的过去记忆 ([@problem_id:1595324])。这一原则可以扩展到工程和控制理论中的无数问题，只要一个系统的行为是其历史的函数。

#### 从文本到意义：符号的语法

“语法”这个概念在人类语言中最为人熟知。一个词的意义取决于它前面的词。RNN 通过逐词处理句子，在其[隐藏状态](@article_id:638657)中建立起上下文的理解。这使得它天然适合于翻译、[情感分析](@article_id:642014)甚至拼写纠错等任务。

考虑拼写[纠错](@article_id:337457)的任务。成功的真正衡量标准不是模型答对了多少个字符，而是“[编辑距离](@article_id:313123)”——修复单词所需的插入、删除或替换的次数。这才是我们真正想要最小化的。然而，计算[编辑距离](@article_id:313123)的标准[算法](@article_id:331821)依赖于在每一步从几个选项中取最小值，这是一个不可微分的操作，因此与[梯度下降法](@article_id:302299)格格不入。

在这里，该领域的独创性大放异彩。我们无法直接对我们关心的目标进行微分，所以我们找到了巧妙的变通方法。一种方法是用一个平滑、可微的近似——“softmin”——来代替硬性的 $\min$ 操作，这使得梯度可以流经整个计算过程，这种技术被称为可微动态规划。另一种完全不同的方法是将问题视为一个[强化学习](@article_id:301586)任务。RNN 生成一个更正后的单词，[编辑距离](@article_id:313123)则作为“奖励”信号。使用像 REINFORCE 这样的[算法](@article_id:331821)，模型学会增加生成[能带](@article_id:306995)来好奖励（低[编辑距离](@article_id:313123)）的序列的概率 ([@problem_id:3231081])。两条路径都通向同一个目标：教会机器根据[期望](@article_id:311378)的、结构化的结果来理解和操作符号。

### 解开生命密码

也许最复杂、最古老的语言是用生命分子写成的：DNA 和蛋白质。在这里，RNN 正在成为生物学家不可或缺的工具，充当计算显微镜，揭示隐藏在浩瀚[序列数据](@article_id:640675)中的模式。

#### 基因组的语法

当一个基因表达时，其 DNA 序列被[转录](@article_id:361745)成 RNA，然后进行“[剪接](@article_id:324995)”，去除不编码的区域（[内含子](@article_id:304790)），并将编码区域（[外显子](@article_id:304908)）拼接在一起。这个[剪接](@article_id:324995)过程由编码在 DNA 序列本身中的复杂“语法”所控制——短基序（motif）发出“在此剪切”（供体位点）或“在此连接”（受体位点）的信号，以及可以增强或沉默[剪接](@article_id:324995)的更远距离的调控序列。

双向 RNN 从两个方向读取 DNA 序列，其设计精妙，非常适合学习这种语法 ([@problem_id:2425651])。它可以学会从周围序列中识别供体和受体位点的统计特征。像 [LSTM](@article_id:640086)s 和 GRUs 这样的架构在这里尤其强大，因为它们的[门控机制](@article_id:312846)允许它们将一个[剪接](@article_id:324995)位点与可能相距数千个[核苷酸](@article_id:339332)的调控元件联系起来——这是一个简单的 RNN 难以学习的[长期依赖](@article_id:642139)关系 ([@problem_id:2425651])。

但我们能相信 RNN 正在学习真正的生物学知识吗？通过使用“归因”方法，我们可以让训练好的模型高亮显示输入序列中对其决策最重要的部分。当这些方法指向已知的[剪接](@article_id:324995)基序时，我们就会更有信心，相信我们的模型不仅仅是一个黑箱，而是一个可解释的科学仪器，它真正地重新发现了一部分生物学语法 ([@problem_id:2425651])。

#### 从序列到科学发现

我们可以更进一步，从仅仅识别模式到提出可检验的科学假说。考虑[蛋白质稳定性](@article_id:297570)的问题。为什么生活在温泉中的生物（嗜热菌）的蛋白质在高温下不会分解，而其他生物的类似蛋白质却会？答案在于它们氨基酸序列的细微差异。

可以在[蛋白质序列](@article_id:364232)及其测得的[热稳定性](@article_id:317879)（$T_m$）数据库上训练 RNN。然而，这里潜伏着一个巨大的危险：[混淆变量](@article_id:351736)。生物体通过进化相互关联。RNN 可能学会的仅仅是识别一个序列“来自嗜热菌”，而不是识别出*导致*热稳定性的特定氨基酸变化。这是混淆相关性与因果关系的经典陷阱。

要建立一个真正科学的模型，我们必须采用更严谨的方法论。我们可以测试[模型泛化](@article_id:353415)到它从未见过的全新物种的能力（留一物种[交叉验证](@article_id:323045)）。我们可以使用归因方法来查看它是否高亮显示了已知形成稳定相互作用的氨基酸位置。最有力的是，我们可以进行*计算机模拟*实验：让模型预测单[点突变](@article_id:336372)的稳定性变化（$\Delta \hat{T}_m$），并将其与真实世界的实验室实验进行比较。如果模型的预测与实验现实高度相关，我们就有力地证明了它已经捕捉到了一些[蛋白质稳定性](@article_id:297570)的因果生物物理学原理 ([@problem_id:2425645])。RNN 从一个单纯的[模式识别](@article_id:300461)器转变为一个假说生成器。

在一个关于涌现结构的最优美展示中，研究人员发现，如果你只训练一个 RNN 在混合的基因组集合上预测下一个[核苷酸](@article_id:339332)，模型的内部[隐藏状态](@article_id:638657)会自发地根据生命的进化树进行组织。为了擅长其简单的局部任务，模型必须隐式地学习物种之间的统计差异。而且因为这些统计差异是通过进化产生的，所学表示的几何结构最终反映了系统发育的几何结构 ([@problem_id:2425725])。在没有任何明确指令的情况下，模型发现了整个生物学中最宏伟的组织原则之一。

### 动力学的统一性：从[神经元](@article_id:324093)到天气

我们这次旅程的最后一站也许是最抽象也是最深刻的。我们将把分析的镜头转回到学习过程本身，并在此过程中发现训练[神经网络](@article_id:305336)与预测天气之间一个惊人的联系。

#### 作为动态系统的学习者

我们用来训练网络的更新规则 $w_{n+1} = w_n - \eta \frac{dE}{dw_n}$ 本身就是一个离散动态系统。下一步的权重 $w$ 是当前步骤权重的函数。我们通常希望这个系统有一个简单、稳定的[不动点](@article_id:304105)，意味着权重收敛到一个好的解。但是，如果我们调高[学习率](@article_id:300654) $\eta$ 这个“旋钮”会发生什么？

就像平稳流动的河流如果水流过强会变得湍急一样，学习过程也可能表现出惊人复杂的行为。对于较小的学习率，权重可能会平滑地稳定在一个最优值。当我们增加[学习率](@article_id:300654)时，训练过程可能不再收敛到单个点，而是开始在两个或多个值之间周期性地[振荡](@article_id:331484)。再进一步增加，这些周期会一次又一次地分裂，直到训练动态变得混沌——[非周期性](@article_id:339566)、不可预测，并对初始权重敏感依赖。通过将[学习率](@article_id:300654)视为一个[分岔参数](@article_id:328437)，我们可以使用[混沌理论](@article_id:302454)的工具来分析训练过程，揭示学习行为本身所蕴含的丰富、隐藏的结构 ([@problem_id:2376564])。

#### [伴随方法](@article_id:362078)的统一力量

这将我们带到了最后的、统一的启示。时间[反向传播算法](@article_id:377031)，这个看似 RNN 特有的[算法](@article_id:331821)，实际上是一个远为通用和强大的数学工具——**[伴随方法](@article_id:362078)**——的一个实例。该方法是[最优控制理论](@article_id:300438)和大规模科学计算的基石。

让我们将 RNN 训练构建为一个最优控制问题：我们想要找到最优参数（$W$），以引导我们的系统状态（$h_t$）沿着一条最小化总成本（$L$）的轨迹运行。网络的动态 $h_{t+1} = f(h_t, x_t, W)$ 作为这个优化的约束条件。当我们使用经典的[拉格朗日乘子法](@article_id:355562)解决这个约束优化问题时，得到的方程恰好就是 BPTT 的方程。BPTT 的反向传播过程，实际上是系统“伴随方程”的数值积分，它计算了轨迹末端的一个小扰动如何影响所有先前的状态。

令人惊讶的是，这种*完全相同的数学结构*也出现在完全不同的领域。考虑天气预报。[气象学](@article_id:327738)家使用庞大的大气计算机模型，将一个状态（温度、压力、风场）随时间向前演化。为了改进他们的预报，他们使用一种称为 4D-Var [数据同化](@article_id:313959)的技术。他们会问：“今天大气初始状态的何种微小变化，能够产生一个与我们过去12小时收集的卫星和气象站观测数据最匹配的预报？”

这是同一个问题！在动态系统（天气模型）的约束下，最小化一个成本函数（与观测数据的失配度）。他们用来解决这个问题的工具就是[伴随方法](@article_id:362078)。用于微调全球天气模型初始状态的[算法](@article_id:331821)和用于在句子上训练 RNN 的[算法](@article_id:331821)，在核心上是同一个东西 ([@problem_id:3101246])。

从平凡到宇宙，从工程到进化，从计算机学习[算法](@article_id:331821)内部的混沌到地球大气的动力学，随时间优化系统的原则始终如一。对循环网络的研究不仅仅是对人造大脑的研究；它是一个窥探变化与结果的普适数学的窗口。