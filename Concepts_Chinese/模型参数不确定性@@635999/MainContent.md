## 引言
建立模型，就是承认我们无法完全把握现实的复杂性。模型是简化的产物，而这种简化之中蕴含着一个关键问题：我们的模型到底错在哪里？不确定性量化科学旨在回答这一问题，它教会模型坦陈自身的无知，从而变得更加可信。本文探讨了理解和利用模型[参数不确定性](@entry_id:264387)这一根本性挑战，旨在将其从一种被视为弱点的认知转变为科学力量与洞见的源泉。

接下来的章节将引导您理解这一变革性的视角。首先，在“原理与机制”一章中，我们将剖析不确定性的两种主要形式——偶然不确定性和[认知不确定性](@entry_id:149866)，并探讨用于度量它们的强大框架和实用工具，从贝叶斯方法到[深度集成](@entry_id:636362)。随后，“应用与跨学科联系”一章将展示这些原理在现实世界中的应用，说明量化疑虑如何推动生物学领域的发现、确保工程学中的安全，以及促进人工智能领域的公平。

## 原理与机制

建立一个世界模型，本质上是一种谦逊的行为。这意味着我们承认，现实以其完整、辉煌的复杂性，超出了我们的掌握能力。模型不是完美的复制品；它是一种概括、一种简化，旨在捕捉现象的本质，同时舍弃大量混杂的细节。在这种简化中，蕴藏着一个深刻问题的种子：“我们的模型错在何处，以及以何种方式出错？”回答这个问题，正是[不确定性量化](@entry_id:138597)的艺术与科学。这是一个教会模型坦陈其无知的过程，并在此过程中，使其成为我们探索自然[世界时](@entry_id:275204)更为可信的向导。

### 疑虑的两个方面：[偶然不确定性与认知不确定性](@entry_id:746346)

想象一下，你正试图预测一片在狂风中从树上飘落的叶子会落在哪个确切的位置。你或许可以建立一个能想到的最复杂的计算机模型，将风速、空气密度和空气动力学定律都考虑在内。然而，你永远无法完美地预测它最终的落点。为什么？因为你的不确定性有两个截然不同的、近乎哲学的来源。

首先，是世界本身固有的混乱。叶片受到微观空气[涡流](@entry_id:271366)的冲击，其自身的飘动改变了路径，这是一场过于复杂和随机、永远无法被完全捕捉的舞蹈。这就是**[偶然不确定性](@entry_id:154011)（aleatoric uncertainty）**，源于拉丁词 *alea*，意为“骰子”。它是宇宙中不可减少的随机性，如同掷骰子，我们可以用概率来描述，但永远无法预测单次事件的结果。在科学建模中，它表现为我们测量中的噪声——测量材料成分的仪器发出的随机噼啪声 [@problem_id:2479744]、[量子蒙特卡洛](@entry_id:144383)模拟中固有的统计波动 [@problem_id:2648582]，或是导致一个生物细胞与其同卵双胞胎行为略有不同的无数未观测因素。这种不确定性是我们所测量系统的属性，而非我们知识的缺陷。即使拥有无限数据，它依然会存在。

其次，是源于我们自身无知的不确定性。我们的天气模型是不完整的。我们只有有限数量的气象站，所以我们对风场的描绘是模糊的。我们用来描述[流体动力学](@entry_id:136788)的方程本身也是近似的。这就是**[认知不确定性](@entry_id:149866)（epistemic uncertainty）**，源于希腊词 *episteme*，意为“知识”。这是一种可减少的不确定性；它反映了知识的缺乏，原则上是可以弥补的。如果我们有更多的数据（更多的气象站）或更好的模型（更精确的方程），我们的认知不确定性就会减小。这就是我们对**模型参数**所具有的不确定性。当我们在有限的数据集上训练模型时，它可能会学到一个完美拟合已知数据点的关系，但对于如何连接这些点之间广阔的、未探索的空间，它仍然是不确定的 [@problem_id:2648582]。这种连接是一条直线？一条平缓的曲线？还是一条剧烈的[振荡](@entry_id:267781)曲线？没有更多的数据，模型根本无从知晓。

值得注意的是，这两种疑虑可以通过数学方法优雅地分离开来。利用[全方差定律](@entry_id:184705)，预测的总不确定性可以被分解。如果我们让模型由一个函数 $f$（带有不确定参数）表示，该函数预测一个结果 $Y$，那么总预测[方差](@entry_id:200758)为：

$$
\mathrm{Var}(Y) = \underbrace{\mathbb{E}[\mathrm{Var}(Y \mid f)]}_{\text{Aleatoric Uncertainty}} + \underbrace{\mathrm{Var}(\mathbb{E}[Y \mid f])}_{\text{Epistemic Uncertainty}}
$$

第一项，即偶然部分，是数据[固有噪声](@entry_id:261197)的平均值，该平均值是在我们模型所有可能的版本上计算得出的。即使我们知道了真实的函数 $f$，这部分仍然存在。第二项，即认知部分，是[模型平均](@entry_id:635177)预测的[方差](@entry_id:200758)。它衡量的是，当我们考虑不同的可能参数值时，模型的答案会发生多大变化。随着我们收集更多数据，知识变得更加确定，这一项就会随之减小 [@problem_id:3568165]。

### 可能性的宇宙：超越“单一最佳”答案

传统的建模方法常常感觉像是在寻求一个单一的最优答案。例如，在重建生命演化树时，像最大似然法这样的方法可能会分析遗传数据，并生成一个“最佳”的树，显示物种之间的关系 [@problem_id:1911272]。这是一种极其强大的技术，但它隐藏了一个更深层次的真相。数据很少只指向一种演化历史；相反，它揭示了一个由各种可能性构成的全景，其中一些[可能性比](@entry_id:170863)其他的更可能发生。

相比之下，贝叶斯方法不仅仅给你那个全景中的最高峰，而是给你整张地图。贝叶斯[系统发育分析](@entry_id:172534)不会生成单一的树，而是产生一个**[后验分布](@entry_id:145605)**：一个包含成千上万个可能树的集合，每个树都附有一个概率。也许 `((A,B),(C,D))` 这棵树出现的概率是 85%，而另一种可能性 `((A,C),(B,D))` 出现的概率是 10% [@problem_id:1911272]。这是对我们知识的一个更为诚实和完整的总结。它不仅告诉我们什么是最有可能的，还量化了其他选项的可能性。

此外，这种不确定性延伸到模型的每一个参数。演化树上一个分支的长度不是以单个数字给出，而是以一个**[可信区间](@entry_id:176433)**的形式呈现，即一个很可能包含真实长度的值域。这种视角的转变是根本性的。目标不再是找到*那个*答案，而是刻画出与我们的数据和先验知识相符的、由所有可能答案构成的整个宇宙。

### 驯服猛兽：量化无知的实用工具

对于简单的模型来说，描绘这个“可能答案的宇宙”是微不足道的，但对于现代科学中使用的复杂庞然大物，如拥有数百万参数的[深度神经网络](@entry_id:636170)，则极其困难。完整的贝叶斯后验分布变成了一个不可思议的、巨大的高维空间。幸运的是，科学家们已经开发出极其巧妙和实用的方法来近似它。

一种强大而直观的方法是**[深度集成](@entry_id:636362)（deep ensemble）**。你不是训练一个模型，而是独立地训练几个——比如说，五个或十个。你给它们不同的随机起始点，或许还以不同的顺序向它们提供数据 [@problem_id:2749052]。因为深度网络的[损失景观](@entry_id:635571)充满了山谷和峡谷，每个网络很可能会落入一个不同的“好”解。当你向这个模型委员会请求预测时，你可以看它们的共识。它们预测的平均值给了你一个稳健的估计。但更重要的是，它们之间的*分歧*——即它们预测的[方差](@entry_id:200758)——直接度量了认知不确定性。如果所有模型都同意，那么它们就很自信。如果它们的意见五花八门，那么这个集成模型就在告诉你它非常不确定，这很可能是因为你提出的场景远离训练数据。

一种更奇特且计算成本更低的技术是**[蒙特卡洛](@entry_id:144354)（MC）dropout** [@problem_id:3500238]。Dropout 最初是为防止[神经网](@entry_id:276355)络变得过于自信而发明的一种方法。在训练期间，它在每一步随机关闭网络中的一部分神经元，迫使网络学习冗余的表示。MC dropout 的绝妙之处在于，在*预测期间*也保持这种随机失活的机制。你不是进行一次预测，而是进行多次，每次都随机“丢弃”一组不同的神经元。每一次[前向传播](@entry_id:193086)都像从一个略有不同、被稀疏化了的网络版本中获得预测。这些预测的集合形成了一个近似的[后验分布](@entry_id:145605)。与[集成方法](@entry_id:635588)一样，这些预测的[方差](@entry_id:200758)提供了对[认知不确定性](@entry_id:149866)的估计 [@problem_id:2749052]。这是一种极其高效的方式来感知模型自身的无知。

这两种方法都可以扩展以捕捉[偶然不确定性](@entry_id:154011)。通过训练模型不仅预测单个值，而是为每个数据点预测均值和[方差](@entry_id:200758)，我们可以显式地对数据中的[固有噪声](@entry_id:261197)进行建模，并将其与通过集成模型的分歧或 dropout 的[方差](@entry_id:200758)捕捉到的认知不确定性清晰地分离开来 [@problem_id:2749052]。

### 最后的边界：当你所有的模型都出错时

到目前为止，我们已经讨论了给定模型*内部*参数的不确定性。但是，如果我们模型本身——它的结构、它的控制方程——就是错误的呢？这是最深层、最具挑战性的不确定性形式，通常被称为**结构不确定性**或**模型形式差异**。

想象一下试图模拟野火的蔓延。你可能有几个相互竞争的理论，每个理论都被编码成一套不同的数学方程：一个模型可能是基于单元的，另一个可能使用“[水平集](@entry_id:751248)”方法，第三个可能有一个更复杂的[子模](@entry_id:148922)型来描述余烬如何被风携带 [@problem_id:2491854]。我们不确定的不仅仅是每个模型内部的参数，还包括首先应该使用哪个模型。像**[贝叶斯模型平均](@entry_id:168960)（BMA）**这样的复杂方法直接解决了这个问题。它不试图挑选一个胜利者，而是运行所有可能的模型并对其预测进行平均，给予那些能更好地解释现有数据的模型更大的权重。最终的预测是所有相互竞争的科学假说的概率性混合。

最谦逊、在智识上最诚实的一步是承认，也许我们所有可用的模型在某种程度上都是错误的。我们可以创建显式考虑这一点的模型。这涉及到在我们的模型中添加一个特殊的**差异项**——一个灵活的、数据驱动的组件（通常是[高斯过程](@entry_id:182192)），其唯一的工作就是学习我们基于物理的方程的系统性误差 [@problem_id:3513334]。该模型实质上学会了预测现象，*并且*预测自己无法完美做到这一点的失败。这是一个学会了自身知识局限性的模型。

### 不确定性的智慧：从疑虑到发现

为什么要费这么大劲呢？因为拥抱不确定性将一个只会输出答案的“黑箱”模型，转变为一个用于真正科学发现的工具。

[认知不确定性](@entry_id:149866)的地图就是一张藏宝图。高不确定性区域直接、定量地指引我们知识最薄弱的地方 [@problem_id:2648582]。它们精确地告诉我们，为了产生最大的影响，我们应该在哪里进行下一次实验或收集更多数据，这一策略被称为**[主动学习](@entry_id:157812)**。

此外，通过分析输出的不确定性如何依赖于输入的不确定性——这一过程称为**[全局敏感性分析](@entry_id:171355)**——我们可以识别出哪些参数是系统行为的真正驱动因素。如果一个参数的 Sobol 指数非常高，这意味着我们对该参数的不确定性是导致我们对结果不确定性的主要原因。这告诉我们需要更精确地测量该参数。相反，如果一个参数的指数接近于零，我们便知道模型对其值是稳健的，或许可以通过忽略它来简化我们的模型 [@problem_id:1436437]。

归根结底，一个没有对其不确定性进行诚实评估的预测，不过是猜测而已。通过教会我们的模型量化自身的疑虑，我们不是在削弱它们，而是在使它们变得无限强大。我们正在赋予它们“知其所不知”的智慧，这是通往真正理解之路上至关重要的第一步。

