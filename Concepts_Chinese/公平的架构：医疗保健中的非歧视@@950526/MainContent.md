## 引言
确保非歧视是现代医疗保健的基石，然而实现这一目标远比简单地承诺平等对待所有患者要复杂得多。真正的公平需要深入理解各种系统、政策乃至算法可能在无意中创造和延续不平等的微妙方式。本文通过构建一个全面的框架来理解和实践非歧视，以应对这一挑战。文章从基础理论入手，逐步深入到现实世界的应用，为创建一个更加公正和公平的医疗保健环境提供指南。

我们的旅程始于第一章“原则与机制”，在这一章中，我们将剖析公平与平等的核心概念，定义歧视的法律形式，并探讨用于揭示隐藏偏见的统计工具。我们会将这些实践机制与赋予其意义的宏大哲学正义理论联系起来。随后，第二章“应用与跨学科联系”将展示这些原则如何在不同情境中应用——从个体患者的诊疗、人工智能驱动的诊断，到国家卫生政策的制定和城市规划。读毕全文，读者将不仅深刻理解*为什么*非歧视至关重要，更将掌握*如何*将其主动构建到医疗保健的架构之中。

## 原则与机制

不妨想象一下，医疗保健中的正义概念就像建造一座桥。一座设计拙劣的桥梁可能看起来笔直且规整，但它可能会在其所处环境的特定压力下坍塌。然而，一座精心设计的桥梁会考虑到它将面临的独特张力和载荷，在需要的地方加入灵活性和加固措施。它的强度并非来自僵化的统一性，而是来自智能的、量身定制的设计。医疗保健中的非歧视原则与此非常相似。它们不是要以完全相同的方式对待每个人，而是要建立一个系统，为每个人提供通往福祉的持久而公平的路径，无论他们的起点如何。

在本章中，我们将从公平的直观基础出发，探索用于构建和维护这座桥梁的精密法律和统计机制。我们将看到，简单的患者护理故事如何揭示深刻的伦理原则，以及这些原则如何被转化为塑造现代医学的规则、测试甚至算法。

### 通往健康的两种路径：平等与公平

让我们从一个简单的故事开始。假设有两个人，都最近被诊断出患有高血压，都需要及时的随访来控制血压。从纸面上看，他们有相同的临床需求；他们都能从医疗服务中获得同等益处。现在，我们来增加一些细节。第一位患者住在诊所附近，有自己的车，工作时间灵活，并且能流利地讲当地语言。第二位患者住得很远，依赖不稳定的公共交通，工作班次不灵活且与诊所的开放时间冲突，并且当地语言的熟练程度有限 [@problem_id:4360872]。

一个建立在严格**平等**原则上的医疗保健系统会为两位患者提供完全相同的标准工作时间内的预约时段。它会以相同的方式对待他们，因为他们的临床需求是相同的。这就是那座“规整划一”的桥。但我们立刻就能看到问题所在：第一位患者可以轻松获得医疗服务，而第二位患者则面临着一条充满障碍的道路。形式上平等的机会导致了结果上的极度不平等。

这时，我们遇到了一个更稳健、更优美的概念：**公平**。公平不是给予每个人相同的东西；它是确保每个人都有公平的机会去实现相似的结果。它承认，我们有时必须以不同的方式对待人们，才能达到公正的结果。在医疗保健领域，这个理念被分为两个精妙的原则：

*   **横向公平**：这是“同等需求同等对待”的原则，但有一个关键的附加条件——它适用于处境相似的个体。在我们的故事中，横向公平的政策将确保所有像第一位患者那样几乎没有就医障碍的患者都得到相似的对待。

*   **纵向公平**：这是一个更具动态性的原则，即“对于不等的需求或处境，给予不等但适当的对待”。为了实现纵向公平，我们的第二位患者需要不同的、量身定制的支持。系统必须“弯曲”以适应他们的处境。这可能意味着提供非正常工作时间的预约、提供交通券，或确保有专业口译员在场。这些不是“特殊优待”，而是为了创造公平竞争环境所必需的调整，确保通往医疗保健的桥梁对所有旅行者都开放，而不仅仅是那些从铺装大路上开始的人 [@problem_id:4360872]。

### 不公的剖析：直接与间接歧视

如果说公平是目标，那么歧视就是破坏它的力量。就像我们桥梁金属中隐藏的裂痕一样，歧视会损害整个医疗保健系统的完整性。在法律和伦理上，它主要有两种形式。

**直接歧视**是最公然、最容易理解的形式。它发生在某人*因其*受保护的特征（如种族、性别、性取向、宗教或残疾）而受到较差待遇时。想象一下，一家生育诊所向已婚异性恋夫妇提供某项服务，但基于关于家庭结构的“良心”信念，拒绝向单身女性或同性伴侣提供完全相同的服务 [@problem_id:4476770]。拒绝的原因不是医疗程序本身，而是请求者的身份。这是一个典型的直接歧视案例。动机，无论是基于良心还是偏见，都不能改变行为的歧视性质。

**间接歧视**则要微妙得多，在许多方面也更为普遍。它是机器中的幽灵。它发生在一项规则或政策被统一应用于每个人，但其*效果*却使特定群体处于不利地位。这项规则表面上是中立的，但其影响却带有偏见。设想一家医院，为了提高效率，决定通过智能手机应用程序来管理所有预约 [@problem_id:4489355] [@problem_id:4489382]。 “所有患者必须使用该应用程序”的规定平等地适用于每个人。然而，谁最有可能被排除在外？可能是那些没有智能手机或不习惯使用该技术的老年患者，或者是无力负担智能手机的低收入个体。数据证实了这一点：在一种情景中，70岁以上患者的预约完成率相比年轻患者急剧下降 [@problem_id:4489382]。

这一区别揭示了法律和伦理思维的一次深刻转变，即从仅仅关注**形式平等**（规则对每个人都一样吗？）转向要求**实质平等**（这些规则是否为每个人带来了公平的结果？）。我们被迫超越政策的意图，去审视其实际效果。

### 医疗保健侦探：揭露隐藏的偏见

那么，我们如何才能探测到这个间接歧视的“幽灵”呢？我们化身为侦探，利用统计学工具在数据中寻找它的踪迹。

第一步是进行简单的比较。如果一个心脏康复项目批准了55%的非移民患者，但只批准了30%的移民患者，我们的警钟就应该敲响 [@problem_id:4489355]。监管机构常用的一个工具是**五分之四规则**（或80%规则）。这是一个简单的筛选测试：如果受保护群体的录用率低于最高录用率群体的80%，这就是一个潜在“差异性影响”的警示信号。在我们的心脏康复例子中，比率是 $\frac{0.30}{0.55} = 0.545$，约为55%，远低于80%的基准 [@problem_id:4491472]。

但任何优秀的科学家都知道，一个简单的经验法则并非故事的全部。数字上的差异可能只是随机偶然，或者是在小样本中的“坏运气”。为了更严谨，我们使用**[统计显著性](@entry_id:147554)检验**。像双比例$z$检验这样的显著性检验会计算出，在假设没有真实潜在差异的情况下，纯粹由偶然因素导致我们观察到如此大差异的概率（即$p$值）。一个非常小的$p$值（通常小于0.05）使我们有信心认为，我们看到的差异是真实的，而不仅仅是统计上的侥幸 [@problem_id:4491472]。

即便如此，仍不足够。也许不同群体之间疾病的潜在发病率或严重程度不同。这是一种合理的可能性。要成为真正的侦探，我们必须尝试将受保护特征（如种族或收入）的影响与合法临床因素的影响分离开来。这时，像**基于回归的控制**这样更复杂的工具就派上用场了。通过建立一个包含疾病严重程度、年龄和其他合并症变量的[统计模型](@entry_id:755400)，我们可以问：“在保持所有这些临床因素不变的情况下，群体之间的结果*仍然*存在差异吗？”[@problem_id:4491472]。一个来自卫生经济学的更专业的工具——**集中指数**，可以精确测量医疗保健使用在富人或穷人中集中的程度，提供一个单一的数字来量化与社会经济相关的医疗不平等 [@problem_id:4371561]。

### 合理化之舞：差异何时合法？

假设我们的统计侦探工作揭示了对某个受保护群体存在显著的、不成比例的负面影响。那么，这家医院或卫生当局是否就自动犯有非法歧视罪呢？答案是否定的。一场引人入胜的法律之舞就此开始。

差异性影响的证据构成了一个所谓的*初步证据*（prima facie）案件——这足以让案件“站得住脚”。此时，举证责任转移到医疗服务提供者身上。他们必须为自己的政策提供**客观理由**。这个理由包括两部分：

1.  **合法目的**：该政策必须服务于一个合法的目的。诸如“提高效率”、“控制成本”或“确保感染控制”等目的通常被认为是合法的 [@problem_id:4489355]。
2.  **相称的手段**：这是关键步骤。提供者必须证明他们选择的方法是实现其目的的*相称*方式。这意味着它必须是适当的、必要的，并且不存在可以合理实现相同目标且歧视性更小的替代方案。

回想一下那个智能手机应用程序。提高效率的目的是合法的。但是，一个仅限应用程序的系统是否相称？完全排除没有智能手机的人真的有必要吗？医院是否可以同时保留一条电话预约线路？因为一个歧视性更小的替代方案显而易见，所以仅限应用程序的规则很可能无法通过相称性测试，并被视为非法的间接歧视 [@problem_id:4489382]。

### 为公平而变通：便利的义务

这让我们回到了纵向公平的理念。如果一个“一刀切”的规则造成了不公平的障碍，解决方案并不总是废除该规则，而是去调整它。这就是**合理便利的义务**的精髓。这是一项法律和伦理上的要求，即进行个性化调整，以确保个人能够安全有效地获得医疗服务。

考虑一家为了省钱而实行“无口译员”统一政策的医院。当一名失聪女性前来接受紧急手术时，这项政策剥夺了她理解医生、提出问题和给予知情同意的能力。她所获得的医疗服务在根本上是无法获取且不安全的。提供一名合格的手语翻译作为一项合理便利——这并非特殊优待；而是为她提供符合法律和伦理标准的可接受医疗服务所必需的 [@problem_id:4489391]。

同样，一条标准的“术前禁食”规则对于患有胰岛素依赖型糖尿病的患者来说可能是危险的。合理的便利是一种经过临床验证的、调整过的禁食方案。这是为了确保患者安全而对标准规则进行的必要偏离 [@problem_id:4489391]。

这项义务并非绝对。它受到**不当负担**概念的限制。如果一项便利措施会给提供者带来不合理的成本或行政困难，则无需提供。然而，这个门槛非常高。以“行政方便”或“普遍预算短缺”为由很少能成为成功的辩护。负担必须是真正不成比例的。基于患者安全的理由，如严格的感染控制政策，会得到更严肃的对待，但即便如此，它也必须是相称的。例如，医院必须证明全面禁止探视是必要的，并且没有限制性更小的措施（如在佩戴个人防护设备的情况下进行有监督的探视）可以替代 [@problem_id:4489391]。

### 宏大的正义理论：我们为何关心

这些实际的规则和机制并非凭空产生。它们是关于正义本质的深层哲学思潮在表层的体现。当我们辩论是优先考虑效率还是公平时，我们实际上是在参与一场已经困扰了哲学家几个世纪的对话。不同的伦理框架为我们看待这些问题提供了不同的视角：

*   **功利主义**：这一框架与 Jeremy Bentham 和 John Stuart Mill 等思想家联系最为紧密，它主张最道德的行为是能为最多数人带来最大利益的行为。在医疗保健领域，这通常转化为在整个人群中最大化**质量调整生命年 (QALYs)** 这样的指标。纯粹的功利主义方法可能会支持一项能产生200个总QALYs的政策，即使这些QALYs分布不均，而不是一项只产生160个QALYs但分配更公平的政策 [@problem_id:4866480]。它关注的是总结果。

*   **义务论**：由 Immanuel Kant 倡导的这一框架关注义务和权利。它认为某些行为本身就是对或错，无论其后果如何。从义务论的角度来看，歧视是错误的，不是因为它导致了坏的结果，而是因为它违反了尊重每个人的基本义务。这个框架会支持执行严格的非歧视规则，即使这样做在最大化总QALYs方面效率较低 [@problem_id:4866480]。

*   **罗尔斯式正义**：哲学家 John Rawls 提出了一个强有力的思想实验：在一个**无知之幕**背后设计你理想的社会，在那里你不知道自己会是富是贫、是健康还是生病、是属于多数群体还是少数群体。Rawls 认为，从这个位置出发，理性的人会选择一个能保护最脆弱者的系统。这导向了**[最大最小原则](@entry_id:272690)**：我们应该致力于最大化社会中处境最差者的福祉 [@problem_id:4417382]。一个罗尔斯主义者会偏爱那个产生160个总QALYs但提高了最弱势群体底线的政策 [@problem_id:4866480]。

*   **可行能力方法**：由 Amartya Sen 和 Martha Nussbaum 发展，这种方法认为，正义不仅仅关乎资源甚至幸福，而关乎人们实质上能够成为什么和做什么。它追问人们是否拥有真实、实际的**可行能力**——即过上繁荣生活的自由。在医疗保健领域，这意味着要超越临床诊疗本身，去审视那些阻碍人们获得良好健康的结构性障碍：缺乏交通、教育或安全住房。这个框架鼓励我们去解决不平等的根源问题 [@problem_id:4866480]。

### 算法前沿：公平的硬核数学

如今，这些历经数百年的辩论正被写入人工智能的代码中。临床算法现在帮助决定谁能获得专家转诊，或者谁有再入院的高风险。这带来了巨大的力量，但也给非歧视带来了新的、复杂的挑战。

在人工智能的世界里，不同伦理目标之间的张力在数学上变得精确。我们可以定义**群体公平**，它要求像错误率这样的统计指标在不同的人口统计群体中是相等的。例如，**[机会均等](@entry_id:637428)**标准要求风险预测工具的真阳性率和[假阳性率](@entry_id:636147)对于（比如说）黑人患者和白人患者是相同的 [@problem_id:4562348]。

我们也可以定义**个体公平**，它指出任何两个临床上相似的个体应该得到相似的预测。这通过要求算法相对于一个精心选择的临床相似性度量是“利普希茨连续”的来形式化——这意味着临床相关特征的微小变化只能导致风险评分的微小变化 [@problem_id:4562348]。

在这里，我们遇到了一个优美而又恼人的结果，这是算法公平性核心的“不可能定理”之一。在一个疾病的潜在流行率（“基础率”）在两个群体之间不同的世界里，一个风险预测模型在数学上不可能同时满足[机会均等](@entry_id:637428)和另一个关键的公平标准——预测均等（即相等的阳性预测值），除非是在一些微不足道的情况下 [@problem_id:4562348]。

这不是一个政治声明，而是一个数学事实。你无法用单一算法确保所有群体的错误率都相同，*并且*一个阳性预测对每个群体都意味着同样的事情。这迫使我们进行一场艰难但必要的对话。我们优先考虑哪种公平？算法无法给我们一个唯一的“正确”答案。公平的硬核数学揭示了，这些是我们作为一个社会必须共同做出的选择，将我们的价值观嵌入我们构建的工具中。追求非歧视不是一个可以一劳永逸解决的问题，而是一个在正义原则和对人类尊严的深刻尊重指引下，不断权衡这些根本性取舍的过程。

