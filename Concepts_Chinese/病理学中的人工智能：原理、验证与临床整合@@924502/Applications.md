## 应用与跨学科联系

我们教会了机器如何观察。我们赋予了它病理学家的训练有素的眼睛，能够在细胞的织锦中发现疾病的微妙特征。但这并非我们故事的终点，而恰恰是起点。真正的探险不在于“看”，而在于“做”。当这种新的智能形式被编织进医学的肌理中时，会发生什么？答案是一段将我们从显微镜带到医院董事会，从人类心理学的复杂性带到政府殿堂的旅程，揭示出意想不到的联系，照亮科学、医学和我们自身的本质。

### 从像素到[精准医疗](@entry_id:152668)

几个世纪以来，病理学一直是一门描述的艺术，一门基于病理学家丰富经验进行定性判断的学科。但如果我们能将其转变为一门*测量*的艺术呢？这是人工智能的第一个，也许也是最深刻的应用：作为一个不知疲倦且极其精确的定量工具。

思考一下现代利用免疫疗法抗击癌症的斗争，这是一种释放人体自身免疫系统对抗肿瘤的革命性疗法。是否使用这些强效药物的决定，通常取决于一个数字——联合阳性评分（CPS），它衡量一种名为PD-L1的蛋白质的丰度。手动计算成千上万的肿瘤细胞和免疫细胞来得出这个分数是一项艰巨的任务，且容易产生变异。在这里，人工智能不仅介入以自动化计数，更是提升了计数的水平。它可以被训练来识别和清点不同类型的细胞，但更重要的是，它可以学会考虑自身的不足之处。如果一个AI模型知道其检测器对某种细胞类型的敏感度为，比如说，$0.90$，它就可以在数学上校正自己的原始计数，以提供一个更准确的最终分数。它可以被教会识别并丢弃由数字分割错误引起的重复计数，确保每个细胞只被计算一次。这将像CPS这样的生物标志物的计算从一个费力的估计，转变为一个可重复、有质量控制的测量，推动我们更接近真正的精准医疗 [@problem_id:4331705]。

这一原则远不止应用于单一的生物标志物。在诊断像[狼疮性肾炎](@entry_id:194138)这样的复杂炎症性疾病时，病理学家使用复杂的评分系统来权衡可治疗的活动性炎症与慢性的、不可逆的瘢痕形成的证据。一份肾活检样本可能会根据六个特征进行分级，从“毛细血管内增生”到“[纤维素](@entry_id:144913)样坏死”，每个特征都有特定的权重。最终的活动指数（AI）和慢性指数（CI）直接指导一个关键的临床决策：是否部署积极的[免疫抑制](@entry_id:190778)治疗。一个人工智能助手可以以完美的-致性应用这些复杂的规则，提供一个标准化的分数，帮助医生在治疗活动性疾病和避免在仅剩永久性瘢痕时使用毒性疗法之间做出关键的权衡 [@problem_id:4901627]。通过这种方式，人工智能扮演了一个完美的学徒角色，掌握了病理学的复杂规则，以提供塑造患者未来的定量见解。

### 人机合作：一种新型团队

这就把我们带到了一个关键点：病理学中人工智能的目标不是创造一个孤独、自主的神谕，而是打造一种新型的人机团队。和任何团队一样，其有效性必须得到证明。一个人工智能模型仅仅在实验室环境中准确是不够的；它必须在真实临床工作流程的混乱中证明其价值。

我们如何衡量这一点？我们可以求助于临床试验的严谨方法。想象一项研究，经验丰富的病理学家被要求诊断一组病例，一次在没有人工智能辅助的情况下，一次在有辅助的情况下。通过使用巧妙的“交叉”设计，让每位病理学家作为自己的[对照组](@entry_id:188599)，并加入一个“洗脱期”以防止他们仅仅记住病例，我们可以精确测量人工智能工具的影响。它是否减少了做出诊断的平均时间？它是否提高了准确性？只有通过统计确定性来回答这些问题，我们才能真正知道我们的新队友是否尽职尽责 [@problem_id:4316724]。

但当队友们意见不合时会发生什么？假设人类病理学家说活检是良性的，但人工智能却将其标记为恶性。谁是对的？将每一个[分歧](@entry_id:193119)都送交另一位专家进行仲裁既昂贵又缓慢。在这里，一种更深入、更数学化的方法揭示了一个更优雅的解决方案。我们可以基于决策理论的原则构建一个智能工作流程。我们知道人工智能的历史敏感性和特异性，人类的表现，疾病的患病率，以及至关重要的，不同错误的*成本*——一个漏诊的癌症（假阴性）的成本远高于一次不必要的检查（[假阳性](@entry_id:635878)）。利用贝叶斯定理，我们可以计算出在每种特定类型的[分歧](@entry_id:193119)下，人类出错的后验概率。然后我们可以设定一个理性的策略：只有当*不*复核的预期损失（[错误概率](@entry_id:267618)乘以其成本）超过复核本身的成本时，才触发昂贵的复核。这就创建了一个智能系统，它知道何时一个[分歧](@entry_id:193119)是真正高风险的，值得再次审视，从而优化专家时间和临床资源的使用 [@problem_id:5203872]。

### 解释的危险之美

为了成为好的队友，我们需要沟通。我们要求我们的人工智能伙伴“解释”它们的推理，通常以[热图](@entry_id:273656)或[显著性图](@entry_id:635441)的形式，突出显示图像中对决策影响最大的区域。但这将我们带入了一个微妙且有时充满陷阱的人类心理学领域。

首先，我们必须坚持“[可解释性](@entry_id:637759)”应与任何其他声明一样，遵循相同的科学标准。一张漂亮的图片并非证据。正如一篇科学论文必须细致地记录其方法一样，一份关于[可解释人工智能](@entry_id:168774)的报告必须提供完整的规格说明：数据的来源、用于训练和测试的精确分割策略、用于生成解释的具体算法和超参数，以及——最重要的是——解释质量的量化指标。这个解释是否*忠实于*模型的推理？它是否准确地*定位*了病变？没有这种严谨性，“可解释的人工智能”就只是一个营销术语，而非一门科学 [@problem_id:4330026]。

但这里存在一个更深的悖论。即使是一个完全忠实的解释也可能具有误导性。我们人类容易受到“自动化偏见”的影响——一种过度信任自动化系统输出的倾向，尤其是当它们伴随着一个引人入胜的叙述或一个看似合理的视觉化呈现时。想象一个不正确的人工智能，但它生成了一个恰好突出显示了某个看起来有点可疑区域的[显著性图](@entry_id:635441)。我们可能会被这个“解释”所左右，从而接受人工智能的错误结论。

我们能模拟这种心理陷阱吗？当然可以。我们可以定义在人工智能正确的情况下，一个解释*看起来*忠实的概率（$\alpha$），相对于在人工智能错误的情况下，它看起来忠实的概率（$\beta$）。[似然比](@entry_id:170863) $L = \alpha/\beta$ 告诉我们，当人工智能正确时，一个看起来忠实的解释出现的可能性比它错误时高多少。这是衡量解释的诊断价值的指标。然后我们可以设计一个安全检查：放射科医生只有在他们的信任阈值被满足*并且*解释的[似然比](@entry_id:170863)高于某个最小值时，才应听从人工智能的意见。本质上，该系统发展出一种自我意识；它知道何时自己的解释不具有很强的诊断价值，不应被信任，从而迫使人类专家重新掌控局面。这是概率论和认知科学的美妙结合，通过[数学建模](@entry_id:262517)被误导的风险来设计更安全的合作伙伴关系 [@problem_id:4883782]。

### 从算法到获批医疗产品：信任的考验

研究人员笔记本电脑上的人工智能模型是一种科学上的好奇心。用于诊断患者的人工智能模型则是一种医疗器械，这一区别意义深远。从前者到后者的旅程是一场旨在建立社会信任的流程、验证和监管的严峻考验。

这段旅程始于内部。一家开发医疗人工智能的公司不能像典型的软件初创公司那样运作。它必须建立一个全面的质量管理体系（QMS），遵循像ISO 13485这样的国际标准。流程的每一步都被正式化。软件本身必须在严格的生命周期流程下开发，例如IEC 62304中定义的流程，该流程强制要求正式的需求管理、架构设计、验证以及一个持续的[风险管理](@entry_id:141282)过程（依据ISO 14971），以识别和减轻任何可能导致患者伤害的危害——从[算法偏见](@entry_id:637996)到网络安全威胁 [@problem_id:4326135]。

有了建立在这一质量基础上的产品，公司接下来必须向世界证明其价值。这需要一个严谨的验证计划。仅仅在内部数据集上显示高准确率是不够的。模型必须被锁定，并在来自不同医院、使用不同扫描仪的完全独立的“外部验证”队列上进行测试，以证明其可以泛化。其性能不仅要通过其辨别能力（例如，ROC-AUC）来评估，还要通过其*校准*来评估——模型对其自身的不确定性是否诚实？一个声称“90%确定”的模型应该在90%的情况下是正确的。最后，必须使用像决策曲线分析（DCA）这样的技术来表明，与现有策略相比，使用该模型确实能带来更好的临床结果。整个过程必须由伦理审查委员会（IRB）监督，并遵循像TRIPOD for AI这样的指南进行完全透明的报告 [@problem_-id:4326143]。

只有到那时，开发者才能接触到守门人：像美国食品药品监督管理局（FDA）或其在欧盟的对应机构等监管机构。对于一个没有明确前代产品的新型设备，可能需要一个特殊的途径，比如FDA的De Novo分类。在欧洲，一个用于辅助诊断的人工智能根据欧盟人工智能法案被自动视为“高风险”系统，从而触发严格的要求。将产品推向市场不是终点，而是一个终身承诺的开始，这个承诺包括上市后监督、不良事件报告和真实世界性能监控，有时还要在一个预先批准的未来模型更新计划（预定变更控制计划或PCCP）下进行 [@problem_id:4405492]。

### 跨学科的回响：一个好想法的统一力量

这种新思维方式的影响并不仅限于病理学实验室。它的原则在整个医院乃至整个科学界回响。为了使人工智能的见解有用，它们必须被传达。这需要一种通用的语言，一种健康数据的*通用语*。像HL7 FHIR（快速医疗保健互操作性资源）这样的标准提供了这种语言。它们定义了结构化的资源——比如用于概率分数的`Observation`或用于打包完整摘要的`DiagnosticReport`——使得人工智能的输出能够无缝且可审计地流入电子健康记录，在那里它可以被临床医生使用，被管理者用于计费，并被用于质量改进的跟踪 [@problem_id:5203843]。这将人工智能算法的深奥世界与健康信息学的实践性、广阔的学科联系起来。

也许最美的联系在于，当我们把这些思想回馈给基础生物学时。考虑一下像额颞叶痴呆这样的神经退行性疾病的毁灭性进展。神经病理学家早就观察到，这些疾病似乎以可预测的模式在大脑中扩散。我们可以使用支撑着如此多人工智能的、同样是网络的数学语言来模拟这一点。想象一下大脑是一个由白质束连接的区域网络。我们可以在一个特定区域——行为性痴呆的前脑岛，或与语言相关的痴呆的前颞叶——播下“病理”的种子。然后，我们让它根据图上的一个[简单扩散](@entry_id:145715)方程传播。该模型完美地预测了病理将沿着最强的连接传播得最快，在早期阶段主要局限于功能网络内。在显著性网络中播种会产生行为综合征；在语言网络中播种会产生失语症。模型的预测反映了在患者身上看到的悲惨现实 [@problem_id:4481027]。

这难道不非凡吗？帮助我们构建人工系统以*识别*疾病的同一种网络和信息流的数学语言，也可以用来创建优雅的模型，描述该疾病如何通过大脑错综复杂的网络*传播*。这是一种深刻的回响，暗示着自然模式与智能逻辑之间更深层次的统一。这是人工智能在医学中的最终承诺：不仅是提供答案，更是提供新的思维方式，建立加深我们对世界以及我们在其中位置的理解的联系。