## 应用与跨学科联系

### [曲线拟合](@article_id:304569)的艺术：从刚性规则到灵活描摹

想象你是一位裁缝。一位顾客走进来，你的任务是为他做一套西装。你可以遵循两种基本理念。第一种是拿出一套预制好的样板——小号、中号、大号等等。你从顾客身上量取几个关键尺寸，然后挑选最接近的样板。经过一些微小的调整，你就能非常快速高效地制作出一套西装。这就是**参数**方法。“参数”就是你用来选择和微调标准、成熟样板的那几个测量值。这种方法的威力在于其假设；你假设你的顾客体型或多或少与你样板所依据的理想化人形相似。当这个假设成立时，结果会非常出色。

但如果你的顾客姿势独特，或者一个肩膀比另一个稍高呢？标准样板永远不会完全合身。它会在某些地方紧绷，在另一些地方松垮。这时就轮到第二种理念出场了。你可以将一大块布料披在顾客身上，用粉笔和别针直接在布料上描出他的确切轮廓。你对他的身材比例不做任何假设。你是在让他的身体，即“数据”本身，来说话。这就是**非参数**方法。它非常灵活，能捕捉任何独特的轮廓。但它也有其自身的危险。它需要更多的数据——你需要描摹整个人的轮廓，而不仅仅是量几个尺寸。而且你必须小心，不要把暂时的懒散姿势误认为是他的真实体态，否则你做出的西装虽然完美贴合他懒散时的样子，但在他站直时就会显得不协调。你可能会对噪声“[过拟合](@article_id:299541)”。

这个裁缝的两难处境——在刚性假设的效率和数据驱动的灵活性力量之间做出的选择——正是我们在所有科学领域解读数据的核心。问题不仅仅是“我们如何在一些点之间画一条线？”，而是“在开始画线之前，我们对世界抱有什么信念？”答案具有深远的影响，回响在遗传学、[材料科学](@article_id:312640)和人工智能等不同领域。

### 洞见未见：当自然不遵循直线时

检验一个模型最直接的方法是看它能多好地描述两个量之间的关系。我们的第一直觉，通常是在入门科学课程中被灌输的，是拟合一条直线或一个简单的曲线，比如抛物线。这些都是[参数模型](@article_id:350083)。但当自然的规律更加局部化和奇特时，会发生什么呢？

想象一下，我们正在研究两个因素，称之为 $x_1$ 和 $x_2$，如何影响一个生物过程。我们怀疑它们之间可能存在相互作用，但也许只在特定条件下——比如说，在它们操作范围的某个特定象限内。如果我们试图拟合一个标准的[参数模型](@article_id:350083)，比如包含一个全局 $x_1 x_2$ 交互项的[多项式回归](@article_id:355094)，我们就是在强迫模型假设这种交互作用在任何地方都以同样的方式表现。模型试图将这种局部效应“涂抹”到整个景观上，导致处处拟合不佳。这就像试图通过倾斜整张地图来描述一张上面只有一座山峰的地图——你既没有捕捉到山峰，又把平地弄得歪歪扭扭。一个更好的方法是像[回归树](@article_id:640453)那样的模型。这种[非参数方法](@article_id:332012)不假设一个全局公式。相反，它通过提出一系列简单的问题，如“$x_1$ 是否大于这个值？”和“$x_2$ 是否大于那个值？”，来自适应地划分景观。通过这样做，它可以自然地分离出交互作用发生的特定区域，并将其与空间的其余部分分开建模，从而更忠实地描述现实[@problem_id:3132277]。

当我们在处理实验伪影时，这种对灵活性的需求就更为关键。考虑一位遗传学家使用双色[微阵列](@article_id:334586)来观察某种药物开启或关闭了哪些基因的工作[@problem_id:2805388]。在这些实验中，来自对照样本的遗传物质用绿色染料标记，来自处理样本的则用红色染料标记。两者都被洗到一张有数千个点的载玻片上，每个点代表一个基因。每个点上红色和绿色的相对亮度告诉我们药物如何影响该基因的活性。理想情况下，如果一个基因的活性没有改变，它的点应该是完美的黄色。然而，染料并不总是表现完美。染料的效率可能会根据点的整体亮度而改变。这会产生一种系统性的、依赖于强度的偏差——一种平滑但完全未知的扭曲。没有简单的参数公式可以描述这种扭曲。试图写下一个公式纯属猜测。

在这里，非参数的“素描艺术家”方法是我们的救星。我们可以用一种特殊的方式将[数据可视化](@article_id:302207)，在一个所谓的MA图上，这种扭曲表现为数据中一个弯曲的“香蕉”形状，偏离了我们[期望](@article_id:311378)的直线。然后我们可以使用像局部加权散点平滑（LOWESS）这样的技术来追踪这个香蕉形。LOWESS的工作原理是沿着数据滑动，并在许多小的、局部的窗口中执行微小的、简单的回归。它不做全局假设，这使得它能够灵活地跟随偏差的曲线。一旦我们有了这个扭曲的轨迹，我们就可以简单地将其减去，从而得到一个干净、无偏的、真正反映基因情况的视图。我们使用了一个灵活的非参数工具来移除一个我们事先无法假设其形状的复杂伪影。

### 灵活性的风险：为现实选择一个代理

如果灵活性如此强大，为什么不总是使用[非参数方法](@article_id:332012)呢？裁缝的两难困境提醒我们[过拟合](@article_id:299541)的危险。在计算科学领域，这种危险被凸显出来，我们经常构建“代理模型”来近似极其复杂的[物理模拟](@article_id:304746)[@problem_id:3109396]。

想象一下，我们试图理解一种新材料的热流如何随着我们改变其三种属性而变化。为每一种可能的属性组合在超级计算机上运行完整的模拟，其成本高得令人望而却步。因此，我们为少量精心挑选的点——比如说20个——运行模拟，然后尝试构建一个廉价、快速的[代理模型](@article_id:305860)，以便在这些点之间进行插值。

一种方法是[多项式混沌展开](@article_id:342224)（PCE），这是一种复杂的参数方法，它假设输出可以很好地由多项式的组合来表示。如果我们使用一个有20个多项式项的PCE来拟合我们的20个数据点，我们的参数数量就和数据点完全一样多。结果是一个模型**恰好**穿过我们每一个训练点。训练数据上的误差为零！这听起来很完美，但这是一个陷阱。这个模型变成了那个过分热心的裁缝学徒，他为了迎合顾客的懒散姿势，制作出了一套扭曲的西装。在数据点之间，多项式可能会剧烈[振荡](@article_id:331484)，产生荒谬的预测。它记住了数据，而不是学习了底层的物理规律。这是最极端形式的[过拟合](@article_id:299541)。

与之形成对比的是[高斯过程](@article_id:323592)（GP），一种非参数的贝叶斯方法。GP不假设一个全局的多项式形式。它本质上只假设底层函数是平滑的。它的本质决定了它有一个内置的“[正则化](@article_id:300216)”，会惩罚过度的波动。当用同样的20个点来拟合时，GP很可能不会精确地穿过所有点。它会生成一条它认为最 plausible 的平滑曲线，平衡了对数据的忠实度和对简单性的偏好。它的[训练误差](@article_id:639944)将不为零，但它在新出现的、未见过的数据点上的误差将远低于过拟合的PCE。此外，作为一种贝叶斯方法，GP还会告诉我们它在哪些地方不确定——它的预测会附带[误差棒](@article_id:332312)，这些[误差棒](@article_id:332312)在远离任何训练数据的区域会变得更大。它不仅给出答案，还告诉我们该在多大程度上信任这个答案。在数据有限且“昂贵”的情况下，非参数GP的谨慎灵活性远优于刚性且过于自信的参数PCE。

### 两全其美：强大的伙伴关系

参数化和非参数化之间的区别并不总是一个泾渭分明的选择。现代数据分析中一些最强大的技术来自于两者之间的巧妙合作。

考虑预测一个复杂软件可靠性的挑战。我们想了解它的“崩溃时间”[@problem_id:3186960]。我们多次运行该软件，记录它何时崩溃。这是一个经典的[生存分析](@article_id:314403)问题。我们可以立即跳到一个[参数模型](@article_id:350083)，比如韦伯分布（Weibull distribution），它常被用来模拟失效时间。但我们怎么知道韦伯分布是合适的呢？

一个更稳健的策略是分两步走。首先，我们使用一种[非参数方法](@article_id:332012)，即Nelson-Aalen估计量，来获得一个原始的、无假设的随时间累积崩溃风险的估计。这是我们的“草图”。然后，我们检查这个草图的形状。例如，如果我们将累积风险的对数对时间的对数作图，看到一条直线，这是一个强烈的线索，表明底层过程确实可以很好地被韦伯分布描述。非参数的草图引导我们找到了**正确**的参数模式。现在，我们可以自信地拟合韦伯模型，利用其参数化的力量来获得平滑、稳定的[生存概率](@article_id:298368)估计，并在任何时间点量化一个新的软件补丁如何提高可靠性。

我们在先进的机器学习中也看到了类似的伙伴关系。假设我们想建立一个像[支持向量回归](@article_id:302383)（SVR）这样的模型，用变量 $x$ 来预测数量 $y$。标准的SVR假设“噪声”，或者说误差的典型大小，在任何地方都是恒定的。但如果过程在 $x$ 值较大时比在 $x$ 值较小时噪声大得多呢？这被称为[异方差性](@article_id:296832)。将一个恒定噪声模型强加于这种情况，就像我们的裁缝用同样薄弱的布料制作裤子的膝盖和衣领一样——它不适合当地的条件。一个复杂的解决方案再次涉及一个两阶段过程[@problem_id:3178792]。首先，我们进行初步拟合并分析误差。然后，我们使用一种灵活的[非参数方法](@article_id:332012)，如[核平滑](@article_id:640111)，来估计噪声的**形状**作为 $x$ 的函数。从本质上讲，我们是利用非参数工具来绘制出模型上的局部“应力”。然后我们可以将这些信息反馈到我们的SVR中，告诉它在高噪声区域允许更宽的误差范围（一个更宽的“管道”）。结果是一个混合模型，它结合了参数化SVR的强大功能和通过[非参数方法](@article_id:332012)学到的对噪声的局部自适应敏感性。

### 审判法庭：无假设地比较群体

到目前为止，我们主要关注[曲线拟合](@article_id:304569)。但科学的很大一部分仅仅是问：这两组东西有区别吗？[t检验](@article_id:335931)是用于此目的的[参数化](@article_id:336283)主力工具，但它有一个关键的假设：两组中的数据都来自钟形的诺莫分布。在真实数据复杂而混乱的世界里，这往往是我们不愿做出的一个信仰之跃。

在设计新药时，计算生物学家可能会进行数千次虚拟对接实验，以观察不同分子与目标蛋白的结合情况[@problem_id:2713883]。这会生成“[对接分数](@article_id:377890)”的分布。这些分数是[正态分布](@article_id:297928)的吗？几乎可以肯定不是。为了比较两类分子，使用像[Mann-Whitney U检验](@article_id:349078)这样的[非参数检验](@article_id:355675)要稳健得多。这个检验基本上忽略了实际的分数值，只处理它们的排名。它回答了一个简单而稳健的问题：“第一类分子的得分**是否倾向于**比第二类分子的得分更好？”通过回避关于分布形状的假设，它提供了一个更值得信赖的结论。

在评估和比较不同机器学习模型的性能时，同样的原则也是不可或缺的，这是现代[材料发现](@article_id:319470)中的一项关键任务[@problem_id:2479769]。假设我们有四种不同的[算法](@article_id:331821)来预测新材料的属性，并且我们在十个不同的预测问题上对它们进行了测试。每种[算法](@article_id:331821)都会有一个包含十个误[差分](@article_id:301764)数的列表。我们不能假设这些误[差分](@article_id:301764)数遵循任何理想的分布。因此，我们不比较平均误差，而是做一些更简单、更稳健的事情。在十个问题中的每一个问题上，我们只是简单地将四种[算法](@article_id:331821)从最好（排名1）到最差（排名4）进行排序。现在我们的数据只包含排名。然后我们可以应用一个为排名数据设计的[非参数检验](@article_id:355675)，如Friedman检验，来确定性能是否存在任何整体上统计显著的差异。这使我们能够在不做关于其误差性质的无法检验的假设的情况下，就哪些[算法](@article_id:331821)更优越做出严谨的论断。

### 结构化的理由：当假设就是力量

为了避免我们认为[非参数方法](@article_id:332012)总是答案，认识到一个精心选择的[参数模型](@article_id:350083)的巨大力量是至关重要的，尤其是在处理复杂的、结构化的数据时。

考虑一个前沿的[CRISPR筛选](@article_id:382944)，这是一种用于发现我们DNA不同部分功能的技术[@problem_id:2946925]。一位科学家想要找到调节特定基因 $G$ 的遥远DNA元件，称为增[强子](@article_id:318729)。这个实验很复杂：它在八种不同条件下进行，每种条件有三个重复。一种天真的方法，比如简单地将增强子的活性与基因 $G$ 的表达进行关联，是注定要失败的。它忽略了不同条件之间存在批次效应，重复样本有其自身的变异性，以及[CRISPR](@article_id:304245)工具本身效率各不相同的事实。数据被一张由混杂因素构成的网络纠缠在一起。

这时，一个复杂的[参数模型](@article_id:350083)，如线性混合效应模型，就变得不可或缺了。这不仅仅是一个简单的直线拟合；它是一个复杂的统计机器，旨在反映实验的真实结构。我们可以为每种条件下的基线效应、重复样本间的方差以及其他已知的混杂因素指定参数。通过将这些关于[数据结构](@article_id:325845)的假设构建到我们的模型中，我们可以在统计上将真正的信号——增[强子](@article_id:318729)与其基因之间的关系——从所有混杂的噪声中解开。一个纯粹的[非参数方法](@article_id:332012)会缺乏执行这种精细解剖所需的结构。在这里，[参数模型](@article_id:350083)的“假设”并非盲目猜测，而是对我们关于[实验设计](@article_id:302887)知识的正式编码，而这种知识就是力量。

同样，在对一个其底层机制已知的过程进行建模时，一个基于该知识构建的[参数模型](@article_id:350083)通常更优越。在研究[细菌生长](@article_id:302655)时，一个具有生物学意义的参数（如“迟滞期”和“最大生长速率”）的机理[参数模型](@article_id:350083)，可以提供比一个碰巧能很好拟合数据点的通用非[参数曲线](@article_id:638335)多得多的洞见[@problem_id:2489472]。

### [数据分析](@article_id:309490)师的工具箱

从参数方法到[非参数方法](@article_id:332012)的旅程，不是从一个“错误”的哲学到一个“正确”的哲学的旅程，而是一个扩展个人工具箱的旅程。[参数模型](@article_id:350083)就像扳手，为特定的螺母和螺栓而设计。当你拥有合适的那一把时，它们在力量和精度上是无与伦比的。[非参数模型](@article_id:380459)就像活动扳手；它们更通用，可以处理各种杂活，但可能缺乏一个尺寸完美的扳手的专用抓力。

选择总是一种权衡，取决于我们愿意假设什么和我们能从现有数据中学到什么之间的平衡。最熟练的科学家和数据分析师不是教条主义者；他们精通两种语言。他们懂得何时使用刚性规则来构建强大的、结构化的模型，何时使用灵活的素描来让数据讲述其自己不受约束的故事。而在最具挑战性的问题中，他们能找到巧妙的方法让两者协同工作，达到任何一方单独都无法提供的理解深度。