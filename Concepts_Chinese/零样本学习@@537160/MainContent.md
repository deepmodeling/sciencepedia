## 引言
机器如何能识别它从未见过的事物？传统的机器学习擅长对已训练过的数据进行分类，但当面对一个全新的类别时，它基本上会失败。这一局限性代表了人工智能与人类智能之间的巨大差距，而我们人类通常利用类比和抽象知识来识别新概念。零样本学习（Zero-Shot Learning, ZSL）是一个强大的范式，旨在弥合这一差距，使模型能够从死记硬背转向一种更灵活、更接近人类的推理形式。它解决了将知识泛化到未见类别的关键挑战，这在专业化和快速发展的领域中是一种常见情景。

本文将对零样本学习进行全面探讨。第一章**“原理与机制”**将解析ZSL背后的核心思想，从其通过映射特征空间和语义空间进行类比学习的基本概念，到[大型语言模型](@entry_id:751149)和提示工程的现代应用。随后的**“应用与跨学科联系”**一章将遍览被ZSL改变的各个领域，展示这一概念如何被用于解读人类语言、分析医疗数据、解码基因组以及加速药物发现。

## 原理与机制

想象一下，你给一个孩子看马、驴和骡子的图片，然后告诉他们：“斑马是一种有条纹的马。”即使从未见过斑马，这个孩子现在也能认出它。他们完成了一项惊人的智力壮举：他们泛化到了一个未见的类别。这就是**零样本学习（ZSL）**的核心魔力所在。它不是关于记忆事实，而是关于理解关系；它是关于通过类比进行学习。

### 通过类比学习：意义的几何学

从本质上讲，ZSL是关于两个世界以及连接它们的一座桥梁的故事。第一个世界是原始数据的世界——我们所能“看见”的。对于计算机来说，这可能是一张图像的像素值或一个蛋白质的生物物理测量数据。我们称之为**[特征空间](@entry_id:638014)**（feature space），$\mathcal{X}$。一个对象，比如一个特定的蛋白质，只是这个高维空间中的一个点，一个向量 $\mathbf{x}$。

第二个世界是意义和描述的世界。这就是**语义空间**（semantic space），$\mathcal{S}$。在这里，“代谢酶”这样的概念不是原子的集合，而是一个由其与其他概念的关系所定义的点，这个点可能被表示为一个向量 $\mathbf{s}$，该向量通过分析数千本生物学教科书得出。“有条纹的马”这一描述就存在于这个世界中。

传统[机器学习模型](@entry_id:262335)的任务是在[特征空间](@entry_id:638014) $\mathcal{X}$ 中划分边界。它学习将对应于“马”的点与对应于“驴”的点分开。但如果它从未见过“斑马”的点，它就不知道该在哪里画一条新的边界。它就卡住了。

ZSL采用了一种不同且更优雅的方法。它不仅仅是在一个世界里学习边界，而是学习两个世界之间的*映射*。它建造了一座桥。这座桥通常是一个简单的数学变换，比如一个矩阵 $W$，它将一个点从特征空间投影到语义空间：$\mathbf{v} = W\mathbf{x}$。

让我们通过一个受生物学挑战启发的具体例子来看看这是如何工作的 [@problem_id:1423402]。假设我们有一些来自我们非常了解的物种A的蛋白质。对于每个蛋白质，我们有它的特征向量 $\mathbf{x}$（来自实验室测量）和它的已知功能，由一个语义向量 $\mathbf{s}$ 表示。我们的目标是找到一个变换矩阵 $W$，它能正确地将已知的特征映射到已知的功能，使得对于我们所有已知的蛋白质，都有 $\mathbf{s} \approx W\mathbf{x}$。如果我们有足够多的例子，我们就可以解出 $W$。例如，如果我们有三个[线性无关](@entry_id:148207)的三维特征向量，它们构成一个基，我们就可以找到一个唯一的 $2 \times 3$ 矩阵 $W$，将它们完美地映射到它们的二维功能向量。

现在，一位科学家在一个完全不同的物种B中发现了一种新蛋白质。他们测量了它的特征，得到了一个新的向量 $\mathbf{x}_{\text{new}}$。他们不知道它的功能。但他们有我们的神奇之桥 $W$。他们可以简单地计算其投影的语义向量：$\mathbf{v}_{\text{new}} = W\mathbf{x}_{\text{new}}$。这个向量 $\mathbf{v}_{\text{new}}$ 是对新蛋白质描述应该是什么样子的一个*预测*。这是模型在说：“根据我所见过的，这个新蛋白质的功能应该被描述为*这样*。”

最后一步是一个简单的搜索。这位科学家有一份候选功能列表，每个功能都有自己的语义向量 $\mathbf{s}_{\text{candidate}}$。他们只需要找到哪个候选向量与预测向量 $\mathbf{v}_{\text{new}}$ 最相似。一种衡量向量之间相似度的自然方法是**余弦相似度**（cosine similarity），它就是两个向量之间夹角的余弦值。余弦相似度最高的候选者就是模型的最佳猜测。这种方法的美妙之处在于，获胜的候选功能可能是模型从未被明确训练过的——一个真正的零样本预测。

### 连接世界：从文本到向量

这种语义空间的想法很强大，但它引出了一个问题：这些语义向量从何而来？在ZSL的早期，它们通常是手工制作的属性列表。对于“斑马”，属性向量可能包含 [是动物, 有条纹, 有蹄, ...] 等条目。

但一个更强大、更具[可扩展性](@entry_id:636611)的方法是从语言本身中派生它们。“一个词的意义由其上下文决定。”通过分析海量文本，我们可以将词语和概念表示为高维空间中的向量，其中相似的概念由相近的[向量表示](@entry_id:166424)。这是现代自然语言处理（NLP）的基础思想。

我们可以构建这个过程的一个简化版本来看看它是如何工作的 [@problem_id:3121759]。想象一下，我们想从水果类别的文本描述（如“green apple”或“ripe banana”）中构建它们的语义向量。一个非常简单的[文本编码](@entry_id:755878)器可以计算每个字母的出现次数，形成一个计数向量。然后，这个向量可以被投影到一个较低维度的空间中，以创建一个文本嵌入（text embedding）。这个嵌入就是我们语义空间 $\mathcal{S}$ 中的一个点。

现在，对于一组*训练*类别，我们也有“视觉”嵌入——比如说，它们是由一个深度网络学习到的，用于区分不同种类的水果图像。我们有一对对数据：描述的文本嵌入 $z(t_i)$ 和类别的视觉嵌入 $e_i$。我们的任务是学习一个对齐映射，即一个矩阵 $A$，它将文本嵌入转换为相应的视觉嵌入：$e_i \approx A z(t_i)$。我们可以通过解决一个标准的机器学习问题——线性回归——来找到最佳矩阵 $A$。具体来说，我们想找到一个 $A$，使得对于我们所有的训练类别， $A z(t_i)$ 和 $e_i$ 之间的平方差最小。

一旦我们有了这个对齐矩阵 $A$，我们就可以进行[零样本分类](@entry_id:637366)。对于一个像“sweet chili”（甜辣椒）这样的新的、未见的类别，我们首先计算它的文本嵌入 $z(t_{\text{chili}})$。然后，我们使用我们学到的映射来预测它的视觉嵌入：$\hat{e}_{\text{chili}} = A z(t_{\text{chili}})$。现在，当我们看到一张新图片时，我们可以处理它以获得其视觉嵌入，然后看看它是否更接近我们预测的辣椒嵌入 $\hat{e}_{\text{chili}}$，还是更接近我们已知的其他水果的嵌入。我们成功地增加了一个新类别，而不需要任何一张它的标记图像。

### 提示的力量：与巨人的对话

前面的例子使用了一个简单的[文本编码](@entry_id:755878)器。当我们用一个真正的巨人——一个像BERT或GPT这样的大规模**预训练语言模型（PLM）**来替换它时，会发生什么？这些模型在海量文本上进行了训练，并已经发展出一个极其丰富和细致的内部语义空间。

这一洞见带来了一次范式转变。我们不再需要训练一个独立的模型来在视觉空间和文本空间之间进行映射，而是可以更直接地利用PLM现有的知识。我们可以将分类问题构建为与模型的一种对话。这就是**提示（prompting）**背后的思想。

我们不再只是将一张图片输入给分类器，而是可以给它图片和一个提示，比如：“这是一张`[MASK]`的照片。”模型的任务是预测最适合填补`[MASK]`的词。如果它预测“斑马”，我们就将图片分类为斑马。类别标签不再是任意的索引；它们就是词语本身。

在这种设置下，分类器的“权重”不是从头开始学习的，而是直接从语言模型对类别名称的表示中派生出来的 [@problem_id:3178397]。一个类别 `y` 的分数就是输入的嵌入 $\mathbf{x}$ 和该类别名称的文本嵌入 $\mathbf{t}_y$ 之间的余弦相似度。

我们可以让这变得更加灵活。我们提出问题的方式——即提示——很重要。“一张{}的照片”可能比“这是一个{}”效果更好。每个提示都可以被看作一个转换矩阵 $\mathbf{A}_p$，它对基础文本嵌入进行微调：$\mathbf{w}_y = \text{normalize}(\mathbf{A}_p \mathbf{t}_y)$。**提示调优（Prompt tuning）**就是找到最佳提示的过程。我们可以在一小组标记样本（一个支持集）上尝试几种不同的提示，然[后选择](@entry_id:154665)效果最好的那个。这使我们能够以极高的效率使庞大的PLM适应我们的特定任务。

### 学习的光谱：何时观察，何时飞跃

这就把我们带到了一个实际问题。我们有零样本学习（立即飞跃）、提示调优或[少样本学习](@entry_id:636112)（观察几个例子）以及完全微调（研究许多例子）。我们应该使用哪一个？答案很巧妙，它取决于你有多少数据。

模型的灵活性与其在有限数据上“过度思考”的风险之间存在一个根本的权衡。
-   **微调**一个大型模型的所有参数（通常超过1亿个）赋予了它巨大的灵活性。有了足够的数据，它可以完美地学习新任务的细微差别。但如果只有少数几个例子，它几乎肯定会[过拟合](@entry_id:139093)——就像一个学生记住了五道练习题的答案，但在真实考试中却失败了。
-   **零样本学习**处于另一个极端。它按原样使用模型，新任务的可训练参数为零。它不会对新数据过拟合，因为它不在这些数据上训练。但它的表现完全取决于模型的预存知识与新任务的契合程度。
-   **基于提示的方法**（如提示调优）提供了一个绝佳的中间地带 [@problem_id:5220078]。通过冻结庞大的PLM，只为提示训练一小组新参数（也许几千个），我们极大地降低了[模型过拟合](@entry_id:153455)的能力。从学习理论的角度来看，“[泛化差距](@entry_id:636743)”——训练数据上的表现与新数据上表现之间的差异——取决于可训练参数的数量。通过保持这个数字很小，我们确保在少数例子上的良好表现更有可能转化为在整个任务上的良好表现。

我们甚至可以定量地对这一选择进行建模 [@problem_id:3195216]。想象一下，随着我们获得更多标记样本 $k$，不同方法的性能（准确率）会提高。像微调这样的方法一开始可能学习得很慢，因为它有太多参数需要调整（“数据需求量”高），但其最终的潜在性能可能非常高。像[少样本学习](@entry_id:636112)这样参数高效的方法可能从最初的几个例子中学习得非常快，但随后会进入平台期。通过对这些学习曲线进行建模，我们可以找到一个“模式切换点”，即一个样本数量 $k^\star$，在这个点上，微调的效果超过了更高效的方法。这为我们根据数据预算选择策略提供了一种有原则的方法。当数据稀缺时，ZSL及其基于提示的“亲戚们”表现最为出色，这在基因组学 [@problem_id:4567064] 或罕见病诊断 [@problem_id:5210097] 等专业领域是很常见的情况。

### 在变动的世界中导航：现实的挑战

然而，现实世界并不像我们的训练数据那样干净。机器学习中最大的挑战之一是**[领域偏移](@entry_id:637840)（domain shift）**：我们在现实世界中遇到的数据可能遵循与我们用于训练的数据不同的分布。我们测试照片中的光照可能不同，或者新蛋白质可能来自不同的实验设置。

这正是ZSL的架构可能提供令人惊讶优势的地方 [@problem_id:3160900]。在标准分类器中，决策边界直接与特征空间的几何形状相关联。如果特征发生偏移，决策边界现在就处于错误的位置。然而，在ZSL中，分类是通过一座通往稳定语义空间的桥梁进行的。“马”和“斑马”的含义不会改变，即使照片中的光照变了。如果模型学到了一个鲁棒的映射，它可能能更好地处理这种偏移。这种迁移的成功取决于学习到不变特征（invariant features）——即捕捉对象本质而非领域特性的表示 [@problem_id:3157545]。一个学会识别抽象概念的“更深”的模型可能比一个记忆了领域特定模式的“更宽”的模型对[领域偏移](@entry_id:637840)更具鲁棒性。

即使有一个完美的模型，另一个挑战也随之出现：不确定性。当一个ZSL模型对一个未见类别做出预测时，它有多自信？我们能相信它的自信吗？我们可以使用信息论中的一个经典概念来衡量模型的不确定性：**[香农熵](@entry_id:144587)（Shannon entropy）** [@problem_id:3174144]。当模型的预测概率分布在许多不同类别上时，熵很高，表明不确定性很高。当概率集中在单个类别上时，熵很低，表明很自信。

这不仅仅是一种被动的测量。我们可以发现，高熵通常与模型犯错相关，尤其是在未见类别上。这一洞见使我们能够构建更智能、自适应的系统。例如，如果我们检测到一个预测的熵高于某个阈值，我们可以触发一个特殊规则：“这是一个不确定的情况。让我们稍微提高未见类别的概率，因为它们本身就更难。”这种简单的、熵感知的提示有时足以将一个错误的答案变成正确的答案。

最后，我们必须诚实地对待我们所测量的东西。在许多现实世界的ZSL应用中，例如诊断一种罕见疾病，阳性案例就像大海捞针 [@problem_id:5210097]。一个模型可以仅仅通过总是猜测“无疾病”就达到99.9%的准确率。在这种不平衡的场景中，标准准确率具有误导性。我们需要关注那些针对稀有阳性类别的指标，比如**阳性预测值（Positive Predictive Value, PPV）**——在所有阳性预测中，有多少是正确的？——以及**[精确率-召回率曲线](@entry_id:637864)下面积（Area Under the Precision-Recall Curve, AUPRC）**。即使一个看似优秀的模型也可能有惊人低的PPV，这提醒我们，科学的征途不仅需要强大的工具，还需要健康的批判性思维。

现代形式的零样本学习，证明了抽象和类比的力量。它正在从死记硬背走向一种更接近人类的推理形式，在这种形式中，知识不仅被存储，而且被连接起来。通过在我们所见的和我们所指的之间架起桥梁，我们使我们的模型能够向未知领域进行有根据的飞跃。

