## 引言
人类是如何识别出一种他们从未见过的动物的？我们不需要成千上万个例子；一句简单的描述，如“一种有黑白条纹的马”，通常就足以让我们认出斑马。这种从抽象知识中进行泛化的能力是智能的标志，但长期以来，对于依赖海量标注数据集进行机械记忆的传统机器学习模型而言，这一直是一个挑战。本文介绍[零样本学习](@article_id:639506)（Zero-shot learning, ZSL），这是一种革命性的[范式](@article_id:329204)，它通过理解标签背后的*意义*来教导机器克服这一限制，使其能够识别在训练期间从未遇到过的对象和概念。我们将首先深入探讨“原理与机制”，探索 ZSL 如何在[共享嵌入空间](@article_id:638675)中搭建视觉数据和语义描述之间的桥梁。随后，“应用与跨学科联系”一章将展示 ZSL 在不同领域的变革力量，从计算机视觉和[自然语言处理](@article_id:333975)，到生物学和医学中生命的编码。

## 原理与机制

### 通过类比学习，而非机械记忆

想象一下教一个孩子什么是“斑马”。你可能不需要给他看成千上万张斑马的图片。你可能会说：“它像一匹马，但身上有黑白条纹。”孩子利用他们已有的关于“马”和“条纹”的知识，为这种新动物建立了一个心智模型。当他们第一次看到斑马时，就能认出它。这就是通过类比学习。

传统的机器学习更像是机械记忆。为了教一个标准分类器识别“斑马”，你需要给它输入一个包含数千张带标签的斑马图像的庞大数据集。模型学习到与“斑马”标签相对应的复杂像素模式。如果你再让它识别一种它从未见过的动物——“㺢㹢狓”（okapi），它将完全失败。因为它对“㺢㹢狓”没有任何概念。

[零样本学习](@article_id:639506)（ZSL）旨在教机器更像人类一样，通过类比进行学习。其核心思想是摆脱学习视觉模式与无意义标签之间直接、僵化的联系。相反，我们希望机器能够理解标签本身的*意义*。通过对比两种方法，可以完美地说明这一根本性转变[@problem_id:3160900]。旧方法为它见过的每个类别学习一个**原型**；如果一个类别是未见过的，它就没有原型，因此无法被识别。而 ZSL 方法则将每个类别与一个丰富的**语义描述**——一组属性或来自语言模型的向量——相关联。模型的工作是学习视觉数据与这些语义描述之间的普遍关系，这种关系可以应用于它在训练中从未遇到的新类别。

### 搭建连接两个世界的桥梁

计算机如何才能理解一张带有尖耳朵的毛茸茸生物的图片与“猫”这个*概念*相关？诀窍在于创造一个共同的基础，一个共享的空间，让视觉信息和语义信息可以共存并进行比较。我们称之为**[共享嵌入空间](@article_id:638675)**。可以把它想象成一个普适的意义图书馆，在那里，一张猫的图片和“猫”的字典定义被放在同一个书架上。

要构建这个图书馆，我们需要两个关键组成部分。首先，我们需要一个强大的**[特征提取器](@article_id:641630)**，通常是一个深度神经网络，它可以观察一张图片并将其精华提炼成一串数字——一个向量[嵌入](@article_id:311541)。这个向量，我们称之为 $z$，捕捉了图像的关键视觉特征。其次，我们需要为我们的标签提供意义的来源。这可以是一个简单的属性列表（例如，*有毛、有胡须、是哺乳动物*），或者更强大地，一个来自[预训练](@article_id:638349)语言模型的向量[嵌入](@article_id:311541)，该模型已经通过分析数十亿个句子学会了词语之间的关系。我们称这个语义向量为 $s_c$，对应类别 $c$。

训练 ZSL 模型的关键部分不仅仅是分类它看到的图像，而是在这两个世界之间建立一座桥梁。模型必须学习视觉空间和语义空间之间的**对齐**或**映射**[@problem_id:3121759]。在一个简化但富有洞察力的模型中，这可能意味着学习一个变换矩阵 $A$，它接收一个视觉[嵌入](@article_id:311541) $z$，并试图使结果 $A z$ 尽可能接近相应的语义[嵌入](@article_id:311541) $s_c$。训练过程本质上是教会模型的视觉部分“说”与文本部分相同的语言。

### 意义的几何学

一旦这座桥梁建成并且学会了对齐，[零样本分类](@article_id:641658)的行为就变得异常优雅和直观。假设我们想分类一张“㺢㹢狓”的图片，这是一个模型从未见过的类别。

首先，[特征提取器](@article_id:641630)处理图像并生成其视觉[嵌入](@article_id:311541) $z_{okapi\_image}$。我们没有任何“㺢㹢狓”的训练样本，但我们*确实*有它的语义[嵌入](@article_id:311541) $s_{okapi}$，这很可能来自一个知道㺢㹢狓是“长颈鹿的森林栖息近亲”的语言模型。我们也有所有其他可能类别的语义[嵌入](@article_id:311541)，比如“马” ($s_{horse}$) 和“鹿” ($s_{deer}$)。

现在，分类变成了一个在[共享嵌入空间](@article_id:638675)中的简单[搜索问题](@article_id:334136)：我们新的图像向量与哪个已知的语义向量最接近？这种“接近度”通常通过**[余弦相似度](@article_id:639253)**来衡量，它计算两个向量之间夹角的余弦值[@problem_id:3178397]。如果在这个高维意义空间中，向量指向几乎相同的方向，它们的[余弦相似度](@article_id:639253)就接近于1。如果它们不相关（正交），则为0。如果它们方向相反，则为-1。模型预测其语义向量与图像向量具有最高[余弦相似度](@article_id:639253)的标签。它得出结论，该图像是一只“㺢㹢狓”，因为 $z_{okapi\_image}$ 指向的[方向比](@article_id:346129)指向 $s_{horse}$ 或 $s_{deer}$ 的方向更接近 $s_{okapi}$。

现代的 ZSL 系统，如 CLIP，通过**提示**（prompts）等概念对这一过程进行了优化[@problem_id:3178397]。它们不仅仅使用“猫”的原始语义向量，而是使用像“一张猫的照片”这样的短语的向量。这种上下文有助于更精确地对齐视觉和语义世界，就像指定我们应该查阅百科全书的哪一卷一样。

### 超能力：在变化的世界中生存

至此，我们来到了[零样本学习](@article_id:639506)最美妙、最深刻的优势之一：**鲁棒性**。现实世界的数据是混乱且不断变化的。一个在干净、影棚光线下拍摄的产品图片上训练的模型，在部署到移动应用上时可能会失败，因为用户上传的是模糊、光线不佳的照片。这被称为**[域偏移](@article_id:642132)**（domain shift）。

一个传统的分类器，由于记住了“影棚”域的原型，将会遇到困难，因为新图像在[嵌入空间](@article_id:641450)中与那些原型在几何上相距甚远。但 ZSL 模型有一个秘密武器。一个精彩的思想实验揭示，我们可以将任何物体视为具有**抽象本质**（其基本、不变的属性）和**领域特定的特征**（上下文，如光照和背景）[@problem_id:3157545]。ZSL 模型学习将视觉特征映射到一个捕捉物体本质的语义描述上。“猫”的语义描述不会因为猫是在影棚里还是在黑暗的小巷里而改变。

因为 ZSL 模型锚定在这种稳定的语义信息上，它自然对领域特定上下文的变化更具弹性[@problem_id:3160900]。只要其[特征提取器](@article_id:641630)仍然能够在新领域中感知到物体的核心本质，它就能成功地将其映射到正确、不变的语义锚点。这使得 ZSL 模型不仅聪明，而且在不可预测的现实世界中也更可靠。

### 知其所不知：不确定性的智慧

当一个 ZSL 模型遇到一幅真正模棱两可或属于它甚至没有描述的类别的图像时，会发生什么？一个表现良好的模型不应该胡乱猜测；它应该表达不确定性。

我们可以使用**香农熵**（Shannon entropy）来衡量这种不确定性[@problem_id:3174144]。当模型自信时，它会为一个类别分配高概率，导致熵值较低。当它不确定时，概率会分散在许多类别上，导致熵值较高。对于 ZSL 模型来说，一个不完全匹配其任何已知语义描述的未见类别的输入，通常会产生高熵输出。模型实际上是在说：“我不确定这是什么，但它看起来不像你告诉我的任何东西。”

这种不确定性不是一个缺陷；它是一个有价值的信号。我们可以设计利用这个信号来更智能地行动的系统。例如，在一个“熵感知”系统中，如果一个预测的熵值超过某个阈值，我们可以触发一个特殊规则。其中一个规则可能是放大模型知道的所有*未见*类别的概率[@problem_id:3174144]。这就像给模型一个提示：“你感到困惑，所以更深入地思考一下你学过的新概念。”这可以帮助解决模糊性，将一个困惑的猜测转变为一个正确的零样本预测。

### 学习的谱系：从零到英雄

[零样本学习](@article_id:639506)非常强大，但它并不是故事的结局。它是一个学习谱系的起点，该谱系根据可用数据的多少进行调整[@problem_id:3195216]。

-   **零样本（$k=0$ 个样本）：** 这是纯 ZSL 的领域。我们完全依赖于从[预训练](@article_id:638349)模型传递的知识和我们语义描述的质量。

-   **少样本（$k$ 很小）：** 如果我们得到少量带标签的样本，我们可以做得更好。我们可以使用这些样本来指导模型，这个过程称为**上下文学习（ICL）**，或者我们可以用它们来稍微更新我们的模型，这是一种轻度的**微调**。例如，我们可以使用这几个样本来为我们的任务找到最优的提示模板[@problem_id:3178397]。

-   **多样本（$k$ 很大）：** 有了充足的数据，我们可以进行全面的**微调**，重新训练模型的大部分，使其专门用于当前任务。这通常会产生最高的性能。

这里存在权衡。正如一个量化模型所建议的，ICL 可能只需几个样本就能提供快速提升，而微调最初可能表现更差，但一旦达到一个临界数量的样本 $k^\star$，最终会超越 ICL [@problem_id:3195216]。理解这个谱系是有效部署机器学习的关键。[零样本学习](@article_id:639506)提供了在新情况下行动的基础能力，这是通往真正掌握一项任务的旅程的第一步。它是从已知通往未知的桥梁，一个让我们的机器向着更通用、更灵活的智能迈出虽小但意义重大一步的原则。

