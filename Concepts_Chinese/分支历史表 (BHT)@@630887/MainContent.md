## 引言
在对速度不懈的追求中，现代处理器在一条被称为流水线的超高效装配线上执行指令。这个过程面临一个关键瓶颈：条件分支，这是一条迫使在两条未来路径之间做出选择的指令。猜错会导致灾难性的[流水线冲刷](@entry_id:753461)，丢弃有价值的工作并浪费宝贵的[时钟周期](@entry_id:165839)。分支历史表 (BHT) 是处理器应对这一挑战的解决方案——一种旨在预测程序下一步行动的预测机制。本文将深入探讨BHT的精妙世界，探索其基本设计及其在整个计算领域的深远影响。首先，在“原理与机制”一章中，我们将从头开始解构BHT，从简单的预测器入手，揭示导致更复杂设计出现的问题。然后，在“应用与跨学科联系”一章中，我们将揭示这个核心硬件组件如何与从[编译器优化](@entry_id:747548)、系统安全到[热力学定律](@entry_id:202285)等一切事物相互作用，展示其深远的影响力。

## 原理与机制

要理解现代处理器的天才之处，我们必须首先认识到它们最大的挑战：未来。处理器的流水线就像一条超高效的装配线，同时处理数十条指令，每条指令都处于不同的完成阶段。这种方式在遇到岔路口之前一直运作良好——这个岔路口就是**条件分支**指令，相当于计算机世界里的“如果这个条件为真，走这边；否则，走另一边”。装配线应该遵循哪条路径？如果猜错了，所有部分完成的工作都必须被丢弃，这是一种灾难性的时间和精力浪费，被称为**[流水线冲刷](@entry_id:753461)**。对于一个每秒能执行数十亿条指令的处理器来说，这些停顿的代价是毁灭性的。想象一下浪费工作的成本：如果一个分支在（比如说）12个周期后才解析，一次错误的预测就可能意味着从内存中获取了超过700字节的无用指令，而这些指令最终都会被丢弃 [@problem_id:3637257]。

为了避免这种情况，处理器需要一个水晶球。它需要在知道实际答案之前，*预测*出分支将走向何方。这个神奇的设备就是分支预测器，其核心是一种称为**分支历史表 (BHT)** 的存储器。让我们从头开始构建一个，看看一个简单的想法如何演变成一件精妙绝伦的东西。

### 短暂记忆的愚蠢：1位预测器

最简单的预测策略是什么？“一个分支很可能会做它上次所做的事。”这是一个出人意料的强大想法。许多分支，比如循环末尾的分支，会连续几百次被“跳转”，然后才有一次“不跳转”以退出循环。为了实现这一点，我们可以创建一个表——我们的BHT——并为每个分支提供自己的条目。当遇到某个地址（其[程序计数器](@entry_id:753801)，PC）的分支时，我们在表中查找它的条目。

在**1位预测器**中，这个条目是单个比特位。如果该位是$1$，我们预测“跳转”；如果它是$0$，我们预测“不跳转”。在分支结果实际揭晓后，我们更新该比特位以匹配实际发生的情况。很简单。对于一个运行很长时间的循环，这套机制工作得非常好。它可能在第一次预测时出错，但它很快就能学会，并正确预测接下来的上千次“跳转”结果。当循环最终退出时，它会错误预测那最后一次“不跳转”的结果，但其总体准确性非常出色。

但这种简单性也是它的致命缺陷。对于一个模式不那么规律的分支会发生什么？考虑一段交替出现结果的代码：跳转、不跳转、跳转、不跳转……让我们来追踪一下我们的1位预测器。假设它的初始状态是$0$（“预测不跳转”）。

1.  第一个分支是**跳转**。我们预测了不跳转。**错误预测**。我们将状态更新为$1$。
2.  下一个分支是**不跳转**。我们的状态是$1$，所以我们预测跳转。**错误预测**。我们将状态更新为$0$。
3.  下一个分支是**跳转**。我们的状态是$0$，所以我们预测不跳转。**错误预测**。我们又将状态更新回$1$。

你看到这个模式了吗？预测器总是慢一步，永远在预测即将发生的事情的相反结果。它陷入了一个完美不准确的循环中 [@problem_id:3637282]。1位预测器只有金鱼般的记忆；它完全被最近一次事件所左右，忘记了任何更深层次的模式。

### 借助滞后性学习：[2位饱和计数器](@entry_id:746151)

1位预测器的问题在于其善[变性](@entry_id:165583)。它没有定见。一旦看到一个相反的结果，它就会彻底改变自己的世界观。一个更好的预测器应该更固执一些。它应该会说：“嗯，这不寻常，但我不会马上改变主意。给我看更多证据。”

这种“固执”的原则被称为**滞后性 (hysteresis)**，它被**[2位饱和计数器](@entry_id:746151)**巧妙地捕捉到了。现在，我们BHT中的每个条目都有两位，而不是一位。这给了我们四种可能的状态，我们可以标记为：

-   $11$：强跳转 (Strongly Taken)
-   $10$：弱跳转 (Weakly Taken)
-   $01$：弱不跳转 (Weakly Not Taken)
-   $00$：强不跳转 (Strongly Not Taken)

预测仅基于最高有效位：如果它是$1$（状态$11$或$10$），我们预测“跳转”；如果它是$0$（状态$01$或$00$），我们预测“不跳转”。

更新规则赋予了它力量。如果一个分支被跳转，我们增加计数器。如果它不跳转，我们减少计数器。关键部分是它会“饱和”：它不能增加超过$11$或减少超过$00$。

现在，让我们重新审视那个交替跳转/不跳转的噩梦。假设预测器已经看到了许多“跳转”分支，并且处于“强跳转” ($11$) 状态。

1.  分支是**不跳转**。我们预测了跳转。**错误预测**。状态从$11$减少到$10$（弱跳转）。
2.  下一个分支是**跳转**。我们的状态是$10$，所以我们仍然预测跳转。**正确预测**。状态增加回$11$。
3.  下一个分支是**不跳转**。状态是$11$，预测跳转。**错误预测**。状态减少到$10$。

看看发生了什么！虽然它仍然错误预测了“不跳转”的分支，但它正确预测了所有“跳转”的分支。它的准确率从$0\%$跃升至$50\%$。计数器“记住”了总体的趋势。单个“不跳转”事件不足以使其将预测从“跳转”翻转为“不跳转”；需要连续两次“不跳转”的结果才能将其从状态$10$推到$01$并改变主意。这种韧性就是滞后性的魔力 [@problem_id:3637282]。

这种稳定性确实带来了一点小小的代价。如果一个分支跳转了$100,000$次，然后转为不跳转，1位预测器只错误预测一次。而2位预测器，从状态$11$开始，将在其预测翻转为“不跳转”之前错误预测两次 [@problem_id:3637328]。然而，对于绝大多数现实世界中的分支模式，它们是“大部分跳转”或“大部分不跳转”并带有一些噪声，这种增加的稳定性是一个巨大的胜利。饱和的特性也是关键；它防止了长时间运行的单一结果导致计数器“回绕”并产生荒谬的预测，而这是一个简单的[模计数器](@entry_id:168554)会有的缺陷 [@problem_id:3637251]。[2位饱和计数器](@entry_id:746151)是整个计算机科学中最优雅、最有效的小规模工程解决方案之一。

### 身份错认的诅咒：混淆 (Aliasing)

到目前为止，我们一直生活在一个完美的世界里，每个分支在BHT中都有自己私有的计数器。但处理器的地址空间是巨大的——一个48位的地址空间包含$281$万亿个可能的地址！拥有这么多条目的BHT在物理上是不可能的。实际上，一个BHT可能有几千个条目，比如$2^{12} = 4096$个。

为了找到一个分支的条目，处理器不能使用整个PC。相反，它使用PC的一小部分，通常是几个低位比特。例如，对于一个有64个条目的BHT，硬件可能会使用PC的第6位到第11位作为索引 [@problem_id:3637232]。

这种将巨大的地址空间压缩到小索引空间中的做法，产生了一个不可避免的问题：**混淆 (aliasing)**。两个完全不相关的、在内存中相距甚远的分支指令，可能碰巧具有相同的PC低位比特。例如，地址为`0x00004030`和`0x00005030`的分支都可能映射到BHT索引$0$ [@problem_id:3637232]。它们现在被迫共享同一个2位计数器。

结果是一片混乱。想象一下，分支A总是跳转，分支B总是不跳转，并且它们混淆到同一个条目。程序执行A，然后是B，然后是A，然后是B……

-   A执行。它是跳转。它将共享计数器推向“强跳转”。
-   B执行。它是不跳转。它预测跳转（因为A的影响）并错误预测。然后它将计数器推回“不跳转”方向。
-   A再次执行。它是跳转。它预测不跳转（因为B的影响）并错误预测。

这两个分支正在积极地相互对抗，污染了共享的历史记录，并摧毁了预测器对两者的准确性。与非混淆情况相比，这种干扰可能导致错误预测的大幅增加 [@problem_id:3637290]。

### 一线上下文的曙光：[gshare预测器](@entry_id:750082)

我们如何对抗混淆？核心问题在于我们的索引只知道分支*在哪里*（它的PC），而不知道程序是如何到达那里的*上下文*。像`if (ptr != NULL)`这样的分支的行为，可能会因到达它的路径不同而大相径庭。

这一洞见引出了一类更高级的预测器。如果我们记录下程序中*任何地方*执行的最后（比如说）8个分支的结果会怎么样？我们可以将这个模式存储在一个8位的[移位寄存器](@entry_id:754780)中，称为**全局历史寄存器 (GHR)**。这个GHR代表了程序最近的“路径”。

绝妙的**gshare**预测器结合了这两条信息。为了创建BHT索引，它取分支PC的低位比特，并与GHR的比特进行**[按位异或](@entry_id:269594) (XOR)** 操作。

索引 = (PC 比特) $\oplus$ (GHR 比特)

为什么是XOR？这是一个极好的置乱函数。想象一下两个分支A和B，它们有相同的PC比特，通常会发生混淆。如果到达A之前的全局历史是`T-T-N`，而到达B之前的历史是`N-T-N`，那么GHR就会不同。XOR操作几乎肯定会产生两个*不同*的BHT索引。Gshare利用程序的最近路径来解开那些否则会冲突的分支。这是一种在历史表中为每个分支提供自己的“上下文敏感”条目的方法。虽然它不是一个完美的解决方案——精心设计或不幸构造的程序仍然可能导致冲突 [@problem_id:3619743]——但它显著减少了典型程序中的混淆，并代表了预测准确性的一次重大飞跃。

### 预言的代价

这整个预测机制，尽管优雅，却并非魔法。它是一个物理电路，有其现实世界的成本和复杂性。

首先，预测所需的信息必须在机器中传输。当一个分支被取指时，它的预测就做出了。很久以后，在执行阶段，它的真实结果才被确定。为了知道是否犯了错误，执行阶段需要知道取指阶段最初预测了什么。而为了正确更新BHT，它需要2位计数器的*原始*状态。这些信息不能从BHT中重新读取，因为在此期间表可能已经被其他分支更新了。唯一的解决方案是，将这些数据——预测的PC和旧的计数器状态——与指令本身一起沿着流水线传递下去。这意味着在每个阶段之间的关键[流水线寄存器](@entry_id:753459)中增加几十个额外的比特位，这在芯片面积和复杂性上是一个实实在在的成本 [@problem_id:3665258]。

其次，BHT更新本身是一个物理动作。当分支结果已知时，必须调度一个[微操作](@entry_id:751957)将新的计数器值[写回](@entry_id:756770)BHT。这个写操作必须使用内部总线，与其他重要流量（如指令取指和数据内存访问）竞争使用权。如果在“关键周期”内总线繁忙，BHT更新就必须等待，从而延迟了预测器的学习能力 [@problem_id:3659171]。

最后，在一个程序的最初阶段，当BHT为空时，我们应该怎么做？我们需要一个**重置策略**。我们应该将所有计数器初始化为“强不跳转” ($00$)，还是“弱跳转” ($10$)？“不跳转”的默认值对于很少发生的“if-error”检查很有利。但“跳转”的默认值对于几乎总是跳转的循环分支更好。计算机架构师在代表性的基准程序上进行大量模拟，以决定哪种默认策略对于短时运行的程序能导致更少的平均错误预测 [@problem-id:3637321]。这个“冷启动”问题也出现在每当一个分支的条目因容量冲突而被从BHT中逐出，随后必须重新初始化时。有时会出现与直觉相反的结果，即对于特定模式，“坏”的初始猜测可能比“好”的猜测导致更少的错误 [@problem_id:3637300]。

分支历史表是[计算机体系结构](@entry_id:747647)本身的一个缩影：一段始于一个简单想法的旅程，这个想法揭示了一个缺陷，从而引出一个带有更深层次问题的更精炼的想法，而这又激发了更复杂的解决方案，所有这一切都受到空间、时间、和能量等物理现实的制约。这是逻辑与物理的一场优美舞蹈。

