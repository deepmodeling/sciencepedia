## 引言
不确定性是科学和决策制定中的一个基本方面，然而并非所有的不确定性都是相同的。我们常常将信心的缺乏视为一个单一的问题，但这忽略了内在随机性与简单的知识缺乏之间的关键区别。本文旨在通过介绍无知的两种面貌：[偶然不确定性](@article_id:314423)（不可约减的随机性）和认知不确定性（可约减的无知），来弥补这一概念上的差距。在接下来的章节中，我们将首先通过清晰的例子和数学框架，探讨定义和区分这些概念的核心“原理与机制”。随后，“应用与跨学科联系”一章将展示这一强大的区分如何在从工程学、气候科学到人工智能前沿等领域中，为行动提供实用的指南。

## 原理与机制

想象一下，有人让你提供两个数字：太阳中心的温度，以及你所在城市下一个雨点将落下的确切位置。这两项任务都涉及不确定性，但你几乎可以凭直觉感受到，它们是不同类型的不确定性。太阳核心的温度是一个固定的实数。我们的不确定性是测量和建模的问题——一种知识的缺乏，原则上我们可以通过更好的仪器和理论来减少这种不确定性。然而，下一个雨点的位置受制于[湍流](@article_id:318989)和[热力学](@article_id:359663)的混沌之舞。即使我们对大气的当前状态有完美的了解，其未来状态本质上也是不可预测的。这是一场机遇游戏。

这一根本区别是理解不确定性的关键。科学界为这两种无知赋予了特殊的名称：**认知不确定性（epistemic uncertainty）** 和 **[偶然不确定性](@article_id:314423)（aleatoric uncertainty）**。

### 无知的两面性

认知不确定性（Epistemic uncertainty）源于希腊词 *epistēmē*，意为“知识”。这是由于*缺乏知识*而产生的不确定性。它是我们对世界的模型与世界本身之间的差距。因为它关乎我们所不知道的事物，所以原则上它是**可约减的**。对太阳核心温度的不确定性就是认知不确定性。

[偶然不确定性](@article_id:314423)（Aleatoric uncertainty）源于拉丁词 *alea*，意为“骰子”（如一对骰子中的一个）。它是一个随机或偶然现象所固有的不确定性。即使我们的知识是完美的，这种可变性依然存在。因此，它是**不可约减的**。对雨点位置的不确定性就是[偶然不确定性](@article_id:314423)。

让我们通过一个简单的数学游戏来将这一点讲得一清二楚。假设一台机器接收一个输入数字 $X$，然后输出 $Y = X^2$。现在，考虑两种我们对输入 $X$ 的了解情况 [@problem_id:3201115]。

**情景1（认知性）：** 我们只被告知 $X$ 的真实值是位于区间 $[-1, 2]$ 内的某个固定数字。我们没有其他信息。这是一种纯粹的认知不确定性状态。我们不知道 $X$ 是哪个数。我们该如何描述关于输出 $Y$ 的不确定性呢？我们能做的最好的事情就是传递这个区间。由于 $X$ 在 $-1$ 和 $2$ 之间，输出 $Y = X^2$ 必定位于 $0$（最小值，在 $X=0$ 时取到）和 $4$（最大值，在 $X=2$ 时取到）之间。所以，我们只能说 $Y \in [0, 4]$。我们甚至无法计算 $Y$ 的一个有意义的“[期望值](@article_id:313620)”，因为那需要假设一个 $X$ 的[概率分布](@article_id:306824)——而这些信息我们根本没有。

**情景2（偶然性）：** 我们被告知 $X$ 是一个在区间 $[-1, 2]$ 上均匀选取的、会“跳动”的随机数。这意味着我们[对生成](@article_id:314537) $X$ 的*过程*有完全的了解。它不是一个我们不知道的固定数字，而是一个内在的随机事件。这是纯粹的[偶然不确定性](@article_id:314423)。现在，我们可以运用概率论的全部力量了。其[概率分布](@article_id:306824)为 $X \sim \mathcal{U}(-1, 2)$。我们可以计算出输出的[期望值](@article_id:313620)恰好是 $\mathbb{E}[Y] = \mathbb{E}[X^2] = 1$。我们可以求出它的方差 $\mathrm{Var}(Y) = 6/5$，以及任何结果的概率，比如 $\mathbb{P}(Y \le 1) = 2/3$。

注意其中的区别！在[认知不确定性](@article_id:310285)的情况下，我们的答案是一个反映我们无知的*区间*。在[偶然不确定性](@article_id:314423)的情况下，我们的答案是一个反映世界内在随机性的精确*[概率分布](@article_id:306824)*。

### 试金石：我们能做得更好吗？

这两种不确定性之间最重要的实际区别在于我们能对它们做些什么。你可以通过收集更多数据来减少[认知不确定性](@article_id:310285)。你无法减少[偶然不确定性](@article_id:314423)。

考虑一个简单的物理实验：一个悬挂在弹簧上的物体。我们想要预测在给定力的作用下弹簧会伸长多少 [@problem_id:2448433]。有两种不确定性来源困扰着我们的预测：

1.  **弹簧刚度（$k$）：** 我们不知道我们这个特定弹簧的确切刚度。我们查阅了制造商的手册，手册给出了一个典型值的范围。这是**[认知不确定性](@article_id:310285)**。我们如何减少它？很简单！我们可以对我们的特定弹簧进行几次简单的测试，直接测量其刚度，用一个精确的测量值替换手册上模糊的数值。更多的数据减少了我们的无知。

2.  **施加的力（$F$）：** 假设这个力是由房间里的[湍流](@article_id:318989)气流产生的。即使我们保持“平均”条件不变，这个力也会时时刻刻、每次实验都随机波动。这是**[偶然不确定性](@article_id:314423)**。我们能通过获取更多数据来减少它吗？不能以同样的方式。我们可以多次测量这个力，以获得其统计特性的非常精确的图像——它的均值、方差、[概率分布](@article_id:306824)的形状。但无论我们多么好地描述这种随机性，我们永远无法预测下一瞬间力的确切值。这种随机性是世界的一个特征，而不是我们知识中的一个缺陷。

这个原则即使在最复杂的系统中也成立。在模拟水流过管道时，我们对管道固定的物理粗糙度的不确定性是认知性的。相比之下，[湍流](@article_id:318989)的混沌、瞬时波动是偶然性的 [@problem_id:2536824]。我们可以学习前者，但我们只能描述后者的统计数据。

### 教会机器知其所不知

这种区分不仅仅是一个哲学上的好奇心；它是构建可信赖人工智能的核心。一辆自动驾驶汽车不仅需要知道它预测*什么*（例如，“前方有行人”），还需要知道它对该预测的*[置信度](@article_id:361655)*如何，以及它*为什么*不确定。它不确定是因为图像模糊、缺乏数据（认知性），还是因为行人的行为根本上是不可预测的（偶然性）？

现代机器学习模型，尤其是在[贝叶斯框架](@article_id:348725)下，可以被教会区分这些不确定性。一个模型的总预测不确定性可以使用一个称为**全方差定律**（Law of Total Variance）的规则进行精妙的分解 [@problem_id:3180557]。想象一个由许多不同神经网络组成的“委员会”，所有网络都用相同的数据进行训练。我们可以将它们看作一个专家小组。委员会最终预测的总不确定性可以分解为两部分：
$$
\text{总方差} = \underbrace{\mathrm{Var}(\text{每个专家的平均预测})}_{\text{认知不确定性}} + \underbrace{\text{Average}(\text{每个专家预测的方差})}_{\text{偶然不确定性}}
$$

**认知不确定性**是*专家之间的分歧*。如果所有专家对一个给定的输入给出截然不同的答案，这意味着委员会不确定是因为模型本身是不同的。当它们预测远离其训练数据的内容时，就会发生这种情况。这是模型无知的一个信号。

**[偶然不确定性](@article_id:314423)**是*每个专家自我宣称的不确定性的平均值*。每个专家可能会说：“根据我所学到的，数据本身是有噪声的。对于这个输入，结果具有内在的随机性，方差为 $\sigma^2$。”这些个体噪声估计的平均值就是[偶然不确定性](@article_id:314423)。

当我们给模型更多数据时，这种分解的力量就显现出来了 [@problem_id:3180557]。假设只有50个数据点时，认知不确定性（分歧）很高，比如为 $0.9$，而共同认定的[偶然不确定性](@article_id:314423)为 $0.4$。总预测方差为 $1.3$。现在，我们在 $5000$ 个数据点上训练同一个模型。我们委员会的专家们现在有了更多的经验。他们对问题达成了相似的理解。他们的[分歧](@article_id:372077)急剧下降——[认知不确定性](@article_id:310285)可能降至 $0.1$。但数据中的内在噪声没有改变。[偶然不确定性](@article_id:314423)仍然是 $0.4$。总方差现在是 $0.5$。我们减少了我们的无知，但我们没有改变世界的随机性。这正是使认知不确定性可约减而[偶然不确定性](@article_id:314423)不可约减的原因。

同样地，这个原则也被其他模型如[高斯过程](@article_id:323592)（Gaussian Processes）优雅地捕捉到，它们自然地提供了一个后验方差，该方差量化了它们对数据点之间函数真值的认知不确定性 [@problem_id:2707416]。

### 随机性的真实形状

到目前为止，我们一直将[偶然不确定性](@article_id:314423)说成是简单的、对称的“噪声”。但世界的随机性可能远比这更有结构、更奇特。想象一个过程，对于给定的输入，它有两个非常不同、更受偏好的结果，但很少有介于两者之间的结果 [@problem_id:3197060]。

如果我们试图用一个假设噪声是简单钟形曲线（单一高斯分布）的工具来建模这个过程，模型将彻底失败。为了解释两个峰值，它能做的最好的事情就是在两个峰值的平均值上放置一个宽大的单一[钟形曲线](@article_id:311235)。它会预测最可能的结果是正中间的那个——而那个地方恰恰是结果几乎从不出现的地方！模型很自信，但对底层结构却完全错误。

这给我们上了一堂深刻的课：[偶然不确定性](@article_id:314423)不仅仅是一个单一的数字（方差）；它有一个*形状*（[概率分布](@article_id:306824)）。我们的模型必须具有正确的架构灵活性来捕捉这种形状。再多的数据——再怎么减少[认知不确定性](@article_id:310285)——也无法修复一个对世界随机性本质有错误基本假设的模型。一个只能预测钟形曲线的模型永远无法理解一个双峰世界。

### 发现的模糊前沿

我们已经在认知不确定性（知识缺乏）和[偶然不确定性](@article_id:314423)（内在随机性）之间划出了一条清晰的界线。但在科学发现的现实世界中，这条线可能会变得非常模糊。今天看起来是偶然性的东西，明天可能就变成了认知性的。

考虑一项新药的[临床试验](@article_id:353944) [@problem_id:3197075]。我们将其给予大量人群，发现它对大约一半的人有效，对另一半人无效。对于任何新患者来说，结果似乎就像抛硬币一样——50/50 的机会。这看起来是高度的[偶然不确定性](@article_id:314423)。不确定性是最大的，量化为 $1$ 比特的香农熵。

但随后，一位遗传学家发现了一个特定的基因 $S$。结果发现，基因型为 $S=a$ 的患者有 $90\%$ 的康复率，而基因型为 $S=b$ 的患者只有 $10\%$ 的康复率。突然之间，情况改变了！“随机性”被解决了。通过发现这个隐藏变量——基因——我们将一个巨大的[偶然不确定性](@article_id:314423)转化为了一个小得多的不确定性。一旦我们知道了基因型，预期的不确定性降至大约 $0.47$ 比特。我们最初的抛硬币式随机性实际上只是伪装的认知不确定性——我们对患者的基因构成一无所知。

这正是科学进步的本质。我们寻找隐藏的变量，更深层次的[因果结构](@article_id:320318)，来解释那些似乎是不可约减的偶然性。一代科学家称之为“随机实验噪声”（偶然性）的东西，下一代科学家凭借更好的理论和更精确的仪器，可能会将其识别为可以建模和校正的系统性效应（认知性）[@problem_id:2479744]。

科学的旅程在很多方面都是一场不懈的探索，旨在推后不确定性的前沿：将表面上的偶然性转化为认知性，然后用数据、测量和洞察力来征服这种[认知不确定性](@article_id:310285)。这是一段从接受掷骰子的结果到理解骰子如何被投掷的物理过程的旅程。

