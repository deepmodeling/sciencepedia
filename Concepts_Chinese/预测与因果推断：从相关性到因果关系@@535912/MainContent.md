## 引言
在大数据时代，发现模式和做出预测的能力比以往任何时候都更加强大。我们建立模型来预测从股票市场波动到疾病爆发的各种事件。然而，一个更深层次的问题往往悬而未决：如果我们改变某个因素，会发生什么？这正是预测（预报将会发生什么）与因果推断（理解如果我们进行干预将会发生什么）之间的关键鸿沟。混淆这两者是[数据分析](@article_id:309490)中最常见却也最关键的错误之一，会导致错误的结论和无效的政策。本文旨在剖析这一根本区别。首先，在“原理与机制”一章中，我们将探讨区分相关性与因果关系的核心概念，揭示为何即使最准确的预测模型也无法洞察其背后的真相。随后，“应用与跨学科联系”一章将展示这一理论分歧在实践中如何体现，介绍医学、生态学和遗传学等领域的科学家如何设计研究，以超越简单的预测，揭示我们周围世界的真正驱动因素。

## 原理与机制

想象一下，你正站在知识的十字路口。一条路通向一个写着“将会发生什么？”的标志牌。这是**预测**之路。另一条路的标志牌则问：“如果……会怎样？”这是**[因果推断](@article_id:306490)**之路。虽然它们似乎都始于同一个地方——一堆数据——但它们通往的目的地却截然不同，理解它们的区别是现代科学最深刻的转变之一。

### 两个基本问题：“将会发生什么？”与“如果……会怎样？”

预测的问题关乎预报。它是被动的。我们观察世界过去的样子，发现其中的模式，并用它们来猜测世界明天会是什么样子。金融分析师可能会使用像 ARIMA 这样复杂的时间序列模型，根据之前所有的回报数据来预测第二天的股票回报。该模型的唯一任务是尽可能频繁地预测正确；其目标是最小化预测误差 [@problem_id:2438832]。生态学家可能会观察到，随着湿地周围道路密度的增加，两栖动物的物种数量会减少。预测模型可以学习到这种相关性，并在给定一个新的湿地时，仅通过查看附近道路的地图就能预测其物种丰富度 [@problem_id:1868277]。这是一种非常有用的能力。

但现在考虑一种不同类型的问题。金融分析师被要求的不仅仅是预测回报；她被要求评估一项*新政策*的影响，这是一项从未发生过的干预。生态学家被要求的不仅仅是预测[物种丰富度](@article_id:344608)；她想知道*修建一条新路是否会主动伤害*两栖动物。这就是“如果……会怎样？”的问题。它是主动的。这不关乎观察河流的流动；而是关乎询问如果我们建一座大坝会发生什么。这就是**[因果推断](@article_id:306490)**的领域。它关乎理解我们行动的后果。

一个预测模型，无论多么准确，都无法回答这个问题。它的模式是相关性，而非因果法则。干预下的世界是一个不同的世界，一个模型可能从未见过的世界。

### 预言家的幻觉：为何你最好的预测器也无法洞察真相

“等等，”你可能会说。“如果我有一个足够强大的[算法](@article_id:331821)——一个拥有十亿参数的深度神经网络——它难道不能学习到真实的关系，从而回答这两个问题吗？”这个想法很诱人，但答案是响亮的“不”。限制不在于[算法](@article_id:331821)，而在于数据本身。

让我们来做一个思想实验，一个上帝的游戏。想象一下，可能有两个宇宙在生成我们看到的数据。这两个宇宙都包含两个变量，$X$和$Y$。

-   **宇宙 A（[直接原因](@article_id:309577)）：** $X$直接导致$Y$。比方说，$Y = X + \text{noise}$。因果故事很简单：$X \rightarrow Y$。
-   **宇宙 B（隐藏[混淆变量](@article_id:351736)）：** 存在一个隐藏因素，一个未被观察到的变量$U$，它同时导致了$X$和$Y$。例如，$X = U + \text{noise}_X$ 和 $Y = 1.5U + \text{noise}_Y$。因果故事是$X \leftarrow U \rightarrow Y$。$X$和$Y$之间根本没有直接的因果联系。

关键在于：正如一个优美的[数学证明](@article_id:297612)所示，我们可以选择噪声分布，使得来自两个宇宙的*观测数据*在统计上是完全相同的。一个试图从$X$预测$Y$的机器学习模型，在两个宇宙中都会学到完全相同的预测规则，$f(x) = \mathbb{E}[Y \mid X=x]$ [@problem_id:3178830]。一个拥有无限能力的深度神经网络，用无限的观测数据进行训练，也无法告诉你它身处哪个宇宙。它学会了完美地“看”到模式，但它对底层的因果机制是盲目的。

这不仅仅是一个数学上的奇谈；它无处不在。在神经科学中，我们可能观察到大脑区域$X$的活动总是先于并能预测区域$Y$的活动。这被称为**[格兰杰因果关系](@article_id:297737)**（Granger causality），一个预测性概念。但完全有可能的是，第三个未被观察到的区域$U$才是真正的驱动者，它先激活$X$，几毫秒后再激活$Y$。仅凭这一观察就断定$X$导致$Y$将是一个错误 [@problem_id:2716243]。预测关系是真实的，但因果故事却是一个幻象。

那么，如果我们全知的预测预言家是盲目的，我们又怎能希望能找到因果关系呢？

### 科学家的答案：要了解一个系统，就去“戳”它一下

答案与科学本身一样古老：如果你想了解某样东西是如何运作的，不要只看着它。要进行干预。去“戳”它一下。对它做点什么，然后看看会发生什么。

最严谨的方法是进行**操控性实验**。让我们回到那位担心两栖动物和道路的生态学家 [@problem_id:1868277]。她可以不只是观察现有的湿地，而是建造一系列相同的人工池塘，或称“中宇宙”（mesocosms）。她会在每个池塘里放养相同的两栖动物群落。然后是关键步骤：她会**随机分配**每个池塘到一个处理组。一组是控制组，得到干净的水。另一组得到含有路盐的水。第三组得到实际的高速公路径流。

通过随机分配处理方式，她打破了混淆的枷锁。池塘之间的任何其他差异——多一点阳光，多几只昆虫——现在都只是[随机噪声](@article_id:382845)，在各组之间被平均掉了。如果在两年后，用盐和径流处理的池塘比控制组池塘的物种更少，她就有了强有力的证据，证明这些因素*导致*了[物种丰富度](@article_id:344608)的下降。她已经从观察世界转向操控世界，从看到相关性转向识别因果关系。这正是神经科学家们所做的，当他们超越[格兰杰因果关系](@article_id:297737)，使用电极直接“扰动”区域$X$以观察其是否改变区域$Y$时 [@problem_id:2716243]。这是提出因果论断的黄金标准。

### 在阴影中寻找因果：反事实的艺术

当然，我们不能总是进行实验。我们不能随机分配一些学生处于贫困状态，而另一些则处于富裕状态。我们不能仅仅为了测试医院政策的效果就建造新的城市。对于人类许多最紧迫的问题，我们只能依赖观测数据。

这正是现代因果推断真正的智力飞跃所在。我们必须使用统计学和假设来模拟实验。指导思想是**反事实**框架 [@problem_id:2735017]。对于我们研究中的每一个个体——比如，一个衰老大脑队列研究中的病人——我们想象两种可能的未来。一种是如果他们接受了一种新的[抗衰老药物](@article_id:309048)（senolytic drug）后*将会发生*的结果，我们可以称之为$Y(1)$。另一种是如果他们没有接受该药物*将会发生*的结果，$Y(0)$。对于那个人来说，该药物的个体因果效应就是$Y(1) - Y(0)$。

[因果推断](@article_id:306490)的根本问题在于，我们永远只能看到这两种现实中的一种。这从本质上说，是一个缺失数据问题。我们通过一个关键的假设来解决它，这个假设被称为**无混淆性**（unconfoundedness）或**可交换性**（exchangeability）：即如果我们测量了所有影响治疗决策和结果的相关背景因素（年龄、先前的健康状况、遗传等），那么在相似人群的组内，选择服药的决定基本上是随机的。

这个假设允许我们使用统计工具来估计本会发生什么。其中最优雅的工具之一是**[倾向得分](@article_id:640160)**（propensity score），即在给定所有背景因素的情况下，接受治疗的概率 [@problem_id:1936677]。在这里，我们以最尖锐的形式看到了预测与因果之间的区别。当我们为[倾向得分](@article_id:640160)建立模型时，我们的目标*不是*尽可能准确地预测谁会服药。一个具有高 AUC（预测准确性的度量）的模型可能不是最好的模型。相反，我们的目标是使用[倾向得分](@article_id:640160)来创建加权的处理组和非处理组，使他们在所有背景特征上看起来平均而言是相同的。我们试图使协变量分布达到平衡，模拟一个随机试验。正确的模型是那个能够实现最佳**协变量平衡**（covariate balance）的模型，而不是预测效果最好的模型 [@problem_id:1936677] [@problem_id:3148913]。模型的目的完全不同。

### 小心巧妙的陷阱：[对撞偏倚](@article_id:322998)的危险

即使有了这些强大的思想，这条路仍然充满危险。因果推理中存在一些微妙的陷阱，即使是最谨慎的分析师也可能上当。其中最令人费解的一个是**[对撞偏倚](@article_id:322998)**（collider bias）。

让我们来讲一个故事 [@problem_id:2382965]。一位公共卫生分析师注意到，尽管城市 A 和城市 B 的医院数量相同，但城市 A 的某种疾病死亡率更高。这位分析师草率地得出结论，认为城市 A 的医院肯定更差。

让我们画出因果箭头。一个城市人口中疾病的潜在严重程度（$S$）肯定会导致死亡率（$M$）。我们还假设医院质量（$Q$）会降低[死亡率](@article_id:375989)。所以我们有$S \rightarrow M$和$Q \rightarrow M$。但什么决定了医院的数量（$H$）呢？它很可能受到疾病负担（病情更严重的城市需要更多医院，$S \rightarrow H$）和城市的财富及医疗保健投入（这与医院质量有关，$Q \rightarrow H$）的影响。

“医院数量”这个变量$H$是一个**对撞变量**（collider）——它是一个有两个箭头指向它的变量：$S \rightarrow H \leftarrow Q$。这位分析师犯了一个关键错误：通过只比较*医院数量相同*的城市，她在统计上“控制”了这个对撞变量。而一条奇怪的数学规则表明，控制对撞变量会在其父节点之间产生一种虚假的、非因果的关联。

这样想：在恰好有10家医院的城市组中，考虑一个我们已知其潜在疾病负担极高的城市。为了让它*只有*10家医院，其医疗保健投入和质量必定异乎寻常地低。相反，这个组中一个疾病负担很低的城市，必须有异乎寻常地高的投入才能建起10家医院。控制$H$在疾病严重程度$S$和质量$Q$之间制造了一种虚假的负相关关系。这完全扭曲了质量与[死亡率](@article_id:375989)之间的关系，使得分析师的结论毫无价值。

同样的陷阱也等待着那些研究某个基因对存活率影响的生物学家，如果他们只将分析限制在住院病人身上。因为基因和其他独立的风险因素都可能导致住院，“住院”就是一个对撞变量。只研究这个被选择的群体，可能会在基因和存活率之间建立起一种完全人为的联系，导致科学家们去追逐幻影 [@problem_id:2382965]。

从预测到因果的旅程迫使我们保持谦逊。它提醒我们，数据不会自己说话。它们只会低语暗示并设下陷阱。要理解“如果……会怎样”，我们不仅要思考我们看到的模式，还要思考产生这些模式的隐藏机制——那个塑造我们世界的错综复杂的因果之网。而那是一段比单纯的预测要激动人心得多的旅程。

