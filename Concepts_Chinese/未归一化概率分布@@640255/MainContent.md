## 引言
在科学和数据的世界里，[概率分布](@entry_id:146404)是我们理解的基础，它让我们能够[量化不确定性](@entry_id:272064)并做出预测。理想情况下，这些[分布](@entry_id:182848)是“归一化”的，意味着所有可能结果的总概率为一。然而，在许多最前沿和最有趣的问题中——从[统计物理学](@entry_id:142945)到贝葉斯推断——我们遇到了一个巨大的障碍：我们可以描述一个[分布](@entry_id:182848)的*形状*，但计算归一化所需的最终常数通常在计算上是不可能的。本文深入探讨未归一化[概率分布](@entry_id:146404)的世界， addressing the challenge posed by this "tyranny of the normalization constant." 在接下来的章节中，我们将首先探究这些[分布](@entry_id:182848)出现的原理和机制，并揭示为绕过这一限制而发展的巧妙计算方法，例如[马尔可夫链蒙特卡洛](@entry_id:138779)。之后，我们将遍览一系列广泛的应用，发现物理学家、统计学家和人工智能研究者如何利用这些技术来解决各自学科中的复杂问题。

## 原理与机制

### 难以逾越的[归一化常数](@entry_id:752675)

这些“未归一化”的[分布](@entry_id:182848)从何而来？为什么我们不能从一开始就得到完整、整洁、归一化的版本呢？答案原来是，在许多科学最有趣的角落里，自然界给我们的是关于*相对*概率的规则，而不是绝对概率。

想象一个盒子中有大量的气体分子，都在某个温度 $T$ 下晃动和碰撞。物理学，以[统计力](@entry_id:194984)学的形式，告诉我们关于任何一个粒子能量 $E$ 的一个极其简单的事情。发现它处于某个能量状态的概率与一个简单而优雅的表达式成正比：**玻尔兹曼因子**，$\exp(-E/k_B T)$ [@problem_id:1962007]。这在直觉上非常有道理：能量非常高的状态比能量低的状态出现的可能性呈指数级下降。它为我们提供了一个美丽的概率景观“形状”。例如，一个粒子的动量 $p_x$ 具有动能 $E = \frac{p_x^2}{2m}$，因此其动量分布的形状由 $\exp(-\frac{p_x^2}{2mk_B T})$ 给出——一条优美的[钟形曲线](@entry_id:150817) [@problem_id:1967705]。

但是，具有某一特定动量的*绝对*概率是多少呢？要找到它，我们必须将 $\exp(-E/k_B T)$ 的值对粒子可能处于的*每一个可能状态*进行求和。这个和，如果状态是连续的，则是一个积分，被称为**[配分函数](@entry_id:193625)**，通常用 $\mathcal{Z}$ 表示。它是我们必须除以的数，以确保所有概率之和为一。问题就在这里：这个计算通常是一场噩梦。对于简单的气体，这是可行的。但对于一个复杂的相互作用系统，比如一块磁铁、一个蛋白质，或者一个带有像 $E(x) = x^4$ [@problem_id:2190990] 这样的“能量函数”的[深度神经网络](@entry_id:636170)，计算 $\mathcal{Z}$ 涉及到对一个令人难以置信的巨大数量的状态求和。这在计算上通常是不可能的。

这种困境并非物理学所独有。它也是现代统计学的核心。想象一下你是一名数据科学家，试图了解选举可能会如何结果。你观察到一个地区有 $n$ 名选民，其中 $y$ 人支持你的候选人。你有一个模型——也许是一个复杂的模型，其中成功概率 $p$ 通过一个函数如 $p = \Phi(\theta)$ [@problem_id:816805] 与某个潜在的“情绪”$\theta$ 相关。你对 $\theta$ 可能是什么也有一些先验信念。**[贝叶斯定理](@entry_id:151040)**为你提供了根据数据更新信念的秘诀：

$P(\text{参数} | \text{数据}) \propto P(\text{数据} | \text{参数}) \times P(\text{参数})$

这太棒了。我们只需将[似然函数](@entry_id:141927)乘以先验分布，就能得到参数的后验分布。但等一下——那个小小的“正比于”符号 $\propto$ 隐藏着同一个猛兽。我们得到的是一个*未归一化*的后验分布。为了归一化它，我们需要将右侧对*所有可能的参数值*进行积分。这个积分，被称为**边缘[似然](@entry_id:167119)**或**证据**，通常又是一个高维的、解析上难以处理的怪物 [@problem_id:816805]。

所以，在物理学和[贝叶斯统计学](@entry_id:142472)中，我们常常处于相同的情境。我们有一个函数，称之为 $\tilde{\pi}(x)$，它完美地描述了不同状态或参数值的相对概率。我们知道 $\frac{\tilde{\pi}(A)}{\tilde{\pi}(B)}$ 告诉我们状态 A 比状态 B 可能性大多少。但是，真实的、归一化的概率是 $P(x) = \frac{\tilde{\pi}(x)}{\mathcal{Z}}$，而[归一化常数](@entry_id:752675) $\mathcal{Z}$ 是一个谜。这就像你有一张完美山脉的地形图：你可以看到每一个山峰和山谷，但你不知道“海平面”在哪里。

### 没有 $\mathcal{Z}$ 的生活：一种新的自由

很长一段时间里，这被视为一个主要的障碍。如果不能计算绝对概率，你还能做什么？解开现代计算科学枷锁的绝妙见解是：对于大量问题，你*根本不需要* $\mathcal{Z}$。我们可以学会直接在我们的地形图上工作，这样做，我们获得了一种新的自由。

关键是提出一个不同的问题。我们不再问“处于状态 $x$ 的概率是多少？”，而是问“我如何能生成一组能够*代表*真实[概率分布](@entry_id:146404)的状态集合？”如果我们能解决这个问题，我们就可以通过对我们的样本集合进行平均来近似我们关心的任何属性——均值、[方差](@entry_id:200758)，应有尽有。

这就是**马尔可夫链蒙特卡洛（MCMC）**方法的工作，它们是所有科学中最美丽的技巧之一。

其中最著名的是**[Metropolis算法](@entry_id:137520)**。让我们回到我们的地形图，其中任何一点 $x$ 的高度由我们的未归一化函数 $\tilde{\pi}(x)$ 给出。我们希望以一种方式“行走”于这个景观之上，使得我们在任何区域花费的时间都与其平均高度成正比。它的工作原理如下：

1. 从某个随机点 $x_{current}$ 开始。
2. 提议一个随机“跳跃”到一个附近的点 $x_{proposal}$。
3. 现在，关键的一步。我们是否应该接受这次跳跃？我们检查我们是在地图上“上坡”还是“下坡”。我们计算比率 $r = \frac{\tilde{\pi}(x_{proposal})}{\tilde{\pi}(x_{current})}$。
4. 如果 $r \ge 1$（我们正在上坡或移动到等高点），我们总是接受跳跃。新状态变成 $x_{proposal}$。
5. 如果 $r \lt 1$（我们正在下坡），我们*仍然可能*接受跳跃，其概率等于 $r$。我们抽取一个随机数；如果它小于 $r$，我们就跳跃。否则，我们原地不动。

注意这里的魔力。决策规则仅取决于未归一化密度的*比率*。未知的[归一化常数](@entry_id:752675) $\mathcal{Z}$ đã完全从方程中消失了！[@problem_id:1962669]。这个简单的过程，即总是接受上坡移动并有时接受下坡移动，可以被证明能够生成一系列服从真实、归一化[分布](@entry_id:182848) $\pi(x)$ 的样本点。我们找到了一种在不知道其绝对尺度的情况下正确探索景观的方法。

景观 $\tilde{\pi}(x)$ 的几何形状对这种行走的效率有巨大影响。如果我们的[分布](@entry_id:182848)是一个长而窄的山脊（像一个高度相关的[二元正态分布](@entry_id:165129)），在错误的方向——垂直于山脊——提议的步长几乎总是会被拒绝，导致采样器效率低下。一个沿着山脊移动的聪明提议会成功得多 [@problem_id:1401736]。一个近亲，**[吉布斯采样](@entry_id:139152)**，提供了另一种巧妙的方法来导航复杂的景观，它将一个高维问题分解成一系列一维步骤，在这些步骤中，全局[归一化常数](@entry_id:752675)再次神奇地从计算中消失了 [@problem_id:1338680]。

### 用蛮力（和一点技巧）驯服野兽

但是，如果我们真的需要知道 $\mathcalZ$ 的值，或者某个似乎依赖于它的其他属性，比如我们[分布](@entry_id:182848)的[方差](@entry_id:200758)，该怎么办？MCMC 给了我们样本，但也许我们需要数字本身。在这里，我们必须借助计算机的力量，正面迎击这个积分。

最直接的方法是直接进行[数值积分](@entry_id:136578)。如果我们有一个一维的未归一化密度，如 $\tilde{p}(x) = \exp(-x^4)$，我们可以使用像辛普森法则这样的经典方法来[数值近似](@entry_id:161970)曲线下的面积。这给了我们一个 $\mathcal{Z}$ 的估计值。然后我们可以对 $x^2 \tilde{p}(x)$ 的积分做同样的事情来找到（未归一化的）二阶矩。然后[方差](@entry_id:200758)就简单地是我们第二个积分与第一个积分的比值（因为通过对称性，均值为零）[@problem_id:2190990]。这种方法甚至可以用来构建累积分布函数（CDF）的数值表，然后我们可以反转它来生成随机样本，为MCMC提供了一种替代方案 [@problem_id:3244412]。

对于更高维度，由于“[维度灾难](@entry_id:143920)”，简单的基于网格的积分变得不可能。我们需要更多的技巧。这就是**[重要性采样](@entry_id:145704)（IS）**发挥作用的地方 [@problem_id:3166256]。这个想法既聪明又强大。我们想计算 $\mathcal{Z} = \int \tilde{\pi}(x) dx$。我们不直接评估它，而是引入一个更简单的“提议”[分布](@entry_id:182848) $q(x)$，我们知道如何从中采样，并且可以评估其密度。然后我们将积分重写为：

$\mathcal{Z} = \int \frac{\tilde{\pi}(x)}{q(x)} q(x) dx$

这现在是函数 $\frac{\tilde{\pi}(x)}{q(x)}$ 关于[分布](@entry_id:182848) $q(x)$ 的[期望值](@entry_id:153208)。根据大数定律，我们可以通过从我们的简单[分布](@entry_id:182848) $q(x)$ 中抽取许多样本 $x_i$ 并计算“重要性权重”$\frac{\tilde{\pi}(x_i)}{q(x_i)}$ 的平均值来近似这个期望。

这一系列技术可以变得极其强大。一种称为**[退火重要性采样](@entry_id:746468)（AIS）**的先进方法将此更进一步。如果我们想找到一个非常简单的[分布](@entry_id:182848) $\pi_0$（我们知道 $\mathcal{Z}_0$）和一个非常复杂的[分布](@entry_id:182848) $\pi_1$（我们想求 $\mathcal{Z}_1$）之间的归一化常数之比，AIS 会在它们之间构建一个由许多中间[分布](@entry_id:182848)组成的“桥梁”[@problem_id:3166256]。然后，它使用一种类似[重要性采样](@entry_id:145704)的技巧来估计桥上每一步的比率 $\frac{\mathcal{Z}_{k+1}}{\mathcal{Z}_k}$。通过将所有这些小的比率估计值相乘，我们得到了整个比率 $\frac{\mathcal{Z}_1}{\mathcal{Z}_0}$ 的估计值 [@problem_id:3295512]。这是一个将一个不可能的大[问题分解](@entry_id:272624)成许多小的、可管理问题的优美例子。

最初的限制——未知归一化常数的诅咒——最终成了一种恩赐。它迫使物理学家、统计学家和计算机科学家放弃直接、通常不可能的绝对概率计算。取而代之的是，他们开发了一套丰富而优美的计算方法工具包——MCMC、[重要性采样](@entry_id:145704)及其现代后裔——专注于采样和近似。这种视角的转变使得现代科学的许多领域成为可能，让我们能够探索支配从物质行为到人工智能逻辑的复杂概率景观。

