## 应用与跨学科联系

所有科学，其核心都是一种比较行为。当我们测量长度时，我们将一个物体与标准米尺进行比较。当我们为比赛计时时，我们将选手的用时与铯原子的振荡进行比较。这种与可信标准——即参考——进行比较的行为看似简单。然而，在这个简单的想法中，蕴含着一个充满微妙、挑战和深刻创造力的世界。它是连接人类探究的最不相关领域的无形之线，从破译遗传密码到确保人工智能的安全。当我们超越简单的尺子和时钟，我们会发现选择、验证和使用参考的艺术成为科学家工具箱中最关键的技能之一。

### 看不见的世界：从基因到基因组

想象一下，你是一名医生，试图确定一种强大的新癌症疗法是否有效。该药物靶向一个特定基因，你想看看它的活性是否降低了。一种名为[定量聚合酶链式反应](@entry_id:138509)（qPCR）的强大技术可以让你测量该基因的信使RNA（mRNA）的数量，作为其活性的代表。但你如何公平地比较治疗前和治疗后采集的样本呢？起始材料的量可能不同，或者你实验室操作的效率可能略有变化。

标准的解决方案是使用一个参考：一个“[看家基因](@entry_id:197045)”，它被假设具有完全稳定的活性，无论病人是生病还是健康，接受治疗还是未接受治疗。你测量你的目标基因*相对于*这个稳定的内部基准。这是一个很棒的想法。但如果“后院起火”了呢？这个所谓的“[看家基因](@entry_id:197045)”可能并非在平静地扫地；它可能在疯狂地四处奔波，其自身的活性因疾病或治疗本身而发生了巨大变化。

这并非纯属假设。在临床环境中，例如监测[白血病](@entry_id:152725)中的微小残留病时，一项治疗可能不仅降低了[癌基因](@entry_id:138565)（如*BCR-ABL1*）的活性，也降低了所选参考基因（如*ABL1*）的活性。如果两者都下降了相同的量——比如16倍——它们的*比率*保持不变。当对这个不稳定的参考进行标准化时，测量结果会危险地得出结论：治疗无效，而实际上它取得了惊人的成功[@problem_id:4408064] [@problem_id:4658079]。这个警示故事揭示了基于参考的评估的一个基本原则：**你的参考的好坏取决于它在你实验背景下的稳定性。** 科学界已经制定了严格的指南，例如使用多个经过验证的稳定参考基因，或添加外部人工“外参”控制，以防止被受损的基准所误导[@problem_id:4408064] [@problem_id:4658079]。

参考的挑战从测量世界延伸到为其创造新部件。在寻求新药和新材料的过程中，科学家现在使用[深度生成模型](@entry_id:748264)——一种人工智能形式——[从头设计](@entry_id:170778)新颖的分子和蛋白质。但是，一个计算机生成的分子是一个杰出的新候选药物，还是仅仅是化学上的胡言乱语？要回答这个问题，我们必须将人工智能的创造物与一个庞大的、包含已知、稳定且有效分子的参考数据库进行比较。我们根据三个关键指标评估人工智能的输出：**有效性**（它是否遵守化学定律？）、**独特性**（它是否只是在复制其训练数据？）和**新颖性**（它是否是真正全新的？）。这些指标中的每一个都是一种比较。例如，新颖性被定义为在参考数据集中*未找到*的有效、独特的生成分子的比例[@problem_id:4567930]。在这里，参考为我们提供了一套词汇来描述和量化创新本身。

但当我们试图发现的东西本身*就是*参考时，会发生什么？这就是*从头*基因组组装的巨大挑战。我们有一个新测序生物的数百万个微小、混乱的DNA片段，我们的任务是将它们拼接成完整的基因组——即真实的参考序列。当我们没有最终的图谱可供比较时，我们如何评估我们的组装算法呢？在这里，科学家们采用了一系列引人入胜的代理参考。一个强有力的策略是使用一个独立的、高质量的、用完全不同技术（例如，长读长测序）获得的同一生物的组装体，作为临时的“真实基准”。另一个策略是检查组装体是否包含一组公认的、普遍存在的单拷贝基因（如[BUSCO](@entry_id:170832)s），这些基因预计会出现在任何完整的基因组中。也许最受控的方法是，从一个已知的基因组（来自另一个研究透彻的生物）开始，模拟将其粉碎成短读长的过程，然后让你的算法任务是把它重新拼凑起来。在这个人造的世界里，你拥有一个完美的真实基准，使你能够精确地对算法的性能进行基准测试[@problem_id:2383423]。对基因组的探索变成了一堂大师课，教我们如何使用不完美但巧妙的比较来航向一个未知的真理。

### 校准我们的仪器：从实验室到宇宙

每一次测量都是仪器与现实之间的一次对话。但仪器会漂移。临床实验室中一台精密的分析机器，如[气相色谱-质谱联用](@entry_id:186837)仪（GC-MS），其内部的时间轴可能会因温度或气体流量的微小波动而在一天与另一天之间发生微妙的扭曲。今天在 $9.763$ 分钟出现的药物代谢物测量值，昨天可能出现在 $9.350$ 分钟。为了理解这些数据，我们必须将今天的“仪器时间”转换回一个稳定的、规范的“参考时间”。

解决方案非常优雅。与病人的样本一起，共注入一对“锁定化合物”——稳定的、已知的分子，它们在参考标度上的保留时间是精确已知的。通过观察这些锁定化合物在今天扭曲的时间轴上出现的位置，我们可以推断出发生的确切[线性变换](@entry_id:143080)——拉伸和移动。然后，我们将此校正应用于我们感兴趣的分析物，从而自信地恢复其真实的保留时间[@problem_id:5206957]。这些内部参考充当了路标，使我们能够将测量值从一个漂移的、不完美的世界映射到一个稳定的、普适的图表上。

同样的校准原则，从小小的实验室仪器扩展到人类一些最大、最复杂的计算工具。当工程师设计核反应堆时，他们依赖于模拟[中子输运](@entry_id:159564)复杂物理过程的大型计算机代码。这里的“仪器”是代码本身，其“测量”是对反应堆行为的预测，比如它的有效增殖因子 $k$。我们如何能确定这个极其复杂的模拟是可信的？

我们通过一个**参考层级**来验证它。在这个层级的顶端是现实本身：来自实际运行反应堆的实验数据，例如启动测试期间燃料[温度系数](@entry_id:262493)（FTC）的测量值。这个系数描述了反应性随燃料温度的变化，是由[多普勒效应](@entry_id:160624)决定的一个关键安全参数。将代码预测的FTC与真实世界的测量值进行比较是最终的测试。但我们也可以将其与其他更抽象的参考进行比较。这些包括由OECD/NEA等组织设立的国际公认的基准问题，它们为所有代码提供了一套标准测试套件来解决，或者是来自其他独立的、[高保真度模拟](@entry_id:750285)代码的结果。通过确保模型与这个参考网络——从物理实验到社区基准——相一致，我们对其预测能力建立了信心[@problem_id:4219934]。这种对照已知基线进行基准测试的过程在计算科学中也至关重要，其中新颖算法（如[数值模拟](@entry_id:146043)中的[和因子分解](@entry_id:755628)）的加速效果是通过将其性能与标准的、强力计算的“参考”方法直接比较来量化的[@problem_id:3390232]。

### 人为因素：衡量健康与确保公平

也许最大的挑战在于衡量人类的体验。我们如何量化中风后病人的“功能性活动能力”？对于这样的事物，没有物理的标尺。相反，我们必须构建一个，通常是以问卷或临床结局评估（COA）的形式。但我们如何知道我们新发明的“标尺”是好是坏呢？

我们通过一张比较之网来验证它。首先，我们建立**内容效度**：通过与患者的深入交谈，我们确保问题是相关的、易于理解的，并且它们真正从患者的角度代表了活动能力的概念。接下来，我们通过测试一个假设网络来建立**结构效度**。我们的新活动能力分数应该与其他相关测量（如临床医生的评估分数）有强相关性，但与不相关的概念（如病人的情绪）只有弱相关性。它还应该能够区分已知严重程度不同的患者群体。最后，如果存在一个“金标准”测量，我们通过展示我们的新仪器与之一致来建立**效标效度**[@problem_id:5060731]。从本质上讲，我们正在将我们新的、主观的标尺与一整个既有知识的星座——定性的、临床的和定量的——进行参照，以证明其价值。

这把我们带到了前沿：医疗领域人工智能的评估。当我们构建人工智能系统来帮助医生做出关键决策时，确保其安全性和有效性至关重要。这要求我们构建合成的基准来测试它们——精心设计的人造世界，在其中我们控制“真实基准”并能观察每一个后果。一个用于临床人工智能的强大基准必须是一个熔炉，包含现实世界的挑战，如[混杂变量](@entry_id:199777)（病人的预后影响其治疗）和行动的延迟效应[@problem_id:4424679]。

但更深刻的是，评估指标本身必须参照我们的伦理原则。仅仅让人工智能平均改善患者结局是不够的。我们必须要求它*公平地*这样做。这导致了复杂的[公平性指标](@entry_id:634499)的发展，例如“均等化受益几率”。该指标不只是问人工智能是否对不同人口群体平等地推荐治疗。它提出了一个更聪明的问题：对于那些*真正会*从治疗中受益的患者子集，人工智能是否在各群体间平等地推荐了它？[@problem_id:4424679]。在这里，公平的概念本身是参照个体因果定义的临床需求。这是基于参考的评估的终极表达：不仅确保我们的工具是准确的，而且要将我们的价值观注入其中。

从一个单一的基因到一台机器的良知，故事都是一样的。进步源于比较。知识建立在可信参考的脚手架上。寻找更好的工具、更好的模型和更好的世界，归根结底，是寻找更好、更可靠、更有意义的比较对象。