## 应用与跨学科联系

既然我们已经探究了[并行性能](@entry_id:636399)的齿轮与杠杆——Amdahl的串行[部分和](@entry_id:162077)Gustafson的扩展工作负载——现在让我们退后一步，审视我们试图构建的宏伟机器。我们将要看到一些奇妙的东西。事实证明，让众人协同工作的挑战并非某一科学或工程领域所独有。无论我们是在模拟星系的诞生、预测天气、训练人工智能，甚至是对整个经济进行建模，同样的成功与失败的基本蓝图都会反复出现。

这种统一性的核心是一种美妙而简单的张力，是两种对立力量之间反复的对决。一方面，是我们问题的“体积”——需要执行的纯粹计算量。另一方面，是“表面”——协调我们[分布](@entry_id:182848)在众多处理器上的问题碎片所需的通信。并行扩展的故事就是这场表面与体积之间永恒战斗的故事。

### 原型：网格上的宇宙

也许整个计算科学中最常见的任务就是在网格上模拟事物的变化。想象一块巨大的金属板，某些地方被加热，另一些地方被冷却。为了预测其温度将如何演变，我们可以将这块板切成一个由许多小方块组成的网格。下一刻每个方块的温度只取决于它自身的温度以及其紧邻方块的温度——这是一个优美的局部规则。

当我们将其并行化时，我们给每个计算机处理器分配一小块网格来管理。在一个时间步长内，处理器要完成其工作，只需要知道其邻居网格片最边缘方块的温度。这点信息，通常被称为“晕圈”或“幽灵区”，就是它需要请求的全部信息 [@problem_id:3190082]。剩下的工作它可以在辉煌的隔离中完成。

在这里，我们看到了最纯粹形式的表面积与体积比。计算量与网格片的面积（其二维“体积”）成正比，而通信量与其周长（其“表面”）成正比。当我们使用**强扩展**——保持总板面尺寸固定并增加更多处理器时——每个网格片会变小。[周长](@entry_id:263239)收缩得比面积慢，因此通信与计算的比率变得更糟。最终，我们的处理器会花更多时间在边界上“喋喋不休”，而不是做有用的工作。

但在**弱扩展**中，我们保持网格片大小固定，并增加更多处理器来模拟一个越来越大的板面。在这里，每个网格片的周长与面积之比保持不变！理想情况下，执行一步所需的时间保持恒定。这就是弱扩展的力量：它使我们能够处理越来越大的问题，无论我们是在模拟热流，还是在地球力学模拟中模拟地壳内部的应力，这一原理都适用 [@problem_id:3529521]。

这个简单的想法具有深远的工程意义。邻居之间不断的“闲聊”提出了一个实际问题：对于我们的互连设备，是拥有一个超快的数据高速公路（高带宽，$\mathcal{B}$）更好，还是拥有一个极低的“上匝道”时间（低延迟，$\alpha$）更好？当强扩展使我们的网格片缩小时，消息就成了微小的耳语。时间主要由发送消息的启动成本所主导。但在弱扩展中，由于网格片很大，我们发送的是长长的数据队列，此时高速公路的容量才是关键。这也正是开发像 NVLink 这样的专用互连技术的原因——为了大幅降低延迟，并为其连接的强大 GPU 扩展强扩展的有效范围 [@problem_id:3529521]。

### 更深层次的结构与全局对话

当然，并非所有算法都是如此简单的局部事务。考虑一下[多重网格方法](@entry_id:146386)，这是一种用于[求解方程组](@entry_id:152624)的极其巧妙的方法 [@problem_id:3271542] [@problem_id:3109425]。我们不只在细网格上工作，而是创建一系列越来越粗的网格。在粗网格上，信息只需几步就能传遍整个区域，从而快速解决大尺度误差。然后我们用这个粗网格解来修正细网格解。

这为我们的扩展故事增添了新的复杂性。大部[分工](@entry_id:190326)作仍然是每个网格层级上的局部晕圈交换。但是，下探到最粗的单一网格再返回的过程可能成为一个瓶颈，一个所有并行工作都必须被汇集和重新分配的点。

这就给我们带来了一种新的通信方式，它远比晕圈交换的局部闲聊要求更高：**全局对话**。想象一下，你不是只和你的近邻交谈，而是需要计算整块板的*平均*温度。每个处理器都必须报告其局部平均值，然后一个处理器（或一系列处理器）必须将它们全部相加并做除法。这就是“全局归约”，其成本通常不随数据大小扩展，而是随参与者数量 $P$ 扩展，通常为 $\log P$。

这种全局对话是许多强大算法的阿喀琉斯之踵。著名的预条件[共轭梯度](@entry_id:145712)（PCG）法是[有限元分析](@entry_id:138109)的主力，它在每一次迭代中都需要进行数次这样的全局[点积](@entry_id:149019)计算。在强扩展场景下，随着我们增加更多处理器，并行工作上花费的时间急剧下降，但用于这些全局归约的时间可能几乎不变甚至增加。这种开销，加上像在单个处理器上执行的粗网格求解这样的串行瓶颈，正是强扩展效率不可避免地下降的原因 [@problem_id:2596798]。我们甚至可以为[湍流](@entry_id:151300)的[直接数值模拟](@entry_id:149543)开发复杂的性能模型，来预测一个确切的处理器数量 $P^{\star}$，在该数量下，全局通信（对于基于 FFT 的方法）不断增加的成本会超过进一步[并行化](@entry_id:753104)带来的好处 [@problem_id:3308698]。

### 超越网格：粒子、射[线与](@entry_id:177118)算法选择

世界并不总是一个整齐有序的网格。如果我们正在模拟十亿颗[恒星形成](@entry_id:159940)星系时的旋转之舞呢？在平滑粒子[流体动力学](@entry_id:136788)（SPH）模拟中，基本对象是粒子，而不是网格点。然而，同样的扩展原则依然适用。工作内容包括计算来自附近粒子的力。当我们在处理器之间分配这些粒子时，我们再次面临一个通信问题：如何有效地找到并交换那些空间上彼此靠近但位于不同处理器上的粒子的数据。当我们分析这类模拟的结果时，我们使用完全相同的强、弱扩展效率指标来判断我们的并行代码性能如何 [@problem_id:3270559]。

或许，我们这次巡览中最深刻的教训来自于比较解决同一问题的不同方法。考虑一下在宇宙学中模拟[辐射转移](@entry_id:151695)的挑战——即来自第一批恒星和星系的光是如何在宇宙中传播的 [@problem_id:3479790]。
- 一种直观的方法是**长[特征线法](@entry_id:177800)**：从光源开始追踪每一束光线穿越宇宙。这对扩展性来说是灾难性的。一条光线是一个非局部对象；它可能穿越数百个处理器区域，需要一个复杂而缓慢的通信网络。
- 一种完全不同的方法是 **M1 [矩方法](@entry_id:752140)**。我们不是追踪单个光线，而是在网格上对辐射场的平均量（其能量和通量）进行演化。这些方程更加抽象，但它们具有优美的*局部性*。一个网格单元的更新只依赖于它的邻居。突然之间，这个问题看起来就像我们简单的热方程一样，并且它的扩展性非常好。
- 这个比较教给我们一个至关重要的教训：有时，并行化的关键不在于巧妙的编码，而在于对问题本身的数学表述进行根本性的重新思考。算法的选择可能比任何硬件或软件优化都更重要。

### 新前沿：人工智能与经济学

你可能会认为这一切都只关乎物理学和工程学，这情有可原。但这些扩展定律的美妙之处在于它们的普适性。让我们前往两个完全不同的知识领域。

首先是人工智能。当我们训练一个像驱动现代人工智能那样的巨型[神经网](@entry_id:276355)络时，任务通常非常庞大，必须[分布](@entry_id:182848)在数百个 GPU 上。在一种称为[数据并行](@entry_id:172541)的通用策略中，每个 GPU 处理一批不同的数据（图像、文本等）——这是一个完全并行的任务。但在每一步结束时，它们都必须就如何更新网络参数达成一致。它们必须对各自计算出的梯度求平均值。这是一个全局 **all-reduce** 操作，一次“全局对话”，其精神[实质](@entry_id:149406)与 PCG 中的[点积](@entry_id:149019)或 FFT 求解器中的全对全交换完全相同。并且它受完全相同的扩展定律支配。计算（前向/后向传播）与通信（梯度同步）之间的斗争定义了一个性能阈值，超过该阈值后，增加更多 GPU 会带来递减的回报 [@problem_id:3100033]。

其次是[计算经济学](@entry_id:140923)。现代宏观经济模型，如异质性代理人新凯恩斯（HANK）模型，异常复杂。它们模拟数百万个别家庭和公司的决策，以理解整个经济。我们如何将其[并行化](@entry_id:753104)？我们给每个处理器分配一个家庭[子集](@entry_id:261956)进行模拟——这又是一个完全并行的任务。但在每个周期结束时，我们必须汇总它们的行为来确定利率和通货膨胀等整个经济范围的变量，这些变量随后又会反馈到下一周期的决策中。这种聚合，又一次，是一个归约操作。使用这些模型的经济学家面临着我们一直以来看到的同样选择：我们是使用**强扩展**来*更快地*求解一个固定规模的经济体，还是使用**弱扩展**在相同时间内求解一个*更大、更详细*的经济体[@problem_id:2417902]？

### 一场普适的对话

从恒星的核心到人工智能的逻辑，再到市场的动态，并行扩展的原理提供了一种通用的语言。工作体积与通信表面之间的张力，局部闲聊与全局广播的不同特性——这些主题在各个学科中回响。理解它们并不仅仅是计算机科学家的技术练习。它是现代科学事业的一个基本组成部分。它使我们能够协同利用计算的力量，建立保真度越来越高的模型，并对我们周围的世界提出更大、更深、更大胆的问题。