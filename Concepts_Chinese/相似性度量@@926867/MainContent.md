## 引言
人类感知相似性的能力是智能的基石，它使我们能够识别模式、进行类比并从经验中学习。但如何将这种对“相像”的直观把握转化为机器能够理解的形式化数学语言？这个问题是现代数据科学中的一个关键挑战，因为如何衡量相似性的选择深刻影响着我们能获得的洞见，无论是在诊断疾病、搜索信息还是构建人工智能。本文旨在弥合直觉与形式化之间的鸿沟。第一章“原理与机制”将深入探讨关键相似性度量的数学和几何基础，探索欧几里得距离、余弦相似度和[编辑距离](@entry_id:152711)等度量如何通过定义“相似”的含义来解决特定问题。随后的“应用与跨学科联系”将展示这些概念的普适力量，揭示一种“亲近度演算”如何在生物学、生态学、人工智能甚至道德哲学等不同领域中解锁新发现，并将它们统一在一个共同的分析框架下。

## 原理与机制

我们如何教会机器识别两个事物是相似的？这不仅是一个哲学问题，更是现代科学技术核心的一个深刻的实践问题。无论我们是试图寻找相似的文档、识别相关的基因、根据症状诊断疾病，还是在人群中识别人脸，我们都需要一种形式化的数学语言来描述“相似性”。这种语言由**相似性度量**构建而成，选择正确的度量就像选择合适的镜头来观察世界。错误的选择会让你看到一个扭曲、误导的画面，而正确的选择则能揭示深刻且原本不可见的联系。

### 比较的几何学：从距离到方向

我们对相似性最基本的直觉是距离。如果两个点在空间中很近，它们就是相似的；如果相距很远，它们就是不同的。我们可以用**[欧几里得距离](@entry_id:143990)**（Euclidean distance）将其形式化。如果我们将两个对象表示为数字向量 $x$ 和 $y$，它们的不相似性就是它们之间的直线距离 $\lVert x-y \rVert_2$。这在很多情况下都非常有效。但如果它失效了呢？

想象一下，你有两份临床记录。记录A写着：“患者报告发烧和咳嗽。”记录B则长得多，可能是从模板复制而来，写着：“患者报告发烧和咳嗽。无胸痛。无气短。患者报告发烧和咳嗽。”在一个简单的**[向量空间模型](@entry_id:636039)**中，每个词对应一个维度，其计数或频率（如**[TF-IDF](@entry_id:634366)**）作为该维度的值。这样，记录B的向量会“更长”——它的模会更大。由于长度的差异，记录A和记录B的向量之间的欧几里得距离可能会非常大，这表明它们非常不同。然而，它们的核心主题是相同的。[欧几里得距离](@entry_id:143990)在这里失效了，因为它对我们不关心的文档长度敏感。

这时，一个优美的几何洞见就派上用场了。与其问“这两个向量相距多远？”，我们可以问“它们指向同一个方向吗？”。这可以通过它们之间的夹角来衡量。**余弦相似度**（Cosine similarity）被定义为两个向量 $x$ 和 $y$ 之间夹角的余弦值，
$$
S_C(x, y) = \frac{x \cdot y}{\lVert x \rVert_2 \lVert y \rVert_2}
$$
这正是我们所需要的。如果两个向量指向同一方向，夹角为 $0^\circ$，余弦相似度为最大值 $1$。如果它们正交（没有共同内容），夹角为 $90^\circ$，相似度为 $0$。关键在于，向量的长度被抵消了。我们的两份临床记录，在高维词汇空间中都指向“发烧和咳嗽”这个方向，现在将被视为最大程度地相似。

这揭示了一个基本原则：选择相似性度量就是定义**不变性**（invariances）。我们选择余弦相似度，是因为我们想要一个对向量的模*不敏感*的度量。这个想法是一个强有力的指导原则。在分析[RNA测序](@entry_id:178187)的基因表达数据时，一个主要的混淆因素是每个样本的总读数（文库大小），它会影响整个表达向量的模。为了在忽略这种技术性伪影的同时比较患者间的相对表达模式，余弦相似度是一个绝佳的选择。但如果我们的数据有不同类型的伪影呢？在蛋白质组学中，来自不同实验批次的数据通常会在其数值上存在一个加性“偏移”。欧几里得距离和余弦相似度都对这种偏移不具有不变性。这时，我们可以转向**[皮尔逊相关系数](@entry_id:270276)**（Pearson correlation），它在数学上等同于对*均值中心化*后的向量计算余弦相似度。通过首先从每个向量中减去其均值，我们消除了基线偏移，随后的余弦相似度计算则处理了任何尺度上的差异。因此，皮尔逊相关系数对偏移和尺度都具有不变性，使其成为解决该特定问题的完美工具。

### 当结构至关重要时：超越特征袋模型

[向量空间模型](@entry_id:636039)很强大，但它将所有特征视为一个“袋子”中的独立项目。词袋没有语法；基因图谱没有通路。但在现实世界中，结构往往是意义的关键。一个真正智能的度量必须理解这种结构。

#### 事物的顺序：序列

让我们回到医学搜索引擎的例子。一位医生输入了“hypertensoin”。[词袋模型](@entry_id:635726)会认为这与“hypertension”是一个完全不同的词元（token）。它们的余弦相似度将为零。机器对这个明显的拼写错误视而不见。为了解决这个问题，我们需要一个能理解序列的度量。**[编辑距离](@entry_id:152711)**（Edit distance），例如 Levenshtein 距离，正是为此而生。它衡量将一个字符串转换为另一个字符串所需的最少单字符编辑次数（插入、删除或替换）。“hypertensoin”和“hypertension”之间的距离很小，从而正确地将它们标记为高度相似。在这里，我们看到两种度量扮演着互补的角色：[编辑距离](@entry_id:152711)捕捉印刷和拼写上的变体，而余弦相似度则捕捉词语共享但顺序不同的语义重叠。

这个想法在生物学中变得更加复杂。蛋白质是氨基酸的序列。DNA中的A到G替换是一回事，但这对蛋白质意味着什么？两个化学性质相似的氨基酸之间的替换（例如，异亮氨酸换成亮氨酸，两者都是疏水性的）是一种“保守”变化，可能不会影响蛋白质的功能。而换成一个化学性质差异很大的残基（例如，疏水性的异亮氨酸换成带正电的精氨酸）则可能是灾难性的。简单的百分比一致性（percent identity）将所有错配同等对待，忽略了这一关键的生物化学背景。

在漫长的进化时间尺度上，会发生一种称为**饱和**（saturation）的现象，即同一位点发生多次突变，从而掩盖了真实的进化距离。一个位点可能从A变为G，然后再变回A，尽管发生了两次突变事件，但看起来与其祖先完全相同。此时，百分比一致性成了一个糟糕的、非线性的亲缘关系度量。为了看透这层迷雾，科学家使用像 [BLOSUM](@entry_id:172132) 这样的**[替换矩阵](@entry_id:170141)**（substitution matrices）。这些矩阵是一个[查找表](@entry_id:177908)，包含了所有可能的氨基酸配对的分数，这些分数源于对真实进化模式的观察。它们为可能发生且保守的替换分配高分，为不可能发生的替换分配低分或负分。基于这些矩阵的相似度分数能够捕捉到早已褪去精确一致性呐喊后的、共享祖先的微弱低语。

#### 知识之网：本体

那么那些并[非线性相关](@entry_id:173593)，而是层次相关的概念呢？“室间隔缺损”和“房间隔缺损”是两种不同的病症，但医生知道它们都属于“心间隔缺损”。这种知识被捕获在本体（ontologies）中，它们是概念的[有向无环图](@entry_id:164045)（DAGs）。要在此处测量相似性，我们必须沿着树状结构向上追溯。

一种简单的方法是比较每个术语的所有祖先集合。一个更强大的想法是测量每个术语的**信息内容**（Information Content, IC）。在本体中，像“疾病”这样的一般性术语很常见，因此信息内容较低。而像“致[心律失常](@entry_id:178381)性右室发育不良”这样的特定术语则很罕见，具有较高的IC。我们可以根据两个术语 $t_1$ 和 $t_2$ 的**信息量最丰富的共同祖先**（Most Informative Common Ancestor, MICA）——即具有最高IC的[共同祖先](@entry_id:175919)——来定义它们之间的相似性。例如，**Resnik 相似度**就直接定义为MICA的IC。这优雅地捕捉了一个思想：共享一个非常具体父节点的两个非常具体的术语，远比共享一个非常笼统父节点的两个笼统术语更为相似。

#### 生命的形状：三维结构

最后，让我们考虑物理三维物体（如蛋白质）的相似性。这里最常用的度量是**[均方根偏差](@entry_id:170440)**（Root-Mean-Square Deviation, RMSD），它测量的是在两个结构经过最佳叠加后，对应原子之间的平均距离。但对于一个由柔性[连接子](@entry_id:177005)连接的复杂多结构域蛋白质来说，会发生什么呢？该蛋白质可能存在于“开放”状态和“闭合”状态。各个结构域在结构上可能完全相同，但由于它们相对移动了，全局RMSD会变得巨大，从而错误地表明这两个结构不相关。

这是全局度量失效的又一个例子。解决方案是局部思考。我们可以通过分别比对和比较每个结构域来计算**结构域特异性RMSD**。或者，我们可以使用更高级的算法，如DALI或TM-align，它们不仅关注原子位置，还关注一个折叠结构内部的接触和距离网络。这些方法对核心架构或折叠的保守性很敏感，同时对于会误导简单全局RMSD的[大尺度结构](@entry_id:158990)域运动具有鲁棒性。

### 数据空间的形态：度量、几何与预处理

到现在，应该很清楚了：一个相似性度量定义了我们数据的几何形态。让我们进一步探索这种几何形态。当我们有一个像余弦相似度（$s$）这样的相似性度量时，我们如何将其转换为不相似度或距离（$d$）？一个朴素的选择是 $d = 1-s$。这个转换是单调的，对于排序任务来说通常足够好。但它有一个隐藏的缺陷：它通常不满足**三角不等式**，这是任何真正[距离度量](@entry_id:636073)的一个核心属性，该属性表明绕行的路程不能比直达路径更短（$d(A, C) \le d(A, B) + d(B, C)$）。一个违反此规则的“距离”在使用多维缩放（MDS）等可视化技术时，可能会导致奇怪且无法解释的结果。

对于余弦相似度，至少有两种“正确”的方式来定义一个真正的度量距离。如果我们将单位归一化后的向量视为超球面上的点，那么**角距离** $d = \arccos(s)$ 就是沿球面曲面的真实距离。而**[弦距离](@entry_id:170189)** $d = \sqrt{2(1-s)}$ 则是穿过球体的直线[欧几里得距离](@entry_id:143990)。两者都是合适的度量，并具有清晰的几何意义。

我们数据空间的几何形态不是固定的；我们可以通过预处理来操纵它。以现代人工智能中使用的[词嵌入](@entry_id:633879)为例。它们常常表现出系统性偏差。例如，所有向量可能都朝着一个共同的方向偏离原点，这是一种“各向异性漂移”。这会扭曲它们之间所有的夹角。对数据进行**均值中心化**——即从每个向量中减去平均向量——会将原点移到数据云的中心，从而消除这种共同偏差，并从根本上改变相似性的图景。

此外，数据云可能会像一个椭圆一样被拉伸，某些维度的方差远高于其他维度。**白化**（Whitening）是一种变换，它通过重新缩放空间，使数据云呈球形或各向同性。它能去除维度间的相关性，并使它们具有相等的方差。这同样会深刻地改变几何形态，以及我们随之使用的相似性度量。这里的教训是，相似性不是原始数据的内在属性，而是数据在选定坐标系内的属性。

### 最终校准：从分数到证据

我们已经看了一系列令人眼花缭乱的度量，每一种都针对特定类型的数据和结构量身定制。当我们使用其中几种来分析一个复杂问题时，会发生什么？比如，利用不同类型的生物数据来为一种罕见病筛选候选基因。我们可能从[蛋白质序列分析](@entry_id:175250)中得到50的相似度分数，而从表型本体比较中得到0.8的分数。我们如何组合它们？50是个大数吗？0.8是个大数吗？没有上下文，原始分数是毫无意义的。

最后，也是最关键的一步是**校准**（calibration）。我们必须将这些任意的分数放在一个通用的、有意义的尺度上。主要有两种方法可以做到这一点。

1.  **统计标准化**：对于每种度量，我们可以通过计算大量随机数据对的分数来生成一个“零分布”。这告诉我们偶然情况下预期的分数是多少。然后我们可以计算这个[零分布](@entry_id:195412)的均值（$\mu$）和标准差（$\sigma$）。我们得到的真实分数 $s$ 可以转换为一个**z分数**（z-score）：$z = (s - \mu) / \sigma$。z分数不再是任意单位；它衡量的是统计上的意外程度。一个3.0的z分数意味着“这个观测值与我偶然预期的值相差3个标准差”，而无论它来自哪个原始度量。这些可比较的z分数现在可以有意义地进行组合。

2.  **[概率校准](@entry_id:636701)**：一个更强大的方法是，如果我们有带标签的“基准真相”（ground truth）数据，就可以学习一个函数，将原始分数直接映射到一个概率。利用逻辑回归等技术，我们可以找到一个从分数 $s$ 到例如两个项目真正相关的[对数优势比](@entry_id:141427)（log-odds）的映射。一个50分的分数不再仅仅是“50”，它变成了“存在真实关联的概率为75%”。这些来自不同证据来源的概率或对数优势比，随后可以运用贝叶斯统计的严谨规则进行组合，得出一个统一的[置信度](@entry_id:267904)。

这就是最终目标：将一个简单的、机械的相似性度量，转化为一个经过校准、可解释的证据。从简单的距离计算到组合的概率分数的这个过程，证明了深入思考“两个事物相似”的真正含义是多么丰富和强大。

