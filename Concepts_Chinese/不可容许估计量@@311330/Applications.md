## 应用与跨学科联系

既然我们已经掌握了风险、优控和可容许性的机制，你可能会认为这不过是统计学家们玩的一种深奥游戏，一种拘泥于形式的练习。但事实远非如此！可容许性的概念不仅仅是统计学上的讲究；它是一种理性的基本原则，在科学和工程的许多意想不到的角落里都能听到它的回响。它的核心是，避免犯下可被证明的愚蠢错误。如果你有两种玩游戏的策略，其中一种保证得到的分数永远不会比另一种好，有时甚至更差，你会选择哪一种？明知故犯地选择[劣势策略](@article_id:299586)，在某种意义上是非理性的。[不可容许估计量](@article_id:355828)正是这些[劣势策略](@article_id:299586)，我们现在的任务是看看它们隐藏在何处，以及它们的发现教会了我们关于知识本质的什么。

### 简单直觉的背叛

我们初次接触不可容许性时，往往会粉碎一些我们最珍视的统计直觉。例如，我们很早就学到，当我们对某个量进行多次独立同分布的测量时，应该给予它们同等的权重。如果我们有两个对均值 $\mu$ 的测量值 $X_1$ 和 $X_2$，我们凭什么会更相信其中一个而不是另一个呢？像 $0.3X_1 + 0.7X_2$ 这样的估计量似乎不平衡、不对称。的确，数学证实了这一强大的直觉。简单的平均值 $0.5X_1 + 0.5X_2$ 对于*任何*可能的真均值和方差，都具有更小的[均方误差](@article_id:354422)。不等权重的估计量是不可容许的；它被证明在所有情况下都更差 [@problem_id:1894906]。在这里，我们的直觉得到了证实：对称性很重要。

但是等等！正当我们感到自信时，却遇到了一个障碍。关于估计量应该是“无偏的”——即平均而言，它应该命中真值——这个想法又如何呢？这当然是好策略的基石。好吧，让我们看一个简单的问题：从一个服从 $U(0, \theta)$ 的[均匀分布](@article_id:325445)中抽取单个样本 $X$ 来估计上界 $\theta$。[无偏估计量](@article_id:323113)是 $2X$。这是有道理的，因为 $X$ 的平均值是 $\frac{\theta}{2}$。然而，这个无偏估计量是不可容许的！可以证明，另一个有偏的估计量 $\frac{3}{2}X$ 对每一个可能的 $\theta$ 值都具有更低的风险 [@problem_id:1894912]。我们被迫用一点偏差换取方差的大幅减少，从而得到一个整体上更好的估计量。这个教训是深刻的：坚决拒绝接受任何偏差可能是一个失败的策略。有时，瞄准靶心稍偏的位置，是确保你的射击平均更接近靶心的最佳方式。

这种直觉的背叛并未停止。考虑估计泊松过程的速率 $\lambda$。标准的、[最大似然](@article_id:306568)的估计就是你观察到的事件数 $X$。如果我们决定“乐观”一点，总是估计为 $X+1$ 呢？我们的猜测当然会有偏，但也许它有其他可取之处？没有。它的风险在所有情况下都比只用 $X$ 要高。它是不可容许的 [@problem_id:1894884]。对于像 $X - 1/2$ 这样的“悲观”估计量也是如此 [@problem_id:1894879]。这些简单的调整，在某些情境下可能看起来合理，但从各个角度来看都是失败的方案。有时，最简单的估计量确实最难被击败。而有时，就像用 $1/X$ 估计指数过程的速率一样，一个看起来“自然”的估计量可能差到其[期望](@article_id:311378)误差为无穷大，使其以最戏剧性的方式成为不可容许的 [@problem_id:1894911]。

### 压缩的无理有效性：斯坦悖论

到目前为止的例子都是关于一维问题的。当我们进入更高维度时，故事变得更加离奇，也更加美丽。这是 Charles Stein 的世界，他的发现是所有现代统计学中最令人震惊和富有哲学意义的结果之一。

让我们用一个简单的抛[硬币问题](@article_id:641507)来热身。我们有一枚硬币，正面朝上的概率 $p$ 未知，我们抛掷 $n$ 次，观察到 $X$ 次正面。对 $p$ 的标准估计是[样本比例](@article_id:328191) $\hat{p} = X/n$。这个估计量是可容许的吗？几十年来，所有人都这么认为。它是无偏的、[最大似然](@article_id:306568)的、符合常识的答案。但如果我们把它与一个“压缩”估计量——一个将估计值稍微拉向中心，即拉向 $1/2$ 的估计量——相比呢？例如，像 $\frac{X+2}{n+4}$ 这样的估计量 [@problem_id:1894905]。这个新估计量是有偏的。如果真实的 $p$ 是，比如说 $0.1$，这个估计量会倾向于猜测一个高于 $0.1$ 的值。但通过引入这种偏差，它极大地减小了方差。当我们考察均方误差时，一件非凡的事情发生了：对于中心附近的一大片真实 $p$ 值，这个压缩估计量更好！它并非在所有情况下都更好——对于非常接近 $0$ 或 $1$ 的 $p$ 值，标准估计量胜出。所以标准估计量并非不可容许。但我们确定性的堡垒上出现了一道裂缝。将估计值拉向一个[中心点](@article_id:641113)的想法似乎有其可取之处。

现在，地震来了。想象一下，你不是要估计一个量，而是要同时估计三个或更多不相关的量。比方说，我们正在测量开罗的真实平均夏季温度（$\theta_1$）、一个特定电子的质量（单位：千克）（$\theta_2$），以及美国职业棒球大联盟一场比赛中平均打出的本垒打数（$\theta_3$）。我们对每个量各得到一个测量值：$X_1$、 $X_2$ 和 $X_3$。估计向量 $\boldsymbol{\theta} = (\theta_1, \theta_2, \theta_3)$ 的标准、“显而易见”的方法是直接使用我们的测量值：$\boldsymbol{\delta}_0 = (X_1, X_2, X_3)$。这是[最大似然估计量](@article_id:323018)，两个世纪以来它被认为是唯一理智的选择。棒球统计数据怎么可能帮助我们估计电子的质量呢？

1956年，Charles Stein 证明了这个估计量是不可容许的。他构建了一个替代估计量，现在称为 James-Stein 估计量，它具有一致更低的总[均方误差](@article_id:354422)。这个新估计量取观测向量 $\boldsymbol{X} = (X_1, X_2, X_3)$ 并*将其向原点 $(0,0,0)$ 压缩*。公式大致如下：
$$ \boldsymbol{\delta}_{JS}(\boldsymbol{X}) = \left(1 - \frac{c}{\|\boldsymbol{X}\|^2}\right)\boldsymbol{X} $$
这个公式说，把你所有三个完全不相关的测量值混合在一起，用来估计其中的每一个。这意味着你可以通过使用关于棒球和电子的数据来获得对开罗温度更好的估计。这如此反直觉，感觉就像一个逻辑悖论。然而，数学是无可否认的。通过组合和压缩我们的估计，我们在每个估计中引入了一点偏差，但却在方差减小方面获得了巨大的回报，导致总误差*总是*更小。

故事甚至还没有结束。James-Stein 估计量，这个[最大似然估计量](@article_id:323018)（MLE）的“杀手”，本身也是有缺陷的。它有一个奇怪的特性：如果测量值非常接近于零，[压缩因子](@article_id:306400)可能变为负数，导致估计量指向与测量值相反的方向！一个简单的修正是“正部”James-Stein 估计量，它只是阻止[压缩因子](@article_id:306400)低于零。这个正部版本优控了原始的 James-Stein 估计量。但是——这是一个真正深刻理论的标志——即使是这个改进后的估计量也是不可容许的！它的压缩规则在过渡到零的地方有一个“尖角”，事实证明，人们可以构建一个具有更平滑压缩规则的、更好的估计量，从而在风险上提供一致的改进 [@problem_id:1956799]。寻找“最佳”估计量的旅程是一场不断增加精妙性和改进的征途。

### 在其他领域的回响：结构、几何与人工智能

可容许性原则并不仅限于参数估计的抽象世界。它出现在任何我们需要基于不完整信息做决策的地方，特别是当我们对问题的结构有某些先验知识时。

想象一下，我们正在测量两个量 $\mu_1$ 和 $\mu_2$，并且我们确切地知道 $\mu_1 \le \mu_2$。例如，$\mu_1$ 可能是对安慰剂的平均反应，而 $\mu_2$ 可能是对一种新药的平均反应。我们进行测量得到 $X$ 和 $Y$。标准估计就是 $(X, Y)$。但如果我们的数据恰好是 $X > Y$ 呢？我们的估计违反了已知的顺序。照原样报告它似乎是愚蠢的。这个直觉的数学严谨版本是将我们的估计投影到约束成立的空间上，例如，如果它们顺序不对，就取两者的平均值。这个新的“等渗”估计量，尊重了我们先验知识的几何结构，结果证明它一致优于标准估计量。标准估计量之所以不可容许，是因为它未能整合已知的结构信息 [@problem_id:1894888]。

也许最令人惊讶的联系在于一个完全不同的领域：人工智能和机器人学。考虑 A*（A-star）[算法](@article_id:331821)，一种寻找两点之间[最短路径](@article_id:317973)的著名方法，就像一个机器人在迷宫中导航一样 [@problem_id:1496523]。该[算法](@article_id:331821)通过一个函数 $f(n) = g(n) + h(n)$ 来确定路径的优先级来探索迷宫，其中 $g(n)$ 是从起点到当前节点 $n$ 的已知成本，而 $h(n)$ 是一个*启发式*——一个有根据的猜测——即从 $n$ 到目标的成本。

要保证 A* [算法](@article_id:331821)能找到真正的最短路径，其启发式函数必须是*可容许的*。那么什么是可容许的启发式函数呢？它是一个*从不*高估到目标的真实成本 $h^*(n)$ 的函数 $h(n)$。也就是说，对于所有节点 $n$，必须满足 $h(n) \le h^*(n)$。

这种相似性令人惊叹。在统计学中，一个不可容许的估计量是存在更好替代品的估计量。在人工智能中，一个不可容许的启发式（有时会高估成本）可能导致[算法](@article_id:331821)找到一条次优路径。欧几里得直线距离是平面上寻路的一个可容许启发式，因为最短路径永远不会比直线短。然而，[曼哈顿距离](@article_id:340687)（$|x_1 - x_2| + |y_1 - y_2|$）对于欧几里得寻路来说是不可容GLISH的，因为它可能高估对角线路径的长度。正如在统计学中一样，可容许性充当了最优性的基本保证。它是一种“知情乐观”的原则。启发式函数必须对其余路径保持乐观，就像一个好的估计量必须明智地平衡各种可能性，而不会以一种可被证明是劣等的方式变得不必要的悲观或有偏。

从我们测量的对称性到斯坦悖论，从约束的几何学到[机器人导航](@article_id:327481)的逻辑，可容许性的概念是一条贯穿始终的线索。它教导我们，直觉是一个强大的向导，但也是一个善变的主人；以不明显的方式组合信息可以具有惊人的力量；以及，仅仅要求自己不犯可被证明的错误，就能引导我们走向关于世界深刻而美丽的真理。