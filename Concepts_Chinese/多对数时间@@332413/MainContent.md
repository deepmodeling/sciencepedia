## 引言
[并行计算](@article_id:299689)的承诺——通过使用更多处理器来更快地解决大规模问题——取决于一个关键且常常被忽视的因素：问题的内在结构。虽然有些任务可以通过[分而治之](@article_id:336911)以近乎完美的效率完成，但其他任务则受到长顺序依赖链的制约，这使得大量的计算资源变得无用。本文旨在解决一个根本性挑战：识别哪些问题是真正可并行的，哪些不是。它为这种区分提供了一种形式化语言，其根基在于[多对数时间](@article_id:327146)的概念。在接下来的章节中，我们将首先在“原理与机制”中深入探讨理论基础，定义用于可高效并行化问题的 NC 类，并探索由 [P-完全性](@article_id:330676)所代表的“顺序性之墙”。随后，“应用与跨学科联系”将展示这些抽象思想如何在算术、[图论](@article_id:301242)及其他领域的具体问题中体现，揭示计算的“并行灵魂”。

{'sup': '4', '#text': '## 原理与机制\n\n要真正掌握[并行计算](@article_id:299689)的能力与局限，我们必须超越“处理器越多，[速度](@article_id:349980)越快”这一简单观念。事实证明，计算世界受一条更深层次的原则支配：[信息流](@article_id:330830)的结构。有些问题如同宽而浅的河流，无数水滴可同时顺流而下。另一些问题则像蜿蜒狭窄的峡谷，每一滴水都必须紧随前一滴。**[多对数时间](@article_id:327146)**的概念正是我们用以区分这两者的数学显微镜。\n\n### 什么是“快速”[并行算法](@article_id:335034)？\n\n想象一下，你有一百万名工人来建造一座金字塔。如果设计允许在奠基时同时铺设一百万块砖石，那么第一天你就能取得惊人的进展。但如果设计规定第100层必须在第99层完工后才能开始，那么你庞大的劳动力对于加快垂直建造过程就毫无用处了。整个工程的时间并非受限于工人的数量，而是受限于这条依赖链的长度。\n\n在计算中，这个依赖链的长度就类似于并行执行时间。一个“快速”的[并行算法](@article_id:335034)，其依赖链即使在输入规模极大时也异常之短。这正是**[多对数时间](@article_id:327146)**概念的用武之地。如果一个[函数增长](@article_id:331351)的阶数为 $(\\ln n)^k$（其中 $n$ 是输入大小，$k$ 是某个常数），那么它就是多对数的。这是一个令人难以置信的缓慢增长率。对于十亿个项目的输入，其自然对数仅约为 20.7。即使将其四次方，结果也小于 200,000。当输入规模爆炸式增长时，时间几乎没有变化。\n\n这一洞见催生了[计算复杂性理论](@article_id:335860)中最重要的类别之一：**NC**，或称“Nick 类”。如果一个问题可以使用[多项式](@article_id:339130)数量的处理器（例如 $n^2$ 或 $n^6$，一个“合理”的数量）在[多对数时间](@article_id:327146)内解决，那么它就属于 **NC** 类。例如，如果一个问题可以在 $T(n) = 3(\\ln n)^4 + 80(\\ln n)^3$ 时间内用 $P(n) = n^6 + 10n^2$ 个处理器解决，那么它的[时间复杂度](@article_id:305487)主要由 $(\\ln n)^4$ 项决定，而处理器数量是[多项式](@article_id:339130)的。这使其明确地属于 **NC'}

