## 应用与跨学科联系

在我们迄今为止的旅程中，我们已经剖析了[卷积神经网络](@entry_id:178973)，理解了它的齿轮和杠杆——滤波器、[池化层](@entry_id:636076)，以及[参数共享](@entry_id:634285)与[平移等变性](@entry_id:636340)的美妙舞蹈。我们已将其视为一种用于观察的机器。但要真正欣赏它的力量，我们现在必须将目光从机器本身移开，通过它的眼睛看世界。我们会发现，“图像”的概念远比我们想象的要广阔和灵活，而滑动模式检测器这个简单的想法已经渗透到科学最意想不到的角落，不仅改变了我们解决问题的方式，也改变了我们思考问题的方式。

### 超越像素：世界即图像

卷积模型的胜利始于照片——代表[光强度](@entry_id:177094)的二维像素网格。但如果我们能将其他类型的[数据表示](@entry_id:636977)为网格呢？如果“像素”不是颜色，而是别的东西呢？

#### 一维“图像”：解读生命与物质的密码

让我们首先将我们的世界从二维压平到一维。想象一个文本字符串。这是一个一维的字符网格。现存最重要的文本之一是基因组，一个用 DNA 的四字母表（A、C、G、T）书写的序列。在合成生物学中，科学家设计定制的 DNA 序列来控制细胞，其中一个关键组成部分是核糖体结合位点（RBS），其序列决定了产生多少蛋白质。一个强的 RBS 就像一个引人注目的标题，能吸引[核糖体](@entry_id:147360)的注意，而一个弱的 RBS 则容易被忽略。

CNN 如何学习阅读这种遗传语言并预测 RBS 的强度？我们可以将序列转化为一维“图像”。每个[核苷酸](@entry_id:275639)变成一个由[向量表示](@entry_id:166424)的“像素”（一种称为[独热编码](@entry_id:170007)的技术）。然后，一个一维卷积滤波器，也许只有几个“像素”宽，沿着这个序列滑动。它在寻找什么？它在学习发现“模体”——DNA 中短小的、重复出现的模式，这些模式是这种分子语言的语法规则。正如一个二维滤波器可能学会识别毛皮的纹理，一个一维滤波器学会识别强[核糖体结合位点](@entry_id:183753)的特征 [@problem_id:2032482]。通过堆叠这些滤波器，网络可以学习一套复杂的规则层次，从简单的模体到它们的远距离语法，并最终预测序列的功能。

这个想法从离散序列延伸到连续信号。考虑一位化学家试图通过[质谱仪](@entry_id:274296)的输出来识别分子。该机器产生一张谱图：[离子强度](@entry_id:152038)与[质荷比](@entry_id:195338)的关系图。这张谱图是分子的独特指纹。我们可以通过将信号[分箱](@entry_id:264748)成离散的像素，将这张谱图视为另一幅一维“图像”。现在，一个一维 CNN 可以沿着谱图滑动其滤波器。在这种情况下，卷积变成了一种高效的“[匹配滤波](@entry_id:144625)”。网络学习不同分子的理想[光谱](@entry_id:185632)形状——即它们的指纹。当它看到来自真实样本的充满噪声的复杂谱图时，其学到的滤波器可以挑选出熟悉的模式，以惊人的准确性识别出存在的分子 [@problem_id:2413437]。从 DNA 的离散密码到化学的连续信号，卷积模型证明了自己是解读一维数据的大师。

#### 科学图像：从组织到断层图

回到二维世界，科学领域充满了并非假日快照的图像。在追求[个性化医疗](@entry_id:152668)的过程中，病理学家检查癌症肿瘤的显微镜载玻片。这些图像蕴含着关于患者预后的线索。但这些线索是什么？它们通常是成千上万个细胞空间[排列](@entry_id:136432)中的微妙模式，一种人类难以量化的疾病“纹理”。在这里，二维 CNN 成为[病理学](@entry_id:193640)家的放大镜。它可以在已知治疗结果的患者图像上进行训练——即对特定疗法有“响应者”和“无响应者”。网络学会看到与成功或失败相关的无形[细胞结构](@entry_id:147666)，例如，肿瘤细胞和免疫细胞是如何混合在一起的 [@problem_id:1457734]。它看到的不是“细胞”；它看到的是预测性模式，为医生帮助为合适的病人选择合适的治疗方案提供了强大的工具。

为何要止步于二维？现代显微技术，如[冷冻电子断层扫描](@entry_id:202972)，使我们能够以绚丽的三维形式对细胞内容物进行成像，生成一幅三维“图像”或[断层扫描](@entry_id:756051)图。神经科学家用它来绘制突触——神经元之间的连接点——的复杂机制。一幅[断层扫描](@entry_id:756051)图是一个拥挤、混乱的膜和分子的世界。手动识别和追踪每一个突触小泡——储存[神经递质](@entry_id:140919)的微小囊泡——是一项艰巨的任务。然而，一个三维 CNN 可以深入这个分子迷宫。它使用三维滤波器来学习囊泡的特征性大小、形状和纹理。然后它可以在整个三维空间中穿梭，自动分割和计数成千上万个囊泡，其速度和一致性是任何人类都无法比拟的 [@problem_id:2757150]。CNN 就像一个不知疲倦的自动化助手，在神经科学的前沿加速了发现的步伐。

### 网格的局限：当数据不是图像时

CNN 的力量似乎近乎无限。但它的魔力建立在一个关键的、常常是隐含的假设之上：数据存在于一个固定的、有意义的网格上。位置 $(i, j)$ 的像素总是与位置 $(i+1, j)$ 和 $(i, j+1)$ 的像素相邻。这种邻接关系是局部性的基础。当我们试图将 CNN 应用于这种假设不成立的数据时，会发生什么？

考虑一个细胞中相互作用的蛋白质网络。我们可以将其表示为一个图，并写出该图的邻接矩阵 $A$，其中如果蛋白质 $i$ 和蛋白质 $j$ 相互作用，则 $A_{ij}=1$。这个矩阵是一个二维数字网格——为什么不把它当作图像，然后输入 CNN 来寻找模式，比如相互作用的蛋白质社群？

这是一个灾难性的想法 [@problem_id:3198596]。邻接矩阵中行和列的顺序是完全任意的。我们可以打乱蛋白质的标签，这将对矩阵的行和列进行[置换](@entry_id:136432)，从而创建出一幅看起来完全不同的“图像”。然而，底层的图及其属性保持完全相同。一个依赖于网格固定空间关系的标准 CNN 会对此感到完全困惑。它在原始矩阵中某个位置学到的模式现在被分散到[置换](@entry_id:136432)后的矩阵各处。CNN 不具备[置换不变性](@entry_id:753356)。

这个“失败”极具启发性。它告诉我们我们工具的边界在哪里。CNN 不是一个通用的模式查找器；它是一个处理网格状数据的专家。它迫使我们提出一个更深层次的问题：我们数据的基本结构是什么？如果它是一个网格（如图像或序列），CNN 是一个自然的选择。如果它是一个没有内在顺序的图，我们就需要一种不同的工具——一种旨在尊重数据拓扑结构的工具，这催生了一类全新的模型，称为图神经网络。

### 被释放的卷积思想

故事并没有随着 CNN 的局限性而结束。事实上，理解其核心原则使我们能够将其与其他领域联系起来，甚至将其整合到更复杂的推理系统中，揭示了跨科学学科的美妙统一性。

#### 手工构建与学习得到的对称性：来自物理学的视角

在物理学和化学中，对称性的概念至关重要。在构建一个模型来预测原子系统[势能](@entry_id:748988)时，物理学家不会从零开始。他们知道能量必须对某些变换保持不变：在空间中平移或旋转整个系统，或者交换两个相同原子的标签，都不应改变能量。几十年来，科学家们手工制作了内置这些对称性的数学函数。例如，著名的 [Behler-Parrinello](@entry_id:177243) [神经网络势](@entry_id:752446)通过一组“以原子为中心的[对称函数](@entry_id:177113)”（ACSFs）来描述每个原子的局部环境，这些函数通过其构造本身就对旋转和[置换](@entry_id:136432)具有不变性 [@problem_id:2456307]。

这与 CNN 的哲学形成了有趣的对比。一个标准的 CNN 滤波器*不*具有[旋转不变性](@entry_id:137644)。它从数据中学习特征，但默认只拥有[平移等变性](@entry_id:636340)。这在科学建模的核心提出了一个深刻的问题：我们何时应该像物理学家处理 ACSF 那样， painstaking地将宇宙已知的对称性手工构建到我们的模型中？我们又何时可以依赖像 CNN 这样强大的通用学习器，仅从数据中发现相关模式，或许借助[数据增强](@entry_id:266029)（例如，向其展示同一对象的旋转版本）？这两个世界之间的比较揭示了，CNN 是关于先验知识和对称性在构建现实模型中作用的更宏大对话的一部分。

#### CNN 作为团队成员：[多模态学习](@entry_id:635489)

在现实世界中，信息很少来自单一来源。一次敏锐的诊断可能涉及查看[医学影像](@entry_id:269649)、阅读实验室报告和倾听患者的陈述。现代人工智能系统正在学习做同样的事情，而 CNN 正是这些多模态团队中的明星球员。

考虑一下空间转录组学这个革命性领域，它可以在一片组织切片内的不同位置测量数千个基因的表达，同时还提供该切片的高分辨率[组织学](@entry_id:147494)图像。为了理解组织的复杂微观结构——例如，在[淋巴结](@entry_id:191498)中识别 T 细胞区与生发中心——我们需要融合这两个数据流。一种强大的方法是使用一个二维 CNN 作为“视觉专家”，从每个位置的[组织学](@entry_id:147494)图像块中提取特征，而另一个模型（可能是一个简单的多层感知机或更先进的图网络）则作为“基因组学专家”来处理基因计数。它们提取的特征随后可以被组合或“融合”，使系统能够基于组织在空间中每一点的*外观*和其基因的*活动*来做出决策 [@problem_id:2890024]。

同样，为了预测一个蛋白质的功能，我们可以查看它的[氨基酸序列](@entry_id:163755)——即它的[一级结构](@entry_id:144876)——我们也可以查看它在细胞内的相互作用伙伴网络——即它的社交环境。一个一维 CNN 是解读序列和识别关键功能模体的完美工具。一个[图神经网络](@entry_id:136853)是分析相互作用网络的完美工具。通过将 CNN 的输出作为 GNN 的初始特征，我们创建了一个强大的[端到端模型](@entry_id:167365)，该模型能同时从两种模态中学习，从而获得比任何单一模态都深刻得多的理解 [@problem_id:2373327]。在这些系统中，CNN 不是一个独立的预测器，而是一个更全面智能系统中的重要[感觉器官](@entry_id:269741)。

#### 学习推理：展开的算法

也许最令人费解的应用是，CNN 不再只是一个静态函数，而是成为一个算法的动态组成部分。信号处理和[计算成像](@entry_id:170703)中的许多经典算法，比如用于从原始传感器数据重建 MRI 扫描的算法，都是迭代式的。它们从一个带噪声的猜测开始，并通过多个步骤逐步精炼。每一步都包含一个固定的数学运算。

“[算法展开](@entry_id:746359)”的思想是，将这样一个迭代过程的步骤“展开”成一个深度网络的层。但这里的转折在于：我们用小型的、可学习的 CNN 来替代固定的数学运算 [@problem_id:3456568]。网络的架构现在镜像了经典算法的数据流，但运算本身是从数据中优化的。CNN 学会了执行每个精炼步骤的完美的、数据驱动的方式。这将经典算法的原则性结构与[深度学习](@entry_id:142022)的[表达能力](@entry_id:149863)结合起来，在解决复杂的[逆问题](@entry_id:143129)方面取得了最先进的成果。CNN 不再仅仅是分类图像；它正在学习体现数学推理的一个步骤。

然而，即使具备这些惊人的能力，我们也必须以一种谦逊的态度结束，这是 Feynman 本人也会欣赏的一课。一个经过训练的 CNN 可以非常准确地预测一个增强子 DNA 序列是在神经元中还是在肝细胞中活跃 [@problem_id:2382340]。它学会了与每种情境下活动相关的[序列模体](@entry_id:177422)。但该模型对神经元或肝细胞*是什么*没有真正的理解。它不知道定义那些细胞的不同[转录因子](@entry_id:137860)或[染色质状态](@entry_id:190061)。它的知识是一幅辉煌但脆弱的、在其被喂养的数据中发现的相关性地图。它可以预测，但它并不能真正解释。

卷积模型，诞生于识别网格上模式的简单愿望，已被证明是现代科学中最富饶的思想之一。它给了我们新的眼睛去看待生命和物质的基石，提供了一种连接不同领域的语言，甚至开始重塑我们对算法可以是什么的理解。它的历程证明了一个简单而优美的思想在科学世界中荡起涟漪、改变其所触及的一切的力量。