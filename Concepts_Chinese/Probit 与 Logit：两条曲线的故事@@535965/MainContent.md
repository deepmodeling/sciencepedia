## 引言
对[二元结果](@article_id:352719)——“是”或“否”、“成功”或“失败”——进行建模，是贯穿科学和工业界的一项基本任务。从预测病人是否会对治疗产生反应，到顾客是否会购买商品，理解这些选择的能力具有不可估量的价值。完成这项工作的两种最主要的工具是 probit 和 logit 模型。乍一看，它们几乎完全相同，都能生成类似的 S 形曲线，并且常常得出几乎无法区分的预测。这种相似性引出了一个关键问题：为什么会有两种截然不同的模型，以及在何时两者之间的选择才真正重要？

本文将踏上一段揭开 probit 与 logit 之间关系的神秘面纱的旅程。我们将超越表面的相似性，去发掘将它们区分开来的深层理论差异和实际后果。首先，在“原理与机制”部分，我们将探索两种模型的理论核心，引入优美的[潜变量](@article_id:304202)概念，并揭示关于随机噪声的一个[简单假设](@article_id:346382)差异如何导致系数尺度和解释上的关键不同。然后，在“应用与跨学科联系”部分，我们将看到这些理论在实践中的应用，穿越遗传学、经济学和人工智能等领域，见证模型曲线之间的细微差异如何能导致从疾病风险到[机器人学](@article_id:311041)习过程等各种不同结论。

## 原理与机制

### [潜变量](@article_id:304202)的秘密世界

想象一下你正在决定是否要买一本新书。你的决定是一个简单的“是”或“否”，一个二元选择。但在这个简单的选择之下，隐藏着一个复杂的、连续的计算过程。你可能会权衡作者的声誉、书籍的类型、价格、你可用的空闲时间以及朋友的评价。原则上，你可以将所有这些因素组合成一个单一的、内在的“购买分数”。如果这个分数超过了你个人的某个热情阈值，你就会买下这本书；如果没超过，你就会把它留在书架上。

这正是 **probit** 和 **logit** 模型背后那个优美而统一的思想。它们都假设，对于我们在世界上看到的每一个[二元结果](@article_id:352719)——贷款是否违约、病人是否对治疗有反应、[半导体](@article_id:301977)芯片是否通过测试——都存在一个隐藏的、不可观测的连续变量在驱动着结果 [@problem_id:1919855]。我们称之为**[潜变量](@article_id:304202)**，它是一种潜在的倾向或分数。让我们称它为 $Y^*$。

我们用一个简单的线性方程来为这个[潜变量](@article_id:304202)建模，就像你学过的最基础的[回归分析](@article_id:323080)一样：

$$
Y^* = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \epsilon
$$

在这里，$x$ 是我们的预测变量（比如贷款申请人的风险评分），$\beta$ 是它们的权重，而 $\epsilon$ 是一个关键组成部分：一个随机噪声项。这个项代表了所有影响结果的未测量因素和固有的随机性。我们称之为 $Y$ 的最终二元事件发生，当且仅当这个[潜变量](@article_id:304202)分数超过某个阈值。为了数学上的方便，我们通常将这个阈值设为零。所以，我们的规则很简单：

$$
Y = 1 \text{ if } Y^* > 0, \text{ and } Y = 0 \text{ otherwise.}
$$

这个框架异常强大。例如，在遗传学中，像“患病”或“未患病”这样的离散疾病，可以被建模为一个由数千个基因和环境因素决定的潜在连续“[易感性](@article_id:307604)”的结果。如果这个[易感性](@article_id:307604)超过了一个生物学阈值，疾病就会显现出来 [@problem_id:2838216]。

### 两种噪声的故事

如果两种模型都共享这个优美的[潜变量](@article_id:304202)故事，那么它们究竟在何处不同呢？区别完全在于它们对噪声项 $\epsilon$ 所假设的随机性的“具体形式”。

**probit 模型**做出了一个非常著名且理论上方便的假设：它假定噪声 $\epsilon$ 服从**[标准正态分布](@article_id:323676)**。这是经典的“钟形曲线”，在自然界中随处可见。这一假设的理由是深刻的，源于**中心极限定理**。如果噪声是大量微小的、独立的随机扰动之和，其分布自然会呈现出[钟形曲线](@article_id:311235)的样子 [@problem_id:2838216]。这给了 probit 模型强大的理论基础。

另一方面，**logit 模型**假设噪声 $\epsilon$ 服从**[标准逻辑](@article_id:357283)斯蒂分布**。这个分布看起来与[正态分布](@article_id:297928)惊人地相似——它也是钟形且对称的——但它的尾部要“更重”一些。这意味着，在 logit 模型中，远离零的极端噪声值出现的可能性比在 probit 模型中略高。我们稍后会看到，尾部这个细微的差异正是两种模型在实际应用中真正产生分歧的地方。

### 不可见与不可知：一个尺度问题

在这里我们遇到了一个非常微妙的问题。[潜变量](@article_id:304202) $Y^*$ 像一个幽灵，我们永远无法直接观测到它。我们只能看到最终的结果 $Y$。这导致了一个关于**[可识别性](@article_id:373082)**的有趣难题。

假设我们有模型 $Y^* = X^\top\beta + \epsilon$。现在，如果我们把系数 $\beta$ 和噪声 $\epsilon$ 都乘以某个正数，比如说 $c=2$ 会怎样？我们新的[潜变量](@article_id:304202)将是 $Y^{*'} = X^\top(2\beta) + 2\epsilon = 2(X^\top\beta + \epsilon) = 2Y^*$。

事件何时发生呢？规则是 $Y'=1$ 如果 $Y^{*'} > 0$，这等同于 $2Y^* > 0$。但这与 $Y^* > 0$ 是*完全相同的条件*。可观测的结果是完全一样的！我们仅通过观察数据，无法知道真实的系数是 $\beta$ 还是 $2\beta$（或任何 $c>0$ 对应的 $c\beta$）[@problem_id:3169411]。整体的尺度是不可识别的。

统计学家是如何解决这个难题的呢？通过一个非常务实的惯例。既然我们无法确定噪声的尺度，我们就干脆约定将其固定。我们*假设*噪声分布具有某个标准的方差。
-   在 **probit 模型**中，我们将正态噪声的方差精确地固定为 1。
-   在 **logit 模型**中，我们将逻辑斯蒂噪声的[尺度参数](@article_id:332407)固定为 1，这对应于 $\pi^2/3$ 的方差。

这种“钉住”方差的行为使得系数 $\beta$ 变得可识别。这有点像决定一种货币单位。 “一美元”的绝对价值是任意的，但一旦我们都同意了它，我们就可以相对于它来为其他所有东西定价。同样，通过固定噪声方差，我们可以唯一地估计出每个预测变量相对于该噪声水平的效应。在这些模型中，我们真正估计的不是 $\beta$ 本身，而是 $\beta$ 与噪声[标准差](@article_id:314030) $\sigma$ 的比值。也就是说，我们只能识别 $\beta/\sigma$ [@problem_id:3169411]。

### 那个神奇的数字：为何你的系数并非你所想

现在到了实际应用的要点。由于[标准逻辑](@article_id:357283)斯蒂分布（方差 $\pi^2/3 \approx 3.29$）比[标准正态分布](@article_id:323676)（方差 1）更宽，为了让两个模型产生相似的概率，它们的系数需要被不同地缩放。

想象你有两张同一城市的地图，一张以公里为单位，另一张以英里为单位。要描述相同的 1.6 公里距离，你会在第一张地图上写“1.6”，而在第二张地图上写“1”。数字不同，但它们代表的是相同的物理现实。

logit 和 probit 也是如此。为了解释 logit 模型中更宽的噪声分布，其系数必须更大，才能对结果产生相同的有效影响。这个缩放因子并非任意的。如果我们在[中心点](@article_id:641113)（概率为 0.5）匹配逻辑斯蒂和（经过缩放的）正态概率曲线的陡峭程度（即[导数](@article_id:318324)），我们就能找到那个神奇的转换因子 [@problem_id:3162348]。一个 logit 模型的系数大约比对相同数据拟合的 probit 模型相应系数大 **1.6 倍**。

$$
\beta_{\text{logit}} \approx 1.6 \times \beta_{\text{probit}}
$$

这个因子的精确理论值是 $4/\sqrt{2\pi}$ [@problem_id:3162348] [@problem_id:2773511]。这意味着，如果你拟合一个 probit 模型，并得到某个预测变量的系数为 $0.50$，那么你可以预期，对相同[数据拟合](@article_id:309426)一个 logit 模型将会得到一个大约为 $0.50 \times 1.6 = 0.80$ 的系数 [@problem_id:1931438]。这不是巧合，而是它们假定的噪声分布尺度不同的直接结果。数值模拟完美地证实了这种关系 [@problem_id:3142168]。

这会带来实际的后果。例如，在遗传学中，如果真实的生物过程遵循 probit 模型，而你错误地拟合了 logit 模型，那么你对某个基因效应的估计值将会因为这个[缩放因子](@article_id:337434)而被向上偏置 [@problem_id:2773511]。

### 两种尾部的故事：选择何时重要

如果这两个模型只是彼此的缩放版本，那么选择它们会有什么影响吗？是的，有影响——在极端情况下。

区别在于逻辑斯蒂分布的那些“重尾”。预测变量的**[边际效应](@article_id:639278)**是指该预测变量每变化一个单位所引起的概率变化。在两种模型中，这种效应在中心附近（当概率接近 0.5 时）最大，并随着概率接近 0 或 1 而减小。

然而，由于[正态分布](@article_id:297928)的尾部“更轻”（由于 $e^{-x^2}$ 项的存在，它们趋向于零的速度快得多），probit 模型的[边际效应](@article_id:639278)在极端情况下会迅速减小。而 logit 模型，凭借其更重的、类似 $e^{-|x|}$ 的尾部，即使在概率已经非常高或非常低时，仍能保持一个稍大的[边际效应](@article_id:639278) [@problem_id:3185517]。

实际上，这意味着 logit 模型假设你仍然可以影响结果，即使它已经非常可能或非常不可能发生。而 probit 模型则更为“怀疑”；它认为一旦一个结果几乎确定，就很难再撼动它。对于一个在这些极端情况下有大量观测值的数据集，两种模型可能会对一个预测变量的实际重要性得出不同的结论 [@problem_id:3185517]。

### 伟大的均衡器：排序与 ROC 曲线

尽管存在这些细微的差异，但还有一个最终的、统一的转折。假设你的目标不是预测事件的确切概率，而只是将个体从最可能到最不可能经历该事件进行*排序*。例如，你想为市场营销活动创建一个优先客户列表。

在这种情况下，probit 和 logit 之间的选择是完全无关紧要的！两种模型都从相同的线性分数 $\eta = X^\top\beta$ 开始。然后，它们对这个分数应用一个严格递增的函数（逻辑斯蒂 S 型函数或正态累积分布函数）来得到概率。由于这些函数总是递增的，如果一个人的线性分数 $\eta$ 高于另一个人，那么无论你使用哪种模型，他最终的概率也会更高。所有个体的排序将保持完全相同。

这意味着，如果你使用一个只依赖于排序的指标来评估你的模型，比如**[受试者工作特征曲线](@article_id:638819)下面积（AUC）**，那么两种模型将得到完全相同的分数 [@problem_id:3162345]。链接函数的选择变得无关紧要。这是一个深刻的洞见：“最佳”模型完全取决于你想用它来做什么。对于效应解释和精确概率预测，差异是重要的。但对于纯粹的排序，则不然。如果你真的需要知道哪个模型更适合你的特定数据，像 Vuong 检验这样的正式统计程序可以帮助你做出决定 [@problem_-id:1919854]。

