## 引言
优化是现代科学与工程领域的核心挑战，通常被形象地比作在复杂地形中寻找最低点。简单的凸问题就像寻找碗底，但许多现实世界中的挑战呈现出非凸的地形，充满了山脊、山峰和局部最小值，使得找到一条通往解的保证路径变得困难。这引出了一个关键问题：我们如何才能在这些险峻的地形中航行，找到有意义的解？放大-最小化（MM）算法提供了一个优雅而强大的答案。它并非直接解决难题，而是系统地将其替换为一系列更简单、可解的问题。

本文对 MM 原理进行了全面概述。第一章“原理与机制”将揭示其核心的两步过程——放大与最小化，解释其保证下降的性质，并展示它如何统一了[梯度下降](@entry_id:145942)等我们所熟悉的算法。第二章“应用与跨学科联系”将展示 MM 算法令人难以置信的通用性，探讨其如何被用于解决[稀疏恢复](@entry_id:199430)、张量补全、[稳健统计学](@entry_id:270055)乃至自动化科学发现等前沿问题。准备好发现一个强大的工具，它能将棘手的优化挑战转化为一系列可控的步骤。

## 原理与机制

想象你是一名登山者，试图在一片广阔、崎岖且雾气弥漫的山脉中找到最低点。这就是优化的挑战。这片地形代表你的[目标函数](@entry_id:267263) $f(x)$，而你的位置就是参数集合 $x$。如果山脉是一个简单的凸形碗，你只需沿着斜坡向下走就能到达底部。但我们的山是非凸的：它是一片险恶的地形，充满了山峰、山谷和蜿蜒的山脊，[全局最小值](@entry_id:165977)隐藏在迷雾之中。在没有完整地图的情况下，你如何保证能不断向下前进？

这就是优雅而强大的**放大-最小化（MM）**原理发挥作用的地方。它提供了一个惊人简单却又意义深远的策略：不要直接在复杂的地形上导航，而是构建一个更简单的局部近似地形，并在此之上进行导航。

### 核心思想：以简代繁

MM 算法遵循两步节奏运行：放大，然后最小化。

1.  **放大 (Majorize)**：在你当前的位置 $x^k$ 处，你构建一个代理函数，我们称之为 $Q(x \mid x^k)$。这个代理函数是你对地形的简化地图。要成为一张有效的地图，它必须满足两个严格的条件。首先，它必须是真实地形的一个全局[上界](@entry_id:274738)；这就是**放大**性质，即对于所有可能的位置 $x$，都有 $Q(x \mid x^k) \ge f(x)$。可以把它想象成一个始终高于地面的保护性顶棚。其次，这个顶棚必须恰好在你站立的位置接触地面；这就是**相切**性质，即 $Q(x^k \mid x^k) = f(x^k)$。

2.  **最小化 (Minimize)**：有了这个简单、易于处理的代理地形 $Q$（通常选择为一个光滑的凸碗），你就可以执行下一步移动。你找到代理函数的最低点并移动到那里。这就成为你的新位置，$x^{k+1} = \arg\min_x Q(x \mid x^k)$。

为什么这个方法保证有效？让我们来追溯一下逻辑。你的新高度是 $f(x^{k+1})$。因为代理顶棚始终在真实地面之上，我们知道 $f(x^{k+1}) \le Q(x^{k+1} \mid x^k)$。又因为你移动到了代理函数的最低点，所以它在那里的高度必然小于或等于它在你出发点的高度，即 $Q(x^{k+1} \mid x^k) \le Q(x^k \mid x^k)$。最后，由于代理函数在你的出发点与地面相切，所以 $Q(x^k \mid x^k) = f(x^k)$。将这些不等式[串联](@entry_id:141009)起来，我们就得到了优美的下降保证：

$$
f(x^{k+1}) \le Q(x^{k+1} \mid x^k) \le Q(x^k \mid x^k) = f(x^k)
$$

你保证会移动到一个高度更低或相等的位置。你永远不会走上坡路！这个优雅的性质即使在原始地形 $f(x)$ 是一个非凸噩梦时也成立。MM 算法的魔力在于将一个困难的非凸问题转化为一系列易于处理的、通常是凸的子问题，同时保证了算法的进展 [@problem_id:3458617] [@problem_id:3454727]。

值得注意的是，你甚至不需要找到代理函数碗的绝对最低点。任何移动到新点 $x^{k+1}$ 的一步，只要能降低代理函数的值，即 $Q(x^{k+1} \mid x^k) \le Q(x^k \mid x^k)$，就足以保证你不会在真实的山上走上坡路 [@problem_id:3454727]。这允许了“非精确”步，增加了巨大的实践灵活性。MM 的基本保证不是算法的更新映射是一个收缩映射，而是它能够精心策划[目标函数](@entry_id:267263)值的单调下降 [@problem_id:3130577]。

### 伪装的熟人：[梯度下降法](@entry_id:637322)

这可能听起来很抽象，但你很可能在不知不觉中已经遇到过 MM 算法。让我们看看最基本的[优化算法](@entry_id:147840)之一：**梯度下降法**。其更新规则很简单：沿着最陡[下降方向](@entry_id:637058)迈出一小步，$x^{k+1} = x^k - \alpha \nabla f(x^k)$。这能被看作是一种 MM 算法吗？

答案是肯定的，这揭示了优化领域深层次的统一性。关键在于梯度的 **$L$-Lipschitz 连续性**。简单来说，这意味着函数的斜率变化不会太剧烈；其曲率是有界的。如果一个函数的梯度是 $L$-Lipschitz 连续的，那么一个强大的结论（通常称为[下降引理](@entry_id:636345)，Descent Lemma）保证了我们可以构建一个简单的二次碗形函数，它在任何地方都能放大该函数：

$$
Q(x \mid x^k) = f(x^k) + \nabla f(x^k)^T(x - x^k) + \frac{L}{2} \|x - x^k\|^2
$$

这个代理函数满足 MM 的两个条件：它始终在 $f(x)$ 上方，并且在 $x^k$ 处与 $f(x)$ 相切。当我们最小化这个特定的二次碗形函数时会发生什么？我们对它关于 $x$ 求梯度并令其为零，这恰好得到了[梯度下降](@entry_id:145942)的更新规则：$x^{k+1} = x^k - \frac{1}{L} \nabla f(x^k)$。

因此，步长为 $\alpha = 1/L$ 的[梯度下降法](@entry_id:637322)不过是使用特定二次代理函数的 MM 算法！[@problem_id:3458601]。这一见解是深刻的。它告诉我们，梯度下降法不仅仅是一种[启发式方法](@entry_id:637904)；它是一个有原则的程序，通过反复最小化真实函数的一个简单的[上界](@entry_id:274738)来工作。这也解释了为什么它对非凸函数有效：下降的保证来自于 MM 原理，该原理不要求[凸性](@entry_id:138568)，只要求梯度的[光滑性](@entry_id:634843)。

这也为步长的选择提供了直观理解。常数 $L$ 决定了我们代理函数碗的“宽度”。如果我们选择的 $L$ 太大（即步长太小），我们的碗就太窄，导致我们迈出的步子微小且效率低下。如果我们选择的 $L$ 小于真实的界，我们的代理函数就不再是放大函数——它会“切穿”真实的地形。取这个有缺陷的代理函数的最小值可能会让你落到山谷的另一边，其高度比你开始时更高，从而打破了下降的保证 [@problem_id:3458601]。

### 构建代理函数的艺术

当我们超越简单的[梯度下降法](@entry_id:637322)，开始为更复杂的问题设计定制的代理函数时，MM 算法的真正威力才得以释放。在机器学习和压缩感知等领域，大量现代问题都涉及最小化一个复合目标函数：

$$
F(x) = \underbrace{\frac{1}{2}\|Ax-b\|_2^2}_{\text{smooth data fit}} + \underbrace{\lambda \sum_{i} \rho(|x_i|)}_{\text{non-convex/non-smooth penalty}}
$$

第一项通常是一个光滑、凸的二次碗形函数。第二项，即惩罚项，是“麻烦制造者”。它通常是非光滑的（如 $\ell_1$ 范数， $|x_i|$）甚至是-非凸的（如当 $p \lt 1$ 时的 $\ell_p$ 范数， $|x_i|^p$，或对数惩罚项），以鼓励[稀疏解](@entry_id:187463)——即大部分分量 $x_i$ 恰好为零的解。

MM 算法如何处理这个问题？通过将其威力集中在困难的部分。

#### 利用[凹性](@entry_id:139843)驯服非凸猛兽

许多强大的促进稀疏性的惩罚项，虽然整体上是非凸的，但它们是由**凹**函数构建的。如果一个函数的图像看起来像一个倒置的碗，那么它就是[凹函数](@entry_id:274100)。任何可微[凹函数](@entry_id:274100)的一个关键性质是，它总是位于其[切线](@entry_id:268870)的*下方*。这为我们提供了一种绝佳的构造放大函数的方法：[切线](@entry_id:268870)本身！

对于一个[凹惩罚](@entry_id:747653)项 $\rho(|x_i|)$，我们可以写出：
$$
\rho(|x_i|) \le \rho(|x_i^k|) + \rho'(|x_i^k|)(|x_i| - |x_i^k|)
$$
右侧是 $|x_i|$ 的一个简单线性函数。通过用这个线性上界替换每个非凸项 $\rho(|x_i|)$，我们将整个[非凸惩罚](@entry_id:752554)项转化为一个简单的[绝对值](@entry_id:147688)加权和：$\lambda \sum_i w_i^k |x_i|$，其中权重恰好是惩[罚函数](@entry_id:638029)在当前位置的导数（斜率），即 $w_i^k = \rho'(|x_i^k|)$ [@problem_id:3455582] [@problem_id:3455581]。

最初的、困难的非凸问题现在被替换为一系列（通常是凸的）**加权 $\ell_1$ 最小化**问题 [@problem_id:3458617]。这是一类著名算法——**[迭代重加权最小二乘法](@entry_id:175255)（IRLS）**背后的引擎。MM 理论揭开了它们的神秘面纱：它们不过是 MM 原理的巧妙实现。

这些权重有一个非常直观的解释。对于一个典型的[凹惩罚](@entry_id:747653)函数，当 $t$ 很小时，斜率 $\rho'(t)$ 很大；当 $t$ 很大时，斜率很小。因此，如果一个分量 $|x_i^k|$ 已经很小，它在下一次迭代中会获得一个大的权重，从而更强力地将其推向零。如果 $|x_i^k|$ 很大，它会获得一个小的权重，实际上等于不受影响。正是这种动态加权机制使得这些方法能够如此有效地寻找并强制实现[稀疏性](@entry_id:136793) [@problem_id:3455582]。

### 统一视角：MM 的其他面貌

如同物理学的基本定律一样，MM 原理以多种形式显现，统一了看似毫不相干的概念。

#### 作为块[坐标下降](@entry_id:137565)的 MM

一个引人入胜的观点是，任何 MM 算法都可以被看作是在一个更高维空间中的简单**块[坐标下降](@entry_id:137565)（BCD）**算法。我们可以引入“辅助变量”来帮助我们构建代理函数。例如，为了放大简单的 $|x_i|$ 项，可以使用巧妙的不等式 $|x_i| \le \frac{x_i^2}{2|z_i|} + \frac{|z_i|}{2}$，它对任何 $z_i \neq 0$ 都成立。这给我们一个关于 $x$ 的二次代理函数 $Q(x \mid z)$。

我们现在可以定义一个联合函数 $F(x,z) = Q(x \mid z)$，并通过在变量块 $x$ 和 $z$ 之间[交替最小化](@entry_id:198823)来求解。
*   **对 $z$ 最小化（固定 $x^k$）：** 当我们设置 $z=x^k$ 时达到最小值。这一步仅仅是设置了我们的辅助变量，有效地“中心化”了代理函数，使其在 $x^k$ 处相切。这*就是*放大步骤。
*   **对 $x$ 最小化（固定 $z$）：** 这就是最小化代理函数 $Q(x \mid z)$，也*就是*最小化步骤。

因此，MM 算法等价于在一个巧妙构建的、更高维但更简单的函数上进行 BCD [@problem_id:3103275]。

### MM 的实践艺术与科学

尽管原理很简单，但其应用是一门艺术。

#### 代理函数的选择至关重要

对于一个给定的问题，可能存在许多不同的代理函数。有些代理函数比其他的“更紧”，意味着它们能为真实函数提供更近的近似。一个更紧的代理函数通常会带来更大的步长和更快的收敛速度。例如，在[稳健回归](@entry_id:139206)中，像[凸凹过程](@entry_id:636912)（CCP）和 IRLS 这样的不同 MM 算法可以被看作是为同一目标使用了不同的代理函数。对于某些类型的噪声，一个算法的代理函数可能被证明比另一个的更紧、更有效 [@problem_id:3114681]。

#### [奇异点](@entry_id:199525)的风险与希望

当使用像 $|x_i|^p$（其中 $p1$）这样的惩罚项时，导数 $\rho'(t) = pt^{p-1}$ 在 $t \to 0$ 时会爆炸。这意味着我们的 IRLS 算法中的权重可能变为无穷大，这在理论上对促进稀疏性很有利，但对于计算机上的[数值稳定性](@entry_id:146550)来说却是一场灾难 [@problem_id:3458633]。

标准的解决方案是一个两步策略。首先，我们对惩罚项进行轻微的**平滑**处理，例如使用 $(|x_i| + \epsilon)^p$（其中 $\epsilon > 0$ 是一个很小的数）。这可以使权重保持有限。其次，我们使用**连续化**方法。我们从一个相对较大的 $\epsilon$ 开始，这使得问题良态且易于求解。一旦我们得到了一个好的近似解，我们就减小 $\epsilon$ 并再次求解，使用前一个解作为“热启动”。通过逐步减小 $\epsilon$，我们可以向着我们期望的、尖锐的、高度稀疏的解前进，而不会在中途掉入数值陷阱 [@problem_id:3458633]。

为什么要费这么多功夫？因为回报是巨大的。建立在这些复杂的 MM 原理之上的算法，比如用于 $\ell_p$ 最小化的 IRLS，通常比用于相同非凸问题的更简单的[启发式方法](@entry_id:637904)，在解的质量方面带有更强的理论保证 [@problem_id:3393313]。

放大-[最小化原理](@entry_id:169952)，以其优雅的简洁性，为理解和设计大量的优化算法提供了一个统一的框架。它证明了用一系列更简单的问题来替代一个难题的力量——这一策略将迷雾中艰难的攀登转变为通往解的、有保证的、一步步的下降过程。

