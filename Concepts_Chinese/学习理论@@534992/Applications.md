## 应用与跨学科联系

既然我们已经探索了[学习理论](@article_id:639048)的内在机制——泛化、容量的齿轮与杠杆，以及[监督学习](@article_id:321485)和[无监督学习](@article_id:320970)的宏大[范式](@article_id:329204)——我们可能会问一个非常实际的问题：这一切究竟有何用处？这仅仅是数学的一个复杂分支，还是它为我们提供了一个观察世界的全新而有力的视角？你会欣喜地发现，答案是这些思想并不仅限于黑板。它们正处于一场科学发现和工程革命的核心，将生物学、化学甚至经济学等截然不同的领域编织在一起。我们将踏上一段旅程，穿越其中的一些应用，不是作为一份枯燥的目录，而是为了看到同样美妙的原理以各种华丽的“服装”发挥作用。

一个极好的思考框架来自于对音乐的类比[@problem_id:2432856]。想象一下，你想教一台电脑关于音乐的知识。如果你给它数千首莫扎特的曲子，并将其标记为“莫扎特”，机器就能以惊人的准确性学会识别莫扎特的风格。这是**[监督学习](@article_id:321485)**：学习识别一种已知的模式。但如果你给机器一个庞大的、未标记的、包含所有有史以来录制音乐的库呢？它可能会通过发现声音中的统计规律，将一些我们后来会标记为“爵士乐”或“嘻哈”的歌曲归为一类。机器自己发现了“流派”这个*概念*。这是**[无监督学习](@article_id:320970)**：发现未知的结构。科学的核心，就是在这两种模式之间的一支舞——证实我们所知的，发现我们所不知的。

### 解码生命蓝图

也许没有哪个领域比现代生物学更能体现这支舞的活力了。这个领域充斥着来自无数生物体基因组的数据。生命的“语言”由DNA、RNA和蛋白质的序列写成。[学习理论](@article_id:639048)为我们提供了工具，既能阅读这种语言，更令人兴奋的是，还能编写我们自己的新词汇。

思考一个基本问题：一个细胞的DNA是一个包含数百万“字母”的文库；一个特定的蛋白质，即[转录因子](@article_id:298309)，如何精确地知道该降落在哪里来开启或关闭一个基因？假设我们通过实验测量了一个蛋白质与许多不同短DNA序列的结合强度——即亲和力。我们现在有了一个带标签的数据集：对于每个序列，我们都有一个相应的亲和力分数。这是一个经典的[监督学习](@article_id:321485)问题[@problem_id:2432839]。我们可以训练一个模型来学习序列与其结合能之间的关系，也许可以像物理学家那样假设，每个位置上的每个碱基都对总能量贡献一点点。模型从带标签的数据中学习这些能量贡献。

但如果我们没有如此精确的测量值呢？如果我们只有一堆DNA序列，我们知道它们是“特殊的”，因为我们的蛋白质与它们全部结合，但我们不知道*结合强度如何*？这里，我们没有标签，只有一堆阳性样本。我们无法监督一个精确能量模型的学习。相反，我们必须转向[无监督学习](@article_id:320970)。我们问机器：所有这些序列有什么共同点？通过比较我们特殊集合中每个位置的DNA碱基频率与整个基因组中它们的频率，机器可以提炼出一个“基序”，或一个统计特征。这个基序就是定义结合位点的模式。它在从未被告知蛋白质偏好的“词汇”是什么的情况下，自己发现了它。

同样的二元性也出现在疫苗设计的关键任务中[@problem_id:2432828]。我们的免疫系统识别病毒的微小片段，称为肽。但是哪些肽能引发强烈的免疫反应呢？如果我们有一份标记为“[免疫原性](@article_id:344179)”和“非[免疫原性](@article_id:344179)”的肽列表，我们可以训练一个监督分类器——例如，一个[逻辑回归模型](@article_id:641340)——来预测哪些新肽会有效。但我们也可以采取无监督的方法：简单地根据肽的化学性质（如它们的氨基酸组成）对所有肽进行[聚类](@article_id:330431)，然后检查这些“自然”的分组是否与[免疫原性](@article_id:344179)相对应。有时，这种[无监督聚类](@article_id:347668)揭示了两个类别之间一个简单的、潜在的物理差异，而一个更复杂的监督模型可能会掩盖这一点。

当我们从仅仅阅读生命语言转向书写它时，真正的兴奋才开始。如果我们能设计一种全新的蛋白质来执行特定任务，比如一种能分解塑料的酶，会怎么样？这是[生成模型](@article_id:356498)的领域。想象一下，用一个庞大的已知蛋白质序列数据库来训练一个模型，比如[变分自编码器](@article_id:356911)（VAE）[@problem_id:2432805]。VAE的训练完全是无监督的；其唯一目标是学习蛋白质潜在的“语法”——进化在亿万年间发现的折叠和稳定性规则。它学习将一个[蛋白质序列](@article_id:364232)压缩到一个连续的、低维的“[潜空间](@article_id:350962)”中，这就像一张所有可能蛋白质的地图。

美妙之处在于，一旦这张地图被学会，我们就可以在其中漫步。我们可以在[潜空间](@article_id:350962)中选择一个随机点，然后问VAE的解码器部分：“哪个蛋白质对应于这个点？”模型将生成一个全新的[氨基酸序列](@article_id:343164)，这个序列由于是从学习到的分布中抽取的，因此很有可能是一个稳定、结构良好的蛋白质。我们可以“构想出”从未存在过的分子！当然，并非所有分子都有用。但我们可以将我们的无监督生成模型与一个监督分类器联系起来，这个分类器被训练来识别（比如说）一种强效酶的特征。我们可以生成成千上万个新颖的候选物，并使用快速的分类器来筛选最有希望的那些，以便在实验室中合成和测试。这种优雅的合作——无监督生成后进行监督选择——是推动生物工程发展的一个强大的新引擎。

随着大型“蛋白质语言模型”的出现，这一思想达到了顶峰[@problem-id:2749082]。通过在一个几乎包含所有已知蛋白质序列的数据库上训练一个[Transformer模型](@article_id:638850)——与驱动ChatGPT等系统的架构相同——我们将[自监督学习](@article_id:352490)推向了极限。模型通过与自己玩一个游戏来学习：它观察一个随机隐藏了某些氨基酸的[蛋白质序列](@article_id:364232)，它的任务是预测缺失的部分。为了精通这个游戏，模型必须含蓄地学习深刻的生物学规则。它必须学习到，在线性序列中相距很远但在最终折叠的3D结构中相互接触的两个氨基酸在统计上是相关的。它学习了关于[活性位点](@article_id:296930)、结构基序和进化关系的一切，而无需任何人工提供的标签。其结果是一个能为任何蛋白质提供丰富数值表示——即“[嵌入](@article_id:311541)”——的模型，捕捉其深层的功​​能和结构本质。这种[预训练](@article_id:638349)的知识是如此强大，以至于我们随后可以用它来解决新问题，比如仅用少量带标签的样本来预测蛋白质的功能，这个过程被称为[迁移学习](@article_id:357432)。

### 学习我们世界的物理规律

学习的原理不仅限于[生物序列](@article_id:353418)的离散世界。当应用于物理和化学的连续定律时，它们同样具有变革性。在这些领域，我们通常有成熟的机理模型，但它们要么[计算成本](@article_id:308397)过高，要么不够完全精确。

一个已经出现的极其优雅的思想叫做**$\Delta$-学习**，或[残差学习](@article_id:638496)[@problem_id:2903824]。在[量子化学](@article_id:300637)中，使用[耦合簇](@article_id:369731)（CC）等方法高精度预测分子的能量，其计算成本高得令人难以置信。然而，我们有更便宜、但精度较低的方法，如[密度泛函理论](@article_id:299475)（DFT）。现在，我们可以尝试训练一个机器学习模型从头开始预测昂贵的CC能量，但这本身就是一项艰巨的任务——这相当于要求模型从数据中重新发现量子力学！更聪明的方法是让机器学习*修正量*，即[残差](@article_id:348682)：$\Delta = E^{\mathrm{CC}} - E^{\mathrm{DFT}}$。

为什么这要容易得多？因为廉价的DFT模型已经完成了大部分工作！它已经捕捉了大部分的物理原理。[残差](@article_id:348682)$\Delta$是一个比总能量$E^{\mathrm{CC}}$“简单”得多的函数。它是一个更小、更平滑、性质更好的量。用[学习理论](@article_id:639048)的语言来说，目标[函数的范数](@article_id:339244)更小，这意味着我们需要少得多的数据点就能以给定的精度学习它。这个原理是深刻的：不要浪费数据和[模型容量](@article_id:638671)去学习你已经知道的东西。把你现有的知识作为基线，让机器学习专注于缺失的部分。这种将基于物理的模型与数据驱动的修正相结合的强大思想现在已经无处不在。

这种混合哲学在“[数字孪生](@article_id:323264)”的概念中得到了最终的体现[@problem_id:2684657]。想象一个生物反应器，其中干细胞被诱导分化成跳动的心肌细胞——这是一个极其复杂的过程。我们希望实时监控和控制这个过程，以确保高质量的产品。我们可以写下一组描述我们对细胞生长、营养消耗和分化最佳理解的[微分方程](@article_id:327891)（ODEs）。但这个模型并不完美。

数字孪生是一个与真实生物反应器并行运行的、活的混合模型。它以机理性的ODEs为核心，但不断通过实时传感器数据流（过程分析技术）进行更新。模型预测与带噪数据的融合由一个[贝叶斯滤波](@article_id:297720)器处理，该滤波器持续优化其对生物反应器真实、[隐藏状态](@article_id:638657)（如已分化细胞的确切比例）的估计。但机器学习在其中扮演什么角色？在两个关键地方。首先，可以训练一个机器学习模型来预测我们ODE模型的[系统误差](@article_id:302833)或[残差](@article_id:348682)，从而使核心模型更准确。其次，一些关键的质量属性，比如细胞的最终“效能”，只有在过程结束后才能测量。我们可以用历史数据训练另一个机器学习模型——一个代理模型——在运行*期间*根据估计的状态轨迹来预测这个最终结果。这个混合系统，结合了基于物理的方程、实时数据和学习到的组件，比纯粹的机理模型或纯粹的数据驱动模型都要强大得多。它避免了纯物理模型的脆弱性，同时比“黑箱”[神经网络](@article_id:305336)更加数据高效和可解释[@problem_id:2773028]。

### 在社会世界中学习

[学习理论](@article_id:639048)的触角甚至超越了自然科学，延伸到了[策略互动](@article_id:301589)的领域。在经济学和博弈论中，主体不仅仅是在学习一个静态的世界，而是在学习其他同样在学习的主体。

考虑一个简单的“消耗战”博弈[@problem_id:2405897]。你和一个对手正在争夺一个奖品。只要你们都留在博弈中，你们都要付出成本。第一个退出的人输。假设你的对手可以是两种类型之一：“强硬”（等待成本低）或“软弱”（等待成本高）。你不知道他们的类型。你能做什么？你可以学习。

在博弈开始时，你对你的对手是强硬类型的概率有一个[先验信念](@article_id:328272)。但他们*没有*退出的每一秒都为你提供了新的信息。这是一个信号。一个软弱的玩家更有可能已经退出了。你的对手仍在博弈中的事实，应该会增加你认为他们是强硬类型的信念。这个推理过程正是[贝叶斯定理](@article_id:311457)的实际应用。你的大脑，无论是有意识还是无意识，都是一个[贝叶斯推断](@article_id:307374)引擎，根据从对手行动（或不行动！）中获得的数据流来更新其对对手的内部模型。这揭示了学习是理性主体在不确定性中导航的基本过程，无论这种不确定性是关于自然法则还是竞争对手的意图。

### 一个普适的视角

从细胞中蛋白质的复杂舞蹈，到分子中电子的微妙能量，再到一座活工厂的复杂运作，甚至到一场智力博弈中的策略计算，我们都看到了[学习理论](@article_id:639048)核心原理的体现。从数据中泛化的能力，在未知中发现结构的能力，将先验知识与新证据融合的能力——这些都是正在增强我们理解、预测和改造我们周围世界能力的通用工具。现代科学的故事越来越成为一个伙伴关系的故事，一场人类思维的结构化假设与学习机器强大的、数据驱动的推理之间的对话。发现之旅才刚刚开始。