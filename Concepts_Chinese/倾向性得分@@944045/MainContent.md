## 引言
在探寻因果关系的征途中，[随机对照试验 (RCT)](@entry_id:167109) 被奉为金标准。然而，在从临床医学到公共政策的许多现实场景中，随机化并不可行或不符合伦理。这使得我们只能依赖观察性数据，而这[类数](@entry_id:156164)据充满了一个根本性挑战：我们希望比较的组别往往从一开始就有所不同，这个问题被称为“混杂”。当起跑线不平时，我们如何进行公平的比较？倾向性得分这一强大的统计工具，正是为了填补这一知识鸿隙而出现的。

本文为理解和应用倾向性得分提供了一份全面的指南，旨在从观察性数据中得出更可靠的因果推断。首先，我们将探讨其核心的**原理与机制**，揭示这个单一得分如何能够平衡众多的[混杂变量](@entry_id:199777)，并详细介绍其主要使用策略，如匹配和加权。随后，**应用与跨学科联系**部分将展示倾向性得分如何用于解决从医学到生态学等领域的实际问题，同时也将坦诚地探讨该方法的关键假设和局限性。

## 原理与机制

要真正领会倾向性得分的力量与精妙之处，我们必须首先回到科学中的一个基本问题：如何判断某样东西是否真正有效。想象一下，我们正在测试一种治疗心脏病的新药。在理想世界中，我们会进行一项**[随机对照试验 (RCT)](@entry_id:167109)**。我们会召集数千人，然后像掷一枚宇宙硬币一样，将一半人分配到接受新药的组，另一半人分配到接受安慰剂的组。随机化的美妙之处在于，平均而言，它创造了两个在所有可以想象的方面都几乎完全相同的组——年龄、生活方式、遗传倾向，甚至包括我们尚未想到要去测量的方面。这两个组是均衡的。如果我们随后观察到两组之间的心脏病发作率存在差异，我们就可以相当自信地认为，是药物，且仅是药物，导致了这一差异。

但在现实世界中，我们常常无法进行随机对照试验。或许是因为不符合伦理，或许是不切实际，又或许我们使用的是已经从日常临床实践中收集的数据，即所谓的**真实世界数据** [@problem_id:5054453]。在这些**观察性研究**中，医生不会掷硬币，而是运用他们的判断。一种新的、强效的他汀类药物可能会更频繁地开给胆[固醇](@entry_id:173187)高得惊人的患者，而较健康的患者则被告知坚持饮食和锻炼 [@problem-id:4624452]。

这便造成了一个危险的统计陷阱。服药组和未服药组从一开始就不同。这种初始差异就是我们所说的**混杂**。如果我们天真地比较他们的结局，我们并非在进行同类比较。我们比较的不是苹果和苹果，而是病苹果和健康的橙子。我们究竟如何才能将药物的效果从初始病情的影响中剥离出来呢？这正是倾向性得分为解决的核心挑战。

### 反事实之梦

从本质上讲，我们想要回答的是一个因果问题。对于任何特定个体，我们想知道，假如他们服用了药物与未服用药物，其结局会有何不同。这些“如果……会怎样”的情景被称为**潜在结局**或**反事实** [@problem_id:4576147]。当然，对每个人我们永远只能观察到一种现实——他们要么服了药，要么没服。因果推断的目标是利用来自一个群体的数据，巧妙地估计这些看不见的个体因果效应的平均值，我们称之为**平均处理效应 (ATE)**。

在[观察性研究](@entry_id:174507)中，实现这一目标的粗暴方法是寻找完美的匹配。对于每个服药的人，我们都试图在未服药的人中找到一个在其他所有方面都完全相同的人：相同的年龄、相同的性别、相同的合并症、相同的实验室结果等等。如果我们能构建这样一个[完美匹配](@entry_id:273916)的数据集，我们的比较就再次变得公平了。但由于**维度灾难**，这个策略很快就会失效。当有几十个特征需要匹配时，可能的个体画像数量会爆炸式增长。在任何实际大小的数据集中，寻找精确匹配都成了一项无望的任务。我们被困在数据的海洋中，无法进行公平的比较。

### 一个数字统领全局

正是在这里，Paul Rosenbaum 和 Donald Rubin 在1983年展现了他们的天才之举。他们提出了一个革命性的问题：我们真的需要匹配*所有*的特征吗？还是有更简单的方法？他们的答案就是**倾向性得分**，一个极其精妙而实用的概念。

倾向性得分的定义是，在给定个体的一组观察到的基线特征（或协变量，我们称之为 $X$）的情况下，该个体接受治疗的概率。用数学公式表示为：

$$e(X) = P(\text{Treatment}=1 \mid X)$$

乍一看，计算这个值似乎有些奇怪。我们已经知道谁接受了治疗，谁没有。但其魔力不在于知晓这个概率，而在于这个单一数字所代表的意义。倾向性得分像一个摘要，是将影响治疗决策的所有多维协变量信息进行的一维提炼。

接下来就是那个惊人的结果，即倾向性得分的**平衡特性**：如果你选取两个个体，一个接受了治疗，一个没有，但他们拥有*完全相同的倾向性得分*，那么在这对个体中，所有协变量 $X$ 的分布在平均意义上是相同的 [@problem_id:4624452]。换言之，在任何一群共享相同倾向性得分的人中，相对于他们已观察到的特征，治疗分配实际上是随机的。以这个单一数字为条件，实现了与随机对照试验中随机化所达到的那种平衡，只不过是针对我们已测量的变量。它打破了协变量与治疗之间的联系，从而允许进行公平的比较。

### 从理论到实践：平衡天平的三种方法

既然我们有了这个“神奇”的平衡数字，我们如何用它来估计因果效应呢？主要有三种策略，每种都有其自身的特点 [@problem_id:5054453]。

#### 匹配

最直观的方法是扮演“媒人”的角色。对于处理组中的每个人，我们在未处理组中寻找他们的“统计学双胞胎”——即倾向性得分非常相似的人。一旦我们有了匹配的配对，我们就可以简单地比较这些配对内的结局。那些无法匹配的个体则被搁置一旁。这种被称为**倾向性[得分匹配](@entry_id:635640)**的方法简单易懂，通常用于估计“处理组平均处理效应 (ATT)”，它回答的问题是：“对于那些实际接受了治疗的人来说，治疗的效果是什么？” [@problem-id:4776644]。

#### 分层

一种稍显粗略但仍然有效的方法是**分层**（或亚组分类）。我们不是寻找一对一的匹配，而是根据倾向性得分将人群切分成少数几个组或“层”。例如，我们可以创建五个分层：得分最低的20%的人，接下来的20%，依此类推，直到得分最高的20%。在每个分层内，倾向性得分大致相似，因此我们假设协变量也大致均衡。然后，我们计算每个分层中的治疗效应，并计算一个加权平均值以获得[总体估计](@entry_id:200993)。

#### 逆概率治疗加权 (IPTW)

最后这种方法或许是最巧妙且统计效力最强的方法。**逆概率治疗加权 (IPTW)** 创建了一个在统计上消除了混杂的“伪人群”。其诀窍是为研究中的每个人分配一个权重 [@problem_id:4576147]。这个权重是他们实际所接受治疗的概率的倒数。

-   一个倾向性得分为 $e(X)$ 的已处理个体，其权重为 $\frac{1}{e(X)}$。
-   一个倾向性得分为 $e(X)$ 的未处理个体，其权重为 $\frac{1}{1-e(X)}$。

想想这是如何运作的。一个本*不太可能*接受治疗（$e(X)$ 较低）而已处理的人，必定是一个不寻常的案例。他会得到一个很大的权重，因此在我们的伪人群中，他代表了许多其他未被治疗的类似人群。相反，一个本*很可能*接受治疗（$e(X)$ 较高）而已处理的人，则是一个典型案例。他会得到一个较小的权重。通过应用这些权重，我们创建了一个新的、合成的人群，其中协变量不再与治疗相关。在这个加权世界里，就好像治疗是随机分配的一样，我们只需比较处理组和未处理组的加权平均结局，就能得到 ATE 的一个[无偏估计](@entry_id:756289)。

### 构建得分的艺术与科学

倾向性得分神奇的平衡特性伴随着一个至关重要的警告：它只有在得分计算正确时才有效。这个过程不是一个无需思考的按键操作；它是一门需要科学判断的艺术。

首先，哪些变量应该进入倾向性得分模型？目标是模拟一项随机对照试验，因此我们必须包含所有可能成为**混杂因素**的**治疗前协变量**——也就是说，那些既是治疗选择的[共同原因](@entry_id:266381)，也是结局的共同原因的变量 [@problem_id:4830883]。遗漏一个关键的混杂因素意味着我们未能平衡它，最终的估计值将仍然存在偏倚。

同样重要的是要知道要*排除*什么。最危险的错误之一是包含一个作为治疗*后果*的变量。例如，如果我们研究的是一种降压药，我们绝不能将治疗开始*后*一个月测量的血压纳入我们的倾向性得分模型。这样的变量是**中介变量**（它位于因果路径上）。对其进行调整会阻断我们想要测量的部分效应。

更微妙的是，我们必须避免以**对撞因子**为条件。对撞因子是另外两个变量的共同*效应*。在因果图中，它是两个箭头碰撞的地方 ($A \rightarrow C \leftarrow U$)。调整对撞因子可能会在其原因之间产生虚假的统计关联，从而在原本不存在偏倚的地方打开了一条后门路径 [@problem-id:4830498]。经验法则是明确的：倾向性得分是为了平衡治疗前的混杂因素，而不是不惜任何代价地最大化对治疗的预测。

构建模型后，我们如何知道它是否奏效？证据不在于模型预测治疗的效果有多好——一个能完美预测治疗的模型意味着组间没有重叠，这对因果推断来说是一场灾难！[@problem_id:4550495]。相反，证据在于平衡性。我们必须进行**平衡性诊断**。在匹配或加权之后，我们检查协变量的分布在处理组和未处理组之间是否变得相似。像**标准化均数差 (SMD)** 这样的工具被用于此目的，其中接近零的值表示良好的平衡 [@problem_id:4980961]。实现出色的协变量平衡是衡量一个好的倾向性得分模型的主要基准 [@problem_id:4576154]。

### 现实的护栏：假设与谦逊

倾向性得分方法是一个强大的工具，但它并非魔杖。其有效性建立在三个核心假设之上，一个优秀的科学家总是对这些假设是否成立保持谦逊。

1.  **条件[可交换性](@entry_id:263314)（无未测量混杂）**：这是最关键的一条。我们假设我们已经成功识别并包含了*所有*治疗和结局的[共同原因](@entry_id:266381)在我们的模型中。倾向性得分只能平衡它所看到的变量 ($X$)。它无法平衡我们数据集中没有的**未测量混杂因素** ($U$)。这个假设是无法检验的。然而，我们可以使用像**阴性对照**这样的巧妙技术来探查其是否被违反。例如，我们可以测试我们的药物对一个我们知道它绝不可能影响的结局（例如，脚踝骨折率）的效果。如果我们的倾向性得分调整后的分析发现了一个“因果效应”，这是一个警示信号，表明可能存在残余混杂，并且这种混杂也可能使我们的主要分析产生偏倚 [@problem-id:5221131]。

2.  **正性（或重叠）**：对于任何一组特征，个体必须有非零的概率被分到治疗组或[对照组](@entry_id:188599)。如果某一类患者*总是*得到药物，我们就没有可以与之比较的人。这违反了正性假设，任何统计技巧都无法在无数据之处创造数据 [@problem_id:4624452]。我们可以通过绘制处理组和未处理组的倾向性得分分布图来诊断这一点。如果**重叠**很少或没有，则表明存在正性问题。这对 IPTW 尤其危险，因为倾向性得分接近 0 或 1 的个体将获得天文数字般的权重，使得最终估计极其不稳定 [@problem_id:4550495]。

3.  **一致性**：这个假设将抽象的潜在结局与现实世界的数据联系起来，指出个体的观察结局确实是他们在实际接受的治疗下的潜在结局。例如，如果存在不同版本的治疗或未考虑依从性，这个假设就可能被违反。

最后，我们必须应对真实数据的混乱，例如**协变量缺失**。简单地忽略有缺失数据的患者可能导致显著偏倚，特别是如果数据缺失的原因与结局相关。正确的处理方法，例如通过像**[多重插补](@entry_id:177416)**这样的复杂统计技术，是至关重要的。即使在这里也存在微妙之处：为了正确地插补一个缺失的混杂因素，[插补模型](@entry_id:169403)可能需要（这或许有违直觉）包含结局变量本身 [@problem_id:4943140]。

总而言之，倾向性得分是统计思维力量的证明。它将一个极其复杂的问题——平衡数不清的患者画像——简化为平衡一个单一数字的可管理任务。它并未消除进行审慎科学思考的必要性，但它提供了一个框架和一种非凡精妙的工具，帮助我们从一个并非为我们方便而设计的世界中学习因果关系。

