## 引言
人工智能融入医学正在彻底改变诊断、治疗和研究，但它也对医疗保健中最神圣的原则之一——知情同意——提出了深刻的挑战。当决策受到一个其推理过程可能不透明、其数据拥有自身生命周期的算法影响时，简单地说“是”这一行为变得无比复杂。本文旨在解决传统同意实践与人工智能驱动的医疗新现实之间的关键差距，主张需要一个更强大的伦理框架来保护患者的自主权和信任。通过探索这一复杂领域，读者将对人工智能时代的同意核心原则有深入的理解。我们将首先探讨基础性的“原则与机制”，从评估患者的能力到披露[算法偏见](@entry_id:637996)的责任。随后，“应用与跨学科联系”部分将展示这些原则如何在真实场景中应用，从患者床边到法庭，再到设计实验室。这段旅程为我们提供了一个全面的指南，以确保在拥抱技术进步的同时，我们尊重而非削弱人类的主体性。

## 原则与机制

在我们理解世界的旅程中，我们常常发现最深刻的原则隐藏在最熟悉的概念之中。“同意”这个概念感觉很简单——就是说“是”。但当我们将这个简单的概念与像人工智能这样具有变革性的力量并置时，它开始展开，揭示出触及心智本质、社会结构乃至人类定义本身的层层含义。让我们一起揭开这些层次，不将其视为一堆规则，而是一次发现之旅。

### 基石：选择的剖析

在我们追问一个“是”是否有意义之前，我们必须先问一个更基本的问题：这个人真的能做出选择吗？在医学上，我们不谈论一般智力或“胜任能力”——一个在法庭上决定的模糊法律术语。相反，我们关注的是更具功能性和具体性的东西：**决策能力**。不要把它看作某人*拥有*的属性，而应看作他们必须为面前的具体决定所展示的一系列能力。

想象两位患者，都在考虑同一个高风险手术。我们称他们为患者X和患者Y [@problem_id:4422884]。患者X因既往中风而有语言障碍，使用眼动追踪设备进行交流。然而，当被提示时，他能用自己的话通过设备解释手术的风险和益处。他认识到这个手术是为*他*和*他的病情*而做的。他能够根据自己的个人价值观权衡利弊，解释为什么他更喜欢这个选择而非更保守的方案。他始终如一地表达着自己的选择。

现在考虑患者Y。他口齿伶俐，能从宣传册上背诵关于手术的统计数据。然而，他坚称诊断是一个“骗局”，并且他个人对任何伤害都免疫。他将事实理解为抽象数据，却无法领会这些事实与他自己的身体和他自己的生活的关联。

谁有能力同意？答案揭示了自主权核心的美妙逻辑。决策能力无关乎完美的头脑或能言善辩。它建立在四大支柱之上：

1.  **理解**：你能否吸收相关事实？患者X通过“回授”信息来证明这一点。
2.  **领会**：你能否领会事实适用于*你*？这正是患者Y失败的地方。他相信自己“受到独特保护”，这表明其领会能力出了问题，使他掌握的事实知识变得毫无用处。
3.  **推理**：你能否利用信息做出符合你价值观的选择？患者X通过根据自己的优先事项比较权衡来证明这一点。
4.  **表达选择**：你能否表达一个一贯的偏好？方式无关紧要——言语、书写或眼动追踪设备都算数 [@problem_id:4422884]。

人工智能或许可以通过清晰地呈现信息，甚至对患者的回忆能力进行评分来提供帮助，但它无法取代评估领会能力和推理能力所需的人类判断 [@problem_id:4422884]。对能力的这一核心评估是任何合乎伦理的同意程序——无论是否有人工智能辅助——都必须建立其上的不可动摇的基础。

### 对话：披露算法的现实

一旦我们确定一个人能够做出选择，我们就必须进行一次对话。几个世纪以来，这场对话的中心一直是临床现实：拟议治疗的性质、其风险和益处，以及替代方案。但当人工智能进入房间，对话的性质必须改变。一个理性的人不仅想知道手术刀的风险；他们还想知道指导手术刀的算法的风险 [@problem_id:4442217]。

这需要一种新的、两部分的披露。我们仍然必须讨论熟悉的临床风险，但现在我们还有一项伦理义务，即披露算法的现实。这并非要揭示源代码或复杂的数学 [@problem_id:4494858]。而是要回答几个对患者决策至关重要的直白问题。

#### 人工智能的角色是什么？

第一步是透明。我们必须清楚地说明，人工智能被用作决策支持工具——一个助手，而非指挥官。最终的权力和责任仍在人类临床医生身上 [@problem_id:4494858]。这种简单的澄清可以对抗黑箱的“不透明权威”，后者可能让人感到非人化，仿佛一个人的命运正由一股看不见、不容置疑的力量决定 [@problem_id:4415669]。我们还必须解释替代方案，包括仅凭临床医生的判断而不借助人工智能输入的选项 [@problem_id:4868886]。

#### 人工智能的缺陷是什么？

诚实地对待技术的局限性至关重要。人工智能不是魔法；它是一种有已知失灵模式的工具。伦理披露的一部分就是讨论这些不完美之处，特别是那些可能对患者产生实质性影响的缺陷。

一个关键的缺陷是**[算法偏见](@entry_id:637996)**。这不是随机错误，而是一种系统性的错误模式，可能使整个群体，通常是那些本已边缘化的人群，处于不利地位。一个再入院风险模型可能总体上非常准确，但由于训练数据存在偏见，对黑人患者的表现可能很差 [@problem_id:4868886]。披露这种偏见的可能性不仅仅是一个技术问题；它是**正义**原则的一项深刻要求。

此外，我们必须谈论不确定性。一个用于败血症的人工智能可能会生成一个风险评分，比如 $p=0.7$，但这个数字并非神谕。它有[误差范围](@entry_id:169950)。解释该工具的性能——它多久正确一次，多久错误一次，以及它对这次具体预测的置信度如何——能让患者对他们被要求信任的技术有一个更诚实的了解 [@problem_id:4415669]。

### 数据的旅程：我的故事将去向何方？

每次你与医疗系统互动时，你都在讲述一个故事。这个故事——以笔记、影像和化验值的形式——就是你的数据。当涉及到人工智能时，这些数据的旅程成为同意对话的核心部分。这里的一个基本原则是**目的限制**：为某一目的收集的数据，未经许可不应用于另一目的 [@problem_id:4847324]。

这就产生了主要用途和次要用途之间的关键区别。

-   **主要用途**：在你的*就诊期间*，使用人工智能分析你的数据以帮助诊断，这属于治疗目的。
-   **次要用途**：在你的*就诊之后*，将你的记录副本发送给一家科技公司，以帮助他们改进其商业化人工智能产品，这属于次要用途。

尽管像HIPAA这样的健康隐私法可能允许在数据被“去识别化”后进行这种次要使用，但法律许可并不等同于伦理上的充分性 [@problem_id:4414040]。在一个充满压力的时刻，与其它文件捆绑在一起的一份密密麻麻的授权书上的签名，可能并不代表一个真正自愿和知情的选择。一个真正合乎伦理的流程需要就这些次要用途进行单独的对话。

此外，“去识别化”的承诺并非坚不可摧的盾牌。对于一个患有罕见、受污名化疾病且生活在小而可识别的农村地区的患者来说，从一个本应“匿名”的数据集中被重新识别出来的概率并非为零。这种隐私泄露可能造成的潜在伤害是严重的。因此，避免伤害的责任（**不伤害原则**）要求采取一种更为稳健的方法：针对次要用途的具体的、选择加入的同意，并结合先进的隐私保护技术和对谁可以访问数据及为何访问的严格治理 [@problem-id:4514100]。

### 超越签名：作为一种关系的同意

这使我们对同意的真正含义有了一个更深刻、更美好的理解。标准模型常常将其视为一个离散的、交易性的事件：披露事实，获得签名，归档表格。但对于像人工智能这样动态的技术来说，这个模型过于脆弱。一个人工智能模型的性能可能随时间漂移，它可能被更新，其数据可能被用于最初签名时无法想象的目标。

一个更稳健的框架是**关系性自主** [@problem_id:4410400]。这一思想源于关怀伦理学，它认为我们并非孤立的、原子化的决策者。我们做出选择的能力受到我们的关系、我们的环境以及我们所获得的支持的塑造。

在这种观点下，知情同意不是一次性的交易，而是一个持续的、对话式的过程。它是一种关系。想象一位数字素养有限的患者。一种交易性的方法可能只是记录下她缺乏理解。而一种关系性的方法则会邀请她将她信任的女儿带入对话中，为她构建理解和做出真正属于自己的选择的能力。

这个模型非常适合人工智能。它把同意变成一个活生生的过程，可以随着技术的发展、数据新用途的提出，或者患者自身理解和偏好的变化而重新审视。它是对不透明权威的非人化的终极解药，将同意从一个法律障碍转变为建立在信任和相互尊重基础上的持续对话 [@problem-id:4415669]。

### 超越个体：社群的声音

我们的旅程已从单个心智的内部运作，走向了医患关系的动态。但还有最后关键的一步。同意是否总是且仅仅关乎个人？

考虑一个项目，旨在使用一个原住民社群——Red River Nation——的基因组数据来构建一个人工智能模型 [@problem_id:4414045]。单个成员可能同意分享他们的数据。但由此产生的人工智能模型不仅仅关乎那一个人。它对整个社群做出预测，并带有集体风险，如群体污名化，以及集体利益。数据本身是一种社群资源，充满了共同的祖先和历史。

在这种情况下，个人同意是必要的，但并非充分。这里我们遇到了**[原住民数据主权](@entry_id:197632)**的原则，它主张一个民族有权管理源自他们的数据。这通过**CARE原则**（集体利益、控制权、责任、伦理）等框架来实施。这意味着社群必须通过其合法的、被承认的治理机构，提供**群体同意**。这不仅仅是一次咨询；这是对整个数据生命周期的集体治理实践，从收集到模型部署，再到利益共享。

在这里，同意的理念达到了其最完整、最统一的表达。它是一个可扩展的原则，尊重个体的自主权、他们生活的关系背景以及他们社群的主权身份。通过拥抱这种丰富、多层次的理解，我们可以确保，在用人工智能构建医学未来的同时，我们不是在削弱人类的主体性，而是在以其所有形式尊重它。

