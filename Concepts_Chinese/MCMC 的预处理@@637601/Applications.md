## 应用与跨学科联系

在我们完成了对马尔可夫链蒙特卡洛原理与机制的探索之后，你可能会有一种类似于学习国际象棋规则的感觉。你理解了棋子的移动方式，但你尚未见识到特级大师对局中那令人叹为观止的美。真正的魔力不在于规则本身，而在于如何应用它们来驾驭棋盘上巨大的复杂性。MCMC 亦是如此。基本的算法很简单，但将它们应用于真实的科学问题时，会揭示出复杂性和美丽程度都令人惊叹的图景。

在本章中，我们将探索这些图景。我们将看到，许多最激动人心的科学问题，从预测金融市场到破译遗传密码，都提出了一个共同的挑战：为我们的 MCMC 采样器提供了一个崎岖不平、难以驾驭的地形。我们还将发现，一个单一而优雅的思想——预处理——是驾驭所有这些问题的关键。这好比是为你想要攀登的山选择合适的登山靴的艺术。

### 从金融到生物学：驾驭相关参数

想象一下，你是一位试图为利率的期限结构建模的经济学家。你的模型可能有两个参数，比如 $\beta_1$ 和 $\beta_2$，它们紧密地联系在一起；也许 $\beta_1$ 每上升一点，$\beta_2$ 就必须下降一点，以保持模型与数据的一致性。在所有可能参数值的地图上，“高概率区域”——即优秀模型所在的区域——并不是一个简单的圆形山丘。相反，它是一条长而极其狭窄的山脊，斜跨在地图上 [@problem_id:2442816]。

现在，如果你使用一个简单的[随机游走](@entry_id:142620)采样器，你就好比一个徒步者，以固定大小的步长向随机的、各向同性的方向前进。如果你在山脊上迈出一步，你几乎肯定会掉进一个概率极低的“山谷”。你的算法会明智地拒绝这一步，而你将停在原地。为了增加你停留在山脊上的机会，你必须采取极其微小的步长。你会有很高的接受率，但你会以蜗牛般的速度沿着山脊爬行，几乎探索不到任何东西。这就是相关参数的诅咒。

当你看到地图时，解决方案似乎显而易见。你要么旋转地图，使山脊笔直延伸（一种称为*重新参数化*的技术），要么更直接地，改变你的步进方式。你可以不走圆形的步子，而是走椭圆形的步子，细长且与山脊对齐。这就是预处理的精髓。你根据问题的局部几何形状来调整你的提议分布 [@problem_id:2442816]。

真正非凡的是，完全相同的问题及其完全相同的解决方案，出现在完全不同的世界里。让我们从交易大厅跳到细胞核。一位系统生物学家正在构建一个[基因调控网络](@entry_id:150976)的模型，这是一个由几十个代表转录率、[结合亲和力](@entry_id:261722)等的参数描述的复杂相互作用网络。当他们试图使用 MCMC 将这个模型与实验[数据拟合](@entry_id:149007)时，他们发现一些参数紧密相连，在极其复杂的参数空间中形成高维“山脊” [@problem_id:3289358]。一个简单的采样器会彻底卡住。解决方案呢？正是同样的想法：利用初步运行的信息来估计这些山脊的形状，并构建一个预处理矩阵，使采样器能够沿着它们迈出长而智能的步伐。这个原理是普适的。

### 深入探究：[信息几何](@entry_id:141183)

到目前为止，我们的方法是直观的。我们“观察”后验地形，并据此设计我们的步长。但算法如何“看到”这个地形呢？答案在于微积分的语言。一个表面的形状由其曲率描述。对于我们的[后验概率](@entry_id:153467)[分布](@entry_id:182848)，一个峰值附近的局部曲率由 Hessian 矩阵——即对数概率的[二阶导数](@entry_id:144508)矩阵——来捕捉。表面急剧弯曲的方向（一个“刚性 (stiff)”方向）对应于 Hessian 矩阵的一个大[特征值](@entry_id:154894)；表面平坦的方向（一个“松弛 (sloppy)”方向）对应于一个小[特征值](@entry_id:154894)。

因此，有效的预处理就是关于使用该 Hessian 矩阵的逆作为我们提议的协[方差](@entry_id:200758) [@problem_id:2627984]。这会自动告诉采样器在刚性方向上提议小步长，在松弛方向上提议大步长，完美地适应地形。

这个想法引出了一个更深、更美的概念：*[信息几何](@entry_id:141183)*。在许多科学模型中，[对数似然](@entry_id:273783)的 Hessian 矩阵与另一个基本量密切相关：[Fisher 信息矩阵 (FIM)](@entry_id:186615) [@problem_id:3578633] [@problem_id:2661063]。FIM 告诉我们测量数据为模型参数提供了多少信息。FIM 较大的方向，恰好是我们的数据已经很好地确定的方向。

这提出了一个深刻的重新解释。预处理不仅仅是一个数值技巧；它等同于赋予我们的[参数空间](@entry_id:178581)一种新的几何结构，一种由信息本身定义的“度量”。在这种新的几何结构中，后验分布看起来更简单、更均匀。一种先进的 MCMC 方法，称为黎曼流形 MCMC，真正地采纳了这个想法，模拟在这个弯曲的信息[流形](@entry_id:153038)上的运动。这使得它能够以惊人的效率驾驭在化学动力学和系统生物学中常见的“松弛”模型，在这些模型中，参数组合可以变化几个[数量级](@entry_id:264888)而模型输出几乎不变 [@problem_id:2661063]。

当然，这是一个动态过程。当采样器探索时，局部曲率会发生变化。最先进的方法，无论是在[核物理](@entry_id:136661)学还是 MCMC 理论中，都常常采用自适应方案。它们利用采样器的历史来不断完善局部曲率的估计，并动态调整[预处理](@entry_id:141204)，例如，使用 Robbins-Monro 算法自动调整步长，以达到理论上的[最优接受率](@entry_id:752970)，对于[随机游走](@entry_id:142620)采样器，该值约为 $0.234$，对于[基于梯度的采样](@entry_id:749987)器，则为 $0.574$ [@problem_id:3578633] [@problem_id:3355206]。

### 现代前沿 I：驯服[深度学习](@entry_id:142022)

在高维、复杂地形的挑战方面，没有哪个领域比机器学习更明显。考虑一个[贝叶斯神经网络](@entry_id:746725) (BNN)。我们不是要找到一组“最佳”权重，而是要从权重在给定训练数据下的整个[后验分布](@entry_id:145605)中采样。这为我们提供了一种有原则的方式来量化模型的不确定性。

但权重的数量可能达到数百万甚至数十亿！“[参数空间](@entry_id:178581)”浩瀚如星海，其损失函数[曲面](@entry_id:267450)是出了名的复杂。然而，这只是一个宏大规模上的 MCMC 问题 [@problem_id:2453049]。负对数后验充当[势能](@entry_id:748988)，我们可以使用采样器来探索它。在这里，像 Metropolis 调整的 Langevin 算法 (MALA) 这样的[基于梯度的方法](@entry_id:749986)是必不可少的，因为它们利用损失的梯度来引导提议“下山”。

然而，即使是这些智能采样器也难以应对[神经网](@entry_id:276355)络损失[曲面](@entry_id:267450)的恶劣条件。解决方案再次是预处理。但这必须谨慎进行。正如我们在原理探索中看到的，在 Langevin 采样器中，如果仅仅将梯度乘以一个预处理矩阵，而不同时变换随机噪声项，将会使采样器偏离[轨道](@entry_id:137151)，靶向错误的[分布](@entry_id:182848) [@problem_id:2453049]。深度学习中的预处理艺术是一个活跃而激动人心的研究领域，但它建立在我们一直在探索的相同基础上。

### 现代前沿 II：从参数到函数

我们把最令人脑洞大开的应用留到了最后。到目前为止，我们一直在推断一组数字，即参数。但如果未知量不是一个数字列表，而是一个完整的*函数*呢？

这就是[贝叶斯逆问题](@entry_id:634644)的世界，它在科学和工程的各个领域都会出现。我们可能想从后期的测量数据推断钢梁的初始温度[分布](@entry_id:182848)，从地震波推断地面随空间变化的刚度，或者从少数传感器读数推断[偏微分方程](@entry_id:141332)模型中污染物的未知[源项](@entry_id:269111) [@problem_id:3402675]。未知量是一个[连续函数](@entry_id:137361)。

在这里，[预处理](@entry_id:141204)不再仅仅是为了效率而提出的一个好主意——它对于问题本身能够成立是*绝对必要*的。当我们在计算机上将函数离散化到网格上时，一个朴素的 MCMC 采样器的性能会随着我们加密网格而灾难性地下降。其接受率将骤降至零 [@problem_id:3385118]。为什么？原因很深刻。一个标准的[基于梯度的采样](@entry_id:749987)器所做的更新在[欧几里得空间](@entry_id:138052)中是自然的，但一个从具有物理意义的先验（通常倾向于平滑性）中抽取的典型函数，并不是一个“欧几里得”对象。一个朴素的更新步骤会在每个网格点上增加“白噪声”式的粗糙度，瞬间将一个平滑函数变成一个锯齿状的、非物理的函数，采样器理所当然会拒绝它。这个提议几乎肯定不在目标分布的高概率区域内 [@problem_id:3385118]。

解决方案是用先验协[方差](@entry_id:200758)本身进行预处理。这确保了提议的步长尊重函数空间固有的属性（如平滑性）。一个这样做的算法，比如[预处理](@entry_id:141204) Crank-Nicolson (pCN) 采样器，其性能与离散化无关。它在函数空间上是“适定的”。

更复杂的技术在此基础上构建。在许多此类问题中，我们拥有的有限数据量只能为无限维[函数空间](@entry_id:143478)内的少数有限“特征”或“方向”提供信息。像[似然信息子空间](@entry_id:751278) (LIS) 这样的方法的绝妙之处在于，识别出数据与我们“对话”的那个低维[子空间](@entry_id:150286)，然后在该[子空间](@entry_id:150286)中使用强大的、数据感知的提议，而在其他所有地方使用简单的、保持先验的提议 [@problem_id:3376425]。这是[预处理](@entry_id:141204)哲学的终极体现：仔细倾听数据告诉你的信息，并将你的努力集中在那里。

### 简单思想的统一性

我们的旅程结束了。我们从金融领域一个简单的二维问题开始，最终在物理和数据同化领域对整个函数进行采样。我们在遗传学、化学和[深度学习](@entry_id:142022)中看到了同样的挑战。然而，解开每个问题的核心原则是相同的：理解你的[后验分布](@entry_id:145605)的几何形状，并调整你的工具来与之匹配。[预处理](@entry_id:141204)正是实现这一目标的艺术与科学，是一条贯穿整个现代计算科学版图的美丽的统一线索。