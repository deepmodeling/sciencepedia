## 引言
在一个从工程设计到医疗诊断等各方面都日益依赖[计算模型](@entry_id:152639)的世界里，确定性的假设可能是危险的。每个模型都是对现实的简化，天生就不完整，并受到各种形式不确定性的影响。我们简化的模型与它们所代表的复杂世界之间的这种差距，迫切需要一种规范的方法来理解和量化我们的模型所不知道的东西。简而言之，如果我们不知道应该对一个模型的预测有多大信心，我们又如何能信任它呢？

本文是关于**[模型不确定性](@entry_id:265539)量化（UQ）**这门科学的综合指南——这是一个构建“知道自己所不知”的模型的框架。在接下来的章节中，我们将踏上一段从理论到实践的旅程。首先，在**原理与机制**部分，我们将剖析 UQ 的基本概念，学习区分不同类型的不确定性，通过[敏感性分析](@entry_id:147555)识别关键的模型参数，并利用强大的计算工具来传播不确定性。随后，在**应用与跨学科联系**部分，我们将看到这些原理如何应用于解决现实世界的问题，展示 UQ 在工程、人工智能和医学等不同领域中建立可信度、实现[稳健决策](@entry_id:184609)的变革性影响。

## 原理与机制

每当我们建立一个模型，无论是用来预测天气、设计新电池，还是指导外科医生，我们都是在为一个复杂的现实编织一个简化的故事。和任何故事一样，它也有其模糊和疏漏之处。**不确定性量化（UQ）**这门科学就是理解、衡量和沟通这些不确定性的艺术。它的核心是用概率分布的诚实智慧，取代单一数字的欺骗性确定性。它是关于构建“知道自己所不知”的模型。

### 不确定性的两种灵魂

让我们从一个简单的思想实验开始。想象一下，你正试图预测一粒从花朵上释放的花粉的精确着陆点。是什么让这件事变得困难？你很快会意识到，这里有两种根本不同类型的“未知”在起作用。

首先，是世界固有的、不可减少的随机性。空气中微小的、混乱的[涡流](@entry_id:271366)会以不可预测的方式冲击这粒花粉。即使你对更大尺度上的风[场模](@entry_id:189270)式了如指掌，花粉的最终位置仍然会带有一种“模糊性”。这就是**[偶然不确定性](@entry_id:154011)**（aleatory uncertainty），源自拉丁语 *alea*，意为“骰子”或“机会游戏”。这是宇宙在掷骰子。它代表了系统中固有的变异性，我们无法通过收集更多关于模型的信息来减少它。我们只能希望用概率的语言来描述它。这就是我们在具有相同[遗传标记](@entry_id:202466)的患者之间看到的生物学变异性 [@problem_id:5042744]，[材料微观结构](@entry_id:198422)中的随机波动 [@problem_id:3763764]，或是传感器测量中不可避免的噪声 [@problem_id:4228105]。

其次，是我们自身的无知。也许我们对风场的描绘不完整，或者我们不知道花粉的确切重量和形状。这就是**认知不确定性**（epistemic uncertainty），源自希腊语 *episteme*，意为“知识”。它不是花粉本身的属性，而是*我们关于它的知识*的属性。关键的区别在于，[认知不确定性](@entry_id:149866)原则上是可以减少的。我们可以进行更多的[风洞](@entry_id:184996)实验，以更好地确定我们[流体动力](@entry_id:750449)学模型中的参数，或者使用更强大的显微镜来测量花粉。这就是我们在药代动力学模型的校准系数或[燃烧模拟](@entry_id:155787)中的[反应速率](@entry_id:185114)上存在的不确定性 [@problem_id:4075423]。

令人惊奇的是，数学提供了一种优美的方式来正式区分这两种不确定性的灵魂：[全方差定律](@entry_id:184705)（Law of Total Variance）。如果我们让模型的预测为 $Y$，它依赖于一些不确定的参数 $\theta$，那么我们预测的总方差可以被完美地分解为：

$$
\operatorname{Var}(Y) = \mathbb{E}_{\theta}[\operatorname{Var}(Y | \theta)] + \operatorname{Var}_{\theta}(\mathbb{E}[Y | \theta])
$$

我们不必被这些符号吓倒。第一项，$\mathbb{E}_{\theta}[\operatorname{Var}(Y | \theta)]$，是**偶然**部分。它是如果我们完全知道参数 $\theta$ 时，所能看到的固有变异性（$\operatorname{Var}(Y | \theta)$）的平均值。第二项，$\operatorname{Var}_{\theta}(\mathbb{E}[Y | \theta])$，是**认知**部分。它衡量了当我们考虑参数 $\theta$ 的不确定性时，我们的平均预测 $\mathbb{E}[Y | \theta]$ 变化了多少。这个优雅的公式为我们提供了一份精确的账单，说明我们的总不确定性中有多少来自自然的随机性，又有多少来自我们自身的知识缺乏 [@problem_id:3763764] [@problem_id:5042744]。

### 机器中的幽灵：[模型形式误差](@entry_id:274198)

然而，还有一种更深层、更麻烦的[认知不确定性](@entry_id:149866)。到目前为止，我们都假设我们模型的方程——它的基本结构——是正确的，我们只是不知道其参数的正确值。但如果方程本身就是错的呢？这不仅仅是一个缺失的数字；这是蓝图中的一个缺陷。这被称为**结构不确定性**（structural uncertainty），或**[模型差异](@entry_id:198101)**（model discrepancy）。

考虑[湍流](@entry_id:158585)[流体流动](@entry_id:201019)的复杂、旋转的世界。为了使其在计算上易于处理，工程师们使用简化的模型，如[雷诺平均纳维-斯托克斯](@entry_id:173045)（Reynolds-Averaged [Navier-Stokes](@entry_id:276387), RANS）方程。这些模型引入了一些假设，例如 Boussinesq 假设，该假设假定[湍流](@entry_id:158585)应力与平均流的应变率之间存在简单的线性关系。这是对一个远为复杂的现实的近似。无论你如何完美地调整模型的参数（比如那个臭名昭著的常数 $C_\mu$），对于某些类型的流动，例如那些具有强曲率或旋转的流动，该模型将系统性地出错 [@problem_id:2536810]。这个误差被固化在模型的结构中。

忽略这种[模型差异](@entry_id:198101)是危险的。如果我们用有缺陷的模型来校准实验数据，参数将被迫取一些“有效”但非物理的值，以补偿模型的结构性错误。模型可能看起来与校准[数据拟合](@entry_id:149007)得很好，但当我们用它来预测新事物（外推）时，预测结果可能是危险的错误和极度的过度自信 [@problem_id:3959836]。

诚实而稳健的方法是直面这个机器中的幽灵。我们可以用一个明确的差异项来增强我们的模型：

$$
\text{Reality} = \text{Model}(\text{parameters}) + \text{Discrepancy}
$$

在这里，差异项是另一个我们试图从数据中学习的未知函数，与模型参数一起学习。这可以防止物理参数被污染，并提供对总不确定性更现实的估计。它承认我们的模型是现实的漫画，并量化了它到底在多大程度上是漫画。这是为做出稳健、高风险决策建立可信预测的基石 [@problem_id:3959836]。我们甚至可以扩展这个想法，来考虑计算机本身引入的误差——完美的数学模型与我们实际计算的近似数值解之间的差异 [@problem_id:3236731]。

### 提出“如果……会怎样？”：敏感性分析的艺术

一旦我们识别了所有这些[不确定性的来源](@entry_id:164809)，一个自然的问题就出现了：“哪一个最重要？”我们的实验预算有限，时间也有限。我们应该把它花在更好的实验上以确定一个扩散系数，还是花在开发更先进的[湍流模型](@entry_id:190404)上？回答这个问题需要**敏感性分析**。

最简单的方法是**局部[敏感性分析](@entry_id:147555)**。它问：“如果我稍微调整这一个输入参数，输出会改变多少？”在数学上，这只是输出相对于输入参数的[偏导数](@entry_id:146280)，在一个名义点上求值：$S_i = \partial Q / \partial \theta_i$ [@problem_id:4075423]。这个系数的符号告诉我们影响的方向（例如，在化学反应中增加活化能 $E_a$ 会降低[反应速率](@entry_id:185114)，导致负的敏感性），其大小告诉我们它的影响力有多大——在局部范围内。

但世界很少是局部和线性的。参数会发生大的变化，并且常常以复杂的方式相互作用。为了得到全貌，我们需要**[全局敏感性分析](@entry_id:171355)（GSA）**。最强大的 GSA 技术是基于方差的，它为我们提供了所谓的**Sobol' 指数**。其思想是将模型输出的总[方差分解](@entry_id:272134)为可归因于每个输入参数及其相互作用的部分 [@problem_id:4121050]。
- **一阶 Sobol' 指数**，$S_i$，告诉我们由*单独*改变参数 $X_i$ 引起的输出方差的比例。
- **总 Sobol' 指数**，$S_{Ti}$，告诉我们由 $X_i$ 引起的输出方差的比例，包括其直接效应*以及*其与所有其他参数的相互作用。

如果一个参数的总指数很高但一阶指数很低，这意味着它是一个“团队合作者”——它主要通过与其他因素的复杂相互作用来发挥其影响。Sobol' 指数为我们提供了一个完整的、定量的排序，说明是什么驱动了我们模型中的不确定性，使我们能够将精力集中在最有影响力的地方。

### 建模者的工具箱：从暴力计算到优雅的代理模型

知道哪些参数重要是一回事；计算我们输出预测的完整分布范围是另一回事。这是[不确定性传播](@entry_id:146574)的任务。

最直接的方法是历史悠久的**[蒙特卡洛模拟](@entry_id:193493)**。我们简单地将输入视为随机变量，从它们的概率分布中抽取数千个样本，为每个样本运行我们庞大而复杂的模拟，并收集输出。由此产生的输出[直方图](@entry_id:178776)为我们描绘了输出分布的图像。这种方法稳健而简单，但如果每次模拟运行需要数小时或数天，通常会成本高得令人望而却步。

我们可以更聪明一点。**[拉丁超立方抽样](@entry_id:751167)（LHS）**是一种“分层”抽样技术。LHS 不是完全随机地向靶子投掷飞镖，而是确保我们在输入空间的每个“行”和每个“列”中都有一个样本。这保证了对参数空间更均匀的探索，对于输入没有疯狂相互作用的模型，通常能用相同数量的模拟运行得到更准确的均值和方差估计 [@problem_id:4075272]。

但是，如果连几百次模拟运行都太多了怎么办？我们需要一个**代理模型**（也称为元模型或模拟器）——一个对我们昂贵模拟的廉价、快速的近似。构建代理模型是 UQ 中的一项核心活动，并且有丰富的工具箱可供使用 [@problem_id:3895231]。

*   **[多项式混沌展开](@entry_id:162793)（PCE）：** 这是一个具有惊人数学优雅性的想法。我们可以将我们复杂的模型表示为一系列简单的正交多项式的无限级数。通过截断这个级数并找到系数（通常用一小组精心选择的模拟运行），我们得到了一个代理模型。神奇之处在于，从这些系数中，我们可以几乎瞬间地、解析地计算出输出的均值、方差，甚至是 Sobol' 敏感性指数。

*   **[高斯过程回归](@entry_id:276025)（GPR）：** 这是一种贝叶斯方法。GPR 不是为代理模型假设一个特定的函数形式，而是在*所有可能函数*的空间上设置一个[先验概率](@entry_id:275634)分布。当我们向它提供来自我们模拟的数据时，它使用[贝叶斯法则](@entry_id:275170)来更新这个分布。结果不仅仅是一个单一的预测，而是对于任何新输入的完整[预测分布](@entry_id:165741)。它的均值给出了最可能的输出，而其方差则是一个内置的[认知不确定性](@entry_id:149866)度量！这个方差在我们没有数据的区域自然会更大，这使得 GPR 成为“[主动学习](@entry_id:157812)”的完美引擎，模型本身会告诉我们应该在哪里运行下一次昂贵的模拟以学到最多 [@problem_id:2760107]。

*   **[物理信息神经网络](@entry_id:145229)（PINN）：** 这是该领域的新秀，它将[深度学习](@entry_id:142022)的力量与物理定律的严谨性融为一体。PINN 是一个神经网络，其训练目标不仅是拟合可用数据，还要满足系统的控制[偏微分](@entry_id:194612)方程。如果网络的输出违反了像质量守恒或能量守恒这样的基本定律，我们会对其进行惩罚。虽然标准的 PINN 是确定性的，但它可以嵌入到贝叶斯或集成框架中以产生[不确定性估计](@entry_id:191096)，为整合数据和第一性原理知识提供了一种强大的方式 [@problem_id:3895231]。

一句警告：即使对于像[稀疏回归](@entry_id:276495)这样表面上简单的数据驱动模型，获得有效的[不确定性估计](@entry_id:191096)也并非易事。一个常见的错误是采用一种流行的机器学习方法，如 LASSO 估计器，并试图在其输出上加上标准的[误差棒](@entry_id:268610)。这在数学上通常是不正确的，因为那些[标准误差公式](@entry_id:172975)的假设被违反了。真正的 UQ 需要更复杂的方法，例如具有自定义先验的完全贝叶斯模型或先进的统计推断技术 [@problem_id:5226512]。

### 建立信任：可信度的三位一体

最后，让我们把视野拉远。所有这些部分如何融入构建一个我们可以信赖的[计算模型](@entry_id:152639)，以做出重要的、现实世界的决策这一宏大挑战中？这就是“[V&V](@entry_id:173817)/UQ”框架的用武之地，这是一个为建立模型可信度所必需的活动三位一体，尤其是在医学和航空航天等高风险领域 [@problem_id:3917327]。

1.  **验证（Verification）：** 这个活动提出问题：“我们是否在正确地求解方程？”这是一个数学和软件工程的练习。它涉及检查代码中的错误，确保[数值算法](@entry_id:752770)被正确实现，以及研究当我们细化计算网格时解的误差如何减少。验证是建模者与计算机之间的对话，确保代码按预期工作。

2.  **确认（Validation）：** 这个活动提出一个更深层次的问题：“我们是否在求解正确的方程？”这是一个科学练习，将模型的预测与现实世界的实验数据进行比较。在这里，我们评估诸如[模型差异](@entry_id:198101)之类的事情，并进行[模型校准](@entry_id:146456)，以查看我们的模型是否能在一定容差内再现物理现实 [@problem_id:2760107]。确认是模型与自然之间的对话。

3.  **不确定性量化（UQ）：** 这个活动提出问题：“考虑到所有不确定性，我们对预测有多大信心？”它承认模型和数据都是不完美的，并提供了以严谨、定量的方式表达我们信心（或缺乏信心）的语言和工具。

对此的现代方法，在 ASME [V&V](@entry_id:173817) 标准等标准中被形式化，是**风险知情**的。它不是一个僵化的清单。[V&V](@entry_id:173817)/UQ 所需的严谨程度完全取决于**使用情境（Context of Use, COU）**。一个用于预测太阳能电池板最佳角度的模型，所需要的审查比一个用于指导外科医生放置起搏器导线的心脏数字孪生要少 [@problem_id:3917327]。对于高风险决策，我们需要来自所有三个支柱——验证、确认和 UQ——的更多证据，以证明模型对其预期目的足够可信。这是 UQ 的最终目标：将我们的模型从黑箱神谕转变为科学发现和工程创新过程中透明、可信赖的伙伴。

