## 引言
图——一组简单的点和线——是模拟我们世界中各种连接的最强大抽象工具之一，从社交友谊到互联网结构。然而，并非所有图的行为都相同。一个具有深远影响的基本区别是，一个网络是稠密的（连接数接近最大可能值），还是稀疏的（连接数相对较少）。大多数现实世界中的网络绝大多数都是稀疏的，而这一个属性改变了一切，从我们如何在计算机中存储网络，到我们用来解决其上问题的策略。本文探讨了[稀疏性](@article_id:297245)的概念，解决了如何利用这种结构特性来提高计算效率的关键问题。您将学习到[稀疏性](@article_id:297245)如何决定数据结构和[算法设计](@article_id:638525)的选择，并见证其在众多学科中的变革性影响。

接下来的章节将引导您完成这次探索。首先，在“原理与机制”中，我们将深入探讨[稀疏性](@article_id:297245)的核心定义、其对[邻接表](@article_id:330577)等[数据表示](@article_id:641270)方式的影响，以及它如何从根本上改变了路径寻找等任务的[算法](@article_id:331821)性能甚至选择。然后，在“应用与跨学科联系”中，我们将穿越不同领域——从社交网络和芯片设计到生物化学和人工智能——去见证[稀疏性](@article_id:297245)原则如何为理解和操纵复杂系统提供关键。

## 原理与机制

我们有图这个概念——点和线的集合，即顶点和边。这是一个极其简单的抽象，但其强大足以描述从你学校里的友谊到庞大的万维网的一切。但事实证明，并非所有的图都是生而平等的。你可以做出的最重要的区分之一，一个能改变从如何在计算机中存储图到解决其上问题的策略的区分，就是图是**稠密的**还是**稀疏的**。

### 连接数量的问题

让我们想象一下万维网。每个网页是一个顶点，每个超链接是一条从一个页面指向另一个页面的有向边。如果我们有 $n$ 个网页，我们可能拥有的最大超链接数是多少？任何页面都可以链接到任何其他页面（不包括它自己），所以我们最多可以有 $n(n-1)$ 个链接。对于一个拥有数十亿页面的网络来说，这个数字是天文数字，量级为 $n^2$。

但真实的万维网是这样的吗？当然不是。平均每个网页不会链接到十亿个其他页面；它链接到少数几个——十个、二十个，也许一百个。关键的洞见是，即使网页总数爆炸式增长，每个页面的平均链接数也基本保持不变。边的总数 $m$ 最终大致与顶点的数量 $n$ 成正比。当我们看到像 $m = \Theta(n)$ 这样的关系时，我们面对的就是一个**[稀疏图](@article_id:325150)**。与此形成鲜明对比的是，**[稠密图](@article_id:639149)**的边数接近最大可[能值](@article_id:367130)，即 $m = \Theta(n^2)$ [@problem_id:3237301]。

这不仅仅是关于网络的一个奇特事实。你将遇到的大多数现实世界网络——社交网络、公[路图](@article_id:338292)、蛋白质相互作用、电路——绝大多数都是稀疏的。你的朋友圈不会扩展到包括世界人口的一个固定百分比；你认识的人数相对较少。城市中的一个十字路口与三四个其他十字路口相连，而不是数千个。稀疏性这个属性是如此基本，以至于它决定了我们与这些网络互动的整个策略手册。

### 稀疏第一法则：只存储你拥有的

假设你正在构建一个工具来模拟一个城市的道路网络。十字路口是顶点，道路是边。城市在不断发展，所以你会不断地增加新的十字路口和道路。你应该如何在计算机内存中存储这个图呢？

你有两个主要选择。第一个是**邻接矩阵**。你可以把它想象成一个巨大的电子表格，一个大小为 $n \times n$ 的网格。如果十字路口 $i$ 和 $j$ 之间有路，第 $i$ 行第 $j$ 列的条目就是'1'，否则是'0'。这很简单，而且检查任意两个十字路口之间是否有路非常快——只需一次查找。

第二个选择是**[邻接表](@article_id:330577)**。这更像一个名片册。对于每个十字路口，你只需保留一个其直接邻居的简单列表。

对于[稀疏图](@article_id:325150)来说，这两者之间的差异是惊人的。[邻接矩阵](@article_id:311427)需要 $n^2$ 位的内存，无论有多少条路。对于一个有 10,000 个十字路口的城市，那就是 1 亿位，其中大部分将是'0'，存储着两个遥远十字路口之间没有直路的“非事实”。更糟糕的是，增加一个新的十字路口意味着你必须拆掉并重建整个 $n \times n$ 的网格，使其成为 $(n+1) \times (n+1)$。

另一方面，[邻接表](@article_id:330577)只存储实际存在的道路。它的内存占用与 $n + m$ 成正比。对于一个 $m$ 与 $n$ 同阶的稀疏道路网络，这仅仅是 $\Theta(n)$。它的内存效率要高得多。而且增加一个新的十字路口？你只需在你的集合中添加一个新的空列表。这是一个简单、廉价的操作。对于任何动态增长的稀疏网络，[邻接表](@article_id:330577)不仅仅是一个好选择；它是唯一明智的选择 [@problem_id:1348814]。

### [算法](@article_id:331821)的困境：为你所用的付费

这种选择的后果远不止于内存。你使用的[数据结构](@article_id:325845)决定了你如何在图中“行走”，这直接影响了你[算法](@article_id:331821)的速度。

让我们以最基本的图[算法](@article_id:331821)之一：[广度优先搜索](@article_id:317036)（BFS）为例。这是你在[无权图](@article_id:337228)中寻找[最短路径](@article_id:317973)的方法，比如寻找两个地铁站之间的最少停站次数。该[算法](@article_id:331821)从一个起点开始，逐层探索图。

- 如果你使用**邻接矩阵**，每次访问一个新顶点时，你都必须问：“你的邻居是谁？”为了回答这个问题，你必须扫描该顶点在矩阵中的整行——所有 $n$ 个条目——只为了找到那几个'1'。因为你对每个顶点都这样做，搜索的总时间变成了 $\Theta(n^2)$。

- 如果你使用**[邻接表](@article_id:330577)**，问“你的邻居是谁？”就变得微不足道。你只需读取与该顶点关联的短列表。在整个[算法](@article_id:331821)过程中，你将精确地查看每个顶点和每条边一次。总时间是优美的 $\Theta(n + m)$。

现在，让我们代入我们对[稀疏性](@article_id:297245)的理解。对于一个[稀疏图](@article_id:325150)，其中 $m = \Theta(n)$，[邻接表](@article_id:330577)方法给我们的运行时间是 $\Theta(n)$。而[邻接矩阵](@article_id:311427)给出的是 $\Theta(n^2)$。这不是一个小的差异。对于一个有一百万个节点的图，一种方法可能需要几秒钟，而另一种可能需要几天。从像 BFS 和 DFS [@problem_id:3276740] 这样的基本搜索，到像 Dijkstra [算法](@article_id:331821)这样更复杂的寻找[最短路径](@article_id:317973)的[算法](@article_id:331821)，一整类[算法](@article_id:331821)的效率都取决于选择一个能利用[稀疏性](@article_id:297245)的表示方法 [@problem_id:3221808]。

### 当暴力破解战胜天才

故事变得更加有趣。[稀疏性](@article_id:297245)不仅使现有[算法](@article_id:331821)更快；它还可以完全改变我们解决问题的策略，有时以奇妙的反直觉方式。

考虑寻找图的**直径**问题——任意两节点间最长的那条[最短路径](@article_id:317973)。这是理解网络“分散”程度的一个关键指标。要找到它，我们需要知道*所有节点对*之间的[最短路径](@article_id:317973)。

有一个著名的、优雅的[算法](@article_id:331821)叫做 **Floyd-Warshall**，专门为这个所有节点对最短路径（APSP）问题设计。它使用了一种巧妙的[动态规划](@article_id:301549)方法，其运行时间总是 $\Theta(n^3)$，无论图有多少条边。

现在，让我们考虑一个“更笨”的方法。我们知道 BFS 可以在[邻接表](@article_id:330577)上以 $\Theta(n+m)$ 的时间找到从单一源点的[最短路径](@article_id:317973)。如果我们从图中的*每个顶点*都运行一次 BFS 会怎么样？有 $n$ 个顶点，所以总时间将是 $n \times \Theta(n+m) = \Theta(n^2 + nm)$。

让我们比较一下。在一个[稠密图](@article_id:639149)上，其中 $m=\Theta(n^2)$，我们的“笨”方法需要 $\Theta(n^3)$，与优雅的 Floyd-Warshall 相同。但在一个**[稀疏图](@article_id:325150)**上，其中 $m=\Theta(n)$，我们的“笨”方法仅仅需要 $\Theta(n^2)$！

想一想这意味着什么。在那些模拟我们世界的网络上，一个简单、重复、暴力的基本[算法](@article_id:331821)应用，其性能竟戏剧性地超越了一个复杂的、专门化的[算法](@article_id:331821) [@problem_id:3279091]。稀疏性这个属性是如此强大，以至于它让本应是幼稚的策略变成了天才之举。

### 可能性的边缘：无法打破的速度限制？

我们已经看到，对于[稀疏图](@article_id:325150)，我们可以设计出比它们的[稠密图](@article_id:639149)对应物快得多的[算法](@article_id:331821)。APSP 问题从 $\Theta(n^3)$ 降到了 $\Theta(n^2)$。这就引出了一个问题：我们还能做得多好？我们能否在，比如说，$\Theta(n^{1.5})$ 的时间内找到一个稀疏[图的直径](@article_id:335052)？是否有一个“真正次二次方”的[算法](@article_id:331821)等待被发现？

这个问题将我们带到了[理论计算机科学](@article_id:330816)的最前沿。许多研究人员认为，对于某些问题，存在我们可能永远无法打破的基本“速度限制”。其中最著名的之一是**[强指数时间假说](@article_id:334203)（SETH）**。不深入细节，S[ETH](@article_id:297476) 假设一个与在高维空间中寻找垂直向量相关的问题，其解决速度不会比一种略优于暴力破解的方法更快。这是一个猜想，但被广泛认为是真的。

这里的联系令人震惊。研究人员已经证明，如果你能以真正的次二次方时间（例如，$O(n^{2-\epsilon})$，对于某个常数 $\epsilon > 0$）找到稀疏[图的直径](@article_id:335052)，即使是近似的，你也可以用那个[算法](@article_id:331821)作为子程序来打破 SETH。具体来说，他们展示了如何将向量问题的一个实例转换为一个[稀疏图](@article_id:325150)，如果存在解，该[图的直径](@article_id:335052)为 6，否则为 4。一个能够以优于 $\frac{3}{2}$ 的因子近似直径的[算法](@article_id:331821)，将能够区分 4 和 6，并在此过程中，比 S[ETH](@article_id:297476) 的“速度限制”更快地解决原始向量问题 [@problem_id:1424344]。

因此，如果我们相信 SETH，那么就不存在这样真正的次二次方直径[算法](@article_id:331821)。我们那个“笨”的、$\Theta(n^2)$ 的重复 BFS 方法，实际上可能就是我们能[期望](@article_id:311378)的最好结果。

大多数网络并非拥有所有可能的连接——这个简单的观察，即[稀疏性](@article_id:297245)，开启了一个丰富而美丽的世界。它指导我们关于数据和计算最实际的决策，同时，它也引导我们去思考关于可能性基本极限的最深刻、最具挑战性的问题。

