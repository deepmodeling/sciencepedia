## 引言
确定因果关系是科学探究的一个根本目标，但其黄金标准方法——随机对照试验（RCT）——常常由于伦理、实践或财务原因而无法实施。研究人员必须频繁地转向观测数据，而在这些数据中，处理并非随机分配。这就引入了一个关键挑战：混杂。这是一种偏倚，当被比较的组别从一开始就存在系统性差异时便会发生，从而使得将处理的真实效应与预先存在的差异分离开来变得困难。这可能导致对干预措施的有效性或安全性得出危险的错误结论。

倾向性评分法提供了一个强大的统计框架来解决这一问题。它们提供了一种严谨的方法来分析观测数据，通过模拟RCT的设计，使研究人员能够得出更可靠的因果推断。本文旨在为理解和应用这一重要工具提供指南。第一章“原理与机制”，将深入解析倾向性评分背后的核心理论，从其由Paul Rosenbaum和Donald Rubin提出的精妙构思，到用于分析的实用技术。随后的“应用与跨学科联系”一章将探讨这些方法如何在现实世界中得到应用——从临床医学到监管科学——同时也会讨论其局限性及其在更广泛的因果推断生态系统中的位置。

## 原理与机制

假设我们想知道一种新的心脏病药物是否能拯救生命。在理想世界中，我们会进行一项随机对照试验：为每位患者抛硬币，正面朝上他们获得新药，反面朝上他们获得旧药。一年后，我们统计结果。因为抛硬币是随机的，两个组——“处理组”和“[对照组](@entry_id:188599)”——平均而言，在研究开始时互为镜像。我们在研究结束时看到的任何差异都可以自信地归因于药物本身。这是黄金标准。

但如果我们只有观测数据呢？如果我们回顾成千上万份电子健康记录呢？在这些记录中，医生选择了开哪种药。也许他们把效力强大的新药给了病情最重的患者，而没有给较健康的患者使用。如果我们天真地比较这两个组，我们可能会发现新药组的死亡人数更多！我们可能错误地得出结论，认为这种药是有害的。这是经典的**混杂**陷阱。我们比较的不是苹果和苹果，而是病苹果和健康的橙子。药物的效果与患者的初始健康状况纠缠在一起。这个特殊的问题，即医生的决策基于患者的预后，在医学中非常普遍，它有自己的名字：**指示混杂**（confounding by indication）[@problem_id:4830539]。

那么，我们如何解开这个结呢？我们的目标是模拟我们希望当初能够进行的那项随机试验——这个想法通常被称为模拟**目标试验**（target trial）[@problem_id:4501711]。我们希望使两个组具有可比性，至少在我们能测量的所有患者特征上是如此：年龄、性别、血压、合并症等等。

### 维度灾难与天才之举

你可能会想：“简单！对于每个接受新药的75岁吸烟男性高血压患者，我们找一个接受旧药的75岁吸烟男性高血压患者进行比较。”这是一个好主意，但它很快就会失效。随着你增加更多的特征，你试[图匹配](@entry_id:270069)的“单元格”会变得微乎其微。在几十个变量上找到一个精确匹配的概率几乎为零。这就是**[维度灾难](@entry_id:143920)**。

这正是**倾向性评分**的天才之处。在1983年一篇里程碑式的论文中，Paul Rosenbaum和Donald Rubin提出了一个惊人而优雅的解决方案。与其试图一次性平衡几十个协变量（$X$），我们是否可以将所有这些信息压缩成一个单一的数字？这个数字就是倾向性评分。

**倾向性评分**，记为$e(X)$，定义为在给定个体所有基线协变量的情况下，其接受处理的条件概率[@problem_id:4862780]。

$$e(X) = P(\text{Treatment}=1 \mid X)$$

简单来说，它是一个人接受处理的*倾向*或*可能性*，基于我们在处理决定做出之前所知道的关于他们的一切。例如，我们可能建立一个简单的[统计模型](@entry_id:755400)，如逻辑回归，来根据患者的年龄和某个生物标志物水平来预测处理分配[@problem_id:4558587]。一个具有强烈预测会接受处理的特征的患者，其倾向性评分会接近1；一个具有预测其将进入[对照组](@entry_id:188599)的特征的患者，其评分会接近0。

### 平衡之术：倾向性评分的魔力

接下来是美妙的部分。Rosenbaum和Rubin证明了一个非凡的定理：如果我们能使处理组和[对照组](@entry_id:188599)具有相同的倾向性评分分布，那么我们也就延伸性地使它们在构成该评分的所有协变量（$X$）上具有相同的分布。以这个单一的数字$e(X)$为条件，就如同以$X$中所有单个协变量为条件一样好。这就是倾向性评分的**平衡性质**。

$$T \perp X \mid e(X)$$

这个公式表示，一旦我们在具有相同倾向性评分$e(X)$的人群切片内，处理分配（$T$）就与协变量（$X$）无关[@problem_id:4862780]。可以这样理解：如果一个病情很重的人（他“应该”得到新药，评分高）和一个非常健康的人（他“不应该”得到新药，评分低）在我们的研究中，我们不能比较他们。但是，如果我们找到两个人——一个得到了药，一个没有——他们根据各自的详细资料都有70%的可能性得到这种药，那么这两个人在统计意义上是可交换的。他们就是我们的“苹果和苹果”。倾向性评分给了我们一种有原则的方法来找到他们。

### 用于比较的工具箱

一旦我们为研究中的每个人估算出了倾向性评分，我们就拥有了一个强大的工具箱来进行公平的比较。主要有三种策略[@problem_id:4956709]：

1.  **匹配（Matching）：** 这是最直观的方法。对于处理组中的每个人，我们在[对照组](@entry_id:188599)中找到一个或多个倾向性评分非常相似的人。我们用这些“统计双胞胎”创建一个新的、更小的数据集。未处理的匹配对象作为处理个体的反事实。通过这样做，我们主要在问：“对于实际接受了处理的这类人，处理的效果是什么？”这个量被称为**处理组平均[处理效应](@entry_id:636010)（ATT）**。

2.  **分层（Stratification，或Blocking）：** 我们可以根据倾向性评分将人群分成，比如说，五个或十个“箱子”（例如，所有评分在0-0.2之间的人，0.2-0.4之间的人，依此类推）。在每个箱子内，处理组和[对照组](@entry_id:188599)的受试者现在相当均衡。我们可以在每个箱子内计算[处理效应](@entry_id:636010)，然后将这些效应在所有箱子间取平均，得到一个单一的[总体估计](@entry_id:200993)值。

3.  **逆概率处理加权（Inverse Probability of Treatment Weighting, IPTW）：** 这可能是最强大但不太直观的方法。其思想是创建一个不存在混杂的**伪群体**[@problem_id:4501711]。我们给每个人分配一个权重。一个倾向性评分较低的处理组个体（例如，一个得到高风险新药的健康人，评分=0.1）是“出乎意料的”。他们被赋予一个大的权重（$1/0.1 = 10$），以代表其他九个按预期未得到该药的类似健康人群。相反，一个倾向性评分较高的未处理组个体（例如，一个未得到新药的重病患者，评分=0.9）也是出乎意料的。他们得到的权重是$1/(1-0.9) = 10$。这个重新加权的过程放大了“出乎意料”的案例，缩小了“符合预期”的案例，从而创建了一个新的、合成的群体，在这个群体中，协变量完全平衡，处理看起来像是随机分配的。这种方法通常回答的问题是：“如果我们将处理措施给予整个人群，平均效应会是什么？”这就是**平均处理效应（ATE）**[@problem_id:4956709]。

ATT和ATE之间的选择不仅仅是学术性的；它取决于政策问题。如果你想知道项目对参与者的效果如何，你想要ATT。如果你想决定是否向所有人推广该项目，你想要ATE。

### 规则与前提：诊断和假设

这个强大的工具箱并非凭空生效。它在严格的规则下运行，并需要仔细的诊断性检验。

首先是**正性**（positivity）的关键假设，也称为**重叠**（overlap）或**共同支撑**（common support）[@problem_id:4979362]。这意味着对于任何给定的特征集，被分到处理组或[对照组](@entry_id:188599)的概率都必须非零。换句话说，不存在“确定性”的处理。如果所有80岁以上的患者都得到新药，而80岁以下的患者都没有得到，那么就不存在重叠。你看不到的就无法比较。我们通过绘制处理组和未处理组的倾向性评分分布图来诊断这一点。如果分布不重叠，我们就有问题了[@problem_id:4635182]。标准的解决方案是“修剪”样本，将我们的分析限制在共同支撑的区域。这解决了统计问题，但也改变了我们的研究问题：我们现在只能对具有重叠的亚群体提出主张，而不能对整个人群。

其次，我们必须假设**条件[可交换性](@entry_id:263314)**，即我们测量的协变量$X$足以捕捉处理和结果之间的所有混杂。这引出了所有规则中最重要的一条：倾向性评分法只能控制你已经测量的混杂因素。这是它们的致命弱点。

最后，在应用倾向性评分法后，我们必须检查它是否真的起作用了！我们必须进行**协变量平衡检验**。我们在新的匹配或加权样本中比较我们的协变量（$X$）的均值、方差和其他分布属性。一个常用的度量是**标准化均数差（SMD）**。在调整之前，我们预计存在大的不平衡。在成功的倾向性评分调整之后，所有协变量的SMD都应该接近于零，表明我们的“苹果和橙子”已经被转换成了两个可比较的“苹果”组[@problem_id:4979362] [@problem_id:4862780]。如果未能实现平衡，我们的倾向性评分模型很可能设定有误，我们必须回到起点重新设计。

### 构建评分的艺术与科学

什么样才是好的倾向性评分模型？这里出现了一个微妙而美妙的见解。我们构建模型不是为了尽可能准确地预测处理分配。事实上，一个能完美预测处理的模型（[曲线下面积](@entry_id:169174)，即AUC，为1.0）将意味着完全没有重叠——这是正性假设的灾难性失败！

目标不是预测，而是**平衡**。这意味着我们应该选择能在最终调整后的样本中产生最佳协变量平衡的模型。对于具有许多非线性关系的复杂数据集，简单的逻辑回归可能不够。[现代机器学习](@entry_id:637169)方法，如**广义增强模型（GBM）**，通常更优，因为它们可以灵活地捕捉这些复杂的模式。然而，它们必须谨慎地进行调整——不是为了最大化预测准确性，而是为了找到使组间不平衡最小化的点，例如，通过在平均SMD最低时停止迭代[@problem_id:4501634]。

现实世界的数据也常常是混乱的，某些协变量存在缺失值。这些不能被忽略。必须在倾向性评分分析*之前*使用有原则的方法，如**[多重插补](@entry_id:177416)（MI）**。至关重要的是，为了使程序有效，[插补模型](@entry_id:169403)必须包含处理和结果变量，以保留我们正试图研究的那些关系[@problem_id:4830515]。

### 房间里的大象：未测量的混杂因素

我们必须以谦逊的态度结束。倾向性评分是处理*可测量*混杂的强大工具。但它们无法修复它们看不到的东西。如果存在一个强大的、未测量的混杂因素——比如说，医生能察觉但数据中未记录的“衰弱”指数——倾向性评分方法仍然会产生有偏倚的结果[@problem_id:5051592]。它们可以减少偏倚，但如果条件[可交换性](@entry_id:263314)假设为假，它们无法消除偏倚。对于这个特别棘手的问题，研究人员必须转向其他高级方法，例如**[工具变量](@entry_id:142324)（IV）分析**，这些方法在另一套不同的假设下运作。

理解倾向性评分，就是理解在一个充满不完美、非随机数据的世界里，什么是可能的艺术。它们让我们能够以谨慎和严谨的方式，将原因从相关性中解开，并模拟随机试验的美妙简洁性，使我们离真相更近一步。

