## 应用与跨学科联系

一项民意调查、一项对癌症幸存者的长期研究以及一项脑电波实验有什么共同之处？表面上看，它们似乎相去甚远。然而，它们都面临一个共同的挑战，一个机器中的幽灵：消失了的信息。数据会缺失。一个人拒绝回答问题，一个病人错过了预约，一个传感器读数被噪声干扰。长期以来，科学家们只有两种粗糙的选择：要么扔掉所有不完整的记录，这就像撕掉每一张有污迹的页面后试图理解一部小说；要么用简单的平均值填补空白，这无异于假设每个缺失的词都是“的”。

但如果这个幽灵并非随机游荡呢？如果它的行踪，它的消失，并非纯粹的混乱，而是遵循一种模式呢？如果某个东西缺失的原因与我们*能*看到的其他东西有关呢？这个简单而强大的想法就是“[随机缺失](@entry_id:168632)”(MAR) 假设的核心。它将[缺失数据](@entry_id:271026)问题从一个令人头疼的麻烦，转变成了一个我们可以解决的结构化谜题。它为我们提供了一种有原则的方法，去倾听沉默，并对它可能隐藏的内容做出有根据的推测。让我们踏上一段跨越科学领域的旅程，看看这个优美的想法是如何应用的。

### 社会科学家的困境：未回答的问题

想象你是一位正在进行大型调查的社会学家。你询问人们的教育程度、职业、年龄和年收入。当结果出来时，你注意到一个令人沮丧的模式：相当多的人没有填写收入问题，而是选择了“不愿回答”。你该怎么办？

如果你假设数据是“[完全随机缺失](@entry_id:170286)”(MCAR)，那你就等于假设一位 CEO 和一名学生跳过这个问题的可能性是一样的。这似乎不太可能。但如果你怀疑缺失是 MAR 呢？现在你做出了一个更细致、更合理的假设：某人跳过收入问题的概率可能不取决于他们的*实际收入*（即缺失的那个值），但可能取决于你*已经*观察到的其他事情。

也许你注意到，年长的受访者或拥有高等学位的受访者，无论他们的收入是高是低，都更可能重视隐私并跳过这个问题。MAR 假设允许你利用这些可观察的模式。通过建立一个将年龄、教育程度和职业与回答收入问题的*概率*联系起来的[统计模型](@entry_id:755400)，你就可以进行更智能的插补。像[多重插补](@entry_id:177416)这样的方法不仅仅是填入一个单一的数字；它们为每个缺失的人生成一系列合理的收入值，这些值是基于与那些*确实*回答了问题的相似人群的特征得出的。这保留了数据中的自然变异性，为你提供了一幅比简单忽略问题更丰富、更准确的图景 [@problem_id:1938753]。你没有读懂那个人的心思，但你利用了他们确实给出的线索，对他们没有提供的信息做出了统计上合理的推断。

### 医生的观察：追踪健康与疾病

在医学领域，风险更高。考虑一项纵向研究，该研究在数年间跟踪[结直肠癌](@entry_id:264919)幸存者，并定期评估他们的生活质量 (QoL)。这类研究是现代循证医学的基石。但人不是机器，他们会错过预约。为什么？

如果我们简单地剔除每一个错过哪怕一次预约的患者，我们的研究最终可能只包括最健康、最积极的幸存者，从而给我们一个关于治疗长期效果的危险的乐观假象。MAR 假设提供了一条生命线。研究人员经常观察到，先前 QoL 评分较差、疼痛程度较高或更疲劳的患者，更有可能错过下一次随访 [@problem_id:4732679]。退出的决定不是随机的——它是由患者可观察的病史驱动的。

这是一个经典的 MAR 场景。缺失取决于我们已经测量过的事物，而不是取决于错过预约那天的具体 QoL 值。这一洞见使我们能够使用强大的统计工具，如 **线性混合效应模型 (LMMs)**。与重复测量[方差分析](@entry_id:275547)等旧方法不同——那些方法在遇到任何缺失数据时都会失效，并且要求严格的、等间隔的测量——LMMs 是为现实世界的复杂性而构建的 [@problem_id:4729502]。这些模型使用诸如全信息[最大似然](@entry_id:146147)法 (FIML) 等方法进行估计，利用了每个患者的每一丁点可用数据。它们自然地考虑了一个人今天的健康状况与昨天的健康状况相关这一事实，并利用这些信息来提供有效的治疗效果估计，即使在 MAR 假设下数据是缺失的。

这一原则可以扩展到更复杂的设计，例如公共卫生领域的整群随机试验，其中整个诊所或村庄被随机分组。数据可能在个体和整群两个层面都发生缺失。同样，通过假设 MAR 并使用尊重分层数据结构的复杂方法（如多级[插补](@entry_id:270805)），研究人员可以维护关键的“意向性治疗”原则——即按照随机分配的方式分析每个人——从而获得对干预措施有效性的无偏见看法 [@problem_id:4603162]。

### 神经科学家的筛子：在噪声中寻找信号

MAR 的概念远远超出了人类选择的范畴。有时，数据因为纯粹的技术原因而“缺失”。想象一位认知神经科学家使用脑电图 (EEG) 测量大脑的事件相关电位 (ERPs)。为了获得干净的信号，他们需要对大脑在多次试验中的反应进行平均。然而，有些试验被“伪迹”污染了——受试者眨眼、肌肉抽搐或电极短暂失联。

这些充满噪声的试验必须被丢弃。实际上，那次试验的数据就是“缺失”的。这是个问题吗？如果 MAR 假设成立，那就不是问题。拒绝一次试验的决定通常基于一个自动化的质量指标，比如在刺激呈现*之前*的基线期电压波动量。科学家丢弃这次试验，是因为一个*可观察*的指标告诉他们这次试验有噪声，而不是因为他们试图测量的那个未被观察到的、“真实”的大脑反应 [@problem_id:4175342]。

这是一个优美而清晰的 MAR 例子。它允许研究人员使用 LMMs 等方法，这些方法能优雅地处理由此产生的[不平衡数据集](@entry_id:637844)（每个受试者的试验次数不同），并且他们可以确信，伪迹剔除过程并没有偏倚他们关于大脑活动的最终结论。这台机器里的幽灵根本不是幽灵；它是一个行为良好的过滤器，有助于提纯最终结果。

### 神来之笔：设计中的[缺失数据](@entry_id:271026)

到目前为止，我们一直将缺失数据视为一个需要解决的问题。但故事在这里发生了令人惊讶的转折，揭示了其背后理论的真正优雅之处。如果[缺失数据](@entry_id:271026)不再是问题，而是一种*解决方案*呢？

考虑一个系统生物学团队正在研究一种昂贵的生物标志物——神经丝轻链 (NfL)，作为疾病进展的指标。在一个为期多年的研究中，在每个时间点为每个患者测量它，成本将高得令人望而却步。解决方案是什么？**计划性缺失 (Planned missingness)**。

研究人员可能会这样设计他们的研究：所有人在研究开始和结束时都进行测量。但在中间的时间点，他们只测量随机选择的三分之二的患者。因为测量谁的决定是通过抛硬币做出的（这个过程根据定义，与患者实际的 NfL 水平完全无关），所以由此产生的[缺失数据](@entry_id:271026)是“[完全随机缺失](@entry_id:170286)”的，这是 MAR 的一个特殊、纯净的案例 [@problem_id:1437166]。

研究人员*有意地制造了*[缺失数据](@entry_id:271026)，但他们是以一种可控的方式进行的。他们知道数据*为何*缺失，并且这个原因与数据本身无关。现在，他们可以使用同样有原则的方法——如[多重插补](@entry_id:177416)或混合效应模型——来填补空白，并准确地为整个队列的生物标志物轨迹建模。他们利用从每个人身上收集到的廉价变量信息，以及观察到的 NfL 数据，来重建完整的图景。通过拥抱[缺失数据](@entry_id:271026)理论，他们设计了一项既科学严谨又经济可行的研究。“问题”变成了一个提高效率的强大工具。

### 边缘求生：当“随机”不足以解释时

MAR 假设很强大，但它*终究*是一个假设。它无法从数据本身得到证明，因为它对已观察到的和未观察到的数据之间的关系做出了陈述。如果这个假设是错误的呢？如果数据是 **[非随机缺失](@entry_id:163489) (MNAR)** 呢？

当缺失的概率直接取决于缺失的值本身时，就会发生这种情况。例如，收入极高的人可能最倾向于隐瞒收入，或者抑郁最严重的患者可能最没有精力填写问卷。在这种情况下，即使考虑了所有其他协变量，缺失值也与观察值不同。

一个好的科学家不会只是希望他们的假设是正确的；他们会检验它们。虽然我们无法证明 MAR，但我们可以进行 **[敏感性分析](@entry_id:147555) (sensitivity analysis)**，看看我们的结论有多脆弱。这就像一位工程师不仅为预期负载测试一座桥，还要为飓风级的风力测试它，看看它会在什么时候断裂。

使用改进的[多重插补](@entry_id:177416)技术，我们可以说：“好吧，让我们假设现实是 MNAR。让我们假设未响应者的真实收入平均比 MAR 模型预测的要高 20%。” 然后我们可以在这个新的、悲观的假设下生成[插补](@entry_id:270805)数据集，并重新运行我们的分析。然后我们再试一次，假设他们高出 40%。我们对一系列可能偏离 MAR 的情况重复这个过程 [@problem_id:1938763] [@problem_id:4919178]。

如果我们的主要结论——比如说，教育与收入正相关——在所有这些不同的“如果-那么”情景下都成立，我们就可以更加确信我们的发现是稳健的。然而，如果随着我们调整 MNAR 假设，结论从正相关变为负相关，我们就知道我们的结果对这个无法检验的假设高度敏感，必须极其谨慎地报告。这种做法体现了一种学术上的诚实，它透明地勾勒出我们知识的边界。

所有这些应用的核心是一个严谨的数学引擎，其中最著名的是 **[期望最大化 (EM) 算法](@entry_id:749167) (Expectation-Maximization (EM) algorithm)**。人们不必理解其推导的每一个齿轮和活塞 [@problem_id:4371655]，就能欣赏它的功能：这是一个优美的迭代过程，让我们能够看见无形之物。在“E-步”（期望步），它使用我们当前对世界的最佳猜测来预测[缺失数据](@entry_id:271026)的贡献。在“M-步”（最大化步），它使用那幅完整的图景来更新我们对世界的猜测。如此往复，直到它收敛于一个最能调和我们所见与所不见的现实。

从社会调查到脑电波，MAR 原则以及为处理它而开发的工具，代表了我们在面对不确定性时进行推理能力的深刻进步。它们让我们超越了完整信息的黑白世界，去接触现实世界提供的那些杂乱、不完整但最终更真实的数集。这证明了统计学有能力在缝隙中发现模式，倾听沉默，并勾勒出一幅关于阴影中事物的异常清晰的图景。