## 引言
管理内存是操作系统内核最基本的职责之一，但这远非一项简单的任务。除了分发和回收内存块的基本功能外，内核分配器还必须应对各种相互竞争的复杂需求：性能与效率、灵活性与专用性，以及硬件和并发性的严格要求。其核心问题在于设计一个快速、能最大限度减少空间浪费（碎片化）、并在内核错综复杂的[多线程](@entry_id:752340)环境中安全运行，而不会导致死锁或安全漏洞的系统。本文将全面探讨内核[内存分配](@entry_id:634722)器的设计。我们将首先深入研究其基础性的 **原则与机制**，考察 slab 和[伙伴分配器](@entry_id:747005)等核心算法，并应对执行上下文和[死锁预防](@entry_id:748243)等架构挑战。随后，我们将通过其 **应用与跨学科联系** 来探索分配器深远的影响，揭示其设计选择如何影响系统性能、安全性，并构架起软件与物理世界之间的桥梁。

## 原则与机制

从本质上讲，在操作系统内核中管理内存听起来似乎很简单：你有一大块连续的物理 [RAM](@entry_id:173159)，需要将其中的小块分发给内核中需要存储数据部分。当它们用完后，再把这些内存块归还。这有什么难的呢？事实证明，这项简单的任务恰好处于算法设计、硬件约束和并发理论的十字路口，使其成为[内核工程](@entry_id:750999)中最引人入胜且最具挑战性的领域之一。让我们踏上设计内核[内存分配](@entry_id:634722)器的旅程，在逐一解决问题的过程中发现其固有的原则和机制。

### 划分内存：对抗碎片化的艺术

想象一下，你是一个仓库的经理，仓库里存放着各种不同尺寸的货物。你的仓库只有一个长长的货架。当一辆卡车带着一个货盘抵达时，你在货架上找到一个空位并把它放上去。当它被取走时，这个位置又空了出来。一段时间后，你可能会发现虽然总的空闲空间很多，但都分散在货盘之间狭小而无用的缝隙里。即使总空间足够，你也无法再放下一个大的新货盘。这就是 **[外部碎片](@entry_id:634663)（external fragmentation）**，它是[内存分配](@entry_id:634722)中的第一个大反派。

另一个反派是 **[内部碎片](@entry_id:637905)（internal fragmentation）**。假设你决定耍个小聪明，把所有东西都预先打包成标准尺寸的盒子。一个顾客带来一件小物品，你把它放进你最小的标准盒子里。盒子里剩下的空间就被浪费了。这就是[内部碎片](@entry_id:637905)。

内核分配器持续与这两种碎片作斗争，并采用两种经典策略。

一种方法是 **分离适配（segregated-fit）** 或 **slab 分配器**。这就像我们那个有[标准尺](@entry_id:157855)寸盒子的仓库一样。分配器维护着几个空闲内存块列表，每个列表存放特定大小的内存块（例如，一个用于 8 字节块的列表，一个用于 16 字节块的列表，一个用于 32 字节块的列表，依此类推）。当一个 12 字节的请求到来时，分配器会取出一个 16 字节的块，浪费了 4 字节的[内部碎片](@entry_id:637905)。这种方法的美妙之处在于其速度：分配和释放可以像从列表头部取下一个块或放回一个块一样简单。

然而，这些“桶（bins）”的设计是一门微妙的艺术。应该选择哪些尺寸才是最佳的？一个常见的选择是 2 的幂次方（$8, 16, 32, 64, \dots$）。但如果你的特定工作负载产生了大量 18 字节的请求，你将持续把它们放入 32 字节的块中，从而浪费大量内存。一个聪明的工程师可能会分析工作负载的[概率分布](@entry_id:146404)，并发现一组不同的桶尺寸——比如 $\{8, 24, 40, 64\}$——对他们特定的系统来说，可以大大降低预期的[内部碎片](@entry_id:637905) [@problem_id:3652191]。理想的设计是分配器结构与其服务的请求特性之间的一场统计学博弈。

另一大策略是 **伙伴（buddy）** 分配器。它不使用固定大小的桶，而是递归地看待内存。它从将整个内存作为一个巨大的块开始，比如 $m$ 阶。如果来了一个较小块的请求，比如 $k$ 阶，分配器会取一个 $k+1$ 阶的空闲块，将其一分为二，成为两个 $k$ 阶的“伙伴”，使用其中一个，并将另一个放入 $k$ 阶的空闲列表中。如果没有 $k+1$ 阶的块，它会向上找到 $k+2$ 阶的块并进行拆分，如此级联拆分，直到得到所需大小的块。

[伙伴系统](@entry_id:637828)的真正优雅之处在内存被释放时得以体现。当一个 $k$ 阶的块被归还时，分配器会检查它的伙伴是否也空闲。如果是，它们会立即被合并（coalesced）成一个单一的 $k+1$ 阶的块。然后分配器会检查这个新块的伙伴是否空闲，可能会触发一连串的合并，一直向上进行。这个机制是对抗[外部碎片](@entry_id:634663)的优美而积极的防御，它不断尝试从小的空闲碎片中重建更大的连续块。当然，天下没有免费的午餐。在最坏的情况下，单次分配可能触发从最大块到最小块的一长串拆分，而一次释放也可能触发一长串的合并。这会引入延迟，对于实时系统，设计者甚至可能会实施策略来限制在单个时间关键型操作中允许的最大拆分或合并次数 [@problem_id:3652110]。

### 内核的两个世界：可睡眠与不可睡眠

到目前为止，我们一直将[内存分配](@entry_id:634722)视为一个简单的、孤立的库调用。但在[操作系统](@entry_id:752937)中，一切都取决于*上下文（context）*。内核在两个根本不同的世界中运行。第一个是**进程上下文（process context）**，此时内核代表用户程序运行（例如，在[系统调用](@entry_id:755772)期间）。在这个世界里，时间相对灵活。如果分配器需要等待某个资源，该进程可以被置于睡眠状态，调度器可以运行另一个进程。

第二个世界是**中断上下文（interrupt context）**。这是一个紧急状态。一个硬件设备——网卡、磁盘控制器——刚刚向 CPU 发出信号，表示需要立即处理。CPU 会放下正在做的事情，跳转到一个称为[中断处理](@entry_id:750775)程序的特殊函数。这个上下文是**[原子性](@entry_id:746561)的（atomic）**或不可睡眠的。处理程序必须快速运行并返回，因为整个系统（或至少是那个 CPU 核心）实际上处于暂停状态。你不能让[中断处理](@entry_id:750775)程序进入睡眠。

这里存在一个深层次的问题。如果一个“正常”的分配需要找到一个空闲页，但已经没有空闲页了怎么办？分配器可能需要执行**回收（reclaim）**：找到一个不怎么被使用的页，如果它是脏的就将其内容写到磁盘，然后重用它。这涉及到磁盘 I/O，而磁盘 I/O 是很慢的。分配器在等待 I/O 完成时*必须*睡眠。这在进程上下文中是完全可以的，但在中断上下文中将是一场灾难——系统会直接挂起。

这种根本性的[二分法](@entry_id:140816)迫使分配器的设计一分为二。内核通过标志来定义不同的分配类型，例如 `GFP_KERNEL`（Get Free Page, Kernel context，获取空闲页，内核上下文），它表示“如果需要，你可以睡眠”；以及 `GFP_ATOMIC`（Get Free Page, Atomic context，获取空闲页，原子上下文），这是一个严格的命令：“你必须立即成功，且绝对不能睡眠” [@problem_id:3652108]。

但是，如何能在不睡眠的情况下保证分配成功呢？你可以作弊！或者说，是预先准备。保证内存可用的唯一方法是已经把它预留出来。这引出了**紧急预留（emergency reserves）**的优雅设计。分配器可以维护一些小的、预先分配的内存池，专门用于原子上下文。在多核系统上，这通常是按 CPU 进行的：每个 CPU 都有自己的小型“应急储备”内存对象。当一个中断到达某个 CPU 时，它的处理程序可以从其本地储备中获取一个对象。这非常快——没有锁、没有等待、没有与其他 CPU 的竞争。这些储备稍后会由在安全的、可睡眠的进程上下文中运行的代码异步地重新填充 [@problem_id:3640045] [@problem_id:3650429]。这种设计完美地将硬件的紧急、时间关键的需求与主系统更有条理、更灵活的操作隔离开来。

### 交互的风险：[死锁](@entry_id:748237)与设备需求

[内存分配](@entry_id:634722)器并非存在于真空中。它是一项基础服务，与内核的每个其他部分都进行交互，而这些交互可能导致微妙而危险的后果。

一类交互是与硬件设备。许多外设，特别是像网卡和存储控制器这样的高性能设备，使用**直接内存访问（Direct Memory Access, DMA）**来读写内存，而无需 CPU 的参与。这些设备可能对其内存有特殊要求。例如，一个设备可能要求其通信缓冲区的物理地址起始于 64 或 128 的倍数。一个只给出第一个可用块的通用分配器将无法满足这一要求。这迫使设计者创建更专门的、**对齐感知（alignment-aware）**的分配器。这样的分配器可能会为具有不同对齐保证的块维护单独的空闲列表。这增加了元数据开销，但避免了另一种选择：分配一个大得多的块，并浪费其中很大一部分作为“前端填充”来满足对齐要求 [@problem_id:3652183]。

一个更隐蔽的危险源于[内存分配](@entry_id:634722)器与其他主要内[核子](@entry_id:158389)系统（如虚拟内存**页面调度器 (pager)**）之间的交互。这可能导致一种被称为**[死锁](@entry_id:748237)（deadlock）**的致命拥抱。让我们来讲一个故事 [@problem_id:3633132]。

想象两个线程 $T_1$ 和 $T_2$，以及两个锁：一个分配器锁 $L_h$，保护分配器的内部数据；一个页面调度器锁 $L_p$，保护页表。

1.  **路径 1**：线程 $T_1$ 调用分配器获取一些内存。它获取了分配器锁 $L_h$。在持有该锁的同时，其代码碰巧接触到一块已被换出到磁盘的内核数据。这触发了一次**[缺页中断](@entry_id:753072)（page fault）**！页面调度器现在必须运行以从磁盘加载数据。为了完成其工作，页面调度器需要获取页面调度器锁 $L_p$。因此，线程 $T_1$ 现在持有 $L_h$ 并等待 $L_p$。

2.  **路径 2**：与此同时，在另一个 CPU 上，线程 $T_2$ 首先触发了一次[缺页中断](@entry_id:753072)。页面调度器开始运行并获取了页面调度器锁 $L_p$。在其工作过程中，页面调度器需要分配一个小的内部数据结构。于是，它调用[内存分配](@entry_id:634722)器并试图获取分配器锁 $L_h$。线程 $T_2$ 现在持有 $L_p$ 并等待 $L_h$。

我们有了一个循环：$T_1$ 持有 $L_h$ 并想要 $L_p$，而 $T_2$ 持有 $L_p$ 并想要 $L_h$。系统陷入停顿。这不是一个理论难题；这是内核开发者必须预防的现实噩梦。解决方案是精心设计的典范：你**解耦（decouple）**这些依赖。首先，你确保[内存分配](@entry_id:634722)器自身的内部代码和数据结构被“钉住（pinned）”或**不可分页（non-pageable）**，这样它们在持有分配器锁时就*永远不会*导致[缺页中断](@entry_id:753072)。这打破了路径 1。其次，你给页面调度器一个专用的、预分配的内存池，这样它在持有页面调度器锁时就永远不需要调用通用分配器。这打破了路径 2。[循环依赖](@entry_id:273976)被消除，系统变得安全。

### 时间的伤痕：与碎片的幽灵作斗争

即使有设计完美的算法，分配器的敌人仍然是时间。在系统长时间运行，经历数百万次分配和释放后，碎片化不可避免地会再次出现。

这个问题通常在系统诞生之初就开始了。在早期引[导序列](@entry_id:140607)中，复杂的伙伴和 slab 分配器尚未初始化。内核需要一个简单的临时分配器来启动自己。它通常使用一个**碰撞指针（bump pointer）**：它只是从 RAM 的起始位置顺序地分配内存，不断向前“碰撞”一个指针。这速度极快。但是在引导期间进行的一些分配是用于那些将永久存在的东西，比如[设备驱动程序](@entry_id:748349)数据。临时分配被释放了，但这些永久性的分配仍然存在，像巨石一样散布在低地址内存区域。当真正的分配器接管时，内存已经被这种碎片化的“原罪”所伤害 [@problem_id:3652127]。

这引出了一个诱人的问题：如果内存变得碎片化，为什么不直接清理它呢？为什么不把已分配的对象四处移动，将所有空闲空间合并成一个大块？这就是我们在 C 这类用于编写内核的语言中遇到的根本性障碍：**指针稳定性（pointer stability）**问题 [@problem_id:3683579]。在 C 语言中，指针只不过是一个原始的内存地址。如果你将一个对象从地址 $A$ 移动到地址 $B$，任何持有指向 $A$ 的指针的代码现在都坏了；它的指针变成了悬空指针，指向无效数据。

要安全地移动一个对象，你需要找到并更新系统中对它的*每一个引用*。在像 Java 或 C# 这样的托管语言中，[运行时环境](@entry_id:754454)正是这样做的；它跟踪所有引用，因此可以执行**移动式垃圾回收（moving garbage collection）**来紧凑堆。但是 C 语言内核没有这样的中央注册表。指针可以存在于任何地方：线程栈上、CPU 寄存器中，或者——最成问题的——传递给硬件设备用于 DMA 操作。你根本无法找到所有这些指针。

这意味着通用的、暂停整个世界的对象紧凑在内核中是不可行的。取而代之的是，设计者使用一系列更具外科手术式精确性的技术。他们可以执行**[页面迁移](@entry_id:753074)（page migration）**，即识别那些“可移动”的页面（例如，包含用户数据而非关键内核结构的页面）。对于一个可移动的页面，内核可以分配一个新的物理页面，复制内容，更新页表以透明地将虚拟地址重定向到新位置，然后释放旧页面。对于涉及 DMA 的页面，这个过程更加精细，有时需要与 IOMMU（I/O [内存管理单元](@entry_id:751868)）协调，甚至暂停设备以更新其地址寄存器 [@problem_id:3652127]。一个更好的解决方案是预防性的：设计更智能的、能够感知分配生命周期的引导时分配器，从一开始就防止永久性碎片的产生。

### 测量即认知

设计了这台复杂的机器之后，我们如何知道它是否真的运行良好？它快吗？它高效吗？在压力下分配会失败吗？要回答这些问题，我们需要观察系统，为我们的分配器构建一个仪表板。

但是观察是有成本的。分配器每秒可能执行数百万次操作。如果我们在每次分配中都添加代码来记录其延迟，这种测量的开销可能会减慢整个系统，从而污染我们试图收集的数据。这就是系统工程中的[观察者效应](@entry_id:186584)。

解决方案不是观察所有事情，而是聪明地观察。答案，美妙地，在于统计学。我们不检测每个操作，而是使用**[随机抽样](@entry_id:175193)（random sampling）**。我们可能决定只测量所有分配中一个极小的、随机的部分——比如 $2\%$ [@problem_id:3652144]。这似乎有悖直觉，但[概率法则](@entry_id:268260)告诉我们，如果我们收集了足够多的随机样本，我们就能以惊人的准确性重建整个总体的统计特性。例如，要以不超过 $1\%$ 的误差和 $99\%$ 的[置信度](@entry_id:267904)估算第 99 百分位的延迟，Dvoretzky–Kiefer–Wolfowitz 不等式告诉我们可能只需要收集大约 $26,500$ 个样本。在一个每秒执行 $120$ 万次操作的系统上，这只是总工作量的极小一部分。

通过将有原则的[统计抽样](@entry_id:143584)与低开销的、基于每个 CPU 的数据结构以及碎片化等指标的巧妙代理相结合，工程师可以构建出能够高度准确地反映分配器健康状况的仪表板，而其性能成本却可以忽略不计。这是一个完美的例子，展示了数学如何提供工具来理解和掌握我们构建的系统的复杂性。

