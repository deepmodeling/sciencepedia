## 引言
现代人工智能模型在众多任务上取得了超人的表现，但它们却隐藏着一个根本性的、且往往是危险的缺陷：它们非常容易轻信。这些模型被训练来识别一组固定的类别，并遵循一个“[闭集](@article_id:296900)假设”，即它们在现实世界中遇到的任何事物都必须属于它们已知的某个类别。这导致了一种脆弱的智能形式，它能够以高[置信度](@article_id:361655)进行分类，但在面对意外情况时却可能完全错误，而且是悄无声息地犯错。模型有限的知识与现实世界开放性之间的这种差距，正是开放集识别（Open-Set Recognition, OSR）旨在解决的核心挑战。

本文深入探讨了构建更谦逊、更稳健、更 realistic 的人工智能系统的原理与应用，这些系统知道自己所不知。在第一部分“原理与机制”中，我们将剖析标准模型为何会失败，探讨像softmax这样的函数是如何强化一种危险的确定性幻觉。然后，我们将介绍OSR的核心概念，从简单的基于置信度的方法，过渡到优雅而强大的[基于能量的模型](@article_id:640714)框架。在第二部分“应用与跨学科联系”中，我们将看到这些原理的实际应用，探索OSR如何通过实现科学发现、确保数据纯度以及促进关键系统中的安全终身学习，从而革新生物学和医学等领域。

## 原理与机制

### 确定性的幻覺：为何我们的模型如此轻信

想象一下，你精心训练了一只狗来识别苹果和香蕉。你给它看一个苹果，它叫一声。一个香蕉，它叫两声。经过大量训练，它变得惊人地准确。你为此感到自豪。然后，为了好玩，你给它看一辆汽车。会发生什么？这只只知道苹果和香蕉世界的狗，可能会自信地叫一声（“苹果！”）或两声（“香蕉！”）。它没有“我不知道这是什么”的概念。它尽力将这个奇怪的新物体塞进它所知的那个小小的现实盒子里。

这正是大多数标准人工智能分类器所处的困境。它们在一个我们称之为**[闭集](@article_id:296900)**的世界里运作，假设它们遇到的任何东西都必须属于它们被训练过的类别之一。许多分类器核心的数学机制，一个名为**softmax**的函数，实际上[强化](@article_id:309007)了这种轻信。

让我们深入了解一下。神经网络在“看”一个输入时，并不会立即决定“猫”或“狗”。它首先会为它所知的每个类别生成一个原始的、实值的得分向量，称为**logits**。假设对于一张图片，它产生的logits是 $\{z_{\text{cat}}=10, z_{\text{dog}}=2, z_{\text{bird}}=-5\}$。然后，softmax函数会将这些logits转换为一个[概率分布](@article_id:306824)。它通过一种“[归一化](@article_id:310343)的指数化”来实现：

$$
p(y=k \mid x) = \frac{\exp(z_k)}{\sum_{j} \exp(z_j)}
$$

指数函数 $\exp(z)$ 增长得非常快。这意味着即使logits之间微小的差异也会在概率上变成巨大的鸿沟。一个10的logit变得远大于一个2的logit。softmax函数因其本质，会放大“获胜者”logit的声音，并有效地压制其他logit，从而迫使概率总和为一。在我们的例子中，模型会以近乎绝对的确定性宣称其预测是“猫”。

训练过程本身，通常使用像**[分类交叉熵](@article_id:324756) (Categorical Cross-Entropy, CCE)**这样的[损失函数](@article_id:638865)，鼓励了这种行为。CCE的目标是使*正确*类别的logit相对于所有其他类别尽可能大。模型因果断而受到奖励，因模棱两可而受到惩罚。

危险就在于此。当这个观点鲜明的模型遇到一个**分布外 (Out-of-Distribution, OOD)**的输入——那个展示给水果识别犬的汽车——它别无选择，只能通过其学习到的函数来处理它。网络可能純粹出于偶然，产生一个其中一个分量略大于其他的logit向量，例如 $\{z_{\text{cat}}=2.5, z_{\textog}=2.1, z_{\text{bird}}=2.2\}$。softmax函数，受其职责所驱使要去找到一个胜者，会抓住这个微小的差异，并自信地宣称这辆车是“猫”。模型并没有说谎；它只是将一个未知的现实投射到它拥有的唯一地图上，从而创造出一种危险的确定性幻觉。

### 划定界限：阈值原则

为了构建一个更聪明、更谦逊的人工智能，我们必须赋予它放弃决策的能力。核心思想非常简单：我们需要将单问题任务（“它是这些中的哪一个？”）转变为一个双问题过程：
1.  这个输入是我能识别的东西吗？
2.  如果是，它属于我已知的哪个类别？

这需要为任何给定的输入建立一个“已知性”分数。有了这样一个分数，我们就可以划定一条界线——一个**阈值**。如果输入的分数落在界线的一侧，我们接受它为已知。如果落在另一侧，我们拒绝它为未知。

最直接的“已知性”分数是模型自己报告的置信度，即**最大Softmax概率 (Maximum Softmax Probability, MSP)**。其直觉是，如果模型对其*任何*预测都不是很有信心，它可能正在看待新颖的事物。然而，正如我们刚刚看到的，模型可能在OOD输入上表现出不合理的过度自信，这使得MSP成为一个不稳固的基础。这是一个开始，但通过更深入的挖掘，我们可以做得更好。

### 寻求更佳指标：从Softmax到能量

与其听模型所说（最终的概率），不如观察它的*思考*（内部的logits）。这引导我们走向一个源自统计物理学语言的、极其优雅且强大的概念：**能量分数**。我们可以根据一个输入$x$的logits来定义它的能量$E(x)$：

$$
E(x) = -\ln \sum_{j=1}^{K} \exp(z_{j}(x))
$$

让我们来解析一下。对数函数内的项 $\sum \exp(z_j)$ 与softmax函数中的[归一化](@article_id:310343)因子相同。思考一下对于一个典型的**分布内 (In-Distribution, ID)** 输入，比如一张清晰的猫的图片，会发生什么。模型会很有信心，为“猫”产生一个大的logit（$z_{\text{cat}}$），而为其他所有类别产生较小的logits。总和 $\sum \exp(z_j)$ 将被 $\exp(z_{\text{cat}})$ 的巨大数值所主导，使得这个总和本身非常大。一个非常大的数的负对数是一个非常小的数（或一个大的负数）。因此，一个自信的、分布内的输入对应着**低能量**。

现在考虑一个OOD输入，它看起来不像模型知道的任何东西。它不太可能强烈激发任何单个logit。这些logits可能都很小甚至是负数。因此，总和 $\sum \exp(z_j)$ 将是一个小数（接近于0，因为当$z$为负数时$\exp(z)$很小）。一个小的正数的负对数是一个大的正数。因此，一个模棱两可的、分布外的输入对应着**高能量**。

这给了我们一个极好且稳健的“已知性”晴雨表：**低能量意味着已知，高能量意味着未知**。这不仅仅是一个聪明的[启发式方法](@article_id:642196)；它是一个具有深厚理论根基的原则。**[基于能量的模型](@article_id:640714) (Energy-Based Models, EBMs)** 的世界将输入的概率概念化为与$\exp(-E(x))$成正比。从这个角度看，[OOD检测](@article_id:640393)变成了一个经典的[统计假设检验](@article_id:338680)：这个样本是来自我们已知的低能量分布，还是来自某个其他的高能量分布？著名的**Neyman-Pearson引理**告诉我们，区分两个假设的[最优检验](@article_id:348547)是对其似然比进行阈值处理。事实证明，在合理的假设下，对能量分数进行阈值处理正是这种[最优检验](@article_id:348547)。这是一个美妙的趋同时刻，一个AI领域的前沿问题在百年历史的统计学定理中找到了它的理论依据。

### 为“谦逊”而训练：使模型具备OOD感知能力

有了一个好的晴雨表，我们还能更进一步吗？我们能否主动*训练*一个模型，让它从一开始就更加谦逊并具备OOD感知能力？答案是肯定的，而且有几种聪明的策略可以实现。

**1. 通过对比进行教学：** 如果我们能在训练期间获得一个OOD样本数据集，我们就可以使用**对比损失**。训练目标被修改以包含一条新规则：对于任何已知样本，将其能量*降低*；对于任何未知样本，将其能量*提高*。这塑造了模型输出空间的几何结构，为熟悉的事物创造了一个低能量景观，并用高能量的“海洋”将其包围。

**2. 合成未知样本：** 如果我们没有明确的OOD样本怎么办？我们可以创造它们！我们可以**合成负样本**。想象一下，我们已知的类别是广阔空间中的几个紧凑的点簇。我们可以在这些簇之间的空白区域生成随机点。根据定义，这些点不属于任何已知类别。然后我们可以训练一个辅助的“拒绝头”，这是一个简单的分类器，学习区分“真实”类别成员和这些合成的冒名顶替者。这个拒绝头可能会使用诸如[主模](@article_id:327170)型的置信度（MSP）和其模糊度（前两个类别概率之间的差值）等特征来做出决策。

**3. 门控学习：** 在像**[半监督学习](@article_id:640715)**这样的复杂场景中，我们得到大量未标记的数据，这些数据是已知和未知类别的混合体。应用假设所有未标记数据都有用的标准方法将是灾难性的，因为它会迫使未知样本归入已知类别。在这里，我们的能量或[置信度](@article_id:361655)分数可以充当一个**守门人**。对于每个未标记的样本，我们首先计算它的分数。如果分数表明它是一个高置信度、低能量的“已知”样本，我们就欢迎它并用它来改进我们的模型。如果分数将其标记为低置信度、高能量的潜在“未知”样本，我们要么丢弃它，要么明确训练模型对其保持不确定。这种选择性方法使我们能够筛选黄金，而不会被渣滓所毒害。

### 阈值设定的艺术：寻找恰当的平衡

我们已经有了原则：分配分数，然后应用阈值。我们有成熟的方法来获得好的分数，并训练模型产生更好的分数。但一个关键问题仍然存在：我们到底应该在哪里划定界线？

设定阈值不是一个数学上的事后思考；它是最终的、由应用驱动的决策，它编码了我们的优先事项。一个高的、严格的阈值会最小化错误接受未知的风险，但会增加错误拒绝已知的机会。这在一个医疗诊断系统中可能是可取的，因为任何未知的读数都应触发人工审查。一个低的、宽松的阈值则相反，对于一个休闲的照片分类应用可能是可以接受的。

**错误[接受率](@article_id:640975)**（被放行的未知[样本比例](@article_id:328191)）和**错误拒绝率**（被剔除的已知[样本比例](@article_id:328191)）之间的这种权衡是根本性的。选择阈值的过程称为**校准**。我们取一个独立的[验证集](@article_id:640740)，其中包含已知和未知样本的混合，然后测试一系列可能的阈值。然后我们选择能够优化反映我们[期望](@article_id:311378)平衡的指标的那个阈值。

这个指标可以有多种形式。它可以是**[平衡准确率](@article_id:639196)**，它同等重视正确处理已知和未知样本。或者，我们可以定义一个自定义的**联合目标函数**，在其中我们为不同类型的错误分配明确的成本。例如，我们可能会声明`成本 = 0.3 * (已知类别错误率) + 0.7 * (未知样本错误[接受率](@article_id:640975))`，这表明我们更关心拒绝未知样本。然后我们找到最小化这个总成本的阈值。

最终，开放集识别是一个从强加盲目确定性到拥抱有原则的不确定性的旅程。它是关于构建不仅知道自己知道什么，而且也知道自己不知道什么的模型。

