## 应用与跨学科联系

我们花了一些时间来理解[神经辐射场](@article_id:641556)内部的精巧机制——它如何使用一个简单的网络、一点[位置编码](@article_id:639065)和经典的体渲染原理，从平面照片中变幻出三维世界。这是一个优雅的构造。但一个真正优美的科学思想不仅仅是优雅；它还富有*生命力*。它不只是回答一个旧问题。它会开花结果，将种子撒向意想不到的花园，在那些从未意识到彼此语言相通的领域之间建立起联系。

现在，我们将踏上一段旅程，去看看将世界表示为一个[连续函数](@article_id:297812)的想法究竟有多么富有生命力。我们将从计算机图形学的熟悉领域出发，走向[材料科学](@article_id:312640)的前沿，发现同样的基本概念为我们提供了一个新的视角，来观察和解决各种各样令人惊叹的问题。

### 为数字世界增压

NeRF最直接的应用，当然是其最初的目的：创造令人惊叹的逼真3[D场](@article_id:373557)景。这已经为虚拟现实、特效和数字遗产保护带来了一场革命。但其对图形学的影响远不止于此。

想象你是一名摄影师。你不仅仅是捕捉一个场景；你是在捕捉光线。真实世界中的光线具有令人难以置信的亮度范围，即*动态范围*，从最暗的阴影到耀眼的太阳。一张标准的照片将这个范围压缩成一个苍白的模仿品。然而，NeRF可以被训练来学习空间中每一点的真实辐射值。它成了一个场景光场的完美“数字底片”。就像摄影师在暗房中处理底片以显现细节一样，我们可以在这个学习到的辐射场上进行计算操作。例如，我们可以应用复杂的*色调映射*[算法](@article_id:331821)来压缩高[动态范围](@article_id:334172)，以便在标准屏幕上观看，同时小心地控制保留高光和阴影中的哪些细节，以达到特定的艺术效果。这给了创作者在照片拍摄后很长时间内对最终图像前所未有的控制权 [@problem_id:3136733]。

但如果场景不是静态的呢？如果它是一个正在说话的人、一面在风中飘扬的旗帜，或一个从岩石上倾泻而下的瀑布呢？优雅的答案是简单地为我们的函数增加一个维度。我们不再让网络学习 $f(x, y, z)$ 来得到颜色和密度，而是教它学习 $f(x, y, z, t)$，其中 $t$ 是时间。突然之间，我们的3D快照变成了一部4D的、完全体积化的电影！当然，这引入了一个新的挑战：我们如何确保场景随时间平滑演变？一个突兀、闪烁的结果是无用的。答案再次来自微积分的语言。我们可以在损失函数中添加一个惩罚项，或称*[正则化](@article_id:300216)器*，以抑制随时间的剧烈变化。例如，我们可以惩罚时间[导数](@article_id:318324)的大小，即 $\partial f / \partial t$ 和 $\partial^2 f / \partial t^2$。通过在训练过程中最小化这个惩罚，网络被鼓励去寻找一个不仅匹配输入视频帧，而且能表示一个随时间优雅连续变化的世界的解决方案 [@problem_id:3136802]。

### 超越表象：理解场景

一张照片告诉我们一个场景*看起来*是什么样子。但它不告诉我们它*是*什么。NeRF在其基本形式下也是如此。它是表象的大师，但对场景中的物体没有理解。然而，这并非一个根本的限制。我们可以教它。

想象一下，我们训练我们的网络不仅在每个点上产生颜色和密度，还产生一个*语义标签*。我们可以在我们的MLP上增加另一个“头”，输出每个点属于某个类别的概率：“树”、“天空”、“建筑”等等。在训练期间，我们不仅提供图像，还提供标记像素的2D分割掩码。然后网络学会将这些标签投射到3D空间中，构建一个完整的、体积化的世界语义地图。现在，当我们查询一个点 $(x, y, z)$ 时，我们不仅可以问“这是什么颜色？”，还可以问“这*是*什么？”。这种几何与语义的融合非常强大，使得诸如通过说“让所有的树都变高”来编辑场景，或让机器人通过理解世界的哪些部分是可通行的地面、哪些是障碍物来规划路径等应用成为可能 [@problem_id:3136705]。

这种“解混”照片信息的思想是*逆向渲染*（inverse rendering）的核心。一张照片无可救药地将场景的各种属性——物体的形状、它的材质（是闪亮的塑料还是粗糙的木头？），以及照亮它的光线——纠缠在一起。NeRF是解开这团乱麻的完美工具。我们可以构建一个更复杂的[前向模型](@article_id:308862)，其中包含例如光源位置和物体[漫反射](@article_id:352316)[反照率](@article_id:367500)等参数。然后，通过向网络展示最终的图像，我们可以要求它反向工作——进行“通过合成进行分析”（analysis-by-synthesis）——并求解出能最好地解释其所见的场景参数。这引领我们进入一个深刻的科学问题：这个问题总是可解的吗？我们总能从一组照片中唯一地确定光照和材质吗？数学领域通过*[可识别性分析](@article_id:362104)*（identifiability analysis）为我们提供了回答这个问题的工具。通过检查我们模型的[导数](@article_id:318324)（[雅可比矩阵](@article_id:303923)），我们可以确定一个问题何时是适定的，何时是模糊的——这对于任何科学家或工程师来说都是一个至关重要的洞见 [@problem_id:3136714]。

### 连接数字模型与物理世界

NeRF是一个数字实体，但它诞生于物理测量。输入照片的质量直接影响最终3[D场](@article_id:373557)景的质量。这在人工智能模型和数据捕获过程的物理学之间建立了一场优美而实际的对话。

我们知道，NeRF表示精细细节的能力受其[位置编码](@article_id:639065)中使用的最高频率的限制。如果我们试图教它一个小于这个极限的细节，它根本“看”不到。现在，考虑相机。一个真实的镜头有有限的景深；没有完全对焦的物体会以一定的光学模糊度被渲染出来。如果这种模糊大于NeRF能表示的最小细节，会发生什么？信息在到达模型之前就已经丢失了！这就像试图阅读一份被水浸湿的报纸。值得注意的是，我们可以在相机的光学特性和NeRF的理论特性之间建立直接的数学联系。我们可以计算出相机镜头所需的确切f值（$N$），以确保散焦模糊足够小，从而保留NeRF所选频率带所需的细节。这是一个理论指导实践的惊人例子，将傅里叶特征的抽象数学与设置相机的具体力学联系起来 [@problem_id:946350]。

工程学并不止于相机。NeRF架构本身呢？我们应该使用一个深而窄的网络，还是一个浅而宽的网络？我们的哈希网格应该有多少层，分辨率又是多少？这些选择在模型质量、渲染速度和内存占用之间造成了复杂的权衡。我们可以花费无尽的时间手动调整这些参数，但有一种更具原则性的方法：我们可以让AI来设计我们的AI。使用*[神经架构搜索](@article_id:639502)（Neural Architecture Search, NAS）*的技术，我们可以定义一个可能架构的搜索空间和一个预算（例如，最大内存）。然后，一个[算法](@article_id:331821)可以自动探索这个空间，评估各种权衡，并找到在我们的特定约束下提供最佳质量和性能平衡的最优架构。这将模型设计的艺术转变为一门[约束优化](@article_id:298365)的科学 [@problem_id:3158055]。

### 一种新型显微镜：科学的工具

也许所有联系中最深刻的是，将类似NeRF的模型不仅用于重现我们的世界，而且用于在基础层面上*理解*它。NeRF是被称为*[物理信息神经网络](@article_id:305653)（Physics-Informed Neural Networks, PINNs）*的一大类模型中的一个具体例子。其核心思想是使用[神经网络](@article_id:305336)来表示的不是一幅图画，而是一个物理场——如温度、应力或流体速度——并训练它遵守物理定律。

考虑[材料科学](@article_id:312640)的世界。科学家研究材料中不同相或晶粒之间错综复杂的三维边界。这些微观结构决定了材料的属性。我们可以通过学习其符号距离函数（Signed Distance Function, SDF）来训练一个INR来表示这个复杂的边界。但SDF不仅仅是任何函数；它必须遵守一个称为*[程函方程](@article_id:342012)*（eikonal equation）的物理定律：其梯度的模长必须处处为一，即 $|\nabla f| = 1$。我们可以教会网络这个定律！在训练过程中，我们添加一个损失项，惩罚网络违反[程函方程](@article_id:342012)的行为。网络因此被迫去寻找一个不仅拟合实验数据，而且尊重距离场基本几何特性的解决方案 [@problem_id:38427]。

这个原理具有惊人的普适性。我们可以将其应用于其他物理定律。例如，在材料中，被称为[位错](@article_id:299027)的[晶体缺陷](@article_id:330719)网络必须遵守一个守恒定律，数学上表示为[位错密度](@article_id:321996)[张量的散度](@article_id:370748)为零。我们可以再次将这个物理定律编码为一个损失函数。通过训练一个网络来最小化这个损失，我们可以学到一个与物理定律一致的[位错](@article_id:299027)场表示。这个网络变成了一个既是“虚拟显微镜”又是“物理模拟器”的工具 [@problem_id:38715]。

这种协同作用——让数据引导解决方案，同时让物理来约束它——非常强大。它使我们即使在实验数据稀疏或嘈杂的情况下也能建立准确的模型，这是科学研究中常见的困境。此外，像*[元学习](@article_id:642349)*（meta-learning）这样的先进技术可以给我们的模型一个“先发优势”。通过在许多不同的先前实验上训练一个模型，它可以学习到例如[材料微观结构](@article_id:377214)的一般模式。这个经过元训练的模型然后可以用极少的数据点来适应一个全新的材料，从而极大地加速科学发现的步伐 [@problem_id:3136761]。

从假日照片到合金的内部结构，这段旅程虽然漫长，但道路却出奇地笔直。它由同一个核心思想铺就：我们可以将世界的一部分表示为一个[连续函数](@article_id:297812)，并且通过使用永恒的微积分语言，我们可以教会这个函数它必须遵守的规则。[神经辐射场](@article_id:641556)不仅仅是一种[算法](@article_id:331821)；它是一种强大的新视角，一座连接像素和传感器的离散世界与它们努力捕捉的连续、优美而复杂的现实之间的桥梁。