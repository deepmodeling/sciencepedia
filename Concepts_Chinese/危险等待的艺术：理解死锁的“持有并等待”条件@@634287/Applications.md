## 应用与跨学科联系

我们已经看到，一个系统要陷入[死锁](@entry_id:748237)的[停顿](@entry_id:186882)状态，必须同时满足四个条件。其中，“[持有并等待](@entry_id:750367)”条件或许是四个中最具人性化的一个。它描述了一种我们都非常熟悉的情景：顽固地抓住你拥有的东西，同时等待别人拥有的东西。这就像两个人在狭窄的走廊里，各自抱着一个大包裹，谁也不愿意放下自己的包裹让对方通过。这个简单、近乎幼稚的僵局是一个强大的模式。它的逻辑如此基础，以至于它会以各种伪装反复出现，在我们有史以来构建的一些最复杂的系统中引发灾难性的故障。让我们踏上一段旅程，看看这种危险的等待艺术将我们引向何方。

### 程序员的博弈：你代码中的[死锁](@entry_id:748237)

最常见到[死锁](@entry_id:748237)的地方是在现代软件的核心：并发程序中，多个执行线程竞相完成工作。想象一个媒体流应用，一个线程解码视频（$T_d$），另一个处理网络数据包（$T_n$）。为了保持秩序，解码器有一个用于其内部数据的锁（$L_d$），网络缓冲区有一个用于其数据的锁（$L_b$）。问题始于解码器线程在持有自己的锁 $L_d$ 的情况下，需要访问网络缓冲区，因此等待锁 $L_b$。而恰在此时，网络线程持有*它的*锁 $L_b$，需要将信息传递给解码器，于是等待 $L_d$。每个线程都持有一个资源并等待另一个。这是一个完美的、两步的[循环等待](@entry_id:747359)，一个“致命拥抱”，应用程序就此冻结 [@problem_id:3662789]。两个线程都将永远等待下去。

这里的问题不仅仅是等待，而是*[持有并等待](@entry_id:750367)*。一个简单而强大的防止这种情况的准则是建立一个获取锁的规范顺序。如果所有人都同意总是先锁定 $L_b$ 再锁定 $L_d$，[循环等待](@entry_id:747359)就变得不可能。一个线程会得到两个锁，另一个只需等待轮到自己。

这种“[持有并等待](@entry_id:750367)”的模式可能更加微妙。它不只发生在两个线程和两个锁之间。考虑一个正在启动的[操作系统](@entry_id:752937)。一个初始化线程（$I$）抓取系统服务注册表上的一个锁（$L_g$）来添加一些初始服务。然后它启动一个新的服务线程（$S$）并等待它的“就绪”信号。但这里有个陷阱：新的服务 $S$ 要*变得*就绪，它首先需要注册自己，这个行为需要获取同一个注册表锁 $L_g$！所以，初始化线程 $I$ 持有锁并等待来自 $S$ 的事件，而 $S$ 在能够产生那个事件之前，被卡住等待 $I$ 持有的锁。系统再次在启动期间冻结 [@problem_id:3662704]。解决方案和诊断一样简单：等待时不要持有锁。初始化线程应该在等待服务发出就绪信号*之前*释放锁。这种放手的准则是健壮[并发编程](@entry_id:637538)的基石。

当我们调用我们没有编写的代码，一个“黑盒”库时，危险变得更大。想象一个Web服务中的工作线程获取一个全局注册表的锁以读取一些配置。然后它进行一个看似简单的阻塞调用来查找域名（DNS查询）。该线程在等待网络响应时持有锁。但是，隐藏在DNS库内部，响应由一个*不同的*库线程处理，该线程随后触发一个回调函数来更新注册表——这个函数需要我们第一个线程仍然持有的那个锁！第一个线程持有锁等待DNS结果，而结果无法传递，因为传递它的回调函数正在等待那个锁。程序死锁了 [@problem_id:3662796]。这是一个特别阴险的错误，因为依赖关系隐藏在API之后。解决方案是打破“[持有并等待](@entry_id:750367)”条件：要么在进行阻塞调用前释放锁，要么更好的是，使用现代异步API，它们根本不会阻塞线程。

### 机器中的幽灵：当软硬件碰撞时

死锁的原理并不局限于软件世界。它是[资源竞争](@entry_id:191325)的一条基本法则，同样适用于计算机的物理组件。“线程”不必是软件线程，“资源”也不必是锁。

考虑一个管理高速直接内存访问（DMA）传输的[设备驱动程序](@entry_id:748349)。这里我们有两个代理：软件驱动程序线程（$T$）和硬件DMA引擎（$D$）。我们有两个资源：内存中的一个缓冲区（$R_{BUF}$）和DMA硬件通道（$R_{DMA}$）。如果驱动程序线程 $T$ 预留了内存缓冲区（持有 $R_{BUF}$），然后试图启动传输，等待DMA通道变为空闲，就可能发生死锁。与此同时，DMA引擎 $D$ 可能已经预留了通道（持有 $R_{DMA}$），现在正等待驱动程序为其提供一个要使用的内存缓冲区。软件持有缓冲区等待通道；硬件持有通道等待缓冲区。结果是系统范围的冻结，一场硅片与软件之间的无声对峙 [@problem_id:3662756]。

“资源”的概念甚至可以更抽象。在单核处理器上，每个进程和每个中断最终需要的那个资源是什么？是CPU本身！假设一个驱动程序线程（$P_T$）获取一个[自旋锁](@entry_id:755228)（$L$）来保护某些数据。当它处于这个[临界区](@entry_id:172793)时，一个硬件中断发生。CPU立即停止执行该线程，跳转到一个[中断服务程序](@entry_id:750778)（ISR），我们称之为 $P_I$。现在，假设这个ISR也需要访问相同的数据并试图获取同一个[自旋锁](@entry_id:755228) $L$。系统现在死锁了。为什么？因为线程 $P_T$ 持有锁 $L$ 并等待CPU再次可用以完成其工作并释放锁。但是ISR，$P_I$，现在持有CPU并且在它能够获取锁 $L$ 之前不会放弃它。一个持有锁等待CPU；另一个持有CPU等待锁。一个完美的、致命的循环 [@problem_id:3662743]。标准的内核解决方案是直接针对这种情况：驱动程序线程必须在获取锁*之前*禁用中断，确保没有ISR可以运行并试图获取同一个锁，从而打破循环。

### 抽象层层，[死锁](@entry_id:748237)层层

随着我们的计算系统变得越来越复杂，具有层层叠叠的抽象，我们发现这些基本问题并没有消失。它们只是以新的、有趣的方式重新出现。

在经典的类Unix[操作系统](@entry_id:752937)中，文件系统是一个抽象的奇迹。但即使是像重命名文件这样看似简单的操作也可能隐藏着死锁。当跨目录重命名文件时，比如从 `/dirA/file1` 到 `/dirB/file2`，[操作系统](@entry_id:752937)必须锁定源目录（$D_A$）和目标目录（$D_B$）。现在，如果一个进程试图从 $D_A$ 重命名到 $D_B$（锁定 $D_A$，然后等待 $D_B$），同时另一个进程从 $D_B$ 重命名到 $D_A$（锁定 $D_B$，然后等待 $D_A$），会发生什么？我们遇到了我们熟悉的致命拥抱 [@problem_id:3662770]。每个进程都持有一个目录锁，同时等待另一个。解决方案，在真实的文件系统中实现，是强制执行一个规范的锁顺序，例如，总是先锁定inode编号较小的目录。

现在让我们跳到现代云端。我们的计算机不再是物理机器，而是运行在虚拟机监控程序上的虚拟机（VM）。这个新的[虚拟化](@entry_id:756508)层肯定解决这些老问题了吧？根本没有。客户VM的内核可能获取一个锁（$L_G$）来准备网络传输的数据。然后它向宿主[虚拟机](@entry_id:756518)监控程序发出一个“[超级调用](@entry_id:750476)”来处理物理I/O。这个[超级调用](@entry_id:750476)，现在在宿主级别运行，需要获取一个宿主端的锁（$L_H$）。但是如果一个宿主工作线程已经持有 $L_H$ 来处理一个之前的I/O完成呢？又如果，为了完成其任务，那个宿主线程需要向客户机注入一条消息，这个任务需要等待客户机锁 $L_G$ 被释放呢？客户机持有 $L_G$ 等待 $L_H$；宿主机持有 $L_H$ 等待 $L_G$。这是相同的死锁模式，但这次它跨越了虚拟机和其宿主之间的边界——一个跨越[特权级别](@entry_id:753757)的[死锁](@entry_id:748237) [@problem_id:3662774]。

### 跨越网络：[分布](@entry_id:182848)式世界中的[死锁](@entry_id:748237)

也许最令人震惊的认识是，“[持有并等待](@entry_id:750367)”不仅可以在一台计算机内部引发死锁，还可以在地球两端的计算机之间引发死锁。这些不是锁的[死锁](@entry_id:748237)，而是协议的死锁。

考虑为现代网络大部分提供动力的HTTP/2协议。它使用流控制机制来防止快速发送方压垮慢速接收方。接收方授予发送方一定数量的“窗口信用”，这是发送方必须“获取”才能发送数据的资源。当接收方的应用程序读取数据时，它会释放其缓冲区，并可以发送一个`WINDOW_UPDATE`来授予发送方更多信用。

现在，想象两台服务器 $E_1$ 和 $E_2$ 处于一个紧密的通信循环中。$E_1$ 正在向 $E_2$ 发送一个大文件，而 $E_2$ 正在向 $E_1$ 发送一个文件。假设两台服务器上的应用程序逻辑都有缺陷：“直到我发送完我自己的所有数据，我才处理我正在接收的数据。”[分布式死锁](@entry_id:748589)的舞台已经搭好。$E_1$ 发送数据，直到用完来自 $E_2$ 的所有窗口信用。它现在等待来自 $E_2$ 的`WINDOW_UPDATE`。对称地，$E_2$ 发送数据，直到用完来自 $E_1$ 的所有信用并等待。但是 $E_1$ 不会发送`WINDOW_UPDATE`，因为它的应用程序没有在读取传入的数据——它在等待完成发送。而 $E_2$ 出于同样的原因也不会发送`WINDOW_UPDATE`。每个服务器都将对方的进展作为人质，同时等待对方迈出第一步。它们通过不消耗数据来持有自己的接收缓冲区，同时等待发送许可。这是一个遍布全球网络的死锁，由同样基本的“[持有并等待](@entry_id:750367)”逻辑引起 [@problem_id:3662701]。

### 放手的准则

从一个简单的编程错误到全球网络协议的冻结，故事都是一样的。“[持有并等待](@entry_id:750367)”条件是系统故障的有力根源。然而，解决方案也共享一个共同的、优雅的主题：放手的准则。

为了避免这些死锁，一个人要么在持有独占资源时不要等待，要么一次性获取所有需要的资源，要么在获取资源的顺序上极其自律。现代工程中这一原则的一个 güzel 例子是日志子系统的重新设计。旧设计中，线程会锁定一个缓冲区然后等待缓慢的磁盘I/O，容易发生死 deadlock。现代解决方案使用一个复杂的“无锁”[环形缓冲区](@entry_id:634142)。生产者线程使用原子硬件指令添加它们的日志消息，而从不获取锁，因此从不在等待I/O时持有资源。它们已经与慢操作[解耦](@entry_id:637294)，从根本上打破了[持有并等待](@entry_id:750367)条件 [@problem_id:3662802]。

这个简单的原则——持有一个东西同时等待另一个是危险的游戏——是计算机科学中一个统一的概念。它的回响可以在CPU、[操作系统](@entry_id:752937)、数据库和全球网络的设计中找到。理解它不仅仅是一项学术练习；它是构建健壮、可靠且最重要的是，能够*正常工作*的系统的艺术中必不可少的一部分。