## 引言
[模型预测控制](@article_id:334376)（MPC）是一种杰出的控制策略，以其处理带物理约束的复杂系统的能力而著称。通过在有限的[预测时域](@article_id:325184)内重复求解优化问题，它基于系统模型规划出最佳的前进路径。然而，这种有限的“前瞻性”带来了一个关键挑战：我们如何能确定今天的最优决策不会在未来导致“死胡同”？这种“递归不可行”的风险，即控制器可能在未来某个步骤失效，削弱了实际应用所需的可靠性。

本文通过探索[鲁棒MPC](@article_id:353442)设计的一个基石——[终端集](@article_id:343296)，来直面这一根本问题。我们将剖析这个优雅的概念，揭示它如何为[长期稳定性](@article_id:306544)和安全性提供可证明的保证。我们的探索始于“原理与机制”一章，在其中我们将揭示[终端集](@article_id:343296)背后的理论机制，解释它如何利用不变性（invariance）和李雅普诺夫函数等概念来确保[递归可行性](@article_id:323125)，并驱动系统走向稳定。随后，“应用与跨学科联系”一章将展示[终端集](@article_id:343296)的非凡通用性，说明这一简单思想如何被用于解决[参考跟踪](@article_id:349843)、[经济优化](@article_id:298707)和安全关键型系统中的复杂挑战。

## 原理与机制

现在我们已经对[模型预测控制](@article_id:334376)的潜力有了初步了解，让我们揭开帷幕，看看使其运转的精妙机制。像任何强大的工具一样，MPC的运行基于几个核心原则。理解这些原则就像学习一场宏大博弈的规则——一场关于预见、优化和稳定的博弈。

### 时域的暴政

想象一下，你正驾驶一辆飞驰的汽车穿越浓雾。你的车头灯只能照亮前方100米的路。在这小小的窗口内，你可以规划出完美的路径——最平稳、最高效的转向和加速序列。你执行了计划的第一部分，向前移动，然后新的一段100米路面出现了。你重复这个过程，始终为你所能看到的这段路进行优化。这就是MPC的本质。

但这其中隐藏着一个危险。如果你为可见的100米制定的“最优”计划，恰好将你引向了视野之外潜伏的悬崖边缘，那该怎么办？在下一刻，当悬崖边缘进入视野时，你可能会发现已经*没有任何可能的操作*——没有足够急的转向，没有足够猛的刹车——来避免灾难。

这就是有限时域控制的根本挑战，一个被称为**[递归可行性](@article_id:323125)**的问题。仅仅因为你*现在*能找到一个可行的计划，并不意味着你没有将自己引向一个“死胡同”，在*下一个*时间步将不存在任何可行的计划 [@problem_id:1579662]。一个随时可能失效的控制器是不可信的。我们如何能给这位“短视”的司机一个保证，前方的路永远不会中断呢？

### 路尽头的庇护所

解决方案既优雅又强大。我们为控制器提供一个承诺，一个保证。我们在[状态空间](@article_id:323449)中定义一个特殊区域，一个“安全区”或庇护所，我们称之为**[终端集](@article_id:343296)**，用符号 $\mathcal{X}_f$ 表示。然后，我们在优化博弈中增加一条新规则：无论你制定出什么计划，其预测的终点，在你的有限时域 $N$ 的末端，*必须*落在这个[终端集](@article_id:343296)内。

再想想我们在雾中开车的司机。现在，我们告诉她：“我不管你在接下来的100米内做什么，但我需要你确保你的路径终点在这段预先批准、经过认证的安全路段上。”如果她能做到这一点，我们就知道她不会开车掉下悬崖。[终端集](@article_id:343296)就像一个锚，将短视的、短期的优化固定在一个无限安全的未来上。但是，是什么赋予了这个集合神奇的“安全”属性呢？

### 庇护所的法则

一个集合不能仅凭宣告就成为庇护所。它必须遵守三条严格的法则才能赢得这个称号。为了让这一点更具体，让我们想象在这个庇护所内，存在一个特殊的、预定义的驾驶策略——一个**终端控制器**，$u = \kappa_f(x)$。这是一个简单的反馈律，它告诉你对于[终端集](@article_id:343296)内的任何状态 $x$ 应该做什么。

1.  **[不变性](@article_id:300612)法则：入者恒在。** 一旦进入[终端集](@article_id:343296) $\mathcal{X}_f$，终端控制器 $\kappa_f(x)$ 必须能够让你永远保持在其中。如果你处于 $\mathcal{X}_f$ 内的一个状态 $x$，并施加控制 $u = \kappa_f(x)$，你的下一个状态 $x^+$ 也必须在 $\mathcal{X}_f$ 内。这个性质被称为**正[不变性](@article_id:300612)** [@problem_id:2884349]。它就像一个温和的漩涡，一旦你进入其范围，就永远不会被甩出去。

2.  **容许性法则：规则依然适用。** 终端控制器所指定的特殊动作不能是凭空变出来的。它们仍必须遵守系统的基本物理限制。对于[终端集](@article_id:343296)中的每一个状态 $x$，指定的控制动作 $\kappa_f(x)$ 必须满足系统的**输入约束**，即 $\kappa_f(x) \in \mathcal{U}$。你不能被要求将方向盘转动到超出其极限的位置。

3.  **包含性法则：庇护所必须是真实的。** [终端集](@article_id:343296)本身必须存在于允许的状态域内。你不能设置一个需要你穿墙而过的安全区。形式上，[终端集](@article_id:343296)必须是[状态约束](@article_id:335313)集的子集，即 $\mathcal{X}_f \subseteq \mathcal{X}$。

如果我们能构建一个集合 $\mathcal{X}_f$ 和一个控制器 $\kappa_f(x)$ 满足这三条法则，我们就得到了一个有效的[终端集](@article_id:343296) [@problem_id:2736421]。这为保证安全性提供了基础。

### 可行性链条

现在是那个美妙的“啊哈！”时刻。这个设置如何解决[递归可行性](@article_id:323125)问题？假设在时间 $k$，我们的MPC控制器找到了一个最优计划 $\{u_{0|k}^\star, u_{1|k}^\star, \dots, u_{N-1|k}^\star\}$，它能使系统在第 $N$ 步进入[终端集](@article_id:343296)。我们应用第一个动作 $u_k = u_{0|k}^\star$，系统移动到一个新的状态 $x_{k+1}$。

在时间 $k+1$，我们必须解决一个新的优化问题。我们能找到解吗？是的，保证能！我们可以通过构建一个候选解来证明这一点。它可能不是*最好*的解，但它的存在本身就证明了问题是可行的。这个候选解是通过一个简单而巧妙的技巧——称为“移位并追加”（shift-and-append）策略——构建的 [@problem_id:2746593] [@problem_id:2884357]：

-   **移位：** 取你上一个最优计划的尾部：$\{u_{1|k}^\star, \dots, u_{N-1|k}^\star\}$。
-   **追加：** 对于最后一个控制动作，使用终端控制器：$u_{N-1|k+1} = \kappa_f(x_{N|k}^\star)$。

这个新序列是可行的吗？让我们来检查一下。“移位”部分根据定义是可行的——它片刻之前还是一个有效计划的一部分。而“追加”部分是可行的，因为庇护所的法则保证了它！由于上一个计划在 $x_{N|k}^\star \in \mathcal{X}_f$ 处结束，我们知道终端控制器提供了一个有效的输入 $\kappa_f(x_{N|k}^\star) \in \mathcal{U}$，并且产生的状态 $x_{N|k+1}$ 也将在 $\mathcal{X}_f$ 内。

在每一步都保证存在一个可行的计划。控制器永远不会面临死胡同。我们已经建立了一条从有限时域延伸至无穷的可行性链条。

### 回归稳定之旅

到目前为止，我们只保证了我们的汽车不会坠毁。但控制的最终目标通常是引导系统到达一个特定的目标，典型地是位于原点（$x=0$）的[稳态](@article_id:326048)。这就是**[渐近稳定性](@article_id:310162)**的性质。

仅仅停留在庇护所里是不够的；我们需要确保向其中心前进。我们通过引入一个**终端成本** $V_f(x)$ 来实现这一点。可以把它看作是[终端集](@article_id:343296)内“不满意度”或势能的一种度量。它在原点处应为零，在其他任何地方都为正。

现在我们为我们的庇护所增加关键的第四条法则，一个关于终端成本的条件。这就是**[控制李雅普诺夫函数](@article_id:343530)（CLF）**条件 [@problem_id:2746605]：

4.  **前进法则：你必须走下坡路。** 在[终端集](@article_id:343296)内部，终端控制器不仅要让你留在里面，还必须主动减少你的“不满意度”。终端成本 $V_f$ 的减少量必须至少等于采取该行动所产生的成本 $\ell(x, \kappa_f(x))$。形式上，对于所有 $x \in \mathcal{X}_f$：
    $$V_f(A x + B \kappa_f(x)) - V_f(x) \le - \ell(x, \kappa_f(x))$$

有了这最后一块拼图，整个谜题就豁然开朗了。MPC控制器在每一步最小化的总成本，成为了[闭环系统](@article_id:334469)的一个**李雅普诺夫函数**。在每一步，控制器应用一个动作，由于该动作本身是最优计划的一部分，它被保证会导致这个总成本严格下降 [@problem_id:2884357]。系统可靠地“滚下山坡”，一直到达原点，而不会被卡住。我们不仅实现了可行性，还实现了可证明的稳定性。

### 从无穷中借用智慧

这听起来很棒，但似乎也很复杂。我们如何凭空捏造出这个完美的[终端集](@article_id:343296)、控制器和成本呢？难道我们只能靠猜吗？幸运的是，并非如此。我们可以从一个更简单、更理想问题的解中借用这些要素：无约束的**[线性二次调节器](@article_id:331574)（LQR）**。

对于没有约束的线性系统，LQR是“上帝模式”的控制器。它解决一个无限时域问题，并提供一个单一的、全局最优的反馈律 $u=Kx$，这个反馈律被保证是稳定的。这个解还附带一个值函数 $V(x) = x^\top P x$，它完美地量化了从任何状态 $x$ 出发的最优未来成本（cost-to-go）。

联系就在这里：LQR的解为我们的约束MPC提供了完美的终端要素！[@problem_id:2884303] [@problem_id:2724661]
-   最优LQR增益 $K$ 成为我们的**终端控制器** $\kappa_f(x) = Kx$。
-   LQR的值函数矩阵 $P$（来自**[Riccati方程](@article_id:323654)**）定义了我们的**终端成本** $V_f(x) = x^\top P x$。

这些选择自动满足了“走下坡路”的条件（法则4）。我们剩下唯一的任务是找到一个尽可能大的[终端集](@article_id:343296) $\mathcal{X}_f$（一个由 $x^\top P x \le \alpha$ 定义的椭球体），在这个集合内，这个出色的[LQR控制器](@article_id:331574)可以在不违反我们现实世界中的状态和输入约束（法则2和3）的情况下运行 [@problem_id:2724634]。这是一个美妙的综合：我们利用无限时域最优解的优雅，创造了一个实用的、安全的、稳定的控制器，它尊重现实世界中混乱的约束。

### 一个巧妙的拐杖

在建立了这个宏伟的理论结构之后，一个好的物理学家会问：这一切真的有必要吗？我们*总是*需要一个[终端集](@article_id:343296)吗？

令人惊讶的答案是否定的。[终端集](@article_id:343296)和终端成本是稳定性的**充分**条件，但它们并非总是**必要**的 [@problem_id:2884369]。例如，如果一个系统是自然稳定的，一个时域 $N=1$ 的短视MPC可能仅仅学会了最好的行动是无为而治，让系统自行滑向原点。

更深刻地讲，[终端集](@article_id:343296)可以被看作一个巧妙的拐杖。如果你给MPC控制器一个非常非常长的[预测时域](@article_id:325184) $N$，它就开始能“看到”其行动的长期后果，其行为也自然开始模仿真正最优的无限时域控制器。[终端集](@article_id:343296)是一个装置，它将这种远见卓识赋予了一个具有短的、计算上可处理时域的控制器。这证明了控制理论的精妙之处：一个用以近似理想的、无穷智慧的实用捷径。