## 引言
在数据世界中，并非所有事件都是生而平等的。通常，最关键的洞见——如罕见疾病、欺诈交易、特效药物——也往往是最不常见的。这种现象被称为[类别不平衡](@article_id:640952)（class imbalance），是机器学习中最常见也最重大的挑战之一。当一个类别的数量远超另一个类别时，标准的模型和评估指标可能会产生严重的误导，制造出高性能的假象，而实际上却完全无法完成其预定任务。本文旨在填补这一知识空白，提供一个用于理解、评估和解决[类别不平衡](@article_id:640952)问题的综合框架。

本指南将为您提供构建稳健且有意义的模型所必需的概念和实践工具。在第一章“原理与机制”中，我们将通过揭示准确率为何是一个有缺陷的指标，来打破“多数派的暴政”。接着，我们将构建一套对少数类别敏感的新评估指标工具箱，例如[精确率-召回率曲线](@article_id:642156)和[马修斯相关系数](@article_id:355761)。最后，我们将探讨修正不平衡问题的两种主要思想：通过移动阈值来调整决策规则，以及通过数据重采样和[类别加权](@article_id:639455)来调整训练环境。在第二章“应用与跨学科联系”中，我们将遍览医学、[计算生物学](@article_id:307404)和金融等不同领域，看这些原则如何应用于实践，并揭示一个清醒地处理不平衡问题的方法对于科学发现和负责任的人工智能是何等重要。

## 原理与机制

### 多数派的暴政：为何准确率是一个具有欺骗性的指标

想象一下，你是一名公共卫生官员，任务是为一种非常罕见但极其严重的新病毒开发一种快速检测方法。这种病毒每10000人中仅有1人感染。你设计了一种看起来万无一失的简单测试：它总是返回“阴性”结果。那么你的测试准确率是多少？惊人的99.99%！你正确地将10000人中的9999人识别为健康。你可能会忍不住宣布成功。但实际上，你的测试毫无价值。它未能完成其被创造出来的唯一任务：找到那一个病人。

这个简单的思想实验揭示了处理[不平衡数据](@article_id:356483)时的核心陷阱。当一个类别（“多数类别”）在数量上远远超过另一个类别（“少数类别”）时，我们最直观的性能度量——**准确率**（accuracy）——就成了一支诱人但危险的塞壬之歌，引诱我们走向无用的模型。准确率只是简单地计算正确预测的数量，然后除以总数。当99.99%的数据都属于同一个类别时，模型只需完全忽略少数类别，就能达到99.99%的准确率。

这不仅仅是一个假设。在为新药进行的[虚拟筛选](@article_id:323263)中，一个数据集可能包含一百万个分子，其中只有100个是“活性”的[@problem_id:1426729]。一个将所有分子都标记为“非活性”的模型将达到99.99%的准确率，但它却无法完成其唯一的目标：找到那少数珍贵的活性化合物。同样，在[计算生物学](@article_id:307404)中，一个旨在从测序数据中检测罕见致病基因变异的分类器（其中只有1%的变异是致病的），可以通过永远持悲观态度（即总是预测为非致病）达到99%的准确率[@problem_id:2383428]。这个高准确率给了我们一个令人安心的数字，但完全掩盖了模型在我们关心的类别上的彻底失败。

这个教训是深刻的：在一个不平衡的世界里，准确率不仅无法提供信息，而且会主动产生误导。它反映了模型在那些无趣、极其普遍的案例上的表现，却对模型发现罕见关键事件的能力只字不提，而这些事件往往正是模型存在的根本原因。要解决这些问题，我们需要一个新的指南针。

### 更好的指南针：能洞察未见之物的指标

如果准确率是一个坏掉的指南针，我们必须找到对少数类别敏感的新工具。这要求我们不再问“模型整体上有多常是正确的？”，而是开始问一些更细致入微的问题。其中两个最重要的问题是关于**召回率**（recall）和**精确率**（precision）。

*   **召回率**（Recall）或称灵敏度（Sensitivity）：在所有真实为正的实例中，我们的模型成功识别出了多大比例？这是衡量[模型完备性](@article_id:310049)的指标。在我们的病毒例子中，“永远为阴性”的测试其召回率为零。它没有找到任何一个病人。

*   **精确率**（Precision）或称[阳性预测值](@article_id:369139)（Positive Predictive Value）：在所有被模型标记为正的实例中，多大比例是真正为正的？这是衡量模型精确性的指标。一个将所有人都标记为阳性的测试具有完美的召回率，但精确率极差。

这两者之间存在着固有的矛盾。如果你想找到每一个致病变异（高召回率），你可能需要放宽标准，结果也会标记许多良性变异（低精确率）。反之，如果你想确保你标记的每一个变异都确实是致病的（高精确率），你可能需要非常严格，以至于错过一些真正的致病变异（低召回率）。

因此，挑战在于找到一个[平衡点](@article_id:323137)。有几种指标就是为此设计的：

*   **$F_1$分数**：这是[精确率和召回率](@article_id:638215)的**调和平均数**，由公式 $F_1 = 2 \cdot \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ 给出。使用调和平均数而非简单平均数有一个绝佳的特性：它会严重惩罚那些在两个指标中有一个非常低的模型。一个模型只有在[精确率和召回率](@article_id:638215)*都*相当高的情况下才能获得高的$F_1$分数。

*   **[马修斯相关系数](@article_id:355761)（MCC）**：这可能是最稳健的指标之一，MCC考虑了[混淆矩阵](@article_id:639354)中的所有四个条目：[真阳性](@article_id:641419)（$TP$）、真阴性（$TN$）、[假阳性](@article_id:375902)（$FP$）和假阴性（$FN$）。它本质上是观测分类和预测分类之间的相关系数。其取值范围从+1（完美预测）到0（不比随机猜测好）再到-1（完美反向预测）。对于那个无用的“永远为阴性”的分类器，MCC为0，正确地告诉我们它没有预测能力——这是一个比99%准确率诚实得多的评估[@problem_id:2383428]。

*   **[平衡准确率](@article_id:639196)（Balanced Accuracy）**：这只是每个类别召回率的平均值。它衡量模型在正类别和负类别上的表现如何，并给予两者同等的重要性。它直接抵消了标准准确率的偏差，后者被多数类别的表现所主导[@problem_id:3147839]。

这些指标依赖于一个特定的**决策阈值**（例如，如果预测概率 > 0.5，则分类为正）。但是，如果我们想评估模型在*所有*可能阈值下的性能呢？这时我们就需要借助评估曲线。最常见的是受试者工作特征（ROC）曲线，它绘制了召回率相对于[假阳性率](@article_id:640443)（$FPR = FP/N$，其中 $N$ 是负样本数量）的曲线。然而，与准确率一样，[ROC曲线](@article_id:361409)在不平衡场景下也可能具有欺骗性。由于负样本数量 $N$ 非常庞大，模型即使做出数千个[假阳性](@article_id:375902)预测，其 $FPR$ 仍然可以保持在具有欺骗性的小值。

一个好得多的工具是**精确率-召回率（PR）曲线**。通过绘制精确率对召回率的曲线，我们可以直接看到我们所关心的权衡关系。一个好的模型会在召回率增加时仍保持高精确率。**[精确率-召回率曲线](@article_id:642156)下面积（AUPRC）**提供了一个总结这种性能的单一数值。与[ROC曲线下面积](@article_id:640986)（[AUROC](@article_id:640986)）不同（即使模型精确率很差，[AUROC](@article_id:640986)也可能保持高位），如果模型为了获得高召回率而产生了太多[假阳性](@article_id:375902)，AUPRC将会急剧下降[@problem_id:3147839]。对于像[药物发现](@article_id:324955)或疾病筛查这类任务，[假阳性](@article_id:375902)的成本（浪费实验、不必要的后续检查）很高，P[R曲线](@article_id:362970)及其面积是衡量模型效用的最真实标准[@problem_id:1426729]。

### 通往公平的两条路径：调整规则 vs. 调整世界

有了更好的指标，我们现在可以着手解决问题了。在一个不平衡的世界中训练一个公平的模型，主要有两种思想，可以被认为是“调整游戏规则”或“调整游戏所在的世界”[@problem_id:3169410]。

#### 路径1：调整规则（移动阈值）

大多数分类器默认使用0.5的决策阈值。如果你的目标是最小化总错误数，并且假阳性和假阴性的成本相同，那么这个规则是最优的。但在现实世界中，成本很少是相等的。漏诊一个癌症病例（假阴性）的代价远比一次不必要的活检（[假阳性](@article_id:375902)）要高得多。

最优决策阈值不是一个普适常数；它是一个关于**类别先验概率**（事件的稀有程度）和不同错误**非对称成本**的函数。正如一个优美的推导所示，即使是单个[神经元](@article_id:324093)的最优偏置也直接取决于成本和先验概率的比率[@problem_id:3180386]。

这就引出了**移动阈值**（threshold-moving）的策略。首先，我们在原始的[不平衡数据](@article_id:356483)上训练一个模型，确保其输出是经过良好校准的概率。然后，我们不盲目使用0.5的阈值，而是将阈值移动到一个能够优化我们真正关心的指标的值，比如$F_1$分数或一个成本加权的目标。这是一个有原则且强大的后处理步骤。关键在于要认识到，[类别不平衡](@article_id:640952)并*不*意味着对于简单的[0-1损失函数](@article_id:352723)而言，0.5的贝叶斯最优阈值是错误的；它意味着简单的[0-1损失函数](@article_id:352723)本身往往就不是正确的优化目标[@problem_id:3169410]。

#### 路径2：调整世界（数据和[损失函数](@article_id:638865)层面的方法）

第二种思想是改变训练过程本身，迫使模型更多地关注少数类别。

一个常见的方法是**[重采样](@article_id:303023)**（resampling）。这可以包括**过采样**（创建少数类别样本的副本）或**[欠采样](@article_id:336567)**（丢弃一些多数类别样本），以创建一个更平衡的[训练集](@article_id:640691)。虽然直观，但这可能是一种粗暴的工具。简单地平衡数据然后使用0.5的阈值，可能会导致一个对于原始问题分布而言不一致且次优的决策规则[@problem_id:3169410]。

一种更优雅且强大的技术是**[类别加权](@article_id:639455)**（class weighting）。我们不改变数据，而是改变损失函数。当模型犯错时，我们惩罚它，但对于在罕见的少数类别上犯的错误，我们施加更重的惩罚。[交叉熵损失](@article_id:301965)函数非常适合于此。我们可以为每个类别 $k$ 引入权重 $\alpha_k$，因此样本 $(x_i, y_i)$ 的损失变为 $-\alpha_{y_i}\ln s_{y_{i}}(x_{i})$。

我们应该如何选择这些权重？一个引人入胜的研究结果表明，我们可以通过有原则的方式选择这些权重，使模型学到的概率与我们[期望](@article_id:311378)的任何[目标分布](@article_id:638818)相匹配[@problem_id:3113761]。例如，如果我们的训练数据中正类别占1%，但我们希望模型的行为就像它是在一个正类别占10%的群体上训练的一样，我们可以计算出实现这种转换所需的确切权重。这使我们能够为不同的操作环境重新[校准模型](@article_id:359958)，或者仅仅通过调整损失函数中的一组权重来迫使模型更重视少数类别。

### 一个实践中的两难困境：验证集中的冲突

最后，让我们考虑一个实践中的两难困境，它完美地揭示了[类别不平衡](@article_id:640952)问题的核心矛盾。在训练期间，我们监控模型在[验证集](@article_id:640740)上的性能，以决定何时停止（这个过程称为**[早停](@article_id:638204)法** (early stopping)）。但是我们应该监控哪个指标呢？是整体的验证损失（例如，[交叉熵](@article_id:333231)），还是像宏平均$F_1$分数这样对不平衡敏感的指标？

正如一个精心构建的场景所示，这两个标准可能会给出相互矛盾的建议[@problem_id:3119097]。
在某个训练周期（$t_1$），模型可能在少数类别上达到了完美的召回率，从而获得了很高的宏平均$F_1$分数。然而，它可能是通过在多数类别的一个子集上过于自信地犯错来实现这一点的，这导致了相对较高的验证损失。
在随后的一个训练周期（$t_2$），模型可能学会了变得更加“谨慎”，纠正了它在多数类别上的过自信错误。这将降低整体的验证损失，因为验证损失主要由大量的多数样本决定。但这种谨慎可能是有代价的：模型现在可能会错误地分类*所有*少数类别的样本，导致其宏平均$F_1$分数崩溃。

基于最小化验证损失来停止训练，可能会得到一个在多数类别上校准良好且表现出色的模型，但对于你寻找稀有正样本的主要目标来说却毫无用处。基于最大化宏平均$F_1$分数来停止训练，可能会选择一个整体上“更嘈杂”但能更有效地识别少数类别的模型[@problem_id:3119097]。

这不是一个悖论。这是一个选择。它揭示了我们对评估指标的选择不是一种被动的测量；它是对我们的价值观和优先事项的主动声明。在[不平衡数据](@article_id:356483)的世界里，你无法同时优化所有东西。你必须决定什么最重要——是整体概率上的“正确性”，还是成功检测到罕见的关键事件——并相应地选择你的原则和机制。

