## 应用与跨学科联系

既然我们已经探讨了机器学习的原理和机制，现在让我们开启一段旅程。我们将看到，这些基本思想并非仅仅是抽象概念，实际上，它们是一种新的语言——一个强大的透镜，我们可以通过它来构建问题，并在几乎科学和工程的每个角落寻求答案。就像物理学家看到同样的引力定律既支配着苹果的下落又支配着月球的轨道一样，我们将会发现，[机器学习范式](@article_id:642023)在解决各种各样壮观的问题时，其应用方式存在着深刻的统一性。

### 一种用于生命科学的新型显微镜

几个世纪以来，显微镜一直是生物学家窥探细胞隐藏世界的典型工具。今天，机器学习提供了一种新型显微镜，它不是用光来看，而是用数据来看，揭示了以前看不见的、惊人复杂的模式。

考虑一下现代生物学中的一个巨大挑战：理解基因组的“操作系统”，即所谓的[表观遗传学](@article_id:298552)。我们的DNA不是一个静态的蓝图；它被化学标记所修饰，这些标记就像开关一样，告诉基因何时开启或关闭。其中最重要的一种是DNA甲基化。能够预测在给定细胞中数百万个开关中哪些是开启的，哪些是关闭的，对于理解发育和疾病具有极其重要的意义。这对于[监督学习](@article_id:321485)来说是一个完美的问题。科学家们可以为每个潜在的开关收集大量数据——局部DNA序列、包裹DNA的各种“[组蛋白](@article_id:375151)标记”的存在、DNA的可及性——并将这些作为输入[特征向量](@article_id:312227) $\mathbf{x}$，来预测一个二元标签 $y$：“甲基化”或“未甲基化”。

但正如问题 [@problem_id:2560955] 所精辟阐述的那样，这并非简单地将数据输入黑箱。真正的洞见来自于生物学知识和机器学习方法的结合。一个天真的[数据科学](@article_id:300658)家可能会随机分割基因组数据来训练和测试模型。而生物学家知道这是一个致命的错误。基因组具有物理的、线性的结构；相邻区域并非[相互独立](@article_id:337365)。随机分割允许模型通过在与测试区域相邻的区域上进行训练来“偷看”答案，导致对性能的评估过于乐观和虚假。正确的方法，即[交叉](@article_id:315017)[染色体](@article_id:340234)验证（使用一些[染色体](@article_id:340234)进行训练，使用完全独立的[染色体](@article_id:340234)进行测试），尊重了数据的内在结构，并对模型的真实能力给出了一个更为诚实的评估。

一旦我们有了数据，我们应该使用哪种模型？这个问题将我们引向所有科学中的一个根本性[张力](@article_id:357470)。例如，在免疫学中，疫苗设计的一个关键问题是预测哪些小的蛋白质片段，即肽，会与[MHC分子](@article_id:361224)结合以呈现给免疫系统。正如问题 [@problem_id:2507812] 所详述的，我们面临一个选择。我们可以使用一个简单、可解释的模型，如[位置权重矩阵](@article_id:310744)（PWM），它假设肽中的每个氨基酸对[结合亲和力](@article_id:325433)的贡献是独立的。这就像通过简单地将引擎、车轮和底盘的标价相加来估算一辆汽车的价值。它很容易理解——我们可以清楚地看到哪些位置是重要的“锚点”——而且它不需要大量数据来训练。另一方面，我们可以使用一个复杂、强大的模型，如[深度神经网络](@article_id:640465)。这样的模型可以学习到复杂的、非线性的依赖关系：即位置3的某个氨基酸只有在位置7有一个互补的氨基酸时才会产生强烈影响。这就像理解一个强大的V8引擎对跑车的价值贡献远大于对高尔夫球车的贡献。这种模型具有高得多的*容量*来学习生物物理相互作用的真实、复杂现实，但它对数据需求量大，其推理过程通常不透明。没有哪种方法是普遍“更好”的；正确的选择取决于可用数据的数量、基础问题的复杂性，以及我们是优先考虑预测准确性还是[可解释性](@article_id:642051)。

也许在这个领域出现的最令人兴奋的[范式](@article_id:329204)是直接解决“小数据”问题的[范式](@article_id:329204)：*[迁移学习](@article_id:357432)*。MHC分子在人类群体中具有极高的多样性。由于缺乏数据，为每种罕见的变体训练一个独立的[预测模型](@article_id:383073)是不可能的。但是，如果我们能够学习肽结合的*一般规则*并将这些知识迁移过去呢？一个“泛等位基因”模型正是这样做的 [@problem_id:2507812]。我们不是为每个MHC变体训练一个模型，而是训练一个统一的模型，该模型同时将肽序列*和*MHC分子结合口袋的序列作为输入。通过观察来自常见的、数据丰富的MHC变体的许多例子，模型学习了哪种口袋形状偏爱哪种氨基酸形状的基本物理学原理。这种抽象知识随后可以被迁移，用于对它从未见过的罕见MHC变体做出惊人准确的预测。

然而，在我们构建这些越来越强大的工具时，我们必须警惕一个微妙的陷阱。想象一个在显微镜图像中自动勾画细胞轮廓的项目 [@problem_id:1422055]。我们从一个由人类专家仔细标注的小数据集开始。我们用这些数据训练我们的第一代模型。为了改进它，我们需要更多的数据——于是我们用我们的模型自动标注一百万张新图像。然后，我们在这个更大的、由机器标注的数据集上训练第二代模型。这个过程不断重复。危险在于，最初人类标注者任何微小的、系统性的偏差——比如倾向于将细胞边界画得稍大一些——都可能被放大。正如简单而强大的递推关系 $\beta_{n+1} = \alpha \beta_n + \delta$ 所显示的，如果我们的学习过程的偏差放大因子 $\alpha$ 大于一，错误可能会随着每一代而增长。这些模型变成了一个高科技的回声室，对一个共同的、被放大的错误越来越自信。这个警示故事突显了在现实世界中部署机器学习所面临的一个深刻挑战，在现实世界中，模型可能会与它们本应理解的数据生成过程形成反馈循环。

### 跨学科建立新联系

机器学习的[范式](@article_id:329204)不仅限于生物学；它们充当了一座强大的桥梁，连接了看似迥异的领域中的思想。

让我们转向物理学和化学这个由对称性原理支配的优雅世界。当你在空间中旋转一个分子时，它的能量保持不变——这个性质称为*不变性*。其他属性，比如它的偶极矩（一个从负电荷中心指向正[电荷中心](@article_id:330769)的向量），会*随着*分子一起旋转。这被称为*[等变性](@article_id:640964)*。预测这些属性是化学的核心，但传统的量子[模拟计算](@article_id:336734)成本高昂。机器学习能帮忙吗？

一种天真的方法可能是将分子原子的三维坐标输入一个标准的神经网络。但是，正如问题 [@problem-id:2903829] 所精彩展示的那样，如果网络内部只计算旋转不变的量，比如原子间的距离，它永远无法以物理上一致的方式输出一个非[零向量](@article_id:316597)，比如偶极矩！一组没有内在方向性的输入无法产生一个具有特定方向的输出。唯一可能的一致答案是零向量。绝妙的解决方案是把物理定律直接融入模型的架构中。一个*S[E(3)-等变网络](@article_id:368060)*的构建方式保证了如果你旋转输入坐标，输出向量在数学上必然会以完全相同的方式旋转。网络不必从数据中*学习*旋转定律；它*天生*就遵守这些定律。这使得它能够解决一些微妙的问题，比如区分一个分子和它不可重叠的镜像（一对*手性对*），它们具有相同的距离但偶极矩指向相反的、镜像的方向。这是物理学中对称性的基本原理与机器学习架构设计的深刻统一。

从分子的精确世界，我们跳到金融市场混乱、狂热的交易大厅。与静态的基因组数据集不同，市场是一个活的系统，实时演变。问题 [@problem_id:2406515] 构想了一个做市商代理，其工作是报出买卖价格，从差价中获利。要成功，它必须预测未来的订单流。这需要一种不同的[范式](@article_id:329204)：*[在线学习](@article_id:642247)*。代理不会在一夜之间对大量数据进行训练。它一次只学习一笔交易。每当一个新的市场订单到达时，它会对内部的[预测模型](@article_id:383073)进行一次微小的更新，使其在片刻之后的下一次预测中表现得稍好一些。这是从“从数据中学习”到“边做边学”的转变。代理是一个动态环境中的自适应参与者，其自身的行为可以影响未来，这个[范式](@article_id:329204)是通向完整的[强化学习](@article_id:301586)框架的关键垫脚石。

最后，让我们用这些思想来审视机器学习本身。我们有各种各样的[算法](@article_id:331821)：逻辑回归、提升树、神经网络。它们之间有何关联？哪些是“近亲”，哪些又处于不同的“进化分支”上？问题 [@problem_id:2408915] 提出了一个绝妙的类比。让我们把每个模型看作一个生物物种。我们可以通过它在大量基准数据集上的性能得分来衡量它的“性状”。这就为每个模型提供了一个性能向量，类似于基因序列。现在，我们可以根据两个模型的表现差异来定义它们之间的“距离”。有了这个距离矩阵，我们可以直接借用计算生物学中的一个工具——Neighbor-Joining [算法](@article_id:331821)——来构建一个机器学习模型的“系统发育树”。这棵树提供了一个令人惊叹的“[模型空间](@article_id:642240)”可视化，将行为相似的[算法](@article_id:331821)聚集在一起。这是一个完美的例子，说明了一个领域的思想如何能够为另一个领域提供一个强大的新隐喻和实用的工具，以获得洞见。

### 知识的基石：基本极限

我们已经看到了机器学习非凡的力量和广度。但是，我们学习的效率是否存在根本性的极限？

考虑一个基本但关键的任务：评估 $n$ 个不同的模型，以找出从最好到最差的完整排名。我们唯一的工具是一个成对的“A/B 测试”，它告诉我们两个模型中哪一个更好。在最坏的情况下，我们必须执行的绝对最小测试次数是多少，才能保证我们找到正确的排名？

问题 [@problem_id:3226528] 使用[决策树](@article_id:299696)的概念阐明了这个问题。可能的正确排名总数是 $n$ 个项目的[排列](@article_id:296886)数，即 $n!$。我们[算法](@article_id:331821)的工作是 navigating 一条问题的路径，以在这 $n!$ 种可能性中找到唯一正确的排名。每次 A/B 测试都是一个二元问题；它最多给我们提供一位（bit）的信息。在每一步，它最多只能将剩余的可能排名空间减半。为了区分 $n!$ 个结果，我们必须获取至少 $\log_2(n!)$ 位的信息。因此，在最坏情况下所需的测试次数 $h^\star(n)$ 必须至少是 $\log_2(n!)$。

这不是关于某个特定[算法](@article_id:331821)的陈述；这是一个基本的、信息论的下界，适用于*任何*依赖于成对比较的[算法](@article_id:331821)。使用 Stirling's approximation 对阶乘进行近似，我们发现 $\log_2(n!) = \Theta(n \log n)$。这告诉我们，无论我们的[算法](@article_id:331821)多么聪明，其复杂度都被这个下限所束缚。这不是我们创造力的局限，而是这类问题的自然法则。这是一个数学确定性的基石，为整个[算法分析](@article_id:327935)领域提供了坚实的基础。

我们的旅程从细胞的操作系统到宇宙的对称性，从市场的动态到知识本身的极限。机器学习的真正美妙之处不仅在于其实用力量，更在于这种非凡的统一性——即关于学习、表示和适应的几个核心[范式](@article_id:329204)如何提供一种通用语言来描述、预测并最终理解我们周围的世界。