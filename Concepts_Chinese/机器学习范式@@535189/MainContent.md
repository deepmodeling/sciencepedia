## 引言
机器学习不仅仅是一套工具，它更是教机器从数据中学习的一系列基本理念。任何机器学习应用，无论是在科学研究还是在工业界，其成效都取决于能否选择正确的方法。理解这些核心[范式](@article_id:329204)对于避免常见的陷阱至关重要，例如构建在真实世界数据上失败或错误解读新信息的模型。本文旨在揭开机器学习主要[范式](@article_id:329204)的神秘面纱，从抽象的原则走向具体且能改变世界的应用。

本文将引导您了解支撑现代人工智能的基本概念。在“原理与机制”一章中，我们将探讨教机器进行学习的核心理念，包括有“老师”和无“老师”的指导下学习（即[监督学习](@article_id:321485)和[无监督学习](@article_id:320970)）、由此产生的挑战，以及将先验知识融入模型的强大能力。随后，在“应用与跨学科联系”一章中，我们将展示这些[范式](@article_id:329204)如何作为一种强大的语言，连接起从绘制人类基因组图谱到破译物理定律等截然不同的科学领域。让我们从探索这些基本原理及其驱动机制开始。

## 原理与机制

想象一下，你想教一台机器。这到底意味着什么？这不像教一个人；你无法与它进行对话，至少一开始不行。“教”一台机器的过程更像是做一个园丁。你不能命令一颗种子生长，但你可以为它提供合适的土壤、水分和阳光，然后引导它的生长。机器学习的不同“[范式](@article_id:329204)”就是不同的园艺哲学——即为机器提供合适的学习环境和信息的不同方式。让我们来探索其中的一些理念，从最熟悉的开始。

### 有老师指导的学习：监督[范式](@article_id:329204)

最直接的教学方式就是通过示例。你给机器看一张猫的图片，并提供“猫”这个标签。你给它看一张狗的图片，并提供“狗”这个标签。经过成千上万个这样的示例后，如果学习[算法设计](@article_id:638525)得好，机器就会开始辨别区分猫和狗的模式。这就是**[监督学习](@article_id:321485)**的本质：从一个数据集中学习，其中每个输入都带有一个对应的正确输出，即标签。

但这个看似简单的过程充满了风险，它是在“知之甚少”与“知之过多”之间进行的一场精妙的舞蹈。考虑一个分类问题，其“正确”答案是将一个圆内的点与圆外的点分开。如果我们给机器一个非常简单的工具，比如一个只能画直线（线性模型）的模型，它将惨败。无论它如何调整其直线的位置，总会错误地分类大量的点。这是一个具有高**偏差**的模型；其内部假设过于僵化，无法捕捉数据的真实情况。它处于**[欠拟合](@article_id:639200)**状态 [@problem_id:3189724]。

受挫之后，我们可能会给机器一个无限灵活的工具，比如一个可以画出极其复杂、弯弯曲曲的线条（如高次多项式）的模型。现在，机器可以完美地让它的线条蜿蜒穿过我们训练集中的每一个数据点，在它见过的样本上达到100%的准确率。我们可能会感到得意，但我们创造了一个怪物。这个模型并没有学会“圆”这个*概念*；它只是记住了训练点的确切位置，包括任何随机噪声或错误。当我们给它看*新*数据时，它的表现会非常糟糕。这是一个具有高**方差**的模型；它对训练它的特定数据过于敏感。它处于**过拟合**状态 [@problem_id:3189724]。

[监督学习](@article_id:321485)的艺术和科学在于驾驭这种**[偏差-方差权衡](@article_id:299270)**。我们需要一个既足够灵活以捕捉潜在模式（比如一个可以描述圆的简单二次方程），又不会灵活到把噪声也记住的模型。这通常通过**正则化**来实现，这项技术就好比告诉模型：“尽量拟合数据，但如果你过于复杂，我会惩罚你。”这是一种鼓励模型保持简单，并[期望](@article_id:311378)其获得更普遍理解能力的方法 [@problem_id:3189724]。

### 当世界比教科书更大时

一个[监督学习](@article_id:321485)器，即使是经过良好[正则化](@article_id:300216)的，也有一个主要弱点：它只知道它被教过的东西。它在一种**[闭集](@article_id:296900)假设**下运行——即认为世界只包含其训练数据中见过的类别。这在现实世界中可能导致灾难性的失败。

想象一个用于微生物学实验室的机器学习模型，它被训练用基因组数据识别数百种已知的细菌物种。有一天，一位研究人员测序了一个全新的物种，一个该模型训练“教科书”中没有的物种。模型会做什么？它不会举起一面旗子说：“我完全不知道这是什么。”相反，它会强行将这个新细菌归入它所知道的最相似的类别中。它可能会自信地宣布这个新物种是*[大肠杆菌](@article_id:329380)*，从而导致错误的诊断或有缺陷的科学结论。一个真正智能的系统不仅必须能够分类它所知道的，还必须能够认识到它*不*知道的。这要求我们超越简单的分类，转向一种称为**开放集识别**的[范式](@article_id:329204)，该[范式](@article_id:329204)明确包含一种[新颖性检测](@article_id:639433)机制 [@problem_id:2432813]。

在处理不断演化的系统时，这个问题变得更加尖锐。考虑一个模型，它被训练用来通过成千上万个细菌基因组来预测[抗生素耐药性](@article_id:307894)。它学会了将特定的已知基因——如 $qnr$ 基因——与[耐药性](@article_id:325570)联系起来。这个模型运行得非常好，直到它被部署到来自新环境（比如一条河流）的细菌上，这些细菌通过水平基因转移进化出了一种全新的[耐药机制](@article_id:339337)。因为这种新机制不在模型的特征集中，模型看不到任何[危险信号](@article_id:374263)，并预测这些细菌是易感的。模型失败了，因为真实世界的数据分布已经偏离了训练分布。世界变了，而模型的知识变得过时了 [@problem_id:2495451]。

### 无老师指导的学习：无监督[范式](@article_id:329204)

如果我们根本没有任何标签呢？如果我们只是被扔进一个充满原始、未标注数据的世界，我们能学到什么吗？答案是响亮的“能”。这就是**[无监督学习](@article_id:320970)**的领域，其目标不是预测特定的标签，而是发现数据本身内部隐藏的结构和固有的模式。

可以把它想象成你拿到了一千片古代文本的碎片。没有人告诉你文本说了什么，甚至不知道原本有多少页。你会从寻找模式开始：边缘匹配的碎片、似乎从一片延续到另一片的单词、反复出现的短语。通过基于这些内在相似性对碎片进行[聚类](@article_id:330431)和排序，你可以开始重建原始页面。你正在没有任何外部标签的情况下发现数据的潜在结构 [@problem_id:2432863]。这正是[生物信息学](@article_id:307177)中许多任务背后的原理，比如从数百万个短[DNA测序](@article_id:300751)读段中组装出完整的基因组。

然而，[无监督学习](@article_id:320970)常常面临一个被称为**维度灾难**的艰巨挑战。当我们的数据由大量特征描述时——比如说，100名癌症患者的20000个基因的表达水平——我们关于距离和相似性的直觉就会失效。在如此高维的空间中，每个数据点都倾向于远离其他所有数据点。寻找有意义的[聚类](@article_id:330431)或模式，就像试图在一片因星星过于密集而呈现均匀白光的天空中寻找星座一样。这就是为什么分析[高维数据](@article_id:299322)的一个关键首要步骤通常是**[降维](@article_id:303417)**：一套旨在寻找一个能使隐藏结构显现出来的低维视角或更简单语言的技术 [@problem_id:1440789]。

### 监督的光谱：两全其美

纯粹的[监督学习](@article_id:321485)和[无监督学习](@article_id:320970)代表了两个极端。现实世界的大部分情况介于两者之间。我们可能只有少量纯净的、有标签的数据和一片浩瀚的无标签数据。或者我们拥有的“标签”可能不是完美的基准真相答案，而是嘈杂、间接的线索。这就是一系列中间[范式](@article_id:329204)发挥作用的地方，包括**[半监督学习](@article_id:640715)**和**弱[监督学习](@article_id:321485)**。

让我们回到古代文本的比喻。如果在给你 shredded fragments 的同时，还给了你一本包含该语言所有有效词汇的词典呢？这本词典没有告诉你每个词应该放在哪里，所以它不是一个完全的监督信号。但它是一个极其强大的线索。你现在可以拒绝任何会产生词典中找不到的胡言乱语的重构尝试。这本词典提供了**[弱监督](@article_id:355774)**。它约束了[假设空间](@article_id:639835)，使问题更易于管理。它引入了一种有益的偏见（“文本很可能由这些词组成”），从而极大地减少了你可能解决方案的方差 [@problem_id:2432863]。

在医学领域，获得明确诊断（一个真实标签）既昂贵又有风险，这些[范式](@article_id:329204)至关重要。如果我们有少数有标签的病人案例和数千个无标签的案例，我们可以使用半监督方法。一种流行的方法是**[伪标签](@article_id:640156)**，即在小型有标签数据集上训练的模型对无标签数据进行预测。对于它最有信心的预测，它会将其视为真实标签，并在这个更大的组合数据集上重新训练自己。这有点像一个学生，从老师那里学了几个例子后，尝试解决剩下的作业题，并用自己最有信心的答案来巩固自己的学习。其他策略包括**[主动学习](@article_id:318217)**，即模型智能地指出最令人困惑的无标签样本，并请求人类专家为其打上标签，从而最有效地利用专家的时间 [@problem_id:3160953]。

### 先验知识的力量：不要从零开始

贯穿整个旅程的一个主题是纯粹数据驱动的发现与融合先验知识的力量之间的权衡。一个从数据中学习一切的“黑箱”模型看起来可能很神奇，但它常常学到的是脆弱、肤浅的相关性，而非深刻的因果关系。一种更鲁棒的方法是构建那些被赋予了我们自身科学理解的模型。

考虑构建一个细胞新陈[代谢模型](@article_id:347141)的任务。一种**自上而下**的方法是将细胞视为一个黑箱，给它喂食各种营养物质并测量其输出，然后将一个统计模型拟合到这个输入-输出数据上。得到的模型可能具有预测性，但它不会告诉我们它*为什么*有效；其内部参数没有明确的物理意义 [@problem_id:1478097]。

相比之下，一种**自下而上**的方法是基于已知的[酶动力学](@article_id:306191)定律来构建一个机理模型。我们会告诉模型关于 Michaelis-Menten 动力学、[速率方程](@article_id:360355)和[抑制常数](@article_id:350182)。这个模型建立在物理定律的基础之上 [@problem_id:1478097]。现在，让我们来检验这两种方法。想象一下，我们训练一个[黑箱模型](@article_id:641571)和一个基于[热力学](@article_id:359663)机理的模型来预测一个基因在体温 $37^\circ\text{C}$ ($310\,\mathrm{K}$) 下的表达水平。两者可能都表现良好。但如果我们要求它们预测在 $30^\circ\text{C}$ ($303\,\mathrm{K}$) 下的表达水平会发生什么？[黑箱模型](@article_id:641571)从未见过这个温度下的数据，因此没有预测的依据。然而，机理模型在其结构中就融入了热力学定律——比如 Boltzmann 常数 $k_B$ 和自由能 $\Delta G$ 对温度的依赖关系。它可以做出有理有据的外推。它的泛化不是通过在数据点之间[插值](@article_id:339740)，而是通过应用一个普适定律 [@problem_id:2719312]。

这种[嵌入](@article_id:311541)先验知识的原则不仅适用于物理学。在我们那个失败的[抗生素耐药性](@article_id:307894)预测器的案例中，一种更复杂的方法将是超越简单的基因名称特征。取而代之的是，我们可以为模型提供源自[蛋白质三维结构](@article_id:372078)和生化特性的特征。这使得模型能够学习[耐药机制](@article_id:339337)的*概念*（例如，“一种保护药物靶点的蛋白质”），使其能够识别一个功能相同但序列可能不熟悉的新蛋白质 [@problem_id:2495451]。我们甚至可以将知识注入到标签空间本身。与其将“猫”、“狗”和“马”视为任意、不同的标签，我们可以为模型提供编码它们之间关系的语义向量——例如，狗和猫都是“宠物”和“哺乳动物”。这可以实现**[零样本学习](@article_id:639506)**，即模型能够识别一个它在训练中从未见过的类别的对象，仅通过被告知其属性就能做到，这是一种非凡的能力 [@problem_id:3160900]。

归根结底，机器学习的旅程是从模仿到理解的转变。我们从简单的监督开始，就像一个孩子记闪卡一样。然后我们意识到需要我们的模型能够处理新颖性，能够自己找到模式，并在一个信息不完美的世界中学习。但最深刻的一步是数据驱动学习与科学知识的综合——创造出的模型不仅能将[曲线拟合](@article_id:304569)到数据上，而且还能学习到受我们已发现的基本原理约束和丰富的世界表征。这正是机器学习从一种工程工具转变为科学发现真正伙伴的转折点。

