## 引言
在患者安全领域，“**永不发生事件**”(Never Event) 的概念不仅是一项零容忍政策，更是一种根本性的思维转变。它挑战了长期以来将某些医疗悲剧视为不可避免的“并发症”的观念，并将其重新定义为系统本身的可预测、可预防的失误。这种方法超越了因错误而指责个人的做法，转而提出了一个更有力的问题：我们系统的哪些部分出了问题？我们如何才能对其进行工程改造，使其更安全？本文通过解构医疗差错的构成，揭示了为何某些伤害被认为是可预防的而另一些则不然，从而着手解决这个问题。

在接下来的章节中，我们将深入探讨这一革命性的框架。“原则与机制”一章将奠定基础，使用严谨的反事实检验来定义何种事件是“可预防的”，并探讨分层防御的工程概念，如瑞士奶酪模型。我们还将审视关键的人为因素，包括建立鼓励学习的“公正文化”以及健康公平的至关重要性。随后，“应用与跨学科联系”一章将展示这些原则如何付诸实践。我们将看到工业工程和心理学的工具如何改善临床流程，法律和伦理框架如何塑造安全政策，以及系统思维的核心理念如何为应对从人工智能到文化安全的未来挑战提供持久的指导。

## 原则与机制

宣布一个事件“永不”应该发生，是一种大胆甚至近乎 defiant (挑衅) 的声明。它与我们日常经验中那个充满缺陷、事故和随机性的世界背道而驰。然而，在患者安全领域，“**永不发生事件**”的概念并非乌托邦式的梦想，而是一项深刻而实用的工程原则。这是一种思维的转变，从接受某些悲剧为不可避免的“并发症”，转向将其视为系统以可预测和可预防的方式失灵的信号。要理解这一点，我们必须剖析失误的本质，并探索赋予“永不发生事件”力量的原则。

### 失误的剖析

让我们从最令人震惊、看似最不可原谅的错误开始。想象一位外科医生为错误的膝盖动手术，为错误的病人实施心脏手术，或者完全切除了错误的器官。这些都是典型的**部位错误、术式错误和患者错误**事件。它们给人的感觉与其他医疗并发症截然不同，因为它们代表了在最基本的识别和执行任务上的灾难性失败 [@problem_id:4391561]。

这样的事情怎么可能发生？在手术室这样复杂、高压的环境中，有着数十个步骤和多名团队成员，人的易错性是必然的。因此，解决方案不能仅仅是要求人们“更小心”。相反，我们必须在系统中构建智能的屏障。其中最优雅和有效的一种是**手术安全暂停**。就在第一次切口之前——那个无法回头的时刻——整个团队暂停。他们停下手中的工作，大声口头确认患者的姓名、确切的术式以及正确的身体部位和位置。

这不仅仅是一份官僚式的核查表，而是一种强大的社会和认知仪式。它强制形成一个共享的心智模型，确保团队中的每一位成员在采取不可逆转的行动之前都达成共识。这是一个精心设计的停顿点，一个抵御人为失误迷雾的系统性防御。这种简单而有效的防御措施的存在，为我们揭示了构成“永不发生事件”的第一个线索：它是一种我们拥有成熟可靠的预防方法的后果。

### 并非所有伤害都是错误

这让我们认识到一个至关重要的区别。我们必须非常小心，不要将所有不良后果都等同于错误。考虑一位癌症患者接受了像顺铂这样的强效化疗药物治疗。该药物成功攻击了肿瘤，但也损害了患者的肾脏，这是一个已知且常见的副作用 [@problem_id:4381485]。患者遭受了伤害，且该伤害是由医疗 treatment 引起的——我们称之为**医源性伤害**。但这是错误吗？不是。只要药物给药正确，并且与患者讨论了风险，这种伤害就是必要治疗中一个可预见且被接受的后果。

现在，将其与另一位患者对比，这位患者因为有人算错剂量而接受了十倍过量的同一种药物。这位患者也遭受了医源性伤害，可能要严重得多。但这一次，伤害不是一个被接受的风险，而是一个流程失败的直接结果——一次**医疗差错**。

这种区别是患者安全的基石。当我们谈论“永不发生事件”时，我们不是在谈论医学中已知的、固有的风险。我们 squarely (完全) 关注的是**可预防的不良事件**：由错误导致的伤害。我们的目标不是消除所有伤害——这是一项不可能完成的任务——而是消除所有*可预防的*伤害。但这引出了最重要的问题：某件事是可预防的，这到底意味着什么？

### 反事实检验：“可预防”的真正含义

说一个事件是“可预防的”，这是一个强有力的断言。它意味着在一个平行宇宙中，一个不同的选择本可以带来更好的结果。这就是哲学家和律师所说的**反事实**论证。例如，在一个医疗过失案件中，原告必须证明，“若非”医生的违反职责行为，伤害发生的概率就不会超过 $0.5$ [@problem_id:4495495]。在胆囊切除术中，如果外科医生忽略了遵守标准的安全指南，对胆管造成的损伤可能是一个可预防的错误。但如果外科医生遵守了所有规则，只是病人的解剖结构异常具有欺骗性，那么完全相同的损伤就可能被认为是不可避免的并发症。区别不在于结果，而在于过程。

我们可以将此从法律论证提升为严谨的科学检验。一个不良事件被定义为可预防的，如果在护理时存在一个可行的、符合指南的替代行动，该行动本可以*实质性地降低伤害的概率* [@problem_id:4381536]。

想象一下，一位接受髋关节手术的患者在肺部出现了危及生命的血块（肺栓塞）。我们从大规模的科学研究——随机对照试验的荟萃分析——中得知，在此类手术后给予特定的血液稀释剂，能将出现此类血块的风险从大约 $4\%$ 降低到 $1.5\%$。这种风险降低在统计学上是显著的，并且具有临床意义。如果一家医院无正当理由未能为患者提供这种标准药物，而该患者随后发生了肺栓塞，我们就可以将该事件归类为可预防的。我们的判断并非基于直觉，而是基于一个以最佳可用科学证据为基础的反事实检验。在那个患者接受了正确护理的“平行宇宙”中，伤害的风险显著降低。

### 零容忍的悖论

至此，我们遇到了一个有趣的悖论。如果“可预防”仅仅意味着将伤害的概率降低——从 $4\%$ 降到 $1.5\%$，但并非降至零——那么我们如何证明“永不发生事件”这个术语的合理性？我们如何能对一个仍有非零发生概率的事件实行“零容忍”？

答案在于[系统工程](@entry_id:180583)中最美妙的概念之一：**分层防御**的力量，通常被称为**瑞士奶酪模型**。想象一下，要防止手术纱布被意外留在病人体内——一个典型的“永不发生事件” [@problem_id:5187429]。你可以依赖单一防御，比如让护士在手术前后清点纱布。但护士可能会分心；这个单一的防御层有“洞”。假设它的[失效率](@entry_id:266388)为 $q_1$。

现在，让我们增加更多的层次。我们增加第二次独立的清点（$q_2$）。我们在暂停期间增加强制性的团队讨论（$q_3$）。我们将射频识别（RFID）标签嵌入纱布中，并在缝合伤口前使用扫描仪（$q_4$）。这些层次中的每一个都是不完美的。但因为它们的失效模式是独立的，所以*整个系统*失效的概率是它们各自[失效率](@entry_id:266388)的乘积：$P(\text{System Failure}) = q_1 \times q_2 \times q_3 \times q_4$。如果每个层次的可靠性为 $90\%$（[失效率](@entry_id:266388)为 $0.1$），那么四层系统的可靠性为 $99.99\%$（失效率为 $0.1^4 = 0.0001$）。我们用不完美的组件 engineered (构建) 出了近乎完美的可靠性。

这就解决了悖论。一个“永不发生事件”不是一个字面概率为零的事件。它是一个我们为其设计了如此强大、冗余且成熟的防御措施的事件，以至于它的发生并非统计上的波动。它是灾难性、系统性崩溃的信号。我们“瑞士奶酪”的多个层次必定是同时失效了。

这就是我们实行零容忍的原因。“零容忍”不是一种预测，而是一种*政策*。它意味着如果这类事件哪怕只发生一次，我们也不能聳聳肩说“运气不好”。我们将其视为一个关键的失败信号。我们会停下来，进行严谨的**根本原因分析（RCA）**，找出哪些防御层失效了以及原因为何，以便我们能够在未来加强它们。

### 系统、信号与公正文化

建立这种可靠性需要将整个医院视为一个集成系统。医院的领导层有责任监督护理质量，但这在信号检测方面是一项巨大的挑战：你如何在日常临床工作排山倒海的“噪音”中，找到不安全操作的微弱“信号”？设计一个监视系统需要在**敏感性**（检测真实问题的能力）和**特异性**（避免误报的能力）之间进行艰难的权衡 [@problemid:4488100]。过多的误报会导致警报疲劳和资源浪费，而敏感性太低则意味着错失在悲剧发生前进行干预的机会。

最重要的是，这些系统是由人来运行的。要找出我们防御中的缺陷，我们需要一线员工报告错误，以及更有价值的**未遂事件**——那些错误在造成伤害前被发现的“免费教训” [@problem_id:4672069]。但如果害怕惩罚，没有人会报告错误。

这就是建立**公正文化**的迫切需要 [@problem_id:4378737]。公正文化并非免责文化，而是一种能够区分不同类型的人类行为并作出相称回应的文化。
- **人为失误**，如无意的疏忽，应予以安慰，并专注于修复那个使人容易犯错的系统。
- **风险行为**，如因时间压力而走捷径，应通过辅导来理解为何捷径看起来是个好主意，并重新调整激励措施。
- **鲁莽行为**，一种有意识且不合理的对安全的漠视，是罕见的，应予以纪律处分。

这个框架允许组织创建一种**双路径架构**：一条受保护的、非惩罚性的路径，用于从绝大多数事件中学习；另一条独立的、狭窄的路径，用于在真正鲁莽的情况下追究责任。它承认，将一个事件定性为“永不发生事件”强烈暗示了系统性失败，但在法庭上并不能自动证明个人存在过失 [@problem_id:4496315]。它触发的是调查，而非处决。

### 最后的疆域：公平

最后，我们必须问最困难的问题：我们精心设计的、高可靠性的系统对*每个人*都安全吗？想象一下，一家医院在两个不同的科室实施了完全相同的手术安全核查表——这是一个提供**平等**的完美例子。然而，服务于有许多非英语患者的[边缘化](@entry_id:264637)社区的科室，其可预防伤害的发生率是服务于富裕、讲英语社区科室的三倍 [@problem_id:4676752]。

流程是相同的，那么哪里出错了？流程周围的*结构*不同。核查表依赖于沟通，但边缘化患者缺乏足够的专业口译员。他们的护理也因低效的排程系统而延误。为有不同需求的人提供相同的工具，并不会产生相同的结果。

这揭示了**平等**（给每个人相同的东西）与**公平**（给每个人成功所需的东西）之间的深刻差异。一个真正安全的系统是一个公平的系统。它必须足够强大，以克服那些使某些患者处于更大风险之中的结构性障碍——贫困、语言、偏见。一个“永不发生事件”系统的最终原则不仅仅是预防特定的技术错误，而是不懈地追求一个如此强大、如此周到、如此公正的系统，以至于它能为每一个将生命托付给我们的 individual (个体) 兑现安全的承诺。

