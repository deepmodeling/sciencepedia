## 引言
在[虚拟化](@entry_id:756508)世界中，在单一物理机器上运行多个相互隔离的[操作系统](@entry_id:752937)的能力彻底改变了计算领域。然而，这种强大的抽象能力通常伴随着性能开销，尤其是在虚拟机（VM）需要与高速外围设备交互时。传统的在软件中模拟硬件的方法会造成严重的 I/O 瓶颈，从而限制了要求苛刻的应用的潜力。我们如何在不损害[虚拟化安全](@entry_id:756509)基石——隔离性——的前提下，赋予[虚拟机](@entry_id:756518)直接访问硬件的原始速度？

本文将探讨**设备直通**（device passthrough）技术，这是一种功能强大的技术，通过在[虚拟机](@entry_id:756518)和物理设备之间建立一个安全、高性能的桥梁，直接解决了这一挑战。它解决了直接访问硬件所固有的安全风险，展示了现代系统如何在不牺牲[系统完整性](@entry_id:755778)的情况下提供接近本机的性能。在接下来的章节中，您将深入了解这项至关重要的[虚拟化](@entry_id:756508)技术。**原理与机制**一章将解构设备直通的工作原理，介绍直接内存访问（DMA）和输入/输出内存管理单元（IOMMU）的关键作用。随后，**应用与跨学科联系**一章将展示这些原理在现实世界中的应用，从构建更快的云平台到设计更安全的汽车。

## 原理与机制

要真正领略设备直通的魅力，我们必须首先退后一步，看看计算机是如何工作的。计算机的核心是一个聪明但常常超负荷工作的中央处理器（CPU）和一个被称为内存的庞大信息库。但一台只能自言自语的计算机并没有多大用处。它需要通过网络、显示器和存储设备与外部世界互动。这就是外围设备的工作。

### 设备的超能力：直接内存访问

想象一下，一个网卡正在接收来自互联网的大量数据。如果 CPU 必须亲自将每一个字节从网卡护送到内存中的最终目的地，它将没有时间做任何其他事情。整个系统都会陷入停顿。为了解决这个问题，工程师们赋予了外围设备一项奇妙的超能力：**直接内存访问（DMA）**。

DMA 允许设备直接对计算机[主存](@entry_id:751652)进行读写数据，完全绕过 CPU。CPU 只需告诉设备：“这里是内存中我希望你发送的一块数据”，或者“当新数据到达时，请将其放入此内存缓冲区”，然后就可以处理其他事务。设备会自己完成整个传输过程。

在一个[操作系统](@entry_id:752937)运行在裸机上的简单世界里，这是一种优美而高效的安排。但在虚拟化世界中，一台物理机承载着许多独立的[虚拟机](@entry_id:756518)（VM），这种超能力就变成了一个可怕的安全风险。如果你让一个[虚拟机](@entry_id:756518)直接控制一个设备，那么该虚拟机内部的恶意程序就可以命令设备利用其 DMA 能力来覆写 hypervisor 的内存，或者窥探另一个[虚拟机](@entry_id:756518)的数据，有什么能阻止它呢？什么也没有。一个拥有不受限制 DMA 能力的设备就是一个巨大的安全漏洞。[@problem_id:3689886]

### 内存的守护者：IOMMU

我们如何在不危及整个系统的情况下，赋予设备这种惊人的性能优势呢？我们需要一个守门人。我们故事中的英雄登场了：**[输入/输出内存管理单元](@entry_id:750812)（IOMMU）**。

IOMMU 是一块位于 I/O 设备和[主存](@entry_id:751652)之间的硬件。它的工作类似于 CPU 自身的[内存管理单元](@entry_id:751868)（MMU），但它管理的不是 CPU 的内存视图，而是*设备*的内存视图。当设备向某个内存地址发起 DMA 请求时，[IOMMU](@entry_id:750812) 会拦截该请求。它会在一个由可信的 hypervisor 编程的特殊表中查找该地址，并进行转换。

可以把它想象成银行的保安。客户虚拟机的驱动程序可能会告诉其设备：“将此数据写入 123 号保险箱。”然而，设备并不知道保险库的真实布局。它将其对 123 号保险箱的请求发送给 IOMMU。我们的保安 IOMMU 会查阅由银行经理（hypervisor）提供给它的账本。账本上写着：“对于这个客户，‘123 号保险箱’实际上对应于真实的 8675 号保险库位置，并且他们只被允许访问 8675 到 8690 号位置。” IOMMU 转换地址并确保访问在允许的范围内。如果设备试图访问 ‘500 号保险箱’，一个在其账本中没有有效映射的地址，IOMMU 就会阻止该请求并发出警报（产生一个故障）。[@problem_id:3689886]

这种优雅的硬件机制是安全设备直通的基石。它将设备强大的 DMA 能力严格限制在分配给其客户[虚拟机](@entry_id:756518)的内存页内。它确保了即使客户机是恶意的，也无法利用设备逃出其虚拟监狱。这种分离至关重要：CPU 的内存访问由其 MMU（使用嵌套页表等结构）监管，而设备的内存访问则由 [IOMMU](@entry_id:750812) 监管。这两个系统并行工作，以提供全面的隔离。[@problem_id:3658003]

### 多样化的选择：从仿真到直通

有了 [IOMMU](@entry_id:750812) 提供的安全网，我们现在可以考虑让虚拟机直接访问物理设备了。这种被称为**设备直通**的技术是虚拟化世界中 I/O 性能的巅峰。但它并非唯一的选择。事实上，它处于性能、灵活性和隔离性之间权衡的一端。

*   **完全设备仿真：** 在这个[光谱](@entry_id:185632)的一端，hypervisor 可以完全在软件中模拟一个设备。当客户[虚拟机](@entry_id:756518)认为它在与网卡通信时，它实际上只是在发出被 hypervisor 捕获的请求。然后，hypervisor 解释这些请求，并在真实硬件上执行相应的操作。这提供了最强的隔离——客户机对任何硬件都没有访问权限。然而，这种软件解释的速度非常慢，使其不适用于高性能任务。[@problem_id:3689905] 有趣的是，这个软件层有时可以提供更高的[数据完整性](@entry_id:167528)。如果底层主机文件系统是健壮的，它可以保护客户机免受廉价、普通的 USB 驱动器在断电期间的不稳定行为的影响——这是直通技术无法提供的保护。[@problem_id:3648909]

*   **[半虚拟化](@entry_id:753169)（例如 [virtio](@entry_id:756507)）：** 这是一种协作式的中间方案。客户机[操作系统](@entry_id:752937)“意识到”自己被虚拟化，并使用一个特殊的高效软件通道与 hypervisor 通信。Hypervisor 仍然仲裁对物理设备的访问，但通信过程被简化了。这提供了比完全仿真好得多的性能，并保留了 hypervisor 控制的许多优点，例如在[虚拟机](@entry_id:756518)之间公平调度[网络流](@entry_id:268800)量的能力以及执行实时迁移的关键能力。[@problem_id:3668525]

*   **设备直通（例如 SR-IOV）：** 这是追求极致性能的选项。[Hypervisor](@entry_id:750489) 几乎完全从数据路径中退出。使用像**单根 I/O 虚拟化（SR-IOV）**这样的技术，一个物理设备可以呈现出多个“虚拟功能”（VF），每个 VF 都可以直通给不同的虚拟机。客户机驱动程序直接与硬件 VF 通信。对于像需要每秒 90 帧的虚拟现实应用这样的高要求工作负载，其他方法的开销实在太高；直通是唯一可行的选择。[@problem_id:3689905] [虚拟机](@entry_id:756518)获得了接近本机的性能，但这是有代价的。Hypervisor 失去了强制执行细粒度网络策略的能力，并且出现了一个重大挑战：设备的状态现在与一块物理硬件绑定在一起。[@problem_id:3668525]

### 全貌：中断、迁移和物理现实

实现真正的本机性能不仅仅涉及数据路径。设备需要引起 CPU 的注意，虚拟机也需要是可管理的。在这里，直通技术的美丽简洁性也暴露了其尖锐的棱角。

设备通过发送**中断**来通知 CPU。在一个纯仿真的世界里，这涉及到一次代价高昂的“VM exit”，即控制权从客户机转移到 hypervisor，然后 hypervisor 再将一个虚拟中断注入回客户机。这会增加显著的延迟。通过直通技术，我们可以利用像**消息信号中断（MSI-X）**这样的硬件特性，并结合 IOMMU 中的**中断重映射**。MSI-X 只是一种特殊的 DMA 写入。[IOMMU](@entry_id:750812) 可以重映射这次写入，以特定客户机的虚拟 CPU 为目标，并且借助一种称为**posted interrupts**的特性，这可以在完全没有 VM exit 的情况下发生。硬件将通知直接传递给客户机，为我们提供了一条与快速数据路径相匹配的极速[控制路径](@entry_id:747840)。[@problem_id:3689896]

但这种与硬件的紧密绑定是有代价的：灵活性。虚拟化的杀手级特性之一是**实时迁移**，即在没有停机时间的情况下将正在运行的[虚拟机](@entry_id:756518)从一个物理主机移动到另一个物理主机的能力。这涉及到复制虚拟机的内存和 CPU 状态。但是，直通网卡的状态怎么办呢？它的配置、活动的连接过滤器、内部缓冲区——所有这些状态都存在于源主机的物理芯片内部。[Hypervisor](@entry_id:750489) 无法简单地读取它。除非设备硬件本身提供一种特殊的机制来保存和恢复其状态，否则实时迁移是不可能的。常见但复杂的解决方法是一种精巧的操作：从[虚拟机](@entry_id:756518)热拔插物理设备，热插拔一个临时的[半虚拟化](@entry_id:753169)设备，迁移虚拟机，然后在目标主机上反向执行此过程。[@problem_id:3689877]

此外，物理世界不容忽视。现代服务器通常采用**[非统一内存访问](@entry_id:752608)（NUMA）**架构，拥有多个插槽，每个插槽都有自己的本地内存。访问远程插槽上的内存速度较慢。如果一个[虚拟机](@entry_id:756518)的 CPU 在插槽 B 上运行，但其直通的网卡物理上插在插槽 A 上，性能损失将不可避免。从设备到[虚拟机](@entry_id:756518)内存的每一次 DMA 都必须跨越插槽间的连接。从设备到虚拟机 CPU 的每一次中断也必须跨越同一个连接。正确的[性能调优](@entry_id:753343)需要 NUMA 感知的布局，将[虚拟机](@entry_id:756518)的 CPU、其内存及其直通设备共同放置在同一个物理插槽上。虚拟世界仍然受制于物理世界。[@problem_id:3648949]

### 当保护失效时：机器中的幽灵

IOMMU 是一个强大的守护者，但它的保护能力取决于 hypervisor 赋予它的规则。在这个复杂系统中，一个单一的 bug 或配置错误就可能导致隔离的彻底崩溃。想象以下几种情况：

*   **过于宽松的映射：** hypervisor 中的一个 bug 可能会意外地在 IOMMU 中创建一个比预期大得多的“超级页”映射，从而暴露出包含 hypervisor 自身代码的物理内存区域。恶意的客户机随后可以编程其设备对该区域进行 DMA，从而控制整个机器。[@problem_id:3646224]

*   **过时的转换：** 为了提高速度，[IOMMU](@entry_id:750812)（以及设备本身）会缓存[地址转换](@entry_id:746280)。如果 hypervisor 从客户机取消映射一个内存页并将其重新分配给自己的内核，它*必须*通知 [IOMMU](@entry_id:750812) 刷新该过时的缓存条目。如果未能及时这样做，客户机的设备可能会继续使用其旧的、缓存的权限对该页面进行 DMA，从而破坏敏感的主机数据。这是一个典型的“检查时到使用时”（Time-of-Check-to-Time-of-Use, [TOCTOU](@entry_id:756027)）攻击。[@problem_id:3646224]

*   **被遗忘的恒等映射：** 一些系统为 [IOMMU](@entry_id:750812) 提供了一种特殊的“[恒等映射](@entry_id:634191)”模式，在这种模式下，它只是简单地传递地址而不进行转换。如果为直通设备错误地启用了此模式，客户机便可以写入其选择的任何物理地址，从而使所有保护措施都变得毫无意义。[@problem_id:3646224]

这些例子表明，虽然原理很优雅，但它们的实现需要格外小心。在这些系统中，安全不是一道单一的墙，而是一系列精心协调的防御措施。

### 深入探索：嵌套 I/O [虚拟化](@entry_id:756508)

正当你认为自己已经完全理解时，[虚拟化](@entry_id:756508)世界又增加了一个层次。如果你的客户虚拟机*本身*就是一个 hypervisor，运行着它自己的一套“孙子”[虚拟机](@entry_id:756518)呢？这就是**[嵌套虚拟化](@entry_id:752416)**。现在，假设这个客户 hypervisor（$L_1$）想把一个物理设备直通给它自己的客户机（$L_2$）。

$L_2$ 中的驱动程序只知道它自己的“物理”地址（$gpa_2$）。然而，设备需要一个最终的主机物理地址（$hpa$）。这需要一个两阶段的转换：首先从 $gpa_2$ 转换到 $L_1$ 的物理地址空间（$gpa_1$），然后从 $gpa_1$ 转换到真正的主机物理地址（$hpa$）。如何安全地做到这一点呢？

答案再次在于扩展我们的原理。要么硬件必须提供一个能够直接执行这种两阶段转换的**嵌套 [IOMMU](@entry_id:750812)**，要么顶级 hypervisor（$L_0$）必须[捕获并模拟](@entry_id:756142) $L_1$ 对 IOMMU 进行编程的所有尝试，在软件中组合这些转换，为真实的硬件 [IOMMU](@entry_id:750812) 构建一个“影子”映射。[@problem_id:3648912] 这种优美的递归展示了底层概念的力量和统一性。无论是访问共享资源的仲裁这个基本问题，还是硬件强制、软件管理的转换层这个解决方案，无论你深入探索到何种程度，它们都一再适用。

