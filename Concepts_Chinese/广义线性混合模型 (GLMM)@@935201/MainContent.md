## 引言
在数据分析领域，简单[线性回归](@entry_id:142318)是一个基础工具，但其关于正态分布结果和独立观测的假设在复杂、真实的现实世界研究中很少成立。科学家们经常遇到聚[类数](@entry_id:156164)据，例如来自同一个体的重复测量数据；或非正态数据，例如[二元结果](@entry_id:173636)（是/否）或计数（事件发生的次数）。使用传统方法分析此[类数](@entry_id:156164)据可能导致错误的结论。本文旨在通过介绍广义[线性混合模型](@entry_id:139702) (GLMM) 来弥补这一关键差距。GLMM 是一个精密而灵活的统计框架，专为应对这些挑战而设计。

本文将引导您了解 GLMM 的强大功能。在“原理与机制”一章中，我们将把模型分解为其两个核心思想：“广义线性”部分，它使用[连接函数](@entry_id:636388)以适应各种数据类型；以及“混合”部分，它使用随机效应来为聚类数据的结构建模。接下来，“应用与跨学科联系”一章将展示这一单一框架如何统一不同领域的研究问题，从生态学中追踪个体随时间的变化，到医学中综合多个临床试验的证据。读完本文，您将理解 GLMM 如何为观察自然世界的结构化复杂性提供一个更细致、更准确的视角。

## 原理与机制

想象一下，你是一位研究人类活动规律的科学家。你给一千人分发了健身追踪器，并收集了他们两个月内的每日步数。简单线性回归这个统计学的主力工具，似乎是一个不错的起点。但你很快就会遇到一些这个可靠工具无法解决的难题。如果你的模型预测某人明天会走 $-500$ 步，该怎么办？这毫无意义。还有，Jane 是一名马拉松运动员，她的步数会持续偏高；而 Bob 在家工作，他的步数会持续偏低。这种情况又该如何处理？每个人的测量数据都不是独立的事件，它们是聚类的。Jane 今天的步数能告诉你一些关于她明天步数的信息。

这些难题——结果不呈优美的[钟形曲线](@entry_id:150817)，以及数据以相关的群组形式出现——在现实世界中并非例外，而是常态。为了理解它们，我们需要一个更精密，而且事实证明也更优美的工具：**广义[线性混合模型](@entry_id:139702) (GLMM)**。这个框架将线性回归的简单思想优雅地扩展到了一个广阔的科学问题新领域。

### 超越直线：“广义线性”部分的故事

我们先来解决第一个难题：数据不符合简单的直线。步数必须是非负整数（$0, 1, 2, \dots$）。患者感染的概率必须在 $0$ 和 $1$ 之间。一个标准线性模型 $y = \beta_0 + \beta_1 x$ 完全无视这些限制，可以预测从负无穷到正无穷的任何值。

我们框架中的“广义线性”模型 (GLM) 部分用一个优雅的想法解决了这个问题：**连接函数**。可以把它想象成一个翻译器。我们不直接对[数据建模](@entry_id:141456)，而是对数据的某种转换形式进行建模。对于像我们的每日步数这样的计数数据，我们可以使用对数作为[连接函数](@entry_id:636388)。模型就变成了 $\ln(\text{mean steps}) = \beta_0 + \beta_1 x$。由于正数的对数可以是任何数，我们右侧的线性预测量就可以自由变化。要获得平均步数的预测值，我们只需进行反向转换：$\text{mean steps} = \exp(\beta_0 + \beta_1 x)$。因为指数函数总是正的，所以我们的预测值保证是合理的——再也不会有负数步了。

对于[二元结果](@entry_id:173636)，比如患者的血压是否得到控制（$1$ 代表是，$0$ 代表否），我们需要预测一个介于 $0$ 和 $1$ 之间的概率。这里一个常用的翻译器是 **logit** 连接函数，即 $\ln(p / (1-p))$，它将一个概率 $p$ 映射到整个数轴上。我们的模型就变成了 $\ln(p / (1-p)) = \beta_0 + \beta_1 x$。同样，右侧不受约束，但当我们反转变换求 $p$ 时，它总是被巧妙地压缩在 $0$ 和 $1$ 之间。

连接函数这个简单的想法将[线性模型](@entry_id:178302)“广义化”，使其能够处理各种数据类型。但它也改变了我们思考数据变异性的方式。对于正态分布，方差是一个独立的参数。然而，对于计数数据，方差通常与均值相关。最简单的计数模型，即泊松分布，有一个严格的假设：方差必须等于均值。但现实世界的数据往往更混乱。在我们的步数研究中，方差可能远大于均值——这种现象称为**[过度离散](@entry_id:263748)** (overdispersion) [@problem_id:4749699]。这告诉我们，存在某种额外的变异来源在起作用。我们可以通过将泊松分布换成一个更灵活的分布来处理这个问题，比如负二项分布，它有一个额外的旋钮可以调节，允许方差远大于均值。GLM 框架让我们不仅能自由选择正确的[连接函数](@entry_id:636388)，还能为我们的响应变量选择正确的分布“族”。

### 群体的特征：“混合”部分的故事

现在来看第二个难题：聚类数据。来自同一个人、同一家医院或同一家族谱系的观测值是相关的。忽略这一点就像把兄弟姐妹当作完全的陌生人——你错过了故事的关键部分，并且你对世界的结论会过于自信。

这就是 GLMM 中“混合”一词的由来。一个[混合模型](@entry_id:266571)既包含**固定效应**也包含**随机效应**。固定效应是[回归模型](@entry_id:163386)中我们熟悉的组成部分——我们预测变量的系数，如年龄、性别或治疗组。我们假设它们是我们想要估计的固定的、普适的常数。例如，一种新药对血压的效应*是*什么？

**随机效应**是一个革命性的想法。它们是我们用来为那些导致聚类之间差异的、未被观测到的异质性建模的方式。在我们的步数研究中，每个人都有自己独特的基线活动水平，这是我们已测量的协变量无法捕捉的。Jane 就是比 Bob 更活跃。[随机效应模型](@entry_id:143279)通过给每个人一个对模型截距的个人化调整来承认这一点。我们不试图将每个人的具体调整估计为一个固定的数值。相反，我们假设这些个人化调整是从一个单一的、总体的分布中“随机”抽取的，这个分布通常是均值为零、方差待我们估计的正态分布 [@problem_id:4924270] [@problem_id:4955042]。

这是一个极其强大的概念。这个分布的估计方差告诉我们个体*之间*存在多大的变异性。是每个人都差不多，还是基线活动水平存在巨大差异？通过对此建模，我们可以恰当地解释个体内相关性，并为我们的固定效应获得更可靠的[标准误](@entry_id:635378)。此外，我们可以开始剖分方差。例如，在进化生物学中，一种被称为“动物模型”的 GLMM 可以利用谱系将[繁殖力](@entry_id:181291)等性状的[表型方差分解](@entry_id:190093)为可归因于加性遗传、[母体效应](@entry_id:172404)和个体永久环境的部分 [@problem_id:2741493]。我们不再仅仅是描述关系，而是在剖析变异的真正来源。

### 两种视角：主体与群体

在这里，我们遇到了使用 GLMM 最微妙和最深刻的后果之一。当我们引入非线性[连接函数](@entry_id:636388)时，我们固定效应的解释分裂为两种。一个像“这种药物的效应是什么？”这样简单的问题，现在有了两个不同但同样有效的答案。

来自 GLMM 的系数具有所谓的**特定于主体（或条件性）的解释**。假设我们用一个逻辑斯蒂 GLMM 来拟合来自聚类在不同医院的患者的感染数据。模型为一种新的清洁方案提供了一个比值比。这个比值比告诉你：“对于一个*特定的医院*，在保持其独特的、未观测到的特征不变的情况下，新方案使其患者的感染比值降低 X%。” 这是以医院的随机效应为条件的效应。这是你会讲给想知道在他们自己院内影响的医院管理者听的故事 [@problem_id:4924270]。

但一位卫生部长可能会问一个不同的问题：“在全国范围内，这个方案的平均效应是什么？” 这需要一种**群体平均（或边际）的解释**。这是如果你对所有不同医院的特征进行平均后会得到的效应。

对于线性混合模型（使用恒等连接函数），这两种解释是相同的。但对于带有非线性连接函数的 GLMM，它们则不同！这是名为[詹森不等式](@entry_id:144269) (Jensen's inequality) 的数学规则的结果。如果你对一组非线性曲线（比如每家医院的 S 形逻辑斯蒂曲线）进行平均，得到的平均曲线将有不同的形状——具体来说，它会更平坦。这意味着群体平均效应几乎总是看起来比特定于主体的效应更小（更接近于零）。

这带来了一个绝妙的见解。并不存在一个“真正”的效应，而是存在两种看待它的不同方式，一种在个体层面，另一种在群体层面。另一类称为广义估计方程 (GEE) 的模型，就是专门设计来直接估计群体平均效应的 [@problem_id:4955042]。

令人惊讶的是，在一种特殊情况下，这种二元性会消失。对于使用[对数连接函数](@entry_id:163146)的泊松或负二项 GLMM 建模的计数数据，特定于主体的和群体平均的*率比*是相同的 [@problem_id:4951112] [@problem_id:4967686]。这是[指数函数](@entry_id:161417)的一个奇特而美妙的性质，其中对 $\exp(\text{effect} + \text{randomness})$ 求平均可以分解为 $\exp(\text{effect}) \times \text{average of randomness}$。效应大小本身被保留了；唯一的区别是基线群体率被一个与随机效应方差相关的因子放大了。这是在复杂性中一个意想不到的数学简洁时刻。

### 深入了解：这些模型是如何拟合的？

那么，我们实际上是如何估计这些复杂模型的参数的呢？我们不能只用普通最小二乘法。指导原则是**最大似然法**。我们想找到那些使我们观测到的数据最可能出现的参数值（包括固定效应和随机效应方差的参数）。

然而，这里有一个难题。要计算数据的似然，我们必须承认我们不知道每个人或每家医院的具体随机效应。我们只知道它们来自哪个分布。所以，为了找到我们数据的真实概率，我们必须对随机效应可能取的所有值进行平均。这种对随机效应的“积分消元”得到了所谓的**[边际似然](@entry_id:636856)** [@problem_id:4967686]。

除了最简单的情况外，这个积分是一个没有干净、[闭式](@entry_id:271343)解的数学怪物。这正是现代计算能力发挥作用的地方。统计学家们已经发展出几种巧妙的近似技术。一些方法，如**自适应高斯求积**，本质上是非常复杂的[数值积分方法](@entry_id:141406)，用一个精心选择的加权和来近似积分。另一些方法，如**[拉普拉斯近似](@entry_id:636859)**，则另辟蹊径：它们用一个更友好的高斯曲线来近似积分内部函数的复杂形状，而高斯曲线的积分是很容易求解的 [@problem_id:4826681]。

这些方法各有取舍。求积法非常准确，但如果你每个聚类中有很多随机效应，计算速度可能会变得很慢（即“维度灾难”）。[拉普拉斯近似](@entry_id:636859)要快得多，但可能会有偏差，尤其是在聚类中数据点很少或随机效应方差很大时 [@problem_id:4826681] [@problem_id:4951148]。理解这些取舍是应用统计学艺术的一部分。

即使在我们拟合了一个模型之后，我们怎么知道它是否好呢？对于 GLMM，传统的残差通常具有误导性。一种现代而优雅的方法，以 DHARMa 等方法为例，是使用仿真。我们用我们拟合的模型来仿真数百个新数据集。然后，我们问：我们真实的、观测到的数据点看起来像我们仿真世界中的一个典型抽样吗？这就创建了“基于仿真的”残差，如果模型正确，这些残差应该是完全均匀分布的。这是一种美妙而直观的检查我们工作的方式，让模型反过来评估自身的合理性 [@problem_id:4949211]。

从一条简单的回归线出发，我们已经进入了一个拥有巨大能力和精妙之处的框架。广义[线性混合模型](@entry_id:139702)让我们能够拥抱现实世界的复杂性——其奇特的分布和聚类结构——并通过这样做，为我们试图解释的现象提供了更丰富、更细致的理解。它们让我们不仅能讲述关于平均值的故事，还能讲述关于变异的故事，并能从个体和群体的双重角度看世界。

