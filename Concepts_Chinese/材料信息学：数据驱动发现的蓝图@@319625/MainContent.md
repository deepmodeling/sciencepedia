## 引言
数个世纪以来，新材料的创造一直是一个缓慢而艰辛的过程，受直觉、机缘和艰苦实验的驱动。虽然这种方法为我们带来了从钢铁到硅等各种材料，但它已难以跟上现代技术对性质日益奇特和定制化的材料的需求。这一瓶颈带来了一个重大挑战：我们如何加速发现那些将定义我们未来的材料？

答案就在[材料科学](@article_id:312640)、[数据科学](@article_id:300658)和人工智能的[交叉](@article_id:315017)点上：一个被称为[材料信息学](@article_id:376250)的领域。这一强大的新[范式](@article_id:329204)将材料视为数据，利用机器学习以前所未有的规模和速度揭示隐藏的规律并预测性质。本文将作为这一革命性方法的指南。在接下来的章节中，您将了解到使其成为可能的基础方法。我们将首先探索“原理与机制”，深入研究如何将原子的物理世界转化为计算机的数字语言。然后，我们将考察激动人心的“应用与跨学科联系”，了解这些工具如何用于[高通量筛选](@article_id:334863)、[逆向设计](@article_id:318434)，甚至实现整个科学过程的自动化。

## 原理与机制

想象一下，你想教一台计算机成为一名[材料科学](@article_id:312640)家。你不能只是给它看一块金属然后说：“这很坚固。”计算机虽然功能强大，但却是一个极其遵循字面意义的“头脑简单者”。它只理解一样东西：数字。因此，我们首要且最根本的挑战，是发明一种新的语言，一种将材料丰富而复杂的世界——它的原子、[化学键](@article_id:305517)、结构——转化为机器可以处理的、冷冰冰的数字的方法。这种转化的行为，即为材料创建一张“数字身份证”，正是[材料信息学](@article_id:376250)的基石。

### 材料的语言：从原子到数字

那么，我们如何开始这种转化呢？让我们从关于化合物的最简单的一条信息开始：它的[化学式](@article_id:296772)。如果我们有一种材料，比如钒酸钠 $NaV_2O_5$，其[化学式](@article_id:296772)本身只是一串字母和数字。我们无法轻易地将其输入数学模型。我们需要将其转换成一个**特征**或**描述符**——一个或一组代表该材料的数字。

一个非常简单的想法是创建一个能够捕捉化合物“平均”化学特性的特征。我们可以选取每种元素的一个基本性质，比如它的**电负性**（衡量原子吸引电子能力的指标），然后根据其在化学式中的比例计算加权平均值。对于$NaV_2O_5$，我们有1个钠原子、2个钒原子和5个氧原子。我们可以查阅它们的电负性，按其原子分数（Na为$\frac{1}{8}$，V为$\frac{2}{8}$，O为$\frac{5}{8}$）进行加权，然后求和。瞧！我们就将一个复杂的化学配方提炼成了一个有意义的单一数字[@problem_id:1312295]。这个数字已经告诉了我们一些关于该材料整体电子特性的重要信息。

当然，材料并不仅仅是其各组分的“平均”。有时，信息不是一个连续的谱，而是一个离散的选择。例如，一个晶体可能属于“立方”晶系族，或“四方”晶系族，或“正交”晶系族。这些是类别，不是数字。我们如何转化一个类别呢？一个巧妙的技巧叫做**[独热编码](@article_id:349211)**。我们可以创建一个由0和1组成的小向量。如果我们有三种可能的晶系，比如（立方、正交、四方），我们可以用向量$\begin{pmatrix} 1 & 0 & 0 \end{pmatrix}$表示一个“立方”材料，用$\begin{pmatrix} 0 & 1 & 0 \end{pmatrix}$表示一个“正交”材料，用$\begin{pmatrix} 0 & 0 & 1 \end{pmatrix}$表示一个“四方”材料[@problem_id:1312310]。我们把一个词转换成了机器可以处理的数值表示，同时避免了无意中暗示某个类别比另一个“更大”或“更小”。通过组合许多这样的描述符——成分平均值、[独热编码](@article_id:349211)以及几十种其他描述符——我们就可以构建一个丰富的[特征向量](@article_id:312227)，一个能让我们的计算机学徒唯一识别材料的数字指纹。

### 捕捉原子的舞蹈：对称性的作用

通过“平均”成分来描述材料是一个很好的开始，但它忽略了一些至关重要的东西：几何构型。原子在三维空间中的[排列](@article_id:296886)方式——[晶体结构](@article_id:300816)——是区分石墨和金刚石的关键，尽管它们都是由纯碳构成的。要预测材料的性质，我们必须捕捉其结构。

但这引出了一个极其深刻的物理问题。物理定律不关心我们人为设定的任意惯例。一个水分子的能量是相同的，无论你将它旋转、在房间里平移，还是决定将氢原子'A'和氢原子'B'用不同的名称称呼。这就是**对称性**原理。我们构建的任何材料表示都*必须*尊重这些基本的对称性。否则，我们将迫使我们的模型从头开始重新学习基础物理定律——这是一项极其艰巨的任务。

我们如何创建一个自动具有对称性的结构指纹呢？考虑一种叫做**库仑矩阵**的分子描述方法[@problem_id:2838013]。其非对角元素$C_{ij}$代表原子$i$和原子$j$的原子核之间的静电排斥力。因为这取决于原子间的距离，所以如果我们平移或旋转整个分子，整个矩阵不会改变。这是一个很好的开始！但有一个问题：如果我们交换两个相同原子（比如两个氢原子）的标签，矩阵的行和列会互换，矩阵就变了！

在这里，数学提供了一个真正优雅的解决方案。虽然矩阵本身会变，但它的**[特征值](@article_id:315305)**——与任何方阵相关的一组特殊数字——却不会变！无论我们如何给原子编号，这组[特征值](@article_id:315305)都保持完全相同。它是一个“规范的”签名。因此，通过将库仑矩阵的[特征值](@article_id:315305)作为我们的特征，我们得到了一个既能捕捉三维结构，又自动对原子任意标记保持不变的数字指纹。这是一个绝佳的例子，说明我们找到了具有与我们想描述的物理现象相同对称性的正确数学对象。

这种匹配对称性的思想引导我们走向一个更强大、更精确的概念：**[等变性](@article_id:640964)**。想象一下要为一个原子体系预测两种不同的性质：它的总能量（一个标量）和每个原子上的力（一组矢量）。
- **能量**应该是**不变的**。如果你旋转原子体系，总能量必须保持完全相同。因此，对于一个从原子位置$X$预测能量的模型$E$，我们必须有$E(RX) = E(X)$，其中$R$是一个旋转操作。
- 然而，**力**是矢量，它们有方向。如果你旋转原子体系，力矢量应该随之旋转。这个性质被称为**[等变性](@article_id:640964)**。对于一个预测力的模型$F$，我们必须有$F(RX) = R F(X)$ [@problem_id:2838022] [@problem_id:2837945]。

请注意，整个体系的平移不改变原子间距离，因此它既不应改变能量，也不应改变力。力矢量只是旋转，它们不会被平移。将这些[不变性](@article_id:300612)和[等变性](@article_id:640964)规则直接构建到机器学习模型的架构中是一项重大突破。它确保了模型不仅仅是一个黑箱[模式匹配](@article_id:298439)器，而是一个内在地尊重物理世界基本对称性的工具。

### 从连接中学习：图的力量

到目前为止，我们将材料看作是数字列表（[特征向量](@article_id:312227)）或矩阵。但是有一种更自然的方式来看待分子或晶体：将其视为一个**图**，其中原子是节点，[化学键](@article_id:305517)是连接它们的边。这个视角为一类强大的模型——**[图神经网络](@article_id:297304) (GNNs)**——打开了大门。

GNN的核心思想非常直观：原子从其局部环境中学习。在网络的每一层，每个原子都从其相连的邻居那里“收集信息”。它获取其邻居当前的[特征向量](@article_id:312227)，将它们组合起来（例如，通过加权平均），然后利用这些聚合信息来更新自己的[特征向量](@article_id:312227)[@problem_id:90200]。

你可以把它想象成一个房间里的人们试图弄清楚房间的整体情绪。在第一轮中，你只知道自己的情绪和你直接邻居的感受。在第二轮中，你的邻居告诉你*他们*的邻居告诉了他们什么，所以两步之外的信息到达了你这里。经过几轮这样的“信息传递”后，每个人（或原子）都获得了包含整个房间（或分子）信息的丰富理解。这个过程让GNN能够通过从原子间的简单、局部相互作用开始，学习材料复杂的、全局的性质——这正与现实世界中化学和物理的运作方式完全一样！

### 公正评估的艺术：我们真的在预测未来吗？

我们现在已经设计了复杂的方法来表示材料，并构建模型来从中学习。假设我们构建了一个模型，用一千种已知材料对其进行了训练，而且它看起来效果非常好。我们如何知道它是真的“智能”，还是只是一个记住了考试答案的好学生？这个关于公正评估的问题，或许是整个事业中最关键——也最微妙——的部分。

想象一个研究小组拥有一个包含5000种不同铁-铬-镍族合金的数据集。他们想训练一个模型来预测合金的强度。他们做了看起来很标准的操作：他们将5000个数据点随机打乱，并留出1000个作为“[测试集](@article_id:641838)”。他们在剩下的4000个数据点上训练模型，并发现它在测试集上得分近乎完美。这是一项突破！但真的是吗？

致命的缺陷在于随机划分。由于该数据集是对Fe-Cr-Ni空间的系统性采样，训练集和[测试集](@article_id:641838)不可避免地包含成分极其相似的合金。例如，训练集可能有一种含$18.0\%$铬的合金，而测试集则有一种含$18.1\%$铬的合金。预测测试合金的强度不是一项科学发现的挑战；这是一种微不足道的[内插](@article_id:339740)行为。模型扮演的不是科学家的角色；它只是在两个非常接近的点之间画一条线 [@problem_id:1312298]。这是一种**[数据泄露](@article_id:324362)**，即关于“秘密”测试集的[信息泄露](@article_id:315895)到了训练过程中。

这引出了一个深刻的原则：**测试必须反映目标**。标准的随机划分，或称“i.i.d.”（独立同分布）划分，测试的是模型在已知数据分布内进行[内插](@article_id:339740)的能力。但在材料*发现*中，目标通常是**外推**——预测那些全新的、可能包含模型从未见过的元素或成分的材料的性质。

为了公正地评估模型用于此目的的能力，我们必须使用更严格的划分方式。例如，**成分划分**确保[测试集](@article_id:641838)中的所有材料都具有在[训练集](@article_id:640691)中完全不存在的化学成分[@problem_id:2837998]。这迫使[模型泛化](@article_id:353415)到新的化学空间区域。测试分数几乎肯定会比随机划分低，但它将是对模型真正发现能力的公正、因而也更有价值的衡量。

### 发现的基石：对优质数据的追求

我们讨论的一切——巧妙的表示方法、对称的模型、公正的验证——都建立在最后一个基础上：数据本身的质量。“垃圾进，垃圾出”这句古老的格言从未如此正确。如果我们的初始数据嘈杂、有偏见或错误，再多的机器学习魔法也无法拯救我们。

在[材料信息学](@article_id:376250)中，我们大部分的“基准”数据来自于大规模计算机模拟，最著名的是使用一种称为**[密度泛函](@article_id:361917)数理论 (DFT)** 的方法。但一次DFT计算并非一个能吐出单一真实数字的简单黑箱。它是一个复杂的多步骤计算实验，有许多参数需要科学家选择。每一个选择都是一种近似，都会影响最终结果。

为了确保计算是可复现的——以便另一位科学家，在另一个实验室，用另一台计算机，能得到相同的答案——我们必须一丝不苟地记录数据的**来源信息**。这份记录是一份长长的技术清单，但每一项都至关重要：模拟软件的确切版本；用于量子力学的具体近似（**[交换相关泛函](@article_id:302482)**）；我们简化原子的方式（**赝势**）；动量空间网格的分辨率（**[k点](@article_id:347930)网格**）；[基组](@article_id:320713)的完备性（**平面波截断能**）；以及我们距离“完美”解的接近程度（**收敛标准**）。即使省略其中任何一个细节，都可能导致无法以所需精度（例如，每原子$10^{-3}$ eV）复现结果，从而给我们数据集注入隐藏的噪声和不一致性[@problem_id:2838008]。

建立全面数据来源信息的文化不仅仅是一种良好的记账行为。它更是对[科学诚信](@article_id:379324)的承诺。正是这一点，将一堆数字转化为一个可靠、可复现、可信赖的基础，宏伟的机器学习驱动的[材料发现](@article_id:319470)大厦才能在其上建立起来。