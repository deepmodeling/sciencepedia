## 应用与跨学科联系

在上一章中，我们窥探了计算机的引擎室，发现了那些使 CPU [虚拟化](@entry_id:756508)成为可能的巧妙骗术——陷阱、模拟、hypercall。我们学习了 hypervisor 如何用一台机器的实体变幻出多台机器的幻象。但一个魔术的好坏取决于你用它来做什么。我们为什么要费尽周折去创造这些数字幽灵呢？

事实证明，答案是这个强大的幻象是构建现代计算大部分内容所依赖的基石。它不仅仅是一种便利；它是一种组织、保护和扩展计算资源的基本工具。现在，让我们踏上一段旅程，看看我们能用这种魔法建造出何等宏伟的建筑，从驱动我们数字生活的广阔数据中心，到计算意义的理论基础。

### 共享的艺术：云与数据中心

想象你是一座大型公共图书馆的建筑师。你拥有大量的书籍（计算能力），但有成千上万的读者（用户）都想同时阅读不同的书籍。你不能给每个人一个私人图书馆；那将是极其低效的。相反，你必须设计一个系统，让大家共享公共空间，确保每个人都感觉自己拥有所需的资源，而不会干扰他人。这正是[云计算](@entry_id:747395)提供商面临的挑战，而[虚拟化](@entry_id:756508)是他们的制胜法宝。

hypervisor 扮演着物理硬件的首席图书管理员。当多个虚拟机 (VM) 运行时，每个[虚拟机](@entry_id:756518)都有自己的一组虚拟 CPU (vCPU)，hypervisor 的调度器必须决定在任何给定时刻，哪个 vCPU 可以在真实的物理 CPU 内核上运行。一种天真的方法可能是给每个 vCPU 平等的轮换机会，但这并不公平。一个用户的 VM 可能只运行一个简单的进程，而另一个用户的 VM 可能运行着数百个。问题不在于对 vCPU 公平，而在于对*租户*——那些为机器特定份额付费的用户——公平。

这催生了像**比例共享调度**（proportional-share scheduling）这样的复杂设计 [@problem_id:3664883]。在这里，每个 VM 被分配一个权重，hypervisor 确保从长远来看，每个 VM 获得的 CPU 总功率份额与其权重成正比。这是一个强大的隔离概念：一个租户运行高要求工作负载的决定，不会超出 hypervisor 策略允许的范围窃取另一个租户的 CPU 周期。此外，一个好的调度器是**工作保守**的（work-conserving）。如果一个 VM 处于空闲状态（也许在等待用户输入），它分配的时间不会被浪费；hypervisor 会立即将那个空闲的物理核心重新分配给有工作要做的 VM。这种公平、隔离和效率的结合是云的经济引擎。

但这种宏大的共享幻象并非完美。在 VM 内部运行的客户机[操作系统](@entry_id:752937)从根本上是盲目的。它相信自己独占了其 vCPU。当 hypervisor 决定抢占一个 vCPU 让另一个 VM 运行时会发生什么？从客户机的角度来看，时间本身似乎冻结了。墙上的时钟在滴答作响，但它自己的世界却毫无进展。这种现象被恰如其分地命名为**窃取时间**（stolen time） [@problem_id:3689651]。

对于许多应用程序来说，这没问题。但对于一个对延迟敏感的数据库或视频会议应用来说，这种被窃取的时间可能是灾难性的。客户机[操作系统](@entry_id:752937)自己的调度器可能会看到一个需要紧急运行的任务，但它却无力执行，因为它的 vCPU 正在休眠，被 VMM 剥夺了调度。客户机的调度器甚至可能做出错误的决定，比如试图将[负载均衡](@entry_id:264055)到一个当前被窃取的 vCPU 上，导致线程饥饿。

我们如何修复这个“黑客帝国”中的小故障？我们打破第四面墙。通过**[半虚拟化](@entry_id:753169)**（paravirtualization），hypervisor 可以向客户机[操作系统](@entry_id:752937)发送一个微妙的信号——一声“耳语”，告知其 vCPU 的状态。客户机可以被确切告知被偷走了多少时间，或者收到一个提示，表明某个特定的 vCPU 当前未被调度。有了这些知识，一个“[半虚拟化](@entry_id:753169)感知”的客户机调度器可以做出更明智的决定。它可以避免将任务迁移到休眠的 vCPU，并校正自己的计时以维持其自身进程间的公平性。客户机和 hypervisor 之间的这种合作舞蹈是一个美丽的例子，说明了承认虚拟化层而不是假装它不存在，如何能导向一个更健壮、性能更佳的系统。

### 为速度和确定性而工程

虽然共享是[虚拟化](@entry_id:756508)的主要用例，但另一个前沿领域在于利用它来处理要求极致性能和可预测性的工作负载。这似乎有些矛盾——一个额外的软件抽象层怎么可能让事情变得更快？答案不在于原始速度，而在于控制、隔离和专门化设计。

考虑从 VM 内部通过网络发送数据包的简单行为。在一个纯模拟系统中，hypervisor 必须煞费苦心地模仿一个真实的物理网卡，比如老旧的 Intel `e1000`。每当客户机[操作系统](@entry_id:752937)试图与设备寄存器交互时，都会触发一次到 hypervisor 的陷阱，然后 hypervisor 会用软件模拟硬件会做的事情。这速度缓慢且产生大量开销，导致[网络延迟](@entry_id:752433)高且多变，即“[抖动](@entry_id:200248)”（jitter） [@problem_id:3668605]。

以 **VirtIO** 等技术为代表的[半虚拟化](@entry_id:753169)方法则要优雅得多。客户机和 hypervisor 不是模仿一个笨重的物理硬件，而是商定一个新的、流线型的、纯软件的接口。客户机驱动程序只需将数据放入一个共享内存队列，然后“拍一拍”hypervisor 的肩膀。这大大减少了客户机和 hypervisor 之间昂贵的“世界切换”（VM exits）次数，从而降低了延迟和[抖动](@entry_id:200248)。这就像是精心模拟一台蒸汽机的机械结构，与从头开始为其目的设计一台现代[电动机](@entry_id:268448)之间的区别。

对性能的追求延伸到虚拟化最苛刻的应用之一：**[实时系统](@entry_id:754137)**。在[工业自动化](@entry_id:276005)、电信或[算法交易](@entry_id:146572)等领域，错过最后期限不仅仅是性能缺陷，而是致命的失败。一个 VM 能否被信任去执行一个必须在，比如说，4 毫秒内完成的任务？[@problem_id:3689866]。对于一个标准的、以公平为导向的调度器来说，答案是否定的。一个同地部署的“批处理”VM 可能会饱和 CPU 并引入不可预测的延迟。

但如果我们正确配置系统，答案就会变成响亮的“是”。通过使用带有[实时调度](@entry_id:754136)器的**Type-1（裸金属）虚拟机监控器**，我们可以给予实时 VM 的 vCPU 严格的优先级和一个专用的物理核心。我们将该 VM 及其设备中断固定在该核心上，构建一个数字堡垒，将其与在其他核心上运行的批处理工作负载的混乱隔离开来。这使我们能够为最坏情况下的延迟提供数学上可证明的保证。这里的虚拟化不是为了共享，而是为了提供铁板一块的隔离。

最终的性能提升来自于使用 **SR-IOV** 等技术，让 VM 直接、无中介地访问物理硬件。这对于速度来说棒极了，但它给[虚拟化](@entry_id:756508)最神奇的特性之一——**实时迁移**（live migration）——带来了巨大的挑战。如果一个 VM 的触角已经缠绕在物理设备上，你怎么能在不停机的情况下将一个正在运行的 VM 从一个物理主机移动到另一个？你不能简单地复制它的内存，因为设备可能在同一时刻通过 DMA 积极地写入该内存，导致[数据损坏](@entry_id:269966) [@problem_id:3668579]。

解决方案是另一场优美的、合作的[半虚拟化](@entry_id:753169)舞蹈。hypervisor 向客户机驱动程序发送一个请求：“准备迁移。”驱动程序随后优雅地使设备静默——它停止提交新工作，等待所有在途操作完成，并撤销其 DMA 映射。只有在驱动程序确认设备已静默后，hypervisor 才会暂停 VM 并将其内存（现在已不受修改影响）传输到目标主机。这个复杂的协议甚至允许直接访问硬件的 VM 实现零停机维护和[负载均衡](@entry_id:264055)的圣杯。

### 机器中的幽灵：测量、安全与更深层的真理

虚拟化层虽然强大，但并非完全不可见。它的存在对安全性、测量，甚至我们对计算本身的理解都产生了微妙而深远的影响。

VM 内部的程序员如何测量其代码的性能？他们可能会使用处理器的性能监控单元 (PMU) 来计算 CPU 周期或缓存未命中等事件。但在一个[虚拟化](@entry_id:756508)的世界里，这些计数器是一个谎言——或者说，是一个精心构建的虚构。当一个 vCPU 被剥夺调度时，它的周期计数器必须被 hypervisor 暂停。当它被迁移到不同的物理核心时，缓存的状态会发生巨大变化。如果它通过[同时多线程](@entry_id:754892) (SMT) 与另一个 vCPU 共享一个核心，它们会争夺资源，从而夸大周期计数。从幻象内部观察系统的行为本身就被幻象的机制所扭曲 [@problem_id:3689902]。获得可靠的性能测量数据，要么需要一个几乎完全隔离的环境，要么需要一个能够解释这些扭曲并向客户机呈现一个修正后的“虚拟”PMU 的 hypervisor。

这种世界的分离也是安全的关键。CPU 不是唯一可以访问内存的角色。高性能设备使用直接内存访问 (DMA) 来直接读写数据，完全绕过 CPU。什么能阻止一个恶意的客户机对其网卡编程，以覆盖 hypervisor 或另一个 VM 的内存？CPU 的[页表](@entry_id:753080)在这里是无用的。答案是另一层硬件虚拟化：**[IOMMU](@entry_id:750812)（输入输出[内存管理单元](@entry_id:751868)）** [@problem_id:3658003]。

IOMMU 对于设备而言，就像 MMU 对于 CPU 一样。它位于设备和主内存之间，拦截每个 DMA 请求并执行自己的[地址转换](@entry_id:746280)。在一个虚拟化系统中，这实现了一种美丽的对称性。CPU 的访问经过两阶段转换（客户机虚拟地址 $\to$ 客户机物理地址 $\to$ 主机物理地址）。hypervisor 可以配置 [IOMMU](@entry_id:750812) 对设备访问做完全相同的事情！这确保了分配给 VM 的设备被限制在该 VM 的物理内存沙箱内，为抵御 DMA 攻击提供了坚固的防御。

虚拟化的应用超出了数据中心。在**[计算生物学](@entry_id:146988)**的世界里，一个试图复现 5 年前分析的科学家可能会发现，由于“依赖地狱”，所需的软件工具已无法在现代[操作系统](@entry_id:752937)上运行。解决方案是**容器化**，一种轻量级的[操作系统级虚拟化](@entry_id:752936)。像 [Docker](@entry_id:262723) 或 Singularity 这样的工具将应用程序及其精确的库依赖打包到一个自包含的环境中 [@problem_id:1463190]。这使得一个古老的软件能够在一个现代机器上完美运行，与最新的工具并存。在这里，虚拟化成为科学[可复现性](@entry_id:151299)的载体，是[科学方法](@entry_id:143231)本身的基石。

这把我们带到了最后一个深刻的观点。我们能够构建一个软件模拟器，在完全不同的 CPU 架构上运行来自另一种架构的程序，这不仅仅是一个巧妙的工程壮举。它是计算机科学中最深刻的思想之一——**[丘奇-图灵论题](@entry_id:138213)**（Church-Turing Thesis）和**[通用图灵机](@entry_id:155764) (UTM)** 存在性 [@problem_id:1405412] 的一个实际证明。UTM 是一台理论上的机器，可以模拟*任何其他*[图灵机](@entry_id:153260)。软件模拟器就是一台现实世界中的 UTM。它证明了所有[通用计算](@entry_id:275847)机，尽管其物理实现千差万别，但在计算能力上是根本等价的。

因此，[虚拟化](@entry_id:756508)不仅仅是一项技术。它是构建通用模拟器的艺术。它让我们能够将计算视为一种抽象的本质，可以与其执行的物理硅片分离。通过操纵这种抽象，我们可以构建比其物理对应物更高效、更安全、更灵活、更强大的系统。我们从一个巧妙的技巧开始这段旅程；我们以对计算本身普适性的反思结束它。