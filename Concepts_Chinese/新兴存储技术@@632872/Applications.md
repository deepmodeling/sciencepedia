## 应用与跨学科联系

在探索了赋予新兴存储器卓越特性的自旋、[相变](@entry_id:147324)和电阻丝的微观世界之后，你可能会问一个非常实际的问题：那又怎样？我们能用这些新玩具*做*什么？这是一个绝妙的问题，因为答案揭示了这些技术不仅仅是渐进式的改进——它们不仅仅是用来建造同样老房子的稍好一点的砖块。相反，它们提供了一种根本上全新的材料，一块新的画布，邀请我们——并且在许多情况下，迫使我们——重新思考计算的根本架构。当我们看到这些器件奇特的物理特性如何向上层层影响，从单个算法的设计到整个数据中心的架构时，这门科学的真正美才得以展现。

### 即时启动计算的曙光

让我们从最明显、或许也是最令人愉悦的承诺开始：告别等待。我们都感受过计算机启动或大型应用程序加载时的那种熟悉的乏味。这种延迟很大程度上是因为传统存储器，如用于缓存的[静态随机存取存储器](@entry_id:170500)（SRAM），是易失性的。它是个出色的短跑选手，但它完全失忆。每次你切断电源，它就忘记了它所知道的一切。当系统唤醒时，它的缓存是冷的、空的，迫使处理器缓慢地从慢得多的主存储中获取所有必要的指令和数据。对任何数据的第一次访问总是一次“[强制性未命中](@entry_id:747599)”——一次缓慢、沉重的仓库之旅。

但如果缓存不必遗忘呢？想象一个由非易失性技术，如[自旋转移矩](@entry_id:146992)MRAM（STT-MRAM）构建的末级缓存。当你关闭机器电源时，数据仍然存在，安全地嵌套在M[RAM](@entry_id:173159)单元的磁取向中。重启时，缓存已经是“热”的。处理器需要的大部分数据已经在那儿等着了。那些最初的、缓慢的[强制性未命中](@entry_id:747599)转变成了闪电般的缓存命中。当然，这并非完美简单；[操作系统](@entry_id:752937)可能已经移动了东西，一些缓存的数据可能已经过时，需要被丢弃。但即使在考虑了这些必要的整理工作之后，拥有一个持久性缓存所带来的性能增益也是巨大的，可以显著减少启动时间和应用程序启动延迟 [@problem_id:3638997]。这个简单的应用是迈向更宏伟旅程的第一步，这一旅程开始模糊快速、短暂的存储器和慢速、永久的存储之间古老的界线。

### 重新定义“好”软件：硬件协同设计的艺术

几十年来，计算机科学家们为编写高效软件制定了经验法则。一个算法的优雅程度通常由抽象的指标来评判，比如总操作数，而很少考虑操作的类型。但新兴存储器正在颠覆这种传统智慧。“最佳”算法不再是一个普适的真理；它深刻地依赖于其运行所在存储器的物理特性。

考虑[相变](@entry_id:147324)存储器（PCM）。正如我们所见，从PCM读取相对快速和高效。然而，写入则是另一回事。它需要熔化一小块硫系玻璃并进行淬火，这个过程比读取要慢几个[数量级](@entry_id:264888)，能耗也更高。这种读写成本之间的鲜明不对称性为软件设计者创造了一套新规则。想象你有两种[排序算法](@entry_id:261019)。算法A可能遵循经典的“分治”策略，涉及许多中间写入，总写入次数与 $n\ln(n)$ 成正比。算法B，也许在传统意义上不那么优雅，但其设计旨在最小化数据移动，导致写入次数仅与 $n$ 成正比。在传统系统上，性能差异可能微不足道。但在基于PCM的机器上，每次写入都带有沉重的能量税，算法B可能会压倒性地优越，仅仅因为它“写入感知”而消耗的功率要少得多 [@problem_id:3639004]。突然之间，程序员必须像物理学家一样思考，不仅要考虑他们代码的逻辑，还要考虑其底层硬件的能量景观。

当我们考虑到*持久性*的挑战时，软件和硬件之间的这种对话会变得更加深入。数据非易失是一回事，但要确保它已*安全*写入，能够在突然断电的情况下幸存下来，则是另一回事。为了保证这一点，软件必须发出特殊指令——一个 `flush` 指令将数据从处理器的缓存推送到持久性存储器，然后是一个 `fence` 指令以确保该 `flush` 确实已完成。可以把 `fence` 看作一个“世界停止”命令：处理器暂停，等待[内存控制器](@entry_id:167560)确认一切都安全无恙。

这些 `fence` 指令是一个强大的工具，但在性能方面也极其昂贵。如果一个更新图数据库的程序在每次微小的边修改后都发出一个 `fence`，系统将会陷入停顿。聪明的解决方案在生活中很常见：不要为每件小事都跑一趟。系统可以批量处理更新，而不是为每个更新单独设置 `fence`。它将若干更新收集在一个临时的、易失性的缓冲区中，然后一次性将它们全部写入持久性存储器，最后跟上一个单一的、分摊的 `fence`。这极大地提高了[吞吐量](@entry_id:271802)。同样的原则也适用于系统层面，例如当直接内存访问（DMA）引擎向NVRAM写入数据时；将许多小的写入合并成一个大的突发写入对于隐藏内存的固定延迟至关重要 [@problem_id:3634904]。当然，这引入了一个权衡：批量越大，如果在批量提交前发生崩溃，丢失的数据就越多。因此，系统设计者必须在性能和最大可接受的潜在数据丢失窗口之间仔细权衡 [@problem_id:3638912]。

### 构建可信的持久化世界

批量写入的能力是一种强大的优化，但它仅仅触及了为持久性存储器构建可靠软件这一挑战的皮毛。最根本的问题是原子性问题。现代处理器通常只能保证单个缓存行（例如，$64$字节）的写入是“原子的”——也就是说，在断电事件中，它要么完全完成，要么根本不发生。但如果我们的[数据结构](@entry_id:262134)，比如说[哈希表](@entry_id:266620)中的一个条目，比一个缓存行大呢？或者如果更新一个逻辑对象需要修改内存中的两个不同位置呢？如果电源在第一次和第二次写入之间失效，我们的数据就会处于损坏、不一致的状态。

为了防止这种情况，程序员必须采用[崩溃一致性](@entry_id:748042)协议，这些协议通常改编自数据库领域。一种常见的技术是重做日志（redo logging）。在更改其实际位置的数据（“原位”更新）之前，程序首先将意图更改的记录写入一个单独的日志。只有在日志条目安全地持久化之后，它才执行原位写入。如果发生崩溃，恢复例程可以扫描日志并重新应用（或“重做”）任何未完成的更改。

这提供了安全性，但代价惊人。这个代价被称为**写放大**。让我们追踪一次对48字节用户数据的单个小更新。首先，程序写入一个80字节的日志条目。因为硬件的原子单元是64字节的缓存行，这个“小”写入实际上强制物理写入了两个完整的缓存行，即 $128$ 字节。然后，程序更新96字节的哈希桶本身，这又需要两次缓存行写入，即另外的 $128$ 字节。最后，它写入一个微小的8字节提交标记，这仍然消耗了一整个64字节的缓存行写入。总共，为了逻辑上更新仅仅 $48$ 字节的数据，我们已经向内存物理写入了 $128 + 128 + 64 = 320$ 字节！[@problem_id:3638976]。这种接近 $7 \times$ 的写放大不仅降低了系统速度，更关键的是，它会更快地磨损内存，因为像PCM和ReRAM这样的技术具有有限的写入耐久性。

显然，我们需要系统各个角落的帮助。这就是工具链——我们的编译器和链接器——可以发挥英雄作用的地方。一个智能的编译器可以分析程序，识别出要写入持久性存储器的操作，并自动重新[排列](@entry_id:136432)和聚集它们。通过将对同一缓存行的写入组合在一起，它可以消除冗余的物理写入。这种技术，称为[写合并](@entry_id:756781)，可以显著降低写放大因子，直接提高性能和内存设备的使用寿命，而所有这一切都不需要应用程序员费心 [@problem_id:3638973]。

持久性的影响一直延伸到[操作系统](@entry_id:752937)，我们软件世界的基石。[操作系统](@entry_id:752937)管理着一个至关重要的数据结构，称为页表，它将程序使用的虚拟内存[地址转换](@entry_id:746280)为硬件的物理地址。如果这个[页表](@entry_id:753080)驻留在持久性存储器中，它也必须是崩溃一致的。[操作系统](@entry_id:752937)设计者随后必须在不同的一致性机制之间评估复杂的权衡，例如日志记录（记录更改）与影子复制（创建一个带有更改的全新副本，然后原子地切换指针指向它）。每种策略都有不同的性能开销，以完成存储、刷新和屏障等复杂操作所需的数百个处理器周期来衡量 [@problem_id:3639010]。

### [混合系统](@entry_id:271183)的宏大交响

我们已经看到，没有哪一种单一的存储技术是万能的银弹。D[RAM](@entry_id:173159)速度快但易失且耗电。MRAM提供出色的速度和耐久性，但密度较低。PCM密度极高，非常适合大容量存储，但写入速度慢、能耗高且耐久性较低。Re[RAM](@entry_id:173159)则处于中间地带。

那么，为什么只选择一种呢？高性能计算的未来不是单一的，而是一场异构的交响乐。最复杂的系统将由多层不同技术的[存储层次结构](@entry_id:755484)构成，为系统架构师提供了一系列选择。于是，宏大的挑战就变成了一个布局问题：哪些数据应该放在哪个层级？

答案再次在于理解工作负载。频繁写入的数据不适合PCM，但可能非常适合D[RAM](@entry_id:173159)或耐久性强的M[RAM](@entry_id:173159)。主要被读取的数据，如大型静态数据库，可以非常经济高效地存储在高密度PCM上。一个智能的[运行时系统](@entry_id:754463)可以分析不同[数据块](@entry_id:748187)的读/写比率，并将它们迁移到最合适的层级，从而动态优化整个系统以获得最大吞吐量 [@problem_id:3638926]。

我们甚至可以设想能够自行学习和适应的系统。随着工作负载随时间变化，它们的内存访问模式也会改变。这为控制理论和人工智能领域开辟了有趣的联系。人们可以设计一个智能软件代理，也许使用强化学习，它不断监控访问模式并做出动态分层决策。它的“状态”可能包括数据块的访问频率和写入强度，其“奖励”函数将被设计为惩罚高延迟、过度能耗和设备磨损。这样的系统将随着时间的推移，学会针对任何给定工作负载的最佳布局策略，成为一个自我优化的[内存管理](@entry_id:636637)器 [@problem_id:3638913]。

最终，设计一个现代存储系统是一个优美的、多变量的[优化问题](@entry_id:266749)。架构师面对一组组件，每个组件都具有独特的延迟、能耗和耐久性特征。然后，他们必须将这些组件组装成一个连贯的系统，并根据一个权衡这些竞争因素的[成本函数](@entry_id:138681)来评估它。“最佳”设计并非绝对；它完全取决于系统的目标。移动设备可能会优先考虑低能耗以最大化电池寿命，而科学计算集群可能会将原始速度置于一切之上。通过将每种技术的物理特性代入一个整体模型，架构师可以探索这个广阔的设计空间，并找到能够为他们的特定需求达到完美平衡的配置 [@problem_id:3638960]。

从即时启动笔记本电脑的简单便利，到分层数据中心的复杂AI驱动管理，新兴存储技术是整个技术栈创新的催化剂。它们挑战我们旧有的假设，并以一种更丰富、更细致、最终更强大的方式回报我们，以构建未来的计算机。