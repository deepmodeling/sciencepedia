## 引言
在几乎所有科学探究领域，从医学到生态学，我们都对[时间问题](@article_id:381476)着迷：患者多久才能康复？一个机器零件能用多久？一个细胞多久分裂一次？虽然这些问题很简单，但现实往往使数据收集变得复杂。研究有终期，研究对象会搬走，外部因素会介入。我们常常只能得到不完整的故事——在这些观测中，我们知道某个事件尚未发生，但我们无法再继续等待它发生的那一刻。这就带来了一个根本性的分析挑战：我们如何从一个充满这些“半截故事”的数据集中得出有效的结论？丢弃这些不完整或“[删失](@article_id:343854)”的数据是一种浪费，而草率地处理它们则会产生严重的误导。

本文旨在通过探索为解决此问题而设计的统计框架——[生存分析](@article_id:314403)——来填补这一知识空白。这一整个领域的力量和有效性都建立在一个关键的假设之上，即非信息性[删失](@article_id:343854)。理解这个概念是从不完美的真实世界数据中解锁真实洞见的钥匙。在接下来的章节中，您将学习这一关键假设的基本原理。“原理与机制”一章将解构[删失](@article_id:343854)的概念，解释非信息性删失与信息性删失之间的关键区别，并揭示像 Kaplan-Meier 估计量这样的方法如何巧妙地将完整和不完整的数据结合在一起。随后，“应用与跨学科联系”一章将展示这些概念在现实世界中的广泛用途，阐明在遗传学、[公共卫生](@article_id:337559)和[细胞生物学](@article_id:304050)等不同领域，承认我们的未知是迈向真正知识的第一步。

## 原理与机制

想象你是一位研究时间的科学家。不是爱因斯坦宇宙意义上的时间，而是更贴近生物学意义上的时间：毛毛虫变成蝴蝶所需的时间，病人从疾病中恢复所需的时间，或者一个新的基因编辑细胞分裂所需的时间。在完美的世界里，你会手持秒表，观察每一个研究对象，直到感兴趣的事件发生。你会收集到一组漂亮、完整的时间数据。

但现实世界是混乱的，充满了各种中断。你的实验有预算，必须在三个月后结束，这使得一些毛毛虫仍然是毛毛虫。一个病人搬到了另一个国家。一批细胞被污染，必须丢弃。在所有这些情况下，你的观察都被迫中断了。你知道故事并没有结束，但你无法再继续观察它的发展。你该如何处理这些信息？这正是[生存分析](@article_id:314403)旨在解决的核心问题。

### 不完整故事的问题：[右删失](@article_id:344060)

让我们思考一项针对新药 “CardioGuard” 的[临床试验](@article_id:353944)，该药物旨在预防心脏病发作。你对 1000 名患者进行了为期五年的随访。不幸的是，一些患者心脏病发作了，你记录下了它发生的确切日期。对于你的研究目的而言，他们的故事是完整的。

但其他人呢？许多患者会安然无恙地完成五年的研究。对他们来说，“到心脏病发作的时间”是未知的，但你知道一些非常有价值的信息：这个时间*至少*是五年。其他人可能会因为在海外找到新工作而在两年后退出研究。对他们来说，你知道他们到心脏病发作的时间*至少*是两年。这种不完整的数据，即我们只知道事件发生在我们最后一次观察*之后*，被称为**[右删失](@article_id:344060)** ([@problem_id:1961444])。

认为这些数据无用是一个常见的错误。我们应该扔掉它吗？绝对不该！那就像扔掉大量人群在五年内保持健康的事实一样。我们应该假装研究在他们最后一天结束，并将他们标记为“无事件”吗？那也是错误的；你不能假设一个健康了两年的​​人会永远保持健康。

真正的洞见在于，[删失数据](@article_id:352325)并非*缺失*数据；它是*部分完整*的数据。它为事件发生的时间提供了一个下限。[生存分析](@article_id:314403)就是一门艺术，它将这些不完整的故事与完整的故事编织在一起，以尽可能准确地重建整个群体的经历图景。无论我们研究的是病人，是在变成青蛙之前被捕食者吃掉的蝌蚪的变态过程([@problem_id:1911744])，还是在损坏前就停止使用的机器的故障时间，同样的逻辑都适用。观察被[删失](@article_id:343854)是因为真实的事件时间 $T$ 是未知的；我们只知道它大于或等于[删失](@article_id:343854)时间 $C$。

### 根本法则：删失是无辜的旁观者吗？

现在，为了让这些统计方法发挥其魔力，我们必须遵守一个根本法则。删失的原因必须是一个与我们研究的事件无关的**无辜旁观者**。用统计术语来说，这就是**非信息性删失**的假设。它意味着[删失](@article_id:343854)行为本身没有为我们提供关于研究对象未来发生事件的任何线索。

回到我们的 CardioGuard 试验。如果一个病人因为研究在五年期满时结束（这被称为**管理性删失**）而被删失，或者因为他们为工作搬家，或者不幸地在与心脏状况无关的交通事故中丧生，这些事件很可能与他们潜在的心脏病发作风险无关。这就是非信息性删失，我们的方法可以很好地处理它。[@problem_id:1961472]

但如果[删失](@article_id:343854)并非那么无辜呢？想象一个场景，在一项针对某种使人衰弱的疾病的试验中，患者感觉自己的病情正在迅速恶化。实验性药物有严重的副作用，所以他们决定退出研究以寻求安宁疗护。这种退出行为（[删失](@article_id:343854)）与他们糟糕的预后直接相关。病情越重的人越有可能退出。这就是**信息性删失** [@problem_id:1925063]。

如果我们把这当作非信息性[删失](@article_id:343854)来处理，我们就在系统性地从分析中移除那些结局最差的人。研究中余下的患者平均看起来会比他们实际情况更健康。我们的分析会因此对药物的有效性产生一个过于乐观的估计，使其看起来比实际效果更好。这就像在让所有挣扎的学生在期末考试前退学后，再来评判一所学校的教学能力。非信息性[删失](@article_id:343854)的假设不是一个小小的技术细节；它是一次有效[生存分析](@article_id:314403)的基石。

### 读懂言外之意：[生存分析](@article_id:314403)的逻辑

那么，我们实际上是如何将完整和不完整的故事结合起来的呢？**Kaplan-Meier 估计量**是实现这一目标的最优雅的工具之一。Kaplan-Meier 方法不试图计算一个“平均”时间——这在有[删失数据](@article_id:352325)的情况下是不可能的——而是采用了一种更巧妙的、循序渐进的方法。

把时间看作一系列的瞬间。只有当一个事件（比如疾病复发）发生时，估计量才会做任何事情。在那个确切的时刻，它会停下来问一个简单的问题：“在这一刻之前仍在研究中的所有人——即**风险集**——中，刚刚发生事件的比例是多少？” 如果有 100 人处于风险中，其中 2 人发生了事件，那么瞬时失败率是 $2/100$，生存率是 $98/100$。

那么，存活到任意时间 $t$ 的总概率就是到 $t$ 为止发生的所有事件的瞬时[生存概率](@article_id:298368)的乘积。如果你在第一天存活的概率是 $0.99$，在第二天（假设你活过了第一天）存活的概率是 $0.98$，那么你在这两天都存活的概率就是 $0.99 \times 0.98$。Kaplan-Meier 估计正是将这个逻辑扩展到整个研究期间。

那么[删失数据](@article_id:352325)是如何融入其中的呢？当一个病人被删失时（比如说，他们搬走了），他们对风险集的贡献一直持续到他们离开的那一刻。他们提供了“存活”了那么久的宝贵信息。在他们被[删失](@article_id:343854)之后，他们就从所有*未来*的计算的风险集中被悄悄地移除了。他们不被算作事件，但他们正确地减小了下一步计算的分母。

这就是为什么更简单的方法会失败。你不能只用线性回归来预测时间，因为对于被[删失](@article_id:343854)的病人，你不知道真实的时间。你也不能使用简单的[二元分类](@article_id:302697)器（复发 vs. 未复发），因为它将一个无事件存活一个月的病人和一个无事件存活十年的病人同等对待，并且它错误地假设被[删失](@article_id:343854)的病人*永远*不会发生事件。[生存分析](@article_id:314403)通过正确地整合删失的观察结果，是唯一尊重数据中全部信息的方法 ([@problem_id:1443745])。

### 边际的危险：尾部的不确定性

Kaplan-Meier 方法很强大，但它不是魔法。其估计的质量取决于你输入的数据。考虑一下在一个长期研究的[后期](@article_id:323057)会发生什么。随着时间的推移，越来越多的人要么发生了事件，要么被[删失](@article_id:343854)。风险集——仍在被随访的人数——逐渐减少。

当你基于 1000 人计算一个比例时，结果是相当稳定的。但如果你的风险集已经缩小到只有五个人呢？如果其中一个人发生了事件，该时间点的[生存概率](@article_id:298368)将骤降 $20\%$。估计变得非常不稳定，就像暴风雨中的小船。这就是为什么 Kaplan-Meier 估计的方差在分布的“尾部”会急剧增加。在图上，你会看到生存曲线周围的[置信区间](@article_id:302737)向外膨胀，警告你这个区域的估计不太精确 ([@problem_id:1925065])。

此外，[生存分析](@article_id:314403)无法预见未来。如果一个研究的设计包含一个硬性终止的删失机制——例如，所有观察都在时间 $\tau_C$ 或之前被[删失](@article_id:343854)——那么我们就无法估计任何时间 $t > \tau_C$ 的[生存概率](@article_id:298368) $S(t)$。Kaplan-Meier 曲线在最后一次观察到的事件时间之后会变平，因为它没有超出该点的信息。估计量“卡在”它最后已知的值上，无法说明接下来会发生什么。它可以一致地估计到其可观察世界边缘的生存率，但无法超越 ([@problem_id:1909349])。

### 岔路口：当事件相互竞争时

最后，我们来到了这个领域中最微妙和最美妙的概念之一：**[竞争风险](@article_id:352378)**。让我们回到我们的蝌蚪，它们要么变态（感兴趣的事件），要么被吃掉（竞争事件）。[@problem_id:1911744] 一位参加癌症试验的老年患者可能会癌症复发，也可能会死于中风。中风和癌症复发是相互竞争的事件；一旦一个发生，另一个就不可能发生。

我们应该如何处理死于中风的病人？一个幼稚的方法是把他们当作删失处理。这似乎合理，但我们实际上在回答什么问题呢？通过将因中风死亡视为[删失](@article_id:343854)，我们实际上是在一个假设的世界里估计癌症复发的概率，在这个世界里，病人是不朽的，不会死于其他原因。这个量与**特定原因风险**有关，对于理解癌症在孤立状态下的纯粹“病因学”力量很有用 ([@problem_id:2811951])。这是一个生物学家的问题。

但是病人或医生可能会问一个不同的、更实际的问题：“在充满各种风险的现实世界中，我到明年癌症复发的实际概率是多少？” 为了回答这个问题，我们不能忽视一些病人会被中风这一[竞争风险](@article_id:352378)永久地从观察队列中移除。这里的正确工具是**累积发生函数 (CIF)**，它计算在所有其他竞争事件存在的情况下，特定事件发生的概率。

至关重要的是，幼稚的“删失”方法几乎总是高估目标事件的真实世界概率。它预测的癌症复发几率会比实际观察到的要高，因为它没有考虑到一些*本会*复发的病人，却因为竞争事件而被移出了人群 ([@problem_id:1911778])。

这导致了两种不同的风险模型。一个针对特定原因风险的模型继续使用一个只包含存活且无事件者的风险集。但是一个针对 CIF 的模型（如 Fine-Gray 模型）则使用了一个巧妙的技巧：例如，它用于癌症复发的风险集不仅包括那些无事件的个体，还包括那些已经死于中风的个体 ([@problem_id:2811951])。这可能看起来很奇怪——一个已故的人怎么会有风险呢？但这是一种数学构造，其目的是正确估计真实世界的概率 $P(\text{event by time } t)$，而不是瞬时的生物学作用力。

理解你问的是哪个问题——是关于孤立风险的机理问题，还是关于真实世界结局的预后问题——是驾驭这个迷人而强大的[生存分析](@article_id:314403)世界的最后一把钥匙。