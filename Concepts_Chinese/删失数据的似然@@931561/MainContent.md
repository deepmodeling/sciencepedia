## 引言
处理不完整信息是数据分析中一个普遍的挑战。其中一种尤为常见且棘手的形式是**删失数据**，即我们知道事件发生在某个时间范围之外，但不知道确切的发生时刻。从确定药物疗效的临床试验，到工程师评估产品寿命，删失观测值的存在是常态，而非例外。这带来的关键问题是，处理这[类数](@entry_id:156164)据的直观或简单化方法，如忽略数据或替换为人工值，总是会导致有偏倚的结果和错误的结论。本文旨在通过介绍一个强大而可靠的统计框架，揭开[删失数据](@entry_id:173222)分析的神秘面纱。在接下来的章节中，我们将首先探讨基础的“原理与机制”，详细说明为何简单的修正方法会失败，以及[最大似然](@entry_id:146147)原理如何提供一个稳健而精妙的解决方案。随后，我们将在“应用与跨学科联系”部分拓宽视野，了解这个强大思想如何统一从医学到制造业等不同领域的分析方法。

## 原理与机制

想象你是一位研究新型灯泡的科学家，目标是确定其平均寿命。你取来一百个全新灯泡，打开开关，并启动计时器。几周后，一些灯泡烧坏了，你尽职地记录下了它们的确切寿命。但一个月后，你的经费耗尽，不得不停止实验。此时，仍有七十个灯泡在亮着。你该如何处理它们？你收集了一系列故事，但其中大部分都未完结。这就是**删失数据**的本质，一个在工程学、经济学乃至决定新药安全性和有效性的临床试验中无处不在的问题。

### 简单修正的诱惑（及其失败原因）

我们的第一反应可能是直接忽略那七十个仍在工作的灯泡。毕竟，我们没有它们完整的寿命数据。但想一想这意味着什么。我们将把整个结论建立在最早失效的那三十个灯泡上。这好比仅通过观察第一年就出故障的汽车来评判一个车型的好坏。我们将不可避免地错误得出结论：这些灯泡的耐用性远低于实际情况。这是一个典型的**选择偏倚**例子。

那么，还有其他办法吗？也许我们可以“保守”一点，直接将研究结束时间——一个月——作为那七十个幸存灯泡的寿命。这似乎更可靠，因为我们纳入了所有研究对象。但这种方法同样存在严重缺陷。我们假装所有七十个灯泡都在我们关灯的那一刻同时失效。事实上，其中一些可能还能再用一天，另一些则可能再用一年。通过在一个月这个节点人为地堆积“失效”事件，我们扭曲了事实。在医学背景下，这种错误可能是灾难性的。如果我们研究的是一种救命药物，这种朴素的替代方法会人为缩短数据集中许多患者的生存时间，从而使药物看起来效果不佳 [@problem_id:4568876]。分布的尾部——即长期幸存者——被被人为地拉向中心，这可能导致我们低估药物真正的长期益处。

这些简单的修正方法，尽管诱人，但终究是失败的，因为它们没有忠实地反映我们实际拥有的信息。它们要么丢弃了有价值的信息，要么凭空捏造了我们没有的信息。要解开这个谜题，我们需要一个更深刻的原则，一个根植于我们真实观测的原则。

### 一个忠于事实的原则：我们所见事件的似然

突破口源于统计学中一个简单而强大的思想：**似然原理**。我们不是去操纵数据以适应简单的公式，而是构建一个能准确描述我们实际所收集数据的公式。我们会问：在给定某种世界模型的情况下，观测到我们实验中出现的确切结果集的概率——即似然——是多少？然后，我们寻找能使我们观测到的现实显得尽可能“像”真的模型参数。这就是**最大似然估计 (MLE)** 方法。

这如何应用于我们的灯泡问题呢？我们需要写下我们特定观测集的似然。关键在于根据我们已知的信息，区别对待两种不同类型的观测值。

1.  **对于我们观测到的事件（灯泡烧坏）：** 对于三十个失效的灯泡，我们知道它们确切的失效时间，记为 $t$。这个灯泡对总似然的贡献是在该特定瞬间失效的概率*密度*。我们可以用一个函数 $f(t)$ 来表示，它告诉我们在任意时间 $t$ 失效的相对可能性。

2.  **对于被删失的观测值（灯泡仍在工作）：** 对于在研究结束时间 $T_c$ 时仍在发光的七十个灯泡，我们观测到了什么？我们没有观测到失效，而是观测到了*生存*。我们确切知道它的真实寿命*大于* $T_c$。因此，它对似然的贡献是这一事件发生的总概率。这就是**生存函数** $S(T_c)$，定义为真实失效时间 $T$ 大于 $T_c$ 的概率，即 $S(T_c) = \Pr(T \gt T_c)$。

我们实验的总似然就是所有一百个灯泡各自贡献的乘积。我们可以用一种极为简洁优美的方式来书写。让我们创建一个小开关，即指示变量 $\delta_i$：如果观测到灯泡 $i$ 发生事件，则 $\delta_i$ 为 1，如果被删失，则为 0。那么，在时间 $t_i$ 观测到的灯泡 $i$ 的似然贡献为：

$$
L_i = [f(t_i)]^{\delta_i} [S(t_i)]^{1-\delta_i}
$$

当灯泡失效时，$\delta_i=1$，其贡献为 $f(t_i)$。当它幸存时，$\delta_i=0$，其贡献为 $S(t_i)$。所有 $n$ 个灯泡的总似然是它们的总乘积 $\prod_{i=1}^{n} L_i$。这个单一的表达式是现代生存分析的基石。它忠实地使用了所有数据而未加扭曲，完美地捕捉了来自事件和非事件的信息 [@problem_id:4550963]。

### 付诸实践：一个简洁而优美的结果

让我们看看这个原理在实践中的应用。一个常见的失效时间模型是**[指数分布](@entry_id:273894)**，它适用于从放射性衰变到客户订阅等多种场景。该模型假设失效率 $\lambda$ 是恒定的。对于此模型，[概率密度函数](@entry_id:140610)为 $f(t; \lambda) = \lambda \exp(-\lambda t)$，生存函数为 $S(t; \lambda) = \exp(-\lambda t)$。

让我们想象一个流媒体服务公司研究为期一年的客户忠诚度。一些客户取消了订阅（事件），而另一些客户在年底时仍处于订阅状态（删失）。如果我们将指数函数代入似然公式，进行一些代数运算，并找到使结果最大化的 $\lambda$ 值，就会发生一些奇妙的事情 [@problem_id:1902760]。失效率的[最大似然估计量](@entry_id:163998) $\hat{\lambda}$ 结果是：

$$
\hat{\lambda} = \frac{\text{Total number of events observed}}{\text{Total time observed for all subjects}}
$$

这是一个极其直观和优美的结果 [@problem_id:5228308]。失效率的最佳估计值就是我们实际观测到的比率！如果在总共 500 个客户-年的观察期内有 10 个客户取消订阅，我们对取消率的最佳猜测是每年 $10/500 = 0.02$。分母正确地包含了忠诚的、被删失的客户的全年观察时间，以及那些已取消订阅客户的较短观察时间。应用于我们所观测事实的忠实表述的最大似然数学机制，给出了一个完全合乎情理的答案。

### 这是作弊吗？为何我们能信任这个答案

一个持怀疑态度的人可能仍会想，我们是不是在投机取巧。基于不完整数据的估计怎么会可靠呢？关键的洞见在于，我们构建的[似然函数](@entry_id:141927)是我们所拥有观测值的一个*有效的概率模型*。因此，[数理统计](@entry_id:170687)的强大定理为我们提供了支持。这些定理保证，在一些合理的“正则性”条件下（例如模型是可识别且表现良好的），[最大似然估计量](@entry_id:163998)是**一致的** [@problem_id:1895937]。

一致性意味着，随着我们收集越来越多的数据——即使其中一大部分是[删失数据](@entry_id:173222)——我们的估计值 $\hat{\lambda}$ 也会收敛于 $\lambda$ 的唯一[真值](@entry_id:636547)。由删失造成的信息损失没有被忽略，而是被正确地纳入了考量。我们甚至可以使用更高级的工具，如**[费雪信息](@entry_id:144784)**，来精确计算我们的删失样本中包含了多少关于某个参数的“信息” [@problem_id:3892848]。虽然与完整数据集相比，删失确实减少了信息量，但这种分析方法精确地告诉了我们还剩下什么可以利用，从而消除了猜测。这就是有原则的方法之美：它将一个令人困惑的数据问题转化为一个具有可信答案的、良定的数学问题。

### 明确定义：并非所有“缺失”数据都一样

当我们将删失与其他类型的不完整数据区分开来时，似然方法的威力就变得更加清晰。在这里，用词很重要，统计学家对此非常精确。

首先，考虑**删失 (censoring) 与截断 (truncation) 的对比**。想象一个生物标志物的实验室检测，它无法测量低于某个限值 $L$ 的浓度 [@problem_id:4990403]。如果我们测试一组患者，其中一些人的结果是“低于[定量限](@entry_id:195270)”，这就是**[左删失](@entry_id:169731)**。我们知道这些患者存在，并且我们掌握了关于他们的信息：其真实值位于区间 $(0, L)$ 内。其似然贡献是该事件的概率 $P(Y \lt L)$，也就是[累积分布函数](@entry_id:143135) $F(L)$ 的值。

现在想象一个不同的场景。我们正在进行一项研究，但只招募生物标志物水平*高于* $L$ 的患者。在这种情况下，我们甚至不知道那些水平较低的人的存在；他们完全不在我们的数据集中。这就是**左截断**。对于我们观测到的数据，我们是从一个修正后的分布中抽样的——即以数值高于 $L$ 为条件的人群原始分布。这意味着我们对一个观测值的似然必须进行重新缩放：其贡献是密度 $f(x)$ 除以其首先被纳入研究的概率 $P(Y \ge L)$。混淆这两种情况并使用错误的似然函数会导致显著的偏倚。

其次，区分**删失与一般性缺失数据**至关重要 [@problem_id:4816953]。删失观测值并非像遗忘的问卷答案那样“缺失”。一个删失的事件发生时间是一个*不等式*。知道一个患者在最后一次随访时间 $C_i$ 时仍然存活，意味着我们知道其真实生存时间大于 $C_i$。这是具体而有价值的信息。标准的生存分析方法通过生存函数 $S(C_i)$ 巧妙地整合了这一不等式信息。相比之下，像“[多重插补](@entry_id:177416)”这类为真正缺失值设计的方法，会试图用具体数值来“填补”删失时间。这通常是不恰当的，因为它抛弃了不等式所包含的确定性信息，并假装我们拥有比实际更多的信息，可能导致结果偏倚和虚假的[精确度](@entry_id:143382)。

### 一个简单思想的普适力量

这个核心原理——为观测到的事件构建基于密度的似然，为删失的观测值构建基于生存（或累积）概率的似然——不仅仅是解决简单问题的巧妙技巧。它是一个普适而强大的思想，构成了某些最复杂科学领域分析的基石。

-   在现代药理学中，**非线性混合效应模型**被用于理解药物浓度在不同患者群体中随时间的变化。这些模型极其复杂，考虑了个体间的变异性。然而，当血样中的药物浓度低于[定量限](@entry_id:195270)（BLQ）时，处理该问题所用的正是同一个原理：该 BLQ 样本的似然贡献是真实浓度低于该限值的概率，而这个概率由模型的预测推导得出 [@problem_id:3920780]。

-   在许多医学研究中，研究人员使用 **Cox [比例风险模型](@entry_id:171806)**。这个卓越的半参数方法允许人们在不对风险率如何随时间变化做强假设的情况下，估计协变量（如治疗或基因表达水平）对[风险率](@entry_id:266388)的影响。它通过“部分似然”来实现这一点，这是似然原理的一个巧妙变体。在每个事件发生的时间点，它考虑的是事件发生在特定失效个体身上的概率，相对于当时所有处于风险中的其他个体。被删失的个体至关重要：他们不贡献于分子，但在被删失之前，他们是分母（“风险集”）的重要组成部分 [@problem_id:4550963]。

归根结底，对[删失数据](@entry_id:173222)的统计处理是一个关于[科学诚信](@entry_id:200601)的优美故事。它关乎承认我们知识的局限，并建立一个精确尊重这些局限的数学框架。通过抵制简单但错误修正方法的诱惑，我们开启了一种不仅优美直观，而且稳健、可信、灵活的方法，足以在整个科学和工程领域推动发现。

