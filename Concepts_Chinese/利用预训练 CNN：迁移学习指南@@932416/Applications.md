## 应用与跨学科联系

想象一下，教一个人成为世界一流的放射科医生。你会从教他们识别基本形状和颜色开始吗，就像孩子学习一样？当然不会。你会从一个已经拥有完全发育的[视觉系统](@entry_id:151281)、一个已经能看见并理解日常世界的人开始。你是在教他们将现有的视觉智能应用到一个新的、专门的领域。这，本质上，就是使用预训练卷积神经网络 (CNN) 背后深刻而强大的思想。一个预训练网络就像一个已经学会了“看”的合成视觉皮层。我们的任务只是教它新技能。

这个被称为**[迁移学习](@entry_id:178540)**的原则，不仅仅是一个学术上的好奇心；它是推动应用科学和工程领域革命的引擎。像 VGG 或 [ResNet](@entry_id:635402) 这样的预训练网络，通过在数百万张互联网照片上训练，已经学习了一套丰富的[特征层次结构](@entry_id:636197)。它数百万的参数已经调整好，可以检测边缘、纹理、形状和物体部件。当一个系统生物学实验室想要对[电子显微镜](@entry_id:161660)图像中的细胞器进行分类时，他们不需要从头构建一个视觉系统。相反，他们可以拿来这个预训练的“视觉皮层”，冻结其庞大的现有知识网络，然后只需在顶部附加一个小的、新的“决策中心”。这个新部分可能只有几百万个可训练参数，只占整体的一小部分。通过只训练这个新的头部，他们是在教网络一个新任务——识别线粒体而不是猫——而无需改变其基本的视觉能力。这种效率是惊人的：我们利用了价值数千万参数的已学知识，却只训练了其中的一小部分，从而用少得多的数据和计算量取得了卓越的成果[@problem_id:1423370]。

### 适应的艺术与科学

当然，现实世界很少如此简单。来自特定领域的图像通常说着一种与 CNN 成长时所见的自然照片不同的“语言”。成功地调整一个预训练模型需要一个深思熟虑的翻译和微调过程，这是一场理解数据物理学和[网络生物学](@entry_id:204052)之间优雅的相互作用。

#### 翻译新领域的语言

在网络能够解释一幅图像之前，必须以它能理解的格式呈现这幅图像。例如，VGG 网络期望的是一个三通道图像，其像素值在特定范围内，就像它在训练期间看到的数百万张红-绿-蓝 (RGB) 照片一样。但医疗 CT 扫描仪产生的东西完全不同：一个单通道、高位深的图像，其值代表物理上的X射线衰减，以亨氏单位 (HU) 衡量。为了弥合这一差距，我们必须进行有原则的翻译。这包括使用来自医疗图像文件的[元数据](@entry_id:275500)——如 Rescale Slope 和 Intercept 等参数——将存储的像素值转换为具有物理意义的 HU 值。然后，我们应用一个有临床动机的“窗位窗宽”处理，选择一个与感兴趣组织（如软组织）相关的特定 HU 值范围，并将这个范围线性映射到我们熟悉的 8 [位图](@entry_id:746847)像的 $0-255$ 强度范围。然后，这个灰度图像被复制到三个通道中，以模仿 RGB 输入，最终创造出预训练网络可以处理的东西[@problem_id:5177804]。

这个想法可以延伸到远超医学的领域。考虑一下[遥感](@entry_id:149993)领域的挑战。卫星的多光谱传感器在许多波段捕捉信息，有些是可见的，有些则远在红外线之外，每个波段测量的是不同的物理量，如光谱[辐射度](@entry_id:156534)。要使用一个在 RGB 图像上预训练的模型，我们不能简单地把其中三个波段塞进输入。一个更深刻的方法是，首先利用[辐射度量学](@entry_id:174998)的原理，将原始[辐射度](@entry_id:156534)值转换为大气顶层[反射率](@entry_id:155393)——这是一个无量纲的量，它已经为太阳角度和地日距离进行了校正。这个基于物理学的预处理步骤，使得来自不同波段的数据更具可比性。只有这样，我们才对每个波段进行统计标准化，以使其分布与网络所期望的相符。这个两步过程——物理归一化后跟统计归一化——是一个美丽的例子，说明了尊[重数](@entry_id:136466)据来源的底层科学是成功进行机器学习的先决条件[@problem_id:3862728]。

#### 微调大脑：一场精细的手术

有时，简单的翻译还不够。当新领域包含根本不同类型的视觉模式时，我们可能需要进行更精细的手术：微调预训练网络本身。这不是一种粗暴的重新训练，而是一个细致的过程，即解冻某些层并允许它们适应，这一决定取决于[领域偏移](@entry_id:637840)的性质。

例如，在计算病理学中，模型必须学会区分组织学切片中的恶性腺体和良性腺体。虽然预训练网络的早期层非常擅长检测构成细胞的边缘和斑点，但其[后期](@entry_id:165003)层却是被训练来识别猫和汽车的部件——这些特征对病理学毫无用处。关键信息在于组织的纹理和结构，这些特征是在网络的中[后期](@entry_id:165003)层学到的。因此，一种复杂的策略是冻结早期的、通用的特征提取层，同时仔细微调[后期](@entry_id:165003)的、更专门化的层。这必须与其他最佳实践相结合，例如预处理图像以实现染色标准化，以及在患者层面分割数据以防止模型获得误导性线索[@problem_id:4316728]。

与之形成对比的是，将模型调整到来自新 CT 扫描仪的图像。底层的解剖结构是相同的，但新的扫描仪可能会在图像强度和噪声上引入轻微变化。这是一个较低层次的偏移。在这里，一个有效的策略可能是调整网络的[批量归一化](@entry_id:634986)层，这些层跟踪每一层特征的运行统计数据。通过向网络展示来自新扫描仪的未标记图像，我们可以更新这些统计数据，有效地将网络的内部“传感器”重新校准到新设备上，而无需大量的标记数据集。这可以与仅微调网络最深层相结合，在适应和保留强大的预训练知识之间达到完美平衡[@problem-id:4955226]。这说明了一个深刻的原则：微调的策略应与[领域偏移](@entry_id:637840)的性质相匹配。

### CNN 作为更大机器中的一个齿轮

预训练 CNN 的威力不仅限于端到端的分类。也许它们最深远的影响来自于它们作为模块化组件的用途——强大的感知引擎，可以插入到更大、更复杂的推理系统中。CNN 提供“是什么”，而第二个模型则推理“如何”和“为什么”。

#### 从集合与情境中学习

在病理学中，一张全切片图像是由数百万个组织块组成的巨大马赛克。诊断通常不取决于单个组织块，而是取决于整张切片的集体证据。在这里，预训练 CNN 可以用作[特征提取器](@entry_id:637338)。它处理每个小块并输出一个固定长度的向量或“嵌入”，该向量总结了其视觉内容。这通常通过获取网络的最终特征图并应用[全局平均池化](@entry_id:634018)来实现，这一步创建了图像块中存在特征的平移不变摘要。然后，这些嵌入被送入第二个模型，一个多示例学习 (MIL) 聚合器，它学会权衡所有图像块的证据，以做出切片级别的诊断[@problem_id:4321352]。

这种模块化允许更复杂的架构。在基于图的放射组学中，一个患者体内的多个肿瘤病灶可以表示为图中的节点。预训练的 CNN 可以分析每个病灶的 CT 图像并生成一个特征向量，该向量成为相应节点的初始状态。然后，一个[图神经网络 (GNN)](@entry_id:635346)——一种旨在推理关系和结构的模型——可以在这个图上操作，在病灶之间传递信息，以学习一个整体的、患者级别的生物标志物，用于预测治疗反应。在这种设置中，冻结还是微调 CNN [特征提取器](@entry_id:637338)的决定成为一个经典的[偏差-方差权衡](@entry_id:138822)。冻结 CNN 会产生一个容量较低的模型，从而降低在小规模患者队列上过拟合的风险。微调 CNN 则允许它学习更多领域特定的特征，从而减少偏差，但增加了记住训练数据的风险[@problem_id:4542456]。

#### 融合数据世界

也许最令人兴奋的前沿是，将 CNN 的视觉感知与完全不同形式的数据结合起来。一个患者的故事不仅由他们的图像讲述，还由他们的电子健康记录 (EHR) 讲述——这是一个包含实验室值、人口统计信息和临床笔记的丰富集合。为了构建一个真正智能的诊断系统，我们必须融合这些模态。

假设我们有一个用于图像的预训练 CNN 和另一个用于结构化 EHR 数据的模型。我们如何将它们结合起来？一种天真的方法可能是将它们的特征向量连接起来，然后输入一个单一的决策网络（早期融合）。但一种更有原则的方法，即晚期融合，则保持这两个[数据流](@entry_id:748201)的分离。每种模态的模型都做出自己的预测，然后一个最终的“[元学习器](@entry_id:637377)”结合这些预测。这种架构有一个植根于概率论的优美理由。如果我们假设，在给定患者真实结果的情况下，图像和 EHR 数据是条件独立的，那么贝叶斯规则告诉我们，结合它们证据的最佳方式是在[对数几率](@entry_id:141427)尺度上进行加法。晚期融合正是这一概率原则的直接工程体现。它防止了来自两种不同数据类型的学习信号在训练过程中相互“污染”，从而在实现有原则的多模态集成的同时，保持了专门的、预训练的图像特征的完整性[@problem_id:4615223]。

### 从黑箱到可信工具

为了让这些强大的工具从研究实验室走向我们的生活——进入我们的医院和手机——我们必须克服最后两个障碍：我们必须学会信任它们，并且必须让它们变得实用。

#### 问网络“为什么？”

对深度学习的一个普遍批评是模型是“黑箱”。它们给出答案，但无法解释其推理过程。然而，一个新兴的[可解释性机器学习](@entry_id:162904)领域正在开发巧妙的方法来窥探内部。其中一种方法是使用概念激活向量进行测试 (Testing with Concept Activation Vectors, TCAV)。这项技术允许我们用一种我们都懂的语言向网络提问：例子的语言。

假设一个网络被训练来根据组织学预测肿瘤的侵袭性，而一位生物学家假设网络可能正在使用细胞缺氧（氧气剥夺）作为一个关键指标。通过使用对缺氧标记物进行染色的共配准切片，我们可以收集一组对“缺氧概念”呈阳性的图像块和一组阴性例子。通过将这些例子输入网络并分析它们在某个内部激活层中的模式，我们可以定义一个“缺氧向量”——一个在网络高维大脑中对应于我们人类定义概念的方向。然后我们可以测量沿着这个方向移动对最终预测的影响有多大。这使我们能够以统计上的严谨性来量化网络是否独立地发现了一个已知的生物学概念，以及它在多大程度上依赖于它。这将 CNN 从一个纯粹的预测工具转变为一个科学研究的对象，从而弥合了数据驱动工程与假设驱动科学之间的鸿沟[@problem_id:2399976]。

#### 从实验室到现场：[知识蒸馏](@entry_id:637767)

最后，是工程现实问题。最强大的模型通常是庞大的网络集成，太大太慢，无法在手机上运行用于即时筛查。在这里，解决方案既优雅又有效：**[知识蒸馏](@entry_id:637767)**。我们使用大型、强大的教师集成模型来训练一个更小、更灵活的学生模型。教师不仅给学生最终答案（“硬标签”），至关重要的是，它通过提供其在所有可能类别上的完整概率分布来分享其细致的推理。这些“软标签”包含“[暗知识](@entry_id:637253)”——即教师对哪些类别彼此相似的感觉。通过训练学生同时匹配硬标签和教师的软标签，我们可以将集成模型相当大一部分的性能和校准能力转移到一个更紧凑的模型中。整个过程可以嵌入到一个复杂的[损失函数](@entry_id:136784)中，该函数同时鼓励学生做到准确、模仿其老师，并变得稀疏和可压缩以满足严格的内存预算。这是信息论工程的一项杰作，使得这些强大的人工智能系统能够被部署在最需要它们的地方[@problem_id:5228751]。

从基本分类到复杂、多模态和可解释的系统，预训练 CNN 的旅程证明了可迁移知识的力量。它向我们展示，通过站在巨人的肩膀上，我们不仅限于看到他们所看到的，而且有能力看得更远，进入他们从未想象过的新世界。