## 引言
在一个数据成为关键资产的时代，数据往往分散在不同的组织中。单个个体的信息——例如，他们的临床、基因组和放射学数据——可能由不同的实体持有，从而形成了阻碍整体分析的“数据孤岛”。这种碎片化状态对科学发现和强大[机器学习模型](@entry_id:262335)的开发构成了重大障碍。纵向联邦学习（VFL）作为解决这一问题的革命性方案应运而生，它提供了一个框架，可以在任何一方都不必共享其原始信息的情况下，协同地在这些纵向分割的数据上训练模型。本文将揭开 VFL 的神秘面纱，引导您了解其核心概念和变革潜力。首先，在“原理与机制”部分，我们将探讨 VFL 的基本工作方式，从用于对齐数据的密码学“秘密握手”，到实现联合模型训练的安全计算方法。随后，在“应用与跨学科联系”部分，我们将看到这些原理的实际应用，审视 VFL 如何有望彻底改变医学等领域，并实现诸如保护隐私的因果推断等复杂分析。

## 原理与机制

想象一下，你有一张巨大而详尽的世界地图。如果你想与合作者分享这张地图，但又不想全盘托出，你有两种基本的分法。你可以沿着纬度线横向切分，把北半球给一个人，南半球给另一个人。或者，你可以沿着经度线纵向切分，把美洲给一个人，欧亚大陆给另一个人。在数据世界里，我们面临着类似的选择，而这导向了两种截然不同的协作方式。

### 数据的两种“地理”划分

当数据分布在不同地方时，比如不同医院的病人记录，它几乎总是以这两种方式之一进行分割。这种分割方式决定了我们在保护隐私的同时进行集体学习的整体策略。

第一种方式是**横向联邦学习 (HFL)**。这就像是纬度切分。想象一下不同城市的医院，都使用相同的软件记录同一组病人特征——人口统计信息、诊断、实验室结果等等。每家医院拥有一组不同的病人（样本），但对每个病人的描述，即属性列表（特征），是相同的。特征空间是共享的，但样本是不同的 [@problem_id:4863858] [@problem_id:4339348]。在 HFL 中，任务是通过整合每家医院的洞见来训练一个单一的、强大的模型。由于大家都在“说同一种特征语言”，中央服务器可以智能地对每家医院的模型或学习更新进行平均，从而创建一个受益于所有数据的全局模型，而任何单个病人的记录都无需离开其所在的机构。

第二种方式，对我们而言也更引人入胜，是**纵向[联邦学习](@entry_id:637118) (VFL)**。这是经度切分。在这里，我们关注的是*同一*组个体，但不同的组织对他们有不同的了解 [@problem_id:4840339]。想象一下单个病人在医疗系统中的旅程。一家医院持有他们的临床记录——症状、诊断和治疗。一个专门的实验室持有他们的基因组数据——对他们 DNA 的深入分析。一个独立的影像中心持有他们的 MRI 扫描和 X 光片。没有任何一个机构拥有完整的图景。病人样本是共享的，但特征是分割的 [@problem_id:4863858]。

这就是 VFL 的世界。挑战不再是平均相似的模型，而是将临床、基因组、放射学等根本不同的信息线索编织在一起，为每个个体形成一幅完整的织锦，同时确保任何一方都看不到对方的线索。当必要的信息分散在被隐私强制执行的鸿沟两岸时，我们怎么可能训练出一个单一、连贯的模型来预测（例如）病人对治疗的反应呢？这正是 VFL 真正精妙之处的开端。

### 第一个挑战：秘密握手

在我们开始梦想建立一个模型之前，我们面临一个看似简单却深刻的问题：我们如何知道我们谈论的是同一个人？医院知道的是“病人 ID 734”，而基因组实验室的数据对应的是“客户 G-921”。他们是同一个人吗？

我们不能简单地让医院和实验室交换他们病人的姓名或国民身份证号码列表。那将是一次灾难性的隐私泄露。实验室会立即知道谁是医院的病人，反之亦然，从而泄露了那些甚至可能不属于合作研究的人的敏感健康信息。我们需要一种方法，让两个组织能够发现他们共同的病人——并且*仅仅*是他们共同的病人——而不泄露任何关于其他人的信息。我们需要一次秘密握手。

这是通过一种名为**隐私集合交集 (PSI)** 的精妙[密码学](@entry_id:139166)工具实现的 [@problem_id:4840288]。想象一下 Alice（医院）和 Bob（实验室）各自有一份他们病人唯一标识符的秘密列表。他们想找出同时出现在两个列表上的名字。一个巧妙的 PSI 协议，通常基于一种叫做不经意[伪随机函数](@entry_id:267521) (OPRF) 的概念，让他们能够做到这一点，效果如同魔法 [@problem_id:4341156]。

其直觉是这样的：Alice 生成一个秘密的“编码器环”（一个带密钥的[密码学](@entry_id:139166)函数）。她对自己病人 ID 的整个列表进行编码，并将这个杂乱无章、无法识别的代码列表发送给 Bob。Bob 无法理解这些代码。现在，Bob 想核对自己的列表。对于他自己的每个病人 ID，他使用一个特殊协议 (OPRF) 来请求 Alice 用她的秘密编码器环来编码他的 ID。“不经意”的部分就是魔法所在：Alice 为 Bob 执行编码，但她不知道他请求她编码的是哪个 ID。Bob 收到结果代码。然后他可以检查这个代码是否出现在 Alice 早先发给他的大列表中。如果出现了，他就找到了一个匹配项！他们有一个共同的病人。如果没有，他也不会了解到更多信息。

通过这场密码学的舞蹈，Bob 了解了两个集合的交集。而 Alice 这边，她对 Bob 的列表一无所知，甚至连他们共同的成员也不知道。Bob 也不会了解到 Alice 列表中那些不属于他列表的病人的任何信息。这种“秘密握手”是 VFL 的基础步骤；没有它，协作甚至无法开始 [@problem_id:4840288]。

### 从分散的线索中编织模型

既然医院和实验室已经有了一份安全对齐的共同病人列表，他们如何训练一个模型呢？让我们考虑一个简单的逻辑回归模型，其目标是基于特征的加权和来预测一个[二元结果](@entry_id:173636)（比如疾病缓解）。对于单个病人，模型的预测值，或称 logit $z$，可能如下所示：

$$z = \underbrace{w_H^\top x_H}_{\text{医院部分}} + \underbrace{w_G^\top x_G}_{\text{实验室部分}}$$

这里，$x_H$ 代表来自医院的病人临床特征，$x_G$ 代表来自实验室的基因组特征。训练的目标是找到最佳的权重 $w_H$ 和 $w_G$。

问题立刻显现出来。医院拥有 $x_H$ 并控制其权重 $w_H$，而实验室拥有 $x_G$ 并控制其权重 $w_G$。告诉我们预测是对是错的结果标签 $y$ 则存放在医院。为了更新其权重 $w_G$，实验室需要知道[预测误差](@entry_id:753692)，这通常是真实结果 $y$ 与模型预测概率 $\sigma(z)$ 之间差异的函数。但总的 logit 值 $z$ 依赖于医院的数据，而结果 $y$ 在医院！实验室无法单独计算其更新 [@problem_id:4339348]。

这时，第二场密码学的舞蹈开始了，使用的工具是**同态加密 (HE)** 或**安全多方计算 (SMPC)**。同态加密尤其直观。它允许你在加密数据上执行数学运算，而无需解密。

把它想象成一个神奇的、透明的保险箱。实验室可以计算其分数部分 $z_G = w_G^\top x_G$，将其放入保险箱（加密），然后发送给医院。没有钥匙的医院无法看到里面的东西。然而，它可以对箱子里的内容执行操作：它可以将自己的分数 $z_H = w_H^\top x_H$ 加到已有的值上。现在，箱子里包含了总分 $z = z_H + z_G$，仍然是安全加密的。

然后，拥有钥匙的医院可以打开箱子得到 $z$，计算[预测误差](@entry_id:753692)，并——通过另一系列安全计算——向实验室提供更新其权重 $w_G$ 所需的精确信息，而始终不泄露结果 $y$ 或其自身的特征 $x_H$。

然而，这种安全协作是有代价的。这些密码学操作计算量巨大，需要大量的通信。在一个包含 256 名病人、每个参与方只有少数特征的小批量数据上训练模型的一步，可能需要在站点之间进行数千次的安全乘法运算 [@problem_id:4339309]。这一现实迫使研究人员做出明智的设计选择，通常倾向于更简单、更高效的模型，而不是复杂的[深度学习架构](@entry_id:634549)，因为后者的性能优势可能无法抵消其巨大的隐私保护成本 [@problem_id:4339361]。

### 链条的脆弱性与对稳健性的追求

使 VFL 成为可能的这一系列优雅协议是强大的，但就像任何链条一样，它的强度取决于其最薄弱的环节。如果最初的“秘密握手”——实体对齐步骤——并非完美无瑕会怎样？如果由于笔误或标识符不一致，一小部分比例为 $\alpha$ 的病人被错误地链接了会怎样？[@problem_id:4341054]

其后果不仅仅是随机噪声；它们会引入一种系统性的、[腐蚀性的](@entry_id:164959)偏误。如果模型试图学习一个病人的临床数据与一个完全不同病人的基因组数据之间的关系，它就是在被灌输无稽之谈。模型的反应相当合乎逻辑：它学会不信任来自“嘈杂”来源的特征。这导致了一种被称为**[衰减偏误](@entry_id:746571)**的现象。基因组特征的估计影响 $\hat{\beta}_G$ 将被系统性地压缩至零。如果真实效应是 $\beta_G$，模型将估计出接近 $(1-\alpha)\beta_G$ 的值。链接错误率越高，模型就越会忽略这些特征，从而可能错失至关重要的生物学信号 [@problem_id:4341054]。

当我们无法简单地“查看数据”来检查链接时，我们如何防范这种情况？我们必须在诊断中同样聪明。我们可以进行隐私保护的“消防演习”：有意地、安全地模拟一个已知的错误链接率，以观察我们模型结果的敏感度。我们还可以采用**阴性对照**——那些我们事先知道没有因果关系的特征或结果。如果我们的 VFL 模型为一个阴性对照发现了“显著”的联系，这是一个重大的警示信号，表明系统性错误，如错误的记录链接，可能正在破坏我们的分析 [@problem_id:4341054]。

### 超越预测：探寻“为什么”

VFL 的最终前景远不止是建立更好的预测模型。它为以保护隐私的方式提出深刻的科学问题打开了大门——最引人注目的是因果关系问题。

假设我们想知道一种新药是否*导致*了更好的健康结果。要回答这个问题，仅仅观察到服用该药的病人情况更好是不够的。我们必须考虑所有的**混杂因素**——那些既影响病人为何接受该药又影响其最终结果的因素。例如，年轻的病人可能更有可能接受新药，同时也更有可能康复。

在 VFL 场景中，这些混杂因素可能是分割的。医院知道病人的年龄和临床病史 ($X_H$)，而实验室知道一个影响药物代谢的基因变异 ($X_G$)。为了分离出药物的真实因果效应，我们必须同时对*两组*混杂因素进行调整 [@problem_id:4341044]。

这正是 VFL 的全部力量得以释放的地方。允许我们训练联合预测模型的同一套安全机制，也可以用来拟合一个联合的因果模型。它使我们能够满足因果推断所需的核心假设，例如在分布式数据集上对完整的混杂因素集进行条件化。这将 VFL 从一项卓越的工程壮举转变为一种革命性的科学工具，使我们能够从“可能会发生什么”转向“为什么会发生”，而无需牺牲使合乎伦理的研究成为可能的基本隐私权。

