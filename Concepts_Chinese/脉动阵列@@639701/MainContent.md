## 引言
在对计算能力的不懈追求中，并非所有架构都生而平等。虽然通用处理器提供了令人难以置信的灵活性，但在现代人工智能和科学计算核心领域的一类特殊问题，需要一种不同的方法——一种优先考虑效率和大规模并行性的方法。[脉动阵列](@entry_id:755785)（systolic array）应运而生，这是一种优雅而强大的并行处理架构，已成为人工智能革命的引擎。其设计理念旨在解决一个关键挑战：如何在不被[功耗](@entry_id:264815)或巨大的数据移动成本所拖累的情况下，每秒执行数万亿次计算。本文将揭开这种卓越架构的神秘面纱。我们将首先探讨其核心原理和机制，从其单个处理单元简单而富有节奏的协作，到构建物理机器的复杂现实。随后，我们将考察其多样化的应用和跨学科联系，探索[脉动阵列](@entry_id:755785)的基本计算模式如何在从人工智能、信号处理到[机器人学](@entry_id:150623)和生物信息学等领域中找到用武之地。

## 原理与机制

要真正领会[脉动阵列](@entry_id:755785)的精髓，我们不能将其视为一整块硅片，而应视之为一个有生命、会呼吸的有机体。与任何有机体一样，它由一个简单的重复单元构成，其力量源于这些单元优美而协调的协作。让我们从这台机器的核心开始。

### 机器的心脏：乘积累加单元

想象一个简单的计算单元，一个微小的数字生物。它一生的全部目的就是以完美的节奏，一遍又一遍地做一件事。它接收两个数，比如 $A$ 和 $B$，将它们相乘，然后将结果加到它内部维持的一个累计总和 $C$ 上。用工程师的语言来说，这是一个**乘积累加**（multiply-accumulate）或 **MAC** 操作：$C \leftarrow C + (A \times B)$。

对于单个单元来说，这样的生活并不十分激动人心。但这里有一个诀窍。在完成任务后，它不会丢弃接收到的数字。相反，它会与全局心跳（一个时钟信号）完美同步，将这些数字传递给它的邻居。这个简单的局部规则——**计算并传递**——是整个架构的秘密所在。这种富有节奏、脉搏般的数据流正是“脉动”阵列名称的由来，它类比了心脏通过收缩（systolic contraction）将血液泵送到全身的过程。

### 节奏链：一维阵列的运作

当我们将这些单元串在一起时会发生什么？让我们构建一个小链条，一个由三个处理单元（PE）组成的一维阵列，比如 $\text{PE}_0$、$\text{PE}_1$ 和 $\text{PE}_2$。我们将它们排成一行，这样在每个时钟滴答时，一个单元的输出就成为下一个单元的输入。

这种简单的[排列](@entry_id:136432)方式功能非常强大。考虑应用数字**有限冲激响应（FIR）**滤波器的任务，这是信号处理的基石，应用范围从音频均衡器到[无线通信](@entry_id:266253)无所不包。该滤波器通过对最近的输入进行加权求和来从输入信号 $x$ 计算输出 $y$：$y[n] = W_0 x[n] + W_1 x[n-1] + W_2 x[n-2]$。

让我们将这个任务映射到我们的阵列上。这些阵列的美妙之处在于让数据的“编排”恰到好处。对于我们的 FIR 滤波器，一种常见的方法是**权重驻留**（weight-stationary）数据流。我们预先将一个静态权重加载到每个单元中：$W_0$ 加载到 $\text{PE}_0$，$W_1$ 加载到 $\text{PE}_1$，$W_2$ 加载到 $\text{PE}_2$。然后，输入信号 $x$ 从阵列的一端（例如 $\text{PE}_0$）泵入，并在每个[时钟周期](@entry_id:165839)从一个单元传播到下一个单元。为了形成乘[积之和](@entry_id:266697)，[部分和](@entry_id:162077)（即 $y$ 值）也必须流经阵列，但方向相反。

想象一下，输入信号 $x[n]$ 从左侧进入，而一串零从右侧进入最后一个 PE 的 $Y$ 输入端。
- 在每个时钟滴答时，一个 PE 从其左邻居接收一个 $x$ 值，并从其右邻居接收一个部分和 $y_{in}$。
- 它执行其 MAC 操作：$y_{out} = y_{in} + (W_{local} \times x_{in})$。
- 然后它将 $x_{in}$ 值传递给其右邻居，并将计算出的 $y_{out}$ 值传递给其左邻居。

通过这种富有节奏、逆向流动的数据协作，正确的滤波输出值（$y[0], y[1], y[2], \dots$）在经过填充流水线的初始延迟后，会从阵列的左端顺序产生，每个时钟周期一个。计算在各个单元之间自然地流水线化，每个 PE 在每个时钟滴答时都为一个不同的输出值贡献一项。这种富有节奏的、波浪般的计算正是脉动原理的精髓。

### 计算的交响乐：二维网格

现在，让我们转向二维。想象一个由我们的 MAC 单元组成的 $N \times N$ 网格。这正是[脉动阵列](@entry_id:755785)真正大放异彩的地方，特别是在**通用矩阵乘法（GEMM）**方面，这是现代人工智能的主力。为了计算 $C = A \times B$，我们可以将矩阵 $A$ 的元素从左侧流式输入网格，将矩阵 $B$ 的元素从顶部流式输入。$A$ 的元素水平移动，$B$ 的元素垂直移动。

网格中位于位置 $(i, j)$ 的每个 PE 负责计算输出矩阵的一个元素 $C_{ij}$。它通过保持原地不动并累积部分乘积来完成此任务。在每个时钟周期，一个来自其左邻居的 $A$ 的新元素和一个来自其上邻居的 $B$ 的新元素到达。PE 将它们相乘并将结果加到其内部[累加器](@entry_id:175215)中。在所有必需的 $A$ 和 $B$ 元素都通过之后，该 PE 就持有了 $C_{ij}$ 的最终值。这种特定的数据流，其中输出在 PE 中保持静止，被恰如其分地称为**输出驻留**（output-stationary）。

其魔力在于，当 PE $(i, j)$ 工作时，它的所有邻居也都在用到达其位置的不同数据处理各自的输出元素。一个计算的波前（wavefront）会斜向扫过整个阵列。不需要复杂的控制逻辑。整个庞大的计算过程，都是从数据和 MAC 操作这种简单、局部、富有节奏的协作中展开的。

### SIMD 的交响：[脉动阵列](@entry_id:755785)的分类

在并行计算的宏伟蓝图中，[脉动阵列](@entry_id:755785)处于什么位置？计算机架构师通常使用**[弗林分类法](@entry_id:749492)**（Flynn's Taxonomy）来对并行机进行分类。[脉动阵列](@entry_id:755785)是**单指令，多数据（SIMD）**架构的一个经典范例 [@problem_id:3643583]。

这意味着在任何给定时刻，一个单一的命令或指令——在这里是“执行一次乘积累加”——被广播到所有处理单元。然而，成千上万个 PE 中的每一个都在对恰好流经它的*不同*数据片段执行这同一个指令。这与**多指令，多数据（MIMD）**机器形成对比，例如多核 CPU，其中每个核心都可以运行一个完全不同的程序。

有人可能会好奇其他类别。**多指令，单数据（MISD）**呢？这将涉及对同一数据片段同时执行多个不同的操作。事实证明，这对于以性能为导向的计算来说是一种极其罕见的模式。为什么？因为大多数计算问题都受益于**[数据并行](@entry_id:172541)**——即有大量数据需要处理。MISD 并没有利用这一点。它的主要应用是在[容错](@entry_id:142190)系统中，你可能会对同一输入运行几种不同的算法来解决同一个问题，并对结果进行投票以确保正确性，这种技术被称为 N-版本编程（N-version programming）[@problem_id:2422605]。在追求原始速度方面，SIMD 和 MIMD 占据主导地位。

### 数据流的艺术：驻留以求成功

虽然我们描述了输出驻留[数据流](@entry_id:748201)，但这并不是编排数据协作的唯一方式。选择将什么“驻留”在 PE 中，以及将什么“流式传输”过去，是**算法-架构协同设计**的一个关键方面。目标始终是最大化复用已经存在于芯片内部的数据，因为从片外内存获取数据非常缓慢且耗能巨大。

对于作为人工智能关键操作的[卷积神经网络](@entry_id:178973)，主要有三种数据流族 [@problem_id:3634483]：
*   **输出驻留（OS）**：正如我们所见，输出像素的部分和保存在 PE 中。这对于累加器的复用非常有利。
*   **输入驻留（IS）**：输入图像的图块在 PE 中保持静止，而不同的滤波器权重流经其中。这最大化了输入数据的复用。
*   **权重驻留（WS）**：滤波器权重保持静止，而输入数据和[部分和](@entry_id:162077)流经其中。在许多深度学习模型中，同一组权重会应用于一个非常大的输入图像。这意味着权重的复用潜力巨大。通过将权重保留在片上，WS [数据流](@entry_id:748201)可以显著减少内存流量。

像谷歌的张量处理单元（TPU）这样的现代加速器通常设计有用于存放权重的大容量片上内存，这使得它们特别适合权重驻留方法。[数据流](@entry_id:748201)的选择并非随意而为；它是一项深刻的设计决策，反映了对最重要计算结构的预判。这种协同设计甚至延伸到常见算法的底层实现。例如，在经典的数字信号处理器（DSP）上，实现一个 FIR 滤波器的“直接型”结构可能比数学上等价的“转置型”结构涉及的内存访问要少得多，这仅仅是因为它映射到寄存器和[内存层次结构](@entry_id:163622)的方式不同 [@problem_id:3634483]。

### 物理机器的现实

[脉动阵列](@entry_id:755785)的抽象原理是优美的，但只有当我们考虑到其实现的物理和经济因素时，它的真正威力才能得以体现。

#### 时序就是一切：时钟速度优势

为什么[脉动阵列](@entry_id:755785)可以以如此高的频率运行？任何[同步电路](@entry_id:172403)的最小始终周期都受其**关键路径**的限制——即任意两个寄存器之间组合逻辑的最长延迟。在传统的[处理器流水线](@entry_id:753773)中，这条路径可能相当长且复杂。而在[脉动阵列](@entry_id:755785)中，单个阶段内的逻辑只是一个简单的 MAC 单元和一些布线。这条路径短而规整，从而允许非常短的[时钟周期](@entry_id:165839)，因此频率非常高 [@problem_id:3634540]。一个脉动单元的级延迟可能为 $1.4\,\text{ns}$，允许约 $714\,\text{MHz}$ 的时钟；而一个更复杂的流水线数据通路的关键级延迟可能为 $1.7\,\text{ns}$，将其限制在约 $588\,\text{MHz}$。

#### 简单的力量

MAC 单元的简单性也在[功耗](@entry_id:264815)效率方面带来了深远的优势。一个通用 CPU 核心是复杂性的奇迹，旨在处理你交给它的任何任务。这种灵活性是以高[功耗](@entry_id:264815)为代价的。而脉动 PE 则是一个专家。它只做一件事，并且其硬件为该任务进行了无情的优化。

当你在固定的[功耗](@entry_id:264815)预算下比较一个带 SIMD 单元的多核 DSP 和一个 TPU 风格的[脉动阵列](@entry_id:755785)时，差异是惊人的。对于同样的 50 瓦，你或许可以构建一个包含 90 个高性能 DSP 核心的集群，实现约 0.65 万亿次 MAC/秒（TMAC/s）。但在相同的[功耗](@entry_id:264815)预算下，你可以制造一个巨大的 $128 \times 128$ [脉动阵列](@entry_id:755785)，尽管其运行时钟速度稍低，但能提供近 10 TMAC/s 的持续吞吐量——性能提升超过 15 倍！[@problem_id:3634505] 这就是领域特定架构的力量：用通用性换取在目标任务上性能和效率的巨大提升。

#### 让问题适应硬件：分块与利用率

一个物理的[脉动阵列](@entry_id:755785)具有固定的大小，比如 $16 \times 16$ 个 PE。但是如果我们需要乘以两个 $1000 \times 1000$ 的矩阵怎么办？我们不能为每种问题规模都制造一个新的芯片。解决方案是**分块**（tiling）。我们将大[矩阵分解](@entry_id:139760)成适合我们硬件阵列的、小块的“瓦片”。

然而，这会带来效率的损失。要用一个 16 行的阵列覆盖一个 100 行的矩阵，我们垂直方向需要 $\lceil 100/16 \rceil = 7$ 个瓦片。前 6 个瓦片是满的，但第 7 个瓦片只使用了阵列的 $100 - 6 \times 16 = 4$ 行。然而，整个 $16 \times 16$ 的阵列在该瓦片计算的整个持续时间内都被调度并供电。这导致了利用率的损失。总体效率是真实问题区域与分块所需的“填充”区域之比，对于一个 $r \times c$ 的问题在一个 $m \times n$ 的阵列上可以表示为：
$$U = \frac{rc}{mn \lceil r/m \rceil \lceil c/n \rceil}$$
最大化这种利用率是针对这些架构的软件编译器面临的一个关键挑战。

#### 喂饱野兽：内存瓶颈

[脉动阵列](@entry_id:755785)可能是一个贪得无厌的计算野兽。一个 $16 \times 16$ 的阵列执行一个[矩阵乘法](@entry_id:156035)瓦片可能在几百个时钟周期内完成计算。但在此期间，它需要被喂入数千字节的数据作为输入矩阵。这些数据必须来自片外内存（DRAM），而 DRAM 的速度远慢于片上逻辑。

这造成了潜在的**内存瓶颈**。系统的真实性能通常不是由计算速度限制，而是由数据移动的速度限制。为了解决这个问题，设计者使用了复杂的技术。一个**直接内存访问（DMA）**引擎在后台工作，当阵列忙于计算*当前*瓦片时，它会获取*下一个*瓦片的数据。这是通过使用**双缓冲**（double-buffering）方案来协调的，其中使用了两组片上内存库：一组用于计算引擎，一组用于 DMA 引擎，它们的作用在每个瓦片完成后交换 [@problem_id:3684376] [@problem_id:3671166]。在这种数据移动和计算的流水线协作中，处理一个瓦片的[稳态](@entry_id:182458)时间不是 DMA 时间和计算时间的总和，而是两者的*最大值*。系统的速度取决于其最慢的阶段。

### 无名英雄：内部网络

最后，我们决不能忘记连接本身。成千上万个[排列](@entry_id:136432)成网格的 PE 是如何如此高效地相互通信的？它们通过一个**[片上网络](@entry_id:752421)（NoC）**连接，这是一个由微型路由器和链路组成的复杂结构。设计这个网络是一个深刻的挑战。例如，为了提高性能，设计者可能会将网格的边缘连接起来形成一个**环绕式环面**（wrap-around torus）。但这会产生循环，可能导致一种被称为**死锁**（deadlock）的致命交通堵塞，其中数据包陷入[循环依赖](@entry_id:273976)，每个都在等待下一个持有的缓冲区。为了打破这些依赖循环并保证无死锁操作，同时保持[环面拓扑](@entry_id:265595)的高[吞吐量](@entry_id:271802)，人们使用了先进的技术，例如向物理链路添加**虚拟通道**，并定义一个数据包必须有序穿过的“日界线” [@problem_id:3636745]。这是一个绝佳的例证，说明即使是这些系统中的“线路”也蕴含着深刻的算法和架构智慧。

从一个单一、不起眼的单元，到一个庞大、高[能效](@entry_id:272127)的片上超级计算机，[脉动阵列](@entry_id:755785)是简单、节奏和局部性力量的证明。它告诉我们，通过编排一个简单的协作并将其复制数千次，我们可以创建一个能够解决我们这个时代一些最严苛问题的计算交响乐。

