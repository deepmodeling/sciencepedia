## 应用与跨学科联系

我们发现了一个深刻而优美的对应关系：机器学习中[正则化](@article_id:300216)的实践，在数学上往往等同于从贝叶斯视角进行最大后验 (MAP) 估计。在我们的学习目标中添加一个惩罚项，就如同对解应该是什么样子轻声说出一个“先验信念”。一个偏爱小参数的高斯先验，产生了我们熟悉的 $L_2$（岭）惩罚。一个偏爱[稀疏解](@article_id:366617)（许多参数严格为零）的拉普拉斯先验，则产生了 $L_1$ ([Lasso](@article_id:305447)) 惩罚。

这不仅仅是一个数学上的巧合，它是一个统一的原则，一块罗塞塔石碑，让我们能够在[算法设计](@article_id:638525)的实用语言和概率推断的原则性语言之间进行翻译。在本章中，我们将踏上一段旅程，去见证这一原则的运作。我们将从[现代机器学习](@article_id:641462)的核心，走到工程和物理的经典领域，甚至触及[鲁棒优化](@article_id:343215)的前沿。一路上，我们将看到这同一个思想是一条金线，连接着惊人多样的领域，揭示了我们将数据转化为知识的方式中深刻的统一性。

### 驯服野兽：现代[机器学习中的正则化](@article_id:641414)

也许 MAP-[正则化](@article_id:300216)对偶性最直接、最广泛的应用，是驯服[现代机器学习](@article_id:641462)模型的复杂性。我们构建的神经网络拥有数百万，有时甚至是数十亿的参数——这个数字可以轻易超过我们拥有的数据点数量。如果没有某种形式的约束，这样的模型就像一个记忆力超群但过于热切的学生：它可以完美地记住训练数据，包括所有的[随机噪声](@article_id:382845)和特质，但在被问到一个新问题时却会惨败。这种泛化失败被称为过拟合，它是机器学习从业者必须斩杀的核心恶龙。

正则化是我们最锋利的剑。最常见的形式，被称为“[权重衰减](@article_id:640230)”或 $L_2$ 正则化，它在[损失函数](@article_id:638865)中加入一个与权重平方和成正比的惩罚项 $\lambda \|w\|_2^2$。从我们新的贝叶斯视角来看，我们发现这并非一个随意的技巧，而是对模型的权重施加一个零均值高斯先验的直接结果 [@problem_id:3169469]。我们实际上是在告诉模型：“我有一个[先验信念](@article_id:328272)，你的权重应该很小且以零为中心。只有当数据提供强有力的证据时，你才能偏离这个信念。”[正则化参数](@article_id:342348) $\lambda$ 不再只是一个需要调整的魔法旋钮；它是我们信念强度的精确度量。它与我们先验的方差 $\tau^2$ 成反比。一个强烈的信念（小的 $\tau^2$）对应于强的[正则化](@article_id:300216)（大的 $\lambda$）。

考虑一个里程碑式的模型，如 AlexNet，它是开启现代人工智能革命的深度[卷积神经网络 (CNN)](@article_id:303143) 之一。它的卓越部分在于其架构，该架构使用卷积层等巧妙结构，通过共享权重来大幅减少与全连接设计相比的参数数量。然而，即使有这些架构上的创新，[正则化](@article_id:300216)仍然是不可或缺的。在 AlexNet 的单层中，[权重共享](@article_id:638181)可以将参数数量从超过 1 亿减少到仅 35,000 个。但即使是训练 35,000 个参数而不加约束，也必然导致[过拟合](@article_id:299541)。[权重衰减](@article_id:640230)的应用——我们伪装的高斯先验——是其成功的关键因素之一 [@problem_id:3118617]。

这种贝叶斯视角不仅仅是提供一个哲学上的辩护，它还指导我们的实践。各向同性的高斯先验对所有权重的惩罚是相同的。但如果我们的输入特征处于完全不同的尺度上呢？例如，在一个用于图像分类的逻辑斯蒂[回归模型](@article_id:342805)中，一个特征可能是从 0 到 255 的像素强度，而另一个可能是值始终小于 1 的[预处理](@article_id:301646)值。各向同性的先验会不公平地惩罚与较大尺度特征相关的权重。模型会不愿意使用它，即使它[信息量](@article_id:333051)很高。我们的[贝叶斯解释](@article_id:329349)使问题变得清晰：先验的各向同性假设与数据的各向异性不匹配。实际的解决方案是[特征缩放](@article_id:335413)——将我们的特征标准化，使其具有相似的均值和方差。这使得数据更好地匹配我们先验的假设，通常[能带](@article_id:306995)来更快的收敛和更好的最终模型 [@problem_id:3157636]。

### 更通用的工具箱：推荐与排名

这个思想的力量远远超出了简单的分类或回归。它是在任何我们从数据中构建模型的领域进行推断的通用工具。

想想驱动 Netflix 和亚马逊等服务的[推荐引擎](@article_id:297640)。一种流行的方法是通过[矩阵分解](@article_id:307986)实现的[协同过滤](@article_id:638199)，我们试图通过发现用户和物品的一组“潜在因子”来预测一个人对某件物品的评分。然后，评分被建模为这些因子以及用户和物品特定偏置的组合 [@problem_id:3157699]。挑战在于数据极其稀疏；任何给定的用户只对可用物品的一小部分进行了评分。一个天真的[最大似然估计 (MLE)](@article_id:639415) 方法，试图完美解释观察到的评分，将会为潜在因子产生狂野且不可靠的估计。解决方案是[正则化](@article_id:300216)。通过对潜在因子向量施加零均值高斯先验，我们表达了一种信念，即大多数用户和物品都不是极端的；他们的潜在特征可能接近某个平均值。这会将估计的因子向零收缩，防止[模型过拟合](@article_id:313867)它所见的少量评分，并极大地提高其预测未见评分的能力。这就是偏差-方差权衡的实际应用：我们引入轻微的偏差（收缩因子）以实现方差的大幅减少（不稳定的估计），从而获得更好的整体性能。

同样的原则也适用于排名问题。想象一下，试图根据两两比赛的结果来确定锦标赛中选手的相对技能。像 Bradley-Terry 这样的模型为每个选手分配一个技能参数。一个选手击败另一个选手的概率是他们技能差异的函数。在这里，如果一些选手只打了少数几场比赛，他们技能的 MLE 可能会不稳定甚至为无穷大。通过对技能参数施加高斯先验，我们可以稳定估计值，将极端值拉向均值，并产生一个更稳健、更可信的排名 [@problem_id:3157622]。

### [大统一](@article_id:320777)：作为[逆问题](@article_id:303564)的科学

到目前为止，我们的例子都来自机器学习的世界。但现在我们准备好拥有一个更宏大的视角。训练一个神经网络、去模糊一张照片，以及从地震波中推断地球内部结构有什么共同点？它们都是*[逆问题](@article_id:303564)*。在每种情况下，我们都观察到对一个系统的某种间接、有噪声且不完整的测量（“果”），我们希望推断出产生它的潜在参数或结构（“因”）。

科学和工程中的许多[逆问题](@article_id:303564)从根本上是*不适定的*。这意味着解可能不是唯一的，或者更危险的是，它可能对数据中的噪声病态敏感。一个经典的例子是[数值微分](@article_id:304880)。假设你测量了一个物体随时间的位置，并想求出它的速度。位置数据是系统的阶跃响应 $s(t)$，速度是它的[导数](@article_id:318324)，即脉冲响应 $h(t)$。天真地对带噪声的数据进行微分是一场灾难。[微分算子](@article_id:300589)，在[频域](@article_id:320474)中对应于乘以 $j\omega$，会极大地放大你测量中的任何高频噪声，将真实的信号淹没在无意义的[振荡](@article_id:331484)海洋中 [@problem_id:2868499]。这个问题是不适定的。

由 Andrey Tikhonov 开创的经典解决方案是[正则化](@article_id:300216)。我们不只是寻找一个拟合数据的 $h$，而是寻找一个既能拟合数据又具有小 $L_2$ 范数的 $h$。这惩罚了剧烈[振荡](@article_id:331484)的解并稳定了反演过程。从我们的贝叶斯角度看，这是什么？这无非就是 MAP 估计，其中数据拟合项来自[高斯噪声](@article_id:324465)模型，而 $L_2$ 惩罚项来自对真实信号 $h(t)$ 的高斯先验！同样的逻辑也适用于[逆热传导问题](@article_id:313669)，比如人们可能试图从深埋在材料内部的温度传感器推断出随时间变化的表面热通量 [@problem_id:2506821]。[热扩散](@article_id:309159)是一个平滑过程；它的逆过程是一个“去平滑”过程，会放大噪声。Tikhonov [正则化](@article_id:300216)——我们的高斯先验——再次成为稳定解的关键。

这揭示了我们概念的惊人普适性。谷歌工程师用来训练语言模型的“[权重衰减](@article_id:640230)”和地球物理学家用来绘制地幔图的“Tikhonov [正则化](@article_id:300216)”，在其核心上是完全相同的思想。它们都是先验信念的表达，用以驯服一个不适定的[逆问题](@article_id:303564) [@problem_id:3286767]。

“先验”的概念可以更加复杂。它不一定作用于一组静态参数。考虑使用[循环神经网络 (RNN)](@article_id:304311) 对时间序列信号进行去噪。我们可以建立一个概率模型，其中干净信号的演化由 RNN 的动态控制。一个认为系统平滑演化的先验信念可以被编码为对每个时间步[隐藏状态](@article_id:638657)的创新或“冲击”的高斯先验。然后，MAP 估计找到一个既能解释有噪声的观测，又遵循被 RNN 先验认为合理的轨迹的干净信号。在这里，我们不仅仅是在[正则化](@article_id:300216)权重；我们是在[正则化](@article_id:300216)解的整个动态行为 [@problem_id:3167597]。

### 前沿：如果我们不信任自己的先验怎么办？

[贝叶斯框架](@article_id:348725)很强大，但它建立在我们能够指定一个先验的能力之上。如果我们对先验本身不确定怎么办？如果我们相信模型中的权重遵循高斯先验，但我们只知道它的方差 $\tau^2$ 位于某个范围 $[\tau_{\min}^2, \tau_{\max}^2]$ 内呢？

这引领我们进入了[鲁棒优化](@article_id:343215)的迷人世界。我们可以构建一个[极小化极大博弈](@article_id:641048)：一个“对手”从我们的[不确定性集合](@article_id:638812)中选择一个使我们处境最困难的先验，而我们则选择在该最坏情况下表现最佳的模型参数。当我们解决这个问题时，一个优美的结果出现了。对手总是选择具有*最小*可能方差 $\tau_{\min}^2$ 的先验。为什么？因为较小的先验方差对应于较大的[正则化参数](@article_id:342348) $\lambda$，从而对权重施加最紧的约束。为了创建最鲁棒的估计器，我们应该持悲观态度，并根据我们愿意接受的最强、最严格的先验进行正则化 [@problem_id:3173987]。这在贝叶斯推断和[鲁棒优化](@article_id:343215)之间提供了深刻的联系，为我们设计即使在我们自己的假设不确定时也具有弹性的[算法](@article_id:331821)提供了原则性的路径。

从一个对抗过拟合的简单技巧，我们已经深入到科学推断的核心。MAP 估计和正则化之间的等价性不仅仅是一个公式，它是一种观点。它告诉我们，每当我们在目标函数中添加一个惩罚项时，我们都在含蓄地陈述一个关于世界本质的信念。这是一种语言，它将最现代的机器学习[算法](@article_id:331821)与来自物理、工程和应用数学的经典方法统一起来，揭示它们都是[概率推理](@article_id:336993)这一共同语言的不同方言。