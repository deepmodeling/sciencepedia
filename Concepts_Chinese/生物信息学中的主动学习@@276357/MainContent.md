## 引言
在现代生物学中，海量的基因组和[蛋白质组](@article_id:310724)数据带来了一个根本性挑战：获取知识的巨大成本。尽管计算方法可以生成数以百万计的预测，但通过昂贵且耗时的实验室实验来逐一验证这些预测是不可能的。这种“标注瓶颈”限制了传统监督式机器学习的能力，因为后者需要大量经过整理的数据来构建准确的模型。我们如何才能更高效地进行研究，将宝贵的实验资源仅集中在最重要的数据上？

本文探讨了[主动学习](@article_id:318217)提供的解决方案。该[范式](@article_id:329204)将[计算模型](@article_id:313052)与人类专家之间的互动重塑为一种智能对话。[主动学习](@article_id:318217)并非随机或批量进行标注，而是让模型能够主动请求其最需要的信息以实现最有效的学习。首先，在“原理与机制”一章中，我们将剖析这一过程，探索模型如何识别其最“困惑”的数据，以及确保结果可信所需的严谨统计方法。然后，在“应用与跨学科联系”一章中，我们将看到该理论在实践中的应用，通过真实的生物学挑战——从发现新的蛋白质家族到工程化新分子——来理解[主动学习](@article_id:318217)为何不仅仅是一种计算技巧，更是一种全新的科学发现哲学。

## 原理与机制

想象你是一名侦探，正试图解开一个巨大而复杂的谜题——生命本身的奥秘，它被编码在基因组和蛋白质的语言中。你有一个强大但非常昂贵的工具：一次实验室实验，可以为你提供关于谜题中某个微小部分的明确线索。问题在于，你的预算只够使用这个工具几百次，而潜在的线索却多达数百万。你该从何入手？是随机调查，期盼好运？还是有更聪明的方法？这正是[主动学习](@article_id:318217)试图在生物信息学中解决的根本挑战。

### 科学家的困境：知识的代价

在[计算生物学](@article_id:307404)的世界里，我们有两种宏观方法来解决问题。一方面，我们有**无监督方法**，这就像查阅一个包含现有知识的大型图书馆。像 BLAST 这样搜索相似蛋白质序列的工具，它不会从你的具体问题中学习；它利用了一个庞大的、预先编译好的数据库，其中包含了人类已知的关于蛋白质的一切。这对于在我们的谜题中找到明显的亲缘体或“已知的罪犯”非常强大 [@problem_id:2432847]。

另一方面，我们有**监督式学习**，我们为自己的特定案例量身打造一个定制的侦探——一个机器学习模型。为了训练这个侦探，我们必须为它提供已标注的样本：“这个蛋白质是酶；这个不是。”模型会学习区分这两个类别的微妙模式。但困境也由此产生：这些标签中的每一个都是我们宝贵且昂贵的实验室实验的结果。专家一丝不苟地验证计算预测的这一过程被称为**人工校正**。要构建一个真正智能的模型，我们可能需要数千个这样的校正标签，这远远超出了我们的预算。

在这里，我们必须改变我们的视角。我们不应再将计算机仅仅看作一个预测引擎，将生物学家仅仅看作一个数据提供者。相反，让我们将他们的互动视为一场对话。[计算模型](@article_id:313052)做出一个预测，我们可以将其框定为一个**可证伪的假设**。实验室里的人工校正就是旨在检验该假设的**实验** [@problem_id:2383778]。如果这是一场科学对话，我们的目标就应该是使其尽可能高效和富有洞见。我们不想浪费时间让计算机生成我们已知答案的假设，也不想进行那些不会告诉我们任何新东西的实验。我们想问那个能让我们学到最多的问题。

### 更智能的对话：[主动学习](@article_id:318217)的核心

[主动学习](@article_id:318217)是关于提出最聪明问题的科学。生物学家不再随机选择要标注的蛋白质，而是由学习[算法](@article_id:331821)本身指出它最希望看到答案的未标注样本。那是哪个样本呢？直观上，这就是模型最感困惑的那个样本。

想象一下我们的模型正试图判断一个蛋白质是否是酶。对于一个蛋白质，它预测的概率是 $99.9\%$。对于另一个，它预测的概率是 $0.1\%$。在这两种情况下，模型都相当自信。得知真实答案可能会证实它的知识，但不会彻底改变它的世界观。但如果有一个蛋白质，模型预测的概率是 $50.1\%$ 呢？这基本上相当于模型在耸耸肩。它并没有真正的把握。揭示这一个高度不确定案例的真实标签可以提供大量信息，并极大地帮助模型完善其内部的决策边界。这种策略被称为**不确定性抽样**。

这个简单的想法是[主动学习](@article_id:318217)的引擎。我们从少量已标注的样本开始，训练一个初始模型。然后我们进入一个循环：

1.  模型在大量未标注数据中进行搜索。
2.  它识别出其最不确定的单个样本（或一批样本）。
3.  它将这个样本呈现给人类专家进行标注。
4.  这个宝贵的新标签被添加到我们的训练集中。
5.  模型用这个新信息重新训练，变得更智能一点。

通过重复这个循环，模型的准确性比我们给它随机选择的标签时提高得快得多。我们正将我们的实验预算精确地集中在它能产生最大影响的地方 [@problem_id:2383769]。

### 提问的艺术：细微之处与必要的复杂性

当然，现实世界从不那么简单。一个好的侦探知道，问“最令人困惑的”问题是一个很好的开始，但真正的精通需要更复杂的策略。

首先，一个聪明的模型，就像一个聪明的科学家一样，应该受到挑战。当我们初次构建一个分类器时，比如说用于识别[启动子](@article_id:316909)（基因的“开启”开关），我们不只想训练它区分[启动子](@article_id:316909)和随机的无意义 DNA。那太容易了。我们应该用**困难负样本**来训练它：那些*不是*[启动子](@article_id:316909)但共享其许多特征的 DNA 片段，比如位于基因组的活跃区域或具有相似的化学成分。这迫使模型忽略肤浅的线索，学习真正定义[启动子](@article_id:316909)的深层、特定的序列模式 [@problem_id:2429087]。这种“困难负样本挖掘”的原则是[主动学习](@article_id:318217)的近亲；两者都是关于策略性地选择[信息量](@article_id:333051)最大的样本进行学习。

其次，我们在生物学中寻找的许多东西都极其罕见——堪称基因组草堆中的那根针。对于每一个真正的[基因剪接](@article_id:335432)位点，都有数百万个几乎相同的序列作为诱饵 [@problem_id:2429066]。如果我们用这种“不平衡”的数据训练模型，它可以通过简单地学习永远说“不是[剪接](@article_id:324995)位点”来达到 $99.99\%$ 的准确率。这在准确率上是完美的，但却完全无用。为了解决这个问题，我们需要两样东西：更好的评估指标，能够奖励找到罕见正样本（如**[精确率-召回率曲线](@article_id:642156)下面积**，即 AUPRC），以及巧妙的训练技巧。一种这样的技巧是 **SMOTE**（合成少数类过采样技术），它通过在特征空间中仔细地在现有稀有类样本之间进行“插值”，来创建新的、合成的稀有类样本。但这伴随着一个严重的警告：这类技术必须极其小心地应用，并且只能用于训练数据，以避免意外地让你的模型看到期末考试的答案。

### 解读生命语言：从序列到向量

你可能想知道，一台由数字构成的机器——计算机，怎么可能“读取”由氨基酸组成的蛋白质序列。这个突破来自于一个从语言学借鉴来的想法：“观其伴，知其言。”（You shall know a word by the company it keeps.）事实证明，这对于氨基酸同样适用。

我们可以构建一种特殊的神经网络，其灵感来源于像 `word2vec` 这样的模型，并向其输入数百万条来自公共数据库的[蛋白质序列](@article_id:364232)。模型的任务很简单：对于序列中的每一个氨基酸，它尝试预测其邻居。它不需要任何标签或先前的生物学知识。通过简单地学习这些共现统计数据，模型会自动为 $20$ 种氨基酸中的每一种学习到一个密集的数值向量，即**[嵌入](@article_id:311541)** [@problem_id:2373389]。奇迹般地，这些学习到的向量捕捉到了深刻的生物化学真理：具有相似化学性质的氨基酸，如疏水性或带正电，最终会得到相似的向量。这种无监督[预训练](@article_id:638349)将离散的生命语言转变为一个丰富的、连续的数学空间，我们的[主动学习](@article_id:318217)侦探可以在其中开展工作。

### 关键时刻：我们是否在自欺欺人？

我们设计了一个巧妙的系统。我们有一个能解读蛋白质语言的模型，能与专家智能对话以高效学习，并能意识到现实世界的挑战。它在所见过的数据上表现出色。但在这里，我们必须停下来问一个在所有科学中都最重要的问题：我们怎么知道我们不是在自欺欺人？

科学史上充满了被丑陋事实扼杀的美丽理论。在机器学习中，最大的罪过是**乐观偏差**，它源于一种称为**[信息泄露](@article_id:315895)**的现象。要获得对我们模型性能的诚实评估，唯一的方法是在它训练、调优或主动选择过程中*从未*见过的数据上进行测试。这是我们的[留出测试集](@article_id:351891)，我们的期末考试。

在生物学中，这异常棘手。生命是进化的产物，序列以称为**[同源物](@article_id:371417)**的亲缘家族形式存在。在一个与你[训练集](@article_id:640691)中某个蛋白质有 $99\%$ 相同的蛋白质上测试你的模型，这不是一个公平的测试；这就像让一个学生在记住了 $2+3=5$ 之后去解 $x+y=5$。模型可能只是在识别一张熟悉的面孔，而不是在归纳一个深层的规则 [@problem_id:2406488]。事实证明，如果你随机地将蛋白质序列分割成[训练集](@article_id:640691)和[测试集](@article_id:641838)，你几乎可以肯定近亲会同时污染这两个集合 [@problem_id:2477427]。

唯一严谨的解决方案是在数据分离上做到毫不留情。我们必须首先描绘出我们数据集中所有的家族关系。然后，当我们创建交叉验证折叠时，我们必须将整个家族视为不可分割的块。一个完整的家族要么进入训练集，要么整个家族进入测试集——但它*绝不*被分割。这被称为**分组 k 折交叉验证**。

只有遵循如此严格的协议——隔离最终测试集，使用基于分组的分割来尊重进化历史，采用适合我们科学目标的评估指标，并使用配对统计检验来比较模型——我们最终才能提出一个站得住脚的主张 [@problem_id:2406488]。而故事也在这里回到了原点。最初，我们寻求最小化标注成本以达到一定的准确率。一个成熟的[主动学习](@article_id:318217)系统的最终目标不仅仅是达到一个目标，而是带着一份统计学保证来做到这一点。我们希望能够停止昂贵的循环，并以 $95\%$ 的置信度宣布，我们最终部署的模型在未来它将遇到的真实世界数据上，其性能将高于某个阈值 [@problem_id:2383769]。这是机器学习效率与科学和统计严谨性相遇的美妙、统一的终点。这不仅仅是关于构建一个更好的模型，更是关于证明它。