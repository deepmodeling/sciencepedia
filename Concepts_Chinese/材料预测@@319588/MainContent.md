## 引言
人类技术的进步，从可再生能源到下一代计算，从根本上都与发现具有非凡性能的新材料紧密相连。几个世纪以来，这一发现过程一直是一项缓慢而昂贵的工作，严重依赖于实验直觉和偶然的试错。本文探讨了向*理性材料设计*的[范式](@article_id:329204)转变，该领域致力于在材料于实验室中合成之前，就从原子层面进行预测和工程设计。文章将探索计算工具如何将[材料科学](@article_id:312640)从一门描述性学科转变为一门预测性学科。

在本文中，我们将深入探讨现代材料预测的两个主要支柱。第一章**“原理与机制”**将揭示第一性原理计算的“自下而上”世界，其中材料的性质源自物理学的基本定律；以及机器学习的“自上而下”领域，它从已知材料的海量数据集中学习模式。随后，**“应用与跨学科联系”**一章将展示这些预测方法如何应用于解决现实世界中的挑战，从设计稳定的[催化剂](@article_id:298981)到工程设计具有独特力学功能的合金。我们的旅程始于理解驱动这场革命的核心计算引擎。

## 原理与机制

想象一下，你想建造一座完美的沙堡。你可以尝试将沙子和水以随机比例混合，希望能偶然发现理想的稠度。或者，你可以理解颗粒材料的物理学和水表面[张力](@article_id:357470)的化学原理，并从这些基本规则中*计算*出完美的配方。预测和设计新材料的探索过程与此非常相似，但我们建造的不是沙堡，而是下一代[太阳能电池](@article_id:298527)、[催化剂](@article_id:298981)和[超导体](@article_id:370061)。我们的“配方”是[元素周期表](@article_id:299916)中的元素，而我们的“规则”是物理定律。

在本章中，我们将深入材料预测的核心，探索科学家们采用的两种宏大策略。第一种是“自下而上”的方法，从最基本的自然法则出发，[从头计算](@article_id:377535)材料的性质。第二种是“自上而下”的方法，从已知的庞大材料库中学习，以智能地预测未知材料的性质。我们将看到这两条曾经分离的道路，如今正如何融合成一个强大的发现引擎。

### 以物理为神谕：从第一性原理计算

在亚原子层面，一种材料是原子核和电子构成的繁华都市，所有这些粒子都通过优雅但极其复杂的量子力学定律相互作用。如果我们能为所有这些粒子解出薛定谔方程，原则上我们就能预测该材料的每一种性质。这就是**[第一性原理](@article_id:382249)（first-principles）**或**从头算（ab initio）**计算的梦想。

问题在于，对于任何比氢原子更复杂的体系，完整的薛定谔方程都极其难以求解。几十年来，这种复杂性似乎是一个不可逾越的障碍。突破来自于一种被称为**密度泛函理论（Density Functional Theory, DFT）**的巧妙问题重构。DFT的核心思想，也是为Walter Kohn赢得诺贝尔奖的思想，是一种优美的简化：我们不必追踪每个电子那复杂到不可能的舞蹈，只需知道平均电子密度$\rho(\mathbf{r})$——一个更简单的量，它只告诉我们电子在空间中任意点出现的可能性——就能获得最重要的信息，即系统最稳定构型下的总能量，也就是**[基态](@article_id:312876)**能量。

这是一个颠覆性的改变。**总能量**是万能钥匙。从中，我们可以解锁[材料性质](@article_id:307141)的宝库。

例如，许多化合物可以以不同的[晶体结构](@article_id:300816)存在，称为**多晶型**。金刚石和石墨都是纯碳，但它们的原子[排列](@article_id:296886)不同，赋予了它们截然不同的性质。哪种多晶型最稳定？自然界，出于经济原则，偏爱能量最低的[排列](@article_id:296886)方式。利用DFT，我们可以在计算机上构建一种化合物不同可能[晶体结构](@article_id:300816)的模型，计算每种结构的[基态能量](@article_id:327411)，并预测哪一种是真实、稳定的形态[@problem_id:1326691]。我们甚至可以更进一步。通过计算能量随体积的变化，我们可以预测在巨大压力下会发生什么。我们可以确定一种材料从一种[晶体结构](@article_id:300816)转变为另一种[晶体结构](@article_id:300816)的精确压力，这种[相变](@article_id:297531)可能会极大地改变其特性[@problem_id:1326691]。

我们能预测的另一个基本性质是材料是金属还是绝缘体。这取决于电子如何被组织成能级，即**[能带](@article_id:306995)**。如果填充[能带](@article_id:306995)与空[能带](@article_id:306995)之间存在一个[带隙](@article_id:331619)——一个不允许电子态存在的能量范围——那么该材料就是绝缘体或[半导体](@article_id:301977)。如果[能带](@article_id:306995)重叠，在最高电子能量（**费米能级**）处没有[带隙](@article_id:331619)，电子可以自由移动，那么该材料就是金属[@problem_id:2952836]。DFT使我们能够计算这整个电子能带结构，从而直接洞悉材料的电子灵魂。

然而，即使是我们最好的工具也有其局限性，理解这些局限性与了解它们的优点同样重要。DFT从其构造上就是一种**[基态](@article_id:312876)理论**[@problem_id:1999062]。它被严格设计用来寻找系统的最低能量状态。虽然[基态能量计算](@article_id:365124)得很准确，但涉及[电子激发](@article_id:363044)的性质，如[带隙](@article_id:331619)的大小，则更具挑战性。DFT计算中的未占据轨道并不能保证代表新加入电子的真实能量。因此，标准的DFT近似会系统性地低估[带隙](@article_id:331619)，有时甚至严重到错误地将[半导体](@article_id:301977)预测为金属。这个“[带隙问题](@article_id:304262)”并不意味着DFT是错误的；它只是提醒我们其理论基础。科学家们已经开发出更先进（且计算成本更高）的方法，如[杂化泛函](@article_id:344288)或$GW$近似，来修正这个问题，并为这些[激发态](@article_id:325164)性质获得更准确的预测[@problem_id:2952836]。

DFT的能力从静态性质延伸到动态功能。以催化为例，它是化学工业的支柱。好的[催化剂](@article_id:298981)能在不被消耗的情况下加速[化学反应](@article_id:307389)。对于像氧还原反应（ORR）这样对燃料电池至关重要的反应，其过程是在[催化剂](@article_id:298981)表面分步进行的。来自气相的分子必须降落并附着在表面（吸附），发生反应，然后离开。利用DFT，我们可以计算每个中间吸附态的自由能，比如在铂表面上的$*$OOH、$*$O和$*$OH [@problem_id:1577975]。反应的整体速率由“最难”的一步决定，即能量壁垒最高的那一步。通过计算这整个能量图景，我们可以从第一性原理计算出[催化剂](@article_id:298981)的理论效率，或称**过电势**。这使我们能够在计算机上筛选数千种潜在的[催化剂](@article_id:298981)材料，在实验室合成之前就识别出最有希望的候选者。

### 学习的艺术：数据驱动的发现

[第一性原理计算](@article_id:377535)功能极其强大，但它们对计算能力的需求也极为贪婪。计算一种简单材料的性质可能需要数小时或数天。用这种方式筛选数百万种可能性是根本不可行的。这正是第二种宏大策略——**机器学习（Machine Learning, ML）**——发挥作用的地方。

这个想法非常直观。如果一位人类科学家经过多年的经验，能够培养出一种“直觉”，判断哪些元素可能组成好的磁体或坚固的合金，为什么计算机不能做同样的事情，而且还能访问整个已知材料库？[材料科学](@article_id:312640)中机器学习的目标是学习材料的成分和结构（输入）与其最终性质（输出）之间复杂而隐藏的关系。

这种关系很少是简单的。想象一下，试图预测一种材料的压电系数——它在受压时产生电压的能力。你可能会从一个简单的**[线性回归](@article_id:302758)模型**开始，假设该性质随着某个输入特征（如其原子间的电负性差异）呈直线式增长。对于一些简单的趋势，这可能行得通。但对于复杂的量子现象，这样的假设可能大错特错。真实材料的性质常常表现出[线性模型](@article_id:357202)无法捕捉的尖峰或非线性行为。在这些情况下，我们需要更复杂的模型，如**[支持向量机](@article_id:351259)**或**[神经网络](@article_id:305336)**，它们可以学习高度非线性、灵活的函数。一个测试案例可能会显示，线性模型的误差比非[线性模型](@article_id:357202)大400倍，这戏剧性地证明了为工作选择正确工具的必要性[@problem_id:1312273]。

那么，这些更复杂的模型是如何施展魔法的呢？机器学习中最优雅的概念之一是**[集成学习](@article_id:639884)**，其典型代表是**[随机森林](@article_id:307083)**模型[@problem_id:1312314]。[随机森林](@article_id:307083)不是试[图构建](@article_id:339529)一个单一、完美、“天才”式的模型，而是构建一支由简单、不完美的模型（称为“决策树”）组成的军队。每棵树都在数据的随机[子集和](@article_id:339599)特征的随机子集上进行训练。单独来看，每棵树可能是一个糟糕的预测器，就像一个视野非常狭窄的单个人。但是为了做出最终预测，[随机森林](@article_id:307083)会从其“森林”中的所有树那里进行多数投票。这种“群体智慧”的方法非常有效地抵消了简单模型的个体错误和偏见，从而得出一个既准确又稳健的最终预测。例如，如果我们问一个由13棵树组成的森林，一种新材料是否是“光伏活性”的，如果有9棵树投票“是”，那么最终的预测就是“是”，置信度为$\frac{9}{13}$，约等于0.692 [@problem_id:1312314]。

### 前沿：信任、不确定性与真正的发现

很长一段时间里，材料预测中基于物理和数据驱动的阵营在各自的世界里运作。但最激动人心的进展正发生在它们的交汇处。如果我们能将DFT的准确性与机器学习的速度结合起来呢？

这就是**[机器学习原子间势](@article_id:344521)（Machine Learning Interatomic Potentials, MLIPs）**背后的思想。我们可以利用DFT进行少量、非常昂贵的计算，来描绘出材料的[能量景观](@article_id:308140)——即当我们移动原子时能量如何变化。然后，我们可以训练一个神经网络来学习这个景观。一旦训练完成，MLIP可以在一秒钟的一小部[分时](@article_id:338112)间内预测任何新原子构型的能量和力，其准确性堪比原始的DFT计算[@problem_id:73177]。这给了我们一个充当超快速神谕的“代理”模型，使我们能够模拟大尺度系统和长时间尺度，这是直接用DFT无法完成的任务。

这就引出了现代科学中一个最重要的问题：如果一台机器给出了一个预测，我们应该在多大程度上信任它？一个单独的数字是不够的；我们需要知道模型对这个数字的[置信度](@article_id:361655)。这就是**[不确定性量化](@article_id:299045)**的科学。

预测中的不确定性有两种类型[@problem_id:73062]。第一种是**[偶然不确定性](@article_id:314423)**，它来自数据本身。这是系统中固有的噪声或随机性，任何模型，无论多好，都无法消除。可以把它想象成收音机频道上无法消除的静电噪音。第二种，也是更有趣的类型，是**认知不确定性**，它来自于模型自身的知识缺乏。如果我们要求一个模型对它从未见过的材料类型进行预测，它的认知不确定性就会很高。这本质上是模型在说：“我这是在猜。”一个估计这种不确定性的有力方法是使用我们前面看到的模型集成。[偶然不确定性](@article_id:314423)是每个模型预测的不确定性的平均值。认知不确定性则是衡量各[模型平均](@article_id:639473)预测值之间*分歧*程度的指标。如果它们都预测相同的值，它们就很有信心。如果它们的预测值五花八门，它们就不确定[@problem_id:73062]。

这种对不确定性的认知不仅仅是学术性的，它具有深远的实用价值。利用像**保形预测**这样的技术，我们可以将[不确定性估计](@article_id:370131)转化为一个严格的**[预测区间](@article_id:640082)**[@problem_id:66043]。模型不再是预测一种材料的性质是，比如说，410，而是可以预测它在405到415之间，[置信度](@article_id:361655)为90%。这是通过首先在一个“校准”数据集上测试模型，看它自身的[不确定性估计](@article_id:370131)与其真实误差的匹配程度来实现的。由此，我们得出一个校正因子，使我们能够为未来未见的材料构建具有统计有效性的[预测区间](@article_id:640082)[@problem_id:66043]。

这引导我们走向任何预测引擎的终极考验。模型仅仅是在**[内插](@article_id:339740)**——即对它已经见过的数据点之间的点做出聪明的猜测？还是它能够真正地**外推**——对全新的事物做出成功的预测？这就像一个学生记住了过去考试的答案，和另一个深刻理解了学科以至于能解决从未见过的问题的学生之间的区别。

标准的[机器学习评估](@article_id:640564)，即使用随机划分的训练集和[测试集](@article_id:641838)，主要测试的是内插能力。测试集可能包含新的化合物，但其组成元素和[晶体结构](@article_id:300816)几乎肯定在[训练集](@article_id:640691)中出现过。一种更具揭示性的测试是刻意的**分布外**评估[@problem_id:2479777]。例如，在一次**留一元素交叉验证**中，我们用一个移除了所有含金（Au）化合物的数据集来训练模型。然后，我们测试它预测含金化合物性质的能力。这迫使模型去泛化它对元素周期表的“理解”，而不是依赖于关于金的记忆事实。如果模型的误差飙升，我们就知道它没有学到潜在的物理规律。如果它成功了，我们就向着一个真正的智能发现伙伴迈进了一步[@problem_id:2479777]。

材料预测的旅程是科学进步本身的缩影：从基本原理出发，从经验中学习，最重要的是，在我们探索未知时，严格地质疑和量化我们自己的确定性。