{"hands_on_practices": [{"introduction": "To build a solid foundation, we begin with the simplest yet most illustrative case: minimizing a convex quadratic energy functional. This type of problem is the bedrock of linear finite element analysis. By first deriving the exact, optimal step length and then comparing it to the step accepted by a practical backtracking algorithm, you will gain a concrete, quantitative understanding of how the Armijo condition works to provide an efficient and reliable approximation of the ideal step [@problem_id:2573793].", "problem": "Consider the quadratic energy arising from the finite element discretization of linear elasticity,\n$$J(u) = \\tfrac{1}{2}\\,u^{\\top} K u - f^{\\top} u,$$\nwhere $K \\in \\mathbb{R}^{2 \\times 2}$ is a symmetric positive definite (SPD) stiffness matrix and $f \\in \\mathbb{R}^{2}$ is the load vector. Let\n$$K = \\begin{pmatrix} 8  -2 \\\\ -2  5 \\end{pmatrix}, \\qquad f = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}, \\qquad u^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}.$$\nAdopt the standard Euclidean inner product and the steepest descent direction $p^{(0)} = -\\nabla J(u^{(0)})$. Starting from the definitions of gradient and directional derivative of $J$ and the Armijo sufficient decrease condition, do the following:\n\n1) Derive from first principles the exact step length $\\alpha_{\\star}$ that minimizes $J(u^{(0)} + \\alpha\\, p^{(0)})$ along the steepest descent direction.\n\n2) Using a backtracking line search with Armijo parameter $c_{1} = 10^{-4}$, initial trial step $\\alpha_{0} = 1$, and reduction factor $\\rho = \\tfrac{1}{2}$, determine the accepted backtracking step $\\alpha_{\\mathrm{bt}}$ at $u^{(0)}$ (that is, the first $\\alpha$ in the sequence $\\{ \\alpha_{0}, \\rho \\alpha_{0}, \\rho^{2} \\alpha_{0}, \\dots \\}$ that satisfies the Armijo condition).\n\n3) Report the ratio $\\alpha_{\\mathrm{bt}}/\\alpha_{\\star}$ as a single reduced fraction. No rounding is required.", "solution": "The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution. The stiffness matrix $K$ is symmetric. Its positive definiteness is confirmed by Sylvester's criterion: the first leading principal minor is $\\det(8) = 8 > 0$, and the second is $\\det(K) = (8)(5) - (-2)(-2) = 40 - 4 = 36 > 0$. As $K$ is symmetric positive definite (SPD), the quadratic functional $J(u)$ is strictly convex and has a unique minimum. We proceed with the solution.\n\nThe quadratic energy functional is given by\n$$J(u) = \\frac{1}{2}u^{\\top} K u - f^{\\top} u.$$\nThe gradient of this functional with respect to $u$ is found using matrix calculus. The derivative of the quadratic term $\\frac{1}{2}u^{\\top} K u$ is $\\frac{1}{2}(K + K^{\\top})u$, and the derivative of the linear term $-f^{\\top} u$ is $-f$. Since the stiffness matrix $K$ is symmetric ($K = K^{\\top}$), the gradient simplifies to\n$$\\nabla J(u) = K u - f.$$\nWe are given the initial point $u^{(0)} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$. At this point, the gradient is\n$$\\nabla J(u^{(0)}) = K u^{(0)} - f = K \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - f = -f = -\\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -1 \\end{pmatrix}.$$\nThe steepest descent direction $p^{(0)}$ is defined as the negative of the gradient at $u^{(0)}$:\n$$p^{(0)} = -\\nabla J(u^{(0)}) = -(-f) = f = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}.$$\n\n1) First, we derive the exact step length $\\alpha_{\\star}$. This is the value of $\\alpha > 0$ that minimizes the one-dimensional function $\\phi(\\alpha) = J(u^{(0)} + \\alpha p^{(0)})$.\n$$\\phi(\\alpha) = J(u^{(0)} + \\alpha p^{(0)}) = \\frac{1}{2}(u^{(0)} + \\alpha p^{(0)})^{\\top} K (u^{(0)} + \\alpha p^{(0)}) - f^{\\top}(u^{(0)} + \\alpha p^{(0)}).$$\nSubstituting $u^{(0)} = 0$, the expression simplifies:\n$$\\phi(\\alpha) = \\frac{1}{2}(\\alpha p^{(0)})^{\\top} K (\\alpha p^{(0)}) - f^{\\top}(\\alpha p^{(0)}) = \\frac{1}{2}\\alpha^{2} (p^{(0)})^{\\top} K p^{(0)} - \\alpha f^{\\top} p^{(0)}.$$\nTo find the minimum of this quadratic function of $\\alpha$, we set its derivative with respect to $\\alpha$ to zero:\n$$\\frac{d\\phi}{d\\alpha} = \\alpha (p^{(0)})^{\\top} K p^{(0)} - f^{\\top} p^{(0)} = 0.$$\nSolving for $\\alpha$ gives the exact step length $\\alpha_{\\star}$:\n$$\\alpha_{\\star} = \\frac{f^{\\top} p^{(0)}}{(p^{(0)})^{\\top} K p^{(0)}}.$$\nSince $p^{(0)} = f$, we can write this as\n$$\\alpha_{\\star} = \\frac{f^{\\top} f}{f^{\\top} K f}.$$\nWe now compute the necessary quantities with the given $K$ and $f$:\n$$f^{\\top} f = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2^{2} + 1^{2} = 4 + 1 = 5.$$\n$$K f = \\begin{pmatrix} 8  -2 \\\\ -2  5 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} (8)(2) + (-2)(1) \\\\ (-2)(2) + (5)(1) \\end{pmatrix} = \\begin{pmatrix} 16 - 2 \\\\ -4 + 5 \\end{pmatrix} = \\begin{pmatrix} 14 \\\\ 1 \\end{pmatrix}.$$\n$$f^{\\top} K f = \\begin{pmatrix} 2  1 \\end{pmatrix} \\begin{pmatrix} 14 \\\\ 1 \\end{pmatrix} = (2)(14) + (1)(1) = 28 + 1 = 29.$$\nSubstituting these values, we find the exact step length:\n$$\\alpha_{\\star} = \\frac{5}{29}.$$\n\n2) Next, we find the accepted backtracking step length $\\alpha_{\\mathrm{bt}}$. The backtracking line search starts with an initial trial step $\\alpha_{0}=1$ and iteratively reduces it by a factor $\\rho = \\frac{1}{2}$ until the Armijo sufficient decrease condition is met. The Armijo condition is\n$$J(u^{(k)} + \\alpha p^{(k)}) \\le J(u^{(k)}) + c_{1} \\alpha \\nabla J(u^{(k)})^{\\top} p^{(k)}.$$\nFor our problem at the initial step ($k=0$), this becomes\n$$J(u^{(0)} + \\alpha p^{(0)}) \\le J(u^{(0)}) + c_{1} \\alpha \\nabla J(u^{(0)})^{\\top} p^{(0)}.$$\nWe evaluate each term:\n$$J(u^{(0)}) = J(\\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}) = \\frac{1}{2}(0) - 0 = 0.$$\n$$\\nabla J(u^{(0)})^{\\top} p^{(0)} = (-f)^{\\top} f = -f^{\\top} f = -5.$$\n$$J(u^{(0)} + \\alpha p^{(0)}) = \\phi(\\alpha) = \\frac{1}{2}\\alpha^{2} (p^{(0)})^{\\top} K p^{(0)} - \\alpha f^{\\top} p^{(0)} = \\frac{29}{2}\\alpha^{2} - 5\\alpha.$$\nThe Armijo condition is thus\n$$\\frac{29}{2}\\alpha^{2} - 5\\alpha \\le 0 + c_{1} \\alpha (-5) = -5 c_{1} \\alpha.$$\nSince $\\alpha$ must be positive, we can divide by $\\alpha$:\n$$\\frac{29}{2}\\alpha - 5 \\le -5 c_{1}.$$\n$$\\frac{29}{2}\\alpha \\le 5 - 5 c_{1} = 5(1 - c_{1}).$$\n$$\\alpha \\le \\frac{10}{29}(1 - c_{1}).$$\nUsing the given Armijo parameter $c_{1} = 10^{-4}$:\n$$\\alpha \\le \\frac{10}{29}(1 - 10^{-4}) = \\frac{10}{29}(0.9999) = \\frac{9.999}{29}.$$\nNow we test the sequence of trial steps $\\alpha = \\{1, \\frac{1}{2}, \\frac{1}{4}, \\dots \\}$.\n- Test $\\alpha = 1$: Is $1 \\le \\frac{9.999}{29}$? No, since $29 > 9.999$. Reject.\n- Test $\\alpha = \\frac{1}{2}$: Is $\\frac{1}{2} \\le \\frac{9.999}{29}$? This is equivalent to $29 \\le 2(9.999) = 19.998$. No. Reject.\n- Test $\\alpha = \\frac{1}{4}$: Is $\\frac{1}{4} \\le \\frac{9.999}{29}$? This is equivalent to $29 \\le 4(9.999) = 39.996$. Yes. Accept.\nThe first step length to satisfy the condition is $\\alpha = \\frac{1}{4}$. Thus, the accepted backtracking step is\n$$\\alpha_{\\mathrm{bt}} = \\frac{1}{4}.$$\n\n3) Finally, we compute the ratio of the backtracking step to the exact step:\n$$\\frac{\\alpha_{\\mathrm{bt}}}{\\alpha_{\\star}} = \\frac{1/4}{5/29} = \\frac{1}{4} \\cdot \\frac{29}{5} = \\frac{29}{20}.$$\nThis fraction is already in simplest form as $29$ is a prime number and $20$ is not a multiple of $29$.", "answer": "$$\\boxed{\\frac{29}{20}}$$", "id": "2573793"}, {"introduction": "While ensuring a sufficient decrease in energy is fundamental, it is not the whole story, especially for the high-performance quasi-Newton methods prevalent in modern FEA. This exercise moves beyond simple descent by introducing the crucial strong Wolfe curvature condition, which ensures that the step length is not excessively small and provides enough information to build stable Hessian approximations. Through this practice, you will dissect the interplay between the Armijo and Wolfe conditions and understand why satisfying both is essential for achieving the rapid, superlinear convergence expected from these advanced solvers [@problem_id:2573854].", "problem": "Consider a one-dimensional finite element discretization of a linear elastic energy with total potential \n$$\n\\Pi(u)=\\frac{1}{2} a\\, u^{2},\n$$\nwhere $a > 0$ is a material-stiffness-like parameter and $u \\in \\mathbb{R}$ is the degree of freedom. Suppose we minimize $\\Pi(u)$ using a descent method with a line search globalization strategy. At iterate $u_{k}=1$, the gradient is $g_{k}=\\nabla \\Pi(u_{k})$ and the search direction is chosen as $d_{k}=-g_{k}$. A step length $\\alpha_{k}0$ is selected by a line search using the standard sufficient decrease (Armijo) condition together with the strong Wolfe curvature condition, each with constants $c_{1}\\in (0,1)$ and $c_{2}\\in (0,1)$ with $c_{1}c_{2}$.\n\nStarting from the foundational definitions of differentiability, the first-order Taylor expansion of $\\Pi(u)$, and the gradient-based sufficient decrease and curvature concepts used in line searches, do the following:\n- Derive analytic conditions on the step length $\\alpha_{k}$ under which the Armijo condition is satisfied for the function $\\Pi(u)$ along the direction $d_{k}$ at $u_{k}=1$.\n- Derive analytic conditions on the step length $\\alpha_{k}$ under which the strong Wolfe curvature condition is satisfied along the same direction.\n- Using the specific constants $a=2$, $c_{1}=\\frac{1}{10}$, and $c_{2}=\\frac{4}{5}$, determine the supremum value of $\\alpha_{k}$ such that the Armijo condition holds but the strong Wolfe curvature condition fails. Express your final answer as an exact fraction with no units.\n- Briefly discuss, using first principles of quasi-Newton updates for approximate Hessians in nonlinear finite element equilibrium, the consequence of accepting step lengths that satisfy only Armijo but violate the strong Wolfe curvature condition on the possibility of achieving superlinear convergence.\n\nYour final boxed answer must be only the requested supremum value of $\\alpha_{k}$ as an exact fraction. No rounding is required.", "solution": "The foundational principle for gradient-based optimization is the first-order Taylor expansion of a differentiable function $\\Pi$ around a point $u_{k}$:\n$$\n\\Pi(u_{k} + \\delta u) = \\Pi(u_{k}) + \\nabla \\Pi(u_{k})^{T} \\delta u + o(||\\delta u||)\n$$\nFor a line search, we set $\\delta u = \\alpha d_{k}$, where $d_{k}$ is a search direction and $\\alpha  0$ is the step length. For a descent method, we require the directional derivative to be negative: $\\nabla \\Pi(u_{k})^{T} d_{k}  0$.\n\nLet us define the objective function along the search direction as a function of the step length $\\alpha$:\n$$\n\\phi(\\alpha) = \\Pi(u_{k} + \\alpha d_{k})\n$$\nThe derivative of $\\phi(\\alpha)$ with respect to $\\alpha$ is given by the chain rule:\n$$\n\\phi'(\\alpha) = \\frac{d}{d\\alpha} \\Pi(u_{k} + \\alpha d_{k}) = \\nabla \\Pi(u_{k} + \\alpha d_{k})^{T} d_{k}\n$$\nIn particular, $\\phi'(0) = \\nabla \\Pi(u_{k})^{T} d_{k} = g_{k}^{T} d_{k}$.\n\nFor the given problem, $\\Pi(u) = \\frac{1}{2} a u^{2}$. The gradient is $\\nabla \\Pi(u) = \\frac{d\\Pi}{du} = a u$.\nAt the iterate $u_{k}=1$, the gradient is $g_{k} = \\nabla \\Pi(1) = a(1) = a$.\nThe search direction is the steepest descent direction, $d_{k} = -g_{k} = -a$.\nThe directional derivative at $\\alpha=0$ is $\\phi'(0) = g_{k}^{T} d_{k} = (a)(-a) = -a^{2}$. Since $a>0$, we have $-a^{2}0$, confirming that $d_{k}$ is a descent direction.\n\nThe function $\\phi(\\alpha)$ is:\n$$\n\\phi(\\alpha) = \\Pi(u_{k} + \\alpha d_{k}) = \\Pi(1 + \\alpha(-a)) = \\Pi(1 - a\\alpha) = \\frac{1}{2} a (1 - a\\alpha)^{2}\n$$\nThe derivative $\\phi'(\\alpha)$ is:\n$$\n\\phi'(\\alpha) = a(1 - a\\alpha) \\cdot (-a) = -a^{2}(1 - a\\alpha)\n$$\n\nFirst, we derive the condition for the sufficient decrease (Armijo) condition. This condition is stated as:\n$$\n\\Pi(u_{k} + \\alpha_{k} d_{k}) \\le \\Pi(u_{k}) + c_{1} \\alpha_{k} \\nabla \\Pi(u_{k})^{T} d_{k}\n$$\nIn terms of $\\phi$, this is $\\phi(\\alpha_{k}) \\le \\phi(0) + c_{1} \\alpha_{k} \\phi'(0)$.\nSubstituting the expressions for our specific problem:\n$$\n\\frac{1}{2} a (1 - a\\alpha_{k})^{2} \\le \\frac{1}{2} a (1)^{2} + c_{1} \\alpha_{k} (-a^{2})\n$$\nSince $a0$, we can divide the inequality by $\\frac{a}{2}$:\n$$\n(1 - a\\alpha_{k})^{2} \\le 1 - 2 c_{1} a\\alpha_{k}\n$$\nExpanding the left side:\n$$\n1 - 2a\\alpha_{k} + a^{2}\\alpha_{k}^{2} \\le 1 - 2 c_{1} a\\alpha_{k}\n$$\nSubtracting $1$ and rearranging gives:\n$$\na^{2}\\alpha_{k}^{2} - 2a\\alpha_{k} + 2 c_{1} a\\alpha_{k} \\le 0\n$$\n$$\na^{2}\\alpha_{k}^{2} - 2a\\alpha_{k}(1 - c_{1}) \\le 0\n$$\nSince $\\alpha_{k}0$ and $a0$, we can divide by $a\\alpha_{k}$:\n$$\na\\alpha_{k} - 2(1 - c_{1}) \\le 0\n$$\nThe analytic condition on $\\alpha_{k}$ for the Armijo condition to be satisfied is:\n$$\n\\alpha_{k} \\le \\frac{2(1 - c_{1})}{a}\n$$\n\nSecond, we derive the condition for the strong Wolfe curvature condition. This condition is stated as:\n$$\n|\\nabla \\Pi(u_{k} + \\alpha_{k} d_{k})^{T} d_{k}| \\le c_{2} |\\nabla \\Pi(u_{k})^{T} d_{k}|\n$$\nIn terms of $\\phi$, this is $|\\phi'(\\alpha_{k})| \\le c_{2} |\\phi'(0)|$.\nSubstituting the expressions for our problem:\n$$\n|-a^{2}(1 - a\\alpha_{k})| \\le c_{2} |-a^{2}|\n$$\nSince $a^{2}0$, we can simplify this to:\n$$\n|1 - a\\alpha_{k}| \\le c_{2}\n$$\nThis absolute value inequality is equivalent to the pair of inequalities:\n$$\n-c_{2} \\le 1 - a\\alpha_{k} \\le c_{2}\n$$\nFrom the left inequality, $a\\alpha_{k} - 1 \\le c_{2}$, which implies $a\\alpha_{k} \\le 1 + c_{2}$, so $\\alpha_{k} \\le \\frac{1 + c_{2}}{a}$.\nFrom the right inequality, $1 - c_{2} \\le a\\alpha_{k}$, which implies $\\alpha_{k} \\ge \\frac{1 - c_{2}}{a}$.\nThe analytic condition on $\\alpha_{k}$ for the strong Wolfe curvature condition to be satisfied is:\n$$\n\\frac{1 - c_{2}}{a} \\le \\alpha_{k} \\le \\frac{1 + c_{2}}{a}\n$$\n\nThird, we use the specific constants $a=2$, $c_{1}=\\frac{1}{10}$, and $c_{2}=\\frac{4}{5}$ to find the supremum of $\\alpha_{k}$ for which the Armijo condition holds but the strong Wolfe curvature condition fails.\n\nThe Armijo condition holds for $\\alpha_{k}  0$ such that:\n$$\n\\alpha_{k} \\le \\frac{2(1 - \\frac{1}{10})}{2} = 1 - \\frac{1}{10} = \\frac{9}{10}\n$$\nSo, the set of acceptable step lengths under the Armijo condition is $S_{A} = (0, \\frac{9}{10}]$.\n\nThe strong Wolfe curvature condition holds for $\\alpha_{k}$ such that:\n$$\n\\frac{1 - \\frac{4}{5}}{2} \\le \\alpha_{k} \\le \\frac{1 + \\frac{4}{5}}{2}\n$$\n$$\n\\frac{1/5}{2} \\le \\alpha_{k} \\le \\frac{9/5}{2}\n$$\n$$\n\\frac{1}{10} \\le \\alpha_{k} \\le \\frac{9}{10}\n$$\nThe set of step lengths for which the strong Wolfe condition holds is $S_{W} = [\\frac{1}{10}, \\frac{9}{10}]$.\n\nWe seek the set of $\\alpha_{k}$ where the Armijo condition is satisfied AND the strong Wolfe condition is violated. This corresponds to the set $S = S_{A} \\setminus S_{W}$.\n$$\nS = \\left(0, \\frac{9}{10}\\right] \\setminus \\left[\\frac{1}{10}, \\frac{9}{10}\\right]\n$$\nThe resulting set is $S = (0, \\frac{1}{10})$.\n\nThe problem asks for the supremum value of $\\alpha_{k}$ in this set $S$. The supremum of the open interval $(0, \\frac{1}{10})$ is its upper boundary.\n$$\n\\sup(S) = \\sup\\left(0, \\frac{1}{10}\\right) = \\frac{1}{10}\n$$\n\n#### Discussion on Quasi-Newton Methods\nQuasi-Newton methods, such as BFGS, construct an approximation to the inverse Hessian matrix, denoted $B_{k}$. A requirement for the stability of these methods and for the preservation of the positive-definiteness of $B_{k}$ is the so-called curvature condition: $y_{k}^{T} s_{k}  0$, where $s_{k} = u_{k+1} - u_{k} = \\alpha_{k}d_{k}$ and $y_{k} = g_{k+1} - g_{k}$. The standard BFGS update formula for $B_{k+1}$ involves the term $y_{k}^{T} s_{k}$ in the denominator, making this condition critical.\n\nThe Wolfe curvature condition is specifically designed to enforce this. We examine the term $y_{k}^{T} s_{k}$:\n$$\ny_{k}^{T} s_{k} = (g_{k+1} - g_{k})^{T} (\\alpha_{k} d_{k}) = \\alpha_{k}(g_{k+1}^{T} d_{k} - g_{k}^{T} d_{k})\n$$\nThe weak Wolfe curvature condition is $g_{k+1}^{T} d_{k} \\ge c_{2} g_{k}^{T} d_{k}$. Since the strong Wolfe condition implies the weak one, satisfying it means:\n$$\ny_{k}^{T} s_{k} \\ge \\alpha_{k}(c_{2} g_{k}^{T} d_{k} - g_{k}^{T} d_{k}) = \\alpha_{k}(c_{2}-1) g_{k}^{T} d_{k}\n$$\nFor a descent direction, $g_{k}^{T} d_{k}  0$. Since $\\alpha_{k}0$ and $c_{2} \\in (0,1)$, the term $(c_{2}-1)$ is negative. The product of three terms—$\\alpha_{k}(+)$, $(c_{2}-1)(-)$, and $g_{k}^{T} d_{k}(-)$—is positive. Thus, the Wolfe curvature condition ensures $y_{k}^{T} s_{k}  0$.\n\nIf a step length is accepted that satisfies only the Armijo condition and violates the curvature condition, there is no guarantee that $y_{k}^{T} s_{k}  0$. If $y_{k}^{T} s_{k} \\le 0$, the Hessian approximation $B_{k+1}$ can become non-positive-definite or the update may fail entirely (division by zero). A non-positive-definite $B_{k+1}$ may generate a subsequent search direction $d_{k+1} = -B_{k+1}g_{k+1}$ that is not a descent direction, causing the optimization to stall or fail. The entire theoretical basis for the superlinear convergence of quasi-Newton methods hinges on the Hessian approximations converging to the true Hessian in a well-defined manner, a process that requires the positive-definiteness to be maintained. Violating the curvature condition breaks this mechanism, precluding the possibility of achieving superlinear convergence.", "answer": "$$\n\\boxed{\\frac{1}{10}}\n$$", "id": "2573854"}, {"introduction": "We now confront a challenge central to real-world nonlinear analysis: non-convexity, where the tangent stiffness matrix can become indefinite. Such situations are common in models of structural buckling or material failure, and they can cause standard energy-based line searches to fail because the Newton direction may no longer point \"downhill\" on the energy landscape. This pivotal exercise demonstrates this failure mode and reveals why a merit function based on the norm of the residual vector offers a more robust globalization strategy, guiding the solver toward an equilibrium state even when the potential energy landscape is complex [@problem_id:2573788].", "problem": "Consider a nonlinear finite element (FE) equilibrium problem derived from a hyperelastic total potential energy $\\Pi(\\mathbf{u})$, with residual $\\mathbf{R}(\\mathbf{u}) = \\nabla \\Pi(\\mathbf{u})$ and consistent tangent $\\mathbf{K}(\\mathbf{u}) = \\nabla^{2} \\Pi(\\mathbf{u})$. A globalization via line search considers trial states $\\mathbf{u}(\\alpha) = \\mathbf{u}^{k} + \\alpha \\mathbf{p}^{k}$ for $\\alpha \\ge 0$, where the Newton direction $\\mathbf{p}^{k}$ solves $\\mathbf{K}^{k}\\mathbf{p}^{k} = -\\mathbf{R}^{k}$ with $\\mathbf{R}^{k} = \\mathbf{R}(\\mathbf{u}^{k})$ and $\\mathbf{K}^{k} = \\mathbf{K}(\\mathbf{u}^{k})$. Two acceptance criteria are commonly used: decrease of the energy $\\Pi$ and decrease of a residual-based merit function $M(\\alpha) = \\tfrac{1}{2}\\|\\mathbf{R}(\\mathbf{u}(\\alpha))\\|_{2}^{2}$.\n\nAssume a local quadratic model is exact around $\\mathbf{u}^{k}$, so that for any increment $\\mathbf{s}$ one has $\\Pi(\\mathbf{u}^{k}+\\mathbf{s}) = \\Pi(\\mathbf{u}^{k}) + \\mathbf{R}^{k\\top}\\mathbf{s} + \\tfrac{1}{2}\\mathbf{s}^{\\top}\\mathbf{K}^{k}\\mathbf{s}$ and $\\mathbf{R}(\\mathbf{u}^{k}+\\mathbf{s}) = \\mathbf{R}^{k} + \\mathbf{K}^{k}\\mathbf{s}$. At the current iterate, let\n- $\\mathbf{R}^{k} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$,\n- $\\mathbf{K}^{k} = \\mathrm{diag}(1,-1)$.\n\nUsing the exact Newton direction $\\mathbf{p}^{k} = -(\\mathbf{K}^{k})^{-1}\\mathbf{R}^{k}$ and the line $\\mathbf{u}(\\alpha) = \\mathbf{u}^{k} + \\alpha \\mathbf{p}^{k}$:\n\n- Derive explicit expressions for $\\Delta \\Pi(\\alpha) := \\Pi(\\mathbf{u}(\\alpha)) - \\Pi(\\mathbf{u}^{k})$ and $M(\\alpha) := \\tfrac{1}{2}\\|\\mathbf{R}(\\mathbf{u}(\\alpha))\\|_{2}^{2}$ as functions of $\\alpha$.\n- Prove that there exists a nonempty interval of $\\alpha$ for which $\\Delta \\Pi(\\alpha)$ is strictly positive while $M(\\alpha)$ is strictly decreasing, thereby demonstrating that a residual-merit line search will accept steps that an energy-decrease line search would reject.\n- Compute the smallest positive step length $\\alpha$ such that $\\Pi(\\mathbf{u}(\\alpha)) = \\Pi(\\mathbf{u}^{k})$. Report this value as your final answer (dimensionless).\n- Based on your derivation, give a concise argument about which acceptance criterion (energy decrease versus residual-merit decrease) more directly reflects convergence to equilibrium in FE.\n\nYour final reported answer must be the single value of the smallest positive $\\alpha$ for which $\\Pi(\\mathbf{u}(\\alpha)) = \\Pi(\\mathbf{u}^{k})$. No rounding is required.", "solution": "The first task is to compute the Newton direction $\\mathbf{p}^{k}$. Given $\\mathbf{K}^{k}\\mathbf{p}^{k} = -\\mathbf{R}^{k}$, we solve for $\\mathbf{p}^{k}$:\n$$\n\\mathbf{p}^{k} = -(\\mathbf{K}^{k})^{-1}\\mathbf{R}^{k}\n$$\nThe tangent matrix is $\\mathbf{K}^{k} = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$. Its inverse is $(\\mathbf{K}^{k})^{-1} = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$, which is identical to $\\mathbf{K}^{k}$.\nWith $\\mathbf{R}^{k} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$, the direction is:\n$$\n\\mathbf{p}^{k} = - \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = - \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}\n$$\n\nNext, we derive the expression for the change in potential energy, $\\Delta \\Pi(\\alpha) = \\Pi(\\mathbf{u}(\\alpha)) - \\Pi(\\mathbf{u}^{k})$.\nUsing the provided quadratic model with the increment $\\mathbf{s} = \\alpha \\mathbf{p}^{k}$:\n$$\n\\Delta \\Pi(\\alpha) = \\mathbf{R}^{k\\top}(\\alpha \\mathbf{p}^{k}) + \\frac{1}{2}(\\alpha \\mathbf{p}^{k})^{\\top}\\mathbf{K}^{k}(\\alpha \\mathbf{p}^{k}) = \\alpha (\\mathbf{R}^{k\\top}\\mathbf{p}^{k}) + \\frac{1}{2}\\alpha^{2} (\\mathbf{p}^{k\\top}\\mathbf{K}^{k}\\mathbf{p}^{k})\n$$\nWe compute the scalar products:\nThe directional derivative of $\\Pi$ along $\\mathbf{p}^{k}$ at $\\mathbf{u}^k$ is $\\mathbf{R}^{k\\top}\\mathbf{p}^{k}$:\n$$\n\\mathbf{R}^{k\\top}\\mathbf{p}^{k} = \\begin{pmatrix} 1  2 \\end{pmatrix} \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = (1)(-1) + (2)(2) = -1 + 4 = 3\n$$\nThe quadratic term is $\\mathbf{p}^{k\\top}\\mathbf{K}^{k}\\mathbf{p}^{k}$. Using the definition $\\mathbf{K}^{k}\\mathbf{p}^{k} = -\\mathbf{R}^{k}$:\n$$\n\\mathbf{p}^{k\\top}\\mathbf{K}^{k}\\mathbf{p}^{k} = \\mathbf{p}^{k\\top}(-\\mathbf{R}^{k}) = -(\\mathbf{p}^{k\\top}\\mathbf{R}^{k}) = -(\\mathbf{R}^{k\\top}\\mathbf{p}^{k}) = -3\n$$\nSubstituting these values back into the expression for $\\Delta \\Pi(\\alpha)$:\n$$\n\\Delta \\Pi(\\alpha) = 3\\alpha - \\frac{3}{2}\\alpha^{2}\n$$\nSince the directional derivative $\\mathbf{R}^{k\\top}\\mathbf{p}^{k} = 3 > 0$, the Newton direction $\\mathbf{p}^{k}$ is an ascent direction for the potential energy $\\Pi$.\n\nNext, we derive the expression for the residual-based merit function $M(\\alpha) = \\frac{1}{2}\\|\\mathbf{R}(\\mathbf{u}(\\alpha))\\|_{2}^{2}$.\nUsing the exact linear model for the residual with $\\mathbf{s} = \\alpha \\mathbf{p}^{k}$:\n$$\n\\mathbf{R}(\\mathbf{u}(\\alpha)) = \\mathbf{R}(\\mathbf{u}^{k} + \\alpha\\mathbf{p}^{k}) = \\mathbf{R}^{k} + \\alpha \\mathbf{K}^{k}\\mathbf{p}^{k}\n$$\nSubstituting $\\mathbf{K}^{k}\\mathbf{p}^{k} = -\\mathbf{R}^{k}$:\n$$\n\\mathbf{R}(\\mathbf{u}(\\alpha)) = \\mathbf{R}^{k} + \\alpha(-\\mathbf{R}^{k}) = (1-\\alpha)\\mathbf{R}^{k}\n$$\nNow we compute the merit function:\n$$\nM(\\alpha) = \\frac{1}{2}\\|(1-\\alpha)\\mathbf{R}^{k}\\|_{2}^{2} = \\frac{1}{2}(1-\\alpha)^{2}\\|\\mathbf{R}^{k}\\|_{2}^{2}\n$$\nWe calculate the squared norm of the initial residual: $\\|\\mathbf{R}^{k}\\|_{2}^{2} = 1^{2} + 2^{2} = 5$.\nThus, the merit function is:\n$$\nM(\\alpha) = \\frac{5}{2}(1-\\alpha)^{2}\n$$\n\nNow we must demonstrate that there exists a nonempty interval of $\\alpha$ where $\\Delta \\Pi(\\alpha) > 0$ while $M(\\alpha)$ is strictly decreasing.\nThe condition $\\Delta \\Pi(\\alpha) > 0$ becomes $3\\alpha - \\frac{3}{2}\\alpha^{2} > 0$, which simplifies to $\\frac{3}{2}\\alpha(2-\\alpha) > 0$. For $\\alpha > 0$, this requires $2-\\alpha > 0$, so $\\alpha \\in (0, 2)$.\nFor $M(\\alpha)$ to be strictly decreasing, its derivative with respect to $\\alpha$ must be negative.\n$$\n\\frac{dM}{d\\alpha} = \\frac{d}{d\\alpha}\\left(\\frac{5}{2}(1-\\alpha)^{2}\\right) = \\frac{5}{2} \\cdot 2(1-\\alpha)(-1) = -5(1-\\alpha)\n$$\nThe condition $\\frac{dM}{d\\alpha}  0$ implies $-5(1-\\alpha)  0$, which means $1-\\alpha > 0$, or $\\alpha  1$.\nThe intersection of the two conditions, $\\alpha \\in (0, 2)$ and $\\alpha  1$, is the interval $\\alpha \\in (0, 1)$. For any $\\alpha$ in this interval, the energy increases ($\\Delta\\Pi > 0$), so an energy-based line search would reject the step. However, the residual-based merit function decreases, so a line search based on $M(\\alpha)$ would accept such a step. This proves the assertion.\n\nWe are asked to compute the smallest positive step length $\\alpha$ for which the potential energy returns to its initial value, i.e., $\\Pi(\\mathbf{u}(\\alpha)) = \\Pi(\\mathbf{u}^{k})$, which is equivalent to $\\Delta \\Pi(\\alpha) = 0$.\n$$\n3\\alpha - \\frac{3}{2}\\alpha^{2} = 0\n$$\n$$\n\\alpha\\left(3 - \\frac{3}{2}\\alpha\\right) = 0\n$$\nThis equation has two solutions: $\\alpha = 0$ (the trivial starting point) and $3 - \\frac{3}{2}\\alpha = 0$.\nSolving for the non-trivial $\\alpha$:\n$$\n3 = \\frac{3}{2}\\alpha \\implies \\alpha = 2\n$$\nThe smallest positive step length is therefore $\\alpha = 2$.\n\n#### Discussion on Acceptance Criteria\nThe fundamental goal in an FE equilibrium analysis is to find the state $\\mathbf{u}^{*}$ for which the internal and external forces are balanced, which is mathematically expressed as the residual vector being zero: $\\mathbf{R}(\\mathbf{u}^{*}) = \\mathbf{0}$. The residual-based merit function $M(\\mathbf{u}) = \\frac{1}{2}\\|\\mathbf{R}(\\mathbf{u})\\|_{2}^{2}$ is constructed specifically to measure progress towards this goal, as $M(\\mathbf{u}) \\ge 0$ and $M(\\mathbf{u}) = 0$ if and only if $\\mathbf{R}(\\mathbf{u}) = \\mathbf{0}$. Therefore, a line search that ensures a decrease in $M$ is directly convergent towards an equilibrium state. In contrast, an energy-decrease criterion seeks a local minimum of the potential energy $\\Pi$. While stable equilibrium points are local minima, equilibrium can also occur at saddle points or local maxima, especially in problems involving instability and path-following. As demonstrated in this problem, when the tangent stiffness $\\mathbf{K}^{k}$ is indefinite, the Newton direction may be an ascent direction for energy, causing an energy-based line search to fail. The residual-merit criterion, however, remains effective and allows the algorithm to progress towards the solution where $\\mathbf{R}=\\mathbf{0}$ (at $\\alpha=1$ in this case). Consequently, the residual-merit criterion is more robust and directly reflects the primary goal of finding any equilibrium state, stable or not.", "answer": "$$\n\\boxed{2}\n$$", "id": "2573788"}]}