{"hands_on_practices": [{"introduction": "The selection of controller gains in a backstepping design directly dictates the system's closed-loop performance. This practice [@problem_id:2736812] will guide you through a rigorous Lyapunov analysis to quantify this relationship for a canonical system. By applying analytical tools like Young’s inequality, you will derive explicit conditions that link the design gains $c_i$ to a guaranteed exponential decay rate $\\lambda$, moving beyond ad-hoc tuning to a more systematic approach to performance optimization.", "problem": "Consider the third-order strict-feedback plant modeled as an Ordinary Differential Equation (ODE)\n$$\n\\dot{x}_{1} = x_{2}, \\quad \\dot{x}_{2} = x_{3}, \\quad \\dot{x}_{3} = u,\n$$\nand apply recursive backstepping to stabilize the origin. Introduce the virtual controls\n$$\n\\alpha_{1}(x_{1}) = -c_{1} x_{1}, \\quad \\alpha_{2}(x_{1},x_{2}) = -c_{2} z_{2} + \\frac{\\partial \\alpha_{1}}{\\partial x_{1}} x_{2},\n$$\nand define the backstepping error coordinates\n$$\nz_{1} = x_{1}, \\quad z_{2} = x_{2} - \\alpha_{1}(x_{1}), \\quad z_{3} = x_{3} - \\alpha_{2}(x_{1},x_{2}),\n$$\nwith the actual control input chosen in the standard manner to render the closed-loop error dynamics lower-triangular with linear damping gains. Under this canonical design, the closed-loop error dynamics take the form\n$$\n\\dot{z}_{1} = -c_{1} z_{1} + z_{2}, \\quad \\dot{z}_{2} = -c_{2} z_{2} + z_{3}, \\quad \\dot{z}_{3} = -c_{3} z_{3},\n$$\nwhere $c_{1} > 0$, $c_{2} > 0$, and $c_{3} > 0$ are design gains. Let $z = \\begin{pmatrix} z_{1} & z_{2} & z_{3} \\end{pmatrix}^{\\top}$ and consider the Lyapunov candidate $V(z) = \\tfrac{1}{2} \\|z\\|^{2}$.\n\nUsing only fundamental inequalities and definitions, perform the following:\n\n1) Starting from $V(z)$, derive an upper bound for $\\dot{V}(z)$ in terms of $z_{1}$, $z_{2}$, $z_{3}$ and the gains $c_{1}$, $c_{2}$, $c_{3}$ by applying Young’s inequality to the coupling products. Introduce positive auxiliary parameters $\\varepsilon_{1} > 0$ and $\\varepsilon_{2} > 0$ to bound the cross terms.\n\n2) From this bound, derive explicit inequalities that link the gains $c_{1}$, $c_{2}$, $c_{3}$, the auxiliary parameters $\\varepsilon_{1}$, $\\varepsilon_{2}$, and the exponential decay rate $\\lambda > 0$ so that the differential inequality $\\dot{V}(z) \\leq -2 \\lambda V(z)$ holds. Conclude that these inequalities ensure $\\|z(t)\\|$ decays exponentially with rate at least $\\lambda$.\n\n3) For the specific gain choices $c_{1} = 3$, $c_{2} = 4$, and $c_{3} = 5$, choose $\\varepsilon_{1}$ and $\\varepsilon_{2}$ to maximize the guaranteed exponential decay rate $\\lambda$ subject to your inequalities from part $2)$. Compute the resulting maximum admissible $\\lambda$ guaranteed by this analysis. Round your answer to $4$ significant figures.", "solution": "The problem presented is a standard exercise in nonlinear control theory utilizing the recursive backstepping design methodology and Lyapunov stability analysis. It is scientifically grounded, self-contained, and well-posed. The validation process confirms its integrity. I shall proceed with the solution.\n\nThe system under consideration is a third-order integrator chain:\n$$\n\\dot{x}_{1} = x_{2}, \\quad \\dot{x}_{2} = x_{3}, \\quad \\dot{x}_{3} = u\n$$\nThe problem specifies the backstepping error coordinates $z_{1}$, $z_{2}$, $z_{3}$ and the resulting closed-loop error dynamics:\n$$\n\\dot{z}_{1} = -c_{1} z_{1} + z_{2} \\\\\n\\dot{z}_{2} = -c_{2} z_{2} + z_{3} \\\\\n\\dot{z}_{3} = -c_{3} z_{3}\n$$\nwhere $c_{1}, c_{2}, c_{3}$ are positive design gains. We are to analyze the stability of the origin of this system in the $z$-coordinates using the Lyapunov candidate function $V(z) = \\frac{1}{2} \\|z\\|^{2} = \\frac{1}{2}(z_{1}^{2} + z_{2}^{2} + z_{3}^{2})$.\n\n**Part 1: Derivation of the upper bound for $\\dot{V}(z)$**\n\nFirst, we compute the time derivative of the Lyapunov function $V(z)$ along the trajectories of the error system:\n$$\n\\dot{V}(z) = \\frac{d}{dt} \\left( \\frac{1}{2} z_{1}^{2} + \\frac{1}{2} z_{2}^{2} + \\frac{1}{2} z_{3}^{2} \\right) = z_{1}\\dot{z}_{1} + z_{2}\\dot{z}_{2} + z_{3}\\dot{z}_{3}\n$$\nSubstituting the given error dynamics into this expression, we obtain:\n$$\n\\dot{V}(z) = z_{1}(-c_{1} z_{1} + z_{2}) + z_{2}(-c_{2} z_{2} + z_{3}) + z_{3}(-c_{3} z_{3})\n$$\nExpanding the terms yields:\n$$\n\\dot{V}(z) = -c_{1} z_{1}^{2} + z_{1}z_{2} - c_{2} z_{2}^{2} + z_{2}z_{3} - c_{3} z_{3}^{2}\n$$\nThis expression contains quadratic terms, which are sign-definite, and cross-product terms $z_{1}z_{2}$ and $z_{2}z_{3}$, which are not. To obtain an upper bound for $\\dot{V}(z)$, we apply Young's inequality to these cross terms. Young's inequality states that for any real numbers $a, b$ and any positive constant $\\varepsilon$, the following holds: $ab \\leq \\frac{a^2}{2\\varepsilon} + \\frac{\\varepsilon b^2}{2}$.\n\nWe apply this inequality to the term $z_{1}z_{2}$ with an auxiliary parameter $\\varepsilon_{1} > 0$:\n$$\nz_{1}z_{2} \\leq \\frac{z_{1}^{2}}{2\\varepsilon_{1}} + \\frac{\\varepsilon_{1} z_{2}^{2}}{2}\n$$\nAnd to the term $z_{2}z_{3}$ with an auxiliary parameter $\\varepsilon_{2} > 0$:\n$$\nz_{2}z_{3} \\leq \\frac{z_{2}^{2}}{2\\varepsilon_{2}} + \\frac{\\varepsilon_{2} z_{3}^{2}}{2}\n$$\nSubstituting these inequalities into the expression for $\\dot{V}(z)$:\n$$\n\\dot{V}(z) \\leq -c_{1} z_{1}^{2} + \\left( \\frac{z_{1}^{2}}{2\\varepsilon_{1}} + \\frac{\\varepsilon_{1} z_{2}^{2}}{2} \\right) - c_{2} z_{2}^{2} + \\left( \\frac{z_{2}^{2}}{2\\varepsilon_{2}} + \\frac{\\varepsilon_{2} z_{3}^{2}}{2} \\right) - c_{3} z_{3}^{2}\n$$\nGrouping the terms by $z_{1}^{2}$, $z_{2}^{2}$, and $z_{3}^{2}$, we arrive at the desired upper bound:\n$$\n\\dot{V}(z) \\leq -\\left(c_{1} - \\frac{1}{2\\varepsilon_{1}}\\right)z_{1}^{2} - \\left(c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}\\right)z_{2}^{2} - \\left(c_{3} - \\frac{\\varepsilon_{2}}{2}\\right)z_{3}^{2}\n$$\n\n**Part 2: Derivation of inequalities for exponential stability**\n\nWe seek to establish the condition $\\dot{V}(z) \\leq -2\\lambda V(z)$ for some exponential decay rate $\\lambda > 0$. Recalling that $V(z) = \\frac{1}{2}(z_{1}^{2} + z_{2}^{2} + z_{3}^{2})$, the condition is equivalent to:\n$$\n\\dot{V}(z) \\leq -\\lambda z_{1}^{2} - \\lambda z_{2}^{2} - \\lambda z_{3}^{2}\n$$\nComparing this with the upper bound derived in Part 1, the inequality is satisfied if the following conditions on the coefficients of $z_{i}^{2}$ hold for all $i \\in \\{1, 2, 3\\}$:\n$$\n-\\left(c_{1} - \\frac{1}{2\\varepsilon_{1}}\\right) \\leq -\\lambda \\implies c_{1} - \\frac{1}{2\\varepsilon_{1}} \\geq \\lambda\n$$\n$$\n-\\left(c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}\\right) \\leq -\\lambda \\implies c_{2} - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}} \\geq \\lambda\n$$\n$$\n-\\left(c_{3} - \\frac{\\varepsilon_{2}}{2}\\right) \\leq -\\lambda \\implies c_{3} - \\frac{\\varepsilon_{2}}{2} \\geq \\lambda\n$$\nThese three inequalities link the gains $c_i$, the auxiliary parameters $\\varepsilon_i$, and the decay rate $\\lambda$. The differential inequality $\\dot{V}(z) \\leq -2\\lambda V(z)$, by the Comparison Lemma, implies $V(z(t)) \\leq V(z(0)) \\exp(-2\\lambda t)$. Substituting the definition of $V(z)$ gives $\\frac{1}{2}\\|z(t)\\|^{2} \\leq \\frac{1}{2}\\|z(0)\\|^{2} \\exp(-2\\lambda t)$, which simplifies to $\\|z(t)\\| \\leq \\|z(0)\\| \\exp(-\\lambda t)$. This confirms that the state norm $\\|z(t)\\|$ decays to zero exponentially with a rate of at least $\\lambda$.\n\n**Part 3: Maximization of the decay rate $\\lambda$**\n\nWe are given the specific gains $c_{1} = 3$, $c_{2} = 4$, and $c_{3} = 5$. Our goal is to choose $\\varepsilon_{1} > 0$ and $\\varepsilon_{2} > 0$ to maximize the guaranteed decay rate $\\lambda$. To satisfy all three inequalities from Part 2, $\\lambda$ must be less than or equal to the minimum of the three left-hand side expressions:\n$$\n\\lambda \\leq \\min \\left\\{ 3 - \\frac{1}{2\\varepsilon_{1}}, \\quad 4 - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}}, \\quad 5 - \\frac{\\varepsilon_{2}}{2} \\right\\}\n$$\nTo maximize this minimum value, we should choose $\\varepsilon_{1}$ and $\\varepsilon_{2}$ such that the three arguments of the minimum function are equal. This is a standard approach for this class of optimization problem. Let the maximal rate be $\\lambda$. We set:\n$$\n\\lambda = 3 - \\frac{1}{2\\varepsilon_{1}} \\quad (A)\n$$\n$$\n\\lambda = 4 - \\frac{\\varepsilon_{1}}{2} - \\frac{1}{2\\varepsilon_{2}} \\quad (B)\n$$\n$$\n\\lambda = 5 - \\frac{\\varepsilon_{2}}{2} \\quad (C)\n$$\nFrom equation $(A)$, we solve for $\\varepsilon_{1}$:\n$3 - \\lambda = \\frac{1}{2\\varepsilon_{1}} \\implies \\varepsilon_{1} = \\frac{1}{2(3 - \\lambda)}$. This requires $\\lambda < 3$.\nFrom equation $(C)$, we solve for $\\varepsilon_{2}$:\n$5 - \\lambda = \\frac{\\varepsilon_{2}}{2} \\implies \\varepsilon_{2} = 2(5 - \\lambda)$. This requires $\\lambda < 5$.\nNow, we substitute the expressions for $\\frac{\\varepsilon_{1}}{2}$ and $\\frac{1}{2\\varepsilon_{2}}$ into equation $(B)$.\nFrom our expressions for $\\varepsilon_1$ and $\\varepsilon_2$, we have $\\frac{\\varepsilon_{1}}{2} = \\frac{1}{4(3 - \\lambda)}$ and $\\frac{1}{2\\varepsilon_{2}} = \\frac{1}{4(5 - \\lambda)}$.\nSubstituting these into $(B)$:\n$$\n\\lambda = 4 - \\frac{1}{4(3 - \\lambda)} - \\frac{1}{4(5 - \\lambda)}\n$$\nTo solve for $\\lambda$, we rearrange the equation:\n$$\n4 - \\lambda = \\frac{1}{4(3 - \\lambda)} + \\frac{1}{4(5 - \\lambda)}\n$$\n$$\n4(4 - \\lambda) = \\frac{1}{3 - \\lambda} + \\frac{1}{5 - \\lambda}\n$$\n$$\n4(4 - \\lambda) = \\frac{(5 - \\lambda) + (3 - \\lambda)}{(3 - \\lambda)(5 - \\lambda)} = \\frac{8 - 2\\lambda}{\\lambda^{2} - 8\\lambda + 15}\n$$\n$$\n4(4 - \\lambda) = \\frac{2(4 - \\lambda)}{\\lambda^{2} - 8\\lambda + 15}\n$$\nSince $\\lambda < 3$, it follows that $\\lambda \\neq 4$. We can safely divide both sides by $4 - \\lambda$:\n$$\n4 = \\frac{2}{\\lambda^{2} - 8\\lambda + 15}\n$$\nThis simplifies to:\n$$\n2(\\lambda^{2} - 8\\lambda + 15) = 1\n$$\n$$\n2\\lambda^{2} - 16\\lambda + 30 = 1\n$$\n$$\n2\\lambda^{2} - 16\\lambda + 29 = 0\n$$\nWe solve this quadratic equation for $\\lambda$ using the quadratic formula, $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\n\\lambda = \\frac{16 \\pm \\sqrt{(-16)^{2} - 4(2)(29)}}{2(2)} = \\frac{16 \\pm \\sqrt{256 - 232}}{4} = \\frac{16 \\pm \\sqrt{24}}{4}\n$$\n$$\n\\lambda = \\frac{16 \\pm 2\\sqrt{6}}{4} = 4 \\pm \\frac{\\sqrt{6}}{2}\n$$\nThis gives two possible solutions for $\\lambda$: $\\lambda_{1} = 4 + \\frac{\\sqrt{6}}{2}$ and $\\lambda_{2} = 4 - \\frac{\\sqrt{6}}{2}$.\nAs established earlier, for $\\varepsilon_{1}$ to be positive, we must have $3 - \\lambda > 0$, which implies $\\lambda < 3$.\nWe evaluate the two solutions:\n$\\lambda_{1} = 4 + \\frac{\\sqrt{6}}{2} \\approx 4 + \\frac{2.449}{2} \\approx 5.225$. This solution violates the condition $\\lambda < 3$ and is therefore extraneous.\n$\\lambda_{2} = 4 - \\frac{\\sqrt{6}}{2} \\approx 4 - \\frac{2.449}{2} \\approx 2.775$. This solution satisfies $\\lambda < 3$.\nThus, the maximum guaranteed exponential decay rate is $\\lambda = 4 - \\frac{\\sqrt{6}}{2}$.\n\nFinally, we compute the numerical value and round to $4$ significant figures as requested.\n$$\n\\lambda = 4 - \\frac{\\sqrt{6}}{2} \\approx 4 - \\frac{2.44948974}{2} = 4 - 1.22474487 = 2.77525513...\n$$\nRounding to $4$ significant figures, we get $2.775$.\nThe optimal auxiliary parameters are $\\varepsilon_1 = \\frac{1}{2(3 - (4-\\sqrt{6}/2))} = \\frac{1}{\\sqrt{6}-2} \\approx 2.225$ and $\\varepsilon_2 = 2(5 - (4-\\sqrt{6}/2)) = 2 + \\sqrt{6} \\approx 4.449$. Both are positive, confirming the validity of the solution.", "answer": "$$\n\\boxed{2.775}\n$$", "id": "2736812"}, {"introduction": "While backstepping provides a systematic recipe for controller design, the resulting controller's complexity is deeply tied to the plant's inherent structure. This insightful exercise [@problem_id:1088218] challenges you to explore this connection by determining a specific system parameter $\\beta$ that allows for a dramatically simplified design. By working backward from the goal of an additively separable Lyapunov function, you will uncover how specific system properties can be exploited to reduce controller complexity.", "problem": "Consider a second-order nonlinear system in strict-feedback form given by the differential equations:\n$$\n\\begin{aligned}\n\\dot{x}_1 &= -x_1^3 + x_1^2 x_2 \\\\\n\\dot{x}_2 &= \\beta x_1^3 + \\cos(x_2) + u\n\\end{aligned}\n$$\nwhere $u$ is the control input and $\\beta$ is a real constant. The objective is to design a stabilizing control law $u$ for the origin $(x_1, x_2) = (0,0)$ using the recursive backstepping method.\n\nThe backstepping design procedure proceeds as follows:\n1.  Consider the $x_1$-subsystem. A Lyapunov function candidate $V_1(x_1)$ is chosen, and a \"virtual control\" law $\\alpha_1(x_1)$ for the state $x_2$ is designed to stabilize this subsystem. For this problem, use the candidate Lyapunov function $V_1(x_1) = \\frac{1}{2}x_1^2$.\n2.  A change of coordinates is defined with an error variable $z_2 = x_2 - \\alpha_1(x_1)$.\n3.  A composite Lyapunov function for the full system is constructed as $V(x_1, z_2) = V_1(x_1) + \\frac{1}{2}z_2^2$.\n4.  The control law $u$ is designed to make the time derivative of $V(x_1, z_2)$ negative definite.\n\nThe structure of the resulting composite Lyapunov function in the original coordinates, $V(x_1, x_2) = V_1(x_1) + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2$, is generally not additively separable, i.e., it cannot be written as a sum of a function of $x_1$ and a function of $x_2$. For this to be the case, the virtual control $\\alpha_1(x_1)$ must be identically zero.\n\nFind the unique value of the parameter $\\beta$ for which both of the following conditions are met:\na) The composite Lyapunov function $V(x_1, x_2)$ is additively separable.\nb) The resulting stabilizing control law $u(x_1, x_2)$ is a function of $x_2$ only.", "solution": "The problem asks for the value of a parameter $\\beta$ in a nonlinear system such that a backstepping control design results in an additively separable composite Lyapunov function and a controller that is a function of only one state variable.\n\n**Step 1: Analyze the condition for additive separability**\n\nThe backstepping procedure constructs a composite Lyapunov function of the form $V(x_1, x_2) = V_1(x_1) + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2$. For this problem, $V_1(x_1) = \\frac{1}{2}x_1^2$, so\n$$\nV(x_1, x_2) = \\frac{1}{2}x_1^2 + \\frac{1}{2}(x_2 - \\alpha_1(x_1))^2 = \\frac{1}{2}x_1^2 + \\frac{1}{2}x_2^2 - x_2 \\alpha_1(x_1) + \\frac{1}{2}\\alpha_1(x_1)^2\n$$\nFor $V(x_1, x_2)$ to be additively separable, it must be of the form $A(x_1) + B(x_2)$. This requires the cross-term $-x_2 \\alpha_1(x_1)$ to vanish for all $x_1$ and $x_2$. This can only be true if $\\alpha_1(x_1) \\equiv 0$.\nSo, the first condition (additive separability) imposes the constraint that the virtual control must be zero.\n\n**Step 2: Determine the virtual control $\\alpha_1(x_1)$ and check for validity**\n\nLet's design the virtual control for the $x_1$-subsystem, $\\dot{x}_1 = -x_1^3 + x_1^2 x_2$, using the given Lyapunov candidate $V_1(x_1) = \\frac{1}{2}x_1^2$.\nThe time derivative of $V_1$ along the trajectories of the subsystem is:\n$$\n\\dot{V}_1 = \\frac{\\partial V_1}{\\partial x_1} \\dot{x}_1 = x_1(-x_1^3 + x_1^2 x_2) = -x_1^4 + x_1^3 x_2\n$$\nIn backstepping, we treat $x_2$ as a virtual control. We define a desired virtual control law $x_{2,d} = \\alpha_1(x_1)$ such that if $x_2 = \\alpha_1(x_1)$, the resulting dynamics make $\\dot{V}_1$ negative definite. The typical choice is to make $\\dot{V}_1$ equal to a desired negative definite function, e.g., $-c_1 x_1^4$ for some constant $c_1 > 0$.\n$$\n-x_1^4 + x_1^3 \\alpha_1(x_1) = -c_1 x_1^4\n$$\nFrom the separability condition, we must have $\\alpha_1(x_1) = 0$. Let's check if this choice is valid. If we set $\\alpha_1(x_1) = 0$, the expression for the stabilized part of the derivative becomes:\n$$\n\\dot{V}_1 = -x_1^4 + x_1^3 (0) = -x_1^4\n$$\nSince $-x_1^4$ is negative definite (for $x_1 \\neq 0$), the choice $\\alpha_1(x_1) = 0$ is a valid virtual control law that stabilizes the $x_1$-subsystem (by rendering its part of the Lyapunov derivative negative definite). This corresponds to choosing $c_1=1$.\n\n**Step 3: Design the control law $u$**\n\nWith $\\alpha_1(x_1) = 0$, the error variable is $z_2 = x_2 - 0 = x_2$.\nThe composite Lyapunov function is $V(x_1, x_2) = \\frac{1}{2}x_1^2 + \\frac{1}{2}x_2^2$, which is additively separable as required.\nNow, we compute the time derivative of $V$ along the trajectories of the full system:\n$$\n\\dot{V} = \\frac{\\partial V}{\\partial x_1}\\dot{x}_1 + \\frac{\\partial V}{\\partial x_2}\\dot{x}_2 = x_1 \\dot{x}_1 + x_2 \\dot{x}_2\n$$\nSubstitute the system dynamics:\n$$\n\\dot{V} = x_1(-x_1^3 + x_1^2 x_2) + x_2(\\beta x_1^3 + \\cos(x_2) + u)\n$$\n$$\n\\dot{V} = -x_1^4 + x_1^3 x_2 + \\beta x_1^3 x_2 + x_2 \\cos(x_2) + x_2 u\n$$\nGroup the terms:\n$$\n\\dot{V} = -x_1^4 + (1+\\beta)x_1^3 x_2 + x_2 \\cos(x_2) + x_2 u\n$$\nTo make $\\dot{V}$ negative definite, we must choose the control law $u$ to cancel the terms that are not negative definite, i.e., the cross-term $(1+\\beta)x_1^3 x_2$ and the term $x_2 \\cos(x_2)$. We also add a stabilizing term $-c_2 x_2^2$ where $c_2 > 0$ is a design parameter.\nA suitable control law is:\n$$\nx_2 u = -(1+\\beta)x_1^3 x_2 - x_2 \\cos(x_2) - c_2 x_2^2\n$$\nAssuming $x_2 \\neq 0$, we can write:\n$$\nu(x_1, x_2) = -(1+\\beta)x_1^3 - \\cos(x_2) - c_2 x_2\n$$\nWith this control law, the derivative of the Lyapunov function becomes:\n$$\n\\dot{V} = -x_1^4 - c_2 x_2^2\n$$\nwhich is negative definite for all $(x_1, x_2) \\neq (0,0)$. This confirms that the choice of $u$ does stabilize the system.\n\n**Step 4: Apply the condition on the control law $u$**\n\nThe second condition of the problem is that the control law $u(x_1, x_2)$ must be a function of $x_2$ only. Let's examine our derived controller:\n$$\nu(x_1, x_2) = -(1+\\beta)x_1^3 - \\cos(x_2) - c_2 x_2\n$$\nFor this expression to be independent of $x_1$, the term containing $x_1$ must be identically zero for all $x_1$.\n$$\n-(1+\\beta)x_1^3 = 0\n$$\nSince this must hold for any $x_1$, the coefficient must be zero:\n$$\n-(1+\\beta) = 0\n$$\nSolving for $\\beta$ gives:\n$$\n\\beta = -1\n$$\nThis is the unique value of $\\beta$ that satisfies both conditions of the problem.", "answer": "$$\n\\boxed{-1}\n$$", "id": "1088218"}, {"introduction": "One of the most powerful features of the backstepping methodology is its seamless integration with adaptive control, enabling stabilization in the presence of parametric uncertainty. This exercise [@problem_id:2689615] provides a comprehensive, step-by-step walkthrough of designing an adaptive backstepping controller for a system with an unknown parameter $a$. You will construct the virtual controls, define the appropriate coordinate transformations, and use a Lyapunov approach to derive both the control law and the parameter adaptation law.", "problem": "Consider the strict-feedback system with an unknown drift parameter\n$$\n\\dot{x}_{1} \\;=\\; -\\,x_{1} \\;+\\; x_{2}, \n\\qquad \n\\dot{x}_{2} \\;=\\; -\\,a\\,x_{2} \\;+\\; u,\n$$\nwhere $x_{1},x_{2}\\in\\mathbb{R}$ are the states, $u\\in\\mathbb{R}$ is the control input, and $a\\in\\mathbb{R}$ is an unknown constant (its sign is not assumed known). Starting only from the strict-feedback interconnection structure, the definitions of virtual control and backstepping coordinates, and Lyapunov stability with gradient adaptation, proceed as follows:\n\n1) Using the interconnection structure, construct a virtual control for the first subsystem by selecting $\\alpha_{1}(x_{1})=-k_{1}x_{1}$ with a given $k_{1}>0$, and define the backstepping coordinates $z_{1}=x_{1}$ and $z_{2}=x_{2}-\\alpha_{1}(x_{1})$. Show by explicit calculation that the resulting transformed dynamics are triangular, in the sense that $\\dot{z}_{1}$ depends on $z_{1}$ and $z_{2}$ only, and $\\dot{z}_{2}$ depends on $z_{1}$, $z_{2}$, and $u$ only, with linear parametrization in the unknown $a$.\n\n2) Using a quadratic Lyapunov function with an adaptation term of the form $V=\\tfrac{1}{2}z_{1}^{2}+\\tfrac{1}{2}z_{2}^{2}+\\tfrac{1}{2\\gamma}\\tilde{a}^{2}$, where $\\tilde{a}=\\hat{a}-a$ and $\\gamma>0$ is a design constant, derive a gradient update law for $\\hat{a}$ from the linear parametrization you obtain in $\\dot{z}_{2}$ so that all terms involving $\\tilde{a}$ cancel in $\\dot{V}$.\n\n3) Design the actual control input $u$ so that $\\dot{V}$ is negative definite with an additional design gain $k_{2}>0$. Your construction must use only the triangular dependence revealed by the strict-feedback structure and the Lyapunov method.\n\n4) For the specific design gains $k_{1}=2$ and $k_{2}=3$, express the final control input $u$ explicitly as a closed-form analytic expression in terms of $x_{1}$, $x_{2}$, and $\\hat{a}$.\n\nProvide only the exact analytic expression for $u(x_{1},x_{2},\\hat{a})$ as your final answer. No rounding is required.", "solution": "The problem statement constitutes a standard, well-posed exercise in adaptive backstepping control design for a strict-feedback system. It is scientifically sound, self-contained, and free from ambiguity. We will proceed with a systematic derivation according to the specified steps.\n\nFirst, we address step 1: the transformation into backstepping coordinates and analysis of the resulting dynamics.\nThe system is given by\n$$\n\\dot{x}_{1} \\;=\\; -x_{1} \\;+\\; x_{2}\n$$\n$$\n\\dot{x}_{2} \\;=\\; -ax_{2} \\;+\\; u\n$$\nwhere $a$ is an unknown constant.\n\nThe backstepping coordinates are defined as $z_{1} = x_{1}$ and $z_{2} = x_{2} - \\alpha_{1}(x_{1})$, where the virtual control is selected as $\\alpha_{1}(x_{1}) = -k_{1}x_{1}$ for a given design constant $k_{1}>0$.\nThus, the coordinates are:\n$$\nz_{1} = x_{1}\n$$\n$$\nz_{2} = x_{2} - (-k_{1}x_{1}) = x_{2} + k_{1}x_{1}\n$$\nFrom this, we can express the original state $x_{2}$ in terms of the new coordinates: $x_{2} = z_{2} - k_{1}x_{1} = z_{2} - k_{1}z_{1}$.\n\nWe now compute the time derivative of $z_{1}$:\n$$\n\\dot{z}_{1} = \\dot{x}_{1} = -x_{1} + x_{2}\n$$\nSubstituting the coordinate transformations, we get:\n$$\n\\dot{z}_{1} = -z_{1} + (z_{2} - k_{1}z_{1}) = -(1+k_{1})z_{1} + z_{2}\n$$\nThis expression depends only on $z_{1}$ and $z_{2}$, as required.\n\nNext, we compute the time derivative of $z_{2}$:\n$$\n\\dot{z}_{2} = \\dot{x}_{2} + k_{1}\\dot{x}_{1}\n$$\nSubstituting the system dynamics for $\\dot{x}_{1}$ and $\\dot{x}_{2}$:\n$$\n\\dot{z}_{2} = (-ax_{2} + u) + k_{1}(-x_{1} + x_{2}) = u - k_{1}x_{1} + (k_{1}-a)x_{2}\n$$\nTo show linear parametrization in $a$, we must express this in terms of $z_{1}$, $z_{2}$, and $u$. We substitute $x_{1}=z_{1}$ and $x_{2} = z_{2} - k_{1}z_{1}$:\n$$\n\\dot{z}_{2} = u - k_{1}z_{1} + (k_{1}-a)(z_{2} - k_{1}z_{1})\n$$\n$$\n\\dot{z}_{2} = u - k_{1}z_{1} + k_{1}z_{2} - k_{1}^{2}z_{1} - a(z_{2} - k_{1}z_{1})\n$$\n$$\n\\dot{z}_{2} = u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - a(z_{2} - k_{1}z_{1})\n$$\nThis expression depends on $z_{1}$, $z_{2}$, and $u$, and is linearly parametrized with respect to the unknown parameter $a$. The triangular structure is confirmed.\n\nSecond, we address step 2: derivation of the adaptation law.\nWe consider the Lyapunov function candidate:\n$$\nV = \\frac{1}{2}z_{1}^{2} + \\frac{1}{2}z_{2}^{2} + \\frac{1}{2\\gamma}\\tilde{a}^{2}\n$$\nwhere $\\tilde{a} = \\hat{a}-a$ and $\\gamma>0$. The time derivative of $V$ is:\n$$\n\\dot{V} = z_{1}\\dot{z}_{1} + z_{2}\\dot{z}_{2} + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\tilde{a}}\n$$\nSince $a$ is a constant, $\\dot{\\tilde{a}} = \\dot{\\hat{a}}$. Substituting the expression for $\\dot{z}_{1}$:\n$$\n\\dot{V} = z_{1}(- (1+k_{1})z_{1} + z_{2}) + z_{2}\\dot{z}_{2} + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\hat{a}}\n$$\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{1}z_{2} + z_{2}\\dot{z}_{2} + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\hat{a}}\n$$\nNow we substitute the dynamics for $\\dot{z}_{2}$:\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{1}z_{2} + z_{2}\\left[u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - a(z_{2} - k_{1}z_{1})\\right] + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\hat{a}}\n$$\nWe replace the unknown parameter $a$ with its estimate $\\hat{a}$ and error $\\tilde{a}$, using $a = \\hat{a} - \\tilde{a}$:\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{1}z_{2} + z_{2}\\left[u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - (\\hat{a}-\\tilde{a})(z_{2} - k_{1}z_{1})\\right] + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\hat{a}}\n$$\nGrouping the terms involving $\\tilde{a}$:\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{1}z_{2} + z_{2}\\left[u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - \\hat{a}(z_{2} - k_{1}z_{1})\\right] + \\tilde{a}z_{2}(z_{2} - k_{1}z_{1}) + \\frac{1}{\\gamma}\\tilde{a}\\dot{\\hat{a}}\n$$\n$$\n\\dot{V} = \\dots + \\tilde{a}\\left[z_{2}(z_{2} - k_{1}z_{1}) + \\frac{1}{\\gamma}\\dot{\\hat{a}}\\right]\n$$\nTo cancel all terms involving the parameter error $\\tilde{a}$, we set the expression in the brackets to zero:\n$$\nz_{2}(z_{2} - k_{1}z_{1}) + \\frac{1}{\\gamma}\\dot{\\hat{a}} = 0\n$$\nThis yields the gradient adaptation law for $\\hat{a}$:\n$$\n\\dot{\\hat{a}} = -\\gamma z_{2}(z_{2} - k_{1}z_{1})\n$$\n\nThird, we address step 3: the design of the actual control input $u$.\nWith the adaptation law in place, the derivative of the Lyapunov function simplifies to:\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{1}z_{2} + z_{2}\\left[u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - \\hat{a}(z_{2} - k_{1}z_{1})\\right]\n$$\n$$\n\\dot{V} = -(1+k_{1})z_{1}^{2} + z_{2}\\left[z_{1} + u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - \\hat{a}(z_{2} - k_{1}z_{1})\\right]\n$$\nTo make $\\dot{V}$ negative definite, we choose the control input $u$ such that the term in the brackets becomes $-k_{2}z_{2}$, where $k_{2}>0$ is another design gain. This will result in $\\dot{V} = -(1+k_{1})z_{1}^{2} - k_{2}z_{2}^{2} < 0$ for any $(z_1, z_2) \\neq (0,0)$.\nWe set:\n$$\nz_{1} + u + k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - \\hat{a}(z_{2} - k_{1}z_{1}) = -k_{2}z_{2}\n$$\nSolving for the control input $u$:\n$$\nu = -z_{1} - k_{2}z_{2} - \\left[k_{1}z_{2} - (k_{1}+k_{1}^{2})z_{1} - \\hat{a}(z_{2} - k_{1}z_{1})\\right]\n$$\n$$\nu = -z_{1} - k_{2}z_{2} - k_{1}z_{2} + (k_{1}+k_{1}^{2})z_{1} + \\hat{a}(z_{2} - k_{1}z_{1})\n$$\nGrouping terms by $z_{1}$ and $z_{2}$:\n$$\nu = (-1 + k_{1} + k_{1}^{2} - k_{1}\\hat{a})z_{1} + (-k_{1} - k_{2} + \\hat{a})z_{2}\n$$\n\nFourth, we address step 4: the explicit form of the control law for $k_{1}=2$ and $k_{2}=3$.\nFirst, we express the backstepping coordinates for $k_{1}=2$:\n$$\nz_{1} = x_{1}\n$$\n$$\nz_{2} = x_{2} + 2x_{1}\n$$\nNext, we substitute $k_{1}=2$ and $k_{2}=3$ into the general control law derived above:\n$$\nu = (-1 + 2 + 2^{2} - 2\\hat{a})z_{1} + (-2 - 3 + \\hat{a})z_{2}\n$$\n$$\nu = (5 - 2\\hat{a})z_{1} + (\\hat{a} - 5)z_{2}\n$$\nFinally, we substitute the expressions for $z_{1}$ and $z_{2}$ in terms of the original states $x_{1}$ and $x_{2}$:\n$$\nu = (5 - 2\\hat{a})x_{1} + (\\hat{a} - 5)(x_{2} + 2x_{1})\n$$\nExpanding and collecting terms for $x_{1}$ and $x_{2}$:\n$$\nu = 5x_{1} - 2\\hat{a}x_{1} + (\\hat{a} - 5)x_{2} + 2(\\hat{a} - 5)x_{1}\n$$\n$$\nu = 5x_{1} - 2\\hat{a}x_{1} + (\\hat{a} - 5)x_{2} + 2\\hat{a}x_{1} - 10x_{1}\n$$\nThe coefficient of $x_{1}$ is $5 - 2\\hat{a} + 2\\hat{a} - 10 = -5$.\nThe coefficient of $x_{2}$ is $\\hat{a} - 5$.\nThe final expression for the control law is:\n$$\nu(x_{1}, x_{2}, \\hat{a}) = -5x_{1} + (\\hat{a} - 5)x_{2}\n$$\nThis is the required closed-form analytic expression for the control input.", "answer": "$$\n\\boxed{-5x_{1} + (\\hat{a}-5)x_{2}}\n$$", "id": "2689615"}]}