{"hands_on_practices": [{"introduction": "Proving stability for Model Predictive Control (MPC) often relies on utilizing the optimal cost as a Lyapunov function. A critical element in this framework is the terminal cost, which must ensure stability within the terminal set. This exercise provides concrete practice in solving the discrete-time Lyapunov equation to construct a quadratic terminal cost, $V_f(x) = x^{\\top} P x$, thereby solidifying the foundational link between linear systems theory and formal MPC stability proofs [@problem_id:2746597].", "problem": "Consider the discrete-time linear time-invariant system used in Model Predictive Control (MPC) stability analysis,\n$$x_{k+1} = A x_k + B u_k,$$\nwith state feedback control law\n$$u_k = K x_k,$$\nand quadratic stage cost\n$$\\ell(x_k,u_k) = x_k^{\\top} Q x_k + u_k^{\\top} R u_k.$$\nAssume that the closed-loop matrix $A_{K} \\coloneqq A + B K$ is Schur (all eigenvalues lie strictly inside the unit disk). A standard terminal cost candidate for MPC is the quadratic Lyapunov function\n$$V(x) = x^{\\top} P x,$$\nwhere $P \\succ 0$ solves the discrete-time Lyapunov equation\n$$P = A_{K}^{\\top} P A_{K} + \\left(Q + K^{\\top} R K\\right).$$\nThis choice is used to guarantee recursive feasibility and closed-loop stability by ensuring the Lyapunov decrease condition.\n\nFor the specific data\n$$A=\\begin{bmatrix}1  1\\\\ 0  1\\end{bmatrix},\\quad B=\\begin{bmatrix}0\\\\ 1\\end{bmatrix},\\quad K=\\begin{bmatrix}-1  -2\\end{bmatrix},\\quad Q=I,\\quad R=1,$$\nperform the following:\n1) Compute the unique symmetric positive definite matrix $P$ that solves the discrete-time Lyapunov equation above.\n2) Using your computed $P$, verify the Lyapunov decrease inequality for all $x$,\n$$V(x^{+})-V(x) \\leq -\\left(x^{\\top} Q x + x^{\\top} K^{\\top} R K x\\right),$$\nwhere $x^{+} = A_{K} x$.\n\nProvide your final answer as the exact $2 \\times 2$ matrix $P$ with rational entries (no rounding). Do not include any inequality in the final answer.", "solution": "The problem presented is a standard exercise in the stability analysis of linear discrete-time systems under feedback control, specifically concerning the construction of a quadratic Lyapunov function. The problem is well-posed and scientifically sound. I will proceed with the solution.\n\nThe task is to solve for the symmetric positive definite matrix $P$ from the discrete-time algebraic Lyapunov equation:\n$$P = A_{K}^{\\top} P A_{K} + \\left(Q + K^{\\top} R K\\right)$$\nand subsequently to verify the Lyapunov decrease condition.\n\nFirst, we must compute the closed-loop system matrix $A_K = A + BK$. The given matrices are:\n$$A = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix}, \\quad B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}, \\quad K = \\begin{bmatrix} -1  -2 \\end{bmatrix}$$\nThe product $BK$ is:\n$$BK = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} -1  -2 \\end{bmatrix} = \\begin{bmatrix} 0 \\times (-1)  0 \\times (-2) \\\\ 1 \\times (-1)  1 \\times (-2) \\end{bmatrix} = \\begin{bmatrix} 0  0 \\\\ -1  -2 \\end{bmatrix}$$\nTherefore, the closed-loop matrix $A_K$ is:\n$$A_K = A + BK = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix} + \\begin{bmatrix} 0  0 \\\\ -1  -2 \\end{bmatrix} = \\begin{bmatrix} 1  1 \\\\ -1  -1 \\end{bmatrix}$$\nThe problem states that $A_K$ is Schur. Let us confirm this. The characteristic equation is $\\det(A_K - \\lambda I) = 0$.\n$$\\det \\left( \\begin{bmatrix} 1-\\lambda  1 \\\\ -1  -1-\\lambda \\end{bmatrix} \\right) = (1-\\lambda)(-1-\\lambda) - (1)(-1) = -1 - \\lambda + \\lambda + \\lambda^2 + 1 = \\lambda^2 = 0$$\nThe eigenvalues are $\\lambda_{1,2} = 0$. Since all eigenvalues have magnitude $|\\lambda| = 0  1$, the matrix $A_K$ is indeed Schur, which guarantees a unique positive definite solution $P$ to the Lyapunov equation for any positive definite weighting matrix $Q + K^{\\top} R K$.\n\nNext, we compute the total weighting matrix for the stage cost, which we denote as $Q_{cl} = Q + K^{\\top} R K$. We are given $Q = I$ and $R = 1$.\n$$K^{\\top} R K = \\begin{bmatrix} -1 \\\\ -2 \\end{bmatrix} (1) \\begin{bmatrix} -1  -2 \\end{bmatrix} = \\begin{bmatrix} (-1)(-1)  (-1)(-2) \\\\ (-2)(-1)  (-2)(-2) \\end{bmatrix} = \\begin{bmatrix} 1  2 \\\\ 2  4 \\end{bmatrix}$$\nThus, $Q_{cl}$ is:\n$$Q_{cl} = Q + K^{\\top} R K = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} + \\begin{bmatrix} 1  2 \\\\ 2  4 \\end{bmatrix} = \\begin{bmatrix} 2  2 \\\\ 2  5 \\end{bmatrix}$$\nThe Lyapunov equation is $P = A_K^{\\top} P A_K + Q_{cl}$. Let $P$ be a symmetric matrix $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$. We must solve for its elements.\nFirst, we compute the term $A_K^{\\top} P A_K$:\n$$A_K^{\\top} P A_K = \\begin{bmatrix} 1  -1 \\\\ 1  -1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 1  1 \\\\ -1  -1 \\end{bmatrix}$$\n$$= \\begin{bmatrix} p_{11}-p_{12}  p_{12}-p_{22} \\\\ p_{11}-p_{12}  p_{12}-p_{22} \\end{bmatrix} \\begin{bmatrix} 1  1 \\\\ -1  -1 \\end{bmatrix}$$\n$$= \\begin{bmatrix} (p_{11}-p_{12}) - (p_{12}-p_{22})  (p_{11}-p_{12}) - (p_{12}-p_{22}) \\\\ (p_{11}-p_{12}) - (p_{12}-p_{22})  (p_{11}-p_{12}) - (p_{12}-p_{22}) \\end{bmatrix}$$\n$$= \\begin{bmatrix} p_{11}-2p_{12}+p_{22}  p_{11}-2p_{12}+p_{22} \\\\ p_{11}-2p_{12}+p_{22}  p_{11}-2p_{12}+p_{22} \\end{bmatrix}$$\nLet the scalar value $c = p_{11}-2p_{12}+p_{22}$. Then $A_K^{\\top} P A_K = c \\begin{bmatrix} 1  1 \\\\ 1  1 \\end{bmatrix}$.\nSubstituting this into the Lyapunov equation:\n$$\\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} = \\begin{bmatrix} c  c \\\\ c  c \\end{bmatrix} + \\begin{bmatrix} 2  2 \\\\ 2  5 \\end{bmatrix} = \\begin{bmatrix} c+2  c+2 \\\\ c+2  c+5 \\end{bmatrix}$$\nBy comparing the elements, we obtain a system of equations:\n1) $p_{11} = c+2$\n2) $p_{12} = c+2$\n3) $p_{22} = c+5$\nFrom equations 1) and 2), we find $p_{11} = p_{12}$.\nNow we substitute these into the definition of $c$:\n$$c = p_{11} - 2p_{12} + p_{22} = (c+2) - 2(c+2) + (c+5)$$\n$$c = c+2 - 2c-4 + c+5 = (c-2c+c) + (2-4+5) = 0 \\cdot c + 3$$\n$$c = 3$$\nUsing this value, we find the elements of $P$:\n$$p_{11} = c+2 = 3+2 = 5$$\n$$p_{12} = c+2 = 3+2 = 5$$\n$$p_{22} = c+5 = 3+5 = 8$$\nSo, the solution is the matrix:\n$$P = \\begin{bmatrix} 5  5 \\\\ 5  8 \\end{bmatrix}$$\nThis matrix is symmetric. We check for positive definiteness using Sylvester's criterion. The leading principal minors are $5  0$ and $\\det(P) = 5 \\times 8 - 5 \\times 5 = 40 - 25 = 15  0$. Both are positive, so $P$ is positive definite. This completes the first part of the problem.\n\nFor the second part, we must verify the Lyapunov decrease inequality:\n$$V(x^{+}) - V(x) \\leq -\\left(x^{\\top} Q x + x^{\\top} K^{\\top} R K x\\right)$$\nwhere $V(x) = x^{\\top} P x$ and $x^{+} = A_K x$.\nThe left-hand side (LHS) is:\n$$V(x^{+}) - V(x) = (A_K x)^{\\top} P (A_K x) - x^{\\top} P x = x^{\\top} (A_K^{\\top} P A_K - P) x$$\nThe right-hand side (RHS) is:\n$$-\\left(x^{\\top} Q x + x^{\\top} K^{\\top} R K x\\right) = -x^{\\top} (Q + K^{\\top} R K) x$$\nThe inequality is equivalent to showing $x^{\\top} (A_K^{\\top} P A_K - P) x \\leq -x^{\\top} (Q + K^{\\top} R K) x$.\nBy the very definition of $P$ from the Lyapunov equation $P = A_K^{\\top} P A_K + Q + K^{\\top} R K$, we can rearrange it to:\n$$A_K^{\\top} P A_K - P = -(Q + K^{\\top} R K)$$\nThis means that the matrices defining the quadratic forms on both sides of the inequality are not just related by an inequality, but are in fact equal. Substituting this equality into the LHS of the inequality yields:\n$$x^{\\top} (-(Q + K^{\\top} R K)) x = -x^{\\top} (Q + K^{\\top} R K) x$$\nThis is precisely the RHS. Therefore, for a matrix $P$ that solves the Lyapunov equation, the relation holds with equality:\n$$V(x^{+}) - V(x) = -\\left(x^{\\top} Q x + x^{\\top} K^{\\top} R K x\\right)$$\nSince equality implies the \"less than or equal to\" condition, the inequality is trivially verified by the construction of $P$. To be thorough, we can re-insert our computed values to show the matrix equality $A_K^{\\top} P A_K - P = -(Q + K^{\\top} R K)$ holds.\nWe calculated $A_K^{\\top} P A_K = \\begin{bmatrix} 3  3 \\\\ 3  3 \\end{bmatrix}$ and $P = \\begin{bmatrix} 5  5 \\\\ 5  8 \\end{bmatrix}$.\n$$A_K^{\\top} P A_K - P = \\begin{bmatrix} 3  3 \\\\ 3  3 \\end{bmatrix} - \\begin{bmatrix} 5  5 \\\\ 5  8 \\end{bmatrix} = \\begin{bmatrix} -2  -2 \\\\ -2  -5 \\end{bmatrix}$$\nAnd we calculated $Q_{cl} = Q + K^{\\top} R K = \\begin{bmatrix} 2  2 \\\\ 2  5 \\end{bmatrix}$.\n$$-(Q + K^{\\top} R K) = -\\begin{bmatrix} 2  2 \\\\ 2  5 \\end{bmatrix} = \\begin{bmatrix} -2  -2 \\\\ -2  -5 \\end{bmatrix}$$\nThe matrices are identical, which confirms our solution for $P$ is correct and verifies the condition.", "answer": "$$\\boxed{\\begin{pmatrix} 5  5 \\\\ 5  8 \\end{pmatrix}}$$", "id": "2746597"}, {"introduction": "After establishing nominal stability, a crucial next step is to ensure the controller operates safely in the real world, where disturbances are unavoidable. This practice introduces a fundamental tool for this purpose: the Robust Positively Invariant (RPI) set, which precisely characterizes the region to which the state error is confined under persistent disturbances. By calculating the minimal RPI set from first principles and using it to tighten state constraints, you will gain hands-on experience with a core technique for guaranteeing robust feasibility in MPC [@problem_id:2746575].", "problem": "Consider a discrete-time Linear Time-Invariant (LTI) closed-loop error system under Model Predictive Control (MPC) with additive bounded disturbance given by the dynamics $e_{k+1} = A_{K} e_{k} + w_{k}$, where $A_{K} \\in \\mathbb{R}^{n \\times n}$ and $w_{k} \\in W$ for all $k \\in \\mathbb{N}$. A set $\\mathcal{E} \\subset \\mathbb{R}^{n}$ is called a Robust Positively Invariant (RPI) set for this system if $A_{K} \\mathcal{E} \\oplus W \\subseteq \\mathcal{E}$, where $\\oplus$ denotes Minkowski sum. In robust MPC, nominal state constraints are typically tightened by the RPI set so that the nominal state remains feasible despite disturbances; specifically, for a symmetric convex constraint set $X$, a common tightening is $X_{\\text{tight}} = X \\ominus \\mathcal{E}$, where $\\ominus$ denotes the Pontryagin difference.\n\nSuppose $A_{K} = 0.5 I$ and the disturbance set is the axis-aligned hypercube $W = \\{ w \\in \\mathbb{R}^{n} : \\|w\\|_{\\infty} \\le 0.1 \\}$. The nominal state constraint set is $X = \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{\\infty} \\le 1 \\}$. Using only fundamental definitions of RPI sets, Minkowski sums, and limits of set-valued series, derive the minimal RPI set $\\mathcal{E}$ as the limit of the Minkowski sum series generated by repeated propagation of $W$ through the closed-loop dynamics. Then, from first principles, quantify the induced infinity-norm constraint tightening, defined as the scalar $\\tau$ that must be subtracted from each bound of $X$ so that $X_{\\text{tight}} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{\\infty} \\le 1 - \\tau \\}$ satisfies $X_{\\text{tight}} \\oplus \\mathcal{E} \\subseteq X$.\n\nProvide the exact value of the tightening magnitude $\\tau$ as your final answer. No rounding is required. The final answer must be a single real number.", "solution": "This problem is scientifically grounded in the principles of robust MPC. The derivation of the minimal Robust Positively Invariant (RPI) set and the corresponding constraint tightening is a standard and well-posed procedure. A solution will be provided based on the given definitions.\n\nThe first step is to derive the minimal Robust Positively Invariant (RPI) set, $\\mathcal{E}$, for the given system. The minimal RPI set is the set of all states reachable from the origin ($e_0 = 0$) under the action of all possible disturbance sequences. It is constructed as the infinite Minkowski sum of the disturbance set propagated by the system dynamics.\nThe state at time step $k$, starting from $e_0 = 0$, is given by:\n$$ e_k = \\sum_{i=0}^{k-1} A_K^i w_{k-1-i} $$\nThe set of all possible states at any time is the union of all reachable sets. The minimal RPI set $\\mathcal{E}$ is the limit of these reachable sets as $k \\to \\infty$:\n$$ \\mathcal{E} = \\bigoplus_{i=0}^{\\infty} A_K^i W $$\nThis series converges because the system matrix $A_K$ is Schur stable. The eigenvalues of $A_K = 0.5 I$ are all $0.5$, which have a magnitude less than $1$.\nSubstituting the given $A_K = 0.5 I$:\n$$ A_K^i = (0.5 I)^i = (0.5)^i I $$\nThe minimal RPI set is therefore:\n$$ \\mathcal{E} = \\bigoplus_{i=0}^{\\infty} (0.5)^i I W = \\bigoplus_{i=0}^{\\infty} (0.5)^i W $$\nThe disturbance set $W = \\{ w \\in \\mathbb{R}^{n} : \\|w\\|_{\\infty} \\le 0.1 \\}$ is a convex, centrally symmetric set (an origin-centered hypercube). For such sets, scaling and Minkowski addition have the property that $\\alpha S \\oplus \\beta S = (\\alpha+\\beta)S$ for non-negative scalars $\\alpha, \\beta$. Extending this to the infinite sum, we can write:\n$$ \\mathcal{E} = \\left( \\sum_{i=0}^{\\infty} (0.5)^i \\right) W $$\nThe sum is a geometric series with ratio $r = 0.5$:\n$$ \\sum_{i=0}^{\\infty} (0.5)^i = \\frac{1}{1 - 0.5} = \\frac{1}{0.5} = 2 $$\nThus, the minimal RPI set is:\n$$ \\mathcal{E} = 2 W = 2 \\{ w \\in \\mathbb{R}^{n} : \\|w\\|_{\\infty} \\le 0.1 \\} $$\nTo characterize this set, let $e \\in \\mathcal{E}$. Then $e = 2w$ for some $w \\in W$. The norm of $e$ is $\\|e\\|_{\\infty} = \\|2w\\|_{\\infty} = 2\\|w\\|_{\\infty}$. Since $\\|w\\|_{\\infty} \\le 0.1$, it follows that $\\|e\\|_{\\infty} \\le 2 \\times 0.1 = 0.2$.\nSo, the minimal RPI set is the hypercube:\n$$ \\mathcal{E} = \\{ e \\in \\mathbb{R}^{n} : \\|e\\|_{\\infty} \\le 0.2 \\} $$\n\nThe second step is to determine the tightening magnitude $\\tau$. The tightened constraint set is given as $X_{\\text{tight}} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{\\infty} \\le 1 - \\tau \\}$. This set must satisfy the condition $X_{\\text{tight}} \\oplus \\mathcal{E} \\subseteq X$. This condition ensures that if the nominal state is in $X_{\\text{tight}}$, the true state (nominal plus error) remains within the original constraint set $X$.\n\nLet us analyze the Minkowski sum $X_{\\text{tight}} \\oplus \\mathcal{E}$. Both $X_{\\text{tight}}$ and $\\mathcal{E}$ are origin-centered hypercubes, defined by infinity-norm bounds.\n- $X_{\\text{tight}}$ is a hypercube of infinity-norm radius $1 - \\tau$.\n- $\\mathcal{E}$ is a hypercube of infinity-norm radius $0.2$.\nThe Minkowski sum of two origin-centered hypercubes is another origin-centered hypercube whose radius is the sum of their radii.\nLet $z \\in X_{\\text{tight}} \\oplus \\mathcal{E}$. Then $z = x + e$ for some $x \\in X_{\\text{tight}}$ and $e \\in \\mathcal{E}$. The infinity norm of $z$ is bounded by:\n$$ \\|z\\|_{\\infty} = \\|x+e\\|_{\\infty} \\le \\|x\\|_{\\infty} + \\|e\\|_{\\infty} $$\nThe maximum possible value is attained, so the resulting set is characterized by:\n$$ \\sup_{z \\in X_{\\text{tight}} \\oplus \\mathcal{E}} \\|z\\|_{\\infty} = \\sup_{x \\in X_{\\text{tight}}} \\|x\\|_{\\infty} + \\sup_{e \\in \\mathcal{E}} \\|e\\|_{\\infty} = (1 - \\tau) + 0.2 = 1.2 - \\tau $$\nSo, $X_{\\text{tight}} \\oplus \\mathcal{E} = \\{ z \\in \\mathbb{R}^{n} : \\|z\\|_{\\infty} \\le 1.2 - \\tau \\}$.\nThe condition $X_{\\text{tight}} \\oplus \\mathcal{E} \\subseteq X$ becomes:\n$$ \\{ z \\in \\mathbb{R}^{n} : \\|z\\|_{\\infty} \\le 1.2 - \\tau \\} \\subseteq \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{\\infty} \\le 1 \\} $$\nFor this set inclusion to hold, the radius of the inner set must be less than or equal to the radius of the outer set:\n$$ 1.2 - \\tau \\le 1 $$\nThis implies $0.2 \\le \\tau$. To ensure feasibility while being minimally conservative, we must choose the smallest possible value for the tightening $\\tau$. The minimal tightening that satisfies the condition is $\\tau = 0.2$.\n\nThis is equivalent to computing the Pontryagin difference $X \\ominus \\mathcal{E}$. By definition, $X \\ominus \\mathcal{E} = \\{ x \\in \\mathbb{R}^n \\mid x \\oplus \\mathcal{E} \\subseteq X \\}$.\nFor an element $x$ to be in this set, we must have $x+e \\in X$ for all $e \\in \\mathcal{E}$. This means $\\|x+e\\|_{\\infty} \\le 1$ for all $\\|e\\|_{\\infty} \\le 0.2$.\nThe maximal value of $\\|x+e\\|_{\\infty}$ for a fixed $x$ is $\\|x\\|_{\\infty} + \\sup_{e \\in \\mathcal{E}}\\|e\\|_{\\infty}$.\nSo, the condition is $\\|x\\|_{\\infty} + 0.2 \\le 1$, which simplifies to $\\|x\\|_{\\infty} \\le 0.8$.\nThis defines the maximally large tightened set: $X_{\\text{tight}} = \\{ x \\in \\mathbb{R}^n \\mid \\|x\\|_{\\infty} \\le 0.8 \\}$.\nComparing this to the given form $X_{\\text{tight}} = \\{ x \\in \\mathbb{R}^n \\mid \\|x\\|_{\\infty} \\le 1 - \\tau \\}$, we equate the bounds:\n$$ 1 - \\tau = 0.8 $$\nSolving for $\\tau$ gives $\\tau = 1 - 0.8 = 0.2$.\nThe tightening magnitude is $\\tau = 0.2$.", "answer": "$$\n\\boxed{0.2}\n$$", "id": "2746575"}, {"introduction": "Having developed tools for nominal stability and robust feasibility, we can now synthesize these concepts to analyze the overall performance of the closed-loop system. In the presence of disturbances, the state typically converges not to the origin but to a small neighborhood around it. This exercise guides you through a complete Input-to-State Stability (ISS) analysis to formally quantify the size of this neighborhood by deriving an 'ultimate bound' on the state as a function of the disturbance magnitude [@problem_id:2746619].", "problem": "Consider the discrete-time linear system with additive disturbance\n$$\nx_{k+1} \\;=\\; A x_k + B u_k + w_k,\n$$\nwhere $x_k \\in \\mathbb{R}$, $u_k \\in \\mathbb{R}$, and the disturbance satisfies $|w_k| \\le \\bar{w}$ for all $k \\in \\mathbb{N}$. A Model Predictive Control (MPC) scheme with horizon $N=1$ is used, with the quadratic cost\n$$\nJ(x_k,u_k) \\;=\\; x_k^{\\top} Q x_k \\;+\\; u_k^{\\top} R u_k \\;+\\; x_{k+1}^{\\top} P x_{k+1},\n$$\nwhere $Q \\succ 0$, $R \\succ 0$, and $P \\succeq 0$. Assume no constraints so that the optimizer is always feasible. Let $V_1(x)$ denote the optimal value of $J$ at state $x$.\n\nTake the specific data\n$$\nA = 0.8,\\quad B = 1,\\quad Q = 1,\\quad R = 1,\\quad P = 1,\n$$\nand assume the Euclidean norm, which for scalars is the absolute value. Starting from the definitions of unconstrained finite-horizon optimal control, compute the induced receding-horizon feedback, the corresponding one-step value function $V_1(x)$, and the closed-loop dynamics under the MPC law in the presence of the disturbance $w_k$. Then, using only norm inequalities that hold for all disturbances satisfying $|w_k| \\le \\bar{w}$, derive constants $\\lambda  0$ and $c  0$ such that the Lyapunov difference inequality\n$$\nV_1(x_{k+1}) - V_1(x_k) \\;\\le\\; -\\,\\lambda\\,\\|x_k\\|^2 \\;+\\; c\\,\\bar{w}^2\n$$\nholds for all $x_k$. From this inequality and quadratic bounds relating $V_1(x)$ to $\\|x\\|^2$, determine the smallest ultimate bound on $\\|x_k\\|$ implied by these calculations. Express your final answer as a closed-form analytic expression in terms of $\\bar{w}$ only. No units are required.", "solution": "The problem statement is critically reviewed and determined to be valid. It is a well-posed problem in the field of control theory, specifically concerning the stability analysis of a discrete-time system under Model Predictive Control (MPC) in the presence of bounded disturbances. The provided data are complete, consistent, and scientifically sound. We proceed with the solution.\n\nThe system is a discrete-time linear time-invariant (LTI) system given by\n$$x_{k+1} = A x_k + B u_k + w_k$$\nwith scalar state $x_k \\in \\mathbb{R}$, control input $u_k \\in \\mathbb{R}$, and disturbance $w_k$ satisfying $|w_k| \\le \\bar{w}$. The given parameters are $A=0.8$ and $B=1$.\n\nThe MPC law is derived by minimizing the cost function $J$ with prediction horizon $N=1$. The predicted next state, used in the cost function, is the nominal state $x_{k+1|k} = A x_k + B u_k$. The cost function is\n$$J(x_k, u_k) = x_k^{\\top} Q x_k + u_k^{\\top} R u_k + x_{k+1|k}^{\\top} P x_{k+1|k}$$\nwhich for the scalar case becomes\n$$J(x_k, u_k) = Q x_k^2 + R u_k^2 + P (A x_k + B u_k)^2$$\nThe optimization problem at each time step $k$ is $\\min_{u_k} J(x_k, u_k)$. To find the optimal control $u_k^*$, we take the derivative of $J$ with respect to $u_k$ and set it to zero, noting that $Qx_k^2$ is constant with respect to $u_k$.\n$$\\frac{\\partial J}{\\partial u_k} = 2 R u_k + 2 P (A x_k + B u_k) B = 0$$\nSolving for $u_k$:\n$$(R + P B^2) u_k = - P B A x_k$$\n$$u_k^* = -\\frac{PBA}{R+PB^2} x_k$$\nThis defines the receding-horizon feedback law $u_k = K x_k$, where the feedback gain $K$ is\n$$K = -\\frac{PBA}{R+PB^2}$$\nSubstituting the given values $A=0.8$, $B=1$, $R=1$, $P=1$:\n$$K = -\\frac{1 \\cdot 1 \\cdot 0.8}{1 + 1 \\cdot 1^2} = -\\frac{0.8}{2} = -0.4$$\nSo, the MPC feedback is $u_k = -0.4 x_k$.\n\nThe one-step value function $V_1(x_k)$ is the optimal cost, obtained by substituting $u_k^* = Kx_k$ back into the cost function expression.\n$$V_1(x_k) = Q x_k^2 + R (K x_k)^2 + P (A x_k + B K x_k)^2$$\n$$V_1(x_k) = \\left( Q + R K^2 + P (A+BK)^2 \\right) x_k^2$$\nLet's define the coefficient $S_1 = Q + R K^2 + P (A+BK)^2$. The closed-loop nominal dynamics matrix is $A_{cl} = A+BK$.\nWith the given values:\n$A_{cl} = 0.8 + 1(-0.4) = 0.4$.\n$S_1 = 1 + 1(-0.4)^2 + 1(0.4)^2 = 1 + 0.16 + 0.16 = 1.32$.\nThus, the value function is $V_1(x_k) = 1.32 x_k^2$.\n\nThe closed-loop dynamics of the actual system under the MPC law in the presence of the disturbance $w_k$ is\n$$x_{k+1} = A x_k + B (K x_k) + w_k = (A+BK) x_k + w_k = A_{cl} x_k + w_k$$\nNumerically, this is $x_{k+1} = 0.4 x_k + w_k$.\n\nNext, we derive the Lyapunov difference inequality. We analyze the change in the value function along the trajectories of the disturbed system.\n$$\\Delta V_1 = V_1(x_{k+1}) - V_1(x_k) = S_1 x_{k+1}^2 - S_1 x_k^2$$\n$$\\Delta V_1 = S_1 (A_{cl} x_k + w_k)^2 - S_1 x_k^2$$\n$$\\Delta V_1 = S_1(A_{cl}^2 x_k^2 + 2 A_{cl} x_k w_k + w_k^2) - S_1 x_k^2$$\n$$\\Delta V_1 = S_1(A_{cl}^2 - 1) x_k^2 + 2 S_1 A_{cl} x_k w_k + S_1 w_k^2$$\nSubstituting the numerical values $S_1=1.32$ and $A_{cl}=0.4$:\n$$S_1(A_{cl}^2 - 1) = 1.32(0.4^2 - 1) = 1.32(0.16-1) = 1.32(-0.84) = -1.1088$$\n$$2 S_1 A_{cl} = 2 \\cdot 1.32 \\cdot 0.4 = 1.056$$\nSo the difference is\n$$\\Delta V_1 = -1.1088 x_k^2 + 1.056 x_k w_k + 1.32 w_k^2$$\nTo obtain the desired inequality, we must bound the cross-term $1.056 x_k w_k$ and the disturbance term $1.32 w_k^2$. We use Young's inequality for the cross-term: for any $\\eta  0$, $2ab \\le \\eta a^2 + \\frac{1}{\\eta} b^2$. Applied to $2|x_k||w_k|$, this gives $|x_k w_k| \\le \\frac{\\eta}{2}x_k^2 + \\frac{1}{2\\eta}w_k^2$.\n$$1.056 x_k w_k \\le 1.056 |x_k w_k| \\le 1.056 \\left( \\frac{\\eta}{2}x_k^2 + \\frac{1}{2\\eta}w_k^2 \\right) = 0.528\\eta x_k^2 + \\frac{0.528}{\\eta} w_k^2$$\nAlso, using the given bound on the disturbance, $|w_k| \\le \\bar{w}$, we have $w_k^2 \\le \\bar{w}^2$.\nSubstituting these bounds into the expression for $\\Delta V_1$:\n$$\\Delta V_1 \\le -1.1088 x_k^2 + \\left( 0.528\\eta x_k^2 + \\frac{0.528}{\\eta} w_k^2 \\right) + 1.32 w_k^2$$\n$$\\Delta V_1 \\le -(1.1088 - 0.528\\eta) x_k^2 + \\left(\\frac{0.528}{\\eta} + 1.32\\right) w_k^2$$\n$$\\Delta V_1 \\le -(1.1088 - 0.528\\eta) x_k^2 + \\left(\\frac{0.528}{\\eta} + 1.32\\right) \\bar{w}^2$$\nThis matches the form $V_1(x_{k+1}) - V_1(x_k) \\le -\\lambda \\|x_k\\|^2 + c \\bar{w}^2$, with $\\|x_k\\|^2=x_k^2$, and\n$$\\lambda(\\eta) = 1.1088 - 0.528\\eta$$\n$$c(\\eta) = \\frac{0.528}{\\eta} + 1.32$$\nFor $\\lambda$ to be positive, we require $1.1088 - 0.528\\eta  0$, which means $\\eta  \\frac{1.1088}{0.528} = 2.1$.\n\nThe state trajectory ultimately enters the set where $\\Delta V_1 \\ge 0$, which is bounded by the condition $\\lambda x_k^2 \\le c \\bar{w}^2$. This implies an ultimate bound on the state magnitude given by $\\|x_k\\| \\le \\sqrt{\\frac{c(\\eta)}{\\lambda(\\eta)}} \\bar{w}$. To find the smallest ultimate bound implied by this method, we must minimize the ratio $\\frac{c(\\eta)}{\\lambda(\\eta)}$ with respect to $\\eta \\in (0, 2.1)$.\nLet $f(\\eta) = \\frac{c(\\eta)}{\\lambda(\\eta)} = \\frac{1.32 + 0.528/\\eta}{1.1088 - 0.528\\eta} = \\frac{1.32\\eta + 0.528}{1.1088\\eta - 0.528\\eta^2}$.\nTo find the minimum, we set the derivative $f'(\\eta)$ to zero. This leads to its numerator being zero:\n$$(1.32)(1.1088\\eta - 0.528\\eta^2) - (1.32\\eta + 0.528)(1.1088 - 1.056\\eta) = 0$$\nThis simplifies to the quadratic equation for $\\eta$:\n$$0.69696\\eta^2 + 0.557568\\eta - 0.5853504 = 0$$\nDividing by $0.69696$ yields:\n$$\\eta^2 + 0.8\\eta - 0.84 = 0$$\nThe solutions are $\\eta = \\frac{-0.8 \\pm \\sqrt{0.8^2 - 4(1)(-0.84)}}{2} = \\frac{-0.8 \\pm \\sqrt{0.64 + 3.36}}{2} = \\frac{-0.8 \\pm \\sqrt{4}}{2}$.\nSince $\\eta  0$, we take the positive root: $\\eta = \\frac{-0.8+2}{2} = 0.6$. This value is in the valid range $(0, 2.1)$.\n\nWe substitute $\\eta=0.6$ back into the expressions for $\\lambda$ and $c$:\n$$\\lambda = 1.1088 - 0.528(0.6) = 1.1088 - 0.3168 = 0.792$$\n$$c = \\frac{0.528}{0.6} + 1.32 = 0.88 + 1.32 = 2.2$$\nThe minimized ratio is\n$$\\frac{c}{\\lambda} = \\frac{2.2}{0.792} = \\frac{2200}{792} = \\frac{25 \\cdot 88}{9 \\cdot 88} = \\frac{25}{9}$$\nThe smallest ultimate bound on $\\|x_k\\|$ is therefore\n$$\\|x_k\\|_{\\text{ult}} = \\sqrt{\\frac{c}{\\lambda}} \\bar{w} = \\sqrt{\\frac{25}{9}} \\bar{w} = \\frac{5}{3} \\bar{w}$$\nThe quadratic bounds relating $V_1(x)$ to $\\|x\\|^2$ are given by $\\alpha_1 \\|x\\|^2 \\le V_1(x) \\le \\alpha_2 \\|x\\|^2$. For this scalar problem, $V_1(x) = 1.32 x^2$ and $\\|x\\|^2=x^2$, so we have $\\alpha_1 = \\alpha_2 = 1.32  0$. This confirms $V_1(x)$ is a valid Lyapunov function candidate, which makes the ultimate bound argument rigorous.", "answer": "$$\\boxed{\\frac{5}{3}\\bar{w}}$$", "id": "2746619"}]}