{"hands_on_practices": [{"introduction": "This practice will guide you through the concrete steps of designing a residual generator using the parity-space method. By explicitly constructing the data-driven matrices for a given system, you will learn how to algebraically eliminate the effects of the initial state and known inputs. This exercise [@problem_id:2706941] demystifies the process of creating a signal that is, by design, primarily responsive to faults and disturbances.", "problem": "Consider the discrete-time single-input single-output (SISO) linear time-invariant system with an additive sensor fault given by\n$$\nx_{k+1}=A x_k + B u_k, \\quad y_k = C x_k + D u_k + f_k,\n$$\nwhere\n$$\nA=\\begin{pmatrix}0.6 & 1.0\\\\ 0 & 0.3\\end{pmatrix},\\quad\nB=\\begin{pmatrix}1\\\\ 0\\end{pmatrix},\\quad\nC=\\begin{pmatrix}1 & 0\\end{pmatrix},\\quad\nD=0.2,\n$$\nand $f_k$ is an unknown sensor fault. The pair $\\left(A,C\\right)$ is observable. Define the stacked horizon-$N$ vectors\n$$\nY=\\begin{pmatrix}y_0\\\\ y_1\\\\ y_2\\\\ y_3\\end{pmatrix},\\quad\nU=\\begin{pmatrix}u_0\\\\ u_1\\\\ u_2\\\\ u_3\\end{pmatrix},\\quad\nf=\\begin{pmatrix}f_0\\\\ f_1\\\\ f_2\\\\ f_3\\end{pmatrix},\n$$\nwith $N=4$. Starting from first principles (state recursion and output equations), explicitly assemble the stacked data equation\n$$\nY=\\mathcal{T}_U\\,U+\\mathcal{T}_X\\,x_0+\\mathcal{T}_F\\,F\\,f,\n$$\nby constructing the $4\\times 4$ lower block Toeplitz input matrix $\\mathcal{T}_U$, the $4\\times 2$ extended observability matrix $\\mathcal{T}_X$, and the $4\\times 4$ fault distribution matrix $\\mathcal{T}_F$ together with the fault signature $F$. Then, by exploiting only linear-algebraic properties of these matrices, derive an explicit nontrivial parity matrix that eliminates both the unknown initial condition $x_0$ and the measured input $U$. Specifically, construct matrices $Q_y\\in\\mathbb{R}^{2\\times 4}$ and $Q_u\\in\\mathbb{R}^{2\\times 4}$ such that\n$$\nQ_y\\,\\mathcal{T}_X=0,\\qquad Q_y\\,\\mathcal{T}_U+Q_u=0,\n$$\nand hence the residual\n$$\nr = Q_y\\,Y + Q_u\\,U\n$$\ndepends only on the fault. Provide one explicit numerical choice of the block parity matrix $\\Pi=\\big[\\,Q_y\\;\\;Q_u\\,\\big]\\in\\mathbb{R}^{2\\times 8}$. Your final answer must be this $\\Pi$ as a single analytic expression. No rounding is required and no units are involved.", "solution": "The starting point is the state recursion and the output map,\n$$\nx_{k+1}=A x_k + B u_k,\\qquad y_k = C x_k + D u_k + f_k,\n$$\ntogether with the definition of the stacked vectors for a horizon $N=4$,\n$$\nY=\\begin{pmatrix}y_0\\\\ y_1\\\\ y_2\\\\ y_3\\end{pmatrix},\\quad\nU=\\begin{pmatrix}u_0\\\\ u_1\\\\ u_2\\\\ u_3\\end{pmatrix},\\quad\nf=\\begin{pmatrix}f_0\\\\ f_1\\\\ f_2\\\\ f_3\\end{pmatrix}.\n$$\nFrom the recursion, one obtains the well-known expressions for the outputs over the horizon by repeatedly substituting the state update into the output equation:\n$$\n\\begin{aligned}\ny_0 &= C x_0 + D u_0 + f_0,\\\\\ny_1 &= C A x_0 + C B u_0 + D u_1 + f_1,\\\\\ny_2 &= C A^2 x_0 + C A B u_0 + C B u_1 + D u_2 + f_2,\\\\\ny_3 &= C A^3 x_0 + C A^2 B u_0 + C A B u_1 + C B u_2 + D u_3 + f_3.\n\\end{aligned}\n$$\nStacking these four equations yields\n$$\nY=\\underbrace{\\begin{pmatrix}\nD & 0 & 0 & 0\\\\\nC B & D & 0 & 0\\\\\nC A B & C B & D & 0\\\\\nC A^2 B & C A B & C B & D\n\\end{pmatrix}}_{\\mathcal{T}_U}\\,U+\n\\underbrace{\\begin{pmatrix}\nC\\\\\nC A\\\\\nC A^2\\\\\nC A^3\n\\end{pmatrix}}_{\\mathcal{T}_X}\\,x_0+\n\\underbrace{I_4}_{\\mathcal{T}_F}\\,\\underbrace{1}_{F}\\,f.\n$$\nThus $\\mathcal{T}_F=I_4$ and $F=1$ for an additive sensor fault.\n\nNext, compute the needed Markov parameters and powers of $A$ to explicitly construct $\\mathcal{T}_U$ and $\\mathcal{T}_X$. With\n$$\nA=\\begin{pmatrix}0.6 & 1.0\\\\ 0 & 0.3\\end{pmatrix},\\quad\nB=\\begin{pmatrix}1\\\\ 0\\end{pmatrix},\\quad\nC=\\begin{pmatrix}1 & 0\\end{pmatrix},\\quad\nD=0.2,\n$$\none finds\n$$\nA^2=\\begin{pmatrix}0.36 & 0.9\\\\ 0 & 0.09\\end{pmatrix},\\qquad\nA^3=\\begin{pmatrix}0.216 & 0.63\\\\ 0 & 0.027\\end{pmatrix}.\n$$\nTherefore,\n$$\n\\begin{aligned}\nC &= \\begin{pmatrix}1 & 0\\end{pmatrix},\\\\\nC A &= \\begin{pmatrix}0.6 & 1\\end{pmatrix},\\\\\nC A^2 &= \\begin{pmatrix}0.36 & 0.9\\end{pmatrix},\\\\\nC A^3 &= \\begin{pmatrix}0.216 & 0.63\\end{pmatrix},\n\\end{aligned}\n$$\nso that\n$$\n\\mathcal{T}_X=\\begin{pmatrix}\n1 & 0\\\\\n0.6 & 1\\\\\n0.36 & 0.9\\\\\n0.216 & 0.63\n\\end{pmatrix}.\n$$\nFor the input Toeplitz matrix, the Markov parameters are\n$$\ng_0 = D = 0.2,\\quad g_1 = C B = 1,\\quad g_2 = C A B = 0.6,\\quad g_3 = C A^2 B = 0.36,\n$$\nyielding\n$$\n\\mathcal{T}_U=\\begin{pmatrix}\n0.2 & 0   & 0   & 0\\\\\n1   & 0.2 & 0   & 0\\\\\n0.6 & 1   & 0.2 & 0\\\\\n0.36& 0.6 & 1   & 0.2\n\\end{pmatrix}.\n$$\n\nTo eliminate the dependence on the unknown initial condition $x_0$ and on the measured inputs $U$, we construct a parity residual of the form\n$$\nr = Q_y\\,Y + Q_u\\,U,\n$$\nwith $Q_y\\in\\mathbb{R}^{2\\times 4}$ and $Q_u\\in\\mathbb{R}^{2\\times 4}$ chosen to satisfy\n$$\nQ_y\\,\\mathcal{T}_X=0,\\qquad Q_y\\,\\mathcal{T}_U+Q_u=0.\n$$\nThe first condition requires that the rows of $Q_y$ lie in the left nullspace of $\\mathcal{T}_X$. Solve $Q_y\\,\\mathcal{T}_X=0$ by finding $q\\in\\mathbb{R}^4$ such that $\\mathcal{T}_X^{\\top} q=0$. Writing $q=\\begin{pmatrix}q_0 & q_1 & q_2 & q_3\\end{pmatrix}^{\\top}$, the equations\n$$\n\\begin{aligned}\nq_0\\cdot 1 + q_1\\cdot 0.6 + q_2\\cdot 0.36 + q_3\\cdot 0.216 &= 0,\\\\\nq_0\\cdot 0 + q_1\\cdot 1 + q_2\\cdot 0.9 + q_3\\cdot 0.63 &= 0,\n\\end{aligned}\n$$\nyield a two-parameter family\n$$\n\\begin{pmatrix}q_0\\\\ q_1\\\\ q_2\\\\ q_3\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.18\\,c + 0.162\\,d\\\\\n-0.9\\,c - 0.63\\,d\\\\\nc\\\\\nd\n\\end{pmatrix},\n\\quad c,d\\in\\mathbb{R}.\n$$\nChoosing the basis vectors corresponding to $(c,d)=(1,0)$ and $(c,d)=(0,1)$, we obtain two independent left-null vectors\n$$\nq^{(1)}=\\begin{pmatrix}0.18\\\\ -0.9\\\\ 1\\\\ 0\\end{pmatrix},\\qquad\nq^{(2)}=\\begin{pmatrix}0.162\\\\ -0.63\\\\ 0\\\\ 1\\end{pmatrix}.\n$$\nStacking these as rows gives\n$$\nQ_y=\\begin{pmatrix}\n0.18 & -0.9 & 1 & 0\\\\\n0.162 & -0.63 & 0 & 1\n\\end{pmatrix},\n$$\nwhich by construction satisfies $Q_y\\,\\mathcal{T}_X=0$.\n\nThe second condition $Q_y\\,\\mathcal{T}_U+Q_u=0$ determines $Q_u$ uniquely for this $Q_y$:\n$$\nQ_u = -\\,Q_y\\,\\mathcal{T}_U.\n$$\nCompute $Q_y\\,\\mathcal{T}_U$ explicitly. For the first row of $Q_y$,\n$$\n\\begin{aligned}\n\\begin{pmatrix}0.18 & -0.9 & 1 & 0\\end{pmatrix}\\mathcal{T}_U\n&= \\begin{pmatrix}-0.264 & 0.82 & 0.2 & 0\\end{pmatrix}.\n\\end{aligned}\n$$\nFor the second row of $Q_y$,\n$$\n\\begin{aligned}\n\\begin{pmatrix}0.162 & -0.63 & 0 & 1\\end{pmatrix}\\mathcal{T}_U\n&= \\begin{pmatrix}-0.2376 & 0.474 & 1 & 0.2\\end{pmatrix}.\n\\end{aligned}\n$$\nTherefore,\n$$\nQ_u=-Q_y\\,\\mathcal{T}_U=\n\\begin{pmatrix}\n0.264 & -0.82 & -0.2 & 0\\\\\n0.2376 & -0.474 & -1 & -0.2\n\\end{pmatrix}.\n$$\nWith these choices, the residual\n$$\nr = Q_y\\,Y + Q_u\\,U\n= Q_y\\left(\\mathcal{T}_U\\,U+\\mathcal{T}_X\\,x_0+\\mathcal{T}_F\\,F\\,f\\right)+Q_u\\,U\n= \\underbrace{Q_y\\,\\mathcal{T}_X}_{0}\\,x_0+\\underbrace{\\big(Q_y\\,\\mathcal{T}_U+Q_u\\big)}_{0}\\,U+Q_y\\,\\mathcal{T}_F\\,F\\,f,\n$$\nreduces to\n$$\nr = Q_y\\,f,\n$$\nsince $\\mathcal{T}_F=I_4$ and $F=1$. Thus the block parity matrix acting on the extended data vector $\\begin{pmatrix}Y^{\\top} & U^{\\top}\\end{pmatrix}^{\\top}$ is\n$$\n\\Pi=\\big[\\,Q_y\\;\\;Q_u\\,\\big]\n=\n\\begin{pmatrix}\n0.18 & -0.9 & 1 & 0 & \\;\\;0.264 & -0.82 & -0.2 & 0\\\\\n0.162 & -0.63 & 0 & 1 & \\;\\;0.2376 & -0.474 & -1 & -0.2\n\\end{pmatrix},\n$$\nwhich eliminates both the unknown initial state $x_0$ and the measured inputs $U$ from the residual.", "answer": "$$\\boxed{\\begin{pmatrix}\n0.18 & -0.9 & 1 & 0 & 0.264 & -0.82 & -0.2 & 0\\\\\n0.162 & -0.63 & 0 & 1 & 0.2376 & -0.474 & -1 & -0.2\n\\end{pmatrix}}$$", "id": "2706941"}, {"introduction": "Once a residual signal is generated, the next crucial step is to make a decision: is there a fault or is the signal just noise? This problem immerses you in the statistical heart of fault detection, guiding you through the design of a Neyman-Pearson detector. You will learn how to set a decision threshold $\\gamma$ to meet a specific false alarm rate $\\alpha$ and then determine the smallest fault magnitude $f_{\\min}$ that your detector can reliably identify [@problem_id:2706769].", "problem": "A residual generator for Fault Detection and Isolation (FDI) in a discrete-time Linear Time-Invariant system produces a scalar residual sequence $ r_k $. Under the no-fault hypothesis $ \\mathcal{H}_0 $, assume $ r_k $ are independent and identically distributed as Gaussian with zero mean and unknown variance $ \\sigma^2 $. A calibration experiment yields an unbiased variance estimate $ \\hat{\\sigma}^2 = 0.09 $, which you may treat as known for detector design due to a large calibration dataset.\n\nYou are to design a one-sided instantaneous detector aimed at a positive-mean bias fault in the residual, modeled under the fault hypothesis $ \\mathcal{H}_1 $ by $ r_k \\sim \\mathcal{N}(f, \\sigma^2) $ with $ f > 0 $ and the same variance as under $ \\mathcal{H}_0 $. The decision rule is of the Neyman–Pearson type: declare a fault at time $ k $ if $ r_k > \\gamma $, where $ \\gamma $ is a threshold to be determined.\n\nThe design requirements are:\n- The per-sample false alarm probability must equal $ \\alpha = 1.0 \\times 10^{-3} $ under $ \\mathcal{H}_0 $.\n- The per-sample detection probability must equal $ \\beta = 0.95 $ under $ \\mathcal{H}_1 $ when the mean shift is at its minimal detectable magnitude $ f_{\\min} $.\n\nStarting from first principles for Gaussian hypothesis testing and without using any pre-stated target formulas, derive:\n1. The threshold $ \\gamma $ that satisfies the false alarm requirement in terms of $ \\hat{\\sigma} $ and $ \\alpha $, and then compute its numerical value.\n2. The minimal detectable positive mean shift $ f_{\\min} $ that achieves the target detection probability $ \\beta $ for the threshold $ \\gamma $, and then compute its numerical value.\n\nExpress both $ \\gamma $ and $ f_{\\min} $ in the same unitless normalized residual units as $ r_k $. Report your final answer as a row vector $ [\\gamma, f_{\\min}] $. Round each entry to four significant figures. All probabilities must be treated as decimals, not percentages.", "solution": "The problem presented is a standard exercise in hypothesis testing, a core component of statistical signal processing for Fault Detection and Isolation (FDI). It is well-posed, scientifically grounded, and provides all necessary information for a unique solution. We shall proceed with the derivation from first principles.\n\nThe problem defines two hypotheses for the observed residual $r_k$ at any time step $k$:\nThe null hypothesis, $\\mathcal{H}_0$, corresponds to the no-fault condition:\n$$r_k \\sim \\mathcal{N}(0, \\sigma^2)$$\nThe alternative hypothesis, $\\mathcal{H}_1$, corresponds to the presence of a positive-mean bias fault:\n$$r_k \\sim \\mathcal{N}(f, \\sigma^2), \\quad \\text{with } f > 0$$\nThe variance $\\sigma^2$ is given as the known value $\\hat{\\sigma}^2 = 0.09$. Therefore, the standard deviation is $\\sigma = \\sqrt{0.09} = 0.3$.\nThe decision rule is to declare a fault if the observed residual $r_k$ exceeds a threshold $\\gamma$, i.e., $r_k > \\gamma$.\n\nFirst, we determine the threshold $\\gamma$.\nThe false alarm probability, $\\alpha$, is the probability of declaring a fault when none exists (i.e., when $\\mathcal{H}_0$ is true). The design specification requires $\\alpha = 1.0 \\times 10^{-3}$.\nBy definition,\n$$\\alpha = P(\\text{declare fault} | \\mathcal{H}_0) = P(r_k > \\gamma | r_k \\sim \\mathcal{N}(0, \\sigma^2))$$\nTo evaluate this probability, we standardize the random variable $r_k$. Let $Z = \\frac{r_k - \\mu}{\\sigma}$ be a standard normal random variable, $Z \\sim \\mathcal{N}(0, 1)$. Under $\\mathcal{H}_0$, the mean $\\mu$ is $0$.\nThe inequality $r_k > \\gamma$ can be rewritten in terms of the standard normal variable $Z$:\n$$\\frac{r_k}{\\sigma} > \\frac{\\gamma}{\\sigma} \\implies Z > \\frac{\\gamma}{\\sigma}$$\nTherefore, the false alarm probability is $\\alpha = P(Z > \\frac{\\gamma}{\\sigma})$.\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, defined as $\\Phi(z) = P(Z \\le z)$. Then, $P(Z > z) = 1 - \\Phi(z)$.\nSo, we have the relation:\n$$\\alpha = 1 - \\Phi\\left(\\frac{\\gamma}{\\sigma}\\right)$$\nRearranging for the CDF gives $\\Phi(\\frac{\\gamma}{\\sigma}) = 1 - \\alpha$.\nTo find the argument of $\\Phi$, we use the inverse cumulative distribution function, $\\Phi^{-1}$:\n$$\\frac{\\gamma}{\\sigma} = \\Phi^{-1}(1 - \\alpha)$$\nThis gives the analytical expression for the threshold $\\gamma$:\n$$\\gamma = \\sigma \\Phi^{-1}(1 - \\alpha)$$\nWe are given $\\sigma = 0.3$ and $\\alpha = 0.001$. We substitute these values:\n$$\\gamma = 0.3 \\times \\Phi^{-1}(1 - 0.001) = 0.3 \\times \\Phi^{-1}(0.999)$$\nThe value $\\Phi^{-1}(0.999)$ corresponds to the z-score leaving a tail probability of $0.001$. From standard normal tables or a calculator, $\\Phi^{-1}(0.999) \\approx 3.09023$.\n$$\\gamma \\approx 0.3 \\times 3.09023 \\approx 0.927069$$\nRounding to four significant figures, the threshold is $\\gamma \\approx 0.9271$.\n\nNext, we determine the minimal detectable positive mean shift $f_{\\min}$.\nThe detection probability, $\\beta$, is the probability of correctly declaring a fault when one exists (i.e., when $\\mathcal{H}_1$ is true). For the minimal detectable magnitude $f_{\\min}$, the problem specifies $\\beta = 0.95$.\nBy definition,\n$$\\beta = P(\\text{declare fault} | \\mathcal{H}_1 \\text{ with } f=f_{\\min}) = P(r_k > \\gamma | r_k \\sim \\mathcal{N}(f_{\\min}, \\sigma^2))$$\nAgain, we standardize the random variable $r_k$, this time under $\\mathcal{H}_1$. The mean is now $\\mu=f_{\\min}$.\n$$Z = \\frac{r_k - f_{\\min}}{\\sigma} \\sim \\mathcal{N}(0, 1)$$\nThe inequality $r_k > \\gamma$ becomes:\n$$r_k - f_{\\min} > \\gamma - f_{\\min} \\implies \\frac{r_k - f_{\\min}}{\\sigma} > \\frac{\\gamma - f_{\\min}}{\\sigma} \\implies Z > \\frac{\\gamma - f_{\\min}}{\\sigma}$$\nThe detection probability is thus:\n$$\\beta = P\\left(Z > \\frac{\\gamma - f_{\\min}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\gamma - f_{\\min}}{\\sigma}\\right)$$\nRearranging for the CDF gives $\\Phi(\\frac{\\gamma - f_{\\min}}{\\sigma}) = 1 - \\beta$.\nApplying the inverse CDF:\n$$\\frac{\\gamma - f_{\\min}}{\\sigma} = \\Phi^{-1}(1 - \\beta)$$\nNow, we solve for $f_{\\min}$:\n$$\\gamma - f_{\\min} = \\sigma \\Phi^{-1}(1 - \\beta)$$\n$$f_{\\min} = \\gamma - \\sigma \\Phi^{-1}(1 - \\beta)$$\nWe can substitute the expression for $\\gamma$ we derived earlier, $\\gamma = \\sigma \\Phi^{-1}(1 - \\alpha)$:\n$$f_{\\min} = \\sigma \\Phi^{-1}(1 - \\alpha) - \\sigma \\Phi^{-1}(1 - \\beta) = \\sigma \\left( \\Phi^{-1}(1 - \\alpha) - \\Phi^{-1}(1 - \\beta) \\right)$$\nNote the property that for the standard normal distribution, $\\Phi^{-1}(p) = -\\Phi^{-1}(1-p)$. This allows us to write $\\Phi^{-1}(1-\\beta) = -\\Phi^{-1}(\\beta)$.\n$$f_{\\min} = \\sigma \\left( \\Phi^{-1}(1 - \\alpha) + \\Phi^{-1}(\\beta) \\right)$$\nWe are given $\\sigma = 0.3$, $\\alpha = 0.001$, and $\\beta = 0.95$.\n$$f_{\\min} = 0.3 \\times \\left( \\Phi^{-1}(0.999) + \\Phi^{-1}(0.95) \\right)$$\nUsing the value $\\Phi^{-1}(0.999) \\approx 3.09023$ from before, and finding $\\Phi^{-1}(0.95) \\approx 1.64485$:\n$$f_{\\min} \\approx 0.3 \\times (3.09023 + 1.64485) = 0.3 \\times 4.73508$$\n$$f_{\\min} \\approx 1.420524$$\nRounding to four significant figures, the minimal detectable fault is $f_{\\min} \\approx 1.421$.\n\nThe required values are $\\gamma \\approx 0.9271$ and $f_{\\min} \\approx 1.421$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9271 & 1.421\n\\end{pmatrix}\n}\n$$", "id": "2706769"}, {"introduction": "Real-world systems can experience multiple simultaneous faults, which may conspire to hide their presence from a single detector. This exercise explores the critical concepts of detectability and isolability by analyzing a scenario where two faults cancel each other out in one residual. You will reason about why this \"fault masking\" occurs and how to design an auxiliary residual to resolve the ambiguity, a key step towards building robust, multi-fault isolation systems [@problem_id:2706778].", "problem": "Consider a stable linear time-invariant plant with a single known control input $u(t)$ and two measurable outputs $y_1(t)$ and $y_2(t)$. Two additive sensor-side fault channels $f_1(t)$ and $f_2(t)$ enter the measured outputs with known static gains, and measurement noise is zero-mean with known covariance. Specifically,\n$$\n\\begin{aligned}\ny_1(t) &= G_1(s)\\,u(t) \\;+\\; f_1(t) \\;+\\; f_2(t) \\;+\\; v_1(t),\\\\\ny_2(t) &= G_2(s)\\,u(t) \\;+\\; a\\,f_1(t) \\;+\\; b\\,f_2(t) \\;+\\; v_2(t),\n\\end{aligned}\n$$\nwhere $G_1(s)$ and $G_2(s)$ are known stable transfer functions, $a \\in \\mathbb{R}$ and $b \\in \\mathbb{R}$ are known constants, and $v_1(t)$ and $v_2(t)$ are zero-mean, wide-sense stationary, mutually uncorrelated measurement noises with finite variances. A standard parity residual for $y_1$ is defined as\n$$\nr_1(t) \\;=\\; y_1(t) \\;-\\; G_1(s)\\,u(t),\n$$\nand a threshold test $|r_1(t)| > \\tau_1$ is used for detection, with $\\tau_1 > 0$ chosen to meet a prescribed false-alarm probability under the fault-free hypothesis. The fault signatures in $r_1$ are additive and linear in $f_1$ and $f_2$.\n\nSuppose two step-like faults occur simultaneously with equal magnitudes and opposite signs, $f_1(t)=A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ and $f_2(t)=-A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ for some $A>0$, so that $f_1$ and $f_2$ cancel each other in $r_1$. You are asked to reason from first principles (linearity of the residual model, hypothesis testing interpretation of thresholding with zero-mean noise, and linear independence of fault signatures) about the consequences for detection using $r_1$, and to propose a secondary residual that resolves the ambiguity caused by cancellation.\n\nWhich option below correctly characterizes the degradation in detection performance caused by the cancellation in $r_1$ and proposes a secondary residual design that provably eliminates this ambiguity for the given two-fault pattern?\n\nA. Because $r_1$ experiences cancellation, its mean shift is zero, but its variance increases, so the detection probability strictly exceeds the false-alarm probability. Therefore, the most reliable remedy is to lower $\\tau_1$ until the cancelling faults are detected without significantly impacting false alarms.\n\nB. When $f_1(t)=A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ and $f_2(t)=-A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$, the scalar residual $r_1$ has zero mean shift relative to the fault-free case, so the detection probability collapses to the preset false-alarm probability. A remedy is to build a second parity residual $r_2(t)=y_2(t)-G_2(s)\\,u(t)=a\\,f_1(t)+b\\,f_2(t)+v_2(t)$ using the auxiliary measurement $y_2$, and to choose $a\\neq b$ so that the fault-signature matrix $S=\\begin{bmatrix}1 & 1\\\\ a & b\\end{bmatrix}$ is full column rank. Then, for $f_1=-f_2\\neq 0$, one has $r_1=0$ but $r_2=(a-b)f_1\\neq 0$, which restores detectability and enables least-squares estimation of $\\begin{bmatrix}f_1 & f_2\\end{bmatrix}^\\top$ from $\\begin{bmatrix}r_1 & r_2\\end{bmatrix}^\\top$.\n\nC. Cancellation in $r_1$ can always be eliminated by scaling: define a secondary residual $r_2(t)=k\\,r_1(t)$ for any $k\\neq 0$, which changes the cancellation direction and ensures $r_2\\neq 0$ whenever $f_1$ and $f_2$ are nonzero.\n\nD. Since the cancelling faults are step-like, passing $r_1$ through a high-pass filter to form $r_2$ will amplify the step content and thereby undo cancellation, improving detection and isolation without changing the measurement set.\n\nE. To maximize isolation capability, choose the auxiliary measurement so that $a=b$, which makes both faults affect $r_2$ identically; then ambiguity is eliminated because $r_1$ and $r_2$ carry redundant evidence of the faults in the same direction.", "solution": "The user requires a critical validation of the provided problem statement, followed by a first-principles derivation of the solution and a detailed analysis of all options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **System model**: A stable linear time-invariant (LTI) plant.\n*   **Input**: One known control input, $u(t)$.\n*   **Outputs**: Two measurable outputs, $y_1(t)$ and $y_2(t)$.\n*   **Measurement equations**:\n    $$\n    \\begin{aligned}\n    y_1(t) &= G_1(s)\\,u(t) \\;+\\; f_1(t) \\;+\\; f_2(t) \\;+\\; v_1(t) \\\\\n    y_2(t) &= G_2(s)\\,u(t) \\;+\\; a\\,f_1(t) \\;+\\; b\\,f_2(t) \\;+\\; v_2(t)\n    \\end{aligned}\n    $$\n*   **Definitions**:\n    *   $G_1(s)$, $G_2(s)$ are known, stable transfer functions.\n    *   $f_1(t)$, $f_2(t)$ are additive sensor-side fault signals.\n    *   $a \\in \\mathbb{R}$, $b \\in \\mathbb{R}$ are known constants.\n    *   $v_1(t)$, $v_2(t)$ are zero-mean, wide-sense stationary, mutually uncorrelated measurement noises with finite variances.\n*   **Residual and Detection for $y_1$**:\n    *   Residual: $r_1(t) = y_1(t) - G_1(s)\\,u(t)$.\n    *   Detection test: $|r_1(t)| > \\tau_1$, where $\\tau_1 > 0$ is a threshold.\n    *   Threshold $\\tau_1$ is set to achieve a prescribed false-alarm probability.\n*   **Specific Fault Scenario**:\n    *   $f_1(t) = A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ and $f_2(t)=-A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ for some constant $A > 0$.\n\n**Step 2: Validate Using Extracted Givens**\n\n1.  **Scientific Groundedness**: The problem is formulated within the standard mathematical framework of model-based fault detection and isolation (FDI) for LTI systems. All concepts—transfer functions, residuals, parity relations, fault signatures, and hypothesis testing—are fundamental to control theory and signal processing. The premises are scientifically sound.\n2.  **Well-Posedness**: The problem is well-posed. It presents a specific scenario of fault masking and asks for an analysis of its consequences and a structured remedy. A unique answer can be derived from the provided information.\n3.  **Objectivity**: The problem is stated in precise mathematical and engineering language. It is free of subjectivity or ambiguity.\n4.  **Completeness and Consistency**: The problem statement is self-contained. It provides all necessary equations, definitions, and conditions to analyze the system's behavior and evaluate potential solutions. There are no contradictions.\n5.  **Realism and Feasibility**: The scenario of analyzing fault directions that are \"difficult\" to detect is a cornerstone of robust FDI design. This specific case of canceling faults is a classic example used to illustrate the concepts of detectability and isolability. The setup is a standard theoretical model.\n\n**Step 3: Verdict and Action**\n\nThe problem statement is valid. It is a well-formulated problem in the field of Fault Detection and Isolation. I will proceed to derive the solution.\n\n### Solution Derivation\n\nThe primary residual $r_1(t)$ is defined as:\n$$r_1(t) = y_1(t) - G_1(s)\\,u(t)$$\nSubstituting the expression for $y_1(t)$:\n$$r_1(t) = \\left(G_1(s)\\,u(t) + f_1(t) + f_2(t) + v_1(t)\\right) - G_1(s)\\,u(t)$$\n$$r_1(t) = f_1(t) + f_2(t) + v_1(t)$$\nThis equation shows the relationship between the faults and the residual. It is a linear model. The term $f_1(t) + f_2(t)$ is the fault signature in the residual $r_1(t)$.\n\n**Analysis of Detection Performance Degradation**\n\nThe detection logic is a hypothesis test on the mean of the residual.\n*   **Null Hypothesis $H_0$ (Fault-Free)**: $f_1(t)=0$ and $f_2(t)=0$. The residual is $r_1(t) = v_1(t)$. Since $v_1(t)$ is a zero-mean process, the expected value of the residual is $E[r_1(t) | H_0] = 0$. The threshold $\\tau_1$ is chosen such that the false-alarm probability $P_{FA} = P(|r_1(t)| > \\tau_1 | H_0)$ is at a small, prescribed level.\n*   **Alternative Hypothesis $H_1$ (Fault-Present)**: The specific fault scenario is given by $f_1(t) = A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ and $f_2(t) = -A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$, where $A>0$.\n\nFor $t \\ge 0$, the residual under this fault scenario is:\n$$r_1(t) = A\\,\\mathbf{1}_{\\{t\\ge 0\\}} + (-A\\,\\mathbf{1}_{\\{t\\ge 0\\}}) + v_1(t) = A - A + v_1(t) = v_1(t)$$\nThe statistical properties of $r_1(t)$ under this specific fault are:\n*   **Mean**: $E[r_1(t) | H_1] = E[v_1(t)] = 0$.\n*   **Variance**: $\\text{Var}[r_1(t) | H_1] = \\text{Var}[v_1(t)]$.\n\nThe statistical distribution of the residual $r_1(t)$ under this specific fault scenario is identical to its distribution under the fault-free hypothesis $H_0$. Therefore, the probability of detection, $P_D = P(|r_1(t)| > \\tau_1 | H_1)$, becomes equal to the probability of false alarm, $P_{FA} = P(|v_1(t)| > \\tau_1) = P(|r_1(t)| > \\tau_1 | H_0)$. The fault is rendered completely undetectable by this residual, as it generates no mean shift. The detection performance collapses to the baseline false-alarm rate.\n\n**Proposing a Secondary Residual**\n\nThe ambiguity arises because the two faults affect $r_1(t)$ in a linearly dependent manner. To resolve this, we must introduce new information from the system. A secondary residual, $r_2(t)$, can be constructed from the second measurement, $y_2(t)$, using the same parity-space principle:\n$$r_2(t) = y_2(t) - G_2(s)\\,u(t)$$\nSubstituting the expression for $y_2(t)$:\n$$r_2(t) = \\left(G_2(s)\\,u(t) + a\\,f_1(t) + b\\,f_2(t) + v_2(t)\\right) - G_2(s)\\,u(t)$$\n$$r_2(t) = a\\,f_1(t) + b\\,f_2(t) + v_2(t)$$\nNow, we have a vector of residuals, $\\mathbf{r}(t) = \\begin{bmatrix} r_1(t) \\\\ r_2(t) \\end{bmatrix}$, whose noise-free part is related to the fault vector $\\mathbf{f}(t) = \\begin{bmatrix} f_1(t) \\\\ f_2(t) \\end{bmatrix}$ by a static matrix, the fault signature matrix $S$:\n$$ \\begin{bmatrix} r_1(t) \\\\ r_2(t) \\end{bmatrix} = \\begin{bmatrix} 1 & 1 \\\\ a & b \\end{bmatrix} \\begin{bmatrix} f_1(t) \\\\ f_2(t) \\end{bmatrix} + \\begin{bmatrix} v_1(t) \\\\ v_2(t) \\end{bmatrix} $$\nFor the fault vector $\\mathbf{f}(t)$ to be uniquely determinable from the residual vector $\\mathbf{r}(t)$ (in a noise-free sense), the matrix $S$ must be invertible, which means it must have full column rank. The condition for this is that its determinant must be non-zero:\n$$\\det(S) = (1)(b) - (1)(a) = b-a \\neq 0 \\implies a \\neq b$$\nIf $a \\neq b$, the fault signatures of $f_1$ and $f_2$ are linearly independent across the two residuals. Let's examine the effect on the specific canceling fault pattern $f_1(t) = -f_2(t) = A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$.\n*   For $r_1(t)$, the mean shift remains zero: $E[r_1(t)] = f_1+f_2 = A-A=0$.\n*   For $r_2(t)$, the mean shift is: $E[r_2(t)] = a\\,f_1 + b\\,f_2 = a(A) + b(-A) = (a-b)A$.\n\nIf $a \\neq b$ and $A > 0$, the mean shift $(a-b)A$ is non-zero. The fault, while invisible to $r_1(t)$, creates a detectable signature in $r_2(t)$. This restores detectability. Furthermore, with $S$ being full rank, one can find a unique least-squares estimate of the fault vector $\\mathbf{f}(t)$ from the measurement vector $\\mathbf{r}(t)$, thereby achieving fault isolation.\n\n### Option-by-Option Analysis\n\n**A. Because $r_1$ experiences cancellation, its mean shift is zero, but its variance increases, so the detection probability strictly exceeds the false-alarm probability. Therefore, the most reliable remedy is to lower $\\tau_1$ until the cancelling faults are detected without significantly impacting false alarms.**\n\n*   **Analysis**: This statement is incorrect. As derived, for the fault $f_1(t) + f_2(t) = 0$, the residual is $r_1(t) = v_1(t)$. Its variance does not increase; it remains $\\text{Var}[v_1(t)]$. The detection probability is exactly equal to the false-alarm probability. Lowering $\\tau_1$ is not a remedy; it inadmissibly increases the false-alarm rate.\n*   **Verdict**: Incorrect.\n\n**B. When $f_1(t)=A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$ and $f_2(t)=-A\\,\\mathbf{1}_{\\{t\\ge 0\\}}$, the scalar residual $r_1$ has zero mean shift relative to the fault-free case, so the detection probability collapses to the preset false-alarm probability. A remedy is to build a second parity residual $r_2(t)=y_2(t)-G_2(s)\\,u(t)=a\\,f_1(t)+b\\,f_2(t)+v_2(t)$ using the auxiliary measurement $y_2$, and to choose $a\\neq b$ so that the fault-signature matrix $S=\\begin{bmatrix}1 & 1\\\\ a & b\\end{bmatrix}$ is full column rank. Then, for $f_1=-f_2\\neq 0$, one has $r_1=0$ but $r_2=(a-b)f_1\\neq 0$, which restores detectability and enables least-squares estimation of $\\begin{bmatrix}f_1 & f_2\\end{bmatrix}^\\top$ from $\\begin{bmatrix}r_1 & r_2\\end{bmatrix}^\\top$.**\n\n*   **Analysis**: This option accurately describes the problem and the solution. It correctly states that the mean shift is zero and detection probability collapses. It correctly proposes the construction of $r_2(t)$. It correctly identifies the fault signature matrix $S$ and the condition $a \\neq b$ for it to be full rank. It correctly deduces that with this condition, $r_2$ will be sensitive to the canceling fault. Finally, it correctly links the full-rank property of $S$ to the ability to estimate (and thus isolate) the faults. The entire statement is correct from first principles.\n*   **Verdict**: Correct.\n\n**C. Cancellation in $r_1$ can always be eliminated by scaling: define a secondary residual $r_2(t)=k\\,r_1(t)$ for any $k\\neq 0$, which changes the cancellation direction and ensures $r_2\\neq 0$ whenever $f_1$ and $f_2$ are nonzero.**\n\n*   **Analysis**: This is fundamentally wrong. If the mean of $r_1(t)$ is zero due to cancellation, the mean of $k\\,r_1(t)$ will also be zero for any non-zero constant $k$. Scaling does not introduce new information and cannot break the linear dependence that causes the problem.\n*   **Verdict**: Incorrect.\n\n**D. Since the cancelling faults are step-like, passing $r_1$ through a high-pass filter to form $r_2$ will amplify the step content and thereby undo cancellation, improving detection and isolation without changing the measurement set.**\n\n*   **Analysis**: The cancellation $f_1(t)+f_2(t)=0$ occurs algebraically before any filtering can be applied to the residual. The input to the proposed high-pass filter would be $r_1(t) = v_1(t)$. There is no \"step content\" in this signal to amplify. The fault information is irrecoverably lost in $r_1(t)$.\n*   **Verdict**: Incorrect.\n\n**E. To maximize isolation capability, choose the auxiliary measurement so that $a=b$, which makes both faults affect $r_2$ identically; then ambiguity is eliminated because $r_1$ and $r_2$ carry redundant evidence of the faults in the same direction.**\n\n*   **Analysis**: This is the opposite of the correct procedure. Setting $a=b$ makes the columns of the signature matrix $S$ linearly dependent, i.e., $\\det(S)=0$. This condition guarantees that the fault direction $f_1 = -f_2$ is invisible to *both* residuals. The two residuals would carry redundant information about the sum $f_1+f_2$, but no information about the difference $f_1-f_2$. This choice of $a=b$ maximizes, not eliminates, the ambiguity.\n*   **Verdict**: Incorrect.", "answer": "$$\\boxed{B}$$", "id": "2706778"}]}