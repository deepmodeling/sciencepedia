{"hands_on_practices": [{"introduction": "The foundation of discretizing a continuous-time system lies in computing the state-transition matrix $A_d = \\exp(AT)$. This exercise [@problem_id:2701295] delves into the fundamental derivation for a non-trivial case where the state matrix $A$ is defective. By working from first principles, you will uncover why the resulting discrete model includes terms polynomial in the sampling period $T$, a key feature of systems with repeated eigenvalues that lack a full set of eigenvectors.", "problem": "Consider the continuous-time, linear time-invariant state-space model with a defective $2 \\times 2$ state matrix\n$$\n\\dot{x}(t) = A x(t), \\quad A = \\begin{bmatrix} -2 & 3 \\\\ 0 & -2 \\end{bmatrix}.\n$$\nLet the sampling period be $T \\gt 0$. Using only foundational definitions from linear systems and matrix analysis (without invoking any pre-tabulated special-case formulas), derive the exact discrete-time state-transition matrix $A_{d}(T)$ for the zero-order hold discretization, which is defined as the state-transition over one sampling interval. Your derivation must start from the definition of the matrix exponential and proceed by first principles of algebraic manipulation.\n\nExplicitly compute every entry of $A_{d}(T)$ in closed form, making clear why polynomial terms in $T$ multiply $\\exp(\\lambda T)$ due to the defectiveness of $A$. For the final answer, report the four entries of $A_{d}(T)$ in the order $(a_{11}, a_{12}, a_{21}, a_{22})$ as a single row matrix. No rounding is required, and no units are needed.", "solution": "The problem as stated is valid. It is a well-posed problem in linear systems theory that is scientifically grounded and objective. All necessary information is provided, and the task is to derive a standard result from first principles.\n\nThe task is to compute the discrete-time state-transition matrix $A_{d}(T)$ for the continuous-time system $\\dot{x}(t) = A x(t)$, where the state matrix is given by\n$$\nA = \\begin{bmatrix} -2 & 3 \\\\ 0 & -2 \\end{bmatrix}\n$$\nand $T \\gt 0$ is the sampling period. The discrete-time state-transition matrix, under a zero-order hold assumption on the input (which is zero in this autonomous system), is defined as the matrix exponential of $A$ scaled by the sampling period $T$.\n$$\nA_{d}(T) = \\exp(AT)\n$$\nThe problem demands a derivation from first principles, without recourse to tabulated formulas. We begin by analyzing the structure of the matrix $A$. $A$ is an upper triangular matrix, so its eigenvalues are its diagonal entries. We have a repeated eigenvalue $\\lambda_{1,2} = -2$. To determine if the matrix is diagonalizable or defective, we find the eigenspace corresponding to this eigenvalue. The eigenvectors $v$ are the non-zero solutions to $(A - \\lambda I)v = 0$.\n$$\n(A - (-2)I)v = \\begin{bmatrix} -2 - (-2) & 3 \\\\ 0 & -2 - (-2) \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}\n$$\nThis matrix equation simplifies to the single linear equation $3v_2 = 0$, which implies $v_2 = 0$. The component $v_1$ is unconstrained. Thus, all eigenvectors are of the form $v = c \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ for some non-zero scalar $c$. The eigenspace has a dimension of $1$. Since the algebraic multiplicity of the eigenvalue $\\lambda = -2$ is $2$, but its geometric multiplicity (the dimension of the eigenspace) is $1$, the matrix $A$ is defective and cannot be diagonalized.\n\nTo compute the matrix exponential $\\exp(AT)$, we decompose the matrix $A$ into a sum of two commuting matrices: a diagonal matrix $D$ and a nilpotent matrix $N$. This is the Jordan-Chevalley decomposition.\nLet $D$ be the diagonal part of $A$, and $N$ be the strictly upper triangular part.\n$$\nD = -2I = \\begin{bmatrix} -2 & 0 \\\\ 0 & -2 \\end{bmatrix}\n$$\n$$\nN = A - D = \\begin{bmatrix} -2 & 3 \\\\ 0 & -2 \\end{bmatrix} - \\begin{bmatrix} -2 & 0 \\\\ 0 & -2 \\end{bmatrix} = \\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix}\n$$\nFor the property $\\exp(X+Y) = \\exp(X)\\exp(Y)$ to hold for matrices, it is required that $X$ and $Y$ commute, i.e., $XY=YX$. We verify this for our decomposition $A = D+N$.\n$$\nDN = (-2I)N = -2N\n$$\n$$\nND = N(-2I) = -2N\n$$\nSince $DN=ND$, the matrices commute. Therefore, we can write:\n$$\n\\exp(AT) = \\exp((D+N)T) = \\exp(DT + NT) = \\exp(DT)\\exp(NT)\n$$\nWe now compute each exponential term separately. First, for $\\exp(DT)$:\nSince $DT = -2TI = \\begin{bmatrix} -2T & 0 \\\\ 0 & -2T \\end{bmatrix}$ is a diagonal matrix, its exponential is found by taking the exponential of each diagonal element.\n$$\n\\exp(DT) = \\begin{bmatrix} \\exp(-2T) & 0 \\\\ 0 & \\exp(-2T) \\end{bmatrix} = \\exp(-2T)I\n$$\nNext, we compute $\\exp(NT)$. The matrix $N$ is nilpotent. A matrix $N$ is nilpotent if $N^k = 0$ for some positive integer $k$. We compute the powers of $N$:\n$$\nN^2 = \\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}\n$$\nSince $N^2=0$, all higher powers $N^k$ for $k \\geq 2$ are also the zero matrix. The definition of the matrix exponential is given by its Taylor series expansion:\n$$\n\\exp(X) = \\sum_{k=0}^{\\infty} \\frac{X^k}{k!} = I + X + \\frac{X^2}{2!} + \\frac{X^3}{3!} + \\dots\n$$\nSubstituting $X = NT$, we have:\n$$\n\\exp(NT) = I + NT + \\frac{(NT)^2}{2!} + \\frac{(NT)^3}{3!} + \\dots\n$$\nAs $(NT)^k = T^k N^k$ and $N^k=0$ for $k \\geq 2$, the series terminates after the second term.\n$$\n\\exp(NT) = I + NT = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} + T\\begin{bmatrix} 0 & 3 \\\\ 0 & 0 \\end{bmatrix} = \\begin{bmatrix} 1 & 3T \\\\ 0 & 1 \\end{bmatrix}\n$$\nFinally, we combine the results to find $A_d(T)$.\n$$\nA_d(T) = \\exp(AT) = \\exp(DT)\\exp(NT) = \\left(\\exp(-2T)I\\right) \\left(I + NT\\right)\n$$\n$$\nA_d(T) = \\exp(-2T) \\begin{bmatrix} 1 & 3T \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} \\exp(-2T) & 3T\\exp(-2T) \\\\ 0 & \\exp(-2T) \\end{bmatrix}\n$$\nThe appearance of the term $3T\\exp(-2T)$, which is a polynomial in $T$ multiplying the exponential term, is a direct consequence of the defectiveness of the matrix $A$. The decomposition $A = D+N$ contains a non-zero nilpotent part $N$. The exponential of the nilpotent part, $\\exp(NT)$, generates a matrix polynomial in $T$ because its Taylor series is finite. In this case, the series gives $I+NT$. When multiplied by $\\exp(DT) = \\exp(-2T)I$, this polynomial term persists, leading to the characteristic $T\\exp(\\lambda T)$ form in the solution for systems with defective matrices. If $A$ were diagonalizable, $N$ would be the zero matrix, and no such polynomial terms would appear. The entries would be purely combinations of $\\exp(\\lambda_i T)$.\n\nThe four entries of $A_d(T)$ are:\n$a_{11} = \\exp(-2T)$\n$a_{12} = 3T\\exp(-2T)$\n$a_{21} = 0$\n$a_{22} = \\exp(-2T)$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\exp(-2T) & 3T\\exp(-2T) & 0 & \\exp(-2T) \\end{pmatrix}}\n$$", "id": "2701295"}, {"introduction": "While discretizing the state matrix $A$ is a direct application of the matrix exponential, handling the input term requires careful consideration of the zero-order hold assumption. This practice problem [@problem_id:2701337] serves as a critical cautionary tale, challenging you to construct a counterexample to a common but naive approximation for the discrete input matrix $B_d$. By comparing the exact solution with the flawed one, you will gain a deeper appreciation for the integral-based derivation that underpins accurate digital control.", "problem": "Consider the scalar continuous-time linear time-invariant system defined by the ordinary differential equation $\\dot{x}(t) = A x(t) + B u(t)$, where $A \\in \\mathbb{R}$ and $B \\in \\mathbb{R}$, with a zero-order hold (ZOH) input $u(t) = u_{k}$ for $t \\in [kT, (k+1)T)$ and $T \\gt 0$ the sampling period. Over one sampling interval, an exact discrete-time update $x_{k+1}$ can be derived from the fundamental solution of linear time-invariant systems, while a common but naive modeling practice replaces the intersample convolution integral by $B T u_k$.\n\nUsing only first principles of linear differential equations and the ZOH assumption, construct a minimal counterexample demonstrating that substituting $B T u_k$ for the exact intersample integral yields an incorrect discrete model even in the scalar case. Specifically, for the parameter choice $A=1, B=1, T=1, x_k=0$, and $u_k=1$:\n- Derive the exact one-step update $x_{k+1}^{\\mathrm{exact}}$.\n- Derive the approximate one-step update $x_{k+1}^{\\mathrm{approx}}$ obtained by replacing the intersample integral by $B T u_k$.\n- Compute the error $\\Delta \\equiv x_{k+1}^{\\mathrm{exact}} - x_{k+1}^{\\mathrm{approx}}$.\n\nReport $\\Delta$ as a single closed-form analytic expression. Do not round your answer. No units are required.", "solution": "The problem requires the derivation of a counterexample to a naive discretization method for a continuous-time linear system. We will proceed by first principles, as instructed.\n\nThe continuous-time linear time-invariant (LTI) system is described by the scalar ordinary differential equation:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\nwhere $A \\in \\mathbb{R}$ and $B \\in \\mathbb{R}$.\n\nThe fundamental solution to this differential equation over the time interval $[t_0, t]$ is given by the variation of parameters formula:\n$$\nx(t) = \\exp(A(t - t_0)) x(t_0) + \\int_{t_0}^{t} \\exp(A(t - \\tau)) B u(\\tau) \\, d\\tau\n$$\nWe are interested in the state transition over one sampling period $T$, from time $t_k = kT$ to $t_{k+1} = (k+1)T$. Let $x_k = x(kT)$ and $x_{k+1} = x((k+1)T)$. Setting $t_0 = kT$ and $t = (k+1)T$, the solution becomes:\n$$\nx_{k+1} = \\exp(A((k+1)T - kT)) x_k + \\int_{kT}^{(k+1)T} \\exp(A((k+1)T - \\tau)) B u(\\tau) \\, d\\tau\n$$\nThe problem specifies a zero-order hold (ZOH) input, meaning the control input $u(t)$ is held constant during each sampling interval: $u(t) = u_k$ for $t \\in [kT, (k+1)T)$. Substituting this into the equation, we can move the constants $B$ and $u_k$ outside the integral:\n$$\nx_{k+1} = \\exp(AT) x_k + B u_k \\int_{kT}^{(k+1)T} \\exp(A((k+1)T - \\tau)) \\, d\\tau\n$$\nThis is the general exact one-step update formula.\n\nFirst, we derive the exact one-step update, $x_{k+1}^{\\mathrm{exact}}$. To evaluate the integral, we perform a change of variable. Let $\\sigma = (k+1)T - \\tau$. This implies $d\\sigma = -d\\tau$. The limits of integration change from $\\tau = kT$ to $\\sigma = T$, and from $\\tau = (k+1)T$ to $\\sigma = 0$. The integral becomes:\n$$\n\\int_{kT}^{(k+1)T} \\exp(A((k+1)T - \\tau)) \\, d\\tau = \\int_{T}^{0} \\exp(A\\sigma) (-d\\sigma) = \\int_{0}^{T} \\exp(A\\sigma) \\, d\\sigma\n$$\nSince $A$ is a non-zero scalar constant ($A=1$), this integral is evaluated as:\n$$\n\\int_{0}^{T} \\exp(A\\sigma) \\, d\\sigma = \\left[ \\frac{1}{A} \\exp(A\\sigma) \\right]_0^T = \\frac{1}{A} (\\exp(AT) - \\exp(A \\cdot 0)) = \\frac{1}{A} (\\exp(AT) - 1)\n$$\nSubstituting this result back gives the expression for the exact discrete-time update:\n$$\nx_{k+1}^{\\mathrm{exact}} = \\exp(AT) x_k + \\frac{B}{A}(\\exp(AT) - 1) u_k\n$$\nWe now substitute the given parameters: $A=1$, $B=1$, $T=1$, $x_k=0$, and $u_k=1$.\n$$\nx_{k+1}^{\\mathrm{exact}} = \\exp(1 \\cdot 1) \\cdot 0 + \\frac{1}{1}(\\exp(1 \\cdot 1) - 1) \\cdot 1 = 0 + (\\exp(1) - 1) = \\exp(1) - 1\n$$\n\nSecond, we derive the approximate one-step update, $x_{k+1}^{\\mathrm{approx}}$. The problem states this is obtained by replacing the \"intersample convolution integral\", which is the term $\\int_{kT}^{(k+1)T} \\exp(A((k+1)T - \\tau)) B u_k \\, d\\tau$, with the naive approximation $B T u_k$.\nThe exact formulation is:\n$$\nx_{k+1} = \\exp(AT) x_k + \\left( \\int_{kT}^{(k+1)T} \\exp(A((k+1)T - \\tau)) d\\tau \\right) B u_k\n$$\nReplacing the integral term as specified yields the approximate model:\n$$\nx_{k+1}^{\\mathrm{approx}} = \\exp(AT) x_k + B T u_k\n$$\nThis approximation is valid only for $AT \\ll 1$. We use the given parameters to compute the value from this model: $A=1$, $B=1$, $T=1$, $x_k=0$, and $u_k=1$.\n$$\nx_{k+1}^{\\mathrm{approx}} = \\exp(1 \\cdot 1) \\cdot 0 + (1)(1)(1) = 0 + 1 = 1\n$$\n\nFinally, we compute the error $\\Delta$, defined as the difference between the exact and approximate results:\n$$\n\\Delta = x_{k+1}^{\\mathrm}^{\\mathrm{exact}} - x_{k+1}^{\\mathrm{approx}}\n$$\nSubstituting the derived values:\n$$\n\\Delta = (\\exp(1) - 1) - 1 = \\exp(1) - 2\n$$\nThis is the final analytical expression for the error.", "answer": "$$\n\\boxed{\\exp(1) - 2}\n$$", "id": "2701337"}, {"introduction": "With a solid theoretical understanding of both $A_d$ and $B_d$, the final step is to learn a practical and numerically stable method for their computation. This exercise [@problem_id:2701343] guides you through implementing the Van Loan method, an elegant approach that computes both matrices simultaneously by forming an augmented system. Mastering this technique is essential for reliably converting continuous-time models into their discrete-time equivalents for simulation and digital controller design.", "problem": "You are given a continuous-time, linear time-invariant state-space model defined by the differential equation $\\dot{x}(t) = A x(t) + B u(t)$ with zero-order hold (ZOH) sampled input, where $u(t)$ is held constant on each sampling interval of length $T \\gt 0$. The goal is to obtain the equivalent discrete-time state-space model $x_{k+1} = A_d x_k + B_d u_k$ that exactly matches the continuous-time dynamics over each sampling interval under ZOH. Your derivation must start from the definition of the state-transition operator for linear systems and the property that the solution of a linear ordinary differential equation with constant input over an interval is obtained by integrating the state transition against the input. Do not assume or quote any closed-form block-matrix exponential identities; instead, reason from these foundational principles to justify an algorithm for computing $A_d$ and $B_d$ that is numerically stable for general matrices $A$ and $B$. Then implement that algorithm.\n\nFor numerical evaluation, use the Van Loan method, which is a construction derived from the fundamental solution of an augmented linear system whose input is constant under zero-order hold. Your program must compute $A_d$ and $B_d$ to four decimal places for each test case below.\n\nImplement a program that, for each test case, computes $A_d$ and $B_d$ and outputs their entries rounded to four decimal places. For each case, you must flatten $A_d$ in row-major order followed by flattening $B_d$ in row-major order, and then concatenate these into a single list of floating-point numbers. Aggregate the results from all cases into one single list in the order listed below.\n\nNo physical units are involved; all quantities are dimensionless real numbers.\n\nTest suite:\n- Case 1 (general oscillatory, damped): $A = \\begin{bmatrix} 0 & 1 \\\\ -10 & -1 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $T = 0.05$.\n- Case 2 (boundary condition $T=0$): $A = \\begin{bmatrix} 0 & 1 \\\\ -10 & -1 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $T = 0$.\n- Case 3 (nilpotent $A$): $A = \\begin{bmatrix} 0 & 1 \\\\ 0 & 0 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $T = 0.1$.\n- Case 4 (no actuation): $A = \\begin{bmatrix} 0 & 1 \\\\ -2 & -0.5 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$, $T = 0.2$.\n- Case 5 (stiff, fast mode): $A = \\begin{bmatrix} 0 & 1 \\\\ -100 & -20 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $T = 0.01$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1, r_2, \\dots]$). The list must contain, for each case in order, the entries of $A_d$ flattened row-wise followed by the entries of $B_d$ flattened row-wise, all rounded to four decimal places as floating-point numbers.", "solution": "The solution to the continuous-time state-space equation $\\dot{x}(t) = A x(t) + B u(t)$ over an interval $[t_0, t]$ is given by the variation of parameters formula:\n$$\nx(t) = e^{A(t-t_0)} x(t_0) + \\int_{t_0}^{t} e^{A(t-\\tau)} B u(\\tau) d\\tau\n$$\nwhere $e^{At}$ is the state-transition matrix.\n\nWe are interested in the evolution of the state from time $t_k = kT$ to $t_{k+1} = (k+1)T$. Setting $t_0 = kT$ and $t = (k+1)T$, we have:\n$$\nx((k+1)T) = e^{A((k+1)T - kT)} x(kT) + \\int_{kT}^{(k+1)T} e^{A((k+1)T - \\tau)} B u(\\tau) d\\tau\n$$\nBy defining the discrete state vector $x_k \\triangleq x(kT)$, the equation becomes:\n$$\nx_{k+1} = e^{AT} x_k + \\int_{kT}^{(k+1)T} e^{A((k+1)T - \\tau)} B u(\\tau) d\\tau\n$$\nThe problem specifies a zero-order hold on the input, which means $u(\\tau)$ is constant over the sampling interval, $u(\\tau) = u(kT) = u_k$ for $\\tau \\in [kT, (k+1)T)$. Substituting this into the equation allows us to move the constant terms $B$ and $u_k$ outside the integral:\n$$\nx_{k+1} = e^{AT} x_k + \\left( \\int_{kT}^{(k+1)T} e^{A((k+1)T - \\tau)} d\\tau \\right) B u_k\n$$\nTo simplify the integral, we perform a change of variables. Let $\\sigma = (k+1)T - \\tau$. This implies $d\\sigma = -d\\tau$. The limits of integration change from $\\tau = kT$ to $\\sigma = T$, and from $\\tau = (k+1)T$ to $\\sigma = 0$. The integral becomes:\n$$\n\\int_{T}^{0} e^{A\\sigma} (-d\\sigma) = \\int_{0}^{T} e^{A\\sigma} d\\sigma\n$$\nSubstituting this result back, we obtain the exact discrete-time model:\n$$\nx_{k+1} = \\left( e^{AT} \\right) x_k + \\left( \\int_{0}^{T} e^{A\\sigma} d\\sigma \\right) B u_k\n$$\nBy comparing this to the target form $x_{k+1} = A_d x_k + B_d u_k$, we identify the discrete-time system matrices:\n$$\nA_d = e^{AT}\n$$\n$$\nB_d = \\left( \\int_{0}^{T} e^{A\\sigma} d\\sigma \\right) B\n$$\nThe computational challenge lies in accurately computing the matrix exponential $e^{AT}$ and the integral of the matrix exponential. The Van Loan method provides a robust way to compute both $A_d$ and $B_d$ simultaneously.\n\nThe method is justified by constructing an augmented $(n+m) \\times (n+m)$ matrix, where $n$ is the dimension of the state and $m$ is the dimension of the input:\n$$\nM = \\begin{bmatrix} A & B \\\\ 0 & 0 \\end{bmatrix}\n$$\nThe zero blocks are of the appropriate dimensions to make $M$ a valid square matrix. We now compute the matrix exponential $e^{MT}$. Using the Taylor series expansion of the matrix exponential, $e^X = \\sum_{k=0}^{\\infty} \\frac{X^k}{k!}$, we analyze the powers of $MT$:\n$$\nMT = \\begin{bmatrix} AT & BT \\\\ 0 & 0 \\end{bmatrix}\n$$\nFor $k \\ge 1$, the powers are:\n$$\n(MT)^k = \\begin{bmatrix} (AT)^k & (AT)^{k-1}BT \\\\ 0 & 0 \\end{bmatrix}\n$$\nThe exponential is thus:\n$$\ne^{MT} = I + \\sum_{k=1}^{\\infty} \\frac{(MT)^k}{k!} = \\begin{bmatrix} I & 0 \\\\ 0 & I \\end{bmatrix} + \\sum_{k=1}^{\\infty} \\frac{1}{k!} \\begin{bmatrix} (AT)^k & (AT)^{k-1}BT \\\\ 0 & 0 \\end{bmatrix}\n$$\nBy summing the corresponding blocks, we get:\n$$\ne^{MT} = \\begin{bmatrix} I + \\sum_{k=1}^{\\infty} \\frac{(AT)^k}{k!} & \\sum_{k=1}^{\\infty} \\frac{(AT)^{k-1}T}{k!} B \\\\ 0 & I \\end{bmatrix}\n$$\nWe recognize the terms in the resulting partitioned matrix. The top-left block is the Taylor series for $e^{AT}$:\n$$\n\\Phi_{11} = I + \\sum_{k=1}^{\\infty} \\frac{(AT)^k}{k!} = e^{AT} = A_d\n$$\nThe top-right block is:\n$$\n\\Phi_{12} = \\left( \\sum_{k=1}^{\\infty} \\frac{A^{k-1}T^k}{k!} \\right) B\n$$\nLet us compare this to the integral form of the pre-multiplier for $B_d$. We expand the integral of the matrix exponential using its Taylor series:\n$$\n\\int_{0}^{T} e^{A\\sigma} d\\sigma = \\int_{0}^{T} \\left( \\sum_{j=0}^{\\infty} \\frac{(A\\sigma)^j}{j!} \\right) d\\sigma = \\sum_{j=0}^{\\infty} \\frac{A^j}{j!} \\int_{0}^{T} \\sigma^j d\\sigma = \\sum_{j=0}^{\\infty} \\frac{A^j}{(j)!} \\frac{T^{j+1}}{j+1} = \\sum_{j=0}^{\\infty} \\frac{A^j T^{j+1}}{(j+1)!}\n$$\nBy setting $k = j+1$, this sum becomes $\\sum_{k=1}^{\\infty} \\frac{A^{k-1} T^k}{k!}$. This is precisely the matrix multiplying $B$ in $\\Phi_{12}$. Therefore:\n$$\n\\Phi_{12} = \\left( \\int_{0}^{T} e^{A\\sigma} d\\sigma \\right) B = B_d\n$$\nThus, we have proven that the exponential of the augmented matrix $MT$ is structured as:\n$$\ne^{MT} = \\begin{bmatrix} A_d & B_d \\\\ 0 & I \\end{bmatrix}\n$$\nThis result forms the basis of the Van Loan algorithm. It is numerically superior because it computes $A_d$ and $B_d$ via a single, well-conditioned matrix exponential calculation, for which highly robust algorithms (such as Padé approximation with scaling and squaring) exist.\n\nThe implementation procedure is as follows:\n1.  For each test case ($A$, $B$, $T$), determine the state dimension $n$ and input dimension $m$.\n2.  Construct the $(n+m) \\times (n+m)$ augmented matrix $M = \\begin{bmatrix} A & B \\\\ 0 & 0 \\end{bmatrix}$.\n3.  Compute the matrix exponential $\\Phi = e^{MT}$ using a reliable numerical library function.\n4.  Extract the submatrices: $A_d$ is the top-left $n \\times n$ block of $\\Phi$, and $B_d$ is the top-right $n \\times m$ block.\n5.  Flatten the resulting matrices $A_d$ and $B_d$ into one-dimensional arrays in row-major order.\n6.  Concatenate these arrays and round the elements to four decimal places.\n7.  Aggregate the results from all test cases into a final list.\nThis procedure correctly and robustly computes the required discrete-time matrices.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Computes the discretized state-space matrices Ad and Bd for a set of test cases\n    using the Van Loan method.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: General oscillatory, damped\n        {'A': np.array([[0, 1], [-10, -1]]), 'B': np.array([[0], [1]]), 'T': 0.05},\n        # Case 2: Boundary condition T=0\n        {'A': np.array([[0, 1], [-10, -1]]), 'B': np.array([[0], [1]]), 'T': 0.0},\n        # Case 3: Nilpotent A\n        {'A': np.array([[0, 1], [0, 0]]), 'B': np.array([[0], [1]]), 'T': 0.1},\n        # Case 4: No actuation\n        {'A': np.array([[0, 1], [-2, -0.5]]), 'B': np.array([[0], [0]]), 'T': 0.2},\n        # Case 5: Stiff, fast mode\n        {'A': np.array([[0, 1], [-100, -20]]), 'B': np.array([[0], [1]]), 'T': 0.01},\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        A = case['A']\n        B = case['B']\n        T = case['T']\n\n        n = A.shape[0]\n        if B.ndim == 1:\n            B = B.reshape(-1, 1)\n        m = B.shape[1]\n\n        # Construct the augmented matrix M for the Van Loan method\n        M = np.zeros((n + m, n + m))\n        M[:n, :n] = A\n        M[:n, n:] = B\n\n        # Compute the matrix exponential of M*T\n        # scipy.linalg.expm is a robust implementation using Padé approximation\n        phi = expm(M * T)\n\n        # Extract Ad and Bd from the resulting matrix\n        Ad = phi[:n, :n]\n        Bd = phi[:n, n:]\n\n        # Flatten Ad and Bd row-wise\n        flat_Ad = Ad.flatten()\n        flat_Bd = Bd.flatten()\n\n        # Concatenate and round results to four decimal places\n        case_result = np.concatenate((flat_Ad, flat_Bd))\n        rounded_result = np.round(case_result, 4)\n\n        final_results.extend(rounded_result.tolist())\n\n    # Format the final output as a single comma-separated list in brackets\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "2701343"}]}