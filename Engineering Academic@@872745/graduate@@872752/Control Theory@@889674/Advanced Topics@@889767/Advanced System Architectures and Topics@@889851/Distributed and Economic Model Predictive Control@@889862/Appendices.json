{"hands_on_practices": [{"introduction": "To optimize large-scale systems in a decentralized manner, we must first understand how to decompose a coupled problem. This exercise introduces dual decomposition, a powerful technique where coupling constraints are relaxed using Lagrange multipliers, which act as market prices for shared resources. By working through a single iteration of the dual ascent algorithm, you will gain hands-on experience with this fundamental price-based coordination mechanism, seeing how local decisions are influenced by a global price signal. [@problem_id:2701668]", "problem": "Consider a single coordination step in a distributed economic Model Predictive Control (MPC) scheme for two subsystems with scalar inputs. At a given prediction step, the centralized stage problem is to minimize the sum of local economic costs under a shared resource balance. The local economic stage costs are strictly convex quadratics given by $J_{1}(u_{1})=\\tfrac{1}{2} q_{1} u_{1}^{2}+r_{1} u_{1}$ and $J_{2}(u_{2})=\\tfrac{1}{2} q_{2} u_{2}^{2}+r_{2} u_{2}$, with individual input constraints $u_{1} \\in [u_{1}^{\\min},u_{1}^{\\max}]$ and $u_{2} \\in [u_{2}^{\\min},u_{2}^{\\max}]$. The agents are coupled by the resource-balance equality constraint $u_{1}+u_{2}=\\bar{u}$.\n\nStarting from the definition of the Lagrangian for the equality-constrained convex program and the subgradient ascent on the dual function using the coupling constraint residual as subgradient, carry out one iteration of dual ascent as follows:\n- For a given current price (dual variable) $\\lambda_{k}$, compute the local optimal inputs by minimizing the local Lagrangians with respect to $u_{1}$ and $u_{2}$ subject to their respective box constraints.\n- Update the price using a constant step size $\\alpha$.\n\nUse the following data for this step:\n- $q_{1}=2$, $r_{1}=-3$, $u_{1}^{\\min}=0$, $u_{1}^{\\max}=2$.\n- $q_{2}=1$, $r_{2}=2$, $u_{2}^{\\min}=-3$, $u_{2}^{\\max}=1$.\n- Coupling parameter $\\bar{u}=-\\tfrac{3}{2}$.\n- Current price $\\lambda_{k}=\\tfrac{6}{5}$.\n- Step size $\\alpha=\\tfrac{1}{2}$.\n\nReport the result of this one dual-ascent iteration as the row vector $\\big(u_{1,k}^{\\star},\\,u_{2,k}^{\\star},\\,\\lambda_{k+1}\\big)$.\n\nYour final answer must be a single row matrix. No rounding is required, and you must present exact values (fractions are acceptable). Do not include any units.", "solution": "The problem presented is a valid, well-posed exercise in convex optimization, specifically an application of dual decomposition to a distributed economic model predictive control scenario. All necessary parameters are provided, and the problem is scientifically sound. We shall proceed with the solution.\n\nThe centralized optimization problem is to minimize the total economic cost, which is the sum of the local costs $J_{1}(u_{1})$ and $J_{2}(u_{2})$, subject to local and coupling constraints.\nThe problem is formulated as:\n$$\n\\min_{u_{1}, u_{2}} \\quad J_{1}(u_{1}) + J_{2}(u_{2}) = \\left(\\frac{1}{2} q_{1} u_{1}^{2} + r_{1} u_{1}\\right) + \\left(\\frac{1}{2} q_{2} u_{2}^{2} + r_{2} u_{2}\\right)\n$$\nsubject to:\n$$\nu_{1} + u_{2} = \\bar{u} \\\\\nu_{1} \\in [u_{1}^{\\min}, u_{1}^{\\max}] \\\\\nu_{2} \\in [u_{2}^{\\min}, u_{2}^{\\max}]\n$$\nThis is a convex optimization problem because the objective function is a sum of strictly convex quadratic functions (since $q_{1} > 0$ and $q_{2} > 0$), and the constraints define a convex set.\n\nTo solve this in a distributed manner using dual decomposition, we relax the coupling constraint $u_{1} + u_{2} - \\bar{u} = 0$ by introducing a Lagrange multiplier, or dual variable, $\\lambda$. The Lagrangian function $L(u_{1}, u_{2}, \\lambda)$ is:\n$$\nL(u_{1}, u_{2}, \\lambda) = J_{1}(u_{1}) + J_{2}(u_{2}) + \\lambda(u_{1} + u_{2} - \\bar{u})\n$$\nThe Lagrangian can be separated into components corresponding to each subsystem:\n$$\nL(u_{1}, u_{2}, \\lambda) = \\left( J_{1}(u_{1}) + \\lambda u_{1} \\right) + \\left( J_{2}(u_{2}) + \\lambda u_{2} \\right) - \\lambda \\bar{u}\n$$\nLet us define the local Lagrangians for each subsystem $i \\in \\{1, 2\\}$:\n$$\nL_{i}(u_{i}, \\lambda) = J_{i}(u_{i}) + \\lambda u_{i}\n$$\nThe dual ascent algorithm proceeds in two steps at each iteration $k$:\n$1$. For a given price $\\lambda_{k}$, each subsystem independently solves its local optimization problem to find the optimal inputs $u_{1,k}^{\\star}$ and $u_{2,k}^{\\star}$:\n$$\nu_{i,k}^{\\star} = \\arg\\min_{u_{i} \\in [u_{i}^{\\min}, u_{i}^{\\max}]} L_{i}(u_{i}, \\lambda_{k})\n$$\n$2$. The price $\\lambda_{k}$ is updated using subgradient ascent, where the subgradient is the residual of the relaxed coupling constraint. The update rule is:\n$$\n\\lambda_{k+1} = \\lambda_{k} + \\alpha (u_{1,k}^{\\star} + u_{2,k}^{\\star} - \\bar{u})\n$$\nwhere $\\alpha > 0$ is the step size.\n\nWe now perform one iteration with the given data:\n- $q_{1}=2$, $r_{1}=-3$, $u_{1}^{\\min}=0$, $u_{1}^{\\max}=2$.\n- $q_{2}=1$, $r_{2}=2$, $u_{2}^{\\min}=-3$, $u_{2}^{\\max}=1$.\n- $\\bar{u}=-\\frac{3}{2}$.\n- Initial price $\\lambda_{k}=\\frac{6}{5}$.\n- Step size $\\alpha=\\frac{1}{2}$.\n\nFirst, we solve the local minimization problems for $u_{1}$ and $u_{2}$.\nFor subsystem $1$:\n$$\nL_{1}(u_{1}, \\lambda_{k}) = \\frac{1}{2} q_{1} u_{1}^{2} + r_{1} u_{1} + \\lambda_{k} u_{1} = \\frac{1}{2} (2) u_{1}^{2} + (-3) u_{1} + \\frac{6}{5} u_{1} = u_{1}^{2} - \\frac{9}{5} u_{1}\n$$\nTo find the unconstrained minimum, we set the derivative with respect to $u_{1}$ to zero:\n$$\n\\frac{\\partial L_{1}}{\\partial u_{1}} = 2 u_{1} - \\frac{9}{5} = 0 \\implies u_{1}^{\\text{unc}} = \\frac{9}{10}\n$$\nThe local constraint for $u_{1}$ is $[0, 2]$. Since $0 \\le \\frac{9}{10} \\le 2$, the unconstrained minimum is feasible. Thus, the optimal local input is:\n$$\nu_{1,k}^{\\star} = \\frac{9}{10}\n$$\n\nFor subsystem $2$:\n$$\nL_{2}(u_{2}, \\lambda_{k}) = \\frac{1}{2} q_{2} u_{2}^{2} + r_{2} u_{2} + \\lambda_{k} u_{2} = \\frac{1}{2} (1) u_{2}^{2} + (2) u_{2} + \\frac{6}{5} u_{2} = \\frac{1}{2} u_{2}^{2} + \\frac{16}{5} u_{2}\n$$\nTo find the unconstrained minimum, we set the derivative with respect to $u_{2}$ to zero:\n$$\n\\frac{\\partial L_{2}}{\\partial u_{2}} = u_{2} + \\frac{16}{5} = 0 \\implies u_{2}^{\\text{unc}} = -\\frac{16}{5} = -3.2\n$$\nThe local constraint for $u_{2}$ is $[-3, 1]$. Since $u_{2}^{\\text{unc}} = -3.2  -3$, the minimum of the convex function $L_{2}$ over the interval is at the lower bound. Thus, the optimal local input is:\n$$\nu_{2,k}^{\\star} = u_{2}^{\\min} = -3\n$$\n\nNext, we update the price $\\lambda$. The residual of the coupling constraint is:\n$$\ns_{k} = u_{1,k}^{\\star} + u_{2,k}^{\\star} - \\bar{u} = \\frac{9}{10} + (-3) - \\left(-\\frac{3}{2}\\right) = \\frac{9}{10} - \\frac{30}{10} + \\frac{15}{10} = \\frac{9 - 30 + 15}{10} = -\\frac{6}{10} = -\\frac{3}{5}\n$$\nThe updated price $\\lambda_{k+1}$ is calculated as:\n$$\n\\lambda_{k+1} = \\lambda_{k} + \\alpha s_{k} = \\frac{6}{5} + \\frac{1}{2} \\left(-\\frac{3}{5}\\right) = \\frac{6}{5} - \\frac{3}{10} = \\frac{12}{10} - \\frac{3}{10} = \\frac{9}{10}\n$$\n\nThe result of this single dual-ascent iteration is the row vector $(u_{1,k}^{\\star}, u_{2,k}^{\\star}, \\lambda_{k+1})$.\nSubstituting the calculated values, we have:\n$$\n\\left( \\frac{9}{10}, -3, \\frac{9}{10} \\right)\n$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{9}{10}  -3  \\frac{9}{10} \\end{pmatrix}}$$", "id": "2701668"}, {"introduction": "A key insight of Economic Model Predictive Control (eMPC) is that optimizing for a steady state is not always economically optimal. This practice moves beyond simple setpoint tracking to explore the core motivation for eMPC, using a conceptual model to illustrate this principle. You will derive the analytical conditions under which a dynamic, periodic operating strategy is provably superior to the best possible steady-state operation, providing a deep understanding of why transient behavior is crucial for economic performance. [@problem_id:2701639]", "problem": "Consider a single-input discrete-time linear time-invariant process governed by the state dynamics $x_{k+1} = a x_{k} + b u_{k}$, where $x_{k} \\in \\mathbb{R}$ is the scalar state, $u_{k} \\in \\mathbb{R}$ is the scalar input, $0  a  1$, and $b > 0$. The operating constraints are:\n- a pointwise input constraint $u_{k} \\in \\{0, u_{\\max}\\}$ with $u_{\\max} > 0$,\n- an actuator cooldown constraint: whenever $u_{k} = u_{\\max}$, it must be followed by at least $m \\in \\mathbb{N}$ consecutive time steps with $u = 0$ (i.e., $u_{k+1} = \\cdots = u_{k+m} = 0$).\n\nThe economic stage cost is $l(x,u) = c_{u} u - r x$, with $c_{u} > 0$ and $r > 0$, and the long-run performance of a policy is evaluated by the time-average cost. Assume the process is initialized on the corresponding periodic orbit when periodic control is considered.\n\nStart from the definitions of time-average cost and steady-state feasibility, and from the system dynamics. Derive, from first principles and using only these definitions, conditions under which the following holds: the unconstrained economically optimal steady state (i.e., a steady state computed without enforcing the cooldown and $\\{0,u_{\\max}\\}$ restrictions) is infeasible under the given constraints, yet there exists a periodic input sequence that satisfies the constraints and achieves strictly lower long-run average cost than any feasible steady state.\n\nFocus on the fastest admissible periodic policy that repeats a cycle consisting of one input pulse $u_{\\max}$ followed by exactly $m$ zeros. Compute the exact analytical expression for the unique critical value $r^{\\star}$ of the economic reward coefficient $r$ such that, for $r > r^{\\star}$, this periodic policy has strictly lower time-average cost than any feasible steady state. Express your final answer as a closed-form symbolic expression in terms of $a$, $b$, and $c_{u}$. Do not round or approximate your result. The final answer must be a single analytic expression with no units.", "solution": "The problem asks for the critical value of the economic reward coefficient, denoted $r^{\\star}$, such that for any $r > r^{\\star}$, a specific periodic control policy yields a strictly lower time-average cost than any feasible steady-state operation. The derivation must proceed from first principles.\n\nFirst, we analyze the possible steady-state operations that are feasible under the given constraints. A steady state $(x_{ss}, u_{ss})$ must satisfy the system dynamics at equilibrium, $x_{ss} = a x_{ss} + b u_{ss}$, which implies $(1-a)x_{ss} = b u_{ss}$. Since $0  a  1$, we have $1-a \\neq 0$, so the steady state is given by $x_{ss} = \\frac{b}{1-a} u_{ss}$. The input $u_{ss}$ must be constant for all time steps $k$. The constraints on the input are $u_{k} \\in \\{0, u_{\\max}\\}$ and a cooldown dynamic.\n\nFor a steady state, we must choose a constant input from the allowed set. The two possibilities are $u_{ss} = 0$ and $u_{ss} = u_{\\max}$.\n1.  If we choose $u_{ss} = 0$, then $x_{ss} = \\frac{b}{1-a} \\cdot 0 = 0$. The input is always $0$, so the cooldown constraint (which is triggered only when $u_k = u_{\\max}$) is never violated. Thus, $(x_{ss}, u_{ss}) = (0, 0)$ is a feasible steady state.\n2.  If we choose $u_{ss} = u_{\\max}$, this implies $u_k = u_{\\max}$ for all $k$. However, the cooldown constraint states that an input $u_k = u_{\\max}$ must be followed by $m$ steps of zero input, i.e., $u_{k+1} = 0$. This contradicts the requirement that $u_{k+1} = u_{\\max}$ for a steady state. Therefore, a steady state with $u_{ss} = u_{\\max}$ is not feasible.\n\nThe only feasible steady state is $(x_{ss}, u_{ss}) = (0, 0)$. The time-average cost for this steady state is the constant stage cost $l(0, 0) = c_u (0) - r (0) = 0$. Let this be $J_{ss}$. So, $J_{ss} = 0$.\n\nNext, we analyze the specified periodic policy. The policy has a period of $N = m+1$ time steps. The input sequence over one period is $u_0 = u_{\\max}$ and $u_k = 0$ for $k \\in \\{1, 2, \\dots, m\\}$. This policy is admissible by construction, as the pulse of $u_{\\max}$ is followed by $m$ zero-input steps.\n\nThe time-average cost for any policy is given by $J = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{k=0}^{T-1} l(x_k, u_k)$. For a periodic policy with period $N$ where the system operates on a periodic orbit, this simplifies to the average over one period:\n$$J_{p} = \\frac{1}{N} \\sum_{k=0}^{N-1} l(x_k, u_k) = \\frac{1}{N} \\sum_{k=0}^{N-1} (c_u u_k - r x_k)$$\nThis can be written in terms of the average input $\\bar{u} = \\frac{1}{N} \\sum_{k=0}^{N-1} u_k$ and average state $\\bar{x} = \\frac{1}{N} \\sum_{k=0}^{N-1} x_k$ as $J_p = c_u \\bar{u} - r \\bar{x}$.\n\nA crucial relationship exists between the average state and average input for any periodic trajectory. Summing the state dynamics $x_{k+1} = a x_k + b u_k$ over one full period from $k=0$ to $k=N-1$:\n$$\\sum_{k=0}^{N-1} x_{k+1} = a \\sum_{k=0}^{N-1} x_k + b \\sum_{k=0}^{N-1} u_k$$\nOn a periodic orbit, $x_N = x_0$. The sum on the left is $\\sum_{j=1}^{N} x_j = x_N + \\sum_{j=1}^{N-1} x_j = x_0 + \\sum_{j=1}^{N-1} x_j = \\sum_{k=0}^{N-1} x_k$.\nTherefore, the equation becomes:\n$$\\sum_{k=0}^{N-1} x_k = a \\sum_{k=0}^{N-1} x_k + b \\sum_{k=0}^{N-1} u_k$$\n$$(1-a) \\sum_{k=0}^{N-1} x_k = b \\sum_{k=0}^{N-1} u_k$$\nDividing by the period $N$, we obtain the relation between the average values:\n$$(1-a) \\bar{x} = b \\bar{u} \\implies \\bar{x} = \\frac{b}{1-a} \\bar{u}$$\nThis elegant result holds for any periodic orbit of the system.\n\nNow, we substitute this into the expression for the average cost $J_p$:\n$$J_p = c_u \\bar{u} - r \\left( \\frac{b}{1-a} \\bar{u} \\right) = \\left( c_u - \\frac{rb}{1-a} \\right) \\bar{u}$$\nFor the specific periodic policy with period $N = m+1$ and input sequence $\\{u_{\\max}, 0, \\dots, 0\\}$, the average input is:\n$$\\bar{u} = \\frac{1}{m+1} (u_{\\max} + 0 + \\dots + 0) = \\frac{u_{\\max}}{m+1}$$\nThe average cost of this periodic policy is thus:\n$$J_p = \\left( c_u - \\frac{rb}{1-a} \\right) \\frac{u_{\\max}}{m+1}$$\nThe problem asks for the condition under which this periodic policy is strictly superior to any feasible steady state. As we found, the best (and only) feasible steady-state policy has a cost of $J_{ss} = 0$. The condition is thus $J_p  J_{ss}$, which translates to $J_p  0$.\n$$\\left( c_u - \\frac{rb}{1-a} \\right) \\frac{u_{\\max}}{m+1}  0$$\nGiven that $u_{\\max} > 0$ and $m+1 > 0$, the sign of the expression is determined entirely by the term in parentheses. The inequality simplifies to:\n$$c_u - \\frac{rb}{1-a}  0$$\nWe seek to find the condition on $r$. Rearranging the inequality:\n$$c_u  \\frac{rb}{1-a}$$\nSince $b > 0$ and $1-a > 0$ (because $0  a  1$), we can multiply both sides by $\\frac{1-a}{b}$ without changing the inequality direction:\n$$c_u \\frac{1-a}{b}  r$$\nThis inequality, $r > c_u \\frac{1-a}{b}$, defines the range of the reward coefficient $r$ for which the periodic policy is strictly more economical than the zero steady state. The critical value $r^{\\star}$ is the value at which this transition occurs.\n\nTherefore, the critical value is:\n$$r^{\\star} = c_u \\frac{1-a}{b}$$\nFor $r > r^{\\star}$, the periodic policy achieves a negative average cost, making it strictly better than the zero-cost steady state. The unconstrained economically optimal steady state, which would seek to maximize $x$ by using a large $u$ when $c_u - \\frac{rb}{1-a}  0$, is indeed infeasible, as required by the problem statement for $r > r^{\\star}$.", "answer": "$$\\boxed{c_{u} \\frac{1-a}{b}}$$", "id": "2701639"}, {"introduction": "Real-world applications of distributed control must be robust to disturbances and uncertainties to ensure safety and reliability. This practice bridges theory and implementation by tackling the problem of robustness in distributed MPC using a tube-based approach. Your task is to develop a program that computes the necessary constraint tightening for a set of interconnected subsystems, which guarantees that the system states remain feasible despite external disturbances. This exercise demonstrates how to calculate an outer approximation of the minimal Robustly Positively Invariant (mRPI) set and apply it to design safe, practical controllers. [@problem_id:2701664]", "problem": "You are given a set of independent linear time-invariant subsystems indexed by $i \\in \\{1,2,3\\}$ with local error dynamics\n$$\ne_{i}^{+} = \\left(A_i + B_i K_i\\right) e_i + w_i,\n$$\nwhere $e_i \\in \\mathbb{R}^{n_i}$ is the local error state, $A_i \\in \\mathbb{R}^{n_i \\times n_i}$, $B_i \\in \\mathbb{R}^{n_i \\times m_i}$, $K_i \\in \\mathbb{R}^{m_i \\times n_i}$ is a given local feedback gain, and $w_i \\in \\mathcal{W}_i$ is the local disturbance. Assume that the closed-loop matrix $A_{i,\\mathrm{cl}} \\triangleq A_i + B_i K_i$ is Schur (all eigenvalues strictly inside the unit disk) and satisfies the induced infinity norm bound $\\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}  1$. The local state constraints are of the polyhedral form\n$$\n\\mathcal{X}_i \\triangleq \\{x_i \\in \\mathbb{R}^{n_i} \\mid H_i x_i \\le h_i \\},\n$$\nwhere $H_i \\in \\mathbb{R}^{p_i \\times n_i}$ has rows $c_{i,j}^{\\top}$ for $j \\in \\{1,\\dots,p_i\\}$ and $h_i \\in \\mathbb{R}^{p_i}$.\n\nFor each subsystem $i$, the minimal Robust Positively Invariant (mRPI) set for the error dynamics above is known to be\n$$\n\\mathcal{Z}_{i,\\infty} = \\bigoplus_{k=0}^{\\infty} A_{i,\\mathrm{cl}}^k \\mathcal{W}_i,\n$$\nprovided $\\mathcal{W}_i$ is convex, compact, and contains the origin, where $\\oplus$ denotes the Minkowski sum. The constraint tightening used in tube-based distributed Model Predictive Control (dMPC) is then given by the Pontryagin difference\n$$\n\\mathcal{X}_{i,\\mathrm{tight}} \\triangleq \\mathcal{X}_i \\ominus \\mathcal{Z}_{i,\\infty} = \\{x_i \\mid H_i x_i \\le h_i - s_i\\},\n$$\nwhere the offset $s_i \\in \\mathbb{R}^{p_i}$ is defined componentwise by\n$$\n\\left[s_i\\right]_j = \\sigma_{\\mathcal{Z}_{i,\\infty}}(c_{i,j}), \\quad \\text{for } j \\in \\{1,\\dots,p_i\\},\n$$\nand $\\sigma_{\\mathcal{S}}(c) \\triangleq \\sup_{z \\in \\mathcal{S}} c^{\\top} z$ denotes the support function of a set $\\mathcal{S}$ in direction $c$.\n\nYour task is to write a program that, for specified numerical data, computes an outer approximation of $\\mathcal{Z}_{i,\\infty}$ suitable for constraint tightening using iterative Minkowski sums and linear maps in the support-function domain, and then returns the vector of tightened bounds $h_i - s_i$ for each subsystem $i$.\n\nUse the following fundamental definitions and facts as the base of your derivation and algorithmic design:\n\n- For any convex compact set $\\mathcal{W} \\subset \\mathbb{R}^{n}$ and matrix $A \\in \\mathbb{R}^{n \\times n}$, the support function satisfies $\\sigma_{A \\mathcal{W}}(c) = \\sigma_{\\mathcal{W}}(A^{\\top} c)$ for any $c \\in \\mathbb{R}^{n}$.\n- For Minkowski sums, $\\sigma_{\\mathcal{S}_1 \\oplus \\mathcal{S}_2}(c) = \\sigma_{\\mathcal{S}_1}(c) + \\sigma_{\\mathcal{S}_2}(c)$.\n- For the infinite series defining $\\mathcal{Z}_{\\infty}$, the support in direction $c$ equals $\\sigma_{\\mathcal{Z}_{\\infty}}(c) = \\sum_{k=0}^{\\infty} \\sigma_{\\mathcal{W}}\\left(\\left(A^{\\top}\\right)^k c\\right)$ when the series converges.\n- For a hyper-rectangle disturbance of the form $\\mathcal{W} = \\{w \\in \\mathbb{R}^n \\mid \\lVert w \\rVert_{\\infty} \\le r\\}$ with $r > 0$, one has $\\sigma_{\\mathcal{W}}(d) = r \\lVert d \\rVert_1$ for any $d \\in \\mathbb{R}^n$.\n- If $\\lVert A \\rVert_{\\infty}  1$, then for any $c \\in \\mathbb{R}^n$ and $r > 0$,\n$$\n\\sum_{k=N+1}^{\\infty} \\sigma_{\\mathcal{W}}\\left(\\left(A^{\\top}\\right)^k c\\right) \\le r \\lVert c \\rVert_1 \\frac{\\lVert A \\rVert_{\\infty}^{N+1}}{1 - \\lVert A \\rVert_{\\infty}},\n$$\nwhich provides a computable tail bound for truncating the infinite sum at index $N$.\n\nAlgorithmic requirement to ensure a certified outer approximation: For each subsystem $i$, choose the smallest integer $N_i \\ge 0$ such that for a given tolerance $\\varepsilon > 0$,\n$$\nr_i \\left(\\max_{j \\in \\{1,\\dots,p_i\\}} \\lVert c_{i,j} \\rVert_1 \\right) \\frac{\\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}^{N_i+1}}{1 - \\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}} \\le \\varepsilon.\n$$\nThen define, for each constraint normal $c_{i,j}$,\n$$\n\\left[s_i\\right]_j = \\sum_{k=0}^{N_i} \\sigma_{\\mathcal{W}_i}\\left(\\left(A_{i,\\mathrm{cl}}^{\\top}\\right)^k c_{i,j}\\right) + r_i \\lVert c_{i,j} \\rVert_1 \\frac{\\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}^{N_i+1}}{1 - \\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}},\n$$\nand finally compute the tightened bounds $h_i - s_i$ componentwise. This yields a guaranteed over-approximation of $\\mathcal{Z}_{i,\\infty}$ in the support-function sense along the constraint normals and thus a valid tightening $\\mathcal{X}_i \\ominus \\mathcal{Z}_{i,\\infty} \\supseteq \\{x_i \\mid H_i x_i \\le h_i - s_i\\}$.\n\nImplement the above for the following test suite of three independent subsystems. In all cases, the disturbance is a centered hyper-rectangle $\\mathcal{W}_i = \\{w \\in \\mathbb{R}^{n_i} \\mid \\lVert w \\rVert_{\\infty} \\le r_i\\}$.\n\n- Test case $1$:\n  - $A_1 = \\begin{bmatrix} 0.6  0.1 \\\\ -0.05  0.5 \\end{bmatrix}$, $B_1 = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$, $K_1 = \\begin{bmatrix} -0.2  0.0 \\end{bmatrix}$.\n  - State constraints $\\mathcal{X}_1 = \\{x \\in \\mathbb{R}^2 \\mid H_1 x \\le h_1\\}$ with $H_1 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\end{bmatrix}$ and $h_1 = \\begin{bmatrix} 2.0 \\\\ 1.5 \\\\ 2.0 \\\\ 1.5 \\end{bmatrix}$.\n  - Disturbance radius $r_1 = 0.05$.\n\n- Test case $2$:\n  - $A_2 = \\begin{bmatrix} 0.7  0.2 \\\\ 0.0  0.8 \\end{bmatrix}$, $B_2 = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$, $K_2 = \\begin{bmatrix} 0.0  0.0 \\end{bmatrix}$.\n  - State constraints $\\mathcal{X}_2 = \\{x \\in \\mathbb{R}^2 \\mid H_2 x \\le h_2\\}$ with $H_2 = \\begin{bmatrix} 1  1 \\\\ -1  2 \\\\ -1  0 \\\\ 0  -1 \\end{bmatrix}$ and $h_2 = \\begin{bmatrix} 2.0 \\\\ 1.5 \\\\ 1.2 \\\\ 1.2 \\end{bmatrix}$.\n  - Disturbance radius $r_2 = 0.02$.\n\n- Test case $3$:\n  - $A_3 = \\begin{bmatrix} 0.95 \\end{bmatrix}$, $B_3 = \\begin{bmatrix} 1.0 \\end{bmatrix}$, $K_3 = \\begin{bmatrix} -0.1 \\end{bmatrix}$.\n  - State constraints $\\mathcal{X}_3 = \\{x \\in \\mathbb{R} \\mid H_3 x \\le h_3\\}$ with $H_3 = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$ and $h_3 = \\begin{bmatrix} 0.5 \\\\ 0.5 \\end{bmatrix}$.\n  - Disturbance radius $r_3 = 0.02$.\n\nUse tolerance $\\varepsilon = 10^{-6}$ for all test cases. Angles do not appear; there are no physical units.\n\nYour program should compute, for each test case $i \\in \\{1,2,3\\}$, the vector $h_i - s_i$ as described above, and produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the Python list of tightened bounds for the corresponding test case, in the order of the test cases. For example, an output of the form $[\\,[\\cdot,\\cdot,\\dots],\\,[\\cdot,\\cdot,\\dots],\\,[\\cdot,\\cdot,\\dots]\\,]$ with floating-point values is required.", "solution": "The problem statement has been critically examined and found to be valid. It is scientifically grounded in the principles of robust control theory, mathematically well-posed, objective, and contains all necessary information to derive a unique solution. The numerical data provided are consistent with the theoretical premises, specifically the stability condition $\\lVert A_i + B_i K_i \\rVert_{\\infty}  1$ for all subsystems $i \\in \\{1, 2, 3\\}$. Therefore, I shall proceed with the derivation and implementation of the solution.\n\nThe problem requires the computation of tightened state constraint bounds for a set of discrete-time linear subsystems affected by bounded disturbances. The core of the task is to compute an outer approximation of the minimal Robust Positively Invariant (mRPI) set $\\mathcal{Z}_{i,\\infty}$ for each subsystem's error dynamics and use this approximation to determine the necessary constraint back-off.\n\nThe error dynamics for subsystem $i$ are given by\n$$\ne_{i}^{+} = A_{i,\\mathrm{cl}} e_i + w_i,\n$$\nwhere $A_{i,\\mathrm{cl}} \\triangleq A_i + B_i K_i$ is the closed-loop matrix and $w_i$ is a disturbance belonging to the set $\\mathcal{W}_i = \\{w \\in \\mathbb{R}^{n_i} \\mid \\lVert w \\rVert_{\\infty} \\le r_i\\}$.\n\nThe mRPI set is the infinite Minkowski sum $\\mathcal{Z}_{i,\\infty} = \\bigoplus_{k=0}^{\\infty} A_{i,\\mathrm{cl}}^k \\mathcal{W}_i$. The state constraints are polyhedral, $\\mathcal{X}_i = \\{x_i \\mid H_i x_i \\le h_i\\}$, where the rows of $H_i$ are the vectors $c_{i,j}^{\\top}$. The tightened constraint vector is $h_i - s_i$, where the components of the offset vector $s_i$ are given by the support function of $\\mathcal{Z}_{i,\\infty}$ in the direction of the constraint normals:\n$$\n[s_i]_j = \\sigma_{\\mathcal{Z}_{i,\\infty}}(c_{i,j}) = \\sup_{z \\in \\mathcal{Z}_{i,\\infty}} c_{i,j}^{\\top} z.\n$$\n\nUsing the properties of the support function, this becomes an infinite series:\n$$\n[s_i]_j = \\sigma_{\\bigoplus_{k=0}^{\\infty} A_{i,\\mathrm{cl}}^k \\mathcal{W}_i}(c_{i,j}) = \\sum_{k=0}^{\\infty} \\sigma_{A_{i,\\mathrm{cl}}^k \\mathcal{W}_i}(c_{i,j}) = \\sum_{k=0}^{\\infty} \\sigma_{\\mathcal{W}_i}\\left(\\left(A_{i,\\mathrm{cl}}^{\\top}\\right)^k c_{i,j}\\right).\n$$\n\nFor the given hyper-rectangular disturbance set $\\mathcal{W}_i$, its support function is $\\sigma_{\\mathcal{W}_i}(d) = r_i \\lVert d \\rVert_1$. Thus,\n$$\n[s_i]_j = \\sum_{k=0}^{\\infty} r_i \\left\\lVert \\left(A_{i,\\mathrm{cl}}^{\\top}\\right)^k c_{i,j} \\right\\rVert_1.\n$$\n\nTo make this computation tractable, the infinite series is truncated at an index $N_i \\ge 0$, and the remaining tail is over-approximated by a computable bound. The algorithm proceeds as follows for each subsystem $i \\in \\{1, 2, 3\\}$.\n\n**Step 1: System Parameter Calculation**\nFirst, we compute the closed-loop matrix $A_{i,\\mathrm{cl}} = A_i + B_i K_i$. Then, we calculate its induced infinity norm, $\\alpha_i \\triangleq \\lVert A_{i,\\mathrm{cl}} \\rVert_{\\infty}$. From the problem validation, we have confirmed that $\\alpha_i  1$ for all given test cases. We also identify the constraint normal vectors $c_{i,j}$ from the rows of the matrix $H_i$ and find the maximum $L_1$-norm among them, $C_{i,\\mathrm{max}} \\triangleq \\max_{j} \\lVert c_{i,j} \\rVert_1$.\n\n**Step 2: Determination of Truncation Horizon $N_i$**\nThe truncation horizon $N_i$ is chosen as the smallest non-negative integer that guarantees the tail of the series, for the worst-case normal vector, is bounded by a given tolerance $\\varepsilon = 10^{-6}$. The condition is:\n$$\nr_i C_{i,\\mathrm{max}} \\frac{\\alpha_i^{N_i+1}}{1 - \\alpha_i} \\le \\varepsilon.\n$$\nThis inequality can be solved for $N_i+1$:\n$$\n\\alpha_i^{N_i+1} \\le \\frac{\\varepsilon (1 - \\alpha_i)}{r_i C_{i,\\mathrm{max}}}.\n$$\nTaking the logarithm (and noting $\\log(\\alpha_i)  0$ since $\\alpha_i  1$) yields:\n$$\nN_i+1 \\ge \\frac{\\log\\left(\\frac{\\varepsilon (1 - \\alpha_i)}{r_i C_{i,\\mathrm{max}}}\\right)}{\\log(\\alpha_i)}.\n$$\nThus, $N_i$ is the smallest integer satisfying this, which is found by iterating $N_i$ from $0$ upwards until the condition is met.\n\n**Step 3: Computation of the Offset Vector $s_i$**\nFor each constraint normal $c_{i,j}$, the corresponding offset $[s_i]_j$ is computed as the sum of a finite series and a tail bound:\n$$\n[s_i]_j = \\left( \\sum_{k=0}^{N_i} \\sigma_{\\mathcal{W}_i}\\left(\\left(A_{i,\\mathrm{cl}}^{\\top}\\right)^k c_{i,j}\\right) \\right) + \\text{Tail}_j.\n$$\nThe first term is the truncated sum, which is computed iteratively:\n$$\nS_{i,j} \\triangleq \\sum_{k=0}^{N_i} r_i \\left\\lVert \\left(A_{i,\\mathrm{cl}}^{\\top}\\right)^k c_{i,j} \\right\\rVert_1.\n$$\nThe second term is the bound on the series tail for the specific normal $c_{i,j}$, given by:\n$$\n\\text{Tail}_j \\triangleq r_i \\lVert c_{i,j} \\rVert_1 \\frac{\\alpha_i^{N_i+1}}{1-\\alpha_i}.\n$$\nThis provides a certified over-approximation of the true support function value, so $[s_i]_j = S_{i,j} + \\text{Tail}_j$.\n\n**Step 4: Final Calculation of Tightened Bounds**\nFinally, the vector of tightened constraint bounds is computed by component-wise subtraction:\n$$\nh_{i, \\text{tight}} = h_i - s_i.\n$$\nThis procedure is implemented for each of the three test cases provided. The numerical calculations are performed by the accompanying Python script.", "answer": "```python\nimport numpy as np\n\ndef compute_tightened_bounds(A, B, K, H, h, r, epsilon):\n    \"\"\"\n    Computes the tightened constraint bounds for a single subsystem.\n\n    Args:\n        A (np.array): System matrix.\n        B (np.array): Input matrix.\n        K (np.array): Feedback gain matrix.\n        H (np.array): Constraint matrix.\n        h (np.array): Constraint vector.\n        r (float): Disturbance radius.\n        epsilon (float): Tolerance for tail bound.\n\n    Returns:\n        list: The vector of tightened bounds h - s.\n    \"\"\"\n    # Step 1: System Parameter Calculation\n    A_cl = A + B @ K\n    alpha = np.linalg.norm(A_cl, np.inf)\n\n    normals = H\n    c_norms_1 = [np.linalg.norm(c, 1) for c in normals]\n    max_c_norm_1 = max(c_norms_1) if c_norms_1 else 0\n\n    # Step 2: Determination of Truncation Horizon N\n    # The problem guarantees alpha  1, so the denominator (1 - alpha) is positive.\n    # The loop will terminate.\n    N = 0\n    while True:\n        # According to the problem, this is the error bound for the worst-case normal\n        tail_bound_max = r * max_c_norm_1 * (alpha**(N + 1)) / (1 - alpha)\n        if tail_bound_max = epsilon:\n            break\n        N += 1\n\n    # Step 3: Computation of the Offset Vector s\n    s = np.zeros(h.shape)\n    A_cl_T = A_cl.T\n    \n    for j, (c, c_norm_1) in enumerate(zip(normals, c_norms_1)):\n        # Compute the finite sum part\n        sum_part = 0.0\n        # This vector will be updated in each iteration: (A_cl_T^k) @ c\n        A_cl_T_k_c = c\n        for _ in range(N + 1):\n            # support function sigma_W(d) = r * ||d||_1\n            sum_part += r * np.linalg.norm(A_cl_T_k_c, 1)\n            # Prepare for next iteration\n            A_cl_T_k_c = A_cl_T @ A_cl_T_k_c\n\n        # Compute the tail bound part for this specific normal\n        tail_part = r * c_norm_1 * (alpha**(N + 1)) / (1 - alpha)\n        \n        # Total offset for this constraint\n        s[j] = sum_part + tail_part\n        \n    # Step 4: Final Calculation of Tightened Bounds\n    h_tight = h - s\n    \n    return h_tight.tolist()\n\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    # Define test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[0.6, 0.1], [-0.05, 0.5]]),\n            \"B\": np.array([[1.0], [0.0]]),\n            \"K\": np.array([[-0.2, 0.0]]),\n            \"H\": np.array([[1, 0], [0, 1], [-1, 0], [0, -1]]),\n            \"h\": np.array([2.0, 1.5, 2.0, 1.5]),\n            \"r\": 0.05\n        },\n        {\n            \"A\": np.array([[0.7, 0.2], [0.0, 0.8]]),\n            \"B\": np.array([[0.0], [1.0]]),\n            \"K\": np.array([[0.0, 0.0]]),\n            \"H\": np.array([[1, 1], [-1, 2], [-1, 0], [0, -1]]),\n            \"h\": np.array([2.0, 1.5, 1.2, 1.2]),\n            \"r\": 0.02\n        },\n        {\n            \"A\": np.array([[0.95]]),\n            \"B\": np.array([[1.0]]),\n            \"K\": np.array([[-0.1]]),\n            \"H\": np.array([[1], [-1]]),\n            \"h\": np.array([0.5, 0.5]),\n            \"r\": 0.02\n        }\n    ]\n    \n    epsilon = 1e-6\n    results = []\n    \n    for case in test_cases:\n        result = compute_tightened_bounds(\n            case[\"A\"], case[\"B\"], case[\"K\"],\n            case[\"H\"], case[\"h\"], case[\"r\"],\n            epsilon\n        )\n        results.append(result)\n        \n    # Final print statement in the exact required format.\n    # The format requires printing a string representation of a list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2701664"}]}