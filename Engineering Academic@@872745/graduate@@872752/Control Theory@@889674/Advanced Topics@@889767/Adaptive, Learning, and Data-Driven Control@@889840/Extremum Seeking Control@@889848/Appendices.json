{"hands_on_practices": [{"introduction": "Understanding extremum seeking control begins with analyzing its core mechanism. This first exercise guides you through a first-principles derivation to show how a simple sinusoidal perturbation, when combined with filtering and demodulation, results in an averaged system that behaves like a gradient descent algorithm [@problem_id:2706287]. By deriving the effective gain, you will solidify your understanding of how ESC translates high-frequency oscillations into a purposeful, optimizing behavior.", "problem": "Consider a classical single-input single-output extremum seeking control (ESC) loop for minimizing an unknown smooth static map. The plant output is modeled as $y(t) = J(\\theta(t))$, where $J \\in C^{3}(\\mathbb{R}, \\mathbb{R})$ has a unique nondegenerate minimizer at $\\theta^{\\star}$ with $J'(\\theta^{\\star}) = 0$ and $J''(\\theta^{\\star})  0$. The ESC loop injects a sinusoidal dither at the plant input and demodulates the output as follows:\n- The plant input is $\\theta(t) = u(t) + a \\sin(\\omega t)$ with $a  0$ and $\\omega  0$.\n- The plant output $y(t)$ is passed through a high-pass filter $F(s) = \\frac{s}{s + \\omega_{h}}$ with $\\omega_{h}  0$, producing $r(t)$.\n- The signal $r(t)$ is multiplied by the reference $\\sin(\\omega t + \\phi)$, where $\\phi \\in \\mathbb{R}$ is a constant demodulation phase specified in radians.\n- The product is passed through a low-pass filter $G(s) = \\frac{\\omega_{\\ell}}{s + \\omega_{\\ell}}$ with $\\omega_{\\ell}  0$, producing $v(t)$.\n- The adaptation law is the integrator $\\dot{u}(t) = -k\\,v(t)$ with $k  0$.\n\nAssume standard ESC scale separation: $a$ is sufficiently small, $\\omega$ is sufficiently large such that averaging is valid, $\\omega_{\\ell} \\ll \\omega$ so that $G(s)$ passes the direct-current component and attenuates harmonics near $\\omega$ and above, and the high-pass filter $F(s)$ has steady-state sinusoidal frequency response values $F(\\mathrm{j}\\omega)$ well defined at the dither frequency.\n\nUsing only first principles (Taylor expansion, linear time-invariant sinusoidal steady-state response, trigonometric identities, and averaging), derive the leading-order averaged slow dynamics in the form\n$$\n\\dot{\\bar{u}}(t) \\;=\\; -k\\,K_{\\mathrm{eff}}\\,J'\\big(\\bar{u}(t)\\big) \\;+\\; \\text{higher-order terms in } a,\n$$\nand determine a closed-form expression for the effective scalar gain $K_{\\mathrm{eff}}$ as a function of $a$, $\\omega$, $\\omega_{h}$, and $\\phi$. You may treat the direct-current gain of $G(s)$ as $1$, i.e., $G(0) = 1$. Ignore all contributions that are higher than first order in $a$ after averaging. Provide your final result for $K_{\\mathrm{eff}}$ as a single simplified analytic expression. No numerical approximation is required.", "solution": "The analysis hinges on the principle of averaging, for which we assume a time-scale separation where $u(t)$ is a slowly varying signal, denoted as $\\bar{u}(t)$, compared to the high-frequency dither $\\sin(\\omega t)$.\n\nFirst, we perform a Taylor series expansion of the plant output $y(t) = J(\\theta(t))$ around the slowly varying component $\\bar{u}(t)$.\n$$\ny(t) = J(\\bar{u}(t) + a \\sin(\\omega t)) = J(\\bar{u}(t)) + J'(\\bar{u}(t)) [a \\sin(\\omega t)] + \\frac{1}{2} J''(\\bar{u}(t)) [a \\sin(\\omega t)]^2 + O(a^3)\n$$\nUsing the identity $\\sin^2(x) = \\frac{1}{2}(1 - \\cos(2x))$, the expansion becomes:\n$$\ny(t) = J(\\bar{u}(t)) + a J'(\\bar{u}(t)) \\sin(\\omega t) + \\frac{a^2}{4} J''(\\bar{u}(t)) (1 - \\cos(2\\omega t)) + O(a^3)\n$$\n$$\ny(t) = \\left( J(\\bar{u}(t)) + \\frac{a^2}{4} J''(\\bar{u}(t)) \\right) + a J'(\\bar{u}(t)) \\sin(\\omega t) - \\frac{a^2}{4} J''(\\bar{u}(t)) \\cos(2\\omega t) + O(a^3)\n$$\nThis output signal $y(t)$ consists of a DC (or slowly varying) part, a component at the dither frequency $\\omega$, and a component at frequency $2\\omega$, plus higher-order terms.\n\nSecond, this signal is passed through the high-pass filter $F(s) = \\frac{s}{s+\\omega_h}$. The DC component is blocked since $F(0)=0$. We analyze the filter's steady-state response to the sinusoidal component at frequency $\\omega$, which is $a J'(\\bar{u}(t)) \\sin(\\omega t)$. The frequency response of the filter is $F(\\mathrm{j}\\omega)$. We express it in polar form:\n$$\nF(\\mathrm{j}\\omega) = \\frac{\\mathrm{j}\\omega}{\\mathrm{j}\\omega + \\omega_h}\n$$\nThe magnitude is $|F(\\mathrm{j}\\omega)| = \\frac{|\\mathrm{j}\\omega|}{|\\mathrm{j}\\omega + \\omega_h|} = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}}$.\nThe phase is $\\angle F(\\mathrm{j}\\omega) = \\angle(\\mathrm{j}\\omega) - \\angle(\\omega_h + \\mathrm{j}\\omega) = \\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)$.\n\nThe component of the filter's output $r(t)$ at frequency $\\omega$ is therefore:\n$$\nr_{\\omega}(t) = a J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\sin(\\omega t + \\angle F(\\mathrm{j}\\omega))\n$$\nThe terms at frequency $2\\omega$ and higher are also passed, but they will be removed by the subsequent low-pass filtering and averaging, so we do not need to track them for the leading-order analysis.\n\nThird, the signal $r(t)$ is multiplied by the demodulation signal $\\sin(\\omega t + \\phi)$. We are interested in the DC component of this product. Let $p(t) = r(t) \\sin(\\omega t + \\phi)$. The dominant terms contributing to the average are from $r_{\\omega}(t)$:\n$$\np(t) \\approx r_{\\omega}(t) \\sin(\\omega t + \\phi) = a J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\sin(\\omega t + \\angle F(\\mathrm{j}\\omega)) \\sin(\\omega t + \\phi)\n$$\nUsing the trigonometric identity $\\sin(A)\\sin(B) = \\frac{1}{2}[\\cos(A-B) - \\cos(A+B)]$:\n$$\np(t) = \\frac{a}{2} J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\left[ \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi) - \\cos(2\\omega t + \\angle F(\\mathrm{j}\\omega) + \\phi) \\right]\n$$\nThis product signal $p(t)$ has a DC component and a high-frequency component at $2\\omega$.\n\nFourth, this signal $p(t)$ is passed through the low-pass filter $G(s) = \\frac{\\omega_{\\ell}}{s+\\omega_{\\ell}}$. Given the assumption $\\omega_{\\ell} \\ll \\omega$, this filter attenuates the high-frequency component at $2\\omega$ and passes the DC component. The DC gain of the filter is given as $G(0)=1$. The output $v(t)$ of the low-pass filter is approximately the DC component of its input $p(t)$. By the principle of averaging, the slowly varying part of $v(t)$, denoted $\\bar{v}(t)$, is the average of $p(t)$:\n$$\n\\bar{v}(t) = \\text{avg}[p(t)] = \\frac{a}{2} J'(\\bar{u}(t)) |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi)\n$$\nAll other terms originating from the Taylor expansion of $y(t)$ are of higher order in $a$ or are at high frequencies that are averaged to zero.\n\nFinally, we find the averaged dynamics for $\\bar{u}(t)$. The adaptation law is $\\dot{u}(t) = -k v(t)$. Applying the averaging theorem, the evolution of the slow variable $\\bar{u}(t)$ is governed by:\n$$\n\\dot{\\bar{u}}(t) = -k \\bar{v}(t) = -k \\left[ \\frac{a}{2} |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi) \\right] J'(\\bar{u}(t))\n$$\nThis equation is in the desired form $\\dot{\\bar{u}}(t) = -k K_{\\mathrm{eff}} J'(\\bar{u}(t))$, where the effective gain $K_{\\mathrm{eff}}$ is:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} |F(\\mathrm{j}\\omega)| \\cos(\\angle F(\\mathrm{j}\\omega) - \\phi)\n$$\nNow, we substitute the expressions for the magnitude and phase of $F(\\mathrm{j}\\omega)$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\cos\\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) - \\phi\\right)\n$$\nWe use the identity $\\cos(\\frac{\\pi}{2} - A) = \\sin(A)$, letting $A = \\arctan(\\frac{\\omega}{\\omega_h}) + \\phi$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) + \\phi\\right)\n$$\nUsing the sum identity for sine, $\\sin(X+Y) = \\sin(X)\\cos(Y) + \\cos(X)\\sin(Y)$, with $X = \\arctan(\\frac{\\omega}{\\omega_h})$ and $Y=\\phi$:\n$$\n\\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)\\right) = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\quad \\text{and} \\quad \\cos\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right)\\right) = \\frac{\\omega_h}{\\sqrt{\\omega^2 + \\omega_h^2}}\n$$\nSubstituting these into the sine sum formula:\n$$\n\\sin\\left(\\arctan\\left(\\frac{\\omega}{\\omega_h}\\right) + \\phi\\right) = \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}}\\cos(\\phi) + \\frac{\\omega_h}{\\sqrt{\\omega^2 + \\omega_h^2}}\\sin(\\phi) = \\frac{\\omega\\cos(\\phi) + \\omega_h\\sin(\\phi)}{\\sqrt{\\omega^2 + \\omega_h^2}}\n$$\nFinally, we substitute this back into the expression for $K_{\\mathrm{eff}}$:\n$$\nK_{\\mathrm{eff}} = \\frac{a}{2} \\frac{\\omega}{\\sqrt{\\omega^2 + \\omega_h^2}} \\left( \\frac{\\omega\\cos(\\phi) + \\omega_h\\sin(\\phi)}{\\sqrt{\\omega^2 + \\omega_h^2}} \\right)\n$$\nSimplifying this expression yields the final result for the effective gain:\n$$\nK_{\\mathrm{eff}} = \\frac{a \\omega (\\omega \\cos(\\phi) + \\omega_h \\sin(\\phi))}{2 (\\omega^2 + \\omega_h^2)}\n$$\nThis is the closed-form expression for the effective scalar gain $K_{\\mathrm{eff}}$ as a function of $a$, $\\omega$, $\\omega_h$, and $\\phi$.", "answer": "$$\n\\boxed{\\frac{a \\omega (\\omega \\cos(\\phi) + \\omega_h \\sin(\\phi))}{2 (\\omega^2 + \\omega_h^2)}}\n$$", "id": "2706287"}, {"introduction": "Real-world systems often include dynamics like time delays and non-minimum phase zeros, which can severely impact controller performance. This practice explores how such dynamics introduce phase shifts that can destabilize an ESC loop, potentially turning a gradient descent into a gradient ascent [@problem_id:2706305]. By calculating the maximum tolerable delay, you will learn to analyze the stability boundaries of ESC and appreciate the critical role of phase management in its design.", "problem": "Consider an extremum seeking control (ESC) loop designed to minimize an unknown, twice continuously differentiable cost function $J(u)$ with a unique strict local minimum at $u^{\\star}$, where $J'(u^{\\star}) = 0$ and $J''(u^{\\star})  0$. The ESC uses a small sinusoidal perturbation to probe the cost gradient while adapting a slowly varying input. The signal definitions are as follows, with all angles in radians and all frequencies in $\\mathrm{rad/s}$:\n- The adjustable input is $x(t)$ and the plant input is $u(t) = x(t) + a \\sin(\\omega t)$, where $a  0$ is the dither amplitude and $\\omega  0$ is the dither frequency.\n- The measured signal is generated by passing $J(u(t))$ through a linear time-invariant channel with transfer function $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$, where $z  0$ models a single right-half-plane (non-minimum phase) zero at $s = +z$ and $\\tau \\ge 0$ is an input delay.\n- The ESC demodulator multiplies the measured signal by $\\sin(\\omega t)$ and passes it through an ideal low-pass filter with unit gain at zero frequency and zero phase distortion, whose cutoff is strictly below $2\\omega$ so that higher harmonics are rejected.\n- The adaptation law is $\\dot{x}(t) = -\\kappa\\,q(t)$, where $\\kappa  0$ is small and $q(t)$ is the low-pass filtered demodulation output.\n\nAssume $a$ and $\\kappa$ are sufficiently small to justify first-order Taylor expansion and first-harmonic averaging: expand $J(x(t) + a \\sin(\\omega t))$ around $x(t)$ to first order in $a$, retain only the fundamental harmonic in the response through $H(s)$, and average the modulation products over a period. Assume all other dynamics in the loop aside from $H(s)$ and the ideal low-pass filter are negligible at frequency $\\omega$ (in particular, the low-pass filter is ideal and contributes no phase shift at any frequency retained by averaging).\n\nUsing only the sinusoidal steady-state response of linear time-invariant systems, trigonometric product-to-sum identities, and averaging arguments, derive the averaged slow dynamics of $x(t)$ near $u^{\\star}$ and determine the condition on the total phase $\\phi$ at frequency $\\omega$ that guarantees the averaged adaptation is a local descent of $J$. Then, specializing to $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$, compute the largest input delay $\\tau_{\\max}$ (in seconds) as an explicit symbolic function of $\\omega$ and $z$ such that the averaged ESC dynamics remains a local descent direction in a neighborhood of $u^{\\star}$.\n\nExpress your final answer as a closed-form analytic expression for $\\tau_{\\max}(\\omega,z)$ in terms of $\\omega$ and $z$. Do not include units in your final expression. All angles must be in radians.", "solution": "The input to the unknown cost function $J(u)$ is $u(t) = x(t) + a \\sin(\\omega t)$, where $x(t)$ is the slowly varying estimate of the optimal input $u^{\\star}$, and $a \\sin(\\omega t)$ is a small dither signal with amplitude $a > 0$ and frequency $\\omega > 0$. The output of the cost function is $y(t) = J(u(t))$.\n\nSince $x(t)$ is slowly varying compared to the dither frequency $\\omega$, and the dither amplitude $a$ is small, we can analyze the system by performing a Taylor series expansion of $J(u(t))$ around $x(t)$. We expand up to the second order to capture the local curvature information, which is essential for extremum seeking.\n$$J(x(t) + a \\sin(\\omega t)) \\approx J(x(t)) + J'(x(t)) a \\sin(\\omega t) + \\frac{1}{2} J''(x(t)) (a \\sin(\\omega t))^2$$\nUsing the trigonometric identity $\\sin^2(\\theta) = \\frac{1}{2}(1 - \\cos(2\\theta))$, the expression for $y(t)$ becomes:\n$$y(t) \\approx J(x(t)) + J'(x(t)) a \\sin(\\omega t) + \\frac{a^2}{4} J''(x(t)) (1 - \\cos(2\\omega t))$$\n$$y(t) \\approx \\left( J(x(t)) + \\frac{a^2}{4} J''(x(t)) \\right) + a J'(x(t)) \\sin(\\omega t) - \\frac{a^2}{4} J''(x(t)) \\cos(2\\omega t)$$\nThis signal $y(t)$ is the input to the linear time-invariant (LTI) channel with transfer function $H(s)$. The signal $y(t)$ contains a DC component, a component at the fundamental frequency $\\omega$, and a component at the second harmonic $2\\omega$. The output of the channel, $y_m(t)$, is obtained by considering the steady-state response to each component. Let $\\phi(\\Omega) = \\angle H(j\\Omega)$ be the phase of the channel at frequency $\\Omega$.\nThe measured signal $y_m(t)$ is given by:\n$$y_m(t) \\approx H(0) \\left( J(x) + \\frac{a^2}{4} J''(x) \\right) + |H(j\\omega)| a J'(x) \\sin(\\omega t + \\phi(\\omega)) - |H(j2\\omega)| \\frac{a^2}{4} J''(x) \\cos(2\\omega t + \\phi(2\\omega))$$\nGiven $H(s) = (1 - \\frac{s}{z})\\exp(-s\\tau)$, we have $H(0) = 1$. Let $\\phi \\equiv \\phi(\\omega) = \\angle H(j\\omega)$. The expression for $y_m(t)$ simplifies to:\n$$y_m(t) \\approx J(x) + \\frac{a^2}{4} J''(x) + a |H(j\\omega)| J'(x) \\sin(\\omega t + \\phi) - \\dots$$\nwhere the ellipsis represents higher-frequency terms.\n\nThe demodulation step multiplies $y_m(t)$ by $\\sin(\\omega t)$. The resulting signal is then passed through an ideal low-pass filter (LPF), which extracts the DC (average) component. The output of the LPF is $q(t)$.\n$$q(t) = \\text{LPF}\\{ y_m(t) \\sin(\\omega t) \\}$$\nTo find the averaged value of $q(t)$, we compute the average of the product $y_m(t) \\sin(\\omega t)$ over one period $T = 2\\pi/\\omega$. The average of any term of the form $\\sin(k\\omega t + \\theta)$ or $\\cos(k\\omega t + \\theta)$ for integer $k \\ge 1$ is zero. We use the product-to-sum identity $\\sin(A)\\sin(B) = \\frac{1}{2}(\\cos(A-B) - \\cos(A+B))$.\nThe average of the demodulated signal is:\n$$q_{avg} = \\left\\langle \\left( J(x) + \\frac{a^2}{4} J''(x) + \\dots \\right) \\sin(\\omega t) \\right\\rangle + \\left\\langle a |H(j\\omega)| J'(x) \\sin(\\omega t + \\phi) \\sin(\\omega t) \\right\\rangle - \\dots$$\nThe term involving the product of DC components and $\\sin(\\omega t)$ averages to zero. The term from the second harmonic also averages to zero because $\\langle \\cos(2\\omega t + \\phi(2\\omega))\\sin(\\omega t) \\rangle = 0$. The only term that produces a non-zero average is the one from the fundamental harmonic:\n$$q_{avg} = \\left\\langle a |H(j\\omega)| J'(x) \\frac{1}{2} (\\cos(\\phi) - \\cos(2\\omega t + \\phi)) \\right\\rangle$$\n$$q_{avg} = \\frac{a}{2} |H(j\\omega)| \\cos(\\phi) J'(x)$$\nThe adaptation law for the slow variable $x(t)$ is $\\dot{x}(t) = -\\kappa q(t)$. Using averaging theory, the dynamics of the averaged system are:\n$$\\dot{x}_{avg} = -\\kappa q_{avg} = -\\kappa \\frac{a}{2} |H(j\\omega)| \\cos(\\phi) J'(x)$$\nFor the ESC to be a local descent of the cost function $J(x)$, the system must behave like a gradient descent algorithm, i.e., $\\dot{x}_{avg}$ must have the opposite sign of the gradient $J'(x)$. This ensures that if $x(t)$ is not at the minimum, it moves towards it. To analyze local stability near the optimum $u^\\star$, we linearize the dynamics around $u^{\\star}$. Let $x(t) = u^{\\star} + \\delta_x(t)$. For small $\\delta_x$, we use the Taylor expansion $J'(x) \\approx J'(u^{\\star}) + J''(u^{\\star})(x-u^{\\star})$. Since $J'(u^{\\star}) = 0$, we have $J'(x) \\approx J''(u^{\\star})\\delta_x$.\nThe dynamics of the deviation $\\delta_x(t)$ are:\n$$\\dot{\\delta}_{x,avg} = -\\left( \\frac{\\kappa a}{2} |H(j\\omega)| \\cos(\\phi) J''(u^{\\star}) \\right) \\delta_x$$\nFor local stability, the coefficient of $\\delta_x$ must be negative, so that $\\delta_x \\to 0$. Given that $\\kappa  0$, $a  0$, $|H(j\\omega)|  0$, and $J''(u^\\star)  0$ (since $u^\\star$ is a strict local minimum), the stability condition reduces to:\n$$\\cos(\\phi)  0$$\nThis is the general condition for the phase $\\phi = \\angle H(j\\omega)$ to guarantee local descent. This condition implies $-\\frac{\\pi}{2}  \\phi  \\frac{\\pi}{2}$ (modulo $2\\pi$).\n\nNow we specialize to the given transfer function $H(s) = \\left(1 - \\frac{s}{z}\\right)\\exp(-s \\tau)$. We compute its phase at $s = j\\omega$:\n$$H(j\\omega) = \\left(1 - j\\frac{\\omega}{z}\\right)\\exp(-j\\omega \\tau)$$\nThe phase $\\phi$ is the sum of the phases of the two factors:\n$$\\phi = \\angle\\left(1 - j\\frac{\\omega}{z}\\right) + \\angle(\\exp(-j\\omega \\tau))$$\nThe first term corresponds to a complex number with a positive real part ($1$) and a negative imaginary part ($-\\omega/z$, since $\\omega, z  0$). Its phase is given by $\\arctan(-\\omega/z) = -\\arctan(\\omega/z)$. The second term, the pure delay, contributes a phase of $-\\omega\\tau$.\nTherefore, the total phase is:\n$$\\phi = -\\arctan\\left(\\frac{\\omega}{z}\\right) - \\omega \\tau$$\nFor the averaged dynamics to be a local descent, we must satisfy $\\cos(\\phi)  0$. Since $\\omega0, z0, \\tau \\ge 0$, the term $-\\arctan(\\omega/z)$ is in the interval $(-\\frac{\\pi}{2}, 0)$ and $-\\omega\\tau \\le 0$. Thus, the total phase $\\phi$ is always non-positive. The condition $\\cos(\\phi)0$ for a non-positive angle $\\phi$ is equivalent to $\\phi  -\\frac{\\pi}{2}$.\n$$-\\arctan\\left(\\frac{\\omega}{z}\\right) - \\omega \\tau  -\\frac{\\pi}{2}$$\nWe solve for the delay $\\tau$:\n$$\\omega \\tau  \\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)$$\n$$\\tau  \\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)$$\nThe largest input delay $\\tau_{\\max}$ for which the condition holds is the value that makes the inequality an equality.\n$$\\tau_{\\max} = \\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)$$\nThis expression provides the maximum tolerable delay as a function of the dither frequency $\\omega$ and the non-minimum phase zero location $z$.", "answer": "$$\\boxed{\\frac{1}{\\omega} \\left(\\frac{\\pi}{2} - \\arctan\\left(\\frac{\\omega}{z}\\right)\\right)}$$", "id": "2706305"}, {"introduction": "Many optimization problems involve multiple parameters, requiring an extension of the single-input ESC concept. This exercise introduces the powerful technique of using orthogonal dither signals to perform multivariable extremum seeking without cross-channel interference [@problem_id:2706364]. By deriving the averaged closed-loop dynamics for a two-dimensional system, you will grasp how to scale ESC to higher dimensions and analyze the stability of the resulting coupled linear system.", "problem": "Consider a static cost map $J:\\mathbb{R}^2 \\to \\mathbb{R}$ given by\n$$\nJ(u) \\;=\\; \\frac{1}{2}\\,(u - u^\\star)^\\top H\\,(u - u^\\star),\n$$\nwhere $u = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix}$, $u^\\star = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$, and\n$$\nH \\;=\\; \\begin{pmatrix} 6  2 \\\\ 2  4 \\end{pmatrix},\n$$\nwhich is symmetric positive definite. You implement a two-channel Extremum Seeking Control (ESC) scheme (Extremum Seeking Control (ESC)) with orthogonal dithers defined as follows. The plant input is\n$$\nu_i(t) \\;=\\; \\hat u_i(t) \\;+\\; a_i\\, d_i(t), \\quad i \\in \\{1,2\\},\n$$\nwhere $\\hat u(t) \\in \\mathbb{R}^2$ is the slowly varying estimate to be adapted, $a_1, a_2  0$ are constant dither amplitudes, and the dithers are\n$$\nd_1(t) \\;=\\; \\sin(\\omega t), \\qquad d_2(t) \\;=\\; \\cos(\\omega t),\n$$\nwith $\\omega  0$. The measured output is $y(t) = J(u(t))$. Each channel uses synchronous demodulation followed by ideal low-pass filtering modeled as ideal averaging over one dither period $T = 2\\pi/\\omega$:\n$$\nz_i(t) \\;=\\; \\frac{1}{T} \\int_{t}^{t+T} y(\\tau)\\, d_i(\\tau)\\, \\mathrm{d}\\tau, \\quad i \\in \\{1,2\\}.\n$$\nThe adaptation law is\n$$\n\\dot{\\hat u}_i(t) \\;=\\; -\\,k_i\\, z_i(t), \\quad k_1, k_2  0.\n$$\nAssume the standard small-signal, high-frequency regime: $a_1, a_2$ are sufficiently small and $\\omega$ is sufficiently large so that first-order averaging accurately captures the slow adaptation dynamics, and higher-order terms can be neglected.\n\nTask: Starting from the definitions above, and using only first principles such as Taylor expansion and the orthogonality of the dithers over one period, derive the averaged closed-loop error dynamics for $e(t) \\coloneqq \\hat u(t) - u^\\star$. Then, for the specific parameter values $a_1 = a_2 = 1$ and $k_1 = k_2 = 4$, compute the two eigenvalues of the averaged linear error-dynamics matrix exactly. Provide your final answer as the two eigenvalues in a single row matrix using the $\\texttt{pmatrix}$ environment. No rounding is required, and no physical units are needed in the final answer.", "solution": "The analysis begins by expressing the system output $y(t)$ in terms of the slow-varying estimate $\\hat u(t)$ and the fast-varying dither signals. We utilize a second-order Taylor series expansion of the cost function $J(u)$ around the estimate $\\hat u(t)$. The input is $u(t) = \\hat u(t) + \\delta(t)$, where $\\delta(t) = \\begin{pmatrix} a_1 d_1(t) \\\\ a_2 d_2(t) \\end{pmatrix}$.\n\nThe expansion is:\n$$\nJ(u(t)) = J(\\hat u(t) + \\delta(t)) \\approx J(\\hat u(t)) + \\nabla J(\\hat u(t))^\\top \\delta(t) + \\frac{1}{2} \\delta(t)^\\top \\nabla^2 J(\\hat u(t)) \\delta(t)\n$$\nFor the given quadratic cost function, the gradient and Hessian are:\n$$\n\\nabla J(u) = H(u - u^\\star)\n$$\n$$\n\\nabla^2 J(u) = H\n$$\nSubstituting these into the expansion and evaluating at $\\hat u(t)$:\n$$\n\\nabla J(\\hat u(t)) = H(\\hat u(t) - u^\\star) = H e(t)\n$$\n$$\ny(t) = J(u(t)) \\approx J(\\hat u(t)) + e(t)^\\top H \\delta(t) + \\frac{1}{2} \\delta(t)^\\top H \\delta(t)\n$$\nHere, $e(t) = \\hat u(t) - u^\\star$ is the error vector, which is assumed to be slowly varying compared to the dither frequency $\\omega$.\n\nNext, we compute the demodulated signals $z_i(t)$. Under the high-frequency assumption, the low-pass filter (modeled as an ideal averager) removes all high-frequency components. We treat $e(t)$ and $\\hat u(t)$ as constant over the integration interval $[t, t+T]$.\n$$\nz_i(t) \\approx \\frac{1}{T} \\int_{t}^{t+T} \\left( J(\\hat u) + e^\\top H \\delta(\\tau) + \\frac{1}{2} \\delta(\\tau)^\\top H \\delta(\\tau) \\right) d_i(\\tau) \\mathrm{d}\\tau\n$$\nWe analyze each term of the integral:\n\n1.  The term $\\frac{1}{T} \\int_{t}^{t+T} J(\\hat u) d_i(\\tau) \\mathrm{d}\\tau = J(\\hat u) \\frac{1}{T} \\int_{t}^{t+T} d_i(\\tau) \\mathrm{d}\\tau = 0$, since the average of $\\sin(\\omega \\tau)$ and $\\cos(\\omega \\tau)$ over one period is zero.\n\n2.  The term involving the gradient is $\\frac{1}{T} \\int_{t}^{t+T} (e^\\top H \\delta(\\tau)) d_i(\\tau) \\mathrm{d}\\tau$.\n    Let $(e^\\top H)_j$ be the $j$-th component of the row vector $e^\\top H$. Then $e^\\top H \\delta(\\tau) = \\sum_{j=1}^2 (e^\\top H)_j a_j d_j(\\tau)$.\n    The integral becomes $\\sum_{j=1}^2 (e^\\top H)_j a_j \\left( \\frac{1}{T} \\int_{t}^{t+T} d_j(\\tau) d_i(\\tau) \\mathrm{d}\\tau \\right)$.\n    We use the orthogonality properties of the dither signals over one period $T=2\\pi/\\omega$:\n    $$\n    \\frac{1}{T} \\int_{t}^{t+T} d_1^2(\\tau) \\mathrm{d}\\tau = \\frac{1}{T} \\int_{t}^{t+T} \\sin^2(\\omega\\tau) \\mathrm{d}\\tau = \\frac{1}{2}\n    $$\n    $$\n    \\frac{1}{T} \\int_{t}^{t+T} d_2^2(\\tau) \\mathrm{d}\\tau = \\frac{1}{T} \\int_{t}^{t+T} \\cos^2(\\omega\\tau) \\mathrm{d}\\tau = \\frac{1}{2}\n    $$\n    $$\n    \\frac{1}{T} \\int_{t}^{t+T} d_1(\\tau)d_2(\\tau) \\mathrm{d}\\tau = \\frac{1}{T} \\int_{t}^{t+T} \\sin(\\omega\\tau)\\cos(\\omega\\tau) \\mathrm{d}\\tau = 0\n    $$\n    This can be summarized as $\\frac{1}{T} \\int_{t}^{t+T} d_j(\\tau)d_i(\\tau) \\mathrm{d}\\tau = \\frac{1}{2}\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n    The summation therefore simplifies to $\\frac{1}{2} (e^\\top H)_i a_i$. As $H$ is symmetric, $(e^\\top H)_i = (H e)_i$. So this term is $\\frac{a_i}{2} (H e)_i$.\n\n3.  The term involving the Hessian is $\\frac{1}{T} \\int_{t}^{t+T} \\frac{1}{2} (\\delta(\\tau)^\\top H \\delta(\\tau)) d_i(\\tau) \\mathrm{d}\\tau$. This term contains products of three dither signals, such as $d_1^3(\\tau)$, $d_2^3(\\tau)$, $d_1^2(\\tau)d_2(\\tau)$, etc. The integral of any such third-order trigonometric monomial over a full period is zero. For example, $\\int_{t}^{t+T} \\sin^3(\\omega\\tau)\\mathrm{d}\\tau = 0$. Thus, this entire term averages to zero.\n\nCombining these results gives the averaged demodulated signal, which we denote $z_{i, \\text{avg}}$:\n$$\nz_{i, \\text{avg}}(t) = \\frac{a_i}{2} (H e(t))_i\n$$\nThe adaptation law is $\\dot{\\hat u}_i(t) = -k_i z_i(t)$. Applying averaging theory, the dynamics of the averaged estimate $\\hat u_{\\text{avg}}(t)$ are governed by:\n$$\n\\dot{\\hat u}_{i, \\text{avg}}(t) = -k_i z_{i, \\text{avg}}(t) = - k_i \\frac{a_i}{2} (H e(t))_i\n$$\nIn vector form, let $K = \\text{diag}(k_1, k_2)$ and $A = \\text{diag}(a_1, a_2)$. The averaged dynamics are:\n$$\n\\dot{\\hat u}_{\\text{avg}}(t) = -\\frac{1}{2} K A H e(t)\n$$\nThe error dynamics are found by differentiating $e(t) = \\hat u(t) - u^\\star$. Since $u^\\star$ is constant, $\\dot{e}(t) = \\dot{\\hat u}(t)$. The averaged error dynamics are therefore:\n$$\n\\dot{e}_{\\text{avg}}(t) = -\\frac{1}{2} K A H e(t)\n$$\nThis is a linear time-invariant system $\\dot{e}_{\\text{avg}}(t) = M e(t)$, where the system matrix is $M = -\\frac{1}{2} K A H$.\n\nNow, we substitute the given specific parameter values: $a_1 = a_2 = 1$, $k_1 = k_2 = 4$, and $H = \\begin{pmatrix} 6  2 \\\\ 2  4 \\end{pmatrix}$.\nThe gain and amplitude matrices become:\n$$\nK = \\begin{pmatrix} 4  0 \\\\ 0  4 \\end{pmatrix} = 4I\n$$\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} = I\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix.\nThe error dynamics matrix $M$ is:\n$$\nM = -\\frac{1}{2} (4I)(I) H = -2H = -2 \\begin{pmatrix} 6  2 \\\\ 2  4 \\end{pmatrix} = \\begin{pmatrix} -12  -4 \\\\ -4  -8 \\end{pmatrix}\n$$\nTo find the eigenvalues of $M$, we solve the characteristic equation $\\det(M - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} -12 - \\lambda  -4 \\\\ -4  -8 - \\lambda \\end{pmatrix} = 0\n$$\n$$\n(-12 - \\lambda)(-8 - \\lambda) - (-4)(-4) = 0\n$$\n$$\n(12 + \\lambda)(8 + \\lambda) - 16 = 0\n$$\n$$\n96 + 20\\lambda + \\lambda^2 - 16 = 0\n$$\n$$\n\\lambda^2 + 20\\lambda + 80 = 0\n$$\nWe use the quadratic formula $\\lambda = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ with $a=1$, $b=20$, $c=80$:\n$$\n\\lambda = \\frac{-20 \\pm \\sqrt{20^2 - 4(1)(80)}}{2}\n$$\n$$\n\\lambda = \\frac{-20 \\pm \\sqrt{400 - 320}}{2}\n$$\n$$\n\\lambda = \\frac{-20 \\pm \\sqrt{80}}{2}\n$$\nSimplifying the square root: $\\sqrt{80} = \\sqrt{16 \\times 5} = 4\\sqrt{5}$.\n$$\n\\lambda = \\frac{-20 \\pm 4\\sqrt{5}}{2}\n$$\n$$\n\\lambda = -10 \\pm 2\\sqrt{5}\n$$\nThe two eigenvalues of the averaged linear error-dynamics matrix are $\\lambda_1 = -10 - 2\\sqrt{5}$ and $\\lambda_2 = -10 + 2\\sqrt{5}$.\nBoth eigenvalues are negative, confirming that the equilibrium at $e=0$ is stable.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-10 - 2\\sqrt{5}  -10 + 2\\sqrt{5}\n\\end{pmatrix}\n}\n$$", "id": "2706364"}]}