{"hands_on_practices": [{"introduction": "The cornerstone of passivity analysis is the ability to verify the property directly from its frequency-domain definition. This first practice provides a direct application of the positive realness condition, which is the frequency-domain manifestation of passivity for Linear Time-Invariant (LTI) systems. By working through the complex arithmetic for a given transfer function, you will gain a tangible understanding of what it means for a system to be passive and whether it possesses a strict margin of passivity [@problem_id:2730380].", "problem": "Consider the real-rational, single-input single-output transfer function $G(s) = \\dfrac{s+1}{s^{2}+2s+2}$. Work from first principles of passivity and positive realness as follows.\n\n- Definition (Positive Realness): A real-rational transfer function $G(s)$ is positive real if it is analytic in the open right half-plane $\\{s \\in \\mathbb{C} : \\Re(s)  0\\}$ and satisfies $\\Re\\{G(\\mathrm{j}\\omega)\\} \\ge 0$ for all real $\\omega$ where $G(\\mathrm{j}\\omega)$ is defined. For a scalar real-rational $G(s)$, the frequency-domain Hermitian part $H(\\omega) \\triangleq G(\\mathrm{j}\\omega) + G(-\\mathrm{j}\\omega)^{\\top}$ equals $2 \\Re\\{G(\\mathrm{j}\\omega)\\}$ because $G(-\\mathrm{j}\\omega)^{\\top} = \\overline{G(\\mathrm{j}\\omega)}$.\n\n- Strictness assessment: Say that $G(s)$ is strictly positive real with a uniform margin if there exists $\\varepsilon  0$ such that $H(\\omega) \\succeq 2 \\varepsilon$ for all real $\\omega$.\n\nTasks:\n\n1. Starting from the definition above and without invoking any pre-packaged passivity tests, derive an explicit real-valued expression for $H(\\omega)$ as a function of $\\omega \\in \\mathbb{R}$ by direct complex arithmetic on $G(\\mathrm{j}\\omega)$.\n\n2. Using only the analyticity of $G(s)$ and your derived $H(\\omega)$, determine whether $G(s)$ is positive real and whether it is strictly positive real with a uniform margin in the sense defined above. Justify each step from the definitions.\n\n3. Compute the infimum\n$$\nh_{\\star} \\triangleq \\inf_{\\omega \\in \\mathbb{R}} \\lambda_{\\min}\\!\\big(H(\\omega)\\big),\n$$\nwhere for the scalar case $\\lambda_{\\min}$ returns the scalar value itself. Report the value of $h_{\\star}$ as your final answer.\n\nThe final answer must be a single real number. No rounding is required.", "solution": "We are tasked with the analysis of the positive realness of a given single-input single-output transfer function $G(s) = \\dfrac{s+1}{s^{2}+2s+2}$. The analysis must proceed from first principles as defined in the problem statement.\n\nFirst, we must validate the problem. The givens are the transfer function $G(s)$, and definitions for positive realness (PR), its strict version with a uniform margin (SPR), and the Hermitian frequency-domain function $H(\\omega)$. The tasks are to derive $H(\\omega)$, analyze the PR and SPR properties of $G(s)$, and compute the infimum $h_{\\star}$ of $H(\\omega)$. The problem is self-contained, scientifically grounded in control theory, and well-posed. The definitions are standard and the transfer function is a simple rational function. There are no contradictions or ambiguities. The problem is valid. We proceed to the solution.\n\nThe first task is to derive an explicit expression for the Hermitian function $H(\\omega) \\triangleq G(\\mathrm{j}\\omega) + G(-\\mathrm{j}\\omega)^{\\top}$. For a scalar transfer function, this simplifies to $H(\\omega) = 2 \\Re\\{G(\\mathrm{j}\\omega)\\}$. We substitute $s = \\mathrm{j}\\omega$ into $G(s)$, where $\\mathrm{j}$ is the imaginary unit and $\\omega \\in \\mathbb{R}$.\n\n$$\nG(\\mathrm{j}\\omega) = \\frac{(\\mathrm{j}\\omega)+1}{(\\mathrm{j}\\omega)^{2}+2(\\mathrm{j}\\omega)+2} = \\frac{1+\\mathrm{j}\\omega}{-\\omega^{2}+2\\mathrm{j}\\omega+2} = \\frac{1+\\mathrm{j}\\omega}{(2-\\omega^{2})+\\mathrm{j}(2\\omega)}\n$$\n\nTo find the real part of this complex expression, we multiply the numerator and the denominator by the complex conjugate of the denominator, which is $(2-\\omega^{2})-\\mathrm{j}(2\\omega)$.\n\nThe numerator becomes:\n$$\n(1+\\mathrm{j}\\omega)((2-\\omega^{2})-\\mathrm{j}(2\\omega)) = 1 \\cdot (2-\\omega^{2}) - 1 \\cdot \\mathrm{j}(2\\omega) + \\mathrm{j}\\omega \\cdot (2-\\omega^{2}) - (\\mathrm{j}\\omega)\\mathrm{j}(2\\omega)\n$$\n$$\n= (2-\\omega^{2}) - 2\\mathrm{j}\\omega + 2\\mathrm{j}\\omega - \\mathrm{j}\\omega^{3} - \\mathrm{j}^{2}2\\omega^{2} = (2-\\omega^{2}) + 2\\omega^{2} - \\mathrm{j}\\omega^{3} = (2+\\omega^{2}) - \\mathrm{j}\\omega^{3}\n$$\n\nThe denominator becomes the squared magnitude of the original denominator:\n$$\n((2-\\omega^{2})+\\mathrm{j}(2\\omega))((2-\\omega^{2})-\\mathrm{j}(2\\omega)) = (2-\\omega^{2})^{2} + (2\\omega)^{2} = (4-4\\omega^{2}+\\omega^{4}) + 4\\omega^{2} = \\omega^{4}+4\n$$\n\nThus, the expression for $G(\\mathrm{j}\\omega)$ is:\n$$\nG(\\mathrm{j}\\omega) = \\frac{(2+\\omega^{2}) - \\mathrm{j}\\omega^{3}}{\\omega^{4}+4} = \\frac{2+\\omega^{2}}{\\omega^{4}+4} - \\mathrm{j}\\frac{\\omega^{3}}{\\omega^{4}+4}\n$$\n\nThe real part is therefore $\\Re\\{G(\\mathrm{j}\\omega)\\} = \\frac{2+\\omega^{2}}{\\omega^{4}+4}$.\nAccording to the definition provided, $H(\\omega) = 2\\Re\\{G(\\mathrm{j}\\omega)\\}$.\nSo, the explicit real-valued expression for $H(\\omega)$ is:\n$$\nH(\\omega) = \\frac{2(2+\\omega^{2})}{\\omega^{4}+4}\n$$\nThis completes the first task.\n\nThe second task is to determine if $G(s)$ is positive real (PR) and strictly positive real (SPR) with a uniform margin.\nA transfer function is positive real if two conditions are met:\n1. $G(s)$ is analytic in the open right half-plane, i.e., for all $s \\in \\mathbb{C}$ with $\\Re\\{s\\}  0$.\n2. $\\Re\\{G(\\mathrm{j}\\omega)\\} \\ge 0$ for all real $\\omega$ where $G(\\mathrm{j}\\omega)$ is defined.\n\nFor the first condition, we find the poles of $G(s)$ by solving the denominator equation $s^{2}+2s+2=0$. Using the quadratic formula:\n$$\ns = \\frac{-2 \\pm \\sqrt{2^{2}-4(1)(2)}}{2(1)} = \\frac{-2 \\pm \\sqrt{4-8}}{2} = \\frac{-2 \\pm \\sqrt{-4}}{2} = \\frac{-2 \\pm 2\\mathrm{j}}{2} = -1 \\pm \\mathrm{j}\n$$\nThe poles are at $s_1 = -1+\\mathrm{j}$ and $s_2 = -1-\\mathrm{j}$. Both poles have a real part equal to $-1$, which is strictly negative. Since $G(s)$ is a rational function, it is analytic everywhere except at its poles. As both poles are in the open left half-plane, $G(s)$ is analytic in the entire open right half-plane. The first condition for positive realness is satisfied.\n\nFor the second condition, we inspect the sign of $\\Re\\{G(\\mathrm{j}\\omega)\\} = \\frac{2+\\omega^{2}}{\\omega^{4}+4}$.\nFor any real number $\\omega$, the numerator $2+\\omega^{2}$ is always positive, with a minimum value of $2$ at $\\omega=0$. The denominator $\\omega^{4}+4$ is also always positive, with a minimum value of $4$ at $\\omega=0$. The ratio of two positive numbers is always positive. Therefore, $\\Re\\{G(\\mathrm{j}\\omega)\\}  0$ for all $\\omega \\in \\mathbb{R}$, which implies $\\Re\\{G(\\mathrm{j}\\omega)\\} \\ge 0$. The second condition is also satisfied.\nSince both conditions are satisfied, we conclude that $G(s)$ is positive real.\n\nNow, we assess if $G(s)$ is strictly positive real with a uniform margin. This property requires the existence of a constant $\\varepsilon  0$ such that $H(\\omega) \\ge 2\\varepsilon$ for all $\\omega \\in \\mathbb{R}$. This is equivalent to requiring $\\Re\\{G(\\mathrm{j}\\omega)\\} \\ge \\varepsilon  0$. We must determine if the function $f(\\omega) = \\Re\\{G(\\mathrm{j}\\omega)\\} = \\frac{2+\\omega^{2}}{\\omega^{4}+4}$ has a strictly positive infimum.\nLet us examine the limit of $f(\\omega)$ as $|\\omega| \\to \\infty$:\n$$\n\\lim_{|\\omega| \\to \\infty} f(\\omega) = \\lim_{|\\omega| \\to \\infty} \\frac{2+\\omega^{2}}{\\omega^{4}+4} = \\lim_{|\\omega| \\to \\infty} \\frac{\\omega^{2}(2/\\omega^{2}+1)}{\\omega^{4}(1+4/\\omega^{4})} = \\lim_{|\\omega| \\to \\infty} \\frac{1}{\\omega^{2}} \\cdot \\frac{1+2/\\omega^{2}}{1+4/\\omega^{4}} = 0 \\cdot 1 = 0\n$$\nSince the function is always positive but approaches $0$ as $|\\omega| \\to \\infty$, its greatest lower bound (infimum) over $\\mathbb{R}$ is $0$. Therefore, there does not exist any $\\varepsilon  0$ for which $\\Re\\{G(\\mathrm{j}\\omega)\\} \\ge \\varepsilon$ holds for all $\\omega$. Consequently, $G(s)$ is not strictly positive real with a uniform margin as per the specified definition.\n\nThe third task is to compute the infimum $h_{\\star} = \\inf_{\\omega \\in \\mathbb{R}} \\lambda_{\\min}(H(\\omega))$.\nFor the scalar case, this simplifies to $h_{\\star} = \\inf_{\\omega \\in \\mathbb{R}} H(\\omega)$.\nWe have the function $H(\\omega) = \\frac{2(2+\\omega^{2})}{\\omega^{4}+4}$.\nAs established earlier, the numerator $2(2+\\omega^{2})$ is always positive, and the denominator $\\omega^{4}+4$ is always positive. Thus, $H(\\omega)  0$ for all $\\omega \\in \\mathbb{R}$.\nWe consider the limit of $H(\\omega)$ as $|\\omega| \\to \\infty$:\n$$\n\\lim_{|\\omega| \\to \\infty} H(\\omega) = \\lim_{|\\omega| \\to \\infty} \\frac{4+2\\omega^{2}}{\\omega^{4}+4} = 0\n$$\nThe function $H(\\omega)$ is continuous and strictly positive for all real $\\omega$, and it approaches $0$ as $|\\omega| \\to \\infty$. The infimum of a set is its greatest lower bound. Since $H(\\omega)$ can be made arbitrarily close to $0$ by taking $|\\omega|$ large enough, but never becomes negative or zero, the greatest lower bound is exactly $0$.\nTherefore, $h_{\\star} = 0$.", "answer": "$$\n\\boxed{0}\n$$", "id": "2730380"}, {"introduction": "While passivity is a powerful tool for analyzing interconnected systems, its guarantees rely on the crucial assumption that the interconnection is well-posed. This exercise presents a compelling counterexample where the feedback connection of two passive systems leads to an ill-posed algebraic loop, violating a core requirement of passivity theorems. By diagnosing the issue and implementing a regularization technique, you will learn to identify and resolve these critical practical issues in feedback design [@problem_id:2730416].", "problem": "Consider scalar, single-input single-output, linear time-invariant systems with the supply rate $w(u,y) = u\\,y$ and passivity interpreted in the frequency domain as the positive real property: for a transfer function $G(s)$, passivity requires $G(s)$ to be analytic in $\\operatorname{Re}(s)  0$ and to satisfy $\\operatorname{Re}\\,G(\\mathrm{j}\\omega) \\ge 0$ for all real $\\omega$. Two systems $\\Sigma_1$ and $\\Sigma_2$ are said to be interconnected by instantaneous positive feedback if their signals satisfy $u_1 = r + y_2$, $u_2 = y_1$, where $r$ is an external input.\n\n1) Construct a concrete counterexample showing that even if each component is passive, the interconnection by instantaneous positive feedback can violate the well-posedness assumption required by passivity theorems. Specifically, take $\\Sigma_1$ and $\\Sigma_2$ to be passive, with transfer functions $G_1(s) = 1 + \\dfrac{b}{s+1}$ and $G_2(s) = 1$, where $b \\in (0,1)$ is a fixed constant. Explain, starting from the passivity definition and the concept of well-posedness for algebraic loops, why the interconnection with $u_1 = r + y_2$, $u_2 = y_1$ is not well-posed.\n\n2) Propose a regularization that perturbs only the instantaneous (algebraic) part of $\\Sigma_1$ by introducing a small series loss while preserving passivity of the component. Concretely, replace $G_1(s)$ by $G_{1,\\delta}(s) = (1 - \\delta) + \\dfrac{b}{s+1}$ with $\\delta \\in (0,1)$. Derive, from first principles using the interconnection equations and the definition of passivity in the frequency domain, the closed-loop transfer $G_{\\mathrm{cl}}(s)$ from $r$ to $y_1$ and a necessary and sufficient inequality on $\\delta$ that guarantees $\\operatorname{Re}\\,G_{\\mathrm{cl}}(\\mathrm{j}\\omega) \\ge 0$ for all real $\\omega$.\n\nWhat is the smallest value of $\\delta$ expressed in terms of $b$ that guarantees passivity of the regularized closed-loop transfer $G_{\\mathrm{cl}}(s)$? Provide your final answer as a closed-form analytic expression in terms of $b$.", "solution": "This problem addresses the topic of passivity in linear time-invariant (LTI) feedback systems, specifically focusing on the critical issue of well-posedness in interconnections with direct feedthrough terms. We will first demonstrate the failure of well-posedness in a positive feedback loop of two passive systems and then analyze a regularization method to restore passivity to the closed-loop system.\n\nFirst, we analyze the problem as stated in Part 1. We are given two passive systems $\\Sigma_1$ and $\\Sigma_2$ with transfer functions $G_1(s) = 1 + \\dfrac{b}{s+1}$ and $G_2(s) = 1$, where $b \\in (0,1)$. We must verify that these components are indeed passive. A transfer function $G(s)$ represents a passive system if it is positive real, which requires it to be analytic in the open right-half plane ($\\operatorname{Re}(s)  0$) and to satisfy $\\operatorname{Re}[G(\\mathrm{j}\\omega)] \\ge 0$ for all real $\\omega$.\n\nFor $G_2(s) = 1$, the function is analytic everywhere, and $\\operatorname{Re}[G_2(\\mathrm{j}\\omega)] = \\operatorname{Re}[1] = 1 \\ge 0$. Thus, $\\Sigma_2$ is passive.\n\nFor $G_1(s) = 1 + \\dfrac{b}{s+1}$, the only pole is at $s = -1$, which is in the left-half plane, so $G_1(s)$ is analytic in $\\operatorname{Re}(s)  0$. We check the real part on the imaginary axis:\n$$\n\\operatorname{Re}[G_1(\\mathrm{j}\\omega)] = \\operatorname{Re}\\left[1 + \\frac{b}{1+\\mathrm{j}\\omega}\\right] = \\operatorname{Re}\\left[1 + \\frac{b(1-\\mathrm{j}\\omega)}{1+\\omega^2}\\right] = 1 + \\frac{b}{1+\\omega^2}\n$$\nGiven that $b  0$ and $1+\\omega^2 \\ge 1$, the term $\\dfrac{b}{1+\\omega^2}$ is always positive. Therefore, $\\operatorname{Re}[G_1(\\mathrm{j}\\omega)]  1 \\ge 0$ for all $\\omega$. Thus, $\\Sigma_1$ is also passive.\n\nThe interconnection is given by $u_1 = r + y_2$ and $u_2 = y_1$. Well-posedness of an interconnection concerns the existence and uniqueness of a solution for the internal signals for any external input $r$. For LTI systems, this is directly related to the algebraic loop formed by the direct feedthrough terms. The direct feedthrough term of a transfer function $G(s)$ is the gain at infinite frequency, $D = \\lim_{s \\to \\infty} G(s)$.\nFor our systems, the feedthrough terms are:\n$$\nD_1 = \\lim_{s \\to \\infty} G_1(s) = \\lim_{s \\to \\infty} \\left(1 + \\frac{b}{s+1}\\right) = 1\n$$\n$$\nD_2 = \\lim_{s \\to \\infty} G_2(s) = \\lim_{s \\to \\infty} 1 = 1\n$$\nThe algebraic relationships between the instantaneous parts of the signals are $y_{1,alg} = D_1 u_1$ and $y_{2,alg} = D_2 u_2$. Substituting these into the interconnection equations gives:\n$$\nu_1 = r + y_{2,alg} = r + D_2 u_2\n$$\n$$\nu_2 = y_{1,alg} = D_1 u_1\n$$\nSubstituting the second equation into the first yields an equation for $u_1$ in terms of the external input $r$:\n$$\nu_1 = r + D_2 (D_1 u_1) \\implies u_1 (1 - D_1 D_2) = r\n$$\nA unique solution for $u_1$ exists for any arbitrary $r$ if and only if the matrix $(I - D)$ is invertible, where $D$ is the feedthrough matrix of the interconnection. For this scalar case, the condition is $1 - D_1 D_2 \\neq 0$.\nIn our case, $1 - D_1 D_2 = 1 - (1)(1) = 0$. The equation becomes $0 \\cdot u_1 = r$. If $r \\neq 0$, there is no solution. If $r = 0$, there are infinitely many solutions. In either case, the internal signals are not uniquely determined by the external input. This is the definition of ill-posedness. The passivity theorem, which states that the feedback interconnection of passive systems is passive, relies on the assumption of well-posedness, which is violated here. This violation manifests as an improper closed-loop transfer function, implying infinite gain at infinite frequencies, which is not physically realizable.\n\nNow we proceed to Part 2, where we introduce a regularization. The transfer function $G_1(s)$ is replaced by $G_{1,\\delta}(s) = (1-\\delta) + \\dfrac{b}{s+1}$ with $\\delta \\in (0,1)$. The component $\\Sigma_2$ remains $G_2(s)=1$. The regularization introduces a loss $(-\\delta)$ in the direct feedthrough path of $\\Sigma_1$. The new feedthrough term is $D_{1,\\delta} = 1-\\delta$. The well-posedness condition becomes $1 - D_{1,\\delta}D_2 = 1 - (1-\\delta)(1) = \\delta$. Since $\\delta \\in (0,1)$, we have $\\delta \\neq 0$, so the regularized interconnection is well-posed.\n\nWe now derive the closed-loop transfer function $G_{\\mathrm{cl}}(s)$ from the input $r$ to the output $y_1$. The relationship in the Laplace domain is $Y_1(s) = G_{\\mathrm{cl}}(s)R(s)$. The general formula for this positive feedback configuration is:\n$$\nG_{\\mathrm{cl}}(s) = \\frac{G_{1,\\delta}(s)}{1 - G_{1,\\delta}(s)G_2(s)}\n$$\nSubstituting the expressions for the transfer functions:\n$$\nG_{\\mathrm{cl}}(s) = \\frac{(1-\\delta) + \\frac{b}{s+1}}{1 - \\left((1-\\delta) + \\frac{b}{s+1}\\right)(1)} = \\frac{\\frac{(1-\\delta)(s+1)+b}{s+1}}{1 - (1-\\delta) - \\frac{b}{s+1}} = \\frac{\\frac{(1-\\delta)s + (1-\\delta+b)}{s+1}}{\\frac{\\delta(s+1)-b}{s+1}}\n$$\n$$\nG_{\\mathrm{cl}}(s) = \\frac{(1-\\delta)s + 1-\\delta+b}{\\delta s + \\delta-b}\n$$\nFor this closed-loop system to be passive, two conditions must be met.\n1. Analyticity in $\\operatorname{Re}(s)0$: The poles of $G_{\\mathrm{cl}}(s)$ must lie in the closed left-half plane, $\\operatorname{Re}(s) \\le 0$. Any simple poles on the imaginary axis must have positive real residues. The pole of $G_{\\mathrm{cl}}(s)$ is the root of the denominator: $\\delta s + \\delta - b = 0$, which gives the pole location $s_p = \\dfrac{b-\\delta}{\\delta}$. Since $\\delta  0$, the condition $\\operatorname{Re}(s_p) \\le 0$ requires $b-\\delta \\le 0$, which implies $\\delta \\ge b$. If $\\delta = b$, the pole is at $s_p = 0$. The residue at this simple pole is $\\lim_{s \\to 0} s G_{\\mathrm{cl}}(s) = \\lim_{s \\to 0} s \\dfrac{(1-b)s+1}{b s} = \\dfrac{1}{b}$. Since $b \\in (0,1)$, the residue $1/b$ is real and positive, which is permissible for a passive system. Thus, the stability condition is $\\delta \\ge b$.\n\n2. Positive Real Part on the Imaginary Axis: We must have $\\operatorname{Re}[G_{\\mathrm{cl}}(\\mathrm{j}\\omega)] \\ge 0$ for all real $\\omega$.\n$$\nG_{\\mathrm{cl}}(\\mathrm{j}\\omega) = \\frac{(1-\\delta)\\mathrm{j}\\omega + (1-\\delta+b)}{\\delta\\mathrm{j}\\omega + (\\delta-b)}\n$$\nTo find the real part, we multiply the numerator and denominator by the conjugate of the denominator:\n$$\n\\operatorname{Re}[G_{\\mathrm{cl}}(\\mathrm{j}\\omega)] = \\operatorname{Re}\\left[ \\frac{((1-\\delta+b) + (1-\\delta)\\mathrm{j}\\omega)((\\delta-b) - \\delta\\mathrm{j}\\omega)}{|\\delta\\mathrm{j}\\omega + (\\delta-b)|^2} \\right]\n$$\nThe denominator is real and positive. The real part of the numerator is:\n$$\n\\operatorname{Re}[\\text{num}] = (1-\\delta+b)(\\delta-b) + ((1-\\delta)\\omega)(\\delta\\omega) = (1-\\delta+b)(\\delta-b) + (1-\\delta)\\delta\\omega^2\n$$\nSo, the condition becomes:\n$$\n\\frac{(1-\\delta+b)(\\delta-b) + (1-\\delta)\\delta\\omega^2}{(\\delta-b)^2 + (\\delta\\omega)^2} \\ge 0\n$$\nSince the denominator is always non-negative, the numerator must be non-negative for all $\\omega$. Let $N(\\omega) = (1-\\delta+b)(\\delta-b) + (1-\\delta)\\delta\\omega^2$. Given $\\delta \\in (0,1)$, the term $(1-\\delta)\\delta\\omega^2$ is non-negative. Therefore, the minimum value of $N(\\omega)$ occurs at $\\omega=0$. The condition reduces to $N(0) \\ge 0$:\n$$\n(1-\\delta+b)(\\delta-b) \\ge 0\n$$\nSince $\\delta \\in (0,1)$ and $b \\in (0,1)$, the first factor $(1-\\delta+b)$ is always positive. The inequality is thus satisfied if and only if the second factor is non-negative:\n$$\n\\delta - b \\ge 0 \\implies \\delta \\ge b\n$$\nBoth the stability condition and the positive real part condition yield the same necessary and sufficient inequality: $\\delta \\ge b$.\nThe problem asks for the smallest value of $\\delta$ that guarantees passivity. This corresponds to the minimum value in the allowed range for $\\delta$. The required range is $\\delta \\ge b$. Since $\\delta \\in (0,1)$ and $b \\in (0,1)$, the full condition for $\\delta$ is $b \\le \\delta  1$. The smallest value in this set is $b$.", "answer": "$$\n\\boxed{b}\n$$", "id": "2730416"}, {"introduction": "Moving from analysis to synthesis is a key step in control engineering. This practice challenges you to design a simple compensator to render a non-passive system passive, a common technique in passivity-based control. You will formulate the problem of finding the minimal required feedforward gain as a convex optimization problem, effectively solving a frequency-domain linear matrix inequality (LMI) to find the system's \"passivity deficit\" and compensate for it computationally [@problem_id:2730388].", "problem": "Consider continuous-time, single-input single-output linear time-invariant systems given in state-space form by matrices $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times 1}$, $C \\in \\mathbb{R}^{1 \\times n}$, and $D \\in \\mathbb{R}^{1 \\times 1}$. The transfer function is $G(s) = C(sI - A)^{-1} B + D$. A system is passive if and only if it is positive real, which for single-input single-output systems is equivalent to the condition $\\operatorname{Re}\\, G(j \\omega) \\ge 0$ for all $\\omega \\in \\mathbb{R}$. By the Kalman–Yakubovich–Popov (KYP) conditions (also called the Positive Real Lemma), positive realness of $G(s)$ is equivalent to feasibility of a Linear Matrix Inequality (LMI) in a symmetric matrix $P \\succeq 0$. In particular, the augmented transfer $G_d(s) = G(s) + d$ for a scalar compensator $K(s) = d$ (a zero-order dynamic compensator) is positive real if and only if, for that $d \\ge 0$, the KYP LMI holds.\n\nYour task is to synthesize, for each given plant, the minimal nonnegative scalar $d^\\star$ such that the compensated system $G_d(s) = G(s) + d^\\star$ is positive real, which renders the closed-loop passive with a minimal dynamic compensator of order zero. To connect directly to an LMI derived from the KYP conditions in a computationally verifiable way, use the equivalent frequency-domain infinite family of linear constraints arising from the KYP lemma for single-input single-output: for all frequencies $\\omega \\in \\mathbb{R}$,\n$$\n\\operatorname{Re}\\, G(j \\omega) + d \\;\\ge\\; 0.\n$$\nThis yields the convex optimization problem\n$$\n\\min_{d \\in \\mathbb{R}} \\; d \\quad \\text{subject to} \\quad \\operatorname{Re}\\, G(j \\omega) + d \\ge 0 \\text{ for all } \\omega \\in \\mathbb{R},\n$$\nwhose optimal value equals\n$$\nd^\\star \\;=\\; \\max\\Bigl\\{0,\\, - \\inf_{\\omega \\in \\mathbb{R}} \\operatorname{Re}\\, G(j \\omega) \\Bigr\\}.\n$$\nComputationally, approximate the infinite constraint set by a dense frequency grid $\\{\\omega_k\\}_{k=1}^N$ and solve the resulting discretized LMI (a set of linear inequalities in $d$) exactly:\n$$\nd^\\star_N \\;=\\; \\max\\Bigl\\{0,\\, \\max_{1 \\le k \\le N} \\bigl(-\\operatorname{Re}\\, G(j \\omega_k)\\bigr) \\Bigr\\}.\n$$\n\nImplement a program that, for each test plant specified below, evaluates $d^\\star_N$ on the prescribed frequency grid and outputs the minimal $d$ that passivizes the plant via $G_d(s) = G(s) + d$. The compensator $K(s) = d$ is the minimal-order (zero) dynamic compensator. All quantities are dimensionless; express the final $d$ values as decimal floating-point numbers rounded to six digits after the decimal point.\n\nTest suite (three plants):\n- Case 1 (lightly damped second-order, strictly proper, non-passive):\n  - $A = \\begin{bmatrix} 0  1 \\\\ -2  -0.2 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $C = \\begin{bmatrix} 1  0 \\end{bmatrix}$, $D = \\begin{bmatrix} 0 \\end{bmatrix}$.\n  - Frequency grid: construct the set $\\{\\omega_k\\}$ as the union of a linearly spaced grid on $[0, 100]$ with $2001$ points and a logarithmically spaced grid on $[10^{-3}, 10^{3}]$ with $2001$ points; remove duplicates and sort ascending.\n- Case 2 (second-order with negative direct term, strongly non-passive):\n  - $A = \\begin{bmatrix} -1  2 \\\\ -3  -1 \\end{bmatrix}$, $B = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$, $C = \\begin{bmatrix} 0  1 \\end{bmatrix}$, $D = \\begin{bmatrix} -0.5 \\end{bmatrix}$.\n  - Frequency grid: union of linear $[0, 150]$ with $2501$ points and logarithmic $[10^{-3}, 10^{3}]$ with $2001$ points; remove duplicates and sort ascending.\n- Case 3 (first-order, already passive; boundary case):\n  - $A = \\begin{bmatrix} -1 \\end{bmatrix}$, $B = \\begin{bmatrix} 1 \\end{bmatrix}$, $C = \\begin{bmatrix} 1 \\end{bmatrix}$, $D = \\begin{bmatrix} 0 \\end{bmatrix}$.\n  - Frequency grid: union of linear $[0, 200]$ with $2001$ points and logarithmic $[10^{-3}, 10^{3}]$ with $2001$ points; remove duplicates and sort ascending.\n\nAlgorithmic requirements:\n- For each plant and its frequency grid $\\{\\omega_k\\}$, compute $\\operatorname{Re}\\, G(j \\omega_k)$ exactly via the state-space formula $G(j \\omega) = C \\,(j \\omega I - A)^{-1} B + D$ for each $\\omega_k$, then solve the discretized LMI by returning\n  $$\n  d^\\star_N \\;=\\; \\max\\Bigl\\{0,\\, \\max_k \\bigl(-\\operatorname{Re}\\, G(j \\omega_k)\\bigr) \\Bigr\\}.\n  $$\n- Use double-precision arithmetic and report $d^\\star_N$ rounded to six digits after the decimal point.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for Cases 1–3 as a comma-separated list enclosed in square brackets, in the order of the cases, for example, \"[d1,d2,d3]\".", "solution": "The problem as stated is submitted for validation. The givens are extracted and analyzed according to the established criteria.\n\nThe task is to determine, for several continuous-time linear time-invariant (LTI) systems, the minimal non-negative scalar feedforward gain $d^\\star$ that renders the compensated system passive. The systems are provided in state-space form with matrices $A$, $B$, $C$, and $D$.\n\nThe fundamental principle is that a single-input single-output (SISO) LTI system with transfer function $G(s)$ is passive if and only if $G(s)$ is positive real. For a real-rational transfer function, this is equivalent to the frequency-domain condition:\n$$\n\\operatorname{Re}[G(j\\omega)] \\ge 0 \\quad \\text{for all } \\omega \\in \\mathbb{R}\n$$\nThe problem considers a compensated system with transfer function $G_d(s) = G(s) + d$, where $d$ is a real scalar. The passivity condition for this compensated system is:\n$$\n\\operatorname{Re}[G_d(j\\omega)] = \\operatorname{Re}[G(j\\omega) + d] = \\operatorname{Re}[G(j\\omega)] + d \\ge 0\n$$\nThis inequality must hold for all frequencies $\\omega \\in \\mathbb{R}$. This implies that $d$ must be greater than or equal to the negative of the real part of $G(j\\omega)$ for all $\\omega$:\n$$\nd \\ge -\\operatorname{Re}[G(j\\omega)] \\quad \\text{for all } \\omega \\in \\mathbb{R}\n$$\nTo satisfy this condition for all frequencies, $d$ must be greater than or equal to the supremum of the right-hand side over all $\\omega$:\n$$\nd \\ge \\sup_{\\omega \\in \\mathbb{R}} \\left( -\\operatorname{Re}[G(j\\omega)] \\right) = - \\inf_{\\omega \\in \\mathbb{R}} \\left( \\operatorname{Re}[G(j\\omega)] \\right)\n$$\nThe problem seeks the minimal *non-negative* scalar $d^\\star$. If the infimum of $\\operatorname{Re}[G(j\\omega)]$ is non-negative, the system is already passive, and the minimal non-negative gain is $d^\\star = 0$. Otherwise, the minimal gain required is precisely $-\\inf_{\\omega \\in \\mathbb{R}} \\operatorname{Re}[G(j\\omega)]$. Combining these two cases yields the correct formula for the optimal value $d^\\star$:\n$$\nd^\\star = \\max\\left\\{0, - \\inf_{\\omega \\in \\mathbb{R}} \\operatorname{Re}[G(j\\omega)] \\right\\}\n$$\nThe validation of this problem statement confirms its scientific soundness. All definitions and derived formulae are standard in control theory. The problem is well-posed and provides all necessary data for its solution. Therefore, we proceed.\n\nThe computational approach involves approximating the infinite set of frequency constraints. The continuous frequency range $\\omega \\in \\mathbb{R}$ is replaced by a finite, dense grid of $N$ points, $\\{\\omega_k\\}_{k=1}^N$. The problem then reduces to finding the minimal non-negative $d$ that satisfies a finite set of linear inequalities:\n$$\nd \\ge -\\operatorname{Re}[G(j\\omega_k)] \\quad \\text{for } k = 1, 2, \\ldots, N\n$$\nThe solution to this discretized problem, denoted $d^\\star_N$, is given by:\n$$\nd^\\star_N = \\max\\left\\{0, \\max_{1 \\le k \\le N} \\left(-\\operatorname{Re}[G(j\\omega_k)]\\right) \\right\\}\n$$\nFor each test case, the value of the transfer function $G(j\\omega_k)$ is computed from the state-space representation $(A, B, C, D)$ using the formula:\n$$\nG(j\\omega_k) = C(j\\omega_k I - A)^{-1}B + D\n$$\nwhere $I$ is the identity matrix of appropriate dimension. The procedure is as follows:\n$1$. For each test case, construct the specified frequency grid $\\{\\omega_k\\}$ by taking the union of a linear and a logarithmic grid.\n$2$. Initialize a variable, `max_neg_re_G`, to a very small number (or to the value at the first frequency point).\n$3$. For each frequency $\\omega_k$ in the grid:\n    a. Construct the complex matrix $S_k = j\\omega_k I - A$.\n    b. Compute the inverse matrix $S_k^{-1}$. The systems given are stable, ensuring $S_k$ is non-singular for all $\\omega_k \\ge 0$.\n    c. Calculate the complex scalar $G(j\\omega_k) = C S_k^{-1} B + D$.\n    d. Update `max_neg_re_G` with $\\max(\\text{`max_neg_re_G`}, -\\operatorname{Re}[G(j\\omega_k)])$.\n$4$. The final result is $d^\\star_N = \\max(0, \\text{`max_neg_re_G`})$. This value is then rounded to six decimal places as required.\n\nThis algorithm will be implemented and applied to the three specified test cases.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the minimal non-negative scalar d that passivizes a given LTI system.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"A\": np.array([[0.0, 1.0], [-2.0, -0.2]]),\n            \"B\": np.array([[0.0], [1.0]]),\n            \"C\": np.array([[1.0, 0.0]]),\n            \"D\": np.array([[0.0]]),\n            \"grid_lin\": (0, 100, 2001),\n            \"grid_log\": (1e-3, 1e3, 2001),\n        },\n        {\n            \"A\": np.array([[-1.0, 2.0], [-3.0, -1.0]]),\n            \"B\": np.array([[0.0], [1.0]]),\n            \"C\": np.array([[0.0, 1.0]]),\n            \"D\": np.array([[-0.5]]),\n            \"grid_lin\": (0, 150, 2501),\n            \"grid_log\": (1e-3, 1e3, 2001),\n        },\n        {\n            \"A\": np.array([[-1.0]]),\n            \"B\": np.array([[1.0]]),\n            \"C\": np.array([[1.0]]),\n            \"D\": np.array([[0.0]]),\n            \"grid_lin\": (0, 200, 2001),\n            \"grid_log\": (1e-3, 1e3, 2001),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A, B, C, D = case[\"A\"], case[\"B\"], case[\"C\"], case[\"D\"]\n        lin_params = case[\"grid_lin\"]\n        log_params = case[\"grid_log\"]\n        \n        n = A.shape[0]\n        I = np.identity(n)\n\n        # Construct the frequency grid\n        lin_grid = np.linspace(lin_params[0], lin_params[1], lin_params[2])\n        log_grid = np.logspace(np.log10(log_params[0]), np.log10(log_params[1]), log_params[2])\n        omegas = np.union1d(lin_grid, log_grid)\n\n        max_neg_re_G = -np.inf\n\n        for omega in omegas:\n            s = 1j * omega\n            \n            # Form the matrix sI - A\n            sI_minus_A = s * I - A\n            \n            # Compute G(jw) = C * inv(sI - A) * B + D\n            try:\n                inv_sI_minus_A = np.linalg.inv(sI_minus_A)\n                G_jw = C @ inv_sI_minus_A @ B + D\n                \n                # Extract the real part of the scalar result\n                re_G_jw = np.real(G_jw[0, 0])\n                \n                # Update the maximum of -Re(G(jw))\n                neg_re_G_jw = -re_G_jw\n                if neg_re_G_jw > max_neg_re_G:\n                    max_neg_re_G = neg_re_G_jw\n\n            except np.linalg.LinAlgError:\n                # This should not happen for the given stable systems\n                # and non-pole frequencies.\n                continue\n        \n        # d_star is max(0, max(-Re(G(jw))))\n        d_star_N = max(0.0, max_neg_re_G)\n        \n        results.append(f\"{d_star_N:.6f}\")\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2730388"}]}