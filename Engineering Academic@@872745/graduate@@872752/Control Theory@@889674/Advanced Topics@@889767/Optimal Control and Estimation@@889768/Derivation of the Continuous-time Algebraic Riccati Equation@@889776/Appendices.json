{"hands_on_practices": [{"introduction": "To build our intuition, we will first derive the Algebraic Riccati Equation from first principles for the simplest case: a scalar (one-dimensional) system. This exercise [@problem_id:2699184] will guide you through the application of the Hamilton-Jacobi-Bellman equation and introduce the crucial concept of selecting the unique 'stabilizing' solution from the possible mathematical roots.", "problem": "Consider the scalar linear time-invariant system governed by $\\dot{x}(t) = a\\,x(t) + b\\,u(t)$ with the infinite-horizon quadratic performance index $J = \\int_{0}^{\\infty} \\big(q\\,x(t)^{2} + r\\,u(t)^{2}\\big)\\,dt$. Start from Bellman’s principle of optimality leading to the stationary Hamilton–Jacobi–Bellman (HJB) equation for the infinite-horizon case, and use a quadratic value function ansatz $V(x) = P\\,x^{2}$ with $P$ constant. By minimizing the HJB Hamiltonian with respect to $u$, derive the scalar continuous-time algebraic Riccati equation (ARE) satisfied by $P$. Then, for the specific data $a=1$, $b=1$, $q=2$, and $r=1$, solve the resulting scalar equation explicitly and select the stabilizing solution that renders the closed-loop system $\\dot{x}(t) = \\big(a - b\\,r^{-1}b\\,P\\big)\\,x(t)$ asymptotically stable. Express your final answer as a single closed-form analytic expression for the stabilizing $P$. No rounding is required.", "solution": "The starting point is the infinite-horizon stationary Hamilton–Jacobi–Bellman (HJB) equation for the optimal value function $V(x)$,\n$$\n0 \\;=\\; \\min_{u}\\,\\Big\\{\\, q\\,x^{2} + r\\,u^{2} + V_{x}(x)\\,\\big(a\\,x + b\\,u\\big) \\Big\\},\n$$\nwhere $V_{x}(x)$ denotes the derivative of $V$ with respect to $x$. We postulate a quadratic value function ansatz $V(x) = P\\,x^{2}$ with constant $P$. Then $V_{x}(x) = 2\\,P\\,x$, and the HJB Hamiltonian becomes\n$$\n\\mathcal{H}(x,u) \\;=\\; q\\,x^{2} + r\\,u^{2} + 2\\,P\\,x\\,(a\\,x + b\\,u).\n$$\nTo obtain the optimal input, minimize $\\mathcal{H}(x,u)$ with respect to $u$. The first-order optimality condition is\n$$\n\\frac{\\partial \\mathcal{H}}{\\partial u} \\;=\\; 2\\,r\\,u + 2\\,P\\,x\\,b \\;=\\; 0,\n$$\nwhich yields the optimal control law\n$$\nu^{\\star}(x) \\;=\\; -\\,\\frac{b\\,P}{r}\\,x.\n$$\nSubstitute $u^{\\star}(x)$ back into the Hamiltonian and enforce the HJB equation. First compute each term:\n- The state penalty is $q\\,x^{2}$.\n- The input penalty is $r\\,(u^{\\star})^{2} = r\\,\\Big(\\frac{b^{2}P^{2}}{r^{2}}\\,x^{2}\\Big) = \\frac{b^{2}}{r}\\,P^{2}\\,x^{2}$.\n- The coupling term is $V_{x}\\,(a\\,x + b\\,u^{\\star}) = 2\\,P\\,x\\,\\Big(a\\,x + b\\big(-\\frac{b\\,P}{r}\\,x\\big)\\Big) = \\big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\big)\\,x^{2}$.\nTherefore,\n$$\n0 \\;=\\; q\\,x^{2} + \\frac{b^{2}}{r}\\,P^{2}\\,x^{2} + \\Big(2\\,a\\,P - \\frac{2\\,b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}\n\\;=\\; \\Big(q + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2}\\Big)\\,x^{2}.\n$$\nBecause this must hold for all $x$, the scalar continuous-time algebraic Riccati equation (ARE) for $P$ is\n$$\nq + 2\\,a\\,P - \\frac{b^{2}}{r}\\,P^{2} \\;=\\; 0.\n$$\n\nFor the given data $a=1$, $b=1$, $q=2$, and $r=1$, the equation becomes\n$$\n2 + 2\\,P - P^{2} \\;=\\; 0,\n$$\nor equivalently\n$$\nP^{2} - 2\\,P - 2 \\;=\\; 0.\n$$\nSolving this quadratic yields\n$$\nP \\;=\\; \\frac{2 \\pm \\sqrt{4 + 8}}{2} \\;=\\; 1 \\pm \\sqrt{3}.\n$$\n\nTo select the stabilizing solution, examine the closed-loop scalar dynamics under the optimal controller. The optimal feedback is $u^{\\star}(x) = -\\frac{b\\,P}{r}\\,x$, so the closed-loop system is\n$$\n\\dot{x}(t) \\;=\\; \\Big(a - \\frac{b^{2}}{r}\\,P\\Big)\\,x(t) \\;=\\; \\big(1 - P\\big)\\,x(t).\n$$\nAsymptotic stability requires $1 - P  0$, i.e., $P > 1$. Among the two roots $1 \\pm \\sqrt{3}$, only $1 + \\sqrt{3}$ satisfies $P > 1$ and is nonnegative. Hence the stabilizing solution is\n$$\nP^{\\star} \\;=\\; 1 + \\sqrt{3}.\n$$", "answer": "$$\\boxed{1+\\sqrt{3}}$$", "id": "2699184"}, {"introduction": "Having mastered the scalar case, we now scale our understanding to matrix systems, which represent the vast majority of real-world applications. This practice [@problem_id:2699194] tackles the classic double integrator, a fundamental model in mechanics, requiring you to solve the full matrix ARE and verify the stability of the resulting closed-loop system.", "problem": "Consider the continuous-time Linear Quadratic Regulator (LQR) problem for the linear time-invariant system with state dynamics $\\dot{x}(t)=A x(t)+B u(t)$ and infinite-horizon performance index $J(x_{0})=\\int_{0}^{\\infty}\\left(x(t)^{\\top} Q x(t)+u(t)^{\\top} R u(t)\\right)\\,\\mathrm{d}t$. Starting from the Hamilton–Jacobi–Bellman (HJB) equation and the Bellman optimality principle, derive the continuous-time Algebraic Riccati Equation (ARE) by assuming a quadratic value function candidate $V(x)=x^{\\top} P x$ with a symmetric matrix $P$. Then, for the specific data\n$$\nA=\\begin{bmatrix}01\\\\00\\end{bmatrix},\\quad B=\\begin{bmatrix}0\\\\1\\end{bmatrix},\\quad Q=I_{2},\\quad R=1,\n$$\nsolve for the symmetric matrix $P$ that yields the stabilizing solution and compute the corresponding optimal state-feedback gain $K$. Finally, verify that the closed-loop matrix $A-BK$ is Hurwitz by analyzing its eigenvalues.\n\nAssume the standard LQR existence conditions (stabilizability of $(A,B)$ and detectability of $(Q^{1/2},A)$) hold. Provide your final answer as the row vector $K$ in a single explicit analytic expression. No numerical rounding is required.", "solution": "The foundation of this derivation is the Bellman optimality principle, which is expressed for continuous-time systems by the Hamilton-Jacobi-Bellman (HJB) equation. For the infinite-horizon LQR problem, the optimal value function $V(x) = \\min_{u} J(x)$ must satisfy the stationary HJB equation:\n$$\n\\min_{u} \\left\\{ \\frac{\\partial V}{\\partial x}^{\\top} (A x + B u) + x^{\\top} Q x + u^{\\top} R u \\right\\} = 0\n$$\nThe problem posits a quadratic candidate for the value function, $V(x) = x^{\\top} P x$, where $P$ is a symmetric positive definite matrix ($P=P^\\top > 0$). The gradient of $V(x)$ with respect to $x$ is:\n$$\n\\frac{\\partial V}{\\partial x} = (P + P^{\\top})x = 2Px\n$$\nSubstituting this into the HJB equation yields:\n$$\n\\min_{u} \\left\\{ (2Px)^{\\top} (A x + B u) + x^{\\top} Q x + u^{\\top} R u \\right\\} = 0\n$$\nExpanding the first term:\n$$\n\\min_{u} \\left\\{ 2x^{\\top}PAx + 2x^{\\top}PBu + x^{\\top}Qx + u^{\\top}Ru \\right\\} = 0\n$$\nThe expression inside the minimization is the Hamiltonian, $H(x, u, P)$. To find the optimal control $u^*(t)$ that minimizes this Hamiltonian, we take its gradient with respect to $u$ and set it to zero. Since $R0$, the Hamiltonian is convex in $u$.\n$$\n\\frac{\\partial H}{\\partial u} = 2B^{\\top}Px + 2Ru = 0\n$$\nSolving for $u$ gives the optimal control law:\n$$\nu^*(t) = -R^{-1}B^{\\top}Px(t)\n$$\nThis is a linear state-feedback law $u = -Kx$, where the optimal gain matrix is $K = R^{-1}B^{\\top}P$.\n\nNow, we substitute this optimal control $u^*$ back into the HJB equation:\n$$\n2x^{\\top}PAx + 2x^{\\top}PB(-R^{-1}B^{\\top}Px) + x^{\\top}Qx + (-R^{-1}B^{\\top}Px)^{\\top}R(-R^{-1}B^{\\top}Px) = 0\n$$\nThis simplifies as follows. The term $2x^{\\top}PAx$ can be written as $x^{\\top}A^{\\top}Px + x^{\\top}PAx = x^{\\top}(A^{\\top}P+PA)x$ because $x^{\\top}PAx$ is a scalar and $P$ is symmetric.\n$$\nx^{\\top}(A^{\\top}P+PA)x - 2x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}Qx + x^{\\top}PB(R^{-1})^{\\top}RR^{-1}B^{\\top}Px = 0\n$$\nSince the weighting matrix $R$ is symmetric, $R^{-1}$ is also symmetric. Therefore, $(R^{-1})^{\\top} = R^{-1}$.\n$$\nx^{\\top}(A^{\\top}P+PA)x - 2x^{\\top}PBR^{-1}B^{\\top}Px + x^{\\top}Qx + x^{\\top}PBR^{-1}B^{\\top}Px = 0\n$$\nCombining terms, we get:\n$$\nx^{\\top}(A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q)x = 0\n$$\nThis equation must hold for any state $x(t) \\in \\mathbb{R}^n$. This is only possible if the matrix expression inside the parentheses is the zero matrix. This gives the continuous-time Algebraic Riccati Equation (ARE):\n$$\nA^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0\n$$\n\n**Part 2: Solution for the Specific System**\n\nWe are given:\n$$\nA=\\begin{bmatrix}01\\\\00\\end{bmatrix}, \\quad B=\\begin{bmatrix}0\\\\1\\end{bmatrix}, \\quad Q=\\begin{bmatrix}10\\\\01\\end{bmatrix}, \\quad R=1\n$$\nLet the symmetric matrix $P$ be parameterized as $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$. We now compute each term of the ARE.\n$$\nA^{\\top}P = \\begin{bmatrix}00\\\\10\\end{bmatrix}\\begin{bmatrix}p_{11}p_{12}\\\\p_{12}p_{22}\\end{bmatrix} = \\begin{bmatrix}00\\\\p_{11}p_{12}\\end{bmatrix}\n$$\n$$\nPA = \\begin{bmatrix}p_{11}p_{12}\\\\p_{12}p_{22}\\end{bmatrix}\\begin{bmatrix}01\\\\00\\end{bmatrix} = \\begin{bmatrix}0p_{11}\\\\0p_{12}\\end{bmatrix}\n$$\nThe term $PBR^{-1}B^{\\top}P$ is computed as:\n$$\nPB = \\begin{bmatrix}p_{11}p_{12}\\\\p_{12}p_{22}\\end{bmatrix}\\begin{bmatrix}0\\\\1\\end{bmatrix} = \\begin{bmatrix}p_{12}\\\\p_{22}\\end{bmatrix}\n$$\n$$\nB^{\\top}P = ([P][B])^{\\top} = \\begin{bmatrix}p_{12}p_{22}\\end{bmatrix}\n$$\n$$\nPBR^{-1}B^{\\top}P = (PB)(R^{-1})(B^{\\top}P) = \\begin{bmatrix}p_{12}\\\\p_{22}\\end{bmatrix} (1) \\begin{bmatrix}p_{12}p_{22}\\end{bmatrix} = \\begin{bmatrix}p_{12}^2  p_{12}p_{22} \\\\ p_{12}p_{22}  p_{22}^2\\end{bmatrix}\n$$\nSubstituting all terms into the ARE, $A^{\\top}P + PA - PBR^{-1}B^{\\top}P + Q = 0$:\n$$\n\\begin{bmatrix}0p_{11}\\\\p_{11}2p_{12}\\end{bmatrix} - \\begin{bmatrix}p_{12}^2  p_{12}p_{22} \\\\ p_{12}p_{22}  p_{22}^2\\end{bmatrix} + \\begin{bmatrix}10\\\\01\\end{bmatrix} = \\begin{bmatrix}00\\\\00\\end{bmatrix}\n$$\n$$\n\\begin{bmatrix}1-p_{12}^2  p_{11}-p_{12}p_{22} \\\\ p_{11}-p_{12}p_{22}  1+2p_{12}-p_{22}^2\\end{bmatrix} = \\begin{bmatrix}00\\\\00\\end{bmatrix}\n$$\nThis matrix equality yields a system of three scalar algebraic equations:\n$$(1) \\quad 1 - p_{12}^2 = 0$$\n$$(2) \\quad p_{11} - p_{12}p_{22} = 0$$\n$$(3) \\quad 1 + 2p_{12} - p_{22}^2 = 0$$\nFrom equation $(1)$, we find $p_{12} = \\pm 1$. We must find the solution for $P$ that is positive definite ($P0$), as this corresponds to the stabilizing solution.\nCase 1: $p_{12} = 1$.\nSubstituting into equation $(3)$: $1 + 2(1) - p_{22}^2 = 0 \\implies 3 - p_{22}^2 = 0 \\implies p_{22} = \\pm\\sqrt{3}$. For $P$ to be positive definite, its diagonal elements must be positive, so we require $p_{22}  0$. Thus, $p_{22} = \\sqrt{3}$.\nSubstituting $p_{12}=1$ and $p_{22}=\\sqrt{3}$ into equation $(2)$: $p_{11} - (1)(\\sqrt{3}) = 0 \\implies p_{11} = \\sqrt{3}$.\nThe resulting matrix is $P = \\begin{bmatrix} \\sqrt{3}  1 \\\\ 1  \\sqrt{3} \\end{bmatrix}$. We check for positive definiteness using Sylvester's criterion:\nThe first leading principal minor is $p_{11} = \\sqrt{3}  0$.\nThe second leading principal minor is $\\det(P) = (\\sqrt{3})(\\sqrt{3}) - (1)^2 = 3-1 = 2  0$.\nSince all leading principal minors are positive, $P$ is positive definite. This is the correct stabilizing solution.\n\nCase 2: $p_{12} = -1$.\nSubstituting into equation $(3)$: $1 + 2(-1) - p_{22}^2 = 0 \\implies -1 - p_{22}^2 = 0 \\implies p_{22}^2 = -1$. This equation has no real solution for $p_{22}$. This case is discarded.\n\nThe unique symmetric positive definite solution is $P = \\begin{bmatrix} \\sqrt{3}  1 \\\\ 1  \\sqrt{3} \\end{bmatrix}$.\n\nNow, we compute the optimal state-feedback gain $K$:\n$$\nK = R^{-1}B^{\\top}P = (1)\\begin{bmatrix}01\\end{bmatrix}\\begin{bmatrix}\\sqrt{3}1\\\\1\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}1\\sqrt{3}\\end{bmatrix}\n$$\nFinally, we verify that the closed-loop system is stable. The closed-loop state matrix is $A_{cl} = A - BK$:\n$$\nA_{cl} = \\begin{bmatrix}01\\\\00\\end{bmatrix} - \\begin{bmatrix}0\\\\1\\end{bmatrix}\\begin{bmatrix}1\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}01\\\\00\\end{bmatrix} - \\begin{bmatrix}00\\\\1\\sqrt{3}\\end{bmatrix} = \\begin{bmatrix}01\\\\-1-\\sqrt{3}\\end{bmatrix}\n$$\nA system is stable if its state matrix is Hurwitz, i.e., all its eigenvalues have negative real parts. We find the eigenvalues by solving the characteristic equation $\\det(A_{cl} - \\lambda I) = 0$:\n$$\n\\det\\left(\\begin{bmatrix}-\\lambda1\\\\-1-\\sqrt{3}-\\lambda\\end{bmatrix}\\right) = (-\\lambda)(-\\sqrt{3}-\\lambda) - (1)(-1) = \\lambda^2 + \\sqrt{3}\\lambda + 1 = 0\n$$\nFor a second-order characteristic polynomial $\\lambda^2 + a_1\\lambda + a_0 = 0$, the Routh-Hurwitz stability criterion states that the system is stable if and only if $a_1  0$ and $a_0  0$. Here, $a_1 = \\sqrt{3}  0$ and $a_0 = 1  0$. The criterion is satisfied, confirming the matrix is Hurwitz. The eigenvalues are $\\lambda = \\frac{-\\sqrt{3} \\pm \\sqrt{3-4}}{2} = -\\frac{\\sqrt{3}}{2} \\pm \\frac{i}{2}$, which have negative real parts. The computed gain $K$ is indeed the stabilizing optimal gain.", "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n1  \\sqrt{3}\n\\end{bmatrix}\n}\n$$", "id": "2699194"}, {"introduction": "The previous exercises focused on *how* to solve the ARE, assuming a solution exists. This final practice [@problem_id:2699182] addresses the more fundamental question of *when* a stabilizing optimal controller can be found. You will use the core concepts of stabilizability and detectability to determine the existence of a solution without needing to solve the ARE itself, highlighting the deep connection between system structure and optimal control.", "problem": "Consider a linear time-invariant system of state dimension $2$ given by $\\dot{x}(t)=A x(t)+B u(t)$ with $A=\\mathrm{diag}(1,-1)$ and $B=\\begin{bmatrix}1\\\\1\\end{bmatrix}$. Consider the infinite-horizon Linear Quadratic Regulator (LQR) problem with cost $J(x_{0},u)=\\int_{0}^{\\infty}\\big(x(t)^{\\top} Q x(t)+u(t)^{\\top} R u(t)\\big)\\,dt$, where $Q=I_{2}$ and $R=1$. Without writing or assuming any specific Riccati formula, and starting from the Hamilton-Jacobi-Bellman optimality principle and the definitions of stabilizability and detectability, decide whether a stabilizing solution to the continuous-time Algebraic Riccati Equation (ARE) can exist for this data. In your reasoning, use a factor $Q=C^{\\top} C$ with a concrete choice of $C$ consistent with $Q$. Select the correct statement.\n\nA. No stabilizing ARE solution exists because the pair $(A,B)$ is not stabilizable; there is an uncontrollable unstable mode at eigenvalue $+1$.\n\nB. No stabilizing ARE solution exists because the pair $(Q^{1/2},A)$ is not detectable; the unstable mode at eigenvalue $+1$ is unobservable in the state penalty.\n\nC. A stabilizing ARE solution exists and is unique because $(A,B)$ is stabilizable (in fact, controllable) and $(Q^{1/2},A)$ is detectable (in fact, observable with a suitable $C$).\n\nD. Stabilizing ARE solutions exist but are not unique; there are multiple positive semidefinite solutions producing different stabilizing feedbacks.\n\nE. Existence of a stabilizing ARE solution depends on the initial condition $x(0)$; for some $x(0)$ it exists and for others it does not.", "solution": "The problem concerns the infinite-horizon LQR problem for the linear time-invariant system $\\dot{x}(t) = Ax(t) + Bu(t)$ with the cost functional $J(u) = \\int_{0}^{\\infty} (x^\\top Q x + u^\\top R u) dt$. The existence of an optimal, stabilizing feedback control law is directly linked to the existence of a stabilizing solution to the ARE.\n\nWe begin, as instructed, from the Hamilton-Jacobi-Bellman (HJB) equation, which states that the optimal value function $V(x) = \\min_u \\int_0^\\infty (x^\\top Q x + u^\\top R u) dt$ must satisfy:\n$$\n\\min_{u(t)} \\left\\{ \\frac{d V(x)}{dt} + x^\\top Q x + u^\\top R u \\right\\} = 0\n$$\nFor an LTI system, the time derivative of the value function along system trajectories is:\n$$\n\\frac{d V(x)}{dt} = \\left(\\frac{\\partial V}{\\partial x}\\right)^\\top \\dot{x} = \\left(\\frac{\\partial V}{\\partial x}\\right)^\\top (Ax + Bu)\n$$\nThus, the HJB equation becomes:\n$$\n\\min_{u} \\left\\{ \\left(\\frac{\\partial V}{\\partial x}\\right)^\\top (Ax + Bu) + x^\\top Q x + u^\\top R u \\right\\} = 0\n$$\nFor the LQR problem, the value function is quadratic in form, $V(x) = x^\\top P x$, where $P$ is a symmetric, positive semidefinite matrix. The gradient is $\\frac{\\partial V}{\\partial x} = 2Px$. Substituting this into the HJB equation yields:\n$$\n\\min_{u} \\left\\{ (2Px)^\\top (Ax + Bu) + x^\\top Q x + u^\\top R u \\right\\} = 0\n$$\n$$\n\\min_{u} \\left\\{ x^\\top(A^\\top P + PA)x + 2x^\\top PBu + x^\\top Q x + u^\\top R u \\right\\} = 0\n$$\nThe expression inside the braces is quadratic in $u$. Since $R=1 > 0$, it is a convex function of $u$. The minimum is found by setting the gradient with respect to $u$ to zero:\n$$\n\\frac{\\partial}{\\partial u} \\left( \\dots \\right) = 2(PBx)^\\top + 2Ru = 2B^\\top Px + 2Ru = 0\n$$\nThis gives the optimal control law in feedback form: $u^*(x) = -R^{-1}B^\\top Px$.\n\nSubstituting $u^*$ back into the HJB equation:\n$$\nx^\\top(A^\\top P + PA)x + 2x^\\top PB(-R^{-1}B^\\top Px) + x^\\top Q x + (-R^{-1}B^\\top Px)^\\top R (-R^{-1}B^\\top Px) = 0\n$$\n$$\nx^\\top(A^\\top P + PA)x - 2x^\\top PBR^{-1}B^\\top Px + x^\\top Q x + x^\\top PBR^{-1}B^\\top Px = 0\n$$\n$$\nx^\\top(A^\\top P + PA - PBR^{-1}B^\\top P + Q)x = 0\n$$\nAs this must hold for all $x(t)$, the matrix expression must be zero. This gives the continuous-time Algebraic Riccati Equation (ARE):\n$$\nA^\\top P + PA - PBR^{-1}B^\\top P + Q = 0\n$$\nA \"stabilizing solution\" is a symmetric positive semidefinite matrix $P$ that satisfies the ARE and for which the closed-loop system matrix, $A_{cl} = A - BR^{-1}B^\\top P$, is Hurwitz (all its eigenvalues have negative real parts).\n\nA fundamental theorem of optimal control states that a unique, positive semidefinite, stabilizing solution $P$ to the ARE exists if and only if:\n1.  The pair $(A, B)$ is stabilizable.\n2.  The pair $(C, A)$ is detectable, where $C$ is any matrix such that $Q = C^\\top C$. The problem notation suggests $C=Q^{1/2}$.\n\nWe must now verify these two conditions for the given data:\n$A = \\begin{bmatrix} 1  0 \\\\ 0  -1 \\end{bmatrix}$, $B = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$, $Q = I_2 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$, $R=1$.\n\n**1. Verification of Stabilizability of $(A, B)$**\n\nA pair $(A,B)$ is stabilizable if all unstable modes of $A$ are controllable. The eigenvalues of $A$ are $\\lambda_1 = 1$ (unstable) and $\\lambda_2 = -1$ (stable). We must check if the mode associated with $\\lambda_1 = 1$ is controllable.\nWe use the Popov-Belevitch-Hautus (PBH) test for controllability. The system is controllable if $\\mathrm{rank}[A - \\lambda I \\quad B] = n$ for all eigenvalues $\\lambda$. Stabilizability only requires this check for unstable eigenvalues, $\\mathrm{Re}(\\lambda) \\ge 0$.\nFor $\\lambda_1 = 1$:\n$$\n[A - 1 \\cdot I \\quad B] = \\begin{bmatrix} 1-1  0  1 \\\\ 0  -1-1  1 \\end{bmatrix} = \\begin{bmatrix} 0  0  1 \\\\ 0  -2  1 \\end{bmatrix}\n$$\nThe rank of this $2 \\times 3$ matrix is $2$, as the two rows are linearly independent. Since the rank is equal to the state dimension $n=2$, the unstable mode is controllable. Therefore, the pair $(A, B)$ is stabilizable.\nIn fact, we can check full controllability by examining the controllability matrix $\\mathcal{C} = [B \\quad AB]$:\n$AB = \\begin{bmatrix} 1  0 \\\\ 0  -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$.\n$\\mathcal{C} = \\begin{bmatrix} 1  1 \\\\ 1  -1 \\end{bmatrix}$.\n$\\det(\\mathcal{C}) = (1)(-1) - (1)(1) = -2 \\ne 0$. The rank is $2$, so the system is fully controllable. Controllability implies stabilizability.\n\n**2. Verification of Detectability of $(C, A)$**\n\nGiven $Q = I_2$, a valid choice for $C$ such that $Q=C^\\top C$ is $C=I_2$. The notation $(Q^{1/2}, A)$ in the options implies $C = Q^{1/2}$, and for $Q=I_2$, we have $C=Q^{1/2}=I_2$.\nA pair $(C, A)$ is detectable if all unstable modes of $A$ are observable. We again check the unstable eigenvalue $\\lambda_1 = 1$.\nUsing the PBH test for observability, the system is observable if $\\mathrm{rank}\\begin{bmatrix} A - \\lambda I \\\\ C \\end{bmatrix} = n$ for all eigenvalues $\\lambda$. Detectability only requires this for unstable modes.\nFor $\\lambda_1 = 1$:\n$$\n\\begin{bmatrix} A - 1 \\cdot I \\\\ C \\end{bmatrix} = \\begin{bmatrix} 1-1  0 \\\\ 0  -1-1 \\\\ 1  0 \\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix} 0  0 \\\\ 0  -2 \\\\ 1  0 \\\\ 0  1 \\end{bmatrix}\n$$\nThe rank of this $4 \\times 2$ matrix is $2$, as the last two rows (which constitute $C=I_2$) are linearly independent. Since the rank equals the state dimension $n=2$, the unstable mode is observable. Therefore, the pair $(C, A)$ is detectable.\nIn fact, the system is fully observable, as shown by the observability matrix $\\mathcal{O} = \\begin{bmatrix} C \\\\ CA \\end{bmatrix}$:\n$CA = I_2 A = A = \\begin{bmatrix} 1  0 \\\\ 0  -1 \\end{bmatrix}$.\n$\\mathcal{O} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\\\ 1  0 \\\\ 0  -1 \\end{bmatrix}$.\nThis matrix has column rank $2$. Thus, the pair $(C, A)$ is observable. Observability implies detectability.\n\n**Conclusion**\nSince $(A, B)$ is stabilizable (in fact, controllable) and $(C, A)$ with $C=Q^{1/2}=I_2$ is detectable (in fact, observable), the conditions for the existence of a unique, symmetric, positive semidefinite, stabilizing solution $P$ to the ARE are satisfied.\n\nLet us now evaluate the provided options.\n\n**A. No stabilizing ARE solution exists because the pair $(A,B)$ is not stabilizable; there is an uncontrollable unstable mode at eigenvalue $+1$.**\nThis statement is **Incorrect**. As demonstrated, the pair $(A,B)$ is fully controllable, and therefore stabilizable. The PBH test for the unstable eigenvalue $\\lambda = 1$ confirms the mode is controllable.\n\n**B. No stabilizing ARE solution exists because the pair $(Q^{1/2},A)$ is not detectable; the unstable mode at eigenvalue $+1$ is unobservable in the state penalty.**\nThis statement is **Incorrect**. With $Q=I_2$, we choose $C=Q^{1/2}=I_2$. The pair $(I_2,A)$ is fully observable, and therefore detectable. The PBH test for the unstable eigenvalue $\\lambda = 1$ confirms the mode is observable.\n\n**C. A stabilizing ARE solution exists and is unique because $(A,B)$ is stabilizable (in fact, controllable) and $(Q^{1/2},A)$ is detectable (in fact, observable with a suitable $C$).**\nThis statement is **Correct**. Our analysis has confirmed every assertion within this option. Both stabilizability of $(A,B)$ and detectability of $(Q^{1/2}, A)$ are satisfied. The conditions are not only satisfied but are met in their stronger forms (controllability and observability). This guarantees the existence and uniqueness of a stabilizing ARE solution.\n\n**D. Stabilizing ARE solutions exist but are not unique; there are multiple positive semidefinite solutions producing different stabilizing feedbacks.**\nThis statement is **Incorrect**. The combination of stabilizability and detectability guarantees a *unique* positive semidefinite stabilizing solution $P$.\n\n**E. Existence of a stabilizing ARE solution depends on the initial condition $x(0)$; for some $x(0)$ it exists and for others it does not.**\nThis statement is **Incorrect**. The ARE is an algebraic equation for the matrix $P$. Its solution, and thus the existence of a stabilizing feedback law, depends only on the system and cost matrices $(A, B, Q, R)$, not on the initial state $x(0)$. The resulting control law is optimal for any initial condition.", "answer": "$$\\boxed{C}$$", "id": "2699182"}]}