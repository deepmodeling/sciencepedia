{"hands_on_practices": [{"introduction": "The solution to the finite-horizon Linear Quadratic Regulator (LQR) problem is found through dynamic programming, working backward from a terminal cost. This process generates a sequence of matrices, $P_k$, that define the optimal cost-to-go at each time step. This exercise [@problem_id:2719945] provides a concrete, hands-on calculation of a single step in this backward recursion, allowing you to see exactly how the value function's curvature evolves as you move one step away from the final time.", "problem": "Consider a finite-horizon Linear Quadratic Regulator (LQR) problem for the discrete-time linear system given by $x_{k+1} = A x_{k} + B u_{k}$, where the state $x_{k} \\in \\mathbb{R}^{2}$ and the control $u_{k} \\in \\mathbb{R}$. The performance index over a horizon ending at time $N$ is\n$$\nJ = \\sum_{k=0}^{N-1} \\left( x_{k}^{\\top} Q x_{k} + u_{k}^{\\top} R u_{k} \\right) + x_{N}^{\\top} P_{f} x_{N}.\n$$\nAssume the matrices are\n$$\nA = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad Q = \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix}, \\quad R = 2, \\quad P_{f} = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}.\n$$\nUsing the principle of optimality and dynamic programming, and assuming the value function at time $k+1$ is quadratic of the form $V_{k+1}(x) = x^{\\top} P_{k+1} x$ with $P_{k+1} = P_{f}$, compute one exact backward step to obtain $P_{k}$. Then, report the exact value of the trace $\\operatorname{tr}(P_{k})$. In your reasoning, interpret qualitatively how $P_{k}$ evolves relative to $P_{k+1}$ in this step in terms of the curvature of the value function. Provide the final numerical answer for $\\operatorname{tr}(P_{k})$ in exact form (no rounding).", "solution": "The problem statement is analyzed and found to be valid. It is a well-posed, scientifically grounded problem in control theory, providing all necessary information for a unique solution.\n\nThe problem requires computing one backward step in the solution of a discrete-time, finite-horizon Linear Quadratic Regulator (LQR) problem. The solution is obtained by applying the principle of optimality using dynamic programming. The cost-to-go, or value function, at time $k$ is defined as the minimum cost from state $x_k$ to the final time $N$:\n$$\nV_k(x_k) = \\min_{u_k, \\dots, u_{N-1}} \\left( \\sum_{j=k}^{N-1} (x_j^\\top Q x_j + u_j^\\top R u_j) + x_N^\\top P_f x_N \\right)\n$$\nThe terminal condition is $V_N(x_N) = x_N^\\top P_f x_N$. The Bellman equation relates the value function at time $k$ to the value function at time $k+1$:\n$$\nV_k(x_k) = \\min_{u_k} \\left( x_k^\\top Q x_k + u_k^\\top R u_k + V_{k+1}(x_{k+1}) \\right)\n$$\nsubject to the system dynamics $x_{k+1} = A x_k + B u_k$.\n\nAssuming the value function at time $k+1$ is quadratic, $V_{k+1}(x) = x^\\top P_{k+1} x$, we substitute this into the Bellman equation:\n$$\nV_k(x_k) = \\min_{u_k} \\left( x_k^\\top Q x_k + u_k^\\top R u_k + (A x_k + B u_k)^\\top P_{k+1} (A x_k + B u_k) \\right)\n$$\nTo find the optimal control $u_k$, we minimize the expression in the parenthesis with respect to $u_k$. Let this expression be $L(u_k)$. We expand it and take the derivative with respect to $u_k$:\n$$\nL(u_k) = x_k^\\top Q x_k + u_k^\\top R u_k + x_k^\\top A^\\top P_{k+1} A x_k + 2 u_k^\\top B^\\top P_{k+1} A x_k + u_k^\\top B^\\top P_{k+1} B u_k\n$$\n$$\n\\frac{\\partial L(u_k)}{\\partial u_k} = 2 u_k^\\top R + 2 x_k^\\top A^\\top P_{k+1} B + 2 u_k^\\top B^\\top P_{k+1} B = 0\n$$\nSince $u_k$ is a scalar, we can write this more simply:\n$$\n2 R u_k + 2 B^\\top P_{k+1} A x_k + 2 (B^\\top P_{k+1} B) u_k = 0\n$$\nSolving for the optimal control $u_k^*$:\n$$\nu_k^* = - (R + B^\\top P_{k+1} B)^{-1} (B^\\top P_{k+1} A) x_k\n$$\nSubstituting $u_k^*$ back into the expression for $V_k(x_k)$ yields a quadratic form $V_k(x_k) = x_k^\\top P_k x_k$, where $P_k$ is given by the discrete-time Riccati equation:\n$$\nP_k = Q + A^\\top P_{k+1} A - A^\\top P_{k+1} B (R + B^\\top P_{k+1} B)^{-1} B^\\top P_{k+1} A\n$$\nThe problem requires computing $P_k$ for the step from $k+1=N$ to $k=N-1$. We are given $P_{k+1} = P_f$. Thus, we compute $P_{N-1}$ using $P_N=P_f$.\nThe given matrices are:\n$$\nA = \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad Q = \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix}, \\quad R = 2, \\quad P_{k+1} = P_f = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}\n$$\nFirst, we compute the necessary components of the Riccati equation.\nThe term $A^\\top P_{k+1} A$:\n$$\nA^\\top P_{k+1} A = \\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix} \\begin{pmatrix} 3  3 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 3  3 \\\\ 3  4 \\end{pmatrix}\n$$\nThe scalar term $(R + B^\\top P_{k+1} B)$:\n$$\nB^\\top P_{k+1} B = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = 1\n$$\n$$\nR + B^\\top P_{k+1} B = 2 + 1 = 3\n$$\nThe inverse is $(R + B^\\top P_{k+1} B)^{-1} = \\frac{1}{3}$.\nThe term $B^\\top P_{k+1} A$:\n$$\nB^\\top P_{k+1} A = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 3  3 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 0  1 \\end{pmatrix}\n$$\nThe term $A^\\top P_{k+1} B$ is the transpose of the above: $(B^\\top P_{k+1} A)^\\top = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$.\nNow, we compute the full correction term:\n$$\nA^\\top P_{k+1} B (R + B^\\top P_{k+1} B)^{-1} B^\\top P_{k+1} A = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\left(\\frac{1}{3}\\right) \\begin{pmatrix} 0  1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix}\n$$\nFinally, we assemble $P_k$:\n$$\nP_k = Q + A^\\top P_{k+1} A - (\\text{correction term})\n$$\n$$\nP_k = \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix} + \\begin{pmatrix} 3  3 \\\\ 3  4 \\end{pmatrix} - \\begin{pmatrix} 0  0 \\\\ 0  \\frac{1}{3} \\end{pmatrix}\n$$\n$$\nP_k = \\begin{pmatrix} 1+3-0  0+3-0 \\\\ 0+3-0  2+4-\\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 4  3 \\\\ 3  6 - \\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 4  3 \\\\ 3  \\frac{17}{3} \\end{pmatrix}\n$$\nQualitatively, the matrix $P_k$ is the Hessian of the value function $V_k(x) = x^\\top P_k x$, representing its curvature. The backward recursion step updates this curvature from time $k+1$ to $k$. The term $A^\\top P_{k+1} A$ propagates the future cost from state $x_{k+1}$ back to state $x_k$ via the system dynamics, and the term $Q$ adds the immediate stage cost. Together, $Q + A^\\top P_{k+1} A$ represents the cost-to-go without control, which increases the overall curvature. The second term, $-A^\\top P_{k+1} B (R + B^\\top P_{k+1} B)^{-1} B^\\top P_{k+1} A$, represents the maximum cost reduction achievable by applying the optimal control $u_k^*$. It is a negative semidefinite matrix that \"flattens\" the value function.\nComparing $P_{k+1} = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}$ with $P_k = \\begin{pmatrix} 4  3 \\\\ 3  \\frac{17}{3} \\end{pmatrix}$, we observe that all diagonal elements have increased (from $3$ to $4$ and from $1$ to $\\approx 5.67$), indicating a steeper cost function. The appearance of non-zero off-diagonal terms in $P_k$ shows that the dynamics have introduced coupling between the states in the cost function. The overall increase of the trace from $\\operatorname{tr}(P_{k+1})=4$ to $\\operatorname{tr}(P_k)=\\frac{29}{3} \\approx 9.67$ confirms that the total curvature of the value function has significantly increased. This reflects that the cost associated with a deviation from the origin is greater one time step earlier, as there is one more step for the state to evolve and accumulate cost.\n\nThe trace of $P_k$ is:\n$$\n\\operatorname{tr}(P_k) = 4 + \\frac{17}{3} = \\frac{12}{3} + \\frac{17}{3} = \\frac{29}{3}\n$$", "answer": "$$\\boxed{\\frac{29}{3}}$$", "id": "2719945"}, {"introduction": "While finite-horizon control is important, many applications require a controller that is optimal over an infinitely long period, leading to a constant, or steady-state, feedback gain. This requires solving the Discrete Algebraic Riccati Equation (DARE) for a single matrix $P$ that represents the infinite-horizon cost. In this practice [@problem_id:2719578], you will solve the DARE for a canonical system, derive the optimal steady-state gain $K$, and verify the stability of the resulting closed-loop system, a fundamental workflow in LQR controller design.", "problem": "Consider the discrete-time linear time-invariant system with state update $x_{k+1} = A x_{k} + B u_{k}$ and infinite-horizon quadratic cost $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\mathsf{T}} Q x_{k} + u_{k}^{\\mathsf{T}} R u_{k} \\right)$, where\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2},\\quad\nR = 1.\n$$\nStarting from the principle of optimality for the dynamic programming formulation of the infinite-horizon discrete-time Linear Quadratic Regulator (LQR) problem, let the stationary value function be quadratic $V(x) = x^{\\mathsf{T}} P x$ with $P = P^{\\mathsf{T}} \\succeq 0$. Derive the matrix relation that $P$ must satisfy and solve analytically for the optimal state-feedback gain $K$ such that the optimal control is $u_{k} = - K x_{k}$. Then verify that the closed-loop matrix $A - B K$ is Schur stable by characterizing its eigenvalues. Finally, briefly explain how the same $K$ would be used with a state estimate in a Linear Quadratic Gaussian (LQG) controller by the certainty equivalence principle. Express your final answer as the exact row vector $K$ using radicals; do not approximate or round.", "solution": "The problem requires the derivation and solution of a discrete-time infinite-horizon Linear Quadratic Regulator (LQR) problem, followed by a stability analysis and a conceptual explanation of its connection to Linear Quadratic Gaussian (LQG) control.\n\n**Step 1: Problem Validation**\n\nThe problem statement provides the following givens: a discrete-time linear time-invariant system and a cost function.\n- State update equation: $x_{k+1} = A x_{k} + B u_{k}$\n- Infinite-horizon quadratic cost: $J = \\sum_{k=0}^{\\infty} \\left( x_{k}^{\\mathsf{T}} Q x_{k} + u_{k}^{\\mathsf{T}} R u_{k} \\right)$\n- System matrices:\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix},\\quad\nQ = I_{2} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix},\\quad\nR = 1\n$$\n- The value function is assumed to be of the form $V(x) = x^{\\mathsf{T}} P x$ where $P = P^{\\mathsf{T}} \\succeq 0$.\n- The optimal control law is of the form $u_k = -K x_k$.\n\nThe problem is scientifically grounded in control theory, well-posed, and stated objectively. The controllability matrix for the pair $(A, B)$ is $\\mathcal{C} = \\begin{bmatrix} B  AB \\end{bmatrix} = \\begin{bmatrix} 0  1 \\\\ 1  1 \\end{bmatrix}$, which has a determinant of $-1$ and is thus full rank. This means the system is controllable, which is a sufficient condition for stabilizability. The pair $(A, \\sqrt{Q}) = (A, I)$ is observable, as the observability matrix $\\mathcal{O} = \\begin{bmatrix} I \\\\ A^{\\mathsf{T}} \\end{bmatrix}$ has full column rank. Since $Q \\succeq 0$ and $R > 0$, and the system is stabilizable and detectable, a unique, positive semidefinite, stabilizing solution $P$ to the associated algebraic Riccati equation exists. The problem is valid.\n\n**Step 2: Derivation of the Discrete Algebraic Riccati Equation (DARE)**\n\nThe principle of optimality leads to the Bellman equation for the infinite-horizon value function $V(x)$:\n$$ V(x) = \\min_{u} \\left\\{ x^{\\mathsf{T}} Q x + u^{\\mathsf{T}} R u + V(Ax + Bu) \\right\\} $$\nSubstituting the quadratic value function $V(x) = x^{\\mathsf{T}} P x$:\n$$ x^{\\mathsf{T}} P x = \\min_{u} \\left\\{ x^{\\mathsf{T}} Q x + u^{\\mathsf{T}} R u + (Ax + Bu)^{\\mathsf{T}} P (Ax + Bu) \\right\\} $$\nTo find the optimal control $u$, we minimize the term in the braces. We take its derivative with respect to $u$ and set it to zero.\n$$ \\frac{\\partial}{\\partial u} \\left( u^{\\mathsf{T}} R u + 2u^{\\mathsf{T}}B^{\\mathsf{T}}PAx + u^{\\mathsf{T}}B^{\\mathsf{T}}PBu \\right) = 2Ru + 2B^{\\mathsf{T}}PAx = 0 $$\nSolving for the optimal control $u_k^*$ at time step $k$:\n$$ u_{k}^* = -(R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A x_{k} $$\nThis gives the optimal state-feedback gain matrix $K = (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A$. Substituting $u_k^* = -K x_k$ back into the Bellman equation yields:\n$$ x^{\\mathsf{T}} P x = x^{\\mathsf{T}} Q x + (-Kx)^{\\mathsf{T}} R (-Kx) + (A-BK)x^{\\mathsf{T}} P (A-BK)x $$\nSince this must hold for all $x$, we obtain the relation $P = Q + K^{\\mathsf{T}} R K + (A-BK)^{\\mathsf{T}} P (A-BK)$. A more direct form, the Discrete Algebraic Riccati Equation (DARE), is obtained by substituting $u^*$ back into the minimized expression:\n$$ P = Q + A^{\\mathsf{T}} P A - A^{\\mathsf{T}} P B (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A $$\n\n**Step 3: Solving the DARE for P**\n\nLet $P = \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix}$ be the symmetric positive semidefinite solution. We calculate the terms in the DARE:\n- $A^{\\mathsf{T}} P A = \\begin{bmatrix} 1  0 \\\\ 1  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix} p_{11}  p_{11}+p_{12} \\\\ p_{11}+p_{12}  p_{11}+2p_{12}+p_{22} \\end{bmatrix}$\n- $B^{\\mathsf{T}} P B = \\begin{bmatrix} 0  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = p_{22}$\n- $A^{\\mathsf{T}} P B = \\begin{bmatrix} 1  0 \\\\ 1  1 \\end{bmatrix} \\begin{bmatrix} p_{11}  p_{12} \\\\ p_{12}  p_{22} \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} p_{12} \\\\ p_{12}+p_{22} \\end{bmatrix}$\n- The correction term is $\\frac{1}{1+p_{22}} (A^{\\mathsf{T}} P B)(B^{\\mathsf{T}} P A) = \\frac{1}{1+p_{22}} \\begin{bmatrix} p_{12}^2  p_{12}(p_{12}+p_{22}) \\\\ p_{12}(p_{12}+p_{22})  (p_{12}+p_{22})^2 \\end{bmatrix}$\n\nSubstituting these into the DARE $P = Q + A^{\\mathsf{T}}PA - (\\text{correction term})$ gives a system of three nonlinear equations:\n1. ($1,1$)-entry: $p_{11} = 1 + p_{11} - \\frac{p_{12}^2}{1+p_{22}} \\implies p_{12}^2 = 1+p_{22}$.\n2. ($1,2$)-entry: $p_{12} = 0 + p_{11}+p_{12} - \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}} \\implies p_{11} = \\frac{p_{12}(p_{12}+p_{22})}{1+p_{22}}$.\n3. ($2,2$)-entry: $p_{22} = 1 + p_{11}+2p_{12}+p_{22} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}} \\implies 0 = 1+p_{11}+2p_{12} - \\frac{(p_{12}+p_{22})^2}{1+p_{22}}$.\n\nUsing $p_{12}^2 = 1+p_{22}$ from (1), we simplify (2): $p_{11} = \\frac{p_{12}(p_{12} + p_{12}^2-1)}{p_{12}^2} = 1+p_{12}-\\frac{1}{p_{12}}$. For $P \\succeq 0$, we need $p_{22} \\ge 0$, so $p_{12}^2 \\ge 1$.\nSubstituting this into (3):\n$0 = 1 + (1+p_{12}-\\frac{1}{p_{12}}) + 2p_{12} - \\frac{(p_{12}+p_{12}^2-1)^2}{p_{12}^2} = 2+3p_{12}-\\frac{1}{p_{12}} - (p_{12}+1-\\frac{1}{p_{12}})^2$\nLet $z=p_{12}$. $0 = 2+3z-\\frac{1}{z} - (z^2-1+2z+1-2/z+1/z^2) = 3+z+\\frac{1}{z}-z^2-1/z^2$.\nMultiplying by $-z^2$ yields the quartic equation: $z^4 - z^3 - 3z^2 - z + 1 = 0$.\nThis is a reciprocal equation. Dividing by $z^2$: $(z^2+\\frac{1}{z^2}) - (z+\\frac{1}{z}) - 3 = 0$.\nLet $w = z+\\frac{1}{z}$. Then $w^2-2 = z^2+\\frac{1}{z^2}$. The equation becomes $(w^2-2) - w - 3 = 0 \\implies w^2-w-5=0$.\nThe solutions for $w$ are $w = \\frac{1 \\pm \\sqrt{1 - 4(1)(-5)}}{2} = \\frac{1 \\pm \\sqrt{21}}{2}$.\nFor a stabilizing solution, the closed-loop eigenvalues must be inside the unit disk. This corresponds to the positive definite solution $P$, which requires $p_{12}=z$ to be chosen appropriately. We need $p_{11} > 0$ and $p_{22} \\ge 0$.\nWe found $p_{11} = 1 + z - 1/z$. With $w=z+1/z$, $z-1/z = \\pm\\sqrt{w^2-4}$. So $p_{11} = 1 \\pm \\sqrt{w^2-4}$.\n$P$ must be positive definite. The condition $p_{22} = z^2-1 \\ge 0$ implies $|z| \\ge 1$. If $|z| \\ge 1$, then $|w| = |z+1/z| \\ge | |z|-|1/z| | \\ge 0$, but for real roots of $z^2-wz+1=0$ we need $|w| \\ge 2$.\n$w_1 = (1+\\sqrt{21})/2 \\approx 2.79 > 2$. $w_2 = (1-\\sqrt{21})/2 \\approx -1.79$, so $|w_2|2$.\nThis implies we must choose $w_1 = (1+\\sqrt{21})/2$, which yields real roots for $z$. The solution $z$ must satisfy $|z| \\ge 1$. The two roots for $z$ from $z+1/z=w_1$ are $z_a>1$ and $z_b=1/z_a1$. So we must choose $p_{12} = z_a > 1$, the larger root.\nFurthermore, $p_{11}=1+z-1/z = 1+(z+1/z)-2/z = 1+w-2/z > 1+2-2/1 > 0$. The condition on $p_{11}$ is satisfied.\n\n**Step 4: Computing the Optimal Gain K**\n\nThe optimal gain is $K = (R + B^{\\mathsf{T}} P B)^{-1} B^{\\mathsf{T}} P A = \\frac{1}{1+p_{22}} [p_{12}, p_{12}+p_{22}]$.\nUsing $1+p_{22} = p_{12}^2$, we have $K = \\frac{1}{p_{12}^2}[p_{12}, p_{12}+p_{12}^2-1] = [\\frac{1}{p_{12}}, 1+\\frac{1}{p_{12}}-\\frac{1}{p_{12}^2}]$.\nLet $k_1 = 1/p_{12}$ and $k_2 = 1+1/p_{12}-1/p_{12}^2 = 1+k_1-k_1^2$.\nSince $p_{12}$ is the larger root of $z^2 - w_1 z + 1 = 0$, $k_1=1/p_{12}$ is the smaller root.\n$k_1 = \\frac{w_1 - \\sqrt{w_1^2-4}}{2}$, where $w_1 = \\frac{1+\\sqrt{21}}{2}$.\n$w_1^2-4 = (\\frac{1+\\sqrt{21}}{2})^2 - 4 = \\frac{1+2\\sqrt{21}+21}{4}-4 = \\frac{22+2\\sqrt{21}-16}{4} = \\frac{6+2\\sqrt{21}}{4} = \\frac{3+\\sqrt{21}}{2}$.\nSo, $k_1 = \\frac{\\frac{1+\\sqrt{21}}{2} - \\sqrt{\\frac{3+\\sqrt{21}}{2}}}{2} = \\frac{1+\\sqrt{21} - \\sqrt{2(3+\\sqrt{21})}}{4} = \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4}$.\nNow we find $k_2 = 1+k_1-k_1^2$. From $k_1^2 - w_1 k_1 + 1 = 0$, we have $k_1^2 = w_1 k_1 - 1$.\n$k_2 = 1 + k_1 - (w_1 k_1 - 1) = 2 + (1 - w_1)k_1$.\n$1-w_1 = 1-\\frac{1+\\sqrt{21}}{2} = \\frac{1-\\sqrt{21}}{2}$.\n$k_2 = 2+\\frac{1-\\sqrt{21}}{2}k_1 = 2+\\frac{1-\\sqrt{21}}{2}\\left(\\frac{1+\\sqrt{21}-\\sqrt{6+2\\sqrt{21}}}{4}\\right) = 2+\\frac{1-21-(1-\\sqrt{21})\\sqrt{6+2\\sqrt{21}}}{8}$.\n$k_2 = 2 - \\frac{20}{8} - \\frac{1-\\sqrt{21}}{8}\\sqrt{6+2\\sqrt{21}} = -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}}$.\nSo, $K = \\begin{bmatrix} k_1  k_2 \\end{bmatrix}$.\n\n**Step 5: Stability Verification**\n\nThe closed-loop system matrix is $A_{cl} = A - BK = \\begin{bmatrix} 1  1 \\\\ 0  1 \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\begin{bmatrix} k_1  k_2 \\end{bmatrix} = \\begin{bmatrix} 1  1 \\\\ -k_1  1-k_2 \\end{bmatrix}$.\nThe characteristic polynomial is $\\det(\\lambda I - A_{cl}) = 0$:\n$\\det \\begin{bmatrix} \\lambda-1  -1 \\\\ k_1  \\lambda-(1-k_2) \\end{bmatrix} = (\\lambda-1)(\\lambda-1+k_2) + k_1 = 0$.\n$\\lambda^2 + (k_2 - 2)\\lambda + (1 - k_2 + k_1) = 0$.\nUsing the relations $k_2-2=(1-w_1)k_1$ and $1-k_2+k_1 = k_1^2$, the polynomial becomes:\n$\\lambda^2 + (1 - w_1)k_1 \\lambda + k_1^2 = 0$.\nThe roots are $\\lambda = \\frac{-(1-w_1)k_1 \\pm \\sqrt{(1-w_1)^2k_1^2 - 4k_1^2}}{2} = \\frac{k_1}{2} \\left( -(1-w_1) \\pm \\sqrt{(1-w_1)^2 - 4} \\right)$.\nThe term under the square root is $(1-w_1)^2-4 = (\\frac{1-\\sqrt{21}}{2})^2-4 = \\frac{1-2\\sqrt{21}+21}{4}-4 = \\frac{22-2\\sqrt{21}-16}{4} = \\frac{6-2\\sqrt{21}}{4} = \\frac{3-\\sqrt{21}}{2}  0$.\nThe roots are complex conjugates. The magnitude squared of the roots is:\n$|\\lambda|^2 = \\left( \\frac{k_1(w_1-1)}{2} \\right)^2 + \\left( \\frac{k_1\\sqrt{4-(w_1-1)^2}}{2} \\right)^2 = \\frac{k_1^2}{4} \\left( (w_1-1)^2 + 4-(w_1-1)^2 \\right) = k_1^2$.\nSo, $|\\lambda| = |k_1|$. Since $p_{12} > 1$, we have $0  k_1 = 1/p_{12}  1$. The eigenvalues of the closed-loop system are strictly inside the unit circle, confirming that $A-BK$ is Schur stable.\n\n**Step 6: Certainty Equivalence Principle**\n\nThe Linear Quadratic Gaussian (LQG) control problem extends the LQR framework to systems affected by Gaussian noise. For a system described by $x_{k+1} = Ax_k + Bu_k + w_k$ and $y_k = Cx_k + v_k$, where $w_k$ and $v_k$ are zero-mean Gaussian white noise processes, the goal is to minimize the expected value of the same quadratic cost functional.\nThe solution to the LQG problem famously separates into an optimal state estimation problem and an optimal control problem. This is known as the **separation principle**.\nFirst, a Kalman filter is designed to produce an optimal estimate of the state, $\\hat{x}_k$, based on the history of measurements.\nThen, the **certainty equivalence principle** states that the optimal control law is obtained by simply using this state estimate $\\hat{x}_k$ in place of the true (and unknown) state $x_k$ in the deterministic LQR control law.\nTherefore, the LQG controller would be $u_k = -K \\hat{x}_k$, using the very same gain matrix $K$ derived in this problem. The design of the controller $(K)$ and the observer (Kalman filter) are independent. This property is a cornerstone of modern control theory but holds specifically for linear systems with Gaussian noise and quadratic costs.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1+\\sqrt{21} - \\sqrt{6+2\\sqrt{21}}}{4}  -\\frac{1}{2} + \\frac{\\sqrt{21}-1}{8}\\sqrt{6+2\\sqrt{21}} \\end{pmatrix}}\n$$", "id": "2719578"}, {"introduction": "A theoretical solution is only complete once it is verified in practice. This final exercise [@problem_id:2701019] moves from pure calculation to simulation, the ultimate test of a control design's effectiveness. You will implement the full LQR design process for several systems, and then simulate their closed-loop behavior to confirm that the optimal controller indeed stabilizes the system and causes the state to decay to zero, providing tangible proof of the theoretical guarantees of stability and optimality.", "problem": "Consider the discrete-time Linear Time-Invariant (LTI) system with state update $x_{k+1} = A x_k + B u_k$ and the infinite-horizon quadratic performance index $J = \\sum_{k=0}^{\\infty} \\left( x_k^{\\top} Q x_k + 2 x_k^{\\top} N u_k + u_k^{\\top} R u_k \\right)$, where $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, $Q \\in \\mathbb{R}^{n \\times n}$ is positive semidefinite, $R \\in \\mathbb{R}^{m \\times m}$ is positive definite, and $N \\in \\mathbb{R}^{n \\times m}$. The Linear Quadratic Regulator (LQR) problem seeks a static state-feedback control law $u_k = -K x_k$ that minimizes $J$. The closed-loop matrix is $A_{\\text{cl}} = A - B K$. The optimal feedback gain $K$ is constructed from the symmetric solution $P \\succeq 0$ of the discrete-time Algebraic Riccati Equation (DARE). Your task is to design a simulation experiment that verifies decay properties of the state and a Lyapunov function under the optimal gain.\n\nYour program must, for each specified test case $(A,B,Q,R,N,x_0)$, do the following, starting from first principles and standard definitions of optimal control:\n- Compute the optimal state-feedback gain $K$ by solving the discrete-time Algebraic Riccati Equation (DARE) associated with the given $(A,B,Q,R,N)$.\n- Form the closed-loop matrix $A_{\\text{cl}} = A - B K$ and evaluate its spectral radius (the maximum absolute value of its eigenvalues).\n- Simulate the closed-loop trajectory $x_{k+1} = A_{\\text{cl}} x_k$ for $k = 0,1,\\dots,T-1$ from the given initial condition $x_0$, with $T$ fixed and specified below.\n- Compute the Euclidean norms $\\lVert x_k \\rVert_2$ and the quadratic Lyapunov sequence $V_k = x_k^{\\top} P x_k$ along the trajectory.\n- For each test case, report:\n  1) A boolean indicating whether the spectral radius of $A_{\\text{cl}}$ is strictly less than $1$.\n  2) A boolean indicating whether the sequence $V_k$ is monotonically nonincreasing up to machine tolerance, that is, $V_{k+1} \\le V_k + \\varepsilon$ for all $k$ with a fixed $\\varepsilon$ specified below.\n  3) A float equal to the ratio $\\lVert x_T \\rVert_2 / \\lVert x_0 \\rVert_2$, rounded to six decimal places.\n\nUse the following fixed horizon and tolerance: $T = 200$ and $\\varepsilon = 10^{-10}$.\n\nTest suite. Implement exactly the following four test cases. Each case specifies $(A,B,Q,R,N,x_0)$.\n\nCase $1$ (baseline, single-input, strictly unstable-open-loop but stabilizable):\n$$\nA_1 = \\begin{bmatrix} 1.2  0.1 \\\\ 0.0  0.95 \\end{bmatrix},\\quad\nB_1 = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\quad\nQ_1 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix},\\quad\nR_1 = \\begin{bmatrix} 1.0 \\end{bmatrix},\\quad\nN_1 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix},\\quad\nx_{0,1} = \\begin{bmatrix} 3.0 \\\\ -1.0 \\end{bmatrix}.\n$$\n\nCase $2$ (near-boundary with a marginal open-loop mode, single-input):\n$$\nA_2 = \\begin{bmatrix} 1.0  0.2 \\\\ 0.0  0.9 \\end{bmatrix},\\quad\nB_2 = \\begin{bmatrix} 1.0 \\\\ 0.1 \\end{bmatrix},\\quad\nQ_2 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix},\\quad\nR_2 = \\begin{bmatrix} 0.1 \\end{bmatrix},\\quad\nN_2 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix},\\quad\nx_{0,2} = \\begin{bmatrix} 1.0 \\\\ 2.0 \\end{bmatrix}.\n$$\n\nCase $3$ (multi-input with nonzero cross-weight, strictly unstable-open-loop but fully actuated):\n$$\nA_3 = \\begin{bmatrix} 1.1  0.3 \\\\ 0.0  0.8 \\end{bmatrix},\\quad\nB_3 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix},\\quad\nQ_3 = \\begin{bmatrix} 2.0  0.5 \\\\ 0.5  1.0 \\end{bmatrix},\\quad\nR_3 = \\begin{bmatrix} 0.5  0.1 \\\\ 0.1  0.3 \\end{bmatrix},\\quad\nN_3 = \\begin{bmatrix} 0.1  -0.05 \\\\ 0.0  0.02 \\end{bmatrix},\\quad\nx_{0,3} = \\begin{bmatrix} 2.0 \\\\ -2.0 \\end{bmatrix}.\n$$\n\nCase $4$ (single-input with small control penalty $R$, two unstable modes but stabilizable):\n$$\nA_4 = \\begin{bmatrix} 1.05  0.5 \\\\ 0.0  1.02 \\end{bmatrix},\\quad\nB_4 = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix},\\quad\nQ_4 = \\begin{bmatrix} 1.0  0.0 \\\\ 0.0  1.0 \\end{bmatrix},\\quad\nR_4 = \\begin{bmatrix} 0.01 \\end{bmatrix},\\quad\nN_4 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix},\\quad\nx_{0,4} = \\begin{bmatrix} 1.0 \\\\ 1.0 \\end{bmatrix}.\n$$\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist of three elements $[b_1, b_2, r]$ with $b_1$ and $b_2$ booleans and $r$ the rounded float. For example, the output should look like:\n$[\\,[\\text{True},\\text{True},0.000001],[\\text{True},\\text{True},0.123456],\\dots\\,]$.\nNo additional text should be printed.", "solution": "The problem presented is a standard exercise in optimal control theory, specifically concerning the discrete-time Linear Quadratic Regulator (LQR). An evaluation of the problem statement confirms its validity. It is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The conditions for the existence of a unique, stabilizing solution to the discrete-time Algebraic Riccati Equation (DARE), namely stabilizability and detectability, are met for all provided test cases. I will therefore proceed with a rigorous solution based on established principles.\n\nThe dynamics of the system are described by the discrete-time, linear time-invariant (LTI) state equation:\n$$\nx_{k+1} = A x_k + B u_k\n$$\nwhere $x_k \\in \\mathbb{R}^n$ is the state vector and $u_k \\in \\mathbb{R}^m$ is the control input vector at time step $k$. The objective is to find a state-feedback control law $u_k = -K x_k$ that minimizes the infinite-horizon quadratic cost function:\n$$\nJ = \\sum_{k=0}^{\\infty} \\left( x_k^{\\top} Q x_k + 2 x_k^{\\top} N u_k + u_k^{\\top} R u_k \\right)\n$$\nHere, $Q \\succeq 0$ and $R \\succ 0$ are weighting matrices for the state and control input, respectively, and $N$ is a cross-weighting matrix. The term $2x_k^\\top N u_k$ complicates the standard LQR formulation. One can handle this by a change of variables. The term inside the summation can be written as a quadratic form:\n$$\n\\begin{bmatrix} x_k \\\\ u_k \\end{bmatrix}^{\\top}\n\\begin{bmatrix} Q  N \\\\ N^{\\top}  R \\end{bmatrix}\n\\begin{bmatrix} x_k \\\\ u_k \\end{bmatrix}\n$$\nFor the cost to be bounded below for any trajectory, this block matrix must be positive semidefinite. All test cases provided satisfy this condition.\n\nThe solution to this LQR problem is found via dynamic programming. The optimal cost-to-go, or value function, from state $x$ is given by $V(x) = x^{\\top} P x$, where $P$ is the unique symmetric positive semidefinite solution to the discrete-time Algebraic Riccati Equation (DARE):\n$$\nP = A^{\\top} P A - (A^{\\top} P B + N)(R + B^{\\top} P B)^{-1}(B^{\\top} P A + N^{\\top}) + Q\n$$\nThe existence of such a stabilizing solution $P$ is guaranteed if the pair $(A, B)$ is stabilizable and the pair $(Q_{eff}, A_{eff})$ is detectable, where $A_{eff}$ and $Q_{eff}$ are effective system matrices after a change of variables to eliminate the cross-term $N$. In the given cases, since the more straightforward conditions of stabilizability of $(A,B)$ and detectability corresponding to the cost function are met, a unique stabilizing solution exists and can be computed numerically.\n\nOnce the Riccati solution $P$ is found, the optimal state-feedback gain matrix $K$ is given by:\n$$\nK = (R + B^{\\top} P B)^{-1}(B^{\\top} P A + N^{\\top})\n$$\nThe control law is then $u_k = -K x_k$. This results in the closed-loop system:\n$$\nx_{k+1} = (A - B K) x_k = A_{\\text{cl}} x_k\n$$\nThe stability of this closed-loop system is determined by the eigenvalues of the matrix $A_{\\text{cl}}$. The system is asymptotically stable if and only if the spectral radius of $A_{\\text{cl}}$, denoted $\\rho(A_{\\text{cl}})$, is strictly less than $1$. The spectral radius is the maximum magnitude of the eigenvalues of $A_{\\text{cl}}$.\n\nFurthermore, the quadratic form $V_k = x_k^{\\top} P x_k$ serves as a discrete-time Lyapunov function for the closed-loop system. The change in this function along a system trajectory is given by the Bellman equation at optimality:\n$$\n\\Delta V_k = V_{k+1} - V_k = - (x_k^{\\top} Q x_k + 2 x_k^{\\top} N u_k + u_k^{\\top} R u_k)\n$$\nSubstituting $u_k = -Kx_k$:\n$$\n\\Delta V_k = -x_k^{\\top} (Q - N K - K^{\\top} N^{\\top} + K^{\\top} R K) x_k\n$$\nThe matrix $Q - N K - K^{\\top} N^{\\top} + K^{\\top} R K$ is the effective stage cost under the optimal policy, and it is guaranteed to be positive semidefinite. Thus, $\\Delta V_k \\le 0$, which implies that the sequence $V_k$ is monotonically nonincreasing. This property confirms the stability of the closed-loop system, as the state is driven towards the origin where $V(x)=0$.\n\nThe following procedure implements these principles to solve the problem for each test case:\n1.  Define the system matrices $(A, B)$ and cost matrices $(Q, R, N)$ for each case.\n2.  Numerically solve the DARE for the symmetric positive semidefinite matrix $P$ using a standard numerical library function, which can handle the cross-term $N$.\n3.  Compute the optimal feedback gain $K$ using its definition in terms of $P$.\n4.  Construct the closed-loop matrix $A_{\\text{cl}} = A - B K$.\n5.  Calculate the eigenvalues of $A_{\\text{cl}}$ and determine its spectral radius $\\rho(A_{\\text{cl}})$. The first required output is the boolean result of $\\rho(A_{\\text{cl}})  1$.\n6.  Simulate the closed-loop system for $T=200$ steps, starting from the given initial state $x_0$, to generate the state trajectory $x_0, x_1, \\dots, x_T$.\n7.  Compute the Lyapunov sequence $V_k = x_k^{\\top} P x_k$ for $k=0, \\dots, T$.\n8.  Verify that $V_{k+1} \\le V_k + \\varepsilon$ for all $k = 0, \\dots, T-1$ with the given tolerance $\\varepsilon=10^{-10}$. The second required output is the boolean result of this check.\n9.  Calculate the Euclidean norms $\\lVert x_T \\rVert_2$ and $\\lVert x_0 \\rVert_2$. The third required output is the ratio $\\lVert x_T \\rVert_2 / \\lVert x_0 \\rVert_2$, rounded to six decimal places.\n10. Collate and format the results as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_discrete_are\n\ndef solve():\n    \"\"\"\n    Solves the LQR problem for the given test cases and performs the required analysis.\n    \"\"\"\n    \n    # Simulation parameters\n    T = 200\n    epsilon = 1e-10\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[1.2, 0.1], [0.0, 0.95]]),\n            \"B\": np.array([[1.0], [0.5]]),\n            \"Q\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"R\": np.array([[1.0]]),\n            \"N\": np.array([[0.0], [0.0]]),\n            \"x0\": np.array([[3.0], [-1.0]]),\n        },\n        {\n            \"A\": np.array([[1.0, 0.2], [0.0, 0.9]]),\n            \"B\": np.array([[1.0], [0.1]]),\n            \"Q\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"R\": np.array([[0.1]]),\n            \"N\": np.array([[0.0], [0.0]]),\n            \"x0\": np.array([[1.0], [2.0]]),\n        },\n        {\n            \"A\": np.array([[1.1, 0.3], [0.0, 0.8]]),\n            \"B\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"Q\": np.array([[2.0, 0.5], [0.5, 1.0]]),\n            \"R\": np.array([[0.5, 0.1], [0.1, 0.3]]),\n            \"N\": np.array([[0.1, -0.05], [0.0, 0.02]]),\n            \"x0\": np.array([[2.0], [-2.0]]),\n        },\n        {\n            \"A\": np.array([[1.05, 0.5], [0.0, 1.02]]),\n            \"B\": np.array([[0.0], [1.0]]),\n            \"Q\": np.array([[1.0, 0.0], [0.0, 1.0]]),\n            \"R\": np.array([[0.01]]),\n            \"N\": np.array([[0.0], [0.0]]),\n            \"x0\": np.array([[1.0], [1.0]]),\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A, B, Q, R, N, x0 = case[\"A\"], case[\"B\"], case[\"Q\"], case[\"R\"], case[\"N\"], case[\"x0\"]\n\n        # 1. Solve the Discrete-time Algebraic Riccati Equation (DARE)\n        # SciPy's s parameter corresponds to the cross-term N\n        P = solve_discrete_are(A, B, Q, R, s=N)\n\n        # 2. Compute the optimal feedback gain K\n        K_inv_term = R + B.T @ P @ B\n        K_mult_term = B.T @ P @ A + N.T\n        K = np.linalg.inv(K_inv_term) @ K_mult_term\n\n        # 3. Form the closed-loop matrix A_cl and check its stability\n        A_cl = A - B @ K\n        eigenvalues = np.linalg.eigvals(A_cl)\n        spectral_radius = np.max(np.abs(eigenvalues))\n        is_stable = bool(spectral_radius  1.0)\n\n        # 4. Simulate the closed-loop trajectory and compute Lyapunov sequence\n        x_k = x0\n        V_seq = [x_k.T @ P @ x_k]\n        \n        x_traj = [x0]\n        for _ in range(T):\n            x_k = A_cl @ x_k\n            x_traj.append(x_k)\n            V_seq.append(x_k.T @ P @ x_k)\n        \n        # 5. Check if the Lyapunov sequence is monotonically nonincreasing\n        is_monotonic = True\n        # V_seq are 1x1 matrices, so use .item()\n        for k in range(T):\n            if V_seq[k+1].item()  V_seq[k].item() + epsilon:\n                is_monotonic = False\n                break\n        \n        # 6. Compute the ratio of final to initial state norms\n        norm_x0 = np.linalg.norm(x0)\n        norm_xT = np.linalg.norm(x_traj[T])\n        \n        if norm_x0 == 0:\n            ratio = 0.0\n        else:\n            ratio = norm_xT / norm_x0\n            \n        ratio_rounded = round(ratio, 6)\n\n        results.append([is_stable, is_monotonic, ratio_rounded])\n\n    # Final print statement in the exact required format.\n    # The default str() representation of a list includes spaces, which is acceptable.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2701019"}]}