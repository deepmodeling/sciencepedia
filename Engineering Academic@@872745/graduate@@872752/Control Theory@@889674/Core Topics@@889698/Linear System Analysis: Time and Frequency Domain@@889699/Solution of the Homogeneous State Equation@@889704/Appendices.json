{"hands_on_practices": [{"introduction": "Mastering the solution of homogeneous state equations begins with the foundational analytical technique for Linear Time-Invariant (LTI) systems. This practice focuses on using modal decomposition—finding the system's eigenvalues and eigenvectors—to construct the exact closed-form solution. By working through this exercise [@problem_id:1611524], you will solidify your understanding of how a system's internal structure, represented by the matrix $A$, dictates its natural dynamic behavior over time.", "problem": "A Linear Time-Invariant (LTI) system is described by the homogeneous state-space equation $\\dot{\\mathbf{x}}(t) = A\\mathbf{x}(t)$, where $\\mathbf{x}(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$ is the state vector. The system matrix $A$ is given by:\n$$\nA = \\begin{pmatrix} -2  1 \\\\ 2  -3 \\end{pmatrix}\n$$\nGiven the initial state of the system at $t=0$ is $\\mathbf{x}(0) = \\begin{pmatrix} 2 \\\\ 5 \\end{pmatrix}$, determine the state vector $\\mathbf{x}(t)$ for all $t \\ge 0$. Express your answer as a column vector whose components are functions of $t$.", "solution": "For the homogeneous LTI system $\\dot{\\mathbf{x}}(t)=A\\mathbf{x}(t)$ with constant matrix $A$, the state trajectory is $\\mathbf{x}(t)=\\exp(At)\\mathbf{x}(0)$. To compute $\\exp(At)$, we diagonalize $A$ via its eigenvalues and eigenvectors.\n\nCompute the characteristic polynomial:\n$$\n\\det(A-\\lambda I)=\\det\\begin{pmatrix}-2-\\lambda  1 \\\\ 2  -3-\\lambda\\end{pmatrix}=(\\lambda+2)(\\lambda+3)-2=\\lambda^{2}+5\\lambda+4.\n$$\nSolve $\\lambda^{2}+5\\lambda+4=0$ to obtain eigenvalues $\\lambda_{1}=-1$ and $\\lambda_{2}=-4$.\n\nFind corresponding eigenvectors. For $\\lambda_{1}=-1$, solve $(A+I)v=0$:\n$$\n\\begin{pmatrix}-1  1 \\\\ 2  -2\\end{pmatrix}\\begin{pmatrix}v_{1}\\\\v_{2}\\end{pmatrix}=0 \\implies v_{2}=v_{1},\n$$\nso choose $v_{1}=\\begin{pmatrix}1\\\\1\\end{pmatrix}$. For $\\lambda_{2}=-4$, solve $(A+4I)v=0$:\n$$\n\\begin{pmatrix}2  1 \\\\ 2  1\\end{pmatrix}\\begin{pmatrix}v_{1}\\\\v_{2}\\end{pmatrix}=0 \\implies v_{2}=-2v_{1},\n$$\nso choose $v_{2}=\\begin{pmatrix}1\\\\-2\\end{pmatrix}$.\n\nThe general solution is a linear combination along eigenvectors:\n$$\n\\mathbf{x}(t)=c_{1}\\exp(-t)\\begin{pmatrix}1\\\\1\\end{pmatrix}+c_{2}\\exp(-4t)\\begin{pmatrix}1\\\\-2\\end{pmatrix}.\n$$\nDetermine $c_{1},c_{2}$ from the initial condition $\\mathbf{x}(0)=\\begin{pmatrix}2\\\\5\\end{pmatrix}$:\n$$\n\\begin{pmatrix}2\\\\5\\end{pmatrix}=c_{1}\\begin{pmatrix}1\\\\1\\end{pmatrix}+c_{2}\\begin{pmatrix}1\\\\-2\\end{pmatrix}=\\begin{pmatrix}c_{1}+c_{2}\\\\c_{1}-2c_{2}\\end{pmatrix}.\n$$\nThis gives the linear system $c_{1}+c_{2}=2$ and $c_{1}-2c_{2}=5$. Subtracting yields $3c_{2}=-3$, so $c_{2}=-1$, and then $c_{1}=3$.\n\nTherefore,\n$$\n\\mathbf{x}(t)=3\\exp(-t)\\begin{pmatrix}1\\\\1\\end{pmatrix}-\\exp(-4t)\\begin{pmatrix}1\\\\-2\\end{pmatrix}=\\begin{pmatrix}3\\exp(-t)-\\exp(-4t)\\\\3\\exp(-t)+2\\exp(-4t)\\end{pmatrix}.\n$$\nThis satisfies both the differential equation and the initial condition.", "answer": "$$\\boxed{\\begin{pmatrix}3\\exp(-t)-\\exp(-4t)\\\\3\\exp(-t)+2\\exp(-4t)\\end{pmatrix}}$$", "id": "1611524"}, {"introduction": "While analytical solutions provide fundamental insight, most real-world control problems are solved numerically. This exercise [@problem_id:1611510] bridges the gap between continuous-time theory and discrete-time simulation by focusing on a critical practical issue: numerical stability. You will move beyond simply applying a numerical method and instead derive a stability condition, learning how properties of the system matrix $A$ constrain the choice of the simulation time step $\\Delta t$ to ensure a reliable result.", "problem": "A control systems engineer is analyzing the numerical stability of a simulation for a linear time-invariant (LTI) system described by the homogeneous state equation $\\frac{d\\mathbf{x}}{dt} = A\\mathbf{x}$, where $\\mathbf{x}(t)$ is the state vector in $\\mathbb{R}^n$ and $A$ is an $n \\times n$ constant matrix. The simulation uses the explicit (forward) Euler method to approximate the state at discrete time steps, given by $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\Delta t \\, A \\mathbf{x}_k$, where $\\Delta t$ is the time step.\n\nThe exact matrix $A$ is unknown, but through system identification experiments, it has been determined that $A$ satisfies the following properties:\n1.  All diagonal elements, $a_{ii}$, are real and negative.\n2.  The matrix is strictly diagonally dominant, meaning for each row $i$, the magnitude of the diagonal element is greater than the sum of the magnitudes of all other elements in that row: $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$. This property guarantees that the continuous-time system is stable.\n\nTwo key parameters quantifying the matrix properties have been measured:\n-   $S = \\max_{i} |a_{ii}|$, the maximum magnitude of any diagonal element.\n-   $d = \\max_{i} \\sum_{j \\neq i} |a_{ij}|$, the maximum row sum of the magnitudes of the off-diagonal elements.\n\nTo ensure the simulation does not diverge due to numerical instability, an appropriate time step $\\Delta t$ must be chosen. In terms of the parameters $S$ and $d$, derive an upper bound on $\\Delta t$ that guarantees the numerical stability of the explicit Euler simulation for *any* matrix $A$ that satisfies the given conditions. Express your answer as an analytic expression.", "solution": "The explicit Euler update for the LTI system is $\\mathbf{x}_{k+1} = (I + \\Delta t\\,A)\\mathbf{x}_{k}$. Numerical stability (no divergence) is guaranteed if and only if the spectral radius satisfies $\\rho(I + \\Delta t\\,A)  1$.\n\nA sufficient, computable condition uses Gershgorin’s theorem applied to $I + \\Delta t\\,A$. For row $i$, write $a_{ii} = -s_{i}$ with $s_{i} = |a_{ii}|  0$, and let $r_{i} = \\sum_{j \\neq i} |a_{ij}|$. Strict diagonal dominance gives $r_{i}  s_{i}$ for all $i$. Define $S = \\max_{i} s_{i}$ and $d = \\max_{i} r_{i}$. Then $d  S$ follows from $r_{i}  s_{i}$ taken over maxima.\n\nThe Gershgorin disk for row $i$ of $I + \\Delta t\\,A$ has center $c_{i} = 1 + \\Delta t\\,a_{ii} = 1 - \\Delta t\\,s_{i}$ and radius $R_{i} = \\Delta t\\,r_{i}$. If, for every $i$, the entire disk $B(c_{i}, R_{i})$ lies strictly inside the unit disk $\\{z: |z|  1\\}$, then all eigenvalues of $I + \\Delta t\\,A$ lie in $\\{z: |z|  1\\}$ and hence $\\rho(I + \\Delta t\\,A)  1$. The inclusion $B(c_{i}, R_{i}) \\subset \\{z: |z|  1\\}$ is ensured by\n$$\n|c_{i}| + R_{i} \\;=\\; |1 - \\Delta t\\,s_{i}| + \\Delta t\\,r_{i} \\;\\; 1 \\quad \\text{for all } i.\n$$\nWe now derive a single $\\Delta t$ bound (in terms of $S$ and $d$) that makes the above inequality hold for any admissible $(s_{i}, r_{i})$.\n\nConsider two cases for each row $i$:\n\n1) If $\\Delta t\\,s_{i} \\leq 1$, then $|1 - \\Delta t\\,s_{i}| = 1 - \\Delta t\\,s_{i}$ and\n$$\n|1 - \\Delta t\\,s_{i}| + \\Delta t\\,r_{i} = 1 - \\Delta t\\,(s_{i} - r_{i})  1,\n$$\nsince $s_{i} - r_{i} > 0$ by strict diagonal dominance. Thus rows with $\\Delta t\\,s_{i} \\leq 1$ impose no further restriction.\n\n2) If $\\Delta t\\,s_{i} \\geq 1$, then $|1 - \\Delta t\\,s_{i}| = \\Delta t\\,s_{i} - 1$, and using $s_{i} \\leq S$ and $r_{i} \\leq d$,\n$$\n|1 - \\Delta t\\,s_{i}| + \\Delta t\\,r_{i} \\;\\leq\\; \\Delta t\\,S - 1 + \\Delta t\\,d \\;=\\; \\Delta t\\,(S + d) - 1.\n$$\nA uniform sufficient condition is therefore\n$$\n\\Delta t\\,(S + d) - 1  1\n\\;\\;\\Longleftrightarrow\\;\\;\n\\Delta t  \\frac{2}{S + d}.\n$$\n\nBecause $d  S$, this bound is positive, and it guarantees $|1 - \\Delta t\\,s_{i}| + \\Delta t\\,r_{i}  1$ for all rows $i$ and for any matrix $A$ satisfying the stated properties. Consequently $\\rho(I + \\Delta t\\,A)  1$ and the explicit Euler simulation is numerically stable. Hence an upper bound that guarantees stability for any such $A$ is $\\frac{2}{S + d}$.", "answer": "$$\\boxed{\\frac{2}{S + d}}$$", "id": "1611510"}, {"introduction": "We now advance from time-invariant to periodic Linear Time-Varying (LTV) systems, a more complex and realistic class of models for which simple analytical solutions rarely exist. This advanced computational practice [@problem_id:2745820] guides you through implementing a numerical algorithm based on Floquet theory to analyze the stability and behavior of such systems. By computing the monodromy and generator matrices, you will gain hands-on experience with the essential tools used to characterize and control periodic dynamic processes.", "problem": "Consider the homogeneous state equation for a continuous-time Linear Time-Varying (LTV) system, defined by the Ordinary Differential Equation (ODE) $\\dot{\\mathbf{x}}(t)=A(t)\\,\\mathbf{x}(t)$ with a $2\\times 2$ matrix $A(t)$ that is $T$-periodic, meaning $A(t+T)=A(t)$ for all $t$. The state-transition matrix $\\Phi(t,t_{0})$ is the unique matrix function satisfying $\\frac{d}{dt}\\Phi(t,t_{0})=A(t)\\,\\Phi(t,t_{0})$ and $\\Phi(t_{0},t_{0})=I$, where $I$ is the identity matrix. The monodromy matrix over one period is $M=\\Phi(T,0)$, which encodes the net evolution over one period when starting from the identity. A constant generator matrix $R$ can be associated to $M$ via a matrix logarithm under the condition that $M$ has no eigenvalues on the nonpositive real axis, so that a principal matrix logarithm exists. Your program must compute $M$ numerically via time-ordered integration of the matrix ODE and then compute $R$ from $M$ using a principal matrix logarithm.\n\nAlgorithmic requirements:\n- Compute $\\Phi(t,0)$ by directly integrating the matrix ODE $\\dot{\\Phi}(t,0)=A(t)\\,\\Phi(t,0)$ with initial condition $\\Phi(0,0)=I$. This realizes the time-ordered exponential numerically by evolving forward in time.\n- Set $M=\\Phi(T,0)$ at the final time $T$.\n- Compute $R$ from $M$ as the principal matrix logarithm scaled by the period, that is, compute a matrix $R$ satisfying $\\exp(R\\,T)=M$ by applying a principal matrix logarithm to $M$ and scaling by $1/T$.\n\nAngle unit specification: whenever trigonometric functions appear, interpret their arguments in radians.\n\nTest suite:\nImplement the algorithm for the following four cases. For each case, compute the scalar error specified below. All numeric constants are dimensionless, and all angles are in radians.\n\n- Case $\\mathbf{1}$ (constant, commuting benchmark):\n  - Period: $T=3$.\n  - Matrix: $A(t)=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$ for all $t$.\n  - Expected generator: $R_{\\text{exp}}=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$.\n  - Required scalar output for this case: $e_{1}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{2}$ (diagonal periodic with zero mean, boundary where $M=I$):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\operatorname{diag}\\left(\\sin(t),-\\sin(t)\\right)$.\n  - Expected generator: $R_{\\text{exp}}=\\begin{bmatrix}0  0\\\\ 0  0\\end{bmatrix}$.\n  - Required scalar output: $e_{2}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{3}$ (diagonal periodic with nonzero mean, commuting but time-varying):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\operatorname{diag}\\left(-0.1+0.05\\sin(2t),\\,-0.3+0.02\\cos(3t)\\right)$.\n  - Expected generator: $R_{\\text{exp}}=\\operatorname{diag}\\left(-0.1,\\,-0.3\\right)$.\n  - Required scalar output: $e_{3}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n\n- Case $\\mathbf{4}$ (noncommuting periodic, reconstruction check):\n  - Period: $T=2\\pi$.\n  - Matrix: $A(t)=\\begin{bmatrix}0  1+0.2\\sin(2t)\\\\ -\\left(1.0+0.1\\cos(t)\\right)  0\\end{bmatrix}$.\n  - No closed-form expected generator is provided.\n  - Required scalar output: $e_{4}=\\left\\|\\exp(R\\,T)-M\\right\\|_{F}$, where $\\|\\cdot\\|_{F}$ denotes the Frobenius norm.\n\nFinal output format:\n- Your program must produce a single line of output containing the list $\\left[e_{1},e_{2},e_{3},e_{4}\\right]$ as a comma-separated Python-style list.\n- Each float must be printed in scientific notation with exactly six digits after the decimal point (for example, $1.234567\\text{e-}04$).\n- No other text should be printed.\n\nYour implementation must be entirely self-contained, must not require any user input, and must use time-ordered numerical integration of the matrix ODE for $\\Phi(t,0)$, followed by a principal matrix logarithm of $M$ to obtain $R$.", "solution": "The problem proposed is a well-defined exercise in computational control theory, specifically concerning the analysis of Linear Time-Varying (LTV) systems with periodic coefficients.\n\n### Step 1: Extract Givens\n- **System Equation**: Homogeneous state equation $\\dot{\\mathbf{x}}(t) = A(t)\\mathbf{x}(t)$.\n- **System Matrix**: $A(t)$ is a $2\\times 2$ matrix, periodic with period $T$, so $A(t+T) = A(t)$.\n- **State-Transition Matrix**: $\\Phi(t, t_0)$ is the unique solution to $\\frac{d}{dt}\\Phi(t,t_0) = A(t)\\Phi(t,t_0)$ with initial condition $\\Phi(t_0,t_0) = I$.\n- **Monodromy Matrix**: $M = \\Phi(T, 0)$.\n- **Generator Matrix**: $R$ is a constant matrix satisfying $\\exp(RT) = M$. It is computed via $R = \\frac{1}{T}\\log(M)$, using the principal matrix logarithm, which is assumed to exist.\n- **Algorithm**:\n    1. Numerically integrate $\\dot{\\Phi}(t,0) = A(t)\\Phi(t,0)$ with $\\Phi(0,0)=I$ from $t=0$ to $t=T$.\n    2. Set $M = \\Phi(T,0)$.\n    3. Compute $R = \\frac{1}{T}\\log(M)$.\n- **Test Cases**:\n    - **Case 1**: $T=3$, $A(t)=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$, $R_{\\text{exp}}=\\begin{bmatrix}-0.2  0\\\\ 0  -0.5\\end{bmatrix}$, error $e_{1}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n    - **Case 2**: $T=2\\pi$, $A(t)=\\operatorname{diag}\\left(\\sin(t),-\\sin(t)\\right)$, $R_{\\text{exp}}=\\begin{bmatrix}0  0\\\\ 0  0\\end{bmatrix}$, error $e_{2}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n    - **Case 3**: $T=2\\pi$, $A(t)=\\operatorname{diag}\\left(-0.1+0.05\\sin(2t),\\,-0.3+0.02\\cos(3t)\\right)$, $R_{\\text{exp}}=\\operatorname{diag}\\left(-0.1,\\,-0.3\\right)$, error $e_{3}=\\max_{i,j}\\left|R_{ij}-(R_{\\text{exp}})_{ij}\\right|$.\n    - **Case 4**: $T=2\\pi$, $A(t)=\\begin{bmatrix}0  1+0.2\\sin(2t)\\\\ -\\left(1.0+0.1\\cos(t)\\right)  0\\end{bmatrix}$, error $e_{4}=\\left\\|\\exp(R\\,T)-M\\right\\|_{F}$.\n- **Output Format**: A list $[e_1, e_2, e_3, e_4]$ with each number in scientific notation with six digits of precision.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in Floquet theory, a standard topic in the study of ordinary differential equations. It is well-posed, with all necessary data and definitions provided. The algorithmic requirements are clear and computationally feasible. The test cases cover both simple, analytically verifiable scenarios and a more complex, non-commuting case that necessitates the specified numerical approach. The problem contains no scientific inaccuracies, ambiguities, or contradictions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution based on numerical integration and matrix analysis will be provided.\n\n### Solution\nThe core of this problem lies in applying the principles of Floquet theory to a periodic LTV system. The system's dynamics are described by the equation $\\dot{\\mathbf{x}}(t) = A(t)\\mathbf{x}(t)$, where $A(t+T)=A(t)$. The evolution of the system is captured by the state-transition matrix $\\Phi(t,t_0)$, which must be found by solving the matrix differential equation:\n$$\n\\frac{d}{dt}\\Phi(t, 0) = A(t)\\Phi(t, 0), \\quad \\Phi(0, 0) = I\n$$\nwhere $I$ is the $2 \\times 2$ identity matrix. Formally, the solution involves a time-ordered exponential, $\\Phi(t, 0) = \\mathcal{T}\\exp\\left(\\int_0^t A(\\tau) d\\tau\\right)$. Except in special cases, this cannot be simplified to a standard matrix exponential. The numerical procedure specified—integrating the matrix ODE directly—is the standard method for computing this time-ordered product.\n\nFor a system with period $T$, the monodromy matrix $M=\\Phi(T,0)$ characterizes the system's evolution over a single period. Floquet's theorem guarantees that we can find a constant matrix $R$, known as the generator, such that $M = \\exp(RT)$. From this relationship, $R$ can be found by taking the matrix logarithm:\n$$\nR = \\frac{1}{T}\\log(M)\n$$\nThe problem demands the use of the principal matrix logarithm, which is unique under the condition that $M$ has no eigenvalues on the nonpositive real axis.\n\nThe numerical implementation proceeds as follows:\n1.  **ODE Integration**: The matrix ODE for $\\Phi(t,0)$ is a system of $2 \\times 2 = 4$ coupled linear first-order differential equations. To use a standard numerical solver like `scipy.integrate.solve_ivp`, the $2 \\times 2$ matrix $\\Phi$ is vectorized (flattened) into a $4 \\times 1$ state vector $y(t)$. The derivative function supplied to the solver calculates $A(t)$, reshapes $y(t)$ back to a matrix $\\Phi$, computes the product $A(t)\\Phi$, and returns the flattened result as the derivative vector $\\dot{y}(t)$. We integrate from $t=0$ to $t=T$ with the initial condition $y(0)$ corresponding to the flattened identity matrix.\n2.  **Monodromy Matrix**: The solver's output at $t=T$ gives the final state vector, which is reshaped to form the monodromy matrix $M = \\Phi(T, 0)$.\n3.  **Generator Matrix**: The generator $R$ is then calculated as $R = \\frac{1}{T}\\log(M)$ using a numerical library function for the principal matrix logarithm (`scipy.linalg.logm`).\n\nFor Cases $1$, $2$, and $3$, the matrix $A(t)$ has the property that $[A(t_1), A(t_2)]=0$ for all $t_1, t_2$. In Case $1$, this is because $A(t)$ is constant. In Cases $2$ and $3$, it is because $A(t)$ is diagonal for all $t$, and diagonal matrices commute. For such commuting systems, the time-ordered exponential simplifies to the standard matrix exponential of the integral:\n$$\n\\Phi(T, 0) = \\exp\\left(\\int_0^T A(\\tau) d\\tau\\right)\n$$\nThe generator $R$ then becomes the time-average of $A(t)$, i.e., $R = \\bar{A} = \\frac{1}{T}\\int_0^T A(\\tau) d\\tau$. This confirms the provided $R_{\\text{exp}}$ for these cases. For instance, in Case 2, $\\int_0^{2\\pi} \\sin(t) dt = 0$, so $\\bar{A}$ is the zero matrix.\n\nFor Case $4$, the matrix $A(t)$ is non-commuting. Simple evaluation shows $[A(t_1), A(t_2)] \\neq 0$. Thus, the full numerical integration of the matrix ODE is indispensable, and the generator $R$ is not simply the time-average of $A(t)$. The error metric $e_4 = \\|\\exp(RT) - M\\|_F$ acts as a verification of the numerical process, checking if the computed $R$ accurately reconstructs $M$. This error is expected to be close to machine precision.\n\nThe implementation will utilize a high-precision `RK45` integration scheme to minimize numerical error, allowing for accurate comparison with the expected results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.linalg import logm, expm\n\ndef solve():\n    \"\"\"\n    Computes the generator matrix R for four LTV systems and calculates\n    the specified error metrics.\n    \"\"\"\n\n    def compute_R_and_M(A_func, T):\n        \"\"\"\n        Computes the monodromy matrix M and the generator R for a given\n        system A(t) and period T.\n        \"\"\"\n        # Define the ODE system for the flattened state-transition matrix Phi.\n        # The state vector y has 4 elements, representing the 2x2 matrix Phi.\n        def ode_system(t, y):\n            Phi = y.reshape((2, 2))\n            A = A_func(t)\n            dPhi_dt = A @ Phi\n            return dPhi_dt.flatten()\n\n        # Initial condition Phi(0, 0) = I, flattened to a vector.\n        y0 = np.identity(2, dtype=float).flatten()\n        \n        # Numerically integrate the ODE from t=0 to t=T.\n        # We use a high-precision solver configuration to ensure accuracy.\n        # We only need the solution at the final time T.\n        sol = solve_ivp(\n            fun=ode_system,\n            t_span=[0, T],\n            y0=y0,\n            method='RK45',\n            t_eval=[T],\n            rtol=1e-13,\n            atol=1e-13\n        )\n        \n        # The monodromy matrix M is the state-transition matrix at t=T.\n        M = sol.y[:, -1].reshape((2, 2))\n        \n        # Compute the generator matrix R using the principal matrix logarithm.\n        R = logm(M) / T\n        \n        return R, M\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"case_id\": 1,\n            \"A_func\": lambda t: np.array([[-0.2, 0.0], [0.0, -0.5]]),\n            \"T\": 3.0,\n            \"R_exp\": np.array([[-0.2, 0.0], [0.0, -0.5]]),\n        },\n        {\n            \"case_id\": 2,\n            \"A_func\": lambda t: np.diag([np.sin(t), -np.sin(t)]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": np.zeros((2, 2)),\n        },\n        {\n            \"case_id\": 3,\n            \"A_func\": lambda t: np.diag([-0.1 + 0.05 * np.sin(2*t), -0.3 + 0.02 * np.cos(3*t)]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": np.diag([-0.1, -0.3]),\n        },\n        {\n            \"case_id\": 4,\n            \"A_func\": lambda t: np.array([[0.0, 1.0 + 0.2 * np.sin(2*t)], [-(1.0 + 0.1 * np.cos(t)), 0.0]]),\n            \"T\": 2 * np.pi,\n            \"R_exp\": None, # No analytical R_exp is provided\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        A_func = case[\"A_func\"]\n        T = case[\"T\"]\n        R_exp = case[\"R_exp\"]\n        \n        R, M = compute_R_and_M(A_func, T)\n        \n        if case[\"case_id\"] in [1, 2, 3]:\n            # For cases 1-3, the error is the maximum absolute difference\n            # between the computed R and the expected R_exp.\n            error = np.max(np.abs(R - R_exp))\n        else: # case_id == 4\n            # For case 4, the error is a self-consistency check: the Frobenius norm\n            # of the difference between the reconstructed M and the original M.\n            M_reconstructed = expm(R * T)\n            error = np.linalg.norm(M_reconstructed - M, 'fro')\n            \n        results.append(error)\n\n    # Final print statement in the exact required format.\n    # e.g., [1.234567e-08,_..._]\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```", "id": "2745820"}]}