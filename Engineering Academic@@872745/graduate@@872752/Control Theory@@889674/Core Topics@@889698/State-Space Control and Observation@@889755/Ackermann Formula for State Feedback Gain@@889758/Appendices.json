{"hands_on_practices": [{"introduction": "We begin by grounding our understanding of the Ackermann formula with a direct application. This first exercise [@problem_id:1599742] presents a straightforward, second-order system, allowing you to focus on the mechanics of the calculation. By working through this problem, you will practice checking for controllability and applying the formula to compute the required feedback gain for pole placement.", "problem": "A linear time-invariant system is described by the state-space model $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t) + b u(t)$, where $\\mathbf{x}(t)$ is the state vector and $u(t)$ is the scalar input. The system matrices are given by:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 4  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\nA state feedback controller with the control law $u(t) = -K \\mathbf{x}(t)$ is to be designed, where $K = \\begin{pmatrix} k_1  k_2 \\end{pmatrix}$ is the state feedback gain matrix. The objective is to place the poles of the closed-loop system at $s = -5$ and $s = -6$.\n\nThe gain matrix $K$ can be determined using Ackermann's formula, which for a single-input, $n$-th order system is given by:\n$$\nK = \\begin{pmatrix} 0  \\dots  0  1 \\end{pmatrix} C^{-1} \\phi(A)\n$$\nwhere $C$ is the system's controllability matrix and $\\phi(s)$ is the desired closed-loop characteristic polynomial.\n\nDetermine the state feedback gain matrix $K$. Express your answer as a row matrix.", "solution": "We are given the LTI system $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t) + b u(t)$ with $A = \\begin{pmatrix} 0  1 \\\\ 4  1 \\end{pmatrix}$ and $b = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, and the state feedback law $u(t) = -K \\mathbf{x}(t)$ with $K = \\begin{pmatrix} k_{1}  k_{2} \\end{pmatrix}$. Under state feedback, the closed-loop system matrix is $A_{\\text{cl}} = A - b K$. The pole placement objective is to assign the closed-loop eigenvalues to $s = -5$ and $s = -6$, so the desired characteristic polynomial is $\\phi(s) = (s + 5)(s + 6) = s^{2} + 11 s + 30$.\n\nFirst, verify controllability required by Ackermann's formula. The controllability matrix is\n$$\nC = \\begin{pmatrix} b  A b \\end{pmatrix} = \\begin{pmatrix} 0  1 \\\\ 1  1 \\end{pmatrix},\n$$\nwith determinant $|C| = -1 \\neq 0$, hence the system is controllable.\n\nUsing direct matching of the characteristic polynomial of $A_{\\text{cl}}$, compute $A_{\\text{cl}} = A - b K$:\n$$\nb K = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} k_{1}  k_{2} \\end{pmatrix} = \\begin{pmatrix} 0  0 \\\\ k_{1}  k_{2} \\end{pmatrix},\n$$\n$$\nA_{\\text{cl}} = \\begin{pmatrix} 0  1 \\\\ 4  1 \\end{pmatrix} - \\begin{pmatrix} 0  0 \\\\ k_{1}  k_{2} \\end{pmatrix} = \\begin{pmatrix} 0  1 \\\\ 4 - k_{1}  1 - k_{2} \\end{pmatrix}.\n$$\nThe characteristic polynomial of $A_{\\text{cl}}$ is\n$$\n\\det\\!\\left(s I - A_{\\text{cl}}\\right) = \\det\\!\\begin{pmatrix} s  -1 \\\\ k_{1} - 4  s - 1 + k_{2} \\end{pmatrix} = s\\left(s - 1 + k_{2}\\right) + \\left(k_{1} - 4\\right),\n$$\nwhich expands to\n$$\ns^{2} + (k_{2} - 1) s + (k_{1} - 4).\n$$\nMatching with the desired polynomial $s^{2} + 11 s + 30$ yields the equations\n$$\nk_{2} - 1 = 11, \\quad k_{1} - 4 = 30,\n$$\nhence\n$$\nk_{2} = 12, \\quad k_{1} = 34.\n$$\n\nEquivalently, applying Ackermann's formula $K = \\begin{pmatrix} 0  1 \\end{pmatrix} C^{-1} \\phi(A)$ provides a consistency check. Compute\n$$\nC^{-1} = \\frac{1}{-1} \\begin{pmatrix} 1  -1 \\\\ -1  0 \\end{pmatrix} = \\begin{pmatrix} -1  1 \\\\ 1  0 \\end{pmatrix},\n$$\n$$\nA^{2} = \\begin{pmatrix} 0  1 \\\\ 4  1 \\end{pmatrix}^{2} = \\begin{pmatrix} 4  1 \\\\ 4  5 \\end{pmatrix},\n$$\n$$\n\\phi(A) = A^{2} + 11 A + 30 I = \\begin{pmatrix} 4  1 \\\\ 4  5 \\end{pmatrix} + \\begin{pmatrix} 0  11 \\\\ 44  11 \\end{pmatrix} + \\begin{pmatrix} 30  0 \\\\ 0  30 \\end{pmatrix} = \\begin{pmatrix} 34  12 \\\\ 48  46 \\end{pmatrix}.\n$$\nThen\n$$\n\\begin{pmatrix} 0  1 \\end{pmatrix} C^{-1} = \\begin{pmatrix} 1  0 \\end{pmatrix}, \\quad K = \\begin{pmatrix} 1  0 \\end{pmatrix} \\phi(A) = \\begin{pmatrix} 34  12 \\end{pmatrix}.\n$$\n\nTherefore, the required state feedback gain matrix is the row matrix $\\begin{pmatrix} 34  12 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix}34  12\\end{pmatrix}}$$", "id": "1599742"}, {"introduction": "Moving from calculation to concept, this next practice [@problem_id:1556685] challenges you to think about the theoretical underpinnings of Ackermann's formula. By considering the special case where the desired poles match the open-loop poles, you will explore the deep connection between the formula and the Cayley-Hamilton theorem. This thought experiment builds crucial intuition about the role of feedback in modifying system dynamics.", "problem": "Consider a general $n$-th order, controllable, Linear Time-Invariant (LTI), Single-Input Single-Output (SISO) system described by the state-space representation $\\dot{x}(t) = Ax(t) + bu(t)$, where $x \\in \\mathbb{R}^{n}$ is the state vector, $u \\in \\mathbb{R}$ is the control input, $A$ is the $n \\times n$ state matrix, and $b$ is the $n \\times 1$ input matrix. The system's open-loop poles are the eigenvalues of the matrix $A$, which are the roots of the open-loop characteristic polynomial, $\\alpha(s) = \\det(sI-A)$.\n\nA state feedback control law of the form $u(t) = -Kx(t)$ is applied, where $K$ is a $1 \\times n$ row vector of feedback gains. The goal of this control law is to place the poles of the closed-loop system, given by the eigenvalues of the matrix $(A - bK)$, at desired locations. The desired pole locations are specified by the roots of a desired characteristic polynomial, $\\alpha_d(s)$.\n\nAckermann's formula provides a method for calculating the gain matrix $K$ that achieves the desired pole placement. The formula is given by:\n$$K = [0 \\ 0 \\ \\dots \\ 1] C^{-1} \\alpha_d(A)$$\nwhere $C$ is the $n \\times n$ controllability matrix of the pair $(A, b)$, and $\\alpha_d(A)$ is the matrix polynomial found by substituting the matrix $A$ for the scalar variable $s$ in the desired characteristic polynomial $\\alpha_d(s)$.\n\nSuppose that a control designer, for analytical purposes, decides to choose the desired closed-loop poles to be exactly the same as the system's original open-loop poles. What is the state feedback gain matrix $K$ that Ackermann's formula would compute for this specific scenario? Express your answer as a general matrix expression valid for any such $n$-th order system.", "solution": "We are given an $n$-th order controllable LTI SISO system $\\dot{x}(t) = Ax(t) + bu(t)$ and the state feedback law $u(t) = -Kx(t)$, with Ackermann’s formula\n$$\nK = \\begin{pmatrix}0  0  \\dots  1\\end{pmatrix} C^{-1} \\alpha_{d}(A),\n$$\nwhere $C$ is the controllability matrix of $(A,b)$ and $\\alpha_{d}(s)$ is the desired characteristic polynomial.\n\nLet the desired closed-loop polynomial be chosen equal to the open-loop characteristic polynomial:\n$$\n\\alpha_{d}(s) = \\alpha(s) = \\det(sI - A).\n$$\nBy the Cayley–Hamilton theorem, the matrix $A$ satisfies its own characteristic polynomial:\n$$\n\\alpha(A) = 0_{n \\times n}.\n$$\nTherefore, substituting $\\alpha_{d}(A) = \\alpha(A)$ into Ackermann’s formula yields\n$$\nK = \\begin{pmatrix}0  0  \\dots  1\\end{pmatrix} C^{-1} \\alpha(A) = \\begin{pmatrix}0  0  \\dots  1\\end{pmatrix} C^{-1} 0_{n \\times n} = 0_{1 \\times n}.\n$$\nHence, the gain returned by Ackermann’s formula in this scenario is the zero row vector, which leaves the closed-loop matrix $A - bK$ equal to $A$, placing the poles at the original open-loop locations as specified.", "answer": "$$\\boxed{0_{1 \\times n}}$$", "id": "1556685"}, {"introduction": "Finally, we transition to the realities of numerical computation, a critical consideration for any practicing engineer. This advanced problem [@problem_id:2689308] addresses the potential numerical instability of directly implementing Ackermann's formula, especially for high-order or ill-conditioned systems. You will develop a robust computational approach using modern numerical linear algebra techniques, a skill essential for reliable control system design.", "problem": "You are given a fully controllable, single-input linear time-invariant state-space model of order $n$ described by the pair $(A,b)$ with $A \\in \\mathbb{R}^{n \\times n}$ and $b \\in \\mathbb{R}^{n \\times 1}$. The objective is to place the closed-loop eigenvalues at a prescribed set of real locations by a static state-feedback law $u = -K x$, while computing the state feedback gain $K \\in \\mathbb{R}^{1 \\times n}$ via a numerically stable method that does not explicitly form any matrix inverse.\n\nStart from the following foundational definitions and facts:\n- The controllability matrix is $C = \\big[ b \\;\\; A b \\;\\; \\cdots \\;\\; A^{n-1} b \\big] \\in \\mathbb{R}^{n \\times n}$.\n- The desired real eigenvalues $\\{\\lambda_1,\\dots,\\lambda_n\\}$ define a monic polynomial $p_d(s) = \\prod_{i=1}^n (s - \\lambda_i) = s^n + a_{n-1} s^{n-1} + \\cdots + a_1 s + a_0$ with real coefficients $\\{a_0,\\dots,a_{n-1}\\}$.\n- For a matrix argument, the associated matrix polynomial is $p_d(A) = A^n + a_{n-1} A^{n-1} + \\cdots + a_1 A + a_0 I$, where $I$ is the identity matrix of size $n$.\n- The Cayley–Hamilton theorem states that every square matrix satisfies its own characteristic polynomial.\n- For a controllable system, there exists a static feedback gain $K$ that assigns the closed-loop eigenvalues to the desired set.\n\nYour task is to:\n- Derive, from these foundations and without invoking any pre-packaged formula, an expression for a computable state feedback gain that places the closed-loop eigenvalues at the desired locations using the controllability matrix $C$ and the matrix polynomial $p_d(A)$. Your derivation should show how to compute an intermediate quantity of the form $C^{-1} p_d(A)$, and how a canonical selector recovers a row vector gain from it. You must not form $C^{-1}$ explicitly.\n- Propose and implement a numerically stable computational procedure to evaluate $C^{-1} p_d(A)$ using either the orthogonal–triangular (QR) factorization or the Singular Value Decomposition (SVD) of $C$. Your implementation must:\n  - Evaluate $p_d(A)$ using a numerically stable matrix polynomial evaluation scheme (such as Horner’s method) to avoid explicitly forming large matrix powers.\n  - Solve the linear matrix equation $C X = p_d(A)$ for $X$ using either a QR-based triangular solve or an SVD-based pseudoinverse with a principled tolerance for small singular values, thereby computing $X = C^{-1} p_d(A)$ without explicitly inverting $C$.\n  - Extract a valid state feedback row vector from $X$ using an appropriate canonical selector.\n- Validate the result by constructing the closed-loop matrix $A_{cl} = A - b K$ and comparing the coefficients of its characteristic polynomial to those of $p_d(s)$. Use the maximum absolute difference between corresponding coefficients as a scalar error metric. Smaller values indicate better eigenvalue placement.\n\nImportant implementation constraints:\n- Do not use any direct matrix inverse. Use either QR factorization or Singular Value Decomposition to solve the linear system for $X$.\n- Use double-precision floating point arithmetic throughout.\n- Angles are not involved in this problem, hence no angle unit is required. No physical units appear in this problem.\n\nTest suite and required outputs:\nImplement your method for the following three test cases. In all cases, $A \\in \\mathbb{R}^{n \\times n}$ and $B \\in \\mathbb{R}^{n \\times 1}$.\n\n- Test case $1$ (happy path):\n  - Dimension $n = 3$.\n  - Use the controllable integrator chain $A = \\begin{bmatrix} 0  1  0 \\\\ 0  0  1 \\\\ 0  0  0 \\end{bmatrix}$ and $B = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Desired eigenvalues $\\{\\lambda_1,\\lambda_2,\\lambda_3\\} = \\{-1,-2,-3\\}$.\n- Test case $2$ (repeated desired eigenvalues):\n  - Dimension $n = 4$.\n  - Use the controllable integrator chain $A = \\begin{bmatrix} 0  1  0  0 \\\\ 0  0  1  0 \\\\ 0  0  0  1 \\\\ 0  0  0  0 \\end{bmatrix}$ and $B = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Desired eigenvalues $\\{\\lambda_1,\\lambda_2,\\lambda_3,\\lambda_4\\} = \\{-1,-1,-2,-2\\}$.\n- Test case $3$ (ill-conditioned controllability via a similarity transform):\n  - Dimension $n = 5$.\n  - Let $J \\in \\mathbb{R}^{5 \\times 5}$ denote the integrator chain $J = \\begin{bmatrix} 0  1  0  0  0 \\\\ 0  0  1  0  0 \\\\ 0  0  0  1  0 \\\\ 0  0  0  0  1 \\\\ 0  0  0  0  0 \\end{bmatrix}$ and $e_5 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$.\n  - Define a poorly scaled similarity transform $T = \\operatorname{diag}(1,10^2,10^4,10^6,10^8) \\in \\mathbb{R}^{5 \\times 5}$.\n  - Set $A = T J T^{-1}$ and $B = T e_5$.\n  - Desired eigenvalues $\\{\\lambda_1,\\lambda_2,\\lambda_3,\\lambda_4,\\lambda_5\\} = \\{-1,-2,-3,-4,-5\\}$.\n\nFor each test case, compute two versions of the feedback gain:\n- One using a QR-based solve for $C X = p_d(A)$.\n- One using an SVD-based solve (with a numerically justified cutoff for small singular values) for $C X = p_d(A)$.\n\nFor each computed gain $K$, form $A_{cl} = A - b K$ and compute the monic characteristic polynomial coefficients of $A_{cl}$, denoted $\\{1,\\hat{a}_{n-1},\\dots,\\hat{a}_0\\}$. Let the scalar error be $\\max_{k \\in \\{0,\\dots,n-1\\}} |a_k - \\hat{a}_k|$. Finally, report, for each test case, the triple of floats:\n- The error for the QR-based method.\n- The error for the SVD-based method.\n- The Euclidean norm of the difference between the two gains, $\\|K_{\\text{QR}} - K_{\\text{SVD}}\\|_2$.\n\nFinal output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist with its three floats in the order specified above. For example, an output for three test cases must look like $[[\\text{err\\_QR}_1,\\text{err\\_SVD}_1,\\text{dK}_1],[\\text{err\\_QR}_2,\\text{err\\_SVD}_2,\\text{dK}_2],[\\text{err\\_QR}_3,\\text{err\\_SVD}_3,\\text{dK}_3]]$ with no additional text.", "solution": "The problem presented is a standard, well-posed problem in linear control theory concerning eigenvalue assignment by state feedback, commonly known as pole placement. All provided information is scientifically sound, internally consistent, and sufficient for derivation and computation. The problem is therefore valid. We shall proceed with the derivation and solution.\n\nThe objective is to find a state feedback gain matrix $K \\in \\mathbb{R}^{1 \\times n}$ for the controllable single-input linear time-invariant system $\\dot{x} = Ax + bu$ such that the closed-loop system, under the control law $u = -Kx$, has its eigenvalues at a prescribed set of real locations $\\{\\lambda_1, \\dots, \\lambda_n\\}$. The closed-loop system is described by $\\dot{x} = (A - bK)x = A_{cl}x$.\n\nThe desired eigenvalues are the roots of the monic polynomial $p_d(s) = \\prod_{i=1}^n (s - \\lambda_i) = s^n + a_{n-1}s^{n-1} + \\dots + a_0$. For the eigenvalues of $A_{cl}$ to be $\\{\\lambda_1, \\dots, \\lambda_n\\}$, its characteristic polynomial, $\\det(sI-A_{cl})$, must be equal to $p_d(s)$. By the Cayley-Hamilton theorem, the matrix $A_{cl}$ must satisfy its own characteristic equation, which implies $p_d(A_{cl}) = 0$.\n\nThe derivation will proceed by postulating the form of the gain $K$, known as Ackermann's formula, and then proving that it achieves the desired eigenvalue placement. The formula is given by:\n$$ K = e_n^T C^{-1} p_d(A) $$\nwhere $e_n^T = [0, \\dots, 0, 1] \\in \\mathbb{R}^{1 \\times n}$ is a canonical row vector, $C$ is the system's controllability matrix, and $p_d(A)$ is the matrix polynomial associated with the desired characteristic polynomial.\n\nLet us define a row vector $q^T = e_n^T C^{-1}$. By definition, $q^T$ is the last row of the inverse of the controllability matrix $C = [b \\;\\; Ab \\;\\; \\dots \\;\\; A^{n-1}b]$. This implies that $q^T C = e_n^T$. Expanding this matrix equation yields a set of distinct properties for $q^T$:\n$$ q^T A^i b = 0 \\quad \\text{for } i = 0, 1, \\dots, n-2 $$\n$$ q^T A^{n-1} b = 1 $$\n\nWith $K = q^T p_d(A)$, we must now demonstrate that the eigenvalues of $A_{cl} = A - bK$ are the roots of $p_d(s)$. The eigenvalues $\\lambda$ of $A_{cl}$ are the solutions to $\\det(\\lambda I - A_{cl}) = 0$. Using the matrix determinant lemma, $\\det(M+uv^T) = \\det(M)(1+v^T M^{-1}u)$, we can write:\n$$ \\det(\\lambda I - A_{cl}) = \\det(\\lambda I - (A - bK)) = \\det((\\lambda I - A) + bK) $$\n$$ = \\det(\\lambda I - A) \\left(1 + K(\\lambda I - A)^{-1}b\\right) $$\nSince the term $K(\\lambda I - A)^{-1}b$ is a scalar for a single-input system, the characteristic equation for the closed-loop system's eigenvalues $\\lambda$ (where $\\lambda$ is not an eigenvalue of $A$) becomes:\n$$ 1 + K(\\lambda I - A)^{-1}b = 0 $$\nSubstituting our expression for $K = q^T p_d(A)$:\n$$ 1 + q^T p_d(A) (\\lambda I - A)^{-1} b = 0 $$\nWe can use polynomial division to write $p_d(s) = p_d(\\lambda) + (s-\\lambda)\\hat{p}(s,\\lambda)$, where $\\hat{p}(s,\\lambda)$ is a polynomial in $s$ of degree $n-1$. The leading coefficient of $\\hat{p}(s,\\lambda)$ is $1$. Evaluating this at the matrix $A$ gives:\n$$ p_d(A) = p_d(\\lambda)I + (A-\\lambda I)\\hat{p}(A,\\lambda) $$\nAssuming $\\lambda I - A$ is invertible, we can write:\n$$ p_d(A)(\\lambda I-A)^{-1} = -p_d(A)(A-\\lambda I)^{-1} = -p_d(\\lambda)(A-\\lambda I)^{-1} - \\hat{p}(A,\\lambda) $$\nSubstituting this into the characteristic equation:\n$$ 1 - q^T \\left( p_d(\\lambda)(A-\\lambda I)^{-1} + \\hat{p}(A,\\lambda) \\right) b = 0 $$\n$$ 1 - p_d(\\lambda) q^T(A-\\lambda I)^{-1}b - q^T\\hat{p}(A,\\lambda)b = 0 $$\nNow, we examine the term $q^T\\hat{p}(A,\\lambda)b$. Since $\\hat{p}(s,\\lambda)$ is a polynomial of degree $n-1$, we can write $\\hat{p}(A,\\lambda) = \\sum_{i=0}^{n-1} c_i A^i$, where $c_{n-1}=1$.\n$$ q^T\\hat{p}(A,\\lambda)b = q^T \\left(\\sum_{i=0}^{n-1} c_i A^i \\right) b = \\sum_{i=0}^{n-1} c_i (q^T A^i b) $$\nUsing the properties of $q^T$, this sum collapses to a single term:\n$$ (c_0 \\cdot 0) + \\dots + (c_{n-2} \\cdot 0) + (c_{n-1} \\cdot 1) = c_{n-1} = 1 $$\nThe characteristic equation thus simplifies to:\n$$ 1 - p_d(\\lambda) q^T(A-\\lambda I)^{-1}b - 1 = 0 $$\n$$ -p_d(\\lambda) \\left(q^T(A-\\lambda I)^{-1}b\\right) = 0 $$\nThis equation holds true if $p_d(\\lambda) = 0$. This proves that any root of the desired polynomial $p_d(s)$ is an eigenvalue of the closed-loop matrix $A_{cl}$. Since there are $n$ such roots, this constitutes the complete set of eigenvalues for $A_{cl}$.\n\nThe computational procedure avoids explicit matrix inversion. The gain is $K = e_n^T C^{-1} p_d(A)$. Let $X = C^{-1} p_d(A)$. Then $K$ is simply the last row of the matrix $X$. We can find $X$ by solving the linear matrix equation $CX = p_d(A)$.\nThe algorithm is as follows:\n1.  From the desired eigenvalues $\\{\\lambda_1, \\dots, \\lambda_n\\}$, compute the coefficients $\\{a_0, \\dots, a_{n-1}\\}$ of the target characteristic polynomial $p_d(s) = s^n + a_{n-1}s^{n-1} + \\dots + a_0$.\n2.  Evaluate the matrix polynomial $p_d(A)$ using a numerically stable scheme like Horner's method to avoid forming and storing high powers of $A$:\n    $p_d(A) = A^n + a_{n-1}A^{n-1} + \\dots + a_0I = (\\dots((I\\cdot A + a_{n-1}I)A + a_{n-2}I)A + \\dots + a_0I)$.\n3.  Construct the controllability matrix $C = [b \\;\\; Ab \\;\\; \\dots \\;\\; A^{n-1}b]$.\n4.  Solve the linear matrix equation $CX = p_d(A)$ for $X$ without forming $C^{-1}$.\n    -   **Using QR factorization**: Compute $C=QR$. The equation becomes $RX = Q^T p_d(A)$. Since $R$ is upper triangular, $X$ can be found efficiently via back substitution.\n    -   **Using SVD**: Compute $C=U\\Sigma V^T$. The solution is $X = V \\Sigma^{\\dagger} U^T p_d(A)$, where $\\Sigma^{\\dagger}$ is the pseudoinverse of the diagonal matrix $\\Sigma$. The entries of $\\Sigma^{\\dagger}$ are $1/\\sigma_i$ for singular values $\\sigma_i$ above a certain tolerance, and $0$ otherwise. A principled tolerance is $\\tau = \\max(n,n) \\cdot \\epsilon \\cdot \\sigma_{\\max}$, where $\\epsilon$ is machine precision and $\\sigma_{\\max}$ is the largest singular value.\n5.  Extract the gain vector $K$ as the last row of the computed matrix $X$: $K = X[n-1, :]$.\n6.  For validation, construct $A_{cl}=A-bK$ and compute the coefficients of its characteristic polynomial. The error is the maximum absolute difference between these coefficients and the target coefficients $\\{a_i\\}$.\n\nThis procedure provides a numerically robust method for computing the state feedback gain.", "answer": "```python\nimport numpy as np\nimport scipy.linalg\n\ndef solve():\n    \"\"\"\n    Solves for the state feedback gain K using QR and SVD based methods for three test cases,\n    and reports the accuracy of eigenvalue placement.\n    \"\"\"\n\n    def compute_ackermann_gain(A, B, desired_eigs, method):\n        \"\"\"\n        Computes the state feedback gain K using Ackermann's formula via QR or SVD.\n        \n        Args:\n            A (np.ndarray): State matrix (n x n).\n            B (np.ndarray): Input matrix (n x 1).\n            desired_eigs (list or np.ndarray): List of desired closed-loop eigenvalues.\n            method (str): 'qr' or 'svd'.\n\n        Returns:\n            np.ndarray: State feedback gain K (1 x n).\n        \"\"\"\n        n = A.shape[0]\n\n        # 1. Compute coefficients of the desired characteristic polynomial p_d(s)\n        # np.poly gives [1, a_{n-1}, ..., a_0]\n        p_coeffs = np.poly(desired_eigs)\n\n        # 2. Evaluate the matrix polynomial p_d(A) using Horner's method\n        # p_d(A) = A^n + a_{n-1}A^{n-1} + ... + a_0*I\n        PdA = np.eye(n)\n        for i in range(1, n + 1):\n            PdA = A @ PdA + p_coeffs[i] * np.eye(n)\n\n        # 3. Construct the controllability matrix C\n        C = np.zeros((n, n), dtype=np.float64)\n        C[:, 0] = B.flatten()\n        for i in range(1, n):\n            C[:, i] = A @ C[:, i - 1]\n        \n        # 4. Solve the linear system CX = p_d(A) for X\n        if method == 'qr':\n            Q, R = np.linalg.qr(C)\n            # Solve R @ X = Q.T @ PdA\n            X = scipy.linalg.solve_triangular(R, Q.T @ PdA)\n        elif method == 'svd':\n            U, s, Vh = np.linalg.svd(C)\n            # Set tolerance for pseudoinverse calculation\n            tol = max(C.shape) * np.finfo(s.dtype).eps * s[0]\n            s_inv = np.where(s  tol, 1 / s, 0)\n            # Compute X = V @ S_pinv @ U.T @ PdA\n            C_pinv = Vh.T @ np.diag(s_inv) @ U.T\n            X = C_pinv @ PdA\n        else:\n            raise ValueError(\"Method must be 'qr' or 'svd'\")\n\n        # 5. Extract gain K from the last row of X\n        K = X[-1, :]\n        return K.reshape(1, n)\n\n    test_cases = [\n        {\n            \"n\": 3,\n            \"A\": np.array([[0, 1, 0], [0, 0, 1], [0, 0, 0]], dtype=np.float64),\n            \"B\": np.array([[0], [0], [1]], dtype=np.float64),\n            \"eigs\": [-1, -2, -3]\n        },\n        {\n            \"n\": 4,\n            \"A\": np.array([[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0, 0, 0, 0]], dtype=np.float64),\n            \"B\": np.array([[0], [0], [0], [1]], dtype=np.float64),\n            \"eigs\": [-1, -1, -2, -2]\n        },\n        {\n            \"n\": 5,\n            \"setup\": {\n                \"J\": np.diag(np.ones(4), 1),\n                \"e5\": np.array([[0],[0],[0],[0],[1]], dtype=np.float64),\n                \"T\": np.diag([10**(2*i) for i in range(5)])\n            },\n            \"eigs\": [-1, -2, -3, -4, -5]\n        }\n    ]\n    # Prepare test case 3\n    tc3 = test_cases[2]\n    J = tc3['setup']['J']\n    T = tc3['setup']['T']\n    e5 = tc3['setup']['e5']\n    T_inv = np.linalg.inv(T)\n    tc3['A'] = T @ J @ T_inv\n    tc3['B'] = T @ e5\n\n    results = []\n    \n    for case in test_cases:\n        A, B, eigs = case['A'], case['B'], case['eigs']\n        n = case['n']\n\n        # Desired characteristic polynomial coefficients\n        p_coeffs_desired = np.poly(eigs)\n\n        # QR method\n        K_qr = compute_ackermann_gain(A, B, eigs, 'qr')\n        A_cl_qr = A - B @ K_qr\n        p_coeffs_qr = np.poly(A_cl_qr)\n        err_qr = np.max(np.abs(p_coeffs_desired[1:] - p_coeffs_qr[1:]))\n\n        # SVD method\n        K_svd = compute_ackermann_gain(A, B, eigs, 'svd')\n        A_cl_svd = A - B @ K_svd\n        p_coeffs_svd = np.poly(A_cl_svd)\n        err_svd = np.max(np.abs(p_coeffs_desired[1:] - p_coeffs_svd[1:]))\n\n        # Difference between gains\n        dK = np.linalg.norm(K_qr - K_svd)\n\n        results.append([err_qr, err_svd, dK])\n\n    # Format the output as specified\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "2689308"}]}