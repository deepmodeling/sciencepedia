## Introduction
Multirate signal processing provides the essential tools for handling [signals and systems](@entry_id:274453) operating at different sampling rates, a ubiquitous requirement in modern digital technology. From professional audio conversion to [wireless communication](@entry_id:274819) transceivers, the ability to efficiently and accurately change a signal's rate is critical. However, the fundamental operations of rate changing—decimation and interpolation—are not time-invariant, which means they cannot be analyzed using the standard framework of Linear Time-Invariant (LTI) systems. This article addresses this challenge by providing a systematic exploration of the theory and practice of [multirate systems](@entry_id:264982).

This journey will unfold across three chapters, each building upon the last.
*   The "Principles and Mechanisms" chapter introduces the core time-varying operations, explores their spectral consequences like aliasing and imaging, and develops the powerful polyphase framework. This framework transforms periodically [time-varying systems](@entry_id:175653) into equivalent time-invariant ones, enabling the design of efficient structures and [perfect reconstruction filter banks](@entry_id:188265).
*   The "Applications and Interdisciplinary Connections" chapter demonstrates the practical utility of these principles. We will examine efficient sample rate converters, including CIC and Farrow structures, and explore the deep connections between multirate [filter banks](@entry_id:266441) and key concepts in digital communications, [wavelet analysis](@entry_id:179037), and adaptive systems.
*   Finally, the "Hands-On Practices" section offers a series of guided problems to solidify your understanding of these theoretical concepts through practical application.

By navigating these topics, you will gain a deep understanding of how to analyze, design, and implement efficient and powerful [multirate signal processing](@entry_id:196803) systems.

## Principles and Mechanisms

This chapter delves into the fundamental principles and operational mechanisms that govern [multirate signal processing](@entry_id:196803). We will move from the basic definitions of [sampling rate](@entry_id:264884) alteration to their consequences in both the time and frequency domains. This exploration will reveal that the core operations of [multirate systems](@entry_id:264982) are not time-invariant, necessitating a more general framework. The solution to this complexity lies in the elegant and powerful **polyphase representation**, which transforms periodically [time-varying systems](@entry_id:175653) into equivalent multi-channel [time-invariant systems](@entry_id:264083). We will develop this framework and use it to construct computationally efficient structures for decimation and interpolation, and to establish the conditions for the perfect reconstruction of signals in analysis-synthesis [filter banks](@entry_id:266441).

### Core Operations: Linearity and Time-Variance

The foundational building blocks of any multirate system are the operators that change the sampling rate of a [discrete-time signal](@entry_id:275390) $x[n]$. These are the downsampler and the upsampler.

The **downsampler**, or decimator, by an integer factor $M \geq 2$, reduces the sampling rate by discarding samples. The output signal $y[n]$ is formed by keeping only every $M$-th sample of the input:
$$ y[n] = x[Mn] $$

The **upsampler**, or expander, by an integer factor $L \geq 2$, increases the sampling rate by inserting zeros. The output signal $v[n]$ is generated by placing $L-1$ zeros between consecutive samples of the input:
$$ v[n] = \begin{cases} x[n/L],  \text{if } n \text{ is an integer multiple of } L \\ 0,  \text{otherwise} \end{cases} $$

A primary task in [system analysis](@entry_id:263805) is to characterize these operations in terms of linearity and time-invariance. Both the downsampler and the upsampler are easily shown to be **[linear operators](@entry_id:149003)**. For any two signals $x_1[n]$ and $x_2[n]$ and scalars $a, b$, the output of the downsampler for the input $a x_1[n] + b x_2[n]$ is $a x_1[Mn] + b x_2[Mn]$, which is the superposition of the individual outputs. A similar argument holds for the upsampler.

The property of time-invariance, however, does not hold. A system $T$ is time-invariant if it commutes with the [shift operator](@entry_id:263113) $S_k$, defined by $(S_k x)[n] = x[n-k]$, for any integer shift $k$. That is, $T S_k = S_k T$. Let us test this for the downsampler. Applying a shift *before* downsampling gives an output $y_1[n] = x[Mn - k]$. Applying the shift *after* downsampling gives $y_2[n] = x[M(n-k)] = x[Mn - Mk]$. In general, $x[Mn - k] \neq x[Mn - Mk]$, so the downsampler is **not time-invariant**. Similarly, for the upsampler, shifting the input by $k$ results in an output that is non-zero at indices $n=mL$ with values $x[n/L - k]$. Shifting the output by $k$ results in a signal that is non-zero at indices $n=mL+k$. These two outcomes are different, proving that the upsampler is also **not time-invariant**.

This is a crucial insight: the fundamental operations of multirate processing are not Linear Time-Invariant (LTI) systems [@problem_id:2874153]. Consequently, they cannot be described by a time-invariant impulse response $h[n]$ via convolution, and the powerful analysis tools of LTI [system theory](@entry_id:165243), such as the transfer function, do not directly apply in their standard form.

Instead, these systems belong to a broader class known as **Linear Periodically Time-Varying (LPTV)** systems. A general linear system is described by a time-varying impulse response $h[n,k]$, representing the system's response at time $n$ to a [unit impulse](@entry_id:272155) applied at time $k$:
$$ y[n] = \sum_{k=-\infty}^{\infty} h[n,k] x[k] $$
An LPTV system with period $M$ is a special case where the impulse response is periodic with respect to shifts of both time indices by $M$:
$$ h[n+M, k+M] = h[n,k] \quad \text{for all } n,k \in \mathbb{Z} $$
Simple multirate structures are canonical examples of LPTV systems. For instance, consider an interpolator formed by an upsampler-by-$L$ followed by an LTI interpolation filter with impulse response $g[n]$ [@problem_id:2874174]. The output is $y[n] = \sum_m g[n-m]v[m]$, where $v[m]$ is the upsampled input. Combining these relations, we find the overall input-output equation is $y[n] = \sum_k g[n-kL]x[k]$. From this, we can identify the equivalent time-varying impulse response of the cascade as:
$$ h[n,k] = g[n - kL] $$
This system can be shown to be LPTV, satisfying a related periodicity condition $h[n+L, k+1] = h[n,k]$, which confirms its periodically time-varying nature.

### Spectral Consequences: Aliasing and Imaging

The time-varying nature of [upsampling and downsampling](@entry_id:186158) has profound and distinct consequences in the frequency domain. These can be derived by analyzing the Discrete-Time Fourier Transform (DTFT) of the output signals [@problem_id:2874157].

Let $X(e^{j\omega})$ be the DTFT of the input signal $x[n]$. The DTFT of the downsampled signal $y[n]=x[Mn]$ can be shown to be:
$$ Y(e^{j\omega}) = \frac{1}{M} \sum_{k=0}^{M-1} X\left(e^{j(\omega - 2\pi k)/M}\right) $$
This expression reveals two fundamental effects. First, the frequency axis is **expanded** (or stretched) by a factor of $M$, evident from the $\omega/M$ term. Second, the resulting expanded spectrum is shifted by multiples of $2\pi/M$ and all $M$ versions are summed together. If the original signal $x[n]$ is not band-limited to the region $[-\pi/M, \pi/M]$, this process causes the expanded spectral replicas to overlap and add, irreversibly corrupting the signal. This phenomenon is known as **[aliasing](@entry_id:146322)**. To prevent aliasing, the input signal must be passed through a low-pass **[anti-aliasing filter](@entry_id:147260)** with a cutoff frequency of $\pi/M$ *before* being downsampled.

The frequency-domain effect of [upsampling](@entry_id:275608) is different. The DTFT of the zero-inserted signal $v[n]$ is:
$$ V(e^{j\omega}) = X(e^{j\omega L}) $$
Here, the frequency axis is **compressed** by a factor of $L$. Since the original spectrum $X(e^{j\omega})$ is $2\pi$-periodic, the compressed spectrum $V(e^{j\omega})$ becomes periodic with a smaller period of $2\pi/L$. This means that within the principal frequency interval $[-\pi, \pi)$, the original baseband spectrum is squeezed into $[-\pi/L, \pi/L]$ and is then repeated $L-1$ times. These spectral repetitions are known as **images**. Unlike aliasing, these images do not overlap. They can be removed by passing the upsampled signal through a low-pass **[anti-imaging filter](@entry_id:273602)** (also called an interpolation filter) with a [cutoff frequency](@entry_id:276383) of $\pi/L$. This filter interpolates the zero-valued samples, effectively smoothing the signal and removing the high-frequency images.

### The Polyphase Framework

The fact that [sampling rate](@entry_id:264884) converters are LPTV systems seems to pose a significant challenge. However, the **polyphase framework** provides a powerful method to re-cast these time-varying problems into a familiar LTI context. The key idea is to decompose a signal $x[n]$ into a set of $M$ subsequences, called **polyphase components**, defined by:
$$ x_k[n] = x[nM + k] \quad \text{for } k=0, 1, \dots, M-1 $$
Each polyphase component $x_k[n]$ is itself a signal, but at $1/M$-th the original [sampling rate](@entry_id:264884).

Similarly, an LTI filter's impulse response $h[n]$ can also be decomposed. The **Type-1 [polyphase decomposition](@entry_id:269253)** represents a filter $H(z)$ in terms of $M$ polyphase component filters $E_k(z)$:
$$ H(z) = \sum_{k=0}^{M-1} z^{-k} E_k(z^M) $$
where the impulse response $e_k[n]$ of the component filter $E_k(z)$ is formed from the original impulse response $h[n]$ by taking every $M$-th sample, starting at index $k$: $e_k[n] = h[nM+k]$. This decomposition is an exact algebraic identity, merely a regrouping of the terms in the original polynomial $H(z)$ [@problem_id:2874131]. For example, for $M=3$, the terms of $H(z)$ are partitioned into those with delays $z^0, z^{-3}, z^{-6}, \dots$ (which form $E_0(z^3)$), those with delays $z^{-1}, z^{-4}, z^{-7}, \dots$ (which form $z^{-1}E_1(z^3)$), and so on.

The true power of this framework is revealed when we apply it to LPTV systems [@problem_id:2874162]. An arbitrary $M$-periodic LPTV system, described by $y[n]=\sum_k h[n,k]x[k]$, can be shown to be perfectly equivalent to an $M \times M$ Multi-Input Multi-Output (MIMO) **LTI system** that relates the polyphase components of the output, $y_r[\ell]$, to the polyphase components of the input, $x_s[\ell]$:
$$ y_r[\ell] = \sum_{s=0}^{M-1} (e_{r,s} * x_s)[\ell] = \sum_{s=0}^{M-1} \sum_{m=-\infty}^{\infty} e_{r,s}[m] x_s[\ell-m] $$
Here, $e_{r,s}[m]$ are the impulse responses of the $M^2$ LTI filters that constitute the equivalent MIMO system. This remarkable result means we can analyze and implement any LPTV system by working with a bank of LTI filters operating in parallel at a lower sampling rate.

### Efficient Structures: Polyphase Decimators and Interpolators

The most immediate practical application of the polyphase framework is the development of computationally efficient architectures for decimation and interpolation.

Consider a decimator, which consists of an anti-aliasing filter $h[n]$ followed by a downsampler-by-$M$. The naive implementation computes all output samples of the filter, $w[n] = (h*x)[n]$, and then discards $M-1$ out of every $M$ samples. The [polyphase decomposition](@entry_id:269253) allows us to commute the order of operations, performing the bulk of the computation at the lower rate. By starting with the output definition $y[n] = w[Mn]$ and using the Type-1 [polyphase decomposition](@entry_id:269253) of the filter $h[n]$, one can derive the following structure [@problem_id:2874197]:
$$ y[n] = \sum_{k=0}^{M-1} \sum_{m=-\infty}^{\infty} e_k[n-m] x[Mm - k] $$
This expression represents the **polyphase decimator**. It is implemented by first passing the input $x[n]$ through a bank of delays and downsamplers to create the signals $u_k[m] = x[Mm-k]$, then filtering each of these low-rate signals with the corresponding polyphase filter $e_k[n]$, and finally summing the results. All convolutions are performed at the low output rate, resulting in an $M$-fold reduction in computational complexity.

A dual structure exists for the interpolator. An interpolator consists of an upsampler-by-$L$ followed by an [anti-imaging filter](@entry_id:273602) $h[n]$. The naive approach filters a signal containing many zeros. A more efficient structure can be derived using the **Type-2 [polyphase decomposition](@entry_id:269253)**:
$$ H(z) = \sum_{k=0}^{L-1} z^{-k} R_k(z^L) $$
where the Type-2 component impulse responses are defined as $r_k[m] = h[mL+k]$. By decomposing the output signal $y[n]$ into its polyphase components $y[Lq+k]$, we find that each component is a convolution of the *entire* input signal $x[n]$ with a respective polyphase filter [@problem_id:2874175]:
$$ y[Lq+k] = (x * r_k)[q] $$
This is the **polyphase interpolator**. The input $x[n]$ is fed to a bank of $L$ polyphase filters $R_k(z)$, all operating at the low input rate. The outputs of these filters are then fed to a commutator that interleaves them to produce the final high-rate output signal $y[n]$. Again, this results in an $L$-fold computational saving. In the $z$-domain, this structure corresponds to the elegant expression for the output $Y(z)$:
$$ Y(z) = X(z^L) \sum_{k=0}^{L-1} z^{-k} R_k(z^L) $$

### Filter Banks: Analysis, Synthesis, and Perfect Reconstruction

A multirate [filter bank](@entry_id:271554) is a system that splits a signal into multiple frequency subbands (analysis) and later recombines them to reconstruct the original signal (synthesis). The principles we have developed are central to their analysis and design.

Consider a [two-channel filter bank](@entry_id:186662) where the analysis stage uses filters $H_0(z)$ and $H_1(z)$ followed by downsampling-by-2, and the synthesis stage uses [upsampling](@entry_id:275608)-by-2 followed by filters $G_0(z)$ and $G_1(z)$. The overall input-output relationship in the $z$-domain can be shown to be [@problem_id:2874141]:
$$ Y(z) = \frac{1}{2} [H_0(z)G_0(z) + H_1(z)G_1(z)] X(z) + \frac{1}{2} [H_0(-z)G_0(z) + H_1(-z)G_1(z)] X(-z) $$
The term multiplying $X(-z)$ is the **aliasing transfer function**. For **Perfect Reconstruction (PR)**, where the output is a possibly scaled and delayed version of the input ($y[n] = c x[n-d]$), the [aliasing](@entry_id:146322) term must be eliminated for all inputs. This gives the **[aliasing cancellation](@entry_id:262830) condition**:
$$ H_0(-z)G_0(z) + H_1(-z)G_1(z) = 0 $$
Once aliasing is cancelled, the term multiplying $X(z)$, the **distortion transfer function**, must be a simple delay:
$$ \frac{1}{2} [H_0(z)G_0(z) + H_1(z)G_1(z)] = c z^{-d} $$
These two equations form the basis for designing PR [filter banks](@entry_id:266441). For a given set of analysis filters, they provide a [system of linear equations](@entry_id:140416) that can be solved to find the required synthesis filters.

A more general and powerful approach uses the [polyphase matrix](@entry_id:201228). For an $M$-channel bank, the analysis filters can be represented by an $M \times M$ **analysis [polyphase matrix](@entry_id:201228)** $E(z)$, and the synthesis filters by a **synthesis [polyphase matrix](@entry_id:201228)** $R(z)$. The PR condition then becomes a matrix equation:
$$ R(z)E(z) = c z^{-d} I $$
where $I$ is the identity matrix. This single equation encapsulates both [aliasing cancellation](@entry_id:262830) and distortion control. It implies that for PR, the synthesis matrix must be proportional to the inverse of the analysis matrix: $R(z) \propto z^{-d} E^{-1}(z)$ [@problem_id:2874195].

This matrix formulation provides deep insights into the feasibility of reconstruction. The properties of the synthesis bank are dictated by the inverse of $E(z)$, which depends critically on its determinant, $\det E(z)$.
- For a **FIR** synthesis bank to exist, $R(z)$ must have polynomial entries. This is only possible if $E^{-1}(z)$ has polynomial entries, which requires $\det E(z)$ to be a simple monomial, $c_0 z^{-d_0}$.
- If $\det E(z)$ is a more complex polynomial, an **IIR** synthesis bank may still exist. However, its stability depends on the poles of $R(z)$, which correspond to the zeros of $\det E(z)$. For the synthesis bank to be Bounded-Input Bounded-Output (BIBO) stable, all zeros of $\det E(z)$ must lie strictly inside the unit circle. If any zero of $\det E(z)$ falls on or outside the unit circle, a stable PR synthesis bank is impossible.

A particularly important and efficient class of [filter banks](@entry_id:266441) are **DFT-modulated [filter banks](@entry_id:266441)** [@problem_id:2874136]. In these systems, all $M$ analysis filters $H_k(z)$ are generated by modulating a single low-pass prototype filter $P(z)$:
$$ H_k(z) = P(z W_M^{-k}) \quad \text{where } W_M = e^{-j2\pi/M} $$
This shifts the prototype's frequency response to different center frequencies, creating a uniformly spaced bank of bandpass filters. The corresponding synthesis filters for an IDFT-based synthesis stage are modulated in the opposite direction, $G_k(z) = P(z W_M^{k})$. This structure is highly efficient as the [modulation](@entry_id:260640) and filtering operations can be implemented using Fast Fourier Transform (FFT) algorithms.