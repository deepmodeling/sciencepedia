{"hands_on_practices": [{"introduction": "We begin our practice by exploring one of the most powerful results in Fourier analysis: Parseval's identity. This theorem provides a fundamental link between a signal's average power in the time domain and the power of its spectral components in the frequency domain. By re-deriving this identity from the orthogonality of the trigonometric basis functions, you will solidify your understanding of Fourier coefficients as projections and see precisely how their normalization factors preserve this power relationship [@problem_id:2860379].", "problem": "Let $x(t)$ be a real-valued, $T$-periodic signal with fundamental angular frequency $\\omega_{0} = \\frac{2\\pi}{T}$, such that $x \\in L^{2}[0,T]$ and admits a trigonometric Fourier series representation in the form\n$$\nx(t) = a_{0} + \\sum_{n=1}^{\\infty} \\left[a_{n}\\cos(n\\omega_{0} t) + b_{n}\\sin(n\\omega_{0} t)\\right],\n$$\nwhere the coefficients are defined by the integrals\n$$\na_{0} = \\frac{1}{T}\\int_{0}^{T} x(t)\\, dt,\\quad\na_{n} = \\frac{2}{T}\\int_{0}^{T} x(t)\\cos(n\\omega_{0} t)\\, dt,\\quad\nb_{n} = \\frac{2}{T}\\int_{0}^{T} x(t)\\sin(n\\omega_{0} t)\\, dt,\n$$\nfor all $n \\geq 1$. Starting only from the orthogonality of the trigonometric system over one period and the above coefficient definitions, re-derive the trigonometric-form version of Parseval’s identity, i.e., obtain a closed-form expression for the time-average of the squared signal over one period,\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt,\n$$\nin terms of $a_{0}$, $\\{a_{n}\\}_{n\\geq 1}$, and $\\{b_{n}\\}_{n\\geq 1}$. In your derivation, explicitly justify the role of the normalization factors in the coefficient definitions. As a consistency check, verify that your identity yields the correct time-average for the test signal $x(t) = \\cos(\\omega_{0} t)$. Provide your final answer as a single closed-form expression for $\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt$ in terms of $a_{0}$, $\\{a_{n}\\}$, and $\\{b_{n}\\}$. No rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and complete. It presents a standard task in the analysis of Fourier series, a fundamental topic in signal processing and applied mathematics. All components—the signal properties, the Fourier series representation, and the coefficient definitions—are canonical. Therefore, the problem is valid, and a rigorous derivation can be provided.\n\nThe objective is to derive an expression for the time-average of the squared signal over one period, $\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt$, also known as the mean-square value or average power of the signal $x(t)$. We start from the provided trigonometric Fourier series representation of the signal $x(t)$:\n$$\nx(t) = a_{0} + \\sum_{n=1}^{\\infty} \\left[a_{n}\\cos(n\\omega_{0} t) + b_{n}\\sin(n\\omega_{0} t)\\right]\n$$\nThe value to be computed is $\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt$. We substitute the series representation for one of the $x(t)$ factors in the integrand:\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt = \\frac{1}{T}\\int_{0}^{T} x(t) \\left( a_{0} + \\sum_{m=1}^{\\infty} \\left[a_{m}\\cos(m\\omega_{0} t) + b_{m}\\sin(m\\omega_{0} t)\\right] \\right) dt\n$$\nGiven that $x \\in L^{2}[0,T]$, the Fourier series converges in the mean-square sense, which justifies interchanging the order of integration and summation. Distributing the terms, we obtain:\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt = a_{0} \\left( \\frac{1}{T}\\int_{0}^{T} x(t) \\, dt \\right) + \\sum_{m=1}^{\\infty} \\left[ a_{m} \\left(\\frac{1}{T}\\int_{0}^{T} x(t)\\cos(m\\omega_{0} t) \\, dt\\right) + b_{m} \\left(\\frac{1}{T}\\int_{0}^{T} x(t)\\sin(m\\omega_{0} t) \\, dt\\right) \\right]\n$$\nWe now use the definitions of the Fourier coefficients provided in the problem statement:\n$$\na_{0} = \\frac{1}{T}\\int_{0}^{T} x(t)\\, dt\n$$\n$$\na_{n} = \\frac{2}{T}\\int_{0}^{T} x(t)\\cos(n\\omega_{0} t)\\, dt \\quad \\implies \\quad \\frac{1}{T}\\int_{0}^{T} x(t)\\cos(n\\omega_{0} t)\\, dt = \\frac{a_{n}}{2}\n$$\n$$\nb_{n} = \\frac{2}{T}\\int_{0}^{T} x(t)\\sin(n\\omega_{0} t)\\, dt \\quad \\implies \\quad \\frac{1}{T}\\int_{0}^{T} x(t)\\sin(n\\omega_{0} t)\\, dt = \\frac{b_{n}}{2}\n$$\nSubstituting these expressions back into the expanded integral yields:\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt = a_{0}(a_{0}) + \\sum_{m=1}^{\\infty} \\left[ a_{m}\\left(\\frac{a_{m}}{2}\\right) + b_{m}\\left(\\frac{b_{m}}{2}\\right) \\right]\n$$\nSimplifying this expression gives the trigonometric form of Parseval's identity:\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt = a_{0}^{2} + \\frac{1}{2} \\sum_{n=1}^{\\infty} \\left(a_{n}^{2} + b_{n}^{2}\\right)\n$$\nThe problem demands a justification for the normalization factors in the coefficient definitions. The set of functions $\\{1, \\cos(n\\omega_{0}t), \\sin(n\\omega_{0}t)\\}_{n=1}^{\\infty}$ forms an orthogonal basis for the space of square-integrable functions on $[0, T]$. The Fourier coefficients are projections of the signal $x(t)$ onto these basis functions. For a general real inner product space with inner product $\\langle f, g \\rangle$, the projection coefficient of a vector $f$ onto a basis vector $g$ is $\\frac{\\langle f, g \\rangle}{\\langle g, g \\rangle}$. For our space $L^{2}[0,T]$, the inner product is defined as $\\langle f, g \\rangle = \\int_{0}^{T} f(t)g(t) \\, dt$.\nWe must compute the squared norms, $\\langle g, g \\rangle = \\int_{0}^{T} g(t)^2 \\, dt$, for each basis function:\n\\begin{enumerate}\n    \\item For the constant basis function $1$:\n    $$ \\int_{0}^{T} (1)^{2}\\, dt = T $$\n    \\item For the cosine basis functions, $\\cos(n\\omega_{0}t)$ where $n \\geq 1$:\n    $$ \\int_{0}^{T} \\cos^{2}(n\\omega_{0} t)\\, dt = \\int_{0}^{T} \\frac{1 + \\cos(2n\\omega_{0} t)}{2}\\, dt = \\left[ \\frac{t}{2} + \\frac{\\sin(2n\\omega_{0} t)}{4n\\omega_{0}} \\right]_{0}^{T} = \\frac{T}{2} $$\n    \\item For the sine basis functions, $\\sin(n\\omega_{0}t)$ where $n \\geq 1$:\n    $$ \\int_{0}^{T} \\sin^{2}(n\\omega_{0} t)\\, dt = \\int_{0}^{T} \\frac{1 - \\cos(2n\\omega_{0} t)}{2}\\, dt = \\left[ \\frac{t}{2} - \\frac{\\sin(2n\\omega_{0} t)}{4n\\omega_{0}} \\right]_{0}^{T} = \\frac{T}{2} $$\n\\end{enumerate}\nThe normalization factors in the coefficient definitions are precisely the reciprocals of these squared norms:\n\\begin{itemize}\n    \\item For $a_{0}$: The factor is $\\frac{1}{T}$, which is $\\frac{1}{\\int_{0}^{T} (1)^{2}\\, dt}$.\n    \\item For $a_{n}$ ($n \\geq 1$): The factor is $\\frac{2}{T}$, which is $\\frac{1}{\\int_{0}^{T} \\cos^{2}(n\\omega_{0} t)\\, dt}$.\n    \\item For $b_{n}$ ($n \\geq 1$): The factor is $\\frac{2}{T}$, which is $\\frac{1}{\\int_{0}^{T} \\sin^{2}(n\\omega_{0} t)\\, dt}$.\n\\end{itemize}\nThis demonstrates that the given coefficient formulas are the standard definitions for projections onto an orthogonal, but not orthonormal, basis. The factors $\\frac{1}{2}$ in the final Parseval's identity arise directly because the squared norms of the sinusoidal basis functions are $\\frac{T}{2}$, not $1$.\n\nFinally, we perform the requested consistency check with the test signal $x(t) = \\cos(\\omega_{0} t)$.\nFirst, we compute the time-average power directly:\n$$\n\\frac{1}{T}\\int_{0}^{T} \\big(x(t)\\big)^{2}\\, dt = \\frac{1}{T}\\int_{0}^{T} \\cos^{2}(\\omega_{0} t)\\, dt = \\frac{1}{T} \\left( \\frac{T}{2} \\right) = \\frac{1}{2}\n$$\nNext, we determine the Fourier coefficients for $x(t) = \\cos(\\omega_{0} t)$:\n\\begin{itemize}\n    \\item $a_{0} = \\frac{1}{T}\\int_{0}^{T} \\cos(\\omega_{0} t)\\, dt = 0$.\n    \\item For $n=1$, $a_{1} = \\frac{2}{T}\\int_{0}^{T} \\cos(\\omega_{0} t)\\cos(\\omega_{0} t)\\, dt = \\frac{2}{T}\\int_{0}^{T} \\cos^{2}(\\omega_{0} t)\\, dt = \\frac{2}{T}\\left(\\frac{T}{2}\\right) = 1$.\n    \\item For $n > 1$, $a_{n} = \\frac{2}{T}\\int_{0}^{T} \\cos(\\omega_{0} t)\\cos(n\\omega_{0} t)\\, dt = 0$ due to orthogonality.\n    \\item For all $n \\geq 1$, $b_{n} = \\frac{2}{T}\\int_{0}^{T} \\cos(\\omega_{0} t)\\sin(n\\omega_{0} t)\\, dt = 0$ due to orthogonality.\n\\end{itemize}\nThe only non-zero coefficient is $a_{1}=1$. Substituting these coefficients into our derived identity:\n$$\na_{0}^{2} + \\frac{1}{2} \\sum_{n=1}^{\\infty} \\left(a_{n}^{2} + b_{n}^{2}\\right) = 0^{2} + \\frac{1}{2} \\left[ (a_{1}^{2} + b_{1}^{2}) + \\sum_{n=2}^{\\infty} (a_{n}^{2} + b_{n}^{2}) \\right] = 0 + \\frac{1}{2} \\left[ (1^{2} + 0^{2}) + \\sum_{n=2}^{\\infty} (0^{2} + 0^{2}) \\right] = \\frac{1}{2}\n$$\nThe result matches the direct calculation, confirming the correctness of the derived Parseval's identity.", "answer": "$$\n\\boxed{a_{0}^{2} + \\frac{1}{2}\\sum_{n=1}^{\\infty} \\left(a_{n}^{2} + b_{n}^{2}\\right)}\n$$", "id": "2860379"}, {"introduction": "Having established the power relationship, we now turn to the critical question of pointwise convergence: what value does the infinite series sum to at a specific time $t$? This practice guides you through the process of translating between the complex exponential and trigonometric forms of a Fourier series. You will then apply foundational convergence principles to determine the series' sum at both a point of continuity and a jump discontinuity, illustrating the famous result that the series converges to the midpoint of the jump [@problem_id:2860322].", "problem": "Consider the continuous-time Fourier series (CTFS) with period $T = 2\\pi$ in its complex exponential form\n$$\nx(t) = \\sum_{k=-\\infty}^{\\infty} c_{k} \\exp(j k t),\n$$\nwhere the complex Fourier coefficients $c_{k}$ are defined by\n$$\nc_{0} = 0, \\quad c_{k} = \\frac{1}{j k} \\text{ for } k \\neq 0.\n$$\nYour tasks are:\n1. Using only the defining relationships between the complex and trigonometric forms of the CTFS and the orthogonality of $\\exp(j k t)$, derive the real trigonometric Fourier series for $x(t)$ on one period and express it in terms of coefficients $a_{0}$, $a_{n}$, and $b_{n}$ in\n$$\nx(t) = \\frac{a_{0}}{2} + \\sum_{n=1}^{\\infty} \\big(a_{n} \\cos(n t) + b_{n} \\sin(n t)\\big).\n$$\n2. Justify, starting from foundational convergence facts for Fourier series of piecewise smooth functions and without invoking any pre-memorized closed-form sums, the pointwise limit of the trigonometric series at\n   - the discontinuity $t = 0$,\n   - the smooth point $t = \\pi/3$.\nIn your justification, you may use summability via an Abel factor and limits thereof as a convergence tool.\n\nReport your final result as two values $S(0)$ and $S(\\pi/3)$, where $S(t)$ denotes the pointwise limit of the series at $t$. Provide the two values in that order. No rounding is required, and no units are needed. Angles are in radians.", "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. It presents a standard problem in the analysis of Fourier series, free of any factual inaccuracies, ambiguities, or contradictions. Therefore, the problem is valid, and I shall proceed with a full solution.\n\nThe analysis is structured in two parts as requested. First, the derivation of the real trigonometric Fourier series from the given complex exponential coefficients. Second, a justification of the pointwise convergence of this series at two specified points, based on foundational principles.\n\n**Part 1: Derivation of the Trigonometric Fourier Series**\n\nThe continuous-time signal $x(t)$ is defined by its complex exponential Fourier series coefficients over a period of $T = 2\\pi$, corresponding to a fundamental frequency of $\\omega_0 = \\frac{2\\pi}{T} = 1$. The series is given by:\n$$\nx(t) = \\sum_{k=-\\infty}^{\\infty} c_{k} \\exp(j k t)\n$$\nwith coefficients:\n$$\nc_{0} = 0, \\quad c_{k} = \\frac{1}{j k} \\quad \\text{for } k \\neq 0\n$$\nThe real trigonometric Fourier series has the form:\n$$\nx(t) = \\frac{a_{0}}{2} + \\sum_{n=1}^{\\infty} \\big(a_{n} \\cos(n t) + b_{n} \\sin(n t)\\big)\n$$\nThe coefficients $a_0$, $a_n$, and $b_n$ are related to the complex coefficients $c_k$. These relationships are derived by substituting Euler's identities for cosine and sine into the trigonometric series and comparing the result with the complex exponential form. This procedure yields:\n$$\na_{0} = 2 c_{0}\n$$\n$$\na_{n} = c_{n} + c_{-n} \\quad \\text{for } n \\ge 1\n$$\n$$\nb_{n} = j(c_{n} - c_{-n}) \\quad \\text{for } n \\ge 1\n$$\nWe now compute these coefficients using the provided values of $c_k$.\n\nFor the DC component, with $c_0 = 0$:\n$$\na_{0} = 2(0) = 0\n$$\n\nFor the cosine coefficients $a_n$ where $n \\ge 1$:\n$$\nc_{n} = \\frac{1}{jn} \\quad \\text{and} \\quad c_{-n} = \\frac{1}{j(-n)} = -\\frac{1}{jn}\n$$\nTherefore,\n$$\na_{n} = \\frac{1}{jn} + \\left(-\\frac{1}{jn}\\right) = 0\n$$\nAll cosine coefficients are zero, which indicates that $x(t)$ is an odd function.\n\nFor the sine coefficients $b_n$ where $n \\ge 1$:\n$$\nb_{n} = j(c_{n} - c_{-n}) = j\\left(\\frac{1}{jn} - \\left(-\\frac{1}{jn}\\right)\\right) = j\\left(\\frac{2}{jn}\\right) = \\frac{2}{n}\n$$\nSubstituting these coefficients into the trigonometric series form, we obtain the series for $x(t)$:\n$$\nx(t) = \\frac{0}{2} + \\sum_{n=1}^{\\infty} \\left(0 \\cdot \\cos(nt) + \\frac{2}{n} \\sin(nt)\\right) = \\sum_{n=1}^{\\infty} \\frac{2}{n} \\sin(nt)\n$$\n\n**Part 2: Justification of Pointwise Convergence**\n\nThe central task here is to determine the pointwise limit of the series, denoted $S(t)$, at $t=0$ and $t=\\pi/3$. This requires a foundational justification rather than merely stating a convergence theorem.\n\nFirst, we must identify the function $x(t)$ represented by the given Fourier coefficients. The coefficients $c_k \\sim 1/|k|$ for large $|k|$ suggest that the function is discontinuous but piecewise smooth. We can identify the function by considering its derivative, $x'(t)$. The Fourier coefficients of the derivative are $c'_k = jk c_k$. For $k \\neq 0$, we have $c'_k = jk (\\frac{1}{jk}) = 1$. The DC coefficient $c'_0 = j(0)c_0 = 0$. However, formal differentiation does not always yield a simple result for discontinuous functions. A more rigorous interpretation is that the Fourier series for $x'(t)$ is $\\sum_{k=-\\infty, k \\neq 0}^{\\infty} \\exp(jkt)$. This series can be recognized as the series for a periodic impulse train minus a constant:\n$$\n\\sum_{k=-\\infty}^{\\infty} \\exp(jkt) = 2\\pi \\sum_{m=-\\infty}^{\\infty} \\delta(t-2\\pi m)\n$$\nThus, the series for $x'(t)$ corresponds to $2\\pi \\sum_{m=-\\infty}^{\\infty} \\delta(t-2\\pi m) - 1$. Integrating this distribution gives a function that has a constant slope of $-1$ and jumps of size $2\\pi$ at integer multiples of $2\\pi$. This implies $x(t) = C - t$ over one period, for some constant $C$. The value of $C$ is determined by the DC offset, $c_0=0$.\n$$\nc_0 = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} x(t) dt = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} (C-t) dt = \\frac{1}{2\\pi} \\left[Ct - \\frac{t^2}{2}\\right]_0^{2\\pi} = \\frac{1}{2\\pi} (2\\pi C - 2\\pi^2) = C - \\pi\n$$\nSince $c_0 = 0$, we must have $C=\\pi$. Therefore, the function represented by the series is, on the interval $(0, 2\\pi)$:\n$$\nx(t) = \\pi - t\n$$\nThis function is extended periodically for all $t \\in \\mathbb{R}$. This function is piecewise linear and thus piecewise smooth.\n\nThe convergence of the Fourier series of a piecewise smooth function is governed by Dirichlet's theorem. The proof of this theorem, which constitutes the required justification, rests on the properties of the Dirichlet kernel. The partial sum of the Fourier series is given by the convolution of the function with the Dirichlet kernel $D_N(u) = \\sum_{k=-N}^N \\exp(jku) = \\frac{\\sin((N+1/2)u)}{\\sin(u/2)}$.\nThe symmetric partial sum converges to the average of the left and right-hand limits of the function:\n$$\nS(t) = \\lim_{N\\to\\infty} S_N(t) = \\frac{x(t^+) + x(t^-)}{2}\n$$\nThis result is established by expressing the difference $S_N(t) - \\frac{x(t^+) + x(t^-)}{2}$ as an integral involving the factor $\\sin((N+1/2)u)$. For a piecewise smooth function, the remaining part of the integrand is absolutely integrable, and by the Riemann-Lebesgue lemma, the integral vanishes as $N \\to \\infty$. This fundamental argument justifies applying this convergence criterion.\n\nWe now apply this result to the specified points:\n\n1.  **Convergence at the discontinuity $t=0$:**\n    The point $t=0$ is a jump discontinuity. We must evaluate the left and right-hand limits of $x(t)$ at this point.\n    The right-hand limit is found directly from the function's definition on $(0, 2\\pi)$:\n    $$\n    x(0^+) = \\lim_{t \\to 0^+} (\\pi - t) = \\pi\n    $$\n    The left-hand limit is found by using the periodicity $x(t) = x(t+2\\pi)$:\n    $$\n    x(0^-) = \\lim_{\\epsilon \\to 0^+} x(-\\epsilon) = \\lim_{\\epsilon \\to 0^+} x(2\\pi-\\epsilon) = \\lim_{t \\to (2\\pi)^-} (\\pi - t) = \\pi - 2\\pi = -\\pi\n    $$\n    The series converges to the average of these limits:\n    $$\n    S(0) = \\frac{x(0^+) + x(0^-)}{2} = \\frac{\\pi + (-\\pi)}{2} = 0\n    $$\n\n2.  **Convergence at the smooth point $t=\\pi/3$:**\n    The point $t=\\pi/3$ lies within the interval $(0, 2\\pi)$, where $x(t)$ is continuous and differentiable. At such a point, the left and right-hand limits are equal to the function's value.\n    $$\n    x((\\pi/3)^+) = x((\\pi/3)^-) = x(\\pi/3)\n    $$\n    The series therefore converges to the value of the function at that point:\n    $$\n    S(\\pi/3) = x(\\pi/3) = \\pi - \\frac{\\pi}{3} = \\frac{2\\pi}{3}\n    $$\nThis completes the justification for the pointwise limits. The values are $S(0)=0$ and $S(\\pi/3)=2\\pi/3$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0  \\frac{2\\pi}{3} \\end{pmatrix}}\n$$", "id": "2860322"}, {"introduction": "Our final practice delves into a fascinating and subtle aspect of Fourier series convergence known as the Gibbs phenomenon. While we know the series converges at a discontinuity, the *manner* of this convergence is not simple, involving characteristic overshoots and oscillations. In this advanced exercise, you will analyze the behavior of the partial sums near a jump, demonstrating that while the oscillations become spatially compressed, the overshoot height remains constant, and you will quantify this asymptotic error [@problem_id:2860329].", "problem": "Let $f:\\mathbb{R}\\to\\mathbb{R}$ be a $2\\pi$-periodic, piecewise $C^{1}$ function with a single jump discontinuity at $x=0$, with left and right limits $f(0^{-})$ and $f(0^{+})$, and jump amplitude $A = f(0^{+}) - f(0^{-}) \\neq 0$. Let $S_{N}$ denote the $N$th symmetric partial sum of the continuous-time Fourier series (CTFS) of $f$, that is, $S_{N}(x) = \\sum_{n=-N}^{N} c_{n} \\exp(j n x)$, where $c_{n}$ are the CTFS coefficients of $f$.\n\nWorking only from the definition of the continuous-time Fourier series and the elementary properties of trigonometric polynomials and integrals, analyze the local behavior of $S_{N}(x)$ in a shrinking neighborhood of the discontinuity at $x=0$ by introducing the rescaled coordinate $y = \\frac{2N+1}{2}\\,x$. Establish the following two claims:\n\n1) The spatial width (in $x$) of the primary Gibbs oscillation lobe around $x=0$ scales proportionally to $1/N$ as $N\\to\\infty$, and the corresponding $y$-domain profile converges to a limit determined by an integral of the normalized sinc function.\n\n2) The height of the maximal overshoot of $S_{N}(x)$ relative to the upper plateau value $f(0^{+})$ does not decay with $N$, and its asymptotic value is proportional to the jump amplitude $A$.\n\nThen, compute the asymptotic overshoot height normalized by the jump amplitude, namely the quantity\n$$\n\\lim_{N\\to\\infty}\\,\\frac{\\max_{x\\ \\text{near }0}\\big(S_{N}(x)-f(0^{+})\\big)}{A},\n$$\nand express your final answer as a single closed-form analytic expression involving only standard mathematical constants and functions. No numerical approximation is required or allowed for the final answer. All angles are to be understood in radians. The final answer must be a single expression with no units.", "solution": "The supplied problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- $f:\\mathbb{R}\\to\\mathbb{R}$ is a $2\\pi$-periodic function.\n- $f$ is piecewise $C^{1}$.\n- $f$ has a single jump discontinuity at $x=0$ in the period $(-\\pi, \\pi]$.\n- Left limit at the discontinuity: $f(0^{-})$.\n- Right limit at the discontinuity: $f(0^{+})$.\n- Jump amplitude: $A = f(0^{+}) - f(0^{-}) \\neq 0$.\n- $S_{N}(x)$ is the $N$th symmetric partial sum of the continuous-time Fourier series (CTFS) of $f$: $S_{N}(x) = \\sum_{n=-N}^{N} c_{n} \\exp(j n x)$.\n- $c_{n}$ are the CTFS coefficients of $f$.\n- Rescaled coordinate: $y = \\frac{2N+1}{2}\\,x$.\n- Task 1: Analyze the spatial width of the Gibbs oscillation lobe, showing it scales as $1/N$, and that the rescaled profile converges to a limit involving an integral of the sinc function.\n- Task 2: Show the maximal overshoot height does not decay with $N$ and is proportional to the jump amplitude $A$.\n- Goal: Compute the asymptotic normalized overshoot height: $\\lim_{N\\to\\infty}\\,\\frac{\\max_{x\\ \\text{near }0}\\big(S_{N}(x)-f(0^{+})\\big)}{A}$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes a classic phenomenon in the theory of Fourier analysis, known as the Gibbs phenomenon. All definitions and concepts are standard in mathematics and signal processing. The problem is scientifically sound.\n- **Well-Posed:** The problem is well-posed. The conditions on the function $f$ are sufficient to guarantee the existence and uniqueness of the Fourier series and the asymptotic limit of the overshoot. The question asks for a specific, calculable mathematical constant.\n- **Objective:** The problem is stated in precise, objective mathematical language, free from any subjectivity or ambiguity.\n\n**Step 3: Verdict and Action**\nThe problem is found to be valid. It is a standard, albeit non-trivial, problem in mathematical analysis. A complete solution will be provided.\n\n**Solution Derivation**\n\nThe analysis of the Gibbs phenomenon hinges on isolating the effect of the jump discontinuity. We decompose the function $f(x)$ into two parts: a pure step function that captures the discontinuity at $x=0$, and a remainder function that is \"more regular\" at $x=0$.\n\nLet us define an auxiliary function $g(x)$ on $(-\\pi, \\pi]$ as follows:\n$$\ng(x) = \\begin{cases} f(0^{-})  x \\in (-\\pi, 0) \\\\ f(0^{+})  x \\in (0, \\pi) \\\\ \\frac{f(0^{+}) + f(0^{-})}{2}  x = 0, \\pi \\end{cases}\n$$\nand extend it to be $2\\pi$-periodic. This function has the same jump discontinuity as $f(x)$ at $x=0$.\nThe function $g(x)$ can be expressed as:\n$$\ng(x) = \\frac{f(0^{+}) + f(0^{-})}{2} + \\frac{f(0^{+}) - f(0^{-})}{2} \\text{ sgn}(x) = \\frac{f(0^{+}) + f(0^{-})}{2} + \\frac{A}{2} \\text{ sgn}(x)\n$$\nfor $x \\in (-\\pi, \\pi)$, where $\\text{sgn}(x)$ is the standard signum function.\n\nNow, define the remainder function $h(x) = f(x) - g(x)$. By construction, the jump of $h(x)$ at $x=0$ is:\n$$\nh(0^{+}) - h(0^{-}) = (f(0^{+}) - g(0^{+})) - (f(0^{-}) - g(0^{-})) = (f(0^{+})-f(0^{+})) - (f(0^{-})-f(0^{-})) = 0.\n$$\nThus, $h(x)$ is continuous at $x=0$. Since $f(x)$ is piecewise $C^1$, $h(x)$ is continuous and piecewise $C^1$. For such a function, its Fourier series $S_N[h](x)$ converges uniformly to $h(x)$. As $x \\to 0$, $h(x) \\to h(0) = 0$. Consequently, for large $N$, the contribution of $S_N[h](x)$ to the behavior of $S_N[f](x)$ near $x=0$ is negligible, as $S_N[h](x) \\approx h(x) \\approx 0$.\n\nThe Gibbs phenomenon is therefore entirely contained in the behavior of the partial sum of $g(x)$, denoted $S_N[g](x)$. The Fourier series is a linear operation, so:\n$$\nS_N[f](x) = S_N[g](x) + S_N[h](x).\n$$\nFor the asymptotic analysis near $x=0$, we have $S_N[f](x) \\approx S_N[g](x)$.\nThe partial sum of a constant is the constant itself, and the Fourier series of $\\text{sgn}(x)$ is well known. However, we will proceed from the integral definition of the partial sum. The $N$th partial sum is given by the convolution with the Dirichlet kernel $D_N(u) = \\sum_{k=-N}^N e^{jku} = \\frac{\\sin((N+1/2)u)}{\\sin(u/2)}$.\n$$\nS_N[g](x) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} g(t) D_N(x-t) dt.\n$$\nUsing the property that $D_N(u)$ is an even function, and changing variables, we get:\n$$\nS_N[g](x) = \\frac{1}{\\pi} \\int_{0}^{\\pi} \\frac{g(x-u) + g(x+u)}{2} D_N(u) du.\n$$\nLet's analyze this for small $x  0$. The term $\\frac{g(x-u) + g(x+u)}{2}$ simplifies:\n- For $0  u  x$: $x-u  0$ and $x+u  0$. So $g(x-u) = f(0^{+})$ and $g(x+u) = f(0^{+})$. The average is $f(0^{+})$.\n- For $x  u  \\pi$: $x-u  0$ and $x+u  0$. So $g(x-u) = f(0^{-})$ and $g(x+u) = f(0^{+})$. The average is $\\frac{f(0^{-}) + f(0^{+})}{2}$.\n\nWe split the integral at $u=x$:\n$$\nS_N[g](x) = \\frac{1}{\\pi} \\int_{0}^{x} f(0^{+}) D_N(u) du + \\frac{1}{\\pi} \\int_{x}^{\\pi} \\frac{f(0^{-}) + f(0^{+})}{2} D_N(u) du.\n$$\nWe can rewrite this by adding and subtracting terms:\n$$\nS_N[g](x) = \\left(f(0^{+}) - \\frac{f(0^{-}) + f(0^{+})}{2}\\right) \\frac{1}{\\pi}\\int_0^x D_N(u)du + \\frac{f(0^{-}) + f(0^{+})}{2} \\frac{1}{\\pi}\\int_0^{\\pi} D_N(u)du.\n$$\nRecognizing that $\\frac{1}{\\pi}\\int_0^{\\pi} D_N(u)du = 1$ and $f(0^{+}) - \\frac{f(0^{-}) + f(0^{+})}{2} = \\frac{A}{2}$, we have:\n$$\nS_N[g](x) = \\frac{f(0^{-}) + f(0^{+})}{2} + \\frac{A}{2\\pi} \\int_0^x D_N(u) du.\n$$\nFor large $N$, the dominant contribution to the integral comes from small $u$, where we can approximate $\\sin(u/2) \\approx u/2$.\n$$\nS_N[g](x) \\approx \\frac{f(0^{-}) + f(0^{+})}{2} + \\frac{A}{2\\pi} \\int_0^x \\frac{\\sin((N+1/2)u)}{u/2} du = \\frac{f(0^{-}) + f(0^{+})}{2} + \\frac{A}{\\pi} \\int_0^x \\frac{\\sin((N+1/2)u)}{u} du.\n$$\nWe introduce the rescaled coordinate $y = (N+1/2)x$. Let $v = (N+1/2)u$, so $du = dv/(N+1/2)$ and $u = v/(N+1/2)$. The integral becomes:\n$$\n\\int_0^{(N+1/2)x} \\frac{\\sin(v)}{v/(N+1/2)} \\frac{dv}{N+1/2} = \\int_0^y \\frac{\\sin v}{v} dv.\n$$\nThis integral is the Sine Integral function, $\\text{Si}(y) = \\int_0^y \\frac{\\sin t}{t} dt$.\nThus, the asymptotic behavior of the partial sum in the rescaled coordinate $y$ is:\n$$\nS_N\\left(\\frac{y}{N+1/2}\\right) \\approx \\frac{f(0^{-}) + f(0^{+})}{2} + \\frac{A}{\\pi} \\text{Si}(y).\n$$\nThis demonstrates that the spatial profile of the oscillation, when rescaled by $N$, converges to a fixed shape determined by the Sine Integral, which is an integral of the sinc function. The width of the main lobe in $x$ is of the order of the first extremum or zero of this function in the $y$ domain, which occurs at $y=O(1)$. Thus, $x = y/(N+1/2) \\propto 1/N$. This establishes the first claim.\n\nNow we analyze the overshoot. We are interested in $S_N(x) - f(0^{+})$:\n$$\nS_N(x) - f(0^{+}) \\approx S_N[g](x) - f(0^{+}) = \\left(\\frac{f(0^{-}) + f(0^{+})}{2} - f(0^{+})\\right) + \\frac{A}{\\pi} \\text{Si}((N+1/2)x).\n$$\n$$\nS_N(x) - f(0^{+}) \\approx -\\frac{A}{2} + \\frac{A}{\\pi} \\text{Si}((N+1/2)x) = A \\left( \\frac{1}{\\pi} \\text{Si}((N+1/2)x) - \\frac{1}{2} \\right).\n$$\nTo find the maximum overshoot, we must find the maximum value of this expression for small $x>0$. This corresponds to finding the maximum value of $\\text{Si}(y)$ for $y>0$. The derivative is $\\frac{d}{dy}\\text{Si}(y) = \\frac{\\sin y}{y}$. The first positive extremum occurs when $\\sin y = 0$, which is at $y=\\pi$. This is a maximum because the second derivative at $y=\\pi$ is $(\\frac{\\cos y}{y} - \\frac{\\sin y}{y^2})|_{y=\\pi} = -\\frac{1}{\\pi}  0$.\nThe maximum is achieved when $(N+1/2)x = \\pi$, or $x_{\\text{max}} = \\frac{\\pi}{N+1/2}$.\nThe location of the maximum overshoot $x_{\\text{max}}$ scales as $1/N$, confirming the previous finding. The height of the maximum overshoot for large $N$ approaches a constant value:\n$$\n\\max_{x\\ \\text{near }0}\\big(S_{N}(x)-f(0^{+})\\big) \\to A \\left( \\frac{1}{\\pi} \\text{Si}(\\pi) - \\frac{1}{2} \\right).\n$$\nThis value is proportional to the jump amplitude $A$ and does not decay as $N \\to \\infty$. This establishes the second claim.\n\nFinally, we compute the required normalized quantity:\n$$\n\\lim_{N\\to\\infty}\\,\\frac{\\max_{x\\ \\text{near }0}\\big(S_{N}(x)-f(0^{+})\\big)}{A} = \\frac{1}{A} \\left[ A \\left( \\frac{1}{\\pi} \\text{Si}(\\pi) - \\frac{1}{2} \\right) \\right] = \\frac{1}{\\pi} \\text{Si}(\\pi) - \\frac{1}{2}.\n$$\nThe value $\\text{Si}(\\pi)$ is given by the integral $\\int_0^\\pi \\frac{\\sin t}{t} dt$. The final answer is thus expressed in terms of this integral and elementary constants.\n$$\n\\frac{1}{\\pi} \\int_0^\\pi \\frac{\\sin t}{t} dt - \\frac{1}{2}.\n$$", "answer": "$$\n\\boxed{\\frac{1}{\\pi}\\int_{0}^{\\pi}\\frac{\\sin(t)}{t}dt - \\frac{1}{2}}\n$$", "id": "2860329"}]}