{"hands_on_practices": [{"introduction": "The convolution integral is the cornerstone of LTI system analysis, yet its abstract definition can sometimes obscure its physical or operational meaning. This first practice grounds the concept by connecting it to the familiar operation of repeated integration [@problem_id:2894646]. By demonstrating that a cascade of integrators forms an LTI system, you will derive its impulse response from first principles and see directly how this response, through convolution, transforms an input signal.", "problem": "Consider the causal repeated-integration operator defined recursively on a signal $x(t)$ by $y_{0}(t)=x(t)$ and $y_{i}(t)=\\int_{0}^{t} y_{i-1}(\\tau)\\, \\mathrm{d}\\tau$ for each integer $i \\geq 1$. Let $T_{k}$ denote the $k$-fold integrator mapping $x$ to $y_{k}$, where $k \\in \\mathbb{N}$. The unit-step function is $u(t)$ and the Dirac delta is $\\delta(t)$.\n\nTasks:\n- Using only the fundamental definitions of linearity, time-invariance, and convolution for Linear Time-Invariant (LTI) systems, show that $T_{k}$ is Linear Time-Invariant (LTI) and that its impulse response $h_{k}(t)$ equals the $k$-fold autoconvolution of the unit-step function. Derive a closed-form expression for $h_{k}(t)$ from first principles.\n- Then, for $k=3$ and input $x(t)=\\big(5 t^{3}-2 t+4\\big)\\,u(t)$, compute the output $y(t)=(T_{3}x)(t)$ and simplify it to a single analytic expression in $t$ using $u(t)$.\n\nState your final answer as a single closed-form expression in $t$; no rounding is required and no units are involved. Angles, if any appear, must be in radians.", "solution": "The problem as stated is subjected to validation.\n\n**Step 1: Extract Givens**\n\n-   The repeated-integration operator is defined by $y_{0}(t)=x(t)$ and $y_{i}(t)=\\int_{0}^{t} y_{i-1}(\\tau)\\, \\mathrm{d}\\tau$ for $i \\geq 1$.\n-   $T_{k}$ denotes the $k$-fold integrator, mapping an input signal $x(t)$ to an output signal $y_{k}(t) = (T_k x)(t)$. The domain for $k$ is the set of natural numbers $\\mathbb{N}$.\n-   Standard signals are the unit-step function $u(t)$ and the Dirac delta function $\\delta(t)$.\n-   Task 1: Demonstrate that $T_{k}$ is a Linear Time-Invariant (LTI) system. Show its impulse response $h_{k}(t)$ is the $k$-fold autoconvolution of $u(t)$. Derive a closed-form expression for $h_{k}(t)$ from first principles.\n-   Task 2: For $k=3$ and input $x(t)=\\big(5 t^{3}-2 t+4\\big)\\,u(t)$, compute the output $y(t)=(T_{3}x)(t)$ and present it as a single simplified analytical expression.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in linear systems theory, addressing fundamental properties like linearity, time-invariance, impulse response, and convolution. The definitions are precise, and the tasks are mathematically formalizable and solvable. The provided operator is a causal integrator, and the specified input signal is a causal polynomial, which is standard. There are no scientific or logical contradictions, no missing information, and no ambiguities that would prevent a unique, meaningful solution.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. A solution will be provided.\n\nWe address the two parts of the problem sequentially.\n\n**Part 1: Analysis of the Operator $T_k$**\n\nFirst, we must prove that the operator $T_k$ is Linear Time-Invariant (LTI).\n\n**Linearity:**\nWe will prove linearity by induction on $k$.\nA system $T$ is linear if $T(a_1 x_1(t) + a_2 x_2(t)) = a_1 (T x_1)(t) + a_2 (T x_2)(t)$.\nBase case ($k=1$): The operator is $T_1$, defined as $(T_1 x)(t) = \\int_{0}^{t} x(\\tau) d\\tau$.\nLet the input be $z(t) = a_1 x_1(t) + a_2 x_2(t)$. The output is:\n$$ (T_1 z)(t) = \\int_{0}^{t} (a_1 x_1(\\tau) + a_2 x_2(\\tau)) d\\tau $$\nBy the linearity property of the integral:\n$$ (T_1 z)(t) = a_1 \\int_{0}^{t} x_1(\\tau) d\\tau + a_2 \\int_{0}^{t} x_2(\\tau) d\\tau = a_1 (T_1 x_1)(t) + a_2 (T_1 x_2)(t) $$\nThus, $T_1$ is a linear operator.\nInductive step: Assume that $T_{k-1}$ is linear for some $k-1 \\ge 1$. We must show that $T_k$ is linear.\nThe operator $T_k$ is defined as $(T_k x)(t) = \\int_{0}^{t} (T_{k-1} x)(\\tau) d\\tau = (T_1 (T_{k-1} x))(t)$.\nLet the input be $z(t) = a_1 x_1(t) + a_2 x_2(t)$.\n$$ (T_k z)(t) = (T_1 (T_{k-1} z))(t) = \\int_{0}^{t} (T_{k-1} z)(\\tau) d\\tau $$\nBy the inductive hypothesis, $T_{k-1}$ is linear, so $(T_{k-1} z)(\\tau) = a_1 (T_{k-1} x_1)(\\tau) + a_2 (T_{k-1} x_2)(\\tau)$.\nSubstituting this into the integral:\n$$ (T_k z)(t) = \\int_{0}^{t} (a_1 (T_{k-1} x_1)(\\tau) + a_2 (T_{k-1} x_2)(\\tau)) d\\tau $$\n$$ = a_1 \\int_{0}^{t} (T_{k-1} x_1)(\\tau) d\\tau + a_2 \\int_{0}^{t} (T_{k-1} x_2)(\\tau) d\\tau = a_1 (T_k x_1)(t) + a_2 (T_k x_2)(t) $$\nThe operator $T_k$ is linear for all $k \\in \\mathbb{N}$ by induction.\n\n**Time-Invariance:**\nA system $T$ is time-invariant if for an output $y(t) = (Tx)(t)$, the output to a shifted input $x(t-t_0)$ is the shifted output $y(t-t_0)$. The operator $(T_1 x)(t) = \\int_0^t x(\\tau)d\\tau$ is only time-invariant under the constraint of causal signals, i.e., signals $x(t)$ such that $x(t)=0$ for $t0$. This is a standard convention in system analysis involving such causal integrators.\nLet $x(t)$ be a causal signal. Let $y_k(t) = (T_k x)(t)$. We must show that $(T_k x(t-t_0)) = y_k(t-t_0)$ for any $t_0  0$. We proceed by induction.\nBase case ($k=1$): Let $y_1(t) = \\int_0^t x(\\tau)d\\tau$. The shifted output is $y_1(t-t_0) = \\int_0^{t-t_0} x(\\tau)d\\tau$. The output to the shifted input $x_d(t) = x(t-t_0)$ is $y_{1,d}(t) = \\int_0^t x(\\tau-t_0)d\\tau$. Since $x(t)$ is causal, $x(\\tau-t_0)$ is zero for $\\tau  t_0$. Thus, for $t \\ge t_0$, we can change the lower limit of integration to $t_0$: $y_{1,d}(t) = \\int_{t_0}^t x(\\tau-t_0)d\\tau$. Let $u=\\tau-t_0$, so $du=d\\tau$. The limits become $u=0$ and $u=t-t_0$. Then $y_{1,d}(t) = \\int_0^{t-t_0} x(u)du = y_1(t-t_0)$. For $tt_0$, $y_{1,d}(t)=0$ and $y_1(t-t_0)=0$. Thus $T_1$ is time-invariant for causal signals.\nInductive Step: Assume $T_{k-1}$ is time-invariant for causal signals. Let $y_k(t) = (T_k x)(t)$ and let $z(t) = (T_{k-1} x)(t)$. If $x(t)$ is causal, then $z(t)$ is also causal.\nThe output to the shifted input $x(t-t_0)$ is $(T_k x(t-t_0)) = (T_1 (T_{k-1} x(t-t_0)))(t)$.\nBy the inductive hypothesis, $(T_{k-1} x(t-t_0)) = z(t-t_0)$.\nSo, $(T_k x(t-t_0)) = (T_1 z(t-t_0))(t)$. From the base case, we know $T_1$ is time-invariant for causal signals like $z(t)$, hence $(T_1 z(t-t_0))(t) = y_k(t-t_0)$.\nThus, $T_k$ is time-invariant for all $k \\in \\mathbb{N}$ for causal signals.\nSince $T_k$ is both linear and time-invariant, it is an LTI system (for causal inputs).\n\n**Impulse Response and relation to Convolution:**\nThe impulse response $h_k(t)$ is the output of $T_k$ when the input is the Dirac delta function, $x(t)=\\delta(t)$.\nFor $k=1$, $h_1(t) = \\int_0^t \\delta(\\tau) d\\tau$. This integral is $0$ for $t0$ and $1$ for $t0$. This is the definition of the unit-step function $u(t)$. So, $h_1(t) = u(t)$.\nThe operator $T_k$ is a cascade of $k$ identical operators $T_1$. For LTI systems, the impulse response of a cascade is the convolution of the individual impulse responses.\nTherefore, $h_k(t) = \\underbrace{h_1(t) * h_1(t) * \\dots * h_1(t)}_{k \\text{ times}}$.\nSince $h_1(t) = u(t)$, we have shown that $h_k(t)$ is the $k$-fold autoconvolution of the unit-step function:\n$$ h_k(t) = \\underbrace{u(t) * u(t) * \\dots * u(t)}_{k \\text{ times}} $$\n\n**Closed-form expression for $h_k(t)$:**\nWe derive the expression from first principles, i.e., from the recursive definition of the operator with $x(t)=\\delta(t)$.\n$h_k(t) = \\int_0^t h_{k-1}(\\tau)d\\tau$.\nWe have $h_1(t) = u(t)$.\n$h_2(t) = \\int_0^t h_1(\\tau)d\\tau = \\int_0^t u(\\tau)d\\tau = \\int_0^t 1 \\cdot d\\tau = t$ for $t0$. So, $h_2(t) = t u(t)$.\n$h_3(t) = \\int_0^t h_2(\\tau)d\\tau = \\int_0^t \\tau u(\\tau)d\\tau = \\int_0^t \\tau d\\tau = \\frac{t^2}{2}$ for $t0$. So, $h_3(t) = \\frac{t^2}{2} u(t)$.\nWe hypothesize the general form $h_k(t) = \\frac{t^{k-1}}{(k-1)!} u(t)$.\nWe prove this by induction.\nBase case ($k=1$): $h_1(t) = \\frac{t^{1-1}}{(1-1)!} u(t) = \\frac{t^0}{0!} u(t) = u(t)$. Correct.\nInductive step: Assume $h_{k-1}(t) = \\frac{t^{k-2}}{(k-2)!} u(t)$.\nThen $h_k(t) = \\int_0^t h_{k-1}(\\tau)d\\tau = \\int_0^t \\frac{\\tau^{k-2}}{(k-2)!} u(\\tau)d\\tau$.\nFor $t  0$, this becomes:\n$$ h_k(t) = \\frac{1}{(k-2)!} \\int_0^t \\tau^{k-2} d\\tau = \\frac{1}{(k-2)!} \\left[ \\frac{\\tau^{k-1}}{k-1} \\right]_0^t = \\frac{1}{(k-2)!} \\frac{t^{k-1}}{k-1} = \\frac{t^{k-1}}{(k-1)!} $$\nFor $t  0$, the integral is $0$. Thus, the expression $h_k(t) = \\frac{t^{k-1}}{(k-1)!} u(t)$ is correct for all $k \\ge 1$.\n\n**Part 2: Output Calculation**\n\nWe need to compute $y(t) = (T_3 x)(t)$ for the input $x(t)=(5t^3-2t+4)u(t)$.\nThis is equivalent to integrating the input signal three times from $0$ to $t$.\nLet $x_p(t) = 5t^3-2t+4$. The input is $x(t)=x_p(t)u(t)$.\n\nFirst integration:\n$y_1(t) = \\int_0^t x(\\tau)d\\tau = \\int_0^t (5\\tau^3-2\\tau+4)d\\tau$ for $t \\ge 0$.\n$$ y_1(t) = \\left[ 5\\frac{\\tau^4}{4} - 2\\frac{\\tau^2}{2} + 4\\tau \\right]_0^t = \\frac{5}{4}t^4 - t^2 + 4t $$\nThis result is for $t \\ge 0$, so we write $y_1(t) = (\\frac{5}{4}t^4 - t^2 + 4t)u(t)$.\n\nSecond integration:\n$y_2(t) = \\int_0^t y_1(\\tau)d\\tau = \\int_0^t (\\frac{5}{4}\\tau^4 - \\tau^2 + 4\\tau)d\\tau$ for $t \\ge 0$.\n$$ y_2(t) = \\left[ \\frac{5}{4}\\frac{\\tau^5}{5} - \\frac{\\tau^3}{3} + 4\\frac{\\tau^2}{2} \\right]_0^t = \\frac{1}{4}t^5 - \\frac{1}{3}t^3 + 2t^2 $$\nSo, $y_2(t) = (\\frac{1}{4}t^5 - \\frac{1}{3}t^3 + 2t^2)u(t)$.\n\nThird integration:\n$y_3(t) = \\int_0^t y_2(\\tau)d\\tau = \\int_0^t (\\frac{1}{4}\\tau^5 - \\frac{1}{3}\\tau^3 + 2\\tau^2)d\\tau$ for $t \\ge 0$.\n$$ y_3(t) = \\left[ \\frac{1}{4}\\frac{\\tau^6}{6} - \\frac{1}{3}\\frac{\\tau^4}{4} + 2\\frac{\\tau^3}{3} \\right]_0^t = \\frac{1}{24}t^6 - \\frac{1}{12}t^4 + \\frac{2}{3}t^3 $$\nThe final output is $y(t) = y_3(t)$, and since the process guarantees a causal output for a causal input, we must include the unit-step function.\n$$ y(t) = \\left(\\frac{1}{24}t^6 - \\frac{1}{12}t^4 + \\frac{2}{3}t^3\\right) u(t) $$\nThis is the simplified analytic expression for the output signal.", "answer": "$$\\boxed{\\left(\\frac{1}{24}t^{6} - \\frac{1}{12}t^{4} + \\frac{2}{3}t^{3}\\right)u(t)}$$", "id": "2894646"}, {"introduction": "While convolution is a fundamental tool, its algebraic properties, such as associativity, are what give it such a powerful and consistent structure. This practice explores this uniqueness by contrasting convolution with its close cousin, cross-correlation [@problem_id:2894693]. You will construct a concrete counterexample and a general proof to demonstrate why correlation fails to be associative, revealing the crucial role of time-reversal in the definition of convolution and deepening your appreciation for its specific mathematical form.", "problem": "Let $x[n]$, $y[n]$, and $z[n]$ be real-valued, absolutely summable, discrete-time signals with finite support. Define the discrete-time convolution by $(x * y)[n] = \\sum_{k \\in \\mathbb{Z}} x[k]\\,y[n-k]$ and the discrete-time (non-conjugating) cross-correlation by $(x \\star y)[n] = \\sum_{k \\in \\mathbb{Z}} x[k]\\,y[k+n]$. Consider the specific sequences given by $x[0] = 1$, $x[1] = 2$, $y[0] = 3$, $y[1] = 4$, $z[0] = 5$, $z[1] = 6$, and $x[n] = y[n] = z[n] = 0$ for all other $n \\in \\mathbb{Z}$. Using only the stated definitions and the time-reversal operator $\\mathcal{R}$ defined by $(\\mathcal{R}w)[n] = w[-n]$ for any signal $w[n]$, do the following: \n1) Compute the scalar difference $\\Delta = \\big((x \\star y) \\star z\\big)[0] - \\big(x \\star (y \\star z)\\big)[0]$ exactly. \n2) Provide a derivation from first principles that explains structurally why replacing convolution by correlation destroys associativity in general, explicitly linking your argument to the role of time reversal. Your derivation must begin from the definitions above and basic properties of sums, and it must identify the feature of $\\mathcal{R}$ that is responsible for the failure of associativity. \nReport only the final value of $\\Delta$ as your answer. No rounding is required.", "solution": "The problem statement is scientifically grounded, well-posed, and objective. All definitions and signal values are provided, forming a self-contained and consistent problem in discrete-time signal processing. The problem is valid and a solution will be provided.\n\nThe problem is composed of two parts: a specific numerical calculation and a general structural derivation. We will first provide the general derivation for why cross-correlation is not associative, as this gives the theoretical foundation for the numerical result. Then, we will perform the explicit calculation.\n\nPart 2: Structural Derivation of Non-Associativity\nThe non-associativity of the cross-correlation operation, denoted by $\\star$, can be demonstrated by relating it to the associative convolution operation, denoted by $*$, through the time-reversal operator $(\\mathcal{R}w)[n] = w[-n]$.\n\nFirst, we establish the relationship between cross-correlation and convolution. By the given definition, $(u \\star v)[n] = \\sum_{k \\in \\mathbb{Z}} u[k]v[k+n]$. Let us relate this to convolution using the time-reversal of the first signal, $u[n]$. The convolution of $(\\mathcal{R}u)[n]$ with $v[n]$ is given by:\n$$ ((\\mathcal{R}u) * v)[n] = \\sum_{k \\in \\mathbb{Z}} (\\mathcal{R}u)[k] v[n-k] = \\sum_{k \\in \\mathbb{Z}} u[-k] v[n-k] $$\nLet $m = -k$. As $k$ ranges over all integers $\\mathbb{Z}$, so does $m$. The summation becomes:\n$$ \\sum_{m \\in \\mathbb{Z}} u[m] v[n+m] = \\sum_{m \\in \\mathbb{Z}} u[m] v[m+n] $$\nThis is precisely the definition of $(u \\star v)[n]$. Thus, we have the identity:\n$$ (u \\star v)[n] = ((\\mathcal{R}u) * v)[n] $$\n\nNext, we establish two key properties of the time-reversal operator $\\mathcal{R}$:\n$1$. It is an involution, meaning applying it twice returns the original signal: $(\\mathcal{R}(\\mathcal{R}u))[n] = (\\mathcal{R}u)[-n] = u[-(-n)] = u[n]$. So, $\\mathcal{R}\\mathcal{R} = I$, the identity operator.\n$2$. It distributes over convolution: $(\\mathcal{R}(a*b))[n] = ((\\mathcal{R}a)*(\\mathcal{R}b))[n]$. To prove this, we write:\n$$ ((\\mathcal{R}a)*(\\mathcal{R}b))[n] = \\sum_{k \\in \\mathbb{Z}} (\\mathcal{R}a)[k] (\\mathcal{R}b)[n-k] = \\sum_{k \\in \\mathbb{Z}} a[-k] b[-(n-k)] = \\sum_{k \\in \\mathbb{Z}} a[-k] b[k-n] $$\nNow, consider $(\\mathcal{R}(a*b))[n] = (a*b)[-n] = \\sum_{j \\in \\mathbb{Z}} a[j] b[-n-j]$. Let $j=-k$, so $k=-j$.\n$$ \\sum_{k \\in \\mathbb{Z}} a[-k] b[-n+k] = \\sum_{k \\in \\mathbb{Z}} a[-k] b[k-n] $$\nThe expressions are identical, so the property $\\mathcal{R}(a*b) = (\\mathcal{R}a)*(\\mathcal{R}b)$ is correct.\n\nNow, we analyze the two groupings for the triple cross-correlation. For the left-to-right grouping, let $w[n] = (x \\star y)[n]$.\n$$ ((x \\star y) \\star z)[n] = (w \\star z)[n] = ((\\mathcal{R}w) * z)[n] $$\nWe have $w[n] = (x \\star y)[n] = ((\\mathcal{R}x) * y)[n]$. Substituting this into the expression:\n$$ ((x \\star y) \\star z)[n] = (\\mathcal{R}((\\mathcal{R}x) * y) * z)[n] $$\nUsing the distributive property of $\\mathcal{R}$ over convolution:\n$$ \\mathcal{R}((\\mathcal{R}x) * y) = (\\mathcal{R}(\\mathcal{R}x)) * (\\mathcal{R}y) = x * (\\mathcal{R}y) $$\nHere, we have used the involutory property $\\mathcal{R}(\\mathcal{R}x) = x$. The left grouping becomes:\n$$ ((x \\star y) \\star z)[n] = ((x * (\\mathcal{R}y)) * z)[n] $$\n\nFor the right-to-left grouping, let $v[n] = (y \\star z)[n]$.\n$$ (x \\star (y \\star z))[n] = (x \\star v)[n] = ((\\mathcal{R}x) * v)[n] $$\nWe have $v[n] = (y \\star z)[n] = ((\\mathcal{R}y) * z)[n]$. Substituting for $v$:\n$$ (x \\star (y \\star z))[n] = ((\\mathcal{R}x) * ((\\mathcal{R}y) * z))[n] $$\n\nConvolution is associative, so we can write $(a*b)*c = a*(b*c)$. Applying this, the two expressions are:\n$$ ((x \\star y) \\star z)[n] = (x * (\\mathcal{R}y) * z)[n] $$\n$$ (x \\star (y \\star z))[n] = ((\\mathcal{R}x) * (\\mathcal{R}y) * z)[n] $$\nThese two expressions are not equal in general, because convolution is a linear operation and $(\\mathcal{R}x)[n] = x[-n]$ is not in general equal to $x[n]$. The expressions are equal only if $x[n]=(\\mathcal{R}x)[n]$, i.e., if $x[n]$ is an even signal.\n\nThe failure of associativity for cross-correlation is therefore structurally rooted in its definition, which asymmetrically applies a time reversal to its first argument. The key feature of the operator $\\mathcal{R}$ responsible for this is its involutory nature ($\\mathcal{R}^2 = I$). When grouped as $((x \\star y) \\star z)$, the signal $x$ is effectively time-reversed twice, cancelling the effect, while in the $(x \\star (y \\star z))$ grouping, it is reversed only once. This produces the discrepancy between $x$ and $\\mathcal{R}x$ in the final convolution-based expressions.\n\nPart 1: Numerical Calculation of $\\Delta$\nWe are asked to compute $\\Delta = \\big((x \\star y) \\star z\\big)[0] - \\big(x \\star (y \\star z)\\big)[0]$.\nThe signals are given by $x[0]=1$, $x[1]=2$; $y[0]=3$, $y[1]=4$; $z[0]=5$, $z[1]=6$; and are zero otherwise.\n\nFirst, we compute the term $\\big((x \\star y) \\star z\\big)[0]$.\nLet $w[n] = (x \\star y)[n] = \\sum_{k \\in \\mathbb{Z}} x[k] y[k+n]$. The sum is non-zero only for $k=0,1$.\n$$ w[n] = x[0] y[n] + x[1] y[1+n] = 1 \\cdot y[n] + 2 \\cdot y[1+n] = y[n] + 2y[1+n] $$\nThe outer correlation is $(w \\star z)[n]$, and we evaluate it at $n=0$:\n$$ (w \\star z)[0] = \\sum_{k \\in \\mathbb{Z}} w[k] z[k] $$\nThe sum is non-zero only for $k=0,1$ since $z[k]$ is zero otherwise. We need $w[0]$ and $w[1]$.\n$$ w[0] = y[0] + 2y[1] = 3 + 2(4) = 11 $$\n$$ w[1] = y[1] + 2y[2] = 4 + 2(0) = 4 $$\nTherefore, the first term is:\n$$ \\big((x \\star y) \\star z\\big)[0] = w[0]z[0] + w[1]z[1] = (11)(5) + (4)(6) = 55 + 24 = 79 $$\n\nNext, we compute the term $\\big(x \\star (y \\star z)\\big)[0]$.\nLet $v[n] = (y \\star z)[n] = \\sum_{k \\in \\mathbb{Z}} y[k] z[k+n]$. The sum is non-zero only for $k=0,1$.\n$$ v[n] = y[0] z[n] + y[1] z[1+n] = 3z[n] + 4z[1+n] $$\nThe outer correlation is $(x \\star v)[n]$, and we evaluate it at $n=0$:\n$$ (x \\star v)[0] = \\sum_{k \\in \\mathbb{Z}} x[k] v[k] $$\nThe sum is non-zero only for $k=0,1$ since $x[k]$ is zero otherwise. We need $v[0]$ and $v[1]$.\n$$ v[0] = 3z[0] + 4z[1] = 3(5) + 4(6) = 15 + 24 = 39 $$\n$$ v[1] = 3z[1] + 4z[2] = 3(6) + 4(0) = 18 $$\nTherefore, the second term is:\n$$ \\big(x \\star (y \\star z)\\big)[0] = x[0]v[0] + x[1]v[1] = (1)(39) + (2)(18) = 39 + 36 = 75 $$\n\nFinally, we compute the difference $\\Delta$:\n$$ \\Delta = 79 - 75 = 4 $$\nThe numerical result confirms the non-associativity demonstrated in the structural derivation.", "answer": "$$\\boxed{4}$$", "id": "2894693"}, {"introduction": "In the world of digital signal processing, linear convolution is often implemented efficiently using the Fast Fourier Transform (FFT). However, this computational shortcut introduces a critical distinction between the desired linear convolution and the circular convolution that the DFT naturally computes. This exercise tasks you with deriving the precise relationship between these two operations from the time domain, revealing how insufficient zero-padding leads to the phenomenon of time-domain aliasing [@problem_id:2894647].", "problem": "Consider two finite-length discrete-time signals in a linear time-invariant setting, and let $y[n]$ denote their linear convolution. Let $\\tilde{y}[n]$ denote the $N$-point circular convolution of the same signals, obtained by evaluating the convolution sum using period-$N$ extensions of the signals (as is done when one uses the $N$-point Discrete Fourier Transform (DFT) without sufficient zero-padding). Work from first principles: use only the definitions of linear convolution and $N$-point circular convolution as your starting point, and reason from those definitions.\n\nPart 1 (derivation): Starting from the definitions of linear convolution and $N$-point circular convolution in the time domain, derive an explicit identity that shows how circular-convolution aliasing arises from wrap-around, i.e., show that for $n \\in \\{0,1,\\dots,N-1\\}$, the $N$-point circular convolution can be written as a sum of shifted copies of the linear convolution $y[n]$. Your derivation must not invoke any transform-domain convolution theorems; it must proceed from the time-domain definitions.\n\nPart 2 (computation of the aliasing term): Let $x[n]$ and $h[n]$ be the finite-length sequences\n$$\nx[n] = \\begin{cases}\n1,  0 \\le n \\le 4,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n\\qquad\nh[n] = \\begin{cases}\n1,  0 \\le n \\le 3,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nLet $N=6$. Define the aliasing term $a[n]$ for $n \\in \\{0,1,\\dots,N-1\\}$ by\n$$\na[n] \\triangleq \\tilde{y}[n] - y[n],\n$$\nwhere by convention $y[n]=0$ outside its natural support. Using your identity from Part $1$, compute $a[n]$ exactly for $n \\in \\{0,1,\\dots,5\\}$, and present your result as a length-$6$ row vector in the order $n=0,1,2,3,4,5$. No rounding is required, and no units are involved.", "solution": "The problem statement has been validated and is deemed sound. It is a well-posed problem in the field of digital signal processing, grounded in established mathematical definitions and free of scientific or logical flaws. We may proceed with the solution.\n\nThis problem demands a rigorous, time-domain derivation of the relationship between linear and circular convolution, followed by a direct computation based on this derived identity.\n\nPart 1: Derivation of the Aliasing Identity\n\nWe begin from first principles, namely the definitions of linear and $N$-point circular convolution.\n\nLet $x[n]$ and $h[n]$ be two discrete-time sequences of finite length. Let the support of $x[n]$ be $\\{0, 1, \\dots, L_x-1\\}$ and the support of $h[n]$ be $\\{0, 1, \\dots, L_h-1\\}$.\n\nThe linear convolution, denoted $y[n]$, is defined as:\n$$\ny[n] = (x * h)[n] = \\sum_{k=-\\infty}^{\\infty} x[k] h[n-k]\n$$\nGiven the finite, causal nature of the signals, the effective summation range for $k$ is from $0$ to $n$. The resulting sequence $y[n]$ has a finite support of length $L_y = L_x + L_h - 1$, specifically for $n \\in \\{0, 1, \\dots, L_x+L_h-2\\}$.\n\nThe $N$-point circular convolution, denoted $\\tilde{y}[n]$, is defined for $n \\in \\{0, 1, \\dots, N-1\\}$. The problem specifies it is obtained using period-$N$ extensions of the signals. This is equivalent to performing the convolution operation in the ring of integers modulo $N$. A direct time-domain definition is:\n$$\n\\tilde{y}[n] = \\sum_{k=0}^{N-1} x_N[k] h_N[(n-k) \\pmod N]\n$$\nwhere $x_N[n]$ and $h_N[n]$ are the sequences $x[n]$ and $h[n]$ respectively, considered over the interval $n \\in \\{0, 1, \\dots, N-1\\}$. If the original sequences have lengths less than or equal to $N$, as is the case in Part 2, then $x_N[n] = x[n]$ and $h_N[n] = h[n]$ within this interval and are zero otherwise where relevant.\n\nThe expression $h_N[(n-k) \\pmod N]$ represents the value of the periodic extension of $h_N[n]$ at time index $n-k$. Let us denote this periodic sequence as $h_{N,p}[m]$. This sequence can be constructed from the finite-length sequence $h_N[m]$ by summation:\n$$\nh_{N,p}[m] = \\sum_{r=-\\infty}^{\\infty} h_N[m - rN]\n$$\nThen, we can write $h_N[(n-k) \\pmod N] = h_{N,p}[n-k]$. Substituting this into the definition of circular convolution:\n$$\n\\tilde{y}[n] = \\sum_{k=0}^{N-1} x_N[k] h_{N,p}[n-k]\n$$\nNow, substitute the summation form of $h_{N,p}[n-k]$:\n$$\n\\tilde{y}[n] = \\sum_{k=0}^{N-1} x_N[k] \\left( \\sum_{r=-\\infty}^{\\infty} h_N[(n-k)-rN] \\right)\n$$\nThe summations are over finite and absolutely convergent series, so we may interchange their order:\n$$\n\\tilde{y}[n] = \\sum_{r=-\\infty}^{\\infty} \\sum_{k=0}^{N-1} x_N[k] h_N[n-k-rN]\n$$\nLet us examine the inner sum. Since the support of $x_N[k]$ is contained within $\\{0, 1, \\dots, N-1\\}$, the limits of summation over $k$ can be extended to $\\pm\\infty$ without changing the value:\n$$\n\\sum_{k=0}^{N-1} x_N[k] h_N[n-k-rN] = \\sum_{k=-\\infty}^{\\infty} x_N[k] h_N[n-k-rN]\n$$\nThis expression is precisely the linear convolution of $x_N[n]$ and $h_N[n]$, evaluated at the time index $n-rN$. Let us call this linear convolution $y_N[n] = (x_N * h_N)[n]$.\n$$\n\\sum_{k=-\\infty}^{\\infty} x_N[k] h_N[n-k-rN] = y_N[n-rN]\n$$\nIf we assume, as is true in Part 2, that the lengths of the original signals are less than $N$ (i.e., $L_x \\le N$ and $L_h \\le N$), then $x_N[n]=x[n]$ and $h_N[n]=h[n]$. Consequently, their linear convolution is identical to the original, $y_N[n] = y[n]$.\n\nSubstituting this back into our expression for $\\tilde{y}[n]$ gives the final identity:\n$$\n\\tilde{y}[n] = \\sum_{r=-\\infty}^{\\infty} y[n-rN]\n$$\nFor consistency with common literature, we can change the summation index by letting $l = -r$:\n$$\n\\tilde{y}[n] = \\sum_{l=-\\infty}^{\\infty} y[n+lN]\n$$\nThis identity demonstrates that the $N$-point circular convolution $\\tilde{y}[n]$ for $n \\in \\{0, 1, \\dots, N-1\\}$ is formed by summing the linear convolution $y[n]$ and all its versions shifted by integer multiples of $N$. This phenomenon is the time-domain aliasing or \"wrap-around\" effect.\n\nPart 2: Computation of the Aliasing Term\n\nWe are given the signals:\n$$\nx[n] = \\begin{cases}\n1,  0 \\le n \\le 4,\\\\\n0,  \\text{otherwise},\n\\end{cases}\n\\qquad\nh[n] = \\begin{cases}\n1,  0 \\le n \\le 3,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThe lengths are $L_x=5$ and $L_h=4$. The circular convolution is performed with $N=6$.\n\nFirst, we compute the linear convolution $y[n] = (x * h)[n]$. This is the convolution of two rectangular pulses of amplitudes $1$ and lengths $5$ and $4$. The result is a trapezoidal sequence of length $L_y = L_x+L_h-1 = 5+4-1=8$. The support is $n \\in \\{0, 1, \\dots, 7\\}$.\nThe values are found by evaluating the convolution sum $y[n] = \\sum_{k=\\max(0, n-3)}^{\\min(4, n)} 1$.\nFor $n=0$: $y[0] = 1$.\nFor $n=1$: $y[1] = 2$.\nFor $n=2$: $y[2] = 3$.\nFor $n=3$: $y[3] = 4$.\nFor $n=4$: $y[4] = 4$.\nFor $n=5$: $y[5] = 3$.\nFor $n=6$: $y[6] = 2$.\nFor $n=7$: $y[7] = 1$.\nFor all other $n$, $y[n]=0$. In sequence form: $y[n] = \\{1, 2, 3, 4, 4, 3, 2, 1\\}$ for $n \\in \\{0, \\dots, 7\\}$.\n\nThe aliasing term is defined as $a[n] = \\tilde{y}[n] - y[n]$ for $n \\in \\{0, 1, \\dots, N-1\\}$. Using our derived identity:\n$$\na[n] = \\left( \\sum_{l=-\\infty}^{\\infty} y[n+lN] \\right) - y[n]\n$$\nThe $l=0$ term is $y[n]$, which cancels.\n$$\na[n] = \\sum_{l \\neq 0, l=-\\infty}^{\\infty} y[n+lN]\n$$\nThis can be split into sums for positive and negative $l$:\n$$\na[n] = \\sum_{l=1}^{\\infty} y[n+lN] + \\sum_{l=1}^{\\infty} y[n-lN]\n$$\nSince $y[n]$ is causal ($y[m]=0$ for $m0$), and we are evaluating $a[n]$ for $n \\in \\{0, 1, \\dots, N-1\\}$, the term $n-lN$ will always be negative for $l \\ge 1$. For example, with $N=6$ and $l=1$, $n-6$ is negative for $n \\in \\{0, \\dots, 5\\}$. Thus, the second sum is zero.\n$$\na[n] = \\sum_{l=1}^{\\infty} y[n+lN] = y[n+N] + y[n+2N] + \\dots\n$$\nWe have $N=6$. The support of $y[n]$ is $\\{0, \\dots, 7\\}$.\nFor any $n \\ge 0$, $n+2N = n+12$ is greater than $7$, so $y[n+12]$ and all higher terms are zero.\nThe aliasing term simplifies to:\n$$\na[n] = y[n+6]\n$$\nWe compute this for $n \\in \\{0, 1, 2, 3, 4, 5\\}$:\n$a[0] = y[0+6] = y[6] = 2$.\n$a[1] = y[1+6] = y[7] = 1$.\n$a[2] = y[2+6] = y[8] = 0$.\n$a[3] = y[3+6] = y[9] = 0$.\n$a[4] = y[4+6] = y[10] = 0$.\n$a[5] = y[5+6] = y[11] = 0$.\n\nThe resulting aliasing term $a[n]$ for $n \\in \\{0, \\dots, 5\\}$ is the sequence $\\{2, 1, 0, 0, 0, 0\\}$. As a row vector, this is $\\begin{pmatrix} 2  1  0  0  0  0 \\end{pmatrix}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  1  0  0  0  0\n\\end{pmatrix}\n}\n$$", "id": "2894647"}]}