{"hands_on_practices": [{"introduction": "This practice reinforces the fundamental connection between a system's time-domain behavior and its representation in the Laplace domain. By deriving the system's output through direct convolution, you will gain hands-on experience with the integral that defines how a linear time-invariant (LTI) system transforms an input signal. This exercise [@problem_id:2910739] also highlights the critical role of the Region of Convergence (ROC) in ensuring the solution aligns with the physical property of causality.", "problem": "Consider a causal Linear Time-Invariant (LTI) continuous-time system with zero initial conditions, whose transfer function in the Laplace domain is\n$$\nH(s) \\;=\\; \\frac{s + 2}{(s + 1)\\,(s + 3)^{2}} \\, .\n$$\nThe input is\n$$\nx(t) \\;=\\; \\exp(a t)\\,u(t) \\, ,\n$$\nwhere $a \\in \\mathbb{R}$ and $a \\neq -1$, $a \\neq -3$, and $u(t)$ is the unit step. Work in the unilateral Laplace transform domain, starting from the core definitions of the Laplace transform and convolution for right-sided signals. Treat the system as a transformation of signals: $y(t) = (h * x)(t)$, where $h(t)$ is the impulse response of the system. \n\nYour tasks:\n- Determine the impulse response $h(t)$ by performing a partial fraction expansion of $H(s)$ and inverting each term. For each inversion step, justify the corresponding Region of Convergence (ROC) based on causality.\n- Using $h(t)$ and the convolution integral with $x(t)$, derive a closed-form expression for the output $y(t)$ in the time domain. At every step where an inverse Laplace transform is invoked (explicitly or implicitly via convolution), justify the ROC choice.\n\nExpress your final answer as a single closed-form analytic expression $y(t)$ in terms of $a$ and $t$ (include $u(t)$ explicitly). No numerical evaluation is required. If any intermediate integrals are needed, evaluate them symbolically. Do not assume any special values of $a$ beyond the exclusions stated above.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens\n- System Type: Causal Linear Time-Invariant (LTI) continuous-time system.\n- Initial Conditions: Zero.\n- Transfer Function: $H(s) = \\frac{s + 2}{(s + 1)(s + 3)^{2}}$.\n- Input Signal: $x(t) = \\exp(at) u(t)$, where $u(t)$ is the unit step function.\n- Constraints: $a \\in \\mathbb{R}$, $a \\neq -1$, $a \\neq -3$.\n- Analysis Method: Unilateral Laplace transform, convolution integral $y(t) = (h * x)(t)$.\n- Task 1: Determine the impulse response $h(t)$ via partial fraction expansion and inverse Laplace transform, justifying the Region of Convergence (ROC) based on causality.\n- Task 2: Determine the output $y(t)$ via the convolution integral of $h(t)$ and $x(t)$, justifying any ROC choices.\n\nStep 2: Validate Using Extracted Givens\n- The problem is **scientifically grounded**. It is a standard problem in the analysis of LTI systems, a core topic in signal processing and control theory, relying on fundamental principles of the Laplace transform and convolution.\n- The problem is **well-posed**. The system and input are clearly defined. The constraints on the parameter $a$ prevent indeterminate forms and ensure that the poles of the input do not coincide with the poles of the system, guaranteeing a unique solution structure.\n- The problem is **objective** and uses precise mathematical language.\n- The problem is **self-contained and consistent**. All necessary information, including the transfer function, input signal, and system properties (causality, LTI), is provided. There are no contradictions.\n\nStep 3: Verdict and Action\n- The problem is deemed **valid**. A solution will be derived.\n\nThe solution proceeds in two parts as required.\n\nPart 1: Determination of the Impulse Response $h(t)$\n\nThe impulse response $h(t)$ is the inverse Laplace transform of the transfer function $H(s)$.\n$$\nh(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{s + 2}{(s + 1)(s + 3)^{2}}\\right\\}\n$$\nThe system is specified as causal. For a rational transfer function, causality implies that the Region of Convergence (ROC) is the right half-plane to the right of the rightmost pole. The poles of $H(s)$ are at $s = -1$ and $s = -3$. The rightmost pole is at $s = -1$. Therefore, the ROC for $H(s)$ is $\\text{Re}(s)  -1$.\n\nTo find $h(t)$, we perform a partial fraction expansion of $H(s)$.\n$$\nH(s) = \\frac{A}{s + 1} + \\frac{B}{s + 3} + \\frac{C}{(s + 3)^{2}}\n$$\nThe coefficients are determined as follows:\nThe coefficient $A$ is the residue of $H(s)$ at the simple pole $s = -1$.\n$$\nA = \\left[(s + 1)H(s)\\right]_{s=-1} = \\left[\\frac{s + 2}{(s + 3)^{2}}\\right]_{s=-1} = \\frac{-1 + 2}{(-1 + 3)^{2}} = \\frac{1}{2^{2}} = \\frac{1}{4}\n$$\nThe coefficient $C$ is found by evaluating $(s+3)^2 H(s)$ at the double pole $s = -3$.\n$$\nC = \\left[(s + 3)^{2}H(s)\\right]_{s=-3} = \\left[\\frac{s + 2}{s + 1}\\right]_{s=-3} = \\frac{-3 + 2}{-3 + 1} = \\frac{-1}{-2} = \\frac{1}{2}\n$$\nThe coefficient $B$ is found from the derivative of $(s+3)^2 H(s)$ at $s = -3$.\n$$\nB = \\frac{d}{ds}\\left[(s + 3)^{2}H(s)\\right]_{s=-3} = \\frac{d}{ds}\\left[\\frac{s + 2}{s + 1}\\right]_{s=-3}\n$$\nUsing the quotient rule for differentiation:\n$$\n\\frac{d}{ds}\\left(\\frac{s + 2}{s + 1}\\right) = \\frac{(1)(s + 1) - (s + 2)(1)}{(s + 1)^{2}} = \\frac{-1}{(s + 1)^{2}}\n$$\nEvaluating at $s = -3$:\n$$\nB = \\frac{-1}{(-3 + 1)^{2}} = \\frac{-1}{(-2)^{2}} = -\\frac{1}{4}\n$$\nThus, the partial fraction expansion of $H(s)$ is:\n$$\nH(s) = \\frac{1/4}{s + 1} - \\frac{1/4}{s + 3} + \\frac{1/2}{(s + 3)^{2}}\n$$\nWe now take the inverse Laplace transform of each term. The overall ROC, $\\text{Re}(s)  -1$, dictates that each individual inverse transform must correspond to a causal (right-sided) time-domain signal.\n- For the term $\\frac{1}{s + 1}$, the pole is at $s=-1$. The causal inverse transform is $\\exp(-t)u(t)$, which has an ROC of $\\text{Re}(s)  -1$. This is consistent.\n- For the term $\\frac{1}{s + 3}$, the pole is at $s=-3$. The causal inverse transform is $\\exp(-3t)u(t)$, which has an ROC of $\\text{Re}(s)  -3$. This is consistent with the overall ROC $\\text{Re}(s)  -1$.\n- For the term $\\frac{1}{(s + 3)^{2}}$, this corresponds to the transform pair $\\mathcal{L}\\{t \\exp(-\\alpha t)u(t)\\} = \\frac{1}{(s+\\alpha)^2}$. The pole is at $s=-3$. The causal inverse transform is $t \\exp(-3t)u(t)$, which has an ROC of $\\text{Re}(s)  -3$, also consistent.\n\nCombining the inverse transforms gives the impulse response $h(t)$:\n$$\nh(t) = \\left(\\frac{1}{4}\\exp(-t) - \\frac{1}{4}\\exp(-3t) + \\frac{1}{2}t\\exp(-3t)\\right)u(t)\n$$\n\nPart 2: Determination of the Output $y(t)$ via Convolution\n\nThe output $y(t)$ is the convolution of the impulse response $h(t)$ and the input $x(t)$:\n$$\ny(t) = (h * x)(t) = \\int_{-\\infty}^{\\infty} h(\\tau)x(t - \\tau) d\\tau\n$$\nSince both $h(t)$ and $x(t)$ are causal (i.e., zero for $t  0$), the integrand $h(\\tau)x(t - \\tau)$ is non-zero only for $0 \\le \\tau \\le t$. Thus, for $t \\ge 0$, the convolution integral is:\n$$\ny(t) = \\int_{0}^{t} h(\\tau)x(t - \\tau) d\\tau\n$$\nSubstituting the expressions for $h(\\tau)$ and $x(t-\\tau)$:\n$$\nh(\\tau) = \\frac{1}{4}\\exp(-\\tau) - \\frac{1}{4}\\exp(-3\\tau) + \\frac{1}{2}\\tau\\exp(-3\\tau)\n$$\n$$\nx(t - \\tau) = \\exp(a(t - \\tau)) = \\exp(at)\\exp(-a\\tau)\n$$\nThe integral becomes:\n$$\ny(t) = \\int_{0}^{t} \\left(\\frac{1}{4}\\exp(-\\tau) - \\frac{1}{4}\\exp(-3\\tau) + \\frac{1}{2}\\tau\\exp(-3\\tau)\\right) \\exp(at)\\exp(-a\\tau) d\\tau\n$$\nWe can factor out $\\exp(at)$ from the integral:\n$$\ny(t) = \\exp(at) \\int_{0}^{t} \\left(\\frac{1}{4}\\exp(-(a+1)\\tau) - \\frac{1}{4}\\exp(-(a+3)\\tau) + \\frac{1}{2}\\tau\\exp(-(a+3)\\tau)\\right) d\\tau\n$$\nLet's evaluate the integral term by term. The constraints $a \\neq -1$ and $a \\neq -3$ ensure the denominators are non-zero.\n1. First term:\n$$\n\\int_{0}^{t} \\frac{1}{4}\\exp(-(a+1)\\tau) d\\tau = \\frac{1}{4}\\left[\\frac{\\exp(-(a+1)\\tau)}{-(a+1)}\\right]_{0}^{t} = \\frac{1}{4(a+1)}\\left(1 - \\exp(-(a+1)t)\\right)\n$$\n2. Second term:\n$$\n\\int_{0}^{t} -\\frac{1}{4}\\exp(-(a+3)\\tau) d\\tau = -\\frac{1}{4}\\left[\\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} = -\\frac{1}{4(a+3)}\\left(1 - \\exp(-(a+3)t)\\right)\n$$\n3. Third term (using integration by parts, $\\int u dv = uv - \\int v du$): let $u = \\frac{1}{2}\\tau$ and $dv = \\exp(-(a+3)\\tau)d\\tau$. Then $du = \\frac{1}{2}d\\tau$ and $v = \\frac{\\exp(-(a+3)\\tau)}{-(a+3)}$.\n\\begin{align*}\n\\int_{0}^{t} \\frac{1}{2}\\tau\\exp(-(a+3)\\tau) d\\tau = \\left[\\frac{1}{2}\\tau \\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} - \\int_{0}^{t} \\frac{1}{-(a+3)}\\exp(-(a+3)\\tau) \\frac{1}{2} d\\tau \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} + \\frac{1}{2(a+3)} \\int_{0}^{t} \\exp(-(a+3)\\tau) d\\tau \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} + \\frac{1}{2(a+3)} \\left[\\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{1}{2(a+3)^{2}}\\left(\\exp(-(a+3)t) - 1\\right) \\\\\n= \\frac{1}{2(a+3)^{2}} - \\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{\\exp(-(a+3)t)}{2(a+3)^{2}}\n\\end{align*}\nCombining all three results inside the integral:\n$$\n\\frac{1-\\exp(-(a+1)t)}{4(a+1)} - \\frac{1-\\exp(-(a+3)t)}{4(a+3)} + \\frac{1}{2(a+3)^{2}} - \\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{\\exp(-(a+3)t)}{2(a+3)^{2}}\n$$\nNow, multiply by $\\exp(at)$ to obtain $y(t)$:\n\\begin{align*}\ny(t) = \\exp(at)\\left( \\frac{1}{4(a+1)} - \\frac{1}{4(a+3)} + \\frac{1}{2(a+3)^{2}} \\right) \\\\\n\\quad - \\frac{\\exp(at)\\exp(-(a+1)t)}{4(a+1)} \\\\\n\\quad + \\frac{\\exp(at)\\exp(-(a+3)t)}{4(a+3)} - \\frac{\\exp(at)\\exp(-(a+3)t)}{2(a+3)^{2}} \\\\\n\\quad - \\frac{t\\exp(at)\\exp(-(a+3)t)}{2(a+3)}\n\\end{align*}\nSimplifying each group of terms:\n- The coefficient of $\\exp(at)$ is $\\frac{1}{4(a+1)} - \\frac{1}{4(a+3)} + \\frac{1}{2(a+3)^{2}} = \\frac{(a+3)^2 - (a+1)(a+3) + 2(a+1)}{4(a+1)(a+3)^2} = \\frac{(a^2+6a+9) - (a^2+4a+3) + (2a+2)}{4(a+1)(a+3)^2} = \\frac{4a+8}{4(a+1)(a+3)^2} = \\frac{a+2}{(a+1)(a+3)^2}$.\n- The term with $\\exp(-t)$ is $-\\frac{\\exp(-t)}{4(a+1)}$.\n- The terms with $\\exp(-3t)$ and $t\\exp(-3t)$ are:\n  $$ \\left(\\frac{1}{4(a+3)} - \\frac{1}{2(a+3)^2}\\right)\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) $$\n  $$ = \\left(\\frac{a+3-2}{4(a+3)^2}\\right)\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) = \\frac{a+1}{4(a+3)^2}\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) $$\nAssembling the final expression for $y(t)$ and including the unit step $u(t)$ to indicate causality:\n$$\ny(t) = \\left( \\frac{a+2}{(a+1)(a+3)^{2}}\\exp(at) - \\frac{1}{4(a+1)}\\exp(-t) + \\frac{a+1}{4(a+3)^{2}}\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) \\right) u(t)\n$$\nThe convolution of two causal signals results in a causal signal, $y(t)$. The Laplace transform $Y(s)$ has poles at $s=a$, $s=-1$, and $s=-3$. The causality of $y(t)$ implies its ROC is the right half-plane to the right of its rightmost pole, which is $\\text{Re}(s)  \\max\\{a, -1\\}$. This is consistent with the operation $Y(s) = H(s)X(s)$, where the ROC of $Y(s)$ is the intersection of the ROCs of $H(s)$ ($\\text{Re}(s)-1$) and $X(s)$ ($\\text{Re}(s)a$).", "answer": "$$\n\\boxed{\\left( \\frac{a+2}{(a+1)(a+3)^{2}} \\exp(at) - \\frac{1}{4(a+1)} \\exp(-t) + \\frac{a+1}{4(a+3)^{2}} \\exp(-3t) - \\frac{t}{2(a+3)} \\exp(-3t) \\right) u(t)}\n$$", "id": "2910739"}, {"introduction": "We now move from physically realizable systems to powerful theoretical constructs by considering a system that acts as an ideal second-order differentiator. This problem [@problem_id:2910770] challenges you to compute the system's output by applying the rules of distributional calculus, which extends the concept of differentiation to signals with discontinuities. Mastering convolution with the Dirac delta distribution $\\delta(t)$ and its derivatives is a key step toward understanding advanced signal modeling and system theory.", "problem": "Consider a continuous-time linear time-invariant system whose impulse response is the second distributional derivative of the Dirac delta, namely $h(t)=\\delta''(t)$. The input is the causal exponential $x(t)=\\exp(-t)\\,u(t)$, where $u(t)$ is the Heaviside unit step. Using only the definition of convolution for linear time-invariant systems, the definition of the distributional derivative, and standard properties of tempered distributions, determine the output $y(t)=(h*x)(t)$ in the sense of distributions. Express your final result as a closed-form analytic expression in terms of $\\exp(-t)u(t)$, $\\delta(t)$, and $\\delta'(t)$, separating the regular component for $t0$ and the singular components supported at $t=0$. No numerical approximation is required, and no physical units are involved. Provide the final answer as a single expression.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- System Type: Continuous-time linear time-invariant (LTI) system.\n- Impulse Response: $h(t) = \\delta''(t)$, where $\\delta(t)$ is the Dirac delta distribution and $\\delta''(t)$ is its second distributional derivative.\n- Input Signal: $x(t) = \\exp(-t)u(t)$, where $u(t)$ is the Heaviside unit step function.\n- Task: Determine the output $y(t) = (h * x)(t)$.\n- Methodology: Use the definition of convolution for LTI systems, the definition of the distributional derivative, and properties of tempered distributions.\n- Required Output Format: A closed-form analytic expression for $y(t)$ in terms of $\\exp(-t)u(t)$, $\\delta(t)$, and $\\delta'(t)$, separating the regular and singular components.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is formulated within the standard mathematical framework of signal processing and distribution theory. The Dirac delta distribution and its derivatives, along with their convolution properties, are fundamental concepts in this field. The system with impulse response $h(t) = \\delta''(t)$ corresponds to an ideal second-order differentiator, which is a standard theoretical construct. The problem is scientifically sound.\n- **Well-Posedness**: The convolution of a tempered distribution (such as $\\delta''(t)$) with a function of slow growth (such as $x(t) = \\exp(-t)u(t)$) is a well-defined operation in the theory of distributions. The problem is specified with sufficient information to yield a unique solution in the space of distributions.\n- **Objectivity**: The problem is stated using precise mathematical language, free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. I will proceed with the derivation.\n\nThe output $y(t)$ of a linear time-invariant system is given by the convolution of the input signal $x(t)$ with the system's impulse response $h(t)$.\n$$y(t) = (x * h)(t) = (h * x)(t)$$\nGiven $h(t) = \\delta''(t)$ and $x(t) = \\exp(-t)u(t)$, the output is:\n$$y(t) = (\\delta'' * x)(t)$$\nA fundamental property of convolution involving the Dirac delta distribution and its derivatives states that for a sufficiently well-behaved function $f(t)$, the convolution with the $n$-th derivative of the delta distribution yields the $n$-th derivative of the function:\n$$(\\delta^{(n)} * f)(t) = f^{(n)}(t)$$\nThe differentiation on the right-hand side must be interpreted in the sense of distributions. In this problem, $n=2$ and $f(t) = x(t)$. Therefore, the output $y(t)$ is the second distributional derivative of the input $x(t)$.\n$$y(t) = x''(t) = \\frac{d^2}{dt^2} \\left[ \\exp(-t)u(t) \\right]$$\nWe must proceed by calculating the derivatives step-by-step. First, we compute the first distributional derivative, $x'(t)$. The function $x(t) = \\exp(-t)u(t)$ is discontinuous at $t=0$. For a function $f(t)$ that is differentiable everywhere except for a finite jump discontinuity at $t=c$, its distributional derivative is given by:\n$$f'(t) = \\{f'(t)\\} + [f(c^+) - f(c^-)]\\delta(t-c)$$\nwhere $\\{f'(t)\\}$ is the classical derivative, which exists for $t \\neq c$. For our input $x(t)$, the discontinuity is at $t=0$. The classical derivative for $t \\neq 0$ is:\n$$\\{x'(t)\\} = \\frac{d}{dt}(\\exp(-t))u(t) = -\\exp(-t)u(t)$$\nThe jump at $t=0$ is:\n$$x(0^+) - x(0^-) = \\lim_{\\epsilon \\to 0^+} \\exp(-\\epsilon) - \\lim_{\\epsilon \\to 0^-} 0 = 1 - 0 = 1$$\nTherefore, the first distributional derivative is:\n$$x'(t) = -\\exp(-t)u(t) + \\delta(t)$$\nNext, we compute the second derivative, $y(t) = x''(t)$, by differentiating $x'(t)$ in the distributional sense. Using the linearity of the differentiation operator:\n$$y(t) = x''(t) = \\frac{d}{dt} \\left( -\\exp(-t)u(t) + \\delta(t) \\right) = \\frac{d}{dt}\\left( -\\exp(-t)u(t) \\right) + \\frac{d}{dt}\\left( \\delta(t) \\right)$$\nThe second term is, by definition, the derivative of the Dirac delta distribution, $\\delta'(t)$.\nFor the first term, we apply the same rule for distributional differentiation to the function $g(t) = -\\exp(-t)u(t)$. The classical derivative of $g(t)$ for $t \\neq 0$ is:\n$$\\{g'(t)\\} = \\frac{d}{dt}(-\\exp(-t))u(t) = \\exp(-t)u(t)$$\nThe jump of $g(t)$ at $t=0$ is:\n$$g(0^+) - g(0^-) = \\lim_{\\epsilon \\to 0^+} (-\\exp(-\\epsilon)) - 0 = -1$$\nThus, the derivative of the first term is:\n$$\\frac{d}{dt}\\left( -\\exp(-t)u(t) \\right) = \\exp(-t)u(t) - 1 \\cdot \\delta(t) = \\exp(-t)u(t) - \\delta(t)$$\nCombining the results, the second distributional derivative of $x(t)$ is:\n$$y(t) = x''(t) = \\left( \\exp(-t)u(t) - \\delta(t) \\right) + \\delta'(t)$$\nThis gives the final expression for the output signal $y(t)$.\n$$y(t) = \\exp(-t)u(t) - \\delta(t) + \\delta'(t)$$\nThis result correctly separates the regular component for $t0$, which is $\\exp(-t)$ (represented by $\\exp(-t)u(t)$), and the singular components supported at the origin, which are $-\\delta(t)$ and $\\delta'(t)$. The expression is in the required form.", "answer": "$$\n\\boxed{\\exp(-t)u(t)-\\delta(t)+\\delta'(t)}\n$$", "id": "2910770"}, {"introduction": "This final practice elevates our perspective from calculating a specific output to analyzing a general property of the system: its stability. By treating the system as an operator on a function space, you will rigorously determine its Bounded-Input, Bounded-Output (BIBO) stability [@problem_id:2910774]. This exercise introduces methods from functional analysis, such as establishing operator norms via integral inequalities, to provide a definitive answer about the system's behavior for any possible bounded input.", "problem": "Consider the causal operator on the nonnegative real line defined for a measurable input signal $x:\\,[0,\\infty)\\to\\mathbb{R}$ by\n$$\n(Tx)(t)\\;=\\;\\int_{0}^{t}\\frac{x(\\tau)}{(t-\\tau)^{\\alpha}}\\,d\\tau,\\qquad t\\ge 0,\n$$\nwhere the parameter satisfies $0\\alpha1$. Assume $x$ is essentially bounded on $[0,\\infty)$ so that $\\|x\\|_{\\infty}=\\operatorname*{ess\\,sup}_{t\\ge 0}|x(t)|\\infty$. The notion of bounded-input bounded-output (BIBO) stability is that there exists a finite constant $M0$ such that every bounded input $x$ produces an output $y=Tx$ satisfying $\\sup_{t\\ge 0}|y(t)|\\le M\\|x\\|_{\\infty}$.\n\nUsing only fundamental definitions of convolution-type operators and appropriate convolution inequalities, derive from first principles the exact value of the least constant $C(\\alpha,T)$, as a function of $\\alpha$ and a finite horizon $T0$, such that for every essentially bounded input $x$,\n$$\n\\sup_{t\\in[0,T]}\\big|(Tx)(t)\\big| \\;\\le\\; C(\\alpha,T)\\,\\|x\\|_{\\infty}.\n$$\nThen use your result to determine whether the operator $T$ is BIBO stable on $[0,\\infty)$. Your derivation must explicitly justify the inequality you use and carefully evaluate any integrals involved. Your final answer must be the closed-form analytic expression for $C(\\alpha,T)$. No rounding is required, and no units are needed. Do not report an inequality or an equation as your final answer; report only the requested expression.", "solution": "The problem requires the derivation of the least constant $C(\\alpha, T)$ such that for a causal operator $T$ defined by\n$$\n(Tx)(t) = \\int_{0}^{t} \\frac{x(\\tau)}{(t-\\tau)^{\\alpha}} \\, d\\tau, \\quad t \\ge 0, \\quad 0  \\alpha  1,\n$$\nthe inequality\n$$\n\\sup_{t \\in [0,T]} |(Tx)(t)| \\le C(\\alpha, T) \\|x\\|_{\\infty}\n$$\nholds for any essentially bounded input $x$. The constant $C(\\alpha, T)$ is, by definition, the norm of the operator $T$ mapping the space of essentially bounded functions on $[0, \\infty)$ to the space of essentially bounded functions on the finite interval $[0, T]$. This operator norm is given by\n$$\nC(\\alpha, T) = \\sup_{\\|x\\|_{\\infty} \\le 1} \\left( \\sup_{t \\in [0,T]} |(Tx)(t)| \\right).\n$$\n\nFirst, we establish an upper bound for $|(Tx)(t)|$. For any $t \\in [0, T]$, we have:\n$$\n|(Tx)(t)| = \\left| \\int_{0}^{t} \\frac{x(\\tau)}{(t-\\tau)^{\\alpha}} \\, d\\tau \\right|.\n$$\nUsing the triangle inequality for integrals, this becomes:\n$$\n|(Tx)(t)| \\le \\int_{0}^{t} \\left| \\frac{x(\\tau)}{(t-\\tau)^{\\alpha}} \\right| \\, d\\tau.\n$$\nSince $\\tau  t$ within the domain of integration, the term $(t-\\tau)^{\\alpha}$ is real and positive. Thus:\n$$\n|(Tx)(t)| \\le \\int_{0}^{t} \\frac{|x(\\tau)|}{(t-\\tau)^{\\alpha}} \\, d\\tau.\n$$\nBy definition, $\\|x\\|_{\\infty} = \\operatorname*{ess\\,sup}_{\\tau \\ge 0} |x(\\tau)|$, which implies that $|x(\\tau)| \\le \\|x\\|_{\\infty}$ for almost every $\\tau \\ge 0$. Substituting this into the inequality gives:\n$$\n|(Tx)(t)| \\le \\int_{0}^{t} \\frac{\\|x\\|_{\\infty}}{(t-\\tau)^{\\alpha}} \\, d\\tau.\n$$\nSince $\\|x\\|_{\\infty}$ is a constant with respect to the integration variable $\\tau$, we can factor it out of the integral:\n$$\n|(Tx)(t)| \\le \\|x\\|_{\\infty} \\int_{0}^{t} \\frac{1}{(t-\\tau)^{\\alpha}} \\, d\\tau.\n$$\nNow, we must evaluate the integral. Let $I(t) = \\int_{0}^{t} (t-\\tau)^{-\\alpha} \\, d\\tau$. We perform a change of variable by letting $u = t-\\tau$. This implies $du = -d\\tau$. The limits of integration change from $\\tau=0$ to $u=t$, and from $\\tau=t$ to $u=0$.\n$$\nI(t) = \\int_{t}^{0} u^{-\\alpha} \\, (-du) = \\int_{0}^{t} u^{-\\alpha} \\, du.\n$$\nSince the problem states that $0  \\alpha  1$, the exponent $1-\\alpha$ is positive. The antiderivative of $u^{-\\alpha}$ is $\\frac{u^{1-\\alpha}}{1-\\alpha}$. The integral is therefore:\n$$\nI(t) = \\left[ \\frac{u^{1-\\alpha}}{1-\\alpha} \\right]_{0}^{t} = \\frac{t^{1-\\alpha}}{1-\\alpha} - \\frac{0^{1-\\alpha}}{1-\\alpha} = \\frac{t^{1-\\alpha}}{1-\\alpha}.\n$$\nSubstituting this result back into our inequality for $|(Tx)(t)|$, we obtain:\n$$\n|(Tx)(t)| \\le \\|x\\|_{\\infty} \\frac{t^{1-\\alpha}}{1-\\alpha}.\n$$\nThis inequality holds for any $t \\in [0, T]$. To find the least upper bound for the output on this interval, we take the supremum of both sides with respect to $t \\in [0, T]$:\n$$\n\\sup_{t \\in [0,T]} |(Tx)(t)| \\le \\sup_{t \\in [0,T]} \\left( \\|x\\|_{\\infty} \\frac{t^{1-\\alpha}}{1-\\alpha} \\right) = \\frac{\\|x\\|_{\\infty}}{1-\\alpha} \\sup_{t \\in [0,T]} (t^{1-\\alpha}).\n$$\nThe function $g(t) = t^{1-\\alpha}$ has an exponent $1-\\alpha$ that is positive. Therefore, $g(t)$ is a monotonically increasing function for $t \\ge 0$. Its supremum on the interval $[0, T]$ is achieved at the right endpoint, $t=T$.\n$$\n\\sup_{t \\in [0,T]} (t^{1-\\alpha}) = T^{1-\\alpha}.\n$$\nThis gives us an upper bound for the constant $C(\\alpha, T)$:\n$$\n\\sup_{t \\in [0,T]} |(Tx)(t)| \\le \\left( \\frac{T^{1-\\alpha}}{1-\\alpha} \\right) \\|x\\|_{\\infty},\n$$\nwhich implies that $C(\\alpha, T) \\le \\frac{T^{1-\\alpha}}{1-\\alpha}$.\n\nTo show that this is the least possible constant, we must demonstrate that this bound can be attained for some input $x(t)$ with $\\|x\\|_{\\infty}  0$. Consider the specific input signal $x(t) = 1$ for all $t \\ge 0$. For this signal, $\\|x\\|_{\\infty} = 1$. Let us compute the output $(Tx)(t)$:\n$$\n(Tx)(t) = \\int_{0}^{t} \\frac{1}{(t-\\tau)^{\\alpha}} \\, d\\tau.\n$$\nThis is precisely the integral $I(t)$ we evaluated earlier. So, for $x(t)=1$, the output is:\n$$\n(Tx)(t) = \\frac{t^{1-\\alpha}}{1-\\alpha}.\n$$\nNow, we find the supremum of this specific output on the interval $[0, T]$:\n$$\n\\sup_{t \\in [0,T]} |(Tx)(t)| = \\sup_{t \\in [0,T]} \\left( \\frac{t^{1-\\alpha}}{1-\\alpha} \\right) = \\frac{T^{1-\\alpha}}{1-\\alpha}.\n$$\nSince we have found an input $x$ with $\\|x\\|_{\\infty}=1$ for which $\\sup_{t \\in [0,T]} |(Tx)(t)|$ is exactly equal to $\\frac{T^{1-\\alpha}}{1-\\alpha}$, the upper bound we derived is sharp. Therefore, the least constant $C(\\alpha, T)$ is exactly this value.\n$$\nC(\\alpha, T) = \\frac{T^{1-\\alpha}}{1-\\alpha}.\n$$\nThe problem also asks to use this result to determine if the operator $T$ is BIBO stable on $[0, \\infty)$. An operator is BIBO stable on $[0, \\infty)$ if there exists a finite constant $M  0$ such that $\\sup_{t \\ge 0}|(Tx)(t)| \\le M \\|x\\|_{\\infty}$ for all bounded inputs $x$. This constant $M$ would be the operator norm on the infinite horizon, which can be found by taking the limit of $C(\\alpha, T)$ as $T \\to \\infty$.\n$$\nM = \\lim_{T \\to \\infty} C(\\alpha, T) = \\lim_{T \\to \\infty} \\frac{T^{1-\\alpha}}{1-\\alpha}.\n$$\nSince $0  \\alpha  1$, the exponent $1-\\alpha$ is positive. As $T \\to \\infty$, the term $T^{1-\\alpha}$ grows without bound.\n$$\n\\lim_{T \\to \\infty} T^{1-\\alpha} = \\infty.\n$$\nTherefore, $M = \\infty$. No finite constant $M$ exists that bounds the output for all bounded inputs over the infinite time horizon $[0, \\infty)$. Consequently, the operator $T$ is not BIBO stable on $[0, \\infty)$.\n\nThe question asks only for the expression for $C(\\alpha, T)$.", "answer": "$$\\boxed{\\frac{T^{1-\\alpha}}{1-\\alpha}}$$", "id": "2910774"}]}