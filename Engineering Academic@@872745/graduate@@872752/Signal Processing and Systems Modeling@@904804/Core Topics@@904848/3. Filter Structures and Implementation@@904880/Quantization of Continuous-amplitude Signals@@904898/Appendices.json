{"hands_on_practices": [{"introduction": "This exercise serves as a fundamental starting point for understanding optimal quantizer design. By considering the simplest non-trivial case—a one-bit quantizer—we will derive the optimal decision threshold and reconstruction levels from first principles. This practice reveals the core necessary conditions that govern any quantizer designed to minimize mean-squared error.", "problem": "Consider a zero-mean Laplacian random variable $X$ with probability density function $f_{X}(x) = \\frac{1}{2b}\\exp\\!\\left(-\\frac{|x|}{b}\\right)$ for a given scale parameter $b0$. A one-bit scalar quantizer is specified by a single decision threshold $\\tau \\in \\mathbb{R}$ and two reproduction levels $r_{1}r_{2}$, with mapping $Q(x)=r_{1}$ for $x\\tau$ and $Q(x)=r_{2}$ for $x\\ge \\tau$. Under the Mean Squared Error (MSE) criterion, the objective is to minimize the expected distortion\n$$\nJ(\\tau,r_{1},r_{2}) \\triangleq \\mathbb{E}\\!\\left[(X-Q(X))^{2}\\right].\n$$\nStarting from first principles, derive the necessary conditions for optimality of $(\\tau,r_{1},r_{2})$ and solve them in closed form for the Laplacian source above. Express the optimal triple $(\\tau^{\\star},r_{1}^{\\star},r_{2}^{\\star})$ explicitly as a function of $b$. Provide your final answer as a single row vector $\\big(\\tau^{\\star},\\,r_{1}^{\\star},\\,r_{2}^{\\star}\\big)$ in terms of $b$. No numerical approximation or rounding is required.", "solution": "The problem as stated constitutes a valid and well-posed exercise in the field of signal processing, specifically in scalar quantization theory. It is scientifically grounded, self-contained, and free of any ambiguities or contradictions. We shall proceed with a rigorous derivation of the solution.\n\nThe problem is to find the optimal decision threshold $\\tau$ and reconstruction levels $r_{1}$ and $r_{2}$ that minimize the Mean Squared Error (MSE) for a one-bit quantizer applied to a Laplacian random variable $X$. The MSE, denoted by $J(\\tau, r_{1}, r_{2})$, is given by the expected squared difference between the original signal and its quantized version:\n$$\nJ(\\tau, r_{1}, r_{2}) = \\mathbb{E}[(X - Q(X))^{2}]\n$$\nGiven the quantizer definition $Q(x)=r_{1}$ for $x\\tau$ and $Q(x)=r_{2}$ for $x\\ge \\tau$, and the probability density function (PDF) $f_{X}(x)$, we can express the expectation as an integral over the domain of $X$:\n$$\nJ(\\tau, r_{1}, r_{2}) = \\int_{-\\infty}^{\\infty} (x - Q(x))^{2} f_{X}(x) \\,dx\n$$\nThis integral can be partitioned according to the decision regions defined by the threshold $\\tau$:\n$$\nJ(\\tau, r_{1}, r_{2}) = \\int_{-\\infty}^{\\tau} (x - r_{1})^{2} f_{X}(x) \\,dx + \\int_{\\tau}^{\\infty} (x - r_{2})^{2} f_{X}(x) \\,dx\n$$\nTo find the values $(\\tau^{\\star}, r_{1}^{\\star}, r_{2}^{\\star})$ that minimize $J$, we must find the critical points by setting the partial derivatives of $J$ with respect to $\\tau$, $r_{1}$, and $r_{2}$ to zero. These are the necessary conditions for optimality.\n\nFirst, we find the optimal reconstruction levels, $r_{1}^{\\star}$ and $r_{2}^{\\star}$, for a fixed threshold $\\tau$.\nThe partial derivative with respect to $r_{1}$ is:\n$$\n\\frac{\\partial J}{\\partial r_{1}} = \\frac{\\partial}{\\partial r_{1}} \\left[ \\int_{-\\infty}^{\\tau} (x - r_{1})^{2} f_{X}(x) \\,dx \\right] = \\int_{-\\infty}^{\\tau} -2(x - r_{1}) f_{X}(x) \\,dx\n$$\nSetting this to zero yields:\n$$\n\\int_{-\\infty}^{\\tau} (x - r_{1}) f_{X}(x) \\,dx = 0 \\implies r_{1} \\int_{-\\infty}^{\\tau} f_{X}(x) \\,dx = \\int_{-\\infty}^{\\tau} x f_{X}(x) \\,dx\n$$\nThis gives the optimal reconstruction level $r_{1}^{\\star}$ as the conditional expectation of $X$ given that $X$ falls into the first quantization region:\n$$\nr_{1}^{\\star} = \\frac{\\int_{-\\infty}^{\\tau} x f_{X}(x) \\,dx}{\\int_{-\\infty}^{\\tau} f_{X}(x) \\,dx} = \\mathbb{E}[X | X  \\tau]\n$$\nThis is the centroid of the first partition.\nBy an identical argument for $r_{2}$:\n$$\n\\frac{\\partial J}{\\partial r_{2}} = \\int_{\\tau}^{\\infty} -2(x - r_{2}) f_{X}(x) \\,dx = 0\n$$\nwhich leads to:\n$$\nr_{2}^{\\star} = \\frac{\\int_{\\tau}^{\\infty} x f_{X}(x) \\,dx}{\\int_{\\tau}^{\\infty} f_{X}(x) \\,dx} = \\mathbb{E}[X | X \\ge \\tau]\n$$\nThis is the centroid of the second partition.\n\nNext, we find the optimal decision threshold $\\tau^{\\star}$ for fixed reconstruction levels $r_{1}$ and $r_{2}$. We use the Leibniz integral rule to differentiate $J$ with respect to $\\tau$:\n$$\n\\frac{\\partial J}{\\partial \\tau} = ((\\tau - r_{1})^{2} f_{X}(\\tau)) - ((\\tau - r_{2})^{2} f_{X}(\\tau)) = 0\n$$\nAssuming $f_{X}(\\tau) \\neq 0$ in the region of interest, we can simplify this to:\n$$\n(\\tau - r_{1})^{2} = (\\tau - r_{2})^{2}\n$$\nTaking the square root of both sides gives two possibilities:\n1. $\\tau - r_{1} = \\tau - r_{2} \\implies r_{1} = r_{2}$. This is disallowed by the problem statement, which requires $r_{1}  r_{2}$.\n2. $\\tau - r_{1} = -(\\tau - r_{2}) = r_{2} - \\tau \\implies 2\\tau = r_{1} + r_{2}$.\n\nThis gives the optimal threshold $\\tau^{\\star}$ as the midpoint of the reconstruction levels:\n$$\n\\tau^{\\star} = \\frac{r_{1}^{\\star} + r_{2}^{\\star}}{2}\n$$\nThis is the nearest neighbor condition.\n\nNow, we apply these general conditions to the specific case of a zero-mean Laplacian source with PDF $f_{X}(x) = \\frac{1}{2b}\\exp(-\\frac{|x|}{b})$. This PDF is symmetric about the origin, i.e., $f_{X}(x) = f_{X}(-x)$. For a source with a symmetric PDF, the optimal quantizer must also be symmetric. This implies that the decision threshold must be at the point of symmetry, $\\tau^{\\star} = 0$, and the reconstruction levels must be antisymmetric, $r_{1}^{\\star} = -r_{2}^{\\star}$. This configuration satisfies the derived condition $\\tau^{\\star} = (r_{1}^{\\star} + r_{2}^{\\star})/2$, since $0 = (-r_{2}^{\\star} + r_{2}^{\\star})/2$.\n\nWith $\\tau^{\\star}=0$, we only need to compute one of the reconstruction levels. We calculate $r_{2}^{\\star}$:\n$$\nr_{2}^{\\star} = \\mathbb{E}[X | X \\ge 0] = \\frac{\\int_{0}^{\\infty} x f_{X}(x) \\,dx}{\\int_{0}^{\\infty} f_{X}(x) \\,dx}\n$$\nThe denominator is the probability $P(X \\ge 0)$:\n$$\n\\int_{0}^{\\infty} f_{X}(x) \\,dx = \\int_{0}^{\\infty} \\frac{1}{2b}\\exp\\left(-\\frac{x}{b}\\right) \\,dx = \\frac{1}{2b} \\left[-b\\exp\\left(-\\frac{x}{b}\\right)\\right]_{0}^{\\infty} = \\frac{1}{2b} (0 - (-b)) = \\frac{1}{2}\n$$\nThe numerator is:\n$$\n\\int_{0}^{\\infty} x f_{X}(x) \\,dx = \\int_{0}^{\\infty} x \\frac{1}{2b}\\exp\\left(-\\frac{x}{b}\\right) \\,dx = \\frac{1}{2b} \\int_{0}^{\\infty} x \\exp\\left(-\\frac{x}{b}\\right) \\,dx\n$$\nWe solve the integral using integration by parts, $\\int u \\,dv = uv - \\int v \\,du$. Let $u=x$ and $dv = \\exp(-x/b)\\,dx$. Then $du=dx$ and $v = -b\\exp(-x/b)$.\n$$\n\\int_{0}^{\\infty} x \\exp\\left(-\\frac{x}{b}\\right) \\,dx = \\left[-bx\\exp\\left(-\\frac{x}{b}\\right)\\right]_{0}^{\\infty} - \\int_{0}^{\\infty} (-b)\\exp\\left(-\\frac{x}{b}\\right) \\,dx\n$$\n$$\n= (0 - 0) + b \\int_{0}^{\\infty} \\exp\\left(-\\frac{x}{b}\\right) \\,dx = b \\left[-b\\exp\\left(-\\frac{x}{b}\\right)\\right]_{0}^{\\infty} = b(0 - (-b)) = b^{2}\n$$\nThus, the numerator is $\\frac{1}{2b} (b^{2}) = \\frac{b}{2}$.\nSubstituting the numerator and denominator back into the expression for $r_{2}^{\\star}$:\n$$\nr_{2}^{\\star} = \\frac{b/2}{1/2} = b\n$$\nFrom the symmetry condition $r_{1}^{\\star} = -r_{2}^{\\star}$, we find:\n$$\nr_{1}^{\\star} = -b\n$$\nThe optimal triple $(\\tau^{\\star}, r_{1}^{\\star}, r_{2}^{\\star})$ is therefore $(0, -b, b)$. This result is consistent with the condition $r_{1}  r_{2}$, as $b0$ implies $-bb$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0  -b  b \\end{pmatrix}}\n$$", "id": "2898731"}, {"introduction": "Building on the principles of optimal design, this practice focuses on a common scenario where the reconstruction levels are predetermined. Your task is to apply the nearest-neighbor condition to define the optimal decision boundaries and then compute the resulting distortion for a multi-level quantizer. This exercise strengthens your ability to analyze quantizer performance when some design parameters are fixed. [@problem_id:2898731]", "problem": "Consider a memoryless scalar quantizer for a continuous-amplitude source. Let the reproduction (codebook) values be fixed and ordered as $y_{1}=-2$, $y_{2}=-0.2$, $y_{3}=0.5$, and $y_{4}=1.7$. The source $X$ is real-valued with the Laplace (double-exponential) Probability Density Function (PDF)\n$$\nf_{X}(x)=\\frac{1}{2b}\\exp\\!\\left(-\\frac{|x|}{b}\\right),\n$$\nwhere $b>0$ is the scale parameter. The performance criterion is the Mean-Squared Error (MSE) distortion\n$$\nD=\\mathbb{E}\\!\\left[(X-q(X))^{2}\\right],\n$$\nwhere $q(\\cdot)$ denotes the quantizer mapping that assigns each $x\\in\\mathbb{R}$ to one of the reproduction values.\n\nUsing only fundamental definitions (partition of the real line into decision regions and the MSE criterion), derive from first principles the decision regions that minimize the MSE for the given fixed reproduction values, and then compute the resulting average distortion $D$ as a closed-form analytic function of $b$. Express your final answer as a single simplified expression in terms of $b$. Do not approximate or round your result.", "solution": "The problem statement is subjected to validation and is found to be valid. It is a well-posed, scientifically grounded problem in the domain of scalar quantization theory, with all necessary information provided and no internal contradictions. We may therefore proceed with a formal derivation.\n\nThe task is to determine the optimal decision regions for a scalar quantizer with fixed reproduction values and then compute the resulting Mean-Squared Error (MSE) distortion. The quantizer $q(x)$ maps an input value $x \\in \\mathbb{R}$ to one of the given reproduction values $y_k$, where $k \\in \\{1, 2, 3, 4\\}$. The set of reproduction values is given as $Y = \\{y_1, y_2, y_3, y_4\\} = \\{-2, -0.2, 0.5, 1.7\\}$.\n\nFirst, we determine the decision regions $R_k$ corresponding to each reproduction value $y_k$. For a given set of reproduction values, the MSE distortion $D$ is minimized when the quantizer is a nearest-neighbor quantizer. This means that any input $x$ is mapped to the reproduction value $y_k$ that is closest to $x$ in Euclidean distance. The decision boundaries, denoted $t_k$, are the points equidistant from adjacent, ordered reproduction values. The boundary $t_k$ between the regions for $y_k$ and $y_{k+1}$ is given by their midpoint:\n$$\nt_k = \\frac{y_k + y_{k+1}}{2}\n$$\nThe given reproduction values are ordered: $y_1 = -2  y_2 = -0.2  y_3 = 0.5  y_4 = 1.7$. We calculate the decision boundaries:\n$$\nt_1 = \\frac{y_1 + y_2}{2} = \\frac{-2 + (-0.2)}{2} = -1.1\n$$\n$$\nt_2 = \\frac{y_2 + y_3}{2} = \\frac{-0.2 + 0.5}{2} = 0.15\n$$\n$$\nt_3 = \\frac{y_3 + y_4}{2} = \\frac{0.5 + 1.7}{2} = 1.1\n$$\nThese boundaries partition the real line $\\mathbb{R}$ into four decision regions:\n$R_1 = (-\\infty, t_1] = (-\\infty, -1.1]$\n$R_2 = (t_1, t_2] = (-1.1, 0.15]$\n$R_3 = (t_2, t_3] = (0.15, 1.1]$\n$R_4 = (t_3, \\infty) = (1.1, \\infty)$\n\nThe quantizer function $q(x)$ is thus defined as:\n$$\nq(x) = y_k \\quad \\text{for } x \\in R_k\n$$\n\nNext, we compute the average MSE distortion $D$, defined as:\n$$\nD = \\mathbb{E}[(X - q(X))^2] = \\int_{-\\infty}^{\\infty} (x-q(x))^2 f_X(x) \\, dx\n$$\nBy expanding the squared term, we can express $D$ as:\n$$\nD = \\mathbb{E}[X^2] - 2\\mathbb{E}[Xq(X)] + \\mathbb{E}[q(X)^2]\n$$\nWe will compute each term separately. The source PDF is $f_X(x) = \\frac{1}{2b} \\exp(-\\frac{|x|}{b})$.\n\n1.  **Calculation of $\\mathbb{E}[X^2]$**:\n    This is the second moment of the Laplace distribution. Since the mean is zero, this is also the variance.\n    $$\n    \\mathbb{E}[X^2] = \\int_{-\\infty}^{\\infty} x^2 \\frac{1}{2b} \\exp\\left(-\\frac{|x|}{b}\\right) dx = 2 \\int_{0}^{\\infty} x^2 \\frac{1}{2b} \\exp\\left(-\\frac{x}{b}\\right) dx = \\frac{1}{b} \\int_{0}^{\\infty} x^2 \\exp\\left(-\\frac{x}{b}\\right) dx\n    $$\n    Using the substitution $u = x/b$, we have $x=bu$ and $dx=b du$.\n    $$\n    \\mathbb{E}[X^2] = \\frac{1}{b} \\int_{0}^{\\infty} (bu)^2 e^{-u} (b du) = b^2 \\int_0^{\\infty} u^2 e^{-u} du = b^2 \\Gamma(3) = 2b^2\n    $$\n    where $\\Gamma(\\cdot)$ is the Gamma function, and $\\Gamma(3) = 2! = 2$. Thus, $\\mathbb{E}[X^2] = 2b^2$.\n\n2.  **Calculation of $\\mathbb{E}[q(X)^2]$**:\n    This term is given by $\\mathbb{E}[q(X)^2] = \\sum_{k=1}^4 y_k^2 P(X \\in R_k)$, where $P(X \\in R_k) = \\int_{R_k} f_X(x) dx$. We first find the Cumulative Distribution Function (CDF), $F_X(x) = \\int_{-\\infty}^x f_X(u) du$:\n    For $x  0$, $F_X(x) = \\int_{-\\infty}^x \\frac{1}{2b} e^{u/b} du = \\frac{1}{2} e^{x/b}$.\n    For $x \\ge 0$, $F_X(x) = F_X(0) + \\int_0^x \\frac{1}{2b} e^{-u/b} du = \\frac{1}{2} + \\left[-\\frac{1}{2}e^{-u/b}\\right]_0^x = 1 - \\frac{1}{2}e^{-x/b}$.\n    The probabilities of the regions are:\n    $P_1 = P(X \\le t_1) = F_X(t_1) = \\frac{1}{2}e^{t_1/b}$.\n    $P_2 = F_X(t_2) - F_X(t_1) = (1 - \\frac{1}{2}e^{-t_2/b}) - \\frac{1}{2}e^{t_1/b}$.\n    $P_3 = F_X(t_3) - F_X(t_2) = (1 - \\frac{1}{2}e^{-t_3/b}) - (1 - \\frac{1}{2}e^{-t_2/b}) = \\frac{1}{2}(e^{-t_2/b} - e^{-t_3/b})$.\n    $P_4 = 1 - F_X(t_3) = 1 - (1 - \\frac{1}{2}e^{-t_3/b}) = \\frac{1}{2}e^{-t_3/b}$.\n    Summing $y_k^2 P_k$:\n    $$\n    \\mathbb{E}[q(X)^2] = y_1^2 \\frac{1}{2}e^{t_1/b} + y_2^2 \\left(1 - \\frac{1}{2}e^{-t_2/b} - \\frac{1}{2}e^{t_1/b}\\right) + y_3^2 \\frac{1}{2}(e^{-t_2/b} - e^{-t_3/b}) + y_4^2 \\frac{1}{2}e^{-t_3/b}\n    $$\n    $$\n    = y_2^2 + \\frac{1}{2}(y_1^2 - y_2^2)e^{t_1/b} + \\frac{1}{2}(y_3^2 - y_2^2)e^{-t_2/b} + \\frac{1}{2}(y_4^2 - y_3^2)e^{-t_3/b}\n    $$\n\n3.  **Calculation of $\\mathbb{E}[Xq(X)]$**:\n    This term is $\\mathbb{E}[Xq(X)] = \\sum_{k=1}^4 y_k \\int_{R_k} x f_X(x) dx$. Let $M_k = \\int_{R_k} x f_X(x) dx$.\n    We require the indefinite integral of $x f_X(x)$:\n    For $x  0$, $\\int x \\frac{1}{2b} e^{x/b} dx = \\frac{1}{2}(x-b)e^{x/b}$. Let this be $G(x)$.\n    For $x  0$, $\\int x \\frac{1}{2b} e^{-x/b} dx = -\\frac{1}{2}(x+b)e^{-x/b}$. Let this be $H(x)$.\n    The integrals over the regions are:\n    $M_1 = G(t_1) - G(-\\infty) = \\frac{1}{2}(t_1-b)e^{t_1/b}$.\n    $M_2 = (G(0)-G(t_1)) + (H(t_2)-H(0)) = (-\\frac{b}{2} - \\frac{1}{2}(t_1-b)e^{t_1/b}) + (-\\frac{1}{2}(t_2+b)e^{-t_2/b} + \\frac{b}{2}) = -\\frac{1}{2}(t_1-b)e^{t_1/b} - \\frac{1}{2}(t_2+b)e^{-t_2/b}$.\n    $M_3 = H(t_3)-H(t_2) = \\frac{1}{2}(t_2+b)e^{-t_2/b} - \\frac{1}{2}(t_3+b)e^{-t_3/b}$.\n    $M_4 = H(\\infty)-H(t_3) = \\frac{1}{2}(t_3+b)e^{-t_3/b}$.\n    The term $-2\\mathbb{E}[Xq(X)] = -2\\sum y_k M_k$ becomes, after collecting terms with common exponentials:\n    $$\n    -2\\mathbb{E}[Xq(X)] = -(y_1-y_2)(t_1-b)e^{t_1/b} - (y_2-y_3)(t_2+b)e^{-t_2/b} - (y_3-y_4)(t_3+b)e^{-t_3/b}\n    $$\n\n4.  **Assembly of the final expression for $D$**:\n    $D = \\mathbb{E}[X^2] + \\mathbb{E}[q(X)^2] - 2\\mathbb{E}[Xq(X)]$.\n    Combining the results and grouping by exponential terms:\n    $D = 2b^2 + y_2^2 + \\left[\\frac{1}{2}(y_1^2 - y_2^2) - (y_1-y_2)(t_1-b)\\right]e^{t_1/b} + \\left[\\frac{1}{2}(y_3^2 - y_2^2) - (y_2-y_3)(t_2+b)\\right]e^{-t_2/b} + \\left[\\frac{1}{2}(y_4^2 - y_3^2) - (y_3-y_4)(t_3+b)\\right]e^{-t_3/b}$.\n    We use the relations $t_k=(y_k+y_{k+1})/2$ and $y_i^2 - y_j^2 = (y_i-y_j)(y_i+y_j)$.\n    The coefficient of $e^{t_1/b}$ is $\\frac{1}{2}(y_1-y_2)(y_1+y_2) - (y_1-y_2)(t_1-b) = (y_1-y_2)(t_1 - (t_1-b)) = b(y_1-y_2)$.\n    The coefficient of $e^{-t_2/b}$ is $\\frac{1}{2}(y_3-y_2)(y_3+y_2) - (y_2-y_3)(t_2+b) = (y_3-y_2)(t_2 - (t_2+b)) = -b(y_3-y_2) = b(y_2-y_3)$.\n    The coefficient of $e^{-t_3/b}$ is $\\frac{1}{2}(y_4-y_3)(y_4+y_3) - (y_3-y_4)(t_3+b) = (y_4-y_3)(t_3 - (t_3+b)) = -b(y_4-y_3) = b(y_3-y_4)$.\n    The complete expression for the distortion is:\n    $$\n    D = 2b^2 + y_2^2 + b(y_1-y_2)e^{t_1/b} + b(y_2-y_3)e^{-t_2/b} + b(y_3-y_4)e^{-t_3/b}\n    $$\n    Now, we substitute the given numerical values:\n    $y_1 = -2$, $y_2 = -0.2$, $y_3 = 0.5$, $y_4 = 1.7$.\n    $t_1 = -1.1$, $t_2 = 0.15$, $t_3 = 1.1$.\n    The constant term is $2b^2 + y_2^2 = 2b^2 + (-0.2)^2 = 2b^2 + 0.04$.\n    The coefficients of the exponential terms are:\n    $b(y_1-y_2) = b(-2 - (-0.2)) = -1.8b$.\n    $b(y_2-y_3) = b(-0.2 - 0.5) = -0.7b$.\n    $b(y_3-y_4) = b(0.5 - 1.7) = -1.2b$.\n    Substituting these into the expression for $D$:\n    $$\n    D(b) = 2b^2 + 0.04 - 1.8b \\cdot e^{-1.1/b} - 0.7b \\cdot e^{-0.15/b} - 1.2b \\cdot e^{-1.1/b}\n    $$\n    Combining the terms with $e^{-1.1/b}$:\n    $$\n    D(b) = 2b^2 + 0.04 - (1.8+1.2)b \\exp\\left(-\\frac{1.1}{b}\\right) - 0.7b \\exp\\left(-\\frac{0.15}{b}\\right)\n    $$\n    $$\n    D(b) = 2b^2 + 0.04 - 3b \\exp\\left(-\\frac{1.1}{b}\\right) - 0.7b \\exp\\left(-\\frac{0.15}{b}\\right)\n    $$\nThis is the final simplified closed-form expression for the average distortion as a function of $b$.", "answer": "$$\n\\boxed{2b^2 + 0.04 - 3b \\exp\\left(-\\frac{1.1}{b}\\right) - 0.7b \\exp\\left(-\\frac{0.15}{b}\\right)}\n$$", "id": "2898775"}, {"introduction": "Practical quantizers have a finite dynamic range, leading to a trade-off between granular error for small signals and overload error for large signals. This problem isolates the latter, asking you to derive the overload distortion for a uniform quantizer whose range is tied to the source statistics. This analysis is crucial for understanding and managing clipping effects in real-world signal processing systems.", "problem": "Consider a memoryless source with samples $X$ that are independent and identically distributed according to a zero-mean Laplace distribution with scale parameter $b0$, with probability density function given by $f_{X}(x)=\\frac{1}{2b}\\exp\\!\\left(-\\frac{|x|}{b}\\right)$. The samples are passed through a symmetric, mid-rise, uniform, saturating quantizer $Q(\\cdot)$ with $B$ bits and decision thresholds at $\\{\\pm k\\Delta: k\\in\\mathbb{Z}\\}$ for some step size $\\Delta0$. The reproduction levels are $\\{(k+\\frac{1}{2})\\Delta: k\\in\\mathbb{Z}\\}$ in the granular region. The quantizer is clipped at symmetric thresholds $\\pm A$ so that inputs $x\\geq A$ are mapped to the outermost positive reproduction level $A-\\frac{\\Delta}{2}$ and inputs $x\\leq -A$ are mapped to the outermost negative reproduction level $-A+\\frac{\\Delta}{2}$. Within $(-A,A)$, the quantizer coincides with the infinite mid-rise quantizer, i.e., $Q(x)=(k+\\frac{1}{2})\\Delta$ for $x\\in[k\\Delta,(k+1)\\Delta)$.\n\nThe dynamic range width is chosen to include a fraction $1-\\epsilon$ of the input probability mass, where $0\\epsilon1$, namely $A$ is chosen so that $\\mathbb{P}(|X|\\leq A)=1-\\epsilon$. The total number of reproduction levels in the granular region is $2^{B}$, so that $2A=2^{B}\\Delta$.\n\nDefine the overload distortion as the contribution to the mean-squared error strictly from overload (clipping) events,\n$$\nD_{\\text{over}}=\\mathbb{E}\\!\\left[\\bigl(X-Q(X)\\bigr)^{2}\\,\\mathbf{1}\\{|X|\\geq A\\}\\right].\n$$\nStarting only from the preceding definitions and the given probability density function, derive a closed-form expression for $D_{\\text{over}}$ in terms of $b$, $B$, and $\\epsilon$. Express your final answer as a single analytic expression involving only elementary functions of $b$, $B$, and $\\epsilon$. Do not leave unevaluated integrals. Do not approximate. Your final answer must be a single closed-form expression.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- **Source Distribution**: Independent and identically distributed (i.i.d.) samples $X$ from a zero-mean Laplace distribution with scale parameter $b0$. The probability density function (PDF) is $f_{X}(x)=\\frac{1}{2b}\\exp(-\\frac{|x|}{b})$.\n- **Quantizer Properties**: A symmetric, mid-rise, uniform, saturating quantizer $Q(\\cdot)$ with $B$ bits.\n- **Quantizer Structure**:\n    - Decision thresholds: $\\{\\pm k\\Delta: k\\in\\mathbb{Z}\\}$ for a step size $\\Delta0$.\n    - Reproduction levels in the granular region: $\\{(k+\\frac{1}{2})\\Delta: k\\in\\mathbb{Z}\\}$.\n    - Saturation (clipping) thresholds: $\\pm A$.\n    - Overload mapping: For inputs $x\\geq A$, $Q(x) = A-\\frac{\\Delta}{2}$. For inputs $x\\leq -A$, $Q(x) = -A+\\frac{\\Delta}{2}$.\n- **Parameter Relationships**:\n    - The dynamic range width $2A$ is related to the number of granular levels $2^B$ and step size $\\Delta$ by $2A=2^{B}\\Delta$.\n    - The clipping threshold $A$ is chosen such that the probability of a sample falling within the dynamic range is $1-\\epsilon$, i.e., $\\mathbb{P}(|X|\\leq A)=1-\\epsilon$, for $0\\epsilon1$.\n- **Objective**: Derive a closed-form expression for the overload distortion, defined as $D_{\\text{over}}=\\mathbb{E}[\\bigl(X-Q(X)\\bigr)^{2}\\,\\mathbf{1}\\{|X|\\geq A\\}]$, in terms of $b$, $B$, and $\\epsilon$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is well-grounded in quantization theory, a core topic in signal processing and information theory. The Laplace distribution is a standard model for signal sources, and the uniform quantizer is a fundamental construct.\n- **Well-Posedness**: The problem is well-posed. The objective is clearly stated, and all necessary parameters and relationships ($f_X(x)$, $Q(x)$, $A$, $\\Delta$, $B$, $\\epsilon$) are defined, allowing for a unique solution to be derived.\n- **Objectivity**: The problem is stated in precise, objective mathematical language, free from any subjectivity or ambiguity.\n- **Consistency and Completeness**: The provided information is self-contained and consistent. The definitions of the quantizer levels, saturation behavior, and parameter interdependencies are coherent.\n- **Verdict**: The problem is valid. It is a standard, solvable problem in the analysis of quantization systems.\n\n**Solution Derivation**\nThe overload distortion $D_{\\text{over}}$ is defined as the mean-squared error (MSE) conditioned on the event that the input magnitude $|X|$ exceeds the clipping threshold $A$. By definition of expectation, this is:\n$$\nD_{\\text{over}} = \\int_{-\\infty}^{\\infty} (x-Q(x))^{2} \\mathbf{1}\\{|x|\\geq A\\} f_{X}(x) dx\n$$\nThe indicator function $\\mathbf{1}\\{|x|\\geq A\\}$ partitions the integral into two regions: $[A, \\infty)$ and $(-\\infty, -A]$.\n$$\nD_{\\text{over}} = \\int_{A}^{\\infty} (x-Q(x))^{2} f_{X}(x) dx + \\int_{-\\infty}^{-A} (x-Q(x))^{2} f_{X}(x) dx\n$$\nFrom the problem statement, for $x \\geq A$, the quantizer output is $Q(x) = A - \\frac{\\Delta}{2}$. For $x \\leq -A$, the output is $Q(x) = -A + \\frac{\\Delta}{2}$. Substituting these into the integrals:\n$$\nD_{\\text{over}} = \\int_{A}^{\\infty} \\left(x - \\left(A - \\frac{\\Delta}{2}\\right)\\right)^{2} f_{X}(x) dx + \\int_{-\\infty}^{-A} \\left(x - \\left(-A + \\frac{\\Delta}{2}\\right)\\right)^{2} f_{X}(x) dx\n$$\n$$\nD_{\\text{over}} = \\int_{A}^{\\infty} \\left(x - A + \\frac{\\Delta}{2}\\right)^{2} f_{X}(x) dx + \\int_{-\\infty}^{-A} \\left(x + A - \\frac{\\Delta}{2}\\right)^{2} f_{X}(x) dx\n$$\nThe Laplace PDF $f_{X}(x)=\\frac{1}{2b}\\exp(-\\frac{|x|}{b})$ is an even function, i.e., $f_{X}(x) = f_{X}(-x)$. We can use this symmetry. Let $u = -x$ in the second integral, so $du = -dx$. The limits become $u=A$ to $u=\\infty$.\n$$\n\\int_{\\infty}^{A} \\left(-u + A - \\frac{\\Delta}{2}\\right)^{2} f_{X}(-u) (-du) = \\int_{A}^{\\infty} \\left(-(u - A + \\frac{\\Delta}{2})\\right)^{2} f_{X}(u) du = \\int_{A}^{\\infty} \\left(u - A + \\frac{\\Delta}{2}\\right)^{2} f_{X}(u) du\n$$\nThis result is identical to the first integral. Therefore, the total overload distortion is twice the integral over the positive overload region.\n$$\nD_{\\text{over}} = 2 \\int_{A}^{\\infty} \\left(x - A + \\frac{\\Delta}{2}\\right)^{2} f_{X}(x) dx\n$$\nFor $x \\ge A  0$, $|x|=x$, so $f_X(x) = \\frac{1}{2b} \\exp(-\\frac{x}{b})$.\n$$\nD_{\\text{over}} = 2 \\int_{A}^{\\infty} \\left(x - A + \\frac{\\Delta}{2}\\right)^{2} \\frac{1}{2b} \\exp\\left(-\\frac{x}{b}\\right) dx = \\frac{1}{b} \\int_{A}^{\\infty} \\left(x - A + \\frac{\\Delta}{2}\\right)^{2} \\exp\\left(-\\frac{x}{b}\\right) dx\n$$\nTo proceed, we express $A$ in terms of $b$ and $\\epsilon$. The probability of overload is given as $\\epsilon$.\n$$\n\\epsilon = \\mathbb{P}(|X|  A) = \\int_{|x|A} f_X(x) dx = 2 \\int_A^\\infty \\frac{1}{2b}\\exp\\left(-\\frac{x}{b}\\right)dx = \\frac{1}{b}\\left[-b\\exp\\left(-\\frac{x}{b}\\right)\\right]_A^\\infty = \\exp\\left(-\\frac{A}{b}\\right)\n$$\nThis gives the relation $A = -b\\ln(\\epsilon) = b\\ln(\\frac{1}{\\epsilon})$.\nNow, we evaluate the integral for $D_{\\text{over}}$. Let's make the substitution $y = x - A$, which means $x = y + A$ and $dx = dy$. The lower limit of integration becomes $y = A - A = 0$.\n$$\nD_{\\text{over}} = \\frac{1}{b} \\int_{0}^{\\infty} \\left(y + \\frac{\\Delta}{2}\\right)^{2} \\exp\\left(-\\frac{y+A}{b}\\right) dy = \\frac{1}{b} \\exp\\left(-\\frac{A}{b}\\right) \\int_{0}^{\\infty} \\left(y + \\frac{\\Delta}{2}\\right)^{2} \\exp\\left(-\\frac{y}{b}\\right) dy\n$$\nUsing $\\exp(-\\frac{A}{b}) = \\epsilon$ and expanding the squared term:\n$$\nD_{\\text{over}} = \\frac{\\epsilon}{b} \\int_{0}^{\\infty} \\left(y^2 + \\Delta y + \\frac{\\Delta^2}{4}\\right) \\exp\\left(-\\frac{y}{b}\\right) dy\n$$\nThis expression separates into three integrals, which are standard forms related to the Gamma function or solvable via integration by parts.\n1. $\\int_{0}^{\\infty} \\exp\\left(-\\frac{y}{b}\\right) dy = b$\n2. $\\int_{0}^{\\infty} y \\exp\\left(-\\frac{y}{b}\\right) dy = b^2$\n3. $\\int_{0}^{\\infty} y^2 \\exp\\left(-\\frac{y}{b}\\right) dy = 2b^3$\n\nSubstituting these results:\n$$\nD_{\\text{over}} = \\frac{\\epsilon}{b} \\left(2b^3 + \\Delta(b^2) + \\frac{\\Delta^2}{4}(b)\\right) = \\epsilon \\left(2b^2 + b\\Delta + \\frac{\\Delta^2}{4}\\right)\n$$\nThe final step is to express $\\Delta$ in terms of $b$, $B$, and $\\epsilon$. From the given relations, $\\Delta = \\frac{2A}{2^B}$ and $A=b\\ln(\\frac{1}{\\epsilon})$.\n$$\n\\Delta = \\frac{2b\\ln(\\frac{1}{\\epsilon})}{2^B}\n$$\nSubstituting this into the expression for $D_{\\text{over}}$:\n$$\nD_{\\text{over}} = \\epsilon \\left(2b^2 + b\\left(\\frac{2b\\ln(\\frac{1}{\\epsilon})}{2^B}\\right) + \\frac{1}{4}\\left(\\frac{2b\\ln(\\frac{1}{\\epsilon})}{2^B}\\right)^2\\right)\n$$\nSimplifying the terms:\n$$\nD_{\\text{over}} = \\epsilon \\left(2b^2 + \\frac{2b^2\\ln(\\frac{1}{\\epsilon})}{2^B} + \\frac{4b^2(\\ln(\\frac{1}{\\epsilon}))^2}{4 \\cdot (2^B)^2}\\right)\n$$\nFactoring out $b^2\\epsilon$:\n$$\nD_{\\text{over}} = b^2\\epsilon \\left(2 + \\frac{2\\ln(\\frac{1}{\\epsilon})}{2^B} + \\frac{(\\ln(\\frac{1}{\\epsilon}))^2}{(2^B)^2}\\right)\n$$\nUsing the identity $2/2^B = 2^{1-B}$ and $1/(2^B)^2 = 1/2^{2B} = 2^{-2B}$, the expression can be written as:\n$$\nD_{\\text{over}} = b^2\\epsilon \\left(2 + 2^{1-B}\\ln\\left(\\frac{1}{\\epsilon}\\right) + 2^{-2B}\\left(\\ln\\left(\\frac{1}{\\epsilon}\\right)\\right)^2\\right)\n$$\nThis is the final, closed-form expression for the overload distortion in terms of the specified parameters $b$, $B$, and $\\epsilon$.", "answer": "$$\n\\boxed{b^2\\epsilon \\left(2 + 2^{1-B}\\ln\\left(\\frac{1}{\\epsilon}\\right) + 2^{-2B}\\left(\\ln\\left(\\frac{1}{\\epsilon}\\right)\\right)^2\\right)}\n$$", "id": "2898761"}]}