{"hands_on_practices": [{"introduction": "The first step in working with lattice filters is understanding how to translate a conventional filter, described by its transfer function polynomial, into the lattice domain. This exercise provides hands-on practice with the Schur step-down recursion, a robust algorithm for extracting reflection coefficients. By performing this conversion, you not only change the filter's representation but also directly test its stability, as the magnitudes of the reflection coefficients, $|k_m| < 1$, provide an immediate and powerful check. [@problem_id:2879672]", "problem": "Consider a real, monic autoregressive (AR) prediction polynomial of order $n$,\n$$A_{n}(z)=1+\\sum_{i=1}^{n} a^{(n)}_{i} z^{-i},$$\nthat is minimum-phase (all zeros strictly inside the unit circle). In the lattice parametrization, the associated reflection coefficients $\\{k_{m}\\}_{m=1}^{n}$ are obtained by the Schur step-down recursion that reduces the model order while preserving stability and monicity. The recursion is constructed by combining the polynomial $A_{m}(z)$ and its time-reversed version $\\tilde{A}_{m}(z)=z^{-m}A_{m}(z^{-1})$ to eliminate the highest-lag term and normalize the constant term to $1$. The magnitude condition $|k_{m}|<1$ follows from the stability and positive-definiteness of the underlying prediction error structure in lattice form.\n\nFor the third-order AR model with\n$$A_{3}(z)=1-1.2\\,z^{-1}+0.7\\,z^{-2}-0.1\\,z^{-3},$$\nuse the Schur step-down recursion to compute the reflection coefficients $\\{k_{1},k_{2},k_{3}\\}$ explicitly, and verify that $|k_{m}|<1$ for $m\\in\\{1,2,3\\}$. Express your final answer as a row matrix $\\big(k_{1}\\;\\;k_{2}\\;\\;k_{3}\\big)$ in exact form. No rounding is required.", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It is a standard exercise in digital signal processing concerning the conversion of autoregressive polynomial coefficients from a direct form to lattice-form reflection coefficients. All necessary data is provided, and the methodology is clearly specified. We shall proceed with the solution.\n\nThe problem requires the computation of the reflection coefficients $\\{k_{1}, k_{2}, k_{3}\\}$ from a given third-order autoregressive (AR) polynomial,\n$$A_{3}(z)=1-1.2\\,z^{-1}+0.7\\,z^{-2}-0.1\\,z^{-3}$$\nThe Schur step-down recursion is the specified method. For a polynomial of order $m$, $A_{m}(z) = 1 + \\sum_{i=1}^{m} a_{i}^{(m)} z^{-i}$, the recursion generates a polynomial of order $m-1$ using the formula:\n$$A_{m-1}(z) = \\frac{A_m(z) - k_m \\tilde{A}_m(z)}{1 - k_m^2}$$\nwhere the reflection coefficient $k_{m}$ is the last coefficient of $A_{m}(z)$, i.e., $k_{m} = a_{m}^{(m)}$, and $\\tilde{A}_{m}(z) = z^{-m}A_{m}(z^{-1})$ is the time-reversed polynomial. The coefficients of the lower-order polynomial $A_{m-1}(z)$ are given by:\n$$a_{j}^{(m-1)} = \\frac{a_{j}^{(m)} - k_{m} a_{m-j}^{(m)}}{1-k_{m}^2}, \\quad j=1, 2, \\ldots, m-1$$\nFor the system to be stable (minimum-phase), it is necessary that $|k_m| < 1$ for all $m$.\n\nTo maintain exactness as required, we express the given decimal coefficients as fractions:\n$1.2 = \\frac{12}{10} = \\frac{6}{5}$\n$0.7 = \\frac{7}{10}$\n$0.1 = \\frac{1}{10}$\nThe polynomial is thus:\n$$A_{3}(z) = 1 - \\frac{6}{5} z^{-1} + \\frac{7}{10} z^{-2} - \\frac{1}{10} z^{-3}$$\nThe coefficients are $a_{1}^{(3)} = -\\frac{6}{5}$, $a_{2}^{(3)} = \\frac{7}{10}$, and $a_{3}^{(3)} = -\\frac{1}{10}$.\n\n**Step 1: Compute $k_{3}$**\nThe third reflection coefficient, $k_3$, is the last coefficient of $A_{3}(z)$:\n$$k_{3} = a_{3}^{(3)} = -\\frac{1}{10}$$\nWe verify the stability condition: $|k_{3}| = |-\\frac{1}{10}| = \\frac{1}{10} < 1$. The condition is satisfied.\n\n**Step 2: Compute $A_{2}(z)$ and $k_{2}$**\nWe now use the recursion to find the coefficients of the second-order polynomial, $A_{2}(z)=1+a_{1}^{(2)}z^{-1}+a_{2}^{(2)}z^{-2}$.\nThe term $1-k_{3}^2$ is $1 - (-\\frac{1}{10})^2 = 1 - \\frac{1}{100} = \\frac{99}{100}$.\n\nThe coefficients $a_{1}^{(2)}$ and $a_{2}^{(2)}$ are calculated as follows:\n$$a_{1}^{(2)} = \\frac{a_{1}^{(3)} - k_{3} a_{2}^{(3)}}{1-k_{3}^2} = \\frac{-\\frac{6}{5} - (-\\frac{1}{10})(\\frac{7}{10})}{\\frac{99}{100}} = \\frac{-\\frac{6}{5} + \\frac{7}{100}}{\\frac{99}{100}} = \\frac{\\frac{-120+7}{100}}{\\frac{99}{100}} = \\frac{-\\frac{113}{100}}{\\frac{99}{100}} = -\\frac{113}{99}$$\n\n$$a_{2}^{(2)} = \\frac{a_{2}^{(3)} - k_{3} a_{1}^{(3)}}{1-k_{3}^2} = \\frac{\\frac{7}{10} - (-\\frac{1}{10})(-\\frac{6}{5})}{\\frac{99}{100}} = \\frac{\\frac{7}{10} - \\frac{6}{50}}{\\frac{99}{100}} = \\frac{\\frac{35-6}{50}}{\\frac{99}{100}} = \\frac{\\frac{29}{50}}{\\frac{99}{100}} = \\frac{29}{50} \\cdot \\frac{100}{99} = \\frac{58}{99}$$\nSo, the second-order polynomial is $A_{2}(z) = 1 - \\frac{113}{99} z^{-1} + \\frac{58}{99} z^{-2}$.\n\nThe second reflection coefficient, $k_{2}$, is the last coefficient of $A_{2}(z)$:\n$$k_{2} = a_{2}^{(2)} = \\frac{58}{99}$$\nWe verify the stability condition: $|k_{2}| = |\\frac{58}{99}| = \\frac{58}{99} < 1$, since $58<99$. The condition is satisfied.\n\n**Step 3: Compute $A_{1}(z)$ and $k_{1}$**\nFinally, we compute the coefficient of the first-order polynomial, $A_1(z) = 1 + a_1^{(1)} z^{-1}$.\nUsing the same recursion formula for $m=2$ and $j=1$:\n$$a_{1}^{(1)} = \\frac{a_{1}^{(2)} - k_{2} a_{1}^{(2)}}{1-k_{2}^2} = \\frac{a_{1}^{(2)}(1-k_{2})}{(1-k_{2})(1+k_{2})} = \\frac{a_{1}^{(2)}}{1+k_{2}}$$\nSubstituting the values for $a_{1}^{(2)}$ and $k_{2}$:\n$$a_{1}^{(1)} = \\frac{-\\frac{113}{99}}{1+\\frac{58}{99}} = \\frac{-\\frac{113}{99}}{\\frac{99+58}{99}} = \\frac{-\\frac{113}{99}}{\\frac{157}{99}} = -\\frac{113}{157}$$\nThe first reflection coefficient, $k_1$, is the coefficient $a_1^{(1)}$:\n$$k_{1} = a_{1}^{(1)} = -\\frac{113}{157}$$\nWe verify the stability condition: $|k_{1}| = |-\\frac{113}{157}| = \\frac{113}{157} < 1$, since $113<157$. The condition is satisfied.\n\nThe set of reflection coefficients is $\\{k_{1}, k_{2}, k_{3}\\} = \\{-\\frac{113}{157}, \\frac{58}{99}, -\\frac{1}{10}\\}$.\nThe problem asks for the answer as a row matrix $\\begin{pmatrix} k_{1} & k_{2} & k_{3} \\end{pmatrix}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{113}{157} & \\frac{58}{99} & -\\frac{1}{10}\n\\end{pmatrix}\n}\n$$", "id": "2879672"}, {"introduction": "Having learned to analyze a filter into its lattice components, we now tackle the reverse process: synthesis. This practice guides you through reconstructing the original filter polynomial from a given set of reflection coefficients using the step-up recursion. Mastering this synthesis procedure is crucial for designing lattice filters from scratch and deeply understanding the structural relationship between the coefficients and the filter's overall response. [@problem_id:2879688]", "problem": "Consider the reconstruction of the monic prediction-error polynomial of order $m$, denoted $A_m(z)$, associated with a stable Infinite Impulse Response (IIR) lattice structure characterized by Schur reflection coefficients $\\{\\kappa_i\\}_{i=1}^m$ satisfying $|\\kappa_i|&lt;1$ for all $i$. Assume $A_m(z)$ is expressed in the $z^{-1}$-domain as $A_m(z)=\\sum_{i=0}^m a_{m,i} z^{-i}$ with $a_{m,0}=1$. Define the reversed (also called paraconjugate or reciprocal) polynomial operator by $A_m^{\\sharp}(z) \\triangleq z^{-m} A_m(z^{-1})$, so that $A_m^{\\sharp}(z) = \\sum_{i=0}^m a_{m,m-i} z^{-i}$. The lattice section is lossless in the sense that its $2\\times 2$ transfer description is paraunitary on the unit circle, and the resulting prediction-error polynomial is minimum-phase.\n\nStarting only from these definitions and the lossless property of the lattice one-step extension, do the following:\n\n1) Derive a reverse recursion that reconstructs $A_m(z)$ from $A_{m-1}(z)$ and the reflection coefficient $\\kappa_m$, using only $A_{m-1}(z)$ and its reversed polynomial $A_{m-1}^{\\sharp}(z)$. Your derivation must ensure that $A_m(0)=1$, that the last coefficient satisfies $a_{m,m}=\\kappa_m$, and that the construction preserves Schur stability (all zeros strictly inside the unit disk). As part of establishing stability, obtain a relation on the unit circle between $|A_m(e^{\\mathrm{j}\\omega})|^2$ and $|A_m^{\\sharp}(e^{\\mathrm{j}\\omega})|^2$ in terms of the corresponding quantities for $m-1$ and $|\\kappa_m|$.\n\n2) Using your recursion, compute $A_3(z)$ explicitly for the sequence of real reflection coefficients $\\kappa_1=\\frac{1}{2}$, $\\kappa_2=-\\frac{1}{3}$, $\\kappa_3=\\frac{1}{4}$. Express $A_3(z)$ as a single polynomial in powers of $z^{-1}$ with exact rational coefficients.\n\nNo rounding is required. Your final answer must be the single explicit expression for $A_3(z)$.", "solution": "The problem statement is C.S. Peirce's \"Do not block the way of inquiry.\" at its finest; it is a well-posed, self-contained, and scientifically grounded exercise in the fundamental theory of lattice filters in digital signal processing. It is free from ambiguity and factual error. We shall proceed.\n\nThe problem requires the derivation of the synthesis recursion for a prediction-error polynomial from its reflection coefficients and its application to a specific case.\n\nPart 1: Derivation of the Reverse Recursion and Stability Analysis\n\nThe lattice structure for prediction error is defined by the recursions for the forward prediction error, $f_m(n)$, and the backward prediction error, $b_m(n)$, at stage $m$:\n$$f_m(n) = f_{m-1}(n) + \\kappa_m b_{m-1}(n-1)$$\n$$b_m(n) = b_{m-1}(n-1) + \\kappa_m^* f_{m-1}(n)$$\nwhere $\\kappa_m$ is the reflection coefficient at stage $m$. The problem specifies real coefficients, so $\\kappa_m^* = \\kappa_m$.\nTaking the z-transform of these equations yields:\n$$F_m(z) = F_{m-1}(z) + \\kappa_m z^{-1} B_{m-1}(z)$$\n$$B_m(z) = z^{-1} B_{m-1}(z) + \\kappa_m F_{m-1}(z)$$\nHere, $F_m(z)$ and $B_m(z)$ are the z-transforms of the respective error signals. The prediction-error polynomial $A_m(z)$ is the transfer function from the input signal $X(z)$ to the forward error $F_m(z)$, i.e., $A_m(z) = F_m(z)/X(z)$. The backward prediction-error polynomial is similarly defined from $B_m(z)$. A key property, given as a definition in the problem, is that the backward prediction-error polynomial is the reversed polynomial of the forward one, which we denote as $A_m^\\sharp(z)$. Thus, $B_m(z)/X(z) = A_m^\\sharp(z) = z^{-m}A_m(z^{-1})$.\nDividing the z-transform recursions by $X(z)$, we obtain the recursions for the polynomials:\n$$A_m(z) = A_{m-1}(z) + \\kappa_m z^{-1} A_{m-1}^\\sharp(z)$$\nThis is the desired recursion for constructing $A_m(z)$ from $A_{m-1}(z)$ and $\\kappa_m$. It is often called the step-up recursion; the problem's use of \"reverse recursion\" refers to the reconstruction from the coefficients, which is valid terminology.\n\nWe now verify the properties of this recursion.\nThe initial condition is $A_0(z) = 1$, corresponding to a zero-order predictor.\n1. Monic property $a_{m,0}=1$: The polynomial is $A_m(z) = \\sum_{i=0}^m a_{m,i} z^{-i}$. The term $a_{m,0}$ is the coefficient of $z^0$. By induction, assume $a_{m-1,0}=1$. In the recursion, $A_{m-1}(z)$ contributes $a_{m-1,0}=1$ to the $z^0$ term. The term $z^{-1}A_{m-1}^\\sharp(z) = z^{-1}z^{-(m-1)}A_{m-1}(z^{-1}) = z^{-m}(a_{m-1,0} + a_{m-1,1}z + \\dots)$ has its highest power of $z^{-1}$ as $z^{-m}$ (assuming $a_{m-1,m-1} \\neq 0$), so it has no $z^0$ term. Thus, $a_{m,0} = a_{m-1,0} = 1$. The monic property is preserved. The expression $A_m(0)$ is formally ill-defined for a polynomial in $z^{-1}$, but it is clear the problem intended to query the constant term $a_{m,0}$, equivalent to evaluating the polynomial at $z^{-1}=0$.\n\n2. Last coefficient property $a_{m,m}=\\kappa_m$: The term $a_{m,m}$ is the coefficient of $z^{-m}$. In the recursion $A_m(z) = A_{m-1}(z) + \\kappa_m z^{-1} A_{m-1}^\\sharp(z)$, the polynomial $A_{m-1}(z)$ has maximum order $m-1$ in $z^{-1}$, so it does not contribute to the $z^{-m}$ term. The term $A_{m-1}^\\sharp(z) = \\sum_{i=0}^{m-1} a_{m-1,m-1-i}z^{-i}$ has a constant term $a_{m-1,m-1-0}=a_{m-1,m-1}$. The expression $z^{-1}A_{m-1}^\\sharp(z)$ is erroneous, let's use the definition: $A_{m-1}^\\sharp(z) = z^{-(m-1)}A_{m-1}(z^{-1})=z^{-(m-1)}(a_{m-1,0}+a_{m-1,1}z+\\dots)$. The highest power of $z$ in $A_{m-1}(z^{-1})$ is $z^{m-1}$, whose coefficient is $a_{m-1,m-1}$. When multiplied by $z^{-(m-1)}$, this gives a constant term. What we need is the coefficient of $z^{-(m-1)}$ in $A_{m-1}^\\sharp(z)$, which is $a_{m-1,0}$. The term $\\kappa_m z^{-1} A_{m-1}^\\sharp(z)$ provides the $z^{-m}$ coefficient, which is $\\kappa_m$ times the coefficient of $z^{-(m-1)}$ in $A_{m-1}^\\sharp(z)$. The coefficients of $A_m^\\sharp(z)$ are the reversed coefficients of $A_m(z)$. So, the coefficient of $z^{-(m-1)}$ in $A_{m-1}^\\sharp(z)$ is $a_{m-1, (m-1)-(m-1)} = a_{m-1,0}$.\nTherefore, $a_{m,m} = \\kappa_m \\cdot a_{m-1,0} = \\kappa_m \\cdot 1 = \\kappa_m$. This property holds.\n\n3. Schur stability (minimum-phase): We must show that if $|\\kappa_i|<1$ for all $i$, all zeros of $A_m(z)$ are strictly inside the unit circle. It is more convenient to analyze the corresponding polynomial in $z$, $P_m(z) = z^m A_m(z) = \\sum_{i=0}^m a_{m,i} z^{m-i}$. The zeros of $P_m(z)$ (for $z \\neq 0$) are identical to a_m(z) zeros. We establish the recursion for $P_m(z)$:\n$P_m(z) = z^m A_m(z) = z^m (A_{m-1}(z) + \\kappa_m z^{-1} A_{m-1}^\\sharp(z)) = z (z^{m-1}A_{m-1}(z)) + \\kappa_m z^{m-1}A_{m-1}^\\sharp(z)$.\n$P_m(z) = z P_{m-1}(z) + \\kappa_m z^{m-1} (z^{-(m-1)}A_{m-1}(z^{-1})) = z P_{m-1}(z) + \\kappa_m A_{m-1}(z^{-1})$.\nThe reciprocal polynomial of $P_{m-1}(z)$ is $P_{m-1}^\\#(z) = z^{m-1}P_{m-1}(z^{-1}) = z^{m-1}(z^{-1})^{m-1}A_{m-1}(z^{-1}) = A_{m-1}(z^{-1})$.\nThus, we have the recursion $P_m(z) = z P_{m-1}(z) + \\kappa_m P_{m-1}^\\#(z)$.\nWe now use Rouche's theorem. Let $f(z) = z P_{m-1}(z)$ and $g(z) = \\kappa_m P_{m-1}^\\#(z)$. On the unit circle $|z|=1$, we compare their magnitudes.\n$|f(z)| = |z| |P_{m-1}(z)| = |P_{m-1}(z)|$.\n$|g(z)| = |\\kappa_m| |P_{m-1}^\\#(z)|$. For $|z|=1$, $|P_{m-1}^\\#(z)| = |z^{m-1}P_{m-1}(z^{-1})| = |P_{m-1}(z^*)| = |P_{m-1}(z)^*| = |P_{m-1}(z)|$, since the coefficients are real.\nSo, on the unit circle, $|g(z)| = |\\kappa_m| |f(z)|$.\nGiven $|\\kappa_m|<1$, we have $|g(z)| < |f(z)|$ on $|z|=1$, provided $f(z)$, and thus $P_{m-1}(z)$, has no zeros on the unit circle. By induction, if $P_{m-1}(z)$ has no zeros on the unit circle, then $P_m(z)$ cannot have one either, otherwise the inequality becomes an equality, forcing $P_{m-1}(z)$ to have a zero. The base case $P_0(z)=1$ has no zeros.\nBy Rouche's theorem, $P_m(z) = f(z)+g(z)$ has the same number of zeros inside the unit circle as $f(z) = z P_{m-1}(z)$. By inductive hypothesis, $P_{m-1}(z)$ has $m-1$ zeros inside the unit circle. The function $f(z)$ has these $m-1$ zeros plus one zero at $z=0$. Thus $f(z)$ has $m$ zeros inside the unit circle. Therefore, $P_m(z)$ has $m$ zeros inside the unit circle. This completes the proof of stability.\n\n4. Relation on the unit circle: We seek a relation between $|A_m(e^{\\mathrm{j}\\omega})|^2$ and $|A_m^{\\sharp}(e^{\\mathrm{j}\\omega})|^2$. Let $z=e^{\\mathrm{j}\\omega}$.\n$|A_m^\\sharp(z)|^2 = |z^{-m}A_m(z^{-1})|^2 = |z|^{-2m}|A_m(z^*)|^2 = |A_m(z)^*|^2 = |A_m(z)|^2$.\nThis simple equality, $|A_m(e^{\\mathrm{j}\\omega})|^2 = |A_m^{\\sharp}(e^{\\mathrm{j}\\omega})|^2$, holds for any $m$ because the coefficients are real. While this is a relation, the question's phrasing \"...in terms of... $m-1$ and $|\\kappa_m|$\" suggests a more detailed expression. We derive an expression for $|A_m(e^{\\mathrm{j}\\omega})|^2$ from the recursion:\n$|A_m(z)|^2 = |A_{m-1}(z) + \\kappa_m z^{-1} A_{m-1}^\\sharp(z)|^2$\n$= |A_{m-1}(z)|^2 + |\\kappa_m|^2 |z^{-1}A_{m-1}^\\sharp(z)|^2 + 2 Re\\{\\kappa_m z^{-1} A_{m-1}^\\sharp(z) A_{m-1}(z)^*\\}$\nOn the unit circle, $|z^{-1}|=1$ and $|A_{m-1}^\\sharp(z)|=|A_{m-1}(z)|$. So:\n$|A_m(e^{\\mathrm{j}\\omega})|^2 = |A_{m-1}(e^{\\mathrm{j}\\omega})|^2(1+|\\kappa_m|^2) + 2 \\kappa_m Re\\{e^{-\\mathrm{j}\\omega} A_{m-1}^\\sharp(e^{\\mathrm{j}\\omega}) A_{m-1}(e^{\\mathrm{j}\\omega})^*\\}$.\nThis is the required relation expressing the magnitude at stage $m$ in terms of stage $m-1$ quantities. A similar expression for $|A_m^{\\sharp}(e^{\\mathrm{j}\\omega})|^2$ using its recursion yields the same result, confirming their equality on the unit circle.\n\nPart 2: Computation of $A_3(z)$\n\nWe are given the reflection coefficients $\\kappa_1=\\frac{1}{2}$, $\\kappa_2=-\\frac{1}{3}$, $\\kappa_3=\\frac{1}{4}$.\nWe start with $A_0(z) = 1$.\n\nStep $m=1$:\n$A_0^\\sharp(z) = z^{-0}A_0(z^{-1}) = 1$.\n$A_1(z) = A_0(z) + \\kappa_1 z^{-1} A_0^\\sharp(z) = 1 + \\frac{1}{2} z^{-1}$.\n\nStep $m=2$:\nFirst, find the reversed polynomial of $A_1(z)$.\n$A_1^\\sharp(z) = z^{-1}A_1(z^{-1}) = z^{-1}(1 + \\frac{1}{2}z) = z^{-1} + \\frac{1}{2}$.\nNow apply the recursion with $\\kappa_2 = -\\frac{1}{3}$.\n$A_2(z) = A_1(z) + \\kappa_2 z^{-2} A_1(z^{-1}) = (1 + \\frac{1}{2} z^{-1}) - \\frac{1}{3} z^{-2} (1 + \\frac{1}{2}z)$.\n$A_2(z) = 1 + \\frac{1}{2} z^{-1} - \\frac{1}{6} z^{-1} - \\frac{1}{3} z^{-2}$.\n$A_2(z) = 1 + (\\frac{3}{6} - \\frac{1}{6}) z^{-1} - \\frac{1}{3} z^{-2} = 1 + \\frac{2}{6} z^{-1} - \\frac{1}{3} z^{-2}$.\n$A_2(z) = 1 + \\frac{1}{3} z^{-1} - \\frac{1}{3} z^{-2}$.\n\nStep $m=3$:\nFirst, find the reversed polynomial of $A_2(z)$.\n$A_2^\\sharp(z) = z^{-2}A_2(z^{-1}) = z^{-2}(1 + \\frac{1}{3}z - \\frac{1}{3}z^2) = z^{-2} + \\frac{1}{3}z^{-1} - \\frac{1}{3}$.\nNow apply the recursion with $\\kappa_3 = \\frac{1}{4}$.\n$A_3(z) = A_2(z) + \\kappa_3 z^{-3} A_2(z^{-1}) = (1 + \\frac{1}{3} z^{-1} - \\frac{1}{3} z^{-2}) + \\frac{1}{4} z^{-3} (1 + \\frac{1}{3}z - \\frac{1}{3}z^2)$.\n$A_3(z) = 1 + \\frac{1}{3} z^{-1} - \\frac{1}{3} z^{-2} + \\frac{1}{4} z^{-3} + \\frac{1}{12} z^{-2} - \\frac{1}{12} z^{-1}$.\nWe collect terms with like powers of $z^{-1}$:\n$A_3(z) = 1 + (\\frac{1}{3} - \\frac{1}{12})z^{-1} + (-\\frac{1}{3} + \\frac{1}{12})z^{-2} + \\frac{1}{4}z^{-3}$.\n$A_3(z) = 1 + (\\frac{4-1}{12})z^{-1} + (\\frac{-4+1}{12})z^{-2} + \\frac{1}{4}z^{-3}$.\n$A_3(z) = 1 + \\frac{3}{12}z^{-1} - \\frac{3}{12}z^{-2} + \\frac{1}{4}z^{-3}$.\n$A_3(z) = 1 + \\frac{1}{4}z^{-1} - \\frac{1}{4}z^{-2} + \\frac{1}{4}z^{-3}$.\n\nThis is the final expression for the third-order prediction-error polynomial.", "answer": "$$\\boxed{1 + \\frac{1}{4}z^{-1} - \\frac{1}{4}z^{-2} + \\frac{1}{4}z^{-3}}$$", "id": "2879688"}, {"introduction": "Beyond the theoretical representation, a practical filter implementation must prevent internal signal values from overflowing the limits of fixed-point hardware. This advanced exercise challenges you to design a dynamic range scaling scheme from first principles, ensuring that all internal signals remain bounded even under worst-case statistical conditions. By deriving and implementing a scaling algorithm based on variance propagation and the Cauchy-Schwarz inequality, you will gain invaluable insight into the robust design of IIR filters for real-world signal processing applications. [@problem_id:2879658]", "problem": "You are given a real-coefficient lattice for an Infinite Impulse Response (IIR) system and asked to design a rigorous, conservative scaling scheme that guarantees bounded mean-square internal forward and backward signals for a unit-variance white input. The internal variables at section index $m \\in \\{1,2,\\dots,M\\}$ are the forward error $f_m(n)$ and backward error $b_m(n)$, related to the previous-section variables by the canonical two-port lattice mixing with a per-section scalar gain. Specifically, define the unscaled intermediate signals\n$$\n\\hat f_m(n) = f_{m-1}(n) + k_m\\, b_{m-1}(n-1), \\quad\n\\hat b_m(n) = k_m\\, f_{m-1}(n) + b_{m-1}(n-1),\n$$\nand the scaled outputs\n$$\nf_m(n) = s_m \\, \\hat f_m(n), \\quad b_m(n) = s_m \\, \\hat b_m(n),\n$$\nwhere $k_m \\in (-1,1)$ is the given real reflection coefficient for section $m$, and $s_m > 0$ is the per-section scaling to be designed. Assume the input to the lattice is a zero-mean, unit-variance white sequence $u(n)$ driving the forward path at section $m=0$, with\n$$\nf_0(n) = u(n), \\quad b_0(n) \\equiv 0,\n$$\nso that $\\mathbb{E}[f_0(n)^2] = 1$ and $\\mathbb{E}[b_0(n)^2] = 0$. You are to work in discrete time $n \\in \\mathbb{Z}$ and with the following engineering design criterion:\n- For each section $m$, you are given a power budget $P_m \\in (0,1]$ which is an upper bound to be enforced simultaneously on the mean-square values of both internal signals at that section, i.e.,\n$$\n\\mathbb{E}[f_m(n)^2] \\le P_m \\quad \\text{and} \\quad \\mathbb{E}[b_m(n)^2] \\le P_m.\n$$\n\nYour task is to derive, from first principles, a numerically implementable recursion to choose the smallest per-section scaling $s_m$ that guarantees the above mean-square constraints at each section for all possible cross-covariances consistent with the given variances up to section $m-1$. You must base your derivation solely on the following foundational definitions and facts:\n- Linearity of expectation and variance, and the definition of covariance $\\mathrm{Cov}(X,Y) = \\mathbb{E}[XY]$ for zero-mean processes.\n- The variance of a linear combination of zero-mean random variables $X$ and $Y$ is $\\mathrm{Var}(aX + bY) = a^2 \\mathrm{Var}(X) + b^2 \\mathrm{Var}(Y) + 2ab \\,\\mathrm{Cov}(X,Y)$.\n- The Cauchy–Schwarz inequality implies the covariance bound $|\\mathrm{Cov}(X,Y)| \\le \\sqrt{\\mathrm{Var}(X)\\,\\mathrm{Var}(Y)}$.\n- White input means $\\mathbb{E}[u(n)u(n-\\ell)] = 0$ for all nonzero integer lags $\\ell$, and $\\mathbb{E}[u(n)^2] = 1$.\n\nNo additional structural identities, paraunitary properties, or specialized lattice formulas may be assumed beyond what is written above.\n\nYou must implement the conservative, worst-case design that treats the unknown cross-covariance between $f_{m-1}(n)$ and $b_{m-1}(n-1)$ adversarially (within the Cauchy–Schwarz bound) and selects $s_m$ as large as possible while ensuring both per-section constraints $\\mathbb{E}[f_m(n)^2] \\le P_m$ and $\\mathbb{E}[b_m(n)^2] \\le P_m$. This yields a recursion on upper bounds of the variances across sections. Use the resulting recursion to compute the numerical values of $\\{s_m\\}_{m=1}^M$.\n\nProgram requirements:\n- Implement a function that, given a list of reflection coefficients $\\{k_m\\}_{m=1}^M$ and a list of power budgets $\\{P_m\\}_{m=1}^M$, returns the list of per-section scalings $\\{s_m\\}_{m=1}^M$ computed by the conservative worst-case design derived from the above fundamentals.\n- Initialization must use $\\mathbb{E}[f_0(n)^2] = 1$ and $\\mathbb{E}[b_0(n)^2] = 0$.\n- For numerical output, round each $s_m$ to $6$ decimal places using standard rounding to nearest, ties to even.\n\nTest suite:\n- Case A (general mixed magnitudes and signs): $\\{k_m\\} = [\\,0.6,\\,-0.4,\\,0.7\\,]$, $\\{P_m\\} = [\\,1,\\,1,\\,1\\,]$.\n- Case B (near-boundary single section): $\\{k_m\\} = [\\,0.99\\,]$, $\\{P_m\\} = [\\,1\\,]$.\n- Case C (all zero reflections): $\\{k_m\\} = [\\,0,\\,0,\\,0,\\,0\\,]$, $\\{P_m\\} = [\\,1,\\,1,\\,1,\\,1\\,]$.\n- Case D (tight budgets): $\\{k_m\\} = [\\,0.8,\\,0.9\\,]$, $\\{P_m\\} = [\\,0.5,\\,0.5\\,]$.\n- Case E (alternating small reflections, decreasing budgets): $\\{k_m\\} = [\\,-0.2,\\,0.2,\\,-0.2,\\,0.2,\\,-0.2\\,]$, $\\{P_m\\} = [\\,1,\\,0.8,\\,0.7,\\,0.6,\\,0.5\\,]$.\n\nFinal output format:\n- Your program should produce a single line containing a list of lists of floats. Each inner list corresponds to one test case, in the same order as specified above, and contains the rounded per-section scaling values $[\\,s_1, s_2, \\dots, s_M\\,]$ for that case.\n- The single output line must be exactly a valid Python-style list literal, for example: \"[[0.123456,0.234567],[1.000000]]\".\n\nThere are no physical units or angles involved in this problem. All answers are unitless real numbers. The only acceptable output types are lists of floats as specified above, rounded to $6$ decimals and arranged in a single-line list-of-lists format.", "solution": "The problem statement is critically examined and found to be valid, despite a minor linguistic ambiguity which will be resolved. The problem is a well-posed exercise in digital signal processing, grounded in fundamental principles of probability theory and filter design.\n\nThe problem contains a contradiction in its directives for choosing the scaling factor $s_m$. It first states to \"choose the smallest per-section scaling $s_m$ that guarantees the above mean-square constraints,\" which implies selecting an infinitesimally small positive value. Subsequently, it directs to \"selects $s_m$ as large as possible while ensuring both per-section constraints.\" This latter directive represents the standard, logical engineering objective: to apply the minimum necessary attenuation to preserve signal integrity and dynamic range. Any other choice would be arbitrary and suboptimal. Therefore, we shall proceed by deriving the largest possible scaling factor $s_m$ that satisfies the given power constraints under a worst-case scenario analysis.\n\nThe objective is to derive a recursive algorithm to compute the per-section scaling factors $\\{s_m\\}_{m=1}^M$ for an IIR lattice filter. The input to the filter, $u(n)$, is a zero-mean, unit-variance white noise process.\nThe initial conditions at stage $m=0$ are $f_0(n) = u(n)$ and $b_0(n) = 0$, which implies initial variances $V_f(0) \\equiv \\mathbb{E}[f_0(n)^2] = 1$ and $V_b(0) \\equiv \\mathbb{E}[b_0(n)^2] = 0$.\n\nFor each subsequent stage $m \\in \\{1, 2, \\dots, M\\}$, we must determine the scaling factor $s_m$. The analysis proceeds as follows.\n\nFirst, we express the mean-square values of the unscaled intermediate signals, $\\hat f_m(n)$ and $\\hat b_m(n)$, in terms of the statistics of the signals from the previous stage, $f_{m-1}(n)$ and $b_{m-1}(n-1)$.\nThe unscaled signals are defined as:\n$$ \\hat f_m(n) = f_{m-1}(n) + k_m\\, b_{m-1}(n-1) $$\n$$ \\hat b_m(n) = k_m\\, f_{m-1}(n) + b_{m-1}(n-1) $$\nLet $V_f(m-1) = \\mathbb{E}[f_{m-1}(n)^2]$ and $V_b(m-1) = \\mathbb{E}[b_{m-1}(n)^2]$ be the variances at the output of stage $m-1$. Since the signals are zero-mean, their variance is equal to their mean-square value. The processes are assumed wide-sense stationary, so $\\mathbb{E}[b_{m-1}(n-1)^2] = V_b(m-1)$. Let $C_{m-1} = \\mathbb{E}[f_{m-1}(n) b_{m-1}(n-1)]$ be the cross-covariance.\nUsing the linearity of expectation and the formula for the variance of a sum of random variables, the variances of the unscaled signals, denoted $\\hat V_f(m)$ and $\\hat V_b(m)$, are:\n$$ \\hat V_f(m) = \\mathbb{E}[\\hat f_m(n)^2] = V_f(m-1) + k_m^2 V_b(m-1) + 2k_m C_{m-1} $$\n$$ \\hat V_b(m) = \\mathbb{E}[\\hat b_m(n)^2] = k_m^2 V_f(m-1) + V_b(m-1) + 2k_m C_{m-1} $$\n\nThe problem requires a conservative, worst-case design. The cross-covariance $C_{m-1}$ is unknown beyond the bound given by the Cauchy–Schwarz inequality:\n$$ |C_{m-1}| \\le \\sqrt{V_f(m-1) V_b(m-1)} $$\nTo find the worst-case (maximum) unscaled variances, we must choose the value of $C_{m-1}$ within its allowed range that maximizes both $\\hat V_f(m)$ and $\\hat V_b(m)$. The term $2k_m C_{m-1}$ is maximized when $C_{m-1}$ has the same sign as $k_m$. Thus, the worst-case covariance is $C_{m-1, \\text{worst}} = \\text{sgn}(k_m) \\sqrt{V_f(m-1) V_b(m-1)}$, which results in a contribution of $2|k_m| \\sqrt{V_f(m-1) V_b(m-1)}$.\nThe maximum possible unscaled variances, $\\hat V_{f, \\text{max}}(m)$ and $\\hat V_{b, \\text{max}}(m)$, are therefore:\n$$ \\hat V_{f, \\text{max}}(m) = V_f(m-1) + k_m^2 V_b(m-1) + 2|k_m| \\sqrt{V_f(m-1) V_b(m-1)} $$\n$$ \\hat V_{b, \\text{max}}(m) = k_m^2 V_f(m-1) + V_b(m-1) + 2|k_m| \\sqrt{V_f(m-1) V_b(m-1)} $$\nThese expressions are recognizable as perfect squares:\n$$ \\hat V_{f, \\text{max}}(m) = \\left( \\sqrt{V_f(m-1)} + |k_m| \\sqrt{V_b(m-1)} \\right)^2 $$\n$$ \\hat V_{b, \\text{max}}(m) = \\left( |k_m| \\sqrt{V_f(m-1)} + \\sqrt{V_b(m-1)} \\right)^2 $$\n\nThe scaled outputs are $f_m(n) = s_m \\hat f_m(n)$ and $b_m(n) = s_m \\hat b_m(n)$. The constraints are on their mean-square values:\n$$ V_f(m) = \\mathbb{E}[f_m(n)^2] = s_m^2 \\mathbb{E}[\\hat f_m(n)^2] \\le P_m $$\n$$ V_b(m) = \\mathbb{E}[b_m(n)^2] = s_m^2 \\mathbb{E}[\\hat b_m(n)^2] \\le P_m $$\nFor a worst-case design, these must hold for the maximum possible unscaled variances:\n$$ s_m^2 \\hat V_{f, \\text{max}}(m) \\le P_m \\quad \\implies \\quad s_m^2 \\le \\frac{P_m}{\\hat V_{f, \\text{max}}(m)} $$\n$$ s_m^2 \\hat V_{b, \\text{max}}(m) \\le P_m \\quad \\implies \\quad s_m^2 \\le \\frac{P_m}{\\hat V_{b, \\text{max}}(m)} $$\nTo satisfy both conditions and select the largest possible $s_m$, we must choose:\n$$ s_m^2 = \\min\\left( \\frac{P_m}{\\hat V_{f, \\text{max}}(m)}, \\frac{P_m}{\\hat V_{b, \\text{max}}(m)} \\right) = \\frac{P_m}{\\max\\left(\\hat V_{f, \\text{max}}(m), \\hat V_{b, \\text{max}}(m)\\right)} $$\nTaking the square root gives the scaling factor $s_m$:\n$$ s_m = \\sqrt{\\frac{P_m}{\\max\\left(\\hat V_{f, \\text{max}}(m), \\hat V_{b, \\text{max}}(m)\\right)}} $$\n\nTo determine the maximum of the two unscaled variances, we compare their bases. Let $x = \\sqrt{V_f(m-1)}$ and $y = \\sqrt{V_b(m-1)}$. We compare $x + |k_m|y$ and $|k_m|x + y$. Their difference is $(x + |k_m|y) - (|k_m|x + y) = (1-|k_m|)(x-y)$. Since $|k_m| < 1$, the term $(1-|k_m|)$ is positive. Thus, $\\hat V_{f, \\text{max}}(m) \\ge \\hat V_{b, \\text{max}}(m)$ if and only if $V_f(m-1) \\ge V_b(m-1)$.\nConsequently, $\\max\\left(\\hat V_{f, \\text{max}}(m), \\hat V_{b, \\text{max}}(m)\\right) = \\left(|k_m|\\sqrt{V_{\\min}(m-1)} + \\sqrt{V_{\\max}(m-1)}\\right)^2$, where $V_{\\max}(m-1) = \\max(V_f(m-1), V_b(m-1))$ and $V_{\\min}(m-1) = \\min(V_f(m-1), V_b(m-1))$.\n\nThe final step is to establish the recursion. The variances $V_f(m)$ and $V_b(m)$ serve as inputs to the next stage, $m+1$. A conservative design propagates the worst-case bounds. Therefore, we update the variances using the maximum possible values they can attain, which ensures the scaling at stage $m+1$ is sufficient for any allowed signal statistics up to stage $m$.\n$$ V_f(m) = s_m^2 \\hat V_{f, \\text{max}}(m) $$\n$$ V_b(m) = s_m^2 \\hat V_{b, \\text{max}}(m) $$\nWith our choice of $s_m$, one of these variances will be exactly equal to the budget $P_m$, and the other will be less than or equal to $P_m$. This satisfies the constraints at stage $m$.\n\nThe complete recursive algorithm is as follows:\n1. Initialize variances for the input stage $m=0$: $V_f \\leftarrow 1$ and $V_b \\leftarrow 0$.\n2. For each stage $m = 1, 2, \\dots, M$:\n   a. Given the reflection coefficient $k_m$, power budget $P_m$, and previous-stage variances $V_f$ and $V_b$:\n   b. Compute the maximum possible unscaled variances:\n      $$ \\hat V_{f, \\text{max}} = \\left( \\sqrt{V_f} + |k_m| \\sqrt{V_b} \\right)^2 $$\n      $$ \\hat V_{b, \\text{max}} = \\left( |k_m| \\sqrt{V_f} + \\sqrt{V_b} \\right)^2 $$\n   c. Compute the required scaling factor:\n      $$ s_m = \\sqrt{\\frac{P_m}{\\max(\\hat V_{f, \\text{max}}, \\hat V_{b, \\text{max}})}} $$\n   d. Store $s_m$.\n   e. Update the variances for the next stage using these worst-case values:\n      $$ V_f \\leftarrow s_m^2 \\cdot \\hat V_{f, \\text{max}} $$\n      $$ V_b \\leftarrow s_m^2 \\cdot \\hat V_{b, \\text{max}} $$\n3. Return the list of computed scaling factors $\\{s_m\\}_{m=1}^M$.\nThis procedure correctly implements the required conservative scaling design based entirely on the stipulated first principles.", "answer": "[[1.000000,0.806452,0.639180],[1.000000],[1.000000,1.000000,1.000000,1.000000],[0.707107,0.581390],[1.000000,0.890871,0.916858,0.941656,0.957583]]", "id": "2879658"}]}