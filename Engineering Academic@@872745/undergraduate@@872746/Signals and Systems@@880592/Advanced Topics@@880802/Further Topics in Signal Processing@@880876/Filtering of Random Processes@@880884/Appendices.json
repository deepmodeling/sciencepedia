{"hands_on_practices": [{"introduction": "Understanding how a filter affects a signal begins with the most fundamental case: processing white noise. This exercise provides a direct, hands-on calculation of how a simple discrete-time Finite Impulse Response (FIR) filter transforms the variance of an input white noise sequence. By working through this problem [@problem_id:1718357], you will solidify your understanding of the direct link between a filter's coefficients and its impact on random signal power.", "problem": "A discrete-time random signal, denoted by $x[n]$, models a stream of noisy measurements from a sensor. This signal is characterized as a stationary white noise process, which means it consists of a sequence of uncorrelated random variables. Each variable in the sequence has a mean of zero and a variance of $\\sigma_x^2$.\n\nTo analyze the underlying trends in the data, this signal is passed through a simple digital Linear Time-Invariant (LTI) filter. The filter's behavior is described by the following input-output difference equation, where $y[n]$ is the output signal:\n$$y[n] = x[n] - 0.8 x[n-1] + 0.2 x[n-2]$$\n\nYour task is to determine the variance of the output signal, denoted by $\\sigma_y^2$. Express your answer as a symbolic expression in terms of the input variance $\\sigma_x^2$.", "solution": "The input is a zero-mean, stationary white noise process with variance $\\sigma_{x}^{2}$ and autocorrelation $R_{x}[k]=\\sigma_{x}^{2}\\delta[k]$, where $\\delta[k]$ is the Kronecker delta. The LTI FIR filter is given by\n$$\ny[n]=b_{0}x[n]+b_{1}x[n-1]+b_{2}x[n-2],\n$$\nwith $b_{0}=1$, $b_{1}=-0.8$, and $b_{2}=0.2$.\n\nSince $x[n]$ is zero-mean, the output mean is zero, and the output variance is\n$$\n\\sigma_{y}^{2}=\\mathbb{E}\\{y^{2}[n]\\}.\n$$\nExpanding $y^{2}[n]$ and taking expectation,\n$$\n\\mathbb{E}\\{y^{2}[n]\\}=\\mathbb{E}\\left\\{\\left(\\sum_{i=0}^{2}b_{i}x[n-i]\\right)\\left(\\sum_{j=0}^{2}b_{j}x[n-j]\\right)\\right\\}\n=\\sum_{i=0}^{2}\\sum_{j=0}^{2}b_{i}b_{j}\\,\\mathbb{E}\\{x[n-i]x[n-j]\\}.\n$$\nUsing stationarity and whiteness,\n$$\n\\mathbb{E}\\{x[n-i]x[n-j]\\}=R_{x}[j-i]=\\sigma_{x}^{2}\\delta[j-i],\n$$\nso only the terms with $i=j$ remain, yielding\n$$\n\\sigma_{y}^{2}=\\sigma_{x}^{2}\\sum_{i=0}^{2}b_{i}^{2}.\n$$\nSubstituting the coefficients,\n$$\n\\sum_{i=0}^{2}b_{i}^{2}=1^{2}+(-0.8)^{2}+(0.2)^{2}=1+0.64+0.04=1.68.\n$$\nTherefore,\n$$\n\\sigma_{y}^{2}=1.68\\,\\sigma_{x}^{2}.\n$$", "answer": "$$\\boxed{1.68\\sigma_{x}^{2}}$$", "id": "1718357"}, {"introduction": "Moving from the time domain to the frequency domain provides a powerful perspective on filtering. This practice problem [@problem_id:1718365] introduces the concept of Power Spectral Density (PSD) and explores how an LTI filter's frequency response, $H(\\omega)$, shapes the distribution of power in a continuous-time random process. You will calculate the total average power of the output signal, a key skill in analyzing signal-to-noise ratios and the effects of frequency-selective filtering.", "problem": "A wide-sense stationary (WSS) random process $X(t)$ has a power spectral density (PSD) given by\n$$S_{XX}(\\omega) = \\frac{N_0}{1 + (a\\omega)^2}$$\nwhere $N_0$ and $a$ are positive real constants. This process is passed through a linear time-invariant (LTI) filter whose frequency response is given by\n$$H(\\omega) = \\frac{j b \\omega}{1 + j b \\omega}$$\nwhere $b$ is a positive real constant representing the filter's time constant, and $j = \\sqrt{-1}$. Let the resulting output process be denoted by $Y(t)$.\n\nAssuming that the constants $a$ and $b$ are not equal ($a \\neq b$), determine the total average power of the output process $Y(t)$. Express your answer as a single, closed-form analytic expression in terms of $N_0$, $a$, and $b$.", "solution": "For a WSS input $X(t)$ passed through an LTI filter with frequency response $H(\\omega)$, the output PSD is given by\n$$S_{YY}(\\omega)=|H(\\omega)|^{2} S_{XX}(\\omega).$$\nThe total average power of the output process equals the autocorrelation at zero lag,\n$$P_{Y} = R_{YY}(0) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} S_{YY}(\\omega)\\, d\\omega,$$\nby the Wiener–Khinchin theorem.\n\nGiven\n$$S_{XX}(\\omega) = \\frac{N_{0}}{1 + (a\\omega)^{2}}, \\quad H(\\omega) = \\frac{j b \\omega}{1 + j b \\omega},$$\nwe compute\n$$|H(\\omega)|^{2} = \\frac{(b\\omega)^{2}}{1 + (b\\omega)^{2}}.$$\nTherefore,\n$$S_{YY}(\\omega) = \\frac{N_{0} (b\\omega)^{2}}{\\left[1 + (b\\omega)^{2}\\right]\\left[1 + (a\\omega)^{2}\\right]}.$$\nHence,\n$$P_{Y} = \\frac{N_{0} b^{2}}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{\\omega^{2}}{\\left[1 + (b\\omega)^{2}\\right]\\left[1 + (a\\omega)^{2}\\right]} \\, d\\omega.$$\n\nDefine\n$$I \\equiv \\int_{-\\infty}^{\\infty} \\frac{\\omega^{2}}{\\left(1 + b^{2}\\omega^{2}\\right)\\left(1 + a^{2}\\omega^{2}\\right)} \\, d\\omega.$$\nUse the partial fraction decomposition (valid for $a \\neq b$ so that $b^{2} - a^{2} \\neq 0$):\n$$\\frac{\\omega^{2}}{\\left(1 + a^{2}\\omega^{2}\\right)\\left(1 + b^{2}\\omega^{2}\\right)} = \\frac{A}{1 + a^{2}\\omega^{2}} + \\frac{B}{1 + b^{2}\\omega^{2}},$$\nwhich implies\n$$A + B = 0, \\quad A b^{2} + B a^{2} = 1.$$\nSolving gives\n$$A = \\frac{1}{b^{2} - a^{2}}, \\quad B = -\\frac{1}{b^{2} - a^{2}}.$$\nThus\n$$I = A \\int_{-\\infty}^{\\infty} \\frac{d\\omega}{1 + a^{2}\\omega^{2}} + B \\int_{-\\infty}^{\\infty} \\frac{d\\omega}{1 + b^{2}\\omega^{2}}.$$\nUsing the standard integral $\\int_{-\\infty}^{\\infty} \\frac{d\\omega}{1 + c^{2}\\omega^{2}} = \\frac{\\pi}{c}$ for $c0$ and noting $a0$, $b0$, we obtain\n$$I = \\pi\\left(\\frac{A}{a} + \\frac{B}{b}\\right) = \\pi \\left(\\frac{1}{b^{2} - a^{2}}\\right)\\left(\\frac{1}{a} - \\frac{1}{b}\\right) = \\frac{\\pi}{ab(a + b)}.$$\n\nTherefore,\n$$P_{Y} = \\frac{N_{0} b^{2}}{2\\pi} \\cdot \\frac{\\pi}{ab(a + b)} = \\frac{N_{0} b}{2a(a + b)}.$$\nThis is the total average power of the output process $Y(t)$ for $a \\neq b$.", "answer": "$$\\boxed{\\frac{N_{0} b}{2 a \\left(a + b\\right)}}$$", "id": "1718365"}, {"introduction": "The ultimate goal of signal processing is often not just to analyze systems, but to design them for a specific purpose. This advanced exercise [@problem_id:1718320] challenges you to step into the role of a filter designer. Starting from a set of practical requirements—unity DC gain and a null at a specific frequency—you will determine the filter coefficients that not only meet these specifications but also minimize the output noise variance, demonstrating a classic trade-off in engineering design.", "problem": "An engineer is designing a digital filter to process a noisy signal. The filter is a causal, three-tap Finite Impulse Response (FIR) filter with a real-valued impulse response given by $h[n] = c_0 \\delta[n] + c_1 \\delta[n-1] + c_2 \\delta[n-2]$.\n\nThe filter is intended to be a notch filter, and its design is governed by two requirements on its frequency response, $H(e^{j\\omega})$:\n1.  It must have a unity gain for direct current (DC) signals.\n2.  It must completely block signals at the normalized angular frequency of $\\omega_0 = \\pi/2$ radians per sample.\n\nThe input to this filter, $X[n]$, is a discrete-time, real-valued, zero-mean, wide-sense stationary (WSS) white noise process with a variance of $\\sigma_X^2$. The filter coefficients $c_0, c_1, c_2$ are to be chosen such that they satisfy the two design requirements while also minimizing the variance of the output noise process, $Y[n]$.\n\nDetermine the minimum possible variance of the output process, $\\sigma_Y^2$. Express your answer as a symbolic expression in terms of the input variance $\\sigma_X^2$.", "solution": "The three-tap causal FIR filter has impulse response $h[n] = c_{0}\\delta[n] + c_{1}\\delta[n-1] + c_{2}\\delta[n-2]$ and frequency response\n$$\nH(e^{j\\omega}) = c_{0} + c_{1}e^{-j\\omega} + c_{2}e^{-j2\\omega}.\n$$\nThe DC unity-gain requirement imposes\n$$\nH(e^{j0}) = c_{0} + c_{1} + c_{2} = 1.\n$$\nThe notch at $\\omega_{0} = \\pi/2$ requires\n$$\nH(e^{j\\pi/2}) = c_{0} + c_{1}e^{-j\\pi/2} + c_{2}e^{-j\\pi} = 0.\n$$\nUsing $e^{-j\\pi/2} = -j$ and $e^{-j\\pi} = -1$, this becomes\n$$\nc_{0} - j c_{1} - c_{2} = 0,\n$$\nwhose real and imaginary parts give\n$$\nc_{0} - c_{2} = 0,\\quad -c_{1} = 0 \\;\\;\\Rightarrow\\;\\; c_{1} = 0,\\; c_{0} = c_{2}.\n$$\nApplying the DC constraint then yields $2c_{0} = 1$, so\n$$\nc_{0} = \\frac{1}{2},\\quad c_{1} = 0,\\quad c_{2} = \\frac{1}{2}.\n$$\nFor a zero-mean WSS white noise input $X[n]$ with variance $\\sigma_{X}^{2}$, the output variance is\n$$\n\\sigma_{Y}^{2} = \\sigma_{X}^{2}\\sum_{n}|h[n]|^{2},\n$$\nwhich follows from $S_{X}(e^{j\\omega}) = \\sigma_{X}^{2}$, $S_{Y}(e^{j\\omega}) = |H(e^{j\\omega})|^{2}S_{X}(e^{j\\omega})$, and Parseval’s relation $(1/2\\pi)\\int_{-\\pi}^{\\pi}|H(e^{j\\omega})|^{2}\\,d\\omega = \\sum_{n}|h[n]|^{2}$. With the coefficients found,\n$$\n\\sum_{n}|h[n]|^{2} = \\left(\\frac{1}{2}\\right)^{2} + 0^{2} + \\left(\\frac{1}{2}\\right)^{2} = \\frac{1}{2},\n$$\nso the (and thus minimum) output variance is\n$$\n\\sigma_{Y}^{2} = \\frac{1}{2}\\sigma_{X}^{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{2}\\sigma_{X}^{2}}$$", "id": "1718320"}]}