## Introduction
The analysis of Linear Time-Invariant (LTI) systems is fundamental to engineering and physics, providing a powerful framework for understanding how signals are processed and transformed. While time-domain methods like convolution offer a complete picture, they can be computationally intensive and conceptually complex. A more intuitive and often simpler approach emerges when we shift our perspective to the frequency domain, particularly when dealing with the common and important class of periodic input signals. This article addresses the core question: How do LTI systems respond to periodic inputs, and how can we use frequency-domain tools to analyze and predict this behavior efficiently?

This article is structured to build a comprehensive understanding from the ground up. In **Principles and Mechanisms**, we will delve into the foundational [eigenfunction](@entry_id:149030) property of LTI systems, establishing why the [frequency response](@entry_id:183149), $H(j\omega)$, is the key to this analysis. We will see how to use Fourier series to decompose any periodic input and determine the system's output. Following this, **Applications and Interdisciplinary Connections** will showcase the real-world utility of these concepts, exploring everything from [electronic filter](@entry_id:276091) design and [signal distortion](@entry_id:269932) to mechanical resonance and advanced [system identification](@entry_id:201290) in experimental physics. Finally, **Hands-On Practices** will provide you with the opportunity to apply your knowledge to solve practical problems in [system analysis](@entry_id:263805) and design. By the end, you will have a robust grasp of one of the most elegant and powerful tools in signal processing.

## Principles and Mechanisms

The analysis of how Linear Time-Invariant (LTI) systems respond to various inputs is a cornerstone of signal processing. While the time-domain [convolution integral](@entry_id:155865) provides a complete description of this relationship, a frequency-domain perspective often yields deeper insights and substantially simplifies calculations, especially for a specific, yet ubiquitous, class of signals: periodic inputs. This chapter will elucidate the fundamental principles governing the response of LTI systems to [periodic signals](@entry_id:266688), anchored by the concept of the system's frequency response. We will explore why LTI systems are uniquely tractable in the frequency domain, how they modify input signals, and what this implies for [signal integrity](@entry_id:170139) and power.

### The Eigenfunction Property of LTI Systems

The profound analytical power of frequency-domain methods stems from a special relationship between LTI systems and a class of functions known as complex exponentials. A signal of the form $x(t) = \exp(j\omega_0 t)$, where $j$ is the imaginary unit and $\omega_0$ is a constant angular frequency, is called an **[eigenfunction](@entry_id:149030)** of any LTI system. This term, borrowed from linear algebra, signifies that when this function is the input to the system, the output is the very same function, merely scaled by a complex constant.

Let an LTI system be described by its impulse response $h(t)$. The output $y(t)$ for an input $x(t)$ is given by the convolution integral:
$$y(t) = \int_{-\infty}^{\infty} h(\tau) x(t-\tau) \,d\tau$$
If we let the input be $x(t) = \exp(j\omega_0 t)$, the output becomes:
$$y(t) = \int_{-\infty}^{\infty} h(\tau) \exp(j\omega_0(t-\tau)) \,d\tau = \exp(j\omega_0 t) \int_{-\infty}^{\infty} h(\tau) \exp(-j\omega_0 \tau) \,d\tau$$
The integral on the right is a function only of the system's impulse response $h(t)$ and the input frequency $\omega_0$. This integral is precisely the definition of the **Fourier Transform** of $h(t)$, which we call the **[frequency response](@entry_id:183149)** of the system, denoted by $H(j\omega)$.
$$H(j\omega) = \int_{-\infty}^{\infty} h(t) \exp(-j\omega t) \,dt$$
Thus, for an input $x(t) = \exp(j\omega_0 t)$, the output is:
$$y(t) = H(j\omega_0) \exp(j\omega_0 t)$$
The complex number $H(j\omega_0)$ is the **eigenvalue** corresponding to the [eigenfunction](@entry_id:149030) $\exp(j\omega_0 t)$. This relationship is the bedrock of frequency-domain analysis for LTI systems. It reveals a crucial property: an LTI system cannot generate new frequency components. If the input is a pure complex exponential at frequency $\omega_0$, the output is also a pure [complex exponential](@entry_id:265100) at the exact same frequency $\omega_0$. The system's only effect is to scale the signal's amplitude and shift its phase, as encapsulated by the complex number $H(j\omega_0)$.

This "no new frequencies" principle is a direct consequence of both linearity and time-invariance. The [frequency spectrum](@entry_id:276824) of the output signal, $Y(j\omega)$, is the product of the input signal's spectrum, $X(j\omega)$, and the system's frequency response, $H(j\omega)$. For a sinusoidal input like $x(t) = \cos(\omega_0 t)$, the spectrum $X(j\omega)$ consists of impulses only at $\omega = \pm\omega_0$. Consequently, the output spectrum $Y(j\omega) = H(j\omega)X(j\omega)$ can also only have non-zero values at these same frequencies, precluding the creation of harmonics at $2\omega_0$, $3\omega_0$, etc. [@problem_id:1721558].

This behavior stands in stark contrast to **nonlinear systems**. For instance, a simple nonlinear device with the relationship $y(t) = (x(t))^2$ will generate new frequencies. If the input is a simple [sinusoid](@entry_id:274998), $x(t) = B\cos(\omega_0 t)$, the output is $y(t) = B^2\cos^2(\omega_0 t) = \frac{B^2}{2}(1 + \cos(2\omega_0 t))$. The output contains a DC component (frequency $\omega=0$) and a second harmonic component (frequency $2\omega_0$), neither of which was present in the input. If the input contains multiple frequencies, such as $x(t) = A + B\cos(\omega_0 t)$, the output $y(t) = (A + B\cos(\omega_0 t))^2 = A^2 + 2AB\cos(\omega_0 t) + B^2\cos^2(\omega_0 t)$ contains not only the original frequencies and their harmonics but also **intermodulation products**, like the $2AB\cos(\omega_0 t)$ term, which represent a failure of the [superposition principle](@entry_id:144649) and are a hallmark of nonlinearity [@problem_id:1721521].

### Response to Real Sinusoidal and Periodic Inputs

While complex exponentials are a powerful analytical tool, real-world signals are real-valued. We can leverage the eigenfunction property for real sinusoids by expressing them using Euler's formula, for example, $x(t) = A\cos(\omega_0 t) = \frac{A}{2}(\exp(j\omega_0 t) + \exp(-j\omega_0 t))$. Due to linearity, the response of an LTI system is the sum of the responses to the two complex exponential components:
$$y(t) = \frac{A}{2} H(j\omega_0) \exp(j\omega_0 t) + \frac{A}{2} H(-j\omega_0) \exp(-j\omega_0 t)$$
For any real-valued impulse response $h(t)$, the frequency response has [conjugate symmetry](@entry_id:144131): $H(-j\omega) = H^*(j\omega)$, where the asterisk denotes the [complex conjugate](@entry_id:174888). Expressing $H(j\omega)$ in [polar form](@entry_id:168412), $H(j\omega) = |H(j\omega)|\exp(j\angle H(j\omega))$, allows us to simplify the output to:
$$y(t) = A|H(j\omega_0)| \cos(\omega_0 t + \angle H(j\omega_0))$$
This is a result of paramount importance: the [steady-state response](@entry_id:173787) of a stable LTI system to a sinusoidal input is another sinusoid of the **same frequency**, with its amplitude scaled by the **magnitude response** $|H(j\omega_0)|$ and its phase shifted by the **phase response** $\angle H(j\omega_0)$.

This principle allows us to determine the frequency response of a "black box" LTI system by observing its input-output behavior.
- If an input $x(t) = \cos(2t)$ produces an output $y(t) = 5\sin(2t)$, we can rewrite the output as $y(t) = 5\cos(2t - \pi/2)$. Comparing this to the general form, we see the system must have amplified the amplitude by a factor of 5 and shifted the phase by $-\pi/2$ radians at the frequency $\omega=2$ rad/s. Therefore, the [frequency response](@entry_id:183149) at this frequency must be $H(j2) = 5\exp(-j\pi/2) = -5j$ [@problem_id:1721569].
- Similarly, if the system's frequency response is known to be purely imaginary for all $\omega$, say $H(j\omega) = jB(\omega)$ for some real function $B$, then the phase shift is always $\pm\pi/2$. For an input $x(t) = \cos(\omega_0 t)$, the output will be of the form $C\sin(\omega_0 t)$, indicating a quadrature phase relationship [@problem_id:1721547].

The true power of this approach is realized when dealing with general [periodic signals](@entry_id:266688). According to Fourier's theorem, any well-behaved periodic signal $x(t)$ with [fundamental frequency](@entry_id:268182) $\omega_0$ can be represented as a sum of harmonically related sinusoids—its **Fourier series**:
$$x(t) = c_0 + \sum_{k=1}^{\infty} |c_k|\cos(k\omega_0 t + \angle c_k)$$
Or, more compactly, using [complex exponentials](@entry_id:198168):
$$x(t) = \sum_{k=-\infty}^{\infty} c_k \exp(jk\omega_0 t)$$
where $c_k$ are the complex Fourier series coefficients. Since the system is linear, the principle of **superposition** applies. The total output $y(t)$ is simply the sum of the individual responses to each harmonic component of the input. Each complex exponential term $c_k \exp(jk\omega_0 t)$ is scaled by the [frequency response](@entry_id:183149) $H(j\omega)$ evaluated at that component's frequency, $\omega = k\omega_0$.
$$y(t) = \sum_{k=-\infty}^{\infty} c_k H(jk\omega_0) \exp(jk\omega_0 t)$$
The Fourier series for the output signal $y(t)$ is therefore given by coefficients $d_k = c_k H(jk\omega_0)$. This provides a complete recipe for finding the output of an LTI system for any periodic input:
1.  Decompose the input signal $x(t)$ into its Fourier series to find the coefficients $c_k$.
2.  For each integer $k$, calculate the output coefficient $d_k$ by multiplying the input coefficient $c_k$ by the system's [frequency response](@entry_id:183149) $H(jk\omega_0)$.
3.  Synthesize the output signal $y(t)$ from the new set of coefficients $d_k$.

As a direct application, consider an input signal $x(t) = 2 + \cos(5t)$ applied to an LTI system, yielding the output $y(t) = 1 - 2\cos(5t)$. We can treat this as a signal with two frequency components: a DC component ($k=0, \omega=0$) and a component at $\omega=5$ rad/s.
- For the DC component, the input is $c_0 = 2$ and the output is $d_0 = 1$. Therefore, $H(j0) = d_0/c_0 = 1/2$.
- For the AC component at $\omega=5$, the input can be seen as having a [complex amplitude](@entry_id:164138) of 1, and the output has a [complex amplitude](@entry_id:164138) of -2 (representing a magnitude of 2 and a phase shift of $\pi$ radians). Thus, $H(j5) = -2/1 = -2$ [@problem_id:1721565].

A special consideration arises for systems with a pole at the origin, such as an [ideal integrator](@entry_id:276682) where $H(j\omega) = 1/(j\omega)$. The response at DC, $H(j0)$, is infinite. If a periodic input signal has a non-zero DC component ($c_0 \neq 0$), the output will contain a term proportional to $c_0 \cdot t$, which grows without bound. For the output of an integrator to be periodic, the input signal must have zero average value, i.e., its DC Fourier coefficient $c_0$ must be zero [@problem_id:1721541].

### Signal Distortion in LTI Systems

The analysis above reveals that an LTI system acts as a "filter," selectively modifying the amplitudes and phases of the input's frequency components. This filtering action can change the shape of the waveform, a phenomenon known as **distortion**.

For a signal to pass through a system without any change in its shape—a process called **distortionless transmission**—the output must be a scaled and delayed version of the input: $y(t) = Kx(t - t_0)$, for some constant gain $K$ and time delay $t_0$. Taking the Fourier transform of this relationship gives $Y(j\omega) = K \exp(-j\omega t_0) X(j\omega)$. This implies that the frequency response of a distortionless system must be $H(j\omega) = Y(j\omega)/X(j\omega) = K \exp(-j\omega t_0)$. Such a system must satisfy two conditions simultaneously:
1.  **Constant Magnitude Response**: $|H(j\omega)| = K$ for all frequencies in the signal's bandwidth.
2.  **Linear Phase Response**: $\angle H(j\omega) = -\omega t_0$, a linear function of frequency.

If a periodic square wave is passed through a system with exactly these characteristics, each of its harmonic components is scaled by the same factor $K$ and delayed by the same time amount $t_0$. When these modified harmonics are summed, they reconstruct the original square wave, but scaled in amplitude by $K$ and shifted in time by $t_0$ [@problem_id:1721520].

When either of these conditions is violated, distortion occurs.
- **Magnitude Distortion**: If $|H(j\omega)|$ is not constant, different harmonics are amplified or attenuated by different amounts, altering their relative contributions and thus changing the waveform's shape. An [ideal low-pass filter](@entry_id:266159), for example, exhibits extreme magnitude distortion by completely eliminating all harmonics above its [cutoff frequency](@entry_id:276383).

- **Phase Distortion**: If $\angle H(j\omega)$ is not a linear function of $\omega$, the system exhibits [phase distortion](@entry_id:184482). The [group delay](@entry_id:267197) of a system, defined as $\tau_g(\omega) = -d(\angle H(j\omega))/d\omega$, represents the time delay experienced by a narrow band of frequencies around $\omega$. For [linear phase](@entry_id:274637), the group delay is constant ($t_0$). If the phase is nonlinear, the [group delay](@entry_id:267197) is frequency-dependent. This means different harmonic components of the input signal are delayed by different amounts of time. When they are summed at the output, they no longer align correctly, resulting in a smeared or reshaped waveform, even if the magnitude response is perfectly flat. A simple first-order filter with $H(j\omega) = 1/(1+j\omega\tau)$ has a nonlinear [phase response](@entry_id:275122) $\angle H(j\omega) = -\arctan(\omega\tau)$, causing [phase distortion](@entry_id:184482) for any input signal composed of multiple frequencies [@problem_id:1721553].

A striking example of distortion occurs when a signal with sharp discontinuities, like a square wave, is passed through an [ideal low-pass filter](@entry_id:266159). Although the filter is "ideal" in its frequency-domain magnitude response, it causes significant time-domain distortion. The output signal exhibits oscillations and an overshoot near the discontinuities of the input. This is the **Gibbs phenomenon**. It arises because a sharp edge requires an infinite number of harmonics to be represented perfectly. By abruptly truncating the Fourier series, the filter removes the higher harmonics needed for [perfect reconstruction](@entry_id:194472). The resulting finite sum of sinusoids overshoots the target value at the discontinuity. For a square wave jumping from -1 to +1, the output will reach a peak value of approximately 1.179, an overshoot of nearly 9% of the total jump, no matter how many harmonics are included (as long as it's a finite number) [@problem_id:1721538].

### Power Calculations for Periodic Signals

The frequency-domain approach also simplifies the calculation of signal power. For a periodic signal $y(t)$, the average power (dissipated in a $1\Omega$ resistor) is defined as $P_y = \frac{1}{T_0} \int_{T_0} |y(t)|^2 dt$. Calculating this integral directly can be cumbersome. **Parseval's theorem** provides an elegant alternative by relating the [average power](@entry_id:271791) to the signal's Fourier series coefficients $d_k$:
$$P_y = \sum_{k=-\infty}^{\infty} |d_k|^2$$
This theorem states that the total average power of a signal is the sum of the average powers of its individual harmonic components. Since the output coefficients are $d_k = c_k H(jk\omega_0)$, the output power can be calculated as:
$$P_y = \sum_{k=-\infty}^{\infty} |c_k H(jk\omega_0)|^2 = \sum_{k=-\infty}^{\infty} |c_k|^2 |H(jk\omega_0)|^2$$
This powerful result means we can calculate the output power without ever synthesizing the output signal $y(t)$ in the time domain. We simply need to know the power spectrum of the input, $|c_k|^2$, and the magnitude response of the system, $|H(j\omega)|$.

For example, consider an input $x(t) = V_0 + V_1\cos(\omega_0 t)$ to an LTI system. This signal has a DC component ($c_0 = V_0$) and AC components at $\pm\omega_0$ ($c_{\pm 1} = V_1/2$). The input power is $P_x = V_0^2 + (V_1/2)^2 + (V_1/2)^2 = V_0^2 + V_1^2/2$. The output signal will have components $d_0 = V_0 H(j0)$ and $d_{\pm 1} = (V_1/2) H(\pm j\omega_0)$. The output power is therefore the sum of the powers of the modified components:
$$P_y = |d_0|^2 + |d_1|^2 + |d_{-1}|^2 = |V_0 H(j0)|^2 + 2|\frac{V_1}{2} H(j\omega_0)|^2 = V_0^2 |H(j0)|^2 + \frac{V_1^2}{2} |H(j\omega_0)|^2$$
This demonstrates that the total power of the output is the sum of the powers of each frequency component, after each has been scaled by the system's power gain ($|H(j\omega)|^2$) at that frequency [@problem_id:1748977]. This method is especially useful when a signal is passed through a filter that removes some components, as one can simply sum the powers of the components that remain in the [passband](@entry_id:276907) [@problem_id:1721548].

In summary, the [frequency response](@entry_id:183149) $H(j\omega)$ provides a complete and intuitive framework for understanding how an LTI system processes [periodic signals](@entry_id:266688). By transforming the problem from time-domain convolution to frequency-domain multiplication, we can readily analyze, predict, and quantify the system's effect on signal amplitude, phase, shape, and power.