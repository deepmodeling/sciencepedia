{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with the most intuitive case: a system whose dynamics are described by a diagonal matrix. Such systems are called \"decoupled\" because the rate of change of each state variable depends only on itself, not on the other states. This exercise provides a foundational understanding of how the eigenvalues of the system matrix, which appear on the diagonal, directly determine the exponential decay or growth of each independent mode of the system [@problem_id:1602271].", "problem": "A simplified model for the cooling of two independent electronic components, a processor and a memory module, inside a device is described by a linear time-invariant system. The state of the system is represented by the vector $x(t) = \\begin{pmatrix} x_p(t) \\\\ x_m(t) \\end{pmatrix}$, where $x_p(t)$ and $x_m(t)$ are the temperatures of the processor and memory module, respectively, above a constant ambient temperature. The temperatures are measured in degrees Celsius (째C), and time $t$ is measured in minutes.\n\nThe dynamics of this thermal system are governed by the state-space equation $\\dot{x}(t) = Ax(t)$, with the state matrix $A$ given by:\n$$\nA = \\begin{pmatrix} -0.5  0 \\\\ 0  -0.2 \\end{pmatrix}\n$$\nAt time $t=0$, when a computationally intensive task is completed, the initial temperatures of the components are measured to be $x_p(0) = 60.0$ 째C and $x_m(0) = 25.0$ 째C.\n\nDetermine the temperature of the processor, $x_p(t)$, and the temperature of the memory module, $x_m(t)$, at time $t = 3.0$ minutes. Your final answer should contain the numerical values for $x_p(3.0)$ and $x_m(3.0)$, in that order. Express the temperatures in 째C, rounded to three significant figures.", "solution": "We are given the linear time-invariant system $\\dot{x}(t)=Ax(t)$ with $A=\\begin{pmatrix}-0.5  0 \\\\ 0  -0.2\\end{pmatrix}$ and initial condition $x(0)=\\begin{pmatrix}60.0 \\\\ 25.0\\end{pmatrix}$. The general solution of an LTI system is $x(t)=\\exp(At)x(0)$. For a diagonal $A=\\operatorname{diag}(-0.5,-0.2)$, the matrix exponential is $\\exp(At)=\\operatorname{diag}(\\exp(-0.5t),\\exp(-0.2t))$. Therefore,\n$$\nx(t)=\\begin{pmatrix}\\exp(-0.5t)  0 \\\\ 0  \\exp(-0.2t)\\end{pmatrix}\\begin{pmatrix}60.0 \\\\ 25.0\\end{pmatrix}=\\begin{pmatrix}60.0\\,\\exp(-0.5t) \\\\ 25.0\\,\\exp(-0.2t)\\end{pmatrix}.\n$$\nThis gives the component temperatures as functions of time:\n$$\nx_{p}(t)=60.0\\,\\exp(-0.5t), \\qquad x_{m}(t)=25.0\\,\\exp(-0.2t).\n$$\n\nEvaluating at $t=3.0$ minutes,\n$$\nx_{p}(3.0)=60.0\\,\\exp(-1.5)\\approx 13.3878096,\\quad \\text{so to three significant figures } x_{p}(3.0)=13.4,\n$$\n$$\nx_{m}(3.0)=25.0\\,\\exp(-0.6)\\approx 13.7202909,\\quad \\text{so to three significant figures } x_{m}(3.0)=13.7.\n$$\nThese values are in degrees Celsius above ambient, as required.", "answer": "$$\\boxed{\\begin{pmatrix} 13.4  13.7 \\end{pmatrix}}$$", "id": "1602271"}, {"introduction": "Not all systems can be simplified into a decoupled, diagonal form. This next practice introduces the canonical double integrator, a fundamental model in dynamics and control, which corresponds to a non-diagonalizable system matrix. However, this matrix possesses a special property known as nilpotency, which allows for a direct and elegant computation of the state transition matrix using its series definition, $\\exp(At) = I + At + \\frac{(At)^2}{2!} + \\dots$. This exercise demonstrates that for certain important structures, the infinite series truncates, providing a powerful alternative to diagonalization [@problem_id:1602232].", "problem": "Consider a simplified one-dimensional dynamic system model. The state of this system is described by a two-component state vector $x(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$. The evolution of the state over time is governed by the linear time-invariant (LTI) differential equation $\\dot{x}(t) = A x(t)$, where the system matrix $A$ is given by:\n$$\nA = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\n$$\nThis particular system is famously known as the canonical double integrator, often used to model the kinematics of a point mass where $x_1$ represents position and $x_2$ represents velocity.\n\nThe relationship between the state at time $t$ and the initial state at time $t=0$ is given by $x(t) = \\Phi(t) x(0)$, where $\\Phi(t)$ is the state transition matrix.\n\nDetermine the state transition matrix $\\Phi(t)$ for this system. The final answer should be a $2 \\times 2$ matrix whose entries are functions of time $t$.", "solution": "For a linear time-invariant system $\\dot{x}(t)=A x(t)$, the state transition matrix is given by the matrix exponential $\\Phi(t)=\\exp(A t)$. By definition, for any square matrix $M$, the matrix exponential is\n$$\n\\exp(M)=\\sum_{k=0}^{\\infty}\\frac{M^{k}}{k!}.\n$$\nHere $A=\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$. Compute the powers of $A$:\n$$\nA^{2}=A A=\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}\\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}=\\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}=0,\n$$\nso $A$ is nilpotent of index $2$, implying $A^{k}=0$ for all $k\\geq 2$. Therefore, the series for $\\exp(A t)$ truncates:\n$$\n\\Phi(t)=\\exp(A t)=\\sum_{k=0}^{\\infty}\\frac{(A t)^{k}}{k!}=I+At,\n$$\nsince $(A t)^{k}=A^{k} t^{k}$ and all terms with $k\\geq 2$ vanish. Compute $I+At$ explicitly:\n$$\nI=\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix},\\quad At=\\begin{pmatrix} 0  t \\\\ 0  0 \\end{pmatrix}\\;\\Rightarrow\\; I+At=\\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}.\n$$\nThus, the state transition matrix is $\\Phi(t)=\\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}$.", "answer": "$$\\boxed{\\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}}$$", "id": "1602232"}, {"introduction": "Moving to a more general and powerful technique, this problem illustrates how to compute the state transition matrix by bridging the time domain and the frequency domain using the Laplace transform. The core of this method is the resolvent matrix, $(sI - A)^{-1}$, which is the Laplace transform of $\\Phi(t)$. By performing a partial fraction expansion on the resolvent, we can decompose the system's response into its fundamental modes, which can then be transformed back to the time domain. This systematic approach is broadly applicable and reveals the deep connection between a system's eigenvalues and its transient behavior [@problem_id:1602298].", "problem": "Consider a linear time-invariant (LTI) dynamical system described by the state-space equation $\\frac{d\\mathbf{x}(t)}{dt} = A \\mathbf{x}(t)$, where $\\mathbf{x}(t)$ is the state vector and $A$ is the system matrix given by:\n$$\nA = \\frac{1}{2} \\begin{pmatrix} -3  -1  1 \\\\ 1  -5  -1 \\\\ 2  -2  -4 \\end{pmatrix}\n$$\nThe evolution of the system is described by the state transition matrix, $\\Phi(t) = \\exp(At)$. A powerful method for determining $\\Phi(t)$ involves the Laplace transform. The Laplace transform of the state transition matrix is the resolvent matrix, $\\Phi(s) = (sI - A)^{-1}$.\n\nYour task is to find the state transition matrix $\\Phi(t)$ for the given system matrix $A$. Your derivation must follow these specific steps:\n1.  Determine the resolvent matrix, $(sI - A)^{-1}$.\n2.  Perform a partial fraction expansion of the resolvent matrix. This expansion will be of the form $\\sum_{i} \\frac{R_i}{s-\\lambda_i}$, where $\\lambda_i$ are the eigenvalues of $A$ and $R_i$ are the corresponding residue matrices.\n3.  Compute the state transition matrix $\\Phi(t)$ by applying the inverse Laplace transform to the partial fraction expansion.\n\nPresent the final state transition matrix $\\Phi(t)$ as a single $3 \\times 3$ matrix.", "solution": "We are given the LTI system $\\dot{\\mathbf{x}}(t)=A\\mathbf{x}(t)$ with\n$$\nA=\\frac{1}{2}\\begin{pmatrix}-3  -1  1 \\\\ 1  -5  -1 \\\\ 2  -2  -4 \\end{pmatrix},\n$$\nand we must compute the state transition matrix $\\Phi(t)=\\exp(At)$ using the Laplace transform method, for which $\\Phi(s)=(sI-A)^{-1}$ is the resolvent.\n\nStep 1: Determine $(sI-A)^{-1}$. We first find the eigenvalues of $A$. Let $M=2A=\\begin{pmatrix}-3  -1  1 \\\\ 1  -5  -1 \\\\ 2  -2  -4 \\end{pmatrix}$. If $\\mu$ is an eigenvalue of $M$, then $\\lambda=\\mu/2$ is an eigenvalue of $A$. Compute the characteristic polynomial of $M$:\n$$\n\\det(M-\\mu I)=\\begin{vmatrix}-3-\\mu  -1  1 \\\\ 1  -5-\\mu  -1 \\\\ 2  -2  -4-\\mu \\end{vmatrix}.\n$$\nExpanding along the first row yields\n$$\n(-3-\\mu)\\big(({-5-\\mu})({-4-\\mu})-(-1)(-2)\\big)+(-1)\\cdot(-1)^{1+2}\\begin{vmatrix}1  -1 \\\\ 2  -4-\\mu\\end{vmatrix}+1\\cdot\\begin{vmatrix}1  -5-\\mu \\\\ 2  -2 \\end{vmatrix}.\n$$\nCompute the minors:\n$$\n(-5-\\mu)({-4-\\mu})-(-1)(-2)=\\mu^{2}+9\\mu+18,\\quad \\begin{vmatrix}1  -1 \\\\ 2  -4-\\mu\\end{vmatrix}=-2-\\mu,\\quad \\begin{vmatrix}1  -5-\\mu \\\\ 2  -2 \\end{vmatrix}=8+2\\mu.\n$$\nHence\n$$\n\\det(M-\\mu I)=(-3-\\mu)(\\mu^{2}+9\\mu+18)+(-2-\\mu)+(8+2\\mu)=-\\big(\\mu^{3}+12\\mu^{2}+44\\mu+48\\big).\n$$\nThus the characteristic equation is $\\mu^{3}+12\\mu^{2}+44\\mu+48=0$. Testing $\\mu=-2$ gives a root, and polynomial division yields\n$$\n\\mu^{3}+12\\mu^{2}+44\\mu+48=(\\mu+2)(\\mu^{2}+10\\mu+24)=(\\mu+2)(\\mu+4)(\\mu+6).\n$$\nTherefore the eigenvalues of $M$ are $\\mu=-2,-4,-6$, so the eigenvalues of $A$ are\n$$\n\\lambda_{1}=-1,\\quad \\lambda_{2}=-2,\\quad \\lambda_{3}=-3.\n$$\nConsequently,\n$$\n\\det(sI-A)=(s-\\lambda_{1})(s-\\lambda_{2})(s-\\lambda_{3})=(s+1)(s+2)(s+3),\n$$\nand the resolvent $(sI-A)^{-1}$ exists for $s\\notin\\{-1,-2,-3\\}$.\n\nStep 2: Partial fraction expansion of $(sI-A)^{-1}$. For a diagonalizable matrix with distinct eigenvalues, the resolvent admits\n$$\n(sI-A)^{-1}=\\sum_{i=1}^{3}\\frac{R_{i}}{s-\\lambda_{i}},\n$$\nwhere the residue matrices (spectral projectors) are\n$$\nR_{i}=\\prod_{j\\neq i}\\frac{A-\\lambda_{j}I}{\\lambda_{i}-\\lambda_{j}}.\n$$\nWith $\\lambda_{1}=-1$, $\\lambda_{2}=-2$, $\\lambda_{3}=-3$, the denominators are\n$$\n(\\lambda_{1}-\\lambda_{2})(\\lambda_{1}-\\lambda_{3})=(1)(2)=2,\\quad\n(\\lambda_{2}-\\lambda_{1})(\\lambda_{2}-\\lambda_{3})=(-1)(1)=-1,\\quad\n(\\lambda_{3}-\\lambda_{1})(\\lambda_{3}-\\lambda_{2})=(-2)(-1)=2.\n$$\nHence\n$$\nR_{-1}=\\frac{(A+2I)(A+3I)}{2},\\quad R_{-2}=-(A+I)(A+3I),\\quad R_{-3}=\\frac{(A+I)(A+2I)}{2}.\n$$\nCompute the needed matrices:\n$$\nA+I=\\begin{pmatrix}-\\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  -\\frac{3}{2}  -\\frac{1}{2} \\\\ 1  -1  -1 \\end{pmatrix},\\quad\nA+2I=\\begin{pmatrix}\\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  -\\frac{1}{2}  -\\frac{1}{2} \\\\ 1  -1  0 \\end{pmatrix},\\quad\nA+3I=\\begin{pmatrix}\\frac{3}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2}  -\\frac{1}{2} \\\\ 1  -1  1 \\end{pmatrix}.\n$$\nMatrix products:\n$$\n(A+2I)(A+3I)=\\begin{pmatrix}1  -1  1 \\\\ 0  0  0 \\\\ 1  -1  1 \\end{pmatrix},\\quad\n(A+I)(A+3I)=\\begin{pmatrix}-\\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\ -\\frac{1}{2}  -\\frac{1}{2}  \\frac{1}{2} \\\\ 0  0  0 \\end{pmatrix},\\quad\n(A+I)(A+2I)=\\begin{pmatrix}0  0  0 \\\\ -1  1  1 \\\\ -1  1  1 \\end{pmatrix}.\n$$\nTherefore,\n$$\nR_{-1}=\\frac{1}{2}\\begin{pmatrix}1  -1  1 \\\\ 0  0  0 \\\\ 1  -1  1 \\end{pmatrix},\\quad\nR_{-2}=\\begin{pmatrix}\\frac{1}{2}  \\frac{1}{2}  -\\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{1}{2}  -\\frac{1}{2} \\\\ 0  0  0 \\end{pmatrix},\\quad\nR_{-3}=\\frac{1}{2}\\begin{pmatrix}0  0  0 \\\\ -1  1  1 \\\\ -1  1  1 \\end{pmatrix}.\n$$\nThus the partial fraction expansion is\n$$\n(sI-A)^{-1}=\\frac{R_{-1}}{s+1}+\\frac{R_{-2}}{s+2}+\\frac{R_{-3}}{s+3}.\n$$\n\nStep 3: Inverse Laplace transform to obtain $\\Phi(t)$. Using $\\mathcal{L}^{-1}\\{(s-\\lambda)^{-1}\\}=\\exp(\\lambda t)$, we have\n$$\n\\Phi(t)=R_{-1}\\exp(-t)+R_{-2}\\exp(-2t)+R_{-3}\\exp(-3t).\n$$\nCombining the matrices entrywise gives\n$$\n\\Phi(t)=\\begin{pmatrix}\n\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-2 t)  -\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-2 t)  \\frac{1}{2}\\exp(-t)-\\frac{1}{2}\\exp(-2 t)\\\\\n\\frac{1}{2}\\exp(-2 t)-\\frac{1}{2}\\exp(-3 t)  \\frac{1}{2}\\exp(-2 t)+\\frac{1}{2}\\exp(-3 t)  -\\frac{1}{2}\\exp(-2 t)+\\frac{1}{2}\\exp(-3 t)\\\\\n\\frac{1}{2}\\exp(-t)-\\frac{1}{2}\\exp(-3 t)  -\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-3 t)  \\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-3 t)\n\\end{pmatrix}.\n$$\nThis matrix satisfies $\\Phi(0)=I$ and $\\frac{d}{dt}\\Phi(t)\\big|_{t=0}=A$, confirming correctness.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-2 t)  -\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-2 t)  \\frac{1}{2}\\exp(-t)-\\frac{1}{2}\\exp(-2 t)\\\\\n\\frac{1}{2}\\exp(-2 t)-\\frac{1}{2}\\exp(-3 t)  \\frac{1}{2}\\exp(-2 t)+\\frac{1}{2}\\exp(-3 t)  -\\frac{1}{2}\\exp(-2 t)+\\frac{1}{2}\\exp(-3 t)\\\\\n\\frac{1}{2}\\exp(-t)-\\frac{1}{2}\\exp(-3 t)  -\\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-3 t)  \\frac{1}{2}\\exp(-t)+\\frac{1}{2}\\exp(-3 t)\n\\end{pmatrix}}$$", "id": "1602298"}]}