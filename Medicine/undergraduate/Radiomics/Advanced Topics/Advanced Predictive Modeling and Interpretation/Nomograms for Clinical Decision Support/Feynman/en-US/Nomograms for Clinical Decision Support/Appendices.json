{
    "hands_on_practices": [
        {
            "introduction": "Before a radiomic feature can be trusted as a component of a clinical nomogram, its measurement must be proven reliable. This practice delves into quantifying test-retest repeatability using the Intraclass Correlation Coefficient (ICC), a fundamental metric for biomarker validation. By dissecting the sources of variability in measurements, you will learn how to assess whether a feature provides a stable, reproducible signal, a critical prerequisite for building a robust predictive model. ",
            "id": "4553774",
            "problem": "A radiomics team is constructing a clinical decision-support nomogram based on a multivariable model that includes texture features extracted from computed tomography images. Before inclusion, each candidate feature must demonstrate acceptable test-retest repeatability under a design with two repeat scans per subject and a single standardized extraction pipeline. Consider a single texture feature measured on a test-retest subset. Assume a one-way random-effects measurement model with a random subject effect and independent measurement errors, a balanced design, and no systematic shift between test and retest. The analysis of variance (ANOVA) on this subset yields an estimate of the within-subject variance $ \\sigma_{w}^{2} = 0.20 $ and the between-subject variance $ \\sigma_{b}^{2} = 1.15 $ for this feature. Starting from variance decomposition for this random-effects model and the definition of correlation as covariance divided by the product of standard deviations, derive the expression for the intraclass correlation coefficient (Intraclass Correlation Coefficient (ICC)) that quantifies test-retest repeatability in this setting, and then compute the ICC for this feature. Briefly justify, based on foundational measurement error principles, a threshold for reliability that would be appropriate when deciding whether this feature should be included in a nomogram intended for individual-level clinical decision support, making clear how the threshold relates to attenuation of effect estimates. Report only the computed ICC as the final answer, expressed as a decimal and rounded to $4$ significant figures. No units are required for the final answer.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in established statistical theory (random-effects models, analysis of variance, intraclass correlation), well-posed with all necessary information provided, and objective in its formulation. The scenario described is a standard and critical step in the development of quantitative imaging biomarkers.\n\nThe problem asks for the derivation and calculation of the Intraclass Correlation Coefficient (ICC) for test-retest repeatability, based on a one-way random-effects model. Let $Y_{ij}$ be the measured feature value for subject $i$ on the $j$-th repeat scan, where $i = 1, \\dots, n$ subjects and $j = 1, 2$ scans. The one-way random-effects model is specified as:\n$$\nY_{ij} = \\mu + b_i + w_{ij}\n$$\nHere, $\\mu$ represents the grand mean of the feature across all subjects and scans. The term $b_i$ is the random effect of subject $i$, representing the true, stable deviation of subject $i$'s mean feature value from the grand mean $\\mu$. It is assumed that $b_i$ are independent and identically distributed (i.i.d.) random variables from a normal distribution with mean $0$ and variance $\\sigma_b^2$, i.e., $b_i \\sim N(0, \\sigma_b^2)$. The variance $\\sigma_b^2$ is the between-subject variance. The term $w_{ij}$ is the random measurement error for subject $i$ on scan $j$, assumed to be i.i.d. from a normal distribution with mean $0$ and variance $\\sigma_w^2$, i.e., $w_{ij} \\sim N(0, \\sigma_w^2)$. The variance $\\sigma_w^2$ is the within-subject variance. The model assumes that the random effects $b_i$ and the error terms $w_{ij}$ are mutually independent.\n\nThe ICC, in this context, is defined as the correlation between two measurements taken on the same subject, i.e., $\\text{Corr}(Y_{i1}, Y_{i2})$. The definition of the Pearson correlation coefficient for two random variables $X$ and $Y$ is $\\text{Corr}(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sqrt{\\text{Var}(X)\\text{Var}(Y)}}$. Applying this to our measurements $Y_{i1}$ and $Y_{i2}$:\n$$\n\\text{ICC} = \\text{Corr}(Y_{i1}, Y_{i2}) = \\frac{\\text{Cov}(Y_{i1}, Y_{i2})}{\\sqrt{\\text{Var}(Y_{i1}) \\text{Var}(Y_{i2})}}\n$$\nWe first derive the expression for the total variance of a single observation, $\\text{Var}(Y_{ij})$.\n$$\n\\text{Var}(Y_{ij}) = \\text{Var}(\\mu + b_i + w_{ij})\n$$\nSince $\\mu$ is a constant, its variance is $0$. Due to the independence of $b_i$ and $w_{ij}$, the variance of their sum is the sum of their variances:\n$$\n\\text{Var}(Y_{ij}) = \\text{Var}(b_i) + \\text{Var}(w_{ij}) = \\sigma_b^2 + \\sigma_w^2\n$$\nThis total variance is the same for any observation, thus $\\text{Var}(Y_{i1}) = \\text{Var}(Y_{i2}) = \\sigma_b^2 + \\sigma_w^2$.\n\nNext, we derive the expression for the covariance between two measurements from the same subject, $\\text{Cov}(Y_{i1}, Y_{i2})$.\n$$\n\\text{Cov}(Y_{i1}, Y_{i2}) = \\text{Cov}(\\mu + b_i + w_{i1}, \\mu + b_i + w_{i2})\n$$\nUsing the bilinearity property of covariance:\n$$\n\\text{Cov}(Y_{i1}, Y_{i2}) = \\text{Cov}(b_i, b_i) + \\text{Cov}(b_i, w_{i2}) + \\text{Cov}(w_{i1}, b_i) + \\text{Cov}(w_{i1}, w_{i2})\n$$\nThe covariance of a variable with itself is its variance, so $\\text{Cov}(b_i, b_i) = \\text{Var}(b_i) = \\sigma_b^2$. By the model assumptions, the subject effect $b_i$ is independent of the measurement errors $w_{i1}$ and $w_{i2}$, and the measurement errors for different scans are independent of each other. Therefore, $\\text{Cov}(b_i, w_{i2}) = 0$, $\\text{Cov}(w_{i1}, b_i) = 0$, and $\\text{Cov}(w_{i1}, w_{i2}) = 0$. This simplifies the covariance to:\n$$\n\\text{Cov}(Y_{i1}, Y_{i2}) = \\sigma_b^2\n$$\nSubstituting the expressions for variance and covariance into the correlation formula gives the derived expression for the ICC:\n$$\n\\text{ICC} = \\frac{\\sigma_b^2}{\\sqrt{(\\sigma_b^2 + \\sigma_w^2)(\\sigma_b^2 + \\sigma_w^2)}} = \\frac{\\sigma_b^2}{\\sigma_b^2 + \\sigma_w^2}\n$$\nThis expression shows that the ICC represents the proportion of the total variance that is attributable to the true differences between subjects.\n\nThe problem provides the estimated variance components from an ANOVA:\nBetween-subject variance: $\\sigma_b^2 = 1.15$\nWithin-subject variance: $\\sigma_w^2 = 0.20$\n\nWe can now compute the ICC for the given feature:\n$$\n\\text{ICC} = \\frac{1.15}{1.15 + 0.20} = \\frac{1.15}{1.35}\n$$\n$$\n\\text{ICC} \\approx 0.85185185...\n$$\nRounding to $4$ significant figures, the ICC is $0.8519$.\n\nRegarding the justification for a reliability threshold, the ICC is a measure of reliability. In classical test theory, the observed score variance ($\\sigma_b^2 + \\sigma_w^2$) is the sum of the true score variance ($\\sigma_b^2$) and the error variance ($\\sigma_w^2$). Measurement error, quantified by $\\sigma_w^2$, leads to the attenuation (underestimation) of true associations. For a regression model where an outcome is predicted by the measured feature, the observed regression coefficient $\\beta_{obs}$ is related to the true coefficient $\\beta_{true}$ by the formula $\\beta_{obs} = \\beta_{true} \\times \\text{ICC}$. A lower ICC value causes a greater attenuation of the observed effect size, diminishing the prognostic or diagnostic power of the feature. For clinical decision support at the individual patient level, high precision is critical. A feature with low reliability adds more noise than signal to a model, potentially leading to patient misclassification and erroneous clinical decisions. While reliability of $0.75$ may be acceptable for group-level research, a much higher standard is required for individual-level applications. A commonly cited, stringent threshold for such high-stakes decisions is an ICC of at least $0.90$. An ICC of $0.90$ implies that only $10\\%$ of the observed feature variance is noise and that any true association is attenuated by only $10\\%$. An ICC of $0.85$, as calculated here, means that $15\\%$ of the variance is noise and the association is attenuated by $15\\%$, which may be considered borderline or insufficient for a nomogram intended to guide critical individual patient care. Therefore, a justifiable threshold would be $\\text{ICC} \\ge 0.90$ to ensure the feature contributes robustly to the nomogram's predictive accuracy.\n\nThe final answer, as requested, is the computed ICC value rounded to $4$ significant figures.\n$$\n\\text{ICC} = 0.8519\n$$",
            "answer": "$$\\boxed{0.8519}$$"
        },
        {
            "introduction": "A nomogram's power lies in its ability to translate a complex statistical model into a simple, graphical tool for clinical use. This exercise bridges the gap between the underlying logistic regression equation and the intuitive point-based system of a nomogram. You will practice converting a specific feature's contribution into nomogram points and see how this score directly impacts the final predicted probability, providing a clear understanding of the model's inner workings. ",
            "id": "4553775",
            "problem": "A radiomics-based clinical decision support tool uses a logistic regression risk model summarized by a nomogram. Predictors are standardized to zero mean and unit variance. In this framework, the linear predictor (log-odds) is additive in predictor contributions, and the nomogram maps predictor contributions to points on a linear scale. Assume the following conditions hold: a single standardized radiomics feature $x_{1}$ has value $x_{1}=1.5$ and regression coefficient $\\beta_{1}=0.6$, and the nomogram is calibrated so that one point corresponds to an increment $\\Delta \\eta=0.05$ in the linear predictor. Also assume a baseline odds of $1:1$ for the clinical event of interest.\n\nUsing only the definitions of odds, log-odds, and the logistic link function as the fundamental base, determine:\n- the number of points contributed by the feature value $x_{1}=1.5$ under the given point scale, and\n- the implied change in predicted probability from the baseline when this feature contribution is added.\n\nExpress the final result as two quantities in a single row vector: first the total points, then the change in predicted probability. For the change in predicted probability, provide an exact analytic expression in terms of $\\exp(\\cdot)$; do not round or approximate. No units are required and no percentage signs should be used.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It provides a self-contained and consistent set of givens rooted in standard statistical methodology (logistic regression) and its application in clinical decision support (nomograms). All provided values are physically and statistically plausible, and the questions asked have unique, verifiable answers.\n\nThe solution proceeds by first principles, as requested. The core of the problem relates a feature's value to its impact on the linear predictor (log-odds) in a logistic regression model, and subsequently to the change in predicted probability.\n\nLet $P$ be the probability of the clinical event of interest. The odds of the event are defined as $O = \\frac{P}{1-P}$.\nThe logistic regression model uses the natural logarithm of the odds, known as the log-odds or linear predictor $\\eta$, as the response variable:\n$$ \\eta = \\ln(O) = \\ln\\left(\\frac{P}{1-P}\\right) $$\nThe linear predictor $\\eta$ is modeled as a linear combination of predictor variables $x_i$ with coefficients $\\beta_i$, plus an intercept $\\beta_0$:\n$$ \\eta = \\beta_0 + \\sum_{i} \\beta_i x_i $$\nThe contribution of a single predictor $x_1$ to the linear predictor is the term $\\Delta\\eta_1 = \\beta_1 x_1$.\n\nThe problem provides the following values:\n- Standardized feature value: $x_1 = 1.5$\n- Regression coefficient: $\\beta_1 = 0.6$\n\nThe contribution of this feature to the linear predictor is calculated as:\n$$ \\Delta\\eta_1 = \\beta_1 x_1 = (0.6)(1.5) = 0.9 $$\n\nThe first quantity to find is the number of points this contribution represents on the nomogram. The problem states that the nomogram is calibrated such that one point corresponds to an increment of $\\Delta\\eta = 0.05$ in the linear predictor. Thus, the total number of points, $N_p$, for the contribution $\\Delta\\eta_1$ is:\n$$ N_p = \\frac{\\Delta\\eta_1}{0.05} = \\frac{0.9}{0.05} = \\frac{90}{5} = 18 $$\nSo, the feature value $x_1=1.5$ contributes $18$ points to the nomogram score.\n\nThe second quantity to find is the implied change in predicted probability from the baseline. To do this, we must first establish the baseline probability and then the new probability after including the feature's contribution.\nThe probability $P$ can be expressed as a function of the linear predictor $\\eta$ by rearranging the log-odds equation. This yields the logistic function:\n$$ P(\\eta) = \\frac{\\exp(\\eta)}{1+\\exp(\\eta)} $$\nThe problem specifies a baseline odds of $1:1$, which means $O_{base} = 1$. The corresponding baseline linear predictor $\\eta_{base}$ is:\n$$ \\eta_{base} = \\ln(O_{base}) = \\ln(1) = 0 $$\nThe baseline probability $P_{base}$ is therefore:\n$$ P_{base} = P(\\eta_{base}) = P(0) = \\frac{\\exp(0)}{1+\\exp(0)} = \\frac{1}{1+1} = \\frac{1}{2} $$\nThe new linear predictor, $\\eta_{new}$, is the sum of the baseline predictor and the contribution from the feature $x_1$:\n$$ \\eta_{new} = \\eta_{base} + \\Delta\\eta_1 = 0 + 0.9 = 0.9 $$\nThe new probability, $P_{new}$, corresponding to this updated linear predictor is:\n$$ P_{new} = P(\\eta_{new}) = P(0.9) = \\frac{\\exp(0.9)}{1+\\exp(0.9)} $$\nThe change in predicted probability, $\\Delta P$, is the difference between the new probability and the baseline probability:\n$$ \\Delta P = P_{new} - P_{base} = \\frac{\\exp(0.9)}{1+\\exp(0.9)} - \\frac{1}{2} $$\nTo obtain a single fractional expression, we find a common denominator:\n$$ \\Delta P = \\frac{2\\exp(0.9)}{2(1+\\exp(0.9))} - \\frac{1+\\exp(0.9)}{2(1+\\exp(0.9))} = \\frac{2\\exp(0.9) - (1+\\exp(0.9))}{2(1+\\exp(0.9))} $$\nSimplifying the numerator yields the final exact analytical expression for the change in probability:\n$$ \\Delta P = \\frac{\\exp(0.9) - 1}{2(1+\\exp(0.9))} $$\nThe two required quantities are the number of points, $18$, and the change in probability, $\\frac{\\exp(0.9) - 1}{2(1+\\exp(0.9))}$. These are to be presented in a single row vector.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 18 & \\frac{\\exp(0.9) - 1}{2(1 + \\exp(0.9))} \\end{pmatrix}} $$"
        },
        {
            "introduction": "Predictive models, including nomograms, are not always universally applicable; their performance can degrade when applied to new patient populations due to calibration drift. This advanced practice addresses the critical real-world task of model recalibration, a process of updating a model to restore its predictive accuracy in a new setting. You will work through the mathematical steps to adjust a nomogram's intercept and slope based on external validation data, a key skill for the responsible deployment and maintenance of clinical decision support tools. ",
            "id": "4553785",
            "problem": "A radiomics-based clinical nomogram for binary outcome prediction was originally derived using a logistic regression model. By construction of the nomogram’s total point scale, the model’s linear predictor is an affine function of the total points $T$, so that the original predicted probability for a patient with total points $T$ is\n$$\np_{\\text{orig}}(T) \\;=\\; \\operatorname{logit}^{-1}\\!\\big(a + b\\,T\\big) \\;=\\; \\frac{1}{1 + \\exp\\!\\big(-\\big(a + b\\,T\\big)\\big)} ,\n$$\nwhere $a$ is the model intercept on the linear predictor scale and $b$ is the slope per point on the same scale.\n\nAn external validation cohort shows calibration drift. Following standard calibration-in-the-large and slope assessment, you fit the calibration model\n$$\n\\operatorname{logit}\\!\\big(p_{\\text{true}}\\big) \\;=\\; \\alpha \\;+\\; \\gamma \\,\\operatorname{logit}\\!\\big(p_{\\text{orig}}(T)\\big),\n$$\nwhich yields estimates $\\alpha$ and $\\gamma$ for the external setting. This motivates two recalibration options for the nomogram:\n- Intercept-only recalibration (adjusting the intercept $\\,\\beta_{0}\\,$): set $\\gamma = 1$ and adjust the intercept by $\\alpha$.\n- Intercept-and-slope recalibration (adjusting both $\\,\\beta_{0}\\,$ and the global slope): use the estimated $\\alpha$ and $\\gamma$.\n\nStarting from the definitions of the logistic link $\\operatorname{logit}(p) = \\ln\\!\\big(\\frac{p}{1-p}\\big)$ and its inverse $\\operatorname{logit}^{-1}(x) = \\frac{1}{1+\\exp(-x)}$, and the linear mapping between nomogram points and the original linear predictor, derive the recalibrated probability function $p_{\\text{recal}}(T)$ for both intercept-only and intercept-and-slope recalibration in terms of $a$, $b$, $\\alpha$, $\\gamma$, and $T$. Then, using the intercept-and-slope recalibration, compute the recalibrated predicted probability for a patient with total points $T = 120$ when $a = -3.0$, $b = 0.02$, $\\alpha = -0.3$, and $\\gamma = 0.9$. Round your final numeric answer to four significant figures and express it as a decimal (no percent sign).",
            "solution": "The problem requires the derivation of recalibrated probability functions based on a logistic regression model and a subsequent calibration model, followed by a numerical calculation for a specific case.\n\nFirst, we validate the problem statement.\nAll givens have been extracted and analyzed. The problem is scientifically grounded in standard statistical methodology for clinical prediction models (logistic regression, nomogram calibration), is well-posed with all necessary information provided and no contradictions, and is expressed in objective, formal language. The problem is therefore deemed valid.\n\nWe begin the derivation. The original predicted probability, $p_{\\text{orig}}(T)$, is defined via its linear predictor, $\\eta_{\\text{orig}} = a + bT$, as:\n$$\np_{\\text{orig}}(T) = \\operatorname{logit}^{-1}(\\eta_{\\text{orig}}) = \\operatorname{logit}^{-1}(a + bT)\n$$\nBy applying the logit function, which is the inverse of the $\\operatorname{logit}^{-1}$ function, to both sides of this definition, we obtain a direct expression for the logit of the original probability:\n$$\n\\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big) = \\operatorname{logit}\\big(\\operatorname{logit}^{-1}(a + bT)\\big) = a + bT\n$$\nThis relationship is the key to connecting the original model to the calibration model.\n\nThe calibration model relates the \"true\" probability in the new population, which we will denote as the recalibrated probability $p_{\\text{recal}}(T)$, to the original predicted probability $p_{\\text{orig}}(T)$:\n$$\n\\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = \\alpha + \\gamma \\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big)\n$$\nHere, $\\alpha$ is the calibration intercept (related to calibration-in-the-large) and $\\gamma$ is the calibration slope. The left-hand side of this equation is the recalibrated linear predictor, $\\eta_{\\text{recal}}$.\n\nBy substituting the expression for $\\operatorname{logit}\\big(p_{\\text{orig}}(T)\\big)$ into the calibration model, we get the recalibrated linear predictor in terms of the original model parameters and the calibration parameters:\n$$\n\\eta_{\\text{recal}} = \\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = \\alpha + \\gamma (a + bT)\n$$\nWe can rearrange this into the form of a new linear predictor:\n$$\n\\operatorname{logit}\\big(p_{\\text{recal}}(T)\\big) = (\\alpha + \\gamma a) + (\\gamma b)T\n$$\nTo find the recalibrated probability $p_{\\text{recal}}(T)$, we apply the inverse logit function to this recalibrated linear predictor:\n$$\np_{\\text{recal}}(T) = \\operatorname{logit}^{-1}\\big((\\alpha + \\gamma a) + (\\gamma b)T\\big)\n$$\nUsing the definition $\\operatorname{logit}^{-1}(x) = \\frac{1}{1 + \\exp(-x)}$, this becomes:\n$$\np_{\\text{recal}}(T) = \\frac{1}{1 + \\exp\\big(-((\\alpha + \\gamma a) + (\\gamma b)T)\\big)}\n$$\nThis is the general formula for the **intercept-and-slope recalibration**.\n\nFor the special case of **intercept-only recalibration**, we set the calibration slope $\\gamma = 1$. Substituting $\\gamma=1$ into the general formula gives:\n$$\np_{\\text{recal}}(T) = \\frac{1}{1 + \\exp\\big(-((\\alpha + 1 \\cdot a) + (1 \\cdot b)T)\\big)} = \\frac{1}{1 + \\exp\\big(-((\\alpha+a) + bT)\\big)}\n$$\nThis corresponds to adjusting the original model's intercept $a$ by the calibration intercept $\\alpha$, while leaving the slope $b$ unchanged.\n\nNext, we perform the numerical calculation as requested, using the intercept-and-slope recalibration formula. The given values are:\n-   Total points $T = 120$\n-   Original intercept $a = -3.0$\n-   Original slope per point $b = 0.02$\n-   Calibration intercept $\\alpha = -0.3$\n-   Calibration slope $\\gamma = 0.9$\n\nWe first compute the recalibrated linear predictor, $\\eta_{\\text{recal}}$:\n$$\n\\eta_{\\text{recal}} = (\\alpha + \\gamma a) + (\\gamma b)T\n$$\nSubstituting the numerical values:\n$$\n\\eta_{\\text{recal}} = (-0.3 + (0.9)(-3.0)) + ((0.9)(0.02))(120)\n$$\n$$\n\\eta_{\\text{recal}} = (-0.3 - 2.7) + (0.018)(120)\n$$\n$$\n\\eta_{\\text{recal}} = -3.0 + 2.16\n$$\n$$\n\\eta_{\\text{recal}} = -0.84\n$$\nNow, we compute the recalibrated probability $p_{\\text{recal}}(T=120)$ by applying the inverse logit function:\n$$\np_{\\text{recal}}(120) = \\frac{1}{1 + \\exp(-\\eta_{\\text{recal}})} = \\frac{1}{1 + \\exp(-(-0.84))} = \\frac{1}{1 + \\exp(0.84)}\n$$\nCalculating the value:\n$$\n\\exp(0.84) \\approx 2.3163668\n$$\n$$\np_{\\text{recal}}(120) \\approx \\frac{1}{1 + 2.3163668} = \\frac{1}{3.3163668} \\approx 0.301535\n$$\nThe problem requires rounding the final answer to four significant figures. The first four significant figures are $3$, $0$, $1$, and $5$. The following digit is $3$, so we round down.\n$$\np_{\\text{recal}}(120) \\approx 0.3015\n$$",
            "answer": "$$\\boxed{0.3015}$$"
        }
    ]
}