{
    "hands_on_practices": [
        {
            "introduction": "在放射组学中，我们使用生成对抗网络（GAN）的一个主要动机是解决数据不平衡问题，尤其是在罕见病变样本不足时。在投入计算资源训练复杂的GAN模型之前，定量理解数据增强对数据集统计特性的影响至关重要。这个练习将通过推导关键指标（如类别不平衡比和类别先验概率）的变化，帮助你从根本上掌握数据增强的数学原理 。",
            "id": "4541978",
            "problem": "在一个基于影像组学的、区分恶性与良性病变的二元病变分类任务中，假设训练数据集最初包含总共 $T_{0}$ 个病变，这些病变被划分为少数类和多数类。设初始类别不平衡比率定义为 $r = n_{\\min,0}/n_{\\maj,0}$，其中 $n_{\\min,0}$ 和 $n_{\\maj,0}$ 分别表示少数类和多数类病变的初始数量。使用生成对抗网络（GAN）来合成 $N$ 个额外的少数类病变，并将其附加到训练集中。假设所有合成的病变都被接纳到数据集中，并被视为完全标记的样本，而不改变多数类的数量。\n\n仅使用经验风险最小化中类别数量、类别不平衡比率和类别先验的基本定义，推导以下两个量的封闭形式表达式：\n- 类别平衡的预期变化，以少数类与多数类比率的差异 $\\Delta r = r_{\\text{new}} - r$ 来衡量，以及\n- 增广后新的少数类先验概率 $\\pi_{\\min,1}$。\n\n将两个结果纯粹用 $r$、$N$ 和 $T_{0}$ 表示。将您的最终答案以一个双元素行矩阵的形式给出，其中第一个元素等于 $\\Delta r$，第二个元素等于 $\\pi_{\\min,1}$。不需要数值近似，也不需要单位。如果选择简化，请进行代数简化；不要引入任何额外的假设或参数。最终表达式必须是精确的，不能四舍五入。",
            "solution": "问题陈述已经过严格验证，并被认为是有效的。它在科学上基于机器学习和统计学的原理，特别涉及针对类别不平衡的数据增广策略。该问题提法得当、客观，并包含推导唯一且有意义解所需的所有信息。\n\n目标是推导数据集增广后类别不平衡比率的变化量 $\\Delta r$ 和新的少数类先验概率 $\\pi_{\\min,1}$ 的表达式。结果必须仅用初始不平衡比率 $r$、合成样本数量 $N$ 和初始总样本数 $T_{0}$ 来表示。\n\n首先，我们必须用给定的参数 $T_{0}$ 和 $r$ 来表示初始的少数类和多数类数量 $n_{\\min,0}$ 和 $n_{\\maj,0}$。\n初始病变总数由下式给出：\n$$T_{0} = n_{\\min,0} + n_{\\maj,0}$$\n初始类别不平衡比率定义为：\n$$r = \\frac{n_{\\min,0}}{n_{\\maj,0}}$$\n根据 $r$ 的定义，我们可以写出 $n_{\\min,0} = r \\cdot n_{\\maj,0}$。将此代入 $T_{0}$ 的方程中：\n$$T_{0} = r \\cdot n_{\\maj,0} + n_{\\maj,0} = (r+1)n_{\\maj,0}$$\n解出 $n_{\\maj,0}$ 得到：\n$$n_{\\maj,0} = \\frac{T_{0}}{r+1}$$\n随后，我们可以通过将此结果代回 $n_{\\min,0}$ 的表达式来求得 $n_{\\min,0}$：\n$$n_{\\min,0} = r \\cdot n_{\\maj,0} = \\frac{r T_{0}}{r+1}$$\n\n接下来，我们定义数据增广后的数量。问题陈述指出，增加了 $N$ 个合成的少数类病变，而多数类的数量保持不变。\n新的少数类数量 $n_{\\min,1}$ 是：\n$$n_{\\min,1} = n_{\\min,0} + N = \\frac{r T_{0}}{r+1} + N$$\n新的多数类数量 $n_{\\maj,1}$ 是：\n$$n_{\\maj,1} = n_{\\maj,0} = \\frac{T_{0}}{r+1}$$\n新的病变总数 $T_{1}$ 是：\n$$T_{1} = T_{0} + N$$\n\n现在我们可以计算新的类别不平衡比率 $r_{\\text{new}}$。\n$$r_{\\text{new}} = \\frac{n_{\\min,1}}{n_{\\maj,1}} = \\frac{\\frac{r T_{0}}{r+1} + N}{\\frac{T_{0}}{r+1}}$$\n为简化此表达式，我们将分子和分母同乘以 $(r+1)$：\n$$r_{\\text{new}} = \\frac{(r T_{0}) + N(r+1)}{T_{0}} = \\frac{r T_{0}}{T_{0}} + \\frac{N(r+1)}{T_{0}}$$\n$$r_{\\text{new}} = r + \\frac{N(r+1)}{T_{0}}$$\n类别平衡比率的变化量 $\\Delta r$ 定义为 $r_{\\text{new}} - r$。\n$$\\Delta r = \\left(r + \\frac{N(r+1)}{T_{0}}\\right) - r$$\n$$\\Delta r = \\frac{N(r+1)}{T_{0}}$$\n这是第一个要求的表达式。\n\n最后，我们推导新的少数类先验概率 $\\pi_{\\min,1}$ 的表达式。一个类别的先验概率是其相对频率，定义为该类别中的样本数除以总样本数。\n$$\\pi_{\\min,1} = \\frac{n_{\\min,1}}{T_{1}}$$\n代入 $n_{\\min,1}$ 和 $T_{1}$ 的表达式：\n$$\\pi_{\\min,1} = \\frac{\\frac{r T_{0}}{r+1} + N}{T_{0} + N}$$\n为了简化分子，我们通分：\n$$\\frac{r T_{0}}{r+1} + N = \\frac{r T_{0}}{r+1} + \\frac{N(r+1)}{r+1} = \\frac{r T_{0} + N(r+1)}{r+1}$$\n将此代回 $\\pi_{\\min,1}$ 的表达式中：\n$$\\pi_{\\min,1} = \\frac{\\frac{r T_{0} + N(r+1)}{r+1}}{T_{0} + N}$$\n$$\\pi_{\\min,1} = \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)}$$\n这是第二个要求的表达式，完全用 $r$、$N$ 和 $T_{0}$ 表示。\n\n推导出的两个表达式是：\n1. $\\Delta r = \\frac{N(r+1)}{T_{0}}$\n2. $\\pi_{\\min,1} = \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)}$\n\n按要求，这些以一个双元素行矩阵的形式给出。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{N(r+1)}{T_{0}} & \\frac{r T_{0} + N(r+1)}{(r+1)(T_{0} + N)} \\end{pmatrix}}$$"
        },
        {
            "introduction": "将理论付诸实践时，我们必须面对现实的工程约束，其中最常见的就是图形处理器（GPU）的显存限制。对于放射组学应用，我们还必须确保生成的图像块足够大，以保留对诊断至关重要的纹理特征。这个练习将引导你设计一个实际的训练流程，在确保灰度共生矩阵（GLCM）特征的有效上下文和严格的显存预算之间找到最佳平衡 。",
            "id": "4541955",
            "problem": "您的任务是为用于放射组学（radiomics）中数据增强的生成对抗网络（GAN）设计一个基于区块（patch-based）的训练流程。关键要求是，区块的维度必须为计算源自灰度共生矩阵（GLCM）的纹理特征提供足够的空间上下文，同时确保图形处理单元（GPU）的总内存使用量不超过指定的预算。\n\n从以下基本概念开始：\n- 对于给定的偏移向量 $\\Delta = (d_x, d_y)$，灰度共生矩阵（GLCM）的定义是通过在一个离散图像中计数所有有序像素位置对 $(\\mathbf{p}, \\mathbf{q})$，使得 $\\mathbf{q} = \\mathbf{p} + \\Delta$，并且这对像素位置需在区块边界内。对于一个高度为 $H$、宽度为 $W$ 的矩形区块，偏移量为 $\\Delta$ 的有效位置对数量等于位置 $\\mathbf{p}$ 的计数，其偏移后的位置 $\\mathbf{q}$ 仍在该区块内部。当 $H \\ge |d_y| + 1$ 且 $W \\ge |d_x| + 1$ 时，该计数为 $(H - |d_y|) \\cdot (W - |d_x|)$，否则为零。\n- 训练期间，生成器和判别器存储的数组所使用的总内存可以建模为单个样本的张量大小与一个总乘法因子的乘积，该因子考虑了前向传播激活值、反向传播梯度和双网络存储。设此因子为 $\\gamma$。设批量大小为 $B$，区块维度为 $H \\times W$，通道数为 $C$，每元素字节数为 $b$，则与激活值相关的内存为 $\\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b$。设两个网络的组合参数内存为 $P$。那么总内存为 $P + \\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b$，该值不得超过可用预算 $M$ 字节。\n\n您的程序必须确定整数区块维度 $H$ 和 $W$ 以及整数批量大小 $B$，使其满足：\n- 对于给定集合 $\\mathcal{O}$ 中的每个偏移量 $\\Delta_i = (d_{x,i}, d_{y,i})$，有效的 GLCM 对的数量 $(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|)$ 至少为所需的最小值 $K$。\n- GPU 内存约束 $P + \\gamma \\cdot B \\cdot H \\cdot W \\cdot C \\cdot b \\le M$ 成立，其中所有内存量均以字节表示。\n- 如果在给定约束下不存在可行的 $(H, W, B)$，您必须为该测试用例输出三元组 $(0, 0, 0)$。\n\n为了使选择唯一且确定，您必须根据以下规则选择 $(H, W, B)$：\n- 在所有满足给定偏移量和 $K$ 的 GLCM 约束的 $(H, W)$ 中，选择使面积 $H \\cdot W$ 最小的一对。\n- 通过选择绝对宽高差 $|H - W|$ 最小的一对来打破平局。\n- 通过选择最小的 $H$ 来打破任何剩余的平局。\n- 给定选定的 $(H, W)$，选择内存预算允许的最大整数 $B$。如果 $B < 1$，则通过输出 $(0, 0, 0)$ 来声明不可行。\n\n所有答案必须是整数，并且所有内存量必须以字节为单位进行处理和表示。\n\n使用以下包含 $4$ 个测试用例的测试套件，每个测试用例由 $(M, P, \\gamma, C, b, \\mathcal{O}, K)$ 指定：\n\n- 测试用例 1（一般情况）：\n  - $M = 1,000,000,000$ 字节, $P = 200,000,000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(1, 0), (0, 1), (1, 1)\\}$,\n  - $K = 80,000$。\n\n- 测试用例 2（边界内存情况）：\n  - $M = 192$ 字节, $P = 64$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(1, 0)\\}$,\n  - $K = 1$。\n\n- 测试用例 3（由于预算紧张和上下文要求大而不可行的情况）：\n  - $M = 60,000,000$ 字节, $P = 50,000,000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(10, 10)\\}$,\n  - $K = 1,000,000$。\n\n- 测试用例 4（具有中等预算的各向异性偏移）：\n  - $M = 300,000,000$ 字节, $P = 100,000,000$ 字节, $\\gamma = 16$, $C = 1$, $b = 4$ 字节,\n  - $\\mathcal{O} = \\{(7, 0), (0, 1)\\}$,\n  - $K = 20,000$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个测试用例结果格式化为列表 $[H,W,B]$ 且不含空格，例如，$[[H_1,W_1,B_1],[H_2,W_2,B_2],[H_3,W_3,B_3],[H_4,W_4,B_4]]$。",
            "solution": "该问题要求在放射组学背景下，为生成对抗网络（GAN）的训练确定最优的整数区块维度 $H$ 和 $W$，以及整数批量大小 $B$。解决方案必须满足关于灰度共生矩阵（GLCM）统计充分性和总 GPU 内存使用量的约束，同时遵守一个确定性的多级优化准则。\n\n该问题可以分解为两个相继的子问题：\n1. 首先，找到满足 GLCM 要求和指定平局打破规则的最优区块维度 $(H, W)$，此过程独立于内存预算。\n2. 其次，给定最优的 $(H, W)$，计算出符合 GPU 内存约束的最大可能整数批量大小 $B$。\n\n### 第一部分：确定最优区块维度 $(H, W)$\n\nGLCM 约束规定，对于大小为 $H \\times W$ 的区块和给定集合 $\\mathcal{O}$ 中的每个偏移量 $\\Delta_i = (d_{x,i}, d_{y,i})$，有效像素对的数量必须至少为 $K$。像素对的数量由 $(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|)$ 给出。这导出一个不等式组：\n$$\n(H - |d_{y,i}|) \\cdot (W - |d_{x,i}|) \\ge K \\quad \\forall \\Delta_i \\in \\mathcal{O}\n$$\n此外，为使这些计数非零，必须满足对所有 $i$ 都有 $H > |d_{y,i}|$ 和 $W > |d_{x,i}|$。这等价于 $H \\ge d_{y,max} + 1$ 和 $W \\ge d_{x,max} + 1$，其中 $d_{y,max} = \\max_{i} |d_{y,i}|$ 且 $d_{x,max} = \\max_i |d_{x,i}|$。\n\n对于任何给定的宽度 $W > d_{x,max}$，高度 $H$ 必须满足：\n$$\nH \\ge |d_{y,i}| + \\frac{K}{W - |d_{x,i}|} \\quad \\forall i\n$$\n由于 $H$ 必须是整数，对于给定的 $W$，所需的最小高度（我们记为 $H_{cand}(W)$）是：\n$$\nH_{cand}(W) = \\max \\left( \\{ d_{y,max} + 1 \\} \\cup \\left\\{ \\left\\lceil \\frac{K}{W - |d_{x,i}|} \\right\\rceil + |d_{y,i}| \\mid \\Delta_i \\in \\mathcal{O} \\right\\} \\right)\n$$\n对于给定的高度 $H > d_{y,max}$，存在一个对称的公式用于计算最小宽度 $W_{cand}(H)$。\n\n优化目标是找到一个满足这些约束的整数对 $(H, W)$，并且：\n1.  最小化面积 $A = H \\cdot W$。\n2.  对于具有相同最小面积的数对，最小化绝对宽高差 $|H - W|$。\n3.  对于仍然平局的数对，最小化高度 $H$。\n\n最优对 $(H, W)$ 必须位于可行域的边界上，这意味着它将满足 $H = H_{cand}(W)$ 或 $W = W_{cand}(H)$。为确保找到全局最小值，我们必须沿着该边界的两个“轴”进行搜索。搜索策略如下：\n\n1.  **建立搜索边界**：首先，我们找到一个初始可行解来限定搜索空间。一个简单且可证明可行的数对是 $(H_0, W_0) = (d_{y,max} + \\lceil\\sqrt{K}\\rceil, d_{x,max} + \\lceil\\sqrt{K}\\rceil)$。这对的面积 $A_0 = H_0 \\cdot W_0$ 作为最小面积的初始上界。任何最优解 $(H, W)$ 都必须满足 $H \\cdot W \\le A_0$。这意味着我们只需要搜索 $W$ 直到一个上限 $W_{limit} = \\lfloor A_0 / (d_{y,max}+1) \\rfloor$ 以及 $H$ 直到一个上限 $H_{limit} = \\lfloor A_0 / (d_{x,max}+1) \\rfloor$，因为任何更大的值都会产生比 $A_0$ 更大的面积（因为 $H \\ge d_{y,max}+1$ 和 $W \\ge d_{x,max}+1$）。\n\n2.  **迭代搜索**：我们执行两次搜索。第一次搜索从 $d_{x,max}+1$ 开始迭代 $W$ 的整数值，直到一个动态更新的搜索上限。对于每个 $W$，我们计算 $H_{cand}(W)$ 和由此产生的面积 $A = H_{cand}(W) \\cdot W$。我们维护一个候选数对列表，这些数对达到了迄今为止发现的最小面积。如果找到一个新的、更小的最小面积，列表将被重置，并且可以收紧搜索上限，从而裁剪搜索空间。第二次搜索执行对称操作，迭代 $H$ 并计算 $W_{cand}(H)$。\n\n3.  **打破平局**：两次搜索完成后，我们得到一个所有达到相同全局最小面积的 $(H,W)$ 对的列表。我们对这个列表应用平局打破规则。我们首先按 $|H-W|$ 升序排序候选者，然后按 $H$ 升序排序。排序后列表中的第一对即为唯一的最优解。\n\n### 第二部分：确定批量大小 $B$\n\n一旦确定了最优区块维度 $(H_{opt}, W_{opt})$，我们就找到满足内存约束的最大整数批量大小 $B$：\n$$\nP + \\gamma \\cdot B \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b \\le M\n$$\n其中 $M$ 是内存预算， $P$ 是参数内存， $\\gamma$ 是内存因子， $C$ 是通道数， $b$ 是每元素的字节数。\n\n重新整理不等式以求解 $B$：\n$$\nB \\le \\frac{M - P}{\\gamma \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b}\n$$\n设可用激活内存为 $M_{avail} = M - P$，每样本在一个批次中的内存为 $M_{per\\_sample} = \\gamma \\cdot H_{opt} \\cdot W_{opt} \\cdot C \\cdot b$。最大整数批量大小是：\n$$\nB = \\left\\lfloor \\frac{M_{avail}}{M_{per\\_sample}} \\right\\rfloor\n$$\n如果 $M_{avail} < 0$ 或计算出的 $B$ 小于 $1$，则对于给定的参数不存在可行解，输出必须是 $(0, 0, 0)$。否则，最终解是三元组 $(H_{opt}, W_{opt}, B)$。\n这种系统的、分两部分的方法确保了所有约束和优化准则都得到满足，从而提供了一个正确且确定性的解决方案。",
            "answer": "```python\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates finding the optimal (H, W) and then calculating B.\n    \"\"\"\n    test_cases = [\n        (1_000_000_000, 200_000_000, 16, 1, 4, [(1, 0), (0, 1), (1, 1)], 80_000),\n        (192, 64, 16, 1, 4, [(1, 0)], 1),\n        (60_000_000, 50_000_000, 16, 1, 4, [(10, 10)], 1_000_000),\n        (300_000_000, 100_000_000, 16, 1, 4, [(7, 0), (0, 1)], 20_000),\n    ]\n\n    results = []\n    for case in test_cases:\n        M, P, gamma, C, b, O, K = case\n        \n        optimal_hw = find_optimal_hw(O, K)\n        \n        if optimal_hw is None:\n            results.append(\"[0,0,0]\")\n            continue\n\n        H, W = optimal_hw\n        \n        mem_avail = M - P\n        if mem_avail  0:\n            results.append(\"[0,0,0]\")\n            continue\n\n        mem_per_sample = gamma * H * W * C * b\n        if mem_per_sample = 0: # Should not happen with positive inputs\n            results.append(\"[0,0,0]\")\n            continue\n\n        B = mem_avail // mem_per_sample\n        \n        if B  1:\n            results.append(\"[0,0,0]\")\n        else:\n            results.append(f\"[{H},{W},{B}]\")\n            \n    print(f\"[{','.join(results)}]\")\n\ndef find_optimal_hw(O, K):\n    \"\"\"\n    Finds the optimal (H, W) pair based on GLCM constraints and tie-breaking rules.\n    \"\"\"\n    if not O:\n        dx_max, dy_max = 0, 0\n    else:\n        dx_max = max(abs(dx) for dx, dy in O)\n        dy_max = max(abs(dy) for dx, dy in O)\n\n    if K == 0:\n        return dy_max + 1, dx_max + 1\n\n    def ceil_div(a, b):\n        return (a + b - 1) // b\n\n    def calc_h_cand(w_val, offsets, k_val, dy_max_val):\n        h_cand = dy_max_val + 1\n        for dx, dy in offsets:\n            if w_val - abs(dx) = 0:\n                return float('inf') # Invalid W\n            required_h = ceil_div(k_val, w_val - abs(dx)) + abs(dy)\n            h_cand = max(h_cand, required_h)\n        return h_cand\n\n    def calc_w_cand(h_val, offsets, k_val, dx_max_val):\n        w_cand = dx_max_val + 1\n        for dx, dy in offsets:\n            if h_val - abs(dy) = 0:\n                return float('inf') # Invalid H\n            required_w = ceil_div(k_val, h_val - abs(dy)) + abs(dx)\n            w_cand = max(w_cand, required_w)\n        return w_cand\n\n    # Initial upper bound for area\n    s_k = math.isqrt(K - 1) + 1 if K > 0 else 0\n    h0, w0 = dy_max + s_k, dx_max + s_k\n    min_area = h0 * w0\n    candidates = [(h0, w0)]\n\n    # Search iterating W\n    w_search_limit = min_area // (dy_max + 1) if dy_max + 1 > 0 else min_area\n    for W_try in range(dx_max + 1, w_search_limit + 1):\n        if W_try * (dy_max + 1) > min_area:\n            break\n        H_cand = calc_h_cand(W_try, O, K, dy_max)\n        current_area = H_cand * W_try\n        \n        if current_area  min_area:\n            min_area = current_area\n            candidates = [(H_cand, W_try)]\n            # Prune search space\n            w_search_limit = min(w_search_limit, min_area // (dy_max + 1) if dy_max + 1 > 0 else min_area)\n        elif current_area == min_area:\n            candidates.append((H_cand, W_try))\n\n    # Search iterating H\n    h_search_limit = min_area // (dx_max + 1) if dx_max + 1 > 0 else min_area\n    for H_try in range(dy_max + 1, h_search_limit + 1):\n        if H_try * (dx_max + 1) > min_area:\n            break\n        W_cand = calc_w_cand(H_try, O, K, dx_max)\n        current_area = H_try * W_cand\n\n        if current_area  min_area:\n            min_area = current_area\n            candidates = [(H_try, W_cand)]\n            # Prune search space\n            h_search_limit = min(h_search_limit, min_area // (dx_max + 1) if dx_max + 1 > 0 else min_area)\n        elif current_area == min_area:\n            candidates.append((H_try, W_cand))\n\n    # Apply tie-breaking rules\n    final_candidates = [p for p in candidates if p[0] * p[1] == min_area]\n    \n    if not final_candidates:\n        return None\n\n    final_candidates.sort(key=lambda p: (abs(p[0] - p[1]), p[0]))\n    \n    return final_candidates[0]\n\nsolve()\n```"
        },
        {
            "introduction": "生成了合成数据之后，我们如何判断其质量？仅凭视觉检查是主观的，而简单的像素级指标可能具有误导性，无法反映复杂的放射组学特征。一种更严谨的方法是定量比较合成数据与真实数据的统计分布，这正是评估GAN性能的核心。本练习将通过编程实现最大均值差异（Maximum Mean Discrepancy, MMD），为你提供一个强大的工具来衡量生成器输出的分布保真度 。",
            "id": "4541982",
            "problem": "您正在评估由生成对抗网络（GAN）生成的合成放射组学特征向量是否与真实放射组学特征向量的分布相匹配。一种量化分布相似性的原则性方法是最大均值差异（MMD），它在一个由正定核导出的再生核希尔伯特空间中比较均值嵌入。使用径向基函数（RBF）核来实现这一比较。您的解决方案应基于以下基本原理构建：正定核的定义及其在再生核希尔伯特空间中导出的内积、作为样本均值的经验期望概念、特征空间中的欧几里得距离，以及指数函数在径向基函数核中的作用。您的任务是实现一个程序，该程序使用有偏经验估计量来计算两个有限放射组学特征向量样本之间的平方MMD，其中RBF核的带宽通过中位数启发法选择。\n\n您必须使用的定义和约束：\n- 最大均值差异（MMD）：再生核希尔伯特空间中两个分布的核均值嵌入之间的距离。\n- 径向基函数（RBF）核：由 $k(\\mathbf{x},\\mathbf{y})=\\exp\\!\\left(-\\|\\mathbf{x}-\\mathbf{y}\\|_{2}^{2}/(2\\sigma^{2})\\right)$ 给出，其中带宽 $\\sigma0$。\n- 带宽选择的中位数启发法：将两个数据集的所有样本合并，计算所有无序成对的平方欧几里得距离 $\\{\\|\\mathbf{z}_{i}-\\mathbf{z}_{j}\\|_{2}^{2}: ij\\}$，并将 $\\sigma^{2}$ 设置为这些距离的中位数。如果该中位数等于 $0$，则将 $\\sigma^{2}$ 设置为一个正下限值 $\\varepsilon$ 以避免除以零。使用 $\\varepsilon=10^{-12}$。\n- 使用平方MMD的有偏经验估计量，该估计量通过样本平均值结合了经验核自相似性和交叉相似性，从而使其在样本量小至 $1$ 时也是良定义的。\n\n您必须满足的算法要求：\n- 接受两组有限的特征向量集，一组为“真实”集，一组为“合成”集，每组均表示为形状分别为 $(m,d)$ 和 $(n,d)$ 的二维数组，其中 $m$ 和 $n$ 是样本大小，$d$ 是特征维度。\n- 按照上述规定，使用大小为 $m+n$ 的合并集和所有满足 $ij$ 的无序对，通过中位数启发法计算 $\\sigma^{2}$。\n- 使用该 $\\sigma^{2}$ 计算RBF核，然后计算两组数据集之间平方MMD的有偏经验估计量。\n- 每个测试用例返回一个实数：平方MMD，四舍五入到 $6$ 位小数。\n\n测试套件：\n- 案例A（一般“顺利”路径）：真实集 $X=\\big[[0.0],[2.0]\\big]$，合成集 $Y=\\big[[1.0],[3.0]\\big]$。\n- 案例B（相同集边界情况）：真实集 $X=\\big[[0.0],[2.0]\\big]$，合成集 $Y=\\big[[0.0],[2.0]\\big]$。\n- 案例C（$m=1$ 的小样本边缘情况）：真实集 $X=\\big[[1.0]\\big]$，合成集 $Y=\\big[[-1.0],[2.0]\\big]$。\n- 案例D（导致成对距离为零的退化常数向量）：真实集 $X=\\big[[5.0],[5.0]\\big]$，合成集 $Y=\\big[[5.0],[5.0]\\big]$。\n\n在这些测试中，所有特征都是无量纲标量。您的程序应按顺序处理上述四个案例，并生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3,result4]”），每个结果是四舍五入到 $6$ 位小数的平方MMD。不允许有其他输出。",
            "solution": "问题要求实现一个函数，用于计算两组特征向量（一组“真实”集 $X$ 和一组“合成”集 $Y$）之间的平方最大均值差异（$\\text{MMD}^2$）。计算必须使用 $\\text{MMD}^2$ 的有偏经验估计量和径向基函数（RBF）核，核的带宽参数需通过中位数启发法选择。\n\n该解决方案基于以下基本原理构建：\n\n1.  **平方MMD的有偏经验估计量**：MMD 是在由核 $k$ 导出的再生核希尔伯特空间（$\\mathcal{H}$）中定义的概率分布度量。对于在 $\\mathcal{H}$ 中具有均值嵌入 $\\mu_P$ 和 $\\mu_Q$ 的两个分布 $P$ 和 $Q$，平方MMD是它们差值的平方范数，即 $\\text{MMD}^2(P, Q) = \\|\\mu_P - \\mu_Q\\|_{\\mathcal{H}}^2$。利用核的再生性，这可以展开为：\n    $$\n    \\text{MMD}^2(P, Q) = \\mathbb{E}_{\\mathbf{x}, \\mathbf{x}' \\sim P}[k(\\mathbf{x}, \\mathbf{x}')] + \\mathbb{E}_{\\mathbf{y}, \\mathbf{y}' \\sim Q}[k(\\mathbf{y}, \\mathbf{y}')] - 2\\mathbb{E}_{\\mathbf{x} \\sim P, \\mathbf{y} \\sim Q}[k(\\mathbf{x}, \\mathbf{y})]\n    $$\n    给定来自 $P$ 的有限样本 $X = \\{\\mathbf{x}_1, \\dots, \\mathbf{x}_m\\}$ 和来自 $Q$ 的有限样本 $Y = \\{\\mathbf{y}_1, \\dots, \\mathbf{y}_n\\}$，通过用样本均值替换期望，可以得到 $\\text{MMD}^2$ 的有偏经验估计量：\n    $$\n    \\text{MMD}_b^2(X, Y) = \\frac{1}{m^2} \\sum_{i=1}^m \\sum_{j=1}^m k(\\mathbf{x}_i, \\mathbf{x}_j) + \\frac{1}{n^2} \\sum_{i=1}^n \\sum_{j=1}^n k(\\mathbf{y}_i, \\mathbf{y}_j) - \\frac{2}{mn} \\sum_{i=1}^m \\sum_{j=1}^n k(\\mathbf{x}_i, \\mathbf{y}_j)\n    $$\n    这可以用核格拉姆矩阵简洁地表示。设 $K_{XX}$ 是一个 $m \\times m$ 矩阵，其元素为 $K_{XX, ij} = k(\\mathbf{x}_i, \\mathbf{x}_j)$；$K_{YY}$ 是一个 $n \\times n$ 矩阵，其元素为 $K_{YY, ij} = k(\\mathbf{y}_i, \\mathbf{y}_j)$；$K_{XY}$ 是一个 $m \\times n$ 矩阵，其元素为 $K_{XY, ij} = k(\\mathbf{x}_i, \\mathbf{y}_j)$。那么，估计量就是 $K_{XX}$ 和 $K_{YY}$ 中所有元素的均值之和，减去 $K_{XY}$ 中所有元素均值的两倍。\n\n2.  **径向基函数（RBF）核**：问题指定使用RBF核，其定义如下：\n    $$\n    k(\\mathbf{x}, \\mathbf{y}) = \\exp\\left(-\\frac{\\|\\mathbf{x} - \\mathbf{y}\\|_{2}^{2}}{2\\sigma^2}\\right)\n    $$\n    其中 $\\|\\mathbf{x} - \\mathbf{y}\\|_{2}^{2}$ 是向量 $\\mathbf{x}$ 和 $\\mathbf{y}$ 之间的平方欧几里得距离，$\\sigma  0$ 是控制核“宽度”的核带宽参数。该核是特征核（characteristic kernel），意味着MMD为零当且仅当两个分布完全相同。\n\n3.  **带宽选择的中位数启发法**：RBF核的性能对 $\\sigma$ 的选择很敏感。中位数启发法提供了一种稳健的、数据驱动的方法来设置此参数。其步骤如下：\n    a. 将来自两个数据集 $X$ 和 $Y$ 的所有样本合并成一个大小为 $N=m+n$ 的集合 $Z = X \\cup Y$。\n    b. 计算所有唯一的、无序的成对平方欧几里得距离的集合：$\\{\\|\\mathbf{z}_i - \\mathbf{z}_j\\|_{2}^{2} : 1 \\le i  j \\le N\\}$。\n    c. 将参数 $\\sigma^2$ 设置为这组距离的中位数。\n    d. 如果中位数距离为 $0$（这在大多数数据点相同时发生），则会出现特殊情况。为防止在核函数中出现除以零的情况，将 $\\sigma^2$ 设置为一个小的正下限值 $\\varepsilon = 10^{-12}$。\n\n**算法综合**\n该实现将这些原理组合成一个具体的算法：\n\n1.  **输入**：接收形状为 $(m, d)$ 的真实数据矩阵 $X$ 和形状为 $(n, d)$ 的合成数据矩阵 $Y$。\n\n2.  **带宽计算**：\n    a. 将 $X$ 和 $Y$ 垂直拼接，形成一个形状为 $(m+n, d)$ 的合并矩阵 $Z$。\n    b. 计算 $Z$ 的行之间所有唯一的成对平方欧几里得距离的压缩向量。\n    c. 计算这些距离的中位数。此值被赋给 $\\sigma^2$。\n    d. 如果 $\\sigma^2 = 0$，则将其重新赋值为下限值 $\\varepsilon = 10^{-12}$。\n\n3.  **核矩阵计算**：\n    a. 计算三个成对平方欧几里得距离矩阵：$X$ 中样本间的 $D_{XX}$，$Y$ 中样本间的 $D_{YY}$，以及 $X$ 和 $Y$ 样本间的 $D_{XY}$。\n    b. 使用计算出的 $\\sigma^2$ 将RBF核逐元素地应用于这些距离矩阵：\n       - $K_{XX} = \\exp(-D_{XX} / (2\\sigma^2))$\n       - $K_{YY} = \\exp(-D_{YY} / (2\\sigma^2))$\n       - $K_{XY} = \\exp(-D_{XY} / (2\\sigma^2))$\n\n4.  **MMD估计**：\n    a. 计算每个核矩阵内元素的均值：$\\bar{K}_{XX}$，$\\bar{K}_{YY}$ 和 $\\bar{K}_{XY}$。\n    b. 根据有偏估计量公式组合这些均值：$\\text{MMD}_b^2 = \\bar{K}_{XX} + \\bar{K}_{YY} - 2\\bar{K}_{XY}$。\n\n5.  **输出**：按要求返回最终的 $\\text{MMD}_b^2$ 值，四舍五入到 $6$ 位小数。此过程系统地应用于每个提供的测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist, cdist\n\ndef compute_squared_mmd(X: np.ndarray, Y: np.ndarray, epsilon: float = 1e-12) -> float:\n    \"\"\"\n    Computes the biased empirical estimator of the squared Maximum Mean Discrepancy (MMD^2)\n    using the Radial Basis Function (RBF) kernel with bandwidth selected by the median heuristic.\n\n    Args:\n        X: A numpy array of shape (m, d) representing the first set of samples.\n        Y: A numpy array of shape (n, d) representing the second set of samples.\n        epsilon: A small positive floor for the kernel bandwidth squared to avoid division by zero.\n\n    Returns:\n        The computed squared MMD value.\n    \"\"\"\n    m, d = X.shape\n    n = Y.shape[0]\n\n    # Step 1: Bandwidth selection via the median heuristic.\n    # Pool the data from both distributions.\n    Z = np.vstack([X, Y])\n\n    # Compute all unique pairwise squared Euclidean distances.\n    # pdist computes a condensed distance matrix for the upper triangle.\n    if Z.shape[0] == 1:\n        # If there's only one point, there are no pairs. The median is undefined.\n        # Fallback to epsilon, though this case is not in the test suite.\n        # With m,n>=1 as per problem, Z.shape[0]>=2 unless one input is empty.\n        # But this would error on m, d = X.shape. Smallest case is m=1, n=1, Z.shape[0]=2.\n        # The logic handles this. But for robustness against m=1,n=0 etc,\n        # we can put a guard. The problem guarantees m,n>=1.\n        # Smallest number of pairs is 1, when Z.shape[0]==2. No risk of empty sq_dists.\n        pass\n    \n    sq_dists = pdist(Z, 'sqeuclidean')\n    \n    # The median of these distances is our sigma^2.\n    sigma_sq = np.median(sq_dists)\n\n    # If the median is 0, use the floor value epsilon.\n    if sigma_sq == 0.0:\n        sigma_sq = epsilon\n\n    # Step 2: Compute the RBF kernel matrices.\n    # gamma = 1 / (2 * sigma^2)\n    gamma = 1.0 / (2.0 * sigma_sq)\n\n    # Compute pairwise squared Euclidean distance matrices.\n    dist_XX = cdist(X, X, 'sqeuclidean')\n    dist_YY = cdist(Y, Y, 'sqeuclidean')\n    dist_XY = cdist(X, Y, 'sqeuclidean')\n\n    # Apply the RBF kernel function.\n    K_XX = np.exp(-gamma * dist_XX)\n    K_YY = np.exp(-gamma * dist_YY)\n    K_XY = np.exp(-gamma * dist_XY)\n\n    # Step 3: Compute the biased MMD^2 estimator.\n    # This is equivalent to mean(K_XX) + mean(K_YY) - 2 * mean(K_XY).\n    term1 = K_XX.sum() / (m * m)\n    term2 = K_YY.sum() / (n * n)\n    term3 = -2.0 * K_XY.sum() / (m * n)\n    \n    mmd2 = term1 + term2 + term3\n    \n    return mmd2\n\ndef solve():\n    \"\"\"\n    Runs the MMD^2 computation on the test cases provided in the problem statement\n    and prints the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: general \"happy path\"\n        (np.array([[0.0], [2.0]]), np.array([[1.0], [3.0]])),\n        # Case B: identical sets boundary\n        (np.array([[0.0], [2.0]]), np.array([[0.0], [2.0]])),\n        # Case C: small-sample edge with m=1\n        (np.array([[1.0]]), np.array([[-1.0], [2.0]])),\n        # Case D: degenerate constant vectors causing zero pairwise distances\n        (np.array([[5.0], [5.0]]), np.array([[5.0], [5.0]])),\n    ]\n\n    results = []\n    for X, Y in test_cases:\n        # Calculate the squared MMD for the current case.\n        mmd_squared_value = compute_squared_mmd(X, Y)\n        # Round the result to 6 decimal places.\n        rounded_result = round(mmd_squared_value, 6)\n        results.append(rounded_result)\n\n    # Final print statement in the exact required format.\n    # Ensure no trailing zeros are cut by casting to string.\n    # e.g. 0.0 becomes \"0.0\" not \"0\"\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    # Handle cases like 0.0 which should not have -0.000000\n    cleaned_results = [r.replace(\"-0.000000\", \"0.000000\") for r in formatted_results]\n    print(f\"[{','.join(cleaned_results)}]\")\n\nsolve()\n```"
        }
    ]
}