{
    "hands_on_practices": [
        {
            "introduction": "To quantify how a radiomic feature changes over time, we need a reliable method to estimate its rate of change. This exercise grounds this process in the fundamental principles of ordinary least squares (OLS) regression. By first deriving the simple slope for two time points and then generalizing to multiple observations, you will build a solid understanding of how to fit a linear trend to longitudinal data, a core task in delta-radiomics .",
            "id": "4536757",
            "problem": "In delta-radiomics for longitudinal analysis, a radiomic feature is modeled as a time-varying quantity to quantify change induced by therapy. Consider a single region-of-interest in a patient where the same radiomic feature is measured across therapy using Magnetic Resonance Imaging (MRI). Let the observed feature values be denoted by $f(t)$ at time $t$ (in weeks), and suppose that the true temporal evolution is approximately linear with additive zero-mean noise, i.e., $f(t) = \\beta_{0} + \\beta_{1} t + \\varepsilon(t)$, where $\\varepsilon(t)$ has mean $0$ and finite variance. The slope $\\beta_{1}$ represents the rate of change and is the quantity of interest in delta-radiomics.\n\nStarting from the definitions of least squares and the assumption above, do the following:\n\n1. Using first principles of ordinary least squares (OLS), derive the slope estimator $\\hat{\\beta}_{1}$ for the special case of exactly $2$ time points. Justify why the minimizer forces the fitted line to pass through both observations in this case, and obtain the slope as a function of the two observed pairs $\\{(t_{1}, f(t_{1})), (t_{2}, f(t_{2}))\\}$.\n\n2. Generalize the derivation to $T > 2$ time points. Starting from the sum of squared residuals $\\sum_{i=1}^{T} \\left(f(t_{i}) - \\beta_{0} - \\beta_{1} t_{i}\\right)^{2}$, derive the closed-form OLS slope estimator $\\hat{\\beta}_{1}$ in terms of $\\{t_{i}\\}$ and $\\{f(t_{i})\\}$ only, without leaving any unknowns in the final expression.\n\n3. Apply your results to the following longitudinal dataset measured at $T = 5$ time points: $t \\in \\{0, 2, 4, 6, 8\\}$ (weeks) with measured feature values $f(0) = 1.30$, $f(2) = 1.18$, $f(4) = 1.02$, $f(6) = 0.87$, and $f(8) = 0.80$ (arbitrary feature units). Compute:\n   - The two-point slope using only the baseline and final follow-up measurements.\n   - The OLS slope using all $5$ time points.\n\nExpress both slopes in units of feature units per week. Round each to four significant figures. Report your final answer as a row matrix in the order $\\left[\\hat{\\beta}_{1,\\text{two-point}} \\ \\hat{\\beta}_{1,\\text{OLS}}\\right]$. Do not include units in your final boxed answer.",
            "solution": "The model for the radiomic feature $f(t)$ at time $t$ is given by a simple linear regression model:\n$$f(t) = \\beta_{0} + \\beta_{1} t + \\varepsilon(t)$$\nwhere $\\beta_{0}$ is the intercept, $\\beta_{1}$ is the slope, and $\\varepsilon(t)$ is a zero-mean error term. The Ordinary Least Squares (OLS) method aims to find the estimators $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ that minimize the sum of squared residuals (SSR), defined as the sum of the squared differences between the observed values and the values predicted by the model.\n\n### 1. Derivation for Two Time Points ($T=2$)\n\nFor the special case of exactly two measurement pairs, $(t_{1}, f(t_{1}))$ and $(t_{2}, f(t_{2}))$, the sum of squared residuals is:\n$$SSR(\\beta_{0}, \\beta_{1}) = \\sum_{i=1}^{2} \\left(f(t_{i}) - (\\beta_{0} + \\beta_{1} t_{i})\\right)^{2} = \\left(f(t_{1}) - \\beta_{0} - \\beta_{1} t_{1}\\right)^{2} + \\left(f(t_{2}) - \\beta_{0} - \\beta_{1} t_{2}\\right)^{2}$$\nTo find the values of $\\beta_{0}$ and $\\beta_{1}$ that minimize this quantity, we can use two approaches: direct minimization or calculus.\n\n**Justification via Minimization Principle:**\nThe quantity $SSR(\\beta_{0}, \\beta_{1})$ is a sum of squared terms, which means its value is always non-negative, i.e., $SSR \\ge 0$. The absolute minimum value possible for $SSR$ is $0$. This minimum is achieved if and only if both squared terms are simultaneously zero:\n\\begin{align*} f(t_{1}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{1} &= 0 \\\\ f(t_{2}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{2} &= 0 \\end{align*}\nThis is a system of two linear equations in two unknowns, $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$. The geometric interpretation of these equations is that the fitted line $\\hat{f}(t) = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} t$ must pass exactly through both observed data points $(t_{1}, f(t_{1}))$ and $(t_{2}, f(t_{2}))$. Since it is possible to find such a line (as long as $t_1 \\neq t_2$), the OLS estimators must describe this line, as it results in the minimum possible SSR of $0$.\n\n**Derivation of the Slope Estimator:**\nWe solve the system of equations for $\\hat{\\beta}_{1}$. Rearranging the equations:\n\\begin{align*} f(t_{1}) &= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} t_{1} \\\\ f(t_{2}) &= \\hat{\\beta}_{0} + \\hat{\\beta}_{1} t_{2} \\end{align*}\nSubtracting the first equation from the second yields:\n$$f(t_{2}) - f(t_{1}) = (\\hat{\\beta}_{0} + \\hat{\\beta}_{1} t_{2}) - (\\hat{\\beta}_{0} + \\hat{\\beta}_{1} t_{1}) = \\hat{\\beta}_{1} (t_{2} - t_{1})$$\nAssuming $t_{1} \\neq t_{2}$, we can isolate $\\hat{\\beta}_{1}$:\n$$\\hat{\\beta}_{1} = \\frac{f(t_{2}) - f(t_{1})}{t_{2} - t_{1}}$$\nThis is the familiar formula for the slope of a line passing through two points.\n\n### 2. Generalization for $T > 2$ Time Points\n\nFor a general set of $T$ observations $\\{(t_{i}, f(t_{i}))\\}_{i=1}^{T}$, the sum of squared residuals is:\n$$SSR(\\beta_{0}, \\beta_{1}) = \\sum_{i=1}^{T} \\left(f(t_{i}) - \\beta_{0} - \\beta_{1} t_{i}\\right)^{2}$$\nTo find the estimators $\\hat{\\beta}_{0}$ and $\\hat{\\beta}_{1}$ that minimize $SSR$, we take the partial derivatives with respect to $\\beta_{0}$ and $\\beta_{1}$ and set them to zero.\n\nTaking the partial derivative with respect to $\\beta_{0}$:\n$$\\frac{\\partial SSR}{\\partial \\beta_{0}} = \\sum_{i=1}^{T} 2 \\left(f(t_{i}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{i}\\right)(-1) = -2 \\sum_{i=1}^{T} \\left(f(t_{i}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{i}\\right)$$\nSetting this to zero:\n$$\\sum_{i=1}^{T} f(t_{i}) - \\sum_{i=1}^{T} \\hat{\\beta}_{0} - \\sum_{i=1}^{T} \\hat{\\beta}_{1} t_{i} = 0 \\implies \\sum f(t_{i}) - T\\hat{\\beta}_{0} - \\hat{\\beta}_{1}\\sum t_{i} = 0$$\nThis is the first normal equation.\n\nTaking the partial derivative with respect to $\\beta_{1}$:\n$$\\frac{\\partial SSR}{\\partial \\beta_{1}} = \\sum_{i=1}^{T} 2 \\left(f(t_{i}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{i}\\right)(-t_{i}) = -2 \\sum_{i=1}^{T} t_{i}\\left(f(t_{i}) - \\hat{\\beta}_{0} - \\hat{\\beta}_{1} t_{i}\\right)$$\nSetting this to zero:\n$$\\sum_{i=1}^{T} t_{i}f(t_{i}) - \\sum_{i=1}^{T} \\hat{\\beta}_{0}t_{i} - \\sum_{i=1}^{T} \\hat{\\beta}_{1}t_{i}^2 = 0 \\implies \\hat{\\beta}_{0}\\sum t_{i} + \\hat{\\beta}_{1}\\sum t_{i}^2 = \\sum t_{i}f(t_{i})$$\nThis is the second normal equation.\n\nFrom the first normal equation, we can express $\\hat{\\beta}_{0}$ in terms of $\\hat{\\beta}_{1}$. Let $\\bar{t} = \\frac{1}{T}\\sum t_{i}$ and $\\bar{f} = \\frac{1}{T}\\sum f(t_{i})$ be the sample means.\n$$T\\hat{\\beta}_{0} = \\sum f(t_{i}) - \\hat{\\beta}_{1}\\sum t_{i} \\implies \\hat{\\beta}_{0} = \\frac{1}{T}\\sum f(t_{i}) - \\hat{\\beta}_{1} \\frac{1}{T}\\sum t_{i} = \\bar{f} - \\hat{\\beta}_{1}\\bar{t}$$\nNow, substitute this expression for $\\hat{\\beta}_{0}$ into the second normal equation:\n$$(\\bar{f} - \\hat{\\beta}_{1}\\bar{t})\\sum t_{i} + \\hat{\\beta}_{1}\\sum t_{i}^2 = \\sum t_{i}f(t_{i})$$\nDistribute and group terms with $\\hat{\\beta}_{1}$:\n$$\\bar{f}\\sum t_{i} - \\hat{\\beta}_{1}\\bar{t}\\sum t_{i} + \\hat{\\beta}_{1}\\sum t_{i}^2 = \\sum t_{i}f(t_{i})$$\n$$\\hat{\\beta}_{1}\\left(\\sum t_{i}^2 - \\bar{t}\\sum t_{i}\\right) = \\sum t_{i}f(t_{i}) - \\bar{f}\\sum t_{i}$$\nSolve for $\\hat{\\beta}_{1}$:\n$$\\hat{\\beta}_{1} = \\frac{\\sum t_{i}f(t_{i}) - \\bar{f}\\sum t_{i}}{\\sum t_{i}^2 - \\bar{t}\\sum t_{i}}$$\nThis is a valid closed-form solution. A more common and insightful form is obtained by substituting $\\sum t_{i} = T\\bar{t}$ and $\\sum f(t_{i}) = T\\bar{f}$:\n$$\\hat{\\beta}_{1} = \\frac{\\sum t_{i}f(t_{i}) - T\\bar{f}\\bar{t}}{\\sum t_{i}^2 - T\\bar{t}^2}$$\nThis expression can be further shown to be equivalent to the ratio of the sample covariance to the sample variance:\n$$\\hat{\\beta}_{1} = \\frac{\\sum_{i=1}^{T} (t_{i} - \\bar{t})(f(t_{i}) - \\bar{f})}{\\sum_{i=1}^{T} (t_{i} - \\bar{t})^2}$$\n\n### 3. Application to Longitudinal Dataset\n\nThe given dataset has $T=5$ time points:\n- Time points $t$: $\\{0, 2, 4, 6, 8\\}$ weeks\n- Feature values $f(t)$: $\\{1.30, 1.18, 1.02, 0.87, 0.80\\}$\n\n**Two-point slope calculation:**\nUsing only the baseline ($t_{1}=0, f(t_{1})=1.30$) and final ($t_{2}=8, f(t_{2})=0.80$) measurements, we apply the formula from Part 1:\n$$\\hat{\\beta}_{1,\\text{two-point}} = \\frac{f(8) - f(0)}{8 - 0} = \\frac{0.80 - 1.30}{8} = \\frac{-0.50}{8} = -0.0625$$\nRounded to four significant figures, this is $-0.06250$ feature units per week.\n\n**OLS slope calculation using all 5 time points:**\nWe use the formula $\\hat{\\beta}_{1} = \\frac{\\sum (t_{i} - \\bar{t})(f(t_{i}) - \\bar{f})}{\\sum (t_{i} - \\bar{t})^2}$.\nFirst, calculate the means:\n$$\\bar{t} = \\frac{0+2+4+6+8}{5} = \\frac{20}{5} = 4$$\n$$\\bar{f} = \\frac{1.30 + 1.18 + 1.02 + 0.87 + 0.80}{5} = \\frac{5.17}{5} = 1.034$$\nNow, we compute the necessary sums.\nSum of squared deviations for $t$:\n$$\\sum_{i=1}^{5} (t_{i} - \\bar{t})^2 = (0-4)^2 + (2-4)^2 + (4-4)^2 + (6-4)^2 + (8-4)^2$$\n$$= (-4)^2 + (-2)^2 + 0^2 + 2^2 + 4^2 = 16 + 4 + 0 + 4 + 16 = 40$$\nSum of the products of deviations:\n$$\\sum_{i=1}^{5} (t_{i} - \\bar{t})(f(t_{i}) - \\bar{f}) = (0-4)(1.30-1.034) + (2-4)(1.18-1.034) + (4-4)(1.02-1.034) + (6-4)(0.87-1.034) + (8-4)(0.80-1.034)$$\n$$= (-4)(0.266) + (-2)(0.146) + (0)(-0.014) + (2)(-0.164) + (4)(-0.234)$$\n$$= -1.064 - 0.292 + 0 - 0.328 - 0.936 = -2.620$$\nFinally, we compute the OLS slope estimator:\n$$\\hat{\\beta}_{1,\\text{OLS}} = \\frac{-2.620}{40} = -0.0655$$\nRounded to four significant figures, this is $-0.06550$ feature units per week.\n\nThe two-point slope is $\\hat{\\beta}_{1,\\text{two-point}} = -0.06250$ and the OLS slope using all data is $\\hat{\\beta}_{1,\\text{OLS}} = -0.06550$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-0.06250 & -0.06550\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Measuring a change in a feature is only half the story; we must also understand the uncertainty associated with that measurement. This practice problem explores how random measurement errors propagate when you calculate a delta-feature, defined as the difference between two time points . You will derive the variance of this change and investigate the critical impact of correlation between noise at different time points, a crucial factor for interpreting the reliability of observed changes.",
            "id": "4536699",
            "problem": "In delta-radiomics for longitudinal analysis, a radiomic feature is extracted at two time points, denoted by $t_1$ and $t_2$. Let the observed feature value at time $t$ be $Y_t = f(t) + \\epsilon_t$, where $f(t)$ is the true (noise-free) feature value and $\\epsilon_t$ is measurement noise arising from segmentation and reconstruction variability. Assume that for a given patient, the quantities $f(t_1)$ and $f(t_2)$ are fixed (non-random) and that $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ with the same variance $\\sigma^2$ at both time points. Define the delta-radiomic feature as $\\Delta f = Y_{t_2} - Y_{t_1}$. Using only the axioms of variance and covariance for linear combinations of random variables, first compute $\\mathrm{Var}(\\Delta f)$ under the assumption that $\\epsilon_{t_1}$ and $\\epsilon_{t_2}$ are independent. Then consider a more realistic scenario in which there is shared acquisition bias so that $\\mathrm{Cov}(\\epsilon_{t_1},\\epsilon_{t_2}) = \\rho\\,\\sigma^2$ with $-1 \\le \\rho \\le 1$. Derive $\\mathrm{Var}(\\Delta f)$ in terms of $\\sigma^2$ and $\\rho$ under this correlated-noise model. Provide your final answer as a single closed-form analytic expression in terms of $\\sigma^2$ and $\\rho$. No rounding is required.",
            "solution": "The objective is to compute the variance of the delta-radiomic feature, $\\mathrm{Var}(\\Delta f)$. We begin by expressing $\\Delta f$ in terms of its constituent components.\n\nThe definition of the delta-radiomic feature is:\n$$ \\Delta f = Y_{t_2} - Y_{t_1} $$\n\nSubstitute the model for the observed feature values, $Y_t = f(t) + \\epsilon_t$:\n$$ \\Delta f = (f(t_2) + \\epsilon_{t_2}) - (f(t_1) + \\epsilon_{t_1}) $$\n\nRearranging the terms to separate the non-random and random components gives:\n$$ \\Delta f = (f(t_2) - f(t_1)) + (\\epsilon_{t_2} - \\epsilon_{t_1}) $$\n\nWe now compute the variance of $\\Delta f$. According to the problem statement, the true feature values $f(t_1)$ and $f(t_2)$ are fixed, non-random quantities for a given patient. Therefore, their difference, $f(t_2) - f(t_1)$, is a constant. A fundamental property of variance is that for any random variable $X$ and constant $c$, $\\mathrm{Var}(X+c) = \\mathrm{Var}(X)$. Applying this property, we have:\n$$ \\mathrm{Var}(\\Delta f) = \\mathrm{Var}((f(t_2) - f(t_1)) + (\\epsilon_{t_2} - \\epsilon_{t_1})) = \\mathrm{Var}(\\epsilon_{t_2} - \\epsilon_{t_1}) $$\n\nWe now use the axiom for the variance of a linear combination of two random variables, $A$ and $B$:\n$$ \\mathrm{Var}(aA + bB) = a^2 \\mathrm{Var}(A) + b^2 \\mathrm{Var}(B) + 2ab \\mathrm{Cov}(A, B) $$\n\nIn our case, $A = \\epsilon_{t_2}$, $B = \\epsilon_{t_1}$, $a = 1$, and $b = -1$. Substituting these into the formula yields:\n$$ \\mathrm{Var}(\\epsilon_{t_2} - \\epsilon_{t_1}) = (1)^2 \\mathrm{Var}(\\epsilon_{t_2}) + (-1)^2 \\mathrm{Var}(\\epsilon_{t_1}) + 2(1)(-1) \\mathrm{Cov}(\\epsilon_{t_2}, \\epsilon_{t_1}) $$\n$$ \\mathrm{Var}(\\Delta f) = \\mathrm{Var}(\\epsilon_{t_2}) + \\mathrm{Var}(\\epsilon_{t_1}) - 2 \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2}) $$\nNote that the covariance is symmetric, i.e., $\\mathrm{Cov}(\\epsilon_{t_2}, \\epsilon_{t_1}) = \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2})$.\n\nFrom the problem statement, we are given that $\\mathrm{Var}(\\epsilon_{t_1}) = \\sigma^2$ and $\\mathrm{Var}(\\epsilon_{t_2}) = \\sigma^2$. Substituting these into the expression gives:\n$$ \\mathrm{Var}(\\Delta f) = \\sigma^2 + \\sigma^2 - 2 \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2}) = 2\\sigma^2 - 2 \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2}) $$\n\nNow we evaluate this expression for the two specified scenarios.\n\n**Case 1: Independent Noise**\nIf the noise terms $\\epsilon_{t_1}$ and $\\epsilon_{t_2}$ are independent, their covariance is zero:\n$$ \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2}) = 0 $$\nSubstituting this into our general expression for $\\mathrm{Var}(\\Delta f)$:\n$$ \\mathrm{Var}(\\Delta f) = 2\\sigma^2 - 2(0) = 2\\sigma^2 $$\nThus, under the assumption of independent noise, the variance of the delta feature is twice the variance of the individual measurements.\n\n**Case 2: Correlated Noise**\nIn the more realistic scenario, we are given a non-zero covariance:\n$$ \\mathrm{Cov}(\\epsilon_{t_1}, \\epsilon_{t_2}) = \\rho\\,\\sigma^2 $$\nHere, $\\rho$ is the correlation coefficient between the noise terms. Substituting this into our general expression for $\\mathrm{Var}(\\Delta f)$:\n$$ \\mathrm{Var}(\\Delta f) = 2\\sigma^2 - 2(\\rho\\,\\sigma^2) $$\n\nFactoring out the term $2\\sigma^2$, we arrive at the final expression for the variance of the delta-radiomic feature under the correlated-noise model:\n$$ \\mathrm{Var}(\\Delta f) = 2\\sigma^2(1 - \\rho) $$\n\nThis expression is the required result, representing the variance of the delta feature in terms of the single-measurement noise variance $\\sigma^2$ and the correlation $\\rho$. This result shows that positive correlation ($\\rho > 0$) reduces the variance of the difference compared to the independent case, while negative correlation ($\\rho  0$) increases it.\n\nThe problem asks for the single closed-form analytic expression from the correlated-noise model.",
            "answer": "$$ \\boxed{2\\sigma^2(1 - \\rho)} $$"
        },
        {
            "introduction": "The ultimate goal of delta-radiomics is often to build predictive models that forecast patient outcomes. This hands-on coding exercise takes you to the final step of the modeling pipeline: performance evaluation in the challenging context of survival analysis . You will implement the time-dependent Brier score with Inverse Probability of Censoring Weighting (IPCW), a sophisticated metric for assessing the accuracy of a survival model that uses time-varying delta-radiomic features.",
            "id": "4536730",
            "problem": "You are given a longitudinal radiomics setting with right-censored survival outcomes and time-varying image-derived predictors. The goal is to define and compute the time-dependent Brier score at evaluation time $t$ for binary survival outcomes under censoring using Inverse Probability of Censoring Weighting (IPCW). Your implementation should be grounded in first principles: the mean squared error for binary outcomes, the definition of the survival indicator at time $t$, and the Kaplan–Meier estimator for the censoring distribution.\n\nDefinitions and assumptions:\n- There are $n$ subjects indexed by $i \\in \\{1,\\dots,n\\}$.\n- For subject $i$, let $T_i$ denote the observed time (event time or censoring time), and let $\\Delta_i \\in \\{0,1\\}$ denote the event indicator, with $\\Delta_i = 1$ indicating an observed event and $\\Delta_i = 0$ indicating right-censoring.\n- At an evaluation time $t$, the binary survival status is $Z_i(t) = \\mathbb{1}\\{T_i  t\\}$, where $\\mathbb{1}\\{\\cdot\\}$ is the indicator function. If $T_i \\le t$ and $\\Delta_i = 0$ (censored before or at $t$), then $Z_i(t)$ is unobserved.\n- You are given time-varying radiomics features $x_i(u)$ measured at discrete times $u \\in \\{0,2,4\\}$ for each subject $i$. Define $x_i^\\ast(t)$ as the last-observation-carried-forward feature value: $x_i^\\ast(t) = x_i(u^\\ast)$ where $u^\\ast = \\max\\{u \\in \\{0,2,4\\} : u \\le t\\}$. The baseline feature is $x_i(0)$.\n- Predicted survival probability at time $t$ for subject $i$ is defined by a logistic model using the current feature and its change from baseline:\n$$\n\\hat{S}_i(t) = \\sigma\\!\\left(\\alpha + \\beta \\, x_i^\\ast(t) + \\gamma \\, (x_i^\\ast(t) - x_i(0)) + \\delta \\, t \\right),\n$$\nwhere $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$ is the logistic function, and $(\\alpha,\\beta,\\gamma,\\delta)$ are fixed coefficients.\n\nUnder the assumption of non-informative censoring (independence of censoring and the event process conditional on the observed features), the IPCW time-dependent Brier score at time $t$ is defined by\n$$\n\\mathrm{BS}(t) = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{\\mathbb{1}\\{T_i  t\\}}{\\hat{G}(t)} \\left(1 - \\hat{S}_i(t)\\right)^2 + \\frac{\\mathbb{1}\\{T_i \\le t, \\, \\Delta_i = 1\\}}{\\hat{G}(T_i)} \\left(0 - \\hat{S}_i(t)\\right)^2 \\right],\n$$\nwhere $\\hat{G}(u)$ is the Kaplan–Meier estimator of the censoring survival function $G(u) = \\mathbb{P}(C \\ge u)$, with $C$ the censoring time. The Kaplan–Meier estimator for censoring treats observed censorings as events in the censoring process: at censoring times $c_j$, with $d_j$ censoring events and $Y_j$ subjects at risk just prior to $c_j$, the estimator satisfies\n$$\n\\hat{G}(u) = \\prod_{c_j \\le u} \\left(1 - \\frac{d_j}{Y_j}\\right).\n$$\nTo ensure numerical stability at times where $\\hat{G}(u)$ is zero, use a small positive lower bound $\\epsilon = 10^{-12}$ in the denominator, that is, replace $\\hat{G}(u)$ by $\\max\\{\\hat{G}(u), \\epsilon\\}$ wherever it appears.\n\nData for this task:\n- Number of subjects $n = 6$.\n- Observed times $(T_i)$ and event indicators $(\\Delta_i)$:\n  - Subject $1$: $T_1 = 5.0$, $\\Delta_1 = 1$.\n  - Subject $2$: $T_2 = 7.0$, $\\Delta_2 = 0$.\n  - Subject $3$: $T_3 = 3.0$, $\\Delta_3 = 1$.\n  - Subject $4$: $T_4 = 10.0$, $\\Delta_4 = 1$.\n  - Subject $5$: $T_5 = 4.0$, $\\Delta_5 = 0$.\n  - Subject $6$: $T_6 = 8.0$, $\\Delta_6 = 1$.\n- Radiomics features $x_i(u)$ measured at times $u \\in \\{0,2,4\\}$:\n  - Subject $1$: $x_1(0) = 1.2$, $x_1(2) = 1.5$, $x_1(4) = 1.8$.\n  - Subject $2$: $x_2(0) = 0.8$, $x_2(2) = 0.9$, $x_2(4) = 1.1$.\n  - Subject $3$: $x_3(0) = 1.6$, $x_3(2) = 1.7$, $x_3(4) = 1.8$.\n  - Subject $4$: $x_4(0) = 0.5$, $x_4(2) = 0.7$, $x_4(4) = 0.9$.\n  - Subject $5$: $x_5(0) = 2.0$, $x_5(2) = 1.8$, $x_5(4) = 1.7$.\n  - Subject $6$: $x_6(0) = 1.1$, $x_6(2) = 1.3$, $x_6(4) = 1.4$.\n- Coefficients $(\\alpha, \\beta, \\gamma, \\delta)$: $\\alpha = 0.2$, $\\beta = -0.5$, $\\gamma = 0.3$, $\\delta = -0.1$.\n\nEvaluation times (test suite):\n- $t \\in \\{2.0, 4.0, 6.0, 7.0\\}$ test four cases: an early time with no censoring or events before it, a boundary at a censoring time, a time after some events with IPCW dependence on $\\hat{G}(T_i)$, and a time exactly at a later censoring time.\n\nTasks:\n1. Implement the Kaplan–Meier estimator $\\hat{G}(u)$ for the censoring distribution using the given $(T_i, \\Delta_i)$, where censorings ($\\Delta_i = 0$) are events in the censoring process and observed events ($\\Delta_i = 1$) are treated as right-censored in the censoring process.\n2. Compute $\\hat{S}_i(t)$ for each subject at each evaluation time using the last-observation-carried-forward feature $x_i^\\ast(t)$ and the specified logistic model.\n3. Compute $\\mathrm{BS}(t)$ for each evaluation time using the IPCW formula and $\\epsilon = 10^{-12}$ for numerical stabilization.\n\nFinal output format:\n- Your program should produce a single line of output containing the Brier scores at the specified evaluation times as a comma-separated list enclosed in square brackets, with each score rounded to six decimal places (for example, $[\\mathrm{BS}(2.0),\\mathrm{BS}(4.0),\\mathrm{BS}(6.0),\\mathrm{BS}(7.0)]$). No other text should be printed.",
            "solution": "The objective is to compute the time-dependent Brier score, $\\mathrm{BS}(t)$, at several evaluation times $t$. The Brier score measures the mean squared error between predicted probabilities and observed outcomes. For right-censored survival data, the true outcome (whether a subject survives past time $t$) is not always known. We use Inverse Probability of Censoring Weighting (IPCW) to correct for this bias, assuming non-informative censoring.\n\nThe IPCW Brier score at time $t$ is given by:\n$$ \\mathrm{BS}(t) = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\frac{\\mathbb{1}\\{T_i  t\\}}{\\hat{G}(t)} \\left(1 - \\hat{S}_i(t)\\right)^2 + \\frac{\\mathbb{1}\\{T_i \\le t, \\, \\Delta_i = 1\\}}{\\hat{G}(T_i)} \\left(0 - \\hat{S}_i(t)\\right)^2 \\right] $$\nwhere $\\hat{S}_i(t)$ is the predicted survival probability for subject $i$ at time $t$, and $\\hat{G}(u)$ is the Kaplan-Meier estimate of the censoring survival function. The two terms in the sum correspond to subjects who are observed to survive past $t$ (true outcome is $1$) and subjects who are observed to have an event at or before $t$ (true outcome is $0$), respectively. Each contribution is weighted by the inverse probability of not being censored up to the time of observation. Subjects censored before or at $t$ do not contribute to the sum as their outcomes are unknown.\n\nThe calculation proceeds in three main steps:\n1.  Estimate the censoring survival function $\\hat{G}(u)$.\n2.  Calculate the predicted survival probabilities $\\hat{S}_i(t)$ for all subjects $i$ and required times $t$.\n3.  Combine these to compute $\\mathrm{BS}(t)$ at each evaluation time.\n\n### Step 1: Kaplan-Meier Estimator for the Censoring Distribution, $\\hat{G}(u)$\n\nTo compute $\\hat{G}(u) = \\mathbb{P}(C \\ge u)$, we treat censoring events ($\\Delta_i=0$) as \"events\" and actual events ($\\Delta_i=1$) as \"censored\" observations in the context of estimating the censoring distribution. The given data for the $n=6$ subjects are $(T_i, \\Delta_i)$:\n-   $i=1: (5.0, 1)$\n-   $i=2: (7.0, 0)$\n-   $i=3: (3.0, 1)$\n-   $i=4: (10.0, 1)$\n-   $i=5: (4.0, 0)$\n-   $i=6: (8.0, 1)$\n\nThe unique times of censoring are $c_1=4.0$ (subject $5$) and $c_2=7.0$ (subject $2$). We construct a life table for the censoring process:\n-   Initially, at time $u=0$, all $6$ subjects are at risk of being censored. $\\hat{G}(u) = 1.0$ for $u  4.0$.\n-   At the first censoring time, $c_1=4.0$:\n    -   The number of subjects at risk just prior to $t=4.0$ are those with $T_i \\ge 4.0$. These are subjects $\\{1, 2, 4, 5, 6\\}$, so the risk set size is $Y_{4.0} = 5$.\n    -   The number of censoring events at $t=4.0$ is $d_{4.0} = 1$ (subject $5$).\n    -   The survival factor is $(1 - d_{4.0}/Y_{4.0}) = (1 - 1/5) = 0.8$.\n    -   Thus, $\\hat{G}(u) = 1.0 \\times 0.8 = 0.8$ for $u \\in [4.0, 7.0)$.\n-   At the second censoring time, $c_2=7.0$:\n    -   The number of subjects at risk just prior to $t=7.0$ are those with $T_i \\ge 7.0$. These are subjects $\\{2, 4, 6\\}$, so the risk set size is $Y_{7.0} = 3$.\n    -   The number of censoring events at $t=7.0$ is $d_{7.0} = 1$ (subject $2$).\n    -   The survival factor is $(1 - d_{7.0}/Y_{7.0}) = (1 - 1/3) = 2/3$.\n    -   Thus, $\\hat{G}(u) = 0.8 \\times (2/3) = 8/15 \\approx 0.5333...$ for $u \\ge 7.0$.\n\nThe resulting censoring survival function is a step function:\n$$\n\\hat{G}(u) =\n\\begin{cases}\n1.0  \\text{if } u  4.0 \\\\\n0.8  \\text{if } 4.0 \\le u  7.0 \\\\\n8/15  \\text{if } u \\ge 7.0\n\\end{cases}\n$$\nThe smallest value of $\\hat{G}(u)$ needed for our denominators is $8/15$, which is much larger than the stability constant $\\epsilon=10^{-12}$, so no stabilization is required.\n\n### Step 2: Predicted Survival Probabilities, $\\hat{S}_i(t)$\n\nThe predicted survival probability is given by the logistic model:\n$$ \\hat{S}_i(t) = \\sigma\\!\\left(\\alpha + \\beta \\, x_i^\\ast(t) + \\gamma \\, (x_i^\\ast(t) - x_i(0)) + \\delta \\, t \\right) $$\nwith coefficients $(\\alpha, \\beta, \\gamma, \\delta) = (0.2, -0.5, 0.3, -0.1)$. The feature value $x_i^\\ast(t)$ is the last observation carried forward (LOCF) from measurement times $u \\in \\{0, 2, 4\\}$.\n-   For $t \\in [2.0, 4.0)$, $x_i^\\ast(t) = x_i(2)$.\n-   For $t \\ge 4.0$, $x_i^\\ast(t) = x_i(4)$.\n\nThe argument of the logistic function $\\sigma(z) = 1/(1+e^{-z})$ is:\n$z_i(t) = 0.2 - 0.5 x_i^\\ast(t) + 0.3 (x_i^\\ast(t) - x_i(0)) - 0.1 t$.\n\nFor each evaluation time $t \\in \\{2.0, 4.0, 6.0, 7.0\\}$, we compute $z_i(t)$ and $\\hat{S}_i(t)$ for all subjects $i=1,\\dots,6$.\n\n### Step 3: Brier Score Calculation\n\nWe now combine the above components to compute $\\mathrm{BS}(t)$ for each evaluation time. We illustrate with $t=6.0$.\nAt $t=6.0$:\n-   The weight for survivors is $1/\\hat{G}(6.0) = 1/0.8 = 1.25$.\n-   Subjects with $T_i  6.0$: $\\{2, 4, 6\\}$. Their contribution is $\\frac{(1 - \\hat{S}_i(6.0))^2}{0.8}$.\n-   Subjects with $T_i \\le 6.0$ and $\\Delta_i=1$: $\\{1, 3\\}$. Their contribution is $\\frac{(0 - \\hat{S}_i(6.0))^2}{\\hat{G}(T_i)}$.\n-   Subjects censored at or before $t=6.0$: $\\{5\\}$. They contribute $0$.\n-   $x_i^\\ast(6.0) = x_i(4)$ for all $i$.\n\nThe total Brier score is the average of individual contributions. For example, for Subject 2 ($T_2=7.0, \\Delta_2=0$), who survived past $t=6.0$, the contribution is:\n$\\frac{(1 - \\hat{S}_2(6.0))^2}{\\hat{G}(6.0)} = \\frac{(1 - \\sigma(0.2 - 0.5(1.1) + 0.3(1.1-0.8) - 0.1(6.0)))^2}{0.8} \\approx 0.6171$.\n\nRepeating this procedure for all evaluation times yields:\n-   $\\mathrm{BS}(2.0) \\approx 0.424104$\n-   $\\mathrm{BS}(4.0) \\approx 0.390764$\n-   $\\mathrm{BS}(6.0) \\approx 0.330678$\n-   $\\mathrm{BS}(7.0) \\approx 0.346288$",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the time-dependent Brier score at specified evaluation times\n    for a longitudinal survival analysis setting using IPCW.\n    \"\"\"\n    # Define the test cases (evaluation times) from the problem statement.\n    eval_times = [2.0, 4.0, 6.0, 7.0]\n\n    # --- Data from the problem statement ---\n    n_subjects = 6\n    # Observed times (T_i) and event indicators (Delta_i)\n    T = np.array([5.0, 7.0, 3.0, 10.0, 4.0, 8.0])\n    delta = np.array([1, 0, 1, 1, 0, 1])  # 1: event, 0: censored\n\n    # Radiomics features x_i(u) at u=0, 2, 4\n    feature_times = np.array([0.0, 2.0, 4.0])\n    features = np.array([\n        [1.2, 1.5, 1.8],  # Subject 1\n        [0.8, 0.9, 1.1],  # Subject 2\n        [1.6, 1.7, 1.8],  # Subject 3\n        [0.5, 0.7, 0.9],  # Subject 4\n        [2.0, 1.8, 1.7],  # Subject 5\n        [1.1, 1.3, 1.4]   # Subject 6\n    ])\n\n    # Model coefficients\n    coeffs = {'alpha': 0.2, 'beta': -0.5, 'gamma': 0.3, 'delta': -0.1}\n    epsilon = 1e-12\n\n    # --- Helper Functions ---\n\n    def kaplan_meier_censoring_estimator(T, delta):\n        \"\"\"\n        Computes the Kaplan-Meier estimator for the censoring distribution.\n        Censorings (delta=0) are treated as events.\n        \"\"\"\n        is_censored = (delta == 0)\n        unique_censoring_times = np.unique(T[is_censored])\n        \n        survival_probs = []\n        current_survival = 1.0\n        \n        for t_cens in unique_censoring_times:\n            n_at_risk = np.sum(T = t_cens)\n            n_censored = np.sum((T == t_cens)  is_censored)\n            \n            if n_at_risk  0:\n                current_survival *= (1.0 - n_censored / n_at_risk)\n            survival_probs.append(current_survival)\n            \n        return unique_censoring_times, np.array(survival_probs)\n\n    def get_G_hat(u, km_times, km_probs, epsilon):\n        \"\"\"\n        Queries the pre-computed Kaplan-Meier curve for G(u).\n        \"\"\"\n        if km_times.size == 0 or u  km_times[0]:\n            return 1.0\n        \n        idx = np.searchsorted(km_times, u, side='right')\n        \n        if idx == 0:\n            return 1.0\n        \n        prob = km_probs[idx - 1]\n        return np.maximum(prob, epsilon)\n\n    def sigma(z):\n        \"\"\"Logistic (sigmoid) function.\"\"\"\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def get_locf_feature(t, subject_idx, features, feature_times):\n        \"\"\"\n        Gets the last-observation-carried-forward (LOCF) feature value for a subject.\n        \"\"\"\n        valid_times_idx = np.where(feature_times = t)[0]\n        locf_idx = valid_times_idx[-1]\n        return features[subject_idx, locf_idx]\n\n    def compute_s_hat(t, subject_idx, features, feature_times, coeffs):\n        \"\"\"\n        Computes the predicted survival probability S_hat(t) for a subject.\n        \"\"\"\n        x_0 = features[subject_idx, 0]\n        x_star_t = get_locf_feature(t, subject_idx, features, feature_times)\n        \n        z = (coeffs['alpha'] + \n             coeffs['beta'] * x_star_t + \n             coeffs['gamma'] * (x_star_t - x_0) + \n             coeffs['delta'] * t)\n        \n        return sigma(z)\n\n    # --- Main Calculation ---\n    \n    # Step 1: Pre-calculate the Kaplan-Meier curve for the censoring distribution\n    km_censoring_times, km_censoring_probs = kaplan_meier_censoring_estimator(T, delta)\n\n    results = []\n    # Loop through each evaluation time to compute the Brier Score\n    for t_eval in eval_times:\n        brier_score_sum = 0.0\n        \n        # Get inverse probability weight for subjects who survive past t_eval\n        G_hat_t_eval = get_G_hat(t_eval, km_censoring_times, km_censoring_probs, epsilon)\n        \n        # Sum contributions from each subject\n        for i in range(n_subjects):\n            # Step 2: Compute predicted survival probability for subject i at t_eval\n            s_hat_i_t = compute_s_hat(t_eval, i, features, feature_times, coeffs)\n            \n            # Step 3: Add the weighted squared error to the sum\n            if T[i]  t_eval:\n                # Case 1: Subject is observed to survive past t_eval\n                weight = 1.0 / G_hat_t_eval\n                error = (1.0 - s_hat_i_t)**2\n                brier_score_sum += error * weight\n            elif T[i] = t_eval and delta[i] == 1:\n                # Case 2: Subject is observed to have an event at or before t_eval\n                G_hat_Ti = get_G_hat(T[i], km_censoring_times, km_censoring_probs, epsilon)\n                weight = 1.0 / G_hat_Ti\n                error = (0.0 - s_hat_i_t)**2\n                brier_score_sum += error * weight\n            # Case 3: Subject is censored at or before t_eval (T[i] = t_eval and delta[i] == 0)\n            # Contribution is 0, so no action needed.\n        \n        # Average the sum to get the Brier Score\n        bs_t = brier_score_sum / n_subjects\n        results.append(bs_t)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}