{
    "hands_on_practices": [
        {
            "introduction": "Quantifying the repeatability of a radiomic feature is a foundational skill. This first exercise challenges you to compute the Intraclass Correlation Coefficient (ICC), the cornerstone metric for this task, directly from the outputs of an Analysis of Variance (ANOVA). By using the provided between-subject and within-subject sums of squares, you will practice partitioning measurement variability to assess feature reliability, a core concept detailed in .",
            "id": "4563339",
            "problem": "A radiomics study quantifies a texture feature derived from the Gray-Level Co-Occurrence Matrix (GLCM) across test-retest scans to assess repeatability. Twenty subjects ($n=20$) are scanned twice under identical acquisition and reconstruction settings ($k=2$ replicates per subject). For a single feature, a one-way analysis of variance (ANOVA) decomposition on the paired measurements yields a between-subject sum of squares $SS_{\\text{between}}=1.50\\times 10^{3}$ and a within-subject sum of squares $SS_{\\text{within}}=1.60\\times 10^{2}$. A separate phantom-based validation using a uniform imaging phantom scanned twice under the same protocol shows negligible feature variation, $SS_{\\text{phantom}}\\approx 0$, consistent with stable acquisition.\n\nStarting from first principles appropriate for a one-way random-effects model for test-retest, derive the single-measure Intraclass Correlation Coefficient (ICC) for this feature using the ANOVA quantities provided. Then evaluate the numeric value using the given $SS_{\\text{between}}$ and $SS_{\\text{within}}$. Finally, in your working, briefly interpret the magnitude of the computed ICC in the context of feature selection for downstream modeling under commonly used reliability guidelines.\n\nExpress the final ICC as a decimal rounded to four significant figures, without units.",
            "solution": "The problem statement has been validated and is deemed sound. It is scientifically grounded, well-posed, and objective. It provides all necessary information to derive and compute the Intraclass Correlation Coefficient (ICC) as requested. The context provided about the phantom-based validation serves to reinforce the suitability of the chosen statistical model by indicating negligible system-level measurement error.\n\nWe begin by establishing the theoretical framework. The problem describes a test-retest reliability study analyzed using a one-way analysis of variance (ANOVA). This corresponds to a one-way random-effects model, which is appropriate for partitioning variance when subjects are considered a random sample from a larger population. The model for the $j$-th measurement on the $i$-th subject is given by:\n$$y_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}$$\nwhere $y_{ij}$ is the observed feature value for subject $i \\in \\{1, \\dots, n\\}$ and replicate $j \\in \\{1, \\dots, k\\}$. The term $\\mu$ is the grand mean of the feature across all subjects and measurements. The term $\\alpha_i$ represents the random effect of subject $i$, assumed to be normally distributed with mean $0$ and variance $\\sigma^2_{\\text{between}}$, i.e., $\\alpha_i \\sim N(0, \\sigma^2_{\\text{between}})$. This variance component, $\\sigma^2_{\\text{between}}$, captures the true biological variability between subjects. The term $\\epsilon_{ij}$ represents the random measurement error, assumed to be normally distributed with mean $0$ and variance $\\sigma^2_{\\text{within}}$, i.e., $\\epsilon_{ij} \\sim N(0, \\sigma^2_{\\text{within}})$. This variance component, $\\sigma^2_{\\text{within}}$, captures the variability within a subject across repeated measurements. The total variance of a single observation is the sum of these two components: $\\sigma^2_{\\text{total}} = \\sigma^2_{\\text{between}} + \\sigma^2_{\\text{within}}$.\n\nThe single-measure Intraclass Correlation Coefficient, often denoted as ICC(1,1), is defined as the proportion of the total variance that is attributable to the between-subject variation. It quantifies the reliability of a single measurement.\n$$ICC = \\frac{\\sigma^2_{\\text{between}}}{\\sigma^2_{\\text{total}}} = \\frac{\\sigma^2_{\\text{between}}}{\\sigma^2_{\\text{between}} + \\sigma^2_{\\text{within}}}$$\nTo calculate the ICC, we must first estimate the variance components $\\sigma^2_{\\text{between}}$ and $\\sigma^2_{\\text{within}}$ from the ANOVA outputs. The expected values of the mean squares in a one-way random-effects ANOVA are:\n$$E(MS_{\\text{between}}) = \\sigma^2_{\\text{within}} + k \\sigma^2_{\\text{between}}$$\n$$E(MS_{\\text{within}}) = \\sigma^2_{\\text{within}}$$\nwhere $MS_{\\text{between}}$ is the between-subject mean square and $MS_{\\text{within}}$ is the within-subject mean square. These are calculated from the sums of squares ($SS$) and degrees of freedom ($df$) as:\n$$MS_{\\text{between}} = \\frac{SS_{\\text{between}}}{df_{\\text{between}}} = \\frac{SS_{\\text{between}}}{n-1}$$\n$$MS_{\\text{within}} = \\frac{SS_{\\text{within}}}{df_{\\text{within}}} = \\frac{SS_{\\text{within}}}{n(k-1)}$$\nBy setting the observed mean squares equal to their expected values, we can derive method-of-moments estimators for the variance components:\n$$\\hat{\\sigma}^2_{\\text{within}} = MS_{\\text{within}}$$\n$$\\hat{\\sigma}^2_{\\text{between}} = \\frac{MS_{\\text{between}} - MS_{\\text{within}}}{k}$$\nSubstituting these estimators into the ICC formula yields:\n$$ICC = \\frac{\\frac{MS_{\\text{between}} - MS_{\\text{within}}}{k}}{\\frac{MS_{\\text{between}} - MS_{\\text{within}}}{k} + MS_{\\text{within}}}$$\nMultiplying the numerator and denominator by $k$ simplifies the expression:\n$$ICC = \\frac{MS_{\\text{between}} - MS_{\\text{within}}}{MS_{\\text{between}} - MS_{\\text{within}} + k \\cdot MS_{\\text{within}}} = \\frac{MS_{\\text{between}} - MS_{\\text{within}}}{MS_{\\text{between}} + (k-1)MS_{\\text{within}}}$$\nThis is the general formula for the single-measure ICC derived from a one-way ANOVA.\n\nNow, we apply this formula to the given data:\nNumber of subjects, $n = 20$.\nNumber of replicates, $k = 2$.\nBetween-subject sum of squares, $SS_{\\text{between}} = 1.50 \\times 10^{3} = 1500$.\nWithin-subject sum of squares, $SS_{\\text{within}} = 1.60 \\times 10^{2} = 160$.\n\nFirst, we calculate the degrees of freedom:\n$$df_{\\text{between}} = n - 1 = 20 - 1 = 19$$\n$$df_{\\text{within}} = n(k - 1) = 20(2 - 1) = 20$$\nNext, we calculate the mean squares:\n$$MS_{\\text{between}} = \\frac{SS_{\\text{between}}}{df_{\\text{between}}} = \\frac{1500}{19}$$\n$$MS_{\\text{within}} = \\frac{SS_{\\text{within}}}{df_{\\text{within}}} = \\frac{160}{20} = 8$$\nNow we substitute these mean squares and $k=2$ into the ICC formula:\n$$ICC = \\frac{MS_{\\text{between}} - MS_{\\text{within}}}{MS_{\\text{between}} + (2-1)MS_{\\text{within}}} = \\frac{MS_{\\text{between}} - MS_{\\text{within}}}{MS_{\\text{between}} + MS_{\\text{within}}}$$\nSubstituting the numerical values for the mean squares:\n$$ICC = \\frac{\\frac{1500}{19} - 8}{\\frac{1500}{19} + 8}$$\nTo simplify, we find a common denominator:\n$$ICC = \\frac{\\frac{1500}{19} - \\frac{8 \\times 19}{19}}{\\frac{1500}{19} + \\frac{8 \\times 19}{19}} = \\frac{\\frac{1500 - 152}{19}}{\\frac{1500 + 152}{19}} = \\frac{1348}{1652}$$\nFinally, we compute the decimal value and round to four significant figures:\n$$ICC = \\frac{1348}{1652} \\approx 0.8159806...$$\n$$ICC \\approx 0.8160$$\n\nInterpretation:\nThe computed ICC value of approximately $0.8160$ indicates that about $81.6\\%$ of the total variance in this radiomic feature is due to true systematic differences between subjects, while the remaining $18.4\\%$ is due to measurement error or random within-subject fluctuations. According to common guidelines for interpreting reliability (e.g., Koo & Li, 2016), an ICC value between $0.75$ and $0.90$ is considered to represent \"good\" reliability. A feature with good reliability produces measurements that can distinguish effectively between subjects. Therefore, this feature demonstrates sufficient repeatability to be considered for inclusion in subsequent quantitative modeling, such as building prognostic or predictive models, as it is not overly corrupted by measurement noise. The supplementary information that $SS_{\\text{phantom}} \\approx 0$ confirms that the acquisition system itself is stable, reinforcing the conclusion that the measured within-subject variance is primarily due to factors like patient positioning and physiological state, not equipment instability.",
            "answer": "$$\\boxed{0.8160}$$"
        },
        {
            "introduction": "This next practice takes a step back from summary statistics to work directly with raw measurement data. You will follow the entire analysis pipeline: calculating ANOVA mean squares from a small test-retest dataset and then estimating the ICC. This hands-on calculation in  is designed to reveal a common but counter-intuitive artifact—a negative ICC estimate—forcing you to understand its statistical origin and the appropriate protocol for its interpretation and reporting.",
            "id": "4563299",
            "problem": "A radiomic feature is measured on a test–retest study with $n$ subjects and $k$ repeat scans per subject. The goal is to assess repeatability using the Intraclass Correlation Coefficient (ICC). Consider the one-way random-effects model $x_{ij} = \\mu + s_i + \\varepsilon_{ij}$, where $x_{ij}$ is the feature value for subject $i \\in \\{1,\\dots,n\\}$ at scan $j \\in \\{1,\\dots,k\\}$, $\\mu$ is a fixed mean, $s_i \\sim \\mathcal{N}(0,\\sigma_{s}^{2})$ are independent subject-specific random effects, and $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_{e}^{2})$ are independent measurement errors. The ICC is defined as $\\mathrm{ICC} = \\dfrac{\\sigma_{s}^{2}}{\\sigma_{s}^{2} + \\sigma_{e}^{2}}$.\n\nIn practice, variance components are estimated from one-way analysis of variance (ANOVA) mean squares. Let $\\bar{x}_{i\\cdot}$ be the mean over scans for subject $i$, and $\\bar{x}_{\\cdot\\cdot}$ the grand mean. The between-subject sum of squares is $\\mathrm{SS}_{B} = k \\sum_{i=1}^{n} \\left(\\bar{x}_{i\\cdot} - \\bar{x}_{\\cdot\\cdot}\\right)^{2}$ with degrees of freedom $\\mathrm{df}_{B} = n-1$, and the within-subject sum of squares is $\\mathrm{SS}_{W} = \\sum_{i=1}^{n}\\sum_{j=1}^{k} \\left(x_{ij} - \\bar{x}_{i\\cdot}\\right)^{2}$ with $\\mathrm{df}_{W} = n(k-1)$. The mean squares are $\\mathrm{MS}_{B} = \\mathrm{SS}_{B}/\\mathrm{df}_{B}$ and $\\mathrm{MS}_{W} = \\mathrm{SS}_{W}/\\mathrm{df}_{W}$. The usual unbiased estimators are $\\widehat{\\sigma}_{s}^{2} = \\dfrac{\\mathrm{MS}_{B} - \\mathrm{MS}_{W}}{k}$ and $\\widehat{\\sigma}_{e}^{2} = \\mathrm{MS}_{W}$, yielding $\\widehat{\\mathrm{ICC}} = \\dfrac{\\widehat{\\sigma}_{s}^{2}}{\\widehat{\\sigma}_{s}^{2} + \\widehat{\\sigma}_{e}^{2}}$.\n\nYou observe the following data for $n=3$ subjects with $k=2$ repeat scans:\n- Subject $1$: $x_{11} = 10.1$, $x_{12} = 9.9$\n- Subject $2$: $x_{21} = 10.2$, $x_{22} = 9.8$\n- Subject $3$: $x_{31} = 10.0$, $x_{32} = 10.0$\n\nFrom first principles starting with the model and ANOVA definitions above, compute $\\mathrm{SS}_{B}$, $\\mathrm{SS}_{W}$, $\\mathrm{MS}_{B}$, $\\mathrm{MS}_{W}$, $\\widehat{\\sigma}_{s}^{2}$, $\\widehat{\\sigma}_{e}^{2}$, and $\\widehat{\\mathrm{ICC}}$, and explain why a negative ICC estimate can occur in such a design. Based on statistical principles and radiomics practice with phantom-based validation, choose the single best protocol that explains the occurrence of negative ICC, specifies how to handle it, and justifies whether such features should be excluded from repeatability analysis and subsequent modeling.\n\nA. Negative ICC estimates occur only due to coding errors; the correct response is to delete the subjects producing low variance and exclude the feature entirely from both the repeatability analysis and all subsequent modeling.\n\nB. Negative ICC estimates occur when the estimated between-subject variance component is negative because $\\mathrm{MS}_{B} < \\mathrm{MS}_{W}$ under the one-way random-effects model; the correct response is to impose a non-negativity constraint by setting $\\widehat{\\sigma}_{s}^{2} = 0$ and report $\\widehat{\\mathrm{ICC}} = 0$ with uncertainty (for example, bootstrap confidence intervals), and to cross-validate stability using phantom-based metrics such as coefficient of variation or repeatability coefficient; do not remove the feature from the repeatability analysis report, but filter it out from downstream modeling that requires stable features.\n\nC. Negative ICC estimates indicate “inverse reliability” and should be converted to positive by taking $\\left|\\widehat{\\mathrm{ICC}}\\right|$; phantom validation is unnecessary; the feature should be retained for modeling because magnitude is preserved.\n\nD. Negative ICC estimates arise only when $n$ is very large; the correct response is to log-transform the feature to force a positive ICC and exclude the feature based on an arbitrary threshold such as $\\mathrm{ICC} < 0.75$ regardless of phantom evidence.\n\nE. Negative ICC estimates are uniquely caused by scanner drift; the correct response is to subtract a linear drift from each time series and recompute ICC; retain the feature if phantom scans show low drift, without further consideration of variance components.",
            "solution": "The user has requested a critical validation of the problem statement, a first-principles derivation of the solution, and a detailed evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe givens from the problem statement are:\n-   **Model:** One-way random-effects model, $x_{ij} = \\mu + s_i + \\varepsilon_{ij}$.\n-   **Indices:** $i \\in \\{1,\\dots,n\\}$ for subjects, $j \\in \\{1,\\dots,k\\}$ for repeat scans per subject.\n-   **Data generation process:** $\\mu$ is a fixed mean, $s_i \\sim \\mathcal{N}(0,\\sigma_{s}^{2})$ are independent subject-specific random effects, and $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_{e}^{2})$ are independent measurement errors.\n-   **Definition of ICC:** $\\mathrm{ICC} = \\dfrac{\\sigma_{s}^{2}}{\\sigma_{s}^{2} + \\sigma_{e}^{2}}$.\n-   **ANOVA Quantities:**\n    -   Between-subject sum of squares: $\\mathrm{SS}_{B} = k \\sum_{i=1}^{n} \\left(\\bar{x}_{i\\cdot} - \\bar{x}_{\\cdot\\cdot}\\right)^{2}$ with $\\mathrm{df}_{B} = n-1$.\n    -   Within-subject sum of squares: $\\mathrm{SS}_{W} = \\sum_{i=1}^{n}\\sum_{j=1}^{k} \\left(x_{ij} - \\bar{x}_{i\\cdot}\\right)^{2}$ with $\\mathrm{df}_{W} = n(k-1)$.\n    -   Mean squares: $\\mathrm{MS}_{B} = \\mathrm{SS}_{B}/\\mathrm{df}_{B}$ and $\\mathrm{MS}_{W} = \\mathrm{SS}_{W}/\\mathrm{df}_{W}$.\n-   **Estimators:**\n    -   $\\widehat{\\sigma}_{s}^{2} = \\dfrac{\\mathrm{MS}_{B} - \\mathrm{MS}_{W}}{k}$.\n    -   $\\widehat{\\sigma}_{e}^{2} = \\mathrm{MS}_{W}$.\n    -   $\\widehat{\\mathrm{ICC}} = \\dfrac{\\widehat{\\sigma}_{s}^{2}}{\\widehat{\\sigma}_{s}^{2} + \\widehat{\\sigma}_{e}^{2}}$.\n-   **Data:**\n    -   Number of subjects $n=3$.\n    -   Number of repeat scans $k=2$.\n    -   Subject $1$: $x_{11} = 10.1$, $x_{12} = 9.9$.\n    -   Subject $2$: $x_{21} = 10.2$, $x_{22} = 9.8$.\n    -   Subject $3$: $x_{31} = 10.0$, $x_{32} = 10.0$.\n-   **Task:** Compute $\\mathrm{SS}_{B}$, $\\mathrm{SS}_{W}$, $\\mathrm{MS}_{B}$, $\\mathrm{MS}_{W}$, $\\widehat{\\sigma}_{s}^{2}$, $\\widehat{\\sigma}_{e}^{2}$, and $\\widehat{\\mathrm{ICC}}$. Explain the occurrence of a negative ICC estimate. Select the best protocol for handling this situation.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is evaluated against the criteria for validity:\n-   **Scientifically Grounded:** The problem is firmly grounded in standard statistical theory. The one-way random-effects ANOVA model, the definitions of sums of squares, mean squares, and variance component estimators via the method of moments are all canonical in the field of statistics and are routinely applied to assess reliability with the Intraclass Correlation Coefficient (ICC). The context is radiomics, where such analyses are standard practice.\n-   **Well-Posed:** The problem provides all necessary data and formulas to perform the requested calculations. The question is structured to first require a calculation based on the provided data, followed by an interpretation of the result and an evaluation of practical protocols. It is a well-defined problem in applied statistics.\n-   **Objective:** The problem statement is expressed in precise, objective, mathematical, and statistical language. There are no subjective or opinion-based claims in the setup.\n-   **Flaw Checklist:**\n    1.  **Scientific or Factual Unsoundness:** None. The statistical framework is correct.\n    2.  **Non-Formalizable or Irrelevant:** None. The problem is formal and directly relevant to the topic.\n    3.  **Incomplete or Contradictory Setup:** None. All necessary information is provided.\n    4.  **Unrealistic or Infeasible:** None. The data values are plausible for a biological or physical measurement, and the experimental design ($n=3, k=2$) represents a small but valid pilot study.\n    5.  **Ill-Posed or Poorly Structured:** None. A unique numerical solution exists for the calculation part. The selection of the best protocol is a standard multiple-choice question format assessing expert knowledge.\n    6.  **Pseudo-Profound, Trivial, or Tautological:** None. The problem requires a non-trivial calculation and a deep conceptual understanding of variance component estimation and its pitfalls, particularly the issue of negative variance estimates.\n    7.  **Outside Scientific Verifiability:** None. The computations are verifiable, and the evaluation of protocols is based on established best practices in statistics and radiomics.\n\n**Step 3: Verdict and Action**\nThe problem statement is **valid**. The solution will be derived as requested.\n\n### Derivation and Analysis\n\n**1. Calculation of ANOVA Quantities and ICC**\n\nGiven $n=3$ and $k=2$. The data are:\n-   Subject $1$: $x_{11} = 10.1$, $x_{12} = 9.9$.\n-   Subject $2$: $x_{21} = 10.2$, $x_{22} = 9.8$.\n-   Subject $3$: $x_{31} = 10.0$, $x_{32} = 10.0$.\n\nFirst, we compute the means for each subject:\n-   $\\bar{x}_{1\\cdot} = \\dfrac{10.1 + 9.9}{2} = \\dfrac{20.0}{2} = 10.0$.\n-   $\\bar{x}_{2\\cdot} = \\dfrac{10.2 + 9.8}{2} = \\dfrac{20.0}{2} = 10.0$.\n-   $\\bar{x}_{3\\cdot} = \\dfrac{10.0 + 10.0}{2} = \\dfrac{20.0}{2} = 10.0$.\n\nNext, we compute the grand mean:\n-   $\\bar{x}_{\\cdot\\cdot} = \\dfrac{\\bar{x}_{1\\cdot} + \\bar{x}_{2\\cdot} + \\bar{x}_{3\\cdot}}{n} = \\dfrac{10.0 + 10.0 + 10.0}{3} = 10.0$.\n\nNow, we compute the sums of squares.\n-   **Between-subject sum of squares ($\\mathrm{SS}_{B}$):**\n    $$ \\mathrm{SS}_{B} = k \\sum_{i=1}^{n} (\\bar{x}_{i\\cdot} - \\bar{x}_{\\cdot\\cdot})^{2} = 2 \\left[ (10.0 - 10.0)^{2} + (10.0 - 10.0)^{2} + (10.0 - 10.0)^{2} \\right] = 2[0] = 0.0 $$\n-   The degrees of freedom are $\\mathrm{df}_{B} = n - 1 = 3 - 1 = 2$.\n-   **Between-subject mean square ($\\mathrm{MS}_{B}$):**\n    $$ \\mathrm{MS}_{B} = \\dfrac{\\mathrm{SS}_{B}}{\\mathrm{df}_{B}} = \\dfrac{0.0}{2} = 0.0 $$\n-   **Within-subject sum of squares ($\\mathrm{SS}_{W}$):**\n    $$ \\mathrm{SS}_{W} = \\sum_{i=1}^{n}\\sum_{j=1}^{k} (x_{ij} - \\bar{x}_{i\\cdot})^{2} $$\n    $$ \\mathrm{SS}_{W} = [(10.1-10.0)^2 + (9.9-10.0)^2] + [(10.2-10.0)^2 + (9.8-10.0)^2] + [(10.0-10.0)^2 + (10.0-10.0)^2] $$\n    $$ \\mathrm{SS}_{W} = [(0.1)^2 + (-0.1)^2] + [(0.2)^2 + (-0.2)^2] + [0^2 + 0^2] $$\n    $$ \\mathrm{SS}_{W} = [0.01 + 0.01] + [0.04 + 0.04] + [0] = 0.02 + 0.08 = 0.10 $$\n-   The degrees of freedom are $\\mathrm{df}_{W} = n(k-1) = 3(2-1) = 3$.\n-   **Within-subject mean square ($\\mathrm{MS}_{W}$):**\n    $$ \\mathrm{MS}_{W} = \\dfrac{\\mathrm{SS}_{W}}{\\mathrm{df}_{W}} = \\dfrac{0.10}{3} $$\n\nNow we compute the estimates of the variance components.\n-   **Estimate of error variance ($\\widehat{\\sigma}_{e}^{2}$):**\n    $$ \\widehat{\\sigma}_{e}^{2} = \\mathrm{MS}_{W} = \\dfrac{0.10}{3} \\approx 0.0333 $$\n-   **Estimate of subject variance ($\\widehat{\\sigma}_{s}^{2}$):**\n    $$ \\widehat{\\sigma}_{s}^{2} = \\dfrac{\\mathrm{MS}_{B} - \\mathrm{MS}_{W}}{k} = \\dfrac{0.0 - \\dfrac{0.10}{3}}{2} = \\dfrac{-0.10/3}{2} = -\\dfrac{0.10}{6} = -\\dfrac{0.05}{3} \\approx -0.0167 $$\n\nFinally, we compute the estimate of the ICC.\n-   **Estimate of ICC ($\\widehat{\\mathrm{ICC}}$):**\n    $$ \\widehat{\\mathrm{ICC}} = \\dfrac{\\widehat{\\sigma}_{s}^{2}}{\\widehat{\\sigma}_{s}^{2} + \\widehat{\\sigma}_{e}^{2}} = \\dfrac{-\\dfrac{0.10}{6}}{-\\dfrac{0.10}{6} + \\dfrac{0.10}{3}} = \\dfrac{-\\dfrac{0.10}{6}}{-\\dfrac{0.10}{6} + \\dfrac{0.20}{6}} = \\dfrac{-\\dfrac{0.10}{6}}{\\dfrac{0.10}{6}} = -1.0 $$\n\n**2. Explanation of Negative ICC Estimate**\n\nA negative ICC estimate, such as the $\\widehat{\\mathrm{ICC}} = -1.0$ computed here, is a known artifact of the ANOVA method-of-moments estimation for variance components.\n-   The true variance components, $\\sigma_{s}^{2}$ and $\\sigma_{e}^{2}$, are by definition non-negative. Therefore, the true ICC, $\\dfrac{\\sigma_{s}^{2}}{\\sigma_{s}^{2} + \\sigma_{e}^{2}}$, must be in the range $[0, 1]$.\n-   The estimator for the between-subject variance is $\\widehat{\\sigma}_{s}^{2} = (\\mathrm{MS}_{B} - \\mathrm{MS}_{W})/k$. While the expected values are $E[\\mathrm{MS}_{B}] = k\\sigma_{s}^{2} + \\sigma_{e}^{2}$ and $E[\\mathrm{MS}_{W}] = \\sigma_e^2$, making $\\widehat{\\sigma}_{s}^{2}$ an unbiased estimator of $\\sigma_s^2$, the sample statistics $\\mathrm{MS}_{B}$ and $\\mathrm{MS}_{W}$ are random variables.\n-   Due to sampling variability, it is possible for the observed value of $\\mathrm{MS}_{B}$ to be less than the observed value of $\\mathrm{MS}_{W}$. This is particularly likely to happen when the true between-subject variance $\\sigma_s^2$ is very small or zero, and/or when the sample size $n$ is small.\n-   When $\\mathrm{MS}_{B} < \\mathrm{MS}_{W}$, the estimator $\\widehat{\\sigma}_{s}^{2}$ becomes negative. Since $\\widehat{\\sigma}_{s}^{2}$ appears in both the numerator and denominator of $\\widehat{\\mathrm{ICC}}$, a negative value for $\\widehat{\\sigma}_{s}^{2}$ can lead to a negative $\\widehat{\\mathrm{ICC}}$.\n-   In the given dataset, the between-subject variability was observed to be exactly zero ($\\bar{x}_{1\\cdot} = \\bar{x}_{2\\cdot} = \\bar{x}_{3\\cdot}$), resulting in $\\mathrm{MS}_{B} = 0$. Since there was non-zero within-subject variability ($\\mathrm{MS}_{W} > 0$), we have $\\mathrm{MS}_{B} < \\mathrm{MS}_{W}$, leading to $\\widehat{\\sigma}_{s}^{2} < 0$ and consequently $\\widehat{\\mathrm{ICC}} < 0$. This indicates that the observed variability within subjects is greater than the variability between subjects.\n\n**3. Evaluation of Options**\n\n**A. Negative ICC estimates occur only due to coding errors; the correct response is to delete the subjects producing low variance and exclude the feature entirely from both the repeatability analysis and all subsequent modeling.**\nThis statement is fundamentally flawed. The claim that negative ICCs arise \"only due to coding errors\" is false; they are a well-understood statistical artifact. The proposed response to delete data (\"delete the subjects producing low variance\") is an unscientific practice that introduces bias. Excluding the feature may be a final outcome, but the reasoning provided is incorrect.\n**Verdict: Incorrect.**\n\n**B. Negative ICC estimates occur when the estimated between-subject variance component is negative because $\\mathrm{MS}_{B} < \\mathrm{MS}_{W}$ under the one-way random-effects model; the correct response is to impose a non-negativity constraint by setting $\\widehat{\\sigma}_{s}^{2} = 0$ and report $\\widehat{\\mathrm{ICC}} = 0$ with uncertainty (for example, bootstrap confidence intervals), and to cross-validate stability using phantom-based metrics such as coefficient of variation or repeatability coefficient; do not remove the feature from the repeatability analysis report, but filter it out from downstream modeling that requires stable features.**\nThis option presents a comprehensive and statistically sound protocol. It correctly identifies the cause ($\\mathrm{MS}_{B} < \\mathrm{MS}_{W}$). The standard procedure for handling a negative variance estimate is to truncate it at zero ($\\widehat{\\sigma}_{s}^{2} = 0$), which implies $\\widehat{\\mathrm{ICC}} = 0$. This reflects that the data are most consistent with zero between-subject variance. Crucially, it recommends reporting the result with uncertainty (e.g., via a confidence interval, which will likely span negative values) for transparency. It correctly integrates the radiomics-specific practice of using phantom studies for validation of technical stability. Finally, it makes the correct distinction between reporting the feature in the repeatability analysis (for completeness) and filtering it from subsequent modeling (as it carries no reliable information).\n**Verdict: Correct.**\n\n**C. Negative ICC estimates indicate “inverse reliability” and should be converted to positive by taking $\\left|\\widehat{\\mathrm{ICC}}\\right|$; phantom validation is unnecessary; the feature should be retained for modeling because magnitude is preserved.**\nThe term \"inverse reliability\" has no meaning in this context. Taking the absolute value is an arbitrary and unjustifiable mathematical manipulation. In our case, it would change $\\widehat{\\mathrm{ICC}} = -1.0$ to $\\widehat{\\mathrm{ICC}} = 1.0$, falsely suggesting perfect reliability, which is the opposite of what the data indicate. Disregarding phantom validation is poor practice in radiomics.\n**Verdict: Incorrect.**\n\n**D. Negative ICC estimates arise only when $n$ is very large; the correct response is to log-transform the feature to force a positive ICC and exclude the feature based on an arbitrary threshold such as $\\mathrm{ICC} < 0.75$ regardless of phantom evidence.**\nThis option contains multiple falsehoods. Negative ICC estimates are more, not less, common with small sample sizes $n$ due to higher sampling variability. A log-transform is not a guaranteed fix for a negative ICC and its application should be theoretically motivated (e.g., to stabilize variance or achieve normality), not as an ad-hoc fix for an estimator's sign. Using an arbitrary cutoff without considering uncertainty or other evidence (like phantom data) is a simplistic and often misleading approach.\n**Verdict: Incorrect.**\n\n**E. Negative ICC estimates are uniquely caused by scanner drift; the correct response is to subtract a linear drift from each time series and recompute ICC; retain the feature if phantom scans show low drift, without further consideration of variance components.**\nThe cause is incorrectly identified as \"uniquely\" scanner drift. The problem is fundamentally with the statistical estimator. While scanner drift can increase within-subject variance ($\\mathrm{MS}_{W}$), it is not the sole or necessary cause. The proposed solution is a specific pre-processing step for a specific artifact (drift), not a general solution for negative ICCs. Ignoring the variance components is nonsensical as they are the basis of the ICC calculation.\n**Verdict: Incorrect.**",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "Our final exercise brings together all the concepts into a computational simulation, a powerful method for phantom-based validation in radiomics. In this task, you will implement a model of test-retest imaging to generate data, extract a suite of first-order features, and systematically assess their stability against noise using the ICC. This comprehensive practice  mirrors a real-world research workflow for identifying robust features suitable for clinical applications.",
            "id": "4563232",
            "problem": "You are tasked with designing a program that simulates test-retest acquisitions of simple phantom regions to evaluate the repeatability of first-order histogram radiomic features under controlled additive noise. The objective is to compute, for each test case, how many features maintain a high Intraclass Correlation Coefficient (ICC) and thus can be considered robust. Your program must implement the simulation and feature computation strictly from first principles.\n\nStart from the following fundamental base:\n\n- For an image with pixel intensities $\\{x_1, x_2, \\dots, x_N\\}$, define the sample mean as $ \\mu = \\frac{1}{N}\\sum_{i=1}^{N} x_i $, the sample variance as $ s^2 = \\frac{1}{N-1}\\sum_{i=1}^{N}(x_i - \\mu)^2 $, and the sample standard deviation as $ s = \\sqrt{s^2} $. Define central moments of order $r$ as $ m_r = \\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\mu)^r $. The skewness is $ \\gamma_1 = \\frac{m_3}{s^3} $ and the kurtosis is $ \\gamma_2 = \\frac{m_4}{s^4} $ when $ s \\neq 0 $, and set $ \\gamma_1 = 0 $ and $ \\gamma_2 = 0 $ when $ s = 0 $ to avoid division by zero.\n- For a histogram with $B$ bins with counts $\\{h_1, h_2, \\dots, h_B\\}$ over a fixed intensity range, the empirical probability mass function is $ p_b = \\frac{h_b}{\\sum_{j=1}^{B} h_j} $ for each bin $b$. The Shannon entropy (natural logarithm) is $ H = -\\sum_{b=1}^{B} p_b \\ln(p_b) $ over bins with $ p_b > 0 $. The intensity energy is defined as $ E = \\frac{1}{N}\\sum_{i=1}^{N} x_i^2 $.\n- Quantiles at fractions $ q \\in [0,1] $ are defined as values $ Q(q) $ such that a fraction $ q $ of the data is less than or equal to $ Q(q) $. In particular, compute $ Q(0.5) $ (the median), $ Q(0.1) $, and $ Q(0.9) $.\n\nModel the test-retest imaging process of $n$ independent phantom regions, each a two-dimensional array of size $H \\times W$ with a uniform base intensity $ I_i $ drawn uniformly from the interval $[I_{\\min}, I_{\\max}]$. Model $k$ repeated acquisitions per region by adding independent, identically distributed additive Gaussian noise with zero mean and standard deviation $\\sigma$ to each pixel. Clip intensities to the interval $[0, 255]$ to maintain physical plausibility of gray-level values.\n\nFor each acquisition, compute the following first-order histogram features on the full image:\n- The mean $ \\mu $.\n- The variance $ s^2 $.\n- The standard deviation $ s $.\n- The skewness $ \\gamma_1 $.\n- The kurtosis $ \\gamma_2 $.\n- The intensity energy $ E $.\n- The Shannon entropy $ H $ using a histogram with $B$ bins over $[0, 255]$.\n- The median $ Q(0.5) $.\n- The quantile $ Q(0.1) $.\n- The quantile $ Q(0.9) $.\n\nTo quantify test-retest repeatability across subjects, use the one-way random effects Intraclass Correlation Coefficient (ICC) for single measurements, denoted as $ \\mathrm{ICC}(1,1) $. Consider $x_{ij}$ to be the feature measurement for subject $i \\in \\{1,\\dots,n\\}$ at repeat $j \\in \\{1,\\dots,k\\}$. Let $ \\bar{x}_i = \\frac{1}{k}\\sum_{j=1}^{k} x_{ij} $ be the mean for subject $i$ and $ \\bar{x} = \\frac{1}{nk}\\sum_{i=1}^{n}\\sum_{j=1}^{k} x_{ij} $ be the grand mean. Define the between-subject mean square\n$$ \\mathrm{BMS} = \\frac{k}{n-1} \\sum_{i=1}^{n} \\left( \\bar{x}_i - \\bar{x} \\right)^2, $$\nand the within-subject mean square\n$$ \\mathrm{WMS} = \\frac{1}{n(k-1)} \\sum_{i=1}^{n} \\sum_{j=1}^{k} \\left( x_{ij} - \\bar{x}_i \\right)^2. $$\nThen compute\n$$ \\mathrm{ICC}(1,1) = \\frac{\\mathrm{BMS} - \\mathrm{WMS}}{\\mathrm{BMS} + (k-1)\\,\\mathrm{WMS}}. $$\n\nA feature is deemed robust in a given test case if $ \\mathrm{ICC}(1,1) \\ge \\tau $, where $ \\tau $ is a specified threshold expressed as a decimal.\n\nImplement a deterministic program that, for each test case in the provided test suite, performs the simulation and computes the number of robust features among the ten listed above. The random number generation must be seeded to ensure reproducibility.\n\nTest Suite:\n- Case $1$: $n = 12$, $k = 3$, $H = 64$, $W = 64$, $I_{\\min} = 80$, $I_{\\max} = 120$, $\\sigma = 2$, $B = 64$, $\\tau = 0.85$.\n- Case $2$: $n = 12$, $k = 3$, $H = 64$, $W = 64$, $I_{\\min} = 80$, $I_{\\max} = 120$, $\\sigma = 15$, $B = 64$, $\\tau = 0.85$.\n- Case $3$: $n = 8$, $k = 2$, $H = 32$, $W = 32$, $I_{\\min} = 80$, $I_{\\max} = 120$, $\\sigma = 40$, $B = 64$, $\\tau = 0.85$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the integer count of robust features for the corresponding test case, in the order listed above (e.g., $[c_1,c_2,c_3]$).",
            "solution": "The problem statement poses a valid and well-defined task in the field of radiomics, specifically concerning the phantom-based validation of feature repeatability. The problem is scientifically grounded, employing standard statistical definitions for image features and for the Intraclass Correlation Coefficient (ICC). All parameters for the simulation are explicitly provided, and the task is to implement a deterministic simulation, which is achievable by seeding the random number generator. The problem is free of contradictions, ambiguities, and non-scientific claims. It represents a standard, albeit simplified, procedure for evaluating the robustness of radiomic features against noise, a critical step in qualifying them for clinical use.\n\nWe will proceed with a full solution. The methodology involves three primary stages:\n1.  **Simulation of Image Data**: For each test case, we generate a set of phantom images according to the specified model. This involves creating $n$ distinct phantom regions, each characterized by a uniform base intensity $I_i$. For each region, we simulate $k$ repeated acquisitions by adding independent Gaussian noise and clipping the resulting pixel intensities.\n2.  **Feature Extraction**: From each simulated image, we compute a panel of ten first-order radiomic features. These features are calculated strictly according to the mathematical definitions provided.\n3.  **Repeatability Analysis**: For each of the ten features, we use the collected data across all $n$ subjects and $k$ repeats to calculate the Intraclass Correlation Coefficient, $\\mathrm{ICC}(1,1)$. We then compare this value to a given threshold $\\tau$ to determine if the feature is robust. The final output for each test case is the total count of robust features.\n\nLet us formalize the step-by-step procedure.\n\nFirst, we set a global seed for the pseudo-random number generator to ensure the entire simulation is deterministic and reproducible. Let the total number of pixels in an image be $N = H \\times W$.\n\nFor each test case with parameters $(n, k, H, W, I_{\\min}, I_{\\max}, \\sigma, B, \\tau)$:\n\n**1. Data Generation**\n\nWe generate a data structure to hold the feature values, which can be visualized as ten distinct matrices, each of size $n \\times k$. Let $F_{l,i,j}$ be the value of the $l$-th feature (for $l \\in \\{1, \\dots, 10\\}$) for subject $i \\in \\{1, \\dots, n\\}$ and repeat acquisition $j \\in \\{1, \\dots, k\\}$.\n\nThe simulation proceeds as follows:\nFor each subject $i$ from $1$ to $n$:\na.  Draw a single base intensity value $I_i$ from a uniform distribution over the interval $[I_{\\min}, I_{\\max}]$.\nb.  For each repeat acquisition $j$ from $1$ to $k$:\n    i.   Generate an $H \\times W$ matrix of noise values, $\\epsilon$, where each element is drawn independently from a Gaussian distribution with mean $0$ and standard deviation $\\sigma$.\n    ii.  Construct the simulated image matrix, $X_{ij}$, by adding the noise to the base intensity: $X_{ij} = I_i + \\epsilon$.\n    iii. Clip all pixel values in $X_{ij}$ to the valid intensity range of $[0, 255]$.\n    iv.  Flatten the $H \\times W$ image matrix $X_{ij}$ into a one-dimensional vector of $N$ pixel intensities, $\\{x_1, x_2, \\dots, x_N\\}$.\n    v.   Compute the ten radiomic features from this vector and store them.\n\n**2. Feature Computation**\n\nFor each vector of pixel intensities $\\{x_1, x_2, \\dots, x_N\\}$, the ten features are calculated:\n\n-   **Mean ($\\mu$)**: $\\mu = \\frac{1}{N}\\sum_{p=1}^{N} x_p$.\n-   **Variance ($s^2$)**: $s^2 = \\frac{1}{N-1}\\sum_{p=1}^{N}(x_p - \\mu)^2$.\n-   **Standard Deviation ($s$)**: $s = \\sqrt{s^2}$.\n-   **Central Moments ($m_r$)**: $m_r = \\frac{1}{N}\\sum_{p=1}^{N}(x_p - \\mu)^r$.\n-   **Skewness ($\\gamma_1$)**: $\\gamma_1 = m_3 / s^3$. If $s=0$, then $\\gamma_1=0$.\n-   **Kurtosis ($\\gamma_2$)**: $\\gamma_2 = m_4 / s^4$. If $s=0$, then $\\gamma_2=0$.\n-   **Energy ($E$)**: $E = \\frac{1}{N}\\sum_{p=1}^{N} x_p^2$.\n-   **Shannon Entropy ($H$)**: A histogram with $B$ bins is constructed for the intensity values over the range $[0, 255]$. Let the counts in each bin be $\\{h_1, \\dots, h_B\\}$. The probability for bin $b$ is $p_b = h_b / N$. The entropy is $H = -\\sum_{b=1}^{B} p_b \\ln(p_b)$, where the sum is over bins with $p_b > 0$.\n-   **Quantiles ($Q(q)$)**: The data is sorted, and the values $Q(0.1)$, $Q(0.5)$ (median), and $Q(0.9)$ are computed.\n\n**3. ICC Calculation and Robustness Assessment**\n\nAfter populating the feature matrices, we analyze each feature one by one. For a given feature $l$, we have the $n \\times k$ matrix of measurements $x_{ij} = F_{l,i,j}$.\n\na.  Calculate the mean measurement for each subject: $\\bar{x}_i = \\frac{1}{k}\\sum_{j=1}^{k} x_{ij}$.\nb.  Calculate the grand mean over all measurements: $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} \\bar{x}_i = \\frac{1}{nk}\\sum_{i=1}^{n}\\sum_{j=1}^{k} x_{ij}$.\nc.  Compute the Between-Subject Mean Square (BMS):\n    $$ \\mathrm{BMS} = \\frac{k}{n-1} \\sum_{i=1}^{n} \\left( \\bar{x}_i - \\bar{x} \\right)^2 $$\nd.  Compute the Within-Subject Mean Square (WMS):\n    $$ \\mathrm{WMS} = \\frac{1}{n(k-1)} \\sum_{i=1}^{n} \\sum_{j=1}^{k} \\left( x_{ij} - \\bar{x}_i \\right)^2 $$\n    These terms quantify the variance between different subjects and the variance within the repeated measurements of the same subject, respectively.\ne.  Calculate the Intraclass Correlation Coefficient for single measurements, $\\mathrm{ICC}(1,1)$:\n    $$ \\mathrm{ICC}(1,1) = \\frac{\\mathrm{BMS} - \\mathrm{WMS}}{\\mathrm{BMS} + (k-1)\\,\\mathrm{WMS}} $$\n    A high ICC value, approaching $1$, indicates that the variability between subjects (BMS) is much larger than the variability from repeated measurements (WMS), signifying good repeatability.\nf.  A feature is classified as robust if $\\mathrm{ICC}(1,1) \\ge \\tau$.\ng.  We count the total number of robust features for the test case. This count is the result for that case.\n\nThis complete process is repeated for each of the three test cases provided in the problem statement. The final output is a list containing the integer counts of robust features for each case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print the results.\n    \"\"\"\n    # Seed the random number generator for deterministic and reproducible results.\n    np.random.seed(0)\n\n    # Test Suite\n    test_cases = [\n        {'n': 12, 'k': 3, 'H': 64, 'W': 64, 'I_min': 80, 'I_max': 120, 'sigma': 2, 'B': 64, 'tau': 0.85},\n        {'n': 12, 'k': 3, 'H': 64, 'W': 64, 'I_min': 80, 'I_max': 120, 'sigma': 15, 'B': 64, 'tau': 0.85},\n        {'n': 8, 'k': 2, 'H': 32, 'W': 32, 'I_min': 80, 'I_max': 120, 'sigma': 40, 'B': 64, 'tau': 0.85},\n    ]\n\n    results = []\n    for case_params in test_cases:\n        robust_count = run_simulation_and_analysis(**case_params)\n        results.append(robust_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef compute_features(pixels, num_bins):\n    \"\"\"\n    Computes all 10 first-order radiomic features from a 1D array of pixel intensities.\n    \"\"\"\n    N = len(pixels)\n    if N == 0:\n        return [0.0] * 10\n\n    # Mean, Variance, Std Dev\n    mu = np.mean(pixels)\n    # The problem defines sample variance with N-1, which is ddof=1 in numpy.\n    s2 = np.var(pixels, ddof=1) if N > 1 else 0.0\n    s = np.sqrt(s2)\n\n    # Skewness and Kurtosis from first principles\n    if s > 0:\n        # Central moments are defined with 1/N\n        m3_term = np.sum((pixels - mu)**3) / N\n        m4_term = np.sum((pixels - mu)**4) / N\n        skewness = m3_term / (s**3)\n        kurtosis = m4_term / (s**4)\n    else:\n        skewness = 0.0\n        kurtosis = 0.0\n\n    # Intensity Energy\n    energy = np.mean(pixels**2)\n\n    # Shannon Entropy\n    # Histogram range is fixed to [0, 255] as per problem context.\n    hist, _ = np.histogram(pixels, bins=num_bins, range=(0, 255))\n    probs = hist / N\n    # Sum over bins with non-zero probability\n    entropy = -np.sum(probs[probs > 0] * np.log(probs[probs > 0]))\n\n    # Quantiles\n    q10 = np.quantile(pixels, 0.1)\n    median = np.quantile(pixels, 0.5)\n    q90 = np.quantile(pixels, 0.9)\n\n    return [\n        mu, s2, s, skewness, kurtosis, energy, entropy, median, q10, q90\n    ]\n\ndef calculate_icc11(feature_matrix, k):\n    \"\"\"\n    Calculates ICC(1,1) from an n x k matrix of feature measurements.\n    \"\"\"\n    n, k_check = feature_matrix.shape\n    if k_check != k:\n        raise ValueError(\"Matrix dimensions do not match k.\")\n\n    if n <= 1 or k <= 1:\n        # ICC is not well-defined for n<=1 or k<=1. The formulas would involve division by zero.\n        return 0.0\n\n    # Means\n    grand_mean = np.mean(feature_matrix)\n    subject_means = np.mean(feature_matrix, axis=1)\n\n    # Between-Subject Mean Square (BMS)\n    bms = (k / (n - 1)) * np.sum((subject_means - grand_mean)**2)\n\n    # Within-Subject Mean Square (WMS)\n    wms_sum_sq = np.sum((feature_matrix - subject_means[:, np.newaxis])**2)\n    wms = wms_sum_sq / (n * (k - 1))\n\n    # ICC(1,1)\n    denominator = bms + (k - 1) * wms\n    if denominator < 1e-9: # Avoid division by zero, handle case of no variance\n        # If both BMS and WMS are zero, all measurements are identical.\n        # If BMS is zero but WMS is not, it implies negative ICC.\n        # If WMS is zero but BMS is not, it implies perfect correlation ICC=1.\n        return 1.0 if bms > wms else 0.0\n    \n    icc = (bms - wms) / denominator\n    return icc\n\ndef run_simulation_and_analysis(n, k, H, W, I_min, I_max, sigma, B, tau):\n    \"\"\"\n    Performs the full simulation, feature extraction, and repeatability analysis for one test case.\n    \"\"\"\n    num_features = 10\n    # feature_data will be a list of 10 numpy arrays, each of shape (n, k)\n    feature_data = [np.zeros((n, k)) for _ in range(num_features)]\n    \n    num_pixels = H * W\n\n    # Generate base intensities for all subjects at once\n    base_intensities = np.random.uniform(I_min, I_max, size=n)\n\n    for i in range(n):\n        base_I = base_intensities[i]\n        for j in range(k):\n            # Create perfect image and add noise\n            noise = np.random.normal(loc=0.0, scale=sigma, size=(H, W))\n            image = base_I + noise\n            \n            # Clip intensities to [0, 255] and flatten\n            image = np.clip(image, 0, 255)\n            pixels = image.flatten()\n\n            # Compute and store features\n            features = compute_features(pixels, B)\n            for feat_idx in range(num_features):\n                feature_data[feat_idx][i, j] = features[feat_idx]\n\n    # Analyze repeatability for each feature\n    robust_feature_count = 0\n    for feat_idx in range(num_features):\n        icc_value = calculate_icc11(feature_data[feat_idx], k)\n        if icc_value >= tau:\n            robust_feature_count += 1\n            \n    return robust_feature_count\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}