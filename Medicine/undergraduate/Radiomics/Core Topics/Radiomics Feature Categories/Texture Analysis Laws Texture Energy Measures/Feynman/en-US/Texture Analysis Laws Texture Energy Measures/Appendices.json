{
    "hands_on_practices": [
        {
            "introduction": "A cornerstone of texture analysis is differentiating textured regions from uniform ones. Laws' high-pass filters are specifically designed to have a zero response in areas of constant intensity, a property stemming from their zero-sum construction. This exercise provides a practical, code-based approach to verify this fundamental principle, allowing you to build and test filters to see this behavior firsthand and understand how even minor errors can be detected .",
            "id": "4565057",
            "problem": "In radiomics texture analysis, Laws' texture energy measures rely on convolving an image with separable high-pass masks derived from one-dimensional Laws vectors, followed by computing an energy summary statistic. A foundational property of high-pass masks is that the sum of all mask coefficients is zero. Consequently, when such a mask is convolved with a constant image, the response should be near zero everywhere except at boundaries, which can be eliminated by using the valid convolution region. This property can be used to numerically detect preprocessing errors such as incorrect normalization or unintended offsets.\n\nStarting from these fundamental bases:\n- The definition of two-dimensional (2D) discrete convolution between a discrete image $I$ and a discrete filter $H$,\n$$\n(I * H)[i,j] \\;=\\; \\sum_{p}\\sum_{q} I[i - p, j - q]\\, H[p, q],\n$$\nwith sums taken over the finite support of $H$.\n- The standard Laws one-dimensional (1D) vectors of length $5$, given by\n$$\nL_5 = [\\,1,\\,4,\\,6,\\,4,\\,1\\,],\\quad\nE_5 = [\\,-1,\\,-2,\\,0,\\,2,\\,1\\,],\\quad\nS_5 = [\\,-1,\\,0,\\,2,\\,0,\\,-1\\,],\n$$\n$$\nW_5 = [\\,-1,\\,2,\\,0,\\,-2,\\,1\\,],\\quad\nR_5 = [\\,1,\\,-4,\\,6,\\,-4,\\,1\\,],\n$$\nand the construction of 2D separable masks by the outer product of two 1D vectors,\n$$\nH \\;=\\; u\\, v^{\\top},\n$$\nwhere $u \\in \\{L_5, E_5, S_5, W_5, R_5\\}$ and $v \\in \\{L_5, E_5, S_5, W_5, R_5\\}$.\n\nYour task is to implement a program that, for a given small test suite of such masks and constant images, numerically verifies the following two criteria for each test case:\n- Zero-sum property: the absolute sum of all mask coefficients is less than or equal to a specified tolerance $\\tau_s$.\n- Near-zero response on constant images: when convolving a constant image $I[i,j] = c$ with the mask using valid convolution, the texture energy defined as the mean absolute response,\n$$\nTE(I,H) \\;=\\; \\frac{1}{M} \\sum_{(i,j)\\in \\Omega_{\\text{valid}}} \\big| (I * H)[i,j] \\big|,\n$$\nis less than or equal to a specified tolerance $\\tau_e$, where $\\Omega_{\\text{valid}}$ denotes the valid convolution region and $M$ is its cardinality.\n\nFor each test case, output a boolean value that is true if and only if both of the above criteria are satisfied. The program must construct the indicated 2D mask $H$ by the specified outer product, optionally scale it by a scalar factor, and optionally perturb a single coefficient by a small additive value to simulate a preprocessing error. Then, it must convolve $H$ with a constant image of specified size and constant level $c$, compute $TE(I,H)$ over the valid region, and evaluate both criteria.\n\nImplement the following test suite. Each test case specifies:\n- The row vector $u$ and column vector $v$ selected from $\\{L_5, E_5, S_5, W_5, R_5\\}$,\n- A scaling factor $s$ to multiply the mask,\n- An optional perturbation triplet $(i_p, j_p, \\delta)$ indicating that $\\delta$ should be added to the single mask entry at row index $i_p$ and column index $j_p$ (zero-based indexing) after scaling,\n- The image size $N$ for an $N \\times N$ constant image,\n- The image constant level $c$,\n- Tolerances $\\tau_s$ and $\\tau_e$.\n\nUse the following six test cases:\n1. $u = E_5$, $v = L_5$, $s = 1.0$, no perturbation, $N = 64$, $c = 7.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n2. $u = L_5$, $v = L_5$, $s = 1.0$, no perturbation, $N = 32$, $c = 2.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n3. $u = W_5$, $v = S_5$, $s = 3.0$, no perturbation, $N = 48$, $c = 5.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n4. $u = E_5$, $v = S_5$, $s = 1.0$, perturbation $(i_p, j_p, \\delta) = (2, 2, 10^{-6})$, $N = 40$, $c = 1.0$, $\\tau_s = 10^{-8}$, $\\tau_e = 10^{-8}$.\n5. $u = R_5$, $v = R_5$, $s = 1.0$, no perturbation, $N = 5$, $c = 10.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n6. $u = L_5$, $v = E_5$, $s = 1.0$, no perturbation, $N = 64$, $c = 3.0$, $\\tau_s = 10^{-12}$, $\\tau_e = 10^{-12}$.\n\nImplementation details:\n- Construct $H = s \\cdot (u\\, v^{\\top})$, then apply the optional perturbation if specified.\n- Perform 2D convolution using valid convolution to avoid boundary effects; only the valid portion contributes to $TE(I,H)$.\n- All computations are dimensionless; no physical units are required.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_6]$), where each $result_k$ is a boolean corresponding to test case $k$ in order.",
            "solution": "The problem requires the numerical verification of fundamental properties of Laws' texture masks, specifically their behavior when applied to constant images. The solution involves implementing an algorithm based on the principles of digital signal processing and linear algebra.\n\nThe foundation of Laws' method lies in a set of one-dimensional (1D) vectors of length $5$. The problem provides the standard set:\n$$L_5 = [\\,1,\\,4,\\,6,\\,4,\\,1\\,]$$\n$$E_5 = [\\,-1,\\,-2,\\,0,\\,2,\\,1\\,]$$\n$$S_5 = [\\,-1,\\,0,\\,2,\\,0,\\,-1\\,]$$\n$$W_5 = [\\,-1,\\,2,\\,0,\\,-2,\\,1\\,]$$\n$$R_5 = [\\,1,\\,-4,\\,6,\\,-4,\\,1\\,]$$\n\nThese vectors can be classified based on their filtering characteristics. The vector $L_5$ (Level) is a low-pass averaging filter. The other four vectors—$E_5$ (Edge), $S_5$ (Spot), $W_5$ (Wave), and $R_5$ (Ripple)—are high-pass or band-pass filters designed to detect specific textural primitives. A defining characteristic of these high-pass filters is that the sum of their coefficients is zero. This can be verified by direct summation:\n$\\sum E_5 = -1 - 2 + 0 + 2 + 1 = 0$\n$\\sum S_5 = -1 + 0 + 2 + 0 - 1 = 0$\n$\\sum W_5 = -1 + 2 + 0 - 2 + 1 = 0$\n$\\sum R_5 = 1 - 4 + 6 - 4 + 1 = 0$\nIn contrast, the low-pass filter $L_5$ does not have this property: $\\sum L_5 = 1 + 4 + 6 + 4 + 1 = 16$.\n\nTwo-dimensional (2D) separable masks $H$ are constructed by taking the outer product of two 1D vectors, $u$ and $v$:\n$$H = u v^\\top$$\nThe sum of all coefficients in the resulting 2D mask $H$ can be expressed as:\n$$\\sum_{i,j} H[i, j] = \\sum_{i,j} u[i] v[j] = \\left(\\sum_i u[i]\\right) \\left(\\sum_j v[j]\\right)$$\nThis identity shows that the 2D mask $H$ is a zero-sum mask if at least one of its constituent 1D vectors, $u$ or $v$, is zero-sum. Therefore, any mask constructed with at least one vector from $\\{E_5, S_5, W_5, R_5\\}$ will be a zero-sum mask. The only combination that results in a non-zero-sum mask is $L_5 L_5^\\top$.\n\nThe core principle to be verified is the response of these masks to a constant input. Consider a discrete image $I$ that is constant everywhere, i.e., $I[i,j] = c$ for some constant $c$. The 2D convolution of $I$ with a mask $H$ is given by:\n$$(I * H)[i,j] = \\sum_{p}\\sum_{q} I[i - p, j - q] H[p, q]$$\nSince $I$ is constant, $I[i - p, j - q] = c$ for all $p, q$. Thus, the expression simplifies:\n$$(I * H)[i,j] = \\sum_{p}\\sum_{q} c \\, H[p, q] = c \\left(\\sum_{p,q} H[p, q]\\right)$$\nIf $H$ is a zero-sum mask, then $\\sum_{p,q} H[p, q] = 0$, and the result of the convolution is $(I * H)[i, j] = c \\cdot 0 = 0$ for all output pixels $(i,j)$. This is true for the 'valid' convolution region, where the kernel $H$ is fully contained within the image, thereby avoiding any boundary effects.\n\nThe problem asks for numerical verification of this property, which requires two checks to account for floating-point inaccuracies and potential introduced errors.\n\n**Criterion 1: Zero-sum property of the mask.**\nThis check directly verifies if the constructed mask $H$ is zero-sum, within a given numerical tolerance $\\tau_s$. A mask might be perturbed, for instance by adding a small value $\\delta$ to one of its coefficients. The check is:\n$$\\left| \\sum_{i,j} H[i, j] \\right| \\le \\tau_s$$\nIf a mask is formed from at least one zero-sum vector and is not perturbed, its sum will be exactly $0$ in ideal arithmetic. In floating-point computation, this sum should be extremely close to $0$. A non-zero-sum mask (like $L_5 L_5^\\top$) or a perturbed zero-sum mask will likely fail this check if the resulting sum exceeds the tolerance.\n\n**Criterion 2: Near-zero response on a constant image.**\nThis check verifies the ultimate consequence of the zero-sum property. The texture energy, $TE(I,H)$, is defined as the mean absolute response in the valid convolution region $\\Omega_{\\text{valid}}$:\n$$TE(I,H) = \\frac{1}{M} \\sum_{(i,j)\\in \\Omega_{\\text{valid}}} \\big| (I * H)[i,j] \\big| \\le \\tau_e$$\nwhere $M$ is the number of pixels in $\\Omega_{\\text{valid}}$. If Criterion 1 holds and the mask sum is (close to) zero, the convolution output $(I * H)[i,j]$ should also be (close to) zero everywhere. Consequently, the texture energy $TE$ should be very small and satisfy this condition.\n\nThe overall algorithm for each test case is as follows:\n1.  Select the specified 1D vectors $u$ and $v$.\n2.  Construct the 2D mask $H$ via the scaled outer product: $H = s \\cdot (u v^\\top)$.\n3.  If a perturbation $(i_p, j_p, \\delta)$ is specified, modify the mask: $H[i_p, j_p] \\leftarrow H[i_p, j_p] + \\delta$.\n4.  Compute the absolute sum of the mask's coefficients and check if it is within tolerance $\\tau_s$.\n5.  Generate the constant $N \\times N$ image with value $c$.\n6.  Perform 2D convolution of the image with the mask, retaining only the 'valid' portion of the output.\n7.  Compute the texture energy $TE$ by taking the mean of the absolute values of the valid convolution output.\n8.  Check if the texture energy is within tolerance $\\tau_e$.\n9.  The result for the test case is `True` if and only if both checks (from steps 4 and 8) pass.\n\nFor example, in test case 2 ($u=L_5, v=L_5$), the sum of the mask coefficients is $s \\cdot (\\sum L_5) \\cdot (\\sum L_5) = 1.0 \\cdot 16 \\cdot 16 = 256$. Since $|256|$ is not less than or equal to $\\tau_s=10^{-12}$, this case fails Criterion 1, and the final result is `False`. In contrast, for test case 1 ($u=E_5, v=L_5$), the sum of coefficients is $s \\cdot (\\sum E_5) \\cdot (\\sum L_5) = 1.0 \\cdot 0 \\cdot 16 = 0$. This passes Criterion 1. The subsequent convolution with a constant image yields a near-zero response, passing Criterion 2. Thus, the result is `True`. Test case 4 introduces a perturbation $\\delta=10^{-6}$, causing the mask sum to become $10^{-6}$, which is greater than the tolerance $\\tau_s=10^{-8}$, so it fails Criterion 1.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Validates Laws' texture masks against zero-sum and near-zero response properties.\n    \"\"\"\n    laws_vectors = {\n        'L5': np.array([1, 4, 6, 4, 1], dtype=np.float64),\n        'E5': np.array([-1, -2, 0, 2, 1], dtype=np.float64),\n        'S5': np.array([-1, 0, 2, 0, -1], dtype=np.float64),\n        'W5': np.array([-1, 2, 0, -2, 1], dtype=np.float64),\n        'R5': np.array([1, -4, 6, -4, 1], dtype=np.float64),\n    }\n\n    test_cases = [\n        {'u': 'E5', 'v': 'L5', 's': 1.0, 'pert': None, 'N': 64, 'c': 7.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'L5', 'v': 'L5', 's': 1.0, 'pert': None, 'N': 32, 'c': 2.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'W5', 'v': 'S5', 's': 3.0, 'pert': None, 'N': 48, 'c': 5.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'E5', 'v': 'S5', 's': 1.0, 'pert': (2, 2, 1e-6), 'N': 40, 'c': 1.0, 'tau_s': 1e-8, 'tau_e': 1e-8},\n        {'u': 'R5', 'v': 'R5', 's': 1.0, 'pert': None, 'N': 5, 'c': 10.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n        {'u': 'L5', 'v': 'E5', 's': 1.0, 'pert': None, 'N': 64, 'c': 3.0, 'tau_s': 1e-12, 'tau_e': 1e-12},\n    ]\n\n    results = []\n    for case in test_cases:\n        u_vec = laws_vectors[case['u']]\n        v_vec = laws_vectors[case['v']]\n\n        # 1. Construct the 2D mask = s * (u v^T)\n        H = case['s'] * np.outer(u_vec, v_vec)\n\n        # 2. Apply optional perturbation\n        if case['pert']:\n            i_p, j_p, delta = case['pert']\n            H[i_p, j_p] += delta\n\n        # 3. Criterion 1: Verify the zero-sum property of the mask\n        mask_sum_abs = np.abs(np.sum(H))\n        criterion1_passed = mask_sum_abs = case['tau_s']\n\n        # 4. Create the constant image\n        image = np.full((case['N'], case['N']), case['c'], dtype=np.float64)\n\n        # 5. Perform 2D convolution with 'valid' mode\n        conv_output = convolve2d(image, H, mode='valid')\n\n        # 6. Criterion 2: Verify near-zero response\n        texture_energy = 0.0\n        if conv_output.size > 0:\n            texture_energy = np.mean(np.abs(conv_output))\n        \n        criterion2_passed = texture_energy = case['tau_e']\n\n        # The final result is true if and only if both criteria are satisfied.\n        results.append(criterion1_passed and criterion2_passed)\n\n    # Format the final output as a comma-separated list of booleans in a string\n    # Python's `str(bool)` converts True to \"True\" and False to \"False\"\n    # The problem asks for lowercase \"true\" and \"false\", so we adjust.\n    output_str = f\"[{','.join(str(r).lower() for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "Moving beyond constant-intensity images, a more powerful way to validate a filter is to test its response to a specific frequency. This practice bridges the spatial domain (convolution) with the frequency domain, which is the natural space to analyze a filter's purpose. By creating a synthetic image with a single sinusoid, you will empirically measure the filter's output and compare it to the theoretically predicted amplification from its frequency response, providing a rigorous proof-of-correctness for your implementation .",
            "id": "4565096",
            "problem": "You are given the task to design a proof-of-correctness test for a Laws filter implementation grounded in the mathematical behavior of Linear Shift-Invariant (LSI) systems. In texture analysis for Radiomics, Laws' Texture Energy Measures (TEM) use small, separable, two-dimensional filters constructed from one-dimensional kernels to accentuate specific texture patterns. Your test must verify, on synthetic data containing a single sinusoidal component, that the amplitude of the filtered output matches the magnitude of the filter’s frequency response at the sinusoid’s spatial frequency. The verification must be conducted under circular convolution to avoid border artifacts, and the comparison must be expressed numerically.\n\nStart from the following base definitions:\n- A Linear Shift-Invariant (LSI) system with impulse response $h[n]$ produces an output by discrete convolution of an input signal $x[n]$ with $h[n]$.\n- The Discrete-Time Fourier Transform (DTFT) of a finite impulse response $h[n]$ is defined by $H(\\omega) = \\sum_{n=0}^{M-1} h[n] e^{-j \\omega n}$ for a mask of length $M$, where $\\omega$ is the angular frequency in radians.\n- For a two-dimensional separable mask $C = a b^{\\top}$, where $a$ is the vertical component applied along the $y$-axis and $b$ is the horizontal component applied along the $x$-axis, the two-dimensional convolution is equivalent to consecutive one-dimensional convolutions along $y$ and $x$.\n- Under LSI, a single-frequency sinusoidal input of unit amplitude remains sinusoidal at the same frequency after filtering, with its amplitude scaled by the magnitude of the system’s frequency response at that frequency. The phase may change but does not affect the Root-Mean-Square (RMS) amplitude.\n\nUse the canonical one-dimensional Laws vectors of length $5$:\n- $L5 = [1,4,6,4,1]$,\n- $E5 = [-1,-2,0,2,1]$,\n- $S5 = [-1,0,2,0,-1]$,\n- $W5 = [-1,2,0,-2,1]$,\n- $R5 = [1,-4,6,-4,1]$.\n\nConstruct two-dimensional masks $C = a b^{\\top}$ from these vectors. Work on a synthetic image $I[x,y]$ of size $128 \\times 128$ with coordinates $x \\in \\{0,1,\\dots,127\\}$ and $y \\in \\{0,1,\\dots,127\\}$. The image shall contain a single sinusoid of unit amplitude:\n$$\nI[x,y] = \\sin\\left(2\\pi\\left(\\frac{k_x}{128} x + \\frac{k_y}{128} y\\right) + \\phi\\right),\n$$\nwhere $k_x$ and $k_y$ are integer spatial frequencies expressed as cycles per image dimension, and $\\phi$ is a phase offset. Use radians for $\\phi$.\n\nFor each test case, proceed as follows:\n- Convolve $I[x,y]$ with $C$ using two-dimensional circular convolution to produce an output $O[x,y]$ of the same size.\n- Compute the measured amplitude of $O[x,y]$ via the RMS: first compute $R = \\sqrt{\\frac{1}{128^2}\\sum_{x=0}^{127}\\sum_{y=0}^{127} O[x,y]^2}$, then convert to sinusoidal amplitude by $A_{\\text{meas}} = \\sqrt{2}\\,R$.\n- Derive the predicted amplitude $A_{\\text{pred}}$ for the separable mask from first principles, starting from the DTFT of the one-dimensional kernels and the separability of the two-dimensional frequency response. Use the magnitude of the complex frequency response at the angular frequencies $\\omega_x = 2\\pi \\frac{k_x}{128}$ and $\\omega_y = 2\\pi \\frac{k_y}{128}$. Do not assume any pre-derived shortcut formulas; justify the construction from the DTFT definition and the properties of separable convolution and LSI systems.\n- Report the relative error for each case as a float:\n$$\ne = \\frac{\\left|A_{\\text{meas}} - A_{\\text{pred}}\\right|}{\\max\\left(10^{-12}, A_{\\text{pred}}\\right)}.\n$$\n\nDesign the test suite with the following six cases, which together probe low and high spatial frequencies, directional selectivity, separability, and near-Nyquist behavior. In each tuple, the first element is the vertical kernel $a$, the second is the horizontal kernel $b$, followed by $(k_x,k_y,\\phi)$:\n1. $(E5, L5, 8, 0, 0.0)$,\n2. $(L5, E5, 0, 8, 1.0)$,\n3. $(S5, S5, 32, 0, 0.5)$,\n4. $(R5, R5, 60, 60, 0.0)$,\n5. $(W5, L5, 1, 0, 0.0)$,\n6. $(E5, E5, 16, 16, 0.25)$.\n\nYour program must compute the relative error $e$ for each of the six test cases and print the results in a single line in the exact format:\n- A comma-separated Python list of six floats enclosed in square brackets, for example, $[e_1,e_2,e_3,e_4,e_5,e_6]$.\n\nNo external input or files are permitted, and all angles must be in radians. The program must use two-dimensional circular convolution (boundary wrapping) and return only the specified single line of output.",
            "solution": "The problem is valid as it presents a well-defined, scientifically sound task based on foundational principles of digital signal processing. The objective is to verify an implementation of Laws' texture filters by comparing the empirically measured response to a sinusoidal input with the theoretically predicted response derived from the filter's frequency characteristics.\n\nThe core principle is that a Linear Shift-Invariant (LSI) system, when subjected to a sinusoidal input, produces a sinusoidal output of the same frequency. The amplitude of the output sinusoid is the product of the input amplitude and the magnitude of the system's frequency response evaluated at the input frequency.\n\nThe input signal is a 2D sinusoid of unit amplitude:\n$$\nI[x,y] = \\sin\\left(2\\pi\\left(\\frac{k_x}{N} x + \\frac{k_y}{N} y\\right) + \\phi\\right)\n$$\nwhere $N=128$ is the image dimension. The input amplitude is $A_{\\text{in}} = 1$. The angular spatial frequencies are $\\omega_x = 2\\pi k_x/N$ and $\\omega_y = 2\\pi k_y/N$.\n\nThe filter is a $5 \\times 5$ separable mask $C = a b^{\\top}$, where $a$ is the vertical kernel (applied along the $y$-axis) and $b$ is the horizontal kernel (applied along the $x$-axis). The output image is $O = I \\circledast C$, where $\\circledast$ denotes 2D circular convolution.\n\n**1. Predicted Amplitude ($A_{\\text{pred}}$) Derivation**\n\nAccording to LSI system theory, the amplitude of the output signal, $A_{\\text{out}}$, is given by:\n$$\nA_{\\text{out}} = A_{\\textin} \\cdot |H_C(\\omega_x, \\omega_y)|\n$$\nwhere $H_C(\\omega_x, \\omega_y)$ is the 2D frequency response of the filter $C$. Since the input amplitude $A_{\\text{in}}$ is $1$, the predicted output amplitude is simply $A_{\\text{pred}} = |H_C(\\omega_x, \\omega_y)|$.\n\nA key property of separable filters is that their 2D frequency response is the product of the 1D frequency responses of the constituent kernels. The kernel $a$ is applied vertically (along $y$) and $b$ is applied horizontally (along $x$). Therefore, the 2D frequency response is:\n$$\nH_C(\\omega_x, \\omega_y) = H_b(\\omega_x) \\cdot H_a(\\omega_y)\n$$\nwhere $H_b(\\omega_x)$ is the frequency response of kernel $b$ at frequency $\\omega_x$, and $H_a(\\omega_y)$ is the frequency response of kernel $a$ at frequency $\\omega_y$.\n\nThe predicted amplitude is thus:\n$$\nA_{\\text{pred}} = |H_b(\\omega_x) \\cdot H_a(\\omega_y)| = |H_b(\\omega_x)| \\cdot |H_a(\\omega_y)|\n$$\nThe 1D frequency response $H_h(\\omega)$ for a given kernel $h$ of length $M=5$ is calculated using the Discrete-Time Fourier Transform (DTFT) as defined in the problem:\n$$\nH_h(\\omega) = \\sum_{n=0}^{M-1} h[n] e^{-j \\omega n}\n$$\nHere, $h[n]$ are the elements of the Laws vector, indexed from $n=0$ to $n=4$. The magnitude $|H_h(\\omega)|$ is computed by taking the absolute value of this complex sum.\n\n**2. Measured Amplitude ($A_{\\text{meas}}$) Procedure**\n\nThe measured amplitude is determined empirically from the output of the convolution.\nFirst, for each test case, the $128 \\times 128$ input image $I[x,y]$ is generated.\nSecond, the $5 \\times 5$ filter kernel $C$ is constructed as the outer product of the vertical kernel $a$ and the horizontal kernel $b$, i.e., $C = ab^{\\top}$.\nThird, the output image $O[x,y]$ is computed by performing a 2D circular convolution of the input image $I$ with the kernel $C$.\n\nThe output signal $O[x,y]$ will be a sinusoid of the form $A_{\\text{meas}} \\sin(\\omega_x x + \\omega_y y + \\phi')$. The Root-Mean-Square (RMS) value of such a signal is $R = A_{\\text{meas}}/\\sqrt{2}$. The problem provides the formula to calculate the RMS of the discrete output image:\n$$\nR = \\sqrt{\\frac{1}{N^2}\\sum_{x=0}^{N-1}\\sum_{y=0}^{N-1} O[x,y]^2}\n$$\nwhere $N=128$. By rearranging the relationship between RMS and amplitude, we can compute the measured amplitude as:\n$$\nA_{\\text{meas}} = \\sqrt{2} \\cdot R\n$$\n\n**3. Error Calculation**\n\nThe theoretical prediction and empirical measurement are compared using the relative error $e$:\n$$\ne = \\frac{\\left|A_{\\text{meas}} - A_{\\text{pred}}\\right|}{\\max\\left(10^{-12}, A_{\\text{pred}}\\right)}\n$$\nThe term $\\max(10^{-12}, A_{\\text{pred}})$ in the denominator is a safeguard against division by zero for cases where the filter is expected to completely nullify the input sinusoid (i.e., $A_{\\text{pred}} = 0$).\n\nThe following program implements this entire procedure for the six specified test cases. It calculates $A_{\\text{pred}}$ from the DTFT formula, $A_{\\text{meas}}$ via circular convolution and RMS, and finally the relative error for each case.",
            "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\n\ndef solve():\n    \"\"\"\n    Solves the Laws' filter proof-of-correctness test.\n    \"\"\"\n    \n    # Define canonical one-dimensional Laws' vectors of length 5\n    LAWS_KERNELS = {\n        'L5': np.array([1, 4, 6, 4, 1], dtype=np.float64),\n        'E5': np.array([-1, -2, 0, 2, 1], dtype=np.float64),\n        'S5': np.array([-1, 0, 2, 0, -1], dtype=np.float64),\n        'W5': np.array([-1, 2, 0, -2, 1], dtype=np.float64),\n        'R5': np.array([1, -4, 6, -4, 1], dtype=np.float64),\n    }\n\n    # Define the test suite\n    test_cases = [\n        # (vertical_kernel, horizontal_kernel, (kx, ky, phi))\n        ('E5', 'L5', (8, 0, 0.0)),\n        ('L5', 'E5', (0, 8, 1.0)),\n        ('S5', 'S5', (32, 0, 0.5)),\n        ('R5', 'R5', (60, 60, 0.0)),\n        ('W5', 'L5', (1, 0, 0.0)),\n        ('E5', 'E5', (16, 16, 0.25)),\n    ]\n\n    def calc_freq_resp_mag(kernel, omega):\n        \"\"\"\n        Calculates the magnitude of the frequency response for a 1D kernel at a\n        given angular frequency, using the DTFT definition.\n        H(omega) = sum_{n=0}^{M-1} h[n] * exp(-j * omega * n)\n        \"\"\"\n        n_indices = np.arange(len(kernel))\n        complex_exponentials = np.exp(-1j * omega * n_indices)\n        H = np.sum(kernel * complex_exponentials)\n        return np.abs(H)\n\n    results = []\n    N = 128\n    x_coords = np.arange(N)\n    y_coords = np.arange(N)\n    xx, yy = np.meshgrid(x_coords, y_coords)\n\n    for case in test_cases:\n        a_name, b_name, params = case\n        kx, ky, phi = params\n        \n        a_kernel = LAWS_KERNELS[a_name]\n        b_kernel = LAWS_KERNELS[b_name]\n\n        # 1. Derive the predicted amplitude (A_pred) from first principles\n        omega_x = 2 * np.pi * kx / N\n        omega_y = 2 * np.pi * ky / N\n        \n        # Frequency response of vertical kernel 'a' at frequency 'omega_y'\n        pred_amp_a = calc_freq_resp_mag(a_kernel, omega_y)\n        # Frequency response of horizontal kernel 'b' at frequency 'omega_x'\n        pred_amp_b = calc_freq_resp_mag(b_kernel, omega_x)\n        \n        # A_pred for the separable 2D filter is the product of 1D responses\n        A_pred = pred_amp_a * pred_amp_b\n\n        # 2. Compute the measured amplitude (A_meas)\n        # Generate the synthetic image with a single sinusoidal component\n        I = np.sin(2 * np.pi * (kx * xx / N + ky * yy / N) + phi)\n\n        # Construct the 2D separable mask C = a * b^T\n        C_2D_kernel = np.outer(a_kernel, b_kernel)\n\n        # Perform 2D circular convolution to get the output image O\n        O = convolve2d(I, C_2D_kernel, boundary='wrap', mode='same')\n\n        # Compute RMS of the output, then convert to sinusoidal amplitude\n        R = np.sqrt(np.mean(np.square(O)))\n        A_meas = np.sqrt(2) * R\n\n        # 3. Report the relative error\n        error = np.abs(A_meas - A_pred) / np.maximum(1e-12, A_pred)\n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(f'{r:.14f}' for r in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Once an implementation is verified, the next step is to understand the statistical nature of the features it produces. In radiomics, we treat texture energy as a random variable, and its reliability is critical. This advanced exercise guides you through a theoretical analysis of the Laws' energy estimator, exploring its bias and variance and connecting these concepts to the Central Limit Theorem. You will derive how the size of the analysis window impacts the estimator's precision and uncover the fundamental bias-variance trade-off that is central to applying these features in practice .",
            "id": "4565108",
            "problem": "In radiomics texture analysis using Laws' texture energy measures, consider a two-dimensional image random field $X(\\mathbf{p})$ with pixel index $\\mathbf{p} \\in \\mathbb{Z}^{2}$, where $X(\\mathbf{p})$ are independent and identically distributed zero-mean Gaussian random variables with variance $\\sigma^{2}$. A Laws filter is formed from the one-dimensional edge kernel $E5 = \\left[-1,\\,-2,\\,0,\\,2,\\,1\\right]$, and the two-dimensional filter is the outer product $h = E5 \\otimes E5$, so that $h(i,j) = E5(i)\\,E5(j)$ for $i,j \\in \\{1,2,3,4,5\\}$. Define the filtered field $Y(\\mathbf{p}) = (h * X)(\\mathbf{p})$, where $*$ denotes two-dimensional discrete convolution with infinite support (ignore boundary effects).\n\nDefine the Laws energy feature $E_{2}(W)$ over a finite set of pixel locations $W \\subset \\mathbb{Z}^{2}$ by\n$$\nE_{2}(W) \\equiv \\frac{1}{|W|} \\sum_{\\mathbf{p} \\in W} \\left(Y(\\mathbf{p})\\right)^{2}.\n$$\nAssume that $W$ is a subsampled lattice such that the sets of input samples contributing to $\\{Y(\\mathbf{p}) : \\mathbf{p} \\in W\\}$ do not overlap, so that the random variables $\\{Y(\\mathbf{p}) : \\mathbf{p} \\in W\\}$ are independent. Let $|W| = n$ denote the window size.\n\nStarting from the definitions of discrete convolution, second-order moments of Gaussian random variables, and the Central Limit Theorem (CLT) for independent and identically distributed samples, do the following:\n\n1. Prove that $E_{2}(W)$ is an unbiased estimator of $\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]$ and express $\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]$ in terms of $\\sigma^{2}$ and the filter coefficients $h(i,j)$.\n2. Derive $\\operatorname{Var}\\!\\left(E_{2}(W)\\right)$ as an explicit function of $n$ and the second and fourth moments of $Y(\\mathbf{p})$.\n3. Using your result, discuss qualitatively how increasing $n$ affects the bias–variance trade-off of $E_{2}(W)$ for estimating texture energy in a homogeneous region, and explain under what practical image conditions increasing $n$ could introduce bias in radiomics applications.\n4. Define the asymptotic variance $\\tau^{2}$ by the CLT\n$$\n\\sqrt{n}\\left(E_{2}(W) - \\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right) \\xrightarrow{d} \\mathcal{N}\\!\\left(0,\\,\\tau^{2}\\right)\n$$\nand compute $\\tau^{2}$ in closed form for the specified $h$ when $\\sigma^{2} = 1$. Report the value of $\\tau^{2}$ as your final answer. Do not round; provide the exact value with no units.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a tractable theoretical problem within the field of statistical image analysis and radiomics. All definitions and conditions are sufficiently specified to derive a unique solution.\n\nThe problem is addressed in four parts as requested.\n\n**1. Unbiasedness of the Estimator and its Expectation**\n\nThe Laws energy feature $E_{2}(W)$ is defined as the sample mean of the squared filtered field values $Y(\\mathbf{p})^{2}$ over a window $W$ of size $|W|=n$.\n$$\nE_{2}(W) = \\frac{1}{|W|} \\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2} = \\frac{1}{n} \\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2}\n$$\nTo determine if $E_{2}(W)$ is an unbiased estimator of $\\mathbb{E}[Y(\\mathbf{p})^{2}]$, we must compute its expectation. By the linearity of the expectation operator:\n$$\n\\mathbb{E}\\left[E_{2}(W)\\right] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2}\\right] = \\frac{1}{n} \\sum_{\\mathbf{p} \\in W} \\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\n$$\nThe input random field $X(\\mathbf{p})$ is stated to be stationary (independent and identically distributed). A linear time-invariant filtering of a stationary process results in a stationary process. Thus, the filtered field $Y(\\mathbf{p})$ is also stationary. This implies that its statistical moments, including $\\mathbb{E}[Y(\\mathbf{p})^{2}]$, are independent of the pixel location $\\mathbf{p}$. Let $\\mu_{Y^2} = \\mathbb{E}[Y(\\mathbf{p})^{2}]$. The sum becomes:\n$$\n\\mathbb{E}\\left[E_{2}(W)\\right] = \\frac{1}{n} \\sum_{\\mathbf{p} \\in W} \\mu_{Y^2} = \\frac{1}{n} (n \\cdot \\mu_{Y^2}) = \\mu_{Y^2} = \\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\n$$\nSince $\\mathbb{E}[E_{2}(W)]$ is equal to the quantity it is estimating, $E_{2}(W)$ is an unbiased estimator of $\\mathbb{E}[Y(\\mathbf{p})^{2}]$.\n\nNext, we express $\\mathbb{E}[Y(\\mathbf{p})^{2}]$ in terms of $\\sigma^{2}$ and the filter coefficients $h(i,j)$. The filtered field is given by the discrete convolution:\n$$\nY(\\mathbf{p}) = (h * X)(\\mathbf{p}) = \\sum_{k,l} h(k,l) X(\\mathbf{p} - (k,l))\n$$\nwhere the sum is over the non-zero support of the filter $h$. The input variables $X(\\mathbf{p})$ are zero-mean, so the mean of $Y(\\mathbf{p})$ is:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})\\right] = \\mathbb{E}\\left[\\sum_{k,l} h(k,l) X(\\mathbf{p} - (k,l))\\right] = \\sum_{k,l} h(k,l) \\mathbb{E}\\left[X(\\mathbf{p} - (k,l))\\right] = \\sum_{k,l} h(k,l) \\cdot 0 = 0\n$$\nSince $Y(\\mathbf{p})$ has zero mean, its second moment is equal to its variance: $\\mathbb{E}[Y(\\mathbf{p})^{2}] = \\operatorname{Var}(Y(\\mathbf{p}))$. We compute this variance. As the random variables $X(\\mathbf{q})$ are independent for different locations $\\mathbf{q}$, the variance of their linear combination is:\n$$\n\\operatorname{Var}(Y(\\mathbf{p})) = \\operatorname{Var}\\left(\\sum_{k,l} h(k,l) X(\\mathbf{p} - (k,l))\\right) = \\sum_{k,l} \\operatorname{Var}\\left(h(k,l) X(\\mathbf{p} - (k,l))\\right)\n$$\nUsing the property $\\operatorname{Var}(aZ) = a^{2}\\operatorname{Var}(Z)$ and that $\\operatorname{Var}(X(\\mathbf{q})) = \\sigma^{2}$ for any location $\\mathbf{q}$:\n$$\n\\operatorname{Var}(Y(\\mathbf{p})) = \\sum_{k,l} h(k,l)^{2} \\operatorname{Var}\\left(X(\\mathbf{p} - (k,l))\\right) = \\sum_{k,l} h(k,l)^{2} \\sigma^{2}\n$$\nTherefore, the desired expectation is:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right] = \\sigma^{2} \\sum_{i=1}^{5} \\sum_{j=1}^{5} h(i,j)^{2}\n$$\n\n**2. Variance of the Estimator**\n\nWe derive the variance of the estimator $E_{2}(W)$.\n$$\n\\operatorname{Var}\\left(E_{2}(W)\\right) = \\operatorname{Var}\\left(\\frac{1}{n} \\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2}\\right) = \\frac{1}{n^{2}} \\operatorname{Var}\\left(\\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2}\\right)\n$$\nA crucial assumption is that the set $W$ is a subsampled lattice such that the random variables $\\{Y(\\mathbf{p}) : \\mathbf{p} \\in W\\}$ are independent. This implies that the random variables $\\{Y(\\mathbf{p})^{2} : \\mathbf{p} \\in W\\}$ are also independent. For a sum of independent random variables, the variance of the sum is the sum of the variances.\n$$\n\\operatorname{Var}\\left(\\sum_{\\mathbf{p} \\in W} Y(\\mathbf{p})^{2}\\right) = \\sum_{\\mathbf{p} \\in W} \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right)\n$$\nDue to the stationarity of the field $Y(\\mathbf{p})$, the variance $\\operatorname{Var}(Y(\\mathbf{p})^{2})$ is also constant for all $\\mathbf{p} \\in W$. The sum simplifies to:\n$$\n\\sum_{\\mathbf{p} \\in W} \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right) = n \\cdot \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right)\n$$\nSubstituting this back, we get:\n$$\n\\operatorname{Var}\\left(E_{2}(W)\\right) = \\frac{1}{n^{2}} \\left(n \\cdot \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right)\\right) = \\frac{1}{n} \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right)\n$$\nUsing the definition of variance, $\\operatorname{Var}(Z) = \\mathbb{E}[Z^{2}] - (\\mathbb{E}[Z])^{2}$, with $Z = Y(\\mathbf{p})^{2}$:\n$$\n\\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right) = \\mathbb{E}\\left[\\left(Y(\\mathbf{p})^{2}\\right)^{2}\\right] - \\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2} = \\mathbb{E}\\left[Y(\\mathbf{p})^{4}\\right] - \\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2}\n$$\nThus, the variance of the estimator is:\n$$\n\\operatorname{Var}\\left(E_{2}(W)\\right) = \\frac{1}{n} \\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{4}\\right] - \\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2}\\right)\n$$\n\n**3. Qualitative Discussion of Bias and Variance**\n\nUnder the idealized assumptions of the problem, the bias-variance characteristics of the estimator $E_{2}(W)$ are straightforward.\nFrom part $1$, we proved that $E_{2}(W)$ is an unbiased estimator of the true texture energy $\\mathbb{E}[Y(\\mathbf{p})^{2}]$. The bias is zero, irrespective of the window size $n$.\nFrom part $2$, the variance of the estimator is $\\operatorname{Var}(E_{2}(W)) = \\frac{1}{n} \\operatorname{Var}(Y(\\mathbf{p})^{2})$. The variance is inversely proportional to the sample size $n$.\nTherefore, in this idealized context of a perfectly homogeneous region (stationary process), increasing $n$ has a purely beneficial effect: it reduces the variance of the estimate, making it more precise, while the bias remains zero. There is no trade-off; a larger window size is unequivocally better, as it minimizes the mean squared error (MSE), which is purely composed of the variance term.\n\nHowever, in practical radiomics applications, this idealization breaks down. Real-world images, even within a designated region of interest (ROI) that appears \"homogeneous\", are rarely perfectly stationary. Tumors, for example, exhibit heterogeneity. Increasing the window size $n$ means averaging over a larger physical area. If this larger area encompasses different tissue types, vasculature, or necrotic zones, the underlying statistical properties (like $\\sigma^{2}$) are no longer constant.\nIn this realistic scenario, the estimator $E_{2}(W)$ computes the average energy over a potentially heterogeneous region. If the goal is to estimate the texture energy of a specific tissue type at a particular location, but the window $W$ grows large enough to include other tissue types, $E_{2}(W)$ will be a biased estimator of the local property of interest. It will instead estimate a mixture of texture properties. This introduces a fundamental bias-variance trade-off:\n- A small $n$ yields an estimate with low bias (as it is more localized to the target tissue) but high variance (due to fewer samples).\n- A large $n$ yields an estimate with low variance (due to statistical averaging) but potentially high bias (due to averaging over heterogeneous regions, blurring spatial details).\nThis trade-off between statistical stability and spatial resolution is a central challenge in feature extraction for radiomics.\n\n**4. Computation of the Asymptotic Variance $\\tau^{2}$**\n\nThe Central Limit Theorem (CLT) is stated as:\n$$\n\\sqrt{n}\\left(E_{2}(W) - \\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right) \\xrightarrow{d} \\mathcal{N}\\!\\left(0,\\,\\tau^{2}\\right)\n$$\nThe estimator $E_{2}(W)$ is the sample mean of the i.i.d. random variables $Z_{\\mathbf{p}} = Y(\\mathbf{p})^{2}$. The standard CLT for a sample mean $\\bar{Z}$ of i.i.d. variables $Z_i$ states that $\\sqrt{n}(\\bar{Z} - \\mathbb{E}[Z]) \\xrightarrow{d} \\mathcal{N}(0, \\operatorname{Var}(Z))$. By direct comparison, the asymptotic variance $\\tau^{2}$ is equal to the variance of the underlying random variable being averaged:\n$$\n\\tau^{2} = \\operatorname{Var}\\left(Y(\\mathbf{p})^{2}\\right) = \\mathbb{E}\\left[Y(\\mathbf{p})^{4}\\right] - \\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2}\n$$\nThe input field $X(\\mathbf{p})$ consists of i.i.d. Gaussian variables. The convolution is a linear operation. Therefore, $Y(\\mathbf{p})$ is a Gaussian random variable. Since its mean is $0$, it is a zero-mean (or central) Gaussian random variable, $Y(\\mathbf{p}) \\sim \\mathcal{N}(0, \\sigma_{Y}^{2})$, where $\\sigma_{Y}^{2} = \\mathbb{E}[Y(\\mathbf{p})^{2}]$.\nFor a central Gaussian random variable $Y \\sim \\mathcal{N}(0, \\sigma_{Y}^{2})$, the fourth moment is $\\mathbb{E}[Y^{4}] = 3(\\sigma_{Y}^{2})^{2}$.\nSubstituting this into the expression for $\\tau^{2}$:\n$$\n\\tau^{2} = 3(\\sigma_{Y}^{2})^{2} - (\\sigma_{Y}^{2})^{2} = 2(\\sigma_{Y}^{2})^{2} = 2\\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2}\n$$\nNow we compute the numerical value for $\\sigma^{2} = 1$ and the filter $h = E5 \\otimes E5$. From part $1$:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right] = \\sigma^{2} \\sum_{i,j} h(i,j)^{2}\n$$\nWith $\\sigma^{2} = 1$ and $h(i,j) = E5(i)E5(j)$:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right] = \\sum_{i=1}^{5} \\sum_{j=1}^{5} (E5(i)E5(j))^{2} = \\sum_{i=1}^{5} \\sum_{j=1}^{5} E5(i)^{2}E5(j)^{2}\n$$\nThis sum is separable:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right] = \\left(\\sum_{i=1}^{5} E5(i)^{2}\\right) \\left(\\sum_{j=1}^{5} E5(j)^{2}\\right) = \\left(\\sum_{k=1}^{5} E5(k)^{2}\\right)^{2}\n$$\nThe kernel is $E5 = \\left[-1,\\,-2,\\,0,\\,2,\\,1\\right]$. We compute the sum of squares of its elements:\n$$\n\\sum_{k=1}^{5} E5(k)^{2} = (-1)^{2} + (-2)^{2} + 0^{2} + 2^{2} + 1^{2} = 1 + 4 + 0 + 4 + 1 = 10\n$$\nTherefore, the second moment is:\n$$\n\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right] = (10)^{2} = 100\n$$\nFinally, we compute the asymptotic variance $\\tau^{2}$:\n$$\n\\tau^{2} = 2\\left(\\mathbb{E}\\left[Y(\\mathbf{p})^{2}\\right]\\right)^{2} = 2(100)^{2} = 2(10000) = 20000\n$$\nIn scientific notation, this is $2 \\times 10^{4}$.",
            "answer": "$$\n\\boxed{2 \\times 10^{4}}\n$$"
        }
    ]
}