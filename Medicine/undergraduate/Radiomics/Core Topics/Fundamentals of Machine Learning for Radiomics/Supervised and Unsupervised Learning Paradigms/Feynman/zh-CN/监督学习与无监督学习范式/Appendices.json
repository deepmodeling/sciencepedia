{
    "hands_on_practices": [
        {
            "introduction": "无监督学习的核心在于从无标签的数据中发现固有的结构或模式。本练习将引导你应用一种强大的聚类算法——基于密度的噪声应用空间聚类（DBSCAN），来处理一个模拟的影像组学特征数据集。通过手动计算，你将深入理解DBSCAN如何根据点的密度来识别核心点、边界点和噪声点，从而形成聚类。",
            "id": "4561470",
            "problem": "考虑代表灰度共生矩阵 (GLCM) 对比度和熵的未标记二维标准化放射组学特征向量。数据集由以下 $16$ 个点组成：\n$$A_1=(0.10, 0.10),\\ A_2=(0.18, 0.12),\\ A_3=(0.12, 0.20),\\ A_4=(0.08, 0.15),\\ A_5=(0.16, 0.18),\\ A_6=(0.14, 0.08),\\ A_7=(0.20, 0.14),$$\n$$B_1=(0.80, 0.80),\\ B_2=(0.86, 0.78),\\ B_3=(0.78, 0.86),\\ B_4=(0.84, 0.88),\\ B_5=(0.76, 0.76),\\ B_6=(0.88, 0.82),\\ B_7=(0.82, 0.74),$$\n$$N_1=(0.02, 0.98),\\ N_2=(0.12, 0.88).$$\n应用基于密度的噪声应用空间聚类 (DBSCAN) 算法，邻域半径 $\\epsilon=0.5$，最小点数 $\\mathrm{minPts}=5$，使用欧几里得范数 $\\|\\cdot\\|_2$ 和标准的 DBSCAN 邻域定义 $N_{\\epsilon}(p)=\\{q:\\|q-p\\|_2\\leq \\epsilon\\}$，该定义包含点 $p$ 本身。从 DBSCAN 的基本定义出发（核心点满足 $|N_{\\epsilon}(p)|\\geq \\mathrm{minPts}$，边界点满足 $|N_{\\epsilon}(p)|  \\mathrm{minPts}$ 但位于至少一个核心点的 $\\epsilon$-邻域内，而噪声点位于所有核心点的 $\\epsilon$-邻域之外），确定哪些点是核心点、边界点或噪声点。然后，根据这些定义推导出 DBSCAN 的聚类分配，解释密度可达性和密度连通性如何在该数据集中形成聚类。\n\n报告 DBSCAN 在此数据集上发现的总聚类数作为唯一的最终量。最终答案以无单位的整数表示。无需四舍五入。",
            "solution": "首先验证问题，以确保其科学上合理、内容完整且定义明确。\n\n### 步骤 1：提取已知条件\n- **数据集**：一组 $16$ 个二维点，表示为 $A_1, \\dots, A_7$、$B_1, \\dots, B_7$ 和 $N_1, N_2$。\n  - $A_1=(0.10, 0.10)$, $A_2=(0.18, 0.12)$, $A_3=(0.12, 0.20)$, $A_4=(0.08, 0.15)$, $A_5=(0.16, 0.18)$, $A_6=(0.14, 0.08)$, $A_7=(0.20, 0.14)$\n  - $B_1=(0.80, 0.80)$, $B_2=(0.86, 0.78)$, $B_3=(0.78, 0.86)$, $B_4=(0.84, 0.88)$, $B_5=(0.76, 0.76)$, $B_6=(0.88, 0.82)$, $B_7=(0.82, 0.74)$\n  - $N_1=(0.02, 0.98)$, $N_2=(0.12, 0.88)$\n- **DBSCAN 参数**：\n  - 邻域半径 $\\epsilon=0.5$\n  - 最小点数 $\\mathrm{minPts}=5$\n- **距离度量**：欧几里得范数，$\\|\\cdot\\|_2$。\n- **邻域定义**：$N_{\\epsilon}(p)=\\{q:\\|q-p\\|_2\\leq \\epsilon\\}$，包含点 $p$。\n- **点的定义**：\n  - **核心点**：如果 $|N_{\\epsilon}(p)|\\geq \\mathrm{minPts}$，则点 $p$ 是核心点。\n  - **边界点**：如果 $|N_{\\epsilon}(p)| \\mathrm{minPts}$ 但 $p$ 位于至少一个核心点的 $\\epsilon$-邻域内，则点 $p$ 是边界点。\n  - **噪声点**：既不是核心点也不是边界点的点。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述是应用 DBSCAN 聚类算法的标准练习。所有数据点、参数（$\\epsilon$, $\\mathrm{minPts}$）和定义都已提供且明确无歧义。该问题在数据挖掘和机器学习领域，特别是在无监督学习方面，具有科学依据。该问题是适定的 (well-posed)，因为 DBSCAN 算法是确定性的，对于给定的输入将产生单一、唯一的结果。不存在矛盾、缺失数据或科学上不合理的情况。\n\n### 步骤 3：结论与行动\n问题是**有效的**。将提供完整的解答。\n\n### 解答推导\n解答过程首先识别每个点的类型（核心、边界或噪声），然后基于密度可达性和密度连通性的原则形成聚类。为简化计算，将欧几里得距离的平方与 $\\epsilon^2 = 0.5^2 = 0.25$ 进行比较。\n\n**第一部分：邻域分析和点分类**\n\n我们按视觉上明显的分组来分析这些点：'A' 点组、'B' 点组和 'N' 点组。\n\n1.  **'A' 点组分析**：$\\{A_1, \\dots, A_7\\}$\n    这些点紧密地聚集在特征空间的低值区域。我们来计算该组中任意两点之间的最大平方距离。坐标范围为 $x=0.08$ 到 $x=0.20$ 和 $y=0.08$ 到 $y=0.20$。最大的间距可能在 $A_4=(0.08, 0.15)$ 和 $A_7=(0.20, 0.14)$ 之间。\n    $$ \\|A_7-A_4\\|_2^2 = (0.20-0.08)^2 + (0.14-0.15)^2 = 0.12^2 + (-0.01)^2 = 0.0144 + 0.0001 = 0.0145 $$\n    由于 $0.0145  \\epsilon^2 = 0.25$，该组中的所有 $7$ 个点都位于彼此的 $\\epsilon$-邻域内。\n    对于任意点 $p \\in \\{A_1, \\dots, A_7\\}$，其邻域 $N_{\\epsilon}(p)$ 将包含该组的所有 $7$ 个点。我们还必须检查其他组的点是否在附近。让我们检查一个中心的 'A' 点，例如 $A_1=(0.10, 0.10)$，到最近的 'B' 点 $B_5=(0.76, 0.76)$ 和最近的 'N' 点 $N_2=(0.12, 0.88)$ 的距离。\n    $$ \\|A_1-B_5\\|_2^2 = (0.10-0.76)^2 + (0.10-0.76)^2 = (-0.66)^2 + (-0.66)^2 = 0.4356 + 0.4356 = 0.8712 > 0.25 $$\n    $$ \\|A_1-N_2\\|_2^2 = (0.10-0.12)^2 + (0.10-0.88)^2 = (-0.02)^2 + (-0.78)^2 = 0.0004 + 0.6084 = 0.6088 > 0.25 $$\n    其他组距离很远。因此，对于任意点 $p_A \\in \\{A_1, \\dots, A_7\\}$，其邻域恰好是 $N_{\\epsilon}(p_A) = \\{A_1, \\dots, A_7\\}$，其大小为 $|N_{\\epsilon}(p_A)| = 7$。\n    由于 $7 \\ge \\mathrm{minPts}=5$，所有 $7$ 个点 $\\{A_1, \\dots, A_7\\}$ 都是**核心点**。\n\n2.  **'B' 点组分析**：$\\{B_1, \\dots, B_7\\}$\n    这些点聚集在高值区域。坐标范围为 $x=0.76$ 到 $x=0.88$ 和 $y=0.74$ 到 $y=0.88$。我们来检查最大平方距离，可能在 $B_5=(0.76, 0.76)$ 和 $B_4=(0.84, 0.88)$ 之间。\n    $$ \\|B_4-B_5\\|_2^2 = (0.84-0.76)^2 + (0.88-0.76)^2 = 0.08^2 + 0.12^2 = 0.0064 + 0.0144 = 0.0208 $$\n    由于 $0.0208  \\epsilon^2 = 0.25$，该组中的所有点都位于彼此的 $\\epsilon$-邻域内。\n    与 'A' 点组类似，'B' 点组也远离所有其他点。因此，对于任意点 $p_B \\in \\{B_1, \\dots, B_7\\}$，其邻域是 $N_{\\epsilon}(p_B) = \\{B_1, \\dots, B_7\\}$，且 $|N_{\\epsilon}(p_B)| = 7$。\n    由于 $7 \\ge \\mathrm{minPts}=5$，所有 $7$ 个点 $\\{B_1, \\dots, B_7\\}$ 也都是**核心点**。\n\n3.  **'N' 点组分析**：$\\{N_1, N_2\\}$\n    我们来检查 $N_1$ 和 $N_2$ 之间的距离。\n    $$ \\|N_1 - N_2\\|_2^2 = (0.02-0.12)^2 + (0.98-0.88)^2 = (-0.1)^2 + 0.1^2 = 0.01 + 0.01 = 0.02  0.25 $$\n    所以，$N_1$ 和 $N_2$ 在彼此的邻域内。$N_1$ 的邻域是 $N_{\\epsilon}(N_1) = \\{N_1, N_2\\}$，而 $N_2$ 的邻域是 $N_{\\epsilon}(N_2) = \\{N_1, N_2\\}$。每个邻域的大小都是 $2$。\n    由于 $|N_{\\epsilon}(N_1)|=2  \\mathrm{minPts}=5$ 且 $|N_{\\epsilon}(N_2)|=2  \\mathrm{minPts}=5$，所以 $N_1$ 和 $N_2$ 都不是核心点。\n    要成为边界点，它们必须位于某个核心点的 $\\epsilon$-邻域内。核心点是 'A' 点集和 'B' 点集。我们来检查 $N_2=(0.12, 0.88)$ 到其最近的 'A' 点 $A_3=(0.12, 0.20)$ 的距离。\n    $$ \\|N_2 - A_3\\|_2^2 = (0.12-0.12)^2 + (0.88-0.20)^2 = 0^2 + 0.68^2 = 0.4624 > 0.25 $$\n    我们来检查 $N_2=(0.12, 0.88)$ 到其最近的 'B' 点 $B_3=(0.78, 0.86)$ 的距离。\n    $$ \\|N_2 - B_3\\|_2^2 = (0.12-0.78)^2 + (0.88-0.86)^2 = (-0.66)^2 + 0.02^2 = 0.4356 + 0.0004 = 0.436 > 0.25 $$\n    由于最近的核心点都在 $N_1$ 和 $N_2$ 的 $\\epsilon$-半径之外，所以这些点不在任何核心点的邻域内。因此，它们不是边界点。\n    根据定义，既不是核心点也不是边界点的点是**噪声点**。因此，$N_1$ 和 $N_2$ 是噪声点。\n\n**第二部分：聚类形成**\n\n聚类由密度连通点的集合形成。\n- 如果存在一条路径 $p_1, \\dots, p_k$，其中 $p_1 = p$ 且 $p_k = q$，并且每个 $p_{i+1}$ 都从 $p_i$ 直接密度可达（即 $p_{i+1} \\in N_{\\epsilon}(p_i)$ 且 $p_i$ 是一个核心点），那么点 $q$ 从点 $p$ 是**密度可达**的。\n- 如果存在一个核心点 $o$，使得点 $p$ 和 $q$ 都从 $o$ 密度可达，那么这两个点是**密度连通**的。\n\nDBSCAN 通过选择一个任意点，如果该点是核心点，则从该点开始扩展来寻找聚类。\n\n- **聚类 1**：我们从 $A_1$ 开始。我们已经确定它是一个核心点。算法创建一个新的聚类。其邻域中的所有点 $\\{A_1, \\dots, A_7\\}$ 都被添加到这个聚类中。然后算法从这些新添加的点开始扩展。对于这个集合中的任何其他点 $A_i$，它也是一个核心点，其邻域是相同的集合 $\\{A_1, \\dots, A_7\\}$。没有新的点可以被添加进来。$\\{A_1, \\dots, A_7\\}$ 中的所有点彼此之间都是密度连通的（例如，通过核心点 $A_1$）。这就形成了第一个聚类。\n\n- **聚类 2**：我们选择一个未访问过的点，比如 $B_1$。它是一个核心点，所以创建了第二个聚类。它的邻域 $\\{B_1, \\dots, B_7\\}$ 被添加到这个新聚类中。就像 'A' 点组一样，这个集合中的所有点都是核心点，它们的邻域仅限于这个集合。它们彼此之间都是密度连通的，形成了第二个聚类。'A' 点组和 'B' 点组的邻域是不相交的，因此两组之间没有密度连通路径。\n\n- **噪声**：剩下未访问的点是 $N_1$ 和 $N_2$。当算法选择 $N_1$ 时，发现它不是核心点，也不属于任何现有聚类，因此它被标记为噪声。$N_2$ 的情况也一样。\n\n算法终止时，识别出两个不同的聚类和两个噪声点。发现的聚类总数为 $2$。\n\n最终点状态：\n- **核心点**：$\\{A_1, ..., A_7\\}$ 和 $\\{B_1, ..., B_7\\}$\n- **边界点**：无\n- **噪声点**：$\\{N_1, N_2\\}$\n- **聚类**：\n  - 聚类 $1$：$\\{A_1, A_2, A_3, A_4, A_5, A_6, A_7\\}$\n  - 聚类 $2$：$\\{B_1, B_2, B_3, B_4, B_5, B_6, B_7\\}$\n\nDBSCAN 发现的聚类总数为 $2$。",
            "answer": "$$\\boxed{2}$$"
        },
        {
            "introduction": "与无监督学习不同，监督学习的目标是从带有标签的数据中学习一个预测模型。支持向量机（SVM）是一种经典的监督分类算法，其核心思想是找到一个能以最大“间隔”将不同类别分开的决策边界。本练习将通过一个简单的二维数据集，让你亲手推导出最大间隔分类器，并确定哪些数据点（即支持向量）是定义该边界的关键。",
            "id": "4561510",
            "problem": "一位放射组学研究者从病灶的计算机断层扫描中提取了两个标准化特征，记为 $f_1$ 和 $f_2$。经过 $z$-score 标准化后，获得一个包含 $4$ 个样本的玩具数据集，这些样本位于特征平面中的角点 $\\left(\\pm 1, \\pm 1\\right)$ 处。考虑一个监督分类任务，使用通过硬间隔支持向量机 (SVM) 训练的线性分类器将病灶区分为两类，其中支持向量机 (SVM) 指的是在经验铰链损失为零和线性可分的约束下最大化间隔。\n\n样本索引如下：\n- 样本 $1$：$x_1 = \\left(1, 1\\right)$, $y_1 = +1$，\n- 样本 $2$：$x_2 = \\left(1, -1\\right)$, $y_2 = +1$，\n- 样本 $3$：$x_3 = \\left(-1, 1\\right)$, $y_3 = -1$，\n- 样本 $4$：$x_4 = \\left(-1, -1\\right)$, $y_4 = -1$，\n\n这对应于根据第一个特征的符号进行标记，$y_i = \\operatorname{sign}\\!\\left(x_{i1}\\right)$，使得数据集线性可分。设分离超平面由权重向量 $w \\in \\mathbb{R}^2$ 和偏置 $b \\in \\mathbb{R}$ 参数化，分类规则为 $\\operatorname{sign}\\!\\left(w^{\\top} x + b\\right)$。硬间隔支持向量机原始问题施加约束 $y_i\\left(w^{\\top} x_i + b\\right) \\ge 1$ 并最小化欧几里得范数的平方 $\\|w\\|_2^2$。\n\n从这些定义和约束集出发，推导最大间隔分离器并计算：\n- 几何间隔，定义为在硬间隔约束下，决策边界到任一类别的最小距离，以及\n- 支持向量的索引。\n\n将最终答案表示为单个行矩阵，其中第一项为几何间隔，其后是按升序排列的支持向量索引。无需四舍五入，也不涉及单位。",
            "solution": "用户想要解决一个硬间隔支持向量机 (SVM) 问题。\n\n### 步骤 1：问题验证\n\n**1.1. 提取已知条件**\n-   **数据集：**\n    -   $x_1 = (1, 1)$， $y_1 = +1$\n    -   $x_2 = (1, -1)$， $y_2 = +1$\n    -   $x_3 = (-1, 1)$， $y_3 = -1$\n    -   $x_4 = (-1, -1)$， $y_4 = -1$\n-   **分类器：** $\\operatorname{sign}(w^{\\top} x + b)$，其中 $w \\in \\mathbb{R}^2$ 且 $b \\in \\mathbb{R}$。\n-   **SVM 原始问题：** 最小化 $\\|w\\|_2^2$，约束条件为 $y_i(w^{\\top} x_i + b) \\ge 1$，其中 $i \\in \\{1, 2, 3, 4\\}$。\n-   **任务：** 推导最大间隔分离器并计算：\n    1.  几何间隔。\n    2.  支持向量的索引。\n-   **答案格式：** 一个单个行矩阵，第一项为几何间隔，其后是按升序排列的支持向量索引。\n\n**1.2. 使用提取的已知条件进行验证**\n-   **科学依据：**该问题是硬间隔 SVM 算法的一个标准应用，这是机器学习和统计学习理论中的一个基本概念。其数学表述是正确的。\n-   **适定性：**所提供的数据集是线性可分的。对于线性可分的数据集，硬间隔 SVM 问题是一个凸优化问题，其对于权重向量 $w$ 和偏置 $b$ 具有唯一解。要推导的量（几何间隔，支持向量）基于此解是良定义的。\n-   **客观性：**该问题使用精确的数学语言和定义进行陈述。没有主观或模棱两可的术语。\n\n**1.3. 结论**\n该问题有效。它在科学上是合理的、自洽的且适定的。\n\n### 步骤 2：求解推导\n\n硬间隔 SVM 的目标是找到一个能最大化到任一类别最近数据点距离的超平面。这等价于最小化 $\\frac{1}{2}\\|w\\|_2^2$，其约束条件是所有数据点都被正确分类，并且与决策边界的函数间隔至少为 $1$。\n\n优化问题是：\n$$\n\\min_{w, b} \\frac{1}{2} \\|w\\|_2^2 \\quad \\text{subject to} \\quad y_i(w^{\\top} x_i + b) \\ge 1, \\quad i=1, 2, 3, 4\n$$\n设 $w = \\begin{pmatrix} w_1 \\\\ w_2 \\end{pmatrix}$。四个数据点的约束条件是：\n1.  对于 $x_1 = (1, 1), y_1 = +1$：\n    $$+1(w^{\\top}x_1 + b) \\ge 1 \\implies w_1 \\cdot 1 + w_2 \\cdot 1 + b \\ge 1 \\implies w_1 + w_2 + b \\ge 1$$\n2.  对于 $x_2 = (1, -1), y_2 = +1$：\n    $$+1(w^{\\top}x_2 + b) \\ge 1 \\implies w_1 \\cdot 1 + w_2 \\cdot (-1) + b \\ge 1 \\implies w_1 - w_2 + b \\ge 1$$\n3.  对于 $x_3 = (-1, 1), y_3 = -1$：\n    $$-1(w^{\\top}x_3 + b) \\ge 1 \\implies -1(w_1 \\cdot (-1) + w_2 \\cdot 1 + b) \\ge 1 \\implies w_1 - w_2 - b \\ge 1$$\n4.  对于 $x_4 = (-1, -1), y_4 = -1$：\n    $$-1(w^{\\top}x_4 + b) \\ge 1 \\implies -1(w_1 \\cdot (-1) + w_2 \\cdot (-1) + b) \\ge 1 \\implies w_1 + w_2 - b \\ge 1$$\n\n类别 $+1$ 的数据点是 $\\{ (1, 1), (1, -1) \\}$，类别 $-1$ 的数据点是 $\\{ (-1, 1), (-1, -1) \\}$。这两类被一条垂直线分开。根据对称性，最优分离超平面必然是一条形式为 $x_1 = c$ 的垂直线，其中 $c$ 为某个常数。\n超平面 $w^{\\top}x + b = 0$ 是垂直的，当且仅当 $w_2 = 0$。所以我们可以设置 $w_2 = 0$。\n\n问题简化为在 $w_2=0$ 的约束下最小化 $\\frac{1}{2}w_1^2$：\n1.  $w_1 + b \\ge 1$\n2.  $w_1 + b \\ge 1$\n3.  $w_1 - b \\ge 1$\n4.  $w_1 - b \\ge 1$\n\n这些可以简化为两个不同的不等式：\n(A) $w_1 + b \\ge 1$\n(B) $w_1 - b \\ge 1$\n\n为确保正确分类，我们需要 $\\operatorname{sign}(w_1 x_{i1} + b) = y_i$。对于 $x_1=(1,1), y_1=1$，我们需要 $w_1+b > 0$，这由 (A) 满足。对于 $x_3=(-1,1), y_3=-1$，我们需要 $-w_1+b  0 \\implies w_1 > b$，这由 (B) 满足，因为 $w_1 \\ge 1+b$。将 (A) 和 (B) 两个不等式相加得到 $2w_1 \\ge 2$，所以 $w_1 \\ge 1$。这意味着 $w_1$ 必须是正数。\n\n为了最小化 $w_1^2$（或 $\\frac{1}{2}w_1^2$），我们需要找到 $|w_1|$ 的最小可能值。因为 $w_1 \\ge 1$，所以当 $w_1$ 尽可能接近 $0$ 时，$w_1^2$ 取得最小值，此时 $w_1 = 1$。\n\n现在我们求 $b$ 的值。将 $w_1 = 1$ 代入不等式：\n(A) $1 + b \\ge 1 \\implies b \\ge 0$\n(B) $1 - b \\ge 1 \\implies -b \\ge 0 \\implies b \\le 0$\n唯一同时满足 $b \\ge 0$ 和 $b \\le 0$ 的 $b$ 值是 $b=0$。\n\n因此，分离超平面的最优参数是 $w = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ 和 $b = 0$。决策边界是 $w^{\\top}x + b = 0$，即 $1 \\cdot x_1 + 0 \\cdot x_2 + 0 = 0$，或 $x_1 = 0$。\n\n**几何间隔的计算**\n几何间隔 $\\gamma$ 定义为决策边界到最近训练样本的距离。对于硬间隔 SVM，这个距离由 $\\gamma = \\frac{1}{\\|w\\|_2}$ 给出。\n当 $w = (1, 0)^{\\top}$ 时，欧几里得范数是：\n$$\n\\|w\\|_2 = \\sqrt{w_1^2 + w_2^2} = \\sqrt{1^2 + 0^2} = 1\n$$\n因此，几何间隔是：\n$$\n\\gamma = \\frac{1}{1} = 1\n$$\n\n**支持向量的确定**\n支持向量是那些恰好位于间隔超平面上的数据点 $x_i$，即那些使不等式约束变为等式（激活）的点：\n$$\ny_i (w^{\\top}x_i + b) = 1\n$$\n让我们用我们的解 $w=(1, 0)^{\\top}$ 和 $b=0$ 来检验这四个点：\n1.  样本 1：$y_1(w^{\\top}x_1 + b) = +1(1 \\cdot 1 + 0 \\cdot 1 + 0) = 1$。约束被激活。\n2.  样本 2：$y_2(w^{\\top}x_2 + b) = +1(1 \\cdot 1 + 0 \\cdot (-1) + 0) = 1$。约束被激活。\n3.  样本 3：$y_3(w^{\\top}x_3 + b) = -1(1 \\cdot (-1) + 0 \\cdot 1 + 0) = -1(-1) = 1$。约束被激活。\n4.  样本 4：$y_4(w^{\\top}x_4 + b) = -1(1 \\cdot (-1) + 0 \\cdot (-1) + 0) = -1(-1) = 1$。约束被激活。\n\n由于所有四个数据点的约束都被激活，因此所有四个点都是支持向量。它们的索引是 $1, 2, 3, 4$。\n\n**最终答案的构建**\n要求的输出是一个行矩阵，包含几何间隔，后面跟着按升序排列的支持向量的索引。\n-   几何间隔: $1$\n-   支持向量索引: $1, 2, 3, 4$\n得到的行矩阵是 $\\begin{pmatrix} 1  1  2  3  4 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1  1  2  3  4 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "在实际的影像组学研究中，我们常常会遇到同时考验我们对监督和无监督学习理解的复杂问题，例如不同扫描仪带来的“批次效应”。本练习模拟了这一情景，要求你量化一种忽略扫描仪信息的“无监督”标准化方法所引入的偏差。通过推导，你将学会如何利用扫描仪标签这一“监督”信息来构建一个更准确的校正模型，从而深刻体会不同学习范式在解决实际问题时的优劣。",
            "id": "4561535",
            "problem": "在一项计算机断层扫描（CT）的影像组学研究中，体素强度以亨氏单位（HU）来衡量。考虑两批患者：扫描仪 A 有 $n_A=70$ 名患者，扫描仪 B 有 $n_B=50$ 名患者。由于已知的硬件校准偏移，对于健康组织，扫描仪 B 相对于扫描仪 A 表现出 $\\delta=15$ HU 的全局强度偏移。假设在每台扫描仪内部，给定的影像组学强度特征 $X$ 服从一个分布，其扫描仪内部标准差 $\\sigma$ 相同，而特定于扫描仪的均值分别为 $\\mu_A$ 和 $\\mu_B=\\mu_A+\\delta$。令合并z分数归一化定义为 $z=(x-\\mu_{\\text{pool}})/s_{\\text{pool}}$，其中 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 是根据合并的 $n_A+n_B$ 个观测值计算出的样本均值和样本标准差，计算时忽略了扫描仪的身份（无监督）。\n\n从z分数归一化、全期望定律以及混合分布的全方差定律的基本定义出发，推导在每个扫描仪队列中，合并z分数的期望均值和方差，从而量化当存在已知的扫描仪间偏移 $\\delta$ 时，合并归一化所引入的偏差。然后，计算特定于扫描仪的校正后标准化参数，这些参数使用扫描仪标签（有监督）来消除扫描仪间的偏移，并将这些参数纯粹用合并统计量 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、样本量 $n_A$、$n_B$ 和已知偏移 $\\delta$ 来表示。\n\n您的最终表达式必须消除未知数 $\\mu_A$ 和 $\\sigma$，并且只依赖于 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、$n_A$、$n_B$ 和 $\\delta$。将最终答案以单行矩阵的形式给出，按顺序包含：\n- 扫描仪 A 中的期望合并归一化均值，$\\mathbb{E}[z \\mid A]$。\n- 扫描仪 A 中的合并归一化方差，$\\operatorname{Var}(z \\mid A)$。\n- 扫描仪 B 中的期望合并归一化均值，$\\mathbb{E}[z \\mid B]$。\n- 扫描仪 B 中的合并归一化方差，$\\operatorname{Var}(z \\mid B)$。\n- 扫描仪 A 的校正后扫描仪内均值，$\\mu_A^{\\text{corr}}$。\n- 扫描仪 A 的校正后扫描仪内标准差，$\\sigma_A^{\\text{corr}}$。\n- 扫描仪 B 的校正后扫描仪内均值，$\\mu_B^{\\text{corr}}$。\n- 扫描仪 B 的校正后扫描仪内标准差，$\\sigma_B^{\\text{corr}}$。\n\n您的最终答案应以符号形式表示，并在适当位置嵌入给定的数值 $n_A=70$、$n_B=50$ 和 $\\delta=15$。无需进行四舍五入。最终的方框表达式中不要包含单位。",
            "solution": "首先验证问题，以确保其具有科学依据、是适定的和客观的。\n\n### 步骤 1：提取已知条件\n-   扫描仪 A 的患者数量：$n_A = 70$。\n-   扫描仪 B 的患者数量：$n_B = 50$。\n-   患者总数：$N = n_A + n_B = 120$。\n-   扫描仪 B 相对于 A 的强度偏移：$\\delta = 15$ HU。\n-   来自扫描仪 A 的影像组学特征 $X$ 是一个随机变量，其均值为 $\\mu_A$，标准差为 $\\sigma$。\n-   来自扫描仪 B 的同一特征 $X$ 是一个随机变量，其均值为 $\\mu_B = \\mu_A + \\delta$，标准差为 $\\sigma$。\n-   合并z分数归一化定义为 $z = (x - \\mu_{\\text{pool}}) / s_{\\text{pool}}$，其中 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 是来自合并的 $n_A+n_B$ 个观测值的样本均值和样本标准差。\n-   任务是推导 $\\mathbb{E}[z \\mid A]$、$\\operatorname{Var}(z \\mid A)$、$\\mathbb{E}[z \\mid B]$、$\\operatorname{Var}(z \\mid B)$ 的表达式，以及校正后的标准化参数 $\\mu_A^{\\text{corr}}$、$\\sigma_A^{\\text{corr}}$、$\\mu_B^{\\text{corr}}$、$\\sigma_B^{\\text{corr}}$。\n-   最终表达式必须用 $\\mu_{\\text{pool}}$、$s_{\\text{pool}}$、$n_A$、$n_B$ 和 $\\delta$ 来表示。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题描述了医学影像数据分析中的一个真实场景，即校正批次效应或扫描仪效应。其统计模型是一个标准的混合模型。均值、方差、z分数归一化、全期望定律和全方差定律等概念都是基本的统计学原理。该问题定义明确、客观，并包含足够的信息，可以在一个合理的假设下（即样本统计量 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 是混合分布的真实总体矩的良好估计）推导出唯一解。因此，该问题被认为是有效的。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整解答。\n\n### 推导过程\n设 $K$ 为一个指示扫描仪的随机变量，其取值为 A 和 B。一个观测值来自每台扫描仪的概率是其样本比例：\n$$p_A = P(K=A) = \\frac{n_A}{n_A + n_B} = \\frac{70}{120} = \\frac{7}{12}$$\n$$p_B = P(K=B) = \\frac{n_B}{n_A + n_B} = \\frac{50}{120} = \\frac{5}{12}$$\n给定的条件矩为：\n$\\mathbb{E}[X \\mid K=A] = \\mu_A$\n$\\mathbb{E}[X \\mid K=B] = \\mu_B = \\mu_A + \\delta$\n$\\operatorname{Var}(X \\mid K=A) = \\operatorname{Var}(X \\mid K=B) = \\sigma^2$\n\n我们将未知参数 $\\mu_A$ 和 $\\sigma$ 与给定的合并样本统计量 $\\mu_{\\text{pool}}$ 和 $s_{\\text{pool}}$ 联系起来。我们使用的原理是，对于大样本，样本统计量是混合分布真实总体矩的可靠估计。\n\n首先，我们将全期望定律应用于合并数据：\n$$\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X \\mid K]] = \\mathbb{E}[X \\mid A] p_A + \\mathbb{E}[X \\mid B] p_B$$\n用 $\\mu_{\\text{pool}}$ 近似 $\\mathbb{E}[X]$：\n$$\\mu_{\\text{pool}} \\approx \\mu_A p_A + (\\mu_A + \\delta) p_B = \\mu_A (p_A + p_B) + \\delta p_B = \\mu_A + \\delta p_B$$\n由此，我们可以用已知量表示未知数 $\\mu_A$：\n$$\\mu_A \\approx \\mu_{\\text{pool}} - \\delta p_B = \\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}$$\n\n接着，我们应用全方差定律：\n$$\\operatorname{Var}(X) = \\mathbb{E}[\\operatorname{Var}(X \\mid K)] + \\operatorname{Var}(\\mathbb{E}[X \\mid K])$$\n用 $s_{\\text{pool}}^2$ 近似 $\\operatorname{Var}(X)$：\n第一项是扫描仪内部方差的平均值：\n$$\\mathbb{E}[\\operatorname{Var}(X \\mid K)] = \\operatorname{Var}(X \\mid A) p_A + \\operatorname{Var}(X \\mid B) p_B = \\sigma^2 p_A + \\sigma^2 p_B = \\sigma^2$$\n第二项是条件期望的方差（扫描仪间方差）：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = \\mathbb{E}[(\\mathbb{E}[X \\mid K])^2] - (\\mathbb{E}[\\mathbb{E}[X \\mid K]])^2$$\n$$= (\\mu_A^2 p_A + \\mu_B^2 p_B) - (\\mu_{\\text{pool}})^2$$\n一个更直接的方法是：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) = (\\mathbb{E}[X \\mid A] - \\mathbb{E}[X])^2 p_A + (\\mathbb{E}[X \\mid B] - \\mathbb{E}[X])^2 p_B$$\n$$ \\approx (\\mu_A - \\mu_{\\text{pool}})^2 p_A + (\\mu_B - \\mu_{\\text{pool}})^2 p_B$$\n代入 $\\mu_A \\approx \\mu_{\\text{pool}} - \\delta p_B$ 和 $\\mu_B = \\mu_A + \\delta \\approx \\mu_{\\text{pool}} + \\delta(1-p_B) = \\mu_{\\text{pool}} + \\delta p_A$：\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) \\approx (-\\delta p_B)^2 p_A + (\\delta p_A)^2 p_B = \\delta^2 p_B^2 p_A + \\delta^2 p_A^2 p_B = \\delta^2 p_A p_B (p_A + p_B) = \\delta^2 p_A p_B$$\n$$\\operatorname{Var}(\\mathbb{E}[X \\mid K]) \\approx \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n合并各项得到总方差：\n$$s_{\\text{pool}}^2 \\approx \\sigma^2 + \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n由此，我们用已知量表示未知数 $\\sigma^2$：\n$$\\sigma^2 \\approx s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}$$\n\n现在我们可以推导前四个所需的量。合并z分数变换为 $z(x) = (x - \\mu_{\\text{pool}}) / s_{\\text{pool}}$。\n\n1.  **扫描仪 A 中的期望合并归一化均值 $\\mathbb{E}[z \\mid A]$**：\n    $$\\mathbb{E}[z \\mid A] = \\mathbb{E}\\left[\\frac{X - \\mu_{\\text{pool}}}{s_{\\text{pool}}} \\mid A \\right] = \\frac{\\mathbb{E}[X \\mid A] - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\mu_A - \\mu_{\\text{pool}}}{s_{\\text{pool}}}$$\n    代入我们关于 $\\mu_A$ 的表达式：\n    $$\\mathbb{E}[z \\mid A] \\approx \\frac{(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A+n_B}) - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = -\\frac{\\delta}{s_{\\text{pool}}} \\frac{n_B}{n_A+n_B}$$\n\n2.  **扫描仪 A 中的合并归一化方差 $\\operatorname{Var}(z \\mid A)$**：\n    $$\\operatorname{Var}(z \\mid A) = \\operatorname{Var}\\left(\\frac{X - \\mu_{\\text{pool}}}{s_{\\text{pool}}} \\mid A \\right) = \\frac{\\operatorname{Var}(X \\mid A)}{s_{\\text{pool}}^2} = \\frac{\\sigma^2}{s_{\\text{pool}}^2}$$\n    代入我们关于 $\\sigma^2$ 的表达式：\n    $$\\operatorname{Var}(z \\mid A) \\approx \\frac{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A+n_B)^2}}{s_{\\text{pool}}^2} = 1 - \\frac{\\delta^2}{s_{\\text{pool}}^2} \\frac{n_A n_B}{(n_A+n_B)^2}$$\n\n3.  **扫描仪 B 中的期望合并归一化均值 $\\mathbb{E}[z \\mid B]$**：\n    $$\\mathbb{E}[z \\mid B] = \\frac{\\mathbb{E}[X \\mid B] - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\mu_B - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{(\\mu_A + \\delta) - \\mu_{\\text{pool}}}{s_{\\text{pool}}}$$\n    代入我们关于 $\\mu_A$ 的表达式：\n    $$\\mathbb{E}[z \\mid B] \\approx \\frac{(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A+n_B} + \\delta) - \\mu_{\\text{pool}}}{s_{\\text{pool}}} = \\frac{\\delta(1 - \\frac{n_B}{n_A+n_B})}{s_{\\text{pool}}} = \\frac{\\delta}{s_{\\text{pool}}} \\frac{n_A}{n_A+n_B}$$\n\n4.  **扫描仪 B 中的合并归一化方差 $\\operatorname{Var}(z \\mid B)$**：\n    $$\\operatorname{Var}(z \\mid B) = \\frac{\\operatorname{Var}(X \\mid B)}{s_{\\text{pool}}^2} = \\frac{\\sigma^2}{s_{\\text{pool}}^2}$$\n    这与扫描仪 A 的方差相同：\n    $$\\operatorname{Var}(z \\mid B) \\approx 1 - \\frac{\\delta^2}{s_{\\text{pool}}^2} \\frac{n_A n_B}{(n_A+n_B)^2}$$\n\n结果表明，合并归一化在每个子组的均值中引入了偏差（$\\mathbb{E}[z \\mid A] \\neq 0$ 且 $\\mathbb{E}[z \\mid B] \\neq 0$），并减小了组内方差（$\\operatorname{Var}(z \\mid K)  1$），这是因为合并方差 $s_{\\text{pool}}^2$ 被扫描仪间的方差分量所夸大。\n\n最后，我们推导校正后的（有监督）标准化参数。这些参数应对应于每个扫描仪队列内的真实均值和标准差。\n5.  **扫描仪 A 的校正后均值 $\\mu_A^{\\text{corr}}$**：这就是 $\\mu_A$。\n    $$\\mu_A^{\\text{corr}} = \\mu_A \\approx \\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}$$\n\n6.  **扫描仪 A 的校正后标准差 $\\sigma_A^{\\text{corr}}$**：这就是 $\\sigma$。\n    $$\\sigma_A^{\\text{corr}} = \\sigma \\approx \\sqrt{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}}$$\n\n7.  **扫描仪 B 的校正后均值 $\\mu_B^{\\text{corr}}$**：这是 $\\mu_B = \\mu_A + \\delta$。\n    $$\\mu_B^{\\text{corr}} = \\mu_A + \\delta \\approx \\left(\\mu_{\\text{pool}} - \\delta \\frac{n_B}{n_A + n_B}\\right) + \\delta = \\mu_{\\text{pool}} + \\delta \\frac{n_A}{n_A + n_B}$$\n\n8.  **扫描仪 B 的校正后标准差 $\\sigma_B^{\\text{corr}}$**：这也是 $\\sigma$，因为假设扫描仪内部标准差是相同的。\n    $$\\sigma_B^{\\text{corr}} = \\sigma \\approx \\sqrt{s_{\\text{pool}}^2 - \\delta^2 \\frac{n_A n_B}{(n_A + n_B)^2}}$$\n\n现在我们代入给定的数值：$n_A = 70$，$n_B = 50$，$N = n_A+n_B = 120$ 和 $\\delta = 15$。\n常数因子为：\n$\\frac{n_B}{N} = \\frac{50}{120} = \\frac{5}{12}$\n$\\frac{n_A}{N} = \\frac{70}{120} = \\frac{7}{12}$\n$\\frac{n_A n_B}{N^2} = \\frac{70 \\times 50}{120^2} = \\frac{3500}{14400} = \\frac{35}{144}$\n\n-   $\\mathbb{E}[z \\mid A] \\approx -\\frac{15}{s_{\\text{pool}}} \\left(\\frac{5}{12}\\right) = -\\frac{75}{12 s_{\\text{pool}}} = -\\frac{25}{4 s_{\\text{pool}}}$。\n-   $\\operatorname{Var}(z \\mid A) \\approx 1 - \\frac{15^2}{s_{\\text{pool}}^2} \\left(\\frac{35}{144}\\right) = 1 - \\frac{225 \\times 35}{144 s_{\\text{pool}}^2} = 1 - \\frac{7875}{144 s_{\\text{pool}}^2} = 1 - \\frac{875}{16 s_{\\text{pool}}^2}$。\n-   $\\mathbb{E}[z \\mid B] \\approx \\frac{15}{s_{\\text{pool}}} \\left(\\frac{7}{12}\\right) = \\frac{105}{12 s_{\\text{pool}}} = \\frac{35}{4 s_{\\text{pool}}}$。\n-   $\\operatorname{Var}(z \\mid B) \\approx 1 - \\frac{875}{16 s_{\\text{pool}}^2}$。\n-   $\\mu_A^{\\text{corr}} \\approx \\mu_{\\text{pool}} - 15 \\left(\\frac{5}{12}\\right) = \\mu_{\\text{pool}} - \\frac{75}{12} = \\mu_{\\text{pool}} - \\frac{25}{4}$。\n-   $\\sigma_A^{\\text{corr}} \\approx \\sqrt{s_{\\text{pool}}^2 - 15^2 \\left(\\frac{35}{144}\\right)} = \\sqrt{s_{\\text{pool}}^2 - \\frac{7875}{144}} = \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}$。\n-   $\\mu_B^{\\text{corr}} \\approx \\mu_{\\text{pool}} + 15 \\left(\\frac{7}{12}\\right) = \\mu_{\\text{pool}} + \\frac{105}{12} = \\mu_{\\text{pool}} + \\frac{35}{4}$。\n-   $\\sigma_B^{\\text{corr}} \\approx \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}$。\n\n这八个表达式构成了最终答案。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{25}{4 s_{\\text{pool}}}  1 - \\frac{875}{16 s_{\\text{pool}}^2}  \\frac{35}{4 s_{\\text{pool}}}  1 - \\frac{875}{16 s_{\\text{pool}}^2}  \\mu_{\\text{pool}} - \\frac{25}{4}  \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}  \\mu_{\\text{pool}} + \\frac{35}{4}  \\sqrt{s_{\\text{pool}}^2 - \\frac{875}{16}}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}