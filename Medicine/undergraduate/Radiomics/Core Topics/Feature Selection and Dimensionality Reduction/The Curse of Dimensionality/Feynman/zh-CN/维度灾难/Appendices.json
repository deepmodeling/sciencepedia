{
    "hands_on_practices": [
        {
            "introduction": "我们对维度诅咒的探索始于一个看似简单的问题：构建一个直方图。在低维度空间中，这是一种直观的数据可视化方法，但在高维度下，维持相同的数据密度需要多少样本呢？这个练习通过一个具体的计算，揭示了覆盖高维空间所需数据量的爆炸性增长，从而直观地展示了数据稀疏性问题。",
            "id": "2439690",
            "problem": "在一个计算金融场景中，假设您正在为一个包含 $d=10$ 个风险因子的状态向量构建一个基于非参数直方图的联合密度估计器，以研究投资组合的风险价值（VaR）动态。您将每个维度离散化为 $b=3$ 个等宽的区间，从而在联合状态空间上创建一个规则网格。如果您要求数据集平均每个网格单元恰好有 $1$ 个观测值，那么需要多少个观测值？请以精确整数形式提供您的答案，不要四舍五入。",
            "solution": "首先对问题陈述进行验证。\n\n逐字提取已知条件：\n1.  领域：计算金融。\n2.  主题背景：用于状态向量的基于非参数直方图的联合密度估计器。\n3.  维度数量（风险因子）：$d=10$。\n4.  每个维度的区间数量：$b=3$。\n5.  网格结构：联合状态空间上的规则网格。\n6.  所需数据密度：平均每个网格单元恰好有 $1$ 个观测值。\n7.  问题：需要多少个观测值？\n8.  答案格式：精确整数，不四舍五入。\n\n根据验证标准对问题进行评估。\n-   **科学依据**：该问题在非参数统计和计算金融的背景下被正确地构建。离散化多维空间以及由此导致的数据需求指数级增长（维度灾难）的概念是一个标准且基础的课题。该前提在科学上是合理的。\n-   **适定性**：该问题是适定的。它提供了计算唯一解所需的所有必要参数（$d$、$b$ 和目标数据密度）。问题是明确的。\n-   **客观性**：该问题以客观、正式的语言陈述，不含主观或推测性内容。\n\n该问题被认为是有效的，因为它没有违反任何指定的无效标准。这是一个直接、定义明确的定量问题。我们可以继续进行求解。\n\n设 $d$ 为状态向量的维度数，设 $b$ 为每个维度被离散化成的区间数。根据问题陈述，我们有 $d=10$ 和 $b=3$。\n\n基于直方图的密度估计器是在一个 $d$ 维空间中的规则网格上构建的。此网格中的单元（或超立方体）总数，我们记为 $N_{cells}$，是沿着 $d$ 个维度中每个维度的区间数量的乘积。由于每个维度被划分为 $b$ 个区间，因此单元总数为：\n$$\nN_{cells} = \\underbrace{b \\times b \\times \\cdots \\times b}_{d \\text{ 次}} = b^d\n$$\n问题规定数据集必须平均每个网格单元恰好包含 $1$ 个观测值。设 $N_{obs}$ 为所需的观测总数。每个单元的平均观测数是观测总数与单元总数的比率：\n$$\n\\text{每个单元的平均观测数} = \\frac{N_{obs}}{N_{cells}}\n$$\n根据问题的要求，这个平均值必须等于 $1$：\n$$\n\\frac{N_{obs}}{N_{cells}} = 1\n$$\n这意味着所需的观测数量必须等于网格中的单元总数：\n$$\nN_{obs} = N_{cells}\n$$\n代入 $N_{cells}$ 的表达式，我们得到所需观测数量作为 $d$ 和 $b$ 的函数：\n$$\nN_{obs} = b^d\n$$\n现在，我们将提供的数值 $d=10$ 和 $b=3$ 代入此方程，以求出所需的具体观测数量。\n$$\nN_{obs} = 3^{10}\n$$\n我们计算此表达式的精确整数值：\n$$\n3^{10} = (3^2)^5 = 9^5 = 9 \\times 9 \\times 9 \\times 9 \\times 9 = 81 \\times 81 \\times 9 = 6561 \\times 9\n$$\n执行最后的乘法：\n$$\n6561 \\times 9 = 59049\n$$\n因此，总共需要 $59049$ 个观测值。这个结果鲜明地说明了维度灾难：即使每个维度只进行粗略的 $3$ 个区间的离散化，覆盖一个 $10$ 维空间所需的数据量也变得相当巨大。",
            "answer": "$$\n\\boxed{59049}\n$$"
        },
        {
            "introduction": "理解了数据稀疏性之后，我们来探究其背后的反直觉几何学。我们在二维或三维空间中形成的直觉在高维空间中往往是错误的。这个练习通过一个经典的思维实验——比较一个高维球体与其外切超立方体的体积比——来揭示高维空间中大部分体积如何集中在“角落”里，从而帮助我们理解为什么采样算法会失效以及为什么所有的数据点看起来都“距离遥远”。",
            "id": "2439712",
            "problem": "一位计量经济学家在一个高维结构模型的蒙特卡洛 (MC) 估计量中实现了一个拒绝抽样步骤。每次抽样时，从超立方体 $\\left[-r, r\\right]^{d}$ 中均匀抽取一个点，当且仅当其欧几里得范数小于或等于 $r$ 时，该点被接受。接受概率等于半径为 $r$ 的 $d$ 维超球体的体积与边长为 $2 r$ 的 $d$ 维超立方体的体积之比。对于一个固定的半径 $r>0$，确定当维度 $d \\to \\infty$ 时接受概率的极限。请用一个数字给出最终答案。无需四舍五入。",
            "solution": "第一步是验证问题陈述。该问题要求解一个高维空间中拒绝抽样方案的极限接受概率。\n\n已知条件如下：\n1.  从超立方体 $[-r, r]^d$ 中均匀抽取一个点。\n2.  如果该点的欧几里得范数小于或等于 $r$，则该点被接受。\n3.  接受概率 $P_d$ 是半径为 $r$ 的 $d$ 维超球体的体积与边长为 $2r$ 的 $d$ 维超立方体的体积之比。\n4.  半径 $r > 0$ 是一个固定的正常数。\n5.  目标是确定当维度 $d \\to \\infty$ 时 $P_d$ 的极限。\n\n该问题具有科学依据，因为它涉及概率论、高维几何和计算统计学（蒙特卡洛方法）中的标准概念。它所描述的现象是“维度灾难”的一个著名例子。该问题是适定的，提供了推导唯一解所需的所有信息。语言客观而精确。因此，该问题是有效的，我们可以继续求解。\n\n令 $V_{sphere}(d, r)$ 表示半径为 $r$ 的 $d$ 维超球体的体积。令 $V_{cube}(d, r)$ 表示顶点在 $(\\pm r, \\pm r, \\dots, \\pm r)$ 的 $d$ 维超立方体的体积。\n\n超立方体 $[-r, r]^d$ 的边长为 $r - (-r) = 2r$。该超立方体的体积是其边长的乘积：\n$$ V_{cube}(d, r) = (2r)^d = 2^d r^d $$\n\n半径为 $r$ 的 $d$ 维超球体（或 $d$-球）的体积由以下公式给出：\n$$ V_{sphere}(d, r) = \\frac{\\pi^{d/2}}{\\Gamma\\left(\\frac{d}{2} + 1\\right)} r^d $$\n其中 $\\Gamma(z)$ 是伽马函数，是阶乘函数的推广。\n\n接受概率 $P_d$ 是这两个体积之比：\n$$ P_d = \\frac{V_{sphere}(d, r)}{V_{cube}(d, r)} = \\frac{\\frac{\\pi^{d/2}}{\\Gamma\\left(\\frac{d}{2} + 1\\right)} r^d}{2^d r^d} $$\n项 $r^d$ 被消去，这是预料之中的，因为在同一维度中相似缩放的物体的体积之比与缩放因子 $r$ 无关。\n$$ P_d = \\frac{\\pi^{d/2}}{2^d \\Gamma\\left(\\frac{d}{2} + 1\\right)} $$\n为了分析当 $d \\to \\infty$ 时的极限，我们可以将表达式重写为：\n$$ P_d = \\frac{(\\sqrt{\\pi})^d}{2^d \\Gamma\\left(\\frac{d}{2} + 1\\right)} = \\frac{\\left(\\frac{\\sqrt{\\pi}}{2}\\right)^d}{\\Gamma\\left(\\frac{d}{2} + 1\\right)} $$\n我们现在必须评估当 $d \\to \\infty$ 时此表达式的极限。让我们分别考察分子和分母。\n\n对于分子，我们有项 $\\left(\\frac{\\sqrt{\\pi}}{2}\\right)^d$。由于 $\\pi$ 的值约为 $3.14159$，$\\sqrt{\\pi}$ 约为 $1.77245$。指数的底为 $\\frac{\\sqrt{\\pi}}{2} \\approx 0.88622$。由于这个底是一个严格小于 $1$ 的正常数，当指数趋于无穷大时，其极限为 $0$：\n$$ \\lim_{d \\to \\infty} \\left(\\frac{\\sqrt{\\pi}}{2}\\right)^d = 0 $$\n\n对于分母，我们有项 $\\Gamma\\left(\\frac{d}{2} + 1\\right)$。当 $d \\to \\infty$ 时，伽马函数的自变量 $\\frac{d}{2} + 1$ 也趋于无穷大。伽马函数 $\\Gamma(z)$ 具有性质 $\\lim_{z \\to \\infty} \\Gamma(z) = \\infty$。因此：\n$$ \\lim_{d \\to \\infty} \\Gamma\\left(\\frac{d}{2} + 1\\right) = \\infty $$\n\n我们现在评估的是一个分数的极限，其中分子趋于 $0$ 而分母趋于 $\\infty$。这样的极限明确地为 $0$。\n$$ \\lim_{d \\to \\infty} P_d = \\lim_{d \\to \\infty} \\frac{\\left(\\frac{\\sqrt{\\pi}}{2}\\right)^d}{\\Gamma\\left(\\frac{d}{2} + 1\\right)} = 0 $$\n这一结果表明，随着空间维度的增加，该拒绝抽样方案的接受概率收敛到零。这意味着对于高维度，必须从超立方体中抽取指数级数量的样本才能找到一个位于内切超球体内的样本，从而使得该方法在计算上不可行。这是维度灾难的一个典型表现。极限接受概率为 $0$。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "最后，我们将抽象的几何概念和数据稀疏性问题与一个实际的统计学习挑战联系起来。当特征维度相对于样本量非常高时，我们应该选择一个更简单但可能存在偏差的模型，还是一个更复杂但容易过拟合的模型？本练习通过比较线性和二次判别分析（LDA 与 QDA），生动地展示了维度诅咒如何通过增加模型参数（数量级为 $O(d^2)$）的估计误差来影响模型性能，并突出了在高维场景下偏差-方差权衡的重要性。",
            "id": "3181701",
            "problem": "考虑一个二元分类问题，其中特征向量 $X \\in \\mathbb{R}^d$ 和类别标签 $Y \\in \\{0,1\\}$ 满足以下生成性假设：对于 $k \\in \\{0,1\\}$，类条件分布为多元正态分布 $X \\mid Y=k \\sim \\mathcal{N}(\\mu_k,\\Sigma_k)$，其均值 $\\mu_k \\in \\mathbb{R}^d$ 和正定协方差 $\\Sigma_k \\in \\mathbb{R}^{d \\times d}$ 均为未知。在参数已知的情况下，最小化错分概率的分类器是贝叶斯分类器，它通过比较从高斯似然函数导出的后验概率来进行决策。在实践中，当参数未知时，人们使用基于从大小为 $n$ 的训练样本中计算出的最大似然估计的代入式分类器；在平衡情况下，每个类别提供 $n/2$ 个样本。\n\n线性判别分析 (LDA) 假设 $\\Sigma_0=\\Sigma_1:=\\Sigma$，并从所有训练样本中估计一个共享的协方差矩阵。而二次判别分析 (QDA) 允许 $\\Sigma_0 \\neq \\Sigma_1$，并为每个类别估计一个独立的协方差矩阵。两种方法都估计类别均值 $\\mu_0$ 和 $\\mu_1$。假设训练集是平衡的，并且相对于 $n$ 而言，$d$ 很大，这是一种由于参数空间增长而导致估计误差受到“维度灾难”影响的典型情况。\n\n假设 $d=80$，$n=150$，每个类别有 $n/2=75$ 个样本。你通过最大似然法拟合 LDA 和 QDA，并使用从高斯模型导出的代入式判别函数（不进行任何正则化或降维）。\n\n选择所有能正确描述为什么在这种高维小样本情况下，LDA 的性能通常优于 QDA，甚至在操作上更稳定的陈述：\n\nA. QDA 估计两个协方差矩阵，每个矩阵有 $d(d+1)/2$ 个自由参数，总共有 $d(d+1)$ 个协方差参数；而 LDA 只估计一个协方差矩阵，有 $d(d+1)/2$ 个参数。当 $d$ 相对于 $n$ 较大时，QDA 参数数量的这种 $O(d^2)$ 增长会增加估计量的方差。\n\nB. 在 $n/2=75$ 和 $d=80$ 的情况下，QDA 中每个类别特定的样本协方差矩阵都是奇异的，因为其秩最多为 $n/2-1=74  80=d$。这使得标准的 QDA 判别函数在数学上无法计算，因为它需要对这些矩阵求逆。相比之下，LDA 的合并协方差矩阵是从 $n-2=148$ 个自由度的基础上估计的，由于 $148 > 80=d$，因此它是可逆的（除非存在完全共线性）。\n\nC. QDA 作为一种更灵活、更复杂的模型，其参数估计存在高方差，容易过拟合。而 LDA 模型更简单，施加了更强的（可能不正确）假设，因此有更高的偏差但方差更低。在 $d \\gg n$ 的情况下，降低方差是提高泛化能力的关键，因此 LDA 通常表现更好。\n\nD. 必须使用严格的嵌套交叉验证来防止数据泄露，否则比较 LDA 和 QDA 的性能是没有意义的。\n\nE. 由于 QDA 的高度灵活性，它会紧密拟合训练数据，包括其中的噪声。这导致其泛化能力差，与更受约束的 LDA 模型相比，其样本外测试误差通常更高。",
            "solution": "本题旨在评估在高维小样本量（$d > n_k$）情境下，对线性判别分析（LDA）与二次判别分析（QDA）之间性能差异的理解。我们逐一分析每个陈述：\n\n- **情景设定**：维度 $d=80$，总样本量 $n=150$，每个类别的样本量为 $n_k=75$。这是一个典型的高维小样本（\"p is large, n is small\"）场景，特别是对于QDA，因为 $d > n_k$。\n\n- **陈述A分析**：此陈述关于要估计的参数数量。一个 $d \\times d$ 的协方差矩阵有 $d(d+1)/2$ 个独立参数。\n    - LDA 估计一个共享协方差矩阵，参数量为 $d(d+1)/2$。对于 $d=80$，这是 3240 个参数。\n    - QDA 估计两个独立的协方差矩阵，参数量为 $2 \\times d(d+1)/2 = d(d+1)$。对于 $d=80$，这是 6480 个参数。\n    该陈述准确地计算了参数数量。统计学的基本原理指出，用有限的数据估计更多的参数会增加估计量的方差。QDA 的参数数量以 $O(d^2)$ 的速度增长，需要从更少的数据（每个类别 $n_k=75$）中估计，这必然导致比 LDA 更高的方差。**因此，陈述A是正确的。**\n\n- **陈述B分析**：此陈述关于样本协方差矩阵的奇异性。\n    - 对于 QDA，每个协方差矩阵 $\\hat{\\Sigma}_k$ 是从 $n_k=75$ 个样本中估计的。样本协方差矩阵的秩最多为 $n_k-1=74$。由于矩阵的维度是 $d=80$，我们有 $\\text{rank}(\\hat{\\Sigma}_k) \\le 74  80$。这意味着矩阵是奇异的（不可逆）。标准的 QDA 需要计算 $\\hat{\\Sigma}_k^{-1}$，因此在这种情况下会失败。\n    - 对于 LDA，共享协方差矩阵 $\\hat{\\Sigma}$ 是从所有 $n=150$ 个样本中估计的。其秩最多为 $n-2=148$（假设均值也已估计）。由于 $\\text{rank}(\\hat{\\Sigma}) \\le 148 > 80=d$，只要数据中没有完全共线性，$\\hat{\\Sigma}$ 通常是满秩且可逆的。\n    该陈述准确地描述了 QDA 在此设置下的数学不稳定性以及 LDA 的相对稳定性。**因此，陈述B是正确的。**\n\n- **陈述C分析**：此陈述关于偏差-方差权衡。\n    - QDA 是一个更灵活的模型，因为它允许每个类别有自己的协方差结构。如果真实的 $\\Sigma_0 \\neq \\Sigma_1$，QDA 的偏差较低。然而，这种灵活性是有代价的：由于需要估计大量参数，其估计量的方差非常高。\n    - LDA 作出了一个更严格的假设（$\\Sigma_0 = \\Sigma_1$）。如果这个假设是错误的，LDA 会有较高的偏差。但由于它估计的参数较少且使用了更多数据，其方差要低得多。\n    - 在高维小样本场景中，方差通常是误差的主要来源。因此，尽管 LDA 可能有偏差，但其较低的方差使其泛化能力通常优于高方差的 QDA。**因此，陈述C是正确的。**\n\n- **陈述D分析**：此陈述关于数据泄露和交叉验证。这是一个关于正确评估模型性能的通用方法论要点。虽然它本身是一个正确的建议，但它并不解释 LDA 相对于 QDA 的**内在**优势或稳定性。问题的核心在于比较这两种模型固有的统计特性，而不是评估它们的程序。**因此，该陈述与问题不直接相关，不是一个正确的答案。**\n\n- **陈述E分析**：此陈述是陈述C中偏差-方差论点的直接结果。QDA 的高方差意味着它对训练数据的特定噪声和随机性非常敏感（即过拟合）。这自然会导致其在未见过的测试数据上表现不佳（即测试误差更高）。LDA 更为受限，不太可能过拟合，因此通常具有更好的泛化能力和更低的测试误差。**因此，陈述E是正确的。**\n\n综上所述，陈述A、B、C 和 E 都正确地描述了为什么在高维小样本量设置下 LDA 通常优于 QDA。",
            "answer": "$$\\boxed{ABCE}$$"
        }
    ]
}