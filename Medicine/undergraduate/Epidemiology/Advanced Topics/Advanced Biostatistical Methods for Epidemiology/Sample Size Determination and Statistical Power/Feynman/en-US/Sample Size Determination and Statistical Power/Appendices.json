{
    "hands_on_practices": [
        {
            "introduction": "Let's begin by building a solid intuition for what statistical power truly represents. Instead of starting with the question \"how many subjects do we need?\", this first exercise takes a planned study design with a fixed sample size and asks, \"What is our probability of detecting a meaningful effect if it truly exists?\". By working through this forward calculation , you will gain a concrete understanding of how study parameters like sample size and the magnitude of the true effect directly influence the power of your findings.",
            "id": "4633045",
            "problem": "A public health team designs a parallel two-arm randomized study to compare the cumulative incidence of a binary outcome (e.g., laboratory-confirmed infection over a fixed follow-up) between an intervention group and a control group. Let $X_1 \\sim \\mathrm{Binomial}(n_1,p_1)$ and $X_2 \\sim \\mathrm{Binomial}(n_2,p_2)$ denote the numbers of cases observed in the intervention and control arms, respectively, with corresponding sample proportions $\\hat{p}_1 = X_1/n_1$ and $\\hat{p}_2 = X_2/n_2$. Assume $X_1$ and $X_2$ are independent.\n\nUsing the Central Limit Theorem (CLT), treat the difference $\\hat{p}_1 - \\hat{p}_2$ as approximately normal under both the null and the alternative. Consider a two-sided test of equality of proportions at significance level $\\alpha = 0.05$ that rejects when the absolute difference is sufficiently large relative to its null variability. For determining the rejection threshold, take the null variability to be computed under $H_0: p_1 = p_2 = p_0$, where $p_0$ is the pooled common proportion implied by the equal allocation design, namely $p_0 = \\frac{n_1 p_1 + n_2 p_2}{n_1 + n_2}$.\n\nSuppose the true proportions are $p_1 = 0.25$ in the intervention arm and $p_2 = 0.20$ in the control arm, with equal sample sizes $n_1 = n_2 = 500$. Using the normal approximation to the difference in proportions and the two-sided critical value from the standard normal distribution consistent with $\\alpha = 0.05$, compute the statistical power of this test under the stated true proportions.\n\nExpress the final power as a decimal and round your answer to four significant figures.",
            "solution": "The objective is to calculate the statistical power of a two-sided test for the difference between two proportions. Power is the probability of correctly rejecting the null hypothesis ($H_0$) when a specific alternative hypothesis ($H_A$) is true.\n\n**1. Define Hypotheses and Parameters**\nThe null and alternative hypotheses are:\n$$H_0: p_1 = p_2$$\n$$H_A: p_1 \\neq p_2$$\nThe given parameters for the power calculation are:\n- True proportion in the intervention arm: $p_1 = 0.25$\n- True proportion in the control arm: $p_2 = 0.20$\n- Sample size per arm: $n_1 = n_2 = 500$\n- Significance level: $\\alpha = 0.05$\n\n**2. Determine the Rejection Region under the Null Hypothesis**\nThe test is based on the difference in sample proportions, $D = \\hat{p}_1 - \\hat{p}_2$. Under the CLT, $D$ is approximately normally distributed.\n\nUnder $H_0$, the expected value of the difference is $E[D|H_0] = p_1 - p_2 = 0$. The variance of $D$ under $H_0$ is calculated assuming a common proportion, which the problem specifies to be $p_0$.\nLet's first calculate $p_0$:\n$$p_0 = \\frac{n_1 p_1 + n_2 p_2}{n_1 + n_2} = \\frac{500(0.25) + 500(0.20)}{500 + 500} = \\frac{125 + 100}{1000} = \\frac{225}{1000} = 0.225$$\nThe standard error of the difference under the null hypothesis, $SE_0$, is:\n$$SE_0 = \\sqrt{p_0(1-p_0)\\left(\\frac{1}{n_1} + \\frac{1}{n_2}\\right)}$$\n$$SE_0 = \\sqrt{0.225(1-0.225)\\left(\\frac{1}{500} + \\frac{1}{500}\\right)} = \\sqrt{0.225(0.775)\\left(\\frac{2}{500}\\right)}$$\n$$SE_0 = \\sqrt{0.174375 \\times 0.004} = \\sqrt{0.0006975}$$\nFor a two-sided test with $\\alpha = 0.05$, the critical value from the standard normal distribution is $z_{\\alpha/2} = z_{0.025}$. The standard value used is approximately $1.96$. Using a more precise value, $z_{0.025} \\approx 1.959964$.\nThe null hypothesis is rejected if the absolute value of the observed difference is greater than a critical threshold, $C$:\n$$|\\hat{p}_1 - \\hat{p}_2| > z_{\\alpha/2} \\times SE_0$$\nSo the rejection region is defined by two critical values:\n$$C_{upper} = z_{\\alpha/2} \\times SE_0 \\approx 1.959964 \\times \\sqrt{0.0006975}$$\n$$C_{lower} = -z_{\\alpha/2} \\times SE_0 \\approx -1.959964 \\times \\sqrt{0.0006975}$$\n\n**3. Characterize the Distribution under the Alternative Hypothesis**\nUnder the alternative hypothesis, the true proportions are $p_1 = 0.25$ and $p_2 = 0.20$.\nThe distribution of the difference $D = \\hat{p}_1 - \\hat{p}_2$ is approximately normal with:\n- Mean: $\\mu_A = E[D|H_A] = p_1 - p_2 = 0.25 - 0.20 = 0.05$\n- Standard Error ($SE_A$):\n$$SE_A = \\sqrt{\\frac{p_1(1-p_1)}{n_1} + \\frac{p_2(1-p_2)}{n_2}}$$\n$$SE_A = \\sqrt{\\frac{0.25(0.75)}{500} + \\frac{0.20(0.80)}{500}} = \\sqrt{\\frac{0.1875}{500} + \\frac{0.16}{500}}$$\n$$SE_A = \\sqrt{\\frac{0.3475}{500}} = \\sqrt{0.000695}$$\nSo, under $H_A$, we have $(\\hat{p}_1 - \\hat{p}_2) \\sim N(\\mu_A = 0.05, SE_A^2 = 0.000695)$.\n\n**4. Calculate the Statistical Power**\nPower is the probability of the test statistic falling in the rejection region, given that the alternative hypothesis is true.\n$$\\text{Power} = P(D > C_{upper} | H_A) + P(D < C_{lower} | H_A)$$\nTo calculate these probabilities, we standardize the critical values $C_{upper}$ and $C_{lower}$ using the distribution under $H_A$:\n$$Z_{upper} = \\frac{C_{upper} - \\mu_A}{SE_A} = \\frac{z_{\\alpha/2} SE_0 - \\mu_A}{SE_A} = \\frac{1.959964 \\sqrt{0.0006975} - 0.05}{\\sqrt{0.000695}}$$\n$$Z_{lower} = \\frac{C_{lower} - \\mu_A}{SE_A} = \\frac{-z_{\\alpha/2} SE_0 - \\mu_A}{SE_A} = \\frac{-1.959964 \\sqrt{0.0006975} - 0.05}{\\sqrt{0.000695}}$$\nNow, we compute the numerical values:\n$SE_0 = \\sqrt{0.0006975} \\approx 0.0264098$\n$SE_A = \\sqrt{0.000695} \\approx 0.0263629$\n$\\mu_A = 0.05$\n$z_{\\alpha/2} \\approx 1.959964$\n\nThe numerator for $Z_{upper}$ is $(1.959964 \\times 0.0264098) - 0.05 \\approx 0.0517623 - 0.05 = 0.0017623$.\nThe numerator for $Z_{lower}$ is $(-1.959964 \\times 0.0264098) - 0.05 \\approx -0.0517623 - 0.05 = -0.1017623$.\n\n$$Z_{upper} \\approx \\frac{0.0017623}{0.0263629} \\approx 0.066848$$\n$$Z_{lower} \\approx \\frac{-0.1017623}{0.0263629} \\approx -3.85999$$\nThe power is the sum of the probabilities in the tails of the standard normal distribution:\n$$\\text{Power} = P(Z > 0.066848) + P(Z < -3.85999)$$\nwhere $Z \\sim N(0,1)$. Let $\\Phi(\\cdot)$ be the cumulative distribution function (CDF) of the standard normal distribution.\n$$\\text{Power} = (1 - \\Phi(0.066848)) + \\Phi(-3.85999)$$\nUsing a standard normal CDF calculator:\n$\\Phi(0.066848) \\approx 0.52664$\n$\\Phi(-3.85999) \\approx 0.000057$\n\n$$\\text{Power} \\approx (1 - 0.52664) + 0.000057 = 0.47336 + 0.000057 = 0.473417$$\nRounding the result to four significant figures, we get $0.4734$.",
            "answer": "$$\\boxed{0.4734}$$"
        },
        {
            "introduction": "Now that we understand how power is determined, let's tackle the most common question in study design: \"How large does my sample need to be?\". This practice  walks you through a classic scenario where you must determine the required number of participants to confidently detect a specific reduction in risk between an intervention and a control group. We will use the logarithm of the risk ratio, a common and powerful method in epidemiology, to illustrate how the choice of statistical analysis directly shapes our sample size requirements.",
            "id": "4633023",
            "problem": "A public health team plans a randomized controlled trial to evaluate a new intervention expected to reduce the risk of a binary clinical event. Let $p_1$ denote the event probability in the intervention group and $p_2$ denote the event probability in the control group. The team will analyze the effect using the natural logarithm ($\\ln$) of the estimated risk ratio, $\\ln(\\widehat{\\text{RR}})=\\ln(\\hat{p}_1)-\\ln(\\hat{p}_2)$, relying on large-sample properties justified by the Central Limit Theorem (CLT) and the delta method. Assume independent Bernoulli outcomes within and across groups, and that $n_1$ and $n_2$ are the group sample sizes with equal allocation ($n_1=n_2$).\n\nThe scientific design targets detection of a true risk ratio $\\text{RR}=0.75$ when the baseline risk in the control group is $p_2=0.40$, using a two-sided Type I error rate $\\alpha=0.05$ and Type II error rate $\\beta=0.20$ (power $1-\\beta=0.80$). Under this design, test the null hypothesis $H_0:\\text{RR}=1$ versus the two-sided alternative $H_1:\\text{RR}\\neq 1$ using the asymptotic normal test based on $\\ln(\\widehat{\\text{RR}})$.\n\nUsing the above foundations (CLT and delta method applied to $\\ln(\\widehat{\\text{RR}})$), compute the required equal group sample sizes $n_1$ and $n_2$ that achieve the specified $\\alpha$ and power to detect $\\text{RR}=0.75$ when $p_2=0.40$. Take $p_1$ under the alternative to satisfy $p_1=\\text{RR}\\times p_2$. Report your answer as the smallest integers $n_1$ and $n_2$ that satisfy the design criterion under the normal approximation, expressed as a row matrix $\\begin{pmatrix} n_1 & n_2 \\end{pmatrix}$. Use the natural logarithm ($\\ln$). No percentage signs are allowed in the answer.",
            "solution": "The objective is to calculate the required sample size per group, $n$, for a randomized controlled trial with two equal-sized groups ($n_1=n_2=n$). The analysis is based on the natural logarithm of the risk ratio, $\\ln(\\text{RR})$.\n\nFirst, we define the parameter of interest and its estimator. The true risk ratio is $\\text{RR} = p_1/p_2$, and the parameter for the statistical test is $\\theta = \\ln(\\text{RR})$. The estimator is $\\hat{\\theta} = \\ln(\\widehat{\\text{RR}}) = \\ln(\\hat{p}_1/\\hat{p}_2) = \\ln(\\hat{p}_1) - \\ln(\\hat{p}_2)$, where $\\hat{p}_1$ and $\\hat{p}_2$ are the sample proportions of events in the intervention and control groups, respectively.\n\nUsing the delta method, we can find the asymptotic variance of $\\hat{\\theta}$. For a single proportion estimator $\\hat{p}$, the variance is $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$. For a function $g(\\hat{p}) = \\ln(\\hat{p})$, the variance is approximated by $\\text{Var}(g(\\hat{p})) \\approx [g'(p)]^2 \\text{Var}(\\hat{p})$. Since $g'(p) = 1/p$, we have:\n$$ \\text{Var}(\\ln(\\hat{p})) \\approx \\left(\\frac{1}{p}\\right)^2 \\frac{p(1-p)}{n} = \\frac{1-p}{np} $$\nSince the two groups are independent, the variance of the difference $\\ln(\\hat{p}_1) - \\ln(\\hat{p}_2)$ is the sum of their variances:\n$$ \\text{Var}(\\ln(\\widehat{\\text{RR}})) \\approx \\text{Var}(\\ln(\\hat{p}_1)) + \\text{Var}(\\ln(\\hat{p}_2)) = \\frac{1-p_1}{n_1 p_1} + \\frac{1-p_2}{n_2 p_2} $$\nGiven equal sample sizes $n_1=n_2=n$, the expression becomes:\n$$ \\text{Var}(\\ln(\\widehat{\\text{RR}})) = \\frac{1}{n} \\left( \\frac{1-p_1}{p_1} + \\frac{1-p_2}{p_2} \\right) $$\n\nThe sample size formula for a two-sided test with significance level $\\alpha$ and power $1-\\beta$ to detect a true effect $\\theta_A$ versus a null effect $\\theta_0=0$ is given by:\n$$ n = \\frac{( z_{1-\\alpha/2} + z_{1-\\beta} )^2 \\sigma^2_{A}}{(\\theta_A - \\theta_0)^2} $$\nwhere $n$ is the size of each group. In this formula, $\\theta_A = \\ln(\\text{RR}_{A})$ is the value of the parameter under the alternative hypothesis, and $\\sigma^2_A$ is the per-subject variance component under the alternative hypothesis, which is the term multiplying $1/n$ in the variance expression.\n$$ \\sigma^2_A = \\frac{1-p_1}{p_1} + \\frac{1-p_2}{p_2} $$\nThe formula for the sample size in each group is therefore:\n$$ n = \\frac{( z_{1-\\alpha/2} + z_{1-\\beta} )^2 \\left( \\frac{1-p_1}{p_1} + \\frac{1-p_2}{p_2} \\right)}{(\\ln(\\text{RR}_A))^2} $$\n\nNow, we substitute the values provided in the problem:\n- Two-sided Type I error rate: $\\alpha = 0.05$. The corresponding critical value from the standard normal distribution is $z_{1-\\alpha/2} = z_{0.975} \\approx 1.95996$.\n- Type II error rate: $\\beta = 0.20$, so power is $1-\\beta = 0.80$. The corresponding value is $z_{1-\\beta} = z_{0.80} \\approx 0.84162$.\n- Risk in the control group: $p_2 = 0.40$.\n- True risk ratio under the alternative hypothesis: $\\text{RR}_A = 0.75$.\n- Risk in the intervention group under the alternative hypothesis: $p_1 = \\text{RR}_A \\times p_2 = 0.75 \\times 0.40 = 0.30$.\n- The effect size on the log scale is $\\ln(\\text{RR}_A) = \\ln(0.75)$.\n\nWe first calculate the variance component:\n$$ \\frac{1-p_1}{p_1} + \\frac{1-p_2}{p_2} = \\frac{1-0.30}{0.30} + \\frac{1-0.40}{0.40} = \\frac{0.7}{0.3} + \\frac{0.6}{0.4} = \\frac{7}{3} + \\frac{3}{2} = \\frac{14}{6} + \\frac{9}{6} = \\frac{23}{6} $$\n\nNext, we assemble the full expression for $n$:\n$$ n = \\frac{(z_{0.975} + z_{0.80})^2 \\left( \\frac{23}{6} \\right)}{(\\ln(0.75))^2} $$\nSubstituting the numerical values for the z-scores and the logarithm:\n$$ n \\approx \\frac{(1.95996 + 0.84162)^2 \\left( \\frac{23}{6} \\right)}{(\\ln(0.75))^2} $$\n$$ n \\approx \\frac{(2.80158)^2 \\times 3.83333}{(\\ln(0.75))^2} $$\n$$ n \\approx \\frac{7.84886 \\times 3.83333}{0.082760} \\approx \\frac{30.0863}{0.082760} \\approx 363.55 $$\nSince the sample size must be an integer and must be large enough to achieve the desired power, we must round up to the next whole number.\n$$ n = \\lceil 363.55 \\rceil = 364 $$\nThus, the required sample size for each group is $n_1=364$ and $n_2=364$. The result is to be presented as a row matrix.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 364 & 364 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Effective study design goes beyond simply enrolling enough participants; it involves allocating them in the most efficient way possible. This final practice  explores a fundamental principle of design optimization: when the outcome's variability differs between groups, an equal allocation of subjects is often not the most powerful approach. By deriving the optimal allocation ratio, you will learn how to maximize your study's statistical power for a given total sample size, a crucial skill for conducting research with limited resources.",
            "id": "4633056",
            "problem": "An epidemiologist is designing a two-arm study to detect a nonzero difference in group means for a continuous outcome. Group $1$ outcomes are independently and identically distributed with mean $\\mu_1$ and variance $\\sigma_1^2$, and group $2$ outcomes are independently and identically distributed with mean $\\mu_2$ and variance $\\sigma_2^2$. All observations are independent across and within groups. Assume the sampling distributions of the sample means are well approximated by normal distributions due to the Central Limit Theorem (CLT). The investigator seeks to achieve a prespecified Type I error probability $\\alpha$ and power $1-\\beta$ for testing $H_0:\\mu_1-\\mu_2=0$ versus $H_1:\\mu_1-\\mu_2=\\Delta$, where $\\Delta \\neq 0$ is a fixed effect size of interest. The per-subject cost is the same in both groups, so the total cost is proportional to the total sample size. \n\nUsing first principles about the variance of the estimator for the mean difference and the relationship between statistical power and the standard error of the estimator, determine the allocation ratio $n_1/n_2$ that minimizes the total sample size needed to achieve the designâ€™s $\\alpha$, $1-\\beta$, and $\\Delta$ when $\\sigma_1^2=1$ and $\\sigma_2^2=4$. Express your final answer as a single reduced fraction. No rounding is required, and no units should be included in your answer.",
            "solution": "The problem requires finding the sample allocation ratio, $k = n_1/n_2$, that minimizes the total sample size, $N = n_1 + n_2$, while achieving a specified power $1-\\beta$ and significance level $\\alpha$ for detecting a mean difference of $\\Delta$.\n\nThe estimator for the difference in means is $\\hat{\\Delta} = \\bar{X}_1 - \\bar{X}_2$, where $\\bar{X}_1$ and $\\bar{X}_2$ are the sample means for group $1$ and group $2$, respectively.\n\nBecause all observations are independent, the variance of the estimator is the sum of the variances of the sample means:\n$$ Var(\\bar{X}_1 - \\bar{X}_2) = Var(\\bar{X}_1) + Var(\\bar{X}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} $$\nThe standard error (SE) of the estimator is the square root of its variance:\n$$ SE(\\bar{X}_1 - \\bar{X}_2) = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} $$\nFor a two-sided test with significance level $\\alpha$, the general formula relating sample size, power, and effect size is derived from the distributions of the test statistic under the null and alternative hypotheses. The test statistic is:\n$$ Z = \\frac{(\\bar{X}_1 - \\bar{X}_2) - (\\mu_1 - \\mu_2)}{SE(\\bar{X}_1 - \\bar{X}_2)} $$\nBased on the CLT, $Z$ follows a standard normal distribution, $Z \\sim N(0,1)$.\n\nTo achieve a power of $1-\\beta$ for a two-sided test at significance level $\\alpha$, the required sample sizes must satisfy the following relationship:\n$$ |\\Delta| = (z_{1-\\alpha/2} + z_{1-\\beta}) \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} $$\nwhere $z_p$ is the $p$-th quantile of the standard normal distribution (i.e., $P(Z \\le z_p) = p$).\nFor fixed $\\alpha$, $\\beta$, and $\\Delta$, the term $(z_{1-\\alpha/2} + z_{1-\\beta})$ is a constant. Let's rearrange the equation to isolate the terms involving sample size:\n$$ \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}} = \\frac{|\\Delta|}{z_{1-\\alpha/2} + z_{1-\\beta}} $$\nSquaring both sides gives:\n$$ \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} = \\left(\\frac{\\Delta}{z_{1-\\alpha/2} + z_{1-\\beta}}\\right)^2 $$\nThe right-hand side is a constant determined by the design parameters. Let us denote this constant by $C$:\n$$ \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2} = C $$\nOur objective is to minimize the total sample size $N = n_1 + n_2$ subject to this constraint.\n\nWe can solve this optimization problem using substitution. Let the allocation ratio be $k = n_1/n_2$. Then $n_1 = kn_2$. The total sample size is $N = kn_2 + n_2 = (k+1)n_2$.\n\nSubstitute $n_1 = kn_2$ into the constraint equation:\n$$ \\frac{\\sigma_1^2}{kn_2} + \\frac{\\sigma_2^2}{n_2} = C $$\nFactor out $1/n_2$:\n$$ \\frac{1}{n_2} \\left( \\frac{\\sigma_1^2}{k} + \\sigma_2^2 \\right) = C $$\nSolve for $n_2$ in terms of $k$:\n$$ n_2 = \\frac{1}{C} \\left( \\frac{\\sigma_1^2}{k} + \\sigma_2^2 \\right) $$\nNow, express the total sample size $N$ as a function of $k$:\n$$ N(k) = (k+1)n_2 = (k+1) \\frac{1}{C} \\left( \\frac{\\sigma_1^2}{k} + \\sigma_2^2 \\right) $$\nTo minimize $N(k)$, we can ignore the positive constant factor $1/C$ and focus on minimizing the function $f(k) = (k+1) \\left( \\frac{\\sigma_1^2}{k} + \\sigma_2^2 \\right)$.\nExpanding this expression gives:\n$$ f(k) = k\\left(\\frac{\\sigma_1^2}{k}\\right) + k\\sigma_2^2 + 1\\left(\\frac{\\sigma_1^2}{k}\\right) + \\sigma_2^2 = \\sigma_1^2 + k\\sigma_2^2 + \\frac{\\sigma_1^2}{k} + \\sigma_2^2 $$\nTo find the minimum, we compute the derivative of $f(k)$ with respect to $k$ and set it to zero.\n$$ \\frac{df}{dk} = \\frac{d}{dk} \\left( \\sigma_1^2 + k\\sigma_2^2 + \\frac{\\sigma_1^2}{k} + \\sigma_2^2 \\right) = 0 + \\sigma_2^2 - \\frac{\\sigma_1^2}{k^2} + 0 $$\nSetting the derivative to zero:\n$$ \\sigma_2^2 - \\frac{\\sigma_1^2}{k^2} = 0 $$\n$$ \\sigma_2^2 = \\frac{\\sigma_1^2}{k^2} $$\n$$ k^2 = \\frac{\\sigma_1^2}{\\sigma_2^2} $$\nSince $k = n_1/n_2$ must be a positive ratio, we take the positive square root:\n$$ k = \\sqrt{\\frac{\\sigma_1^2}{\\sigma_2^2}} = \\frac{\\sigma_1}{\\sigma_2} $$\nTo confirm this is a minimum, we can check the second derivative:\n$$ \\frac{d^2f}{dk^2} = \\frac{d}{dk} \\left( \\sigma_2^2 - \\sigma_1^2 k^{-2} \\right) = -(-2)\\sigma_1^2 k^{-3} = \\frac{2\\sigma_1^2}{k^3} $$\nSince variances $\\sigma_1^2$ and the ratio $k$ are positive, the second derivative is positive, confirming that this value of $k$ minimizes the function $f(k)$ and thus minimizes the total sample size $N$.\n\nThe optimal allocation ratio is the ratio of the standard deviations of the two groups.\nThe problem provides the variances: $\\sigma_1^2 = 1$ and $\\sigma_2^2 = 4$.\nFirst, we find the standard deviations:\n$$ \\sigma_1 = \\sqrt{\\sigma_1^2} = \\sqrt{1} = 1 $$\n$$ \\sigma_2 = \\sqrt{\\sigma_2^2} = \\sqrt{4} = 2 $$\nNow, we calculate the optimal allocation ratio $k$:\n$$ k = \\frac{n_1}{n_2} = \\frac{\\sigma_1}{\\sigma_2} = \\frac{1}{2} $$\nThis result indicates that for every subject allocated to group $1$, two subjects should be allocated to group $2$. This is intuitive, as more samples are needed from the group with higher variability to achieve the same precision in estimating its mean.\n\nThe question asks for the final answer as a single reduced fraction, which is $1/2$.",
            "answer": "$$\\boxed{\\frac{1}{2}}$$"
        }
    ]
}