## 引言
在实证研究中，评估干预措施的因果效应是核心目标，而随机对照试验（RCT）被视为黄金标准。然而，在公共卫生和政策领域，由于伦理、实践或法律限制，进行随机化往往不可行。这便产生了一个关键的知识鸿沟：当无法随机分配时，我们如何能够严谨地判断一项政策或干预是否真正有效？准实验研究设计正是为了应对这一挑战而生，它提供了一套在非实验数据中识别因果关系的强大方法论。

本文将系统性地引导您深入准实验研究的世界。在“原则与机制”一章中，我们将奠定因果推断的基础，介绍[潜在结果框架](@entry_id:636884)，并详细拆解[双重差分法](@entry_id:636293)、[工具变量法](@entry_id:204495)、回归断点设计等核心方法的内在逻辑与识别假设。接着，在“应用与跨学科联系”一章，我们将展示这些设计如何在公共卫生、政策评估、法律甚至医学史等多个领域发挥作用，并探讨如何处理交错采纳、溢出效应等复杂现实问题。最后，通过“动手实践”部分，您将有机会运用所学知识解决具体的分析难题。通过学习本文，您将掌握在现实世界数据中进行可靠因果推断的关键技能。

## 原则与机制

在实证研究中，我们的核心目标往往是探究一项干预（如一项新政策或一个临床治疗方案）是否对某个结果产生了因果效应。理想情况下，随机对照试验（RCT）是回答此类问题的黄金标准。通过随机分配，RCT能够确保处理组和[对照组](@entry_id:188599)在所有可观测和不可观测的特征上平均而言是可比较的，从而直接、无偏地估计因果效应。然而，在许多现实世界的情境中，由于伦理、法律或实践上的限制，进行随机分配是不可行或不被允许的。在这些情况下，研究者必须依赖于非实验性数据，这就引出了准实验研究设计（Quasi-experimental Study Designs）的用武之地。本章将深入探讨支撑这些设计的核心原则与机制，解释它们如何在一个无法进行随机化的世界里，为因果推断提供严谨的框架。

### 因果推断的基础：[潜在结果框架](@entry_id:636884)

为了严谨地讨论因果关系，我们首先需要一个形式化的语言。在现代流行病学和统计学中，**[潜在结果框架](@entry_id:636884)**（Potential Outcomes Framework），也常被称为Rubin因果模型，扮演了这一角色。该框架的核心思想是，对于每一个研究单元（例如，一个病人、一所学校、一个地区），都存在着对应于不同处理状态下的[潜在结果](@entry_id:753644)。

假设我们关心一项处理（记为 $A$）对某个结果（记为 $Y$）的影响。为了简化，我们考虑一个二元处理，即单元 $i$ 或者接受处理（$A_i=1$），或者不接受处理（$A_i=0$）。根据[潜在结果框架](@entry_id:636884)，每个单元 $i$ 都拥有一对潜在结果：
- $Y_i(1)$：如果单元 $i$ 接受处理，将会观察到的结果。
- $Y_i(0)$：如果单元 $i$ 未接受处理，将会观察到的结果。

对于单元 $i$ 而言，处理的个体因果效应（Individual Causal Effect）就是 $Y_i(1) - Y_i(0)$。然而，**因果推断的根本问题**在于，对于任何一个单元，我们至多只能观察到这两个潜在结果中的一个。我们观察到的实际结果 $Y_i$ 可以表示为 $Y_i = A_i Y_i(1) + (1-A_i) Y_i(0)$。我们永远无法同时观察到同一个人在同一时间点接受处理和未接受处理两种情况下的结果。缺失的那一个[潜在结果](@entry_id:753644)，我们称之为**反事实**（counterfactual）。

因此，我们通常将目标转向估计群体的平均因果效应（Average Causal Effect, ACE），即 $E[Y(1) - Y(0)]$，或者处理组的平均[处理效应](@entry_id:636010)（Average Treatment Effect on the Treated, ATT），即 $E[Y(1) - Y(0) \mid A=1]$。RCT通过随机化，使得处理分配 $A$ 独立于潜在结果对 $(Y(0), Y(1))$，即 $(Y(0), Y(1)) \perp A$，从而保证了 $E[Y \mid A=1] = E[Y(1)]$ 且 $E[Y \mid A=0] = E[Y(0)]$。这样，处理组和[对照组](@entry_id:188599)的平均结果之差便能无偏地估计平均因果效应。当RCT不可行时，准实验设计便试图寻找其他方式来令人信服地构建一个反事实。

### 因果推断的基石性假设

无论是RCT还是准实验设计，所有因果推断都建立在一系列基本假设之上。这些假设是连接我们观察到的数据和我们希望估计的因果量之间的桥梁 。

1.  **稳定单元处理价值假设 (Stable Unit Treatment Value Assumption, SUTVA)**：这个假设包含两个子假设：
    *   **无干预 (No Interference)**：任何一个单元的[潜在结果](@entry_id:753644)不受其他单元处理状态的影响。例如，在一个评估地区性疫苗接种项目的研究中，SUTVA假设一个地区的疫苗接种项目不会影响邻近地区的住院率。
    *   **处理版本一致性 (No Hidden Variations of Treatment)**：对于任何指定的处理水平 $a$，所有接受该处理的单元所接受的干预是同质的，不存在会影响结果的、未被言明的处理版本差异。例如，所有被标记为实施了某项学校计划的学区，其实施的计划内容和强度都是一致的。
    SUTVA确保了每个单元的[潜在结果](@entry_id:753644) $Y_i(a)$ 是一个明确、单一的数值。

2.  **一致性 (Consistency)**：该假设将潜在结果与我们观察到的数据联系起来。它表明，如果一个单元实际接受的处理是 $A_i=a$，那么我们观察到的结果 $Y_i$ 就是该单元在该处理水平下的[潜在结果](@entry_id:753644) $Y_i(a)$。形式上，若 $A_i = a$，则 $Y_i = Y_i(a)$。这使得我们能够利用观察数据来推断[潜在结果](@entry_id:753644)的分布。

3.  **[可交换性](@entry_id:263314) (Exchangeability)**：这是实现因果推断的核心“类随机”假设。它要求处理组和[对照组](@entry_id:188599)具有可比性。
    *   **无条件[可交换性](@entry_id:263314)**：在RCT中，由于随机化，$A$ 与 $(Y(0), Y(1))$ 相互独立。这意味着处理组和[对照组](@entry_id:188599)在处理前是完全可比的。
    *   **条件可交换性 (Conditional Exchangeability)**：在许多非随机研究中，处理组和[对照组](@entry_id:188599)在基线特征上可能存在系统性差异。例如，接受某项新药治疗的患者可能病情更重。在这种情况下，我们退而求其次，假设在控制了一系列可观测的基线协变量 $X$ 之后，处理分配与[潜在结果](@entry_id:753644)是独立的。这被称为**无混淆假设** (No Unmeasured Confounding)，形式化为 $(Y(0), Y(1)) \perp A \mid X$。这一假设意味着，在具有相同协变量 $X$ 的个体组成的亚群内，接受处理的个体和未接受处理的个体是可交换的。这是许多基于回归调整或匹配的观察性研究的基石。

4.  **正性 (Positivity)** 或称 **重叠性 (Overlap)**：这是一个关于数据的实际要求。它要求对于协变量 $X$ 的所有可能取值，在该协变量层内，接受处理和未接受处理的概率都必须大于零。形式化为，对于所有满足 $P(X=x) > 0$ 的 $x$，都有 $0  P(A=1 \mid X=x)  1$。这个假设保证了对于任何特征的人群，我们总能找到接受处理和未接受处理的个体进行比较，从而使得基于 $X$ 的调整成为可能。

### 准实验设计的逻辑

准实验设计是介于RCT和纯粹依赖于条件[可交换性](@entry_id:263314)假设的观察性研究之间的一类方法。纯粹的观察性研究（如一个简单的队列研究）可能通过回归模型调整已知的混杂因素，但其有效性完全取决于“所有重要的混杂因素都已被测量并正确纳入模型”这一通常无法验证的假设。

相比之下，**准实验设计**的精髓在于，它不依赖于对所有混杂因素的测量，而是巧妙地利用一个由政策、环境或规则驱动的**外生变异**（exogenous variation）来模拟随机分配。这个变异源于一个研究者无法控制的、已知的分配机制，该机制在特定子人群或数据的特定边界处，创造了“仿佛随机”的分配 。

一个典型的例子是**自然实验**（natural experiment）。自然实验并非指在自然环境中进行的实验，而是指[自然发生](@entry_id:138395)或由社会事件引发的某种情况，其处理分配机制类似于随机化。关键在于，这个分配机制对于受影响的个体来说是外生的，且与他们的[潜在结果](@entry_id:753644)无关。例如，假设一个电子处方系统的软件更新中存在一个编码错误，导致位于某个特定经度以西的诊所，其处方单上会默认预选一种降胆[固醇](@entry_id:173187)药物。这个基于地理编码四舍五入的奇怪规则与患者风险、医生偏好或诊所绩效无关，因此可以被视为一种“仿佛随机”的分配机制。与之相对，一个突然的经济衰退虽然也是一个“冲击”，但它对不同社区的影响可能与社区原有的经济脆弱性、社会服务等因素（这些因素也与健康结果相关）紧密相连，因此不能简单地视为一个创造了外生变异的自然实验 。

准实验设计的力量在于，它用一个更具体、更可辩护、基于设计本身的识别假设（如后面将要讨论的平行趋势、断点处的连续性等），替代了宽泛且难以验证的“无未观测混杂”假设。其代价是，得到的因果效应估计往往是**局部的**（local），例如仅适用于断点附近的个体，或仅适用于那些因政策鼓励而改变行为的“依从者”。

### 关键的准实验设计方法

以下我们介绍几种最常用和最强大的准实验设计。

#### [双重差分法](@entry_id:636293) (Difference-in-Differences, DiD)

[双重差分法](@entry_id:636293)是评估政策或项目影响最常用的[准实验方法](@entry_id:636714)之一。它适用于拥有处理组和[对照组](@entry_id:188599)在干预前后两个或多个时期的数据。

其基本思想是，通过比较处理组在干预前后的结果变化与同一时期内[对照组](@entry_id:188599)的结果变化，来“差分”掉那些随时间变化的、影响两组的共同因素。例如，评估一个地区实施的疾病筛查项目对发病率的影响，而邻近地区未实施该项目 。

经典的双重差分估计量可以表示为：
$$ \hat{\tau}_{DiD} = ( \bar{Y}_{1}^{T} - \bar{Y}_{0}^{T} ) - ( \bar{Y}_{1}^{C} - \bar{Y}_{0}^{C} ) $$
其中，$\bar{Y}_{t}^{G}$ 表示在时间 $t$（$t=0$ 为干预前，$t=1$ 为干预后）下，组别 $G$（$T$ 为处理组，$C$ 为[对照组](@entry_id:188599)）的平均结果。这个公式直观地体现了“双重差分”：第一个差分是各组内部的时间变化，第二个差分是两组变化之间的差异。

DiD设计的核心识别假设是**[平行趋势假设](@entry_id:633981)**（Parallel Trends Assumption）。该假设要求，**在没有处理的情况下**，处理组的结果变化趋势本应与[对照组](@entry_id:188599)相同。用潜在结果的语言来表述，这个假设是  ：
$$ E[ Y_{1}(0) - Y_{0}(0) \mid D=1 ] = E[ Y_{1}(0) - Y_{0}(0) \mid D=0 ] $$
这里，$D=1$ 表示处理组，$D=0$ 表示[对照组](@entry_id:188599)。这个假设的核心在于左边的项 $E[Y_1(0) \mid D=1]$，即处理组在处理时期的反事实结果。[平行趋势假设](@entry_id:633981)允许我们用[对照组](@entry_id:188599)的观察到的趋势 $E[Y_1(0) \mid D=0] - E[Y_0(0) \mid D=0]$ 来代替处理组的反事实趋势。值得注意的是，DiD并不要求两组在基线水平上相同，只要求它们的趋势平行。

这个假设本身是无法直接检验的，因为它涉及到一个反事实量。但是，如果有多于一个干预前的时间点，我们可以通过检验干预前的趋势是否平行来进行一个安慰剂检验。例如，比较 $t=0$ 与 $t=-1$ 的趋势。如果干预前趋势不平行，那么[平行趋势假设](@entry_id:633981)就很可能不成立。如果干预前趋势平行，这为[平行趋势假设](@entry_id:633981)提供了支持性证据，但并非决定性证据，因为不能排除在干预发生的同时，恰好有某个未观测因素只影响了处理组的趋势 。在[平行趋势假设](@entry_id:633981)下，$\hat{\tau}_{DiD}$ 能够识别出处理组的平均[处理效应](@entry_id:636010)（ATT）。

#### [工具变量法](@entry_id:204495) (Instrumental Variables, IV)

当存在未观测到的混杂因素，使得处理状态 $D$ 与[潜在结果](@entry_id:753644) $Y(d)$ 相关时，即使控制了所有可观测变量，直接比较处理组和[对照组](@entry_id:188599)的结果也会产生偏误。[工具变量法](@entry_id:204495)提供了一种解决方案。

一个有效的**[工具变量](@entry_id:142324)**（$Z$）必须满足四个核心条件 ：
1.  **相关性 (Relevance)**：[工具变量](@entry_id:142324)必须与处理状态 $D$ 相关。即 $E[D \mid Z=1] - E[D \mid Z=0] \neq 0$。在鼓励设计（encouragement design）的例子中，一个旨在提高流感疫苗接种率的代金券项目（$Z$）必须确实能提高疫苗接种率（$D$）。

2.  **独立性 (Independence/Exogeneity)**：[工具变量](@entry_id:142324)的分配是“仿佛随机”的，它与任何影响结果 $Y$ 的未观测混杂因素都无关。形式上，$Z \perp \{Y(0), Y(1), D(0), D(1)\}$。在随机化的鼓励设计中，由于 $Z$ 是随机分配的，这个条件自然成立。

3.  **排他性限制 (Exclusion Restriction)**：工具变量只能通过影响处理状态 $D$ 来影响结果 $Y$，而不能有任何直接影响 $Y$ 的旁路。形式上，一个人的[潜在结果](@entry_id:753644) $Y(d,z)$ 只依赖于处理状态 $d$，而与工具变量状态 $z$ 无关，即 $Y(d,z) = Y(d)$ 。这意味着，在疫苗的例子中，代金券本身不能预防流感，只有它促使人们接种的疫苗才能。这个假设与DiD的[平行趋势假设](@entry_id:633981)有本质区别：排他性限制是关于个体层面不存在从 $Z$ 到 $Y$ 的直接因果路径，而平行趋势是关于群体平均趋势的假设 。

4.  **[单调性](@entry_id:143760) (Monotonicity)**：工具变量对所有个体的处理状态的影响方向是相同的。在鼓励设计中，这意味着代金券只会让一些人从不接种变为接种，但不会让任何人从打算接种变为不接种。即不存在“逆反者”（defiers）。形式上，$D(1) \ge D(0)$ 对所有个体成立。

在这些假设下，IV估计量——即[工具变量](@entry_id:142324)对结果的平均影响（简化形式）与[工具变量](@entry_id:142324)对处理的平均影响（第一阶段）之比——能够识别出一个**局部平均处理效应**（Local Average Treatment Effect, LATE）。
$$ \tau_{IV} = \frac{E[Y \mid Z=1] - E[Y \mid Z=0]}{E[D \mid Z=1] - E[D \mid Z=0]} \rightarrow E[Y(1) - Y(0) \mid D(1)  D(0)] $$
LATE是处理对“依从者”（compliers）的平均因果效应，即那些仅在受到[工具变量](@entry_id:142324)影响时才接受处理的亚群。

#### 回归断点设计 (Regression Discontinuity Design, RDD)

回归断点设计利用了政策或项目资格通常取决于一个连续变量（称为**分配变量**，forcing variable）是否超过某个特定**阈值**的规则。例如，一项免疫补贴仅提供给风险评分 $X$ 超过阈值 $c$ 的个体 。

RDD的核心思想是，那些分数恰好在阈值两侧的个体（例如，一个人的分数是 $c-\epsilon$，另一个是 $c+\epsilon$），在其他所有方面都极其相似，可以认为他们被“仿佛随机”地分配到了处理组和[对照组](@entry_id:188599)。

RDD的主要识别假设是，[潜在结果](@entry_id:753644) $Y(d)$ 作为分配变量 $X$ 的函数，在阈值 $c$ 处是连续的。这意味着，如果没有干预，结果的平均值在阈值处不会发生跳跃。因此，在阈值处观察到的任何结果均值的**不连续性**（或称“断点”）都可以归因于处理的因果效应。

RDD分为两种类型 ：
*   **清晰断点设计 (Sharp RDD)**：处理状态完全由分配变量是否超过阈值决定。即 $D = \mathbf{1}\{X \ge c\}$。在这种情况下，在阈值处观察到的结果均值的跳跃直接识别了在阈值处的平均[处理效应](@entry_id:636010)：$\tau_{SRD} = E[Y(1) - Y(0) \mid X=c]$。

*   **模糊断点设计 (Fuzzy RDD)**：跨越阈值只是增加了接受处理的概率，但并不完全决定它（例如，有些符合资格的人没有申请补贴）。这时，处理概率 $\Pr(D=1 \mid X=x)$ 在阈值 $c$ 处发生跳跃。模糊RDD本质上是在阈值附近应用了[工具变量法](@entry_id:204495)。这里的工具是“是否超过阈值”（$Z = \mathbf{1}\{X \ge c\}$）。模糊RDD估计量是结果的跳跃与处理概率的跳跃之比，它识别的是在阈值处的“依从者”的局部平均处理效应（LATE）。

RDD的估计量本质上是**局部的**，它估计的是对于分数恰好在阈值处的个体的因果效应，其外部有效性需要谨慎评估。

#### 中断[时间序列分析](@entry_id:178930) (Interrupted Time Series, ITS)

当只有受处理单元的[时间序列数据](@entry_id:262935)，而没有一个明确的[对照组](@entry_id:188599)时，中断[时间序列分析](@entry_id:178930)是一个强大的设计。它适用于干预在一个已知时间点 $T_0$ 发生的情况。例如，评估某城市一项法令对伤害发生率月度数据的影响 。

ITS的逻辑是通过干预前的大量数据点（越多越好）来建立一个稳定的基线趋势，然后将这个趋势外推到干预后的时期，作为反事实的参照。干预的效果就是观察到的干预后轨迹与这个反事实轨迹之间的差异。

在实践中，这通常通过**分段回归**（segmented regression）模型来实现：
$$ E[Y_t] = \beta_0 + \beta_1 t + \beta_2 A_t + \beta_3 P_t + \text{控制项} $$
其中，$t$ 是时间计数器，$A_t$ 是一个指示变量（干预后为1，否则为0），$P_t$ 是一个干预后的时间计数器（干预后为 $t-T_0$，否则为0）。
*   $\beta_2$ 捕捉了干预发生瞬间的**水平即时变化**（level change）。
*   $\beta_3$ 捕捉了干预后趋势相对于干预前趋势的**斜率变化**（slope change）。

ITS的核心识别假设是，**在没有干预的情况下，干预前的趋势会持续不变**。这个假设的有效性受到多种威胁，包括：在同一时间点发生其他影响结果的事件（共存干预）、数据收集方式或人群构成的突然改变、以及人们在干预正式开始前就预知并改变行为（预期效应）。

### 高级议题与常见陷阱

#### 后处理变量调整的风险

在因果推断中，一个常见的严重错误是在[回归模型](@entry_id:163386)中控制（或调整）受处理影响的**后处理变量**（post-treatment variables）。研究者可能会认为，控制一个位于处理和结果之间且与结果强相关的变量（即中介变量 $M$），能够“解释”一部分效应或提高模型精度。然而，这种做法通常会引入严重偏误 。

假设一个政策（$A$）通过改变某种行为（$M$）来影响健康结果（$Y$），即存在因果路径 $A \to M \to Y$。
1.  **阻断因果路径**：调整 $M$ 会阻断 $A$ 通过 $M$ 影响 $Y$ 的间接路径。这样得到的 $A$ 的系数不再是总因果效应，而是一种“直接效应”，但它也未必是无偏的。
2.  **引入[对撞偏倚](@entry_id:163186) (Collider Bias)**：通常存在一些未观测因素 $U$（如个人偏好或压力）同时影响中介变量 $M$ 和结果 $Y$。在这种情况下，$M$ 是一个“对撞点”（collider），因为有两条“箭头”指向它（$A \to M \leftarrow U$）。在未调整 $M$ 时， $A$ 和 $U$ 是不相关的。但一旦在回归中控制了 $M$ ，就会在 $A$ 和 $U$ 之间打开一条虚假的[统计关联](@entry_id:172897)，从而在 $A$ 对 $Y$ 的效应估计中引入偏误。

如果研究的兴趣确实在于分解总效应为直接和间接效应，那么应该使用正规的**因果中介分析**（Causal Mediation Analysis）框架。该框架严谨地定义了自然直接效应（NDE）和自然间接效应（NIE），并依赖于更强的假设（如序贯可忽略性, sequential ignorability）来进行识别和估计。

#### 内部有效性、外部有效性与可移植性

最后，在评估一项准实验研究的结果时，区分两种有效性至关重要 。

*   **内部有效性 (Internal Validity)**：指研究在其特定的研究样本和背景下，对因果效应的估计是否无偏。上述所有设计（DiD, IV, RDD, ITS）的核心识别假设（平行趋势、排他性限制等）都是为了确保内部有效性。

*   **外部有效性 (External Validity)** 或 **可推广性 (Generalizability)**：指研究结果能否推广到研究样本之外的其他人群、环境或时间。准实验研究的估计量通常是局部的（如LATE或断点处的效应），这使得其外部有效性成为一个特别需要关注的问题。

当希望将一项研究的发现从一个“源人群”应用到一个特征分布不同的“目标人群”时，我们需要考虑**可移植性**（transportability）的问题。假设源人群和目标人群的唯一区别在于某个效应修饰因子 $Z$（例如年龄构成）的分布不同，而 $Z$ 本身不会被处理 $X$ 影响，且 $X$ 对 $Y$ 的因果机制在 $Z$ 的每个层内是相同的。在这种情况下，我们可以通过对源人群中估计的特定于 $Z$ 层级的因果效应，用目标人群中 $Z$ 的分布进行加权，来得到目标人群的平均因果效应。这个过程的公式为：
$$ P^\ast(Y \mid \operatorname{do}(X)) = \sum_{z} P(Y \mid \operatorname{do}(X), z) P^\ast(z) $$
其中，$P$ 代表源人群的概率分布，$P^\ast$ 代表目标人群的概率分布。这个公式为我们提供了一个从一个情境到另一个情境进行严谨、有原则的推广的框架。

总之，准实验设计为在无法进行随机化的现实世界中进行因果推断提供了一套强大而严谨的工具。它们成功的关键在于识别出一个可信的外生变异来源，并仔细审视和论证其背后的识别假设。理解这些设计的原则与机制，是成为一个有能力的流行病学家或政策评估者的核心技能。