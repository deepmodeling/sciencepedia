{
    "hands_on_practices": [
        {
            "introduction": "Before a single participant is enrolled in a randomized controlled trial, investigators must answer a critical question: how many participants are needed? This exercise guides you through a first-principles derivation of one of the most common sample size formulas. By building the formula from the ground up, you will gain a deeper understanding of the interplay between statistical power, significance levels, and the expected effect size, empowering you to design statistically robust trials. ",
            "id": "4628034",
            "problem": "Consider a two-arm randomized controlled trial with equal allocation to intervention and control, evaluating a binary outcome observed once per participant at a common follow-up time under stable conditions. Let $p_0$ denote the true event probability in the control arm and $p_1$ the true event probability in the intervention arm. The target effect is the risk difference $\\Delta = p_1 - p_0$, and suppose the design aims to test the null hypothesis $H_0: p_1 - p_0 = 0$ against the two-sided alternative $H_1: p_1 - p_0 \\neq 0$ at type I error $\\,\\alpha\\,$ and achieve power $\\,1 - \\beta\\,$ to detect the prespecified nonzero risk difference $\\,\\Delta\\,$.\n\nUse the following fundamental base:\n- Under independent sampling, the sample proportion $\\hat{p}_a$ in arm $a \\in \\{0,1\\}$ has large-sample distribution $\\hat{p}_a \\approx \\mathcal{N}\\!\\left(p_a,\\, p_a(1 - p_a)/n\\right)$ for $n$ participants per arm, by the Central Limit Theorem, and the two arms are independent under equal allocation.\n- The difference in sample proportions $D = \\hat{p}_1 - \\hat{p}_0$ is approximately normal with mean $p_1 - p_0$ and variance $p_1(1 - p_1)/n + p_0(1 - p_0)/n$ by independence.\n- For a $2$-sided $\\alpha$-level test of $H_0$, a rejection threshold is set using the standard normal quantile function $\\Phi^{-1}(\\cdot)$ and a design-stage null variance. Let the design-stage pooled planning value be $p_{\\ast} = (p_0 + p_1)/2$, giving a null standard deviation $\\sqrt{2\\,p_{\\ast}(1 - p_{\\ast})/n}$ for $D$.\n\nStarting from these bases and without invoking any pre-memorized sample size formula, derive the closed-form analytic expression for the required per-arm sample size $n$ (an integer is not required; ignore any integer rounding) that ensures type I error $\\,\\alpha\\,$ and power $\\,1 - \\beta\\,$ to detect the risk difference $\\Delta$ under equal allocation. Express your final answer as a single analytic expression in terms of $p_0$, $p_1$, $\\alpha$, $\\beta$, and $\\Delta$, and the standard normal quantile function $\\Phi^{-1}(\\cdot)$. You may assume $\\Delta \\neq 0$. No numerical evaluation is required, and no rounding is required. The answer must be the per-arm sample size.",
            "solution": "The problem statement is a valid, well-posed question in the field of biostatistics, specifically concerning the design of randomized controlled trials. It provides a complete and consistent set of givens and assumptions from which a unique, analytical solution can be derived.\n\n### Step 1: Extract Givens\n-   **Study Design**: Two-arm randomized controlled trial with equal allocation ($n$ participants per arm).\n-   **Outcome**: Binary.\n-   **Parameters**: $p_0$ is the true event probability in the control arm; $p_1$ is the true event probability in the intervention arm.\n-   **Effect Measure**: Risk difference, $\\Delta = p_1 - p_0$.\n-   **Hypotheses**: Null hypothesis $H_0: p_1 - p_0 = 0$; alternative hypothesis $H_1: p_1 - p_0 \\neq 0$.\n-   **Error Rates**: Type I error rate is $\\alpha$; Type II error rate is $\\beta$, corresponding to a power of $1 - \\beta$.\n-   **Distributional Assumptions**:\n    1.  The sample proportion in arm $a \\in \\{0,1\\}$, denoted $\\hat{p}_a$, is approximately normally distributed: $\\hat{p}_a \\sim \\mathcal{N}(p_a, \\frac{p_a(1-p_a)}{n})$.\n    2.  The difference in sample proportions, $D = \\hat{p}_1 - \\hat{p}_0$, is approximately normally distributed: $D \\sim \\mathcal{N}(p_1 - p_0, \\frac{p_1(1-p_1)}{n} + \\frac{p_0(1-p_0)}{n})$.\n-   **Test Construction**:\n    1.  The test uses the standard normal quantile function $\\Phi^{-1}(\\cdot)$.\n    2.  For design, the null variance of $D$ is based on a planning value $p_{\\ast} = (p_0 + p_1)/2$, yielding a standard deviation for $D$ under $H_0$ of $\\sqrt{2 p_{\\ast}(1-p_{\\ast})/n}$.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is based on the well-established statistical theory for comparing two proportions using the normal approximation to the binomial distribution, which is a fundamental concept in designing clinical trials.\n-   **Well-Posed**: The problem is clearly defined, providing all necessary parameters ($\\alpha, \\beta, p_0, p_1$) and distributional foundations to derive the required sample size, $n$. The instructions are explicit and lead to a unique solution.\n-   **Objective**: The language is formal, precise, and devoid of any subjectivity or ambiguity.\n\nThe problem is valid as it satisfies all criteria for a well-formulated scientific question.\n\n### Derivation of the Sample Size Formula\n\nThe objective is to derive an expression for the per-arm sample size, $n$, that satisfies the specified type I and type II error constraints. The derivation proceeds from the given first principles.\n\n**1. Type I Error and the Rejection Rule**\n\nThe null hypothesis is $H_0: \\Delta = p_1 - p_0 = 0$. The test statistic is the observed difference in proportions, $D = \\hat{p}_1 - \\hat{p}_0$.\n\nAccording to the problem statement, for the purpose of trial design, the distribution of $D$ under $H_0$ is taken to be approximately normal with a mean of $0$ and a variance, $\\text{Var}_0(D)$, constructed using the planning value $p_{\\ast} = (p_0 + p_1)/2$.\n$$ \\text{Var}_0(D) = \\frac{2 p_{\\ast}(1 - p_{\\ast})}{n} = \\frac{2 \\left(\\frac{p_0+p_1}{2}\\right) \\left(1 - \\frac{p_0+p_1}{2}\\right)}{n} $$\nFor a two-sided test with a type I error rate of $\\alpha$, we reject $H_0$ if the observed difference $|D|$ is greater than a critical value, $C$. This critical value is determined by the tails of the null distribution. The standardized statistic under $H_0$ would be $Z = D / \\sqrt{\\text{Var}_0(D)}$. We reject if $|Z| > \\Phi^{-1}(1 - \\alpha/2)$.\nThis implies that the rejection region for the unstandardized difference $D$ is $|D| > C$, where:\n$$ C = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\text{Var}_0(D)} = \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\frac{2 p_{\\ast}(1 - p_{\\ast})}{n}} $$\n\n**2. Type II Error and Power**\n\nPower is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_1$ is true. Under $H_1$, the true difference is $\\Delta = p_1 - p_0 \\neq 0$.\n\nThe distribution of $D$ under $H_1$ is approximately normal with mean $\\Delta$ and variance $\\text{Var}_1(D)$:\n$$ D \\sim \\mathcal{N}\\left(\\Delta, \\text{Var}_1(D)\\right) \\quad \\text{where} \\quad \\text{Var}_1(D) = \\frac{p_1(1-p_1)}{n} + \\frac{p_0(1-p_0)}{n} $$\nThe power, $1 - \\beta$, is the probability that $D$ falls in the rejection region, i.e., $P(|D| > C | H_1)$.\n$$ 1 - \\beta = P(D > C | H_1) + P(D  -C | H_1) $$\nAssuming $\\Delta > 0$ (the case for $\\Delta  0$ is symmetric), the term $P(D  -C | H_1)$ is typically negligible for a well-powered study, as the distribution of $D$ is centered far from $-C$. Thus, we can approximate the power by the first term:\n$$ 1 - \\beta \\approx P(D > C | H_1) $$\nTo evaluate this probability, we standardize $D$ using its distribution under $H_1$:\n$$ 1 - \\beta \\approx P\\left( \\frac{D - \\Delta}{\\sqrt{\\text{Var}_1(D)}} > \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} \\right) $$\nThe term on the left inside the probability is a standard normal variable, $Z \\sim \\mathcal{N}(0,1)$.\n$$ P\\left( Z > \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} \\right) = 1 - \\beta $$\nFrom the definition of the standard normal cumulative distribution function, $\\Phi$, this implies:\n$$ \\frac{C - \\Delta}{\\sqrt{\\text{Var}_1(D)}} = \\Phi^{-1}(1 - (1-\\beta)) = \\Phi^{-1}(\\beta) $$\nSolving for the critical value $C$, we obtain a second expression for it, this time from the power requirement:\n$$ C = \\Delta + \\Phi^{-1}(\\beta) \\sqrt{\\text{Var}_1(D)} $$\n\n**3. Solving for the Sample Size, n**\n\nWe now have two expressions for the critical value $C$, one from the type I error constraint and one from the power constraint. By equating them, we can solve for $n$.\n$$ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{\\text{Var}_0(D)} = \\Delta + \\Phi^{-1}(\\beta) \\sqrt{\\text{Var}_1(D)} $$\nSubstitute the expressions for the variances, which both depend on $1/\\sqrt{n}$:\n$$ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\frac{\\sqrt{2 p_{\\ast}(1 - p_{\\ast})}}{\\sqrt{n}} = \\Delta + \\Phi^{-1}(\\beta) \\frac{\\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\sqrt{n}} $$\nRearrange the equation to isolate $\\Delta$:\n$$ \\Delta = \\frac{1}{\\sqrt{n}} \\left[ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} - \\Phi^{-1}(\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)} \\right] $$\nUsing the symmetry property of the standard normal quantile function, $\\Phi^{-1}(\\beta) = -\\Phi^{-1}(1-\\beta)$:\n$$ \\Delta = \\frac{1}{\\sqrt{n}} \\left[ \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)} \\right] $$\nNow, we solve for $\\sqrt{n}$ and then square the result to find $n$:\n$$ \\sqrt{n} = \\frac{\\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\Delta} $$\n$$ n = \\left( \\frac{\\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 p_{\\ast}(1 - p_{\\ast})} + \\Phi^{-1}(1-\\beta) \\sqrt{p_1(1-p_1) + p_0(1-p_0)}}{\\Delta} \\right)^2 $$\nSubstituting the definition of $p_{\\ast} = (p_0+p_1)/2$ and writing the expression as a single fraction yields the final closed-form expression for the per-arm sample size $n$.\n$$ n = \\frac{\\left( \\Phi^{-1}\\left(1 - \\frac{\\alpha}{2}\\right) \\sqrt{2 \\left(\\frac{p_0+p_1}{2}\\right)\\left(1 - \\frac{p_0+p_1}{2}\\right)} + \\Phi^{-1}(1-\\beta) \\sqrt{p_0(1-p_0) + p_1(1-p_1)} \\right)^2}{\\Delta^2} $$\nThis expression provides the required sample size per arm as a function of the specified parameters $p_0$, $p_1$, $\\alpha$, $\\beta$, and the risk difference $\\Delta = p_1-p_0$.",
            "answer": "$$ \\boxed{ \\frac{\\left( \\Phi^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\sqrt{2 \\left(\\frac{p_0+p_1}{2}\\right) \\left(1 - \\frac{p_0+p_1}{2}\\right)} + \\Phi^{-1}(1-\\beta) \\sqrt{p_0(1-p_0) + p_1(1-p_1)} \\right)^{2}}{\\Delta^{2}} } $$"
        },
        {
            "introduction": "Once trial data are collected, the next step is to quantify the intervention's effect. This practice challenges you to calculate three fundamental measures of effect for a binary outcome—the risk difference, risk ratio, and odds ratio—from hypothetical trial data. More importantly, it introduces the concept of collapsibility, a key statistical property that affects how these measures behave when we account for other patient characteristics and is crucial for their correct interpretation. ",
            "id": "4628160",
            "problem": "A Randomized Controlled Trial (RCT) evaluates a prophylactic intervention to reduce a binary outcome. Among $1000$ participants randomized to the intervention arm, $100$ experienced the outcome. Among $1000$ participants randomized to the control arm, $150$ experienced the outcome. Starting from first principles appropriate to epidemiology, use core definitions of probability, odds, and independence induced by randomization to derive and compute the following population effect measures from the observed data: the risk difference, the risk ratio, and the odds ratio. Then, reason from the definition of collapsibility (marginal effect equaling the common stratum-specific effect under randomization and no effect modification) to determine which of these three measures are collapsible in the context of randomized assignment with no unmeasured confounders. Express the final answer as a row matrix in the order $[\\text{risk difference}, \\text{risk ratio}, \\text{odds ratio}, I_{\\text{RD}}, I_{\\text{RR}}, I_{\\text{OR}}]$, where $I_{\\text{RD}}$, $I_{\\text{RR}}$, and $I_{\\text{OR}}$ are indicator variables taking value $1$ if the measure is collapsible and $0$ otherwise. Provide the risk difference, risk ratio, and odds ratio in exact fractional form if possible; if you choose to provide decimal approximations, round to $4$ significant figures. No physical units are involved; report all quantities as dimensionless numbers.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of epidemiology and biostatistics, is well-posed with sufficient and consistent information, and is stated objectively.\n\nLet $X$ denote the treatment assignment, where $X=1$ for the intervention arm and $X=0$ for the control arm. Let $Y$ denote the binary outcome, where $Y=1$ if the outcome occurred and $Y=0$ if it did not. The problem provides the following data from a Randomized Controlled Trial (RCT):\nFor the intervention arm ($X=1$):\n- Number of participants: $N_1 = 1000$\n- Number with the outcome: $A_1 = 100$\n- Number without the outcome: $B_1 = N_1 - A_1 = 1000 - 100 = 900$\n\nFor the control arm ($X=0$):\n- Number of participants: $N_0 = 1000$\n- Number with the outcome: $A_0 = 150$\n- Number without the outcome: $B_0 = N_0 - A_0 = 1000 - 150 = 850$\n\nThe task is to derive and compute three effect measures (risk difference, risk ratio, odds ratio) and determine their collapsibility property.\n\nFirst, we define the risk (probability) of the outcome in each arm. The risk is the conditional probability of the outcome given the treatment assignment, $P(Y=1|X=x)$. In an RCT, these probabilities are estimated directly from the observed proportions in each arm.\n\nThe risk in the intervention arm is estimated as:\n$$ \\hat{R}_1 = \\frac{A_1}{N_1} = \\frac{100}{1000} = \\frac{1}{10} $$\nThe risk in the control arm is estimated as:\n$$ \\hat{R}_0 = \\frac{A_0}{N_0} = \\frac{150}{1000} = \\frac{15}{100} = \\frac{3}{20} $$\n\n**Part 1: Calculation of Effect Measures**\n\n1.  **Risk Difference (RD)**: The risk difference is the arithmetic difference in risks between the two arms.\n    $$ RD = R_1 - R_0 $$\n    Using the sample estimates:\n    $$ \\hat{RD} = \\hat{R}_1 - \\hat{R}_0 = \\frac{1}{10} - \\frac{3}{20} = \\frac{2}{20} - \\frac{3}{20} = -\\frac{1}{20} $$\n\n2.  **Risk Ratio (RR)**: The risk ratio is the ratio of the risks in the two arms.\n    $$ RR = \\frac{R_1}{R_0} $$\n    Using the sample estimates:\n    $$ \\hat{RR} = \\frac{\\hat{R}_1}{\\hat{R}_0} = \\frac{1/10}{3/20} = \\frac{1}{10} \\times \\frac{20}{3} = \\frac{20}{30} = \\frac{2}{3} $$\n\n3.  **Odds Ratio (OR)**: First, we define the odds of an outcome as the ratio of the probability of the outcome occurring to the probability of it not occurring.\n    $$ \\text{Odds}(x) = \\frac{P(Y=1|X=x)}{P(Y=0|X=x)} = \\frac{R_x}{1-R_x} $$\n    The odds ratio is the ratio of the odds in the intervention arm to the odds in the control arm.\n    $$ OR = \\frac{\\text{Odds}(1)}{\\text{Odds}(0)} = \\frac{R_1 / (1-R_1)}{R_0 / (1-R_0)} $$\n    The sample odds are:\n    $$ \\hat{\\text{Odds}}_1 = \\frac{\\hat{R}_1}{1-\\hat{R}_1} = \\frac{1/10}{1 - 1/10} = \\frac{1/10}{9/10} = \\frac{1}{9} $$\n    $$ \\hat{\\text{Odds}}_0 = \\frac{\\hat{R}_0}{1-\\hat{R}_0} = \\frac{3/20}{1 - 3/20} = \\frac{3/20}{17/20} = \\frac{3}{17} $$\n    The sample odds ratio is:\n    $$ \\hat{OR} = \\frac{\\hat{\\text{Odds}}_1}{\\hat{\\text{Odds}}_0} = \\frac{1/9}{3/17} = \\frac{1}{9} \\times \\frac{17}{3} = \\frac{17}{27} $$\n    Alternatively, the odds ratio can be computed as the cross-product ratio from the $2 \\times 2$ contingency table:\n    $$ \\hat{OR} = \\frac{A_1 B_0}{A_0 B_1} = \\frac{100 \\times 850}{150 \\times 900} = \\frac{85000}{135000} = \\frac{85}{135} = \\frac{17}{27} $$\n\n**Part 2: Collapsibility Analysis**\n\nCollapsibility refers to the property that a marginal (crude) measure of effect is equal to a common stratum-specific measure of effect, given there is no effect modification across strata. The stratification is done by a third variable, say $Z$. The problem specifies the context of \"randomized assignment with no unmeasured confounders\" and \"no effect modification\".\n\nLet $Z$ be a baseline covariate (e.g., age, sex) with levels $k=1, 2, \\dots, K$.\nThe marginal risk in arm $x$ is $R_x = P(Y=1|X=x)$. By the law of total probability, we can expand this over the strata of $Z$:\n$$ R_x = \\sum_{k=1}^{K} P(Y=1|X=x, Z=k) P(Z=k|X=x) $$\nLet $R_{xk} = P(Y=1|X=x, Z=k)$ be the stratum-specific risk.\nIn an RCT, randomization ensures that the treatment assignment $X$ is statistically independent of any baseline covariate $Z$. Thus, $P(Z=k|X=x) = P(Z=k)$ for all $x$. Let $p_k = P(Z=k)$.\nThe marginal risks are then a weighted average of the stratum-specific risks:\n$$ R_1 = \\sum_{k} R_{1k} p_k $$\n$$ R_0 = \\sum_{k} R_{0k} p_k $$\nThe condition \"no effect modification\" means the effect measure is constant across the strata of $Z$.\n\n- **Risk Difference (RD)**:\n  The marginal RD is $RD = R_1 - R_0$. The stratum-specific RD is $RD_k = R_{1k} - R_{0k}$.\n  The \"no effect modification\" condition implies $RD_k = RD_{\\text{common}}$ for all $k$.\n  $$ RD = R_1 - R_0 = \\sum_{k} R_{1k} p_k - \\sum_{k} R_{0k} p_k = \\sum_{k} (R_{1k} - R_{0k}) p_k = \\sum_{k} RD_k p_k $$\n  Substituting $RD_k = RD_{\\text{common}}$:\n  $$ RD = \\sum_{k} RD_{\\text{common}} p_k = RD_{\\text{common}} \\sum_{k} p_k = RD_{\\text{common}} \\times 1 = RD_{\\text{common}} $$\n  The marginal RD equals the common stratum-specific RD. Therefore, the risk difference is collapsible. $I_{\\text{RD}} = 1$.\n\n- **Risk Ratio (RR)**:\n  The marginal RR is $RR = R_1 / R_0$. The stratum-specific RR is $RR_k = R_{1k} / R_{0k}$.\n  The \"no effect modification\" condition implies $RR_k = RR_{\\text{common}}$ for all $k$, so $R_{1k} = RR_{\\text{common}} \\times R_{0k}$.\n  $$ RR = \\frac{R_1}{R_0} = \\frac{\\sum_{k} R_{1k} p_k}{\\sum_{k} R_{0k} p_k} $$\n  Substituting $R_{1k} = RR_{\\text{common}} R_{0k}$:\n  $$ RR = \\frac{\\sum_{k} (RR_{\\text{common}} R_{0k}) p_k}{\\sum_{k} R_{0k} p_k} = \\frac{RR_{\\text{common}} \\sum_{k} R_{0k} p_k}{\\sum_{k} R_{0k} p_k} = RR_{\\text{common}} $$\n  The marginal RR equals the common stratum-specific RR. Therefore, the risk ratio is collapsible. $I_{\\text{RR}} = 1$.\n\n- **Odds Ratio (OR)**:\n  The marginal OR is $OR = \\frac{R_1/(1-R_1)}{R_0/(1-R_0)}$. The stratum-specific OR is $OR_k = \\frac{R_{1k}/(1-R_{1k})}{R_{0k}/(1-R_{0k})}$.\n  The \"no effect modification\" condition implies $OR_k = OR_{\\text{common}}$ for all $k$.\n  The odds function, $f(p) = p/(1-p)$, is a non-linear convex function for $p \\in (0, 0.5)$ and concave for $p \\in (0.5, 1)$. Due to this non-linearity, the weighted average of risks does not translate into a simple form for the odds. The marginal odds are:\n  $$ \\text{Odds}_1 = \\frac{\\sum_k R_{1k}p_k}{1 - \\sum_k R_{1k}p_k} \\quad \\text{and} \\quad \\text{Odds}_0 = \\frac{\\sum_k R_{0k}p_k}{1 - \\sum_k R_{0k}p_k} $$\n  By Jensen's inequality, for a non-linear function $f$, $f(E[X]) \\neq E[f(X)]$. Here, the marginal risk $R_x$ is the expectation of the stratum-specific risks $R_{xk}$ over the distribution of $Z$. Thus, the marginal odds, $\\text{Odds}_x = f(R_x) = f(E[R_{xk}])$, are not equal to the weighted average of the stratum-specific odds, $E[f(R_{xk})] = \\sum_k f(R_{xk}) p_k$.\n  Consequently, the marginal odds ratio $OR = \\text{Odds}_1 / \\text{Odds}_0$ will not, in general, be equal to the common stratum-specific odds ratio $OR_{\\text{common}}$, unless $Z$ is not a risk factor for the outcome (i.e., $R_{0k}$ is constant over $k$) or the treatment has no effect ($OR_{\\text{common}}=1$). Since these exceptions are not generally true, the odds ratio is non-collapsible. $I_{\\text{OR}} = 0$.\n\nCombining the results, the final values are:\n- Risk Difference: $-\\frac{1}{20}$\n- Risk Ratio: $\\frac{2}{3}$\n- Odds Ratio: $\\frac{17}{27}$\n- $I_{\\text{RD}} = 1$ (collapsible)\n- $I_{\\text{RR}} = 1$ (collapsible)\n- $I_{\\text{OR}} = 0$ (non-collapsible)\n\nThe final answer will be presented as a row matrix.\n$$\n\\begin{pmatrix}\n-\\frac{1}{20}  \\frac{2}{3}  \\frac{17}{27}  1  1  0\n\\end{pmatrix}\n$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{1}{20}  \\frac{2}{3}  \\frac{17}{27}  1  1  0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While risk differences and ratios are statistically essential, clinicians often prefer a more intuitive metric: the Number Needed to Treat (NNT). This exercise focuses on translating the absolute risk reduction from a trial into the NNT, a powerful tool for communicating clinical significance. You will also explore the statistical challenges in quantifying the uncertainty around the NNT, learning why simple methods fail and how to construct a more robust confidence interval. ",
            "id": "4628182",
            "problem": "A parallel two-arm Randomized Controlled Trial (RCT) evaluates an intervention intended to reduce an adverse outcome. In the treatment arm, $n_{T} = 500$ participants are randomized and $x_{T} = 60$ experience the outcome. In the control arm, $n_{C} = 500$ participants are randomized and $x_{C} = 100$ experience the outcome. Using only fundamental definitions for risks and sampling variability under independent binomial sampling, do the following:\n\n1. From first principles, define the arm-specific risks $p_{T}$ and $p_{C}$, the risk difference $RD$, and the absolute risk reduction $\\Delta$ appropriate for a beneficial intervention that reduces the adverse outcome. Then compute the number needed to treat (NNT) as the reciprocal of the absolute risk reduction. Express the NNT as a count of patients and round your numerical answer to three significant figures.\n\n2. Derive the large-sample variance of the estimated risk difference under the assumption that outcomes in the two arms are independent Bernoulli trials, and explain how this variance relates to the variability of the NNT via the delta method. Provide the symbolic expression for the approximate standard error of the NNT in terms of $\\Delta$, $p_{T}$, $p_{C}$, $n_{T}$, and $n_{C}$.\n\n3. Briefly justify why a naive symmetric confidence interval for the NNT based on the delta method may be inappropriate, and propose an interval estimation strategy that constructs a confidence interval for the NNT by inverting a two-sided confidence interval for the risk difference (for example, based on a score or Wilson-type method for differences in proportions). State the closed-form transformation that maps the endpoints of the risk difference interval to the endpoints of the NNT interval when the intervention is beneficial (that is, when $\\Delta > 0$). Do not compute any numerical interval endpoints.\n\nRound any required numerical value to three significant figures. If units are needed, express the NNT in patients. Percentages must be expressed as decimals or fractions, not with a percentage sign.",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It presents a standard biostatistical analysis scenario based on data from a randomized controlled trial. All necessary information is provided, and the questions are internally consistent and solvable using established principles of epidemiology and statistics.\n\n### Part 1: Definitions and Calculation of NNT\n\nFrom first principles, we define the arm-specific risks and related measures. Let $p_{T}$ be the true probability of the adverse outcome in the treatment arm and $p_{C}$ be the true probability in the control arm. These are population parameters. The problem provides sample data from which we can estimate these risks.\n\nThe point estimator for the risk in the treatment arm is given by the sample proportion:\n$$ \\hat{p}_{T} = \\frac{x_{T}}{n_{T}} = \\frac{60}{500} = 0.12 $$\nThe point estimator for the risk in the control arm is:\n$$ \\hat{p}_{C} = \\frac{x_{C}}{n_{C}} = \\frac{100}{500} = 0.20 $$\n\nThe risk difference ($RD$) is defined as the difference between the risk in the treatment arm and the control arm:\n$$ RD = p_{T} - p_{C} $$\nIts point estimate is $\\widehat{RD} = \\hat{p}_{T} - \\hat{p}_{C} = 0.12 - 0.20 = -0.08$.\n\nThe absolute risk reduction ($\\Delta$) is defined for a beneficial intervention, where the risk is reduced. Thus, it is the difference between the control risk and the treatment risk:\n$$ \\Delta = p_{C} - p_{T} $$\nThe point estimate for the absolute risk reduction is:\n$$ \\hat{\\Delta} = \\hat{p}_{C} - \\hat{p}_{T} = 0.20 - 0.12 = 0.08 $$\nThis positive value indicates that the observed risk in the treatment group is lower than in the control group, consistent with a beneficial intervention.\n\nThe Number Needed to Treat (NNT) is defined as the reciprocal of the absolute risk reduction. It represents the estimated number of patients that need to be treated with the intervention to prevent one additional adverse outcome, compared to the control.\n$$ NNT = \\frac{1}{\\Delta} $$\nThe point estimate for the NNT is calculated using the estimated absolute risk reduction:\n$$ \\widehat{NNT} = \\frac{1}{\\hat{\\Delta}} = \\frac{1}{0.08} = 12.5 $$\nThe problem requires this to be expressed as a count of patients, rounded to three significant figures. The calculated value of $12.5$ already has three significant figures. Therefore, the estimated NNT is $12.5$ patients. Conventionally, NNT is often rounded up to the next integer, but adhering to the explicit instruction, the value is $12.5$.\n\n### Part 2: Variance Derivation and Standard Error of NNT\n\nThe derivation of the large-sample variance of the estimated risk difference assumes that the outcomes in the two arms are independent Bernoulli trials. The number of events in each arm, $x_{T}$ and $x_{C}$, follows a binomial distribution:\n$$ x_{T} \\sim \\text{Binomial}(n_{T}, p_{T}) \\quad \\text{and} \\quad x_{C} \\sim \\text{Binomial}(n_{C}, p_{C}) $$\nThe variance of a sample proportion $\\hat{p} = x/n$ is $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$. Thus, the variances of the arm-specific risk estimators are:\n$$ \\text{Var}(\\hat{p}_{T}) = \\frac{p_{T}(1-p_{T})}{n_{T}} \\quad \\text{and} \\quad \\text{Var}(\\hat{p}_{C}) = \\frac{p_{C}(1-p_{C})}{n_{C}} $$\nThe estimated absolute risk reduction is $\\hat{\\Delta} = \\hat{p}_{C} - \\hat{p}_{T}$. Since the two trial arms are independent, the variance of the difference of the estimators is the sum of their variances:\n$$ \\text{Var}(\\hat{\\Delta}) = \\text{Var}(\\hat{p}_{C} - \\hat{p}_{T}) = \\text{Var}(\\hat{p}_{C}) + \\text{Var}(\\hat{p}_{T}) = \\frac{p_{C}(1-p_{C})}{n_{C}} + \\frac{p_{T}(1-p_{T})}{n_{T}} $$\nThis is the large-sample variance of the estimated risk difference.\n\nTo find the variability of the NNT, we use the delta method. The NNT is a non-linear function of the absolute risk reduction, $g(\\Delta) = 1/\\Delta$. The delta method provides a first-order Taylor series approximation for the variance of a function of a random variable. For a function $g(Y)$, the approximate variance is $\\text{Var}(g(Y)) \\approx [g'(E[Y])]^{2} \\text{Var}(Y)$.\nIn our case, $Y = \\hat{\\Delta}$, $E[Y] = \\Delta$, and the function is $g(\\Delta) = 1/\\Delta$. The derivative is:\n$$ g'(\\Delta) = \\frac{d}{d\\Delta}\\left(\\frac{1}{\\Delta}\\right) = -\\frac{1}{\\Delta^{2}} $$\nApplying the delta method, the approximate variance of the $\\widehat{NNT}$ is:\n$$ \\text{Var}(\\widehat{NNT}) \\approx [g'(\\Delta)]^{2} \\text{Var}(\\hat{\\Delta}) = \\left(-\\frac{1}{\\Delta^{2}}\\right)^{2} \\text{Var}(\\hat{\\Delta}) = \\frac{1}{\\Delta^{4}} \\text{Var}(\\hat{\\Delta}) $$\nThe standard error (SE) is the square root of the variance. Therefore, the symbolic expression for the approximate standard error of the NNT is:\n$$ \\text{SE}(\\widehat{NNT}) \\approx \\sqrt{\\frac{1}{\\Delta^{4}} \\text{Var}(\\hat{\\Delta})} = \\frac{1}{\\Delta^{2}} \\sqrt{\\text{Var}(\\hat{\\Delta})} $$\nSubstituting the expression for $\\text{Var}(\\hat{\\Delta})$ yields the final symbolic expression:\n$$ \\text{SE}(\\widehat{NNT}) \\approx \\frac{1}{\\Delta^{2}} \\sqrt{\\frac{p_{C}(1-p_{C})}{n_{C}} + \\frac{p_{T}(1-p_{T})}{n_{T}}} $$\nIn practice, the unknown parameters $\\Delta$, $p_{C}$, and $p_{T}$ would be replaced by their sample estimates $\\hat{\\Delta}$, $\\hat{p}_{C}$, and $\\hat{p}_{T}$ to compute a numerical value for the standard error.\n\n### Part 3: Confidence Interval for NNT\n\nA naive symmetric confidence interval for the NNT, constructed as $\\widehat{NNT} \\pm z_{\\alpha/2} \\times \\text{SE}(\\widehat{NNT})$, is inappropriate for several fundamental reasons:\n1.  **Non-linearity and Skewness**: The relationship $NNT = 1/\\Delta$ is highly non-linear. The sampling distribution of $\\hat{\\Delta}$ may be approximately normal for large samples, but the distribution of $1/\\hat{\\Delta}$ is not. It is highly skewed, especially when $\\Delta$ is close to $0$, making a symmetric interval based on the normal approximation invalid.\n2.  **Boundary Problems**: As $\\hat{\\Delta}$ approaches $0$, $\\widehat{NNT}$ approaches $\\pm\\infty$. A symmetric confidence interval calculated using the delta method can produce nonsensical results. For example, it might include negative values even when the point estimate is positive and indicates benefit, wrongly suggesting a number needed to harm. It can also include $0$, which is not interpretable for NNT.\n3.  **Inclusion of Zero by the Risk Difference Interval**: If the confidence interval for the risk difference $\\Delta$ includes $0$ (i.e., the result is not statistically significant), the corresponding confidence interval for NNT should logically span from some NNT value to $\\infty$ and from $-\\infty$ to some NNH (Number Needed to Harm) value. A simple symmetric interval cannot represent this discontinuous range.\n\nA more robust and appropriate strategy is to first construct a confidence interval for the risk difference, $\\Delta$, and then transform its endpoints to obtain a confidence interval for the NNT. This is known as the inversion method.\nThe procedure is as follows:\n1.  Calculate a $(1-\\alpha)$ confidence interval for $\\Delta = p_{C} - p_{T}$. Let this interval be $[L_{\\Delta}, U_{\\Delta}]$. It is preferable to use methods that perform well for proportions, such as the Wilson score interval for the difference, rather than the simpler Wald interval, especially if proportions are near $0$ or $1$ or sample sizes are modest.\n2.  Apply the transformation $g(\\Delta) = 1/\\Delta$ to the endpoints $L_{\\Delta}$ and $U_{\\Delta}$.\n\nThe problem asks for the closed-form transformation when the intervention is beneficial ($\\Delta > 0$). In this scenario, we consider a case where the confidence interval for the risk difference is entirely positive, i.e., $0  L_{\\Delta} \\leq U_{\\Delta}$. The function $f(x) = 1/x$ is a strictly decreasing function for $x > 0$. Consequently, the transformation reverses the order of the endpoints. The upper bound for $\\Delta$ becomes the lower bound for NNT, and the lower bound for $\\Delta$ becomes the upper bound for NNT.\n\nTherefore, the closed-form transformation that maps the endpoints of the risk difference interval $[L_{\\Delta}, U_{\\Delta}]$ to the endpoints of the NNT interval is:\n$$ \\text{CI}_{NNT} = \\left[ \\frac{1}{U_{\\Delta}}, \\frac{1}{L_{\\Delta}} \\right] $$\nThis method correctly handles the non-linearity and asymmetry, yielding an interval that is philosophically and mathematically more coherent than the naive symmetric approach. If the interval for $\\Delta$ were to span $0$, e.g., $L_{\\Delta}  0  U_{\\Delta}$, this method correctly yields a discontinuous interval for NNT, $(-\\infty, 1/L_{\\Delta}] \\cup [1/U_{\\Delta}, \\infty)$, reflecting the non-significant result.",
            "answer": "$$\n\\boxed{12.5}\n$$"
        }
    ]
}