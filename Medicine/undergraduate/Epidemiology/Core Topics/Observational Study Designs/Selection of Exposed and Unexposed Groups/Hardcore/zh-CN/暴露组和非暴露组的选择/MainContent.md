## 引言
在流行病学和公共卫生领域，我们持续探索各种暴露（如药物、[环境污染](@entry_id:197929)物或生活方式）与健康结局之间的关系。然而，要确定观察到的关联是否为真正的因果关系，而非由其他因素驱动的假象，是该领域面临的核心挑战。这一挑战的答案，在很大程度上取决于我们如何构建用于比较的参照群体——即未暴露组。一个理想的比较组应该能告诉我们：如果暴露组的个体未曾接受暴露，他们的结局将会是怎样？

本文旨在系统性地解决在观察性研究中选择暴露组与未暴露组这一关键问题。许多研究结论的谬误源于比较[组选择](@entry_id:175784)不当，导致了难以察觉的混杂和选择偏倚。本文将填补理论与实践之间的鸿沟，为研究者提供一套完整的决策框架。

通过阅读本文，您将深入学习三个核心层面：首先，在“原理与机制”章节中，我们将奠定因果推断的理论基础，包括潜在结局框架、[可交换性](@entry_id:263314)假设以及各种系统性偏倚的成因。其次，在“应用与跨学科联系”章节中，我们将通过药理流行病学、职业健康等领域的真实案例，展示这些原则如何被灵活运用于解决复杂的现实问题。最后，“动手实践”部分将提供具体的练习，帮助您将理论知识转化为可操作的分析技能。

## 原理与机制

在流行病学研究中，因果推断的核心挑战在于进行有效的比较。当我们观察到一项暴露（例如，一种新药或一项公共卫生干预）与某个结局（例如，疾病康复或死亡率下降）之间存在关联时，我们必须回答一个关键问题：这种关联是因果关系，还是仅仅由其他因素造成的虚假现象？问题的答案很大程度上取决于我们如何选择和构建用于比较的参照组，即未暴露组。一个理想的未暴露组应能告诉我们，如果暴露组中的个体没有接受暴露，他们将会发生什么。本章将深入探讨选择暴露组和未暴露组的根本原理，阐明实现有效比较所需满足的关键假设，剖析在实践中容易出现的各种偏倚，并介绍用于构建可比群体的先进设计策略。

### 因果推断的基石：潜在结局与可交换性

为了严谨地思考因果效应，流行病学家常使用**潜在结局 (potential outcomes)** 的理论框架。对于任何一个个体，我们设想其在两种不同暴露情境下的结局：如果接受暴露 ($X=1$)，其潜在结局为 $Y^1$；如果未接受暴露 ($X=0$)，其潜在结局为 $Y^0$。个体的因果效应就是这两个潜在结局之差，即 $Y^1 - Y^0$。然而，在现实世界中，我们面临一个根本性的难题：对于任何一个个体，我们只能观测到其中一个潜在结局——要么是接受暴露后的结局，要么是未接受暴露后的结局。我们永远无法同时观测到同一个体在两种情境下的不同结局。

这个难题的解决方案是转向群体层面，通过比较暴露组的平均结局与未暴露组的平均结局来估计平均因果效应，例如 $E[Y^1] - E[Y^0]$。然而，这种比较只有在两个组“可比”的情况下才有效。在因果推断的语言中，这种可比性被称为**可交换性 (exchangeability)**。

最理想的情况是**边际[可交换性](@entry_id:263314) (marginal exchangeability)**，即 $(Y^0, Y^1) \perp X$。这意味着暴露分配与潜在结局完全独立。换句话说，无论潜在结局如何，个体被分到暴露组或未暴露组的概率是相同的。这种情况在设计良好的大规模随机对照试验 (Randomized Controlled Trial, RCT) 中可以实现。通过随机化，我们可以期望（在大样本中）暴露组和未暴露组在所有测量的和未测量的基线特征上都相似，从而使它们成为彼此有效的反事实替代。

然而，在观察性研究中，暴露分配通常不是随机的。例如，医生更可能将新药开给病情更严重的患者，或者注重健康的人更可能接种疫苗。在这种情况下，暴露组和未暴露组在研究开始时就存在系统性差异。这些差异（即**混杂因素 (confounders)**）既与暴露相关，又与结局相关，会导致简单的组间比较产生偏倚。因此，在观察性研究中，我们追求一个更现实的目标：**条件可交换性 (conditional exchangeability)**。

条件[可交换性](@entry_id:263314)，记为 $(Y^0, Y^1) \perp X \mid Z$，指的是在给定的混杂因素集合 $Z$ 的同一层内，暴露分配与潜在结局是独立的。这意味着，对于具有相同特征 $Z$（例如，相同的年龄、性别、疾病严重程度）的个体亚群来说，他们接受暴露与否是“仿佛随机”的。如果我们能够识别并测量所有这些[共同原因](@entry_id:266381) $Z$，我们就可以通过在 $Z$ 的每个层内进行比较，或者通过统计方法（如分层、匹配或回归）对 $Z$ 进行调整，来获得无偏的因果效应估计 。

**有向无环图 (Directed Acyclic Graphs, DAGs)** 为理解和实现条件可交换性提供了一个强大的可视化工具。在DAG中，变量之间的因果关系用箭头表示。混杂现象表现为一条从混杂因素 $Z$ 分别指向暴露 $X$ 和结局 $Y$ 的“后门路径” (backdoor path)，例如 $X \leftarrow Z \rightarrow Y$。为了满足条件可交换性，我们需要选择一个调整集 $Z$，该集合能够阻断所有连接 $X$ 和 $Y$ 的非因果路径（即后门路径），同时不阻断任何因果路径（从 $X$ 指向 $Y$ 的路径）。这就是**[后门准则](@entry_id:637856) (backdoor criterion)**。一个有效的调整集 $Z$ 必须满足两个条件：(1) $Z$ 中没有变量是 $X$ 的后代（即不受 $X$ 影响）；(2) $Z$ 能够阻断所有以箭头指向 $X$ 开头的路径 。例如，在一个研究疫苗接种 $(X)$ 对住院 $(Y)$ 影响的DAG中，如果存在混杂因素如年龄和合并症 $(C)$ 以及健康寻求行为 $(L)$，即存在路径 $X \leftarrow C \rightarrow Y$ 和 $X \leftarrow L \rightarrow Y$，那么一个有效的调整集 $Z$ 必须包含 $C$ 和 $L$。

### 因果推断的三个核心假设

除了[可交换性](@entry_id:263314)，从观察性数据中识别因果效应还需要另外两个关键假设：一致性和正性。这三者共同构成了因果推断的基石。

#### 一致性与稳定单位治疗价值假设 (SUTVA)

**一致性 (Consistency)** 假设是连接潜在结局和我们实际观测到的结局的桥梁。它规定，如果一个个体实际接受的暴露水平是 $X=x$，那么他/她的观测结局 $Y$ 就等于其在该暴露水平下的潜在结局 $Y^x$。形式上，对每个个体，有 $Y = Y^X$。这个假设看起来理所当然，但它要求暴露的定义必须清晰明确，没有歧义。

这就引出了一个更深层次的假设，即**稳定单位治疗价值假设 (Stable Unit Treatment Value Assumption, SUTVA)**。SUTVA包含两个子假设：
1.  **无干扰 (No interference)**：任何一个个体的潜在结局不受其他个体暴露状态的影响。例如，在疫苗研究中，一个人的免疫力可能受到周围人群接种率的影响（[群体免疫](@entry_id:139442)），这会违反该假设。
2.  **不存在隐藏的多种暴露版本 (No multiple versions of exposure)**：对于任意暴露水平 $x$，其干预效果是恒定的，不存在导致不同结局的多种版本。

第二个子假设在选择暴露组和未暴露组时尤其重要。在实践中，一个看似单一的暴露（如“接种疫苗”）可能捆绑了其他干预措施。例如，在一项评估流感疫苗 $(X)$ 对住院 $(Y)$ 影响的研究中，研究者发现接种疫苗的患者在出现流感样症状后，也更容易获得[抗病毒药物](@entry_id:171468)治疗 $(Z)$。这意味着，“接种疫苗”实际上代表了“疫苗 + 更高概率的抗病毒药物”这一组合疗法，而“未接种疫苗”则代表了“无疫苗 + 更低概率的[抗病毒药物](@entry_id:171468)”。此时，暴露 $X=1$ 存在多个版本，其效果取决于是否同时接受了 $Z$，导致潜在结局 $Y^1$ 的定义模糊不清，违反了SUTVA 。

解决这个问题有两种主要策略：
- **重新定义暴露**：将暴露定义为一个联合方案，如 $(X, Z)$。这样，每个暴露水平（例如，“接种疫苗且接受[抗病毒药物](@entry_id:171468)治疗”）都是明确且单一的。然后，我们可以比较两个明确定义的方案，例如比较 $(X=1, Z=1)$ 与 $(X=0, Z=1)$ 的效果。
- **限制研究人群**：将分析限制在共同干预措施恒定的亚组中。例如，仅分析那些没有接受抗病毒药物治疗 $(Z=0)$ 的患者，比较其中接种疫苗与未接种疫苗者的结局。这实际上是在估计一个特定亚人群中的因果效应 。

#### 正性 (Positivity)

**正性 (Positivity)**，也称为“重叠性” (overlap)，要求对于研究人群中具有任何给定协变量组合 $Z=z$ 的个体，他们接受每种暴露水平的概率都必须大于零且小于一。对于二元暴露，即 $0  P(X=1|Z=z)  1$。这个假设确保在 $Z$ 的每一层中，都同时存在暴露者和非暴露者，从而使得比较成为可能。

如果对于某个协变量组合 $z$，所有个体都接受了暴露（即 $P(X=1|Z=z) = 1$），或者所有个体都未接受暴露（即 $P(X=1|Z=z) = 0$），这就构成了**结构性正性违背 (structural positivity violation)**。例如，在一项评估高纤维饮食效果的研究中，如果患有晚期肾病的患者因医疗禁忌症而从不被推荐高纤维饮食，那么在“晚期肾病”这个协变量层中，就无法比较高纤维饮食与常规饮食的效果，因为根本不存在接受高纤维饮食的晚期肾病患者 。

当面临结构性正性违背时，唯一有效的处理方法是在研究设计阶段**限制研究人群**。研究者应明确地将那些暴露分配是确定性的协变量层排除在分析之外，并将研究的因果效应结论限定于那些“所有暴露选项在理论上都是可行的”人群。例如，在上述饮食研究中，研究者应将晚期肾病患者排除，并明确指出研究结论仅适用于无此类禁忌症的人群。此外，为了避免因数据稀疏导致的**实践性正性违背 (practical positivity violation)**，研究者应避免将协变量分层过细，并确保每个协变量-暴露组合的格子里有足够的样本量  。

### 比较[组选择](@entry_id:175784)中的常见偏倚

选择不当的比较组是导致观察性研究结论错误的主要原因。以下是一些在构建比较组时必须警惕的常见偏倚。

#### 适应证混杂与引导偏倚

**适应证混杂 (Confounding by indication)** 是观察性研究中最普遍的挑战之一。其根本原因在于，决定患者是否接受某种治疗（暴露）的因素——即治疗的“适应证”——本身就与疾病的预后（结局）密切相关。通常，病情更严重、预后更差的患者更有可能接受治疗。

**引导偏倚 (Channeling bias)** 是适应证混杂的一种特殊形式，指医生系统性地将具有特定预后特征的患者“引导”至某些特定的治疗方案。例如，在评估一种新型强效生物制剂 $(E)$ 对类风湿关节炎患者严重感染风险 $(Y)$ 的研究中，医生倾向于将该药物用于那些对传统疗法反应不佳、疾病活动度更高、存在未测量严重性因素 $(U)$ 的患者。这些未测量的严重性因素 $U$（如临床直觉、未记录的衰弱）既驱动了暴露分配 $(E \leftarrow U)$，又直接影响结局 $(U \rightarrow Y)$，形成了一条难以阻断的后门路径，从而导致严重的混杂偏倚 。

我们可以通过一个简单的线性模型来直观理解这种偏倚。假设结局 $Y$ 由以下结构决定：$Y = \mu + \tau A + \beta Z + \gamma T + \varepsilon$，其中 $A$ 是暴露，$\tau$ 是真实的因果效应， $Z$ 是基线风险评分（一个混杂因素），$T$ 是时期，$\beta$ 和 $\gamma$ 是其相应系数。暴露组 $(A=1)$ 的平均基线风险为 $m_1 = E[Z \mid A=1]$，而未暴露组 $(A=0)$ 的平均基线风险为 $m_0 = E[Z \mid A=0]$。一个简单的组间均值差异估计值为 $\Delta = E[Y|A=1] - E[Y|A=0] = \tau + \beta(m_1 - m_0)$。其偏倚量为 $\beta(m_1 - m_0)$。只有当 $Z$ 与结局无关 $(\beta=0)$ 或两组基线风险完全平衡 $(m_1 = m_0)$ 时，偏倚才会消失 。

#### 选择偏倚：当抽样过程本身成为混杂源

选择偏倚 (Selection bias) 发生在研究样本的纳入过程与暴露和结局均相关联时，导致样本中的关联模式不能代表目标人群中的真实关联。

**研究基础原则 (Study Base Principle)**：在病例-对照研究中，这一原则至关重要。它要求[对照组](@entry_id:188599)必须从产生病例的同一源头人群（即“研究基础”）中抽样。这样才能保证[对照组](@entry_id:188599)的暴露分布能代表源头人群在产生病例期间的暴露分布。如果[对照组](@entry_id:188599)从一个不同的群体（如来自不同医院或社区的群体）中抽样，而这个群体的成员资格又与暴露相关，那么选择过程本身就会引入偏倚。从数学上讲，如果入选研究的概率 $\Pr(S=1)$ 在非病例 $(Y=0)$ 中取决于暴露状态 $E$（即 $\Pr(S=1|E, Y=0) \neq \Pr(S=1|Y=0)$），那么计算出的优势比 (Odds Ratio) 将会是有偏的 。

**对撞机-分层偏倚 (Collider-Stratification Bias)**：这是一种更微妙但同样致命的选择偏倚。在DAG中，**对撞机 (collider)** 是一个同时被两个或多个其他变量指向的变量（例如，$A \rightarrow C \leftarrow B$）。默认情况下，[对撞机](@entry_id:192770)能阻断其父节点之间的路径。然而，如果我们对对撞机或其后代进行分层、匹配或以任何方式进行“控制”，就会打开这条原本被阻断的路径，从而在两个原本独立的父节点之间制造出虚假的关联。

医院研究是这种偏倚的典型重灾区。例如，一项研究旨在评估院前服用某种心脏保护药物 $(X)$ 对急性冠脉综合征患者院内死亡率 $(Y)$ 的影响。假设患者是否被医院收治 $(A)$ 取决于其就诊时的症状严重程度 $(S)$。而症状严重程度 $(S)$ 同时受到药物 $(X)$（减轻症状）和一种未测量的基础疾病进展过程 $(U)$（加重症状）的影响。同时，这个未测量的 $U$ 也直接导致更高的死亡率 $(Y)$。这个[因果结构](@entry_id:159914)可以表示为 $X \rightarrow S \leftarrow U \rightarrow Y$。在这里，$S$ 就是一个[对撞机](@entry_id:192770)。如果研究者将分析**仅限于入院患者** (即控制 $A=1$，而 $A$ 是 $S$ 的后代)，他们实际上就控制了[对撞机](@entry_id:192770) $S$。这将打开 $X$ 和 $U$ 之间的非因果路径，导致在入院患者中，$X$ 和 $U$ 产生虚假关联。例如，在症状严重程度相似的入院患者中，服用了药物（减轻了症状）的患者，其潜在的疾病进展过程 $U$ 必然比未服药者更严重。由于 $U$ 又导致死亡，这将使得药物看起来效果更差（或在某些情况下，效果更好），从而产生偏倚 。

#### 与时间相关的偏倚

在纵向研究中，对时间的处理不当是偏倚的另一个主要来源。

**不朽时间偏倚 (Immortal Time Bias)**：当一项暴露（如开始服药）不是在研究开始时 $(t=0)$ 发生，而是在随访过程中的某个时间点 $T^*$ 才发生时，这种偏倚就可能出现。从研究开始到暴露发生前的这段时间 $(0, T^*)$ 被称为“不朽时间”，因为个体必须“存活”过这段时间才能最终成为暴露者。一种幼稚的分析方法是将这些最终暴露的个体从 $t=0$ 开始就归类为“暴露组”。这种做法错误地将这段零风险（因为个体必须存活才能暴露）的“不朽”人时计入了暴露组的分母，从而人为地、虚假地降低了暴露组的事件发生率 。

**现患使用者偏倚 (Prevalent User Bias)**：这种偏倚发生在使用“现患使用者”（即在研究开始时已经在使用某种药物的患者）作为暴露组，并与“从未使用者”进行比较时。现患使用者是一个经过“筛选”的群体，他们是能够耐受药物且没有因副作用或无效而停药的“幸存者”。他们与刚开始使用药物的“新使用者” (new users) 在许多方面（如病程、依从性）都不可比。因此，这种设计会引入严重的选择偏倚 。

### 构建可比群体的设计策略

为了克服上述偏倚，流行病学家已经发展出一系列复杂而有效的设计和分析策略。

#### 新使用者、阳性对照设计

对于药物效果的[观察性研究](@entry_id:174507)，**新使用者、阳性对照设计 (new-user, active comparator design)** 被公认为是一种黄金标准方法。

- **新使用者设计**：该设计要求暴露组和比较组都由**新**开始使用某种疗法的患者组成。所有个体的随访时间零点 $(t=0)$ 都被设定在其各自开始用药的当天。这种设计通过对齐时间起点，天然地避免了不朽时间偏倚和现患使用者偏倚  。

- **阳性对照 (Active Comparator)**：该设计选择那些开始使用一种**替代性**标准疗法（用于相同适应证）的患者作为比较组，而不是选择未接受任何治疗的患者（“非使用者”）。这样做背后的逻辑是，接受新药和接受标准疗法的患者都因相似的临床原因（适应证）而被认为需要治疗，因此他们在疾病严重程度、健康状况等（包括测量的 $Z$ 和未测量的 $U$）方面更为相似。这极大地缓解了适应证混杂和引导偏倚 。

与之相比，其他比较组的选择则存在明显缺陷。选择**非使用者 (non-users)** 作为对照，会因严重的适应证混杂而产生巨大偏倚。选择**历史对照 (historical controls)**（即在新药上市前接受治疗的患者），则容易受到医疗实践、诊断标准、患者人群随时间变化的“时期效应” (secular trends) 的影响，同样会导致偏倚 。

#### 分析性调整：倾向性评分的角色

即使采用了精良的设计，统计调整仍然是控制剩余混杂因素所必需的。**倾向性评分 (Propensity Score, PS)** 是实现这一目标的核心工具。倾向性评分 $e(Z)$ 被定义为在给定一系列基线协变量 $Z$ 的条件下，一个个体接受暴露的[条件概率](@entry_id:151013)，即 $e(Z) = P(X=1|Z)$。

倾向性评分的强大之处在于它是一个“平衡得分” (balancing score)。Rosenbaum和Rubin的理论证明，如果条件[可交换性](@entry_id:263314)在协变量集 $Z$ 上成立，那么它在倾向性评分 $e(Z)$ 上也成立。这意味着，只要我们能使暴露组和未暴露组在倾向性评分上达到平衡，就等于在所有构成倾向性评分的协变量 $Z$ 上达到了平衡 。

一个典型的基于倾向性评分的分析流程如下：
1.  **定义协变量集 $Z$**：纳入所有与暴露和结局相关的基线（暴露前）变量。
2.  **估计倾向性评分**：通常使用逻辑[回归模型](@entry_id:163386)，以暴露 $X$ 为因变量，协变量集 $Z$ 为自变量，为每个个体估计其倾向性评分 $\hat{e}(Z)$。
3.  **检查重叠性（共同支撑域）**：评估暴露组和未暴露组的倾向性评分分布是否存在充分的重叠。对于评分落在非重叠区域的个体，应从分析中剔除，以避免模型外推。
4.  **应用倾向性评分**：通过**匹配 (matching)**、**分层 (stratification)** 或**逆概率加权 (inverse probability weighting, IPW)** 等方法，利用倾向性评分来平衡两组的协变量分布。例如，在1:1匹配中，为每个暴露者从非暴露者中寻找一个倾向性评分最接近的个体作为其对照 。
5.  **评估平衡性**：这是**至关重要**的一步。在使用倾向性评分后，必须检查原始协变量 $Z$ 在新形成的暴露组和[对照组](@entry_id:188599)中是否达到了平衡。常用的诊断指标是标准化均数差 (standardized mean difference)。如果平衡性不佳，则需要重新设定倾向性评分模型（例如，加入交互项或高阶项），并重复整个过程。

#### 处理时依性暴露

当暴露状态随时间变化时，对时间的恰当处理是避免偏倚的关键。如前所述，不朽时间偏倚是一个主要威胁。有两种标准方法可以正确处理这种情况：

1.  **风险集抽样 (Risk-Set Sampling)**：这种方法也称为“克隆/匹配/重置时间零点”法。其核心思想是，对于每个在时间 $T^*$ 开始暴露的个体 $i$，我们将 $T^*$ 定义为一个新的“时间零点”。然后，我们从在 $T^*$ 时刻仍然存活且未暴露的个体集合中（即风险集），为个体 $i$ 抽样一个或多个对照者。暴露者 $i$ 和其匹配的对照者都从这个对齐的时间点 $T^*$ 开始他们的分析性随访。这种方法通过在暴露者“不朽时间”结束后才开始分析，并为其匹配同样“存活”了这么久的对照者，从而确保了比较的公平性 。

2.  **时依性协变量建模 (Time-Varying Covariate Models)**：这是另一种在生存分析（如Cox比例风险模型）中常用的方法。它将暴露状态 $X_i(t)$ 视为一个随时间变化的协变量。对于一个个体，在他/她开始暴露之前的时间段 $(t  T^*)$，其人时被归因于未暴露组 $(X(t)=0)$；在开始暴露之后的时间段 $(t \ge T^*)$，其人时被归因于暴露组 $(X(t)=1)$。模型在每个时间点 $t$ 比较当前暴露者和当前非暴露者的瞬时风险，从而正确地将人时归因于其当时的实际暴露状态，从根本上消除了不朽时间偏倚 。

总之，选择一个合适的比较组是流行病学因果推断研究设计的核心，而非统计分析的次要步骤。所有设计和分析策略的最终目标，都是为了让[观察性研究](@entry_id:174507)尽可能地逼近随机试验所能达到的“可交换”状态。比较组的选择直接决定了研究结论的有效性和可信度，需要研究者基于对研究问题、数据结构和潜在偏倚来源的深刻理解，做出审慎而明智的决策。