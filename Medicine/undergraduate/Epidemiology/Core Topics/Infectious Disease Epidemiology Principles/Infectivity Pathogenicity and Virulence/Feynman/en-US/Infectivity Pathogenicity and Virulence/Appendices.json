{
    "hands_on_practices": [
        {
            "introduction": "While average measures of infectivity like the basic reproduction number ($R$) are useful, they often mask significant underlying variation. In reality, a small number of individuals may be responsible for a large proportion of transmission, a phenomenon known as superspreading. This practice  explores how to model this heterogeneity using a Poisson-Gamma mixture, revealing how the variability in individual infectiousness—not just the average—critically shapes outbreak potential.",
            "id": "4602129",
            "problem": "In a discrete-time Galton–Watson branching process, suppose each infectious individual independently generates a random number $X$ of secondary infections in the next generation. Heterogeneity in infectivity is modeled by introducing a latent individual transmission rate $\\Lambda$, where conditional on $\\Lambda$ one has $X \\mid \\Lambda \\sim \\text{Poisson}(\\Lambda)$, and across individuals $\\Lambda$ is independent and identically distributed. Assume the following fundamental base:\n- Conditional Poisson mechanism: $P(X=x \\mid \\Lambda=\\lambda) = e^{-\\lambda} \\lambda^{x} / x!$ for $x \\in \\{0,1,2,\\dots\\}$.\n- Gamma heterogeneity mechanism: $\\Lambda \\sim \\text{Gamma}(\\text{shape}=k, \\text{scale}=\\theta)$ with density $f_{\\Lambda}(\\lambda) = \\lambda^{k-1} e^{-\\lambda/\\theta} / (\\Gamma(k)\\,\\theta^{k})$ for $\\lambda>0$.\n- Mean infectivity constraint: choose the scale $\\theta$ such that $\\mathbb{E}[\\Lambda] = R$, where $R>0$ is the mean number of secondary infections per infectious individual.\n\nUsing these bases only, deduce the induced offspring distribution for $X$ in terms of $R$ and $k$, and reason about how changing $k$ affects outbreak variability when $R$ is held fixed. Then select the single option that correctly gives the probability mass function for $X$ (including its domain), correctly states its mean and variance, and correctly explains qualitatively how decreasing $k$ affects outbreak variability without altering the average infectivity.\n\nA. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{k}{k+R}\\right)^{k} \\left(\\dfrac{R}{k+R}\\right)^{x}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R+R^{2}/k$. Decreasing $k$ (at fixed $R$) increases the variance of $X$, creating more zero-inflation and a heavier right tail (superspreading), which makes outbreaks more variable: both early extinction is more likely when $R \\lesssim 1$ and, conditional on survival, large outbreak sizes become more probable, while the average infectivity remains $\\mathbb{E}[X]=R$.\n\nB. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} (1-R)^{k} R^{x}$ for $x \\in \\{0,1,2,\\dots\\}$ with $0<R<1$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R(1-R)$. Decreasing $k$ reduces variability because more mass concentrates near the mean when $k$ is small.\n\nC. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{R}{R+k}\\right)^{k} \\left(\\dfrac{k}{R+k}\\right)^{x}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=k$ and $\\mathrm{Var}(X)=k(1+k/R)$. Decreasing $k$ lowers the average infectivity and therefore lowers outbreak variability.\n\nD. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{R}{1+R}\\right)^{x} \\left(\\dfrac{1}{1+R}\\right)^{k}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R$. Decreasing $k$ does not change variability because the Poisson component dominates.",
            "solution": "The problem asks for the derivation of the offspring distribution $X$ in a Galton-Watson process where infectivity is heterogeneous. The setup is a Poisson-Gamma mixture model. We must find the probability mass function (PMF) of $X$, its mean and variance, and analyze the effect of the heterogeneity parameter $k$.\n\nFirst, we validate the problem statement. The problem provides a clear hierarchical model:\n1.  $X \\mid \\Lambda \\sim \\text{Poisson}(\\Lambda)$, with PMF $P(X=x \\mid \\Lambda=\\lambda) = e^{-\\lambda} \\lambda^{x} / x!$ for $x \\in \\{0, 1, 2, \\ldots\\}$.\n2.  $\\Lambda \\sim \\text{Gamma}(k, \\theta)$, with PDF $f_{\\Lambda}(\\lambda) = \\lambda^{k-1} e^{-\\lambda/\\theta} / (\\Gamma(k)\\,\\theta^{k})$ for $\\lambda>0$.\n3.  A constraint $\\mathbb{E}[\\Lambda] = R$, which connects the model parameters to the basic reproduction number $R$.\n\nFor a Gamma distribution with shape $k$ and scale $\\theta$, the mean is $\\mathbb{E}[\\Lambda] = k\\theta$. The constraint $\\mathbb{E}[\\Lambda] = R$ implies $k\\theta = R$, so the scale parameter is $\\theta = R/k$. This is a well-defined relationship for $R>0$ and $k>0$. The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution. The problem statement is valid.\n\nWe proceed to derive the marginal distribution of $X$. The PMF of $X$, $P(X=x)$, is obtained by integrating the conditional PMF of $X$ given $\\Lambda$ over the distribution of $\\Lambda$. This is an application of the law of total probability for continuous random variables:\n$$P(X=x) = \\int_{0}^{\\infty} P(X=x \\mid \\Lambda=\\lambda) f_{\\Lambda}(\\lambda) \\, d\\lambda$$\nSubstituting the given PMF for the Poisson distribution and the PDF for the Gamma distribution:\n$$P(X=x) = \\int_{0}^{\\infty} \\left( \\frac{e^{-\\lambda} \\lambda^x}{x!} \\right) \\left( \\frac{\\lambda^{k-1} e^{-\\lambda/\\theta}}{\\Gamma(k) \\theta^k} \\right) d\\lambda$$\nWe can collect terms that do not depend on $\\lambda$ outside the integral:\n$$P(X=x) = \\frac{1}{x! \\Gamma(k) \\theta^k} \\int_{0}^{\\infty} \\lambda^{x+k-1} e^{-\\lambda(1 + 1/\\theta)} d\\lambda$$\nThe integral is a standard form related to the Gamma function. A general Gamma integral is $\\int_{0}^{\\infty} t^{a-1} e^{-ct} dt = \\Gamma(a)/c^a$. In our case, the exponent of $\\lambda$ is $(x+k)-1$, so $a = x+k$. The coefficient in the exponential is $c = 1 + 1/\\theta = (1+\\theta)/\\theta$.\nThe integral thus evaluates to:\n$$\\int_{0}^{\\infty} \\lambda^{(x+k)-1} e^{-\\lambda \\left(\\frac{1+\\theta}{\\theta}\\right)} d\\lambda = \\frac{\\Gamma(x+k)}{\\left(\\frac{1+\\theta}{\\theta}\\right)^{x+k}} = \\Gamma(x+k) \\left(\\frac{\\theta}{1+\\theta}\\right)^{x+k}$$\nSubstituting this result back into the expression for $P(X=x)$:\n$$P(X=x) = \\frac{1}{x! \\Gamma(k) \\theta^k} \\Gamma(x+k) \\left(\\frac{\\theta}{1+\\theta}\\right)^{x+k}$$\nRearranging the terms gives:\n$$P(X=x) = \\frac{\\Gamma(x+k)}{\\Gamma(k) x!} \\frac{1}{\\theta^k} \\frac{\\theta^{x+k}}{(1+\\theta)^{x+k}} = \\frac{\\Gamma(x+k)}{\\Gamma(k) x!} \\frac{\\theta^x}{(1+\\theta)^{x+k}}$$\nWe can rewrite this as:\n$$P(X=x) = \\frac{\\Gamma(x+k)}{\\Gamma(k) x!} \\left(\\frac{1}{1+\\theta}\\right)^k \\left(\\frac{\\theta}{1+\\theta}\\right)^x$$\nThis is the PMF of a Negative Binomial distribution. Now we substitute $\\theta = R/k$ to express the PMF in terms of $R$ and $k$:\nThe probability parameter $p$ is $\\frac{1}{1+\\theta} = \\frac{1}{1+R/k} = \\frac{k}{k+R}$.\nThe other probability parameter $1-p$ is $\\frac{\\theta}{1+\\theta} = \\frac{R/k}{1+R/k} = \\frac{R}{k+R}$.\nSubstituting these into the PMF:\n$$P(X=x) = \\frac{\\Gamma(x+k)}{\\Gamma(k) x!} \\left(\\frac{k}{k+R}\\right)^k \\left(\\frac{R}{k+R}\\right)^x \\quad \\text{for } x \\in \\{0, 1, 2, \\ldots\\}$$\n\nNext, we calculate the mean and variance of $X$ using the laws of total expectation and total variance.\nThe mean of $X$ is:\n$$\\mathbb{E}[X] = \\mathbb{E}[\\mathbb{E}[X \\mid \\Lambda]]$$\nSince $X \\mid \\Lambda \\sim \\text{Poisson}(\\Lambda)$, its conditional mean is $\\mathbb{E}[X \\mid \\Lambda] = \\Lambda$.\nThus, $\\mathbb{E}[X] = \\mathbb{E}[\\Lambda]$. By the problem's constraint, $\\mathbb{E}[\\Lambda] = R$. Therefore, $\\mathbb{E}[X] = R$.\n\nThe variance of $X$ is:\n$$\\mathrm{Var}(X) = \\mathbb{E}[\\mathrm{Var}(X \\mid \\Lambda)] + \\mathrm{Var}(\\mathbb{E}[X \\mid \\Lambda])$$\nFor a Poisson distribution, the variance is equal to the mean, so $\\mathrm{Var}(X \\mid \\Lambda) = \\Lambda$. The first term is $\\mathbb{E}[\\Lambda] = R$.\nThe second term is $\\mathrm{Var}(\\mathbb{E}[X \\mid \\Lambda]) = \\mathrm{Var}(\\Lambda)$. For a Gamma distribution with shape $k$ and scale $\\theta$, the variance is $\\mathrm{Var}(\\Lambda) = k\\theta^2$. Substituting $\\theta = R/k$:\n$$\\mathrm{Var}(\\Lambda) = k \\left(\\frac{R}{k}\\right)^2 = k \\frac{R^2}{k^2} = \\frac{R^2}{k}$$\nCombining the two terms, the variance of $X$ is:\n$$\\mathrm{Var}(X) = R + \\frac{R^2}{k}$$\nThis expression shows that the variance of the offspring distribution is greater than its mean ($R$) by a term $R^2/k$, which is known as overdispersion.\n\nFinally, we analyze the effect of decreasing $k$ while keeping $R$ fixed. The parameter $k$ is the dispersion parameter.\nThe variance is $\\mathrm{Var}(X) = R + R^2/k$. Since $R > 0$, the term $R^2/k$ is always positive. As $k$ decreases, $R^2/k$ increases, and therefore $\\mathrm{Var}(X)$ increases. In the limit $k \\to \\infty$, $\\mathrm{Var}(X) \\to R$, which corresponds to the homogeneous case $X \\sim \\text{Poisson}(R)$. In the limit $k \\to 0^+$, $\\mathrm{Var}(X) \\to \\infty$.\nA larger variance for a fixed mean implies a more skewed distribution with a heavier right tail. This corresponds to the phenomenon of \"superspreading\", where a small fraction of individuals are responsible for a large proportion of secondary infections.\nSimultaneously, to maintain the mean $R$, the increased probability in the tail must be balanced by an increased probability mass at low values, particularly at $X=0$. The probability of zero secondary infections is $P(X=0) = (1+R/k)^{-k}$. As $k \\to 0^+$, $P(X=0) \\to 1$. Thus, decreasing $k$ leads to more \"zero-inflation\".\nThis increased variability has significant epidemiological consequences. The higher probability of zero offspring means that many introductions of a pathogen will fail to establish a chain of transmission, leading to a higher chance of early outbreak extinction. However, if an outbreak does become established (e.g., through a superspreading event), the heavy tail means it has the potential to grow explosively. Therefore, decreasing $k$ increases the variability of outbreak outcomes.\n\nNow we evaluate each option:\n\n**A. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{k}{k+R}\\right)^{k} \\left(\\dfrac{R}{k+R}\\right)^{x}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R+R^{2}/k$. Decreasing $k$ (at fixed $R$) increases the variance of $X$, creating more zero-inflation and a heavier right tail (superspreading), which makes outbreaks more variable: both early extinction is more likely when $R \\lesssim 1$ and, conditional on survival, large outbreak sizes become more probable, while the average infectivity remains $\\mathbb{E}[X]=R$.**\n- PMF: This matches our derived PMF for the Negative Binomial distribution. Correct.\n- Mean and Variance: $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R+R^2/k$. Both match our derivations. Correct.\n- Qualitative Explanation: This explanation accurately describes the effect of decreasing $k$ on the variance, the shape of the distribution (zero-inflation, heavy tail/superspreading), and the epidemiological consequences (increased outbreak variability). Correct.\n- Verdict: **Correct**.\n\n**B. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} (1-R)^{k} R^{x}$ for $x \\in \\{0,1,2,\\dots\\}$ with $0<R<1$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R(1-R)$. Decreasing $k$ reduces variability because more mass concentrates near the mean when $k$ is small.**\n- PMF: The probability parameters are incorrect. It should be $p = k/(k+R)$, not $1-R$. Incorrect.\n- Mean and Variance: For the given PMF, the mean would be $kR/(1-R)$, not $R$. The variance $R(1-R)$ is also incorrect. Incorrect.\n- Qualitative Explanation: The claim that decreasing $k$ reduces variability is the opposite of the correct behavior. Incorrect.\n- Verdict: **Incorrect**.\n\n**C. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{R}{R+k}\\right)^{k} \\left(\\dfrac{k}{R+k}\\right)^{x}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=k$ and $\\mathrm{Var}(X)=k(1+k/R)$. Decreasing $k$ lowers the average infectivity and therefore lowers outbreak variability.**\n- PMF: The probability terms are swapped. The term raised to the power $x$ should be $R/(k+R)$. Incorrect.\n- Mean and Variance: The mean is $\\mathbb{E}[X]=R$, not $k$. The variance expression is also wrong. Incorrect.\n- Qualitative Explanation: It incorrectly claims that decreasing $k$ lowers average infectivity (which is fixed at $R$) and lowers variability (it increases it). Incorrect.\n- Verdict: **Incorrect**.\n\n**D. $P(X=x) = \\dfrac{\\Gamma(x+k)}{\\Gamma(k)\\,x!} \\left(\\dfrac{R}{1+R}\\right)^{x} \\left(\\dfrac{1}{1+R}\\right)^{k}$ for $x \\in \\{0,1,2,\\dots\\}$; $\\mathbb{E}[X]=R$ and $\\mathrm{Var}(X)=R$. Decreasing $k$ does not change variability because the Poisson component dominates.**\n- PMF: This PMF corresponds to the case where $\\theta=R$, which only holds if $k=1$. It is not the general formula. Incorrect.\n- Mean and Variance: The mean for this PMF would be $kR$, which is not $R$ in general. The variance would be $kR(1+R)$, not $R$. Incorrect.\n- Qualitative Explanation: The statement that decreasing $k$ does not change variability is fundamentally wrong, as $k$ is the parameter that controls the level of overdispersion. Incorrect.\n- Verdict: **Incorrect**.\n\nBased on the thorough derivation and analysis, option A is the only one that is correct in all aspects.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "The spread of an infectious disease is not just a biological process; it is deeply intertwined with human behavior. The public's perception of a pathogen's virulence can lead to 'risk compensation,' where lower perceived danger results in behaviors that increase exposure. This exercise  provides a hands-on method to quantify this effect, demonstrating how to calculate the resulting change in the force of infection and overall disease incidence.",
            "id": "4602119",
            "problem": "A campus community considers a newly circulating pathogen to have low virulence (severity), and many individuals respond with risk compensation by increasing their daily close-contact activities. Assume mass-action mixing with homogeneous contacts. Infectivity is defined as the per-contact transmission probability. Let the following parameters be constant over a short observation window: the total population size is $N = 20000$, the number of currently infectious individuals is $I = 200$, the baseline daily contact rate per susceptible individual is $c_{0} = 12$ contacts per day, and the per-contact transmission probability is $p = 0.02$. The observation window has duration $T = 7$ days. Following the perception of low virulence, the daily contact rate increases multiplicatively by a risk compensation factor $r = 1.5$, producing a new contact rate $c_{1} = r c_{0}$.\n\nStarting only from core epidemiological definitions—infectivity as the per-contact transmission probability, mass-action mixing as the assumption that the fraction of contacts with infectious individuals equals the infectious prevalence, and the relationship between a constant hazard (force of infection) and the cumulative incidence over a fixed time window—derive an expression for the baseline cumulative incidence proportion over $T$ days and the post-compensation cumulative incidence proportion over $T$ days. Then compute the ratio of post-compensation to baseline cumulative incidence proportions.\n\nExpress your final answer as a decimal number. Round your answer to four significant figures. Do not use a percentage sign.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, self-contained, and well-posed.\n\n**Step 1: Extract Givens**\n- Total population size: $N = 20000$\n- Number of infectious individuals: $I = 200$\n- Baseline daily contact rate: $c_{0} = 12$\n- Per-contact transmission probability: $p = 0.02$\n- Observation window duration: $T = 7$ days\n- Risk compensation factor: $r = 1.5$\n- New contact rate: $c_{1} = r c_{0}$\n- Assumption: Mass-action mixing.\n- Assumption: Parameters $N$, $I$, $c_0$, $p$, and $r$ are constant over the time window $T$. This implies the force of infection is also constant.\n- Required derivation: A formula for baseline and post-compensation cumulative incidence proportions based on first principles, and their ratio.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, utilizing standard concepts from mathematical epidemiology such as mass-action mixing, force of infection, and the relationship between a constant hazard rate and cumulative incidence. The parameters are specified, and the assumptions (e.g., constant $I$ over a short period) are standard simplifications for such problems. The problem is well-posed, objective, and contains sufficient information for a unique solution.\n\n**Step 3: Verdict and Action**\nThe problem is deemed valid. A full solution will be provided.\n\n**Derivation and Solution**\n\nThe solution proceeds by first defining the force of infection, then relating it to cumulative incidence, and finally calculating the required ratio.\n\nThe force of infection, denoted by $\\lambda$, is the per capita rate at which susceptible individuals acquire the infection. The problem specifies a mass-action mixing assumption. Under this assumption, contacts are made at random within the population. The proportion of all individuals who are infectious is given by the prevalence, $I/N$.\n\nA susceptible individual makes $c$ contacts per day. The proportion of these contacts that are with an infectious individual is $I/N$. Therefore, the number of contacts with infectious individuals per day is $c \\times (I/N)$.\nGiven that each contact with an infectious individual results in transmission with probability $p$ (the infectivity), the rate of infection for a susceptible individual is the product of these factors. This rate is the force of infection, $\\lambda$.\n$$ \\lambda = c \\cdot p \\cdot \\frac{I}{N} $$\nThe units of $\\lambda$ are per unit time (in this case, per day). The problem states that the parameters are constant over the observation window $T$, which implies that $\\lambda$ is a constant hazard rate.\n\nFirst, we calculate the baseline force of infection, $\\lambda_0$, using the baseline contact rate $c_0$.\n$$ \\lambda_0 = c_0 \\cdot p \\cdot \\frac{I}{N} $$\nSubstituting the given values:\n$$ \\lambda_0 = 12 \\, \\text{day}^{-1} \\cdot 0.02 \\cdot \\frac{200}{20000} = 12 \\cdot 0.02 \\cdot 0.01 \\, \\text{day}^{-1} = 0.0024 \\, \\text{day}^{-1} $$\n\nThe cumulative incidence proportion, $CI$, over a time period $T$ for a population exposed to a constant force of infection $\\lambda$ is the probability that a susceptible individual becomes infected during that period. This is given by the relationship $CI = 1 - \\exp(-\\lambda T)$. This formula arises from considering the complementary event: the probability of remaining susceptible (not getting infected) over the interval $[0, T]$ is $\\exp(-\\lambda T)$, which is the survivor function for a constant hazard rate.\n\nThe baseline cumulative incidence proportion over $T=7$ days, $CI_0$, is:\n$$ CI_0 = 1 - \\exp(-\\lambda_0 T) $$\nThe argument of the exponent is:\n$$ \\lambda_0 T = (0.0024 \\, \\text{day}^{-1}) \\cdot (7 \\, \\text{days}) = 0.0168 $$\nSo, the baseline cumulative incidence is:\n$$ CI_0 = 1 - \\exp(-0.0168) $$\n\nNext, we consider the scenario with risk compensation. The daily contact rate increases by a factor of $r = 1.5$. The new contact rate, $c_1$, is:\n$$ c_1 = r \\cdot c_0 = 1.5 \\cdot 12 = 18 \\, \\text{day}^{-1} $$\nThe new force of infection, $\\lambda_1$, is calculated using this new contact rate, with all other parameters remaining the same:\n$$ \\lambda_1 = c_1 \\cdot p \\cdot \\frac{I}{N} = (r \\cdot c_0) \\cdot p \\cdot \\frac{I}{N} = r \\cdot \\lambda_0 $$\n$$ \\lambda_1 = 1.5 \\cdot (0.0024 \\, \\text{day}^{-1}) = 0.0036 \\, \\text{day}^{-1} $$\n\nThe post-compensation cumulative incidence proportion, $CI_1$, over the same period $T=7$ days is:\n$$ CI_1 = 1 - \\exp(-\\lambda_1 T) $$\nThe argument of the exponent is:\n$$ \\lambda_1 T = (0.0036 \\, \\text{day}^{-1}) \\cdot (7 \\, \\text{days}) = 0.0252 $$\nAlso note that $\\lambda_1 T = (r \\lambda_0) T = r (\\lambda_0 T) = 1.5 \\times 0.0168 = 0.0252$.\nSo, the post-compensation cumulative incidence is:\n$$ CI_1 = 1 - \\exp(-0.0252) $$\n\nThe problem asks for the ratio of the post-compensation to baseline cumulative incidence proportions, which we denote as $R_{CI}$.\n$$ R_{CI} = \\frac{CI_1}{CI_0} = \\frac{1 - \\exp(-\\lambda_1 T)}{1 - \\exp(-\\lambda_0 T)} = \\frac{1 - \\exp(-r \\lambda_0 T)}{1 - \\exp(-\\lambda_0 T)} $$\nSubstituting the values for the exponents:\n$$ R_{CI} = \\frac{1 - \\exp(-0.0252)}{1 - \\exp(-0.0168)} $$\nNow we compute the numerical values:\n$$ \\exp(-0.0252) \\approx 0.9751140 $$\n$$ \\exp(-0.0168) \\approx 0.9833430 $$\n$$ R_{CI} \\approx \\frac{1 - 0.9751140}{1 - 0.9833430} = \\frac{0.0248860}{0.0166570} \\approx 1.4939911 $$\n\nRounding the result to four significant figures gives $1.494$.\nThe ratio is close to the risk compensation factor $r=1.5$, which is expected because for small values of $x$, the approximation $1-\\exp(-x) \\approx x$ holds. In this case, $R_{CI} \\approx \\frac{r \\lambda_0 T}{\\lambda_0 T} = r$. The slight difference from $1.5$ is due to the non-linearity of the exponential function.",
            "answer": "$$\\boxed{1.494}$$"
        },
        {
            "introduction": "Accurately measuring a pathogen's pathogenicity and virulence is a cornerstone of public health surveillance, yet our data sources can introduce significant bias. Data collected from hospitals, for example, may not represent the entire infected population, leading to skewed estimates of disease severity. This exercise  will guide you through a classic example of selection bias, allowing you to mathematically demonstrate and quantify how hospital-based sampling can lead to an overestimation of true virulence.",
            "id": "4602164",
            "problem": "In a pathogen surveillance study, hospital-based data are used to estimate virulence. Virulence is defined here as the probability of severe disease among infected individuals, denoted by $P(S=1 \\mid I=1)$. Consider an infectious agent circulating in a population with a comorbidity indicator $C \\in \\{0,1\\}$ among infected individuals. Hospitalization is denoted by $H \\in \\{0,1\\}$. The study enrolls only hospitalized patients with confirmed infection, so severity is observed conditional on $I=1$ and $H=1$.\n\nAssume the following scientifically plausible structure:\n- Among infected individuals, the prevalence of comorbidity is $P(C=1 \\mid I=1) = 0.3$ and $P(C=0 \\mid I=1) = 0.7$.\n- The baseline virulence (probability of severe disease among infected) depends on comorbidity: $P(S=1 \\mid I=1, C=1) = 0.4$ and $P(S=1 \\mid I=1, C=0) = 0.1$.\n- Hospitalization depends on severity and comorbidity: $P(H=1 \\mid I=1, S=1, C=1) = 0.9$, $P(H=1 \\mid I=1, S=1, C=0) = 0.7$, $P(H=1 \\mid I=1, S=0, C=1) = 0.3$, and $P(H=1 \\mid I=1, S=0, C=0) = 0.05$.\n\nUsing only foundational definitions of conditional probability, the law of total probability, and scientifically consistent selection mechanisms, first derive the expression for the true virulence $P(S=1 \\mid I=1)$ and the hospital-based virulence $P(S=1 \\mid I=1, H=1)$. Then, compute the Berkson’s bias factor on virulence, defined as\n$$\nB \\equiv \\frac{P(S=1 \\mid I=1, H=1)}{P(S=1 \\mid I=1)}.\n$$\nInterpretation: values of $B$ greater than $1$ indicate upward bias due to hospital-based selection on $H=1$, and values less than $1$ indicate downward bias.\n\nReport the single numerical value of $B$ and round your answer to four significant figures. No units are required.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in epidemiological principles, internally consistent, well-posed, and contains all necessary information to derive a unique solution. The problem describes a classic case of selection bias, specifically Berkson's bias, which arises when conditioning on a common effect (a \"collider\") of two or more independent or associated causes. Here, hospitalization ($H$) is a collider for disease severity ($S$) and comorbidity ($C$).\n\nThe objective is to compute the Berkson's bias factor, $B$, defined as the ratio of the hospital-based virulence to the true virulence:\n$$\nB \\equiv \\frac{P(S=1 \\mid I=1, H=1)}{P(S=1 \\mid I=1)}\n$$\nAll probabilities provided in the problem are conditional on an individual being infected ($I=1$). To simplify the notation during the derivation, we will temporarily omit the explicit conditioning on $I=1$, with the understanding that every probability is within the sub-population of infected individuals. The expression for the bias factor becomes:\n$$\nB = \\frac{P(S=1 \\mid H=1)}{P(S=1)}\n$$\n\nFirst, we calculate the denominator, which represents the true virulence $P(S=1 \\mid I=1)$, denoted here as $P(S=1)$. We apply the law of total probability, marginalizing over the comorbidity status $C$:\n$$\nP(S=1) = P(S=1, C=1) + P(S=1, C=0)\n$$\nUsing the definition of conditional probability, $P(A,B) = P(A \\mid B)P(B)$, we have:\n$$\nP(S=1) = P(S=1 \\mid C=1)P(C=1) + P(S=1 \\mid C=0)P(C=0)\n$$\nSubstituting the given values:\n$$\nP(S=1) = (0.4)(0.3) + (0.1)(0.7) = 0.12 + 0.07 = 0.19\n$$\nThus, the true virulence in the infected population is $0.19$.\n\nNext, we calculate the numerator, which is the hospital-based virulence $P(S=1 \\mid H=1)$. Using Bayes' theorem:\n$$\nP(S=1 \\mid H=1) = \\frac{P(S=1, H=1)}{P(H=1)}\n$$\nWe must compute the joint probability $P(S=1, H=1)$ and the marginal probability $P(H=1)$.\n\nTo find the joint probability $P(S=1, H=1)$, we again apply the law of total probability, marginalizing over the comorbidity status $C$:\n$$\nP(S=1, H=1) = P(S=1, H=1, C=1) + P(S=1, H=1, C=0)\n$$\nUsing the chain rule for probability, $P(A, B, C) = P(A \\mid B, C)P(B \\mid C)P(C)$:\n$$\nP(S=1, H=1) = P(H=1 \\mid S=1, C=1)P(S=1 \\mid C=1)P(C=1) + P(H=1 \\mid S=1, C=0)P(S=1 \\mid C=0)P(C=0)\n$$\nSubstituting the given values:\n$$\nP(S=1, H=1) = (0.9)(0.4)(0.3) + (0.7)(0.1)(0.7) = 0.108 + 0.049 = 0.157\n$$\n\nTo find the marginal probability of hospitalization $P(H=1)$, we marginalize over all possible states of severity $S$ and comorbidity $C$:\n$$\nP(H=1) = \\sum_{s \\in \\{0,1\\}} \\sum_{c \\in \\{0,1\\}} P(H=1, S=s, C=c)\n$$\nAgain, using the chain rule:\n$$\nP(H=1) = \\sum_{s \\in \\{0,1\\}} \\sum_{c \\in \\{0,1\\}} P(H=1 \\mid S=s, C=c)P(S=s \\mid C=c)P(C=c)\n$$\nWe can organize this sum into four terms:\nTerm 1 ($S=1, C=1$): $P(H=1 \\mid S=1, C=1)P(S=1 \\mid C=1)P(C=1) = (0.9)(0.4)(0.3) = 0.108$\nTerm 2 ($S=1, C=0$): $P(H=1 \\mid S=1, C=0)P(S=1 \\mid C=0)P(C=0) = (0.7)(0.1)(0.7) = 0.049$\nTerm 3 ($S=0, C=1$): $P(H=1 \\mid S=0, C=1)P(S=0 \\mid C=1)P(C=1) = (0.3)(1-0.4)(0.3) = (0.3)(0.6)(0.3) = 0.054$\nTerm 4 ($S=0, C=0$): $P(H=1 \\mid S=0, C=0)P(S=0 \\mid C=0)P(C=0) = (0.05)(1-0.1)(0.7) = (0.05)(0.9)(0.7) = 0.0315$\nSumming these terms gives the total probability of hospitalization for an infected individual:\n$$\nP(H=1) = 0.108 + 0.049 + 0.054 + 0.0315 = 0.2425\n$$\nNow we can compute the hospital-based virulence:\n$$\nP(S=1 \\mid H=1) = \\frac{P(S=1, H=1)}{P(H=1)} = \\frac{0.157}{0.2425}\n$$\nFinally, we compute the bias factor $B$:\n$$\nB = \\frac{P(S=1 \\mid H=1)}{P(S=1)} = \\frac{0.157 / 0.2425}{0.19} = \\frac{0.157}{0.2425 \\times 0.19} = \\frac{0.157}{0.046075}\n$$\nPerforming the division:\n$$\nB \\approx 3.4074883342...\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nB \\approx 3.407\n$$\nThis value, being substantially greater than $1$, indicates a significant upward bias in the virulence estimate when it is based solely on hospitalized patients. This is expected, as individuals with severe disease are more likely to be hospitalized, leading to their overrepresentation in the study sample.",
            "answer": "$$\\boxed{3.407}$$"
        }
    ]
}