{
    "hands_on_practices": [
        {
            "introduction": "在分解一个时间序列之前，一个基础性的决定是选择其基本结构是加性的还是乘性的。这个选择至关重要，因为它直接影响我们如何解释趋势和季节性成分，以及是否需要对数据进行变换，例如对数变换。本练习将指导您通过一个量化诊断方法，通过考察季节性均值与方差之间的关系，来做出这一关键的建模决策。",
            "id": "4642189",
            "problem": "您的任务是在流行病学时间序列的背景下，通过使用对数变换作为诊断工具，对加性与乘性“使用Loess的季节性-趋势分解法（STL）”进行操作性比较。考虑一个代表新发病例的非负计数单变量月度时间序列，按时间 $t = 1, 2, \\dots, N$ 索引，其季节性周期为 $m$ 个月，共有 $K$ 个完整年份，因此 $N = mK$。两个典型模型是加性季节-趋势-噪声模型 $Y_t = T_t + S_t + R_t$ 和乘性季节-趋势-噪声模型 $Y_t = T_t \\times S_t \\times R_t$，其中 $T_t$ 是趋势分量，$S_t$ 是周期为 $m$ 的季节性因子（即 $S_{t+m} = S_t$），而 $R_t$ 是残差项，在乘性模型中其均值为 $1$，在加性模型中其均值为 $0$。一个广泛使用的结论是，在具有随均值增加的异方差性（这在计数数据中很常见）的乘性结构下，对于一个小的偏移量 $\\varepsilon > 0$ 以处理零值，对数变换 $Y'_t = \\log(Y_t + \\varepsilon)$ 能将乘性模型转换为加性模型，$Y'_t \\approx \\log T_t + \\log S_t + \\log R_t$，并且当 $\\operatorname{Var}(Y_t \\mid \\text{season})$ 与季节性均值的平方成比例增长时，该变换能近似地稳定方差。将使用以下原理：如果 $\\operatorname{Var}(Y \\mid \\text{season } j) \\propto \\mu_j^2$，其中 $\\mu_j = \\mathbb{E}[Y \\mid \\text{season } j]$，那么根据delta方法，对于较小的变异系数，$\\operatorname{Var}(\\log Y \\mid \\text{season } j) \\approx \\operatorname{Var}(Y \\mid \\text{season } j)/\\mu_j^2 \\approx \\text{constant}$ 对所有 $j$ 成立。\n\n您的程序必须实现以下决策规则，仅使用季节内均值-标准差关系来选择加性或乘性STL：\n\n1. 给定 $m$、$K$ 和数据 $\\{Y_t\\}_{t=1}^N$（其中 $N=mK$），定义季节索引 $j \\in \\{1, 2, \\dots, m\\}$ 和年份索引 $k \\in \\{1, 2, \\dots, K\\}$，使得 $Y_{j,k}$ 表示第 $k$ 年第 $j$ 个月的观测值。对于每个季节 $j$，计算 $\\{Y_{j,k}\\}_{k=1}^K$ 的样本均值 $\\hat{\\mu}_j$ 和样本标准差 $\\hat{s}_j$。使用常规样本相关性公式计算向量 $(\\hat{\\mu}_1, \\dots, \\hat{\\mu}_m)$ 和 $(\\hat{s}_1, \\dots, \\hat{s}_m)$ 之间的皮尔逊相关系数 $r_{\\text{raw}}$\n$$\nr(x,y) = \\frac{\\sum_{i=1}^m (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^m (x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^m (y_i - \\bar{y})^2}}.\n$$\n\n2. 定义 $Y'_t = \\log(Y_t + \\varepsilon)$，其中 $\\varepsilon = 0.5$。重复上述步骤，从对数变换后的数据中获得 $\\hat{\\mu}'_j$、$\\hat{s}'_j$ 和 $r_{\\log}$。\n\n3. 当且仅当 $r_{\\text{raw}} - r_{\\log} \\ge \\tau$ 且 $r_{\\text{raw}} \\ge \\rho_{\\min}$ 时，决定使用乘性STL（即在对数尺度上应用STL），其中阈值 $\\tau = 0.3$ 且 $\\rho_{\\min} = 0.3$。否则，决定使用加性STL（即在原始尺度上应用STL）。\n\n为使任务在没有外部数据的情况下完全可测试，请使用以下参数化族，在科学上合理的数据生成机制下生成合成流行病学时间序列。对于 $t = 1, 2, \\dots, N$（其中 $N = mK$），令 $j = 1 + \\big((t-1) \\bmod m\\big)$ 表示年内季节（月份）。按如下方式定义趋势和季节因子：\n\n- 加性趋势: $T^{\\text{add}}_t = b + \\alpha (t-1)$，其中 $b > 0$，斜率 $\\alpha \\ge 0$。\n- 乘性（指数）趋势: $T^{\\text{mult}}_t = b \\times \\exp\\big(\\gamma (t-1)/N\\big)$，其中 $b > 0$，增长参数 $\\gamma \\ge 0$。\n- 加性季节: $S^{\\text{add}}_j = A \\sin\\left(2\\pi j/m\\right)$，其中振幅 $A \\ge 0$。\n- 乘性季节（正值）: $S^{\\text{mult}}_j = 1 + A \\sin\\left(2\\pi j/m\\right)$，其中振幅 $A \\in [0,1)$ 以保持 $S^{\\text{mult}}_j > 0$。\n\n噪声机制：\n\n- 加性高斯噪声：$E^{\\text{add}}_t \\sim \\mathcal{N}(0, \\sigma^2)$，在时间 $t$ 上独立。\n- 乘性对数正态噪声：$E^{\\text{mult}}_t \\sim \\operatorname{LogNormal}(0, \\sigma_{\\log}^2)$，在时间 $t$ 上独立。\n- 泊松抽样噪声：$Y_t \\sim \\operatorname{Poisson}(\\lambda_t)$，均值为 $\\lambda_t$。\n\n根据以下模型之一构造观测值 $Y_t$：\n- 加性模型：$Y_t = T^{\\text{add}}_t + S^{\\text{add}}_j + E^{\\text{add}}_t$，通过参数构造约束为非负。\n- 带对数正态噪声的乘性模型：$Y_t = T^{\\text{mult}}_t \\times S^{\\text{mult}}_j \\times E^{\\text{mult}}_t$。\n- 泊松计数：$Y_t \\sim \\operatorname{Poisson}\\left(T^{\\text{mult}}_t \\times S^{\\text{mult}}_j\\right)$。\n\n使用固定的随机种子实现确定性生成，然后应用决策规则。您的程序必须解决以下参数值测试套件，每个测试用例都指定为一个元组并用文字描述。对于每个案例，生成一个布尔值，指示是选择乘性STL（对数尺度）（true）还是选择加性STL（原始尺度）（false）：\n\n- 案例1（乘性模型的理想路径）：$(m, K, b, \\gamma, A, \\sigma_{\\log}, \\text{noise}, \\text{seed}) = (12, 8, 20.0, 0.5, 0.5, 0.25, \\text{multiplicative\\_lognormal}, 123)$。使用 $T^{\\text{mult}}_t$、$S^{\\text{mult}}_j$ 和对数正态噪声。\n- 案例2（加性模型的理想路径）：$(m, K, b, \\alpha, A, \\sigma, \\text{noise}, \\text{seed}) = (12, 8, 20.0, 0.2, 5.0, 3.0, \\text{additive\\_gaussian}, 456)$。使用 $T^{\\text{add}}_t$、$S^{\\text{add}}_j$ 和加性高斯噪声。\n- 案例3（边界情况，接近常数）：$(m, K, b, \\alpha, A, \\sigma, \\text{noise}, \\text{seed}) = (12, 6, 15.0, 0.0, 0.0, 0.1, \\text{additive\\_gaussian}, 789)$。使用 $T^{\\text{add}}_t$、$S^{\\text{add}}_j$ 和加性高斯噪声，产生近似恒定的序列。\n- 案例4（通过泊松分布产生零值的边缘情况）：$(m, K, b, \\gamma, A, \\text{noise}, \\text{seed}) = (12, 10, 1.2, 0.3, 0.8, \\text{poisson}, 321)$。使用 $T^{\\text{mult}}_t$、$S^{\\text{mult}}_j$ 和泊松抽样。\n\n角度单位不适用。由于输出是布尔值选项，因此无需报告物理单位。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[true,false,true,true]”，但使用Python布尔值的大小写），按案例1到4的顺序排列结果。",
            "solution": "问题陈述已经过严格验证，并被认为是有效的。它在科学上基于时间序列分析的原理，特别是关于在加性与乘性分解模型之间进行选择。该问题是适定的、客观的，并为确定性计算任务提供了完整、自洽的规范。所有参数、模型和决策标准都以足够的精度定义，以确保唯一解。合成数据生成过程基于流行病学及相关领域使用的标准、合理的模型。\n\n问题的核心是实现一个诊断检验，以判断一个流行病学时间序列是由加性模型 $Y_t = T_t + S_t + R_t$ 还是由乘性模型 $Y_t = T_t \\times S_t \\times R_t$ 更好地描述。这里，$Y_t$ 是时间 $t$ 的观测数据，$T_t$ 是趋势，$S_t$ 是季节分量，$R_t$ 是残差或噪声项。这一选择是根本性的，因为它决定了合适的分解方法，例如在原始数据上使用“使用Loess的季节性-趋势分解法（STL）”（加性）或在对数变换后的数据上使用（乘性）。\n\n指导原则基于序列均值与方差之间的关系。许多生成计数数据的过程，例如由泊松分布或对数正态分布建模的过程，都表现出异方差性，即观测值的方差随均值水平的增加而增加。在乘性模型中，季节和噪声分量作为趋势的缩放因子，特定季节内数据的标准差往往与该季节的均值水平成正比。也就是说，如果 $\\mu_j$ 是季节 $j$ 的期望值，那么 $\\operatorname{StdDev}(Y \\mid \\text{season } j) \\propto \\mu_j$。这意味着 $\\operatorname{Var}(Y \\mid \\text{season } j) \\propto \\mu_j^2$。相比之下，一个带有同方差噪声（$R_t$ 具有恒定方差）的简单加性模型，在季节均值和季节标准差之间不会显示出系统性关系。\n\n对数变换 $Y'_t = \\log(Y_t + \\varepsilon)$（对于一个小的偏移量 $\\varepsilon > 0$）通常用于稳定乘性模型中的方差。根据delta方法，如果 $\\operatorname{Var}(Y) \\propto (\\mathbb{E}[Y])^2$，那么 $\\operatorname{Var}(\\log Y)$ 将近似为常数。此变换将乘性结构转换为加性结构：$\\log(T_t \\times S_t \\times R_t) = \\log T_t + \\log S_t + \\log R_t$。\n\n指定的决策规则将此原理操作化。它使用季节均值和季节标准差之间的皮尔逊相关系数作为均值-方差关系强度的度量标准。算法如下：\n\n1.  对于给定的时间序列 $\\{Y_t\\}_{t=1}^N$（季节周期为 $m$，有 $K$ 个年份），数据按季节分组。对每个季节 $j \\in \\{1, 2, \\dots, m\\}$，计算 $K$ 个年份的样本均值 $\\hat{\\mu}_j$ 和样本标准差 $\\hat{s}_j$。\n2.  计算配对集合 $\\{(\\hat{\\mu}_j, \\hat{s}_j)\\}_{j=1}^m$ 的皮尔逊相关系数，记为 $r_{\\text{raw}}$。强正相关表明存在乘性结构。\n3.  使用 $Y'_t = \\log(Y_t + \\varepsilon)$（其中 $\\varepsilon = 0.5$）对数据进行变换。重复此过程，计算新的季节均值 $\\hat{\\mu}'_j$ 和标准差 $\\hat{s}'_j$，以及它们的相关性 $r_{\\log}$。\n4.  如果对数变换成功地稳定了方差，$r_{\\log}$ 应远小于 $r_{\\text{raw}}$。如果满足两个条件，则选择乘性模型：\n    a. 原始尺度上的相关性足够高，表明初始均值-方差关系很强：$r_{\\text{raw}} \\ge \\rho_{\\min}$，其中 $\\rho_{\\min} = 0.3$。\n    b. 对数变换显著降低了此相关性，表明方差稳定化成功：$r_{\\text{raw}} - r_{\\log} \\ge \\tau$，其中 $\\tau = 0.3$。\n    如果两个条件都成立，则选择乘性模型。否则，默认选择加性模型。\n\n实现将首先根据四个指定的测试用例生成合成时间序列。每个用例使用不同的趋势、季节和噪声模型组合来模拟合理的场景。对于每个生成的序列，执行诊断程序以获得布尔决策。\n\n函数 `calculate_correlation` 将接受时间序列数据、$m$ 和 $K$ 作为输入。它会将 $N$ 个点的时间序列重塑为一个 $K \\times m$ 的矩阵，其中行代表年份，列代表季节。然后，它将为每列（季节）计算均值和样本标准差（使用自由度差为 $1$）。最后，它将使用 `numpy.corrcoef` 计算得出的均值向量和标准差向量之间的皮尔逊相关性，并返回该值。\n\n主函数将为每个测试用例协调此过程，应用决策规则，使用给定的阈值参数 $\\tau = 0.3$ 和 $\\rho_{\\min} = 0.3$ 以及对数变换偏移量 $\\varepsilon = 0.5$。结果将被收集并按指定格式化。为保证可复现性，随机种子是固定的。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_correlation(data: np.ndarray, m: int, K: int) -> float:\n    \"\"\"\n    Calculates the Pearson correlation between seasonal means and standard deviations.\n\n    Args:\n        data: A 1D numpy array representing the time series.\n        m: The seasonal period.\n        K: The number of complete years.\n\n    Returns:\n        The Pearson correlation coefficient.\n    \"\"\"\n    if data.ndim != 1 or len(data) != m * K:\n        raise ValueError(\"Data must be a 1D array of length m*K.\")\n\n    # Reshape data into a (K, m) matrix [years x seasons]\n    series_matrix = data.reshape(K, m)\n\n    # Calculate mean and standard deviation for each season (column)\n    # ddof=1 for sample standard deviation\n    seasonal_means = np.mean(series_matrix, axis=0)\n    seasonal_stds = np.std(series_matrix, axis=0, ddof=1)\n    \n    # If all standard deviations are zero, correlation is undefined (NaN).\n    # This can happen if the series is constant within each season.\n    # np.corrcoef handles this by returning NaN.\n    if np.all(seasonal_stds == 0):\n        return 0.0 # Define as 0 to avoid NaN propagation issues in comparisons\n\n    # Calculate Pearson correlation coefficient\n    # np.corrcoef returns a 2x2 matrix, we need the off-diagonal element\n    # It returns nan if one of the inputs is constant, which is desired.\n    corr_matrix = np.corrcoef(seasonal_means, seasonal_stds)\n    \n    correlation = corr_matrix[0, 1]\n    \n    # If correlation is NaN (due to constant stds or means), treat it as 0.\n    if np.isnan(correlation):\n        return 0.0\n        \n    return correlation\n\ndef apply_decision_rule(Y: np.ndarray, m: int, K: int, epsilon: float, tau: float, rho_min: float) -> bool:\n    \"\"\"\n    Applies the decision rule to choose between additive and multiplicative models.\n\n    Args:\n        Y: The time series data.\n        m: The seasonal period.\n        K: The number of years.\n        epsilon: Offset for log transform.\n        tau: Threshold for correlation reduction.\n        rho_min: Threshold for raw correlation.\n\n    Returns:\n        True if multiplicative is chosen, False otherwise.\n    \"\"\"\n    # 1. Compute correlation for raw data\n    r_raw = calculate_correlation(Y, m, K)\n\n    # 2. Compute correlation for log-transformed data\n    Y_prime = np.log(Y + epsilon)\n    r_log = calculate_correlation(Y_prime, m, K)\n\n    # 3. Apply the decision rule\n    is_multiplicative = (r_raw - r_log >= tau) and (r_raw >= rho_min)\n    return is_multiplicative\n\ndef generate_series(params: dict):\n    \"\"\"\n    Generates a synthetic time series based on the provided parameters.\n    \"\"\"\n    np.random.seed(params['seed'])\n    \n    m = params['m']\n    K = params['K']\n    N = m * K\n    t_idx = np.arange(N)\n    j_idx = t_idx % m\n    \n    model_type = params['model']\n    \n    if model_type == 'additive_gaussian':\n        b = params['b']\n        alpha = params['alpha']\n        A = params['A']\n        sigma = params['sigma']\n        \n        trend = b + alpha * t_idx\n        seasonality = A * np.sin(2 * np.pi * (j_idx + 1) / m)\n        noise = np.random.normal(0, sigma, N)\n        \n        Y = trend + seasonality + noise\n        # As per problem, data represent non-negative counts.\n        # Although parameters are chosen to make negative values unlikely,\n        # we enforce this for robustness.\n        Y = np.maximum(0, Y)\n\n    elif model_type == 'multiplicative_lognormal':\n        b = params['b']\n        gamma = params['gamma']\n        A = params['A']\n        sigma_log = params['sigma_log']\n\n        trend = b * np.exp(gamma * t_idx / N)\n        seasonality = 1 + A * np.sin(2 * np.pi * (j_idx + 1) / m)\n        noise = np.random.lognormal(0, sigma_log, N)\n        \n        Y = trend * seasonality * noise\n\n    elif model_type == 'poisson':\n        b = params['b']\n        gamma = params['gamma']\n        A = params['A']\n        \n        trend = b * np.exp(gamma * t_idx / N)\n        seasonality = 1 + A * np.sin(2 * np.pi * (j_idx + 1) / m)\n        \n        lambda_t = trend * seasonality\n        # Ensure lambda is non-negative, although parameters should guarantee this.\n        lambda_t = np.maximum(0, lambda_t)\n        Y = np.random.poisson(lambda_t)\n\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n        \n    return Y, m, K\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Multiplicative model with lognormal noise\n        {'model': 'multiplicative_lognormal', 'm': 12, 'K': 8, 'b': 20.0, 'gamma': 0.5, 'A': 0.5, 'sigma_log': 0.25, 'seed': 123},\n        # Case 2: Additive model with Gaussian noise\n        {'model': 'additive_gaussian', 'm': 12, 'K': 8, 'b': 20.0, 'alpha': 0.2, 'A': 5.0, 'sigma': 3.0, 'seed': 456},\n        # Case 3: Additive model, nearly constant\n        {'model': 'additive_gaussian', 'm': 12, 'K': 6, 'b': 15.0, 'alpha': 0.0, 'A': 0.0, 'sigma': 0.1, 'seed': 789},\n        # Case 4: Multiplicative mean structure with Poisson noise\n        {'model': 'poisson', 'm': 12, 'K': 10, 'b': 1.2, 'gamma': 0.3, 'A': 0.8, 'seed': 321}\n    ]\n\n    # Decision rule parameters\n    epsilon = 0.5\n    tau = 0.3\n    rho_min = 0.3\n\n    results = []\n    for params in test_cases:\n        Y, m, K = generate_series(params)\n        is_multiplicative = apply_decision_rule(Y, m, K, epsilon, tau, rho_min)\n        results.append(is_multiplicative)\n\n    # Format the output as specified: [True,False,...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "长期趋势揭示了疾病发生率的长期变化方向，但人口结构的变化（如人口老龄化）可能会对其造成混淆。为了揭示真实的长期趋势，我们必须控制这些混杂因素的影响。本练习将引导您实践一项基本的流行病学技术——直接年龄标化，通过将不同时期观察到的率调整到一个固定的标准人口结构上，从而对长期趋势进行无偏的比较。",
            "id": "4642214",
            "problem": "一个基于人群的疾病监测项目旨在量化长时间跨度内的发病率长期趋势，同时消除因年龄结构变化所产生的混淆。该项目将对多个数据集采用直接年龄标化法，比较两个十年期间的情况，每个数据集都使用一个固定的标准人口。从流行病学的基本定义和加权平均的基本性质出发，推导一个算法，该算法为每个数据集计算两个十年期间各自的年龄标化发病率以及它们之间的长期变化。\n\n在问题陈述中，请使用以下基础，不要引入任何快捷公式。对于年龄组索引 $i \\in \\{1,\\dots,k\\}$ 和时间索引 $t \\in \\{t_1,t_2\\}$：\n- 特定年龄发病率定义为 $r_{i,t} = c_{i,t}/N_{i,t}$，其中 $c_{i,t}$ 是新发病例数，$N_{i,t}$ 是同一年龄组和十年期间的人时数或风险人口。\n- 一个固定的标准人口通过归一化提供权重：使用一个非负计数向量 $S = (S_1,\\dots,S_k)$ 来构建总和为1的归一化权重 $w_i$。\n- 最终的年龄标化率以每$10^5$人年为单位表示。设乘数 $m = 10^5$。\n\n您的任务是：\n1. 根据这些定义，推导如何计算两个十年期间各自的直接年龄标化发病率，并使用相同的固定标准人口以分离出长期趋势。\n2. 将长期变化定义为两个十年期间年龄标化发病率之间的绝对差。\n3. 实现一个程序，为每个测试用例计算一个三元组，包括两个年龄标化率及其绝对差，所有值均以每$10^5$人年为单位表示，并四舍五入到两位小数。\n\n科学真实性：以下数据集在内部是一致的，并且对于传染病或慢性病监测项目是合理的。由于数据聚合的时间跨度长达数十年，因此不考虑季节性因素；重点在于长期趋势。每个测试用例中的所有年龄组在两个十年期间均使用相同的固定标准人口。\n\n单位：所有率必须以每$10^5$人年报告。\n\n角度单位：不适用。\n\n百分比：不适用。\n\n测试套件和参数规范（每个向量均按五个年龄组 $(G_1,G_2,G_3,G_4,G_5)$ 的顺序列出）：\n- 测试用例1（正常路径；中度老龄化和中度发病率变化）：\n  - 标准人口 $S^{(1)} = (300000, 320000, 200000, 140000, 40000)$。\n  - 十年期 $t_1$：病例数 $C^{(1)}_{t_1} = (180, 450, 720, 980, 500)$，人口数 $N^{(1)}_{t_1} = (200000, 180000, 120000, 70000, 20000)$。\n  - 十年期 $t_2$：病例数 $C^{(1)}_{t_2} = (160, 400, 800, 1100, 600)$，人口数 $N^{(1)}_{t_2} = (180000, 160000, 130000, 90000, 30000)$。\n- 测试用例2（边界情况；年轻年龄组病例为零，年长年龄组变化显著）：\n  - 标准人口 $S^{(2)} = (400000, 300000, 180000, 100000, 20000)$。\n  - 十年期 $t_1$：病例数 $C^{(2)}_{t_1} = (0, 200, 500, 600, 150)$，人口数 $N^{(2)}_{t_1} = (250000, 200000, 100000, 40000, 5000)$。\n  - 十年期 $t_2$：病例数 $C^{(2)}_{t_2} = (0, 210, 600, 700, 350)$，人口数 $N^{(2)}_{t_2} = (240000, 220000, 120000, 60000, 10000)$。\n- 测试用例3（边界；跨十年期间年龄结构发生巨大变化，但特定年龄发病率保持不变）：\n  - 标准人口 $S^{(3)} = (500000, 250000, 150000, 80000, 20000)$。\n  - 十年期 $t_1$：病例数 $C^{(3)}_{t_1} = (50, 100, 400, 1000, 2000)$，人口数 $N^{(3)}_{t_1} = (100000, 100000, 100000, 100000, 100000)$。\n  - 十年期 $t_2$：病例数 $C^{(3)}_{t_2} = (200, 200, 480, 600, 400)$，人口数 $N^{(3)}_{t_2} = (400000, 200000, 120000, 60000, 20000)$。\n- 测试用例4（小人口；检查罕见事件下的数值稳定性和舍入）：\n  - 标准人口 $S^{(4)} = (200000, 300000, 250000, 200000, 50000)$。\n  - 十年期 $t_1$：病例数 $C^{(4)}_{t_1} = (2, 9, 15, 30, 12)$，人口数 $N^{(4)}_{t_1} = (20000, 30000, 25000, 20000, 5000)$。\n  - 十年期 $t_2$：病例数 $C^{(4)}_{t_2} = (3, 12, 20, 45, 25)$，人口数 $N^{(4)}_{t_2} = (20000, 30000, 25000, 20000, 5000)$。\n\n程序输出格式：\n- 对于每个测试用例，按顺序计算三个值：十年期 $t_1$ 的年龄标化发病率、十年期 $t_2$ 的年龄标化发病率，以及绝对长期变化 $|R_{t_2} - R_{t_1}|$，所有值均以每$10^5$人年为单位，并四舍五入到两位小数。\n- 将所有测试用例的结果按照测试用例的顺序聚合到一个扁平列表中：$[R^{(1)}_{t_1}, R^{(1)}_{t_2}, |R^{(1)}_{t_2} - R^{(1)}_{t_1}|, R^{(2)}_{t_1}, R^{(2)}_{t_2}, |R^{(2)}_{t_2} - R^{(2)}_{t_1}|, R^{(3)}_{t_1}, R^{(3)}_{t_2}, |R^{(3)}_{t_2} - R^{(3)}_{t_1}|, R^{(4)}_{t_1}, R^{(4)}_{t_2}, |R^{(4)}_{t_2} - R^{(4)}_{t_1}|]$。\n- 您的程序应生成单行输出，其中包含此列表，形式为方括号内由逗号分隔的序列，例如 $[x_1,x_2,\\dots,x_{12}]$。",
            "solution": "该问题要求推导并实现一个算法，用以计算两个不同时间段（十年）的直接年龄标化发病率及其间的长期变化。在流行病学中，这是一种基础方法，用于在控制不同年龄结构的混淆效应的同时，比较不同时间或人群间的率。推导将从所提供的基本定义开始。\n\n设年龄组索引为 $i \\in \\{1, 2, \\dots, k\\}$，两个十年期的索引为 $t \\in \\{t_1, t_2\\}$。每个测试用例给出的量如下：\n- $C_{t} = (c_{1,t}, c_{2,t}, \\dots, c_{k,t})$：给定十年期 $t$ 的新发病例计数向量。\n- $N_{t} = (N_{1,t}, N_{2,t}, \\dots, N_{k,t})$：相应年龄组和十年期的人时数或风险人口计数向量。\n- $S = (S_1, S_2, \\dots, S_k)$：一个固定的标准人口的人口计数向量。\n- $m = 10^5$：用于将率表示为每 $10^5$ 人年的乘数。\n\n**1. 特定年龄发病率的推导**\n\n在特定亚群中，疾病频率的基础测量指标是特定年龄发病率。根据问题定义，对于年龄组 $i$ 和十年期 $t$，该率（记为 $r_{i,t}$）是新发病例数与总风险人时数的比率。\n$$r_{i,t} = \\frac{c_{i,t}}{N_{i,t}}$$\n对每个年龄组 $i$ 以及两个十年期 $t_1$ 和 $t_2$ 均执行此计算。\n\n**2. 标准化权重的推导**\n\n直接标化的核心是将一个共同的年龄结构应用于被比较的人群。这个共同的结构由标准人口 $S$ 提供。我们必须推导出一组归一化权重 $w_i$，它代表标准人口中每个年龄组 $i$ 的比例。\n\n标准人口的总规模是其各年龄组人数的总和：\n$$S_{total} = \\sum_{j=1}^{k} S_j$$\n年龄组 $i$ 的权重 $w_i$ 是该总人口中属于组 $i$ 的比例：\n$$w_i = \\frac{S_i}{S_{total}} = \\frac{S_i}{\\sum_{j=1}^{k} S_j}$$\n通过这种构造，权重是非负的（因为 $S_i \\ge 0$）并且总和为1，这是加权平均的一个必要属性：\n$$\\sum_{i=1}^{k} w_i = \\sum_{i=1}^{k} \\frac{S_i}{\\sum_{j=1}^{k} S_j} = \\frac{\\sum_{i=1}^{k} S_i}{\\sum_{j=1}^{k} S_j} = 1$$\n\n**3. 年龄标化发病率 (ASR) 的推导**\n\n给定十年期 $t$ 的直接年龄标化发病率（我们记为 $R_t$）是特定年龄发病率 $r_{i,t}$ 的加权平均值。所使用的权重是上面推导出的标准人口权重 $w_i$。如果研究人口具有与标准人口相同的年龄结构，则此过程得出的是在该研究人口中将观察到的总发病率。\n\n原始的标化率 $R_{t, \\text{raw}}$ 计算如下：\n$$R_{t, \\text{raw}} = \\sum_{i=1}^{k} w_i \\cdot r_{i,t}$$\n代入先前推导出的 $w_i$ 和 $r_{i,t}$ 的表达式：\n$$R_{t, \\text{raw}} = \\sum_{i=1}^{k} \\left( \\frac{S_i}{\\sum_{j=1}^{k} S_j} \\right) \\cdot \\left( \\frac{c_{i,t}}{N_{i,t}} \\right)$$\n问题要求最终的率以每 $m = 10^5$ 人年表示。因此，我们用这个乘数来缩放原始率：\n$$R_t = m \\cdot R_{t, \\text{raw}} = 10^5 \\cdot \\sum_{i=1}^{k} \\left( \\frac{S_i}{\\sum_{j=1}^{k} S_j} \\right) \\left( \\frac{c_{i,t}}{N_{i,t}} \\right)$$\n这个计算对十年期 $t_1$ 和十年期 $t_2$ 都要执行，使用它们各自的病例数和人口数（$c_{i,t_1}, N_{i,t_1}$ 和 $c_{i,t_2}, N_{i,t_2}$），但关键的是，两者都使用*相同*的标准人口权重 $w_i$。这确保了 $R_{t_1}$ 和 $R_{t_2}$ 之间的任何观察到的差异不是由这两个十年期间研究人口的年龄构成变化引起的。\n\n**4. 长期变化的定义**\n\n长期变化量化了发病率的长期趋势。按照规定，我们将其定义为两个十年期间年龄标化率之间的绝对差：\n$$\\Delta R = |R_{t_2} - R_{t_1}|$$\n这个值表示在十年期 $t_1$ 和 $t_2$ 之间年龄调整发病率变化的幅度，以每 $10^5$ 人年为单位表示。\n\n**5. 算法摘要**\n\n需要实现的完整算法如下：对于每个提供的测试用例：\n1.  接收标准人口 $S$、病例数 $C_{t_1}$ 和 $C_{t_2}$，以及研究人口 $N_{t_1}$ 和 $N_{t_2}$ 的输入向量。\n2.  计算标准人口总数 $S_{total} = \\sum_{i=1}^{k} S_i$。\n3.  计算标准权重向量 $W = (w_1, \\dots, w_k)$，其中 $w_i = S_i / S_{total}$。\n4.  对于十年期 $t_1$：\n    a. 计算特定年龄发病率向量 $R'_{t_1} = (r_{1,t_1}, \\dots, r_{k,t_1})$，其中 $r_{i,t_1} = c_{i,t_1} / N_{i,t_1}$。\n    b. 计算标化率 $R_{t_1} = 10^5 \\cdot \\sum_{i=1}^{k} w_i \\cdot r_{i,t_1}$。\n5.  对于十年期 $t_2$：\n    a. 计算特定年龄发病率向量 $R'_{t_2} = (r_{1,t_2}, \\dots, r_{k,t_2})$，其中 $r_{i,t_2} = c_{i,t_2} / N_{i,t_2}$。\n    b. 计算标化率 $R_{t_2} = 10^5 \\cdot \\sum_{i=1}^{k} w_i \\cdot r_{i,t_2}$。\n6.  计算长期变化 $\\Delta R = |R_{t_2} - R_{t_1}|$。\n7.  将计算出的三个值 $R_{t_1}$、$R_{t_2}$ 和 $\\Delta R$ 四舍五入到两位小数。\n8.  存储结果三元组。\n\n这个过程将对所有测试用例执行，并将结果聚合到一个单一的扁平化列表中以供输出。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements an algorithm for direct age standardization to compute\n    age-standardized incidence rates and their secular change for multiple test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1\n        (\n            (300000, 320000, 200000, 140000, 40000),  # Standard population S^(1)\n            (180, 450, 720, 980, 500),                # Cases C^(1)_t1\n            (200000, 180000, 120000, 70000, 20000),  # Population N^(1)_t1\n            (160, 400, 800, 1100, 600),                # Cases C^(1)_t2\n            (180000, 160000, 130000, 90000, 30000)   # Population N^(1)_t2\n        ),\n        # Test case 2\n        (\n            (400000, 300000, 180000, 100000, 20000),  # Standard population S^(2)\n            (0, 200, 500, 600, 150),                   # Cases C^(2)_t1\n            (250000, 200000, 100000, 40000, 5000),   # Population N^(2)_t1\n            (0, 210, 600, 700, 350),                   # Cases C^(2)_t2\n            (240000, 220000, 120000, 60000, 10000)   # Population N^(2)_t2\n        ),\n        # Test case 3\n        (\n            (500000, 250000, 150000, 80000, 20000),  # Standard population S^(3)\n            (50, 100, 400, 1000, 2000),                # Cases C^(3)_t1\n            (100000, 100000, 100000, 100000, 100000), # Population N^(3)_t1\n            (200, 200, 480, 600, 400),                 # Cases C^(3)_t2\n            (400000, 200000, 120000, 60000, 20000)    # Population N^(3)_t2\n        ),\n        # Test case 4\n        (\n            (200000, 300000, 250000, 200000, 50000),  # Standard population S^(4)\n            (2, 9, 15, 30, 12),                       # Cases C^(4)_t1\n            (20000, 30000, 25000, 20000, 5000),     # Population N^(4)_t1\n            (3, 12, 20, 45, 25),                      # Cases C^(4)_t2\n            (20000, 30000, 25000, 20000, 5000)      # Population N^(4)_t2\n        )\n    ]\n\n    results = []\n    multiplier = 1e5\n\n    for s_pop, c_t1, n_t1, c_t2, n_t2 in test_cases:\n        # Convert tuples to numpy arrays for vectorized operations, ensuring float division.\n        s_pop_arr = np.array(s_pop, dtype=float)\n        c_t1_arr = np.array(c_t1, dtype=float)\n        n_t1_arr = np.array(n_t1, dtype=float)\n        c_t2_arr = np.array(c_t2, dtype=float)\n        n_t2_arr = np.array(n_t2, dtype=float)\n\n        # Step 1: Calculate standard weights\n        total_s_pop = np.sum(s_pop_arr)\n        weights = s_pop_arr / total_s_pop\n\n        # Step 2: Calculate age-specific rates for each decade\n        age_specific_rates_t1 = c_t1_arr / n_t1_arr\n        age_specific_rates_t2 = c_t2_arr / n_t2_arr\n\n        # Step 3: Calculate age-standardized rates (ASR)\n        # The ASR is the weighted average of age-specific rates, scaled by the multiplier.\n        # np.sum(weights * rates) is equivalent to the dot product.\n        asr_t1 = np.sum(weights * age_specific_rates_t1) * multiplier\n        asr_t2 = np.sum(weights * age_specific_rates_t2) * multiplier\n\n        # Step 4: Calculate secular change\n        secular_change = np.abs(asr_t2 - asr_t1)\n\n        # Step 5: Round results to 2 decimal places\n        asr_t1_rounded = np.round(asr_t1, 2)\n        asr_t2_rounded = np.round(asr_t2, 2)\n        secular_change_rounded = np.round(secular_change, 2)\n\n        results.extend([asr_t1_rounded, asr_t2_rounded, secular_change_rounded])\n\n    # Format results to always show two decimal places and create the final output string\n    formatted_results = [f\"{x:.2f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "当我们拟合了一个时间序列模型（例如使用STL分解）后，如何判断它是否充分捕捉了数据中的模式？答案在于分析残差，即移除趋势和季节性成分后剩下的部分。本练习将教您如何进行残差诊断，这是模型验证的关键一步，您将学习使用统计检验来检测残差中是否存在自相关等未被模型解释的结构，并根据诊断结果来决定如何改进模型。",
            "id": "4642205",
            "problem": "给定一组残差时间序列 $R_t$，该序列是通过对流行病学监测数据应用 Loess 季节性-趋势分解法 (STL) 得到的。在一个设定良好的分解下，残差应近似于一个白噪声过程，即在非零滞后项上具有近似为零的线性自相关。您的任务是评估每个残差序列是否显示出与季节性或趋势分量欠拟合相符的自相关证据，并以算法方式提出补救措施。\n\n使用的基本事实和定义：\n- 一个平稳的白噪声序列在所有非零滞后项上的自相关为零。\n- 滞后 $k$ 阶的样本自相关比较了 $R_t$ 和 $R_{t+k}$ 之间的协方差与 $R_t$ 的方差。\n- 一种用于残差自相关的标准 Portmanteau 检验，通过聚合多个滞后项的自相关贡献，来检验直到指定最大滞后阶数的所有自相关均为零的原假设。\n\n对于下文定义的每个测试用例，您的程序必须严格以数值方式执行以下所有操作：\n1) 从长度为 $n$ 的序列 $R_t$ 中计算滞后 $k \\in \\{1,2,\\dots,L\\}$ 的样本自相关值 $r_k$。\n2) 在显著性水平 $\\alpha$ 下，对直到滞后 $L$ 的自相关性进行标准的 Portmanteau 检验，以检验不存在自相关。使用任何与上述基本事实一致的公认 Portmanteau 公式，并报告一个布尔值，以指示是否检测到自相关。\n3) 使用方差近似为 $1/n$ 的大样本正态近似法，在显著性水平 $\\alpha$ 下，识别出 $|r_k|$ 单独显著的滞后 $k$ 的集合。具体来说，如果 $|r_k| > z_{1-\\alpha/2}/\\sqrt{n}$，则宣布滞后 $k$ 是显著的，其中 $z_{1-\\alpha/2}$ 是双侧正态临界值。\n4) 根据显著自相关的模式，依据以下反映常见 STL 调优操作的决策规则，提出一个数字补救代码：\n   - 代码 $0$：无操作。如果没有基于 Portmanteau 检验的自相关证据，并且不存在单独显著的滞后，则使用此代码。\n   - 代码 $2$：减小季节性平滑窗口大小（增加季节性灵活性）。如果在季节性倍数 $k \\in \\{m,2m,3m,\\dots\\}$ 中的一个或多个滞后处存在显著自相关，并且其平均符号为正，则使用此代码。\n   - 代码 $3$：增大趋势平滑窗口大小（使趋势更平滑）。如果存在显著的负短滞后自相关，特别是当滞后 $k=1$ 显著且 $r_1 < 0$ 时，使用此代码。\n   - 代码 $4$：减小趋势平滑窗口大小（使趋势更灵活）。如果存在显著的正短滞后自相关，特别是当滞后 $k=1$ 显著且 $r_1 > 0$ 时，使用此代码。\n   - 代码 $5$：考虑添加自回归移动平均误差模型（明确允许残差自相关）。如果许多滞后项显著，但与季节性倍数不符，且不符合上述特定的短滞后模式，则使用此代码。具体来说，如果显著滞后项的数量至少为 $\\max\\{5,\\lfloor 0.25L \\rfloor\\}$，并且短滞后规则和季节性倍数规则均不适用，则应用此代码。\n\n如果可能应用多个规则，请按此顺序确定优先级：季节性倍数（代码 $2$），然后是短滞后 $k=1$ 正相关（代码 $4$），然后是短滞后 $k=1$ 负相关（代码 $3$），然后是广泛残差自相关（代码 $5$），否则为代码 $0$。\n\n测试套件。对于每个案例，$t$ 从 $1$ 开始，每次递增 $1$，直到指定的 $n$。使用给定的季节性周期 $m$、最大滞后 $L$ 和显著性水平 $\\alpha$。所有计算均无单位。\n\n- 案例 A（季节性欠拟合模式）：\n  - $n=120$, $m=12$, $L=24$, $\\alpha=0.05$。\n  - $R_t = \\sin\\!\\left(2\\pi t/12\\right)$，对于 $t \\in \\{1,\\dots,120\\}$。\n\n- 案例 B（短滞后负自相关）：\n  - $n=100$, $m=12$, $L=20$, $\\alpha=0.05$。\n  - $R_t = (-0.8)^t$，对于 $t \\in \\{1,\\dots,100\\}$。\n\n- 案例 C（残留的缓慢趋势）：\n  - $n=200$, $m=12$, $L=24$, $\\alpha=0.05$。\n  - $R_t = \\sin\\!\\left(2\\pi t/200\\right)$，对于 $t \\in \\{1,\\dots,200\\}$。\n\n- 案例 D（与 $m$ 不一致的广泛结构性残差自相关）：\n  - $n=140$, $m=12$, $L=24$, $\\alpha=0.05$。\n  - $R_t = \\sin\\!\\left(2\\pi t/7\\right) + 0.5\\sin\\!\\left(2\\pi t/5\\right)$，对于 $t \\in \\{1,\\dots,140\\}$。\n\n- 案例 E（通过线性同余生成器产生的近白噪声确定性残差，边界/无操作案例）：\n  - $n=200$, $m=12$, $L=10$, $\\alpha=0.05$。\n  - 定义整数，模数 $M=10007$，乘数 $a=48271$，增量 $c=0$，种子 $x_1=1$，以及递推关系 $x_{t+1} = (a x_t + c) \\bmod M$ (对于 $t \\in \\{1,\\dots,199\\}$)。令 $U_t = x_t/M$。定义 $R_t = \\left(U_t - \\overline{U}\\right)/s_U$，其中 $\\overline{U}$ 是 $U_t$ 在 $t \\in \\{1,\\dots,200\\}$ 上的样本均值，$s_U$ 是 $U_t$ 的样本标准差。\n\n您的程序应生成单行输出，其中包含五个案例的结果，格式为一个用方括号括起来的逗号分隔列表。对于每个案例，输出一个包含三个元素的列表：\n- 一个布尔值，指示 Portmanteau 检验是否在显著性水平 $\\alpha$ 下拒绝无自相关的原假设，\n- 一个由正态近似规则确定的所有单独显著滞后（从 $1$ 到 $L$ 的整数）的升序列表，\n- 上文定义的整数补救代码。\n\n例如，最终输出必须是 \"[[bool,[k_1,k_2,...],code],[bool,[...],code],[...],[...],[...]]\" 的形式，不得包含任何额外文本。",
            "solution": "问题陈述已经过严格审查，并被确定为有效。它在科学上基于时间序列分析的原理，特别是在流行病学建模中对残差的诊断性检验。该问题提法得当，提供了所有必需的参数、数据定义和决策逻辑规则。任务是客观、定量且可通过计算验证的。\n\n目标是分析给定的残差时间序列 $R_t$，寻找可能表明 Loess 季节性-趋势分解法 (STL) 存在缺陷的自相关模式。这包括计算样本自相关函数 (ACF)，执行 Portmanteau 检验以评估总体显著性，识别单独显著的滞后，并根据指定的基于规则的系统推荐纠正措施。\n\n对每个长度为 $n$ 的时间序列的分析过程如下：\n\n首先，我们为每个测试用例定义时间序列。问题提供了五个不同的案例，生成序列 $R_t$ (对于 $t \\in \\{1, 2, \\dots, n\\}$)。\n\n其次，我们计算滞后 $k \\in \\{1, 2, \\dots, L\\}$ 的样本自相关函数 (ACF) $r_k$。滞后 $k$ 阶的 ACF 衡量了时间序列与其自身滞后版本之间的相关性。对于一个样本均值为 $\\bar{R}$ 的序列 $R_t$，样本自相关定义为：\n$$\nr_k = \\frac{\\sum_{t=1}^{n-k} (R_t - \\bar{R})(R_{t+k} - \\bar{R})}{\\sum_{t=1}^{n} (R_t - \\bar{R})^2}\n$$\n这些值是所有后续检验的基础。\n\n第三，我们执行 Ljung-Box Portmanteau 检验，以评估跨多个滞后的自相关的总体显著性。此检验评估原假设 $H_0$，即序列的前 $L$ 个自相关系数全部为零，即 $H_0: \\rho_1 = \\rho_2 = \\dots = \\rho_L = 0$。Ljung-Box Q 统计量计算如下：\n$$\nQ(L) = n(n+2) \\sum_{k=1}^{L} \\frac{r_k^2}{n-k}\n$$\n在原假设下，$Q(L)$ 服从自由度为 $L$ 的卡方分布，记作 $\\chi^2(L)$。如果计算出的 p 值 $P(\\chi^2(L) > Q(L))$ 小于显著性水平 $\\alpha$，我们就拒绝 $H_0$。结果是一个指示拒绝的布尔值。\n\n第四，我们识别出自相关 $r_k$ 具有统计显著性的单个滞后 $k$。对于大样本量 $n$，在原假设 ($\\rho_k = 0$) 下，$r_k$ 近似服从均值为 $0$、方差为 $1/n$ 的正态分布。因此，如果其绝对值超过基于标准正态分布的临界阈值，我们就在显著性水平 $\\alpha$ 下宣布滞后 $k$ 是显著的：\n$$\n|r_k| > \\frac{z_{1-\\alpha/2}}{\\sqrt{n}}\n$$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha = 0.05$，$z_{0.975} \\approx 1.96$。将编译一个从 $1$ 到 $L$ 的所有此类显著滞后的列表。\n\n第五，我们应用一个有优先级的、基于规则的算法来提出数字补救代码。规则按指定顺序进行评估：\n1.  **代码 2 (季节性欠拟合)：** 如果在季节性滞后（即集合 $\\{m, 2m, \\dots\\}$ 中的 $k$，其中 $m$ 是季节周期）处存在显著自相关，并且这些显著季节性自相关的平均符号为正，则触发此代码。\n2.  **代码 4 (趋势过于平滑)：** 如果前一规则不适用，并且滞后 $k=1$ 处的自相关显著且为正 ($r_1 > 0$)，则触发此代码，这表明趋势欠拟合（不够灵活）。\n3.  **代码 3 (趋势过于灵活)：** 如果之前的规则不适用，并且滞后 $k=1$ 处的自相关显著且为负 ($r_1 < 0$)，则触发此代码，这表明趋势过拟合（过于灵活）。\n4.  **代码 5 (一般残差结构)：** 如果以上规则均不适用，并且存在大量显著滞后（具体来说，如果计数至少为 $\\max\\{5, \\lfloor 0.25L \\rfloor\\}$），则触发此代码。这表明存在更复杂的相关结构，可能需要为残差建立自回归移动平均 (ARMA) 模型。\n5.  **代码 0 (无操作)：** 如果代码 $2、4、3$ 或 $5$ 的条件均未满足，则分配此代码，表示残差已足够接近白噪声。\n\n此完整过程将应用于问题陈述中定义的五个测试用例中的每一个。案例 E 的序列生成涉及一个线性同余生成器 $x_{t+1} = (a x_t + c) \\pmod M$，其种子 $x_1=1$，乘数 $a=48271$，增量 $c=0$，模数 $M=10007$，然后对序列 $U_t = x_t / M$ 进行标准化。所有计算都以数值方式执行，为每个案例生成指定的输出格式。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2, norm\n\ndef analyze_series(R_t, n, m, L, alpha):\n    \"\"\"\n    Analyzes a time series for autocorrelation and proposes a remedy.\n    \n    Args:\n        R_t (np.ndarray): The time series data.\n        n (int): Length of the time series.\n        m (int): Seasonal period.\n        L (int): Maximum lag for tests.\n        alpha (float): Significance level.\n\n    Returns:\n        list: [portmanteau_rejection (bool), significant_lags (list), remedy_code (int)]\n    \"\"\"\n    \n    # Step 1: Compute sample autocorrelation function (ACF) r_k for k=1,...,L\n    mean_R = np.mean(R_t)\n    centered_R = R_t - mean_R\n    var_R = np.sum(centered_R**2)\n    \n    r = np.zeros(L)\n    for k in range(1, L + 1):\n        # Numerator: sum of cross-products of lagged series\n        numerator = np.sum(centered_R[:n-k] * centered_R[k:])\n        r[k-1] = numerator / var_R\n\n    # Step 2: Perform Ljung-Box portmanteau test\n    q_statistic = 0\n    for k in range(1, L + 1):\n        q_statistic += (r[k-1]**2) / (n - k)\n    q_statistic *= n * (n + 2)\n    \n    p_value = chi2.sf(q_statistic, df=L)\n    portmanteau_rejection = p_value  alpha\n\n    # Step 3: Identify individually significant lags\n    critical_value = norm.ppf(1 - alpha / 2) / np.sqrt(n)\n    significant_lags = [k for k in range(1, L + 1) if np.abs(r[k-1]) > critical_value]\n\n    # Step 4: Propose a numeric remedy code based on prioritized rules\n    remedy_code = 0  # Default: No action\n    \n    # Rule for Code 2 (seasonal underfitting)\n    seasonal_lags_significant = [k for k in significant_lags if k > 0 and k % m == 0]\n    if seasonal_lags_significant:\n        avg_seasonal_r = np.mean([r[k-1] for k in seasonal_lags_significant])\n        if avg_seasonal_r > 0:\n            remedy_code = 2\n            return [portmanteau_rejection, significant_lags, remedy_code]\n\n    # Rule for Code 4 (trend too smooth)\n    if 1 in significant_lags and r[0] > 0:\n        remedy_code = 4\n        return [portmanteau_rejection, significant_lags, remedy_code]\n\n    # Rule for Code 3 (trend too flexible)\n    if 1 in significant_lags and r[0]  0:\n        remedy_code = 3\n        return [portmanteau_rejection, significant_lags, remedy_code]\n        \n    # Rule for Code 5 (broad residual autocorrelation)\n    min_significant_count = max(5, L // 4)\n    if len(significant_lags) >= min_significant_count:\n        remedy_code = 5\n        return [portmanteau_rejection, significant_lags, remedy_code]\n\n    # Rule for Code 0 is the fallback if no other rules apply.\n    # An additional condition is added from the description for clarity, though priority implies it.\n    if not portmanteau_rejection and not significant_lags:\n        remedy_code = 0\n        \n    return [portmanteau_rejection, significant_lags, remedy_code]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases_defs = {\n        'A': {'n': 120, 'm': 12, 'L': 24, 'alpha': 0.05, 'type': 'A'},\n        'B': {'n': 100, 'm': 12, 'L': 20, 'alpha': 0.05, 'type': 'B'},\n        'C': {'n': 200, 'm': 12, 'L': 24, 'alpha': 0.05, 'type': 'C'},\n        'D': {'n': 140, 'm': 12, 'L': 24, 'alpha': 0.05, 'type': 'D'},\n        'E': {'n': 200, 'm': 12, 'L': 10, 'alpha': 0.05, 'type': 'E'},\n    }\n\n    results = []\n\n    for case_id in ['A', 'B', 'C', 'D', 'E']:\n        params = test_cases_defs[case_id]\n        n, m, L, alpha = params['n'], params['m'], params['L'], params['alpha']\n        \n        R_t = None\n        t = np.arange(1, n + 1)\n\n        if params['type'] == 'A':\n            R_t = np.sin(2 * np.pi * t / 12)\n        elif params['type'] == 'B':\n            R_t = (-0.8)**t\n        elif params['type'] == 'C':\n            R_t = np.sin(2 * np.pi * t / 200)\n        elif params['type'] == 'D':\n            R_t = np.sin(2 * np.pi * t / 7) + 0.5 * np.sin(2 * np.pi * t / 5)\n        elif params['type'] == 'E':\n            M = 10007\n            a = 48271\n            c = 0\n            x = np.zeros(n, dtype=np.int64)\n            x[0] = 1\n            for i in range(1, n):\n                x[i] = (a * x[i-1] + c) % M\n            \n            U_t = x / M\n            mean_U = np.mean(U_t)\n            std_U = np.std(U_t)\n            R_t = (U_t - mean_U) / std_U\n        \n        result_tuple = analyze_series(R_t, n, m, L, alpha)\n        results.append(result_tuple)\n    \n    # Using python's default string conversion for bools (True/False)\n    # and lists, as the prompt example is ambiguous.\n    final_output_string = str(results).replace(\"'\", \"\")\n    \n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}