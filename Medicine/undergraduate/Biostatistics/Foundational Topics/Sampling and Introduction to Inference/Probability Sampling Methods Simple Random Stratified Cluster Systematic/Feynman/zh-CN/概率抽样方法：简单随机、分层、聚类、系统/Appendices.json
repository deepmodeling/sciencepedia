{
    "hands_on_practices": [
        {
            "introduction": "抽样设计的一个核心目标是在固定成本或样本量下最大化估计的精确度（即最小化方差）。分层抽样是实现这一目标的有力工具。本练习将通过一个生物统计学场景，让您亲手实践并量化最优分配策略（Neyman分配）相比于简单的比例分配所带来的效率提升。这个计算将清晰地揭示分层抽样中样本分配决策背后的统计学原理及其对研究结果精确度的实际影响。",
            "id": "4942771",
            "problem": "一个生物统计学团队正计划进行一项分层研究，以估计一个连续性生物标志物在三个由临床风险类别定义的层中的总体均值。各层的人口规模分别为 $N_{1} = 1200$、$N_{2} = 800$ 和 $N_{3} = 500$，总人口规模为 $N = 2500$。该生物标志物在各层中的总体标准差分别为 $S_{1} = 12$、$S_{2} = 20$ 和 $S_{3} = 8$。总样本量固定为 $n = 300$，且每层内的抽样方法为无放回简单随机抽样（SRSWOR）。\n\n仅使用分层抽样的第一性原理和经过充分检验的事实，计算比率\n$$\\frac{\\operatorname{Var}_{\\text{prop}}}{\\operatorname{Var}_{\\text{Neyman}}}$$\n其中 $\\operatorname{Var}_{\\text{prop}}$ 是在比例分配 $n_{h} = n \\cdot N_{h}/N$ 下总体均值的分层估计量的方差，而 $\\operatorname{Var}_{\\text{Neyman}}$ 是在 Neyman 分配 $n_{h} \\propto N_{h} S_{h}$ 下的方差，两者均在层内使用有限总体校正进行评估。为了计算方便，将 $n_{h}$ 视为实数（忽略整数取整）。将最终比率四舍五入至四位有效数字。然后，根据 Neyman 分配相对于比例分配所实现的效率增益，简要解释此比率，将任何分数形式的减少表示为小数（不要使用百分号）。",
            "solution": "该问题是有效的，因为它在科学上基于生物统计学的原理，是自洽的，并且提法明确。所有计算所需的数据都已提供，目标也已明确定义。我们可以着手解决。\n\n目标是计算比率 $\\frac{\\operatorname{Var}_{\\text{prop}}}{\\operatorname{Var}_{\\text{Neyman}}}$，其中 $\\operatorname{Var}_{\\text{prop}}$ 和 $\\operatorname{Var}_{\\text{Neyman}}$ 分别是比例分配和 Neyman 分配下分层均值估计量的方差。\n\n分层均值估计量 $\\bar{y}_{st} = \\sum_{h=1}^{L} W_h \\bar{y}_h$ 在使用有限总体校正（FPC）时的通用方差公式为：\n$$ \\operatorname{Var}(\\bar{y}_{st}) = \\sum_{h=1}^{L} W_h^2 \\operatorname{Var}(\\bar{y}_h) = \\sum_{h=1}^{L} W_h^2 \\left(1-\\frac{n_h}{N_h}\\right) \\frac{S_h^2}{n_h} $$\n其中 $L$ 是分层数，$W_h = N_h/N$ 是第 $h$ 层的权重，$N_h$ 是第 $h$ 层的总体规模，$N$ 是总总体规模，$n_h$ 是第 $h$ 层的样本量，$S_h$ 是第 $h$ 层的总体标准差。这可以改写为：\n$$ \\operatorname{Var}(\\bar{y}_{st}) = \\sum_{h=1}^{L} W_h^2 \\left(\\frac{S_h^2}{n_h} - \\frac{S_h^2}{N_h}\\right) = \\sum_{h=1}^{L} \\frac{W_h^2 S_h^2}{n_h} - \\sum_{h=1}^{L} \\frac{W_h^2 S_h^2}{N_h} $$\n由于 $W_h = N_h/N$，第二项简化为 $\\frac{1}{N^2} \\sum_{h=1}^{L} N_h S_h^2$，或等价地 $\\frac{1}{N} \\sum_{h=1}^{L} W_h S_h^2$。无论采用何种样本分配方法，这一项都是一个常数。\n\n已知数据如下：\n总总体规模 $N = 2500$。\n总样本量 $n = 300$。\n第 1 层：$N_1 = 1200$, $S_1 = 12$。\n第 2 层：$N_2 = 800$, $S_2 = 20$。\n第 3 层：$N_3 = 500$, $S_3 = 8$。\n\n首先，我们计算各层权重 $W_h$：\n$W_1 = \\frac{N_1}{N} = \\frac{1200}{2500} = 0.48$\n$W_2 = \\frac{N_2}{N} = \\frac{800}{2500} = 0.32$\n$W_3 = \\frac{N_3}{N} = \\frac{500}{2500} = 0.20$\n\n接下来，我们评估每种分配方案的方差。\n\n**1. 比例分配**\n在比例分配下，每层的样本量为 $n_h^{\\text{prop}} = n \\frac{N_h}{N} = n W_h$。\n$n_1^{\\text{prop}} = 300 \\cdot 0.48 = 144$\n$n_2^{\\text{prop}} = 300 \\cdot 0.32 = 96$\n$n_3^{\\text{prop}} = 300 \\cdot 0.20 = 60$\n对于比例分配，FPC 项 $(1 - n_h/N_h)$ 在各层之间是恒定的：$1 - \\frac{n}{N} = 1 - \\frac{300}{2500} = 1 - 0.12 = 0.88$。\n方差公式简化为：\n$$ \\operatorname{Var}_{\\text{prop}} = \\left(1 - \\frac{n}{N}\\right) \\sum_{h=1}^{L} \\frac{W_h^2 S_h^2}{n_h^{\\text{prop}}} = \\left(1 - \\frac{n}{N}\\right) \\sum_{h=1}^{L} \\frac{W_h^2 S_h^2}{n W_h} = \\frac{1}{n}\\left(1 - \\frac{n}{N}\\right) \\sum_{h=1}^{L} W_h S_h^2 $$\n我们计算项 $\\sum W_h S_h^2$：\n$$ \\sum_{h=1}^{3} W_h S_h^2 = (0.48)(12^2) + (0.32)(20^2) + (0.20)(8^2) $$\n$$ = (0.48)(144) + (0.32)(400) + (0.20)(64) = 69.12 + 128 + 12.8 = 209.92 $$\n现在我们计算 $\\operatorname{Var}_{\\text{prop}}$：\n$$ \\operatorname{Var}_{\\text{prop}} = \\frac{1}{300}\\left(1 - \\frac{300}{2500}\\right) (209.92) = \\frac{0.88}{300}(209.92) = \\frac{184.7296}{300} \\approx 0.61576533 $$\n\n**2. Neyman 分配**\n在 Neyman 分配下，样本量为 $n_h^{\\text{Neyman}} = n \\frac{N_h S_h}{\\sum_{k=1}^{L} N_k S_k}$。\n首先，计算分母 $\\sum N_k S_k$：\n$$ \\sum_{k=1}^{3} N_k S_k = (1200)(12) + (800)(20) + (500)(8) = 14400 + 16000 + 4000 = 34400 $$\n可分配的样本量（作为实数值）为：\n$n_1^{\\text{Neyman}} = 300 \\cdot \\frac{14400}{34400} = \\frac{5400}{43} \\approx 125.58$\n$n_2^{\\text{Neyman}} = 300 \\cdot \\frac{16000}{34400} = \\frac{6000}{43} \\approx 139.53$\n$n_3^{\\text{Neyman}} = 300 \\cdot \\frac{4000}{34400} = \\frac{1500}{43} \\approx 34.88$\nNeyman 分配下的方差可以使用一个包含 FPC 的简化公式来计算：\n$$ \\operatorname{Var}_{\\text{Neyman}} = \\frac{1}{n}\\left(\\sum_{h=1}^{L} W_h S_h\\right)^2 - \\frac{1}{N}\\sum_{h=1}^{L} W_h S_h^2 $$\n我们需要项 $\\sum W_h S_h$ 和 $\\sum W_h S_h^2$。我们已经求得 $\\sum W_h S_h^2 = 209.92$。\n我们来求 $\\sum W_h S_h$：\n$$ \\sum_{h=1}^{3} W_h S_h = (0.48)(12) + (0.32)(20) + (0.20)(8) = 5.76 + 6.4 + 1.6 = 13.76 $$\n现在我们计算 $\\operatorname{Var}_{\\text{Neyman}}$：\n$$ \\operatorname{Var}_{\\text{Neyman}} = \\frac{1}{300}(13.76)^2 - \\frac{1}{2500}(209.92) $$\n$$ = \\frac{189.3376}{300} - \\frac{209.92}{2500} = 0.63112533... - 0.083968 = 0.54715733... $$\n\n**3. 计算比率**\n现在我们计算比率 $\\frac{\\operatorname{Var}_{\\text{prop}}}{\\operatorname{Var}_{\\text{Neyman}}}$：\n$$ \\text{Ratio} = \\frac{0.61576533...}{0.54715733...} \\approx 1.125390 $$\n四舍五入到四位有效数字，比率为 $1.125$。\n\n**解释**\n方差比 $\\frac{\\operatorname{Var}_{\\text{prop}}}{\\operatorname{Var}_{\\text{Neyman}}} \\approx 1.125$ 量化了 Neyman 分配相对于比例分配的相对效率。大于 $1$ 的比率表明 Neyman 分配效率更高，能在相同的总样本量下产生更小的方差。效率增益可以表示为使用 Neyman 分配替代比例分配时方差的分数减少量。这个分数减少量由 $1 - \\frac{\\operatorname{Var}_{\\text{Neyman}}}{\\operatorname{Var}_{\\text{prop}}} = 1 - \\frac{1}{\\text{Ratio}}$ 给出。使用未四舍五入的比率以获得更高的精度：\n$$ \\text{Fractional Reduction} = 1 - \\frac{1}{1.125390...} \\approx 1 - 0.88858 = 0.11142 $$\n因此，对于本研究设计，从比例分配转向 Neyman 分配将使估计的总体均值的方差减少约 $0.1114$ 的分数。这种精度的提升得以实现，是因为 Neyman 分配将更多的抽样精力投入到规模更大（$N_h$ 更大）和变异性更大（$S_h$ 更大）的层中，这是最小化估计量总方差的最优策略。",
            "answer": "$$\\boxed{1.125}$$"
        },
        {
            "introduction": "尽管分层抽样可以提高效率，但其他抽样方法（如整群抽样）常因其操作上的便利性而被采用，但这通常会以牺牲统计效率为代价。本练习将向您介绍“组内相关系数”（ICC）这一关键概念，它是导致整群抽样效率损失的根源。通过从第一性原理出发，您将推导并计算“设计效应”（DEFF），从而精确地量化与简单随机抽样相比，整群抽样的方差被放大了多少，并理解其对置信区间宽度的直接影响。",
            "id": "4942743",
            "problem": "一个公共卫生团队正在使用一级整群抽样设计来估计总体比例。假设群组的定义是每个抽样群组恰好贡献 $b=15$ 个观测单位，并且感兴趣的结果是二元的，成功指示符为 $Y \\in \\{0,1\\}$，总体成功概率为 $p$。假设总体很大，因此有限总体校正可以忽略不计。不同群组之间的观测是独立的。在任何给定的群组内，所有不同观测对都具有相同的群内相关性 $\\rho=0.1$。设总样本量为 $n=m b$，其中 $m$ 是抽样群组的数量。\n\n将估计量 $\\hat{p}$ 定义为所有抽样单位的总体样本均值。使用方差、协方差和群内相关性的核心定义，并从以下恒等式出发：对于任何有限的随机变量集合，\n$$\n\\operatorname{Var}\\!\\Big(\\sum_{k} X_{k}\\Big) \\;=\\; \\sum_{k} \\operatorname{Var}(X_{k}) \\;+\\; 2 \\sum_{k\\ell} \\operatorname{Cov}(X_{k}, X_{\\ell}),\n$$\n推导在此整群抽样设计下，$\\hat{p}$ 的方差相对于 $n$ 个独立单位的简单随机抽样（具有相同的 $n$ 和 $p$）的乘法膨胀因子。然后，确定在整群抽样设计下，相对于简单随机抽样，$p$ 的标准大样本正态（Wald）置信区间宽度的相应乘法膨胀因子，保持置信水平不变。将这两个量表示为无单位的因子。\n\n最后，代入 $b=15$ 和 $\\rho=0.1$ 以数值方式计算这两个因子，并按以下顺序报告它们：\n- 首先：相对于简单随机抽样的方差膨胀因子，以及\n- 其次：相对于简单随机抽样的置信区间宽度膨胀因子。\n\n将每个因子四舍五入到四位有效数字。以纯数字形式表示最终答案（无单位）。",
            "solution": "问题要求计算与一级整群抽样设计相关的两个乘法膨胀因子，并将其与具有相同总样本量 $n$ 的简单随机抽样 (SRS) 设计进行比较。第一个因子是比例估计量 $\\hat{p}$ 的方差，第二个是相应置信区间的宽度。\n\n设 $m$ 是抽样的群组数， $b$ 是每个群组的观测单位数。总样本量为 $n=mb$。设 $Y_{ij}$ 为第 $i$ 个群组中第 $j$ 个单位的二元结果，其中 $i \\in \\{1, \\dots, m\\}$ 且 $j \\in \\{1, \\dots, b\\}$。由于结果是二元的，总体成功概率为 $p$，因此 $Y_{ij}$ 服从参数为 $p$ 的伯努利分布。因此，对于任何 $i, j$：\n$$\n\\mathrm{E}[Y_{ij}] = p\n$$\n$$\n\\mathrm{Var}(Y_{ij}) = p(1-p)\n$$\n总体比例的估计量 $\\hat{p}$ 是总体样本均值：\n$$\n\\hat{p} = \\frac{1}{n} \\sum_{i=1}^{m} \\sum_{j=1}^{b} Y_{ij} = \\frac{1}{mb} \\sum_{i=1}^{m} \\sum_{j=1}^{b} Y_{ij}\n$$\n首先，我们推导在这种整群抽样设计下 $\\hat{p}$ 的方差，记为 $\\mathrm{Var}_{\\text{cluster}}(\\hat{p})$。\n$$\n\\mathrm{Var}_{\\text{cluster}}(\\hat{p}) = \\mathrm{Var}\\left(\\frac{1}{mb} \\sum_{i=1}^{m} \\sum_{j=1}^{b} Y_{ij}\\right) = \\frac{1}{(mb)^2} \\mathrm{Var}\\left(\\sum_{i=1}^{m} \\sum_{j=1}^{b} Y_{ij}\\right)\n$$\n设 $T = \\sum_{i=1}^{m} \\sum_{j=1}^{b} Y_{ij}$。我们可以写成 $T = \\sum_{i=1}^{m} T_i$，其中 $T_i = \\sum_{j=1}^{b} Y_{ij}$ 是群组 $i$ 内结果的总和。问题陈述，不同群组之间的观测是独立的。因此，两个不同群组总和之间的协方差为零，即对于 $i \\neq k$，有 $\\mathrm{Cov}(T_i, T_k) = 0$。这意味着总和 $T$ 的方差是各群组总和方差之和：\n$$\n\\mathrm{Var}(T) = \\mathrm{Var}\\left(\\sum_{i=1}^{m} T_i\\right) = \\sum_{i=1}^{m} \\mathrm{Var}(T_i)\n$$\n由于每个群组在结构上是相同的，所以 $\\mathrm{Var}(T_i)$ 对所有 $i$ 都是相同的。让我们计算 $\\mathrm{Var}(T_1)$：\n$$\n\\mathrm{Var}(T_1) = \\mathrm{Var}\\left(\\sum_{j=1}^{b} Y_{1j}\\right)\n$$\n使用所提供的恒等式 $\\mathrm{Var}(\\sum_{k} X_{k}) = \\sum_{k} \\mathrm{Var}(X_{k}) + 2 \\sum_{k\\ell} \\mathrm{Cov}(X_{k}, X_{\\ell})$，我们有：\n$$\n\\mathrm{Var}(T_1) = \\sum_{j=1}^{b} \\mathrm{Var}(Y_{1j}) + 2 \\sum_{1 \\le j  k \\le b} \\mathrm{Cov}(Y_{1j}, Y_{1k})\n$$\n每个观测的方差是 $\\mathrm{Var}(Y_{1j}) = p(1-p)$。对于同一群组内的任意两个不同观测，群内相关系数 $\\rho$ 定义为：\n$$\n\\rho = \\frac{\\mathrm{Cov}(Y_{ij}, Y_{ik})}{\\sqrt{\\mathrm{Var}(Y_{ij})\\mathrm{Var}(Y_{ik})}} = \\frac{\\mathrm{Cov}(Y_{ij}, Y_{ik})}{p(1-p)} \\quad \\text{for } j \\neq k\n$$\n由此，我们得到对于 $j \\neq k$，有 $\\mathrm{Cov}(Y_{ij}, Y_{ik}) = \\rho p(1-p)$。\n将这些代入 $\\mathrm{Var}(T_1)$ 的表达式中：\n方差之和为 $\\sum_{j=1}^{b} \\mathrm{Var}(Y_{1j}) = b \\cdot p(1-p)$。\n协方差之和涉及群组内 $\\binom{b}{2} = \\frac{b(b-1)}{2}$ 对不同的观测。\n$$\n2 \\sum_{1 \\le j  k \\le b} \\mathrm{Cov}(Y_{1j}, Y_{1k}) = 2 \\cdot \\frac{b(b-1)}{2} \\cdot \\rho p(1-p) = b(b-1)\\rho p(1-p)\n$$\n因此，一个群组总和的方差是：\n$$\n\\mathrm{Var}(T_1) = b p(1-p) + b(b-1)\\rho p(1-p) = b p(1-p) [1 + (b-1)\\rho]\n$$\n现在，我们可以求出总和 $T$ 的方差：\n$$\n\\mathrm{Var}(T) = \\sum_{i=1}^{m} \\mathrm{Var}(T_i) = m \\cdot \\mathrm{Var}(T_1) = m b p(1-p) [1 + (b-1)\\rho]\n$$\n最后，我们将此代回 $\\mathrm{Var}_{\\text{cluster}}(\\hat{p})$ 的表达式中：\n$$\n\\mathrm{Var}_{\\text{cluster}}(\\hat{p}) = \\frac{1}{(mb)^2} \\mathrm{Var}(T) = \\frac{m b p(1-p) [1 + (b-1)\\rho]}{(mb)^2} = \\frac{p(1-p)}{mb} [1 + (b-1)\\rho]\n$$\n因为 $n=mb$，我们有：\n$$\n\\mathrm{Var}_{\\text{cluster}}(\\hat{p}) = \\frac{p(1-p)}{n} [1 + (b-1)\\rho]\n$$\n接下来，我们考虑在 $n$ 个单位的简单随机抽样下 $\\hat{p}$ 的方差，记为 $\\mathrm{Var}_{\\text{SRS}}(\\hat{p})$。在 SRS 下，所有 $n$ 个观测都是独立的。\n$$\n\\mathrm{Var}_{\\text{SRS}}(\\hat{p}) = \\mathrm{Var}\\left(\\frac{1}{n} \\sum_{k=1}^{n} Y_k\\right) = \\frac{1}{n^2} \\sum_{k=1}^{n} \\mathrm{Var}(Y_k) = \\frac{1}{n^2} \\cdot n \\cdot p(1-p) = \\frac{p(1-p)}{n}\n$$\n所需的第一个量是方差膨胀因子 (VIF)，也称为设计效应 (DEFF)。这是整群抽样下的方差与简单随机抽样下的方差之比。\n$$\n\\text{VIF} = \\frac{\\mathrm{Var}_{\\text{cluster}}(\\hat{p})}{\\mathrm{Var}_{\\text{SRS}}(\\hat{p})} = \\frac{\\frac{p(1-p)}{n} [1 + (b-1)\\rho]}{\\frac{p(1-p)}{n}} = 1 + (b-1)\\rho\n$$\n第二个量是大样本正态（Wald）置信区间宽度的膨胀因子。这种区间的宽度与估计量的标准误成正比，$\\mathrm{SE}(\\hat{p}) = \\sqrt{\\mathrm{Var}(\\hat{p})}$。\n区间的宽度为 $2 z_{\\alpha/2} \\mathrm{SE}(\\hat{p})$，其中 $z_{\\alpha/2}$ 是对于给定置信水平 $1-\\alpha$ 从标准正态分布中得到的临界值。\n因此，宽度的比值为：\n$$\n\\text{Width Inflation Factor} = \\frac{\\text{Width}_{\\text{cluster}}}{\\text{Width}_{\\text{SRS}}} = \\frac{2 z_{\\alpha/2} \\mathrm{SE}_{\\text{cluster}}(\\hat{p})}{2 z_{\\alpha/2} \\mathrm{SE}_{\\text{SRS}}(\\hat{p})} = \\frac{\\sqrt{\\mathrm{Var}_{\\text{cluster}}(\\hat{p})}}{\\sqrt{\\mathrm{Var}_{\\text{SRS}}(\\hat{p})}}\n$$\n这个因子是 VIF 的平方根：\n$$\n\\text{Width Inflation Factor} = \\sqrt{\\frac{\\mathrm{Var}_{\\text{cluster}}(\\hat{p})}{\\mathrm{Var}_{\\text{SRS}}(\\hat{p})}} = \\sqrt{\\text{VIF}} = \\sqrt{1 + (b-1)\\rho}\n$$\n这个量也称为设计效应的平方根 (DEFT)。\n\n最后，我们代入给定的数值 $b=15$ 和 $\\rho=0.1$ 来计算这两个因子。\n方差膨胀因子是：\n$$\n\\text{VIF} = 1 + (15 - 1) \\times 0.1 = 1 + 14 \\times 0.1 = 1 + 1.4 = 2.4\n$$\n四舍五入到四位有效数字得到 $2.400$。\n\n置信区间宽度膨胀因子是：\n$$\n\\text{Width Inflation Factor} = \\sqrt{2.4} \\approx 1.5491933...\n$$\n四舍五入到四位有效数字得到 $1.549$。\n\n这两个因子按指定顺序报告：首先是方差膨胀因子，然后是置信区间宽度膨胀因子。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.400  1.549\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在掌握了整群抽样的理论挑战（如设计效应）后，至关重要的是学习如何在真实数据分析中处理这些问题。本练习将理论与现代统计计算实践相结合，要求您编写代码，比较两种主流的方差估计方法：泰勒线性化（一种经典的分析近似方法）和自助法（一种现代的重抽样方法）。通过处理给定的整群抽样数据，本练习将帮助您掌握在复杂抽样设计下估计比例值方差的实用技能，为解决现实世界中的生物统计学问题做好准备。",
            "id": "4942737",
            "problem": "给定一个单阶段整群抽样样本，其中包含初级抽样单元 (PSU)，每个 PSU 包含个体总数和具有感兴趣的二元结果的个体数。您将使用两种方法在一个有放回 PSU 抽样框架下估计总体比例及其方差：一种是对 PSU 进行有放回重抽样的整群层面自助法，另一种是用于比率估计量的一阶泰勒线性化近似。所有量必须以小数（而非百分比）表示。基于设计的逻辑必须从以下基本基础出发：等概率抽样下 Horvitz–Thompson 总量的无偏性、作为估计总量之比形成的比例估计量，以及用于方差线性化的一阶泰勒展开。\n\n使用的定义。设有 $m$ 个 PSU，索引为 $i \\in \\{1,\\dots,m\\}$。对于 PSU $i$，设 $n_i$ 为观察到的个体数，$y_i$ 为具有二元结果的个体数。比例的估计量是总量的样本比率，\n$$\n\\hat{p} \\;=\\; \\frac{\\sum_{i=1}^{m} y_i}{\\sum_{i=1}^{m} n_i}.\n$$\n整群自助法（有放回地重抽样 PSU）通过生成 $B$ 个自助法重复样本来进行。在重复样本 $b \\in \\{1,\\dots,B\\}$ 中，从集合 $\\{1,\\dots,m\\}$ 中有放回地抽取 $m$ 个 PSU，计算\n$$\n\\hat{p}^{*(b)} \\;=\\; \\frac{\\sum_{j=1}^{m} y_{I^{(b)}_j}}{\\sum_{j=1}^{m} n_{I^{(b)}_j}},\n$$\n然后将自助法方差估计为各重复样本间的样本方差：\n$$\n\\hat{V}_{\\text{boot}}(\\hat{p}) \\;=\\; \\frac{1}{B-1}\\sum_{b=1}^{B}\\Big(\\hat{p}^{*(b)} - \\bar{\\hat{p}}^{*}\\Big)^2,\\quad \\bar{\\hat{p}}^{*} \\;=\\; \\frac{1}{B}\\sum_{b=1}^{B}\\hat{p}^{*(b)}.\n$$\n比率估计量的一阶泰勒线性化使用线性化变量\n$$\nu_i \\;=\\; y_i \\;-\\; \\hat{p}\\, n_i.\n$$\n在有放回 PSU 抽样近似下，$\\hat{p}$ 方差的一个估计量是\n$$\n\\hat{V}_{\\text{lin}}(\\hat{p}) \\;=\\; \\frac{m}{m-1}\\,\\frac{\\sum_{i=1}^{m} u_i^2}{\\Big(\\sum_{i=1}^{m} n_i\\Big)^2}.\n$$\n\n实现一个程序，为每个指定的测试用例计算 $\\hat{p}$、自助法方差 $\\hat{V}_{\\text{boot}}(\\hat{p})$ 和线性化方差 $\\hat{V}_{\\text{lin}}(\\hat{p})$，并返回三元组 $[\\hat{p}, \\hat{V}_{\\text{boot}}(\\hat{p}), \\hat{V}_{\\text{lin}}(\\hat{p})]$，每个值四舍五入到 $6$ 位小数。\n\n使用以下数值数据集和测试套件。每个数据集都是明确给出的 PSU 对 $(n_i,y_i)$ 的列表，每个测试指定自助法重复次数 $B$ 和一个伪随机种子值以确保可复现性。所有数字都以整数形式出现；您的计算必须产生十进制输出。\n\n数据集 A（中等规模，均衡的整群大小）：\n- (85, 12), (73, 9), (120, 20), (64, 6), (95, 14), (102, 13), (58, 5), (80, 10), (140, 25), (77, 8), (66, 7), (90, 11).\n\n数据集 B（异构大小，并包含一个零结果 PSU）：\n- (150, 28), (45, 2), (60, 4), (110, 15), (90, 8), (200, 35), (30, 0), (75, 7).\n\n数据集 C（少量 PSU，边界情况）：\n- (40, 3), (55, 7), (35, 2).\n\n要实现的测试套件：\n- 情况 1：数据集 A, B = 10000, 种子 = 12345.\n- 情况 2：数据集 A, B = 500, 种子 = 12345.\n- 情况 3：数据集 B, B = 10000, 种子 = 202311.\n- 情况 4：数据集 C, B = 10000, 种子 = 777.\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，其中每个情况的三元组都是一个内部列表，例如：\n\"[[p_1, v_{b,1}, v_{\\ell,1}],[p_2, v_{b,2}, v_{\\ell,2}],...]\".\n您必须将每个浮点数四舍五入到 $6$ 位小数，并返回小数（而非百分比）。不应打印其他任何文本。\n\n您的实现必须是完全自包含的，不接受任何输入，也不访问任何文件或网络。您必须遵守指定的测试套件和输出格式。",
            "solution": "该问题是有效的。它在生物统计学和调查抽样理论的既定原则内，提出了一个明确定义的计算任务。所有必要的数据、公式和参数都已提供，并且该问题是自包含的、客观的且科学上合理的。\n\n任务是从单阶段整群抽样数据中估计比例 $\\hat{p}$，并使用两种不同的方法计算此估计的方差：整群层面自助法和一阶泰勒级数线性化。\n\n设数据由 $m$ 个初级抽样单元 (PSU) 或整群组成。对于每个 PSU $i \\in \\{1, \\dots, m\\}$，我们给定了整群大小 $n_i$ 和具有二元结果的个体计数 $y_i$。\n\n**1. 比例估计**\n\n总体比例的估计量 $\\hat{p}$ 是两个估计总量的比率：样本中阳性结果的总计数除以样本中个体的总计数。这是一个比率估计量，对于真实的总体比例是一致的。公式是：\n$$\n\\hat{p} \\;=\\; \\frac{\\sum_{i=1}^{m} y_i}{\\sum_{i=1}^{m} n_i}\n$$\n此计算涉及将所有整群的 $y_i$ 值相加，然后除以所有 $n_i$ 值的总和。\n\n**2. 通过一阶泰勒线性化进行方差估计**\n\n泰勒线性化方法是一种分析技术，用于近似像 $\\hat{p}$ 这样复杂的非线性估计量的方差。两个随机变量之比 $\\hat{Y}/\\hat{N}$ 的方差可以通过在真实总体总量 $(Y, N)$ 周围线性化函数 $f(\\hat{Y}, \\hat{N}) = \\hat{Y}/\\hat{N}$ 来近似。这得到：\n$$\nV(\\hat{p}) \\approx V\\left(\\frac{\\hat{Y}}{N} - \\frac{Y}{N^2}\\hat{N}\\right) = \\frac{1}{N^2} V(\\hat{Y} - p\\hat{N})\n$$\n其中 $p = Y/N$。为了形成一个估计量，我们用样本估计值代替总体参数。我们为每个整群定义一个“线性化变量”$u_i$，它代表该整群对分子方差的贡献：\n$$\nu_i \\;=\\; y_i - \\hat{p}\\,n_i\n$$\n该问题指定了在有放回抽样近似下 PSU 的方差估计量。在对 $m$ 个整群进行有放回简单随机抽样的情况下，样本总量 $\\sum_{i=1}^{m} t_i$ 的方差估计为 $m$ 乘以 $t_i$ 值的样本方差。由于 $\\sum u_i = 0$， $u_i$ 值的样本方差得以简化。线性化分子 $\\sum_{i=1}^{m} u_i$ 的方差估计为 $\\frac{m}{m-1}\\sum_{i=1}^{m} u_i^2$。除以估计的分母总量平方 $(\\sum_{i=1}^{m} n_i)^2$，得到 $\\hat{p}$ 的最终方差估计量：\n$$\n\\hat{V}_{\\text{lin}}(\\hat{p}) \\;=\\; \\frac{m}{m-1}\\,\\frac{\\sum_{i=1}^{m} u_i^2}{\\left(\\sum_{i=1}^{m} n_i\\right)^2}\n$$\n项 $\\frac{m}{m-1}$ 是来自简单随机样本的单个均值/总量的方差的无偏性校正因子。\n\n算法是：\na. 计算 $\\hat{p}$。\nb. 为每个整群 $i=1, \\dots, m$ 计算 $u_i$。\nc. 计算 $\\sum_{i=1}^{m} u_i^2$ 和 $\\sum_{i=1}^{m} n_i$。\nd. 将这些量代入 $\\hat{V}_{\\text{lin}}(\\hat{p})$ 的公式中。\n\n**3. 通过整群自助法进行方差估计**\n\n自助法是一种用于估计估计量方差的非参数计算方法。对于整群数据，关键是要重抽样整个整群（PSU），以保存在整群内部的相关性结构。过程如下：\n\na. 生成大量，即 $B$ 个，自助法重复样本。对于从 $1$ 到 $B$ 的每个重复样本 $b$：\n    i. 通过从原始的 $m$ 个 PSU 集合中有放回地抽取 $m$ 个 PSU 来创建一个自助法样本。这将产生一个包含 $m$ 个整群的新数据集，$\\{(n_{I_j^{(b)}}, y_{I_j^{(b)}})\\}_{j=1}^m$，其中每个索引 $I_j^{(b)}$ 都是从 $\\{1, \\dots, m\\}$ 中均匀抽取的。\n    ii. 为此自助法样本计算比例估计值 $\\hat{p}^{*(b)}$：\n    $$\n    \\hat{p}^{*(b)} \\;=\\; \\frac{\\sum_{j=1}^{m} y_{I^{(b)}_j}}{\\sum_{j=1}^{m} n_{I^{(b)}_j}}\n    $$\nb. 这 $B$ 个估计值的集合 $\\{\\hat{p}^{*(1)}, \\dots, \\hat{p}^{*(B)}\\}$ 构成了 $\\hat{p}$ 的一个经验抽样分布。自助法方差估计是这些重复估计值的样本方差：\n$$\n\\hat{V}_{\\text{boot}}(\\hat{p}) \\;=\\; \\frac{1}{B-1}\\sum_{b=1}^{B}\\left(\\hat{p}^{*(b)} - \\bar{\\hat{p}}^{*}\\right)^2, \\quad \\text{where } \\bar{\\hat{p}}^{*} = \\frac{1}{B}\\sum_{b=1}^{B}\\hat{p}^{*(b)}\n$$\n为确保随机抽样过程的可复现性，每个测试用例都使用一个特定的种子来初始化伪随机数生成器。\n\n该实现将处理每个测试用例，首先计算 $\\hat{p}$ 和 $\\hat{V}_{\\text{lin}}(\\hat{p})$。然后，它将使用给定的种子运行指定重复次数 $B$ 的自助法程序来计算 $\\hat{V}_{\\text{boot}}(\\hat{p})$。最后，它将按照规定格式化这三个结果值，四舍五入到 $6$ 位小数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes proportion and variance estimates for cluster-sampled data\n    using both bootstrap and linearization methods for specified test cases.\n    \"\"\"\n\n    # Define the datasets from the problem statement.\n    dataset_A = [\n        (85, 12), (73, 9), (120, 20), (64, 6), (95, 14), (102, 13),\n        (58, 5), (80, 10), (140, 25), (77, 8), (66, 7), (90, 11)\n    ]\n    dataset_B = [\n        (150, 28), (45, 2), (60, 4), (110, 15), (90, 8), (200, 35),\n        (30, 0), (75, 7)\n    ]\n    dataset_C = [\n        (40, 3), (55, 7), (35, 2)\n    ]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'dataset': dataset_A, 'B': 10000, 'seed': 12345},\n        {'dataset': dataset_A, 'B': 500, 'seed': 12345},\n        {'dataset': dataset_B, 'B': 10000, 'seed': 202311},\n        {'dataset': dataset_C, 'B': 10000, 'seed': 777}\n    ]\n\n    all_results_str = []\n    for case in test_cases:\n        dataset = case['dataset']\n        B = case['B']\n        seed = case['seed']\n\n        # Convert dataset to numpy arrays for efficient computation\n        data = np.array(dataset, dtype=np.float64)\n        n_i = data[:, 0]\n        y_i = data[:, 1]\n        m = len(n_i)\n\n        # 1. Estimate the proportion, p_hat\n        sum_y_i = np.sum(y_i)\n        sum_n_i = np.sum(n_i)\n        p_hat = sum_y_i / sum_n_i\n\n        # 2. Calculate linearization variance (V_lin)\n        u_i = y_i - p_hat * n_i\n        sum_u_i_sq = np.sum(u_i**2)\n        v_lin = (m / (m - 1.0)) * sum_u_i_sq / (sum_n_i**2)\n\n        # 3. Calculate bootstrap variance (V_boot)\n        rng = np.random.default_rng(seed)\n        p_hat_star_b = np.empty(B)\n        original_indices = np.arange(m)\n        \n        for b in range(B):\n            # Draw m indices with replacement\n            bootstrap_indices = rng.choice(original_indices, size=m, replace=True)\n            \n            # Create bootstrap sample of clusters\n            y_i_star = y_i[bootstrap_indices]\n            n_i_star = n_i[bootstrap_indices]\n            \n            # Calculate proportion for the bootstrap sample\n            # Handle potential division by zero if all sampled clusters have size 0\n            sum_n_i_star = np.sum(n_i_star)\n            if sum_n_i_star == 0:\n                # This is unlikely with the given data but is good practice.\n                # A proportion is ill-defined. Can be set to 0 or NaN.\n                # Given the problem's data, this branch is not hit.\n                p_hat_star_b[b] = 0.0\n            else:\n                p_hat_star_b[b] = np.sum(y_i_star) / sum_n_i_star\n        \n        # Compute the sample variance of the bootstrap estimates\n        # ddof=1 ensures division by (B-1)\n        v_boot = np.var(p_hat_star_b, ddof=1)\n        \n        # Round results to 6 decimal places\n        p_hat_rounded = round(p_hat, 6)\n        v_boot_rounded = round(v_boot, 6)\n        v_lin_rounded = round(v_lin, 6)\n        \n        result_list = [p_hat_rounded, v_boot_rounded, v_lin_rounded]\n        \n        # Format for final output string. Use .6f to ensure 6 decimal places printed.\n        str_list = [f'{val:.6f}' for val in result_list]\n        all_results_str.append(f\"[{','.join(str_list)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results_str)}]\")\n\nsolve()\n```"
        }
    ]
}