{
    "hands_on_practices": [
        {
            "introduction": "Before we can interpret the results of a repeated measures ANOVA, we must first understand its fundamental structure. This exercise  provides a hands-on look at the building blocks of the within-subjects $F$-test: the degrees of freedom. By working through a typical longitudinal study scenario, you will learn how the number of participants and time points are used to define the statistical test and its underlying assumptions, like sphericity.",
            "id": "4948291",
            "problem": "A longitudinal biomarker study measures a continuous outcome at $t=6$ equally spaced follow-up visits for each of $n=30$ participants, with no missing data. Consider a one-factor repeated measures analysis of variance with a fixed within-subject factor (time) and a subject blocking effect. Starting from the linear model representation and the identifiability constraints that define unique parameterization of subject and time effects, derive the number of independent contrasts for the time factor and for the residual term against which the time factor is tested in the within-subject $F$-test. Then, compute the numerical values of the numerator and denominator degrees of freedom for this $F$-test using $t=6$ and $n=30$.\n\nIn addition, articulate the distributional assumptions of normality and sphericity that justify the use of the standard within-subject $F$-test in this design, and explain qualitatively how a violation of sphericity leads to adjusted degrees of freedom via a correction factor. The final answer must consist only of the two degrees of freedom values, expressed without units. No rounding is required.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of biostatistics, specifically repeated measures analysis of variance (ANOVA). It is well-posed, providing all necessary data ($t=6$, $n=30$) for a unique solution, and is expressed in objective, formal language. We will proceed with the derivation and calculation.\n\nA one-way repeated measures ANOVA can be conceptualized using a linear model. For a study with $n$ subjects measured at $t$ time points, the observation $Y_{ij}$ for subject $i$ at time $j$ can be modeled as:\n$$Y_{ij} = \\mu + \\pi_i + \\tau_j + (\\pi\\tau)_{ij}$$\nwhere $i=1, 2, \\dots, n$ and $j=1, 2, \\dots, t$. In this model:\n- $\\mu$ is the overall grand mean.\n- $\\pi_i$ is the effect of subject $i$, which is unique to each individual and accounts for the baseline differences between subjects. It is treated as a random effect, representing a random sample from a population of subjects. The subjects serve as blocks.\n- $\\tau_j$ is the fixed effect of the $j$-th level of the within-subject factor, which in this case is time.\n- $(\\pi\\tau)_{ij}$ represents the interaction between subject $i$ and time $j$. This term captures how the effect of time might differ across subjects. In repeated measures ANOVA, this interaction is inseparable from random error and serves as the error term for testing the significance of the time effect.\n\nFor the model parameters to be uniquely identifiable, we impose sum-to-zero constraints. For the fixed time effects, the constraint is $\\sum_{j=1}^{t} \\tau_j = 0$. This constraint means that once $t-1$ of the $\\tau_j$ values are known, the last one is determined. Consequently, there are $t-1$ independent parameters associated with the time factor. The number of independent parameters corresponds to the degrees of freedom. Therefore, the number of independent contrasts for the time factor is $t-1$.\n\nThe total variability in the data is partitioned into between-subjects and within-subjects sources of variation. The within-subjects variation is further partitioned into variation due to the time factor and residual (or error) variation.\nThe degrees of freedom ($df$) for each source are as follows:\n- $df_{\\text{Between-Subjects}} = n-1$\n- $df_{\\text{Within-Subjects}} = n(t-1)$\n\nThe within-subjects degrees of freedom are then partitioned:\n- $df_{\\text{Time}} = t-1$\n- $df_{\\text{Residual}} = df_{\\text{Within-Subjects}} - df_{\\text{Time}} = n(t-1) - (t-1) = (n-1)(t-1)$\n\nThe residual term, $df_{\\text{Residual}}$, corresponds to the Subject $\\times$ Time interaction. It represents the $n-1$ subject degrees of freedom interacting with the $t-1$ time degrees of freedom. The number of independent contrasts for this residual term is therefore $(n-1)(t-1)$.\n\nThe $F$-test for the within-subject effect of time is the ratio of the mean square for time to the mean square for the residual (Subject $\\times$ Time interaction):\n$$F = \\frac{MS_{\\text{Time}}}{MS_{\\text{Residual}}} = \\frac{SS_{\\text{Time}} / df_{\\text{Time}}}{SS_{\\text{Residual}} / df_{\\text{Residual}}}$$\nThe numerator degrees of freedom for this test are $df_{\\text{num}} = df_{\\text{Time}}$, and the denominator degrees of freedom are $df_{\\text{den}} = df_{\\text{Residual}}$.\n\nUsing the provided values $t=6$ and $n=30$:\n- Numerator degrees of freedom: $df_{\\text{num}} = t-1 = 6-1 = 5$.\n- Denominator degrees of freedom: $df_{\\text{den}} = (n-1)(t-1) = (30-1)(6-1) = 29 \\times 5 = 145$.\n\nThe validity of this standard $F$-test depends on several assumptions. The critical assumptions for the within-subject test are:\n1.  **Independence of Subjects**: The observations for different subjects must be independent of one another. This is typically ensured by the study design (i.e., random sampling of participants).\n2.  **Multivariate Normality**: The dependent variable vector for each subject is assumed to be drawn from a multivariate normal distribution. This also implies that the differences between treatment levels are normally distributed.\n3.  **Sphericity (or Circularity)**: This assumption requires that the variances of the differences between all possible pairs of levels of the within-subject factor (time) are equal. Formally, for any two time points $j$ and $k$:\n    $$\\text{Var}(Y_{ij} - Y_{ik}) = \\text{constant}$$\n    Sphericity is a less strict condition than compound symmetry, which requires both homogeneity of variances at each time point and homogeneity of covariances between pairs of time points.\n\nA violation of the sphericity assumption is common in longitudinal studies where measurements closer in time tend to be more correlated than those further apart. When sphericity is violated, the denominator of the $F$-statistic, $MS_{\\text{Residual}}$, is, on average, too small. This inflates the $F$-ratio, leading to an increased probability of a Type I error (i.e., falsely rejecting the null hypothesis). The standard $F$-test becomes too liberal.\n\nTo address this, a correction is applied to the degrees of freedom. The correction involves estimating a parameter, $\\epsilon$ (epsilon), which quantifies the extent of the departure from sphericity. The value of $\\epsilon$ is bounded by $\\frac{1}{t-1} \\le \\epsilon \\le 1$. A value of $\\epsilon = 1$ indicates that the sphericity assumption holds perfectly. A value of $\\epsilon = \\frac{1}{t-1}$ indicates a maximal violation.\n\nThe original numerator and denominator degrees of freedom are multiplied by an estimate of $\\epsilon$ (e.g., the Greenhouse-Geisser $\\hat{\\epsilon}_{GG}$ or Huynh-Feldt $\\hat{\\epsilon}_{HF}$ estimate) to obtain adjusted degrees of freedom:\n- Adjusted $df_{\\text{num}} = \\hat{\\epsilon} (t-1)$\n- Adjusted $df_{\\text{den}} = \\hat{\\epsilon} (n-1)(t-1)$\n\nBy reducing the degrees of freedom, this correction increases the critical $F$-value required to achieve statistical significance, thereby yielding a more conservative test that effectively controls the Type I error rate at the desired level.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n5  145\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "The validity of the standard repeated measures ANOVA relies on the sphericity assumption, which requires that the variances of the differences between all pairs of time points are equal. This theoretical practice  clarifies this concept by connecting it to a simpler, more intuitive covariance structure known as compound symmetry. By mathematically demonstrating that compound symmetry is a sufficient condition for sphericity, you will gain a more robust conceptual grasp of this critical assumption.",
            "id": "4948310",
            "problem": "A clinical study tracks a continuous biomarker within the same participants across $t=5$ equally spaced visits. Let $\\mathbf{Y}_i=(Y_{i,1},Y_{i,2},Y_{i,3},Y_{i,4},Y_{i,5})^{\\top}$ denote the $5$-dimensional measurement vector for participant $i$. Suppose the within-subject covariance structure follows compound symmetry, meaning $\\operatorname{Var}(Y_{i,k})=\\sigma^{2}+\\tau^{2}$ for all $k \\in \\{1,2,3,4,5\\}$ and $\\operatorname{Cov}(Y_{i,k},Y_{i,\\ell})=\\tau^{2}$ for all $k \\neq \\ell$, with $\\sigma^{2} \\ge 0$ and $\\tau^{2} \\ge 0$. In repeated measures Analysis of Variance (ANOVA), the sphericity assumption requires that the variance of all pairwise differences among the $t$ levels is equal.\n\nStarting only from the core definitions of variance and covariance for linear combinations of random variables, compute the variance of a generic pairwise difference $Y_{i,k}-Y_{i,\\ell}$, for any distinct $k,\\ell \\in \\{1,2,3,4,5\\}$, under the stated compound symmetry structure. Then, use this computation to assess whether equality of pairwise difference variances (the sphericity requirement) can be satisfied for some $(\\sigma^{2},\\tau^{2})$ when $t=5$. Your final answer must be the simplified symbolic expression for the common variance of all such pairwise differences as a function of $\\sigma^{2}$ and $\\tau^{2}$. Do not provide any qualitative statements in the final answer; express only the single closed-form analytic expression.",
            "solution": "The problem requires the calculation of the variance of a generic pairwise difference between repeated measurements under a compound symmetry covariance structure, and an assessment of the sphericity condition. The validation of the problem statement is the mandatory first step.\n\nThe problem is determined to be valid. It is scientifically grounded in the statistical theory of repeated measures ANOVA, specifically concerning the concepts of compound symmetry and sphericity, which are well-defined in biostatistics. The problem is well-posed, providing all necessary information: the number of repeated measures $t=5$, the general form of the measurement vector $\\mathbf{Y}_i$, and the precise definitions of the variance and covariance components ($\\sigma^2+\\tau^2$ and $\\tau^2$, respectively) under the compound symmetry model. The constraints $\\sigma^2 \\ge 0$ and $\\tau^2 \\ge 0$ ensure a physically meaningful and mathematically sound covariance structure. The problem is objective, uses formal language, and leads to a unique, verifiable solution through direct application of statistical principles. It does not violate any of the criteria for invalidity.\n\nWe proceed with the solution. The core task is to compute $\\operatorname{Var}(Y_{i,k} - Y_{i,l})$ for any two distinct time points $k$ and $l$, where $k, l \\in \\{1, 2, 3, 4, 5\\}$ and $k \\neq l$.\n\nThe fundamental property for the variance of a linear combination of two random variables, say $A$ and $B$, is given by:\n$$\n\\operatorname{Var}(c_1 A + c_2 B) = c_1^2 \\operatorname{Var}(A) + c_2^2 \\operatorname{Var}(B) + 2c_1 c_2 \\operatorname{Cov}(A, B)\n$$\nwhere $c_1$ and $c_2$ are scalar constants.\n\nWe apply this formula to the pairwise difference $Y_{i,k} - Y_{i,l}$. In this context, $A = Y_{i,k}$, $B = Y_{i,l}$, $c_1 = 1$, and $c_2 = -1$. Substituting these into the general formula yields:\n$$\n\\operatorname{Var}(Y_{i,k} - Y_{i,l}) = (1)^2 \\operatorname{Var}(Y_{i,k}) + (-1)^2 \\operatorname{Var}(Y_{i,l}) + 2(1)(-1) \\operatorname{Cov}(Y_{i,k}, Y_{i,l})\n$$\nSimplifying this expression, we get:\n$$\n\\operatorname{Var}(Y_{i,k} - Y_{i,l}) = \\operatorname{Var}(Y_{i,k}) + \\operatorname{Var}(Y_{i,l}) - 2 \\operatorname{Cov}(Y_{i,k}, Y_{i,l})\n$$\nThe problem states that the covariance structure follows compound symmetry. The specific definitions provided are:\n1. The variance of any measurement is constant: $\\operatorname{Var}(Y_{i,k}) = \\sigma^2 + \\tau^2$ for all $k \\in \\{1, 2, 3, 4, 5\\}$.\n2. The covariance between any two distinct measurements is constant: $\\operatorname{Cov}(Y_{i,k}, Y_{i,l}) = \\tau^2$ for all $k \\neq l$.\n\nWe now substitute these compound symmetry definitions into the derived variance-of-a-difference formula. Since $k$ and $l$ are distinct, we have:\n$$\n\\operatorname{Var}(Y_{i,k}) = \\sigma^2 + \\tau^2\n$$\n$$\n\\operatorname{Var}(Y_{i,l}) = \\sigma^2 + \\tau^2\n$$\n$$\n\\operatorname{Cov}(Y_{i,k}, Y_{i,l}) = \\tau^2\n$$\nThe substitution yields:\n$$\n\\operatorname{Var}(Y_{i,k} - Y_{i,l}) = (\\sigma^2 + \\tau^2) + (\\sigma^2 + \\tau^2) - 2(\\tau^2)\n$$\nWe now perform algebraic simplification on this expression:\n$$\n\\operatorname{Var}(Y_{i,k} - Y_{i,l}) = 2\\sigma^2 + 2\\tau^2 - 2\\tau^2\n$$\n$$\n\\operatorname{Var}(Y_{i,k} - Y_{i,l}) = 2\\sigma^2\n$$\nThis result, $2\\sigma^2$, is the variance of the difference between measurements at any two distinct time points $k$ and $l$.\n\nThe second part of the problem is to assess whether the sphericity requirement can be satisfied. Sphericity requires that the variance of all pairwise differences among the levels is equal. Our derived expression for the variance of a generic pairwise difference, $2\\sigma^2$, is a constant that does not depend on the specific indices $k$ and $l$. Therefore, for any choice of distinct $k, l \\in \\{1, 2, 3, 4, 5\\}$, the variance of the difference $Y_{i,k} - Y_{i,l}$ is always equal to $2\\sigma^2$. This demonstrates that the sphericity condition is inherently satisfied by any covariance structure exhibiting compound symmetry, for any non-negative values of $\\sigma^2$ and $\\tau^2$.\n\nThe problem asks for the single closed-form analytic expression for the common variance of all such pairwise differences. This is the expression we have derived.",
            "answer": "$$\\boxed{2\\sigma^{2}}$$"
        },
        {
            "introduction": "In practice, the sphericity assumption is frequently violated, which increases the rate of Type I errors if ignored. This problem  transitions from theory to application by using a realistic scenario where a correction is needed. You will apply the widely used Greenhouse-Geisser correction to adjust the degrees of freedom and explore how this adjustment leads to a more conservative and reliable statistical conclusion.",
            "id": "4836009",
            "problem": "A longitudinal clinical trial investigates the effect of a novel antihypertensive treatment on systolic blood pressure trajectories across time. A total of $n=30$ patients are measured at $k=5$ prespecified clinic visits, yielding a within-subject factor with $k$ levels. The primary inferential target is the main effect of time in a univariate repeated measures analysis of variance (ANOVA), treating time as a within-subject factor. Assume the standard univariate repeated measures ANOVA model with subject-specific random intercepts, homoscedastic residuals, and the usual constraint on cell means, and recall that the uncorrected $F$ test for the within-subject time effect relies on the sphericity assumption concerning the covariance structure of repeated measures.\n\nSuppose Mauchly’s test provides strong evidence against sphericity, and the Greenhouse–Geisser (GG) sphericity correction factor is estimated as $\\hat{\\epsilon}_{\\mathrm{GG}}=0.6$. Starting from the fundamental definitions of degrees of freedom in univariate repeated measures ANOVA for a within-subject factor and the role of sphericity in the exact $F$ distribution, derive the Greenhouse–Geisser–adjusted numerator and denominator degrees of freedom for testing the time effect. Then, at a type I error rate of $\\alpha=0.05$, interpret qualitatively how these adjusted degrees of freedom will change the $F$ critical value relative to the uncorrected sphericity case.\n\nProvide the corrected degrees of freedom as a two-entry row matrix in the order numerator, denominator. If rounding were necessary, round to four significant figures; however, report exact values when available. Do not include any units in your final answer.",
            "solution": "The problem statement is deemed valid as it is scientifically grounded, well-posed, objective, and provides a self-contained and consistent set of parameters for a standard statistical procedure.\n\nThe problem asks for the derivation of the Greenhouse–Geisser (GG) adjusted degrees of freedom for the main effect of a within-subject factor in a repeated measures ANOVA and a qualitative interpretation of the effect of this adjustment on the critical value of the F-test.\n\nFirst, we establish the standard (uncorrected) degrees of freedom for the F-test of the within-subject factor, which is 'time' in this clinical trial context. Let $n$ be the number of subjects and $k$ be the number of repeated measures (levels of the within-subject factor).\nThe provided values are $n=30$ and $k=5$.\n\nIn a one-way repeated measures ANOVA, the F-statistic for the within-subject effect is constructed as the ratio of the mean square for the factor (time) to the mean square for the error (time $\\times$ subject interaction). The degrees of freedom for this F-statistic, under the assumption of sphericity, are:\nThe numerator degrees of freedom, $df_{\\text{num}}$, correspond to the main effect of time:\n$$df_{\\text{num}} = k - 1$$\nThe denominator degrees of freedom, $df_{\\text{den}}$, correspond to the interaction between time and subjects, which serves as the error term:\n$$df_{\\text{den}} = (k - 1)(n - 1)$$\n\nSubstituting the given values:\n$$df_{\\text{num}} = 5 - 1 = 4$$\n$$df_{\\text{den}} = (5 - 1)(30 - 1) = 4 \\times 29 = 116$$\nThus, under the sphericity assumption, the test statistic follows an $F$ distribution with $4$ and $116$ degrees of freedom, denoted as $F(4, 116)$.\n\nThe problem states that Mauchly’s test provides strong evidence against sphericity. When the sphericity assumption is violated, the Type I error rate of the uncorrected F-test is inflated. To control for this inflation, a correction is applied to the degrees of freedom. The F-statistic itself remains unchanged, but it is compared to a critical value from an F-distribution with adjusted degrees of freedom.\n\nThe Greenhouse–Geisser correction involves multiplying both the numerator and denominator degrees of freedom by an estimate of the sphericity parameter, $\\epsilon$. The value of $\\epsilon$ ranges from $\\frac{1}{k-1}$ (for maximal violation of sphericity) to $1$ (for perfect sphericity). The problem provides the Greenhouse–Geisser estimate, $\\hat{\\epsilon}_{\\mathrm{GG}} = 0.6$.\n\nThe adjusted degrees of freedom, denoted $df'_{\\text{num}}$ and $df'_{\\text{den}}$, are calculated as follows:\n$$df'_{\\text{num}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times df_{\\text{num}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times (k - 1)$$\n$$df'_{\\text{den}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times df_{\\text{den}} = \\hat{\\epsilon}_{\\mathrm{GG}} \\times (k - 1)(n - 1)$$\n\nUsing the given values $\\hat{\\epsilon}_{\\mathrm{GG}} = 0.6$, $k=5$, and $n=30$:\n$$df'_{\\text{num}} = 0.6 \\times (5 - 1) = 0.6 \\times 4 = 2.4$$\n$$df'_{\\text{den}} = 0.6 \\times (5 - 1)(30 - 1) = 0.6 \\times 4 \\times 29 = 2.4 \\times 29 = 69.6$$\nThese are the Greenhouse–Geisser–adjusted numerator and denominator degrees of freedom for the test of the time effect.\n\nNext, we interpret qualitatively how these adjusted degrees of freedom affect the F critical value. The critical value for the test, $F_{\\text{crit}}$, is the value from the F-distribution that cuts off the upper $\\alpha$ proportion of the area. For a given significance level $\\alpha=0.05$, the critical value is a function of the numerator and denominator degrees of freedom.\n\nUncorrected case: $F_{\\text{crit, uncorrected}} = F_{1-\\alpha}(df_{\\text{num}}, df_{\\text{den}}) = F_{0.95}(4, 116)$\nCorrected case: $F_{\\text{crit, corrected}} = F_{1-\\alpha}(df'_{\\text{num}}, df'_{\\text{den}}) = F_{0.95}(2.4, 69.6)$\n\nThe Greenhouse-Geisser correction, by its nature (since $\\hat{\\epsilon}_{\\mathrm{GG}}  1$), reduces both the numerator and denominator degrees of freedom. A reduction in degrees of freedom causes the probability density function of the F-distribution to become more spread out (more platykurtic) and shifts the mass towards the right tail. Consequently, to maintain the same tail area $\\alpha$, the critical value must be larger.\n\nTherefore, $F_{\\text{crit, corrected}}  F_{\\text{crit, uncorrected}}$. This increase in the critical value makes the test more conservative, meaning a larger observed F-statistic is required to reject the null hypothesis. This conservativeness is the desired outcome, as it corrects the inflated Type I error rate that occurs when using the uncorrected degrees of freedom in the presence of a sphericity violation.\n\nThe final answer requires the corrected degrees of freedom as a two-entry row matrix. These are the calculated values $df'_{\\text{num}} = 2.4$ and $df'_{\\text{den}} = 69.6$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.4  69.6\n\\end{pmatrix}\n}\n$$"
        }
    ]
}