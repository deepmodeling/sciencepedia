{
    "hands_on_practices": [
        {
            "introduction": "理论付诸实践是掌握知识的关键。在本节中，我们将通过一个具体的模拟研究，亲手揭示偏差-方差权衡的奥秘。我们将比较一个简单模型和一个复杂模型在拟合含噪声数据时的表现，并利用交叉验证来评估它们的真实泛化能力，从而直观地理解过拟合现象。",
            "id": "4897610",
            "problem": "您的任务是设计并实现一个完整的模拟研究，该研究旨在使用多项式回归模型，在一个真实的数据生成机制下，揭示偏差-方差权衡，并使用交叉验证（CV）来估计预期测试误差。目标是构建这样的场景：一个拥有更多参数的模型获得了更低的训练误差，但预期测试误差却更差，并证明这种行为是由显式方差项的增加所驱动的。\n\n基本基础和设置：\n- 设预测变量为一个实值协变量 $x \\in [-1,1]$，其分布为 $x \\sim \\mathrm{Uniform}([-1,1])$。\n- 设响应变量由 $y = f(x) + \\epsilon$ 生成，其中 $f(x)$ 是一个确定性函数，$\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 是方差为 $\\sigma^2$ 的独立噪声。\n- 定义真实信号 $f(x)$ 为 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$，其中 $\\alpha$ 和 $\\beta$ 是固定的实数常量。\n- 考虑 $d$ 次（包括截距项）的多项式回归模型，该模型通过对训练数据进行最小二乘估计来估算函数 $\\hat{f}_d(x)$。“简单”模型使用次数 $d_s$，“复杂”模型使用次数 $d_c$，且 $d_c > d_s$。\n\n使用的核心定义：\n- 对于一个大小为 $n$ 的训练数据集，训练均方误差 (MSE) 为 $\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i - \\hat{f}(x_i)\\right)^2$。\n- 预期测试MSE的 $K$ 折交叉验证估计量是，通过划分训练数据集形成的 $K$ 个折中，所有留出折的MSE的平均值。\n- 在数据生成模型 $y = f(x) + \\epsilon$ 下，一个固定点 $x$ 的偏差-方差分解为\n$$\n\\mathbb{E}\\left[(\\hat{f}(x) - y)^2\\right] = \\left(\\mathbb{E}[\\hat{f}(x)] - f(x)\\right)^2 + \\mathrm{Var}(\\hat{f}(x)) + \\sigma^2,\n$$\n其中期望和方差是针对训练样本中的随机性（以及适用时的 $\\epsilon$）计算的。在此模拟中，您将通过蒙特卡洛重复实验来显式估计方差项 $\\mathrm{Var}(\\hat{f}(x))$。\n\n任务要求：\n1. 对于每个指定的测试用例，根据 $x \\sim \\mathrm{Uniform}([-1,1])$ 和 $y = f(x) + \\epsilon$（其中 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$ 固定）生成 $B$ 个大小为 $n$ 的独立训练数据集。使用 $\\alpha = 1.5$ 和 $\\beta = 0.5$。\n2. 对于每个数据集和每个模型次数 $d \\in \\{d_s, d_c\\}$：\n   - 拟合次数为 $d$ 的最小二乘多项式模型。\n   - 计算训练MSE。\n   - 计算 $K$ 折交叉验证MSE，其中 $K=5$ 折。\n3. 为了估计每个次数 $d$ 的方差项 $\\mathrm{Var}(\\hat{f}(x))$，构建一个覆盖 $[-1,1]$ 的包含 $m$ 个点的固定网格 $\\{x_j\\}_{j=1}^m$，为每次蒙特卡洛重复实验 $b \\in \\{1,\\dots,B\\}$ 计算 $\\hat{f}_d^{(b)}(x_j)$，然后通过重复实验间的样本方差来估计 $\\mathrm{Var}(\\hat{f}(x_j))$。将这些方差在网格上平均，以获得单一的标量摘要\n$$\nV_d = \\frac{1}{m} \\sum_{j=1}^m \\widehat{\\mathrm{Var}}\\left(\\hat{f}_d(x_j)\\right).\n$$\n4. 对于每个测试用例，聚合 $B$ 次重复实验的结果以计算：\n   - 简单模型和复杂模型的平均训练MSE。\n   - 简单模型和复杂模型的平均 $K$ 折CV MSE。\n   - 方差摘要 $V_{d_s}$ 和 $V_{d_c}$。\n5. 定义一个测试用例的过拟合表现指标，如果以下所有三个条件都成立，则为 $1$ (true)，否则为 $0$ (false)：\n   - 复杂模型的平均训练MSE严格小于简单模型的平均训练MSE。\n   - 复杂模型的平均 $K$ 折CV MSE严格大于简单模型的平均CV MSE。\n   - 方差摘要 $V_{d_c}$ 严格大于 $V_{d_s}$。\n\n参数值（测试套件）：\n- 使用 $B = 200$ 和 $m = 201$ 个网格点。\n- 使用 $K = 5$ 折。\n- 使用以下三个测试用例，它们共同探讨了一个通用场景、一个大样本边界和一个无噪声边缘案例：\n  1. 案例 A (happy path)：$n = 60$, $\\sigma = 0.5$, $d_s = 3$, $d_c = 18$。\n  2. 案例 B (large sample boundary)：$n = 400$, $\\sigma = 0.5$, $d_s = 3$, $d_c = 18$。\n  3. 案例 C (noise-free edge case)：$n = 60$, $\\sigma = 0$, $d_s = 3$, $d_c = 18$。\n\n要求的最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[result1,result2,result3]$），其中每个 $resultk$ 是第 $k$ 个测试用例的整数 $0$ 或 $1$，根据上述指标进行评估。不应打印其他输出或文本。",
            "solution": "该问题提出了一个在生物统计学领域内有效且定义明确的模拟研究，旨在通过多项式回归来探究偏差-方差权衡。所有参数和步骤都定义清晰，科学上基于已建立的统计学原理，并且在计算上是可行的。该问题客观且无歧义，满足所有验证标准。\n\n任务的核心是根据一个已知的真实函数来模拟数据，拟合不同复杂度的模型，并评估它们的性能以说明过拟合的概念。模拟框架定义如下：\n\n数据生成过程基于一个从区间 $[-1, 1]$ 均匀采样的预测变量 $x$，即 $x \\sim \\mathrm{Uniform}([-1,1])$。相应的响应变量 $y$ 由模型 $y = f(x) + \\epsilon$ 生成，其中 $f(x)$ 是确定性的真实信号，而 $\\epsilon$ 是一个随机噪声项。信号由函数 $f(x) = \\alpha \\sin(\\pi x) + \\beta x$ 给出，其中指定了常数 $\\alpha = 1.5$ 和 $\\beta = 0.5$。噪声遵循正态分布 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2)$，其方差 $\\sigma^2$ 是模拟的参数之一。\n\n我们比较两个模型：一个次数为 $d_s$ 的“简单”多项式回归模型和一个次数为 $d_c$ 的“复杂”模型，其中 $d_c > d_s$。对于每个大小为 $n$ 的训练数据集，我们通过最小化残差平方和（普通最小二乘法）来拟合模型 $\\hat{f}_{d_s}(x)$ 和 $\\hat{f}_{d_c}(x)$。\n\n对于提供的三个测试用例中的每一个，模拟协议都执行 $B=200$ 次蒙特卡洛重复实验。每次重复实验包括以下步骤：\n1.  **数据生成**：根据指定的数据生成过程，创建一个新的大小为 $n$ 的训练数据集 $\\{(x_i, y_i)\\}_{i=1}^n$。\n2.  **模型拟合与评估**：对于每个次数 $d \\in \\{d_s, d_c\\}$：\n    -   将多项式模型 $\\hat{f}_d(x)$ 拟合到训练数据上。\n    -   计算**训练均方误差 (MSE)**，即 $\\mathrm{MSE}_{\\text{train}} = \\frac{1}{n}\\sum_{i=1}^{n}\\left(y_i - \\hat{f}_d(x_i)\\right)^2$。这衡量了模型对其训练数据的拟合程度。\n    -   使用 **$K$ 折交叉验证 (CV)**（其中 $K=5$）来估计预期测试 MSE。训练集被划分为 $K$ 个不相交的子集（折）。对于每一折，在其余的 $K-1$ 折上训练一个模型，并在留出的那一折上进行测试。CV 误差 $\\mathrm{MSE}_{\\text{CV}}$ 是这 $K$ 个验证折的 MSE 的平均值。该指标为模型在未见数据上的泛化性能提供了一个更稳健的估计。\n\n3.  **显式方差估计**：模型本身的方差是偏差-方差权衡中的一个关键组成部分。我们通过蒙特卡洛模拟直接估计它。在定义域 $[-1,1]$ 上建立一个包含 $m=201$ 个点的固定网格 $\\{x_j\\}_{j=1}^m$。对于每次重复实验 $b$ 和每个模型次数 $d$，我们计算此网格上的预测值 $\\hat{f}_d^{(b)}(x_j)$。在某一点 $x_j$ 上的估计量方差，通过该点上所有 $B$ 次重复实验的预测值的样本方差来估计。然后，通过在整个网格上平均这些逐点方差估计值，计算出模型方差的单一标量摘要 $V_d$：$V_d = \\frac{1}{m} \\sum_{j=1}^m \\widehat{\\mathrm{Var}}\\left(\\hat{f}_d(x_j)\\right)$。\n\n在所有 $B$ 次重复实验完成后，对收集到的指标进行平均，从而为简单模型和复杂模型分别得出 $\\overline{\\mathrm{MSE}}_{\\text{train}}$、$\\overline{\\mathrm{MSE}}_{\\text{CV}}$ 和聚合方差项 $V_d$。\n\n最后，为每个测试用例计算一个**过拟合表现指标**。当且仅当以下所有三个条件同时满足时，此二元指标设置为 $1$ (true)，否则为 $0$ (false)：\n1.  $\\overline{\\mathrm{MSE}}_{\\text{train}, d_c} < \\overline{\\mathrm{MSE}}_{\\text{train}, d_s}$：复杂模型在训练数据上实现了更低的误差。\n2.  $\\overline{\\mathrm{MSE}}_{\\text{CV}, d_c} > \\overline{\\mathrm{MSE}}_{\\text{CV}, d_s}$：复杂模型表现出更高的估计测试误差，表明泛化能力差（过拟合）。\n3.  $V_{d_c} > V_{d_s}$：复杂模型比简单模型更不稳定（方差更大）。\n\n这种结构化的分析被应用于三个不同的测试用例，以探究模型在不同样本量和噪声水平条件下的行为。实现将通过系统地执行此模拟设计并报告生成的指标值列表来进行。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Runs a simulation study to demonstrate the bias-variance tradeoff\n    and computes an overfitting indicator for three test cases.\n    \"\"\"\n    # Set a random seed for reproducibility of the simulation results.\n    np.random.seed(42)\n\n    # --- Simulation parameters from the problem statement ---\n    B = 200      # Number of Monte Carlo replicates\n    m = 201      # Number of grid points for variance estimation\n    K = 5        # Number of folds for cross-validation\n    alpha = 1.5  # Parameter for the true function f(x)\n    beta = 0.5   # Parameter for the true function f(x)\n\n    # Test cases: (n, sigma, d_s, d_c)\n    test_cases = [\n        (60, 0.5, 3, 18),   # Case A: Canonical overfitting scenario\n        (400, 0.5, 3, 18),  # Case B: Large sample size scenario\n        (60, 0.0, 3, 18),   # Case C: Noise-free scenario\n    ]\n\n    def calculate_cv_mse(x, y, d, k_folds):\n        \"\"\"\n        Calculates the K-fold cross-validation MSE for a polynomial model.\n        \"\"\"\n        fold_mses = []\n        n_samples = len(x)\n        indices = np.arange(n_samples)\n        \n        # Shuffle indices to ensure random distribution of data across folds.\n        np.random.shuffle(indices)\n        \n        # Split indices into k_folds.\n        fold_indices = np.array_split(indices, k_folds)\n\n        for k in range(k_folds):\n            val_idx = fold_indices[k]\n            train_idx = np.concatenate([fold_indices[i] for i in range(k_folds) if i != k])\n\n            x_fold_train, y_fold_train = x[train_idx], y[train_idx]\n            x_fold_val, y_fold_val = x[val_idx], y[val_idx]\n\n            # Fit model on the training part of the fold.\n            # numpy might issue a RankWarning for high-degree polynomials, \n            # which is expected and can be ignored for this problem.\n            coeffs = np.polyfit(x_fold_train, y_fold_train, d)\n            \n            # Predict on the validation part.\n            y_pred_val = np.polyval(coeffs, x_fold_val)\n\n            # Calculate and store MSE for the fold.\n            fold_mse = np.mean((y_fold_val - y_pred_val)**2)\n            fold_mses.append(fold_mse)\n        \n        return np.mean(fold_mses)\n\n    final_results = []\n\n    for case in test_cases:\n        n, sigma, d_s, d_c = case\n\n        # Accumulators for metrics over B replicates\n        train_mses_s, train_mses_c = [], []\n        cv_mses_s, cv_mses_c = [], []\n        \n        # Grid for variance estimation\n        grid = np.linspace(-1, 1, m)\n        \n        # Storage for predictions on the grid across all replicates\n        all_preds_s = np.zeros((B, m))\n        all_preds_c = np.zeros((B, m))\n\n        for b in range(B):\n            # 1. Generate data for the current replicate\n            x_train = np.random.uniform(-1, 1, n)\n            y_true = alpha * np.sin(np.pi * x_train) + beta * x_train\n            if sigma > 0:\n                noise = np.random.normal(0, sigma, n)\n                y_train = y_true + noise\n            else:\n                y_train = y_true\n\n            # 2. Process simple model (degree d_s)\n            coeffs_s = np.polyfit(x_train, y_train, d_s)\n            y_pred_train_s = np.polyval(coeffs_s, x_train)\n            train_mses_s.append(np.mean((y_train - y_pred_train_s)**2))\n            cv_mses_s.append(calculate_cv_mse(x_train, y_train, d_s, K))\n            all_preds_s[b, :] = np.polyval(coeffs_s, grid)\n\n            # 3. Process complex model (degree d_c)\n            coeffs_c = np.polyfit(x_train, y_train, d_c)\n            y_pred_train_c = np.polyval(coeffs_c, x_train)\n            train_mses_c.append(np.mean((y_train - y_pred_train_c)**2))\n            cv_mses_c.append(calculate_cv_mse(x_train, y_train, d_c, K))\n            all_preds_c[b, :] = np.polyval(coeffs_c, grid)\n\n        # 4. Aggregate results across B replicates\n        avg_train_mse_s = np.mean(train_mses_s)\n        avg_train_mse_c = np.mean(train_mses_c)\n        avg_cv_mse_s = np.mean(cv_mses_s)\n        avg_cv_mse_c = np.mean(cv_mses_c)\n\n        # Calculate variance summary V_d using sample variance (ddof=1)\n        V_s = np.mean(np.var(all_preds_s, axis=0, ddof=1))\n        V_c = np.mean(np.var(all_preds_c, axis=0, ddof=1))\n        \n        # 5. Apply the overfitting manifestation indicator logic\n        cond1 = avg_train_mse_c < avg_train_mse_s\n        cond2 = avg_cv_mse_c > avg_cv_mse_s\n        cond3 = V_c > V_s\n        \n        indicator = 1 if (cond1 and cond2 and cond3) else 0\n        final_results.append(indicator)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "掌握了如何使用交叉验证来估计模型误差后，我们必须学会正确地使用它，以避免常见的陷阱。“数据泄漏”是一个尤其危险的错误，它指的是测试集的信息无意中“泄漏”到了模型训练过程中。本练习将探讨一个典型的数据泄漏场景：在交叉验证之前，使用整个数据集进行特征选择，这会导致对模型性能的评估过于乐观。",
            "id": "4897575",
            "problem": "一个生物统计学团队正在评估一个线性预测器，用于预测一个标准化的定量表型。对于每个受试者 $i \\in \\{1,\\dots,n\\}$ 和每个生物标志物 $j \\in \\{1,\\dots,p\\}$，假设在没有真实关联的零模型下，数据生成过程如下：\n- $y_i \\sim \\mathcal{N}(0,1)$ 在 $i$ 上独立同分布。\n- $x_{ij} \\sim \\mathcal{N}(0,1)$ 在 $i$ 和 $j$ 上独立同分布，且独立于 $y_i$。\n\n他们在模型评估前，错误地使用完整数据集进行特征选择，步骤如下。\n- 步骤 $1$（在完整数据上进行泄露的特征选择）：对完整数据集上的每个生物标志物 $j$ 计算样本相关性 $r_j = \\frac{1}{n}\\sum_{i=1}^{n} x_{ij} y_i$，并选择具有最大绝对相关性的单个生物标志物 $j^{\\star}$，即 $j^{\\star} \\in \\arg\\max_{1 \\leq j \\leq p} |r_j|$。\n- 步骤 $2$（通过交叉验证重用所选特征进行评估）：通过留一法交叉验证（LOOCV）估计均方预测误差，在每一折中对大小为 $n-1$ 的训练集重新拟合不带截距的普通最小二乘法，以为固定的生物标志物 $x_{ij^{\\star}}$ 获得系数 $\\hat{\\beta}_{(-i)}$，并为留出的受试者 $i$ 预测 $\\hat{y}_i = \\hat{\\beta}_{(-i)} x_{ij^{\\star}}$。\n\n令 $\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}$ 表示上述易泄露程序产生的均方误差的LOOCV估计值，令 $\\mathrm{MSE}_{\\mathrm{test}}$ 表示当该程序在 $n$ 个观测值上训练后应用于新的独立受试者时的真实期望均方预测误差（仍然使用如上所述在全部 $n$ 个训练观测值上选择的特征 $j^{\\star}$）。定义偏差\n$$\nB(n,p) \\equiv \\mathbb{E}\\!\\left[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}\\right] \\;-\\; \\mathbb{E}\\!\\left[\\mathrm{MSE}_{\\mathrm{test}}\\right].\n$$\n\n假设 $n$ 很大，$p$ 可能随 $n$ 增长且满足 $\\ln p = o(n)$，并忽略所有比 $\\frac{\\ln p}{n}$ 低阶的项。从基本定义和标准大样本近似出发，推导在所述零模型下 $B(n,p)$ 作为 $n$ 和 $p$ 的函数的领头阶渐近表达式。请以单个闭式解析表达式的形式提供您的答案。不需要四舍五入，也不需要单位。",
            "solution": "用户希望找到偏差 $B(n,p) = \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] - \\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]$ 的领头阶渐近表达式。我们将分别推导这两个期望的表达式，然后计算它们的差值。\n\n### 步骤 1：初步定义与近似\n\n设 $X$ 是生物标志物数据的 $n \\times p$ 矩阵，$y$ 是表型数据的 $n \\times 1$ 向量。元素 $x_{ij}$ 和 $y_i$ 是独立同分布的 $\\mathcal{N}(0,1)$。\n生物标志物 $j$ 的样本相关性为 $r_j = \\frac{1}{n}\\sum_{i=1}^{n} x_{ij} y_i$。令 $C_j = \\sum_{i=1}^{n} x_{ij} y_i = n r_j$。\n预测变量 $j$ 的平方和为 $S_j = \\sum_{i=1}^{n} x_{ij}^2$。根据大数定律，当 $n$ 很大时，$S_j/n \\to \\mathbb{E}[x_{ij}^2] = 1$。我们将使用近似 $S_j \\approx n$。这对所有 $j$ 都成立，包括被选中的 $j^{\\star}$。\n特征选择规则是 $j^{\\star} = \\arg\\max_{1 \\leq j \\leq p} |r_j| = \\arg\\max_{1 \\leq j \\leq p} |C_j|$。\n\n为了分析选择过程，我们定义归一化变量 $\\tilde{r}_j = C_j / \\sqrt{S_j}$。在给定 $X$ 的条件下，每个 $\\tilde{r}_j$ 都是独立同分布的标准正态变量 $y_i$ 的线性组合：$\\tilde{r}_j = \\sum_i (x_{ij}/\\sqrt{S_j}) y_i$。因此，$\\mathbb{E}[\\tilde{r}_j|X] = 0$ 且 $\\mathrm{Var}(\\tilde{r}_j|X) = \\sum_i (x_{ij}/\\sqrt{S_j})^2 \\mathrm{Var}(y_i) = S_j/S_j = 1$。所以，$\\tilde{r}_j | X \\sim \\mathcal{N}(0,1)$。\n协方差为 $\\mathrm{Cov}(\\tilde{r}_j, \\tilde{r}_k|X) = \\frac{\\sum_i x_{ij}x_{ik}}{\\sqrt{S_j S_k}}$，当 $n$ 很大时，对于 $j \\neq k$，该值收敛于 $0$。因此，对于大 $n$，变量 $\\{\\tilde{r}_j\\}_{j=1}^p$ 可以被视为独立同分布的 $\\mathcal{N}(0,1)$ 随机变量。\n\n选择规则 $j^{\\star} = \\arg\\max_j |C_j| = \\arg\\max_j |\\sqrt{S_j} \\tilde{r}_j|$ 近似等价于 $j^{\\star} \\approx \\arg\\max_j |\\tilde{r}_j|$，因为对于所有 $j$ 都有 $S_j \\approx n$。令 $M_p^2 = \\max_{1 \\leq j \\leq p} \\tilde{r}_j^2$。对于大 $p$，$p$ 个独立同分布的 $\\chi^2(1)$ 变量的最大值的期望可以很好地近似为 $\\mathbb{E}[M_p^2] \\approx 2 \\ln p$。\n\n### 步骤 2：推导 $\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]$\n\n真实测试误差 $\\mathrm{MSE}_{\\text{test}}$ 是对于一个从相同分布中抽取且独立于训练数据的新受试者 $(x_{\\text{new}}, y_{\\text{new}})$ 的期望平方预测误差。预测值为 $\\hat{y}_{\\text{new}} = \\hat{\\beta} x_{\\text{new}, j^{\\star}}$，其中 $\\hat{\\beta}$ 是从大小为 $n$ 的完整训练集中估计出的 OLS 系数。\n$$\n\\mathrm{MSE}_{\\text{test}} = \\mathbb{E}_{\\text{new}}[(y_{\\text{new}} - \\hat{\\beta} x_{\\text{new}, j^{\\star}})^2 | X, y]\n$$\n展开此式并利用新受试者的独立性（$\\mathbb{E}[y_{\\text{new}}] = 0$，$\\mathbb{E}[y_{\\text{new}}^2]=1$，$\\mathbb{E}[x_{\\text{new}, j^{\\star}}^2]=1$）：\n$$\n\\mathrm{MSE}_{\\text{test}} = \\mathbb{E}_{\\text{new}}[y_{\\text{new}}^2] - 2\\hat{\\beta}\\mathbb{E}_{\\text{new}}[y_{\\text{new}}x_{\\text{new}, j^{\\star}}] + \\hat{\\beta}^2\\mathbb{E}_{\\text{new}}[x_{\\text{new}, j^{\\star}}^2] = 1 - 0 + \\hat{\\beta}^2 = 1 + \\hat{\\beta}^2\n$$\n不含截距的 OLS 估计为 $\\hat{\\beta} = \\frac{\\sum_i x_{ij^{\\star}}y_i}{\\sum_i x_{ij^{\\star}}^2} = \\frac{C_{j^{\\star}}}{S_{j^{\\star}}}$。\n因此，$\\mathrm{MSE}_{\\text{test}} = 1 + \\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}^2}$。\n我们需要计算关于训练数据分布的期望：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] = 1 + \\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}^2}\\right]\n$$\n使用近似 $S_{j^{\\star}} \\approx n$：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] \\approx 1 + \\frac{1}{n^2}\\mathbb{E}[C_{j^{\\star}}^2]\n$$\n我们有 $C_{j^{\\star}} = \\sqrt{S_{j^{\\star}}} \\tilde{r}_{j^{\\star}}$，其中 $|\\tilde{r}_{j^{\\star}}|^2 \\approx M_p^2$。\n所以，$\\mathbb{E}[C_{j^{\\star}}^2] = \\mathbb{E}[S_{j^{\\star}} \\tilde{r}_{j^{\\star}}^2] \\approx \\mathbb{E}[S_{j^{\\star}}] \\mathbb{E}[\\tilde{r}_{j^{\\star}}^2] \\approx n \\mathbb{E}[M_p^2]$。\n使用 $\\mathbb{E}[M_p^2] \\approx 2 \\ln p$，我们得到 $\\mathbb{E}[C_{j^{\\star}}^2] \\approx 2n \\ln p$。\n将此代入期望测试误差的表达式中：\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\text{test}}] \\approx 1 + \\frac{1}{n^2}(2n \\ln p) = 1 + \\frac{2 \\ln p}{n}\n$$\n\n### 步骤 3：推导 $\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}]$\n\nLOOCV 误差估计为 $\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} = \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$，其中 $\\hat{y}_i = \\hat{\\beta}_{(-i)} x_{ij^{\\star}}$。\nOLS 的一个标准结果将 LOOCV 残差与完整模型拟合的残差联系起来。对于无截距模型，该恒等式为：\n$$\ny_i - \\hat{y}_i = \\frac{y_i - \\hat{\\beta} x_{ij^{\\star}}}{1 - h_{ii}}\n$$\n其中 $h_{ii}$ 是帽子矩阵 $H = x_{j^{\\star}}(x_{j^{\\star}}^Tx_{j^{\\star}})^{-1}x_{j^{\\star}}^T$ 的第 $i$ 个对角元素。\n$h_{ii} = \\frac{x_{ij^{\\star}}^2}{\\sum_{k=1}^n x_{kj^{\\star}}^2} = \\frac{x_{ij^{\\star}}^2}{S_{j^{\\star}}}$。\n对于大 $n$，$S_{j^{\\star}} \\approx n$，因此 $h_{ii} = O_p(1/n)$。\nLOOCV 估计可以写为：\n$$\n\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{(y_i - \\hat{\\beta}x_{ij^{\\star}})^2}{(1-h_{ii})^2}\n$$\n令 $\\widehat{\\mathrm{MSE}}_{\\text{in}} = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{\\beta}x_{ij^{\\star}})^2$ 为样本内（训练）MSE。使用展开式 $(1-h_{ii})^{-2} = 1 + 2h_{ii} + O_p(h_{ii}^2)$：\n$$\n\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}} \\approx \\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\hat{\\beta}x_{ij^{\\star}})^2(1+2h_{ii}) = \\widehat{\\mathrm{MSE}}_{\\text{in}} + \\frac{2}{n}\\sum_{i=1}^{n} (y_i - \\hat{\\beta}x_{ij^{\\star}})^2 h_{ii}\n$$\n首先，我们计算样本内 MSE 的期望：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] = \\mathbb{E}\\left[\\frac{1}{n}\\sum_i(y_i - \\hat{\\beta}x_{ij^{\\star}})^2\\right] = \\frac{1}{n}\\mathbb{E}\\left[\\sum_i y_i^2 - \\hat{\\beta}^2 S_{j^{\\star}}\\right]\n$$\n这里使用了 OLS 残差的正交性。$\\mathbb{E}[\\sum y_i^2]=n$。\n$\\hat{\\beta}^2 S_{j^{\\star}} = (\\frac{C_{j^{\\star}}}{S_{j^{\\star}}})^2 S_{j^{\\star}} = \\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}$。\n$\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] = \\frac{1}{n}\\left(n - \\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}\\right]\\right) = 1 - \\frac{1}{n}\\mathbb{E}\\left[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}\\right]$。\n如前所述，$\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}} \\approx M_p^2$，因此 $\\mathbb{E}[\\frac{C_{j^{\\star}}^2}{S_{j^{\\star}}}] \\approx 2 \\ln p$。\n因此，期望的样本内误差是高度乐观的：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] \\approx 1 - \\frac{2 \\ln p}{n}\n$$\n接下来，考虑修正项 $\\frac{2}{n}\\mathbb{E}[\\sum_i (y_i - \\hat{\\beta}x_{ij^{\\star}})^2 h_{ii}]$。\n根据对称性，这等于 $2\\mathbb{E}[(y_1 - \\hat{\\beta}x_{1j^{\\star}})^2 h_{11}]$。\n$h_{11} = x_{1j^{\\star}}^2/S_{j^{\\star}} \\approx x_{1j^{\\star}}^2/n$。该项为 $\\frac{2}{n}\\mathbb{E}[(y_1 - \\hat{\\beta}x_{1j^{\\star}})^2 x_{1j^{\\star}}^2]$。\n对于大 $n$，$\\hat{\\beta} = O_p(\\sqrt{\\ln p / n})$，它趋向于 $0$。因此，$y_1 - \\hat{\\beta}x_{1j^{\\star}} \\approx y_1$。期望变为 $\\frac{2}{n}\\mathbb{E}[y_1^2 x_{1j^{\\star}}^2]$。由于 $y_1$ 和 $x_{1j^{\\star}}$ 是独立的标准正态分布（对于任何单行，选择 $j^{\\star}$ 是一个低概率事件），$\\mathbb{E}[y_1^2 x_{1j^{\\star}}^2] = \\mathbb{E}[y_1^2]\\mathbb{E}[x_{1j^{\\star}}^2]=1$。\n所以修正项约为 $2/n$。\n合并期望 LOOCV 误差的各项：\n$$\n\\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] \\approx \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\text{in}}] + \\frac{2}{n} \\approx \\left(1 - \\frac{2 \\ln p}{n}\\right) + \\frac{2}{n}\n$$\n\n### 步骤 4：计算偏差 $B(n,p)$\n\n偏差是两个推导出的期望之间的差值。\n$$\nB(n,p) = \\mathbb{E}[\\widehat{\\mathrm{MSE}}_{\\mathrm{LOOCV, leak}}] - \\mathbb{E}[\\mathrm{MSE}_{\\text{test}}]\n$$\n代入推导出的表达式：\n$$\nB(n,p) \\approx \\left(1 - \\frac{2 \\ln p}{n} + \\frac{2}{n}\\right) - \\left(1 + \\frac{2 \\ln p}{n}\\right)\n$$\n$$\nB(n,p) \\approx -\\frac{4 \\ln p}{n} + \\frac{2}{n}\n$$\n问题要求领头阶渐近表达式，并忽略比 $\\frac{\\ln p}{n}$ 低阶的项。假设 $p$ 足够大或随 $n$ 增长以至于 $\\ln p \\to \\infty$，则 $\\frac{2}{n}$ 项的阶数低于 $\\frac{4 \\ln p}{n}$。因此我们将其舍去。\n偏差的领头阶渐近表达式为：\n$$\nB(n,p) \\approx -\\frac{4 \\ln p}{n}\n$$\n这个负偏差表明，由于在交叉验证之前对完整数据集执行了特征选择，泄露的交叉验证程序表现出显著的乐观性，低估了真实的预测误差。",
            "answer": "$$\n\\boxed{-\\frac{4 \\ln(p)}{n}}\n$$"
        },
        {
            "introduction": "在生物统计学的实际应用中，我们面临的挑战往往比标准教科书中的例子更为复杂，例如处理不平衡的数据集或满足特定的临床诊断要求。本练习要求我们为一项不平衡的案例-对照研究设计一个定制的交叉验证方案。我们的目标不再是简单地最小化均方误差，而是要在保证特异度不低于某一阈值的前提下，最大化模型的灵敏度。",
            "id": "4897592",
            "problem": "一个生物统计团队正在为一项非平衡病例-对照研究构建一个二元风险分类器，其中病例表示为 $Y=1$，对照表示为 $Y=0$。对于每个受试者 $i \\in \\{1,\\dots,n\\}$，一个模型会生成一个实值分数 $\\hat f(X_i)$，该分数旨在使病例的分数高于对照。该分类器将通过对该分数设置一个可调阈值 $\\tau \\in \\mathbb{R}$ 来实现，规则如下：如果 $\\hat f(X_i) \\ge \\tau$，则预测为 1，否则预测为 0。临床目标是选择 $\\tau$ 以在达到至少为 $\\alpha \\in (0,1)$ 的目标特异性的约束下，最大化敏感性。该团队希望使用分层重复 K 折交叉验证 (CV) 来评估性能并调整 $\\tau$，其中包含 $K \\in \\{2,3,\\dots\\}$ 折和 $R \\in \\{1,2,\\dots\\}$ 次独立重复。\n\n从敏感性和特异性的定义以及 K 折交叉验证的定义出发，设计一个适用于非平衡病例-对照数据的分层重复 CV 方案。该方案应仅使用折外预测，并以控制方差的方式跨重复汇总性能估计。然后，仅使用这些基本定义并避免任何样本内重用，推导一个适用于阈值调整的经验损失函数 $\\widehat{L}(\\tau)$。该函数通过单侧线性惩罚来编码“在特异性至少为 $\\alpha$ 的约束下最大化敏感性”这一目标。当满足特异性约束时，该惩罚项为零；当违反约束时，该惩罚项随差额线性增加。您的损失函数必须使用指示函数、来自重复分层 K 折 CV 方案的折外预测、以及量 $n$、$K$、$R$ 和 $\\alpha$，连同一个控制约束强度的惩罚权重 $\\lambda>0$ 来明确表示。\n\n假设和约定：\n- 对于每次重复 $r \\in \\{1,\\dots,R\\}$，将数据索引 $\\{1,\\dots,n\\}$ 划分为 $K$ 个折，并对 $Y$ 进行分层，以使每个折尽可能保持经验类别比例。对于重复 $r$ 中验证折内的每个受试者 $i$，令 $\\hat f^{(-i,r)}(X_i)$ 表示在重复 $r$ 中使用 $K-1$ 个训练折（排除包含 $i$ 的折）训练模型并对 $X_i$ 进行预测所得到的分数。\n- 使用跨所有重复的所有折外预测的微观平均聚合来估计敏感性和特异性。\n- 在评估折外预测时，使用分类规则“当且仅当 $\\hat f^{(-i,r)}(X_i) \\ge \\tau$ 时预测为 1”。\n\n请提供交叉验证惩罚损失 $\\widehat{L}(\\tau)$ 的单个闭式解析表达式作为您的最终答案，使用记号 $\\mathbb{1}\\{\\cdot\\}$ 表示指示函数，并使用 $(x)_{+}=\\max\\{x,0\\}$。不需要进行数值计算，也不适用任何单位。",
            "solution": "该问题是有效的，因为它具有科学依据、提法得当且客观。它提出了生物统计建模中的一项标准但并非无足轻重的任务：基于分层重复交叉验证的性能估计，为调整分类器阈值推导一个惩罚损失函数。所有定义和约束都清晰、一致且足以推导出唯一的解析解。\n\n解答过程分三步进行。首先，我们概述所指定的分层重复交叉验证 (CV) 和聚合方案。其次，我们基于该方案的折外预测，将敏感性和特异性的微观平均估计形式化。最后，我们构建惩罚经验损失函数 $\\widehat{L}(\\tau)$，该函数编码了指定的最优化目标。\n\n**步骤 1：分层重复 K 折交叉验证方案**\n\n问题要求一个分层重复 K 折交叉验证方案。此程序旨在产生可靠的样本外性能估计，特别是对于非平衡数据。设 $n$ 为受试者总数，其中有 $N_1 = \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}$ 个病例 ($Y=1$) 和 $N_0 = \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}$ 个对照 ($Y=0$)。\n\n该程序如下：\n1.  整个过程重复 $R$ 次，由 $r \\in \\{1,\\dots,R\\}$ 索引。每次重复都涉及对数据进行一次新的、独立的随机划分。\n2.  对于每次重复 $r$，将包含 $n$ 个受试者的数据集划分为 $K$ 个不相交的折。该划分是按结果变量 $Y$ 分层的。这确保了 $K$ 个折中的每一个都具有与完整数据集大致相同的病例和对照比例，即每个折大约包含 $N_1/K$ 个病例和 $N_0/K$ 个对照。\n3.  对于重复 $r$ 中的每个折 $k \\in \\{1,\\dots,K\\}$，该折中的受试者被指定为验证集，而其余 $K-1$ 个折中的受试者构成训练集。\n4.  在训练集上训练一个模型。然后使用该模型为相应验证集中的每个受试者 $i$ 生成一个实值分数 $\\hat f(X_i)$。根据问题的记法，我们将重复 $r$ 中受试者 $i$ 的这个折外分数表示为 $\\hat f^{(-i,r)}(X_i)$。\n5.  在所有 $R$ 次重复中为所有 $K$ 个折完成此过程后，我们总共获得 $n \\times R$ 个折外预测。对于每个受试者 $i$，有 $R$ 个预测，即 $\\{\\hat f^{(-i,1)}(X_i), \\dots, \\hat f^{(-i,R)}(X_i)\\}$，每个重复中得到一个。\n\n**步骤 2：微观平均性能指标**\n\n问题指定了微观平均聚合。这意味着我们在计算性能指标之前，汇集所有 $n \\times R$ 个折外预测及其真实标签。这等同于对所有预测的真阳性 (TP)、真阴性 (TN)、假阳性 (FP) 和假阴性 (FN) 的计数求和。\n\n对于给定的阈值 $\\tau$，分类规则是：如果受试者的分数大于或等于 $\\tau$，则将其预测为病例 (1)。\n- 预测为阳性：$\\hat f^{(-i,r)}(X_i) \\ge \\tau$\n- 预测为阴性：$\\hat f^{(-i,r)}(X_i) < \\tau$\n\n我们可以通过对所有受试者 $i \\in \\{1,\\dots,n\\}$ 和所有重复 $r \\in \\{1,\\dots,R\\}$ 求和，将 TP、FN、TN 和 FP 的总计数定义为 $\\tau$ 的函数：\n- 总真阳性：$\\text{TP}(\\tau) = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1 \\text{ and } \\hat f^{(-i,r)}(X_i) \\ge \\tau\\} = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}$\n- 总真阴性：$\\text{TN}(\\tau) = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0 \\text{ and } \\hat f^{(-i,r)}(X_i) < \\tau\\} = \\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) < \\tau\\}$\n\n所有重复中的病例实例总数为 $R \\cdot N_1 = R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}$。\n所有重复中的对照实例总数为 $R \\cdot N_0 = R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}$。\n\n微观平均敏感性 $\\widehat{\\text{Sens}}(\\tau)$ 是总真阳性与总实际阳性的比率：\n$$ \\widehat{\\text{Sens}}(\\tau) = \\frac{\\text{TP}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} $$\n微观平均特异性 $\\widehat{\\text{Spec}}(\\tau)$ 是总真阴性与总实际阴性的比率：\n$$ \\widehat{\\text{Spec}}(\\tau) = \\frac{\\text{TN}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) < \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} $$\n\n**步骤 3：惩罚损失函数的推导**\n\n目标是在特异性至少为 $\\alpha$ 的约束下最大化敏感性。这是一个约束优化问题。我们可以通过最小化一个惩罚损失函数，将其重新表述为无约束问题。最大化敏感性等同于最小化负敏感性。约束条件是 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$。当此约束被违反时，即当 $\\widehat{\\text{Spec}}(\\tau) < \\alpha$ 时，应施加惩罚。\n\n损失函数 $\\widehat{L}(\\tau)$ 的形式如下：\n$$ \\widehat{L}(\\tau) = (\\text{Objective Term}) + (\\text{Penalty Term}) $$\n目标项对应于最小化负敏感性：$-\\widehat{\\text{Sens}}(\\tau)$。\n当 $\\alpha - \\widehat{\\text{Spec}}(\\tau) > 0$ 时，惩罚项被激活。问题要求对差额进行线性惩罚，因此惩罚项为 $\\lambda \\cdot \\max\\{0, \\alpha - \\widehat{\\text{Spec}}(\\tau)\\}$，其中 $\\lambda > 0$ 是一个惩罚权重。使用记号 $(x)_+ = \\max\\{x,0\\}$，这可以写作 $\\lambda (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+$。\n\n所以，损失函数为：\n$$ \\widehat{L}(\\tau) = -\\widehat{\\text{Sens}}(\\tau) + \\lambda (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+ $$\n通常使用假阳性率 (FPR) 更为方便，其中 $\\text{Spec} = 1 - \\text{FPR}$。约束 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$ 等价于 $1 - \\widehat{\\text{FPR}}(\\tau) \\ge \\alpha$，或 $\\widehat{\\text{FPR}}(\\tau) \\le 1-\\alpha$。\n然后，惩罚项可以用 FPR 重写为：\n$$ (\\alpha - \\widehat{\\text{Spec}}(\\tau))_+ = (\\alpha - (1 - \\widehat{\\text{FPR}}(\\tau)))_+ = (\\widehat{\\text{FPR}}(\\tau) - (1-\\alpha))_+ $$\n估计的假阳性率 $\\widehat{\\text{FPR}}(\\tau)$ 是被错误分类为病例的对照的比例：\n$$ \\widehat{\\text{FPR}}(\\tau) = \\frac{\\text{FP}(\\tau)}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} = \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} $$\n这种形式在计算上是直接的，因为它与敏感性一样，都依赖于计算超过阈值 $\\tau$ 的分数数量。\n\n将 $-\\widehat{\\text{Sens}}(\\tau)$ 和基于 FPR 的惩罚项的表达式代入，我们得到经验损失函数 $\\widehat{L}(\\tau)$ 的最终表达式：\n$$ \\widehat{L}(\\tau) = - \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} + \\lambda \\left( \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\}\\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} - (1-\\alpha) \\right)_{+} $$\n该表达式满足问题陈述的所有要求。关于 $\\tau$ 最小化此损失函数将得出一个最优阈值，该阈值在最大化敏感性的主要目标与对特异性的临床约束之间取得平衡。参数 $\\lambda$ 控制约束的硬度：当 $\\lambda \\to \\infty$ 时，任何对特异性约束的违反都会带来无限大的代价，从而迫使解满足 $\\widehat{\\text{Spec}}(\\tau) \\ge \\alpha$。",
            "answer": "$$\\boxed{- \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=1\\} \\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=1\\}} + \\lambda \\left( \\frac{\\sum_{r=1}^R \\sum_{i=1}^n \\mathbb{1}\\{Y_i=0\\} \\mathbb{1}\\{\\hat f^{(-i,r)}(X_i) \\ge \\tau\\}}{R \\sum_{j=1}^n \\mathbb{1}\\{Y_j=0\\}} - (1-\\alpha) \\right)_{+}}$$"
        }
    ]
}