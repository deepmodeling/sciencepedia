{
    "hands_on_practices": [
        {
            "introduction": "贝叶斯推断的核心在于利用观测数据来更新我们对未知参数的认知。本练习将通过一个经典案例——泊松-伽马共轭模型——来具体展示这一过程。通过从头推导后验分布和后验预测分布，你将亲身体验贝叶斯定理的运作机制，并理解先验超参数如何被直观地解释为“伪计数”和“伪时间”，从而为更复杂的贝叶斯建模打下坚实的基础。",
            "id": "4912491",
            "problem": "一个医院的流行病学部门监测各个病房中耐甲氧西林金黄色葡萄球菌定植的事件计数。对于病房 $i$，在 $t_{i}$ 个人日的暴露下，观测到的计数为 $y_{i}$。假设每人日的发病率 $\\lambda$ 是一个常数，并且在给定 $\\lambda$ 的条件下，各个计数是独立的，满足 $y_{i} \\sim \\mathrm{Poisson}(\\lambda t_{i})$，$i = 1, \\dots, n$。$\\lambda$ 的先验分布为 $\\mathrm{Gamma}(\\alpha_{0}, \\beta_{0})$，其形状参数 $\\alpha_{0} > 0$，率参数 $\\beta_{0} > 0$，这意味着其密度函数为 $p(\\lambda) = \\frac{\\beta_{0}^{\\alpha_{0}}}{\\Gamma(\\alpha_{0})} \\lambda^{\\alpha_{0}-1} \\exp(-\\beta_{0} \\lambda)$，其中 $\\lambda > 0$。\n\n从贝叶斯定理以及泊松分布和伽马分布的定义出发（不提供其他公式），推导后验分布 $p(\\lambda \\mid y_{1:n}, t_{1:n})$ 以及在新的暴露 $t_{\\mathrm{new}} > 0$ 下，未来计数 $y_{\\mathrm{new}}$ 的后验预测分布 $p(y_{\\mathrm{new}} \\mid y_{1:n}, t_{1:n}, t_{\\mathrm{new}})$。然后，根据 $\\alpha_{0}$ 和 $\\beta_{0}$ 与观测数据结合的方式，将它们解释为伪计数和伪时间。\n\n请用伽马函数将您的最终答案表示为 $y_{\\mathrm{new}}$ 的后验预测概率质量函数的闭式解析表达式，该表达式应包含 $\\alpha_{0}$、$\\beta_{0}$、$\\sum_{i=1}^{n} y_{i}$、$\\sum_{i=1}^{n} t_{i}$ 和 $t_{\\mathrm{new}}$。无需四舍五入。",
            "solution": "### 1. 推导后验分布 $p(\\lambda \\mid y_{1:n}, t_{1:n})$\n\n根据贝叶斯定理，后验分布正比于似然函数与先验分布的乘积：\n$$ p(\\lambda \\mid y_{1:n}, t_{1:n}) \\propto p(y_{1:n} \\mid \\lambda, t_{1:n}) p(\\lambda) $$\n\n由于观测值是相互独立的，似然函数为：\n$$ L(\\lambda) = p(y_{1:n} \\mid \\lambda, t_{1:n}) = \\prod_{i=1}^{n} p(y_i \\mid \\lambda, t_i) = \\prod_{i=1}^{n} \\frac{(\\lambda t_i)^{y_i} e^{-\\lambda t_i}}{y_i!} $$\n忽略与 $\\lambda$ 无关的常数项，似然函数的核心部分为：\n$$ L(\\lambda) \\propto \\prod_{i=1}^{n} \\lambda^{y_i} e^{-\\lambda t_i} = \\lambda^{\\sum_{i=1}^{n} y_i} e^{-\\lambda \\sum_{i=1}^{n} t_i} $$\n\n先验分布是 $\\text{Gamma}(\\alpha_0, \\beta_0)$，其概率密度函数为：\n$$ p(\\lambda) \\propto \\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda} $$\n\n将似然函数与先验相乘，得到后验分布的核：\n$$ p(\\lambda \\mid y_{1:n}, t_{1:n}) \\propto \\left( \\lambda^{\\sum y_i} e^{-\\lambda \\sum t_i} \\right) \\times \\left( \\lambda^{\\alpha_0 - 1} e^{-\\beta_0 \\lambda} \\right) $$\n$$ p(\\lambda \\mid y_{1:n}, t_{1:n}) \\propto \\lambda^{(\\alpha_0 + \\sum y_i) - 1} e^{-(\\beta_0 + \\sum t_i) \\lambda} $$\n\n这正是形状参数为 $\\alpha' = \\alpha_0 + \\sum y_i$、率参数为 $\\beta' = \\beta_0 + \\sum t_i$ 的伽马分布的核。因此，后验分布为：\n$$ \\lambda \\mid y_{1:n}, t_{1:n} \\sim \\text{Gamma}(\\alpha_0 + \\sum_{i=1}^{n} y_i, \\beta_0 + \\sum_{i=1}^{n} t_i) $$\n\n### 2. 先验超参数的解释\n\n从后验参数的更新形式可以看出，后验的形状参数 $\\alpha'$ 是先验形状参数 $\\alpha_0$ 加上观测到的总事件数 $\\sum y_i$。后验的率参数 $\\beta'$ 是先验率参数 $\\beta_0$ 加上总暴露时间 $\\sum t_i$。这直观地支持了将先验超参数 $\\alpha_0$ 解释为“伪计数”（pseudo-counts），即在观测数据之前我们信念中包含的虚拟事件数；将 $\\beta_0$ 解释为“伪时间”（pseudo-time），即虚拟的暴露时间。\n\n### 3. 推导后验预测分布 $p(y_{\\text{new}} \\mid y_{1:n}, t_{1:n}, t_{\\text{new}})$\n\n后验预测分布是新观测值 $y_{\\text{new}}$ 的分布，它是通过对参数 $\\lambda$ 的后验分布进行积分（或求期望）得到的：\n$$ p(y_{\\text{new}} \\mid \\dots) = \\int_0^\\infty p(y_{\\text{new}} \\mid \\lambda, t_{\\text{new}}) p(\\lambda \\mid y_{1:n}, t_{1:n}) d\\lambda $$\n\n其中，$p(y_{\\text{new}} \\mid \\lambda, t_{\\text{new}})$ 是泊松分布的概率质量函数，而 $p(\\lambda \\mid y_{1:n}, t_{1:n})$ 是我们刚刚推导出的伽马后验分布。设 $\\alpha' = \\alpha_0 + \\sum y_i$ 和 $\\beta' = \\beta_0 + \\sum t_i$。\n$$ p(y_{\\text{new}} \\mid \\dots) = \\int_0^\\infty \\left( \\frac{(\\lambda t_{\\text{new}})^{y_{\\text{new}}} e^{-\\lambda t_{\\text{new}}}}{y_{\\text{new}}!} \\right) \\left( \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\lambda^{\\alpha' - 1} e^{-\\beta' \\lambda} \\right) d\\lambda $$\n整理积分项：\n$$ = \\frac{t_{\\text{new}}^{y_{\\text{new}}} (\\beta')^{\\alpha'}}{y_{\\text{new}}! \\Gamma(\\alpha')} \\int_0^\\infty \\lambda^{(y_{\\text{new}} + \\alpha') - 1} e^{-(\\beta' + t_{\\text{new}}) \\lambda} d\\lambda $$\n\n这个积分是另一个伽马分布（形状参数为 $y_{\\text{new}} + \\alpha'$，率参数为 $\\beta' + t_{\\text{new}}$）的概率密度函数乘以其归一化常数的倒数。积分的值为：\n$$ \\int_0^\\infty \\lambda^{(y_{\\text{new}} + \\alpha') - 1} e^{-(\\beta' + t_{\\text{new}}) \\lambda} d\\lambda = \\frac{\\Gamma(y_{\\text{new}} + \\alpha')}{(\\beta' + t_{\\text{new}})^{y_{\\text{new}} + \\alpha'}} $$\n\n将此结果代回原式：\n$$ p(y_{\\text{new}} \\mid \\dots) = \\frac{t_{\\text{new}}^{y_{\\text{new}}} (\\beta')^{\\alpha'}}{y_{\\text{new}}! \\Gamma(\\alpha')} \\frac{\\Gamma(y_{\\text{new}} + \\alpha')}{(\\beta' + t_{\\text{new}})^{y_{\\text{new}} + \\alpha'}} $$\n使用 $\\Gamma(y_{\\text{new}}+1) = y_{\\text{new}}!$ 并重新整理，可得与最终答案相同的形式：\n$$ p(y_{\\text{new}} \\mid \\dots) = \\frac{\\Gamma(y_{\\text{new}} + \\alpha')}{\\Gamma(y_{\\text{new}}+1) \\Gamma(\\alpha')} \\frac{t_{\\text{new}}^{y_{\\text{new}}} (\\beta')^{\\alpha'}}{(\\beta' + t_{\\text{new}})^{y_{\\text{new}} + \\alpha'}} $$\n最后，代回 $\\alpha'$ 和 $\\beta'$ 的定义，我们得到与答案框中完全一致的表达式。这个分布是负二项分布的一种形式。",
            "answer": "$$\n\\boxed{\\frac{\\Gamma(y_{\\mathrm{new}} + \\alpha_{0} + \\sum_{i=1}^{n} y_{i})}{\\Gamma(y_{\\mathrm{new}}+1) \\Gamma(\\alpha_{0} + \\sum_{i=1}^{n} y_{i})} \\frac{t_{\\mathrm{new}}^{y_{\\mathrm{new}}} (\\beta_{0} + \\sum_{i=1}^{n} t_{i})^{\\alpha_{0} + \\sum_{i=1}^{n} y_{i}}}{(\\beta_{0} + \\sum_{i=1}^{n} t_{i} + t_{\\mathrm{new}})^{y_{\\mathrm{new}} + \\alpha_{0} + \\sum_{i=1}^{n} y_{i}}}}\n$$"
        },
        {
            "introduction": "在掌握了贝叶斯更新的基本机制后，一个自然而然的问题便是：“我们应该如何选择先验分布？”本练习旨在探讨“无信息先验”这一重要概念。通过为伯努利模型推导著名的杰弗里斯先验（Jeffreys prior），并将其与看似直观的均匀先验进行对比，你将发现不同的“无信息”假设会如何影响模型的预测行为，从而更深刻地理解先验选择背后的原则及其对推断结果的微妙影响。",
            "id": "4912591",
            "problem": "一项生物统计学初步研究考虑了一种新疗法的二元临床终点，该终点被建模为参数为 $\\theta \\in (0,1)$ 的伯努利随机变量。其目标是使用一个能反映参数化不变性的先验，并将其在小样本量下的先验预测行为与均匀先验进行比较。从第一性原理出发，将数据 $X \\in \\{0,1\\}$ 视为单次伯努利试验，并推导出 $\\theta$ 的费雪信息。利用此信息定义伯努利参数的Jeffreys先验。然后，考虑一个大小为 $n=3$ 的样本，并计算在Jeffreys先验下观测到3名响应者（即全部成功）的先验预测概率。同时，计算在 $\\mathrm{Beta}(1,1)$ 先验下观测到3名响应者的先验预测概率。最后，将这两个先验预测概率之比（Jeffreys先验除以 $\\mathrm{Beta}(1,1)$ 先验）作为一个精确值报告。不要四舍五入；以最简分数形式给出精确比率。",
            "solution": "用户希望解决一个贝叶斯生物统计学问题。我将首先验证问题陈述。\n\n### 步骤 1：提取已知条件\n-   **模型**：数据来自一个二元临床终点，建模为伯努利随机变量。\n-   **参数**：伯努利参数为 $\\theta \\in (0,1)$。\n-   **用于计算费雪信息的数据**：单次伯努利试验 $X \\in \\{0,1\\}$，其似然为 $P(X=x|\\theta)$。\n-   **用于计算预测概率的数据**：样本大小为 $n=3$。\n-   **关注事件**：在大小为 $n=3$ 的样本中观测到 $k=3$ 名响应者（成功）。\n-   **任务 1**：推导伯努利参数的费雪信息 $I(\\theta)$。\n-   **任务 2**：使用 $I(\\theta)$ 定义 $\\theta$ 的Jeffreys先验。\n-   **任务 3**：在Jeffreys先验下，计算 $n=3$ 次试验中出现 $k=3$ 次成功的先验预测概率，我们称之为 $P_J(Y=3|n=3)$。\n-   **任务 4**：在 $\\mathrm{Beta}(1,1)$ 先验下，计算 $n=3$ 次试验中出现 $k=3$ 次成功的先验预测概率，我们称之为 $P_U(Y=3|n=3)$。\n-   **任务 5**：计算比率 $\\frac{P_J(Y=3|n=3)}{P_U(Y=3|n=3)}$。\n-   **要求格式**：最终答案必须是一个精确的最简分数。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据。伯努利试验、费雪信息、Jeffreys先验、Beta先验和先验预测分布等概念是贝叶斯统计学及其在生物统计学应用中的基础和标准概念。该问题提法明确，计算步骤清晰，可得出一个唯一的、确定性的结果。其语言客观而精确。该问题是自洽的，不包含任何矛盾或歧义。这是理论统计学中一个标准的、有一定难度的练习题。\n\n### 步骤 3：结论与行动\n问题有效。我将继续提供完整解答。\n\n### 解题推导\n\n该问题要求逐步推导，从费雪信息开始，直到最终的先验预测概率之比。\n\n**1. 伯努利参数的费雪信息**\n\n成功参数为 $\\theta$ 的单次伯努利试验的概率质量函数为 $P(X=x|\\theta) = \\theta^x (1-\\theta)^{1-x}$，其中 $x \\in \\{0, 1\\}$。单个观测值 $x$ 的似然函数为 $L(\\theta|x) = \\theta^x (1-\\theta)^{1-x}$。\n\n对数似然函数为 $\\ell(\\theta|x) = \\ln L(\\theta|x) = x \\ln(\\theta) + (1-x) \\ln(1-\\theta)$。\n\n为了找到费雪信息 $I(\\theta)$，我们计算对数似然函数关于 $\\theta$ 的二阶导数的负期望。\n\n一阶导数：\n$$ \\frac{\\partial \\ell}{\\partial \\theta} = \\frac{x}{\\theta} - \\frac{1-x}{1-\\theta} $$\n\n二阶导数：\n$$ \\frac{\\partial^2 \\ell}{\\partial \\theta^2} = -\\frac{x}{\\theta^2} - \\frac{1-x}{(1-\\theta)^2} $$\n\n单个观测值的费雪信息为 $I(\\theta) = -E\\left[\\frac{\\partial^2 \\ell}{\\partial \\theta^2}\\right]$。期望是关于 $X$ 的分布计算的，其中 $E[X] = \\theta$。\n$$ I(\\theta) = -E\\left[ -\\frac{X}{\\theta^2} - \\frac{1-X}{(1-\\theta)^2} \\right] = E\\left[ \\frac{X}{\\theta^2} \\right] + E\\left[ \\frac{1-X}{(1-\\theta)^2} \\right] $$\n$$ I(\\theta) = \\frac{E[X]}{\\theta^2} + \\frac{1-E[X]}{(1-\\theta)^2} = \\frac{\\theta}{\\theta^2} + \\frac{1-\\theta}{(1-\\theta)^2} = \\frac{1}{\\theta} + \\frac{1}{1-\\theta} $$\n化简后，我们得到：\n$$ I(\\theta) = \\frac{1-\\theta+\\theta}{\\theta(1-\\theta)} = \\frac{1}{\\theta(1-\\theta)} $$\n\n**2. 伯努利参数的Jeffreys先验**\n\nJeffreys先验 $p_J(\\theta)$ 定义为与费雪信息平方根成正比：\n$$ p_J(\\theta) \\propto \\sqrt{I(\\theta)} = \\sqrt{\\frac{1}{\\theta(1-\\theta)}} = \\theta^{-1/2} (1-\\theta)^{-1/2} $$\n这是一个Beta分布的核，$p(\\theta|\\alpha, \\beta) \\propto \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}$。通过比较指数，我们有 $\\alpha-1 = -1/2$ 和 $\\beta-1 = -1/2$，这得出 $\\alpha = 1/2$ 和 $\\beta = 1/2$。因此，伯努利参数的Jeffreys先验是一个 $\\mathrm{Beta}(1/2, 1/2)$ 分布。归一化的概率密度函数是：\n$$ p_J(\\theta) = \\frac{\\theta^{1/2-1} (1-\\theta)^{1/2-1}}{B(1/2, 1/2)} = \\frac{\\theta^{-1/2} (1-\\theta)^{-1/2}}{\\frac{\\Gamma(1/2)\\Gamma(1/2)}{\\Gamma(1)}} = \\frac{1}{\\pi} \\theta^{-1/2} (1-\\theta)^{-1/2} $$\n其中我们使用了 $\\Gamma(1/2) = \\sqrt{\\pi}$ 和 $\\Gamma(1) = 1$。\n\n**3. Jeffreys先验下的先验预测概率**\n\n我们考虑一个大小为 $n=3$ 的样本，并观测到 $k=3$ 次成功。令 $Y$ 为成功次数。该观测值的似然由二项分布的概率质量函数给出：\n$$ P(Y=3|\\theta, n=3) = \\binom{3}{3} \\theta^3 (1-\\theta)^{3-3} = \\theta^3 $$\n先验预测概率 $P_J(Y=3|n=3)$ 是数据的边际概率，通过将似然函数对先验分布进行积分得到：\n$$ P_J(Y=3|n=3) = \\int_0^1 P(Y=3|\\theta, n=3) p_J(\\theta) d\\theta $$\n$$ P_J(Y=3|n=3) = \\int_0^1 \\theta^3 \\left( \\frac{1}{\\pi} \\theta^{-1/2} (1-\\theta)^{-1/2} \\right) d\\theta = \\frac{1}{\\pi} \\int_0^1 \\theta^{5/2} (1-\\theta)^{-1/2} d\\theta $$\n该积分是Beta函数的形式，$B(a, b) = \\int_0^1 t^{a-1} (1-t)^{b-1} dt = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a+b)}$。\n这里，$a-1 = 5/2 \\Rightarrow a=7/2$ 且 $b-1 = -1/2 \\Rightarrow b=1/2$。\n该积分为 $B(7/2, 1/2)$。我们使用Gamma函数的性质 $\\Gamma(z+1)=z\\Gamma(z)$ 和对于整数 $n$ 的 $\\Gamma(n)=(n-1)!$ 来计算它。\n$$ \\Gamma(7/2) = \\frac{5}{2}\\Gamma(5/2) = \\frac{5}{2}\\frac{3}{2}\\Gamma(3/2) = \\frac{5}{2}\\frac{3}{2}\\frac{1}{2}\\Gamma(1/2) = \\frac{15}{8}\\sqrt{\\pi} $$\n$$ \\Gamma(1/2) = \\sqrt{\\pi} $$\n$$ \\Gamma(7/2 + 1/2) = \\Gamma(4) = 3! = 6 $$\n所以，$B(7/2, 1/2) = \\frac{\\Gamma(7/2)\\Gamma(1/2)}{\\Gamma(4)} = \\frac{(\\frac{15}{8}\\sqrt{\\pi})(\\sqrt{\\pi})}{6} = \\frac{15\\pi}{48} = \\frac{5\\pi}{16}$。\n将其代回到先验预测概率的表达式中：\n$$ P_J(Y=3|n=3) = \\frac{1}{\\pi} B(7/2, 1/2) = \\frac{1}{\\pi} \\left( \\frac{5\\pi}{16} \\right) = \\frac{5}{16} $$\n\n**4. $\\mathrm{Beta}(1,1)$先验下的先验预测概率**\n\n$\\mathrm{Beta}(1,1)$ 先验是 $(0,1)$ 上的均匀先验，其概率密度函数为 $p_U(\\theta) = 1$，其中 $\\theta \\in (0,1)$。\n先验预测概率 $P_U(Y=3|n=3)$ 为：\n$$ P_U(Y=3|n=3) = \\int_0^1 P(Y=3|\\theta, n=3) p_U(\\theta) d\\theta $$\n$$ P_U(Y=3|n=3) = \\int_0^1 \\theta^3 \\cdot 1 d\\theta = \\left[ \\frac{\\theta^4}{4} \\right]_0^1 = \\frac{1}{4} - 0 = \\frac{1}{4} $$\n\n**5. 先验预测概率之比**\n\n最后，我们计算Jeffreys先验下的先验预测概率与 $\\mathrm{Beta}(1,1)$ 先验下的先验预测概率之比。\n$$ \\text{比率} = \\frac{P_J(Y=3|n=3)}{P_U(Y=3|n=3)} = \\frac{5/16}{1/4} $$\n$$ \\text{比率} = \\frac{5}{16} \\times \\frac{4}{1} = \\frac{20}{16} = \\frac{5}{4} $$\n这个比率表明，与均匀先验相比，Jeffreys先验为极端结果（全部成功或全部失败）分配了更高的概率。",
            "answer": "$$\n\\boxed{\\frac{5}{4}}\n$$"
        },
        {
            "introduction": "在实践中，选择看似“无偏”的扁平先验（flat prior）似乎是一种安全的做法，但这其中暗藏风险。本练习将逻辑回归模型作为背景，揭示不当的先验（improper prior）如何导致无效的后验分布（improper posterior）。通过分析诸如“完全分离”（complete separation）和“共线性”（collinearity）等特定数据模式，你将学会识别模型失效的关键预警信号，并理解数据、模型与先验之间深刻的相互作用。",
            "id": "4912450",
            "problem": "考虑一个二元结果研究，其观测值为 $\\{(y_i, x_i)\\}_{i=1}^n$，其中 $y_i \\in \\{0,1\\}$，$x_i \\in \\mathbb{R}$。该研究使用逻辑斯蒂回归进行建模，其线性预测器为 $\\eta_i = \\beta_0 + \\beta_1 x_i$，成功概率为 $p_i = \\operatorname{logit}^{-1}(\\eta_i) = \\{1 + \\exp(-\\eta_i)\\}^{-1}$。在条件独立性假设下，似然函数为\n$$\nL(\\beta_0,\\beta_1) \\;=\\; \\prod_{i=1}^n p_i^{\\,y_i}\\,\\{1-p_i\\}^{\\,1-y_i}.\n$$\n假设贝叶斯分析对回归系数使用不当平坦先验，即 $\\pi(\\beta_0,\\beta_1) \\propto 1$ 在 $\\mathbb{R}^2$ 上。根据贝叶斯法则，后验密度正比于 $L(\\beta_0,\\beta_1)\\,\\pi(\\beta_0,\\beta_1)$。一个后验是正常的（proper），当且仅当其归一化常数 $\\int_{\\mathbb{R}^2} L(\\beta_0,\\beta_1)\\,\\mathrm{d}\\beta_0\\,\\mathrm{d}\\beta_1$ 是有限的。\n\n你的任务是找出导致此不当先验产生非正常后验（improper posterior）的反例，并将每个失败情况与潜在的数据模式联系起来。对于下面的每个选项，都指定了一种数据情景和拟合模型。假设观测值之间相互独立，并且对所有自由系数使用所述的不当平坦先验。选择所有后验为非正常的选项，并在每个选中的选项中，指出导致问题的确切数据模式。\n\nA. 仅含截距模型，所有观测均为成功。模型：$p(y_i=1) = \\operatorname{logit}^{-1}(\\beta_0)$，先验为 $\\pi(\\beta_0)\\propto 1$ 在 $\\mathbb{R}$ 上。数据：$n=5$，其中 $(y_1,\\dots,y_5)=(1,1,1,1,1)$。\n\nB. 不可分、满秩单预测变量模型。模型：$p(y_i=1) = \\operatorname{logit}^{-1}(\\beta_0+\\beta_1 x_i)$，先验为 $\\pi(\\beta_0,\\beta_1)\\propto 1$。数据：$n=4$，其中 $(x,y)$ 对为 $(0,0)$、$(0,1)$、$(1,0)$、$(1,1)$。\n\nC. 完全共线性的预测变量，无分离现象。模型：$p(y_i=1) = \\operatorname{logit}^{-1}(\\beta_0+\\beta_x x_i+\\beta_z z_i)$，先验为 $\\pi(\\beta_0,\\beta_x,\\beta_z)\\propto 1$。数据：$n=4$，其中 $(x,z,y)$ 对为 $(0,0,0)$、$(0,0,1)$、$(1,1,0)$、$(1,1,1)$。\n\nD. 单个预测变量导致的完全分离。模型：$p(y_i=1) = \\operatorname{logit}^{-1}(\\beta_0+\\beta_1 x_i)$，先验为 $\\pi(\\beta_0,\\beta_1)\\propto 1$。数据：$n=4$，其中 $(x,y)$ 对为 $(-1,0)$、$(-1,0)$、$(+1,1)$、$(+1,1)$。\n\n选择所有适用项。",
            "solution": "问题的陈述有效性已得到确认。该问题描述了贝叶斯逻辑斯蒂回归中的标准情景，并要求确定在何种条件下，不当平坦先验会导致非正常后验。这是贝叶斯分析中一个明确定义的基本问题。我们现在将进行解答。\n\n后验密度是正常的，当且仅当在给定先验为不当均匀先验（即 $\\pi(\\boldsymbol{\\beta}) \\propto 1$）的情况下，似然函数在整个参数空间上是可积的。条件是 $\\int L(\\boldsymbol{\\beta}) \\, \\mathrm{d}\\boldsymbol{\\beta}  \\infty$。如果该积分发散，则会出现非正常后验。这通常在两种情况下发生：(1) 设计矩阵中存在完全共线性，或 (2) 数据点存在完全或准完全分离。我们根据这些原则分析每个选项。\n\n### 选项 A：仅含截距模型，所有观测均为成功。\n**模型**：成功概率为 $p_i = \\operatorname{logit}^{-1}(\\beta_0) = (1 + \\exp(-\\beta_0))^{-1}$。先验为 $\\pi(\\beta_0) \\propto 1$。\n**数据**：$n=5$，所有结果均为成功，即对 $i=1, \\dots, 5$ 都有 $y_i=1$。\n**分析**：对于此数据，似然函数为：\n$$\nL(\\beta_0) = \\prod_{i=1}^5 p_i^{y_i} (1-p_i)^{1-y_i} = \\prod_{i=1}^5 p_i^1 (1-p_i)^0 = p_i^5 = \\left(\\frac{1}{1 + \\exp(-\\beta_0)}\\right)^5\n$$\n为了确定后验是否正常，我们必须检查似然函数在参数空间 $\\mathbb{R}$ 上的积分是否有限：\n$$\n\\int_{-\\infty}^{\\infty} L(\\beta_0) \\, \\mathrm{d}\\beta_0 = \\int_{-\\infty}^{\\infty} \\left(\\frac{1}{1 + \\exp(-\\beta_0)}\\right)^5 \\, \\mathrm{d}\\beta_0\n$$\n让我们考察当 $\\beta_0 \\to \\infty$ 时被积函数的行为：\n$$\n\\lim_{\\beta_0 \\to \\infty} L(\\beta_0) = \\lim_{\\beta_0 \\to \\infty} \\left(\\frac{1}{1 + \\exp(-\\beta_0)}\\right)^5 = \\left(\\frac{1}{1 + 0}\\right)^5 = 1\n$$\n由于当 $\\beta_0 \\to \\infty$ 时，被积函数趋近于一个非零常数（1），因此对于任何大的 $M$，在区间 $[M, \\infty)$ 上的积分将发散。因此，总积分是无限的。后验是非正常的。\n**导致问题的数据模式**：问题是由因变量缺乏变异（所有 $y_i$ 均为 1）引起的。这对于仅含截距的模型来说是一种 **完全分离** 的形式，模型可以通过将概率 $p_i$ 推向 1 来实现完美拟合，这对应于 $\\beta_0 \\to \\infty$。似然函数不会衰减，导致后验密度不可积。\n\n**结论**：**正确**。后验是非正常的。\n\n### 选项 B：不可分、满秩单预测变量模型。\n**数据**：$(x,y)$ 对为 $(0,0)$、$(0,1)$、$(1,0)$、$(1,1)$。\n**分析**：这种数据配置表现出 **重叠**（overlap）。在 $x=0$ 时，观测到 $y=0$ 和 $y=1$ 两种结果。同样，在 $x=1$ 时，也观测到两种结果。这明确地阻止了完全分离。完全分离要求存在一个参数向量 $(\\beta_0, \\beta_1)$，使得对于所有 $y_i=1$，$\\beta_0 + \\beta_1 x_i$ 的符号一致，而对于所有 $y_i=0$，其符号相反。对于此数据集，分离将要求：\n对于 $(0,0)$：$\\beta_0 + \\beta_1(0)  0 \\implies \\beta_0  0$。\n对于 $(0,1)$：$\\beta_0 + \\beta_1(0)  0 \\implies \\beta_0  0$。\n这些条件是矛盾的。因此，分离是不可能的。\n设计矩阵为 $\\mathbf{X} = \\begin{pmatrix} 1  0 \\\\ 1  0 \\\\ 1  1 \\\\ 1  1 \\end{pmatrix}$。两列是线性无关的，所以该矩阵是满秩的。\n在贝叶斯逻辑斯蒂回归中，一个已知的结果是，如果数据不是完全或准完全可分的，并且设计矩阵是满秩的，那么由平坦不当先验产生的后验是正常的。\n**数据模式**：该模式是 **重叠**，这与分离相反。这确保了后验是正常的。\n\n**结论**：**错误**。后验是正常的。\n\n### 选项 C：完全共线性的预测变量，无分离现象。\n**模型**：$p(y_i=1) = \\operatorname{logit}^{-1}(\\beta_0+\\beta_x x_i+\\beta_z z_i)$。\n**数据**：$(x,z,y)$ 对为 $(0,0,0)$、$(0,0,1)$、$(1,1,0)$、$(1,1,1)$。\n**分析**：让我们检查预测变量（截距项, $x$, $z$）的设计矩阵：\n$$\n\\mathbf{X} = \\begin{pmatrix} 1  0  0 \\\\ 1  0  0 \\\\ 1  1  1 \\\\ 1  1  1 \\end{pmatrix}\n$$\n第二列（对应预测变量 $x$）与第三列（对应预测变量 $z$）完全相同。这意味着存在 **完全共线性**（perfect collinearity）。各列是线性相关的，因为 $1 \\cdot (x \\text{列}) - 1 \\cdot (z \\text{列}) + 0 \\cdot (\\text{截距列}) = \\mathbf{0}$。设计矩阵不是满秩的。\n线性预测器为 $\\eta_i = \\beta_0 + \\beta_x x_i + \\beta_z z_i$。因为在数据集中对所有 $i$ 都有 $x_i = z_i$，所以这变成了 $\\eta_i = \\beta_0 + (\\beta_x + \\beta_z) x_i$。似然函数 $L(\\beta_0, \\beta_x, \\beta_z)$ 仅依赖于 $\\beta_0$ 和和 $\\beta_x+\\beta_z$，而不分别依赖于 $\\beta_x$ 和 $\\beta_z$。\n对于任何常数 $c$，参数向量 $(\\beta_0, \\beta_x+c, \\beta_z-c)$ 产生相同的线性预测器，因此与 $(\\beta_0, \\beta_x, \\beta_z)$ 具有相同的似然值。这意味着对于固定的 $\\beta_0$ 和和 $\\beta_x+\\beta_z$，似然函数沿着 $(\\beta_x, \\beta_z)$ 平面中的直线是恒定的。\n似然函数的积分为 $\\int_{\\mathbb{R}^3} L(\\beta_0, \\beta_x, \\beta_z) \\, \\mathrm{d}\\beta_0 \\, \\mathrm{d}\\beta_x \\, \\mathrm{d}\\beta_z$。因为似然函数在参数空间中的无限长的直线上是恒定的，所以沿这些直线的积分将发散。因此，在 $\\mathbb{R}^3$ 上的总积分是无限的，后验是非正常的。\n**导致问题的数据模式**：问题是由预测变量 $x$ 和 $z$ 之间的 **完全共线性** 引起的。这使得单个系数 $\\beta_x$ 和 $\\beta_z$ 不可识别（non-identifiable）。\n\n**结论**：**正确**。后验是非正常的。\n\n### 选项 D：单个预测变量导致的完全分离。\n**数据**：$(x,y)$ 对为 $(-1,0)$、$(-1,0)$、$(+1,1)$、$(+1,1)$。\n**分析**：这是 **完全分离**（complete separation）的一个经典案例。所有 $y_i=0$ 的数据点都有 $x_i=-1$，而所有 $y_i=1$ 的数据点都有 $x_i=+1$。预测变量 $x$ 完美地分开了结果。\n我们可以找到一个实现这种分离的向量 $(\\beta_0, \\beta_1)$。例如，令 $\\beta_0=0$，$\\beta_1=1$。线性预测器为 $\\eta_i = x_i$。\n对于 $y_i=0$，我们有 $x_i=-1$，所以 $\\eta_i = -1  0$。成功概率被推向 0。\n对于 $y_i=1$，我们有 $x_i=+1$，所以 $\\eta_i = +1  0$。成功概率被推向 1。\n现在，考虑将这些参数按一个因子 $k  0$ 进行缩放。令参数向量为 $(0, k)$。线性预测器变为 $\\eta_i = k x_i$。\n似然函数为 $L(\\beta_0, \\beta_1) = \\prod_i p_i^{y_i} (1-p_i)^{1-y_i}$。对于我们的数据和参数 $(0, k)$：\n$$\nL(0, k) = \\left(1 - p(x=-1)\\right)^2 \\cdot \\left(p(x=+1)\\right)^2\n$$\n其中 $p(x) = (1+\\exp(-(kx)))^{-1}$。\n$$\nL(0, k) = \\left(1 - \\frac{1}{1+\\exp(k)}\\right)^2 \\left(\\frac{1}{1+\\exp(-k)}\\right)^2 = \\left(\\frac{\\exp(k)}{1+\\exp(k)}\\right)^2 \\left(\\frac{1}{1+\\exp(-k)}\\right)^2\n$$\n当 $k \\to \\infty$ 时：\n$\\frac{\\exp(k)}{1+\\exp(k)} \\to 1$ 且 $\\frac{1}{1+\\exp(-k)} \\to 1$。\n因此，$\\lim_{k \\to \\infty} L(0, k) = 1^2 \\cdot 1^2 = 1$。\n似然函数沿着射线 $(\\beta_0, \\beta_1) = (0, k)$ 并在 $k \\to \\infty$ 时趋近于 $1$。一个在无穷域上不衰减至零的函数的积分必然发散。因此，后验是非正常的。\n**导致问题的数据模式**：问题是由 **完全分离** 引起的，即预测变量的线性组合可以完美地对二元结果进行分类。\n\n**结论**：**正确**。后验是非正常的。\n\n最终结论：选项 A、C 和 D 描述了在逻辑斯蒂回归中使用平坦先验时导致非正常后验的情景。",
            "answer": "$$\\boxed{A, C, D}$$"
        }
    ]
}