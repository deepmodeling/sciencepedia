{
    "hands_on_practices": [
        {
            "introduction": "Hypothesis tests and confidence intervals are not separate tools but rather two sides of the same inferential coin. This practice provides a concrete demonstration of this fundamental duality. By calculating a $95\\%$ confidence interval and performing a two-sided t-test on the same dataset, you will verify that the interval-based decision (whether the null value is included) perfectly aligns with the test-based conclusion, solidifying your understanding of the one-sample t-procedure .",
            "id": "4934484",
            "problem": "A clinical research team is studying the mean concentration of C-reactive protein in blood serum following a standardized intervention. Assume the underlying population distribution of concentrations is approximately normal with unknown variance. A simple random sample of size $n=25$ yields a sample mean $\\bar{X}=9.8$ and a sample standard deviation $s=2.5$ (both in mg/L). Consider the two-sided hypothesis test at significance level $\\alpha=0.05$ for $H_{0}:\\ \\mu=\\mu_{0}$ versus $H_{1}:\\ \\mu\\neq\\mu_{0}$, where $\\mu_{0}=9$ (in mg/L). Using first principles appropriate to the one-sample $t$-procedure, compute the $95\\%$ $t$-based confidence interval for the true mean $\\mu$, and verify whether the decision of the corresponding two-sided one-sample $t$-test at $\\alpha=0.05$ matches the inclusion or exclusion of $\\mu_{0}$ in the confidence interval. Report the two interval endpoints and encode the test decision numerically as $1$ for “reject $H_{0}$” and $0$ for “fail to reject $H_{0}$.” Round all reported numerical values to four significant figures. Express the interval endpoints in mg/L.",
            "solution": "The problem requires the calculation of a confidence interval for the population mean $\\mu$ and the execution of a hypothesis test concerning $\\mu$. Since the population standard deviation is unknown and the underlying population is assumed to be normally distributed, the one-sample $t$-procedure is the correct statistical method.\n\nFirst, we compute the $95\\%$ confidence interval for the true mean concentration $\\mu$. The formula for a $(1-\\alpha) \\times 100\\%$ confidence interval for $\\mu$ is given by:\n$$ \\bar{X} \\pm t_{\\alpha/2, n-1} \\frac{s}{\\sqrt{n}} $$\nThe given values are:\n-   Sample mean, $\\bar{X} = 9.8$.\n-   Sample standard deviation, $s = 2.5$.\n-   Sample size, $n = 25$.\n-   Significance level, $\\alpha = 0.05$.\n\nThe confidence level is $1-\\alpha = 1 - 0.05 = 0.95$, or $95\\%$. The degrees of freedom for the $t$-distribution are $df = n-1 = 25-1 = 24$. For a two-sided interval, we need the critical value $t_{\\alpha/2, df}$, which corresponds to $t_{0.05/2, 24} = t_{0.025, 24}$. Consulting a $t$-distribution table or using statistical software, we find this critical value to be $t_{0.025, 24} \\approx 2.0639$.\n\nNext, we calculate the standard error of the mean ($SE_{\\bar{X}}$):\n$$ SE_{\\bar{X}} = \\frac{s}{\\sqrt{n}} = \\frac{2.5}{\\sqrt{25}} = \\frac{2.5}{5} = 0.5 $$\nThe margin of error ($ME$) is the product of the critical value and the standard error:\n$$ ME = t_{0.025, 24} \\times SE_{\\bar{X}} \\approx 2.0639 \\times 0.5 = 1.03195 $$\nThe confidence interval is then calculated as $\\bar{X} \\pm ME$:\n$$ 9.8 \\pm 1.03195 $$\nThis gives the interval $(9.8 - 1.03195, 9.8 + 1.03195)$, which is $(8.76805, 10.83195)$.\nRounding the endpoints to four significant figures, we obtain:\n-   Lower endpoint: $8.768$\n-   Upper endpoint: $10.83$\n\nSecond, we perform the two-sided one-sample $t$-test and verify its correspondence with the confidence interval.\nThe hypotheses are:\n-   $H_{0}: \\mu = 9$\n-   $H_{1}: \\mu \\neq 9$\n\nThe test statistic is calculated as:\n$$ t = \\frac{\\bar{X} - \\mu_{0}}{s/\\sqrt{n}} = \\frac{\\bar{X} - \\mu_{0}}{SE_{\\bar{X}}} $$\nSubstituting the given values:\n$$ t = \\frac{9.8 - 9}{0.5} = \\frac{0.8}{0.5} = 1.6 $$\nFor a two-sided test at significance level $\\alpha=0.05$ with $24$ degrees of freedom, the rejection region is $|t| > t_{0.025, 24}$. We already established that $t_{0.025, 24} \\approx 2.0639$.\nWe compare our calculated test statistic to the critical value:\n$$ |t| = |1.6| = 1.6 $$\nSince $1.6 \\ngtr 2.0639$, the test statistic does not fall into the rejection region. Therefore, we fail to reject the null hypothesis $H_{0}$. The numerical code for \"fail to reject $H_{0}$\" is $0$.\n\nFinally, we verify the correspondence between the two results. The fundamental duality principle states that a $(1-\\alpha) \\times 100\\%$ confidence interval for $\\mu$ contains all values of $\\mu_{0}$ for which the null hypothesis $H_{0}: \\mu = \\mu_{0}$ would not be rejected in a two-sided test at significance level $\\alpha$.\nOur calculated $95\\%$ confidence interval is approximately $(8.768, 10.83)$. The hypothesized mean is $\\mu_{0}=9$.\nSince $8.768 < 9 < 10.83$, the value $\\mu_{0}=9$ is contained within the confidence interval.\nThis outcome is consistent with our hypothesis test decision to \"fail to reject $H_{0}$\". The verification is successful.\n\nThe requested numerical results are the lower and upper endpoints of the confidence interval and the test decision code, all rounded to four significant figures where applicable.\n-   Lower endpoint: $8.768$ mg/L\n-   Upper endpoint: $10.83$ mg/L\n-   Test decision code: $0$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 8.768 & 10.83 & 0 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The classical t-test relies on the sample mean and standard deviation, statistics that are highly sensitive to extreme values. This exercise offers a hands-on exploration of an outlier's dramatic impact on a t-test's outcome and introduces a robust alternative to mitigate its influence. By quantifying the inflation in variance and comparing the classical t-statistic to a winsorized version, you will develop a practical appreciation for the importance of data quality and robust statistical methods .",
            "id": "4934504",
            "problem": "A clinical study monitors fasting blood glucose concentrations (mg/dL) in a cohort of healthy adults to assess whether the population mean equals a reference value. Assume observations are independent and identically distributed from a continuous population, and the null hypothesis is that the population mean equals $100$ mg/dL. Consider the following sample of $10$ participants: $96$, $102$, $105$, $98$, $110$, $94$, $101$, $99$, $107$, $100$. Then suppose a single erroneous extreme measurement is inadvertently included from a miscalibrated device: $300$ mg/dL, giving an augmented sample of $11$ observations.\n\nStarting from first principles—the definitions of the sample mean, the unbiased sample variance, and the one-sample $t$ statistic under normal sampling—carry out the following:\n\n- Using the $10$-observation sample, compute the unbiased sample variance $S_{\\text{clean}}^{2}$ and the one-sample $t$ statistic for testing whether the mean equals $100$ mg/dL.\n- Using the $11$-observation sample (the $10$ original observations plus the single extreme outlier at $300$ mg/dL), compute the unbiased sample variance $S_{\\text{out}}^{2}$ and the one-sample $t$ statistic for testing whether the mean equals $100$ mg/dL.\n- Quantify the inflation of variability due to the outlier by the ratio $R = S_{\\text{out}}^{2} / S_{\\text{clean}}^{2}$.\n- For a robust comparison, construct a $20\\%$ winsorized analysis of the $11$-observation sample: replace the lowest $g$ and highest $g$ observations by the $(g+1)$-th smallest and the $(n-g)$-th largest observations respectively, where $g = \\lfloor 0.2 n \\rfloor$ and $n = 11$. Use the winsorized sample to compute a winsorized mean and a winsorized unbiased sample variance $S_{\\text{win}}^{2}$. Form a $t$-like statistic by replacing the classical mean and standard deviation with the winsorized mean and $\\sqrt{S_{\\text{win}}^{2}}$ in the usual one-sample $t$ construction. Compare, at significance level $\\alpha = 0.05$ (two-sided), whether the test decision changes between the classical outlier-inclusive analysis and the winsorized robust analysis.\n- Let $t_{\\text{out}}$ denote the classical $t$ statistic computed on the $11$-observation sample (including the outlier), and let $t_{\\text{win}}$ denote the winsorized $t$-like statistic on the $11$-observation sample. Define the scalar\n$$\nQ \\;=\\; R \\;-\\; \\left(|t_{\\text{win}}| \\;-\\; |t_{\\text{out}}|\\right).\n$$\n\nRound your final numerical value of $Q$ to four significant figures. Express the final answer as a dimensionless number.",
            "solution": "The problem is a valid exercise in biostatistics, requiring the calculation of standard and robust test statistics and the assessment of an outlier's impact. I will proceed with the solution by following the specified tasks.\n\nThe fundamental definitions are as follows. For a sample of observations $\\{x_1, x_2, \\dots, x_n\\}$, the sample mean $\\bar{x}$ is defined as:\n$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i $$\nThe unbiased sample variance $S^2$ is defined as:\n$$ S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (x_i - \\bar{x})^2 $$\nThe one-sample $t$-statistic for testing the null hypothesis $H_0: \\mu = \\mu_0$ is given by:\n$$ t = \\frac{\\bar{x} - \\mu_0}{S / \\sqrt{n}} $$\nwhere $S = \\sqrt{S^2}$ is the sample standard deviation.\n\nThe problem provides a null hypothesis mean $\\mu_0 = 100$ mg/dL.\n\n**Analysis of the 10-observation (clean) sample**\n\nThe sample data, which we denote as the \"clean\" sample, consists of $n_{\\text{clean}} = 10$ observations:\n$\\{96, 102, 105, 98, 110, 94, 101, 99, 107, 100\\}$.\n\nFirst, we compute the sample mean, $\\bar{x}_{\\text{clean}}$:\n$$ \\sum_{i=1}^{10} x_i = 96+102+105+98+110+94+101+99+107+100 = 1012 $$\n$$ \\bar{x}_{\\text{clean}} = \\frac{1012}{10} = 101.2 $$\n\nNext, we compute the unbiased sample variance, $S_{\\text{clean}}^{2}$. The sum of squared deviations from the mean is:\n$$ \\sum_{i=1}^{10} (x_i - \\bar{x}_{\\text{clean}})^2 = (96-101.2)^2 + \\dots + (100-101.2)^2 $$\n$$ = (-5.2)^2 + (0.8)^2 + (3.8)^2 + (-3.2)^2 + (8.8)^2 + (-7.2)^2 + (-0.2)^2 + (-2.2)^2 + (5.8)^2 + (-1.2)^2 $$\n$$ = 27.04 + 0.64 + 14.44 + 10.24 + 77.44 + 51.84 + 0.04 + 4.84 + 33.64 + 1.44 = 221.6 $$\n$$ S_{\\text{clean}}^{2} = \\frac{221.6}{10-1} = \\frac{221.6}{9} = \\frac{1108}{45} $$\n\nFinally, we compute the one-sample $t$-statistic, $t_{\\text{clean}}$:\n$$ t_{\\text{clean}} = \\frac{\\bar{x}_{\\text{clean}} - \\mu_0}{S_{\\text{clean}} / \\sqrt{n_{\\text{clean}}}} = \\frac{101.2 - 100}{\\sqrt{(1108/45)} / \\sqrt{10}} = \\frac{1.2}{\\sqrt{1108/450}} \\approx 0.76472 $$\n\n**Analysis of the 11-observation (outlier) sample**\n\nThis sample consists of the original $10$ observations plus an outlier, $300$. Let's call this the \"outlier\" sample, with $n_{\\text{out}} = 11$.\nThe data are: $\\{96, 102, 105, 98, 110, 94, 101, 99, 107, 100, 300\\}$.\n\nThe sample mean, $\\bar{x}_{\\text{out}}$, is:\n$$ \\sum_{i=1}^{11} x_i = 1012 + 300 = 1312 $$\n$$ \\bar{x}_{\\text{out}} = \\frac{1312}{11} $$\n\nFor the variance, we use the computational formula $S^2 = \\frac{1}{n-1} \\left( \\sum x_i^2 - \\frac{(\\sum x_i)^2}{n} \\right)$.\n$$ \\sum_{i=1}^{11} x_i^2 = \\left( \\sum_{i=1}^{10} x_i^2 \\right) + 300^2 $$\nWe find $\\sum_{i=1}^{10} x_i^2 = (n_{\\text{clean}}-1)S_{\\text{clean}}^2 + n_{\\text{clean}} \\bar{x}_{\\text{clean}}^2 = 9 \\left(\\frac{1108}{45}\\right) + 10(101.2)^2 = 221.6 + 102414.4 = 102636$.\n$$ \\sum_{i=1}^{11} x_i^2 = 102636 + 90000 = 192636 $$\n$$ S_{\\text{out}}^{2} = \\frac{1}{11-1} \\left( 192636 - \\frac{1312^2}{11} \\right) = \\frac{1}{10} \\left( 192636 - \\frac{1721344}{11} \\right) $$\n$$ S_{\\text{out}}^{2} = \\frac{1}{10} \\left( \\frac{11 \\times 192636 - 1721344}{11} \\right) = \\frac{1}{110} (2118996 - 1721344) = \\frac{397652}{110} = \\frac{198826}{55} $$\n\nThe one-sample $t$-statistic for this sample, $t_{\\text{out}}$, is:\n$$ t_{\\text{out}} = \\frac{\\bar{x}_{\\text{out}} - \\mu_0}{S_{\\text{out}} / \\sqrt{n_{\\text{out}}}} = \\frac{(1312/11) - 100}{\\sqrt{(198826/55)} / \\sqrt{11}} = \\frac{212/11}{\\sqrt{198826/605}} \\approx 1.0631 $$\n\n**Quantifying Variability Inflation**\n\nThe ratio $R$ is defined as $R = S_{\\text{out}}^{2} / S_{\\text{clean}}^{2}$:\n$$ R = \\frac{198826/55}{1108/45} = \\frac{198826}{55} \\times \\frac{45}{1108} = \\frac{198826 \\times 9}{11 \\times 1108} = \\frac{1789434}{12188} = \\frac{894717}{6094} \\approx 146.82 $$\n\n**Robust Winsorized Analysis**\n\nFor the $11$-observation sample, we perform a $20\\%$ winsorization. The number of observations to be replaced at each end is $g = \\lfloor 0.2 \\times n \\rfloor = \\lfloor 0.2 \\times 11 \\rfloor = \\lfloor 2.2 \\rfloor = 2$.\nFirst, we sort the outlier sample:\n$$ \\{94, 96, 98, 99, 100, 101, 102, 105, 107, 110, 300\\} $$\nThe values to be replaced are the $g=2$ lowest ($94, 96$) and $g=2$ highest ($110, 300$). The lowest two are replaced by the $(g+1)$-th smallest value, which is $x_{(3)} = 98$. The highest two are replaced by the $(n-g)$-th value, which is $x_{(11-2)} = x_{(9)} = 107$.\nThe winsorized sample, $x_{\\text{win}}$, is:\n$$ \\{98, 98, 98, 99, 100, 101, 102, 105, 107, 107, 107\\} $$\nThe winsorized mean, $\\bar{x}_{\\text{win}}$, is:\n$$ \\sum x_{i, \\text{win}} = 3(98) + 99 + 100 + 101 + 102 + 105 + 3(107) = 294 + 607 + 321 = 1122 $$\n$$ \\bar{x}_{\\text{win}} = \\frac{1122}{11} = 102 $$\nThe winsorized unbiased sample variance, $S_{\\text{win}}^{2}$, is the variance of this new sample:\n$$ \\sum (x_{i, \\text{win}} - \\bar{x}_{\\text{win}})^2 = 3(98-102)^2 + (99-102)^2 + (100-102)^2 + (101-102)^2 + (102-102)^2 + (105-102)^2 + 3(107-102)^2 $$\n$$ = 3(-4)^2 + (-3)^2 + (-2)^2 + (-1)^2 + 0^2 + 3^2 + 3(5)^2 = 3(16)+9+4+1+0+9+3(25) = 48+9+4+1+0+9+75 = 146 $$\n$$ S_{\\text{win}}^{2} = \\frac{146}{11-1} = 14.6 $$\nThe winsorized $t$-like statistic, $t_{\\text{win}}$, is:\n$$ t_{\\text{win}} = \\frac{\\bar{x}_{\\text{win}} - \\mu_0}{\\sqrt{S_{\\text{win}}^{2}} / \\sqrt{n}} = \\frac{102 - 100}{\\sqrt{14.6} / \\sqrt{11}} = \\frac{2}{\\sqrt{14.6/11}} \\approx 1.7360 $$\n\nTo compare test decisions at $\\alpha = 0.05$ (two-sided):\nFor the outlier-inclusive test, we use $t_{\\text{out}} \\approx 1.0631$ with $df_{\\text{out}} = n-1 = 10$. The critical value is $t_{0.025, 10} = 2.228$. Since $|1.0631| < 2.228$, we fail to reject $H_0$.\nFor the winsorized test, a common practice is to use degrees of freedom $df_{\\text{win}} = n - 2g - 1 = 11 - 2(2) - 1 = 6$. The critical value is $t_{0.025, 6} = 2.447$. Since $|t_{\\text{win}}| \\approx 1.7360 < 2.447$, we also fail to reject $H_0$. The test decision does not change.\n\n**Final Calculation of $Q$**\n\nThe problem asks for the value of $Q = R - (|t_{\\text{win}}| - |t_{\\text{out}}|)$.\nUsing the computed values:\n$R = \\frac{894717}{6094} \\approx 146.81933$\n$|t_{\\text{win}}| = \\frac{2}{\\sqrt{14.6/11}} \\approx 1.736034$\n$|t_{\\text{out}}| = \\frac{212/11}{\\sqrt{198826/605}} \\approx 1.063116$\n$$ Q \\approx 146.81933 - (1.736034 - 1.063116) = 146.81933 - 0.672918 = 146.146412 $$\nRounding to four significant figures, we get $Q = 146.1$.",
            "answer": "$$\\boxed{146.1}$$"
        },
        {
            "introduction": "Before collecting a single data point, a well-designed study must answer a critical question: how many subjects are needed? This practice shifts our focus from data analysis to prospective study planning, a cornerstone of biostatistics. You will derive and apply the formula to calculate the sample size required for a one-sample z-test to achieve a desired statistical power, ensuring the study is equipped to detect a meaningful effect if one truly exists .",
            "id": "4934516",
            "problem": "A clinical biostatistics team is planning a one-sample test to determine whether the mean fasting plasma glucose level in a specific patient population differs from a known reference mean. Historical laboratory records support treating the population standard deviation as known and equal to $\\sigma=10$ (in milligrams per deciliter). The team wishes to design a two-sided one-sample $z$-test for the mean at significance level $\\alpha=0.05$ that will achieve power $0.80$ to detect a true mean difference of magnitude $\\delta=3$ from the reference.\n\nStarting from the normal modeling assumptions and the definitions of Type I error and power for the two-sided one-sample $z$-test (with known $\\sigma$), derive the sample size formula needed to plan such a study. Then compute the required sample size $n$ to achieve the specified power. When numerical approximation is necessary, round any intermediate quantile values to four significant figures. Report the final answer as the smallest integer value of $n$ that meets or exceeds the power target. The final answer must be a single number.",
            "solution": "The problem requires the derivation of a sample size formula for a two-sided one-sample $z$-test and the subsequent calculation of the required sample size $n$ for a specified set of parameters.\n\nLet $\\mu$ be the true mean fasting plasma glucose level in the patient population and $\\mu_0$ be the known reference mean. The population standard deviation is given as known, $\\sigma = 10$. The study concerns a random sample of size $n$, denoted $X_1, X_2, \\ldots, X_n$. We assume the observations are independent and identically distributed, drawn from a normal distribution, $X_i \\sim N(\\mu, \\sigma^2)$. The sample mean, $\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i$, is therefore also normally distributed: $\\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})$.\n\nThe null and alternative hypotheses for a two-sided test are:\n$$H_0: \\mu = \\mu_0$$\n$$H_a: \\mu \\neq \\mu_0$$\n\nThe test statistic is the one-sample $z$-statistic:\n$$Z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}$$\nUnder the null hypothesis $H_0$, the statistic $Z$ follows the standard normal distribution, $Z \\sim N(0, 1)$.\n\nThe Type I error rate, or significance level, is $\\alpha = 0.05$. For a two-sided test, we reject $H_0$ if the observed test statistic is in either tail of the distribution. The critical values are $\\pm z_{\\alpha/2}$, where $z_{\\alpha/2}$ is the upper $\\alpha/2$ quantile of the standard normal distribution. That is, $P(Z > z_{\\alpha/2}) = \\alpha/2$. The rejection region is defined by $|Z| > z_{\\alpha/2}$.\nIn terms of the sample mean $\\bar{X}$, we reject $H_0$ if:\n$$\\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}} > z_{\\alpha/2} \\quad \\text{or} \\quad \\frac{\\bar{X} - \\mu_0}{\\sigma/\\sqrt{n}}  -z_{\\alpha/2}$$\nThis is equivalent to rejecting $H_0$ if:\n$$\\bar{X} > \\mu_0 + z_{\\alpha/2}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\quad \\text{or} \\quad \\bar{X}  \\mu_0 - z_{\\alpha/2}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right)$$\n\nPower is the probability of correctly rejecting $H_0$ when the alternative hypothesis $H_a$ is true. The power is denoted by $1-\\beta$, where $\\beta$ is the Type II error rate. We are given the desired power is $1-\\beta = 0.80$. The test is designed to detect a specific alternative, namely that the true mean $\\mu_1$ differs from $\\mu_0$ by a magnitude of $\\delta=3$. So, under the alternative, $|\\mu_1 - \\mu_0| = \\delta$.\nWithout loss of generality, let us consider the case where $\\mu_1 = \\mu_0 + \\delta$. Under this specific alternative hypothesis, the sample mean $\\bar{X}$ is distributed as $N(\\mu_1, \\sigma^2/n)$.\n\nThe power is the probability that $\\bar{X}$ falls into the rejection region, given $\\mu = \\mu_1$:\n$$\\text{Power} = P\\left(\\bar{X} > \\mu_0 + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\text{ or } \\bar{X}  \\mu_0 - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}} \\;\\Bigg|\\; \\mu = \\mu_1\\right)$$\nTo evaluate this probability, we standardize $\\bar{X}$ using its distribution under $H_a$. Let $Z' = \\frac{\\bar{X} - \\mu_1}{\\sigma/\\sqrt{n}}$. Under $H_a$, $Z' \\sim N(0, 1)$. We can express $\\bar{X}$ as $\\bar{X} = \\mu_1 + Z'(\\sigma/\\sqrt{n})$. Substituting this into the power expression:\n$$\\text{Power} = P\\left(\\mu_1 + Z'\\frac{\\sigma}{\\sqrt{n}} > \\mu_0 + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right) + P\\left(\\mu_1 + Z'\\frac{\\sigma}{\\sqrt{n}}  \\mu_0 - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)$$\nSubstitute $\\mu_1 = \\mu_0 + \\delta$:\n$$\\text{Power} = P\\left(\\mu_0 + \\delta + Z'\\frac{\\sigma}{\\sqrt{n}} > \\mu_0 + z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right) + P\\left(\\mu_0 + \\delta + Z'\\frac{\\sigma}{\\sqrt{n}}  \\mu_0 - z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\\right)$$\nSimplifying the inequalities for $Z'$:\n$$P\\left(Z' > z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma}\\right) + P\\left(Z'  -z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma}\\right)$$\nSince $\\delta > 0$, the term $\\frac{\\delta\\sqrt{n}}{\\sigma}$ is positive. For typical parameters, the argument of the second probability, $-z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma}$, is a large negative number, making the probability $P(Z'  -z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma})$ negligible. Therefore, we can approximate the power by the first term:\n$$\\text{Power} \\approx P\\left(Z' > z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma}\\right)$$\nWe require this probability to be $1-\\beta$. Let $z_{\\beta}$ be the upper $\\beta$ quantile of the standard normal distribution, i.e., $P(Z' > z_{\\beta}) = \\beta$. This implies that $P(Z' \\le z_{\\beta}) = 1-\\beta$, and by symmetry, $P(Z' > -z_{\\beta}) = 1-\\beta$.\nThus, we set the lower bound of the probability integral equal to $-z_{\\beta}$:\n$$z_{\\alpha/2} - \\frac{\\delta\\sqrt{n}}{\\sigma} = -z_{\\beta}$$\nWe can now solve this equation for $n$.\n$$\\frac{\\delta\\sqrt{n}}{\\sigma} = z_{\\alpha/2} + z_{\\beta}$$\n$$\\sqrt{n} = \\frac{\\sigma (z_{\\alpha/2} + z_{\\beta})}{\\delta}$$\nSquaring both sides gives the required sample size formula:\n$$n = \\frac{\\sigma^2 (z_{\\alpha/2} + z_{\\beta})^2}{\\delta^2}$$\nThis is the general formula for the sample size of a two-sided, one-sample $z$-test.\n\nNext, we compute the numerical value for $n$ using the given parameters:\n- Population standard deviation: $\\sigma = 10$.\n- Magnitude of the difference to detect: $\\delta = 3$.\n- Significance level: $\\alpha = 0.05$.\n- Desired power: $1-\\beta = 0.80$, which implies $\\beta = 0.20$.\n\nWe need the values of the standard normal quantiles, rounded to four significant figures as per the problem's instruction.\nFor $\\alpha = 0.05$, we need $z_{\\alpha/2} = z_{0.025}$. This is the value such that the cumulative probability is $1 - 0.025 = 0.975$. From a standard normal table or calculator, $z_{0.025} \\approx 1.95996$. Rounded to four significant figures, $z_{0.025} = 1.960$.\nFor $\\beta = 0.20$, we need $z_{\\beta} = z_{0.20}$. This is the value such that the cumulative probability is $1-0.20 = 0.80$. From a standard normal table or calculator, $z_{0.20} \\approx 0.84162$. Rounded to four significant figures, $z_{0.20} = 0.8416$.\n\nNow, we substitute these values into the derived formula:\n$$n = \\frac{(10)^2 (1.960 + 0.8416)^2}{(3)^2}$$\n$$n = \\frac{100 (2.8016)^2}{9}$$\nFirst, calculate the square of the sum of quantiles:\n$$(2.8016)^2 = 7.84896256$$\nThen, compute $n$:\n$$n = \\frac{100 \\times 7.84896256}{9} = \\frac{784.896256}{9} \\approx 87.210695\\ldots$$\nThe sample size must be an integer. To ensure that the power is at least $0.80$, we must round the calculated value of $n$ up to the next largest integer.\n$$n = \\lceil 87.210695\\ldots \\rceil = 88$$\nTherefore, a sample size of $88$ is required to achieve the specified power.",
            "answer": "$$\\boxed{88}$$"
        }
    ]
}