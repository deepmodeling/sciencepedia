{
    "hands_on_practices": [
        {
            "introduction": "This practice extends the basic concept of a confidence interval for variance from a single sample to the more common setting of linear regression. Here, we'll use the residual sum of squares to estimate the error variance, $\\sigma^2$, which often represents measurement noise or unexplained biological variability. This exercise is crucial for understanding the precision of predictive models and quantifying the uncertainty around it .",
            "id": "4903186",
            "problem": "A biomedical engineering team is calibrating a new sensor that estimates a continuous biomarker from measured covariates using a linear model. They fit a normal linear regression with $p=5$ unknown coefficients (including the intercept) to $n=40$ independent observations, where the error term represents the sensor’s measurement noise. The residual sum of squares is reported as $\\text{RSS}=78$ in the squared units of the biomarker. Assume the classical normal linear model with independent, identically distributed Gaussian errors of mean $0$ and variance $\\sigma^{2}$.\n\nStarting from fundamental distributional properties of the residual sum of squares under the normal linear model, construct a two-sided $95\\%$ confidence interval for the error variance $\\sigma^{2}$, and then compute its numerical endpoints using appropriate quantiles. Finally, interpret this interval as describing plausible values of the sensor’s measurement error variance for the underlying data-generating process.\n\nRound your interval endpoints to three significant figures and express them in the squared units of the biomarker response variable.",
            "solution": "The problem is well-posed and scientifically sound, resting on the fundamental principles of statistical inference for the normal linear model. We may proceed with a solution.\n\nThe problem asks for a two-sided $95\\%$ confidence interval for the error variance, $\\sigma^2$, of a normal linear regression model. The model is fitted to $n=40$ independent observations with $p=5$ unknown coefficients. The residual sum of squares is given as $\\text{RSS}=78$.\n\nThe theoretical foundation for this problem is a key result in linear model theory. For a classical normal linear model, $Y = X\\beta + \\epsilon$, where the errors $\\epsilon_i$ are independent and identically distributed as $N(0, \\sigma^2)$, the quantity $\\frac{\\text{RSS}}{\\sigma^2}$ follows a chi-squared distribution. The degrees of freedom for this distribution are $df = n - p$, where $n$ is the number of observations and $p$ is the number of estimated regression coefficients (including the intercept).\n\nFirst, we identify the given parameters:\n- Number of observations, $n = 40$.\n- Number of regression coefficients, $p = 5$.\n- Residual Sum of Squares, $\\text{RSS} = 78$.\n- The confidence level is $95\\%$, which corresponds to a significance level $\\alpha = 1 - 0.95 = 0.05$.\n\nThe degrees of freedom for the chi-squared distribution are calculated as:\n$$ df = n - p = 40 - 5 = 35 $$\nThus, the pivotal quantity $\\frac{\\text{RSS}}{\\sigma^2}$ follows a chi-squared distribution with $35$ degrees of freedom:\n$$ \\frac{\\text{RSS}}{\\sigma^2} \\sim \\chi^2_{35} $$\nTo construct a two-sided $100(1-\\alpha)\\%$ confidence interval for $\\sigma^2$, we find two quantiles of the $\\chi^2_{35}$ distribution, $\\chi^2_{1-\\alpha/2, df}$ and $\\chi^2_{\\alpha/2, df}$, such that:\n$$ P\\left( \\chi^2_{1-\\alpha/2, df} < \\frac{\\text{RSS}}{\\sigma^2} < \\chi^2_{\\alpha/2, df} \\right) = 1 - \\alpha $$\nHere, $\\chi^2_{q, df}$ denotes the value such that the area to its right under the $\\chi^2_{df}$ probability density function is $q$.\n\nWith $\\alpha = 0.05$, we need the quantiles corresponding to tail probabilities of $\\alpha/2 = 0.025$ and $1 - \\alpha/2 = 0.975$.\nThe lower critical value is $\\chi^2_{1-\\alpha/2, df} = \\chi^2_{0.975, 35}$.\nThe upper critical value is $\\chi^2_{\\alpha/2, df} = \\chi^2_{0.025, 35}$.\n\nUsing a statistical table or software for the $\\chi^2$ distribution with $df=35$:\n- The lower critical value is $\\chi^2_{0.975, 35} \\approx 20.569$. This is the value for which $P(\\chi^2_{35} > 20.569) = 0.975$, or equivalently, $P(\\chi^2_{35} < 20.569) = 0.025$.\n- The upper critical value is $\\chi^2_{0.025, 35} \\approx 53.203$. This is the value for which $P(\\chi^2_{35} > 53.203) = 0.025$.\n\nNow, we rearrange the inequalities in the probability statement to isolate $\\sigma^2$:\nThe left inequality:\n$$ \\chi^2_{0.975, 35} < \\frac{\\text{RSS}}{\\sigma^2} \\implies \\sigma^2 < \\frac{\\text{RSS}}{\\chi^2_{0.975, 35}} $$\nThe right inequality:\n$$ \\frac{\\text{RSS}}{\\sigma^2} < \\chi^2_{0.025, 35} \\implies \\frac{\\text{RSS}}{\\chi^2_{0.025, 35}} < \\sigma^2 $$\nCombining these gives the $95\\%$ confidence interval for $\\sigma^2$:\n$$ \\left( \\frac{\\text{RSS}}{\\chi^2_{0.025, 35}}, \\frac{\\text{RSS}}{\\chi^2_{0.975, 35}} \\right) $$\nSubstituting the numerical values:\n- Lower bound: $\\frac{78}{53.203} \\approx 1.46608$\n- Upper bound: $\\frac{78}{20.569} \\approx 3.79211$\n\nThe problem requires rounding the interval endpoints to three significant figures.\n- Lower bound rounded to three significant figures is $1.47$.\n- Upper bound rounded to three significant figures is $3.79$.\n\nThe resulting $95\\%$ confidence interval for the error variance $\\sigma^2$ is $(1.47, 3.79)$, with units being the squared units of the biomarker.\n\nFinally, we interpret this interval. We are $95\\%$ confident that the true, unknown variance of the sensor's measurement error, $\\sigma^2$, lies between $1.47$ and $3.79$ squared units of the biomarker. This interval provides a range of plausible values for the population error variance that are consistent with the observed data from the experiment. It quantifies the uncertainty in our estimate of the sensor's precision.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1.47 & 3.79 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "The standard chi-squared method for a variance confidence interval rests on strong assumptions, particularly that observations are independent. This hands-on coding exercise challenges you to investigate what happens when this assumption is violated, a common scenario in biostatistics with clustered data like patients within hospitals. By simulating data with intracluster correlation and comparing the standard method to a cluster bootstrap approach, you will empirically discover the risks of ignoring data dependencies and learn a powerful, modern technique to address them .",
            "id": "4903180",
            "problem": "You are to write a complete and runnable program that uses Monte Carlo simulation to compare the empirical coverage of two different confidence interval constructions for a population variance under clustered (intracluster-correlated) sampling. The two methods are: (i) an independence-based confidence interval obtained by inverting the known sampling distribution of the sample variance under independent and identically distributed normal data, and (ii) a design-based confidence interval constructed via cluster bootstrap resampling. Your task is to quantify the undercoverage risk when the intracluster correlation is substantial.\n\nStart from the following fundamental base:\n- Under independent and identically distributed normal sampling, the sampling distribution of the sample variance admits an exact form that enables interval inversion.\n- Under multistage or clustered sampling, Primary Sampling Units (PSUs) can be used for design-based resampling that preserves the dependence structure within clusters.\n- In a two-level Gaussian random effects model, intracluster correlation can be generated by a shared cluster-level effect added to independent within-cluster errors.\n\nThe data generating mechanism for each dataset is as follows. For given numbers of clusters $C$ and cluster size $m$, generate observations $\\{Y_{ij} : i = 1,\\dots,C,\\ j = 1,\\dots,m\\}$ from\n$$\nY_{ij} \\;=\\; \\mu \\;+\\; U_i \\;+\\; \\varepsilon_{ij},\n$$\nwhere $U_i \\sim \\mathcal{N}(0,\\sigma_b^2)$, $\\varepsilon_{ij} \\sim \\mathcal{N}(0,\\sigma_w^2)$, all mutually independent, with the total marginal variance $\\sigma^2 = \\sigma_b^2 + \\sigma_w^2$ and the intracluster correlation $\\rho = \\sigma_b^2/\\sigma^2$. Set $\\mu = 0$ without loss of generality. For each simulated dataset, compute the usual unbiased sample variance\n$$\nS^2 \\;=\\; \\frac{1}{n-1}\\sum_{i=1}^C \\sum_{j=1}^m \\big(Y_{ij} - \\overline{Y}\\big)^2, \\quad \\text{where } n = C m \\text{ and } \\overline{Y} \\text{ is the overall sample mean.}\n$$\n\nFor each dataset, construct two two-sided confidence intervals at nominal level $1-\\alpha$ for the population variance $\\sigma^2$:\n1. Independence-based interval: invert the exact sampling distribution of $S^2$ under independent and identically distributed normal observations (treating the $n$ observations as independent).\n2. Design-based interval: perform cluster bootstrap resampling by resampling the $C$ clusters with replacement, keeping all $m$ observations within any resampled cluster intact. For each bootstrap resample, recompute $S^2$ from the pooled resampled observations. Use the percentile method from the bootstrap empirical distribution of $S^2$ to form a two-sided confidence interval.\n\nDefine the empirical coverage for a method as the proportion of simulated datasets for which the interval contains the true $\\sigma^2$. Define the undercoverage risk as the nonnegative difference between the nominal coverage and the empirical coverage:\n$$\n\\text{undercoverage} \\;=\\; \\max\\{(1-\\alpha) - \\widehat{\\text{coverage}},\\ 0\\}.\n$$\n\nUse the following test suite of parameter values, which spans both substantial intracluster correlation and a boundary condition:\n- Case A: $C = 20$, $m = 10$, $\\sigma^2 = 1.0$, $\\rho = 0.3$.\n- Case B: $C = 8$, $m = 20$, $\\sigma^2 = 1.5$, $\\rho = 0.6$.\n- Case C: $C = 50$, $m = 5$, $\\sigma^2 = 2.0$, $\\rho = 0.4$.\n- Case D (boundary, no clustering): $C = 20$, $m = 10$, $\\sigma^2 = 1.0$, $\\rho = 0.0$.\n\nImplement the following simulation settings for all cases:\n- Nominal level: $\\alpha = 0.05$.\n- Monte Carlo replicates per case: $R = 400$.\n- Bootstrap resamples per dataset for the design-based procedure: $B = 200$.\n- Random seed: set to $12345$ for reproducibility.\n\nYour program must:\n- For each case, generate $R$ datasets under the model above using the specified $C$, $m$, $\\sigma^2$, and $\\rho$.\n- For each dataset, compute the two confidence intervals, and record whether the true $\\sigma^2$ lies within each interval.\n- For each case, report four quantities in the following order: empirical coverage of the design-based interval, empirical coverage of the independence-based interval, undercoverage risk of the design-based interval, undercoverage risk of the independence-based interval. Each quantity must be represented as a float.\n\nFinal output format:\n- Your program should produce a single line of output containing a list of length $4$, where each element is a list of the four floats corresponding to one case, in the order A, B, C, D. For example:\n$[\\,[\\text{cov\\_design\\_A},\\text{cov\\_indep\\_A},\\text{under\\_design\\_A},\\text{under\\_indep\\_A}],\\dots]$.\n- Round each reported float to three decimal places.",
            "solution": "The problem as stated is valid. It is scientifically grounded in statistical theory, well-posed with all necessary parameters and definitions provided, and presented in an objective, formal manner. It poses a non-trivial comparison between two standard statistical methods under conditions designed to highlight their differing theoretical underpinnings. We may therefore proceed with a solution.\n\nThe objective is to conduct a Monte Carlo simulation to evaluate and compare the empirical coverage properties of two distinct confidence interval estimators for a population variance, $\\sigma^2$. The comparison is performed under conditions of clustered data, which introduces intracluster correlation, a feature known to violate the assumptions of classical statistical methods. The two estimators are: ($i$) a parametric interval based on the chi-squared distribution, which assumes independent and identically distributed (IID) normal data, and ($ii$) a non-parametric, design-based interval constructed using a cluster bootstrap procedure that accounts for the data's dependence structure.\n\n**Data Generation Process**\n\nFor each simulation, we generate a dataset of $n=Cm$ observations, organized into $C$ clusters of size $m$. The data are generated from a two-level Gaussian random effects model:\n$$\nY_{ij} = \\mu + U_i + \\varepsilon_{ij}\n$$\nfor cluster $i \\in \\{1, \\dots, C\\}$ and observation $j \\in \\{1, \\dots, m\\}$. The parameters are defined as:\n- $\\mu$: The overall population mean, which can be set to $0$ without loss of generality as the sample variance is location-invariant.\n- $U_i$: A cluster-specific random effect, drawn from a normal distribution $U_i \\sim \\mathcal{N}(0, \\sigma_b^2)$. These effects are independent across clusters.\n- $\\varepsilon_{ij}$: An individual-level random error, drawn from a normal distribution $\\varepsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_w^2)$. These errors are mutually independent and independent of the $U_i$.\n\nThe total marginal variance of any observation $Y_{ij}$ is the target parameter $\\sigma^2$, given by the sum of the variance components: $\\sigma^2 = \\sigma_b^2 + \\sigma_w^2$.\nThe intracluster correlation coefficient (ICC), $\\rho$, measures the correlation between two distinct observations within the same cluster. It is defined as:\n$$\n\\rho = \\text{Corr}(Y_{ij}, Y_{ik}) = \\frac{\\text{Cov}(U_i+\\varepsilon_{ij}, U_i+\\varepsilon_{ik})}{\\sigma^2} = \\frac{\\text{Var}(U_i)}{\\sigma^2} = \\frac{\\sigma_b^2}{\\sigma^2} \\quad \\text{for } j \\neq k.\n$$\nGiven the simulation parameters $\\sigma^2$ and $\\rho$, the variance components are determined by $\\sigma_b^2 = \\rho \\sigma^2$ and $\\sigma_w^2 = (1-\\rho)\\sigma^2$.\n\nFor each generated dataset, the unbiased sample variance is computed as:\n$$\nS^2 = \\frac{1}{n-1} \\sum_{i=1}^C \\sum_{j=1}^m \\left(Y_{ij} - \\overline{Y}\\right)^2\n$$\nwhere $n=Cm$ is the total number of observations and $\\overline{Y} = \\frac{1}{n}\\sum_{i=1}^C \\sum_{j=1}^m Y_{ij}$ is the overall sample mean.\n\n**Confidence Interval Methodologies**\n\nWe construct two types of two-sided confidence intervals for $\\sigma^2$ at a nominal confidence level of $1-\\alpha$.\n\n1.  **Independence-Based (Chi-Squared) Interval:**\n    This method proceeds by incorrectly assuming the $n=Cm$ observations are IID draws from a $\\mathcal{N}(\\mu, \\sigma^2)$ distribution. Under this assumption, the pivotal quantity $\\frac{(n-1)S^2}{\\sigma^2}$ follows a chi-squared distribution with $n-1$ degrees of freedom, denoted $\\chi^2_{n-1}$.\n    By inverting the probability statement $P\\left(\\chi^2_{n-1, \\alpha/2} \\le \\frac{(n-1)S^2}{\\sigma^2} \\le \\chi^2_{n-1, 1-\\alpha/2}\\right) = 1-\\alpha$, where $\\chi^2_{df, q}$ is the $q$-th quantile of the $\\chi^2_{df}$ distribution, we obtain the $(1-\\alpha)$ confidence interval for $\\sigma^2$:\n    $$\n    CI_{\\text{indep}} = \\left[ \\frac{(n-1)S^2}{\\chi^2_{n-1, 1-\\alpha/2}}, \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha/2}} \\right]\n    $$\n    When $\\rho > 0$, the IID assumption is violated, and this interval is expected to exhibit poor coverage performance, typically undercovering the true $\\sigma^2$ because the data contain less information than $n$ independent observations would.\n\n2.  **Design-Based (Cluster Bootstrap) Interval:**\n    This method is designed to be robust to the dependence structure within clusters. It treats the clusters (Primary Sampling Units, or PSUs) as the units of observation for resampling. The procedure is as follows:\n    a.  From the original set of $C$ clusters $\\{ (Y_{11}, \\dots, Y_{1m}), \\dots, (Y_{C1}, \\dots, Y_{Cm}) \\}$, draw a sample of $C$ clusters with replacement.\n    b.  Combine the observations from these resampled clusters to form a bootstrap dataset.\n    c.  Compute the sample variance $S^2_*$ from this bootstrap dataset.\n    d.  Repeat steps a-c $B$ times to obtain a collection of bootstrap variance estimates $\\{S^2_{*b}\\}_{b=1}^B$.\n    e.  The $(1-\\alpha)$ percentile bootstrap confidence interval is formed by the empirical $\\alpha/2$ and $1-\\alpha/2$ quantiles of the bootstrap distribution:\n    $$\n    CI_{\\text{design}} = \\left[ Q_{\\alpha/2}(S^2_{*}), Q_{1-\\alpha/2}(S^2_{*}) \\right]\n    $$\n    This method is expected to provide coverage closer to the nominal level $1-\\alpha$ because the resampling scheme preserves the correlation structure of the original data generation process.\n\n**Simulation Execution and Analysis**\n\nThe simulation will be run for each of the four specified cases (A, B, C, D) using $R=400$ Monte Carlo replicates. For each replicate, both confidence intervals are constructed and tested for coverage of the true $\\sigma^2$. The empirical coverage for a method is the fraction of the $R$ intervals that contain $\\sigma^2$. The undercoverage risk is calculated as $\\max\\{(1-\\alpha) - \\widehat{\\text{coverage}}, 0\\}$. For the specified $\\alpha=0.05$, the nominal coverage is $0.95$. A random seed is fixed at $12345$ for reproducibility. Finally, the results—empirical coverages and undercoverage risks for both methods for all four cases—are reported, rounded to three decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef run_simulation_case(C, m, sigma2, rho, alpha, R, B, rng):\n    \"\"\"\n    Runs a Monte Carlo simulation for a single parameter case.\n\n    Args:\n        C (int): Number of clusters.\n        m (int): Size of each cluster.\n        sigma2 (float): True population variance.\n        rho (float): Intracluster correlation.\n        alpha (float): Significance level for confidence intervals.\n        R (int): Number of Monte Carlo replicates.\n        B (int): Number of bootstrap resamples.\n        rng (np.random.Generator): A NumPy random number generator instance.\n\n    Returns:\n        tuple: A tuple containing four floats:\n               (empirical_coverage_design, empirical_coverage_indep,\n                undercoverage_risk_design, undercoverage_risk_indep).\n    \"\"\"\n    n = C * m\n    df = n - 1\n    nominal_coverage = 1.0 - alpha\n\n    # Derived variance components\n    sigma_b2 = rho * sigma2\n    sigma_w2 = (1.0 - rho) * sigma2\n    sigma_b = np.sqrt(sigma_b2) if sigma_b2 > 0 else 0\n    sigma_w = np.sqrt(sigma_w2) if sigma_w2 > 0 else 0\n\n    # Chi-squared quantiles for the independence-based interval\n    # These are constant for a given case\n    chi2_q_upper = chi2.ppf(1 - alpha / 2, df)\n    chi2_q_lower = chi2.ppf(alpha / 2, df)\n\n    coverage_indep_count = 0\n    coverage_design_count = 0\n\n    for _ in range(R):\n        # 1. Generate data from the random effects model\n        # Cluster effects U_i ~ N(0, sigma_b^2)\n        U = rng.normal(loc=0.0, scale=sigma_b, size=C)\n        # Individual errors e_ij ~ N(0, sigma_w^2)\n        epsilon = rng.normal(loc=0.0, scale=sigma_w, size=(C, m))\n        # Form observations Y_ij = U_i + e_ij\n        Y = U[:, np.newaxis] + epsilon\n\n        # 2. Compute the overall sample variance S^2\n        y_flat = Y.flatten()\n        S2 = np.var(y_flat, ddof=1)\n\n        # 3. Construct and check independence-based CI\n        ci_indep_low = (df * S2) / chi2_q_upper\n        ci_indep_high = (df * S2) / chi2_q_lower\n        if ci_indep_low <= sigma2 <= ci_indep_high:\n            coverage_indep_count += 1\n\n        # 4. Construct and check design-based (cluster bootstrap) CI\n        bootstrap_S2_values = []\n        for _ in range(B):\n            # Resample clusters with replacement\n            cluster_indices = rng.choice(C, size=C, replace=True)\n            Y_bootstrap = Y[cluster_indices, :]\n            \n            # Compute variance for the bootstrap sample\n            S2_bootstrap = np.var(Y_bootstrap.flatten(), ddof=1)\n            bootstrap_S2_values.append(S2_bootstrap)\n        \n        # Percentile method\n        ci_design_low = np.percentile(bootstrap_S2_values, 100 * (alpha / 2))\n        ci_design_high = np.percentile(bootstrap_S2_values, 100 * (1 - alpha / 2))\n        \n        if ci_design_low <= sigma2 <= ci_design_high:\n            coverage_design_count += 1\n            \n    # 5. Calculate empirical coverages\n    emp_cov_design = coverage_design_count / R\n    emp_cov_indep = coverage_indep_count / R\n\n    # 6. Calculate undercoverage risks\n    under_risk_design = max(nominal_coverage - emp_cov_design, 0)\n    under_risk_indep = max(nominal_coverage - emp_cov_indep, 0)\n\n    # 7. Round results to three decimal places\n    return (\n        round(emp_cov_design, 3),\n        round(emp_cov_indep, 3),\n        round(under_risk_design, 3),\n        round(under_risk_indep, 3)\n    )\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    # Define problem parameters\n    alpha = 0.05\n    R = 400\n    B = 200\n    seed = 12345\n\n    # Initialize the random number generator\n    rng = np.random.default_rng(seed)\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        # Case A\n        {'C': 20, 'm': 10, 'sigma2': 1.0, 'rho': 0.3},\n        # Case B\n        {'C': 8, 'm': 20, 'sigma2': 1.5, 'rho': 0.6},\n        # Case C\n        {'C': 50, 'm': 5, 'sigma2': 2.0, 'rho': 0.4},\n        # Case D (boundary, no clustering)\n        {'C': 20, 'm': 10, 'sigma2': 1.0, 'rho': 0.0},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        case_results = run_simulation_case(\n            case['C'], case['m'], case['sigma2'], case['rho'],\n            alpha, R, B, rng\n        )\n        all_results.append(list(case_results))\n\n    # Format the output as specified\n    print(all_results)\n\nsolve()\n```"
        },
        {
            "introduction": "Beyond correctly calculating an interval, a skilled biostatistician must choose the right statistical tool for the job. This exercise introduces a decision-theoretic framework where the choice between a one-sided and a two-sided confidence interval is guided by the real-world consequences of making a mistake. By analyzing a scenario with asymmetric costs for under- or overestimating variance, you will learn to justify your choice of interval based on the specific goals and risks of a study .",
            "id": "4903175",
            "problem": "A laboratory assay validation study collects $n$ independent and identically distributed (i.i.d.) observations from a population modeled as normal with unknown mean $\\mu$ and unknown variance $\\sigma^{2}$. The analyst must summarize uncertainty about $\\sigma^{2}$ by reporting one of two standard exact procedures that achieve nominal coverage under the normal model:\n- Policy $\\mathrm{T}$: the equal-tailed two-sided confidence interval (CI) for $\\sigma^{2}$ with nominal coverage $1-\\alpha$.\n- Policy $\\mathrm{L}$: the one-sided lower CI for $\\sigma^{2}$ with nominal coverage $1-\\alpha$, reported as $[L,\\infty)$.\n\nIn this application, under-reporting variability is more harmful than over-reporting. To formalize this asymmetry, define the loss for reporting interval $I$ as\n$$\n\\mathcal{L}(\\sigma^{2}, I)=\n\\begin{cases}\n0, & \\text{if } \\sigma^{2}\\in I,\\\\\nc_{\\text{under}}, & \\text{if } \\sup(I)<\\sigma^{2}\\ \\text{(interval entirely below the true value; underestimation)},\\\\\nc_{\\text{over}}, & \\text{if } \\inf(I)>\\sigma^{2}\\ \\text{(interval entirely above the true value; overestimation)},\n\\end{cases}\n$$\nwith $c_{\\text{under}}>c_{\\text{over}}>0$. Assume each policy’s interval is constructed from the same sample and that both policies attain their nominal coverage $1-\\alpha$ under the normal model.\n\nWhich statement is correct under this loss structure?\n\nA. Under any $c_{\\text{under}}>c_{\\text{over}}$, Policy $\\mathrm{L}$ yields a smaller expected loss than Policy $\\mathrm{T}$; both have coverage $1-\\alpha$, but Policy $\\mathrm{L}$ allocates all noncoverage to overestimation. Moreover, Policy $\\mathrm{T}$ has finite expected length proportional to $\\sigma^{2}$, whereas Policy $\\mathrm{L}$ has infinite expected length.\n\nB. Under any $c_{\\text{under}}>c_{\\text{over}}$, Policy $\\mathrm{T}$ yields a smaller expected loss because it halves the probability of overestimation relative to Policy $\\mathrm{L}$; additionally, both policies have finite expected lengths.\n\nC. The policies have identical expected loss for all $c_{\\text{under}},c_{\\text{over}}$ because both have coverage $1-\\alpha$; furthermore, Policy $\\mathrm{L}$ has a shorter expected length since it reports only one bound.\n\nD. Policy $\\mathrm{L}$ has coverage $1-\\alpha/2$ and zero probability of overestimation, so for $c_{\\text{under}}>c_{\\text{over}}$ its expected loss is always zero.",
            "solution": "The problem statement is scientifically grounded, self-contained, and well-posed. It presents a standard decision-theoretic comparison of two common statistical procedures under a clearly defined loss function. The premises are consistent with established principles of statistical inference for the normal distribution. We may therefore proceed with the solution.\n\nLet the $n$ i.i.d. observations be $X_1, \\dots, X_n$ from a $N(\\mu, \\sigma^2)$ distribution. Let $S^2$ be the unbiased sample variance, $S^2 = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar{X})^2$. The pivotal quantity for the variance $\\sigma^2$ is $V = \\frac{(n-1)S^2}{\\sigma^2}$, which follows a chi-squared distribution with $n-1$ degrees of freedom, denoted $\\chi^2_{n-1}$. We denote the upper $\\gamma$ quantile of this distribution as $\\chi^2_{n-1, \\gamma}$, such that $P(V > \\chi^2_{n-1, \\gamma}) = \\gamma$.\n\nFirst, we formalize the two policies and their properties.\n\n**Policy T: Equal-tailed two-sided Confidence Interval (CI)**\nA $(1-\\alpha)$ two-sided CI for $\\sigma^2$ is of the form $\\left( \\frac{(n-1)S^2}{b}, \\frac{(n-1)S^2}{a} \\right)$. For an equal-tailed interval, the total non-coverage probability of $\\alpha$ is split equally between the two tails of the chi-squared distribution. We find constants $a$ and $b$ such that $P(V < a) = \\alpha/2$ and $P(V > b) = \\alpha/2$. This implies that $a = \\chi^2_{n-1, 1-\\alpha/2}$ and $b = \\chi^2_{n-1, \\alpha/2}$.\nThe interval for Policy T is $I_T = \\left[ \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha/2}}, \\frac{(n-1)S^2}{\\chi^2_{n-1, 1-\\alpha/2}} \\right]$.\n\nThe events for the loss function $\\mathcal{L}(\\sigma^2, I_T)$ are:\n1.  **Coverage ($\\sigma^2 \\in I_T$)**: The event of coverage has probability $1-\\alpha$ by construction. The loss is $0$.\n2.  **Underestimation ($\\sup(I_T) < \\sigma^2$)**: This occurs if $\\frac{(n-1)S^2}{\\chi^2_{n-1, 1-\\alpha/2}} < \\sigma^2$, which is equivalent to $\\frac{(n-1)S^2}{\\sigma^2} < \\chi^2_{n-1, 1-\\alpha/2}$. The probability of this event is $P(V < \\chi^2_{n-1, 1-\\alpha/2}) = \\alpha/2$. The loss is $c_{\\text{under}}$.\n3.  **Overestimation ($\\inf(I_T) > \\sigma^2$)**: This occurs if $\\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha/2}} > \\sigma^2$, which is equivalent to $\\frac{(n-1)S^2}{\\sigma^2} > \\chi^2_{n-1, \\alpha/2}$. The probability of this event is $P(V > \\chi^2_{n-1, \\alpha/2}) = \\alpha/2$. The loss is $c_{\\text{over}}$.\n\nThe expected loss for Policy T is:\n$$E[\\mathcal{L}(\\sigma^2, I_T)] = (0)(1-\\alpha) + c_{\\text{under}}(\\alpha/2) + c_{\\text{over}}(\\alpha/2) = \\frac{\\alpha}{2} (c_{\\text{under}} + c_{\\text{over}})$$\n\n**Policy L: One-sided lower CI**\nA $(1-\\alpha)$ one-sided lower CI for $\\sigma^2$ is of the form $[L, \\infty)$. The lower bound $L$ is determined such that $P(L \\le \\sigma^2) = 1-\\alpha$. This implies $P(L > \\sigma^2) = \\alpha$, which constitutes the overestimation event. The interval is derived from the relation $P(\\frac{(n-1)S^2}{\\sigma^2} \\le \\chi^2_{n-1, \\alpha}) = 1-\\alpha$, which rearranges to $P(\\sigma^2 \\ge \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha}}) = 1-\\alpha$.\nThus, the interval for Policy L is $I_L = \\left[ \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha}}, \\infty \\right)$.\n\nThe events for the loss function $\\mathcal{L}(\\sigma^2, I_L)$ are:\n1.  **Coverage ($\\sigma^2 \\in I_L$)**: The event of coverage has probability $1-\\alpha$. The loss is $0$.\n2.  **Underestimation ($\\sup(I_L) < \\sigma^2$)**: This event is $\\infty < \\sigma^2$, which is impossible. Its probability is $0$. The loss would be $c_{\\text{under}}$.\n3.  **Overestimation ($\\inf(I_L) > \\sigma^2$)**: This occurs if $\\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha}} > \\sigma^2$, equivalent to $\\frac{(n-1)S^2}{\\sigma^2} > \\chi^2_{n-1, \\alpha}$. The probability of this event is $P(V > \\chi^2_{n-1, \\alpha}) = \\alpha$. The loss is $c_{\\text{over}}$.\n\nThe expected loss for Policy L is:\n$$E[\\mathcal{L}(\\sigma^2, I_L)] = (0)(1-\\alpha) + c_{\\text{under}}(0) + c_{\\text{over}}(\\alpha) = \\alpha \\cdot c_{\\text{over}}$$\n\n**Comparison of Expected Losses**\nWe compare $E[\\mathcal{L}(\\sigma^2, I_T)]$ with $E[\\mathcal{L}(\\sigma^2, I_L)]$. Policy L has a smaller expected loss if $E[\\mathcal{L}(\\sigma^2, I_L)] < E[\\mathcal{L}(\\sigma^2, I_T)]$.\n$$ \\alpha \\cdot c_{\\text{over}} < \\frac{\\alpha}{2} (c_{\\text{under}} + c_{\\text{over}}) $$\nSince $\\alpha > 0$, we can divide by $\\alpha$:\n$$ c_{\\text{over}} < \\frac{1}{2} (c_{\\text{under}} + c_{\\text{over}}) $$\n$$ 2c_{\\text{over}} < c_{\\text{under}} + c_{\\text{over}} $$\n$$ c_{\\text{over}} < c_{\\text{under}} $$\nThis inequality is given in the problem statement ($c_{\\text{under}} > c_{\\text{over}} > 0$). Therefore, Policy L yields a smaller expected loss than Policy T. The reason is that Policy L completely avoids the more costly error of underestimation, at the expense of doubling the probability of the less costly error of overestimation.\n\n**Comparison of Expected Lengths**\nThe length of interval $I_T$ is $\\text{Length}(I_T) = \\frac{(n-1)S^2}{\\chi^2_{n-1, 1-\\alpha/2}} - \\frac{(n-1)S^2}{\\chi^2_{n-1, \\alpha/2}} = S^2 \\cdot (n-1) \\left(\\frac{1}{\\chi^2_{n-1, 1-\\alpha/2}} - \\frac{1}{\\chi^2_{n-1, \\alpha/2}}\\right)$.\nSince $E[S^2] = \\sigma^2$, the expected length is finite and proportional to $\\sigma^2$:\n$$E[\\text{Length}(I_T)] = \\sigma^2 \\cdot (n-1) \\left(\\frac{1}{\\chi^2_{n-1, 1-\\alpha/2}} - \\frac{1}{\\chi^2_{n-1, \\alpha/2}}\\right)$$\nThe length of interval $I_L = [L, \\infty)$ is infinite. Its expected length is therefore also infinite.\n\n**Evaluation of Options**\n\nA. Under any $c_{\\text{under}}>c_{\\text{over}}$, Policy $\\mathrm{L}$ yields a smaller expected loss than Policy $\\mathrm{T}$; both have coverage $1-\\alpha$, but Policy $\\mathrm{L}$ allocates all noncoverage to overestimation. Moreover, Policy $\\mathrm{T}$ has finite expected length proportional to $\\sigma^{2}$, whereas Policy $\\mathrm{L}$ has infinite expected length.\n- \"Policy L yields a smaller expected loss than Policy T\": Correct, as derived above.\n- \"both have coverage $1-\\alpha$\": Correct, as assumed in the problem.\n- \"Policy L allocates all noncoverage to overestimation\": Correct. The probability of underestimation for Policy L is $0$.\n- \"Policy T has finite expected length proportional to $\\sigma^2$\": Correct.\n- \"Policy L has infinite expected length\": Correct.\nAll statements in this option are accurate.\nVerdict: **Correct**.\n\nB. Under any $c_{\\text{under}}>c_{\\text{over}}$, Policy $\\mathrm{T}$ yields a smaller expected loss because it halves the probability of overestimation relative to Policy $\\mathrm{L}$; additionally, both policies have finite expected lengths.\n- \"Policy T yields a smaller expected loss\": Incorrect. Our derivation shows Policy L has the smaller expected loss.\n- \"both policies have finite expected lengths\": Incorrect. Policy L has infinite expected length.\nVerdict: **Incorrect**.\n\nC. The policies have identical expected loss for all $c_{\\text{under}},c_{\\text{over}}$ because both have coverage $1-\\alpha$; furthermore, Policy $\\mathrm{L}$ has a shorter expected length since it reports only one bound.\n- \"The policies have identical expected loss\": Incorrect. Their expected losses are different whenever $c_{\\text{under}} \\neq c_{\\text{over}}$.\n- \"the reason being both have coverage $1-\\alpha$\": This reasoning is fallacious. The type of non-coverage matters for the loss function.\n- \"Policy L has a shorter expected length\": Incorrect. Its expected length is infinite, which is greater than the finite expected length of Policy T.\nVerdict: **Incorrect**.\n\nD. Policy $\\mathrm{L}$ has coverage $1-\\alpha/2$ and zero probability of overestimation, so for $c_{\\text{under}}>c_{\\text{over}}$ its expected loss is always zero.\n- \"Policy L has coverage $1-\\alpha/2$\": Incorrect. It is stated to have coverage $1-\\alpha$.\n- \"zero probability of overestimation\": Incorrect. It has zero probability of *underestimation*. The probability of overestimation is $\\alpha$.\n- \"its expected loss is always zero\": Incorrect. Its expected loss is $\\alpha c_{\\text{over}}$, which is strictly positive as $c_{\\text{over}}>0$ and $\\alpha>0$.\nVerdict: **Incorrect**.\n\nBased on the rigorous analysis of both policies under the specified loss structure, option A is the only statement that is entirely correct.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}