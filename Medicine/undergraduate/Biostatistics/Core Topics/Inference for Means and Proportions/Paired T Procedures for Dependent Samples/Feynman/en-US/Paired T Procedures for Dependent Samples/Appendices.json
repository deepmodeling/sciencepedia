{
    "hands_on_practices": [
        {
            "introduction": "The power of a paired design lies in its ability to control for variability between subjects, making it a highly efficient method for detecting changes. To truly appreciate this efficiency, it is essential to compare it directly with its alternative: the independent two-sample design. This practice challenges you to derive and calculate the ratio of sample sizes needed for both designs to achieve the same statistical power, revealing the pivotal role of within-subject correlation in this comparison .",
            "id": "4936040",
            "problem": "A biostatistician is planning a hypothesis test for a mean difference between two conditions, denoted by the parameter $\\Delta = \\mu_{1} - \\mu_{2}$, where $\\mu_{1}$ and $\\mu_{2}$ are the population means under the two conditions. The biostatistician can choose between:\n\n1. A paired design, where each of $n_{p}$ individuals is measured under both conditions, producing paired measurements $(X_{i}, Y_{i})$ on the same individual $i$.\n\n2. An independent two-sample design, where two groups of equal size $n_{i}$ are formed; the first group is measured under condition $1$ and the second group under condition $2$, producing independent samples $\\{X_{j}\\}$ and $\\{Y_{k}\\}$.\n\nAssume the following scientifically plausible conditions hold:\n\n- The marginal variances are equal, $\\sigma_{1}^{2} = \\sigma_{2}^{2} = \\sigma^{2}$.\n- In the paired design, the within-subject correlation between $X_{i}$ and $Y_{i}$ is $\\rho$.\n- In the independent design, samples across groups are independent.\n- A two-sided test at fixed type I error level $\\alpha$ is used, and for large samples the power is governed by the standardized effect size $\\Delta$ divided by the standard error of the estimator for $\\mu_{1} - \\mu_{2}$, consistent with the Central Limit Theorem (CLT).\n\nStarting from first principles—specifically, the properties of variances and covariances for linear combinations, and the sampling variance of sample means—derive an expression for the ratio of the total number of individuals required in the independent design to the number of individuals required in the paired design to achieve the same power. Then, compute this ratio when $\\rho = 0.5$. Express the final ratio as a pure number with no units. No rounding is required; provide the exact value.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded, well-posed, objective, and contains a complete and consistent set of formalizable conditions. We may therefore proceed with a solution.\n\nThe core principle for achieving the same statistical power for a hypothesis test on the mean difference $\\Delta = \\mu_1 - \\mu_2$, given a fixed Type I error rate $\\alpha$, is that the variance of the estimator of $\\Delta$ must be the same for both the paired and independent study designs. This is because power in a test based on the Central Limit Theorem is a function of the non-centrality parameter, which is proportional to $|\\Delta| / \\text{SE}(\\hat{\\Delta})$, where $\\text{SE}(\\hat{\\Delta}) = \\sqrt{\\text{Var}(\\hat{\\Delta})}$. Thus, for the same power, we must have $\\text{Var}(\\hat{\\Delta}_{\\text{paired}}) = \\text{Var}(\\hat{\\Delta}_{\\text{independent}})$.\n\nWe begin by deriving the variance of the estimator for the mean difference in each design, starting from first principles of variance for linear combinations of random variables and the variance of a sample mean.\n\nFirst, consider the paired design.\nIn this design, we have $n_p$ individuals, with paired measurements $(X_i, Y_i)$ for each individual $i$. The difference for each individual is a random variable $D_i = X_i - Y_i$. The estimator for the mean difference $\\Delta = \\mu_1 - \\mu_2$ is the sample mean of these differences:\n$$ \\hat{\\Delta}_{\\text{paired}} = \\bar{D} = \\frac{1}{n_p} \\sum_{i=1}^{n_p} D_i $$\nThe variance of this estimator is the variance of the sample mean:\n$$ \\text{Var}(\\hat{\\Delta}_{\\text{paired}}) = \\text{Var}(\\bar{D}) = \\frac{\\text{Var}(D_i)}{n_p} $$\nTo find $\\text{Var}(D_i)$, we use the property for the variance of a difference of two random variables:\n$$ \\text{Var}(D_i) = \\text{Var}(X_i - Y_i) = \\text{Var}(X_i) + \\text{Var}(Y_i) - 2\\text{Cov}(X_i, Y_i) $$\nWe are given that the marginal variances are equal, $\\text{Var}(X_i) = \\sigma^2$ and $\\text{Var}(Y_i) = \\sigma^2$. The covariance is related to the correlation coefficient $\\rho$ by the definition $\\rho = \\frac{\\text{Cov}(X_i, Y_i)}{\\sqrt{\\text{Var}(X_i)\\text{Var}(Y_i)}}$. This gives $\\text{Cov}(X_i, Y_i) = \\rho \\sqrt{\\sigma^2 \\cdot \\sigma^2} = \\rho\\sigma^2$.\nSubstituting these into the expression for $\\text{Var}(D_i)$:\n$$ \\text{Var}(D_i) = \\sigma^2 + \\sigma^2 - 2\\rho\\sigma^2 = 2\\sigma^2(1 - \\rho) $$\nTherefore, the variance of the estimator in the paired design is:\n$$ \\text{Var}(\\hat{\\Delta}_{\\text{paired}}) = \\frac{2\\sigma^2(1 - \\rho)}{n_p} $$\n\nNext, consider the independent two-sample design.\nIn this design, we have two independent groups of size $n_i$ each. The estimator for the mean difference $\\Delta$ is the difference between the two sample means:\n$$ \\hat{\\Delta}_{\\text{independent}} = \\bar{X} - \\bar{Y} $$\nwhere $\\bar{X} = \\frac{1}{n_i} \\sum_{j=1}^{n_i} X_j$ and $\\bar{Y} = \\frac{1}{n_i} \\sum_{k=1}^{n_i} Y_k$.\nThe variance of this estimator is found using the property for the variance of a difference of independent random variables:\n$$ \\text{Var}(\\hat{\\Delta}_{\\text{independent}}) = \\text{Var}(\\bar{X} - \\bar{Y}) = \\text{Var}(\\bar{X}) + \\text{Var}(\\bar{Y}) $$\nThe variance of each sample mean is given by:\n$$ \\text{Var}(\\bar{X}) = \\frac{\\text{Var}(X)}{n_i} = \\frac{\\sigma^2}{n_i} $$\n$$ \\text{Var}(\\bar{Y}) = \\frac{\\text{Var}(Y)}{n_i} = \\frac{\\sigma^2}{n_i} $$\nSubstituting these into the expression for $\\text{Var}(\\hat{\\Delta}_{\\text{independent}})$:\n$$ \\text{Var}(\\hat{\\Delta}_{\\text{independent}}) = \\frac{\\sigma^2}{n_i} + \\frac{\\sigma^2}{n_i} = \\frac{2\\sigma^2}{n_i} $$\n\nTo achieve the same power, we equate the variances of the estimators from the two designs:\n$$ \\text{Var}(\\hat{\\Delta}_{\\text{paired}}) = \\text{Var}(\\hat{\\Delta}_{\\text{independent}}) $$\n$$ \\frac{2\\sigma^2(1 - \\rho)}{n_p} = \\frac{2\\sigma^2}{n_i} $$\nAssuming $\\sigma^2 > 0$, we can cancel the term $2\\sigma^2$ from both sides, yielding:\n$$ \\frac{1 - \\rho}{n_p} = \\frac{1}{n_i} $$\nThis gives a relationship between the sample sizes $n_i$ and $n_p$:\n$$ n_i = \\frac{n_p}{1 - \\rho} $$\nThe problem asks for the ratio of the total number of individuals required.\nFor the paired design, the total number of individuals is $N_{\\text{paired}} = n_p$.\nFor the independent design, the total number of individuals is the sum of the individuals in both groups, $N_{\\text{indep}} = n_i + n_i = 2n_i$.\n\nThe desired ratio is $\\frac{N_{\\text{indep}}}{N_{\\text{paired}}}$:\n$$ \\frac{N_{\\text{indep}}}{N_{\\text{paired}}} = \\frac{2n_i}{n_p} $$\nSubstituting the expression for $n_i$ in terms of $n_p$:\n$$ \\frac{N_{\\text{indep}}}{N_{\\text{paired}}} = \\frac{2 \\left(\\frac{n_p}{1 - \\rho}\\right)}{n_p} $$\nCanceling $n_p$ (since $n_p > 0$ for a study to exist), we obtain the general expression for the ratio:\n$$ \\frac{N_{\\text{indep}}}{N_{\\text{paired}}} = \\frac{2}{1 - \\rho} $$\nFinally, we compute this ratio for the specific case where the within-subject correlation is $\\rho = 0.5$:\n$$ \\text{Ratio} = \\frac{2}{1 - 0.5} = \\frac{2}{0.5} = 4 $$\nThus, to achieve the same statistical power, the independent design requires $4$ times the total number of individuals as the paired design when the correlation between paired measurements is $0.5$.",
            "answer": "$$\\boxed{4}$$"
        },
        {
            "introduction": "Having established that positive correlation enhances the efficiency of a paired design, we now focus on the core mathematical component: the variance of the paired differences, $\\sigma_{D}^{2}$. This variance represents the statistical 'noise' that a test must see through to detect a true effect. This exercise provides a concrete scenario to calculate $\\sigma_{D}^{2}$ from the marginal variances and correlation, reinforcing your understanding of how these parameters combine and directly impact the statistical power of a study .",
            "id": "4936030",
            "problem": "A biomedical study measures a continuous biomarker on the same individuals at two time points, producing paired observations $\\{(Y_{i1},Y_{i2}): i=1,\\dots,n\\}$ where $Y_{i1}$ is the baseline measurement and $Y_{i2}$ is the follow-up measurement. Let the within-subject difference be $D_i = Y_{i2} - Y_{i1}$, and let the population variance of the difference be $\\sigma_{D}^{2} = \\operatorname{Var}(D_i)$. Suppose that the marginal variances of the two measurements are $\\operatorname{Var}(Y_{i1}) = 4$ and $\\operatorname{Var}(Y_{i2}) = 5$, and the population correlation between $Y_{i1}$ and $Y_{i2}$ is $\\rho = 0.6$. Using only core definitions of variance, covariance, correlation, and properties of linear combinations of random variables, compute $\\sigma_{D}^{2}$. Round your numerical answer to four significant figures. Then, briefly explain how the magnitude of $\\sigma_{D}^{2}$ affects the required sample size $n$ to achieve a prespecified power and significance level in a paired $t$ procedure for dependent samples, assuming the mean difference $\\mu_{D} = \\mathbb{E}[D_i]$ is fixed and nonzero. No units are required for the numerical value of $\\sigma_{D}^{2}$.",
            "solution": "The problem is deemed valid as it is scientifically grounded in established statistical theory, well-posed with sufficient information for a unique solution, and stated objectively. All provided values are consistent and plausible.\n\nThe first task is to compute the population variance of the within-subject difference, $\\sigma_{D}^{2}$. The difference is defined as $D_i = Y_{i2} - Y_{i1}$ for the $i$-th subject. The variance of this difference, $\\sigma_{D}^{2}$, is given by the formula for the variance of a linear combination of two random variables:\n$$\n\\sigma_{D}^{2} = \\operatorname{Var}(D_i) = \\operatorname{Var}(Y_{i2} - Y_{i1})\n$$\nUsing the property $\\operatorname{Var}(A - B) = \\operatorname{Var}(A) + \\operatorname{Var}(B) - 2\\operatorname{Cov}(A, B)$, we can write:\n$$\n\\sigma_{D}^{2} = \\operatorname{Var}(Y_{i2}) + \\operatorname{Var}(Y_{i1}) - 2\\operatorname{Cov}(Y_{i1}, Y_{i2})\n$$\nThe problem provides the marginal variances: $\\operatorname{Var}(Y_{i1}) = 4$ and $\\operatorname{Var}(Y_{i2}) = 5$.\n\nThe covariance, $\\operatorname{Cov}(Y_{i1}, Y_{i2})$, is not given directly but can be calculated from the given population correlation, $\\rho = 0.6$. The definition of correlation is:\n$$\n\\rho = \\frac{\\operatorname{Cov}(Y_{i1}, Y_{i2})}{\\sqrt{\\operatorname{Var}(Y_{i1})} \\sqrt{\\operatorname{Var}(Y_{i2})}}\n$$\nRearranging this formula to solve for the covariance gives:\n$$\n\\operatorname{Cov}(Y_{i1}, Y_{i2}) = \\rho \\cdot \\sqrt{\\operatorname{Var}(Y_{i1})} \\cdot \\sqrt{\\operatorname{Var}(Y_{i2})}\n$$\nSubstituting the given values:\n$$\n\\operatorname{Cov}(Y_{i1}, Y_{i2}) = 0.6 \\cdot \\sqrt{4} \\cdot \\sqrt{5} = 0.6 \\cdot 2 \\cdot \\sqrt{5} = 1.2\\sqrt{5}\n$$\nNow, we substitute the known variances and the calculated covariance back into the formula for $\\sigma_{D}^{2}$:\n$$\n\\sigma_{D}^{2} = 5 + 4 - 2(1.2\\sqrt{5}) = 9 - 2.4\\sqrt{5}\n$$\nTo obtain the numerical value, we use the approximation $\\sqrt{5} \\approx 2.2360679...$:\n$$\n\\sigma_{D}^{2} \\approx 9 - 2.4(2.2360679...) = 9 - 5.3665631... = 3.6334368...\n$$\nRounding this result to four significant figures, we get $\\sigma_{D}^{2} = 3.633$.\n\nThe second task is to explain how the magnitude of $\\sigma_{D}^{2}$ affects the required sample size $n$ in a paired $t$-procedure. In a hypothesis test, statistical power is the probability of correctly detecting a true effect. For a paired $t$-test, the effect is quantified by the mean difference $\\mu_{D}$. The test's ability to detect this effect depends on the ratio of the \"signal\" (the effect size) to the \"noise\" (the variability of the data).\n\nThe standardized effect size for a paired samples design is given by Cohen's $d_z = \\frac{|\\mu_D|}{\\sigma_D}$. The test statistic for the paired $t$-test is $t = \\frac{\\bar{D}}{s_D / \\sqrt{n}}$, where $\\bar{D}$ is the sample mean difference and $s_D$ is the sample standard deviation of the differences.\n\nThe required sample size $n$ to achieve a prespecified power $1-\\beta$ and significance level $\\alpha$ for a two-sided test can be approximated by the formula:\n$$\nn \\approx \\left( \\frac{(z_{1-\\alpha/2} + z_{1-\\beta}) \\sigma_D}{\\mu_D} \\right)^2 = (z_{1-\\alpha/2} + z_{1-\\beta})^2 \\frac{\\sigma_D^2}{\\mu_D^2}\n$$\nwhere $z$ represents the quantiles of the standard normal distribution. This formula explicitly shows that for fixed $\\mu_D$, $\\alpha$, and power, the required sample size $n$ is directly proportional to the variance of the differences, $\\sigma_{D}^{2}$.\n$$\nn \\propto \\sigma_{D}^{2}\n$$\nTherefore, a larger variance $\\sigma_{D}^{2}$ implies greater \"noise\" or random variability in the measured differences. To distinguish the \"signal\" ($\\mu_D$) from this increased noise with the same level of confidence (i.e., to achieve the same power and significance), a larger sample size $n$ is required. The larger sample size allows for a more precise estimation of the mean difference, reducing the standard error of the mean ($\\frac{\\sigma_D}{\\sqrt{n}}$) and increasing the power of the test.",
            "answer": "$$\n\\boxed{3.633}\n$$"
        },
        {
            "introduction": "Theoretical efficiency is valuable, but its practical application depends on satisfying statistical assumptions. The paired t-test, for instance, assumes that the paired differences are approximately normally distributed, a condition that must be verified in practice. This final exercise moves from pure calculation to applied decision-making, placing you in the role of the data analyst. You will learn to integrate formal statistical tests with graphical diagnostics to make a sound judgment about whether a paired t-test is appropriate or if a robust alternative is needed .",
            "id": "4936017",
            "problem": "A researcher plans a paired analysis of pre-intervention and post-intervention systolic blood pressure in a cohort of $n=28$ participants. For each participant $i$, the researcher computes the paired differences $D_i=X_{i,\\text{post}}-X_{i,\\text{pre}}$. The inferential goal is to test whether the population mean of the paired differences is zero using a paired $t$ procedure, but the researcher first wants to assess the normality of the $D_i$ to justify using the paired $t$ procedure.\n\nThe researcher adopts the following diagnostic tools and obtains the following outputs on the sample of differences: a Shapiro–Wilk test statistic of $W=0.958$ and a corresponding $p$-value of $p=0.12$ at a planned significance level of $\\alpha=0.05$, and a quantile–quantile (QQ) plot comparing the sample quantiles of the $D_i$ to the theoretical quantiles under a normal distribution that appears approximately linear with mild tail deviations and no extreme outliers.\n\nStarting from the following fundamental bases:\n- The definition of the paired difference $D_i$ and that the paired $t$ procedure assumes the $D_i$ are independent and drawn from a population that is approximately normal.\n- The Shapiro–Wilk test for normality has null hypothesis that the sample is drawn from a normal distribution, with interpretation of the $p$-value as the probability, under the null, of observing a test statistic as extreme or more extreme than the one observed.\n- The concept of the QQ plot as a graphical tool to assess how closely sample quantiles align with theoretical normal quantiles.\n- The robustness of the paired $t$ procedure to mild deviations from normality, particularly for symmetric distributions and moderate sample sizes, and the availability of the Wilcoxon signed-rank test as a nonparametric alternative when normality is not tenable.\n\nWhich of the following protocols correctly specifies what to test for normality, how to combine Shapiro–Wilk and QQ plot interpretation, and how to state decision rules for whether to proceed with the paired $t$ procedure on the mean difference, including appropriate alternatives if assumptions are violated?\n\nA. Compute $D_i$ for all pairs; apply the Shapiro–Wilk test to $\\{D_i\\}$ at $\\alpha=0.05$; inspect the QQ plot of $\\{D_i\\}$ against theoretical normal quantiles. If $p\\ge\\alpha$ and the QQ plot is approximately linear without severe curvature or outliers, proceed with the paired $t$ procedure on the mean of $D_i$. If $p\\alpha$ or the QQ plot shows marked S-shaped curvature, heavy tails, or outliers suggesting clear non-normality, prefer the Wilcoxon signed-rank test on $D_i$. If $p$ is borderline and $n$ is moderate (for example, $n\\approx 25$ to $n\\approx 30$) with a QQ plot showing only mild tail deviations and approximate symmetry, proceed with the paired $t$ procedure acknowledging its robustness and consider a sensitivity analysis using the Wilcoxon signed-rank test.\n\nB. Test normality separately on the pre-intervention values $\\{X_{i,\\text{pre}}\\}$ and post-intervention values $\\{X_{i,\\text{post}}\\}$ using the Shapiro–Wilk test at $\\alpha=0.05$. If both are normal, proceed with the paired $t$ procedure; if either is non-normal, apply a logarithmic transformation to both series to force normality, then proceed with the paired $t$ procedure regardless of the QQ plot of $D_i$.\n\nC. Compute $D_i$ and apply the Shapiro–Wilk test to $\\{D_i\\}$ at $\\alpha=0.05$. If $p\\alpha$, interpret this as evidence that the $D_i$ are normal and proceed with the paired $t$ procedure; if $p\\ge\\alpha$, interpret this as non-normality and use the Mann–Whitney $U$ test on unpaired observations.\n\nD. Ignore the Shapiro–Wilk test and rely solely on the QQ plot. If the QQ plot of $\\{D_i\\}$ shows any deviation from a straight line, do not use the paired $t$ procedure and instead always use the Wilcoxon signed-rank test; if the QQ plot is perfectly straight, use the paired $t$ procedure. Do not consider $p$-values or sample size because graphical judgment suffices.\n\nE. Since $n=28$, invoke the Central Limit Theorem (CLT) to conclude that the $D_i$ themselves are normal regardless of the underlying distribution. Proceed with the paired $t$ procedure without any normality checks; only if $n25$ should one consider the Wilcoxon signed-rank test based on a histogram of $D_i$.",
            "solution": "The problem requires identifying the correct protocol for assessing the normality assumption for a paired $t$-test. A correct protocol must test the correct data, use appropriate tools, interpret them correctly, and specify the right course of action, including the proper alternative test if needed.\n\n1.  **Object of the Normality Test:** The paired $t$-test is mathematically a one-sample $t$-test on the paired differences, $D_i = X_{i,\\text{post}} - X_{i,\\text{pre}}$. Therefore, the normality assumption applies to the population of these differences, and we must assess the normality of the sample of differences, $\\{D_i\\}$. Any protocol that tests the pre- and post-intervention data separately is incorrect.\n\n2.  **Integration of Diagnostic Tools:** Best practice involves using both a formal hypothesis test (like the Shapiro–Wilk test) and a graphical assessment (like a QQ plot). The formal test provides an objective measure of evidence against normality, while the graphical plot reveals the nature and severity of any deviations.\n    - The Shapiro–Wilk test has a null hypothesis that the data are from a normal distribution. A small $p$-value ($p  \\alpha$) provides evidence to reject this hypothesis. Here, $p=0.12$, which is greater than the significance level $\\alpha=0.05$. Thus, we fail to reject the null hypothesis; there is no significant statistical evidence of non-normality.\n    - The QQ plot is described as \"approximately linear with mild tail deviations and no extreme outliers,\" which graphically supports the conclusion that the data are reasonably close to normal.\n\n3.  **Decision-Making and Robustness:** Given the moderate sample size ($n=28$), the non-significant Shapiro–Wilk test, and the well-behaved QQ plot, the normality assumption is considered met for practical purposes. The paired $t$-test is robust to such mild deviations.\n\n4.  **Alternative Test:** If the normality assumption were clearly violated (e.g., a very low $p$-value or a QQ plot with strong curvature or outliers), the appropriate nonparametric alternative for paired data is the Wilcoxon signed-rank test, which tests the median of the differences.\n\n**Evaluation of the Options:**\n\n-   **A:** This option correctly specifies testing the differences $\\{D_i\\}$, combining the Shapiro–Wilk test and QQ plot, interpreting the results correctly, and identifying the Wilcoxon signed-rank test as the proper alternative. It also includes a nuanced rule for borderline cases, which reflects sound statistical practice. This protocol is correct and comprehensive.\n\n-   **B:** This option is incorrect because it tests the normality of the raw pre- and post-intervention data, not the differences. This is a fundamental error.\n\n-   **C:** This option is incorrect because it reverses the interpretation of the $p$-value from the normality test and specifies the wrong alternative test (Mann–Whitney $U$ test, which is for independent samples).\n\n-   **D:** This option is incorrect because it relies solely on a subjective graphical assessment with an unrealistically strict criterion (\"any deviation\") and ignores the crucial context provided by sample size and formal tests.\n\n-   **E:** This option is incorrect because it misinterprets the Central Limit Theorem (CLT). The CLT applies to the distribution of the *sample mean*, not the underlying data points themselves. For a sample size of $n=28$, it is not appropriate to blindly assume normality without checking.\n\nBased on this analysis, protocol A is the only one that represents a correct and professionally sound approach to assessing the assumptions of a paired $t$-test.",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}