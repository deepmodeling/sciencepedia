{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in analyzing any bisulfite sequencing experiment is to assess its technical quality. This practice guides you through estimating the bisulfite conversion failure rate, a key performance metric, by leveraging the biological fact that most non-CpG cytosines in mammalian somatic cells are unmethylated. By mastering this calculation , you will learn how to derive a vital quality control parameter directly from your sequencing data using fundamental principles of statistical inference.",
            "id": "5016965",
            "problem": "In sodium bisulfite sequencing (bisulfite sequencing), unmethylated cytosines are deaminated to uracil and sequenced as thymine, while methylated cytosines resist conversion and are sequenced as cytosine. In mammalian somatic tissues, non-CpG contexts (that is, cytosines not followed by guanine) are typically negligibly methylated under physiological conditions. Therefore, cytosine observations in non-CpG contexts largely reflect failures of conversion rather than true methylation.\n\nA laboratory performs bisulfite sequencing on a human blood sample. Across all reads, they tally non-CpG cytosine positions and observe that out of a total of $n = 50{,}000$ non-CpG cytosine positions covered, $k = 600$ are called as cytosine (rather than thymine). Assume each non-CpG cytosine observation represents an independent Bernoulli trial with probability $p$ that an unmethylated cytosine fails to convert and remains a cytosine call. Treat true non-CpG methylation as negligible.\n\nUsing only the axioms of probability, the definition of the binomial distribution, and likelihood-based inference, do the following:\n\n1. Starting from the binomial model for the number of unconverted cytosine calls in non-CpG contexts, derive an estimator $\\hat{p}$ for the conversion failure probability $p$.\n2. Using large-sample likelihood theory for the binomial model, derive an approximate two-sided confidence interval for $p$ at confidence level $1-\\alpha = 0.95$ and then compute its numerical value for the given $n$ and $k$.\n\nRound your final numerical results to four significant figures. Express the final answer as a row matrix $\\big[\\hat{p} \\; L \\; U\\big]$, where $L$ and $U$ are the lower and upper confidence limits, respectively. Express all probabilities as decimals (do not use the percent sign).",
            "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It provides a complete and consistent setup for a standard problem in statistical inference applied to genomics.\n\nThe problem asks for two main derivations based on the binomial model of bisulfite sequencing conversion failure. We are given the total number of non-CpG cytosine positions, $n = 50{,}000$, and the number of observed cytosine calls (failures of conversion), $k = 600$.\n\nLet $K$ be the random variable representing the number of unconverted cytosine calls. We model $K$ as a binomial random variable, $K \\sim \\text{Bin}(n, p)$, where $n$ is the number of trials (non-CpG cytosine positions) and $p$ is the probability of a conversion failure for any given trial. The probability mass function (PMF) for observing $k$ failures in $n$ trials is given by:\n$$P(K=k | n, p) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n\n**1. Derivation of the Estimator $\\hat{p}$**\n\nTo derive an estimator for $p$, we use the method of maximum likelihood. The likelihood function $L(p | k, n)$ is the probability of observing the data, $k$, as a function of the parameter $p$.\n$$L(p | k, n) = \\binom{n}{k} p^k (1-p)^{n-k}$$\nMaximizing the likelihood function is equivalent to maximizing its natural logarithm, the log-likelihood function $\\ell(p) = \\ln(L(p))$. This simplifies the calculus by converting products into sums.\n$$\\ell(p) = \\ln \\left( \\binom{n}{k} \\right) + k \\ln(p) + (n-k) \\ln(1-p)$$\nTo find the value of $p$ that maximizes $\\ell(p)$, we take the first derivative with respect to $p$ and set it to zero. The term $\\ln \\binom{n}{k}$ is a constant with respect to $p$, so its derivative is zero.\n$$\\frac{d\\ell}{dp} = \\frac{d}{dp} \\left[ \\ln \\binom{n}{k} + k \\ln(p) + (n-k) \\ln(1-p) \\right] = \\frac{k}{p} - \\frac{n-k}{1-p}$$\nSetting the derivative to zero gives the maximum likelihood estimate, denoted $\\hat{p}$:\n$$\\frac{k}{\\hat{p}} - \\frac{n-k}{1-\\hat{p}} = 0$$\n$$\\frac{k}{\\hat{p}} = \\frac{n-k}{1-\\hat{p}}$$\n$$k(1-\\hat{p}) = \\hat{p}(n-k)$$\n$$k - k\\hat{p} = n\\hat{p} - k\\hat{p}$$\n$$k = n\\hat{p}$$\nSolving for $\\hat{p}$, we obtain the maximum likelihood estimator for $p$:\n$$\\hat{p} = \\frac{k}{n}$$\nTo confirm this is a maximum, we check the second derivative:\n$$\\frac{d^2\\ell}{dp^2} = -\\frac{k}{p^2} - \\frac{n-k}{(1-p)^2}$$\nSince $n > k > 0$ and $0 < p < 1$, both terms are negative, so the second derivative is always negative. This confirms that $\\hat{p} = k/n$ is indeed a maximum.\n\nUsing the given data, $n=50{,}000$ and $k=600$:\n$$\\hat{p} = \\frac{600}{50{,}000} = \\frac{6}{500} = 0.012$$\n\n**2. Derivation and Computation of the 95% Confidence Interval**\n\nWe use large-sample likelihood theory, which states that for large $n$, the maximum likelihood estimator $\\hat{p}$ is approximately normally distributed with mean $p$ and variance given by the inverse of the Fisher information. For a binomial proportion, the variance is $\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}$.\nAn approximate two-sided confidence interval for $p$ is constructed as:\n$$\\hat{p} \\pm z_{\\alpha/2} \\cdot \\text{SE}(\\hat{p})$$\nwhere $\\text{SE}(\\hat{p})$ is the standard error of the estimator, and $z_{\\alpha/2}$ is the critical value from the standard normal distribution for a confidence level $1-\\alpha$.\n\nThe standard error is the square root of the estimated variance. We estimate the variance by substituting $\\hat{p}$ for the unknown true parameter $p$:\n$$\\widehat{\\text{Var}}(\\hat{p}) = \\frac{\\hat{p}(1-\\hat{p})}{n}$$\n$$\\text{SE}(\\hat{p}) = \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\nFor a confidence level of $1-\\alpha = 0.95$, we have $\\alpha = 0.05$ and $\\alpha/2 = 0.025$. The corresponding critical value is $z_{0.025}$, which is the upper $0.025$ quantile of the standard normal distribution. This value is approximately $1.96$.\n\nThe $95\\%$ confidence interval is therefore:\n$$L, U = \\hat{p} \\pm z_{0.025} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}$$\nNow, we substitute the numerical values:\n$\\hat{p} = 0.012$\n$n = 50{,}000$\n$z_{0.025} \\approx 1.96$\n\nFirst, calculate the standard error:\n$$\\text{SE}(\\hat{p}) = \\sqrt{\\frac{0.012(1-0.012)}{50{,}000}} = \\sqrt{\\frac{0.012(0.988)}{50{,}000}} = \\sqrt{\\frac{0.011856}{50{,}000}} = \\sqrt{0.00000023712}$$\n$$\\text{SE}(\\hat{p}) \\approx 0.0004869518$$\nNext, calculate the margin of error (ME):\n$$\\text{ME} = z_{0.025} \\cdot \\text{SE}(\\hat{p}) \\approx 1.96 \\times 0.0004869518 \\approx 0.0009544255$$\nFinally, calculate the lower ($L$) and upper ($U$) limits of the confidence interval:\n$$L = \\hat{p} - \\text{ME} \\approx 0.012 - 0.0009544255 = 0.0110455745$$\n$$U = \\hat{p} + \\text{ME} \\approx 0.012 + 0.0009544255 = 0.0129544255$$\nRounding the final results to four significant figures as requested:\n$\\hat{p} = 0.01200$\n$L \\approx 0.01105$\n$U \\approx 0.01295$\nThe final answer is presented as a row matrix $[\\hat{p} \\; L \\; U]$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.01200 & 0.01105 & 0.01295\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Raw methylation data is not the full truth; it contains systematic biases that must be addressed. This exercise demonstrates how the incomplete conversion of unmethylated cytosines leads to an overestimation of the true methylation fraction. You will derive a mathematical correction to remove this bias , a fundamental data processing step required for generating accurate methylation profiles.",
            "id": "5016924",
            "problem": "In whole-genome bisulfite sequencing of a single Cytosine-phosphate-Guanine (CpG) site, let the true methylation fraction be $m \\in [0,1]$. During bisulfite treatment, unmethylated cytosines are converted to thymine with probability $1-p$ and fail to convert with probability $p$, while methylated cytosines remain cytosine. Assume there are no sequencing errors, no over-conversion of methylated cytosines, and that each read is an independent Bernoulli trial with respect to the outcome of being called cytosine. A standard estimator of methylation from reads is the observed fraction of cytosine calls, $\\hat{m} = c/n$, where $n$ is total coverage and $c$ is the number of reads observed as cytosine at this CpG.\n\nUsing only these assumptions and fundamental probability (law of total probability and expectation for Bernoulli trials), derive from first principles the expected value $\\mathbb{E}[\\hat{m}]$ in terms of $m$ and $p$, and hence the bias $\\mathrm{Bias}(\\hat{m}) = \\mathbb{E}[\\hat{m}] - m$. Then, obtain an algebraic expression for a bias-corrected estimator $\\tilde{m}$ by solving for $m$ in the relationship between $\\mathbb{E}[\\hat{m}]$, $m$, and $p$ and substituting $\\hat{m}$ for $\\mathbb{E}[\\hat{m}]$.\n\nFinally, apply your derived $\\tilde{m}$ to the following data: $n = 1000$ reads with $c = 430$ cytosine calls, and a measured incomplete conversion rate $p = 0.04$. Report the corrected methylation fraction as a decimal (not a percentage), rounded to four significant figures. Your final answer should be only the single numerical value for the corrected methylation fraction.",
            "solution": "The problem is evaluated as valid, as it is scientifically grounded in the principles of molecular biology and statistics, well-posed with a clear objective, and internally consistent.\n\nFirst, we will derive the expected value of the estimator $\\hat{m} = c/n$. Let $R_i$ be a Bernoulli random variable for the $i$-th read, where $R_i=1$ if the read is a cytosine (C) and $R_i=0$ if it is a thymine (T). The total number of cytosine reads, $c$, is the sum of these random variables over the $n$ total reads: $c = \\sum_{i=1}^{n} R_i$. The estimator is then $\\hat{m} = \\frac{1}{n} \\sum_{i=1}^{n} R_i$.\n\nBy the linearity of expectation, the expected value of $\\hat{m}$ is:\n$$\n\\mathbb{E}[\\hat{m}] = \\mathbb{E}\\left[\\frac{1}{n} \\sum_{i=1}^{n} R_i\\right] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}[R_i]\n$$\nSince each read is an independent and identically distributed (i.i.d.) trial, the expected value is the same for all reads, i.e., $\\mathbb{E}[R_i] = \\mathbb{E}[R_1]$ for any $i \\in \\{1, \\dots, n\\}$. Thus, the sum simplifies to:\n$$\n\\mathbb{E}[\\hat{m}] = \\frac{1}{n} (n \\cdot \\mathbb{E}[R_1]) = \\mathbb{E}[R_1]\n$$\nThe expected value of a Bernoulli random variable is the probability of success, so $\\mathbb{E}[R_1] = P(R_1=1)$. We need to find the probability that a randomly selected read is a cytosine. This can be determined using the law of total probability, conditioning on the true methylation state of the CpG site from which the read originated.\n\nLet $M$ be the event that the DNA strand is methylated at the site, and $U$ be the event that it is unmethylated. The problem gives the true methylation fraction as $m$, so we have $P(M) = m$ and $P(U) = 1-m$. The event of interest is observing a cytosine read, which we denote as $C_{obs}$.\n$$\nP(C_{obs}) = P(C_{obs}|M)P(M) + P(C_{obs}|U)P(U)\n$$\nAccording to the problem statement:\n- Methylated cytosines remain cytosine. This implies the probability of observing a cytosine read given the site was methylated is $P(C_{obs}|M) = 1$.\n- Unmethylated cytosines fail to convert to thymine with probability $p$, meaning they remain as cytosine. This implies the probability of observing a cytosine read given the site was unmethylated is $P(C_{obs}|U) = p$.\n\nSubstituting these probabilities into the equation:\n$$\nP(C_{obs}) = (1)(m) + (p)(1-m) = m + p - pm = m(1-p) + p\n$$\nTherefore, the expected value of the estimator $\\hat{m}$ is:\n$$\n\\mathbb{E}[\\hat{m}] = m(1-p) + p\n$$\n\nNext, we calculate the bias of the estimator, $\\mathrm{Bias}(\\hat{m})$.\n$$\n\\mathrm{Bias}(\\hat{m}) = \\mathbb{E}[\\hat{m}] - m = (m(1-p) + p) - m = m - mp + p - m = p(1-m)\n$$\nThe bias is positive for $p>0$ and $m<1$, indicating that incomplete conversion leads to an overestimation of the true methylation level.\n\nTo find the bias-corrected estimator, $\\tilde{m}$, we solve the relationship for the true methylation fraction, $m$. We start with the expectation equation and substitute the observed fraction $\\hat{m}$ for its expectation $\\mathbb{E}[\\hat{m}]$, treating $\\hat{m}$ as a point estimate of $\\mathbb{E}[\\hat{m}]$.\n$$\n\\hat{m} = \\tilde{m}(1-p) + p\n$$\nSolving for $\\tilde{m}$:\n$$\n\\hat{m} - p = \\tilde{m}(1-p)\n$$\n$$\n\\tilde{m} = \\frac{\\hat{m} - p}{1 - p}\n$$\nThis is the algebraic expression for the bias-corrected estimator.\n\nFinally, we apply this formula to the given data: total coverage $n = 1000$, cytosine reads $c = 430$, and incomplete conversion rate $p = 0.04$.\n\nFirst, calculate the uncorrected methylation fraction, $\\hat{m}$:\n$$\n\\hat{m} = \\frac{c}{n} = \\frac{430}{1000} = 0.43\n$$\nNow, substitute $\\hat{m}$ and $p$ into the expression for $\\tilde{m}$:\n$$\n\\tilde{m} = \\frac{0.43 - 0.04}{1 - 0.04} = \\frac{0.39}{0.96}\n$$\nPerforming the division:\n$$\n\\tilde{m} = 0.40625\n$$\nThe problem requires the answer rounded to four significant figures. The first four significant figures are $4$, $0$, $6$, and $2$. The fifth digit is $5$, so we round up the fourth digit.\n$$\n\\tilde{m} \\approx 0.4063\n$$\nThis is the bias-corrected methylation fraction.",
            "answer": "$$\n\\boxed{0.4063}\n$$"
        },
        {
            "introduction": "After correcting for systematic errors, we still face the challenge of statistical uncertainty, especially at sites with low sequencing coverage. This practice moves beyond simple point estimates to compare frequentist and Bayesian approaches to methylation quantification. By exploring the Beta-Binomial model , you will understand how Bayesian methods can provide more stable and reliable estimates by incorporating prior knowledge, a cornerstone of modern computational genomics.",
            "id": "5016930",
            "problem": "In Whole-Genome Bisulfite Sequencing (WGBS) used in medical genetics, unmethylated cytosines in deoxyribonucleic acid (DNA) are converted to uracil by sodium bisulfite treatment and read as thymine in sequencing, whereas methylated cytosines remain as cytosine. Consider a single cytosine-phosphate-guanine (CpG) dinucleotide site where $n$ independent reads are observed, and $k$ of these reads show cytosine ($C$). Define the per-CpG methylation fraction estimator as $\\hat{m} = k/n$, where $\\hat{m}$ is intended to estimate the true methylation fraction $m \\in [0,1]$ at that site. Under the assumption that, conditional on $m$, each read is an independent Bernoulli trial indicating methylation status, the sampling model for $k$ is $\\mathrm{Binomial}(n,m)$.\n\nSuppose one instead places a $\\mathrm{Beta}(\\alpha,\\beta)$ prior on $m$ reflecting prior knowledge about methylation levels in the assayed tissue or genomic context and then uses the posterior distribution for inference. Which of the following statements correctly describe conditions under which a posterior estimate based on the $\\mathrm{Beta}(\\alpha,\\beta)$ prior is preferred over the frequentist estimator $\\hat{m} = k/n$ for per-CpG methylation inference?\n\nChoose all that apply.\n\nA. When coverage $n$ is small or observed counts are extreme (e.g., $k=0$ or $k=n$), a posterior estimate that shrinks toward the prior mean reduces expected mean squared error under squared loss compared to $\\hat{m}$, provided the prior reflects plausible methylation levels.\n\nB. When coverage $n$ is large (formally, $n \\to \\infty$), the $\\mathrm{Beta}(\\alpha,\\beta)$ prior dominates the likelihood, so the posterior mean is preferred to prevent overfitting to the data.\n\nC. When estimates are needed genome-wide across many CpG sites with heterogeneous coverage, a hierarchical $\\mathrm{Beta}$ prior that pools information across sites yields more stable site-level estimates than $\\hat{m}$, especially for low-coverage sites.\n\nD. Because bisulfite conversion is perfect, a prior is unnecessary; thus the posterior is preferred only for philosophical reasons, not for performance.\n\nE. When informative prior knowledge is available (for example, promoter CpGs in the studied tissue are typically hypomethylated), incorporating a $\\mathrm{Beta}(\\alpha,\\beta)$ prior is preferred to encode that information, particularly when $n$ is limited.",
            "solution": "This problem compares the standard frequentist estimator for methylation proportion with a Bayesian estimator, highlighting situations where the Bayesian approach is preferred. The core of the comparison lies in understanding the properties of the Maximum Likelihood Estimate (MLE) and the Bayesian posterior mean.\n\n**Statistical Framework**\n\n*   **Frequentist Estimator (MLE):** The standard estimator, $\\hat{m} = k/n$, is the Maximum Likelihood Estimate for the binomial proportion. It is unbiased and relies solely on the observed data.\n*   **Bayesian Model:** The problem specifies a Bayesian model using a Beta-Binomial framework, which is a common choice for modeling proportions.\n    *   **Prior:** The prior belief about the methylation fraction $m$ is modeled by a Beta distribution: $p(m) = \\mathrm{Beta}(m | \\alpha, \\beta)$. The mean of this prior is $\\mu_{prior} = \\frac{\\alpha}{\\alpha+\\beta}$.\n    *   **Likelihood:** The probability of observing $k$ methylated reads out of $n$ total reads, given $m$, is the Binomial probability mass function: $p(k|m, n) = \\binom{n}{k} m^k (1-m)^{n-k}$.\n    *   **Posterior:** Due to the conjugacy of the Beta prior and Binomial likelihood, the posterior distribution of $m$ is also a Beta distribution: $m | k, n \\sim \\mathrm{Beta}(k+\\alpha, n-k+\\beta)$.\n\nA common Bayesian point estimate is the mean of the posterior distribution.\n$$\\hat{m}_{Bayes} = E[m|k,n] = \\frac{k+\\alpha}{n+\\alpha+\\beta}$$\nThis estimator can be rewritten as a weighted average of the MLE and the prior mean:\n$$\\hat{m}_{Bayes} = \\left( \\frac{n}{n+\\alpha+\\beta} \\right) \\left( \\frac{k}{n} \\right) + \\left( \\frac{\\alpha+\\beta}{n+\\alpha+\\beta} \\right) \\left( \\frac{\\alpha}{\\alpha+\\beta} \\right) = w \\cdot \\hat{m}_{MLE} + (1-w) \\cdot \\mu_{prior}$$\nThis formula shows that the Bayesian estimate \"shrinks\" the data-driven MLE towards the prior mean. The amount of shrinkage depends on the relative strength of the data (coverage $n$) versus the prior (strength $\\alpha+\\beta$).\n\nWith this framework, we can evaluate each option:\n\n**A. When coverage $n$ is small or observed counts are extreme (e.g., $k=0$ or $k=n$), a posterior estimate that shrinks toward the prior mean reduces expected mean squared error under squared loss compared to $\\hat{m}$, provided the prior reflects plausible methylation levels.**\n\nCorrect. When coverage $n$ is small, the MLE $\\hat{m} = k/n$ has high variance. For extreme counts like $k=0$ or $k=n$, the MLE is 0 or 1, which are often biologically unrealistic. The Bayesian estimator provides regularization by pulling the estimate towards the prior mean. This shrinkage reduces variance at the cost of a small amount of bias, often leading to a lower overall mean squared error (MSE). This is a well-known statistical benefit of shrinkage estimators, especially in low-information settings.\n\n**B. When coverage $n$ is large (formally, $n \\to \\infty$), the $\\mathrm{Beta}(\\alpha,\\beta)$ prior dominates the likelihood, so the posterior mean is preferred to prevent overfitting to the data.**\n\nIncorrect. As coverage $n$ becomes large, the weight on the MLE, $\\frac{n}{n+\\alpha+\\beta}$, approaches 1, while the weight on the prior approaches 0. The likelihood (data) dominates the prior, and the Bayesian estimate converges to the MLE. This is a desirable property, as with abundant data, we trust the data more than our prior beliefs. The statement has the relationship backward.\n\n**C. When estimates are needed genome-wide across many CpG sites with heterogeneous coverage, a hierarchical $\\mathrm{Beta}$ prior that pools information across sites yields more stable site-level estimates than $\\hat{m}$, especially for low-coverage sites.**\n\nCorrect. This describes a powerful application of Bayesian methods. In a hierarchical model, the prior parameters $(\\alpha, \\beta)$ are estimated from the data across all CpG sites. This data-driven prior is then used for each individual site. This process \"borrows strength\" from high-coverage sites to stabilize the estimates for low-coverage sites, which are then shrunk towards a global, empirically-determined mean. This is a standard and highly effective technique in genomics.\n\n**D. Because bisulfite conversion is perfect, a prior is unnecessary; thus the posterior is preferred only for philosophical reasons, not for performance.**\n\nIncorrect. The premise that bisulfite conversion is perfect is false; it's a chemical reaction with known error rates. More importantly, even with perfect data generation, statistical uncertainty due to finite sampling ($n  \\infty$) remains. Priors are a mathematical tool to manage this uncertainty, and as shown in options A and C, they offer tangible performance benefits (e.g., lower MSE, estimate stabilization), not just philosophical ones.\n\n**E. When informative prior knowledge is available (for example, promoter CpGs in the studied tissue are typically hypomethylated), incorporating a $\\mathrm{Beta}(\\alpha,\\beta)$ prior is preferred to encode that information, particularly when $n$ is limited.**\n\nCorrect. This is a fundamental strength of the Bayesian framework. It provides a formal mechanism to incorporate external knowledge. If we know from previous studies that promoter CpGs are usually hypomethylated, we can choose prior parameters $(\\alpha, \\beta)$ that reflect this belief (e.g., $\\mathrm{Beta}(1, 10)$). This is most valuable when data is sparse (small $n$), as the prior helps guide the estimate towards a plausible value.\n\nTherefore, the correct options are A, C, and E.",
            "answer": "$$\\boxed{ACE}$$"
        }
    ]
}