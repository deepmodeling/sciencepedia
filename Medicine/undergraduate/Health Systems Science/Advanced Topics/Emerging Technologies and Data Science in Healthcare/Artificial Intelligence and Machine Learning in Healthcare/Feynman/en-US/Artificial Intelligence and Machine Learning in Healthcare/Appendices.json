{
    "hands_on_practices": [
        {
            "introduction": "When an AI diagnostic tool is developed, its performance is often summarized by its intrinsic sensitivity and specificity. However, for a clinician at the bedside, the more pressing question is: \"Given this positive test result, what is the probability my patient actually has the disease?\" This exercise  walks you through the fundamental application of Bayes' theorem to derive the Positive and Negative Predictive Values ($PPV$ and $NPV$), revealing how a model's practical utility is deeply connected to the prevalence of the condition it screens for.",
            "id": "4360373",
            "problem": "A hospital system deploys a binary Artificial Intelligence (AI) screening tool built using Machine Learning (ML) to flag a condition in primary care. Let $D$ denote the event that a randomly selected patient truly has the condition and $\\bar{D}$ the event that the patient does not have the condition. The tool outputs a binary label, with $+$ for a positive screen and $-$ for a negative screen. The population disease prevalence is $\\pi = P(D)$, the tool's sensitivity is $t = P(+ \\mid D)$, and its specificity is $c = P(- \\mid \\bar{D})$. Assume $t, c \\in (0,1)$ and $\\pi \\in (0,1)$.\n\nUsing only core definitions from diagnostic testing and the probability axioms (in particular the Law of Total Probability and Bayes' theorem), derive closed-form expressions for the Positive Predictive Value (PPV), $PPV = P(D \\mid +)$, and the Negative Predictive Value (NPV), $NPV = P(\\bar{D} \\mid -)$, in terms of $\\pi$, $t$, and $c$. Then, for fixed $t$ and $c$, compute the derivative $\\frac{d}{d\\pi}PPV(\\pi)$ with respect to $\\pi$ and simplify it to a single closed-form expression that depends only on $\\pi$, $t$, and $c$.\n\nExpress your final results for $PPV$, $NPV$, and $\\frac{d}{d\\pi}PPV(\\pi)$ as closed-form analytic expressions. No rounding is required.",
            "solution": "The problem is well-posed, scientifically grounded, objective, and contains all necessary information for a unique solution. The concepts of prevalence, sensitivity, and specificity are cornerstone principles in biostatistics and epidemiology for evaluating diagnostic tests. The derivation of Positive Predictive Value (PPV) and Negative Predictive Value (NPV) is a standard application of Bayes' theorem and the Law of Total Probability. I will proceed with the derivation.\n\nThe problem provides the following definitions:\nThe event that a patient has the condition is denoted by $D$.\nThe event that a patient does not have the condition is denoted by $\\bar{D}$.\nThe event of a positive test result is denoted by $+$.\nThe event of a negative test result is denoted by $-$.\n\nThe given probabilities are:\nPrevalence: $\\pi = P(D) \\in (0,1)$.\nSensitivity: $t = P(+ \\mid D) \\in (0,1)$.\nSpecificity: $c = P(- \\mid \\bar{D}) \\in (0,1)$.\n\nFrom the axioms of probability, we can derive the probabilities of complementary events:\nThe probability of a patient not having the condition is $P(\\bar{D}) = 1 - P(D) = 1 - \\pi$.\nThe false positive rate is the probability of a positive test given the patient does not have the condition: $P(+ \\mid \\bar{D}) = 1 - P(- \\mid \\bar{D}) = 1 - c$.\nThe false negative rate is the probability of a negative test given the patient does have the condition: $P(- \\mid D) = 1 - P(+ \\mid D) = 1 - t$.\n\n**Part 1: Derivation of the Positive Predictive Value (PPV)**\nThe PPV is defined as the probability that a patient has the condition given a positive test result, $PPV = P(D \\mid +)$.\nUsing Bayes' theorem, we have:\n$$PPV = P(D \\mid +) = \\frac{P(+ \\mid D) P(D)}{P(+)}$$\nThe numerator is given by the product of the sensitivity and the prevalence:\n$$P(+ \\mid D) P(D) = t \\pi$$\nThe denominator, $P(+)$, is the total probability of a positive test. We find this using the Law of Total Probability, summing over the mutually exclusive events $D$ and $\\bar{D}$:\n$$P(+) = P(+ \\mid D) P(D) + P(+ \\mid \\bar{D}) P(\\bar{D})$$\nSubstituting the known quantities:\n$$P(+) = t \\pi + (1 - c) (1 - \\pi)$$\nNow, we substitute the expressions for the numerator and denominator back into the Bayes' theorem formula for PPV:\n$$PPV = \\frac{t \\pi}{t \\pi + (1 - c) (1 - \\pi)}$$\nThis is the closed-form expression for PPV in terms of $\\pi$, $t$, and $c$.\n\n**Part 2: Derivation of the Negative Predictive Value (NPV)**\nThe NPV is defined as the probability that a patient does not have the condition given a negative test result, $NPV = P(\\bar{D} \\mid -)$.\nUsing Bayes' theorem:\n$$NPV = P(\\bar{D} \\mid -) = \\frac{P(- \\mid \\bar{D}) P(\\bar{D})}{P(-)}$$\nThe numerator is given by the product of the specificity and the probability of not having the condition:\n$$P(- \\mid \\bar{D}) P(\\bar{D}) = c (1 - \\pi)$$\nThe denominator, $P(-)$, is the total probability of a negative test. Using the Law of Total Probability:\n$$P(-) = P(- \\mid D) P(D) + P(- \\mid \\bar{D}) P(\\bar{D})$$\nSubstituting the known quantities:\n$$P(-) = (1 - t) \\pi + c (1 - \\pi)$$\nSubstituting the expressions for the numerator and denominator back into the Bayes' theorem formula for NPV:\n$$NPV = \\frac{c (1 - \\pi)}{(1 - t) \\pi + c (1 - \\pi)}$$\nThis is the closed-form expression for NPV in terms of $\\pi$, $t$, and $c$. For clarity, we can write the denominator as $c(1-\\pi) + (1-t)\\pi$.\n\n**Part 3: Derivative of PPV with respect to Prevalence ($\\pi$)**\nWe are asked to compute $\\frac{d}{d\\pi} PPV(\\pi)$ for fixed $t$ and $c$. The expression for PPV is:\n$$PPV(\\pi) = \\frac{t \\pi}{t \\pi + (1 - c) (1 - \\pi)}$$\nLet's first simplify the denominator:\n$$t \\pi + (1 - c) (1 - \\pi) = t \\pi + 1 - \\pi - c + c \\pi = \\pi(t + c - 1) + (1 - c)$$\nSo, the function to differentiate is:\n$$PPV(\\pi) = \\frac{t \\pi}{\\pi(t + c - 1) + (1 - c)}$$\nWe will use the quotient rule for differentiation, $\\frac{d}{dx} \\left( \\frac{u(x)}{v(x)} \\right) = \\frac{u'(x)v(x) - u(x)v'(x)}{[v(x)]^2}$.\nLet $u(\\pi) = t \\pi$ and $v(\\pi) = \\pi(t + c - 1) + (1 - c)$.\nThe derivatives with respect to $\\pi$ are:\n$u'(\\pi) = t$\n$v'(\\pi) = t + c - 1$\nApplying the quotient rule:\n$$\\frac{d}{d\\pi} PPV(\\pi) = \\frac{(t)[\\pi(t + c - 1) + (1 - c)] - (t \\pi)(t + c - 1)}{[\\pi(t + c - 1) + (1 - c)]^2}$$\nNow, we simplify the numerator:\n$$\\text{Numerator} = t\\pi(t + c - 1) + t(1 - c) - t\\pi(t + c - 1)$$\nThe first and third terms cancel each other out, leaving:\n$$\\text{Numerator} = t(1 - c)$$\nThe denominator is the square of the denominator of $PPV(\\pi)$. So, we can write the final derivative as:\n$$\\frac{d}{d\\pi} PPV(\\pi) = \\frac{t(1-c)}{[\\pi(t + c - 1) + (1 - c)]^2} = \\frac{t(1-c)}{\\left[ t\\pi + (1-c)(1-\\pi) \\right]^2}$$\nThis is the closed-form expression for the derivative of PPV with respect to $\\pi$. Since $t \\in (0,1)$ and $c \\in (0,1)$, the numerator $t(1-c)$ is always positive. The denominator is a squared term and thus is also positive. Therefore, the derivative is always positive, which confirms the known relationship that PPV increases with prevalence.",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{t\\pi}{t\\pi + (1-c)(1-\\pi)}  \\frac{c(1-\\pi)}{c(1-\\pi) + (1-t)\\pi}  \\frac{t(1-c)}{\\left(t\\pi + (1-c)(1-\\pi)\\right)^2} \\end{pmatrix}}$$"
        },
        {
            "introduction": "An AI model that outputs a probability of disease, such as $p=0.7$, doesn't tell a clinician what to *do*. The decision to act depends on weighing the consequences of being wrongâ€”the severe harm of a missed diagnosis versus the cost of an unnecessary intervention. This practice  guides you through the principles of Bayesian decision theory to derive an optimal decision threshold that minimizes expected costs, providing a rational framework for turning a model's prediction into a concrete clinical action.",
            "id": "4360388",
            "problem": "A hospital deploys a binary classifier to triage suspected sepsis using Electronic Health Record (EHR) data. For each patient encounter with features $x$, the model outputs a calibrated probability $p \\in [0,1]$ of true sepsis within $6$ hours, meaning $p = \\mathbb{P}(Y=1 \\mid x)$ where $Y \\in \\{0,1\\}$ denotes the true sepsis status. The clinical action set is $a \\in \\{1,0\\}$, where $a=1$ triggers an early sepsis protocol and $a=0$ does not trigger it.\n\nFrom a health systems science perspective, the hospital assigns a cost $C_{FP}  0$ to a false positive (unnecessary protocol) and a cost $C_{FN}  0$ to a false negative (missed sepsis). Assume baseline costs for true positives and true negatives are $0$. Using the principle of expected risk minimization under calibrated probabilities, do the following:\n\n1. Construct the conditional expected cost (risk) for each action $a \\in \\{1,0\\}$ as a function of $p$, $C_{FP}$, and $C_{FN}$.\n2. From first principles of Bayesian decision theory, derive the decision rule that minimizes conditional expected cost and show that it reduces to a threshold test $p \\ge \\tau$ for some threshold $\\tau$ expressed in terms of $C_{FP}$ and $C_{FN}$.\n3. For $C_{FP} = 200$ and $C_{FN} = 3000$, compute the numerical value of the optimal threshold $\\tau$.\n\nProvide your final answer as the single numeric value of $\\tau$ with no units. No rounding is required.",
            "solution": "The solution proceeds in three parts as requested by the problem statement.\n\n### 1. Construction of Conditional Expected Cost (Risk)\n\nLet $Y \\in \\{0, 1\\}$ be the random variable for the true patient state, where $Y=1$ indicates sepsis and $Y=0$ indicates no sepsis. Let $a \\in \\{0, 1\\}$ be the chosen action, where $a=1$ means triggering the protocol and $a=0$ means not triggering it. The model provides the calibrated probability $p = \\mathbb{P}(Y=1 \\mid x)$ for a given patient with features $x$. Consequently, $\\mathbb{P}(Y=0 \\mid x) = 1-p$.\n\nThe cost function, $C(a, Y)$, is defined based on the problem description:\n-   True Positive (TP): Action $a=1$, State $Y=1$. Cost $C(1,1) = 0$.\n-   False Positive (FP): Action $a=1$, State $Y=0$. Cost $C(1,0) = C_{FP}$.\n-   False Negative (FN): Action $a=0$, State $Y=1$. Cost $C(0,1) = C_{FN}$.\n-   True Negative (TN): Action $a=0$, State $Y=0$. Cost $C(0,0) = 0$.\n\nThe conditional expected cost, or risk, $R(a \\mid x)$, of taking an action $a$ given the information $x$ (and thus probability $p$) is the expectation of the cost function with respect to the conditional probability distribution of $Y$.\n$$R(a \\mid x) = \\mathbb{E}[C(a, Y) \\mid x] = \\sum_{y \\in \\{0,1\\}} C(a, y) \\mathbb{P}(Y=y \\mid x)$$\n\nWe compute the risk for each of the two possible actions:\n-   **Risk of action $a=1$ (trigger protocol):**\n    $$R(a=1 \\mid x) = C(1,1) \\mathbb{P}(Y=1 \\mid x) + C(1,0) \\mathbb{P}(Y=0 \\mid x)$$\n    $$R(a=1 \\mid x) = (0)(p) + (C_{FP})(1-p) = C_{FP}(1-p)$$\n\n-   **Risk of action $a=0$ (do not trigger protocol):**\n    $$R(a=0 \\mid x) = C(0,1) \\mathbb{P}(Y=1 \\mid x) + C(0,0) \\mathbb{P}(Y=0 \\mid x)$$\n    $$R(a=0 \\mid x) = (C_{FN})(p) + (0)(1-p) = C_{FN}p$$\n\n### 2. Derivation of the Optimal Decision Rule\n\nAccording to Bayesian decision theory, the optimal decision rule is to choose the action $a$ that minimizes the conditional expected cost $R(a \\mid x)$. We should therefore choose to trigger the protocol (action $a=1$) if and only if the risk of doing so is less than or equal to the risk of not doing so. The tie-breaking rule (choosing $a=1$ when risks are equal) is a common convention.\n\nThe decision rule is: choose $a=1$ if $R(a=1 \\mid x) \\le R(a=0 \\mid x)$.\nSubstituting the expressions for the risks derived in the previous step:\n$$C_{FP}(1-p) \\le C_{FN}p$$\n\nWe now solve this inequality for $p$:\n$$C_{FP} - C_{FP}p \\le C_{FN}p$$\n$$C_{FP} \\le C_{FN}p + C_{FP}p$$\n$$C_{FP} \\le p(C_{FN} + C_{FP})$$\n\nSince $C_{FP}  0$ and $C_{FN}  0$, the term $(C_{FN} + C_{FP})$ is strictly positive. We can divide by it without changing the direction of the inequality:\n$$p \\ge \\frac{C_{FP}}{C_{FN} + C_{FP}}$$\n\nThis demonstrates that the optimal decision rule is a threshold test. We should take action $a=1$ if the probability $p$ meets or exceeds a certain threshold $\\tau$. The threshold $\\tau$ is given by:\n$$\\tau = \\frac{C_{FP}}{C_{FN} + C_{FP}}$$\n\n### 3. Computation of the Numerical Threshold\n\nThe problem provides the specific cost values $C_{FP} = 200$ and $C_{FN} = 3000$. We can substitute these values into the expression for $\\tau$:\n$$\\tau = \\frac{200}{3000 + 200}$$\n$$\\tau = \\frac{200}{3200}$$\n\nSimplifying the fraction:\n$$\\tau = \\frac{2}{32} = \\frac{1}{16}$$\nTherefore, the optimal decision threshold is $\\frac{1}{16}$. The clinical protocol should be triggered if the model's predicted probability of sepsis is $p \\ge \\frac{1}{16}$.",
            "answer": "$$\\boxed{\\frac{1}{16}}$$"
        },
        {
            "introduction": "We often evaluate AI models against a \"gold standard\" diagnosis, but in many real-world scenarios, this reference test is itself imperfect. This introduces a critical challenge: if our yardstick is flawed, how can we accurately measure the true prevalence of a disease or a model's performance? This advanced exercise  equips you with a crucial epidemiological tool, showing how to work backwards from the observed results of an imperfect test to estimate the true, underlying disease prevalence in a population.",
            "id": "4360419",
            "problem": "A health system deploys an Artificial Intelligence (AI) screening algorithm as an imperfect reference test, denoted by the binary variable $R \\in \\{0,1\\}$, to flag potential cases of a disease whose true status is denoted by the binary variable $D \\in \\{0,1\\}$. The algorithm has constant sensitivity $s$, defined as $P(R=1 \\mid D=1)$, and constant specificity $c$, defined as $P(R=0 \\mid D=0)$, across the target population. In a large, representative retrospective cohort, the observed fraction of patients flagged positive is $P(R=1)$.\n\nStarting only from the definitions of sensitivity, specificity, the law of total probability, and the fact that $P(D=0)=1-P(D=1)$, derive a closed-form expression for the disease prevalence $P(D=1)$ in terms of $P(R=1)$, $s$, and $c$. Express your final answer as a single simplified analytic expression. No numerical rounding is required.",
            "solution": "The objective is to find an expression for the disease prevalence, which we will denote as $p = P(D=1)$, in terms of the given parameters. The core principle connecting the observed probability of a positive test, $P(R=1)$, to the prevalence is the law of total probability. This law allows us to express the marginal probability of an event by summing its conditional probabilities over a complete set of mutually exclusive events. In this case, the disjoint partition of the patient population is into those with the disease ($D=1$) and those without the disease ($D=0$).\n\nAccording to the law of total probability, $P(R=1)$ can be written as:\n$$P(R=1) = P(R=1 \\mid D=1)P(D=1) + P(R=1 \\mid D=0)P(D=0)$$\n\nWe are given the following definitions and information:\n1.  Prevalence: $p = P(D=1)$.\n2.  From this, it follows that $P(D=0) = 1 - P(D=1) = 1 - p$.\n3.  Sensitivity: $s = P(R=1 \\mid D=1)$.\n4.  Specificity: $c = P(R=0 \\mid D=0)$.\n\nTo use the law of total probability equation, we need the term $P(R=1 \\mid D=0)$. This is the probability of a positive test result given the absence of disease, commonly known as the false positive rate. Since the test result $R$ is binary, $P(R=1 \\mid D=0) + P(R=0 \\mid D=0) = 1$. Therefore, we can express the false positive rate in terms of specificity:\n$$P(R=1 \\mid D=0) = 1 - P(R=0 \\mid D=0) = 1 - c$$\n\nNow, we can substitute all these expressions into the law of total probability equation:\n$$P(R=1) = (s)(p) + (1-c)(1-p)$$\n\nThis equation establishes a linear relationship between the observable $P(R=1)$ and the unknown prevalence $p$. The next step is to perform algebraic manipulation to isolate $p$.\nFirst, expand the term on the right:\n$$P(R=1) = sp + 1 - p - c + cp$$\n\nNext, we group all terms containing $p$ on one side of the equation:\n$$P(R=1) = p(s - 1 + c) + (1 - c)$$\n\nTo solve for $p$, we first isolate the term $p(s - 1 + c)$:\n$$P(R=1) - (1 - c) = p(s - 1 + c)$$\n$$P(R=1) - 1 + c = p(s + c - 1)$$\n\nFinally, we divide by the coefficient of $p$, which is $(s + c - 1)$, to obtain the closed-form expression for the prevalence $p = P(D=1)$:\n$$p = \\frac{P(R=1) + c - 1}{s + c - 1}$$\n\nThis expression gives the disease prevalence, $P(D=1)$, solely in terms of the observed positive test rate, $P(R=1)$, the test's sensitivity, $s$, and its specificity, $c$. The denominator, $s+c-1$, is also known as Youden's J-statistic, a measure of a diagnostic test's performance. For a test to be informative, $s+c$ must be greater than $1$, ensuring the denominator is non-zero.",
            "answer": "$$\n\\boxed{\\frac{P(R=1) + c - 1}{s + c - 1}}\n$$"
        }
    ]
}