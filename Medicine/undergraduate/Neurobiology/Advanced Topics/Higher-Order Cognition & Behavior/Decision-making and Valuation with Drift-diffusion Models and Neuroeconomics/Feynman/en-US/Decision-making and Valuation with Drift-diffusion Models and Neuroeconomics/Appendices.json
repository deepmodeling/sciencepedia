{
    "hands_on_practices": [
        {
            "introduction": "One of the most powerful features of the Drift-Diffusion Model is its ability to formalize the well-known speed-accuracy tradeoff. This exercise demonstrates the direct link between the height of the decision boundary, which represents the amount of evidence required to commit to a choice, and the resulting decision accuracy. By deriving and applying the formula for choice probability, you will calculate the precise boundary setting needed to achieve a target level of performance, a core skill in fitting these models to behavioral data .",
            "id": "5011105",
            "problem": "A classic empirical phenomenon in two-alternative perceptual decision-making is the speed-accuracy tradeoff: subjects can increase decision speed by lowering their criterion for commitment at the expense of accuracy. Consider a neurally plausible evidence accumulation process modeled as a Drift-Diffusion Model (DDM), in which a scalar decision variable $x(t)$ evolves according to the stochastic differential equation $dx(t) = \\mu \\, dt + \\sigma \\, dW_t$, where $W_t$ is a standard Wiener process, $\\mu$ is a constant drift reflecting the average momentary evidence favoring the correct alternative, and $\\sigma$ is the diffusion amplitude reflecting neural variability. The process starts at $x(0) = 0$ and terminates when it hits either an upper absorbing boundary at $x = +A$ (committing to the correct choice when $\\mu > 0$) or a lower absorbing boundary at $x = -A$ (committing to the incorrect choice). Assume symmetric boundaries and an unbiased starting point.\n\nStarting from the Kolmogorov backward operator for this drift-diffusion process and appropriate boundary conditions for absorption at $\\pm A$, derive the expression for the probability of hitting the upper boundary when starting at $x(0) = 0$ in terms of $\\mu$, $\\sigma$, and $A$. Then, impose a fixed-accuracy policy with target accuracy $p^{\\star} = 0.82$ and compute the boundary magnitude $A$ required to achieve this accuracy for $\\mu = 0.75$ (evidence per second) and $\\sigma = 1.10$ (evidence per square-root second). Express the final $A$ in evidence units. Round your answer to four significant figures.",
            "solution": "The problem asks for two things: first, to derive the expression for the probability of making a correct decision in a Drift-Diffusion Model (DDM) with symmetric boundaries, and second, to calculate the boundary height $A$ required to achieve a specific accuracy $p^{\\star}$ for given model parameters.\n\n#### Part 1: Derivation of the Choice Probability\n\nLet $P(x)$ be the probability that the decision variable $x(t)$, starting at $x(0) = x$, hits the upper boundary at $+A$ before hitting the lower boundary at $-A$. We are interested in finding $P(0)$. This probability is also known as the accuracy or probability correct, $P_c$.\n\nFor an Itô process of the form $dx_t = a(x_t, t)dt + b(x_t, t)dW_t$, the probability of a first-passage event, like $P(x)$, satisfies the Kolmogorov backward equation. For our time-homogeneous process, $dx(t) = \\mu \\, dt + \\sigma \\, dW_t$, the drift term is $a(x) = \\mu$ and the diffusion term is $b(x) = \\sigma$. The Kolmogorov backward operator $\\mathcal{L}$ is given by:\n$$\n\\mathcal{L} = a(x)\\frac{d}{dx} + \\frac{1}{2}b(x)^2\\frac{d^2}{dx^2}\n$$\nFor our specific DDM, this becomes:\n$$\n\\mathcal{L} = \\mu\\frac{d}{dx} + \\frac{1}{2}\\sigma^2\\frac{d^2}{dx^2}\n$$\nThe probability $P(x)$ must satisfy the differential equation $\\mathcal{L}P(x) = 0$ for all starting points $x$ within the boundaries, i.e., for $x \\in (-A, A)$. This leads to the following second-order ordinary differential equation (ODE):\n$$\n\\frac{1}{2}\\sigma^2 \\frac{d^2P}{dx^2} + \\mu \\frac{dP}{dx} = 0\n$$\nThe boundary conditions are determined by the nature of absorption. If the process starts at the upper boundary, it is absorbed instantaneously, so the probability of hitting it is $1$. If it starts at the lower boundary, it is also absorbed, and the probability of hitting the upper boundary is $0$.\n$$\nP(A) = 1\n$$\n$$\nP(-A) = 0\n$$\nThe general solution to the ODE is of the form $P(x) = K_1 + K_2 \\exp\\left(-\\frac{2\\mu}{\\sigma^2}x\\right)$. We apply the boundary conditions to determine the constants $K_1$ and $K_2$:\n1. $P(A) = K_1 + K_2 \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right) = 1$\n2. $P(-A) = K_1 + K_2 \\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right) = 0$\n\nSolving this system of equations yields:\n$$\nP(x) = \\frac{\\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2\\mu x}{\\sigma^2}\\right)}{\\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right)}\n$$\nThe problem asks for the probability of a correct choice when starting from $x(0)=0$. We evaluate $P(x)$ at $x=0$:\n$$\nP(0) = \\frac{\\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right) - 1}{\\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right)}\n$$\nThis expression can be simplified by recognizing it as $\\frac{y-1}{y-1/y}$ where $y=\\exp\\left(\\frac{2\\mu A}{\\sigma^2}\\right)$. This simplifies to $\\frac{y}{y+1}$, which gives the final logistic (sigmoid) function for the probability of a correct choice:\n$$\nP(0) = \\frac{1}{1 + \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right)}\n$$\n\n#### Part 2: Calculation of the Boundary Height A\n\nWe are given a target accuracy $p^{\\star} = 0.82$. This corresponds to $P(0)$. We set our derived expression equal to $p^{\\star}$ and solve for $A$:\n$$\np^{\\star} = \\frac{1}{1 + \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right)}\n$$\nRearranging the equation to solve for $A$:\n$$\n1 + \\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right) = \\frac{1}{p^{\\star}}\n$$\n$$\n\\exp\\left(-\\frac{2\\mu A}{\\sigma^2}\\right) = \\frac{1}{p^{\\star}} - 1 = \\frac{1 - p^{\\star}}{p^{\\star}}\n$$\nTaking the natural logarithm of both sides:\n$$\n-\\frac{2\\mu A}{\\sigma^2} = \\ln\\left(\\frac{1 - p^{\\star}}{p^{\\star}}\\right)\n$$\nFinally, isolating $A$:\n$$\nA = -\\frac{\\sigma^2}{2\\mu} \\ln\\left(\\frac{1 - p^{\\star}}{p^{\\star}}\\right) = \\frac{\\sigma^2}{2\\mu} \\ln\\left(\\frac{p^{\\star}}{1 - p^{\\star}}\\right)\n$$\nNow, we substitute the given numerical values: $\\mu = 0.75$, $\\sigma = 1.10$, and $p^{\\star} = 0.82$.\n$$\nA = \\frac{(1.10)^2}{2(0.75)} \\ln\\left(\\frac{0.82}{1 - 0.82}\\right)\n$$\n$$\nA = \\frac{1.21}{1.5} \\ln\\left(\\frac{0.82}{0.18}\\right)\n$$\n$$\nA = \\frac{1.21}{1.5} \\ln\\left(\\frac{41}{9}\\right)\n$$\nCalculating the numerical value:\n$$\nA \\approx (0.80666...) \\times \\ln(4.5555...)\n$$\n$$\nA \\approx (0.80666...) \\times (1.5163475...)\n$$\n$$\nA \\approx 1.2229561\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\nA \\approx 1.223\n$$\nThe units of $A$ are evidence units, consistent with the definition of the decision variable $x(t)$.",
            "answer": "$$\\boxed{1.223}$$"
        },
        {
            "introduction": "Real-world decisions are rarely made in a vacuum; they are often influenced by prior knowledge or expectations. This practice explores how the DDM framework can incorporate such cognitive factors by adjusting the starting point of the evidence accumulation process. You will learn how to mathematically translate prior probabilities into a starting point bias and see how this initial advantage affects the final choice outcome .",
            "id": "5011103",
            "problem": "A two-alternative forced-choice decision in a neuroeconomic task is modeled as a Drift-Diffusion Model (DDM). The internal decision variable is the Log-Likelihood Ratio (LLR), denoted by $Y_t$, which evolves as a continuous-time stochastic process with dynamics given by the stochastic differential equation $dY_t = v\\,dt + \\sigma\\,dW_t$, where $v$ is the constant drift rate, $\\sigma$ is the diffusion coefficient, and $W_t$ is a standard Wiener process. The decision terminates when $Y_t$ reaches either the upper absorbing boundary at $+B$ (choose option $\\mathcal{A}$) or the lower absorbing boundary at $-B$ (choose option $\\mathcal{B}$). Prior beliefs about the options set the initial condition to the prior log-odds $Y_0 = \\ln\\!\\big(\\pi_{\\mathcal{A}}/\\pi_{\\mathcal{B}}\\big)$, providing a starting-point bias.\n\nStarting from the definition of the DDM and the boundary conditions described above, derive the closed-form expression for the probability of choosing option $\\mathcal{A}$ as a function of the parameters $v$, $\\sigma$, $B$, and the initial condition $Y_0$. Then evaluate this probability for $v = 0.4$ (in log-odds units per second), $\\sigma = 1.2$ (in log-odds units per square-root second), $B = 1.1$ (in log-odds units), and prior probabilities $\\pi_{\\mathcal{A}} = 0.65$ and $\\pi_{\\mathcal{B}} = 0.35$. Express the final probability as a decimal and round your answer to four significant figures.",
            "solution": "The problem requires us to derive the probability of choosing option $\\mathcal{A}$ in a Drift-Diffusion Model (DDM) with a biased starting point and then to calculate this probability for a given set of parameters.\n\n#### Part 1: Derivation of Choice Probability\n\nLet $P(y)$ be the probability that the decision variable $Y_t$, starting at an initial point $Y_0 = y$, hits the upper boundary at $+B$ before the lower boundary at $-B$. For a time-homogeneous Itô process like the DDM described by $dY_t = v\\,dt + \\sigma\\,dW_t$, this probability function $P(y)$ must satisfy the stationary backward Kolmogorov equation. The generator $\\mathcal{L}$ for this process is $\\mathcal{L} = v \\frac{d}{dy} + \\frac{1}{2}\\sigma^2 \\frac{d^2}{dy^2}$. The condition $\\mathcal{L}P(y) = 0$ for $y \\in (-B, B)$ gives the ordinary differential equation (ODE):\n$$\n\\frac{1}{2}\\sigma^2 \\frac{d^2P}{dy^2} + v \\frac{dP}{dy} = 0\n$$\nThe boundary conditions are given by the absorbing nature of the boundaries: if the process starts at $+B$, the probability of choosing $\\mathcal{A}$ is 1, and if it starts at $-B$, the probability is 0.\n$$\nP(B) = 1\n$$\n$$\nP(-B) = 0\n$$\nThe characteristic equation for this second-order linear homogeneous ODE is $\\frac{1}{2}\\sigma^2 r^2 + vr = 0$, which has roots $r_1=0$ and $r_2 = -2v/\\sigma^2$. The general solution is therefore:\n$$\nP(y) = C_1 + C_2 \\exp\\left(-\\frac{2v}{\\sigma^2}y\\right)\n$$\nWe use the boundary conditions to find the constants $C_1$ and $C_2$:\n1.  $P(B) = C_1 + C_2 \\exp\\left(-\\frac{2vB}{\\sigma^2}\\right) = 1$\n2.  $P(-B) = C_1 + C_2 \\exp\\left(\\frac{2vB}{\\sigma^2}\\right) = 0$\n\nSolving this system of equations for $C_1$ and $C_2$ and substituting them back into the general solution gives the probability of hitting the upper boundary from a starting point $y$:\n$$\nP(y) = \\frac{\\exp\\left(\\frac{2vB}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2vy}{\\sigma^2}\\right)}{\\exp\\left(\\frac{2vB}{\\sigma^2}\\right) - \\exp\\left(-\\frac{2vB}{\\sigma^2}\\right)}\n$$\nThe problem specifies the starting point $y=Y_0$. Thus, the probability of choosing option $\\mathcal{A}$ is $P(Y_0)$.\n\n#### Part 2: Numerical Evaluation\n\nWe are given the following parameters:\n-   Drift rate $v = 0.4$\n-   Diffusion coefficient $\\sigma = 1.2$\n-   Boundary magnitude $B = 1.1$\n-   Prior probabilities $\\pi_{\\mathcal{A}} = 0.65$ and $\\pi_{\\mathcal{B}} = 0.35$\n\nFirst, we calculate the starting point $Y_0$ from the prior log-odds:\n$$\nY_0 = \\ln\\left(\\frac{\\pi_{\\mathcal{A}}}{\\pi_{\\mathcal{B}}}\\right) = \\ln\\left(\\frac{0.65}{0.35}\\right) = \\ln\\left(\\frac{13}{7}\\right) \\approx 0.619039\n$$\nNext, we calculate the key exponent term $\\frac{2v}{\\sigma^2}$:\n$$\n\\frac{2v}{\\sigma^2} = \\frac{2 \\times 0.4}{(1.2)^2} = \\frac{0.8}{1.44} = \\frac{5}{9}\n$$\nNow, we can substitute all values into the probability formula $P(Y_0)$:\n$$\nP(\\text{choose } \\mathcal{A}) = \\frac{\\exp\\left(\\frac{2(0.4)(1.1)}{(1.2)^2}\\right) - \\exp\\left(-\\frac{2(0.4)(0.619039)}{(1.2)^2}\\right)}{\\exp\\left(\\frac{2(0.4)(1.1)}{(1.2)^2}\\right) - \\exp\\left(-\\frac{2(0.4)(1.1)}{(1.2)^2}\\right)}\n$$\n$$\nP(\\text{choose } \\mathcal{A}) = \\frac{\\exp\\left(\\frac{11}{9}\\right) - \\exp\\left(-\\frac{5}{9} \\times 0.619039\\right)}{\\exp\\left(\\frac{11}{9}\\right) - \\exp\\left(-\\frac{11}{9}\\right)}\n$$\n$$\nP(\\text{choose } \\mathcal{A}) \\approx \\frac{\\exp(1.222222) - \\exp(-0.343911)}{\\exp(1.222222) - \\exp(-1.222222)} \\approx \\frac{3.39485 - 0.70901}{3.39485 - 0.29457} \\approx \\frac{2.68584}{3.10028} \\approx 0.86632\n$$\nLet's use an alternative form of the solution for simpler calculation: $P(y) = \\frac{1 - \\exp\\left(-\\frac{2v(y+B)}{\\sigma^2}\\right)}{1 - \\exp\\left(-\\frac{4vB}{\\sigma^2}\\right)}$.\n-   Numerator argument: $-\\frac{2v(Y_0+B)}{\\sigma^2} = -\\frac{5}{9} (0.619039 + 1.1) \\approx -0.955022$\n-   Denominator argument: $-\\frac{4vB}{\\sigma^2} = -\\frac{5}{9} (2 \\times 1.1) = -\\frac{11}{9} \\approx -1.222222$\n$$\nP(\\text{choose } \\mathcal{A}) = \\frac{1 - \\exp(-0.955022)}{1 - \\exp(-1.222222)} \\approx \\frac{1 - 0.384813}{1 - 0.294570} = \\frac{0.615187}{0.705430} \\approx 0.872080\n$$\nRounding the final answer to four significant figures, we get 0.8721.",
            "answer": "$$\n\\boxed{0.8721}\n$$"
        },
        {
            "introduction": "Our choices are often linked in a sequence, with past decisions influencing future ones. This hands-on programming exercise challenges you to model these sequential dependencies, a phenomenon known as history bias. You will implement a DDM where the starting point is dynamically shifted based on the outcome of the previous trial, providing practical experience in simulating and analyzing more complex and realistic patterns of behavior .",
            "id": "5011115",
            "problem": "A central construct in neuroeconomics and decision neuroscience is the drift–diffusion process for evidence accumulation. Consider a two-alternative forced-choice decision modeled by a one-dimensional stochastic differential equation for the latent decision variable $X_t$,\n$$\ndX_t \\;=\\; v\\,dt \\;+\\; \\sigma\\,dW_t,\n$$\nwith absorbing boundaries at $X_t=0$ (lower boundary) and $X_t=a$ (upper boundary), and an initial condition $X_0=z$ where $z\\in[0,a]$. Here $v$ is the drift, $\\sigma&gt;0$ is the diffusion scale, $W_t$ is a standard Wiener process, and $a&gt;0$ is the boundary separation. The realization that hits the upper boundary is mapped to the “upper” choice, while hitting the lower boundary is mapped to the “lower” choice.\n\nSequential dependencies and history biases are commonly incorporated by allowing the starting point $z$ on trial $n$ to depend on the previous choice $c_{n-1}\\in\\{+1,-1\\}$ as\n$$\nz \\;=\\; \\frac{a}{2} \\;+\\; b\\,c_{n-1},\n$$\nwhere $b$ is a constant “stay” bias magnitude in units of the decision coordinate. A positive $b$ produces a tendency to repeat the previous choice (“stay”), whereas a negative $b$ produces a tendency to alternate (“switch”). For plausibility, $z$ is clipped to the interval $[0,a]$. The drift on the current trial is coupled to a signed stimulus strength $s$ by a proportionality constant $k&gt;0$ via\n$$\nv \\;=\\; k\\,s.\n$$\nAssume the diffusion has variance per unit time $\\sigma^2$ and that non-decision latency does not affect choice probabilities. You may assume standard regularity of $W_t$ and the well-posedness of the absorbing boundary value problem.\n\nTask:\n- From first principles appropriate to stochastic processes in neurobiology, derive the closed-form expression for the probability that the process starting at $z$ is absorbed at the upper boundary before the lower boundary, as a function of $v$, $\\sigma$, $a$, and $z$, including the correct limiting behavior when $v=0$ and the boundary-start edge cases $z\\in\\{0,a\\}$. Justify each step using the backward equation or an equivalent fundamental tool.\n- Using that expression, define the next-trial repeat probability given the previous choice $c_{n-1}$ as follows: if $c_{n-1}=+1$, the repeat probability equals the absorption probability at the upper boundary; if $c_{n-1}=-1$, the repeat probability equals one minus that absorption probability.\n- Implement an algorithm to compute this repeat probability deterministically for given parameters, with proper handling of limits and edge cases.\n\nInput parameters for each test case:\n- Boundary separation $a$.\n- Diffusion scale $\\sigma$.\n- Drift gain $k$.\n- Signed stimulus strength $s$.\n- History bias magnitude $b$.\n- Previous choice $c_{n-1}\\in\\{+1,-1\\}$.\n\nFor numerical reporting consistency, round each repeat probability to six decimal places.\n\nTest suite:\n- Case 1 (general “happy path”): $a=1.0$, $\\sigma=1.0$, $k=0.8$, $s=0.5$, $b=0.1$, $c_{n-1}=+1$.\n- Case 2 (zero-drift limit): $a=1.0$, $\\sigma=1.0$, $k=0.5$, $s=0.0$, $b=0.2$, $c_{n-1}=+1$.\n- Case 3 (negative previous choice and nonunit scales): $a=1.2$, $\\sigma=0.9$, $k=1.0$, $s=0.6$, $b=0.15$, $c_{n-1}=-1$.\n- Case 4 (starting at the boundary due to strong stay bias): $a=1.0$, $\\sigma=1.0$, $k=0.5$, $s=1.5$, $b=0.5$, $c_{n-1}=+1$.\n- Case 5 (negative drift with weak bias): $a=1.0$, $\\sigma=0.5$, $k=0.4$, $s=-0.2$, $b=0.05$, $c_{n-1}=+1$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the six-decimal rounded repeat probabilities for the five cases, as a comma-separated list enclosed in square brackets (for example, “$[0.500000,0.600000,0.700000,0.800000,0.900000]$”). No other text should be printed.",
            "solution": "The primary task is to derive the probability that a one-dimensional diffusion process is absorbed at its upper boundary before its lower boundary. The process is described by the stochastic differential equation for the decision variable $X_t$:\n$$\ndX_t = v\\,dt + \\sigma\\,dW_t\n$$\nwhere $X_t$ evolves from a starting point $X_0 = z \\in [0, a]$. The process terminates upon hitting either the lower boundary at $0$ or the upper boundary at $a > 0$. We seek to find the probability of hitting the upper boundary first, which we denote as $p(z) = P(\\tau_a < \\tau_0 | X_0=z)$, where $\\tau_k$ is the first passage time to boundary $k$.\n\nTo derive $p(z)$, we use the backward Kolmogorov equation. For our specific drift-diffusion model, the generator $\\mathcal{L}$ is $v\\frac{d}{dz} + \\frac{1}{2}\\sigma^2\\frac{d^2}{dz^2}$. Setting $\\mathcal{L}p(z)=0$ yields the following second-order ordinary differential equation (ODE):\n$$\n\\frac{1}{2}\\sigma^2\\frac{d^2p}{dz^2} + v\\frac{dp}{dz} = 0\n$$\nThis ODE must be solved subject to boundary conditions derived from the definition of $p(z)$. If the process starts at the upper boundary $z=a$, it is absorbed there immediately with probability $1$. If it starts at the lower boundary $z=0$, the probability of being absorbed at the upper boundary *first* is $0$. Thus, the boundary conditions are:\n$$\np(0) = 0 \\quad \\text{and} \\quad p(a) = 1\n$$\n\nWe now solve this boundary value problem. We consider two cases for the drift rate $v$.\n\nCase 1: $v \\neq 0$.\nThe general solution to the ODE is $p(z) = C_1 + C_2 e^{-\\frac{2vz}{\\sigma^2}}$. Applying the boundary conditions:\n$p(0) = 0 \\implies C_1 + C_2 = 0 \\implies C_1 = -C_2$.\n$p(a) = 1 \\implies C_1 + C_2 e^{-\\frac{2va}{\\sigma^2}} = 1$.\nSubstituting $C_1 = -C_2$ into the second equation gives $C_2(e^{-\\frac{2va}{\\sigma^2}} - 1) = 1$, so $C_2 = \\frac{1}{e^{-2va/\\sigma^2} - 1}$.\nThis gives the final solution:\n$$\np(z) = \\frac{-1 + e^{-\\frac{2vz}{\\sigma^2}}}{e^{-2va/\\sigma^2} - 1} = \\frac{1 - e^{-\\frac{2vz}{\\sigma^2}}}{1 - e^{-\\frac{2va}{\\sigma^2}}}\n$$\nThis is the closed-form solution for the absorption probability at the upper boundary when $v \\neq 0$.\n\nCase 2: $v = 0$ (zero-drift limit).\nWhen $v=0$, the ODE simplifies to $\\frac{d^2p}{dz^2} = 0$. Integrating twice yields a linear solution: $p(z) = C_1 z + C_2$.\nApplying the boundary conditions:\n$p(0) = 0 \\implies C_2 = 0$.\n$p(a) = 1 \\implies C_1 a = 1 \\implies C_1 = 1/a$.\nThus, for $v=0$, the solution is:\n$$\np(z) = \\frac{z}{a}\n$$\nThis result is intuitive: with no drift, the probability of hitting a boundary is linearly proportional to the starting distance from the other boundary. This can also be shown to be the limit of the general solution as $v \\to 0$ via L'Hôpital's rule.\n\nNow we formulate the algorithm to compute the repeat probability for a given trial.\n1.  Calculate the drift rate $v$ from the stimulus strength $s$ and gain $k$:\n    $$v = k\\,s$$\n2.  Calculate the initial position $z_{raw}$ based on the previous choice $c_{n-1} \\in \\{+1, -1\\}$ and bias magnitude $b$:\n    $$z_{raw} = \\frac{a}{2} + b\\,c_{n-1}$$\n3.  Clip the starting point $z$ to ensure it lies within the decision boundaries $[0, a]$:\n    $$z = \\max(0, \\min(a, z_{raw}))$$\n4.  Calculate the probability of absorption at the upper boundary, $P_{upper} = p(z)$, using the derived formulae. Special care must be taken for the $v=0$ case to ensure numerical stability.\n    $$\n    P_{upper} = \\begin{cases}\n    \\frac{z}{a} & \\text{if } v = 0 \\\\\n    \\frac{1 - e^{-2vz/\\sigma^2}}{1 - e^{-2va/\\sigma^2}} & \\text{if } v \\neq 0\n    \\end{cases}\n    $$\n5.  Determine the next-trial repeat probability, $P_{repeat}$, based on the previous choice $c_{n-1}$. Repeating a choice means choosing \"upper\" if the previous choice was \"upper\" ($c_{n-1}=+1$) or choosing \"lower\" if the previous choice was \"lower\" ($c_{n-1}=-1$).\n    - If $c_{n-1} = +1$, a repeat is an \"upper\" choice. The probability is $P_{upper}$.\n    - If $c_{n-1} = -1$, a repeat is a \"lower\" choice. The probability is $P(\\text{hit } 0) = 1 - P(\\text{hit } a) = 1 - P_{upper}$.\n    Therefore:\n    $$\n    P_{repeat} = \\begin{cases}\n    P_{upper} & \\text{if } c_{n-1} = +1 \\\\\n    1 - P_{upper} & \\text{if } c_{n-1} = -1\n    \\end{cases}\n    $$\nFinally, the result is rounded to six decimal places as required.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the repeat probability for a series of drift-diffusion model test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (a, sigma, k, s, b, c_n-1)\n    test_cases = [\n        (1.0, 1.0, 0.8, 0.5, 0.1, 1),   # Case 1\n        (1.0, 1.0, 0.5, 0.0, 0.2, 1),   # Case 2\n        (1.2, 0.9, 1.0, 0.6, 0.15, -1), # Case 3\n        (1.0, 1.0, 0.5, 1.5, 0.5, 1),   # Case 4\n        (1.0, 0.5, 0.4, -0.2, 0.05, 1)  # Case 5\n    ]\n\n    results = []\n    \n    # A small tolerance for floating point comparison with zero.\n    epsilon = 1e-12\n\n    for case in test_cases:\n        a, sigma, k, s, b, c_prev = case\n\n        # 1. Calculate drift rate v\n        v = k * s\n\n        # 2. Calculate initial position z_raw\n        z_raw = a / 2.0 + b * c_prev\n\n        # 3. Clip starting point z to be within [0, a]\n        z = np.clip(z_raw, 0, a)\n\n        # 4. Calculate the probability of absorption at the upper boundary, p_upper\n        p_upper = 0.0\n\n        if a <= 0: # Defensive check, though problem implies a > 0\n            if z > 0:\n                p_upper = 1.0\n            else:\n                p_upper = 0.0\n        elif abs(v) < epsilon:\n            # Handle v=0 case (linear solution)\n            p_upper = z / a\n        else:\n            # Handle v!=0 case (exponential solution)\n            # Check for z being at a boundary, which are trivial cases\n            if z == 0:\n                p_upper = 0.0\n            elif z == a:\n                p_upper = 1.0\n            else:\n                # Using np.expm1(x) = exp(x) - 1 for numerical stability\n                exponent_arg_z = -2.0 * v * z / (sigma**2)\n                exponent_arg_a = -2.0 * v * a / (sigma**2)\n                \n                numerator = -np.expm1(exponent_arg_z)\n                denominator = -np.expm1(exponent_arg_a)\n                \n                if abs(denominator) < epsilon:\n                    p_upper = z / a # Fallback to linear approximation\n                else: \n                     p_upper = numerator / denominator\n\n        # 5. Determine the repeat probability based on the previous choice\n        if c_prev == 1:\n            p_repeat = p_upper\n        else:  # c_prev == -1\n            p_repeat = 1.0 - p_upper\n\n        # Round to six decimal places for reporting\n        results.append(round(p_repeat, 6))\n\n    # Format the final output string as specified.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}