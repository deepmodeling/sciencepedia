{
    "hands_on_practices": [
        {
            "introduction": "信息论为我们量化神经元传递的信息量提供了一个强大的数学框架。这项练习将引导你从一个最基础的模型入手：一个带有高斯噪声的简单线性通道，来推导刺激与响应之间的互信息。这个经典的计算不仅能让你熟练运用熵和互信息的定义，更揭示了信噪比如何从根本上决定了信息传输的理论上限。",
            "id": "5037464",
            "problem": "在一个简化的单个感觉神经元神经编码模型中，标量刺激 $S$ 表示围绕基线的偏差，并被建模为一个均值为零、方差为 $\\sigma_{S}^{2}$ 的高斯随机变量，即 $S \\sim \\mathcal{N}(0,\\sigma_{S}^{2})$。神经元的响应 $R$ 被假定为线性的，并受到独立的加性噪声 $N \\sim \\mathcal{N}(0,\\sigma_{N}^{2})$ 的干扰，其中 $S$ 和 $N$ 相互独立，因此 $R = S + N$。以用微分熵表示的互信息定义和高斯随机变量的经过充分检验的性质为基础出发点，推导该模型中刺激与响应之间的互信息 $I(S;R)$ 的闭式表达式。使用自然对数，使得信息量以奈特 (nats) 为单位进行度量。你的最终答案必须用 $\\sigma_{S}^{2}$ 和 $\\sigma_{N}^{2}$ 进行符号化表示，并且不要进行近似。最终答案必须是单个闭式解析表达式。",
            "solution": "该问题是有效的，因为它在信息论和统计学方面有科学依据，提法恰当，具有唯一且有意义的解，并使用客观、正式的语言进行陈述。所有必要的信息都已提供，并且没有矛盾或含糊之处。\n\n目标是推导刺激 $S$ 和神经响应 $R$ 之间的互信息 $I(S;R)$ 的闭式表达式。该模型由以下给定条件定义：\n1.  刺激 $S$ 是一个均值为零、方差为 $\\sigma_{S}^{2}$ 的高斯随机变量，记作 $S \\sim \\mathcal{N}(0, \\sigma_{S}^{2})$。\n2.  响应 $R$ 由线性关系 $R = S + N$ 给出。\n3.  噪声 $N$ 是一个独立的均值为零、方差为 $\\sigma_{N}^{2}$ 的高斯随机变量，记作 $N \\sim \\mathcal{N}(0, \\sigma_{N}^{2})$。\n4.  刺激 $S$ 和噪声 $N$ 在统计上是独立的。\n\n我们从用微分熵表示的互信息定义开始。对于连续随机变量 $S$ 和 $R$，互信息由下式给出：\n$$\nI(S;R) = H(R) - H(R|S)\n$$\n其中 $H(R)$ 是响应 $R$ 的微分熵，$H(R|S)$ 是在给定 $S$ 的条件下 $R$ 的条件微分熵。我们将分别计算这些项。\n\n首先，我们确定响应 $R$ 的分布。由于 $R$ 是两个独立高斯随机变量 $S$ 和 $N$ 的和，$R$ 本身也是一个高斯随机变量。\n$R$ 的均值是 $S$ 和 $N$ 的均值之和：\n$$\nE[R] = E[S+N] = E[S] + E[N] = 0 + 0 = 0\n$$\n由于它们的独立性，$R$ 的方差是 $S$ 和 $N$ 的方差之和：\n$$\n\\text{Var}(R) = \\text{Var}(S+N) = \\text{Var}(S) + \\text{Var}(N) = \\sigma_{S}^{2} + \\sigma_{N}^{2}\n$$\n因此，响应的分布为 $R \\sim \\mathcal{N}(0, \\sigma_{S}^{2} + \\sigma_{N}^{2})$。\n\n当使用自然对数（以奈特为单位度量）时，高斯随机变量 $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 的微分熵 $H(X)$ 由以下公式给出：\n$$\nH(X) = \\frac{1}{2} \\ln(2\\pi e \\sigma^2)\n$$\n将此公式应用于响应变量 $R$，我们得到其熵：\n$$\nH(R) = \\frac{1}{2} \\ln\\left(2\\pi e (\\sigma_{S}^{2} + \\sigma_{N}^{2})\\right)\n$$\n\n接下来，我们计算条件熵 $H(R|S)$。这一项表示当 $S$ 的值已知时，$R$ 中剩余的不确定性。如果我们以特定刺激值 $S=s$ 为条件，响应方程变为 $R = s + N$。在此情境下，由于 $s$ 是一个固定值，$R$ 中的随机性完全来自于噪声 $N$。在给定 $S=s$ 的条件下，$R$ 的分布是一个高斯分布，其均值为 $E[R|S=s] = E[s+N] = s + E[N] = s$，方差为 $\\text{Var}(R|S=s) = \\text{Var}(s+N) = \\text{Var}(N) = \\sigma_{N}^{2}$。因此，$R|S=s \\sim \\mathcal{N}(s, \\sigma_{N}^{2})$。\n\n这个条件分布的熵为：\n$$\nH(R|S=s) = \\frac{1}{2} \\ln(2\\pi e \\sigma_{N}^{2})\n$$\n注意，这个表达式是一个常数，不依赖于 $s$ 的具体值。条件熵 $H(R|S)$ 是 $H(R|S=s)$ 在 $S$ 的所有可能值上的期望：\n$$\nH(R|S) = E_S[H(R|S=s)] = E_S\\left[\\frac{1}{2} \\ln(2\\pi e \\sigma_{N}^{2})\\right]\n$$\n由于期望内的表达式相对于 $S$ 是一个常数，期望就是该常数本身：\n$$\nH(R|S) = \\frac{1}{2} \\ln(2\\pi e \\sigma_{N}^{2})\n$$\n\n最后，我们将 $H(R)$ 和 $H(R|S)$ 的表达式代入互信息的定义中：\n$$\nI(S;R) = H(R) - H(R|S) = \\frac{1}{2} \\ln\\left(2\\pi e (\\sigma_{S}^{2} + \\sigma_{N}^{2})\\right) - \\frac{1}{2} \\ln(2\\pi e \\sigma_{N}^{2})\n$$\n使用对数性质 $\\ln(a) - \\ln(b) = \\ln(a/b)$，我们可以简化表达式：\n$$\nI(S;R) = \\frac{1}{2} \\left[ \\ln\\left(2\\pi e (\\sigma_{S}^{2} + \\sigma_{N}^{2})\\right) - \\ln(2\\pi e \\sigma_{N}^{2}) \\right] = \\frac{1}{2} \\ln\\left(\\frac{2\\pi e (\\sigma_{S}^{2} + \\sigma_{N}^{2})}{2\\pi e \\sigma_{N}^{2}}\\right)\n$$\n分子和分母中的 $2\\pi e$ 项相互抵消：\n$$\nI(S;R) = \\frac{1}{2} \\ln\\left(\\frac{\\sigma_{S}^{2} + \\sigma_{N}^{2}}{\\sigma_{N}^{2}}\\right)\n$$\n通过分离分数，可以将其写成更标准的形式：\n$$\nI(S;R) = \\frac{1}{2} \\ln\\left(1 + \\frac{\\sigma_{S}^{2}}{\\sigma_{N}^{2}}\\right)\n$$\n项 $\\frac{\\sigma_{S}^{2}}{\\sigma_{N}^{2}}$ 是系统的信噪比 (SNR)。这个结果是信息论中高斯信道的一个基本公式。",
            "answer": "$$\n\\boxed{\\frac{1}{2} \\ln\\left(1 + \\frac{\\sigma_{S}^{2}}{\\sigma_{N}^{2}}\\right)}\n$$"
        },
        {
            "introduction": "理论模型需要用真实数据来检验。在神经科学中，泊松过程是描述神经元发放活动最常用的基准模型，其标志性特征是发放计数的方差等于均值。这项编码练习将指导你分析神经元发放计数序列，计算法诺因子（Fano factor），并构建统计检验来判断真实的神经活动是否偏离了泊松过程的预测。掌握这项技能，是你从数据出发，探索神经编码内在统计结构的关键一步。",
            "id": "5037305",
            "problem": "给定从单个神经元在等长、不重叠的时间窗口中观测到的非负整数脉冲计数的有限序列。假设平稳性，因此所有窗口共享一个共同的潜在平均速率，并且窗口之间相互独立。从神经编码和统计推断的基本原理出发，设计一个程序，为每个序列估计脉冲计数的离散度，并检验数据是否偏离泊松过程。设计必须遵循以下要求。\n\n基本基础：\n- 一个窗口内的脉冲计数被建模为一个取值为 $\\{0,1,2,\\dots\\}$ 的随机变量 $X$。\n- 对于 $n$ 个窗口，样本均值定义为 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$，无偏样本方差定义为 $s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})^2$。\n- 神经编码中使用的法诺因子根据潜在分布定义为 $F = \\frac{\\mathrm{Var}[X]}{\\mathbb{E}[X]}$。对于在所有窗口中速率参数恒定的泊松过程，其等离散性质意味着 $\\mathrm{Var}[X] = \\mathbb{E}[X]$，即 $F = 1$。\n- 当共同均值从数据中估计时，根据等离散性质，定义为缩放方差均值比的离散指数近似服从自由度为 $n-1$ 的卡方分布。\n\n任务：\n- 对于每个测试用例序列 $\\{x_i\\}_{i=1}^{n}$，仅使用 $\\bar{x}$ 和 $s^2$ 计算法诺因子 $\\hat{F}$ 的估计值。\n- 使用离散指数的卡方近似，为模型 $\\mathrm{Var}[X] = \\phi \\,\\mathbb{E}[X]$ 中的离散参数 $\\phi$ 构建一个双侧置信区间。使用置信水平 $0.95$，这对应于显著性水平 $\\alpha = 0.05$。\n- 通过检查数值 $1$ 是否位于为 $\\phi$ 构建的置信区间内，来判断是否偏离泊松过程。如果数据偏离泊松过程，则返回布尔值 true，否则返回 false。\n\n重要细节：\n- 如果 $\\bar{x} = 0$，不要尝试计算 $\\hat{F}$ 或置信区间；对于无法从数据中计算的未定义量，应返回一个非数值（non-number）。\n- 如果 $n = 1$，将样本方差视为未定义，并遵循同样的做法，对需要方差的量返回非数值。\n- 程序在其输入或输出中不得假定任何角度或物理单位。\n- 对于每个测试用例，程序必须输出一个四元组 $(\\hat{F}, L, U, B)$，其中 $L$ 和 $U$ 是置信水平为 $0.95$ 时 $\\phi$ 的置信区间的下界和上界，$B$ 是基于 $1$ 是否位于 $[L, U]$ 之外的关于偏离泊松过程的布尔决策。\n\n测试套件：\n使用以下五个脉冲计数序列作为输入测试套件。每个序列都是在等长时间窗口内获得的，并按顺序列出。\n1. 一个具有中等离散度的典型案例：$[2,3,1,2,0,4,2,1,3,2,2,1,3,2,1,2,3,1,2,2]$。\n2. 一个过离散的案例：$[0,7,2,10,3,8,1,9,4,6,0,11]$。\n3. 一个欠离散的常数案例：$[3,3,3,3,3,3,3,3,3,3]$。\n4. 一个小样本边界案例：$[0,1,0]$。\n5. 一个低均值的稀疏案例：$[0,0,1,0,1,0,1,0,0,1]$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含五个测试用例的结果，形式为一个用方括号括起来的逗号分隔列表。列表中的每个元素本身必须是一个形式为 $(\\hat{F}, L, U, B)$ 的元组，其中前三个元素是浮点数，最后一个元素是布尔值。例如，输出应类似于 $[ (\\hat{F}_1,L_1,U_1,B_1),(\\hat{F}_2,L_2,U_2,B_2),\\dots ]$，不含任何附加文本。",
            "solution": "该问题要求设计一个统计程序，以检验一系列神经脉冲计数是否偏离泊松过程。这通过估计计数的离散度并为离散参数构建一个置信区间来完成。整个分析都基于应用于神经科学的统计推断基本原理。\n\n问题的核心在于量化脉冲计数相对于其均值的变异性。对于泊松过程，一个关键特征是等离散性，即方差等于均值。偏离此性质的表现，无论是过离散（方差大于均值）还是欠离散（方差小于均值），都表明潜在的脉冲生成机制不是一个简单的泊松过程。\n\n设从单个神经元在 $n$ 个等长、不重叠时间窗口中观测到的非负整数脉冲计数序列为 $\\{x_1, x_2, \\dots, x_n\\}$。我们将这些计数建模为来自一个随机变量 $X$ 的独立同分布样本。\n\n样本均值 $\\bar{x}$ 是真实均值 $\\mu = \\mathbb{E}[X]$ 的估计量：\n$$ \\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i $$\n无偏样本方差 $s^2$ 是真实方差 $\\sigma^2 = \\mathrm{Var}[X]$ 的估计量：\n$$ s^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2 $$\n神经脉冲序列分析中的一个核心量是法诺因子，它根据潜在分布定义为 $F = \\frac{\\mathrm{Var}[X]}{\\mathbb{E}[X]}$。对于泊松过程，$F=1$。法诺因子的一个自然估计量，我们记为 $\\hat{F}$，是样本方差与样本均值的比率：\n$$ \\hat{F} = \\frac{s^2}{\\bar{x}} $$\n为了形式化地检验是否偏离泊松过程，我们采用广义模型 $\\mathrm{Var}[X] = \\phi \\mathbb{E}[X]$，其中 $\\phi$ 是一个无量纲的离散参数。在这个模型中，法诺因子 $F$ 与 $\\phi$ 相同。过程是泊松过程的零假设 $H_0$ 等价于检验 $H_0: \\phi = 1$。备择假设 $H_1$ 是过程不是泊松过程，对应于 $\\phi \\neq 1$。\n\n为了检验这个假设，我们为 $\\phi$ 构建一个置信区间。这通过使用一个枢轴量来实现，该量的抽样分布（至少是近似地）是已知的，并且独立于参数 $\\phi$。根据问题陈述，我们使用这样一个事实：在某些假设下（例如数据呈正态分布，这对于均值足够大的泊松分布是近似成立的），离散指数统计量服从卡方分布。枢轴量 $Q$ 定义为：\n$$ Q = \\frac{(n-1)s^2}{\\phi \\bar{x}} $$\n该量近似服从自由度为 $n-1$ 的卡方随机变量分布，记为 $\\chi^2_{n-1}$。\n$$ Q \\sim \\chi^2_{n-1} $$\n对于置信水平为 $1-\\alpha$ 的双侧置信区间，我们从 $\\chi^2_{n-1}$ 分布中找到下临界值和上临界值。设 $\\chi^2_{\\alpha/2, n-1}$ 是满足 $P(\\chi^2_{n-1} \\le \\chi^2_{\\alpha/2, n-1}) = \\alpha/2$ 的值，设 $\\chi^2_{1-\\alpha/2, n-1}$ 是满足 $P(\\chi^2_{n-1} \\le \\chi^2_{1-\\alpha/2, n-1}) = 1-\\alpha/2$ 的值。置信区间由以下概率陈述导出：\n$$ P\\left( \\chi^2_{\\alpha/2, n-1} \\le Q \\le \\chi^2_{1-\\alpha/2, n-1} \\right) \\approx 1-\\alpha $$\n代入 $Q$ 的表达式并整理不等式以分离出 $\\phi$，我们得到：\n$$ P\\left( \\frac{(n-1)s^2}{\\bar{x} \\cdot \\chi^2_{1-\\alpha/2, n-1}} \\le \\phi \\le \\frac{(n-1)s^2}{\\bar{x} \\cdot \\chi^2_{\\alpha/2, n-1}} \\right) \\approx 1-\\alpha $$\n因此，$\\phi$ 的置信区间的下界 $L$ 和上界 $U$ 分别是：\n$$ L = \\frac{(n-1)\\hat{F}}{\\chi^2_{1-\\alpha/2, n-1}}, \\quad U = \\frac{(n-1)\\hat{F}}{\\chi^2_{\\alpha/2, n-1}} $$\n问题指定置信水平为 $0.95$，所以 $\\alpha = 0.05$。临界值所需的概率是 $\\alpha/2 = 0.025$ 和 $1-\\alpha/2 = 0.975$。\n\n判断是否偏离泊松过程的决策规则基于假设值 $\\phi=1$ 是否落在这个置信区间内。如果 $1 \\in [L, U]$，我们没有足够的证据拒绝零假设，并得出数据与泊松过程一致的结论。如果 $1 \\notin [L, U]$，我们拒绝零假设，并得出数据偏离泊松过程的结论。因此，布尔决策变量 $B$ 是：\n$$ B = (1  L) \\text{ 或 } (1 > U) $$\n特殊情况必须得到妥善处理：\n- 如果样本量 $n \\le 1$，样本方差 $s^2$ 未定义。因此，$\\hat{F}$、$L$ 和 $U$ 无法计算。在这种情况下，我们无法做出有意义的统计决策，因此我们为这些量报告非数值，并断定没有偏离（即 $B = \\text{False}$）。\n- 如果样本均值 $\\bar{x} = 0$，这意味着所有 $x_i = 0$，那么估计量 $\\hat{F}$ 由于除以零而未定义。一个全为零的序列与速率为 $0$ 的泊松过程完全一致。因此，我们再次为计算出的量报告非数值，并断定没有偏离（$B = \\text{False}$）。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to process the test suite and print results.\n    \"\"\"\n    \n    # Test suite provided in the problem statement.\n    test_cases = [\n        [2, 3, 1, 2, 0, 4, 2, 1, 3, 2, 2, 1, 3, 2, 1, 2, 3, 1, 2, 2],\n        [0, 7, 2, 10, 3, 8, 1, 9, 4, 6, 0, 11],\n        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n        [0, 1, 0],\n        [0, 0, 1, 0, 1, 0, 1, 0, 0, 1]\n    ]\n\n    results = []\n    for case_data in test_cases:\n        result_tuple = analyze_spike_counts(case_data)\n        results.append(result_tuple)\n\n    # Format the output as a list of tuples, without extra spaces.\n    formatted_results = []\n    for res in results:\n        # Handle nan for formatting\n        F_hat_str = f\"{res[0]:.7f}\" if not np.isnan(res[0]) else \"nan\"\n        L_str = f\"{res[1]:.7f}\" if not np.isnan(res[1]) else \"nan\"\n        U_str = f\"{res[2]:.7f}\" if not np.isnan(res[2]) else \"nan\"\n        B_str = str(res[3])\n        formatted_results.append(f\"({F_hat_str},{L_str},{U_str},{B_str})\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef analyze_spike_counts(x):\n    \"\"\"\n    Analyzes a sequence of spike counts to test for deviation from a Poisson process.\n\n    Args:\n        x (list): A list of non-negative integer spike counts.\n\n    Returns:\n        tuple: A quadruple (F_hat, L, U, B), where:\n               - F_hat is the estimated Fano factor.\n               - L and U are the lower and upper bounds of the 95% CI for the dispersion parameter phi.\n               - B is a boolean indicating deviation from a Poisson process.\n    \"\"\"\n    n = len(x)\n    alpha = 0.05\n\n    # Edge case: If n = 1, sample variance is undefined.\n    # No basis for statistical inference, so return non-numbers and False for deviation.\n    if n = 1:\n        return (np.nan, np.nan, np.nan, False)\n\n    x_arr = np.array(x, dtype=float)\n    x_bar = np.mean(x_arr)\n\n    # Edge case: If mean is 0, all counts are 0.\n    # This is consistent with a Poisson(0) process. F_hat is undefined (0/0).\n    # Return non-numbers for computed quantities and False for deviation.\n    if x_bar == 0:\n        return (np.nan, np.nan, np.nan, False)\n        \n    # Unbiased sample variance (ddof=1 for n-1 denominator).\n    s2 = np.var(x_arr, ddof=1)\n    \n    # Estimated Fano factor (sample variance / sample mean).\n    F_hat = s2 / x_bar\n    \n    df = n - 1\n    \n    # Critical values from the chi-square distribution for the 95% confidence interval.\n    # ppf is the percent point function (inverse of CDF).\n    chi2_lower_crit = chi2.ppf(alpha / 2, df)\n    chi2_upper_crit = chi2.ppf(1 - alpha / 2, df)\n    \n    # The denominator chi2_lower_crit is guaranteed to be > 0 since df=n-1 >= 1 and alpha > 0.\n\n    # Lower bound of the confidence interval for the dispersion parameter phi.\n    L = (df * F_hat) / chi2_upper_crit\n    \n    # Upper bound of the confidence interval.\n    U = (df * F_hat) / chi2_lower_crit\n    \n    # Decision: The data deviates from Poisson if the value 1 is outside the CI [L, U].\n    is_deviated = not (L = 1 and 1 = U)\n    \n    return (F_hat, L, U, is_deviated)\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "理解了信息如何量化以及神经信号的统计特性后，一个更高级的目标便是“解码”——即从神经活动中读出其所编码的信息。这项综合性练习将让你扮演“读心者”的角色，构建一个贝叶斯群体解码器，这是现代计算神经科学的基石之一。通过整合群体神经元的调谐曲线、发放统计模型和观测到的尖峰计数，你将能计算出刺激的后验概率分布，并据此得出对外部刺激的最佳估计。这个过程将让你直观地体验到，大脑可能是如何根据神经活动模式来推断和重构外部世界的感觉信息的。",
            "id": "5037476",
            "problem": "你的任务是使用离散化网格，为一个一维刺激变量实现一个基于原则的贝叶斯群体解码器。目标是根据已知调谐曲线的神经元群体所观测到的脉冲计数，计算刺激的后验分布，然后报告每个测试用例的后验均值估计和不确定性。\n\n基本原理：\n- 假设时间窗口的持续时间为 $T$ 秒。\n- 在给定刺激 $s$ 的条件下，每个神经元 $i$ 产生的脉冲计数 $k_i$ 在神经元之间是独立的，并且每个计数被建模为一个泊松随机变量，其期望计数为 $\\lambda_i(s) = T \\, r_i(s)$，其中 $r_i(s)$ 是发放率（单位：脉冲/秒）。\n- 神经元 $i$ 的调谐曲线是高斯型的：$r_i(s) = r_{0,i} + r_{\\max,i} \\exp\\!\\left(-\\frac{1}{2}\\left(\\frac{s - \\mu_i}{\\sigma_i}\\right)^{2}\\right)$，其中 $r_{0,i} \\ge 0$ 是基线发放率，$r_{\\max,i} \\ge 0$ 是峰值振幅，$\\mu_i$ 是偏好刺激（单位：度），$\\sigma_i  0$ 是调谐宽度（单位：度）。\n- 使用贝叶斯定理，可以选择刺激网格上的均匀先验，或高斯先验 $p(s) \\propto \\exp\\!\\left(-\\frac{1}{2}\\left(\\frac{s-\\mu_0}{\\tau}\\right)^2\\right)$，其先验均值为 $\\mu_0$，先验标准差为 $\\tau$。\n\n你的实现必须：\n1. 将刺激域离散化为一个网格 $s \\in \\{-90, -89, \\dots, 89, 90\\}$（单位：度）。\n2. 对每个测试用例，计算网格上的未归一化对数后验，\n   $$\\log p(s \\mid \\mathbf{k}) = \\log p(s) + \\sum_{i} \\left[k_i \\log \\lambda_i(s) - \\lambda_i(s)\\right],$$\n   其中 $\\lambda_i(s) = T \\, r_i(s)$ 且 $\\mathbf{k} = (k_1, \\dots, k_N)$。因子 $\\log(k_i!)$ 可以省略，因为它不依赖于 $s$。\n3. 在网格上对后验进行数值归一化，以获得有效的概率质量函数，\n   $$p(s \\mid \\mathbf{k}) = \\frac{\\exp(\\log p(s \\mid \\mathbf{k}) - c)}{\\sum_{s'} \\exp(\\log p(s' \\mid \\mathbf{k}) - c)},$$\n   其中 $c = \\max_s \\log p(s \\mid \\mathbf{k})$ 是一个稳定化常数。\n4. 计算后验均值，\n   $$\\mathbb{E}[s \\mid \\mathbf{k}] = \\sum_s s \\, p(s \\mid \\mathbf{k}),$$\n   和后验标准差，\n   $$\\sqrt{\\mathbb{V}[s \\mid \\mathbf{k}]} = \\sqrt{\\sum_s (s - \\mathbb{E}[s \\mid \\mathbf{k}])^2 \\, p(s \\mid \\mathbf{k})}.$$\n5. 以后验均值（单位：度）和后验标准差（单位：度）表示结果。本问题中所有角度均以度为单位。\n6. 将后验均值和后验标准差均四舍五入到 $4$ 位小数。\n\n测试套件：\n对于下方的每个测试用例，刺激网格为 $s \\in \\{-90,-89,\\dots,90\\}$（单位：度）。所需参数包括时间窗口 $T$（单位：秒）、先验、观测到的脉冲计数 $\\mathbf{k}$，以及每个神经元 $i$ 的参数集 $(\\mu_i, \\sigma_i, r_{0,i}, r_{\\max,i})$。\n\n- 测试用例 $1$（一般情况）：\n  - $T = 0.2$。\n  - 先验：高斯先验，$\\mu_0 = 10$ 且 $\\tau = 30$。\n  - 观测到的计数 $\\mathbf{k} = [1, 2, 1, 3, 0]$。\n  - 神经元：\n    - $i=1$: $(\\mu_1, \\sigma_1, r_{0,1}, r_{\\max,1}) = (-40, 20, 2, 18)$。\n    - $i=2$: $(\\mu_2, \\sigma_2, r_{0,2}, r_{\\max,2}) = (-10, 20, 2, 18)$。\n    - $i=3$: $(\\mu_3, \\sigma_3, r_{0,3}, r_{\\max,3}) = (0, 20, 2, 18)$。\n    - $i=4$: $(\\mu_4, \\sigma_4, r_{0,4}, r_{\\max,4}) = (15, 20, 2, 18)$。\n    - $i=5$: $(\\mu_5, \\sigma_5, r_{0,5}, r_{\\max,5}) = (40, 20, 2, 18)$。\n\n- 测试用例 $2$（零脉冲和均匀先验的边缘情况）：\n  - $T = 0.1$。\n  - 先验：网格上的均匀先验。\n  - 观测到的计数 $\\mathbf{k} = [0, 0, 0, 0]$。\n  - 神经元：\n    - $i=1$: $(\\mu_1, \\sigma_1, r_{0,1}, r_{\\max,1}) = (-30, 15, 1, 9)$。\n    - $i=2$: $(\\mu_2, \\sigma_2, r_{0,2}, r_{\\max,2}) = (0, 15, 1, 9)$。\n    - $i=3$: $(\\mu_3, \\sigma_3, r_{0,3}, r_{\\max,3}) = (30, 15, 1, 9)$。\n    - $i=4$: $(\\mu_4, \\sigma_4, r_{0,4}, r_{\\max,4}) = (60, 15, 1, 9)$。\n\n- 测试用例 $3$（围绕一个偏好方向的高信息量脉冲发放）：\n  - $T = 0.2$。\n  - 先验：高斯先验，$\\mu_0 = 25$ 且 $\\tau = 20$。\n  - 观测到的计数 $\\mathbf{k} = [0, 1, 8, 12, 2, 1]$。\n  - 神经元：\n    - $i=1$: $(\\mu_1, \\sigma_1, r_{0,1}, r_{\\max,1}) = (-60, 12, 3, 27)$。\n    - $i=2$: $(\\mu_2, \\sigma_2, r_{0,2}, r_{\\max,2}) = (-30, 12, 3, 27)$。\n    - $i=3$: $(\\mu_3, \\sigma_3, r_{0,3}, r_{\\max,3}) = (0, 12, 3, 27)$。\n    - $i=4$: $(\\mu_4, \\sigma_4, r_{0,4}, r_{\\max,4}) = (30, 12, 3, 27)$。\n    - $i=5$: $(\\mu_5, \\sigma_5, r_{0,5}, r_{\\max,5}) = (60, 12, 3, 27)$。\n    - $i=6$: $(\\mu_6, \\sigma_6, r_{0,6}, r_{\\max,6}) = (75, 12, 3, 27)$。\n\n- 测试用例 $4$（后验分布集中在网格边界附近）：\n  - $T = 0.15$。\n  - 先验：高斯先验，$\\mu_0 = 85$ 且 $\\tau = 5$。\n  - 观测到的计数 $\\mathbf{k} = [0, 0, 5]$。\n  - 神经元：\n    - $i=1$: $(\\mu_1, \\sigma_1, r_{0,1}, r_{\\max,1}) = (80, 10, 2, 20)$。\n    - $i=2$: $(\\mu_2, \\sigma_2, r_{0,2}, r_{\\max,2}) = (85, 10, 2, 20)$。\n    - $i=3$: $(\\mu_3, \\sigma_3, r_{0,3}, r_{\\max,3}) = (90, 10, 2, 20)$。\n\n你的程序必须为每个测试用例计算后验均值 $\\mathbb{E}[s \\mid \\mathbf{k}]$（单位：度）和后验标准差 $\\sqrt{\\mathbb{V}[s \\mid \\mathbf{k}]}$（单位：度），两者均四舍五入到 $4$ 位小数。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个元素是一个形式为 $[\\text{均值}, \\text{标准差}]$ 的双元素列表。例如：$[[m_1, s_1],[m_2, s_2],[m_3, s_3],[m_4, s_4]]$，其中每个 $m_j$ 和 $s_j$ 都是四舍五入到 $4$ 位小数的浮点数。",
            "solution": "该问题要求实现一个贝叶斯群体解码器，以根据一个包含 $N$ 个神经元的群体的脉冲计数 $\\mathbf{k} = (k_1, \\dots, k_N)$ 来估计一维刺激 $s$。该解决方案在一个概率框架内制定，利用贝叶斯定理来计算给定观测到的神经活动下刺激的后验分布。\n\n贝叶斯方法的核心是后验概率分布，由贝叶斯定理给出：\n$$\np(s \\mid \\mathbf{k}) \\propto p(\\mathbf{k} \\mid s) \\, p(s)\n$$\n其中 $p(\\mathbf{k} \\mid s)$ 是在给定刺激 $s$ 的情况下观测到脉冲计数 $\\mathbf{k}$ 的似然，而 $p(s)$ 是刺激的先验分布。该问题通过将刺激空间离散化并在该网格上计算此后验分布来解决。\n\n问题陈述，刺激变量 $s$ 在从 $-90$ 度到 $90$ 度的整数值网格上进行离散化。所有计算都在此网格上执行。\n\n**1. 似然模型: $p(\\mathbf{k} \\mid s)$**\n\n每个神经元的响应被建模为一个独立的泊松过程。在一个持续时间为 $T$ 的时间窗口内，神经元 $i$ 的脉冲计数 $k_i$ 是一个从泊松分布中抽取的随机变量，其均值 $\\lambda_i(s)$ 依赖于刺激 $s$：\n$$\nk_i \\sim \\text{Poisson}(\\lambda_i(s))\n$$\n因此，观测到特定计数 $k_i$ 的概率是：\n$$\np(k_i \\mid s) = \\frac{\\lambda_i(s)^{k_i} e^{-\\lambda_i(s)}}{k_i!}\n$$\n平均脉冲计数 $\\lambda_i(s)$ 是时间持续 $T$ 与神经元发放率 $r_i(s)$ 的乘积：\n$$\n\\lambda_i(s) = T \\cdot r_i(s)\n$$\n发放率 $r_i(s)$ 由一个高斯调谐曲线描述，该曲线建模了神经元对刺激的响应特异性：\n$$\nr_i(s) = r_{0,i} + r_{\\max,i} \\exp\\!\\left(-\\frac{1}{2}\\left(\\frac{s - \\mu_i}{\\sigma_i}\\right)^{2}\\right)\n$$\n此处，$r_{0,i}$ 是基线发放率，$r_{\\max,i}$ 是超出基线的最大发放率，$\\mu_i$ 是神经元的偏好刺激，$\\sigma_i$ 是调谐宽度。\n\n由于假设在给定刺激的情况下神经元是独立的，因此群体的总似然是各个似然的乘积：\n$$\np(\\mathbf{k} \\mid s) = \\prod_{i=1}^{N} p(k_i \\mid s) = \\prod_{i=1}^{N} \\frac{\\lambda_i(s)^{k_i} e^{-\\lambda_i(s)}}{k_i!}\n$$\n为了计算上的稳定性和便利性，我们使用对数似然：\n$$\n\\log p(\\mathbf{k} \\mid s) = \\sum_{i=1}^{N} \\left[ k_i \\log \\lambda_i(s) - \\lambda_i(s) - \\log(k_i!) \\right]\n$$\n项 $\\log(k_i!)$ 是一个关于刺激 $s$ 的常数，在计算后验时可以被舍弃，因为它将被吸收到归一化常数中。\n\n**2. 先验模型: $p(s)$**\n\n先验分布 $p(s)$ 代表我们在观测任何数据之前对刺激值的初始信念。考虑两种类型的先验：\n- **均匀先验**：此先验假设网格上所有的刺激值都是等可能的。对数先验 $\\log p(s)$ 是一个常数，为简单起见可以设为 $0$，因为任何加性常数都将由最终的归一化处理。\n- **高斯先验**：此先验假设刺激可能接近某个值 $\\mu_0$，标准差为 $\\tau$。未归一化的先验为 $p(s) \\propto \\exp\\left(-\\frac{1}{2}\\left(\\frac{s-\\mu_0}{\\tau}\\right)^2\\right)$。因此，对数先验为：\n$$\n\\log p(s) = -\\frac{1}{2}\\left(\\frac{s-\\mu_0}{\\tau}\\right)^2 + C\n$$\n其中常数 $C$ 可以忽略。\n\n**3. 后验分布: $p(s \\mid \\mathbf{k})$**\n\n对数后验是对数似然和对数先验的和（不计归一化常数）：\n$$\n\\log p(s \\mid \\mathbf{k}) \\approx \\log p(s) + \\log p(\\mathbf{k} \\mid s) = \\log p(s) + \\sum_{i=1}^{N} \\left[ k_i \\log \\lambda_i(s) - \\lambda_i(s) \\right]\n$$\n这个未归一化的对数后验是为离散网格上的每个刺激值 $s_j$ 计算的。为了获得一个有效的概率质量函数，我们必须对其进行归一化。一种数值上稳定的方法是使用 log-sum-exp 技巧。首先，我们找到对数后验的最大值，$c = \\max_{s_j} \\log p(s_j \\mid \\mathbf{k})$。然后，每个网格点 $s_j$ 的后验概率为：\n$$\np(s_j \\mid \\mathbf{k}) = \\frac{\\exp(\\log p(s_j \\mid \\mathbf{k}) - c)}{\\sum_{s'_l} \\exp(\\log p(s'_l \\mid \\mathbf{k}) - c)}\n$$\n\n**4. 估计与不确定性**\n\n从归一化后的后验分布中，我们可以计算出刺激的估计值及其相关的不确定性。\n- **后验均值**：在平方误差损失函数下，刺激的最优估计是后验均值。它被计算为 $s$ 在后验分布下的期望值：\n$$\n\\hat{s} = \\mathbb{E}[s \\mid \\mathbf{k}] = \\sum_{j} s_j \\, p(s_j \\mid \\mathbf{k})\n$$\n- **后验标准差**：估计的不确定性由后验标准差量化，它是后验方差的平方根：\n$$\n\\sqrt{\\mathbb{V}[s \\mid \\mathbf{k}]} = \\sqrt{\\sum_{j} (s_j - \\hat{s})^2 \\, p(s_j \\mid \\mathbf{k})}\n$$\n\n实现将对每个测试用例遵循这些步骤，计算后验均值和标准差，并将它们四舍五入到指定的精度。",
            "answer": "```python\nimport numpy as np\n\ndef run_bayesian_decoder(T, prior_params, k, neurons):\n    \"\"\"\n    Computes the posterior mean and standard deviation for a stimulus s.\n\n    Args:\n        T (float): Time window duration in seconds.\n        prior_params (dict): Dictionary specifying the prior ('uniform' or 'gaussian' with mu0, tau).\n        k (np.ndarray): Array of observed spike counts for each neuron.\n        neurons (np.ndarray): Array of neuron parameters (mu, sigma, r0, r_max).\n\n    Returns:\n        tuple[float, float]: The posterior mean and a posteriori standard deviation.\n    \"\"\"\n    # 1. Discretize the stimulus domain\n    s_grid = np.arange(-90, 91, 1).astype(float)\n\n    # 2. Compute the log-prior probability log p(s)\n    if prior_params[\"type\"] == \"uniform\":\n        log_prior = np.zeros_like(s_grid)\n    elif prior_params[\"type\"] == \"gaussian\":\n        mu0 = prior_params[\"mu0\"]\n        tau = prior_params[\"tau\"]\n        log_prior = -0.5 * ((s_grid - mu0) / tau)**2\n    else:\n        raise ValueError(\"Invalid prior type specified\")\n\n    # 3. Compute the log-likelihood log p(k|s)\n    # Unpack neuron parameters\n    mu = neurons[:, 0]\n    sigma = neurons[:, 1]\n    r0 = neurons[:, 2]\n    r_max = neurons[:, 3]\n\n    # Use broadcasting for efficient computation across the stimulus grid\n    # s_grid shape: (181,) -> s_grid_col shape: (181, 1)\n    # neuron params mu, sigma, etc. shape: (N,) -> (1, N)\n    s_grid_col = s_grid[:, np.newaxis]\n    \n    # Firing rates r_i(s) for all neurons i and stimuli s\n    # rates shape: (181, N)\n    exponent = -0.5 * ((s_grid_col - mu) / sigma)**2\n    rates = r0 + r_max * np.exp(exponent)\n\n    # Expected spike counts lambda_i(s)\n    # lambdas shape: (181, N)\n    lambdas = T * rates\n    \n    # Total log-likelihood for each stimulus s, summed over neurons\n    # The term k_i * log(lambda_i(s)) is calculated safely.\n    # If lambda_i(s) is close to 0, log(lambda) is a large negative number.\n    # The problem parameters ensure r_i(s) > 0, so lambda_i(s) > 0, avoiding log(0).\n    log_likelihood_matrix = k * np.log(lambdas) - lambdas\n    total_log_likelihood = np.sum(log_likelihood_matrix, axis=1)\n\n    # 4. Compute the unnormalized log-posterior\n    log_posterior = log_prior + total_log_likelihood\n\n    # 5. Numerically stabilize and normalize the posterior\n    # Use the log-sum-exp trick for numerical stability\n    c = np.max(log_posterior)\n    log_posterior_stable = log_posterior - c\n    unnormalized_posterior = np.exp(log_posterior_stable)\n    normalization_constant = np.sum(unnormalized_posterior)\n    posterior = unnormalized_posterior / normalization_constant\n\n    # 6. Compute posterior mean and standard deviation\n    posterior_mean = np.sum(s_grid * posterior)\n    posterior_variance = np.sum(((s_grid - posterior_mean)**2) * posterior)\n    posterior_std_dev = np.sqrt(posterior_variance)\n\n    return posterior_mean, posterior_std_dev\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Bayesian population decoder.\n    \"\"\"\n    test_cases = [\n        {\n            \"T\": 0.2,\n            \"prior\": {\"type\": \"gaussian\", \"mu0\": 10, \"tau\": 30},\n            \"k\": np.array([1, 2, 1, 3, 0]),\n            \"neurons\": np.array([\n                [-40, 20, 2, 18], [-10, 20, 2, 18], [0, 20, 2, 18],\n                [15, 20, 2, 18], [40, 20, 2, 18]\n            ])\n        },\n        {\n            \"T\": 0.1,\n            \"prior\": {\"type\": \"uniform\"},\n            \"k\": np.array([0, 0, 0, 0]),\n            \"neurons\": np.array([\n                [-30, 15, 1, 9], [0, 15, 1, 9], [30, 15, 1, 9], [60, 15, 1, 9]\n            ])\n        },\n        {\n            \"T\": 0.2,\n            \"prior\": {\"type\": \"gaussian\", \"mu0\": 25, \"tau\": 20},\n            \"k\": np.array([0, 1, 8, 12, 2, 1]),\n            \"neurons\": np.array([\n                [-60, 12, 3, 27], [-30, 12, 3, 27], [0, 12, 3, 27],\n                [30, 12, 3, 27], [60, 12, 3, 27], [75, 12, 3, 27]\n            ])\n        },\n        {\n            \"T\": 0.15,\n            \"prior\": {\"type\": \"gaussian\", \"mu0\": 85, \"tau\": 5},\n            \"k\": np.array([0, 0, 5]),\n            \"neurons\": np.array([\n                [80, 10, 2, 20], [85, 10, 2, 20], [90, 10, 2, 20]\n            ])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        mean, std = run_bayesian_decoder(case[\"T\"], case[\"prior\"], case[\"k\"], case[\"neurons\"])\n        # Round to 4 decimal places as required\n        rounded_mean = round(mean, 4)\n        rounded_std = round(std, 4)\n        results.append((rounded_mean, rounded_std))\n\n    # Format the output string exactly as specified: [[m1,s1],[m2,s2],...]\n    formatted_results = [f\"[{m},{s}]\" for m, s in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}