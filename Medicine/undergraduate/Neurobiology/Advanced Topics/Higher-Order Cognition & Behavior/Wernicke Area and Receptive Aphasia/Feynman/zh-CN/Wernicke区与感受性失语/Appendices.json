{
    "hands_on_practices": [
        {
            "introduction": "现代临床神经心理学越来越依赖定量模型来辅助诊断决策。本实践练习将让您扮演一位精通数据的临床医生，使用一个假设的多项逻辑回归模型——一种强大的统计工具——来处理患者的行为得分 。通过计算后验概率，您将看到如何综合理解、流畅性等语言功能的测试数据，从而客观地估计患者患有感受性失语症的可能性。",
            "id": "5079533",
            "problem": "语言理解、自发流利性、复述和对抗性命名是语言功能的标准化行为测量指标，与后颞上皮层的韦尼克区（Wernicke’s area）及其分布式网络连接的完整性密切相关。感受性失语症（也称为韦尼克失语症）的特征是理解能力受损，但言语相对流利，复述和命名能力有不同程度的缺陷。考虑一个基于多项逻辑斯蒂模型的判别分类器，该分类器根据观察到的测试分数，为四个诊断类别分配后验概率：感受性失语症（韦尼克失语症）、布洛卡失语症（表达性失语症）、命名性失语症和神经典型的语言功能。患者在$0$–$100$分制量表上的得分为$(\\text{理解}=30,\\ \\text{流利性}=85,\\ \\text{复述}=40,\\ \\text{命名}=50)$。该模型使用一个特征向量 $x$，通过公式 $x=\\left(\\frac{c}{100},\\frac{f}{100},\\frac{r}{100},\\frac{n}{100}\\right)$ 将每个分数重新缩放到单位区间得到，其中 $c$、$f$、$r$ 和 $n$ 分别代表理解、流利性、复述和命名。多项逻辑斯蒂模型为每个类别 $k\\in\\{\\text{Wernicke},\\ \\text{Broca},\\ \\text{Anomic},\\ \\text{Healthy}\\}$ 指定了一个线性预测器 $z_{k}=\\beta_{k,0}+\\beta_{k}^{\\top}x$，其参数如下：\n- 韦尼克失语症 (Wernicke): $\\beta_{\\text{W},0}=1.0$, $\\beta_{\\text{W}}=\\left(-2.5,\\ 1.8,\\ -1.2,\\ -0.8\\right)$。\n- 布洛卡失语症 (Broca): $\\beta_{\\text{B},0}=0.2$, $\\beta_{\\text{B}}=\\left(1.4,\\ -2.0,\\ -0.8,\\ -0.3\\right)$。\n- 命名性失语症 (Anomic): $\\beta_{\\text{A},0}=0.0$, $\\beta_{\\text{A}}=\\left(0.1,\\ 0.4,\\ -0.4,\\ -2.2\\right)$。\n- 健康 (Healthy): $\\beta_{\\text{H},0}=-3.5$, $\\beta_{\\text{H}}=\\left(3.0,\\ 1.0,\\ 2.0,\\ 1.0\\right)$。\n\n使用与贝叶斯定理和最大熵假设一致的多项逻辑斯蒂模型的标准概率解释，计算在给定患者分数的情况下，患有感受性失语症的后验概率。将最终答案四舍五入到四位有效数字，并以小数形式表示（不加百分号）。",
            "solution": "问题陈述经评估有效。它在临床神经科学和统计建模领域有科学依据，问题设定良好，数据和参数完整一致，陈述客观。任务是使用标准的多项逻辑斯蒂回归模型计算后验概率，所有必需的输入均已提供。\n\n第一步是根据患者的测试分数构建特征向量 $x$。给定的分数为理解 $c=30$、流利性 $f=85$、复述 $r=40$ 和命名 $n=50$。这些分数是基于$0$–$100$分制的，并根据公式 $x=\\left(\\frac{c}{100},\\frac{f}{100},\\frac{r}{100},\\frac{n}{100}\\right)$ 重新缩放到单位区间 $[0, 1]$。\n代入给定的分数：\n$$\nx = \\left(\\frac{30}{100}, \\frac{85}{100}, \\frac{40}{100}, \\frac{50}{100}\\right) = (0.3, 0.85, 0.4, 0.5)\n$$\n\n多项逻辑斯蒂回归模型为每个诊断类别 $k$ 定义一个线性预测器 $z_k$。线性预测器的公式为 $z_k = \\beta_{k,0} + \\beta_k^\\top x$，其中 $\\beta_{k,0}$ 是截距，$\\beta_k$ 是类别 $k$ 的权重向量。我们为四个类别分别计算 $z_k$：韦尼克失语症 (W)、布洛卡失语症 (B)、命名性失语症 (A) 和健康 (H)。\n\n对于韦尼克失语症 ($k=\\text{W}$):\n$\\beta_{\\text{W},0} = 1.0$ and $\\beta_{\\text{W}} = (-2.5, 1.8, -1.2, -0.8)$.\n$$\nz_{\\text{W}} = 1.0 + (-2.5)(0.3) + (1.8)(0.85) + (-1.2)(0.4) + (-0.8)(0.5)\n$$\n$$\nz_{\\text{W}} = 1.0 - 0.75 + 1.53 - 0.48 - 0.40 = 0.90\n$$\n\n对于布洛卡失语症 ($k=\\text{B}$):\n$\\beta_{\\text{B},0} = 0.2$ and $\\beta_{\\text{B}} = (1.4, -2.0, -0.8, -0.3)$.\n$$\nz_{\\text{B}} = 0.2 + (1.4)(0.3) + (-2.0)(0.85) + (-0.8)(0.4) + (-0.3)(0.5)\n$$\n$$\nz_{\\text{B}} = 0.2 + 0.42 - 1.70 - 0.32 - 0.15 = -1.55\n$$\n\n对于命名性失语症 ($k=\\text{A}$):\n$\\beta_{\\text{A},0} = 0.0$ and $\\beta_{\\text{A}} = (0.1, 0.4, -0.4, -2.2)$.\n$$\nz_{\\text{A}} = 0.0 + (0.1)(0.3) + (0.4)(0.85) + (-0.4)(0.4) + (-2.2)(0.5)\n$$\n$$\nz_{\\text{A}} = 0.03 + 0.34 - 0.16 - 1.10 = -0.89\n$$\n\n对于神经典型的语言功能 (健康, $k=\\text{H}$):\n$\\beta_{\\text{H},0} = -3.5$ and $\\beta_{\\text{H}} = (3.0, 1.0, 2.0, 1.0)$.\n$$\nz_{\\text{H}} = -3.5 + (3.0)(0.3) + (1.0)(0.85) + (2.0)(0.4) + (1.0)(0.5)\n$$\n$$\nz_{\\text{H}} = -3.5 + 0.90 + 0.85 + 0.80 + 0.50 = -0.45\n$$\n\n给定类别 $k$ 的后验概率 $P(y=k|x)$ 使用 softmax 函数计算，该函数对指数化的线性预测器进行归一化：\n$$\nP(y=k|x) = \\frac{\\exp(z_k)}{\\sum_{j \\in \\{\\text{W, B, A, H}\\}} \\exp(z_j)}\n$$\n我们需要计算感受性失语症的后验概率，它对应于韦尼克失语症类别 ($k=\\text{W}$)。我们将此概率表示为 $P_{\\text{W}}$。\n$$\nP_{\\text{W}} = \\frac{\\exp(z_{\\text{W}})}{\\exp(z_{\\text{W}}) + \\exp(z_{\\text{B}}) + \\exp(z_{\\text{A}}) + \\exp(z_{\\text{H}})}\n$$\n代入计算出的 $z_k$ 值：\n$$\nP_{\\text{W}} = \\frac{\\exp(0.90)}{\\exp(0.90) + \\exp(-1.55) + \\exp(-0.89) + \\exp(-0.45)}\n$$\n现在，我们计算指数项：\n$\\exp(0.90) \\approx 2.459603$\n$\\exp(-1.55) \\approx 0.212248$\n$\\exp(-0.89) \\approx 0.410656$\n$\\exp(-0.45) \\approx 0.637628$\n\n分母中的和为：\n$$\n\\sum_{j} \\exp(z_j) \\approx 2.459603 + 0.212248 + 0.410656 + 0.637628 = 3.720135\n$$\n最后，韦尼克失语症的后验概率为：\n$$\nP_{\\text{W}} \\approx \\frac{2.459603}{3.720135} \\approx 0.66115904\n$$\n题目要求将答案四舍五入到四位有效数字。前四位有效数字是 $6, 6, 1, 1$。第五位有效数字是 $5$，所以我们将第四位数字向上取整。\n$$\nP_{\\text{W}} \\approx 0.6612\n$$",
            "answer": "$$\\boxed{0.6612}$$"
        },
        {
            "introduction": "我们已经了解了行为症状如何指向诊断，但我们最初是如何确定大脑中负责这些功能的区域的呢？本练习深入探讨了功能性磁共振成像（fMRI），这是现代认知神经科学的基石 。您将学习构建通用线性模型（General Linear Model, GLM）来分析血氧水平依赖（BOLD）信号，通过对比大脑对真实单词和伪单词的反应，从而在统计上分离出与词汇处理（韦尼克区的核心功能）相关的神经活动。",
            "id": "5079579",
            "problem": "在一个旨在探测颞上回后部（STG；韦尼克区）词汇处理的快速事件相关功能性磁共振成像（fMRI）实验中，参与者观看视觉呈现的单词和可发音的假词。假设血氧水平依赖（BOLD）系统在任务时间尺度上近似为线性时不变（LTI）系统，其血流动力学响应函数（HRF）作为脉冲响应。从LTI假设和卷积的定义出发，构建一个信号模型。在该模型中，对单词和假词的预测BOLD响应是通过将它们各自的刺激时间序列与一个典型的HRF进行卷积而形成的。展示这如何导出一个针对单个左侧颞上回后部体素的通用线性模型（GLM），其形式为 $y = X \\beta + \\varepsilon$。其中，$y$ 是采样的BOLD时间序列，$X$ 至少包含两列，分别对应于卷积后的单词和假词回归量，并且可能包含额外的干扰列（如运动和低频漂移）。明确陈述在体素水平上证明普通最小二乘估计合理性所需的任何假设，并指定一个对比向量，用于分离STG中的词汇处理，即单词的响应大于假词的响应。\n\n对于一个特定的左侧颞上回后部体素，假设普通最小二乘法得到的前两个回归量（单词和假词）的系数估计为 $\\hat{\\beta}_{\\text{word}} = 0.92$ 和 $\\hat{\\beta}_{\\text{pseudo}} = 0.50$。假设这两个系数的抽样协方差矩阵（即 $\\operatorname{Var}(\\hat{\\beta})$ 对应的 $2 \\times 2$ 主子矩阵）为\n$$\n\\begin{pmatrix}\n0.0100  & 0.0025\\\\\n0.0025  & 0.0100\n\\end{pmatrix}.\n$$\n使用你推导出的对比来计算该体素中词汇效应对应的 $t$ 统计量。将你的最终数值答案四舍五入到四位有效数字。最终答案必须是一个没有单位的实数。",
            "solution": "该问题是有效的，因为它科学地基于fMRI数据分析的原理，问题陈述清晰，信息充分且一致，并且表述客观。我们可以开始求解。\n\n解答分为两个主要部分。首先，我们将基于线性时不变（LTI）系统假设推导信号模型，并构建通用线性模型（GLM）。其次，我们将使用提供的数值数据计算所要求的 $t$ 统计量。\n\n**第一部分：fMRI的通用线性模型**\n\n核心假设是将神经活动映射到观测到的血氧水平依赖（BOLD）信号的系统近似为线性时不变（LTI）系统。在LTI系统中，输出信号是输入信号与系统脉冲响应的卷积。\n\n令 $s(t)$ 表示随时间变化的神经活动，它作为血流动力学系统的输入。在事件相关fMRI中，此输入被建模为在刺激起始时间点上的一系列脉冲（狄拉克δ函数）。令 $h(t)$ 为血流动力学响应函数（HRF），它是对单个、无限短暂的神经活动脉冲的BOLD响应。预测的BOLD信号 $y_{\\text{predicted}}(t)$ 则是 $s(t)$ 和 $h(t)$ 的卷积，记作 $(s * h)(t)$：\n$$y_{\\text{predicted}}(t) = (s * h)(t) = \\int_{-\\infty}^{\\infty} s(\\tau) h(t - \\tau) d\\tau$$\n\n在本实验中，有两种不同的刺激类型：单词和假词。令它们各自的刺激时间序列为 $s_{\\text{word}}(t)$ 和 $s_{\\text{pseudo}}(t)$。每个函数都是一个δ函数序列，代表单词或假词刺激的起始。根据系统的线性特性，总响应是每种刺激类型响应的总和，并由它们各自的响应幅度 $\\beta_{\\text{word}}$ 和 $\\beta_{\\text{pseudo}}$ 进行缩放：\n$$y_{\\text{predicted}}(t) = \\beta_{\\text{word}} (s_{\\text{word}} * h)(t) + \\beta_{\\text{pseudo}} (s_{\\text{pseudo}} * h)(t)$$\n\nfMRI在离散的时间点 $t_i$（其中 $i = 1, 2, \\dots, N$，$N$ 是总扫描次数）测量BOLD信号。一个体素中测得的BOLD信号 $y(t_i)$ 被建模为预测信号、来自干扰源（例如，头部运动、低频漂移）的贡献以及随机误差 $\\varepsilon(t_i)$ 的总和。完整的模型是：\n$$y(t_i) = \\beta_{\\text{word}} (s_{\\text{word}} * h)(t_i) + \\beta_{\\text{pseudo}} (s_{\\text{pseudo}} * h)(t_i) + \\sum_{j=1}^{M} \\beta_j g_j(t_i) + \\varepsilon(t_i)$$\n其中 $g_j(t_i)$ 是 $M$ 个干扰回归量在时间 $t_i$ 的值，其对应系数为 $\\beta_j$。\n\n这个方程可以用矩阵形式表示，从而定义了通用线性模型（GLM）。令 $\\mathbf{y}$ 为一个 $N \\times 1$ 的列向量，表示观测到的BOLD时间序列，其中 $y_i = y(t_i)$。令 $\\mathbf{x}_{\\text{word}}$ 为一个 $N \\times 1$ 的列向量，其中第 $i$ 个元素是 $(s_{\\text{word}} * h)(t_i)$。这就是“单词回归量”。类似地，令 $\\mathbf{x}_{\\text{pseudo}}$ 为“假词回归量”。令 $\\mathbf{x}_j$ 为干扰回归量的列向量。设计矩阵 $\\mathbf{X}$ 是通过将这些列向量连接起来形成的：\n$$\\mathbf{X} = \\begin{pmatrix} \\mathbf{x}_{\\text{word}}  \\mathbf{x}_{\\text{pseudo}}  \\mathbf{x}_1  \\cdots  \\mathbf{x}_M \\end{pmatrix}$$\n令 $\\boldsymbol{\\beta}$ 为待估计参数的列向量：\n$$\\boldsymbol{\\beta} = \\begin{pmatrix} \\beta_{\\text{word}}  \\beta_{\\text{pseudo}}  \\beta_1  \\cdots  \\beta_M \\end{pmatrix}^T$$\n令 $\\boldsymbol{\\varepsilon}$ 为 $N \\times 1$ 的误差列向量。则GLM表示为：\n$$\\mathbf{y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$$\n\n为了使 $\\boldsymbol{\\beta}$ 的普通最小二乘（OLS）估计成为最佳线性无偏估计量（BLUE），关于误差项 $\\boldsymbol{\\varepsilon}$ 的高斯-马尔可夫假设必须成立：\n1.  **零均值**：误差的期望为零，$E[\\boldsymbol{\\varepsilon}] = \\mathbf{0}$。\n2.  **同方差性和无自相关性**：误差是不相关的，并且具有恒定的方差。这表示为误差的协方差矩阵是单位矩阵的标量倍：$\\operatorname{Var}(\\boldsymbol{\\varepsilon}) = E[\\boldsymbol{\\varepsilon} \\boldsymbol{\\varepsilon}^T] = \\sigma^2 \\mathbf{I}$，其中 $\\mathbf{I}$ 是 $N \\times N$ 的单位矩阵，$\\sigma^2$ 是误差方差。\n对于统计推断（如下文的 $t$ 检验），一个额外的假设是误差呈正态分布，即 $\\boldsymbol{\\varepsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$。\n\n研究问题是要分离词汇处理，具体表现为对单词的响应大于对假词的响应。这可以转化为统计假设 $H_1: \\beta_{\\text{word}} > \\beta_{\\text{pseudo}}$，或等效地，$\\beta_{\\text{word}} - \\beta_{\\text{pseudo}} > 0$。这是对模型参数的线性对比。该对比可以写成 $\\mathbf{c}^T \\boldsymbol{\\beta}$ 的形式，其中 $\\mathbf{c}$ 是一个对比向量。给定 $\\boldsymbol{\\beta}$ 中参数的顺序为 $(\\beta_{\\text{word}}, \\beta_{\\text{pseudo}}, \\dots)$，检验此假设的对比向量是：\n$$\\mathbf{c} = \\begin{pmatrix} 1  -1  0  \\cdots  0 \\end{pmatrix}^T$$\n\n**第二部分：$t$统计量的计算**\n\n对于一个通用线性对比 $\\mathbf{c}^T \\boldsymbol{\\beta}$，其 $t$ 统计量由下式给出：\n$$t = \\frac{\\mathbf{c}^T \\hat{\\boldsymbol{\\beta}}}{\\text{SE}(\\mathbf{c}^T \\hat{\\boldsymbol{\\beta}})} = \\frac{\\mathbf{c}^T \\hat{\\boldsymbol{\\beta}}}{\\sqrt{\\mathbf{c}^T \\operatorname{Var}(\\hat{\\boldsymbol{\\beta}}) \\mathbf{c}}}$$\n其中 $\\hat{\\boldsymbol{\\beta}}$ 是 $\\boldsymbol{\\beta}$ 的OLS估计值，$\\operatorname{Var}(\\hat{\\boldsymbol{\\beta}})$ 是其抽样协方差矩阵。\n\n对于一个特定的体素，我们有以下信息：\n前两个回归量的系数估计值：\n$$\\hat{\\beta}_{\\text{word}} = 0.92$$\n$$\\hat{\\beta}_{\\text{pseudo}} = 0.50$$\n令 $\\hat{\\boldsymbol{\\beta}}_{\\text{sub}} = \\begin{pmatrix} 0.92 \\\\ 0.50 \\end{pmatrix}$。\n\n对应的 $2 \\times 2$ 抽样协方差子矩阵是：\n$$\\mathbf{C}_{\\text{sub}} = \\operatorname{Var} \\left( \\begin{pmatrix} \\hat{\\beta}_{\\text{word}} \\\\ \\hat{\\beta}_{\\text{pseudo}} \\end{pmatrix} \\right) = \\begin{pmatrix} 0.0100  & 0.0025 \\\\ 0.0025  & 0.0100 \\end{pmatrix}$$\n对比向量的相关部分是 $\\mathbf{c}_{\\text{sub}} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$。\n\n首先，我们使用估计的系数计算对比的值（$t$ 统计量的分子）：\n$$\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}} = \\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 0.92 \\\\ 0.50 \\end{pmatrix} = (1)(0.92) + (-1)(0.50) = 0.92 - 0.50 = 0.42$$\n\n接下来，我们计算对比估计的方差（分母中平方根下的项）：\n$$\\text{Var}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = \\mathbf{c}_{\\text{sub}}^T \\mathbf{C}_{\\text{sub}} \\mathbf{c}_{\\text{sub}}$$\n$$\\text{Var}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = \\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 0.0100  & 0.0025 \\\\ 0.0025  & 0.0100 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$$\n$$\\text{Var}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = \\begin{pmatrix} 1 \\times 0.0100 - 1 \\times 0.0025  & 1 \\times 0.0025 - 1 \\times 0.0100 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$$\n$$\\text{Var}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = \\begin{pmatrix} 0.0075  & -0.0075 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$$\n$$\\text{Var}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = (0.0075)(1) + (-0.0075)(-1) = 0.0075 + 0.0075 = 0.0150$$\n\n或者，方差也可以计算如下：\n$$\\text{Var}(\\hat{\\beta}_{\\text{word}} - \\hat{\\beta}_{\\text{pseudo}}) = \\text{Var}(\\hat{\\beta}_{\\text{word}}) + \\text{Var}(\\hat{\\beta}_{\\text{pseudo}}) - 2 \\text{Cov}(\\hat{\\beta}_{\\text{word}}, \\hat{\\beta}_{\\text{pseudo}})$$\n$$= 0.0100 + 0.0100 - 2(0.0025) = 0.0200 - 0.0050 = 0.0150$$\n\n对比的标准误（SE）是该方差的平方根：\n$$\\text{SE}(\\mathbf{c}_{\\text{sub}}^T \\hat{\\boldsymbol{\\beta}}_{\\text{sub}}) = \\sqrt{0.0150}$$\n\n最后，我们计算 $t$ 统计量：\n$$t = \\frac{0.42}{\\sqrt{0.0150}} \\approx \\frac{0.42}{0.122474487} \\approx 3.429281$$\n\n将结果四舍五入到四位有效数字，我们得到 $3.429$。",
            "answer": "$$\\boxed{3.429}$$"
        },
        {
            "introduction": "对大脑区域功能的最终验证，往往来自于对脑损伤影响的研究。本实践模拟了一项前沿的基于体素的病变-症状定位（Voxel-Based Lesion-Symptom Mapping, VLSM）分析，这项技术改变了我们对大脑-行为关系的理解 。通过生成合成的患者数据并进行体素水平的统计检验，您将亲身体验神经科学家如何系统地将特定的语言缺陷（如理解能力差）定位到韦尼克区等精确的病变位置，并理解其中涉及的统计挑战，例如多重比较校正。",
            "id": "5079543",
            "problem": "您的任务是实现一项基于语言神经生物学的、基于体素的病灶-症状图谱分析。其概念基础是，影响后颞上皮层（Wernicke区）的病灶与感受性失语症中的听觉-言语理解受损有关。您将为一个队列模拟病灶掩模和波士顿命名测试的理解分测验分数，然后执行逐体素统计检验和多重比较校正。\n\n基本原理和定义：\n- 病灶-症状图谱假设，如果Wernicke区中的一个体素发生病变，患者的理解分测验分数会趋于更低。设$N$为患者数量，$V$为体素数量。设$s_i$为患者$i$的理解分测验分数，$X_{ij} \\in \\{0,1\\}$为患者$i$在体素$j$处的二元病灶指示符。\n- 双样本Welch t统计量用于比较在体素$j$处有病灶和无病灶两组患者的分数，且不假设方差相等。对于一个体素$j$，定义组$\\mathcal{L}_j = \\{ i \\mid X_{ij} = 1 \\}$和组$\\mathcal{U}_j = \\{ i \\mid X_{ij} = 0 \\}$，其样本量分别为$n_1 = |\\mathcal{L}_j|$和$n_2 = |\\mathcal{U}_j|$。定义这两组的样本均值$\\bar{s}_1$和$\\bar{s}_2$以及样本方差$v_1$和$v_2$。Welch t统计量为\n$$\nt_j = \\frac{\\bar{s}_1 - \\bar{s}_2}{\\sqrt{\\frac{v_1}{n_1} + \\frac{v_2}{n_2}}} \\, ,\n$$\n其Welch–Satterthwaite自由度为\n$$\n\\nu_j = \\frac{\\left(\\frac{v_1}{n_1} + \\frac{v_2}{n_2}\\right)^2}{\\frac{\\left(\\frac{v_1}{n_1}\\right)^2}{n_1 - 1} + \\frac{\\left(\\frac{v_2}{n_2}\\right)^2}{n_2 - 1}} \\, .\n$$\n体素$j$的双侧p值为\n$$\np_j = 2 \\cdot \\left(1 - F_{t,\\nu_j}\\left(|t_j|\\right)\\right) \\, ,\n$$\n其中，$F_{t,\\nu}$是自由度为$\\nu$的学生t分布的累积分布函数。只有当两组样本量都达到最小要求时，体素才可被检验；将每组的最小样本量记为$n_{\\min}$。\n\n- 错误发现率（FDR）校正控制了在所有声明的发现中假阳性的预期比例。使用水平为$q$的Benjamini–Hochberg程序，该程序对$m$个已检验体素的p值$\\{p_1,\\dots,p_m\\}$进行升序排序$p_{(1)} \\le \\dots \\le p_{(\\!m)}$，并找到满足以下条件的最大$k$：\n$$\np_{(k)} \\le \\frac{k}{m} q \\, .\n$$\n拒绝（声明为显著）所有p值小于等于$p_{(k)}$的已检验体素。未被检验的体素（由于组样本量不足）不得计入$m$中，也绝不能声明为显著。\n\n模拟的数据生成模型：\n- 固定$N = 50$和$V = 200$。定义一个Wernicke区掩模$\\mathcal{W} = \\{80,81,\\dots,119\\}$（一个包含$40$个体素的连续区域），该区域作为与理解缺陷相关的真实（ground-truth）区域。\n- 对每位患者$i$，从伯努利($\\pi$)分布中抽取一个潜在的Wernicke病灶指示符$L_i \\sim \\mathrm{Bernoulli}(\\pi)$，其中$\\pi$是Wernicke中心型病灶的患病率。生成一个理解分数\n$$\ns_i = \\mu - \\Delta \\, L_i + \\epsilon_i \\, ,\n$$\n其中$\\mu$是基线分数，$\\Delta$是效应大小（由Wernicke中心型病灶导致的分数下降量），$\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$是噪声。\n- 对于每个体素$j \\in \\mathcal{W}$，从伯努利($p_{\\mathrm{W} \\mid L_i}$)分布中抽取$X_{ij}$，其中如果$L_i = 1$，则$p_{\\mathrm{W} \\mid 1} = p_{\\mathrm{W}|\\mathrm{L}}$，否则$p_{\\mathrm{W} \\mid 0} = p_{\\mathrm{W}|\\neg \\mathrm{L}}$。对于体素$j \\notin \\mathcal{W}$，独立地从伯努利($p_{\\mathrm{NW}}$)分布中抽取$X_{ij}$。这在Wernicke区病灶与理解障碍之间建立了一种合理的关联，同时允许其他地方存在背景性病灶。\n\n实现要求：\n- 为确保可复现性，对每个测试用例使用一个指定整数种子的伪随机数生成器。\n- 逐体素地使用Welch t统计量和Welch–Satterthwaite自由度来计算双侧p值。如果任一组的样本量小于$n_{\\min}$或者$t_j$的分母为零，则将该体素排除在检验之外。\n- 仅对已检验的体素集合应用水平为$q = 0.05$的Benjamini–Hochberg FDR校正。\n- 对于每个测试用例，输出位于Wernicke掩模$\\mathcal{W}$内的显著体素的整数数量。\n\n测试套件：\n对于所有情况，取$N = 50$，$V = 200$，$\\mathcal{W} = \\{80,81,\\dots,119\\}$，$n_{\\min} = 5$，$q = 0.05$。每个测试用例由元组$(\\mu, \\Delta, \\sigma, \\pi, p_{\\mathrm{W}|\\mathrm{L}}, p_{\\mathrm{W}|\\neg \\mathrm{L}}, p_{\\mathrm{NW}}, \\text{seed})$指定：\n\n1. 情况A（理想路径，中等效应和充足的组样本量）：$(10, 3.0, 2.0, 0.5, 0.8, 0.05, 0.1, 12345)$。\n2. 情况B（无效应，FDR校正后应无显著体素）：$(10, 0.0, 2.0, 0.5, 0.8, 0.05, 0.1, 12346)$。\n3. 情况C（边界情况：几乎普遍存在的Wernicke病灶导致无病灶组样本过小，从而没有可检验的体素）：$(10, 3.0, 2.0, 1.0, 0.98, 0.0, 0.1, 12347)$。\n4. 情况D（边缘情况：效应大小过小，FDR校正后可能不足以产生显著结果）：$(10, 0.5, 2.0, 0.5, 0.7, 0.05, 0.1, 12348)$。\n\n最终输出规格：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[result1,result2,result3,result4]”）。每个结果是对应测试用例在$\\mathcal{W}$内的显著体素的整数数量，顺序与上面列出的一致。不涉及物理单位或角度单位。FDR水平按给定的小数$q = 0.05$表示。",
            "solution": "该问题提出了一个在计算神经生物学领域中有效且定义明确的任务，具体来说，是基于体素的病灶-症状图谱（VLSM）的模拟。其前提在科学上植根于失语症学和脑图谱绘制的原理，所用的统计方法是恰当的，模拟参数是完整且明确的。因此，我将着手提供一个完整的解决方案。\n\n任务的核心是实现一个计算流程，该流程首先生成一个包含患者病灶掩模和行为分数的合成数据集，然后应用逐体素的统计分析来识别与行为缺陷相关的脑区。此解决方案的设计遵循可复现性、统计严谨性和计算效率的原则。\n\n总体算法按顺序处理所提供的每个测试用例。对每个用例，执行以下步骤：\n\n**1. 数据生成**\n\n此阶段基于一组生成参数，为包含$N$名患者、$V$个体素的队列模拟生物学和行为数据。通过为每个测试用例使用指定的整数种子来初始化伪随机数生成器（PRNG），以确保可复现性。\n\n- **患者层面的潜在状态**：对$N=50$名患者中的每一位，从伯努利分布中抽取一个潜在的二元变量$L_i \\sim \\mathrm{Bernoulli}(\\pi)$。该变量表示患者是否有一个主要集中在Wernicke区的病灶（$L_i=1$）或没有（$L_i=0$）。参数$\\pi$决定了这类病灶在模拟队列中的患病率。\n\n- **行为分数**：为每位患者生成一个理解分数$s_i$。该分数被建模为潜在状态$L_i$的线性函数，并带有加性高斯噪声：$s_i = \\mu - \\Delta \\cdot L_i + \\epsilon_i$。这里，$\\mu$是无Wernicke中心型病灶个体的基线分数，$\\Delta$是与此类病灶相关的理解缺陷的程度，$\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$是一个正态分布的噪声项。此模型建立了特定病灶类型与行为结果之间的真实关系。\n\n- **体素层面的病灶掩模**：生成一个大小为$N \\times V$（其中$V=200$）的二元病灶矩阵$X$。患者$i$在给定体素$j$处有病灶（$X_{ij}=1$）的概率取决于该体素是否属于指定的Wernicke区掩模$\\mathcal{W} = \\{80, 81, \\dots, 119\\}$，以及患者的潜在状态$L_i$。\n    - 如果体素$j$在Wernicke区内（$j \\in \\mathcal{W}$），病灶概率取决于$L_i$：如果$L_i=1$，则$P(X_{ij}=1) = p_{\\mathrm{W}|\\mathrm{L}}$；如果$L_i=0$，则$P(X_{ij}=1) = p_{\\mathrm{W}|\\neg\\mathrm{L}}$。\n    - 如果体素$j$在Wernicke区外（$j \\notin \\mathcal{W}$），病灶概率是一个恒定的背景率，$P(X_{ij}=1) = p_{\\mathrm{NW}}$，与$L_i$无关。\n这个概率模型创建了所需的关联结构：$\\mathcal{W}$内的病灶在统计上与较低的分数$s_i$相关（通过它们对$L_i$的共同依赖性），而$\\mathcal{W}$外的病灶则不相关。\n\n**2. 逐体素统计分析**\n\n此阶段旨在通过独立检验每个体素来恢复真实的关联关系。\n\n- **分组比较**：对每个体素$j=0, \\dots, V-1$，将$N$名患者的队列划分为两组：在体素$j$有病灶的组（组$\\mathcal{L}_j$，其中$X_{ij}=1$）和没有病灶的组（组$\\mathcal{U}_j$，其中$X_{ij}=0$）。\n\n- **可检验性标准**：只有当一个体素满足两组的最小样本量要求时，它才被认为是可检验的。具体来说，病灶组的患者数$n_1 = |\\mathcal{L}_j|$和无病灶组的患者数$n_2 = |\\mathcal{U}_j|$都必须大于或等于一个最小阈值$n_{\\min}=5$。此外，导致退化统计检验（例如，两组方差均为零，导致t统计量未定义）的体素将被排除。\n\n- **Welch t检验**：对每个可检验的体素，对两组的理解分数$s_i$执行双样本Welch t检验。选择此检验是因为它不假设病灶组和无病灶组之间的方差相等，这在病灶研究中是一个审慎的假设。检验得出一个t统计量$t_j$和相应的双侧p值$p_j$。p值使用学生t分布计算，其自由度$\\nu_j$通过Welch-Satterthwaite公式估计。带有参数`equal_var=False`的`scipy.stats.ttest_ind`函数为此整个过程提供了一个稳健且数值稳定的实现。\n\n**3. 多重比较校正**\n\n在每个体素上执行统计检验会引发多重比较问题，从而增加了假阳性发现的比率。为解决此问题，使用Benjamini-Hochberg（B-H）程序来控制错误发现率（FDR）。\n\n- **程序**：B-H程序仅应用于来自可检验体素的$m$个p值集合。\n    1. 将$m$个p值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n    2. 找到最大的索引$k$（其中$k \\in \\{1, \\dots, m\\}$），使得第$k$个排序后的p值满足条件$p_{(k)} \\le \\frac{k}{m} q$，其中$q=0.05$是期望的FDR水平。\n    3. 如果找到了这样的$k$，则所有原始（未排序）p值小于或等于$p_{(k)}$的已检验体素都将被声明为统计显著。如果不存在这样的$k$，则没有体素被声明为显著。\n\n**4. 最终指标计算**\n\n最后一步是量化每个测试用例的分析结果。问题要求报告位于真实Wernicke区掩模$\\mathcal{W}$内的显著体素数量。这个计数可作为真阳性的度量，反映了VLSM分析在不同条件下（例如，变化的效应大小、病灶患病率）正确识别与模拟缺陷相关区域的能力（效能）。最终输出是这些整数计数的列表，每个测试用例对应一个计数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import ttest_ind\n\ndef run_vlsm_analysis(N, V, wernicke_mask_indices, n_min, q_level, params):\n    \"\"\"\n    Runs the full lesion-symptom mapping simulation and analysis for one test case.\n    \"\"\"\n    mu, delta, sigma, pi, p_W_L, p_W_notL, p_NW, seed = params\n    \n    rng = np.random.default_rng(seed)\n\n    # 1. Data Generation\n    # Generate latent Wernicke-lesion indicators\n    L = rng.binomial(1, pi, size=N)\n    \n    # Generate comprehension scores based on latent state and noise\n    epsilon = rng.normal(loc=0, scale=sigma, size=N)\n    s = mu - delta * L + epsilon\n    \n    # Generate lesion mask matrix X (N x V)\n    X = np.zeros((N, V), dtype=np.int8)\n    \n    # Efficiently generate lesion data\n    for i in range(N):\n        p_W = p_W_L if L[i] == 1 else p_W_notL\n        if wernicke_mask_indices:\n            X[i, wernicke_mask_indices] = rng.binomial(1, p_W, size=len(wernicke_mask_indices))\n    \n    non_wernicke_mask = np.ones(V, dtype=bool)\n    if wernicke_mask_indices:\n        non_wernicke_mask[wernicke_mask_indices] = False\n    num_non_wernicke_voxels = np.sum(non_wernicke_mask)\n    if num_non_wernicke_voxels > 0:\n        X[:, non_wernicke_mask] = rng.binomial(1, p_NW, size=(N, num_non_wernicke_voxels))\n\n    # 2. Voxel-wise Statistical Analysis\n    tested_voxels_pvals = []\n    tested_voxels_indices = []\n\n    for j in range(V):\n        lesion_mask = X[:, j] == 1\n        scores_lesioned = s[lesion_mask]\n        scores_unlesioned = s[~lesion_mask]\n        \n        n1 = len(scores_lesioned)\n        n2 = len(scores_unlesioned)\n        \n        # Check testability criteria\n        if n1  n_min or n2  n_min:\n            continue\n            \n        # Perform Welch's t-test\n        t_stat, p_val = ttest_ind(scores_lesioned, scores_unlesioned, equal_var=False, nan_policy='propagate')\n        \n        if np.isnan(p_val):\n            continue\n            \n        tested_voxels_pvals.append(p_val)\n        tested_voxels_indices.append(j)\n\n    # 3. False Discovery Rate (FDR) Correction\n    significant_voxel_indices = []\n    m = len(tested_voxels_pvals)\n\n    if m > 0:\n        pvals_array = np.array(tested_voxels_pvals)\n        sort_indices = np.argsort(pvals_array)\n        sorted_pvals = pvals_array[sort_indices]\n        \n        k_values = np.arange(1, m + 1)\n        bh_thresholds = (k_values / m) * q_level\n        \n        pvals_below_threshold_mask = sorted_pvals = bh_thresholds\n        \n        if np.any(pvals_below_threshold_mask):\n            last_significant_k_idx = np.where(pvals_below_threshold_mask)[0][-1]\n            p_threshold = sorted_pvals[last_significant_k_idx]\n            \n            significant_mask = pvals_array = p_threshold\n            original_indices = np.array(tested_voxels_indices)\n            significant_voxel_indices = list(original_indices[significant_mask])\n\n    # 4. Final Metric Calculation\n    count = 0\n    w_set = set(wernicke_mask_indices)\n    for idx in significant_voxel_indices:\n        if idx in w_set:\n            count += 1\n            \n    return count\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results in the specified format.\n    \"\"\"\n    # Define global parameters and test cases from the problem statement.\n    N = 50\n    V = 200\n    wernicke_mask_indices = list(range(80, 120))\n    n_min = 5\n    q_level = 0.05\n\n    test_cases = [\n        (10, 3.0, 2.0, 0.5, 0.8, 0.05, 0.1, 12345),  # Case A\n        (10, 0.0, 2.0, 0.5, 0.8, 0.05, 0.1, 12346),  # Case B\n        (10, 3.0, 2.0, 1.0, 0.98, 0.0, 0.1, 12347),  # Case C\n        (10, 0.5, 2.0, 0.5, 0.7, 0.05, 0.1, 12348),  # Case D\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = run_vlsm_analysis(N, V, wernicke_mask_indices, n_min, q_level, case_params)\n        results.append(result)\n\n    # Print the final output as a comma-separated list in brackets.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}