{
    "hands_on_practices": [
        {
            "introduction": "要理解迭代重建，首先需要了解我们处理的数据的物理和统计特性。这个练习将带你从CT成像的物理基础出发，探讨光子计数的泊松统计特性，并推导出如何将其转化为一个加权最小二乘（WLS）问题。掌握这一过程至关重要，因为它揭示了重建算法中数学模型与物理现实之间的联系。",
            "id": "4895909",
            "problem": "一个平行束透射计算机断层扫描（CT）系统测量探测器上的光子计数。假设由于量子噪声，每次射线测量都是一个遵循泊松统计的随机变量。设入射光子通量为每个探测器积分周期 $I_0$ 个光子，对于具有恒定线性衰减系数 $\\mu$ 和射线路径长度 $l$ 的均匀平板，根据 Beer–Lambert 定律，平均透射通量为 $I_0 \\exp(-l \\mu)$。射线上测得的探测器计数 $n$ 被建模为均值为 $I_0 \\exp(-l \\mu)$ 的泊松随机变量。考虑对数变换后的测量值 $y = -\\ln\\!\\big(n/I_0\\big)$。\n\n基于这些基础：\n- Beer–Lambert 定律，以及\n- 均值等于透射通量的光子计数泊松统计，\n\n请执行以下任务：\n1. 对变换 $y = -\\ln\\!\\big(n/I_0\\big)$ 在均值计数附近使用一阶近似，推导出 $y$ 的近似方差表达式（用泊松均值表示），并为加权最小二乘（WLS）公式确定最佳权重。该公式将 $y$ 建模为对 $l \\mu$ 的带噪线性观测。\n2. 对于均匀的 $\\mu$ 和一组由索引 $i$ 标记的独立射线，其路径长度 $l_i$、对数变换后的测量值 $y_i$ 以及从第1部分推导出的权重均为已知，请推导出 $\\mu$ 的闭式 WLS 估计量。\n3. 使用以下来自三条独立射线的数据，计算 $\\mu$ 的 WLS 估计的数值：\n   - 所有射线的入射通量 $I_0$ 相同，等于每个探测器积分周期 $5.0 \\times 10^{5}$ 个光子。\n   - 路径长度分别为 $l_1 = 30$ mm, $l_2 = 50$ mm, 和 $l_3 = 80$ mm。\n   - 测量计数分别为 $n_1 = 450000$, $n_2 = 420000$, 和 $n_3 = 380000$。\n   - 使用对数变换 $y_i = -\\ln\\!\\big(n_i/I_0\\big)$ 和“代入”近似法，即用测量计数代替权重中的泊松均值。\n\n将 $\\mu$ 的最终数值估计以 $\\mathrm{mm}^{-1}$ 为单位表示，并四舍五入到四位有效数字。",
            "solution": "### 解答\n\n该问题被认为是有效的，因为它科学合理、适定，并且提供了所有必要的信息。我们将按顺序完成这三项任务。\n\n**1. $y$ 的近似方差和最佳 WLS 权重**\n\n对数变换后的测量值为 $y = g(n) = -\\ln(n/I_0)$，其中 $n$ 是一个泊松随机变量，其均值为 $\\lambda = \\mathbb{E}[n] = I_0 \\exp(-l \\mu)$。泊松随机变量的方差等于其均值，因此 $\\mathrm{Var}(n) = \\lambda$。\n\n为了求变换后变量 $y$ 的近似方差，我们使用 $g(n)$ 在其均值 $\\lambda$ 附近的一阶泰勒级数展开。这通常被称为 delta 方法。方差近似为：\n$$\n\\mathrm{Var}(y) = \\mathrm{Var}(g(n)) \\approx \\left[ g'(\\mathbb{E}[n]) \\right]^2 \\mathrm{Var}(n)\n$$\n首先，我们求 $g(n)$ 对 $n$ 的导数：\n$$\ng(n) = -\\ln(n) + \\ln(I_0)\n$$\n$$\ng'(n) = \\frac{d}{dn} \\left( -\\ln(n) + \\ln(I_0) \\right) = -\\frac{1}{n}\n$$\n接下来，我们在 $n$ 的均值 $\\lambda$ 处计算这个导数：\n$$\ng'(\\lambda) = -\\frac{1}{\\lambda}\n$$\n将此结果以及 $\\mathrm{Var}(n) = \\lambda$ 代入方差近似公式：\n$$\n\\mathrm{Var}(y) \\approx \\left( -\\frac{1}{\\lambda} \\right)^2 \\lambda = \\frac{1}{\\lambda^2} \\lambda = \\frac{1}{\\lambda}\n$$\n代入 $\\lambda$ 的表达式：\n$$\n\\mathrm{Var}(y) \\approx \\frac{1}{I_0 \\exp(-l \\mu)} = \\frac{\\exp(l \\mu)}{I_0}\n$$\n在加权最小二乘（WLS）回归中，最佳权重是测量方差的倒数。模型是 $y \\approx l\\mu$，这是对投影图值 $p = l\\mu$ 的带噪线性观测。测量值 $y$ 的权重 $w$ 是：\n$$\nw = \\frac{1}{\\mathrm{Var}(y)} \\approx \\lambda = I_0 \\exp(-l \\mu)\n$$\n因此，$y$ 的近似方差是 $1/ \\lambda$，而最佳 WLS 权重是 $\\lambda$。\n\n**2. $\\mu$ 的闭式 WLS 估计量**\n\n我们有一组独立测量值 $\\{y_i\\}$，其中 $i=1, 2, ..., N$。每个测量的模型是：\n$$\ny_i \\approx l_i \\mu\n$$\n这可以写成一个线性模型 $y_i = l_i \\mu + \\epsilon_i$，其中 $\\epsilon_i$ 是一个零均值噪声项，其方差为 $\\mathrm{Var}(y_i) \\approx 1/w_i$。$\\mu$ 的 WLS 估计量，记作 $\\hat{\\mu}$，是使加权残差平方和 $S(\\mu)$ 最小化的值：\n$$\nS(\\mu) = \\sum_{i=1}^{N} w_i (y_i - l_i \\mu)^2\n$$\n为了找到最小值，我们将 $S(\\mu)$ 对 $\\mu$ 求导，并令结果为零：\n$$\n\\frac{dS}{d\\mu} = \\sum_{i=1}^{N} w_i \\cdot 2(y_i - l_i \\mu) \\cdot (-l_i) = -2 \\sum_{i=1}^{N} w_i l_i (y_i - l_i \\mu)\n$$\n令 $\\frac{dS}{d\\mu} = 0$：\n$$\n\\sum_{i=1}^{N} w_i l_i (y_i - l_i \\mu) = 0\n$$\n$$\n\\sum_{i=1}^{N} w_i l_i y_i - \\sum_{i=1}^{N} w_i l_i^2 \\mu = 0\n$$\n求解 $\\mu$：\n$$\n\\mu \\left( \\sum_{i=1}^{N} w_i l_i^2 \\right) = \\sum_{i=1}^{N} w_i l_i y_i\n$$\n因此，$\\mu$ 的闭式 WLS 估计量为：\n$$\n\\hat{\\mu}_{\\text{WLS}} = \\frac{\\sum_{i=1}^{N} w_i l_i y_i}{\\sum_{i=1}^{N} w_i l_i^2}\n$$\n正如在第1部分中推导的，最佳权重是 $w_i = \\lambda_i = I_0 \\exp(-l_i \\mu)$。由于这些权重依赖于未知参数 $\\mu$，一个实际的解决方案是采用“代入”近似法，即用测量的计数值 $n_i$ 替代未知的平均计数值 $\\lambda_i$。问题陈述明确要求使用这种近似，因此我们使用 $w_i = n_i$。\n\n**3. $\\mu$ 的 WLS 估计的数值计算**\n\n给定以下 $N=3$ 条射线的数据：\n- $I_0 = 5.0 \\times 10^5$\n- $l_1 = 30$ mm, $l_2 = 50$ mm, $l_3 = 80$ mm\n- $n_1 = 450000$, $n_2 = 420000$, $n_3 = 380000$\n\n首先，我们计算对数变换后的测量值 $y_i = -\\ln(n_i/I_0)$：\n$$\ny_1 = -\\ln\\left(\\frac{450000}{500000}\\right) = -\\ln(0.9) \\approx 0.1053605\n$$\n$$\ny_2 = -\\ln\\left(\\frac{420000}{500000}\\right) = -\\ln(0.84) \\approx 0.1743534\n$$\n$$\ny_3 = -\\ln\\left(\\frac{380000}{500000}\\right) = -\\ln(0.76) \\approx 0.2744368\n$$\n我们使用代入权重 $w_i = n_i$：\n- $w_1 = 450000$\n- $w_2 = 420000$\n- $w_3 = 380000$\n\n现在，我们计算 WLS 估计量公式的分子和分母：\n$$\n\\hat{\\mu} = \\frac{n_1 l_1 y_1 + n_2 l_2 y_2 + n_3 l_3 y_3}{n_1 l_1^2 + n_2 l_2^2 + n_3 l_3^2}\n$$\n\n分子：$\\sum_{i=1}^{3} n_i l_i y_i$\n$$\n(450000)(30)(0.1053605) \\approx 1422366.75\n$$\n$$\n(420000)(50)(0.1743534) \\approx 3661421.4\n$$\n$$\n(380000)(80)(0.2744368) \\approx 8342858.88\n$$\n分子之和 $\\approx 1422366.75 + 3661421.4 + 8342858.88 = 13426647.03$\n\n分母：$\\sum_{i=1}^{3} n_i l_i^2$\n$$\n(450000)(30^2) = (450000)(900) = 405,000,000\n$$\n$$\n(420000)(50^2) = (420000)(2500) = 1,050,000,000\n$$\n$$\n(380000)(80^2) = (380000)(6400) = 2,432,000,000\n$$\n分母之和 = $405,000,000 + 1,050,000,000 + 2,432,000,000 = 3,887,000,000$\n\n最后，我们计算 $\\hat{\\mu}$ 的估计值：\n$$\n\\hat{\\mu} = \\frac{13426647.03}{3887000000} \\approx 0.003454244... \\; \\mathrm{mm}^{-1}\n$$\n将结果四舍五入到四位有效数字，我们得到：\n$$\n\\hat{\\mu} \\approx 0.003454 \\; \\mathrm{mm}^{-1}\n$$",
            "answer": "$$\n\\boxed{0.003454}\n$$"
        },
        {
            "introduction": "在得到一个线性方程组后，噪声和不适定性往往使得求解过程变得复杂。本练习提供了一个具体的、基于计算的实践，让你亲手应用Tikhonov正则化——这是稳定逆问题解的最基本技术之一。你将为一个简化但富有洞察力的CT几何模型推导并计算出正则化后的解，从而加深对正则化目标函数及其分析解的理解。",
            "id": "4895893",
            "problem": "考虑一个简化的平行束计算机断层扫描（CT）正向模型，其中有两个未知的、空间均匀的像素衰减系数 $x \\in \\mathbb{R}^{2}$，代表一个由列像素组成的 $2 \\times 1$ 物体。测量了三条射线：射线1仅穿过像素1，路径长度为 $1\\,\\mathrm{cm}$；射线2仅穿过像素2，路径长度为 $1\\,\\mathrm{cm}$；射线3穿过两个像素，每个像素的路径长度均为 $1\\,\\mathrm{cm}$。将探测到的光子计数进行对数转换得到线积分后，测量数据向量为 $b \\in \\mathbb{R}^{3}$，其分量为 $b_{1} = 0.10\\,\\mathrm{cm}^{-1}$，$b_{2} = 0.20\\,\\mathrm{cm}^{-1}$ 和 $b_{3} = 0.25\\,\\mathrm{cm}^{-1}$。系统矩阵 $A \\in \\mathbb{R}^{3 \\times 2}$ 对应于这些路径长度，并由上述几何结构隐式给出。假设各射线上的噪声是独立同分布的高斯噪声，因此加权最小二乘法（WLS）的权重矩阵为 $W = I_{3}$。为稳定重建结果，应用二次吉洪诺夫正则化，其一阶有限差分算子 $L \\in \\mathbb{R}^{1 \\times 2}$ 定义为 $L = \\begin{bmatrix}1  -1\\end{bmatrix}$，正则化参数为 $\\lambda = 0.50$。\n\n从线性正向模型 $b = A x + n$ 和 WLS 吉洪诺夫目标函数\n$$\nJ(x) = \\frac{1}{2}\\,\\|W^{1/2}(A x - b)\\|_{2}^{2} + \\frac{\\lambda}{2}\\,\\|L x\\|_{2}^{2},\n$$\n出发，推导其最小化解必须满足的条件，然后使用给定的 $A$，$b$，$W$，$L$ 和 $\\lambda$ 计算最小化解 $x^{\\star}$。将最终重建的衰减系数以厘米的倒数（$\\mathrm{cm}^{-1}$）表示。以 $\\begin{pmatrix}\\cdot  \\cdot\\end{pmatrix}$ 格式的单个行向量形式提供最终答案。无需四舍五入；报告精确值。",
            "solution": "### 解题推导\n目标是找到向量 $x \\in \\mathbb{R}^2$，以最小化吉洪诺夫正则化加权最小二乘目标函数：\n$$\nJ(x) = \\frac{1}{2}\\,\\|W^{1/2}(A x - b)\\|_{2}^{2} + \\frac{\\lambda}{2}\\,\\|L x\\|_{2}^{2}\n$$\n平方 $L_2$-范数可以用转置表示：$\\|v\\|_2^2 = v^T v$。\n$$\nJ(x) = \\frac{1}{2}\\,(A x - b)^T W (A x - b) + \\frac{\\lambda}{2}\\,(L x)^T (L x)\n$$\n展开各项，我们得到：\n$$\nJ(x) = \\frac{1}{2}\\,(x^T A^T - b^T) W (A x - b) + \\frac{\\lambda}{2}\\, x^T L^T L x\n$$\n$$\nJ(x) = \\frac{1}{2}\\,(x^T A^T W A x - x^T A^T W b - b^T W A x + b^T W b) + \\frac{\\lambda}{2}\\, x^T L^T L x\n$$\n由于 $x^T A^T W b$ 是一个标量，它等于其转置，即 $(x^T A^T W b)^T = b^T W^T A x$。因为 $W$ 是一个权重矩阵，所以它是对称的（$W^T = W$），因此 $b^T W A x = x^T A^T W b$。\n$$\nJ(x) = \\frac{1}{2}\\,x^T (A^T W A) x - x^T (A^T W b) + \\frac{1}{2}\\,b^T W b + \\frac{1}{2}\\, x^T (\\lambda L^T L) x\n$$\n这是一个关于 $x$ 的二次函数。为求最小值，我们计算 $J(x)$ 关于 $x$ 的梯度，并将其设为零向量。\n$$\n\\nabla_{x} J(x) = \\frac{1}{2}\\,(2 A^T W A x) - A^T W b + \\frac{1}{2}\\,(2 \\lambda L^T L x)\n$$\n$$\n\\nabla_{x} J(x) = A^T W A x - A^T W b + \\lambda L^T L x\n$$\n将梯度设为零，得到最小化解 $x^{\\star}$ 的条件：\n$$\nA^T W A x^{\\star} + \\lambda L^T L x^{\\star} = A^T W b\n$$\n提取出 $x^{\\star}$，我们得到吉洪诺夫正则化WLS的法方程：\n$$\n(A^T W A + \\lambda L^T L) x^{\\star} = A^T W b\n$$\n因此，解为：\n$$\nx^{\\star} = (A^T W A + \\lambda L^T L)^{-1} A^T W b\n$$\n\n现在，我们代入给定值。首先，根据提供的几何结构为 $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$ 构建系统矩阵 $A$：\n- 射线1：$1 \\cdot x_1 + 0 \\cdot x_2 = b_1$。这给出了 $A$ 的第一行为 $\\begin{bmatrix} 1  0 \\end{bmatrix}$。\n- 射线2：$0 \\cdot x_1 + 1 \\cdot x_2 = b_2$。这给出了 $A$ 的第二行为 $\\begin{bmatrix} 0  1 \\end{bmatrix}$。\n- 射线3：$1 \\cdot x_1 + 1 \\cdot x_2 = b_3$。这给出了 $A$ 的第三行为 $\\begin{bmatrix} 1  1 \\end{bmatrix}$。\n所以，系统矩阵为：\n$$\nA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{pmatrix}\n$$\n数据向量为 $b = \\begin{pmatrix} 0.10 \\\\ 0.20 \\\\ 0.25 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{5} \\\\ \\frac{1}{4} \\end{pmatrix}$。\n权重矩阵为 $W = I_3$，所以公式简化为：\n$$\nx^{\\star} = (A^T A + \\lambda L^T L)^{-1} A^T b\n$$\n我们计算所需的矩阵：\n$A^T = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\end{pmatrix}$\n$A^T A = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1+0+1  0+0+1 \\\\ 0+0+1  0+1+1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix}$\n$L = \\begin{bmatrix} 1  -1 \\end{bmatrix}$，所以 $L^T = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$\n$L^T L = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} \\begin{bmatrix} 1  -1 \\end{bmatrix} = \\begin{pmatrix} 1  -1 \\\\ -1  1 \\end{pmatrix}$\n正则化参数为 $\\lambda = 0.50 = \\frac{1}{2}$。\n现在，我们计算项 $(A^T A + \\lambda L^T L)$：\n$$\nA^T A + \\lambda L^T L = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} + \\frac{1}{2} \\begin{pmatrix} 1  -1 \\\\ -1  1 \\end{pmatrix} = \\begin{pmatrix} 2  1 \\\\ 1  2 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2}  -\\frac{1}{2} \\\\ -\\frac{1}{2}  \\frac{1}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{2}  \\frac{1}{2} \\\\ \\frac{1}{2}  \\frac{5}{2} \\end{pmatrix}\n$$\n接下来，我们计算其逆矩阵。行列式为 $\\det(\\cdot) = (\\frac{5}{2})(\\frac{5}{2}) - (\\frac{1}{2})(\\frac{1}{2}) = \\frac{25}{4} - \\frac{1}{4} = \\frac{24}{4} = 6$。\n逆矩阵是：\n$$\n(A^T A + \\lambda L^T L)^{-1} = \\frac{1}{6} \\begin{pmatrix} \\frac{5}{2}  -\\frac{1}{2} \\\\ -\\frac{1}{2}  \\frac{5}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{12}  -\\frac{1}{12} \\\\ -\\frac{1}{12}  \\frac{5}{12} \\end{pmatrix}\n$$\n接下来，我们计算项 $A^T b$：\n$$\nA^T b = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{10} \\\\ \\frac{1}{5} \\\\ \\frac{1}{4} \\end{pmatrix} = \\begin{pmatrix} 1(\\frac{1}{10}) + 0(\\frac{1}{5}) + 1(\\frac{1}{4}) \\\\ 0(\\frac{1}{10}) + 1(\\frac{1}{5}) + 1(\\frac{1}{4}) \\end{pmatrix} = \\begin{pmatrix} \\frac{2+5}{20} \\\\ \\frac{4+5}{20} \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{20} \\\\ \\frac{9}{20} \\end{pmatrix}\n$$\n最后，我们计算解 $x^{\\star}$：\n$$\nx^{\\star} = (A^T A + \\lambda L^T L)^{-1} (A^T b) = \\begin{pmatrix} \\frac{5}{12}  -\\frac{1}{12} \\\\ -\\frac{1}{12}  \\frac{5}{12} \\end{pmatrix} \\begin{pmatrix} \\frac{7}{20} \\\\ \\frac{9}{20} \\end{pmatrix}\n$$\n$$\nx^{\\star} = \\begin{pmatrix} \\frac{5}{12} \\cdot \\frac{7}{20} - \\frac{1}{12} \\cdot \\frac{9}{20} \\\\ -\\frac{1}{12} \\cdot \\frac{7}{20} + \\frac{5}{12} \\cdot \\frac{9}{20} \\end{pmatrix} = \\begin{pmatrix} \\frac{35 - 9}{240} \\\\ \\frac{-7 + 45}{240} \\end{pmatrix} = \\begin{pmatrix} \\frac{26}{240} \\\\ \\frac{38}{240} \\end{pmatrix}\n$$\n化简分数：\n$$\nx^{\\star} = \\begin{pmatrix} x_1^{\\star} \\\\ x_2^{\\star} \\end{pmatrix} = \\begin{pmatrix} \\frac{13}{120} \\\\ \\frac{19}{120} \\end{pmatrix}\n$$\n重建的衰减系数为 $x_1^{\\star} = \\frac{13}{120}\\,\\mathrm{cm}^{-1}$ 和 $x_2^{\\star} = \\frac{19}{120}\\,\\mathrm{cm}^{-1}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{13}{120}  \\frac{19}{120} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "对于大规模的CT系统，直接求解正规方程组往往是不可行的，因此需要依赖计算效率更高的迭代算法。本练习将引导你从第一性原理出发，实现两种经典的迭代算法：应用于正规方程的高斯-赛德尔（Gauss-Seidel）法和代数重建技术（ART）。通过在不同数据集上比较它们的性能，你将获得关于算法收敛特性和噪声敏感性的直观认识。",
            "id": "3135124",
            "problem": "您正在为计算机断层扫描（CT）中的迭代图像重建进行建模，这是一个线性逆问题，由线性系统 $A x = b$ 描述，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是投影（系统）矩阵，$x \\in \\mathbb{R}^{n}$ 是未知图像向量（例如，像素值），$b \\in \\mathbb{R}^{m}$ 是测量的线积分。在存在测量噪声的情况下，该系统通常是不相容的，人们寻求一种能在收敛和噪声放大之间取得平衡的最小二乘解。任务是从基本原理出发，设计并实现两种迭代求解器：应用于正规方程的高斯-赛德尔 (Gauss-Seidel) 迭代和代数重建技术 (ART)。计算机断层扫描 (CT) 和代数重建技术 (ART) 必须在首次使用时进行定义。计算机断层扫描 (CT) 是一种利用X射线投影重建横断面图像的成像模式。代数重建技术 (ART) 是一种迭代方法，通过依次投影到由线性方程定义的超平面上来更新图像。\n\n从最小二乘解最小化平方误差目标函数 $$\\min_{x \\in \\mathbb{R}^{n}} \\ \\lVert A x - b \\rVert_2^2,$$ 这一基本出发点开始，并且驻点满足正规方程 $$A^{\\mathsf{T}} A x = A^{\\mathsf{T}} b.$$ 对于ART，利用每个线性方程 $a_i^{\\mathsf{T}} x = b_i$ 在 $\\mathbb{R}^{n}$ 中定义一个超平面的几何事实，以及到这些超平面上的顺序正交投影会驱动迭代解趋向可行性。通过将系数矩阵分解为下三角和上三角部分，并要求新迭代的每个分量在使用最新的可用分量的情况下精确满足相应的标量方程，来推导正规方程的高斯-赛德尔 (Gauss-Seidel) 迭代。通过使用内积和欧几里得范数表示到一个超平面上的正交投影，来推导ART的更新规则。不要使用未从这些原理推导出的快捷公式。\n\n为以下合成CT测试套件实现这两种方法，以从 $A$ 和 $b$ 重建 $x$。该系统模拟一个 $2 \\times 2$ 像素图像 ($n = 4$)，具有 $m = 6$ 个射线和：两行、两列和两条对角线。像素按 $[x_1, x_2, x_3, x_4]^{\\mathsf{T}}$ 顺序排列，对应于位置 $[(1,1), (1,2), (2,1), (2,2)]$。每个测试用例的投影矩阵和数据如下：\n\n- 测试用例 $1$（理想情况，相容且良态）：\n  $$A_1 = \\begin{bmatrix}\n  1  1  0  0 \\\\\n  0  0  1  1 \\\\\n  1  0  1  0 \\\\\n  0  1  0  1 \\\\\n  1  0  0  1 \\\\\n  0  1  1  0\n  \\end{bmatrix}, \\quad x_{\\text{true},1} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix}, \\quad \\eta_1 = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad b_1 = A_1 x_{\\text{true},1} + \\eta_1.$$\n  对正规方程使用 $N_{\\mathrm{GS},1} = 20$ 次高斯-赛德尔 (Gauss-Seidel) 迭代，并对所有行使用 $N_{\\mathrm{ART},1} = 20$ 次ART完整扫描，松弛参数为 $\\lambda_1 = 1.0$。\n\n- 测试用例 $2$（中等噪声，相同几何结构）：\n  $$A_2 = A_1, \\quad x_{\\text{true},2} = \\begin{bmatrix} 1 \\\\ 0.5 \\\\ 1.5 \\\\ 1 \\end{bmatrix}, \\quad \\eta_2 = \\begin{bmatrix} 0.02 \\\\ -0.015 \\\\ 0.01 \\\\ -0.005 \\\\ 0.0 \\\\ 0.025 \\end{bmatrix}, \\quad b_2 = A_2 x_{\\text{true},2} + \\eta_2.$$\n  使用 $N_{\\mathrm{GS},2} = 40$ 次高斯-赛德尔 (Gauss-Seidel) 迭代和 $N_{\\mathrm{ART},2} = 40$ 次ART完整扫描，松弛参数为 $\\lambda_2 = 1.0$。\n\n- 测试用例 $3$（近冗余射线，更高噪声，测试稳定性）：\n  $$A_3 = \\begin{bmatrix}\n  1  1  0  0 \\\\\n  0  0  1  1 \\\\\n  1  0  1  0 \\\\\n  0  1  0  1 \\\\\n  0.99  0.99  0  0 \\\\\n  0  0  1.01  1.01\n  \\end{bmatrix}, \\quad x_{\\text{true},3} = \\begin{bmatrix} 1.2 \\\\ 0.8 \\\\ 1.0 \\\\ 1.5 \\end{bmatrix}, \\quad \\eta_3 = \\begin{bmatrix} 0.2 \\\\ -0.15 \\\\ 0.1 \\\\ -0.05 \\\\ 0.0 \\\\ 0.25 \\end{bmatrix}, \\quad b_3 = A_3 x_{\\text{true},3} + \\eta_3.$$\n  使用 $N_{\\mathrm{GS},3} = 80$ 次高斯-赛德尔 (Gauss-Seidel) 迭代和 $N_{\\mathrm{ART},3} = 80$ 次ART完整扫描，松弛参数为 $\\lambda_3 = 1.2$。\n\n对于所有情况，使用零向量 $x^{(0)} = \\mathbf{0}$ 作为初始猜测。为每个测试用例计算并报告两种方法的以下可量化指标：\n- 数据空间中的最终残差范数，定义为 $$\\rho = \\lVert A x_{\\text{final}} - b \\rVert_2,$$ 以浮点数形式报告。\n- 噪声放大因子，定义为 $$\\alpha = \\frac{\\lVert x_{\\text{final}} - x_{\\text{true}} \\rVert_2}{\\max\\big(\\lVert \\eta \\rVert_2, \\varepsilon\\big)},$$ 其中 $\\varepsilon = 10^{-12}$ 是一个小的稳定器。对于无噪声数据（即 $\\lVert \\eta \\rVert_2 = 0$），根据定义设置 $\\alpha = 0$。以浮点数形式报告 $\\alpha$。\n\n您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表。列表必须按\n$$[\\rho_{\\mathrm{GS},1}, \\ \\rho_{\\mathrm{ART},1}, \\ \\alpha_{\\mathrm{GS},1}, \\ \\alpha_{\\mathrm{ART},1}, \\ \\rho_{\\mathrm{GS},2}, \\ \\rho_{\\mathrm{ART},2}, \\ \\alpha_{\\mathrm{GS},2}, \\ \\alpha_{\\mathrm{ART},2}, \\ \\rho_{\\mathrm{GS},3}, \\ \\rho_{\\mathrm{ART},3}, \\ \\alpha_{\\mathrm{GS},3}, \\ \\alpha_{\\mathrm{ART},3}],$$\n顺序排列，每个浮点数四舍五入到$6$位小数。此问题不涉及物理单位。不使用角度。不得使用百分比；只应打印指定的浮点数。",
            "solution": "该问题要求推导和实现两种迭代算法，即应用于正规方程的高斯-赛德尔 (Gauss-Seidel) 算法和代数重建技术 (ART)，以求解模拟简化计算机断层扫描（CT）重建问题的线性系统 $A x = b$。计算机断层扫描（CT）是一种利用X射线投影重建横断面图像的成像模式。向量 $x$ 表示未知的像素值，$A$ 是将像素值映射到线积分的系统矩阵，$b$ 是测量的线积分向量，可能受到噪声 $\\eta$ 的污染。\n\n解决方法是首先按照指定的基本原理推导两种方法的迭代更新规则。然后，将实现这些方法并将其应用于三个不同的测试用例，以基于最终残差范数 $\\rho$ 和噪声放大因子 $\\alpha$ 来评估它们的性能。\n\n首先，我们建立数学基础。对于一个不相容系统 $A x = b$，我们寻求一个最小二乘解，该解最小化残差的欧几里得范数平方，由目标函数定义：\n$$ \\min_{x \\in \\mathbb{R}^{n}} \\ \\lVert A x - b \\rVert_2^2 $$\n该目标函数的最小值在梯度相对于 $x$ 为零的驻点处找到。目标函数可以写成 $f(x) = (Ax-b)^{\\mathsf{T}}(Ax-b) = x^{\\mathsf{T}}A^{\\mathsf{T}}Ax - 2b^{\\mathsf{T}}Ax + b^{\\mathsf{T}}b$。梯度是 $\\nabla_x f(x) = 2A^{\\mathsf{T}}Ax - 2A^{\\mathsf{T}}b$。将梯度设置为零可得出正规方程：\n$$ A^{\\mathsf{T}} A x = A^{\\mathsf{T}} b $$\n这构成一个对称半正定线性系统，我们将其表示为 $Cx = d$，其中 $C = A^{\\mathsf{T}}A$ 且 $d = A^{\\mathsf{T}}b$。如果 $A$ 具有满列秩，则 $C$ 是正定的。\n\n**正规方程的高斯-赛德尔 (Gauss-Seidel) 方法推导**\n\n高斯-赛德尔 (Gauss-Seidel) 方法是一种求解方形线性系统 $Cx=d$ 的迭代技术。它通过首先将矩阵 $C$ 分解为其对角 ($D$)、严格下三角 ($L$) 和严格上三角 ($U$) 部分来推导，使得 $C = L + D + U$。系统 $Cx = d$ 可以写成：\n$$ (L + D + U)x = d $$\n该迭代方法生成一个向量序列 $x^{(k)}$，理想情况下该序列收敛于真实解 $x$。高斯-赛德尔 (Gauss-Seidel) 的核心思想是重新排列方程，以使用最新计算出的值来求解下一个迭代解 $x^{(k+1)}$：\n$$ (L + D) x^{(k+1)} = d - U x^{(k)} $$\n这可以按分量表示。对于系统中的第 $j$ 个方程，我们有：\n$$ \\sum_{i=1}^{n} C_{ji} x_i = d_j $$\n展开此和得到：\n$$ \\sum_{i=1}^{j-1} C_{ji} x_i + C_{jj} x_j + \\sum_{i=j+1}^{n} C_{ji} x_i = d_j $$\n高斯-赛德尔 (Gauss-Seidel) 方法在迭代 $k+1$ 时更新解向量的第 $j$ 个分量 $x_j$，方法是使用当前迭代中已经更新的分量 $x_1^{(k+1)}, \\dots, x_{j-1}^{(k+1)}$ 和前一次迭代中的旧分量 $x_{j+1}^{(k)}, \\dots, x_n^{(k)}$。我们求解 $x_j^{(k+1)}$：\n$$ C_{jj} x_j^{(k+1)} = d_j - \\sum_{i=1}^{j-1} C_{ji} x_i^{(k+1)} - \\sum_{i=j+1}^{n} C_{ji} x_i^{(k)} $$\n在迭代 $k+1$ 时，第 $j$ 个分量的最终更新规则是：\n$$ x_j^{(k+1)} = \\frac{1}{C_{jj}} \\left( d_j - \\sum_{i=1}^{j-1} C_{ji} x_i^{(k+1)} - \\sum_{i=j+1}^{n} C_{ji} x_i^{(k)} \\right) $$\n对 $j = 1, \\dots, n$ 执行此迭代，以完成从 $x^{(k)}$ 到 $x^{(k+1)}$ 的一次完整更新。该过程从一个初始猜测 $x^{(0)}$（在本问题中为零向量）开始，并重复指定的迭代次数。为了使该方法收敛，矩阵 $C$ 必须是对称正定的或严格对角占优的。由于 $C=A^{\\mathsf{T}}A$，并且所提供的矩阵 $A$ 在前两种情况下具有满列秩，在第三种情况下几乎满列秩，因此 $C$ 是对称正定的，这保证了收敛性。\n\n**代数重建技术 (ART) 的推导**\n\n代数重建技术 (ART) 是 Kaczmarz 方法的一个具体应用，它逐行处理原始系统 $Ax=b$。代数重建技术 (ART) 是一种迭代方法，通过依次投影到由线性方程定义的超平面上来更新图像。系统的每一行，$a_i^{\\mathsf{T}} x = b_i$（对于 $i=1, \\dots, m$），在 $\\mathbb{R}^n$ 中定义了一个超平面 $H_i$。目标是迭代地将当前的解估计值投影到这些超平面上。\n\n设 $x^{(k)}$ 为当前估计值。我们希望通过将 $x^{(k)}$ 正交投影到超平面 $H_i$ 上来找到下一个估计值 $x^{(k+1)}$。连接 $x^{(k)}$ 到其在 $H_i$ 上的投影的向量必须与超平面的法向量 $a_i$ 平行。因此，更新具有以下形式：\n$$ x^{(k+1)} = x^{(k)} + c \\cdot a_i $$\n对于某个标量 $c$。由于 $x^{(k+1)}$ 必须位于超平面 $H_i$ 上，它必须满足方程 $a_i^{\\mathsf{T}} x^{(k+1)} = b_i$。将更新形式代入此方程得到：\n$$ a_i^{\\mathsf{T}} (x^{(k)} + c \\cdot a_i) = b_i $$\n$$ a_i^{\\mathsf{T}} x^{(k)} + c \\cdot (a_i^{\\mathsf{T}} a_i) = b_i $$\n项 $a_i^{\\mathsf{T}} a_i$ 是向量 $a_i$ 的欧几里得范数的平方，记作 $\\lVert a_i \\rVert_2^2$。解出 $c$：\n$$ c \\cdot \\lVert a_i \\rVert_2^2 = b_i - a_i^{\\mathsf{T}} x^{(k)} $$\n$$ c = \\frac{b_i - a_i^{\\mathsf{T}} x^{(k)}}{\\lVert a_i \\rVert_2^2} $$\n这假设 $\\lVert a_i \\rVert_2 \\neq 0$，对于给定的系统矩阵这是成立的。将 $c$ 代回更新形式，得到正交投影更新：\n$$ x^{(k+1)} = x^{(k)} + \\frac{b_i - a_i^{\\mathsf{T}} x^{(k)}}{\\lVert a_i \\rVert_2^2} a_i $$\n问题要求一个带有松弛参数 $\\lambda$ 的版本。该参数控制投影的步长，其中 $\\lambda=1$ 对应于完全正交投影。广义更新规则是：\n$$ x^{(k+1)} = x^{(k)} + \\lambda \\frac{b_i - a_i^{\\mathsf{T}} x^{(k)}}{\\lVert a_i \\rVert_2^2} a_i $$\nART 的一次完整扫描包括对每一行 $i=1, \\dots, m$ 依次应用此更新。也就是说，投影到 $H_i$ 上的结果成为投影到 $H_{i+1}$ 上的起点。\n\n**实现与指标**\n\n将这两种推导出的方法实现并应用于三个测试用例。对于每种方法和每种情况，使用最终解向量 $x_{\\text{final}}$ 计算两个指标：\n1. 最终残差范数：$\\rho = \\lVert A x_{\\text{final}} - b \\rVert_2$。\n2. 噪声放大因子：$\\alpha = \\frac{\\lVert x_{\\text{final}} - x_{\\text{true}} \\rVert_2}{\\max\\big(\\lVert \\eta \\rVert_2, \\varepsilon\\big)}$，其中 $\\varepsilon = 10^{-12}$。根据给出的定义，如果 $\\lVert \\eta \\rVert_2=0$，则 $\\alpha = 0$。\n\n实现将遵循推导出的公式，从初始猜测 $x^{(0)} = \\mathbf{0}$ 开始，进行指定次数的迭代或扫描。然后收集最终结果并按要求进行格式化。\n\n```python\nimport numpy as np\n\ndef run_gauss_seidel(A, b, n_iters):\n    \"\"\"\n    Solves the normal equations Ax=b using the Gauss-Seidel method.\n    The system being solved is (A^T A)x = (A^T b).\n    \"\"\"\n    m, n = A.shape\n    x_gs = np.zeros(n)\n    \n    C = A.T @ A\n    d = A.T @ b\n    \n    for _ in range(n_iters):\n        for j in range(n):\n            # Sum for already updated components in this iteration\n            sum_new = C[j, :j] @ x_gs[:j]\n            # Sum for components from the previous iteration\n            sum_old = C[j, j+1:] @ x_gs[j+1:]\n            \n            # Avoid division by zero for numerical stability\n            diag_element = C[j, j]\n            if abs(diag_element)  1e-12:\n                diag_element = 1e-12\n\n            x_gs[j] = (d[j] - sum_new - sum_old) / diag_element\n            \n    return x_gs\n\ndef run_art(A, b, n_sweeps, lam):\n    \"\"\"\n    Solves Ax=b using the Algebraic Reconstruction Technique (ART).\n    \"\"\"\n    m, n = A.shape\n    x_art = np.zeros(n)\n    \n    # Pre-calculate the squared L2 norm of each row of A\n    a_row_norm_sq = np.sum(A**2, axis=1)\n    \n    for _ in range(n_sweeps):\n        for i in range(m):\n            a_i = A[i, :]\n            b_i = b[i]\n            \n            norm_sq = a_row_norm_sq[i]\n            if norm_sq  1e-12:\n                # This row is all zeros, no information, skip update\n                continue\n            \n            # ART update rule\n            current_projection = a_i @ x_art\n            update_factor = lam * (b_i - current_projection) / norm_sq\n            x_art = x_art + update_factor * a_i\n            \n    return x_art\n\ndef calculate_alpha(x_final, x_true, eta):\n    \"\"\"\n    Calculates the noise amplification factor alpha.\n    \"\"\"\n    eps = 1e-12\n    norm_eta = np.linalg.norm(eta)\n    \n    if norm_eta  eps:\n        return 0.0\n    \n    error_norm = np.linalg.norm(x_final - x_true)\n    alpha = error_norm / max(norm_eta, eps)\n    return alpha\n\ndef solve_and_get_results():\n    \"\"\"\n    Main function to run all test cases and return the results.\n    \"\"\"\n    # Test Case 1\n    A1 = np.array([\n        [1, 1, 0, 0],\n        [0, 0, 1, 1],\n        [1, 0, 1, 0],\n        [0, 1, 0, 1],\n        [1, 0, 0, 1],\n        [0, 1, 1, 0]\n    ], dtype=float)\n    x_true1 = np.array([1, 2, 3, 4], dtype=float)\n    eta1 = np.zeros(6, dtype=float)\n    N_GS1, N_ART1, lambda1 = 20, 20, 1.0\n\n    # Test Case 2\n    A2 = A1\n    x_true2 = np.array([1, 0.5, 1.5, 1], dtype=float)\n    eta2 = np.array([0.02, -0.015, 0.01, -0.005, 0.0, 0.025], dtype=float)\n    N_GS2, N_ART2, lambda2 = 40, 40, 1.0\n\n    # Test Case 3\n    A3 = np.array([\n        [1.00, 1.00, 0.00, 0.00],\n        [0.00, 0.00, 1.00, 1.00],\n        [1.00, 0.00, 1.00, 0.00],\n        [0.00, 1.00, 0.00, 1.00],\n        [0.99, 0.99, 0.00, 0.00],\n        [0.00, 0.00, 1.01, 1.01]\n    ], dtype=float)\n    x_true3 = np.array([1.2, 0.8, 1.0, 1.5], dtype=float)\n    eta3 = np.array([0.2, -0.15, 0.1, -0.05, 0.0, 0.25], dtype=float)\n    N_GS3, N_ART3, lambda3 = 80, 80, 1.2\n    \n    test_cases = [\n        (A1, x_true1, eta1, N_GS1, N_ART1, lambda1),\n        (A2, x_true2, eta2, N_GS2, N_ART2, lambda2),\n        (A3, x_true3, eta3, N_GS3, N_ART3, lambda3),\n    ]\n\n    results = []\n    for A, x_true, eta, N_GS, N_ART, lam in test_cases:\n        b = A @ x_true + eta\n\n        # Run Gauss-Seidel for Normal Equations\n        x_final_gs = run_gauss_seidel(A, b, N_GS)\n        rho_gs = np.linalg.norm(A @ x_final_gs - b)\n        alpha_gs = calculate_alpha(x_final_gs, x_true, eta)\n\n        # Run ART\n        x_final_art = run_art(A, b, N_ART, lam)\n        rho_art = np.linalg.norm(A @ x_final_art - b)\n        alpha_art = calculate_alpha(x_final_art, x_true, eta)\n\n        results.extend([rho_gs, rho_art, alpha_gs, alpha_art])\n\n    return f\"[{','.join(f'{x:.6f}' for x in results)}]\"\n\n# The final answer is generated by running the function above.\n# print(solve_and_get_results())\n```",
            "answer": "[0.000000,0.000000,0.000000,0.000000,0.038573,0.038730,0.852332,0.838531,0.370154,0.364906,0.334008,0.344426]"
        }
    ]
}