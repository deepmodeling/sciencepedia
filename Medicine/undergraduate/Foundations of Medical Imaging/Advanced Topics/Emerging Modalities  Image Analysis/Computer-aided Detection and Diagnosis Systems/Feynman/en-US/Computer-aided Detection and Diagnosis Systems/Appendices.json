{
    "hands_on_practices": [
        {
            "introduction": "The foundation of any Computer-Aided Detection (CAD) system is the classifier that distinguishes between different classes, such as \"disease present\" and \"disease absent.\" This exercise guides you through the process of deriving an optimal linear classifier, known as the Hotelling observer, from first principles. By working through this problem, you will understand how to construct a decision rule that maximizes the separability between two groups based on their underlying statistical properties, providing a theoretical benchmark for classifier performance.",
            "id": "4871522",
            "problem": "In a Computer-Aided Detection (CAD) system for medical imaging, suppose the feature vector extracted from an image, denoted by $\\mathbf{x} \\in \\mathbb{R}^{n}$, is modeled as coming from one of two hypotheses: $H_{0}$ (disease absent) or $H_{1}$ (disease present). Assume the following generative model based on well-tested statistical principles: under $H_{i}$, $\\mathbf{x}$ is multivariate Gaussian with mean $\\boldsymbol{\\mu}_{i} \\in \\mathbb{R}^{n}$ and a common, symmetric positive definite covariance matrix $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{n \\times n}$, so that\n$$\n\\mathbf{x} \\mid H_{i} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{i}, \\boldsymbol{\\Sigma}), \\quad i \\in \\{0,1\\}.\n$$\nA linear observer forms a scalar test statistic $T = \\mathbf{w}^{\\mathsf{T}} \\mathbf{x}$ for some template $\\mathbf{w} \\in \\mathbb{R}^{n}$. The design goal is to maximize the decision Signal-to-Noise Ratio (SNR), defined as\n$$\nd'(\\mathbf{w}) \\equiv \\frac{\\mathbb{E}[T \\mid H_{1}] - \\mathbb{E}[T \\mid H_{0}]}{\\sqrt{\\operatorname{Var}[T \\mid H_{0}]}}.\n$$\n\nStarting from the foundational properties of linear transformations of multivariate Gaussian random vectors and the definitions of mean and covariance:\n\n- Derive expressions for $\\mathbb{E}[T \\mid H_{i}]$ and $\\operatorname{Var}[T \\mid H_{i}]$ in terms of $\\mathbf{w}$, $\\boldsymbol{\\mu}_{i}$, and $\\boldsymbol{\\Sigma}$.\n- Express $d'(\\mathbf{w})$ explicitly in terms of $\\mathbf{w}$, $\\boldsymbol{\\mu}_{0}$, $\\boldsymbol{\\mu}_{1}$, and $\\boldsymbol{\\Sigma}$.\n- Determine the template $\\mathbf{w}$ that maximizes $d'(\\mathbf{w})$ using first principles (e.g., constrained optimization) and provide its closed-form expression in terms of $\\boldsymbol{\\mu}_{0}$, $\\boldsymbol{\\mu}_{1}$, and $\\boldsymbol{\\Sigma}$.\n- For this optimal template, derive the distribution of $T$ under each hypothesis $H_{0}$ and $H_{1}$, specifying the mean and variance under each.\n- Finally, write the optimal detectability index $d'_\\star$ (the maximized value of $d'(\\mathbf{w})$) as a closed-form analytic expression in terms of $\\boldsymbol{\\mu}_{0}$, $\\boldsymbol{\\mu}_{1}$, and $\\boldsymbol{\\Sigma}$.\n\nYour submitted answer must be only the single final closed-form expression for $d'_\\star$, with no units, enclosed as required. Do not provide intermediate steps in the final answer box. No rounding is required; provide the exact expression.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It presents a standard task in statistical signal processing and pattern recognition, specifically the derivation of the optimal linear classifier for two classes with Gaussian distributions and equal covariance. All provided information is self-contained and consistent. Therefore, the problem is valid, and we may proceed with the solution.\n\nThe problem asks for a sequence of derivations related to a linear observer in a binary signal detection task. We will address each part in the order presented.\n\nFirst, we derive the expressions for the conditional expectation and variance of the test statistic $T = \\mathbf{w}^{\\mathsf{T}} \\mathbf{x}$. The feature vector $\\mathbf{x}$ is conditionally distributed as $\\mathbf{x} \\mid H_{i} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{i}, \\boldsymbol{\\Sigma})$ for $i \\in \\{0, 1\\}$.\n\nThe expectation $\\mathbb{E}[\\cdot]$ is a linear operator. For a constant vector $\\mathbf{w}$, the conditional expectation of $T$ is:\n$$\n\\mathbb{E}[T \\mid H_{i}] = \\mathbb{E}[\\mathbf{w}^{\\mathsf{T}} \\mathbf{x} \\mid H_{i}] = \\mathbf{w}^{\\mathsf{T}} \\mathbb{E}[\\mathbf{x} \\mid H_{i}]\n$$\nUsing the given mean $\\mathbb{E}[\\mathbf{x} \\mid H_{i}] = \\boldsymbol{\\mu}_{i}$, we find:\n$$\n\\mathbb{E}[T \\mid H_{i}] = \\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\mu}_{i}\n$$\n\nNext, we find the conditional variance. For a random vector $\\mathbf{y}$ with covariance matrix $\\operatorname{Cov}[\\mathbf{y}]$ and a constant matrix $\\mathbf{A}$, the covariance of the transformed vector $\\mathbf{A}\\mathbf{y}$ is $\\mathbf{A} \\operatorname{Cov}[\\mathbf{y}] \\mathbf{A}^{\\mathsf{T}}$. Here, $T$ is a scalar, so $\\mathbf{w}^{\\mathsf{T}}$ acts as the matrix $\\mathbf{A}$. The variance of $T$ is:\n$$\n\\operatorname{Var}[T \\mid H_{i}] = \\operatorname{Var}[\\mathbf{w}^{\\mathsf{T}} \\mathbf{x} \\mid H_{i}] = \\mathbf{w}^{\\mathsf{T}} \\operatorname{Cov}[\\mathbf{x} \\mid H_{i}] \\mathbf{w}\n$$\nUsing the given common covariance matrix $\\operatorname{Cov}[\\mathbf{x} \\mid H_{i}] = \\boldsymbol{\\Sigma}$, we have:\n$$\n\\operatorname{Var}[T \\mid H_{i}] = \\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}\n$$\nNote that the variance of $T$ is the same under both hypotheses, so we can write $\\operatorname{Var}[T] = \\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}$.\n\nNow, we express the decision Signal-to-Noise Ratio (SNR), $d'(\\mathbf{w})$, using these results. Substituting the derived expressions into the definition of $d'(\\mathbf{w})$:\n$$\nd'(\\mathbf{w}) = \\frac{\\mathbb{E}[T \\mid H_{1}] - \\mathbb{E}[T \\mid H_{0}]}{\\sqrt{\\operatorname{Var}[T \\mid H_{0}]}} = \\frac{\\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\mu}_{1} - \\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\mu}_{0}}{\\sqrt{\\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}}}\n$$\nUsing the linearity of the transpose operation, we combine the terms in the numerator:\n$$\nd'(\\mathbf{w}) = \\frac{\\mathbf{w}^{\\mathsf{T}} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})}{\\sqrt{\\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}}}\n$$\n\nThe next step is to find the template vector $\\mathbf{w}$ that maximizes $d'(\\mathbf{w})$. Let $\\Delta \\boldsymbol{\\mu} = \\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}$. The expression for the SNR becomes:\n$$\nd'(\\mathbf{w}) = \\frac{\\mathbf{w}^{\\mathsf{T}} \\Delta \\boldsymbol{\\mu}}{\\sqrt{\\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}}}\n$$\nSince $\\boldsymbol{\\Sigma}$ is symmetric and positive definite, there exists a symmetric positive definite square root matrix $\\boldsymbol{\\Sigma}^{1/2}$ such that $\\boldsymbol{\\Sigma} = \\boldsymbol{\\Sigma}^{1/2} \\boldsymbol{\\Sigma}^{1/2}$. Let's define new vectors $\\mathbf{u} = \\boldsymbol{\\Sigma}^{1/2} \\mathbf{w}$ and $\\mathbf{v} = \\boldsymbol{\\Sigma}^{-1/2} \\Delta \\boldsymbol{\\mu}$. Then $\\mathbf{w} = \\boldsymbol{\\Sigma}^{-1/2} \\mathbf{u}$. Substituting these into the expression for $d'(\\mathbf{w})$:\nThe numerator becomes: $\\mathbf{w}^{\\mathsf{T}} \\Delta \\boldsymbol{\\mu} = (\\boldsymbol{\\Sigma}^{-1/2} \\mathbf{u})^{\\mathsf{T}} (\\boldsymbol{\\Sigma}^{1/2} \\mathbf{v}) = \\mathbf{u}^{\\mathsf{T}} (\\boldsymbol{\\Sigma}^{-1/2})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{1/2} \\mathbf{v} = \\mathbf{u}^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1/2} \\boldsymbol{\\Sigma}^{1/2} \\mathbf{v} = \\mathbf{u}^{\\mathsf{T}} \\mathbf{v}$.\nThe term in the denominator becomes: $\\mathbf{w}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w} = (\\boldsymbol{\\Sigma}^{-1/2} \\mathbf{u})^{\\mathsf{T}} \\boldsymbol{\\Sigma} (\\boldsymbol{\\Sigma}^{-1/2} \\mathbf{u}) = \\mathbf{u}^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1/2} \\boldsymbol{\\Sigma} \\boldsymbol{\\Sigma}^{-1/2} \\mathbf{u} = \\mathbf{u}^{\\mathsf{T}} \\mathbf{u} = \\|\\mathbf{u}\\|_{2}^{2}$.\nSo, the SNR is transformed to:\n$$\nd'(\\mathbf{w}) = \\frac{\\mathbf{u}^{\\mathsf{T}} \\mathbf{v}}{\\sqrt{\\|\\mathbf{u}\\|_{2}^{2}}} = \\frac{\\mathbf{u}^{\\mathsf{T}} \\mathbf{v}}{\\|\\mathbf{u}\\|_{2}}\n$$\nBy the Cauchy-Schwarz inequality, $|\\mathbf{u}^{\\mathsf{T}} \\mathbf{v}| \\le \\|\\mathbf{u}\\|_{2} \\|\\mathbf{v}\\|_{2}$. Therefore,\n$$\n|d'(\\mathbf{w})| \\le \\frac{\\|\\mathbf{u}\\|_{2} \\|\\mathbf{v}\\|_{2}}{\\|\\mathbf{u}\\|_{2}} = \\|\\mathbf{v}\\|_{2}\n$$\nThe maximum value of $d'(\\mathbf{w})$ is achieved when the equality in the Cauchy-Schwarz inequality holds, which occurs when the vector $\\mathbf{u}$ is collinear with $\\mathbf{v}$, i.e., $\\mathbf{u} = c\\mathbf{v}$ for some scalar $c > 0$.\nSubstituting back for $\\mathbf{w}$, $\\Delta \\boldsymbol{\\mu}$, and $\\boldsymbol{\\Sigma}$:\n$$\n\\boldsymbol{\\Sigma}^{1/2} \\mathbf{w}_{\\star} = c (\\boldsymbol{\\Sigma}^{-1/2} \\Delta \\boldsymbol{\\mu})\n$$\n$$\n\\mathbf{w}_{\\star} = c \\boldsymbol{\\Sigma}^{-1/2} \\boldsymbol{\\Sigma}^{-1/2} \\Delta \\boldsymbol{\\mu} = c \\boldsymbol{\\Sigma}^{-1} \\Delta \\boldsymbol{\\mu}\n$$\nThe magnitude of $\\mathbf{w}$ is irrelevant for the value of $d'(\\mathbf{w})$ (it is invariant to scaling of $\\mathbf{w}$ by a positive constant). Thus, we can choose $c=1$. The optimal template, often called the prewhitening matched filter, is:\n$$\n\\mathbf{w}_{\\star} = \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})\n$$\n\nNow, we determine the distribution of $T$ under each hypothesis for this optimal template $\\mathbf{w}_{\\star}$. Since $\\mathbf{x}$ is a multivariate Gaussian random vector, any linear transformation of it, such as $T = \\mathbf{w}_{\\star}^{\\mathsf{T}} \\mathbf{x}$, is a univariate Gaussian random variable. Its distribution is fully characterized by its mean and variance.\nThe mean under hypothesis $H_{i}$ is:\n$$\n\\mathbb{E}[T \\mid H_{i}] = \\mathbf{w}_{\\star}^{\\mathsf{T}} \\boldsymbol{\\mu}_{i} = (\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}))^{\\mathsf{T}} \\boldsymbol{\\mu}_{i} = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_{i} \\quad (\\text{since } \\boldsymbol{\\Sigma}^{-1} \\text{ is symmetric})\n$$\nThe variance is common to both hypotheses and is given by:\n$$\n\\operatorname{Var}[T] = \\mathbf{w}_{\\star}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}_{\\star} = (\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}))^{\\mathsf{T}} \\boldsymbol{\\Sigma} (\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}))\n$$\n$$\n\\operatorname{Var}[T] = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\Sigma} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}) = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})\n$$\nTherefore, the distributions are:\n$T \\mid H_{0} \\sim \\mathcal{N}\\left( (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_{0}, (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}) \\right)$\n$T \\mid H_{1} \\sim \\mathcal{N}\\left( (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} \\boldsymbol{\\mu}_{1}, (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}) \\right)$\n\nFinally, we derive the optimal detectability index, $d'_\\star$, which is the value of $d'(\\mathbf{w})$ at $\\mathbf{w} = \\mathbf{w}_{\\star}$.\n$$\nd'_\\star = d'(\\mathbf{w}_{\\star}) = \\frac{\\mathbf{w}_{\\star}^{\\mathsf{T}} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})}{\\sqrt{\\mathbf{w}_{\\star}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}_{\\star}}}\n$$\nThe numerator is:\n$$\n\\mathbf{w}_{\\star}^{\\mathsf{T}} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}) = (\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0}))^{\\mathsf{T}} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0}) = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})\n$$\nThe term under the square root in the denominator is:\n$$\n\\mathbf{w}_{\\star}^{\\mathsf{T}} \\boldsymbol{\\Sigma} \\mathbf{w}_{\\star} = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})\n$$\nThis is the same expression as the numerator. Let this scalar quantity be $M^{2} = (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})$. This quantity is the square of the Mahalanobis distance between $\\boldsymbol{\\mu}_{1}$ and $\\boldsymbol{\\mu}_{0}$. Since $\\boldsymbol{\\Sigma}^{-1}$ is positive definite, $M^{2} \\ge 0$.\nSubstituting this into the expression for $d'_\\star$:\n$$\nd'_\\star = \\frac{M^2}{\\sqrt{M^2}} = \\frac{M^2}{|M|}\n$$\nAssuming $\\boldsymbol{\\mu}_{1} \\neq \\boldsymbol{\\mu}_{0}$, $M > 0$, so $d'_\\star = M$.\nTherefore, the optimal detectability index is:\n$$\nd'_\\star = \\sqrt{(\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1}-\\boldsymbol{\\mu}_{0})}\n$$\nThis is the final closed-form analytic expression required.",
            "answer": "$$\n\\boxed{\\sqrt{(\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})^{\\mathsf{T}} \\boldsymbol{\\Sigma}^{-1} (\\boldsymbol{\\mu}_{1} - \\boldsymbol{\\mu}_{0})}}\n$$"
        },
        {
            "introduction": "Once a classifier is built, we must rigorously evaluate its performance to understand its strengths and weaknesses. This practice delves into the critical choice between two common evaluation tools: the Receiver Operating Characteristic (ROC) curve and the Precision-Recall (PR) curve. You will derive the mathematical relationship between them and discover why PR curves are often more informative and practical in realistic medical scenarios where the prevalence of disease, $\\pi$, is low.",
            "id": "4871532",
            "problem": "A Computer-Aided Detection (CAD) system is evaluated on a large medical imaging dataset where the positive class (pathology present) is rare. Let $Y \\in \\{0,1\\}$ denote the ground-truth class, with $Y=1$ indicating pathology and $Y=0$ indicating normal. The classifier outputs a binary decision $\\hat{Y} \\in \\{0,1\\}$ for a fixed threshold. Define the Receiver Operating Characteristic (ROC) operating point by the true positive rate $TPR = P(\\hat{Y}=1 \\mid Y=1)$ and the false positive rate $FPR = P(\\hat{Y}=1 \\mid Y=0)$. Let the prevalence be $\\pi = P(Y=1)$, which is fixed and known. Precision-Recall (PR) coordinates are given by precision $PPV = P(Y=1 \\mid \\hat{Y}=1)$ and recall $R = P(\\hat{Y}=1 \\mid Y=1)$.\n\nStarting from the fundamental definitions of conditional probability and Bayes’ rule, and without invoking any pre-derived mapping formula, derive the functional relationship that maps a ROC operating point $(TPR, FPR)$ to the corresponding PR coordinates $(PPV, R)$ when the prevalence $\\pi$ is fixed. In your derivation, explicitly express $PPV$ solely in terms of $TPR$, $FPR$, and $\\pi$, and identify $R$ in terms of $TPR$.\n\nAdditionally, explain, using these probability definitions, how severe class imbalance (small $\\pi$) affects the interpretation of ROC curves relative to precision-recall curves, and why PR curves are more sensitive to $\\pi$ than ROC curves.\n\nExpress your final mapping as a single row matrix of the form $\\begin{pmatrix} PPV & R \\end{pmatrix}$ in terms of $TPR$, $FPR$, and $\\pi$. No numerical evaluation is required.",
            "solution": "The problem is valid as it is scientifically grounded in the principles of probability theory and classifier evaluation, is well-posed with all necessary definitions provided, and is stated in objective, formal language. The task is to derive a standard, verifiable mathematical relationship and provide a conceptual explanation based on it.\n\nThe problem asks for two main components: first, to derive the functional relationship that maps Receiver Operating Characteristic (ROC) coordinates to Precision-Recall (PR) coordinates, and second, to explain the impact of class imbalance on these two types of curves.\n\nLet's begin by stating the given definitions:\n-   Prevalence: $\\pi = P(Y=1)$. It follows that $P(Y=0) = 1 - \\pi$.\n-   True Positive Rate (TPR): $TPR = P(\\hat{Y}=1 \\mid Y=1)$. This is also known as sensitivity or recall.\n-   False Positive Rate (FPR): $FPR = P(\\hat{Y}=1 \\mid Y=0)$.\n-   Precision (PPV): $PPV = P(Y=1 \\mid \\hat{Y}=1)$, also known as Positive Predictive Value.\n-   Recall (R): $R = P(\\hat{Y}=1 \\mid Y=1)$.\n\nThe mapping is from the ROC point $(TPR, FPR)$ to the PR point $(PPV, R)$, given a fixed prevalence $\\pi$.\n\nFirst, let us establish the relationship for Recall, $R$. By its definition, $R = P(\\hat{Y}=1 \\mid Y=1)$. This is identical to the definition of the True Positive Rate, $TPR$.\nTherefore, the recall component of the PR point is simply equal to the true positive rate component of the ROC point:\n$$R = TPR$$\n\nNext, we derive the expression for Precision, $PPV$. The definition is $PPV = P(Y=1 \\mid \\hat{Y}=1)$. This is a posterior probability. To express it in terms of the given quantities, which include likelihoods ($TPR$, $FPR$) and a prior probability ($\\pi$), we must use Bayes' rule.\nBayes' rule states that for two events $A$ and $B$:\n$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{P(B)}$$\nWe set $A$ to be the event $Y=1$ (pathology is present) and $B$ to be the event $\\hat{Y}=1$ (the classifier predicts pathology). Substituting these into Bayes' rule gives:\n$$PPV = P(Y=1 \\mid \\hat{Y}=1) = \\frac{P(\\hat{Y}=1 \\mid Y=1) P(Y=1)}{P(\\hat{Y}=1)}$$\nWe can substitute the known definitions into the numerator:\n-   $P(\\hat{Y}=1 \\mid Y=1) = TPR$\n-   $P(Y=1) = \\pi$\nSo the expression becomes:\n$$PPV = \\frac{TPR \\cdot \\pi}{P(\\hat{Y}=1)}$$\nNow, we must find an expression for the denominator, $P(\\hat{Y}=1)$, which is the marginal probability of a positive prediction. We can expand this term using the law of total probability, conditioning on the true class $Y$:\n$$P(\\hat{Y}=1) = P(\\hat{Y}=1 \\mid Y=1)P(Y=1) + P(\\hat{Y}=1 \\mid Y=0)P(Y=0)$$\nAgain, we substitute the known quantities into this expansion:\n-   $P(\\hat{Y}=1 \\mid Y=1) = TPR$\n-   $P(Y=1) = \\pi$\n-   $P(\\hat{Y}=1 \\mid Y=0) = FPR$\n-   $P(Y=0) = 1 - P(Y=1) = 1 - \\pi$\nSubstituting these gives the full expression for the denominator:\n$$P(\\hat{Y}=1) = (TPR \\cdot \\pi) + (FPR \\cdot (1 - \\pi))$$\nFinally, by substituting this expression for $P(\\hat{Y}=1)$ back into our equation for $PPV$, we obtain the complete relationship for precision:\n$$PPV = \\frac{TPR \\cdot \\pi}{TPR \\cdot \\pi + FPR \\cdot (1 - \\pi)}$$\nThis equation expresses $PPV$ solely in terms of $TPR$, $FPR$, and $\\pi$, as required.\nCombining the results, the mapping from a ROC point $(TPR, FPR)$ to a PR point $(PPV, R)$ is:\n$$(PPV, R) = \\left( \\frac{TPR \\cdot \\pi}{TPR \\cdot \\pi + FPR \\cdot (1 - \\pi)}, TPR \\right)$$\n\nNow, for the second part of the problem, we explain the effect of severe class imbalance (small $\\pi$) on the interpretation of ROC versus PR curves.\n\nThe coordinates of the ROC curve, $(FPR, TPR)$, are defined as $P(\\hat{Y}=1 \\mid Y=0)$ and $P(\\hat{Y}=1 \\mid Y=1)$, respectively. These probabilities are conditioned on the true class. They measure the classifier's performance independently within the negative class population and the positive class population. Consequently, the prevalence $\\pi = P(Y=1)$ does not appear in their definitions. An ROC curve is therefore invariant to the class prevalence. It represents a fundamental property of the classifier's ability to discriminate between the two classes, regardless of how rare one class is.\n\nIn contrast, the PR curve has coordinates $(R, PPV)$. While $R = TPR$ is independent of prevalence, the precision, $PPV$, is highly dependent on $\\pi$, as shown by the derived formula:\n$$PPV = \\frac{TPR \\cdot \\pi}{TPR \\cdot \\pi + FPR \\cdot (1 - \\pi)}$$\nLet's analyze this relationship under severe class imbalance, where $\\pi$ is very small ($\\pi \\to 0$). In this case, $(1 - \\pi) \\to 1$. The term $TPR \\cdot \\pi$ in the denominator becomes negligible compared to $FPR \\cdot (1 - \\pi)$, especially for a reasonably good classifier where $FPR$ is not zero. The expression simplifies to:\n$$PPV \\approx \\frac{TPR \\cdot \\pi}{FPR}$$\nThis approximation demonstrates that even for a classifier with excellent ROC characteristics (high $TPR$, very low $FPR$), the precision will be very low if the prevalence $\\pi$ is also very low. For example, if $TPR = 0.95$, $FPR = 0.01$, and $\\pi = 0.001$, the $PPV$ would be approximately $PPV \\approx (0.95 \\cdot 0.001) / 0.01 = 0.095$. This means that despite the classifier's high true positive rate and low false positive rate, over $90\\%$ of its positive predictions would be incorrect.\n\nThis sensitivity makes PR curves more informative than ROC curves in settings with significant class imbalance, such as medical screening for rare diseases. An ROC curve might look impressively close to the top-left corner, suggesting excellent performance. However, the corresponding PR curve for a low-prevalence scenario would reveal the practical reality that the positive predictive value is poor, which is a critical piece of information for clinical application. The PR curve directly visualizes the impact of prevalence on performance, whereas the ROC curve obfuscates it.\n\nThe final mapping from $(TPR, FPR)$ to $(PPV, R)$ is thus fully derived and its implications for imbalanced data are explained.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{TPR \\cdot \\pi}{TPR \\cdot \\pi + FPR \\cdot (1-\\pi)} & TPR\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A CAD system's output, often a probability, must be translated into a practical clinical decision, like whether to alert a radiologist. This final exercise demonstrates how to set an optimal decision threshold by balancing the specific costs of different types of errors—a false positive ($c_{\\mathrm{FP}}$) versus a false negative ($c_{\\mathrm{FN}}$). This practice bridges the gap from model prediction to real-world utility, a crucial step in deploying any diagnostic tool responsibly and effectively.",
            "id": "4871526",
            "problem": "A hospital deploys a Computer-Aided Detection and Diagnosis system (CADx) for triaging pulmonary nodules on low-dose computed tomography. For each candidate nodule, the CADx model outputs a calibrated posterior probability $p$ of malignancy, where calibration means $p$ equals the true conditional probability $\\mathbb{P}(Y=1 \\mid \\text{features})$. The triage policy is a threshold rule: raise an alert to the radiologist if $p \\geq t$, otherwise do not alert.\n\nTo formalize decision quality, define a single-case utility function where correct decisions have baseline utility $0$, a false positive incurs utility $-c_{\\mathrm{FP}}$, and a false negative incurs utility $-c_{\\mathrm{FN}}$. Suppose the hospital’s health economics analysis yields $c_{\\mathrm{FP}}=3$ and $c_{\\mathrm{FN}}=57$ in comparable utility-loss units.\n\nUsing the principles of expected utility maximization for a single case under a calibrated probability model, derive the threshold $t^{\\ast}$ that maximizes expected utility and provide its value. Express your final threshold $t^{\\ast}$ as a single exact number (a decimal or a fraction). If you choose a decimal representation, round your answer to four significant figures.",
            "solution": "The problem asks for the optimal decision threshold $t^{\\ast}$ for a Computer-Aided Detection and Diagnosis (CADx) system that maximizes expected utility. The system provides a calibrated posterior probability $p$ of malignancy for a given case. The decision is to either raise an alert or not, based on whether $p$ is greater than or equal to a threshold $t$.\n\nLet us formalize the decision problem. For any given case, there are two possible true states of nature, denoted by the random variable $Y$:\n1.  The nodule is malignant ($Y=1$).\n2.  The nodule is benign ($Y=0$).\n\nThe CADx system provides the calibrated posterior probability $p$ of malignancy, where calibration means $p = \\mathbb{P}(Y=1 \\mid \\text{features})$. Consequently, the probability of the nodule being benign is $\\mathbb{P}(Y=0 \\mid \\text{features}) = 1-p$.\n\nThere are two possible actions, $A$, that can be taken based on the value of $p$:\n1.  $A_{\\text{alert}}$: Raise an alert to the radiologist. This corresponds to a positive diagnosis.\n2.  $A_{\\text{no alert}}$: Do not raise an alert. This corresponds to a negative diagnosis.\n\nThe decision rule is defined by a threshold $t$:\n- If $p \\geq t$, take action $A_{\\text{alert}}$.\n- If $p < t$, take action $A_{\\text{no alert}}$.\n\nThe utility of a decision depends on the action taken and the true state of nature. The problem defines a utility function where correct decisions have a baseline utility of $0$, and incorrect decisions incur a utility loss (a negative utility). Let's define the utility $U(A, Y)$ for each of the four possible outcomes:\n\n1.  **True Positive (TP)**: $A=A_{\\text{alert}}$ and $Y=1$. Correct decision. $U(A_{\\text{alert}}, Y=1) = 0$.\n2.  **True Negative (TN)**: $A=A_{\\text{no alert}}$ and $Y=0$. Correct decision. $U(A_{\\text{no alert}}, Y=0) = 0$.\n3.  **False Positive (FP)**: $A=A_{\\text{alert}}$ and $Y=0$. Incorrect decision. $U(A_{\\text{alert}}, Y=0) = -c_{\\mathrm{FP}}$.\n4.  **False Negative (FN)**: $A=A_{\\text{no alert}}$ and $Y=1$. Incorrect decision. $U(A_{\\text{no alert}}, Y=1) = -c_{\\mathrm{FN}}$.\n\nThe principle of maximizing expected utility dictates that for a given case with probability $p$, we should choose the action that has the higher expected utility. The expected utility of each action, $\\mathbb{E}[U(A)]$, is calculated by averaging the utilities of its possible outcomes, weighted by their probabilities.\n\nThe expected utility of taking action $A_{\\text{alert}}$ is:\n$$\n\\mathbb{E}[U(A_{\\text{alert}})] = U(A_{\\text{alert}}, Y=1) \\cdot \\mathbb{P}(Y=1) + U(A_{\\text{alert}}, Y=0) \\cdot \\mathbb{P}(Y=0)\n$$\nSubstituting the utilities and probabilities:\n$$\n\\mathbb{E}[U(A_{\\text{alert}})] = (0) \\cdot p + (-c_{\\mathrm{FP}}) \\cdot (1-p) = -c_{\\mathrm{FP}}(1-p)\n$$\n\nThe expected utility of taking action $A_{\\text{no alert}}$ is:\n$$\n\\mathbb{E}[U(A_{\\text{no alert}})] = U(A_{\\text{no alert}}, Y=1) \\cdot \\mathbb{P}(Y=1) + U(A_{\\text{no alert}}, Y=0) \\cdot \\mathbb{P}(Y=0)\n$$\nSubstituting the utilities and probabilities:\n$$\n\\mathbb{E}[U(A_{\\text{no alert}})] = (-c_{\\mathrm{FN}}) \\cdot p + (0) \\cdot (1-p) = -c_{\\mathrm{FN}}p\n$$\n\nTo maximize expected utility, we should choose to alert if $\\mathbb{E}[U(A_{\\text{alert}})] \\geq \\mathbb{E}[U(A_{\\text{no alert}})]$. This sets the condition on $p$ for triggering an alert:\n$$\n-c_{\\mathrm{FP}}(1-p) \\geq -c_{\\mathrm{FN}}p\n$$\nMultiplying both sides by $-1$ reverses the inequality sign:\n$$\nc_{\\mathrm{FP}}(1-p) \\leq c_{\\mathrm{FN}}p\n$$\nExpanding the left side:\n$$\nc_{\\mathrm{FP}} - c_{\\mathrm{FP}}p \\leq c_{\\mathrm{FN}}p\n$$\nRearranging the terms to solve for $p$:\n$$\nc_{\\mathrm{FP}} \\leq c_{\\mathrm{FN}}p + c_{\\mathrm{FP}}p\n$$\n$$\nc_{\\mathrm{FP}} \\leq (c_{\\mathrm{FP}} + c_{\\mathrm{FN}})p\n$$\n$$\np \\geq \\frac{c_{\\mathrm{FP}}}{c_{\\mathrm{FP}} + c_{\\mathrm{FN}}}\n$$\nThis inequality defines the optimal decision rule. An alert should be raised if the probability of malignancy $p$ is greater than or equal to the ratio $\\frac{c_{\\mathrm{FP}}}{c_{\\mathrm{FP}} + c_{\\mathrm{FN}}}$. The optimal threshold $t^{\\ast}$ is the value at which the decision changes, which is the boundary of this condition.\n$$\nt^{\\ast} = \\frac{c_{\\mathrm{FP}}}{c_{\\mathrm{FP}} + c_{\\mathrm{FN}}}\n$$\nThe problem provides the numerical values for the utility-loss constants: $c_{\\mathrm{FP}}=3$ and $c_{\\mathrm{FN}}=57$. Substituting these values into the expression for $t^{\\ast}$:\n$$\nt^{\\ast} = \\frac{3}{3 + 57} = \\frac{3}{60}\n$$\nSimplifying the fraction gives:\n$$\nt^{\\ast} = \\frac{1}{20}\n$$\nExpressed as a decimal, this is:\n$$\nt^{\\ast} = 0.05\n$$\nThis value represents the optimal threshold for the triage policy. If the CADx model outputs a probability $p \\geq 0.05$, the expected utility is maximized by raising an alert. If $p < 0.05$, the expected utility is maximized by not raising an alert. The value $0.05$ is an exact numerical answer.",
            "answer": "$$\\boxed{0.05}$$"
        }
    ]
}