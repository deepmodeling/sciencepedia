{
    "hands_on_practices": [
        {
            "introduction": "A common task in clinical medicine is interpreting the result of a diagnostic test. This exercise guides you through the fundamental calculations that allow us to update our belief about a patient's disease status after a test result is known. Mastering these calculations, such as likelihood ratios and post-test probabilities, is crucial for building and understanding clinical decision support systems that provide diagnostic aid. ",
            "id": "4839022",
            "problem": "A hospital is implementing a Clinical Decision Support (CDS) module grounded in Evidence-Based Medicine (EBM). The module encodes binary diagnostic test performance and uses the odds-likelihood form of Bayes’ theorem to update disease probability after a positive test. You are tasked with configuring a calculation routine for a test whose sensitivity is $0.90$, specificity is $0.95$, and disease prevalence in the target population is $0.02$. Starting from the core definitions of sensitivity, specificity, pre-test odds, likelihood ratios, and the probability–odds relationship, derive the general expressions for the positive likelihood ratio $LR^{+}$, the negative likelihood ratio $LR^{-}$, the post-test odds after a positive result, and the corresponding post-test probability. Then evaluate these quantities for the given values. Finally, a treatment threshold of $0.10$ is configured in the CDS module: encode the clinical decision as an indicator $d$ defined by $d=1$ if the post-test probability for a positive result is greater than or equal to $0.10$, and $d=0$ otherwise.\n\nExpress probabilities as decimals or fractions (do not use the percentage sign). Provide exact fractional forms where possible. If you choose to report a repeating decimal approximation for any non-terminating quantity, round to four significant figures. Report your final results as a single row matrix with entries, in order: $LR^{+}$, $LR^{-}$, post-test odds for a positive result, post-test probability for a positive result, and the decision indicator $d$.",
            "solution": "The problem requires the derivation and calculation of several key metrics used in Evidence-Based Medicine (EBM) and their application in a Clinical Decision Support (CDS) context. We will proceed by first deriving the general formulas from foundational principles and then substituting the given values to find the numerical results.\n\nLet $D$ be the event that a patient has the disease and $D^c$ be the event that the patient does not have the disease. Let $T^+$ be the event of a positive test result and $T^-$ be the event of a negative test result.\n\nThe given quantities are:\n- Sensitivity ($Se$): The probability of a positive test given disease, $Se = P(T^+ | D) = 0.90$.\n- Specificity ($Sp$): The probability of a negative test given no disease, $Sp = P(T^- | D^c) = 0.95$.\n- Prevalence (pre-test probability), $p = P(D) = 0.02$.\n\nFrom these, we can state other useful probabilities:\n- The probability of a false positive is $P(T^+ | D^c) = 1 - P(T^- | D^c) = 1 - Sp$.\n- The probability of a false negative is $P(T^- | D) = 1 - P(T^+ | D) = 1 - Se$.\n- The pre-test probability of not having the disease is $P(D^c) = 1 - P(D) = 1 - p$.\n\n**1. Derivation of General Expressions**\n\n**Positive Likelihood Ratio ($LR^{+}$)**\nThe positive likelihood ratio is the ratio of the probability of a positive test in a diseased individual to the probability of a positive test in a non-diseased individual.\n$$LR^+ = \\frac{P(T^+ | D)}{P(T^+ | D^c)}$$\nSubstituting the definitions of sensitivity and specificity, we get:\n$$LR^+ = \\frac{Se}{1 - Sp}$$\n\n**Negative Likelihood Ratio ($LR^{-}$)**\nThe negative likelihood ratio is the ratio of the probability of a negative test in a diseased individual to the probability of a negative test in a non-diseased individual.\n$$LR^- = \\frac{P(T^- | D)}{P(T^- | D^c)}$$\nSubstituting the definitions, we get:\n$$LR^- = \\frac{1 - Se}{Sp}$$\n\n**Pre-test Odds and Post-test Odds**\nOdds are defined as the ratio of the probability of an event occurring to the probability of it not occurring. The pre-test odds of disease are:\n$$PreTestOdds = \\frac{P(D)}{P(D^c)} = \\frac{p}{1 - p}$$\nThe odds-likelihood form of Bayes' theorem states that post-test odds are the product of pre-test odds and the relevant likelihood ratio. For a positive test result, the post-test odds are:\n$$PostTestOdds(+) = PreTestOdds \\times LR^+$$\nSubstituting the expressions for pre-test odds and $LR^+$:\n$$PostTestOdds(+) = \\left(\\frac{p}{1 - p}\\right) \\times \\left(\\frac{Se}{1 - Sp}\\right)$$\n\n**Post-test Probability**\nThe relationship between a probability $P$ and its corresponding odds $O$ is given by $P = \\frac{O}{1 + O}$. Therefore, the post-test probability of disease after a positive test, $P_{post}(+) = P(D|T^+)$, is:\n$$P_{post}(+) = \\frac{PostTestOdds(+)}{1 + PostTestOdds(+)}$$\n\n**2. Evaluation for Given Values**\n\nWe are given $Se = 0.90$, $Sp = 0.95$, and $p = 0.02$.\n\n**Calculation of $LR^{+}$:**\n$$LR^+ = \\frac{Se}{1 - Sp} = \\frac{0.90}{1 - 0.95} = \\frac{0.90}{0.05} = 18$$\n\n**Calculation of $LR^{-}$:**\n$$LR^- = \\frac{1 - Se}{Sp} = \\frac{1 - 0.90}{0.95} = \\frac{0.10}{0.95} = \\frac{10}{95} = \\frac{2}{19}$$\n\n**Calculation of Post-test Odds for a Positive Result:**\nFirst, we calculate the pre-test odds:\n$$PreTestOdds = \\frac{p}{1 - p} = \\frac{0.02}{1 - 0.02} = \\frac{0.02}{0.98} = \\frac{2}{98} = \\frac{1}{49}$$\nNow we calculate the post-test odds using the $LR^+$:\n$$PostTestOdds(+) = PreTestOdds \\times LR^+ = \\frac{1}{49} \\times 18 = \\frac{18}{49}$$\n\n**Calculation of Post-test Probability for a Positive Result:**\nUsing the post-test odds, we find the post-test probability:\n$$P_{post}(+) = \\frac{PostTestOdds(+)}{1 + PostTestOdds(+)} = \\frac{\\frac{18}{49}}{1 + \\frac{18}{49}} = \\frac{\\frac{18}{49}}{\\frac{49}{49} + \\frac{18}{49}} = \\frac{\\frac{18}{49}}{\\frac{67}{49}} = \\frac{18}{67}$$\n\n**3. Determination of the Decision Indicator $d$**\n\nThe decision indicator $d$ is determined by comparing the post-test probability, $P_{post}(+)$, to the treatment threshold of $0.10$. The rule is: $d=1$ if $P_{post}(+) \\ge 0.10$, and $d=0$ otherwise.\nWe must compare our result, $\\frac{18}{67}$, with the threshold, $0.10 = \\frac{1}{10}$.\nTo compare the fractions $\\frac{18}{67}$ and $\\frac{1}{10}$, we can cross-multiply:\n$$18 \\times 10 = 180$$\n$$67 \\times 1 = 67$$\nSince $180 > 67$, it follows that $\\frac{18}{67} > \\frac{1}{10}$.\nThe post-test probability of disease is approximately $0.2687$, which is greater than the threshold of $0.10$.\nTherefore, the decision indicator is $d=1$.\n\nThe final results to be reported are, in order: $LR^{+}$, $LR^{-}$, post-test odds for a positive result, post-test probability for a positive result, and the decision indicator $d$.\n- $LR^{+} = 18$\n- $LR^{-} = \\frac{2}{19}$\n- $PostTestOdds(+) = \\frac{18}{49}$\n- $P_{post}(+) = \\frac{18}{67}$\n- $d = 1$",
            "answer": "$$\\boxed{\\begin{pmatrix} 18 & \\frac{2}{19} & \\frac{18}{49} & \\frac{18}{67} & 1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "Moving from individual diagnosis to population-level evidence, this practice focuses on quantifying the effect of a treatment or exposure from a cohort study. You will calculate essential metrics like the risk ratio, risk difference, and the number needed to treat ($NNT$), which are the building blocks for making evidence-based recommendations. These measures help translate study findings into clinically meaningful statements about an intervention's impact. ",
            "id": "4839021",
            "problem": "A learning health system deploys a Clinical Decision Support (CDS) module to summarize effect measures for cohort studies under Evidence-Based Medicine (EBM) principles. Consider a hypothetical observational cohort comparing an exposure (for example, a new care pathway intended to increase the probability of a beneficial outcome) versus no exposure. In the exposed group, there are $2000$ individuals with $120$ observed beneficial outcome events over a fixed follow-up period. In the unexposed group, there are $3000$ individuals with $90$ observed beneficial outcome events over the same period.\n\nStarting from core definitions in epidemiology and Evidence-Based Medicine, and without assuming any pre-derived formulas, derive and compute the following effect measures:\n\n1. The risk ratio comparing exposed to unexposed.\n2. The risk difference comparing exposed to unexposed.\n3. The number needed to treat, defined for a beneficial outcome in terms of the absolute effect on risk.\n\nUse only the counts provided and fundamental definitions of risk and effect measures to produce the numerical values. Round your answers to four significant figures and express all values as dimensionless decimals (no units). In one or two sentences, explain how these metrics could guide clinical decision-making in a CDS context, focusing on whether the exposure is likely to be beneficial and the magnitude of its effect.",
            "solution": "The problem asks for the derivation and computation of three key effect measures from a hypothetical cohort study, framed within the context of Evidence-Based Medicine (EBM) and a Clinical Decision Support (CDS) system. The core principle for this analysis is the definition of risk, also known as cumulative incidence, within a population over a fixed time period.\n\nRisk ($R$) is defined as the proportion of a population, initially free of an outcome, that develops the outcome over a specified time interval. It is calculated as the number of new cases ($A$) divided by the number of individuals at risk at the beginning of the period ($N$).\n$$R = \\frac{A}{N}$$\n\nWe are given the following data for two groups: an exposed group and an unexposed group.\nFor the exposed group:\n- The total number of individuals is $N_E = 2000$.\n- The number of observed beneficial outcome events is $A_E = 120$.\n\nFor the unexposed group:\n- The total number of individuals is $N_U = 3000$.\n- The number of observed beneficial outcome events is $A_U = 90$.\n\nFirst, we calculate the risk of the beneficial outcome for each group using the fundamental definition.\nThe risk in the exposed group, $R_E$, is:\n$$R_E = \\frac{A_E}{N_E} = \\frac{120}{2000} = 0.06$$\nThe risk in the unexposed group, $R_U$, is:\n$$R_U = \\frac{A_U}{N_U} = \\frac{90}{3000} = 0.03$$\nThese risk values represent the probability of experiencing the beneficial outcome in each group over the fixed follow-up period.\n\nWith these fundamental quantities, we can now derive and compute the requested effect measures.\n\n1.  **Risk Ratio (RR)**\nThe risk ratio is a relative measure of effect. It quantifies how many times more likely the outcome is in the exposed group compared to the unexposed group. It is defined as the ratio of the risk in the exposed group to the risk in the unexposed group.\n$$RR = \\frac{R_E}{R_U}$$\nSubstituting the calculated risk values:\n$$RR = \\frac{0.06}{0.03} = 2$$\nThe data provided are exact counts, so this result is exact. To express this value with four significant figures as requested, we write $2.000$. An RR greater than $1$ indicates an increased risk of the outcome in the exposed group. Since the outcome is beneficial, this suggests a positive effect of the exposure.\n\n2.  **Risk Difference (RD)**\nThe risk difference, also known as the absolute risk increase or absolute risk reduction, is an absolute measure of effect. It represents the simple difference in risk between the two groups.\n$$RD = R_E - R_U$$\nSubstituting the calculated risk values:\n$$RD = 0.06 - 0.03 = 0.03$$\nThis value is also exact. Expressed to four significant figures, it is $0.03000$. A positive $RD$ indicates that the absolute risk of the outcome is higher in the exposed group. In this case, there is a $3$ percentage point increase in the probability of the beneficial outcome attributable to the exposure.\n\n3.  **Number Needed to Treat (NNT)**\nThe number needed to treat is a measure of clinical effort. It is defined as the number of patients who must receive an intervention for one additional person to experience a particular outcome compared to a control group. For a beneficial outcome, where the goal is to increase its occurrence, the NNT is the reciprocal of the absolute risk increase (the risk difference, $RD$, when $RD > 0$).\n$$NNT = \\frac{1}{RD}$$\nUsing the calculated risk difference:\n$$NNT = \\frac{1}{0.03} = \\frac{100}{3} \\approx 33.333...$$\nRounding this value to four significant figures gives $33.33$. This means that, on average, $33.33$ individuals must be subjected to the exposure (the new care pathway) for one additional beneficial outcome to occur.\n\nIn a CDS context, these metrics provide a concise, multi-faceted summary of the exposure's effect to inform clinical practice. The risk ratio ($2.000$) shows the exposure doubles the chance of a good outcome, while the risk difference ($0.03000$) and number needed to treat ($33.33$) frame this as a $3\\%$ absolute gain in benefit and the need to treat approximately $33$ patients for one extra successful outcome, respectively, thereby guiding the clinician's decision on the magnitude and practical implications of the intervention's effect.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.000 & 0.03000 & 33.33\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "This final practice integrates principles of evidence-based practice into a realistic medical informatics challenge: building and evaluating a computable phenotype. You will translate a clinical definition of heart failure into a precise algorithm using structured data, and then measure its performance using standard metrics like precision and recall. This task exemplifies how EBM rules are operationalized at scale within a learning health system to identify patient populations for research, quality improvement, or clinical care. ",
            "id": "4839044",
            "problem": "You are to design and evaluate a computable phenotype for heart failure, consistent with Evidence-Based Medicine (EBM) principles, using only structured data elements. The phenotype must operationalize a case definition using three independent data sources that are routinely available in clinical data warehouses:\n- International Classification of Diseases, Tenth Revision (ICD-10) diagnostic codes.\n- Medication dispensing or administration records grouped into classes consistent with guideline-directed therapy.\n- Echocardiogram findings quantified by Left Ventricular Ejection Fraction (LVEF).\n\nYou must compute predicted labels and evaluate them against a chart-reviewed reference standard. Your program must implement the following components and evaluation protocol precisely and deterministically.\n\nDefinitions and phenotype logic:\n- International Classification of Diseases, Tenth Revision (ICD-10) heart failure codes: any code whose string begins with the prefix I50 (e.g., I50.1, I50.9) is considered a heart failure code.\n- Settings for ICD-10 codes: each diagnostic code occurrence is associated with either the string \"inpatient\" or \"outpatient\" and a calendar day represented as an integer day index.\n- Medication classes: medication events are represented as tuples of a medication class string and an integer day index. The permitted medication classes are the strings \"loop_diuretic\", \"ace_arb_arni\", and \"beta_blocker\".\n- Echocardiogram: an echocardiogram summary is represented by a single LVEF value as a real number in $[0,1]$, or the special value None (no echocardiogram).\n\nComputable phenotype positive label rule: assign a predicted positive heart failure label to a patient if and only if at least one of the following independent criteria is satisfied:\n- Criterion A (ICD-10 rule): at least one inpatient ICD-10 heart failure code, or at least two outpatient ICD-10 heart failure codes on distinct dates.\n- Criterion B (Echocardiogram rule): an LVEF value that is less than or equal to $0.40$.\n- Criterion C (Medication pattern rule): there exists at least one pair of medication events on distinct dates, where one event is of class \"loop_diuretic\" and the other event is of class either \"ace_arb_arni\" or \"beta_blocker\", such that the absolute difference between their integer day indices is less than or equal to $180$.\n\nEvaluation protocol and metrics:\n- Each patient has a chart-reviewed reference label that is either True (heart failure present) or False (heart failure absent).\n- For a collection of patients, compute the following counts from first principles: true positives, false positives, true negatives, and false negatives.\n- From these counts, compute precision, recall, and the harmonic mean $F_{1}$ of precision and recall using their standard definitions derived from the confusion matrix. When a denominator in any metric’s definition is equal to $0$, define the corresponding metric’s value to be $0$.\n- All computed metric values must be reported as real numbers rounded to exactly three digits after the decimal point.\n\nTest suite and input data:\nYour program must use the following three datasets. Each dataset is a list of patients, and each patient is defined by a tuple with four components: a list of diagnostic code tuples (code string, setting string, integer day), a list of medication tuples (medication class string, integer day), an LVEF value or None, and a chart-reviewed label boolean. For example, a patient with one inpatient I50.9 code on day 60, two medication events, an LVEF of 0.35, and a chart label of True could be represented as: `([(\"I50.9\", \"inpatient\", 60)], [(\"loop_diuretic\", 10), (\"beta_blocker\", 20)], 0.35, True)`. Use the datasets below exactly as specified.\n\nDataset $1$ (general case with positive and negative examples and boundary conditions):\n- Patient $1$: codes [], meds [], LVEF $0.35$, gold True.\n- Patient $2$: codes [(\"I50.1\",\"outpatient\",5), (\"I50.9\",\"outpatient\",40)], meds [], LVEF None, gold True.\n- Patient $3$: codes [], meds [(\"loop_diuretic\",0), (\"ace_arb_arni\",180)], LVEF $0.55$, gold False.\n- Patient $4$: codes [], meds [(\"loop_diuretic\",0), (\"beta_blocker\",400)], LVEF $0.55$, gold False.\n- Patient $5$: codes [(\"I50.2\",\"inpatient\",60)], meds [], LVEF None, gold True.\n- Patient $6$: codes [(\"I10\",\"outpatient\",50)], meds [], LVEF $0.45$, gold False.\n- Patient $7$: codes [], meds [], LVEF $0.40$, gold True.\n- Patient $8$: codes [(\"I50.9\",\"outpatient\",70), (\"I50.1\",\"outpatient\",70)], meds [], LVEF $0.60$, gold True.\n\nDataset $2$ (edge case with no predicted positives expected):\n- Patient A: codes [(\"I50.9\",\"outpatient\",10)], meds [], LVEF $0.50$, gold True.\n- Patient B: codes [], meds [(\"loop_diuretic\",0), (\"ace_arb_arni\",400)], LVEF None, gold False.\n- Patient C: codes [(\"I50.1\",\"outpatient\",20), (\"I50.9\",\"outpatient\",20)], meds [], LVEF None, gold True.\n- Patient D: codes [(\"J96.0\",\"inpatient\",5)], meds [], LVEF $0.60$, gold False.\n- Patient E: codes [], meds [], LVEF $0.41$, gold True.\n\nDataset $3$ (edge case with no gold positives):\n- Patient X: codes [(\"I50.9\",\"inpatient\",12)], meds [], LVEF None, gold False.\n- Patient Y: codes [], meds [], LVEF $0.35$, gold False.\n- Patient Z: codes [], meds [(\"loop_diuretic\",10), (\"beta_blocker\",15)], LVEF $0.60$, gold False.\n\nTask and output specification:\n- Implement the phenotype logic and evaluation protocol described above.\n- For each dataset, compute precision, recall, and $F_{1}$, rounded to exactly three decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order: precision, recall, $F_{1}$ for Dataset $1$, then precision, recall, $F_{1}$ for Dataset $2$, then precision, recall, $F_{1}$ for Dataset $3$. For example: \"[0.123,0.456,0.321,0.000,0.000,0.000,1.000,1.000,1.000]\".",
            "solution": "The problem of designing and evaluating a computable phenotype is an exercise in translating clinical logic into a formal algorithm and then measuring its performance against a reference standard. This solution follows a principle-based design, first by systematically formalizing the phenotype rules and then by implementing a rigorous evaluation protocol.\n\nA patient is assigned a predicted positive heart failure label if they satisfy at least one of three independent criteria, which are combined using a logical OR operation. The final predicted label, $Y_{pred}$, is thus given by the expression:\n$$ Y_{pred} = (\\text{Criterion A}) \\lor (\\text{Criterion B}) \\lor (\\text{Criterion C}) $$\n\nThe design and implementation of each criterion are detailed below.\n\n**Phenotype Rule Formalization**\n\n1.  **Criterion A: ICD-10 Diagnosis Rule**\n    This criterion is based on diagnostic codes from the International Classification of Diseases, Tenth Revision (ICD-10). A patient is considered positive if they have a sufficient burden of heart failure-specific codes.\n    - **Heart Failure Code Definition**: Any ICD-10 code string that begins with the prefix `I50`.\n    - **Conditions**: The criterion is satisfied if either of the following sub-conditions is true:\n        1.  The patient has at least one (`$\\ge 1$`) `I50` code recorded in an `'inpatient'` setting.\n        2.  The patient has at least two (`$\\ge 2$`) `I50` codes recorded in an `'outpatient'` setting on distinct calendar days.\n    - **Algorithmic Logic**: To check this criterion, the patient's list of diagnostic codes is scanned. The presence of any inpatient `I50` code immediately satisfies the rule. If no such code exists, the algorithm collects all outpatient `I50` codes, extracts their associated day indices, and counts the number of unique days. If this count is $2$ or greater, the rule is satisfied.\n\n2.  **Criterion B: Echocardiogram Rule**\n    This criterion uses a key quantitative biomarker from cardiac imaging, the Left Ventricular Ejection Fraction ($L_{VEF}$), which measures the heart's pumping efficiency. A low $L_{VEF}$ is a hallmark of a specific type of heart failure.\n    - **Condition**: The patient has a recorded $L_{VEF}$ value, and this value is less than or equal to $0.40$. Formally, the condition is $L_{VEF} \\in [0, 0.40]$. Patients with no recorded $L_{VEF}$ (represented as `None`) do not satisfy this criterion.\n    - **Algorithmic Logic**: The implementation checks if the patient's $L_{VEF}$ value is not `None` and then evaluates the inequality $L_{VEF} \\le 0.40$.\n\n3.  **Criterion C: Medication Pattern Rule**\n    This criterion identifies patients based on a treatment pattern suggestive of heart failure, specifically the co-prescription of drugs for symptom management (diuretics) and guideline-directed medical therapy.\n    - **Condition**: The patient has records for at least one `'loop_diuretic'` and at least one medication from the set `{'ace_arb_arni', 'beta_blocker'}`. Critically, these two medication events must occur on distinct days, and the absolute time difference between their day indices must be no more than $180$ days.\n    - **Algorithmic Logic**: The algorithm first partitions the patient's medication list into two sets: one for `'loop_diuretic'` events and one for `'ace_arb_arni'` or `'beta_blocker'` events. It then iterates through all pairs of medications, one from each set. For each pair $(m_1, m_2)$ with corresponding day indices $(d_1, d_2)$, it checks if $d_1 \\neq d_2$ and $|d_1 - d_2| \\le 180$. The first such pair found satisfies the criterion. If no such pair exists after checking all combinations, the criterion is not met.\n\n**Evaluation Protocol**\n\nThe phenotype's accuracy is quantified by comparing its predictions ($Y_{pred}$) to pre-adjudicated, chart-reviewed reference labels ($Y_{gold}$) for a cohort of patients. This comparison generates four counts:\n- **True Positives (TP)**: Number of patients with $Y_{pred} = \\text{True}$ and $Y_{gold} = \\text{True}$.\n- **False Positives (FP)**: Number of patients with $Y_{pred} = \\text{True}$ and $Y_{gold} = \\text{False}$.\n- **True Negatives (TN)**: Number of patients with $Y_{pred} = \\text{False}$ and $Y_{gold} = \\text{False}$.\n- **False Negatives (FN)**: Number of patients with $Y_{pred} = \\text{False}$ and $Y_{gold} = \\text{True}$.\n\nFrom these counts, three standard metrics are derived:\n- **Precision**: Measures the accuracy of positive predictions.\n  $$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n- **Recall (Sensitivity)**: Measures the ability to identify all actual positive cases.\n  $$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n- **$F_1$ Score**: The harmonic mean of precision and recall, providing a balanced measure.\n  $$ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} $$\nIn cases where a denominator is zero (e.g., $\\text{TP} + \\text{FP} = 0$ if there are no positive predictions), the corresponding metric's value is defined as $0.0$. Final metric values are reported after rounding to exactly three decimal places. This entire process is applied independently to each of the three datasets provided.",
            "answer": "[0.800,0.800,0.800,0.000,0.000,0.000,0.000,0.000,0.000]"
        }
    ]
}