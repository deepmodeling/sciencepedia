{
    "hands_on_practices": [
        {
            "introduction": "预测建模的起点并非算法，而是数据。在临床研究中，一个常见而又微妙的错误是“不朽时间偏倚”（immortal time bias），即研究设计本身错误地保证了患者在一段时间内必然存活。本练习  提供了一个动手实践的机会，让您理解并纠正这种偏倚，展示了“时间零点”的选择对于准确估计风险是何等关键。",
            "id": "4853264",
            "problem": "给定一个围绕某项实验室检测构建的队列，该队列最初以实验室结果时间为索引时间，这无意中引入了不朽时间偏倚。请重新设计该队列，以实验室医嘱时间为索引时间，并重新计算结局风险窗口，然后比较朴素设计（以结果时间为索引）与校正后设计（以医嘱时间为索引）。目标是计算一个固定长度结局窗口的风险，并量化由不朽时间导致的差异。\n\n基于事件时间分析的基本定义：\n1. 对于由 $i \\in \\{1,\\dots,n\\}$ 索引的每个个体，您会观测到实验室医嘱时间 $t_i^{\\mathrm{ord}} \\in \\mathbb{R}_{\\ge 0}$、处理延迟 $d_i \\in \\mathbb{R}_{\\ge 0}$、实验室结果时间 $t_i^{\\mathrm{res}} = t_i^{\\mathrm{ord}} + d_i$、结局时间 $t_i^{\\mathrm{out}} \\in \\mathbb{R}_{\\ge 0} \\cup \\{+\\infty\\}$ 以及删失时间 $t_i^{\\mathrm{cens}} \\in \\mathbb{R}_{\\ge 0} \\cup \\{+\\infty\\}$。所有时间都以天为单位在同一时间轴上度量，其中 $+\\infty$ 表示在观测期内相应事件未发生。\n2. 定义一个索引函数 $t_i^{\\mathrm{idx},s}$，该函数依赖于方案 $s \\in \\{\\mathrm{naive}, \\mathrm{corr}\\}$，具体为 $t_i^{\\mathrm{idx},\\mathrm{naive}} := t_i^{\\mathrm{res}}$ 和 $t_i^{\\mathrm{idx},\\mathrm{corr}} := t_i^{\\mathrm{ord}}$。\n3. 对于一个固定的窗口长度 $W \\in \\mathbb{R}_{> 0}$（以天为单位），定义方案 $s$ 的风险集纳入规则为：个体 $i$ 被纳入当且仅当 $t_i^{\\mathrm{cens}} \\ge t_i^{\\mathrm{idx},s}$ 且 $t_i^{\\mathrm{out}} \\ge t_i^{\\mathrm{idx},s}$。此规则编码了在索引时间点无事件发生且未删失的条件。\n4. 对于被纳入的个体，定义结局指标 $y_i^{(s)}$ 为：如果 $t_i^{\\mathrm{out}} \\in [\\,t_i^{\\mathrm{idx},s}, \\min\\{t_i^{\\mathrm{idx},s} + W, t_i^{\\mathrm{cens}}\\}\\,]$，则 $y_i^{(s)} = 1$，否则 $y_i^{(s)} = 0$。区间端点为闭合区间。\n5. 定义方案 $s$ 的风险为 $R^{(s)} = \\left(\\sum_{i \\in \\mathcal{I}_s} y_i^{(s)}\\right) / \\left|\\mathcal{I}_s\\right|$，其中 $\\mathcal{I}_s$ 是在方案 $s$ 下被纳入个体的集合。每个数据集需要关注的量是 $(R^{(\\mathrm{naive})}, R^{(\\mathrm{corr})}, R^{(\\mathrm{corr})} - R^{(\\mathrm{naive})})$。\n\n所有时间值均以天为单位；输出的风险值必须以小数形式报告（而非百分比），并四舍五入至小数点后六位。\n\n请实现一个程序，对下方的每个测试用例，使用上述定义计算三元组 $(R^{(\\mathrm{naive})}, R^{(\\mathrm{corr})}, R^{(\\mathrm{corr})} - R^{(\\mathrm{naive})})$，并将所有结果以方括号括起的逗号分隔列表形式单行输出。\n\n测试套件（所有时间单位为天；在规定处使用 $+\\infty$）：\n- 测试用例 $1$，窗口 $W = 7$，个体如下：\n  - $i_1$: $t^{\\mathrm{ord}} = 0$, $d = 2$ 因此 $t^{\\mathrm{res}} = 2$, $t^{\\mathrm{out}} = 5$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_2$: $t^{\\mathrm{ord}} = 1$, $d = 3$ 因此 $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 3$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_3$: $t^{\\mathrm{ord}} = 4$, $d = 1$ 因此 $t^{\\mathrm{res}} = 5$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 10$。\n  - $i_4$: $t^{\\mathrm{ord}} = 2$, $d = 2$ 因此 $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 12$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_5$: $t^{\\mathrm{ord}} = 3$, $d = 7$ 因此 $t^{\\mathrm{res}} = 10$, $t^{\\mathrm{out}} = 8$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_6$: $t^{\\mathrm{ord}} = 6$, $d = 2$ 因此 $t^{\\mathrm{res}} = 8$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 7$。\n- 测试用例 $2$，窗口 $W = 3$，个体如下：\n  - $i_1$: $t^{\\mathrm{ord}} = 0$, $d = 0$ 因此 $t^{\\mathrm{res}} = 0$, $t^{\\mathrm{out}} = 0$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_2$: $t^{\\mathrm{ord}} = 5$, $d = 2$ 因此 $t^{\\mathrm{res}} = 7$, $t^{\\mathrm{out}} = 8$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_3$: $t^{\\mathrm{ord}} = 1$, $d = 3$ 因此 $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 2$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_4$: $t^{\\mathrm{ord}} = 3$, $d = 1$ 因此 $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 4$。\n  - $i_5$: $t^{\\mathrm{ord}} = 2$, $d = 5$ 因此 $t^{\\mathrm{res}} = 7$, $t^{\\mathrm{out}} = 1$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_6$: $t^{\\mathrm{ord}} = 6$, $d = 0$ 因此 $t^{\\mathrm{res}} = 6$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 6$。\n- 测试用例 $3$，窗口 $W = 5$，个体如下：\n  - $i_1$: $t^{\\mathrm{ord}} = 0$, $d = 4$ 因此 $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 3$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_2$: $t^{\\mathrm{ord}} = 2$, $d = 1$ 因此 $t^{\\mathrm{res}} = 3$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 2$。\n  - $i_3$: $t^{\\mathrm{ord}} = 5$, $d = 10$ 因此 $t^{\\mathrm{res}} = 15$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = 7$。\n  - $i_4$: $t^{\\mathrm{ord}} = 8$, $d = 0$ 因此 $t^{\\mathrm{res}} = 8$, $t^{\\mathrm{out}} = 12$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_5$: $t^{\\mathrm{ord}} = 1$, $d = 2$ 因此 $t^{\\mathrm{res}} = 3$, $t^{\\mathrm{out}} = 20$, $t^{\\mathrm{cens}} = +\\infty$。\n  - $i_6$: $t^{\\mathrm{ord}} = 9$, $d = 1$ 因此 $t^{\\mathrm{res}} = 10$, $t^{\\mathrm{out}} = +\\infty$, $t^{\\mathrm{cens}} = +\\infty$。\n\n您的程序必须：\n- 严格按照上述定义实现。\n- 对每个测试用例，计算 $(R^{(\\mathrm{naive})}, R^{(\\mathrm{corr})}, R^{(\\mathrm{corr})} - R^{(\\mathrm{naive})})$。\n- 生成一行输出，包含三个测试用例的所有九个数字，按顺序排列，四舍五入至小数点后六位，并以逗号分隔的列表形式包含在方括号内。格式为：\n  $[r_{1,\\mathrm{naive}}, r_{1,\\mathrm{corr}}, r_{1,\\mathrm{diff}}, r_{2,\\mathrm{naive}}, r_{2,\\mathrm{corr}}, r_{2,\\mathrm{diff}}, r_{3,\\mathrm{naive}}, r_{3,\\mathrm{corr}}, r_{3,\\mathrm{diff}}]$，其中对于测试用例 $k \\in \\{1,2,3\\}$，$r_{k,\\mathrm{diff}} = r_{k,\\mathrm{corr}} - r_{k,\\mathrm{naive}}$。",
            "solution": "该问题陈述在形式上定义明确，在科学上基于事件时间分析的原则，并且在计算上是可行的。它提供了一套清晰、自洽的定义和数据，从而可以得出一个唯一且可验证的解。该问题探讨了不朽时间偏倚的概念，这是观察性研究和临床预测建模中的一个关键问题，其中不恰当的索引时间（时间零点）选择可能导致风险估计出现偏差。该问题是有效的。\n\n核心任务是比较两种队列构建方案，用于估计在实验室检测后固定时间窗口 $W$ 内发生结局的风险。关键区别在于索引时间 $t^{\\mathrm{idx}}$ 的定义，所有随访都从该时间点开始测量。\n\n1.  **朴素方案 ($s = \\mathrm{naive}$)**：索引时间是实验室结果时间，$t_i^{\\mathrm{idx},\\mathrm{naive}} = t_i^{\\mathrm{res}}$。这种设计很常见但存在缺陷。对于个体 $i$ 要被纳入队列，他/她必须在 $t_i^{\\mathrm{res}}$ 时仍然存活且未被删失。从下达检测医嘱 ($t_i^{\\mathrm{ord}}$) 到收到结果 ($t_i^{\\mathrm{res}}$) 之间的时间间隔，即处理延迟 $d_i$，成为了“不朽时间”。根据定义，对于被纳入队列的个体，在此期间不可能观察到不良结局，因为任何在此期间经历结局或被删失的人都会被排除在分析之外。这系统性地移除了早期事件，导致对真实风险的低估。\n\n2.  **校正方案 ($s = \\mathrm{corr}$)**：索引时间是实验室医嘱时间，$t_i^{\\mathrm{idx},\\mathrm{corr}} = t_i^{\\mathrm{ord}}$。这是概念上正确的方法。下达检测医嘱的时刻是临床决策过程开始的时刻，也是患者就该检测将提供的信息而言正式进入“风险期”的时刻。这种设计正确地允许事件和删失在医嘱时间后的任何时间点发生，包括在处理延迟期间，从而提供了对风险的无偏估计。\n\n每种方案 $s$ 的风险，记为 $R^{(s)}$，计算为在指定风险窗口内经历结局的个体数量与该方案下被纳入风险集的总个体数量之比。计算过程遵循所提供的形式化定义。我们用 $\\infty$ 表示 $+\\infty$。\n\n### 测试用例 1：$W=7$\n\n- 个体数据：\n  - $i_1$: $t^{\\mathrm{ord}} = 0$, $d = 2$, $t^{\\mathrm{res}} = 2$, $t^{\\mathrm{out}} = 5$, $t^{\\mathrm{cens}} = \\infty$。\n  - $i_2$: $t^{\\mathrm{ord}} = 1$, $d = 3$, $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 3$, $t^{\\mathrm{cens}} = \\infty$。\n  - $i_3$: $t^{\\mathrm{ord}} = 4$, $d = 1$, $t^{\\mathrm{res}} = 5$, $t^{\\mathrm{out}} = \\infty$, $t^{\\mathrm{cens}} = 10$。\n  - $i_4$: $t^{\\mathrm{ord}} = 2$, $d = 2$, $t^{\\mathrm{res}} = 4$, $t^{\\mathrm{out}} = 12$, $t^{\\mathrm{cens}} = \\infty$。\n  - $i_5$: $t^{\\mathrm{ord}} = 3$, $d = 7$, $t^{\\mathrm{res}} = 10$, $t^{\\mathrm{out}} = 8$, $t^{\\mathrm{cens}} = \\infty$。\n  - $i_6$: $t^{\\mathrm{ord}} = 6$, $d = 2$, $t^{\\mathrm{res}} = 8$, $t^{\\mathrm{out}} = \\infty$, $t^{\\mathrm{cens}} = 7$。\n\n#### 朴素方案 ($t^{\\mathrm{idx}} = t^{\\mathrm{res}}$)\n个体 $i$ 被纳入，如果 $t_i^{\\mathrm{cens}} \\ge t_i^{\\mathrm{res}}$ 且 $t_i^{\\mathrm{out}} \\ge t_i^{\\mathrm{res}}$。\n- $i_1$: $t^{\\mathrm{res}}=2$。纳入（$\\infty \\ge 2$, $5 \\ge 2$）。\n- $i_2$: $t^{\\mathrm{res}}=4$。排除（$t^{\\mathrm{out}}=3  4$）。\n- $i_3$: $t^{\\mathrm{res}}=5$。纳入（$10 \\ge 5$, $\\infty \\ge 5$）。\n- $i_4$: $t^{\\mathrm{res}}=4$。纳入（$\\infty \\ge 4$, $12 \\ge 4$）。\n- $i_5$: $t^{\\mathrm{res}}=10$。排除（$t^{\\mathrm{out}}=8  10$）。\n- $i_6$: $t^{\\mathrm{res}}=8$。排除（$t^{\\mathrm{cens}}=7  8$）。\n\n被纳入的个体集合为 $\\mathcal{I}_{\\mathrm{naive}} = \\{i_1, i_3, i_4\\}$，因此 $|\\mathcal{I}_{\\mathrm{naive}}| = 3$。\n结局指标 $y_i^{(s)}=1$ 如果 $t_i^{\\mathrm{out}} \\in [t_i^{\\mathrm{idx},s}, \\min\\{t_i^{\\mathrm{idx},s} + W, t_i^{\\mathrm{cens}}\\}]$。\n- $i_1$: $t^{\\mathrm{idx}}=2$。窗口为 $[2, \\min\\{2+7, \\infty\\}]=[2, 9]$。$t^{\\mathrm{out}}=5 \\in [2, 9]$，所以 $y_1=1$。\n- $i_3$: $t^{\\mathrm{idx}}=5$。窗口为 $[5, \\min\\{5+7, 10\\}]=[5, 10]$。$t^{\\mathrm{out}}=\\infty \\notin [5, 10]$，所以 $y_3=0$。\n- $i_4$: $t^{\\mathrm{idx}}=4$。窗口为 $[4, \\min\\{4+7, \\infty\\}]=[4, 11]$。$t^{\\mathrm{out}}=12 \\notin [4, 11]$，所以 $y_4=0$。\n\n总结局数为 $1$。风险为 $R^{(\\mathrm{naive})} = 1/3 \\approx 0.333333$。\n\n#### 校正方案 ($t^{\\mathrm{idx}} = t^{\\mathrm{ord}}$)\n个体 $i$ 被纳入，如果 $t_i^{\\mathrm{cens}} \\ge t_i^{\\mathrm{ord}}$ 且 $t_i^{\\mathrm{out}} \\ge t_i^{\\mathrm{ord}}$。\n- $i_1$: $t^{\\mathrm{ord}}=0$。纳入（$\\infty \\ge 0$, $5 \\ge 0$）。\n- $i_2$: $t^{\\mathrm{ord}}=1$。纳入（$\\infty \\ge 1$, $3 \\ge 1$）。\n- $i_3$: $t^{\\mathrm{ord}}=4$。纳入（$10 \\ge 4$, $\\infty \\ge 4$）。\n- $i_4$: $t^{\\mathrm{ord}}=2$。纳入（$\\infty \\ge 2$, $12 \\ge 2$）。\n- $i_5$: $t^{\\mathrm{ord}}=3$。纳入（$\\infty \\ge 3$, $8 \\ge 3$）。\n- $i_6$: $t^{\\mathrm{ord}}=6$。纳入（$7 \\ge 6$, $\\infty \\ge 6$）。\n\n所有 $6$ 个个体都被纳入，$\\mathcal{I}_{\\mathrm{corr}} = \\{i_1, i_2, i_3, i_4, i_5, i_6\\}$，因此 $|\\mathcal{I}_{\\mathrm{corr}}| = 6$。\n- $i_1$: $t^{\\mathrm{idx}}=0$。窗口为 $[0, 7]$。$t^{\\mathrm{out}}=5 \\in [0, 7]$，$y_1=1$。\n- $i_2$: $t^{\\mathrm{idx}}=1$。窗口为 $[1, 8]$。$t^{\\mathrm{out}}=3 \\in [1, 8]$，$y_2=1$。\n- $i_3$: $t^{\\mathrm{idx}}=4$。窗口为 $[4, 10]$。$t^{\\mathrm{out}}=\\infty \\notin [4, 10]$，$y_3=0$。\n- $i_4$: $t^{\\mathrm{idx}}=2$。窗口为 $[2, 9]$。$t^{\\mathrm{out}}=12 \\notin [2, 9]$，$y_4=0$。\n- $i_5$: $t^{\\mathrm{idx}}=3$。窗口为 $[3, 10]$。$t^{\\mathrm{out}}=8 \\in [3, 10]$，$y_5=1$。\n- $i_6$: $t^{\\mathrm{idx}}=6$。窗口为 $[6, \\min\\{6+7, 7\\}]=[6, 7]$。$t^{\\mathrm{out}}=\\infty \\notin [6, 7]$，$y_6=0$。\n\n总结局数为 $1+1+0+0+1+0 = 3$。风险为 $R^{(\\mathrm{corr})} = 3/6 = 0.5$。\n结果三元组为 $(0.333333, 0.500000, 0.166667)$。\n\n### 测试用例 2：$W=3$\n遵循相同的步骤：\n- **朴素方案**：纳入集合 $\\mathcal{I}_{\\mathrm{naive}} = \\{i_1, i_2, i_4, i_6\\}$， $|\\mathcal{I}_{\\mathrm{naive}}| = 4$。结局：$y_1=1, y_2=1, y_4=0, y_6=0$。风险 $R^{(\\mathrm{naive})} = 2/4 = 0.5$。\n- **校正方案**：纳入集合 $\\mathcal{I}_{\\mathrm{corr}} = \\{i_1, i_2, i_3, i_4, i_6\\}$， $|\\mathcal{I}_{\\mathrm{corr}}| = 5$。结局：$y_1=1, y_2=1, y_3=1, y_4=0, y_6=0$。风险 $R^{(\\mathrm{corr})} = 3/5 = 0.6$。\n- 结果三元组为 $(0.500000, 0.600000, 0.100000)$。\n\n### 测试用例 3：$W=5$\n遵循相同的步骤：\n- **朴素方案**：纳入集合 $\\mathcal{I}_{\\mathrm{naive}} = \\{i_4, i_5, i_6\\}$， $|\\mathcal{I}_{\\mathrm{naive}}| = 3$。结局：$y_4=1, y_5=0, y_6=0$。风险 $R^{(\\mathrm{naive})} = 1/3 \\approx 0.333333$。\n- **校正方案**：纳入集合 $\\mathcal{I}_{\\mathrm{corr}} = \\{i_1, i_2, i_3, i_4, i_5, i_6\\}$， $|\\mathcal{I}_{\\mathrm{corr}}| = 6$。结局：$y_1=1, y_2=0, y_3=0, y_4=1, y_5=0, y_6=0$。风险 $R^{(\\mathrm{corr})} = 2/6 = 1/3 \\approx 0.333333$。\n- 结果三元组为 $(0.333333, 0.333333, 0.000000)$。在这个例子中，队列构建中的偏倚恰好被分母和分子的变化所抵消，偶然导致风险估计没有净变化。\n\n整套计算确认了将在程序中实现的逻辑和结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the immortal time bias problem for the given test cases.\n    \"\"\"\n    \n    # Use np.inf to represent infinity for time values.\n    inf = np.inf\n\n    test_cases = [\n        (7, [\n            (0, 2, 5, inf),   # i_1\n            (1, 3, 3, inf),   # i_2\n            (4, 1, inf, 10),  # i_3\n            (2, 2, 12, inf),  # i_4\n            (3, 7, 8, inf),   # i_5\n            (6, 2, inf, 7)    # i_6\n        ]),\n        (3, [\n            (0, 0, 0, inf),   # i_1\n            (5, 2, 8, inf),   # i_2\n            (1, 3, 2, inf),   # i_3\n            (3, 1, inf, 4),   # i_4\n            (2, 5, 1, inf),   # i_5\n            (6, 0, inf, 6)    # i_6\n        ]),\n        (5, [\n            (0, 4, 3, inf),   # i_1\n            (2, 1, inf, 2),   # i_2\n            (5, 10, inf, 7),  # i_3\n            (8, 0, 12, inf),  # i_4\n            (1, 2, 20, inf),  # i_5\n            (9, 1, inf, inf)  # i_6\n        ])\n    ]\n\n    all_results = []\n\n    for W, individuals in test_cases:\n        # --- Naive Schema Calculation ---\n        included_naive_count = 0\n        outcome_naive_count = 0\n        for ind in individuals:\n            t_ord, d, t_out, t_cens = ind\n            t_res = t_ord + d\n            \n            # Inclusion rule: individual is event-free and uncensored at index time\n            if t_cens >= t_res and t_out >= t_res:\n                included_naive_count += 1\n                \n                # Outcome rule: outcome occurs within the risk window\n                t_idx_naive = t_res\n                risk_window_end = min(t_idx_naive + W, t_cens)\n                if t_idx_naive = t_out = risk_window_end:\n                    outcome_naive_count += 1\n        \n        r_naive = outcome_naive_count / included_naive_count if included_naive_count > 0 else 0.0\n\n        # --- Corrected Schema Calculation ---\n        included_corr_count = 0\n        outcome_corr_count = 0\n        for ind in individuals:\n            t_ord, d, t_out, t_cens = ind\n            \n            # Inclusion rule\n            if t_cens >= t_ord and t_out >= t_ord:\n                included_corr_count += 1\n                \n                # Outcome rule\n                t_idx_corr = t_ord\n                risk_window_end = min(t_idx_corr + W, t_cens)\n                if t_idx_corr = t_out = risk_window_end:\n                    outcome_corr_count += 1\n                    \n        r_corr = outcome_corr_count / included_corr_count if included_corr_count > 0 else 0.0\n        \n        r_diff = r_corr - r_naive\n        \n        all_results.extend([r_naive, r_corr, r_diff])\n    \n    # Format results to six decimal places for the final output string\n    formatted_results = [f\"{round(r, 6):.6f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "有了正确构建的数据集，我们就可以着手建立预测模型了。本练习  将带您深入一个广泛应用的分类器核心：正则化逻辑回归。通过从其数学基础开始亲手实现模型，您将深刻体会到模型是如何从数据中学习的，以及正则化是如何帮助我们建立更稳健、更具泛化能力的模型的。",
            "id": "4853338",
            "problem": "您将为医学信息学中的一项临床预测任务实现一个带惩罚项的二元分类器，使用一个将患者特征映射到$30$天死亡率概率的模型。目标变量是$30$天死亡率，编码为$0$（存活）或$1$（死亡）。特征集包括年龄、生命体征和合并症。您必须推导、实现并应用一个带$L_2$（欧几里得）惩罚项的正则化逻辑回归，然后解释年龄每增加一个单位时，几率（odds）的变化。您的实现必须从最基本的基础开始：二元结局被建模为独立的伯努利随机变量，其概率由一个从线性预测器到概率的可微连接函数确定，并结合一个抑制大参数值的惩罚项。不要假设或使用任何预先给定的快捷公式；从基本定义中推导您所需要的一切。\n\n临床变量和单位：\n- 年龄 $a$，单位为年。\n- 收缩压 $s$，单位为毫米汞柱（mmHg）。\n- 心率 $h$，单位为次/分钟（bpm）。\n- 糖尿病指标 $d \\in \\{0,1\\}$。\n- 慢性肾病指标 $c \\in \\{0,1\\}$。\n- 死亡结局 $y \\in \\{0,1\\}$。\n\n数据集（每行为一名患者，数据为 $(a, s, h, d, c, y)$）：\n- 患者 1：$a=72$ 岁，$s=110$ mmHg，$h=92$ bpm，$d=1$，$c=1$，$y=1$。\n- 患者 2：$a=55$ 岁，$s=130$ mmHg，$h=78$ bpm，$d=0$，$c=0$，$y=0$。\n- 患者 3：$a=80$ 岁，$s=100$ mmHg，$h=88$ bpm，$d=1$，$c=1$，$y=1$。\n- 患者 4：$a=45$ 岁，$s=120$ mmHg，$h=70$ bpm，$d=0$，$c=0$，$y=0$。\n- 患者 5：$a=67$ 岁，$s=115$ mmHg，$h=85$ bpm，$d=0$，$c=1$，$y=1$。\n- 患者 6：$a=60$ 岁，$s=140$ mmHg，$h=75$ bpm，$d=1$，$c=0$，$y=0$。\n- 患者 7：$a=50$ 岁，$s=125$ mmHg，$h=68$ bpm，$d=0$，$c=0$，$y=0$。\n- 患者 8：$a=76$ 岁，$s=105$ mmHg，$h=95$ bpm，$d=1$，$c=1$，$y=1$。\n- 患者 9：$a=65$ 岁，$s=110$ mmHg，$h=82$ bpm，$d=1$，$c=0$，$y=0$。\n- 患者 10：$a=58$ 岁，$s=135$ mmHg，$h=80$ bpm，$d=0$，$c=0$，$y=0$。\n- 患者 11：$a=85$ 岁，$s=98$ mmHg，$h=100$ bpm，$d=1$，$c=1$，$y=1$。\n- 患者 12：$a=70$ 岁，$s=108$ mmHg，$h=90$ bpm，$d=0$，$c=1$，$y=1$。\n\n建模与任务：\n- 使用带有显式截距项（常数项）的线性预测器。不要对截距项施加任何惩罚；对所有其他系数应用$L_2$惩罚。\n- 从伯努利似然的定义以及线性预测器与事件概率之间的可微连接函数出发，推导出目标函数，该函数是负对数似然与非截距项系数的$L_2$惩罚项之和。\n- 推导目标函数相对于系数向量的梯度和海森矩阵，并实现一个带有回溯线搜索的牛顿类方法来找到系数估计值。\n- 计算指定测试套件的系数估计值。\n- 将年龄每增加一个单位（年）的几率变化解释为年龄系数的指数。对每个测试案例报告此解释。\n\n测试套件：\n- 案例 1：惩罚参数 $\\lambda = 0$，对所有 12 名患者使用基础特征 $(a, s, h, d, c)$，无共线性。\n- 案例 2：惩罚参数 $\\lambda = 0.1$，特征和患者与案例 1 相同。\n- 案例 3：惩罚参数 $\\lambda = 10$，特征和患者与案例 1 相同。\n- 案例 4：惩罚参数 $\\lambda = 1$，在所有 12 名患者上添加一个与年龄完全共线的特征（即，同时包含 $a$ 和一个精确的副本 $a'$）。\n- 案例 5：惩罚参数 $\\lambda = 1$，使用基础特征 $(a, s, h, d, c)$，但只使用前 6 名患者。\n\n答案规格和单位：\n- 年龄的系数必须解释为每增加 1 年的变化，因此几率乘数为 $\\exp(\\beta_{\\text{age}})$，这是一个无单位因子。将几率乘数表示为小数。\n- 您的程序应为每个测试案例计算年龄系数 $\\beta_{\\text{age}}$ 和几率乘数 $\\exp(\\beta_{\\text{age}})$。\n- 输出格式：单行，包含一个用方括号括起来的逗号分隔列表，按以下顺序包含保留六位小数的浮点数：$[\\beta_{\\text{age}}^{(1)}, \\exp(\\beta_{\\text{age}}^{(1)}), \\beta_{\\text{age}}^{(2)}, \\exp(\\beta_{\\text{age}}^{(2)}), \\beta_{\\text{age}}^{(3)}, \\exp(\\beta_{\\text{age}}^{(3)}), \\beta_{\\text{age}}^{(4)}, \\exp(\\beta_{\\text{age}}^{(4)}), \\beta_{\\text{age}}^{(5)}, \\exp(\\beta_{\\text{age}}^{(5)})]$，其中上标表示从 1 到 5 的案例编号。\n\n您的程序必须是自包含的，不接受任何输入，并严格按照上述规定产生单行输出。",
            "solution": "该问题要求推导并实现一个带 $L_2$ 正则化（也称为岭回归）的逻辑回归模型，用以根据一组临床特征预测30天死亡率。实现必须从第一性原理出发，从模型的统计基础开始，最终形成一个带有回溯线搜索的牛顿-拉弗森优化算法。\n\n### I. 模型构建\n\n我们为每位患者 $i$ 的二元结局 $y_i \\in \\{0, 1\\}$ 建模为一个独立的伯努利随机变量。正向结局（$y_i=1$，死亡）的概率记为 $p_i$，它是患者特征向量 $\\mathbf{x}_i$ 的函数。患者 $i$ 的特征向量为 $\\mathbf{x}_i = [1, a_i, s_i, h_i, d_i, c_i]$，其中第一个 $1$ 对应于截距项。完整的系数向量为 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_a, \\beta_s, \\beta_h, \\beta_d, \\beta_c]^T$，其中 $\\beta_0$ 是截距。\n\n线性预测器 $\\eta_i$ 定义为特征向量和系数向量的内积：\n$$\n\\eta_i = \\mathbf{x}_i \\boldsymbol{\\beta} = \\beta_0 + \\beta_a a_i + \\beta_s s_i + \\beta_h h_i + \\beta_d d_i + \\beta_c c_i\n$$\n\n线性预测器 $\\eta_i$ 和概率 $p_i$ 之间的关系由逻辑连接函数（logit函数的逆函数）建立：\n$$\np_i = P(y_i=1 | \\mathbf{x}_i; \\boldsymbol{\\beta}) = \\sigma(\\eta_i) = \\frac{1}{1 + e^{-\\eta_i}}\n$$\n其中 $\\sigma(\\cdot)$ 是 sigmoid 函数。相应地，存活的概率是 $P(y_i=0) = 1 - p_i = \\frac{e^{-\\eta_i}}{1 + e^{-\\eta_i}} = \\frac{1}{1 + e^{\\eta_i}}$。\n\n### II. 带惩罚项的目标函数推导\n\n目标是找到系数向量 $\\boldsymbol{\\beta}$，使其在最大化观测数据似然的同时，惩罚较大的系数值以防止过拟合。这等价于最小化带惩罚项的负对数似然。\n\n**1. 似然函数：**\n鉴于 $N$ 个观测是独立的，数据 $(\\mathbf{y}, X)$ 的总似然是各个伯努利概率的乘积：\n$$\nL(\\boldsymbol{\\beta}) = \\prod_{i=1}^{N} p_i^{y_i} (1 - p_i)^{1-y_i}\n$$\n\n**2. 对数似然函数：**\n处理似然函数的对数更为方便：\n$$\n\\ell(\\boldsymbol{\\beta}) = \\log L(\\boldsymbol{\\beta}) = \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right]\n$$\n我们可以用线性预测器 $\\eta_i$ 来表达它。对数几率 (logit) 是 $\\log\\left(\\frac{p_i}{1-p_i}\\right) = \\eta_i$。同时，$\\log(1-p_i) = -\\log(1+e^{\\eta_i})$。将这些代入对数似然表达式中得到：\n$$\n\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{N} \\left[ y_i \\eta_i - \\log(1+e^{\\eta_i}) \\right] = \\sum_{i=1}^{N} \\left[ y_i (\\mathbf{x}_i \\boldsymbol{\\beta}) - \\log(1+e^{\\mathbf{x}_i \\boldsymbol{\\beta}}) \\right]\n$$\n\n**3. 带惩罚项的目标函数：**\n我们的目标是最小化负对数似然，并加上一个 $L_2$ 惩罚项。惩罚项适用于除截距 $\\beta_0$ 之外的所有系数。设 $p$ 为特征数量（不包括截距）。惩罚项为 $\\frac{\\lambda}{2} \\sum_{j=1}^{p} \\beta_j^2$，其中 $\\lambda \\ge 0$ 是正则化参数。\n最终要最小化的目标函数是 $J(\\boldsymbol{\\beta})$：\n$$\nJ(\\boldsymbol{\\beta}) = -\\ell(\\boldsymbol{\\beta}) + \\frac{\\lambda}{2} \\sum_{j=1}^{p} \\beta_j^2 = \\sum_{i=1}^{N} \\left[ \\log(1+e^{\\mathbf{x}_i \\boldsymbol{\\beta}}) - y_i (\\mathbf{x}_i \\boldsymbol{\\beta}) \\right] + \\frac{\\lambda}{2} \\sum_{j=1}^{p} \\beta_j^2\n$$\n\n### III. 使用牛顿法进行优化\n\n为了找到最小化 $J(\\boldsymbol{\\beta})$ 的最优 $\\boldsymbol{\\beta}$，我们使用牛顿-拉弗森方法，这是一种迭代的二阶优化算法。更新规则是：\n$$\n\\boldsymbol{\\beta}^{(k+1)} = \\boldsymbol{\\beta}^{(k)} - \\alpha [H(\\boldsymbol{\\beta}^{(k)})]^{-1} \\mathbf{g}(\\boldsymbol{\\beta}^{(k)})\n$$\n其中 $\\mathbf{g}(\\boldsymbol{\\beta})$ 是 $J(\\boldsymbol{\\beta})$ 的梯度，$H(\\boldsymbol{\\beta})$ 是其海森矩阵，$\\alpha$ 是由线搜索过程确定的步长。\n\n**1. 目标函数的梯度：**\n梯度 $\\mathbf{g}(\\boldsymbol{\\beta}) = \\nabla J(\\boldsymbol{\\beta})$ 是一个由偏导数 $\\frac{\\partial J}{\\partial \\beta_j}$ 组成的向量。\n$$\n\\frac{\\partial J}{\\partial \\beta_j} = \\sum_{i=1}^{N} \\left[ \\frac{\\partial}{\\partial \\beta_j} \\log(1+e^{\\mathbf{x}_i \\boldsymbol{\\beta}}) - y_i \\frac{\\partial}{\\partial \\beta_j} (\\mathbf{x}_i \\boldsymbol{\\beta}) \\right] + \\frac{\\partial}{\\partial \\beta_j} \\left( \\frac{\\lambda}{2} \\sum_{k=1}^{p} \\beta_k^2 \\right)\n$$\n使用链式法则，$\\frac{\\partial}{\\partial \\beta_j} \\log(1+e^{\\eta_i}) = \\frac{e^{\\eta_i}}{1+e^{\\eta_i}} \\frac{\\partial \\eta_i}{\\partial \\beta_j} = p_i x_{ij}$。同时，$\\frac{\\partial}{\\partial \\beta_j} (\\mathbf{x}_i \\boldsymbol{\\beta}) = x_{ij}$。惩罚项的导数对于 $j \\ge 1$ 是 $\\lambda \\beta_j$，对于 $j=0$ 是 $0$。\n$$\n\\frac{\\partial J}{\\partial \\beta_j} = \\sum_{i=1}^{N} [p_i x_{ij} - y_i x_{ij}] + \\lambda \\beta_j \\cdot \\mathbb{I}(j \\ge 1) = \\sum_{i=1}^{N} (p_i - y_i) x_{ij} + \\lambda \\beta_j \\cdot \\mathbb{I}(j \\ge 1)\n$$\n在矩阵表示法中，设 $X$ 为 $N \\times (p+1)$ 的设计矩阵，$\\mathbf{y}$ 为 $N \\times 1$ 的结局向量，$\\mathbf{p}$ 为 $N \\times 1$ 的概率向量。设 $\\boldsymbol{\\beta}^*$ 是截距为零的系数向量（$\\beta_0^*=0, \\beta_j^*=\\beta_j$ for $j \\ge 1$）。梯度为：\n$$\n\\mathbf{g}(\\boldsymbol{\\beta}) = \\nabla J(\\boldsymbol{\\beta}) = X^T(\\mathbf{p} - \\mathbf{y}) + \\lambda \\boldsymbol{\\beta}^*\n$$\n\n**2. 目标函数的海森矩阵：**\n海森矩阵 $H(\\boldsymbol{\\beta}) = \\nabla^2 J(\\boldsymbol{\\beta})$ 是一个由二阶偏导数 $H_{jk} = \\frac{\\partial^2 J}{\\partial \\beta_k \\partial \\beta_j}$ 组成的矩阵。\n$$\nH_{jk} = \\frac{\\partial}{\\partial \\beta_k} \\left[ \\sum_{i=1}^{N} (p_i - y_i) x_{ij} \\right] + \\frac{\\partial}{\\partial \\beta_k} (\\lambda \\beta_j \\cdot \\mathbb{I}(j \\ge 1))\n$$\n$p_i$ 相对于 $\\eta_i$ 的导数是 $\\frac{dp_i}{d\\eta_i} = p_i(1-p_i)$。使用链式法则，$\\frac{\\partial p_i}{\\partial \\beta_k} = \\frac{dp_i}{d\\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta_k} = p_i(1-p_i)x_{ik}$。\n$$\nH_{jk} = \\sum_{i=1}^{N} x_{ij} \\frac{\\partial p_i}{\\partial \\beta_k} + \\lambda \\delta_{jk} \\cdot \\mathbb{I}(j \\ge 1) = \\sum_{i=1}^{N} x_{ij} p_i(1-p_i) x_{ik} + \\lambda \\delta_{jk} \\cdot \\mathbb{I}(j \\ge 1)\n$$\n其中 $\\delta_{jk}$ 是克罗内克δ。在矩阵形式中，设 $W$ 是一个 $N \\times N$ 的对角矩阵，其对角线元素为 $W_{ii} = p_i(1-p_i)$。设 $\\boldsymbol{\\Lambda}$ 是一个 $(p+1) \\times (p+1)$ 的对角矩阵，其中 $\\Lambda_{00}=0$ 且对于 $j \\ge 1$ 有 $\\Lambda_{jj}=\\lambda$。海森矩阵为：\n$$\nH(\\boldsymbol{\\beta}) = X^T W X + \\boldsymbol{\\Lambda}\n$$\n该海森矩阵保证是半正定的。对于 $\\lambda > 0$，它是正定的，即使存在共线性（如案例 4）或数据分离（如案例 5）也能确保唯一解。\n\n**3. 回溯线搜索：**\n为了确保收敛，完整的牛顿步长可能过大。我们引入一个步长 $\\alpha \\in (0, 1]$，选择它来满足Armijo-Goldstein充分下降条件。给定一个搜索方向 $\\mathbf{d} = -H^{-1}\\mathbf{g}$，我们从 $\\alpha=1$ 开始，并将其乘以一个因子 $\\tau$（例如 0.5）进行递减，直到满足 $J(\\boldsymbol{\\beta} + \\alpha \\mathbf{d}) \\le J(\\boldsymbol{\\beta}) + c_1 \\alpha \\mathbf{g}^T \\mathbf{d}$，其中 $c_1$ 是一个小常数（例如 $10^{-4}$）。\n\n### IV. 系数的解释\n在逻辑回归中，系数表示预测变量每改变一个单位，结局的对数几率的变化。死亡的几率为 $\\frac{p_i}{1-p_i} = e^{\\eta_i}$。对于特征 $x_j$ 每增加一个单位，新的对数几率为 $\\eta_i + \\beta_j$。新的几率为 $e^{\\eta_i + \\beta_j} = e^{\\eta_i}e^{\\beta_j}$。因此，几率乘以一个因子 $e^{\\beta_j}$，这就是几率比。对于年龄系数 $\\beta_a$，年龄每增加一年的几率比为 $\\exp(\\beta_a)$。\n\n### V. 在测试案例上的应用\n将推导出的算法应用于五个指定的测试案例。对于每个案例，构建相应的设计矩阵 $X$、结局向量 $\\mathbf{y}$ 和惩罚参数 $\\lambda$。然后使用牛顿-拉弗森优化器找到系数向量 $\\boldsymbol{\\beta}$。最后，计算并报告年龄系数 $\\beta_a$（在我们的零索引向量中是 $\\beta_1$）和相应的几率比 $\\exp(\\beta_a)$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and applies a regularized logistic regression model\n    from first principles to a clinical prediction task.\n    \"\"\"\n\n    # Dataset: (age, sbp, hr, diabetes, ckd, mortality)\n    data = np.array([\n        [72, 110, 92, 1, 1, 1],\n        [55, 130, 78, 0, 0, 0],\n        [80, 100, 88, 1, 1, 1],\n        [45, 120, 70, 0, 0, 0],\n        [67, 115, 85, 0, 1, 1],\n        [60, 140, 75, 1, 0, 0],\n        [50, 125, 68, 0, 0, 0],\n        [76, 105, 95, 1, 1, 1],\n        [65, 110, 82, 1, 0, 0],\n        [58, 135, 80, 0, 0, 0],\n        [85, 98, 100, 1, 1, 1],\n        [70, 108, 90, 0, 1, 1]\n    ], dtype=float)\n\n    X_raw = data[:, :-1]\n    y_raw = data[:, -1]\n\n    def _logistic_func(eta):\n        \"\"\"Numerically stable logistic sigmoid function.\"\"\"\n        # p = 1 / (1 + exp(-eta))\n        p = np.empty_like(eta)\n        pos_mask = eta >= 0\n        neg_mask = ~pos_mask\n        p[pos_mask] = 1. / (1. + np.exp(-eta[pos_mask]))\n        exp_eta_neg = np.exp(eta[neg_mask])\n        p[neg_mask] = exp_eta_neg / (1. + exp_eta_neg)\n        return p\n\n    def _objective_function(X, y, beta, lambda_val):\n        \"\"\"Calculates the penalized negative log-likelihood.\"\"\"\n        eta = X @ beta\n        beta_penalized = beta.copy()\n        beta_penalized[0] = 0.0\n        \n        # Numerically stable calculation of log(1 + exp(eta))\n        log_likelihood_term = np.empty_like(eta)\n        pos_mask = eta >= 0\n        neg_mask = ~pos_mask\n        log_likelihood_term[pos_mask] = eta[pos_mask] + np.log(1. + np.exp(-eta[pos_mask]))\n        log_likelihood_term[neg_mask] = np.log(1. + np.exp(eta[neg_mask]))\n        \n        neg_log_likelihood = np.sum(log_likelihood_term - y * eta)\n        penalty = (lambda_val / 2.0) * np.sum(beta_penalized**2)\n        return neg_log_likelihood + penalty\n\n    def solve_logistic_newton(X, y, lambda_val, max_iter=100, tol=1e-8):\n        \"\"\"\n        Solves regularized logistic regression using Newton-Raphson with backtracking.\n        \"\"\"\n        n_samples, n_features = X.shape\n        beta = np.zeros(n_features)\n        \n        # Backtracking line search parameters\n        alpha_init = 1.0\n        c1 = 1e-4\n        tau = 0.5\n\n        for i in range(max_iter):\n            beta_old = beta.copy()\n\n            # Calculate probabilities, gradient, and Hessian\n            eta = X @ beta\n            p = _logistic_func(eta)\n            \n            # Gradient\n            beta_penalized = beta.copy()\n            beta_penalized[0] = 0.0\n            grad = X.T @ (p - y) + lambda_val * beta_penalized\n\n            # Hessian\n            W = np.diag(p * (1.0 - p))\n            hessian = X.T @ W @ X\n            hessian_penalty = np.diag(np.full(n_features, lambda_val))\n            hessian_penalty[0, 0] = 0.0\n            hessian += hessian_penalty\n\n            # Newton step direction\n            try:\n                step = np.linalg.solve(hessian, -grad)\n            except np.linalg.LinAlgError:\n                # Fallback to gradient descent if Hessian is singular\n                step = -grad\n\n            # Backtracking line search\n            alpha = alpha_init\n            obj_val = _objective_function(X, y, beta, lambda_val)\n            grad_dot_step = grad.T @ step\n            \n            while True:\n                beta_new = beta + alpha * step\n                obj_val_new = _objective_function(X, y, beta_new, lambda_val)\n                \n                # Check Armijo-Goldstein condition\n                if obj_val_new = obj_val + c1 * alpha * grad_dot_step or alpha  1e-9:\n                    break\n                alpha *= tau\n            \n            beta = beta_new\n\n            # Check for convergence\n            if np.linalg.norm(beta - beta_old)  tol:\n                break\n        \n        return beta\n\n    test_cases = [\n        {'lambda': 0.0, 'data': (X_raw, y_raw), 'collinear': False},\n        {'lambda': 0.1, 'data': (X_raw, y_raw), 'collinear': False},\n        {'lambda': 10.0, 'data': (X_raw, y_raw), 'collinear': False},\n        {'lambda': 1.0, 'data': (X_raw, y_raw), 'collinear': True},\n        {'lambda': 1.0, 'data': (X_raw[:6], y_raw[:6]), 'collinear': False},\n    ]\n\n    results = []\n    for case in test_cases:\n        lambda_val = case['lambda']\n        X_case_raw, y_case = case['data']\n        n_samples = X_case_raw.shape[0]\n\n        if case['collinear']:\n            age_col = X_case_raw[:, 0].reshape(-1, 1)\n            X_case_features = np.hstack([X_case_raw, age_col])\n        else:\n            X_case_features = X_case_raw\n\n        X = np.hstack([np.ones((n_samples, 1)), X_case_features])\n        \n        beta_solution = solve_logistic_newton(X, y_case, lambda_val)\n        \n        beta_age = beta_solution[1]  # Age is the first feature after intercept\n        odds_multiplier = np.exp(beta_age)\n        \n        results.append(round(beta_age, 6))\n        results.append(round(odds_multiplier, 6))\n\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "我们如何评价模型在预测结果方面的表现？回答这个问题需要可靠的评估指标，尤其是在处理时间事件数据时，因为部分患者的最终结局在研究期间内并未观察到（即“删失”）。本练习  将指导您实现Harrell's C-index，这是评估生存分析模型区分能力的关键指标，教您如何正确处理含有删失数据和时间平局的配对。",
            "id": "4853322",
            "problem": "在临床环境中，给定一个事件时间模型的预测结果，其中每位患者都有一个观测时间 $T_i$（单位任意）、一个事件指示符 $\\delta_i$（$\\delta_i = 1$ 表示临床事件发生，$\\delta_i = 0$ 表示观测值为右删失），以及一个模型产生的风险评分 $r_i$（$r_i$ 越大表示事件发生得越早的风险越高）。目标是实现一个程序，用于计算生存数据的 Harrell 一致性指数 (C-index)，并严格处理风险评分相同和数据删失的对。一致性指数 (C-index) 定义为：在所有可恰当比较的患者对中，其预测风险评分的排序与观测到的事件时间排序相匹配的患者对所占的比例，其中风险评分相同的对贡献 0.5 的分值。\n\n使用的基本依据：生存数据会产生右删失观测值，这将成对比较限制在那些观测时间较早的患者发生了事件（而非删失）的数据对上。两名患者 $i$ 和 $j$ 被认为是可比较的，当且仅当 $T_i  T_j$ 且 $\\delta_i = 1$，或者 $T_j  T_i$ 且 $\\delta_j = 1$。如果 $T_i = T_j$，那么无论 $\\delta_i$ 和 $\\delta_j$ 的值如何，该对都不可比较。对于每个可比较的对，其贡献如下：\n- 如果事件时间较早的患者具有严格更高的风险评分，则贡献为 $1$\n- 如果事件时间较早的患者具有严格更低的风险评分，则贡献为 $0$\n- 如果两个风险评分完全相等，则贡献为 $0.5$\n\n数据集的 Harrell C-指数计算方法为：所有成对贡献之和除以可比较对的数量。如果没有可比较的对，则返回 $0.0$ 作为哨兵值，表示无法从所提供的数据中评估区分度。\n\n实现一个程序，对下面的每个测试用例，按照上述规则计算 Harrell C-指数，并打印一行结果。该行结果包含所有计算值，以方括号括起来的逗号分隔列表形式呈现，每个值为保留小数点后四位的十进制数。\n\n测试套件（每个用例是一个 $(T, \\delta, r)$ 元组）：\n- 用例 1（混合事件与删失，风险评分基本有序）：\n  - $T = [10, 8, 12, 7, 14, 9]$\n  - $\\delta = [1, 1, 0, 1, 0, 1]$\n  - $r = [0.7, 0.8, 0.2, 0.9, 0.1, 0.6]$\n- 用例 2（完全有序，全部为事件）：\n  - $T = [5, 10, 15, 20, 25]$\n  - $\\delta = [1, 1, 1, 1, 1]$\n  - $r = [0.9, 0.8, 0.7, 0.6, 0.5]$\n- 用例 3（无可比较对，全部删失）：\n  - $T = [5, 10, 15]$\n  - $\\delta = [0, 0, 0]$\n  - $r = [0.5, 0.6, 0.7]$\n- 用例 4（事件时间和风险评分存在相同值，混合删失）：\n  - $T = [10, 10, 12, 12, 15]$\n  - $\\delta = [1, 1, 1, 0, 1]$\n  - $r = [0.5, 0.5, 0.7, 0.7, 0.4]$\n- 用例 5（逆序，全部为事件）：\n  - $T = [5, 8, 12, 20]$\n  - $\\delta = [1, 1, 1, 1]$\n  - $r = [0.1, 0.2, 0.3, 0.4]$\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个值都精确到小数点后四位（例如 $[0.9286,1.0000,0.0000,0.4286,0.0000]$）。无需用户输入。不涉及物理单位。所有结果均以小数表示，而非百分比。",
            "solution": "该问题要求为右删失生存数据实现 Harrell 一致性指数 (C-index)。这是评估预测事件时间结果模型区分度的标准度量。在进行求解之前，需要对问题陈述进行正式验证。\n\n### 步骤 1：提取给定信息\n问题提供了以下数据和定义：\n-   **输入数据**：对于每位患者 $i$，我们给定：\n    -   观测时间 $T_i$。\n    -   事件指示符 $\\delta_i$，其中 $\\delta_i = 1$ 表示事件发生，$\\delta_i = 0$ 表示右删失。\n    -   模型生成的风险评分 $r_i$，其中值越高表示风险越高。\n-   **可比较对的定义**：一对患者 $(i, j)$ 是可比较的，当且仅当观测时间较早的患者发生了事件。形式上，这意味着 ($T_i  T_j$ 且 $\\delta_i = 1$) 或 ($T_j  T_i$ 且 $\\delta_j = 1$)。事件时间相同 ($T_i = T_j$) 的对不可比较。\n-   **可比较对的评分**：对于一个可比较对：\n    -   如果事件时间较早的患者风险评分严格更高，则得分为 $1$。这是一致对。\n    -   如果事件时间较早的患者风险评分严格更低，则得分为 $0$。这是不一致对。\n    -   如果风险评分完全相等，则得分为 $0.5$。这是评分相同的对。\n-   **C-指数计算**：C-指数是所有可比较对的得分之和除以可比较对的总数。\n-   **边界情况**：如果没有可比较的对，C-指数定义为 $0.0$。\n-   **测试套件**：提供了五个测试用例，每个用例都包含 $T$、$\\delta$ 和 $r$ 的数组。\n-   **输出格式**：单行输出，包含一个用方括号括起来的逗号分隔列表，其中是每个测试用例的 C-指数值，格式化为四位小数。\n\n### 步骤 2：使用提取的给定信息进行验证\n根据验证标准对问题陈述进行评估。\n-   **科学性**：该问题描述了 Harrell C-指数，这是生存分析中评估预后模型区分能力的一项基石性指标。可比较对（考虑了删失）的定义以及一致、不一致和评分相同的评分规则在生物统计学和医学信息学领域是标准且正确的。该问题具有科学合理性。\n-   **良构性**：所提供的规则是明确且无歧义的。它们定义了一个清晰的算法，对于任何给定的有效输入数据集 ($T, \\delta, r$)，都能产生一个唯一的数值结果。对零可比较对（除以零）情况的明确处理确保了问题的良构性。\n-   **客观性**：问题陈述使用了精确的数学定义和算法规则，没有任何主观或模棱两可的语言。\n-   **完整性和一致性**：所有必要的组成部分（数据结构、定义、计算规则、边界情况处理）都已提供。没有矛盾之处。例如，明确规定 $T_i = T_j$ 的对不可比较，避免了歧义。\n-   **真实性和可行性**：测试用例中提供的数据是简单的数值数组，完全可以作为临床研究和预测模型的输出。该任务在计算上是可行的。\n\n### 步骤 3：结论与行动\n问题陈述是有效的。它具有科学性、良构性、客观性和完整性。我现在将进行完整解答。\n\n解决方案涉及对给定数据集中的所有患者进行系统的成对比较。设患者数量为 $N$。我们必须考虑每个唯一的患者对 $(i, j)$，其中 $0 \\le i  j  N$。对于每一对，我们确定它们是否可比较，如果是，则计算它们对 C-指数的贡献。\n\n设 $C_{total}$ 为可比较对的数量，$S_{concordant}$ 为得分总和。初始时，两者都设置为 $0$。\n\n算法流程如下：\n1.  初始化 $C_{total} = 0$ 和 $S_{concordant} = 0.0$。\n2.  遍历所有患者对 $(i, j)$，其中 $i$ 的范围从 $0$ 到 $N-2$，$j$ 的范围从 $i+1$ 到 $N-1$。\n3.  对于每一对 $(i, j)$，获取他们的观测时间 ($T_i, T_j$)、事件指示符 ($\\delta_i, \\delta_j$) 和风险评分 ($r_i, r_j$)。\n4.  应用可比较性规则：\n    a. 如果 $T_i  T_j$ 且 $\\delta_i = 1$，则该对可比较。事件较早的患者是 $i$。\n    b. 如果 $T_j  T_i$ 且 $\\delta_j = 1$，则该对可比较。事件较早的患者是 $j$。\n    c. 如果 $T_i = T_j$，则该对不可比较。\n    d. 如果 $T_i  T_j$ 但 $\\delta_i = 0$，则该对不可比较。\n    e. 如果 $T_j  T_i$ 但 $\\delta_j = 0$，则该对不可比较。\n5.  如果一对被确定为可比较的：\n    a. 增加可比较对的计数：$C_{total} = C_{total} + 1$。\n    b. 设事件较早的患者为 $u$，另一位患者为 $v$。我们比较他们的风险评分 $r_u$ 和 $r_v$。\n    c. 如果 $r_u > r_v$ (一致)，则将得分总和加 $1.0$：$S_{concordant} = S_{concordant} + 1.0$。\n    d. 如果 $r_u  r_v$ (不一致)，则将得分总和加 $0.0$：$S_{concordant} = S_{concordant} + 0.0$。\n    e. 如果 $r_u = r_v$ (风险评分相同)，则将得分总和加 $0.5$：$S_{concordant} = S_{concordant} + 0.5$。\n6.  遍历所有对之后，计算 C-指数。\n    a. 如果 $C_{total} > 0$，则 C-指数为 $I_C = \\frac{S_{concordant}}{C_{total}}$。\n    b. 如果 $C_{total} = 0$，则 C-指数定义为 $0.0$。\n\n该算法通过详尽地检查所有对，根据删失数据的规则正确识别可比较对，并对其进行适当评分，从而正确实现了 Harrell C-指数的指定定义。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_c_index(T, delta, r):\n    \"\"\"\n    Computes Harrell's Concordance Index (C-index) for survival data.\n\n    Args:\n        T (list or np.ndarray): Observed times for each patient.\n        delta (list or np.ndarray): Event indicators (1=event, 0=censored).\n        r (list or np.ndarray): Predicted risk scores (higher value means higher risk).\n\n    Returns:\n        float: The calculated C-index.\n    \"\"\"\n    T = np.asarray(T, dtype=np.float64)\n    delta = np.asarray(delta, dtype=np.int32)\n    r = np.asarray(r, dtype=np.float64)\n\n    n_patients = len(T)\n    if n_patients  2:\n        return 0.0\n\n    comparable_pairs_count = 0\n    concordant_sum = 0.0\n\n    for i in range(n_patients):\n        for j in range(i + 1, n_patients):\n            # Extract data for the pair (i, j)\n            T_i, delta_i, r_i = T[i], delta[i], r[i]\n            T_j, delta_j, r_j = T[j], delta[j], r[j]\n\n            # Rule: Pairs with tied event times are not comparable.\n            if T_i == T_j:\n                continue\n\n            # Determine if the pair is comparable based on censoring rules\n            # and identify the patient with the earlier event.\n            is_comparable = False\n            earlier_event_patient_risk = 0\n            other_patient_risk = 0\n\n            if T_i  T_j and delta_i == 1:\n                # Patient i has an event before patient j's observation\n                is_comparable = True\n                earlier_event_patient_risk = r_i\n                other_patient_risk = r_j\n            elif T_j  T_i and delta_j == 1:\n                # Patient j has an event before patient i's observation\n                is_comparable = True\n                earlier_event_patient_risk = r_j\n                other_patient_risk = r_i\n            \n            # If the pair is comparable, score it.\n            if is_comparable:\n                comparable_pairs_count += 1\n                \n                # Concordant: earlier event has higher risk score\n                if earlier_event_patient_risk > other_patient_risk:\n                    concordant_sum += 1.0\n                # Tied risk scores\n                elif earlier_event_patient_risk == other_patient_risk:\n                    concordant_sum += 0.5\n                # Discordant: earlier event has lower risk score (add 0.0)\n\n    # Calculate C-index\n    if comparable_pairs_count == 0:\n        return 0.0\n    else:\n        return concordant_sum / comparable_pairs_count\n\ndef solve():\n    \"\"\"\n    Runs the C-index calculation for all provided test cases and prints the results.\n    \"\"\"\n    # Test cases defined in the problem statement\n    test_cases = [\n        # Case 1\n        (\n            [10, 8, 12, 7, 14, 9],\n            [1, 1, 0, 1, 0, 1],\n            [0.7, 0.8, 0.2, 0.9, 0.1, 0.6]\n        ),\n        # Case 2\n        (\n            [5, 10, 15, 20, 25],\n            [1, 1, 1, 1, 1],\n            [0.9, 0.8, 0.7, 0.6, 0.5]\n        ),\n        # Case 3\n        (\n            [5, 10, 15],\n            [0, 0, 0],\n            [0.5, 0.6, 0.7]\n        ),\n        # Case 4\n        (\n            [10, 10, 12, 12, 15],\n            [1, 1, 1, 0, 1],\n            [0.5, 0.5, 0.7, 0.7, 0.4]\n        ),\n        # Case 5\n        (\n            [5, 8, 12, 20],\n            [1, 1, 1, 1],\n            [0.1, 0.2, 0.3, 0.4]\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        T, delta, r = case\n        c_index = calculate_c_index(T, delta, r)\n        results.append(f\"{c_index:.4f}\")\n\n    # Print the final output in the required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}