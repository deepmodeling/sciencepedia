{
    "hands_on_practices": [
        {
            "introduction": "为了有效地设计和分析联邦学习系统，我们首先必须理解其基本的计算结构。本练习  提供了一个量化联邦平均（FedAvg）算法核心操作的基础实践。通过推导本地梯度更新总数和全局通信轮数的表达式，您将对计算和通信在联邦网络中的分布情况有一个清晰的认识。",
            "id": "4840326",
            "problem": "一个由 $K$ 家医院组成的医学信息学联盟，旨在使用联邦平均 (Federated Averaging, FedAvg) 进行隐私保护分析，在不集中患者信息的情况下，对电子健康记录 (Electronic Health Record, EHR) 数据训练一个预测模型。医院 $i$ 在本地存储了 $N_{i}$ 条患者记录。在 FedAvg 中，一个中央服务器协调 $R$ 轮全局训练。在每一轮全局训练中，服务器将当前模型广播给所有 $K$ 家医院，每家医院使用大小为 $B$ 的小批量随机梯度下降法在本地训练 $E$ 个周期 (epoch)，然后每家医院将其更新后的模型返回给服务器，服务器对它们进行聚合。\n\n从以下基本定义出发：客户端 $i$ 上的一个周期 (epoch) 是对其 $N_{i}$ 条记录的一次完整遍历；对于从本地数据集中形成的每个小批量，都会执行一次小批量梯度步长（允许最后一个小批量小于 $B$ 且仍计为一步），请推导以下各项的封闭形式表达式：\n- 在所有 $R$ 轮全局训练中，所有医院执行的本地梯度步长的总数，以及\n- 在整个训练过程中，服务器与医院之间发生的通信轮次总数。\n\n用 $K$、$E$、$B$、$R$ 和 $\\{N_{i}\\}_{i=1}^{K}$ 符号化地表示您的最终答案。无需四舍五入。请使用 LaTeX 的 $\\texttt{pmatrix}$ 环境将两个量表示为单行矩阵。",
            "solution": "在尝试求解之前，应首先对问题陈述进行严格的验证过程。\n\n### 第1步：提取已知条件\n问题陈述中逐字提供了以下数据和定义：\n-   医院数量：$K$\n-   医院 $i$ 的患者记录数：$N_{i}$，其中 $i$ 是从 $1$ 到 $K$ 的索引\n-   全局训练总轮数：$R$\n-   每轮全局训练的本地周期数：$E$\n-   随机梯度下降 (SGD) 的小批量大小：$B$\n-   周期的定义：“对其 $N_{i}$ 条记录的一次完整遍历”\n-   梯度步长的条件：“对于从本地数据集中形成的每个小批量，都会执行一次小批量梯度步长”\n-   最后一个小批量的条件：“允许最后一个小批量小于 $B$ 且仍计为一步”\n-   要求输出：\n    1.  本地梯度步长总数的封闭形式表达式。\n    2.  通信轮次总数的封闭形式表达式。\n\n### 第2步：使用提取的已知条件进行验证\n根据所需标准对问题进行评估：\n-   **科学依据：** 问题描述了联邦平均 (FedAvg) 算法，这是联邦学习领域中一个成熟的、经典的方法。其在医学信息学中用于隐私保护分析是一个主要且现实的用例。该设置在科学上是合理的。\n-   **适定性：** 这是一个适定问题。所有变量（$K$、$R$、$E$、$B$、$\\{N_{i}\\}_{i=1}^{K}$）都有定义。计算梯度步长的过程有明确详细的说明，包括处理最后一个可能较小的小批量。这一细节明确地暗示了向上取整函数的使用。术语“通信轮次”在联邦学习的语境中被理解为与“全局轮次”或“聚合周期”同义。问题是自包含的，并提供了足够的信息来为所求量推导出唯一且有意义的表达式。\n-   **客观性：** 问题以清晰、精确、无歧义的技术语言陈述。它不含任何主观或基于观点的内容。\n\n该问题没有表现出任何列举的缺陷（例如，科学上不合理、不完整、矛盾、模棱两可）。它是一个植根于成熟的计算机科学和机器学习原理的可形式化、可解决的问题。\n\n### 第3步：结论与行动\n问题有效。现在将提供一个完整且合理的解决方案。\n\n### 解题推导\n\n问题要求推导两个量：本地梯度步长的总数和通信轮次的总数。每个量都将根据所提供的定义进行推导。\n\n**1. 本地梯度步长总数**\n\n我们首先确定单个医院（指定为医院 $i$）在单个本地训练周期内执行的梯度步长数。\n-   医院 $i$ 拥有一个大小为 $N_i$ 的本地数据集。\n-   本地训练使用小批量大小为 $B$ 的小批量 SGD 进行。\n-   每个小批量执行一次梯度下降步长。\n-   问题指明最后一个小批量可能小于 $B$。这意味着记录总数 $N_i$被划分为尽可能多的、大小为 $B$ 的完整批次，余下的记录形成最后一个批次。\n-   因此，处理 $N_i$ 条记录所需的批次数是记录总数除以批量大小，并向上取整。这个操作由向上取整函数表示。\n-   医院 $i$ 每个周期的梯度步长数：$\\lceil \\frac{N_i}{B} \\rceil$。\n\n接下来，我们计算医院 $i$ 在一轮全局训练中的总梯度步长数。\n-   在每一轮全局训练中，每家医院训练 $E$ 个本地周期。\n-   由于对于给定的医院，每个周期的步长数是恒定的，因此医院 $i$ 在一轮全局训练中的总步长数是 $E$ 乘以每个周期的步长数。\n-   医院 $i$ 每轮全局训练的梯度步长数：$E \\times \\lceil \\frac{N_i}{B} \\rceil$。\n\n现在，我们可以计算在一轮全局训练中所有医院的总梯度步长数。\n-   联盟中有 $K$ 家医院。\n-   一轮全局训练的总步长数是每家医院所采取步长数的总和。\n-   每轮全局训练的总步长数：$\\sum_{i=1}^{K} \\left( E \\times \\lceil \\frac{N_i}{B} \\rceil \\right) = E \\sum_{i=1}^{K} \\lceil \\frac{N_i}{B} \\rceil$。\n\n最后，我们确定整个训练过程中的本地梯度步长总数。\n-   整个过程包括 $R$ 轮全局训练。\n-   梯度步长的总数是每轮全局训练的步长数乘以全局训练的总轮数。\n-   设 $S_{total}$ 为本地梯度步长的总数。\n$$S_{total} = R \\times \\left( E \\sum_{i=1}^{K} \\lceil \\frac{N_i}{B} \\rceil \\right) = R E \\sum_{i=1}^{K} \\lceil \\frac{N_i}{B} \\rceil$$\n这是第一个要求的表达式。\n\n**2. 通信轮次总数**\n\n第二个任务是确定通信轮次的总数。\n-   问题描述了单个“全局轮次”内的一系列事件：\n    1.  中央服务器将当前全局模型广播给所有 $K$ 家医院。\n    2.  医院执行本地训练。\n    3.  每家医院将其更新后的模型返回给服务器进行聚合。\n-   这一完整的广播、本地计算和聚合周期构成了 FedAvg 协议中服务器与客户端之间交互的基本单元。在联邦学习的标准术语中，这个周期被定义为一个“通信轮次”。\n-   问题陈述了训练过程总共进行 $R$ 轮全局训练。\n-   因此，根据定义，通信轮次的总数等于全局训练的总轮数。\n-   设 $C_{total}$ 为通信轮次的总数。\n$$C_{total} = R$$\n这是第二个要求的表达式。\n\n最终答案按要求将这两个结果合并为一个单行矩阵。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} R E \\sum_{i=1}^{K} \\lceil \\frac{N_i}{B} \\rceil  R \\end{pmatrix} } $$"
        },
        {
            "introduction": "尽管联邦学习避免了原始数据的集中化，但交换大型模型更新可能会造成严重的通信瓶颈。这个实践问题  通过计算一个大型诊断模型所需的通信时间，来探讨这一关键的现实世界挑战。它还展示了像量化这样的技术如何能显著减少这种开销，从而使大规模联邦训练变得可行。",
            "id": "4840332",
            "problem": "一个医院联合体正在使用联邦学习中的标准算法——联邦平均（FedAvg）——来训练一个共享诊断模型，通过将数据保留在本地来保护患者隐私。在每个通信轮次中，每家医院都将其本地模型更新传输给协调器，然后接收聚合后的全局模型。假设模型有 $d=10^{7}$ 个可训练参数，并且一次传输更新的大小等于参数向量的大小。考虑两种参数编码方案：每个参数使用 $32$ 位的单精度浮点数，以及每个参数使用 $8$ 位的均匀量化。每家医院可用的网络链路速度为 $100$ 兆比特每秒，其中一兆比特等于 $10^{6}$ 比特。\n\n从数据大小和吞吐量的核心定义（数据大小以比特为单位，吞吐量以比特每秒为单位，时间等于数据大小除以速率）出发，推导在两种编码方案下，每家医院每轮的总通信时间（上传加下载）。假设没有压缩，没有协议开销，并且协调器发回的模型大小与医院发送的更新大小相同。\n\n判断在每轮 $2\\,\\mathrm{s}$ 的真实时间预算下，每种方案是否可行，其中可行性定义为每轮总通信时间小于或等于 $2\\,\\mathrm{s}$。\n\n将最终的数值时间四舍五入到四位有效数字，并以秒为单位表示。以行矩阵的形式提供最终答案，其中第一个元素等于 $32$ 位方案的时间，第二个元素等于 $8$ 位方案的时间。",
            "solution": "首先根据所需标准对问题进行验证。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   模型参数数量：$d = 10^7$\n-   编码方案 1（单精度）：$b_{32} = 32$ 比特/参数\n-   编码方案 2（量化）：$b_8 = 8$ 比特/参数\n-   网络链路速度（吞吐量）：$R = 100$ 兆比特/秒，其中 $1$ 兆比特 $= 10^6$ 比特。\n-   通信轮次结构：每家医院执行一次上传和一次下载。\n-   下载模型的大小：与上传的模型更新相同。\n-   假设：无压缩，无协议开销。\n-   可行性预算：每轮总通信时间 $\\le T_{budget} = 2\\,\\mathrm{s}$。\n-   计算基础：时间 = 数据大小 / 吞吐量。\n-   四舍五入要求：最终时间需四舍五入至四位有效数字。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题在科学上基于计算机网络和联邦学习的原理。该场景是联邦学习在医学信息学中的一个标准应用。所提供的参数（$10^7$ 个参数、$100\\,\\mathrm{Mbps}$ 链路、$32$ 位和 $8$ 位编码）在现代机器学习和网络基础设施中是现实的数值。该问题是适定的，提供了计算唯一解所需的所有必要信息和清晰、客观的定义（例如，$1$ 兆比特 $= 10^6$ 比特）。它没有科学缺陷、歧义或矛盾。\n\n**步骤 3：结论与行动**\n该问题被认为是有效的。将提供一个解决方案。\n\n### 解题推导\n\n分析首先为每种编码方案定义单个通信轮次中要传输的总数据大小。然后，使用给定的网络吞吐量，计算此传输所需的时间。最后，将此时间与指定的可行性预算进行比较。\n\n设 $d$ 为模型中可训练参数的数量。\n设 $b$ 为用于编码每个参数的比特数。\n模型更新的大小 $S$（以比特为单位）由参数数量和每参数比特数的乘积给出：\n$$S = d \\times b$$\n\n网络链路速度 $R$ 给定为 $100$ 兆比特每秒。使用提供的定义，即：\n$$R = 100 \\times 10^6 \\frac{\\mathrm{bits}}{\\mathrm{second}} = 10^8 \\frac{\\mathrm{bits}}{\\mathrm{second}}$$\n\n一家医院的单个通信轮次包括一次向协调器上传模型更新和一次从协调器下载聚合的全局模型。问题陈述下载的模型与上传的更新大小相同。因此，每家医院每轮传输的总数据量 $S_{total}$ 是单个更新大小的两倍：\n$$S_{total} = S_{upload} + S_{download} = S + S = 2S$$\n\n一轮的总时间 $T_{round}$ 是总数据大小除以网络链路速度：\n$$T_{round} = \\frac{S_{total}}{R} = \\frac{2S}{R} = \\frac{2db}{R}$$\n\n我们现在为两种编码方案计算这个时间。\n\n**方案 1：单精度浮点（$32$ 位）**\n\n在这种情况下，每参数的比特数是 $b_{32} = 32$。\n参数数量为 $d = 10^7$。\n单个模型更新的大小是：\n$$S_{32} = d \\times b_{32} = 10^7 \\times 32 = 3.2 \\times 10^8 \\text{ bits}$$\n\n每轮总通信时间 $T_{round, 32}$ 是：\n$$T_{round, 32} = \\frac{2 S_{32}}{R} = \\frac{2 \\times (3.2 \\times 10^8 \\text{ bits})}{10^8 \\text{ bits/s}} = 2 \\times 3.2\\,\\mathrm{s} = 6.4\\,\\mathrm{s}$$\n\n问题要求四舍五入到四位有效数字。因此，$T_{round, 32} = 6.400\\,\\mathrm{s}$。\n\n**方案 1 的可行性检查：**\n可行性预算为 $T_{budget} = 2\\,\\mathrm{s}$。\n我们比较计算出的时间：$6.400\\,\\mathrm{s}  2\\,\\mathrm{s}$。\n因此，在给定约束下，$32$ 位编码方案是**不可行的**。\n\n**方案 2：均匀量化（$8$ 位）**\n\n在这种情况下，每参数的比特数是 $b_8 = 8$。\n参数数量为 $d = 10^7$。\n单个模型更新的大小是：\n$$S_8 = d \\times b_8 = 10^7 \\times 8 = 8 \\times 10^7 \\text{ bits}$$\n\n每轮总通信时间 $T_{round, 8}$ 是：\n$$T_{round, 8} = \\frac{2 S_8}{R} = \\frac{2 \\times (8 \\times 10^7 \\text{ bits})}{10^8 \\text{ bits/s}} = 2 \\times 0.8\\,\\mathrm{s} = 1.6\\,\\mathrm{s}$$\n\n问题要求四舍五入到四位有效数字。因此，$T_{round, 8} = 1.600\\,\\mathrm{s}$。\n\n**方案 2 的可行性检查：**\n可行性预算为 $T_{budget} = 2\\,\\mathrm{s}$。\n我们比较计算出的时间：$1.600\\,\\mathrm{s} \\le 2\\,\\mathrm{s}$。\n因此，在给定约束下，$8$ 位编码方案是**可行的**。\n\n最终答案要求将两个计算出的时间（以秒为单位并四舍五入到四位有效数字）以行矩阵的形式呈现。\n$32$ 位方案的时间是 $6.400\\,\\mathrm{s}$。\n$8$ 位方案的时间是 $1.600\\,\\mathrm{s}$。\n该行矩阵为 $\\begin{pmatrix} 6.400  1.600 \\end{pmatrix}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n6.400  1.600\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "在联邦学习中加入像差分隐私（DP）这样的形式化隐私保证，涉及到具有深远权衡的关键架构决策。本练习  在一个医疗联盟的背景下，对比了两种主流范式：本地差分隐私和中央差分隐私。通过分析它们在不同信任假设下的特性，您将学会如何在隐私保证、模型效用和系统稳健性之间进行复杂的权衡。",
            "id": "4840335",
            "problem": "在一个应用联邦学习（FL）的医院联盟中， $n$ 个站点各自在其电子健康记录队列上计算一个裁剪后的局部梯度 $g_i \\in \\mathbb{R}^d$ ，并参与安全聚合（SA）。安全聚合是一种密码学协议，它只向服务器揭示精确的向量和 $G = \\sum_{i=1}^{n} g_i$ ，而隐藏所有单独的 $g_i$ 。为了保护患者级别的信息，考虑了两种隐私设计：一种是本地差分隐私（LDP）设计，另一种是中心化差分隐私设计。该联盟必须根据对SA的不同信任假设以及随机化的位置来决定哪种设计是合适的。\n\n您可以假设以下经过充分检验的基本事实和定义：\n\n- 对于一个作用于数据集上的随机化机制 $M$ ，其差分隐私（DP）定义为：对于任意一对仅相差1个个体记录的相邻数据集 $D$ 和 $D'$ ，以及任意可测集 $S$ ，如果满足以下条件，则该机制满足 $(\\epsilon,\\delta)$-DP：\n$$\n\\Pr[M(D) \\in S] \\le e^{\\epsilon} \\Pr[M(D') \\in S] + \\delta.\n$$\n- 本地差分隐私（LDP）是一种特殊情况，其中每个客户端在任何管理者看到其输入 $x_i$ 之前，都对其应用一个随机化机制 $M_i$ ；相邻关系定义在同一客户端的两个可能输入 $x_i$ 和 $x_i'$ 上。\n- 中心化差分隐私（central DP）是一种情况，其中管理者持有聚合数据集（或统计量），并集中应用单个随机化机制 $M$ 来保护全局数据集中任何单个个体的贡献；相邻关系定义在相差1条记录的数据集 $D$ 和 $D'$ 上。\n- 安全聚合（SA）是一种密码学协议，确保只向服务器透露 $G$ ，而不透露任何单个 $g_i$ ；SA本身不是一种DP机制，但它可以是一个受信任的组件，用以限制攻击者可以观察到的内容。\n- 后处理不变性：如果一个机制 $M$ 满足 $(\\epsilon,\\delta)$-DP，那么对于任何数据无关的函数 $f$ ，复合输出 $f(M(\\cdot))$ 也满足 $(\\epsilon,\\delta)$-DP。\n- 对于独立的加性噪声向量，方差在求和下相加：如果 $\\tilde{g}_i = g_i + Z_i$ ，其中 $Z_i$ 是独立的零均值、协方差为 $\\Sigma_i$ 的噪声，那么总噪声 $Z = \\sum_{i=1}^{n} Z_i$ 的协方差为 $\\sum_{i=1}^{n} \\Sigma_i$ 。\n- 裁剪后总和的敏感度：如果每个 $g_i$ 都被裁剪以使 $\\|g_i\\|_2 \\le C$ ，那么用 $g_j'$ 替换任何单个 $g_j$ 会使 $G$ 的变化量最多为 $\\|g_j - g_j'\\|_2 \\le 2C$ ，因此 $G$ 的 $\\ell_2$-敏感度是有界的。\n\n提出了两个方案：\n\n- 方案 L（本地 DP）：每个客户端对其梯度应用一个 $(\\epsilon_L,\\delta_L)$-LDP机制，在本地生成 $\\tilde{g}_i = M_i(g_i)$ ，然后使用SA来求和 $\\tilde{G} = \\sum_{i=1}^{n} \\tilde{g}_i$ 。\n- 方案 C（中心化 DP）：每个客户端将其真实的 $g_i$ 输入到SA中，SA只向管理者揭示 $G$ ；管理者对 $G$ 应用一个 $(\\epsilon_C,\\delta_C)$-DP机制 $M$ ，以生成一个发布的聚合结果 $\\hat{G} = M(G)$ 。\n\n假设存在一个诚实但好奇的攻击者，他可以观察到服务器所能看到的一切，并考虑两种情况：SA受信任（它只揭示 $G$ 而从不揭示单个 $g_i$ ）和SA发生灾难性故障（单个 $g_i$ 被揭示给服务器）。\n\n在這種联邦学习设置中，以下哪些陈述正确地对比了本地DP和中心化DP？\n\nA. 如果SA发生灾难性故障，导致服务器在方案L中看到每个 $\\tilde{g}_i$ ，在方案C中看到每个原始 $g_i$ ，那么方案L仍然为每个客户端的数据提供针对服务器的 $(\\epsilon_L,\\delta_L)$ 保证，而方案C则不提供任何DP保证，因为在聚合之前没有进行任何随机化。\n\nB. 在受信任的SA下，方案C可以在聚合 $G$ 的层面上实现一个目标 $(\\epsilon_C,\\delta_C)$ ，同时只需在中心添加一次随机噪声，这通常比方案L在相同隐私目标下产生更高的效用，因为方案L中独立的客户端侧噪声会在聚合时跨 $n$ 个参与者累积。\n\nC. 在方案L中，用于 $(\\epsilon_L,\\delta_L)$ 保证的相邻关系是定义在跨所有客户端相差1个个体的全局数据集 $D$ 和 $D'$ 上，而不是在单个客户端的两个可能输入上。\n\nD. 在方案C和受信任的SA下，SA内部使用的加密和掩码随机性就是使发布结果满足 $(\\epsilon_C,\\delta_C)$-DP的随机性；管理者不需要向 $G$ 添加任何进一步的随机化。\n\nE. 在方案L中，即使每个客户端的机制单独满足 $(\\epsilon_L,\\delta_L)$-LDP，单轮发布 $\\tilde{g}_1, \\ldots, \\tilde{g}_n$ 也会因组合效应导致每个客户端的隐私参数线性地随 $n$ 退化。\n\n选择所有适用的选项。",
            "solution": "首先必须验证问题陈述的科学正确性、逻辑一致性和客观性。\n\n### 步骤1：提取已知条件\n问题提供了以下信息：\n- 一个由 $n$ 家医院组成的联邦学习联盟。\n- 每个站点 $i$ 计算一个裁剪后的局部梯度 $g_i \\in \\mathbb{R}^d$ ，使得 $\\|g_i\\|_2 \\le C$。\n- 安全聚合（SA）是一种密码学协议，它只向服务器揭示总和 $G = \\sum_{i=1}^{n} g_i$ ，并隐藏单个 $g_i$。\n- 差分隐私（DP）定义：对于一个机制 $M$ 、相邻数据集 $D, D'$ 以及任意可测集 $S$ ，$\\Pr[M(D) \\in S] \\le e^{\\epsilon} \\Pr[M(D') \\in S] + \\delta$。\n- 本地差分隐私（LDP）是一种特殊情况，其中客户端使用机制 $M_i$ 对其自己的输入 $x_i$ 进行随机化。相邻关系是针对同一客户端的两个可能输入 $x_i, x_i'$。\n- 中心化差分隐私（central DP）是一种情况，其中管理者应用机制 $M$ 于一个聚合结果。相邻关系是针对相差一个记录的全局数据集 $D, D'$。\n- SA不是DP机制，但可以是一个受信任的组件。\n- 后处理不变性：对一个DP保护的输出应用一个数据无关的函数 $f$ 不会降低隐私性。\n- 对于独立的加性噪声向量 $Z_i$ （零均值，协方差为 $\\Sigma_i$），它们被加到 $g_i$ 上，总噪声 $Z = \\sum_{i=1}^{n} Z_i$ 的协方差为 $\\sum_{i=1}^{n} \\Sigma_i$。\n- 总和 $G$ 对于更改一个客户端贡献的 $\\ell_2$-敏感度上限为 $2C$。\n- 方案L（本地 DP）：每个客户端通过一个 $(\\epsilon_L, \\delta_L)$-LDP机制计算 $\\tilde{g}_i = M_i(g_i)$。然后使用SA计算 $\\tilde{G} = \\sum_{i=1}^{n} \\tilde{g}_i$。\n- 方案C（中心化 DP）：客户端将其真实的 $g_i$ 提供给SA。SA向管理者提供 $G = \\sum_{i=1}^{n} g_i$。管理者使用一个 $(\\epsilon_C, \\delta_C)$-DP机制计算发布的聚合结果 $\\hat{G} = M(G)$。\n- 攻击者是诚实但好奇的，并观察服务器所看到的一切。\n- 考虑两种威胁模型：（1）SA受信任且按规定工作。（2）SA发生灾难性故障，将其所有输入都透露给服务器。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在科学上和逻辑上都是合理的。\n- **科学依据**：问题基于隐私保护机器学习中的基本和标准概念，即联邦学习、差分隐私（本地和中心化模型）以及安全聚合。所提供的定义和属性（DP、LDP、SA、后处理、噪声求和、敏感度）都是该领域中正确且公认的。\n- **问题定义明确**：问题是明确的。它提出了两个清晰定义的方案（方案L和方案C），并要求在不同的信任假设下对它们的属性进行比较分析。问题的结构旨在测试对这些概念的理解，并且可以根据所提供的定义对给定的陈述进行明确的评估。\n- **客观性**：语言精确、正式，没有主观性。所有关键术语都已明确定义。\n\n该问题没有表现出任何诸如科学不合理、信息缺失、矛盾、不可行性或模糊性等缺陷。这个设置是讨论FL中隐私问题的典型场景。\n\n### 步骤3：结论和行动\n问题陈述有效。我将继续分析每个选项。\n\n### 解决方案与逐项分析\n\n**A. 如果SA发生灾难性故障，导致服务器在方案L中看到每个 $\\tilde{g}_i$ ，在方案C中看到每个原始 $g_i$ ，那么方案L仍然为每个客户端的数据提供针对服务器的 $(\\epsilon_L,\\delta_L)$ 保证，而方案C则不提供任何DP保证，因为在聚合之前没有进行任何随机化。**\n\n- **对方案L在SA故障下的分析**：在方案L中，每个客户端 $i$ 对其梯度 $g_i$ 应用一个本地随机化机制 $M_i$ 以产生 $\\tilde{g}_i$。这种随机化是在客户端设备上本地执行的，在任何数据发送之前。根据定义，机制 $M_i$ 满足 $(\\epsilon_L, \\delta_L)$-LDP。这个保证是相对于客户端自身数据而言的。如果SA发生故障，服务器观察到 $\\tilde{g}_i$，服务器看到的是一个已经随机化的值。LDP保证意味着观察 $\\tilde{g}_i$ 只能提供关于原始 $g_i$ 的有限信息。因此，每个客户端的隐私都受到 $(\\epsilon_L,\\delta_L)$-DP级别的保护，以抵御服务器的攻击。\n\n- **对方案C在SA故障下的分析**：在方案C中，客户端将其精确的、未随机化的梯度 $g_i$ 发送到SA协议。整个隐私保证依赖于两个组件：（1）SA协议成功隐藏单个 $g_i$ 并只揭示总和 $G$，以及（2）管理者随后向 $G$ 添加噪声。如果SA发生灾难性故障，服务器会看到原始梯度 $\\{g_1, g_2, \\ldots, g_n\\}$。由于此时没有发生任何随机化，服务器可以访问每个客户端的精确、未受保护的贡献。这构成了一次彻底的隐私泄露；没有任何DP保证。\n\n- **结论**：该陈述正确且基础性地比较了本地DP与中心化DP中的信任模型。LDP对于中央服务器或聚合器的故障具有鲁棒性，而中心化DP则严重依赖于它们。**正确**。\n\n**B. 在受信任的SA下，方案C可以在聚合 $G$ 的层面上实现一个目标 $(\\epsilon_C,\\delta_C)$ ，同时只需在中心添加一次随机噪声，这通常比方案L在相同隐私目标下产生更高的效用，因为方案L中独立的客户端侧噪声会在聚合时跨 $n$ 个参与者累积。**\n\n- **对方案C噪声的分析**：在方案C中，受信任的管理者接收到精确的总和 $G = \\sum_{i=1}^{n} g_i$。为了使这个发布满足 $(\\epsilon_C, \\delta_C)$-DP，管理者会添加噪声。例如，使用高斯机制，噪声的标准差与 $G$ 的 $\\ell_2$-敏感度成正比。问题指出这个敏感度的上限为 $2C$。因此，所添加噪声的方差与 $(2C)^2 = 4C^2$ 成正比。噪声只添加一次。\n\n- **对方案L噪声的分析**：在方案L中， $n$ 个客户端中的每一个都向其本地梯度 $g_i$ 添加噪声以实现 $(\\epsilon_L, \\delta_L)$-LDP。每个客户端 $g_i$ 的敏感度是 $C$ （因为 $\\|g_i\\|_2 \\le C$）。每个客户端添加的噪声，比如 $Z_i$，必须足够大以掩盖这种幅度的变化。假设每个 $Z_i$ 的方差为 $\\sigma_L^2$，它与 $C^2$ 成正比。服务器接收到总和 $\\tilde{G} = \\sum_{i=1}^{n} \\tilde{g}_i = G + \\sum_{i=1}^{n} Z_i$。由于客户端的噪声 $Z_i$ 是独立的，它们的方差会相加。最终聚合结果中的总噪声方差为 $\\sum_{i=1}^{n} \\text{Var}(Z_i) = n \\sigma_L^2$。这个方差与 $nC^2$ 成正比。\n\n- **比较**：对于可比的隐私水平，方案L中的噪声方差随参与者数量 $n$ 线性增长，而在方案C中，它相对于 $n$ 是一个常数。对于任何 $n  4$，假设隐私参数和机制相似，方案L中的总噪声将显著大于方案C。聚合梯度 $\\tilde{G}$ 中如此大的噪声会降低其质量，导致模型准确性较低和/或收敛速度变慢。因此，方案C通常比方案L产生高得多的效用（准确性）。\n\n- **结论**：该陈述正确地指出了本地DP和中心化DP模型之间核心的效用-隐私权衡。噪声的累积是本地模型的主要缺点。**正确**。\n\n**C. 在方案L中，用于 $(\\epsilon_L,\\delta_L)$ 保证的相邻关系是定义在跨所有客户端相差1个个体的全局数据集 $D$ 和 $D'$ 上，而不是在单个客户端的两个可能输入上。**\n\n- **分析**：该陈述描述的是中心化DP的相邻关系，而非本地DP。问题正确地定义了LDP：“本地差分隐私（LDP）是一种特殊情况，其中每个客户端在任何管理者看到其输入 $x_i$ 之前，都对其应用一个随机化机制 $M_i$ ... 相邻关系是定义在同一客户端的两个可能输入 $x_i$ 和 $x_i'$ 上。” 方案L明确是一个LDP设计。对客户端 $i$ 的 $(\\epsilon_L, \\delta_L)$ 保证确保了看到 $\\tilde{g}_i$ 的攻击者无法可靠地区分该客户端的本地数据是 $D_i$ 还是相邻的 $D'_i$ （它们相差一个患者记录）。隐私保证是针对客户端本地的。全局数据集的概念与单个客户端的LDP保证无关。\n\n- **结论**：该陈述从根本上误解并错误地描述了本地差分隐私。**不正确**。\n\n**D. 在方案C和受信任的SA下，SA内部使用的加密和掩码随机性就是使发布结果满足 $(\\epsilon_C,\\delta_C)$-DP的随机性；管理者不需要向 $G$ 添加任何进一步的随机化。**\n\n- **分析**：该陈述混淆了密码学安全性与DP的统计隐私性。安全聚合使用密码学技术（如秘密共享或同态加密）来计算总和 $G$，同时对服务器保密加数 $g_i$。SA中的随机性（例如，加密密钥、求和后抵消的随机掩码）是为了提供这种密码学安全性而设计的。然而，一个完美的SA协议的输出是*精确*的总和 $G = \\sum g_i$。发布这个精确的总和 $G$ 并不满足DP。一个拥有背景知识（例如，知道所有其他梯度）的攻击者可以完美地推断出特定客户端的贡献。DP要求在输出中注入经过校准的*统计噪声*，这是一个与SA分离的过程。在方案C中，管理者从SA接收到 $G$，然后*必须*应用一个DP机制 $M$ （例如，添加噪声）来产生公开的、保护隐私的输出 $\\hat{G}$。\n\n- **结论**：该陈述不正确。SA的随机性是为了安全，而不是为了DP风格的隐私。需要额外添加经过校准的噪声。**不正确**。\n\n**E. 在方案L中，即使每个客户端的机制单独满足 $(\\epsilon_L,\\delta_L)$-LDP，单轮发布 $\\tilde{g}_1, \\ldots, \\tilde{g}_n$ 也会因组合效应导致每个客户端的隐私参数线性地随 $n$ 退化。**\n\n- **分析**：该陈述错误地应用了隐私组合的概念。DP中的组合定理描述了当*同一数据集*被多次查询时隐私如何退化。在所述场景中，我们考虑的是单个客户端（比如客户端 $j$）的隐私。攻击者看到了输出集合 $\\{\\tilde{g}_1, \\ldots, \\tilde{g}_n\\}$。客户端 $j$ 的数据隐私由其机制 $M_j$ 保护，该机制将 $g_j$ 随机化为 $\\tilde{g}_j$。其他的输出 $\\tilde{g}_i$ (对于 $i \\neq j$) 是从*其他客户端*的数据生成的，这些数据与客户端 $j$ 的数据是独立的。因为 $\\tilde{g}_i$ (对于 $i \\neq j$) 在统计上与 $g_j$ 独立，观察 $\\tilde{g}_i$ 并不能提供关于 $g_j$ 的任何信息。因此，客户端 $j$ 的隐私保证完全由其自身的LDP机制 $M_j$ 决定，不受其他客户端独立私有化报告的发布影响。每个客户端的隐私保证仍然是 $(\\epsilon_L, \\delta_L)$。\n\n- **结论**：该陈述错误地应用了组合原则。一个客户端数据的隐私不会因为发布来自其他客户端的独立随机化数据而退化。**不正确**。",
            "answer": "$$\\boxed{AB}$$"
        }
    ]
}