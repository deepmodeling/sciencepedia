{
    "hands_on_practices": [
        {
            "introduction": "The effectiveness of a VR surgical simulator depends on its visual realism and the display's ability to show fine details. This practice explores angular resolution, a key metric quantifying the detail perceptible to the human eye on a given display. By deriving this from first principles, you will gain a fundamental understanding of how hardware specifications directly impact the perceptual quality of a VR system .",
            "id": "4863089",
            "problem": "A medical training system uses a head-mounted display (HMD) to deliver Virtual Reality (VR) surgical simulations. To reason about perceptual detail, assume a simple geometric eye model: a flat, rectangular microdisplay of active horizontal width subtends a horizontal field of view (FOV) at the eye, and the eye’s entrance pupil is located at a fixed vertex distance from the display. The horizontal FOV is the visual angle subtended by the active display width about the eye’s optical axis. Pixels are arranged on a uniform grid with constant pixel pitch. Using only trigonometric geometry and the definition of a visual angle, derive from first principles an expression for the average horizontal angular subtense per pixel (that is, the average horizontal angular resolution per pixel across the active width) in arcminutes. Then evaluate it for a pixel pitch of $10\\,\\mu\\text{m}$, a display-to-eye vertex distance of $40\\,\\text{mm}$, and a horizontal FOV of $100^{\\circ}$. \n\nAssumptions: \n- The microdisplay is flat and centered on the optical axis. \n- Pixels are densely packed with constant pitch and fully span the active width that produces the stated FOV. \n- The horizontal FOV equals the visual angle subtended by the active width of the display at the given vertex distance.\n\nCompute the final numerical value of the average horizontal angular resolution per pixel and express it in arcminutes. Round your answer to three significant figures.",
            "solution": "The user has provided a problem to be solved. As per the instructions, the first step is to validate the problem statement.\n\n### Step 1: Extract Givens\nThe givens extracted verbatim from the problem statement are:\n-   **Model**: A simple geometric eye model with a flat, rectangular microdisplay.\n-   **Pixel Pitch**: $p = 10 \\, \\mu\\text{m}$.\n-   **Vertex Distance**: $d = 40 \\, \\text{mm}$.\n-   **Horizontal Field of View**: $\\theta_{\\text{FOV}} = 100^{\\circ}$.\n-   **Target Quantity**: Average horizontal angular subtense per pixel, in arcminutes.\n-   **Assumptions**:\n    1.  The microdisplay is flat and centered on the optical axis.\n    2.  Pixels are densely packed with constant pitch and fully span the active width.\n    3.  The horizontal FOV equals the visual angle subtended by the active width of the display at the given vertex distance.\n-   **Task Requirements**:\n    1.  Derive an expression for the average horizontal angular subtense per pixel from first principles using trigonometric geometry.\n    2.  Evaluate the expression for the given numerical values.\n    3.  Round the final numerical answer to three significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria:\n-   **Scientifically Grounded**: The problem is grounded in basic geometric optics. The model of a flat screen viewed from a fixed distance is a standard first-order approximation used in analyzing head-mounted displays. The physical quantities (pixel pitch, vertex distance, FOV) are within realistic ranges for current technology. The concepts of angular resolution and field of view are fundamental to display engineering and visual perception.\n-   **Well-Posed**: The problem is well-posed. It provides all the necessary data ($p$, $d$, $\\theta_{\\text{FOV}}$) and a clear set of assumptions to define the geometric relationship between these quantities. The objective is to derive a specific physical quantity and then compute its value, which is a standard structure for a physics or engineering problem. A unique solution exists.\n-   **Objective**: The language is precise, quantitative, and free of subjective or ambiguous terminology. The assumptions are explicitly stated, leaving no room for misinterpretation.\n\nThe problem does not exhibit any of the defined flaws:\n1.  **Scientific or Factual Unsoundness**: No violation of scientific principles.\n2.  **Non-Formalizable or Irrelevant**: The problem is readily formalizable using geometry.\n3.  **Incomplete or Contradictory Setup**: The setup is complete and self-consistent.\n4.  **Unrealistic or Infeasible**: The parameters are physically plausible.\n5.  **Ill-Posed or Poorly Structured**: The problem is well-structured and leads to a unique solution.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem requires a non-trivial derivation and calculation.\n7.  **Outside Scientific Verifiability**: The derivation and result are mathematically verifiable.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A reasoned solution will be provided.\n\n### Solution Derivation\nThe problem asks for the average horizontal angular subtense per pixel. This quantity, which we will denote as $\\alpha_{\\text{avg}}$, is defined as the total horizontal field of view divided by the total number of horizontal pixels.\n$$\n\\alpha_{\\text{avg}} = \\frac{\\theta_{\\text{FOV}}}{N}\n$$\nwhere $\\theta_{\\text{FOV}}$ is the horizontal field of view and $N$ is the number of pixels along the horizontal width of the display.\n\nOur first task is to find an expression for $N$. The number of pixels is the total active horizontal width of the display, $W$, divided by the pixel pitch, $p$.\n$$\nN = \\frac{W}{p}\n$$\nThe problem requires us to relate the width $W$ to the field of view $\\theta_{\\text{FOV}}$ and the vertex distance $d$. We use the provided geometric model. The display is flat and centered on the optical axis, with the eye's entrance pupil at a distance $d$ from the display. This forms an isosceles triangle with the eye at the apex, the display width $W$ as the base, and the distance $d$ as the altitude.\n\nThis geometry can be analyzed by considering one of the two right-angled triangles formed by bisecting the isosceles triangle with the altitude $d$. Each right-angled triangle has:\n-   An angle at the eye of $\\frac{\\theta_{\\text{FOV}}}{2}$.\n-   An opposite side of length $\\frac{W}{2}$.\n-   An adjacent side of length $d$.\n\nFrom the definition of the tangent function in a right-angled triangle:\n$$\n\\tan\\left(\\frac{\\theta_{\\text{FOV}}}{2}\\right) = \\frac{\\text{opposite}}{\\text{adjacent}} = \\frac{W/2}{d}\n$$\nWe can solve for the display width $W$:\n$$\nW = 2d \\tan\\left(\\frac{\\theta_{\\text{FOV}}}{2}\\right)\n$$\nNow we can find the total number of horizontal pixels, $N$, by substituting this expression for $W$:\n$$\nN = \\frac{W}{p} = \\frac{2d \\tan\\left(\\frac{\\theta_{\\text{FOV}}}{2}\\right)}{p}\n$$\nFinally, we substitute this expression for $N$ into our initial definition for the average angular subtense per pixel, $\\alpha_{\\text{avg}}$:\n$$\n\\alpha_{\\text{avg}} = \\frac{\\theta_{\\text{FOV}}}{N} = \\frac{\\theta_{\\text{FOV}}}{\\frac{2d \\tan\\left(\\frac{\\theta_{\\text{FOV}}}{2}\\right)}{p}}\n$$\nThis simplifies to the desired expression:\n$$\n\\alpha_{\\text{avg}} = \\frac{p \\cdot \\theta_{\\text{FOV}}}{2d \\tan\\left(\\frac{\\theta_{\\text{FOV}}}{2}\\right)}\n$$\nThis expression gives the average angular size of a pixel. Note that the units of $\\alpha_{\\text{avg}}$ will be the same as the units used for $\\theta_{\\text{FOV}}$ in the numerator, as the ratio $p/d$ is dimensionless and the trigonometric function is also dimensionless.\n\n### Numerical Evaluation\nWe are given the following values:\n-   $p = 10 \\, \\mu\\text{m} = 10 \\times 10^{-6} \\, \\text{m}$\n-   $d = 40 \\, \\text{mm} = 40 \\times 10^{-3} \\, \\text{m}$\n-   $\\theta_{\\text{FOV}} = 100^{\\circ}$\n\nFirst, we calculate the half-angle for the tangent function:\n$$\n\\frac{\\theta_{\\text{FOV}}}{2} = \\frac{100^{\\circ}}{2} = 50^{\\circ}\n$$\nNow, we substitute the values into the derived expression. We will calculate $\\alpha_{\\text{avg}}$ in degrees first.\n$$\n\\alpha_{\\text{avg}}[\\text{degrees}] = \\frac{(10 \\times 10^{-6} \\, \\text{m}) \\cdot 100^{\\circ}}{2 \\cdot (40 \\times 10^{-3} \\, \\text{m}) \\tan(50^{\\circ})}\n$$\n$$\n\\alpha_{\\text{avg}}[\\text{degrees}] = \\frac{10^{-3}}{8 \\times 10^{-2} \\tan(50^{\\circ})} = \\frac{1}{80 \\tan(50^{\\circ})}\n$$\nUsing the value $\\tan(50^{\\circ}) \\approx 1.19175359$:\n$$\n\\alpha_{\\text{avg}}[\\text{degrees}] \\approx \\frac{1}{80 \\cdot 1.19175359} \\approx \\frac{1}{95.340287} \\approx 0.01048873^{\\circ}\n$$\nThe problem requires the answer in arcminutes. We use the conversion factor $1^{\\circ} = 60 \\, \\text{arcmin}$.\n$$\n\\alpha_{\\text{avg}}[\\text{arcmin}] = \\alpha_{\\text{avg}}[\\text{degrees}] \\times 60\n$$\n$$\n\\alpha_{\\text{avg}}[\\text{arcmin}] \\approx 0.01048873 \\times 60 \\approx 0.6293238 \\, \\text{arcmin}\n$$\nFinally, we round the result to three significant figures as requested.\n$$\n\\alpha_{\\text{avg}} \\approx 0.629 \\, \\text{arcmin}\n$$\nThis value represents the average angle that a single pixel subtends at the eye. For reference, the acuity of the human eye is often cited as being around $1$ arcminute, so this resolution is in the ballpark of human perception limits under ideal conditions, although slightly coarser.",
            "answer": "$$\\boxed{0.629}$$"
        },
        {
            "introduction": "A visually detailed display is ineffective if the image lags behind a user's head movements, which can cause disorientation and simulator sickness. This exercise introduces the concept of the motion-to-photon pipeline, the sequence of steps required to generate a new image based on user motion. You will practice analyzing a system's real-time performance by calculating the 'slack' time in the rendering loop, a critical skill for diagnosing performance bottlenecks and ensuring a comfortable, immersive experience .",
            "id": "4863084",
            "problem": "A hospital deploys a virtual reality surgical training system to teach endoscopic procedures. To minimize simulator-induced discomfort and maintain stable hand–eye coordination, the system targets a display refresh of $90\\,\\text{Hz}$, and its motion-to-photon pipeline consists of strictly serial stages with no overlap: head-mounted display inertial sensor readout, head pose tracking update, scene rendering, and display scanout. Assume a single-buffered vertical synchronization, so that each frame must complete all stages within the frame period to avoid missing the next vertical blank. The measured stage latencies for a typical frame are $2\\,\\text{ms}$ for sensor readout, $3\\,\\text{ms}$ for tracking update, $4\\,\\text{ms}$ for rendering, and $7\\,\\text{ms}$ for display scanout.\n\nStarting from the definition that the frame time budget equals the display period $T$ given by $T = 1/f$ for refresh frequency $f$, and that the motion-to-photon pipeline time is the sum of the serial stage latencies, compute the signed slack\n$$\nS \\equiv T_{\\text{ms}} - L_{\\text{pipeline}},\n$$\nwhere $T_{\\text{ms}}$ is the frame time budget expressed in milliseconds and $L_{\\text{pipeline}}$ is the total pipeline latency in milliseconds. A negative value of $S$ implies that the pipeline exceeds the frame budget and asynchronous reprojection would be required to mask the overrun.\n\nProvide the value of $S$ in $\\text{ms}$, rounded to four significant figures. Express the final result in milliseconds as a real number. Do not include any explanatory text in your final answer.",
            "solution": "The problem is first validated against the required criteria.\n\n**Step 1: Extract Givens**\n- Display refresh frequency: $f = 90\\,\\text{Hz}$\n- Pipeline stages are strictly serial.\n- Sensor readout latency: $L_{\\text{sensor}} = 2\\,\\text{ms}$\n- Tracking update latency: $L_{\\text{tracking}} = 3\\,\\text{ms}$\n- Rendering latency: $L_{\\text{rendering}} = 4\\,\\text{ms}$\n- Display scanout latency: $L_{\\text{scanout}} = 7\\,\\text{ms}$\n- Frame time budget definition: $T = \\frac{1}{f}$\n- Total pipeline latency definition: $L_{\\text{pipeline}}$ is the sum of serial stage latencies.\n- Signed slack definition: $S \\equiv T_{\\text{ms}} - L_{\\text{pipeline}}$\n- $T_{\\text{ms}}$ is the frame time budget in milliseconds.\n- $L_{\\text{pipeline}}$ is the total pipeline latency in milliseconds.\n- Required output: Value of $S$ in $\\text{ms}$, rounded to four significant figures.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, as it deals with standard concepts in virtual reality engineering and computer graphics (refresh rate, motion-to-photon latency, frame budget). The values provided are realistic for a modern VR system. The problem is well-posed, providing all necessary information and clear definitions for a unique solution. The language is objective and precise. The problem is self-contained, consistent, and does not violate any scientific or mathematical principles.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be provided.\n\nThe task is to compute the signed slack, $S$, for a VR system's rendering pipeline. This value is defined as the difference between the frame time budget, $T_{\\text{ms}}$, and the total pipeline latency, $L_{\\text{pipeline}}$.\n\nFirst, we calculate the total pipeline latency, $L_{\\text{pipeline}}$. The problem states that the pipeline stages are strictly serial, so their latencies add up. The given latencies for the stages are $2\\,\\text{ms}$ (sensor), $3\\,\\text{ms}$ (tracking), $4\\,\\text{ms}$ (rendering), and $7\\,\\text{ms}$ (scanout).\nThe total latency is the sum of these individual latencies:\n$$\nL_{\\text{pipeline}} = 2\\,\\text{ms} + 3\\,\\text{ms} + 4\\,\\text{ms} + 7\\,\\text{ms}\n$$\n$$\nL_{\\text{pipeline}} = 16\\,\\text{ms}\n$$\n\nNext, we calculate the frame time budget, $T_{\\text{ms}}$. This budget is the period corresponding to the display's refresh frequency, $f$. The given frequency is $f = 90\\,\\text{Hz}$. The frame period, $T$, is the reciprocal of the frequency:\n$$\nT = \\frac{1}{f} = \\frac{1}{90\\,\\text{Hz}} = \\frac{1}{90}\\,\\text{s}\n$$\nThe problem requires this time to be in milliseconds. We use the conversion $1\\,\\text{s} = 1000\\,\\text{ms}$:\n$$\nT_{\\text{ms}} = \\left(\\frac{1}{90}\\right)\\,\\text{s} \\times \\left(\\frac{1000\\,\\text{ms}}{1\\,\\text{s}}\\right) = \\frac{1000}{90}\\,\\text{ms} = \\frac{100}{9}\\,\\text{ms}\n$$\n\nFinally, we compute the signed slack, $S$, using the provided definition:\n$$\nS = T_{\\text{ms}} - L_{\\text{pipeline}}\n$$\nSubstituting the calculated values:\n$$\nS = \\frac{100}{9}\\,\\text{ms} - 16\\,\\text{ms}\n$$\nTo subtract, we use a common denominator:\n$$\nS = \\left(\\frac{100}{9} - \\frac{16 \\times 9}{9}\\right)\\,\\text{ms} = \\left(\\frac{100 - 144}{9}\\right)\\,\\text{ms} = -\\frac{44}{9}\\,\\text{ms}\n$$\nThe problem requires the answer as a real number rounded to four significant figures. We perform the division:\n$$\nS = -\\frac{44}{9} \\approx -4.8888... \\,\\text{ms}\n$$\nRounding this value to four significant figures yields:\n$$\nS \\approx -4.889\\,\\text{ms}\n$$\nThe negative sign indicates that the time required to complete the pipeline ($16\\,\\text{ms}$) is greater than the time available in a single frame's budget (approximately $11.11\\,\\text{ms}$), resulting in a deficit.",
            "answer": "$$\\boxed{-4.889}$$"
        },
        {
            "introduction": "In augmented reality surgery, the system overlays a digital model of anatomy onto the surgeon's view of the patient, and the system's safety depends critically on the geometric accuracy of this digital model. This exercise applies fundamental validation metrics to quantify the performance of a medical image segmentation, which forms the basis of the AR overlay. You will learn not only to calculate these metrics but also to interpret their clinical relevance, a vital skill for anyone developing or evaluating medical AR technologies .",
            "id": "4863080",
            "problem": "An augmented reality (AR) surgical guidance system overlays a segmented anatomical structure—the left kidney capsule—onto live laparoscopic video to assist surgeons in maintaining safe margins during partial nephrectomy. In the medical informatics pipeline, segmentation masks are represented as binary sets of voxels. Let the predicted AR segmentation mask be the set $P$ and the ground-truth mask (manually curated by expert radiologists from preoperative computed tomography) be the set $G$. For a particular case, the following are observed from volumetric analysis:\n- The predicted mask contains $|P| = 110{,}000$ voxels.\n- The ground-truth mask contains $|G| = 120{,}000$ voxels.\n- The intersection contains $|P \\cap G| = 100{,}000$ voxels.\n\nUsing fundamental set-theoretic definitions of binary classification counts for segmentation, where true positives are overlapping voxels, false positives are predicted voxels not in the ground truth, and false negatives are ground-truth voxels not predicted, compute the following segmentation performance metrics for the overlay:\n- Dice coefficient,\n- Jaccard index,\n- precision,\n- recall.\n\nExpress each metric as a unitless decimal between $0$ and $1$ and round your results to four significant figures. Report your four metrics in the single final answer in the order: Dice, Jaccard, precision, recall. Additionally, in your reasoning, interpret the clinical relevance of these values for AR overlay safety and usability, starting from core definitions rather than shortcut formulas or pre-memorized results.",
            "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- The predicted AR segmentation mask is the set $P$.\n- The ground-truth mask is the set $G$.\n- The size of the predicted mask is $|P| = 110,000$ voxels.\n- The size of the ground-truth mask is $|G| = 120,000$ voxels.\n- The size of the intersection of the two masks is $|P \\cap G| = 100,000$ voxels.\n- Definitions for classification counts:\n  - True positives ($TP$): overlapping voxels.\n  - False positives ($FP$): predicted voxels not in the ground truth.\n  - False negatives ($FN$): ground-truth voxels not predicted.\n- Required computations: Dice coefficient, Jaccard index, precision, and recall.\n- Output format: Decimal rounded to four significant figures, reported in the order Dice, Jaccard, precision, recall.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It utilizes standard, formally defined concepts from set theory and applies them to the field of medical image analysis, a core component of medical informatics. The provided data are internally consistent; the size of the intersection, $|P \\cap G| = 100,000$, is correctly less than or equal to the sizes of the individual sets, $|P| = 110,000$ and $|G| = 120,000$. The problem is complete, as it furnishes all necessary data to compute the requested metrics. The voxel counts are realistic for a high-resolution medical scan of an anatomical substructure. There are no ambiguities, contradictions, or violations of scientific principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Solution Derivation\n\nThe problem requires the calculation of four performance metrics for a segmentation mask based on set-theoretic principles. We begin by formalizing the definitions of true positives ($TP$), false positives ($FP$), and false negatives ($FN$) using the provided sets $P$ (prediction) and $G$ (ground truth).\n\nA **true positive** ($TP$) is a voxel that is correctly identified as part of the kidney capsule. These are the voxels present in both the predicted mask $P$ and the ground-truth mask $G$. Therefore, the number of true positives is the cardinality of the intersection of the two sets.\n$$TP = |P \\cap G|$$\nUsing the given data, we have:\n$$TP = 100,000$$\n\nA **false positive** ($FP$) is a voxel that is incorrectly identified as part of the kidney capsule. These are the voxels present in the predicted mask $P$ but not in the ground-truth mask $G$. This corresponds to the set difference $P \\setminus G$. The number of false positives is the cardinality of this set difference, which can be calculated as:\n$$FP = |P \\setminus G| = |P| - |P \\cap G|$$\nSubstituting the given values:\n$$FP = 110,000 - 100,000 = 10,000$$\n\nA **false negative** ($FN$) is a voxel that belongs to the kidney capsule but was missed by the segmentation algorithm. These are the voxels present in the ground-truth mask $G$ but not in the predicted mask $P$. This corresponds to the set difference $G \\setminus P$. The number of false negatives is the cardinality of this set difference:\n$$FN = |G \\setminus P| = |G| - |P \\cap G|$$\nSubstituting the given values:\n$$FN = 120,000 - 100,000 = 20,000$$\n\nWith these fundamental quantities established, we can now define and compute each of the required metrics.\n\n**1. Dice Coefficient (Sørensen–Dice index)**\nThe Dice coefficient is a measure of spatial overlap between two sets. It is defined as twice the size of the intersection divided by the sum of the sizes of the two sets.\n$$Dice = \\frac{2 |P \\cap G|}{|P| + |G|}$$\nIn terms of $TP$, $FP$, and $FN$, we can express $|P| = TP + FP$ and $|G| = TP + FN$. Substituting these gives:\n$$Dice = \\frac{2 TP}{(TP + FP) + (TP + FN)} = \\frac{2 TP}{2 TP + FP + FN}$$\nUsing the given cardinalities:\n$$Dice = \\frac{2 \\times 100,000}{110,000 + 120,000} = \\frac{200,000}{230,000} = \\frac{20}{23}$$\nAs a decimal rounded to four significant figures:\n$$Dice \\approx 0.869565... \\approx 0.8696$$\n\n**2. Jaccard Index (Intersection over Union, IoU)**\nThe Jaccard index is another measure of set similarity, defined as the size of the intersection divided by the size of the union.\n$$Jaccard = \\frac{|P \\cap G|}{|P \\cup G|}$$\nThe cardinality of the union is given by the principle of inclusion-exclusion: $|P \\cup G| = |P| + |G| - |P \\cap G|$.\nIn terms of $TP$, $FP$, and $FN$, the union $|P \\cup G|$ represents all voxels flagged in at least one of the masks, which is $TP + FP + FN$.\n$$Jaccard = \\frac{TP}{TP + FP + FN}$$\nUsing the calculated values:\n$$Jaccard = \\frac{100,000}{100,000 + 10,000 + 20,000} = \\frac{100,000}{130,000} = \\frac{10}{13}$$\nAs a decimal rounded to four significant figures:\n$$Jaccard \\approx 0.769230... \\approx 0.7692$$\n\n**3. Precision (Positive Predictive Value)**\nPrecision answers the question: \"Of all the voxels a system predicted to be target tissue, what fraction were actually target tissue?\" It is the ratio of true positives to the total number of predicted positives. The total number of predicted positives is the size of the predicted set, $|P|$.\n$$Precision = \\frac{TP}{|P|} = \\frac{TP}{TP + FP}$$\nUsing the calculated values:\n$$Precision = \\frac{100,000}{110,000} = \\frac{10}{11}$$\nAs a decimal rounded to four significant figures:\n$$Precision \\approx 0.909090... \\approx 0.9091$$\n\n**4. Recall (Sensitivity, True Positive Rate)**\nRecall answers the question: \"Of all the voxels that are truly target tissue, what fraction did the system correctly identify?\" It is the ratio of true positives to the total number of actual positives. The total number of actual positives is the size of the ground-truth set, $|G|$.\n$$Recall = \\frac{TP}{|G|} = \\frac{TP}{TP + FN}$$\nUsing the calculated values:\n$$Recall = \\frac{100,000}{120,000} = \\frac{10}{12} = \\frac{5}{6}$$\nAs a decimal rounded to four significant figures:\n$$Recall \\approx 0.833333... \\approx 0.8333$$\n\n### Clinical Relevance of Metrics\n\n- **Dice ($0.8696$) and Jaccard ($0.7692$):** These metrics give a global sense of the overlay's geometric accuracy. A Dice score of approximately $0.87$ indicates a good-to-excellent spatial overlap. For an AR surgical guide, this is crucial for surgeon trust and usability. A low score would imply a poorly shaped or misaligned overlay, rendering it useless or even dangerous.\n- **Precision ($0.9091$):** This is a critical safety metric. High precision means the AR overlay has a low rate of false positives ($FP=10,000$). When the system highlights a region, a surgeon can be confident ($90.91\\%$ in this case) that it is indeed the target tissue. This minimizes the risk of iatrogenic damage to healthy, non-target structures that might have been incorrectly included in the overlay.\n- **Recall ($0.8333$):** This metric relates to the completeness of the overlay. A recall of $0.8333$ means the system successfully identified $83.33\\%$ of the true kidney capsule but missed $16.67\\%$ ($FN=20,000$ voxels). For a partial nephrectomy, where a key goal is to preserve maximal healthy kidney tissue, these false negatives are significant. The surgeon, relying on the overlay, might cut closer to the actual kidney than intended, believing they have a safe margin in an area where the overlay is absent. This could compromise the renopreservation goal of the surgery.\n\nIn summary, the AR system is quite precise, reducing the risk of cutting outside the target, but its recall indicates it is not perfectly complete, creating a risk of excising too close to the true boundary. The high Dice coefficient suggests it is a very useful guide overall, but the surgeon must remain aware of its potential to under-represent the full extent of the anatomical structure.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.8696 & 0.7692 & 0.9091 & 0.8333 \\end{pmatrix}}\n$$"
        }
    ]
}