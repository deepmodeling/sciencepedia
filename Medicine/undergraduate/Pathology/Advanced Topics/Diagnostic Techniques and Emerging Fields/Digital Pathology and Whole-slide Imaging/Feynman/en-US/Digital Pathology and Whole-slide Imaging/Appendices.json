{
    "hands_on_practices": [
        {
            "introduction": "Whole-slide images (WSIs) are fundamentally different from consumer digital photos due to their immense scale, often containing billions of pixels. To enable efficient viewing with smooth panning and zooming, WSIs are not stored as single, flat images but as multi-resolution pyramids. This exercise  provides a practical, quantitative understanding of this structure by guiding you through the calculation of the total storage space required for a realistic WSI pyramid, from its full-resolution base to its lowest-resolution peak.",
            "id": "4356862",
            "problem": "A pathology laboratory scans a digitized whole-slide image using Whole-Slide Imaging (WSI) and stores it as a multi-resolution pyramid to support rapid pan-and-zoom. The full-resolution level (level $0$) has dimensions $100{,}000 \\times 50{,}000$ pixels. The image is standard color with three channels ($RGB$), each at $8$ bits per channel. The pyramid is constructed by downsampling by a factor of $2$ in each dimension between successive levels, with each level’s dimensions defined as the ceiling of the previous dimension divided by $2$ to preserve full coverage. Tiling is performed at each level with a fixed tile size of $512 \\times 512$ pixels, and levels are included until a level is reached whose dimensions are each less than or equal to $512$ pixels. Assume that the Joint Photographic Experts Group (JPEG) compression achieves a constant compression ratio of exactly $10{:}1$ at every level, and ignore any metadata, tile headers, or padding overhead. \n\nStarting from core definitions—bits per channel, bytes per pixel, pixel count at each level via the ceiling function, and a constant compression ratio—derive the total compressed storage required for the entire pyramid by summing over all included levels. Express your final answer in gibibytes (GiB), where $1\\,\\mathrm{GiB} = 2^{30}$ bytes, and round your result to four significant figures.",
            "solution": "The user wants me to solve the following problem:\nA pathology laboratory scans a digitized whole-slide image using Whole-Slide Imaging (WSI) and stores it as a multi-resolution pyramid to support rapid pan-and-zoom. The full-resolution level (level $0$) has dimensions $100{,}000 \\times 50{,}000$ pixels. The image is standard color with three channels ($RGB$), each at $8$ bits per channel. The pyramid is constructed by downsampling by a factor of $2$ in each dimension between successive levels, with each level’s dimensions defined as the ceiling of the previous dimension divided by $2$ to preserve full coverage. Tiling is performed at each level with a fixed tile size of $512 \\times 512$ pixels, and levels are included until a level is reached whose dimensions are each less than or equal to $512$ pixels. Assume that the Joint Photographic Experts Group (JPEG) compression achieves a constant compression ratio of exactly $10{:}1$ at every level, and ignore any metadata, tile headers, or padding overhead. \n\nStarting from core definitions—bits per channel, bytes per pixel, pixel count at each level via the ceiling function, and a constant compression ratio—derive the total compressed storage required for the entire pyramid by summing over all included levels. Express your final answer in gibibytes (GiB), where $1\\,\\mathrm{GiB} = 2^{30}$ bytes, and round your result to four significant figures.\n\n### Step 1: Extract Givens\n- Level $0$ dimensions: $100,000 \\times 50,000$ pixels\n- Number of color channels: $3$\n- Bits per channel: $8$\n- Downsampling factor: $2$ in each dimension\n- Downsampling rule: `ceiling(previous_dim / 2)`\n- Stopping condition: Level is included until a level is reached whose dimensions are each less than or equal to $512$ pixels.\n- Compression ratio: $10:1$\n- Final units: Gibibytes (GiB)\n- Unit definition: $1\\,\\mathrm{GiB} = 2^{30}$ bytes\n- Rounding: Four significant figures\n- Ignored factors: Metadata, tile headers, padding overhead.\n- Tiling size: $512 \\times 512$ pixels (Note: This information is not required for calculating total storage space, only the total number of pixels at each level is needed.)\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem describes the standard practice of creating image pyramids for Whole-Slide Images in digital pathology. The concepts of multi-resolution levels, downsampling, RGB color channels, bit depth, and JPEG compression are all fundamental and accurately represented. The setup is scientifically and technically realistic.\n- **Well-Posed**: The problem is well-posed. It provides a clear set of initial conditions ($W_0, H_0$), a recursive formula for generating subsequent states (pyramid levels), a clear stopping condition, and a defined set of operations to arrive at a single numerical answer.\n- **Objective**: The problem is stated using precise, quantitative, and unambiguous language.\n- **Completeness and Consistency**: All necessary parameters are provided. There are no contradictions. The mention of tiling size is extraneous to the final calculation but does not create an inconsistency, as the total pixel count is independent of how the image is tiled.\n\n### Step 3: Verdict and Action\nThe problem is valid. I will now proceed with the solution.\n\nTo determine the total compressed storage size, we must first calculate the size of each level in the image pyramid and then sum these sizes.\n\nFirst, we establish the uncompressed size of a single pixel. The image has $3$ channels (RGB), and each channel is encoded with $8$ bits.\nThe number of bits per pixel is:\n$$N_{\\text{bits per pixel}} = 3\\,\\text{channels} \\times 8\\,\\frac{\\text{bits}}{\\text{channel}} = 24\\,\\text{bits}$$\nSince there are $8$ bits in a byte, the number of bytes per pixel is:\n$$N_{\\text{bytes per pixel}} = \\frac{24\\,\\text{bits}}{8\\,\\text{bits}/\\text{byte}} = 3\\,\\text{bytes}$$\n\nNext, we establish the dimensions and compressed storage size for each level of the pyramid, starting from level $i=0$. Let $W_i$ and $H_i$ be the width and height of the image at level $i$. The dimensions for level $i > 0$ are given by:\n$$W_i = \\lceil \\frac{W_{i-1}}{2} \\rceil \\quad \\text{and} \\quad H_i = \\lceil \\frac{H_{i-1}}{2} \\rceil$$\nThe compressed size of level $i$ in bytes, $S_i$, is calculated by taking the total number of pixels ($W_i \\times H_i$), multiplying by the bytes per pixel, and dividing by the compression ratio of $10$.\n$$S_i = \\frac{W_i \\times H_i \\times 3}{10}$$\nWe generate levels until we reach the first level $N$ where both $W_N \\le 512$ and $H_N \\le 512$.\n\nLet's compute the properties for each level:\n\nLevel $i=0$:\n$W_0 = 100,000$, $H_0 = 50,000$. Both dimensions are greater than $512$.\n$S_0 = \\frac{100,000 \\times 50,000 \\times 3}{10} = 1,500,000,000$ bytes.\n\nLevel $i=1$:\n$W_1 = \\lceil \\frac{100,000}{2} \\rceil = 50,000$, $H_1 = \\lceil \\frac{50,000}{2} \\rceil = 25,000$. Both dimensions are greater than $512$.\n$S_1 = \\frac{50,000 \\times 25,000 \\times 3}{10} = 375,000,000$ bytes.\n\nLevel $i=2$:\n$W_2 = \\lceil \\frac{50,000}{2} \\rceil = 25,000$, $H_2 = \\lceil \\frac{25,000}{2} \\rceil = 12,500$. Both dimensions are greater than $512$.\n$S_2 = \\frac{25,000 \\times 12,500 \\times 3}{10} = 93,750,000$ bytes.\n\nLevel $i=3$:\n$W_3 = \\lceil \\frac{25,000}{2} \\rceil = 12,500$, $H_3 = \\lceil \\frac{12,500}{2} \\rceil = 6,250$. Both dimensions are greater than $512$.\n$S_3 = \\frac{12,500 \\times 6,250 \\times 3}{10} = 23,437,500$ bytes.\n\nLevel $i=4$:\n$W_4 = \\lceil \\frac{12,500}{2} \\rceil = 6,250$, $H_4 = \\lceil \\frac{6,250}{2} \\rceil = 3,125$. Both dimensions are greater than $512$.\n$S_4 = \\frac{6,250 \\times 3,125 \\times 3}{10} = 5,859,375$ bytes.\n\nLevel $i=5$:\n$W_5 = \\lceil \\frac{6,250}{2} \\rceil = 3,125$, $H_5 = \\lceil \\frac{3,125}{2} \\rceil = 1,563$. Both dimensions are greater than $512$.\n$S_5 = \\frac{3,125 \\times 1,563 \\times 3}{10} = 1,465,312.5$ bytes.\n\nLevel $i=6$:\n$W_6 = \\lceil \\frac{3,125}{2} \\rceil = 1,563$, $H_6 = \\lceil \\frac{1,563}{2} \\rceil = 782$. Both dimensions are greater than $512$.\n$S_6 = \\frac{1,563 \\times 782 \\times 3}{10} = 366,679.8$ bytes.\n\nLevel $i=7$:\n$W_7 = \\lceil \\frac{1,563}{2} \\rceil = 782$, $H_7 = \\lceil \\frac{782}{2} \\rceil = 391$. Here, $W_7 > 512$ but $H_7 \\le 512$. The stopping condition ($W_i \\le 512$ AND $H_i \\le 512$) is not met, so we must continue.\n$S_7 = \\frac{782 \\times 391 \\times 3}{10} = 91,728.6$ bytes.\n\nLevel $i=8$:\n$W_8 = \\lceil \\frac{782}{2} \\rceil = 391$, $H_8 = \\lceil \\frac{391}{2} \\rceil = 196$. Now, $W_8 \\le 512$ and $H_8 \\le 512$. This is the final level to be included.\n$S_8 = \\frac{391 \\times 196 \\times 3}{10} = 22,990.8$ bytes.\n\nThe pyramid consists of levels $0$ through $8$. The total compressed size, $S_{\\text{total}}$, is the sum of the sizes of all these levels.\n$$S_{\\text{total}} = \\sum_{i=0}^{8} S_i$$\n$$S_{\\text{total}} = 1,500,000,000 + 375,000,000 + 93,750,000 + 23,437,500 + 5,859,375 + 1,465,312.5 + 366,679.8 + 91,728.6 + 22,990.8$$\n$$S_{\\text{total}} = 1,999,993,586.7\\,\\text{bytes}$$\n\nFinally, we convert this total size into gibibytes (GiB). The problem defines $1\\,\\mathrm{GiB} = 2^{30}\\,\\text{bytes}$.\n$$2^{30} = 1,073,741,824$$\nSo, the total size in GiB is:\n$$S_{\\text{GiB}} = \\frac{S_{\\text{total}}}{2^{30}} = \\frac{1,999,993,586.7}{1,073,741,824} \\approx 1.86259000007\\,\\mathrm{GiB}$$\nRounding the result to four significant figures gives:\n$$S_{\\text{GiB}} \\approx 1.863\\,\\mathrm{GiB}$$",
            "answer": "$$\n\\boxed{1.863}\n$$"
        },
        {
            "introduction": "The quality of a digital image is fundamentally limited by the physical system that acquires it. In whole-slide imaging, we must ensure that the digital sensor is sampling the specimen at a high enough resolution to capture all the detail resolved by the microscope's optics. This practice  delves into the crucial relationship between the objective's numerical aperture ($NA$), the wavelength of light ($\\lambda$), and the scanner's pixel size, using the Nyquist-Shannon sampling theorem as a guide to determine if an imaging system meets the criteria for high-fidelity digitization.",
            "id": "4356907",
            "problem": "A whole-slide imaging scanner in digital pathology uses an infinity-corrected brightfield microscope. An objective labeled $40\\times$ is designed to achieve its nominal magnification with a standard tube lens of focal length $f_t=200\\,\\text{mm}$. The camera has sensor pixel pitch $s=6.5\\,\\mu\\text{m}$. Illumination is broadband, and for performance assessment use the green spectral component $\\lambda=550\\,\\text{nm}$, with the objective numerical aperture $NA=0.75$. Starting from the definition of magnification as the ratio of image size to object size, the meaning of the $40\\times$ label in an infinity microscope, the sampling theorem, and the cutoff of the incoherent optical transfer function, derive the specimen-plane microns-per-pixel $p_{\\text{spec}}$ and use the sampling theorem to determine whether the sampling meets the Nyquist requirement for the given $\\lambda$ and $NA$. Report a single scalar summary of sampling adequacy defined by the oversampling factor\n$$R=\\frac{\\lambda}{4\\,NA\\,p_{\\text{spec}}},$$\nwhere $R\\geq 1$ indicates compliance. Round your final $R$ to four significant figures. Express $R$ as a pure number with no units.",
            "solution": "The goal is to compute the specimen-plane microns-per-pixel and assess Nyquist compliance via an oversampling factor. The fundamental bases are as follows.\n\nFirst, in an infinity-corrected microscope, the objective forms a collimated beam and the tube lens of focal length $f_t$ forms the intermediate image. The objective’s labeled magnification $M_{\\text{obj}}$ is defined for a standard tube lens, and for standard systems the label $40\\times$ corresponds to an objective-tube lens pair that yields image magnification $M=40$ at the intermediate image plane. Thus the total lateral magnification from specimen to sensor is\n$$M=40.$$\n\nThe specimen-plane pixel size $p_{\\text{spec}}$ is the sensor pixel pitch demagnified by $M$,\n$$p_{\\text{spec}}=\\frac{s}{M}.$$\nSubstituting $s=6.5\\,\\mu\\text{m}$ and $M=40$,\n$$p_{\\text{spec}}=\\frac{6.5\\,\\mu\\text{m}}{40}=0.1625\\,\\mu\\text{m}.$$\n\nNext, to assess sampling adequacy, use the sampling theorem (Nyquist-Shannon). For incoherent brightfield imaging, the optical transfer function (OTF) has a cutoff spatial frequency\n$$f_c=\\frac{2\\,NA}{\\lambda},$$\nwhich is the highest spatial frequency transmitted by the optics. Sampling with pixel spacing $p_{\\text{spec}}$ corresponds to a sampling frequency\n$$f_s=\\frac{1}{p_{\\text{spec}}}.$$\nNyquist requires $f_s\\geq 2 f_c$, which implies\n$$\\frac{1}{p_{\\text{spec}}}\\geq 2\\left(\\frac{2\\,NA}{\\lambda}\\right)\\quad\\Rightarrow\\quad p_{\\text{spec}}\\leq\\frac{\\lambda}{4\\,NA}.$$\nDefine the oversampling factor\n$$R=\\frac{\\lambda}{4\\,NA\\,p_{\\text{spec}}}.$$\nIf $R\\geq 1$, the sampling complies with Nyquist; if $R<1$, it does not.\n\nNow substitute the given values, using consistent units. Let $\\lambda=550\\,\\text{nm}=0.55\\,\\mu\\text{m}$, $NA=0.75$, and $p_{\\text{spec}}=0.1625\\,\\mu\\text{m}$. Then\n$$R=\\frac{0.55\\,\\mu\\text{m}}{4\\times 0.75\\times 0.1625\\,\\mu\\text{m}}=\\frac{0.55}{3\\times 0.1625}=\\frac{0.55}{0.4875}.$$\nCompute the ratio exactly via symbolic multiplication:\n$$R=\\frac{0.55\\times 40}{4\\times 0.75\\times 6.5}=\\frac{22}{19.5}\\approx 1.128205128.$$\n\nTherefore, the specimen-plane microns-per-pixel is $p_{\\text{spec}}=0.1625\\,\\mu\\text{m}$, and the oversampling factor is $R\\approx 1.128205128$. Because $R\\geq 1$, the sampling meets the Nyquist requirement for $\\lambda=550\\,\\text{nm}$ and $NA=0.75$. Rounding the final $R$ to four significant figures gives\n$$R\\approx 1.128.$$",
            "answer": "$$\\boxed{1.128}$$"
        },
        {
            "introduction": "A major challenge in computational pathology is the variability in tissue staining across different slides, which can confound automated analysis. Color normalization is a critical preprocessing step to address this issue by standardizing the appearance of images. In this hands-on exercise , you will implement a foundational color normalization technique that maps the color profile of a source image to a target template in the perceptually uniform $L^{*}a^{*}b^{*}$ color space and use the Kullback-Leibler divergence to quantitatively measure the reduction in statistical divergence between the images, providing insight into the effectiveness of the algorithm.",
            "id": "4356903",
            "problem": "In digital pathology, accurate cross-slide color consistency is essential for robust analysis. Consider two whole-slide imaging (WSI) scans of hematoxylin and eosin stained tissue: a source slide and a target slide. For each slide, the per-pixel color channel intensities in the CIE $L^{*}a^{*}b^{*}$ space are empirically observed to be approximately Gaussian and independent across channels. The source slide has global channel statistics (mean and standard deviation) given by $L$: $\\mu_{sL} = 55$, $\\sigma_{sL} = 12$; $a$: $\\mu_{sa} = 22$, $\\sigma_{sa} = 5$; $b$: $\\mu_{sb} = 8$, $\\sigma_{sb} = 7$. The target slide has global channel statistics $L$: $\\mu_{tL} = 62$, $\\sigma_{tL} = 9$; $a$: $\\mu_{ta} = 18$, $\\sigma_{ta} = 6$; $b$: $\\mu_{tb} = 12$, $\\sigma_{tb} = 5$.\n\nTwo rectangular patches ($P_1$ and $P_2$) are sampled from the source slide. Their channel statistics (mean and standard deviation) are:\n- Patch $P_1$: $L$: $\\mu_{1L} = 54$, $\\sigma_{1L} = 11$; $a$: $\\mu_{1a} = 23$, $\\sigma_{1a} = 4.5$; $b$: $\\mu_{1b} = 9$, $\\sigma_{1b} = 6.5$.\n- Patch $P_2$: $L$: $\\mu_{2L} = 57$, $\\sigma_{2L} = 13$; $a$: $\\mu_{2a} = 20$, $\\sigma_{2a} = 5.5$; $b$: $\\mu_{2b} = 7$, $\\sigma_{2b} = 6$.\n\nAssume each channel distribution is univariate Gaussian and channels are independent. You will implement per-channel affine color normalization of the form $y = \\alpha x + \\beta$ that maps the source slide’s global distribution to the target slide’s global distribution for each channel. That mapping is then applied to each patch channel to produce normalized patch statistics.\n\nStarting from the definitions of expectation, variance, and the Kullback–Leibler divergence (KL) between continuous distributions, do the following:\n1. Determine the unique per-channel affine parameters $(\\alpha_{L}, \\beta_{L})$, $(\\alpha_{a}, \\beta_{a})$, and $(\\alpha_{b}, \\beta_{b})$ that make the normalized source channel have the same mean and standard deviation as the target channel.\n2. Apply this normalization to each patch channel to obtain the normalized means and standard deviations for $P_1$ and $P_2$ in $L$, $a$, and $b$.\n3. For each patch and channel, compute the Kullback–Leibler divergence (KL) from the patch distribution to the target distribution, both before and after normalization. Use the natural logarithm in the KL definition and treat each channel independently.\n4. Aggregate by summing the KL divergences across the $L$, $a$, and $b$ channels for each patch and then across the two patches to produce $D_{\\text{before}}$ and $D_{\\text{after}}$.\n5. Compute the reduction $\\Delta D = D_{\\text{before}} - D_{\\text{after}}$.\n\nExpress the final value of $\\Delta D$ as a unitless pure number. Round your answer to four significant figures.",
            "solution": "The user wants to solve a problem about color normalization in digital pathology. First, I will validate the problem statement.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- **Color Space**: CIE $L^{*}a^{*}b^{*}$\n- **Distributions**: Per-channel intensities are approximately Gaussian and independent.\n- **Source Slide Global Statistics**:\n    - $L$ channel: $\\mu_{sL} = 55$, $\\sigma_{sL} = 12$\n    - $a$ channel: $\\mu_{sa} = 22$, $\\sigma_{sa} = 5$\n    - $b$ channel: $\\mu_{sb} = 8$, $\\sigma_{sb} = 7$\n- **Target Slide Global Statistics**:\n    - $L$ channel: $\\mu_{tL} = 62$, $\\sigma_{tL} = 9$\n    - $a$ channel: $\\mu_{ta} = 18$, $\\sigma_{ta} = 6$\n    - $b$ channel: $\\mu_{tb} = 12$, $\\sigma_{tb} = 5$\n- **Patch $P_1$ Statistics (from source slide)**:\n    - $L$ channel: $\\mu_{1L} = 54$, $\\sigma_{1L} = 11$\n    - $a$ channel: $\\mu_{1a} = 23$, $\\sigma_{1a} = 4.5$\n    - $b$ channel: $\\mu_{1b} = 9$, $\\sigma_{1b} = 6.5$\n- **Patch $P_2$ Statistics (from source slide)**:\n    - $L$ channel: $\\mu_{2L} = 57$, $\\sigma_{2L} = 13$\n    - $a$ channel: $\\mu_{2a} = 20$, $\\sigma_{2a} = 5.5$\n    - $b$ channel: $\\mu_{2b} = 7$, $\\sigma_{2b} = 6$\n- **Normalization Model**: Per-channel affine transform $y = \\alpha x + \\beta$.\n- **Objective**: Compute the total reduction in Kullback-Leibler (KL) divergence, $\\Delta D = D_{\\text{before}} - D_{\\text{after}}$, after normalization. The KL divergence uses the natural logarithm.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientific Grounding**: The problem is well-grounded in the field of computational pathology. Color normalization is a critical preprocessing step for analyzing whole-slide images (WSIs). The use of CIE $L^{*}a^{*}b^{*}$ color space is standard because it is perceptually more uniform than RGB. Modeling color channel distributions as Gaussian is a common and effective approximation. The affine transformation described is a simplified version of the widely used Reinhard color normalization method. The use of KL divergence to measure the \"distance\" between probability distributions is a standard concept from information theory. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides all necessary data and defines a clear, sequential procedure for calculation. The mathematical operations are well-defined, leading to a unique numerical solution.\n- **Objectivity**: The problem statement is objective and uses precise, unambiguous technical language. The parameters given are realistic for H&E stained tissue images.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. It is scientifically sound, well-posed, and objective. I will proceed with a full solution.\n\n### Solution\n\nThe problem requires a five-step calculation process. We will address each step systematically. Throughout the solution, we consider a single color channel. The process is identical for all channels ($L, a, b$) and is applied independently due to the stated channel independence.\n\nLet a random variable $X$ represent the pixel intensity in a given channel of a source patch, with $X \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$. The global source distribution is $X_s \\sim \\mathcal{N}(\\mu_s, \\sigma_s^2)$, and the global target distribution is $Y_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$.\n\n**1. Determine the affine parameters $(\\alpha, \\beta)$**\n\nThe affine normalization is given by $Y = \\alpha X + \\beta$, where $Y$ is the normalized pixel intensity. The goal is to match the mean and variance of the globally normalized source distribution to the target distribution.\nLet $X_s$ be a random variable for the source slide channel. Its mean is $E[X_s] = \\mu_s$ and its variance is $\\text{Var}(X_s) = \\sigma_s^2$. The normalized variable is $Y_s = \\alpha X_s + \\beta$.\nUsing the properties of expectation and variance:\nThe mean of the normalized variable is $E[Y_s] = E[\\alpha X_s + \\beta] = \\alpha E[X_s] + \\beta = \\alpha \\mu_s + \\beta$.\nThe variance of the normalized variable is $\\text{Var}(Y_s) = \\text{Var}(\\alpha X_s + \\beta) = \\alpha^2 \\text{Var}(X_s) = \\alpha^2 \\sigma_s^2$.\nThe standard deviation is $\\sigma_{Y_s} = \\sqrt{\\alpha^2 \\sigma_s^2} = |\\alpha| \\sigma_s$. We assume $\\alpha > 0$ to preserve the order of intensities, so $\\sigma_{Y_s} = \\alpha \\sigma_s$.\n\nWe equate these to the target statistics, $\\mu_t$ and $\\sigma_t$:\n$\\alpha \\mu_s + \\beta = \\mu_t$\n$\\alpha \\sigma_s = \\sigma_t$\n\nFrom the second equation, we find $\\alpha = \\frac{\\sigma_t}{\\sigma_s}$.\nSubstituting into the first equation gives $\\beta = \\mu_t - \\alpha \\mu_s = \\mu_t - \\frac{\\sigma_t}{\\sigma_s}\\mu_s$.\n\nWe apply these formulas for each channel using the global source and target statistics:\n- **L channel**:\n$\\alpha_L = \\frac{\\sigma_{tL}}{\\sigma_{sL}} = \\frac{9}{12} = 0.75$\n$\\beta_L = \\mu_{tL} - \\alpha_L \\mu_{sL} = 62 - (0.75)(55) = 62 - 41.25 = 20.75$\n- **a channel**:\n$\\alpha_a = \\frac{\\sigma_{ta}}{\\sigma_{sa}} = \\frac{6}{5} = 1.2$\n$\\beta_a = \\mu_{ta} - \\alpha_a \\mu_{sa} = 18 - (1.2)(22) = 18 - 26.4 = -8.4$\n- **b channel**:\n$\\alpha_b = \\frac{\\sigma_{tb}}{\\sigma_{sb}} = \\frac{5}{7}$\n$\\beta_b = \\mu_{tb} - \\alpha_b \\mu_{sb} = 12 - \\left(\\frac{5}{7}\\right)(8) = 12 - \\frac{40}{7} = \\frac{84-40}{7} = \\frac{44}{7}$\n\n**2. Apply normalization to patch statistics**\n\nLet a patch from the source slide have a channel distribution with mean $\\mu_p$ and standard deviation $\\sigma_p$. After applying the transformation $Y = \\alpha X + \\beta$, the new statistics $(\\mu'_p, \\sigma'_p)$ are:\n$\\mu'_p = E[\\alpha X + \\beta] = \\alpha \\mu_p + \\beta$\n$\\sigma'_p = \\sqrt{\\text{Var}(\\alpha X + \\beta)} = \\alpha \\sigma_p$\n\nWe apply this to patches $P_1$ and $P_2$:\n- **Normalized Patch $P_1'**:\n$\\mu'_{1L} = \\alpha_L \\mu_{1L} + \\beta_L = (0.75)(54) + 20.75 = 40.5 + 20.75 = 61.25$\n$\\sigma'_{1L} = \\alpha_L \\sigma_{1L} = (0.75)(11) = 8.25$\n$\\mu'_{1a} = \\alpha_a \\mu_{1a} + \\beta_a = (1.2)(23) + (-8.4) = 27.6 - 8.4 = 19.2$\n$\\sigma'_{1a} = \\alpha_a \\sigma_{1a} = (1.2)(4.5) = 5.4$\n$\\mu'_{1b} = \\alpha_b \\mu_{1b} + \\beta_b = \\left(\\frac{5}{7}\\right)(9) + \\frac{44}{7} = \\frac{45}{7} + \\frac{44}{7} = \\frac{89}{7}$\n$\\sigma'_{1b} = \\alpha_b \\sigma_{1b} = \\left(\\frac{5}{7}\\right)(6.5) = \\left(\\frac{5}{7}\\right)\\left(\\frac{13}{2}\\right) = \\frac{65}{14}$\n- **Normalized Patch $P_2'**:\n$\\mu'_{2L} = \\alpha_L \\mu_{2L} + \\beta_L = (0.75)(57) + 20.75 = 42.75 + 20.75 = 63.5$\n$\\sigma'_{2L} = \\alpha_L \\sigma_{2L} = (0.75)(13) = 9.75$\n$\\mu'_{2a} = \\alpha_a \\mu_{2a} + \\beta_a = (1.2)(20) + (-8.4) = 24 - 8.4 = 15.6$\n$\\sigma'_{2a} = \\alpha_a \\sigma_{2a} = (1.2)(5.5) = 6.6$\n$\\mu'_{2b} = \\alpha_b \\mu_{2b} + \\beta_b = \\left(\\frac{5}{7}\\right)(7) + \\frac{44}{7} = 5 + \\frac{44}{7} = \\frac{35+44}{7} = \\frac{79}{7}$\n$\\sigma'_{2b} = \\alpha_b \\sigma_{2b} = \\left(\\frac{5}{7}\\right)(6) = \\frac{30}{7}$\n\n**3. Compute Kullback–Leibler Divergence**\n\nThe KL divergence from a Gaussian distribution $P \\sim \\mathcal{N}(\\mu_p, \\sigma_p^2)$ to a target Gaussian distribution $Q \\sim \\mathcal{N}(\\mu_t, \\sigma_t^2)$ is:\n$D_{KL}(P \\| Q) = E_P[\\ln(P/Q)] = \\int p(x)\\ln\\frac{p(x)}{q(x)}dx$. For Gaussian distributions, this simplifies to:\n$D_{KL}(\\mathcal{N}(\\mu_p, \\sigma_p^2) \\| \\mathcal{N}(\\mu_t, \\sigma_t^2)) = \\ln\\left(\\frac{\\sigma_t}{\\sigma_p}\\right) + \\frac{\\sigma_p^2 + (\\mu_p - \\mu_t)^2}{2\\sigma_t^2} - \\frac{1}{2}$\nWe compute this for each patch and channel, before and after normalization.\n\n**Before Normalization:**\n$D_{1L, \\text{before}} = \\ln(\\frac{9}{11}) + \\frac{11^2 + (54 - 62)^2}{2 \\cdot 9^2} - \\frac{1}{2} = \\ln(\\frac{9}{11}) + \\frac{185}{162} - 0.5 \\approx 0.441305$\n$D_{1a, \\text{before}} = \\ln(\\frac{6}{4.5}) + \\frac{4.5^2 + (23 - 18)^2}{2 \\cdot 6^2} - \\frac{1}{2} = \\ln(\\frac{4}{3}) + \\frac{45.25}{72} - 0.5 \\approx 0.416154$\n$D_{1b, \\text{before}} = \\ln(\\frac{5}{6.5}) + \\frac{6.5^2 + (9 - 12)^2}{2 \\cdot 5^2} - \\frac{1}{2} = \\ln(\\frac{10}{13}) + \\frac{51.25}{50} - 0.5 \\approx 0.262636$\n$D_{2L, \\text{before}} = \\ln(\\frac{9}{13}) + \\frac{13^2 + (57 - 62)^2}{2 \\cdot 9^2} - \\frac{1}{2} = \\ln(\\frac{9}{13}) + \\frac{194}{162} - 0.5 \\approx 0.329807$\n$D_{2a, \\text{before}} = \\ln(\\frac{6}{5.5}) + \\frac{5.5^2 + (20 - 18)^2}{2 \\cdot 6^2} - \\frac{1}{2} = \\ln(\\frac{12}{11}) + \\frac{34.25}{72} - 0.5 \\approx 0.062706$\n$D_{2b, \\text{before}} = \\ln(\\frac{5}{6}) + \\frac{6^2 + (7 - 12)^2}{2 \\cdot 5^2} - \\frac{1}{2} = \\ln(\\frac{5}{6}) + \\frac{61}{50} - 0.5 \\approx 0.537678$\n\n**After Normalization:**\n$D_{1L, \\text{after}} = \\ln(\\frac{9}{8.25}) + \\frac{8.25^2 + (61.25 - 62)^2}{2 \\cdot 9^2} - \\frac{1}{2} = \\ln(\\frac{12}{11}) + \\frac{68.625}{162} - 0.5 \\approx 0.010622$\n$D_{1a, \\text{after}} = \\ln(\\frac{6}{5.4}) + \\frac{5.4^2 + (19.2 - 18)^2}{2 \\cdot 6^2} - \\frac{1}{2} = \\ln(\\frac{10}{9}) + \\frac{30.6}{72} - 0.5 \\approx 0.030361$\n$D_{1b, \\text{after}} = \\ln(\\frac{5}{65/14}) + \\frac{(65/14)^2 + (89/7 - 12)^2}{2 \\cdot 5^2} - \\frac{1}{2} = \\ln(\\frac{14}{13}) + \\frac{173}{392} - 0.5 \\approx 0.015434$\n$D_{2L, \\text{after}} = \\ln(\\frac{9}{9.75}) + \\frac{9.75^2 + (63.5 - 62)^2}{2 \\cdot 9^2} - \\frac{1}{2} = \\ln(\\frac{12}{13}) + \\frac{97.3125}{162} - 0.5 \\approx 0.020652$\n$D_{2a, \\text{after}} = \\ln(\\frac{6}{6.6}) + \\frac{6.6^2 + (15.6 - 18)^2}{2 \\cdot 6^2} - \\frac{1}{2} = \\ln(\\frac{10}{11}) + \\frac{49.32}{72} - 0.5 \\approx 0.089690$\n$D_{2b, \\text{after}} = \\ln(\\frac{5}{30/7}) + \\frac{(30/7)^2 + (79/7 - 12)^2}{2 \\cdot 5^2} - \\frac{1}{2} = \\ln(\\frac{7}{6}) + \\frac{37}{98} - 0.5 \\approx 0.031702$\n\n**4. Aggregate KL Divergences**\n\nWe sum the KL divergences across all channels and both patches.\n$D_{\\text{before}} = D_{1L, \\text{before}} + D_{1a, \\text{before}} + D_{1b, \\text{before}} + D_{2L, \\text{before}} + D_{2a, \\text{before}} + D_{2b, \\text{before}}$\n$D_{\\text{before}} \\approx 0.441305 + 0.416154 + 0.262636 + 0.329807 + 0.062706 + 0.537678 = 2.050286$\n\n$D_{\\text{after}} = D_{1L, \\text{after}} + D_{1a, \\text{after}} + D_{1b, \\text{after}} + D_{2L, \\text{after}} + D_{2a, \\text{after}} + D_{2b, \\text{after}}$\n$D_{\\text{after}} \\approx 0.010622 + 0.030361 + 0.015434 + 0.020652 + 0.089690 + 0.031702 = 0.198461$\n\n**5. Compute the reduction $\\Delta D$**\n\nFinally, we compute the difference between the total KL divergence before and after normalization.\n$\\Delta D = D_{\\text{before}} - D_{\\text{after}}$\n$\\Delta D \\approx 2.050286 - 0.198461 = 1.851825$\n\nRounding to four significant figures, we get $1.852$.",
            "answer": "$$\\boxed{1.852}$$"
        }
    ]
}