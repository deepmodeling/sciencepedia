{
    "hands_on_practices": [
        {
            "introduction": "在构建任何预测模型时，获得其在未来新数据上表现的无偏估计至关重要，尤其是在高风险的个性化医疗领域。由于模型选择和超参数调优过程本身会利用数据，如果在同一数据集上评估性能，很容易导致过于乐观的结果。这项练习将引导您设计一个嵌套重采样方案，这是避免信息泄露和选择偏倚、获得模型泛化能力真实度量的黄金标准。",
            "id": "4376899",
            "problem": "您正在评估一个用于系统生物医学中个性化肿瘤学的预测模型。该模型旨在从高维多组学特征 $X \\in \\mathbb{R}^p$（其中 $p \\gg n$，例如 $n = 240$ 名患者和 $p = 10000$ 个转录本）中预测对靶向治疗的二元响应 $Y \\in \\{0,1\\}$。您考虑一个由超参数索引的模型族 $\\{f_j : j = 1,\\dots,M\\}$（例如，弹性网络的正则化强度和混合参数，或核方法的核尺度），其中有 $M$ 个候选超参数配置。\n\n您使用交叉验证（CV）来调整超参数，并使用受试者工作特征曲线下面积（AUC）来衡量性能。对于一个固定的损失函数 $L(\\cdot,\\cdot)$，设配置 $j$ 的真实泛化损失为 $R_j = \\mathbb{E}[L(f_j(X),Y)]$，真实AUC用 $A_j$ 表示。假设您通过重复随机划分，在单个开发数据集上获得了CV估计量 $\\hat{R}_j$ 和 $\\hat{A}_j$。为了分析方便，假设对于每个固定的 $j$，估计量 $\\hat{R}_j$ 是 $R_j$ 的无偏估计，并且其方差为 $\\sigma^2$，不依赖于 $j$；对 $\\hat{A}_j$ 也作类似假设。\n\n您通过经验风险最小化来选择超参数索引 $\\hat{\\jmath}$，即 $\\hat{\\jmath} = \\arg\\min_{j} \\hat{R}_j$（如果使用AUC，则等价于最大化 $\\hat{A}_j$）。在一个患者级别的设置中（可能包括每位患者的多个活检样本和位点特异性批次效应），您的目标是获得一个外部性能的无偏估计，该估计在可交换性假设下将适用于从同一群体中抽取的新患者。\n\n基于以下第一性原理和核心定义：\n- 泛化性能定义为 $R(f) = \\mathbb{E}_{(X,Y)\\sim P}[L(f(X),Y)]$，其中 $(X,Y)$ 从感兴趣的总体分布 $P$ 中抽取。\n- 基于有限样本的经验风险估计量 $\\hat{R}$ 因抽样变异性而是随机变量。\n- 在多个带噪声的估计上进行最小化（或最大化）选择，会引入对随机变量取极值的操作。\n- 调优数据和评估数据的独立性对于无偏的外部性能估计是必需的。\n\n请分析在相同重抽样样本上进行超参数调优所导致的 $\\hat{R}_{\\hat{\\jmath}}$（或 $\\hat{A}_{\\hat{\\jmath}}$）中乐观偏差的方向和驱动因素，并推导出一个嵌套重抽样方案，该方案在上述假设下能产生对外部性能的无偏估计，包括对患者级别分组和数据泄漏控制（例如，标准化、特征选择和概率校准）的正确处理。哪个选项最能满足这些要求？\n\nA. 在完整数据集上执行一次$K$折交叉验证，使用完整数据集标准化特征，通过最大化所有折的平均 $\\hat{A}_j$ 来选择 $\\hat{\\jmath}$，并报告同一个交叉验证得到的 $\\hat{A}_{\\hat{\\jmath}}$ 作为外部性能。这只使用所有数据一次，避免了额外的外层循环。\n\nB. 使用嵌套交叉验证：在患者级别将患者划分为 $K_{\\mathrm{outer}}$ 个外层折，以避免跨活检样本的相关性泄漏。对于每个外层训练集，在内层的 $K_{\\mathrm{inner}}$折交叉验证中严格重复所有预处理步骤（例如，仅使用内层训练划分计算的均值和方差进行标准化，有监督特征选择限制在内层重抽样样本中，以及概率校准）来选择 $\\hat{\\jmath}$；然后使用从内层导出的预处理流程在整个外层训练集上重新拟合 $f_{\\hat{\\jmath}}$，并在未接触过的外层测试集上进行评估。对所有外层折的AUC取平均值，以估计外部性能。\n\nC. 在开始时预留一个单独的测试集，在剩余数据上通过重复交叉验证来调整超参数，如果配置之间出现结果相同或相近的情况，则通过检查在预留测试集上的性能来打破平局，然后最终确定 $\\hat{\\jmath}$；最后报告该测试集上的AUC作为外部性能。\n\nD. 使用非嵌套自助法（bootstrap）：对于每个自助重抽样样本，使用完整的重抽样样本进行标准化，通过最大化袋外AUC来调整超参数，在相同的袋外样本上评估调优后的模型，并将所有重抽样样本的AUC取平均值作为外部性能报告。这将袋外样本同时用于调优和评估。\n\nE. 使用嵌套交叉验证，但首先在完整数据集上执行有监督的单变量特征排序，以选择一个顶层特征子集；然后仅在该固定的特征子集上进行内层交叉验证以调整超参数，并在外层折上进行评估，报告平均的外层AUC作为外部性能。\n\n选择唯一的最佳选项。",
            "solution": "问题要求找到在个性化医疗背景下，获得预测模型外部性能无偏估计的最佳程序。该场景的特点是高维数据（$p \\gg n$）、需要进行超参数调优，以及涉及每位患者多个样本的复杂数据结构。核心挑战是避免因模型选择和数据泄漏而产生的乐观偏差。\n\n我们首先验证问题陈述。\n\n### 步骤1：提取给定信息\n- **任务**：从高维特征 $X \\in \\mathbb{R}^p$ 预测二元响应 $Y \\in \\{0,1\\}$。\n- **数据集**：$n$ 名患者，$p$ 个特征，其中 $p \\gg n$（$n=240, p=10000$）。数据集可能包括每位患者的多个活检样本和位点特异性批次效应。\n- **模型**：由超参数索引的模型族 $\\{f_j : j=1, \\dots, M\\}$。\n- **评估指标**：受试者工作特征曲线下面积（AUC）。\n- **调优方法**：交叉验证（CV）。\n- **估计量**：$\\hat{R}_j$ 和 $\\hat{A}_j$ 分别是模型配置 $j$ 的真实泛化损失 $R_j$ 和真实AUC $A_j$ 的CV估计量。\n- **分析性假设**：对于固定的 $j$，$\\hat{R}_j$ 是 $R_j$ 的无偏估计量，其方差在所有 $j$ 上为常数 $\\sigma^2$。类似假设也适用于 $\\hat{A}_j$。\n- **选择规则**：$\\hat{\\jmath} = \\arg\\min_{j} \\hat{R}_j$（或 $\\arg\\max_{j} \\hat{A}_j$）。\n- **目标**：获得对新患者的外部性能的无偏估计。\n- **第一性原理**：\n    1. 泛化性能定义为 $R(f) = \\mathbb{E}_{(X,Y)\\sim P}[L(f(X),Y)]$。\n    2. 经验估计量 $\\hat{R}$ 是随机变量。\n    3. 在多个带噪声的估计上选择极值会引入偏差。\n    4. 调优数据和评估数据的独立性对于无偏的外部性能估计是必需的。\n\n### 步骤2：使用提取的给定信息进行验证\n问题陈述具有科学依据且定义明确。它探讨了统计机器学习及其在系统生物医学中应用的一个关键且标准的主题：泛化性能的估计。\n- **科学合理性**：泛化误差、经验风险、超参数调优、交叉验证、选择偏差（乐观偏差）和数据泄漏等概念都是基础且描述准确的。该场景（$p \\gg n$，患者级别数据）是现代生物医学研究中挑战的真实写照。\n- **完整性与一致性**：问题是自洽的。它提供了必要的背景（高维数据、超参数调优）、统计挑战（选择偏差）以及解决问题所需的原理。简化假设（具有恒定方差的无偏估计量）是对此现象进行理论分析的标准做法，并不影响问题的实际意义。\n- **清晰度**：语言精确且客观。目标陈述清晰：找到一个能产生外部性能无偏估计的程序。\n\n### 步骤3：结论与行动\n问题陈述是**有效的**。我们可以继续进行求解。\n\n### 正确程序的推导\n\n问题的核心在于，通过调优过程选择的模型的性能估计，如果是在用于调优的同一数据上衡量，则会存在乐观偏差。设 $\\hat{A}_j$ 是超参数设置 $j$ 的AUC的CV估计。调优过程选择 $\\hat{\\jmath} = \\arg\\max_{j} \\hat{A}_j$。由此产生的性能估计是 $\\hat{A}_{\\hat{\\jmath}} = \\max_j \\hat{A}_j$。\n\n由于数据中的随机抽样变异性，每个 $\\hat{A}_j$ 都是一个随机变量。一组随机变量的最大值的期望值，平均而言，将大于其真实均值的最大值。也就是说，$\\mathbb{E}[\\max_j \\hat{A}_j] \\ge \\max_j \\mathbb{E}[\\hat{A}_j]$。如果我们假设 $\\mathbb{E}[\\hat{A}_j] = A_j$（配置 $j$ 的真实AUC），那么 $\\mathbb{E}[\\hat{A}_{\\hat{\\jmath}}] \\ge \\max_j A_j$。这个估计是向上偏置的。更正式地说，我们报告的量 $\\hat{A}_{\\hat{\\jmath}}$ 是所选模型真实性能 $A_{\\hat{\\jmath}}$ 的一个估计。因为 $\\hat{\\jmath}$ 是专门为了最大化 $\\hat{A}_j$ 而选择的，所以 $\\hat{A}_{\\hat{\\jmath}}$ 是对 $A_{\\hat{\\jmath}}$ 的一个乐观估计。\n\n为了获得无偏估计，我们必须在一个与模型构建*过程*（包括超参数调优）完全分离的数据上评估该过程的性能。这就是提供的第四条原则：“调优数据和评估数据的独立性对于无偏的外部性能估计是必需的。”\n\n这个原则直接导向了**嵌套重抽样**策略，例如嵌套交叉验证。\n\n1.  **外层循环（用于性能估计）**：将数据集划分为 $K_{\\mathrm{outer}}$ 个折。其中一折被预留作为测试集，其余 $K_{\\mathrm{outer}}-1$ 折构成训练集。这个循环重复 $K_{\\mathrm{outer}}$ 次，每个折都作为测试集一次。为了尊重数据结构（“每位患者多个活检样本”），这种划分必须在**患者级别**进行。来自同一个患者的所有数据必须位于同一个折中。\n\n2.  **内层循环（用于超参数调优）**：对于每个外层循环的迭代，相应的训练集用于运行一个完整的模型构建流程。该流程包括超参数调优。为了为*这个特定的训练集*选择最佳超参数，在其上执行内层交叉验证。该训练集被划分为 $K_{\\mathrm{inner}}$ 个折，并选择在这些内层折上产生最佳平均性能的超参数配置 $\\hat{\\jmath}_k$（对于外层折 $k$）。\n\n3.  **数据泄漏控制**：任何数据驱动的预处理步骤都是模型拟合过程的一部分，必须完全从每个外层循环内的训练数据中学习。这包括特征归一化/标准化（计算均值和方差）、有监督的特征选择等。这些步骤必须为 $K_{\\mathrm{outer}}$ 个训练集中的每一个从头重新学习。在划分数据前对完整数据集应用从整体学习到的转换，构成了数据泄漏，并使性能估计无效。\n\n4.  **评估与汇总**：一旦内层循环确定了外层折 $k$ 的最优超参数设置 $\\hat{\\jmath}_k$，就用这个设置在*整个*外层训练集上训练一个新模型。然后，该模型的性能在原始的、预留的外层测试集上进行评估。将来自 $K_{\\mathrm{outer}}$ 个测试集中的每一个的性能指标（AUCs）进行平均，以产生一个对整体建模策略的泛化性能的单一、无偏的估计。\n\n这个完整、严谨的程序确保了最终的性能评估在任何时候都不会被用于模型选择或调优的任何方面的数据所污染。\n\n### 逐项分析\n\n**A. 在完整数据集上执行一次$K$折交叉验证，使用完整数据集标准化特征，通过最大化所有折的平均 $\\hat{A}_j$ 来选择 $\\hat{\\jmath}$，并报告同一个交叉验证得到的 $\\hat{A}_{\\hat{\\jmath}}$ 作为外部性能。这只使用所有数据一次，避免了额外的外层循环。**\n- **分析**：这是一个非嵌套交叉验证过程。它使用相同的CV划分来选择最佳模型（$\\hat{\\jmath}$）并报告其性能（$\\hat{A}_{\\hat{\\jmath}}$）。如上所述，这引入了乐观的选择偏差。此外，它明确规定在完整数据集上标准化特征，这是一个明显的数据泄漏案例，测试折的信息污染了训练折。\n- **结论**：**不正确**。\n\n**B. 使用嵌套交叉验证：在患者级别将患者划分为 $K_{\\mathrm{outer}}$ 个外层折，以避免跨活检样本的相关性泄漏。对于每个外层训练集，在内层的 $K_{\\mathrm{inner}}$折交叉验证中严格重复所有预处理步骤（例如，仅使用内层训练划分计算的均值和方差进行标准化，有监督特征选择限制在内层重抽样样本中，以及概率校准）来选择 $\\hat{\\jmath}$；然后使用从内层导出的预处理流程在整个外层训练集上重新拟合 $f_{\\hat{\\jmath}}$，并在未接触过的外层测试集上进行评估。对所有外层折的AUC取平均值，以估计外部性能。**\n- **分析**：此选项正确地描述了嵌套交叉验证过程。它规定了：\n    1.  一个嵌套结构，以将调优与评估分开。\n    2.  在患者级别进行划分，以处理相关数据。\n    3.  将所有预处理和调优步骤封装在外层循环的训练集内，从而防止数据泄漏。\n    4.  在每个折中，在未接触过的外层测试集上进行评估。\n    5.  对外层折的性能进行平均，以得出最终估计。\n该程序严格遵守了获得无偏性能估计的原则。\n- **结论**：**正确**。\n\n**C. 在开始时预留一个单独的测试集，在剩余数据上通过重复交叉验证来调整超参数，如果配置之间出现结果相同或相近的情况，则通过检查在预留测试集上的性能来打破平局，然后最终确定 $\\hat{\\jmath}$；最后报告该测试集上的AUC作为外部性能。**\n- **分析**：单个预留集是一种有效的方法（在某种意义上等同于 $K_{\\mathrm{outer}}=1$），但该选项描述了一个关键缺陷：“通过检查在预留测试集上的性能来打破平局，然后最终确定 $\\hat{\\jmath}$”。这种“偷看”测试集以影响建模决策的行为，即使是为了打破平局，也意味着测试集不再是独立的。它已被用于调优，从而使其用于无偏性能估计变得无效。\n- **结论**：**不正确**。\n\n**D. 使用非嵌套自助法（bootstrap）：对于每个自助重抽样样本，使用完整的重抽样样本进行标准化，通过最大化袋外AUC来调整超参数，在相同的袋外样本上评估调优后的模型，并将所有重抽样样本的AUC取平均值作为外部性能报告。这将袋外样本同时用于调优和评估。**\n- **分析**：该程序使用袋外（OOB）样本进行超参数调优（“最大化袋外AUC”）和最终性能评估（“在相同的袋外样本上评估...”）。这与非嵌套CV（选项A）犯了同样的基本错误。OOB数据被用来选择最佳模型，当使用相同的数据报告性能时，会产生乐观偏差。一个正确的基于自助法的程序也需要一个嵌套结构（例如，“`.632+`”估计量或嵌套自助法）。\n- **结论**：**不正确**。\n\n**E. 使用嵌套交叉验证，但首先在完整数据集上执行有监督的单变量特征排序，以选择一个顶层特征子集；然后仅在该固定的特征子集上进行内层交叉验证以调整超参数，并在外层折上进行评估，报告平均的外层AUC作为外部性能。**\n- **分析**：此选项正确地认识到需要嵌套CV，但在开始时引入了一个重大的数据泄漏错误。在任何划分之前对“完整数据集”进行有监督的特征选择，意味着来自外层测试集的标签信息被用来决定模型中包含哪些特征。这使得特征集本身产生偏差，并将导致过于乐观的性能估计。所有的特征选择都必须在外层循环内部完成，并且只使用该折的外层训练数据。\n- **结论**：**不正确**。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "一个预测模型的准确率或 $AUC$ 等传统指标，并不能完全反映其在临床决策中的实际价值。决策曲线分析 (Decision Curve Analysis, DCA) 提供了一个框架，通过计算净获益 (Net Benefit)，将模型的预测性能与临床后果直接联系起来。本练习要求您从效用理论的第一性原理出发，推导净获益的表达式，从而深刻理解模型如何权衡真阳性带来的益处与假阳性带来的危害。",
            "id": "4376938",
            "problem": "在系统生物医学中，一个临床预测模型为每位患者输出一个校准的风险评分，该评分被解释为从靶向治疗中获益的概率 $p$（例如，携带某种药物基因组学特征，使得某种药物既有效又安全）。在个性化医疗中，临床医生使用一个阈值概率 $\\tau$ 来决定治疗方案：如果 $p \\geq \\tau$ 则治疗，否则不治疗。考虑一个二元健康状态 $D \\in \\{0,1\\}$，其中 $D=1$ 表示如果接受治疗，患者将获益（例如，具有可操作的靶点），而 $D=0$ 表示如果接受治疗，患者不会获益（并且可能受到伤害）。设决策为 $T \\in \\{0,1\\}$，其中 $T=1$ 表示治疗，$T=0$ 表示不治疗。\n\n假设一个预期效用框架基于以下基本基础：\n\n- 效用是在仿射变换下定义的，可以在不改变最优决策的情况下进行平移和缩放。假设效用被锚定，使得两种不治疗结果的效用均为零：$U(T=0,D=1)=0$ 和 $U(T=0,D=0)=0$。\n- 设正确治疗一个会受益的患者的增量效用为 $\\Delta_{1} = U(T=1,D=1) - U(T=0,D=1) > 0$，代表对那些会受益者进行适当治疗所带来的益处。\n- 设治疗一个不会受益的患者的增量效用为 $-\\Delta_{0}$，其中 $\\Delta_{0} = U(T=0,D=0) - U(T=1,D=0) > 0$，代表对那些不会受益者进行不当治疗所造成的伤害。\n- 阈值概率 $\\tau$ 由患者层面的无差异点定义：当 $p=\\tau$ 时，治疗的预期效用等于不治疗的预期效用，因此治疗既不被偏好也不被排斥。\n\n在一个应用了该阈值规则的包含 $N$ 名患者的队列中，令 $TP$ 表示真阳性（接受治疗，$T=1$，且 $D=1$）的数量，令 $FP$ 表示假阳性（接受治疗，$T=1$，但 $D=0$）的数量。决策曲线分析 (DCA) 通过净获益来总结临床价值，净获益定义为阈值策略与不治疗任何人的策略之间的平均预期效用差，并将效用缩放到一个被正确治疗的真阳性的单位。\n\n从上述定义和阈值无差异条件出发，推导一个关于阈值 $\\tau$ 和队列中计数 $(TP,FP)$ 的净获益的封闭形式表达式，该表达式按每位患者由 $N$ 进行归一化，并以 $\\Delta_{1}$ 为单位表示（即，净获益应将每个真阳性计为 $+1$，每个假阳性计为乘以一个依赖于阈值的因子的损失）。你的最终表达式必须用 $TP$、$FP$、$N$ 和 $\\tau$ 来表示。只需提供表达式；无需进行数值四舍五入，也无需在最终的方框答案中报告单位。",
            "solution": "该问题要求推导决策曲线分析 (DCA) 中使用的净获益 (NB) 公式。推导过程将分三个主要步骤进行：首先，建立效用成本和收益（$\\Delta_0$, $\\Delta_1$）与决策阈值 $\\tau$ 之间的关系；其次，计算决策策略相对于默认策略的总效用增益；第三，对此效用增益进行归一化，以得出净获益的最终表达式。\n\n步骤1：从阈值无差异条件推导效用比。\n\n问题陈述，决策阈值 $\\tau$ 被设置在这样一个概率 $p$ 上，即临床医生对于治疗 ($T=1$) 和不治疗 ($T=0$) 处于无差异状态。这种无差异意味着，在预测概率等于阈值 $p=\\tau$ 的条件下，治疗的预期效用等于不治疗的预期效用。\n\n一项决策的预期效用是每种可能结果的效用乘以其各自概率的总和。结果取决于患者真实的潜在状态 $D \\in \\{0,1\\}$。对于风险评分为 $p=\\tau$ 的患者，模型被假定为已校准，这意味着患者实际会受益的概率为 $P(D=1|p=\\tau) = \\tau$。因此，患者不会受益的概率为 $P(D=0|p=\\tau) = 1-\\tau$。\n\n对于风险评分为 $p=\\tau$ 的患者，治疗 ($T=1$) 的预期效用是：\n$$E[U|T=1, p=\\tau] = U(T=1, D=1) \\cdot P(D=1|p=\\tau) + U(T=1, D=0) \\cdot P(D=0|p=\\tau)$$\n$$E[U|T=1, p=\\tau] = U(T=1, D=1) \\cdot \\tau + U(T=1, D=0) \\cdot (1-\\tau)$$\n\n对于风险评分为 $p=\\tau$ 的患者，不治疗 ($T=0$) 的预期效用是：\n$$E[U|T=0, p=\\tau] = U(T=0, D=1) \\cdot P(D=1|p=\\tau) + U(T=0, D=0) \\cdot P(D=0|p=\\tau)$$\n$$E[U|T=0, p=\\tau] = U(T=0, D=1) \\cdot \\tau + U(T=0, D=0) \\cdot (1-\\tau)$$\n\n问题定义的效用使得 $U(T=0, D=1) = 0$ 且 $U(T=0, D=0) = 0$。因此，不治疗的预期效用总是零：\n$$E[U|T=0, p=\\tau] = 0 \\cdot \\tau + 0 \\cdot (1-\\tau) = 0$$\n\n在无差异阈值 $\\tau$ 处，我们令预期效用相等：\n$$E[U|T=1, p=\\tau] = E[U|T=0, p=\\tau]$$\n$$U(T=1, D=1) \\cdot \\tau + U(T=1, D=0) \\cdot (1-\\tau) = 0$$\n\n现在，我们代入增量效用的定义。正确治疗的益处是 $\\Delta_{1} = U(T=1,D=1) - U(T=0,D=1)$。由于 $U(T=0,D=1)=0$，这得出 $U(T=1,D=1) = \\Delta_{1}$。不正确治疗的伤害是 $-\\Delta_{0}$，其中 $\\Delta_{0} = U(T=0,D=0) - U(T=1,D=0)$。由于 $U(T=0,D=0)=0$，这得出 $U(T=1,D=0) = -\\Delta_{0}$。\n\n将这些代入无差异方程：\n$$\\Delta_{1} \\cdot \\tau + (-\\Delta_{0}) \\cdot (1-\\tau) = 0$$\n$$\\Delta_{1} \\tau = \\Delta_{0} (1-\\tau)$$\n\n这个方程提供了危害与收益之比和决策阈值之间的一个关键关系：\n$$\\frac{\\Delta_{0}}{\\Delta_{1}} = \\frac{\\tau}{1-\\tau}$$\n这个比率代表了选择阈值 $\\tau$ 所隐含的假阳性危害与真阳性收益之间的“交换率”。\n\n步骤2：计算决策策略的总效用。\n\n净获益是相对于不治疗任何人的策略来定义的。在“不治疗任何人”的策略下，一个包含 $N$ 名患者的队列的总效用为 $0$，因为所有未接受治疗的患者，无论其真实状态 $D$ 如何，其效用均为 $0$。\n\n接下来，我们计算在使用阈值 $\\tau$ 的决策策略下队列的总效用。如果患者的风险评分 $p \\geq \\tau$，则对其进行治疗。在给定的队列中，这会产生 $TP$ 个真阳性和 $FP$ 个假阳性。\n- 真阳性是指被治疗 ($T=1$) 且会受益 ($D=1$) 的患者。有 $TP$ 名此类患者。每人的效用为 $U(T=1,D=1) = \\Delta_1$。\n- 假阳性是指被治疗 ($T=1$) 但不会受益 ($D=0$) 的患者。有 $FP$ 名此类患者。每人的效用为 $U(T=1,D=0) = -\\Delta_0$。\n- 未被治疗的患者（真阴性和假阴性）的 $T=0$，因此根据问题的定义，他们的效用为 $0$。\n\n在此策略下，队列的总效用是所有患者的效用之和：\n$$\\text{Total Utility}_{\\text{policy}} = TP \\cdot U(T=1,D=1) + FP \\cdot U(T=1,D=0)$$\n$$\\text{Total Utility}_{\\text{policy}} = TP \\cdot \\Delta_1 - FP \\cdot \\Delta_0$$\n\n步骤3：进行归一化，求出每位患者的净获益。\n\n净获益是该策略与“不治疗任何人”的默认策略之间的平均效用差，并以一个真阳性收益 ($\\Delta_1$) 的单位进行缩放。\n\n首先，总效用差（总净效用）为：\n$$\\text{Total Net Utility} = \\text{Total Utility}_{\\text{policy}} - \\text{Total Utility}_{\\text{treat none}}$$\n$$\\text{Total Net Utility} = (TP \\cdot \\Delta_1 - FP \\cdot \\Delta_0) - 0 = TP \\cdot \\Delta_1 - FP \\cdot \\Delta_0$$\n\n为了求出每位患者的平均净效用，我们除以患者总数 $N$：\n$$\\text{Average Net Utility} = \\frac{TP \\cdot \\Delta_1 - FP \\cdot \\Delta_0}{N}$$\n\n最后，将该值除以一个真阳性的收益 $\\Delta_1$ 进行缩放，以真阳性的单位来表示净获益。\n$$\\text{Net Benefit (NB)} = \\frac{\\text{Average Net Utility}}{\\Delta_1} = \\frac{\\frac{TP \\cdot \\Delta_1 - FP \\cdot \\Delta_0}{N}}{\\Delta_1}$$\n$$\\text{NB} = \\frac{1}{N} \\left( \\frac{TP \\cdot \\Delta_1}{\\Delta_1} - \\frac{FP \\cdot \\Delta_0}{\\Delta_1} \\right)$$\n$$\\text{NB} = \\frac{1}{N} \\left( TP - FP \\cdot \\frac{\\Delta_0}{\\Delta_1} \\right)$$\n\n现在，我们将步骤1中推导出的关系 $\\frac{\\Delta_0}{\\Delta_1} = \\frac{\\tau}{1-\\tau}$ 代入此表达式：\n$$\\text{NB} = \\frac{1}{N} \\left( TP - FP \\cdot \\frac{\\tau}{1-\\tau} \\right)$$\n\n这是每位患者净获益的最终封闭形式表达式，是关于 $TP$、$FP$、$N$ 和决策阈值 $\\tau$ 的函数。它也可以写成真阳性率与加权假阳性率之差：\n$$\\text{NB} = \\frac{TP}{N} - \\frac{FP}{N} \\left( \\frac{\\tau}{1-\\tau} \\right)$$\n这个公式表明，基于模型的决策策略的净获益是其识别出的真阳性率，减去其产生的假阳性率所带来的惩罚，其中对每个假阳性的惩罚由决策阈值 $\\tau$ 决定。",
            "answer": "$$\\boxed{\\frac{1}{N} \\left( TP - FP \\frac{\\tau}{1-\\tau} \\right)}$$"
        },
        {
            "introduction": "一个在总体人群中表现出色的模型，可能对不同亚群（如不同种族或临床地点的患者）产生不公平的影响，这是个性化医疗中一个严峻的伦理挑战。本练习探讨了两个关键的公平性标准——均等化赔率 (equalized odds) 和组内校准 (calibration within groups) 之间的内在冲突。通过推导证明在特定条件下两者不可兼得，您将认识到在开发和部署预测模型时必须面对和权衡的公平性问题。",
            "id": "4376953",
            "problem": "一个临床决策支持系统产生一个连续的风险评分 $S \\in [0,1]$，用于预测一个二元结果 $Y \\in \\{0,1\\}$（例如，30天内发生严重药物不良反应的风险）。患者属于两个亚组 $A \\in \\{0,1\\}$ 之一（例如，两个不同的血统或两个临床地点）。设亚组的基准率（或称阳性率）为 $\\pi_a = \\mathbb{P}(Y=1 \\mid A=a)$，且 $\\pi_0 \\neq \\pi_1$。该系统被部署为一个单阈值分类器 $\\hat{Y}_t = \\mathbb{I}\\{S \\ge t\\}$，其中对所有亚组使用相同的阈值 $t \\in (0,1)$。\n\n对此类风险模型，精确的公平性和可靠性概念定义如下：\n\n- 风险评分的均等化赔率（Equalized odds）：评分 $S$ 在给定真实结果的情况下，与亚组条件独立，即 $S \\perp A \\mid Y$。等价地，对于每个阈值 $t \\in (0,1)$，分类器 $\\hat{Y}_t$ 在不同亚组间实现相等的真正例率和假正例率。其中，亚组 $a$ 在阈值 $t$ 下的真正例率（TPR）和假正例率（FPR）分别为 $\\mathrm{TPR}_a(t) = \\mathbb{P}(S \\ge t \\mid Y=1, A=a)$ 和 $\\mathrm{FPR}_a(t) = \\mathbb{P}(S \\ge t \\mid Y=0, A=a)$。\n\n- 组内校准（Calibration within groups）：对于每个亚组 $a$ 和评分值 $s \\in (0,1)$，条件概率等于该评分，即 $\\mathbb{P}(Y=1 \\mid S=s, A=a) = s$。\n\n从以上定义和贝叶斯法则出发，推导在组内校准条件下似然比 $\\frac{f_{S \\mid Y=1,A=a}(s)}{f_{S \\mid Y=0,A=a}(s)}$ 的表达式，并解释当 $\\pi_0 \\neq \\pi_1$ 且评分不具有完全预测性时，均等化赔率和校准之间的不兼容性权衡。然后，通过选择所有正确的陈述来回答以下多项选择题。\n\nA. 一个统一应用于所有亚组的单阈值分类器 $\\hat{Y}_t = \\mathbb{I}\\{S \\ge t\\}$，在 $\\pi_0 \\neq \\pi_1$ 的情况下，可以同时满足均等化赔率和组内校准，只要适当地选择阈值 $t$。\n\nB. 如果 $\\pi_0 \\neq \\pi_1$ 并且风险评分 $S$ 不是完全预测性的（即，在两个结果类别中，$S$ 以非零概率取 $(0,1)$ 内的值），那么没有任何统一应用的单阈值分类器能够同时实现均等化赔率并保持 $S$ 的组内校准。\n\nC. 在组内校准的条件下，似然比 $\\frac{f_{S \\mid Y=1,A=a}(s)}{f_{S \\mid Y=0,A=a}(s)}$ 等于 $\\frac{s}{1-s}$，因此不依赖于亚组基准率。\n\nD. 如果 $S$ 是完全预测性的（即，几乎必然地 $S \\in \\{0,1\\}$），即使在 $\\pi_0 \\neq \\pi_1$ 的情况下，均等化赔率和组内校准之间的不兼容性也会消失。\n\nE. 均等化赔率要求 $S$ 在边际上独立于 $A$（即 $S \\perp A$），因此除非基准率相等，否则均等化赔率无法成立。",
            "solution": "首先验证问题陈述的科学合理性、清晰度和完整性。\n\n### 步骤1：提取已知条件\n-   一个连续的风险评分 $S \\in [0,1]$。\n-   一个二元结果 $Y \\in \\{0,1\\}$。\n-   两个亚组 $A \\in \\{0,1\\}$。\n-   亚组特定的结果基准率：$\\pi_a = \\mathbb{P}(Y=1 \\mid A=a)$。\n-   关于基准率的条件：$\\pi_0 \\neq \\pi_1$。\n-   一个单阈值分类器：$\\hat{Y}_t = \\mathbb{I}\\{S \\ge t\\}$，对于 $t \\in (0,1)$。\n-   均等化赔率的定义：评分 $S$ 在给定真实结果 $Y$ 的条件下，与亚组 $A$ 条件独立，记为 $S \\perp A \\mid Y$。这被陈述为等同于对于每个阈值 $t$，不同亚组间的真正例率（TPR）和假正例率（FPR）相等。\n    -   $\\mathrm{TPR}_a(t) = \\mathbb{P}(S \\ge t \\mid Y=1, A=a)$\n    -   $\\mathrm{FPR}_a(t) = \\mathbb{P}(S \\ge t \\mid Y=0, A=a)$\n    -   均等化赔率意味着对于所有 $t \\in (0,1)$，$\\mathrm{TPR}_0(t) = \\mathrm{TPR}_1(t)$ 且 $\\mathrm{FPR}_0(t) = \\mathrm{FPR}_1(t)$。这等价于在结果的条件下，评分分布在各组之间是相同的：对于 $y \\in \\{0,1\\}$，$f_{S \\mid Y, A}(s \\mid y, 0) = f_{S \\mid Y, A}(s \\mid y, 1)$。\n-   组内校准的定义：对于每个亚组 $a$ 和评分值 $s \\in (0,1)$，结果的条件概率等于该评分：$\\mathbb{P}(Y=1 \\mid S=s, A=a) = s$。\n-   不兼容性的条件：评分不是完全预测性的，意味着它以非零概率取区间 $(0,1)$ 内的值。\n-   任务：在校准的假设下，推导似然比 $\\frac{f_{S \\mid Y=1,A=a}(s)}{f_{S \\mid Y=0,A=a}(s)}$，解释在给定条件下均等化赔率和校准的不兼容性，并评估所提供的选项。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题定义明确且有科学依据。它展示了机器学习公平性研究中的一个经典且重要的结果，该结果由 Kleinberg、Mullainathan 和 Raghavan 首次正式证明。均等化赔率和校准的定义是该领域的标准定义。前提条件（$\\pi_0 \\neq \\pi_1$ 和不完美的评分）是导致不兼容性出现的精确条件。该问题不违反任何科学原则，内容完整且不矛盾，并使用了精确、客观的语言。这是一个形式化的、可验证的数学问题。\n\n### 步骤3：结论与行动\n该问题是**有效的**。现在开始推导解答。\n\n### 似然比和不兼容性的推导\n任务要求在假设评分 $S$ 是组内校准的前提下，推导似然比 $\\frac{f_{S \\mid Y=1,A=a}(s)}{f_{S \\mid Y=0,A=a}(s)}$。\n\n我们从贝叶斯法则开始，它连接了后验概率、先验概率和似然。后验赔率等于似然比乘以先验赔率。在特定亚组 $A=a$ 内，“先验”是亚组特定的基准率。\n$$ \\frac{\\mathbb{P}(Y=1 \\mid S=s, A=a)}{\\mathbb{P}(Y=0 \\mid S=s, A=a)} = \\frac{f_{S \\mid Y=1, A=a}(s)}{f_{S \\mid Y=0, A=a}(s)} \\times \\frac{\\mathbb{P}(Y=1 \\mid A=a)}{\\mathbb{P}(Y=0 \\mid A=a)} $$\n\n这里，$f_{S \\mid Y, A}$ 表示评分 $S$ 的条件概率密度函数。我们可以重新整理这个等式来求解似然比：\n$$ \\frac{f_{S \\mid Y=1, A=a}(s)}{f_{S \\mid Y=0, A=a}(s)} = \\frac{\\mathbb{P}(Y=1 \\mid S=s, A=a)}{\\mathbb{P}(Y=0 \\mid S=s, A=a)} \\times \\frac{\\mathbb{P}(Y=0 \\mid A=a)}{\\mathbb{P}(Y=1 \\mid A=a)} $$\n\n现在，我们应用给定的定义：\n1.  **组内校准**：$\\mathbb{P}(Y=1 \\mid S=s, A=a) = s$。因此，$\\mathbb{P}(Y=0 \\mid S=s, A=a) = 1 - \\mathbb{P}(Y=1 \\mid S=s, A=a) = 1-s$。\n2.  **亚组基准率**：$\\mathbb{P}(Y=1 \\mid A=a) = \\pi_a$。因此，$\\mathbb{P}(Y=0 \\mid A=a) = 1 - \\pi_a$。\n\n将这些代入似然比的方程中：\n$$ \\frac{f_{S \\mid Y=1, A=a}(s)}{f_{S \\mid Y=0, A=a}(s)} = \\frac{s}{1-s} \\times \\frac{1-\\pi_a}{\\pi_a} $$\n这是在组内校准假设下，亚组 $a$ 的似然比表达式。\n\n接下来，我们解释不兼容性。\n**均等化赔率**要求评分 $S$ 的分布在以结果 $Y$ 为条件时，独立于组 $A$。这意味着 $f_{S \\mid Y,A}(s \\mid y, a)$ 不依赖于 $a$。因此，对于 $a=0$ 和 $a=1$ 的分布是相同的：\n-   $f_{S \\mid Y=1, A=0}(s) = f_{S \\mid Y=1, A=1}(s)$\n-   $f_{S \\mid Y=0, A=0}(s) = f_{S \\mid Y=0, A=1}(s)$\n\n如果校准和均等化赔率同时成立，那么似然比对于组 $a=0$ 和 $a=1$ 必须相同。\n$$ \\frac{f_{S \\mid Y=1, A=0}(s)}{f_{S \\mid Y=0, A=0}(s)} = \\frac{f_{S \\mid Y=1, A=1}(s)}{f_{S \\mid Y=0, A=1}(s)} $$\n\n使用我们推导出的在校准条件下的似然比表达式：\n$$ \\frac{s}{1-s} \\frac{1-\\pi_0}{\\pi_0} = \\frac{s}{1-s} \\frac{1-\\pi_1}{\\pi_1} $$\n\n问题陈述中提到评分不是完全预测性的，所以存在评分值 $s \\in (0,1)$，其密度非零。对于任何这样的 $s$，项 $\\frac{s}{1-s}$ 是一个非零的有限数，可以从两边消去：\n$$ \\frac{1-\\pi_0}{\\pi_0} = \\frac{1-\\pi_1}{\\pi_1} $$\n$$ \\frac{1}{\\pi_0} - 1 = \\frac{1}{\\pi_1} - 1 $$\n$$ \\frac{1}{\\pi_0} = \\frac{1}{\\pi_1} $$\n$$ \\pi_0 = \\pi_1 $$\n\n这个结果 $\\pi_0 = \\pi_1$ 与问题的前提 $\\pi_0 \\neq \\pi_1$ 相矛盾。因此，对于一个非完美的预测器，当亚组基准率不相等时，评分 $S$ 不可能同时满足组内校准和均等化赔率。\n\n### 逐项分析\n\n**A. 一个统一应用于所有亚组的单阈值分类器 $\\hat{Y}_t = \\mathbb{I}\\{S \\ge t\\}$，在 $\\pi_0 \\neq \\pi_1$ 的情况下，可以同时满足均等化赔率和组内校准，只要适当地选择阈值 $t$。**\n这个陈述是错误的。均等化赔率和组内校准是风险评分 $S$ 在其整个值域上的属性，而不是分类器 $\\hat{Y}_t$ 在单个阈值 $t$ 上的属性。上述推导表明，在不完美预测器和不相等基准率的条件下，评分 $S$ 本身的这两个属性之间存在根本的不兼容性。选择任何单个阈值 $t$ 都无法解决底层评分函数属性之间的这种根本冲突。\n**结论：错误。**\n\n**B. 如果 $\\pi_0 \\neq \\pi_1$ 并且风险评分 $S$ 不是完全预测性的（即，在两个结果类别中，$S$ 以非零概率取 $(0,1)$ 内的值），那么没有任何统一应用的单阈值分类器能够同时实现均等化赔率并保持 $S$ 的组内校准。**\n这个陈述正确地总结了上面推导的不兼容性定理。“保持校准”意味着评分 $S$ 是校准的。“实现均等化赔率”意味着评分 $S$ 满足均等化赔率。如上所示，当基准率 $\\pi_a$ 不同时，一个不完美的评分 $S$ 不能同时拥有这两个属性。分类器 $\\hat{Y}_t$ 仅仅是评分 $S$ 的一个下游应用；如果 $S$ 不能同时具有这两个属性，那么基于它的任何分类器都不能说是在这两个条件下同时运行的。\n**结论：正确。**\n\n**C. 在组内校准的条件下，似然比 $\\frac{f_{S \\mid Y=1,A=a}(s)}{f_{S \\mid Y=0,A=a}(s)}$ 等于 $\\frac{s}{1-s}$，因此不依赖于亚组基准率。**\n这是错误的。如前所述，似然比是：\n$$ \\frac{f_{S \\mid Y=1, A=a}(s)}{f_{S \\mid Y=0, A=a}(s)} = \\frac{s}{1-s} \\times \\frac{1-\\pi_a}{\\pi_a} $$\n项 $\\frac{s}{1-s}$ 是后验赔率 $\\frac{\\mathbb{P}(Y=1 \\mid S=s, A=a)}{\\mathbb{P}(Y=0 \\mid S=s, A=a)}$。似然比是这个量除以先验赔率 $\\frac{\\pi_a}{1-\\pi_a}$。该表达式明显包含项 $\\pi_a$，即亚组基准率。因此，似然比确实依赖于亚组基准率。\n**结论：错误。**\n\n**D. 如果 $S$ 是完全预测性的（即，几乎必然地 $S \\in \\{0,1\\}$），即使在 $\\pi_0 \\neq \\pi_1$ 的情况下，均等化赔率和组内校准之间的不兼容性也会消失。**\n这个陈述是正确的。一个完全预测性的评分意味着几乎必然有 $S=Y$。让我们检查这两个条件。\n1.  **校准**：$\\mathbb{P}(Y=1 \\mid S=s, A=a)=s$。\n    -   如果 $s=1$，我们评估 $\\mathbb{P}(Y=1 \\mid S=1, A=a)$。因为 $S=1$ 意味着 $Y=1$，所以这是 $\\mathbb{P}(Y=1 \\mid Y=1, A=a) = 1$。条件 $1=s$ 得到满足。\n    -   如果 $s=0$，我们评估 $\\mathbb{P}(Y=1 \\mid S=0, A=a)$。因为 $S=0$ 意味着 $Y=0$，所以这是 $\\mathbb{P}(Y=1 \\mid Y=0, A=a) = 0$。条件 $0=s$ 得到满足。\n    所以，一个完美的预测器是校准的。\n2.  **均等化赔率**：$S \\perp A \\mid Y$。这意味着给定 $Y$ 时，$S$ 的分布对于所有 $A$ 都是相同的。\n    -   对于 $Y=1$，$S$ 的分布是集中在 $S=1$ 的点质量（因为 $S=Y$），与 $A$ 无关。\n    -   对于 $Y=0$，$S$ 的分布是集中在 $S=0$ 的点质量（因为 $S=Y$），与 $A$ 无关。\n    所以，一个完美的预测器满足均等化赔率。\n由于一个完美的预测器同时满足这两个条件，所以不兼容性不适用。不兼容性的数学证明依赖于 $s \\in (0,1)$，这对于完美的预测器来说是不成立的。\n**结论：正确。**\n\n**E. 均等化赔率要求 $S$ 在边际上独立于 $A$（即 $S \\perp A$），因此除非基准率相等，否则均等化赔率无法成立。**\n这个陈述是错误的。前提是错误的。均等化赔率是 $S \\perp A \\mid Y$（条件独立）。这并不意味着边际独立（$S \\perp A$）。为了说明这一点，我们可以使用全概率律来写出组 $a$ 的 $S$ 的边际分布：\n$f_{S|A}(s|a) = f_{S|Y=1,A}(s|1,a) \\mathbb{P}(Y=1|A=a) + f_{S|Y=0,A}(s|0,a) \\mathbb{P}(Y=0|A=a)$。\n在均等化赔率下，$f_{S|Y,A}(s|y,a)$ 不依赖于 $a$，所以我们可以写成 $f_{S|Y}(s|y)$：\n$f_{S|A}(s|a) = f_{S|Y}(s|1) \\pi_a + f_{S|Y}(s|0) (1-\\pi_a)$。\n对于边际独立（$S \\perp A$），$f_{S|A}(s|a)$ 必须不依赖于 $a$。这将要求 $f_{S|Y}(s|1) \\pi_a + f_{S|Y}(s|0) (1-\\pi_a) = C$ 对于某个常数 $C$ 和所有 $a$ 都成立。如果 $\\pi_0 \\neq \\pi_1$，这只有在 $f_{S|Y}(s|1) = f_{S|Y}(s|0)$ 时才能成立，这意味着评分对结果没有预测能力。对于任何有用的、非平凡的评分，均等化赔率与不相等的基准率结合*意味着*违反了边际独立性。前提是错误的，推理也是有缺陷的。\n**结论：错误。**",
            "answer": "$$\\boxed{BD}$$"
        }
    ]
}