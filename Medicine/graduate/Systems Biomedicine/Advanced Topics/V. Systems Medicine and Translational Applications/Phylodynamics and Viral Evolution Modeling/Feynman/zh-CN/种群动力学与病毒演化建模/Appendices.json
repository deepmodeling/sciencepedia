{
    "hands_on_practices": [
        {
            "introduction": "在应用复杂的分子钟模型来推断病毒进化历史之前，一个关键的先决步骤是验证数据中是否包含足够强的“时间信号”。本练习将引导你实现日期随机化检验（Date Randomization Test），这是一种基于置换检验的强大统计方法。通过将观测到的遗传距离与采样时间之间的相关性，与通过随机打乱时间标签生成的零分布进行比较，我们可以稳健地评估观测到的时间信号是真实存在的，还是仅仅源于随机波动。",
            "id": "4374506",
            "problem": "您的任务是实现一个日期随机化检验（Date Randomization Test, DRT），用于在谱系动力学和病毒演化建模中评估分子钟分析的时间信号。考虑一个包含 $n=100$ 个病毒序列的数据集，这些序列是在3年的时间跨度内采样的。对于每个序列 $i$，都提供了两个量：一个采样时间 $t_i$（相对于一个任意起点，以年为单位）和一个从根到梢的遗传距离 $d_i$（来自一个经过时间校准的系统发育树，以每位点替换数为单位）。在严格分子钟假设下，预期的从根到梢遗传距离与采样时间呈线性关系。形式上，一个经过充分检验的模型表明：\n$$\n\\mathbb{E}[d_i \\mid t_i] = r \\cdot (t_i - t_0),\n$$\n其中 $r$ 是替换速率，单位为每位点每年替换数，$t_0$ 是根节点的时间，单位与 $t_i$ 相同。\n\n日期随机化检验（DRT）通过将观测到的 $r$ 估计值与一个零分布进行比较来评估是否存在时间信号，该零分布是通过在序列间随机排列采样时间以消除采样时间与遗传分歧之间的任何关联而形成的。适用以下定义和程序：\n\n1. 时钟速率 $r$ 的普通最小二乘估计值是从数据 $\\{(t_i, d_i)\\}_{i=1}^n$ 中将 $d_i$ 对 $t_i$ 进行回归得到的斜率，由下式给出：\n$$\n\\hat{r} = \\frac{\\sum_{i=1}^{n} (t_i - \\bar{t})(d_i - \\bar{d})}{\\sum_{i=1}^{n} (t_i - \\bar{t})^2},\n$$\n其中 $\\bar{t}$ 和 $\\bar{d}$ 分别是 $t_i$ 和 $d_i$ 的样本均值。\n2. 在无时间信号的零假设下，采样时间和遗传距离是独立的，在序列间排列 $\\{t_i\\}$ 会生成估计量 $\\hat{r}$ 的零分布。通过对时间进行 $b = 1, \\dots, B$ 次独立的随机排列并计算 $\\hat{r}^{(b)}$，可以获得经验零分布。\n3. 用于检测正向时间信号的单边p值使用排列分布计算如下：\n$$\np = \\frac{1 + \\sum_{b=1}^{B} \\mathbb{I}\\left(\\hat{r}^{(b)} \\ge \\hat{r}\\right)}{B + 1},\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。然后通过将 $p$ 与显著性阈值 $\\alpha$ 进行比较来做出检测决策；如果 $p  \\alpha$，则判定为检测到信号。\n\n您的程序必须实现上述检验，并为以下测试套件生成结果，其中的合成数据按如下方式生成。对于每个测试用例，令 $t_i$ 从区间 $[0, 3]$ 年的均匀分布中独立抽取，$n = 100$ 个序列。令 $t_0 = -10$ 年，并根据以下公式生成从根到梢的距离：\n$$\nd_i = r_{\\text{true}} \\cdot (t_i - t_0) + \\epsilon_i,\n$$\n其中 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$ 对所有 $i$ 独立。为确保科学真实性，从根到梢的距离必须为非负值；生成后，任何为负的 $d_i$ 都必须替换为一个小的正常数 $10^{-6}$ 每位点替换数。估计速率的单位必须是每位点每年替换数，所有输出都应表示为不带百分号的浮点数。为保证可复现性，请使用固定的伪随机数生成器种子 $12345$。\n\n测试套件参数集：\n- 用例 A (理想路径，强时间信号)：$r_{\\text{true}} = 1.0 \\times 10^{-3}$，$\\sigma = 5.0 \\times 10^{-4}$，$B = 1000$，$\\alpha = 0.05$。\n- 用例 B (弱信号)：$r_{\\text{true}} = 2.0 \\times 10^{-4}$，$\\sigma = 1.0 \\times 10^{-3}$，$B = 1000$，$\\alpha = 0.05$。\n- 用例 C (零假设，无信号)：$r_{\\text{true}} = 0$，$\\sigma = 1.0 \\times 10^{-3}$，$B = 1000$，$\\alpha = 0.05$。\n- 用例 D (边缘用例，高噪声掩盖信号)：$r_{\\text{true}} = 1.0 \\times 10^{-3}$，$\\sigma = 5.0 \\times 10^{-3}$，$B = 500$，$\\alpha = 0.05$。\n\n对于每个用例，计算：\n- 估计的时钟速率 $\\hat{r}$（单位：每位点每年替换数），如上定义。\n- 单边排列p值 $p$。\n- 检测决策（布尔值），指示 $p  \\alpha$ 是否成立。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个元素对应一个测试用例，并且本身是一个形式为 $[\\hat{r}, p, \\text{detected}]$ 的列表。例如，格式应为 $\\big[\\,[\\hat{r}_A, p_A, \\text{detected}_A], [\\hat{r}_B, p_B, \\text{detected}_B], [\\hat{r}_C, p_C, \\text{detected}_C], [\\hat{r}_D, p_D, \\text{detected}_D]\\,\\big]$，使用标准 Python 列表语法表示。",
            "solution": "本解决方案详细说明了日期随机化检验（DRT）的实现，该检验用于根据问题陈述中的规定，评估模拟病毒序列数据中的时间信号。该方法论基于系统动力学中使用的基本统计学原理。\n\n### 1. 基本原理：严格分子钟与时间信号\n\n核心假设是严格分子钟模型，该模型假定一个序列与其共同祖先之间的遗传分歧与所经过的时间之间存在线性关系。对于一组序列 $\\{i\\}_{i=1}^n$，其采样时间为 $\\{t_i\\}$，从根到梢的遗传距离为 $\\{d_i\\}$，其预期距离由下式给出：\n$$\n\\mathbb{E}[d_i \\mid t_i] = r \\cdot (t_i - t_0)\n$$\n此处，$r$ 是恒定的替换速率（“时钟速率”），$t_0$ 是最近共同祖先的时间（系统发育树的根节点）。如果 $d_i$ 和 $t_i$ 之间存在统计上显著的正相关，则存在“时间信号”，这意味着时钟速率 $r$ 的可测量值大于零。\n\n### 2. 日期随机化检验（DRT）\n\nDRT 是一种基于排列的方法，用于检验不存在时间信号（$r = 0$）的零假设 $H_0$。这等同于陈述遗传距离 $d_i$ 和采样时间 $t_i$ 是相互独立的。该检验按以下步骤进行：\n\n- **检验统计量**：时间信号的强度由估计的时钟速率 $\\hat{r}$ 来量化。它通过对 $d_i$ 关于 $t_i$ 进行普通最小二乘（OLS）线性回归计算出的斜率得到。该估计量的公式为：\n$$\n\\hat{r} = \\frac{\\sum_{i=1}^{n} (t_i - \\bar{t})(d_i - \\bar{d})}{\\sum_{i=1}^{n} (t_i - \\bar{t})^2}\n$$\n其中 $\\bar{t}$ 和 $\\bar{d}$ 分别是时间和距离的样本均值。一个较大的 $\\hat{r}$ 正值表明存在强时间信号。\n\n- **零分布**：为确定观测到的 $\\hat{r}$ 是否具有统计显著性，需将其与一个零分布进行比较。该分布是通过打破时间与距离之间的真实关联生成的。对于大量的排列，$b = 1, \\dots, B$：\n    1. 将采样时间集 $\\{t_i\\}$ 随机打乱，以创建一个排列后的集合 $\\{t_i^{(b)}\\}$。\n    2. 遗传距离 $\\{d_i\\}$ 保持其原始顺序。\n    3. 使用排列后的时间 $\\{t_i^{(b)}\\}$ 和原始距离 $\\{d_i\\}$ 计算一个新的速率 $\\hat{r}^{(b)}$。\n这些速率的集合 $\\{\\hat{r}^{(b)}\\}$ 构成了 $H_0$ 下速率估计量的经验零分布。\n\n- **P值与决策**：单边p值是在零假设下观测到至少与实际观测值 $\\hat{r}$ 一样大的速率的概率，其计算方式如下：\n$$\np = \\frac{1 + \\sum_{b=1}^{B} \\mathbb{I}\\left(\\hat{r}^{(b)} \\ge \\hat{r}\\right)}{B + 1}\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。在分子和分母中加入1是为了将观测到的统计量本身计算在内，并防止p值为0。如果该p值小于预定义的显著性水平 $\\alpha$（即 $p  \\alpha$），则“检测到”时间信号。\n\n### 3. 实现与算法设计\n\n该解决方案使用 Python 的 `numpy` 库实现。一个以 $12345$ 为种子的单一伪随机数生成器用于所有随机过程，以确保完全的可复现性。\n\n**步骤1：数据模拟**\n对于四个测试用例中的每一个，都会生成一个包含 $n=100$ 个序列的合成数据集。\n- 使用一个以种子 $12345$ 初始化的 `numpy.random.Generator` 实例。\n- 采样时间 $t_i$ 从区间 $[0, 3]$ 上的均匀分布中抽取。\n- 高斯噪声项 $\\epsilon_i$ 从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取，其中 $\\sigma$ 特定于该测试用例。\n- 遗传距离按 $d_i = r_{\\text{true}} \\cdot (t_i - t_0) + \\epsilon_i$ 计算，其中 $r_{\\text{true}}$ 是该用例的真实时钟速率，且 $t_0 = -10$。\n- 为了符合物理现实，任何产生的负距离 $d_i$ 都被下限裁剪为一个小的正值 $10^{-6}$。\n\n**步骤2：估计与排列**\n一个单一函数处理每个测试用例。\n- 它首先使用OLS公式从模拟的 $(t_i, d_i)$ 数据对中计算观测速率 $\\hat{r}$。\n- 然后它进入一个进行 $B$ 次迭代的循环（根据用例，$B$ 为 $1000$ 或 $500$）。在每次迭代中，它对时间向量 $t$ 调用生成器的 `permutation` 方法，并重新计算速率以构建零分布 $\\{\\hat{r}^{(b)}\\}$。\n\n**步骤3：最终计算**\n- 排列循环结束后，通过计算大于或等于观测速率 $\\hat{r}$ 的零速率数量并应用指定公式来计算p值 $p$。\n- 通过将 $p$ 与给定的 $\\alpha=0.05$ 进行比较，做出布尔检测决策。\n- 收集每个用例的结果——$[\\hat{r}, p, \\text{detected}]$。\n\n**步骤4：输出格式化**\n最终的结果列表被转换为所需的字符串表示形式（即标准的 Python 列表嵌套列表格式），并打印到标准输出。这种结构化的方法确保了复杂的统计过程被转化为一个正确且可验证的计算算法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Date Randomization Test (DRT) for assessing temporal signal\n    in simulated viral evolution data, as per the problem specification.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Format: (r_true, sigma, B, alpha)\n    test_cases = [\n        (1.0e-3, 5.0e-4, 1000, 0.05),  # Case A: Strong signal\n        (2.0e-4, 1.0e-3, 1000, 0.05),  # Case B: Weak signal\n        (0.0, 1.0e-3, 1000, 0.05),     # Case C: Null, no signal\n        (1.0e-3, 5.0e-3, 500, 0.05),    # Case D: High noise\n    ]\n\n    # Initialize a single pseudo-random number generator for reproducibility.\n    # All random aspects of the simulation will use this generator instance.\n    rng = np.random.default_rng(12345)\n\n    # General parameters\n    n = 100          # Number of sequences\n    t0 = -10.0       # Time of the root in years\n    t_span_max = 3.0 # Sampling time upper bound in years\n    d_min = 1e-6     # Minimum allowed genetic distance\n\n    results = []\n    \n    def calculate_rate(times, distances):\n        \"\"\"\n        Calculates the OLS slope (rate) of distances regressed on times.\n        \"\"\"\n        t_mean = np.mean(times)\n        d_mean = np.mean(distances)\n        \n        # Denominator of OLS slope formula. Handle case of zero variance in times.\n        # This is extremely unlikely with float uniform random numbers but is good practice.\n        t_var_sum = np.sum((times - t_mean)**2)\n        if t_var_sum == 0:\n            return 0.0\n        \n        # Numerator of OLS slope formula\n        td_cov_sum = np.sum((times - t_mean) * (distances - d_mean))\n        \n        return td_cov_sum / t_var_sum\n\n    for r_true, sigma, B, alpha in test_cases:\n        # Step 1: Generate synthetic data for the current test case\n        # Sampling times t_i are drawn from a uniform distribution.\n        t = rng.uniform(low=0.0, high=t_span_max, size=n)\n\n        # Error terms epsilon_i are drawn from a normal distribution.\n        epsilon = rng.normal(loc=0.0, scale=sigma, size=n)\n\n        # Generate root-to-tip distances d_i based on the strict clock model.\n        d = r_true * (t - t0) + epsilon\n\n        # Enforce non-negativity constraint for genetic distances.\n        d[d  0] = d_min\n        \n        # Step 2: Calculate the observed clock rate\n        r_hat = calculate_rate(t, d)\n        \n        # Step 3: Perform the permutation test\n        null_rates = np.empty(B)\n        for i in range(B):\n            # Permute the sampling times randomly.\n            t_permuted = rng.permutation(t)\n            # Calculate the rate for the permuted data.\n            # This builds the null distribution.\n            null_rates[i] = calculate_rate(t_permuted, d)\n            \n        # Step 4: Compute the one-sided p-value and make a decision\n        # Count how many null rates are greater than or equal to the observed rate.\n        count_ge = np.sum(null_rates >= r_hat)\n        \n        # Calculate p-value. The +1s account for the observed statistic.\n        p_value = (1.0 + count_ge) / (B + 1.0)\n        \n        # Decision: A temporal signal is detected if p  alpha.\n        detected = p_value  alpha\n        \n        results.append([r_hat, p_value, detected])\n\n    # Final print statement in the exact required format.\n    # The string representation of a list of lists is desired.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "一旦确认了数据中存在可靠的时间信号，我们就可以开始构建谱系动力学模型，将系统发育树的谱系分支模式与病毒的种群动态联系起来。本练习将带你深入谱系动力学推断的核心——溯祖似然函数的计算。你将从非齐次泊松过程的第一性原理出发，推导并实现一个给定系统发育树在指数增长有效种群数量模型下的似然函数。",
            "id": "4374502",
            "problem": "给定一个所有样本均在当前时间采集的、有时间刻度的等时系统发育树，其溯祖事件的时间是已知的。考虑一个在指数增长模型下，具有时变有效种群大小的 Kingman 溯祖模型。设 $t \\ge 0$ 表示从现在往回计算的时间，单位为年。假设有效种群大小轨迹为 $N_{e}(t) = N_{e0} \\exp(- r t)$，其中增长率 $r$ 的单位为 $\\text{year}^{-1}$，当前时间的有效种群大小 $N_{e0}$ 的单位为个体数。该系统发育树有 $n$ 个在时间 $t=0$ 采样的叶节点，其 $n-1$ 个内部节点（溯祖事件）发生在距今严格递增的时间点 $0  t_1  t_2  \\dots  t_{n-1}$。在回溯时间 $t \\in [t_{i-1}, t_{i})$（其中 $t_0 = 0$），存在 $k_i = n - (i-1)$ 个谱系。\n\n任务：仅从以下两个基本事实出发\n- 在具有时变有效种群大小 $N_{e}(t)$ 的 Kingman 溯祖模型下，当存在 $k$ 个谱系时，瞬时总溯祖风险率为二项式系数 $\\binom{k}{2}$ 除以 $N_{e}(t)$，以及\n- 对于一个风险率为 $h(t)$ 的非齐次泊松过程，其在某个区间上的事件时间密度由生存因子 $\\exp\\!\\left(- \\int h(u)\\,du \\right)$ 和在事件时间点计算的风险率的乘积构成，\n推导出在模型 $N_{e}(t) = N_{e0} \\exp(- r t)$ 下，给定树的溯祖对数似然，并将其表示为 $r$ 和 $N_{e0}$ 的函数。你的推导过程应清楚说明需要哪些从树中得到的量以及它们如何组合，并应明确地将 $r = 0$ 的边界情况作为指数模型的极限情况来处理。\n\n然后，实现一个程序，为几个指定的测试用例计算自然对数似然（一个无量纲实数）。每个测试用例提供：叶节点数 $n$，距今严格递增的溯祖时间列表 $[t_1, \\dots, t_{n-1}]$（单位为年），增长率 $r$（单位为 $\\text{year}^{-1}$），以及 $N_{e0}$（单位为个体数）。你的程序必须：\n- 仅使用上述原理和你推导的表达式来计算对数似然，\n- 使用你公式的显式极限来处理 $r=0$ 的情况，\n- 假设所有时间的单位都是年，$r$ 的单位是 $\\text{year}^{-1}$，$N_{e0}$ 的单位是个体数，\n- 返回一个列表，其中包含每个测试用例的对数似然值（浮点数）。\n\n此外，在你的推导中指出，对于此模型，树的哪些统计量足以评估似然。\n\n需要在程序内部实现的测试套件（不读取任何输入）：\n- 案例 A（一般情况）：$n = 5$，时间 $[0.2, 0.5, 1.1, 1.8]$，$r = 0.5$，$N_{e0} = 8000$。\n- 案例 B（边界情况 $r=0$）：$n = 5$，时间 $[0.2, 0.5, 1.1, 1.8]$，$r = 0.0$，$N_{e0} = 8000$。\n- 案例 C（谱系少，中度增长）：$n = 3$，时间 $[0.1, 2.0]$，$r = 0.2$，$N_{e0} = 1000$。\n- 案例 D（负增长参数，即时间上向前增长）：$n = 4$，时间 $[0.05, 0.07, 0.09]$，$r = -0.1$，$N_{e0} = 2000$。\n- 案例 E（大的正 $r$）：$n = 4$，时间 $[0.3, 0.6, 1.2]$，$r = 1.5$，$N_{e0} = 500$。\n\n要求的最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[resultA,resultB,resultC,resultD,resultE]”）。每个结果必须是对应案例的自然对数似然值，顺序与上面列出的一致。不应打印单位，也不应输出任何其他文本。",
            "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n- **模型**：具有时变有效种群大小 $N_{e}(t)$ 的 Kingman 溯祖模型。\n- **种群大小轨迹**：$N_{e}(t) = N_{e0} \\exp(-r t)$，其中 $t \\ge 0$ 是从现在往回计算的时间，单位为年。$N_{e0}$ 是当前时间的有效种群大小，$r$ 是指数增长率，单位为 $\\text{year}^{-1}$。\n- **系统发育数据**：一个有 $n$ 个叶节点在 $t=0$ 采样的等时性、有时间刻度的系统发育树。\n- **溯祖时间**：一组 $n-1$ 个严格递增的事件时间：$0  t_1  t_2  \\dots  t_{n-1}$ 年（距今）。\n- **谱系数量**：在任何回溯时间区间 $[t_{i-1}, t_i)$（其中 $t_0=0$），存在 $k_i = n - (i-1)$ 个谱系。\n- **基本事实 1**：对于 $k$ 个谱系，瞬时总溯祖风险率为 $\\lambda_k(t) = \\binom{k}{2} / N_e(t)$。\n- **基本事实 2**：风险率为 $h(t)$ 的非齐次泊松过程中，事件时间的概率密度函数是在事件时间点的风险率与生存因子的乘积：$p(t) = h(t) \\exp\\left(-\\int_{t_{start}}^{t} h(u)\\,du \\right)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据**：该问题基于 Kingman 溯祖模型，这是群体遗传学和系统发育动力学中的一个基本框架。有效种群大小的指数增长模型是一个标准且特性明确的模型。非齐次泊松过程的风险率和似然之间的关系是概率论的核心概念。该问题在科学上和数学上都是合理的。\n- **适定性**：该问题提供了推导对数似然函数所需的所有必要定义、常数和数据。它要求为确定的输入提供特定的输出（对数似然值），使得目标明确且计算上可解。\n- **客观性**：该问题以精确的数学和科学语言陈述，没有主观性或模糊性。\n- **完整性与一致性**：已知条件是自洽且一致的。$N_e(t)$、溯祖风险率和似然密度的定义都是标准的，并且相互兼容。\n- **所有其他标准均已满足**：该问题是可形式化的、现实的、结构良好的和可验证的。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个完整的、有理有据的解决方案。\n\n## 溯祖对数似然的推导\n\n观测到给定溯祖时间集合 $\\{t_1, \\dots, t_{n-1}\\}$ 的似然，是对于每个区间 $[t_{i-1}, t_i)$ 两种事件概率的乘积：(1) 在开区间 $(t_{i-1}, t_i)$ 内没有发生溯祖事件，以及 (2) 在时间 $t_i$ 发生了一个溯祖事件。这由非齐次泊松过程的理论所决定。\n\n**1. 定义风险函数**\n时间从现在（$t=0$）开始向后计算。在区间 $[t_{i-1}, t_i)$ 内，有 $k_i = n-(i-1)$ 个谱系。根据问题陈述，瞬时溯祖风险率为：\n$$ \\lambda_{k_i}(t) = \\frac{\\binom{k_i}{2}}{N_e(t)} $$\n代入有效种群大小模型 $N_e(t) = N_{e0} \\exp(-rt)$，我们得到：\n$$ \\lambda_{k_i}(t) = \\frac{\\binom{k_i}{2}}{N_{e0} \\exp(-rt)} = \\frac{\\binom{k_i}{2}}{N_{e0}} e^{rt} $$\n\n**2. 构建每个区间的似然贡献**\n使用问题中给出的关于非齐次泊松过程事件时间密度的规则，观测到第 $i$ 个溯祖事件发生在时间 $t_i$（条件是在 $[t_{i-1}, t_i)$ 内没有事件发生）的似然贡献为：\n$$ L_i = \\lambda_{k_i}(t_i) \\exp\\left( - \\int_{t_{i-1}}^{t_i} \\lambda_{k_i}(u) \\, du \\right) $$\n\n**3. 构建总对数似然**\n整棵树的总似然是来自每个溯祖事件的似然贡献的乘积，因为这些事件是条件独立的：\n$$ L = \\prod_{i=1}^{n-1} L_i $$\n总对数似然 $\\mathcal{L} = \\ln(L)$ 是各个对数似然的总和：\n$$ \\mathcal{L} = \\sum_{i=1}^{n-1} \\ln(L_i) = \\sum_{i=1}^{n-1} \\left[ \\ln(\\lambda_{k_i}(t_i)) - \\int_{t_{i-1}}^{t_i} \\lambda_{k_i}(u) \\, du \\right] $$\n这将对数似然分为两个部分：一个是在事件时间点计算的对数风险率之和，另一个是在等待区间上的积分风险率之和。\n\n**4. 情况 1：一般情况 ($r \\neq 0$)**\n我们计算对数似然的两个组成部分。\n\n*   **对数风险率部分：**\n    $$ \\sum_{i=1}^{n-1} \\ln(\\lambda_{k_i}(t_i)) = \\sum_{i=1}^{n-1} \\ln\\left( \\frac{\\binom{k_i}{2}}{N_{e0}} e^{rt_i} \\right) = \\sum_{i=1}^{n-1} \\left[ \\ln\\binom{k_i}{2} - \\ln(N_{e0}) + rt_i \\right] $$\n    $$ = \\left( \\sum_{i=1}^{n-1} \\ln\\binom{k_i}{2} \\right) - (n-1)\\ln(N_{e0}) + r \\sum_{i=1}^{n-1} t_i $$\n\n*   **积分风险率部分：**\n    $$ \\int_{t_{i-1}}^{t_i} \\lambda_{k_i}(u) \\, du = \\int_{t_{i-1}}^{t_i} \\frac{\\binom{k_i}{2}}{N_{e0}} e^{ru} \\, du = \\frac{\\binom{k_i}{2}}{N_{e0}} \\left[ \\frac{e^{ru}}{r} \\right]_{t_{i-1}}^{t_i} = \\frac{\\binom{k_i}{2}}{rN_{e0}} (e^{rt_i} - e^{rt_{i-1}}) $$\n    总积分风险率是所有区间的总和：\n    $$ \\sum_{i=1}^{n-1} \\int_{t_{i-1}}^{t_i} \\lambda_{k_i}(u) \\, du = \\frac{1}{rN_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (e^{rt_i} - e^{rt_{i-1}}) $$\n\n*   **$r \\neq 0$ 时的完整对数似然：**\n    结合各部分，得到最终表达式：\n    $$ \\mathcal{L}(r, N_{e0}) = \\left(\\sum_{i=1}^{n-1} \\ln\\binom{k_i}{2}\\right) - (n-1)\\ln(N_{e0}) + r\\sum_{i=1}^{n-1} t_i - \\frac{1}{rN_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (e^{rt_i} - e^{rt_{i-1}}) $$\n\n**5. 情况 2：边界情况 ($r = 0$)**\n当 $r=0$ 时，种群大小是恒定的：$N_e(t) = N_{e0}$。在每个有 $k_i$ 个谱系的区间内，风险率也是恒定的：$\\lambda_{k_i}(t) = \\binom{k_i}{2} / N_{e0}$。\n\n*   **对数风险率部分：**\n    $$ \\sum_{i=1}^{n-1} \\ln(\\lambda_{k_i}(t_i)) = \\sum_{i=1}^{n-1} \\ln\\left( \\frac{\\binom{k_i}{2}}{N_{e0}} \\right) = \\left(\\sum_{i=1}^{n-1} \\ln\\binom{k_i}{2}\\right) - (n-1)\\ln(N_{e0}) $$\n\n*   **积分风险率部分：**\n    $$ \\int_{t_{i-1}}^{t_i} \\lambda_{k_i}(u) \\, du = \\int_{t_{i-1}}^{t_i} \\frac{\\binom{k_i}{2}}{N_{e0}} \\, du = \\frac{\\binom{k_i}{2}}{N_{e0}} (t_i - t_{i-1}) $$\n    总积分风险率为：\n    $$ \\sum_{i=1}^{n-1} \\frac{\\binom{k_i}{2}}{N_{e0}} (t_i - t_{i-1}) = \\frac{1}{N_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (t_i - t_{i-1}) $$\n\n*   **$r = 0$ 时的完整对数似然：**\n    $$ \\mathcal{L}(0, N_{e0}) = \\left(\\sum_{i=1}^{n-1} \\ln\\binom{k_i}{2}\\right) - (n-1)\\ln(N_{e0}) - \\frac{1}{N_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (t_i - t_{i-1}) $$\n\n**6. 一致性检验：$r \\to 0$ 的极限**\n为确保一致性，我们对通用公式 $\\mathcal{L}(r, N_{e0})$ 取 $r \\to 0$ 的极限。关键项是积分风险率。我们对小的 $x$ 使用泰勒展开 $e^x \\approx 1+x$：\n$$ \\lim_{r\\to 0} \\frac{1}{rN_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (e^{rt_i} - e^{rt_{i-1}}) $$\n$$ = \\lim_{r\\to 0} \\frac{1}{rN_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} ((1+rt_i) - (1+rt_{i-1}) + O(r^2)) $$\n$$ = \\lim_{r\\to 0} \\frac{1}{rN_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (r(t_i - t_{i-1}) + O(r^2)) $$\n$$ = \\frac{1}{N_{e0}} \\sum_{i=1}^{n-1} \\binom{k_i}{2} (t_i - t_{i-1}) $$\n当 $r \\to 0$ 时，$r \\sum t_i \\to 0$。因此，通用表达式的极限等于专门为 $r=0$ 推导的表达式，这证实了公式的正确性。\n\n**7. 充分统计量**\n为了评估对数似然，需要样本数 $n$ 和完整的溯祖时间集合 $\\{t_1, t_2, \\dots, t_{n-1}\\}$。表达式中包含的求和项依赖于每个单独的 $t_i$ 和相应的区间长度 $(t_i - t_{i-1})$，这些无法简化为更小的一组概要统计量（例如仅时间的总和或总树高）。因此，对于此模型，树的充分统计量由对 $(n, \\{t_1, \\dots, t_{n-1}\\})$ 构成。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_log_likelihood(n: int, times: list[float], r: float, Ne0: float) -> float:\n    \"\"\"\n    Computes the coalescent log-likelihood for a dated phylogeny under an exponential growth model.\n\n    Args:\n        n: The number of tips in the phylogeny.\n        times: A list of n-1 strictly increasing coalescent event times before present.\n        r: The exponential growth rate (r > 0 for population decline backwards in time).\n        Ne0: The effective population size at present (t=0).\n\n    Returns:\n        The natural log-likelihood.\n    \"\"\"\n    if n  2:\n        return 0.0\n\n    num_coalescent_events = n - 1\n    # Prepend t_0 = 0 to the list of coalescent times.\n    all_times = [0.0] + times\n\n    # --- Term 1: Sum of log-hazards at event times ---\n    # This term is of the form:\n    # sum(ln(C(k_i, 2))) - (n-1)*ln(Ne0) + r*sum(t_i)\n    \n    # Calculate sum(ln(C(k_i, 2)))\n    sum_log_binom_k_2 = 0.0\n    for i in range(1, num_coalescent_events + 1):\n        # In the interval [t_{i-1}, t_i), there are k_i = n - (i-1) lineages.\n        k_i = n - (i - 1)\n        binom_k_2 = k_i * (k_i - 1) / 2.0\n        # If binom_k_2 is 0 or less (e.g., k_i  2), its log is -inf.\n        # This only happens if n  2, handled at start.\n        sum_log_binom_k_2 += np.log(binom_k_2)\n\n    # Calculate r * sum(t_i)\n    sum_of_times = sum(times)\n    r_sum_t = r * sum_of_times\n\n    log_hazard_term = sum_log_binom_k_2 - num_coalescent_events * np.log(Ne0) + r_sum_t\n\n    # --- Term 2: Sum of integrated hazards over intervals ---\n    # This term is subtracted from Term 1.\n    \n    # This will hold sum( C(k_i, 2) * (t_i - t_{i-1}) ) for r=0\n    # or sum( C(k_i, 2) * (exp(r*t_i) - exp(r*t_{i-1})) ) for r!=0\n    integrated_hazard_sum_raw = 0.0\n\n    if r == 0.0:\n        # Constant population size case\n        for i in range(1, num_coalescent_events + 1):\n            k_i = n - (i - 1)\n            binom_k_2 = k_i * (k_i - 1) / 2.0\n            t_curr = all_times[i]\n            t_prev = all_times[i-1]\n            interval_length = t_curr - t_prev\n            integrated_hazard_sum_raw += binom_k_2 * interval_length\n        integrated_hazard_term = integrated_hazard_sum_raw / Ne0\n    else:\n        # Exponential growth/decline case\n        for i in range(1, num_coalescent_events + 1):\n            k_i = n - (i - 1)\n            binom_k_2 = k_i * (k_i - 1) / 2.0\n            t_curr = all_times[i]\n            t_prev = all_times[i-1]\n            integrated_hazard_sum_raw += binom_k_2 * (np.exp(r * t_curr) - np.exp(r * t_prev))\n        integrated_hazard_term = integrated_hazard_sum_raw / (r * Ne0)\n    \n    # Final log-likelihood is Term 1 - Term 2\n    log_likelihood = log_hazard_term - integrated_hazard_term\n    \n    return log_likelihood\n\n\ndef solve():\n    \"\"\"\n    Solves for the log-likelihood for the predefined test cases.\n    \"\"\"\n    test_cases = [\n        # Case A (general)\n        {'n': 5, 'times': [0.2, 0.5, 1.1, 1.8], 'r': 0.5, 'Ne0': 8000},\n        # Case B (boundary r=0)\n        {'n': 5, 'times': [0.2, 0.5, 1.1, 1.8], 'r': 0.0, 'Ne0': 8000},\n        # Case C (few lineages, moderate growth)\n        {'n': 3, 'times': [0.1, 2.0], 'r': 0.2, 'Ne0': 1000},\n        # Case D (negative growth parameter)\n        {'n': 4, 'times': [0.05, 0.07, 0.09], 'r': -0.1, 'Ne0': 2000},\n        # Case E (large positive r)\n        {'n': 4, 'times': [0.3, 0.6, 1.2], 'r': 1.5, 'Ne0': 500},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_log_likelihood(case['n'], case['times'], case['r'], case['Ne0'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{res:.8f}' for res in results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的种群动态历史往往比简单的参数模型（如指数增长）所能描述的要复杂得多，因此我们需要更灵活的非参数方法。这项高级练习将向你介绍高斯过程（Gaussian Process）这一强大的非参数工具，用于重建有效种群数量 $N_e(t)$ 的轨迹。你将学习如何应用一种严谨的统计方法——分块交叉验证（blocked cross-validation）——来选择高斯过程模型的关键平滑超参数，从而确保模型在具备灵活性的同时也能有效避免过拟合。",
            "id": "4374476",
            "problem": "设计并实现一个完整的程序，该程序使用一种基于原则的分块交叉验证方案和一个定义在留出时间区间上的预测损失函数，为基于高斯过程（GP）的有效种群大小随时间变化（记为 $N_e(t)$）的重建选择一个平滑超参数。您必须使用的科学基础和定义如下。\n\n从 Kingman 的溯祖理论开始。当在时间 $t$ 有 $k$ 个共存的谱系时，瞬时溯祖率为 $\\lambda_k(t) = \\binom{k}{2}/N_e(t)$。对于一个溯祖间隔 $[t_i, t_{i+1}]$（在此期间谱系数量恒定为 $k_i$），在模型 $N_e(t)$ 下的似然贡献等于该区间上的生存概率（无溯祖）与在 $t_{i+1}$ 发生溯祖事件时的终点风险率的乘积。当该区间以溯祖事件结束时，其对数形式的贡献为 $-\\int_{t_i}^{t_{i+1}} \\lambda_{k_i}(t) \\, dt + \\log \\lambda_{k_i}(t_{i+1})$。此处假设所提供数据中的每个区间都以一个溯祖事件结束。\n\n设 $g(t) = \\log N_e(t)$ 被建模为一个零均值高斯过程（GP），其协方差为平方指数协方差（也称为径向基函数核），$k_\\ell(t, t') = \\sigma_f^2 \\exp\\left(-\\frac{(t - t')^2}{2 \\ell^2}\\right)$，其中信号方差固定为 $\\sigma_f^2 = 1$，长度尺度 $\\ell  0$ 可调。用于拟合GP的观测值仅在训练区间上由经典的天际线式矩估计量构建：对于一个持续时间为 $\\Delta t_i = t_{i+1} - t_i$ 且谱系数量为 $k_i$ 的区间 $[t_i, t_{i+1}]$，在中点 $s_i = (t_i + t_{i+1})/2$ 处定义一个伪观测值 $y_i = \\log\\left(\\binom{k_i}{2} \\, \\Delta t_i\\right)$。这些 $(s_i, y_i)$ 对（仅适用于训练折中的区间）被用于标准高斯过程回归，其观测噪声方差为独立同分布的 $\\sigma_n^2$，以生成一个依赖于 $\\ell$ 选择的后验均值函数 $\\hat{g}_\\ell(t)$。\n\n定义一个适用于时序数据的分块 $K$-折交叉验证方案：将区间序列按时间顺序划分为 $K$ 个连续的块，各块大小差异最多为一个区间。对于第 $j$ 折，仅使用训练块（除第 $j$ 块外的所有块）来拟合GP，并通过将 $N_e(t) = \\exp(\\hat{g}_\\ell(t))$ 代入这些留出区间上的溯祖对数似然中，在留出的第 $j$ 块上评估预测负对数似然。对于每个谱系数量为 $k_i$ 的留出区间 $[t_i, t_{i+1}]$，将该折的损失定义为\n$$\n\\mathcal{L}_i(\\ell) \\;=\\; \\int_{t_i}^{t_{i+1}} \\frac{\\binom{k_i}{2}}{\\exp(\\hat{g}_\\ell(t))} \\, dt \\;-\\; \\log\\!\\left(\\frac{\\binom{k_i}{2}}{\\exp(\\hat{g}_\\ell(t_{i+1}))}\\right),\n$$\n并将该折的得分定义为留出块中所有区间的损失之和。$\\ell$ 的交叉验证得分是 $K$ 个折得分的平均值。每个时间积分使用梯形法则进行数值逼近，每个留出区间分为 $M = 64$ 个相等的子区间。选择使平均留出得分最小的 $\\ell$，若有多个最小值，则选择其中最小的 $\\ell$ 来打破平局。\n\n实现上述完整过程，并将其应用于以下测试套件。在每个测试案例中，时间以任意一致的单位度量，您必须以相同的单位报告所选的 $\\ell$。在所有案例中均使用 $\\sigma_f^2 = 1$ 和 $\\sigma_n^2 = 0.0025$。在所有案例中，折数均为 $K = 3$。在每个案例中，输入包含来自单个树的连续溯祖间隔列表，且仅在现今采样，因此每个区间都以一个溯祖事件结束，并且谱系数量在区间边界处减一。对于区间 $i$，通过持续时间 $\\Delta t_i$ 给出 $(t_i, t_{i+1}, k_i)$，其中 $t_0 = 0$ 且 $t_{i+1} = t_i + \\Delta t_i$，并且 $k_i$ 的取值为 $k_1 = 10, k_2 = 9, k_3 = 8, k_4 = 7, k_5 = 6, k_6 = 5, k_7 = 4, k_8 = 3, k_9 = 2$。\n\n- 测试案例 1：\n  - 持续时间 $\\Delta t_i$: $[0.12, 0.09, 0.11, 0.14, 0.20, 0.18, 0.25, 0.30, 0.45]$。\n  - 候选长度尺度 $\\ell$: $[0.05, 0.10, 0.20, 0.40]$。\n\n- 测试案例 2：\n  - 持续时间 $\\Delta t_i$: $[0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13]$。\n  - 候选长度尺度 $\\ell$: $[0.20, 0.40, 0.80]$。\n\n- 测试案例 3：\n  - 持续时间 $\\Delta t_i$: $[0.05, 0.25, 0.06, 0.30, 0.05, 0.28, 0.06, 0.26, 0.05]$。\n  - 候选长度尺度 $\\ell$: $[0.05, 0.10, 0.20]$。\n\n您的程序必须：\n- 仅从每个交叉验证划分中的训练折构建中点 $s_i$ 和天际线伪观测值 $y_i$。\n- 对于每个候选 $\\ell$，使用核函数 $k_\\ell$（其中 $\\sigma_f^2 = 1$）和观测噪声方差 $\\sigma_n^2 = 0.0025$，在评估留出损失所需的求积节点上计算高斯过程后验均值 $\\hat{g}_\\ell(t)$。\n- 计算 $K$ 折的平均留出负对数似然，并选择使其最小化的 $\\ell$，按指定方式打破平局。\n\n最终输出格式：您的程序应生成单行输出，其中包含三个测试案例所选的 $\\ell$，形式为用方括号括起来的逗号分隔列表（例如，$[0.10,0.40,0.05]$）。以时间单位报告每个所选的 $\\ell$，格式为标准浮点数。不应打印任何其他文本。",
            "solution": "该问题要求设计一个程序，为病毒有效种群大小 $N_e(t)$ 随时间变化的高斯过程（GP）模型选择一个最优的平滑超参数，即长度尺度 $\\ell$。该选择基于一种基于原则的分块交叉验证方案和一个源自溯祖理论的预测损失函数。该方法按以下步骤执行。\n\n**1. 科学模型构建**\n模型的核心在于 Kingman 的溯祖理论，该理论指出，在时间 $t$ 的 $k$ 个谱系的溯祖率为 $\\lambda_k(t) = \\binom{k}{2} / N_e(t)$。对数有效种群大小 $g(t) = \\log N_e(t)$ 被建模为一个零均值高斯过程。该GP的特征是一个平方指数协方差函数，$k_\\ell(t, t') = \\sigma_f^2 \\exp(-\\frac{(t - t')^2}{2\\ell^2})$，其信号方差固定为 $\\sigma_f^2 = 1$，长度尺度 $\\ell$ 可调。这种构建方式提供了一个非参数贝叶斯框架，用于从离散数据中推断连续函数 $g(t)$。\n\n**2. 交叉验证与数据划分**\n为了从一组候选值中选择最优的 $\\ell$，采用了分块 $K$-折交叉验证。鉴于数据由按时间排序的溯祖间隔序列组成，该方案对于保持时间依赖结构、防止未来数据泄露到过去至关重要。这 9 个区间的序列被划分为 $K=3$ 个大小相等（每个3个区间）的连续、不重叠的块。在 $K$ 次迭代的每一次中，一个块被作为测试集留出，而其余的 $K-1$ 个块组合成训练集。\n\n**3. 高斯过程训练与预测**\n对于每个交叉验证折，仅使用训练集中的区间来训练GP。训练数据不是原始的时间数据，而是一组派生出的伪观测值。对于每个谱系数量为 $k_i$、持续时间为 $\\Delta t_i = t_{i+1} - t_i$ 的训练区间 $[t_i, t_{i+1}]$，我们构建一个数据点 $(s_i, y_i)$。该点位于区间的中点 $s_i = (t_i + t_{i+1})/2$，其值 $y_i = \\log(\\binom{k_i}{2} \\Delta t_i)$ 是假设 $N_e(t)$ 在该区间内为常数时，基于矩的估计量的对数。\n\n使用这些训练对 $(S_{train}, Y_{train})$ 和选定的 $\\ell$，我们执行GP回归。标准的GP方程会产生一个函数上的后验分布。我们关心的是它的均值 $\\hat{g}_\\ell(t)$，它作为我们对对数种群规模历史的重建。对于一组预测点 $S_{pred}$，后验均值由下式给出：\n$$ \\hat{g}_\\ell(S_{pred}) = K(S_{pred}, S_{train}) [K(S_{train}, S_{train}) + \\sigma_n^2 I]^{-1} Y_{train} $$\n其中 $K(\\cdot, \\cdot)$ 表示核函数求值矩阵，$I$ 是单位矩阵，$\\sigma_n^2 = 0.0025$ 是用于正则化模型的指定观测噪声方差。项 $[K(S_{train}, S_{train}) + \\sigma_n^2 I]^{-1} Y_{train}$ 可以通过求解关于 $\\alpha$ 的线性方程组 $(K(S_{train}, S_{train}) + \\sigma_n^2 I) \\alpha = Y_{train}$ 来高效计算。\n\n**4. 预测损失计算**\n给定 $\\ell$ 的性能在留出的测试块上进行评估。评分指标是溯祖模型下的负对数似然，使用GP的后验均值 $\\hat{g}_\\ell(t)$ 作为 $g(t)$ 的估计。对于每个有 $k_i$ 个谱系的留出区间 $[t_i, t_{i+1}]$，损失 $\\mathcal{L}_i(\\ell)$ 为：\n$$ \\mathcal{L}_i(\\ell) \\;=\\; \\int_{t_i}^{t_{i+1}} \\frac{\\binom{k_i}{2}}{\\exp(\\hat{g}_\\ell(t))} \\, dt \\;-\\; \\log\\left(\\frac{\\binom{k_i}{2}}{\\exp(\\hat{g}_\\ell(t_{i+1}))}\\right) $$\n积分项使用梯形法则进行数值计算，使用 $M=64$ 个子区间。这需要在每个留出区间内的 $M+1$ 个等距点上评估 $\\hat{g}_\\ell(t)$。给定折的总得分是该折中所有区间的这些损失之和。$\\ell$ 的最终交叉验证得分是所有 $K$ 折的这些得分的平均值。\n\n**5. 超参数选择**\n对每个候选的长度尺度 $\\ell$ 重复整个交叉验证过程。产生最小平均交叉验证得分的 $\\ell$ 被选为最优超参数。问题规定，如果得分出现平局，应选择最小的 $\\ell$。\n\n**实现摘要**\n该实现封装了这一逻辑。对于每个测试案例，它遍历候选的 $\\ell$ 值。在此循环内，它执行 $K$-折交叉验证。在每个折中，它组装训练数据，计算GP后验均值函数（具体来说是向量 $\\alpha$），然后使用数值积分评估留出块上的损失。这些损失被汇总以计算 $\\ell$ 的最终得分。最后，在所有候选中得分最高的 $\\ell$ 被识别并报告。每个测试案例由一个单独的函数来协调整个过程，该函数使用 `numpy` 进行高效的数值运算，使用 `scipy.special.comb` 计算二项式系数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the hyperparameter selection process for each case\n    and prints the final results in the specified format.\n    \"\"\"\n\n    def run_test_case(durations, lineage_counts, candidate_ls):\n        \"\"\"\n        Performs blocked K-fold cross-validation to select the best\n        GP length-scale hyperparameter for a single test case.\n\n        Args:\n            durations (np.ndarray): Array of inter-coalescent interval durations.\n            lineage_counts (np.ndarray): Array of lineage counts for each interval.\n            candidate_ls (list): List of candidate length-scale values.\n\n        Returns:\n            float: The selected optimal length-scale.\n        \"\"\"\n        # Fixed parameters from the problem statement\n        sigma_f_sq = 1.0\n        sigma_n_sq = 0.0025\n        K = 3\n        M = 64\n\n        # Calculate interval boundaries from durations\n        t_boundaries = np.concatenate(([0], np.cumsum(durations)))\n        num_intervals = len(durations)\n        \n        # Partition interval indices into K contiguous blocks for cross-validation\n        all_indices = np.arange(num_intervals)\n        blocks = np.array_split(all_indices, K)\n        \n        cv_scores = []\n\n        # Squared-exponential kernel function\n        def kernel(t1, t2, l_sq):\n            # Uses broadcasting to compute pairwise squared distances\n            dist_sq = np.subtract.outer(t1, t2)**2\n            return sigma_f_sq * np.exp(-dist_sq / (2 * l_sq))\n\n        # Iterate over each candidate length-scale\n        for l_val in candidate_ls:\n            l_val_sq = l_val**2\n            total_fold_loss = 0.0\n\n            # Perform K-fold cross-validation\n            for j in range(K):\n                # a. Split data into training and test sets\n                test_indices = blocks[j]\n                train_indices_list = [blocks[i] for i in range(K) if i != j]\n                train_indices = np.concatenate(train_indices_list)\n\n                # b. Construct training data (midpoints and pseudo-observations)\n                train_midpoints = []\n                train_y = []\n                for i in train_indices:\n                    t_start, t_end = t_boundaries[i], t_boundaries[i+1]\n                    delta_t = t_end - t_start\n                    midpoint = (t_start + t_end) / 2\n                    \n                    k = lineage_counts[i]\n                    binom_coeff = comb(k, 2, exact=True)\n                    \n                    y_val = np.log(binom_coeff * delta_t)\n                    train_y.append(y_val)\n                    train_midpoints.append(midpoint)\n                \n                S_train = np.array(train_midpoints)\n                Y_train = np.array(train_y)\n                \n                # c. Fit GP: solve for alpha = (K + sigma_n^2*I)^-1 * y\n                K_train_train = kernel(S_train, S_train, l_val_sq)\n                K_solve = K_train_train + sigma_n_sq * np.identity(len(S_train))\n                alpha = np.linalg.solve(K_solve, Y_train)\n\n                # d. Calculate fold score on the held-out block\n                fold_loss = 0.0\n                \n                # Collect all unique points for efficient batch prediction\n                prediction_points_set = set()\n                for i in test_indices:\n                    t_start, t_end = t_boundaries[i], t_boundaries[i+1]\n                    quad_points = np.linspace(t_start, t_end, M + 1)\n                    prediction_points_set.update(quad_points)\n\n                if not prediction_points_set:\n                    total_fold_loss += 0.0\n                    continue\n                \n                S_pred = np.array(sorted(list(prediction_points_set)))\n                \n                # Predict g_hat(t) at all required points\n                K_pred_train = kernel(S_pred, S_train, l_val_sq)\n                g_hat_pred = K_pred_train @ alpha\n                pred_lookup = dict(zip(S_pred, g_hat_pred))\n\n                # Calculate loss for each interval in the held-out block\n                for i in test_indices:\n                    t_start, t_end = t_boundaries[i], t_boundaries[i+1]\n                    k = lineage_counts[i]\n                    binom_coeff = comb(k, 2, exact=True)\n                    \n                    quad_points = np.linspace(t_start, t_end, M + 1)\n                    g_hat_at_quad_points = np.array([pred_lookup[p] for p in quad_points])\n                    \n                    # i. Numerically integrate the rate\n                    integrand_vals = binom_coeff / np.exp(g_hat_at_quad_points)\n                    integral_val = np.trapz(integrand_vals, x=quad_points)\n                    \n                    # ii. Calculate the log-hazard term\n                    g_hat_at_end = g_hat_at_quad_points[-1]\n                    log_hazard = np.log(binom_coeff) - g_hat_at_end\n                    \n                    # iii. Interval loss is the negative log-likelihood\n                    interval_loss = integral_val - log_hazard\n                    fold_loss += interval_loss\n                \n                total_fold_loss += fold_loss\n\n            # Average score for the current l_val\n            avg_cv_score = total_fold_loss / K\n            cv_scores.append((avg_cv_score, l_val))\n        \n        # Select best l (primary sort by score, secondary by l for tie-breaking)\n        cv_scores.sort()\n        best_l = cv_scores[0][1]\n        \n        return best_l\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"durations\": [0.12, 0.09, 0.11, 0.14, 0.20, 0.18, 0.25, 0.30, 0.45],\n            \"candidate_ls\": [0.05, 0.10, 0.20, 0.40]\n        },\n        {\n            \"durations\": [0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.11, 0.12, 0.13],\n            \"candidate_ls\": [0.20, 0.40, 0.80]\n        },\n        {\n            \"durations\": [0.05, 0.25, 0.06, 0.30, 0.05, 0.28, 0.06, 0.26, 0.05],\n            \"candidate_ls\": [0.05, 0.10, 0.20]\n        },\n    ]\n\n    # Lineage counts are the same for all test cases\n    lineage_counts = np.arange(10, 1, -1) # k=10, 9, ..., 2\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(\n            np.array(case[\"durations\"]),\n            lineage_counts,\n            case[\"candidate_ls\"]\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}