{
    "hands_on_practices": [
        {
            "introduction": "在验证新型可穿戴传感器或比较不同测量技术时，一个核心任务是评估它们之间的一致性。例如，我们如何定量地判断基于光电容积描记（PPG）的心率计与作为金标准的（ECG）心率计的测量结果是否可以互换？本练习将指导您使用Bland-Altman分析，这是一种超越简单相关性分析的强大生物统计学方法，用于量化两种测量方法之间的系统性偏差（bias）和一致性界限（limits of agreement），从而为设备验证提供关键依据。",
            "id": "4399060",
            "problem": "考虑在系统生物医学中使用可穿戴传感器进行跨设备心率整合。心电图 (ECG) 和光电容积脉搏波 (PPG) 是两种估计心率的方法。设第 $i$ 次配对观测的潜在真实心率为 $h_i$。ECG 导出的心率记为 $y^{\\mathrm{ECG}}_i$，PPG 导出的心率记为 $y^{\\mathrm{PPG}}_i$，单位均为每分钟心跳次数 (bpm)。假设每个观测到的心率是真实心率加上设备特定的测量误差扰动，即 $y^{\\mathrm{ECG}}_i = h_i + \\varepsilon^{\\mathrm{ECG}}_i$ 和 $y^{\\mathrm{PPG}}_i = h_i + \\varepsilon^{\\mathrm{PPG}}_i$，其中 $\\varepsilon^{\\mathrm{ECG}}_i$ 和 $\\varepsilon^{\\mathrm{PPG}}_i$ 是具有有限方差的随机误差。定义配对差值 $d_i = y^{\\mathrm{PPG}}_i - y^{\\mathrm{ECG}}_i$ 和配对均值 $m_i = \\left(y^{\\mathrm{PPG}}_i + y^{\\mathrm{ECG}}_i\\right)/2$。设备间偏差是差值的期望值 $\\mathbb{E}[d_i]$，而 Bland–Altman 分析则在差值服从正态模型的假设下表征设备间的一致性。\n\n你的任务是编写一个程序，对每个测试用例，从基本原理出发执行以下计算：\n- 在移除任何 $y^{\\mathrm{ECG}}_i$ 或 $y^{\\mathrm{PPG}}_i$ 缺失的数据对后，使用配对差值 $d_i$ 估计设备间偏差。缺失值表示为非数字（not-a-number），应通过按对删除的方式排除。\n- 使用无偏样本标准差估计 $d_i$ 的离散度。\n- 假设差值 $d_i$ 独立且近似服从方差恒定的正态分布，使用适当的正态分位数计算差值的双侧 $95\\%$ 覆盖率 Bland–Altman 一致性界限。\n- 通过拟合普通最小二乘回归 $d_i = a + b\\,m_i + \\eta_i$ 来评估比例偏差，并使用双侧显著性水平 $\\alpha = 0.05$（以小数表示）检验无比例偏差的零假设 $b = 0$。报告斜率 $b$ 和一个布尔值，指示比例偏差在给定水平下是否具有统计显著性。如果由于 $m_i$ 的方差为零或数据不足导致回归未定义，则将斜率视为 $0$ 且显著性为假。\n\n所有偏差和一致性界限的答案必须以每分钟心跳次数 (bpm) 为单位表示。斜率 $b$ 是无量纲的（bpm/bpm）。不涉及角度。百分比必须作为小数处理；不要使用百分号。\n\n使用以下配对观测值测试套件（每个值单位均为 bpm）。对于每个案例，ECG 列表和 PPG 列表是在不同会话中测量的对齐数据对；将它们视为每个案例的一个组合数据集。\n\n- 案例 1（一般情况，存在小的正偏差）：\n  - ECG: $\\{\\,72,\\,75,\\,80,\\,78,\\,90,\\,92,\\,88,\\,85,\\,76,\\,84\\,\\}$\n  - PPG: $\\{\\,74,\\,77,\\,83,\\,80,\\,93,\\,94,\\,90,\\,86,\\,78,\\,86\\,\\}$\n\n- 案例 2（边界情况，偏差和离散度均为零）：\n  - ECG: $\\{\\,60,\\,65,\\,70,\\,75,\\,80,\\,85\\,\\}$\n  - PPG: $\\{\\,60,\\,65,\\,70,\\,75,\\,80,\\,85\\,\\}$\n\n- 案例 3（边缘情况，比例偏差随心率增加而增加）：\n  - ECG: $\\{\\,50,\\,60,\\,70,\\,80,\\,90,\\,100,\\,110\\,\\}$\n  - PPG: $\\{\\,52,\\,62,\\,74.5,\\,84,\\,92.5,\\,107,\\,115.5\\,\\}$\n\n- 案例 4（边缘情况，存在需要按对删除的缺失值）：\n  - ECG: $\\{\\,70,\\,\\text{NaN},\\,85,\\,95,\\,100\\,\\}$\n  - PPG: $\\{\\,72,\\,78,\\,\\text{NaN},\\,99,\\,102\\,\\}$\n\n您的程序的最终输出格式要求是单行，包含四个案例结果的列表（按顺序），其中每个案例的结果本身就是一个列表，包含以下六个元素，并严格按照此顺序排列：\n$[\\,\\widehat{B},\\,\\widehat{S}_d,\\,\\mathrm{LOA}_{\\mathrm{lower}},\\,\\mathrm{LOA}_{\\mathrm{upper}},\\,\\widehat{b},\\,\\mathrm{is\\_significant}\\,]$,\n其中 $\\widehat{B}$ 是估计的偏差 (bpm)，$\\widehat{S}_d$ 是 $d_i$ 的无偏样本标准差 (bpm)，$\\mathrm{LOA}_{\\mathrm{lower}}$ 和 $\\mathrm{LOA}_{\\mathrm{upper}}$ 是 Bland–Altman 一致性界限 (bpm)，$\\widehat{b}$ 是回归斜率 (bpm/bpm)，$\\mathrm{is\\_significant}$ 是在 $\\alpha = 0.05$ 水平下进行比例偏差检验的布尔值。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表，每个案例的列表也用其自己的方括号括起来，例如：$[[r_{1,1},r_{1,2},\\ldots],[r_{2,1},r_{2,2},\\ldots],[r_{3,1},\\ldots],[r_{4,1},\\ldots]]$。",
            "solution": "该问题是有效的，因为它基于标准的生物统计学方法，具有科学依据，提法明确，信息充分且一致，并且表述客观。任务是针对来自 ECG 和 PPG 传感器的配对心率测量值，执行 Bland-Altman 分析并评估比例偏差。\n\n解决方案首先实现数据预处理，然后从基本原理出发计算指定的统计指标。\n\n**1. 数据预处理**\n对于每个测试用例，处理配对观测值 $(y^{\\mathrm{ECG}}_i, y^{\\mathrm{PPG}}_i)$。移除任何包含缺失值（表示为非数字 NaN）的数据对。此过程称为按对删除。设 $n$ 为此步骤后剩余的有效数据对数量。对于所有提供的测试用例，$n \\ge 3$，这足以进行所有后续计算。\n\n**2. 配对差值和均值**\n根据清理后的数据，我们为每个观测值 $i=1, \\dots, n$ 计算配对差值 $d_i$ 和配对均值 $m_i$：\n$$d_i = y^{\\mathrm{PPG}}_i - y^{\\mathrm{ECG}}_i$$\n$$m_i = \\frac{y^{\\mathrm{PPG}}_i + y^{\\mathrm{ECG}}_i}{2}$$\n\n**3. Bland-Altman 分析**\nBland-Altman 分析量化了两种测量设备之间的一致性。\n\n**3.1. 设备间偏差估计**\n设备间偏差 $\\mathbb{E}[d_i]$ 通过差值的样本均值来估计，记为 $\\widehat{B}$：\n$$\\widehat{B} = \\bar{d} = \\frac{1}{n}\\sum_{i=1}^{n} d_i$$\n\n**3.2. 离散度估计**\n差值的离散度使用无偏样本标准差进行估计，记为 $\\widehat{S}_d$：\n$$\\widehat{S}_d = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n} (d_i - \\bar{d})^2}$$\n此计算至少需要 $n=2$ 个有效数据对。\n\n**3.3. 一致性界限 (LOA)**\n假设差值 $d_i$ 服从正态分布，计算 $95\\%$ 的一致性界限。这些界限定义了一个范围，预计两种方法之间 $95\\%$ 的差值会落入此范围内。\n$$\\mathrm{LOA} = \\bar{d} \\pm z_{1-\\alpha/2} \\cdot \\widehat{S}_d$$\n对于双侧 $95\\%$ 的覆盖率，显著性水平为 $\\alpha=0.05$。我们使用标准正态分布的 $1-\\alpha/2 = 0.975$ 分位数，$z_{0.975} \\approx 1.95996$。下限和上限为：\n$$\\mathrm{LOA}_{\\mathrm{lower}} = \\bar{d} - z_{0.975} \\cdot \\widehat{S}_d$$\n$$\\mathrm{LOA}_{\\mathrm{upper}} = \\bar{d} + z_{0.975} \\cdot \\widehat{S}_d$$\n\n**4. 比例偏差评估**\n如果两种测量值之间的差异随测量值的大小系统地变化，则会发生比例偏差。这通过拟合普通最小二乘 (OLS) 回归模型来评估：\n$$d_i = a + b\\,m_i + \\eta_i$$\n其中 $\\eta_i$ 是误差项。\n\n**4.1. 斜率估计**\n斜率系数 $\\widehat{b}$ 使用 OLS 公式估计：\n$$\\widehat{b} = \\frac{\\sum_{i=1}^{n} (m_i - \\bar{m})(d_i - \\bar{d})}{\\sum_{i=1}^{n} (m_i - \\bar{m})^2} = \\frac{\\mathrm{Cov}(m, d)}{\\mathrm{Var}(m)}$$\n其中 $\\bar{m}$ 是 $m_i$ 的样本均值。如果 $m_i$ 的方差为零，则此计算未定义。在这种情况下，根据问题陈述，我们设定 $\\widehat{b}=0$ 并得出结论，不存在显著的比例偏差。\n\n**4.2. 斜率的假设检验**\n我们在显著性水平 $\\alpha = 0.05$ 下，检验零假设 $H_0: b = 0$（无比例偏差）与备择假设 $H_1: b \\neq 0$。检验统计量是 t-统计量，在 $H_0$ 下，它服从自由度为 $n-2$ 的 t-分布：\n$$t = \\frac{\\widehat{b}}{\\mathrm{SE}(\\widehat{b})}$$\n斜率的标准误 $\\mathrm{SE}(\\widehat{b})$ 计算如下：\n$$\\mathrm{SE}(\\widehat{b}) = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum_{i=1}^{n} (m_i - \\bar{m})^2}}$$\n其中 $\\hat{\\sigma}^2$ 是残差 $\\eta_i$ 方差的无偏估计量：\n$$\\hat{\\sigma}^2 = \\frac{1}{n-2} \\sum_{i=1}^{n} e_i^2$$\n且 $e_i = d_i - (\\hat{a} + \\hat{b}m_i)$ 是回归的残差，其中 $\\hat{a} = \\bar{d} - \\hat{b}\\bar{m}$。此检验在 $n > 2$ 时有效。\n\n如果检验统计量的绝对值超过 t-分布的临界值，则拒绝零假设：\n$$|t| > t_{n-2, 1-\\alpha/2}$$\n其中 $t_{n-2, 1-\\alpha/2}$ 是双侧检验的上临界值。如果 $|t| \\le t_{n-2, 1-\\alpha/2}$，我们未能拒绝 $H_0$，比例偏差不具有统计显著性。布尔值 `is_significant` 会相应设置。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, t\n\ndef solve():\n    \"\"\"\n    Performs Bland-Altman and proportional bias analysis on paired heart rate data.\n    \"\"\"\n    test_cases = [\n        # Case 1: general case with small positive bias\n        {\n            'ECG': [72, 75, 80, 78, 90, 92, 88, 85, 76, 84],\n            'PPG': [74, 77, 83, 80, 93, 94, 90, 86, 78, 86]\n        },\n        # Case 2: boundary case with zero bias and zero dispersion\n        {\n            'ECG': [60, 65, 70, 75, 80, 85],\n            'PPG': [60, 65, 70, 75, 80, 85]\n        },\n        # Case 3: edge case with proportional bias\n        {\n            'ECG': [50, 60, 70, 80, 90, 100, 110],\n            'PPG': [52, 62, 74.5, 84, 92.5, 107, 115.5]\n        },\n        # Case 4: edge case with missing values\n        {\n            'ECG': [70, np.nan, 85, 95, 100],\n            'PPG': [72, 78, np.nan, 99, 102]\n        },\n    ]\n\n    all_results = []\n\n    for case_data in test_cases:\n        y_ecg = np.array(case_data['ECG'], dtype=float)\n        y_ppg = np.array(case_data['PPG'], dtype=float)\n\n        # Step 1: Pairwise deletion for NaN values\n        valid_mask = ~np.isnan(y_ecg)  ~np.isnan(y_ppg)\n        y_ecg_clean = y_ecg[valid_mask]\n        y_ppg_clean = y_ppg[valid_mask]\n\n        n = len(y_ecg_clean)\n\n        # Step 2: Compute paired differences (d) and means (m)\n        d = y_ppg_clean - y_ecg_clean\n        m = (y_ppg_clean + y_ecg_clean) / 2.0\n\n        # Step 3.1: Estimate inter-device bias\n        bias_est = np.mean(d) if n > 0 else 0.0\n\n        # Step 3.2: Estimate dispersion (unbiased sample standard deviation)\n        sd_est = np.std(d, ddof=1) if n > 1 else 0.0\n\n        # Step 3.3: Compute 95% Bland-Altman limits of agreement\n        z_crit = norm.ppf(0.975)\n        loa_margin = z_crit * sd_est\n        loa_lower = bias_est - loa_margin\n        loa_upper = bias_est + loa_margin\n\n        # Step 4: Assess proportional bias\n        slope_est = 0.0\n        is_significant = False\n\n        # Regression and t-test require n >= 3 and Var(m) > 0\n        if n >= 3 and np.var(m) > 1e-12:\n            # Step 4.1: OLS slope estimation from first principles\n            m_mean = np.mean(m)\n            d_mean = np.mean(d)\n            \n            # Covariance term S_md and variance term S_mm\n            cov_md_sum = np.sum((m - m_mean) * (d - d_mean))\n            var_m_sum = np.sum((m - m_mean) ** 2)\n            \n            slope_est = cov_md_sum / var_m_sum\n\n            # Step 4.2: Hypothesis testing for the slope\n            df = n - 2\n            \n            # Sum of squared residuals (SSR)\n            var_d_sum = np.sum((d - d_mean) ** 2)\n            ssr = var_d_sum - slope_est * cov_md_sum\n            \n            # Handle potential floating point inaccuracies\n            ssr = max(0, ssr)\n\n            # Estimated variance of the residuals\n            residual_var_est = ssr / df\n            \n            # Standard error of the slope\n            se_slope = np.sqrt(residual_var_est / var_m_sum)\n            \n            # Perform t-test if SE is non-zero\n            if se_slope > 1e-12:\n                t_stat = slope_est / se_slope\n                alpha = 0.05\n                t_crit = t.ppf(1 - alpha / 2, df=df)\n                is_significant = np.abs(t_stat) > t_crit\n            # If se_slope is zero, it implies a perfect fit. If slope is also\n            # zero, H0 is not rejected (is_significant remains False).\n\n        all_results.append([\n            bias_est, sd_est, loa_lower, loa_upper, slope_est, is_significant\n        ])\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "可穿戴传感器的数据常常是不规则或稀疏采样的，这给时间序列分析带来了挑战。例如，心率数据可能由于功耗管理或信号质量问题而出现非均匀间隔。本练习将引导您使用高斯过程（Gaussian Processes, GP），这是一种强大的非参数贝叶斯方法，不仅可以对不规则采样的数据进行插值，还能为插值结果提供量化的不确定性，这对于做出可靠的生理学推断至关重要。",
            "id": "4399008",
            "problem": "您会获得不规则采样的可穿戴设备心率测量数据，并被要求使用高斯过程（GP）构建一个有原则的插值器，该插值器可以在任意查询时间量化不确定性。您需要从贝叶斯推断和多元正态分布性质的第一性原理出发，构建逻辑，形式化模型，然后实现一个算法，该算法能在指定的查询时间返回预测均值和标准差。\n\n从以下基础开始：高斯过程（GP）的定义，即其任何有限维边际分布都是多元正态的函数分布；测量值的生成模型，即一个潜在函数加上独立高斯噪声；半正定协方差核的定义；以及联合高斯随机变量的条件化规则。假设心率测量值 $y_i$（单位：次/分钟）是由一个潜在函数 $f(t)$ 加上独立高斯噪声 $\\epsilon_i$（方差为 $\\sigma_n^2$）生成的，其中 $t$ 表示时间（单位：秒）。核函数是径向基函数（RBF）核，其振幅为 $\\sigma_f$（单位：次/分钟），长度尺度为 $\\ell$（单位：秒）。您需要从联合高斯先验和似然函数推导出查询时间的预测分布，并设计一个计算预测均值和标准差的算法。\n\n模型规范：\n- 令 $f(t)$ 为一个潜在心率函数，其先验为 $f(\\cdot) \\sim \\mathcal{GP}(0, k(\\cdot,\\cdot))$，其中 $k(t,t') = \\sigma_f^2 \\exp\\left(-\\frac{(t-t')^2}{2\\ell^2}\\right)$。\n- 观测值服从 $y_i = f(t_i) + \\epsilon_i$，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_n^2)$ 独立同分布。\n- 对于一组观测时间 $\\mathbf{t} = [t_1,\\dots,t_N]$ 和查询时间 $\\mathbf{t}_* = [t^*_1,\\dots,t^*_M]$，推导在 $\\mathbf{t}_*$ 处的后验预测均值和协方差。\n\n算法约束：\n- 使用数值稳定的线性代数方法，避免显式地对矩阵求逆。\n- 处理接近重复的观测时间以及在观测时间窗口之外的外推。\n- 通过报告后验标准差，为每个查询时间量化不确定性（单位：次/分钟）。\n\n单位：\n- 时间单位必须是秒。\n- 心率单位必须是次/分钟（bpm）。\n- 噪声标准差和核函数振幅的单位是 bpm；核函数长度尺度的单位是秒。\n\n测试套件：\n提供如下三个测试用例。每个测试用例指定了观测时间 $\\mathbf{t}$、观测心率 $\\mathbf{y}$、观测噪声标准差 $\\sigma_n$、核函数振幅 $\\sigma_f$、核函数长度尺度 $\\ell$ 和查询时间 $\\mathbf{t}_*。$\n\n- 测试用例 1（正常路径，中等噪声，轻度外推）：\n  - $\\mathbf{t} = [\\,0,\\,15,\\,47,\\,120,\\,121,\\,180,\\,240,\\,300\\,]$ 秒\n  - $\\mathbf{y} = [\\,72,\\,75,\\,90,\\,85,\\,84,\\,80,\\,78,\\,76\\,]$ 次/分钟\n  - $\\sigma_n = 2.0$ 次/分钟, $\\sigma_f = 15.0$ 次/分钟, $\\ell = 60.0$ 秒\n  - $\\mathbf{t}_* = [\\,30,\\,60,\\,150,\\,270,\\,360\\,]$ 秒\n\n- 测试用例 2（稀疏观测，低噪声，外推）：\n  - $\\mathbf{t} = [\\,0,\\,180\\,]$ 秒\n  - $\\mathbf{y} = [\\,70,\\,95\\,]$ 次/分钟\n  - $\\sigma_n = 0.5$ 次/分钟, $\\sigma_f = 30.0$ 次/分钟, $\\ell = 200.0$ 秒\n  - $\\mathbf{t}_* = [\\,0,\\,90,\\,180,\\,240\\,]$ 秒\n\n- 测试用例 3（接近重复的时间点，小长度尺度）：\n  - $\\mathbf{t} = [\\,10,\\,11,\\,50,\\,51,\\,200\\,]$ 秒\n  - $\\mathbf{y} = [\\,100,\\,102,\\,80,\\,82,\\,90\\,]$ 次/分钟\n  - $\\sigma_n = 3.0$ 次/分钟, $\\sigma_f = 20.0$ 次/分钟, $\\ell = 5.0$ 秒\n  - $\\mathbf{t}_* = [\\,11,\\,49,\\,52,\\,199,\\,201\\,]$ 秒\n\n要求的最终输出格式：\n对于每个测试用例，输出一个包含两个列表的对：第一个列表是查询时间点的预测均值（单位：bpm），第二个列表是相同查询时间点的预测标准差（单位：bpm）。将三个测试用例的结果聚合为单行，格式为用方括号括起来的逗号分隔列表。具体来说，您的程序应打印单行：\n\"[[means_case1,stds_case1],[means_case2,stds_case2],[means_case3,stds_case3]]\"\n其中每个 \"means_caseX\" 和 \"stds_caseX\" 都是一个浮点数列表。不应打印任何额外文本。\n\n您的任务是：\n- 仅使用上述基础，从所述模型推导出预测分布。\n- 实现一个数值稳定的算法，为每个测试用例计算所提供查询时间点的预测均值和标准差。\n- 以所述精确格式生成最终输出，数值以次/分钟（bpm）表示。",
            "solution": "该问题要求推导并实现一个高斯过程（GP）回归器，以对不规则采样的心率数据进行建模。解决方案必须从第一性原理构建，确保科学正确性和数值稳定性。\n\n### 第一部分：预测分布的理论推导\n\n问题的核心是，在给定时间 $\\mathbf{t}$ 的观测值 $\\mathbf{y}$ 的情况下，求出潜在心率函数 $f(t)$ 在一组查询时间 $\\mathbf{t}_*$ 上的后验预测分布。这是一个经典的贝叶斯推断问题。\n\n**1. 生成模型与联合先验**\n\n我们给定一个模型，其中在时间 $\\mathbf{t} = [t_1, \\dots, t_N]^T$ 的观测值 $\\mathbf{y}$ 是一个潜在函数 $f(t)$ 的带噪版本。\n潜在函数通过高斯过程先验建模：\n$$f(\\cdot) \\sim \\mathcal{GP}(0, k(\\cdot, \\cdot))$$\n其中均值函数为零，协方差函数为径向基函数（RBF）核：\n$$k(t, t') = \\sigma_f^2 \\exp\\left(-\\frac{(t - t')^2}{2\\ell^2}\\right)$$\n观测值 $y_i$ 与潜在函数值 $f_i = f(t_i)$ 的关系如下：\n$$y_i = f(t_i) + \\epsilon_i, \\quad \\text{with} \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2) \\quad \\text{iid}$$\n\n根据高斯过程的定义，任何有限的函数值集合都服从多元高斯分布。令 $\\mathbf{f}$ 为观测时间 $\\mathbf{t}$ 上的潜在函数值向量，$\\mathbf{f}_*$ 为查询时间 $\\mathbf{t}_* = [t_1^*, \\dots, t_M^*]^T$ 上的潜在函数值向量。它们的联合分布由先验给出：\n$$\n\\begin{pmatrix} \\mathbf{f} \\\\ \\mathbf{f}_* \\end{pmatrix}\n\\sim \\mathcal{N} \\left(\n\\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n\\begin{pmatrix}\nK(\\mathbf{t}, \\mathbf{t})  K(\\mathbf{t}, \\mathbf{t}_*) \\\\\nK(\\mathbf{t}_*, \\mathbf{t})  K(\\mathbf{t}_*, \\mathbf{t}_*)\n\\end{pmatrix}\n\\right)\n$$\n其中协方差矩阵是通过将核函数 $k$ 应用于相应的时间点形成的。我们采用标准简写：$K = K(\\mathbf{t}, \\mathbf{t})$，$K_* = K(\\mathbf{t}, \\mathbf{t}_*)$，以及 $K_{**} = K(\\mathbf{t}_*, \\mathbf{t}_*)$。注意 $K(\\mathbf{t}_*, \\mathbf{t}) = K_*^T$。\n\n**2. 观测值与测试点的联合分布**\n\n观测向量 $\\mathbf{y}$ 是 $\\mathbf{f}$ 的线性变换加上高斯噪声，即 $\\mathbf{y} = \\mathbf{f} + \\boldsymbol{\\epsilon}$，其中 $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_n^2 I)$。我们需要 $\\mathbf{y}$ 和 $\\mathbf{f}_*$ 的联合分布。由于两者都是通过对联合高斯变量进行线性运算形成的，它们本身也是联合高斯分布的。\n\n该联合分布的均值为 $\\mathbf{0}$。协方差块矩阵为：\n- $\\text{Cov}(\\mathbf{y}, \\mathbf{y}) = \\mathbb{E}[(\\mathbf{f} + \\boldsymbol{\\epsilon})(\\mathbf{f} + \\boldsymbol{\\epsilon})^T] = \\mathbb{E}[\\mathbf{f}\\mathbf{f}^T] + \\mathbb{E}[\\boldsymbol{\\epsilon}\\boldsymbol{\\epsilon}^T] = K + \\sigma_n^2 I$。我们将这个 $N \\times N$ 矩阵记为 $K_y$。\n- $\\text{Cov}(\\mathbf{f}_*, \\mathbf{f}_*) = K_{**}$。\n- $\\text{Cov}(\\mathbf{y}, \\mathbf{f}_*) = \\mathbb{E}[(\\mathbf{f} + \\boldsymbol{\\epsilon})\\mathbf{f}_*^T] = \\mathbb{E}[\\mathbf{f}\\mathbf{f}_*^T] = K_*$。\n\n因此，联合分布为：\n$$\n\\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{f}_* \\end{pmatrix}\n\\sim \\mathcal{N} \\left(\n\\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{0} \\end{pmatrix},\n\\begin{pmatrix}\nK_y  K_* \\\\\nK_*^T  K_{**}\n\\end{pmatrix}\n\\right)\n$$\n\n**3. 条件化以求后验预测分布**\n\n我们使用多元高斯分布中的标准条件化规则。对于一个联合分布 $\\begin{pmatrix} \\mathbf{a} \\\\ \\mathbf{b} \\end{pmatrix} \\sim \\mathcal{N}\\left(\\begin{pmatrix} \\boldsymbol{\\mu}_a \\\\ \\boldsymbol{\\mu}_b \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{aa}  \\Sigma_{ab} \\\\ \\Sigma_{ba}  \\Sigma_{bb} \\end{pmatrix}\\right)$，条件分布 $p(\\mathbf{a}|\\mathbf{b})$ 是高斯分布，其：\n$$ \\mathbb{E}[\\mathbf{a}|\\mathbf{b}] = \\boldsymbol{\\mu}_a + \\Sigma_{ab} \\Sigma_{bb}^{-1}(\\mathbf{b} - \\boldsymbol{\\mu}_b) $$\n$$ \\text{Cov}(\\mathbf{a}|\\mathbf{b}) = \\Sigma_{aa} - \\Sigma_{ab} \\Sigma_{bb}^{-1} \\Sigma_{ba} $$\n\n为了求出 $p(\\mathbf{f}_*|\\mathbf{y})$，我们进行项的映射：$\\mathbf{a} \\to \\mathbf{f}_*$，$\\mathbf{b} \\to \\mathbf{y}$，$\\boldsymbol{\\mu}_a \\to \\mathbf{0}$，$\\boldsymbol{\\mu}_b \\to \\mathbf{0}$，$\\Sigma_{aa} \\to K_{**}$，$\\Sigma_{ab} \\to K_*^T$，$ \\Sigma_{ba} \\to K_*$，以及 $\\Sigma_{bb} \\to K_y$。\n\n应用这些代换，得到后验预测均值 $\\boldsymbol{\\mu}_*$ 和协方差 $\\Sigma_*$：\n$$ \\boldsymbol{\\mu}_* = K_*^T K_y^{-1} \\mathbf{y} $$\n$$ \\Sigma_* = K_{**} - K_*^T K_y^{-1} K_* $$\n预测分布为 $p(\\mathbf{f}_* | \\mathbf{t}, \\mathbf{y}, \\mathbf{t}_*) = \\mathcal{N}(\\boldsymbol{\\mu}_*, \\Sigma_*)$。每个查询点的不确定性由 $\\Sigma_*$ 对角线元素的平方根给出。\n\n### 第二部分：数值稳定的算法设计\n\n$K_y^{-1}$ 的直接计算在数值上不稳定且效率低下。矩阵 $K_y = K + \\sigma_n^2 I$ 是对称正定（SPD）的，因为 $K$ 是半正定的，且对于 $\\sigma_n  0$ 时 $\\sigma_n^2 I$ 是正定的。这种结构允许使用乔列斯基分解（Cholesky decomposition）进行稳定高效的计算。\n\n设 $K_y$ 的乔列斯基分解为 $K_y = LL^T$，其中 $L$ 是一个下三角矩阵。\n\n**预测均值 $\\boldsymbol{\\mu}_*$ 的算法**：\n均值为 $\\boldsymbol{\\mu}_* = K_*^T (K_y^{-1} \\mathbf{y})$。我们首先通过求解线性方程组 $K_y \\boldsymbol{\\alpha} = \\mathbf{y}$ 来计算向量 $\\boldsymbol{\\alpha} = K_y^{-1} \\mathbf{y}$。\n1.  计算 $K_y$ 的乔列斯基因子 $L$。\n2.  求解 $LL^T \\boldsymbol{\\alpha} = \\mathbf{y}$。这分两步完成：\n    a. 使用前向替换（forward substitution）求解 $L\\mathbf{v} = \\mathbf{y}$ 得到 $\\mathbf{v}$。\n    b. 使用后向替换（backward substitution）求解 $L^T\\boldsymbol{\\alpha} = \\mathbf{v}$ 得到 $\\boldsymbol{\\alpha}$。\n    （这两个步骤被封装在 `scipy.linalg.cho_solve` 中）。\n3.  计算所有查询点的预测均值：$\\boldsymbol{\\mu}_* = K_*^T \\boldsymbol{\\alpha}$。\n\n**预测标准差的算法**：\n我们需要后验协方差矩阵 $\\Sigma_* = K_{**} - K_*^T K_y^{-1} K_*$ 的对角线元素。$\\Sigma_*$ 的第 $i$ 个对角线元素是：\n$$ (\\Sigma_*)_i = (K_{**})_{ii} - (K_*^T)_{i,:} K_y^{-1} (K_*)_{:,i} $$\n令 $\\mathbf{k}_i^*$ 为 $K_*$ 的第 $i$ 列（即 $t_i^*$ 与所有训练点 $\\mathbf{t}$ 之间的协方差向量）。第 $i$ 个查询点的方差为：\n$$ \\text{var}(f_i^*) = k(t_i^*, t_i^*) - (\\mathbf{k}_i^*)^T K_y^{-1} \\mathbf{k}_i^* $$\n二次项可以高效计算。令 $\\mathbf{w}_i$ 为 $L\\mathbf{w}_i = \\mathbf{k}_i^*$ 的解。那么：\n$$ (\\mathbf{k}_i^*)^T K_y^{-1} \\mathbf{k}_i^* = (L\\mathbf{w}_i)^T (LL^T)^{-1} (L\\mathbf{w}_i) = \\mathbf{w}_i^T L^T (L^T)^{-1} L^{-1} L \\mathbf{w}_i = \\mathbf{w}_i^T \\mathbf{w}_i $$\n这导出了一个高效的算法：\n1.  使用为计算均值而得到的乔列斯基因子 $L$。\n2.  对于每个查询点 $t_i^*$：\n    a. 计算协方差向量 $\\mathbf{k}_i^* = K(\\mathbf{t}, t_i^*)$。\n    b. 使用前向替换求解三角系统 $L\\mathbf{w}_i = \\mathbf{k}_i^*$ 得到 $\\mathbf{w}_i$。\n    c. 计算预测方差：$\\text{var}(f_i^*) = k(t_i^*, t_i^*) - \\mathbf{w}_i^T \\mathbf{w}_i$。注意，对于 RBF 核，$k(t_i^*, t_i^*) = \\sigma_f^2$。\n3.  预测标准差为 $\\sqrt{\\text{var}(f_i^*)}$。应用一个小的数值容差，将方差的下限设为0，以防止对一个极小的负数取平方根时出错。\n\n这种有原则且数值稳健的方法提供了所需的预测均值和标准差。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cholesky, cho_solve, solve_triangular\nimport math\n\ndef gp_predict(t_obs, y_obs, sigma_n, sigma_f, l, t_query):\n    \"\"\"\n    Computes Gaussian Process predictive mean and standard deviation.\n\n    Args:\n        t_obs (np.ndarray): Observed times (N,).\n        y_obs (np.ndarray): Observed heart rates (N,).\n        sigma_n (float): Observation noise standard deviation.\n        sigma_f (float): RBF kernel amplitude.\n        l (float): RBF kernel length-scale.\n        t_query (np.ndarray): Query times (M,).\n\n    Returns:\n        tuple[list[float], list[float]]: A tuple containing the list of predictive\n        means and the list of predictive standard deviations.\n    \"\"\"\n    \n    # Ensure inputs are 2D column vectors for consistent broadcasting\n    t_obs = t_obs.reshape(-1, 1)\n    y_obs = y_obs.reshape(-1, 1)\n    t_query = t_query.reshape(-1, 1)\n\n    n_obs = t_obs.shape[0]\n\n    # RBF Kernel implementation\n    def rbf_kernel(t1, t2, sigma_f, l):\n        # Using broadcasting to compute squared Euclidean distances\n        # (a-b)^2 = a^2 - 2ab + b^2\n        sqdist = np.sum(t1**2, 1).reshape(-1, 1) + np.sum(t2**2, 1) - 2 * np.dot(t1, t2.T)\n        # Numerical stability: ensure squared distances are non-negative\n        sqdist = np.maximum(sqdist, 0)\n        return sigma_f**2 * np.exp(-0.5 / l**2 * sqdist)\n\n    # 1. Compute training covariance matrix with noise nugget\n    # K_y = K(t, t) + sigma_n^2 * I\n    k_obs_obs = rbf_kernel(t_obs, t_obs, sigma_f, l)\n    k_y = k_obs_obs + (sigma_n**2) * np.eye(n_obs)\n\n    # 2. Compute Cholesky decomposition of K_y for stable solves\n    # K_y = L * L^T\n    try:\n        L = cholesky(k_y, lower=True)\n    except np.linalg.LinAlgError:\n        # Fallback for ill-conditioned matrix, although sigma_n should prevent this\n        jitter = 1e-6\n        L = cholesky(k_y + jitter * np.eye(n_obs), lower=True)\n\n    # 3. Compute alpha = K_y^-1 * y\n    # This solves L*L^T*alpha = y_obs\n    alpha = cho_solve((L, True), y_obs)\n\n    # 4. Compute predictive mean and variance for query points\n    # K_* = K(t_obs, t_query)\n    k_obs_query = rbf_kernel(t_obs, t_query, sigma_f, l)\n\n    # Predictive mean: mu_* = K_*^T * alpha\n    mu_query = k_obs_query.T @ alpha\n\n    # Predictive variance: var_* = diag(K_**) - diag(K_*^T * K_y^-1 * K_*)\n    # Efficient computation:\n    # Let v = L^-1 * K_*, then K_*^T * K_y^-1 * K_* = K_*^T * (L*L^T)^-1 * K_* = v^T * v\n    v = solve_triangular(L, k_obs_query, lower=True)\n    \n    # Kernel of query points with themselves: diag(K_**)\n    # For RBF, k(t*, t*) = sigma_f^2\n    k_query_query_diag = np.full(t_query.shape[0], sigma_f**2)\n    \n    # var_query = diag(K(t_*,t_*)) - sum(v^2), sums over columns of v\n    var_query = k_query_query_diag - np.sum(v**2, axis=0)\n    \n    # Ensure variance is non-negative due to potential numerical errors\n    var_query[var_query  0] = 0.0\n    \n    std_query = np.sqrt(var_query)\n\n    return mu_query.flatten().tolist(), std_query.flatten().tolist()\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite and prints the result.\n    \"\"\"\n    test_cases = [\n        {\n            \"t\": np.array([0, 15, 47, 120, 121, 180, 240, 300]),\n            \"y\": np.array([72, 75, 90, 85, 84, 80, 78, 76]),\n            \"sigma_n\": 2.0, \"sigma_f\": 15.0, \"l\": 60.0,\n            \"t_star\": np.array([30, 60, 150, 270, 360])\n        },\n        {\n            \"t\": np.array([0, 180]),\n            \"y\": np.array([70, 95]),\n            \"sigma_n\": 0.5, \"sigma_f\": 30.0, \"l\": 200.0,\n            \"t_star\": np.array([0, 90, 180, 240])\n        },\n        {\n            \"t\": np.array([10, 11, 50, 51, 200]),\n            \"y\": np.array([100, 102, 80, 82, 90]),\n            \"sigma_n\": 3.0, \"sigma_f\": 20.0, \"l\": 5.0,\n            \"t_star\": np.array([11, 49, 52, 199, 201])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        means, stds = gp_predict(\n            t_obs=case[\"t\"],\n            y_obs=case[\"y\"],\n            sigma_n=case[\"sigma_n\"],\n            sigma_f=case[\"sigma_f\"],\n            l=case[\"l\"],\n            t_query=case[\"t_star\"]\n        )\n        # Rounding for consistent output format if needed, but not specified.\n        # Let's keep full precision and rely on Python's default conversion.\n        all_results.append([means, stds])\n\n    # Manual string formatting to exactly match the required output format\n    # without any extra spaces.\n    results_str_parts = []\n    for means, stds in all_results:\n        means_str = '[' + ','.join(f'{m:.10f}' for m in means) + ']'\n        stds_str = '[' + ','.join(f'{s:.10f}' for s in stds) + ']'\n        results_str_parts.append(f'[{means_str},{stds_str}]')\n    \n    final_output = '[' + ','.join(results_str_parts) + ']'\n    \n    # The problem implies a default float to string conversion would be sufficient.\n    # To be robust, let's create a string representation, remove spaces, and\n    # replace tuple parentheses with list brackets if any are present.\n    final_output_alt = str(all_results).replace(\" \", \"\").replace(\"(\", \"[\").replace(\")\", \"]\")\n    print(final_output_alt)\n\nsolve()\n\n```"
        },
        {
            "introduction": "在现实世界的生物医学数据分析中，数据缺失是一个普遍存在且棘手的问题。考虑一个场景：我们希望建立一个从加速度计强度（$x_t$）推断能量消耗（$y_t$）的模型，但部分加速度计数据丢失了。本练习将指导您从第一性原理推导并实现期望最大化（Expectation-Maximization, EM）算法，这是一种在存在潜在变量或数据缺失情况下进行最大似然估计的经典方法，让您掌握如何利用概率模型以统计上稳健的方式“填补”数据空白。",
            "id": "4399026",
            "problem": "您的任务是构建一个完整、可运行的程序，实现期望最大化（EM）算法，以处理在从可穿戴传感器推断每日活动能量消耗时缺失的加速计片段。此任务置于系统生物医学中数据融合和不确定性下估计的背景下。考虑一个单日分钟级模型，其中分钟 $t$ 时由加速计得出的活动强度（表示为 $x_t$）被建模为一个独立的、具有已知先验均值 $m_0$ 和先验方差 $s_0^2$ 的高斯随机变量，即 $x_t \\sim \\mathcal{N}(m_0, s_0^2)$ 在所有 $t$ 上独立。分钟级能量消耗 $y_t$（单位：千焦耳/分钟）通过一个线性高斯校准模型与活动强度相关联：在给定 $x_t$ 的条件下，它遵循 $y_t \\mid x_t \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_t, \\sigma^2)$，其中 $\\beta_0 \\in \\mathbb{R}$、$\\beta_1 \\in \\mathbb{R}$ 和 $\\sigma^2  0$ 是待估计的未知参数。您观测到所有 $t$ 的 $y_t$ 和部分 $t$ 的加速计数据 $x_t$，其余部分缺失。假设先验超参数 $m_0$ 和 $s_0^2$ 在EM迭代过程中是已知且固定的。您的任务是，从第一性原理出发，推导并实现一个EM算法，用于在给定观测到的 $y_t$ 和部分观测到的 $x_t$ 的情况下，对 $(\\beta_0, \\beta_1, \\sigma^2)$ 进行最大似然估计，然后使用估计出的参数来推断一个单独的目标日期的每日总活动能量消耗，该目标日期只包含（部分缺失的）加速计数据，而没有 $y_t$ 数据。EM算法必须从基本概率规则推导得出：贝叶斯法则、高斯分布的性质以及不完整数据的最大似然估计定义。\n\n您的推导必须从以下基本基础开始：\n- 联合密度分解 $p(y, x; \\theta) = \\prod_{t=1}^T p(y_t \\mid x_t; \\theta) p(x_t)$，其中 $p(y_t \\mid x_t; \\theta) = \\mathcal{N}(y_t \\mid \\beta_0 + \\beta_1 x_t, \\sigma^2)$ 且 $p(x_t) = \\mathcal{N}(x_t \\mid m_0, s_0^2)$，参数 $\\theta = (\\beta_0, \\beta_1, \\sigma^2)$。\n- 期望最大化（EM）原理：通过迭代E步 $Q(\\theta \\mid \\theta^{(old)}) = \\mathbb{E}[\\log p(y, x; \\theta) \\mid y, x_{\\text{obs}}; \\theta^{(old)}]$ 和M步 $\\theta^{(new)} = \\arg\\max_{\\theta} Q(\\theta \\mid \\theta^{(old)})$ 来最大化观测数据的对数似然。\n- 高斯共轭性：对于缺失的 $x_t$，在给定 $y_t$ 和固定的 $(\\beta_0, \\beta_1, \\sigma^2, m_0, s_0^2)$ 的条件下，由于 $x_t$ 的高斯先验和 $y_t \\mid x_t$ 的高斯似然，其后验分布是高斯分布，其均值和方差可以解析计算。\n\n仅使用这些基础，并且不使用捷径公式，推导在某些 $x_t$ 缺失时估计 $(\\beta_0, \\beta_1, \\sigma^2)$ 所需的E步和M步更新。然后，指明如何计算一个仅有加速计数据的目标日期的预测每日总能量消耗。对于一个没有 $y_t$ 的目标日期，您必须提供逐分钟计算 $\\mathbb{E}[y_t \\mid \\text{available data}]$ 并对全天求和的逻辑。最终程序必须实现此EM算法，并为以下测试套件生成数值输出。\n\n测试套件和要求的输出：\n对于以下每种情况，程序必须：\n- 在校准日上运行EM算法，该校准日有观测到的 $y_t$（单位：千焦耳/分钟）和部分观测到的 $x_t$（无单位的加速计强度；存在缺失值），并使用为该情况提供的固定先验超参数 $(m_0, s_0^2)$。\n- EM收敛后，计算目标日期的预测总活动能量消耗，定义为 $\\sum_{t=1}^{T_{\\text{target}}} \\mathbb{E}[y_t \\mid \\text{available accelerometer data at } t]$，以千焦耳（kJ）为单位表示，并四舍五入到三位小数。对于 $x_t$ 被观测到的目标分钟 $t$，使用 $\\mathbb{E}[y_t \\mid x_t] = \\beta_0 + \\beta_1 x_t$。对于 $x_t$ 缺失且没有可用 $y_t$ 的目标分钟 $t$，在先验下使用 $\\mathbb{E}[x_t] = m_0$，因此 $\\mathbb{E}[y_t] = \\beta_0 + \\beta_1 m_0$。\n\n情况A（理想路径）：\n- 超参数：$m_0 = 0.5$, $s_0^2 = 1.0$。\n- 校准日长度 $T = 6$，其中 $y = [\\,1.50,\\,1.75,\\,3.00,\\,0.20,\\,1.05,\\,2.30\\,]$ 且 $x = [\\,0.20,\\,\\text{NaN},\\,1.00,\\,-0.50,\\,\\text{NaN},\\,0.70\\,]$，其中 $\\text{NaN}$ 表示缺失值。\n- 目标日长度 $T_{\\text{target}} = 6$，其中 $x^{\\text{target}} = [\\,0.00,\\,0.50,\\,\\text{NaN},\\,-0.20,\\,0.90,\\,\\text{NaN}\\,]$。\n\n情况B（校准和目标中所有加速计数据均缺失）：\n- 超参数：$m_0 = 0.00$, $s_0^2 = 1.0$。\n- 校准日长度 $T = 4$，其中 $y = [\\,0.50,\\,1.25,\\,-0.25,\\,2.00\\,]$ 且 $x = [\\,\\text{NaN},\\,\\text{NaN},\\,\\text{NaN},\\,\\text{NaN}\\,]$。\n- 目标日长度 $T_{\\text{target}} = 3$，其中 $x^{\\text{target}} = [\\,\\text{NaN},\\,\\text{NaN},\\,\\text{NaN}\\,]$。\n\n情况C（低观测噪声，部分缺失）：\n- 超参数：$m_0 = 0.30$, $s_0^2 = 0.20$。\n- 校准日长度 $T = 5$，其中 $y = [\\,2.30,\\,2.40,\\,2.005,\\,2.595,\\,2.20\\,]$ 且 $x = [\\,0.30,\\,\\text{NaN},\\,0.00,\\,0.60,\\,\\text{NaN}\\,]$。\n- 目标日长度 $T_{\\text{target}} = 4$，其中 $x^{\\text{target}} = [\\,\\text{NaN},\\,0.10,\\,0.20,\\,\\text{NaN}\\,]$。\n\n角度单位不适用。物理单位：报告每种情况的最终预测总能量消耗，单位为千焦耳（kJ），四舍五入到三位小数。您的程序应生成单行输出，包含三个结果，形式为用方括号括起来的逗号分隔列表（例如，\"[12.345,67.890,1.234]\"），顺序与情况A、B、C一致。\n\n科学真实性约束：\n- 将分钟级 $y_t$ 视为千焦耳/分钟，将 $x_t$ 视为无单位的加速计强度。\n- EM算法必须从上述高斯模型推导得出，使用贝叶斯法则和高斯条件分布的性质，并且不得引用未引入的捷径公式。\n\n您的最终程序必须是完全自包含的，不需要外部输入，并按上述规定为测试套件生成输出。",
            "solution": "用户提供的问题在科学上是合理的、定义明确的，并且要求在一个相关应用领域中推导和实现一个标准的统计算法。该问题指定了一个清晰的模型、一个明确的目标和可验证的测试用例。所有必要的数据和条件都已提供。因此，该问题被认为是有效的。\n\n### 期望最大化（EM）算法的解析推导\n\n此问题解决了系统生物医学中的一个核心挑战：整合来自多个来源（如可穿戴传感器）的噪声和不完整数据，以推断潜在的生理状态。在这里，我们的目标是通过融合加速计数据（$x_t$）与能量消耗（$y_t$）的校准模型来估计每日活动能量消耗，其中加速计流存在缺失片段。我们将使用期望最大化（EM）算法来寻找模型参数的最大似然估计（MLE）。\n\n待估计的参数是 $\\theta = (\\beta_0, \\beta_1, \\sigma^2)$。模型规定如下：\n1.  活动强度的先验：$x_t \\sim \\mathcal{N}(m_0, s_0^2)$\n2.  能量消耗的似然：$y_t | x_t \\sim \\mathcal{N}(\\beta_0 + \\beta_1 x_t, \\sigma^2)$\n\n数据包括完全观测到的 $y = \\{y_t\\}_{t=1}^T$ 和部分观测到的 $x = \\{x_t\\}_{t=1}^T$。令 $\\mathcal{O}$ 为 $x_t$ 被观测到的时间索引集合，$\\mathcal{M}$ 为 $x_t$ 缺失的时间索引集合。完整数据是 $(y, x)$，观测数据是 $(y, x_{\\mathcal{O}})$。\n\nEM算法通过迭代最大化以观测数据和当前参数估计为条件的完整数据对数似然的期望来进行。\n\n**完整数据对数似然**\n\n完整数据 $(y, x)$ 的联合概率密度为 $p(y, x; \\theta) = \\prod_{t=1}^T p(y_t \\mid x_t; \\theta) p(x_t)$。对数似然 $\\ell(\\theta; y, x) = \\log p(y, x; \\theta)$ 为：\n$$\n\\ell(\\theta; y, x) = \\sum_{t=1}^T \\log p(y_t \\mid x_t; \\theta) + \\sum_{t=1}^T \\log p(x_t)\n$$\n由于 $p(x_t) = \\mathcal{N}(x_t \\mid m_0, s_0^2)$ 不依赖于参数 $\\theta = (\\beta_0, \\beta_1, \\sigma^2)$，我们可以将 $\\sum \\log p(x_t)$ 在最大化过程中视为常数。我们专注于第一项：\n$$\n\\sum_{t=1}^T \\log \\mathcal{N}(y_t \\mid \\beta_0 + \\beta_1 x_t, \\sigma^2) = \\sum_{t=1}^T \\left[ -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}(y_t - \\beta_0 - \\beta_1 x_t)^2 \\right]\n$$\n$$\n\\ell_c(\\theta; y, x) = -\\frac{T}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{t=1}^T (y_t - \\beta_0 - \\beta_1 x_t)^2 + \\text{const}\n$$\n其中 $\\ell_c(\\theta; y, x)$ 是与 $\\theta$ 相关的对数似然部分。\n\n**E步：计算Q函数**\n\n在第 $k+1$ 次迭代中，E步计算Q函数，该函数是完整数据对数似然关于缺失数据 $x_{\\mathcal{M}}$ 的后验分布的期望，该后验分布以观测数据和当前参数估计 $\\theta^{(k)} = (\\beta_0^{(k)}, \\beta_1^{(k)}, (\\sigma^2)^{(k)})$ 为条件。\n$$\nQ(\\theta \\mid \\theta^{(k)}) = \\mathbb{E}_{x_{\\mathcal{M}}}[\\ell_c(\\theta; y, x) \\mid y, x_{\\mathcal{O}}; \\theta^{(k)}]\n$$\n由于时间点之间的独立性，期望可以分布到求和中：\n$$\nQ(\\theta \\mid \\theta^{(k)}) = -\\frac{T}{2}\\log(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{t=1}^T \\mathbb{E}[(y_t - \\beta_0 - \\beta_1 x_t)^2 \\mid y_t, x_t \\text{ if } t \\in \\mathcal{O}; \\theta^{(k)}]\n$$\n对于 $t \\in \\mathcal{O}$，$x_t$ 是已知的，因此期望是平凡的。对于 $t \\in \\mathcal{M}$，我们需要计算涉及缺失 $x_t$ 的项的期望。\n$$\n\\mathbb{E}[(y_t - \\beta_0 - \\beta_1 x_t)^2 \\mid \\dots] = \\mathbb{E}[ (y_t-\\beta_0)^2 - 2\\beta_1(y_t-\\beta_0)x_t + \\beta_1^2 x_t^2 \\mid \\dots]\n$$\n$$\n= (y_t-\\beta_0)^2 - 2\\beta_1(y_t-\\beta_0)\\mathbb{E}[x_t \\mid \\dots] + \\beta_1^2 \\mathbb{E}[x_t^2 \\mid \\dots]\n$$\n因此，E步需要为每个 $t \\in \\mathcal{M}$ 计算两个条件矩：\n1.  $\\tilde{x}_t^{(k)} = \\mathbb{E}[x_t \\mid y_t; \\theta^{(k)}]$\n2.  $\\widetilde{x_t^2}^{(k)} = \\mathbb{E}[x_t^2 \\mid y_t; \\theta^{(k)}]$\n\n对于 $t \\in \\mathcal{O}$，我们简单地有 $\\tilde{x}_t^{(k)} = x_t$ 和 $\\widetilde{x_t^2}^{(k)} = x_t^2$。\n\n为了找到 $t \\in \\mathcal{M}$ 的这些矩，我们使用贝叶斯法则推导后验分布 $p(x_t \\mid y_t; \\theta^{(k)})$：\n$$\np(x_t \\mid y_t; \\theta^{(k)}) \\propto p(y_t \\mid x_t; \\theta^{(k)}) p(x_t)\n$$\n两者都是高斯分布。两个高斯概率密度函数（PDF）的乘积与另一个高斯PDF成正比。后验分布的指数是 $x_t$ 的二次型：\n$$\n-\\frac{1}{2} \\left[ \\frac{(y_t - \\beta_0^{(k)} - \\beta_1^{(k)} x_t)^2}{(\\sigma^2)^{(k)}} + \\frac{(x_t - m_0)^2}{s_0^2} \\right]\n$$\n通过对 $x_t$ 配方法，我们发现后验分布 $p(x_t \\mid y_t; \\theta^{(k)})$ 是一个高斯分布 $\\mathcal{N}(\\mu_{t,\\text{post}}^{(k)}, (s_{t,\\text{post}}^2)^{(k)})$，其方差为：\n$$\n(s_{t,\\text{post}}^2)^{(k)} = \\left( \\frac{(\\beta_1^{(k)})^2}{(\\sigma^2)^{(k)}} + \\frac{1}{s_0^2} \\right)^{-1}\n$$\n均值为：\n$$\n\\mu_{t,\\text{post}}^{(k)} = (s_{t,\\text{post}}^2)^{(k)} \\left( \\frac{\\beta_1^{(k)}(y_t - \\beta_0^{(k)})}{(\\sigma^2)^{(k)}} + \\frac{m_0}{s_0^2} \\right)\n$$\n所需的矩则为：\n$$\n\\tilde{x}_t^{(k)} = \\mu_{t,\\text{post}}^{(k)}\n$$\n$$\n\\widetilde{x_t^2}^{(k)} = \\text{Var}(x_t|y_t;\\theta^{(k)}) + (\\mathbb{E}[x_t|y_t;\\theta^{(k)}])^2 = (s_{t,\\text{post}}^2)^{(k)} + (\\mu_{t,\\text{post}}^{(k)})^2\n$$\n\n**M步：最大化Q函数**\n\nM步通过最大化 $Q(\\theta \\mid \\theta^{(k)})$ 来更新参数为 $\\theta^{(k+1)}$。这等价于最小化关于 $\\beta_0$ 和 $\\beta_1$ 的平方误差和项：\n$$\nS(\\beta_0, \\beta_1) = \\sum_{t=1}^T \\left[ (y_t-\\beta_0)^2 - 2\\beta_1(y_t-\\beta_0)\\tilde{x}_t^{(k)} + \\beta_1^2 \\widetilde{x_t^2}^{(k)} \\right]\n$$\n将偏导数 $\\frac{\\partial S}{\\partial \\beta_0}$ 和 $\\frac{\\partial S}{\\partial \\beta_1}$ 设为零，得到加权最小二乘问题的正规方程：\n$$\n\\begin{pmatrix} T  \\sum_{t=1}^T \\tilde{x}_t^{(k)} \\\\ \\sum_{t=1}^T \\tilde{x}_t^{(k)}  \\sum_{t=1}^T \\widetilde{x_t^2}^{(k)} \\end{pmatrix}\n\\begin{pmatrix} \\beta_0^{(k+1)} \\\\ \\beta_1^{(k+1)} \\end{pmatrix}\n=\n\\begin{pmatrix} \\sum_{t=1}^T y_t \\\\ \\sum_{t=1}^T y_t \\tilde{x}_t^{(k)} \\end{pmatrix}\n$$\n解这个 $2 \\times 2$ 系统得到更新：\n$$\n\\beta_1^{(k+1)} = \\frac{T \\sum y_t \\tilde{x}_t^{(k)} - (\\sum y_t)(\\sum \\tilde{x}_t^{(k)})}{T \\sum \\widetilde{x_t^2}^{(k)} - (\\sum \\tilde{x}_t^{(k)})^2}\n$$\n$$\n\\beta_0^{(k+1)} = \\frac{1}{T} \\left( \\sum y_t - \\beta_1^{(k+1)} \\sum \\tilde{x}_t^{(k)} \\right)\n$$\n为了更新 $\\sigma^2$，我们设置 $\\frac{\\partial Q}{\\partial (\\sigma^2)} = 0$，得到：\n$$\n(\\sigma^2)^{(k+1)} = \\frac{1}{T} S(\\beta_0^{(k+1)}, \\beta_1^{(k+1)})\n$$\n$$\n(\\sigma^2)^{(k+1)} = \\frac{1}{T} \\sum_{t=1}^T \\left[ (y_t - \\beta_0^{(k+1)})^2 - 2\\beta_1^{(k+1)}(y_t - \\beta_0^{(k+1)}) \\tilde{x}_t^{(k)} + (\\beta_1^{(k+1)})^2 \\widetilde{x_t^2}^{(k)} \\right]\n$$\n\n**算法初始化和预测**\n\n为参数 $\\theta^{(0)}$ 选择一个合适的初始化至关重要。\n- 如果有足够多的完整观测（$t \\in \\mathcal{O}$），我们可以通过对 $t \\in \\mathcal{O}$ 的 $y_t$ 对 $x_t$ 进行简单线性回归来初始化 $\\beta_0^{(0)}$ 和 $\\beta_1^{(0)}$。\n- 如果没有完整观测（如情况B），数据中没有信息来估计 $\\beta_1$。一个有原则的初始化是设置 $\\beta_1^{(0)}=0$，这意味着没有关系。那么 $\\beta_0^{(0)}$ 是 $y$ 的样本均值，$(\\sigma^2)^{(0)}$ 是 $y$ 的样本方差。\n- $(\\sigma^2)^{(0)}$ 可以初始化为 $1.0$ 或初始回归的残差方差。\n\n当EM算法收敛到最终估计值 $(\\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\sigma}^2)$ 后，计算目标日期的预测总能量消耗。对于目标日期的每一分钟 $t$：\n- 如果 $x_t^{\\text{target}}$ 被观测到：预测的 $y_t = \\hat{\\beta}_0 + \\hat{\\beta}_1 x_t^{\\text{target}}$。\n- 如果 $x_t^{\\text{target}}$ 缺失：由于没有 $y_t^{\\text{target}}$ 可用，我们使用 $x_t$ 的先验期望，即 $m_0$。预测的 $y_t$ 是 $\\mathbb{E}[y_t] = \\mathbb{E}[\\hat{\\beta}_0 + \\hat{\\beta}_1 x_t] = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\mathbb{E}[x_t] = \\hat{\\beta}_0 + \\hat{\\beta}_1 m_0$。\n\n每日总消耗是这些逐分钟预测的总和。",
            "answer": "```python\nimport numpy as np\n\ndef em_algorithm(y_cal, x_cal, m0, s0_sq, n_iter=100):\n    \"\"\"\n    Implements the EM algorithm for a linear-Gaussian model with missing data.\n\n    Args:\n        y_cal (np.ndarray): Observed energy expenditure data.\n        x_cal (np.ndarray): Partially observed accelerometer data (with np.nan for missing).\n        m0 (float): Prior mean for x.\n        s0_sq (float): Prior variance for x.\n        n_iter (int): Number of EM iterations.\n\n    Returns:\n        tuple: Estimated parameters (beta0, beta1, sigma_sq).\n    \"\"\"\n    T = len(y_cal)\n    obs_indices = np.where(~np.isnan(x_cal))[0]\n    mis_indices = np.where(np.isnan(x_cal))[0]\n\n    # Initialization\n    if len(obs_indices) >= 2:\n        x_obs = x_cal[obs_indices]\n        y_obs = y_cal[obs_indices]\n        # Linear regression on complete cases\n        x_mean, y_mean = np.mean(x_obs), np.mean(y_obs)\n        ss_xy = np.sum((x_obs - x_mean) * (y_obs - y_mean))\n        ss_xx = np.sum((x_obs - x_mean) ** 2)\n        if ss_xx > 1e-9:\n            beta1 = ss_xy / ss_xx\n            beta0 = y_mean - beta1 * x_mean\n        else: # not enough variation in observed x\n            beta1 = 0.0\n            beta0 = y_mean\n        # Initialize sigma_sq based on residuals or simply 1.0\n        y_pred = beta0 + beta1 * x_obs\n        sigma_sq = np.mean((y_obs - y_pred)**2)\n        if sigma_sq  1e-9:\n            sigma_sq = 1.0\n    else: # No or too few complete cases (e.g., Case B)\n        beta1 = 0.0\n        beta0 = np.mean(y_cal)\n        sigma_sq = np.var(y_cal) if T > 1 else 1.0\n    \n    if sigma_sq  1e-9: # ensure variance is positive\n        sigma_sq = 1.0\n    \n    for _ in range(n_iter):\n        # --- E-Step ---\n        # For missing x, calculate posterior mean and variance\n        # then compute E[x] and E[x^2]\n        if sigma_sq = 0 or s0_sq = 0: # Check for invalid variances\n            # If variance collapses, we cannot proceed. This might happen with ill-conditioned data.\n            # Return current estimates.\n             break\n\n        s_t_post_sq_inv = (beta1**2 / sigma_sq) + (1 / s0_sq)\n        s_t_post_sq = 1.0 / s_t_post_sq_inv\n        \n        y_mis = y_cal[mis_indices]\n        mu_t_post = s_t_post_sq * (beta1 * (y_mis - beta0) / sigma_sq + m0 / s0_sq)\n\n        x_tilde = np.copy(x_cal)\n        x_sq_tilde = np.copy(x_cal)**2\n\n        x_tilde[mis_indices] = mu_t_post\n        x_sq_tilde[mis_indices] = s_t_post_sq + mu_t_post**2\n        \n        # --- M-Step ---\n        # Update beta0 and beta1\n        s_x = np.sum(x_tilde)\n        s_xx = np.sum(x_sq_tilde)\n        s_y = np.sum(y_cal)\n        s_yx = np.sum(y_cal * x_tilde)\n\n        # Solve the 2x2 system from the normal equations\n        # Denominator = T * S_xx - S_x^2\n        denominator = T * s_xx - s_x**2\n        if abs(denominator)  1e-9:\n            # This can happen if all x_tilde are the same.\n            # In this case, beta1 is not identifiable from the regression.\n            # Keep beta1 as is, or set to 0. We keep it to avoid oscillations.\n            pass\n        else:\n            beta1 = (T * s_yx - s_y * s_x) / denominator\n        \n        beta0 = (s_y - beta1 * s_x) / T\n\n        # Update sigma_sq\n        term1 = np.sum((y_cal - beta0)**2)\n        term2 = -2 * beta1 * np.sum((y_cal - beta0) * x_tilde)\n        term3 = beta1**2 * np.sum(x_sq_tilde)\n        sigma_sq = (term1 + term2 + term3) / T\n        \n        if sigma_sq = 1e-9: # Prevent variance from collapsing to zero\n            sigma_sq = 1e-9\n\n    return beta0, beta1, sigma_sq\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # Case A\n        {\n            \"m0\": 0.5, \"s0_sq\": 1.0,\n            \"y_cal\": np.array([1.50, 1.75, 3.00, 0.20, 1.05, 2.30]),\n            \"x_cal\": np.array([0.20, np.nan, 1.00, -0.50, np.nan, 0.70]),\n            \"x_target\": np.array([0.00, 0.50, np.nan, -0.20, 0.90, np.nan])\n        },\n        # Case B\n        {\n            \"m0\": 0.0, \"s0_sq\": 1.0,\n            \"y_cal\": np.array([0.50, 1.25, -0.25, 2.00]),\n            \"x_cal\": np.array([np.nan, np.nan, np.nan, np.nan]),\n            \"x_target\": np.array([np.nan, np.nan, np.nan])\n        },\n        # Case C\n        {\n            \"m0\": 0.30, \"s0_sq\": 0.20,\n            \"y_cal\": np.array([2.30, 2.40, 2.005, 2.595, 2.20]),\n            \"x_cal\": np.array([0.30, np.nan, 0.00, 0.60, np.nan]),\n            \"x_target\": np.array([np.nan, 0.10, 0.20, np.nan])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        m0 = case[\"m0\"]\n        s0_sq = case[\"s0_sq\"]\n        y_cal = case[\"y_cal\"]\n        x_cal = case[\"x_cal\"]\n        x_target = case[\"x_target\"]\n\n        # Run EM algorithm to estimate parameters\n        beta0_hat, beta1_hat, _ = em_algorithm(y_cal, x_cal, m0, s0_sq)\n\n        # Predict total energy expenditure for the target day\n        y_pred_total = 0.0\n        for xt in x_target:\n            if np.isnan(xt):\n                # Use prior mean m0 for missing x_target\n                y_pred_total += beta0_hat + beta1_hat * m0\n            else:\n                # Use observed x_target\n                y_pred_total += beta0_hat + beta1_hat * xt\n        \n        results.append(f\"{y_pred_total:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}