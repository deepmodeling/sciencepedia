{
    "hands_on_practices": [
        {
            "introduction": "在生物网络中，识别功能模块是核心任务之一。一个常见的直觉是，连接紧密的节点群（例如，参与许多三角形基序的节点）应该形成一个模块。然而，这个实践练习将挑战这一直觉，通过一个具体的例子展示了基序富集区域与通过模块度最大化定义的功能社区之间的区别，帮助你理解全局结构和局部密度在模块识别中的不同角色。",
            "id": "4362361",
            "problem": "一个无向蛋白质-蛋白质相互作用网络在10个标记为1到10的节点上给出，代表了两个具有串扰的通路区室。边是无序对\n$\\{(1,2), (2,3), (3,4), (4,5), (6,7), (7,8), (6,8), (8,9), (9,10), (3,6), (3,7), (4,6), (4,7)\\}$。\n将3节点环状基序（三角形）视为我们感兴趣的基序。假设一位基序富集分析师提出将集合 $S=\\{3,4,6,7\\}$ 作为一个假定模块，因为这些节点参与了许多三角形。而一位社区分区分析师则提出了区室划分 $C_1=\\{1,2,3,4,5\\}$ 和 $C_2=\\{6,7,8,9,10\\}$，其动机是区室内的边密度以及区室间的串扰边。\n\n使用网络基序的基本定义（三角形是3节点环）和相对于度保持的零模型（广泛使用的 Newman–Girvan 模块度框架）评估的社区分区质量，不依赖任何快捷公式，按以下步骤进行：\n- 枚举网络中的三角形，并验证集合 $S$ 中的节点是否确实比其他节点有更高的三角形参与度。\n- 对于两个候选划分中的每一个，量化每个社区内部的边数以及每个社区中节点度的总和。\n- 从第一性原理出发，评估在度保持的零模型下哪个划分能产生更高的社区分区质量，并解释 $S$ 处的高基序频率是否与社区分区边界一致。\n\n哪个陈述与结果及其在系统生物医学推断中的意义最一致？\n\nA. 基序富集划分 $\\{S, V\\setminus S\\}$ 比 $\\{C_1, C_2\\}$ 产生更高的社区分区质量；因此，高三角形频率足以描绘社区分区边界。\n\nB. 区室划分 $\\{C_1, C_2\\}$ 比 $\\{S, V\\setminus S\\}$ 产生更高的社区分区质量；$\\{3,4,6,7\\}$ 处的高三角形频率并未定义社区分区边界，并且仅依赖基序计数可能将边界区域误识别为独立的模块。\n\nC. 两种划分具有相同的社区分区质量，因为它们各自包含相同数量的内部边；社区分区质量仅取决于内部边数，而不取决于度分布。\n\nD. 即使在度保持的零模型下社区分区质量较低，基序富集也能检测到功能性社区，因此模块度对于生物网络中的模块检测是无关紧要的。",
            "solution": "问题陈述提供了一个定义明确的网络和两种替代划分。它提出了一个关于使用网络科学中一个标准且指定的度量来比较这些划分的清晰、定量的问题。所给条件是完整的、一致的且科学上合理的。因此，我们可以进行形式化分析。\n\n设网络由图 $G=(V, E)$ 表示，其中顶点集为 $V = \\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}$，边集为 $E = \\{(1,2), (2,3), (3,4), (4,5), (6,7), (7,8), (6,8), (8,9), (9,10), (3,6), (3,7), (4,6), (4,7)\\}$。总边数为 $m = |E| = 13$。\n\n首先，我们计算每个节点 $i \\in V$ 的度 $k_i$：\n$k_1=1$\n$k_2=2$\n$k_3=4$（到 $2,4,6,7$ 的边）\n$k_4=4$（到 $3,5,6,7$ 的边）\n$k_5=1$\n$k_6=4$（到 $3,4,7,8$ 的边）\n$k_7=4$（到 $3,4,6,8$ 的边）\n$k_8=3$（到 $6,7,9$ 的边）\n$k_9=2$\n$k_{10}=1$\n度的总和为 $\\sum_{i \\in V} k_i = 1+2+4+4+1+4+4+3+2+1 = 26$，这正确地等于 $2m = 2 \\times 13$。\n\n**1. 三角形枚举与参与度**\n\n三角形是一个3节点环，即三个节点的集合 $\\{a,b,c\\}$，使得 $(a,b), (b,c), (c,a) \\in E$。通过检查边集，我们枚举出以下三角形：\n- $\\{3,4,6\\}$: 边 $(3,4), (3,6), (4,6)$ 存在。\n- $\\{3,4,7\\}$: 边 $(3,4), (3,7), (4,7)$ 存在。\n- $\\{3,6,7\\}$: 边 $(3,6), (3,7), (6,7)$ 存在。\n- $\\{4,6,7\\}$: 边 $(4,6), (4,7), (6,7)$ 存在。\n- $\\{6,7,8\\}$: 边 $(6,7), (6,8), (7,8)$ 存在。\n网络中总共有 $5$ 个三角形。\n\n每个节点参与的三角形数量为：\n- 节点 $3$: 参与 $\\{3,4,6\\}, \\{3,4,7\\}, \\{3,6,7\\}$。总计: $3$。\n- 节点 $4$: 参与 $\\{3,4,6\\}, \\{3,4,7\\}, \\{4,6,7\\}$。总计: $3$。\n- 节点 $6$: 参与 $\\{3,4,6\\}, \\{3,6,7\\}, \\{4,6,7\\}, \\{6,7,8\\}$。总计: $4$。\n- 节点 $7$: 参与 $\\{3,4,7\\}, \\{3,6,7\\}, \\{4,6,7\\}, \\{6,7,8\\}$。总计: $4$。\n- 节点 $8$: 参与 $\\{6,7,8\\}$。总计: $1$。\n- 所有其他节点（$1,2,5,9,10$）的度小于或等于 $2$，且它们的邻居节点之间没有连接，因此它们的三角形参与度为 $0$。\n\n集合 $S = \\{3,4,6,7\\}$ 由三角形参与度计数分别为 $3, 3, 4, 4$ 的节点组成。所有其他节点的参与度计数为 $1$ 或 $0$。因此，$S$ 中的节点确实具有显著更高的三角形参与度。\n\n**2. 社区分区质量评估**\n\n我们使用 Newman-Girvan 模块度 $Q$ 来评估社区分区质量。对于将网络划分为若干社区 $c$ 的一个划分，模块度从第一性原理定义为：落在给定社区内部的边所占的比例，减去在保持每个节点度不变的情况下随机重连边时，落入社区内部的边的预期比例。\n公式为：\n$$Q = \\sum_{c} \\left[ \\frac{L_c}{m} - \\left( \\frac{K_c}{2m} \\right)^2 \\right]$$\n其中对于每个社区 $c$，$L_c$ 是内部边的数量，$K_c$ 是其内部节点度的总和。此处，$m=13$ 且 $2m=26$。\n\n**划分 1：基序富集划分 $P_S = \\{S, V\\setminus S\\}$**\n- 社区 $S = \\{3,4,6,7\\}$。\n- 社区 $V\\setminus S = \\{1,2,5,8,9,10\\}$。\n\n对于社区 $S$：\n- 内部边为 $(3,4)$, $(3,6)$, $(3,7)$, $(4,6)$, $(4,7)$, $(6,7)$。因此，$L_S = 6$。\n- 度的总和为 $K_S = k_3 + k_4 + k_6 + k_7 = 4+4+4+4 = 16$。\n\n对于社区 $V\\setminus S$：\n- 内部边为 $(1,2)$, $(8,9)$, $(9,10)$。因此，$L_{V\\setminus S} = 3$。\n- 度的总和为 $K_{V\\setminus S} = k_1+k_2+k_5+k_8+k_9+k_{10} = 1+2+1+3+2+1=10$。\n\n内部边总数为 $6+3=9$。模块度 $Q_{P_S}$ 为：\n$$Q_{P_S} = \\left[ \\frac{6}{13} - \\left(\\frac{16}{26}\\right)^2 \\right] + \\left[ \\frac{3}{13} - \\left(\\frac{10}{26}\\right)^2 \\right]$$\n$$Q_{P_S} = \\left[ \\frac{6}{13} - \\left(\\frac{8}{13}\\right)^2 \\right] + \\left[ \\frac{3}{13} - \\left(\\frac{5}{13}\\right)^2 \\right]$$\n$$Q_{P_S} = \\left[ \\frac{78}{169} - \\frac{64}{169} \\right] + \\left[ \\frac{39}{169} - \\frac{25}{169} \\right] = \\frac{14}{169} + \\frac{14}{169} = \\frac{28}{169}$$\n$Q_{P_S} \\approx 0.1657$。\n\n**划分 2：区室划分 $P_C = \\{C_1, C_2\\}$**\n- 社区 $C_1 = \\{1,2,3,4,5\\}$。\n- 社区 $C_2 = \\{6,7,8,9,10\\}$。\n\n对于社区 $C_1$：\n- 内部边为 $(1,2)$, $(2,3)$, $(3,4)$, $(4,5)$。因此，$L_{C_1} = 4$。\n- 度的总和为 $K_{C_1} = k_1+k_2+k_3+k_4+k_5 = 1+2+4+4+1 = 12$。\n\n对于社区 $C_2$：\n- 内部边为 $(6,7)$, $(7,8)$, $(6,8)$, $(8,9)$, $(9,10)$。因此，$L_{C_2} = 5$。\n- 度的总和为 $K_{C_2} = k_6+k_7+k_8+k_9+k_{10} = 4+4+3+2+1=14$。\n\n内部边总数为 $4+5=9$。模块度 $Q_{P_C}$ 为：\n$$Q_{P_C} = \\left[ \\frac{4}{13} - \\left(\\frac{12}{26}\\right)^2 \\right] + \\left[ \\frac{5}{13} - \\left(\\frac{14}{26}\\right)^2 \\right]$$\n$$Q_{P_C} = \\left[ \\frac{4}{13} - \\left(\\frac{6}{13}\\right)^2 \\right] + \\left[ \\frac{5}{13} - \\left(\\frac{7}{13}\\right)^2 \\right]$$\n$$Q_{P_C} = \\left[ \\frac{52}{169} - \\frac{36}{169} \\right] + \\left[ \\frac{65}{169} - \\frac{49}{169} \\right] = \\frac{16}{169} + \\frac{16}{169} = \\frac{32}{169}$$\n$Q_{P_C} \\approx 0.1893$。\n\n**3. 比较与启示**\n\n比较模块度值，我们发现 $Q_{P_C} = \\frac{32}{169} > Q_{P_S} = \\frac{28}{169}$。区室划分 $\\{C_1, C_2\\}$ 的社区分区质量得分高于基序富集划分 $\\{S, V\\setminus S\\}$。\n\n集合 $S=\\{3,4,6,7\\}$ 是一个稠密子图（具体来说，是一个 $K_4$ 团），其中节点的三角形参与度很高。然而，这些节点也构成了两个原本分离的通路之间唯一的通信桥梁。节点 $\\{3,4\\}$ 属于通路1，而 $\\{6,7\\}$ 属于通路2。划分 $\\{S, V\\setminus S\\}$ 将这个稠密的接口孤立为一个社区，这导致了较低的模块度。$\\{C_1, C_2\\}$ 的较高模块度表明，该网络更好地被描述为两个具有一定串扰的较大社区，而不是一个稠密的核心模块和一个稀疏的外围。这表明，高基序密度的区域不一定本身就构成社区；它们可以代表社区之间的接口或边界区域。仅仅依赖像基序计数这样的局部特征对于识别全局社区结构可能具有误导性。\n\n**选项评估**\n\nA. 基序富集划分 $\\{S, V\\setminus S\\}$ 比 $\\{C_1, C_2\\}$ 产生更高的社区分区质量；因此，高三角形频率足以描绘社区分区边界。\n- 前提是错误的。我们的计算表明 $Q_{P_S}  Q_{P_C}$。结论也与我们的发现不一致。\n- **错误**。\n\nB. 区室划分 $\\{C_1, C_2\\}$ 比 $\\{S, V\\setminus S\\}$ 产生更高的社区分区质量；$\\{3,4,6,7\\}$ 处的高三角形频率并未定义社区分区边界，并且仅依赖基序计数可能将边界区域误识别为独立的模块。\n- 第一句话是正确的 ($Q_{P_C} > Q_{P_S}$)。随后的论述是对这一结果的正确解释，正如我们在分析中所解释的。高基序频率是两个较高模块度社区之间接口的特征。\n- **正确**。\n\nC. 两种划分具有相同的社区分区质量，因为它们各自包含相同数量的内部边；社区分区质量仅取决于内部边数，而不取决于度分布。\n- 社区分区质量相同的前提是错误的。给出的理由也是错误的；模块度公式明确包含一个项 $(K_c/2m)^2$，它依赖于度的总和 $K_c$。虽然两个划分恰好有相同数量的内部边（9条），但由于社区内度的分布不同，它们的模块度得分也不同。\n- **错误**。\n\nD. 即使在度保持的零模型下社区分区质量较低，基序富集也能检测到功能性社区，因此模块度对于生物网络中的模块检测是无关紧要的。\n- 这个陈述对模块度的一般效用做出了一个宽泛、主观的论断，这超出了本特定问题分析的范围。问题问的是与此处得出的结果最一致的是什么。结果是，模块度提供了一个与简单基序计数不同的、并且在此背景下更直观的答案。基于此就宣称模块度“无关紧要”是一个站不住脚的逻辑跳跃。\n- **错误**。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "生物模块不仅体现在静态的相互作用网络中，更深刻地反映在系统的动态功能上。本练习将带你进入代谢网络的世界，在这里，模块是由相互依赖的反应流（即“流耦合”）定义的。你将通过线性规划从基本原理出发，实现一个算法来识别这些功能性的代谢模块，从而将模块化的概念从网络拓扑扩展到系统功能层面。",
            "id": "4362294",
            "problem": "您的任务是实现一个程序，该程序为一组代谢网络实例，使用化学计量矩阵和稳态下的质量平衡来计算反应对之间的通量耦合关系，然后根据强耦合关系描绘出代谢模块。目标是从第一性原理出发，从稳态下的质量守恒和通量的线性边界开始，推导出如何判断一个反应对是强耦合、方向耦合还是弱耦合，并将其转化为一个基于线性规划的鲁棒算法。最终输出必须按照下面指定的格式，将所提供的测试套件的结果汇总到单行中。\n\n定义和假设：\n- 令 $S \\in \\mathbb{R}^{m \\times n}$ 表示一个具有 $m$ 个内部代谢物和 $n$ 个反应的代谢网络的化学计量矩阵。令 $v \\in \\mathbb{R}^{n}$ 表示反应通量向量。\n- 稳态质量平衡要求 $S v = 0$。\n- 每个反应 $i$ 都有下界和上界 $l_i \\le v_i \\le u_i$，这些界限被收集到向量 $l \\in \\mathbb{R}^{n}$ 和 $u \\in \\mathbb{R}^{n}$ 中。\n- 可行通量集是一个多面体 $\\mathcal{F} = \\{ v \\in \\mathbb{R}^{n} \\mid S v = 0,\\, l \\le v \\le u \\}$。\n- 测试套件中的所有反应都是不可逆的，且 $l_i = 0$，因此对所有 $i$ 都有 $v_i \\ge 0$，这是稳态通量平衡分析中的常见情况。尽管如此，您的算法在数学上必须对通用的 $l$ 和 $u$ 都是正确的。\n\n通量状态分类：\n- 定义一个小的数值容差 $\\varepsilon = 10^{-9}$ 来判断正性。如果 $\\max\\{ v_i \\mid v \\in \\mathcal{F} \\}  \\varepsilon$，则反应 $i$ 被称为“阻塞”的。\n- 对于一对非阻塞反应 $(i,j)$，定义三种耦合类型：\n  1. 强耦合（代码 $2$）：如果存在一个正标量 $\\phi \\ge \\varepsilon$，使得当 $v_j$ 固定为 $\\phi$ 时，$v_i$ 在 $\\mathcal{F}$ 中的可行值是唯一的，并且对称地，当 $v_i$ 固定为 $\\phi$ 时，$v_j$ 在 $\\mathcal{F}$ 中的可行值也是唯一的，则 $i$ 和 $j$ 是强耦合的。唯一性需要通过检查目标通量在相应等式约束下的最小值和最大值的绝对值差在容差 $\\tau = 10^{-7}$ 以内来数值验证。为确保等式约束的可行性，选择 $\\phi = \\min\\{\\max v_i, \\max v_j\\}$，其中 $\\max v_k = \\max\\{ v_k \\mid v \\in \\mathcal{F} \\}$。\n  2. 方向耦合（对于有序对 $i \\to j$，代码为 $1$）：如果对于所有 $v \\in \\mathcal{F}$ 且 $v_i \\ge \\varepsilon$，都必须满足 $v_j \\ge \\varepsilon$，则 $i$ 方向耦合到 $j$。在算法上，这等同于检查约束条件 $S v = 0$，$l \\le v \\le u$，$v_i \\ge \\varepsilon$ 和 $v_j \\le 0$ 是否不可行。如果不可行，则声明 $i \\to j$ 是方向耦合。如果可行，则 $i \\to j$ 不是方向耦合。不要从一个阻塞的反应来评估方向耦合。\n  3. 弱耦合（对于 $i \\to j$，代码为 $0$）：如果有序对既不满足强耦合也不满足方向耦合，则声明为弱耦合。按照惯例，对角线上的条目为 $0$。\n\n代谢模块：\n- 当 $i \\to j$ 和 $j \\to i$ 都是强耦合时（您的强耦合测试对称地强制执行这一点），在 $i$ 和 $j$ 之间定义无向强耦合边。一个代谢模块是由这些强耦合边在非阻塞反应集合上导出的最大无向连通分量。单点（没有强耦合边的非阻塞反应）也算作模块。阻塞的反应被排除在模块之外。\n\n基本基础：\n- 使用稳态下的质量守恒 $S v = 0$ 和线性边界下可行多面体 $\\mathcal{F}$ 的定义作为出发点。所有的判定都必须简化为具有线性等式和边界约束的线性规划（或可行性问题）。\n\n测试套件：\n对于每个测试用例，您将获得一个化学计量矩阵 $S$、下界 $l$ 和上界 $u$。问题中不出现角度，因此不需要角度单位。此问题中通量没有物理单位；将通量视为无量纲实数。\n\n- 测试用例 1（线性链，所有反应预期为强耦合）：\n  - $S \\in \\mathbb{R}^{3 \\times 4}$:\n    $$\n    S = \\begin{bmatrix}\n    1   -1  0   0 \\\\\n    0   1   -1  0 \\\\\n    0   0   1   -1\n    \\end{bmatrix}\n    $$\n  - $l = [0, 0, 0, 0]$\n  - $u = [10, 100, 100, 100]$\n\n- 测试用例 2（汇合供应到一个中间产物，产生方向耦合但在分支上不产生强耦合）：\n  - $S \\in \\mathbb{R}^{3 \\times 5}$:\n    $$\n    S = \\begin{bmatrix}\n    1   -1  0   0   0 \\\\\n    0   1   -1  0   1 \\\\\n    0   0   1   -1  0\n    \\end{bmatrix}\n    $$\n  - $l = [0, 0, 0, 0, 0]$\n  - $u = [10, 100, 100, 100, 7]$\n\n- 测试用例 3（一个反应因内部池没有汇而被阻塞，其他反应强耦合）：\n  - $S \\in \\mathbb{R}^{3 \\times 4}$:\n    $$\n    S = \\begin{bmatrix}\n    1   -1  0   0 \\\\\n    0   1   -1  0 \\\\\n    0   0   0   1\n    \\end{bmatrix}\n    $$\n    第三行强制 $v_4 = 0$，从而阻塞了反应 $4$。\n  - $l = [0, 0, 0, 0]$\n  - $u = [5, 100, 100, 100]$\n\n程序要求：\n- 通过仅使用从 $S v = 0$ 和边界 $l \\le v \\le u$ 导出的线性约束来求解所需的线性规划，为每个测试用例实现分类。\n- 使用 $\\varepsilon = 10^{-9}$ 和 $\\tau = 10^{-7}$ 作为上述定义的数值容差。\n- 对于每个具有 $n$ 个反应的测试用例，构建一个 $n \\times n$ 的整数矩阵 $C$，其中条目 $C_{ij}$ 为：\n  - 如果反应 $i$ 和 $j$ 是强耦合的，则为 $2$（对称的，适用于两个方向），\n  - 如果反应 $i$ 方向耦合到反应 $j$ 但它们不是强耦合的，则为 $1$，\n  - 否则为 $0$（包括对角线条目）。\n- 计算代谢模块，即非阻塞反应中无向强耦合边下的连通分量列表。在模块内部使用零基索引表示反应标识符。每个模块内的反应按升序排序。模块列表按其最小索引升序排序。\n- 最终输出格式：您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，其中每个元素对应一个测试用例。对于每个测试用例，输出一个包含两个元素的列表：\n  - 第一个元素是按行主序展开的 $C$ 矩阵，作为一个整数列表。\n  - 第二个元素是模块列表，每个模块是一个整数列表。\n因此，总输出格式为 $[ [C^{(1)}\\_{\\mathrm{flat}}, \\mathrm{modules}^{(1)}], [C^{(2)}\\_{\\mathrm{flat}}, \\mathrm{modules}^{(2)}], [C^{(3)}\\_{\\mathrm{flat}}, \\mathrm{modules}^{(3)}] ]$，打印在单行上，不带任何额外文本。\n\n您的实现必须是通用的，并且对提供的测试套件是正确的，并严格遵守上述定义。",
            "solution": "在生物网络中识别通量耦合关系和代谢模块的问题，是系统生物学和基于约束的建模领域中一个定义明确的问题。其解决方案可以从稳态下质量守恒的基本原理推导出来，并受制于反应通量的热力学和容量约束。\n\n### 基于原理的推导\n\n代谢网络由其化学计量学描述，表示为矩阵 $S \\in \\mathbb{R}^{m \\times n}$，其中 $m$ 是代谢物数量，$n$ 是反应数量。向量 $v \\in \\mathbb{R}^{n}$ 包含这些反应的通量。\n\n1.  **稳态和可行通量空间**：核心原理是内部代谢物的质量守恒。在准稳态假设（$\\frac{d[\\text{metabolite}]}{dt} = 0$）下，每种代谢物的产生和消耗必须平衡，从而得到线性方程组：\n    $$S v = 0$$\n    此外，每个反应通量 $v_i$ 都受下界和上界 $l_i \\le v_i \\le u_i$ 的约束，这些约束源于热力学不可逆性（例如 $l_i=0$）和酶容量（$u_i  \\infty$）。这些约束在 $\\mathbb{R}^n$ 中定义了一个凸多面体，称为可行通量空间：\n    $$\\mathcal{F} = \\{ v \\in \\mathbb{R}^{n} \\mid S v = 0, \\, l \\le v \\le u \\}$$\n    所有后续分析都在这个集合 $\\mathcal{F}$ 上进行。\n\n2.  **通量变异性和阻塞反应**：为了理解单个反应 $i$ 的能力，我们可以确定其在整个可行空间中的最小和最大可能通量值。这是一个线性规划（LP）问题。例如，要找到反应 $i$ 的最大通量：\n    $$\n    \\begin{aligned}\n     \\underset{v}{\\text{maximize}}   v_i \\\\\n     \\text{subject to}   S v = 0 \\\\\n       l \\le v \\le u\n    \\end{aligned}\n    $$\n    如果一个反应 $i$ 的通量在所有可行状态下都被迫为可忽略的值，则该反应被定义为“阻塞”的。根据问题的定义，这通过确定其最大通量是否低于一个小的容差 $\\varepsilon > 0$ 来检查。对于一个通常可逆的反应，必须检查 $\\max(|v_i|)$ 是否可忽略，这涉及到求解 $\\max(v_i)$ 和 $\\min(v_i)$。问题规定检查 $\\max\\{ v_i \\mid v \\in \\mathcal{F} \\}  \\varepsilon = 10^{-9}$。这对于 $l_i=0$ 的测试用例是足够的。\n\n3.  **通量耦合分析**：耦合关系描述了一个反应的活性如何约束另一个反应。这些关系可以通过求解一系列线性规划问题来系统地揭示。让我们考虑两个非阻塞的反应 $i$ 和 $j$。\n\n    a.  **强耦合**：如果反应 $i$ 和 $j$ 的通量必须成比例，则它们是强耦合的。问题为此提供了一个特定的算法测试：将一个反应的通量固定为一个选定的正值 $\\phi$，并检查另一个反应的通量是否变得唯一确定。$\\phi$ 的值被规定为 $\\phi = \\min\\{\\max v_i, \\max v_j\\}$。该过程如下：\n    \n        -   首先，测试蕴含关系 $j \\to i$：在受限的可行集 $\\mathcal{F}'_j = \\{ v \\in \\mathcal{F} \\mid v_j = \\phi \\}$ 上求解 $v_i$ 的最小值和最大值。如果此集合为空（不可行）或如果 $\\max_{\\mathcal{F}'_j}(v_i) - \\min_{\\mathcal{F}'_j}(v_i) \\ge \\tau = 10^{-7}$，则测试失败。\n        -   其次，对称地测试蕴含关系 $i \\to j$：在 $\\mathcal{F}'_i = \\{ v \\in \\mathcal{F} \\mid v_i = \\phi \\}$ 上求解 $v_j$ 的最小值/最大值。如果这不可行或通量范围不在 $\\tau$ 之内，则测试失败。\n        -   如果两个测试都通过，则声明反应 $i$ 和 $j$ 是强耦合的（代码 $2$）。\n\n    b.  **方向耦合**：如果通过 $i$ 的正通量必然导致通过 $j$ 的正通量，则反应 $i$ 方向耦合到反应 $j$ ($i \\to j$)。问题通过一个等效的算法检查来定义这一点：对应于“在 $\\mathcal{F}$ 中存在一个通量向量，使得 $v_i \\ge \\varepsilon$ 且 $v_j \\le 0$”的约束系统必须是不可行的。这是一个可行性线性规划问题：\n        $$\n        \\begin{aligned}\n         \\text{find}   v \\\\\n         \\text{subject to}   S v = 0 \\\\\n           l \\le v \\le u \\\\\n           v_i \\ge \\varepsilon \\\\\n           v_j \\le 0\n        \\end{aligned}\n        $$\n        如果一个线性规划求解器发现这个系统是不可行的，我们断定 $i$ 方向耦合到 $j$（代码 $1$）。这个检查只在该对尚未被确定为强耦合时进行。\n\n    c.  **弱耦合**：如果一对反应在给定方向上既不是强耦合也不是方向耦合，则它们是弱耦合的（代码 $0$）。这是默认状态。\n\n4.  **代谢模块**：强耦合的反应在代谢网络中形成紧密协同调控的区块，通常对应于线性途径或必须协同作用的酶集。这些可以被定义为代谢模块。问题将一个模块定义为一个图中的最大连通分量，其中顶点是非阻塞反应，如果两个顶点是强耦合的，则它们之间存在一条边。寻找这些模块是一个标准的图遍历问题（例如，使用广度优先搜索或深度优先搜索）来识别连通分量。未与其他任何反应强耦合的单个非阻塞反应形成单点模块。\n\n### 算法实现\n\n总体算法流程如下：\n1.  对于 $n$ 个反应中的每一个，求解一个线性规划问题以找到其最大通量 $\\max v_i$。识别所有阻塞的反应（$\\max v_i  \\varepsilon$），并存储非阻塞反应列表及其最大通量。\n2.  初始化一个 $n \\times n$ 的耦合矩阵 $C$，所有元素为零。\n3.  遍历所有非阻塞反应的唯一对 $(i, j)$。对于每一对，使用四个线性规划问题（固定 $v_j$ 时的 $\\min/\\max v_i$，以及固定 $v_i$ 时的 $\\min/\\max v_j$）应用强耦合测试。如果测试通过，设置 $C_{ij} = C_{ji} = 2$。\n4.  遍历所有反应的有序对 $(i, j)$。如果 $i$ 未被阻塞且 $C_{ij}$ 不已经是 $2$，则执行方向耦合可行性测试。如果相应的线性规划问题不可行，则设置 $C_{ij} = 1$。\n5.  使用非阻塞反应作为顶点构建一个图。如果在任意两个反应 $i$ 和 $j$ 之间 $C_{ij} = 2$，则在它们之间添加一条无向边。\n6.  找到这个图的连通分量。每个分量都是一个代谢模块。对每个模块内的反应进行排序，并按模块中最小元素对模块列表进行排序。\n7.  为每个测试用例格式化展开的 $C$ 矩阵和模块列表。\n`scipy.optimize.linprog` 函数用于解决所有必需的线性规划和可行性问题。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Main function to solve the metabolic network analysis problem for all test cases.\n    \"\"\"\n\n    def list_to_str(data):\n        \"\"\"\n        Recursively converts a Python list to a string with no whitespace.\n        \"\"\"\n        if isinstance(data, list):\n            return f\"[{','.join(map(list_to_str, data))}]\"\n        return str(data)\n\n    class MetabolicNetworkAnalyzer:\n        \"\"\"\n        A class to perform flux coupling and module analysis on a metabolic network.\n        \"\"\"\n        def __init__(self, S, l, u, eps=1e-9, tau=1e-7):\n            self.S = np.array(S, dtype=float)\n            self.l = np.array(l, dtype=float)\n            self.u = np.array(u, dtype=float)\n            self.eps = eps\n            self.tau = tau\n            self.m, self.n = self.S.shape\n            \n            self.b_eq = np.zeros(self.m)\n            self.base_bounds = list(zip(self.l, self.u))\n            \n            self.max_fluxes = np.zeros(self.n)\n            self.non_blocked_reactions = []\n            self.coupling_matrix = np.zeros((self.n, self.n), dtype=int)\n            self.modules = []\n\n        def _solve_lp(self, c, bounds):\n            \"\"\"Helper function to call scipy's linprog.\"\"\"\n            # The 'highs' method is robust and recommended.\n            res = linprog(c, A_eq=self.S, b_eq=self.b_eq, bounds=bounds, method='highs')\n            return res\n\n        def _find_blocked_reactions(self):\n            \"\"\"\n            Identifies blocked reactions by maximizing flux for each reaction.\n            A reaction i is blocked if max(v_i)  eps.\n            \"\"\"\n            non_blocked = []\n            for i in range(self.n):\n                c = np.zeros(self.n)\n                c[i] = -1  # To maximize v_i\n                \n                res = self._solve_lp(c, self.base_bounds)\n                \n                max_v = -res.fun if res.success else 0.0\n                self.max_fluxes[i] = max_v\n                \n                if max_v >= self.eps:\n                    non_blocked.append(i)\n            \n            self.non_blocked_reactions = non_blocked\n\n        def _check_strong_coupling(self, i, j):\n            \"\"\"\n            Checks for strong coupling between reactions i and j.\n            \"\"\"\n            phi = min(self.max_fluxes[i], self.max_fluxes[j])\n            if phi  self.eps:\n                return False\n\n            # Test 1: Fix v_j = phi, check if v_i is unique\n            bounds1 = list(self.base_bounds)\n            bounds1[j] = (phi, phi)\n\n            # Minimize v_i\n            c_min_i = np.zeros(self.n)\n            c_min_i[i] = 1\n            res_min_i = self._solve_lp(c_min_i, bounds1)\n            if not res_min_i.success: return False\n            v_i_min = res_min_i.fun\n\n            # Maximize v_i\n            c_max_i = np.zeros(self.n)\n            c_max_i[i] = -1\n            res_max_i = self._solve_lp(c_max_i, bounds1)\n            if not res_max_i.success: return False\n            v_i_max = -res_max_i.fun\n            \n            if abs(v_i_max - v_i_min) >= self.tau:\n                return False\n\n            # Test 2: Fix v_i = phi, check if v_j is unique\n            bounds2 = list(self.base_bounds)\n            bounds2[i] = (phi, phi)\n            \n            # Minimize v_j\n            c_min_j = np.zeros(self.n)\n            c_min_j[j] = 1\n            res_min_j = self._solve_lp(c_min_j, bounds2)\n            if not res_min_j.success: return False\n            v_j_min = res_min_j.fun\n            \n            # Maximize v_j\n            c_max_j = np.zeros(self.n)\n            c_max_j[j] = -1\n            res_max_j = self._solve_lp(c_max_j, bounds2)\n            if not res_max_j.success: return False\n            v_j_max = -res_max_j.fun\n            \n            if abs(v_j_max - v_j_min) >= self.tau:\n                return False\n\n            return True\n\n        def _check_directional_coupling(self, i, j):\n            \"\"\"\n            Checks for directional coupling i -> j.\n            \"\"\"\n            if i not in self.non_blocked_reactions:\n                return False\n\n            temp_bounds = list(self.base_bounds)\n            \n            # v_i >= eps\n            l_i, u_i = temp_bounds[i]\n            temp_bounds[i] = (max(l_i, self.eps), u_i)\n            \n            # v_j = 0\n            l_j, u_j = temp_bounds[j]\n            temp_bounds[j] = (l_j, min(u_j, 0.0))\n\n            if temp_bounds[i][0] > temp_bounds[i][1] or temp_bounds[j][0] > temp_bounds[j][1]:\n                return True # Inherently infeasible bounds\n\n            # Feasibility problem: objective is zero vector.\n            c_feasibility = np.zeros(self.n)\n            res = self._solve_lp(c_feasibility, temp_bounds)\n            \n            # Infeasible (status 2) implies directional coupling\n            return res.status == 2\n\n        def _calculate_couplings(self):\n            \"\"\"\n            Calculates the full coupling matrix C.\n            \"\"\"\n            # Strong coupling (symmetric)\n            for idx1, i in enumerate(self.non_blocked_reactions):\n                for j in self.non_blocked_reactions[idx1+1:]:\n                    if self._check_strong_coupling(i, j):\n                        self.coupling_matrix[i, j] = 2\n                        self.coupling_matrix[j, i] = 2\n\n            # Directional coupling\n            for i in range(self.n):\n                for j in range(self.n):\n                    if i == j or self.coupling_matrix[i, j] == 2:\n                        continue\n                    if self._check_directional_coupling(i, j):\n                        self.coupling_matrix[i, j] = 1\n        \n        def _find_modules(self):\n            \"\"\"\n            Finds metabolic modules from strong coupling graph.\n            \"\"\"\n            adj = {r: [] for r in self.non_blocked_reactions}\n            for i in range(self.n):\n                for j in range(i + 1, self.n):\n                    if self.coupling_matrix[i, j] == 2:\n                        adj[i].append(j)\n                        adj[j].append(i)\n\n            visited = set()\n            modules = []\n            for r in self.non_blocked_reactions:\n                if r not in visited:\n                    current_module = []\n                    q = [r]\n                    visited.add(r)\n                    while q:\n                        node = q.pop(0)\n                        current_module.append(node)\n                        for neighbor in adj[node]:\n                            if neighbor not in visited:\n                                visited.add(neighbor)\n                                q.append(neighbor)\n                    modules.append(sorted(current_module))\n            \n            self.modules = sorted(modules, key=lambda m: m[0])\n\n        def run(self):\n            \"\"\"\n            Executes the full analysis pipeline.\n            \"\"\"\n            self._find_blocked_reactions()\n            self._calculate_couplings()\n            self._find_modules()\n\n        def get_result(self):\n            \"\"\"\n            Returns the final formatted result for the test case.\n            \"\"\"\n            c_flat = self.coupling_matrix.flatten().tolist()\n            return [c_flat, self.modules]\n\n    test_cases = [\n        (\n            [[1, -1, 0, 0], [0, 1, -1, 0], [0, 0, 1, -1]],\n            [0, 0, 0, 0],\n            [10, 100, 100, 100],\n        ),\n        (\n            [[1, -1, 0, 0, 0], [0, 1, -1, 0, 1], [0, 0, 1, -1, 0]],\n            [0, 0, 0, 0, 0],\n            [10, 100, 100, 100, 7],\n        ),\n        (\n            [[1, -1, 0, 0], [0, 1, -1, 0], [0, 0, 0, 1]],\n            [0, 0, 0, 0],\n            [5, 100, 100, 100],\n        )\n    ]\n    \n    all_results = []\n    for S, l, u in test_cases:\n        analyzer = MetabolicNetworkAnalyzer(S, l, u)\n        analyzer.run()\n        all_results.append(analyzer.get_result())\n        \n    print(list_to_str(all_results))\n\nsolve()\n```"
        },
        {
            "introduction": "在系统生物学中，任何计算分析的结论都需要经过严格的统计验证，模块识别也不例外。由于生物数据的内在噪声和不完整性，我们发现的模块有多大可能是真实存在的，而不是随机的假象？这个高级实践将指导你实施一个基于“自举法”（bootstrap）重采样的框架，以评估社区划分的稳健性，并量化我们所识别模块的可复现性，这是将计算结果转化为可靠生物学见解的关键一步。",
            "id": "4362312",
            "problem": "给定一个由邻接概率矩阵 $P \\in [0,1]^{n \\times n}$ 表示的无向、无自环、加权图族，其中 $P_{ii} = 0$ 且 $P_{ij} = P_{ji}$。每个条目 $P_{ij}$ 被解释为节点 $i$ 和节点 $j$ 之间存在边的概率。目标是评估在进行边的自助重采样（bootstrap resampling）和社群检测后，模块（社群）的可复现性，并使用节点成员关系的 Jaccard 相似度来识别一致的模块。\n\n评估必须从第一性原理出发，并在一个单一的可运行程序中实现。您的程序必须实现以下定义和步骤：\n\n- 图的构建与零模型：\n    - 图由一个对称邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 表示，其中 $A_{ij} \\ge 0$ 且 $A_{ii} = 0$。\n    - 节点 $i$ 的度为 $k_i = \\sum_{j=1}^{n} A_{ij}$。\n    - 总边权重为 $m = \\frac{1}{2} \\sum_{i,j=1}^{n} A_{ij}$。\n    - 社群分配是一个向量 $c \\in \\{0,1,\\dots,K-1\\}^{n}$，其中 $c_i$ 标记节点 $i$ 所属的社群。\n    - 一个划分 $c$ 的模块度 $Q$ 是相对于配置模型（configuration-model）的零期望定义的，公式如下\n      $$ Q(A,c) = \\frac{1}{2m} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) \\, \\mathbf{1}\\{ c_i = c_j \\}, $$\n      其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，且 $m > 0$。如果 $m = 0$，则定义 $Q(A,c) = 0$。\n\n- 边的自助重采样：\n    - 给定 $P$，通过对上三角部分进行独立的伯努利抽样来生成自助重采样副本 $\\tilde{A}^{(b)}$（其中 $b \\in \\{1,\\dots,B\\}$）：对于 $i  j$，抽取 $\\tilde{A}^{(b)}_{ij} \\sim \\text{Bernoulli}(P_{ij})$ 并设置 $\\tilde{A}^{(b)}_{ji} = \\tilde{A}^{(b)}_{ij}$，同时设置 $\\tilde{A}^{(b)}_{ii} = 0$。\n    - 这通过与给定概率一致的独立试验来为边的存在不确定性建模。\n\n- 通过贪心模块度最大化进行社群检测：\n    - 实现一个确定性的贪心算法，该算法开始时将每个节点置于其自身的社群中，然后迭代地将节点移动到能够严格增加 $Q$ 值的社群，每次候选移动后都重新计算 $Q$。在没有任何单节点移动能改善 $Q$ 之后，尝试能够严格增加 $Q$ 值的成对社群合并，直到无法进一步改善为止。更新后，将社群索引重新标记为连续整数。此算法必须适用于加权图，并且除了基本的矩阵运算外，不得假定任何专门的库函数。\n\n- 节点成员关系的 Jaccard 相似度：\n    - 对于一个划分 $c$，节点 $i$ 的成员关系集合是 $S_i(c) = \\{ j \\in \\{1,\\dots,n\\} \\,:\\, c_j = c_i \\}$。\n    - 对于通过将 $P$ 视为加权邻接矩阵并应用贪心模块度算法得到的参考划分 $c^{(0)}$，以及对于从 $\\tilde{A}^{(b)}$ 得到的每个自助重采样划分 $c^{(b)}$，定义节点级别的 Jaccard 相似度\n      $$ J_i^{(b)} = \\frac{ \\left| S_i(c^{(0)}) \\cap S_i(c^{(b)}) \\right| }{ \\left| S_i(c^{(0)}) \\cup S_i(c^{(b)}) \\right| }. $$\n    - 对于一个参考模块 $M \\subseteq \\{1,\\dots,n\\}$，其中 $M = \\{ i \\,:\\, c_i^{(0)} = \\ell \\}$（$\\ell$ 为某个标签），将其可复现性分数定义为其成员节点和所有自助重采样副本上的平均 Jaccard 相似度：\n      $$ R_M = \\frac{1}{|M| \\, B} \\sum_{i \\in M} \\sum_{b=1}^{B} J_i^{(b)}. $$\n    - 通过要求 $|M| \\ge 2$ 从一致性评估中排除平凡的单例模块。\n\n- 一致性决策规则：\n    - 给定一个阈值 $\\tau \\in [0,1]$，如果 $R_M \\ge \\tau$，则宣布模块 $M$ 是一致的。\n\n您的程序必须实现上述完整过程，并评估以下测试套件，其中每个测试用例由 (`module_sizes`, `p_in`, `p_out`, `B`, `tau`, `s`) 指定：\n\n- 测试用例 1（清晰的模块结构）：\n    - `module_sizes` = [4,4],\n    - `p_in` = 0.9,\n    - `p_out` = 0.05,\n    - `B` = 200,\n    - `tau` = 0.8,\n    - `s` = 123.\n\n- 测试用例 2（模糊的结构）：\n    - `module_sizes` = [3,3,3],\n    - `p_in` = 0.6,\n    - `p_out` = 0.4,\n    - `B` = 300,\n    - `tau` = 0.8,\n    - `s` = 456.\n\n- 测试用例 3（均匀连接，单一模块）：\n    - `module_sizes` = [6],\n    - `p_in` = 0.5,\n    - `p_out` = 0.5,\n    - `B` = 200,\n    - `tau` = 0.8,\n    - `s` = 789.\n\n- 测试用例 4（类似核心-边缘结构，带有一个单例）：\n    - `module_sizes` = [1,3,3],\n    - `p_in` = 0.85,\n    - `p_out` = 0.1,\n    - `B` = 250,\n    - `tau` = 0.8,\n    - `s` = 42.\n\n对于每个测试用例，按如下方式构建概率邻接矩阵 $P$：令 $n$ 为 `module_sizes` 的总和。对于在同一声明模块内的节点，设置 $P_{ij} = p_{\\text{in}}$（$i \\ne j$）；对于在不同声明模块中的节点，设置 $P_{ij} = p_{\\text{out}}$（$i \\ne j$）。始终设置 $P_{ii} = 0$。在单一模块的情况下，这简化为 $P_{ij} = p_{\\text{in}}$（$i \\ne j$）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[result1,result2,result3,result4]”），其中每个结果是相应测试用例的一致模块（大小至少为 $2$）的整数计数，按上面列出的顺序排列。不应打印任何其他文本。所有量都是无单位的实数或整数；不涉及物理单位或角度单位。阈值 $\\tau$ 必须视为 $[0,1]$ 范围内的十进制值。",
            "solution": "目标是评估在一个由边概率矩阵 $P$ 定义的图族中，所识别出的网络模块（社群）的可复现性。评估过程包括对图的边进行自助重采样，随后通过贪心模块度最大化算法进行社群检测，并使用已发现模块中节点成员关系的 Jaccard 相似度来量化一致性。\n\n### **1. 问题阐述**\n\n设一个图由一个对称邻接矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 表示，其中 $n$ 是节点数，$A_{ij} \\ge 0$ 是节点 $i$ 和 $j$ 之间边的权重，且 $A_{ii} = 0$（无自环）。\n\n节点 $i$ 的**度**是其关联边的权重之和：\n$$ k_i = \\sum_{j=1}^{n} A_{ij} $$\n\n图中**总边权重**为 $m$：\n$$ m = \\frac{1}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n} A_{ij} = \\frac{1}{2} \\sum_{i=1}^{n} k_i $$\n\n**社群结构**是节点的一个不相交集合划分。它由一个社群分配向量 $c \\in \\{0, 1, \\dots, K-1\\}^n$ 表示，其中 $c_i$ 是分配给节点 $i$ 的社群标签。\n\n**模块度** $Q$ 用于衡量一个划分的质量。它将社群内部的边权重比例与一个零模型（配置模型）中的期望比例进行比较，在零模型中，边是随机放置的，但保留了节点的度。对于图 $A$ 的一个划分 $c$，其模块度为：\n$$ Q(A, c) = \\frac{1}{2m} \\sum_{i=1}^{n} \\sum_{j=1}^{n} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) \\mathbf{1}\\{c_i = c_j\\} $$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。如果 $m=0$，我们定义 $Q(A,c) = 0$。\n\n该问题通过一个对称的**邻接概率矩阵** $P \\in [0,1]^{n \\times n}$ 来定义一个图族，其中 $P_{ij}$ 是节点 $i$ 和 $j$ 之间存在边的概率。\n\n### **2. 算法流程**\n\n对每个测试用例，评估过程包括以下步骤。\n\n**步骤 1：参考社群检测**\n概率矩阵 $P$ 本身被视为一个加权邻接矩阵，代表了期望的图结构。通过对该矩阵 $P$ 应用确定性的贪心模块度最大化算法，可以获得一个**参考划分** $c^{(0)}$。\n\n**步骤 2：自助重采样**\n为评估稳定性，生成 $B$ 个自助重采样副本图，其邻接矩阵表示为 $\\tilde{A}^{(b)}$（$b \\in \\{1, \\dots, B\\}$）。每个 $\\tilde{A}^{(b)}$ 都是一个无权、无向图。对于每对节点 $(i, j)$（$i  j$），以概率 $P_{ij}$ 独立地创建一条边。形式上：\n$$ \\tilde{A}^{(b)}_{ij} \\sim \\text{Bernoulli}(P_{ij}) \\quad \\text{for } i  j $$\n通过设置 $\\tilde{A}^{(b)}_{ji} = \\tilde{A}^{(b)}_{ij}$ 使矩阵对称，且对角线元素为零，即 $\\tilde{A}^{(b)}_{ii} = 0$。指定的随机种子 $s$ 确保了此过程的可复现性。\n\n**步骤 3：在副本图上进行社群检测**\n将相同的贪心模块度最大化算法应用于每个自助重采样副本 $\\tilde{A}^{(b)}$，以获得一组自助重采样划分 $\\{c^{(1)}, c^{(2)}, \\dots, c^{(B)}\\}$。\n\n**步骤 4：一致性评估**\n在参考划分 $c^{(0)}$ 中找到的模块的一致性，将通过与自助重采样划分 $c^{(b)}$ 的比较来进行评估。\n\n- **节点成员关系集合**：对于给定的划分 $c$，节点 $i$ 的成员关系集合（表示为 $S_i(c)$）是所有与节点 $i$ 属于同一社群的节点的集合：\n  $$ S_i(c) = \\{ j \\in \\{1, \\dots, n\\} \\,:\\, c_j = c_i \\} $$\n\n- **节点级 Jaccard 相似度**：节点 $i$ 周围的局部社群结构在参考划分 $c^{(0)}$ 和自助重采样划分 $c^{(b)}$ 之间的相似性，通过其成员关系集合的 Jaccard 相似度来量化：\n  $$ J_i^{(b)} = \\frac{ \\left| S_i(c^{(0)}) \\cap S_i(c^{(b)}) \\right| }{ \\left| S_i(c^{(0)}) \\cup S_i(c^{(b)}) \\right| } $$\n\n- **模块可复现性分数**：一个**参考模块** $M$ 是在参考划分中共享相同社群标签的一组节点，即 $M = \\{i \\,:\\, c_i^{(0)} = \\ell\\}$（$\\ell$ 为某个标签）。该模块的可复现性分数 $R_M$ 是节点级 Jaccard 相似度的平均值，该平均值计算了模块中所有节点和所有自助重采样副本：\n  $$ R_M = \\frac{1}{|M| \\cdot B} \\sum_{i \\in M} \\sum_{b=1}^{B} J_i^{(b)} $$\n  大小为 $|M|  2$ 的平凡模块被排除在此分析之外。\n\n- **一致性决策**：如果一个参考模块 $M$（$|M| \\ge 2$）的可复现性分数达到或超过给定阈值 $\\tau$，则该模块被声明为**一致的**：\n  $$ R_M \\ge \\tau $$\n一个测试用例的最终结果是此类一致模块的总数。\n\n### **3. 贪心模块度最大化算法**\n\n实现一个确定性的贪心算法来找到一个近似最大化模块度 $Q$ 的划分。该算法分两个阶段进行，这两个阶段会重复执行，直到 $Q$ 值无法再增加为止。\n\n**初始化**：将 $n$ 个节点中的每一个都分配到其自己唯一的社群中。\n\n**阶段 1：迭代节点移动**\n该阶段包括在社群之间迭代地移动单个节点。算法遍历每个节点，并评估将其移动到其他每个社群时模块度 $Q$ 的变化量 $\\Delta Q$。执行能带来最大正 $\\Delta Q$ 的移动。为确保确定性，此实现在每一步中都会在所有节点和所有可能的目标社群中搜索全局最佳移动。只有当 $\\Delta Q > 0$ 时才会进行移动。此阶段重复进行，直到没有任何单节点移动能严格增加 $Q$。将节点 $u$ 从社群 $C$ 移动到社群 $D$ 的模块度变化量由下式给出：\n$$ \\Delta Q_{move} = \\frac{k_{u,D} - k_{u,C}}{m} + \\frac{k_u(D_C - D_D - k_u)}{2m^2} $$\n其中 $k_{u,X} = \\sum_{j \\in X} A_{uj}$ 是从节点 $u$ 到社群 $X$ 中节点的边权重之和，$D_X = \\sum_{j \\in X} k_j$ 是社群 $X$ 中节点的度之和。\n\n**阶段 2：迭代社群合并**\n节点移动阶段收敛后，算法会尝试合并现有的社群对。它评估每对可能合并的社群的 $\\Delta Q$。执行能产生最大正 $\\Delta Q$ 的合并。此阶段重复进行，直到没有任何成对合并能严格增加 $Q$。合并两个社群 $C_1$ 和 $C_2$ 的模块度变化量为：\n$$ \\Delta Q_{merge} = \\frac{L_{12}}{m} - \\frac{D_1 D_2}{2m^2} $$\n其中 $L_{12} = \\sum_{i \\in C_1, j \\in C_2} A_{ij}$ 是社群 $C_1$ 和 $C_2$ 之间的边权重之和。\n\n**终止条件**：整个算法交替运行阶段 1 至收敛和阶段 2 至收敛。当完整地执行完两个阶段后，社群结构不再发生变化，即全局模块度无法再增加时，算法终止。在任何可能产生空社群的更新之后，社群标签会被重新标记为连续整数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef _calculate_q(A, c, m, k):\n    \"\"\"Calculates modularity Q.\"\"\"\n    if m == 0:\n        return 0.0\n    \n    q_val = 0.0\n    communities = np.unique(c)\n    for comm_id in communities:\n        nodes_in_comm = np.where(c == comm_id)[0]\n        sum_weights_in = A[np.ix_(nodes_in_comm, nodes_in_comm)].sum() / 2.0\n        sum_degrees_in = k[nodes_in_comm].sum()\n        \n        term1 = sum_weights_in / m\n        term2 = (sum_degrees_in / (2.0 * m)) ** 2\n        q_val += term1 - term2\n    return q_val\n\ndef _relabel_communities(c):\n    \"\"\"Relabels community indices to be contiguous from 0.\"\"\"\n    _, a = np.unique(c, return_inverse=True)\n    return a\n\ndef greedy_modularity_maximization(A):\n    \"\"\"\n    Performs greedy modularity maximization on an adjacency matrix A.\n    The algorithm is deterministic.\n    \"\"\"\n    n = A.shape[0]\n    if n == 0:\n        return np.array([], dtype=int)\n\n    k = A.sum(axis=1)\n    m = k.sum() / 2.0\n\n    if m == 0:\n        return np.arange(n)\n\n    c = np.arange(n)\n\n    while True:\n        global_improvement = False\n\n        # Phase 1: Node movements\n        while True:\n            node_move_improvement = False\n            best_delta_q = 1e-10 # Use a small epsilon to ensure strict increase\n            best_move = None\n            \n            # Deterministic iteration over nodes\n            for u in range(n):\n                current_comm_id = c[u]\n                ku = k[u]\n                \n                # Try moving node u to other communities\n                comms_to_try = np.unique(c)\n                \n                for target_comm_id in comms_to_try:\n                    if target_comm_id == current_comm_id:\n                        continue\n\n                    # Calculate Delta Q\n                    nodes_in_current_comm = np.where(c == current_comm_id)[0]\n                    nodes_in_target_comm = np.where(c == target_comm_id)[0]\n\n                    k_u_current = A[u, nodes_in_current_comm].sum()\n                    k_u_target = A[u, nodes_in_target_comm].sum()\n                    \n                    D_current = k[nodes_in_current_comm].sum()\n                    D_target = k[nodes_in_target_comm].sum()\n\n                    delta_q = ((k_u_target - k_u_current) / m) + \\\n                              (ku * (D_current - D_target - ku) / (2.0 * m**2))\n\n                    if delta_q > best_delta_q:\n                        best_delta_q = delta_q\n                        best_move = (u, target_comm_id)\n            \n            if best_move is not None:\n                u, target_comm_id = best_move\n                c[u] = target_comm_id\n                c = _relabel_communities(c)\n                node_move_improvement = True\n                global_improvement = True\n            \n            if not node_move_improvement:\n                break\n        \n        # Phase 2: Community merging\n        while True:\n            merge_improvement = False\n            best_delta_q = 1e-10 # Use a small epsilon\n            best_merge = None\n            \n            unique_comms = np.unique(c)\n            if len(unique_comms) = 1:\n                break\n            \n            # Deterministic iteration over community pairs\n            for i in range(len(unique_comms)):\n                for j in range(i + 1, len(unique_comms)):\n                    comm1_id = unique_comms[i]\n                    comm2_id = unique_comms[j]\n                    \n                    nodes1 = np.where(c == comm1_id)[0]\n                    nodes2 = np.where(c == comm2_id)[0]\n                    \n                    L12 = A[np.ix_(nodes1, nodes2)].sum()\n                    D1 = k[nodes1].sum()\n                    D2 = k[nodes2].sum()\n                    \n                    delta_q = (L12 / m) - (D1 * D2 / (2.0 * m**2))\n                    \n                    if delta_q > best_delta_q:\n                        best_delta_q = delta_q\n                        best_merge = (comm1_id, comm2_id)\n\n            if best_merge is not None:\n                comm1_id, comm2_id = best_merge\n                c[c == comm2_id] = comm1_id\n                c = _relabel_communities(c)\n                merge_improvement = True\n                global_improvement = True\n\n            if not merge_improvement:\n                break\n\n        if not global_improvement:\n            break\n            \n    return c\n\ndef _build_p_matrix(module_sizes, p_in, p_out):\n    n = sum(module_sizes)\n    P = np.zeros((n, n))\n    \n    node_indices = np.cumsum([0] + module_sizes)\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            is_same_module = False\n            for k in range(len(module_sizes)):\n                if node_indices[k] = i  node_indices[k+1] and \\\n                   node_indices[k] = j  node_indices[k+1]:\n                    is_same_module = True\n                    break\n            \n            if is_same_module:\n                P[i, j] = P[j, i] = p_in\n            else:\n                P[i, j] = P[j, i] = p_out\n    return P\n\ndef evaluate_reproducibility(module_sizes, p_in, p_out, B, tau, s):\n    \"\"\"\n    Main function to run the full evaluation procedure for one test case.\n    \"\"\"\n    rng = np.random.default_rng(seed=s)\n    P = _build_p_matrix(module_sizes, p_in, p_out)\n    n = P.shape[0]\n\n    # Step 1: Reference community detection on P\n    c0 = greedy_modularity_maximization(P)\n\n    jaccard_scores = np.zeros((B, n))\n\n    for b in range(B):\n        # Step 2: Bootstrap resampling\n        A_tilde = np.zeros((n, n))\n        rand_mat = rng.random((n, n))\n        for i in range(n):\n            for j in range(i + 1, n):\n                if rand_mat[i, j]  P[i, j]:\n                    A_tilde[i, j] = A_tilde[j, i] = 1.0\n\n        # Step 3: Community detection on replicate\n        cb = greedy_modularity_maximization(A_tilde)\n        \n        # Step 4: Calculate Jaccard similarities\n        for i in range(n):\n            c0_i = c0[i]\n            cb_i = cb[i]\n            \n            S_i_c0 = np.where(c0 == c0_i)[0]\n            S_i_cb = np.where(cb == cb_i)[0]\n            \n            intersection = np.intersect1d(S_i_c0, S_i_cb, assume_unique=True)\n            union = np.union1d(S_i_c0, S_i_cb)\n            \n            if union.size == 0:\n                jaccard_scores[b, i] = 1.0\n            else:\n                jaccard_scores[b, i] = intersection.size / union.size\n\n    # Step 5: Calculate reproducibility scores and count consistent modules\n    consistent_module_count = 0\n    ref_modules = {}\n    for i in range(n):\n        comm_id = c0[i]\n        if comm_id not in ref_modules:\n            ref_modules[comm_id] = []\n        ref_modules[comm_id].append(i)\n\n    for comm_id, M_nodes in ref_modules.items():\n        if len(M_nodes)  2:\n            continue\n\n        M_nodes_idx = np.array(M_nodes)\n        \n        sum_jaccard = jaccard_scores[:, M_nodes_idx].sum()\n        R_M = sum_jaccard / (len(M_nodes) * B)\n\n        if R_M >= tau:\n            consistent_module_count += 1\n            \n    return consistent_module_count\n\n\ndef solve():\n    \"\"\"Defines and runs the test cases.\"\"\"\n    test_cases = [\n        # (module_sizes, p_in, p_out, B, tau, s)\n        ([4, 4], 0.9, 0.05, 200, 0.8, 123),\n        ([3, 3, 3], 0.6, 0.4, 300, 0.8, 456),\n        ([6], 0.5, 0.5, 200, 0.8, 789),\n        ([1, 3, 3], 0.85, 0.1, 250, 0.8, 42),\n    ]\n\n    results = []\n    for case in test_cases:\n        module_sizes, p_in, p_out, B, tau, s = case\n        result = evaluate_reproducibility(module_sizes, p_in, p_out, B, tau, s)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}