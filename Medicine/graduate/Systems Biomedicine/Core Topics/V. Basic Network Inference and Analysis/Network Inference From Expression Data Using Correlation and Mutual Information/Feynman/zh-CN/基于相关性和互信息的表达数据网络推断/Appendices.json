{
    "hands_on_practices": [
        {
            "introduction": "网络推断的第一步是量化基因之间的成对关联。本练习将带你从头开始计算皮尔逊相关系数，这是衡量线性关系强度的基本指标，并使用t检验评估其统计显著性。通过这个过程，你不仅能掌握核心计算技能，还将学会批判性地思考支撑这些经典统计检验的假设，例如数据中的异常值和异方差性可能带来的影响 ()。",
            "id": "4365175",
            "problem": "您正在研究共表达关系，以从独立生物样本中测量的稳态信使核糖核酸（mRNA）表达来推断基因网络中的调控相互作用。考虑两个基因，记为 $G_{1}$ 和 $G_{2}$，其在 $n=10$ 个样本中的归一化对数转换表达值由以下给出\n$G_{1}: \\{2.0,\\ 2.5,\\ 3.0,\\ 3.5,\\ 4.0,\\ 4.5,\\ 5.0,\\ 5.5,\\ 6.0,\\ 8.0\\}$ 和 $G_{2}: \\{1.9,\\ 2.6,\\ 2.7,\\ 3.6,\\ 3.9,\\ 4.7,\\ 5.1,\\ 5.4,\\ 6.1,\\ 6.5\\}$。目标是量化 $G_{1}$ 和 $G_{2}$ 之间的线性关联，并在共表达网络推断中常用的假设下评估其统计显著性。\n\n从样本均值、样本协方差和 Pearson 积矩相关系数的定义出发，计算 $G_{1}$ 和 $G_{2}$ 之间的样本 Pearson 相关系数 $r$。然后，从经典线性模型假设出发，即 $(G_{1},G_{2})$ 是联合高斯分布，且样本是独立同分布（i.i.d.）的，并检验零假设 $H_{0}:\\rho=0$。通过将其与 $G_{2}$ 对 $G_{1}$ 的简单线性回归中斜率的普通最小二乘 $t$ 检验联系起来，推导基于相关的检验统计量的零分布。使用此推导计算上述数据的 $t$ 统计量值。\n\n将计算出的 $t$ 统计量四舍五入至四位有效数字。\n\n最后，讨论表达数据中的异方差性（方差随均值变化）和离群值（包括高杠杆点）如何影响这种基于相关的 $t$ 检验的有效性以及下游网络推断；特别是，解释其对假阳性边的影响，并与高斯假设下的互信息推断以及非参数估计器进行对比。\n\n您最终报告的值必须是等于 $t$ 统计量的单个实数，四舍五入至四位有效数字，无单位。",
            "solution": "用户提供了一个问题，要求计算两个变量之间关联性的统计度量，推导相关的检验统计量，并讨论其基本假设。\n\n首先，我将验证问题陈述。\n\n### 第1步：提取已知条件\n-   基因1表达数据 ($G_{1}$): $\\{2.0,\\ 2.5,\\ 3.0,\\ 3.5,\\ 4.0,\\ 4.5,\\ 5.0,\\ 5.5,\\ 6.0,\\ 8.0\\}$\n-   基因2表达数据 ($G_{2}$): $\\{1.9,\\ 2.6,\\ 2.7,\\ 3.6,\\ 3.9,\\ 4.7,\\ 5.1,\\ 5.4,\\ 6.1,\\ 6.5\\}$\n-   样本数 ($n$): $10$\n-   任务1：计算样本 Pearson 相关系数 $r$。\n-   任务2：通过将其与简单线性回归中斜率的普通最小二乘（OLS）$t$ 检验联系起来，推导基于相关的检验统计量的零分布。\n-   任务3：计算 $t$ 统计量的值。\n-   任务4：将 $t$ 统计量四舍五入至四位有效数字。\n-   任务5：讨论异方差性和离群值对检验有效性的影响，并与基于互信息的推断进行比较。\n\n### 第2步：使用提取的已知条件进行验证\n-   **科学依据**：该问题是生物统计学中的一个标准练习，特别是在用于网络推断的基因表达数据分析方面。Pearson 相关、线性回归、$t$ 检验以及这些模型的假设都是基本的统计学原理。讨论点（异方差性、离群值、互信息）是基因组学中稳健统计推断的核心。该问题在科学上是合理的。\n-   **定义明确**：该问题提供了所有必要的数据，并明确指定了所需的计算、推导和讨论主题。计算部分存在唯一的数值答案。\n-   **客观性**：该问题使用精确、客观和标准的科学术语进行陈述。\n\n### 第3步：结论与行动\n问题有效。我将继续提供完整解答。\n\n***\n\n**第1部分：样本 Pearson 相关系数（$r$）的计算**\n\n设基因 $G_{1}$ 的表达值用集合 $\\{x_i\\}$ 表示，基因 $G_{2}$ 的表达值用集合 $\\{y_i\\}$ 表示，其中 $i=1, \\dots, n$，且 $n=10$。\n\n样本 Pearson 相关系数 $r$ 定义为：\n$$r = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 \\sum_{i=1}^{n} (y_i - \\bar{y})^2}} = \\frac{SS_{xy}}{\\sqrt{SS_{xx} SS_{yy}}}$$\n其中 $\\bar{x}$ 和 $\\bar{y}$ 是样本均值，$SS_{xx}$、$SS_{yy}$ 和 $SS_{xy}$ 是平方和与交叉乘积和。\n\n首先，我们计算样本均值：\n$$\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i = \\frac{1}{10}(2.0+2.5+3.0+3.5+4.0+4.5+5.0+5.5+6.0+8.0) = \\frac{44.0}{10} = 4.4$$\n$$\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i = \\frac{1}{10}(1.9+2.6+2.7+3.6+3.9+4.7+5.1+5.4+6.1+6.5) = \\frac{42.5}{10} = 4.25$$\n\n接下来，我们计算平方和与交叉乘积和：\n$$SS_{xx} = \\sum_{i=1}^{n} (x_i - \\bar{x})^2 = (2.0-4.4)^2 + (2.5-4.4)^2 + \\dots + (8.0-4.4)^2$$\n$$SS_{xx} = (-2.4)^2 + (-1.9)^2 + (-1.4)^2 + (-0.9)^2 + (-0.4)^2 + (0.1)^2 + (0.6)^2 + (1.1)^2 + (1.6)^2 + (3.6)^2$$\n$$SS_{xx} = 5.76 + 3.61 + 1.96 + 0.81 + 0.16 + 0.01 + 0.36 + 1.21 + 2.56 + 12.96 = 29.4$$\n\n$$SS_{yy} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2 = (1.9-4.25)^2 + (2.6-4.25)^2 + \\dots + (6.5-4.25)^2$$\n$$SS_{yy} = (-2.35)^2 + (-1.65)^2 + (-1.55)^2 + (-0.65)^2 + (-0.35)^2 + (0.45)^2 + (0.85)^2 + (1.15)^2 + (1.85)^2 + (2.25)^2$$\n$$SS_{yy} = 5.5225 + 2.7225 + 2.4025 + 0.4225 + 0.1225 + 0.2025 + 0.7225 + 1.3225 + 3.4225 + 5.0625 = 21.925$$\n\n$$SS_{xy} = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y}) = (2.0-4.4)(1.9-4.25) + \\dots + (8.0-4.4)(6.5-4.25)$$\n$$SS_{xy} = (-2.4)(-2.35) + (-1.9)(-1.65) + (-1.4)(-1.55) + (-0.9)(-0.65) + (-0.4)(-0.35) + (0.1)(0.45) + (0.6)(0.85) + (1.1)(1.15) + (1.6)(1.85) + (3.6)(2.25)$$\n$$SS_{xy} = 5.64 + 3.135 + 2.17 + 0.585 + 0.14 + 0.045 + 0.51 + 1.265 + 2.96 + 8.1 = 24.55$$\n\n最后，我们计算 $r$：\n$$r = \\frac{24.55}{\\sqrt{29.4 \\times 21.925}} = \\frac{24.55}{\\sqrt{644.595}} \\approx 0.96696025$$\n\n**第2部分：相关性检验统计量的零分布推导**\n\n我们的目标是检验零假设 $H_0: \\rho = 0$，其中 $\\rho$ 是总体相关系数。这等价于在简单线性回归模型 $Y = \\beta_0 + \\beta_1 X + \\epsilon$ 中检验斜率的零假设 $H_0: \\beta_1 = 0$，其中我们将 $G_2$（作为 $Y$）对 $G_1$（作为 $X$）进行回归。\n\nOLS 斜率估计值 $b_1$ 的检验统计量由下式给出：\n$$t = \\frac{b_1 - \\beta_1}{SE(b_1)}$$\n在 $H_0: \\beta_1 = 0$ 的条件下，这简化为 $t = \\frac{b_1}{SE(b_1)}$。已知在模型假设（线性、独立性、同方差性、误差正态性）成立的情况下，该统计量服从自由度为 $n-2$ 的 Student's $t$ 分布。\n\n斜率的 OLS 估计值为 $b_1 = \\frac{SS_{xy}}{SS_{xx}}$。\n斜率估计值的标准误为 $SE(b_1) = \\frac{\\hat{\\sigma}}{\\sqrt{SS_{xx}}}$，其中 $\\hat{\\sigma}^2$ 是均方误差（MSE），是误差方差 $\\sigma^2_ \\epsilon$ 的无偏估计量。\nMSE 计算为 $MSE = \\frac{SSE}{n-2}$，其中 $SSE$ 是误差平方和（残差平方和）。\nSSE 可以用平方和表示：$SSE = SS_{yy} - \\frac{(SS_{xy})^2}{SS_{xx}}$。\n\n现在，我们用 $r$ 来重写 $t$ 统计量。首先，认识到 $r$ 和 $b_1$ 之间的关系：\n$$r = \\frac{SS_{xy}}{\\sqrt{SS_{xx} SS_{yy}}} \\implies b_1 = \\frac{SS_{xy}}{SS_{xx}} = \\frac{r \\sqrt{SS_{xx} SS_{yy}}}{SS_{xx}} = r \\sqrt{\\frac{SS_{yy}}{SS_{xx}}}$$\n\n接下来，我们用 $r$ 来表示 $SSE$：\n$$SSE = SS_{yy} - \\frac{(r \\sqrt{SS_{xx} SS_{yy}})^2}{SS_{xx}} = SS_{yy} - \\frac{r^2 SS_{xx} SS_{yy}}{SS_{xx}} = SS_{yy} (1 - r^2)$$\n\n现在将这些表达式代回 $t$ 统计量的公式中：\n$$t = \\frac{b_1}{SE(b_1)} = \\frac{b_1}{\\sqrt{\\frac{SSE}{n-2}} / \\sqrt{SS_{xx}}} = \\frac{b_1 \\sqrt{SS_{xx}}}{\\sqrt{\\frac{SS_{yy}(1 - r^2)}{n-2}}}$$\n\n代入 $b_1$ 的表达式：\n$$t = \\frac{\\left(r \\sqrt{\\frac{SS_{yy}}{SS_{xx}}}\\right) \\sqrt{SS_{xx}}}{\\sqrt{\\frac{SS_{yy}(1 - r^2)}{n-2}}} = \\frac{r \\sqrt{SS_{yy}}}{\\frac{\\sqrt{SS_{yy}} \\sqrt{1 - r^2}}{\\sqrt{n-2}}}$$\n$$t = \\frac{r \\sqrt{n-2}}{\\sqrt{1 - r^2}}$$\n这就是所求的检验统计量。在零假设 $H_0: \\rho = 0$ 下，该统计量服从自由度为 $n-2$ 的 Student's $t$ 分布。这就是零分布。\n\n**第3部分：t-统计量的计算**\n\n使用第1部分计算的值：\n$n = 10$\n$r \\approx 0.96696025$\n\n$$t = \\frac{0.96696025 \\sqrt{10-2}}{\\sqrt{1 - (0.96696025)^2}} = \\frac{0.96696025 \\sqrt{8}}{\\sqrt{1 - 0.93501192}} = \\frac{0.96696025 \\times 2.828427}{\\sqrt{0.06498808}} \\approx \\frac{2.73500}{0.2549178} \\approx 10.7290$$\n将结果四舍五入到四位有效数字，我们得到 $10.73$。\n\n**第4部分：关于模型有效性和比较的讨论**\n\n相关性 $t$ 检验的有效性，以及由此延伸的基于它的共表达网络推断，关键取决于基础线性模型的假设。两个主要的违规情况是异方差性和离群值的存在。\n\n**异方差性**：这是指残差的方差在预测变量的一系列值上不是恒定的情况。在基因表达数据中，平均表达水平较高的基因通常也表现出较高的方差。OLS 过程假定同方差性（恒定方差）。当这个假设被违反时，斜率的 OLS 估计量（$b_1$）仍然是无偏的，但其标准误（$SE(b_1)$）的公式是不正确的，并且通常是有偏的。这种偏差导致计算出的 $t$ 统计量不正确，它在零假设下不再服从 $t$ 分布。其后果是 p 值无效，并且通常会夸大第一类错误率。对于网络推断，这意味着**假阳性边**数量的增加，即由于有缺陷的统计检验而不是潜在的生物学关联而宣称存在显著相关性。\n\n**离群值和高杠杆点**：离群值是明显偏离其他观测值的数据点。高杠杆点是具有极端预测变量值的观测值（例如，本问题中的点 $(x_{10}, y_{10}) = (8.0, 6.5)$，其中 $x_{10}=8.0$ 远离 $\\bar{x}=4.4$）。既是离群值又具有高杠杆的点是影响点。Pearson 相关系数对这类点非常敏感。单个影响点可以在大部分数据不存在相关性的情况下制造出强烈的、统计上显著的相关性，或者它可以掩盖一个真实的潜在相关性。这会导致**假阳性**（由于伪影推断出边）和**假阴性**（未能推断出真实的边）。推断出的网络连接变得高度依赖于单个、可能是错误的数据点，而不是整体的生物学趋势。\n\n**与互信息（MI）的对比**：\n\n1.  **高斯假设下的互信息（MI）**：如果数据 $(G_1, G_2)$ 确实来自二元高斯分布，那么互信息 $I(G_1, G_2)$ 是 Pearson 相关系数平方 $\\rho^2$ 的单调函数：$I(G_1, G_2) = -\\frac{1}{2} \\ln(1 - \\rho^2)$。在这种特定的、理想化的情况下，检验 $I=0$ 与检验 $\\rho=0$ 是完全等价的。使用 MI 相对于相关性没有优势，因为它们衡量的是相同的潜在线性关联。\n\n2.  **使用非参数估计器的互信息（MI）**：MI 的真正优势在于与不假设高斯（或任何其他）分布的非参数估计器（例如，k-最近邻或核密度估计器）一起使用时才能实现。\n    -   **捕获非线性关系**：MI 量化任何统计依赖关系，而不仅仅是线性关系。对于开关样或S型的调控关系，Pearson 相关系数可能接近于零，导致假阴性。MI 可以检测到这种非线性关联。\n    -   **稳健性**：非参数 MI 通常比 Pearson 相关对某些类型的离群值更稳健。因为它基于概率密度（通常从秩或局部密度估计），所以它受极端值大小的扭曲较小。它可以减轻由影响点驱动的、困扰基于相关性方法的假阳性和假阴性。\n    -   **缺点**：非参数 MI 的主要挑战是从有限数据中进行估计。它容易出现系统性估计偏差，尤其是在样本量较小的情况下（$n=10$ 对于此目的来说非常小），并且其方差可能很高。准确的 MI 估计是数据密集型的，如果处理不当，其本身就可能导致错误的推断。\n\n总之，对于网络推断，一个显著的基于相关的 $t$ 检验仅在严格的假设下才是线性关联的可靠指标。像异方差性和离群值这样的违规情况在真实数据中很常见，可能导致虚假的网络边。非参数 MI 为检测依赖关系提供了一种更稳健、更通用的替代方案，但其实际应用需要更大的样本量和谨慎的实施，以避免其自身的估计陷阱。",
            "answer": "$$\n\\boxed{10.73}\n$$"
        },
        {
            "introduction": "构建一个有意义的网络需要区分直接连接和间接连接。本练习将指导你使用条件互信息 (CMI) 这一关键概念来解决基因网络推断中的“中介效应”问题。你将学习如何通过计算条件互信息并结合置换检验来判断两个基因之间的关联是否由第三个基因介导，从而学会从复杂的关联网络中“剪枝”，保留更可能代表直接调控关系的边 ()。",
            "id": "4365154",
            "problem": "给定四个在零均值三元高斯模型下生成的合成基因表达三元组 $(X,Y,Z)$，其相关矩阵是指定的。任务是，当考虑一个潜在中介基因 $Z$ 时，推断基因调控网络中基因 $(X,Y)$ 之间的无向边是否应被保留。该决策依赖于检验在以 $Z$ 为条件后，$X$ 和 $Y$ 之间的互信息 (Mutual Information, MI) 是否显著减少，此过程使用基于置换的显著性评估。\n\n从连续随机变量的微分熵和互信息 (MI) 的基本定义出发，假设使用以下建模和估计框架：\n\n- $(X,Y,Z)$ 的联合分布是三元正态分布，其协方差矩阵 $\\boldsymbol{\\Sigma}$ 未知。\n- 使用基于样本的协方差最大似然估计来计算：\n  1. 在高斯模型下，根据 $X$ 和 $Y$ 之间估计的皮尔逊相关性，计算互信息 (MI) $I(X;Y)$。\n  2. 在高斯模型下，根据在控制了 $Z$ 之后 $X$ 和 $Y$ 之间估计的偏相关性，计算条件互信息 (Conditional Mutual Information, CMI) $I(X;Y \\mid Z)$。\n- 实现一个用于中介分析的非参数置换检验：通过在观测样本中随机置换 $Z$ 的样本，为每次置换重新计算 $I(X;Y \\mid Z^{\\pi})$ 和 $\\Delta^{\\pi}$（其中 $Z^{\\pi}$ 表示一个置换后的中介变量），从而构建减少量 $\\Delta = I(X;Y) - I(X;Y \\mid Z)$ 的经验零分布。将满足 $\\Delta^{\\pi} \\ge \\Delta$ 的置换次数所占的比例估计为经验 $p$ 值。如果 $p$ 值严格小于显著性水平 $\\alpha$，则判定该减少量是显著的，应移除边 $(X,Y)$；否则，保留该边。\n\n你的程序必须实现上述逻辑，并将其应用于以下测试套件。对于每个测试用例，从 $\\mathcal{N}(\\boldsymbol{0}, \\mathbf{R})$ 生成 $n$ 个独立样本，其中 $\\mathbf{R}$ 是一个对角线上方差为单位1的相关矩阵。使用指定的置换次数 $B$ 和显著性水平 $\\alpha$。为保证可复现性，请使用固定的随机种子。\n\n测试套件 (每个 $\\mathbf{R}$ 都表示为相关矩阵):\n1. 案例 A (条件化后直接关联仍然存在):\n   $$\n   n = 500,\\quad\n   \\mathbf{R} =\n   \\begin{bmatrix}\n   1  0.8  0.2 \\\\\n   0.8  1  0.2 \\\\\n   0.2  0.2  1\n   \\end{bmatrix},\\quad\n   B = 300,\\quad\n   \\alpha = 0.05.\n   $$\n2. 案例 B ($Z$ 完全中介了相关性):\n   $$\n   n = 500,\\quad\n   \\mathbf{R} =\n   \\begin{bmatrix}\n   1  0.49  0.7 \\\\\n   0.49  1  0.7 \\\\\n   0.7  0.7  1\n   \\end{bmatrix},\\quad\n   B = 300,\\quad\n   \\alpha = 0.05.\n   $$\n3. 案例 C (接近边界的部分中介):\n   $$\n   n = 300,\\quad\n   \\mathbf{R} =\n   \\begin{bmatrix}\n   1  0.3  0.4 \\\\\n   0.3  1  0.4 \\\\\n   0.4  0.4  1\n   \\end{bmatrix},\\quad\n   B = 300,\\quad\n   \\alpha = 0.05.\n   $$\n4. 案例 D (小样本，弱中介):\n   $$\n   n = 60,\\quad\n   \\mathbf{R} =\n   \\begin{bmatrix}\n   1  0.3  0.05 \\\\\n   0.3  1  0.05 \\\\\n   0.05  0.05  1\n   \\end{bmatrix},\\quad\n   B = 200,\\quad\n   \\alpha = 0.05.\n   $$\n\n算法要求:\n- 对于每个案例，从模拟数据中估计样本协方差 $\\boldsymbol{\\hat{\\Sigma}}$，并计算 $X$ 和 $Y$ 之间的皮尔逊相关性。\n- 通过精度矩阵 $\\mathbf{P} = \\boldsymbol{\\hat{\\Sigma}}^{-1}$ 计算在给定 $Z$ 的条件下 $X$ 和 $Y$ 之间的偏相关性。\n- 在高斯模型下，分别从相关性和偏相关性计算 $I(X;Y)$ 和 $I(X;Y \\mid Z)$。\n- 执行包含 $B$ 次置换的置换检验，计算 MI 减少量的经验 $p$ 值，并决定边的保留：如果边 $(X,Y)$ 被保留，则返回 $\\,\\text{True}\\,$，如果被移除，则返回 $\\,\\text{False}\\,$。\n- 使用固定的随机种子以确保每次运行结果的可复现性。\n\n你的程序应生成单行输出，其中包含案例 A–D 的四个布尔决策，形式为方括号内以逗号分隔的列表，例如 $[\\,\\text{True},\\text{False},\\text{True},\\text{False}\\,]$。不涉及物理单位或角度，所有输出均为布尔值。",
            "solution": "该问题要求实现一个统计流程，以决定在调控网络中是否保留或移除两个基因 $X$ 和 $Y$ 之间的边，其依据是第三个基因 $Z$ 的潜在中介效应。该框架基于三元高斯模型下的互信息，并通过置换检验来评估显著性。\n\n### 1. 理论基础：高斯变量的互信息\n\n此分析的基础是信息论。对于一个服从多元正态分布 $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$ 的连续 $d$ 维随机变量 $\\mathbf{X}$，其微分熵 $h(\\mathbf{X})$ 由以下公式给出：\n$$\nh(\\mathbf{X}) = \\frac{1}{2} \\ln \\left( (2\\pi e)^d \\det(\\boldsymbol{\\Sigma}) \\right)\n$$\n互信息 (MI) 量化了两个变量之间的统计依赖性。对于变量 $X$ 和 $Y$，其定义为 $I(X;Y) = h(X) + h(Y) - h(X,Y)$。假设 $(X,Y)$ 联合服从高斯分布，其方差为 $\\sigma_X^2=1$、$\\sigma_Y^2=1$，皮尔逊相关性为 $\\rho_{XY}$，则互信息可以简化为相关性的直接函数：\n$$\nI(X;Y) = -\\frac{1}{2} \\ln(1 - \\rho_{XY}^2)\n$$\n该公式表明，随着相关性的大小 $|\\rho_{XY}|$ 接近 $1$，互信息随之增加。\n\n### 2. 条件互信息与中介效应\n\n条件互信息 (CMI)，即 $I(X;Y \\mid Z)$，衡量在已知 $Z$ 的情况下 $X$ 和 $Y$ 之间的依赖关系。对于高斯变量，一个重要的结论将 CMI 与偏相关性 $\\rho_{XY \\mid Z}$ 联系起来，偏相关性是在回归消除 $Z$ 的线性效应后 $X$ 和 $Y$ 之间的相关性。其计算公式与 MI 的公式类似：\n$$\nI(X;Y \\mid Z) = -\\frac{1}{2} \\ln(1 - \\rho_{XY \\mid Z}^2)\n$$\n如果 $Z$ 完全中介了 $X$ 和 $Y$ 之间的关系，那么在给定 $Z$ 的条件下，$X$ 和 $Y$ 是条件独立的，这意味着 $\\rho_{XY \\mid Z} = 0$，因此 $I(X;Y \\mid Z) = 0$。这为识别中介效应提供了一个明确的标准：在以中介变量 $Z$ 为条件后，互信息出现显著下降。\n\n### 3. 从样本数据中进行估计\n\n在实际应用中，真实的协方差矩阵 $\\mathbf{R}$ 是未知的，必须从 $(X,Y,Z)$ 的 $n$ 个样本中进行估计。设 $n \\times 3$ 的数据矩阵为 $\\mathbf{D}$。\n\n-   **样本协方差和相关性**：协方差矩阵的最大似然估计 (MLE) 是 $\\boldsymbol{\\hat{\\Sigma}} = \\frac{1}{n} (\\mathbf{D}-\\bar{\\mathbf{D}})^T(\\mathbf{D}-\\bar{\\mathbf{D}})$，其中 $\\bar{\\mathbf{D}}$ 包含样本均值。样本皮尔逊相关性 $\\hat{\\rho}_{XY}$ 从 $\\boldsymbol{\\hat{\\Sigma}}$ 的元素中计算得出。然后我们计算估计的 MI：$\\hat{I}(X;Y) = -\\frac{1}{2}\\ln(1-\\hat{\\rho}_{XY}^2)$。\n\n-   **样本偏相关性**：偏相关性 $\\hat{\\rho}_{XY \\mid Z}$ 使用样本精度矩阵 $\\mathbf{P} = \\boldsymbol{\\hat{\\Sigma}}^{-1}$ 进行估计。公式为：\n    $$\n    \\hat{\\rho}_{XY \\mid Z} = -\\frac{p_{12}}{\\sqrt{p_{11} p_{22}}}\n    $$\n    其中 $p_{ij}$ 是 $\\mathbf{P}$ 的元素。然后，估计的 CMI 为 $\\hat{I}(X;Y \\mid Z) = -\\frac{1}{2}\\ln(1-\\hat{\\rho}_{XY \\mid Z}^2)$。\n\n### 4. 用于显著性检验的置换检验\n\n核心假设是观测到的 MI 减少量 $\\hat{\\Delta} = \\hat{I}(X;Y) - \\hat{I}(X;Y \\mid Z)$ 是否具有统计显著性。我们采用置换检验来为该减少量生成一个经验零分布。零假设 $H_0$ 是 $Z$ 与 $(X,Y)$ 对独立，因此不是一个中介变量。\n\n流程如下：\n1.  从 $\\mathcal{N}(\\boldsymbol{0}, \\mathbf{R})$ 生成 $n$ 个样本，并计算观测到的统计量 $\\hat{I}(X;Y)$、$\\hat{I}(X;Y \\mid Z)$ 以及观测到的减少量 $\\hat{\\Delta}$。\n2.  执行 $B$ 次置换。在每次置换 $b \\in \\{1, \\dots, B\\}$ 中：\n    a. 创建一个打乱后的数据集 $(X, Y, Z^{\\pi_b})$，其中 $Z^{\\pi_b}$ 是原始 $Z$ 数据向量的一个随机置换。这个过程打破了每个 $z_i$ 与其对应的 $(x_i, y_i)$ 对之间的特定关联，从而模拟了零假设。\n    b. 为置换后的数据计算 CMI，即 $\\hat{I}_b(X;Y \\mid Z^{\\pi_b})$。\n    c. 计算本次置换的 MI 减少量：$\\hat{\\Delta}^{\\pi_b} = \\hat{I}(X;Y) - \\hat{I}_b(X;Y \\mid Z^{\\pi_b})$。请注意，$\\hat{I}(X;Y)$ 是来自原始数据的值，在整个置换过程中保持不变。\n3.  值集合 $\\{\\hat{\\Delta}^{\\pi_b}\\}$ 构成了经验零分布。\n4.  经验 $p$ 值是在置换中，减少量至少与观测到的减少量一样大的次数所占的比例：\n    $$\n    p = \\frac{|\\{b \\mid \\hat{\\Delta}^{\\pi_b} \\ge \\hat{\\Delta}\\}|}{B}\n    $$\n5.  最后，应用决策规则：如果 $p$ 值严格小于显著性水平 $\\alpha$（即 $p < \\alpha$），则拒绝零假设。这表明存在显著的中介效应，应移除边 $(X,Y)$（返回 `False`）。否则，对于 $p \\ge \\alpha$ 的情况，中介效应的证据不足，应保留该边（返回 `True`）。\n\n这个完整的算法将为所提供的 4 个测试用例中的每一个实现，并使用固定的随机种子来确保结果的可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the network inference test for all specified cases.\n    \"\"\"\n    \n    # Fixed random seed for reproducibility as required by the problem.\n    seed = 42\n    rng = np.random.default_rng(seed)\n\n    # Test suite from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"n\": 500,\n            \"R\": np.array([[1.0, 0.8, 0.2], [0.8, 1.0, 0.2], [0.2, 0.2, 1.0]]),\n            \"B\": 300,\n            \"alpha\": 0.05,\n        },\n        {\n            \"name\": \"Case B\",\n            \"n\": 500,\n            \"R\": np.array([[1.0, 0.49, 0.7], [0.49, 1.0, 0.7], [0.7, 0.7, 1.0]]),\n            \"B\": 300,\n            \"alpha\": 0.05,\n        },\n        {\n            \"name\": \"Case C\",\n            \"n\": 300,\n            \"R\": np.array([[1.0, 0.3, 0.4], [0.3, 1.0, 0.4], [0.4, 0.4, 1.0]]),\n            \"B\": 300,\n            \"alpha\": 0.05,\n        },\n        {\n            \"name\": \"Case D\",\n            \"n\": 60,\n            \"R\": np.array([[1.0, 0.3, 0.05], [0.3, 1.0, 0.05], [0.05, 0.05, 1.0]]),\n            \"B\": 200,\n            \"alpha\": 0.05,\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        decision = perform_mediation_test(\n            n=case[\"n\"],\n            R=case[\"R\"],\n            B=case[\"B\"],\n            alpha=case[\"alpha\"],\n            rng=rng\n        )\n        results.append(decision)\n\n    # Print the final result in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef compute_mi_from_corr(rho):\n    \"\"\"Computes mutual information from correlation for Gaussian variables.\"\"\"\n    # Clamp rho**2 to avoid domain errors with log due to floating point inaccuracies.\n    rho2 = np.clip(rho * rho, 0.0, 1.0 - 1e-15)\n    return -0.5 * np.log(1.0 - rho2)\n\n\ndef get_mi_cmi_stats(data_x, data_y, data_z):\n    \"\"\"\n    Computes MI(X;Y) and CMI(X;Y|Z) from sample data.\n    \"\"\"\n    data = np.column_stack((data_x, data_y, data_z))\n    \n    # Compute the sample covariance matrix (MLE, ddof=0).\n    try:\n        cov_matrix = np.cov(data, rowvar=False, ddof=0)\n    except Exception: # Fails if data is constant\n        return 0.0, 0.0\n\n    # ----- MI(X;Y) from Pearson correlation -----\n    var_x, var_y = cov_matrix[0, 0], cov_matrix[1, 1]\n    if var_x < 1e-15 or var_y < 1e-15:\n        mi_xy = 0.0\n    else:\n        rho_xy = cov_matrix[0, 1] / np.sqrt(var_x * var_y)\n        mi_xy = compute_mi_from_corr(rho_xy)\n\n    # ----- CMI(X;Y|Z) from partial correlation -----\n    try:\n        # Precision matrix is the inverse of the covariance matrix.\n        prec_matrix = np.linalg.inv(cov_matrix)\n    except np.linalg.LinAlgError:\n        # If matrix is singular, CMI is ill-defined. Treat as maximal dependence.\n        # This implies huge reduction, but since it's a numeric error,\n        # we return a value that will cause retention of the edge.\n        return mi_xy, np.inf\n\n    p11, p22, p12 = prec_matrix[0, 0], prec_matrix[1, 1], prec_matrix[0, 1]\n    if p11 < 1e-15 or p22 < 1e-15:\n        cmi_xy_z = 0.0\n    else:\n        rho_xy_z = -p12 / np.sqrt(p11 * p22)\n        cmi_xy_z = compute_mi_from_corr(rho_xy_z)\n\n    return mi_xy, cmi_xy_z\n\n\ndef perform_mediation_test(n, R, B, alpha, rng):\n    \"\"\"\n    Performs the full permutation test for a single case.\n    Returns True to retain the edge, False to remove.\n    \"\"\"\n    # 1. Generate data from the specified trivariate Gaussian model.\n    mean = np.zeros(3)\n    data = rng.multivariate_normal(mean, R, size=n)\n    X, Y, Z = data[:, 0], data[:, 1], data[:, 2]\n\n    # 2. Calculate the observed MI reduction.\n    mi_obs, cmi_obs = get_mi_cmi_stats(X, Y, Z)\n\n    # If CMI is infinite due to singularity, the reduction is undefined/negative.\n    # This leads to retaining the edge, which is a safe choice.\n    if np.isinf(cmi_obs):\n        return True\n    \n    delta_obs = mi_obs - cmi_obs\n\n    # 3. Perform permutation test to build the null distribution of the MI reduction.\n    permuted_deltas_ge_observed = 0\n    Z_perm = Z.copy() # Create a copy to shuffle in-place\n    for _ in range(B):\n        rng.shuffle(Z_perm)\n        # For permuted data, we only need CMI. MI(X;Y) is invariant.\n        _, cmi_perm = get_mi_cmi_stats(X, Y, Z_perm)\n\n        # Handle numerical issues in permuted data\n        if np.isinf(cmi_perm):\n            delta_perm = -np.inf # Effectively ensures delta_perm < delta_obs\n        else:\n            delta_perm = mi_obs - cmi_perm\n        \n        if delta_perm >= delta_obs:\n            permuted_deltas_ge_observed += 1\n\n    # 4. Calculate the empirical p-value.\n    p_value = permuted_deltas_ge_observed / B\n\n    # 5. Make the decision: retain if p >= alpha, remove if p < alpha.\n    return p_value >= alpha\n\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}