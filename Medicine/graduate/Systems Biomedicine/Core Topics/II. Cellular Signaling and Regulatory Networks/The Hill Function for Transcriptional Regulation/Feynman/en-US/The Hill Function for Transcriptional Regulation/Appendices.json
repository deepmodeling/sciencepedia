{
    "hands_on_practices": [
        {
            "introduction": "The Hill function is a cornerstone of quantitative biology, but it is not merely a convenient mathematical form. Its sigmoidal shape arises directly from the fundamental principles of statistical mechanics applied to cooperative molecular binding. This first exercise guides you through this foundational derivation, starting from the statistical weights of a promoter's states and arriving at the canonical Hill equation. By then exploring the behavior in the limit of high cooperativity, you will gain a deep, first-principles understanding of how sharp, switch-like responses in gene expression are generated. ",
            "id": "4393060",
            "problem": "A transcriptional activator $X$ regulates a promoter by binding in a concerted manner: the promoter switches to an active state only when $n$ molecules of $X$ are simultaneously bound. Assume rapid equilibrium, negligible promoter depletion by bound activator (the total activator concentration is approximately equal to the free concentration), and identical, indistinguishable binding sites on the promoter. The inactive promoter state has statistical weight $1$, and the active state has statistical weight proportional to $[X]^{n}$, where $[X]$ denotes the activator concentration. Let the proportionality constant (an equilibrium association parameter) be denoted by $\\kappa$ with units $\\text{(concentration)}^{-n}$.\n\nStarting from the law of mass action and equilibrium statistical mechanics of binding, derive the normalized promoter activity $A_{n}([X])$, defined as the probability that the promoter is in the active state, expressed in terms of $[X]$, $n$, and an effective concentration scale $K$ that you define in terms of $\\kappa$. Then, to characterize the edge behavior of the activation threshold in the highly cooperative limit, define the scaled variable $z = n \\ln\\!\\left(\\frac{[X]}{K}\\right)$ and evaluate the limiting scaled activity\n$$\ng(z) = \\lim_{n \\to \\infty} A_{n}\\!\\big(K \\exp(z/n)\\big).\n$$\nExpress your final answer for $g(z)$ as a single closed-form analytic expression with no units. No numerical evaluation or rounding is required.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It describes a standard model of cooperative transcriptional activation based on equilibrium statistical mechanics. The derivation is a textbook exercise in systems biology.\n\nThe problem asks for two main results: first, the derivation of the normalized promoter activity $A_n([X])$ as a function of the activator concentration $[X]$, the cooperativity parameter $n$, and an effective concentration scale $K$; and second, the evaluation of the limiting scaled activity $g(z)$ in the limit of high cooperativity ($n \\to \\infty$).\n\nFirst, we derive the expression for the normalized promoter activity $A_n([X])$. The system consists of a single promoter which can exist in one of two states: an inactive state (unbound or partially bound, which are all considered inactive for this concerted model) and an active state (with $n$ molecules of activator $X$ simultaneously bound).\n\nAccording to the principles of equilibrium statistical mechanics, the probability of finding the system in a particular state is proportional to its statistical weight. The problem provides the statistical weights for the two states:\n1.  The inactive promoter state: statistical weight $W_{\\text{inactive}} = 1$.\n2.  The active promoter state, where $n$ molecules of activator $X$ are bound: statistical weight $W_{\\text{active}} = \\kappa [X]^n$, where $[X]$ is the activator concentration and $\\kappa$ is an equilibrium association parameter.\n\nThe partition function, $Z$, is the sum of the statistical weights of all possible states of the system.\n$$\nZ = W_{\\text{inactive}} + W_{\\text{active}} = 1 + \\kappa [X]^n\n$$\n\nThe normalized promoter activity, $A_n([X])$, is defined as the probability that the promoter is in the active state. This probability is given by the ratio of the statistical weight of the active state to the total partition function.\n$$\nA_n([X]) = \\frac{W_{\\text{active}}}{Z} = \\frac{\\kappa [X]^n}{1 + \\kappa [X]^n}\n$$\n\nTo express this activity in terms of an effective concentration scale $K$, we rearrange the equation into the canonical form of the Hill function. By dividing the numerator and the denominator by $\\kappa$, we obtain:\n$$\nA_n([X]) = \\frac{[X]^n}{\\frac{1}{\\kappa} + [X]^n}\n$$\n\nWe can now define an effective concentration scale $K$ such that its $n$-th power corresponds to the term $1/\\kappa$. Let $K^n = 1/\\kappa$. This definition implies $K = \\kappa^{-1/n}$. The units of $\\kappa$ are given as $(\\text{concentration})^{-n}$, so the units of $K$ are $((\\text{concentration})^{-n})^{-1/n} = \\text{concentration}$. $K$ represents the concentration of activator $[X]$ at which the promoter activity is half-maximal, as $A_n(K) = K^n / (K^n + K^n) = 1/2$.\n\nSubstituting $K^n$ into the expression for $A_n([X])$, we arrive at the standard Hill equation:\n$$\nA_n([X]) = \\frac{[X]^n}{K^n + [X]^n}\n$$\nThis can also be written as:\n$$\nA_n([X]) = \\frac{\\left(\\frac{[X]}{K}\\right)^n}{1 + \\left(\\frac{[X]}{K}\\right)^n}\n$$\n\nNext, we evaluate the limiting scaled activity $g(z)$ for $n \\to \\infty$. The problem defines a scaled variable $z = n \\ln\\left(\\frac{[X]}{K}\\right)$, which focuses on the transition region around $[X]=K$. From this definition, we can express the ratio $[X]/K$ in terms of $z$ and $n$:\n$$\n\\frac{z}{n} = \\ln\\left(\\frac{[X]}{K}\\right) \\implies \\frac{[X]}{K} = \\exp\\left(\\frac{z}{n}\\right)\n$$\nThis means that the concentration $[X]$ is being set to $K \\exp(z/n)$. The function to be evaluated in the limit is thus $A_n([X])$ with this specific substitution for $[X]$.\n\nWe substitute $[X]/K = \\exp(z/n)$ into our expression for $A_n([X])$:\n$$\nA_n\\big(K \\exp(z/n)\\big) = \\frac{\\left(\\exp\\left(\\frac{z}{n}\\right)\\right)^n}{1 + \\left(\\exp\\left(\\frac{z}{n}\\right)\\right)^n}\n$$\nSimplifying the exponential term in the numerator and denominator gives:\n$$\n\\left(\\exp\\left(\\frac{z}{n}\\right)\\right)^n = \\exp\\left(\\frac{z}{n} \\times n\\right) = \\exp(z)\n$$\nSubstituting this back into the expression for the activity, we get:\n$$\nA_n\\big(K \\exp(z/n)\\big) = \\frac{\\exp(z)}{1 + \\exp(z)}\n$$\nNow we can compute the desired limit, which is the limiting scaled activity $g(z)$:\n$$\ng(z) = \\lim_{n \\to \\infty} A_{n}\\!\\big(K \\exp(z/n)\\big) = \\lim_{n \\to \\infty} \\left( \\frac{\\exp(z)}{1 + \\exp(z)} \\right)\n$$\nThe expression $\\frac{\\exp(z)}{1 + \\exp(z)}$ does not contain the variable $n$. Therefore, the limit as $n \\to \\infty$ is simply the expression itself.\n$$\ng(z) = \\frac{\\exp(z)}{1 + \\exp(z)}\n$$\nThis function, known as the logistic function, describes the \"soft\" step-function shape of the activation profile in the highly cooperative limit, when viewed through the lens of the scaled variable $z$.\nThis is the final closed-form analytic expression for $g(z)$.",
            "answer": "$$\n\\boxed{\\frac{\\exp(z)}{1 + \\exp(z)}}\n$$"
        },
        {
            "introduction": "Understanding the probability of a promoter's activity is only the first step; a cell's state is ultimately defined by the abundance of molecules, which changes over time. This practice bridges the gap between the static, equilibrium model of promoter binding and the dynamic reality of gene expression. You will build a model that combines the Hill function for transcription initiation with first-order kinetics for messenger ribonucleic acid (mRNA) degradation. Solving the resulting differential equation will allow you to predict the full time-course of a gene's response to a constant stimulus, a fundamental skill for modeling any dynamic biological process. ",
            "id": "4393067",
            "problem": "A single gene in a mammalian cell nucleus is regulated by an activator transcription factor (TF). The promoter has $n$ identical binding sites that behave in an all-or-none cooperative manner: the promoter is transcriptionally active if and only if all $n$ sites are occupied by TF. Assume that transcription factor binding and unbinding to the promoter reach thermodynamic equilibrium on a timescale that is fast compared to messenger ribonucleic acid (mRNA) synthesis and degradation. The gene produces mRNA with a synthesis rate proportional to the probability that the promoter is in the active state, and mRNA is degraded by first-order kinetics. Starting from core physical chemistry and biochemistry principles—mass-action binding equilibrium for the promoter–TF interaction, the law of detailed balance, and the central dogma (Deoxyribonucleic Acid (DNA) is transcribed to mRNA)—derive the closed-form expression for the mRNA time course $x(t)$ when the TF concentration is clamped to a constant value $\\bar{T}$ at time $t=0$ and the initial mRNA is $x(0)=0$.\n\nAssume the following:\n- The dissociation constant for a single TF binding site is $K$.\n- Cooperative binding is effectively all-or-none: the active promoter state requires simultaneous occupation by $n$ TF molecules.\n- The mRNA synthesis rate constant is $k_{\\mathrm{tr}}$ (in molecules per cell per unit time), proportional to the probability the promoter is active.\n- The mRNA degradation rate constant is $\\gamma$ (in per unit time).\n- The TF concentration $\\bar{T}$ and dissociation constant $K$ are expressed in the same concentration units.\n- Express the final mRNA concentration function $x(t)$ in molecules per cell.\n\nYour answer must be a single closed-form analytic expression for $x(t)$ in terms of $k_{\\mathrm{tr}}$, $\\gamma$, $\\bar{T}$, $K$, $n$, and $t$. Do not present an inequality, equation to be solved, or a numerical value. No rounding is required.",
            "solution": "The problem requires the derivation of the time course of messenger ribonucleic acid (mRNA) concentration, denoted by $x(t)$, for a gene regulated by an activator transcription factor (TF). The derivation must be based on first principles of biochemistry and physical chemistry.\n\nFirst, we model the state of the gene's promoter. The problem states that the promoter has $n$ identical binding sites for the TF and that binding is an \"all-or-none cooperative manner\". This means we can model the promoter as existing in only two states: a free, inactive state ($P_{\\text{free}}$) and a fully bound, active state where all $n$ sites are occupied ($P_{\\text{active}}$). Intermediate states with partial occupancy are considered negligible. The reversible binding reaction is:\n$$ P_{\\text{free}} + nT \\rightleftharpoons P_{\\text{active}} $$\nwhere $T$ represents the TF molecule.\n\nThe problem states that this binding-unbinding process reaches thermodynamic equilibrium rapidly compared to the timescales of transcription and translation. We can therefore apply the law of mass action to this equilibrium. The overall dissociation constant, $K_{D}$, for this reaction is given by:\n$$ K_{D} = \\frac{[P_{\\text{free}}][T]^{n}}{[P_{\\text{active}}]} $$\nwhere $[...]$ denotes concentration.\n\nThe problem provides a dissociation constant $K$ for a single TF binding site. For an \"all-or-none\" or perfectly cooperative process involving $n$ identical sites, the overall dissociation constant $K_{D}$ is related to the single-site constant $K$ by $K_{D} = K^{n}$. This is a standard assumption in modeling high-cooperativity systems, reflecting the multiplicative effect of individual binding affinities in a concerted binding event. Substituting this into our equilibrium equation gives:\n$$ K^{n} = \\frac{[P_{\\text{free}}][T]^{n}}{[P_{\\text{active}}]} $$\n\nThe promoter is transcriptionally active only when it is in the $P_{\\text{active}}$ state. The probability of the promoter being active, $p_{\\text{active}}$, is the fraction of the total promoter population that is in the active state:\n$$ p_{\\text{active}} = \\frac{[P_{\\text{active}}]}{[P_{\\text{total}}]} = \\frac{[P_{\\text{active}}]}{[P_{\\text{free}}] + [P_{\\text{active}}]} $$\nFrom the equilibrium expression, we can express $[P_{\\text{free}}]$ in terms of $[P_{\\text{active}}]$:\n$$ [P_{\\text{free}}] = [P_{\\text{active}}] \\frac{K^{n}}{[T]^{n}} $$\nSubstituting this into the equation for $p_{\\text{active}}$:\n$$ p_{\\text{active}} = \\frac{[P_{\\text{active}}]}{[P_{\\text{active}}] \\frac{K^{n}}{[T]^{n}} + [P_{\\text{active}}]} $$\nBy canceling the $[P_{\\text{active}}]$ term from the numerator and denominator, we obtain:\n$$ p_{\\text{active}} = \\frac{1}{\\frac{K^{n}}{[T]^{n}} + 1} = \\frac{[T]^{n}}{K^{n} + [T]^{n}} $$\nThis is the well-known Hill function, describing the probabilistic response of the promoter to TF concentration. The problem states that the TF concentration is clamped at a constant value $\\bar{T}$ for $t \\ge 0$. Therefore, the probability of activation is constant in time:\n$$ p_{\\text{active}} = \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} $$\n\nNext, we formulate the differential equation governing the mRNA concentration, $x(t)$. The rate of change of $x(t)$ is the difference between its synthesis rate and its degradation rate.\n$$ \\frac{dx}{dt} = (\\text{synthesis rate}) - (\\text{degradation rate}) $$\nThe synthesis rate is given as proportional to the probability of the promoter being active, with a rate constant $k_{\\mathrm{tr}}$.\n$$ \\text{synthesis rate} = k_{\\mathrm{tr}} \\cdot p_{\\text{active}} = k_{\\mathrm{tr}} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} $$\nThe degradation of mRNA follows first-order kinetics with a rate constant $\\gamma$.\n$$ \\text{degradation rate} = \\gamma x(t) $$\nCombining these terms, we have the following first-order linear ordinary differential equation (ODE):\n$$ \\frac{dx}{dt} = k_{\\mathrm{tr}} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} - \\gamma x(t) $$\nLet the constant synthesis term be denoted by $C_S = k_{\\mathrm{tr}} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}}$. The ODE becomes:\n$$ \\frac{dx}{dt} + \\gamma x(t) = C_S $$\nThis is a standard form of a linear ODE. The general solution can be found using an integrating factor or by summing the homogeneous and particular solutions. The homogeneous solution to $\\frac{dx_h}{dt} + \\gamma x_h = 0$ is $x_h(t) = A \\exp(-\\gamma t)$, where $A$ is an integration constant. For the particular solution, since the right-hand side is constant, we can assume a constant particular solution $x_p(t) = B$. Substituting this into the ODE gives $0 + \\gamma B = C_S$, so $B = \\frac{C_S}{\\gamma}$.\nThe general solution is the sum of the homogeneous and particular solutions:\n$$ x(t) = x_h(t) + x_p(t) = A \\exp(-\\gamma t) + \\frac{C_S}{\\gamma} $$\n\nTo determine the constant $A$, we apply the initial condition specified in the problem: $x(0) = 0$.\n$$ x(0) = A \\exp(-\\gamma \\cdot 0) + \\frac{C_S}{\\gamma} = A \\cdot 1 + \\frac{C_S}{\\gamma} = 0 $$\nThis gives $A = -\\frac{C_S}{\\gamma}$.\n\nSubstituting $A$ back into the general solution, we find the specific solution for $x(t)$:\n$$ x(t) = -\\frac{C_S}{\\gamma} \\exp(-\\gamma t) + \\frac{C_S}{\\gamma} = \\frac{C_S}{\\gamma} (1 - \\exp(-\\gamma t)) $$\nFinally, we substitute the full expression for $C_S$:\n$$ x(t) = \\frac{1}{\\gamma} \\left( k_{\\mathrm{tr}} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} \\right) (1 - \\exp(-\\gamma t)) $$\nThis expression can be written more compactly as:\n$$ x(t) = \\frac{k_{\\mathrm{tr}}}{\\gamma} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} (1 - \\exp(-\\gamma t)) $$\nThis is the closed-form analytical expression for the mRNA concentration as a function of time, based on the given parameters and principles.",
            "answer": "$$\\boxed{\\frac{k_{\\mathrm{tr}}}{\\gamma} \\frac{\\bar{T}^{n}}{K^{n} + \\bar{T}^{n}} (1 - \\exp(-\\gamma t))}$$"
        },
        {
            "introduction": "Individual regulatory interactions, like those described by the Hill function, are the building blocks of larger gene regulatory networks that orchestrate complex cellular behaviors. In this final practice, you will investigate one of the most important network motifs: the positive feedback loop, where a transcription factor activates its own production. By combining the nonlinear Hill function with this feedback architecture, you will discover how a system can exhibit bistability—the capacity to exist in two distinct, stable states. This computational exercise will challenge you to find these steady states and analyze their stability, providing insight into how cells make robust, all-or-none decisions. ",
            "id": "4393065",
            "problem": "A single gene product engages in positive feedback by activating its own transcription through cooperative binding to its promoter. Assume that transcriptional activation arises from the equilibrium occupancy of the promoter by an activator whose concentration is denoted by $A$ (in $\\mathrm{nM}$), under the rapid-equilibrium approximation and cooperative binding of order $n$ with dissociation constant $K$ (in $\\mathrm{nM}$). Let there be a basal production rate $\\alpha_0$ (in $\\mathrm{nM}/\\mathrm{h}$), a maximal activation-amplified production contribution $\\alpha$ (in $\\mathrm{nM}/\\mathrm{h}$), and a first-order degradation rate constant $\\delta$ (in $\\mathrm{h}^{-1}$). The continuous-time dynamics of the activator concentration $A(t)$ is governed by a one-dimensional ordinary differential equation constructed from these components.\n\nStarting from the foundational base comprising: (i) mass-action binding equilibrium for promoter occupancy with cooperativity, (ii) the Central Dogma of molecular biology (DNA $\\rightarrow$ RNA $\\rightarrow$ protein) asserting that transcriptional activity determines production rate, and (iii) linear first-order degradation, derive the regulatory activation function as a saturating, monotonically increasing function of $A$ that arises from cooperative promoter occupancy, and formulate the dynamical equation for $A(t)$. Then, focus on steady states and their stability.\n\nFor a given parameter set $(\\alpha_0,\\alpha,\\delta,K,n)$, define the steady-state equation $f(A)=0$ for $A\\ge 0$ by equating total production to degradation. A steady state $A^\\ast$ is stable if the one-dimensional stability criterion holds, namely if the derivative $\\frac{d f}{d A}(A^\\ast)$ is negative, and it is unstable if the derivative is positive. Under strong positive feedback with sufficient cooperativity, multiple steady states can exist, including bistability with two stable steady states separated by one unstable steady state.\n\nYour program must:\n- Implement the derived regulatory function based on the equilibrium occupancy with cooperativity and construct $f(A)$ from the production and degradation terms.\n- Numerically find all nonnegative steady states $A^\\ast$ (roots of $f(A)$ for $A\\ge 0$) by scanning a sufficiently large interval and bracketing sign changes, then refining roots with a robust solver.\n- Classify each steady state as stable or unstable using the sign of $\\frac{d f}{d A}$ at the root.\n- For each test case, return the number of stable steady states and the sorted list (ascending) of the stable steady-state concentrations, expressed in $\\mathrm{nM}$ as floating-point values.\n\nUse the following test suite with scientifically plausible parameters:\n- Test case $1$: $(\\alpha_0,\\alpha,\\delta,K,n)=(2,120,1,20,4)$ with $A$ in $\\mathrm{nM}$, rates in $\\mathrm{nM}/\\mathrm{h}$ and $\\mathrm{h}^{-1}$.\n- Test case $2$: $(\\alpha_0,\\alpha,\\delta,K,n)=(2,15,1,20,4)$ with $A$ in $\\mathrm{nM}$, rates in $\\mathrm{nM}/\\mathrm{h}$ and $\\mathrm{h}^{-1}$.\n- Test case $3$: $(\\alpha_0,\\alpha,\\delta,K,n)=(2,120,8,20,4)$ with $A$ in $\\mathrm{nM}$, rates in $\\mathrm{nM}/\\mathrm{h}$ and $\\mathrm{h}^{-1}$.\n- Test case $4$: $(\\alpha_0,\\alpha,\\delta,K,n)=(2,120,1,20,1)$ with $A$ in $\\mathrm{nM}$, rates in $\\mathrm{nM}/\\mathrm{h}$ and $\\mathrm{h}^{-1}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list of case-wise items, enclosed in square brackets. Each case-wise item must itself be a list of the form $[\\text{num\\_stable},[\\text{stable\\_root}_1,\\text{stable\\_root}_2,\\ldots]]$ with no spaces. For example, for two cases the format would be $[[2,[a,b]],[1,[c]]]$ where $a$, $b$, and $c$ are floating-point concentrations in $\\mathrm{nM}$ expressed as decimals. The final output must follow this exact format for the four test cases specified above.",
            "solution": "The problem requires an analysis of the steady states and their stability for a genetic auto-regulatory network. The core task involves deriving the governing differential equation, identifying the steady-state condition, and implementing a numerical algorithm to find and classify the steady states for given parameter sets.\n\nFirst, we formulate the mathematical model based on the provided physical and biological principles. The concentration of the activator protein, denoted by $A$, changes over time according to the balance between its production and degradation. This can be expressed as a one-dimensional ordinary differential equation (ODE):\n$$ \\frac{dA}{dt} = \\text{Rate of Production} - \\text{Rate of Degradation} $$\n\nThe degradation process is described as a first-order reaction with a rate constant $\\delta$. Thus, the rate of degradation is proportional to the concentration $A$:\n$$ \\text{Rate of Degradation} = \\delta A $$\n\nThe production of the activator is regulated by the activator itself. There is a basal production rate, $\\alpha_0$, which occurs even in the absence of the activator. Additionally, the activator enhances its own production by binding to its promoter. This binding is described as a cooperative process of order $n$. Under the rapid-equilibrium approximation, the fraction of promoters occupied by the activator, $\\theta$, is given by the Hill function:\n$$ \\theta(A) = \\frac{A^n}{K^n + A^n} $$\nHere, $K$ is the dissociation constant, representing the concentration of $A$ at which the promoter occupancy is half-maximal. The activated production rate is proportional to this occupancy fraction, with a maximal activation-amplified contribution of $\\alpha$. The total production rate is the sum of the basal and activated rates:\n$$ \\text{Rate of Production} = \\alpha_0 + \\alpha \\cdot \\theta(A) = \\alpha_0 + \\alpha \\frac{A^n}{K^n + A^n} $$\n\nCombining the production and degradation terms, we obtain the complete dynamical equation for $A(t)$:\n$$ \\frac{dA}{dt} = \\alpha_0 + \\alpha \\frac{A^n}{K^n + A^n} - \\delta A $$\n\nSteady states of the system are the concentrations $A^\\ast$ at which the net rate of change is zero, i.e., $\\frac{dA}{dt} = 0$. This condition defines the steady-state equation $f(A) = 0$, where:\n$$ f(A) = \\alpha_0 + \\alpha \\frac{A^n}{K^n + A^n} - \\delta A $$\nThe non-negative roots $A^\\ast \\ge 0$ of this equation correspond to the steady-state concentrations. Graphically, these are the intersection points of the sigmoidal production curve, $P(A) = \\alpha_0 + \\alpha \\frac{A^n}{K^n + A^n}$, and the linear degradation line, $D(A) = \\delta A$.\n\nThe stability of a steady state $A^\\ast$ is determined by the system's response to small perturbations around $A^\\ast$. For a one-dimensional system, this is given by the sign of the derivative of $f(A)$ evaluated at the steady state. A steady state $A^\\ast$ is stable if $\\frac{df}{dA}(A^\\ast) < 0$, meaning perturbations decay and the system returns to $A^\\ast$. It is unstable if $\\frac{df}{dA}(A^\\ast) > 0$, meaning perturbations are amplified, driving the system away from $A^\\ast$.\n\nTo find the derivative, we differentiate $f(A)$ with respect to $A$:\n$$ \\frac{df}{dA} = \\frac{d}{dA} \\left( \\alpha_0 + \\alpha \\frac{A^n}{K^n + A^n} - \\delta A \\right) $$\nUsing the quotient rule for the Hill function term, we get:\n$$ \\frac{df}{dA} = \\alpha \\frac{(nA^{n-1})(K^n + A^n) - (A^n)(nA^{n-1})}{(K^n + A^n)^2} - \\delta = \\alpha \\frac{nK^nA^{n-1}}{(K^n + A^n)^2} - \\delta $$\n\nThe numerical implementation proceeds as follows:\n$1$.  For each parameter set $(\\alpha_0, \\alpha, \\delta, K, n)$, define the functions for $f(A)$ and $\\frac{df}{dA}$.\n$2$.  Determine a suitable search interval for the roots $A^\\ast$. A safe upper bound for any steady state is given by the maximum possible production rate divided by the degradation constant, $A_{max} = (\\alpha_0 + \\alpha) / \\delta$. We scan a slightly larger interval, for instance, from $0$ to $1.5 \\cdot A_{max} + 10$.\n$3$.  Scan this interval with a small step size to identify pairs of consecutive points where $f(A)$ changes sign. Each such pair brackets a root.\n$4$.  For each bracket found, use a robust numerical root-finding algorithm, such as the Brent-Dekker method (implemented in `scipy.optimize.brentq`), to find the precise value of the root $A^\\ast$.\n$5$.  For each root $A^\\ast$, calculate the derivative $\\frac{df}{dA}(A^\\ast)$.\n$6$.  If $\\frac{df}{dA}(A^\\ast) < 0$, the root is classified as stable.\n$7$.  The stable roots for each case are collected, sorted in ascending order, and formatted along with their count as specified in the problem statement.\nThis procedure systematically finds all non-negative steady states and determines their stability, allowing us to characterize the system's behavior (monostable vs. bistable) for each set of parameters.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves for the stable steady states of a genetic auto-activation circuit.\n\n    The function iterates through a set of test cases, each defined by parameters\n    (alpha0, alpha, delta, K, n). For each case, it finds the non-negative roots\n    of the steady-state equation f(A) = 0 and classifies them as stable or unstable.\n\n    The steady-state equation is:\n    f(A) = alpha0 + alpha * A^n / (K^n + A^n) - delta * A\n\n    A steady state A* is stable if df/dA(A*) < 0. The derivative is:\n    df/dA = alpha * n * K^n * A^(n-1) / (K^n + A^n)^2 - delta\n    \"\"\"\n    test_cases = [\n        # (alpha0, alpha, delta, K, n)\n        (2, 120, 1, 20, 4),\n        (2, 15, 1, 20, 4),\n        (2, 120, 8, 20, 4),\n        (2, 120, 1, 20, 1)\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        alpha0, alpha, delta, K, n = case\n\n        # To avoid potential overflow with large powers, use log-exp trick if needed,\n        # but standard float64 is sufficient for these parameters.\n        # Define f(A) and its derivative df/dA\n        def f(A):\n            if A < 0:\n                return np.inf  # We only care about A >= 0\n            A_n = A**n\n            K_n = K**n\n            return alpha0 + alpha * A_n / (K_n + A_n) - delta * A\n\n        def dfdA(A):\n            if A < 0:\n                return 0 # Value for A<0 is not relevant for stability analysis.\n            \n            # Handle A=0 case for A**(n-1) when n=1, where it's A**0=1.\n            # a**(b-1) for a=0, b=1 should be 1. np.power(0,0) is 1.\n            A_pow_n_minus_1 = np.power(A, n - 1)\n            \n            K_n = K**n\n            A_n = A**n\n            \n            numerator = alpha * n * K_n * A_pow_n_minus_1\n            denominator = (K_n + A_n)**2\n            \n            if denominator == 0:\n                # Should not happen for K>0 or A>0. If K=0 and A=0, it's a singularity.\n                # All K in test cases are > 0.\n                return -delta\n            \n            return numerator / denominator - delta\n\n        # Root finding using a bracketing scan followed by a robust solver\n        roots = []\n        \n        # A generous but informed search range\n        A_max_bound = (alpha0 + alpha) / delta\n        search_domain_max = A_max_bound * 1.5 + 50\n        \n        # Scan for intervals where f(A) changes sign\n        scan_step = 0.01\n        A_scan_points = np.arange(0, search_domain_max, scan_step)\n        \n        # Ensure the first point's value is calculated\n        f_prev = f(A_scan_points[0])\n\n        for i in range(1, len(A_scan_points)):\n            a = A_scan_points[i-1]\n            b = A_scan_points[i]\n            f_curr = f(b)\n            if np.sign(f_curr) != np.sign(f_prev):\n                # A bracket [a, b] is found\n                try:\n                    root = brentq(f, a, b)\n                    # Add root if it's not a duplicate from a previous bracket\n                    if not any(np.isclose(root, r) for r in roots):\n                        roots.append(root)\n                except ValueError:\n                    # brentq might fail if signs are not opposite, though our check prevents this.\n                    # This can happen if one value is exactly zero.\n                    if f_prev == 0:\n                        if not any(np.isclose(a, r) for r in roots):\n                            roots.append(a)\n            f_prev = f_curr\n\n        # If alpha0 is exactly 0, A=0 is a trivial root. Not the case here.\n        # Check f(0) in case the first root is missed by the scan.\n        # f(0) is alpha0, which is > 0 for all cases. So no root at A=0.\n\n        # Classify each found root and collect the stable ones\n        stable_roots = []\n        for root in roots:\n            derivative_at_root = dfdA(root)\n            if derivative_at_root < 0:\n                stable_roots.append(root)\n        \n        stable_roots.sort()\n\n        # Store the result for the current case\n        case_result = [len(stable_roots), stable_roots]\n        all_results.append(case_result)\n\n    # Format the final output string as specified: [[num,[root1,...]],...]\n    # without any spaces.\n    result_strings = []\n    for num_stable, roots_list in all_results:\n        # Convert each root to a string, then join them with commas\n        roots_str = f\"[{','.join(map(str, roots_list))}]\"\n        result_strings.append(f\"[{num_stable},{roots_str}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}