{
    "hands_on_practices": [
        {
            "introduction": "要真正掌握基因集富集分析（GSEA），理解其核心引擎——“运行总和”统计量——至关重要。第一个练习将剥离软件的复杂性，要求您从第一性原理出发，手动计算富集分数（ES）。通过遍历一个排序的基因列表并追踪“命中”和“错失”的基因，您将对GSEA如何量化基因集的富集程度建立起具体的直觉。",
            "id": "4567424",
            "problem": "给定一个来自转录组差异表型分析的预排序基因列表，其中每个基因都与一个排序度量值相关联，该度量值被解释为与表型相关性的绝对值。任务是根据第一性原理，使用类似柯尔莫哥洛夫–斯米尔诺夫的运行总和定义，计算加权参数 $p=1$ 时的基因集富集分析（GSEA）富集分数，然后确定领先边缘子集。不要使用任何预先记忆的快捷公式；相反，应从命中和错过的经验累积分布函数的定义出发，明确地构建运行总和过程。\n\n基因总数为 $N=10$，从最相关到最不相关的排序列表如下：\n1. MYC，分数为 $10$\n2. TP53，分数为 $9$\n3. EGFR，分数为 $8$\n4. BRCA1，分数为 $7$\n5. PTEN，分数为 $6$\n6. KRAS，分数为 $5$\n7. AKT1，分数为 $4$\n8. BRAF，分数为 $3$\n9. MDM2，分数为 $2$\n10. CDK2，分数为 $1$\n\n考虑大小为 $|S|=3$ 的基因集 $S$，由 $S=\\{\\text{TP53}, \\text{KRAS}, \\text{MDM2}\\}$ 给出。使用加权参数 $p=1$，这样在命中时，运行总和会增加一个与该基因分数成正比并由 $S$ 中总分归一化的值；在错过时，运行总和会减少一个常数，使得所有错过的总减少量等于 $1$。\n\n从命中和错过的经验累积分布函数的定义以及它们在排序列表中的差异出发，手动计算：\n- 富集分数（ES），即运行总和与零的最大偏差，以及\n- 达到富集分数位置所对应的领先边缘子集。\n\n将富集分数表示为一个精确的既约分数（不要四舍五入），不带单位。最终答案应仅为富集分数。",
            "solution": "用户提供的问题陈述经过了验证过程。\n\n### 步骤1：提取已知条件\n- 排序列表中的基因总数：$N=10$。\n- 附有分数（解释为绝对相关性）的基因排序列表：\n  1. MYC (分数 $10$)\n  2. TP53 (分数 $9$)\n  3. EGFR (分数 $8$)\n  4. BRCA1 (分数 $7$)\n  5. PTEN (分数 $6$)\n  6. KRAS (分数 $5$)\n  7. AKT1 (分数 $4$)\n  8. BRAF (分数 $3$)\n  9. MDM2 (分数 $2$)\n  10. CDK2 (分数 $1$)\n- 目标基因集：$S=\\{\\text{TP53}, \\text{KRAS}, \\text{MDM2}\\}$。\n- 基因集大小：$N_H = |S|=3$。\n- 加权参数：$p=1$。\n- 命中增量规则：对于 $S$ 中的一个基因，运行总和增加一个与该基因分数成正比并由 $S$ 中所有基因的总分归一化的值。\n- 错过减量规则：对于不在 $S$ 中的一个基因，运行总和减少一个恒定值，使得所有错过的总减量等于 $1$。\n- 富集分数（ES）的定义：运行总和与零的最大偏差。\n- 任务：使用由经验累积分布函数定义的运行总和，从第一性原理计算 ES 和领先边缘子集。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据，因为它描述了一个标准的、尽管是简化的基因集富集分析（GSEA）程序，这是一种生物信息学中公认的方法。使用 $p=1$ 的加权类柯尔莫哥洛夫–斯米尔诺夫统计量是 GSEA 的一个有效变体。所有必要的数据（$N$、排序列表、分数、基因集 $S$ 以及运行总和的规则）均已提供，使得该问题是适定且自洽的。语言客观，数据内部一致。该问题未违反任何无效标准。\n\n### 步骤3：结论与行动\n该问题被判定为**有效**。将提供解答。\n\n### 解答\n基因集富集分析（GSEA）的富集分数（ES）是通过沿基因排序列表 $L$ 向下移动并计算一个运行总和统计量来计算的。ES 是此运行总和与零的最大偏差。排序列表中任意点 $i$ 的运行总和是在基因集 $S$ 中存在的基因（命中）的加权经验累积分布函数与不在 $S$ 中的基因（错过）的经验累积分布函数之间的差值。\n\n首先，我们识别出排序列表中的命中和错过。基因总数为 $N=10$。基因集 $S=\\{\\text{TP53}, \\text{KRAS}, \\text{MDM2}\\}$ 有 $N_H = |S| = 3$ 个基因（命中）。不在 $S$ 中的基因数量为 $N_M = N - N_H = 10 - 3 = 7$ 个（错过）。\n\n带有命中/错过状态和分数（$r_j$）的排序列表如下：\n1. MYC, $r_1=10$ (错过)\n2. TP53, $r_2=9$ (命中)\n3. EGFR, $r_3=8$ (错过)\n4. BRCA1, $r_4=7$ (错过)\n5. PTEN, $r_5=6$ (错过)\n6. KRAS, $r_6=5$ (命中)\n7. AKT1, $r_7=4$ (错过)\n8. BRAF, $r_8=3$ (错过)\n9. MDM2, $r_9=2$ (命中)\n10. CDK2, $r_{10}=1$ (错过)\n\n在排名 $i$ 处的运行总和，记为 $ES_i$，定义为 $ES_i = P_{hit}(S, i) - P_{miss}(S, i)$。\n\n项 $P_{hit}(S, i)$ 是命中的加权经验累积分布。当加权参数 $p=1$ 时，其计算公式为：\n$$P_{hit}(S, i) = \\sum_{g_j \\in S, j \\le i} \\frac{r_j}{N_R}$$\n其中 $N_R$ 是归一化因子，等于 $S$ 中所有基因的分数总和：\n$$N_R = \\sum_{g_j \\in S} r_j = r_{\\text{TP53}} + r_{\\text{KRAS}} + r_{\\text{MDM2}} = 9 + 5 + 2 = 16$$\n当我们在排名 $j$ 遇到一个命中基因 $g_j \\in S$，其分数为 $r_j$ 时，运行总和增加 $\\frac{r_j}{N_R} = \\frac{r_j}{16}$。\n\n项 $P_{miss}(S, i)$ 是错过的经验累积分布：\n$$P_{miss}(S, i) = \\sum_{g_j \\notin S, j \\le i} \\frac{1}{N_M}$$\n其中 $N_M = 7$。当我们在排名 $j$ 遇到一个错过基因 $g_j \\notin S$ 时，运行总和减少 $\\frac{1}{N_M} = \\frac{1}{7}$。\n\n我们现在从 $ES_0=0$ 开始，计算排序列表中每个基因 $g_i$ 的运行总和 $ES_i$。\n\n1.  **基因 1 (MYC, 错过):**\n    $P_{hit}(S, 1) = 0$。 $P_{miss}(S, 1) = \\frac{1}{7}$。\n    $ES_1 = 0 - \\frac{1}{7} = -\\frac{1}{7} = -\\frac{16}{112}$。\n\n2.  **基因 2 (TP53, 命中, 分数=9):**\n    $P_{hit}(S, 2) = \\frac{9}{16}$。 $P_{miss}(S, 2) = \\frac{1}{7}$。\n    $ES_2 = \\frac{9}{16} - \\frac{1}{7} = \\frac{63 - 16}{112} = \\frac{47}{112}$。\n\n3.  **基因 3 (EGFR, 错过):**\n    $P_{hit}(S, 3) = \\frac{9}{16}$。 $P_{miss}(S, 3) = \\frac{2}{7}$。\n    $ES_3 = \\frac{9}{16} - \\frac{2}{7} = \\frac{63 - 32}{112} = \\frac{31}{112}$。\n\n4.  **基因 4 (BRCA1, 错过):**\n    $P_{hit}(S, 4) = \\frac{9}{16}$。 $P_{miss}(S, 4) = \\frac{3}{7}$。\n    $ES_4 = \\frac{9}{16} - \\frac{3}{7} = \\frac{63 - 48}{112} = \\frac{15}{112}$。\n\n5.  **基因 5 (PTEN, 错过):**\n    $P_{hit}(S, 5) = \\frac{9}{16}$。 $P_{miss}(S, 5) = \\frac{4}{7}$。\n    $ES_5 = \\frac{9}{16} - \\frac{4}{7} = \\frac{63 - 64}{112} = -\\frac{1}{112}$。\n\n6.  **基因 6 (KRAS, 命中, 分数=5):**\n    $P_{hit}(S, 6) = \\frac{9}{16} + \\frac{5}{16} = \\frac{14}{16}$。 $P_{miss}(S, 6) = \\frac{4}{7}$。\n    $ES_6 = \\frac{14}{16} - \\frac{4}{7} = \\frac{7}{8} - \\frac{4}{7} = \\frac{49 - 32}{56} = \\frac{17}{56} = \\frac{34}{112}$。\n\n7.  **基因 7 (AKT1, 错过):**\n    $P_{hit}(S, 7) = \\frac{14}{16}$。 $P_{miss}(S, 7) = \\frac{5}{7}$。\n    $ES_7 = \\frac{14}{16} - \\frac{5}{7} = \\frac{7}{8} - \\frac{5}{7} = \\frac{49 - 40}{56} = \\frac{9}{56} = \\frac{18}{112}$。\n\n8.  **基因 8 (BRAF, 错过):**\n    $P_{hit}(S, 8) = \\frac{14}{16}$。 $P_{miss}(S, 8) = \\frac{6}{7}$。\n    $ES_8 = \\frac{14}{16} - \\frac{6}{7} = \\frac{7}{8} - \\frac{6}{7} = \\frac{49 - 48}{56} = \\frac{1}{56} = \\frac{2}{112}$。\n\n9.  **基因 9 (MDM2, 命中, 分数=2):**\n    $P_{hit}(S, 9) = \\frac{14}{16} + \\frac{2}{16} = \\frac{16}{16} = 1$。 $P_{miss}(S, 9) = \\frac{6}{7}$。\n    $ES_9 = 1 - \\frac{6}{7} = \\frac{1}{7} = \\frac{16}{112}$。\n\n10. **基因 10 (CDK2, 错过):**\n    $P_{hit}(S, 10) = 1$。 $P_{miss}(S, 10) = \\frac{7}{7} = 1$。\n    $ES_{10} = 1 - 1 = 0$。\n\n运行总和值的序列为： $\\{-\\frac{16}{112}, \\frac{47}{112}, \\frac{31}{112}, \\frac{15}{112}, -\\frac{1}{112}, \\frac{34}{112}, \\frac{18}{112}, \\frac{2}{112}, \\frac{16}{112}, 0\\}$。\n\n富集分数（ES）是此运行总和与零的最大偏差。这是运行总和绝对值的最大值：\n$$ES = \\max_{i=1,\\ldots,10} |ES_i|$$\n该集合中的最大值为 $ES_2 = \\frac{47}{112}$。最小值为 $ES_1 = -\\frac{16}{112}$。\n与零的最大偏差是 $\\max(\\frac{47}{112}, |-\\frac{16}{112}|) = \\max(\\frac{47}{112}, \\frac{16}{112}) = \\frac{47}{112}$。\n因此，富集分数为 $\\frac{47}{112}$。数字 $47$ 是质数，不能整除 $112 = 2^4 \\times 7$，所以这个分数是其最简形式。\n\n领先边缘子集由基因集 $S$ 中，在排序列表中出现于最大富集分数所在位置及之前的所有基因组成。最大分数 $ES = \\frac{47}{112}$ 出现在排名 $i=2$ 处。排序列表中排名到 $2$ 的基因为 $\\{\\text{MYC}, \\text{TP53}\\}$。该集合与基因集 $S$ 的交集为 $\\{\\text{TP53}\\}$。因此，领先边缘子集是 $\\{\\text{TP53}\\}$。",
            "answer": "$$\\boxed{\\frac{47}{112}}$$"
        },
        {
            "introduction": "一个观测到的富集分数（ES）本身只说明了部分情况；为了评估其显著性并在不同基因集之间进行比较，必须对其进行归一化。本练习探讨了计算归一化富集分数（NES）的关键步骤，即将观测到的ES置于一个零分布的背景下进行评估。您将应用两种常见的标准化方法，从而深入了解原始分数是如何转化为统计上更稳健的度量指标的。",
            "id": "4345921",
            "problem": "在基因集富集分析（GSEA）中，一个基因集的观测富集得分 $ES$ 是通过对一个排序的基因列表计算运行总和统计量得到的，而 $ES$ 大小的零分布是通过表型标签置換生成的，用以估计伪富集的预期大小。为了消除对基因集大小和抽样变异性的依赖，归一化过程使用绝对富集得分的零分布，将观测到的 $ES$ 映射到一个无量纲的尺度上。考虑一个基因集，其观测到的 $ES$ 等于 $0.62$。通过 $N$ 次置换，绝对富集得分的经验零分布产生的均值为 $0.31$，标准差为 $0.12$。假设在从绝对值零分布映射到归一化富集得分 $NES$ 时，归一化过程保留了观测到的 $ES$ 的符号。\n\n使用应用于绝对零分布量值的均值标准化和 $z$-分数标准化的统计定义，计算以下两个 $NES$ 值：\n- 均值标准化的 $NES$，以及\n- $z$-分数标准化的 $NES$。\n\n以行向量 $\\left(NES_{\\text{mean}}, NES_{z}\\right)$ 的形式给出您的最终答案，并将每个值四舍五入到四位有效数字。无需单位。",
            "solution": "该问题要求根据一个给定基因集的观测富集得分（$ES$）和一个零分布的统计特性，计算两种类型的归一化富集得分（$NES$）。\n\n首先，确定给定的值：\n- 观测富集得分，$ES_{obs} = 0.62$。\n- 由置换生成的绝对富集得分的零分布 $|ES|_{null}$ 具有以下特性：\n  - 均值，$\\mu_{|ES|} = 0.31$。\n  - 标准差，$\\sigma_{|ES|} = 0.12$。\n\n问题指明，归一化过程保留观测到的 $ES$ 的符号。由于 $ES_{obs} = 0.62$ 是正数，因此两个得到的 $NES$ 值都将是正数。归一化是通过将观测得分的绝对值 $|ES_{obs}|$ 与绝对值零分布进行标准化来实现的。\n\n观测富集得分的绝对值为 $|ES_{obs}| = |0.62| = 0.62$。\n\n两种要求的归一化方法是均值标准化和 $z$-分数标准化。\n\n1.  **均值标准化的 $NES$ ($NES_{\\text{mean}}$)**\n    在GSEA的背景下，均值标准化涉及将观测得分除以零分布的均值来进行归一化。问题指示我们使用绝对得分的零分布。因此，将观测到的 $ES$ 的绝对值除以零分布中绝对得分的均值。然后应用原始 $ES_{obs}$ 的符号。\n\n    公式为：\n    $$NES_{\\text{mean}} = \\text{sign}(ES_{obs}) \\times \\frac{|ES_{obs}|}{\\mu_{|ES|}}$$\n    鉴于 $ES_{obs} > 0$，$\\text{sign}(ES_{obs}) = +1$。\n    代入给定值：\n    $$NES_{\\text{mean}} = \\frac{0.62}{0.31} = 2$$\n    四舍五入到四位有效数字，结果为 $2.000$。\n\n2.  **$z$-分数标准化的 $NES$ ($NES_{z}$)**\n    $z$-分数标准化通过一个值与分布均值相差的标准差个数来重新缩放该值。在这里，我们相对于绝对得分零分布的均值和标准差来标准化观测到的 $ES$ 的绝对值 $|ES_{obs}|$。原始 $ES_{obs}$ 的符号被保留。\n\n    $z$-分数的公式为 $z = \\frac{(x - \\mu)}{\\sigma}$。将其应用于我们的情景中：\n    $$NES_{z} = \\text{sign}(ES_{obs}) \\times \\frac{|ES_{obs}| - \\mu_{|ES|}}{\\sigma_{|ES|}}$$\n    同样地，由于 $ES_{obs} > 0$，$\\text{sign}(ES_{obs}) = +1$。\n    代入给定值：\n    $$NES_{z} = \\frac{0.62 - 0.31}{0.12} = \\frac{0.31}{0.12}$$\n    $$NES_{z} \\approx 2.58333...$$\n    将该值四舍五入到四位有效数字，得到 $2.583$。\n\n最终答案应以行向量 $(NES_{\\text{mean}}, NES_{z})$ 的形式呈现，并将计算出的值四舍五入到四位有效数字。\n计算出的值为 $NES_{\\text{mean}} = 2.000$ 和 $NES_{z} = 2.583$。",
            "answer": "$$\\boxed{\\begin{pmatrix} 2.000  2.583 \\end{pmatrix}}$$"
        },
        {
            "introduction": "基因集富集分析通常是始于原始实验数据的漫长分析旅程的最后一步。这个综合性练习模拟了一个真实的生物信息学工作流程，引导您完成从RNA测序原始计数生成排序基因列表，再到执行GSEA的全过程。通过实践数据筛选、归一化和统计建模等关键步骤，您将理解上游的分析选择如何直接影响最终的富集分析结果。",
            "id": "4346070",
            "problem": "你的任务是构建一个分析流程，该流程模拟基于负二项建模假设的转录组学分析中广泛使用的差异表达工具所生成的每个基因的统计输出，以产生一个适用于基因集富集分析 (GSEA) 的排序列表。教育背景为系统生物医学，主题为基因集富集分析。该流程必须基于基本原理：将负二项分布作为 RNA 测序计数的模型，使用组合性概念进行文库大小归一化，以及使用 delta 方法进行方差传播。任务是为每个提供的测试用例实施一系列步骤，根据明确的假设来证明每个预处理操作的合理性，计算适用于 GSEA 排序的每个基因的统计量，然后为所提供的基因集计算经典的运行总和富集分数。\n\n要使用的基本原理和假设：\n- 将样本 $i$ 中基因 $g$ 的 RNA 测序计数数据建模为从负二项分布中抽样，其均值为 $\\mu_{g,i}$，离散度为 $\\phi_{g}$，记作 $\\operatorname{NB}(\\mu_{g,i}, \\phi_{g})$，方差为 $\\operatorname{Var}(Y_{g,i}) = \\mu_{g,i} + \\phi_{g} \\mu_{g,i}^{2}$。负二项概率质量函数由下式给出\n$$\nP(Y=k \\mid \\mu, \\phi) = \\frac{\\Gamma(k + \\phi^{-1})}{\\Gamma(\\phi^{-1}) \\, k!} \\left(\\frac{\\phi^{-1}}{\\phi^{-1} + \\mu}\\right)^{\\phi^{-1}} \\left(\\frac{\\mu}{\\phi^{-1} + \\mu}\\right)^{k},\n$$\n对于整数 $k \\ge 0$，$\\mu > 0$ 和 $\\phi > 0$。\n- 假设期望计数可分解为 $\\mu_{g,i} = s_{i} \\, \\theta_{g,i}$，其中 $s_{i} > 0$ 是一个未知的样本特异性大小因子，用于捕捉文库大小和组成效应，而 $\\theta_{g,i}$ 是潜在的表达水平。这个组合性假设意味着，在没有绝对校准的情况下，只有 $\\theta_{g,i}$ 的比率是可识别的。\n- 使用一个双组设计指示符 $X_{i} \\in \\{0,1\\}$ 和一个对数链接的广义线性模型 $\\log(\\mu_{g,i}) = \\log(s_{i}) + \\beta_{0,g} + \\beta_{1,g} X_{i}$，将条件效应建模为对均值的乘法倍数变化。\n- 使用 delta 方法来近似随机变量平滑函数的方差。特别地，对于负二项模型下的样本均值，其对数的方差可以通过将均值的方差除以均值的平方来近似。\n\n为每个测试用例实施的预处理步骤和统计计算：\n1. 基于可检测性进行过滤：移除表达证据不足的基因，特别是那些严格正计数样本少于 $2$ 个或总计数小于所选最小值的基因。其理由是负二项离散度估计和对数倍数变化方差依赖于非退化的样本均值和方差。\n2. 文库大小归一化：使用与分解式 $\\mu_{g,i} = s_{i} \\, \\theta_{g,i}$ 一致的比率中位数原则来估计样本特异性的大小因子 $\\{s_{i}\\}$。即，估计一个伪参考的每个基因的量，并选择 $s_{i}$，使得对于大多数基因，$Y_{g,i} / s_{i}$ 的值围绕该参考值居中。当大量零值导致无法获得稳定的伪参考时，退而求其次，使用总计数归一化，即 $s_{i}$ 与文库大小成正比，并标准化至均值为 $1$。\n3. 离散度估计：对每个基因 $g$，使用矩量法从归一化计数中估计一个原始离散度 $\\hat{\\phi}_{g} = \\max\\{0, (\\hat{v}_{g} - \\hat{m}_{g}) / \\hat{m}_{g}^{2}\\}$，其中 $\\hat{m}_{g}$ 是归一化计数的跨样本均值，$\\hat{v}_{g}$ 是跨样本方差。然后通过跨基因的最小二乘法估计一个形式为 $a + b/\\hat{m}_{g}$ 的趋势函数 $\\phi_{\\mathrm{trend}}(\\hat{m}_{g})$，并通过一个权重取决于样本数的凸组合将 $\\hat{\\phi}_{g}$ 向 $\\phi_{\\mathrm{trend}}(\\hat{m}_{g})$ 收缩，以获得一个稳定的离散度 $\\tilde{\\phi}_{g}$。\n4. 每个基因的效应和 Wald 统计量：计算两种条件下每个基因的组均值 $\\hat{\\mu}_{g,0}$ 和 $\\hat{\\mu}_{g,1}$（在归一化尺度上）。在必要时使用一个小的正常数来避免除以零，从而估计对数倍数变化 $\\widehat{\\mathrm{LFC}}_{g} = \\log\\left(\\frac{\\hat{\\mu}_{g,1}}{\\hat{\\mu}_{g,0}}\\right)$。使用 delta 方法和负二项方差，将 $\\widehat{\\mathrm{LFC}}_{g}$ 的方差近似为\n$$\n\\widehat{\\operatorname{Var}}(\\widehat{\\mathrm{LFC}}_{g}) \\approx \\frac{\\hat{\\mu}_{g,1} + \\tilde{\\phi}_{g} \\hat{\\mu}_{g,1}^{2}}{n_{1} \\, \\hat{\\mu}_{g,1}^{2}} + \\frac{\\hat{\\mu}_{g,0} + \\tilde{\\phi}_{g} \\hat{\\mu}_{g,0}^{2}}{n_{0} \\, \\hat{\\mu}_{g,0}^{2}},\n$$\n其中 $n_{1}$ 和 $n_{0}$ 分别是处理组和对照组的样本数。定义 Wald 统计量 $Z_{g} = \\widehat{\\mathrm{LFC}}_{g} / \\sqrt{\\widehat{\\operatorname{Var}}(\\widehat{\\mathrm{LFC}}_{g})}$，当分母为零时，令 $Z_{g} = 0$。\n5. 为 GSEA 排序：使用 $Z_{g}$ 作为排序分数，并为提供的基因集计算加权的运行总和富集分数。对于基因集 $S \\subset \\{1,\\dots,G\\}$ 和分数 $\\{Z_{g}\\}$，按 $Z_{g}$ 降序对基因进行排序，使用权重 $w_{g} = |Z_{g}|^{p}$（其中 $p=1$），并计算一个运行总和：当 $g \\in S$ 时，该总和增加 $w_{g} / \\sum_{h \\in S} w_{h}$；当 $g \\notin S$ 时，该总和减少 $1 / (G - |S|)$。富集分数是此运行总和偏离零的有符号极端偏差。\n\n测试套件：\n对于每个测试用例，您将获得一个维度为 $G \\times S$（基因数 × 样本数）的计数矩阵、一个长度为 $S$ 的二元条件向量，以及一个作为基因列表索引的基因集。基因名称隐式排序为 $G1, G2, \\dots$，对应索引 $1, 2, \\dots$。\n\n- 测试用例 1（平衡设计，中等计数）：\n  - 计数矩阵，包含 $G = 12$ 个基因和 $S = 6$ 个样本，前三个为对照组，后三个为处理组。对照组样本 $A, B, C$：\n    - $A$: $[40, 55, 20, 18, 22, 60, 35, 25, 45, 50, 28, 30]$\n    - $B$: $[42, 53, 19, 20, 20, 58, 36, 24, 46, 51, 30, 32]$\n    - $C$: $[39, 57, 18, 19, 21, 62, 34, 26, 44, 49, 29, 31]$\n  - 处理组样本 $D, E, F$：\n    - $D$: $[41, 56, 36, 40, 44, 61, 37, 50, 45, 52, 55, 33]$\n    - $E$: $[43, 54, 35, 39, 43, 59, 38, 49, 47, 53, 54, 34]$\n    - $F$: $[40, 58, 34, 41, 45, 63, 36, 51, 46, 50, 56, 35]$\n  - 条件向量：$[0,0,0,1,1,1]$。\n  - 基因集：$S_{1} = \\{3,4,5,8,11\\}$。\n  - 要求输出：根据上述流程计算出的单个浮点数富集分数（按规定计算的运行总和）。\n\n- 测试用例 2（稀疏计数，大量零值，平衡设计）：\n  - 计数矩阵，包含 $G = 10$ 个基因和 $S = 4$ 个样本。对照组样本 $A, B$：\n    - $A$: $[0,0,1,0,2,1,0,0,0,1]$\n    - $B$: $[0,1,0,0,1,0,0,0,1,0]$\n  - 处理组样本 $C, D$：\n    - $C$: $[0,0,0,0,1,1,0,1,0,0]$\n    - $D$: $[1,0,0,0,0,1,0,0,0,0]$\n  - 条件向量：$[0,0,1,1]$。\n  - 基因集：$S_{2} = \\{2,5,9\\}$。\n  - 要求输出：根据上述流程计算出的单个浮点数富集分数。\n\n- 测试用例 3（非平衡设计，基因集下调）：\n  - 计数矩阵，包含 $G = 12$ 个基因和 $S = 6$ 个样本，前四个为对照组，后两个为处理组。对照组样本 $A, B, C, D$：\n    - $A$: $[30,45,60,55,50,40,35,20,25,18,22,28]$\n    - $B$: $[31,44,62,57,49,39,36,21,26,19,23,29]$\n    - $C$: $[32,46,61,56,51,41,34,22,27,17,24,30]$\n    - $D$: $[29,47,63,54,52,42,33,23,28,20,21,27]$\n  - 处理组样本 $E, F$：\n    - $E$: $[15,45,30,28,26,40,35,20,25,18,22,28]$\n    - $F$: $[16,44,31,29,27,39,36,21,26,19,23,29]$\n  - 条件向量：$[0,0,0,0,1,1]$。\n  - 基因集：$S_{3} = \\{1,3,4,5\\}$。\n  - 要求输出：根据上述流程计算出的单个浮点数富集分数。\n\n最终输出格式：\n你的程序应产生单行输出，包含三个结果，格式为逗号分隔的列表并用方括号括起（例如：`\"[result1,result2,result3]\"`），其中每个结果是相应测试用例的浮点数富集分数。不应打印任何额外文本。不涉及角度，也没有物理单位；所有结果均以普通十进制浮点数表示。",
            "solution": "用户指定构建一个计算流程，以模拟标准的转录组学差异表达分析及随后的基因集富集分析 (GSEA)。该问题在科学上是合理的、定义明确且客观的，基于系统生物医学的既定原则提供了一系列清晰的步骤。所有必要的组成部分，包括 RNA 测序计数的统计模型、归一化程序、效应大小估计和富集分数计算，都已明确说明。一些次要参数未指定，这在此类问题中很常见；这些参数已设置为标准的、合理的值，详见下文。\n\n该解决方案通过为每个测试用例实施分析流程的五个指定阶段来进行。\n\n**1. 基因过滤**\n\n第一步是过滤掉表达水平不足的基因，这些基因缺乏统计功效，并可能引入噪声。问题指定了两个标准：移除严格正计数样本少于 $2$ 个的基因，或所有样本总计数小于所选最小值的基因。其理由是为了确保每个基因的均值和方差是可计算且非退化的。对于测试用例 2 中的稀疏数据，较高的最小总计数阈值会剔除所有基因。因此，为该阈值选择一个较小的值 $2$，即 `total_count` $\\ge 2$，以保留最少的基因集进行分析，这是处理非常稀疏数据集的常见做法。\n\n**2. 文库大小归一化**\n\nRNA 测序计数数据是组合性的，意味着一个基因的计数取决于其表达量和其所在样本的总测序深度。为了使计数在不同样本间具有可比性，我们必须估计样本特异性的大小因子 $s_i$。模型假设 $\\mu_{g,i} = s_i \\theta_{g,i}$，其中 $\\mu_{g,i}$ 是基因 $g$ 在样本 $i$ 中的期望计数，而 $\\theta_{g,i}$ 是真实的表达水平。估计 $s_i$ 的主要方法是比率中位数法。通过计算每个基因在所有样本中计数的几何平均值来创建一个伪参考样本。这只对在每个样本中计数都非零的基因才可行。然后，每个样本 $i$ 的大小因子是其计数与伪参考计数比率的中位数。\n\n如果没有基因在所有样本中都表达（这在稀疏数据中很常见，如测试用例 2），此方法将失败。指定的回退方法是总计数归一化。在这种情况下，样本的大小因子是其总读数。最后，估计出的大小因子集 $\\{s_i\\}$ 被缩放以使均值为 $1$，从而保持计数尺度。然后，归一化计数被计算为 $Y_{g,i} / s_i$。\n\n**3. 离散度估计**\n\n负二项分布 $\\operatorname{NB}(\\mu, \\phi)$ 的方差取决于均值 $\\mu$ 和离散度参数 $\\phi$，关系为 $\\operatorname{Var}(Y) = \\mu + \\phi \\mu^2$。准确估计 $\\phi$至关重要。这通过三个子步骤实现：\n- **原始离散度**：对每个基因 $g$，使用矩量法在归一化计数上估计一个原始离散度 $\\hat{\\phi}_g$。计算样本均值 $\\hat{m}_g$ 和方差 $\\hat{v}_g$，则离散度为 $\\hat{\\phi}_g = \\max\\{0, (\\hat{v}_g - \\hat{m}_g) / \\hat{m}_g^2\\}$。\n- **趋势拟合**：来自小样本量的单个基因离散度估计是有噪声的。通过对离散度与平均表达量之间的普遍关系进行建模，可以找到一个更稳定的估计。使用普通最小二乘法将形式为 $\\phi_{\\mathrm{trend}}(\\hat{m}_g) = a + b/\\hat{m}_g$ 的趋势函数拟合到所有基因的 $(\\hat{m}_g, \\hat{\\phi}_g)$ 数据对上。\n- **收缩**：每个基因的最终稳定离散度估计 $\\tilde{\\phi}_g$ 是其原始估计 $\\hat{\\phi}_g$ 和趋势值 $\\phi_{\\mathrm{trend}}(\\hat{m}_g)$ 的加权平均值。这将噪声较大的单个估计值“收缩”到更稳定的趋势上。凸组合为 $\\tilde{\\phi}_{g} = \\alpha \\phi_{\\mathrm{trend}}(\\hat{m}_g) + (1-\\alpha) \\hat{\\phi}_{g}$。权重 $\\alpha$ 取决于样本数 $S$，随着样本量的增加，给予原始估计更多的信任。我们使用 $\\alpha = k/(k+S)$，其中先验强度参数为 $k=4$。\n\n**4. 每个基因的效应和 Wald 统计量**\n\n目标是量化两种条件（例如，处理组 vs. 对照组）之间的表达变化。\n- **对数倍数变化 (LFC)**：为对照组 ($\\hat{\\mu}_{g,0}$) 和处理组 ($\\hat{\\mu}_{g,1}$) 计算归一化计数的每个基因的均值。效应大小是对数倍数变化，$\\widehat{\\mathrm{LFC}}_{g} = \\log_e(\\hat{\\mu}_{g,1} / \\hat{\\mu}_{g,0})$。为防止在组均值为 $0$ 时出现除以零或取零的对数的情况，在计算前向每个均值添加一个小的常数 $\\epsilon = 10^{-8}$。\n- **LFC 方差和 Wald 统计量**：LFC 的显著性通过 Wald 检验进行评估。LFC 估计量的方差使用 delta 方法和负二项方差函数近似得出：\n$$\n\\widehat{\\operatorname{Var}}(\\widehat{\\mathrm{LFC}}_{g}) \\approx \\frac{1/\\hat{\\mu}_{g,1} + \\tilde{\\phi}_{g}}{n_{1}} + \\frac{1/\\hat{\\mu}_{g,0} + \\tilde{\\phi}_{g}}{n_{0}}\n$$\n其中 $n_0$ 和 $n_1$ 分别是对照组和处理组的样本数。然后 Wald 统计量为 $Z_g = \\widehat{\\mathrm{LFC}}_{g} / \\sqrt{\\widehat{\\operatorname{Var}}(\\widehat{\\mathrm{LFC}}_{g})}$。该统计量作为 GSEA 的排序度量。如果方差为零，则将 $Z_g$ 设为 $0$。\n\n**5. 基因集富集分析 (GSEA)**\n\nGSEA 判断一个预定义的基因集 $S$ 是否在两种条件之间显示出统计上显著且一致的差异。\n- **排序**：所有过滤后的基因根据其 Wald 统计量 $Z_g$ 进行降序排列。\n- **运行总和**：通过遍历排序列表计算一个运行总和。对于在基因集 $S$ 中的每个基因，总和增加；对于不在集中的每个基因，总和减少。步长是加权的。对于基因 $g \\in S$，增量与其分数成正比，即 $|Z_g|^p$（其中 $p=1$），并由 $S$ 中所有基因的权重总和进行归一化。对于基因 $g \\notin S$，减量是一个常数 $1 / (G_{filt} - |S_{filt}|)$，其中 $G_{filt}$ 是过滤后的基因总数，|S_{filt}| 是过滤后的基因集大小。\n- **富集分数 (ES)**：ES 是运行总和偏离零的最大偏差。它是有符号的，取正向最大偏差或负向最大偏差的绝对值较大者。该分数反映了基因集 $S$ 在所有基因的排序列表的顶部或底部的富集程度。\n\n将此完整的流程应用于每个测试用例，以计算最终的富集分数。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis pipeline on the provided test cases.\n    \"\"\"\n\n    def run_pipeline(counts_matrix, condition_vector, gene_set):\n        \"\"\"\n        Executes the full GSEA pipeline for a single test case.\n        \"\"\"\n        # Data setup\n        counts = np.array(counts_matrix).T  # Transpose to get Genes x Samples\n        conditions = np.array(condition_vector)\n        # Convert 1-based gene set to 0-based for Python indexing\n        gene_set_indices = {g - 1 for g in gene_set}\n        \n        # Step 1: Filtering based on detectability\n        min_samples_positive = 2\n        min_total_count = 2  # A reasonable assumption for the provided sparse data\n        \n        positive_samples_per_gene = np.sum(counts > 0, axis=1)\n        total_counts_per_gene = np.sum(counts, axis=1)\n        \n        keep_mask = (positive_samples_per_gene >= min_samples_positive) & (total_counts_per_gene >= min_total_count)\n        \n        filtered_counts = counts[keep_mask]\n        \n        if filtered_counts.shape[0] == 0:\n            return 0.0\n\n        original_indices = np.where(keep_mask)[0]\n        gene_map = {orig_idx: new_idx for new_idx, orig_idx in enumerate(original_indices)}\n        filtered_gene_set = {gene_map[g_idx] for g_idx in gene_set_indices if g_idx in gene_map}\n\n        G_filt, S = filtered_counts.shape\n        \n        # Step 2: Library size normalization\n        genes_all_nonzero_mask = np.all(filtered_counts > 0, axis=1)\n        \n        if np.any(genes_all_nonzero_mask):\n            # Median-of-ratios method\n            pseudo_ref_table = filtered_counts[genes_all_nonzero_mask, :]\n            geo_means = np.exp(np.mean(np.log(pseudo_ref_table), axis=1))\n            \n            # Prevent division by zero if a geo_mean is zero\n            geo_means[geo_means == 0] = 1e-9\n\n            # Ratios are S x num_ref_genes\n            ratios = pseudo_ref_table.T / geo_means\n            size_factors_raw = np.median(ratios, axis=1)\n        else:\n            # Fallback to total-count normalization using original pre-filter counts\n            size_factors_raw = np.sum(counts, axis=0)\n            \n        # Standardize size factors to have a mean of 1\n        size_factors = size_factors_raw / np.mean(size_factors_raw)\n        \n        normalized_counts = filtered_counts / size_factors[np.newaxis, :]\n        \n        # Step 3: Dispersion estimation\n        means_g = np.mean(normalized_counts, axis=1)\n        # ddof=1 for unbiased sample variance\n        vars_g = np.var(normalized_counts, axis=1, ddof=1)\n        \n        # Raw dispersion\n        phi_raw = np.zeros_like(means_g)\n        idx_mean_pos = means_g > 0\n        phi_raw[idx_mean_pos] = (vars_g[idx_mean_pos] - means_g[idx_mean_pos]) / (means_g[idx_mean_pos]**2)\n        phi_raw[phi_raw < 0] = 0\n        \n        # Trend fitting\n        phi_trend = np.zeros_like(means_g)\n        fit_idx = idx_mean_pos & np.isfinite(phi_raw)\n        if np.sum(fit_idx) >= 2:\n            means_for_fit = means_g[fit_idx]\n            phi_for_fit = phi_raw[fit_idx]\n            \n            X_fit = np.vstack([np.ones(means_for_fit.shape[0]), 1 / means_for_fit]).T\n            try:\n                coeffs, _, _, _ = np.linalg.lstsq(X_fit, phi_for_fit, rcond=None)\n                a, b = coeffs\n                phi_trend = a + b / means_g\n                phi_trend[phi_trend < 0] = 0\n            except np.linalg.LinAlgError:\n                positive_phi_raw = phi_raw[phi_raw > 0]\n                median_phi = np.median(positive_phi_raw) if len(positive_phi_raw) > 0 else 0.01\n                phi_trend[:] = median_phi\n        else:\n           positive_phi_raw = phi_raw[phi_raw > 0]\n           median_phi = np.median(positive_phi_raw) if len(positive_phi_raw) > 0 else 0.01\n           phi_trend[:] = median_phi\n\n        # Shrinkage\n        k = 4.0 # Prior strength parameter assumption\n        alpha = k / (k + S)\n        phi_shrunk = alpha * phi_trend + (1 - alpha) * phi_raw\n        phi_shrunk[phi_shrunk < 0] = 0\n\n        # Step 4: Per-gene effect and Wald statistic\n        cond0_mask = conditions == 0\n        cond1_mask = conditions == 1\n        n0, n1 = np.sum(cond0_mask), np.sum(cond1_mask)\n        \n        mu_g0 = np.mean(normalized_counts[:, cond0_mask], axis=1)\n        mu_g1 = np.mean(normalized_counts[:, cond1_mask], axis=1)\n        \n        epsilon = 1e-8 # Small constant for numerical stability\n        LFC = np.log((mu_g1 + epsilon) / (mu_g0 + epsilon))\n        \n        var_LFC = ((1 / (mu_g1 + epsilon) + phi_shrunk) / n1) + \\\n                  ((1 / (mu_g0 + epsilon) + phi_shrunk) / n0)\n        \n        Z_scores = np.zeros_like(LFC)\n        valid_var_mask = var_LFC > 0\n        Z_scores[valid_var_mask] = LFC[valid_var_mask] / np.sqrt(var_LFC[valid_var_mask])\n\n        # Step 5: Gene Set Enrichment Analysis\n        if len(filtered_gene_set) == 0 or len(filtered_gene_set) == G_filt:\n            return 0.0\n\n        in_set_mask = np.zeros(G_filt, dtype=bool)\n        if filtered_gene_set:\n            in_set_mask[list(filtered_gene_set)] = True\n\n        abs_Z = np.abs(Z_scores)\n        sum_weights_in_set = np.sum(abs_Z[in_set_mask])\n        \n        if sum_weights_in_set == 0:\n            return 0.0\n\n        sorted_indices = np.argsort(Z_scores)[::-1]\n        \n        is_in_set_sorted = in_set_mask[sorted_indices]\n        abs_Z_sorted = abs_Z[sorted_indices]\n        \n        step_hit = abs_Z_sorted / sum_weights_in_set\n        step_miss = 1.0 / (G_filt - len(filtered_gene_set))\n        \n        running_sum = 0.0\n        running_sum_values = [0.0]\n        \n        for i in range(G_filt):\n            if is_in_set_sorted[i]:\n                running_sum += step_hit[i]\n            else:\n                running_sum -= step_miss\n            running_sum_values.append(running_sum)\n            \n        max_rs = np.max(running_sum_values)\n        min_rs = np.min(running_sum_values)\n\n        return max_rs if abs(max_rs) > abs(min_rs) else min_rs\n            \n    test_cases = [\n        {\n            \"counts\": [\n                [40, 55, 20, 18, 22, 60, 35, 25, 45, 50, 28, 30],\n                [42, 53, 19, 20, 20, 58, 36, 24, 46, 51, 30, 32],\n                [39, 57, 18, 19, 21, 62, 34, 26, 44, 49, 29, 31],\n                [41, 56, 36, 40, 44, 61, 37, 50, 45, 52, 55, 33],\n                [43, 54, 35, 39, 43, 59, 38, 49, 47, 53, 54, 34],\n                [40, 58, 34, 41, 45, 63, 36, 51, 46, 50, 56, 35]\n            ],\n            \"conditions\": [0, 0, 0, 1, 1, 1],\n            \"gene_set\": {3, 4, 5, 8, 11}\n        },\n        {\n            \"counts\": [\n                [0, 0, 1, 0, 2, 1, 0, 0, 0, 1],\n                [0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n                [0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n                [1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n            ],\n            \"conditions\": [0, 0, 1, 1],\n            \"gene_set\": {2, 5, 9}\n        },\n        {\n            \"counts\": [\n                [30, 45, 60, 55, 50, 40, 35, 20, 25, 18, 22, 28],\n                [31, 44, 62, 57, 49, 39, 36, 21, 26, 19, 23, 29],\n                [32, 46, 61, 56, 51, 41, 34, 22, 27, 17, 24, 30],\n                [29, 47, 63, 54, 52, 42, 33, 23, 28, 20, 21, 27],\n                [15, 45, 30, 28, 26, 40, 35, 20, 25, 18, 22, 28],\n                [16, 44, 31, 29, 27, 39, 36, 21, 26, 19, 23, 29]\n            ],\n            \"conditions\": [0, 0, 0, 0, 1, 1],\n            \"gene_set\": {1, 3, 4, 5}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_pipeline(case[\"counts\"], case[\"conditions\"], case[\"gene_set\"])\n        results.append(result)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```"
        }
    ]
}