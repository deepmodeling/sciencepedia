{
    "hands_on_practices": [
        {
            "introduction": "主成分的解释始于理解它代表了哪些原始变量。本练习将重点探讨如何利用载荷的平方来定量地分解一个主成分的方差，并了解模型捕获了每个原始变量多大比例的方差 。掌握这项基本技能，是将抽象的数学成分转化为有意义的生物学或临床解释的关键一步。",
            "id": "5220656",
            "problem": "用于精准医疗的人工智能 (AI) 临床特征提取流程考虑了三个标准化的实验室变量：空腹血糖 $x_{1}$、甘油三酯 $x_{2}$ 和高密度脂蛋白胆固醇 $x_{3}$。对样本相关系数矩阵执行主成分分析 (PCA; Principal Component Analysis)，产生一个到不相关成分的正交变换，这些成分的方差等于其特征值。保留了两个成分，其特征值为 $\\lambda_{1} = 1.8$ 和 $\\lambda_{2} = 0.9$。保留成分的载荷矩阵为\n$$\nL = \\begin{pmatrix}\n\\sqrt{0.9} & 0 \\\\\n\\frac{\\sqrt{1.8}}{2} & \\sqrt{0.45} \\\\\n\\frac{\\sqrt{1.8}}{2} & -\\sqrt{0.45}\n\\end{pmatrix},\n$$\n其中条目 $L_{ij}$ 是变量 $x_{i}$ 在成分 $j$ 上的载荷。\n\n从 PCA 的核心定义出发，即相关系数矩阵使用标准正交特征向量的正交谱分解，以及每个成分的方差等于其特征值的性质，推导如何量化：\n- 使用载荷平方，第一个保留成分的方差中可归因于 $x_{1}$ 的比例，以及\n- $x_{1}$ 在两个保留成分上的累积共同度，表示为载荷平方和。\n\n然后计算 $x_{1}$ 在保留成分上的累积共同度。将最终答案表示为无单位的小数。无需四舍五入。",
            "solution": "问题要求推导与主成分分析 (PCA) 相关的两个量，并进行后续计算。这些推导的基础在于主成分的定义、它们的方差（特征值）以及原始变量在这些成分上的载荷。我们首先将这些核心概念形式化。\n\n设标准化原始变量由向量 $X = (x_1, x_2, x_3)^T$ 表示，其中对于每个变量 $x_i$，均值为 $0$，方差为 $1$。分析在 $3 \\times 3$ 的样本相关系数矩阵 $R$ 上进行。主成分 $y_j$ 是原始变量的线性组合。第 $j$ 个主成分由 $y_j = e_{1j}x_1 + e_{2j}x_2 + e_{3j}x_3 = e_j^T X$ 给出，其中 $e_j$ 是 $R$ 的第 $j$ 个标准正交特征向量。第 $j$ 个成分的方差等于相应的特征值 $\\lambda_j$，因此 $\\text{Var}(y_j) = \\lambda_j$。\n\n变量 $x_i$ 在成分 $y_j$ 上的载荷，记作 $L_{ij}$，定义为它们的相关系数：$L_{ij} = \\text{Corr}(x_i, y_j)$。这可以用特征向量和特征值来表示。\n$$\nL_{ij} = \\text{Corr}(x_i, y_j) = \\frac{\\text{Cov}(x_i, y_j)}{\\sqrt{\\text{Var}(x_i) \\text{Var}(y_j)}}\n$$\n由于变量是标准化的，$\\text{Var}(x_i) = 1$。成分方差为 $\\text{Var}(y_j) = \\lambda_j$。协方差为 $\\text{Cov}(x_i, y_j) = \\text{Cov}(x_i, \\sum_{k=1}^3 e_{kj}x_k) = \\sum_{k=1}^3 e_{kj} \\text{Cov}(x_i, x_k)$。由于 $\\text{Cov}(x_i, x_k) = R_{ik}$，这变为 $\\sum_{k=1}^3 R_{ik} e_{kj}$，即向量 $R e_j$ 的第 $i$ 个元素。因为 $e_j$ 是 $R$ 的一个特征向量，我们有 $R e_j = \\lambda_j e_j$。因此，$\\text{Cov}(x_i, y_j) = \\lambda_j e_{ij}$。\n将这些代回相关公式，得到载荷的基本关系：\n$$\nL_{ij} = \\frac{\\lambda_j e_{ij}}{\\sqrt{1 \\cdot \\lambda_j}} = e_{ij}\\sqrt{\\lambda_j}\n$$\n\n**成分方差比例的推导**\n\n任务的第一部分是推导如何量化第一个保留成分 ($y_1$) 的方差中可归因于变量 $x_1$ 的比例。成分 $y_1$ 的总方差是 $\\lambda_1$。我们需要展示这个方差是如何在原始变量之间分配的。\n\n让我们对一个给定成分 $j$ 在所有变量 $i = 1, 2, 3$ 上的载荷平方求和：\n$$\n\\sum_{i=1}^3 L_{ij}^2 = \\sum_{i=1}^3 (e_{ij}\\sqrt{\\lambda_j})^2 = \\sum_{i=1}^3 e_{ij}^2 \\lambda_j = \\lambda_j \\sum_{i=1}^3 e_{ij}^2\n$$\n向量 $e_j = (e_{1j}, e_{2j}, e_{3j})^T$ 是一个单位长度的特征向量，这意味着它是归一化的：$\\|e_j\\|^2 = e_{1j}^2 + e_{2j}^2 + e_{3j}^2 = 1$。\n因此，我们得到恒等式：\n$$\n\\sum_{i=1}^3 L_{ij}^2 = \\lambda_j \\cdot 1 = \\lambda_j\n$$\n这个恒等式表明，一个主成分 $j$ 的载荷平方和等于其方差 $\\lambda_j$。这提供了对成分方差的自然分解。$L_{ij}^2$ 项被解释为变量 $x_i$ 对成分 $y_j$ 总方差的贡献。\n\n因此，成分 $y_j$ 的方差中可归因于变量 $x_i$ 的比例是此贡献与总方差的比率：\n$$\n\\text{Fraction for } x_i \\text{ in } y_j = \\frac{L_{ij}^2}{\\lambda_j}\n$$\n对于所要求的特定情况——$x_1$ 在第一个成分 $y_1$ 中的比例——我们设置 $i=1$ 和 $j=1$：\n$$\n\\text{Fraction for } x_1 \\text{ in } y_1 = \\frac{L_{11}^2}{\\lambda_1}\n$$\n这就完成了第一个要求的推导。\n\n**累积共同度的推导**\n\n任务的第二部分是推导 $x_1$ 在两个保留成分上的累积共同度的量化方法。一个变量的共同度是其方差中能被一组保留成分所解释的比例。由于变量是标准化的，$\\text{Var}(x_i) = 1$。\n\n特征向量集合 $\\{e_1, e_2, e_3\\}$ 构成一个标准正交基。我们可以将原始变量 $x_i$ 表示为主成分 $y_j$ 的线性组合。变换为 $Y = E^T X$，其中 $E$ 是以特征向量 $e_j$ 为列的矩阵。由于 $E$ 是正交的（$E^T = E^{-1}$），逆变换为 $X = E Y$。对于特定变量 $x_i$，这表示为：\n$$\nx_i = \\sum_{j=1}^3 E_{ij} y_j = \\sum_{j=1}^3 e_{ij} y_j\n$$\n$x_i$ 的方差可以从此表达式计算得出。由于主成分 $y_j$ 是不相关的，和的方差等于方差的和：\n$$\n\\text{Var}(x_i) = \\text{Var}\\left(\\sum_{j=1}^3 e_{ij} y_j\\right) = \\sum_{j=1}^3 \\text{Var}(e_{ij} y_j) = \\sum_{j=1}^3 e_{ij}^2 \\text{Var}(y_j) = \\sum_{j=1}^3 e_{ij}^2 \\lambda_j\n$$\n使用关系 $L_{ij}^2 = e_{ij}^2 \\lambda_j$，我们可以将其重写为：\n$$\n\\text{Var}(x_i) = \\sum_{j=1}^3 L_{ij}^2\n$$\n由于 $\\text{Var}(x_i) = 1$，我们有恒等式 $1 = \\sum_{j=1}^3 L_{ij}^2$。这表明一个标准化变量的总方差是其在所有主成分上的载荷平方和。\n\n一个变量 $x_i$ 在一组 $k$ 个保留成分上的累积共同度是其方差中由这些成分解释的部分。这即为相应载荷平方的和。对于 $k=2$ 个保留成分， $x_i$ 的累积共同度是：\n$$\nh_i^2 = \\sum_{j=1}^2 L_{ij}^2 = L_{i1}^2 + L_{i2}^2\n$$\n对于变量 $x_1$ 的特定情况，其在两个保留成分上的累积共同度是：\n$$\nh_1^2 = L_{11}^2 + L_{12}^2\n$$\n这就完成了第二个要求的推导。\n\n**$x_1$ 的累积共同度的计算**\n\n我们被要求计算 $x_1$ 在两个保留成分上的累积共同度。根据上面的推导，这个量是 $h_1^2 = L_{11}^2 + L_{12}^2$。\n问题给出了两个保留成分的载荷矩阵：\n$$\nL = \\begin{pmatrix}\n\\sqrt{0.9} & 0 \\\\\n\\frac{\\sqrt{1.8}}{2} & \\sqrt{0.45} \\\\\n\\frac{\\sqrt{1.8}}{2} & -\\sqrt{0.45}\n\\end{pmatrix}\n$$\n第一行中的条目对应于变量 $x_1$。因此，我们有：\n-   $L_{11}$，即 $x_1$ 在第一个成分上的载荷，是 $\\sqrt{0.9}$。\n-   $L_{12}$，即 $x_1$ 在第二个成分上的载荷，是 $0$。\n\n将这些值代入共同度公式：\n$$\nh_1^2 = (\\sqrt{0.9})^2 + (0)^2 = 0.9 + 0 = 0.9\n$$\n$x_1$ 在两个保留成分上的累积共同度是 $0.9$。这意味着空腹血糖 ($x_1$) 的方差中有 $90\\%$ 被前两个主成分所解释。",
            "answer": "$$\\boxed{0.9}$$"
        },
        {
            "introduction": "在解释保留的主成分*捕获*了什么信息之后，理解它们*错过*了什么同样重要。本练习将深入探讨重建误差的概念，它量化了从低维PCA模型中近似重建原始数据的程度 。为一个新的数据点计算此误差，为我们提供了一个衡量模型保真度和降维过程中信息损失的具体指标。",
            "id": "5220668",
            "problem": "一个研究团队正在为一个肿瘤学影像数据集构建一个降维模型，其中每位患者由从计算机断层扫描纹理分析中提取的 $p=3$ 个标准化定量特征表示。设训练集已均值中心化，并假设中心化后的训练数据的经验样本协方差矩阵为\n$$\nS \\;=\\; \\begin{pmatrix}\n2 & 1 & 0 \\\\\n1 & 2 & 0 \\\\\n0 & 0 & 0.5\n\\end{pmatrix}.\n$$\n该团队应用主成分分析（PCA），并保留 $k=2$ 个主成分来构建一个秩为 $k$ 的模型。一位新患者的特征向量为 $x_{\\text{new}} \\in \\mathbb{R}^3$，该向量已使用训练集的均值进行了中心化：\n$$\nx_{\\text{new}} \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\n从 PCA 的定义（即在单位范数和相互正交性约束下，最大化数据投影方差的正交方向）出发，推导任意中心化观测值在由 $S$ 的前导特征向量张成的 $k$ 维主子空间上的投影得分表达式，并使用此表达式计算 $x_{\\text{new}}$ 在 $k=2$ 模型下的重构误差，该误差定义为平方欧几里得范数\n$$\n\\left\\|\\, x_{\\text{new}} \\;-\\; \\hat{x} \\,\\right\\|_2^2,\n$$\n其中 $\\hat{x}$ 是 $x_{\\text{new}}$ 在主子空间上的正交投影。请以单个实数形式提供您的最终答案。如果任何中间数值计算需要四舍五入，请保留精确形式；最终答案无需四舍五入。",
            "solution": "首先对问题进行验证。\n\n### 步骤 1：提取已知条件\n- 特征数量：$p=3$。\n- 数据已均值中心化。\n- 中心化数据的样本协方差矩阵：\n$$\nS \\;=\\; \\begin{pmatrix}\n2 & 1 & 0 \\\\\n1 & 2 & 0 \\\\\n0 & 0 & 0.5\n\\end{pmatrix}\n$$\n- 保留的主成分数量：$k=2$。\n- 新的中心化观测值：\n$$\nx_{\\text{new}} \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}\n$$\n- 目标是计算重构误差，定义为平方欧几里得范数 $\\| x_{\\text{new}} - \\hat{x} \\|_2^2$，其中 $\\hat{x}$ 是 $x_{\\text{new}}$ 在 $k=2$ 维主子空间上的正交投影。\n- 推导必须从 PCA 的定义开始。\n\n### 步骤 2：使用提取的已知条件进行验证\n评估问题的有效性。\n- **科学依据：** 问题涉及主成分分析（PCA），这是线性代数和统计学中的一个标准和基础技术。提供的样本协方差矩阵 $S$ 是对称的。要成为一个有效的协方差矩阵，它还必须是半正定的。通过计算其特征值来检验这一点。特征方程为 $\\det(S - \\lambda I) = 0$：\n$$\n\\det \\begin{pmatrix}\n2-\\lambda & 1 & 0 \\\\\n1 & 2-\\lambda & 0 \\\\\n0 & 0 & 0.5-\\lambda\n\\end{pmatrix} = (0.5-\\lambda)\\left[(2-\\lambda)^2 - 1\\right] = (0.5-\\lambda)(\\lambda^2 - 4\\lambda + 3) = (0.5-\\lambda)(\\lambda-3)(\\lambda-1) = 0.\n$$\n特征值为 $\\lambda = 3$, $\\lambda = 1$ 和 $\\lambda = 0.5$。由于所有特征值均为正，矩阵 $S$ 是正定的，因此是一个有效的协方差矩阵。\n- **适定性：** 问题提供了计算唯一重构误差所需的所有信息（$S$, $x_{\\text{new}}$, $k$）。\n- **客观性：** 问题以精确的数学语言陈述，没有歧义或主观声明。\n\n### 步骤 3：结论与行动\n该问题具有科学有效性、自洽性和适定性。将推导解答。\n\n### 解题推导\n\n主成分分析（PCA）旨在找到一组称为主成分的正交基向量，这些向量依次最大化数据在其上投影的方差。设 $v \\in \\mathbb{R}^p$ 为单位范数方向向量，$\\|v\\|_2 = 1$。对于一组均值中心化的数据点 $\\{x_i\\}$，数据在 $v$ 上投影的方差由得分 $x_i^T v$ 的样本方差给出。由于数据是均值中心化的，$E[x_i]=0$，所以 $E[x_i^T v] = E[x_i]^T v = 0$。方差为：\n$$\n\\text{Var}(x^T v) = E[(x^T v)^2] = E[v^T x x^T v] = v^T E[x x^T] v.\n$$\n$E[x x^T]$ 的样本估计是样本协方差矩阵 $S$。第一个主成分 $v_1$ 的优化问题是最大化这个投影方差：\n$$\n\\max_{v} \\quad v^T S v \\quad \\text{约束条件为} \\quad v^T v = 1.\n$$\n这个约束优化问题可以使用拉格朗日乘子 $\\lambda$ 来解决。我们定义拉格朗日函数 $\\mathcal{L}(v, \\lambda) = v^T S v - \\lambda(v^T v - 1)$。对 $v$ 求梯度并令其为零，得到：\n$$\n\\nabla_v \\mathcal{L} = 2Sv - 2\\lambda v = 0 \\implies Sv = \\lambda v.\n$$\n这是矩阵 $S$ 的标准特征值问题。$v$ 的解是 $S$ 的特征向量，投影方差是对应的特征值 $\\lambda$。为了最大化方差，第一个主成分 $v_1$ 是对应于最大特征值 $\\lambda_1$ 的特征向量。第二个主成分 $v_2$ 是对应于第二大特征值 $\\lambda_2$ 的特征向量，依此类推。对称矩阵的特征向量是正交的（或可以选择为正交的），满足相互正交性约束。\n\n任意中心化观测值 $x$ 在第 $j$ 个主成分 $v_j$ 上的投影得分是标量投影：\n$$\nz_j = x^T v_j.\n$$\n这是推导出的投影得分表达式。前 $k$ 个成分的得分向量是 $z = (z_1, \\dots, z_k)^T$。\n\n向量 $x$ 在由前导特征向量 $\\{v_1, \\dots, v_k\\}$ 张成的 $k$ 维主子空间上的投影是重构向量 $\\hat{x}$。它是由这些基向量以得分为系数的线性组合构成的：\n$$\n\\hat{x} = \\sum_{j=1}^{k} (x^T v_j) v_j.\n$$\n完整的向量 $x$ 可以在所有 $p$ 个特征向量构成的完备正交基中表示为 $x = \\sum_{j=1}^{p} (x^T v_j) v_j$。重构误差向量是原始向量与其投影之间的差：\n$$\nx - \\hat{x} = \\sum_{j=1}^{p} (x^T v_j) v_j - \\sum_{j=1}^{k} (x^T v_j) v_j = \\sum_{j=k+1}^{p} (x^T v_j) v_j.\n$$\n重构误差是该误差向量的平方欧几里得范数。由于特征向量 $\\{v_j\\}$ 的正交性，毕达哥拉斯定理适用：\n$$\n\\| x - \\hat{x} \\|_2^2 = \\left\\| \\sum_{j=k+1}^{p} (x^T v_j) v_j \\right\\|_2^2 = \\sum_{j=k+1}^{p} (x^T v_j)^2 \\|v_j\\|_2^2 = \\sum_{j=k+1}^{p} (x^T v_j)^2.\n$$\n重构误差是在被舍弃的主成分上的投影得分的平方和。\n\n现在，我们将此应用于给定的问题。首先，我们求 $S$ 的特征向量。特征值按降序排列为 $\\lambda_1 = 3$, $\\lambda_2 = 1$ 和 $\\lambda_3 = 0.5$。\n\n对应于 $\\lambda_1 = 3$ 的特征向量：\n$(S - 3I)v = 0 \\implies \\begin{pmatrix} -1 & 1 & 0 \\\\ 1 & -1 & 0 \\\\ 0 & 0 & -2.5 \\end{pmatrix}v = 0$。这得到 $-v_1+v_2=0$ 和 $v_3=0$。所以 $v_1=v_2$。归一化后，$v_1 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{2} \\\\ 0 \\end{pmatrix}$。\n\n对应于 $\\lambda_2 = 1$ 的特征向量：\n$(S - 1I)v = 0 \\implies \\begin{pmatrix} 1 & 1 & 0 \\\\ 1 & 1 & 0 \\\\ 0 & 0 & -0.5 \\end{pmatrix}v = 0$。这得到 $v_1+v_2 = 0$ 和 $v_3=0$。归一化后，$v_2 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ -1/\\sqrt{2} \\\\ 0 \\end{pmatrix}$。\n\n对应于 $\\lambda_3 = 0.5$ 的特征向量：\n$(S - 0.5I)v = 0 \\implies \\begin{pmatrix} 1.5 & 1 & 0 \\\\ 1 & 1.5 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}v = 0$。这得到 $1.5v_1+v_2 = 0$ 和 $v_1+1.5v_2=0$，这意味着 $v_1=0$ 和 $v_2=0$。$v_3$ 是自由变量。归一化后，$v_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$。\n\n特征向量为：\n$v_1 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ 1/\\sqrt{2} \\\\ 0 \\end{pmatrix}$， $v_2 = \\begin{pmatrix} 1/\\sqrt{2} \\\\ -1/\\sqrt{2} \\\\ 0 \\end{pmatrix}$， $v_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$。\n\n模型保留 $k=2$ 个成分，所以主子空间由 $\\{v_1, v_2\\}$ 张成。被舍弃的成分是 $v_3$。\n$x_{\\text{new}}$ 的重构误差由其在被舍弃的成分 $v_3$ 上的投影得分的平方给出：\n$$\n\\| x_{\\text{new}} - \\hat{x} \\|_2^2 = (x_{\\text{new}}^T v_3)^2.\n$$\n给定 $x_{\\text{new}} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}$。我们计算得分 $z_3 = x_{\\text{new}}^T v_3$：\n$$\nz_3 = \\begin{pmatrix} 1 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = (1)(0) + (0)(0) + (1)(1) = 1.\n$$\n因此，重构误差为：\n$$\n\\| x_{\\text{new}} - \\hat{x} \\|_2^2 = (1)^2 = 1.\n$$",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "在将PCA应用于纵向或多被试神经科学数据时，一个主要挑战是主成分的符号模糊性。本练习直面这一关键问题，通过实施一种标准方法，即使用锚向量来对齐成分的方向 。掌握这项技术对于在不同会话或条件下对神经群体动态进行有意义且可复现的比较至关重要。",
            "id": "4172070",
            "problem": "您正在分析多会话神经元群体记录，并对跨会话的同一组特征应用主成分分析 (PCA)。在神经科学数据分析中，主成分分析 (PCA) 产生的主成分载荷向量的方向仅在符号上不确定，这意味着如果 $v$ 是一个主成分载荷向量，那么 $-v$ 代表相同的子空间并解释相同的方差。这种符号不确定性阻碍了跨会话的解释，除非强制执行一致的方向约定。一个常见且有科学依据的约定是通过要求每个主成分与一个可解释的锚向量的内积为非负来定向它。\n\n从基本原理开始：\n- 特征的经验协方差矩阵 $C \\in \\mathbb{R}^{F \\times F}$ 由中心化外积的样本均值定义，其特征向量是主成分载荷方向。\n- 如果 $u$ 是与特征值 $\\lambda$ 相关联的 $C$ 的一个特征向量，那么 $-u$ 也是与同一特征值 $\\lambda$ 相关联的特征向量。因此，PCA 载荷向量在符号上具有方向模糊性。\n- 内积（点积）编码了 $\\mathbb{R}^{F}$ 中的对齐情况，内积 $w^{\\top} l$ 的符号表示 $l$ 是指向与 $w$ 相同的半空间还是相反的半空间。\n\n对于多个测试用例，您将获得一组会话载荷矩阵和一组定义每个成分期望方向的锚向量。您必须通过翻转任何其与相应锚向量的内积为负的会话成分载荷向量的符号来强制实现跨会话的符号一致性。如果内积等于零，则不进行翻转。对齐后，您必须报告每个测试用例的两个量：在所有会话和成分上执行的符号翻转总次数，以及在所有会话和成分上的最小锚内积值。\n\n定义和符号：\n- 设有 $S$ 个会话，$F$ 个特征和 $K$ 个成分。对于会话 $s \\in \\{0, \\ldots, S-1\\}$，令 $L^{(s)} \\in \\mathbb{R}^{F \\times K}$ 表示载荷矩阵，其第 $k$ 列表示为 $l^{(s)}_{k} \\in \\mathbb{R}^{F}$。\n- 设锚为 $W \\in \\mathbb{R}^{F \\times K}$，其第 $k$ 列表示为 $w_{k} \\in \\mathbb{R}^{F}$。定向规则是：如果 $w_{k}^{\\top} l^{(s)}_{k} < 0$，则将 $l^{(s)}_{k}$ 替换为 $-l^{(s)}_{k}$；如果 $w_{k}^{\\top} l^{(s)}_{k} \\ge 0$，则保持不变。\n- 对齐摘要指标是：\n  1. 整数总翻转次数 $N_{\\text{flip}} = \\sum_{s=0}^{S-1} \\sum_{k=1}^{K} \\mathbf{1}\\{w_{k}^{\\top} l^{(s)}_{k} < 0\\}$。\n  2. 浮点数最小对齐锚内积 $m_{\\min} = \\min_{s,k} w_{k}^{\\top} \\tilde{l}^{(s)}_{k}$，其中 $\\tilde{l}^{(s)}_{k}$ 表示在强制执行规则后可能被翻转的载荷向量。\n\n任务：\n- 实现一个程序，使用提供的测试套件应用上述定向规则。为每个测试用例计算 $N_{\\text{flip}}$ 和 $m_{\\min}$。浮点数 $m_{\\min}$ 必须四舍五入到六位小数。不涉及物理单位。\n\n假设：\n- 跨会话的成分身份已经通过索引 $k$ 匹配，只需强制实现符号一致性。\n- 所有向量和矩阵都是实值的，并且在每个测试用例中特征维度是一致的。\n\n测试套件：\n- 测试用例 1 ($S=2$, $F=4$, $K=2$)：\n  - 会话 0：列 $l^{(0)}_{1}$ 和 $l^{(0)}_{2}$ 在\n    $$\n    L^{(0)} = \\begin{bmatrix}\n    0.8 & -0.2 \\\\\n    0.1 & 0.9 \\\\\n    0.0 & 0.05 \\\\\n    -0.1 & 0.0\n    \\end{bmatrix}.\n    $$\n  - 会话 1：\n    $$\n    L^{(1)} = -L^{(0)} = \\begin{bmatrix}\n    -0.8 & 0.2 \\\\\n    -0.1 & -0.9 \\\\\n    -0.0 & -0.05 \\\\\n    0.1 & -0.0\n    \\end{bmatrix}.\n    $$\n  - 锚（列 $w_{1}$, $w_{2}$）：\n    $$\n    W = \\begin{bmatrix}\n    1 & 0 \\\\\n    0 & 1 \\\\\n    0 & 0 \\\\\n    0 & 0\n    \\end{bmatrix}.\n    $$\n- 测试用例 2 ($S=3$, $F=5$, $K=3$)：\n  - 会话 0：\n    $$\n    L^{(0)} = \\begin{bmatrix}\n    0.5 & 0.0 & 0.0 \\\\\n    0.2 & -0.1 & 0.1 \\\\\n    0.1 & 0.7 & 0.0 \\\\\n    0.0 & 0.2 & 0.6 \\\\\n    0.1 & 0.0 & 0.3\n    \\end{bmatrix}.\n    $$\n  - 会话 1（成分 2 相对于锚被翻转）：\n    $$\n    L^{(1)} = \\begin{bmatrix}\n    0.5 & -0.0 & 0.0 \\\\\n    0.2 & 0.1 & 0.1 \\\\\n    0.1 & -0.7 & 0.0 \\\\\n    0.0 & -0.2 & 0.6 \\\\\n    0.1 & -0.0 & 0.3\n    \\end{bmatrix}.\n    $$\n  - 会话 2（成分 1 和 3 相对于锚被翻转）：\n    $$\n    L^{(2)} = \\begin{bmatrix}\n    -0.5 & 0.0 & -0.0 \\\\\n    -0.2 & -0.1 & -0.1 \\\\\n    -0.1 & 0.7 & -0.0 \\\\\n    -0.0 & 0.2 & -0.6 \\\\\n    -0.1 & 0.0 & -0.3\n    \\end{bmatrix}.\n    $$\n  - 锚：\n    $$\n    W = \\begin{bmatrix}\n    1 & 0 & 0 \\\\\n    0 & 0 & 0 \\\\\n    0 & 1 & 0 \\\\\n    0 & 0 & 1 \\\\\n    0 & 0 & 0\n    \\end{bmatrix}.\n    $$\n- 测试用例 3 ($S=2$, $F=3$, $K=2$)：\n  - 会话 0：\n    $$\n    L^{(0)} = \\begin{bmatrix}\n    1.0 & 0.0 \\\\\n    0.0 & 0.0 \\\\\n    0.0 & 0.9\n    \\end{bmatrix}.\n    $$\n  - 会话 1：\n    $$\n    L^{(1)} = \\begin{bmatrix}\n    -1.0 & 0.0 \\\\\n    -0.0 & 0.0 \\\\\n    -0.0 & -0.9\n    \\end{bmatrix}.\n    $$\n  - 锚：\n    $$\n    W = \\begin{bmatrix}\n    0 & 0 \\\\\n    1 & 0 \\\\\n    0 & 1\n    \\end{bmatrix}.\n    $$\n  在此情况下，请注意对于成分 1，锚内积在任何翻转前后都为 0，因此对于零内积不应进行翻转。\n\n所需输出格式：\n- 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表。对于每个测试用例 $i \\in \\{1,2,3\\}$，按顺序输出两个值：整数 $N_{\\text{flip}}$，后跟四舍五入到六位小数的浮点数 $m_{\\min}$。因此，最后一行总共包含 6 个值，顺序为 $[N_{\\text{flip}}^{(1)}, m_{\\min}^{(1)}, N_{\\text{flip}}^{(2)}, m_{\\min}^{(2)}, N_{\\text{flip}}^{(3)}, m_{\\min}^{(3)}]$。",
            "solution": "该问题在科学和数学上是有效的。它解决了在主成分分析 (PCA) 应用于多会话或多主体数据时的一个基本而实际的问题，即特征向量的符号模糊性。为解决此模糊性而提出的方法——将每个主成分 (PC) 载荷向量相对于预定义的锚向量进行定向——是一种标准、可解释且计算上直接的技术。该问题是适定的，提供了计算唯一解所需的所有必要数据和定义。\n\n核心原理是，对于任何对称矩阵，例如 $F$ 个特征的经验协方差矩阵 $C \\in \\mathbb{R}^{F \\times F}$，如果 $u \\in \\mathbb{R}^F$ 是一个特征值为 $\\lambda$ 的特征向量，那么 $-u$ 也是一个特征值为 $\\lambda$ 的特征向量，因为 $C(-u) = -Cu = -(\\lambda u) = \\lambda(-u)$。PC 载荷向量是 $C$ 的特征向量，因此它们的方向在符号上是任意的。这种模糊性妨碍了在不同数据集（例如，记录会话）之间直接比较载荷向量。\n\n为强制实现一致的方向，我们引入一组锚向量 $W \\in \\mathbb{R}^{F \\times K}$，其中 $K$ 是主成分的数量。$W$ 的每一列 $w_k$ 作为第 $k$ 个 PC 的参考。来自会话 $s$ 的成分 $k$ 的载荷向量 $l_k^{(s)}$ 的方向由其与相应锚向量 $w_k$ 的内积的符号决定。内积 $w_k^\\top l_k^{(s)}$ 衡量了 $l_k^{(s)}$ 在 $w_k$ 上的投影。正号表示在相同大致方向上的对齐，而负号表示在相反方向上的对齐。\n\n规定的定向规则是确保此内积始终为非负：对于每个会话 $s \\in \\{0, \\ldots, S-1\\}$ 和成分 $k \\in \\{1, \\ldots, K\\}$，载荷向量必须满足 $w_k^\\top \\tilde{l}_k^{(s)} \\ge 0$，其中 $\\tilde{l}_k^{(s)}$ 是最终对齐的载荷向量。\n\n实现这一点的算法如下：\n1.  对于每个会话 $s$ 和每个成分 $k$，计算内积 $p_{s,k} = w_k^\\top l_k^{(s)}$。\n2.  严格检查 $p_{s,k}$ 的符号。如果 $p_{s,k} < 0$，则载荷向量 $l_k^{(s)}$ 与其锚未对齐。为纠正这一点，我们翻转其符号。对齐后的向量变为 $\\tilde{l}_k^{(s)} = -l_k^{(s)}$。此操作被计为一次“符号翻转”。新的、对齐后的内积是 $w_k^\\top \\tilde{l}_k^{(s)} = w_k^\\top (-l_k^{(s)}) = -p_{s,k}$，这保证是正的。\n3.  如果 $p_{s,k} \\ge 0$，则载荷向量 $l_k^{(s)}$ 已经正确定向（或与锚正交，在这种情况下其方向不变）。对齐后的向量就是 $\\tilde{l}_k^{(s)} = l_k^{(s)}$，并且不计入翻转次数。对齐后的内积保持为 $p_{s,k}$。\n\n在将此规则应用于所有载荷向量后，我们为每个测试用例计算两个摘要指标：\n1.  符号翻转的总次数 $N_{\\text{flip}}$，是满足条件 $w_k^\\top l\n_k^{(s)} < 0$ 的所有实例的总和：\n    $$\n    N_{\\text{flip}} = \\sum_{s=0}^{S-1} \\sum_{k=1}^{K} \\mathbf{1}\\{w_{k}^{\\top} l^{(s)}_{k} < 0\\}\n    $$\n    其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数，如果其参数为真则等于 1，否则为 0。\n\n2.  最小对齐锚内积 $m_{\\min}$，是在强制执行一致方向后所有内积中的最小值。根据构造，所有对齐后的内积都是非负的。\n    $$\n    m_{\\min} = \\min_{s,k} \\{w_{k}^{\\top} \\tilde{l}^{(s)}_{k}\\}\n    $$\n    该值量化了校正后所有会话中任何成分与其锚之间的“最差情况”对齐程度。\n\n整个过程可以使用矩阵运算高效实现。对于每个会话 $s$，可以通过取矩阵 $W$ 和 $L^{(s)}$ 的逐元素乘积并沿特征维度（轴 0）求和来计算 $K$ 个内积的集合 $\\{w_k^\\top l_k^{(s)}\\}_{k=1}^K$。随后，可以使用一个布尔掩码来识别哪些成分需要翻转，并通过取原始内积的绝对值来计算对齐后的内积。对每个会话重复此过程，并聚合结果以找到 $N_{\\text{flip}}$ 和 $m_{\\min}$。",
            "answer": "[2,0.800000,3,0.500000,1,0.000000]"
        }
    ]
}