{
    "hands_on_practices": [
        {
            "introduction": "掌握奇异值分解（SVD）的第一步是理解其核心计算过程。这个练习旨在通过一个简单的 $2 \\times 2$ 矩阵，让你亲手计算奇异值，从而巩固你对奇异值与矩阵 $A^T A$ 的特征值之间关系的理解。这是后续更复杂应用的基础。",
            "id": "1071366",
            "problem": "计算 $2 \\times 2$ 矩阵\n\n$$\nA = \\begin{bmatrix} 1  1 \\\\ 1  0 \\end{bmatrix}\n$$\n\n的奇异值。\n\n将奇异值用最简根式形式表示，并按降序排列。",
            "solution": "1. $A$ 的奇异值 $\\sigma_i$ 是 $A^T A$ 的特征值的平方根。\n\n2. 计算 $A^T A$：\n$$A^T A = \\begin{bmatrix}1  1\\\\1  0\\end{bmatrix}\\begin{bmatrix}1  1\\\\1  0\\end{bmatrix}\n=\\begin{bmatrix}2  1\\\\1  1\\end{bmatrix}.$$\n\n3. $A^T A$ 的特征多项式是\n$$\\det\\bigl(\\begin{bmatrix}2  1\\\\1  1\\end{bmatrix}-\\lambda I\\bigr)\n=(2-\\lambda)(1-\\lambda)-1\n=\\lambda^2-3\\lambda+1.$$\n\n4. 解方程 $\\lambda^2-3\\lambda+1=0$：\n$$\\lambda=\\frac{3\\pm\\sqrt{9-4}}{2}=\\frac{3\\pm\\sqrt5}{2}.$$\n\n5. 因此，奇异值为\n$$\\sigma_1=\\sqrt{\\frac{3+\\sqrt5}{2}} = \\frac{1+\\sqrt{5}}{2},\\quad\n\\sigma_2=\\sqrt{\\frac{3-\\sqrt5}{2}} = \\frac{\\sqrt{5}-1}{2},$$\n按降序排列。",
            "answer": "$$\\boxed{\\frac{1+\\sqrt{5}}{2},\\ \\frac{\\sqrt{5}-1}{2}}$$"
        },
        {
            "introduction": "奇异值分解的真正力量在于其深刻的几何意义，它揭示了线性变换如何拉伸和旋转空间。这个练习将挑战你区分奇异向量和特征向量的几何直觉，这对于理解 SVD 如何识别数据中最重要的变化方向至关重要，尤其是在处理非对称变换时。通过分析旋转和拉伸等具体变换，你将建立起超越纯代数计算的深刻理解。",
            "id": "3275104",
            "problem": "特征向量和奇异向量之间的一个核心几何差异是：特征向量捕捉的是在线性映射下方向保持不变（仅有尺度变化）的方向，而奇异向量捕捉的是映射拉伸或收缩幅度最大的正交方向。仅使用这些概念基础以及特征向量和奇异值分解 (SVD) 的定义，判断以下哪个选项正确地将一个具体的实 $2 \\times 2$ 矩阵 $A$ 与一个关于其奇异向量与特征向量为何截然不同的合理解释配对。选择所有适用项。\n\nA. $A = \\begin{bmatrix} 0  -1 \\\\ 2  0 \\end{bmatrix}$。理由：$A$ 是一个旋转 $ \\pi/2 $ 和一个各向异性缩放的复合，因此 $A$ 没有实不变方向（没有实特征向量），但其奇异向量是实的、与 $A$ 将单位圆映射成的椭圆的主轴对齐的正交基轴；因此，奇异向量与特征向量截然不同。\n\nB. $A = \\begin{bmatrix} 3  1 \\\\ 1  2 \\end{bmatrix}$。理由：因为 $A$ 有非零的非对角线元素，其奇异向量必定与特征向量无关；几何上，$A$ 由单位圆生成的椭圆，其主轴与特征方向无关，所以这两组方向不同。\n\nC. $A = \\begin{bmatrix} 3  1 \\\\ 0  1 \\end{bmatrix}$。理由：对于任何上三角矩阵，奇异向量都与特征向量重合；几何上，剪切变换不改变由特征方向定义的主轴，因此没有差异。\n\nD. $A = \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix}$。理由：$A$ 是一个纯旋转 $ \\pi/2 $，因此它没有实特征向量，而其奇异向量构成一个实正交基，因为单位圆的像是其自身；因此，奇异向量和特征向量截然不同。\n\n你的答案应指出所有且仅有那些提供了正确示例和正确几何解释的选项。",
            "solution": "经评估，问题陈述是有效的。它科学地基于线性代数原理，是适定且客观的。它为严谨的分析提供了充分的信息。\n\n问题的核心在于实 $2 \\times 2$ 矩阵 $A$ 的特征向量和奇异向量之间的几何区别。\n矩阵 $A$ 的一个特征向量 $v$ 是一个非零向量，满足方程 $Av = \\lambda v$，其中 $\\lambda$ 是某个标量特征值。几何上，$A$ 对特征向量 $v$ 的作用是将其按因子 $\\lambda$ 进行拉伸或收缩，而不改变其方向。$v$ 的方向是变换 $A$ 下的一个不变子空间。对于实矩阵 $A$，对应于实特征值的特征向量是表示这些不变方向的实向量。\n\n矩阵 $A$ 的奇异值分解 (SVD) 形式为 $A = U\\Sigma V^T$，其中 $U$ 和 $V$ 是正交矩阵，$\\Sigma$ 是一个对角矩阵，其对角线上的非负元素称为奇异值。$V$ 的列是右奇异向量，$U$ 的列是左奇异向量。几何上，右奇异向量 $\\{v_i\\}$ 构成定义域中的一个标准正交基，$A$ 将其映射到值域中的一组正交向量 $\\{u_i \\sigma_i\\}$。左奇异向量 $\\{u_i\\}$ 是这些结果向量的方向。因此，奇异向量 $v_i$ 确定了单位球面在 $A$ 映射下形成的椭球体的主轴。奇异值 $\\sigma_i$ 表示这些半轴的长度。右奇异向量是对称矩阵 $A^T A$ 的特征向量，左奇异向量是对称矩阵 $A A^T$ 的特征向量。作为实对称矩阵的特征向量，奇异向量总是实的，并且可以选择为标准正交的。\n\n当 $A$ 不是正规矩阵（$A^T A \\neq A A^T$）时，特征向量和奇异向量之间会出现显著差异。对于正规矩阵，特征向量构成一个标准正交集，并与奇异向量密切相关。特别地，对于实对称矩阵（$A=A^T$），特征向量就是奇异向量。对于一般的非正规矩阵，特征向量不一定是正交的，并且它们可能与奇异向量不同。此外，一个实矩阵可以有复特征值和复特征向量，这意味着它没有实不变方向。然而，其奇异向量总是实的。\n\n我们现在评估每个选项。\n\n**选项 A：** $A = \\begin{bmatrix} 0  -1 \\\\ 2  0 \\end{bmatrix}$。理由：$A$ 是一个旋转 $\\pi/2$ 和一个各向异性缩放的复合，因此 $A$ 没有实不变方向（没有实特征向量），但其奇异向量是实的、与 $A$ 将单位圆映射成的椭圆的主轴对齐的正交基轴；因此，奇异向量与特征向量截然不同。\n\n首先，我们分析矩阵 $A$。我们通过求解特征方程 $\\det(A - \\lambda I) = 0$ 来找到其特征值：\n$$ \\det \\begin{pmatrix} -\\lambda  -1 \\\\ 2  -\\lambda \\end{pmatrix} = (-\\lambda)(-\\lambda) - (-1)(2) = \\lambda^2 + 2 = 0 $$\n特征值为 $\\lambda = \\pm i\\sqrt{2}$。由于特征值是纯虚数，矩阵 $A$ 没有实特征向量。“$A$ 没有实不变方向”的说法是正确的。\n\n接下来，我们找奇异向量。右奇异向量是 $A^T A$ 的特征向量：\n$$ A^T A = \\begin{bmatrix} 0  2 \\\\ -1  0 \\end{bmatrix} \\begin{bmatrix} 0  -1 \\\\ 2  0 \\end{bmatrix} = \\begin{bmatrix} 4  0 \\\\ 0  1 \\end{bmatrix} $$\n这个对角矩阵的特征值为 $\\sigma_1^2 = 4$ 和 $\\sigma_2^2 = 1$。对应的特征向量是标准基向量 $v_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ 和 $v_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。这些是 $A$ 的右奇异向量。它们是实的，并构成一个标准正交基。\n左奇异向量是 $A A^T$ 的特征向量：\n$$ A A^T = \\begin{bmatrix} 0  -1 \\\\ 2  0 \\end{bmatrix} \\begin{bmatrix} 0  2 \\\\ -1  0 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  4 \\end{bmatrix} $$\n特征值同样是 $1$ 和 $4$。对应的特征向量是 $u_2 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$（对于 $\\sigma_2^2=1$）和 $u_1 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$（对于 $\\sigma_1^2=4$）。这些是左奇异向量。\n将 $A$ 描述为旋转和各向异性缩放的复合是准确的；例如，$A = \\begin{bmatrix} 1  0 \\\\ 0  2 \\end{bmatrix} \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix}$。单位圆 $x^2+y^2=1$ 在 $A$ 作用下的像是点集 $(x', y')=(-y, 2x)$，满足 $(x')^2 + (y'/2)^2 = 1$，这是一个半轴沿坐标轴的椭圆，与左奇异向量匹配。\n这个理由完全正确。该矩阵没有实特征向量，但它有一组唯一的、实的、标准正交的奇异向量。这是一个巨大的差异。\n\n结论：**正确**。\n\n**选项 B：** $A = \\begin{bmatrix} 3  1 \\\\ 1  2 \\end{bmatrix}$。理由：因为 $A$ 有非零的非对角线元素，其奇异向量必定与特征向量无关；几何上，$A$ 由单位圆生成的椭圆，其主轴与特征方向无关，所以这两组方向不同。\n\n矩阵 $A$ 是一个实对称矩阵，即 $A=A^T$。对于任何实对称矩阵，谱定理保证其特征向量构成一个标准正交基。奇异向量也来自对称矩阵（即 $A^TA$ 和 $AA^T$）的特征向量。由于 $A=A^T$，我们有 $A^TA = AA^T = A^2$。$A^2$ 的特征向量与 $A$ 的特征向量相同。因此，对于实对称矩阵，特征向量方向的集合与左、右奇异向量方向的集合是相同的。奇异值是特征值的绝对值。\n所给的理由声称，因为 $A$ 有非零的非对角线元素，其特征向量和奇异向量必定无关。这根本上是错误的。对称性是决定性因素，而不是非对角线元素是否为零。在这种情况下，因为 $A$ 是对称的，其特征向量和奇异向量重合。没有差异。\n\n结论：**不正确**。\n\n**选项 C：** $A = \\begin{bmatrix} 3  1 \\\\ 0  1 \\end{bmatrix}$。理由：对于任何上三角矩阵，奇异向量都与特征向量重合；几何上，剪切变换不改变由特征方向定义的主轴，因此没有差异。\n\n理由声称“对于任何上三角矩阵，奇异向量都与特征向量重合。”这是错误的。这个性质只对正规矩阵成立。一个上三角矩阵是正规的当且仅当它是对角矩阵。给定的矩阵 $A$ 不是对角矩阵，也不是正规矩阵：\n$A^T A = \\begin{bmatrix} 9  3 \\\\ 3  2 \\end{bmatrix}$\n$A A^T = \\begin{bmatrix} 10  1 \\\\ 1  1 \\end{bmatrix}$\n由于 $A^T A \\neq A A^T$，该矩阵不是正规矩阵，其特征向量预计不会是其奇异向量。\n我们来找 $A$ 的特征向量。由于 $A$ 是三角矩阵，特征值是对角线元素：$\\lambda_1 = 3, \\lambda_2 = 1$。\n对于 $\\lambda_1 = 3$：$(A-3I)v=0 \\implies \\begin{bmatrix} 0  1 \\\\ 0  -2 \\end{bmatrix}v=0 \\implies v_1=k\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$。\n对于 $\\lambda_2 = 1$：$(A-1I)v=0 \\implies \\begin{bmatrix} 2  1 \\\\ 0  0 \\end{bmatrix}v=0 \\implies v_2=k\\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}$。\n特征向量不是正交的。奇异向量作为对称矩阵 $A^TA$ 的特征向量，必须是正交的。因此，特征向量和奇异向量不可能是相同的。理由中的断言是错误的，并且“没有差异”的结论也是错误的。\n\n结论：**不正确**。\n\n**选项 D：** $A = \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix}$。理由：$A$ 是一个纯旋转 $\\pi/2$，因此它没有实特征向量，而其奇异向量构成一个实正交基，因为单位圆的像是其自身；因此，奇异向量和特征向量截然不同。\n\n矩阵 $A$ 表示一个逆时针旋转 $\\theta = \\pi/2$。我们求其特征值：\n$$ \\det(A - \\lambda I) = \\det \\begin{pmatrix} -\\lambda  -1 \\\\ 1  -\\lambda \\end{pmatrix} = \\lambda^2 + 1 = 0 $$\n特征值为 $\\lambda = \\pm i$。由于这些是复数， $A$ 没有实特征向量。“$A$ 是一个纯旋转 $\\pi/2$，因此它没有实特征向量”的说法是正确的。\n接下来，我们检查奇异向量。矩阵 $A$ 是正交的，意味着 $A^T A = A A^T = I$。\n$$ A^T A = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix} \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} = I $$\n单位矩阵 $I$ 的特征值都是 $1$。因此，$A$ 的奇异值是 $\\sigma_1 = \\sigma_2 = 1$。$I$ 的特征向量（即 $A$ 的右奇异向量）可以是 $\\mathbb{R}^2$ 中的任何一组标准正交向量。左奇异向量同理。\n所提供的几何理由是“单位圆的像是其自身”。这对于旋转是正确的，也正是所有奇异值都为 $1$ 的原因。因为奇异值相等，所以没有唯一的最大拉伸方向，导致奇异向量的非唯一性。然而，任何对奇异向量的有效选择都必须是一个实标准正交基。例如，我们可以选择标准基 $v_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, v_2 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。\n特征向量是复数，而奇异向量是实数。这构成了一个巨大的差异。所提供的理由完全有效。\n\n结论：**正确**。",
            "answer": "$$\\boxed{AD}$$"
        },
        {
            "introduction": "在神经科学数据分析中，SVD 是一个强大的降维工具，但其有效性取决于一个关键决策：如何选择合适的秩 $k$ 来区分信号与噪声。这个高级练习将你置于一个真实的研究场景中，要求你不仅要评估常用的启发式方法（如碎石图）的局限性，还要构建一个基于最小描述长度（MDL）原则的更严谨的模型选择标准。 这能培养你在处理高维神经数据时进行严谨模型选择和评估的关键技能。",
            "id": "4193353",
            "problem": "一个实验室记录了一个神经活动矩阵 $X \\in \\mathbb{R}^{n \\times t}$，其中 $n$ 表示神经元的数量，$t$ 表示时间的点数。在对每一行进行跨时间均值中心化后，对于每个 $i \\in \\{1,\\dots,n\\}$，都有 $\\sum_{j=1}^{t} X_{ij} = 0$。设 $X$ 的奇异值分解（SVD）为 $X = U \\Sigma V^\\top$，奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r \\ge 0$，其中 $r = \\min\\{n,t\\}$。该团队考虑通过秩为 $k$ 的信号加噪声模型 $X = S + E$ 对 $X$ 进行低秩建模，其中 $S$ 的秩 $\\mathrm{rank}(S) \\le k$，$E$ 代表噪声。\n\n他们希望 (i) 指定一个碎石图准则来选择 $k$ 并阐明其在神经数据中的局限性，以及 (ii) 在高斯噪声模型下，基于最小描述长度（MDL）原则，提出一个有原则的信息论选择规则。假设以下基本依据：\n\n- Frobenius 范数下的最佳秩-$k$ 近似由截断 SVD 给出，并且残差平方和等于被舍弃的奇异值的平方和。\n- 在独立同分布的高斯噪声模型 $E_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ 下，残差的负对数似然与由 $\\sigma^2$ 缩放的残差平方和成正比，并且在最大似然估计下，方差是经验残差方差。\n- 两部分的 MDL 编码长度在拟合优度（最大似然估计下的负对数似然）与随自由参数数量和样本量增长的模型复杂度项之间取得平衡。\n\n哪个选项正确地指定了一个正式的碎石图准则及其在神经数据设置中的实质性局限，并且还给出了一个在 SVD 和秩-$k$ 矩阵基本参数计数方面一致的用于选择 $k$ 的 MDL 目标？\n\nA. 碎石图准则：选择 $\\hat{k}$ 作为对数奇异值序列的最大离散曲率的索引，$\\hat{k}_{\\mathrm{elbow}} = \\arg\\max_{i \\in \\{2,\\dots,r-1\\}} \\left(\\log \\sigma_{i-1} - 2 \\log \\sigma_i + \\log \\sigma_{i+1}\\right)$。局限性：当奇异值逐渐衰减时，“肘部”可能不明确；对神经记录中常见的异方差或时间相关噪声以及缩放敏感；并且在 $n$ 或 $t$ 较小时不稳定。MDL：在 $E_{ij} \\sim \\mathcal{N}(0,\\sigma^2)$ 下，通过最小化 $L(k) = \\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) + \\frac{1}{2}\\,k\\,(n+t-k)\\,\\log(nt) + C$ 来选择 $k$，其中 $\\mathrm{RSS}_k = \\sum_{i=k+1}^{r} \\sigma_i^2$ 且 $C$ 不依赖于 $k$。\n\nB. 碎石图准则：选择满足 $\\sigma_k = \\bar{\\sigma}$ 的最小 $k$，其中 $\\bar{\\sigma} = \\frac{1}{r}\\sum_{i=1}^{r}\\sigma_i$。局限性：如果数据经过标准化，则没有局限性。MDL：通过最小化 $L(k) = \\frac{nt}{2}\\log(\\mathrm{RSS}_k) + k(n+t)\\log(\\sigma_1)$ 来选择 $k$。\n\nC. 碎石图准则：选择满足 $\\sum_{i=1}^{k}\\sigma_i^2 / \\sum_{i=1}^{r}\\sigma_i^2 \\ge 0.9$ 的最小 $k$。局限性：阈值 $0.9$ 是常规性的，可能无法反映神经噪声的特性。MDL：使用 Akaike 类型的分数 $A(k) = nt \\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) + 2k$，将参数数量视为 $k$。\n\nD. 碎石图准则：选择满足 $\\sigma_{k+1} \\le \\hat{\\sigma}\\,(\\sqrt{n}+\\sqrt{t})$ 的最大索引 $k$，其中对于某个固定的 $m$，有 $\\hat{\\sigma}^2 = \\mathrm{RSS}_m/(nt)$。局限性：在各向同性噪声下没有局限性。MDL: $L(k) = \\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) + \\frac{k}{2}\\log(nt)$。\n\n选择唯一的最佳选项。",
            "solution": "问题陈述已经过验证，被认为是在统计数据分析中一个一致、适定且有科学依据的问题。该问题要求正确地指定一个碎石图启发式方法和一个最小描述长度（MDL）准则，用于选择数据矩阵 $X \\in \\mathbb{R}^{n \\times t}$ 的低秩近似的秩 $k$。我们将根据提供的原则依次解决每个部分。\n\n第(i)部分：碎石图准则及其局限性\n\n碎石图按降序显示奇异值 $\\sigma_i$（或它们的平方，即协方差矩阵的特征值）。其启发式方法是在图中识别一个“肘部”，该点代表了从谱的陡峭“信号”部分到平坦“噪声”部分的过渡点。秩 $k$ 被选为该噪声基底开始前的索引。\n\n识别肘部的一个正式方法是找到最大曲率点。对于一个离散点序列 $(i, y_i)$，其中 $y_i = \\log \\sigma_i$，曲率可以用二阶差分的幅度来近似。$\\log \\sigma_i$ 序列是递减的。一个肘部对应于曲线最凸的点。离散二阶导数由 $(\\log \\sigma_{i+1} - \\log \\sigma_i) - (\\log \\sigma_i - \\log \\sigma_{i-1}) = \\log \\sigma_{i-1} - 2\\log \\sigma_i + \\log \\sigma_{i+1}$ 给出。我们寻求最大化这个量来找到“最尖锐”的肘部。因此，一个正式的准则是 $\\hat{k}_{\\mathrm{elbow}} = \\arg\\max_{i \\in \\{2,\\dots,r-1\\}} \\left(\\log \\sigma_{i-1} - 2 \\log \\sigma_i + \\log \\sigma_{i+1}\\right)$。\n\n这种启发式方法的局限性对于神经数据尤其显著：\n1.  模糊性：神经群体活动通常在其奇异值谱中表现出类似幂律的衰减。这意味着没有尖锐的肘部，而是平滑、逐渐的衰减，使得 $k$ 的选择非常主观和不稳定。\n2.  噪声结构：碎石图启发式方法隐含地假设噪声 $E$ 是独立同分布（i.i.d.）的高斯噪声，这会导致碎石图中出现平坦的“噪声基底”。神经噪声很少如此简单；它通常在时间上相关（例如，由于钙指示剂动力学或 LFP 信号渗透），并且在神经元间是异方差的（一些神经元本质上比其他神经元更嘈杂）。这种结构化噪声不会有平坦的奇异值谱，从而模糊或产生虚假的肘部。\n3.  抽样问题：对于有限的 $n$ 和 $t$，样本奇异值只是真实潜在总体值的估计。这种估计误差会移动肘部的位置，使得 $k$ 的选择不稳定，尤其是在小数据集上。\n\n第(ii)部分：最小描述长度（MDL）准则\n\nMDL 原则在模型拟合和模型复杂度之间提供了一个正式的权衡。要最小化的目标函数是 $L(k) = -\\log P(X| M_k, \\hat{\\theta}_k) + \\text{Penalty}(k)$，其中第一项是在给定复杂度为 $k$ 的最佳拟合模型下数据的负对数似然，而惩罚项则对更复杂的模型进行惩罚。\n\n1.  拟合优度项：给定一个独立同分布的高斯噪声模型 $E_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。给定秩为 $k$ 的信号 $S$ 和噪声方差 $\\sigma^2$ 时，数据 $X$ 的对数似然是：\n    $$ \\log P(X|S, \\sigma^2) = -\\frac{nt}{2}\\log(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2} \\|X-S\\|_F^2 $$\n    根据 Eckart-Young-Mirsky 定理，最小化 Frobenius 范数 $\\|X-S\\|_F^2$ 的最佳秩-$k$ 近似 $S_k$ 是通过截断 $X$ 的 SVD 得到的。残差平方和是 $\\mathrm{RSS}_k = \\|X-S_k\\|_F^2 = \\sum_{i=k+1}^r \\sigma_i^2$。对于给定的 $k$，我们需要 $\\sigma^2$ 的最大似然估计（MLE）。对对数似然函数关于 $\\sigma^2$ 求导并令其为零，得到 MLE：\n    $$ \\hat{\\sigma}_k^2 = \\frac{\\|X-S_k\\|_F^2}{nt} = \\frac{\\mathrm{RSS}_k}{nt} $$\n    将此代回到对数似然函数中，得到最大化的对数似然：\n    $$ \\log P(X | S_k, \\hat{\\sigma}_k^2) = -\\frac{nt}{2}\\log(2\\pi) - \\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) - \\frac{nt}{2} $$\n    其负值，在舍去与 $k$ 无关的常数项后，给出了 MDL 准则的拟合优度部分：$\\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right)$。\n\n2.  模型复杂度项：惩罚项通常形式为 $\\frac{D}{2}\\log N_s$，其中 $D$ 是模型中的自由参数数量，$N_s$ 是数据样本的数量。\n    *   参数数量 ($D$)：$\\mathbb{R}^{n \\times t}$ 中的一个秩-$k$ 矩阵可以由 $k(n+t)$ 个参数指定（对于大小为 $n \\times k$ 和 $t \\times k$ 的因子），但这有一个 $k^2$ 维的冗余。真实的自由度数量是 $D = k(n+t) - k^2 = k(n+t-k)$。\n    *   样本数量 ($N_s$)：我们有一个 $n \\times t$ 的观测矩阵，所以 $N_s = nt$。\n    因此，惩罚项是 $\\frac{1}{2} k(n+t-k) \\log(nt)$。\n\n结合这些，要对 $k$ 进行最小化的 MDL 目标函数是：\n$$ L(k) = \\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) + \\frac{1}{2} k(n+t-k) \\log(nt) $$\n其中 $\\mathrm{RSS}_k = \\sum_{i=k+1}^{r} \\sigma_i^2$。任何不依赖于 $k$ 的项都可以被吸收到一个加性常数 $C$ 中。\n\n选项评估：\n\nA. 碎石图准则：$\\hat{k}_{\\mathrm{elbow}} = \\arg\\max_{i \\in \\{2,\\dots,r-1\\}} \\left(\\log \\sigma_{i-1} - 2 \\log \\sigma_i + \\log \\sigma_{i+1}\\right)$。这正确地将肘部形式化为对数奇异值的最大离散曲率点。局限性：正确地指出了由逐渐衰减引起的模糊性、对现实神经噪声结构（异方差性、时间相关性）的敏感性以及小样本的不稳定性。MDL：$L(k) = \\frac{nt}{2}\\log\\left(\\frac{\\mathrm{RSS}_k}{nt}\\right) + \\frac{1}{2}\\,k\\,(n+t-k)\\,\\log(nt) + C$。这与我们的推导完全匹配。**正确**。\n\nB. 碎石图准则：使用了一个特设规则，即比较 $\\sigma_k$ 和均值 $\\bar{\\sigma}$，这不是标准的肘部准则。局限性：错误地声称如果数据被标准化就没有局限性。标准化并不能消除时间相关性或其他噪声结构。MDL：拟合项 $\\frac{nt}{2}\\log(\\mathrm{RSS}_k)$ 不正确，因为它省略了归一化因子 $1/(nt)$。惩罚项 $k(n+t)\\log(\\sigma_1)$ 使用了不正确的参数计数和一个不合理的缩放因子 $\\log(\\sigma_1)$。**不正确**。\n\nC. 碎石图准则：这描述的是一个“解释方差百分比”（PVE）准则，而不是碎石图/肘部准则。虽然 PVE 是选择 $k$ 的一种方法，但它解决的是一个不同的问题（保留多少方差），而不是识别信号/噪声的过渡。MDL：提出了一个 Akaike 类型的分数，而不是 MDL 分数。MDL 中的惩罚项取决于 $\\log(N_s)$，而在 AIC 中它是一个常数 $2$。它还错误地将参数数量指定为 $k$，而不是 $k(n+t-k)$。**不正确**。\n\nD. 碎石图准则：准则 $\\sigma_{k+1} \\le \\hat{\\sigma}\\,(\\sqrt{n}+\\sqrt{t})$ 是从随机矩阵理论中推导出的关于随机矩阵最大奇异值的阈值，而不是碎石图肘部准则。局限性：“在各向同性噪声下没有局限性”的说法是错误的；随机矩阵理论的结果是渐近的，并且有其自身的假设和局限性。MDL：拟合项是正确的，但惩罚项 $\\frac{k}{2}\\log(nt)$ 使用了不正确的参数计数 $k$。**不正确**。\n\n基于从第一性原理的详尽推导，选项 A 为碎石图准则及其局限性，以及 MDL 目标函数提供了正确的形式化表述。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}