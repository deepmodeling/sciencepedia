{
    "hands_on_practices": [
        {
            "introduction": "The Blood Oxygenation Level Dependent (BOLD) signal is an indirect measure of neural activity, originating from a cascade of complex hemodynamic changes. This exercise explores the fundamental relationship between Cerebral Blood Flow (CBF) and Cerebral Blood Volume (CBV), which is empirically described by Grubb's law. By working through this problem, you will develop a quantitative intuition for neurovascular coupling and connect these core biophysical principles to hallmark features of the observed BOLD signal, such as the post-stimulus undershoot. ",
            "id": "3998822",
            "problem": "Consider a brief neural stimulus that increases Cerebral Blood Flow (CBF) by a constant fraction for a short period. Let the baseline CBF be denoted by $f_{0}$ and the baseline Cerebral Blood Volume (CBV) by $v_{0}$. Define the relative changes as $r_{f} = f/f_{0}$ and $r_{v} = v/v_{0}$. Assume quasi-steady hemodynamics during the peak response and the empirically established Grubb’s relationship $v \\propto f^{\\alpha}$ holds locally, with exponent $\\alpha$ characterizing microvascular compliance. From mass balance, the volume dynamics obey $dv/dt = \\text{inflow} - \\text{outflow}$, and under the quasi-steady condition at the peak, the instantaneous $r_{v}$ may be related to $r_{f}$ via Grubb’s relationship.\n\nSuppose the stimulus produces a $20\\%$ increase in CBF at peak, i.e., $r_{f} = 1.2$, and the local Grubb exponent is $\\alpha = 0.2$. Using only the definitions above and the Grubb coupling, derive the closed-form expression for the fractional CBV change at peak, $\\Delta v / v_{0} = r_{v} - 1$, and then compute its numerical value. Round your final numerical answer to four significant figures. Express the fractional change as a dimensionless decimal (do not use a percentage sign).\n\nFinally, discuss qualitatively, using the definitions of deoxyhemoglobin content and volume and without invoking any specific Blood Oxygenation Level Dependent (BOLD) signal equation, how the magnitude of this CBV change and its potential delayed recovery relative to CBF could contribute to the post-stimulus undershoot in the BOLD signal. Define all acronyms on first use: Blood Oxygenation Level Dependent (BOLD), Cerebral Blood Volume (CBV), Cerebral Blood Flow (CBF).",
            "solution": "The problem requires the derivation and calculation of the fractional change in Cerebral Blood Volume (CBV) based on a given change in Cerebral Blood Flow (CBF) and an established empirical relationship, followed by a qualitative discussion of the post-stimulus undershoot in the Blood Oxygenation Level Dependent (BOLD) signal.\n\nFirst, we derive the closed-form expression for the fractional CBV change at its peak.\nThe problem states the empirically established Grubb's relationship, which couples CBV, denoted by $v$, to CBF, denoted by $f$:\n$$v \\propto f^{\\alpha}$$\nThis proportionality can be written as an equation with a constant of proportionality, $k$:\n$$v = k f^{\\alpha}$$\nThis relationship holds under different physiological states, including baseline and activation. Let the baseline CBV be $v_{0}$ and the baseline CBF be $f_{0}$. At baseline, the equation is:\n$$v_{0} = k f_{0}^{\\alpha}$$\nAt the peak of the stimulus-induced response, the CBV is $v$ and the CBF is $f$. The equation is:\n$$v = k f^{\\alpha}$$\nTo find the relationship between the relative changes, we can divide the equation at peak activation by the equation at baseline:\n$$\\frac{v}{v_{0}} = \\frac{k f^{\\alpha}}{k f_{0}^{\\alpha}}$$\nThe constant $k$ cancels, yielding:\n$$\\frac{v}{v_{0}} = \\left(\\frac{f}{f_{0}}\\right)^{\\alpha}$$\nThe problem defines the relative changes as $r_{v} = v/v_{0}$ and $r_{f} = f/f_{0}$. Substituting these definitions into the equation gives the coupling between the relative changes:\n$$r_{v} = r_{f}^{\\alpha}$$\nThe problem asks for the fractional CBV change, which is defined as $\\frac{\\Delta v}{v_{0}}$. We can express this in terms of $r_v$:\n$$\\frac{\\Delta v}{v_{0}} = \\frac{v - v_{0}}{v_{0}} = \\frac{v}{v_{0}} - \\frac{v_{0}}{v_{0}} = r_{v} - 1$$\nBy substituting the expression for $r_{v}$, we arrive at the final closed-form expression for the fractional CBV change in terms of the fractional CBF change:\n$$\\frac{\\Delta v}{v_{0}} = r_{f}^{\\alpha} - 1$$\n\nNext, we compute the numerical value of this fractional change using the provided data.\nThe stimulus produces a $20\\%$ increase in CBF, which means the peak flow $f$ is $120\\%$ of the baseline flow $f_0$. This corresponds to a relative change $r_{f}$ of:\n$$r_{f} = \\frac{f}{f_{0}} = \\frac{1.20 f_{0}}{f_{0}} = 1.2$$\nThe local Grubb exponent is given as $\\alpha = 0.2$.\nSubstituting these values into our derived expression:\n$$\\frac{\\Delta v}{v_{0}} = (1.2)^{0.2} - 1$$\nWe can calculate the numerical value. Note that an exponent of $0.2$ is equivalent to the $5^{th}$ root:\n$$(1.2)^{0.2} = (1.2)^{1/5} = \\sqrt[5]{1.2} \\approx 1.037137$$\nTherefore, the fractional change is:\n$$\\frac{\\Delta v}{v_{0}} \\approx 1.037137 - 1 = 0.037137$$\nRounding this result to four significant figures gives:\n$$\\frac{\\Delta v}{v_{0}} \\approx 0.03714$$\n\nFinally, we discuss qualitatively how the magnitude of this CBV change and its potential delayed recovery relative to CBF contribute to the post-stimulus undershoot.\nThe Blood Oxygenation Level Dependent (BOLD) signal, used in functional magnetic resonance imaging, indirectly measures neural activity by detecting changes in blood oxygenation. The signal is sensitive to the local concentration of deoxyhemoglobin, which is paramagnetic and causes magnetic field inhomogeneities. A lower concentration of deoxyhemoglobin results in a higher BOLD signal.\n\nDuring neural stimulation, there is a large increase in Cerebral Blood Flow (CBF), the rate of blood delivery. This flow increase significantly overcompensates for the much smaller increase in oxygen consumption. The result is a \"washout\" of deoxyhemoglobin from the venous side of the capillary bed, leading to a decrease in its concentration and thus an increase in the BOLD signal. This CBF increase also forces an increase in Cerebral Blood Volume (CBV), the total volume of blood in a given brain region, as the blood vessels distend to accommodate the higher flow.\n\nThe post-stimulus undershoot refers to the phenomenon where the BOLD signal drops below its pre-stimulus baseline level for a period after the neural stimulus has ceased. A primary hypothesis for this effect centers on the differential temporal dynamics of CBF and CBV recovery.\nFollowing the cessation of the stimulus, CBF tends to return to its baseline level relatively quickly. However, the venous blood vessels, having been stretched, are compliant and tend to return to their baseline volume much more slowly. This biomechanical property results in a transient state where CBF has normalized (or nearly so), but CBV remains elevated.\n\nIn this specific post-stimulus period:\n1.  **CBF is at baseline**: The supply of fresh, oxygenated blood is back to normal.\n2.  **CBV is elevated**: The volume of the venous compartment is still larger than its baseline state.\n\nBecause metabolic oxygen consumption continues at a near-baseline rate, deoxyhemoglobin is still being produced. This deoxyhemoglobin now pools in the still-enlarged venous volume. The total amount of deoxyhemoglobin within the imaging voxel (which is a product of its concentration and the venous blood volume) becomes greater than it was at the initial baseline. This increased total amount of paramagnetic deoxyhemoglobin creates stronger local magnetic field distortions, leading to a faster signal decay and, consequently, a BOLD signal that is lower than the initial baseline level. This effect persists until the venous CBV fully returns to its baseline state, at which point the BOLD signal also recovers to baseline. Thus, the mismatch in recovery timescales between a fast-recovering CBF and a slow-recovering CBV is a key proposed mechanism for the post-stimulus BOLD undershoot.",
            "answer": "$$\n\\boxed{0.03714}\n$$"
        },
        {
            "introduction": "The General Linear Model (GLM) is the workhorse for analyzing functional MRI data, but its statistical power is deeply tied to the experimental design. This practice delves into the critical issue of multicollinearity, where correlations between task regressors can inflate the variance of parameter estimates and reduce statistical confidence. You will derive the Variance Inflation Factor (VIF) from first principles, providing a concrete tool to diagnose how the structure of your experimental design impacts the precision of your findings. ",
            "id": "4198478",
            "problem": "A single voxel blood-oxygen-level-dependent (BOLD) time series is modeled with a general linear model (GLM). Let the observed time series be $y \\in \\mathbb{R}^{N}$, the design matrix be $X \\in \\mathbb{R}^{N \\times p}$ with $p=3$ regressors corresponding to two task conditions and one nuisance motion parameter, and suppose that the parameter vector is $\\beta \\in \\mathbb{R}^{3}$. Assume the classical linear model with independent, identically distributed Gaussian noise: $\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{N})$, and $y = X \\beta + \\epsilon$, with the parameters estimated by ordinary least squares (OLS). The $3$ columns of $X$ have been constructed by convolving event sequences with a canonical hemodynamic response function (HRF) and then column-wise standardized to have zero mean and unit variance. The sample size is $N=200$. Denote the regressors by $A$, $B$, and $M$ (for the two task conditions and the motion nuisance, respectively). The sample correlation matrix of the columns of $X$ is\n$$\nR \\;=\\; \\begin{pmatrix}\n1 & r & 0 \\\\\nr & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix},\n$$\nwith $r = 0.8$. By definition of the sample correlation matrix under this column standardization, $X^{\\top} X = N R$.\n\nWorking from the fundamental properties of the ordinary least squares estimator under the classical linear model and using only the information given above, derive the relationship between the variance of the OLS coefficient estimates and the design correlation structure. Use this to define the variance-inflation factor for each coefficient as the ratio of its variance under the given design to its variance under a counterfactual design in which the three columns are mutually orthogonal but have the same column norms as in the given design. Compute the variance-inflation factors for regressors $A$, $B$, and $M$ for the given $R$ and $N$.\n\nReport the three variance-inflation factors for $(A, B, M)$ as a single row matrix using the LaTeX $\\texttt{pmatrix}$ environment. Do not round your answer.",
            "solution": "The problem asks for the derivation and computation of variance-inflation factors (VIFs) for the ordinary least squares (OLS) estimates of parameters in a general linear model (GLM) applied to a BOLD time series.\n\nFirst, we establish the fundamental properties of the OLS estimator. The model is given by $y = X \\beta + \\epsilon$, where $y \\in \\mathbb{R}^{N}$ is the observed data, $X \\in \\mathbb{R}^{N \\times p}$ is the design matrix, $\\beta \\in \\mathbb{R}^{p}$ is the parameter vector, and $\\epsilon$ is the noise vector. We are given $p=3$ and $N=200$. The noise is assumed to be white Gaussian noise, $\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{N})$, where $\\sigma^2$ is the noise variance and $I_N$ is the $N \\times N$ identity matrix.\n\nThe OLS estimator for $\\beta$ is given by the expression $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$. The covariance matrix of this estimator, $\\text{Cov}(\\hat{\\beta})$, is derived as follows:\n$$\n\\text{Cov}(\\hat{\\beta}) = \\text{Cov}((X^{\\top} X)^{-1} X^{\\top} y)\n$$\nSince $X$ is a fixed matrix of regressors, we can write:\n$$\n\\text{Cov}(\\hat{\\beta}) = (X^{\\top} X)^{-1} X^{\\top} \\text{Cov}(y) ( (X^{\\top} X)^{-1} X^{\\top} )^{\\top}\n$$\nThe covariance of the data $y$ is $\\text{Cov}(y) = \\text{Cov}(X\\beta + \\epsilon) = \\text{Cov}(\\epsilon) = \\sigma^2 I_N$. Substituting this into the expression for $\\text{Cov}(\\hat{\\beta})$ yields:\n$$\n\\text{Cov}(\\hat{\\beta}) = (X^{\\top} X)^{-1} X^{\\top} (\\sigma^2 I_N) X (X^{\\top} X)^{-1} = \\sigma^2 (X^{\\top} X)^{-1} (X^{\\top} X) (X^{\\top} X)^{-1}\n$$\nThis simplifies to the well-known result:\n$$\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X^{\\top} X)^{-1}\n$$\nThe variance of a single coefficient estimate, $\\hat{\\beta}_j$, is the $j$-th diagonal element of this covariance matrix:\n$$\n\\text{Var}(\\hat{\\beta}_j) = [\\text{Cov}(\\hat{\\beta})]_{jj} = \\sigma^2 [(X^{\\top} X)^{-1}]_{jj}\n$$\nThe problem states that for the given design matrix $X$, the relationship $X^{\\top} X = N R$ holds, where $N=200$ is the sample size and $R$ is the sample correlation matrix of the columns of $X$. Substituting this into the variance expression, we find the relationship between the variance of the estimates and the design correlation structure:\n$$\n\\text{Var}(\\hat{\\beta}_j) = \\sigma^2 [(N R)^{-1}]_{jj} = \\frac{\\sigma^2}{N} [R^{-1}]_{jj}\n$$\nThe variance-inflation factor (VIF) is defined as the ratio of the variance of a coefficient estimate under the given design to its variance under a counterfactual design where the regressors are mutually orthogonal but have the same column norms.\n\nLet's first determine the variance in the counterfactual orthogonal design, denoted $X_{ortho}$. The problem states that the columns of $X_{ortho}$ have the same norms as the columns of $X$. The diagonal elements of $X^{\\top}X = NR$ are $(X^{\\top}X)_{jj} = X_j^{\\top}X_j = \\|X_j\\|^2$. Since $R_{jj}=1$, we have $\\|X_j\\|^2 = N \\cdot 1 = N$ for each column $j$. The counterfactual design $X_{ortho}$ thus has orthogonal columns with $\\|X_{ortho,j}\\|^2 = N$. The Gram matrix for this orthogonal design is a diagonal matrix:\n$$\nX_{ortho}^{\\top} X_{ortho} = \\begin{pmatrix} N & 0 & 0 \\\\ 0 & N & 0 \\\\ 0 & 0 & N \\end{pmatrix} = N I_3\n$$\nThe variance of the estimate $\\hat{\\beta}_{j, ortho}$ in this case is:\n$$\n\\text{Var}(\\hat{\\beta}_{j, ortho}) = \\sigma^2 [(N I_3)^{-1}]_{jj} = \\sigma^2 \\left[\\frac{1}{N} I_3\\right]_{jj} = \\frac{\\sigma^2}{N}\n$$\nNow, we can compute the VIF for the $j$-th coefficient as defined:\n$$\n\\text{VIF}_j = \\frac{\\text{Var}(\\hat{\\beta}_j)}{\\text{Var}(\\hat{\\beta}_{j, ortho})} = \\frac{\\frac{\\sigma^2}{N} [R^{-1}]_{jj}}{\\frac{\\sigma^2}{N}} = [R^{-1}]_{jj}\n$$\nThus, the VIF for each coefficient is simply the corresponding diagonal element of the inverse of the correlation matrix $R$.\n\nWe are given the correlation matrix:\n$$\nR = \\begin{pmatrix}\n1 & r & 0 \\\\\nr & 1 & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix} \\quad\\text{with}\\quad r = 0.8\n$$\nThis is a block-diagonal matrix. Its inverse is the block-diagonal matrix of the inverses of its blocks. Let the top-left $2 \\times 2$ block be $R_{12} = \\begin{pmatrix} 1 & r \\\\ r & 1 \\end{pmatrix}$.\nThe determinant of this block is $\\det(R_{12}) = 1 \\cdot 1 - r \\cdot r = 1 - r^2$.\nThe inverse is $R_{12}^{-1} = \\frac{1}{1-r^2} \\begin{pmatrix} 1 & -r \\\\ -r & 1 \\end{pmatrix}$.\nThe bottom-right block is just the scalar $1$, whose inverse is $1$.\nTherefore, the inverse of the full correlation matrix is:\n$$\nR^{-1} = \\begin{pmatrix}\n\\frac{1}{1-r^2} & \\frac{-r}{1-r^2} & 0 \\\\\n\\frac{-r}{1-r^2} & \\frac{1}{1-r^2} & 0 \\\\\n0 & 0 & 1\n\\end{pmatrix}\n$$\nThe VIFs for the three regressors (A, B, M) are the diagonal elements of this matrix:\n$\\text{VIF}_A = [R^{-1}]_{11} = \\frac{1}{1-r^2}$\n$\\text{VIF}_B = [R^{-1}]_{22} = \\frac{1}{1-r^2}$\n$\\text{VIF}_M = [R^{-1}]_{33} = 1$\n\nWe substitute the given value $r=0.8$:\n$r^2 = (0.8)^2 = 0.64$\n$1 - r^2 = 1 - 0.64 = 0.36$\nThe VIFs for regressors $A$ and $B$ are:\n$\\text{VIF}_A = \\text{VIF}_B = \\frac{1}{0.36} = \\frac{1}{36/100} = \\frac{100}{36} = \\frac{25}{9}$\nThe VIF for regressor $M$ is:\n$\\text{VIF}_M = 1$\nThis result is expected, as regressor $M$ is uncorrelated with regressors $A$ and $B$, so its variance is not inflated by their presence. The high correlation between $A$ and $B$ results in a significant inflation of the variance for their respective coefficient estimates.\n\nThe three variance-inflation factors for $(A, B, M)$ are $(\\frac{25}{9}, \\frac{25}{9}, 1)$. We report this as a single row matrix.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{25}{9} & \\frac{25}{9} & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "A key challenge in fMRI analysis is that the brain's Hemodynamic Response Function (HRF) varies across regions and individuals, often mismatching the fixed \"canonical\" HRF used in standard models. This hands-on coding exercise demonstrates how such a model mismatch can systematically bias our estimates of neural activation amplitude. You will implement a simulation to quantify this bias and then test a powerful solution—augmenting the GLM with a temporal derivative basis function—to build more robust and physiologically accurate models of BOLD activity. ",
            "id": "3998785",
            "problem": "Consider the convolutional model of functional Magnetic Resonance Imaging (fMRI) Blood Oxygen Level Dependent (BOLD) signal as a linear time-invariant system: the observed signal is the result of convolving a stimulus time series with a Hemodynamic Response Function (HRF). Let the stimulus be a discrete-time sequence sampled at a fixed temporal resolution. The BOLD signal obeys linear superposition and time shift properties of convolution. The General Linear Model (GLM) provides an ordinary least squares estimator for linear regression parameters.\n\nYou are tasked with quantifying the bias introduced when fitting a mismatched canonical HRF to data generated by a delayed HRF, and measuring the improvement when augmenting the GLM with the temporal derivative basis. Use a principled derivation from the convolution model and linear regression to define and compute the amplitude bias and its reduction.\n\nUse the following foundations:\n\n- The observed BOLD signal is modeled as a convolution: for a stimulus sequence $s[n]$ and an HRF $h[n]$, the noise-free response is $y[n] = \\sum_{k=0}^{\\infty} s[k] h[n-k] \\Delta t$, where $\\Delta t$ is the sampling interval in seconds.\n- The GLM posits $y = X \\beta + \\varepsilon$ and uses ordinary least squares to estimate $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$, where $X$ is the design matrix and $\\varepsilon$ is the residual (here, set $\\varepsilon = 0$ to isolate model mismatch bias).\n- The canonical Hemodynamic Response Function (HRF) $h_{0}(t)$ is defined as a difference of gamma density functions, which is widely used in neuroimaging. In discrete time, sample it at interval $\\Delta t$ over a finite support.\n\nPrecisely implement the following:\n\n1. Let the sampling interval be $\\Delta t = 0.5$ seconds. Let the total simulated duration be $T = 120$ seconds. Construct the discrete-time grid $t = 0, \\Delta t, 2\\Delta t, \\ldots, T - \\Delta t$.\n\n2. Define the canonical HRF $h_{0}(t)$ for $t \\ge 0$ by\n   $$h_{0}(t) = g(t; a_{1}, b_{1}) - c \\, g(t; a_{2}, b_{2}),$$\n   where $g(t; a, b)$ is the gamma density\n   $$g(t; a, b) = \\frac{t^{a-1} e^{-t/b}}{b^{a} \\Gamma(a)}, \\quad t \\ge 0,$$\n   and use parameters $a_{1} = 6$, $b_{1} = 1$, $a_{2} = 16$, $b_{2} = 1$, and $c = 1/6$. Sample $h_{0}(t)$ on $t = 0, \\Delta t, \\ldots, t_{\\max}$ with $t_{\\max} = 32$ seconds, and set $h_{0}(t) = 0$ for $t < 0$.\n\n3. Construct a stimulus train $s[n]$ consisting of five $1$-second boxcar events at times $10$ seconds, $30$ seconds, $50$ seconds, $70$ seconds, and $90$ seconds. That is, if an event begins at time $t_{e}$, then for indices $n$ where $t[n] \\in [t_{e}, t_{e} + 1)$, set $s[n] = 1$, and $s[n] = 0$ otherwise.\n\n4. Define the delayed HRF as $h_{d}(t) = h_{0}(t - d)$, with $h_{d}(t) = 0$ for $t - d < 0$, where $d$ is a constant delay in seconds that may be positive (late response) or negative (early response). Implement discrete-time shifting of the sampled HRF by $d$ using integer sample shifts of $d/\\Delta t$.\n\n5. Generate the noise-free observed data $y[n]$ by discrete convolution:\n   $$y[n] = \\Delta t \\sum_{k=0}^{N-1} s[k] h_{d}[n-k],$$\n   truncated to the length of the stimulus $N$.\n\n6. Construct the canonical-only GLM design matrix $X_{1} = [r_{c}, \\mathbf{1}]$, where $\\mathbf{1}$ is the column of ones and\n   $$r_{c}[n] = \\Delta t \\sum_{k=0}^{N-1} s[k] h_{0}[n-k],$$\n   is the canonical regressor. Compute the ordinary least squares estimate $\\hat{\\beta}_{1}$ and define the amplitude estimate $\\hat{A}_{1}$ as the coefficient of the canonical regressor, i.e., the first component of $\\hat{\\beta}_{1}$. Let the true amplitude be $A_{\\text{true}} = 1$. Define the bias as $b_{1} = \\hat{A}_{1} - A_{\\text{true}}$.\n\n7. Construct the derivative-augmented GLM design matrix $X_{2} = [r_{c}, r_{d}, \\mathbf{1}]$, where $r_{d}[n]$ is the regressor obtained by convolving the stimulus with the temporal derivative of the canonical HRF:\n   $$r_{d}[n] = \\Delta t \\sum_{k=0}^{N-1} s[k] \\left(\\frac{d}{dt} h_{0}\\right)[n-k],$$\n   with the derivative implemented numerically on the sampled $h_{0}(t)$ via a finite difference. Compute $\\hat{\\beta}_{2}$ and define $\\hat{A}_{2}$ as the first component of $\\hat{\\beta}_{2}$, with bias $b_{2} = \\hat{A}_{2} - A_{\\text{true}}$.\n\n8. Quantify the improvement due to the derivative basis as the reduction in absolute bias:\n   $$R = |b_{1}| - |b_{2}|.$$\n   A positive $R$ indicates reduced amplitude bias.\n\nTest Suite:\n\nEvaluate the improvement $R$ for the following delays $d$ (in seconds):\n\n- Case $1$: $d = 0.0$ (no delay, boundary case).\n- Case $2$: $d = 0.5$ (small positive delay).\n- Case $3$: $d = 2.0$ (moderate positive delay).\n- Case $4$: $d = 4.0$ (large positive delay).\n- Case $5$: $d = -0.5$ (small negative delay).\n\nRequired output:\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_{1}, r_{2}, r_{3}, r_{4}, r_{5}]$), where each $r_{i}$ is the computed improvement $R$ for the corresponding test case. Express all numbers as decimal floats. Time is in seconds throughout; amplitudes are dimensionless and biases are dimensionless.",
            "solution": "The problem requires a quantitative analysis of the bias in amplitude estimation for a functional Magnetic Resonance Imaging (fMRI) signal model when there is a mismatch between the true and modeled Hemodynamic Response Function (HRF), and to evaluate the effectiveness of augmenting the General Linear Model (GLM) with a temporal derivative basis function to correct for this bias. The procedure is grounded in the theory of linear time-invariant (LTI) systems and ordinary least squares (OLS) estimation.\n\nFirst, we establish the mathematical and computational framework as specified.\n\n**1. Temporal Discretization and Stimulus Definition**\nThe simulation is conducted over a total duration of $T = 120$ seconds, with a sampling interval of $\\Delta t = 0.5$ seconds. This defines a discrete time grid $t_n = n \\Delta t$ for $n = 0, 1, \\ldots, N-1$, where $N = T/\\Delta t = 240$.\nThe stimulus $s[n]$ is a binary sequence representing neural events. It consists of five $1$-second boxcar functions commencing at times $t_e \\in \\{10, 30, 50, 70, 90\\}$ seconds. For each event starting at $t_e$, the discrete stimulus samples $s[n]$ are set to $1$ for all time points $t_n$ such that $t_e \\le t_n < t_e + 1$, and $0$ otherwise.\n\n**2. Hemodynamic Response Function (HRF) Definition**\nThe canonical HRF, denoted $h_0(t)$, models the BOLD signal response to a brief, impulse-like neural event. It is defined as a difference of two gamma probability density functions:\n$$h_{0}(t) = g(t; a_{1}, b_{1}) - c \\, g(t; a_{2}, b_{2})$$\nwhere the gamma density function $g(t; a, b)$ is given by:\n$$g(t; a, b) = \\frac{t^{a-1} e^{-t/b}}{b^{a} \\Gamma(a)}, \\quad t \\ge 0$$\nThe parameters are specified as $a_{1} = 6$, $b_{1} = 1$, $a_{2} = 16$, $b_{2} = 1$, and $c = 1/6$. We sample $h_0(t)$ at the temporal resolution $\\Delta t$ over a finite support of $t_{max} = 32$ seconds to obtain the discrete filter kernel $h_0[n]$.\n\nThe true HRF underlying the data is a time-shifted version of the canonical one, $h_d(t) = h_0(t-d)$, where $d$ is a delay in seconds. A positive $d$ corresponds to a delayed response, and a negative $d$ to an advanced response. In the discrete domain, this is implemented by shifting the sampled kernel $h_0[n]$ by a number of samples equal to $d/\\Delta t$. For a shift of $k = d/\\Delta t$ samples, if $k>0$, we prepend $k$ zeros to $h_0[n]$ and truncate the end; if $k<0$, we remove the first $|k|$ samples and append $|k|$ zeros. This produces the discrete delayed kernel $h_d[n]$.\n\n**3. Data Generation via Convolution**\nUnder the LTI system assumption, the noise-free BOLD signal $y[n]$ is the discrete convolution of the stimulus $s[n]$ with the true (delayed) HRF kernel $h_d[n]$, scaled by the sampling interval $\\Delta t$:\n$$y[n] = \\Delta t \\sum_{k=0}^{N-1} s[k] h_{d}[n-k]$$\nThis operation models the linear superposition of responses to each component of the stimulus sequence.\n\n**4. GLM Estimation and Bias Calculation**\nThe General Linear Model (GLM) framework is used to estimate the amplitude of the response. The model is $y = X \\beta + \\varepsilon$. We consider a noise-free scenario ($\\varepsilon=0$) to isolate the bias due to model mismatch. The OLS estimate for the parameters $\\beta$ is $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$.\n\n**Model 1: Canonical-Only GLM**\nThe first model attempts to explain the data $y$ using only the canonical HRF. The design matrix $X_1$ is constructed with two regressors:\n1.  The canonical regressor, $r_c[n]$, formed by convolving the stimulus $s[n]$ with the canonical HRF $h_0[n]$: $r_c[n] = \\Delta t \\sum_k s[k] h_0[n-k]$.\n2.  An intercept term, a column of ones, to model the baseline signal level.\nSo, $X_1 = [r_c, \\mathbf{1}]$. We solve the system $y = X_1 \\beta_1$ for $\\hat{\\beta}_1 = [\\hat{A}_1, \\text{intercept}]^{\\top}$. The true amplitude of the response is $A_{\\text{true}} = 1$ by construction. The bias of this first estimator is $b_1 = \\hat{A}_1 - A_{\\text{true}}$. When $d \\neq 0$, $y$ is mismatched with $r_c$, leading to a non-zero bias $b_1$.\n\n**Model 2: Derivative-Augmented GLM**\nThe second model is based on a first-order Taylor series approximation of the delayed HRF:\n$$h_d(t) = h_0(t-d) \\approx h_0(t) - d \\cdot \\frac{d}{dt}h_0(t)$$\nConvolving with the stimulus $s(t)$ suggests that the resulting signal $y(t)$ can be approximated by a linear combination of $r_c(t) = s(t) * h_0(t)$ and $s(t) * \\frac{d}{dt}h_0(t)$. This motivates adding a regressor based on the temporal derivative of the HRF to the GLM.\n\nThe derivative of the canonical HRF, $\\frac{d}{dt}h_0(t)$, is computed numerically using a finite difference method on the sampled kernel $h_0[n]$. This derivative kernel is convolved with the stimulus to create the derivative regressor: $r_d[n] = \\Delta t \\sum_k s[k] (\\frac{d}{dt}h_0)[n-k]$.\n\nThe augmented design matrix is $X_2 = [r_c, r_d, \\mathbf{1}]$. We solve $y = X_2 \\beta_2$ for $\\hat{\\beta}_2 = [\\hat{A}_2, \\hat{\\beta}_{d}, \\text{intercept}]^{\\top}$. The amplitude estimate $\\hat{A}_2$ is the coefficient of the canonical regressor. The bias is $b_2 = \\hat{A}_2 - A_{\\text{true}}$. By accounting for the temporal shift, this model is expected to provide a more accurate estimate of the amplitude, resulting in a smaller bias $|b_2|$ compared to $|b_1|$.\n\n**5. Quantifying Improvement**\nThe improvement from including the temporal derivative basis is quantified as the reduction in absolute bias:\n$$R = |b_1| - |b_2|$$\nA positive value of $R$ indicates that the augmented model provides a less biased estimate of the response amplitude. We compute $R$ for each specified delay $d$ in the test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Computes the reduction in amplitude estimation bias for an fMRI GLM\n    by augmenting the model with a temporal derivative basis function.\n    \"\"\"\n\n    def g_pdf(t, a, b):\n        \"\"\"Gamma probability density function.\"\"\"\n        # Handle t=0 case where t**(a-1) is 0 for a > 1\n        t_safe = np.maximum(t, 1e-12)\n        val = (t_safe**(a - 1) * np.exp(-t_safe / b)) / (b**a * gamma(a))\n        val[t == 0] = 0.0\n        return val\n\n    def calculate_improvement(d):\n        \"\"\"\n        Calculates the bias improvement R for a given delay d.\n        \"\"\"\n        # 1. Setup time grid and constants\n        dt = 0.5  # Sampling interval in seconds\n        T = 120.0  # Total duration in seconds\n        t_max_hrf = 32.0  # HRF support duration\n        time_vec = np.arange(0, T, dt)\n        N = len(time_vec)\n        A_true = 1.0\n\n        # 2. Define canonical HRF h0(t)\n        hrf_time_vec = np.arange(0, t_max_hrf + dt, dt)\n        a1, b1 = 6.0, 1.0\n        a2, b2 = 16.0, 1.0\n        c = 1.0 / 6.0\n        h0_sampled = g_pdf(hrf_time_vec, a1, b1) - c * g_pdf(hrf_time_vec, a2, b2)\n\n        # 3. Construct stimulus train s[n]\n        s = np.zeros(N)\n        event_times = [10.0, 30.0, 50.0, 70.0, 90.0]\n        event_duration = 1.0\n        for t_e in event_times:\n            event_indices = (time_vec >= t_e) & (time_vec < t_e + event_duration)\n            s[event_indices] = 1.0\n\n        # 4. Define the delayed HRF h_d(t)\n        shift_samples = int(round(d / dt))\n        h_d_sampled = np.zeros_like(h0_sampled)\n        if shift_samples == 0:\n            h_d_sampled = h0_sampled.copy()\n        elif shift_samples > 0:\n            h_d_sampled[shift_samples:] = h0_sampled[:-shift_samples]\n        else: # shift_samples < 0\n            h_d_sampled[:shift_samples] = h0_sampled[-shift_samples:]\n\n        # 5. Generate noise-free observed data y[n]\n        y = dt * np.convolve(s, h_d_sampled, mode='full')[:N]\n\n        # 6. Canonical-only GLM (GLM 1)\n        r_c = dt * np.convolve(s, h0_sampled, mode='full')[:N]\n        intercept = np.ones(N)\n        X1 = np.vstack([r_c, intercept]).T\n        \n        beta1, _, _, _ = np.linalg.lstsq(X1, y, rcond=None)\n        A1_hat = beta1[0]\n        b1 = A1_hat - A_true\n\n        # 7. Derivative-augmented GLM (GLM 2)\n        h0_deriv = np.gradient(h0_sampled, dt)\n        r_d = dt * np.convolve(s, h0_deriv, mode='full')[:N]\n        X2 = np.vstack([r_c, r_d, intercept]).T\n        \n        beta2, _, _, _ = np.linalg.lstsq(X2, y, rcond=None)\n        A2_hat = beta2[0]\n        b2 = A2_hat - A_true\n\n        # 8. Quantify improvement R\n        R = abs(b1) - abs(b2)\n        return R\n\n    # Test Suite: Delays d in seconds\n    test_cases = [\n        0.0,   # Case 1: no delay\n        0.5,   # Case 2: small positive delay\n        2.0,   # Case 3: moderate positive delay\n        4.0,   # Case 4: large positive delay\n        -0.5   # Case 5: small negative delay\n    ]\n\n    results = []\n    for d_val in test_cases:\n        improvement = calculate_improvement(d_val)\n        results.append(improvement)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}