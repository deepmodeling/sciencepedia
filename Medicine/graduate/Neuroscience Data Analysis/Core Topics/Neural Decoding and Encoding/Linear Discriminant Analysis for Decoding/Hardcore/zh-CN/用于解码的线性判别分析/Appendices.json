{
    "hands_on_practices": [
        {
            "introduction": "线性判别分析（LDA）的核心在于找到一个最佳的投影方向，即权重向量，以最大化类别间的可分离性。这个基础练习将引导你完成从经验数据中计算该向量的关键步骤。通过这个练习，你将亲手实践如何将理论公式 $\\hat{\\mathbf{w}} = \\hat{\\boldsymbol{\\Sigma}}^{-1}(\\hat{\\boldsymbol{\\mu}}_1 - \\hat{\\boldsymbol{\\mu}}_0)$ 应用于具体的神经科学数据，从而巩固对LDA解码器构建过程的理解。",
            "id": "4174380",
            "problem": "在一个双类别神经解码任务中，一个群体响应向量 $\\mathbf{x} \\in \\mathbb{R}^{2}$ 在线性判别分析 (LDA) 的经典生成假设下被建模：每个类别 $k \\in \\{0,1\\}$ 根据一个多元正态分布产生 $\\mathbf{x}$，该分布具有依赖于类别的均值 $\\boldsymbol{\\mu}_{k}$ 和一个独立于类别的协方差 $\\boldsymbol{\\Sigma}$。决策规则是根据对数似然比和先验概率，通过具有相等错分代价的贝叶斯决策理论构建的。从多元正态对数密度和贝叶斯决策规则出发，推导用于分离类别的线性判别函数中与 $\\mathbf{x}$ 相乘的经验LDA解码权重向量 $\\hat{\\mathbf{w}}$。然后，使用来自一个具有两种条件（类别）的神经科学实验的以下经验估计量，\n- 类别样本大小 $n_{0} = 50$ 和 $n_{1} = 60$，\n- 样本均值 $\\hat{\\boldsymbol{\\mu}}_{0} = (0, 1)$ 和 $\\hat{\\boldsymbol{\\mu}}_{1} = (1, 2)$，\n- 合并协方差\n$$\n\\hat{\\boldsymbol{\\Sigma}} = \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix},\n$$\n计算此二维特征空间的经验LDA解码权重向量 $\\hat{\\mathbf{w}}$ 的数值。将 $\\hat{\\mathbf{w}}$ 的最终数值分量精确地表示为最简分数。无需四舍五入。",
            "solution": "问题要求推导经验线性判别分析 (LDA) 解码权重向量 $\\hat{\\mathbf{w}}$，并针对一组给定的经验数据进行数值计算。推导和计算过程如下。\n\n**1. LDA权重向量的推导**\n\n分类是基于给定观测向量 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 的两个类别 $k \\in \\{0,1\\}$ 的后验概率。根据具有相等错分代价的贝叶斯决策理论，如果类别 $k=1$ 的后验概率 $P(k=1|\\mathbf{x})$ 大于类别 $k=0$ 的后验概率，即 $P(k=1|\\mathbf{x})  P(k=0|\\mathbf{x})$，我们将 $\\mathbf{x}$ 分配给类别 $k=1$。\n\n使用贝叶斯定理 $P(k|\\mathbf{x}) = \\frac{p(\\mathbf{x}|k)P(k)}{p(\\mathbf{x})}$，其中 $p(\\mathbf{x}|k)$ 是类条件密度，$P(k)$ 是类先验概率，决策规则可以重写为：\n$$\n\\frac{p(\\mathbf{x}|k=1)P(k=1)}{p(\\mathbf{x})}  \\frac{p(\\mathbf{x}|k=0)P(k=0)}{p(\\mathbf{x})}\n$$\n这可以简化为 $p(\\mathbf{x}|k=1)P(k=1)  p(\\mathbf{x}|k=0)P(k=0)$。为了获得线性决策函数，我们对两边取自然对数：\n$$\n\\ln(p(\\mathbf{x}|k=1)) + \\ln(P(k=1))  \\ln(p(\\mathbf{x}|k=0)) + \\ln(P(k=0))\n$$\n这个不等式定义了一个判别函数 $\\delta(\\mathbf{x})$，我们将其与阈值 $0$ 进行比较：\n$$\n\\delta(\\mathbf{x}) = \\ln\\left(\\frac{p(\\mathbf{x}|k=1)}{p(\\mathbf{x}|k=0)}\\right) + \\ln\\left(\\frac{P(k=1)}{P(k=0)}\\right)  0\n$$\n问题陈述了类条件密度是多元正态分布，$p(\\mathbf{x}|k) = \\mathcal{N}(\\mathbf{x}; \\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma})$，具有一个公共的协方差矩阵 $\\boldsymbol{\\Sigma}$。其对数密度为：\n$$\n\\ln(p(\\mathbf{x}|k)) = -\\frac{1}{2}(\\mathbf{x} - \\boldsymbol{\\mu}_k)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) - \\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(\\boldsymbol{\\Sigma}))\n$$\n判别函数的首项是对数似然比，$\\ln(p(\\mathbf{x}|k=1)) - \\ln(p(\\mathbf{x}|k=0))$。项 $-\\frac{d}{2}\\ln(2\\pi)$ 和 $-\\frac{1}{2}\\ln(\\det(\\boldsymbol{\\Sigma}))$ 对两个类别是共同的，在求差时会消掉：\n$$\n\\ln\\left(\\frac{p(\\mathbf{x}|k=1)}{p(\\mathbf{x}|k=0)}\\right) = -\\frac{1}{2}\\left[ (\\mathbf{x} - \\boldsymbol{\\mu}_1)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_1) - (\\mathbf{x} - \\boldsymbol{\\mu}_0)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_0) \\right]\n$$\n展开二次型 $(\\mathbf{x} - \\boldsymbol{\\mu}_k)^T \\boldsymbol{\\Sigma}^{-1} (\\mathbf{x} - \\boldsymbol{\\mu}_k) = \\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - 2\\boldsymbol{\\mu}_k^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_k^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_k$，我们发现关于 $\\mathbf{x}$ 的二次项 $\\mathbf{x}^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x}$ 会消掉。\n$$\n\\ln\\left(\\frac{p(\\mathbf{x}|k=1)}{p(\\mathbf{x}|k=0)}\\right) = -\\frac{1}{2}\\left[ (-2\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1) - (-2\\boldsymbol{\\mu}_0^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} + \\boldsymbol{\\mu}_0^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_0) \\right]\n$$\n$$\n= \\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - \\boldsymbol{\\mu}_0^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}(\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_0)\n$$\n$$\n= (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0)^T \\boldsymbol{\\Sigma}^{-1}\\mathbf{x} - \\frac{1}{2}(\\boldsymbol{\\mu}_1^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0^T \\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\mu}_0)\n$$\n判别函数 $\\delta(\\mathbf{x})$ 写成 $\\mathbf{w}^T \\mathbf{x} + w_0$ 的形式。权重向量 $\\mathbf{w}$ 是表达式中与 $\\mathbf{x}$ 相乘的部分。通过观察可知，$\\mathbf{w}^T = (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0)^T \\boldsymbol{\\Sigma}^{-1}$。对两边取转置，并注意到 $\\boldsymbol{\\Sigma}^{-1}$ 是对称的，我们得到权重向量：\n$$\n\\mathbf{w} = \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0)\n$$\n对于经验情况，我们将真实参数替换为从数据中得到的样本估计值 $(\\hat{\\boldsymbol{\\mu}}_0, \\hat{\\boldsymbol{\\mu}}_1, \\hat{\\boldsymbol{\\Sigma}})$，从而得到经验权重向量 $\\hat{\\mathbf{w}}$：\n$$\n\\hat{\\mathbf{w}} = \\hat{\\boldsymbol{\\Sigma}}^{-1}(\\hat{\\boldsymbol{\\mu}}_1 - \\hat{\\boldsymbol{\\mu}}_0)\n$$\n\n**2. 数值计算**\n\n给定的经验量为：\n- 样本均值：$\\hat{\\boldsymbol{\\mu}}_{0} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ 和 $\\hat{\\boldsymbol{\\mu}}_{1} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$。\n- 合并协方差矩阵：$\\hat{\\boldsymbol{\\Sigma}} = \\begin{pmatrix} 3  1 \\\\ 1  2 \\end{pmatrix}$。\n\n首先，我们计算样本均值之差：\n$$\n\\hat{\\boldsymbol{\\mu}}_1 - \\hat{\\boldsymbol{\\mu}}_0 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n其次，我们求合并协方差矩阵的逆 $\\hat{\\boldsymbol{\\Sigma}}^{-1}$。对于一个通用的 $2 \\times 2$ 矩阵 $\\begin{pmatrix} a  b \\\\ c  d \\end{pmatrix}$，其逆由 $\\frac{1}{ad-bc}\\begin{pmatrix} d  -b \\\\ -c  a \\end{pmatrix}$ 给出。$\\hat{\\boldsymbol{\\Sigma}}$ 的行列式为 $\\det(\\hat{\\boldsymbol{\\Sigma}}) = (3)(2) - (1)(1) = 5$。\n因此，逆矩阵为：\n$$\n\\hat{\\boldsymbol{\\Sigma}}^{-1} = \\frac{1}{5} \\begin{pmatrix} 2  -1 \\\\ -1  3 \\end{pmatrix} = \\begin{pmatrix} \\frac{2}{5}  -\\frac{1}{5} \\\\ -\\frac{1}{5}  \\frac{3}{5} \\end{pmatrix}\n$$\n最后，我们将这些代入 $\\hat{\\mathbf{w}}$ 的公式中：\n$$\n\\hat{\\mathbf{w}} = \\hat{\\boldsymbol{\\Sigma}}^{-1}(\\hat{\\boldsymbol{\\mu}}_1 - \\hat{\\boldsymbol{\\mu}}_0) = \\begin{pmatrix} \\frac{2}{5}  -\\frac{1}{5} \\\\ -\\frac{1}{5}  \\frac{3}{5} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n执行矩阵-向量乘法：\n$$\n\\hat{\\mathbf{w}} = \\begin{pmatrix} \\frac{2}{5}(1) - \\frac{1}{5}(1) \\\\ -\\frac{1}{5}(1) + \\frac{3}{5}(1) \\end{pmatrix} = \\begin{pmatrix} \\frac{2-1}{5} \\\\ \\frac{-1+3}{5} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5} \\\\ \\frac{2}{5} \\end{pmatrix}\n$$\n经验LDA解码权重向量的分量为 $\\frac{1}{5}$ 和 $\\frac{2}{5}$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{5} \\\\\n\\frac{2}{5}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "当数据的真实分布满足LDA的高斯假设时，LDA分类器不仅是一个好的分类器，它在理论上是贝叶斯最优的。这个练习将从纯粹的计算转向一个完整的计算模拟，让你通过编写代码来验证这一关键的理论结果。你将学习如何构建一个生成模型，训练一个分类器，并在一个独立的测试集上评估其性能，然后将其与理论上的最优准确率进行比较。",
            "id": "4174390",
            "problem": "你需要设计并分析一个仿真，以在一个统计上明确定义的生成模型下，评估线性判别分析 (LDA) 在神经解码中的性能。考虑一个双类别神经群体编码，其中观测到的特征向量 $x \\in \\mathbb{R}^2$ 服从以下类别条件模型：对于类别标签 $y \\in \\{0,1\\}$，$x \\mid y=k \\sim \\mathcal{N}(\\mu_k,\\Sigma)$，其中 $\\mathcal{N}$ 表示多元正态分布。假设类别先验相等，$P(y=0)=P(y=1)=\\tfrac{1}{2}$。协方差矩阵由相关系数 $ \\rho \\in (-1,1)$ 参数化，且方差为单位1，\n$$\n\\Sigma(\\rho) = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix},\n$$\n均值向量为\n$$\n\\mu_0 = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}, \\qquad \\mu_1 = \\begin{pmatrix}\\delta \\\\ \\delta\\end{pmatrix},\n$$\n其中 $\\delta \\in \\mathbb{R}$ 控制均值的分离程度。你将通过推导和仿真来验证，在这些假设下，LDA 能够达到贝叶斯最优分类准确率。\n\n从第一性原理出发，使用以下与上下文相符的基础知识：\n- 贝叶斯分类器的定义，即最大化后验概率 $P(y=k \\mid x)$ 的决策规则，这等价于对从类别条件密度和类别先验推导出的对数似然比进行阈值处理。\n- 均值为 $\\mu$、协方差为 $\\Sigma$ 的多元正态密度及其对数似然的显式形式。\n- 当类别先验相等且类别协方差相等时，决策边界是关于 $x$ 的线性函数的统计学事实。\n\n你的任务是：\n1. 从多元正态对数似然比和相等的先验出发，推导该模型的最优贝叶斯决策规则，明确地将线性判别方向和决策阈值表示为 $\\mu_0$、$\\mu_1$ 和 $\\Sigma$ 的函数。不要在没有推导的情况下引入任何捷径公式。\n2. 使用导出的一维判别变量，推导贝叶斯最优准确率的解析表达式，将其表示为 $\\mu_0$ 和 $\\mu_1$ 在协方差 $\\Sigma$ 下的马氏距离平方的函数。将准确率表示为一个标量 $A(\\delta,\\rho) \\in [0,1]$。\n3. 实现一个仿真，以估计从数据中训练的 LDA 的经验准确率。对于每组参数设置，根据指定的高斯模型为每个类别生成 $n$ 个独立样本，从样本中估计类别均值和合并协方差，构建 LDA 判别器，并在一个从相同生成模型中抽取的留出集上计算经验分类准确率。为训练和测试使用同样大的样本量以最小化方差，并确保估计的协方差在数值上是稳定的。此问题不涉及任何物理单位。\n\n测试套件和要求的输出：\n- 使用以下参数值，每个值产生一个独立的测试用例：\n    1. $(\\rho,\\delta,n) = (0,1,80000)$。\n    2. $(\\rho,\\delta,n) = (0.8,1,80000)$。\n    3. $(\\rho,\\delta,n) = (-0.8,1,80000)$。\n    4. $(\\rho,\\delta,n) = (0.99,0.5,80000)$。\n    5. $(\\rho,\\delta,n) = (0.2,0,80000)$。\n- 对于每个测试用例，计算经验 LDA 准确率与任务2中推导的解析贝叶斯最优准确率之间的绝对差。设 $\\varepsilon = 0.02$，返回一个布尔值，指示该绝对差是否小于或等于 $\\varepsilon$。\n- 最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[$\\texttt{result1}$,$\\texttt{result2}$,$\\texttt{result3}$,$\\texttt{result4}$,$\\texttt{result5}$]”），其中每个 $\\texttt{resulti}$ 是对应于第 $i$ 个测试用例的布尔值。\n\n使用最终答案部分指定的单个、自包含的程序实现解决方案。不允许外部输入或文件，并且应为随机数生成器设定种子以确保可复现性。你不能在此问题陈述中提供任何目标公式；应在你的解决方案中推导它们。",
            "solution": "该问题要求在一个指定的高斯生成模型下，通过推导和基于仿真的验证，来评估线性判别分析 (LDA) 在一个双类别分类问题上的性能。任务的核心是证明对于该模型——其类别条件密度是具有相同协方差矩阵的多元正态分布——LDA 分类器等价于贝叶斯最优分类器，并且其在大型数据集上的经验准确率会收敛于解析推导出的贝叶斯最优准确率。\n\n解决方案按要求分三部分进行：\n1.  最优贝叶斯决策规则的推导。\n2.  解析贝叶斯最优准确率的推导。\n3.  设计并实现一个仿真，用以计算训练后的 LDA 分类器的经验准确率，并将其与解析结果进行比较。\n\n### 1. 最优贝叶斯决策规则的推导\n\n目标是找到使分类错误概率最小化的决策规则。对于给定的特征向量 $x$，贝叶斯分类器将其分配给使后验概率 $P(y=k \\mid x)$ 最大化的类别 $y=k$。决策规则是：如果 $P(y=1 \\mid x)  P(y=0 \\mid x)$，则选择类别 $y=1$，否则选择类别 $y=0$。\n\n使用贝叶斯定理，$P(y=k \\mid x) = \\frac{P(x \\mid y=k)P(y=k)}{P(x)}$。决策规则变为：\n$$\n\\frac{P(x \\mid y=1)P(y=1)}{P(x)}  \\frac{P(x \\mid y=0)P(y=0)}{P(x)}\n$$\n由于给定的类别先验相等，$P(y=0) = P(y=1) = \\frac{1}{2}$，这简化为对类别条件似然的比较：\n$$\nP(x \\mid y=1)  P(x \\mid y=0)\n$$\n对两边取自然对数（这是一个单调变换），我们得到等价的对数似然比检验：\n$$\n\\ln P(x \\mid y=1) - \\ln P(x \\mid y=0)  0\n$$\n问题陈述，类别条件密度 $P(x \\mid y=k)$ 是一个二维多元正态分布 $\\mathcal{N}(\\mu_k, \\Sigma)$。其概率密度函数为：\n$$\nP(x \\mid \\mu_k, \\Sigma) = \\frac{1}{(2\\pi)^{d/2}|\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2}(x-\\mu_k)^T\\Sigma^{-1}(x-\\mu_k)\\right)\n$$\n其中 $d=2$ 是维度。对数似然为：\n$$\n\\ln P(x \\mid \\mu_k, \\Sigma) = -\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\Sigma| - \\frac{1}{2}(x-\\mu_k)^T\\Sigma^{-1}(x-\\mu_k)\n$$\n将此代入对数似然比检验，常数项 $-\\frac{d}{2}\\ln(2\\pi)$ 和 $-\\frac{1}{2}\\ln|\\Sigma|$（因为 $\\Sigma$ 对两个类别是共同的）会相互抵消：\n$$\n-\\frac{1}{2}(x-\\mu_1)^T\\Sigma^{-1}(x-\\mu_1) - \\left(-\\frac{1}{2}(x-\\mu_0)^T\\Sigma^{-1}(x-\\mu_0)\\right)  0\n$$\n$$\n(x-\\mu_0)^T\\Sigma^{-1}(x-\\mu_0) - (x-\\mu_1)^T\\Sigma^{-1}(x-\\mu_1)  0\n$$\n展开二次型：\n$$\n(x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\mu_0 + \\mu_0^T\\Sigma^{-1}\\mu_0) - (x^T\\Sigma^{-1}x - 2x^T\\Sigma^{-1}\\mu_1 + \\mu_1^T\\Sigma^{-1}\\mu_1)  0\n$$\n$x$ 的二次项 $x^T\\Sigma^{-1}x$ 被消掉。重新整理剩余项，得到一个线性决策规则：\n$$\n2x^T\\Sigma^{-1}\\mu_1 - 2x^T\\Sigma^{-1}\\mu_0  \\mu_1^T\\Sigma^{-1}\\mu_1 - \\mu_0^T\\Sigma^{-1}\\mu_0\n$$\n$$\n(\\mu_1 - \\mu_0)^T\\Sigma^{-1}x  \\frac{1}{2}(\\mu_1^T\\Sigma^{-1}\\mu_1 - \\mu_0^T\\Sigma^{-1}\\mu_0)\n$$\n这是 $w^T x  c$ 的形式，定义了一个线性分类器。**线性判别方向**是：\n$$\nw = \\Sigma^{-1}(\\mu_1 - \\mu_0)\n$$\n**决策阈值**是：\n$$\nc = \\frac{1}{2}(\\mu_1^T\\Sigma^{-1}\\mu_1 - \\mu_0^T\\Sigma^{-1}\\mu_0) = \\frac{1}{2}(w^T\\mu_1 + w^T\\mu_0) = w^T\\left(\\frac{\\mu_0 + \\mu_1}{2}\\right)\n$$\n这就是最优贝叶斯分类器的决策规则，其形式与 LDA 分类器完全相同。\n\n### 2. 解析贝叶斯最优准确率的推导\n\nLDA/贝叶斯分类器将数据 $x$ 投影到方向 $w$上，并基于一个阈值进行分类。投影后的标量变量为 $z = w^T x$。由于 $x$ 是一个高斯随机向量，$z$ 是一个高斯随机变量。其在类别 $y=k$ 条件下的分布是 $z \\mid y=k \\sim \\mathcal{N}(E[z|y=k], \\text{Var}(z|y=k))$。\n\n对于类别 $k$，投影变量的均值是：\n$$\n\\mu_{z,k} = E[w^T x \\mid y=k] = w^T E[x \\mid y=k] = w^T \\mu_k\n$$\n由于协方差矩阵 $\\Sigma$ 是共享的，两个类别的方差相同：\n$$\n\\sigma_z^2 = \\text{Var}(w^T x) = w^T \\Sigma w = (\\Sigma^{-1}(\\mu_1 - \\mu_0))^T \\Sigma (\\Sigma^{-1}(\\mu_1 - \\mu_0)) = (\\mu_1 - \\mu_0)^T \\Sigma^{-T} (\\mu_1 - \\mu_0)\n$$\n因为 $\\Sigma$ 是一个协方差矩阵，所以它是对称的（$\\Sigma^T=\\Sigma$），其逆矩阵也是对称的。\n$$\n\\sigma_z^2 = (\\mu_1 - \\mu_0)^T \\Sigma^{-1} (\\mu_1 - \\mu_0) = \\Delta^2\n$$\n这个量 $\\Delta^2$ 是均值 $\\mu_0$ 和 $\\mu_1$ 之间的马氏距离的平方。投影数据的标准差是 $\\sigma_z = \\Delta$。\n\n现在分类任务是一维的：给定 $z_0 \\sim \\mathcal{N}(\\mu_{z,0}, \\Delta^2)$ 和 $z_1 \\sim \\mathcal{N}(\\mu_{z,1}, \\Delta^2)$，找到最优阈值和由此产生的准确率。最优阈值是均值的中点：\n$$\nc_z = \\frac{\\mu_{z,0} + \\mu_{z,1}}{2} = \\frac{w^T\\mu_0 + w^T\\mu_1}{2} = w^T\\left(\\frac{\\mu_0 + \\mu_1}{2}\\right) = c\n$$\n由于先验相等，总准确率 $A$ 是类别条件准确率的平均值：\n$A = \\frac{1}{2} P(\\text{correct} \\mid y=0) + \\frac{1}{2} P(\\text{correct} \\mid y=1)$。假设 $w^T\\mu_1  w^T_0$，决策规则是如果 $zc_z$ 则 $y=1$。\n$$\nP(\\text{correct} \\mid y=1) = P(z  c_z \\mid y=1) = P\\left(\\frac{z-\\mu_{z,1}}{\\Delta}  \\frac{c_z-\\mu_{z,1}}{\\Delta}\\right) = P\\left(Z  \\frac{(\\mu_{z,0}+\\mu_{z,1})/2 - \\mu_{z,1}}{\\Delta}\\right)\n$$\n其中 $Z \\sim \\mathcal{N}(0,1)$。这是 $P(Z  \\frac{\\mu_{z,0}-\\mu_{z,1}}{2\\Delta}) = P(Z  \\frac{\\mu_{z,1}-\\mu_{z,0}}{2\\Delta})$。类似地，$P(\\text{correct} \\mid y=0) = P(Z  \\frac{\\mu_{z,1}-\\mu_{z,0}}{2\\Delta})$。\n投影均值的分离度是 $\\mu_{z,1}-\\mu_{z,0} = w^T(\\mu_1-\\mu_0) = (\\mu_1-\\mu_0)^T \\Sigma^{-1} (\\mu_1-\\mu_0) = \\Delta^2$。\n因此每个类别的准确率是 $P(Z  \\frac{\\Delta^2}{2\\Delta}) = P(Z  \\frac{\\Delta}{2}) = \\Phi(\\frac{\\Delta}{2})$，其中 $\\Phi$ 是标准正态分布的累积分布函数 (CDF)。\n总准确率为 $A = \\Phi(\\frac{\\Delta}{2})$。\n\n对于具体模型：$\\mu_0 = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$，$\\mu_1 = \\begin{pmatrix}\\delta \\\\ \\delta\\end{pmatrix}$，$\\Sigma(\\rho) = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$。\n逆协方差矩阵是 $\\Sigma^{-1} = \\frac{1}{1-\\rho^2}\\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$。\n马氏距离的平方是：\n$$\n\\Delta^2 = (\\mu_1-\\mu_0)^T \\Sigma^{-1} (\\mu_1-\\mu_0) = \\begin{pmatrix}\\delta  \\delta\\end{pmatrix} \\frac{1}{1-\\rho^2}\\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} \\begin{pmatrix}\\delta \\\\ \\delta\\end{pmatrix}\n$$\n$$\n\\Delta^2 = \\frac{\\delta^2}{1-\\rho^2} \\begin{pmatrix}1-\\rho  1-\\rho\\end{pmatrix} \\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\frac{\\delta^2(2-2\\rho)}{1-\\rho^2} = \\frac{2\\delta^2(1-\\rho)}{(1-\\rho)(1+\\rho)} = \\frac{2\\delta^2}{1+\\rho}\n$$\n因此，贝叶斯最优准确率为：\n$$\nA(\\delta, \\rho) = \\Phi\\left(\\frac{1}{2}\\sqrt{\\frac{2\\delta^2}{1+\\rho}}\\right) = \\Phi\\left(\\frac{|\\delta|}{\\sqrt{2(1+\\rho)}}\\right)\n$$\n\n### 3. 仿真设计\n\n仿真验证了在一个有限但大型的数据集上训练的 LDA 分类器所实现的经验准确率能够紧密逼近理论上的贝叶斯最优准确率 $A(\\delta, \\rho)$。\n\n对于每组参数 $(\\rho, \\delta, n)$：\n1.  **解析准确率计算**：理论准确率 $A_{Bayes}$ 使用推导出的公式计算。在数值实现中，标准正态 CDF $\\Phi(x)$ 可通过误差函数 $\\text{erf}(x)$ 表示：$\\Phi(x) = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$。\n    $$\n    A_{Bayes} = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{|\\delta|}{\\sqrt{2(1+\\rho)}\\sqrt{2}}\\right)\\right) = \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{|\\delta|}{2\\sqrt{1+\\rho}}\\right)\\right)\n    $$\n2.  **数据生成**：生成两个数据集：一个训练集和一个留出测试集。使用一个独立的测试集（“留出集”）对于获得分类器泛化性能的无偏估计至关重要。\n    *   **训练集**：$n$ 个类别 0 的样本，$X_{train,0} \\sim \\mathcal{N}(\\mu_0, \\Sigma)$，以及 $n$ 个类别 1 的样本，$X_{train,1} \\sim \\mathcal{N}(\\mu_1, \\Sigma)$。\n    *   **测试集**：为确保准确率估计的低方差，独立生成一个同样大小的大型测试集：$n$ 个类别 0 的样本，$X_{test,0} \\sim \\mathcal.N}(\\mu_0, \\Sigma)$，以及 $n$ 个类别 1 的样本，$X_{test,1} \\sim \\mathcal{N}(\\mu_1, \\Sigma)$。固定的随机种子确保了可复现性。\n3.  **LDA 参数估计**：从训练数据中估计 LDA 参数。\n    *   样本均值：$\\hat{\\mu}_0 = \\frac{1}{n}\\sum_{x \\in X_{train,0}} x$，$\\hat{\\mu}_1 = \\frac{1}{n}\\sum_{x \\in X_{train,1}} x$。\n    *   样本协方差：$\\hat{\\Sigma}_0$ 和 $\\hat{\\Sigma}_1$ 是每个类别的无偏样本协方差矩阵。\n    *   合并协方差：$\\hat{\\Sigma}_{pooled} = \\frac{(n-1)\\hat{\\Sigma}_0 + (n-1)\\hat{\\Sigma}_1}{(n-1)+(n-1)} = \\frac{\\hat{\\Sigma}_0 + \\hat{\\Sigma}_1}{2}$。\n4.  **经验准确率计算**：将训练好的分类器应用于测试集。\n    *   计算估计的权重向量 $\\hat{w} = \\hat{\\Sigma}_{pooled}^{-1}(\\hat{\\mu}_1 - \\hat{\\mu}_0)$ 和阈值 $\\hat{c} = \\hat{w}^T(\\hat{\\mu}_0 + \\hat{\\mu}_1)/2$。\n    *   通过比较得分 $\\hat{w}^T x_{test}$ 与阈值 $\\hat{c}$ 来对测试样本 $x_{test}$ 进行分类。\n    *   经验准确率 $A_{emp}$ 是测试集中被正确分类的样本比例。\n5.  **比较**：计算绝对差 $|A_{emp} - A_{Bayes}|$ 并与容差 $\\varepsilon=0.02$ 进行核对。结果是一个布尔值。\n\n对所有五个测试用例重复此过程。大的样本量 $n=80000$ 确保了估计的参数 $(\\hat{\\mu}_k, \\hat{\\Sigma}_{pooled})$ 非常接近真实参数，因此训练后的 LDA 的经验准确率应非常接近理论上的贝叶斯最优准确率。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Solves the LDA simulation problem by deriving, simulating, and comparing\n    analytic and empirical classification accuracies.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (rho, delta, n)\n        (0.0, 1.0, 80000),\n        (0.8, 1.0, 80000),\n        (-0.8, 1.0, 80000),\n        (0.99, 0.5, 80000),\n        (0.2, 0.0, 80000),\n    ]\n\n    # Global parameters\n    random_seed = 42\n    epsilon = 0.02\n    \n    # Use a single RNG for reproducibility across all cases\n    rng = np.random.default_rng(random_seed)\n\n    # -------- Helper Functions --------\n\n    def calculate_analytic_accuracy(rho, delta):\n        \"\"\"\n        Calculates the theoretical Bayes-optimal accuracy A(delta, rho).\n        A = Phi(|delta| / sqrt(2 * (1 + rho))), where Phi is the standard normal CDF.\n        \"\"\"\n        if 1.0 + rho = 0:\n            # Avoid division by zero or sqrt of negative. Given rho in (-1,1), this is only for rho -> -1.\n            # For this problem's constraints, 1+rho is always > 0.\n            return 1.0 if delta != 0 else 0.5\n\n        if delta == 0:\n            return 0.5\n        \n        # A = Phi(x) = 0.5 * (1 + erf(x / sqrt(2)))\n        # x = |delta| / sqrt(2 * (1 + rho))\n        arg_for_erf = abs(delta) / (2.0 * np.sqrt(1.0 + rho))\n        accuracy = 0.5 * (1.0 + erf(arg_for_erf))\n        \n        return accuracy\n\n    def run_simulation(rho, delta, n_samples_per_class, rng_instance):\n        \"\"\"\n        Runs the LDA simulation for a given set of parameters.\n        \"\"\"\n        # 1. Define the true generative model parameters\n        mu0_true = np.array([0.0, 0.0])\n        mu1_true = np.array([delta, delta])\n        cov_true = np.array([[1.0, rho], [rho, 1.0]])\n\n        # 2. Generate training data\n        train_data_0 = rng_instance.multivariate_normal(mu0_true, cov_true, size=n_samples_per_class)\n        train_data_1 = rng_instance.multivariate_normal(mu1_true, cov_true, size=n_samples_per_class)\n\n        # 3. Estimate LDA parameters from training data\n        mu0_hat = np.mean(train_data_0, axis=0)\n        mu1_hat = np.mean(train_data_1, axis=0)\n        \n        # Unbiased sample covariance (ddof=1)\n        cov0_hat = np.cov(train_data_0, rowvar=False, ddof=1)\n        cov1_hat = np.cov(train_data_1, rowvar=False, ddof=1)\n        \n        # Pooled covariance\n        cov_pooled_hat = (cov0_hat + cov1_hat) / 2.0\n        \n        # Ensure numerical stability for inversion, although with n=80000 it's unlikely to be an issue\n        try:\n            inv_cov_pooled_hat = np.linalg.inv(cov_pooled_hat)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse if singular, or add regularization (not specified, so inv is preferred)\n            inv_cov_pooled_hat = np.linalg.pinv(cov_pooled_hat)\n\n        # 4. Construct the trained LDA classifier\n        w_hat = inv_cov_pooled_hat @ (mu1_hat - mu0_hat)\n        c_hat = 0.5 * w_hat.T @ (mu0_hat + mu1_hat)\n\n        # 5. Generate a separate held-out test set\n        test_data_0 = rng_instance.multivariate_normal(mu0_true, cov_true, size=n_samples_per_class)\n        test_data_1 = rng_instance.multivariate_normal(mu1_true, cov_true, size=n_samples_per_class)\n\n        # 6. Compute empirical accuracy on the test set\n        # For class 0, prediction is correct if w^T.x = c\n        scores_0 = test_data_0 @ w_hat\n        correct_0 = np.sum(scores_0 = c_hat)\n        \n        # For class 1, prediction is correct if w^T.x > c\n        scores_1 = test_data_1 @ w_hat\n        correct_1 = np.sum(scores_1 > c_hat)\n\n        total_correct = correct_0 + correct_1\n        total_samples = 2 * n_samples_per_class\n        empirical_accuracy = total_correct / total_samples\n        \n        return empirical_accuracy\n\n    # -------- Main Logic --------\n\n    results = []\n    for rho_val, delta_val, n_val in test_cases:\n        # Calculate analytic Bayes-optimal accuracy\n        analytic_acc = calculate_analytic_accuracy(rho_val, delta_val)\n        \n        # Estimate empirical LDA accuracy via simulation\n        empirical_acc = run_simulation(rho_val, delta_val, n_val, rng)\n        \n        # Compare and store the boolean result\n        abs_diff = abs(empirical_acc - analytic_acc)\n        results.append(abs_diff = epsilon)\n\n    # Final print statement in the exact required format.\n    # The Python 'bool' type stringifies to 'True' and 'False' with a capital letter.\n    # The problem example shows lowercase 'true', 'false'. Let's match that.\n    print(f\"[{','.join(map(str, results)).lower()}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "在真实的神经科学研究中，数据（如神经元发放计数）往往不完全符合高斯分布，这导致了LDA模型的“失配”问题。这个练习模拟了一个更贴近现实的场景，即数据服从泊松分布，并探讨了如何应对这一挑战。通过比较在原始计数和经过方差稳定变换（Anscombe变换）后的数据上LDA的性能，你将学到一种在真实数据上应用LDA等模型的宝贵预处理策略。",
            "id": "4174506",
            "problem": "您的任务是评估在使用线性判别分析（LDA）对神经活动进行二元分类时，将脉冲计数特征建模为近似高斯分布所引入的经验解码误差。考虑一个合成数据生成过程，其中，在每次试验中，来自 $p$ 个神经元的脉冲计数在给定类别标签 $y \\in \\{0,1\\}$ 的条件下是条件独立的，并且服从具有类别特定率向量的独立泊松分布的乘积。具体来说，对于类别 $k \\in \\{0,1\\}$ 和神经元 $j \\in \\{1,\\dots,p\\}$，脉冲计数 $X_j \\mid y=k$ 服从 $X_j \\sim \\mathrm{Poisson}(\\lambda^{(k)}_j)$ 分布，且 $X_j$ 在不同 $j$ 之间是条件独立的。每次试验产生一个特征向量 $x \\in \\mathbb{N}^p$。\n\n您的程序必须比较两个基于线性判别分析（LDA）的解码器，LDA 假设类条件分布为具有共享协方差的高斯分布：\n- 解码器 A 使用原始计数，即特征 $x$。\n- 解码器 B 使用平方根变换后的计数，其特征为 $z = \\sqrt{x + c}$，其中 $c$ 是一个固定常数，定义为 $c = 3/8$。\n\n两个解码器都应在类别先验概率相等的情况下，使用标准的 LDA 决策规则进行训练，从训练数据中估计类别均值和合并协方差矩阵。为确保有限样本协方差估计的数值稳定性，通过向合并协方差矩阵中添加 $\\epsilon I_p$ 来应用岭正则化，其中 $\\epsilon = 10^{-6}$，$I_p$ 是 $p \\times p$ 的单位矩阵。正则化参数 $\\epsilon$ 是固定的，无需调整。\n\n您的目标是根据以下测试套件，在泊松模型下模拟数据，训练这两个解码器，并在每种情况下在独立的测试集上评估它们的错分率。对于每种情况，您必须计算一个标量，该标量定义为解码器 A（原始计数）的错误率与解码器 B（平方根变换计数）的错误率之差，即\n$$\n\\Delta = \\mathrm{Err}_{\\text{raw}} - \\mathrm{Err}_{\\sqrt{\\cdot}},\n$$\n其中每个错误率是测试集上错分试验的经验分数，表示为 $[0,1]$ 范围内的十进制数，不带百分号。正的 $\\Delta$ 值表示平方根变换特征具有优势。\n\n实现以下测试套件。在每种情况下，使用指定的随机种子抽取独立的训练集和测试集，每个类别有 $n_{\\mathrm{tr}}$ 次训练试验和 $n_{\\mathrm{te}}$ 次测试试验。所有脉冲计数都是无量纲的计数。\n\n- 情况 1：\n  - $p = 5$,\n  - $\\lambda^{(0)} = [0.2, 0.5, 0.3, 0.1, 0.4]$,\n  - $\\lambda^{(1)} = [0.8, 0.5, 0.7, 0.1, 0.6]$,\n  - $n_{\\mathrm{tr}} = 400$,\n  - $n_{\\mathrm{te}} = 800$,\n  - $\\text{seed} = 1234$.\n\n- 情况 2：\n  - $p = 8$,\n  - $\\lambda^{(0)} = [3, 5, 2, 6, 1, 4, 3, 2]$,\n  - $\\lambda^{(1)} = [4, 4, 3, 7, 1, 6, 2, 3]$,\n  - $n_{\\mathrm{tr}} = 300$,\n  - $n_{\\mathrm{te}} = 600$,\n  - $\\text{seed} = 2021$.\n\n- 情况 3：\n  - $p = 6$,\n  - $\\lambda^{(0)} = [20, 35, 18, 42, 10, 25]$,\n  - $\\lambda^{(1)} = [24, 32, 22, 40, 12, 28]$,\n  - $n_{\\mathrm{tr}} = 200$,\n  - $n_{\\mathrm{te}} = 400$,\n  - $\\text{seed} = 7$.\n\n- 情况 4：\n  - $p = 12$,\n  - $\\lambda^{(0)} = [2, 4, 1, 3, 5, 2, 1, 4, 3, 2, 5, 1]$,\n  - $\\lambda^{(1)} = [3, 3, 2, 4, 5, 3, 2, 5, 2, 3, 6, 1]$,\n  - $n_{\\mathrm{tr}} = 5$,\n  - $n_{\\mathrm{te}} = 500$,\n  - $\\text{seed} = 99$.\n\n对于每种情况，执行以下步骤：\n- 通过从指定的泊松分布中独立抽样来生成训练数据和测试数据。\n- 训练两个 LDA 分类器：一个使用原始计数 $x$，另一个使用变换后的计数 $z = \\sqrt{x + 3/8}$。\n- 在测试集的相应表示上评估每个分类器的经验错分误差。\n- 按上述定义计算 $\\Delta$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含对应于情况 1 到 4 的四个 $\\Delta$ 值，四舍五入到 $6$ 位小数，格式为用方括号括起来的逗号分隔列表，例如\n$[0.012345,0.000000,-0.001234,0.056789]$。",
            "solution": "该问题要求比较两种用于分类神经脉冲计数数据的线性判别分析（LDA）解码器。每个类别的数据都从一组独立的泊松分布中生成。问题的核心是评估一种方差稳定变换——具体来说是平方根变换——是否能提高 LDA 的性能，而 LDA 的形式化假设是类条件数据分布为具有共享协方差矩阵的高斯分布。\n\n第一步是形式化数据生成过程。对于两个类别中的每一个，即 $k \\in \\{0, 1\\}$，我们为 $p$ 个神经元生成脉冲计数。在给定类别 $k$ 的情况下，神经元 $j$ 的计数 $X_j$ 是一个随机变量，服从泊松分布，其类别特定率参数为 $\\lambda_j^{(k)}$，记为 $X_j \\mid y=k \\sim \\mathrm{Poisson}(\\lambda_j^{(k)})$。单次试验产生一个特征向量 $x = [X_1, \\dots, X_p]^T$。问题规定，对于四个测试用例中的每一个，我们必须为每个类别生成一个包含 $n_{\\mathrm{tr}}$ 次试验的训练集和一个包含 $n_{\\mathrm{te}}$ 次试验的独立测试集，并使用特定的随机种子以保证可复现性。\n\n待比较的两个解码器在不同的特征表示上操作：\n1.  **解码器 A（原始计数）**：直接使用特征向量 $x$。\n2.  **解码器 B（变换后计数）**：使用特征向量 $z = \\sqrt{x + c}$，其中常数 $c = 3/8$。这是 Anscombe 变换，旨在稳定泊松分布数据的方差。对于一个泊松变量 $X \\sim \\mathrm{Poisson}(\\lambda)$，其均值为 $\\mathrm{E}[X] = \\lambda$，方差为 $\\mathrm{Var}(X) = \\lambda$。方差依赖于均值。对于较大的 $\\lambda$，变换 $Z = \\sqrt{X+c}$ 旨在使 $Z$ 的方差近似为常数，且独立于 $\\lambda$。这种变换可以使数据的分布更适合 LDA 所基于的高斯假设。\n\n两个解码器都采用 LDA 分类规则。LDA 假设类别 $k$ 的特征 $v$ 的概率密度是多元高斯分布，$p(v|y=k) = \\mathcal{N}(v | \\mu_k, \\Sigma)$，并且在不同类别之间具有共享的协方差矩阵 $\\Sigma$。在两个类别的先验概率相等的情况下，即 $P(y=0) = P(y=1) = 0.5$，如果对数似然比为正，则新的数据点 $v$ 被分类为类别 1：\n$$\n\\log \\frac{p(v|y=1)}{p(v|y=0)}  0\n$$\n代入高斯密度函数会得到一个线性决策规则。如果 $w^T v  b$，点 $v$ 被分配到类别 1，其中：\n-   权重向量为 $w = \\Sigma^{-1}(\\mu_1 - \\mu_0)$。\n-   决策阈值（或偏置）为 $b = \\frac{1}{2}(\\mu_1 + \\mu_0)^T w = \\frac{1}{2}(\\mu_1^T \\Sigma^{-1} \\mu_1 - \\mu_0^T \\Sigma^{-1} \\mu_0)$。\n\n在实践中，真实参数 $\\mu_0, \\mu_1, \\Sigma$ 是未知的，必须从训练数据中估计。对于每个解码器（操作于特征 $v=x$ 或 $v=z$），训练过程如下：\n1.  **估计类别均值**：对于每个类别 $k \\in \\{0, 1\\}$，均值向量 $\\mu_k$ 通过该类别训练数据的样本均值来估计：\n    $$\n    \\hat{\\mu}_k = \\frac{1}{n_{\\mathrm{tr}}} \\sum_{i=1}^{n_{\\mathrm{tr}}} v_i^{(k)}\n    $$\n2.  **估计合并协方差**：首先，计算单个的样本协方差矩阵：\n    $$\n    \\hat{\\Sigma}_k = \\frac{1}{n_{\\mathrm{tr}}-1} \\sum_{i=1}^{n_{\\mathrm{tr}}} (v_i^{(k)} - \\hat{\\mu}_k) (v_i^{(k)} - \\hat{\\mu}_k)^T\n    $$\n    由于每个类别的训练样本数相等（$n_0 = n_1 = n_{\\mathrm{tr}}$），合并协方差估计是个体估计的平均值：\n    $$\n    \\hat{\\Sigma}_{\\text{pooled}} = \\frac{(n_{\\mathrm{tr}}-1)\\hat{\\Sigma}_0 + (n_{\\mathrm{tr}}-1)\\hat{\\Sigma}_1}{(n_{\\mathrm{tr}}-1) + (n_{\\mathrm{tr}}-1)} = \\frac{1}{2}(\\hat{\\Sigma}_0 + \\hat{\\Sigma}_1)\n    $$\n3.  **应用正则化**：为确保协方差矩阵是良态且可逆的，尤其是在特征数量 $p$ 相对于样本数量 $n_{\\mathrm{tr}}$ 较大时（如情况 4），应用岭正则化：\n    $$\n    \\hat{\\Sigma}_{\\text{reg}} = \\hat{\\Sigma}_{\\text{pooled}} + \\epsilon I_p\n    $$\n    其中 $\\epsilon = 10^{-6}$ 是一个很小的常数，$I_p$ 是 $p \\times p$ 的单位矩阵。\n4.  **计算分类器参数**：将估计出的参数代入 $w$ 和 $b$ 的公式中：\n    $$\n    \\hat{w} = \\hat{\\Sigma}_{\\text{reg}}^{-1}(\\hat{\\mu}_1 - \\hat{\\mu}_0)\n    $$\n    $$\n    \\hat{b} = \\frac{1}{2}(\\hat{\\mu}_1 + \\hat{\\mu}_0)^T \\hat{w}\n    $$\n训练后，每个解码器都在独立的测试集上进行评估。对于一个测试样本 $v_{\\text{test}}$，如果 $\\hat{w}^T v_{\\text{test}}  \\hat{b}$，则预测类别 $\\hat{y}$ 为 1，否则为 0。经验错误率 $\\mathrm{Err}$ 是测试集中被错误分类的样本所占的比例。\n$$\n\\mathrm{Err} = \\frac{\\text{Number of misclassified test samples}}{\\text{Total number of test samples}} = \\frac{1}{2n_{\\mathrm{te}}} \\sum_{i=1}^{2n_{\\mathrm{te}}} \\mathbb{I}(\\hat{y}_i \\neq y_i)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n\n对解码器 A（使用原始计数 $x$）和解码器 B（使用变换后计数 $z$）都执行此过程，分别得到错误率 $\\mathrm{Err}_{\\text{raw}}$ 和 $\\mathrm{Err}_{\\sqrt{\\cdot}}$。每个测试用例最终关注的量是其差值：\n$$\n\\Delta = \\mathrm{Err}_{\\text{raw}} - \\mathrm{Err}_{\\sqrt{\\cdot}}\n$$\n正的 $\\Delta$ 值表示平方根变换通过降低错误率提高了解码性能。对于四个指定的测试用例中的每一个，都重复这整个模拟过程。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Case 1\n        {\n            \"p\": 5,\n            \"lambda0\": np.array([0.2, 0.5, 0.3, 0.1, 0.4]),\n            \"lambda1\": np.array([0.8, 0.5, 0.7, 0.1, 0.6]),\n            \"n_tr\": 400,\n            \"n_te\": 800,\n            \"seed\": 1234,\n        },\n        # Case 2\n        {\n            \"p\": 8,\n            \"lambda0\": np.array([3, 5, 2, 6, 1, 4, 3, 2]),\n            \"lambda1\": np.array([4, 4, 3, 7, 1, 6, 2, 3]),\n            \"n_tr\": 300,\n            \"n_te\": 600,\n            \"seed\": 2021,\n        },\n        # Case 3\n        {\n            \"p\": 6,\n            \"lambda0\": np.array([20, 35, 18, 42, 10, 25]),\n            \"lambda1\": np.array([24, 32, 22, 40, 12, 28]),\n            \"n_tr\": 200,\n            \"n_te\": 400,\n            \"seed\": 7,\n        },\n        # Case 4\n        {\n            \"p\": 12,\n            \"lambda0\": np.array([2, 4, 1, 3, 5, 2, 1, 4, 3, 2, 5, 1]),\n            \"lambda1\": np.array([3, 3, 2, 4, 5, 3, 2, 5, 2, 3, 6, 1]),\n            \"n_tr\": 5,\n            \"n_te\": 500,\n            \"seed\": 99,\n        },\n    ]\n\n    c = 3.0 / 8.0\n    epsilon = 1e-6\n    delta_results = []\n\n    for case in test_cases:\n        p = case[\"p\"]\n        lambda0 = case[\"lambda0\"]\n        lambda1 = case[\"lambda1\"]\n        n_tr = case[\"n_tr\"]\n        n_te = case[\"n_te\"]\n        seed = case[\"seed\"]\n\n        # Set seed for reproducibility for each case\n        rng = np.random.default_rng(seed)\n\n        # Generate training data\n        X_tr_0 = rng.poisson(lambda0, size=(n_tr, p))\n        X_tr_1 = rng.poisson(lambda1, size=(n_tr, p))\n\n        # Generate test data\n        X_te_0 = rng.poisson(lambda0, size=(n_te, p))\n        X_te_1 = rng.poisson(lambda1, size=(n_te, p))\n\n        # --- Decoder A: Raw Counts ---\n        err_raw = train_and_evaluate_lda(X_tr_0, X_tr_1, X_te_0, X_te_1, p, epsilon)\n\n        # --- Decoder B: Square-root Transformed Counts ---\n        Z_tr_0 = np.sqrt(X_tr_0 + c)\n        Z_tr_1 = np.sqrt(X_tr_1 + c)\n        Z_te_0 = np.sqrt(X_te_0 + c)\n        Z_te_1 = np.sqrt(X_te_1 + c)\n        err_sqrt = train_and_evaluate_lda(Z_tr_0, Z_tr_1, Z_te_0, Z_te_1, p, epsilon)\n\n        # --- Calculate Delta ---\n        delta = err_raw - err_sqrt\n        delta_results.append(delta)\n\n    # Format and print the final output\n    formatted_results = [f\"{res:.6f}\" for res in delta_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef train_and_evaluate_lda(V_tr_0, V_tr_1, V_te_0, V_te_1, p, epsilon):\n    \"\"\"\n    Trains an LDA classifier and evaluates its error rate on test data.\n\n    Args:\n        V_tr_0 (np.ndarray): Training data for class 0 (n_tr, p).\n        V_tr_1 (np.ndarray): Training data for class 1 (n_tr, p).\n        V_te_0 (np.ndarray): Test data for class 0 (n_te, p).\n        V_te_1 (np.ndarray): Test data for class 1 (n_te, p).\n        p (int): Number of features.\n        epsilon (float): Regularization parameter.\n\n    Returns:\n        float: The empirical misclassification error rate.\n    \"\"\"\n    n_tr = V_tr_0.shape[0]\n    n_te = V_te_0.shape[0]\n\n    # 1. Estimate class means from training data\n    mu0_hat = np.mean(V_tr_0, axis=0)\n    mu1_hat = np.mean(V_tr_1, axis=0)\n\n    # 2. Estimate class covariance matrices and the pooled covariance\n    # np.cov with ddof=1 uses a denominator of n-1, which is correct\n    if n_tr > 1:\n        Sigma0_hat = np.cov(V_tr_0, rowvar=False, ddof=1)\n        Sigma1_hat = np.cov(V_tr_1, rowvar=False, ddof=1)\n        Sigma_pooled = 0.5 * (Sigma0_hat + Sigma1_hat)\n    else: # Handle n_tr=1 case where covariance is undefined\n        Sigma_pooled = np.zeros((p, p))\n\n    # 3. Apply ridge regularization\n    Sigma_reg = Sigma_pooled + epsilon * np.eye(p)\n\n    # 4. Compute classifier parameters\n    Sigma_reg_inv = np.linalg.inv(Sigma_reg)\n    w_hat = Sigma_reg_inv @ (mu1_hat - mu0_hat)\n    b_hat = 0.5 * (mu1_hat + mu0_hat) @ w_hat\n    \n    # 5. Evaluate on test data\n    # Predictions for class 0 data\n    pred_0 = V_te_0 @ w_hat > b_hat\n    misclassified_0 = np.sum(pred_0) # Count how many are incorrectly predicted as 1\n\n    # Predictions for class 1 data\n    pred_1 = V_te_1 @ w_hat = b_hat\n    misclassified_1 = np.sum(pred_1) # Count how many are incorrectly predicted as 0\n\n    # 6. Compute total error rate\n    total_misclassified = misclassified_0 + misclassified_1\n    total_test_samples = 2 * n_te\n    error_rate = total_misclassified / total_test_samples\n\n    return error_rate\n\nsolve()\n```"
        }
    ]
}