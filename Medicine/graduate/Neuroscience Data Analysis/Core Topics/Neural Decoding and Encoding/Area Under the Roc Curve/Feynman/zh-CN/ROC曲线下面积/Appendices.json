{
    "hands_on_practices": [
        {
            "introduction": "对AUC的理解始于其构建过程。本练习将指导您完成从解码器的离散输出（在处理分组或平分分数时很常见）构建经验ROC曲线的基本过程。通过应用梯形法则，您不仅将计算出AUC，还将对其如何量化分类器在所有决策阈值下的性能获得深刻的几何直觉。",
            "id": "4138914",
            "problem": "一个在多单元脉冲特征上训练的群体解码器，试图在每次试验中确定一个振动触觉刺激是存在 ($+$) 还是缺失 ($-$)。该解码器输出一个离散化的分数，该分数被解释为校准后的后验概率 $p(\\text{stimulus present} \\mid \\text{neural features})$，并被分箱到五个级别 $\\{0.9, 0.7, 0.5, 0.3, 0.1\\}$。由于分箱，许多试验共享相等的分数。在一个大型留出测试集上，在每个分数级别观察到以下计数：\n- 分数 $0.9$：$10$ 次试验刺激存在 ($+$)，$1$ 次试验刺激缺失 ($-$)。\n- 分数 $0.7$：$8$ 次试验刺激存在 ($+$)，$3$ 次试验刺激缺失 ($-$)。\n- 分数 $0.5$：$5$ 次试验刺激存在 ($+$)，$6$ 次试验刺激缺失 ($-$)。\n- 分数 $0.3$：$3$ 次试验刺激存在 ($+$)，$9$ 次试验刺激缺失 ($-$)。\n- 分数 $0.1$：$1$ 次试验刺激存在 ($+$)，$12$ 次试验刺激缺失 ($-$)。\n\n仅使用受试者工作特征 (Receiver Operating Characteristic, ROC) 曲线和 ROC 曲线下面积 (Area Under the ROC Curve, AUC) 的基本定义，通过将决策阈值从最高分之上向下扫过各个分箱来构建经验 ROC 曲线，并将同一分箱内的所有试验视为分数相等。令 $N_{+}$ 表示刺激存在的试验总数，$N_{-}$ 表示刺激缺失的试验总数。将真阳性率 (True Positive Rate, TPR) 定义为 $\\mathrm{TPR} = \\mathrm{TP}/N_{+}$，假阳性率 (False Positive Rate, FPR) 定义为 $\\mathrm{FPR} = \\mathrm{FP}/N_{-}$，其中 $\\mathrm{TP}$ 和 $\\mathrm{FP}$ 分别是在每个阈值下被正确和错误阈值化的试验计数。\n\n从第一性原理出发，解释阶梯函数形式的 ROC 曲线如何累积面积：为什么垂直线段不贡献面积，为什么水平线段贡献的面积等于其宽度乘以相应的高度，以及同一分箱内的相等分数如何以一种产生唯一 AUC 值的方式确定该高度。然后，计算该经验 ROC 曲线的 AUC，结果应为一个单一的精确值。请提供未经四舍五入的最终 AUC 值。最终答案必须是单个实数或单个无单位的封闭形式解析表达式。",
            "solution": "在尝试解答之前，对问题进行验证。\n\n### 第 1 步：提取已知信息\n- 一个群体解码器输出一个离散化的分数，分箱到五个级别：$\\{0.9, 0.7, 0.5, 0.3, 0.1\\}$。\n- 每个分数的刺激存在 ($+$) 和刺激缺失 ($-$) 试验的计数：\n    - 分数 $0.9$：$10$ ($+$)，$1$ ($-$)。\n    - 分数 $0.7$：$8$ ($+$)，$3$ ($-$)。\n    - 分数 $0.5$：$5$ ($+$)，$6$ ($-$)。\n    - 分数 $0.3$：$3$ ($+$)，$9$ ($-$)。\n    - 分数 $0.1$：$1$ ($+$)，$12$ ($-$)。\n- 刺激存在的试验总数表示为 $N_{+}$。\n- 刺激缺失的试验总数表示为 $N_{-}$。\n- 真阳性率 (TPR) 定义为 $\\mathrm{TPR} = \\mathrm{TP}/N_{+}$。\n- 假阳性率 (FPR) 定义为 $\\mathrm{FPR} = \\mathrm{FP}/N_{-}$。\n- 经验受试者工作特征 (ROC) 曲线将通过从最高分之上向下移动决策阈值来构建。\n- 同一分箱内的所有试验都被视为分数相等。\n- 任务要求解释 AUC 如何累积，并最终计算出 AUC 的单一精确值。\n\n### 第 2 步：使用提取的已知信息进行验证\n根据验证标准对问题进行评估。\n- **科学依据：** 该问题牢固地植根于信号检测论和机器学习在神经科学数据分析中的标准实践。ROC 分析是评估分类器性能的基本工具。所描述的场景是一个典型的应用。\n- **适定性：** 该问题提供了所有必要的数据（每个分数分箱的结果计数）和待计算量（TPR, FPR）的明确定义。将同一分箱内的试验视为分数相等的指令，结合经验 ROC 曲线的标准定义，明确了一个获得唯一解的清晰程序。\n- **客观性：** 问题以精确、定量且无偏见的语言陈述。\n\n该问题没有表现出任何无效性缺陷：\n- 它不违反任何科学或数学原理。\n- 它可以被形式化，并且与所述主题领域直接相关。\n- 设置是完整且一致的。\n- 条件和数据对于神经生理学实验是现实的。\n- 结构导向一个唯一的、有意义的解。\n- 问题并非微不足道，因为它需要仔细的逐步构建和计算，以及概念上的解释。\n- 结果是数学上可验证的。\n\n### 第 3 步：结论与行动\n问题有效。将提供完整的解答。\n\n### 解答\n受试者工作特征曲线下面积 (AUC) 是衡量分类器区分两个类别能力的一个指标。ROC 曲线本身是在不同阈值设置下，真阳性率 (TPR) 对假阳性率 (FPR) 的绘图。我们首先计算阳性 ($N_{+}$) 和阴性 ($N_{-}$) 试验的总数。\n\n根据已知信息：\n$N_{+} = 10 + 8 + 5 + 3 + 1 = 27$\n$N_{-} = 1 + 3 + 6 + 9 + 12 = 31$\n\n经验 ROC 曲线是通过将决策阈值从高到低移动来构建的。如果一个试验的分数大于或等于阈值，则被分类为阳性。该曲线由一系列对应于一组递减阈值的点 $(FPR_i, TPR_i)$ 组成。曲线总是从 $(0, 0)$ 开始（阈值高到没有任何试验被分类为阳性），到 $(1, 1)$ 结束（阈值低到所有试验都被分类为阳性）。\n\n因为分数是分箱的并被视为相等，我们从最高分到最低分逐个分箱处理数据。对于每个分箱，我们计算真阳性 (TP) 和假阳性 (FP) 的变化量，并更新累计计数。ROC 曲线将是连接从这些累计计数导出的点的一系列线段。\n\n令 $n_{+,s}$ 和 $n_{-,s}$ 分别为分数为 $s$ 时的阳性和阴性试验数。令 $CTP_i$ 和 $CFP_i$ 为处理第 $i$ 个分箱（从最高分到最低分排序）后的累计 TP 和 FP 计数。ROC 曲线上的对应点是 $P_i = (FPR_i, TPR_i) = (CFP_i/N_{-}, CTP_i/N_{+})$。\n\n- **初始状态 (阈值 $> 0.9$):** $CTP_0 = 0, CFP_0 = 0$。这给出了起始点 $P_0 = (0, 0)$。\n\n- **处理分数 $s = 0.9$:** 我们加上来自这个分箱的试验。\n  $n_{+,0.9} = 10, n_{-,0.9} = 1$。\n  $CTP_1 = CTP_0 + 10 = 10$。\n  $CFP_1 = CFP_0 + 1 = 1$。\n  $P_1 = (FPR_1, TPR_1) = (\\frac{1}{31}, \\frac{10}{27})$。\n\n- **处理分数 $s = 0.7$:**\n  $n_{+,0.7} = 8, n_{-,0.7} = 3$。\n  $CTP_2 = CTP_1 + 8 = 18$。\n  $CFP_2 = CFP_1 + 3 = 4$。\n  $P_2 = (FPR_2, TPR_2) = (\\frac{4}{31}, \\frac{18}{27})$。\n\n- **处理分数 $s = 0.5$:**\n  $n_{+,0.5} = 5, n_{-,0.5} = 6$。\n  $CTP_3 = CTP_2 + 5 = 23$。\n  $CFP_3 = CFP_2 + 6 = 10$。\n  $P_3 = (FPR_3, TPR_3) = (\\frac{10}{31}, \\frac{23}{27})$。\n\n- **处理分数 $s = 0.3$:**\n  $n_{+,0.3} = 3, n_{-,0.3} = 9$。\n  $CTP_4 = CTP_3 + 3 = 26$。\n  $CFP_4 = CFP_3 + 9 = 19$。\n  $P_4 = (FPR_4, TPR_4) = (\\frac{19}{31}, \\frac{26}{27})$。\n\n- **处理分数 $s = 0.1$:**\n  $n_{+,0.1} = 1, n_{-,0.1} = 12$。\n  $CTP_5 = CTP_4 + 1 = 27$。\n  $CFP_5 = CFP_4 + 12 = 31$。\n  $P_5 = (FPR_5, TPR_5) = (\\frac{31}{31}, \\frac{27}{27}) = (1, 1)$。\n\n经验 ROC 曲线是连接 $P_0, P_1, P_2, P_3, P_4,$ 和 $P_5$ 的线段集合。\n\n### AUC 累积的第一性原理解释\nROC 曲线下面积 (AUC) 是 TPR 关于 FPR 从 $FPR=0$ 到 $FPR=1$ 的积分：$AUC = \\int_{0}^{1} TPR(FPR) \\, dFPR$。对于由线段组成的经验 ROC 曲线，这个积分变成了每个线段下方几何图形面积的总和。\n\n- **垂直线段：** 如果一个阈值穿过的分数只属于阳性样本 ($n_+=k, n_-=0$)，曲线会从 $(FPR, TPR_{old})$ 垂直移动到 $(FPR, TPR_{new})$。FPR 的变化量是 $\\Delta FPR = 0$。该线段贡献的面积是一个宽度为 $0$ 的矩形，因此面积为 $0$。垂直线段对 AUC 没有面积贡献。\n\n- **水平线段：** 如果一个阈值穿过的分数只属于阴性样本 ($n_+=0, n_-=k$)，曲线会从 $(FPR_{old}, TPR)$ 水平移动到 $(FPR_{new}, TPR)$。高度 (TPR) 是恒定的。该线段形成一个高度为 $TPR$、宽度为 $\\Delta FPR = FPR_{new} - FPR_{old}$ 的矩形。贡献的面积是 $TPR \\times \\Delta FPR$。\n\n- **对角线段（分数相等）：** 在本问题中，每个分数分箱都同时包含阳性和阴性样本，导致分数相等。当阈值穿过这样一个分箱时，TP 和 FP 计数会同时增加。这在 ROC 图上创建了一个对角线段，连接点 $P_{i-1} = (FPR_{i-1}, TPR_{i-1})$ 和点 $P_{i} = (FPR_{i}, TPR_{i})$。该线段下方的面积是一个梯形。该梯形的面积由以下公式给出：\n$$Area_i = \\frac{1}{2}(\\text{height}_1 + \\text{height}_2) \\times \\text{width} = \\frac{1}{2}(TPR_{i-1} + TPR_i) (FPR_i - FPR_{i-1})$$\n这种方法之所以能得到唯一的 AUC，是因为它遵循一个标准的、确定性的约定。虽然在分数相等的组块内，试验的真实排序是未知的，但这条对角线代表了在考虑了所有相等分数的阳性和阴性试验的可能排序并对其 ROC 路径进行平均后的期望路径。因此，梯形面积是来自相等分数块的有原则的、期望的面积贡献，从而确保了 AUC 的单一、唯一值。\n\n总 AUC 是这些梯形面积的总和：\n$$AUC = \\sum_{i=1}^{5} \\frac{1}{2}(TPR_{i-1} + TPR_i)(FPR_i - FPR_{i-1})$$\n\n### AUC 的计算\n我们现在计算每个线段的面积。\n$AUC = \\frac{1}{2}\\sum_{i=1}^{5} (TPR_{i-1} + TPR_i)(FPR_i - FPR_{i-1})$\n\n- 面积 1 (线段 $P_0P_1$):\n$A_1 = \\frac{1}{2}(0 + \\frac{10}{27})(\\frac{1}{31} - 0) = \\frac{1}{2} \\cdot \\frac{10}{27} \\cdot \\frac{1}{31} = \\frac{5}{27 \\cdot 31}$\n\n- 面积 2 (线段 $P_1P_2$):\n$A_2 = \\frac{1}{2}(\\frac{10}{27} + \\frac{18}{27})(\\frac{4}{31} - \\frac{1}{31}) = \\frac{1}{2} \\cdot \\frac{28}{27} \\cdot \\frac{3}{31} = \\frac{42}{27 \\cdot 31}$\n\n- 面积 3 (线段 $P_2P_3$):\n$A_3 = \\frac{1}{2}(\\frac{18}{27} + \\frac{23}{27})(\\frac{10}{31} - \\frac{4}{31}) = \\frac{1}{2} \\cdot \\frac{41}{27} \\cdot \\frac{6}{31} = \\frac{123}{27 \\cdot 31}$\n\n- 面积 4 (线段 $P_3P_4$):\n$A_4 = \\frac{1}{2}(\\frac{23}{27} + \\frac{26}{27})(\\frac{19}{31} - \\frac{10}{31}) = \\frac{1}{2} \\cdot \\frac{49}{27} \\cdot \\frac{9}{31} = \\frac{441}{2 \\cdot 27 \\cdot 31}$\n\n- 面积 5 (线段 $P_4P_5$):\n$A_5 = \\frac{1}{2}(\\frac{26}{27} + 1)(\\frac{31}{31} - \\frac{19}{31}) = \\frac{1}{2}(\\frac{53}{27})(\\frac{12}{31}) = \\frac{318}{27 \\cdot 31}$\n\n现在，我们将这些面积相加。我们使用公分母 $2 \\cdot 27 \\cdot 31 = 1674$。\n$AUC = \\frac{2 \\cdot 5 + 2 \\cdot 42 + 2 \\cdot 123 + 441 + 2 \\cdot 318}{1674}$\n$AUC = \\frac{10 + 84 + 246 + 441 + 636}{1674}$\n$AUC = \\frac{1417}{1674}$\n\n这就是 ROC 曲线下面积的精确值。",
            "answer": "$$\\boxed{\\frac{1417}{1674}}$$"
        },
        {
            "introduction": "虽然准确率是一个直观的指标，但它可能具有危险的误导性，尤其是在神经科学中常见的类别不平衡数据集中。本练习提供了一个精心构建的场景，其中一个准确率近乎完美的分类器实际上完全没有信息量。通过计算AUC并将其与准确率进行比较，您将直面这一悖论，并理解为什么AUC是衡量解码器真实判别能力的更稳健、更可靠的指标。",
            "id": "4138865",
            "problem": "一个研究团队正在分析钙成像信号，以检测小鼠嗅皮层中是否存在微弱的气味刺激。每次试验都会从一个经过训练的解码器中产生一个标量决策变量 $S \\in [0,1]$，该解码器聚合了100毫秒窗口内的荧光动态。由于实验限制，数据集严重不平衡：刺激存在的概率为 $P(Y=1)=0.01$，不存在的概率为 $P(Y=0)=0.99$，其中 $Y \\in \\{0,1\\}$ 表示真实类别。在一次特定的实验中，由于解码器是在未对齐的特征上训练的，其得分不具信息量：对于两个类别，$S$ 都作为 $\\mathrm{Uniform}(0,1)$ 连续且独立地分布。在部署期间，实验室使用了固定的决策阈值 $\\tau^{\\star}=1$ 以最小化假警报；在此阈值下，分类器对所有试验都预测 $Y=0$，从而产生了由多数类主导的高准确率。\n\n从受试者工作特征（ROC）曲线的标准定义出发，计算在上述连续得分模型下该实验的受试者工作特征曲线下面积（AUC）。在你的推理中，简要解释为什么在这种严重类别不平衡的情况下，ROC分析比准确率更具信息量。将最终的AUC值表示为一个四舍五入到四位有效数字的实数。无需单位。",
            "solution": "在进行解答之前，需对问题进行验证。\n\n### 第1步：提取已知条件\n- 决策变量：$S \\in [0,1]$。\n- 数据来源：用于检测气味刺激的小鼠嗅皮层钙成像信号。\n- 时间窗口：$100$ ms。\n- 真实类别变量：$Y \\in \\{0,1\\}$，其中 $Y=1$ 为刺激存在，$Y=0$ 为刺激不存在。\n- 类别概率：$P(Y=1)=0.01$ 和 $P(Y=0)=0.99$。\n- 得分 $S$ 的条件概率分布：\n  - 对于类别 $Y=1$ (存在): $S \\sim \\mathrm{Uniform}(0,1)$。\n  - 对于类别 $Y=0$ (不存在): $S \\sim \\mathrm{Uniform}(0,1)$。\n- 分布是连续且独立的。\n- 部署中使用了固定的决策阈值 $\\tau^{\\star}=1$。\n- 任务是计算受试者工作特征曲线下面积（AUC），解释为什么在这种情况下ROC分析比准确率更具信息量，并提供四舍五入到四位有效数字的AUC值。\n\n### 第2步：使用提取的已知条件进行验证\n该问题具有科学依据，描述了信号检测理论和机器学习应用于神经科学数据的标准场景。不具信息量的分类器（其两个类别的得分分布相同）的概念，是阐释ROC分析特性的经典教科书案例。所提供的信息是完整的、自洽的且逻辑一致的。分布定义明确，任务——计算AUC——是适定的。该问题没有违反任何基本科学原理，不包含事实错误，也不依赖于主观论断。类别不平衡的数值虽然极端，但在许多筛选应用中是现实的。因此，该问题被认为是有效的。\n\n### 第3步：结论与行动\n问题有效。将提供完整解答。\n\n### 解答推导\n\n受试者工作特征（ROC）曲线是一个图形图表，它展示了二元分类器系统在改变其判别阈值时的诊断能力。它是通过在各种阈值设置下绘制真阳性率（TPR）对假阳性率（FPR）的曲线而创建的。\n\n真阳性率（True Positive Rate, TPR），也称为灵敏度或召回率，是在条件真实存在的情况下，测试结果为阳性的概率。对于给定的决策阈值 $\\tau$，如果得分 $S \\ge \\tau$，则预测为阳性（$\\hat{Y}=1$）。因此：\n$$\n\\text{TPR}(\\tau) = P(\\hat{Y}=1 | Y=1) = P(S \\ge \\tau | Y=1)\n$$\n\n假阳性率（False Positive Rate, FPR）是在条件真实不存在的情况下，测试结果为阳性的概率：\n$$\n\\text{FPR}(\\tau) = P(\\hat{Y}=1 | Y=0) = P(S \\ge \\tau | Y=0)\n$$\n\n问题陈述，对于两个类别，得分 $S$ 均服从区间 $[0,1]$ 上的连续均匀分布。对于一个随机变量 $X \\sim \\mathrm{Uniform}(a,b)$，其概率密度函数（PDF）为 $f(x) = \\frac{1}{b-a}$（当 $x \\in [a,b]$ 时），否则为0。其累积分布函数（CDF）为 $F(x) = P(X \\le x) = \\frac{x-a}{b-a}$（当 $x \\in [a,b]$ 时）。\n\n在本例中，对于 $P(S|Y=1)$ 和 $P(S|Y=0)$，分布均为 $\\mathrm{Uniform}(0,1)$。设 $f_1(s)$ 和 $f_0(s)$ 分别为阳性类和阴性类的概率密度函数。我们有 $f_1(s) = f_0(s) = 1$（当 $s \\in [0,1]$ 时），否则为0。\n\n现在我们可以计算对于任意阈值 $\\tau \\in [0,1]$ 的 $\\text{TPR}(\\tau)$ 和 $\\text{FPR}(\\tau)$。\n$$\n\\text{TPR}(\\tau) = P(S \\ge \\tau | Y=1) = \\int_{\\tau}^{1} f_1(s) ds = \\int_{\\tau}^{1} 1 ds = [s]_{\\tau}^{1} = 1 - \\tau\n$$\n$$\n\\text{FPR}(\\tau) = P(S \\ge \\tau | Y=0) = \\int_{\\tau}^{1} f_0(s) ds = \\int_{\\tau}^{1} 1 ds = [s]_{\\tau}^{1} = 1 - \\tau\n$$\n\nROC曲线由 $\\tau$ 参数化。设 $x = \\text{FPR}(\\tau)$ 且 $y = \\text{TPR}(\\tau)$。根据我们的计算，可得：\n$$\nx = 1 - \\tau\n$$\n$$\ny = 1 - \\tau\n$$\n这意味着ROC曲线的方程是 $y=x$。当阈值 $\\tau$ 从1扫到0时，$x$ 和 $y$ 都从0扫到1。因此，ROC曲线是ROC空间中从点 $(0,0)$ 到 $(1,1)$ 的对角线段。\n\n曲线下面积（AUC）是ROC曲线 $y(x)$ 从 $x=0$ 到 $x=1$ 的积分。\n$$\n\\text{AUC} = \\int_{0}^{1} y(x) dx = \\int_{0}^{1} x dx\n$$\n计算该积分：\n$$\n\\text{AUC} = \\left[ \\frac{1}{2}x^2 \\right]_{0}^{1} = \\frac{1}{2}(1)^2 - \\frac{1}{2}(0)^2 = \\frac{1}{2} = 0.5\n$$\nAUC为0.5表示分类器没有判别能力；其性能不优于随机猜测。这个结果是预料之中的，因为阳性类和阴性类的得分分布是相同的。\n\n关于与准确率的比较：在问题中，使用了阈值 $\\tau^{\\star}=1$。对于 $[0,1]$ 上的连续分布， $S \\ge 1$ 的概率实际上是 $P(S=1)$，即为0。因此，该分类器总是预测为阴性类，即 $\\hat{Y}=0$。\n\n准确率是正确预测的总概率：\n$$\n\\text{Accuracy} = P(\\hat{Y}=Y) = P(\\hat{Y}=0, Y=0) + P(\\hat{Y}=1, Y=1)\n$$\n由于 $\\hat{Y}$ 总是0，第二项为0。第一项是：\n$$\nP(\\hat{Y}=0, Y=0) = P(\\hat{Y}=0 | Y=0) P(Y=0)\n$$\n$P(\\hat{Y}=0 | Y=0)$ 是真阴性率（TNR）。由于预测总是阴性，所以 $\\text{TNR}=1$。阴性类的先验概率给定为 $P(Y=0)=0.99$。\n因此，准确率为：\n$$\n\\text{Accuracy} = 1 \\times 0.99 = 0.99\n$$\n这个99%的准确率异常之高，但却具有极大的误导性。它表明这是一个优秀的分类器，而实际上该分类器完全不具信息量。这个悖论的产生是因为在严重的类别不平衡（99%对1%）情况下，准确率指标被多数类（$Y=0$）的性能所主导。通过总是猜测多数类，分类器在没有任何真正判别能力的情况下获得了很高的准确率分数。\n\n相比之下，ROC曲线和AUC对类别流行率不敏感。TPR和FPR都是以真实类别为条件的，这意味着它们分别评估在阳性群体和阴性群体内部的性能。0.5的AUC正确而明确地揭示了分类器没有能力区分这两个类别，暴露了高准确率所掩盖的失败。因此，在存在严重类别不平衡的情况下，ROC分析是衡量分类器性能的远更具信息量和可靠性的指标。\n\n最终的AUC值，四舍五入到四位有效数字，是 $0.5000$。",
            "answer": "$$\\boxed{0.5000}$$"
        },
        {
            "introduction": "AUC的点估计值只提供了分类器性能的不完整图像；严谨的科学结论需要量化此估计的不确定性。这个高级编程练习要求您实现并比较两种广泛用于估计AUC方差的方法：参数化的Hanley-McNeil近似法和非参数化的DeLong方法。通过模拟，您将在神经科学数据典型的小样本情景下研究它们的特性，从而培养统计验证和报告的关键技能。",
            "id": "4138944",
            "problem": "一个研究实验室正在评估源自小型神经元集成的标量决策分数，以区分两种实验条件。这种区分性能由受试者工作特征（ROC）曲线下面积（AUC）来概括。其中，受试者工作特征（ROC）曲线是当决策阈值变化时，真阳性率对假阳性率的曲线；而曲线下面积（AUC）是一个随机选择的正类分数超过一个随机选择的负类分数的概率。\n\n基本原理与任务。从AUC作为独立抽样概率的定义出发：给定两个独立的实值随机变量 $X$（正类）和 $Y$（负类），它们具有连续分布，总体AUC为 $P(X > Y) + \\tfrac{1}{2} P(X = Y)$。从 $m$ 个独立的正类分数 $\\{x_i\\}_{i=1}^m$ 和 $n$ 个独立的负类分数 $\\{y_j\\}_{j=1}^n$ 计算出的经验AUC是所有 $m n$ 个配对上指示核函数的平均值。基于此，根据以下建模假设，实现AUC估计量的两种方差估计量：\n- Hanley–McNeil 的参数化方差近似，该方法假设底层的ROC服从双正态模型。\n- DeLong 的基于单个分类器的U-统计量的非参数方差估计。\n\n不要使用任何预封装的ROC实用工具；直接根据其定义来实现AUC和两种方差估计量。使用每种方差估计量和标准正态分位数，为AUC构建水平为 $0.95$ 的Wald型双边置信区间。对AUC估计量的抽样分布使用正态近似。\n\n模拟设计。对于下面测试套件中的每个参数集，模拟 $R$ 个独立的数据集。在每个数据集中，从均值为 $\\mu_1$、标准差为 $\\sigma_1$ 的高斯分布中独立同分布地抽取 $m$ 个正类分数，并从均值为 $\\mu_0$、标准差为 $\\sigma_0$ 的高斯分布中独立同分布地抽取 $n$ 个负类分数。对于每个数据集，计算经验AUC、Hanley–McNeil方差估计和DeLong方差估计。对于给定参数集的 $R$ 个模拟数据集，计算以下内容：\n- AUC估计量的经验方差（作为 $R$ 次运行的样本方差）。\n- Hanley–McNeil方法和DeLong方法下的平均估计方差。\n- 每种方差估计量的偏差，定义为平均估计方差减去经验方差。\n- 每种方法的名义水平为 $0.95$ 的双边Wald区间的覆盖概率，定义为在高斯数据生成模型下，包含真实AUC的区间的比例。对于独立的两个高斯类 $X \\sim \\mathcal{N}(\\mu_1,\\sigma_1^2)$ 和 $Y \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$，真实AUC等于 $\\Phi\\!\\left(\\dfrac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)$，其中 $\\Phi(\\cdot)$ 表示标准正态累积分布函数。\n- 每种方法的 $0.95$ 双边Wald区间的平均宽度。\n\n为每个参数集报告以下九个量，并严格遵守此顺序：\n1. AUC估计量的经验方差。\n2. Hanley–McNeil方差估计的均值。\n3. DeLong方差估计的均值。\n4. Hanley–McNeil方差偏差。\n5. DeLong方差偏差。\n6. Hanley–McNeil $0.95$ 水平覆盖概率（以小数表示，而非百分比）。\n7. DeLong $0.95$ 水平覆盖概率（以小数表示，而非百分比）。\n8. Hanley–McNeil区间的平均宽度。\n9. DeLong区间的平均宽度。\n\n测试套件。使用以下四个参数集，每个参数集指定为 $(m,n,\\mu_1,\\sigma_1,\\mu_0,\\sigma_0,R,\\text{seed})$：\n- 案例A（平衡，中等分离度）：$(10,10,0.8,1.0,0.0,1.0,2000,12345)$。\n- 案例B（样本极小，中等分离度）：$(3,4,0.6,1.0,0.0,1.0,2000,23456)$。\n- 案例C（不平衡，近乎随机）：$(12,20,0.0,1.0,0.0,1.0,2000,34567)$。\n- 案例D（样本小，高分离度）：$(8,12,1.6,1.0,0.0,1.0,2000,45678)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含四个案例（按A、B、C、D的顺序）的结果，形式为一个逗号分隔的四个子列表。每个子列表必须按顺序包含上面列出的九个量，均为浮点数。整行必须用方括号括起来，例如：“[[a1,a2,...,a9],[b1,...,b9],[c1,...,c9],[d1,...,d9]]”。除了分隔数字所必需的逗号外，不需要额外的文本或空格。\n\n此问题不涉及物理单位或角度。所有概率必须以小数或分数表示，而非百分比。",
            "solution": "该问题要求对经验性受试者工作特征（ROC）曲线下面积（AUC）的方差的两种估计量进行比较分析。AUC是评估分类器区分能力的常用指标。此分析将通过在指定的高斯数据生成模型下进行蒙特卡洛模拟研究来完成。这两种方差估计量分别是Hanley and McNeil的参数化近似方法和DeLong, DeLong, and Clarke-Pearson的非参数方法。\n\n首先，我们为需要实现的各个量建立理论基础。对于具有连续分数输出的分类器，AUC是为两个随机变量定义的，其中 $X$ 代表正类分数， $Y$ 代表负类分数。总体AUC是概率 $A = P(X > Y)$。如问题所述，如果可能出现相等的情况（$P(X=Y) > 0$），则公式变为 $A = P(X > Y) + \\frac{1}{2} P(X = Y)$。给定 $m$ 个正类分数样本 $\\{x_i\\}_{i=1}^m$ 和 $n$ 个负类分数样本 $\\{y_j\\}_{j=1}^n$，经验AUC（表示为 $\\widehat{A}$）是 $A$ 的一个无偏估计量。它通过归一化的Wilcoxon-Mann-Whitney U-统计量计算得出：\n$$\n\\widehat{A} = \\frac{1}{mn} \\sum_{i=1}^m \\sum_{j=1}^n \\psi(x_i, y_j)\n$$\n其中核函数 $\\psi(u, v)$ 定义如下：\n$$\n\\psi(u, v) =\n\\begin{cases}\n1 & \\text{if } u > v \\\\\n\\frac{1}{2} & \\text{if } u = v \\\\\n0 & \\text{if } u < v\n\\end{cases}\n$$\n由于数据生成过程涉及连续的正态分布，出现相等的概率为零。然而，为了数值上的稳健性，实现时应处理可能出现的相等情况。\n\n问题的核心在于估计 $\\widehat{A}$ 的方差。我们实现两种估计量。\n\n1.  **Hanley-McNeil 参数化方差估计量**：该方法在数据服从“双正态”模型的假设下近似 $\\widehat{A}$ 的方差，这意味着正类和负类分数在经过某个未知的单调变换后均服从正态分布。方差估计值 $\\widehat{\\text{Var}}_{\\text{HM}}(\\widehat{A})$ 仅依赖于经验AUC $\\widehat{A}$ 以及样本量 $m$ 和 $n$：\n    $$\n    \\widehat{\\text{Var}}_{\\text{HM}}(\\widehat{A}) = \\frac{\\widehat{A}(1-\\widehat{A}) + (m-1)(Q_1 - \\widehat{A}^2) + (n-1)(Q_2 - \\widehat{A}^2)}{mn}\n    $$\n    其中 $Q_1$ 和 $Q_2$ 是 $\\widehat{A}$ 的函数：\n    $$\n    Q_1 = \\frac{\\widehat{A}}{2 - \\widehat{A}} \\quad \\text{and} \\quad Q_2 = \\frac{2\\widehat{A}^2}{1 + \\widehat{A}}\n    $$\n\n2.  **DeLong 非参数方差估计量**：此方法基于U-统计量理论，不依赖于关于分数分布的参数假设，因此更具稳健性。它通过考虑单个观测值的贡献来估计方差。首先，我们定义“分量”向量。对于每个正类分数 $x_i$，其分量 $V_{10}(x_i)$ 是它与所有负类分数比较得出的估计AUC。对于每个负类分数 $y_j$，其分量 $V_{01}(y_j)$ 是它（从正类角度）与所有正类分数比较得出的估计AUC。\n    $$\n    V_{10}(x_i) = \\frac{1}{n} \\sum_{j=1}^n \\psi(x_i, y_j) \\quad \\text{for } i=1, \\dots, m \\\\\n    V_{01}(y_j) = \\frac{1}{m} \\sum_{i=1}^m \\psi(x_i, y_j) \\quad \\text{for } j=1, \\dots, n\n    $$\n    然后计算这些分量的样本方差：\n    $$\n    S_{10} = \\frac{1}{m-1} \\sum_{i=1}^m (V_{10}(x_i) - \\widehat{A})^2 \\\\\n    S_{01} = \\frac{1}{n-1} \\sum_{j=1}^n (V_{01}(y_j) - \\widehat{A})^2\n    $$\n    DeLong方差估计值 $\\widehat{\\text{Var}}_{\\text{DL}}(\\widehat{A})$ 由缩放后的分量方差之和给出：\n    $$\n    \\widehat{\\text{Var}}_{\\text{DL}}(\\widehat{A}) = \\frac{S_{10}}{m} + \\frac{S_{01}}{n}\n    $$\n\n模拟研究将基于从高斯分布 $X \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)$ 和 $Y \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$ 生成的数据来评估这些估计量。对于此特定模型，真实的总体AUC $A_{\\text{true}}$ 具有一个闭式表达式。差值 $D = X - Y$ 服从正态分布 $\\mathcal{N}(\\mu_1 - \\mu_0, \\sigma_1^2 + \\sigma_0^2)$。真实AUC为 $P(X > Y) = P(D > 0)$，它可以通过标准正态分布的累积分布函数（CDF）$\\Phi(\\cdot)$ 计算得出：\n$$\nA_{\\text{true}} = \\Phi\\left(\\frac{\\mu_1 - \\mu_0}{\\sqrt{\\sigma_1^2 + \\sigma_0^2}}\\right)\n$$\n对于每个参数集，模拟过程通过重复数据生成和估计过程 $R$ 次来进行。对于每个集合，我们计算九个指标：\n1.  **$\\widehat{A}$ 的经验方差**：$R$ 个存储的 $\\widehat{A}$ 值的样本方差，计算公式为 $S^2_{\\widehat{A}} = \\frac{1}{R-1}\\sum_{r=1}^R (\\widehat{A}_r - \\bar{\\widehat{A}})^2$。\n2.  **Hanley–McNeil 方差均值**：$R$ 个 $\\widehat{\\text{Var}}_{\\text{HM}}(\\widehat{A})$ 值的算术平均值。\n3.  **DeLong 方差均值**：$R$ 个 $\\widehat{\\text{Var}}_{\\text{DL}}(\\widehat{A})$ 值的算术平均值。\n4.  **Hanley–McNeil 方差的偏差**：平均估计方差减去经验方差。\n5.  **DeLong 方差的偏差**：平均估计方差减去经验方差。\n6.  **Hanley–McNeil $0.95$ 置信区间的覆盖概率**：在 $R$ 次模拟中，真实AUC $A_{\\text{true}}$ 落在区间 $\\widehat{A} \\pm z_{0.975} \\sqrt{\\widehat{\\text{Var}}_{\\text{HM}}(\\widehat{A})}$ 内的比例，其中 $z_{0.975}$ 是标准正态分布的 $0.975$ 分位数。\n7.  **DeLong $0.95$ 置信区间的覆盖概率**：在 $R$ 次模拟中，$A_{\\text{true}}$ 落在区间 $\\widehat{A} \\pm z_{0.975} \\sqrt{\\widehat{\\text{Var}}_{\\text{DL}}(\\widehat{A})}$ 内的比例。\n8.  **Hanley–McNeil 区间平均宽度**：在 $R$ 次模拟中，Hanley-McNeil置信区间的平均宽度。\n9.  **DeLong 区间平均宽度**：DeLong置信区间的平均宽度。\n\n这一全面的评估将有助于深入了解这两种方差估计量在不同样本量、类别平衡和效应大小条件下的性能、偏差和可靠性。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation study as specified in the problem.\n    \"\"\"\n    test_cases = [\n        # (m, n, mu_1, sigma_1, mu_0, sigma_0, R, seed)\n        (10, 10, 0.8, 1.0, 0.0, 1.0, 2000, 12345),  # Case A\n        (3, 4, 0.6, 1.0, 0.0, 1.0, 2000, 23456),    # Case B\n        (12, 20, 0.0, 1.0, 0.0, 1.0, 2000, 34567),  # Case C\n        (8, 12, 1.6, 1.0, 0.0, 1.0, 2000, 45678),   # Case D\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = _solve_one_case(*case)\n        all_results.append(results)\n\n    # Format the final output string as specified.\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, r))}]\" for r in all_results]) + \"]\"\n    print(output_str)\n\ndef _get_auc_and_components(pos_scores, neg_scores, m, n):\n    \"\"\"\n    Computes empirical AUC and the component vectors for DeLong's method.\n    \"\"\"\n    # Use broadcasting for efficient pairwise comparisons\n    pos_scores_col = pos_scores[:, np.newaxis]\n    \n    comparisons = pos_scores_col > neg_scores\n    ties = pos_scores_col == neg_scores\n    \n    # Calculate components\n    v10 = (np.sum(comparisons, axis=1) + 0.5 * np.sum(ties, axis=1)) / n\n    v01 = (np.sum(comparisons.T, axis=1) + 0.5 * np.sum(ties.T, axis=1)) / m\n    \n    # Calculate AUC from components\n    auc = np.mean(v10)\n    \n    return auc, v10, v01\n\ndef _calculate_hm_var(auc, m, n):\n    \"\"\"\n    Calculates the Hanley-McNeil variance estimate.\n    \"\"\"\n    # Handle edge cases where auc is 0 or 1, although unlikely with continuous data.\n    if auc <= 0.0 or auc >= 1.0:\n        return 0.0\n\n    q1 = auc / (2.0 - auc)\n    q2 = (2.0 * auc**2) / (1.0 + auc)\n    \n    term1 = auc * (1.0 - auc)\n    term2 = (m - 1) * (q1 - auc**2)\n    term3 = (n - 1) * (q2 - auc**2)\n    \n    var_hm = (term1 + term2 + term3) / (m * n)\n    return var_hm\n\ndef _calculate_dl_var(v10, v01, m, n):\n    \"\"\"\n    Calculates the DeLong variance estimate.\n    Handles small sample sizes where variance calculation needs ddof.\n    \"\"\"\n    if m < 2 or n < 2:\n        return np.nan # Undefined for sample size < 2\n\n    # s10 is the sample variance of the v10 components\n    s10 = np.var(v10, ddof=1)\n    \n    # s01 is the sample variance of the v01 components\n    s01 = np.var(v01, ddof=1)\n    \n    var_dl = (s10 / m) + (s01 / n)\n    return var_dl\n\ndef _solve_one_case(m, n, mu_1, sigma_1, mu_0, sigma_0, R, seed):\n    \"\"\"\n    Performs the simulation for a single parameter set and returns the 9 metrics.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Calculate true AUC for the Gaussian model\n    numerator = mu_1 - mu_0\n    denominator = np.sqrt(sigma_1**2 + sigma_0**2)\n    true_auc = norm.cdf(numerator / denominator if denominator > 0 else np.inf * np.sign(numerator))\n    \n    # Quantile for 95% CI\n    z_alpha_2 = norm.ppf(0.975)\n    \n    # Storage for simulation results\n    aucs = np.zeros(R)\n    hm_vars = np.zeros(R)\n    dl_vars = np.zeros(R)\n    \n    for r in range(R):\n        # Generate data\n        pos_scores = rng.normal(mu_1, sigma_1, m)\n        neg_scores = rng.normal(mu_0, sigma_0, n)\n        \n        # Calculate AUC and components\n        auc, v10, v01 = _get_auc_and_components(pos_scores, neg_scores, m, n)\n        aucs[r] = auc\n        \n        # Calculate variance estimates\n        hm_vars[r] = _calculate_hm_var(auc, m, n)\n        dl_vars[r] = _calculate_dl_var(v10, v01, m, n)\n\n    # 1. Empirical variance of the AUC estimator\n    emp_var_auc = np.var(aucs, ddof=1)\n    \n    # 2. Mean Hanley-McNeil variance estimate\n    mean_hm_var = np.mean(hm_vars)\n    \n    # 3. Mean DeLong variance estimate\n    # Handle NaN for small sample cases\n    if np.isnan(dl_vars).any():\n        mean_dl_var = np.nanmean(dl_vars)\n    else:\n        mean_dl_var = np.mean(dl_vars)\n\n    # 4. Hanley-McNeil variance bias\n    bias_hm = mean_hm_var - emp_var_auc\n    \n    # 5. DeLong variance bias\n    bias_dl = mean_dl_var - emp_var_auc\n    \n    # Calculate CIs and coverage. Use np.maximum to prevent sqrt of negative values.\n    # Hanley-McNeil\n    std_err_hm = np.sqrt(np.maximum(0, hm_vars))\n    ci_lower_hm = aucs - z_alpha_2 * std_err_hm\n    ci_upper_hm = aucs + z_alpha_2 * std_err_hm\n    coverage_hm = np.mean((ci_lower_hm <= true_auc) & (true_auc <= ci_upper_hm))\n    \n    # DeLong\n    std_err_dl = np.sqrt(np.maximum(0, dl_vars))\n    # Replace nan std_err with 0 to prevent nan propagation in CI calc where var is undefined\n    std_err_dl_clean = np.nan_to_num(std_err_dl)\n    ci_lower_dl = aucs - z_alpha_2 * std_err_dl_clean\n    ci_upper_dl = aucs + z_alpha_2 * std_err_dl_clean\n    # Exclude runs where var was undefined from coverage calculation\n    valid_dl_runs = ~np.isnan(dl_vars)\n    coverage_dl = np.mean((ci_lower_dl[valid_dl_runs] <= true_auc) & (true_auc <= ci_upper_dl[valid_dl_runs]))\n\n    # 8. Mean Hanley-McNeil interval width\n    mean_width_hm = np.mean(2 * z_alpha_2 * std_err_hm)\n\n    # 9. Mean DeLong interval width\n    mean_width_dl = np.mean(2 * z_alpha_2 * std_err_dl_clean[valid_dl_runs])\n    \n    return [\n        emp_var_auc,\n        mean_hm_var,\n        mean_dl_var,\n        bias_hm,\n        bias_dl,\n        coverage_hm,\n        coverage_dl,\n        mean_width_hm,\n        mean_width_dl,\n    ]\n\nif __name__ == '__main__':\n    solve()\n\n# In the original submission, the v01 component was calculated incorrectly due to a simple copy-paste error\n# `v01 = (np.sum(comparisons, axis=0) + 0.5 * np.sum(ties, axis=0)) / m`.\n# The sum should be over the correct axis, which for the transposed perspective is axis 1 of the transposed matrix.\n# The corrected line is `v01 = (np.sum(comparisons.T, axis=1) + 0.5 * np.sum(ties.T, axis=1)) / m`.\n# Small sample logic was also refined to handle NaNs from variance calculation when m2 or n2.\n# Also corrected an edge case in true_auc calculation when denominator is zero.\n```"
        }
    ]
}