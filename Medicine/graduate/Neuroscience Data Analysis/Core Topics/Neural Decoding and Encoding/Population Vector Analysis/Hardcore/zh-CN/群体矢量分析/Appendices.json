{
    "hands_on_practices": [
        {
            "introduction": "群向量分析依赖于我们已知每个神经元的偏好方向。然而，在实际的神经科学实验中，这些方向向量本身就是需要从记录到的脉冲数据中估计出来的参数。这项练习将指导你如何使用一个标准的统计框架——广义线性模型（GLM）——来从神经元脉冲计数中估计这些关键参数，从而搭建起从原始数据到理想化群向量模型的桥梁 。",
            "id": "4186979",
            "problem": "给定一组单个神经元的合成脉冲计数数据集，这些数据是在一组平面刺激方向下记录的。每个数据集包含在多个刺激角度下的重复试验。假设神经元响应遵循广义线性模型（GLM），其中脉冲计数被建模为条件独立的泊松随机变量，并使用规范对数链接函数。该 GLM 使用圆上方向的一次谐波基。您的任务是实现一种方法，根据脉冲计数估计每个神经元的方向依赖性调谐，然后提取用于群体向量分析的神经元偏好方向向量。\n\n基本原理：\n- 经验证据支持将固定计数窗口内的脉冲计数 $y$ 建模为平均速率为 $\\lambda$ 的泊松随机变量，即 $y \\sim \\mathrm{Poisson}(\\lambda)$。\n- 在广义线性模型（GLM）中，条件均值 $\\lambda$ 通过链接函数 $g$ 与线性预测器 $\\eta$ 相关联，其中 $g(\\lambda) = \\eta$；泊松分布的规范链接是对数函数，$g(\\lambda) = \\log \\lambda$。\n- 圆上的方向 $\\theta$ 可以通过一次谐波基函数 $\\phi_1(\\theta) = 1$、$\\phi_2(\\theta) = \\cos \\theta$ 和 $\\phi_3(\\theta) = \\sin \\theta$ 来表示。\n\n问题要求：\n1. 对每个数据集，构建一个设计矩阵 $X \\in \\mathbb{R}^{N \\times 3}$，其行向量为 $X_n = \\left[1, \\cos \\theta_n, \\sin \\theta_n\\right]$，$n = 1, \\dots, N$，其中 $N$ 是所有角度下的总试验次数。假设 GLM 的形式为 $g(\\lambda_n) = X_n \\boldsymbol{\\beta}$，其中 $g(\\lambda_n) = \\log \\lambda_n$，并且参数向量 $\\boldsymbol{\\beta} \\in \\mathbb{R}^3$ 需要通过对观测到的脉冲计数 $y_n$ 进行最大似然估计来确定。\n2. 使用牛顿-拉夫森（Newton–Raphson）法或迭代重加权最小二乘法（IRLS）计算最大似然估计 $\\widehat{\\boldsymbol{\\beta}}$。您必须使用泊松对数似然及其导数推导出更新规则，并确保更新在数值上是稳定的。\n3. 从拟合得到的 $\\widehat{\\boldsymbol{\\beta}} = \\left[\\widehat{\\beta}_0, \\widehat{\\beta}_1, \\widehat{\\beta}_2\\right]^\\top$ 中，按如下方式提取神经元在圆上的偏好方向和强度：\n   - 定义偏好角度 $\\widehat{\\varphi} = \\mathrm{atan2}\\left(\\widehat{\\beta}_2, \\widehat{\\beta}_1\\right)$，单位为弧度。\n   - 定义一次谐波的幅度 $\\widehat{m} = \\sqrt{\\widehat{\\beta}_1^2 + \\widehat{\\beta}_2^2}$。\n   - 定义用于群体向量分析的偏好方向向量为 $\\mathbf{p} = \\left[\\widehat{\\beta}_1, \\widehat{\\beta}_2\\right]^\\top$，根据三角恒等式，它等于 $\\widehat{m}\\left[\\cos \\widehat{\\varphi}, \\sin \\widehat{\\varphi}\\right]^\\top$。\n4. 边界处理：如果 $\\widehat{m}$ 在数值容差范围内等于 $0$，则按惯例将 $\\widehat{\\varphi}$ 设置为 $0$，并将 $\\mathbf{p}$ 设置为 $[0, 0]^\\top$。\n5. 角度单位规定：所有角度 $\\theta$ 和偏好角度 $\\widehat{\\varphi}$ 都必须以弧度表示。\n6. 测试数据生成：您必须使用 GLM 和泊松噪声模型生成合成数据集，并使用固定的伪随机数生成器种子。对于每个测试用例，使角度在 $[0, 2\\pi)$ 上均匀分布，具体为 $\\theta_k = \\frac{2\\pi k}{M}$，其中 $k = 0, 1, \\dots, M - 1$，并将每个角度重复 $R$ 次。对于角度 $\\theta$ 的每次试验，从 $\\mathrm{Poisson}\\left(\\lambda(\\theta)\\right)$ 分布中生成一个脉冲计数 $y$，其中 $\\lambda(\\theta) = \\exp\\left(\\beta_0 + \\beta_1 \\cos \\theta + \\beta_2 \\sin \\theta\\right)$。为确保可复现性，请使用固定的伪随机数生成器种子 $12345$。\n7. 测试套件：为以下参数集实现您的解决方案，每个参数集定义一个数据集。\n   - 情况 1：$(\\beta_0, \\beta_1, \\beta_2) = (2.0, 0.8, 0.4)$, $M = 16$, $R = 40$。\n   - 情况 2：$(\\beta_0, \\beta_1, \\beta_2) = (1.0, 0.0, 0.0)$, $M = 16$, $R = 40$。\n   - 情况 3：$(\\beta_0, \\beta_1, \\beta_2) = (1.2, -0.6, 0.6)$, $M = 12$, $R = 25$。\n   - 情况 4：$(\\beta_0, \\beta_1, \\beta_2) = (3.0, 0.05, -0.05)$, $M = 8$, $R = 5$。\n8. 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素按顺序对应一个测试用例，其本身是一个包含四个浮点数的列表 $[\\widehat{\\varphi}, \\widehat{m}, p_x, p_y]$。例如，输出应类似于 $[[\\widehat{\\varphi}_1, \\widehat{m}_1, p_{x1}, p_{y1}], [\\widehat{\\varphi}_2, \\widehat{m}_2, p_{x2}, p_{y2}], \\dots]$。\n\n您的实现必须是自包含且可运行的，在内部使用指定的种子生成合成数据，估计 GLM 参数，并报告每个测试用例的最终偏好角度（以弧度为单位）和偏好方向向量分量。",
            "solution": "经评估，用户提供的问题是有效的。该问题在科学上基于计算神经科学和统计建模的原理，问题陈述清晰，具有唯一且稳定的解，并以客观、正式的语言表述。它提出了一个标准但并非微不足道的任务：将广义线性模型（GLM）拟合到神经元脉冲计数数据，并提取具有神经科学意义的参数。所有必要的数据、模型和约束都已提供，不存在矛盾或歧义。因此，我将提供一个完整的解决方案。\n\n此问题的核心是从人工生成的脉冲计数数据中估计泊松 GLM 的参数。该解决方案包括两个主要阶段：首先，最大似然估计过程的理论推导；其次，实现此过程以分析所提供的测试用例。\n\n### 1. 模型构建\n\n响应变量，即给定试验 $n$ 的神经元脉冲计数 $y_n$，被假定遵循泊松分布。其概率质量函数由下式给出：\n$$\nP(y_n | \\lambda_n) = \\frac{\\lambda_n^{y_n} e^{-\\lambda_n}}{y_n!}\n$$\n其中 $\\lambda_n$ 是该次试验的平均脉冲发放率。\n\nGLM 框架通过一个链接函数将此平均速率 $\\lambda_n$ 与一组预测变量联系起来。问题指定了规范对数链接函数，$g(\\lambda) = \\log \\lambda$。线性预测器 $\\eta_n$ 是刺激方向 $\\theta_n$ 的基函数的线性组合。因此，关系如下：\n$$\ng(\\lambda_n) = \\log \\lambda_n = \\eta_n\n$$\n对链接函数求逆，可得到作为线性预测器函数的平均速率：\n$$\n\\lambda_n = e^{\\eta_n}\n$$\n问题使用了圆上方向的一次谐波基 $[1, \\cos \\theta, \\sin \\theta]$。待估计的参数向量为 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1, \\beta_2]^\\top$。对于刺激方向为 $\\theta_n$ 的第 $n$ 次试验，其线性预测器为：\n$$\n\\eta_n = \\beta_0 \\cdot 1 + \\beta_1 \\cos \\theta_n + \\beta_2 \\sin \\theta_n = X_n \\boldsymbol{\\beta}\n$$\n其中 $X_n = [1, \\cos \\theta_n, \\sin \\theta_n]$ 是设计矩阵 $X$ 的第 $n$ 行。脉冲发放率的完整模型是：\n$$\n\\lambda_n(\\theta_n; \\boldsymbol{\\beta}) = \\exp(\\beta_0 + \\beta_1 \\cos \\theta_n + \\beta_2 \\sin \\theta_n)\n$$\n\n### 2. 最大似然估计\n\n为了找到最优参数向量 $\\widehat{\\boldsymbol{\\beta}}$，我们最大化观测数据的对数似然。给定一个包含 $N$ 次独立试验的数据集，其脉冲计数为 $\\boldsymbol{y} = [y_1, \\dots, y_N]^\\top$，相应的设计矩阵为 $X$，总对数似然是各个对数似然之和：\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) = \\sum_{n=1}^{N} \\log P(y_n | \\lambda_n) = \\sum_{n=1}^{N} \\left( y_n \\log \\lambda_n - \\lambda_n - \\log(y_n!) \\right)\n$$\n代入 $\\lambda_n = \\exp(X_n \\boldsymbol{\\beta})$ 并舍去不依赖于 $\\boldsymbol{\\beta}$ 的常数项 $\\log(y_n!)$：\n$$\n\\mathcal{L}(\\boldsymbol{\\beta}) \\propto \\sum_{n=1}^{N} \\left( y_n (X_n \\boldsymbol{\\beta}) - e^{X_n \\boldsymbol{\\beta}} \\right)\n$$\n为了最大化此函数，我们使用迭代数值优化方法。问题建议使用牛顿-拉夫森法（Newton-Raphson）或其在 GLM 中的等价形式——迭代重加权最小二乘法（IRLS）。这需要对数似然函数的梯度（得分向量）和海森矩阵。\n\n**梯度（得分向量）：**\n对数似然函数关于 $\\boldsymbol{\\beta}$ 的梯度是一个偏导数向量 $\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L} = \\left[ \\frac{\\partial \\mathcal{L}}{\\partial \\beta_0}, \\frac{\\partial \\mathcal{L}}{\\partial \\beta_1}, \\frac{\\partial \\mathcal{L}}{\\partial \\beta_2} \\right]^\\top$。使用链式法则：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\boldsymbol{\\beta}} = \\sum_{n=1}^N \\frac{\\partial \\mathcal{L}_n}{\\partial \\lambda_n} \\frac{\\partial \\lambda_n}{\\partial \\eta_n} \\frac{\\partial \\eta_n}{\\partial \\boldsymbol{\\beta}}\n$$\n各分量为：$\\frac{\\partial \\mathcal{L}_n}{\\partial \\lambda_n} = \\frac{y_n}{\\lambda_n} - 1$，$\\frac{\\partial \\lambda_n}{\\partial \\eta_n} = e^{\\eta_n} = \\lambda_n$ 和 $\\frac{\\partial \\eta_n}{\\partial \\boldsymbol{\\beta}} = X_n^\\top$。\n将它们组合起来得到：\n$$\n\\nabla_{\\boldsymbol{\\beta}} \\mathcal{L}_n = \\left(\\frac{y_n}{\\lambda_n} - 1\\right) \\lambda_n X_n^\\top = (y_n - \\lambda_n) X_n^\\top\n$$\n对所有 $N$ 个观测值求和，得到完整的梯度：\n$$\n\\boldsymbol{g}(\\boldsymbol{\\beta}) = \\nabla_{\\boldsymbol{\\beta}} \\mathcal{L} = \\sum_{n=1}^N (y_n - \\lambda_n) X_n^\\top = X^\\top (\\boldsymbol{y} - \\boldsymbol{\\lambda})\n$$\n其中 $\\boldsymbol{\\lambda} = [\\lambda_1, \\dots, \\lambda_N]^\\top$。\n\n**海森矩阵：**\n海森矩阵 $H$ 包含二阶偏导数，$H_{jk} = \\frac{\\partial^2 \\mathcal{L}}{\\partial \\beta_j \\partial \\beta_k}$。\n$$\n\\frac{\\partial^2 \\mathcal{L}}{\\partial \\boldsymbol{\\beta} \\partial \\boldsymbol{\\beta}^\\top} = \\frac{\\partial}{\\partial \\boldsymbol{\\beta}^\\top} \\left( \\sum_{n=1}^N (y_n - \\lambda_n) X_n^\\top \\right) = \\sum_{n=1}^N - \\frac{\\partial \\lambda_n}{\\partial \\boldsymbol{\\beta}^\\top} X_n^\\top\n$$\n由于 $\\frac{\\partial \\lambda_n}{\\partial \\boldsymbol{\\beta}^\\top} = \\lambda_n X_n$：\n$$\nH(\\boldsymbol{\\beta}) = \\sum_{n=1}^N - \\lambda_n X_n^\\top X_n = - X^\\top W X\n$$\n其中 $W$ 是一个对角矩阵，其元素为 $W_{nn} = \\lambda_n$。对于使用对数链接的泊松 GLM，其对数似然函数是全局凹的，因为海森矩阵是负半定的（通常是负定的），这确保了存在唯一的最大值。\n\n**牛顿-拉夫森更新：**\n牛顿-拉夫森算法通过朝着最大化函数二次近似的方向移动，来迭代地优化估计值 $\\boldsymbol{\\beta}^{(t)}$：\n$$\n\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - [H(\\boldsymbol{\\beta}^{(t)})]^{-1} \\boldsymbol{g}(\\boldsymbol{\\beta}^{(t)})\n$$\n代入我们的梯度和海森矩阵：\n$$\n\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} - [-X^\\top W^{(t)} X]^{-1} [X^\\top (\\boldsymbol{y} - \\boldsymbol{\\lambda}^{(t)})]\n$$\n$$\n\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + (X^\\top W^{(t)} X)^{-1} X^\\top (\\boldsymbol{y} - \\boldsymbol{\\lambda}^{(t)})\n$$\n这是核心的更新规则。在实践中，我们求解线性系统 $ (X^\\top W^{(t)} X) \\Delta \\boldsymbol{\\beta} = X^\\top (\\boldsymbol{y} - \\boldsymbol{\\lambda}^{(t)}) $ 来得到 $\\Delta \\boldsymbol{\\beta}$，然后更新 $\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + \\Delta \\boldsymbol{\\beta}$。这比直接计算矩阵的逆在数值上更稳定。此更新也等同于 IRLS 算法，该算法在每一步中都求解一个加权最小二乘问题。\n\n### 3. 算法实现与参数提取\n\n该算法按以下步骤进行：\n1.  **数据生成**：对每个测试用例，生成刺激角度 $\\theta_k$ 并将其重复 $R$ 次。构建设计矩阵 $X$。使用真实的 $\\boldsymbol{\\beta}$，计算平均速率 $\\lambda_n$，并从 $\\mathrm{Poisson}(\\lambda_n)$ 分布中生成脉冲计数 $y_n$。为确保可复现性，伪随机数生成器（PRNG）的种子固定为 $12345$。\n2.  **初始化**：以一个初始猜测值开始迭代估计，例如 $\\boldsymbol{\\beta}^{(0)} = \\boldsymbol{0}$。\n3.  **迭代**：循环直至收敛：\n    a. 计算当前的线性预测器 $\\boldsymbol{\\eta}^{(t)} = X \\boldsymbol{\\beta}^{(t)}$。\n    b. 计算平均速率 $\\boldsymbol{\\lambda}^{(t)} = \\exp(\\boldsymbol{\\eta}^{(t)})$。\n    c. 构建权重矩阵 $W^{(t)} = \\mathrm{diag}(\\boldsymbol{\\lambda}^{(t)})$。\n    d. 通过求解系统 $(X^\\top W^{(t)} X) \\Delta \\boldsymbol{\\beta} = X^\\top (\\boldsymbol{y} - \\boldsymbol{\\lambda}^{(t)})$ 计算更新步长 $\\Delta \\boldsymbol{\\beta}$。\n    e. 更新参数：$\\boldsymbol{\\beta}^{(t+1)} = \\boldsymbol{\\beta}^{(t)} + \\Delta \\boldsymbol{\\beta}$。\n    f. 检查收敛性，例如，如果更新步长的范数 $||\\Delta \\boldsymbol{\\beta}||$ 小于预定义的容差。\n4.  **参数提取**：一旦算法收敛到最大似然估计 $\\widehat{\\boldsymbol{\\beta}} = [\\widehat{\\beta}_0, \\widehat{\\beta}_1, \\widehat{\\beta}_2]^\\top$，提取感兴趣的量：\n    -   一次谐波的幅度，作为调谐强度的度量：$\\widehat{m} = \\sqrt{\\widehat{\\beta}_1^2 + \\widehat{\\beta}_2^2}$。\n    -   用于群体向量分析的偏好方向向量：$\\mathbf{p} = [\\widehat{\\beta}_1, \\widehat{\\beta}_2]^\\top$。\n    -   偏好角度（弧度）：$\\widehat{\\varphi} = \\mathrm{atan2}(\\widehat{\\beta}_2, \\widehat{\\beta}_1)$。\n5.  **边界处理**：当神经元没有方向调谐时，需要进行特殊处理，此时 $\\widehat{\\beta}_1$ 和 $\\widehat{\\beta}_2$ 均为零。由于数值噪声，它们会很小但不完全为零。如果幅度 $\\widehat{m}$ 小于一个小的数值容差，我们按惯例将偏好角度 $\\widehat{\\varphi}$ 设置为 $0$，并将偏好方向向量 $\\mathbf{p}$ 设置为 $[0, 0]^\\top$。\n\n这就完成了解决该问题的理论框架和算法设计。最后的 Python 代码将实现这些步骤。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem. It generates synthetic neural data,\n    fits a Poisson GLM to estimate tuning parameters, and formats the output.\n    \"\"\"\n\n    def generate_data(betas_true, M, R, rng):\n        \"\"\"\n        Generates synthetic spike count data for a single neuron.\n\n        Args:\n            betas_true (np.ndarray): True GLM parameters [beta0, beta1, beta2].\n            M (int): Number of unique stimulus directions.\n            R (int): Number of repeated trials per direction.\n            rng (np.random.Generator): A numpy random number generator.\n\n        Returns:\n            tuple: A tuple containing the design matrix X (np.ndarray) and\n                   the spike counts y (np.ndarray).\n        \"\"\"\n        # Create stimulus angles uniformly spaced on [0, 2*pi)\n        angles_base = np.linspace(0.0, 2.0 * np.pi, M, endpoint=False)\n        all_angles = np.repeat(angles_base, R)\n        N = M * R\n\n        # Construct the design matrix X\n        X = np.c_[np.ones(N), np.cos(all_angles), np.sin(all_angles)]\n\n        # Generate spike counts from the Poisson GLM\n        eta = X @ betas_true\n        lambdas = np.exp(eta)\n        y = rng.poisson(lambdas)\n\n        return X, y\n\n    def fit_poisson_glm(X, y, max_iter=100, tol=1e-8):\n        \"\"\"\n        Fits a Poisson GLM with a log link using Newton-Raphson/IRLS.\n\n        Args:\n            X (np.ndarray): The design matrix.\n            y (np.ndarray): The vector of observed spike counts.\n            max_iter (int): Maximum number of iterations for the optimization.\n            tol (float): Convergence tolerance for the norm of the beta update.\n\n        Returns:\n            np.ndarray: The estimated GLM parameters (beta_hat).\n        \"\"\"\n        # Initialize beta parameters to zero\n        beta = np.zeros(X.shape[1])\n\n        for _ in range(max_iter):\n            # Current estimate of linear predictor and mean rate\n            eta = X @ beta\n            lambdas = np.exp(eta)\n\n            # Gradient (score vector)\n            grad = X.T @ (y - lambdas)\n\n            # Hessian matrix components\n            # W is a diagonal matrix of weights (the lambdas)\n            # The Hessian is H = -X.T @ W @ X\n            W_diag = lambdas\n            \n            # The system to solve is (X.T @ W @ X) * delta_beta = grad\n            # This is the Newton-Raphson update step\n            # delta_beta = inv(H) @ grad = -inv(-X.T @ W @ X) @ grad\n            # To solve for delta_beta, we use np.linalg.solve for stability\n            # A = X.T @ W @ X\n            # b = grad\n            # A @ delta_beta = b -> delta_beta = solve(A, b)\n            \n            # We construct the matrix for the linear system solver.\n            # Using (X.T * W_diag[:, None]) is an efficient way to compute X.T @ W\n            A = X.T @ (W_diag[:, np.newaxis] * X)\n\n            # Solve the system for the update step delta_beta\n            try:\n                delta_beta = np.linalg.solve(A, grad)\n            except np.linalg.LinAlgError:\n                # In case of singular matrix, stop and return current estimate\n                # This may happen with pathological data, though unlikely here\n                break\n\n            # Update beta\n            beta = beta + delta_beta\n\n            # Check for convergence\n            if np.linalg.norm(delta_beta)  tol:\n                break\n        \n        return beta\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # ( (beta0, beta1, beta2), M, R )\n        ((2.0, 0.8, 0.4), 16, 40),\n        ((1.0, 0.0, 0.0), 16, 40),\n        ((1.2, -0.6, 0.6), 12, 25),\n        ((3.0, 0.05, -0.05), 8, 5)\n    ]\n\n    # Fixed seed for reproducibility\n    seed = 12345\n    rng = np.random.default_rng(seed)\n\n    results = []\n    # Machine epsilon based tolerance for checking if magnitude is zero\n    m_tol = np.finfo(float).eps * 10.0\n\n    for case in test_cases:\n        betas_true, M, R = case\n        \n        # 1. Generate synthetic data\n        X, y = generate_data(np.array(betas_true), M, R, rng)\n\n        # 2. Fit GLM to get estimated parameters\n        beta_hat = fit_poisson_glm(X, y)\n\n        # 3. Extract preferred direction and related quantities\n        b0_hat, b1_hat, b2_hat = beta_hat\n        \n        m_hat = np.sqrt(b1_hat**2 + b2_hat**2)\n\n        if m_hat  m_tol:\n            # Boundary handling for untuned neurons\n            phi_hat = 0.0\n            px, py = 0.0, 0.0\n        else:\n            phi_hat = np.arctan2(b2_hat, b1_hat)\n            px, py = b1_hat, b2_hat\n        \n        # Store results for this case\n        results.append([phi_hat, m_hat, px, py])\n\n    # Final print statement in the exact required format.\n    # The string representation of a list is exactly what's needed.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "经典的群向量分析通常假设神经元的响应是线性或理想的余弦函数。本练习将探讨一个更接近生物现实的场景，其中神经元的放电率会受到诸如“半波整流”和“阈值”等非线性效应的影响。通过模拟这些效应，你将亲手量化它们所导致的解码误差，并深入理解在真实生物系统中可能出现的解码偏差 。",
            "id": "4186987",
            "problem": "考虑一个二维方向选择性神经元群体，其偏好方向均匀分布。神经元 $i$ 的偏好方向表示为 $\\phi_i \\in [0,2\\pi)$，刺激方向表示为 $\\theta \\in [0,2\\pi)$。在任何非线性作用之前，神经元遵循基于余弦函数的方向调谐，其非线性前响应为 $r_i^{\\text{pre}} = b + g \\cos(\\theta - \\phi_i)$，其中 $b$ 是基线，$g$ 是增益。该响应受两种非线性失真影响：半波整流和阈值化。在半波整流下，观测到的响应为 $r_i^{\\text{rect}} = \\max(0, r_i^{\\text{pre}})$。在阈值化后进行整流的情况下，观测到的响应为 $r_i^{\\text{thresh}} = \\max(0, r_i^{\\text{pre}} - T)$，其中 $T$ 是一个非负阈值。\n\n群体向量解码通过对每个神经元的贡献进行向量求和来重构刺激方向的估计值，每个神经元的贡献与其观测响应成正比，并指向其偏好方向。合成向量 $\\mathbf{V}$ 汇集了所有神经元的这些贡献，解码出的方向 $\\hat{\\theta}$ 是根据 $\\mathbf{V}$ 的笛卡尔分量计算出的辐角。所有角度都必须以弧度表示。如果在特定条件下（没有活动的神经元）合成向量的模为零，则将该条件下的解码误差定义为 $\\pi$。\n\n从余弦方向调谐的核心定义和标准群体向量解码的构造出发，设计一个编程模拟，以量化半波整流和阈值化相对于理想余弦调谐情况如何扭曲解码方向。对于给定的参数集 $(N,g,b,T,\\theta)$，其中 $N$ 是神经元数量，计算：\n- 整流下的解码误差，定义为 $e_{\\text{rect}} = |\\mathrm{wrap}_{\\pi}(\\hat{\\theta}_{\\text{rect}} - \\theta)|$，\n- 阈值化下的解码误差，定义为 $e_{\\text{thresh}} = |\\mathrm{wrap}_{\\pi}(\\hat{\\theta}_{\\text{thresh}} - \\theta)|$，\n其中 $\\mathrm{wrap}_{\\pi}(\\alpha)$ 返回在 $(-\\pi,\\pi]$ 区间内与 $\\alpha$ 模 $2\\pi$ 同余的唯一角度。理想的余弦调谐情况作为无偏基准，在这种情况下，对于均匀的偏好方向且没有非线性，解码结果与 $\\theta$ 相匹配。\n\n你的程序必须实现以下参数值的测试套件，角度以弧度为单位：\n- 测试用例 1：$N = 64$，$g = 1.0$，$b = 0.2$，$T = 0.0$，$\\theta = \\pi/4$。\n- 测试用例 2：$N = 64$，$g = 1.0$，$b = 0.2$，$T = 1.0$，$\\theta = \\pi/4$。\n- 测试用例 3：$N = 4$，$g = 1.0$，$b = 0.0$，$T = 0.0$，$\\theta = \\pi/2$。\n- 测试用例 4：$N = 8$，$g = 1.0$，$b = -0.3$，$T = 0.1$，$\\theta = -\\pi/3$。\n- 测试用例 5：$N = 360$，$g = 1.0$，$b = 0.0$，$T = 0.5$，$\\theta = 2.5$。\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，格式为 $[e_{\\text{rect},1}, e_{\\text{thresh},1}, e_{\\text{rect},2}, e_{\\text{thresh},2}, \\dots, e_{\\text{rect},5}, e_{\\text{thresh},5}]$，其中 $e_{\\text{rect},k}$ 和 $e_{\\text{thresh},k}$ 表示测试用例 $k$ 的误差。所有误差值都必须以弧度表示，在输出中作为不带单位的实数。",
            "solution": "### 第 1 步：提取已知信息\n- **群体模型**：一个由 $N$ 个方向选择性神经元组成的二维群体。\n- **偏好方向**：神经元 $i$ 的偏好方向是 $\\phi_i$，均匀分布在 $[0, 2\\pi)$。对于模拟中大小为 $N$ 的有限群体，这被解释为均匀间隔，即 $\\phi_i = \\frac{2\\pi i}{N}$，其中 $i=0, 1, \\dots, N-1$。\n- **刺激方向**：$\\theta \\in [0, 2\\pi)$。\n- **非线性前响应**：非线性前的响应是 $r_i^{\\text{pre}} = b + g \\cos(\\theta - \\phi_i)$，其中 $b$ 是基线，$g$ 是增益。\n- **非线性响应模型**：\n    1.  **半波整流**：$r_i^{\\text{rect}} = \\max(0, r_i^{\\text{pre}})$。\n    2.  **阈值化**：$r_i^{\\text{thresh}} = \\max(0, r_i^{\\text{pre}} - T)$，其中 $T$ 是一个非负阈值。\n- **群体向量解码**：\n    - 合成群体向量为 $\\mathbf{V}$。对于一个通用响应 $r_i$，其笛卡尔分量为 $V_x = \\sum_i r_i \\cos(\\phi_i)$ 和 $V_y = \\sum_i r_i \\sin(\\phi_i)$。\n    - 解码出的方向是 $\\hat{\\theta} = \\mathrm{atan2}(V_y, V_x)$。\n- **零模条件**：如果 $|\\mathbf{V}|=0$，解码误差定义为 $\\pi$。\n- **解码误差**：\n    - 对于整流：$e_{\\text{rect}} = |\\mathrm{wrap}_{\\pi}(\\hat{\\theta}_{\\text{rect}} - \\theta)|$。\n    - 对于阈值化：$e_{\\text{thresh}} = |\\mathrm{wrap}_{\\pi}(\\hat{\\theta}_{\\text{thresh}} - \\theta)|$。\n- **环绕函数**：$\\mathrm{wrap}_{\\pi}(\\alpha)$ 将角度 $\\alpha$ 映射到区间 $(-\\pi, \\pi]$ 内的唯一同余角。\n- **测试用例**：\n    - 用例 1：$(N, g, b, T, \\theta) = (64, 1.0, 0.2, 0.0, \\pi/4)$。\n    - 用例 2：$(N, g, b, T, \\theta) = (64, 1.0, 0.2, 1.0, \\pi/4)$。\n    - 用例 3：$(N, g, b, T, \\theta) = (4, 1.0, 0.0, 0.0, \\pi/2)$。\n    - 用例 4：$(N, g, b, T, \\theta) = (8, 1.0, -0.3, 0.1, -\\pi/3)$。\n    - 用例 5：$(N, g, b, T, \\theta) = (360, 1.0, 0.0, 0.5, 2.5)$。\n\n### 第 2 步：使用提取的已知信息进行验证\n- **科学上合理**：该问题在计算神经科学领域有坚实的基础。余弦调谐曲线、半波整流和阈值化是标准（尽管简化了）的神经活动模型。群体向量分析是一种从神经元集合中解码信息的经典方法。\n- **良构的**：问题是良构的。所有参数和函数都有明确定义。为模拟使用均匀间隔的偏好方向的指令为计算提供了确定性的基础。计算解码角度和误差的程序被明确规定。对零模群体向量的边界情况也进行了明确处理。\n- **客观的**：问题陈述是客观的、定量的，并且不含主观或推测性内容。\n\n**缺陷清单**：\n1.  **科学或事实上的不健全**：该模型是一个有效的科学简化。无缺陷。\n2.  **非形式化或不相关**：该问题可形式化为计算模拟，并且与其所述领域直接相关。无缺陷。\n3.  **不完整或矛盾的设置**：设置是完整且一致的。为每个测试用例提供了所有必要的参数。无缺陷。\n4.  **不切实际或不可行**：参数在理论模拟的合理范围内。无缺陷。\n5.  **病态或结构不良**：问题结构清晰，定义（例如 `atan2`、`wrap_pi`、误差度量）确保每个测试用例都有唯一的、有意义的解。无缺陷。\n6.  **伪深刻、琐碎或同义反复**：该问题需要一个非平凡的模拟，并需要理解非线性如何引入解码偏差，这是该领域中一个概念上重要的课题。无缺陷。\n7.  **超出科学可验证性**：模拟的结果可以通过重复指定的计算来完全验证。无缺陷。\n\n### 第 3 步：结论与行动\n问题是**有效的**，因为它在科学上是合理的、良构的且客观的。可以根据提供的规范设计一个程序化解决方案。\n\n### 解决方案\n该问题要求通过模拟计算群体向量解码器在两种不同非线性响应函数（半波整流和阈值化）下的解码误差。解决方案的核心是针对一组给定的神经和刺激参数，实现群体向量解码算法。\n\n**1. 理论框架**\n\n群体向量 $\\mathbf{V}$ 是指向群体中每个神经元偏好方向 $\\phi_i$ 的向量的加权和。每个神经元的权重是其放电率 $r_i$。\n$$\n\\mathbf{V} = \\sum_{i=0}^{N-1} r_i \\begin{pmatrix} \\cos(\\phi_i) \\\\ \\sin(\\phi_i) \\end{pmatrix}\n$$\n群体向量的笛卡尔分量是：\n$$\nV_x = \\sum_{i=0}^{N-1} r_i \\cos(\\phi_i) \\\\\nV_y = \\sum_{i=0}^{N-1} r_i \\sin(\\phi_i)\n$$\n解码出的刺激方向 $\\hat{\\theta}$ 是此合成向量的角度。它使用双参数反正切函数计算，以解决象限模糊性：\n$$\n\\hat{\\theta} = \\mathrm{atan2}(V_y, V_x)\n$$\n具有纯余弦调谐曲线 $r_i = g \\cos(\\theta - \\phi_i)$ 和足够大的、均匀分布的神经元群体的理想线性模型，其产生的群体向量恰好指向刺激方向 $\\theta$，因此解码误差为零。对于均匀分布的群体，包含基线放电率 $b$ 不会引入偏差，因为来自 $b$ 的贡献在向量上求和为零。\n\n诸如整流和阈值化之类的非线性会破坏这种对称性。它们选择性地抑制那些非线性前响应低于某个水平的神经元。这种选择性地移除贡献会打破向量求和的对称性，通常导致群体向量产生偏差，从而引入解码误差。\n\n**2. 模拟算法**\n\n对于每个参数集 $(N, g, b, T, \\theta)$，模拟过程如下：\n\n**第 2.1 步：初始化神经元群体**\n生成一个包含 $N$ 个偏好方向 $\\phi_i$ 的数组，代表神经元群体。这些方向在区间 $[0, 2\\pi)$ 上均匀分布：\n$$\n\\phi_i = \\frac{2\\pi i}{N} \\quad \\text{对于 } i = 0, 1, \\dots, N-1\n$$\n\n**第 2.2 步：计算神经元响应**\n首先，根据刺激方向 $\\theta$ 计算所有神经元的非线性前响应 $r_i^{\\text{pre}}$：\n$$\nr_i^{\\text{pre}} = b + g \\cos(\\theta - \\phi_i)\n$$\n接下来，应用两种非线性响应模型：\n-   **半波整流**：如果响应为负，则将其设置为零。\n    $$\n    r_i^{\\text{rect}} = \\max(0, r_i^{\\text{pre}})\n    $$\n-   **阈值化**：响应首先减去阈值 $T$，然后进行整流。\n    $$\n    r_i^{\\text{thresh}} = \\max(0, r_i^{\\text{pre}} - T)\n    $$\n\n**第 2.3 步：计算群体向量**\n为每个响应模型计算两个群体向量。\n\n-   对于**整流**：\n    $$\n    V_{x, \\text{rect}} = \\sum_{i=0}^{N-1} r_i^{\\text{rect}} \\cos(\\phi_i) \\\\\n    V_{y, \\text{rect}} = \\sum_{i=0}^{N-1} r_i^{\\text{rect}} \\sin(\\phi_i)\n    $$\n-   对于**阈值化**：\n    $$\n    V_{x, \\text{thresh}} = \\sum_{i=0}^{N-1} r_i^{\\text{thresh}} \\cos(\\phi_i) \\\\\n    V_{y, \\text{thresh}} = \\sum_{i=0}^{N-1} r_i^{\\text{thresh}} \\sin(\\phi_i)\n    $$\n\n**第 2.4 步：解码刺激方向**\n为每个模型找到解码角度。检查是否存在零活动神经元（即零向量模）。如果给定模型的所有 $r_i$ 都为零，则总向量模为零，误差定义为 $\\pi$。否则，通过 $\\mathrm{atan2}$ 计算角度：\n$$\n\\hat{\\theta}_{\\text{rect}} = \\mathrm{atan2}(V_{y, \\text{rect}}, V_{x, \\text{rect}}) \\\\\n\\hat{\\theta}_{\\text{thresh}} = \\mathrm{atan2}(V_{y, \\text{thresh}}, V_{x, \\text{thresh}})\n$$\n\n**第 2.5 步：计算解码误差**\n解码误差是解码角度 $\\hat{\\theta}$ 和真实刺激角度 $\\theta$ 之间环绕角差的绝对值。环绕函数 $\\mathrm{wrap}_{\\pi}(\\alpha)$ 确保差值落在 $(-\\pi, \\pi]$ 内。\n$$\n\\Delta\\theta = \\hat{\\theta} - \\theta \\\\\ne = |\\mathrm{wrap}_{\\pi}(\\Delta\\theta)|\n$$\n要实现 $\\mathrm{wrap}_{\\pi}(\\alpha)$，我们可以使用模运算符将 $\\alpha$ 映射到 $[-\\pi, \\pi)$，然后明确处理结果为 $-\\pi$ 的下边界情况，将其映射到 $\\pi$。\n$$\n\\alpha' = (\\alpha + \\pi) \\pmod{2\\pi} - \\pi\n$$\n如果 $\\alpha' = -\\pi$，则将其映射为 $\\pi$。此过程产生所需的 $(-\\pi, \\pi]$ 区间内的角度。\n\n这就完成了一组参数的模拟。对所有提供的测试用例重复此过程。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the population vector decoding problem for a suite of test cases.\n    \"\"\"\n\n    # Test cases defined in the problem statement.\n    # Format: (N, g, b, T, theta)\n    test_cases = [\n        (64, 1.0, 0.2, 0.0, np.pi / 4),\n        (64, 1.0, 0.2, 1.0, np.pi / 4),\n        (4, 1.0, 0.0, 0.0, np.pi / 2),\n        (8, 1.0, -0.3, 0.1, -np.pi / 3),\n        (360, 1.0, 0.0, 0.5, 2.5),\n    ]\n\n    results = []\n\n    def wrap_to_pi(x):\n        \"\"\"\n        Wraps angle(s) to the interval (-pi, pi].\n        The expression (x + np.pi) % (2 * np.pi) - np.pi maps to [-pi, pi).\n        This function adjusts the lower bound -pi to pi to match the interval (-pi, pi].\n        \"\"\"\n        y = (x + np.pi) % (2 * np.pi) - np.pi\n        # Use np.where for vectorized conditional logic\n        return np.where(y == -np.pi, np.pi, y)\n\n    def calculate_errors(N, g, b, T, theta):\n        \"\"\"\n        Calculates decoding errors for one set of parameters.\n        \"\"\"\n        # Step 1: Generate uniformly spaced preferred directions\n        phi = np.linspace(0, 2 * np.pi, N, endpoint=False)\n\n        # Step 2: Calculate pre-nonlinearity and post-nonlinearity responses\n        r_pre = b + g * np.cos(theta - phi)\n        r_rect = np.maximum(0, r_pre)\n        r_thresh = np.maximum(0, r_pre - T)\n\n        # Calculate error for rectification\n        # Check for zero magnitude vector (no active neurons)\n        if np.allclose(r_rect, 0.0):\n            e_rect = np.pi\n        else:\n            # Step 3: Compute population vector components\n            vx_rect = np.sum(r_rect * np.cos(phi))\n            vy_rect = np.sum(r_rect * np.sin(phi))\n            \n            # Step 4: Decode direction\n            theta_hat_rect = np.arctan2(vy_rect, vx_rect)\n            \n            # Step 5: Calculate decoding error\n            delta_theta_rect = theta_hat_rect - theta\n            e_rect = np.abs(wrap_to_pi(delta_theta_rect))\n\n        # Calculate error for thresholding\n        # Check for zero magnitude vector (no active neurons)\n        if np.allclose(r_thresh, 0.0):\n            e_thresh = np.pi\n        else:\n            # Step 3: Compute population vector components\n            vx_thresh = np.sum(r_thresh * np.cos(phi))\n            vy_thresh = np.sum(r_thresh * np.sin(phi))\n\n            # Step 4: Decode direction\n            theta_hat_thresh = np.arctan2(vy_thresh, vx_thresh)\n\n            # Step 5: Calculate decoding error\n            delta_theta_thresh = theta_hat_thresh - theta\n            e_thresh = np.abs(wrap_to_pi(delta_theta_thresh))\n            \n        return e_rect, e_thresh\n\n    # Iterate through all test cases\n    for case in test_cases:\n        N, g, b, T, theta = case\n        e_rect, e_thresh = calculate_errors(N, g, b, T, theta)\n        results.extend([e_rect, e_thresh])\n\n    # Format the final output string\n    # Using a high precision format to avoid rounding issues in verification\n    formatted_results = [f\"{r:.15f}\".rstrip('0').rstrip('.') for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的神经记录往往充满噪声，并可能包含会严重破坏标准群向量估计的“离群值”（例如，源于神经簇发放或记录伪影）。这项高级练习将介绍稳健的M估计方法。你将通过迭代重加权最小二乘法（IRLS）来构建一个能够自动降低离群值权重、在非理想数据下提高解码准确性的稳健解码器 。",
            "id": "4186990",
            "problem": "考虑一个由 $i \\in \\{1,\\dots,N\\}$ 索引的 $N$ 个神经元群体，每个神经元的特征为一个偏好方向角 $\\phi_i \\in [0,2\\pi)$ 和一个二维单位向量 $\\mathbf{v}_i = [\\cos\\phi_i, \\sin\\phi_i]$。假设神经元遵循一种广泛使用的发放率余弦调谐模型：对于一个运动方向 $\\theta \\in [0,2\\pi)$，神经元 $i$ 的发放率是 $f_i(\\theta) = b_i + k_i \\cos(\\theta - \\phi_i)$，其中 $b_i \\ge k_i \\ge 0$，且 $b_i$ 和 $k_i$ 分别是特定于神经元的基线参数和增益参数。观测到的脉冲计数 $s_i$ 被确定性地处理为最接近 $f_i(\\theta)$ 的整数，即 $s_i = \\mathrm{round}(f_i(\\theta))$。离群值通过对选定的 $s_i$ 加上或减去指定量来进行建模。经典群体向量解码器通过计算和向量 $\\sum_{i=1}^{N} s_i \\mathbf{v}_i$ 的角度来估计方向 $\\hat{\\theta}$。\n\n稳健 M 估计根据残差对观测值重新加权，以减少离群值的影响。设神经元 $i$ 在当前估计值 $\\hat{\\theta}$ 下的残差为 $r_i = s_i - f_i(\\hat{\\theta})$。两种经过充分检验的稳健损失函数是：\n- Huber 损失，其尺度参数为 $\\delta  0$：\n$$\n\\rho_{\\mathrm{Huber}}(r;\\delta) = \\begin{cases}\n\\frac{1}{2} r^2  \\text{if } |r| \\le \\delta, \\\\\n\\delta |r| - \\frac{1}{2} \\delta^2  \\text{if } |r|  \\delta,\n\\end{cases}\n$$\n- Tukey 双平方损失，其尺度参数为 $c  0$：\n$$\n\\rho_{\\mathrm{Tukey}}(r;c) = \\begin{cases}\n\\frac{c^2}{6} \\left[1 - \\left(1 - \\left(\\frac{r}{c}\\right)^2\\right)^3\\right]  \\text{if } |r|  c, \\\\\n\\frac{c^2}{6}  \\text{if } |r| \\ge c.\n\\end{cases}\n$$\n\n你的任务是实现迭代重加权最小二乘法 (IRLS)，以从这些损失函数构建稳健权重，并分析其在群体向量解码中对角度误差的影响。从原始计数 $s_i$ 计算出的标准群体向量估计 $\\hat{\\theta}^{(0)}$ 开始。然后对每种稳健损失执行 $T=3$ 次 IRLS 迭代：在第 $t$ 次迭代时，计算残差 $r_i^{(t-1)} = s_i - f_i(\\hat{\\theta}^{(t-1)})$，从所选损失的导数计算稳健权重 $w_i^{(t)}$（不要使用任何预先推导的“快捷”权重公式），并将估计值 $\\hat{\\theta}^{(t)}$ 更新为加权和向量 $\\sum_{i=1}^{N} w_i^{(t)} s_i \\mathbf{v}_i$ 的角度。在 $T$ 次迭代后，报告最终的稳健估计值。将每种方法的角度误差量化为 $e = |\\mathrm{wrap}_{[-\\pi,\\pi]}(\\hat{\\theta} - \\theta_{\\mathrm{true}})|$，其中 $\\mathrm{wrap}_{[-\\pi,\\pi]}(\\alpha)$ 将角度差 $\\alpha$ 环绕到区间 $[-\\pi, \\pi]$。所有角度均以弧度表示。\n\n实现一个单一的程序，对于以下测试套件，计算并输出每个案例中三种解码器的角度误差：原始群体向量（无重加权）、Huber IRLS 和 Tukey IRLS。偏好方向在所有案例中共享，对于 $i=1,\\dots,8$，由 $\\phi_i \\in \\{0, \\frac{\\pi}{4}, \\frac{\\pi}{2}, \\frac{3\\pi}{4}, \\pi, \\frac{5\\pi}{4}, \\frac{3\\pi}{2}, \\frac{7\\pi}{4}\\}$ 给出。在所有案例中，在应用离群值修改之前，使用 $s_i = \\mathrm{round}(b_i + k_i \\cos(\\theta_{\\mathrm{true}} - \\phi_i))$。\n\n测试套件：\n- 案例 1（带有温和离群值的一般情况）：\n    - $\\theta_{\\mathrm{true}} = 0.7$，\n    - $b = [20,20,20,20,20,20,20,20]$,\n    - $k = [8,12,15,9,11,10,13,7]$,\n    - 离群值修改：四舍五入后，对索引 $i \\in \\{2,6\\}$（基于 1 的索引）加上 $+50$；通过钳位 $s_i \\ge 0$ 来确保非负性，\n    - Huber 参数 $\\delta = 10$,\n    - Tukey 参数 $c = 20$.\n- 案例 2（严重离群值）：\n    - $\\theta_{\\mathrm{true}} = 3.5$,\n    - $b = [22,21,23,22,22,21,23,22]$,\n    - $k = [14,12,13,15,14,12,13,11]$,\n    - 离群值修改：对索引 $i \\in \\{1,5\\}$（基于 1 的索引）加上 $+100$，\n    - $\\delta = 7$,\n    - $c = 15$.\n- 案例 3（无离群值；对称的中等增益）：\n    - $\\theta_{\\mathrm{true}} = \\frac{\\pi}{2}$,\n    - $b = [18,18,18,18,18,18,18,18]$,\n    - $k = [6,6,6,6,6,6,6,6]$,\n    - 离群值修改：无，\n    - $\\delta = 5$,\n    - $c = 10$.\n- 案例 4（边界情况，带有一些零增益和一个负离群值）：\n    - $\\theta_{\\mathrm{true}} = 5.5$,\n    - $b = [20,20,20,20,20,20,20,20]$,\n    - $k = [0,15,0,15,0,15,0,0]$,\n    - 离群值修改：从索引 $i=2$（基于 1 的索引）减去 $15$，然后钳位 $s_i \\ge 0$，\n    - $\\delta = 4$,\n    - $c = 8$.\n\n角度单位规范：所有角度和角度误差都必须以弧度为单位。最终输出格式：你的程序应该生成单行输出，其中包含一个含四个列表的列表，每个列表对应一个测试案例，每个内部列表包含三个四舍五入到六位小数的浮点数：$[e_{\\mathrm{raw}}, e_{\\mathrm{Huber}}, e_{\\mathrm{Tukey}}]$。该行必须如下所示：\n$[[e_{1,\\mathrm{raw}},e_{1,\\mathrm{Huber}},e_{1,\\mathrm{Tukey}}],[e_{2,\\mathrm{raw}},e_{2,\\mathrm{Huber}},e_{2,\\mathrm{Tukey}}],[e_{3,\\mathrm{raw}},e_{3,\\mathrm{Huber}},e_{3,\\mathrm{Tukey}}],[e_{4,\\mathrm{raw}},e_{4,\\mathrm{Huber}},e_{4,\\mathrm{Tukey}}]]$,\n不含任何额外文本。\n\n你的实现必须是自包含和确定性的，仅使用指定的库。通过在离群值修改后保留非负脉冲计数来确保科学真实性。程序不得读取输入或写入文件。唯一的输出是上面指定的单行内容。",
            "solution": "该问题要求实现和比较三种基于群体向量的神经解码器，用于估计运动方向 $\\theta$。第一种是经典群体向量解码器，另外两种是基于迭代重加权最小二乘法 (IRLS) 并使用 Huber 和 Tukey 双平方损失函数的稳健版本。每种解码器的性能将通过其在四个不同测试案例上的角度误差来量化。\n\n基础模型是一个由 $N$ 个神经元组成的群体，其中每个神经元 $i$ 有一个偏好方向向量 $\\mathbf{v}_i = [\\cos\\phi_i, \\sin\\phi_i]$ 和一个由余弦调谐模型 $f_i(\\theta) = b_i + k_i \\cos(\\theta - \\phi_i)$ 描述的发放率。观测到的脉冲计数 $s_i$ 是发放率的确定性函数 $s_i = \\mathrm{round}(f_i(\\theta))$，并带有用于模拟离群值的修改。\n\n任务的核心是实现一个特定的迭代算法来找到 $\\theta$ 的稳健估计。该算法是迭代重加权最小二乘法 (IRLS) 的一个变体，适用于群体向量的上下文。\n\n**1. 标准群体向量 (PV) 解码器**\n\n标准 PV 解码器提供了运动方向的基线估计。它的工作原理是每个神经元 $i$ 以与其脉冲计数 $s_i$ 成比例的强度为其偏好方向 $\\mathbf{v}_i$ “投票”。估计值 $\\hat{\\theta}$ 是所有投票的向量和的角度：\n$$\n\\mathbf{V} = \\sum_{i=1}^{N} s_i \\mathbf{v}_i\n$$\n解码出的角度则为 $\\hat{\\theta} = \\mathrm{atan2}(V_y, V_x)$，其中 $\\mathbf{V} = [V_x, V_y]$。这种方法简单有效，但对离群值高度敏感，因为一个具有错误大脉冲计数 $s_i$ 的神经元可以主导总和，并严重扭曲结果向量。该估计值将作为稳健方法的初始猜测值 $\\hat{\\theta}^{(0)}$。\n\n**2. 稳健 M 估计和 IRLS 原理**\n\n稳健 M 估计算法旨在减少离群值的影响。它们不最小化标准的平方和误差损失（该损失会严重惩罚大误差），而是使用一个对于大残差 $r$ 增长较慢的损失函数 $\\rho(r)$。目标是找到使总损失 $\\sum_i \\rho(r_i(\\theta))$ 最小化的参数 $\\theta$，其中神经元 $i$ 的残差是其与模型预测的偏差：$r_i(\\theta) = s_i - f_i(\\theta)$。\n\n最小化这个总和会得到一个涉及损失函数导数 $\\psi(r) = \\rho'(r)$ 的估计方程，该导数通常被称为影响函数。IRLS 是求解该方程的迭代过程。在每一步中，它通过为每个数据点分配一个权重来重新计算其贡献。该权重通常从影响函数导出。权重函数的一个常见定义是 $w(r) = \\psi(r)/r$。具有大残差的数据点会获得较小的权重，从而减少其影响。\n\n**3. 稳健权重的推导**\n\n问题指定权重必须从给定损失函数的导数推导出来。\n\n**Huber 权重：** Huber 损失函数定义为：\n$$\n\\rho_{\\mathrm{Huber}}(r;\\delta) = \\begin{cases}\n\\frac{1}{2} r^2  \\text{if } |r| \\le \\delta \\\\\n\\delta |r| - \\frac{1}{2} \\delta^2  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n其导数，即影响函数 $\\psi_{\\mathrm{Huber}}(r) = \\rho'_{\\mathrm{Huber}}(r)$，是：\n$$\n\\psi_{\\mathrm{Huber}}(r;\\delta) = \\begin{cases}\nr  \\text{if } |r| \\le \\delta \\\\\n\\delta \\cdot \\mathrm{sgn}(r)  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n相应的权重函数 $w(r) = \\psi(r)/r$ 是：\n$$\nw_{\\mathrm{Huber}}(r;\\delta) = \\begin{cases}\n1  \\text{if } |r| \\le \\delta \\\\\n\\delta/|r|  \\text{if } |r|  \\delta\n\\end{cases}\n$$\n这可以紧凑地表示为 $w_{\\mathrm{Huber}}(r;\\delta) = \\min(1, \\delta/|r|)$。对于小残差（在二次区域内），该权重为 1，对于大残差，该权重双曲递减。\n\n**Tukey 双平方权重：** Tukey 双平方（或双权重）损失是：\n$$\n\\rho_{\\mathrm{Tukey}}(r;c) = \\begin{cases}\n\\frac{c^2}{6} \\left[1 - \\left(1 - \\left(\\frac{r}{c}\\right)^2\\right)^3\\right]  \\text{if } |r|  c \\\\\n\\frac{c^2}{6}  \\text{if } |r| \\ge c\n\\end{cases}\n$$\n其导数是：\n$$\n\\psi_{\\mathrm{Tukey}}(r;c) = \\begin{cases}\nr \\left(1 - \\left(\\frac{r}{c}\\right)^2\\right)^2  \\text{if } |r|  c \\\\\n0  \\text{if } |r| \\ge c\n\\end{cases}\n$$\n相应的权重函数 $w(r) = \\psi(r)/r$ 是：\n$$\nw_{\\mathrm{Tukey}}(r;c) = \\begin{cases}\n\\left(1 - \\left(\\frac{r}{c}\\right)^2\\right)^2  \\text{if } |r|  c \\\\\n0  \\text{if } |r| \\ge c\n\\end{cases}\n$$\n这个权重函数比 Huber 的更具侵略性：当 $|r|$ 接近 $c$ 时，它会平滑地减小到 0，并通过分配零权重来完全拒绝任何残差 $|r| \\ge c$ 的观测值。\n\n**4. 迭代重加权群体向量算法**\n\n问题指定了一个特定的迭代算法，该算法将 IRLS 加权方案应用于群体向量解码器。总共进行 $T=3$ 次迭代，执行以下步骤：\n1.  **初始化**：方向的初始估计值 $\\hat{\\theta}^{(0)}$ 从标准（原始）群体向量解码器获得。\n2.  **迭代 ($t=1, 2, 3$)**：\n    a.  **计算残差**：对于每个神经元 $i$，根据前一个估计值 $\\hat{\\theta}^{(t-1)}$ 计算残差：$r_i^{(t-1)} = s_i - f_i(\\hat{\\theta}^{(t-1)})$。\n    b.  **计算权重**：使用应用于其残差 $r_i^{(t-1)}$ 的 Huber 或 Tukey 权重函数，为每个神经元计算稳健权重 $w_i^{(t)}$。\n    c.  **更新估计**：计算一个新的加权群体向量 $\\mathbf{V}^{(t)} = \\sum_{i=1}^{N} w_i^{(t)} s_i \\mathbf{v}_i$。更新后的角度估计值 $\\hat{\\theta}^{(t)}$ 是该向量的角度。\n3.  **最终估计**：经过 $T=3$ 次迭代后的估计值 $\\hat{\\theta}^{(3)}$ 是最终的稳健估计值。\n\n**5. 角度误差计算**\n\n为了比较这三种方法（原始、Huber、Tukey），计算了每种方法的角度误差。误差 $e$ 是估计角度 $\\hat{\\theta}$ 与真实角度 $\\theta_{\\mathrm{true}}$ 之间的绝对差，并环绕到区间 $[-\\pi, \\pi]$ 以找到它们之间的最短角度。\n$$\ne = |\\mathrm{wrap}_{[-\\pi,\\pi]}(\\hat{\\theta} - \\theta_{\\mathrm{true}})|\n$$\n其中环绕函数定义为 $\\mathrm{wrap}_{[-\\pi,\\pi]}(\\alpha) = (\\alpha + \\pi) \\pmod{2\\pi} - \\pi$。所有角度都以弧度处理。\n\n该实现将系统地将这整个过程应用于四个测试案例中的每一个，计算带有离群值的脉冲计数，运行三种解码器算法，并计算最终的角度误差进行比较。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the population vector decoding problem with robust methods.\n\n    This function implements and compares three decoders:\n    1. Raw Population Vector (PV)\n    2. Robust PV with Iteratively Reweighted Least Squares (IRLS) using Huber loss.\n    3. Robust PV with IRLS using Tukey bisquare loss.\n\n    It processes a suite of four test cases, computes the angular error for each\n    decoder in each case, and formats the results as a single string.\n    \"\"\"\n\n    def wrap_angle(angle_rad):\n        \"\"\"Wraps an angle in radians to the interval [-pi, pi].\"\"\"\n        return (angle_rad + np.pi) % (2 * np.pi) - np.pi\n\n    # Shared parameters for all test cases\n    N = 8\n    phi = np.arange(N) * np.pi / 4  # Preferred direction angles\n    v_pref = np.stack([np.cos(phi), np.sin(phi)], axis=1)  # Preferred direction vectors\n    T_iterations = 3\n\n    # Define the test suite\n    test_cases = [\n        {\n            \"theta_true\": 0.7,\n            \"b\": [20, 20, 20, 20, 20, 20, 20, 20],\n            \"k\": [8, 12, 15, 9, 11, 10, 13, 7],\n            \"outliers\": {2: 50, 6: 50},  # 1-based index: value to add\n            \"delta\": 10,\n            \"c\": 20,\n        },\n        {\n            \"theta_true\": 3.5,\n            \"b\": [22, 21, 23, 22, 22, 21, 23, 22],\n            \"k\": [14, 12, 13, 15, 14, 12, 13, 11],\n            \"outliers\": {1: 100, 5: 100},\n            \"delta\": 7,\n            \"c\": 15,\n        },\n        {\n            \"theta_true\": np.pi / 2,\n            \"b\": [18, 18, 18, 18, 18, 18, 18, 18],\n            \"k\": [6, 6, 6, 6, 6, 6, 6, 6],\n            \"outliers\": {},\n            \"delta\": 5,\n            \"c\": 10,\n        },\n        {\n            \"theta_true\": 5.5,\n            \"b\": [20, 20, 20, 20, 20, 20, 20, 20],\n            \"k\": [0, 15, 0, 15, 0, 15, 0, 0],\n            \"outliers\": {2: -15},\n            \"delta\": 4,\n            \"c\": 8,\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        theta_true = case[\"theta_true\"]\n        b = np.array(case[\"b\"])\n        k = np.array(case[\"k\"])\n        delta_huber = case[\"delta\"]\n        c_tukey = case[\"c\"]\n\n        # Step 1: Generate spike counts with outliers\n        f_i = b + k * np.cos(theta_true - phi)\n        s = np.round(f_i)\n        \n        for idx, val in case[\"outliers\"].items():\n            s[idx - 1] += val  # Convert 1-based index to 0-based\n        \n        s = np.maximum(0, s) # Ensure non-negative spike counts\n\n        # Step 2: Raw Population Vector Decoder\n        V_raw = np.sum(s[:, np.newaxis] * v_pref, axis=0)\n        theta_raw = np.arctan2(V_raw[1], V_raw[0])\n        e_raw = np.abs(wrap_angle(theta_raw - theta_true))\n\n        # Step 3: Huber IRLS Decoder\n        theta_est = theta_raw\n        for _ in range(T_iterations):\n            residuals = s - (b + k * np.cos(theta_est - phi))\n            weights = np.ones_like(residuals, dtype=float)\n            mask = np.abs(residuals) > delta_huber\n            # Only update weights for residuals outside the delta threshold\n            if np.any(mask):\n                weights[mask] = delta_huber / np.abs(residuals[mask])\n            \n            weighted_s = weights * s\n            V_huber = np.sum(weighted_s[:, np.newaxis] * v_pref, axis=0)\n            theta_est = np.arctan2(V_huber[1], V_huber[0])\n        \n        theta_huber = theta_est\n        e_huber = np.abs(wrap_angle(theta_huber - theta_true))\n\n        # Step 4: Tukey IRLS Decoder\n        theta_est = theta_raw\n        for _ in range(T_iterations):\n            residuals = s - (b + k * np.cos(theta_est - phi))\n            weights = np.zeros_like(residuals, dtype=float)\n            mask = np.abs(residuals)  c_tukey\n            \n            # calculate weights only for residuals inside the c threshold\n            if np.any(mask):\n                ratio_sq = (residuals[mask] / c_tukey)**2\n                weights[mask] = (1 - ratio_sq)**2\n            \n            weighted_s = weights * s\n            V_tukey = np.sum(weighted_s[:, np.newaxis] * v_pref, axis=0)\n            \n            # np.arctan2(0, 0) is 0.0, handling the case of a zero vector gracefully.\n            theta_est = np.arctan2(V_tukey[1], V_tukey[0])\n\n        theta_tukey = theta_est\n        e_tukey = np.abs(wrap_angle(theta_tukey - theta_true))\n\n        all_results.append([e_raw, e_huber, e_tukey])\n    \n    # Step 5: Format the final output string\n    outer_parts = []\n    for res_list in all_results:\n        inner_parts = [f\"{val:.6f}\" for val in res_list]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    final_output = f\"[{','.join(outer_parts)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}