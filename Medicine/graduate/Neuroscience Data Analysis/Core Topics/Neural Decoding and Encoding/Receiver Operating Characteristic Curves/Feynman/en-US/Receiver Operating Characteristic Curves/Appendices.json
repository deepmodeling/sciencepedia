{
    "hands_on_practices": [
        {
            "introduction": "A central task in evaluating a classifier is choosing an optimal decision threshold. This practice provides a foundational approach to this problem by introducing Youden's index, $J = \\mathrm{TPR} - \\mathrm{FPR}$, an intuitive metric that seeks to maximize the vertical distance between the ROC curve and the line of no-discrimination. By working through this exercise , you will derive the optimal threshold under a common generative model of Gaussian-distributed signal and noise, gaining insight into how classifier performance can be analytically optimized under a simple, cost-agnostic criterion.",
            "id": "4189213",
            "problem": "A single-channel extracellular recording from a cortical neuron is analyzed with a simple thresholding detector on a scalar detection statistic $A$ (the peak-to-peak amplitude of a bandpass-filtered snippet). In a time bin, the detector declares a spike whenever $A \\geq \\tau$ for some threshold $\\tau$. Assume a generative model in which the class-conditional distributions of $A$ are Gaussian with equal variance: under noise (no spike), $A \\mid \\text{noise} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$, and under spike, $A \\mid \\text{spike} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$. In this recording, empirical calibration gives $\\mu_{0} = 0$ microvolts, $\\mu_{1} = 60$ microvolts, and $\\sigma = 20$ microvolts.\n\nUsing only the core definitions of the Receiver Operating Characteristic (ROC) in terms of the true positive rate and false positive rate, and the definition of Youden’s index $J(\\tau)$ as the difference between sensitivity (true positive rate) and fall-out (false positive rate), do the following:\n\n1. Derive an expression for $J(\\tau)$ in terms of the standard normal cumulative distribution function starting from $J(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau)$ and the class-conditional Gaussian models above.\n2. From first principles, determine the threshold $\\tau^{\\star}$ that maximizes $J(\\tau)$ and evaluate $J(\\tau^{\\star})$.\n3. Briefly justify, from a decision-theoretic perspective, when maximizing Youden’s index is suitable versus unsuitable in the presence of symmetric versus asymmetric misclassification costs and class imbalance.\n\nReport the numerical values of the optimal threshold and the maximized Youden’s index using the given parameters. Express the threshold in microvolts. Round both the threshold and the maximized Youden’s index to four significant figures. The final answer should contain only the numerical values (with no units) in the order $\\tau^{\\star}, J(\\tau^{\\star})$.",
            "solution": "The problem statement is first subjected to validation.\n\n### Step 1: Extract Givens\n-   The detection statistic is a scalar $A$.\n-   A spike is declared if the detection statistic $A$ is greater than or equal to a threshold $\\tau$, i.e., $A \\geq \\tau$.\n-   The class-conditional probability distribution for $A$ given noise is $A \\mid \\text{noise} \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$.\n-   The class-conditional probability distribution for $A$ given a spike is $A \\mid \\text{spike} \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$.\n-   The parameters are given as $\\mu_{0} = 0$ microvolts, $\\mu_{1} = 60$ microvolts, and $\\sigma = 20$ microvolts.\n-   Youden's index is defined as $J(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau)$, where TPR is the true positive rate and FPR is the false positive rate.\n-   The tasks are to:\n    1.  Derive an expression for $J(\\tau)$ in terms of the standard normal cumulative distribution function (CDF).\n    2.  Find the optimal threshold $\\tau^{\\star}$ that maximizes $J(\\tau)$ and evaluate the maximum value $J(\\tau^{\\star})$.\n    3.  Provide a decision-theoretic justification for the suitability of maximizing Youden's index.\n    4.  Report the numerical values of $\\tau^{\\star}$ (in microvolts) and $J(\\tau^{\\star})$, rounded to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem is well-grounded in statistical decision theory and its application to spike detection in neuroscience, which is a standard topic in computational neuroscience. The use of a Gaussian model for signal amplitudes is a common and valid simplifying assumption.\n-   **Well-Posed**: The problem is well-posed. All necessary parameters and definitions ($\\mathcal{N}(\\mu_{0}, \\sigma^{2})$, $\\mathcal{N}(\\mu_{1}, \\sigma^{2})$, $J(\\tau)$) are provided to derive and optimize the objective function. The function to be optimized is well-behaved, ensuring a unique maximum exists.\n-   **Objective**: The problem is stated in precise, objective, and quantitative terms.\n-   **Incomplete or Contradictory Setup**: The problem is self-contained and consistent. No essential information is missing, and no contradictions are present.\n-   **Unrealistic or Infeasible**: The parameter values ($\\mu_0 = 0$, $\\mu_1 = 60$, $\\sigma = 20$) are physically realistic for extracellular neural recordings.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n***\n\n### 1. Derivation of Youden's Index $J(\\tau)$\nYouden's index is defined as $J(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau)$. We must first derive expressions for the True Positive Rate (TPR) and False Positive Rate (FPR) as functions of the threshold $\\tau$.\n\nThe True Positive Rate, or sensitivity, is the probability of correctly detecting a spike when one is present. This corresponds to the event $A \\geq \\tau$ given the \"spike\" condition.\n$$\n\\text{TPR}(\\tau) = P(A \\geq \\tau \\mid \\text{spike})\n$$\nThe random variable $A$ under the \"spike\" condition follows the distribution $\\mathcal{N}(\\mu_{1}, \\sigma^{2})$. To calculate this probability, we standardize the variable by defining $Z = \\frac{A - \\mu_{1}}{\\sigma}$, where $Z \\sim \\mathcal{N}(0, 1)$.\nThe inequality $A \\geq \\tau$ is equivalent to $\\frac{A - \\mu_{1}}{\\sigma} \\geq \\frac{\\tau - \\mu_{1}}{\\sigma}$.\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z) = P(Z \\leq z)$. Then,\n$$\n\\text{TPR}(\\tau) = P\\left(Z \\geq \\frac{\\tau - \\mu_{1}}{\\sigma}\\right) = 1 - P\\left(Z < \\frac{\\tau - \\mu_{1}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)\n$$\n\nThe False Positive Rate, or fall-out, is the probability of incorrectly declaring a spike when only noise is present. This corresponds to the event $A \\geq \\tau$ given the \"noise\" condition.\n$$\n\\text{FPR}(\\tau) = P(A \\geq \\tau \\mid \\text{noise})\n$$\nThe random variable $A$ under the \"noise\" condition follows the distribution $\\mathcal{N}(\\mu_{0}, \\sigma^{2})$. We standardize the variable by defining $Z = \\frac{A - \\mu_{0}}{\\sigma}$, where $Z \\sim \\mathcal{N}(0, 1)$.\nThe inequality $A \\geq \\tau$ is equivalent to $\\frac{A - \\mu_{0}}{\\sigma} \\geq \\frac{\\tau - \\mu_{0}}{\\sigma}$.\n$$\n\\text{FPR}(\\tau) = P\\left(Z \\geq \\frac{\\tau - \\mu_{0}}{\\sigma}\\right) = 1 - P\\left(Z < \\frac{\\tau - \\mu_{0}}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)\n$$\n\nNow, we substitute these expressions into the definition of $J(\\tau)$:\n$$\nJ(\\tau) = \\text{TPR}(\\tau) - \\text{FPR}(\\tau) = \\left[1 - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)\\right] - \\left[1 - \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right)\\right]\n$$\n$$\nJ(\\tau) = \\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right) - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)\n$$\nThis is the desired expression for $J(\\tau)$ in terms of the standard normal CDF.\n\n### 2. Maximization of Youden's Index\nTo find the threshold $\\tau^{\\star}$ that maximizes $J(\\tau)$, we compute the derivative of $J(\\tau)$ with respect to $\\tau$ and set it to zero. Let $\\phi(z) = \\frac{d\\Phi(z)}{dz} = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{z^2}{2}\\right)$ be the probability density function (PDF) of the standard normal distribution. Using the chain rule:\n$$\n\\frac{dJ}{d\\tau} = \\frac{d}{d\\tau}\\left[\\Phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right) - \\Phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right)\\right] = \\phi\\left(\\frac{\\tau - \\mu_{0}}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma} - \\phi\\left(\\frac{\\tau - \\mu_{1}}{\\sigma}\\right) \\cdot \\frac{1}{\\sigma}\n$$\nSetting the derivative to zero to find the optimal threshold $\\tau^{\\star}$:\n$$\n\\frac{1}{\\sigma} \\left[ \\phi\\left(\\frac{\\tau^{\\star} - \\mu_{0}}{\\sigma}\\right) - \\phi\\left(\\frac{\\tau^{\\star} - \\mu_{1}}{\\sigma}\\right) \\right] = 0\n$$\n$$\n\\phi\\left(\\frac{\\tau^{\\star} - \\mu_{0}}{\\sigma}\\right) = \\phi\\left(\\frac{\\tau^{\\star} - \\mu_{1}}{\\sigma}\\right)\n$$\nSubstituting the expression for $\\phi(z)$:\n$$\n\\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{\\tau^{\\star} - \\mu_{0}}{\\sigma}\\right)^2\\right) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{1}{2}\\left(\\frac{\\tau^{\\star} - \\mu_{1}}{\\sigma}\\right)^2\\right)\n$$\nTaking the natural logarithm of both sides and simplifying:\n$$\n\\left(\\frac{\\tau^{\\star} - \\mu_{0}}{\\sigma}\\right)^2 = \\left(\\frac{\\tau^{\\star} - \\mu_{1}}{\\sigma}\\right)^2 \\implies (\\tau^{\\star} - \\mu_{0})^2 = (\\tau^{\\star} - \\mu_{1})^2\n$$\nThis equation yields two possibilities:\n1. $\\tau^{\\star} - \\mu_{0} = \\tau^{\\star} - \\mu_{1}$, which implies $\\mu_{0} = \\mu_{1}$. This is false, as the means are distinct.\n2. $\\tau^{\\star} - \\mu_{0} = -(\\tau^{\\star} - \\mu_{1}) = \\mu_{1} - \\tau^{\\star}$.\nSolving the second case for $\\tau^{\\star}$:\n$$\n2\\tau^{\\star} = \\mu_{0} + \\mu_{1} \\implies \\tau^{\\star} = \\frac{\\mu_{0} + \\mu_{1}}{2}\n$$\nThis value corresponds to the point where the two class-conditional PDFs, $p(A|\\text{noise})$ and $p(A|\\text{spike})$, intersect. To confirm this is a maximum, the second derivative test can be applied, and it would show $\\frac{d^2J}{d\\tau^2} < 0$ at this point, given $\\mu_1 > \\mu_0$.\n\nNow we evaluate $J(\\tau^{\\star})$ by substituting $\\tau^{\\star}$ back into the expression for $J(\\tau)$:\n$$\nJ(\\tau^{\\star}) = \\Phi\\left(\\frac{\\frac{\\mu_{0} + \\mu_{1}}{2} - \\mu_{0}}{\\sigma}\\right) - \\Phi\\left(\\frac{\\frac{\\mu_{0} + \\mu_{1}}{2} - \\mu_{1}}{\\sigma}\\right)\n$$\n$$\nJ(\\tau^{\\star}) = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{2\\sigma}\\right) - \\Phi\\left(\\frac{\\mu_{0} - \\mu_{1}}{2\\sigma}\\right)\n$$\nUsing the symmetry property of the normal CDF, $\\Phi(-z) = 1 - \\Phi(z)$:\n$$\nJ(\\tau^{\\star}) = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{2\\sigma}\\right) - \\left[1 - \\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{2\\sigma}\\right)\\right] = 2\\Phi\\left(\\frac{\\mu_{1} - \\mu_{0}}{2\\sigma}\\right) - 1\n$$\n\n### 3. Decision-Theoretic Justification\nMaximizing Youden's index, $J = \\text{TPR} - \\text{FPR}$, is geometrically equivalent to finding the point on the ROC curve with the greatest vertical distance from the chance line ($y=x$). This criterion equally weights the benefit of increasing TPR and the cost of increasing FPR.\n\nThis strategy is **suitable** under specific decision-theoretic assumptions:\n1.  **Symmetric Misclassification Costs**: The cost of a false negative, $C_{FN}$ (missing a real spike), is equal to the cost of a false positive, $C_{FP}$ (detecting a non-existent spike).\n2.  **Equal Class Priors**: The prior probabilities of a spike, $P(\\text{spike})$, and noise, $P(\\text{noise})$, are equal, i.e., $P(\\text{spike}) = P(\\text{noise}) = 0.5$.\nUnder these two conditions, maximizing $J$ is equivalent to minimizing the total probability of classification error, $P(\\text{error}) = P(\\text{spike}) (1 - \\text{TPR}) + P(\\text{noise}) \\text{FPR}$, and thus maximizing the overall accuracy.\n\nThis strategy is **unsuitable** when these assumptions are violated:\n1.  **Asymmetric Misclassification Costs**: If, for instance, missing a spike is far more deleterious than a false alarm ($C_{FN} \\gg C_{FP}$), one should choose a lower threshold to increase TPR, even at the expense of a higher FPR. An example is the detection of an epileptic seizure onset, where a missed event is critical. The optimal threshold would shift to prioritize sensitivity.\n2.  **Class Imbalance**: In most neuroscience applications, spikes are rare events, meaning $P(\\text{spike}) \\ll P(\\text{noise})$. In this scenario, even a low FPR can result in a large absolute number of false positives, potentially overwhelming the true positives. The optimal strategy would be to choose a higher threshold to enforce a very low FPR, thus increasing the precision of the detector.\n\nIn general, the optimal threshold is determined by the likelihood ratio test, which compares the likelihood ratio $\\frac{p(A|\\text{spike})}{p(A|\\text{noise})}$ to a cost- and prior-dependent term $\\frac{C_{FP} P(\\text{noise})}{C_{FN} P(\\text{spike})}$. Maximizing Youden's index implicitly sets this term to $1$.\n\n### 4. Numerical Calculation\nUsing the given parameters: $\\mu_{0} = 0$, $\\mu_{1} = 60$, and $\\sigma = 20$.\n\nThe optimal threshold $\\tau^{\\star}$ is:\n$$\n\\tau^{\\star} = \\frac{0 + 60}{2} = 30\n$$\nSince the parameters are in microvolts, $\\tau^{\\star} = 30$ microvolts.\n\nThe maximum Youden's index $J(\\tau^{\\star})$ is:\n$$\nJ(30) = 2\\Phi\\left(\\frac{60 - 0}{2 \\cdot 20}\\right) - 1 = 2\\Phi\\left(\\frac{60}{40}\\right) - 1 = 2\\Phi(1.5) - 1\n$$\nFrom standard statistical tables or computation, the value of the standard normal CDF at $z=1.5$ is $\\Phi(1.5) \\approx 0.9331928...$.\n$$\nJ(30) \\approx 2 \\times 0.9331928 - 1 = 1.8663856 - 1 = 0.8663856\n$$\nRounding the results to four significant figures:\n-   $\\tau^{\\star} = 30.00$\n-   $J(\\tau^{\\star}) = 0.8664$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 30.00 & 0.8664 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "While Youden's index provides a straightforward optimization target, it implicitly assumes that the costs of different errors are equal and that positive and negative classes are equally prevalent. In many neuroscience applications, such as detecting rare neural events or avoiding critical failures, these assumptions are invalid. This practice  introduces a more powerful and realistic framework from Bayesian decision theory, where you will derive the optimal threshold that minimizes expected misclassification cost by explicitly accounting for asymmetric costs ($C_{FP}$, $C_{FN}$) and class prevalence ($\\pi$). This exercise connects the analytical solution to a geometric interpretation on the ROC curve, providing a robust method for tailoring decision rules to specific experimental contexts.",
            "id": "4189176",
            "problem": "A cortical decoder produces a continuous neurometric score $S$ intended to indicate whether a transient somatosensory stimulus is present ($Y=1$) or absent ($Y=0$). In a particular experimental condition, the conditional distributions of $S$ are well described by Gaussian densities with equal variance: when $Y=1$, $S \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$; when $Y=0$, $S \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$. A threshold rule declares the stimulus present if $S \\geq \\tau$ and absent otherwise. Let the prevalence of stimulus-present trials be $\\pi = \\mathbb{P}(Y=1)$, with $\\mathbb{P}(Y=0)=1-\\pi$. Let $C_{FP}$ denote the cost of a false positive (declaring present when absent) and $C_{FN}$ denote the cost of a false negative (declaring absent when present). The receiver operating characteristic (ROC) curve is the set of achievable pairs of true positive rate (TPR) and false positive rate (FPR) indexed by the threshold $\\tau$, where $\\mathrm{TPR}(\\tau) = \\mathbb{P}(S \\geq \\tau \\mid Y=1)$ and $\\mathrm{FPR}(\\tau) = \\mathbb{P}(S \\geq \\tau \\mid Y=0)$.\n\nStarting only from the definitions of expected misclassification cost, Gaussian densities, and the ROC as a parametric curve in the threshold, derive the Bayes-optimal threshold $\\tau^{\\star}$ that minimizes the expected misclassification cost. Then, using the parametric representation of the ROC by $\\tau$, show how the slope of the ROC at the optimal operating point relates to the tangent condition implied by cost minimization.\n\nFinally, compute the optimal threshold for the following experimentally measured parameter values: $\\mu_{0} = -0.2$, $\\mu_{1} = 1.0$, $\\sigma = 0.5$, $C_{FP} = 2$, $C_{FN} = 4$, and $\\pi = 0.4$. Round your numerical answer for $\\tau^{\\star}$ to four significant figures.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Neurometric score: $S$.\n- Stimulus state: $Y=1$ (present), $Y=0$ (absent).\n- Conditional distribution for stimulus present ($Y=1$): $S \\sim \\mathcal{N}(\\mu_{1}, \\sigma^{2})$.\n- Conditional distribution for stimulus absent ($Y=0$): $S \\sim \\mathcal{N}(\\mu_{0}, \\sigma^{2})$.\n- Decision rule: Stimulus is declared present if $S \\geq \\tau$, absent if $S < \\tau$.\n- Prevalence of stimulus-present trials: $\\pi = \\mathbb{P}(Y=1)$, $\\mathbb{P}(Y=0)=1-\\pi$.\n- Cost of a false positive: $C_{FP}$.\n- Cost of a false negative: $C_{FN}$.\n- True Positive Rate: $\\mathrm{TPR}(\\tau) = \\mathbb{P}(S \\geq \\tau \\mid Y=1)$.\n- False Positive Rate: $\\mathrm{FPR}(\\tau) = \\mathbb{P}(S \\geq \\tau \\mid Y=0)$.\n- Task 1: Derive the Bayes-optimal threshold $\\tau^{\\star}$ that minimizes the expected misclassification cost.\n- Task 2: Relate the slope of the ROC curve at $\\tau^{\\star}$ to the tangent condition from cost minimization.\n- Task 3: Compute $\\tau^{\\star}$ for the parameters: $\\mu_{0} = -0.2$, $\\mu_{1} = 1.0$, $\\sigma = 0.5$, $C_{FP} = 2$, $C_{FN} = 4$, $\\pi = 0.4$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, using standard principles of signal detection theory and Bayesian decision theory, which are central to neuroscience data analysis. The use of Gaussian distributions to model neural responses is a common and valid simplification. The problem is well-posed, providing all necessary parameters ($\\mu_0, \\mu_1, \\sigma, C_{FP}, C_{FN}, \\pi$) and a clear objective (minimize expected cost). The terminology is precise and objective. The problem is self-contained, consistent, and does not violate any scientific or mathematical principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. We proceed with the solution.\n\n### Part 1: Derivation of the Bayes-Optimal Threshold $\\tau^{\\star}$\n\nThe expected misclassification cost, $C(\\tau)$, is the sum of the expected costs of false positives and false negatives. A false positive occurs when $Y=0$ but the decision is $1$ (i.e., $S \\geq \\tau$). A false negative occurs when $Y=1$ but the decision is $0$ (i.e., $S < \\tau$).\n\nThe expected cost is given by:\n$$\nC(\\tau) = C_{FP} \\cdot \\mathbb{P}(\\text{decision}=1, Y=0) + C_{FN} \\cdot \\mathbb{P}(\\text{decision}=0, Y=1)\n$$\nUsing the law of total probability and the decision rule:\n$$\nC(\\tau) = C_{FP} \\cdot \\mathbb{P}(S \\geq \\tau \\mid Y=0) \\mathbb{P}(Y=0) + C_{FN} \\cdot \\mathbb{P}(S < \\tau \\mid Y=1) \\mathbb{P}(Y=1)\n$$\nLet $p(s|Y=i)$ denote the probability density function (PDF) for the score $S$ given the state $Y=i$. For $i \\in \\{0, 1\\}$, this is the Gaussian PDF: $p(s|Y=i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(s-\\mu_i)^2}{2\\sigma^2}\\right)$.\nThe cost function can be written in integral form:\n$$\nC(\\tau) = C_{FP} (1-\\pi) \\int_{\\tau}^{\\infty} p(s|Y=0) \\,ds + C_{FN} \\pi \\int_{-\\infty}^{\\tau} p(s|Y=1) \\,ds\n$$\nTo find the threshold $\\tau^{\\star}$ that minimizes $C(\\tau)$, we differentiate $C(\\tau)$ with respect to $\\tau$ and set the result to zero. Using the Leibniz integral rule ($\\frac{d}{dx} \\int_{a(x)}^{b(x)} f(t) dt = f(b(x))b'(x) - f(a(x))a'(x)$), we find:\n$$\n\\frac{dC(\\tau)}{d\\tau} = C_{FP} (1-\\pi) [-p(\\tau|Y=0)] + C_{FN} \\pi [p(\\tau|Y=1)]\n$$\nSetting the derivative to zero for the optimal threshold $\\tau^{\\star}$:\n$$\nC_{FN} \\pi p(\\tau^{\\star}|Y=1) = C_{FP} (1-\\pi) p(\\tau^{\\star}|Y=0)\n$$\nThis can be rearranged into a likelihood ratio condition:\n$$\n\\frac{p(\\tau^{\\star}|Y=1)}{p(\\tau^{\\star}|Y=0)} = \\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\n$$\nNow, we substitute the Gaussian PDFs into this equation. The constant term $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$ cancels out:\n$$\n\\frac{\\exp\\left(-\\frac{(\\tau^{\\star}-\\mu_1)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(\\tau^{\\star}-\\mu_0)^2}{2\\sigma^2}\\right)} = \\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\n$$\n$$\n\\exp\\left(\\frac{(\\tau^{\\star}-\\mu_0)^2 - (\\tau^{\\star}-\\mu_1)^2}{2\\sigma^2}\\right) = \\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\n$$\nTaking the natural logarithm of both sides:\n$$\n\\frac{(\\tau^{\\star}-\\mu_0)^2 - (\\tau^{\\star}-\\mu_1)^2}{2\\sigma^2} = \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\nExpanding the squared terms in the numerator:\n$$\n(\\tau^{\\star2} - 2\\tau^{\\star}\\mu_0 + \\mu_0^2) - (\\tau^{\\star2} - 2\\tau^{\\star}\\mu_1 + \\mu_1^2) = 2\\tau^{\\star}(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2)\n$$\nSubstituting this back and solving for $\\tau^{\\star}$:\n$$\n2\\tau^{\\star}(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2) = 2\\sigma^2 \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\n$$\n2\\tau^{\\star}(\\mu_1 - \\mu_0) = \\mu_1^2 - \\mu_0^2 + 2\\sigma^2 \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\n$$\n2\\tau^{\\star}(\\mu_1 - \\mu_0) = (\\mu_1 - \\mu_0)(\\mu_1 + \\mu_0) + 2\\sigma^2 \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\nAssuming $\\mu_1 \\neq \\mu_0$, we divide by $2(\\mu_1 - \\mu_0)$:\n$$\n\\tau^{\\star} = \\frac{\\mu_1+\\mu_0}{2} + \\frac{\\sigma^2}{\\mu_1-\\mu_0} \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\n\n### Part 2: ROC Slope and Tangent Condition\n\nThe ROC curve is a parametric plot of $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$. The slope of the ROC curve at a point corresponding to a threshold $\\tau$ is $\\frac{d(\\mathrm{TPR})}{d(\\mathrm{FPR})}$. Using the chain rule, this is $\\frac{d(\\mathrm{TPR})/d\\tau}{d(\\mathrm{FPR})/d\\tau}$.\n\nFirst, we find the derivatives of TPR and FPR with respect to $\\tau$:\n$$\n\\mathrm{TPR}(\\tau) = \\int_{\\tau}^{\\infty} p(s|Y=1) \\,ds \\implies \\frac{d(\\mathrm{TPR})}{d\\tau} = -p(\\tau|Y=1)\n$$\n$$\n\\mathrm{FPR}(\\tau) = \\int_{\\tau}^{\\infty} p(s|Y=0) \\,ds \\implies \\frac{d(\\mathrm{FPR})}{d\\tau} = -p(\\tau|Y=0)\n$$\nThe slope of the ROC curve is therefore:\n$$\n\\frac{d(\\mathrm{TPR})}{d(\\mathrm{FPR})} = \\frac{-p(\\tau|Y=1)}{-p(\\tau|Y=0)} = \\frac{p(\\tau|Y=1)}{p(\\tau|Y=0)}\n$$\nThis is the likelihood ratio at the score value $\\tau$.\n\nNow consider the tangent condition from cost minimization. The total cost is $C(\\tau) = C_{FP}(1-\\pi)\\mathrm{FPR}(\\tau) + C_{FN}\\pi(1-\\mathrm{TPR}(\\tau))$.\nLines of constant expected cost (iso-cost lines) in the ROC space (with axes FPR, TPR) are defined by:\n$$\nC_{\\text{const}} = C_{FP}(1-\\pi)\\mathrm{FPR} + C_{FN}\\pi(1-\\mathrm{TPR})\n$$\nRearranging to express TPR as a function of FPR (like $y=mx+b$):\n$$\nC_{FN}\\pi\\mathrm{TPR} = C_{FP}(1-\\pi)\\mathrm{FPR} + C_{FN}\\pi - C_{\\text{const}}\n$$\n$$\n\\mathrm{TPR} = \\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\\mathrm{FPR} + \\left(1 - \\frac{C_{\\text{const}}}{C_{FN}\\pi}\\right)\n$$\nThe slope of these iso-cost lines is constant and equal to $M = \\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}$.\nMinimizing the expected cost corresponds to finding the point on the convex ROC curve that is tangent to an iso-cost line. At this optimal operating point, the slope of the ROC curve must equal the slope of the iso-cost line.\nTherefore, at the optimal threshold $\\tau^{\\star}$:\n$$\n\\text{Slope of ROC at } \\tau^{\\star} = \\text{Slope of iso-cost line}\n$$\n$$\n\\frac{p(\\tau^{\\star}|Y=1)}{p(\\tau^{\\star}|Y=0)} = \\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\n$$\nThis is precisely the same optimality condition derived by direct differentiation of the cost function $C(\\tau)$. This confirms the geometric interpretation that the Bayes-optimal operating point lies at the tangency point between the ROC curve and the line representing the trade-off between costs and prevalences.\n\n### Part 3: Numerical Calculation of $\\tau^{\\star}$\n\nWe are given the parameters:\n$\\mu_{0} = -0.2$, $\\mu_{1} = 1.0$, $\\sigma = 0.5$, $C_{FP} = 2$, $C_{FN} = 4$, $\\pi = 0.4$.\nFrom these, we derive:\n$\\sigma^2 = (0.5)^2 = 0.25$\n$1-\\pi = 1 - 0.4 = 0.6$\n\nWe use the derived formula for $\\tau^{\\star}$:\n$$\n\\tau^{\\star} = \\frac{\\mu_1+\\mu_0}{2} + \\frac{\\sigma^2}{\\mu_1-\\mu_0} \\ln\\left(\\frac{C_{FP}(1-\\pi)}{C_{FN}\\pi}\\right)\n$$\nSubstitute the values:\n$$\n\\tau^{\\star} = \\frac{1.0 + (-0.2)}{2} + \\frac{0.25}{1.0 - (-0.2)} \\ln\\left(\\frac{2 \\times 0.6}{4 \\times 0.4}\\right)\n$$\n$$\n\\tau^{\\star} = \\frac{0.8}{2} + \\frac{0.25}{1.2} \\ln\\left(\\frac{1.2}{1.6}\\right)\n$$\n$$\n\\tau^{\\star} = 0.4 + \\frac{0.25}{1.2} \\ln(0.75)\n$$\nNow, we compute the numerical values:\n$$\n\\frac{0.25}{1.2} = \\frac{1/4}{6/5} = \\frac{5}{24} \\approx 0.208333...\n$$\n$$\n\\ln(0.75) \\approx -0.287682\n$$\n$$\n\\tau^{\\star} \\approx 0.4 + (0.208333...) \\times (-0.287682)\n$$\n$$\n\\tau^{\\star} \\approx 0.4 - 0.05993375\n$$\n$$\n\\tau^{\\star} \\approx 0.34006625\n$$\nRounding to four significant figures, the optimal threshold is $0.3401$.",
            "answer": "$$\n\\boxed{0.3401}\n$$"
        },
        {
            "introduction": "Moving from theoretical models to empirical data is a crucial step in data analysis. This hands-on coding challenge  tasks you with implementing a complete ROC analysis pipeline from first principles, using deconvolved calcium imaging scores and ground-truth labels as a practical example. You will learn to construct an ROC curve from discrete data points, correctly handling score ties, and to compute the partial Area Under the Curve (pAUC) within a specified low false-positive rate budget—a critical metric for applications where false alarms are highly undesirable. This exercise bridges the gap between theory and implementation, equipping you with the skills to evaluate and compare classifiers on your own experimental data.",
            "id": "4189171",
            "problem": "You are given deconvolved calcium imaging activity scores aligned to electrophysiology ground-truth binary labels across time bins. For each time bin index $i$ in a dataset of $n$ bins, let $s_i \\in \\mathbb{R}$ denote the deconvolved score and $y_i \\in \\{0,1\\}$ denote the ground-truth label, where $y_i = 1$ indicates that an electrophysiology-confirmed event (spike) occurred in bin $i$. An event detector declares a positive detection at threshold $\\tau \\in \\mathbb{R}$ if $s_i \\ge \\tau$ and declares a negative detection otherwise. From first principles, define and use the following:\n\n- True Positive (TP), False Positive (FP), True Negative (TN), and False Negative (FN) counts at threshold $\\tau$ are functions of the predictions relative to $y_i$.\n- True Positive Rate (TPR) is $ \\mathrm{TPR}(\\tau) = \\dfrac{\\mathrm{TP}(\\tau)}{P} $ where $P = \\sum_{i=1}^{n} y_i$ is the total number of positives.\n- False Positive Rate (FPR) is $ \\mathrm{FPR}(\\tau) = \\dfrac{\\mathrm{FP}(\\tau)}{N} $ where $N = \\sum_{i=1}^{n} (1 - y_i)$ is the total number of negatives.\n- The Receiver Operating Characteristic (ROC) curve is the set of points $\\{(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau)) : \\tau \\in \\mathbb{R}\\}$ traced by varying the threshold $\\tau$ from $+\\infty$ to $-\\infty$, evaluated only at thresholds that change the prediction, which for finite data are the unique score values.\n- For a given false positive budget $ \\alpha \\in [0,1] $, the partial Area Under the Curve (partial AUC) is the integral $$ \\mathrm{pAUC}(\\alpha) = \\int_{0}^{\\alpha} \\mathrm{TPR}(\\mathrm{FPR}) \\, d(\\mathrm{FPR}) $$ computed along the ROC curve using piecewise linear interpolation between consecutive ROC points. The normalized partial AUC is defined as $$ \\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha) = \\begin{cases}\\dfrac{\\mathrm{pAUC}(\\alpha)}{\\alpha}, & \\alpha > 0, \\\\ 0, & \\alpha = 0.\\end{cases} $$\n\nYour task is to implement a complete, runnable program that, for each test case provided below, constructs the ROC curve from the scores and labels using the above fundamental definitions, computes the partial AUC up to the specified low false positive rate constraint $\\alpha$, and returns the normalized partial AUC value as a decimal. You must compute the ROC curve by sorting the unique score thresholds in descending order, grouping ties, and using exact counts to produce monotone $\\mathrm{FPR}$ and $\\mathrm{TPR}$ sequences, then integrate using the trapezoidal rule on the piecewise linear ROC segments up to $ \\alpha $.\n\nUse the following test suite. Each test case is a triple $(\\mathbf{s}, \\mathbf{y}, \\alpha)$ where $\\mathbf{s}$ is the list of scores, $\\mathbf{y}$ is the list of labels aligned to $\\mathbf{s}$, and $\\alpha$ is the maximum false positive rate. All quantities are dimensionless and must be expressed as decimals (not percentages).\n\n- Case $1$ (happy path, moderate overlap, balanced-ish):\n  - $\\mathbf{s} = [\\, 0.88, 0.82, 0.79, 0.75, 0.71, 0.64, 0.58, 0.54, 0.66, 0.60, 0.59, 0.57, 0.52, 0.50, 0.46, 0.43, 0.38, 0.34, 0.29, 0.22 \\,]$\n  - $\\mathbf{y} = [\\, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 \\,]$\n  - $\\alpha = 0.10$\n- Case $2$ (all scores identical, random-like classifier behavior):\n  - $\\mathbf{s} = [\\, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50 \\,]$\n  - $\\mathbf{y} = [\\, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0 \\,]$\n  - $\\alpha = 0.20$\n- Case $3$ (highly imbalanced negatives, extremely low false positive budget):\n  - $\\mathbf{s} = [\\, 0.90, 0.87, 0.85, 0.88, 0.86, 0.84, 0.70, 0.60, 0.58, 0.55, 0.52, 0.50, 0.47, 0.45, 0.43, 0.40, 0.37, 0.35, 0.33, 0.30, 0.28, 0.26, 0.24, 0.22, 0.20, 0.18, 0.16, 0.14, 0.12, 0.10 \\,]$\n  - $\\mathbf{y} = [\\, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 \\,]$\n  - $\\alpha = 0.02$\n- Case $4$ (perfect separation):\n  - $\\mathbf{s} = [\\, 0.95, 0.92, 0.90, 0.88, 0.85, 0.20, 0.18, 0.15, 0.10, 0.05 \\,]$\n  - $\\mathbf{y} = [\\, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0 \\,]$\n  - $\\alpha = 0.30$\n- Case $5$ (inverted classifier, worst-case under low false positives):\n  - $\\mathbf{s} = [\\, 0.20, 0.18, 0.15, 0.10, 0.05, 0.95, 0.92, 0.90, 0.88, 0.85 \\,]$\n  - $\\mathbf{y} = [\\, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0 \\,]$\n  - $\\alpha = 0.10$\n- Case $6$ (boundary condition $\\alpha = 0$):\n  - $\\mathbf{s} = [\\, 0.70, 0.60, 0.55, 0.40 \\,]$\n  - $\\mathbf{y} = [\\, 1, 0, 1, 0 \\,]$\n  - $\\alpha = 0.00$\n\nYour program should produce a single line of output containing the normalized partial AUC values for the cases in the order above, as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4,r_5,r_6]$, where each $r_k$ is the computed $\\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha)$ for case $k$ as a decimal.",
            "solution": "The problem as stated is valid. It is scientifically grounded in the principles of signal detection theory, specifically the construction and analysis of Receiver Operating Characteristic (ROC) curves, a standard methodology in neuroscience, machine learning, and other STEM fields for evaluating binary classifiers. The problem is well-posed, with all necessary definitions, data, and constraints provided to ensure a unique, verifiable solution. The language is objective and mathematically precise. Therefore, we may proceed with a principled solution.\n\nThe task is to compute the normalized partial Area Under the Curve, $\\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha)$, for a series of datasets. This requires a two-step process: first, constructing the ROC curve from the provided scores and labels, and second, integrating the area under this curve up to a specified false positive rate, $\\alpha$.\n\n**1. ROC Curve Construction from First Principles**\n\nAn ROC curve illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The curve plots the True Positive Rate ($\\mathrm{TPR}$) against the False Positive Rate ($\\mathrm{FPR}$) at various threshold settings.\n\nGiven a set of scores $\\{s_i\\}_{i=1}^n$ and corresponding true binary labels $\\{y_i\\}_{i=1}^n$ where $y_i \\in \\{0,1\\}$, a decision rule classifies an observation $i$ as positive if its score $s_i$ is greater than or equal to a threshold $\\tau$, and negative otherwise.\n\nThe fundamental quantities are defined at a given threshold $\\tau$:\n- True Positives, $\\mathrm{TP}(\\tau)$: The count of correctly identified positive instances. $\\mathrm{TP}(\\tau) = \\sum_{i: s_i \\ge \\tau \\land y_i=1} 1$.\n- False Positives, $\\mathrm{FP}(\\tau)$: The count of negative instances incorrectly identified as positive. $\\mathrm{FP}(\\tau) = \\sum_{i: s_i \\ge \\tau \\land y_i=0} 1$.\n- True Negatives, $\\mathrm{TN}(\\tau)$: The count of correctly identified negative instances.\n- False Negatives, $\\mathrm{FN}(\\tau)$: The count of positive instances incorrectly identified as negative.\n\nThe total number of actual positive instances is $P = \\sum_{i=1}^n y_i$, and the total number of actual negative instances is $N = \\sum_{i=1}^n (1 - y_i)$.\n\nThe rates are then defined as:\n- True Positive Rate: $\\mathrm{TPR}(\\tau) = \\dfrac{\\mathrm{TP}(\\tau)}{P}$\n- False Positive Rate: $\\mathrm{FPR}(\\tau) = \\dfrac{\\mathrm{FP}(\\tau)}{N}$\n\nTo construct the ROC curve, we trace the $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ points as $\\tau$ is swept from $+\\infty$ to $-\\infty$.\n- At $\\tau = +\\infty$, no scores meet the criterion $s_i \\ge \\tau$. Thus, $\\mathrm{TP}(+\\infty) = 0$ and $\\mathrm{FP}(+\\infty) = 0$. This gives the starting point of the ROC curve, $(\\mathrm{FPR}, \\mathrm{TPR}) = (0, 0)$.\n- As $\\tau$ decreases, it will cross the values of the scores $s_i$. The values of $\\mathrm{TP}(\\tau)$ and $\\mathrm{FP}(\\tau)$ are piecewise constant and only change when $\\tau$ is equal to one of the scores present in the data. Therefore, we only need to evaluate the rates at thresholds corresponding to the unique score values.\n\nThe algorithm to generate the ROC points is as follows:\n1. Identify the set of unique scores in the data and sort them in descending order, let these be $\\{t_1, t_2, \\dots, t_k\\}$ where $t_1 > t_2 > \\dots > t_k$.\n2. Initialize cumulative true positives, $\\mathrm{tp}_{\\mathrm{cum}}$, and false positives, $\\mathrm{fp}_{\\mathrm{cum}}$, to $0$. Initialize the list of ROC points with $(0, 0)$.\n3. For each unique threshold $t_j$ from $j=1$ to $k$:\n    a. Count the number of actual positive labels ($\\Delta \\mathrm{tp}$) and actual negative labels ($\\Delta \\mathrm{fp}$) among all data points with score $s_i = t_j$.\n    b. Update the cumulative counts: $\\mathrm{tp}_{\\mathrm{cum}} \\leftarrow \\mathrm{tp}_{\\mathrm{cum}} + \\Delta \\mathrm{tp}$ and $\\mathrm{fp}_{\\mathrm{cum}} \\leftarrow \\mathrm{fp}_{\\mathrm{cum}} + \\Delta \\mathrm{fp}$.\n    c. Add a new point $(\\mathrm{fp}_{\\mathrm{cum}}/N, \\mathrm{tp}_{\\mathrm{cum}}/P)$ to the list of ROC points.\nThis process correctly handles tied scores by moving diagonally on the ROC plot, increasing both $\\mathrm{TPR}$ and $\\mathrm{FPR}$ simultaneously. The resulting list of points, when connected by line segments, forms the ROC curve.\n\n**2. Partial AUC Calculation and Normalization**\n\nThe partial Area Under the Curve, $\\mathrm{pAUC}(\\alpha)$, is the integral of the ROC curve from $\\mathrm{FPR}=0$ to $\\mathrm{FPR}=\\alpha$:\n$$ \\mathrm{pAUC}(\\alpha) = \\int_{0}^{\\alpha} \\mathrm{TPR}(\\mathrm{FPR}) \\, d(\\mathrm{FPR}) $$\nSince the ROC curve constructed from finite data is piecewise linear, this integral can be computed as a sum of areas of trapezoids formed by consecutive ROC points.\n\nLet the sequence of ROC points be $(x_0, y_0), (x_1, y_1), \\dots, (x_m, y_m)$, where $(x_0, y_0) = (0, 0)$ and $x_i = \\mathrm{FPR}_i, y_i = \\mathrm{TPR}_i$.\nThe algorithm for computing $\\mathrm{pAUC}(\\alpha)$ is:\n1. Initialize total area, $A$, to $0$.\n2. Iterate through the ROC points from $i=1$ to $m$. Let the previous point be $(x_{i-1}, y_{i-1})$ and the current point be $(x_i, y_i)$.\n3. If the previous point's FPR is already beyond the budget (i.e., $x_{i-1} \\ge \\alpha$), terminate the integration.\n4. If the current segment is entirely within the budget (i.e., $x_i \\le \\alpha$), add the full area of the trapezoid to the total:\n   $$ A \\leftarrow A + \\frac{1}{2} (y_i + y_{i-1})(x_i - x_{i-1}) $$\n5. If the current segment crosses the budget boundary (i.e., $x_{i-1} < \\alpha < x_i$), we must integrate only up to $\\alpha$. We find the TPR value at $\\mathrm{FPR}=\\alpha$ by linear interpolation along the segment from $(x_{i-1}, y_{i-1})$ to $(x_i, y_i)$:\n   $$ y_{\\alpha} = y_{i-1} + (y_i - y_{i-1}) \\frac{\\alpha - x_{i-1}}{x_i - x_{i-1}} $$\n   The area of this final, clipped trapezoid is:\n   $$ A \\leftarrow A + \\frac{1}{2} (y_{\\alpha} + y_{i-1})(\\alpha - x_{i-1}) $$\n   After adding this area, the integration is complete, so we terminate the loop.\n\nFinally, the problem asks for the normalized partial AUC, which is defined as:\n$$ \\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha) = \\begin{cases}\\dfrac{\\mathrm{pAUC}(\\alpha)}{\\alpha}, & \\alpha > 0, \\\\ 0, & \\alpha = 0.\\end{cases} $$\nThis normalization scales the result. For a perfect classifier that achieves $\\mathrm{TPR}=1$ for any $\\mathrm{FPR}>0$, the $\\mathrm{pAUC}(\\alpha)$ would be $\\alpha$, and thus $\\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha)=1$. For a classifier that is no better than random guessing along the diagonal, $\\mathrm{TPR}=\\mathrm{FPR}$, the $\\mathrm{pAUC}(\\alpha) = \\alpha^2/2$, and $\\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha)=\\alpha/2$. For the worst-case classifier that only produces false positives in the low-FPR region, $\\mathrm{pAUC}_{\\mathrm{norm}}(\\alpha)=0$.\n\nThe following implementation adheres to these principles to solve the provided test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases specified.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path, moderate overlap, balanced-ish)\n        (\n            [0.88, 0.82, 0.79, 0.75, 0.71, 0.64, 0.58, 0.54, 0.66, 0.60, 0.59, 0.57, 0.52, 0.50, 0.46, 0.43, 0.38, 0.34, 0.29, 0.22],\n            [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            0.10\n        ),\n        # Case 2 (all scores identical, random-like classifier behavior)\n        (\n            [0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50],\n            [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n            0.20\n        ),\n        # Case 3 (highly imbalanced negatives, extremely low false positive budget)\n        (\n            [0.90, 0.87, 0.85, 0.88, 0.86, 0.84, 0.70, 0.60, 0.58, 0.55, 0.52, 0.50, 0.47, 0.45, 0.43, 0.40, 0.37, 0.35, 0.33, 0.30, 0.28, 0.26, 0.24, 0.22, 0.20, 0.18, 0.16, 0.14, 0.12, 0.10],\n            [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            0.02\n        ),\n        # Case 4 (perfect separation)\n        (\n            [0.95, 0.92, 0.90, 0.88, 0.85, 0.20, 0.18, 0.15, 0.10, 0.05],\n            [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n            0.30\n        ),\n        # Case 5 (inverted classifier, worst-case under low false positives)\n        (\n            [0.20, 0.18, 0.15, 0.10, 0.05, 0.95, 0.92, 0.90, 0.88, 0.85],\n            [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n            0.10\n        ),\n        # Case 6 (boundary condition alpha = 0)\n        (\n            [0.70, 0.60, 0.55, 0.40],\n            [1, 0, 1, 0],\n            0.00\n        )\n    ]\n\n    results = []\n    for scores, labels, alpha in test_cases:\n        result = calculate_pauc_norm(scores, labels, alpha)\n        results.append(f\"{result:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_pauc_norm(scores, labels, alpha):\n    \"\"\"\n    Computes the normalized partial Area Under the ROC Curve (pAUC_norm).\n\n    Args:\n        scores (list or np.ndarray): Deconvolved activity scores.\n        labels (list or np.ndarray): Ground-truth binary labels (0 or 1).\n        alpha (float): The maximum false positive rate for partial AUC calculation.\n\n    Returns:\n        float: The normalized partial AUC value.\n    \"\"\"\n    if alpha == 0.0:\n        return 0.0\n\n    scores = np.asarray(scores, dtype=np.float64)\n    labels = np.asarray(labels, dtype=np.int32)\n    \n    pos_mask = (labels == 1)\n    neg_mask = (labels == 0)\n    \n    P = np.sum(pos_mask)\n    N = np.sum(neg_mask)\n\n    if P == 0 or N == 0:\n        # If no positives, TPR is always 0, so pAUC is 0.\n        # If no negatives, FPR is always 0, ROC is a vertical line at FPR=0,\n        # so integral over [0, alpha] has zero width and area is 0.\n        return 0.0\n\n    # Get unique scores and sort them in descending order for threshold sweeping\n    unique_scores = np.unique(scores)[::-1]\n    \n    roc_points = [(0.0, 0.0)]\n    tp_cum = 0\n    fp_cum = 0\n    \n    # Construct ROC curve points by processing scores in descending order\n    for threshold in unique_scores:\n        threshold_mask = (scores == threshold)\n        delta_tp = np.sum(pos_mask[threshold_mask])\n        delta_fp = np.sum(neg_mask[threshold_mask])\n        \n        tp_cum += delta_tp\n        fp_cum += delta_fp\n        \n        roc_points.append((fp_cum / N, tp_cum / P))\n\n    # Calculate partial AUC using trapezoidal rule\n    pauc = 0.0\n    for i in range(1, len(roc_points)):\n        x_prev, y_prev = roc_points[i - 1]\n        x_curr, y_curr = roc_points[i]\n\n        # Stop if the previous point is already past the budget\n        if x_prev >= alpha:\n            break\n\n        # If the whole segment is within the budget, add the full trapezoid area\n        if x_curr = alpha:\n            pauc += 0.5 * (y_prev + y_curr) * (x_curr - x_prev)\n        # If the segment crosses the budget, add the area up to alpha and stop\n        else:\n            # Check for vertical line case: x_curr == x_prev\n            # If so, this segment has zero width and adds no area.\n            if x_curr > x_prev:\n                # Interpolate TPR at FPR = alpha\n                y_interp = y_prev + (y_curr - y_prev) * (alpha - x_prev) / (x_curr - x_prev)\n                pauc += 0.5 * (y_prev + y_interp) * (alpha - x_prev)\n            break\n            \n    # Normalize the partial AUC by alpha\n    pauc_norm = pauc / alpha\n    return pauc_norm\n\nif __name__ == \"__main__\":\n    solve()\n```"
        }
    ]
}