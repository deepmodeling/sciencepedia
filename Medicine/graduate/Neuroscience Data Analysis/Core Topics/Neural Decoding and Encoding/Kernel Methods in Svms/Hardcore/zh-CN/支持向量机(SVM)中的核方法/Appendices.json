{
    "hands_on_practices": [
        {
            "introduction": "理解支持向量机始于其几何结构。第一个实践将抽象的决策函数置于我们所熟悉的一些概念中，例如点、平面和距离。通过计算几何间隔以及新数据点到决策边界的距离，您将对SVM如何分离数据和量化其分类置信度建立起一种直观的理解。",
            "id": "4172666",
            "problem": "一个神经科学实验室正在使用一个带有线性核的支持向量机（SVM），对源于源定位带限功率的标准化特征进行训练，以解码脑电图（EEG）数据中的运动想象。设输入特征空间中训练好的线性决策函数由权重向量 $\\mathbf{w} = (2,-1,0)^\\top$ 和截距 $b = -0.5$ 指定。假设该SVM解决方案以典范形式给出，这意味着训练集上的最小有符号函数间隔等于 $1$。\n\n给出三个留出的标准化脑电图特征向量为 $\\mathbf{x}^{(1)} = (1,0,0)^\\top$、$\\mathbf{x}^{(2)} = (0,1,0)^\\top$ 和 $\\mathbf{x}^{(3)} = (0.25,0.5,1)^\\top$。仅使用线性支持向量机的核心几何定义以及在线性核情况下的欧几里得投影，推导训练好的超平面的几何间隔，以及每个留出样本到SVM决策边界的垂直距离。指出每个样本决策函数的符号，并根据核方法中常用的基于间隔的解释，简要说明距离的大小如何与分类置信度相关。\n\n将几何间隔和三个距离的最终数值答案表示为按 $\\big(\\gamma, d^{(1)}, d^{(2)}, d^{(3)}\\big)$ 顺序排列的单个行向量，使用精确的根式而非小数。不包括单位。不要四舍五入。",
            "solution": "该问题经验证具有科学依据、提法恰当且客观。提供了所有必要信息，且所涉及的概念在机器学习领域及其在神经科学数据分析中的应用中都是标准的。\n\n线性支持向量机（SVM）的决策函数根据其符号对新数据点 $\\mathbf{x}$ 进行分类：\n$$f(\\mathbf{x}) = \\mathbf{w}^\\top \\mathbf{x} + b$$\n决策边界是由决策函数为零的点集所定义的超平面：$\\mathbf{w}^\\top \\mathbf{x} + b = 0$。\n\n问题给出了权重向量 $\\mathbf{w} = (2,-1,0)^\\top$ 和截距 $b = -0.5$。问题还指出，该SVM以其典范形式（canonical form）表述，这意味着支持向量的函数间隔等于 $1$。超平面的几何间隔，记作 $\\gamma$，是决策边界到最近的训练样本（即支持向量）的垂直距离。在典范表示中，该几何间隔由权重向量的欧几里得范数的倒数给出：\n$$\\gamma = \\frac{1}{\\|\\mathbf{w}\\|}$$\n首先，我们计算 $\\mathbf{w}$ 的欧几里得范数：\n$$\\|\\mathbf{w}\\| = \\sqrt{2^2 + (-1)^2 + 0^2} = \\sqrt{4 + 1 + 0} = \\sqrt{5}$$\n因此，训练好的超平面的几何间隔是：\n$$\\gamma = \\frac{1}{\\sqrt{5}} = \\frac{\\sqrt{5}}{5}$$\n\n接下来，我们必须求出每个留出样本 $\\mathbf{x}^{(i)}$ 到决策边界的垂直距离。这个距离 $d^{(i)}$ 由以下公式给出：\n$$d^{(i)} = \\frac{|\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b|}{\\|\\mathbf{w}\\|}$$\n分子中的项 $|\\mathbf{w}^\\top \\mathbf{x}^{(i)} + b|$ 是在点 $\\mathbf{x}^{(i)}$ 处求值的决策函数的绝对值。决策函数的符号 $\\text{sign}(f(\\mathbf{x}^{(i)}))$ 决定了预测的类别标签（$+1$ 或 $-1$）。\n\n我们现在为给定的三个特征向量分别计算决策函数值和垂直距离。\n\n对于第一个样本 $\\mathbf{x}^{(1)} = (1,0,0)^\\top$：\n决策函数值为：\n$$f(\\mathbf{x}^{(1)}) = \\mathbf{w}^\\top \\mathbf{x}^{(1)} + b = (2)(1) + (-1)(0) + (0)(0) - 0.5 = 2 - 0.5 = 1.5$$\n$f(\\mathbf{x}^{(1)})$ 的符号为正，因此该样本被归类为正类。\n$\\mathbf{x}^{(1)}$ 到决策边界的垂直距离是：\n$$d^{(1)} = \\frac{|f(\\mathbf{x}^{(1)})|}{\\|\\mathbf{w}\\|} = \\frac{|1.5|}{\\sqrt{5}} = \\frac{3/2}{\\sqrt{5}} = \\frac{3}{2\\sqrt{5}} = \\frac{3\\sqrt{5}}{10}$$\n\n对于第二个样本 $\\mathbf{x}^{(2)} = (0,1,0)^\\top$：\n决策函数值为：\n$$f(\\mathbf{x}^{(2)}) = \\mathbf{w}^\\top \\mathbf{x}^{(2)} + b = (2)(0) + (-1)(1) + (0)(0) - 0.5 = -1 - 0.5 = -1.5$$\n$f(\\mathbf{x}^{(2)})$ 的符号为负，因此该样本被归类为负类。\n$\\mathbf{x}^{(2)}$ 到决策边界的垂直距离是：\n$$d^{(2)} = \\frac{|f(\\mathbf{x}^{(2)})|}{\\|\\mathbf{w}\\|} = \\frac{|-1.5|}{\\sqrt{5}} = \\frac{1.5}{\\sqrt{5}} = \\frac{3}{2\\sqrt{5}} = \\frac{3\\sqrt{5}}{10}$$\n\n对于第三个样本 $\\mathbf{x}^{(3)} = (0.25,0.5,1)^\\top$：\n决策函数值为：\n$$f(\\mathbf{x}^{(3)}) = \\mathbf{w}^\\top \\mathbf{x}^{(3)} + b = (2)(0.25) + (-1)(0.5) + (0)(1) - 0.5 = 0.5 - 0.5 + 0 - 0.5 = -0.5$$\n$f(\\mathbf{x}^{(3)})$ 的符号为负，因此该样本被归类为负类。\n$\\mathbf{x}^{(3)}$ 到决策边界的垂直距离是：\n$$d^{(3)} = \\frac{|f(\\mathbf{x}^{(3)})|}{\\|\\mathbf{w}\\|} = \\frac{|-0.5|}{\\sqrt{5}} = \\frac{0.5}{\\sqrt{5}} = \\frac{1/2}{\\sqrt{5}} = \\frac{1}{2\\sqrt{5}} = \\frac{\\sqrt{5}}{10}$$\n\n在基于间隔的SVM解释中，一个点到决策边界的几何距离的大小是分类置信度的一种度量。距离越大意味着该点离划分不同类别的边界越远，因此其分类被认为更可信或更鲁棒。\n对我们的样本而言，$d^{(1)} = \\frac{3\\sqrt{5}}{10}$ 且 $d^{(2)} = \\frac{3\\sqrt{5}}{10}$，而 $d^{(3)} = \\frac{\\sqrt{5}}{10}$。分类器的几何间隔是 $\\gamma = \\frac{\\sqrt{5}}{5} = \\frac{2\\sqrt{5}}{10}$。\n$\\mathbf{x}^{(1)}$ 和 $\\mathbf{x}^{(2)}$ 到决策边界的距离都大于间隔 $\\gamma$ ($d^{(1)} > \\gamma$ 且 $d^{(2)} > \\gamma$) 。因此它们的分类被认为是可信的。\n相比之下，$\\mathbf{x}^{(3)}$ 的距离小于间隔 ($d^{(3)}  \\gamma$)。尽管它被分类了（因为它不位于边界上），但它落在了间隔区域内。这表明这是一个低置信度的分类，因为该点靠近决策边界。\n\n几何间隔和三个距离的最终数值答案，按 $(\\gamma, d^{(1)}, d^{(2)}, d^{(3)})$ 顺序排列为 $(\\frac{\\sqrt{5}}{5}, \\frac{3\\sqrt{5}}{10}, \\frac{3\\sqrt{5}}{10}, \\frac{\\sqrt{5}}{10})$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{\\sqrt{5}}{5}  \\frac{3\\sqrt{5}}{10}  \\frac{3\\sqrt{5}}{10}  \\frac{\\sqrt{5}}{10}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "SVM是如何找到最优分离超平面的？答案在于约束优化和强大的对偶概念。这个练习将指导您完成为一个简单数据集构建和求解对偶二次规划问题的完整过程，揭示间隔最大化背后的精妙机制以及支持向量的关键作用。",
            "id": "4172634",
            "problem": "一位临床神经科学家正在使用支持向量机 (SVM) 初步构建一个二元分类器，用于从一个小的功能性磁共振成像 (fMRI) 感兴趣区域数据集中分离两种任务条件。该科学家为每次试验提取两个特征，这两个特征代表了两个典型网络中的归一化激活摘要，并根据任务条件对每次试验进行标记。三次试验的特征向量和标签分别为：$x_{1} = (1, 0)$，标签为 $y_{1} = +1$；$x_{2} = (0, 1)$，标签为 $y_{2} = +1$；以及 $x_{3} = (1, 1)$，标签为 $y_{3} = -1$。该科学家选择了线性核 $K(x, z) = x^{\\top} z$ 和硬间隔公式。\n\n从硬间隔SVM原始问题的基本定义和拉格朗日对偶性原理出发，完成以下任务：\n\n1. 针对此数据集和核函数，推导关于对偶变量 $\\alpha_{1}$、$\\alpha_{2}$ 和 $\\alpha_{3}$ 的显式对偶二次规划问题，包括等式约束和非负约束。您的推导必须从原始优化定义开始，通过构建拉格朗日函数，应用关于原始变量的平稳性条件，并消除原始变量以获得对偶问题。\n\n2. 解析地求解对偶问题，以获得满足等式约束的最优 $\\boldsymbol{\\alpha} = (\\alpha_{1}, \\alpha_{2}, \\alpha_{3})$。然后，使用决策函数 $f(x) = \\sum_{j=1}^{3} \\alpha_{j} y_{j} K(x_{j}, x) + b$ 的定义以及适用于硬间隔情况的互补松弛条件，计算偏置项 $b$。\n\n3. 通过对 $i \\in \\{1, 2, 3\\}$ 显式计算 $\\alpha_{i}\\big(y_{i} f(x_{i}) - 1\\big)$，来验证每个样本的 Karush-Kuhn-Tucker (KKT) 互补条件。\n\n在每一步骤中提供清晰的推理，并避免使用未从规定基础推导出来的简化公式。作为最终输出，请将偏置项 $b$ 的精确值以单个数字的形式报告。无需四舍五入。",
            "solution": "该问题被评估为有效，因为它在科学上基于机器学习和优化的原理，问题提法良好，数据充分且一致，可得到唯一解，并以客观、正式的语言表述。所提供的数据点是线性可分的，这是硬间隔SVM解存在的必要条件。\n\n解答按要求分为三部分。\n\n### 第1部分：对偶二次规划问题的推导\n\n硬间隔支持向量机 (SVM) 旨在找到一个具有最大可能间隔的分离超平面。这被表述为一个凸优化问题。\n\n**原始问题**\n目标是最小化 $\\frac{1}{2} \\|\\boldsymbol{w}\\|^2$，这等价于最大化间隔 $\\frac{2}{\\|\\boldsymbol{w}\\|}$，其约束条件是所有数据点都被正确分类并且位于间隔区域之外。对于一个包含 $N$ 个点 $(\\boldsymbol{x}_i, y_i)$ 的数据集，其中 $\\boldsymbol{x}_i \\in \\mathbb{R}^d$ 且 $y_i \\in \\{-1, +1\\}$，原始问题为：\n$$\n\\min_{\\boldsymbol{w}, b} \\frac{1}{2} \\boldsymbol{w}^{\\top} \\boldsymbol{w}\n$$\n约束条件为：\n$$\ny_i(\\boldsymbol{w}^{\\top} \\boldsymbol{x}_i + b) \\ge 1, \\quad \\text{for } i = 1, \\dots, N\n$$\n对于本问题，$N=3$。数据为：$\\boldsymbol{x}_{1} = (1, 0)$，标签为 $y_{1} = +1$；$\\boldsymbol{x}_{2} = (0, 1)$，标签为 $y_{2} = +1$；以及 $\\boldsymbol{x}_{3} = (1, 1)$，标签为 $y_{3} = -1$。\n\n**拉格朗日公式**\n我们为 $N=3$ 个约束中的每一个引入非负拉格朗日乘子 $\\alpha_i \\ge 0$。拉格朗日函数 $L_P$ 构建如下：\n$$\nL_P(\\boldsymbol{w}, b, \\boldsymbol{\\alpha}) = \\frac{1}{2} \\boldsymbol{w}^{\\top} \\boldsymbol{w} - \\sum_{i=1}^{3} \\alpha_i \\left[ y_i (\\boldsymbol{w}^{\\top} \\boldsymbol{x}_i + b) - 1 \\right]\n$$\n其中 $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\alpha_3)^{\\top}$。\n\n**平稳性条件**\n为了找到拉格朗日函数的鞍点，我们通过将其关于原始变量 $\\boldsymbol{w}$ 和 $b$ 的偏导数设为零，来最小化 $L_P$。\n1. 关于 $\\boldsymbol{w}$ 的导数：\n$$\n\\frac{\\partial L_P}{\\partial \\boldsymbol{w}} = \\boldsymbol{w} - \\sum_{i=1}^{3} \\alpha_i y_i \\boldsymbol{x}_i = \\boldsymbol{0} \\implies \\boldsymbol{w} = \\sum_{i=1}^{3} \\alpha_i y_i \\boldsymbol{x}_i\n$$\n2. 关于 $b$ 的导数：\n$$\n\\frac{\\partial L_P}{\\partial b} = - \\sum_{i=1}^{3} \\alpha_i y_i = 0 \\implies \\sum_{i=1}^{3} \\alpha_i y_i = 0\n$$\n\n**对偶问题**\n我们将这些平稳性条件代回到拉格朗日函数 $L_P$ 中，以获得对偶拉格朗日函数 $L_D$。\n$$\nL_D(\\boldsymbol{\\alpha}) = \\frac{1}{2} \\left(\\sum_{i=1}^{3} \\alpha_i y_i \\boldsymbol{x}_i\\right)^{\\top} \\left(\\sum_{j=1}^{3} \\alpha_j y_j \\boldsymbol{x}_j\\right) - \\sum_{i=1}^{3} \\alpha_i y_i \\left(\\left(\\sum_{j=1}^{3} \\alpha_j y_j \\boldsymbol{x}_j\\right)^{\\top} \\boldsymbol{x}_i + b\\right) + \\sum_{i=1}^{3} \\alpha_i\n$$\n重新整理并展开各项：\n$$\nL_D(\\boldsymbol{\\alpha}) = \\frac{1}{2} \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\alpha_i \\alpha_j y_i y_j \\boldsymbol{x}_i^{\\top} \\boldsymbol{x}_j - \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\alpha_i \\alpha_j y_i y_j \\boldsymbol{x}_j^{\\top} \\boldsymbol{x}_i - b \\sum_{i=1}^{3} \\alpha_i y_i + \\sum_{i=1}^{3} \\alpha_i\n$$\n由于第二个平稳性条件 $\\sum_{i=1}^{3} \\alpha_i y_i = 0$，包含 $b$ 的项变为零。合并前两项并使用指定的线性核 $K(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{x}_j$：\n$$\nL_D(\\boldsymbol{\\alpha}) = \\sum_{i=1}^{3} \\alpha_i - \\frac{1}{2} \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\alpha_i \\alpha_j y_i y_j K(\\boldsymbol{x}_i, \\boldsymbol{x}_j)\n$$\n对偶问题是在满足从平稳性和原始拉格朗日设定推导出的约束条件下，最大化 $L_D(\\boldsymbol{\\alpha})$。这等价于最小化 $-L_D(\\boldsymbol{\\alpha})$。因此，对偶二次规划问题是：\n$$\n\\min_{\\boldsymbol{\\alpha}} \\frac{1}{2} \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\alpha_i \\alpha_j y_i y_j K(\\boldsymbol{x}_i, \\boldsymbol{x}_j) - \\sum_{i=1}^{3} \\alpha_i\n$$\n约束条件为：\n$$\n\\sum_{i=1}^{3} \\alpha_i y_i = 0 \\quad \\text{and} \\quad \\alpha_i \\ge 0 \\text{ for } i=1, 2, 3.\n$$\n\n**针对该数据集的显式公式**\n首先，我们计算格拉姆矩阵 (Gram matrix) $K_{ij} = K(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = \\boldsymbol{x}_i^{\\top} \\boldsymbol{x}_j$：\n$K_{11} = (1, 0)(1, 0)^{\\top} = 1$；$K_{12} = (1, 0)(0, 1)^{\\top} = 0$；$K_{13} = (1, 0)(1, 1)^{\\top} = 1$。\n$K_{22} = (0, 1)(0, 1)^{\\top} = 1$；$K_{23} = (0, 1)(1, 1)^{\\top} = 1$。\n$K_{33} = (1, 1)(1, 1)^{\\top} = 2$。\n根据对称性，$K_{21}=K_{12}$，$K_{31}=K_{13}$，$K_{32}=K_{23}$。所以格拉姆矩阵为 $K = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 1  1  2 \\end{pmatrix}$。\n\n二次项的矩阵是 $H_{ij} = y_i y_j K_{ij}$。其中 $y_1=+1$, $y_2=+1$, $y_3=-1$：\n$H_{11} = y_1^2 K_{11} = 1$；$H_{12} = y_1 y_2 K_{12} = 0$；$H_{13} = y_1 y_3 K_{13} = -1$。\n$H_{22} = y_2^2 K_{22} = 1$；$H_{23} = y_2 y_3 K_{23} = -1$。\n$H_{33} = y_3^2 K_{33} = 2$。\n海森矩阵 (Hessian matrix) 为 $H = \\begin{pmatrix} 1  0  -1 \\\\ 0  1  -1 \\\\ -1  -1  2 \\end{pmatrix}$。\n\n要最小化的二次目标函数为 $\\frac{1}{2} \\boldsymbol{\\alpha}^{\\top} H \\boldsymbol{\\alpha} - \\mathbf{1}^{\\top} \\boldsymbol{\\alpha}$：\n$$\n\\frac{1}{2} (\\alpha_1^2 + \\alpha_2^2 + 2\\alpha_3^2 - 2\\alpha_1\\alpha_3 - 2\\alpha_2\\alpha_3) - (\\alpha_1 + \\alpha_2 + \\alpha_3)\n$$\n等式约束为 $\\sum_i \\alpha_i y_i = \\alpha_1(1) + \\alpha_2(1) + \\alpha_3(-1) = 0$，即 $\\alpha_1 + \\alpha_2 - \\alpha_3 = 0$。\n\n因此，显式的对偶二次规划问题是：\n**最小化：**\n$$\n\\frac{1}{2} \\alpha_1^2 + \\frac{1}{2} \\alpha_2^2 + \\alpha_3^2 - \\alpha_1\\alpha_3 - \\alpha_2\\alpha_3 - \\alpha_1 - \\alpha_2 - \\alpha_3\n$$\n**约束条件为：**\n$$\n\\alpha_1 + \\alpha_2 - \\alpha_3 = 0 \\quad \\text{and} \\quad \\alpha_1 \\ge 0, \\alpha_2 \\ge 0, \\alpha_3 \\ge 0\n$$\n\n### 第2部分：求解对偶问题并计算偏置项\n\n为了求解这个约束优化问题，我们将等式约束 $\\alpha_3 = \\alpha_1 + \\alpha_2$ 代入目标函数，从而得到一个关于 $\\alpha_1$ 和 $\\alpha_2$ 的函数：\n$$\nJ(\\alpha_1, \\alpha_2) = \\frac{1}{2} \\alpha_1^2 + \\frac{1}{2} \\alpha_2^2 + (\\alpha_1+\\alpha_2)^2 - \\alpha_1(\\alpha_1+\\alpha_2) - \\alpha_2(\\alpha_1+\\alpha_2) - \\alpha_1 - \\alpha_2 - (\\alpha_1+\\alpha_2)\n$$\n展开并简化表达式：\n$$\nJ(\\alpha_1, \\alpha_2) = (\\frac{1}{2}\\alpha_1^2 + \\frac{1}{2}\\alpha_2^2) + (\\alpha_1^2 + 2\\alpha_1\\alpha_2 + \\alpha_2^2) - (\\alpha_1^2 + \\alpha_1\\alpha_2) - (\\alpha_1\\alpha_2 + \\alpha_2^2) - (2\\alpha_1 + 2\\alpha_2)\n$$\n$$\nJ(\\alpha_1, \\alpha_2) = \\frac{1}{2}\\alpha_1^2 + \\frac{1}{2}\\alpha_2^2 - 2\\alpha_1 - 2\\alpha_2\n$$\n现在我们在约束条件 $\\alpha_1 \\ge 0$ 和 $\\alpha_2 \\ge 0$ 下最小化 $J(\\alpha_1, \\alpha_2)$。我们通过将偏导数设为零来找到驻点：\n$$\n\\frac{\\partial J}{\\partial \\alpha_1} = \\alpha_1 - 2 = 0 \\implies \\alpha_1 = 2\n$$\n$$\n\\frac{\\partial J}{\\partial \\alpha_2} = \\alpha_2 - 2 = 0 \\implies \\alpha_2 = 2\n$$\n由于 $\\alpha_1=2$ 和 $\\alpha_2=2$ 都满足非负约束，因此这是最优解。我们根据等式约束求出 $\\alpha_3$：\n$$\n\\alpha_3 = \\alpha_1 + \\alpha_2 = 2 + 2 = 4\n$$\n最优对偶变量为 $\\boldsymbol{\\alpha} = (2, 2, 4)$。\n\n接下来，我们计算偏置项 $b$。Karush-Kuhn-Tucker (KKT) 互补松弛条件表明，对于每个 $i$，都有 $\\alpha_i [y_i(\\boldsymbol{w}^{\\top}\\boldsymbol{x}_i + b) - 1] = 0$。任何满足 $\\alpha_i  0$ 的数据点 $\\boldsymbol{x}_i$ 都是一个支持向量，并且必须位于间隔边界上，满足 $y_i(\\boldsymbol{w}^{\\top}\\boldsymbol{x}_i + b) = 1$。在本例中，所有三个 $\\alpha_i$ 均为正数，因此所有三个点都是支持向量。我们可以使用其中任何一个来求解 $b$。\n首先，我们计算权重向量 $\\boldsymbol{w}$：\n$$\n\\boldsymbol{w} = \\sum_{i=1}^{3} \\alpha_i y_i \\boldsymbol{x}_i = \\alpha_1 y_1 \\boldsymbol{x}_1 + \\alpha_2 y_2 \\boldsymbol{x}_2 + \\alpha_3 y_3 \\boldsymbol{x}_3\n$$\n$$\n\\boldsymbol{w} = (2)(+1)(1, 0)^{\\top} + (2)(+1)(0, 1)^{\\top} + (4)(-1)(1, 1)^{\\top}\n$$\n$$\n\\boldsymbol{w} = (2, 0)^{\\top} + (0, 2)^{\\top} - (4, 4)^{\\top} = (-2, -2)^{\\top}\n$$\n使用支持向量 $\\boldsymbol{x}_1$：\n$$\ny_1(\\boldsymbol{w}^{\\top}\\boldsymbol{x}_1 + b) = 1 \\implies (+1) \\left( (-2, -2)(1, 0)^{\\top} + b \\right) = 1\n$$\n$$\n-2 + b = 1 \\implies b = 3\n$$\n为了确认，使用支持向量 $\\boldsymbol{x}_2$：\n$$\ny_2(\\boldsymbol{w}^{\\top}\\boldsymbol{x}_2 + b) = 1 \\implies (+1) \\left( (-2, -2)(0, 1)^{\\top} + b \\right) = 1\n$$\n$$\n-2 + b = 1 \\implies b = 3\n$$\n以及使用支持向量 $\\boldsymbol{x}_3$：\n$$\ny_3(\\boldsymbol{w}^{\\top}\\boldsymbol{x}_3 + b) = 1 \\implies (-1) \\left( (-2, -2)(1, 1)^{\\top} + b \\right) = 1\n$$\n$$\n(-1)(-2 - 2 + b) = 1 \\implies -(-4+b) = 1 \\implies 4-b=1 \\implies b=3\n$$\n所有三个支持向量都得出相同的偏置值 $b=3$。\n\n### 第3部分：KKT互补条件的验证\n\n该条件为 $\\alpha_i(y_i f(\\boldsymbol{x}_i) - 1) = 0$，其中决策函数为 $f(\\boldsymbol{x}) = \\boldsymbol{w}^{\\top}\\boldsymbol{x} + b$。我们已经得到 $\\boldsymbol{w}=(-2, -2)^{\\top}$ 和 $b=3$。\n\n对于 $i=1$：$\\boldsymbol{x}_1=(1,0), y_1=+1, \\alpha_1=2$。\n$$\n\\alpha_1 \\left( y_1 (\\boldsymbol{w}^{\\top}\\boldsymbol{x}_1 + b) - 1 \\right) = 2 \\left( (+1) ((-2)(1) + (-2)(0) + 3) - 1 \\right) = 2 \\left( (-2+3) - 1 \\right) = 2(1 - 1) = 0\n$$\n\n对于 $i=2$：$\\boldsymbol{x}_2=(0,1), y_2=+1, \\alpha_2=2$。\n$$\n\\alpha_2 \\left( y_2 (\\boldsymbol{w}^{\\top}\\boldsymbol{x}_2 + b) - 1 \\right) = 2 \\left( (+1) ((-2)(0) + (-2)(1) + 3) - 1 \\right) = 2 \\left( (-2+3) - 1 \\right) = 2(1 - 1) = 0\n$$\n\n对于 $i=3$：$\\boldsymbol{x}_3=(1,1), y_3=-1, \\alpha_3=4$。\n$$\n\\alpha_3 \\left( y_3 (\\boldsymbol{w}^{\\top}\\boldsymbol{x}_3 + b) - 1 \\right) = 4 \\left( (-1) ((-2)(1) + (-2)(1) + 3) - 1 \\right) = 4 \\left( (-1)(-4+3) - 1 \\right) = 4(1 - 1) = 0\n$$\nKKT互补条件对所有三个样本都成立，这证实了我们解的正确性。最终要求的值是偏置项 $b$。",
            "answer": "$$\n\\boxed{3}\n$$"
        },
        {
            "introduction": "SVM的真正威力通过核技巧得以释放，它可以在没有过高计算成本的情况下实现复杂的非线性决策边界。本练习将让你揭开这一核心概念的神秘面纱，首先构建一个显式的特征映射，然后验证其与相应多项式核的等价性。这种对比说明了核函数如何在高维空间中间接运算，为神经科学数据分析提供了一个强大而高效的工具。",
            "id": "4172673",
            "problem": "在一项神经元群体编码的研究中，每次试验提供两个放电率特征，形成一个二维输入 $\\mathbf{x} = (x_{1}, x_{2})$，单位为脉冲/秒。提出了一个二元分类问题，用以区分刺激类别，该问题使用带有二次核的支持向量机 (SVM) 来解决。从以下核心定义开始。\n\n- 由特征映射 $\\boldsymbol{\\phi}$ 定义的特征空间中的线性决策函数为 $f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\boldsymbol{\\phi}(\\mathbf{x}) + b$，其中 $\\mathbf{w} = \\sum_{i=1}^{n} \\alpha_{i} y_{i} \\boldsymbol{\\phi}(\\mathbf{x}_{i})$，$\\alpha_{i} \\ge 0$ 是拉格朗日乘子，$y_{i} \\in \\{-1, +1\\}$ 是标签，$b \\in \\mathbb{R}$ 是偏置。\n- 一个半正定核 $k(\\mathbf{x}, \\mathbf{z})$ 对应于一个可能更高维的特征空间中的内积，通过 $k(\\mathbf{x}, \\mathbf{z}) = \\boldsymbol{\\phi}(\\mathbf{x})^{\\top} \\boldsymbol{\\phi}(\\mathbf{z})$。\n- 决策函数可以用对偶形式写为 $f(\\mathbf{x}) = \\sum_{i=1}^{n} \\alpha_{i} y_{i} k(\\mathbf{x}_{i}, \\mathbf{x}) + b$。\n\n考虑非齐次二次多项式核 $k(\\mathbf{x}, \\mathbf{z}) = (\\mathbf{x}^{\\top}\\mathbf{z} + c)^{2}$，其中偏移参数 $c = 1$。构建一个显式的二次特征映射 $\\boldsymbol{\\phi} : \\mathbb{R}^{2} \\to \\mathbb{R}^{m}$，使得对于所有 $\\mathbf{x}, \\mathbf{z} \\in \\mathbb{R}^{2}$，$k(\\mathbf{x}, \\mathbf{z}) = \\boldsymbol{\\phi}(\\mathbf{x})^{\\top} \\boldsymbol{\\phi}(\\mathbf{z})$ 成立。\n\n在以下神经元放电率数据集上训练一个硬间隔 SVM（每个 $\\mathbf{x}_{i}$ 是一个带有标签 $y_{i}$ 的试验）：\n\n- 刺激 $+1$：$\\mathbf{x}_{1} = (2, 1)$，$y_{1} = +1$；以及 $\\mathbf{x}_{2} = (1, 2)$，$y_{2} = +1$。\n- 刺激 $-1$：$\\mathbf{x}_{3} = (1, 3)$，$y_{3} = -1$；以及 $\\mathbf{x}_{4} = (0, 1)$，$y_{4} = -1$。\n\n训练后，只有 $\\mathbf{x}_{1}$ 和 $\\mathbf{x}_{3}$ 是支持向量，其拉格朗日乘子非零，具体为 $\\alpha_{1} = \\frac{1}{2}$ 和 $\\alpha_{3} = \\frac{1}{4}$，学习到的偏置为 $b = 0$。\n\n任务：\n\n1. 使用你为二次核（$c = 1$）构建的 $\\boldsymbol{\\phi}$，计算 $\\mathbf{w} = \\sum_{i \\in \\{1,3\\}} \\alpha_{i} y_{i} \\boldsymbol{\\phi}(\\mathbf{x}_{i})$。\n2. 对于测试输入 $\\mathbf{x}^{\\ast} = (2, 0)$，在映射空间中计算决策函数 $f(\\mathbf{x}^{\\ast}) = \\mathbf{w}^{\\top}\\boldsymbol{\\phi}(\\mathbf{x}^{\\ast}) + b$。\n3. 通过再次使用核表示 $f(\\mathbf{x}^{\\ast}) = \\sum_{i \\in \\{1,3\\}} \\alpha_{i} y_{i} (\\mathbf{x}_{i}^{\\top}\\mathbf{x}^{\\ast} + 1)^{2} + b$ 来计算 $f(\\mathbf{x}^{\\ast})$，并验证两次计算得出相同的值，从而验证等价性。\n\n精确地（无四舍五入）表示 $f(\\mathbf{x}^{\\ast})$ 的最终数值。",
            "solution": "在尝试解答之前，将对问题进行验证。\n\n### 第1步：提取已知条件\n- 输入空间：$\\mathbf{x} = (x_{1}, x_{2}) \\in \\mathbb{R}^{2}$。\n- 分类标签：$y_{i} \\in \\{-1, +1\\}$。\n- 非齐次二次多项式核：$k(\\mathbf{x}, \\mathbf{z}) = (\\mathbf{x}^{\\top}\\mathbf{z} + c)^{2}$，其中 $c = 1$。\n- 特征映射定义：$k(\\mathbf{x}, \\mathbf{z}) = \\boldsymbol{\\phi}(\\mathbf{x})^{\\top} \\boldsymbol{\\phi}(\\mathbf{z})$。\n- 原始决策函数：$f(\\mathbf{x}) = \\mathbf{w}^{\\top}\\boldsymbol{\\phi}(\\mathbf{x}) + b$。\n- 原始权重向量：$\\mathbf{w} = \\sum_{i=1}^{n} \\alpha_{i} y_{i} \\boldsymbol{\\phi}(\\mathbf{x}_{i})$。\n- 对偶决策函数：$f(\\mathbf{x}) = \\sum_{i=1}^{n} \\alpha_{i} y_{i} k(\\mathbf{x}_{i}, \\mathbf{x}) + b$。\n- 训练数据：\n  - $\\mathbf{x}_{1} = (2, 1)$, $y_{1} = +1$。\n  - $\\mathbf{x}_{2} = (1, 2)$, $y_{2} = +1$。\n  - $\\mathbf{x}_{3} = (1, 3)$, $y_{3} = -1$。\n  - $\\mathbf{x}_{4} = (0, 1)$, $y_{4} = -1$。\n- SVM训练结果（硬间隔）：\n  - 支持向量是 $\\mathbf{x}_{1}$ 和 $\\mathbf{x}_{3}$。\n  - 拉格朗日乘子：$\\alpha_{1} = \\frac{1}{2}$，$\\alpha_{3} = \\frac{1}{4}$，以及 $\\alpha_{2} = \\alpha_{4} = 0$。\n  - 偏置：$b = 0$。\n- 测试输入：$\\mathbf{x}^{\\ast} = (2, 0)$。\n\n### 第2步：使用提取的已知条件进行验证\n根据验证标准评估问题：\n- **科学依据**：该问题基于支持向量机和核方法的标准数学理论，这些是机器学习和数据分析中的既定技术。分析神经元放电率的用例是这些方法的常见且有效的应用领域。\n- **良构性**：该问题是良构的。它提供了执行所需计算的所有必要数据点、参数（$\\alpha_i$, $c$, $b$）和定义。任务具体，并导向一个唯一的、确定性的答案。\n- **客观性**：该问题使用精确的数学语言和客观数据陈述。没有主观或含糊不清的术语。\n- **完整性和一致性**：该问题是自包含的。所有变量和常量都已定义。为拉格朗日乘子、支持向量和偏置提供的值与训练好的SVM模型一致（尽管我们不被要求验证训练过程本身，只要求使用其结果）。\n- **未触发其他无效标志。** 该问题是应用核方法定义的标准练习。\n\n### 第3步：结论与行动\n问题有效。将提供完整解答。\n\n**解答推导**\n\n该问题需要三部分计算：构建特征映射 $\\boldsymbol{\\phi}(\\mathbf{x})$ 并计算权重向量 $\\mathbf{w}$；在特征空间中评估决策函数 $f(\\mathbf{x}^{\\ast})$；并使用核技巧验证此结果。\n\n**任务1：构建 $\\boldsymbol{\\phi}(\\mathbf{x})$ 并计算 $\\mathbf{w}$**\n\n首先，我们为给定的核 $k(\\mathbf{x}, \\mathbf{z}) = (\\mathbf{x}^{\\top}\\mathbf{z} + 1)^{2}$ 找出一个显式的特征映射 $\\boldsymbol{\\phi}(\\mathbf{x})$。\n令 $\\mathbf{x} = (x_1, x_2)^{\\top}$ 和 $\\mathbf{z} = (z_1, z_2)^{\\top}$。\n内积为 $\\mathbf{x}^{\\top}\\mathbf{z} = x_1 z_1 + x_2 z_2$。\n核函数为 $k(\\mathbf{x}, \\mathbf{z}) = (x_1 z_1 + x_2 z_2 + 1)^{2}$。\n展开此表达式：\n$$k(\\mathbf{x}, \\mathbf{z}) = (x_1 z_1)^2 + (x_2 z_2)^2 + 1^2 + 2(x_1 z_1)(x_2 z_2) + 2(x_1 z_1)(1) + 2(x_2 z_2)(1)$$\n$$k(\\mathbf{x}, \\mathbf{z}) = x_1^2 z_1^2 + x_2^2 z_2^2 + 1 + 2 x_1 x_2 z_1 z_2 + 2 x_1 z_1 + 2 x_2 z_2$$\n为满足 $k(\\mathbf{x}, \\mathbf{z}) = \\boldsymbol{\\phi}(\\mathbf{x})^{\\top} \\boldsymbol{\\phi}(\\mathbf{z})$，我们根据项对 $\\mathbf{x}$ 和 $\\mathbf{z}$ 的依赖关系对其进行分组：\n$$k(\\mathbf{x}, \\mathbf{z}) = (x_1^2)(z_1^2) + (x_2^2)(z_2^2) + (\\sqrt{2} x_1 x_2)(\\sqrt{2} z_1 z_2) + (\\sqrt{2} x_1)(\\sqrt{2} z_1) + (\\sqrt{2} x_2)(\\sqrt{2} z_2) + (1)(1)$$\n这对应于一个 $6$ 维空间 $\\mathbb{R}^{6}$ 中的内积。一个有效的特征映射是：\n$$\\boldsymbol{\\phi}(\\mathbf{x}) = \\begin{pmatrix} x_1^2 \\\\ x_2^2 \\\\ \\sqrt{2} x_1 x_2 \\\\ \\sqrt{2} x_1 \\\\ \\sqrt{2} x_2 \\\\ 1 \\end{pmatrix}$$\n接下来，我们计算权重向量 $\\mathbf{w} = \\sum_{i=1}^{n} \\alpha_{i} y_{i} \\boldsymbol{\\phi}(\\mathbf{x}_{i})$。求和仅针对支持向量 $\\mathbf{x}_1$ 和 $\\mathbf{x}_3$。\n$$\\mathbf{w} = \\alpha_1 y_1 \\boldsymbol{\\phi}(\\mathbf{x}_1) + \\alpha_3 y_3 \\boldsymbol{\\phi}(\\mathbf{x}_3)$$\n我们将支持向量映射到特征空间：\n对于 $\\mathbf{x}_1 = (2, 1)$：\n$$\\boldsymbol{\\phi}(\\mathbf{x}_1) = \\begin{pmatrix} 2^2 \\\\ 1^2 \\\\ \\sqrt{2}(2)(1) \\\\ \\sqrt{2}(2) \\\\ \\sqrt{2}(1) \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 1 \\\\ 2\\sqrt{2} \\\\ 2\\sqrt{2} \\\\ \\sqrt{2} \\\\ 1 \\end{pmatrix}$$\n对于 $\\mathbf{x}_3 = (1, 3)$：\n$$\\boldsymbol{\\phi}(\\mathbf{x}_3) = \\begin{pmatrix} 1^2 \\\\ 3^2 \\\\ \\sqrt{2}(1)(3) \\\\ \\sqrt{2}(1) \\\\ \\sqrt{2}(3) \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 9 \\\\ 3\\sqrt{2} \\\\ \\sqrt{2} \\\\ 3\\sqrt{2} \\\\ 1 \\end{pmatrix}$$\n代入值 $\\alpha_1=\\frac{1}{2}$, $y_1=+1$, $\\alpha_3=\\frac{1}{4}$ 和 $y_3=-1$：\n$$\\mathbf{w} = \\frac{1}{2}(+1)\\begin{pmatrix} 4 \\\\ 1 \\\\ 2\\sqrt{2} \\\\ 2\\sqrt{2} \\\\ \\sqrt{2} \\\\ 1 \\end{pmatrix} + \\frac{1}{4}(-1)\\begin{pmatrix} 1 \\\\ 9 \\\\ 3\\sqrt{2} \\\\ \\sqrt{2} \\\\ 3\\sqrt{2} \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 1/2 \\\\ \\sqrt{2} \\\\ \\sqrt{2} \\\\ \\sqrt{2}/2 \\\\ 1/2 \\end{pmatrix} - \\begin{pmatrix} 1/4 \\\\ 9/4 \\\\ 3\\sqrt{2}/4 \\\\ \\sqrt{2}/4 \\\\ 3\\sqrt{2}/4 \\\\ 1/4 \\end{pmatrix}$$\n$$\\mathbf{w} = \\begin{pmatrix} 2 - 1/4 \\\\ 1/2 - 9/4 \\\\ \\sqrt{2} - 3\\sqrt{2}/4 \\\\ \\sqrt{2} - \\sqrt{2}/4 \\\\ \\sqrt{2}/2 - 3\\sqrt{2}/4 \\\\ 1/2 - 1/4 \\end{pmatrix} = \\begin{pmatrix} 7/4 \\\\ -7/4 \\\\ \\sqrt{2}/4 \\\\ 3\\sqrt{2}/4 \\\\ -\\sqrt{2}/4 \\\\ 1/4 \\end{pmatrix}$$\n\n**任务2：在映射空间中计算 $f(\\mathbf{x}^{\\ast})$**\n\n我们使用 $f(\\mathbf{x}^{\\ast}) = \\mathbf{w}^{\\top}\\boldsymbol{\\phi}(\\mathbf{x}^{\\ast}) + b$ 计算测试输入 $\\mathbf{x}^{\\ast} = (2, 0)$ 的决策函数值。给定的偏置 $b$ 为 $0$。\n首先，将 $\\mathbf{x}^{\\ast}$ 映射到特征空间：\n$$\\boldsymbol{\\phi}(\\mathbf{x}^{\\ast}) = \\boldsymbol{\\phi}((2, 0)) = \\begin{pmatrix} 2^2 \\\\ 0^2 \\\\ \\sqrt{2}(2)(0) \\\\ \\sqrt{2}(2) \\\\ \\sqrt{2}(0) \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\\\ 2\\sqrt{2} \\\\ 0 \\\\ 1 \\end{pmatrix}$$\n现在，计算内积 $\\mathbf{w}^{\\top}\\boldsymbol{\\phi}(\\mathbf{x}^{\\ast})$：\n$$f(\\mathbf{x}^{\\ast}) = \\begin{pmatrix} 7/4  -7/4  \\sqrt{2}/4  3\\sqrt{2}/4  -\\sqrt{2}/4  1/4 \\end{pmatrix} \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\\\ 2\\sqrt{2} \\\\ 0 \\\\ 1 \\end{pmatrix} + 0$$\n$$f(\\mathbf{x}^{\\ast}) = (\\frac{7}{4})(4) + (-\\frac{7}{4})(0) + (\\frac{\\sqrt{2}}{4})(0) + (\\frac{3\\sqrt{2}}{4})(2\\sqrt{2}) + (-\\frac{\\sqrt{2}}{4})(0) + (\\frac{1}{4})(1)$$\n$$f(\\mathbf{x}^{\\ast}) = 7 + 0 + 0 + \\frac{3 \\cdot 2 \\cdot (\\sqrt{2})^2}{4} + 0 + \\frac{1}{4}$$\n$$f(\\mathbf{x}^{\\ast}) = 7 + \\frac{12}{4} + \\frac{1}{4} = 7 + 3 + \\frac{1}{4} = 10 + \\frac{1}{4} = \\frac{41}{4}$$\n\n**任务3：使用核表示进行验证**\n\n我们现在使用对偶形式重新计算 $f(\\mathbf{x}^{\\ast})$，$f(\\mathbf{x}^{\\ast}) = \\sum_{i \\in \\{1,3\\}} \\alpha_{i} y_{i} k(\\mathbf{x}_{i}, \\mathbf{x}^{\\ast}) + b$：\n$$f(\\mathbf{x}^{\\ast}) = \\alpha_1 y_1 k(\\mathbf{x}_1, \\mathbf{x}^{\\ast}) + \\alpha_3 y_3 k(\\mathbf{x}_3, \\mathbf{x}^{\\ast}) + b$$\n我们需要计算核函数值 $k(\\mathbf{x}_1, \\mathbf{x}^{\\ast})$ 和 $k(\\mathbf{x}_3, \\mathbf{x}^{\\ast})$。\n对于 $\\mathbf{x}_1 = (2, 1)$ 和 $\\mathbf{x}^{\\ast} = (2, 0)$：\n$$\\mathbf{x}_1^{\\top}\\mathbf{x}^{\\ast} = (2)(2) + (1)(0) = 4$$\n$$k(\\mathbf{x}_1, \\mathbf{x}^{\\ast}) = (\\mathbf{x}_1^{\\top}\\mathbf{x}^{\\ast} + 1)^2 = (4 + 1)^2 = 5^2 = 25$$\n对于 $\\mathbf{x}_3 = (1, 3)$ 和 $\\mathbf{x}^{\\ast} = (2, 0)$：\n$$\\mathbf{x}_3^{\\top}\\mathbf{x}^{\\ast} = (1)(2) + (3)(0) = 2$$\n$$k(\\mathbf{x}_3, \\mathbf{x}^{\\ast}) = (\\mathbf{x}_3^{\\top}\\mathbf{x}^{\\ast} + 1)^2 = (2 + 1)^2 = 3^2 = 9$$\n现在将这些值代入决策函数：\n$$f(\\mathbf{x}^{\\ast}) = (\\frac{1}{2})(+1)(25) + (\\frac{1}{4})(-1)(9) + 0$$\n$$f(\\mathbf{x}^{\\ast}) = \\frac{25}{2} - \\frac{9}{4}$$\n为了合并这些项，我们使用公分母 $4$：\n$$f(\\mathbf{x}^{\\ast}) = \\frac{50}{4} - \\frac{9}{4} = \\frac{41}{4}$$\n原始形式的计算结果（$\\frac{41}{4}$）与对偶（核）形式的计算结果（$\\frac{41}{4}$）相匹配，这按要求验证了等价性。最终值为 $\\frac{41}{4}$。",
            "answer": "$$\n\\boxed{\\frac{41}{4}}\n$$"
        }
    ]
}