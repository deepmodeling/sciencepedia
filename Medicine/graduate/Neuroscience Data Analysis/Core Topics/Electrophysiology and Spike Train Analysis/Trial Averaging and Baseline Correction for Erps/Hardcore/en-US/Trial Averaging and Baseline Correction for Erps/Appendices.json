{
    "hands_on_practices": [
        {
            "introduction": "Baseline correction is a fundamental step in Event-Related Potential (ERP) analysis, but its validity rests on the critical assumption that pre-stimulus activity is stationary and unrelated to the post-stimulus effects of interest. This exercise reveals the hidden dangers when this assumption is violated. Through a hands-on derivation , you will discover how seemingly innocuous, condition-specific slow drifts can be transformed by the mechanics of baseline correction into purely artifactual post-stimulus amplitude differences, providing a crucial lesson on a major potential confound in ERP research.",
            "id": "4173065",
            "problem": "Consider a two-condition experiment measuring Event-Related Potentials (ERPs), where each trial for condition $c \\in \\{A,B\\}$ yields a single-channel time series $x_{c,i}(t)$ defined on an epoch $t \\in [-T_0, T_1]$ with stimulus onset at $t = 0$. The ERP for condition $c$ is the across-trial average $\\bar{x}_c(t) = \\frac{1}{N_c} \\sum_{i=1}^{N_c} x_{c,i}(t)$, and the amplitude of a component at latency $\\tau$ is defined as $\\bar{x}_c(\\tau)$ after baseline correction. Baseline correction subtracts the mean in a pre-stimulus window $[-T_b,0)$ from every time point, applied trial-wise: $x'_{c,i}(t) = x_{c,i}(t) - \\frac{1}{T_b}\\int_{-T_b}^{0} x_{c,i}(u)\\,du$, and the baseline-corrected ERP is $\\bar{x}'_c(t) = \\frac{1}{N_c} \\sum_{i=1}^{N_c} x'_{c,i}(t)$. Assume a generative model in which the measured signal comprises an evoked response, a slow non-evoked baseline process, and noise: $x_{c,i}(t) = s_c(t) + d_{c,i}(t) + \\epsilon_{c,i}(t)$, where $s_c(t)$ is the condition-specific evoked response, $d_{c,i}(t)$ is a slow process that is present both before and after $t=0$, and $\\epsilon_{c,i}(t)$ is zero-mean noise independent of $s_c(t)$ and $d_{c,i}(t)$. Suppose that $d_{c,i}(t)$ is adequately approximated on the epoch by a deterministic linear trend $d_{c,i}(t) = \\alpha_c t$, with $\\alpha_c$ potentially differing by condition due to slow drifts or overlap from preceding processes, and that $s_A(t) = s_B(t)$ for all $t \\ge 0$. Under these assumptions and definitions, derive the expected difference $\\Delta(\\tau) = \\mathbb{E}[\\bar{x}'_A(\\tau) - \\bar{x}'_B(\\tau)]$ in terms of $\\alpha_A$, $\\alpha_B$, $T_b$, and $\\tau$, and use your derivation to evaluate how subtracting baselines with different means can induce spurious amplitude differences post-stimulus. Then, evaluate the following statements and select all that are correct about the existence of spurious differences and strategies to mitigate them:\n\nA. If the pre-stimulus drift is condition-specific and continues post-stimulus as $d_c(t) = \\alpha_c t$, baseline subtraction with window $[-T_b,0)$ yields an expected difference at latency $\\tau$ of $(\\alpha_A - \\alpha_B)\\,(\\tau + T_b/2)$ even when the true evoked responses are identical.\n\nB. Using condition-specific baseline subtraction always guarantees unbiased post-stimulus amplitude differences regardless of nonstationary baseline dynamics.\n\nC. Matching baseline distributions across conditions by reweighting trials so that the empirical baseline means are equal removes the constant-offset contribution to the bias but not the time-varying component induced by different slopes.\n\nD. Including the baseline mean as a covariate in a trial-level General Linear Model (GLM), estimating the evoked amplitude as the coefficient of a post-stimulus regressor while controlling for the pre-stimulus baseline, can remove both constant and linear drift-induced bias if the model includes appropriate basis functions (e.g., a linear term in time).\n\nE. High-pass filtering at $2\\,\\mathrm{Hz}$ is always a safe baseline strategy for ERPs because it never distorts component amplitudes.",
            "solution": "The problem statement is scientifically grounded, well-posed, and objective. It presents a simplified but standard generative model for Event-Related Potential (ERP) data to explore the artifacts introduced by baseline correction in the presence of condition-specific linear drift. All terms are defined, and the assumptions are explicit, allowing for a unique and meaningful solution. I will therefore proceed with the derivation and evaluation.\n\nThe first step is to derive the expected difference in the baseline-corrected ERP amplitudes between the two conditions, $\\Delta(\\tau) = \\mathbb{E}[\\bar{x}'_A(\\tau) - \\bar{x}'_B(\\tau)]$.\n\nThe baseline-corrected signal for a single trial $i$ in condition $c$ is given by:\n$$x'_{c,i}(t) = x_{c,i}(t) - B_{c,i}$$\nwhere $B_{c,i}$ is the mean of the signal in the pre-stimulus baseline interval $[-T_b, 0)$:\n$$B_{c,i} = \\frac{1}{T_b}\\int_{-T_b}^{0} x_{c,i}(u)\\,du$$\nThe generative model for the observed signal is:\n$$x_{c,i}(t) = s_c(t) + d_{c,i}(t) + \\epsilon_{c,i}(t)$$\nwhere $s_c(t)$ is the evoked signal, $d_{c,i}(t)$ is a slow drift, and $\\epsilon_{c,i}(t)$ is zero-mean noise.\nWe are given the specific form for the drift, $d_{c,i}(t) = \\alpha_c t$. It is standard to assume that the evoked response $s_c(t)$ is zero for pre-stimulus times, i.e., $s_c(t) = 0$ for $t  0$.\n\nSubstituting the model into the expression for the baseline mean $B_{c,i}$:\n$$B_{c,i} = \\frac{1}{T_b}\\int_{-T_b}^{0} [s_c(u) + \\alpha_c u + \\epsilon_{c,i}(u)]\\,du$$\nGiven $s_c(u) = 0$ for $u0$, this simplifies to:\n$$B_{c,i} = \\frac{1}{T_b}\\int_{-T_b}^{0} [\\alpha_c u + \\epsilon_{c,i}(u)]\\,du = \\frac{\\alpha_c}{T_b}\\int_{-T_b}^{0} u\\,du + \\frac{1}{T_b}\\int_{-T_b}^{0} \\epsilon_{c,i}(u)\\,du$$\nThe integral of the linear term is $\\int_{-T_b}^{0} u\\,du = \\left[\\frac{u^2}{2}\\right]_{-T_b}^{0} = 0 - \\frac{(-T_b)^2}{2} = -\\frac{T_b^2}{2}$.\nSo, the baseline mean for a single trial is:\n$$B_{c,i} = \\frac{\\alpha_c}{T_b} \\left(-\\frac{T_b^2}{2}\\right) + \\frac{1}{T_b}\\int_{-T_b}^{0} \\epsilon_{c,i}(u)\\,du = -\\frac{\\alpha_c T_b}{2} + \\frac{1}{T_b}\\int_{-T_b}^{0} \\epsilon_{c,i}(u)\\,du$$\nNow, we find the baseline-corrected signal at a post-stimulus latency $\\tau \\ge 0$:\n$$x'_{c,i}(\\tau) = x_{c,i}(\\tau) - B_{c,i} = [s_c(\\tau) + \\alpha_c \\tau + \\epsilon_{c,i}(\\tau)] - \\left[-\\frac{\\alpha_c T_b}{2} + \\frac{1}{T_b}\\int_{-T_b}^{0} \\epsilon_{c,i}(u)\\,du\\right]$$\n$$x'_{c,i}(\\tau) = s_c(\\tau) + \\alpha_c \\tau + \\frac{\\alpha_c T_b}{2} + \\epsilon_{c,i}(\\tau) - \\frac{1}{T_b}\\int_{-T_b}^{0} \\epsilon_{c,i}(u)\\,du$$\nThe condition-specific ERP $\\bar{x}'_c(\\tau)$ is the average of $x'_{c,i}(\\tau)$ across $N_c$ trials. Taking the expectation $\\mathbb{E}[...]$ over all possible noise realizations, and noting that $\\mathbb{E}[\\epsilon_{c,i}(t)] = 0$ for all $t$, we have:\n$$\\mathbb{E}[\\bar{x}'_c(\\tau)] = \\mathbb{E}\\left[\\frac{1}{N_c}\\sum_{i=1}^{N_c} x'_{c,i}(\\tau)\\right] = s_c(\\tau) + \\alpha_c \\tau + \\frac{\\alpha_c T_b}{2} = s_c(\\tau) + \\alpha_c\\left(\\tau + \\frac{T_b}{2}\\right)$$\nThe expected difference between conditions $A$ and $B$ is:\n$$\\Delta(\\tau) = \\mathbb{E}[\\bar{x}'_A(\\tau)] - \\mathbb{E}[\\bar{x}'_B(\\tau)] = \\left[s_A(\\tau) + \\alpha_A\\left(\\tau + \\frac{T_b}{2}\\right)\\right] - \\left[s_B(\\tau) + \\alpha_B\\left(\\tau + \\frac{T_b}{2}\\right)\\right]$$\n$$\\Delta(\\tau) = (s_A(\\tau) - s_B(\\tau)) + (\\alpha_A - \\alpha_B)\\left(\\tau + \\frac{T_b}{2}\\right)$$\nThe problem states that the true evoked responses are identical post-stimulus, $s_A(t) = s_B(t)$ for $t \\ge 0$. Therefore, for $\\tau \\ge 0$, the first term is zero. The resulting expected difference is purely a spurious artifact of the interaction between baseline correction and differential drift:\n$$\\Delta(\\tau) = (\\alpha_A - \\alpha_B)\\left(\\tau + \\frac{T_b}{2}\\right)$$\nThis derivation shows that a difference in pre-stimulus drift slopes $(\\alpha_A \\neq \\alpha_B)$ induces a spurious post-stimulus amplitude difference that is not constant but changes linearly with latency $\\tau$.\n\nNow, I will evaluate each statement.\n\nA. If the pre-stimulus drift is condition-specific and continues post-stimulus as $d_c(t) = \\alpha_c t$, baseline subtraction with window $[-T_b,0)$ yields an expected difference at latency $\\tau$ of $(\\alpha_A - \\alpha_B)\\,(\\tau + T_b/2)$ even when the true evoked responses are identical.\nThis statement is a direct and precise match to the result derived above. The formula is identical to the spurious expected difference $\\Delta(\\tau)$ we calculated under the given assumptions.\nVerdict: **Correct**.\n\nB. Using condition-specific baseline subtraction always guarantees unbiased post-stimulus amplitude differences regardless of nonstationary baseline dynamics.\nThis statement is false. My derivation provides a direct counterexample. For the case of linear nonstationary dynamics ($d_c(t)=\\alpha_c t$), applying condition-specific baseline subtraction results in a biased estimate of the amplitude difference, $\\Delta(\\tau) = (\\alpha_A - \\alpha_B)(\\tau + T_b/2)$, which is non-zero if $\\alpha_A \\neq \\alpha_B$. The term \"always guarantees\" is far too strong, as this common form of baseline correction is well-known to be sensitive to various forms of nonstationarity.\nVerdict: **Incorrect**.\n\nC. Matching baseline distributions across conditions by reweighting trials so that the empirical baseline means are equal removes the constant-offset contribution to the bias but not the time-varying component induced by different slopes.\nThe derived bias is $\\Delta(\\tau) = (\\alpha_A - \\alpha_B)\\tau + (\\alpha_A - \\alpha_B)\\frac{T_b}{2}$. This has two components: a time-varying component $(\\alpha_A - \\alpha_B)\\tau$ and a constant-offset component $(\\alpha_A - \\alpha_B)\\frac{T_b}{2}$. The expected baseline mean for condition $c$ is $\\mathbb{E}[B_c] = -\\frac{\\alpha_c T_b}{2}$. The difference in expected baseline means is thus $\\mathbb{E}[B_A] - \\mathbb{E}[B_B] = -(\\alpha_A - \\alpha_B)\\frac{T_b}{2}$. The constant-offset bias is the negative of this difference. A procedure that matches the empirical baseline means (e.g., by subsampling or reweighting trials) forces the average baseline levels to be equal across conditions, thereby removing the constant-offset contribution to the bias. However, this procedure does not alter the underlying signal dynamics. The time-varying component $(\\alpha_A - \\alpha_B)\\tau$ arises from the fact that the actual signal at time $\\tau$ contains the term $\\alpha_c \\tau$, and this difference in ongoing drift is not corrected by adjusting the pre-stimulus mean. Thus, the statement accurately describes the effect of this corrective strategy.\nVerdict: **Correct**.\n\nD. Including the baseline mean as a covariate in a trial-level General Linear Model (GLM), estimating the evoked amplitude as the coefficient of a post-stimulus regressor while controlling for the pre-stimulus baseline, can remove both constant and linear drift-induced bias if the model includes appropriate basis functions (e.g., a linear term in time).\nThis statement describes a sophisticated and valid approach to mitigate such artifacts. A GLM can model the contribution of multiple factors to the observed data. In a trial-level model of the data point $x_{c,i}(t)$, one could include regressors for the experimental condition, the pre-stimulus baseline mean of that trial, time $t$ itself, and crucially, the interaction between time and condition. A model of the form $x_i(t) \\sim \\text{Condition} + B_i + t + \\text{Condition} \\times t$ explicitly models and estimates the condition-specific linear drift via the main effect of $t$ and the interaction term. By accounting for this differential drift, the model can provide an unbiased estimate of the condition effect on the evoked response. This method removes the root cause of the bias (the differential slopes), thereby correcting for both the time-varying and constant-offset components of the artifact.\nVerdict: **Correct**.\n\nE. High-pass filtering at $2\\,\\mathrm{Hz}$ is always a safe baseline strategy for ERPs because it never distorts component amplitudes.\nThis statement is categorically false. High-pass filtering is a linear time-invariant operation that removes or attenuates frequency components below its cutoff frequency. While it can be effective at removing slow drifts (which are low-frequency phenomena), it will also distort any part of the signal of interest that has energy in the stopband. Many important ERP components, such as the P300, slow cortical potentials, and readiness potentials, are characterized by slow voltage changes and have substantial energy below $2\\,\\mathrm{Hz}$. Applying a $2\\,\\mathrm{Hz}$ high-pass filter would severely attenuate and distort these components, potentially leading to incorrect conclusions about their amplitude and latency. No filtering strategy is \"always safe\" or \"never distorts\"; the choice of filter parameters must be carefully considered based on the specific ERP components of interest and the nature of the noise.\nVerdict: **Incorrect**.",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "After theoretically demonstrating how baseline differences can create spurious results, this practice moves toward a concrete, computational quality check. A core prerequisite for comparing ERPs across conditions is that the baseline activity itself does not differ systematically between them. This hands-on coding exercise  builds your practical skills by tasking you with generating synthetic ERP data and implementing a formal statistical test to check for baseline non-stationarity, providing you with an essential tool for validating your own experimental analyses.",
            "id": "4202094",
            "problem": "You are given a formal task in Event-Related Potential (ERP) analysis for Electroencephalography (EEG) that focuses on trial averaging and baseline correction, framed purely in mathematical and statistical terms. The goal is to compare the baseline across experimental conditions and electrodes, using first principles about statistical estimation and hypothesis testing. You must implement a complete program that generates synthetic, scientifically plausible ERP-like data, applies baseline computations and corrections, and then performs comparative baseline analysis across conditions and electrodes.\n\nUse the following foundational base. An ERP is a stimulus-locked signal defined as an expected value across repeated trials. Let $x_{c,e,i}(t)$ denote the amplitude in microvolts for condition $c$, electrode $e$, trial $i$, at relative time $t$ in milliseconds, where $t = 0$ denotes stimulus onset. The baseline is defined on a pre-stimulus time window $B = [t_1, t_2]$ with $t_1  0$ and $t_2 \\le 0$. The per-trial baseline mean is\n$$\nb_{c,e,i} = \\frac{1}{|B|} \\sum_{t \\in B} x_{c,e,i}(t).\n$$\nBaseline correction of each trial is the transformation\n$$\n\\tilde{x}_{c,e,i}(t) = x_{c,e,i}(t) - b_{c,e,i}.\n$$\nThe trial-averaged ERP for a condition and electrode is defined as the arithmetic mean across trials:\n$$\n\\mathrm{ERP}_{c,e}(t) = \\frac{1}{n_c} \\sum_{i=1}^{n_c} \\tilde{x}_{c,e,i}(t),\n$$\nwhere $n_c$ is the number of trials in condition $c$. To assess whether baselines differ across conditions for each electrode, model per-trial baseline means as independent samples and compare the two condition-specific baseline distributions using a two-sided Welch’s $t$-test at significance level $\\alpha = 0.05$, relying on well-tested properties of the sample mean as an unbiased estimator and on large-sample approximations for Gaussian noise.\n\nYour program must generate ERP-like synthetic data for each test case as follows. For each trial, electrode, and condition, construct $x_{c,e,i}(t)$ by summing three components: a condition-specific constant baseline offset $\\Delta_{c,e}$ in microvolts applied over the entire time series, a common stimulus-locked ERP “bump” modeled as a Gaussian pulse of amplitude $A$ microvolts centered at time $\\mu$ milliseconds with width parameter $\\sigma$ milliseconds, and zero-mean Gaussian noise with standard deviation $\\eta$ microvolts independently sampled at each time point. All time points and windows are defined in milliseconds and sampled at integer millisecond resolution according to the sampling rate $f_s$ in Hertz. Amplitudes must be treated and interpreted in microvolts, and time must be treated and interpreted in milliseconds. Angles are not used.\n\nFor each test case, perform the following computations:\n- Compute $b_{c,e,i}$ for all trials and electrodes using the specified baseline window.\n- Apply baseline correction to obtain $\\tilde{x}_{c,e,i}(t)$ and form $\\mathrm{ERP}_{c,e}(t)$ via trial averaging.\n- For each electrode, perform a two-sided Welch’s $t$-test comparing $\\{b_{A,e,i}\\}_{i=1}^{n_A}$ versus $\\{b_{B,e,j}\\}_{j=1}^{n_B}$ at $\\alpha = 0.05$.\n- Count the number of electrodes for which the baseline difference is statistically significant, that is, where the $p$-value is strictly less than $0.05$.\n\nThe test suite consists of three parameter sets designed for coverage and scientific realism. In all cases, the ERP component is identical across conditions to ensure the baseline is the primary differentiator, and random generation must be deterministic per test case via fixed seeds to make the output reproducible.\n\nTest Case $1$ (general “happy path” with multiple electrodes and balanced trials):\n- Sampling rate $f_s = 1000$ Hertz.\n- Time axis from $t_{\\min} = -200$ milliseconds to $t_{\\max} = 600$ milliseconds inclusive.\n- Baseline window $B = [-200, 0]$ milliseconds inclusive.\n- Number of trials $n_A = 120$ and $n_B = 120$.\n- Number of electrodes $E = 3$ with indices $e \\in \\{0,1,2\\}$.\n- Baseline offsets in microvolts: $\\Delta_{A,e} = 0$ for all $e$, and $\\Delta_{B,0} = 0$, $\\Delta_{B,1} = 0.8$, $\\Delta_{B,2} = 1.2$.\n- ERP Gaussian pulse parameters: amplitude $A = 5$, center $\\mu = 300$, width $\\sigma = 50$.\n- Noise standard deviation $\\eta = 0.5$ microvolts.\n- Deterministic random seed $s = 42$.\n\nTest Case $2$ (boundary-like case with a short baseline window and a single electrode):\n- Sampling rate $f_s = 500$ Hertz.\n- Time axis from $t_{\\min} = -20$ milliseconds to $t_{\\max} = 200$ milliseconds inclusive.\n- Baseline window $B = [-20, 0]$ milliseconds inclusive.\n- Number of trials $n_A = 60$ and $n_B = 60$.\n- Number of electrodes $E = 1$ with index $e = 0$.\n- Baseline offsets in microvolts: $\\Delta_{A,0} = 0$ and $\\Delta_{B,0} = 0$.\n- ERP Gaussian pulse parameters: amplitude $A = 3$, center $\\mu = 100$, width $\\sigma = 30$.\n- Noise standard deviation $\\eta = 0.6$ microvolts.\n- Deterministic random seed $s = 43$.\n\nTest Case $3$ (edge case with unequal trials and a strong baseline difference for one electrode):\n- Sampling rate $f_s = 1000$ Hertz.\n- Time axis from $t_{\\min} = -100$ milliseconds to $t_{\\max} = 500$ milliseconds inclusive.\n- Baseline window $B = [-100, 0]$ milliseconds inclusive.\n- Number of trials $n_A = 100$ and $n_B = 70$.\n- Number of electrodes $E = 3$ with indices $e \\in \\{0,1,2\\}$.\n- Baseline offsets in microvolts: $\\Delta_{A,e} = 0$ for all $e$, and $\\Delta_{B,0} = 2.0$, $\\Delta_{B,1} = 0$, $\\Delta_{B,2} = 0$.\n- ERP Gaussian pulse parameters: amplitude $A = 4$, center $\\mu = 200$, width $\\sigma = 40$.\n- Noise standard deviation $\\eta = 0.7$ microvolts.\n- Deterministic random seed $s = 44$.\n\nYour program must output a single line containing the integer counts of significant electrodes for Test Cases $1$, $2$, and $3$, respectively, as a comma-separated list enclosed in square brackets with no spaces, for example, $[x_1,x_2,x_3]$. There are no units associated with this output because it is a count. All intermediate quantities in the computations must properly use microvolts for amplitudes and milliseconds for time as specified in each test case. The hypothesis tests must be two-sided and use $\\alpha = 0.05$.",
            "solution": "The user-provided problem is valid. It is scientifically grounded in the principles of neurophysiological signal processing and statistical inference, specifically concerning Event-Related Potentials (ERPs). The problem is well-posed, with all parameters, models, and procedures explicitly and unambiguously defined, ensuring a unique and reproducible solution. It is objective and free of non-formalizable or subjective elements. Therefore, a solution will be provided.\n\nThe problem requires the implementation of a computational model to analyze synthetic ERP data. The core tasks are to generate the data according to a specified model, compute per-trial baselines, and then perform a statistical comparison of these baselines between two experimental conditions for a set of electrodes.\n\nThe solution proceeds in four main stages: (1) generation of synthetic ERP data, (2) calculation of per-trial baseline means, (3) statistical hypothesis testing on these means, and (4) aggregation of results across specified test cases.\n\n**1. Synthetic Data Generation**\nThe voltage signal for a given condition $c \\in \\{A, B\\}$, electrode $e$, and trial $i$ at time $t$ is modeled as:\n$$\nx_{c,e,i}(t) = \\Delta_{c,e} + G(t; A, \\mu, \\sigma) + \\epsilon_{c,e,i}(t)\n$$\nwhere:\n- $\\Delta_{c,e}$ is a constant baseline offset in microvolts ($\\mu$V) specific to the condition and electrode. This term represents the underlying difference in brain activity we aim to detect.\n- $G(t; A, \\mu, \\sigma)$ is a deterministic, stimulus-locked ERP component common to all trials, modeled as a Gaussian pulse:\n$$\nG(t; A, \\mu, \\sigma) = A \\exp\\left(-\\frac{(t - \\mu)^2}{2\\sigma^2}\\right)\n$$\nHere, $A$ is the amplitude ($\\mu$V), $\\mu$ is the temporal center (ms), and $\\sigma$ is the width (ms) of the pulse.\n- $\\epsilon_{c,e,i}(t)$ is a random noise term, modeled as an independent sample from a zero-mean Gaussian distribution with standard deviation $\\eta$, i.e., $\\epsilon_{c,e,i}(t) \\sim \\mathcal{N}(0, \\eta^2)$.\n\nFor each test case, we first establish a discrete time vector based on the specified sampling rate $f_s$ (in Hz) and time range $[t_{\\min}, t_{\\max}]$ (in ms). The time step is $\\Delta t = 1000/f_s$ ms. The time vector consists of points $t_k = t_{\\min} + k \\cdot \\Delta t$ up to $t_{\\max}$. For each condition, electrode, and trial, a time series is constructed by summing the constant offset, the common Gaussian pulse evaluated at each time point, and a unique realization of the Gaussian noise. The use of a fixed seed for the random number generator ensures reproducibility.\n\n**2. Per-Trial Baseline Calculation**\nThe baseline period is defined as a pre-stimulus time window $B = [t_1, t_2]$, where $t_2 \\le 0$. The per-trial baseline mean, $b_{c,e,i}$, is the sample mean of the signal $x_{c,e,i}(t)$ over the discrete time points falling within this window. It is an estimator for the true mean amplitude during the baseline period.\n$$\nb_{c,e,i} = \\frac{1}{N_B} \\sum_{k \\text{ s.t. } t_k \\in B} x_{c,e,i}(t_k)\n$$\nwhere $N_B$ is the number of time samples in the window $B$. Since the ERP component $G(t)$ is designed to be negligible during the baseline period and the noise $\\epsilon(t)$ has zero mean, the expected value of the baseline mean is approximately the true offset: $\\mathbb{E}[b_{c,e,i}] \\approx \\Delta_{c,e}$.\n\nThe problem also specifies computing the baseline-corrected signal $\\tilde{x}_{c,e,i}(t) = x_{c,e,i}(t) - b_{c,e,i}$ and the trial-averaged $\\mathrm{ERP}_{c,e}(t) = \\frac{1}{n_c} \\sum_{i=1}^{n_c} \\tilde{x}_{c,e,i}(t)$. While these are standard steps in ERP analysis, the core task of comparing baselines relies solely on the $b_{c,e,i}$ values. These quantities are computed as part of the specified procedure.\n\n**3. Statistical Hypothesis Testing**\nTo determine if the baseline activity differs significantly between conditions $A$ and $B_j$ for a given electrode $e$, we compare the distributions of their respective per-trial baseline means, $\\{b_{A,e,i}\\}_{i=1}^{n_A}$ and $\\{b_{B,e,j}\\}_{j=1}^{n_B}$. The null hypothesis ($H_0$) is that the true population means of the baselines are equal ($\\mathbb{E}[b_{A,e}] = \\mathbb{E}[b_{B,e}]$), implying no difference in baseline offset ($\\Delta_{A,e} = \\Delta_{B,e}$). The alternative hypothesis ($H_A$) is that they are not equal.\n\nA two-sided Welch's $t$-test is employed for this comparison. This test is appropriate as it does not assume equal variances or equal sample sizes ($n_A$ vs. $n_B$) between the two groups, making it more robust than the standard Student's $t$-test. The test yields a $p$-value, which represents the probability of observing a difference in sample means as large as or larger than the one computed, assuming the null hypothesis is true. If this $p$-value is less than the pre-defined significance level $\\alpha = 0.05$, we reject the null hypothesis and conclude that there is a statistically significant difference in baselines for that electrode.\n\n**4. Algorithmic Implementation and Aggregation**\nThe overall algorithm is as follows:\n1. Initialize a list to store the results for each test case.\n2. For each of the three test cases defined in the problem:\n    a. Configure all parameters: $f_s, t_{\\min}, t_{\\max}, B, n_A, n_B, E, \\{\\Delta_{c,e}\\}, A, \\mu, \\sigma, \\eta$, and the random seed $s$.\n    b. Create a reproducible random number generator using the specified seed.\n    c. Construct the discrete time vector.\n    d. Generate the common Gaussian ERP pulse.\n    e. For each condition ($A$ and $B$):\n        i. Generate the full data tensor $x_{c,e,i}(t)$ by combining the offsets, ERP pulse, and noise via broadcasting.\n        ii. Identify the time indices corresponding to the baseline window $B$.\n        iii. Calculate the per-trial baseline means $b_{c,e,i}$ by averaging the data over the baseline indices, resulting in a matrix of shape (electrodes, trials).\n    f. Initialize a counter for significant electrodes to $0$.\n    g. For each electrode index $e$ from $0$ to $E-1$:\n        i. Extract the two samples of baseline means: $\\{b_{A,e,i}\\}$ and $\\{b_{B,e,j}\\}$.\n        ii. Perform the two-sided Welch's $t$-test on these two samples.\n        iii. If the resulting $p$-value is strictly less than $0.05$, increment the counter.\n    h. Append the final count to the results list.\n3. Format the results list into the specified output string `\"[count1,count2,count3]\"`.\n\nThis procedure is implemented in the provided Python code, utilizing `numpy` for efficient array computation and `scipy.stats.ttest_ind` for the statistical test.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef run_analysis(params: dict) - int:\n    \"\"\"\n    Generates synthetic ERP data and performs baseline comparison for a single test case.\n\n    Args:\n        params: A dictionary containing all parameters for the test case.\n\n    Returns:\n        The number of electrodes with a statistically significant baseline difference.\n    \"\"\"\n    # Unpack parameters from the dictionary\n    f_s = params[\"f_s\"]\n    t_min, t_max = params[\"t_range\"]\n    b_win_start, b_win_end = params[\"b_win\"]\n    n_trials = params[\"n_trials\"]\n    E = params[\"E\"]\n    deltas = params[\"deltas\"]\n    erp_params = params[\"erp_params\"]\n    eta = params[\"eta\"]\n    seed = params[\"seed\"]\n\n    # 1. Setup time vector and reproducible random number generator\n    rng = np.random.default_rng(seed)\n    sampling_interval = 1000.0 / f_s\n    # Use np.arange with a small tolerance for the endpoint to be inclusive\n    time_vector = np.arange(t_min, t_max + 1e-9, sampling_interval)\n\n    # 2. Generate common ERP component (Gaussian pulse)\n    A = erp_params['A']\n    mu = erp_params['mu']\n    sigma = erp_params['sigma']\n    erp_bump = A * np.exp(-((time_vector - mu)**2) / (2 * sigma**2))\n\n    baseline_means = {}\n    conditions = ['A', 'B']\n\n    for cond in conditions:\n        n_c = n_trials[cond]\n        delta_c = deltas[cond]\n\n        # 3. Generate synthetic data x_c,e,i(t)\n        # Noise tensor: (electrodes, trials, time points)\n        noise = rng.normal(loc=0.0, scale=eta, size=(E, n_c, len(time_vector)))\n        \n        # Combine components using broadcasting:\n        # delta_c: (E,) - (E, 1, 1)\n        # erp_bump: (time,) - (1, 1, time)\n        # noise: (E, n_c, time)\n        x_c = delta_c[:, np.newaxis, np.newaxis] + erp_bump[np.newaxis, np.newaxis, :] + noise\n\n        # 4. Compute per-trial baseline means b_c,e,i\n        baseline_mask = (time_vector = b_win_start)  (time_vector = b_win_end)\n        b_c = np.mean(x_c[:, :, baseline_mask], axis=2)\n        baseline_means[cond] = b_c  # Shape: (E, n_c)\n\n        # As required, perform baseline correction and trial averaging, though not used in the final result\n        # _tilde_x_c = x_c - b_c[:, :, np.newaxis]\n        # _erp_c = np.mean(_tilde_x_c, axis=1)\n\n    # 5. Perform Welch's t-test for each electrode\n    significant_electrodes_count = 0\n    alpha = 0.05\n    baselines_A = baseline_means['A']\n    baselines_B = baseline_means['B']\n\n    for e in range(E):\n        sample_A = baselines_A[e, :]\n        sample_B = baselines_B[e, :]\n        \n        # Perform two-sided Welch's t-test\n        _t_stat, p_val = stats.ttest_ind(sample_A, sample_B, equal_var=False, alternative='two-sided')\n        \n        if p_val  alpha:\n            significant_electrodes_count += 1\n            \n    return significant_electrodes_count\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1\n        {\n            \"f_s\": 1000, \"t_range\": (-200, 600), \"b_win\": (-200, 0),\n            \"n_trials\": {'A': 120, 'B': 120}, \"E\": 3,\n            \"deltas\": {'A': np.array([0.0, 0.0, 0.0]), 'B': np.array([0.0, 0.8, 1.2])},\n            \"erp_params\": {'A': 5, 'mu': 300, 'sigma': 50},\n            \"eta\": 0.5, \"seed\": 42\n        },\n        # Test Case 2\n        {\n            \"f_s\": 500, \"t_range\": (-20, 200), \"b_win\": (-20, 0),\n            \"n_trials\": {'A': 60, 'B': 60}, \"E\": 1,\n            \"deltas\": {'A': np.array([0.0]), 'B': np.array([0.0])},\n            \"erp_params\": {'A': 3, 'mu': 100, 'sigma': 30},\n            \"eta\": 0.6, \"seed\": 43\n        },\n        # Test Case 3\n        {\n            \"f_s\": 1000, \"t_range\": (-100, 500), \"b_win\": (-100, 0),\n            \"n_trials\": {'A': 100, 'B': 70}, \"E\": 3,\n            \"deltas\": {'A': np.array([0.0, 0.0, 0.0]), 'B': np.array([2.0, 0.0, 0.0])},\n            \"erp_params\": {'A': 4, 'mu': 200, 'sigma': 40},\n            \"eta\": 0.7, \"seed\": 44\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        result = run_analysis(params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real-world data is often messy, and robust analysis requires principled methods for handling imperfect measurements. This final practice tackles a challenging but common scenario: estimating an ERP with very few trials, one of which has a corrupted or missing baseline window. The exercise introduces the Best Linear Unbiased Estimator (BLUE) framework, a powerful statistical method for optimally combining measurements with differing levels of uncertainty. By working through the problem , you will learn to estimate missing data, propagate the associated uncertainty, and perform an inverse-variance weighted average to achieve the most precise estimate possible from the available data.",
            "id": "4202144",
            "problem": "A cognitive electrophysiology experiment records scalp potentials from a single electrode in response to a repeated visual stimulus. The goal is to estimate the Event-Related Potential (ERP) amplitude at a latency of $300\\,\\mathrm{ms}$ under two edge-case constraints: very few trials and one trial missing the canonical baseline window. Use only foundational definitions and widely accepted principles to construct the estimator and its uncertainty weighting.\n\nDefinitions and assumptions:\n- An Event-Related Potential (ERP) is the condition-averaged time-locked voltage across repeated trials, intended to improve the estimate of a deterministic stimulus-evoked signal by reducing random noise through averaging.\n- Trial-specific observed voltages are modeled as the sum of the deterministic waveform and zero-mean random noise that is independent across trials and approximately wide-sense stationary within short windows.\n- Baseline correction for a trial subtracts the mean voltage over a pre-stimulus window from all time points of that trial. When the baseline window is corrupted or missing, assume the baseline for all trials in the same condition is a shared but unknown constant. In that case, estimate it from intact trials and propagate its estimation variance into downstream quantities.\n- For inverse-variance weighting of heterogeneous trials, adopt the Best Linear Unbiased Estimator (BLUE) justified by the Gauss–Markov theorem: among unbiased linear estimators, the estimator with minimum variance assigns weights proportional to the inverse of the measurement variance.\n\nData:\n- Sampling rate is $1000\\,\\mathrm{Hz}$. The canonical baseline window is $[-100,0]\\,\\mathrm{ms}$, containing $n=100$ samples.\n- Three trials are available, with uncorrected voltages at $300\\,\\mathrm{ms}$: $v_{1}(300)=5.0\\,\\mathrm{\\mu V}$, $v_{2}(300)=3.0\\,\\mathrm{\\mu V}$, $v_{3}(300)=4.5\\,\\mathrm{\\mu V}$.\n- Trial $1$ baseline: mean $b_{1}=1.2\\,\\mathrm{\\mu V}$; baseline sample variance $s_{1}^{2}=4.0\\,\\mathrm{\\mu V}^{2}$.\n- Trial $2$ baseline: mean $b_{2}=-0.6\\,\\mathrm{\\mu V}$; baseline sample variance $s_{2}^{2}=8.0\\,\\mathrm{\\mu V}^{2}$.\n- Trial $3$ baseline is missing due to artifact in $[-100,0]\\,\\mathrm{ms}$. A late window $[600,700]\\,\\mathrm{ms}$ with no expected response provides a stationary noise estimate $s_{3}^{2}=9.0\\,\\mathrm{\\mu V}^{2}$.\n\nModeling details to use:\n- For intact baselines, the variance of a baseline mean is $\\sigma_{b_{i}}^{2}=s_{i}^{2}/n$, assuming independent samples within the short baseline window.\n- For the missing-baseline trial, estimate a common baseline $\\hat{b}$ from intact trials under the assumption of a shared condition baseline and independent Gaussian measurement noise in the baseline means. Use the BLUE with inverse-variance weights based on $\\sigma_{b_{i}}^{2}$, and compute $\\operatorname{Var}(\\hat{b})$ from those weights.\n- After baseline correction, the variance of a single-trial corrected amplitude at $300\\,\\mathrm{ms}$ is the sum of the per-sample noise variance at $300\\,\\mathrm{ms}$ and the variance of the baseline mean (or the variance of $\\hat{b}$ for the missing-baseline trial), assuming independence of baseline and post-stimulus noise.\n- Form the ERP estimate at $300\\,\\mathrm{ms}$ as the inverse-variance weighted average of the baseline-corrected single-trial amplitudes.\n\nTask:\nCompute the inverse-variance weighted ERP amplitude at $300\\,\\mathrm{ms}$ using the described modeling and data. Express the final amplitude in microvolts. Round your answer to four significant figures.",
            "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, objective, and self-contained, presenting a standard problem in signal processing for electrophysiological data.\n\nThe objective is to compute the Best Linear Unbiased Estimator (BLUE) for the Event-Related Potential (ERP) amplitude at a latency of $300\\,\\mathrm{ms}$, denoted as $\\hat{A}_{300}$. This is achieved by taking an inverse-variance weighted average of the baseline-corrected single-trial amplitudes.\n\nLet $v_i(300)$ be the uncorrected voltage of trial $i$ at $300\\,\\mathrm{ms}$, and let $v'_i(300)$ be the corresponding baseline-corrected amplitude. The final estimate is given by:\n$$\n\\hat{A}_{300} = \\frac{\\sum_{i=1}^{3} w_i v'_i(300)}{\\sum_{i=1}^{3} w_i}\n$$\nwhere the weights $w_i$ are the inverse of the variance of each corrected amplitude:\n$$\nw_i = \\frac{1}{\\operatorname{Var}(v'_i(300))}\n$$\n\nThe calculation is performed in three stages:\n1.  Analyze the trials with intact baselines (trial $1$ and trial $2$).\n2.  Analyze the trial with the missing baseline (trial $3$) by first estimating a common baseline.\n3.  Combine the results using inverse-variance weighting.\n\n**Step 1: Analysis of Trials with Intact Baselines (Trials $1$ and $2$)**\n\nFor a trial $i$ with an intact baseline, the corrected amplitude is $v'_i(300) = v_i(300) - b_i$, where $b_i$ is the empirical mean of the baseline period.\n\nThe variance of this corrected amplitude, assuming independence between the noise at $300\\,\\mathrm{ms}$ and the noise in the baseline period, is the sum of their variances:\n$$\n\\operatorname{Var}(v'_i(300)) = \\operatorname{Var}(v_i(300)) + \\operatorname{Var}(b_i)\n$$\nThe term $\\operatorname{Var}(v_i(300))$ represents the variance of a single sample, which is estimated by the sample variance of the noise, $s_i^2$, due to the assumption of wide-sense stationarity. The term $\\operatorname{Var}(b_i)$ is the variance of the sample mean of the baseline, which consists of $n$ samples, and is given by $\\sigma_{b_i}^2 = \\frac{s_i^2}{n}$.\nThus, the variance for a corrected trial with an intact baseline is:\n$$\n\\operatorname{Var}(v'_i(300)) = s_i^2 + \\frac{s_i^2}{n} = s_i^2 \\left(1 + \\frac{1}{n}\\right)\n$$\nWe are given $n=100$.\n\nFor trial $1$:\n- Uncorrected amplitude: $v_1(300) = 5.0\\,\\mathrm{\\mu V}$.\n- Baseline mean: $b_1 = 1.2\\,\\mathrm{\\mu V}$.\n- Baseline sample variance: $s_1^2 = 4.0\\,\\mathrm{\\mu V}^2$.\n- Corrected amplitude: $v'_1(300) = 5.0 - 1.2 = 3.8\\,\\mathrm{\\mu V}$.\n- Variance of corrected amplitude: $\\operatorname{Var}(v'_1(300)) = 4.0 \\left(1 + \\frac{1}{100}\\right) = 4.0 \\times 1.01 = 4.04\\,\\mathrm{\\mu V}^2$.\n\nFor trial $2$:\n- Uncorrected amplitude: $v_2(300) = 3.0\\,\\mathrm{\\mu V}$.\n- Baseline mean: $b_2 = -0.6\\,\\mathrm{\\mu V}$.\n- Baseline sample variance: $s_2^2 = 8.0\\,\\mathrm{\\mu V}^2$.\n- Corrected amplitude: $v'_2(300) = 3.0 - (-0.6) = 3.6\\,\\mathrm{\\mu V}$.\n- Variance of corrected amplitude: $\\operatorname{Var}(v'_2(300)) = 8.0 \\left(1 + \\frac{1}{100}\\right) = 8.0 \\times 1.01 = 8.08\\,\\mathrm{\\mu V}^2$.\n\n**Step 2: Analysis of the Trial with Missing Baseline (Trial $3$)**\n\nFor trial $3$, we must first estimate the baseline. We use the baseline means from the intact trials, $b_1$ and $b_2$, as two independent measurements of a shared, unknown baseline. The BLUE for this common baseline, $\\hat{b}$, is their inverse-variance weighted average.\n\nThe variances of the measurements $b_1$ and $b_2$ are:\n- $\\sigma_{b_1}^2 = \\frac{s_1^2}{n} = \\frac{4.0}{100} = 0.04\\,\\mathrm{\\mu V}^2$.\n- $\\sigma_{b_2}^2 = \\frac{s_2^2}{n} = \\frac{8.0}{100} = 0.08\\,\\mathrm{\\mu V}^2$.\n\nThe corresponding inverse-variance weights are:\n- $w_{b1} = \\frac{1}{\\sigma_{b_1}^2} = \\frac{1}{0.04} = 25$.\n- $w_{b2} = \\frac{1}{\\sigma_{b_2}^2} = \\frac{1}{0.08} = 12.5$.\n\nThe estimated common baseline is:\n$$\n\\hat{b} = \\frac{w_{b1} b_1 + w_{b2} b_2}{w_{b1} + w_{b2}} = \\frac{(25)(1.2) + (12.5)(-0.6)}{25 + 12.5} = \\frac{30 - 7.5}{37.5} = \\frac{22.5}{37.5} = 0.6\\,\\mathrm{\\mu V}\n$$\nThe variance of this estimator is given by $\\operatorname{Var}(\\hat{b}) = \\frac{1}{\\sum w_{bi}}$.\n$$\n\\operatorname{Var}(\\hat{b}) = \\frac{1}{25 + 12.5} = \\frac{1}{37.5} = \\frac{2}{75}\\,\\mathrm{\\mu V}^2\n$$\n\nNow, we can find the corrected amplitude for trial $3$ and its variance.\n- Corrected amplitude: $v'_3(300) = v_3(300) - \\hat{b} = 4.5 - 0.6 = 3.9\\,\\mathrm{\\mu V}$.\n- The variance of this corrected amplitude is:\n$$\n\\operatorname{Var}(v'_3(300)) = \\operatorname{Var}(v_3(300)) + \\operatorname{Var}(\\hat{b})\n$$\nThe per-sample noise variance for trial $3$ is given as $s_3^2 = 9.0\\,\\mathrm{\\mu V}^2$.\n$$\n\\operatorname{Var}(v'_3(300)) = s_3^2 + \\operatorname{Var}(\\hat{b}) = 9.0 + \\frac{2}{75} = \\frac{9 \\times 75 + 2}{75} = \\frac{675+2}{75} = \\frac{677}{75}\\,\\mathrm{\\mu V}^2\n$$\n\n**Step 3: Final Combination**\n\nWe now have the three corrected amplitudes and their associated variances:\n- $v'_1(300) = 3.8\\,\\mathrm{\\mu V}$, with variance $\\sigma'^2_1 = 4.04 = \\frac{101}{25}\\,\\mathrm{\\mu V}^2$.\n- $v'_2(300) = 3.6\\,\\mathrm{\\mu V}$, with variance $\\sigma'^2_2 = 8.08 = \\frac{202}{25}\\,\\mathrm{\\mu V}^2$.\n- $v'_3(300) = 3.9\\,\\mathrm{\\mu V}$, with variance $\\sigma'^2_3 = \\frac{677}{75}\\,\\mathrm{\\mu V}^2$.\n\nThe final ERP amplitude estimate $\\hat{A}_{300}$ is the inverse-variance weighted mean:\n$$\n\\hat{A}_{300} = \\frac{\\frac{v'_1(300)}{\\sigma'^2_1} + \\frac{v'_2(300)}{\\sigma'^2_2} + \\frac{v'_3(300)}{\\sigma'^2_3}}{\\frac{1}{\\sigma'^2_1} + \\frac{1}{\\sigma'^2_2} + \\frac{1}{\\sigma'^2_3}}\n$$\nLet's compute the numerator and denominator separately.\n\nDenominator (sum of weights):\n$$\nD = \\frac{1}{4.04} + \\frac{1}{8.08} + \\frac{1}{677/75} = \\frac{100}{404} + \\frac{100}{808} + \\frac{75}{677} = \\frac{25}{101} + \\frac{25}{202} + \\frac{75}{677}\n$$\n$$\nD = \\frac{50}{202} + \\frac{25}{202} + \\frac{75}{677} = \\frac{75}{202} + \\frac{75}{677} = 75 \\left( \\frac{1}{202} + \\frac{1}{677} \\right) = 75 \\left( \\frac{677 + 202}{202 \\times 677} \\right) = \\frac{75 \\times 879}{136754} = \\frac{65925}{136754}\n$$\n\nNumerator (sum of weighted amplitudes):\n$$\nN = \\frac{3.8}{4.04} + \\frac{3.6}{8.08} + \\frac{3.9}{677/75} = \\frac{380}{404} + \\frac{360}{808} + \\frac{3.9 \\times 75}{677} = \\frac{95}{101} + \\frac{45}{101} + \\frac{292.5}{677}\n$$\n$$\nN = \\frac{140}{101} + \\frac{292.5}{677} = \\frac{140 \\times 677 + 292.5 \\times 101}{101 \\times 677} = \\frac{94780 + 29542.5}{68377} = \\frac{124322.5}{68377}\n$$\n\nFinally, we compute the ratio $\\hat{A}_{300} = N/D$:\n$$\n\\hat{A}_{300} = \\frac{124322.5/68377}{65925/136754} = \\frac{124322.5}{68377} \\times \\frac{136754}{65925}\n$$\nSince $136754 = 2 \\times 68377$:\n$$\n\\hat{A}_{300} = \\frac{124322.5}{\\cancel{68377}} \\times \\frac{2 \\times \\cancel{68377}}{65925} = \\frac{2 \\times 124322.5}{65925} = \\frac{248645}{65925}\n$$\n$$\n\\hat{A}_{300} \\approx 3.771638225... \\,\\mathrm{\\mu V}\n$$\nRounding to four significant figures, the final result is $3.772\\,\\mathrm{\\mu V}$.",
            "answer": "$$\\boxed{3.772}$$"
        }
    ]
}