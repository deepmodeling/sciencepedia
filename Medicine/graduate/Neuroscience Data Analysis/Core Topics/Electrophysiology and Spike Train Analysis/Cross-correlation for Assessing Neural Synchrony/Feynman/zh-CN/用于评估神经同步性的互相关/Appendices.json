{
    "hands_on_practices": [
        {
            "introduction": "在寻找神经同步性之前，我们必须首先理解缺乏同步性的信号在互相关图上应呈现何种形态。本练习将引导你完成一个基础的理论推导，证明对于两个独立的神经元（在此被建模为泊松过程），其期望的互相关图是一条平坦的直线。这条基线对于我们从背景噪声中识别出真实的神经同步信号至关重要。",
            "id": "4151144",
            "problem": "两个同时记录的神经元产生脉冲序列，这些脉冲序列在观测区间 $[0,T]$ 上被建模为独立的齐次泊松点过程，分别记为 $X$ 和 $Y$，其恒定强度（速率）分别为 $\\lambda_{x}$ 和 $\\lambda_{y}$。根据齐次性，对于任意长度为 $L$ 的区间，脉冲计数的期望值为 $\\lambda L$；根据独立性，不相交区间内以及不同过程之间的脉冲计数是独立的。考虑以下在时滞 $\\tau \\in \\mathbb{R}$、窗宽 $\\Delta > 0$ 下，单位时间内时滞符合事件的分箱互相关图估计量：\n$$\n\\hat{C}_{xy}(\\tau) \\equiv \\frac{1}{T} \\sum_{t_{i} \\in X \\cap [0,T]} N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big),\n$$\n其中 $N_{Y}(I)$ 表示过程 $Y$ 在区间 $I$ 内的脉冲计数。假设 $T$ 很大且 $|\\tau| + \\Delta \\ll T$，因此在计算期望值时可以忽略边界效应。仅从齐次泊松过程的定义以及 $X$ 和 $Y$ 的独立性出发，推导出期望值 $\\mathbb{E}[\\hat{C}_{xy}(\\tau)]$ 关于 $\\lambda_{x}$、$\\lambda_{y}$ 和 $\\Delta$ 的显式表达式，并证明它不依赖于 $\\tau$。请以单一闭式解析表达式的形式给出你的最终答案。不需要数值近似。",
            "solution": "题目要求计算分箱互相关图估计量的期望值 $\\mathbb{E}[\\hat{C}_{xy}(\\tau)]$，其中涉及两个独立的齐次泊松脉冲序列 $X$ 和 $Y$，其恒定强度分别为 $\\lambda_x$ 和 $\\lambda_y$。\n\n该估计量定义为：\n$$\n\\hat{C}_{xy}(\\tau) \\equiv \\frac{1}{T} \\sum_{t_{i} \\in X \\cap [0,T]} N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big)\n$$\n其中 $T$ 是观测区间的持续时间，$\\Delta$ 是窗宽，$\\tau$ 是时滞，$t_i$ 是过程 $X$ 的脉冲时间，$N_Y(I)$ 是过程 $Y$ 在给定区间 $I$ 内的脉冲数。\n\n我们首先对 $\\hat{C}_{xy}(\\tau)$ 的定义应用期望算子：\n$$\n\\mathbb{E}[\\hat{C}_{xy}(\\tau)] = \\mathbb{E}\\left[ \\frac{1}{T} \\sum_{t_{i} \\in X \\cap [0,T]} N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big) \\right]\n$$\n根据期望的线性性质，常数因子 $\\frac{1}{T}$ 可以移到期望符号外面：\n$$\n\\mathbb{E}[\\hat{C}_{xy}(\\tau)] = \\frac{1}{T} \\mathbb{E}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big) \\right]\n$$\n求和是针对点过程 $X$ 的脉冲时间 $\\{t_i\\}$ 进行的，这些时间本身就是随机变量。为了计算这个和的期望，我们通过对脉冲序列 $X$ 的实现进行条件化，应用全期望定律（也称为塔性质）。设过程 $X$ 的特定实现为脉冲时间集合 $\\{t_i\\}$。\n$$\n\\mathbb{E}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} \\dots \\right] = \\mathbb{E}_{X}\\left[ \\mathbb{E}_{Y}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big) \\bigg| X = \\{t_i\\} \\right] \\right]\n$$\n题目说明过程 $X$ 和 $Y$ 是独立的。因此，对 $X$ 取条件不会改变 $Y$ 的统计特性。内部对 $Y$ 的期望可以通过将 $X$ 的脉冲时间 $\\{t_i\\}$ 视为固定值来计算。\n$$\n= \\mathbb{E}_{X}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} \\mathbb{E}_{Y}\\left[ N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big) \\right] \\right]\n$$\n接下来，我们计算内部期望 $\\mathbb{E}_{Y}[\\dots]$。过程 $Y$ 是一个强度恒为 $\\lambda_y$ 的齐次泊松过程。这种过程的一个基本性质是，在长度为 $L$ 的区间内，事件数的期望值为 $\\lambda_y L$。我们关心的区间是 $[t_i + \\tau, t_i + \\tau + \\Delta)$，其长度为 $\\Delta$。因此，期望计数为：\n$$\n\\mathbb{E}_{Y}\\left[ N_{Y}\\big([t_{i} + \\tau,\\, t_{i} + \\tau + \\Delta)\\big) \\right] = \\lambda_y \\Delta\n$$\n这个结果是一个常数，与具体的脉冲时间 $t_i$ 和时滞 $\\tau$ 无关。这是过程 $Y$ 齐次性的直接结果。将这个常数值代回到我们的主表达式中：\n$$\n\\mathbb{E}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} \\dots \\right] = \\mathbb{E}_{X}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} (\\lambda_y \\Delta) \\right]\n$$\n常数项 $\\lambda_y \\Delta$ 可以从求和中提取出来：\n$$\n= \\mathbb{E}_{X}\\left[ (\\lambda_y \\Delta) \\sum_{t_{i} \\in X \\cap [0,T]} 1 \\right]\n$$\n根据定义，和式 $\\sum_{t_{i} \\in X \\cap [0,T]} 1$ 是过程 $X$ 在观测区间 $[0, T]$ 内的总脉冲数。这被记为 $N_X([0, T])$。\n$$\n= \\mathbb{E}_{X}\\left[ (\\lambda_y \\Delta) N_X([0, T]) \\right]\n$$\n将常数项 $\\lambda_y \\Delta$ 从期望中提取出来，得到：\n$$\n= (\\lambda_y \\Delta) \\mathbb{E}_{X}\\left[ N_X([0, T]) \\right]\n$$\n现在，我们必须计算过程 $X$ 的期望脉冲数。因为 $X$ 是一个强度恒为 $\\lambda_x$ 的齐次泊松过程，所以在长度为 $T$ 的区间内的期望脉冲数为：\n$$\n\\mathbb{E}_{X}\\left[ N_X([0, T]) \\right] = \\lambda_x T\n$$\n题目说明我们可以忽略边界效应，这一点由假设 $|\\tau| + \\Delta \\ll T$ 所保证。这确保了我们的计算在整个区间上都成立。\n\n综合各个部分，求和项的期望为：\n$$\n\\mathbb{E}\\left[ \\sum_{t_{i} \\in X \\cap [0,T]} \\dots \\right] = (\\lambda_y \\Delta) (\\lambda_x T) = \\lambda_x \\lambda_y T \\Delta\n$$\n最后，我们将这个结果代回到 $\\mathbb{E}[\\hat{C}_{xy}(\\tau)]$ 的表达式中：\n$$\n\\mathbb{E}[\\hat{C}_{xy}(\\tau)] = \\frac{1}{T} (\\lambda_x \\lambda_y T \\Delta) = \\lambda_x \\lambda_y \\Delta\n$$\n这个表达式是互相关图的期望值。它取决于两个神经元的发放率 $\\lambda_x$ 和 $\\lambda_y$，以及窗宽 $\\Delta$。正如所要求的，结果不依赖于时滞 $\\tau$，这是独立齐次过程的一个特征，代表了偶然符合事件的期望率。",
            "answer": "$$\n\\boxed{\\lambda_{x} \\lambda_{y} \\Delta}\n$$"
        },
        {
            "introduction": "理论模型的纯粹性在面对计算算法的现实复杂性时常常会遇到挑战。本练习将探讨一种在使用基于快速傅里叶变换（FFT）的方法计算互相关时常见且危险的陷阱：“环绕”效应（wrap-around artifact）。理解这个问题对于避免将虚假的峰值误解为真实的神经元相互作用至关重要。",
            "id": "4151103",
            "problem": "一个实验室记录了在一次时长为 $T = 1$ 秒的单次试验中，来自两个皮层神经元的脉冲序列。数据以 $\\Delta t = 10$ 毫秒的宽度进行分箱，得到 $N = 100$ 个时间窗格，索引为 $n = 0, 1, \\dots, 99$。定义两个二元序列 $x[n]$ 和 $y[n]$，其中当 $n \\in \\{0,1,2,3,4\\}$ 时，$x[n] = 1$，其他情况下 $x[n] = 0$；当 $n \\in \\{95,96,97,98,99\\}$ 时，$y[n] = 1$，其他情况下 $y[n] = 0$。你希望通过计算 $x[n]$ 和 $y[n]$ 之间的互相关函数 (CCF) 来评估神经同步性。\n\n考虑实践中使用的两种计算方案：\n- 一种线性的、非周期性的互相关，它将超出范围的索引视为零（通常直接在时域中实现，或通过带有适当零填充的快速傅里叶变换 (FFT) 实现）。\n- 一种循环的、周期性的互相关，它隐式地对索引进行模 $N$ 环绕（当基于FFT的相关计算没有进行足够的零填充时，就会发生这种情况，从而假定了周期性扩展）。\n\n假设研究人员错误地将循环、周期性的解释应用于这些有限的、非周期性的脉冲序列。哪个选项最能描述相关图的差异以及这对评估该数据集中的同步性所带来的解释性后果？\n\nA. 循环方法由于环绕效应，在延迟 $k = 5$ 个时间窗格处产生一个显著的峰值，而线性方法将相同的重叠置于延迟 $k = -95$ 个时间窗格处；对于非周期性的神经数据，循环方法产生的小延迟峰值是虚假的，因为它将试验结束时的活动与试验开始时的活动混叠在一起。\n\nB. 两种方法都产生相同的相关图，在延迟 $k = -95$ 个时间窗格处有一个单一峰值；当脉冲序列是二元时，环绕效应没有影响。\n\nC. 循环方法抑制了所有边界效应，并且不产生任何峰值，因为脉冲几乎被整个试验时长隔开；线性方法也由于支撑集不重叠而在任何延迟下都显示没有相关性。\n\nD. 在互相关之前对脉冲计数进行去趋势处理可以消除环绕伪影，因此无论周期性假设如何，两种方法都只在 $k = 0$ 个时间窗格附近产生生理上有意义的峰值。",
            "solution": "在尝试任何解答之前，需对问题陈述进行验证。\n\n### 第1步：提取已知条件\n-   试验时长：$T = 1$ s。\n-   时间窗格宽度：$\\Delta t = 10$ ms。\n-   时间窗格数量：$N = T / \\Delta t = (1 \\text{ s}) / (10 \\times 10^{-3} \\text{ s}) = 100$。\n-   时间窗格索引：$n \\in \\{0, 1, \\dots, 99\\}$。\n-   信号 $x[n]$：当 $n \\in \\{0,1,2,3,4\\}$ 时，$x[n] = 1$，其他情况下 $x[n] = 0$。这代表试验开始时的一个包含5个脉冲的爆发。\n-   信号 $y[n]$：当 $n \\in \\{95,96,97,98,99\\}$ 时，$y[n] = 1$，其他情况下 $y[n] = 0$。这代表试验结束时的一个包含5个脉冲的爆发。\n-   方法1：线性、非周期性互相关。超出范围的索引被视为零。\n-   方法2：循环、周期性互相关。索引按模 $N$ 环绕。\n-   问题要求描述这两种方法所得相关图的差异，以及当循环方法被错误应用时，对解释该数据集中神经同步性的后续影响。\n\n### 第2步：使用提取的已知条件进行验证\n该问题在科学上和数学上都是合理的。\n-   **科学依据：** 该场景描述了一种标准的数据分析技术（互相关），用于神经科学中一种常见的数据类型（脉冲序列）。线性和循环相关之间的区别，特别是不正确使用基于FFT的方法所产生的环绕伪影，是信号处理中一个真实且重要的问题。所给参数是一致且符合实际的。\n-   **良定义：** 信号 $x[n]$ 和 $y[n]$ 有精确的定义。两种计算方法是标准的数学运算。问题要求比较它们的结果和解释，这可以被明确地推导出来。\n-   **客观性：** 该问题使用精确、客观的数学和科学术语进行表述。它不包含任何主观论断。\n\n所有验证标准均已满足。问题设置没有任何科学、逻辑或结构上的缺陷。\n\n### 第3步：结论与行动\n该问题是**有效的**。将推导完整解答。\n\n### 推导\n\n我们将分析线性和循环两种方法的互相关函数 (CCF)。信号 $x[n]$ 与信号 $y[n]$ 的互相关的一个常用定义是\n$$\nC_{xy}[k] = \\sum_{n=-\\infty}^{\\infty} x[n] y[n-k]\n$$\n其中 $k$ 是延迟。在负延迟 $k$ 处的峰值表示信号 $y[n]$ 必须向*左*平移（在时间上提前）以与 $x[n]$ 对齐，这意味着 $y[n]$ 发生在 $x[n]$ *之后*。在我们的例子中，$x[n]$ 在试验开始时，$y[n]$ 在试验结束时，所以我们预期主要的相关峰会出现在一个大的负延迟处。\n\n**1. 线性互相关**\n\n对于长度为 $N$ 的有限信号，线性互相关假设信号在区间 $[0, N-1]$ 之外为零。求和实际上是有限的。\n$$\nC_{xy}^{\\text{linear}}[k] = \\sum_{n=0}^{N-1} x[n] y[n-k]\n$$\n其中如果 $m  0$ 或 $m \\ge N$，则 $y[m]$ 被视为 $0$。\n要使乘积 $x[n]y[n-k]$ 不为零，我们需要 $x[n]=1$ 和 $y[n-k]=1$ 同时成立。\n-   $x[n]=1$ 要求 $n \\in \\{0, 1, 2, 3, 4\\}$。\n-   $y[n-k]=1$ 要求 $n-k \\in \\{95, 96, 97, 98, 99\\}$。\n\n让我们找到提供最大重叠的延迟 $k$。当 $x[n]$ 的五个活动时间窗格与平移后的 $y[n]$ 的五个活动时间窗格对齐时，发生最大重叠。我们必须将 $y[n]$ 向左平移 $95$ 个时间窗格，以将其在 $n=95$ 处的起点与 $x[n]$ 在 $n=0$ 处的起点对齐。向左平移 $95$ 个时间窗格对应于延迟 $k = -95$。让我们用数学方法来验证这一点：\n对于 $k = -95$，CCF 为：\n$$\nC_{xy}^{\\text{linear}}[-95] = \\sum_{n=0}^{4} x[n] y[n - (-95)] = \\sum_{n=0}^{4} x[n] y[n+95]\n$$\n对于 $n \\in \\{0, 1, 2, 3, 4\\}$，我们有 $x[n] = 1$。$y$ 的索引变为 $n+95 \\in \\{95, 96, 97, 98, 99\\}$。对于这些索引，$y[n+95]=1$。因此，对于所有五个 $n$ 值，乘积为 $1 \\cdot 1 = 1$。\n$$\nC_{xy}^{\\text{linear}}[-95] = \\sum_{n=0}^{4} 1 = 5\n$$\n这是最大可能值，在 $k = -95$ 处形成一个峰值。对于此峰值附近的延迟，重叠是部分的（例如，$C_{xy}^{\\text{linear}}[-94] = 4$）。对于接近 $k=0$ 的延迟，信号之间没有重叠（例如，对于 $k=0$，$x[n]y[n]$ 总是零），因此对于小的 $|k|$，$C_{xy}^{\\text{linear}}[k] \\approx 0$。\n\n**2. 循环互相关**\n\n循环互相关假设信号是周期性的，周期为 $N=100$。索引按模 $N$ 计算。\n$$\nC_{xy}^{\\text{circ}}[k] = \\sum_{n=0}^{N-1} x[n] y[(n-k) \\pmod N]\n$$\n循环CCF本身是周期性的，周期为 $N$。在延迟 $k$ 处的峰值将在所有延迟 $k \\pm mN$ (对于任意整数 $m$) 处重复出现。我们在线性情况下找到的 $k=-95$ 处的峰值在循环情况下也会存在：$C_{xy}^{\\text{circ}}[-95] = 5$。\n由于周期性，这个峰值也会出现在其他等效延迟处，例如 $k = -95 + 100 = 5$。让我们显式地计算在 $k=5$ 处的值：\n$$\nC_{xy}^{\\text{circ}}[5] = \\sum_{n=0}^{4} x[n] y[(n-5) \\pmod{100}]\n$$\n我们只需要对 $n \\in \\{0, 1, 2, 3, 4\\}$ 进行求和，因为在其他情况下 $x[n]=0$。\n-   对于 $n=0$， $y[(0-5) \\pmod{100}] = y[-5 \\pmod{100}] = y[95] = 1$。\n-   对于 $n=1$， $y[(1-5) \\pmod{100}] = y[-4 \\pmod{100}] = y[96] = 1$。\n-   对于 $n=2$， $y[(2-5) \\pmod{100}] = y[-3 \\pmod{100}] = y[97] = 1$。\n-   对于 $n=3$， $y[(3-5) \\pmod{100}] = y[-2 \\pmod{100}] = y[98] = 1$。\n-   对于 $n=4$， $y[(4-5) \\pmod{100}] = y[-1 \\pmod{100}] = y[99] = 1$。\n在所有这些情况下，求和项为 $x[n] \\cdot 1 = 1$。所以，\n$$\nC_{xy}^{\\text{circ}}[5] = \\sum_{n=0}^{4} 1 = 5\n$$\n因此，循环方法在 $k=5$ 个时间窗格的小延迟处产生一个显著的峰值。这是一个“环绕”或“混叠”伪影。它的产生是因为周期性假设将信号的末端（接近 $99$ 的时间窗格）视为紧随着信号的开端（接近 $0$ 的时间窗格）。这错误地暗示了试验结束时的活动（$y[n]$）与试验开始时的活动（$x[n]$）之间存在短延迟相关。对于寻找通常体现在小延迟上的同步性的研究人员来说，这个伪影峰可能会被严重误解为神经元之间存在强而快的相互作用的证据，而真实的关系是一个长延迟。\n\n### 逐项分析\n\n**A. 循环方法由于环绕效应，在延迟 $k = 5$ 个时间窗格处产生一个显著的峰值，而线性方法将相同的重叠置于延迟 $k = -95$ 个时间窗格处；对于非周期性的神经数据，循环方法产生的小延迟峰值是虚假的，因为它将试验结束时的活动与试验开始时的活动混叠在一起。**\n-   我们对循环方法的计算显示，由于环绕效应，在 $k=5$ 处有一个幅度为 $5$ 的峰值。这部分是正确的。\n-   我们对线性方法的计算显示，在 $k=-95$ 处有一个幅度为 $5$ 的峰值。这部分是正确的。注意，延迟 $k=5$ 和 $k=-95$ 在模 $N=100$ 的情况下是等效的，这证实了它们在不同边界条件下代表了相同的重叠。\n-   解释也是正确的。在 $k=5$ 处的峰值是一个伪影（虚假的），它源于将试验结束时的活动与开始时的活动混叠在一起。\n-   **结论：正确。**\n\n**B. 两种方法都产生相同的相关图，在延迟 $k = -95$ 个时间窗格处有一个单一峰值；当脉冲序列是二元时，环绕效应没有影响。**\n-   两种方法不会产生相同的相关图。循环CCF是周期性的，在 $k=5$ 处有一个峰值，而线性CCF是非周期性的，在 $k=5$ 处为零。该说法是错误的。\n-   “对于二元信号，环绕效应没有影响”的说法是无稽之谈。伪影是算法边界假设的函数，而不是数据类型（二元与连续值）的函数。该说法是错误的。\n-   **结论：不正确。**\n\n**C. 循环方法抑制了所有边界效应，并且不产生任何峰值，因为脉冲几乎被整个试验时长隔开；线性方法也由于支撑集不重叠而在任何延迟下都显示没有相关性。**\n-   “循环方法‘抑制边界效应’”的前提与事实恰恰相反；它引入了边界效应。它不会产生“无峰值”；它在 $k=5$ 和 $k=-95$ 处产生强峰值。该说法是错误的。\n-   线性方法确实显示了相关性。通过延迟 $k$ 平移信号的全部目的就是为了在不同的时间偏移下找到相关性，即使原始信号不重叠。它在 $k=-95$ 处找到了一个强峰值。该说法是错误的。\n-   **结论：不正确。**\n\n**D. 在互相关之前对脉冲计数进行去趋势处理可以消除环绕伪影，因此无论周期性假设如何，两种方法都只在 $k = 0$ 个时间窗格附近产生生理上有意义的峰值。**\n-   去趋势（减去均值）并不能消除环绕伪影。正如详细的思考过程所示，即使从每个信号中减去平均发放率后，在 $k=5$ 处的一个大伪影峰依然存在。该说法是错误的。\n-   生理上有意义的峰值位于 $95$ 个时间窗格的延迟处（在我们的约定中为 $k=-95$），对应于 $950$ 毫秒的延迟。它不接近 $k=0$。该陈述的这一部分对于此数据集也与事实不符。\n-   **结论：不正确。**",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "真实世界的数据分析需要将估算与严谨的统计检验相结合。这个综合性练习将挑战你构建一个完整的分析流程：模拟包含已知同步成分的脉冲序列，计算互相关图，以及最关键的，实施非参数置换检验来控制因同时测试多个时间延迟而产生的高假阳性率。这种“最大统计量”方法是现代神经科学家工具箱中的一个强大工具。",
            "id": "4151171",
            "problem": "考虑两个离散时间脉冲计数序列 $x_{t}$ 和 $y_{t}$，它们在持续时间 $T$ 内以固定的时间窗宽度 $d t$ 进行采样，其中 $t \\in \\{0,1,2,\\dots,N-1\\}$ 且 $N = \\lfloor T / d t \\rfloor$。目标是通过互相关图评估神经同步性，同时控制因跨延迟的多重比较而增加的假阳性风险。从以下基础开始：\n\n- 两个等长有限序列 $a_{t}$ 和 $b_{t}$（长度为 $m$）之间的皮尔逊相关系数定义为\n$$\nr(a,b) = \\frac{\\sum_{t=0}^{m-1} (a_{t} - \\bar{a})(b_{t} - \\bar{b})}{\\sqrt{\\sum_{t=0}^{m-1}(a_{t}-\\bar{a})^{2}} \\sqrt{\\sum_{t=0}^{m-1}(b_{t}-\\bar{b})^{2}}},\n$$\n其中 $\\bar{a}$ 和 $\\bar{b}$ 分别是 $a_{t}$ 和 $b_{t}$ 的样本均值。\n\n- $x_{t}$ 和 $y_{t}$ 之间的互相关图是整数延迟 $\\ell$ 的函数，通过计算 $x_{t}$ 和 $y_{t}$ 在该延迟下的重叠片段之间的皮尔逊相关系数来定义，即，对于 $\\ell \\geq 0$\n$$\nr(\\ell) = r\\big(x_{0:(N-1-\\ell)}, y_{\\ell:(N-1)}\\big),\n$$\n对于 $\\ell  0$\n$$\nr(\\ell) = r\\big(x_{(-\\ell):(N-1)}, y_{0:(N-1+\\ell)}\\big).\n$$\n\n- 族别差错率 (Family-Wise Error Rate, FWER) 是在一系列同时进行的假设检验中至少出现一次错误拒绝的概率。在此背景下，每个延迟 $\\ell \\in \\{-L,\\dots,+L\\}$ 定义了一个在该延迟处是否存在超额相关的检验。为了将 FWER 控制在水平 $\\alpha$，您必须使用最大统计量方法：在不存在真实同步性的原假设下，通过将 $y_{t}$ 进行随机偏移量的循环移位（在保持平稳性的允许移位上均匀分布）来生成零替代数据，从而破坏对齐关系，同时保留边缘性质。为每个替代数据计算互相关图，取每个替代数据在所有延迟上的最大绝对相关值，并使用这些最大值的经验 $(1-\\alpha)$ 分位数作为阈值 $t_{\\alpha}$，该阈值控制了整个延迟检验族的 FWER。然后，将那些观测到的绝对相关值超过 $t_{\\alpha}$ 的延迟宣告为显著。\n\n任务。实现一个程序，该程序：\n\n1. 通过结合独立的泊松脉冲生成和附加的同步分量，模拟具有真实神经脉冲结构的分箱脉冲计数序列 $x_{t}$ 和 $y_{t}$：\n   - 独立背景：将 $x_{t}$ 和 $y_{t}$ 的计数作为独立的泊松随机变量在每个时间窗内抽取，其均值分别为 $\\lambda_{x} d t$ 和 $\\lambda_{y} d t$。\n   - 同步分量：在 $[0,T)$ 上以速率 $\\lambda_{\\mathrm{sync}}$ 抽取泊松数量的同步事件，将每个事件时间 $u$ 放置在 $x_{t}$ 中的 $u + \\varepsilon_{x}$ 处和 $y_{t}$ 中的 $u + \\tau + \\varepsilon_{y}$ 处，其中 $\\tau$ 是一个固定的同步延迟，$\\varepsilon_{x}, \\varepsilon_{y}$ 是标准差为 $\\sigma$ 的独立高斯抖动（数值被截断以保持在 $[0,T)$ 内）。通过增加相应时间窗的计数，将这些事件分箱到 $x_{t}$ 和 $y_{t}$ 中。\n\n2. 计算观测到的互相关图 $r(\\ell)$，其中整数延迟 $\\ell \\in \\{-L,\\dots,+L\\}$，$L$ 以秒为单位指定，并通过 $L_{\\mathrm{bins}} = \\lfloor L / d t \\rfloor$ 转换为时间窗数。\n\n3. 通过生成 $y_{t}$ 的 $K$ 个循环移位替代数据（每个替代数据 $y^{(k)}_{t}$ 是 $y_{(t+s_{k}) \\bmod N}$，其中 $s_{k}$ 是随机选择的移位量），为最大统计量构建一个零分布，为每个替代数据计算互相关图 $r^{(k)}(\\ell)$，并记录 $M_{k} = \\max_{\\ell \\in \\{-L,\\dots,+L\\}} \\left| r^{(k)}(\\ell) \\right|$。\n\n4. 将阈值 $t_{\\alpha}$ 确定为 $\\{M_{1},\\dots,M_{K}\\}$ 的经验 $(1-\\alpha)$ 分位数，并返回满足 $\\left| r(\\ell) \\right| \\geq t_{\\alpha}$ 的观测延迟 $\\ell$ 的集合，表示为以秒为单位的延迟值 $\\ell \\cdot d t$，四舍五入到三位小数。\n\n假设和约束：\n- 您必须将 $\\ell$ 视为整数个时间窗，并将延迟值转换为秒作为最终输出。\n- 使用循环移位生成替代数据，以在无同步的原假设下保持 $y_{t}$ 的平稳性，同时破坏其与 $x_{t}$ 的对齐关系。\n- 如果任何重叠片段的方差为零（所有计数相同），则为避免未定义值，将其在该延迟下的相关性定义为 $0$。\n- 所有时间量必须以秒表示；延迟输出必须四舍五入到三位小数（以秒为单位）。\n- 每个测试用例的输出必须是一个浮点数列表（以秒为单位的延迟值），而聚合的程序输出必须是包含每个测试用例的这样一个列表的单一列表。\n\n测试套件：\n为以下参数集实现程序。每个参数集是一个元组，指定了 $(T, d t, \\lambda_{x}, \\lambda_{y}, \\lambda_{\\mathrm{sync}}, \\tau, \\sigma, L, K, \\alpha, \\text{随机种子})$。请使用提供的随机种子以确保确定性输出。\n\n- 情况 1：$(T = \\, 20, d t = \\, 0.005, \\lambda_{x} = \\, 15, \\lambda_{y} = \\, 15, \\lambda_{\\mathrm{sync}} = \\, 5, \\tau = \\, 0, \\sigma = \\, 0.003, L = \\, 0.025, K = \\, 200, \\alpha = \\, 0.05, \\text{随机种子} = \\, 101)$。\n\n- 情况 2：$(T = \\, 20, d t = \\, 0.005, \\lambda_{x} = \\, 15, \\lambda_{y} = \\, 15, \\lambda_{\\mathrm{sync}} = \\, 5, \\tau = \\, 0.015, \\sigma = \\, 0.003, L = \\, 0.025, K = \\, 200, \\alpha = \\, 0.05, \\text{随机种子} = \\, 102)$。\n\n- 情况 3：$(T = \\, 20, d t = \\, 0.005, \\lambda_{x} = \\, 15, \\lambda_{y} = \\, 15, \\lambda_{\\mathrm{sync}} = \\, 0, \\tau = \\, 0, \\sigma = \\, 0, L = \\, 0.025, K = \\, 200, \\alpha = \\, 0.05, \\text{随机种子} = \\, 103)$。\n\n- 情况 4（仅零延迟的边界条件）：$(T = \\, 10, d t = \\, 0.005, \\lambda_{x} = \\, 20, \\lambda_{y} = \\, 20, \\lambda_{\\mathrm{sync}} = \\, 5, \\tau = \\, 0, \\sigma = \\, 0.002, L = \\, 0, K = \\, 200, \\alpha = \\, 0.05, \\text{随机种子} = \\, 104)$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素是对应一个测试用例的显著延迟值列表（以秒为单位，四舍五入到三位小数）。例如，一个有四个测试用例的输出必须看起来像 $[\\,[0.000,0.015],\\,[0.000],\\,[\\,],\\,[0.000]\\,]$，其中空列表 $[\\,]$ 表示没有检测到显著延迟。",
            "solution": "该方法基于统计检验原理和互相关图的定义。我们按步骤进行。\n\n1. 基本定义。对于在持续时间 $T$ 内以时间窗宽度 $d t$ 采样的离散时间脉冲计数序列 $x_{t}$ 和 $y_{t}$，其中时间窗数量为 $N = \\lfloor T / d t \\rfloor$，皮尔逊相关系数对两个等长片段的定义为\n$$\nr(a,b) = \\frac{\\sum_{t=0}^{m-1} (a_{t} - \\bar{a})(b_{t} - \\bar{b})}{\\sqrt{\\sum_{t=0}^{m-1}(a_{t}-\\bar{a})^{2}} \\sqrt{\\sum_{t=0}^{m-1}(b_{t}-\\bar{b})^{2}}}.\n$$\n互相关图 $r(\\ell)$ 跨整数延迟 $\\ell$ 使用此相关性计算重叠片段。对于 $\\ell \\geq 0$，\n$$\nr(\\ell) = r\\big(x_{0:(N-1-\\ell)}, y_{\\ell:(N-1)}\\big),\n$$\n对于 $\\ell  0$，\n$$\nr(\\ell) = r\\big(x_{(-\\ell):(N-1)}, y_{0:(N-1+\\ell)}\\big).\n$$\n如果任一重叠片段的方差为零，则相关性未定义；为保证稳健性，我们设 $r(\\ell) = 0$。\n\n2. 跨延迟的多重比较和族别差错率 (FWER)。在每个延迟 $\\ell \\in \\{-L,\\dots,+L\\}$ 处检验 $H_{0}:\\text{无同步}$ 会引入一系列检验。族别差错率 (FWER) 是 $P(\\text{在这些检验中至少出现一个假阳性})$。如果每个延迟检验都独立地在水平 $\\alpha$ 下进行，则至少出现一个假阳性的概率会随着延迟数量的增加而增加。为了在水平 $\\alpha$ 上控制 FWER 而不使用过于保守的校正，我们采用一种针对跨延迟依赖结构量身定制的最大统计量方法。\n\n3. 最大统计量方法。在不存在真实同步性的原假设 $H_{0}$ 下，一个有效的零程序是通过一个随机偏移量 $s$（在 $\\{0,1,\\dots,N-1\\}$ 上均匀分布）循环移位 $y_{t}$ 以产生 $y^{(k)}_{t} = y_{(t+s_{k}) \\bmod N}$。这保留了 $y_{t}$ 的平稳性和边缘分布，同时破坏了与 $x_{t}$ 的对齐关系。对于每个替代数据 $k \\in \\{1,\\dots,K\\}$，计算在 $\\ell \\in \\{-L_{\\mathrm{bins}},\\dots,+L_{\\mathrm{bins}}\\}$ 上的互相关图 $r^{(k)}(\\ell)$，并记录最大统计量\n$$\nM_{k} = \\max_{\\ell \\in \\{-L_{\\mathrm{bins}},\\dots,+L_{\\mathrm{bins}}\\}} \\left| r^{(k)}(\\ell) \\right|.\n$$\n$M_{k}$ 的零分布近似了 $H_{0}$ 下最大绝对相关的抽样分布。令 $t_{\\alpha}$ 为 $\\{M_{1},\\dots,M_{K}\\}$ 的经验 $(1-\\alpha)$ 分位数。那么\n$$\nP\\left(\\max_{\\ell} \\left| r(\\ell) \\right| \\geq t_{\\alpha} \\,\\big|\\, H_{0}\\right) \\approx \\alpha,\n$$\n这意味着对于该延迟检验族，FWER 被控制在近似 $\\alpha$ 的水平。因此，将满足 $\\left| r(\\ell) \\right| \\geq t_{\\alpha}$ 的延迟 $\\ell$ 宣告为显著，可以得到一组 FWER 受控的发现。\n\n4. 脉冲序列的模拟。为了生成真实的序列，我们结合了独立的泊松背景与同步事件。对每个时间窗，抽取独立计数：\n$$\nx_{t}^{\\text{bg}} \\sim \\text{Poisson}(\\lambda_{x} d t), \\quad y_{t}^{\\text{bg}} \\sim \\text{Poisson}(\\lambda_{y} d t).\n$$\n对于同步分量，以均值 $\\lambda_{\\mathrm{sync}} T$ 抽取泊松数量的事件。对于每个基准时间为 $u$ 的事件，生成扰动后的时间\n$$\nu_{x} = \\mathrm{clip}(u + \\varepsilon_{x}, 0, T), \\quad u_{y} = \\mathrm{clip}(u + \\tau + \\varepsilon_{y}, 0, T),\n$$\n其中 $\\varepsilon_{x}, \\varepsilon_{y} \\sim \\mathcal{N}(0,\\sigma^{2})$。通过增加相应时间窗的计数，将这些时间分箱到 $x_{t}$ 和 $y_{t}$ 中：\n$$\nt_{x} = \\left\\lfloor \\frac{u_{x}}{d t} \\right\\rfloor, \\quad t_{y} = \\left\\lfloor \\frac{u_{y}}{d t} \\right\\rfloor.\n$$\n得到的序列为 $x_{t} = x_{t}^{\\text{bg}} + x_{t}^{\\text{sync}}$ 和 $y_{t} = y_{t}^{\\text{bg}} + y_{t}^{\\text{sync}}$。\n\n5. 算法步骤。\n- 将 $L$ 秒转换为时间窗数：$L_{\\mathrm{bins}} = \\lfloor L / d t \\rfloor$。\n- 对所有整数 $\\ell \\in \\{-L_{\\mathrm{bins}},\\dots,+L_{\\mathrm{bins}}\\}$ 计算观测到的 $r(\\ell)$。\n- 对于 $k = 1$ 到 $K$：从 $\\{0,1,\\dots,N-1\\}$ 中均匀抽取一个随机移位 $s_{k}$，设置 $y^{(k)}_{t} = y_{(t+s_{k}) \\bmod N}$，计算跨延迟的 $r^{(k)}(\\ell)$，记录 $M_{k} = \\max_{\\ell} |r^{(k)}(\\ell)|$。\n- 计算 $t_{\\alpha}$ 作为 $\\{M_{k}\\}$ 的经验 $(1-\\alpha)$ 分位数。\n- 输出集合 $\\{\\ell \\cdot d t : |r(\\ell)| \\geq t_{\\alpha}\\}$，单位为秒，四舍五入到三位小数。\n\n6. 边缘情况和边界条件。如果 $L = 0$，则仅执行零延迟检验；最大统计量简化为零延迟处的绝对相关值。如果任何重叠片段的方差为零，则设置 $r(\\ell) = 0$ 以避免除以零。循环移位替代数据保留了 $y_{t}$ 中的自相关性，但在 $H_{0}$ 下使得其与 $x_{t}$ 的对齐关系实际上是随机的，这证明了其用于零最大统计量的合理性。\n\n7. 输出规范。对于每个测试用例，程序返回一个以秒为单位的显著延迟值列表（四舍五入到三位小数）。最终的程序输出是包含这些列表的逗号分隔列表的单行字符串，并用方括号括起来。输出中所有延迟值的单位都是秒，$\\alpha$ 被指定为小数（例如，0.05）。\n\n通过这些步骤，该实现使用跨延迟的最大统计量来控制族别差错率 (FWER)，为在互相关图中检测同步峰值提供了有统计学原理支持的方法。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_spike_counts(T, dt, rate_x, rate_y, sync_rate, tau, sigma, rng):\n    \"\"\"\n    Simulate binned spike-count sequences x_t and y_t:\n    - Independent Poisson background per bin.\n    - Add synchronous events with jitter and lag tau.\n    \"\"\"\n    N = int(np.floor(T / dt))\n    # Background Poisson counts\n    mean_x = rate_x * dt\n    mean_y = rate_y * dt\n    x_bg = rng.poisson(mean_x, size=N)\n    y_bg = rng.poisson(mean_y, size=N)\n\n    x = x_bg.copy()\n    y = y_bg.copy()\n\n    # Synchronous component\n    if sync_rate  0:\n        n_sync = rng.poisson(sync_rate * T)\n        if n_sync  0:\n            # Draw base event times uniformly over [0, T)\n            base_times = rng.random(n_sync) * T\n            # Jitters\n            jitter_x = rng.normal(0.0, sigma, size=n_sync) if sigma  0 else np.zeros(n_sync)\n            jitter_y = rng.normal(0.0, sigma, size=n_sync) if sigma  0 else np.zeros(n_sync)\n            # Compute event times for x and y, apply lag tau to y\n            times_x = base_times + jitter_x\n            times_y = base_times + tau + jitter_y\n            # Clamp to [0, T)\n            times_x = np.clip(times_x, 0.0, T - 1e-12)\n            times_y = np.clip(times_y, 0.0, T - 1e-12)\n            # Bin indices\n            bins_x = np.floor(times_x / dt).astype(int)\n            bins_y = np.floor(times_y / dt).astype(int)\n            # Increment counts\n            # Multiple events can land in the same bin; use add.at for correctness\n            np.add.at(x, bins_x, 1)\n            np.add.at(y, bins_y, 1)\n\n    return x, y\n\ndef pearson_corr(x_seg, y_seg):\n    \"\"\"\n    Compute Pearson correlation for two equal-length 1D arrays.\n    If std dev of either segment is zero, return 0.\n    Uses sample correlation with denominator (n-1)*std_x*std_y.\n    \"\"\"\n    n = x_seg.size\n    if n  2:\n        return 0.0\n    x_mean = x_seg.mean()\n    y_mean = y_seg.mean()\n    x_center = x_seg - x_mean\n    y_center = y_seg - y_mean\n    sx = x_center.std(ddof=1)\n    sy = y_center.std(ddof=1)\n    if sx == 0 or sy == 0:\n        return 0.0\n    cov = np.dot(x_center, y_center) / (n - 1)\n    return cov / (sx * sy)\n\ndef correlogram(x, y, L_bins):\n    \"\"\"\n    Compute Pearson cross-correlogram r(lag) for lags in [-L_bins, ..., +L_bins].\n    \"\"\"\n    N = x.size\n    lags = np.arange(-L_bins, L_bins + 1, dtype=int)\n    r_vals = np.zeros(lags.shape[0], dtype=float)\n    for i, lag in enumerate(lags):\n        if lag = 0:\n            x_seg = x[:N - lag] if lag != 0 else x\n            y_seg = y[lag:] if lag != 0 else y\n        else:\n            k = -lag\n            x_seg = x[k:]\n            y_seg = y[:N - k]\n        r_vals[i] = pearson_corr(x_seg, y_seg)\n    return lags, r_vals\n\ndef max_stat_threshold(x, y, L_bins, K, alpha, rng):\n    \"\"\"\n    Build null distribution via circular shifts of y and return the (1-alpha) quantile threshold.\n    \"\"\"\n    N = x.size\n    max_vals = np.empty(K, dtype=float)\n    # Precompute shifts\n    shifts = rng.integers(0, N, size=K)\n    for k in range(K):\n        y_shift = np.roll(y, shifts[k])\n        _, r_vals = correlogram(x, y_shift, L_bins)\n        max_vals[k] = np.max(np.abs(r_vals))\n    # Empirical (1 - alpha) quantile; use 'higher' to be conservative in FWER control\n    threshold = np.quantile(max_vals, 1.0 - alpha, method='higher')\n    return threshold\n\ndef run_test_case(params):\n    \"\"\"\n    Execute one test case: simulate data, compute correlogram, compute max-stat threshold,\n    and return list of significant lags (in seconds, rounded to 3 decimals).\n    params: (T, dt, rate_x, rate_y, sync_rate, tau, sigma, L, K, alpha, seed)\n    \"\"\"\n    T, dt, rate_x, rate_y, sync_rate, tau, sigma, L, K, alpha, seed = params\n    rng = np.random.default_rng(seed)\n    x, y = simulate_spike_counts(T, dt, rate_x, rate_y, sync_rate, tau, sigma, rng)\n    L_bins = int(np.floor(L / dt))\n    lags_bins, r_obs = correlogram(x, y, L_bins)\n    thr = max_stat_threshold(x, y, L_bins, K, alpha, rng)\n    sig_mask = np.abs(r_obs) = thr\n    sig_lags_sec = (lags_bins[sig_mask].astype(float) * dt).tolist()\n    # Round to 3 decimals for output\n    sig_lags_sec_rounded = [float(f\"{val:.3f}\") for val in sig_lags_sec]\n    return sig_lags_sec_rounded\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (T, dt, lambda_x, lambda_y, lambda_sync, tau, sigma, L, K, alpha, seed)\n    test_cases = [\n        (20.0, 0.005, 15.0, 15.0, 5.0, 0.0,    0.003, 0.025, 200, 0.05, 101),\n        (20.0, 0.005, 15.0, 15.0, 5.0, 0.015,  0.003, 0.025, 200, 0.05, 102),\n        (20.0, 0.005, 15.0, 15.0, 0.0, 0.0,    0.0,   0.025, 200, 0.05, 103),\n        (10.0, 0.005, 20.0, 20.0, 5.0, 0.0,    0.002, 0.000, 200, 0.05, 104),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Print a single list of lists, each inner list contains floats rounded to 3 decimals.\n    # Build the string manually to ensure formatting.\n    def format_list(lst):\n        return \"[\" + \",\".join(f\"{x:.3f}\" for x in lst) + \"]\"\n    output_str = \"[\" + \",\".join(format_list(r) for r in results) + \"]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}