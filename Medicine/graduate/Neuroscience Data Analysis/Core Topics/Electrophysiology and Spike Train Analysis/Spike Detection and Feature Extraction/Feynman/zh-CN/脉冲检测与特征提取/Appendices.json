{
    "hands_on_practices": [
        {
            "introduction": "神经脉冲检测的第一步通常是设定一个电压阈值，该阈值常根据背景噪声的统计特性来确定。然而，原始的电生理记录往往被偶尔出现的、大幅度的伪迹所污染，这使得基于标准差的传统噪声估计方法不够可靠。本练习将引导你推导并应用一种更为稳健的噪声水平估计方法——中位数绝对偏差（MAD），以确保即使在存在伪迹的情况下也能准确设定检测阈值。",
            "id": "4194221",
            "problem": "在细胞外尖峰检测中，鲁棒的阈值设置需要一个对偶发的大幅度伪影不敏感的背景噪声尺度估计。考虑一个从胞外电极以$f_{s} = 30\\,\\mathrm{kHz}$的采样率记录的电压轨迹$x(t)$。该轨迹中的背景噪声被建模为一个具有未知标准差$\\sigma$的平稳、零均值高斯过程，而伪影是稀疏且非平稳的。现已确定一个持续时间为$0.5\\,\\mathrm{ms}$的无伪影区间$I$，其中包含$15$个样本。区间$I$中的样本（单位为微伏）如下：\n$$\n[-8,\\; 5,\\; -3,\\; 0,\\; 2,\\; -1,\\; 4,\\; -6,\\; 7,\\; -2,\\; 3,\\; -4,\\; 1,\\; -5,\\; 6]\\,\\mu\\mathrm{V}.\n$$\n从中位数的定义、零均值高斯分布的对称性以及正态分布的累积分布函数（CDF）出发，推导精确常数 $k$，使得当 $X \\sim \\mathcal{N}(0,\\sigma^{2})$ 时，有 $\\mathrm{median}(|X|) = k\\,\\sigma$。使用这个 $k$，定义一个基于在无伪影样本上计算的中位数绝对偏差（MAD）的鲁棒噪声尺度估计器，如下所示：\n$$\n\\hat{\\sigma} \\equiv \\frac{\\mathrm{median}(|x_{i}|)}{k}.\n$$\n根据所提供的样本数值计算 $\\hat{\\sigma}$。将你的答案四舍五入到四位有效数字，并以微伏表示最终值。你的最终答案必须是一个实数。",
            "solution": "在尝试求解之前，对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n-   电压轨迹：$x(t)$\n-   采样率：$f_{s} = 30\\,\\mathrm{kHz}$\n-   背景噪声模型：平稳、零均值高斯过程，$X \\sim \\mathcal{N}(0, \\sigma^2)$，具有未知标准差 $\\sigma$。\n-   持续时间为$0.5\\,\\mathrm{ms}$的无伪影区间 $I$。\n-   区间 $I$ 中的样本数：$15$。\n-   区间 $I$ 中的样本：$[-8,\\; 5,\\; -3,\\; 0,\\; 2,\\; -1,\\; 4,\\; -6,\\; 7,\\; -2,\\; 3,\\; -4,\\; 1,\\; -5,\\; 6]\\,\\mu\\mathrm{V}$。\n-   常数 $k$ 的定义：对于 $X \\sim \\mathcal{N}(0,\\sigma^{2})$，有 $\\mathrm{median}(|X|) = k\\,\\sigma$。\n-   估计器的定义：$\\hat{\\sigma} \\equiv \\frac{\\mathrm{median}(|x_{i}|)}{k}$。\n-   要求输出：$\\hat{\\sigma}$ 的数值，四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据、是良定的且客观的。\n1.  **科学合理性**：该问题描述了一种鲁棒的统计估计方法（使用中位数绝对偏差，MAD）来寻找高斯噪声的尺度，这是信号处理和神经科学中的一项标准技术。将背景噪声建模为零均值高斯过程是一种常见且有效的近似。\n2.  **完整性和一致性**：所有必要信息均已提供。样本数量与采样率和区间持续时间一致：$(0.5 \\times 10^{-3}\\,\\mathrm{s}) \\times (30 \\times 10^{3}\\,\\mathrm{s}^{-1}) = 15$ 个样本，这与所提供数据点的数量相符。已知条件是自洽的。\n3.  **良定性**：该问题要求推导一个标准统计常数并将其应用于一个数据集。任务定义清晰，能够导出一个唯一、稳定的解。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将提供完整解答。\n\n### 常数 $k$ 的推导\n设 $X$ 是一个服从零均值高斯分布的随机变量，$X \\sim \\mathcal{N}(0, \\sigma^2)$。我们的任务是找到常数 $k$，使得 $X$ 绝对值的中位数是 $k\\sigma$。设 $Y = |X|$。$Y$ 的中位数，记为 $m_Y$，由性质 $P(Y \\le m_Y) = \\frac{1}{2}$ 定义。\n根据问题陈述，我们有 $m_Y = \\mathrm{median}(|X|) = k\\sigma$。将此代入中位数的定义中：\n$$\nP(|X| \\le k\\sigma) = \\frac{1}{2}\n$$\n这个不等式可以展开为：\n$$\nP(-k\\sigma \\le X \\le k\\sigma) = \\frac{1}{2}\n$$\n为了计算这个概率，我们通过定义 $Z = \\frac{X}{\\sigma}$ 来标准化随机变量 $X$。变量 $Z$ 服从标准正态分布，$Z \\sim \\mathcal{N}(0, 1)$。不等式变为：\n$$\nP(-k \\le Z \\le k) = \\frac{1}{2}\n$$\n设 $\\Phi(z)$ 为标准正态分布的累积分布函数（CDF），定义为 $\\Phi(z) = P(Z \\le z)$。该概率可以用 CDF 表示：\n$$\nP(-k \\le Z \\le k) = \\Phi(k) - \\Phi(-k)\n$$\n由于标准正态分布关于 $0$ 的对称性，我们有恒等式 $\\Phi(-k) = 1 - \\Phi(k)$。将此代入方程中得到：\n$$\n\\Phi(k) - (1 - \\Phi(k)) = \\frac{1}{2}\n$$\n$$\n2\\Phi(k) - 1 = \\frac{1}{2}\n$$\n求解 $\\Phi(k)$：\n$$\n2\\Phi(k) = 1 + \\frac{1}{2} = \\frac{3}{2}\n$$\n$$\n\\Phi(k) = \\frac{3}{4} = 0.75\n$$\n因此，$k$ 是使标准正态分布的累积概率为 $0.75$ 的值。这是标准正态分布的第 75 百分位数，或称第三四分位数。$k$ 的精确解析表达式是标准正态 CDF 在 $0.75$ 处的反函数值：\n$$\nk = \\Phi^{-1}(0.75)\n$$\n至此，常数 $k$ 的推导完成。\n\n### 噪声尺度估计器 $\\hat{\\sigma}$ 的计算\n标准差 $\\sigma$ 的估计器由下式给出：\n$$\n\\hat{\\sigma} = \\frac{\\mathrm{median}(|x_{i}|)}{k}\n$$\n其中 $\\{x_i\\}$ 是所提供的电压样本。步骤如下：\n\n1.  **列出样本：**\n    给定的样本为 $x_i = [-8, 5, -3, 0, 2, -1, 4, -6, 7, -2, 3, -4, 1, -5, 6]$。单位是 $\\mu\\mathrm{V}$。\n\n2.  **计算样本的绝对值：**\n    绝对值集合 $|x_i|$ 为 $[8, 5, 3, 0, 2, 1, 4, 6, 7, 2, 3, 4, 1, 5, 6]$。\n\n3.  **找到绝对值的中位数：**\n    首先，我们将绝对值按非递减顺序排序。排序后的列表是：\n    $$\n    [0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 8]\n    $$\n    共有 $N=15$ 个样本，这是一个奇数。中位数是中间的那个值，位于第 $\\frac{N+1}{2} = \\frac{15+1}{2} = 8$ 个位置。\n    排序后列表中的第 $8$ 个值是 $4$。因此：\n    $$\n    \\mathrm{median}(|x_i|) = 4\\,\\mu\\mathrm{V}\n    $$\n\n4.  **计算 $\\hat{\\sigma}$：**\n    现在我们将中位数和 $k$ 的表达式代入估计器公式中：\n    $$\n    \\hat{\\sigma} = \\frac{4\\,\\mu\\mathrm{V}}{\\Phi^{-1}(0.75)}\n    $$\n    $k = \\Phi^{-1}(0.75)$ 的数值约为 $0.67448975$。\n    $$\n    \\hat{\\sigma} \\approx \\frac{4}{0.67448975}\\,\\mu\\mathrm{V} \\approx 5.930436\\,\\mu\\mathrm{V}\n    $$\n\n5.  **对结果进行四舍五入：**\n    问题要求将答案四舍五入到四位有效数字。$5.930436$ 的前四位有效数字是 $5.930$。第五位数字是 $4$，所以我们向下舍入。\n    $$\n    \\hat{\\sigma} \\approx 5.930\\,\\mu\\mathrm{V}\n    $$\n这个值代表了对背景噪声标准差的鲁棒估计。",
            "answer": "$$\n\\boxed{5.930}\n$$"
        },
        {
            "introduction": "在检测到神经脉冲后，我们通常会从每个脉冲的波形中提取一组特征（如峰值、宽度等），用于后续的脉冲分类。如果这些特征之间高度相关，即存在多重共线性，会严重影响分类算法的性能和稳定性。本练习通过一个编程实践，教你如何使用方差膨胀因子（VIF）这一强大的统计工具，来量化特征之间的冗余度，并系统地剔除高度相关的特征，从而为后续的脉冲分类（Spike Sorting）构建一个更优的特征集。",
            "id": "4194200",
            "problem": "给定一个用于胞外神经脉冲放电分类的特征工程的数学抽象模型。对于每个脉冲放电事件，会根据其波形构建一个特征向量。目标是标准化特征，分析其协方差以理解冗余性，并使用方差膨胀因子 (VIF) 避免多重共线性。您必须实现一个完全确定性的程序，该程序在指定条件下生成合成特征数据集，对特征进行标准化，计算样本协方差矩阵，然后使用 VIF 迭代地移除冗余特征，直到满足指定的冗余阈值为止。程序必须生成单行输出，汇总每个测试用例所选出的特征索引。\n\n仅使用统计信号处理和多元分析中的标准定义和事实，并在神经科学数据分析的背景下进行解释：\n- 特征标准化 (z-score 标准化)：对于每个特征维度（列），减去根据数据计算出的经验均值，然后除以经验标准差。\n- 无偏样本协方差矩阵使用分母 $n-1$ 计算，其中 $n$ 是样本数（脉冲放电数）。\n- 特征的方差膨胀因子 (VIF) 量化了由于其与其他特征的线性依赖性而导致的方差膨胀程度。对于特征 $j$，其定义为 $VIF_j = \\dfrac{1}{1 - R_j^2}$，其中 $R_j^2$ 是通过普通最小二乘法将特征 $j$ 对所有其他特征进行回归时的决定系数。\n- 为确保计算 $R_j^2$ 时普通最小二乘法的数值鲁棒性，必要时使用 Moore–Penrose 伪逆进行线性求解。\n\n您的程序必须为每个测试用例实现以下步骤：\n1. 根据该测试用例指定的生成模型，生成一个合成特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$。所有随机抽样必须使用指定的种子和独立的标准正态变量。所有特征均为实值且无量纲。\n2. 对特征进行 z-score 标准化（即，通过减去列均值并除以使用分母 $n-1$ 计算的列标准差来标准化 $X$ 的每一列）。\n3. 使用分母 $n-1$ 计算标准化数据的无偏样本协方差矩阵 $S$。\n4. 通过使用普通最小二乘法将每个特征对所有其余特征进行回归并计算 $R^2$ 来计算该特征的方差膨胀因子 (VIF)；然后计算 $VIF = 1/(1 - R^2)$。如果出现数值奇异性，则使用 Moore–Penrose 伪逆获得最小二乘解。给定种子后，所有计算必须是确定性的。\n5. 迭代消除特征以强制执行 VIF 阈值 $\\tau$：当任何特征的 VIF 超过 $\\tau$ 时，移除具有最大 VIF 的单个特征。如果在 $10^{-12}$ 的容差内存在并列情况，则移除具有最大原始列索引的特征。每次移除后，对剩余的特征重新计算 z-score 标准化、样本协方差矩阵和 VIF。当所有剩余特征的 VIF 均小于或等于 $\\tau$，或者只剩下一个特征时，停止操作。\n6. 返回保留的特征索引，形式为按升序排序的原始 0-索引列索引列表。\n\n测试套件。严格实现以下三个测试用例，按规定逐列生成 $X$。在每个用例中，$g_0, g_1, \\dots$ 表示在 $\\mathbb{R}^n$ 中的独立标准正态向量，使用给定的种子进行采样。所有平方根均为主根。在整个测试用例中使用相同的种子，按需顺序生成所有必需的 $g_k$ 和任何共享的潜在变量。为清晰起见，用 $n$ 表示脉冲放电数（行），用 $p$ 表示特征数（列）。\n\n- 测试用例 A（强两两相关和中度耦合）：\n  - 种子：$271828$。\n  - 维度：$n = 1500$, $p = 4$。\n  - 阈值：$\\tau = 5$。\n  - 构建方法：\n    - $x_0 = g_0$。\n    - $x_1 = 0.95\\,x_0 + \\sqrt{1 - 0.95^2}\\,g_1$。\n    - $x_2 = g_2$。\n    - $x_3 = 0.6\\,x_2 + \\sqrt{1 - 0.6^2}\\,g_3$。\n    - 通过列拼接形成 $X = [x_0, x_1, x_2, x_3]$。\n\n- 测试用例 B（具有弱共享潜在驱动因素的近正交特征）：\n  - 种子：$161803$。\n  - 维度：$n = 1200$, $p = 5$。\n  - 阈值：$\\tau = 5$。\n  - 构建方法：\n    - 令 $s$ 为长度为 $n$ 的标准正态向量。\n    - 对于 $j \\in \\{0,1,2,3,4\\}$，设置 $x_j = g_j + 0.05\\,s$。\n    - 形成 $X = [x_0, x_1, x_2, x_3, x_4]$。\n\n- 测试用例 C（复合多重共线性，包括一个近线性组合和一个高度相关的对）：\n  - 种子：$314159$。\n  - 维度：$n = 1000$, $p = 6$。\n  - 阈值：$\\tau = 4$。\n  - 构建方法：\n    - $x_0 = g_0$。\n    - $x_1 = g_1$。\n    - $x_2 = g_2$。\n    - $x_3 = x_0 + x_1 + 0.05\\,g_3$。\n    - $x_4 = 0.9\\,x_2 + \\sqrt{1 - 0.9^2}\\,g_4$。\n    - $x_5 = g_5$。\n    - 形成 $X = [x_0, x_1, x_2, x_3, x_4, x_5]$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表包含了三个测试用例的保留索引列表，并用一对总的方括号括起来。每个内部列表也用方括号括起来，并包含按升序排列的保留的原始特征索引。例如，一个有效的输出格式形如 $[[i_{A,1}, i_{A,2}, \\dots], [i_{B,1}, \\dots], [i_{C,1}, \\dots]]$，不含任何额外文本。条目必须是整数。不涉及物理单位，也不存在角度。",
            "solution": "该问题要求实现一个基于方差膨胀因子 (VIF) 的确定性特征选择算法。该过程涉及生成具有指定相关结构的合成数据集，然后通过迭代程序移除表现出高度多重共线性的特征，直到满足给定的阈值为止。本解决方案严格遵守所提供的定义和步骤。\n\n### 基于原则的设计\n\n该解决方案围绕多元统计分析的核心原则设计，专门解决特征集中的多重共线性问题。\n\n1.  **合成数据生成**：此问题的基础是创建合成特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$。为每个测试用例提供的生成模型是基于独立标准正态变量（表示为 $g_k \\in \\mathbb{R}^n$）的线性构造。此方法是创建具有精确控制的、先验已知的相关结构的数据集的标准实践。此类数据集对于验证统计算法的正确性和性能非常宝贵，因为预期的结果通常可以从数据的构造中推断出来。例如，一个定义为 $x_1 = \\rho x_0 + \\sqrt{1-\\rho^2} g_1$ 的特征，其与特征 $x_0$ 的理论相关性为 $\\rho$，这使得可以直接测试算法检测这种关系的能力。\n\n2.  **特征标准化 (Z-score 标准化)**：在评估多重共线性之前，所有特征都经过标准化。对于数据矩阵 $X$ 中的每个特征向量（列）$x_j$，其标准化对应项 $z_j$ 的计算方式如下：\n    $$ z_{ij} = \\frac{x_{ij} - \\mu_j}{\\sigma_j} $$\n    其中 $\\mu_j$ 是特征 $j$ 的经验均值，$\\sigma_j$ 是其经验标准差，计算时使用分母 $n-1$（方差的无偏估计量）。标准化将所有特征转换到同一尺度（零均值和单位方差），这至关重要，原因有二：它防止具有较大尺度的特征对分析产生不成比例的影响，并且它使得标准化数据的样本协方差矩阵等同于样本相关矩阵。\n\n3.  **方差膨胀因子 (VIF)**：VIF 是量化多重共线性的核心指标。对于给定的特征 $j$，其 VIF 定义为：\n    $$ VIF_j = \\frac{1}{1 - R_j^2} $$\n    此处，$R_j^2$ 是将特征 $j$（作为响应变量）对所有其他特征（作为预测变量）进行普通最小二乘法 (OLS) 回归得到的决定系数。一个高的 $R_j^2$ 值（接近 1）表明特征 $j$ 可以被其他特征的线性组合准确预测，这意味着冗余。因此，一个高的 VIF 值预示着严重的多重共线性。一个常见的经验法则是，认为 $VIF > 5$ 或 $VIF > 10$ 是有问题的。\n\n4.  **通过普通最小二乘法 (OLS) 计算 $R^2$**：根据问题的明确指示，为每个特征计算 $R_j^2$。给定标准化特征矩阵 $Z$，我们选择一列 $z_j$ 作为响应向量 $y$，其余列作为预测变量矩阵 $Z_{\\text{others}}$。OLS 问题是找到系数向量 $\\beta$，以最小化模型 $y \\approx Z_{\\text{others}} \\beta$ 中的残差平方和。为了数值稳定性，特别是在接近奇异的情况下，使用 Moore-Penrose 伪逆来找到解：\n    $$ \\beta = (Z_{\\text{others}}^\\dagger) y $$\n    预测的响应为 $\\hat{y} = Z_{\\text{others}} \\beta$。由于数据是中心化的（均值为零），总平方和 (TSS) 和解释平方和 (ESS) 简化为 $TSS = \\sum y_i^2$ 和 $ESS = \\sum \\hat{y}_i^2$。然后，决定系数可以稳健地计算为：\n    $$ R_j^2 = \\frac{ESS}{TSS} = \\frac{\\sum \\hat{y}_i^2}{\\sum y_i^2} $$\n\n5.  **迭代特征消除**：采用贪婪后向消除策略来减少多重共线性。该算法按以下步骤进行：\n    a.  从完整的特征集开始。\n    b.  在每次迭代中，计算当前集合中每个特征的 VIF。这需要对当前的特征子集重新进行标准化，并重新计算所有的 VIF。\n    c.  识别最大的 VIF 值，$VIF_{\\text{max}}$。\n    d.  如果 $VIF_{\\text{max}}$ 小于或等于指定的阈值 $\\tau$，则过程终止，因为剩余的特征满足了期望的冗余标准。\n    e.  如果 $VIF_{\\text{max}} > \\tau$，则移除具有最高 VIF 的单个特征。应用一个特定的并列处理规则：如果多个特征共享最高的 VIF（在 $10^{-12}$ 的容差范围内），则消除具有最大原始列索引的那个。\n    f.  重复此过程，直到满足 (d) 中的条件或只剩下一个特征为止。\n\n这种迭代的、确定性的过程确保了最冗余的特征被逐步移除，从而得到一个具有受控多重共线性的最终特征集。最终输出是经过此消除过程后幸存下来的特征的原始 0-索引的排序列表。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n\n    def generator_A(n, rng):\n        \"\"\"Generates data for Test Case A.\"\"\"\n        g0 = rng.standard_normal(n)\n        g1 = rng.standard_normal(n)\n        g2 = rng.standard_normal(n)\n        g3 = rng.standard_normal(n)\n        x0 = g0\n        x1 = 0.95 * x0 + np.sqrt(1 - 0.95**2) * g1\n        x2 = g2\n        x3 = 0.6 * x2 + np.sqrt(1 - 0.6**2) * g3\n        return np.column_stack([x0, x1, x2, x3])\n\n    def generator_B(n, rng):\n        \"\"\"Generates data for Test Case B.\"\"\"\n        s = rng.standard_normal(n)\n        columns = []\n        for _ in range(5):\n            g = rng.standard_normal(n)\n            x = g + 0.05 * s\n            columns.append(x)\n        return np.column_stack(columns)\n\n    def generator_C(n, rng):\n        \"\"\"Generates data for Test Case C.\"\"\"\n        g0 = rng.standard_normal(n)\n        g1 = rng.standard_normal(n)\n        g2 = rng.standard_normal(n)\n        g3 = rng.standard_normal(n)\n        g4 = rng.standard_normal(n)\n        g5 = rng.standard_normal(n)\n        x0 = g0\n        x1 = g1\n        x2 = g2\n        x3 = x0 + x1 + 0.05 * g3\n        x4 = 0.9 * x2 + np.sqrt(1 - 0.9**2) * g4\n        x5 = g5\n        return np.column_stack([x0, x1, x2, x3, x4, x5])\n\n    test_cases = [\n        {'n': 1500, 'p': 4, 'tau': 5, 'seed': 271828, 'generator': generator_A},\n        {'n': 1200, 'p': 5, 'tau': 5, 'seed': 161803, 'generator': generator_B},\n        {'n': 1000, 'p': 6, 'tau': 4, 'seed': 314159, 'generator': generator_C},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = process_case(case['n'], case['p'], case['tau'], case['seed'], case['generator'])\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    formatted_results = ','.join(map(str, all_results))\n    print(f\"[{formatted_results}]\")\n\ndef calculate_vifs_ols(standardized_features):\n    \"\"\"\n    Calculates VIF for each feature by regressing it on the others.\n    \"\"\"\n    n_samples, num_features = standardized_features.shape\n    vifs = np.zeros(num_features)\n\n    for i in range(num_features):\n        y = standardized_features[:, i]\n        \n        # Create predictor matrix excluding the current feature\n        X_reg = np.delete(standardized_features, i, axis=1)\n\n        # Handle edge case where there's only one predictor\n        if X_reg.shape[1] == 0:\n            vifs[i] = 1.0\n            continue\n        \n        # Solve for regression coefficients using Moore-Penrose pseudoinverse\n        beta = np.linalg.pinv(X_reg) @ y\n        \n        # Calculate predicted values\n        y_hat = X_reg @ beta\n        \n        # Calculate R^2. For standardized data, TSS = sum(y**2)\n        tss = np.sum(y**2)\n        ess = np.sum(y_hat**2)\n        \n        if tss  1e-12:\n            # If TSS is zero, the feature column was constant (zero variance),\n            # which is perfectly predictable. R^2 is 1.\n            r_squared = 1.0\n        else:\n            r_squared = ess / tss\n            # Clamp to 1.0 to handle potential floating point inaccuracies\n            r_squared = min(r_squared, 1.0)\n            \n        # Calculate VIF from R^2\n        if 1.0 - r_squared  1e-12:\n            vifs[i] = np.inf\n        else:\n            vifs[i] = 1.0 / (1.0 - r_squared)\n            \n    return vifs\n\ndef process_case(n, p, tau, seed, generator_func):\n    \"\"\"\n    Processes a single test case: generates data and iteratively removes features based on VIF.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = generator_func(n, rng)\n    \n    original_indices = list(range(p))\n    \n    while True:\n        num_features = len(original_indices)\n        if num_features = 1:\n            break\n            \n        current_features = X[:, original_indices]\n        \n        # Step 2: Perform z-scoring on the current set of features\n        mean = np.mean(current_features, axis=0)\n        std = np.std(current_features, axis=0, ddof=1)\n        \n        # To avoid division by zero for constant features\n        std[std == 0] = 1.0\n        \n        standardized_features = (current_features - mean) / std\n\n        # Step 4: Compute VIF for each feature using OLS\n        vifs = calculate_vifs_ols(standardized_features)\n        \n        # Step 5: Iteratively eliminate features\n        max_vif = np.max(vifs)\n        \n        if max_vif = tau:\n            break\n            \n        # Find all features with VIF close to the max (tie-breaking)\n        candidates = np.where(vifs >= max_vif - 1e-12)[0]\n        \n        # Map local indices of candidates to their original indices\n        candidate_original_indices = [original_indices[i] for i in candidates]\n        \n        # Remove the one with the largest original index\n        idx_to_remove = max(candidate_original_indices)\n        original_indices.remove(idx_to_remove)\n        \n    original_indices.sort()\n    return original_indices\n\nsolve()\n```"
        },
        {
            "introduction": "构建脉冲检测算法后，定量评估其性能至关重要。接收者操作特征（ROC）曲线和精确率-召回率（PR）曲线是评估二元分类器性能的两种标准方法。本练习将指导你从零开始编写代码，实现这两种曲线的构建和相关性能指标的计算。通过这个过程，你不仅能掌握评估检测器的核心技能，还能深刻理解为何在神经科学数据中（通常脉冲事件是稀有的，即类别不平衡），PR曲线往往比ROC曲线更具信息量。",
            "id": "4194179",
            "problem": "给定细胞外峰电位检测实验的检测输出，其形式为实值分数和二元基准真相标签，用于指示每个带时间戳的观测是否对应于一个真实的峰电位事件。目标是通过在所有唯一分数水平上扫描决策阈值，从第一性原理出发推导出受试者工作特征 (ROC) 曲线和精确率-召回率 (PR) 曲线，计算这些曲线下的面积，并评估在类别不平衡的情况下哪条曲线信息量更大。您必须构建一个完整的、可运行的程序，该程序在固定的测试套件上执行这些步骤，并以指定格式输出所要求的指标。\n\n将要使用的基本依据和定义：\n- 给定一组由 $i \\in \\{1,\\dots,M\\}$ 索引的观测值，令分数为 $s_i \\in \\mathbb{R}$，基准真相标签为 $y_i \\in \\{0,1\\}$，其中 $y_i = 1$ 表示真实峰电位，$y_i = 0$ 表示非峰电位。\n- 对于任何决策阈值 $\\tau \\in \\mathbb{R}$，如果 $s_i \\ge \\tau$，则预测类别为 $\\hat{y}_i(\\tau) = 1$，否则为 $\\hat{y}_i(\\tau) = 0$。\n- 令 $P = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 1\\}$ 为正例总数，$N = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 0\\}$ 为负例总数。假设 $P \\ge 1$ 且 $N \\ge 1$。\n- 在阈值 $\\tau$ 下，根据标准定义，定义混淆矩阵计数：真阳性 $TP(\\tau)$、假阳性 $FP(\\tau)$、假阴性 $FN(\\tau)$ 和真阴性 $TN(\\tau)$。由此定义：\n  - 真阳性率（也称为灵敏度或召回率）$TPR(\\tau) = \\dfrac{TP(\\tau)}{P}$。\n  - 假阳性率 $FPR(\\tau) = \\dfrac{FP(\\tau)}{N}$。\n  - 精确率 $Prec(\\tau) = \\dfrac{TP(\\tau)}{TP(\\tau) + FP(\\tau)}$，当 $TP(\\tau) + FP(\\tau) \\ge 1$ 时。\n\n曲线构建要求：\n- 将 ROC 曲线构建为点集 $\\{(FPR(\\tau), TPR(\\tau))\\}$，这些点是通过将 $\\tau$ 在按严格降序排列的唯一分数集 $U = \\{u_1, u_2, \\dots, u_K\\}$ 上扫描得到的，并包括由 $\\tau = +\\infty$ 和 $\\tau = -\\infty$ 分别隐含的端点 $(0,0)$ 和 $(1,1)$。在每个唯一的分数水平上，所有分数相同的项必须同时包含在预测集中。\n- 将 PR 曲线构建为点集 $\\{(Rec(\\tau), Prec(\\tau))\\}$，其中 $Rec(\\tau) = TPR(\\tau)$，在按降序排列的相同阈值序列 $U$ 上计算，并将其解释为召回率的右连续阶梯函数。\n\n曲线下面积定义：\n- 将 ROC 曲线下面积 $AUC_{\\mathrm{ROC}}$ 定义为 $TPR$ 对 $FPR$ 在 $[0,1]$ 上的黎曼积分，通过梯形法则对由升序 $FPR$ 的 ROC 点构成的分段线性路径进行数值计算。\n- 将 PR 曲线下面积 $AUC_{\\mathrm{PR}}$ 定义为 $Prec$ 对 $Rec$ 在 $[0,1]$ 上的黎曼-斯蒂尔杰斯积分，使用右连续精确率作为阶梯式求和进行数值计算：如果 $(Rec_k, Prec_k)$ 是按召回率非递减顺序排列的 PR 点，且 $Rec_0 = 0$，则\n  $$AUC_{\\mathrm{PR}} = \\sum_{k=1}^{K} \\left(Rec_k - Rec_{k-1}\\right) \\cdot Prec_k.$$\n\n类别不平衡下的信息量：\n- 令流行率为 $\\pi = \\dfrac{P}{P+N}$。考虑与随机基线的归一化偏差：\n  - 对于 ROC，随机基线为 $0.5$，因此定义 $I_{\\mathrm{ROC}} = \\dfrac{AUC_{\\mathrm{ROC}} - 0.5}{0.5}$。\n  - 对于 PR，随机基线为 $\\pi$，因此定义 $I_{\\mathrm{PR}} = \\dfrac{AUC_{\\mathrm{PR}} - \\pi}{1 - \\pi}$，其中 $\\pi \\in [0,1)$。\n- 定义布尔指示符 $B$ 来表示 PR 是否比 ROC 更具信息量，其定义为 $B = \\mathbb{1}\\{I_{\\mathrm{PR}}  I_{\\mathrm{ROC}}\\}$。\n\n任务：\n- 实现一个程序，对于每个测试用例，通过在唯一分数上按严格降序扫描阈值来构建上述的 ROC 和 PR 曲线，计算 $AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$，计算 $\\pi$、$I_{\\mathrm{ROC}}$、$I_{\\mathrm{PR}}$，然后计算 $B$。\n- 对于数值报告，将 $AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$ 四舍五入到 $6$ 位小数。布尔值 $B$ 必须报告为字面量 $True$ 或 $False$。\n\n测试套件：\n提供以下三个测试用例，每个用例都是一个列表对 $(\\mathbf{s}, \\mathbf{y})$，其中 $\\mathbf{s}$ 是分数，$\\mathbf{y}$ 是标签：\n- 用例 1 (中度可分，大致平衡)：\n  - $\\mathbf{s}^{(1)} = [\\,0.95,\\,0.90,\\,0.85,\\,0.80,\\,0.75,\\,0.70,\\,0.65,\\,0.60,\\,0.55,\\,0.50,\\,0.45,\\,0.40\\,]$\n  - $\\mathbf{y}^{(1)} = [\\,1,\\,1,\\,1,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0\\,]$\n- 用例 2 (严重不平衡，且在低分附近有一个困难正例)：\n  - $\\mathbf{s}^{(2)} = [\\,0.99,\\,0.80,\\,0.75,\\,0.70,\\,0.65,\\,0.60,\\,0.58,\\,0.57,\\,0.56,\\,0.55,\\,0.54,\\,0.53,\\,0.52,\\,0.50,\\,0.49,\\,0.48,\\,0.30,\\,0.25,\\,0.20,\\,0.10\\,]$\n  - $\\mathbf{y}^{(2)} = [\\,1,\\,1,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\,]$\n- 用例 3 (所有分数相同；边界行为)：\n  - $\\mathbf{s}^{(3)} = [\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50,\\,0.50\\,]$\n  - $\\mathbf{y}^{(3)} = [\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\,]$\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个列表的列表形式的结果，每个内部列表对应一个测试用例，顺序与上述相同。每个内部列表必须是 $[AUC\\_{{ROC}}, AUC\\_{{PR}}, B]$ 的形式，其中 $AUC\\_{{ROC}}$ 和 $AUC\\_{{PR}}$ 是四舍五入到 $6$ 位小数的浮点数，而 $B$ 是一个布尔值。例如，一个包含三个测试用例的输出必须看起来完全像\n  \"[[0.812345,0.701234,True],[0.923456,0.812345,True],[0.500000,0.300000,False]]\"\n不带任何多余的空格和附加文本。",
            "solution": "该问题要求实现一个算法，用于根据一组给定的检测分数和基准真相标签来计算受试者工作特征 (ROC) 曲线和精确率-召回率 (PR) 曲线，以及它们各自的曲线下面积（$AUC_{\\mathrm{ROC}}$ 和 $AUC_{\\mathrm{PR}}$）。此外，它还要求比较它们在类别不平衡情况下的信息量。整个过程必须按规定从第一性原理出发进行推导。\n\n该方法的核心是在不同的决策阈值下评估分类性能。如果一个样本的分数 $s_i$ 大于或等于阈值 $\\tau$，则该样本被分类为正例，即若 $s_i \\ge \\tau$ 则 $\\hat{y}_i(\\tau) = 1$。通过将 $\\tau$ 从 $+\\infty$ 降至 $-\\infty$ 进行变化，我们可以追踪分类器的性能，这构成了 ROC 和 PR 曲线的基础。\n\n首先，让我们确定必要的量。给定 $M$ 个观测值，每个观测值都有一个分数 $s_i$ 和一个二元标签 $y_i \\in \\{0, 1\\}$。正例（真实峰电位）的总数是 $P = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 1\\}$，负例（非峰电位）的总数是 $N = \\sum_{i=1}^{M} \\mathbb{1}\\{y_i = 0\\}$。问题假设 $P \\ge 1$ 且 $N \\ge 1$。\n\n在给定的阈值 $\\tau$ 下，二元分类的四个基本结果是：\n- 真阳性 ($TP(\\tau)$)：$s_i \\ge \\tau$ 且 $y_i = 1$ 的实例数量。\n- 假阳性 ($FP(\\tau)$)：$s_i \\ge \\tau$ 且 $y_i = 0$ 的实例数量。\n- 真阴性 ($TN(\\tau)$)：$s_i  \\tau$ 且 $y_i = 0$ 的实例数量。\n- 假阴性 ($FN(\\tau)$)：$s_i  \\tau$ 且 $y_i = 1$ 的实例数量。\n\n由此，我们定义关键比率：\n- 真阳性率 (TPR) 或召回率 (Recall)：$TPR(\\tau) = Rec(\\tau) = \\frac{TP(\\tau)}{P}$。这是被正确识别的实际正例的比例。\n- 假阳性率 (FPR)：$FPR(\\tau) = \\frac{FP(\\tau)}{N}$。这是被错误识别为正例的实际负例的比例。\n- 精确率 (Precision)：$Prec(\\tau) = \\frac{TP(\\tau)}{TP(\\tau) + FP(\\tau)}$，当 $TP(\\tau) + FP(\\tau) \\ge 1$ 时定义。这是预测为正例的实例中实际正确的比例。\n\n算法流程如下：\n\n**步骤 1：数据准备与排序**\n高效构建这些曲线的基本思路是，$TP(\\tau)$、$FP(\\tau)$ 以及所有派生指标的值仅在阈值 $\\tau$ 越过数据中存在的分数值时才会改变。因此，我们无需连续扫描 $\\tau$，只需将唯一的得分值作为阈值来考虑。\n\n问题要求我们将唯一分数按严格降序排列。一个更稳健和标准的算法，它能按规定正确处理分数并列的情况，是对所有单个观测值进行排序。我们将分数 $s_i$ 和标签 $y_i$ 组合成对 $(s_i, y_i)$，并根据分数 $s_i$ 按降序对这些对进行排序。在分数并列的情况下，标签的相对顺序不影响该阈值水平下累积 $TP$ 和 $FP$ 计数的计算。\n\n**步骤 2：曲线点生成**\n我们遍历排序后的观测值列表，这实际上是在降低决策阈值。问题规定，所有分数相同的项必须同时被包括。这可以通过按分数分组处理观测值来实现。\n\n让我们初始化累积计数 $TP_{cum} = 0$ 和 $FP_{cum} = 0$。这对应于一个阈值 $\\tau  \\max(s_i)$，此时没有任何东西被分类为正例。这为我们提供了 ROC 曲线的起点 $(FPR, TPR) = (0, 0)$。\n\n然后，我们遍历排序后的观测值，按分数对它们进行分组。对于每个具有唯一分数值 $u$ 的观测值组：\n1.  计算该组内的正例数（$\\Delta TP$）和负例数（$\\Delta FP$）。\n2.  更新累积计数：$TP_{cum} \\leftarrow TP_{cum} + \\Delta TP$ 和 $FP_{cum} \\leftarrow FP_{cum} + \\Delta FP$。这些更新后的计数代表了阈值为 $\\tau=u$ 时的总真阳性和假阳性数。\n3.  计算曲线上的新点：\n    -   $FPR_{new} = \\frac{FP_{cum}}{N}$\n    -   $TPR_{new} = \\frac{TP_{cum}}{P}$\n    -   $Prec_{new} = \\frac{TP_{cum}}{TP_{cum} + FP_{cum}}$\n4.  生成一个新的 ROC 点 $(FPR_{new}, TPR_{new})$ 和一个新的 PR 点 $(TPR_{new}, Prec_{new})$。对所有唯一的分数值重复此过程。处理完所有观测值后的最终状态将是 $TP_{cum} = P$ 和 $FP_{cum} = N$，从而得到 ROC 的终点 $(1, 1)$。\n\n**步骤 3：曲线下面积 (AUC) 计算**\n- **$AUC_{\\mathrm{ROC}}$**：ROC 曲线是由生成的 $(FPR, TPR)$ 点组成的集合，从 $(0,0)$ 开始到 $(1,1)$ 结束。面积是使用梯形法则在连接这些点的分段线性路径上计算的，这些点按 $FPR$ 递增排序。对于一系列 ROC 点 $(x_k, y_k)$，其中 $x_k = FPR_k$ 和 $y_k = TPR_k$，面积为：\n  $$AUC_{\\mathrm{ROC}} = \\sum_{k=1}^{L} \\frac{(y_k + y_{k-1})}{2} (x_k - x_{k-1})$$\n  其中 $L+1$ 是 ROC 路径中的点数。\n- **$AUC_{\\mathrm{PR}}$**：PR 曲线由点 $(Rec_k, Prec_k)$ 给出，其中 $Rec_k = TPR_k$。面积被定义为一个右连续阶梯函数的积分。所提供的公式是该积分的数值计算，等同于通常所说的平均精确率 (Average Precision)：\n  $$AUC_{\\mathrm{PR}} = \\sum_{k=1}^{K} (Rec_k - Rec_{k-1}) \\cdot Prec_k$$\n  这里，$(Rec_k, Prec_k)$ 是按召回率非递减顺序生成的 PR 点，并且我们定义 $Rec_0 = 0$。总和中的每一项代表一个高度为 $Prec_k$、宽度为 $(Rec_k - Rec_{k-1})$（即在步骤 $k$ 的召回率增量）的矩形面积。\n\n**步骤 4：信息量比较**\n通过将曲线的 AUC 值相对于随机分类器的性能进行归一化，来评估其信息量。\n- 对于 ROC，随机分类器产生的 $AUC_{\\mathrm{ROC}}$ 为 $0.5$。归一化信息为 $I_{\\mathrm{ROC}} = \\frac{AUC_{\\mathrm{ROC}} - 0.5}{0.5}$。\n- 对于 PR，随机分类器产生的 $AUC_{\\mathrm{PR}}$ 等于正类的流行率 $\\pi = \\frac{P}{P+N}$。归一化信息为 $I_{\\mathrm{PR}} = \\frac{AUC_{\\mathrm{PR}} - \\pi}{1 - \\pi}$。\n布尔指示符 $B = \\mathbb{1}\\{I_{\\mathrm{PR}}  I_{\\mathrm{ROC}}\\}$ 决定了在此特定归一化下，PR 曲线是否比 ROC 曲线更具信息量。这种比较在类别不平衡（即 $\\pi$ 远非 $0.5$）的情况下尤其重要，在这种情况下，PR 曲线通常被认为是比 ROC 曲线更敏感的性能度量。ROC 基线是恒定的，而 PR 基线随不平衡性而变化，使得后者成为一个更具挑战性的基准。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the full analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (moderately separable, roughly balanced)\n        (\n            [0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50, 0.45, 0.40],\n            [1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n        ),\n        # Case 2 (severely imbalanced with a hard positive near low score)\n        (\n            [0.99, 0.80, 0.75, 0.70, 0.65, 0.60, 0.58, 0.57, 0.56, 0.55, 0.54, 0.53, 0.52, 0.50, 0.49, 0.48, 0.30, 0.25, 0.20, 0.10],\n            [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n        ),\n        # Case 3 (all scores tied; boundary behavior)\n        (\n            [0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50],\n            [1, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n        )\n    ]\n\n    all_results = []\n    for scores, labels in test_cases:\n        result = _calculate_metrics(np.array(scores), np.array(labels))\n        all_results.append(result)\n\n    # Format the final output string\n    formatted_results = []\n    for auc_roc, auc_pr, b_flag in all_results:\n        formatted_results.append(f\"[{auc_roc:.6f},{auc_pr:.6f},{str(b_flag)}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _calculate_metrics(scores, labels):\n    \"\"\"\n    Calculates ROC/PR AUC and informativeness for a single test case.\n    \"\"\"\n    # Total number of positive and negative samples\n    pos_total = np.sum(labels == 1)\n    neg_total = len(labels) - pos_total\n\n    # The problem assumes P>=1 and N>=1, so no need to check for zero division here.\n    \n    # Combine scores and labels, then sort by score descending.\n    # A secondary sort key is not strictly needed for the logic but is good practice.\n    indices = np.argsort(scores, kind='mergesort')[::-1]\n    sorted_scores = scores[indices]\n    sorted_labels = labels[indices]\n    \n    roc_fpr = [0.0]\n    roc_tpr = [0.0]\n    pr_points = []\n\n    tp_cum = 0\n    fp_cum = 0\n    i = 0\n    while i  len(sorted_scores):\n        current_score = sorted_scores[i]\n        \n        # Group all items with the same score\n        j = i\n        while j  len(sorted_scores) and sorted_scores[j] == current_score:\n            j += 1\n        \n        # Count positives and negatives in this tied-score group\n        labels_in_group = sorted_labels[i:j]\n        delta_tp = np.sum(labels_in_group == 1)\n        \n        # Update cumulative counts. This happens after processing the group.\n        tp_cum += delta_tp\n        fp_cum += (j - i) - delta_tp\n\n        # Calculate metrics for this new threshold level\n        tpr = tp_cum / pos_total\n        fpr = fp_cum / neg_total\n        \n        roc_tpr.append(tpr)\n        roc_fpr.append(fpr)\n        \n        # Precision is only defined when TP+FP > 0\n        if (tp_cum + fp_cum) > 0:\n            precision = tp_cum / (tp_cum + fp_cum)\n            pr_points.append((tpr, precision))\n\n        i = j\n\n    # Compute Area Under the ROC Curve using the trapezoidal rule\n    # np.trapz integrates y (tpr) with respect to x (fpr)\n    auc_roc = np.trapz(roc_tpr, roc_fpr)\n\n    # Compute Area Under the PR Curve (Average Precision)\n    auc_pr = 0.0\n    last_recall = 0.0\n    # pr_points are naturally sorted by non-decreasing recall\n    for recall, precision in pr_points:\n        auc_pr += (recall - last_recall) * precision\n        last_recall = recall\n\n    # Compute informativeness metrics\n    prevalence = pos_total / (pos_total + neg_total)\n    \n    # ROC informativeness\n    i_roc = (auc_roc - 0.5) / 0.5\n    \n    # PR informativeness\n    # Prevent division by zero if prevalence is 1 (all positive samples)\n    if prevalence  1.0:\n        i_pr = (auc_pr - prevalence) / (1 - prevalence)\n    else: # If pi=1, the denominator is 0. By convention, if auc_pr=1, info=1, else can be undefined/0.\n          # For this problem, N>=1, so pi  1 is always true.\n        i_pr = 0.0\n\n    b_flag = i_pr > i_roc\n    \n    return auc_roc, auc_pr, b_flag\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}