{
    "hands_on_practices": [
        {
            "introduction": "第一个练习为神经数据建模奠定了基础。我们从最简单的情景入手：假设一个神经元的发放遵循一个齐次泊松过程。本练习将指导你估算该神经元的发放率，并通过构建置信区间来量化该估计的不确定性，此过程中将比较一种精确方法与一种常用近似方法的差异。",
            "id": "4186662",
            "problem": "在长度为 $T = 2$ 秒的稳态时间窗内，于恒定刺激下记录单个神经元的活动。脉冲生成过程被建模为一个齐次泊松过程，其发放率 $\\lambda$（单位为 $\\mathrm{Hz}$）未知。在这次记录中，观测到的脉冲计数为 $N = 5$。\n\n仅使用适用于神经科学数据分析中泊松过程建模的第一性原理和核心定义，完成以下任务：\n\n- 通过反转精确的 $\\mathrm{Poisson}(T\\lambda)$ 计数分布，为发放率 $\\lambda$ 构建一个置信水平为 $0.95$ 的双边置信区间，不使用渐近近似。\n- 基于中心极限定理 (CLT)，使用对脉冲计数的正态近似，独立地为 $\\lambda$ 构建一个置信水平为 $0.95$ 的双边置信区间。\n- 计算精确区间长度与正态近似区间长度之比。\n\n以 $\\mathrm{Hz}$ 为单位表示 $\\lambda$ 的任何中间区间。最终报告的量必须是区间长度之比，这是一个无量纲的量。将最终的比值四舍五入到四位有效数字。",
            "solution": "用户要求我解决一个问题，需要我：\n1.  **验证问题陈述的有效性。**\n2.  如果有效，提供一个完整且有理有据的解答。\n\n### 步骤 1：提取给定条件\n-   时间窗长度：$T = 2$ 秒\n-   观测到的脉冲计数：$N = 5$\n-   模型：齐次泊松过程\n-   未知参数：发放率 $\\lambda$（单位：$\\mathrm{Hz}$）\n-   置信水平：$0.95$\n-   任务 1：使用精确的泊松分布为 $\\lambda$ 构建一个 $95\\%$ 的置信区间。\n-   任务 2：基于中心极限定理 (CLT) 使用正态近似为 $\\lambda$ 构建一个 $95\\%$ 的置信区间。\n-   任务 3：计算精确区间长度与正态近似区间长度之比。\n-   最终答案精度：将最终比值四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的给定条件进行验证\n-   **科学依据**：该问题基于泊松过程，这是神经元脉冲序列分析的标准和基础模型。这是定量神经科学中一个常见且现实的问题。此标准已满足。\n-   **良态问题**：问题定义清晰，包含所有必要数据（$N$、$T$、置信水平），并要求计算具体的、可计算的量。存在唯一解。此标准已满足。\n-   **客观性**：语言精确、量化，没有任何主观或模糊的陈述。此标准已满足。\n-   **完整性与一致性**：问题是自洽的，内部一致。给定的数值是合理的。\n-   **总体评估**：该问题不违反任何无效标准。它是统计数据分析中一个标准的、良态的问题。\n\n### 步骤 3：结论与行动\n问题是**有效的**。我将继续进行解答。\n\n该问题要求在给定时间窗长度 $T$ 内观测到的脉冲计数 $N$ 的情况下，为一个齐次泊松过程的发放率 $\\lambda$ 计算两种不同的置信区间。\n\n在区间 $T$ 内观测到的脉冲数 $N$ 服从参数为 $\\mu = \\lambda T$ 的泊松分布。给定 $N=5$ 和 $T=2$ 秒。置信水平为 $1-\\alpha = 0.95$，这意味着 $\\alpha = 0.05$。\n\n**1. $\\lambda$ 的精确置信区间**\n\n泊松参数的精确置信区间是通过反转假设检验得出的，这与二项比例的 Clopper-Pearson 区间类似。设真实（未知）的平均计数为 $\\mu = \\lambda T$。给定观测值 $N=n=5$，$\\mu$ 的 $100(1-\\alpha)\\%$ 置信区间（记为 $[\\mu_L, \\mu_U]$）构造如下：\n\n下界 $\\mu_L$ 是这样一个 $\\mu$ 值，使得观测到 $n$ 或更多事件的概率为 $\\alpha/2$：\n$$ P(N \\ge n | \\mu = \\mu_L) = \\sum_{k=n}^{\\infty} \\frac{e^{-\\mu_L} \\mu_L^k}{k!} = \\frac{\\alpha}{2} $$\n这等价于 $P(N \\le n-1 | \\mu = \\mu_L) = 1 - \\alpha/2$。\n\n上界 $\\mu_U$ 是这样一个 $\\mu$ 值，使得观测到 $n$ 或更少事件的概率为 $\\alpha/2$：\n$$ P(N \\le n | \\mu = \\mu_U) = \\sum_{k=0}^{n} \\frac{e^{-\\mu_U} \\mu_U^k}{k!} = \\frac{\\alpha}{2} $$\n\n这些方程可以使用泊松累积分布函数 (CDF) 和卡方 ($\\chi^2$) 累积分布函数之间的关系求解 $\\mu_L$ 和 $\\mu_U$。这些关系是：\n$$ P(N \\le k ; \\mu) = P(\\chi^2_{2(k+1)} > 2\\mu) $$\n$$ P(N \\ge k ; \\mu) = P(\\chi^2_{2k} < 2\\mu) $$\n\n使用这些恒等式，其中 $n=5$ 且 $\\alpha=0.05$：\n\n对于下界 $\\mu_L$：\n$P(N \\ge 5 | \\mu_L) = P(\\chi^2_{2 \\times 5} < 2\\mu_L) = \\alpha/2 = 0.025$。\n这意味着 $2\\mu_L$ 是自由度为 $10$ 的 $\\chi^2$ 分布的 $0.025$ 分位数。\n$$ 2\\mu_L = \\chi^2_{10, 0.025} \\implies \\mu_L = \\frac{1}{2} \\chi^2_{10, 0.025} $$\n从统计表或软件中查得，$\\chi^2_{10, 0.025} \\approx 3.24697$。\n$$ \\mu_L \\approx \\frac{1}{2}(3.24697) = 1.623485 $$\n\n对于上界 $\\mu_U$：\n$P(N \\le 5 | \\mu_U) = P(\\chi^2_{2(5+1)} > 2\\mu_U) = \\alpha/2 = 0.025$。\n这意味着 $P(\\chi^2_{12} \\le 2\\mu_U) = 1 - 0.025 = 0.975$。因此，$2\\mu_U$ 是自由度为 $12$ 的 $\\chi^2$ 分布的 $0.975$ 分位数。\n$$ 2\\mu_U = \\chi^2_{12, 0.975} \\implies \\mu_U = \\frac{1}{2} \\chi^2_{12, 0.975} $$\n从统计表或软件中查得，$\\chi^2_{12, 0.975} \\approx 23.33666$。\n$$ \\mu_U \\approx \\frac{1}{2}(23.33666) = 11.66833 $$\n\n$\\mu = \\lambda T$ 的置信区间约为 $[1.623485, 11.66833]$。为了求出 $\\lambda$ 的区间，我们除以 $T=2$ 秒。\n$$ \\lambda_L^{\\text{exact}} = \\frac{\\mu_L}{T} \\approx \\frac{1.623485}{2} = 0.81174 \\ \\mathrm{Hz} $$\n$$ \\lambda_U^{\\text{exact}} = \\frac{\\mu_U}{T} \\approx \\frac{11.66833}{2} = 5.83417 \\ \\mathrm{Hz} $$\n精确区间的长度为：\n$$ L_{\\text{exact}} = \\lambda_U^{\\text{exact}} - \\lambda_L^{\\text{exact}} \\approx 5.83417 - 0.81174 = 5.02243 $$\n\n**2. $\\lambda$ 的正态近似置信区间**\n\n中心极限定理 (CLT) 表明，对于足够大的期望计数 $\\mu = \\lambda T$，泊松分布可以由正态分布近似。发放率的估计量是 $\\hat{\\lambda} = N/T$。\n该估计量的期望是 $E[\\hat{\\lambda}] = E[N/T] = (1/T)E[N] = (1/T)(\\lambda T) = \\lambda$。\n方差是 $\\mathrm{Var}(\\hat{\\lambda}) = \\mathrm{Var}(N/T) = (1/T^2)\\mathrm{Var}(N) = (1/T^2)(\\lambda T) = \\lambda/T$。\n\n为了构建置信区间，我们利用 $\\hat{\\lambda}$ 的抽样分布近似为正态分布这一事实。标准误 $\\mathrm{SE}(\\hat{\\lambda}) = \\sqrt{\\mathrm{Var}(\\hat{\\lambda})} = \\sqrt{\\lambda/T}$ 是未知的，因为它依赖于 $\\lambda$。标准方法（Wald 区间）是在标准误公式中用估计值 $\\hat{\\lambda}$ 代替 $\\lambda$：\n$$ \\widehat{\\mathrm{SE}}(\\hat{\\lambda}) = \\sqrt{\\frac{\\hat{\\lambda}}{T}} = \\sqrt{\\frac{N/T}{T}} = \\frac{\\sqrt{N}}{T} $$\n那么 $\\lambda$ 的 $100(1-\\alpha)\\%$ 置信区间由下式给出：\n$$ \\hat{\\lambda} \\pm z_{\\alpha/2} \\cdot \\widehat{\\mathrm{SE}}(\\hat{\\lambda}) $$\n其中 $z_{\\alpha/2}$ 是标准正态分布的上 $\\alpha/2$ 临界值。对于 $95\\%$ 的置信水平，$\\alpha=0.05$，因此 $\\alpha/2=0.025$，并且 $z_{0.025} \\approx 1.95996$。\n\n使用给定数据 $N=5$ 和 $T=2$：\n$$ \\hat{\\lambda} = \\frac{5}{2} = 2.5 \\ \\mathrm{Hz} $$\n$$ \\widehat{\\mathrm{SE}}(\\hat{\\lambda}) = \\frac{\\sqrt{5}}{2} \\approx 1.11803 \\ \\mathrm{Hz} $$\n近似区间的下界和上界是：\n$$ \\lambda_L^{\\text{approx}} = \\hat{\\lambda} - z_{0.025} \\frac{\\sqrt{N}}{T} \\approx 2.5 - 1.95996 \\left(\\frac{\\sqrt{5}}{2}\\right) \\approx 2.5 - 2.19135 = 0.30865 \\ \\mathrm{Hz} $$\n$$ \\lambda_U^{\\text{approx}} = \\hat{\\lambda} + z_{0.025} \\frac{\\sqrt{N}}{T} \\approx 2.5 + 1.95996 \\left(\\frac{\\sqrt{5}}{2}\\right) \\approx 2.5 + 2.19135 = 4.69135 \\ \\mathrm{Hz} $$\n正态近似区间的长度为：\n$$ L_{\\text{approx}} = \\lambda_U^{\\text{approx}} - \\lambda_L^{\\text{approx}} = 2 \\cdot z_{\\alpha/2} \\cdot \\frac{\\sqrt{N}}{T} \\approx 2 \\cdot 2.19135 = 4.38270 $$\n注意，对于小的 $N$ 值（例如 $N=5$），这种近似预计是不准确的。\n\n**3. 区间长度之比**\n\n最后，我们计算精确区间长度与正态近似区间长度之比。\n$$ \\text{Ratio} = \\frac{L_{\\text{exact}}}{L_{\\text{approx}}} \\approx \\frac{5.02243}{4.38270} \\approx 1.14594 $$\n四舍五入到四位有效数字，比值为 $1.146$。与 $1$ 的偏差反映了对于 $N=5$ 这样的小计数值，正态近似的不准确性。精确区间更宽，表明不确定性更大，这对于低计数值是合适的。已知 Wald 区间在 $N$ 值较小时具有较差的覆盖性质，并且通常比应有的宽度更窄。",
            "answer": "$$\\boxed{1.146}$$"
        },
        {
            "introduction": "在拟合一个简单模型之后，关键的下一步是评估其拟合优度。泊松过程的一个核心假设是脉冲计数的方差等于其均值。在本练习中，你将实现一个卡方离散度检验，以正式检查数据是否存在“过度离散”现象——这是一种常见情况，表明数据的变异性超出了模型的预测，暗示可能需要一个更复杂的模型。",
            "id": "4186690",
            "problem": "一位研究人员分析了在多个不重叠的时间窗口内记录的神经元脉冲计数，以评估计数的变异性是否超过了在均匀泊松过程模型下预期的水平。在均匀泊松过程中，跨窗口的计数是独立的，并且方差等于均值。构建一个过离散检验，该检验使用从泊松过程的第一性原理推导出的基于卡方的离散方法，将观测到的计数变异性与泊松模型下预期的变异性进行比较。该检验必须在显著性水平 $\\alpha = 0.05$ 下产生一个关于过离散的单边决策，并且必须明确确定检验有效性的假设是否得到满足。\n\n您的程序必须纯粹用数学和逻辑术语实现以下要求：\n- 从具有恒定速率的均匀泊松过程的核心定义以及不相交区间内计数独立性出发。\n- 仅使用以下事实：在速率为 $r$ 的均匀泊松过程的原假设下，持续时间为 $t_i$ 的窗口中的预期计数与 $t_i$ 成正比，且方差等于均值。\n- 构建一个基于卡方的离散检验，通过适当考虑暴露（窗口持续时间），该检验能处理等持续时间窗口和不等持续时间窗口。\n- 为“过离散”假设计算一个单边 $p$ 值，该值针对与大于预期变异性一致的尾部。\n- 实施一个透明的有效性检查，该检查基于大样本和足够的预期计数条件，这些是卡方近似可靠所必需的。具体来说，对于此任务，如果窗口数 $n$ 满足 $n \\ge 15$ 并且所有窗口中的最小预期计数满足 $\\min_i \\mu_i \\ge 1$，则认为检验有效，其中 $\\mu_i$ 表示在均匀泊松模型下窗口 $i$ 中的预期计数。\n\n对于下面的每个测试用例，您的程序必须计算并输出以下四个量：\n- 卡方离散统计量（一个非负浮点数）。\n- 用于过离散的单边 $p$ 值（一个在 $[0,1]$ 区间内的浮点数）。\n- 在 $\\alpha = 0.05$ 水平下关于过离散的布尔决策（如果检测到过离散则为 True，否则为 False）。\n- 一个布尔标志，指示在规定标准下检验的假设是否被视为有效（True 或 False）。\n\n测试套件：\n- 案例1（等暴露，典型变异性）：计数 $[\\,4,6,5,7,3,6,5,4,7,5,5,6,4,5,6,5,5,7,4,6\\,]$，持续时间 $[\\,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\,]$。\n- 案例2（等暴露，显著的脉冲爆发导致过离散）：计数 $[\\,0,1,2,15,0,3,1,20,0,2,30,1,0,1,2,25,0,1,2,18\\,]$，持续时间 $[\\,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\,]$。\n- 案例3（等暴露，接近规则的计数表明欠离散）：计数 $[\\,5,4,5,5,5,6,5,5,5,4,5,5,6,5,5,5,5,4,5,5\\,]$，持续时间 $[\\,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1\\,]$。\n- 案例4（等暴露，平均计数非常低，卡方近似可能无效）：计数 $[\\,0,0,0,1,0,0,0,1,0,0\\,]$，持续时间 $[\\,1,1,1,1,1,1,1,1,1,1\\,]$。\n- 案例5（不等暴露，中等计数）：计数 $[\\,5,8,6,5,7,6,6,9,5,8,7,6,5,7,8\\,]$，持续时间 $[\\,0.8,1.2,1.0,0.9,1.1,0.95,1.05,1.3,0.85,1.25,1.15,1.0,0.9,1.1,1.2\\,]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个元素对应一个测试用例，并且本身必须是包含四个元素的列表，顺序为：[卡方离散统计量，单边 p 值，在 $\\alpha = 0.05$ 下的过离散布尔决策，布尔有效性标志]。例如：$[[\\dots],[\\dots],[\\dots],[\\dots],[\\dots]]$。",
            "solution": "该问题要求构建并实现一个统计检验，用于在原假设（即计数由均匀泊松过程生成）下检测神经元脉冲计数数据中的过离散现象。过离散意味着观测到的计数方差显著大于均值，这违反了泊松模型中方差等于均值的假设。\n\n该解决方案从以下第一性原理推导而来。\n\n我们考虑 $n$ 个不重叠的时间窗口，第 $i$ 个窗口的持续时间为 $t_i$。在此窗口中记录的脉冲数表示为 $k_i$。\n\n原假设 $H_0$ 指出，脉冲计数是具有恒定但未知速率 $r > 0$ 的单个均匀泊松过程的实现。在此假设下：\n1.  在持续时间为 $t_i$ 的区间内，事件数 $k_i$ 服从参数为 $\\lambda_i = r \\cdot t_i$ 的泊松分布。我们将其记为 $k_i \\sim \\text{Poisson}(\\lambda_i)$。\n2.  泊松分布的一个基本性质是其期望等于方差：$E[k_i] = \\text{Var}(k_i) = \\lambda_i = r \\cdot t_i$。\n3.  在不重叠区间内的计数是统计独立的。\n\n由于速率 $r$ 是未知的，必须从数据中估计。观测到的脉冲总数为 $K = \\sum_{i=1}^{n} k_i$，总观测持续时间为 $T = \\sum_{i=1}^{n} t_i$。公共速率 $r$ 的最大似然估计量 (MLE) 是事件总数除以总持续时间：\n$$\n\\hat{r} = \\frac{K}{T} = \\frac{\\sum_{i=1}^{n} k_i}{\\sum_{i=1}^{n} t_i}\n$$\n使用这个估计速率，我们可以计算在 $H_0$ 下每个窗口的估计期望计数 $\\hat{\\mu}_i$：\n$$\n\\hat{\\mu}_i = \\hat{r} \\cdot t_i\n$$\n过离散检验基于比较观测计数 $k_i$ 和这些期望计数 $\\hat{\\mu}_i$。卡方离散统计量提供了这种偏差的一个标准化度量。它定义为观测计数与期望计数之间平方差的总和，每一项都由期望计数归一化：\n$$\n\\chi^2 = \\sum_{i=1}^{n} \\frac{(k_i - \\hat{\\mu}_i)^2}{\\hat{\\mu}_i}\n$$\n在原假设 $H_0$ 下，该统计量近似服从卡方分布。该分布的自由度 ($df$) 为 $n-1$。我们从 $n$ 个独立数据点 ($k_i$) 开始，由于我们使用数据估计了一个参数（速率 $r$），因此失去了一个自由度。因此，在 $H_0$ 下：\n$$\n\\chi^2 \\sim \\chi^2_{n-1}\n$$\n备择假设 $H_a$ 是数据存在过离散。这意味着计数的真实方差大于其均值。这种增加的变异性会导致更大的平方差 $(k_i - \\hat{\\mu}_i)^2$，从而导致 $\\chi^2$ 统计量的值更大。因此，为了检验过离散，我们执行一个单边上尾检验。我们计算 $p$ 值，即在假设 $H_0$ 为真的情况下，观测到与我们从数据中计算出的 $\\chi^2$ 统计量一样极端或更极端的概率：\n$$\np\\text{-value} = P(\\chi^2_{n-1} \\ge \\chi^2_{\\text{observed}})\n$$\n这个概率是使用 $\\chi^2_{n-1}$ 分布的生存函数 (SF)，也称为互补累积分布函数 (CCDF) 计算的。\n\n通过将 $p$ 值与预定义的显著性水平 $\\alpha = 0.05$ 进行比较来做出决策。如果 $p$ 值小于 $\\alpha$，我们拒绝原假设，并断定存在统计上显著的过离散证据。否则，我们不拒绝 $H_0$。\n\n卡方近似的有效性取决于某些条件。问题将这些条件规定为：\n1.  窗口数 $n$ 应足够大：$n \\ge 15$。\n2.  估计的期望计数不应太小：$\\min_{i} \\hat{\\mu}_i \\ge 1$。\n在此框架下，必须同时满足这两个条件，检验结果才被认为是可靠的。\n\n要实现的算法如下：\n1.  对于给定的一组计数 $k_1, \\dots, k_n$ 和持续时间 $t_1, \\dots, t_n$，计算估计速率 $\\hat{r} = (\\sum k_i) / (\\sum t_i)$。\n2.  计算所有 $i=1, \\dots, n$ 的估计期望计数 $\\hat{\\mu}_i = \\hat{r} \\cdot t_i$。\n3.  计算卡方离散统计量 $\\chi^2 = \\sum_{i=1}^{n} \\frac{(k_i - \\hat{\\mu}_i)^2}{\\hat{\\mu}_i}$。在 $\\hat{\\mu}_i = 0$ 的情况下，相应的 $k_i$ 也必须为 $0$（因为 $\\hat{r}$ 将为 $0$），该项的贡献为 $0$。\n4.  确定自由度 $df = n-1$。\n5.  使用 $\\chi^2_{df}$ 分布的生存函数计算单边 $p$ 值。\n6.  确定过离散的布尔决策：如果 $p < 0.05$ 则为 `True`，否则为 `False`。\n7.  确定布尔有效性标志：如果 $n \\ge 15$ 且 $\\min(\\hat{\\mu}_i) \\ge 1$ 则为 `True`，否则为 `False`。\n8.  将这四个结果组合成一个列表作为最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Analyzes neuronal spike counts for overdispersion relative to a\n    homogeneous Poisson process model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (equal exposures, typical variability)\n        (np.array([4, 6, 5, 7, 3, 6, 5, 4, 7, 5, 5, 6, 4, 5, 6, 5, 5, 7, 4, 6]),\n         np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n        # Case 2 (equal exposures, pronounced bursts causing overdispersion)\n        (np.array([0, 1, 2, 15, 0, 3, 1, 20, 0, 2, 30, 1, 0, 1, 2, 25, 0, 1, 2, 18]),\n         np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n        # Case 3 (equal exposures, near-regular counts suggesting underdispersion)\n        (np.array([5, 4, 5, 5, 5, 6, 5, 5, 5, 4, 5, 5, 6, 5, 5, 5, 5, 4, 5, 5]),\n         np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n        # Case 4 (equal exposures, low mean counts where chi-square approx may be invalid)\n        (np.array([0, 0, 0, 1, 0, 0, 0, 1, 0, 0]),\n         np.array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])),\n        # Case 5 (unequal exposures, moderate counts)\n        (np.array([5, 8, 6, 5, 7, 6, 6, 9, 5, 8, 7, 6, 5, 7, 8]),\n         np.array([0.8, 1.2, 1.0, 0.9, 1.1, 0.95, 1.05, 1.3, 0.85, 1.25, 1.15, 1.0, 0.9, 1.1, 1.2])),\n    ]\n\n    results = []\n    alpha = 0.05\n\n    for counts, durations in test_cases:\n        n = len(counts)\n        total_counts = np.sum(counts)\n        total_duration = np.sum(durations)\n\n        # Estimate the common rate r under the homogeneous Poisson model\n        # Handle case where total duration is zero to avoid division by zero\n        if total_duration > 0:\n            r_hat = total_counts / total_duration\n        else:\n            # If total duration is zero, rate is undefined. This is an invalid setup.\n            # Chi-square stat and p-value are not meaningfully computable.\n            # We set them to NaN and mark as invalid.\n            results.append([float('nan'), float('nan'), False, False])\n            continue\n            \n        # Estimate expected counts for each window\n        mu_hat = r_hat * durations\n\n        # Calculate chi-square dispersion statistic\n        # chi2_stat = sum((k_i - mu_hat_i)^2 / mu_hat_i)\n        # Use np.divide to handle cases where mu_hat_i might be 0.\n        # If mu_hat_i is 0, then k_i must also be 0, so the term is 0.\n        numerator = (counts - mu_hat)**2\n        denominator = mu_hat\n        chi2_stat = np.sum(np.divide(numerator, denominator, \n                                     out=np.zeros_like(numerator, dtype=float), \n                                     where=denominator!=0))\n\n        # Degrees of freedom is n-1 because one parameter (r) was estimated\n        df = n - 1\n\n        # Calculate one-sided p-value for overdispersion (upper tail test)\n        # Check for non-positive degrees of freedom\n        if df > 0:\n            p_value = chi2.sf(chi2_stat, df)\n        else:\n            # Test is not applicable if n = 1\n            p_value = float('nan')\n\n        # Decision for overdispersion\n        decision = p_value  alpha\n        \n        # Check validity of the chi-square approximation\n        # Condition 1: Number of windows n >= 15\n        # Condition 2: Minimum expected count across windows min(mu_i) >= 1\n        min_mu_hat = np.min(mu_hat) if len(mu_hat) > 0 else 0\n        is_valid = (n >= 15) and (min_mu_hat >= 1)\n\n        results.append([chi2_stat, p_value, bool(decision), is_valid])\n\n    # The problem asks for a list of lists, so stringify each inner list\n    # and join with commas.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "真实的神经活动很少是恒定的；它会随着刺激或内部状态的变化而动态改变。当我们的诊断检验表明简单的齐次模型不足时，我们通常会转向具有时变速率 $\\lambda(t)$ 的非齐次泊松过程。这个高级练习将介绍一种强大的方法——核平滑，并使用留一法交叉验证从脉冲数据中估算 $\\lambda(t)$，让你能够可视化和分析神经元的动态发放模式。",
            "id": "4186689",
            "problem": "在观测窗口 $[0,T]$ 内从单个神经元记录的脉冲序列被建模为非齐次泊松过程的一个实现，该过程具有非负强度函数 $\\lambda(t)$，单位为 $\\mathrm{s}^{-1}$。其基础出发点是非齐次泊松过程的标准似然：对于在 $[0,T]$ 内观测到的脉冲时间 $\\{t_i\\}_{i=1}^n$，其似然与 $\\exp\\!\\left(-\\int_{0}^{T}\\lambda(t)\\,dt\\right)\\prod_{i=1}^{n}\\lambda(t_i)$ 成正比，相应的对数似然为 $\\sum_{i=1}^{n}\\log\\lambda(t_i)-\\int_{0}^{T}\\lambda(t)\\,dt$。考虑一个核速率估计器，它使用带宽为 $h$ 的高斯核从脉冲时间生成平滑的强度估计 $\\lambda_h(t)$，其中核函数是标准正态概率密度函数，经带宽缩放后单位为 $\\mathrm{s}^{-1}$。为避免在脉冲时间点评估 $\\lambda_h(t)$ 时因自身贡献（self-contribution）而产生的乐观偏差，使用留一法交叉验证（LOOCV），定义为在泊松对数似然上进行的留一法交叉验证（LOOCV），其中每个脉冲都在通过排除该脉冲计算出的强度估计下进行评估。您必须直接从泊松过程似然的定义出发，论证 LOOCV 准则的合理性，并在问题陈述中不提供捷径公式的情况下实现它。\n\n您的任务是：\n1. 仅从非齐次泊松过程似然和高斯核的定义出发，推导出一个有原则的 LOOCV 目标函数。该目标函数通过在提供的候选 $h$ 值网格上最大化交叉验证的泊松对数似然来选择平滑带宽 $h$。明确解释为何需要在每个脉冲自身的时间点上排除该脉冲，以及积分项 $\\int_{0}^{T}$ 是如何进入该准则的。\n2. 实现一个完整的程序，对下方的每个测试用例，在候选带宽网格上计算 LOOCV 分数，并返回使分数最大化的带宽 $h$（以秒为单位）。为确保当留一法强度在某个脉冲时间点为零时的数值稳定性，在取对数前，应在核估计中加入一个小的基线强度 $b$（单位为 $\\mathrm{s}^{-1}$），并将其对 $[0,T]$ 上积分的贡献也包括在内。\n\n使用带宽为 $h$ 的高斯核（标准正态概率密度），并以秒为单位表示所有时间量。不涉及角度。强度必须以 $\\mathrm{s}^{-1}$ 为单位处理。最终输出是代表所选 $h$ 值的浮点数（以秒为单位）。\n\n测试套件（每个用例指定观测窗口长度 $T$（秒），脉冲时间 $\\{t_i\\}$（秒），候选带宽网格 $\\mathcal{H}$（秒），以及基线 $b$（$\\mathrm{s}^{-1}$））：\n- 用例 1（通用情况）：$T=10.0$, $\\{t_i\\}=\\{0.21,0.48,1.24,1.52,2.97,3.08,3.22,4.99,7.97,9.51\\}$, $\\mathcal{H}=\\{0.05,0.10,0.20,0.50,1.00,2.00\\}$, $b=10^{-8}$。\n- 用例 2（边界密集型脉冲）：$T=2.0$, $\\{t_i\\}=\\{0.01,0.02,0.05,1.95,1.97,1.99\\}$, $\\mathcal{H}=\\{0.005,0.010,0.020,0.050,0.100,0.200,0.500\\}$, $b=10^{-8}$。\n- 用例 3（极端稀疏）：$T=10.0$, $\\{t_i\\}=\\{4.50\\}$, $\\mathcal{H}=\\{0.01,0.02,0.05,0.10,0.20,0.50,1.00,2.00\\}$, $b=10^{-8}$。\n- 用例 4（含边缘的聚类脉冲）：$T=1.0$, $\\{t_i\\}=\\{0.02,0.04,0.45,0.45625,0.46250,0.46875,0.47500,0.48125,0.48750,0.49375,0.50000,0.50625,0.51250,0.51875,0.52500,0.53125,0.53750,0.54375,0.47,0.53,0.55,0.96,0.98\\}$, $\\mathcal{H}=\\{0.005,0.010,0.020,0.050,0.100,0.200\\}$, $b=10^{-8}$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$\\texttt{[result1,result2,result3,result4]}$），其中每个 $\\texttt{result}$ 是对应测试用例所选出的带宽 $h$（以秒为单位），表示为浮点数。",
            "solution": "任务是为非齐次泊松过程的核强度估计推导一个留一法交叉验证（LOOCV）目标函数，用以选择最优带宽 $h$；然后实现一个程序，为多个测试用例从候选网格 $\\mathcal{H}$ 中找到这个最优 $h$。推导过程必须从泊松过程对数似然的基本定义开始。\n\n**1. 基本原理：非齐次泊松过程对数似然**\n\n出发点是非齐次泊松过程的对数似然函数。给定在区间 $[0, T]$ 内观测到的一组 $n$ 个脉冲时间 $\\{t_i\\}_{i=1}^n$，以及一个随时间变化的强度函数 $\\lambda(t)$（单位为 $\\mathrm{s}^{-1}$），其对数似然 $\\mathcal{L}$ 由下式给出：\n$$\n\\mathcal{L}(\\lambda) = \\sum_{i=1}^{n} \\log \\lambda(t_i) - \\int_{0}^{T} \\lambda(t) \\,dt\n$$\n该表达式包含两个部分。第一项 $\\sum_{i=1}^{n} \\log \\lambda(t_i)$ 最大化了在脉冲实际发生的特定时间 $t_i$ 观测到脉冲的似然。第二项 $-\\int_{0}^{T} \\lambda(t) \\,dt$ 是一个惩罚项，代表在整个区间内观测到*没有其他脉冲*的对数概率。积分 $\\int_{0}^{T} \\lambda(t) \\,dt$ 是在模型 $\\lambda(t)$ 下 $[0, T]$ 内的期望脉冲数。该项惩罚强度过高的模型，从而防止 $\\lambda(t) \\to \\infty$ 的平凡解。\n\n**2. 基于核的强度估计与过拟合**\n\n我们使用基于核的方法，从观测到的脉冲数据 $\\{t_j\\}_{j=1}^n$ 估计未知的强度函数 $\\lambda(t)$。问题指定了高斯核，它源自标准正态概率密度函数 $\\phi(u) = (2\\pi)^{-1/2} e^{-u^2/2}$。为了使其成为一个带宽为 $h$（单位为秒）的速率核，我们定义在 $t_j$ 处的单个脉冲的核函数为：\n$$\nk_h(t-t_j) = \\frac{1}{h} \\phi\\left(\\frac{t-t_j}{h}\\right) = \\frac{1}{h\\sqrt{2\\pi}} \\exp\\left(-\\frac{(t-t_j)^2}{2h^2}\\right)\n$$\n此函数 $k_h$ 的单位为 $\\mathrm{s}^{-1}$，符合要求。总强度估计 $\\lambda_h(t)$，包括为保证数值稳定性而设的一个小的恒定基线强度 $b$，是所有脉冲贡献的总和：\n$$\n\\lambda_h(t) = b + \\sum_{j=1}^{n} k_h(t-t_j)\n$$\n如果我们将此估计 $\\lambda_h(t)$ 直接代入对数似然函数，会得到一个目标函数 $\\mathcal{L}(h) = \\sum_{i=1}^{n} \\log \\lambda_h(t_i) - \\int_{0}^{T} \\lambda_h(t) \\,dt$。这种方法存在乐观偏差（optimistic bias）。项 $\\lambda_h(t_i)$ 包含了以 $t_i$ 本身为中心的核 $k_h(t-t_i)$ 的贡献。当 $h \\to 0$ 时，$k_h(0)$ 的值趋于无穷大，导致 $\\log \\lambda_h(t_i)$ 发散。这意味着最大化 $\\mathcal{L}(h)$ 会错误地偏好无穷小的带宽，这是过拟合的典型标志。\n\n**3. LOOCV 目标函数的推导**\n\n留一法交叉验证（LOOCV）是一种有原则的方法，通过估计模型的泛化性能来对抗此类过拟合。其核心思想是在一个从模型构建中排除的数据点上评估模型的预测准确性。\n\n对于我们数据集中的每个脉冲时间 $t_i$，我们构建一个留一法强度估计 $\\lambda_h^{(-i)}(t)$，它使用除 $t_i$ 之外的所有脉冲：\n$$\n\\lambda_h^{(-i)}(t) = b + \\sum_{j \\neq i} k_h(t-t_j)\n$$\n然后，我们使用这个“无偏”的估计来评估被排除的脉冲 $t_i$ 的对数似然贡献。这得到了对数似然的交叉验证求和项：\n$$\n\\mathcal{L}_{\\text{sum}}(h) = \\sum_{i=1}^{n} \\log \\lambda_h^{(-i)}(t_i) = \\sum_{i=1}^{n} \\log \\left( b + \\sum_{j \\neq i} k_h(t_i - t_j) \\right)\n$$\n该项正确地量化了模型基于周围脉冲预测每个脉冲位置的能力，而没有来自自身贡献的人为膨胀。\n\n接下来，我们必须考虑积分惩罚项 $-\\int_{0}^{T} \\lambda(t) \\,dt$。该项代表了模型在整个观测窗口上的复杂度成本。在选择带宽 $h$ 时，我们是在提出一个单一、完整的模型 $\\lambda_h(t)$（基于所有数据点）来描述该过程。因此，模型复杂度的惩罚应该针对这个完整的模型进行评估。对积分项使用留一法估计是不一致的，因为这意味着要评估 $n$ 个不同模型的成本。有原则的方法是对积分项使用完整的强度估计 $\\lambda_h(t)$：\n$$\n\\mathcal{I}(h) = \\int_{0}^{T} \\lambda_h(t) \\,dt = \\int_{0}^{T} \\left( b + \\sum_{j=1}^{n} k_h(t-t_j) \\right) dt\n$$\n将交叉验证的求和项与完整模型的惩罚项相结合，得到最终的 LOOCV 目标函数 $\\mathcal{L}_{\\text{CV}}(h)$，我们的目标是针对 $h$ 将其最大化：\n$$\n\\mathcal{L}_{\\text{CV}}(h) = \\mathcal{L}_{\\text{sum}}(h) - \\mathcal{I}(h) = \\sum_{i=1}^{n} \\log \\left( b + \\sum_{j \\neq i} k_h(t_i - t_j) \\right) - \\int_{0}^{T} \\left( b + \\sum_{j=1}^{n} k_h(t - t_j) \\right) dt\n$$\n\n**4. 积分项的解析评估**\n\n为了实现此目标函数，积分项 $\\mathcal{I}(h)$ 必须被高效计算。我们可以解析地求解它：\n$$\n\\mathcal{I}(h) = \\int_{0}^{T} b \\, dt + \\sum_{j=1}^{n} \\int_{0}^{T} k_h(t-t_j) \\, dt = bT + \\sum_{j=1}^{n} \\int_{0}^{T} \\frac{1}{h\\sqrt{2\\pi}} \\exp\\left(-\\frac{(t-t_j)^2}{2h^2}\\right) dt\n$$\n求和中的每个积分对应于均值为 $\\mu=t_j$、标准差为 $\\sigma=h$ 的正态分布在区间 $[0, T]$ 上的概率质量。这可以使用标准正态分布的累积分布函数（CDF），$\\Phi(z) = \\int_{-\\infty}^z \\phi(u)\\,du$ 来表示：\n$$\n\\int_{0}^{T} k_h(t-t_j) \\, dt = \\Phi\\left(\\frac{T-t_j}{h}\\right) - \\Phi\\left(\\frac{0-t_j}{h}\\right)\n$$\n标准正态 CDF 可以通过关系式 $\\Phi(z) = \\frac{1}{2}\\left(1 + \\mathrm{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)$ 使用误差函数 $\\mathrm{erf}(x)$ 来计算。这使得精确的数值计算成为可能。\n\n最终的算法是，对于每个候选带宽 $h \\in \\mathcal{H}$，使用推导出的公式计算 $\\mathcal{L}_{\\text{CV}}(h)$，并选择产生最大分数的 $h$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Solves for the optimal bandwidth h for kernel-based Poisson intensity\n    estimation using Leave-One-Out Cross-Validation (LOOCV).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"T\": 10.0,\n            \"spikes\": [0.21, 0.48, 1.24, 1.52, 2.97, 3.08, 3.22, 4.99, 7.97, 9.51],\n            \"H_grid\": [0.05, 0.10, 0.20, 0.50, 1.00, 2.00],\n            \"b\": 1e-8,\n        },\n        {\n            \"T\": 2.0,\n            \"spikes\": [0.01, 0.02, 0.05, 1.95, 1.97, 1.99],\n            \"H_grid\": [0.005, 0.010, 0.020, 0.050, 0.100, 0.200, 0.500],\n            \"b\": 1e-8,\n        },\n        {\n            \"T\": 10.0,\n            \"spikes\": [4.50],\n            \"H_grid\": [0.01, 0.02, 0.05, 0.10, 0.20, 0.50, 1.00, 2.00],\n            \"b\": 1e-8,\n        },\n        {\n            \"T\": 1.0,\n            \"spikes\": [0.02, 0.04, 0.45, 0.45625, 0.46250, 0.46875, 0.47500, 0.48125, 0.48750, 0.49375, 0.50000, 0.50625, 0.51250, 0.51875, 0.52500, 0.53125, 0.53750, 0.54375, 0.47, 0.53, 0.55, 0.96, 0.98],\n            \"H_grid\": [0.005, 0.010, 0.020, 0.050, 0.100, 0.200],\n            \"b\": 1e-8,\n        },\n    ]\n\n    results = []\n\n    def normal_cdf(x):\n        \"\"\"Computes the standard normal CDF using the error function.\"\"\"\n        return 0.5 * (1.0 + erf(x / np.sqrt(2.0)))\n\n    def calculate_loocv_score(h, T, spikes, b):\n        \"\"\"\n        Calculates the LOOCV score for a given bandwidth h.\n        \n        The score is derived from the Poisson log-likelihood:\n        sum_{i} log(lambda_h^{(-i)}(t_i)) - integral_0^T lambda_h(t) dt\n        \"\"\"\n        n = len(spikes)\n        if n == 0:\n            return -b * T\n\n        # 1. Calculate the sum term: sum_{i} log(lambda_h^{(-i)}(t_i))\n        log_likelihood_sum = 0.0\n        \n        # Pre-calculate constants for efficiency\n        kernel_norm_factor = 1.0 / (h * np.sqrt(2.0 * np.pi))\n        h_squared = h * h\n\n        for i in range(n):\n            t_i = spikes[i]\n            \n            # Create leave-one-out spike set\n            spikes_loo = np.delete(spikes, i)\n            \n            # Calculate intensity at t_i from other spikes\n            if len(spikes_loo) > 0:\n                diffs = t_i - spikes_loo\n                kernel_vals = kernel_norm_factor * np.exp(-0.5 * diffs**2 / h_squared)\n                rate_at_ti_loo = np.sum(kernel_vals)\n            else: # Case with only one spike\n                rate_at_ti_loo = 0.0\n            \n            # Add baseline and take log\n            log_likelihood_sum += np.log(rate_at_ti_loo + b)\n\n        # 2. Calculate the integral term: integral_0^T lambda_h(t) dt\n        # The integral is b*T + sum_j integral_0^T k_h(t-t_j) dt\n        \n        # Start with the integral of the baseline\n        integral_term = b * T\n        \n        # Add the integral of each kernel\n        for t_j in spikes:\n            upper_bound_arg = (T - t_j) / h\n            lower_bound_arg = (0.0 - t_j) / h\n            \n            integral_of_one_kernel = normal_cdf(upper_bound_arg) - normal_cdf(lower_bound_arg)\n            integral_term += integral_of_one_kernel\n            \n        return log_likelihood_sum - integral_term\n\n    for case in test_cases:\n        T = case[\"T\"]\n        spikes = np.array(case[\"spikes\"])\n        H_grid = case[\"H_grid\"]\n        b = case[\"b\"]\n        \n        scores = []\n        for h in H_grid:\n            score = calculate_loocv_score(h, T, spikes, b)\n            scores.append(score)\n            \n        best_h_index = np.argmax(scores)\n        best_h = H_grid[best_h_index]\n        results.append(best_h)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}