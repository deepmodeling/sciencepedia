{
    "hands_on_practices": [
        {
            "introduction": "To begin, we ground our understanding of AIC and BIC with a direct calculation. This exercise provides a classic model comparison scenario where a more complex model achieves a better fit (a higher log-likelihood) at the cost of more parameters. By applying the AIC and BIC formulas, you will directly quantify the trade-off between model fit and complexity and see firsthand how their different penalty terms can lead to selecting different models .",
            "id": "4595206",
            "problem": "A hospital-based cross-sectional study investigates risk factors for current influenza infection among adult patients presenting with acute respiratory symptoms. The binary outcome is infection status, coded as $Y_{i} \\in \\{0,1\\}$ for patient $i$, with a logistic regression generalized linear model using the logit link. Two nested models are fit by maximum likelihood on the same dataset of $n = 1000$ independent patients.\n\nModel $\\mathcal{M}_{1}$ (full) includes an intercept and $5$ covariate terms (total parameter count $k_{1} = 6$). Model $\\mathcal{M}_{0}$ (reduced) includes an intercept and $3$ covariate terms (total parameter count $k_{0} = 4$). The maximized log-likelihoods are $\\ell_{1} = -120$ for $\\mathcal{M}_{1}$ and $\\ell_{0} = -125$ for $\\mathcal{M}_{0}$. Using the definitions of the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for model selection in generalized linear models, compute the AIC and BIC for each model and determine, based on each criterion separately, which model is preferred.\n\nReport your numerical results for $(\\mathrm{AIC}_{1}, \\mathrm{BIC}_{1}, \\mathrm{AIC}_{0}, \\mathrm{BIC}_{0})$ as a single row matrix, rounded to four significant figures. No units are required. The preference decision does not need to be included in the reported matrix.",
            "solution": "The problem requires the calculation of the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) for two nested logistic regression models, $\\mathcal{M}_{1}$ (full) and $\\mathcal{M}_{0}$ (reduced), and a determination of which model is preferred by each criterion.\n\nThe problem provides the following information:\nThe sample size is $n = 1000$ patients.\nFor the full model $\\mathcal{M}_{1}$:\nThe number of parameters is $k_{1} = 6$.\nThe maximized log-likelihood is $\\ell_{1} = -120$.\n\nFor the reduced model $\\mathcal{M}_{0}$:\nThe number of parameters is $k_{0} = 4$.\nThe maximized log-likelihood is $\\ell_{0} = -125$.\n\nThe Akaike Information Criterion (AIC) is defined as:\n$$ \\mathrm{AIC} = -2\\ell + 2k $$\nwhere $k$ is the number of estimated parameters in the model and $\\ell$ is the maximized value of the log-likelihood function for the model.\n\nThe Bayesian Information Criterion (BIC) is defined as:\n$$ \\mathrm{BIC} = -2\\ell + k \\ln(n) $$\nwhere $n$ is the number of observations, or sample size.\n\nFor both criteria, a model with a lower value is generally preferred, as it indicates a better balance between model fit (higher $\\ell$) and model parsimony (lower $k$).\n\nFirst, we compute the AIC and BIC for the full model, $\\mathcal{M}_{1}$.\nUsing the given values $k_{1} = 6$, $\\ell_{1} = -120$, and $n = 1000$:\n$$ \\mathrm{AIC}_{1} = -2\\ell_{1} + 2k_{1} = -2(-120) + 2(6) = 240 + 12 = 252 $$\n$$ \\mathrm{BIC}_{1} = -2\\ell_{1} + k_{1} \\ln(n) = -2(-120) + 6 \\ln(1000) = 240 + 6 \\ln(1000) $$\nTo find the numerical value of $\\mathrm{BIC}_{1}$, we use $\\ln(1000) \\approx 6.907755$:\n$$ \\mathrm{BIC}_{1} \\approx 240 + 6(6.907755) \\approx 240 + 41.44653 = 281.44653 $$\n\nNext, we compute the AIC and BIC for the reduced model, $\\mathcal{M}_{0}$.\nUsing the given values $k_{0} = 4$, $\\ell_{0} = -125$, and $n = 1000$:\n$$ \\mathrm{AIC}_{0} = -2\\ell_{0} + 2k_{0} = -2(-125) + 2(4) = 250 + 8 = 258 $$\n$$ \\mathrm{BIC}_{0} = -2\\ell_{0} + k_{0} \\ln(n) = -2(-125) + 4 \\ln(1000) = 250 + 4 \\ln(1000) $$\nUsing $\\ln(1000) \\approx 6.907755$:\n$$ \\mathrm{BIC}_{0} \\approx 250 + 4(6.907755) \\approx 250 + 27.63102 = 277.63102 $$\n\nNow, we determine the preferred model based on each criterion by comparing the calculated values.\nFor the AIC:\n$\\mathrm{AIC}_{1} = 252$ and $\\mathrm{AIC}_{0} = 258$.\nSince $\\mathrm{AIC}_{1}  \\mathrm{AIC}_{0}$ ($252  258$), the Akaike Information Criterion prefers the full model, $\\mathcal{M}_{1}$.\n\nFor the BIC:\n$\\mathrm{BIC}_{1} \\approx 281.4465$ and $\\mathrm{BIC}_{0} \\approx 277.6310$.\nSince $\\mathrm{BIC}_{0}  \\mathrm{BIC}_{1}$ ($277.6310  281.4465$), the Bayesian Information Criterion prefers the reduced model, $\\mathcal{M}_{0}$.\n\nThe divergence in preference is a known characteristic when comparing these two criteria. The penalty for model complexity in BIC, $k \\ln(n)$, is larger than the penalty in AIC, $2k$, whenever $\\ln(n) > 2$, which is true for sample sizes $n > e^2 \\approx 7.4$. In this case, with $n = 1000$, the BIC imposes a much stronger penalty for the two additional parameters in $\\mathcal{M}_{1}$, leading to the selection of the more parsimonious model $\\mathcal{M}_{0}$.\n\nThe problem requires the numerical results for $(\\mathrm{AIC}_{1}, \\mathrm{BIC}_{1}, \\mathrm{AIC}_{0}, \\mathrm{BIC}_{0})$ rounded to four significant figures.\n$\\mathrm{AIC}_{1} = 252$, which is $252.0$ to four significant figures.\n$\\mathrm{BIC}_{1} \\approx 281.44653$, which rounds to $281.4$.\n$\\mathrm{AIC}_{0} = 258$, which is $258.0$ to four significant figures.\n$\\mathrm{BIC}_{0} \\approx 277.63102$, which rounds to $277.6$.\nTherefore, the final vector of values is $(252.0, 281.4, 258.0, 277.6)$.",
            "answer": "$$ \\boxed{\\begin{pmatrix} 252.0  281.4  258.0  277.6 \\end{pmatrix}} $$"
        },
        {
            "introduction": "Building on the previous calculation, we now explore the theoretical underpinnings of why AIC and BIC can diverge. Instead of just plugging in numbers, this practice challenges you to derive the exact analytical threshold for log-likelihood improvement, $\\Delta \\ln \\hat{L}$, that is required to justify adding a new parameter according to each criterion. This exercise  provides a deep, quantitative insight into the relative stringency of the complexity penalties imposed by AIC and BIC.",
            "id": "3919103",
            "problem": "A synthetic biology team is modeling single-cell messenger ribonucleic acid (mRNA) counts from a promoter under an inducible condition. They compare two nested stochastic models of transcriptional bursting for $n$ independent cells: a simpler model $\\mathcal{M}_{S}$ with parameter dimension $k_{S}$, and a more complex model $\\mathcal{M}_{C}$ with parameter dimension $k_{C} = k_{S} + 1$ that adds one biologically interpretable parameter capturing induction-dependent burst size. Let $\\ln \\hat{L}_{S}$ and $\\ln \\hat{L}_{C}$ denote the maximized log-likelihoods under the two models, computed at their respective maximum likelihood estimates (MLEs). Define the log-likelihood improvement of the complex over the simple model as $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$, with $\\Delta \\ln \\hat{L} \\geq 0$ for nested models fit by maximum likelihood.\n\nStarting from the standard definitions of the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) as penalized criteria combining a goodness-of-fit term and a complexity penalty, and using only the assumptions stated above, derive the minimal threshold in $\\Delta \\ln \\hat{L}$ required for the complex model $\\mathcal{M}_{C}$ to be preferred over the simple model $\\mathcal{M}_{S}$ under each criterion for a given sample size $n$. Express your final answer as two exact analytic expressions in terms of $n$, presented as a single row matrix $[\\Delta_{\\mathrm{AIC}} \\quad \\Delta_{\\mathrm{BIC}}]$, where $\\Delta_{\\mathrm{AIC}}$ and $\\Delta_{\\mathrm{BIC}}$ are the smallest values of $\\Delta \\ln \\hat{L}$ that make the complex model favored by the Akaike Information Criterion and the Bayesian Information Criterion, respectively. No rounding is required and no units should be used in your final expressions.",
            "solution": "The objective is to determine the minimal threshold for the log-likelihood improvement, $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$, that is required for the more complex model, $\\mathcal{M}_{C}$, to be preferred over the simpler model, $\\mathcal{M}_{S}$, according to the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC).\n\nFor model selection criteria like AIC and BIC, the model with the lower criterion value is preferred. Thus, $\\mathcal{M}_{C}$ is preferred over $\\mathcal{M}_{S}$ if $\\text{AIC}(\\mathcal{M}_{C})  \\text{AIC}(\\mathcal{M}_{S})$ and $\\text{BIC}(\\mathcal{M}_{C})  \\text{BIC}(\\mathcal{M}_{S})$, respectively. The threshold value corresponds to the point of equality.\n\nLet $k$ be the number of estimated parameters in a model, $\\hat{L}$ be the maximized value of the likelihood function for the model, and $n$ be the number of data points.\n\n**1. Derivation for the Akaike Information Criterion (AIC)**\n\nThe standard definition of AIC is:\n$$ \\text{AIC} = -2\\ln \\hat{L} + 2k $$\n\nFor our two models, $\\mathcal{M}_{S}$ and $\\mathcal{M}_{C}$, the AIC values are:\n$$ \\text{AIC}_{S} = -2\\ln \\hat{L}_{S} + 2k_{S} $$\n$$ \\text{AIC}_{C} = -2\\ln \\hat{L}_{C} + 2k_{C} $$\n\nThe complex model $\\mathcal{M}_{C}$ is preferred over the simple model $\\mathcal{M}_{S}$ when $\\text{AIC}_{C}  \\text{AIC}_{S}$. We can write this inequality as:\n$$ -2\\ln \\hat{L}_{C} + 2k_{C}  -2\\ln \\hat{L}_{S} + 2k_{S} $$\n\nTo find the condition on the log-likelihood improvement, we rearrange the inequality to group the likelihood terms and the parameter count terms:\n$$ 2\\ln \\hat{L}_{C} - 2\\ln \\hat{L}_{S} > 2k_{C} - 2k_{S} $$\n$$ 2(\\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}) > 2(k_{C} - k_{S}) $$\n\nUsing the problem's definition, $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$, we have:\n$$ 2\\Delta \\ln \\hat{L} > 2(k_{C} - k_{S}) $$\n$$ \\Delta \\ln \\hat{L} > k_{C} - k_{S} $$\n\nThe problem states that the parameter dimension of the complex model is greater than that of the simple model by one, i.e., $k_{C} = k_{S} + 1$, which implies $k_{C} - k_{S} = 1$. Substituting this into the inequality gives:\n$$ \\Delta \\ln \\hat{L} > 1 $$\n\nThe minimal value of $\\Delta \\ln \\hat{L}$ required to favor $\\mathcal{M}_{C}$ is the value at the threshold of this inequality. Therefore, the minimal threshold for AIC is:\n$$ \\Delta_{\\text{AIC}} = 1 $$\n\n**2. Derivation for the Bayesian Information Criterion (BIC)**\n\nThe standard definition of BIC is:\n$$ \\text{BIC} = -2\\ln \\hat{L} + k\\ln(n) $$\nwhere $n$ is the sample size.\n\nFor our two models, the BIC values are:\n$$ \\text{BIC}_{S} = -2\\ln \\hat{L}_{S} + k_{S}\\ln(n) $$\n$$ \\text{BIC}_{C} = -2\\ln \\hat{L}_{C} + k_{C}\\ln(n) $$\n\nThe complex model $\\mathcal{M}_{C}$ is preferred over the simple model $\\mathcal{M}_{S}$ when $\\text{BIC}_{C}  \\text{BIC}_{S}$:\n$$ -2\\ln \\hat{L}_{C} + k_{C}\\ln(n)  -2\\ln \\hat{L}_{S} + k_{S}\\ln(n) $$\n\nWe again rearrange to isolate the log-likelihood improvement:\n$$ 2\\ln \\hat{L}_{C} - 2\\ln \\hat{L}_{S} > k_{C}\\ln(n) - k_{S}\\ln(n) $$\n$$ 2(\\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}) > (k_{C} - k_{S})\\ln(n) $$\n\nSubstituting $\\Delta \\ln \\hat{L} = \\ln \\hat{L}_{C} - \\ln \\hat{L}_{S}$:\n$$ 2\\Delta \\ln \\hat{L} > (k_{C} - k_{S})\\ln(n) $$\n\nAgain, we use the fact that $k_{C} - k_{S} = 1$:\n$$ 2\\Delta \\ln \\hat{L} > \\ln(n) $$\n$$ \\Delta \\ln \\hat{L} > \\frac{1}{2}\\ln(n) $$\n\nThe minimal value of $\\Delta \\ln \\hat{L}$ required to favor $\\mathcal{M}_{C}$ under the BIC is the value at the boundary of this condition. Thus, the minimal threshold for BIC is:\n$$ \\Delta_{\\text{BIC}} = \\frac{1}{2}\\ln(n) $$\n\nThe final answer is composed of the two derived thresholds, $\\Delta_{\\text{AIC}}$ and $\\Delta_{\\text{BIC}}$, presented as a row matrix.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1  \\frac{1}{2}\\ln(n) \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "This final practice synthesizes theory and computation into a complete data analysis workflow, moving from raw data to model selection. You will engage in a common task in neuroscience: fitting competing models to a dataset and deciding which provides a more parsimonious description. This exercise  requires you to not only calculate AIC and BIC but also to first perform the necessary prerequisite steps of model fitting and residual calculation, bridging the gap between abstract formulas and their practical implementation in a research context.",
            "id": "2408012",
            "problem": "You are given several independent datasets consisting of paired values $(x_i,y_i)$. Assume that the observation errors in $y_i$ are independent and identically distributed Gaussian random variables with zero mean and unknown variance. For each dataset, consider two competing models for $y$ as a function of $x$: a quadratic polynomial of degree $2$ and a cubic polynomial of degree $3$. For each model, fit the coefficients by ordinary least squares under the stated Gaussian error assumption, then perform model selection using the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC). The number of free parameters $k$ equals the polynomial degree plus one. Decide which model is preferred by AIC and which is preferred by BIC for each dataset, and report these decisions.\n\nDatasets (each presented as an ordered list of $x$ values and a corresponding ordered list of $y$ values of the same length):\n\n- Test case $1$:\n  - $x$: $[-3,-2,-1,0,1,2,3]$\n  - $y$: $[9.45,4.90,2.30,0.95,1.13,3.09,6.17]$\n\n- Test case $2$:\n  - $x$: $[-2,-1,0,1,2,3,4]$\n  - $y$: $[3.35,1.73,0.52,-0.03,0.94,3.75,9.31]$\n\n- Test case $3$:\n  - $x$: $[-1,-0.5,0,1,2]$\n  - $y$: $[1.53,1.605,2.01,3.49,5.96]$\n\n- Test case $4$:\n  - $x$: $[-3,-2,-1,0,1,2,3,4]$\n  - $y$: $[2.035,1.48,1.295,0.98,0.915,0.77,0.985,1.35]$\n\nYour program must, for each dataset, fit both candidate models and compute both the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) based on the Gaussian maximum-likelihood under the fitted residuals. For each criterion separately, select the model that attains the smaller value. Represent the quadratic model by the integer $2$ and the cubic model by the integer $3$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each item corresponds to one test case in the same order as above and must itself be a two-element list $[a,b]$ where $a$ is the preferred model by AIC and $b$ is the preferred model by BIC. For example, a valid output for four test cases is $[[2,2],[3,3],[2,2],[2,2]]$.\n\nNo physical units are required in your answer. Angles are not involved. Express all final decisions as integers.",
            "solution": "This problem requires performing model selection between a quadratic ($d=2$) and a cubic ($d=3$) polynomial model for several datasets. The solution involves a two-step process for each dataset: model fitting followed by criterion calculation.\n\n**1. Model Fitting**\n\nFor each polynomial model, the coefficients are found by minimizing the Residual Sum of Squares (RSS), a method known as Ordinary Least Squares (OLS). For a model with degree $d$ and coefficients $\\mathbf{\\beta}$, the RSS for a dataset with $n$ points $(x_i, y_i)$ is:\n$$ \\text{RSS} = \\sum_{i=1}^{n} (y_i - f(x_i; \\hat{\\mathbf{\\beta}}))^2 $$\nwhere $f(x; \\mathbf{\\beta}) = \\sum_{j=0}^{d} \\beta_j x^j$. A lower RSS indicates a better fit.\n\n**2. Model Selection**\n\nUnder the assumption of i.i.d. Gaussian errors, the maximized log-likelihood is a function of the RSS. The AIC and BIC can be expressed in terms of RSS as:\n$$ \\text{AIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + 2k $$\n$$ \\text{BIC} = n \\ln\\left(\\frac{\\text{RSS}}{n}\\right) + k \\ln(n) $$\nHere, $n$ is the number of data points, and $k$ is the number of free parameters. The problem defines $k = d+1$.\n- For the quadratic model ($d=2$), $k=3$.\n- For the cubic model ($d=3$), $k=4$.\n\nThese formulas drop constant terms that are identical for both models, which is sufficient for comparison. For each criterion, the model with the smaller value is selected as it represents a better balance between fit (low RSS) and parsimony (low $k$).\n\nThe following Python code implements this procedure for each dataset.\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the model selection problem for the given datasets.\n\n    For each dataset, it fits a quadratic (degree 2) and a cubic (degree 3)\n    polynomial model. It then calculates the Akaike Information Criterion (AIC)\n    and Bayesian Information Criterion (BIC) for both models and determines\n    which model is preferred by each criterion.\n    \"\"\"\n    test_cases = [\n        {\n            \"x\": [-3, -2, -1, 0, 1, 2, 3],\n            \"y\": [9.45, 4.90, 2.30, 0.95, 1.13, 3.09, 6.17]\n        },\n        {\n            \"x\": [-2, -1, 0, 1, 2, 3, 4],\n            \"y\": [3.35, 1.73, 0.52, -0.03, 0.94, 3.75, 9.31]\n        },\n        {\n            \"x\": [-1, -0.5, 0, 1, 2],\n            \"y\": [1.53, 1.605, 2.01, 3.49, 5.96]\n        },\n        {\n            \"x\": [-3, -2, -1, 0, 1, 2, 3, 4],\n            \"y\": [2.035, 1.48, 1.295, 0.98, 0.915, 0.77, 0.985, 1.35]\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        x_data = np.array(case[\"x\"])\n        y_data = np.array(case[\"y\"])\n        n = len(x_data)\n\n        # --- Model 1: Quadratic Polynomial ---\n        deg2 = 2\n        k2 = deg2 + 1\n        \n        _, residuals2_info, _, _, _ = np.polyfit(x_data, y_data, deg2, full=True)\n        rss2 = residuals2_info[0] if residuals2_info.size > 0 else 1e-16\n\n        aic2 = n * np.log(rss2 / n) + 2 * k2\n        bic2 = n * np.log(rss2 / n) + k2 * np.log(n)\n\n        # --- Model 2: Cubic Polynomial ---\n        deg3 = 3\n        k3 = deg3 + 1\n        \n        _, residuals3_info, _, _, _ = np.polyfit(x_data, y_data, deg3, full=True)\n        rss3 = residuals3_info[0] if residuals3_info.size > 0 else 1e-16\n        \n        aic3 = n * np.log(rss3 / n) + 2 * k3\n        bic3 = n * np.log(rss3 / n) + k3 * np.log(n)\n\n        # --- Model Selection ---\n        aic_choice = 3 if aic3  aic2 else 2\n        bic_choice = 3 if bic3  bic2 else 2\n\n        results.append([aic_choice, bic_choice])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Calling solve() would produce the final answer.\n```",
            "answer": "[[2,2],[3,3],[3,3],[3,3]]"
        }
    ]
}