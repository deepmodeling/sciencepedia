{
    "hands_on_practices": [
        {
            "introduction": "留一法交叉验证 (LOOCV) 通过每次只留一个数据点作为验证集，提供了对模型泛化能力近乎无偏的估计，但其表面上需要训练 $n$ 次模型的巨大计算成本常常令人望而却步。然而，对于神经科学数据分析中广泛应用的线性模型，存在一个优雅的解析捷径。本练习将引导你推导出这个捷径 ，揭示模型的残差、杠杆值与其留一法预测误差之间的深刻联系，并让你亲手计算，体会其如何将计算复杂度显著降低。",
            "id": "4152064",
            "problem": "考虑一个用于神经科学数据分析的线性普通最小二乘 (OLS) 回归，该回归用于通过一个编码了实验协变量（包括截距项）的设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 来建模一个 z-分数标准化的发放率响应 $y \\in \\mathbb{R}^{n}$。令 OLS 估计量由正规方程定义，帽子矩阵为 $H = X (X^{\\top} X)^{-1} X^{\\top}$，拟合值为 $\\hat{y} = H y$，残差为 $e = y - \\hat{y}$。留一交叉验证 (LOOCV) 通过对每个索引 $i$ 执行以下操作来评估预测质量：移除观测值 $i$ 后重新拟合 OLS 模型，然后计算在留出的协变量 $x_{i}^{\\top}$ 上的预测值。\n\n仅从 OLS 的基本定义和标准线性代数恒等式（包括 Sherman–Morrison–Woodbury 恒等式）出发，推导观测值 $i$ 处的 LOOCV 预测残差，用全样本残差 $e_{i}$ 和杠杆值 $h_{ii}$ 表示。然后，将 LOOCV 均方误差 (MSE) 表示为一个仅依赖于 $\\{e_{i}\\}$ 和 $\\{h_{ii}\\}$ 的单一闭式形式。解释为什么在神经回归流程中，这个表达式使得我们无需重新拟合 $n$ 个独立的 OLS 模型就能计算 LOOCV MSE。\n\n然后，将你的推导应用于以下实验，其中有 $n = 6$ 个试次和 $p = 3$ 个参数（一个截距项和两个刺激特征）。假设全样本 OLS 拟合产生了残差\n$$\ne_{1} = 0.8,\\quad e_{2} = -0.2,\\quad e_{3} = 1.1,\\quad e_{4} = -0.5,\\quad e_{5} = 0.3,\\quad e_{6} = -1.5,\n$$\n以及帽子矩阵的对角线元素（杠杆值）\n$$\nh_{11} = 0.7,\\quad h_{22} = 0.4,\\quad h_{33} = 0.6,\\quad h_{44} = 0.3,\\quad h_{55} = 0.5,\\quad h_{66} = 0.5,\n$$\n其中 $\\sum_{i=1}^{6} h_{ii} = p$ 与 OLS 的几何性质一致。将 LOOCV MSE 计算为单个实数。将最终数值答案四舍五入至四位有效数字。响应变量是 z-分数标准化的，因此报告一个无单位的值。",
            "solution": "该问题要求我们为普通最小二乘 (OLS) 回归模型推导留一交叉验证 (LOOCV) 的均方误差 (MSE)，解释其计算效率，并将推导出的公式应用于一个特定数据集。\n\n令完整数据集包含 $n$ 个观测值。OLS 模型为 $y = X\\beta + \\epsilon$，其中 $y \\in \\mathbb{R}^{n}$ 是响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^{p}$ 是系数向量。基于全样本的 $\\beta$ 的 OLS 估计量为 $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$。拟合值为 $\\hat{y} = X\\hat{\\beta} = X(X^{\\top} X)^{-1} X^{\\top} y = Hy$，其中 $H = X(X^{\\top} X)^{-1} X^{\\top}$ 是帽子矩阵。残差为 $e = y - \\hat{y}$，第 $i$ 个残差为 $e_i = y_i - \\hat{y}_i$。帽子矩阵的对角元素 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$ 是杠杆值，其中 $x_i^{\\top}$ 是 $X$ 的第 $i$ 行。\n\n我们的第一个目标是推导第 $i$ 个观测值的 LOOCV 预测残差。令 $X_{(-i)}$ 和 $y_{(-i)}$ 表示移除了第 $i$ 个观测值后的设计矩阵和响应向量。在没有第 $i$ 个观测值的情况下计算出的 OLS 估计量为 $\\hat{\\beta}_{(-i)} = (X_{(-i)}^{\\top} X_{(-i)})^{-1} X_{(-i)}^{\\top} y_{(-i)}$。$y_i$ 的 LOOCV 预测值为 $\\hat{y}_{i,(-i)} = x_i^{\\top} \\hat{\\beta}_{(-i)}$，相应的预测残差为 $e_{i, \\text{LOO}} = y_i - \\hat{y}_{i,(-i)}$。\n\n我们可以将矩阵 $X^{\\top} X$ 表示为外积之和：$X^{\\top} X = \\sum_{j=1}^{n} x_j x_j^{\\top}$。由此可知 $X_{(-i)}^{\\top} X_{(-i)} = \\sum_{j \\neq i} x_j x_j^{\\top} = X^{\\top} X - x_i x_i^{\\top}$。为了求该矩阵的逆，我们使用 Sherman-Morrison 公式，它是 Sherman–Morrison–Woodbury 恒等式的一个特例，其形式为 $(A - uv^{\\top})^{-1} = A^{-1} + \\frac{A^{-1}uv^{\\top}A^{-1}}{1 - v^{\\top}A^{-1}u}$。\n令 $A = X^{\\top} X$ 且 $u = v = x_i$，我们有：\n$$\n(X_{(-i)}^{\\top} X_{(-i)})^{-1} = (X^{\\top} X - x_i x_i^{\\top})^{-1} = (X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - x_i^{\\top} (X^{\\top} X)^{-1} x_i}\n$$\n注意到分母中的杠杆值 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$，上式可简化为：\n$$\n(X_{(-i)}^{\\top} X_{(-i)})^{-1} = (X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - h_{ii}}\n$$\n接下来，我们将 $X_{(-i)}^{\\top} y_{(-i)}$ 与全样本的量联系起来：$X^{\\top} y = \\sum_{j=1}^{n} x_j y_j = X_{(-i)}^{\\top} y_{(-i)} + x_i y_i$，所以 $X_{(-i)}^{\\top} y_{(-i)} = X^{\\top} y - x_i y_i$。\n\n现在我们可以写出 $\\hat{\\beta}_{(-i)}$ 的表达式：\n$$\n\\hat{\\beta}_{(-i)} = \\left((X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - h_{ii}}\\right) (X^{\\top} y - x_i y_i)\n$$\n展开此表达式：\n$$\n\\hat{\\beta}_{(-i)} = (X^{\\top} X)^{-1}(X^{\\top} y - x_i y_i) + \\frac{(X^{\\top} X)^{-1} x_i [x_i^{\\top} (X^{\\top} X)^{-1} (X^{\\top} y - x_i y_i)]}{1 - h_{ii}}\n$$\n回忆一下，$\\hat{\\beta} = (X^{\\top} X)^{-1}X^{\\top}y$，$\\hat{y}_i = x_i^{\\top}\\hat{\\beta}$，以及 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$。方括号中的项变为 $x_i^{\\top}\\hat{\\beta} - y_i(x_i^{\\top}(X^{\\top} X)^{-1}x_i) = \\hat{y}_i - y_i h_{ii}$。\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - (X^{\\top} X)^{-1}x_i y_i + \\frac{(X^{\\top} X)^{-1} x_i (\\hat{y}_i - y_i h_{ii})}{1 - h_{ii}}\n$$\n为简化起见，我们合并包含 $(X^{\\top} X)^{-1}x_i$ 的项：\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - (X^{\\top} X)^{-1}x_i \\left( y_i - \\frac{\\hat{y}_i - y_i h_{ii}}{1 - h_{ii}} \\right)\n$$\n括号中的项可简化为：\n$$\ny_i - \\frac{\\hat{y}_i - y_i h_{ii}}{1 - h_{ii}} = \\frac{y_i(1 - h_{ii}) - (\\hat{y}_i - y_i h_{ii})}{1 - h_{ii}} = \\frac{y_i - y_i h_{ii} - \\hat{y}_i + y_i h_{ii}}{1 - h_{ii}} = \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} = \\frac{e_i}{1 - h_{ii}}\n$$\n因此，留一法估计量和全样本系数估计量之间的关系为：\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - \\frac{(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}}\n$$\n现在我们可以求出 LOOCV 预测残差 $e_{i, \\text{LOO}} = y_i - x_i^{\\top} \\hat{\\beta}_{(-i)}$：\n$$\ne_{i, \\text{LOO}} = y_i - x_i^{\\top} \\left( \\hat{\\beta} - \\frac{(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}} \\right) = (y_i - x_i^{\\top}\\hat{\\beta}) + \\frac{x_i^{\\top}(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}}\n$$\n注意到 $e_i = y_i - x_i^{\\top}\\hat{\\beta}$ 和 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$，我们得到：\n$$\ne_{i, \\text{LOO}} = e_i + \\frac{h_{ii} e_i}{1 - h_{ii}} = e_i \\left(1 + \\frac{h_{ii}}{1 - h_{ii}}\\right) = e_i \\left(\\frac{1 - h_{ii} + h_{ii}}{1 - h_{ii}}\\right) = \\frac{e_i}{1 - h_{ii}}\n$$\n这就是所求的 LOOCV 残差和普通残差之间的关系。这些 LOOCV 残差也被称为 PRESS (预测残差平方和) 残差。\n\nLOOCV 均方误差是 LOOCV 残差平方的平均值：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{1}{n} \\sum_{i=1}^{n} (e_{i, \\text{LOO}})^2 = \\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{e_i}{1 - h_{ii}}\\right)^2\n$$\n这就是所要求的闭式表达式。\n\n这个公式提供了显著的计算优势。一种朴素的、暴力计算 LOOCV MSE 的方法需要拟合 OLS 模型 $n$ 次，每次省略一个观测值。对于一个有 $n$ 个观测值和 $p$ 个特征的数据集，每次 OLS 拟合的计算复杂度约为 $O(np^2 + p^3)$。总成本将是 $O(n(np^2+p^3))$。相比之下，推导出的公式允许我们只需在完整数据集上拟合一次模型，以获得残差 $\\{e_i\\}$ 和杠杆值 $\\{h_{ii}\\}$，就能计算出精确的 LOOCV MSE。这一次拟合的成本是 $O(np^2 + p^3)$，然后是一个 $O(n)$ 的计算来求和。对于大的 $n$（这在神经科学数据中很常见，例如，来自许多试次或时间点的脉冲序列），这将计算负担减少了大约 $n$ 倍，使 LOOCV 成为一种计算上可行且高效的模型评估方法。\n\n现在我们将此结果应用于给定的实验数据。\n给定：\n- 试次数, $n = 6$。\n- 参数个数, $p = 3$。\n- 全样本残差, $\\{ e_1, e_2, e_3, e_4, e_5, e_6 \\} = \\{ 0.8, -0.2, 1.1, -0.5, 0.3, -1.5 \\}$。\n- 全样本杠杆值, $\\{ h_{11}, h_{22}, h_{33}, h_{44}, h_{55}, h_{66} \\} = \\{ 0.7, 0.4, 0.6, 0.3, 0.5, 0.5 \\}$。\n\n使用 LOOCV MSE 的公式：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{1}{6} \\sum_{i=1}^{6} \\left(\\frac{e_i}{1 - h_{ii}}\\right)^2\n$$\n我们为每个观测值计算 LOOCV 残差的平方：\n- 对于 $i=1$: $\\left( \\frac{0.8}{1 - 0.7} \\right)^2 = \\left( \\frac{0.8}{0.3} \\right)^2 = \\left( \\frac{8}{3} \\right)^2 = \\frac{64}{9}$\n- 对于 $i=2$: $\\left( \\frac{-0.2}{1 - 0.4} \\right)^2 = \\left( \\frac{-0.2}{0.6} \\right)^2 = \\left( \\frac{-1}{3} \\right)^2 = \\frac{1}{9}$\n- 对于 $i=3$: $\\left( \\frac{1.1}{1 - 0.6} \\right)^2 = \\left( \\frac{1.1}{0.4} \\right)^2 = \\left( \\frac{11}{4} \\right)^2 = \\frac{121}{16}$\n- 对于 $i=4$: $\\left( \\frac{-0.5}{1 - 0.3} \\right)^2 = \\left( \\frac{-0.5}{0.7} \\right)^2 = \\left( \\frac{-5}{7} \\right)^2 = \\frac{25}{49}$\n- 对于 $i=5$: $\\left( \\frac{0.3}{1 - 0.5} \\right)^2 = \\left( \\frac{0.3}{0.5} \\right)^2 = \\left( \\frac{3}{5} \\right)^2 = \\frac{9}{25}$\n- 对于 $i=6$: $\\left( \\frac{-1.5}{1 - 0.5} \\right)^2 = \\left( \\frac{-1.5}{0.5} \\right)^2 = (-3)^2 = 9$\n\n现在，我们对这些值求和：\n$$\n\\sum_{i=1}^{6} (e_{i, \\text{LOO}})^2 = \\frac{64}{9} + \\frac{1}{9} + \\frac{121}{16} + \\frac{25}{49} + \\frac{9}{25} + 9\n$$\n$$\n= \\frac{65}{9} + \\frac{121}{16} + \\frac{25}{49} + \\frac{9}{25} + 9\n$$\n$$\n\\approx 7.222222 + 7.5625 + 0.510204 + 0.36 + 9 = 24.654926\n$$\n最后，我们通过除以 $n=6$ 来计算均值：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{24.654926}{6} \\approx 4.109154\n$$\n四舍五入到四位有效数字，LOOCV MSE 为 $4.109$。",
            "answer": "$$\\boxed{4.109}$$"
        },
        {
            "introduction": "模型选择是数据分析的核心环节，而交叉验证并非唯一的工具。本练习将交叉验证与另一类流行的方法——信息准则（如 $AIC$ 和 $BIC$）——进行正面对决。通过构建一个模拟的神经科学实验场景，其中数据生成过程故意违反了标准线性模型的某些核心假设（即同方差性），你将看到信息准则和交叉验证可能会给出截然不同的答案 。这个实践旨在从第一性原理出发，揭示交叉验证在面对模型设定不当时所表现出的稳健性，并深化你对不同评估方法内在逻辑的理解。",
            "id": "4152067",
            "problem": "您正在神经科学数据分析的背景下，分析受控刺激下的模拟单次试验神经响应振幅。您将比较刺激-响应映射的两个线性模型，并通过信息准则和交叉验证来评估模型选择。目的是构建并量化一个场景，在该场景中，信息准则选择了更复杂的模型，而交叉验证则偏好更简单的模型，并通过将每个准则都基于第一性原理进行解释来调和这种差异。\n\n推导的基本依据：从高斯观测模型的最大似然原理、定义为期望损失的样本外预测风险，以及均方误差的偏差-方差分解出发。设响应向量为 $y \\in \\mathbb{R}^n$，主要协变量为 $x \\in \\mathbb{R}^n$。设线性模型为 $y = X \\beta + \\varepsilon$，其中 $X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是通过普通最小二乘法估计的参数，$\\varepsilon$ 是加性噪声。使用在同方差性假设下通过最大化高斯对数似然得到的普通最小二乘估计量作为基础估计量。通过k折交叉验证和留一交叉验证来评估预测风险，这两种方法被定义为通过重复的训练-测试划分来近似期望损失。\n\n场景设计：模拟具有异方差试验噪声的数据，并考虑两种模型：\n- 一个较简单的模型，其设计矩阵 $X_{\\text{simple}}$ 由一个截距项和单个协变量 $x$ 组成（列为 $[1, x]$）。\n- 一个较复杂的模型，其设计矩阵 $X_{\\text{complex}}$ 由一个截距项、协变量 $x$ 以及直到 $d$ 次的多项式展开 $x^2, x^3, \\dots, x^d$ 组成（列为 $[1, x, x^2, \\dots, x^d]$）。\n\n数据生成：对于每个测试用例，从标准高斯分布中抽取 $x$，并根据 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 \\cdot \\mathbf{1}_{\\text{quad}} + \\varepsilon_i$ 生成 $y$，其中 $\\varepsilon_i \\sim \\mathcal{N}\\!\\left(0, \\sigma^2 \\cdot (1 + \\alpha x_i^2)\\right)$，且 $\\mathbf{1}_{\\text{quad}} \\in \\{0,1\\}$ 用于切换均值中是否包含真实的二次分量。这模拟了真实的神经振幅变异性，即响应变异性随刺激强度增加而增加，这种情况在较大刺激引起较大响应变异性时很常见。确保为每个测试用例设定随机数生成器的种子以保证可复现性。\n\n信息准则：计算Akaike信息准则（AIC）和贝叶斯信息准则（BIC）。使用最大化的高斯似然及其标准的参数数量惩罚项来估计AIC和BIC，其中 $p$ 是参数的数量。交叉验证：为每个模型计算留一交叉验证（LOOCV）均方误差和k折交叉验证均方误差。通过比较标量分数进行选择：较低的AIC或BIC表示更好的拟合，较低的交叉验证均方误差表示更好的预测性能。\n\n您的程序必须：\n- 对于每个测试用例，按照规定模拟数据，通过普通最小二乘法拟合两个模型，计算信息准则和交叉验证分数，并输出四个整数，表示每个准则选择的模型：\n  - 选择较简单的模型输出代码 $0$，选择较复杂的模型输出代码 $1$。\n  - 每个用例的四个输出为 $(\\text{AIC选择}, \\text{BIC选择}, \\text{LOOCV选择}, \\text{k折选择})$。\n- 将所有测试用例的结果汇总为单行输出，该输出包含一个用方括号括起来的、无空格的、逗号分隔的列表的列表。\n\n测试套件：\n- 用例 1：$n = 60$，$\\sigma = 4.0$，$\\alpha = 2.5$， $d = 6$， $k = 5$， 种子 $= 12345$， $\\mathbf{1}_{\\text{quad}} = 0$。\n- 用例 2：$n = 200$，$\\sigma = 0.8$，$\\alpha = 0.0$， $d = 2$， $k = 10$， 种子 $= 54321$， $\\mathbf{1}_{\\text{quad}} = 1$。\n- 用例 3：$n = 20$，$\\sigma = 3.0$，$\\alpha = 0.0$， $d = 8$， $k = 2$， 种子 $= 111$， $\\mathbf{1}_{\\text{quad}} = 0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的结果，形式为逗号分隔的列表的列表（例如，`[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]`），字符串中不含任何空格。\n- 所有输出必须是如上定义的整数。",
            "solution": "该问题要求在模拟的神经科学背景下分析模型选择准则，其目标是创建并解释一个场景，在该场景中，信息准则（Akaike信息准则，AIC；贝叶斯信息准则，BIC）和交叉验证（CV）方法得出了相互矛盾的模型选择。这种差异源于一种特定形式的模型设定错误：用一个假设误差为同方差的模型去拟合由异方差噪声生成的数据。\n\n首先，我们为所使用的方法建立理论框架。底层的估计程序是普通最小二乘法（OLS），它源于高斯噪声模型下的最大似然原理。\n\n设线性模型为 $y = X\\beta + \\varepsilon$，其中 $y \\in \\mathbb{R}^n$ 是观测到的响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是一个具有 $p$ 个参数的模型的设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是参数向量，$\\varepsilon \\in \\mathbb{R}^n$ 是噪声向量。OLS程序假设误差是独立同分布的，具体来说，对于所有 $i=1, \\dots, n$，有 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。在此假设下，数据的对数似然函数为：\n$$ \\ln \\mathcal{L}(\\beta, \\sigma^2; y, X) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\|y - X\\beta\\|^2 $$\n关于 $\\beta$ 最大化此函数等价于最小化残差平方和（RSS），即 $\\|y - X\\beta\\|^2$。这得到了著名的OLS估计量：\n$$ \\hat{\\beta} = (X^T X)^{-1} X^T y $$\n随后，方差的最大似然估计为 $\\hat{\\sigma}^2_{ML} = \\frac{1}{n}\\|y - X\\hat{\\beta}\\|^2 = \\frac{\\text{RSS}}{n}$。将这些估计值代回对数似然函数，得到最大化后的对数似然 $\\ln \\mathcal{L}_{\\text{max}}$。\n\n信息准则基于这个最大化后的对数似然。它们在样本内模型拟合优度和模型复杂度之间进行权衡。\nAkaike信息准则（AIC）定义为：\n$$ \\text{AIC} = -2\\ln\\mathcal{L}_{\\text{max}} + 2p $$\n贝叶斯信息准则（BIC）定义为：\n$$ \\text{BIC} = -2\\ln\\mathcal{L}_{\\text{max}} + p\\ln(n) $$\n使用从高斯模型推导出的 $\\mathcal{L}_{\\text{max}}$ 的表达式，并省略不影响模型比较的常数，这些准则可以表示为：\n$$ \\text{AIC} \\propto n \\ln(\\text{RSS}) + 2p $$\n$$ \\text{BIC} \\propto n \\ln(\\text{RSS}) + p\\ln(n) $$\n关键在于，AIC和BIC是通过似然函数来评估模型质量的，而似然函数是建立在同方差高斯噪声的假设之上的。\n\n相比之下，交叉验证提供了对模型样本外预测性能的直接、非参数估计。其目标是估计期望预测误差，或称风险，$E[(y_{\\text{new}} - \\hat{f}(x_{\\text{new}}))^2]$。\n对于k折交叉验证，数据集被划分为 $k$ 个不相交的子集（折）。模型在 $k-1$ 个折上进行训练，并在留出的那个折上测试其预测准确性。这个过程重复 $k$ 次，每个折都作为测试集一次。k折CV误差是在测试折上计算的均方误差（MSE）的平均值。\n留一交叉验证（LOOCV）是 $k=n$ 的特例。对于通过OLS拟合的线性模型，LOOCV误差可以通过解析方式高效计算，无需重复拟合模型：\n$$ \\text{MSE}_{\\text{LOOCV}} = \\frac{1}{n} \\sum_{i=1}^n \\left( \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)^2 $$\n其中 $\\hat{y}_i$ 是在所有数据上训练的模型得到的第 $i$ 个拟合值，而 $h_{ii}$ 是帽子矩阵 $H = X(X^T X)^{-1}X^T$ 的第 $i$ 个对角元素。\n\n当模型假设被违反时，核心冲突就出现了。在本问题中，数据是由异方差噪声生成的，其中误差项 $\\varepsilon_i$ 的方差依赖于协变量 $x_i$：$\\text{Var}(\\varepsilon_i) = \\sigma^2(1 + \\alpha x_i^2)$ 且 $\\alpha > 0$。然而，模型却是通过从一个错误地假设了恒定方差（$\\alpha=0$）的似然函数推导出的AIC和BIC来进行评估的。\n当一个更复杂的模型（例如，一个高阶多项式）被用来拟合这类数据时，它可以通过过拟合不仅真实的底层信号，还包括噪声的结构化模式，从而实现极低的RSS。设定错误的似然函数会为AIC/BIC将RSS的大幅下降解释为拟合优度显著提升的标志，这可能超过对新增参数的惩罚。因此，AIC和BIC可能会偏好过于复杂的模型。\n交叉验证对这种形式的设定错误更具鲁棒性。因为它直接衡量样本外预测误差，它会正确地识别出复杂模型的收益是由于拟合了训练集中的噪声，而这种“能力”无法泛化到未见的测试数据。过拟合的模型将表现出高方差，导致在留出数据上的预测效果差，从而得到更高的CV分数。这与偏差-方差权衡是一致的，即一个过于复杂的模型具有低偏差但高方差，导致总预测误差较大，而CV正是估计了这个误差。\n因此，在一个具有显著异方差性和一个足够复杂的备选模型的场景中，我们预期AIC和BIC会选择复杂模型，而CV方法会选择更简单、更具泛化能力的模型。\n\n该模拟实现了这一场景。对于给定的测试用例，执行以下步骤：\n1. **数据生成**：对于每个测试用例，生成 $n$ 个数据点 $(x_i, y_i)$。$x_i$ 的值从标准正态分布中抽取。响应值 $y_i$ 根据真实模型 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 \\cdot \\mathbf{1}_{\\text{quad}} + \\varepsilon_i$ 生成，其中噪声 $\\varepsilon_i$ 从 $\\mathcal{N}(0, \\sigma^2(1 + \\alpha x_i^2))$ 中抽取。选择真实系数为 $\\beta_0=0.5, \\beta_1=2.0, \\beta_2=1.5$ 来表示一个不可忽略的信号。\n2. **模型设定**：考虑两个模型：一个简单的线性模型 ($M_S$)，有 $p_S=2$ 个参数（截距项和 $x$）；以及一个复杂的多项式模型 ($M_C$)，有 $p_C=d+1$ 个参数（截距项和 $x$ 的幂次直到 $x^d$）。\n3. **模型拟合与评估**：两个模型都使用OLS拟合模拟数据。为每个模型计算AIC、BIC、LOOCV-MSE和k折-MSE分数。\n4. **选择**：对于每个准则，选择分数较低的模型。选择 $M_S$ 编码为 $0$，选择 $M_C$ 编码为 $1$。这样每个测试用例产生四个二元选择。\n\n测试用例中的参数旨在突出这种权衡的不同方面：\n- **用例 1**：一个简单的真实模型（$\\mathbf{1}_{\\text{quad}}=0$），高异方差性（$\\alpha=2.5$），以及一个非常复杂的备选模型（$d=6$）。这是信息准则和CV之间差异预期最为显著的典型案例。\n- **用例 2**：一个二次的真实模型（$\\mathbf{1}_{\\text{quad}}=1$），无异方差性（$\\alpha=0$），大样本量（$n=200$），以及一个与真实均值结构相匹配的复杂模型（$d=2$）。在这里，OLS的所有假设都得到满足，且复杂模型是正确的模型，所以所有准则应该会达成一致。\n- **用例 3**：一个简单的真实模型（$\\mathbf{1}_{\\text{quad}}=0$），无异方差性（$\\alpha=0$），但样本量非常小（$n=20$），以及一个极其复杂的备选模型（$d=8$）。这在经典的、严重的过拟合情况下测试了这些准则，且没有设定错误的误差结构这个混淆因素。BIC中较大的参数惩罚和CV的直接误差估计预期能防止过拟合，而AIC较弱的惩罚可能无法做到。\n\n现在，已实现的代码将为每个测试用例执行此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_model_selection(n, sigma, alpha, d, k, seed, quad_toggle, beta_params):\n    \"\"\"\n    Simulates data, fits simple and complex models, and compares them using\n    AIC, BIC, LOOCV, and k-fold CV.\n    \"\"\"\n    beta0, beta1, beta2 = beta_params\n    \n    # 1. Data Generation\n    rng = np.random.default_rng(seed)\n    x = rng.standard_normal(n)\n    \n    # Heteroscedastic noise\n    noise_std = sigma * np.sqrt(1 + alpha * x**2)\n    epsilon = rng.normal(0, noise_std)\n    \n    # True mean model\n    y_true_mean = beta0 + beta1 * x\n    if quad_toggle == 1:\n        y_true_mean += beta2 * x**2\n    y = y_true_mean + epsilon\n    \n    # 2. Define Models\n    # Simple model: intercept + x\n    X_simple = np.c_[np.ones(n), x]\n    p_simple = X_simple.shape[1]\n    \n    # Complex model: intercept + polynomials up to degree d\n    X_complex = np.vander(x, d + 1, increasing=True)\n    p_complex = X_complex.shape[1]\n    \n    model_results = {}\n    \n    # 3. Analyze each model\n    for model_name, X, p in [('simple', X_simple, p_simple), ('complex', X_complex, p_complex)]:\n        \n        # 3.1. OLS Fit\n        # np.linalg.lstsq is numerically stable\n        beta_hat = np.linalg.lstsq(X, y, rcond=None)[0]\n        y_hat = X @ beta_hat\n        rss = np.sum((y - y_hat)**2)\n        \n        # 3.2. AIC and BIC Calculation\n        # The criteria are proportional to n*log(RSS/n) + penalty.\n        # This form is valid for comparing models.\n        if rss == 0: # Avoid log(0) in edge cases\n            aic = np.inf\n            bic = np.inf\n        else:\n            log_likelihood_term = n * np.log(rss / n)\n            aic = log_likelihood_term + 2 * p\n            bic = log_likelihood_term + p * np.log(n)\n\n        # 3.3. LOOCV MSE (analytic formula for OLS)\n        # Use QR decomposition for stable computation of hat matrix diagonals\n        Q, _ = np.linalg.qr(X)\n        h_ii = np.sum(Q * Q, axis=1)\n        \n        # Avoid division by zero if h_ii is exactly 1\n        one_minus_h = 1 - h_ii\n        # Set a floor to avoid division by very small numbers or zero\n        one_minus_h[one_minus_h  1e-9] = 1e-9\n        \n        loocv_errors = (y - y_hat) / one_minus_h\n        mse_loocv = np.mean(loocv_errors**2)\n        \n        # 3.4. k-fold CV MSE (manual loop)\n        cv_rng = np.random.default_rng(seed + 1) # Use a derived seed for reproducible folds\n        indices = np.arange(n)\n        cv_rng.shuffle(indices)\n        \n        folds = np.array_split(indices, k)\n        \n        total_squared_error_kfold = 0\n        for i in range(k):\n            test_indices = folds[i]\n            train_indices_list = [folds[j] for j in range(k) if i != j]\n            if not train_indices_list: continue\n            train_indices = np.concatenate(train_indices_list)\n\n            X_train, y_train = X[train_indices], y[train_indices]\n            X_test, y_test = X[test_indices], y[test_indices]\n            \n            beta_hat_train = np.linalg.lstsq(X_train, y_train, rcond=None)[0]\n            y_hat_test = X_test @ beta_hat_train\n            \n            total_squared_error_kfold += np.sum((y_test - y_hat_test)**2)\n            \n        mse_kfold = total_squared_error_kfold / n\n        \n        model_results[model_name] = {\n            'aic': aic, \n            'bic': bic, \n            'mse_loocv': mse_loocv, \n            'mse_kfold': mse_kfold\n        }\n\n    # 4. Compare models and generate output codes (0 for simple, 1 for complex)\n    simple_scores = model_results['simple']\n    complex_scores = model_results['complex']\n    \n    aic_choice = 1 if complex_scores['aic']  simple_scores['aic'] else 0\n    bic_choice = 1 if complex_scores['bic']  simple_scores['bic'] else 0\n    loocv_choice = 1 if complex_scores['mse_loocv']  simple_scores['mse_loocv'] else 0\n    kfold_choice = 1 if complex_scores['mse_kfold']  simple_scores['mse_kfold'] else 0\n    \n    return [aic_choice, bic_choice, loocv_choice, kfold_choice]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # n, sigma, alpha, d, k, seed, quad_toggle\n        (60, 4.0, 2.5, 6, 5, 12345, 0),\n        (200, 0.8, 0.0, 2, 10, 54321, 1),\n        (20, 3.0, 0.0, 8, 2, 111, 0),\n    ]\n\n    # Set true coefficient values for the data generating process.\n    # These are reasonable, non-zero values chosen to create a clear signal.\n    beta_params = (0.5, 2.0, 1.5)\n\n    results = []\n    for case in test_cases:\n        result = calculate_model_selection(*case, beta_params=beta_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Example format: [[a1,b1,c1,d1],[a2,b2,c2,d2],[a3,b3,c3,d3]]\n    # str() creates spaces, so we remove them.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "交叉验证的有效性取决于训练集和验证集之间的严格隔离，但这种隔离有时会在不经意间被打破，导致所谓的“数据泄漏”。这种泄漏会使性能评估结果过于乐观，从而误导科学结论。本练习聚焦于一个在脑电图 (EEG) 分析中常见的预处理步骤——基线校正，探讨其如何成为数据泄漏的潜在源头 。通过分析这个问题，你将学会识别并修正这类微妙但至关重要的错误，掌握构建一个无泄漏、真正稳健的交叉验证流程的原则。",
            "id": "4152103",
            "problem": "考虑一个脑电图 (EEG) 实验，该实验包含来自单个受试者的 $N$ 个独立试验，每个试验在 $C$ 个通道上记录，具有刺激前基线窗口 $t \\in [-\\tau, 0)$ 和刺激后分析窗口 $t \\in [0, T)$。对于每个试验 $i \\in \\{1,\\dots,N\\}$ 和通道 $c \\in \\{1,\\dots,C\\}$，令 $B_{i,c}(t)$ 表示基线信号，$S_{i,c}(t)$ 表示分析窗口中的刺激后信号。在一个固定的、包含 $L$ 个时间样本的基线子窗口 $\\mathcal{W} \\subset [-\\tau, 0)$ 上，定义每个试验的基线平均值 $\\bar{B}_{i,c} = \\frac{1}{L} \\sum_{t \\in \\mathcal{W}} B_{i,c}(t)$。\n\n假设从经过基线校正的刺激后信号中提取特征 $X_i \\in \\mathbb{R}^d$。考虑两种基线校正策略：\n\n1. 跨试验基线减法：估计一个全局的、每个通道的基线 $\\hat{\\mu}_c = \\frac{1}{N} \\sum_{i=1}^{N} \\bar{B}_{i,c}$，并在特征提取前从所有试验的所有通道中减去 $\\hat{\\mu}_c$，即使用 $S'_{i,c}(t) = S_{i,c}(t) - \\hat{\\mu}_c$。\n\n2. 逐试验基线减法：从每个试验的刺激后信号中减去其自身的基线平均值，即 $S'_{i,c}(t) = S_{i,c}(t) - \\bar{B}_{i,c}$。\n\n训练一个分类器 $f$ 从 $X_i$ 预测试验标签 $y_i \\in \\{0,1\\}$，并使用 $K$ 折交叉验证来估计其性能，其中折为 $(\\mathcal{T}_k, \\mathcal{V}_k)$，$k \\in \\{1,\\dots,K\\}$，$\\mathcal{T}_k$ 和 $\\mathcal{V}_k$ 分别是训练和验证索引集，且 $\\mathcal{T}_k \\cap \\mathcal{V}_k = \\emptyset$，$\\mathcal{T}_k \\cup \\mathcal{V}_k = \\{1,\\dots,N\\}$。风险的交叉验证估计量为\n$$\n\\hat{R}_{CV} = \\frac{1}{K} \\sum_{k=1}^{K} \\frac{1}{|\\mathcal{V}_k|} \\sum_{i \\in \\mathcal{V}_k} \\ell\\!\\left(f_k\\!\\left(\\Phi_k(X_i)\\right),\\, y_i\\right),\n$$\n其中 $\\ell$ 是有界损失函数，$f_k$ 是在经过预处理映射 $\\Phi_k$ 转换后的特征上训练的分类器（$\\Phi_k$ 可能依赖于用于拟合它的数据），$X_i$ 表示根据所选策略从基线校正信号中提取的特征。\n\n假设试验是独立同分布 (i.i.d.) 的，在任何处理之前，基线和刺激后窗口不含与标签相关的伪迹，并且 $f_k$ 仅在预处理后于 $\\mathcal{T}_k$ 上训练。\n\n在 $K$ 折交叉验证和留一法交叉验证 (LOOCV)下，关于跨试验基线减法和考虑折的基线估计过程所导致的信息泄露，以下哪些陈述是正确的？\n\nA. 在分配折之前，使用所有 $N$ 个试验一次性估计全局跨试验基线 $\\hat{\\mu}_c$ 不会引入信息泄露，因为该估计量不使用标签，并且只访问刺激前数据。\n\nB. 一个考虑折的跨试验基线估计量，定义为 $\\hat{\\mu}_{c}^{(k)} = \\frac{1}{|\\mathcal{T}_k|} \\sum_{i \\in \\mathcal{T}_k} \\bar{B}_{i,c}$，并应用于第 $k$ 折内的所有训练和验证试验，可以防止信息泄露，并且在 i.i.d. 假设下产生泛化风险的无偏估计。\n\nC. 在留一法交叉验证 (LOOCV) 中，使用在所有 $N$ 个试验（包括留出的试验）上估计的全局 $\\hat{\\mu}_c$ 不会使性能产生偏差，因为留出试验的贡献是 $1/N$，当 $N$ 增大时该值趋于零。\n\nD. 仅在训练试验上计算的、考虑折的基线估计量减少了信息泄露，但相对于使用所有 $N$ 个试验，通常会增加基线估计的方差；尽管如此，在 i.i.d. 试验下，交叉验证仍然是泛化风险的无偏估计量。\n\nE. 逐试验基线减法 $S'_{i,c}(t) = S_{i,c}(t) - \\bar{B}_{i,c}$，对训练和验证试验同样应用，是与折无关的，并且不会引起信息泄露，因为它在转换给定试验时不使用来自其他试验的信息。",
            "solution": "我们从基本定义开始。交叉验证通过留出验证集 $\\mathcal{V}_k$，在 $\\mathcal{T}_k$ 上拟合整个预处理和学习流程，并在 $\\mathcal{V}_k$ 上进行评估，来构建样本外风险的估计。在独立同分布 (i.i.d.) 试验的假设下，并且将验证数据与任何使用训练数据拟合参数的步骤完全隔离，$\\hat{R}_{CV}$ 是与将训练数据映射到预测器 $f_k$ 和预处理 $\\Phi_k$ 的流程相关的泛化风险的无偏估计量。\n\n当来自 $\\mathcal{V}_k$ 的信息影响了在训练时拟合的对象时，就会发生数据泄露，从而破坏了验证评估和训练流程之间的独立性。关键是，这包括那些使用所有数据（即包括 $\\mathcal{V}_k$）来估计参数的无监督预处理，因为它会在应用于验证试验的变换与这些验证试验本身之间引入统计依赖性。\n\n为了分析跨试验基线减法，我们考虑全局的、每个通道的基线估计量\n$$\n\\hat{\\mu}_c = \\frac{1}{N} \\sum_{i=1}^{N} \\bar{B}_{i,c}.\n$$\n令 $j \\in \\mathcal{V}_k$ 为一个验证试验。如果我们在分配折之前从所有试验中减去 $\\hat{\\mu}_c$，则转换后的验证信号为\n$$\nS'_{j,c}(t) = S_{j,c}(t) - \\hat{\\mu}_c = S_{j,c}(t) - \\frac{1}{N}\\bar{B}_{j,c} - \\frac{1}{N}\\sum_{i \\neq j} \\bar{B}_{i,c}.\n$$\n这里的预处理变换 $\\Phi$ 由 $\\hat{\\mu}_c$ 参数化，而 $\\hat{\\mu}_c$ 是所有试验（包括正在评估的试验 $j$）的函数。因此，转换后的验证特征 $X_j$ 不仅通过其自身的原始信号依赖于 $j$，还通过包含 $\\bar{B}_{j,c}$ 的拟合参数 $\\hat{\\mu}_c$ 依赖于 $j$。这在变换参数和验证数据之间引入了非零协方差：\n$$\n\\operatorname{Cov}\\!\\left(\\hat{\\mu}_c,\\, \\bar{B}_{j,c}\\right) = \\operatorname{Var}\\!\\left(\\bar{B}_{j,c}\\right)\\cdot \\frac{1}{N} \\neq 0,\n$$\n假设 $\\operatorname{Var}\\!\\left(\\bar{B}_{j,c}\\right)  0$。因此，验证损失 $\\ell\\!\\left(f_k\\!\\left(\\Phi(X_j)\\right), y_j\\right)$ 与在划分折之前拟合的训练流程不是独立的，并且 $\\hat{R}_{CV}$ 会向下偏置（过于乐观），即使在拟合 $\\hat{\\mu}_c$ 时没有使用标签。每个试验的影响大小与 $1/N$ 成比例，但对于有限的 $N$ 来说，它不为零，因此存在信息泄露。\n\n一个考虑折的跨试验基线估计量通过仅使用训练试验来估计每折的基线来解决这个问题：\n$$\n\\hat{\\mu}_{c}^{(k)} = \\frac{1}{|\\mathcal{T}_k|} \\sum_{i \\in \\mathcal{T}_k} \\bar{B}_{i,c}.\n$$\n在第 $k$ 折内，对所有 $i \\in \\mathcal{T}_k \\cup \\mathcal{V}_k$，在特征提取前使用 $S'_{i,c}(t) = S_{i,c}(t) - \\hat{\\mu}_{c}^{(k)}$。现在，对于 $j \\in \\mathcal{V}_k$，在 i.i.d. 试验的假设下，变换参数 $\\hat{\\mu}_{c}^{(k)}$ 与 $\\bar{B}_{j,c}$ 和 $S_{j,c}(t)$ 是独立的，因为它只是 $\\{\\bar{B}_{i,c} : i \\in \\mathcal{T}_k\\}$ 的函数。这恢复了验证数据和拟合的训练流程之间所要求的独立性，确保了 $\\hat{R}_{CV}$ 仍然是在训练数据上拟合 $\\hat{\\mu}_{c}^{(k)}$ 的流程的风险的无偏估计量。付出的代价是 $\\hat{\\mu}_{c}^{(k)}$ 相对于 $\\hat{\\mu}_c$ 的方差增加了：\n$$\n\\operatorname{Var}\\!\\left(\\hat{\\mu}_{c}^{(k)}\\right) = \\frac{1}{|\\mathcal{T}_k|}\\operatorname{Var}\\!\\left(\\bar{B}_{i,c}\\right), \\quad\n\\operatorname{Var}\\!\\left(\\hat{\\mu}_c\\right) = \\frac{1}{N}\\operatorname{Var}\\!\\left(\\bar{B}_{i,c}\\right),\n$$\n因此 $\\operatorname{Var}\\!\\left(\\hat{\\mu}_{c}^{(k)}\\right) \\ge \\operatorname{Var}\\!\\left(\\hat{\\mu}_c\\right)$ 因为 $|\\mathcal{T}_k| \\le N$。这种增加的方差会使每折的变换噪声更大，但只要 i.i.d. 假设成立，它不会给交叉验证的风险估计引入偏差。\n\n对于留一法交叉验证 (LOOCV)，$K = N$ 且 $|\\mathcal{T}_k| = N - 1$。使用包含留出试验 $j$ 的全局估计量 $\\hat{\\mu}_c$ 仍然会用来自 $j$ 的信息污染验证变换，其贡献权重为 $1/N$。尽管对于大的 $N$ 来说这种影响很小，但对于有限的 $N$ 来说它不为零，因此信息泄露依然存在，且估计量不是严格无偏的。正确的 LOOCV 实现对留出的试验 $j$ 使用\n$$\n\\hat{\\mu}_{c}^{(-j)} = \\frac{1}{N - 1} \\sum_{i \\neq j} \\bar{B}_{i,c},\n$$\n从而再次恢复独立性。\n\n最后，考虑逐试验基线减法 $S'_{i,c}(t) = S_{i,c}(t) - \\bar{B}_{i,c}$。这种变换完全由试验 $i$ 本身计算得出，不依赖于其他试验。当对训练集和验证集中的所有试验同样应用时，它不会产生跨折的依赖性或信息泄露。这是一个样本级别的预处理步骤，而不是一个需要训练数据来拟合的参数，因此它与折无关。\n\n我们现在评估每个选项：\n\nA. 错误。尽管没有使用标签，但在交叉验证之前在所有 $N$ 个试验上拟合 $\\hat{\\mu}_c$ 会使用验证数据来设置一个预处理参数。这在 $\\Phi$ 和验证试验之间创建了依赖关系，从而导致信息泄露和偏差。\n\nB. 正确。仅使用 $\\mathcal{T}_k$ 估计 $\\hat{\\mu}_{c}^{(k)}$ 并将其应用于第 $k$ 折内，可以防止验证数据影响拟合的预处理。在 i.i.d. 试验下，这会产生一个无偏的交叉验证风险估计。\n\nC. 错误。留出试验对 $\\hat{\\mu}_c$ 的 $1/N$ 贡献虽小但非零。对于有限的 $N$，这仍然会导致信息泄露和偏差。正确的 LOOCV 要求从基线估计中排除留出的试验。\n\nD. 正确。仅使用训练试验来估计基线会相对于使用所有试验增加了基线估计量的方差，但它消除了信息泄露。在 i.i.d. 试验下，对于考虑折的流程，交叉验证估计量仍然是泛化风险的无偏估计量。\n\nE. 正确。逐试验基线减法仅使用来自试验本身的信息，并且不在其他数据上拟合参数。当一致地应用时，它不会导致跨折信息泄露。",
            "answer": "$$\\boxed{BDE}$$"
        }
    ]
}