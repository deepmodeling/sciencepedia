{
    "hands_on_practices": [
        {
            "introduction": "留一法交叉验证（LOOCV）是 k 折交叉验证最细粒度的形式，但其表面上需要重新拟合模型 $n$ 次，计算成本似乎极高。这个练习 () 将引导你完成一个数学推导，证明对于线性模型，这种计算负担可以被完全绕开。你将发现，模型的残差、杠杆值与预测误差之间存在着深刻的联系，这一实践是理解交叉验证分析性质的基础。",
            "id": "4152064",
            "problem": "考虑一个用于神经科学数据分析的线性普通最小二乘 (OLS) 回归模型，该模型用于从一个编码了实验协变量（包括一个截距）的设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 来建模一个 z-分数化的发放率响应 $y \\in \\mathbb{R}^{n}$。设 OLS 估计量由正规方程定义，帽子矩阵为 $H = X (X^{\\top} X)^{-1} X^{\\top}$，拟合值为 $\\hat{y} = H y$，残差为 $e = y - \\hat{y}$。留一交叉验证 (LOOCV) 通过对每个索引 $i$ 进行如下操作来评估预测质量：移除观测值 $i$ 后重新拟合 OLS 模型，然后计算在留出的协变量 $x_{i}^{\\top}$ 上的预测值。\n\n请仅从 OLS 的基本定义和标准的线性代数恒等式（包括 Sherman–Morrison–Woodbury 恒等式）出发，推导观测值 $i$ 处的 LOOCV 预测残差，用全样本残差 $e_{i}$ 和杠杆值 $h_{ii}$ 表示。然后，将 LOOCV 均方误差 (MSE) 表示为一个仅依赖于 $\\{e_{i}\\}$ 和 $\\{h_{ii}\\}$ 的单一闭式。解释为什么在神经回归流程中，这个表达式使得我们无需重新拟合 $n$ 个独立的 OLS 模型就能计算 LOOCV MSE。\n\n然后，将你的推导应用于以下实验：该实验有 $n = 6$ 次试验和 $p = 3$ 个参数（一个截距和两个刺激特征）。假设全样本 OLS 拟合产生了如下残差\n$$\ne_{1} = 0.8,\\quad e_{2} = -0.2,\\quad e_{3} = 1.1,\\quad e_{4} = -0.5,\\quad e_{5} = 0.3,\\quad e_{6} = -1.5,\n$$\n和帽子矩阵的对角线元素（杠杆值）\n$$\nh_{11} = 0.7,\\quad h_{22} = 0.4,\\quad h_{33} = 0.6,\\quad h_{44} = 0.3,\\quad h_{55} = 0.5,\\quad h_{66} = 0.5,\n$$\n其中 $\\sum_{i=1}^{6} h_{ii} = p$ 与 OLS 的几何性质一致。计算 LOOCV MSE，结果表示为一个实数。将最终数值答案四舍五入到四位有效数字。响应变量是 z-分数化的，因此报告一个无单位的值。",
            "solution": "本题要求推导普通最小二乘 (OLS) 回归模型的留一交叉验证 (LOOCV) 均方误差 (MSE)，解释其计算效率，并将推导出的公式应用于一个具体的数据集。\n\n设完整数据集包含 $n$ 个观测值。OLS 模型为 $y = X\\beta + \\epsilon$，其中 $y \\in \\mathbb{R}^{n}$ 是响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^{p}$ 是系数向量。基于全样本的 $\\beta$ 的 OLS 估计量是 $\\hat{\\beta} = (X^{\\top} X)^{-1} X^{\\top} y$。拟合值为 $\\hat{y} = X\\hat{\\beta} = X(X^{\\top} X)^{-1} X^{\\top} y = Hy$，其中 $H = X(X^{\\top} X)^{-1} X^{\\top}$ 是帽子矩阵。残差为 $e = y - \\hat{y}$，第 $i$ 个残差为 $e_i = y_i - \\hat{y}_i$。帽子矩阵的对角元素 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$ 是杠杆值，其中 $x_i^{\\top}$ 是 $X$ 的第 $i$ 行。\n\n我们的首要目标是推导第 $i$ 个观测值的 LOOCV 预测残差。设 $X_{(-i)}$ 和 $y_{(-i)}$ 表示移除了第 $i$ 个观测值后的设计矩阵和响应向量。在没有第 $i$ 个观测值的情况下计算出的 OLS 估计量是 $\\hat{\\beta}_{(-i)} = (X_{(-i)}^{\\top} X_{(-i)})^{-1} X_{(-i)}^{\\top} y_{(-i)}$。对 $y_i$ 的 LOOCV 预测是 $\\hat{y}_{i,(-i)} = x_i^{\\top} \\hat{\\beta}_{(-i)}$，相应的预测残差是 $e_{i, \\text{LOO}} = y_i - \\hat{y}_{i,(-i)}$。\n\n我们可以将矩阵 $X^{\\top} X$ 表示为外积之和：$X^{\\top} X = \\sum_{j=1}^{n} x_j x_j^{\\top}$。因此，$X_{(-i)}^{\\top} X_{(-i)} = \\sum_{j \\neq i} x_j x_j^{\\top} = X^{\\top} X - x_i x_i^{\\top}$。为了求该矩阵的逆，我们使用 Sherman-Morrison 公式，它是 Sherman–Morrison–Woodbury 恒等式的一个特例，该公式表明 $(A - uv^{\\top})^{-1} = A^{-1} + \\frac{A^{-1}uv^{\\top}A^{-1}}{1 - v^{\\top}A^{-1}u}$。\n令 $A = X^{\\top} X$ 且 $u = v = x_i$，我们得到：\n$$\n(X_{(-i)}^{\\top} X_{(-i)})^{-1} = (X^{\\top} X - x_i x_i^{\\top})^{-1} = (X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - x_i^{\\top} (X^{\\top} X)^{-1} x_i}\n$$\n识别出分母中的杠杆值 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$，上式可简化为：\n$$\n(X_{(-i)}^{\\top} X_{(-i)})^{-1} = (X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - h_{ii}}\n$$\n接下来，我们将 $X_{(-i)}^{\\top} y_{(-i)}$ 与全样本量联系起来：$X^{\\top} y = \\sum_{j=1}^{n} x_j y_j = X_{(-i)}^{\\top} y_{(-i)} + x_i y_i$，所以 $X_{(-i)}^{\\top} y_{(-i)} = X^{\\top} y - x_i y_i$。\n\n现在我们可以写出 $\\hat{\\beta}_{(-i)}$ 的表达式：\n$$\n\\hat{\\beta}_{(-i)} = \\left((X^{\\top} X)^{-1} + \\frac{(X^{\\top} X)^{-1} x_i x_i^{\\top} (X^{\\top} X)^{-1}}{1 - h_{ii}}\\right) (X^{\\top} y - x_i y_i)\n$$\n展开此表达式：\n$$\n\\hat{\\beta}_{(-i)} = (X^{\\top} X)^{-1}(X^{\\top} y - x_i y_i) + \\frac{(X^{\\top} X)^{-1} x_i [x_i^{\\top} (X^{\\top} X)^{-1} (X^{\\top} y - x_i y_i)]}{1 - h_{ii}}\n$$\n回顾 $\\hat{\\beta} = (X^{\\top} X)^{-1}X^{\\top}y$，$\\hat{y}_i = x_i^{\\top}\\hat{\\beta}$，以及 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$。方括号中的项变为 $x_i^{\\top}\\hat{\\beta} - y_i(x_i^{\\top}(X^{\\top} X)^{-1}x_i) = \\hat{y}_i - y_i h_{ii}$。\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - (X^{\\top} X)^{-1}x_i y_i + \\frac{(X^{\\top} X)^{-1} x_i (\\hat{y}_i - y_i h_{ii})}{1 - h_{ii}}\n$$\n为简化起见，我们合并包含 $(X^{\\top} X)^{-1}x_i$ 的项：\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - (X^{\\top} X)^{-1}x_i \\left( y_i - \\frac{\\hat{y}_i - y_i h_{ii}}{1 - h_{ii}} \\right)\n$$\n括号中的项简化为：\n$$\ny_i - \\frac{\\hat{y}_i - y_i h_{ii}}{1 - h_{ii}} = \\frac{y_i(1 - h_{ii}) - (\\hat{y}_i - y_i h_{ii})}{1 - h_{ii}} = \\frac{y_i - y_i h_{ii} - \\hat{y}_i + y_i h_{ii}}{1 - h_{ii}} = \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} = \\frac{e_i}{1 - h_{ii}}\n$$\n因此，留一法和全样本系数估计量之间的关系是：\n$$\n\\hat{\\beta}_{(-i)} = \\hat{\\beta} - \\frac{(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}}\n$$\n现在我们可以求出 LOOCV 预测残差 $e_{i, \\text{LOO}} = y_i - x_i^{\\top} \\hat{\\beta}_{(-i)}$：\n$$\ne_{i, \\text{LOO}} = y_i - x_i^{\\top} \\left( \\hat{\\beta} - \\frac{(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}} \\right) = (y_i - x_i^{\\top}\\hat{\\beta}) + \\frac{x_i^{\\top}(X^{\\top} X)^{-1} x_i e_i}{1 - h_{ii}}\n$$\n识别出 $e_i = y_i - x_i^{\\top}\\hat{\\beta}$ 和 $h_{ii} = x_i^{\\top}(X^{\\top} X)^{-1}x_i$，我们得到：\n$$\ne_{i, \\text{LOO}} = e_i + \\frac{h_{ii} e_i}{1 - h_{ii}} = e_i \\left(1 + \\frac{h_{ii}}{1 - h_{ii}}\\right) = e_i \\left(\\frac{1 - h_{ii} + h_{ii}}{1 - h_{ii}}\\right) = \\frac{e_i}{1 - h_{ii}}\n$$\n这就是所求的 LOOCV 残差与普通残差之间的关系。这些 LOOCV 残差也被称为 PRESS (预测残差平方和) 残差。\n\nLOOCV 均方误差是 LOOCV 残差平方的平均值：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{1}{n} \\sum_{i=1}^{n} (e_{i, \\text{LOO}})^2 = \\frac{1}{n} \\sum_{i=1}^{n} \\left(\\frac{e_i}{1 - h_{ii}}\\right)^2\n$$\n这就是所要求的闭式表达式。\n\n这个公式提供了巨大的计算优势。一种朴素的、暴力的计算 LOOCV MSE 的方法需要拟合 OLS 模型 $n$ 次，每次省略一个观测值。对于一个有 $n$ 个观测值和 $p$ 个特征的数据集，每次 OLS 拟合的计算复杂度约为 $O(np^2 + p^3)$。总成本将是 $O(n(np^2+p^3))$。相比之下，推导出的公式允许我们通过在完整数据集上仅拟合一次模型来获得残差 $\\{e_i\\}$ 和杠杆值 $\\{h_{ii}\\}$，从而计算出精确的 LOOCV MSE。这一次拟合的成本是 $O(np^2 + p^3)$，随后是一个 $O(n)$ 的求和计算。对于大的 $n$（这在神经科学数据中很常见，例如，来自许多试验或时间点的脉冲序列），这将计算负担减少了大约 $n$ 倍，使 LOOCV 成为一种计算上可行且高效的模型评估方法。\n\n现在我们将此结果应用于给定的实验数据。\n给定：\n- 试验次数，$n = 6$。\n- 参数数量，$p = 3$。\n- 全样本残差，$\\{ e_1, e_2, e_3, e_4, e_5, e_6 \\} = \\{ 0.8, -0.2, 1.1, -0.5, 0.3, -1.5 \\}$。\n- 全样本杠杆值，$\\{ h_{11}, h_{22}, h_{33}, h_{44}, h_{55}, h_{66} \\} = \\{ 0.7, 0.4, 0.6, 0.3, 0.5, 0.5 \\}$。\n\n使用 LOOCV MSE 的公式：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{1}{6} \\sum_{i=1}^{6} \\left(\\frac{e_i}{1 - h_{ii}}\\right)^2\n$$\n我们计算每个观测值的 LOOCV 残差的平方：\n- 对于 $i=1$: $\\left( \\frac{0.8}{1 - 0.7} \\right)^2 = \\left( \\frac{0.8}{0.3} \\right)^2 = \\left( \\frac{8}{3} \\right)^2 = \\frac{64}{9}$\n- 对于 $i=2$: $\\left( \\frac{-0.2}{1 - 0.4} \\right)^2 = \\left( \\frac{-0.2}{0.6} \\right)^2 = \\left( \\frac{-1}{3} \\right)^2 = \\frac{1}{9}$\n- 对于 $i=3$: $\\left( \\frac{1.1}{1 - 0.6} \\right)^2 = \\left( \\frac{1.1}{0.4} \\right)^2 = \\left( \\frac{11}{4} \\right)^2 = \\frac{121}{16}$\n- 对于 $i=4$: $\\left( \\frac{-0.5}{1 - 0.3} \\right)^2 = \\left( \\frac{-0.5}{0.7} \\right)^2 = \\left( \\frac{-5}{7} \\right)^2 = \\frac{25}{49}$\n- 对于 $i=5$: $\\left( \\frac{0.3}{1 - 0.5} \\right)^2 = \\left( \\frac{0.3}{0.5} \\right)^2 = \\left( \\frac{3}{5} \\right)^2 = \\frac{9}{25}$\n- 对于 $i=6$: $\\left( \\frac{-1.5}{1 - 0.5} \\right)^2 = \\left( \\frac{-1.5}{0.5} \\right)^2 = (-3)^2 = 9$\n\n现在，我们将这些值相加：\n$$\n\\sum_{i=1}^{6} (e_{i, \\text{LOO}})^2 = \\frac{64}{9} + \\frac{1}{9} + \\frac{121}{16} + \\frac{25}{49} + \\frac{9}{25} + 9\n$$\n$$\n= \\frac{65}{9} + \\frac{121}{16} + \\frac{25}{49} + \\frac{9}{25} + 9\n$$\n$$\n\\approx 7.222222 + 7.5625 + 0.510204 + 0.36 + 9 = 24.654926\n$$\n最后，我们通过除以 $n=6$ 来计算均值：\n$$\n\\text{MSE}_{\\text{LOO}} = \\frac{24.654926}{6} \\approx 4.109154\n$$\n四舍五入到四位有效数字，LOOCV MSE 为 $4.109$。",
            "answer": "$$\\boxed{4.109}$$"
        },
        {
            "introduction": "在构建模型并用交叉验证评估其性能后，我们通常会问：“这个性能在统计上显著吗？”。置换检验（Permutation testing）是回答此问题的标准非参数方法，但它包含一个微妙而关键的陷阱。这个练习 () 探讨了将置换检验与交叉验证相结合时的错误与正确方法，以确保生成的零分布是有效的，并且统计推断不会产生过于乐观的偏差。",
            "id": "4152145",
            "problem": "一个实验室正在分析来自一项视觉运动任务的 $n$ 次试验的多变量神经元记录，其中每次试验都有一个特征向量 $X_i \\in \\mathbb{R}^p$ 和一个二元标签 $Y_i \\in \\{0,1\\}$，表示是否存在运动指令。该实验室使用 $k$ 折交叉验证 (CV) 来估计泛化性能，其中 $k \\geq 2$，并且也考虑将留一法交叉验证 (LOOCV) 作为 $k = n$ 的特例。对于一个将 $X$ 映射到预测标签 $\\hat{Y} = \\hat{f}(X)$ 的监督学习器，期望损失的 CV 估计量定义为\n$$\n\\hat{T}_{\\text{CV}} = \\frac{1}{n} \\sum_{i=1}^n \\ell\\bigl(Y_i, \\hat{f}^{(-i)}(X_i)\\bigr),\n$$\n其中 $\\ell(\\cdot,\\cdot)$ 是一个固定的损失函数（对于分类问题，是 $0$-$1$ 损失），而 $\\hat{f}^{(-i)}$ 表示在不使用样本 $i$ 的情况下，仅使用相应训练折的数据和标签训练出的模型。该实验室希望在 $Y$ 与 $X$ 独立的零假设下，为 $\\hat{T}_{\\text{CV}}$ 计算一个基于置换的零分布。一名技术人员提出了以下捷径：在 CV 循环之外，生成一个 $\\{1,\\dots,n\\}$ 的单一全局置换 $\\pi$，对所有 $i$ 用 $Y_{\\pi(i)}$ 替换 $Y_i$，然后对置换后的数据集照常运行 $k$ 折 CV 以获得零分布下的值。\n\n使用的基本原理：\n- 监督学习中置换检验的零假设是 $Y$ 与 $X$ 独立。\n- 零假设下的可交换性意味着通过随机置换对 $Y$ 进行重新标记会保留数据的联合分布，但不得改变目标统计量的条件结构（训练与测试的分离）。\n- 一个有效的 CV 过程通过确保对于每个留出的样本 $i$，$\\hat{f}^{(-i)}$ 仅依赖于训练集的特征和标签，而不依赖于任何从留出样本的特征或标签中派生的信息，来估计泛化损失。\n\n问题：哪个选项正确地解释了为什么在 CV 循环外置换标签会产生有偏的 $\\hat{T}_{\\text{CV}}$ 零分布估计，并且哪个选项提供了一个修正的算法，该算法在每次重采样内部执行标签置换，以使零分布的目标为 $E\\bigl[\\ell(Y, \\hat{f}(X)) \\mid Y \\perp X\\bigr]$？\n\n选项：\n- A. 理由：在 CV 循环外进行单一的全局置换，会用 $Y_{\\pi(i)}$ 替换测试标签，从而将目标统计量从 $\\ell(Y_i, \\hat{f}^{(-i)}(X_i))$ 改变为 $\\ell(Y_{\\pi(i)}, \\hat{f}^{(-i)}(X_i))$，这并不是原始性能指标的零分布，并且在典型的依赖于标签的预处理或模型选择中，这会在学习到的内容和置换后的测试标签之间引入依赖性，从而产生乐观偏差。修正算法：对于每个外部重采样（$k$ 折 CV 中的每一折或 LOOCV 中的每个留出样本）以及对于每个置换 $b \\in \\{1,\\dots,B\\}$，通过定义在训练索引上的置换 $\\pi_{b,r}$，仅在该重采样内部置换训练标签，使用置换后的训练标签训练包括任何预处理和超参数调整在内的完整流程，对留出的测试特征进行预测，并根据真实的测试标签 $Y_i$ 进行评分。聚合各折的损失以获得一个零分布下的重复值。对 $b$ 进行重复以形成零分布。\n- B. 理由：在 CV 外部进行全局置换会增加方差但不会引入偏差，因为置换标签保留了可交换性。修正算法：全局置换特征向量 $X_i$，而不是标签 $Y_i$，然后运行 $k$ 折 CV，并根据原始标签评估准确性以获得零分布。\n- C. 理由：如果增加折数 $k$ 或使用留一法交叉验证 (LOOCV)，在 CV 外部进行全局置换是无偏的，因为每个样本都只被测试一次。修正算法：继续对训练折和测试折使用单一的全局 $Y$ 置换，但执行嵌套的超参数调整；根据置换后的测试标签 $Y_{\\pi(i)}$ 评估预测，以确保一致性。\n- D. 理由：偏差的产生是因为折分配不够随机；在 CV 外部重新标记是可以的，但是分层会导致不平衡。修正算法：不要置换标签；而是重复地对原始标签的折成员关系进行重新洗牌，并对多次洗牌的 CV 分数求平均以近似零分布。",
            "solution": "在进行解答之前，首先对问题陈述的有效性进行严格评估。\n\n### 步骤 1：提取已知信息\n- 数据包含 $n$ 次试验。\n- 对于每次试验 $i$，给定一个特征向量 $X_i \\in \\mathbb{R}^p$ 和一个二元标签 $Y_i \\in \\{0,1\\}$。\n- 使用 $k$ 折交叉验证 (CV) 估计泛化性能，其中 $k \\geq 2$。\n- 留一法交叉验证 (LOOCV) 是 $k=n$ 的特例。\n- 一个监督学习器将特征映射到预测标签：$\\hat{Y} = \\hat{f}(X)$。\n- 期望损失的 CV 估计量是 $\\hat{T}_{\\text{CV}} = \\frac{1}{n} \\sum_{i=1}^n \\ell\\bigl(Y_i, \\hat{f}^{(-i)}(X_i)\\bigr)$。\n- $\\ell(\\cdot,\\cdot)$ 是一个固定的损失函数（例如，$0$-$1$ 损失）。\n- $\\hat{f}^{(-i)}$ 是在没有第 $i$ 个样本的情况下，仅使用相应训练折的数据训练的模型。\n- 目标是为 $\\hat{T}_{\\text{CV}}$ 计算一个基于置换的零分布。\n- 零假设 ($H_0$) 是 $Y$ 与 $X$ 独立，记作 $Y \\perp X$。\n- 一名技术人员提出的“捷径”：\n    1. 生成一个 $\\{1,\\dots,n\\}$ 的单一全局置换 $\\pi$。\n    2. 将所有 $Y_i$ 替换为 $Y_{\\pi(i)}$。\n    3. 在全局置换后的数据集 $\\{(X_i, Y_{\\pi(i)})\\}_{i=1}^n$ 上运行 $k$ 折 CV。\n- 提供的基本原理：\n    1. $H_0: Y \\perp X$。\n    2. $H_0$ 下的可交换性允许重新标记，但必须保留条件结构（训练与测试分离）。\n    3. 一个有效的 CV 过程要求 $\\hat{f}^{(-i)}$ 仅依赖于其训练数据，而不依赖于留出的样本 $i$。\n\n### 步骤 2：使用提取的已知信息进行验证\n这个问题在科学上植根于机器学习和计算统计学领域，特别涉及模型验证和非参数假设检验。交叉验证、置换检验、零假设以及信息泄露等潜在陷阱的概念都是标准的、定义明确的。问题提得很好，要求识别一种特定的统计偏差并加以纠正，这在统计理论上有确定的答案。语言客观而精确。所提供的信息是自洽的，足以回答问题。没有内部矛盾、不切实际的条件或其他缺陷。该问题解决了一个在实际数据分析中微妙但常见且关键的错误，使其成为一个有实质意义且有效的问题。\n\n### 步骤 3：结论与行动\n问题陈述是**有效的**。将推导出一个完整的解决方案。\n\n### 推导与选项分析\n\n问题的核心在于正确实施置换检验，以便为交叉验证的性能指标生成一个零分布。目标是在零假设 $H_0: Y \\perp X$ 下估计统计量 $\\hat{T}_{\\text{CV}}$ 的分布。\n\n在 $H_0$ 下，标签 $Y$ 不提供关于特征 $X$ 的任何信息。一个有效的置换方案必须模拟这种情况。这通过重复地打破 $X$ 和 $Y$ 之间的关联，重新计算感兴趣的统计量，并收集这些新值以形成一个经验零分布来实现。\n\n交叉验证过程通过将数据划分为训练集和测试集来估计泛化误差。对于每个样本 $i$（或样本折），在训练数据上训练一个模型 $\\hat{f}^{(-i)}$，并在留出的测试数据 $(X_i, Y_i)$ 上对其进行评估。关键原则是严格分离训练和测试数据。模型 $\\hat{f}^{(-i)}$ 的构建必须在完全不知道测试样本标签 $Y_i$ 的情况下进行。\n\n让我们分析一下技术人员提出的“捷径”：\n1.  对标签应用一个单一的全局置换 $\\pi$，创建一个新的数据集 $D_{\\pi} = \\{ (X_i, Y_{\\pi(i)}) \\}_{i=1}^n$。\n2.  在 $D_{\\pi}$ 上执行 $k$ 折 CV。\n\n在这个过程中，对于给定的折，设 $S_{\\text{train}}$ 和 $S_{\\text{test}}$ 分别是训练数据和测试数据的索引集。对于一个测试样本 $i \\in S_{\\text{test}}$，模型 $\\hat{f}^{(-i)}_{\\pi}$ 在集合 $\\{ (X_j, Y_{\\pi(j)}) \\}_{j \\in S_{\\text{train}}}$ 上进行训练。然后在测试样本上计算损失为 $\\ell(Y_{\\pi(i)}, \\hat{f}^{(-i)}_{\\pi}(X_i))$。因此，计算出的统计量是 $\\hat{T}_{\\text{CV, wrong}} = \\frac{1}{n} \\sum_{i=1}^n \\ell\\bigl(Y_{\\pi(i)}, \\hat{f}^{(-i)}_{\\pi}(X_i)\\bigr)$。\n\n这个过程存在一个根本性的缺陷：它未能在置换下保持训练过程和测试数据之间的独立性。因为置换 $\\pi$ 是全局的，它在训练标签 $\\{ Y_{\\pi(j)} \\}_{j \\in S_{\\text{train}}}$ 和测试标签 $\\{ Y_{\\pi(i)} \\}_{i \\in S_{\\text{test}}}$ 之间创建了一个伪依赖结构。它们不是独立的抽样，而是通过单一的置换 $\\pi$ 联系在一起。此外，如果建模流程的任何部分（例如，特征选择、超参数调整）在 CV 循环开始前在整个数据集 $D_{\\pi}$ 上执行，那么关于测试标签 $Y_{\\pi(i)}$ 的信息已经“泄露”到每个模型 $\\hat{f}^{(-i)}_{\\pi}$ 的训练中。这会导致乐观偏差：零分布会偏向于优于随机猜测的性能，从而使检验的灵敏度降低（即增加了第二类错误）。\n\n正确的过程必须在*每一折的训练阶段*强制执行零假设。\n对于每一折和每个期望的置换重复：\n1.  分离训练数据 $\\{ (X_j, Y_j) \\}_{j \\in S_{\\text{train}}}$ 和测试数据 $\\{ (X_i, Y_i) \\}_{i \\in S_{\\text{test}}}$。\n2.  *仅在训练集内部*置换标签。设 $\\pi_{\\text{train}}$ 为 $S_{\\text{train}}$ 中索引的一个置换。这创建了零假设下的训练集 $\\{ (X_j, Y_{\\pi_{\\text{train}}(j)}) \\}_{j \\in S_{\\text{train}}}$。\n3.  在这个零假设下的训练集上训练一个模型 $\\hat{f}^{(-i)}_{H_0}$。整个建模流程，包括任何预处理或调优，都必须包含在这一步中，并且只使用这个零假设下的训练集。\n4.  在*原始的、未被触碰的*测试数据上评估模型：为所有 $i \\in S_{\\text{test}}$ 计算损失 $\\ell(Y_i, \\hat{f}^{(-i)}_{H_0}(X_i))$。\n5.  聚合所有折的损失，以获得零统计量的一个值。对许多不同的置换重复这整个过程，以构建零分布。\n\n现在我们评估给定的选项。\n\n**选项 A. 理由：在 CV 循环外进行单一的全局置换，会用 $Y_{\\pi(i)}$ 替换测试标签，从而将目标统计量从 $\\ell(Y_i, \\hat{f}^{(-i)}(X_i))$ 改变为 $\\ell(Y_{\\pi(i)}, \\hat{f}^{(-i)}(X_i))$，这并不是原始性能指标的零分布，并且在典型的依赖于标签的预处理或模型选择中，这会在学习到的内容和置换后的测试标签之间引入依赖性，从而产生乐观偏差。修正算法：对于每个外部重采样...仅在该重采样内部置换训练标签...训练完整流程...对留出的测试特征进行预测，并根据真实的测试标签 $Y_i$ 进行评分。聚合各折的损失以获得一个零分布下的重复值。对 $b$ 进行重复以形成零分布。**\n\n-   **理由分析**：这个陈述是准确的。它正确地指出，被计算的统计量与目标统计量不同。关键是，它指出了在训练过程和置换后的测试标签之间引入了依赖性（信息泄露），特别是当依赖于标签的步骤没有被正确地嵌套时。它正确地将结果诊断为乐观偏差。\n-   **修正算法分析**：所描述的算法是执行带交叉验证的置换检验的标准、最先进的方法。它正确地将置换隔离在每一折的训练集内，并根据原始的、未被触碰的测试集进行评估。这正确地模拟了零假设。\n-   **结论**：**正确**。\n\n**选项 B. 理由：在 CV 外部进行全局置换会增加方差但不会引入偏差，因为置换标签保留了可交换性。修正算法：全局置换特征向量 $X_i$，而不是标签 $Y_i$，然后运行 $k$ 折 CV，并根据原始标签评估准确性以获得零分布。**\n\n-   **理由分析**：这是不正确的。主要问题是偏差（特别是乐观偏差），而不仅仅是方差。虽然对 i.i.d. 数据集的标签进行全局置换保留了边际分布，但它没有保留交叉验证折所需的条件独立性结构，因此引入了偏差。\n-   **修正算法分析**：在打破 $X$-$Y$ 关联方面，置换特征向量 $X_i$ 在统计上等同于置换标签 $Y_i$。所提出的算法仍然在 CV 循环*外部*进行*全局*置换，因此与原始提议存在完全相同的缺陷。\n-   **结论**：**不正确**。\n\n**选项 C. 理由：如果增加折数 $k$ 或使用留一法交叉验证 (LOOCV)，在 CV 外部进行全局置换是无偏的，因为每个样本都只被测试一次。修正算法：继续对训练折和测试折使用单一的全局 $Y$ 置换，但执行嵌套的超参数调整；根据置换后的测试标签 $Y_{\\pi(i)}$ 评估预测，以确保一致性。**\n\n-   **理由分析**：这是错误的。偏差不会随着 $k \\to n$ 而消失；实际上，在 LOOCV 中问题可能会被加剧，因为不同折的训练集几乎完全相同，放大了单一全局置换在所有折中的影响。\n-   **修正算法分析**：这个算法仍然有缺陷。它继续使用不正确的全局置换，并根据置换后的测试标签 $Y_{\\pi(i)}$ 进行评估，这是在计算一个被打乱的数据集上的性能，而不是为原始性能指标生成零分布。\n-   **结论**：**不正确**。\n\n**选项 D. 理由：偏差的产生是因为折分配不够随机；在 CV 外部重新标记是可以的，但是分层会导致不平衡。修正算法：不要置换标签；而是重复地对原始标签的折成员关系进行重新洗牌，并对多次洗牌的 CV 分数求平均以近似零分布。**\n\n-   **理由分析**：这错误地识别了误差的来源。问题与折分配或分层无关。“在 CV 外部重新标记是可以的”这一说法正是我们试图纠正的错误。\n-   **修正算法分析**：这个过程不会为检验假设 $Y \\perp X$ 生成零分布。要生成零分布，必须打破特征 ($X$) 和标签 ($Y$) 之间的关联。该算法仅仅是计算真实性能指标的多个估计值，这可以用来获得更稳定的估计，但它不是一个假设检验。\n-   **结论**：**不正确**。\n\n因此，选项 A 为该缺陷提供了完全准确的理由，并提出了正确的算法。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "交叉验证是一种模型选择工具，但并非唯一。像 AIC 和 BIC 这样的信息准则也被广泛使用。这个编码练习 () 构建了一个来自神经科学的真实场景，在其中这两类方法给出了相互矛盾的选择。通过模拟具有神经记录常见特性的数据（如异方差性），你将揭示每种方法的隐藏假设，并理解为何交叉验证对预测能力的直接估计使其在面对特定形式的模型设定错误时更为稳健。",
            "id": "4152067",
            "problem": "在神经科学数据分析的背景下，您正在分析受控刺激下模拟的单次试验神经响应振幅。您将比较刺激-响应映射的两种线性模型，并通过信息准则和交叉验证来评估模型选择。目的是构建并量化一个场景，在该场景中，信息准则选择了更复杂的模型，而交叉验证则偏好更简单的模型，并通过将每个准则建立在第一性原理之上来调和这种差异。\n\n推导的基本依据：从高斯观测模型的最大似然原理、作为期望损失的样本外预测风险的定义，以及均方误差的偏差-方差分解开始。设响应向量为 $y \\in \\mathbb{R}^n$，主协变量为 $x \\in \\mathbb{R}^n$。设线性模型为 $y = X \\beta + \\varepsilon$，其中 $X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是通过普通最小二乘法估计的参数，$\\varepsilon$ 是加性噪声。使用在同方差性假设下通过最大化高斯对数似然获得的普通最小二乘估计量作为基础估计量。通过 $k$ 折交叉验证和留一法交叉验证评估预测风险，这两种方法被定义为重复的训练-测试划分，以近似期望损失。\n\n场景设计：模拟具有异方差试验噪声的数据，并考虑两种模型：\n- 一个更简单的模型，其设计矩阵 $X_{\\text{simple}}$ 由一个截距和单个协变量 $x$ 组成（列为 $[1, x]$）。\n- 一个更复杂的模型，其设计矩阵 $X_{\\text{complex}}$ 由一个截距、协变量 $x$ 以及最高到 $d$ 次的多项式展开 $x^2, x^3, \\dots, x^d$ 组成（列为 $[1, x, x^2, \\dots, x^d]$）。\n\n数据生成：对于每个测试用例，从标准化高斯分布中抽取 $x$，并根据 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 \\cdot \\mathbf{1}_{\\text{quad}} + \\varepsilon_i$ 生成 $y$，其中 $\\varepsilon_i \\sim \\mathcal{N}\\!\\left(0, \\sigma^2 \\cdot (1 + \\alpha x_i^2)\\right)$，并且 $\\mathbf{1}_{\\text{quad}} \\in \\{0,1\\}$ 用于切换均值中是否包含真实的二次分量。这模拟了真实的神经振幅可变性，该可变性随刺激强度增加而增加，这在较大刺激引发较大响应可变性的情况中很常见。确保每个测试用例都为随机数生成器设定种子以保证可复现性。\n\n信息准则：计算赤池信息准则 (Akaike Information Criterion, AIC) 和贝叶斯信息准则 (Bayesian Information Criterion, BIC)。使用最大化的高斯似然及其标准的参数数量惩罚项（其中 $p$ 是参数数量）来估计 AIC 和 BIC。交叉验证：为每个模型计算留一法交叉验证 (LOOCV) 均方误差和 $k$ 折交叉验证均方误差。通过比较标量分数进行选择：较低的 AIC 或 BIC 表示更好的拟合，较低的交叉验证均方误差表示更好的预测性能。\n\n您的程序必须：\n- 对于每个测试用例，按规定模拟数据，通过普通最小二乘法拟合两个模型，计算信息准则和交叉验证分数，并输出四个整数，表示每个准则选择的模型：\n  - 选择更简单的模型输出代码 $0$，选择更复杂的模型输出代码 $1$。\n  - 每个用例的四个输出是 $(\\text{AIC choice}, \\text{BIC choice}, \\text{LOOCV choice}, \\text{$k$-fold choice})$。\n- 将所有测试用例的结果汇总为单行输出，该输出包含一个用方括号括起来的、无空格的、逗号分隔的列表的列表。\n\n测试套件：\n- 用例 1：$n = 60$，$\\sigma = 4.0$，$\\alpha = 2.5$，$d = 6$，$k = 5$，种子 $= 12345$，$\\mathbf{1}_{\\text{quad}} = 0$。\n- 用例 2：$n = 200$，$\\sigma = 0.8$，$\\alpha = 0.0$，$d = 2$，$k = 10$，种子 $= 54321$，$\\mathbf{1}_{\\text{quad}} = 1$。\n- 用例 3：$n = 20$，$\\sigma = 3.0$，$\\alpha = 0.0$，$d = 8$，$k = 2$，种子 $= 111$，$\\mathbf{1}_{\\text{quad}} = 0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的、逗号分隔的列表的列表形式的结果（例如，$[[a_1,b_1,c_1,d_1],[a_2,b_2,c_2,d_2],[a_3,b_3,c_3,d_3]]$），字符串中任何地方都不能有空格。\n- 所有输出必须是如上定义的整数。",
            "solution": "该问题要求在模拟的神经科学背景下分析模型选择准则，其目标是创建并解释一个场景，在该场景中，信息准则（赤池信息准则 AIC；贝叶斯信息准则 BIC）和交叉验证 (CV) 方法会产生矛盾的模型选择。这种差异源于一种特定形式的模型设定错误：将一个假设误差为同方差的模型拟合到由异方差噪声生成的数据上。\n\n首先，我们为所使用的方法建立理论框架。底层的估计程序是普通最小二乘法 (Ordinary Least Squares, OLS)，它源自高斯噪声模型下的最大似然原理。\n\n设线性模型为 $y = X\\beta + \\varepsilon$，其中 $y \\in \\mathbb{R}^n$ 是观测到的响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是一个具有 $p$ 个参数的模型的设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是参数向量，$\\varepsilon \\in \\mathbb{R}^n$ 是噪声向量。OLS 程序假设误差是独立同分布的，具体来说，对于所有 $i=1, \\dots, n$，有 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。在此假设下，数据的对数似然函数为：\n$$ \\ln \\mathcal{L}(\\beta, \\sigma^2; y, X) = -\\frac{n}{2}\\ln(2\\pi\\sigma^2) - \\frac{1}{2\\sigma^2}\\|y - X\\beta\\|^2 $$\n关于 $\\beta$ 最大化此函数等价于最小化残差平方和 (RSS)，即 $\\|y - X\\beta\\|^2$。这得到了著名的 OLS 估计量：\n$$ \\hat{\\beta} = (X^T X)^{-1} X^T y $$\n随后可以找到方差的最大似然估计为 $\\hat{\\sigma}^2_{ML} = \\frac{1}{n}\\|y - X\\hat{\\beta}\\|^2 = \\frac{\\text{RSS}}{n}$。将这些估计值代入对数似然函数，得到最大化的对数似然 $\\ln \\mathcal{L}_{\\text{max}}$。\n\n信息准则基于这个最大化的对数似然。它们在样本内模型拟合与模型复杂度之间取得平衡。\n赤池信息准则 (AIC) 定义为：\n$$ \\text{AIC} = -2\\ln\\mathcal{L}_{\\text{max}} + 2p $$\n贝叶斯信息准则 (BIC) 定义为：\n$$ \\text{BIC} = -2\\ln\\mathcal{L}_{\\text{max}} + p\\ln(n) $$\n使用从高斯模型导出的 $\\mathcal{L}_{\\text{max}}$ 表达式，并舍去不影响模型比较的常数，这些准则可以表示为：\n$$ \\text{AIC} \\propto n \\ln(\\text{RSS}) + 2p $$\n$$ \\text{BIC} \\propto n \\ln(\\text{RSS}) + p\\ln(n) $$\n至关重要的是，AIC 和 BIC 是通过似然函数的视角来评估模型质量的，而该似然函数建立在同方差高斯噪声的假设之上。\n\n相比之下，交叉验证提供了一种对模型样本外预测性能的直接、非参数的估计。其目标是估计期望预测误差，或称风险，$E[(y_{\\text{new}} - \\hat{f}(x_{\\text{new}}))^2]$。\n对于 $k$ 折交叉验证，数据集被划分为 $k$ 个不相交的子集（折）。模型在 $k-1$ 个折上进行训练，并在留出的那个折上测试其预测准确性。这个过程重复 $k$ 次，每个折都作为一次测试集。$k$ 折 CV 误差是在测试折上计算的均方误差 (MSE) 的平均值。\n留一法交叉验证 (LOOCV) 是 $k=n$ 的特例。对于通过 OLS 拟合的线性模型，LOOCV 误差可以解析地、高效地计算出来，无需重复拟合模型：\n$$ \\text{MSE}_{\\text{LOOCV}} = \\frac{1}{n} \\sum_{i=1}^n \\left( \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)^2 $$\n其中 $\\hat{y}_i$ 是在所有数据上训练的模型得到的第 $i$ 个拟合值，$h_{ii}$ 是帽子矩阵 $H = X(X^T X)^{-1}X^T$ 的第 $i$ 个对角元素。\n\n当模型假设被违反时，核心冲突就出现了。在这个问题中，数据是由异方差噪声生成的，其中误差项 $\\varepsilon_i$ 的方差依赖于协变量 $x_i$：$\\text{Var}(\\varepsilon_i) = \\sigma^2(1 + \\alpha x_i^2)$，其中 $\\alpha  0$。然而，用于评估模型的 AIC 和 BIC 却是从一个错误地假设方差恒定 ($\\alpha=0$) 的似然函数导出的。\n当一个更复杂的模型（例如，一个高次多项式）被拟合到这类数据时，它可以通过不仅过拟合真实的底层信号，还过拟合噪声的结构化模式，来达到一个极低的 RSS。AIC/BIC 的设定错误的似然函数将 RSS 的大幅下降解释为拟合好得多的迹象，这可能超过对增加参数的惩罚。因此，AIC 和 BIC 可能会偏好过于复杂的模型。\n交叉验证对这种形式的模型设定错误更具鲁棒性。因为它直接衡量样本外预测误差，它会正确地识别出，复杂模型的增益是由于拟合了训练集中的噪声，这是一种无法泛化到未见过的测试数据上的“技能”。过拟合的模型会表现出高方差，导致在留出数据上的预测效果差，从而得到更高的 CV 分数。这与偏差-方差权衡是一致的，即一个过于复杂的模型具有低偏差但高方差，导致总预测误差很大，而 CV 正是估计这个误差。\n因此，在一个具有显著异方差性和一个足够复杂的备选模型的场景中，我们预期 AIC 和 BIC 会选择复杂模型，而 CV 方法会选择更简单、更具泛化性的模型。\n\n该模拟实现了这个场景。对于给定的测试用例，执行以下步骤：\n1.  **数据生成**：对于每个测试用例，生成 $n$ 个数据点 $(x_i, y_i)$。$x_i$ 的值从标准正态分布中抽取。响应 $y_i$ 从真实模型 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 \\cdot \\mathbf{1}_{\\text{quad}} + \\varepsilon_i$ 生成，其中噪声 $\\varepsilon_i$ 从 $\\mathcal{N}(0, \\sigma^2(1 + \\alpha x_i^2))$ 中抽取。选择真实的系数为 $\\beta_0=0.5, \\beta_1=2.0, \\beta_2=1.5$ 以表示一个不可忽略的信号。\n2.  **模型设定**：考虑两个模型：一个简单的线性模型 ($M_S$)，有 $p_S=2$ 个参数（截距和 $x$）；以及一个复杂的多项式模型 ($M_C$)，有 $p_C=d+1$ 个参数（截距和 $x$ 的幂次直到 $x^d$）。\n3.  **模型拟合与评估**：使用 OLS 将两个模型都拟合到模拟数据上。对于每个模型，计算 AIC、BIC、LOOCV-MSE 和 $k$ 折-MSE 分数。\n4.  **选择**：对于每个准则，选择分数较低的模型。选择 $M_S$ 编码为 $0$，选择 $M_C$ 编码为 $1$。这样每个测试用例产生四个二元选择。\n\n测试用例中的参数旨在突出这种权衡的不同方面：\n- **用例 1**：一个简单的真实模型 ($\\mathbf{1}_{\\text{quad}}=0$)、高度异方差 ($\\alpha=2.5$) 和一个非常复杂的备选模型 ($d=6$)。这是一个典型用例，预计其中信息准则和 CV 之间的差异最为显著。\n- **用例 2**：一个二次的真实模型 ($\\mathbf{1}_{\\text{quad}}=1$)、无异方差 ($\\alpha=0$)、大样本量 ($n=200$) 和一个与真实均值结构匹配的复杂模型 ($d=2$)。在这里，OLS 的所有假设都得到满足，且复杂模型是正确的模型，因此所有准则应该会达成一致。\n- **用例 3**：一个简单的真实模型 ($\\mathbf{1}_{\\text{quad}}=0$)、无异方差 ($\\alpha=0$)，但样本量非常小 ($n=20$) 且备选模型极其复杂 ($d=8$)。这在一个经典的、严重的过拟合情境下测试这些准则，没有设定错误的误差结构这一混淆因素。预计 BIC 中较大的参数惩罚项和 CV 的直接误差估计会防止过拟合，而 AIC 较弱的惩罚项可能无法做到。\n\n现在，所实现的代码将为每个测试用例执行此过程。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_model_selection(n, sigma, alpha, d, k, seed, quad_toggle, beta_params):\n    \"\"\"\n    Simulates data, fits simple and complex models, and compares them using\n    AIC, BIC, LOOCV, and k-fold CV.\n    \"\"\"\n    beta0, beta1, beta2 = beta_params\n    \n    # 1. Data Generation\n    rng = np.random.default_rng(seed)\n    x = rng.standard_normal(n)\n    \n    # Heteroscedastic noise\n    noise_std = sigma * np.sqrt(1 + alpha * x**2)\n    epsilon = rng.normal(0, noise_std)\n    \n    # True mean model\n    y_true_mean = beta0 + beta1 * x\n    if quad_toggle == 1:\n        y_true_mean += beta2 * x**2\n    y = y_true_mean + epsilon\n    \n    # 2. Define Models\n    # Simple model: intercept + x\n    X_simple = np.c_[np.ones(n), x]\n    p_simple = X_simple.shape[1]\n    \n    # Complex model: intercept + polynomials up to degree d\n    X_complex = np.vander(x, d + 1, increasing=True)\n    p_complex = X_complex.shape[1]\n    \n    model_results = {}\n    \n    # 3. Analyze each model\n    for model_name, X, p in [('simple', X_simple, p_simple), ('complex', X_complex, p_complex)]:\n        \n        # 3.1. OLS Fit\n        # np.linalg.lstsq is numerically stable\n        beta_hat = np.linalg.lstsq(X, y, rcond=None)[0]\n        y_hat = X @ beta_hat\n        rss = np.sum((y - y_hat)**2)\n        \n        # 3.2. AIC and BIC Calculation\n        # The criteria are proportional to n*log(RSS/n) + penalty.\n        # This form is valid for comparing models.\n        if rss = 1e-9: # Handle perfect fits where RSS is zero or negligible\n             aic = -np.inf\n             bic = -np.inf\n        else:\n             log_likelihood_term = n * np.log(rss / n)\n             aic = log_likelihood_term + 2 * p\n             bic = log_likelihood_term + p * np.log(n)\n\n        # 3.3. LOOCV MSE (analytic formula for OLS)\n        # Use QR decomposition for stable computation of hat matrix diagonals\n        Q, _ = np.linalg.qr(X)\n        h_ii = np.sum(Q * Q, axis=1)\n        \n        # Avoid division by zero if h_ii is exactly 1\n        one_minus_h = 1 - h_ii\n        # Set a floor to avoid division by very small numbers or zero\n        one_minus_h[one_minus_h  1e-9] = 1e-9\n        \n        loocv_errors = (y - y_hat) / one_minus_h\n        mse_loocv = np.mean(loocv_errors**2)\n        \n        # 3.4. k-fold CV MSE (manual loop)\n        cv_rng = np.random.default_rng(seed + 1) # Use a derived seed for reproducible folds\n        indices = np.arange(n)\n        cv_rng.shuffle(indices)\n        \n        folds = np.array_split(indices, k)\n        \n        total_squared_error_kfold = 0\n        for i in range(k):\n            test_indices = folds[i]\n            train_indices_list = [folds[j] for j in range(k) if i != j]\n            if not train_indices_list: continue\n            train_indices = np.concatenate(train_indices_list)\n\n            X_train, y_train = X[train_indices], y[train_indices]\n            X_test, y_test = X[test_indices], y[test_indices]\n            \n            beta_hat_train = np.linalg.lstsq(X_train, y_train, rcond=None)[0]\n            y_hat_test = X_test @ beta_hat_train\n            \n            total_squared_error_kfold += np.sum((y_test - y_hat_test)**2)\n            \n        mse_kfold = total_squared_error_kfold / n\n        \n        model_results[model_name] = {\n            'aic': aic, \n            'bic': bic, \n            'mse_loocv': mse_loocv, \n            'mse_kfold': mse_kfold\n        }\n\n    # 4. Compare models and generate output codes (0 for simple, 1 for complex)\n    simple_scores = model_results['simple']\n    complex_scores = model_results['complex']\n    \n    aic_choice = 1 if complex_scores['aic']  simple_scores['aic'] else 0\n    bic_choice = 1 if complex_scores['bic']  simple_scores['bic'] else 0\n    loocv_choice = 1 if complex_scores['mse_loocv']  simple_scores['mse_loocv'] else 0\n    kfold_choice = 1 if complex_scores['mse_kfold']  simple_scores['mse_kfold'] else 0\n    \n    return [aic_choice, bic_choice, loocv_choice, kfold_choice]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # n, sigma, alpha, d, k, seed, quad_toggle\n        (60, 4.0, 2.5, 6, 5, 12345, 0),\n        (200, 0.8, 0.0, 2, 10, 54321, 1),\n        (20, 3.0, 0.0, 8, 2, 111, 0),\n    ]\n\n    # Set true coefficient values for the data generating process.\n    # These are reasonable, non-zero values chosen to create a clear signal.\n    beta_params = (0.5, 2.0, 1.5)\n\n    results = []\n    for case in test_cases:\n        result = calculate_model_selection(*case, beta_params=beta_params)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Example format: [[a1,b1,c1,d1],[a2,b2,c2,d2],[a3,b3,c3,d3]]\n    # str() creates spaces, so we remove them.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```"
        }
    ]
}