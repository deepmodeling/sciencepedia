{
    "hands_on_practices": [
        {
            "introduction": "Many complex biological responses can be understood as the result of simpler processes occurring in sequence. This practice demonstrates this fundamental principle by using continuous-time convolution to derive the overall impulse response of a two-stage filtering system. By convolving two simple exponential decays, you will derive the biexponential \"alpha function\" kernel, a ubiquitous model for phenomena like postsynaptic currents and other transient responses in neuroscience, thereby connecting the abstract mathematics of convolution to concrete biophysical modeling .",
            "id": "4149344",
            "problem": "A simplified two-compartment cascade is often used in neuroscience data analysis to model synaptic current filtering by dendritic and somatic membranes. Consider two causal Linear Time-Invariant (LTI) first-order compartments connected in series. The first compartment receives a stimulus modeled as a Dirac delta input $\\delta(t)$ and has state $x_1(t)$ obeying the ordinary differential equation $\\tau_1 \\frac{d x_1}{dt} + x_1 = \\delta(t)$ with zero initial condition. The second compartment takes $x_1(t)$ as its input and has state $x_2(t)$ obeying $\\tau_2 \\frac{d x_2}{dt} + x_2 = x_1(t)$ with zero initial condition. Here $\\tau_1 > 0$ and $\\tau_2 > 0$ are the compartment time constants, and $\\delta(t)$ is the Dirac delta with the usual distributional properties. Let $H(t)$ denote the Heaviside step function.\n\nStarting only from the core definitions of LTI impulse response and convolution for cascaded systems, derive the overall impulse response $h(t)$ of the cascade (the output of the second compartment in response to $\\delta(t)$ at its input) as a closed-form analytical expression in terms of $\\tau_1$, $\\tau_2$, and $t$. Then, interpret the resulting kernel by establishing its causality, its total area under the curve, and its qualitative shape, including the existence and location of its peak for $\\tau_1 \\neq \\tau_2$, and the limiting form when $\\tau_1 \\to \\tau_2$.\n\nExpress your final kernel $h(t)$ as a single analytic expression. Treat time $t$ in seconds, but do not include any units in your final expression. No rounding is required.",
            "solution": "The problem statement has been validated and is found to be scientifically grounded, well-posed, objective, and self-contained. It describes a standard model in systems theory and computational neuroscience, and the tasks are clearly defined mathematical derivations and interpretations. The problem is valid.\n\nThe problem asks for the overall impulse response, $h(t)$, of a cascade of two first-order causal LTI systems. The core principle for such a system is that the overall impulse response is the convolution of the individual impulse responses. Let $h_1(t)$ be the impulse response of the first compartment and $h_2(t)$ be the impulse response of the second compartment. The total system response $h(t)$ is then given by the convolution integral:\n$$h(t) = (h_1 * h_2)(t) = \\int_{-\\infty}^{\\infty} h_1(\\tau) h_2(t-\\tau) d\\tau$$\n\nFirst, we must determine the individual impulse responses, $h_1(t)$ and $h_2(t)$.\n\nThe first compartment is described by the ordinary differential equation (ODE) with a Dirac delta function as input:\n$$\\tau_{1}\\,\\frac{d x_{1}}{d t} + x_{1} = \\delta(t)$$\nwith zero initial condition. By definition, its impulse response $h_1(t)$ is the solution $x_1(t)$. We can solve this using the Laplace transform, denoted by $\\mathcal{L}\\{\\cdot\\}$. Let $X_1(s) = \\mathcal{L}\\{x_1(t)\\}$.\n$$\\mathcal{L}\\left\\{\\tau_{1}\\,\\frac{d x_{1}}{d t} + x_{1}\\right\\} = \\mathcal{L}\\{\\delta(t)\\}$$\n$$\\tau_1 (s X_1(s) - x_1(0^-)) + X_1(s) = 1$$\nGiven the zero initial condition, $x_1(0^-) = 0$.\n$$X_1(s) (\\tau_1 s + 1) = 1$$\n$$X_1(s) = \\frac{1}{\\tau_1 s + 1} = \\frac{1/\\tau_1}{s + 1/\\tau_1}$$\nThe inverse Laplace transform gives the impulse response $h_1(t)$. The Heaviside step function $H(t)$ is included to reflect the causality of the system.\n$$h_1(t) = x_1(t) = \\mathcal{L}^{-1}\\{X_1(s)\\} = \\frac{1}{\\tau_1} \\exp\\left(-\\frac{t}{\\tau_1}\\right) H(t)$$\n\nThe second compartment is identical in form to the first, just with a different time constant $\\tau_2$. Its impulse response $h_2(t)$ would be its output if its input were $\\delta(t)$. By analogy:\n$$h_2(t) = \\frac{1}{\\tau_2} \\exp\\left(-\\frac{t}{\\tau_2}\\right) H(t)$$\n\nNow, we compute the convolution $h(t) = (h_1 * h_2)(t)$.\n$$h(t) = \\int_{-\\infty}^{\\infty} \\left[\\frac{1}{\\tau_1} \\exp\\left(-\\frac{\\tau}{\\tau_1}\\right) H(\\tau)\\right] \\left[\\frac{1}{\\tau_2} \\exp\\left(-\\frac{t-\\tau}{\\tau_2}\\right) H(t-\\tau)\\right] d\\tau$$\nThe product of Heaviside functions $H(\\tau)H(t-\\tau)$ is non-zero only when $\\tau \\ge 0$ and $t-\\tau \\ge 0$ (i.e., $\\tau \\le t$). This implies that for $t < 0$, the integral is zero, so $h(t) = 0$. For $t \\ge 0$, the integration limits become $0$ to $t$.\n$$h(t) = \\frac{1}{\\tau_1 \\tau_2} \\int_0^t \\exp\\left(-\\frac{\\tau}{\\tau_1}\\right) \\exp\\left(-\\frac{t-\\tau}{\\tau_2}\\right) d\\tau \\quad \\text{for } t \\ge 0$$\nWe can factor out the term independent of the integration variable $\\tau$:\n$$h(t) = \\frac{1}{\\tau_1 \\tau_2} \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\int_0^t \\exp\\left(-\\frac{\\tau}{\\tau_1} + \\frac{\\tau}{\\tau_2}\\right) d\\tau$$\n$$h(t) = \\frac{1}{\\tau_1 \\tau_2} \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\int_0^t \\exp\\left(\\tau \\left(\\frac{1}{\\tau_2} - \\frac{1}{\\tau_1}\\right)\\right) d\\tau$$\n\nWe now evaluate the integral, considering two cases.\n\nCase 1: $\\tau_1 \\neq \\tau_2$.\nThe exponent in the integral is non-zero. Let the coefficient of $\\tau$ be $k = \\frac{1}{\\tau_2} - \\frac{1}{\\tau_1} = \\frac{\\tau_1 - \\tau_2}{\\tau_1 \\tau_2}$.\n$$\\int_0^t \\exp(k\\tau) d\\tau = \\left[\\frac{1}{k} \\exp(k\\tau)\\right]_0^t = \\frac{1}{k} (\\exp(kt) - 1) = \\frac{\\tau_1 \\tau_2}{\\tau_1 - \\tau_2} \\left(\\exp\\left(t\\frac{\\tau_1-\\tau_2}{\\tau_1\\tau_2}\\right) - 1\\right)$$\nSubstituting this back into the expression for $h(t)$:\n$$h(t) = \\frac{1}{\\tau_1 \\tau_2} \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\left[ \\frac{\\tau_1 \\tau_2}{\\tau_1 - \\tau_2} \\left(\\exp\\left(\\frac{t}{\\tau_2} - \\frac{t}{\\tau_1}\\right) - 1\\right) \\right]$$\n$$h(t) = \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\exp\\left(\\frac{t}{\\tau_2} - \\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right)$$\n$$h(t) = \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) \\quad \\text{for } t \\ge 0$$\nCombining with the $t < 0$ case, the full expression is:\n$$h(t) = \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) H(t)$$\n\nCase 2: Limiting form as $\\tau_1 \\to \\tau_2$. Let $\\tau_1 = \\tau_2 = \\tau$.\nThe expression for $h(t)$ in Case 1 becomes an indeterminate form $0/0$. We can find the limit using L'Hôpital's rule by differentiating the numerator and denominator with respect to $\\tau_1$ and then taking the limit $\\tau_1 \\to \\tau_2$.\n$$h(t) = \\lim_{\\tau_1 \\to \\tau_2} \\frac{\\frac{d}{d\\tau_1}\\left( \\exp\\left(-t/\\tau_1\\right) - \\exp\\left(-t/\\tau_2\\right) \\right)}{\\frac{d}{d\\tau_1}(\\tau_1 - \\tau_2)} H(t)$$\n$$\\frac{d}{d\\tau_1}\\left( \\exp\\left(-t/\\tau_1\\right) \\right) = \\exp\\left(-t/\\tau_1\\right) \\cdot \\left(\\frac{t}{\\tau_1^2}\\right)$$\n$$\\frac{d}{d\\tau_1}(\\tau_1 - \\tau_2) = 1$$\nTaking the limit as $\\tau_1 \\to \\tau_2 = \\tau$:\n$$h(t) = \\frac{\\exp(-t/\\tau) \\cdot (t/\\tau^2)}{1} H(t) = \\frac{t}{\\tau^2} \\exp\\left(-\\frac{t}{\\tau}\\right) H(t)$$\nThis function is known as an alpha function in neuroscience.\n\nNow, we interpret the derived kernel $h(t)$ for the general case $\\tau_1 \\neq \\tau_2$.\n\nCausality: The presence of the Heaviside function $H(t)$ ensures that $h(t) = 0$ for all $t < 0$. This means the system's output does not precede its input, which is the definition of a causal system.\n\nTotal area under the curve: This is given by the integral of $h(t)$ over all time.\n$$\\text{Area} = \\int_{-\\infty}^{\\infty} h(t) dt = \\int_0^{\\infty} \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) dt$$\n$$\\text{Area} = \\frac{1}{\\tau_1 - \\tau_2} \\left[ \\int_0^{\\infty} \\exp\\left(-\\frac{t}{\\tau_1}\\right) dt - \\int_0^{\\infty} \\exp\\left(-\\frac{t}{\\tau_2}\\right) dt \\right]$$\nUsing the standard integral $\\int_0^\\infty \\exp(-at) dt = 1/a$ for $a>0$:\n$$\\text{Area} = \\frac{1}{\\tau_1 - \\tau_2} \\left[ \\left(-\\tau_1 \\exp\\left(-\\frac{t}{\\tau_1}\\right)\\right)_0^{\\infty} - \\left(-\\tau_2 \\exp\\left(-\\frac{t}{\\tau_2}\\right)\\right)_0^{\\infty} \\right]$$\n$$\\text{Area} = \\frac{1}{\\tau_1 - \\tau_2} [ (0 - (-\\tau_1)) - (0 - (-\\tau_2)) ] = \\frac{\\tau_1 - \\tau_2}{\\tau_1 - \\tau_2} = 1$$\nThe total area under the impulse response is $1$.\n\nQualitative shape and peak location ($\\tau_1 \\neq \\tau_2$): The function $h(t)$ starts at $h(0)=0$, rises to a single maximum, and then decays exponentially to $0$ as $t \\to \\infty$. To find the time of the peak, $t_{peak}$, we set the derivative of $h(t)$ to zero.\n$$\\frac{dh}{dt} = \\frac{d}{dt} \\left[ \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) \\right] = 0$$\n$$\\frac{1}{\\tau_1 - \\tau_2} \\left( -\\frac{1}{\\tau_1}\\exp\\left(-\\frac{t}{\\tau_1}\\right) + \\frac{1}{\\tau_2}\\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) = 0$$\n$$\\frac{1}{\\tau_2}\\exp\\left(-\\frac{t}{\\tau_2}\\right) = \\frac{1}{\\tau_1}\\exp\\left(-\\frac{t}{\\tau_1}\\right)$$\n$$\\frac{\\tau_1}{\\tau_2} = \\frac{\\exp(-t/\\tau_2)}{\\exp(-t/\\tau_1)} = \\exp\\left(t\\left(\\frac{1}{\\tau_1} - \\frac{1}{\\tau_2}\\right)\\right)$$\nTaking the natural logarithm of both sides:\n$$\\ln\\left(\\frac{\\tau_1}{\\tau_2}\\right) = t \\left(\\frac{1}{\\tau_1} - \\frac{1}{\\tau_2}\\right) = t \\frac{\\tau_2 - \\tau_1}{\\tau_1 \\tau_2}$$\nSolving for $t = t_{peak}$:\n$$t_{peak} = \\frac{\\tau_1 \\tau_2}{\\tau_2 - \\tau_1} \\ln\\left(\\frac{\\tau_1}{\\tau_2}\\right) = \\frac{\\tau_1 \\tau_2 (\\ln\\tau_1 - \\ln\\tau_2)}{\\tau_2 - \\tau_1} = \\frac{\\tau_1 \\tau_2 (\\ln\\tau_2 - \\ln\\tau_1)}{\\tau_1 - \\tau_2}$$\nThis time is always positive for $\\tau_1, \\tau_2 > 0$ and $\\tau_1 \\neq \\tau_2$.\nThe limit of this expression as $\\tau_1 \\to \\tau_2 = \\tau$ is $t_{peak}=\\tau$, which is the correct peak time for the alpha function.\n\nThe final derived impulse response for the cascade is thereby confirmed.",
            "answer": "$$\n\\boxed{ \\frac{1}{\\tau_1 - \\tau_2} \\left( \\exp\\left(-\\frac{t}{\\tau_1}\\right) - \\exp\\left(-\\frac{t}{\\tau_2}\\right) \\right) H(t) }\n$$"
        },
        {
            "introduction": "Building on the concept of an impulse response, this practice moves to a real-world application in functional Magnetic Resonance Imaging (fMRI). Convolution is a cornerstone of forward modeling, allowing us to predict complex measurements from a known input and system response. In this exercise, you will use the canonical Hemodynamic Response Function (HRF) as your kernel and convolve it with a hypothetical neural activity pattern to simulate the BOLD signal, demonstrating how convolution serves as a powerful predictive tool in neuroimaging analysis .",
            "id": "4149331",
            "problem": "You are given a discrete-time model of Blood Oxygen Level Dependent (BOLD) signal generation in functional Magnetic Resonance Imaging (fMRI) within the linear systems framework. The neurovascular coupling will be modeled as a Linear Time-Invariant (LTI) system: the system is completely characterized by its impulse response, and the output to any input is determined by superposition of scaled, time-shifted impulse responses. The input is a block design neural activity signal, and the output is the predicted BOLD. Time must be expressed in seconds.\n\nDefine the canonical Hemodynamic Response Function (HRF) $h(t)$ as a difference of two gamma functions with parameters chosen to be physiologically plausible. For $t \\ge 0$, let\n$$\nh(t) = \\frac{t^{a_1-1} e^{-t/b_1}}{b_1^{a_1}\\,\\Gamma(a_1)} \\;-\\; c \\,\\frac{t^{a_2-1} e^{-t/b_2}}{b_2^{a_2}\\,\\Gamma(a_2)},\n$$\nwith parameters $a_1 = 6$, $b_1 = 1$, $a_2 = 12$, $b_2 = 1$, and $c = 0.35$. For $t < 0$, set $h(t) = 0$. Normalize $h(t)$ to unit area by dividing by its integral over $t \\in [0, t_{\\max}]$, where $t_{\\max} = 32 \\, \\mathrm{s}$.\n\nA block design neural activity $n(t)$ is defined as a piecewise-constant function that takes value $A$ during prespecified stimulus blocks and $0$ otherwise. For a block starting at onset time $s$ with duration $D$, $n(t) = A$ for $t \\in [s, s + D)$ and $n(t) = 0$ otherwise. Assume $A = 1$ for all cases in this problem.\n\nThe predicted BOLD $y(t)$ is the output of the LTI system to input $n(t)$. You must compute $y(t)$ on a uniform discrete-time grid using the discrete-time approximation consistent with the LTI definition. Use a sampling interval $\\Delta t = 0.1\\,\\mathrm{s}$. For numerical convolution, implement the Riemann sum approximation of the continuous-time operation on the given grid, ensuring the correct scaling by $\\Delta t$.\n\nTo analyze how overlap of $h(t)$ across blocks leads to sustained responses, define the \"sustained index\" $S$ for a given block schedule as follows. Let the set of block onset times be $\\{s_i\\}$ with a common duration $D$. For each consecutive pair $(s_i, s_{i+1})$ such that $s_{i+1} > s_i + D$, define the inter-block gap interval $G_i = [s_i + D, s_{i+1})$ on which $n(t) = 0$. Compute the mean of the predicted BOLD over each gap interval,\n$$\n\\overline{y}(G_i) \\;=\\; \\frac{1}{|G_i|} \\int_{G_i} y(t)\\, dt,\n$$\nwhere $|G_i|$ is the duration of the gap interval in seconds. Let $y_{\\max} = \\max_{t} y(t)$ over the full analysis window. The sustained index is\n$$\nS \\;=\\; \\begin{cases}\n\\displaystyle \\max_i \\left( \\frac{\\overline{y}(G_i)}{y_{\\max}} \\right), & \\text{if there exists at least one gap interval } G_i, \\\\\n0, & \\text{if there are no gap intervals.}\n\\end{cases}\n$$\nThe sustained index $S$ is a dimensionless decimal in $[0,1]$ that quantifies the degree to which the BOLD remains elevated between blocks due to overlap of $h(t)$.\n\nImplement a program that:\n- Constructs $h(t)$ on $[0, t_{\\max}]$, normalizes it to unit area, and constructs $n(t)$ on $[0, T_{\\text{total}}]$ for each test case.\n- Computes the predicted BOLD $y(t)$ via discrete-time convolution consistent with the LTI framework and the Riemann sum approximation.\n- Computes the sustained index $S$ for each test case as defined above.\n\nExpress all time values in seconds. All returned numeric values must be floating-point numbers. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3]\").\n\nUse the following test suite, where each test case is fully specified by block onset times, common block duration, and total analysis window:\n1. Happy path case with a single block, no gap: onset times $\\{20\\}$, duration $D = 20 \\, \\mathrm{s}$, total time $T_{\\text{total}} = 100 \\, \\mathrm{s}$.\n2. Boundary case with two blocks separated well beyond the HRF support: onset times $\\{10, 90\\}$, duration $D = 10 \\, \\mathrm{s}$, total time $T_{\\text{total}} = 150 \\, \\mathrm{s}$.\n3. Overlap case with two blocks whose gap is shorter than the HRF tail: onset times $\\{10, 25\\}$, duration $D = 15 \\, \\mathrm{s}$, total time $T_{\\text{total}} = 90 \\, \\mathrm{s}$.\n4. High-overlap edge case with many short blocks and small inter-stimulus intervals: onset times $\\{0, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112\\}$, duration $D = 6 \\, \\mathrm{s}$, total time $T_{\\text{total}} = 120 \\, \\mathrm{s}$.\n\nYour program must output the sustained index $S$ for each test case in the order listed above, as a single line \"[S1,S2,S3,S4]\".",
            "solution": "The problem is validated as scientifically grounded, well-posed, and objective. All definitions and parameters are sufficient to construct a unique, computable solution. The analysis proceeds by implementing the specified model and metrics.\n\nThe solution is developed in four main steps:\n1.  Construction of the normalized Hemodynamic Response Function (HRF).\n2.  Generation of the block-design neural activity signal for each test case.\n3.  Computation of the predicted Blood Oxygen Level Dependent (BOLD) signal via discrete convolution.\n4.  Calculation of the sustained index $S$ from the resulting BOLD signal.\n\n### Step 1: Hemodynamic Response Function (HRF) Construction\n\nThe canonical HRF, denoted by $h(t)$, models the vascular response to a brief, impulse-like neural event. It is defined as a difference of two gamma functions for $t \\ge 0$:\n$$\nh(t) = \\frac{t^{a_1-1} e^{-t/b_1}}{b_1^{a_1}\\,\\Gamma(a_1)} \\;-\\; c \\,\\frac{t^{a_2-1} e^{-t/b_2}}{b_2^{a_2}\\,\\Gamma(a_2)}\n$$\nwhere $\\Gamma(\\cdot)$ is the standard gamma function. The parameters are given as $a_1 = 6$, $b_1 = 1$, $a_2 = 12$, $b_2 = 1$, and $c = 0.35$. For $t < 0$, $h(t) = 0$.\n\nThis function is discretized on a time grid from $t=0$ to $t_{\\max} = 32\\,\\mathrm{s}$ with a sampling interval of $\\Delta t = 0.1\\,\\mathrm{s}$. Let this discrete sequence be $h[k] = h(k \\Delta t)$.\n\nThe problem requires normalizing $h(t)$ to have a unit area over the interval $[0, t_{\\max}]$. The integral is approximated using a Riemann sum over the discrete grid:\n$$\nI = \\int_{0}^{t_{\\max}} h(t) \\,dt \\approx \\sum_{k=0}^{N_{\\text{hrf}}-1} h(t_k) \\Delta t\n$$\nwhere $t_k = k \\Delta t$ and $N_{\\text{hrf}}$ is the number of points in the HRF's time vector. The normalized HRF, $h_{\\text{norm}}(t)$, is then:\n$$\nh_{\\text{norm}}(t) = \\frac{h(t)}{I}\n$$\nThe discrete normalized sequence is $h_{\\text{norm}}[k] = h[k] / I$.\n\n### Step 2: Neural Activity Signal Construction\n\nThe input to the system, the neural activity $n(t)$, is modeled as a block design. It is a piecewise-constant function that equals an amplitude $A=1$ during specified stimulus blocks and $0$ otherwise. For a given set of onset times $\\{s_i\\}$ and a common duration $D$, the signal is defined as:\n$$\nn(t) = \\begin{cases} 1 & \\text{if } t \\in [s_i, s_i + D) \\text{ for some } i \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nFor each test case, we construct a discrete signal $n[k] = n(k \\Delta t)$ over the total analysis window $[0, T_{\\text{total}}]$.\n\n### Step 3: BOLD Signal Computation via Convolution\n\nThe predicted BOLD signal $y(t)$ is the output of the Linear Time-Invariant (LTI) system, which is given by the convolution of the input signal $n(t)$ with the system's impulse response $h_{\\text{norm}}(t)$:\n$$\ny(t) = (n * h_{\\text{norm}})(t) = \\int_{-\\infty}^{\\infty} n(\\tau) h_{\\text{norm}}(t - \\tau) \\,d\\tau\n$$\nThe problem specifies computing this using a discrete-time approximation consistent with a Riemann sum. The discrete convolution is:\n$$\ny[k] = y(t_k) \\approx \\sum_{j} n(\\tau_j) h_{\\text{norm}}(t_k - \\tau_j) \\Delta \\tau\n$$\nwhere $t_k = k\\Delta t$, $\\tau_j = j\\Delta t$, and $\\Delta \\tau = \\Delta t$. This corresponds to performing a standard discrete convolution of the sequences $n[k]$ and $h_{\\text{norm}}[k]$ and then scaling the result by $\\Delta t$:\n$$\ny[k] = \\Delta t \\cdot \\sum_{j=0}^{M-1} n[j] h_{\\text{norm}}[k-j]\n$$\nwhere $M$ is the length of the signal $n[k]$. This operation is performed for each test case. The output of the convolution is truncated to match the length of the input signal $n[k]$.\n\n### Step 4: Sustained Index Calculation\n\nThe sustained index $S$ quantifies the elevation of the BOLD signal in the gaps between stimulus blocks.\nFirst, the global maximum of the BOLD signal, $y_{\\max} = \\max_k y[k]$, is determined over the entire analysis window.\n\nNext, we identify all inter-block gap intervals. For each pair of consecutive onsets $(s_i, s_{i+1})$ with common duration $D$, a gap interval $G_i$ exists if $s_{i+1} > s_i + D$. The interval is defined as $G_i = [s_i + D, s_{i+1})$.\n\nFor each such gap $G_i$, the mean BOLD signal is computed. The continuous definition is:\n$$\n\\overline{y}(G_i) \\;=\\; \\frac{1}{|G_i|} \\int_{G_i} y(t)\\, dt,\n$$\nwhere $|G_i| = s_{i+1} - (s_i+D)$ is the duration of the gap. Its discrete approximation is the arithmetic mean of the BOLD signal samples within the gap interval:\n$$\n\\overline{y}(G_i) \\approx \\frac{1}{N_{G_i}} \\sum_{t_k \\in G_i} y[k]\n$$\nwhere $N_{G_i}$ is the number of time points in the gap interval $G_i$.\n\nA ratio $r_i = \\overline{y}(G_i) / y_{\\max}$ is calculated for each gap. The sustained index $S$ is the maximum of these ratios over all gaps. If no such gaps exist (e.g., a single block, or contiguous blocks), then $S$ is defined to be $0$.\n$$\nS \\;=\\; \\begin{cases}\n\\displaystyle \\max_i (r_i), & \\text{if there is at least one gap interval } G_i, \\\\\n0, & \\text{if there are no gap intervals.}\n\\end{cases}\n$$\nThis procedure is applied to each of the four test cases specified in the problem statement to obtain the final results.\n\nFor Case 1 (single block) and Case 3 (contiguous blocks where $s_{i+1} = s_i+D$), the condition $s_{i+1} > s_i+D$ is not met. Therefore, no gap intervals exist, and the sustained index $S$ is $0$ by definition for both cases. For Case 2 and Case 4, gap intervals exist, and $S$ is computed as the maximum ratio described above.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Solves the BOLD signal modeling problem by computing the sustained index\n    for several block-design experiments.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\"onsets\": [20.0], \"D\": 20.0, \"T_total\": 100.0},\n        {\"onsets\": [10.0, 90.0], \"D\": 10.0, \"T_total\": 150.0},\n        {\"onsets\": [10.0, 25.0], \"D\": 15.0, \"T_total\": 90.0},\n        {\"onsets\": [0.0, 8.0, 16.0, 24.0, 32.0, 40.0, 48.0, 56.0, 64.0, 72.0, 80.0, 88.0, 96.0, 104.0, 112.0], \"D\": 6.0, \"T_total\": 120.0}\n    ]\n\n    results = []\n    \n    # Global parameters\n    delta_t = 0.1\n    t_max_hrf = 32.0\n    a1, b1, a2, b2, c = 6.0, 1.0, 12.0, 1.0, 0.35\n    A = 1.0\n\n    # 1. Construct and normalize the Hemodynamic Response Function (HRF)\n    \n    def gamma_pdf_term(t, a, b):\n        \"\"\"\n        Computes the unscaled gamma PDF term.\n        Note: t must be a numpy array. a-1 > 0 is assumed.\n        \"\"\"\n        # The expression t**(a-1) is numerically safe for t=0 since a>1.\n        numerator = t**(a-1) * np.exp(-t/b)\n        denominator = b**a * gamma(a)\n        # Handle division by zero just in case, though not expected here.\n        with np.errstate(divide='ignore', invalid='ignore'):\n            term = np.true_divide(numerator, denominator)\n        term[denominator == 0] = 0.0 # defensive\n        return term\n\n    t_hrf = np.arange(0, t_max_hrf + delta_t / 2, delta_t)\n    \n    h_unnormalized = gamma_pdf_term(t_hrf, a1, b1) - c * gamma_pdf_term(t_hrf, a2, b2)\n    \n    integral_h = np.sum(h_unnormalized) * delta_t\n    h_norm = h_unnormalized / integral_h\n\n    # Process each test case\n    for case in test_cases:\n        onsets = case[\"onsets\"]\n        D = case[\"D\"]\n        T_total = case[\"T_total\"]\n\n        # 2. Construct the neural activity signal n(t)\n        num_points = int(round(T_total / delta_t)) + 1\n        t_vec = np.linspace(0, T_total, num_points)\n        n = np.zeros_like(t_vec)\n\n        for s in onsets:\n            start_idx = int(round(s / delta_t))\n            # The interval is [s, s+D), so the end index is exclusive.\n            end_idx = int(round((s + D) / delta_t))\n            n[start_idx:end_idx] = A\n            \n        # 3. Compute predicted BOLD signal y(t) via discrete convolution\n        y = np.convolve(n, h_norm, mode='full')\n        # Truncate to original signal length and scale by delta_t for Riemann sum\n        y = y[:len(n)] * delta_t\n        \n        # 4. Compute the sustained index S\n        y_max = np.max(y)\n        \n        # If no activity, y_max can be 0. Avoid division by zero.\n        if y_max <= 0:\n            S = 0.0\n            results.append(S)\n            continue\n            \n        # According to the definition, S=0 if there are no gaps.\n        # This occurs if there is only one block or no blocks.\n        if len(onsets) <= 1:\n            S = 0.0\n            results.append(S)\n            continue\n            \n        gap_ratios = []\n        for i in range(len(onsets) - 1):\n            s_i = onsets[i]\n            s_i_plus_1 = onsets[i+1]\n\n            # A gap interval exists only if s_{i+1} > s_i + D\n            if s_i_plus_1 > s_i + D:\n                gap_start_t = s_i + D\n                gap_end_t = s_i_plus_1\n                \n                gap_start_idx = int(round(gap_start_t / delta_t))\n                gap_end_idx = int(round(gap_end_t / delta_t))\n                \n                # Ensure the indices define a non-empty slice\n                if gap_start_idx >= gap_end_idx:\n                    continue\n                \n                y_gap_segment = y[gap_start_idx:gap_end_idx]\n                \n                # Compute mean BOLD over the gap and its ratio to max BOLD\n                mean_y_gap = np.mean(y_gap_segment)\n                gap_ratios.append(mean_y_gap / y_max)\n        \n        if not gap_ratios:\n            S = 0.0\n        else:\n            S = max(gap_ratios)\n            \n        results.append(S)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While the previous exercises illustrate what convolution achieves, this final practice focuses on the crucial details of *how* it is implemented computationally. Fast algorithms for convolution, which rely on the Fast Fourier Transform (FFT), inherently perform a different operation known as circular convolution. This exercise dissects the precise relationship between the theoretically desired linear convolution and its computationally efficient counterpart, revealing how to avoid common \"wrap-around\" artifacts that can corrupt analysis results—a vital lesson for any practitioner performing time-series analysis .",
            "id": "4149361",
            "problem": "A core operation in neuroscience data analysis is the discrete-time convolution that maps a finite neural activity sequence and a finite synaptic impulse response kernel to a postsynaptic current or filtered activity. To ensure scientific realism and rigor, start from the fundamental base: the definition of discrete linear convolution and the definition of discrete circular convolution as a periodic operation.\n\nLet $x[n]$ be a finite sequence of length $N$ and let $h[n]$ be a finite sequence of length $M$. The discrete linear convolution $y_{\\mathrm{lin}}[n]$ is defined by\n$$\ny_{\\mathrm{lin}}[n] = \\sum_{r=-\\infty}^{\\infty} x[r]\\,h[n-r],\n$$\nwith the understanding that $x[r]=0$ for $r \\notin \\{0,1,\\dots,N-1\\}$ and $h[\\ell]=0$ for $\\ell \\notin \\{0,1,\\dots,M-1\\}$, so that $y_{\\mathrm{lin}}[n]$ is nonzero only for $n \\in \\{0,1,\\dots,N+M-2\\}$.\n\nFor an integer $L \\ge 1$, the $L$-point discrete circular convolution $y_{\\mathrm{circ}}^{(L)}[n]$ is defined by\n$$\ny_{\\mathrm{circ}}^{(L)}[n] = \\sum_{r=0}^{L-1} x[r]\\,h\\big((n-r)\\bmod L\\big), \\quad n \\in \\{0,1,\\dots,L-1\\},\n$$\nwhere $x[r]$ and $h[\\ell]$ are interpreted as $L$-periodic extensions of their first $L$ samples.\n\nIn fast Fourier transform based implementations commonly used in computational neuroscience, performing convolution via multiplication in the discrete Fourier transform domain without sufficient zero-padding implements the $L$-point circular convolution, which introduces wrap-around artifacts when $L < N+M-1$.\n\nYour tasks are:\n\n$1.$ For each provided test case, compute the discrete linear convolution $y_{\\mathrm{lin}}$ and the $L$-point discrete circular convolution $y_{\\mathrm{circ}}^{(L)}$.\n\n$2.$ For each test case, define the discrepancy vector\n$$\nd^{(L)}[n] = y_{\\mathrm{lin}}[n] - y_{\\mathrm{circ}}^{(L)}[n], \\quad n \\in \\{0,1,\\dots,L-1\\},\n$$\nand the wrap-around alias vector\n$$\na^{(L)}[n] = \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n + qL],\n$$\nwith the convention that $y_{\\mathrm{lin}}[m]=0$ for $m \\notin \\{0,1,\\dots,N+M-2\\}$, so only finitely many terms contribute. Relate the discrepancy $d^{(L)}$ to the wrap-around artifacts by verifying, numerically, that\n$$\nd^{(L)}[n] = -\\,a^{(L)}[n]\n$$\nfor all $n \\in \\{0,1,\\dots,L-1\\}$.\n\n$3.$ Quantify the magnitude of wrap-around artifacts in each test case by computing the Euclidean norm\n$$\n\\|d^{(L)}\\|_2 = \\left(\\sum_{n=0}^{L-1} \\big(d^{(L)}[n]\\big)^2\\right)^{1/2}\n$$\nand the infinity norm\n$$\n\\|d^{(L)}\\|_{\\infty} = \\max_{0 \\le n \\le L-1} \\left|d^{(L)}[n]\\right|,\n$$\nand list the indices $n$ where $|d^{(L)}[n]|$ exceeds a numerical tolerance of $10^{-12}$.\n\nUse the following test suite, chosen to probe typical cases, boundary conditions, and edge cases relevant to neuroscience signal processing workflows:\n\nTest case $1$ (typical finite spike train convolved with a short synaptic kernel; $L$ too short, wrap-around present):\n$$\nx^{(1)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], \\quad h^{(1)} = [0.0, 0.7, 0.5, 0.3, 0.1], \\quad L^{(1)} = 12.\n$$\n\nTest case $2$ (same inputs but $L$ chosen to avoid wrap-around by zero-padding to the full linear length):\n$$\nx^{(2)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], \\quad h^{(2)} = [0.0, 0.7, 0.5, 0.3, 0.1], \\quad L^{(2)} = 16.\n$$\n\nTest case $3$ (same inputs with smaller $L$ increasing aliasing severity):\n$$\nx^{(3)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], \\quad h^{(3)} = [0.0, 0.7, 0.5, 0.3, 0.1], \\quad L^{(3)} = 8.\n$$\n\nTest case $4$ (edge case with zero signal where both linear and circular convolution are identically zero):\n$$\nx^{(4)} = [0, 0, 0, 0, 0, 0, 0], \\quad h^{(4)} = [0.2, 0.5, 0.2, 0.1], \\quad L^{(4)} = 7.\n$$\n\nFor each test case $i \\in \\{1,2,3,4\\}$, your program must output a list containing:\n$[$boolean equality check of $d^{(L)}$ and $-a^{(L)}$ within tolerance $10^{-12}$, $\\|d^{(L)}\\|_2$, $\\|d^{(L)}\\|_{\\infty}$, list of indices $n$ with $|d^{(L)}[n]| > 10^{-12}]$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a list in the order specified above, for example, $[\\text{result}^{(1)},\\text{result}^{(2)},\\text{result}^{(3)},\\text{result}^{(4)}]$. No units or textual annotations should be printed, and all numeric values should be decimal numbers.",
            "solution": "The user has provided a well-defined problem in the domain of digital signal processing, specifically concerning the relationship between linear and circular discrete-time convolution, a foundational concept in computational neuroscience and other fields relying on time-series analysis.\n\n### Step 1: Extract Givens\n- **Sequences**: A finite neural activity sequence $x[n]$ of length $N$, and a finite synaptic impulse response kernel $h[n]$ of length $M$.\n- **Linear Convolution**: The discrete linear convolution $y_{\\mathrm{lin}}[n]$ is defined as $y_{\\mathrm{lin}}[n] = \\sum_{r=-\\infty}^{\\infty} x[r]\\,h[n-r]$. The resulting sequence is of length $N+M-1$, non-zero for $n \\in \\{0, 1, \\dots, N+M-2\\}$.\n- **Circular Convolution**: For an integer $L \\ge 1$, the $L$-point discrete circular convolution $y_{\\mathrm{circ}}^{(L)}[n]$ is defined as $y_{\\mathrm{circ}}^{(L)}[n] = \\sum_{r=0}^{L-1} x[r]\\,h\\big((n-r)\\bmod L\\big)$ for $n \\in \\{0, 1, \\dots, L-1\\}$, using $L$-periodic extensions of the first $L$ samples of $x$ and $h$.\n- **Discrepancy Vector**: $d^{(L)}[n] = y_{\\mathrm{lin}}[n] - y_{\\mathrm{circ}}^{(L)}[n]$ for $n \\in \\{0, 1, \\dots, L-1\\}$.\n- **Wrap-around Alias Vector**: $a^{(L)}[n] = \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n + qL]$.\n- **Verification Task**: Numerically verify that $d^{(L)}[n] = -a^{(L)}[n]$ for all $n \\in \\{0, 1, \\dots, L-1\\}$.\n- **Quantification Task**: Compute the Euclidean norm $\\|d^{(L)}\\|_2 = \\left(\\sum_{n=0}^{L-1} (d^{(L)}[n])^2\\right)^{1/2}$ and the infinity norm $\\|d^{(L)}\\|_{\\infty} = \\max_{0 \\le n \\le L-1} |d^{(L)}[n]|$.\n- **Index Identification Task**: List indices $n$ where $|d^{(L)}[n]| > 10^{-12}$.\n- **Test Cases**:\n    1.  $x^{(1)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1]$, $h^{(1)} = [0.0, 0.7, 0.5, 0.3, 0.1]$, $L^{(1)} = 12$.\n    2.  $x^{(2)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1]$, $h^{(2)} = [0.0, 0.7, 0.5, 0.3, 0.1]$, $L^{(2)} = 16$.\n    3.  $x^{(3)} = [0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1]$, $h^{(3)} = [0.0, 0.7, 0.5, 0.3, 0.1]$, $L^{(3)} = 8$.\n    4.  $x^{(4)} = [0, 0, 0, 0, 0, 0, 0]$, $h^{(4)} = [0.2, 0.5, 0.2, 0.1]$, $L^{(4)} = 7$.\n- **Numerical Tolerance**: $10^{-12}$.\n- **Output Format**: For each case, a list containing a boolean for the equality check, $\\|d^{(L)}\\|_2$, $\\|d^{(L)}\\|_{\\infty}$, and a list of indices. The final output is a list of these lists.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded**: The problem is fundamentally based on the definitions and relationship between linear and circular convolution, which are core, well-established principles in digital signal processing. The application context of neuroscience is appropriate and realistic.\n- **Well-Posed**: The problem is entirely self-contained. All necessary definitions, formulas, data, and tasks are provided explicitly. For each test case, the inputs are specified, and the required computations lead to a unique, well-defined numerical result.\n- **Objective**: The problem statement is written in precise, mathematical language, free of ambiguity or subjective claims.\n\nThe problem passes all validation criteria. It is a valid, well-posed, and scientifically sound problem.\n\n### Step 3: Verdict and Action\nThe problem is valid. A solution will be provided.\n\n### Principle-Based Solution Design\n\nThe core principle to be demonstrated is that an $L$-point circular convolution is mathematically equivalent to a time-aliased version of the corresponding linear convolution. Specifically, the circular convolution $y_{\\mathrm{circ}}^{(L)}[n]$ can be expressed in terms of the linear convolution $y_{\\mathrm{lin}}[n]$ as:\n$$\ny_{\\mathrm{circ}}^{(L)}[n] = \\sum_{q=-\\infty}^{\\infty} y_{\\mathrm{lin}}[n+qL]\n$$\nSince the sequence $y_{\\mathrm{lin}}[n]$ is causal and has a finite length of $N+M-1$, this infinite sum simplifies. The terms $y_{\\mathrm{lin}}[n+qL]$ are zero for $q<0$ (since $n \\ge 0$ and $y_{\\mathrm{lin}}$ is zero for negative indices) and for $q$ large enough such that $n+qL \\ge N+M-1$. Thus, the sum becomes:\n$$\ny_{\\mathrm{circ}}^{(L)}[n] = \\sum_{q=0}^{\\infty} y_{\\mathrm{lin}}[n+qL] = y_{\\mathrm{lin}}[n] + \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n+qL]\n$$\nThe problem defines the discrepancy vector as $d^{(L)}[n] = y_{\\mathrm{lin}}[n] - y_{\\mathrm{circ}}^{(L)}[n]$ and the wrap-around alias vector as $a^{(L)}[n] = \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n+qL]$. By substituting the expression for $y_{\\mathrm{circ}}^{(L)}[n]$ into the definition of $d^{(L)}[n]$, we get:\n$$\nd^{(L)}[n] = y_{\\mathrm{lin}}[n] - \\left( y_{\\mathrm{lin}}[n] + \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n+qL] \\right) = - \\sum_{q=1}^{\\infty} y_{\\mathrm{lin}}[n+qL] = -a^{(L)}[n]\n$$\nOur task is to implement this verification numerically and quantify the resulting discrepancy for the specified test cases. The magnitude of the discrepancy, quantified by $\\|d^{(L)}\\|_2$ and $\\|d^{(L)}\\|_{\\infty}$, is a direct measure of the wrap-around artifact. This artifact is zero if and only if $L \\ge N+M-1$, which corresponds to providing sufficient zero-padding for frequency-domain convolution methods to correctly replicate linear convolution.\n\nThe implementation will proceed as follows for each test case $(x, h, L)$:\n1.  **Compute Linear Convolution**: The sequence $y_{\\mathrm{lin}}$ will be computed using the definition of linear convolution. Its length is $N+M-1$, where $N=\\text{length}(x)$ and $M=\\text{length}(h)$.\n2.  **Compute Circular Convolution**: The sequence $y_{\\mathrm{circ}}^{(L)}$ will be computed directly from its summation definition. This involves using the first $L$ samples of $x$ and $h$ (zero-padded if their original lengths are less than $L$) and performing the modulo arithmetic on the kernel index.\n3.  **Compute Discrepancy**: The vector $d^{(L)}$ is found by subtracting $y_{\\mathrm{circ}}^{(L)}$ from the first $L$ samples of $y_{\\mathrm{lin}}$. Care must be taken to handle the case where $y_{\\mathrm{lin}}$ is shorter than $L$.\n4.  **Compute Alias Vector**: The vector $a^{(L)}$ is computed by summing the time-aliased \"tails\" of the $y_{\\mathrm{lin}}$ sequence, as per its definition.\n5.  **Verify and Quantify**: The equality $d^{(L)} = -a^{(L)}$ is checked using a numerical tolerance of $10^{-12}$. The required norms of $d^{(L)}$ are calculated, and the indices of significant discrepancy are identified.\n\nThis procedure will be applied to all four test cases, which are designed to probe the behavior when $L < N+M-1$ (aliasing), $L = N+M-1$ (no aliasing), $L \\ll N+M-1$ (severe aliasing), and the trivial case of a zero input signal.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to process test cases and print results.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], dtype=np.float64),\n         np.array([0.0, 0.7, 0.5, 0.3, 0.1], dtype=np.float64),\n         12),\n        (np.array([0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], dtype=np.float64),\n         np.array([0.0, 0.7, 0.5, 0.3, 0.1], dtype=np.float64),\n         16),\n        (np.array([0, 1, 0, 2, 0, 1, 0, 0, 3, 0, 0, 1], dtype=np.float64),\n         np.array([0.0, 0.7, 0.5, 0.3, 0.1], dtype=np.float64),\n         8),\n        (np.array([0, 0, 0, 0, 0, 0, 0], dtype=np.float64),\n         np.array([0.2, 0.5, 0.2, 0.1], dtype=np.float64),\n         7),\n    ]\n\n    results = []\n    for x, h, L in test_cases:\n        result = process_case(x, h, L)\n        results.append(result)\n\n    # Format the final output string as a list of lists.\n    # The str() representation of a list is standard and sufficient.\n    # e.g., str([True, 1.23, [0, 1]]) -> '[True, 1.23, [0, 1]]'\n    final_output = f\"[{','.join(map(str, results))}]\"\n    print(final_output)\n\ndef process_case(x, h, L):\n    \"\"\"\n    Performs all computations for a single test case.\n    \n    Args:\n        x (np.ndarray): The input signal sequence.\n        h (np.ndarray): The kernel sequence.\n        L (int): The length for circular convolution.\n        \n    Returns:\n        list: A list containing [equality_check, norm2, norm_inf, indices].\n    \"\"\"\n    N = len(x)\n    M = len(h)\n    tolerance = 1e-12\n\n    # 1. Compute discrete linear convolution y_lin\n    y_lin = np.convolve(x, h)\n    \n    # 2. Compute L-point discrete circular convolution y_circ_L\n    # Prepare L-length versions of x and h by zero-padding or truncating\n    x_L = np.zeros(L, dtype=np.float64)\n    h_L = np.zeros(L, dtype=np.float64)\n    n_x_copy = min(N, L)\n    n_h_copy = min(M, L)\n    x_L[:n_x_copy] = x[:n_x_copy]\n    h_L[:n_h_copy] = h[:n_h_copy]\n\n    y_circ_L = np.zeros(L, dtype=np.float64)\n    for n in range(L):\n        for r in range(L):\n            y_circ_L[n] += x_L[r] * h_L[(n - r) % L]\n\n    # 3. Compute the discrepancy vector d_L\n    # d_L[n] = y_lin[n] - y_circ_L[n] for n in {0, ..., L-1}\n    # We must pad y_lin if its length is less than L\n    y_lin_prefix = np.zeros(L, dtype=np.float64)\n    copy_len = min(len(y_lin), L)\n    y_lin_prefix[:copy_len] = y_lin[:copy_len]\n    d_L = y_lin_prefix - y_circ_L\n\n    # 4. Compute the wrap-around alias vector a_L\n    # a_L[n] = sum_{q=1 to inf} y_lin[n + qL]\n    a_L = np.zeros(L, dtype=np.float64)\n    len_y_lin = len(y_lin)\n    if len_y_lin > L:\n        for n in range(L):\n            for q in range(1, (len_y_lin // L) + 2):\n                idx = n + q * L\n                if idx < len_y_lin:\n                    a_L[n] += y_lin[idx]\n                else:\n                    break\n    \n    # 5. Verify the relationship d_L = -a_L\n    is_equal = np.allclose(d_L, -a_L, rtol=0, atol=tolerance)\n\n    # 6. Quantify the magnitude of wrap-around artifacts\n    norm2 = np.linalg.norm(d_L, ord=2)\n    norm_inf = np.linalg.norm(d_L, ord=np.inf)\n\n    # 7. List indices n where |d_L[n]| exceeds tolerance\n    significant_indices = np.where(np.abs(d_L) > tolerance)[0].tolist()\n\n    return [is_equal, norm2, norm_inf, significant_indices]\n\nsolve()\n```"
        }
    ]
}