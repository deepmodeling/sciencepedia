## 引言
在定量神经科学的广阔领域中，从原始数据中提取有意义的生物学见解，往往依赖于一系列复杂的数学操作。矩阵变换——包括旋转、缩放和剪切——构成了这些操作的核心，它们是精确处理空间坐标、对齐多模态图像以及分析高维特征空间的基石。然而，尽管这些工具在神经影像[配准](@entry_id:1122567)、[运动校正](@entry_id:902964)和[特征提取](@entry_id:164394)等流程中无处不在，但对其背后深刻的数学原理、内在联系以及应用局限的系统性理解往往是分散的。这种知识上的隔阂可能导致研究者在选择模型或解释结果时出现偏差，从而影响科学发现的可靠性。

本文旨在填补这一空白，为读者提供一个关于[矩阵变换](@entry_id:156789)及其在神经科学中应用的全面而深入的指南。我们将从第一性原理出发，系统地剖析这些几何工具。在“原理与机制”一章中，我们将奠定坚实的数学基础，从基本的[线性变换](@entry_id:149133)讲起，逐步深入到[仿射变换](@entry_id:144885)、奇异值分解、四元数以及[李群](@entry_id:137659)等高级概念。接着，在“应用与跨学科联系”一章中，我们将通过一系列生动的案例，展示这些理论如何在头部[运动校正](@entry_id:902964)、跨模态[图像配准](@entry_id:908079)、[弥散张量](@entry_id:1123855)分析以及[数据白化](@entry_id:636289)等前沿应用中发挥关键作用。最后，通过“动手实践”部分，你将有机会亲手实现和探索这些变换，将理论知识转化为解决实际问题的能力。

## 原理与机制

在[神经科学数据分析](@entry_id:1128665)领域，对空间坐标和[特征向量](@entry_id:151813)进行精确的[几何变换](@entry_id:150649)是许多核心技术的基础，例如[图像配准](@entry_id:908079)、[运动校正](@entry_id:902964)和[多模态数据融合](@entry_id:1128309)。本章将系统地阐述这些变换背后的基本原理和关键机制，从基本的[线性变换](@entry_id:149133)（如旋转、缩放和剪切）开始，逐步深入到更高级的概念，如[仿射变换](@entry_id:144885)、奇异值分解、四元数以及[李群](@entry_id:137659)理论。

### [神经影像学](@entry_id:896120)中的基本变换

[线性变换](@entry_id:149133)是[向量空间](@entry_id:151108)中保持[向量加法](@entry_id:155045)和[标量乘法](@entry_id:155971)运算的映射，构成了更复杂几何操作的基石。在[神经科学数据分析](@entry_id:1128665)中，最常见的三种[线性变换](@entry_id:149133)是旋转、缩放和剪切。任何[线性变换](@entry_id:149133) $T: \mathbb{R}^n \to \mathbb{R}^n$ 都可以用一个 $n \times n$ 矩阵 $A$ 来表示，即 $T(\mathbf{x}) = A\mathbf{x}$。一个重要的特性是，所有[线性变换](@entry_id:149133)都保持原点不变，即 $T(\mathbf{0}) = \mathbf{0}$。

#### 旋转 (Rotation)

旋转是一种保持[向量长度](@entry_id:156432)（即[欧几里得范数](@entry_id:172687)）和向量间角度的[刚性变换](@entry_id:140326)。在二维平面中，一个绕原点逆时针旋转角度 $\theta$ 的变换可以用旋转矩阵 $R(\theta)$ 表示：
$$
R(\theta) = \begin{pmatrix} \cos\theta  -\sin\theta \\ \sin\theta  \cos\theta \end{pmatrix}
$$
[旋转变换](@entry_id:200017)的关键特性是其[矩阵表示](@entry_id:146025)是**[正交矩阵](@entry_id:169220)**。一个矩阵 $A$ 被称为正交的，如果其[转置](@entry_id:142115)等于其逆，即 $A^{\top}A = AA^{\top} = I$，其中 $I$ 是单位矩阵。我们可以验证[旋转矩阵](@entry_id:140302)确实满足这个条件：
$$
R(\theta)^{\top}R(\theta) = \begin{pmatrix} \cos\theta  \sin\theta \\ -\sin\theta  \cos\theta \end{pmatrix} \begin{pmatrix} \cos\theta  -\sin\theta \\ \sin\theta  \cos\theta \end{pmatrix} = \begin{pmatrix} \cos^2\theta + \sin^2\theta  0 \\ 0  \sin^2\theta + \cos^2\theta \end{pmatrix} = \begin{pmatrix} 1  0 \\ 0  1 \end{pmatrix} = I
$$
这个[正交性质](@entry_id:268007)直接导致了范数的保持。对于任意向量 $\mathbf{s} \in \mathbb{R}^2$，其变换后的向量为 $R(\theta)\mathbf{s}$。变换后向量的平方范数为：
$$
\|R(\theta)\mathbf{s}\|^2 = (R(\theta)\mathbf{s})^{\top}(R(\theta)\mathbf{s}) = \mathbf{s}^{\top}R(\theta)^{\top}R(\theta)\mathbf{s} = \mathbf{s}^{\top}I\mathbf{s} = \mathbf{s}^{\top}\mathbf{s} = \|\mathbf{s}\|^2
$$
由于范数为非负，因此 $\|R(\theta)\mathbf{s}\| = \|\mathbf{s}\|$。这在处理神经信号时具有重要意义，例如，当一个二维向量 $\mathbf{s}$ 代表两个通道的瞬时神经活动时，其平方范数 $\|\mathbf{s}\|^2$ 与瞬时总能量成正比。[旋转操作](@entry_id:140575)（例如，由于传感器方向的改变）不会改变这个总能量 。

#### 缩放 (Scaling)

[缩放变换](@entry_id:166413)用于改变坐标轴的尺度，在处理来自不同成像设备或具有不同物理分辨率的数据时至关重要。缩放可以是各向同性的或各向异性的。

**[各向同性缩放](@entry_id:267671) (Isotropic Scaling)** 将所有坐标轴缩放相同的因子 $s > 0$。其[变换矩阵](@entry_id:151616)为 $S = sI$。例如，在三维空间中：
$$
S = \begin{pmatrix} s  0  0 \\ 0  s  0 \\ 0  0  s \end{pmatrix}
$$
在这种变换下，一个体素的每条边长都变为原来的 $s$ 倍。体积是长度的三次方，因此体素的体积变为原来的 $s^3$ 倍。体积的变化比例由变换[矩阵的行列式](@entry_id:148198) $|\det(S)| = s^3$ 决定 。

**[各向异性缩放](@entry_id:261477) (Anisotropic Scaling)** 对不同的坐标轴使用不同的缩放因子。其[变换矩阵](@entry_id:151616)是一个[对角矩阵](@entry_id:637782) $S = \text{diag}(s_1, s_2, s_3)$：
$$
S = \begin{pmatrix} s_1  0  0 \\ 0  s_2  0 \\ 0  0  s_3 \end{pmatrix}
$$
在这种情况下，沿第 $i$ [根轴](@entry_id:166633)的体素边长变为原来的 $s_i$ 倍。例如，在[磁共振成像 (MRI)](@entry_id:139464) 中，采集的体素在三个维度上的物理尺寸可能不同，这就需要通过[各向异性缩放](@entry_id:261477)来将其重采样到具有立方体素的标准空间中。变换后，体素的体积变为原来的 $s_1 s_2 s_3$ 倍，这同样由[矩阵的行列式](@entry_id:148198) $|\det(S)| = s_1 s_2 s_3$ 给出 。

#### 剪切 (Shear)

[剪切变换](@entry_id:151272)使物体的形状发生倾斜，但保持其体积（或面积）不变。一个典型的二维水平[剪切矩阵](@entry_id:180719) $H$ 形式如下，它将每个点的 $x$ 坐标根据其 $y$ 坐标进行平移：
$$
H = \begin{pmatrix} 1  k \\ 0  1 \end{pmatrix}
$$
其中 $k$ 是剪切因子。这种变换在校正某些成像伪影（如功能磁共振成像中由逐行[采集时间](@entry_id:266526)延迟引起的伪影）时非常有用 。

[剪切变换](@entry_id:151272)具有两个关键的几何特性：
1.  **保持面积/体积**：剪切[矩阵的行列式](@entry_id:148198)为 $\det(H) = (1)(1) - (k)(0) = 1$。由于[线性变换](@entry_id:149133)对面积的缩放因子是其行列式的绝对值，值为 1 的行列式意味着面积不变。
2.  **扭曲角度**：剪切通常不保持角度。我们可以通过考察它如何改变[标准正交基](@entry_id:147779)向量 $\mathbf{e}_1 = (1, 0)^{\top}$ 和 $\mathbf{e}_2 = (0, 1)^{\top}$ 之间的角度来证明这一点。变换后，向量变为 $H\mathbf{e}_1 = (1, 0)^{\top}$ 和 $H\mathbf{e}_2 = (k, 1)^{\top}$。当 $k \neq 0$ 时，这两个向量的点积为 $1 \cdot k + 0 \cdot 1 = k \neq 0$，表明它们不再正交。更普遍地，一个变换保持角度的条件是它的[格拉姆矩阵](@entry_id:203297) (Gram matrix) $A^{\top}A$ 是单位矩阵的标量倍。对于[剪切变换](@entry_id:151272)，
    $$
    H^{\top}H = \begin{pmatrix} 1  0 \\ k  1 \end{pmatrix} \begin{pmatrix} 1  k \\ 0  1 \end{pmatrix} = \begin{pmatrix} 1  k \\ k  1+k^2 \end{pmatrix}
    $$
    当 $k \neq 0$ 时，该矩阵不是 $cI$ 的形式，因此角度被扭曲 。

### 组合变换：仿射图与[齐次坐标](@entry_id:154569)

在实际应用中，如将一个被试的 fMRI 扫描图像对齐到标准脑模板空间，通常需要组合使用旋转、缩放、剪切以及**平移 (translation)**。平移变换将每个点 $\mathbf{x}$ 移动一个固定的向量 $\mathbf{b}$，即 $T(\mathbf{x}) = \mathbf{x} + \mathbf{b}$。

当 $\mathbf{b} \neq \mathbf{0}$ 时，平移不是一个线性变换，因为它不满足 $T(\mathbf{0}) = \mathbf{0}$ 的要求。一个[线性变换](@entry_id:149133)与一个平移的组合被称为**[仿射变换](@entry_id:144885) (affine transformation)**，其一般形式为：
$$
T(\mathbf{x}) = A\mathbf{x} + \mathbf{b}
$$
其中 $A$ 是线性部分（可以是旋转、缩放、剪切的任意组合），$\mathbf{b}$ 是平移向量。由于存在平移项，[仿射变换](@entry_id:144885)通常不保持原点 。

为了在计算上统一处理这些复杂的变换序列，我们引入**[齐次坐标](@entry_id:154569) (homogeneous coordinates)**。这个强大的技巧通过增加一个维度，将 $\mathbb{R}^n$ 空间中的[仿射变换](@entry_id:144885)表示为 $\mathbb{R}^{n+1}$ 空间中的一个线性变换。具体来说，我们将一个点 $\mathbf{x} \in \mathbb{R}^n$ 增广为一个新的向量 $\tilde{\mathbf{x}} \in \mathbb{R}^{n+1}$，方法是在末尾添加一个分量 1：
$$
\tilde{\mathbf{x}} = \begin{pmatrix} \mathbf{x} \\ 1 \end{pmatrix}
$$
现在，[仿射变换](@entry_id:144885) $T(\mathbf{x}) = A\mathbf{x} + \mathbf{b}$ 可以通过一个 $(n+1) \times (n+1)$ 的[增广矩阵](@entry_id:150523) $\tilde{A}$ 的乘法来实现：
$$
\tilde{A} = \begin{pmatrix} A  \mathbf{b} \\ \mathbf{0}^{\top}  1 \end{pmatrix}
$$
变换过程变为 $\tilde{T}(\tilde{\mathbf{x}}) = \tilde{A}\tilde{\mathbf{x}}$，其结果是：
$$
\tilde{A}\tilde{\mathbf{x}} = \begin{pmatrix} A  \mathbf{b} \\ \mathbf{0}^{\top}  1 \end{pmatrix} \begin{pmatrix} \mathbf{x} \\ 1 \end{pmatrix} = \begin{pmatrix} A\mathbf{x} + \mathbf{b} \\ 1 \end{pmatrix}
$$
变换后向量的前 $n$ 个分量正是我们期望的 $A\mathbf{x} + \mathbf{b}$。这种表示方法极为方便，因为它允许我们将一长串的[仿射变换](@entry_id:144885)（如剪切、缩放、旋转再平移）通过矩阵乘法组合成一个单一的[变换矩阵](@entry_id:151616)。例如，在对钙成像数据进行[配准](@entry_id:1122567)时，一个包含剪切 ($H$)、缩放 ($S$)、旋转 ($R$) 和平移 ($\mathbf{b}$) 的完整变换链 $T(\mathbf{x}) = R(S(H\mathbf{x})) + \mathbf{b}$，可以表示为一个单一的[齐次坐标](@entry_id:154569)矩阵 $\tilde{A} = \begin{pmatrix} RSH  \mathbf{b} \\ \mathbf{0}^{\top}  1 \end{pmatrix}$ 。值得注意的是，[齐次坐标](@entry_id:154569)是一种数学表示技巧，它并没有改变原始变换在 $\mathbb{R}^n$ 空间中作为[仿射变换](@entry_id:144885)的本质 。

### 分解变换：奇异值分解

虽然我们可以将多个变换组合成一个矩阵，但反过来，将一个复杂的[变换矩阵](@entry_id:151616)分解为其基本的几何成分也同样重要。**[奇异值分解](@entry_id:138057) (Singular Value Decomposition, SVD)** 提供了一种深刻而通用的方法来“剖析”任何[线性变换](@entry_id:149133) $A$。

任何实数矩阵 $A \in \mathbb{R}^{m \times n}$ 都可以分解为：
$$
A = U\Sigma V^{\top}
$$
其中：
-   $U$ 是一个 $m \times m$ 的[正交矩阵](@entry_id:169220)，其列向量构成了输出空间的一组[标准正交基](@entry_id:147779)。
-   $V$ 是一个 $n \times n$ 的[正交矩阵](@entry_id:169220)，其列向量构成了输入空间的一组[标准正交基](@entry_id:147779)。
-   $\Sigma$ 是一个 $m \times n$ 的[对角矩阵](@entry_id:637782)，其对角线上的元素 $\sigma_i \ge 0$ 称为**奇异值**，并按降序排列。

SVD 的几何解释非常直观：任何[线性变换](@entry_id:149133) $A\mathbf{x}$ 都可以看作是三个连续操作的组合：
1.  **输入空间中的旋转/反射**：由 $V^{\top}$ 实现。它将输入向量 $\mathbf{x}$ 对齐到由 $V$ 的列向量（[右奇异向量](@entry_id:754365)）定义的新坐标系上。
2.  **轴向缩放**：由 $\Sigma$ 实现。它沿着新坐标系的轴，将每个分量独立地缩放[奇异值](@entry_id:152907) $\sigma_i$。
3.  **输出空间中的旋转/反射**：由 $U$ 实现。它将缩放后的向量旋转到最终位置。

当一个线性变换作用于[单位球](@entry_id:142558)（所有长度为 1 的向量的集合）时，SVD 揭示了其几何效应：[单位球](@entry_id:142558)被变换成一个[椭球体](@entry_id:165811)。这个[椭球体](@entry_id:165811)的[主轴](@entry_id:172691)方向由 $U$ 的列向量（[左奇异向量](@entry_id:751233)）给出，而[主轴](@entry_id:172691)的半轴长度恰好是对应的[奇异值](@entry_id:152907) $\sigma_i$ 。

这一概念在**[弥散张量](@entry_id:1123855)成像 (Diffusion Tensor Imaging, DTI)** 中有直接应用。DTI 通过一个[对称正定矩阵](@entry_id:136714) $D$（[弥散张量](@entry_id:1123855)）来描述水分子的弥散特性。$D$ 的 SVD（在这种特殊情况下等同于其[特征值分解](@entry_id:272091)）揭示了弥散的**各向异性 (anisotropy)**。$D$ 的奇异值（等于其特征值）代表了沿主要弥散方向（由 $U$ 的列向量，即[特征向量](@entry_id:151813)给出）的弥散率。如果所有[奇异值](@entry_id:152907)都相等，则弥散是各向同性的（在所有方向上都相同）；如果[奇异值](@entry_id:152907)不相等，则弥散是各向异性的。诸如**[分数各向异性](@entry_id:189754) (Fractional Anisotropy, FA)** 等重要的临床指标，完全由这些[奇异值](@entry_id:152907)计算得出，因此它们是旋转不变的，这意味着头部的朝向不影响这些生物物理度量的值 。

### [三维旋转](@entry_id:148533)的高级表示

在三维空间中，旋转是[运动校正](@entry_id:902964)和姿态估计等任务的核心。虽然 $3 \times 3$ 的旋转矩阵是其标准定义，但在实践中，尤其是在优化和插值方面，它存在一些局限。

#### [欧拉角](@entry_id:171794)的问题：万向节死锁

**欧拉角 (Euler angles)**，如[偏航-俯仰-滚转](@entry_id:199824) (yaw-pitch-roll)，是一种直观的三[参数表示](@entry_id:173803)法，通过绕三个连续轴的旋转来描述任意[三维方向](@entry_id:164813)。然而，这种表示法存在一个被称为**[万向节死锁](@entry_id:171734) (gimbal lock)** 的固有问题。在特定的姿态下（例如，对于 $Z-Y-X$ 顺序，当俯仰角 $\theta = \pm 90^{\circ}$ 时），第一次旋转的轴和第三次旋转的轴会重合，导致系统失去一个旋转自由度。

从数学上看，这表现为将[欧拉角](@entry_id:171794)变化率 $(\dot{\phi}, \dot{\theta}, \dot{\psi})$ 映射到身体坐标系[角速度](@entry_id:192539) $\omega$ 的[雅可比矩阵](@entry_id:178326) $J$ 的奇异性。对于 $Z-Y-X$ [欧拉角](@entry_id:171794)，这个雅可比[矩阵的行列式](@entry_id:148198)恰好是 $\cos\theta$ 。当 $\theta = \pm 90^{\circ}$ 时，$\det(J) = 0$，[雅可比矩阵](@entry_id:178326)变为不可逆。这意味着存在某些方向的瞬时旋转无法用欧拉角变化率的组合来实现，这给基于梯度的优化算法带来了严重的[数值不稳定性](@entry_id:137058)。

#### 一种更优的替代方案：[单位四元数](@entry_id:204470)

为了克服[万向节死锁](@entry_id:171734)，神经影像学中的[运动校正](@entry_id:902964)流水线广泛使用**[单位四元数](@entry_id:204470) (unit quaternions)** 来[参数化](@entry_id:265163)旋转。一个[单位四元数](@entry_id:204470) $\mathbf{q} = (w, x, y, z)$ 是一个[四维向量](@entry_id:275085)，满足约束 $w^2 + x^2 + y^2 + z^2 = 1$。它可以被看作是四维空间中的单位超球面上的一个点。

[单位四元数](@entry_id:204470)与[三维旋转](@entry_id:148533)之间存在一个优美的对应关系。一个绕单位轴 $\mathbf{u}=(u_x, u_y, u_z)$ 旋转角度 $\theta$ 的变换，可以由四元数 $\mathbf{q} = (\cos(\theta/2), \sin(\theta/2)\mathbf{u})$ 表示。从四元数到 $3 \times 3$ [旋转矩阵](@entry_id:140302)的转换为：
$$
\mathbf{R} =
\begin{pmatrix}
1 - 2(y^2 + z^2)  2(xy - wz)  2(xz + wy) \\
2(xy + wz)  1 - 2(x^2 + z^2)  2(yz - wx) \\
2(xz - wy)  2(yz + wx)  1 - 2(x^2 + y^2)
\end{pmatrix}
$$
这个映射是二次的，[非线性](@entry_id:637147)的 。

与[欧拉角](@entry_id:171794)相比，[单位四元数](@entry_id:204470)具有显著优势：
-   **无奇异点**：[四元数](@entry_id:1130460)的参数空间是光滑的，不存在万向节死锁这样的[奇点](@entry_id:266699)。
-   **高效的组合**：两个旋转的组合对应于两个四元数的乘法，计算上比[矩阵乘法](@entry_id:156035)更高效。
-   **平滑的插值**：通过**[球面线性插值](@entry_id:1131743) (Spherical Linear Interpolation, SLERP)**，可以在两个姿态之间生成平滑、最短的路径，这对于插值[运动伪影](@entry_id:1128203)或生成平滑的动画至关重要。

由于这些优点，[单位四元数](@entry_id:204470)在 fMRI 体积间[刚体运动](@entry_id:144691)校正的[最小二乘法拟合](@entry_id:1127151)中，能够提供更稳定的梯度，从而改善[优化算法](@entry_id:147840)的收敛性 。需要强调的是，[单位四元数](@entry_id:204470)仅能表示旋转（3个自由度），不能表示缩放或剪切等更一般的[仿射变换](@entry_id:144885)。

#### 基础理论：[李群](@entry_id:137659)与[李代数](@entry_id:137954)

对[三维旋转](@entry_id:148533)更深层次的理解来自于**李群 (Lie group)** 和**李代数 (Lie algebra)** 的理论。所有[三维旋转矩阵](@entry_id:152550)的集合构成了**[特殊正交群](@entry_id:146418) $SO(3)$**。这是一个连续的群，也是一个光滑的流形。

**李代数 $\mathfrak{so}(3)$** 是 $SO(3)$ 在单位元（即[单位矩阵](@entry_id:156724) $I$）处的[切空间](@entry_id:199137)。通过对 $SO(3)$ 的定义约束 $R^{\top}R=I$ 求导，可以证明 $\mathfrak{so}(3)$ 由所有 $3 \times 3$ **[斜对称矩阵](@entry_id:155998) (skew-symmetric matrices)** 组成，即满足 $\Omega^{\top} = -\Omega$ 的矩阵。这些矩阵代表了**[无穷小旋转](@entry_id:166635)**，也就是角速度。任何三维角速度向量 $\omega = (\omega_x, \omega_y, \omega_z)^{\top}$ 都可以唯一地映射到一个[斜对称矩阵](@entry_id:155998) $[\omega]_{\times}$ 。

连接[李代数](@entry_id:137954)和[李群](@entry_id:137659)的桥梁是**[指数映射](@entry_id:137184) (exponential map)**。对于任何 $\Omega \in \mathfrak{so}(3)$，其矩阵指数 $\exp(\Omega)$ 必定是一个[旋转矩阵](@entry_id:140302)，即 $\exp(\Omega) \in SO(3)$。这是因为：
1.  $(\exp(\Omega))^{\top} = \exp(\Omega^{\top}) = \exp(-\Omega)$。由于 $\Omega$ 和 $-\Omega$ 可交换，所以 $(\exp(\Omega))^{\top}\exp(\Omega) = \exp(-\Omega)\exp(\Omega) = \exp(0) = I$。因此 $\exp(\Omega)$ 是正交的。
2.  根据[雅可比公式](@entry_id:142453)，$\det(\exp(\Omega)) = \exp(\text{tr}(\Omega))$。由于[斜对称矩阵](@entry_id:155998)的对角[线元](@entry_id:196833)素必为零，其迹 $\text{tr}(\Omega) = 0$。因此，$\det(\exp(\Omega)) = \exp(0) = 1$。

这个映射有一个重要的具体形式，即**罗德里格斯旋转公式 (Rodrigues' rotation formula)**。一个绕单位轴 $\mathbf{u}$ 旋转角度 $\theta$ 的旋转矩阵，可以表示为 $R = \exp(\theta[\mathbf{u}]_{\times})$ 。这一理论框架为处理旋[转动力学](@entry_id:167121)（如从 IMU 传感器数据积分得到姿态）和理解旋转参数空间提供了坚实的数学基础。

### [概率模型](@entry_id:265150)的变换

除了变换空间坐标，我们还经常需要理解当[特征向量](@entry_id:151813)经过线性变换后，其概率分布会如何改变。假设一个随机向量 $X \in \mathbb{R}^n$ 的[概率密度函数](@entry_id:140610) (PDF) 为 $p_X(x)$，它经过一个[可逆线性变换](@entry_id:149915) $Y = AX$。我们希望找到新随机向量 $Y$ 的密度函数 $p_Y(y)$。

根据[概率守恒](@entry_id:149166)原理，在一个小区域 $d^n y$ 中找到 $Y$ 的概率 $p_Y(y) d^n y$ 必须等于在对应的原始区域 $d^n x$ 中找到 $X$ 的概率 $p_X(x) d^n x$。我们知道 $x = A^{-1}y$，并且根据多元微[积分的变量替换](@entry_id:178219)规则，[体积元](@entry_id:267802)之间的关系是 $d^n x = |\det(A^{-1})| d^n y = \frac{1}{|\det(A)|} d^n y$。因此：
$$
p_Y(y) d^n y = p_X(A^{-1}y) \frac{1}{|\det(A)|} d^n y
$$
由此可得变换后的[概率密度函数](@entry_id:140610)为：
$$
p_Y(y) = \frac{p_X(A^{-1}y)}{|\det(A)|}
$$
这个公式直观地表明，新的[概率密度](@entry_id:175496)不仅取决于在变换前对应点的密度值 $p_X(A^{-1}y)$，还必须用变换所引起的[体积缩放因子](@entry_id:158899) $|\det(A)|$ 进行归一化。如果变换扩大了体积（$|\det(A)| > 1$），则密度会降低；反之，如果变换压缩了体积，密度会升高。这一原理在对[神经特征](@entry_id:894052)（如[主成分分析](@entry_id:145395)得分、放电率等）进行跨实验会话的对齐和归一化时非常关键 。