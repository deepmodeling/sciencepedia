{
    "hands_on_practices": [
        {
            "introduction": "The core power of eigenvalue analysis in dynamical systems is its ability to decompose complex dynamics into simpler, fundamental \"modes.\" This practice reverses the typical textbook problem: instead of calculating eigenvectors from a matrix, you will infer an eigenvalue and its corresponding eigenvector directly from an observed trajectory. This exercise reinforces the foundational concept that an eigenvector represents a direction in state space along which the system's evolution is purely exponential, scaled by its eigenvalue. ",
            "id": "1674179",
            "problem": "A simplified model for the population dynamics of two competing species, let's call them species A and species B, is described by a system of linear first-order ordinary differential equations. Let $x(t)$ and $y(t)$ be the populations of species A and B at time $t$, respectively. The state of the system is represented by the vector $\\mathbf{p}(t) = \\begin{pmatrix} x(t) \\\\ y(t) \\end{pmatrix}$. The evolution of these populations is governed by the matrix equation $\\frac{d\\mathbf{p}}{dt} = M\\mathbf{p}$, where $M$ is a $2 \\times 2$ matrix of constant coefficients that represents the interaction between the species. An ecologist observes that one specific mode of decay in the populations follows the trajectory $\\mathbf{p}(t) = k e^{-3t} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$, where $k$ is a non-zero constant determined by the initial populations. This mode represents one of the fundamental behaviors, or eigensolutions, of the system. Based on this observation, identify the eigenvalue $\\lambda$ and its corresponding eigenvector $\\mathbf{v}$ that describe this mode. For the eigenvector, provide the version with the simplest integer components.\n\nWrite your answer as a single row matrix containing the eigenvalue followed by the components of the eigenvector, in the format $\\begin{pmatrix} \\lambda  v_1  v_2 \\end{pmatrix}$.",
            "solution": "We are given a linear system $\\frac{d\\mathbf{p}}{dt}=M\\mathbf{p}$ with an observed mode $\\mathbf{p}(t)=k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}$, where $k\\neq 0$. For a linear time-invariant system, a solution of the form $\\mathbf{p}(t)=k\\exp(\\lambda t)\\mathbf{v}$ implies that $\\mathbf{v}$ is an eigenvector of $M$ with eigenvalue $\\lambda$. To verify this, differentiate the observed mode:\n$$\n\\frac{d\\mathbf{p}}{dt}=\\frac{d}{dt}\\left(k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}\\right)=-3k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nOn the other hand,\n$$\nM\\mathbf{p}(t)=M\\left(k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}\\right)=k\\exp(-3t)M\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nSince $\\frac{d\\mathbf{p}}{dt}=M\\mathbf{p}$, we equate the two expressions:\n$$\n-3k\\exp(-3t)\\begin{pmatrix}1\\\\-1\\end{pmatrix}=k\\exp(-3t)M\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nCanceling the nonzero scalar factor $k\\exp(-3t)$ yields\n$$\nM\\begin{pmatrix}1\\\\-1\\end{pmatrix}=-3\\begin{pmatrix}1\\\\-1\\end{pmatrix}.\n$$\nTherefore, the eigenvalue is $\\lambda=-3$ and a corresponding eigenvector is $\\mathbf{v}=\\begin{pmatrix}1\\\\-1\\end{pmatrix}$. Any nonzero scalar multiple would also be valid, and the simplest integer components are $(1,-1)$.\n\nThus the requested row matrix is $\\begin{pmatrix}\\lambda  v_{1}  v_{2}\\end{pmatrix}=\\begin{pmatrix}-3  1  -1\\end{pmatrix}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} -3  1  -1 \\end{pmatrix}}$$"
        },
        {
            "introduction": "While the real parts of eigenvalues determine a system's long-term stability, they do not tell the whole story about short-term behavior. In many neural systems, transient amplification of activity can occur even if the system is asymptotically stable. This exercise delves into this phenomenon by constructing a non-normal matrix, where eigenvectors are nearly parallel, to explore how their geometry governs transient dynamics and can lead to significant, short-lived responses. ",
            "id": "4158636",
            "problem": "In the analysis of transient amplification in a linearized firing-rate model of a two-population cortical microcircuit, the local dynamics around a stable equilibrium are approximated by a linear system $\\frac{d}{dt}\\,\\delta x(t) = A\\,\\delta x(t)$ with state $\\delta x(t) \\in \\mathbb{R}^{2}$ and system matrix $A \\in \\mathbb{R}^{2 \\times 2}$. Empirically observed local field potential (LFP) transients motivate constructing a stable but highly non-normal $A$ that can exhibit large short-lived gains in $\\|\\delta x(t)\\|_{2}$ following a brief perturbation. You are tasked with constructing such a matrix and analyzing its eigenvectors and condition number.\n\nConsider a design in which $A$ is diagonalizable with real, strictly negative eigenvalues $\\lambda_{1} = -5$ and $\\lambda_{2} = -1$ (units $\\mathrm{s}^{-1}$), and with unit-norm right eigenvectors $v_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $v_{2} = \\begin{pmatrix} \\cos\\theta \\\\ \\sin\\theta \\end{pmatrix}$, where $\\theta = 0.2$ is specified in radians. Let $V = \\begin{pmatrix} v_{1}  v_{2} \\end{pmatrix}$ denote the eigenvector matrix and $\\Lambda = \\mathrm{diag}(\\lambda_{1}, \\lambda_{2})$ the diagonal matrix of eigenvalues, so that by spectral decomposition $A = V\\,\\Lambda\\,V^{-1}$. Throughout, use the induced $2$-norm $\\|\\,\\cdot\\,\\|_{2}$ on vectors and matrices, defined by $\\|M\\|_{2} = \\sup_{x \\neq 0} \\frac{\\|Mx\\|_{2}}{\\|x\\|_{2}}$ and the corresponding matrix condition number $\\kappa_{2}(M) = \\|M\\|_{2}\\,\\|M^{-1}\\|_{2}$.\n\nTasks:\n1. Using only the core definitions of eigenvalues, eigenvectors, and spectral decomposition, explicitly construct $A$ from $V$ and $\\Lambda$ for the specified $\\lambda_{1}$, $\\lambda_{2}$, and $\\theta$.\n2. Starting from the definition of the induced $2$-norm and singular values, derive an analytic expression for $\\kappa_{2}(V)$ in terms of $\\theta$ and evaluate it for $\\theta = 0.2$.\n3. Using spectral decomposition and the submultiplicativity of the induced norm, derive a rigorous upper bound for the worst-case transient amplification $\\sup_{t \\geq 0} \\left\\| \\exp(A t) \\right\\|_{2}$ of the linearized dynamics in terms of $V$ and $\\Lambda$, and evaluate this bound numerically for the given parameters.\n\nAnswer specification:\n- Provide your final answer as a single real number equal to the evaluated upper bound for $\\sup_{t \\geq 0} \\left\\| \\exp(A t) \\right\\|_{2}$.\n- Round your answer to four significant figures.\n- Express the final answer as a dimensionless quantity.",
            "solution": "The matrix $A$ can be constructed from its spectral decomposition $A = V \\Lambda V^{-1}$. The eigenvector and eigenvalue matrices are:\n$$V = \\begin{pmatrix} v_{1}  v_{2} \\end{pmatrix} = \\begin{pmatrix} 1  \\cos\\theta \\\\ 0  \\sin\\theta \\end{pmatrix}, \\quad \\Lambda = \\begin{pmatrix} -5  0 \\\\ 0  -1 \\end{pmatrix}$$\nThe inverse of $V$ is $V^{-1} = \\frac{1}{\\sin\\theta} \\begin{pmatrix} \\sin\\theta  -\\cos\\theta \\\\ 0  1 \\end{pmatrix}$. This completes the construction of $A$ as part of Task 1.\n\nFor Task 2, the condition number is $\\kappa_{2}(V) = \\|V\\|_{2} \\|V^{-1}\\|_{2}$. The induced 2-norm, $\\|M\\|_{2}$, is the largest singular value of $M$, $\\sigma_{\\max}(M)$. The singular values are the square roots of the eigenvalues of $M^T M$.\nFor $V$, we compute $V^T V = \\begin{pmatrix} 1  \\cos\\theta \\\\ \\cos\\theta  1 \\end{pmatrix}$. The eigenvalues of $V^T V$ are the roots of $(1-\\mu)^2 - \\cos^2\\theta = 0$, which are $\\mu = 1 \\pm \\cos\\theta$.\nThe singular values of $V$ are $\\sigma_1(V) = \\sqrt{1+\\cos\\theta}$ and $\\sigma_2(V) = \\sqrt{1-\\cos\\theta}$.\nThus, $\\|V\\|_{2} = \\sigma_{\\max}(V) = \\sqrt{1+\\cos\\theta}$.\nThe singular values of $V^{-1}$ are the reciprocals of those of $V$, so $\\|V^{-1}\\|_{2} = 1/\\sigma_{\\min}(V) = 1/\\sqrt{1-\\cos\\theta}$.\nThe condition number is:\n$$\\kappa_{2}(V) = \\|V\\|_{2} \\|V^{-1}\\|_{2} = \\sqrt{\\frac{1+\\cos\\theta}{1-\\cos\\theta}} = \\sqrt{\\frac{2\\cos^2(\\theta/2)}{2\\sin^2(\\theta/2)}} = |\\cot(\\theta/2)|$$\nFor $\\theta=0.2 \\in (0, \\pi)$, this simplifies to $\\kappa_{2}(V) = \\cot(\\theta/2)$.\n\nFor Task 3, we seek an upper bound for $\\sup_{t \\geq 0} \\left\\| \\exp(A t) \\right\\|_{2}$.\nUsing the spectral decomposition, $\\exp(At) = V \\exp(\\Lambda t) V^{-1}$. By the submultiplicativity of the norm:\n$$\\|\\exp(At)\\|_{2} \\le \\|V\\|_{2} \\|\\exp(\\Lambda t)\\|_{2} \\|V^{-1}\\|_{2} = \\kappa_2(V) \\|\\exp(\\Lambda t)\\|_{2}$$\nThe norm of the diagonal matrix $\\exp(\\Lambda t) = \\mathrm{diag}(e^{-5t}, e^{-t})$ is $\\|\\exp(\\Lambda t)\\|_{2} = \\max(|e^{-5t}|, |e^{-t}|) = e^{-t}$ for $t \\ge 0$.\nThe bound on the norm is $\\|\\exp(At)\\|_{2} \\le \\kappa_2(V) e^{-t}$. The maximum value of this bound occurs at $t=0$.\nTherefore, a rigorous upper bound for the transient amplification is:\n$$\\sup_{t \\geq 0} \\|\\exp(At)\\|_{2} \\le \\kappa_2(V)$$\nEvaluating this bound numerically with $\\theta = 0.2$:\n$$\\kappa_2(V) = \\cot(0.2/2) = \\cot(0.1) \\approx 9.96664442$$\nRounding to four significant figures, the bound is 9.967.",
            "answer": "$$\\boxed{9.967}$$"
        },
        {
            "introduction": "A linear system is not always guaranteed to have a full set of linearly independent eigenvectors. This \"defective\" case, mathematically described by Jordan blocks, is critical for understanding systems tuned to specific operational points. This practice challenges you to analyze the impulse response of a defective system, revealing a characteristic dynamic signature that is not purely exponential but involves a polynomial-in-time term, a key feature of critical dynamics in neural models. ",
            "id": "4158698",
            "problem": "Consider a simplified continuous-time linear recurrent population model used in neuroscience to describe the evolution of mean activity rates in a small microcircuit. Let the state vector be $x(t) \\in \\mathbb{R}^{2}$, representing two interacting neuronal populations whose activities are normalized to be dimensionless. The dynamics are given by the linear time-invariant (LTI) system\n$$\n\\frac{d}{dt} x(t) = A x(t) + B u(t), \\quad x(0^{-}) = 0,\n$$\nwhere $A \\in \\mathbb{R}^{2 \\times 2}$ is the synaptic connectivity matrix, $B \\in \\mathbb{R}^{2 \\times 1}$ specifies how external input drives the circuit, and $u(t)$ is a scalar input. To isolate the effect of a non-diagonalizable mode, construct $A$ to have a single $2 \\times 2$ Jordan block with a repeated eigenvalue $\\lambda \\in \\mathbb{R}$ (assume $\\lambda  0$ for stability), specifically\n$$\nA = \\begin{pmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{pmatrix}.\n$$\nLet the circuit receive a unit impulse input at time $t=0$ applied to the second population only, i.e.,\n$$\nu(t) = \\delta(t), \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}.\n$$\nAssume the readout of interest is the activity of the first population, $y(t) = C x(t)$ with\n$$\nC = \\begin{pmatrix} 1  0 \\end{pmatrix}.\n$$\nStarting from the definitions of the matrix exponential via its power series and the impulse response of linear systems via convolution with the Dirac delta, derive a closed-form analytic expression for the impulse response $y(t)$ for $t \\ge 0$ as a function of $\\lambda$ and $t$. Express your final answer as a single symbolic expression in terms of $\\lambda$ and $t$. Do not include units in your final expression. No numerical approximation or rounding is required.",
            "solution": "The problem describes a linear time-invariant (LTI) system. For an impulse input $u(t) = \\delta(t)$ and zero initial conditions, the state vector response is $x(t) = e^{At}B$. The output is then $y(t) = C x(t) = C e^{At} B$. The core task is to compute the matrix exponential $e^{At}$ for the given Jordan block matrix.\n\nThe matrix $A$ can be decomposed as the sum of a commuting diagonal and nilpotent matrix:\n$$\nA = \\begin{pmatrix} \\lambda  1 \\\\ 0  \\lambda \\end{pmatrix} = \\begin{pmatrix} \\lambda  0 \\\\ 0  \\lambda \\end{pmatrix} + \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix} = \\lambda I + N\n$$\nSince $\\lambda I$ and $N$ commute, $e^{At} = e^{(\\lambda I + N)t} = e^{\\lambda It} e^{Nt}$.\n\nThe first term is $e^{\\lambda It} = (e^{\\lambda t})I = \\begin{pmatrix} e^{\\lambda t}  0 \\\\ 0  e^{\\lambda t} \\end{pmatrix}$.\n\nFor the second term, we compute powers of $N$:\n$N = \\begin{pmatrix} 0  1 \\\\ 0  0 \\end{pmatrix}$, and $N^2 = \\begin{pmatrix} 0  0 \\\\ 0  0 \\end{pmatrix}$. All higher powers are also the zero matrix.\nThe power series for $e^{Nt}$ truncates:\n$$\ne^{Nt} = I + Nt + \\frac{(Nt)^2}{2!} + \\dots = I + Nt = \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix}\n$$\nCombining these results, the full matrix exponential is:\n$$\ne^{At} = e^{\\lambda t} I \\cdot (I + Nt) = e^{\\lambda t}(I+Nt) = e^{\\lambda t} \\begin{pmatrix} 1  t \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\\\ 0  e^{\\lambda t} \\end{pmatrix}\n$$\nFinally, we compute the impulse response $y(t)$ for $t \\ge 0$:\n$$\ny(t) = C e^{At} B = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\\\ 0  e^{\\lambda t} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n$$\ny(t) = \\begin{pmatrix} e^{\\lambda t}  t e^{\\lambda t} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = (e^{\\lambda t})(0) + (t e^{\\lambda t})(1) = t e^{\\lambda t}\n$$\nThis is the required closed-form expression.",
            "answer": "$$\n\\boxed{t \\exp(\\lambda t)}\n$$"
        }
    ]
}