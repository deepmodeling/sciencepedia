{
    "hands_on_practices": [
        {
            "introduction": "理解白噪声需要在时域和频域两个维度上把握其特性。这项基础练习通过推导采样白噪声信号的时域方差与其功率谱密度 (PSD) 水平之间的精确关系，将这两个视角联系起来。掌握这种联系对于正确解读频谱图和量化数字记录中的噪声功率至关重要。",
            "id": "4188424",
            "problem": "在一个神经记录实验中，你采集到一个零均值离散时间噪声序列 $\\{x[n]\\}_{n \\in \\mathbb{Z}}$。该序列经实验验证为广义平稳白噪声，其时域方差为 $\\sigma_{x}^{2}$（单位 $\\mathrm{V}^{2}$）。该序列是通过在采样频率 $f_{s}$（单位 $\\mathrm{Hz}$）下进行理想均匀采样得到的。请利用功率谱密度 (PSD) 是自相关函数的傅里叶变换（Wiener–Khinchin 定理）这一定义，以及通过 $f = \\omega f_{s} / (2\\pi)$ 将离散时间频率变量 $\\omega$（单位 $\\mathrm{rad/sample}$）与连续频率 $f$（单位 $\\mathrm{Hz}$）联系起来的归一化关系，推导在 $0  f  f_{s}/2$ 范围内的单边功率谱密度 $S_{1}(f)$ 的恒定水平（单位 $\\mathrm{V}^{2}/\\mathrm{Hz}$）。你的推导必须从白噪声的自相关函数开始，并确保单边功率谱密度在奈奎斯特频带上的积分能够恢复时域方差。\n\n将最终结果表示为关于 $\\sigma_{x}^{2}$ 和 $f_{s}$ 的单一闭式解析表达式。最终的方框答案中不要包含单位，单位假定为 $\\mathrm{V}^{2}/\\mathrm{Hz}$。不需要进行数值近似。",
            "solution": "出发点是离散时间白噪声的定义以及 Wiener–Khinchin 定理。对于一个零均值、广义平稳、方差为 $\\sigma_{x}^{2}$ 的白噪声序列 $x[n]$，其自相关函数为\n$$\nR_{x}[k] = \\mathbb{E}\\{x[n] x[n+k]\\} = \\sigma_{x}^{2} \\,\\delta[k],\n$$\n其中 $\\delta[k]$ 是克罗内克 δ 函数。根据 Wiener–Khinchin 定理，离散时间功率谱密度 $S_{x}^{(d)}(\\omega)$（以与 $\\omega$ 相关的传统离散时间单位 $\\mathrm{rad/sample}$ 计量）是 $R_{x}[k]$ 的离散时间傅里叶变换：\n$$\nS_{x}^{(d)}(\\omega) = \\sum_{k=-\\infty}^{\\infty} R_{x}[k] \\exp(-\\mathrm{i}\\,\\omega k) = \\sigma_{x}^{2},\n$$\n在 $\\omega \\in [-\\pi,\\pi]$ 范围内，该谱是平坦的（恒定的）。\n\n为了将其与以赫兹为单位表示的 PSD（记作 $S_{x}^{(2)}(f)$ 代表双边 PSD）联系起来，我们使用在从 $\\omega$ 到 $f$ 的变量变换下保持总功率（方差）不变的归一化方法：\n$$\nf = \\frac{\\omega f_{s}}{2\\pi}, \\quad \\mathrm{d}f = \\frac{f_{s}}{2\\pi}\\,\\mathrm{d}\\omega.\n$$\n方差 $\\sigma_{x}^{2}$ 必须等于双边 PSD 在基本奈奎斯特区间上的积分面积：\n$$\n\\sigma_{x}^{2} = \\int_{-f_{s}/2}^{f_{s}/2} S_{x}^{(2)}(f)\\,\\mathrm{d}f.\n$$\n在离散时间频率变量下，相同的方差为\n$$\n\\sigma_{x}^{2} = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} S_{x}^{(d)}(\\omega)\\,\\mathrm{d}\\omega = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\sigma_{x}^{2}\\,\\mathrm{d}\\omega = \\sigma_{x}^{2}.\n$$\n为了确保积分在变量变换下的一致性，我们要求\n$$\nS_{x}^{(2)}(f)\\,\\mathrm{d}f = \\frac{1}{2\\pi} S_{x}^{(d)}(\\omega)\\,\\mathrm{d}\\omega,\n$$\n这就得到\n$$\nS_{x}^{(2)}(f) = \\frac{1}{2\\pi} S_{x}^{(d)}(\\omega)\\,\\frac{\\mathrm{d}\\omega}{\\mathrm{d}f} = \\frac{1}{2\\pi}\\,\\sigma_{x}^{2}\\,\\frac{2\\pi}{f_{s}} = \\frac{\\sigma_{x}^{2}}{f_{s}},\n$$\n对于 $f \\in (-f_{s}/2, f_{s}/2)$。因此，以 $\\mathrm{V}^{2}/\\mathrm{Hz}$ 为单位的双边 PSD 在 $\\sigma_{x}^{2}/f_{s}$ 水平上是平坦的。\n\n在 $f \\in (0, f_{s}/2)$ 上的单边 PSD $S_{1}(f)$ 的定义是，将其在正频率上积分可以恢复总方差。这可以通过将严格正频率的双边水平加倍来实现：\n$$\nS_{1}(f) = 2\\,S_{x}^{(2)}(f) = \\frac{2\\,\\sigma_{x}^{2}}{f_{s}}, \\quad 0  f  \\frac{f_{s}}{2}.\n$$\n最后，我们验证单边 PSD 的积分等于方差：\n$$\n\\int_{0}^{f_{s}/2} S_{1}(f)\\,\\mathrm{d}f = \\int_{0}^{f_{s}/2} \\frac{2\\,\\sigma_{x}^{2}}{f_{s}}\\,\\mathrm{d}f = \\frac{2\\,\\sigma_{x}^{2}}{f_{s}} \\cdot \\frac{f_{s}}{2} = \\sigma_{x}^{2}.\n$$\n因此，以 $\\mathrm{V}^{2}/\\mathrm{Hz}$ 为单位的恒定单边 PSD 水平为\n$$\nS_{1}(f) = \\frac{2\\,\\sigma_{x}^{2}}{f_{s}} \\quad \\text{for} \\quad 0  f  \\frac{f_{s}}{2}.\n$$",
            "answer": "$$\\boxed{\\frac{2\\,\\sigma_{x}^{2}}{f_{s}}}$$"
        },
        {
            "introduction": "在数据分析中，一个关键目标是建立能够捕捉信号底层结构的模型。一个成功的模型应该只留下与随机、不相关的噪声无法区分的残差。本练习将提供一个广泛使用的诊断工具——Ljung-Box检验的动手实践，用于正式评估模型残差序列是否与白噪声一致，这是模型验证中的一个关键步骤。",
            "id": "4188384",
            "problem": "您的任务是推导并实现一个统计检验，用以评估神经脉冲序列分析中使用的广义线性模型（GLM）的残差序列是否与白噪声一致。请从核心定义和广为接受的事实出发，不要假设任何专门或简化的公式。具体来说，请使用以下基础理论：\n\n- 定义白噪声：一个序列 $\\{e_t\\}_{t=1}^n$，其满足 $E[e_t] = 0$，$\\operatorname{Var}(e_t) = \\sigma^2$ 不随时间变化，且对于所有滞后 $k \\ge 1$，自协方差为零，即 $E[(e_t - E[e_t])(e_{t-k} - E[e_{t-k}])] = 0$。\n- 定义样本均值 $\\bar{e} = \\frac{1}{n} \\sum_{t=1}^n e_t$，滞后 $k$ 的样本自协方差为 $\\hat{\\gamma}(k) = \\frac{1}{n} \\sum_{t=k+1}^n (e_t - \\bar{e})(e_{t-k} - \\bar{e})$，以及当 $\\hat{\\gamma}(0)  0$ 时，滞后 $k$ 的样本自相关为 $\\hat{r}_k = \\hat{\\gamma}(k) / \\hat{\\gamma}(0)$。\n- 使用一个经过充分检验的事实：在独立性（白噪声）的原假设下，对于较大的 $n$，集合 $\\{\\hat{r}_1, \\ldots, \\hat{r}_h\\}$ 近似以零为中心，并且经过适当的缩放后，可以得到一个综合检验统计量，其分布可以用自由度为 $h$ 的卡方分布来近似。\n\n您的任务是：\n\n1. 推导一个综合检验统计量，该统计量汇集了直到滞后 $h$ 的非零样本自相关的证据，并确保在原假设下，该统计量近似服从自由度为 $h$ 的卡方分布。您的推导必须从上述定义开始，并证明为获得此渐近分布所需的缩放是合理的。\n\n2. 给定一个显著性水平 $\\alpha$，根据推导出的检验统计量及其零分布，陈述一个决策规则，以确定残差是否与白噪声一致。\n\n3. 实现一个完整的程序，该程序能够：\n   - 从给定的残差序列中计算 $k = 1, \\ldots, h$ 的样本自相关 $\\hat{r}_k$（假设 $h \\le n-1$；如果 $h  n-1$，则使用 $h' = \\min(h, n-1)$ 替代 $h$）。\n   - 构建推导出的检验统计量，并使用相应的卡方分布计算出对应的 $p$ 值。\n   - 对每个测试用例输出一个布尔决策，指明在指定的 $\\alpha$ 水平下残差是否与白噪声一致（如果一致，输出 `True`，否则输出 `False`）。\n   - 处理 $\\hat{\\gamma}(0) = 0$（所有残差相等）的边界情况，此时定义对所有 $k$ 都有 $\\hat{r}_k = 0$。\n\n测试套件规范：\n\n使用以下四个测试用例来验证您的实现。对于随机模拟，请使用指定的伪随机种子以确保可复现性。\n\n- 案例 A（神经 GLM，正确设定）：使用种子 $s_1 = 12345$ 模拟独立的泊松尖峰计数 $\\{y_t\\}_{t=1}^n$，其中 $n = 200$，恒定速率 $\\lambda = 10$。使用正确设定的模型 $\\hat{\\mu}_t = \\lambda$ 并构建皮尔逊残差 $e_t = (y_t - \\hat{\\mu}_t)/\\sqrt{\\hat{\\mu}_t}$。使用滞后 $h = 10$ 和显著性水平 $\\alpha = 0.05$。\n\n- 案例 B（神经 GLM，错误设定并带有色噪声）：使用种子 $s_2 = 24680$ 模拟相关的泊松尖峰计数 $\\{y_t\\}_{t=1}^n$，其中 $n = 200$，自回归强度为 $\\lambda_t = \\lambda_0 + \\phi y_{t-1}$，$\\lambda_0 = 10$，$\\phi = 0.6$，初始计数 $y_0 = \\lambda_0$。使用错误设定的恒定速率模型 $\\hat{\\mu}_t = \\lambda_0$ 并构建皮尔逊残差 $e_t = (y_t - \\hat{\\mu}_t)/\\sqrt{\\hat{\\mu}_t}$。使用滞后 $h = 10$ 和显著性水平 $\\alpha = 0.05$。\n\n- 案例 C（边界滞后，高斯白噪声）：使用种子 $s_3 = 13579$ 模拟一个高斯白残差序列 $\\{e_t\\}_{t=1}^{50}$，其均值为 $0$，方差为 $1$。使用滞后 $h = 1$ 和显著性水平 $\\alpha = 0.05$。\n\n- 案例 D（零方差边界情况）：使用一个恒定残差序列 $e_t = 0$，其中 $t = 1, \\ldots, 100$。使用滞后 $h = 10$ 和显著性水平 $\\alpha = 0.05$。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含按案例 A、B、C、D 顺序排列的结果，形式为方括号内逗号分隔的列表。例如，`[resultA,resultB,resultC,resultD]`，其中每个 `resultX` 是一个布尔值，表示在给定的 $\\alpha$ 水平下残差是否与白噪声一致。",
            "solution": "我们从白噪声的定义开始。如果 $E[e_t] = 0$，$\\operatorname{Var}(e_t) = \\sigma^2$ 是常数，并且自协方差函数 $\\gamma(k) = E[(e_t - E[e_t])(e_{t-k} - E[e_{t-k}])]$ 满足对于所有 $k \\ge 1$ 都有 $\\gamma(k) = 0$，则残差序列 $\\{e_t\\}_{t=1}^n$ 是白噪声。因此，要评估的核心属性是在非零滞后下不存在自相关。\n\n根据观测数据，我们使用样本均值 $\\bar{e} = \\frac{1}{n}\\sum_{t=1}^n e_t$，样本自协方差 $\\hat{\\gamma}(k) = \\frac{1}{n}\\sum_{t=k+1}^n (e_t - \\bar{e})(e_{t-k} - \\bar{e})$，以及在 $\\hat{\\gamma}(0)  0$ 的条件下，样本自相关 $\\hat{r}_k = \\hat{\\gamma}(k)/\\hat{\\gamma}(0)$。如果 $\\hat{\\gamma}(0) = 0$（所有残差相等），则每个中心化乘积都为零，我们可以定义对所有 $k$ 都有 $\\hat{r}_k = 0$。\n\n在独立性和平稳性（白噪声）的原假设 $H_0$ 下，一个经过充分检验的渐近事实是：对于固定的 $h$ 和大的 $n$，向量 $\\sqrt{n}(\\hat{r}_1, \\ldots, \\hat{r}_h)$ 近似服从多元正态分布，其均值为零，对于独立同分布的残差，其协方差矩阵接近单位矩阵。直观上，每个 $\\hat{r}_k$ 是 $n$ 个中心化乘积的平均值，根据中心极限定理，它近似服从正态分布，其方差以 $1/n$ 的速率递减。因此，一个自然的综合检验统计量，用于汇集跨滞后的零偏差，是 $\\hat{r}_k$ 的加权平方和。\n\nBox–Pierce 统计量使用 $Q_{\\mathrm{BP}} = n \\sum_{k=1}^h \\hat{r}_k^2$，其渐近零分布是 $\\chi^2_h$。Ljung–Box 检验通过调整每一项来考虑滞后 $k$ 处的有效数据对数量，从而改善了有限样本的性能，得到\n$$\nQ = n(n + 2)\\sum_{k=1}^h \\frac{\\hat{r}_k^2}{n - k}.\n$$\n这种缩放是通过将 $\\hat{r}_k$ 的方差近似为 $\\operatorname{Var}(\\hat{r}_k) \\approx \\frac{1}{n}\\left(1 + \\frac{2k}{n}\\right)$ 得出的，这导致了求和内部的乘法校正因子 $\\frac{n(n+2)}{n-k}$，从而改善了对于中等大小 $n$ 的卡方近似效果。在 $H_0$ 下且对于较大的 $n$，$Q$ 近似服从一个自由度为 $h$ 的卡方随机变量，记作 $\\chi^2_h$。\n\n在显著性水平 $\\alpha$ 下的决策规则是：\n- 根据 $k = 1, \\ldots, h'$ 的 $\\hat{r}_k$ 计算 $Q$，其中 $h' = \\min(h, n - 1)$。\n- 计算 $p$ 值 $p = P(\\chi^2_{h'} \\ge Q)$，即在 $Q$ 处评估的、自由度为 $h'$ 的卡方生存函数值。\n- 如果 $p \\ge \\alpha$，则不拒绝 $H_0$，并判定残差与白噪声一致；否则，拒绝 $H_0$，并判定残差与白噪声不一致（有色噪声）。\n\n算法设计：\n- 对于一个输入的残差序列和滞后 $h$，计算 $\\bar{e}$ 和 $\\hat{\\gamma}(0)$。如果 $\\hat{\\gamma}(0) = 0$，根据定义将所有 $\\hat{r}_k$ 设为 $0$ 且 $Q=0$，从而得到 $p = 1$ 和一个与白噪声一致的决策。\n- 否则，对于每个 $k = 1, \\ldots, h'$，通过对 $t = k+1, \\ldots, n$ 求和 $(e_t - \\bar{e})(e_{t-k} - \\bar{e})$，然后除以 $n$，再用 $\\hat{\\gamma}(0)$ 进行归一化，来计算 $\\hat{r}_k$。\n- 计算 $Q = n(n + 2)\\sum_{k=1}^{h'} \\hat{r}_k^2/(n - k)$ 并从卡方分布中得到 $p$ 值。\n- 使用给定的 $\\alpha$ 应用决策规则。\n\n应用于测试案例：\n- 案例 A：具有恒定速率和正确设定模型的独立泊松计数产生的皮尔逊残差是独立的，除了抽样噪声外没有自相关；在 $\\alpha = 0.05$ 时，检验应返回 `True`。\n- 案例 B：具有自回归强度和错误设定的恒定速率模型的相关泊松计数会产生具有正自相关的皮尔逊残差；检验应能检测到有色噪声并返回 `False`。\n- 案例 C：高斯白残差，其中 $h=1$，用于检验即时滞后的自相关，应返回 `True`。\n- 案例 D：残差方差为零；我们的定义将所有 $\\hat{r}_k$ 设为 $0$，从而 $Q=0$，$p=1$，决策为 `True`。\n\n该实现为每个随机模拟使用固定的随机数生成器种子以确保可复现性，并遵循指定的最终输出格式 `[resultA,resultB,resultC,resultD]`。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef ljung_box_test(residuals: np.ndarray, h: int, alpha: float = 0.05):\n    \"\"\"\n    Compute the Ljung–Box Q statistic, its p-value, and the decision\n    on whether the residuals are consistent with white noise.\n\n    Parameters:\n        residuals: 1D numpy array of residuals e_t.\n        h: maximum lag for testing autocorrelation (integer).\n        alpha: significance level for decision (float).\n\n    Returns:\n        decision: bool, True if residuals are consistent with white noise (fail to reject H0).\n        Q: float, Ljung–Box statistic value.\n        p_value: float, chi-squared survival probability at Q with h_eff degrees of freedom.\n    \"\"\"\n    r = np.asarray(residuals, dtype=float)\n    n = r.size\n    h_eff = max(0, min(h, n - 1))\n\n    # Center residuals\n    mean_r = np.mean(r)\n    centered = r - mean_r\n\n    # Sample autocovariance at lag 0 (variance proxy)\n    # Using 1/n normalization per problem statement base.\n    gamma0 = np.sum(centered * centered) / n\n\n    # Handle zero variance edge case: define autocorrelations as zero.\n    if gamma0 == 0.0 or h_eff == 0:\n        Q = 0.0\n        p_value = 1.0\n        decision = p_value = alpha\n        return decision, Q, p_value\n\n    # Compute sample autocorrelations for k = 1..h_eff\n    r_k = np.empty(h_eff, dtype=float)\n    for k in range(1, h_eff + 1):\n        # Sum over t = k .. n-1 = indices t and t-k\n        prod_sum = np.dot(centered[k:], centered[:-k])\n        gamma_k = prod_sum / n\n        r_k[k - 1] = gamma_k / gamma0\n\n    # Ljung–Box Q statistic\n    # Q = n(n+2) * sum_{k=1}^h r_k^2 / (n - k)\n    ks = np.arange(1, h_eff + 1, dtype=float)\n    denom = (n - ks)\n    Q = n * (n + 2) * np.sum((r_k * r_k) / denom)\n\n    # p-value from chi-squared distribution with h_eff degrees of freedom\n    p_value = chi2.sf(Q, df=h_eff)\n\n    decision = p_value = alpha\n    return decision, Q, p_value\n\ndef simulate_case_A(seed=12345, n=200, lam=10.0):\n    rng = np.random.default_rng(seed)\n    y = rng.poisson(lam, size=n)\n    mu_hat = lam\n    residuals = (y - mu_hat) / np.sqrt(mu_hat)\n    return residuals\n\ndef simulate_case_B(seed=24680, n=200, lam0=10.0, phi=0.6):\n    rng = np.random.default_rng(seed)\n    y = np.empty(n, dtype=float)\n    # Initial count set to lam0 as specified\n    y0 = lam0\n    y[0] = y0\n    for t in range(1, n):\n        lam_t = lam0 + phi * y[t - 1]\n        y[t] = rng.poisson(lam_t)\n    mu_hat = lam0  # mis-specified constant-rate model\n    residuals = (y - mu_hat) / np.sqrt(mu_hat)\n    return residuals\n\ndef simulate_case_C(seed=13579, n=50):\n    rng = np.random.default_rng(seed)\n    residuals = rng.normal(loc=0.0, scale=1.0, size=n)\n    return residuals\n\ndef simulate_case_D(n=100):\n    return np.zeros(n, dtype=float)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each test case: (residuals, h, alpha)\n    caseA_resid = simulate_case_A(seed=12345, n=200, lam=10.0)\n    caseB_resid = simulate_case_B(seed=24680, n=200, lam0=10.0, phi=0.6)\n    caseC_resid = simulate_case_C(seed=13579, n=50)\n    caseD_resid = simulate_case_D(n=100)\n\n    test_cases = [\n        (caseA_resid, 10, 0.05),  # Case A\n        (caseB_resid, 10, 0.05),  # Case B\n        (caseC_resid, 1, 0.05),   # Case C\n        (caseD_resid, 10, 0.05),  # Case D\n    ]\n\n    results = []\n    for resid, h, alpha in test_cases:\n        decision, Q, p_value = ljung_box_test(resid, h, alpha)\n        results.append(decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "现实世界中的信号，尤其是在神经科学中，常常表现出复杂的模式，并非简单的白噪声。一个至关重要的任务是确定这种结构是否可以由一个线性过程（即有色噪声）解释，还是包含了更复杂的非线性动力学特征。这项高级练习介绍了强大的代理数据方法 (IAAFT)，用于检验非线性，使您能够区分数据中有意义的动力学复杂性与简单的线性相关性。",
            "id": "4188408",
            "problem": "您的任务是实现一种基于迭代幅度调整傅里叶变换 (IAAFT) 的代理数据方法，用以检验单变量时间序列中观测到的时间结构是否超出了有色噪声零模型下的预期。零假设为：该过程是一个平稳线性随机过程的实现，具有指定的幅度分布和功率谱密度，这两者共同捕捉了数据的线性特性。\n\n请使用以下基础理论：\n- 一个离散时间、零均值的随机过程 $x[t]$, $t = 0,1,\\dots,N-1$，其功率谱密度 (PSD) 为 $S_{xx}(f)$。对于离散信号，PSD 与离散傅里叶变换 (DFT) 相关。令 $X[k]$ 表示 $x[t]$ 的 DFT，定义为\n$$\nX[k] = \\sum_{t=0}^{N-1} x[t] e^{-i 2 \\pi k t / N}, \\quad k = 0,1,\\dots,N-1,\n$$\n并令 $|X[k]|$ 为其幅值。白噪声的特征是平坦的 PSD，而有色噪声的 PSD 是非平坦的（例如，自回归过程呈现有色谱）。\n- IAAFT 方法旨在生成代理信号 $y[t]$，使其保留原始数据的两个属性：幅度分布（样本值的经验分布）和 DFT 的幅值 $|X[k]|$，从而保留编码在 PSD 中的线性自相关结构，同时随机化相位以破坏非线性依赖关系。\n\n定义用于检测非线性结构的时间反演不对称性检验统计量：\n- 令增量序列为 $d[t] = x[t+1] - x[t]$，其中 $t = 0,1,\\dots,N-2$。\n- 定义归一化增量三阶矩\n$$\nT(x) = \\frac{1}{N-1} \\sum_{t=0}^{N-2} \\frac{(d[t])^3}{\\sigma_d^3 + \\varepsilon},\n$$\n其中 $\\sigma_d$ 是 $d[t]$ 的标准差，$\\varepsilon$ 是一个小的正常数，以避免除以零。对于具有对称分布的线性高斯过程，$T(x)$ 的期望值接近于零，而非线性或不对称的时间依赖关系可能导致 $T(x)$ 显著偏离零。\n\n您的程序必须：\n1. 实现 IAAFT 代理数据生成算法。从 $x[t]$ 的一个初始随机排列 $y^{(0)}[t]$ 开始，迭代以下投影，直至收敛或达到最大迭代次数：\n   - 谱投影：计算 $y^{(m)}[t]$ 的 DFT 得到 $Y^{(m)}[k]$，设置\n   $$\n   \\tilde{Y}^{(m)}[k] = |X[k]| e^{i \\angle Y^{(m)}[k]},\n   $$\n   然后进行逆变换以获得 $\\tilde{y}^{(m)}[t]$。\n   - 幅度分布投影：对 $\\tilde{y}^{(m)}[t]$ 进行排序，并用 $x[t]$ 的排序值替换其排序值，以获得 $y^{(m+1)}[t]$。\n   - 使用相对谱误差来监控收敛，\n   $$\n   E^{(m)} = \\frac{\\left\\|\\,| \\mathrm{DFT}(y^{(m)}[t])| - |X[k]|\\,\\right\\|_2}{\\left\\||X[k]|\\right\\|_2},\n   $$\n   当 $E^{(m)}$ 低于一个容差或迭代次数达到预设最大值时停止。\n\n2. 对于每个测试用例，生成指定数量的 IAAFT 代理数据，为每个代理数据 $y_s$ 计算 $T(y_s)$，并相对于代理分布计算观测统计量 $T(x)$ 的双边经验 p 值。使用 $T(y_s)$ 的代理均值 $\\mu_s$，并计算观测统计量与 $\\mu_s$ 的绝对偏差。双边经验 p 值为\n$$\np = \\frac{1 + \\#\\{s: |T(y_s) - \\mu_s| \\ge |T(x) - \\mu_s|\\}}{1 + S},\n$$\n其中 $S$ 是代理数据的数量。一个显著的结果表明，观测到的结构超出了由幅度分布和 PSD 所保留的有色噪声零假设下的预期。\n\n3. 使用阈值 $\\alpha = 0.01$（以小数形式表示）来判断显著性。为每个测试用例输出一个布尔值，指示是否 $p  \\alpha$。\n\n使用以下测试套件，其中所有时间序列在分析前都必须标准化为零均值和单位方差：\n- 用例 A（正常路径，白噪声）：生成长度为 $N = 2048$ 的高斯白噪声。\n- 用例 B（有色线性噪声，一阶自回归）：生成 $x[t] = \\phi x[t-1] + e[t]$，其中 $\\phi = 0.9$，$e[t]$ 为高斯噪声，长度为 $N = 2048$。\n- 用例 C（非线性有色过程）：生成 $x[t] = \\phi x[t-1] + \\beta x[t-1]^2 + e[t]$，其中 $\\phi = 0.8$，$\\beta = 0.3$，$e[t]$ 为高斯噪声，长度为 $N = 2048$。\n- 用例 D（边缘用例，短有色线性噪声）：生成 $x[t] = \\phi x[t-1] + e[t]$，其中 $\\phi = 0.95$，$e[t]$ 为高斯噪声，长度为 $N = 512$。\n\n实现约束：\n- 每个测试用例使用 $S = 40$ 个代理数据。\n- IAAFT 迭代次数最多为 $100$ 次，相对谱容差为 $10^{-6}$。\n- 在 $T(x)$ 的定义中使用一个小的 $\\varepsilon = 10^{-12}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的布尔值列表（例如，“[True,False,True,False]”），依次对应于用例 A、B、C 和 D 的结果。",
            "solution": "该任务是使用迭代幅度调整傅里叶变换 (IAAFT) 代理数据方法，实现一个针对时间序列非线性的统计检验。零假设 $H_0$ 假定观测到的时间序列是一个平稳、线性、随机高斯过程的实现。拒绝 $H_0$ 表明存在非线性结构。分析过程首先验证问题，然后概述理论原理，最后详细说明算法实现。\n\n该问题被认为是有效的，因为它在科学上基于非线性时间序列分析的既定方法，问题陈述清晰，提供了所有必要的参数和定义，并以客观、正式的语言表述。其中没有矛盾、歧义或事实错误。\n\n代理数据方法的核心原理是生成一组时间序列（称为代理数据），这些序列与原始数据共享符合零假设的特定属性，而在其他方面是随机的。对于给定的零假设，代理数据必须保留原始数据的线性特性，这些特性由自相关函数或等效地由功率谱密度 (PSD) 捕捉。IAAFT 算法专门用于创建既匹配原始序列的 PSD 又匹配其幅度分布的代理数据。\n\n设原始的离散时间序列为 $x[t]$，$t = 0, 1, \\dots, N-1$。首先将其标准化为零均值和单位方差。其离散傅里葉变换 (DFT) 是 $X[k]$。PSD 与 $|X[k]|^2$ 成正比。IAAFT 方法生成一个代理序列 $y[t]$，旨在同时满足两个约束条件：\n1. $y[t]$ 中的值集合是 $x[t]$ 中值的排列，从而保留了幅度分布。\n2. $y[t]$ 的 DFT 的幅值，记为 $|Y[k]|$，等于 $x[t]$ 的 DFT 的幅值，即 $|Y[k]| = |X[k]|$。\n\nIAAFT 算法通过迭代实现这一点。以 $x[t]$ 的一个初始随机排列作为第一个代理猜测值 $y^{(0)}[t]$ 开始，算法在两个投影步骤之间交替进行：\n1. **谱投影**：将当前代理数据 $y^{(m)}[t]$ 变换到频域以获得其 DFT $Y^{(m)}[k]$。保留 $Y^{(m)}[k]$ 的相位（记为 $\\angle Y^{(m)}[k]$），但将其幅值替换为来自原始数据的目标幅值 $|X[k]|$。这就创建了一个新的复数谱 $\\tilde{Y}^{(m)}[k] = |X[k]| e^{i \\angle Y^{(m)}[k]}$。然后应用逆 DFT 获得时域信号 $\\tilde{y}^{(m)}[t]$。此步骤强制施加了所需的 PSD，但破坏了幅度分布。\n2. **幅度投影**：调整 $\\tilde{y}^{(m)}[t]$ 的幅度分布以匹配 $x[t]$ 的幅度分布。这是通过等级排序实现的。根据 $\\tilde{y}^{(m)}[t]$ 中值的等级，用 $x[t]$ 的值替换它们。具体来说，$\\tilde{y}^{(m)}[t]$ 中的最小值被 $x[t]$ 的最小值替换，第二小的值被第二小的值替换，依此类推。此过程产生代理数据的下一次迭代 $y^{(m+1)}[t]$。此步骤强制施加了所需的幅度分布，但扰动了 PSD。\n\n重复这两个投影，直到代理数据同时满足两个约束条件达到所需的精度。通过相对谱误差 $E^{(m)} = \\frac{\\left\\|\\,| \\mathrm{DFT}(y^{(m)}[t])| - |X[k]|\\,\\right\\|_2}{\\left\\||X[k]|\\right\\|_2}$ 来监控收敛，其中 $\\|\\cdot\\|_2$ 表示欧几里得范数。当 $E^{(m)}$ 低于容差 $\\tau$ 或达到最大迭代次数时，迭代停止。\n\n为了检验非线性，需要一个对代理数据未保留的属性敏感的检验统计量。问题指定了一个时间反演不对称性的度量，通过时间序列增量的归一化三阶矩来定义。增量序列为 $d[t] = x[t+1] - x[t]$，其中 $t = 0, \\dots, N-2$。检验统计量为：\n$$\nT(x) = \\frac{1}{N-1} \\sum_{t=0}^{N-2} \\frac{(d[t])^3}{\\sigma_d^3 + \\varepsilon}\n$$\n其中 $\\sigma_d$ 是增量 $d[t]$ 的标准差，$\\varepsilon$ 是一个小的正则化常数。对于线性高斯过程，增量的分布是对称的，$T(x)$ 的期望值接近于零。显著偏离零表明存在时间反演不对称性，这是某些非线性动力学的标志。\n\n统计检验按以下步骤进行：\n1. 计算原始数据的统计量 $T_{obs} = T(x)$。\n2. 生成大量的（$S$ 个）IAAFT 代理数据 $\\{y_s[t]\\}_{s=1}^S$。\n3. 为每个代理数据计算统计量 $T_s = T(y_s)$，形成一个代理分布。\n4. 计算代理统计量的均值 $\\mu_s = \\frac{1}{S} \\sum_{s=1}^S T_s$。\n5. 计算双边经验 p 值，它量化了在零假设下，观测到与代理均值的偏差等于或大于观测偏差的概率：\n$$\np = \\frac{1 + \\#\\{s: |T_s - \\mu_s| \\ge |T_{obs} - \\mu_s|\\}}{1 + S}\n$$\n6. 如果计算出的 p 值小于预定的显著性水平 $\\alpha$（此处 $\\alpha=0.01$），则拒绝零假设，并认为数据包含显著的非线性结构。\n\n实现中按规定生成了四个时间序列：高斯白噪声（用例 A）、线性自回归过程（用例 B）、非线性自回归过程（用例 C）以及一个较短的线性自回归过程（用例 D）。对于自回归模型，使用了一个预热期以确保生成的序列是平稳的。然后对每个序列进行标准化。对于每个用例，使用 IAAFT 算法生成 $S=40$ 个代理数据，最大迭代次数为 100 次，容差为 $10^{-6}$。为原始数据和所有代理数据计算检验统计量 $T(x)$，并确定 p 值。最终输出是一个布尔值，指示每个用例是否 $p  \\alpha$。我们预期在线性过程（用例 A、B、D）中不会发现显著的非线性，而在非线性过程（用例 C）中会发现显著的非线性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print the final result.\n    \"\"\"\n    # Set a seed for reproducibility of random processes.\n    np.random.seed(42)\n\n    # --- Problem Parameters ---\n    S = 40  # Number of surrogates\n    MAX_ITER = 100  # Max IAAFT iterations\n    TOL = 1e-6  # IAAFT convergence tolerance\n    EPSILON = 1e-12  # Regularization term for T-statistic\n    ALPHA = 0.01  # Significance level\n\n    # --- Test Case Definitions ---\n    # Case A: White noise\n    x_A = np.random.randn(2048)\n\n    # Case B: AR(1) process\n    x_B = generate_ar_process(N=2048, phi=0.9)\n\n    # Case C: Nonlinear process\n    x_C = generate_ar_process(N=2048, phi=0.8, beta=0.3)\n\n    # Case D: Short AR(1) process\n    x_D = generate_ar_process(N=512, phi=0.95)\n\n    test_cases = [x_A, x_B, x_C, x_D]\n    results = []\n\n    for x_orig in test_cases:\n        is_significant = perform_significance_test(\n            x_orig, S, MAX_ITER, TOL, EPSILON, ALPHA\n        )\n        results.append(is_significant)\n    \n    # Format and print the final output as a boolean list.\n    # The boolean values are capitalized in Python, so convert to lowercase 'true'/'false'\n    # for full compliance with example if interpreted as JSON boolean.\n    # Here, string representation of Python's bool (`True`/`False`) is used as per common interpretation.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef generate_ar_process(N, phi, beta=0.0, burn_in=500):\n    \"\"\"\n    Generates a linear or nonlinear autoregressive time series.\n    \n    Args:\n        N (int): The desired length of the final time series.\n        phi (float): The AR(1) coefficient.\n        beta (float, optional): The coefficient for the nonlinear term x[t-1]^2. Defaults to 0.0.\n        burn_in (int, optional): Number of initial points to discard. Defaults to 500.\n\n    Returns:\n        np.ndarray: The generated time series of length N.\n    \"\"\"\n    length = N + burn_in\n    e = np.random.randn(length)\n    x = np.zeros(length, dtype=np.float64)\n    for t in range(1, length):\n        x[t] = phi * x[t-1] + beta * x[t-1]**2 + e[t]\n    return x[burn_in:]\n\ndef standardize(x):\n    \"\"\"\n    Standardizes a time series to zero mean and unit variance.\n    \n    Args:\n        x (np.ndarray): The input time series.\n\n    Returns:\n        np.ndarray: The standardized time series.\n    \"\"\"\n    return (x - np.mean(x)) / np.std(x)\n\ndef calculate_T(x, epsilon):\n    \"\"\"\n    Calculates the time-reversal asymmetry test statistic T(x).\n    \n    Args:\n        x (np.ndarray): The input time series.\n        epsilon (float): Small constant to prevent division by zero.\n\n    Returns:\n        float: The value of the test statistic T(x).\n    \"\"\"\n    N = len(x)\n    d = x[1:] - x[:-1]\n    sigma_d = np.std(d)\n    # The problem specifies epsilon is added to sigma_d^3\n    denominator = sigma_d**3 + epsilon\n    if denominator == 0:\n        return 0.0 # Should not happen with epsilon, but as a safeguard.\n    T_val = (1.0 / (N - 1)) * np.sum(np.power(d, 3) / denominator)\n    return T_val\n\ndef generate_iaaft_surrogate(x, max_iter, tol):\n    \"\"\"\n    Generates one IAAFT surrogate for the given time series.\n    \n    Args:\n        x (np.ndarray): The original time series (must be pre-standardized).\n        max_iter (int): Maximum number of iterations.\n        tol (float): Convergence tolerance for relative spectral error.\n\n    Returns:\n        np.ndarray: The generated surrogate time series.\n    \"\"\"\n    # Store properties of the original series\n    x_sorted = np.sort(x)\n    X_mag = np.abs(np.fft.fft(x))\n    X_mag_norm = np.linalg.norm(X_mag)\n    if X_mag_norm == 0:\n        return x # Return original if it's a zero series\n\n    # 1. Start with a random permutation of x\n    y = np.random.permutation(x)\n\n    for _ in range(max_iter):\n        # 2a. Spectral projection: Impose the power spectrum of x\n        Y = np.fft.fft(y)\n        Y_phases = np.angle(Y)\n        Y_tilde = X_mag * np.exp(1j * Y_phases)\n        y_tilde = np.real(np.fft.ifft(Y_tilde))\n\n        # 2b. Amplitude projection: Impose the amplitude distribution of x\n        sort_indices = np.argsort(y_tilde)\n        y_next = np.zeros_like(y)\n        y_next[sort_indices] = x_sorted\n        y = y_next\n\n        # 3. Check for convergence\n        Y_mag_current = np.abs(np.fft.fft(y))\n        error = np.linalg.norm(Y_mag_current - X_mag) / X_mag_norm\n        if error  tol:\n            break\n            \n    return y\n\ndef perform_significance_test(x_orig, S, max_iter, tol, epsilon, alpha):\n    \"\"\"\n    Performs the full significance test for a given time series.\n    \n    Args:\n        x_orig (np.ndarray): The original time series.\n        S (int): Number of surrogates to generate.\n        max_iter (int): Max IAAFT iterations.\n        tol (float): IAAFT convergence tolerance.\n        epsilon (float): Regularizer for T-statistic.\n        alpha (float): Significance level for p-value.\n\n    Returns:\n        bool: True if the result is significant (p  alpha), False otherwise.\n    \"\"\"\n    # All time series must be standardized before analysis\n    x = standardize(x_orig)\n    \n    # Calculate statistic for observed data\n    T_obs = calculate_T(x, epsilon)\n    \n    # Generate surrogates and calculate their statistics\n    T_surr_list = []\n    for _ in range(S):\n        y = generate_iaaft_surrogate(x, max_iter, tol)\n        T_surr = calculate_T(y, epsilon)\n        T_surr_list.append(T_surr)\n        \n    T_surr_arr = np.array(T_surr_list)\n    mu_s = np.mean(T_surr_arr)\n    \n    # Calculate two-sided p-value\n    dev_obs = np.abs(T_obs - mu_s)\n    dev_surr = np.abs(T_surr_arr - mu_s)\n    \n    # Count how many surrogate deviations are = observed deviation\n    count = np.sum(dev_surr = dev_obs)\n    \n    p_val = (1.0 + count) / (1.0 + S)\n    \n    return p_val  alpha\n\nif __name__ == \"__main__\":\n    solve()\n\n```"
        }
    ]
}