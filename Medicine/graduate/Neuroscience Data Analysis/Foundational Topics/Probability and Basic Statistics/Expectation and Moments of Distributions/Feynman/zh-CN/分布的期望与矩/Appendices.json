{
    "hands_on_practices": [
        {
            "introduction": "矩是描述概率分布形状的基本工具。虽然原始矩（关于原点的矩）易于计算，但中心矩（关于均值的矩）在描述方差、偏度和峰度等与分布形态密切相关的特征时更为有用。本练习旨在通过从第一性原理出发，巩固您在原始矩和中心矩之间进行代数转换的技能，并揭示这些抽象定义如何导出像正态分布峰度这样的关键特性。",
            "id": "4160952",
            "problem": "您正在分析在重复呈现相同刺激时，从皮层记录的感觉诱发的局部场电位 (LFP) 幅度的逐次试验变异性。设试验间的幅度由一个实值随机变量 $X$ 建模，该变量存在最高四阶的有限原点矩，其中 $k$ 阶原点矩定义为 $m_{k} = \\mathbb{E}[X^{k}]$，均值定义为 $\\mu = \\mathbb{E}[X] = m_{1}$。$k$ 阶中心矩定义为 $\\mu_{k} = \\mathbb{E}\\!\\left[(X - \\mu)^{k}\\right]$。\n\n任务1：仅从期望、原点矩和中心矩的这些定义出发，推导第三和第四中心矩 $\\mu_{3}$ 和 $\\mu_{4}$ 关于原点矩 $m_{1}, m_{2}, m_{3}, m_{4}$ 和均值 $\\mu$ 的表达式。\n\n任务2：假设逐次试验的变异性源于许多独立微观来源的聚合，并且可以很好地由正态（高斯）分布 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ 建模。仅使用正态分布的基本定义和广泛接受的性质，推导由 $\\gamma_{2} = \\mu_{4} / \\mu_{2}^{2}$ 定义的峰度 $\\gamma_{2}$，并求得其在试验幅度的正态模型下的数值。\n\n提供您得到的 $\\mu_{3}$ 和 $\\mu_{4}$ 关于 $m_{k}$ 和 $\\mu$ 的闭式表达式，以及 $\\gamma_{2}$ 的数值作为最终答案。无需四舍五入。",
            "solution": "该问题被验证为具有科学依据、良定且客观。它基于概率论和统计学中的标准定义，并代表了神经科学数据分析中的一个常见应用。所有必要信息均已提供，并且任务可通过直接的数学推导解决。\n\n该问题包含两个任务。第一个任务是推导第三和第四中心矩 $\\mu_{3}$ 和 $\\mu_{4}$ 关于原点矩 $m_{k}$ 和均值 $\\mu$ 的表达式。第二个任务是计算正态分布的峰度 $\\gamma_{2}$。\n\n**任务1：从原点矩推导中心矩**\n\n提供的定义如下：\n- 均值：$\\mu = \\mathbb{E}[X] = m_{1}$\n- $k$ 阶原点矩：$m_{k} = \\mathbb{E}[X^{k}]$\n- $k$ 阶中心矩：$\\mu_{k} = \\mathbb{E}[(X - \\mu)^{k}]$\n\n首先，我们推导第三中心矩 $\\mu_{3}$ 的表达式。我们从其定义开始：\n$$\n\\mu_{3} = \\mathbb{E}[(X - \\mu)^{3}]\n$$\n使用二项式展开 $(a-b)^{3} = a^{3} - 3a^{2}b + 3ab^{2} - b^{3}$，其中 $a=X$ 且 $b=\\mu$，我们展开期望内的项：\n$$\n(X - \\mu)^{3} = X^{3} - 3X^{2}\\mu + 3X\\mu^{2} - \\mu^{3}\n$$\n根据期望算子的线性性质，我们有：\n$$\n\\mu_{3} = \\mathbb{E}[X^{3} - 3X^{2}\\mu + 3X\\mu^{2} - \\mu^{3}] = \\mathbb{E}[X^{3}] - \\mathbb{E}[3X^{2}\\mu] + \\mathbb{E}[3X\\mu^{2}] - \\mathbb{E}[\\mu^{3}]\n$$\n由于 $\\mu$ 是一个常数，它可以从期望中提出：\n$$\n\\mu_{3} = \\mathbb{E}[X^{3}] - 3\\mu\\mathbb{E}[X^{2}] + 3\\mu^{2}\\mathbb{E}[X] - \\mu^{3}\n$$\n现在，我们代入原点矩 ($m_{k} = \\mathbb{E}[X^{k}]$) 和均值 ($\\mu = \\mathbb{E}[X] = m_{1}$) 的定义：\n$$\n\\mu_{3} = m_{3} - 3\\mu m_{2} + 3\\mu^{2} m_{1} - \\mu^{3}\n$$\n由于题目说明 $\\mu=m_{1}$，我们可以用 $\\mu$ 代替 $m_{1}$：\n$$\n\\mu_{3} = m_{3} - 3\\mu m_{2} + 3\\mu^{2}(\\mu) - \\mu^{3}\n$$\n化简该表达式得到 $\\mu_{3}$ 的最终形式：\n$$\n\\mu_{3} = m_{3} - 3\\mu m_{2} + 2\\mu^{3}\n$$\n\n接下来，我们推导第四中心矩 $\\mu_{4}$ 的表达式。我们再次从其定义开始：\n$$\n\\mu_{4} = \\mathbb{E}[(X - \\mu)^{4}]\n$$\n使用二项式展开 $(a-b)^{4} = a^{4} - 4a^{3}b + 6a^{2}b^{2} - 4ab^{3} + b^{4}$，其中 $a=X$ 且 $b=\\mu$：\n$$\n(X - \\mu)^{4} = X^{4} - 4X^{3}\\mu + 6X^{2}\\mu^{2} - 4X\\mu^{3} + \\mu^{4}\n$$\n应用期望的线性性质：\n$$\n\\mu_{4} = \\mathbb{E}[X^{4}] - 4\\mu\\mathbb{E}[X^{3}] + 6\\mu^{2}\\mathbb{E}[X^{2}] - 4\\mu^{3}\\mathbb{E}[X] + \\mathbb{E}[\\mu^{4}]\n$$\n代入原点矩和均值的定义：\n$$\n\\mu_{4} = m_{4} - 4\\mu m_{3} + 6\\mu^{2} m_{2} - 4\\mu^{3} m_{1} + \\mu^{4}\n$$\n再次，我们用 $\\mu$ 代替 $m_{1}$：\n$$\n\\mu_{4} = m_{4} - 4\\mu m_{3} + 6\\mu^{2} m_{2} - 4\\mu^{3}(\\mu) + \\mu^{4}\n$$\n化简该表达式得到 $\\mu_{4}$ 的最终形式：\n$$\n\\mu_{4} = m_{4} - 4\\mu m_{3} + 6\\mu^{2} m_{2} - 3\\mu^{4}\n$$\n\n**任务2：正态分布的峰度**\n\n峰度定义为 $\\gamma_{2} = \\mu_{4} / \\mu_{2}^{2}$。给定随机变量 $X$ 服从正态（高斯）分布，$X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$。\n\n第二中心矩 $\\mu_{2}$ 是分布的方差。对于参数为 $\\mu$ 和 $\\sigma^{2}$ 的正态分布，根据定义，其方差为 $\\sigma^{2}$。\n$$\n\\mu_{2} = \\mathbb{E}[(X-\\mu)^{2}] = \\text{Var}(X) = \\sigma^{2}\n$$\n为了求出 $X \\sim \\mathcal{N}(\\mu, \\sigma^{2})$ 的第四中心矩 $\\mu_{4}$，使用标准正态变量 $Z = (X - \\mu) / \\sigma$（其中 $Z \\sim \\mathcal{N}(0, 1)$）会很方便。$X$ 的中心矩可以用 $Z$ 的矩来表示：\n$$\n\\mu_{k} = \\mathbb{E}[(X - \\mu)^{k}] = \\mathbb{E}[(\\sigma Z)^{k}] = \\sigma^{k} \\mathbb{E}[Z^{k}]\n$$\n对于 $\\mu_{4}$，这给出：\n$$\n\\mu_{4} = \\sigma^{4} \\mathbb{E}[Z^{4}]\n$$\n现在我们必须求标准正态分布的四阶矩 $\\mathbb{E}[Z^{4}]$。标准正态分布的一个广泛接受的性质（可通过对其概率密度函数 $\\phi(z) = (1/\\sqrt{2\\pi})\\exp(-z^{2}/2)$ 进行分部积分推导）是其偶数阶矩由 $\\mathbb{E}[Z^{2n}] = (2n-1)!! = (2n-1)(2n-3)\\cdots 1$ 给出。对于 $n=2$，这给出了四阶矩：\n$$\n\\mathbb{E}[Z^{4}] = (2 \\cdot 2 - 1)!! = 3!! = 3 \\cdot 1 = 3\n$$\n将此结果代回 $\\mu_{4}$ 的表达式中：\n$$\n\\mu_{4} = \\sigma^{4} \\cdot 3 = 3\\sigma^{4}\n$$\n现在我们有了计算峰度 $\\gamma_{2}$ 所需的所有分量：\n$$\n\\gamma_{2} = \\frac{\\mu_{4}}{\\mu_{2}^{2}} = \\frac{3\\sigma^{4}}{(\\sigma^{2})^{2}} = \\frac{3\\sigma^{4}}{\\sigma^{4}} = 3\n$$\n因此，任何正态分布的峰度都恰好是 $3$。\n\n最终结果是 $\\mu_{3}$ 和 $\\mu_{4}$ 的表达式，以及正态分布的 $\\gamma_{2}$ 的数值。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nm_3 - 3\\mu m_2 + 2\\mu^3 & m_4 - 4\\mu m_3 + 6\\mu^2 m_2 - 3\\mu^4 & 3\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "虽然高斯分布在理论上很方便，但神经科学中的许多真实数据，例如大量突触输入的总和，表现出“重尾”特性，这给分析带来了独特的挑战。本练习介绍了一个关键概念：对于某些分布（如 $\\alpha$-稳定分布），低阶矩（如均值）可能存在，而高阶矩（如方差）却可能发散至无穷大。通过这个练习，您将深入理解基于方差的传统统计方法（如计算标准差或执行主成分分析）在何种情况下会失效，以及为何必须谨慎选择分析工具。",
            "id": "4160959",
            "problem": "一个神经回路在短时间窗口内接收到许多独立突触输入的叠加，导致聚合的突触后电流波动。根据经验，这种波动是重尾的，并且在聚合下近似稳定。考虑使用尾部指数为 $\\alpha \\in (1,2)$ 的对称严格稳定律来为一个单窗口内的波动建模。为了构建一个具体且易于解析处理的例子，取 $\\alpha = \\tfrac{3}{2}$，并通过其特征函数定义一个随机变量 $X$\n$$\n\\varphi_{X}(t) \\equiv \\mathbb{E}[\\exp(i t X)] = \\exp\\!\\big(i \\mu t - \\sigma^{3/2} |t|^{3/2}\\big),\n$$\n其中 $\\sigma > 0$ 是一个尺度参数，$\\mu \\in \\mathbb{R}$ 是一个位置参数。这是一个对称 $\\alpha$-稳定模型，常用于捕捉重尾的突触波动。\n\n仅从期望和特征函数的定义出发，并利用关于稳定律渐近尾部行为的公认事实，完成以下任务：\n- 推导 $\\mathbb{E}[X]$，并说明该模型的 $\\mathbb{E}[X^{2}]$ 是否存在。通过基于特征函数和渐近尾部行为的明确推理来证明你的结论。\n- 简要解释你的结论对于基于方差的突触波动分析（例如，依赖于有限二阶矩的方法）有何影响。\n\n将你的最终答案表示为关于 $\\mu$ 的单一闭式解析表达式。无需四舍五入，最终答案中不报告物理单位。",
            "solution": "首先对问题陈述进行验证。\n\n### 第1步：提取已知条件\n- **模型：** 神经回路中的聚合突触后电流波动。\n- **分布：** 对称严格稳定律。\n- **尾部指数：** $\\alpha = \\frac{3}{2}$，一般情况为 $\\alpha \\in (1,2)$。\n- **随机变量：** $X$。\n- **特征函数：** $\\varphi_{X}(t) \\equiv \\mathbb{E}[\\exp(i t X)] = \\exp(i \\mu t - \\sigma^{3/2} |t|^{3/2})$。\n- **参数：** 尺度参数 $\\sigma > 0$，位置参数 $\\mu \\in \\mathbb{R}$。\n- **任务：**\n    1. 从期望和特征函数的定义出发，推导 $\\mathbb{E}[X]$。\n    2. 判断 $\\mathbb{E}[X^{2}]$ 是否存在。\n    3. 同时使用特征函数和稳定律的渐近尾部行为来证明结论。\n    4. 解释对基于方差的分析的影响。\n- **最终答案要求：** 一个关于 $\\mu$ 的单一闭式解析表达式。\n\n### 第2步：使用提取的已知条件进行验证\n- **科学依据：** 该问题在科学和数学上是合理的。稳定分布是概率论中为重尾现象建模的基石。给定的特征函数是带位置偏移的对称 $\\alpha$-稳定分布的标准形式。使用此类模型来描述突触电流波动是理论神经科学中一种公认的方法。值 $\\alpha = \\frac{3}{2}$ 是指定范围 $(1,2)$ 内的有效尾部指数。\n- **适定性：** 该问题是适定的。分布由其特征函数明确定义。任务是具体的，要求推导标准的统计特性（矩），这些特性可以从所提供的信息中唯一确定。\n- **客观性：** 语言正式、精确，不含主观或基于观点的陈述。\n\n### 第3步：结论与行动\n问题被判定为**有效**。这是研究生水平的概率论或统计物理课程中的一个标准练习，并恰当地置于神经科学的背景下。现在开始求解过程。\n\n### $\\mathbb{E}[X]$ 的推导与 $\\mathbb{E}[X^{2}]$ 的分析\n\n将随机变量 $X$ 的特征函数 $\\varphi_X(t)$ 与其矩联系起来的一个基本性质是，只要 $n$ 阶导数存在，$n$ 阶矩 $\\mathbb{E}[X^n]$ 就可以通过 $\\varphi_X(t)$ 在 $t=0$ 处的 $n$ 阶导数计算得出：\n$$\n\\mathbb{E}[X^n] = i^{-n} \\frac{d^n \\varphi_X(t)}{dt^n} \\bigg|_{t=0}\n$$\n$\\varphi_X(t)$ 在 $t=0$ 处的 $n$ 阶导数的存在是 $n$ 阶矩 $\\mathbb{E}[X^n]$ 存在的充分必要条件。\n\n**1. 一阶矩 $\\mathbb{E}[X]$ 的计算**\n\n我们计算给定特征函数 $\\varphi_{X}(t) = \\exp(i \\mu t - \\sigma^{3/2} |t|^{3/2})$ 的一阶导数。\n使用链式法则，对于 $t \\neq 0$：\n$$\n\\frac{d\\varphi_X(t)}{dt} = \\varphi_X(t) \\cdot \\frac{d}{dt} \\left( i \\mu t - \\sigma^{3/2} |t|^{3/2} \\right)\n$$\n$|t|^{3/2}$ 这一项的导数必须小心处理。对于 $t \\neq 0$，其导数为 $\\frac{3}{2}|t|^{1/2} \\text{sgn}(t)$，其中 $\\text{sgn}(t)$ 是符号函数。\n因此，对于 $t \\neq 0$：\n$$\n\\frac{d\\varphi_X(t)}{dt} = \\exp(i \\mu t - \\sigma^{3/2} |t|^{3/2}) \\cdot \\left( i \\mu - \\sigma^{3/2} \\frac{3}{2} |t|^{1/2} \\text{sgn}(t) \\right)\n$$\n为了求出在 $t=0$ 处的导数，我们必须考察当 $t \\to 0$ 时该表达式的极限。\n$$\n\\lim_{t \\to 0} \\frac{d\\varphi_X(t)}{dt} = \\lim_{t \\to 0} \\left[ \\exp(i \\mu t - \\sigma^{3/2} |t|^{3/2}) \\cdot \\left( i \\mu - \\sigma^{3/2} \\frac{3}{2} |t|^{1/2} \\text{sgn}(t) \\right) \\right]\n$$\n当 $t \\to 0$ 时，第一项 $\\exp(i \\mu t - \\sigma^{3/2} |t|^{3/2}) \\to \\exp(0) = 1$。第二项的行为由 $|t|^{1/2}$ 决定，它趋近于 $0$。\n所以，极限为：\n$$\n\\lim_{t \\to 0} \\frac{d\\varphi_X(t)}{dt} = 1 \\cdot (i \\mu - 0) = i \\mu\n$$\n由于极限存在，$\\varphi_X(t)$ 在 $t=0$ 处的一阶导数是良定义的，且等于 $i\\mu$。因此，一阶矩存在。\n$$\n\\mathbb{E}[X] = i^{-1} \\frac{d\\varphi_X(t)}{dt} \\bigg|_{t=0} = i^{-1} (i\\mu) = \\mu\n$$\n随机变量 $X$ 的期望等于位置参数 $\\mu$。\n\n**2. 二阶矩 $\\mathbb{E}[X^2]$ 的存在性**\n\n我们现在必须评估 $\\varphi_X(t)$ 在 $t=0$ 处的二阶导数是否存在。我们使用乘法法则对 $\\frac{d\\varphi_X(t)}{dt}$ 的表达式求导：\n$$\n\\frac{d^2\\varphi_X(t)}{dt^2} = \\frac{d}{dt} \\left[ \\varphi_X(t) \\cdot \\left( i \\mu - \\frac{3\\sigma^{3/2}}{2} |t|^{1/2} \\text{sgn}(t) \\right) \\right]\n$$\n$$\n\\frac{d^2\\varphi_X(t)}{dt^2} = \\frac{d\\varphi_X(t)}{dt} \\left( i \\mu - \\frac{3\\sigma^{3/2}}{2} |t|^{1/2} \\text{sgn}(t) \\right) + \\varphi_X(t) \\frac{d}{dt} \\left( i \\mu - \\frac{3\\sigma^{3/2}}{2} |t|^{1/2} \\text{sgn}(t) \\right)\n$$\n让我们分析当 $t \\to 0$ 时第二项的行为。我们需要求 $|t|^{1/2} \\text{sgn}(t)$ 的导数。当 $t > 0$ 时，该函数等价于 $t^{1/2}$；当 $t < 0$ 时，等价于 $-(-t)^{1/2}$。\n对于 $t > 0$，导数是 $\\frac{1}{2} t^{-1/2}$。\n对于 $t < 0$，导数是 $-\\frac{1}{2}(-t)^{-1/2}(-1) = \\frac{1}{2}(-t)^{-1/2}$。\n在两种情况下，对于 $t \\neq 0$，导数都是 $\\frac{1}{2}|t|^{-1/2}$。\n因此，乘积第二部分的导数是：\n$$\n\\frac{d}{dt} \\left( i \\mu - \\frac{3\\sigma^{3/2}}{2} |t|^{1/2} \\text{sgn}(t) \\right) = - \\frac{3\\sigma^{3/2}}{2} \\frac{1}{2}|t|^{-1/2} = - \\frac{3\\sigma^{3/2}}{4|t|^{1/2}}\n$$\n当 $t \\to 0$ 时，该项发散到 $-\\infty$。因为二阶导数表达式中的一项在 $t=0$ 处发散，所以二阶导数 $\\frac{d^2\\varphi_X(t)}{dt^2}$ 在 $t=0$ 处不存在。因此，二阶矩 $\\mathbb{E}[X^2]$ 不存在有限值。\n\n**3. 基于渐近尾部行为的证明**\n\n问题陈述 $X$ 服从尾部指数为 $\\alpha = \\frac{3}{2}$ 的对称稳定律。对于此类分布，一个公认的事实是其概率密度函数 $p(x)$ 具有渐近幂律尾：\n$$\np(x) \\sim c|x|^{-(\\alpha+1)} \\quad \\text{as } |x| \\to \\infty,\n$$\n其中 $c$ 为某个正常数。这里，当 $\\alpha = \\frac{3}{2}$ 时，我们有 $p(x) \\sim c|x|^{-5/2}$。\n\n$k$ 阶绝对矩 $\\mathbb{E}[|X|^k]$ 是有限的，当且仅当积分 $\\int_{-\\infty}^\\infty |x|^k p(x) dx$ 收敛。由于对称性，这等价于 $2\\int_0^\\infty x^k p(x) dx$ 的收敛。\n对于大的 $x$，被积函数的行为如同 $x^k \\cdot c x^{-(\\alpha+1)} = c x^{k-\\alpha-1}$。\n积分收敛当且仅当指数小于 $-1$，即 $k-\\alpha-1 < -1$，可简化为 $k < \\alpha$。\n\n让我们将这个条件应用于 $\\alpha = \\frac{3}{2}$ 的具体情况：\n- 对于一阶矩，$k=1$。条件是 $1 < \\frac{3}{2}$，这是成立的。因此，$\\mathbb{E}[|X|]$ 是有限的，这意味着 $\\mathbb{E}[X]$ 也是有限且良定义的。这证实了我们之前的结果。\n- 对于二阶矩，$k=2$。条件是 $2 < \\frac{3}{2}$，这是不成立的。由于条件不满足，$\\mathbb{E}[|X|^2]$ 的积分发散。这意味着 $\\mathbb{E}[|X|^2] = \\infty$，因此二阶矩 $\\mathbb{E}[X^2]$ 不存在（是无限的）。这独立地证实了从特征函数分析得出的结论。\n\n**4. 对基于方差的分析的影响**\n\n随机变量的方差定义为 $\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$。我们已经确定 $\\mathbb{E}[X] = \\mu$ 是有限的，但 $\\mathbb{E}[X^2]$ 是无限的。因此，在此模型下，突触电流波动的方差是无限的。\n\n这对数据分析具有深远的影响。许多标准的统计方法都基本以有限二阶矩（因此是有限方差）的存在为前提。例子包括：\n- **样本方差和标准差：** 随着收集更多数据，这些统计量不会收敛到一个稳定的值。相反，它们会随着样本量的增加而增长，并且其值对极端事件（即“重尾”）高度敏感。\n- **最小二乘优化：** 像线性回归这样最小化平方误差的方法，在有限方差的假设下（例如，高斯-马尔可夫定理）是最优的。对于重尾数据，它们的估计值可能会被异常值严重影响。\n- **主成分分析（PCA）：** 该方法基于协方差矩阵，其对角线元素为方差。如果方差是无限的，协方差矩阵就无定义，PCA 也不适用。\n- **信噪比（SNR）：** 当用信号和噪声功率（方差）来定义时，该度量变得无定义。\n\n总之，对于可以被这种重尾稳定模型准确描述的突触波动，任何依赖于有限方差的分析流程在数学上都是不合理的，并且会产生不稳定、不可靠且可能具有误导性的结果。分析必须转而使用适合重尾分布的工具。离散程度应通过替代度量来表征，例如稳定分布的尺度参数 $\\sigma$ 或像四分位距这样的稳健统计量。",
            "answer": "$$\n\\boxed{\\mu}\n$$"
        },
        {
            "introduction": "在理论神经科学中，许多描述神经元活动的真实模型，例如将非线性函数应用于高斯变化的膜电位，其期望值无法通过解析方法求得。此时，我们必须回归期望的积分定义，并采用数值方法进行计算。本练习将指导您使用高斯-埃尔米特求积法，这是一种处理涉及高斯权重函数的积分的强大技术，来解决一个典型的神经元输入-输出转换问题。这项实践将理论与计算紧密结合，让您掌握在实际建模中估算复杂期望值的关键技能。",
            "id": "4160986",
            "problem": "考虑一个神经元输入-输出转换模型，其中膜电位 $V$ 是一个服从高斯分布 $V \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 的随机变量，瞬时输出是一个有界非线性函数 $f(\\beta V) = \\tanh(\\beta V)$，其中 $\\beta$ 是控制灵敏度的增益参数。目标是计算期望 $E[\\tanh(\\beta V)]$ 并分析其对增益参数 $\\beta$ 的灵敏度。\n\n从连续随机变量的期望的基本定义和正态分布的概率密度函数 (PDF) 出发，可测函数 $g(V)$ 的期望定义为\n$$\nE[g(V)] = \\int_{-\\infty}^{\\infty} g(v)\\, \\phi(v; \\mu, \\sigma^2)\\, dv,\n$$\n其中\n$$\n\\phi(v; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma} \\exp\\left(-\\frac{(v - \\mu)^2}{2\\sigma^2}\\right)\n$$\n是正态分布的PDF。在本问题中，$g(v) = \\tanh(\\beta v)$。您必须使用数值积分方法计算 $E[\\tanh(\\beta V)]$，该方法基于变量替换，将积分简化为带权重 $e^{-x^2}$ 的形式，从而允许使用高斯-埃尔米特求积进行近似。请勿使用任何闭式解捷径；需从上述核心定义出发，推导并实现求积方法。\n\n此外，将 $E[\\tanh(\\beta V)]$ 对 $\\beta$ 的局部灵敏度定义为导数\n$$\nS(\\beta) = \\frac{d}{d\\beta} E[\\tanh(\\beta V)],\n$$\n并通过在积分号下求导，使用相同的求积框架来计算它。通过独立的有限差分近似来验证此导数\n$$\nS_{\\text{fd}}(\\beta) = \\frac{E[\\tanh((\\beta + \\Delta) V)] - E[\\tanh((\\beta - \\Delta) V)]}{2\\Delta},\n$$\n其中 $\\Delta$ 是一个您必须选择的小步长，以平衡截断误差和舍入误差。同时报告绝对差异\n$$\n\\varepsilon = \\left| S(\\beta) - S_{\\text{fd}}(\\beta) \\right|.\n$$\n\n此处所有量均为无量纲。您的实现必须在宽泛的参数范围内保持数值稳定。对所有情况使用固定的求积阶数，并根据被积函数和正态权重的性质证明其合理性。\n\n测试套件：\n为以下每个参数集 $(\\mu, \\sigma, \\beta)$ 计算结果元组 $\\left[E[\\tanh(\\beta V)],\\, S(\\beta),\\, S_{\\text{fd}}(\\beta),\\, \\varepsilon\\right]$：\n1. $(\\mu, \\sigma, \\beta) = (0.5, 1.0, 1.2)$\n2. $(\\mu, \\sigma, \\beta) = (0.0, 1.0, 10.0)$\n3. $(\\mu, \\sigma, \\beta) = (3.0, 0.5, 2.0)$\n4. $(\\mu, \\sigma, \\beta) = (-1.0, 0.2, 5.0)$\n5. $(\\mu, \\sigma, \\beta) = (1.234, 10^{-6}, 0.75)$\n6. $(\\mu, \\sigma, \\beta) = (2.0, 1.5, 0.0)$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素本身是针对一个测试用例的四个浮点值的逗号分隔列表，顺序如上所述。例如，输出格式必须为\n$$\n[\\,[E_1, S_1, S_{\\text{fd},1}, \\varepsilon_1],\\, [E_2, S_2, S_{\\text{fd},2}, \\varepsilon_2],\\, \\dots\\, ].\n$$\n除了构成有效 Python 列表字面量所需的内容外，不应打印任何额外的文本或空白字符。",
            "solution": "该问题要求数值计算期望 $E[\\tanh(\\beta V)]$ 及其灵敏度 $S(\\beta) = \\frac{d}{d\\beta}E[\\tanh(\\beta V)]$，其中膜电位 $V$ 是一个服从高斯分布的随机变量，$V \\sim \\mathcal{N}(\\mu, \\sigma^2)$。任务的核心是基于高斯-埃尔米特求积推导并实现一个解决方案。\n\n对于具有概率密度函数 (PDF) $\\phi(v)$ 的连续随机变量 $V$，其函数 $g(V)$ 的期望由下式给出：\n$$ E[g(V)] = \\int_{-\\infty}^{\\infty} g(v) \\phi(v; \\mu, \\sigma^2) dv $$\n对于本问题，$g(v) = \\tanh(\\beta v)$ 且 $\\phi(v; \\mu, \\sigma^2)$ 是高斯PDF：\n$$ \\phi(v; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(v - \\mu)^2}{2\\sigma^2}\\right) $$\n因此，期望积分为：\n$$ E[\\tanh(\\beta V)] = \\int_{-\\infty}^{\\infty} \\tanh(\\beta v) \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(v - \\mu)^2}{2\\sigma^2}\\right) dv $$\n\n为了利用高斯-埃尔米特求积（该方法专为形如 $\\int_{-\\infty}^{\\infty} h(x)e^{-x^2}dx$ 的积分而设计），我们必须进行变量替换。我们将指数函数的参数设为 $-x^2$：\n$$ x^2 = \\frac{(v - \\mu)^2}{2\\sigma^2} \\implies x = \\frac{v - \\mu}{\\sqrt{2}\\sigma} $$\n这给出了 $v$ 及其微分 $dv$ 的以下变换：\n$$ v = \\mu + \\sqrt{2}\\sigma x $$\n$$ dv = \\sqrt{2}\\sigma dx $$\n将这些代入期望积分，得到：\n$$ E[\\tanh(\\beta V)] = \\int_{-\\infty}^{\\infty} \\tanh(\\beta (\\mu + \\sqrt{2}\\sigma x)) \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-x^2} (\\sqrt{2}\\sigma dx) $$\n化简该表达式，我们发现：\n$$ E[\\tanh(\\beta V)] = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} \\tanh(\\beta(\\mu + \\sqrt{2}\\sigma x)) e^{-x^2} dx $$\n现在这个积分的形式适合使用高斯-埃尔米特求积。该求积法则将积分近似为一个加权和：\n$$ \\int_{-\\infty}^{\\infty} f(x) e^{-x^2} dx \\approx \\sum_{i=1}^n w_i f(x_i) $$\n其中 $x_i$ 是 $n$ 次物理学家埃尔米特多项式的根（节点），$w_i$ 是相应的权重。将此规则应用于我们的期望，其中 $f(x) = \\frac{1}{\\sqrt{\\pi}} \\tanh(\\beta(\\mu + \\sqrt{2}\\sigma x))$，我们得到数值近似：\n$$ E[\\tanh(\\beta V)] \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{n} w_i \\tanh(\\beta(\\mu + \\sqrt{2}\\sigma x_i)) $$\n\n接下来，我们计算灵敏度 $S(\\beta) = \\frac{d}{d\\beta} E[\\tanh(\\beta V)]$。我们可以应用莱布尼茨积分法则（在积分号下求导），因为被积函数及其关于 $\\beta$ 的偏导数是连续的，并且积分一致收敛。\n$$ S(\\beta) = \\frac{d}{d\\beta} \\int_{-\\infty}^{\\infty} \\tanh(\\beta v) \\phi(v) dv = \\int_{-\\infty}^{\\infty} \\frac{\\partial}{\\partial\\beta} \\left[ \\tanh(\\beta v) \\right] \\phi(v) dv $$\n偏导数为 $\\frac{\\partial}{\\partial\\beta} \\tanh(\\beta v) = v \\cdot \\text{sech}^2(\\beta v)$，其中 $\\text{sech}(z) = 1/\\cosh(z)$。这可以得到：\n$$ S(\\beta) = \\int_{-\\infty}^{\\infty} v \\, \\text{sech}^2(\\beta v) \\, \\phi(v) dv = E[V \\, \\text{sech}^2(\\beta V)] $$\n我们可以使用相同的求积框架来计算这个新的期望。现在要积分的函数是 $g_S(v) = v \\, \\text{sech}^2(\\beta v)$。应用相同的变量替换 $v = \\mu + \\sqrt{2}\\sigma x$：\n$$ S(\\beta) \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{n} w_i \\left[ (\\mu + \\sqrt{2}\\sigma x_i) \\, \\text{sech}^2(\\beta(\\mu + \\sqrt{2}\\sigma x_i)) \\right] $$\n对于 $\\beta = 0$ 的特殊情况，表达式得到简化。$E[\\tanh(0 \\cdot V)] = E[0] = 0$。灵敏度变为 $S(0) = E[V \\cdot \\text{sech}^2(0)] = E[V \\cdot 1] = E[V] = \\mu$。这些解析结果为数值实现提供了有价值的检验。\n\n数值实现采用了以下设计选择：\n1.  **求积阶数**：为高斯-埃尔米特求积选择了一个固定的阶数 $n=64$。被积函数是无穷可微（$C^\\infty$）的函数。对于此类光滑函数，高斯求积表现出指数收敛性。$n=64$ 的高阶可以确保在所有给定的测试用例中都具有高精度，包括那些参数（如大的 $\\beta$）导致被积函数更陡峭的情况，而不会产生过高的计算成本。求积节点 $x_i$ 和权重 $w_i$ 使用 `scipy.special.roots_hermite` 预先计算。\n2.  **有限差分验证**：解析导数 $S(\\beta)$ 通过中心有限差分近似进行验证：\n    $$ S_{\\text{fd}}(\\beta) = \\frac{E[\\tanh((\\beta + \\Delta) V)] - E[\\tanh((\\beta - \\Delta) V)]}{2\\Delta} $$\n    步长选择为 $\\Delta = 10^{-6}$。对于双精度浮点运算，这个值足够小，可以最小化阶为 $\\mathcal{O}(\\Delta^2)$ 的截断误差，同时又足够大，可以避免由灾难性抵消引起的、量级为 $\\mathcal{O}(\\epsilon_{machine}/\\Delta)$ 的显著舍入误差。\n3.  **数值稳定性**：项 $\\text{sech}^2(z) = 1/\\cosh^2(z)$ 被直接实现。对于大的参数 $z$，$\\cosh(z)$ 可能会溢出。然而，`numpy.cosh` 对于大的输入能正确地计算为无穷大（`inf`），而 $1/\\text{inf}^2$ 能正确地计算为 $0.0$，这确保了计算的数值稳定性，而无需为尾部情况设计特殊的处理逻辑。\n\n每个参数集 $(\\mu, \\sigma, \\beta)$ 要计算的最终结果元组是 $[E[\\tanh(\\beta V)], S(\\beta), S_{\\text{fd}}(\\beta), \\varepsilon]$，其中 $\\varepsilon = |S(\\beta) - S_{\\text{fd}}(\\beta)|$ 是解析导数与其有限差分近似之间的绝对差异。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_hermite\n\ndef solve():\n    \"\"\"\n    Computes expectation and sensitivity of a transformed Gaussian random variable.\n    \"\"\"\n    # Define the test suite of parameters (mu, sigma, beta).\n    test_cases = [\n        (0.5, 1.0, 1.2),\n        (0.0, 1.0, 10.0),\n        (3.0, 0.5, 2.0),\n        (-1.0, 0.2, 5.0),\n        (1.234, 1e-6, 0.75),\n        (2.0, 1.5, 0.0),\n    ]\n\n    # Set numerical parameters for the computation.\n    # A high quadrature order is chosen for accuracy with smooth integrands.\n    QUADRATURE_ORDER = 64\n    # Delta for finite difference is chosen to balance truncation and round-off error.\n    DELTA = 1e-6\n\n    # Pre-compute Gaussian-Hermite quadrature nodes and weights for efficiency.\n    x_nodes, w_nodes = roots_hermite(QUADRATURE_ORDER)\n    SQRT_PI = np.sqrt(np.pi)\n    SQRT_2 = np.sqrt(2.0)\n\n    def calculate_expectation(func_of_v, mu, sigma):\n        \"\"\"\n        Computes E[func_of_v(V)] for V ~ N(mu, sigma^2) using Gauss-Hermite quadrature.\n        \"\"\"\n        # Change of variables: v = mu + sqrt(2)*sigma*x\n        v_vals = mu + SQRT_2 * sigma * x_nodes\n        integrand_vals = func_of_v(v_vals)\n        \n        # Apply quadrature rule: sum(w_i * f(x_i))\n        integral_approx = np.sum(w_nodes * integrand_vals)\n        \n        # Final expectation includes the 1/sqrt(pi) prefactor from the derivation.\n        return integral_approx / SQRT_PI\n\n    results = []\n    for mu, sigma, beta in test_cases:\n        # 1. Compute E[tanh(beta*V)]\n        if beta == 0.0:\n            E_val = 0.0\n        else:\n            f_tanh = lambda v: np.tanh(beta * v)\n            E_val = calculate_expectation(f_tanh, mu, sigma)\n\n        # 2. Compute S(beta) = E[V * sech^2(beta*V)]\n        if beta == 0.0:\n            # Analytical result: S(0) = E[V] = mu\n            S_val = mu\n        else:\n            f_sensitivity = lambda v: v / np.cosh(beta * v)**2\n            S_val = calculate_expectation(f_sensitivity, mu, sigma)\n\n        # 3. Compute S_fd(beta) using central finite difference\n        beta_plus = beta + DELTA\n        f_tanh_plus = lambda v: np.tanh(beta_plus * v)\n        E_plus = calculate_expectation(f_tanh_plus, mu, sigma)\n        \n        beta_minus = beta - DELTA\n        f_tanh_minus = lambda v: np.tanh(beta_minus * v)\n        E_minus = calculate_expectation(f_tanh_minus, mu, sigma)\n        \n        S_fd_val = (E_plus - E_minus) / (2 * DELTA)\n        \n        # 4. Compute absolute discrepancy epsilon\n        eps_val = np.abs(S_val - S_fd_val)\n\n        results.append([E_val, S_val, S_fd_val, eps_val])\n\n    # Format the output as a string representing a list of lists with no spaces.\n    outer_parts = []\n    for res in results:\n        inner_parts = [repr(val) for val in res]\n        outer_parts.append(f\"[{','.join(inner_parts)}]\")\n    \n    print(f\"[{','.join(outer_parts)}]\")\n\nsolve()\n```"
        }
    ]
}