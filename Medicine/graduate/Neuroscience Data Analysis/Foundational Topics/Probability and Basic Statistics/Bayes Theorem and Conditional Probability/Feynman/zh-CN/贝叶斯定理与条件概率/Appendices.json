{
    "hands_on_practices": [
        {
            "introduction": "在神经科学数据分析中，一个核心任务是根据观测到的神经元发放脉冲数来估计其潜在的发放率。本练习  为这一任务提供了贝叶斯推断的分析基础。你将通过为泊松（Poisson）似然选择一个共轭的伽马（Gamma）先验分布，从零开始推导出发放率的后验分布，这个过程将清晰地展示贝叶斯定理如何利用数据来更新我们对参数的认知。",
            "id": "4140543",
            "problem": "在一个稳定的行为时期，对单个孤立的神经元进行持续时间为 $\\,\\tau>0\\,$ 秒的细胞外记录。令 $\\,K\\,$ 表示在此窗口中观察到的脉冲计数，其模型为在未知放电率 $\\,\\lambda>0\\,$（单位：脉冲/秒）的条件下服从条件泊松分布，即 $\\,K \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda \\tau)\\,$。为了根据先前的记录捕捉关于 $\\,\\lambda\\,$ 的先验不确定性，假设其服从形状参数为 $\\,a>0\\,$、速率参数为 $\\,b>0\\,$ 的伽马先验分布，其先验密度为 $\\,p(\\lambda) = \\frac{b^{a}}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b \\lambda)\\,$，其中 $\\,\\lambda>0\\,$。使用贝叶斯定理和条件概率的核心定义，推导后验密度 $\\,p(\\lambda \\mid K=k)\\,$，它是一个关于 $\\,\\lambda\\,$ 的归一化函数，其中观测值 $\\,k \\in \\{0,1,2,\\dots\\}\\,$ 和参数 $\\,\\tau,a,b>0\\,$ 均为固定值。通过在 $\\,\\lambda \\in (0,\\infty)\\,$ 上积分来显式计算归一化常数，并验证后验分布的积分为 $\\,1\\,$。将你的最终结果表示为关于 $\\,a,b,\\tau,k,\\lambda\\,$ 的 $\\,p(\\lambda \\mid K=k)\\,$ 的单一闭式解析表达式。不需要数值近似，也不需要四舍五入。给出答案时无需单位。",
            "solution": "经过全面评估，所提供的问题被认为是有效的。它具有科学依据，问题定义明确，客观，并包含足够的信息以获得唯一且有意义的解。该问题要求使用贝叶斯定理推导后验概率密度函数，这是贝叶斯统计学及其在神经科学数据分析中应用的标准流程。\n\n目标是推导放电率 $\\lambda$ 的后验密度 $p(\\lambda \\mid K=k)$。根据贝叶斯定理，后验密度与给定参数下数据的似然函数和参数的先验密度的乘积成正比。\n$$p(\\lambda \\mid K=k) = \\frac{p(K=k \\mid \\lambda) p(\\lambda)}{\\int_{0}^{\\infty} p(K=k \\mid \\lambda) p(\\lambda) d\\lambda}$$\n\n首先，我们确定分子的两个组成部分：似然函数 $p(K=k \\mid \\lambda)$ 和先验密度 $p(\\lambda)$。\n\n似然函数由泊松分布给出。问题指出，在持续时间为 $\\tau$ 的时间窗口内的脉冲计数 $K$ 被建模为 $K \\mid \\lambda \\sim \\mathrm{Poisson}(\\lambda \\tau)$。对于一个观测到的计数 $K=k$，其中 $k \\in \\{0, 1, 2, \\dots\\}$，其概率质量函数在 $k$ 固定时可视为 $\\lambda$ 的函数，即似然函数 $L(\\lambda; k)$：\n$$L(\\lambda; k) = p(K=k \\mid \\lambda) = \\frac{(\\lambda\\tau)^k \\exp(-\\lambda\\tau)}{k!}$$\n这在 $\\lambda > 0$ 时有效。\n\n放电率 $\\lambda$ 的先验分布被给定为形状参数为 $a>0$、速率参数为 $b>0$ 的伽马分布。其概率密度函数为：\n$$p(\\lambda) = \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda)$$\n这在 $\\lambda > 0$ 时有效。\n\n接下来，我们通过将似然函数与先验密度相乘来构建未归一化的后验密度：\n$$p(\\lambda \\mid K=k) \\propto p(K=k \\mid \\lambda) p(\\lambda)$$\n$$p(\\lambda \\mid K=k) \\propto \\left( \\frac{(\\lambda\\tau)^k \\exp(-\\lambda\\tau)}{k!} \\right) \\left( \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda) \\right)$$\n我们可以将依赖于 $\\lambda$ 的项和相对于 $\\lambda$ 为常数的项分组。项 $1/k!$、$\\tau^k$、 $b^a$ 和 $1/\\Gamma(a)$ 都是相对于 $\\lambda$ 的常数，可以被吸收到比例常数中。\n$$p(\\lambda \\mid K=k) \\propto (\\lambda^k \\exp(-\\lambda\\tau)) (\\lambda^{a-1} \\exp(-b\\lambda))$$\n合并含 $\\lambda$ 的项：\n$$p(\\lambda \\mid K=k) \\propto \\lambda^{k+a-1} \\exp(-\\lambda\\tau - b\\lambda)$$\n$$p(\\lambda \\mid K=k) \\propto \\lambda^{(a+k)-1} \\exp(-(b+\\tau)\\lambda)$$\n这个表达式是 $\\lambda$ 的一个概率分布的核。我们识别出这是伽马分布的核，形式为 $\\lambda^{\\text{形状}-1} \\exp(-\\text{速率} \\cdot \\lambda)$。通过比较各项，我们可以确定后验分布的参数。后验分布是一个伽马分布，其更新后的形状参数为 $a' = a+k$，更新后的速率参数为 $b' = b+\\tau$。\n\n令该后验分布表示为 $\\mathrm{Gamma}(a', b')$。伽马分布的归一化概率密度函数由 $p(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} \\exp(-\\beta x)$ 给出。代入我们的后验参数 $a'$ 和 $b'$，我们得到 $\\lambda$ 的归一化后验密度：\n$$p(\\lambda \\mid K=k) = \\frac{(b+\\tau)^{a+k}}{\\Gamma(a+k)} \\lambda^{a+k-1} \\exp(-(b+\\tau)\\lambda)$$\n\n问题要求我们显式地计算归一化常数。归一化常数是未归一化的后验密度在 $\\lambda$ 的定义域 $(0, \\infty)$ 上的积分。令此常数为 $C$。\n$$C = \\int_{0}^{\\infty} p(K=k \\mid \\lambda) p(\\lambda) d\\lambda$$\n$$C = \\int_{0}^{\\infty} \\left( \\frac{(\\lambda\\tau)^k \\exp(-\\lambda\\tau)}{k!} \\right) \\left( \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda) \\right) d\\lambda$$\n我们可以提出所有不含 $\\lambda$ 的因子：\n$$C = \\frac{\\tau^k b^a}{k! \\Gamma(a)} \\int_{0}^{\\infty} \\lambda^k \\exp(-\\lambda\\tau) \\lambda^{a-1} \\exp(-b\\lambda) d\\lambda$$\n合并积分内的项：\n$$C = \\frac{\\tau^k b^a}{k! \\Gamma(a)} \\int_{0}^{\\infty} \\lambda^{a+k-1} \\exp(-(b+\\tau)\\lambda) d\\lambda$$\n该积分具有伽马函数的形式。积分部分可以使用伽马函数的定义 $\\Gamma(z) = \\int_0^\\infty t^{z-1} e^{-t} dt$ 来求解。我们可以使用换元法，令 $u = (b+\\tau)\\lambda$，这意味着 $d\\lambda = du/(b+\\tau)$ 且 $\\lambda = u/(b+\\tau)$。\n$$\\int_{0}^{\\infty} \\lambda^{a+k-1} \\exp(-(b+\\tau)\\lambda) d\\lambda = \\int_{0}^{\\infty} \\left(\\frac{u}{b+\\tau}\\right)^{a+k-1} \\exp(-u) \\frac{du}{b+\\tau}$$\n$$= \\frac{1}{(b+\\tau)^{a+k}} \\int_{0}^{\\infty} u^{a+k-1} \\exp(-u) du = \\frac{\\Gamma(a+k)}{(b+\\tau)^{a+k}}$$\n将此结果代回 $C$ 的表达式中：\n$$C = \\frac{\\tau^k b^a}{k! \\Gamma(a)} \\frac{\\Gamma(a+k)}{(b+\\tau)^{a+k}}$$\n这个常数 $C$ 是边际似然 $p(K=k)$。因此，后验密度为 $p(\\lambda \\mid K=k) = \\frac{p(K=k \\mid \\lambda)p(\\lambda)}{C}$。\n$$p(\\lambda \\mid K=k) = \\frac{\\frac{(\\lambda\\tau)^k \\exp(-\\lambda\\tau)}{k!} \\frac{b^a}{\\Gamma(a)} \\lambda^{a-1} \\exp(-b\\lambda)}{\\frac{\\tau^k b^a \\Gamma(a+k)}{k! \\Gamma(a) (b+\\tau)^{a+k}}} = \\frac{(\\lambda\\tau)^k \\exp(-\\lambda\\tau) b^a \\lambda^{a-1} \\exp(-b\\lambda) k! \\Gamma(a) (b+\\tau)^{a+k}}{k! \\Gamma(a) \\tau^k b^a \\Gamma(a+k)}$$\n$$p(\\lambda \\mid K=k) = \\frac{\\lambda^{a+k-1} \\exp(-\\lambda(b+\\tau)) (b+\\tau)^{a+k}}{\\Gamma(a+k)}$$\n这与通过识别后验核推导出的表达式相匹配。\n\n最后，我们验证该后验密度的积分为 $1$。\n$$\\int_{0}^{\\infty} p(\\lambda \\mid K=k) d\\lambda = \\int_{0}^{\\infty} \\frac{(b+\\tau)^{a+k}}{\\Gamma(a+k)} \\lambda^{a+k-1} \\exp(-(b+\\tau)\\lambda) d\\lambda$$\n$$= \\frac{(b+\\tau)^{a+k}}{\\Gamma(a+k)} \\int_{0}^{\\infty} \\lambda^{a+k-1} \\exp(-(b+\\tau)\\lambda) d\\lambda$$\n使用我们之前的积分计算结果：\n$$= \\frac{(b+\\tau)^{a+k}}{\\Gamma(a+k)} \\left( \\frac{\\Gamma(a+k)}{(b+\\tau)^{a+k}} \\right) = 1$$\n验证成功。该后验是一个有效的概率密度。\n\n因此，后验密度 $p(\\lambda \\mid K=k)$ 的最终闭式解析表达式是形状参数为 $a+k$、速率参数为 $b+\\tau$ 的伽马分布的概率密度函数。",
            "answer": "$$\\boxed{\\frac{(b+\\tau)^{a+k}}{\\Gamma(a+k)} \\lambda^{a+k-1} \\exp\\left(-(b+\\tau)\\lambda\\right)}$$"
        },
        {
            "introduction": "当我们从分析单个神经元转向解码多个神经元的联合活动时，一个常见且强大的简化是假设它们在给定刺激下是条件独立的。本练习  构建了一个精妙的反例，旨在揭示“朴素贝叶斯”分类器中这一核心假设的潜在风险，并强调了神经元之间的相关性在解码中的关键作用。这个思想实验将让你深刻理解，检验模型假设与掌握模型机理同等重要。",
            "id": "4140527",
            "problem": "一个系统神经科学实验室记录了在呈现两种分别表示为 $S_1$ 和 $S_2$ 的刺激时，两个同时活动的皮层神经元的活动。在每次试验中，对于一个固定的 $10$ 毫秒窗口，尖峰响应被二值化为 $X_1 \\in \\{0,1\\}$ 和 $X_2 \\in \\{0,1\\}$，其中 $1$ 表示窗口内至少有一次尖峰放电。假设类别先验相等 $P(S_1)=P(S_2)$。\n\n该实验室报告称，对于两种刺激，每个神经元的边缘放电概率是相同的：$P(X_1=1 \\mid S_1)=P(X_1=1 \\mid S_2)=\\tfrac{1}{2}$ 并且 $P(X_2=1 \\mid S_1)=P(X_2=1 \\mid S_2)=\\tfrac{1}{2}$。然而，联合活动是依赖于刺激的，并表现出不同的相关性：对于 $S_1$，$P(X_1=1,X_2=1 \\mid S_1)=0.4$，而对于 $S_2$，$P(X_1=1,X_2=1 \\mid S_2)=0.1$。从这些摘要统计数据中，您可以推断出在每种刺激下 $(X_1,X_2)$ 的完整联合分布。\n\n考虑两种分类器：使用真实联合分布 $P(X_1,X_2 \\mid S_k)$ 的最优贝叶斯分类器，以及将 $X_1$ 和 $X_2$ 视为在给定 $S_k$ 时条件独立的朴素贝叶斯分类器。\n\n仅使用贝叶斯定理和条件独立的定义，结合所提供的统计数据，判断以下哪些陈述是正确的。\n\n- A. 对于观测值 $\\mathbf{x}=(1,1)$ 和相等的类别先验，最优贝叶斯分类器选择 $S_1$，而朴素贝叶斯分类器在 $S_1$ 和 $S_2$ 之间得出平局结果。\n- B. 对于观测值 $\\mathbf{x}=(0,0)$ 和相等的类别先验，最优贝叶斯分类器和朴素贝叶斯分类器都选择 $S_2$。\n- C. 对于观测值 $\\mathbf{x}=(1,0)$ 和相等的类别先验，最优贝叶斯分类器选择 $S_2$，而朴素贝叶斯分类器得出 $S_1$ 和 $S_2$ 相等的后验概率。\n- D. 在这种构造下，对于相等的类别先验和任意 $\\mathbf{x} \\in \\{0,1\\}^2$，朴素贝叶斯后验几率等于 $1$（即对数几率为 $0$），而真实贝叶斯后验几率则随 $\\mathbf{x}$ 变化。",
            "solution": "用户想让我解决这个问题。\n我的任务是首先验证问题陈述，然后提供详细的解决方案并评估给定的选项。\n\n### 问题验证\n\n**步骤 1：提取已知信息**\n\n问题提供了以下信息：\n- 两种刺激：$S_1$, $S_2$。\n- 两个二元神经元响应：$X_1 \\in \\{0,1\\}$， $X_2 \\in \\{0,1\\}$。\n- 相等的类别先验：$P(S_1) = P(S_2)$。由于它们的和必须为 $1$，所以 $P(S_1) = P(S_2) = \\frac{1}{2}$。\n- 边缘条件概率：\n  - $P(X_1=1 \\mid S_1) = \\frac{1}{2}$\n  - $P(X_1=1 \\mid S_2) = \\frac{1}{2}$\n  - $P(X_2=1 \\mid S_1) = \\frac{1}{2}$\n  - $P(X_2=1 \\mid S_2) = \\frac{1}{2}$\n- 联合条件概率：\n  - $P(X_1=1, X_2=1 \\mid S_1) = 0.4$\n  - $P(X_1=1, X_2=1 \\mid S_2) = 0.1$\n- 问题比较了使用真实联合分布 $P(X_1, X_2 \\mid S_k)$ 的最优贝叶斯分类器与假设条件独立的朴素贝叶斯分类器：$P(X_1, X_2 \\mid S_k) \\approx P(X_1 \\mid S_k)P(X_2 \\mid S_k)$。\n\n**步骤 2：使用提取的已知信息进行验证**\n\n在求解之前，我们必须验证所提供的统计数据是否一致，并且能够定义有效的概率分布。这需要推导在 $k \\in \\{1,2\\}$ 条件下的完整联合分布 $P(X_1, X_2 \\mid S_k)$。\n\n**对于刺激 $S_1$：**\n我们已知 $P(X_1=1 \\mid S_1) = 0.5$，$P(X_2=1 \\mid S_1) = 0.5$ 和 $P(X_1=1, X_2=1 \\mid S_1) = 0.4$。\n使用全概率定律（边缘化）：\n$P(X_1=1 \\mid S_1) = P(X_1=1, X_2=0 \\mid S_1) + P(X_1=1, X_2=1 \\mid S_1)$\n$0.5 = P(X_1=1, X_2=0 \\mid S_1) + 0.4 \\implies P(X_1=1, X_2=0 \\mid S_1) = 0.1$。\n\n类似地，\n$P(X_2=1 \\mid S_1) = P(X_1=0, X_2=1 \\mid S_1) + P(X_1=1, X_2=1 \\mid S_1)$\n$0.5 = P(X_1=0, X_2=1 \\mid S_1) + 0.4 \\implies P(X_1=0, X_2=1 \\mid S_1) = 0.1$。\n\n所有联合概率之和必须为 $1$：\n$$ \\sum_{x_1 \\in \\{0,1\\}} \\sum_{x_2 \\in \\{0,1\\}} P(X_1=x_1, X_2=x_2 \\mid S_1) = 1 $$\n$P(1,1|S_1) + P(1,0|S_1) + P(0,1|S_1) + P(0,0|S_1) = 1$\n$0.4 + 0.1 + 0.1 + P(X_1=0, X_2=0 \\mid S_1) = 1$\n$0.6 + P(X_1=0, X_2=0 \\mid S_1) = 1 \\implies P(X_1=0, X_2=0 \\mid S_1) = 0.4$。\n\n所有概率都在 $[0,1]$ 区间内。推导出的分布是有效的。\n\n**对于刺激 $S_2$**：\n我们已知 $P(X_1=1 \\mid S_2) = 0.5$，$P(X_2=1 \\mid S_2) = 0.5$ 和 $P(X_1=1, X_2=1 \\mid S_2) = 0.1$。\n$P(X_1=1 \\mid S_2) = P(X_1=1, X_2=0 \\mid S_2) + P(X_1=1, X_2=1 \\mid S_2)$\n$0.5 = P(X_1=1, X_2=0 \\mid S_2) + 0.1 \\implies P(X_1=1, X_2=0 \\mid S_2) = 0.4$。\n\n$P(X_2=1 \\mid S_2) = P(X_1=0, X_2=1 \\mid S_2) + P(X_1=1, X_2=1 \\mid S_2)$\n$0.5 = P(X_1=0, X_2=1 \\mid S_2) + 0.1 \\implies P(X_1=0, X_2=1 \\mid S_2) = 0.4$。\n\n概率之和为 $1$：\n$P(1,1|S_2) + P(1,0|S_2) + P(0,1|S_2) + P(0,0|S_2) = 1$\n$0.1 + 0.4 + 0.4 + P(X_1=0, X_2=0 \\mid S_2) = 1$\n$0.9 + P(X_1=0, X_2=0 \\mid S_2) = 1 \\implies P(X_1=0, X_2=0 \\mid S_2) = 0.1$。\n\n所有概率都在 $[0,1]$ 区间内。这个推导出的分布也是有效的。\n\n**步骤 3：结论与行动**\n\n问题陈述具有科学依据、提法明确且客观。所提供的统计数据内部一致，并允许推导出完整且有效的概率分布。因此，该问题是**有效的**。\n\n---\n\n### 求解过程\n\n对于一个观测值 $\\mathbf{x}=(x_1, x_2)$，贝叶斯分类器选择使后验概率 $P(S_k \\mid \\mathbf{x})$ 最大化的刺激 $S_k$。根据贝叶斯定理：\n$$ P(S_k \\mid \\mathbf{x}) = \\frac{P(\\mathbf{x} \\mid S_k) P(S_k)}{P(\\mathbf{x})} $$\n由于先验概率 $P(S_1)$ 和 $P(S_2)$ 相等，最大化后验概率等价于最大化似然 $P(\\mathbf{x} \\mid S_k)$。因此，决策规则是：\n$$ \\text{如果 } P(\\mathbf{x} \\mid S_1) > P(\\mathbf{x} \\mid S_2) \\text{，选择 } S_1 $$\n$$ \\text{如果 } P(\\mathbf{x} \\mid S_2) > P(\\mathbf{x} \\mid S_1) \\text{，选择 } S_2 $$\n$$ \\text{如果 } P(\\mathbf{x} \\mid S_1) = P(\\mathbf{x} \\mid S_2) \\text{，则为平局} $$\n\n**1. 最优贝叶斯分类器**\n\n该分类器使用真实的联合似然 $P(\\mathbf{x} \\mid S_k)$，我们在验证阶段已经推导出来。为了清晰起见，我们将它们制成表格。\n\n$S_1$ 的似然函数：\n- $P((X_1,X_2)=(1,1) \\mid S_1) = 0.4$\n- $P((X_1,X_2)=(1,0) \\mid S_1) = 0.1$\n- $P((X_1,X_2)=(0,1) \\mid S_1) = 0.1$\n- $P((X_1,X_2)=(0,0) \\mid S_1) = 0.4$\n\n$S_2$ 的似然函数：\n- $P((X_1,X_2)=(1,1) \\mid S_2) = 0.1$\n- $P((X_1,X_2)=(1,0) \\mid S_2) = 0.4$\n- $P((X_1,X_2)=(0,1) \\mid S_2) = 0.4$\n- $P((X_1,X_2)=(0,0) \\mid S_2) = 0.1$\n\n**2. 朴素贝叶斯分类器**\n\n该分类器假设条件独立，因此似然为 $P_{NB}(\\mathbf{x} \\mid S_k) = P(X_1=x_1 \\mid S_k) P(X_2=x_2 \\mid S_k)$。\n\n所需的边缘概率是已知的：\n- $P(X_1=1 \\mid S_1) = 0.5 \\implies P(X_1=0 \\mid S_1) = 1 - 0.5 = 0.5$。\n- $P(X_2=1 \\mid S_1) = 0.5 \\implies P(X_2=0 \\mid S_1) = 1 - 0.5 = 0.5$。\n- $P(X_1=1 \\mid S_2) = 0.5 \\implies P(X_1=0 \\mid S_2) = 1 - 0.5 = 0.5$。\n- $P(X_2=1 \\mid S_2) = 0.5 \\implies P(X_2=0 \\mid S_2) = 1 - 0.5 = 0.5$。\n\n值得注意的是，所有边缘概率均为 $0.5$。\n让我们计算朴素贝叶斯似然。对于任何观测值 $\\mathbf{x}=(x_1, x_2)$：\n- 对于 $S_1$：$P_{NB}(\\mathbf{x} \\mid S_1) = P(X_1=x_1 \\mid S_1) P(X_2=x_2 \\mid S_1) = 0.5 \\times 0.5 = 0.25$。\n- 对于 $S_2$：$P_{NB}(\\mathbf{x} \\mid S_2) = P(X_1=x_1 \\mid S_2) P(X_2=x_2 \\mid S_2) = 0.5 \\times 0.5 = 0.25$。\n\n对于朴素贝叶斯分类器，$P_{NB}(\\mathbf{x} \\mid S_1) = P_{NB}(\\mathbf{x} \\mid S_2) = 0.25$ 对所有可能的观测值 $\\mathbf{x} \\in \\{ (0,0), (0,1), (1,0), (1,1) \\}$ 都成立。\n由于似然总是相等且先验也相等，所以后验概率 $P_{NB}(S_1 \\mid \\mathbf{x})$ 和 $P_{NB}(S_2 \\mid \\mathbf{x})$ 总是相等的。这意味着朴素贝叶斯分类器总是得到平局结果。\n\n### 逐项分析\n\n**A. 对于观测值 $\\mathbf{x}=(1,1)$ 和相等的类别先验，最优贝叶斯分类器选择 $S_1$，而朴素贝叶斯分类器在 $S_1$ 和 $S_2$ 之间得出平局结果。**\n\n- **最优贝叶斯分类器**：对于 $\\mathbf{x}=(1,1)$，我们比较似然：\n  - $P(\\mathbf{x}=(1,1) \\mid S_1) = 0.4$\n  - $P(\\mathbf{x}=(1,1) \\mid S_2) = 0.1$\n  因为 $0.4 > 0.1$，最优分类器选择 $S_1$。\n- **朴素贝叶斯分类器**：对于任何 $\\mathbf{x}$，包括 $(1,1)$，我们有 $P_{NB}(\\mathbf{x} \\mid S_1) = 0.25$ 和 $P_{NB}(\\mathbf{x} \\mid S_2) = 0.25$。由于似然相等，这导致了平局。\n- **结论**：该陈述与我们的推导完全一致。**正确**。\n\n**B. 对于观测值 $\\mathbf{x}=(0,0)$ 和相等的类别先验，最优贝叶斯分类器和朴素贝叶斯分类器都选择 $S_2$。**\n\n- **最优贝叶斯分类器**：对于 $\\mathbf{x}=(0,0)$，我们比较似然：\n  - $P(\\mathbf{x}=(0,0) \\mid S_1) = 0.4$\n  - $P(\\mathbf{x}=(0,0) \\mid S_2) = 0.1$\n  因为 $0.4 > 0.1$，最优分类器选择 $S_1$，而不是 $S_2$。\n- **朴素贝叶斯分类器**：该分类器总是得到平局，它不会选择 $S_2$。\n- **结论**：该陈述对两个分类器都为假。**错误**。\n\n**C. 对于观测值 $\\mathbf{x}=(1,0)$ 和相等的类别先验，最优贝叶斯分类器选择 $S_2$，而朴素贝叶斯分类器得出 $S_1$ 和 $S_2$ 相等的后验概率。**\n\n- **最优贝叶斯分类器**：对于 $\\mathbf{x}=(1,0)$，我们比较似然：\n  - $P(\\mathbf{x}=(1,0) \\mid S_1) = 0.1$\n  - $P(\\mathbf{x}=(1,0) \\mid S_2) = 0.4$\n  因为 $0.4 > 0.1$，最优分类器选择 $S_2$。\n- **朴素贝叶斯分类器**：如前所示，该分类器对两个类别总是产生相等的似然（$0.25$）。在先验相等的情况下，后验概率 $P_{NB}(S_1 \\mid \\mathbf{x})$ 和 $P_{NB}(S_2 \\mid \\mathbf{x})$ 也将相等。\n- **结论**：该陈述与我们的推导完全一致。**正确**。\n\n**D. 在这种构造下，对于相等的类别先验和任意 $\\mathbf{x} \\in \\{0,1\\}^2$，朴素贝叶斯后验几率等于 $1$（即对数几率为 $0$），而真实贝叶斯后验几率则随 $\\mathbf{x}$ 变化。**\n\n- $S_1$ 相对于 $S_2$ 的后验几率由它们的后验概率之比给出：\n  $$ \\frac{P(S_1 \\mid \\mathbf{x})}{P(S_2 \\mid \\mathbf{x})} = \\frac{P(\\mathbf{x} \\mid S_1)P(S_1)}{P(\\mathbf{x} \\mid S_2)P(S_2)} $$\n- 由于先验相等，这简化为似然比：\n  $$ \\frac{P(S_1 \\mid \\mathbf{x})}{P(S_2 \\mid \\mathbf{x})} = \\frac{P(\\mathbf{x} \\mid S_1)}{P(\\mathbf{x} \\mid S_2)} $$\n- **朴素贝叶斯后验几率**：对于朴素贝叶斯分类器，似然比为：\n  $$ \\frac{P_{NB}(\\mathbf{x} \\mid S_1)}{P_{NB}(\\mathbf{x} \\mid S_2)} = \\frac{0.25}{0.25} = 1 $$\n  这对任何 $\\mathbf{x}$ 都成立。后验几率为 $1$，对数后验几率为 $\\log(1)=0$。\n- **真实贝叶斯后验几率**：对于最优分类器，似然比为：\n  - 对于 $\\mathbf{x}=(1,1)$：几率 = $\\frac{0.4}{0.1} = 4$。\n  - 对于 $\\mathbf{x}=(1,0)$：几率 = $\\frac{0.1}{0.4} = 0.25$。\n  - 对于 $\\mathbf{x}=(0,0)$：几率 = $\\frac{0.4}{0.1} = 4$。\n  几率明显随观测值 $\\mathbf{x}$ 而变化。\n- **结论**：该陈述准确地描述了两种几率的行为。**正确**。",
            "answer": "$$\\boxed{ACD}$$"
        },
        {
            "introduction": "在构建了神经元发放率的贝叶斯模型之后，一个至关重要的问题是：我们的模型对真实数据的拟合程度如何？本练习  介绍了一种强大的计算方法——后验预测检验——来回答这个问题。你将学习如何通过模拟从后验分布中生成的“复制”数据集，并将其与观测数据进行比较，来严格评估模型的有效性，这在应用贝叶斯工作流程中是不可或缺的一步。",
            "id": "4140541",
            "problem": "您将使用贝叶斯定理和条件概率，为一个泊松模型下的尖峰计数数据实现后验预测检验。考虑一个包含重复试验的实验，每次试验都会产生一个尖峰计数。假设在给定一个公共速率参数的情况下，各次试验的计数是条件独立的。其生成模型为：在给定潜在速率参数 $\\lambda$ 的条件下，每个尖峰计数 $y_i$ 都是从参数为 $\\lambda$ 的泊松分布中独立抽取的。对 $\\lambda$ 采用形状-速率参数化的伽马先验。您的任务是使用一个离散度统计量，通过后验预测检验来评估模型的充分性。\n\n从以下基础出发：\n- 条件独立性：给定 $\\lambda$，观测值是独立同分布的。\n- 泊松概率质量函数：对于整数 $k \\ge 0$ 和速率 $\\lambda > 0$，取值为 $k$ 的概率是 $p(k \\mid \\lambda) = \\exp(-\\lambda)\\lambda^{k}/k!$。\n- 伽马先验（形状-速率）：对于 $\\lambda > 0$，形状参数 $\\alpha_0 > 0$ 和速率参数 $\\beta_0 > 0$，$p(\\lambda \\mid \\alpha_0,\\beta_0) = \\dfrac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0-1}\\exp(-\\beta_0 \\lambda)$。\n- 贝叶斯定理：$p(\\lambda \\mid y) \\propto p(y \\mid \\lambda)\\,p(\\lambda)$，其中 $p(y \\mid \\lambda)$ 是似然，$p(\\lambda)$ 是先验。\n\n对于计数向量 $y = (y_1,\\dots,y_n)$，其样本均值为 $\\bar{y}$，无偏样本方差为 $s^2$（自由度等于 $1$），定义其离散度统计量为\n$$\nD(y) \\;=\\; \\frac{s^2(y)}{\\bar{y}}.\n$$\n如果 $\\bar{y} = 0$，则 $D(y)$ 未定义；对于本问题，所有提供的观测数据集都将满足 $\\bar{y} > 0$。\n\n实现以下后验预测检验：\n1. 使用贝叶斯定理和指定的伽马先验，计算后验分布 $p(\\lambda \\mid y)$。\n2. 对于 $S$ 个独立的后验预测复制，重复以下步骤：\n   - 抽取 $\\lambda^{(s)} \\sim p(\\lambda \\mid y)$。\n   - 抽取一个复制数据集 $y^{(s)}_{\\mathrm{rep}} = (y^{(s)}_{\\mathrm{rep},1},\\dots,y^{(s)}_{\\mathrm{rep},n})$，其中对于不同的 $i$，$y^{(s)}_{\\mathrm{rep},i} \\mid \\lambda^{(s)} \\sim \\text{Poisson}(\\lambda^{(s)})$ 是独立的。\n   - 使用与上述相同的定义计算 $D\\!\\left(y^{(s)}_{\\mathrm{rep}}\\right)$。如果 $\\bar{y}^{(s)}_{\\mathrm{rep}} = 0$，则 $D\\!\\left(y^{(s)}_{\\mathrm{rep}}\\right)$ 未定义；在尾部概率计算中省略此类复制。\n3. 令 $D_{\\mathrm{obs}} = D(y)$。估计上尾后验预测概率\n$$\np_{\\mathrm{upper}} \\;=\\; \\mathbb{P}\\!\\left(D\\!\\left(y_{\\mathrm{rep}}\\right) \\ge D_{\\mathrm{obs}} \\,\\middle|\\, y\\right)\n$$\n，其值为满足 $D\\!\\left(y^{(s)}_{\\mathrm{rep}}\\right) \\ge D_{\\mathrm{obs}}$ 的有效复制所占的比例。同样地，估计下尾后验预测概率\n$$\np_{\\mathrm{lower}} \\;=\\; \\mathbb{P}\\!\\left(D\\!\\left(y_{\\mathrm{rep}}\\right) \\le D_{\\mathrm{obs}} \\,\\middle|\\, y\\right)\n$$\n，其值为满足 $D\\!\\left(y^{(s)}_{\\mathrm{rep}}\\right) \\le D_{\\mathrm{obs}}$ 的有效复制所占的比例。\n\n您的程序必须：\n- 使用每个测试用例中提供的形状-速率参数为 $(\\alpha_0,\\beta_0)$ 的伽马先验。\n- 在计算 $s^2$ 时，使用自由度等于 $1$ 的无偏样本方差。\n- 为了可复现性，使用固定的随机种子 $2025$。\n- 在尾部概率估计中，省略均值等于零的后验预测复制；如果在例外情况下没有剩余的有效复制，则该测试用例返回 $p_{\\mathrm{upper}} = 0.5$ 和 $p_{\\mathrm{lower}} = 0.5$。\n- 以小数（而非百分比）形式返回结果。\n\n测试套件：\n- 情况 1：$y = [\\,3,\\,2,\\,5,\\,4,\\,1,\\,0,\\,6,\\,2,\\,4,\\,3\\,]$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0$, $S = 20000$。\n- 情况 2（相对于泊松分布是过离散的）：$y = [\\,0,\\,7,\\,0,\\,12,\\,3,\\,9,\\,1,\\,15,\\,2,\\,0\\,]$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0$, $S = 20000$。\n- 情况 3（相对于泊松分布是欠离散的）：$y = [\\,5,\\,5,\\,4,\\,5,\\,6,\\,5,\\,5,\\,5,\\,5,\\,4\\,]$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0$, $S = 20000$。\n- 情况 4（边界行为）：$y = [\\,0,\\,1\\,]$, $\\alpha_0 = 1.0$, $\\beta_0 = 1.0$, $S = 20000$。\n- 情况 5（强先验影响）：$y = [\\,2,\\,2\\,]$, $\\alpha_0 = 10.0$, $\\beta_0 = 5.0$, $S = 20000$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例对应一个双元素列表 $[p_{\\mathrm{upper}}, p_{\\mathrm{lower}}]$，其中每个概率都四舍五入到六位小数，例如：\n\"[ [p1_upper,p1_lower], [p2_upper,p2_lower], ... ]\" 不含多余空格。具体来说，确切要求的格式是单行：\n\"[[p1_upper,p1_lower],[p2_upper,p2_lower],[p3_upper,p3_lower],[p4_upper,p4_lower],[p5_upper,p5_lower]]\"。",
            "solution": "该问题要求为尖峰计数数据的分层泊松-伽马模型实现后验预测检验。其目标是通过将从观测数据计算出的离散度统计量与从模型的后验预测分布中复制的模拟数据计算出的同一统计量的分布进行比较，来评估模型的充分性。\n\n首先，必须形式化地指定贝叶斯模型。数据由一个包含 $n$ 个尖峰计数的向量 $y = (y_1, \\dots, y_n)$ 组成。生成模型假定，在给定潜在速率参数 $\\lambda > 0$ 的条件下，每个计数 $y_i$ 都是从泊松分布中独立抽取的值。因此，似然函数为：\n$$\np(y \\mid \\lambda) = \\prod_{i=1}^{n} p(y_i \\mid \\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda} \\lambda^{y_i}}{y_i!} = \\frac{e^{-n\\lambda} \\lambda^{\\sum_{i=1}^{n} y_i}}{\\prod_{i=1}^{n} y_i!}\n$$\n对于速率参数 $\\lambda$，选择伽马分布作为其先验，其参数为形状参数 $\\alpha_0 > 0$ 和速率参数 $\\beta_0 > 0$。由于伽马分布是泊松似然的共轭先验，这是一个标准的选择。先验概率密度函数为：\n$$\np(\\lambda \\mid \\alpha_0, \\beta_0) = \\frac{\\beta_0^{\\alpha_0}}{\\Gamma(\\alpha_0)} \\lambda^{\\alpha_0-1} e^{-\\beta_0 \\lambda}\n$$\n根据贝叶斯定理，$\\lambda$ 的后验分布与似然和先验的乘积成正比：$p(\\lambda \\mid y) \\propto p(y \\mid \\lambda) p(\\lambda)$。我们可以通过组合涉及 $\\lambda$ 的项来推导后验分布的函数形式：\n$$\np(\\lambda \\mid y) \\propto \\left( e^{-n\\lambda} \\lambda^{\\sum_{i=1}^{n} y_i} \\right) \\left( \\lambda^{\\alpha_0-1} e^{-\\beta_0 \\lambda} \\right)\n$$\n$$\np(\\lambda \\mid y) \\propto \\lambda^{(\\alpha_0 + \\sum_{i=1}^{n} y_i) - 1} e^{-(\\beta_0 + n) \\lambda}\n$$\n该表达式是伽马分布的核。通过观察，我们可以确定后验分布的参数，我们将其表示为 $\\alpha_n$ 和 $\\beta_n$：\n- 后验形状：$\\alpha_n = \\alpha_0 + \\sum_{i=1}^{n} y_i$\n- 后验速率：$\\beta_n = \\beta_0 + n$\n因此，$\\lambda$ 的后验分布是 $p(\\lambda \\mid y) = \\text{Gamma}(\\lambda \\mid \\alpha_n, \\beta_n)$。\n\n下一步是为模型检验定义检验统计量。问题指定了一个离散度统计量 $D(y)$，定义为样本方差与样本均值的比率：\n$$\nD(y) = \\frac{s^2(y)}{\\bar{y}}\n$$\n其中 $\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$ 是样本均值。$s^2(y)$ 项是无偏样本方差。问题陈述中描述其具有“等于 $1$ 的自由度”。这被解释为对使用除数 $n-1$ 的无偏样本方差标准公式的一个略微不精确的提法，这对应于像 NumPy 这样的数值库中的 `ddof=1`（自由度差值）参数。该估计量关联的抽样分布具有 $n-1$ 个自由度。对于大小为 $n$ 的样本，其公式为：\n$$\ns^2(y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (y_i - \\bar{y})^2\n$$\n采用此解释是因为它是“无偏样本方差”的标准定义。对于观测数据 $y$，所有提供的测试用例都满足 $n \\ge 2$ 和 $\\bar{y} > 0$，从而确保 $D(y)$ 是良定义的。\n\n后验预测检验通过一个基于模拟的算法执行：\n1.  计算观测数据的离散度统计量 $D_{\\mathrm{obs}} = D(y)$。\n2.  生成大量的（$S$ 个）独立后验预测复制。对于从 $1$ 到 $S$ 的每个复制 $s$：\n    a. 从后验分布中抽取一个速率参数 $\\lambda^{(s)}$：$\\lambda^{(s)} \\sim \\text{Gamma}(\\alpha_n, \\beta_n)$。\n    b. 通过从以抽样速率为参数的泊松分布中独立抽取每个计数，生成一个复制数据集 $y^{(s)}_{\\mathrm{rep}} = (y^{(s)}_{\\mathrm{rep},1}, \\dots, y^{(s)}_{\\mathrm{rep},n})$：$y^{(s)}_{\\mathrm{rep},i} \\sim \\text{Poisson}(\\lambda^{(s)})$。\n    c. 计算该复制的离散度统计量 $D(y^{(s)}_{\\mathrm{rep}})$。样本均值 $\\bar{y}^{(s)}_{\\mathrm{rep}}$ 为 $0$ 的复制被视为无效，并从后续分析中省略，因为 $D(y^{(s)}_{\\mathrm{rep}})$ 将是未定义的。\n3.  估计上尾和下尾后验预测概率（$p$-值）。这些量度量了根据所选统计量，复制数据与观测数据同样极端或更极端的概率。它们被估计为满足以下条件的有效复制所占的比例：\n$$\np_{\\mathrm{upper}} = \\mathbb{P}(D(y_{\\mathrm{rep}}) \\ge D_{\\mathrm{obs}} \\mid y) \\approx \\frac{1}{N_{\\mathrm{valid}}} \\sum_{s=1}^{S} \\mathbb{I}\\left(\\bar{y}^{(s)}_{\\mathrm{rep}} > 0 \\text{ and } D(y^{(s)}_{\\mathrm{rep}}) \\ge D_{\\mathrm{obs}}\\right)\n$$\n$$\np_{\\mathrm{lower}} = \\mathbb{P}(D(y_{\\mathrm{rep}}) \\le D_{\\mathrm{obs}} \\mid y) \\approx \\frac{1}{N_{\\mathrm{valid}}} \\sum_{s=1}^{S} \\mathbb{I}\\left(\\bar{y}^{(s)}_{\\mathrm{rep}} > 0 \\text{ and } D(y^{(s)}_{\\mathrm{rep}}) \\le D_{\\mathrm{obs}}\\right)\n$$\n此处，$\\mathbb{I}(\\cdot)$ 是指示函数，$N_{\\mathrm{valid}}$ 是有效复制的总数（其中 $\\bar{y}^{(s)}_{\\mathrm{rep}} > 0$）。如果 $N_{\\mathrm{valid}} = 0$，则根据问题规范，将概率设置为 $0.5$。\n\n将对每个测试用例实施此过程，使用固定的随机种子 $2025$ 来确保模拟结果的可复现性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a posterior predictive check for spike count data modeled\n    with a Poisson-Gamma hierarchical model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'y': np.array([3, 2, 5, 4, 1, 0, 6, 2, 4, 3]), 'alpha0': 1.0, 'beta0': 1.0, 'S': 20000},\n        {'y': np.array([0, 7, 0, 12, 3, 9, 1, 15, 2, 0]), 'alpha0': 1.0, 'beta0': 1.0, 'S': 20000},\n        {'y': np.array([5, 5, 4, 5, 6, 5, 5, 5, 5, 4]), 'alpha0': 1.0, 'beta0': 1.0, 'S': 20000},\n        {'y': np.array([0, 1]), 'alpha0': 1.0, 'beta0': 1.0, 'S': 20000},\n        {'y': np.array([2, 2]), 'alpha0': 10.0, 'beta0': 5.0, 'S': 20000},\n    ]\n\n    # Initialize a random number generator with the specified seed.\n    rng = np.random.default_rng(2025)\n    \n    results = []\n\n    def dispersion_statistic(counts):\n        \"\"\"\n        Calculates the dispersion statistic D(y) = s^2(y) / y_bar.\n        Returns None if y_bar is 0 or if variance is ill-defined (n  2).\n        \"\"\"\n        n = len(counts)\n        if n  2:\n            return 0.0 # Variance is 0 for n=1, or undefined. Treat as 0. \n                       # Problem cases all have n>=2, so this is for internal robustness.\n        \n        mean_val = np.mean(counts)\n        if mean_val == 0.0:\n            return None # Undefined\n        \n        # Use ddof=1 for unbiased sample variance (divisor n-1).\n        var_val = np.var(counts, ddof=1)\n        return var_val / mean_val\n\n    for case in test_cases:\n        y_obs = case['y']\n        alpha0 = case['alpha0']\n        beta0 = case['beta0']\n        S = case['S']\n        n = len(y_obs)\n\n        # 1. Compute observed statistic\n        d_obs = dispersion_statistic(y_obs)\n\n        # 2. Compute posterior parameters for lambda ~ Gamma(alpha_n, beta_n)\n        alpha_post = alpha0 + np.sum(y_obs)\n        beta_post = beta0 + n\n\n        # 3. Draw S samples from the posterior predictive distribution\n        # Draw lambda samples from the Gamma posterior\n        # numpy.random.gamma uses shape and scale, where scale = 1 / rate.\n        lambda_samples = rng.gamma(shape=alpha_post, scale=1.0/beta_post, size=S)\n\n        # Draw replicated datasets y_rep from Poisson(lambda_sample)\n        # Reshape lambda_samples to (S, 1) to broadcast for generating (S, n) replicates\n        y_reps = rng.poisson(lam=lambda_samples[:, np.newaxis], size=(S, n))\n        \n        # 4. Compute dispersion statistic for each replicate\n        mean_reps = np.mean(y_reps, axis=1)\n        \n        # Create a mask for valid replicates (mean > 0)\n        valid_mask = mean_reps > 0\n        \n        if not np.any(valid_mask):\n            # Special case: no valid replicates generated.\n            p_upper, p_lower = 0.5, 0.5\n        else:\n            valid_y_reps = y_reps[valid_mask]\n            valid_mean_reps = mean_reps[valid_mask]\n            \n            # Using ddof=1 for unbiased sample variance\n            var_reps = np.var(valid_y_reps, axis=1, ddof=1)\n\n            # Handle cases where mean is > 0 but var is 0 (e.g., [1, 1, 1])\n            # The calculation is still valid: D_rep will be 0.\n            d_reps = var_reps / valid_mean_reps\n            \n            # 5. Estimate tail probabilities\n            num_valid_reps = len(d_reps)\n            \n            p_upper = np.sum(d_reps >= d_obs) / num_valid_reps\n            p_lower = np.sum(d_reps = d_obs) / num_valid_reps\n\n        # Format results for the final output string\n        results.append(f\"[{p_upper:.6f},{p_lower:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}