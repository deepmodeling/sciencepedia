{
    "hands_on_practices": [
        {
            "introduction": "In electrophysiological recordings, the choice of a reference scheme is a critical pre-processing step that acts as a spatial filter. This exercise explores how different referencing methods, such as common average and bipolar referencing, alter the underlying cross-spectral properties of the signals. By calculating the impact on coherence, you will gain a hands-on understanding of how methodological choices can shape our interpretation of neural connectivity .",
            "id": "4181539",
            "problem": "A research team is analyzing Electrocorticography (ECoG) signals recorded from a linear array of $M=5$ electrodes at a fixed frequency $f_0$. Let the raw zero-mean signals be $x_i(t)$, $i \\in \\{1,2,3,4,5\\}$, modeled as a stationary multivariate process whose cross-spectral density matrix at frequency $f_0$ is the symmetric Toeplitz matrix with entries\n$$\nS_{ij}(f_0) \\equiv S_{ij} = s \\exp\\!\\big(-|i-j|\\big) + n \\,\\delta_{ij},\n$$\nwhere $s0$ captures a spatially correlated field and $n0$ captures independent channel noise. Assume $s=1$ and $n=0.2$.\n\nTwo referencing schemes are considered as spatial linear filters:\n- Common-average reference (CAR): $y = R_{\\mathrm{CAR}} x$ with $R_{\\mathrm{CAR}} = I - \\frac{1}{M} \\mathbf{1}\\mathbf{1}^{\\top}$, where $\\mathbf{1}$ is the $M \\times 1$ vector of ones and $I$ is the $M \\times M$ identity matrix. The CAR-referenced signals are $y_i(t)$.\n- Bipolar reference across adjacent electrodes: define $b_k(t) = x_k(t) - x_{k+1}(t)$ for $k \\in \\{1,2,3,4\\}$, collecting these into $b = R_{\\mathrm{BIP}} x$ with $R_{\\mathrm{BIP}}$ the $(M-1)\\times M$ first-difference operator along the array.\n\nStarting only from the definitions of linear filtering and spectral density, and the definition of magnitude-squared coherence between two zero-mean stationary processes $u(t)$ and $v(t)$ at frequency $f_0$,\n$$\nC(u,v; f_0) = \\frac{|S_{uv}(f_0)|^2}{S_{uu}(f_0)\\,S_{vv}(f_0)},\n$$\nderive the spatial filtering action of the two referencing schemes on the cross-spectral density and compute the magnitude-squared coherence between $y_2(t)$ and $y_3(t)$, denoted $C_{\\mathrm{CAR}}$, and between $b_2(t)$ and $b_3(t)$, denoted $C_{\\mathrm{BIP}}$. Then, quantify the effect of referencing on coherence by computing the ratio\n$$\n\\rho = \\frac{C_{\\mathrm{CAR}}}{C_{\\mathrm{BIP}}}.\n$$\nUse $s=1$, $n=0.2$, and $\\exp(-1)$, $\\exp(-2)$, $\\exp(-3)$, $\\exp(-4)$ for the spatial correlation terms as implied by the model above. Round your final numeric value of $\\rho$ to four significant figures. Express the answer as a dimensionless decimal.",
            "solution": "The fundamental principle governing the transformation of cross-spectral densities under a linear spatial filter is as follows. Let $x(t)$ be a vector of $M$ zero-mean stationary time series with a cross-spectral density matrix $S_x(f)$. If a new set of time series $y(t)$ is obtained through a linear transformation $y(t) = R x(t)$, where $R$ is a transformation matrix, its cross-spectral density matrix $S_y(f)$ is given by:\n$$S_y(f) = R S_x(f) R^{\\dagger}$$\nwhere $R^{\\dagger}$ is the conjugate transpose of $R$. As the referencing matrices in this problem are real, this simplifies to $S_y(f) = R S_x(f) R^{\\top}$. All calculations are performed at the fixed frequency $f_0$, so we will omit the argument $f_0$ for brevity, writing $S_{ij}$ instead of $S_{ij}(f_0)$.\n\nFirst, we construct the $M \\times M$ input cross-spectral density matrix $S_x$ for the raw signals $x_i(t)$.\nThe problem states $M=5$, and the matrix entries are $S_{ij} = s \\exp(-|i-j|) + n \\delta_{ij}$, with parameter values $s=1$ and $n=0.2$. The matrix $S_x$ is therefore a $5 \\times 5$ symmetric Toeplitz matrix:\n$$S_x = \\begin{pmatrix}\n1+n  s e^{-1}  s e^{-2}  s e^{-3}  s e^{-4} \\\\\ns e^{-1}  1+n  s e^{-1}  s e^{-2}  s e^{-3} \\\\\ns e^{-2}  s e^{-1}  1+n  s e^{-1}  s e^{-2} \\\\\ns e^{-3}  s e^{-2}  s e^{-1}  1+n  s e^{-1} \\\\\ns e^{-4}  s e^{-3}  s e^{-2}  s e^{-1}  1+n\n\\end{pmatrix}$$\nSubstituting $s=1$ and $n=0.2$:\n$$S_x = \\begin{pmatrix}\n1.2  e^{-1}  e^{-2}  e^{-3}  e^{-4} \\\\\ne^{-1}  1.2  e^{-1}  e^{-2}  e^{-3} \\\\\ne^{-2}  e^{-1}  1.2  e^{-1}  e^{-2} \\\\\ne^{-3}  e^{-2}  e^{-1}  1.2  e^{-1} \\\\\ne^{-4}  e^{-3}  e^{-2}  e^{-1}  1.2\n\\end{pmatrix}$$\n\nWe need to compute the magnitude-squared coherence $C(u,v) = \\frac{|S_{uv}|^2}{S_{uu} S_{vv}}$ for the two referencing schemes.\n\n**1. Common-Average Reference (CAR)**\n\nThe CAR transformation is given by $y = R_{\\mathrm{CAR}} x$, where $R_{\\mathrm{CAR}} = I - \\frac{1}{M} \\mathbf{1}\\mathbf{1}^{\\top}$. This matrix is symmetric, so $R_{\\mathrm{CAR}}^{\\top} = R_{\\mathrm{CAR}}$. The cross-spectral matrix of the CAR-referenced signals $y_i(t)$ is $S_y = R_{\\mathrm{CAR}} S_x R_{\\mathrm{CAR}}$.\nAn element $(S_y)_{ij}$ of this matrix can be expressed as:\n$$(S_y)_{ij} = (S_x)_{ij} - \\frac{1}{M} \\sum_{k=1}^{M} (S_x)_{ik} - \\frac{1}{M} \\sum_{k=1}^{M} (S_x)_{kj} + \\frac{1}{M^2} \\sum_{k=1}^{M}\\sum_{l=1}^{M} (S_x)_{kl}$$\nLet $R_i = \\sum_{k=1}^{M}(S_x)_{ik}$ be the sum of the $i$-th row of $S_x$, and $T = \\sum_{i,j} (S_x)_{ij}$ be the sum of all elements. Since $S_x$ is symmetric, the $j$-th column sum is equal to the $j$-th row sum, $R_j$. The formula becomes:\n$$(S_y)_{ij} = (S_x)_{ij} - \\frac{R_i}{M} - \\frac{R_j}{M} + \\frac{T}{M^2}$$\nWe need to compute $C_{\\mathrm{CAR}} = \\frac{|(S_y)_{23}|^2}{(S_y)_{22}(S_y)_{33}}$. This requires computing the row sums of $S_x$ with $M=5$. Let $c_k = \\exp(-k)$.\n$R_1 = (1.2 + c_1 + c_2 + c_3 + c_4)$\n$R_2 = (c_1 + 1.2 + c_1 + c_2 + c_3) = 1.2 + 2c_1 + c_2 + c_3$\n$R_3 = (c_2 + c_1 + 1.2 + c_1 + c_2) = 1.2 + 2c_1 + 2c_2$\nDue to symmetry, $R_4 = R_2$ and $R_5 = R_1$.\nThe total sum is $T = 2R_1 + 2R_2 + R_3$.\n\nUsing the approximate values $c_1 \\approx 0.367879$, $c_2 \\approx 0.135335$, $c_3 \\approx 0.049787$, $c_4 \\approx 0.018316$:\n$R_1 \\approx 1.2 + 0.367879 + 0.135335 + 0.049787 + 0.018316 = 1.771317$\n$R_2 \\approx 1.2 + 2(0.367879) + 0.135335 + 0.049787 = 2.120880$\n$R_3 \\approx 1.2 + 2(0.367879) + 2(0.135335) = 2.206429$\n$T \\approx 2(1.771317) + 2(2.120880) + 2.206429 = 9.990822$\nAnd $\\frac{T}{M^2} = \\frac{T}{25} \\approx 0.399633$.\n\nNow we compute the required elements of $S_y$:\n$(S_y)_{22} = (S_x)_{22} - \\frac{2R_2}{M} + \\frac{T}{M^2} \\approx 1.2 - \\frac{2(2.120880)}{5} + 0.399633 = 1.2 - 0.848352 + 0.399633 = 0.751281$\n$(S_y)_{33} = (S_x)_{33} - \\frac{2R_3}{M} + \\frac{T}{M^2} \\approx 1.2 - \\frac{2(2.206429)}{5} + 0.399633 = 1.2 - 0.882572 + 0.399633 = 0.717061$\n$(S_y)_{23} = (S_x)_{23} - \\frac{R_2+R_3}{M} + \\frac{T}{M^2} \\approx c_1 - \\frac{2.120880+2.206429}{5} + 0.399633 = 0.367879 - 0.865462 + 0.399633 = -0.097950$\n\nThe coherence is then:\n$$C_{\\mathrm{CAR}} = \\frac{(-0.097950)^2}{(0.751281)(0.717061)} \\approx \\frac{0.0095942}{0.538722} \\approx 0.017809$$\n\n**2. Bipolar Reference**\n\nThe bipolar signals are $b_k(t) = x_k(t) - x_{k+1}(t)$ for $k \\in \\{1,2,3,4\\}$. We need the coherence between $b_2(t) = x_2(t) - x_3(t)$ and $b_3(t) = x_3(t) - x_4(t)$. The cross-spectral densities are derived by linear combination:\n$S_{b_i b_j} = \\mathbb{E}[\\tilde{b}_i(f) \\tilde{b}_j(f)^*]$. For $i=2, j=2$:\n$S_{b_2 b_2} = S_{(x_2-x_3)(x_2-x_3)} = S_{22} - S_{23} - S_{32} + S_{33}$. Since $S_x$ is real and symmetric, $S_{23}=S_{32}$.\n$S_{b_2 b_2} = S_{22} + S_{33} - 2S_{23} = 1.2 + 1.2 - 2 e^{-1} = 2.4 - 2e^{-1}$.\nFor $i=3, j=3$:\n$S_{b_3 b_3} = S_{(x_3-x_4)(x_3-x_4)} = S_{33} + S_{44} - 2S_{34}$. By the Toeplitz property, $S_{33}=S_{44}=1.2$ and $S_{34}=e^{-1}$.\n$S_{b_3 b_3} = 1.2 + 1.2 - 2 e^{-1} = 2.4 - 2e^{-1}$.\nSo, $S_{b_2 b_2} = S_{b_3 b_3}$.\n\nThe cross-term is:\n$S_{b_2 b_3} = S_{(x_2-x_3)(x_3-x_4)} = S_{23} - S_{24} - S_{33} + S_{34}$.\nUsing the entries of $S_x$:\n$S_{b_2 b_3} = e^{-1} - e^{-2} - 1.2 + e^{-1} = 2e^{-1} - e^{-2} - 1.2$.\n\nNow, we substitute the values:\n$S_{b_2 b_2} = S_{b_3 b_3} \\approx 2.4 - 2(0.367879) = 1.664242$.\n$S_{b_2 b_3} \\approx 2(0.367879) - 0.135335 - 1.2 = 0.735758 - 0.135335 - 1.2 = -0.599577$.\n\nThe bipolar coherence is:\n$$C_{\\mathrm{BIP}} = \\frac{|S_{b_2 b_3}|^2}{S_{b_2 b_2} S_{b_3 b_3}} = \\frac{(S_{b_2 b_3})^2}{(S_{b_2 b_2})^2} \\approx \\frac{(-0.599577)^2}{(1.664242)^2} \\approx \\frac{0.359493}{2.769696} \\approx 0.129795$$\n\n**3. Ratio of Coherences**\n\nFinally, we compute the ratio $\\rho = \\frac{C_{\\mathrm{CAR}}}{C_{\\mathrm{BIP}}}$.\n$$\\rho \\approx \\frac{0.017809}{0.129795} \\approx 0.137209$$\nRounding to four significant figures, we get $0.1372$. This result quantifies the relative impact of the two referencing schemes on the measured channel-to-channel coherence. In this specific scenario, CAR reduces the coherence much more significantly than bipolar referencing.",
            "answer": "$$\\boxed{0.1372}$$"
        },
        {
            "introduction": "Spike sorting algorithms are essential for extracting the activity of individual neurons from extracellular recordings, but their output must be rigorously validated. This practice uses a hypothetical dataset with ground-truth labels, similar to what might be obtained from optotagging, to assess a sorter's performance. By computing key metrics like precision and recall at different decision thresholds, you will learn how to quantitatively evaluate and compare the performance of detection algorithms .",
            "id": "4181531",
            "problem": "You are analyzing neuronal spike data in a modality that provides paired ground truth via optogenetic tagging (optotagging). For each candidate spike produced by a spike-sorting algorithm, you have a confidence score and a binary pairing label indicating whether this candidate matched a ground-truth tagged event. A decision threshold determines whether a candidate spike is accepted as belonging to the tagged neuron.\n\nFundamental base: In binary decision analysis, for any threshold $\\tau \\in [0,1]$, an event with score $s_i \\in [0,1]$ is classified as predicted positive if $s_i \\ge \\tau$ and predicted negative otherwise. With ground-truth labels $g_i \\in \\{0,1\\}$, the confusion counts at threshold $\\tau$ are defined from first principles as follows: a true positive is a predicted positive with $g_i = 1$, a false positive is a predicted positive with $g_i = 0$, and a false negative is a predicted negative with $g_i = 1$. Let $TP(\\tau)$, $FP(\\tau)$, and $FN(\\tau)$ denote these counts. Using the standard definitions derived from these counts, compute the precision, recall, and false discovery rate for each test case below. All metrics must be expressed as unitless decimals.\n\nCorner conventions must be applied to ensure well-defined outputs in edge cases: if $TP(\\tau)+FP(\\tau)=0$, define the precision as $1$ and the false discovery rate as $0$; if $TP(\\tau)+FN(\\tau)=0$, define the recall as $1$.\n\nInput specification: Each test case provides a list of scores $[s_1,\\dots,s_n]$, a list of paired ground-truth labels $[g_1,\\dots,g_n]$, and a threshold $\\tau$. The pairing is assumed to have been performed and validated using time-window matching appropriate for optotagging; you need only use the provided labels $g_i$.\n\nTask: For each test case, compute the precision, recall, and false discovery rate at the given threshold $\\tau$, strictly from the fundamental base above.\n\nTest suite:\n- Case A (mixed ground truth, moderate threshold): scores $[0.9,0.8,0.1,0.4,0.6,0.3,0.95,0.2]$, labels $[1,1,0,1,0,0,1,0]$, threshold $\\tau=0.5$.\n- Case B (same data, lowest threshold): scores $[0.9,0.8,0.1,0.4,0.6,0.3,0.95,0.2]$, labels $[1,1,0,1,0,0,1,0]$, threshold $\\tau=0.0$.\n- Case C (same data, highest threshold with no accepted spikes): scores $[0.9,0.8,0.1,0.4,0.6,0.3,0.95,0.2]$, labels $[1,1,0,1,0,0,1,0]$, threshold $\\tau=1.0$.\n- Case D (no ground-truth positives): scores $[0.7,0.2,0.9]$, labels $[0,0,0]$, threshold $\\tau=0.8$.\n- Case E (all ground-truth positives, ties at threshold): scores $[0.51,0.49,0.5]$, labels $[1,1,1]$, threshold $\\tau=0.5$.\n- Case F (same mixed data, stricter threshold): scores $[0.9,0.8,0.1,0.4,0.6,0.3,0.95,0.2]$, labels $[1,1,0,1,0,0,1,0]$, threshold $\\tau=0.7$.\n\nOutput specification: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sub-list in the order $\\left[\\text{precision},\\text{recall},\\text{false discovery rate}\\right]$ computed at its specified threshold. For example, the output format must be like $[[p_A,r_A,f_A],[p_B,r_B,f_B],\\dots]$ where each $p_X$, $r_X$, and $f_X$ is a decimal number rounded to six decimal places.",
            "solution": "We begin by formalizing the definitions provided. Let there be $n$ candidate spike events. For each event $i \\in \\{1, \\dots, n\\}$, we are given a confidence score $s_i \\in [0, 1]$ and a binary ground-truth label $g_i \\in \\{0, 1\\}$, where $g_i=1$ indicates a true spike from the tagged neuron and $g_i=0$ indicates otherwise.\n\nGiven a decision threshold $\\tau \\in [0, 1]$, a candidate spike is classified as a \"predicted positive\" if its score $s_i$ satisfies $s_i \\ge \\tau$. Otherwise, it is a \"predicted negative\".\n\nFrom these predictions and the ground-truth labels, we can compute the confusion counts at a given threshold $\\tau$:\n-   True Positives, $TP(\\tau)$: The number of events for which $s_i \\ge \\tau$ and $g_i=1$.\n-   False Positives, $FP(\\tau)$: The number of events for which $s_i \\ge \\tau$ and $g_i=0$.\n-   False Negatives, $FN(\\tau)$: The number of events for which $s_i  \\tau$ and $g_i=1$.\n\nThe total number of events classified as positive is $TP(\\tau) + FP(\\tau)$. The total number of actual positive events in the dataset is $P = TP(\\tau) + FN(\\tau)$, a quantity which is independent of the threshold $\\tau$.\n\nUsing these counts, the standard definitions for the required metrics are:\n-   **Precision**: $\\text{Precision}(\\tau) = \\frac{TP(\\tau)}{TP(\\tau) + FP(\\tau)}$\n-   **Recall** (also known as True Positive Rate or Sensitivity): $\\text{Recall}(\\tau) = \\frac{TP(\\tau)}{TP(\\tau) + FN(\\tau)} = \\frac{TP(\\tau)}{P}$\n-   **False Discovery Rate**: $\\text{FDR}(\\tau) = \\frac{FP(\\tau)}{TP(\\tau) + FP(\\tau)}$\n\nThe problem specifies conventions for edge cases where denominators are zero:\n1.  If $TP(\\tau) + FP(\\tau) = 0$, then $\\text{Precision}(\\tau)$ is defined as $1$ and $\\text{FDR}(\\tau)$ is defined as $0$. This occurs when no spikes are accepted at the threshold $\\tau$.\n2.  If $TP(\\tau) + FN(\\tau) = 0$, then $\\text{Recall}(\\tau)$ is defined as $1$. This occurs if there are no ground-truth positive events in the dataset.\n\nWe now apply these principles to each test case.\n\n**Case A**: `scores = [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2]`, `labels = [1, 1, 0, 1, 0, 0, 1, 0]`, $\\tau=0.5$.\n-   Events with $s_i \\ge 0.5$: scores $0.9, 0.8, 0.6, 0.95$.\n-   Corresponding labels: $1, 1, 0, 1$.\n-   $TP(0.5) = 3$ (from scores $0.9, 0.8, 0.95$).\n-   $FP(0.5) = 1$ (from score $0.6$).\n-   Events with $s_i  0.5$: scores $0.1, 0.4, 0.3, 0.2$.\n-   Corresponding labels: $0, 1, 0, 0$.\n-   $FN(0.5) = 1$ (from score $0.4$).\n-   $\\text{Precision} = \\frac{3}{3+1} = 0.75$.\n-   $\\text{Recall} = \\frac{3}{3+1} = 0.75$.\n-   $\\text{FDR} = \\frac{1}{3+1} = 0.25$.\n\n**Case B**: Same data, $\\tau=0.0$.\n-   Events with $s_i \\ge 0.0$: All $8$ events.\n-   Corresponding labels: $1, 1, 0, 1, 0, 0, 1, 0$.\n-   $TP(0.0) = 4$.\n-   $FP(0.0) = 4$.\n-   Events with $s_i  0.0$: None.\n-   $FN(0.0) = 0$.\n-   $\\text{Precision} = \\frac{4}{4+4} = 0.5$.\n-   $\\text{Recall} = \\frac{4}{4+0} = 1.0$.\n-   $\\text{FDR} = \\frac{4}{4+4} = 0.5$.\n\n**Case C**: Same data, $\\tau=1.0$.\n-   Events with $s_i \\ge 1.0$: None.\n-   $TP(1.0) = 0$.\n-   $FP(1.0) = 0$.\n-   The denominator $TP+FP = 0$, so we use the corner convention.\n-   $\\text{Precision} = 1.0$.\n-   $\\text{FDR} = 0.0$.\n-   Events with $s_i  1.0$: All $8$ events.\n-   The total number of actual positives is $4$. All are missed.\n-   $FN(1.0) = 4$.\n-   $\\text{Recall} = \\frac{TP}{TP+FN} = \\frac{0}{0+4} = 0.0$.\n\n**Case D**: `scores = [0.7, 0.2, 0.9]`, `labels = [0, 0, 0]`, $\\tau=0.8$.\n-   Events with $s_i \\ge 0.8$: score $0.9$.\n-   Corresponding label: $0$.\n-   $TP(0.8) = 0$.\n-   $FP(0.8) = 1$.\n-   $\\text{Precision} = \\frac{0}{0+1} = 0.0$.\n-   $\\text{FDR} = \\frac{1}{0+1} = 1.0$.\n-   There are no ground-truth positives in the data, so $TP+FN=0$ regardless of $\\tau$.\n-   This is the corner case for recall. $\\text{Recall} = 1.0$.\n\n**Case E**: `scores = [0.51, 0.49, 0.5]`, `labels = [1, 1, 1]`, $\\tau=0.5$.\n-   Events with $s_i \\ge 0.5$: scores $0.51, 0.5$.\n-   Corresponding labels: $1, 1$.\n-   $TP(0.5) = 2$.\n-   $FP(0.5) = 0$.\n-   $\\text{Precision} = \\frac{2}{2+0} = 1.0$.\n-   $\\text{FDR} = \\frac{0}{2+0} = 0.0$.\n-   Events with $s_i  0.5$: score $0.49$.\n-   Corresponding label: $1$.\n-   $FN(0.5) = 1$.\n-   The total number of actual positives is $3$.\n-   $\\text{Recall} = \\frac{2}{2+1} = \\frac{2}{3} \\approx 0.666667$.\n\n**Case F**: Same data as Case A, $\\tau=0.7$.\n-   `scores = [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2]`, `labels = [1, 1, 0, 1, 0, 0, 1, 0]`.\n-   Events with $s_i \\ge 0.7$: scores $0.9, 0.8, 0.95$.\n-   Corresponding labels: $1, 1, 1$.\n-   $TP(0.7) = 3$.\n-   $FP(0.7) = 0$.\n-   $\\text{Precision} = \\frac{3}{3+0} = 1.0$.\n-   $\\text{FDR} = \\frac{0}{3+0} = 0.0$.\n-   Total actual positives is $4$.\n-   $FN(0.7) = (\\text{total positives}) - TP(0.7) = 4 - 3 = 1$. The missed positive has score $0.4$.\n-   $\\text{Recall} = \\frac{3}{3+1} = \\frac{3}{4} = 0.75$.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes precision, recall, and false discovery rate for several test cases\n    of neuronal spike classification, adhering to specified definitions and\n    corner cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A (mixed ground truth, moderate threshold)\n        {'scores': [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2], 'labels': [1, 1, 0, 1, 0, 0, 1, 0], 'threshold': 0.5},\n        # Case B (same data, lowest threshold)\n        {'scores': [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2], 'labels': [1, 1, 0, 1, 0, 0, 1, 0], 'threshold': 0.0},\n        # Case C (same data, highest threshold with no accepted spikes)\n        {'scores': [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2], 'labels': [1, 1, 0, 1, 0, 0, 1, 0], 'threshold': 1.0},\n        # Case D (no ground-truth positives)\n        {'scores': [0.7, 0.2, 0.9], 'labels': [0, 0, 0], 'threshold': 0.8},\n        # Case E (all ground-truth positives, ties at threshold)\n        {'scores': [0.51, 0.49, 0.5], 'labels': [1, 1, 1], 'threshold': 0.5},\n        # Case F (same mixed data, stricter threshold)\n        {'scores': [0.9, 0.8, 0.1, 0.4, 0.6, 0.3, 0.95, 0.2], 'labels': [1, 1, 0, 1, 0, 0, 1, 0], 'threshold': 0.7},\n    ]\n\n    def compute_metrics(scores, labels, threshold):\n        \"\"\"\n        Calculates precision, recall, and FDR from fundamental counts.\n\n        Args:\n            scores (list[float]): List of confidence scores.\n            labels (list[int]): List of binary ground-truth labels.\n            threshold (float): The decision threshold.\n\n        Returns:\n            tuple[float, float, float]: A tuple containing precision, recall, and FDR.\n        \"\"\"\n        scores = np.array(scores)\n        labels = np.array(labels)\n        \n        # Predictions based on the threshold\n        predicted_positives_mask = scores >= threshold\n        \n        # Calculate confusion counts from first principles\n        tp = np.sum((predicted_positives_mask)  (labels == 1))\n        fp = np.sum((predicted_positives_mask)  (labels == 0))\n        \n        predicted_negatives_mask = scores  threshold\n        fn = np.sum((predicted_negatives_mask)  (labels == 1))\n        \n        # Total number of predicted positives\n        total_predicted_positives = tp + fp\n        \n        # Apply corner conventions for precision and FDR\n        if total_predicted_positives == 0:\n            precision = 1.0\n            fdr = 0.0\n        else:\n            precision = tp / total_predicted_positives\n            fdr = fp / total_predicted_positives\n\n        # Total number of actual positives\n        total_actual_positives = tp + fn\n\n        # Apply corner convention for recall\n        if total_actual_positives == 0:\n            recall = 1.0\n        else:\n            recall = tp / total_actual_positives\n            \n        return precision, recall, fdr\n\n    results = []\n    for case in test_cases:\n        p, r, f = compute_metrics(case['scores'], case['labels'], case['threshold'])\n        results.append(f\"[{p:.6f},{r:.6f},{f:.6f}]\")\n\n    print(f\"[[{','.join(results)}]]\")\n\nsolve()\n```"
        },
        {
            "introduction": "To interpret brain signals in a common anatomical context, it is crucial to accurately map recording sites from their native acquisition space to a standard coordinate system like MNI. This advanced practice models the process of localizing ECoG electrodes from intraoperative photos, requiring you to implement a coordinate transformation and, critically, to quantify the resulting spatial uncertainty. By propagating error from sources like measurement noise and brain shift, you will appreciate the challenges of multimodal integration and learn to characterize the confidence in your spatial localizations .",
            "id": "4181479",
            "problem": "You are given a simplified, mathematically rigorous scenario for mapping Electrocorticography (ECoG) electrode locations from intraoperative photo coordinates to the Montreal Neurological Institute (MNI) three-dimensional space and for quantifying spatial uncertainty introduced by brain shift. The cortical patch visible in the intraoperative photo is modeled as a locally planar surface in MNI space. The mapping from photo coordinates to the planar coordinates is assumed to be a two-dimensional similarity transform, and the embedding of the planar coordinates into MNI space is defined by an orthonormal basis of the plane.\n\nFundamental base and definitions to be used:\n- A two-dimensional similarity transform maps points $p_i \\in \\mathbb{R}^2$ to $q_i \\in \\mathbb{R}^2$ via $q_i = s \\mathbf{R} p_i + \\mathbf{t}$, where $s \\in \\mathbb{R}$ is a positive scale, $\\mathbf{R} \\in \\mathbb{R}^{2 \\times 2}$ is a rotation matrix satisfying $\\mathbf{R}^{\\top}\\mathbf{R} = \\mathbf{I}$ and $\\det(\\mathbf{R}) = 1$, and $\\mathbf{t} \\in \\mathbb{R}^2$ is a translation vector.\n- The plane in $\\mathbb{R}^3$ is parameterized by a point $\\mathbf{O} \\in \\mathbb{R}^3$ and an orthonormal basis $\\{\\mathbf{u}, \\mathbf{v}\\}$ with $\\|\\mathbf{u}\\| = 1$, $\\|\\mathbf{v}\\| = 1$, and $\\mathbf{u}^{\\top}\\mathbf{v} = 0$. The unit normal is $\\mathbf{n} = \\frac{\\mathbf{u} \\times \\mathbf{v}}{\\|\\mathbf{u} \\times \\mathbf{v}\\|}$. A planar coordinate $\\mathbf{q} = [q_x, q_y]^{\\top} \\in \\mathbb{R}^2$ is embedded in MNI space as $\\mathbf{x} = \\mathbf{O} + q_x \\mathbf{u} + q_y \\mathbf{v} \\in \\mathbb{R}^3$.\n- Noise propagation: if a random vector $\\mathbf{z}$ has covariance $\\boldsymbol{\\Sigma}_{\\mathbf{z}}$ and a linear transformation $\\mathbf{A}$ is applied, the resulting covariance is $\\boldsymbol{\\Sigma}_{\\mathbf{A}\\mathbf{z}} = \\mathbf{A} \\boldsymbol{\\Sigma}_{\\mathbf{z}} \\mathbf{A}^{\\top}$.\n- Confidence ellipsoid in $\\mathbb{R}^3$ for a zero-mean Gaussian with covariance $\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{3 \\times 3}$ is the set $\\{\\mathbf{x} \\in \\mathbb{R}^3 : \\mathbf{x}^{\\top} \\boldsymbol{\\Sigma}^{-1} \\mathbf{x} \\le q\\}$, where $q$ is the chi-square quantile for $3$ degrees of freedom at the desired confidence level. If $\\lambda_1, \\lambda_2, \\lambda_3$ are the eigenvalues of $\\boldsymbol{\\Sigma}$, the semi-axis lengths are $a_i = \\sqrt{\\lambda_i} \\sqrt{q}$ for $i \\in \\{1,2,3\\}$, the maximum semi-axis is $\\max_i a_i$, and the volume is $V = \\frac{4}{3}\\pi a_1 a_2 a_3$.\n\nYour task is to:\n1. Estimate the two-dimensional similarity transform parameters $(s, \\mathbf{R}, \\mathbf{t})$ that best map intraoperative photo landmark points $\\{\\mathbf{p}_i\\}_{i=1}^N$ to their corresponding planar coordinates $\\{\\mathbf{q}_i\\}_{i=1}^N$. The planar coordinates $\\{\\mathbf{q}_i\\}$ are obtained by projecting provided MNI three-dimensional landmark points $\\{\\mathbf{x}_i\\}$ onto the plane basis via $\\mathbf{q}_i = [\\mathbf{u}^{\\top}(\\mathbf{x}_i - \\mathbf{O}), \\mathbf{v}^{\\top}(\\mathbf{x}_i - \\mathbf{O})]^{\\top}$.\n2. Map a set of intraoperative photo electrode centers $\\{\\mathbf{p}^{\\text{elec}}_j\\}_{j=1}^M$ to MNI three-dimensional space using the estimated similarity transform and the plane embedding: compute $\\mathbf{q}^{\\text{elec}}_j = s \\mathbf{R} \\mathbf{p}^{\\text{elec}}_j + \\mathbf{t}$, then $\\mathbf{x}^{\\text{elec}}_j = \\mathbf{O} + (\\mathbf{q}^{\\text{elec}}_j)_x \\mathbf{u} + (\\mathbf{q}^{\\text{elec}}_j)_y \\mathbf{v}$.\n3. Quantify spatial uncertainty introduced by brain shift and photo measurement error. Model the photo coordinate measurement error as independent zero-mean Gaussian with covariance $\\boldsymbol{\\Sigma}_{\\text{photo}} = \\sigma^2 \\mathbf{I}_2$ in units of square millimeters, and model brain shift as independent zero-mean Gaussian displacement along the plane normal with covariance $\\boldsymbol{\\Sigma}_{\\text{shift}} = \\tau^2 \\mathbf{n}\\mathbf{n}^{\\top}$ in units of square millimeters. For each electrode $j$, propagate photo noise through the similarity transform and plane embedding to obtain the three-dimensional covariance\n$$\n\\boldsymbol{\\Sigma}^{(j)}_{\\text{3D}} = \\mathbf{B} \\left( s \\mathbf{R} \\boldsymbol{\\Sigma}_{\\text{photo}} (s \\mathbf{R})^{\\top} \\right) \\mathbf{B}^{\\top} + \\tau^2 \\mathbf{n}\\mathbf{n}^{\\top},\n$$\nwhere $\\mathbf{B} = [\\mathbf{u}\\ \\mathbf{v}] \\in \\mathbb{R}^{3 \\times 2}$, and then compute the $95\\%$ confidence ellipsoid semi-axis lengths $a_1^{(j)}, a_2^{(j)}, a_3^{(j)}$, the maximum semi-axis $\\max_i a_i^{(j)}$, and the ellipsoid volume $V^{(j)}$.\n\nCompute and report the following per-test-case metrics:\n- The estimated scale $s$ (unitless).\n- The estimated rotation angle $\\theta$ in radians, recovered from $\\mathbf{R}$ using $\\theta = \\operatorname{atan2}(R_{21}, R_{11})$.\n- The root-mean-square (RMS) registration error in millimeters between the embedded transformed landmarks $\\{\\mathbf{O} + q_{x,i} \\mathbf{u} + q_{y,i} \\mathbf{v}\\}$ and the given MNI three-dimensional landmark positions $\\{\\mathbf{x}_i\\}$.\n- The maximum semi-axis length across electrodes $\\max_j \\max_i a_i^{(j)}$ in millimeters for the $95\\%$ confidence ellipsoid.\n- The mean ellipsoid volume across electrodes $\\frac{1}{M} \\sum_{j=1}^M V^{(j)}$ in cubic millimeters.\n\nUnits and angle requirements:\n- All spatial quantities must be in millimeters.\n- All angles must be in radians.\n- Express the final numerical outputs as decimal floats.\n\nTest suite to cover different cases:\n- Case A (general planar, axis-aligned):\n    - Plane origin $\\mathbf{O} = [-40, -20, 60]$ millimeters.\n    - Plane basis $\\mathbf{u} = [1, 0, 0]$, $\\mathbf{v} = [0, 1, 0]$.\n    - Intraoperative photo landmarks $\\{\\mathbf{p}_i\\}$: $[(0,0), (30,0), (0,20), (30,20)]$ millimeters.\n    - Similarity transform parameters used to generate target planar coordinates: $s = 1.0$, $\\theta = 0.0$, $\\mathbf{t} = [0,0]$ millimeters.\n    - Electrode centers $\\{\\mathbf{p}^{\\text{elec}}_j\\}$: $[(5,5), (15,5), (25,5), (5,15), (15,15), (25,15)]$ millimeters.\n    - Photo noise standard deviation $\\sigma = 1.0$ millimeters, brain shift normal standard deviation $\\tau = 2.0$ millimeters.\n- Case B (tilted plane, rotated and scaled mapping):\n    - Plane origin $\\mathbf{O} = [-42, -18, 58]$ millimeters.\n    - Plane basis $\\mathbf{u} = [0.866025403784, 0.0, 0.5]$, $\\mathbf{v} = [0.0, 1.0, 0.0]$.\n    - Intraoperative photo landmarks $\\{\\mathbf{p}_i\\}$: $[(0,0), (30,0), (0,20), (30,20)]$ millimeters.\n    - Similarity transform parameters used to generate target planar coordinates: $s = 0.9$, $\\theta = \\pi/6$, $\\mathbf{t} = [-5, 3]$ millimeters.\n    - Electrode centers $\\{\\mathbf{p}^{\\text{elec}}_j\\}$: $[(5,5), (15,5), (25,5), (5,15), (15,15), (25,15)]$ millimeters.\n    - Photo noise standard deviation $\\sigma = 0.5$ millimeters, brain shift normal standard deviation $\\tau = 1.0$ millimeters.\n- Case C (near-collinear landmarks, edge case):\n    - Plane origin $\\mathbf{O} = [-30, -10, 65]$ millimeters.\n    - Plane basis $\\mathbf{u} = [1.0, 0.0, 0.0]$, $\\mathbf{v} = [0.0, 1.0, 0.0]$.\n    - Intraoperative photo landmarks $\\{\\mathbf{p}_i\\}$: $[(0,0), (30, 0.001), (60, 0.002), (90, 0.003)]$ millimeters.\n    - Similarity transform parameters used to generate target planar coordinates: $s = 1.0$, $\\theta = 0.0$, $\\mathbf{t} = [0, 0]$ millimeters.\n    - Electrode centers $\\{\\mathbf{p}^{\\text{elec}}_j\\}$: $[(10, 0.0), (20, 0.0005), (30, 0.001)]$ millimeters.\n    - Photo noise standard deviation $\\sigma = 2.0$ millimeters, brain shift normal standard deviation $\\tau = 0.5$ millimeters.\n\nYour program should implement the estimation and uncertainty propagation using only the provided parameter values and report the per-case results in the exact final output format specified below.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a comma-separated list enclosed in square brackets, in the order Case A, Case B, Case C. Each inner list must contain five floats in the order $[s, \\theta, \\text{RMS}_{\\text{mm}}, \\text{L\\_max}_{\\text{mm}}, \\text{V\\_mean}_{\\text{mm}^3}]$. For example, a valid output line will look like $[[s_A,\\theta_A,\\text{RMS}_A,\\text{L\\_max}_A,\\text{V\\_mean}_A],[s_B,\\theta_B,\\text{RMS}_B,\\text{L\\_max}_B,\\text{V\\_mean}_B],[s_C,\\theta_C,\\text{RMS}_C,\\text{L\\_max}_C,\\text{V\\_mean}_C]]$ with no spaces.",
            "solution": "First, we must generate the target planar coordinates to which the photo landmarks will be registered. The problem provides the source photo landmarks $\\{\\mathbf{p}_i\\}_{i=1}^N$ and the ground-truth similarity transform parameters $(s_{\\text{true}}, \\mathbf{R}_{\\text{true}}, \\mathbf{t}_{\\text{true}})$ used to create the target data. The target planar coordinates $\\{\\mathbf{q}_i\\}_{i=1}^N$ are thus generated by applying this transform:\n$$ \\mathbf{q}_i = s_{\\text{true}} \\mathbf{R}_{\\text{true}} \\mathbf{p}_i + \\mathbf{t}_{\\text{true}} $$\nwhere $\\mathbf{R}_{\\text{true}}$ is the $2 \\times 2$ rotation matrix corresponding to the angle $\\theta_{\\text{true}}$.\n\n**1. Estimation of the 2D Similarity Transform**\n\nThe primary task is to estimate the parameters $(s, \\mathbf{R}, \\mathbf{t})$ of a similarity transform $f(\\mathbf{p}) = s\\mathbf{R}\\mathbf{p} + \\mathbf{t}$ that best aligns the set of source photo landmarks $\\{\\mathbf{p}_i\\}_{i=1}^N$ with the set of target planar landmarks $\\{\\mathbf{q}_i\\}_{i=1}^N$. This is achieved by minimizing the sum of squared errors, a classic problem known as similarity Procrustes analysis. The objective function to minimize is:\n$$ E(s, \\mathbf{R}, \\mathbf{t}) = \\sum_{i=1}^N \\| (s\\mathbf{R}\\mathbf{p}_i + \\mathbf{t}) - \\mathbf{q}_i \\|^2 $$\nThe solution proceeds as follows:\n\nFirst, the point sets are centered by subtracting their respective centroids:\n$$ \\bar{\\mathbf{p}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{p}_i \\quad \\text{and} \\quad \\bar{\\mathbf{q}} = \\frac{1}{N} \\sum_{i=1}^N \\mathbf{q}_i $$\n$$ \\mathbf{p}'_i = \\mathbf{p}_i - \\bar{\\mathbf{p}} \\quad \\text{and} \\quad \\mathbf{q}'_i = \\mathbf{q}_i - \\bar{\\mathbf{q}} $$\nThe problem then reduces to finding $s$ and $\\mathbf{R}$ that minimize $\\sum_i \\| s\\mathbf{R}\\mathbf{p}'_i - \\mathbf{q}'_i \\|^2$. The optimal translation $\\mathbf{t}$ can be found afterward.\n\nNext, we construct the $2 \\times 2$ covariance matrix $\\mathbf{H}$ of the centered point sets. Letting $P'$ be the $N \\times 2$ matrix whose rows are $\\mathbf{p}'_i$ and $Q'$ be the $N \\times 2$ matrix whose rows are $\\mathbf{q}'_i$, we have:\n$$ \\mathbf{H} = (P')^{\\top}Q' = \\sum_{i=1}^N \\mathbf{p}'_i (\\mathbf{q}'_i)^{\\top} $$\nThe Singular Value Decomposition (SVD) of $\\mathbf{H}$ is computed:\n$$ \\mathbf{H} = \\mathbf{U}\\boldsymbol{\\Sigma}\\mathbf{V}^{\\top} $$\nThe optimal rotation matrix $\\mathbf{R}$ is found from the SVD components:\n$$ \\mathbf{R} = \\mathbf{V}\\mathbf{U}^{\\top} $$\nTo ensure $\\mathbf{R}$ is a proper rotation matrix (i.e., $\\det(\\mathbf{R}) = +1$), a correction is applied if $\\det(\\mathbf{V}\\mathbf{U}^{\\top}) = -1$. This typically occurs in the presence of reflection or noisy data. The correction involves inverting the sign of the last column of $\\mathbf{V}$ before computing $\\mathbf{R}$, which corresponds to flipping the axis associated with the smallest singular value.\n\nWith the rotation $\\mathbf{R}$ determined, the optimal scale factor $s$ is calculated as:\n$$ s = \\frac{\\sum_{i=1}^N (\\mathbf{q}'_i)^{\\top} \\mathbf{R} \\mathbf{p}'_i}{\\sum_{i=1}^N (\\mathbf{p}'_i)^{\\top} \\mathbf{p}'_i} = \\frac{\\text{tr}(\\mathbf{R}\\mathbf{H})}{\\text{tr}((P')^{\\top}P')} $$\n\nFinally, the translation vector $\\mathbf{t}$ is computed using the centroids and the estimated $s$ and $\\mathbf{R}$:\n$$ \\mathbf{t} = \\bar{\\mathbf{q}} - s\\mathbf{R}\\bar{\\mathbf{p}} $$\nThe estimated rotation angle $\\theta$ is recovered from the elements of $\\mathbf{R}$ using the two-argument arctangent function: $\\theta = \\operatorname{atan2}(R_{21}, R_{11})$.\n\n**2. Electrode Mapping and RMS Error Calculation**\n\nOnce the transform parameters $(s, \\mathbf{R}, \\mathbf{t})$ are estimated, any electrode photo coordinate $\\mathbf{p}^{\\text{elec}}_j$ is mapped to its corresponding MNI coordinate $\\mathbf{x}^{\\text{elec}}_j$. This is a two-step process:\n1.  Transform to planar coordinates: $\\mathbf{q}^{\\text{elec}}_j = s\\mathbf{R}\\mathbf{p}^{\\text{elec}}_j + \\mathbf{t}$.\n2.  Embed in 3D MNI space using the plane definition $(\\mathbf{O}, \\mathbf{u}, \\mathbf{v})$: $\\mathbf{x}^{\\text{elec}}_j = \\mathbf{O} + (\\mathbf{q}^{\\text{elec}}_j)_x \\mathbf{u} + (\\mathbf{q}^{\\text{elec}}_j)_y \\mathbf{v}$.\n\nThe Root-Mean-Square (RMS) registration error is computed to quantify the goodness of fit. The estimated transform is applied to the original photo landmarks $\\{\\mathbf{p}_i\\}$, and the resulting 3D coordinates are compared to the target 3D MNI landmark coordinates $\\{\\mathbf{x}_i\\}$, which are the embeddings of the target planar coordinates $\\{\\mathbf{q}_i\\}$.\n$$ \\mathbf{x}^{\\text{est}}_i = \\mathbf{O} + (s\\mathbf{R}\\mathbf{p}_i + \\mathbf{t})_x \\mathbf{u} + (s\\mathbf{R}\\mathbf{p}_i + \\mathbf{t})_y \\mathbf{v} $$\n$$ \\text{RMS Error} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N \\|\\mathbf{x}^{\\text{est}}_i - \\mathbf{x}_i\\|^2} $$\nSince the target data is generated without noise, the estimated parameters should be identical to the true parameters, and the RMS error should be effectively zero.\n\n**3. Uncertainty Quantification**\n\nSpatial uncertainty arises from two independent, zero-mean Gaussian sources: photo measurement error with covariance $\\boldsymbol{\\Sigma}_{\\text{photo}} = \\sigma^2 \\mathbf{I}_2$ and brain shift along the plane normal $\\mathbf{n}$ with covariance $\\boldsymbol{\\Sigma}_{\\text{shift}} = \\tau^2 \\mathbf{n}\\mathbf{n}^{\\top}$. The total uncertainty for an electrode's 3D position is the sum of the propagated covariances.\n\nThe transformation from a photo coordinate error $\\delta_{\\mathbf{p}}$ to a 3D MNI coordinate error $\\delta_{\\mathbf{x}}$ (ignoring translation) is linear: $\\delta_{\\mathbf{x}} = \\mathbf{B} s \\mathbf{R} \\delta_{\\mathbf{p}}$, where $\\mathbf{B} = [\\begin{matrix} \\mathbf{u}  \\mathbf{v} \\end{matrix}] \\in \\mathbb{R}^{3 \\times 2}$ is the embedding matrix from the plane basis. Using the rule for linear propagation of covariance, the 3D covariance due to photo noise is:\n$$ \\boldsymbol{\\Sigma}_{\\text{photo\\_3D}} = (\\mathbf{B} s \\mathbf{R}) \\boldsymbol{\\Sigma}_{\\text{photo}} (\\mathbf{B} s \\mathbf{R})^{\\top} = \\mathbf{B} s \\mathbf{R} (\\sigma^2 \\mathbf{I}_2) (s \\mathbf{R})^{\\top} \\mathbf{B}^{\\top} = s^2 \\sigma^2 \\mathbf{B} (\\mathbf{R}\\mathbf{R}^{\\top}) \\mathbf{B}^{\\top} = s^2 \\sigma^2 \\mathbf{B} \\mathbf{B}^{\\top} $$\nThe total 3D covariance matrix $\\boldsymbol{\\Sigma}_{\\text{3D}}$ is the sum of the components:\n$$ \\boldsymbol{\\Sigma}_{\\text{3D}} = s^2 \\sigma^2 \\mathbf{B} \\mathbf{B}^{\\top} + \\tau^2 \\mathbf{n}\\mathbf{n}^{\\top} $$\nwhere the unit normal $\\mathbf{n} = \\mathbf{u} \\times \\mathbf{v}$ since $\\{\\mathbf{u}, \\mathbf{v}\\}$ is an orthonormal basis. Note that this covariance is constant for all electrodes in a given case.\n\nThe $95\\%$ confidence ellipsoid is characterized by the eigenvalues $\\{\\lambda_1, \\lambda_2, \\lambda_3\\}$ of the symmetric matrix $\\boldsymbol{\\Sigma}_{\\text{3D}}$. The semi-axis lengths of the ellipsoid are given by $a_i = \\sqrt{q \\lambda_i}$, where $q$ is the $95\\%$ quantile of the chi-square distribution with $3$ degrees of freedom ($q \\approx 7.8147$). The volume of the ellipsoid is $V = \\frac{4}{3}\\pi a_1 a_2 a_3$. The required metrics are the maximum semi-axis length $\\max_i a_i$ and the mean ellipsoid volume across all electrodes (which, in this simplified model, is just the volume $V$ itself).",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Main function to solve the ECoG mapping and uncertainty problem for all test cases.\n    \"\"\"\n    \n    # Chi-square quantile for 95% confidence with 3 degrees of freedom.\n    q_95_3df = chi2.ppf(0.95, 3)\n\n    test_cases = [\n        # Case A\n        {\n            \"O\": np.array([-40.0, -20.0, 60.0]),\n            \"u\": np.array([1.0, 0.0, 0.0]),\n            \"v\": np.array([0.0, 1.0, 0.0]),\n            \"p_landmarks\": np.array([[0.0, 0.0], [30.0, 0.0], [0.0, 20.0], [30.0, 20.0]]),\n            \"s_true\": 1.0,\n            \"theta_true\": 0.0,\n            \"t_true\": np.array([0.0, 0.0]),\n            \"p_elecs\": np.array([[5.0, 5.0], [15.0, 5.0], [25.0, 5.0], [5.0, 15.0], [15.0, 15.0], [25.0, 15.0]]),\n            \"sigma\": 1.0,\n            \"tau\": 2.0,\n        },\n        # Case B\n        {\n            \"O\": np.array([-42.0, -18.0, 58.0]),\n            \"u\": np.array([0.866025403784, 0.0, 0.5]),\n            \"v\": np.array([0.0, 1.0, 0.0]),\n            \"p_landmarks\": np.array([[0.0, 0.0], [30.0, 0.0], [0.0, 20.0], [30.0, 20.0]]),\n            \"s_true\": 0.9,\n            \"theta_true\": np.pi / 6.0,\n            \"t_true\": np.array([-5.0, 3.0]),\n            \"p_elecs\": np.array([[5.0, 5.0], [15.0, 5.0], [25.0, 5.0], [5.0, 15.0], [15.0, 15.0], [25.0, 15.0]]),\n            \"sigma\": 0.5,\n            \"tau\": 1.0,\n        },\n        # Case C\n        {\n            \"O\": np.array([-30.0, -10.0, 65.0]),\n            \"u\": np.array([1.0, 0.0, 0.0]),\n            \"v\": np.array([0.0, 1.0, 0.0]),\n            \"p_landmarks\": np.array([[0.0, 0.0], [30.0, 0.001], [60.0, 0.002], [90.0, 0.003]]),\n            \"s_true\": 1.0,\n            \"theta_true\": 0.0,\n            \"t_true\": np.array([0.0, 0.0]),\n            \"p_elecs\": np.array([[10.0, 0.0], [20.0, 0.0005], [30.0, 0.001]]),\n            \"sigma\": 2.0,\n            \"tau\": 0.5,\n        },\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        # Extract data for the current case\n        O, u, v = case[\"O\"], case[\"u\"], case[\"v\"]\n        p_landmarks = case[\"p_landmarks\"]\n        s_true, theta_true, t_true = case[\"s_true\"], case[\"theta_true\"], case[\"t_true\"]\n        p_elecs = case[\"p_elecs\"]\n        sigma, tau = case[\"sigma\"], case[\"tau\"]\n\n        # --- Generate target data ---\n        R_true = np.array([\n            [np.cos(theta_true), -np.sin(theta_true)],\n            [np.sin(theta_true), np.cos(theta_true)]\n        ])\n        # Generate target 2D planar coordinates q_i\n        q_landmarks = (s_true * p_landmarks @ R_true.T) + t_true\n        # Generate target 3D MNI coordinates x_i\n        x_landmarks = O + q_landmarks[:, 0, np.newaxis] * u + q_landmarks[:, 1, np.newaxis] * v\n\n        # --- 1. Estimate Similarity Transform ---\n        p_centroid = p_landmarks.mean(axis=0)\n        q_centroid = q_landmarks.mean(axis=0)\n        p_centered = p_landmarks - p_centroid\n        q_centered = q_landmarks - q_centroid\n        H = p_centered.T @ q_centered\n        U, S, Vt = np.linalg.svd(H)\n        R_est = Vt.T @ U.T\n        if np.linalg.det(R_est)  0:\n            Vt[-1, :] *= -1\n            R_est = Vt.T @ U.T\n        \n        # Numerator for scale: tr(R_est * H)\n        var_p = np.sum(p_centered**2)\n        s_est = np.trace(R_est @ H) / var_p if var_p > 1e-9 else 1.0\n\n        t_est = q_centroid - s_est * (R_est @ p_centroid)\n\n        theta_est = np.arctan2(R_est[1, 0], R_est[0, 0])\n\n        # --- 2. Calculate RMS Error ---\n        q_est_landmarks = (s_est * p_landmarks @ R_est.T) + t_est\n        x_est_landmarks = O + q_est_landmarks[:, 0, np.newaxis] * u + q_est_landmarks[:, 1, np.newaxis] * v\n        rms_error = np.sqrt(np.mean(np.sum((x_est_landmarks - x_landmarks)**2, axis=1)))\n\n        # --- 3. Quantify Spatial Uncertainty ---\n        # NOTE: Covariance is constant for all electrodes in this model\n        \n        # Plane basis embedding matrix B and normal n\n        B = np.vstack((u, v)).T\n        n = np.cross(u, v)\n\n        # Propagated covariance from photo noise\n        Sigma_photo_3D = (s_est**2) * (sigma**2) * (B @ B.T)\n        \n        # Covariance from brain shift\n        Sigma_shift = (tau**2) * np.outer(n, n)\n        \n        # Total 3D covariance\n        Sigma_3D = Sigma_photo_3D + Sigma_shift\n\n        # Eigenvalues give variance along principal axes\n        eigvals = np.linalg.eigvalsh(Sigma_3D)\n        \n        # Semi-axis lengths of 95% confidence ellipsoid\n        semi_axes = np.sqrt(q_95_3df * eigvals)\n        \n        # Maximum semi-axis length\n        max_semi_axis = np.max(semi_axes)\n        \n        # Ellipsoid volume\n        ellipsoid_volume = (4.0 / 3.0) * np.pi * np.prod(semi_axes)\n        \n        # Mean volume across electrodes is just the single calculated volume\n        mean_volume = ellipsoid_volume\n\n        # Store results for this case\n        all_results.append(\n            f\"[{s_est},{theta_est},{rms_error},{max_semi_axis},{mean_volume}]\"\n        )\n\n    # Format and print the final output\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n\n```"
        }
    ]
}