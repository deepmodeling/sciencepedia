{
    "hands_on_practices": [
        {
            "introduction": "变分自编码器（VAE）中的证据下界（ELBO）目标函数由两个关键部分组成：重建项和正则化项。本练习将重点关注正则化项，即Kullback-Leibler（KL）散度，它促使近似后验分布与预定义的先验分布保持接近。通过从第一性原理出发推导和计算此项，您将对VAE如何构建其潜空间以促进良好的生成特性获得基础性的理解()。",
            "id": "4139921",
            "problem": "我们训练一个变分自编码器 (VAE) 来建模低维潜在变量，这些变量能够捕捉同时记录的神经元群体中的协调神经活动。对于每个观测到的神经活动向量，编码器会生成一个对角高斯近似后验，其形式为 $q(\\boldsymbol{z}\\mid \\boldsymbol{x})=\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$，其中 $\\boldsymbol{\\Sigma}=\\mathrm{diag}(\\sigma_{1}^{2},\\dots,\\sigma_{k}^{2})$，并且方差通过 $\\log \\sigma_{i}^{2}$ 进行逐元素参数化。先验是标准正态分布 $p(\\boldsymbol{z})=\\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I})$。对于来自一个钙成像数据集的某个特定留出试验，编码器输出了 $k=4$ 个潜在维度，其参数为\n$\\boldsymbol{\\mu}=(0.6,\\,-0.8,\\,0.1,\\,-0.3)^{\\top}$ 和 $\\log \\boldsymbol{\\sigma}^{2}=(-0.2,\\,0.7,\\,-1.0,\\,-0.5)^{\\top}$。\n请仅从 Kullback-Leibler 散度的定义 $ \\mathrm{KL}(q\\parallel p)=\\mathbb{E}_{q}[\\ln q(\\boldsymbol{z})-\\ln p(\\boldsymbol{z})] $ 和多元高斯分布的概率密度函数出发，推导 $\\mathrm{KL}(q\\parallel p)$ 在这种对角情况下的解析表达式（用 $\\boldsymbol{\\mu}$ 和 $\\boldsymbol{\\Sigma}$ 表示），然后用给定的数值进行计算。请以纳特 (nats) 为单位报告最终数值，并将答案四舍五入到 $4$ 位有效数字。",
            "solution": "该问题要求推导对角协方差高斯分布 $q(\\boldsymbol{z})$ 与标准正态分布 $p(\\boldsymbol{z})$ 之间的 Kullback-Leibler (KL) 散度的解析表达式，然后用给定的参数进行数值计算。\n\n### 步骤 1：KL 散度的解析推导\n\n给定 KL 散度的定义：\n$$\n\\mathrm{KL}(q\\parallel p) = \\mathbb{E}_{q}[\\ln q(\\boldsymbol{z}) - \\ln p(\\boldsymbol{z})] = \\mathbb{E}_{q}[\\ln q(\\boldsymbol{z})] - \\mathbb{E}_{q}[\\ln p(\\boldsymbol{z})]\n$$\n近似后验 $q(\\boldsymbol{z})$ 是一个 $k$ 维多元高斯分布，$q(\\boldsymbol{z}) = \\mathcal{N}(\\boldsymbol{z} \\mid \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})$。其概率密度函数 (PDF) 为：\n$$\nq(\\boldsymbol{z}) = \\frac{1}{(2\\pi)^{k/2} |\\boldsymbol{\\Sigma}|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})\\right)\n$$\n该 PDF 的自然对数为：\n$$\n\\ln q(\\boldsymbol{z}) = -\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}| - \\frac{1}{2}(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})\n$$\n先验 $p(\\boldsymbol{z})$ 是一个标准的 $k$ 维正态分布，$p(\\boldsymbol{z})=\\mathcal{N}(\\boldsymbol{z} \\mid \\boldsymbol{0}, \\boldsymbol{I})$，其中 $\\boldsymbol{I}$ 是单位矩阵。其 PDF 为：\n$$\np(\\boldsymbol{z}) = \\frac{1}{(2\\pi)^{k/2} |\\boldsymbol{I}|^{1/2}} \\exp\\left(-\\frac{1}{2}\\boldsymbol{z}^{\\top}\\boldsymbol{I}^{-1}\\boldsymbol{z}\\right) = \\frac{1}{(2\\pi)^{k/2}} \\exp\\left(-\\frac{1}{2}\\boldsymbol{z}^{\\top}\\boldsymbol{z}\\right)\n$$\n先验 PDF 的自然对数为：\n$$\n\\ln p(\\boldsymbol{z}) = -\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\boldsymbol{z}^{\\top}\\boldsymbol{z}\n$$\n现在，我们计算这些对数 PDF 关于 $q(\\boldsymbol{z})$ 的期望。\n\n首先，对于 $\\mathbb{E}_{q}[\\ln q(\\boldsymbol{z})]$：\n$$\n\\mathbb{E}_{q}[\\ln q(\\boldsymbol{z})] = \\mathbb{E}_{q}\\left[-\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}| - \\frac{1}{2}(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})\\right]\n$$\n前两项相对于 $\\boldsymbol{z}$ 是常数，因此它们的期望就是它们自身。我们只需要计算二次型的期望。利用期望的线性和迹算子的技巧：\n\\begin{align*} \\mathbb{E}_{q}\\left[(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})\\right] = \\mathbb{E}_{q}\\left[\\mathrm{tr}\\left((\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})\\right)\\right] \\\\ = \\mathbb{E}_{q}\\left[\\mathrm{tr}\\left(\\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{z}-\\boldsymbol{\\mu})(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\right)\\right] \\\\ = \\mathrm{tr}\\left(\\boldsymbol{\\Sigma}^{-1}\\mathbb{E}_{q}\\left[(\\boldsymbol{z}-\\boldsymbol{\\mu})(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\right]\\right)\\end{align*}\n根据定义，$\\mathbb{E}_{q}\\left[(\\boldsymbol{z}-\\boldsymbol{\\mu})(\\boldsymbol{z}-\\boldsymbol{\\mu})^{\\top}\\right]$ 是 $q(\\boldsymbol{z})$ 的协方差矩阵，即 $\\boldsymbol{\\Sigma}$。\n$$\n\\mathrm{tr}\\left(\\boldsymbol{\\Sigma}^{-1}\\boldsymbol{\\Sigma}\\right) = \\mathrm{tr}(\\boldsymbol{I}_{k}) = k\n$$\n因此，对数后验的期望是：\n$$\n\\mathbb{E}_{q}[\\ln q(\\boldsymbol{z})] = -\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}| - \\frac{k}{2}\n$$\n接下来，对于 $\\mathbb{E}_{q}[\\ln p(\\boldsymbol{z})]$：\n$$\n\\mathbb{E}_{q}[\\ln p(\\boldsymbol{z})] = \\mathbb{E}_{q}\\left[-\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\boldsymbol{z}^{\\top}\\boldsymbol{z}\\right] = -\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\mathbb{E}_{q}[\\boldsymbol{z}^{\\top}\\boldsymbol{z}]\n$$\n为了计算 $\\mathbb{E}_{q}[\\boldsymbol{z}^{\\top}\\boldsymbol{z}]$，我们使用协方差矩阵的性质：$\\mathrm{Cov}_{q}(\\boldsymbol{z}) = \\mathbb{E}_{q}[\\boldsymbol{z}\\boldsymbol{z}^{\\top}] - \\mathbb{E}_{q}[\\boldsymbol{z}]\\mathbb{E}_{q}[\\boldsymbol{z}]^{\\top}$。\n对于 $q(\\boldsymbol{z})$，$\\mathrm{Cov}_{q}(\\boldsymbol{z}) = \\boldsymbol{\\Sigma}$ 且 $\\mathbb{E}_{q}[\\boldsymbol{z}] = \\boldsymbol{\\mu}$。因此：\n$$\n\\boldsymbol{\\Sigma} = \\mathbb{E}_{q}[\\boldsymbol{z}\\boldsymbol{z}^{\\top}] - \\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top} \\implies \\mathbb{E}_{q}[\\boldsymbol{z}\\boldsymbol{z}^{\\top}] = \\boldsymbol{\\Sigma} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}\n$$\n项 $\\boldsymbol{z}^{\\top}\\boldsymbol{z}$ 是一个标量，它是外积 $\\boldsymbol{z}\\boldsymbol{z}^{\\top}$ 的迹。\n$$\n\\mathbb{E}_{q}[\\boldsymbol{z}^{\\top}\\boldsymbol{z}] = \\mathbb{E}_{q}[\\mathrm{tr}(\\boldsymbol{z}\\boldsymbol{z}^{\\top})] = \\mathrm{tr}(\\mathbb{E}_{q}[\\boldsymbol{z}\\boldsymbol{z}^{\\top}]) = \\mathrm{tr}(\\boldsymbol{\\Sigma} + \\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}) = \\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\mathrm{tr}(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top})\n$$\n由于 $\\mathrm{tr}(\\boldsymbol{\\mu}\\boldsymbol{\\mu}^{\\top}) = \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu}$，我们有：\n$$\n\\mathbb{E}_{q}[\\boldsymbol{z}^{\\top}\\boldsymbol{z}] = \\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu}\n$$\n所以，对数先验的期望是：\n$$\n\\mathbb{E}_{q}[\\ln p(\\boldsymbol{z})] = -\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}(\\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu})\n$$\n将这些期望代入 KL 散度公式：\n\\begin{align*}\n\\mathrm{KL}(q\\parallel p) = \\left(-\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}| - \\frac{k}{2}\\right) - \\left(-\\frac{k}{2}\\ln(2\\pi) - \\frac{1}{2}(\\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu})\\right) \\\\\n= -\\frac{1}{2}\\ln|\\boldsymbol{\\Sigma}| - \\frac{k}{2} + \\frac{1}{2}\\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\frac{1}{2}\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu} \\\\\n= \\frac{1}{2}\\left( \\mathrm{tr}(\\boldsymbol{\\Sigma}) + \\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu} - k - \\ln|\\boldsymbol{\\Sigma}| \\right)\n\\end{align*}\n这是通用公式。对于对角协方差矩阵 $\\boldsymbol{\\Sigma} = \\mathrm{diag}(\\sigma_{1}^{2}, \\dots, \\sigma_{k}^{2})$ 的情况，我们有：\n-   $\\mathrm{tr}(\\boldsymbol{\\Sigma}) = \\sum_{i=1}^{k} \\sigma_i^2$\n-   $|\\boldsymbol{\\Sigma}| = \\prod_{i=1}^{k} \\sigma_i^2$\n-   $\\ln|\\boldsymbol{\\Sigma}| = \\sum_{i=1}^{k} \\ln(\\sigma_i^2)$\n此外，$\\boldsymbol{\\mu}^{\\top}\\boldsymbol{\\mu} = \\sum_{i=1}^{k} \\mu_i^2$。将这些代入公式：\n$$\n\\mathrm{KL}(q\\parallel p) = \\frac{1}{2}\\left( \\sum_{i=1}^{k} \\sigma_i^2 + \\sum_{i=1}^{k} \\mu_i^2 - k - \\sum_{i=1}^{k} \\ln(\\sigma_i^2) \\right)\n$$\n重新排列各项并按维度分组，得到最终的解析表达式：\n$$\n\\mathrm{KL}(q\\parallel p) = \\frac{1}{2} \\sum_{i=1}^{k} \\left( \\sigma_i^2 + \\mu_i^2 - 1 - \\ln(\\sigma_i^2) \\right)\n$$\n\n### 步骤 2：数值计算\n\n给定潜在空间维度 $k = 4$ 的以下值：\n-   $\\boldsymbol{\\mu}=(0.6,\\,-0.8,\\,0.1,\\,-0.3)^{\\top}$\n-   $\\log \\boldsymbol{\\sigma}^{2}=(-0.2,\\,0.7,\\,-1.0,\\,-0.5)^{\\top}$，其中向量的分量是 $\\ln(\\sigma_i^2)$。\n\n让我们计算每个维度 $i \\in \\{1, 2, 3, 4\\}$ 的求和分量。注意 $\\sigma_i^2 = \\exp(\\ln(\\sigma_i^2))$。\n\n对于 $i=1$：\n-   $\\mu_1 = 0.6 \\implies \\mu_1^2 = 0.36$\n-   $\\ln(\\sigma_1^2) = -0.2 \\implies \\sigma_1^2 = \\exp(-0.2)$\n-   第1项：$\\exp(-0.2) + 0.36 - 1 - (-0.2) = \\exp(-0.2) - 0.44$\n\n对于 $i=2$：\n-   $\\mu_2 = -0.8 \\implies \\mu_2^2 = 0.64$\n-   $\\ln(\\sigma_2^2) = 0.7 \\implies \\sigma_2^2 = \\exp(0.7)$\n-   第2项：$\\exp(0.7) + 0.64 - 1 - 0.7 = \\exp(0.7) - 1.06$\n\n对于 $i=3$：\n-   $\\mu_3 = 0.1 \\implies \\mu_3^2 = 0.01$\n-   $\\ln(\\sigma_3^2) = -1.0 \\implies \\sigma_3^2 = \\exp(-1.0)$\n-   第3项：$\\exp(-1.0) + 0.01 - 1 - (-1.0) = \\exp(-1.0) + 0.01$\n\n对于 $i=4$：\n-   $\\mu_4 = -0.3 \\implies \\mu_4^2 = 0.09$\n-   $\\ln(\\sigma_4^2) = -0.5 \\implies \\sigma_4^2 = \\exp(-0.5)$\n-   第4项：$\\exp(-0.5) + 0.09 - 1 - (-0.5) = \\exp(-0.5) - 0.41$\n\n总和为：\n\\begin{align*}\n\\sum_{i=1}^{4} \\left( \\sigma_i^2 + \\mu_i^2 - 1 - \\ln(\\sigma_i^2) \\right) = (\\exp(-0.2) - 0.44) + (\\exp(0.7) - 1.06) + (\\exp(-1.0) + 0.01) + (\\exp(-0.5) - 0.41) \\\\\n= \\sum_{i=1}^4 \\sigma_i^2 + \\sum_{i=1}^4 \\mu_i^2 - \\sum_{i=1}^4 1 - \\sum_{i=1}^4 \\ln(\\sigma_i^2) \\\\\n\\end{align*}\n让我们计算各分量的总和：\n-   $\\sum \\mu_i^2 = (0.6)^2 + (-0.8)^2 + (0.1)^2 + (-0.3)^2 = 0.36 + 0.64 + 0.01 + 0.09 = 1.1$\n-   $\\sum \\ln(\\sigma_i^2) = -0.2 + 0.7 - 1.0 - 0.5 = -1.0$\n-   $\\sum \\sigma_i^2 = \\exp(-0.2) + \\exp(0.7) + \\exp(-1.0) + \\exp(-0.5)$\n    $\\approx 0.81873075 + 2.01375271 + 0.36787944 + 0.60653066 \\approx 3.80689356$\n-   $k = 4$\n\n括号内的总和是：\n$$\n\\sum (\\dots) = 3.80689356 + 1.1 - 4 - (-1.0) = 3.80689356 + 1.1 - 4 + 1.0 = 1.90689356\n$$\n最后，KL 散度是：\n$$\n\\mathrm{KL}(q\\parallel p) = \\frac{1}{2} \\times 1.90689356 \\approx 0.95344678\n$$\n四舍五入到 $4$ 位有效数字，我们得到 $0.9534$。单位是纳特 (nats)，因为定义中使用了自然对数。",
            "answer": "$$\\boxed{0.9534}$$"
        },
        {
            "introduction": "在掌握了正则化项之后，我们现在转向ELBO的另一半：重建损失。虽然许多VAE示例假设数据服从高斯分布，但现实世界中的神经科学数据，如神经尖峰计数，通常遵循不同的统计规律。本练习将指导您为泊松（Poisson）分布的数据推导出合适的重建损失，这是将VAE正确应用于神经活动建模的关键一步()。",
            "id": "4139965",
            "problem": "考虑将计数型神经数据建模为在给定一个潜码的条件下，独立的泊松观测。设观测计数是跨越 $D$ 个神经元的向量 $x \\in \\mathbb{N}^{D}$，潜变量为 $z \\in \\mathbb{R}^{K}$。假设似然可分解为 $p(x \\mid z) = \\prod_{d=1}^{D} p(x_{d} \\mid z)$，其中每个 $p(x_{d} \\mid z)$ 是一个速率为 $\\lambda_{d}(z)$ 的 $\\mathrm{Poisson}$ 分布。变分自编码器（VAE）的证据下界中的重构项定义为期望负对数似然 $\\mathbb{E}_{q(z \\mid x)}\\left[-\\ln p(x \\mid z)\\right]$，其中 $q(z \\mid x)$ 是变分后验。请从泊松概率质量函数的定义和期望的基本性质出发，推导泊松似然的重构项 $\\mathbb{E}_{q(z \\mid x)}\\left[-\\ln p(x \\mid z)\\right]$ 的一般形式。然后，对于采用指数非线性的线性解码器定义的速率 $\\lambda_{d}(z) = \\exp\\left(b_{d} + w_{d}^{\\top} z\\right)$ (其中 $d \\in \\{1,\\dots,D\\}$，$w_{d} \\in \\mathbb{R}^{K}$，$b_{d} \\in \\mathbb{R}$)，并假设变分后验为多元正态分布 $q(z \\mid x) = \\mathcal{N}(\\mu, \\Sigma)$ (其均值为 $\\mu \\in \\mathbb{R}^{K}$，协方差矩阵 $\\Sigma \\in \\mathbb{R}^{K \\times K}$ 为对称半正定)，请为重构项中出现的两个期望提供解析闭式表达式。你的最终答案应为 $\\mathbb{E}_{q(z \\mid x)}\\left[-\\ln p(x \\mid z)\\right]$ 的单个解析闭式表达式，用 $x$、$\\{w_{d}\\}_{d=1}^{D}$、$\\{b_{d}\\}_{d=1}^{D}$、$\\mu$ 和 $\\Sigma$ 表示。无需取整。",
            "solution": "目标是推导在变分后验下泊松似然的重构项。我们从基本定义开始。\n\n首先，回顾泊松概率质量函数的定义。对于速率为 $\\lambda_{d}(z)  0$ 的单个计数值 $x_{d} \\in \\mathbb{N}$，其似然为\n$$\np(x_{d} \\mid z) = \\frac{\\lambda_{d}(z)^{x_{d}} \\exp\\left(-\\lambda_{d}(z)\\right)}{x_{d}!}.\n$$\n在 $d \\in \\{1,\\dots,D\\}$ 上条件独立的情况下，\n$$\np(x \\mid z) = \\prod_{d=1}^{D} p(x_{d} \\mid z) = \\prod_{d=1}^{D} \\frac{\\lambda_{d}(z)^{x_{d}} \\exp\\left(-\\lambda_{d}(z)\\right)}{x_{d}!}.\n$$\n取自然对数并加上负号，负对数似然可按维度分解为：\n$$\n-\\ln p(x \\mid z) = \\sum_{d=1}^{D} \\left[ \\lambda_{d}(z) - x_{d} \\ln \\lambda_{d}(z) + \\ln\\left(x_{d}!\\right) \\right].\n$$\n重构项是该量在变分后验 $q(z \\mid x)$ 下的期望：\n$$\n\\mathbb{E}_{q(z \\mid x)}\\left[-\\ln p(x \\mid z)\\right] = \\sum_{d=1}^{D} \\left[ \\mathbb{E}_{q(z \\mid x)}\\left[\\lambda_{d}(z)\\right] - x_{d} \\,\\mathbb{E}_{q(z \\mid x)}\\left[\\ln \\lambda_{d}(z)\\right] + \\ln\\left(x_{d}!\\right) \\right].\n$$\n因此，问题简化为对每个 $d$ 计算 $\\mathbb{E}_{q(z \\mid x)}\\left[\\lambda_{d}(z)\\right]$ 和 $\\mathbb{E}_{q(z \\mid x)}\\left[\\ln \\lambda_{d}(z)\\right]$。\n\n在指定的带有指数非线性的线性解码器下，\n$$\n\\lambda_{d}(z) = \\exp\\left(b_{d} + w_{d}^{\\top} z\\right),\n$$\n并且变分后验是多元正态的，\n$$\nq(z \\mid x) = \\mathcal{N}(\\mu, \\Sigma),\n$$\n其中 $\\mu \\in \\mathbb{R}^{K}$ 且 $\\Sigma \\in \\mathbb{R}^{K \\times K}$ 是对称半正定矩阵。\n\n我们首先计算 $\\mathbb{E}_{q(z \\mid x)}\\left[\\ln \\lambda_{d}(z)\\right]$。利用 $\\lambda_{d}(z)$ 的对数，\n$$\n\\ln \\lambda_{d}(z) = b_{d} + w_{d}^{\\top} z,\n$$\n以及期望的线性性质，\n$$\n\\mathbb{E}_{q(z \\mid x)}\\left[\\ln \\lambda_{d}(z)\\right] = b_{d} + w_{d}^{\\top} \\,\\mathbb{E}_{q(z \\mid x)}[z] = b_{d} + w_{d}^{\\top} \\mu.\n$$\n\n接下来，我们计算 $\\mathbb{E}_{q(z \\mid x)}\\left[\\lambda_{d}(z)\\right] = \\mathbb{E}_{q(z \\mid x)}\\left[\\exp\\left(b_{d} + w_{d}^{\\top} z\\right)\\right]$。根据多元正态分布的性质，当 $z \\sim \\mathcal{N}(\\mu, \\Sigma)$ 时，线性形式 $w_{d}^{\\top} z$ 的矩生成函数意味着\n$$\n\\mathbb{E}_{q(z \\mid x)}\\left[\\exp\\left(w_{d}^{\\top} z\\right)\\right] = \\exp\\left(w_{d}^{\\top} \\mu + \\frac{1}{2} \\, w_{d}^{\\top} \\Sigma \\, w_{d}\\right).\n$$\n因此，\n$$\n\\mathbb{E}_{q(z \\mid x)}\\left[\\lambda_{d}(z)\\right] = \\exp\\left(b_{d}\\right) \\,\\mathbb{E}_{q(z \\mid x)}\\left[\\exp\\left(w_{d}^{\\top} z\\right)\\right] = \\exp\\left(b_{d} + w_{d}^{\\top} \\mu + \\frac{1}{2} \\, w_{d}^{\\top} \\Sigma \\, w_{d}\\right).\n$$\n\n将这些期望代入重构项的分解式中，得到\n$$\n\\mathbb{E}_{q(z \\mid x)}\\left[-\\ln p(x \\mid z)\\right]\n= \\sum_{d=1}^{D} \\left[\n\\exp\\left(b_{d} + w_{d}^{\\top} \\mu + \\frac{1}{2} \\, w_{d}^{\\top} \\Sigma \\, w_{d}\\right)\n- x_{d} \\left(b_{d} + w_{d}^{\\top} \\mu\\right)\n+ \\ln\\left(x_{d}!\\right)\n\\right].\n$$\n这是一个用 $x$、$\\{w_{d}\\}_{d=1}^{D}$、$\\{b_{d}\\}_{d=1}^{D}$、$\\mu$ 和 $\\Sigma$ 表示的解析闭式表达式。这就完成了在多元正态变分后验下，对于带有指数线性解码器的泊松似然的重构项的推导。",
            "answer": "$$\\boxed{\\sum_{d=1}^{D}\\left[\\exp\\left(b_{d}+w_{d}^{\\top}\\mu+\\frac{1}{2}\\,w_{d}^{\\top}\\Sigma\\,w_{d}\\right)-x_{d}\\left(b_{d}+w_{d}^{\\top}\\mu\\right)+\\ln\\!\\left(x_{d}!\\right)\\right]}$$"
        },
        {
            "introduction": "在核心VAE原理的基础上，这最后一个练习解决了一个复杂且高度相关的神经科学挑战：整合来自多种模态的数据，并优雅地处理缺失信息。您将探索一个使用“专家乘积”（product-of-experts）方法来结合信息的多模态VAE，并分析当一个数据源不可用时，模型的不确定性（后验方差）如何自适应地调整。这个练习展示了VAE作为一种原则性生成工具，在稳健的多模态数据分析中的强大能力()。",
            "id": "4139982",
            "problem": "考虑一个用于神经记录的多模态生成模型，该模型具有两个观测模态：$x_A$（例如，电生理学特征）和 $x_B$（例如，钙成像特征）。设潜变量为 $z \\in \\mathbb{R}^k$。生成假设如下：先验为 $p(z) = \\mathcal{N}(0, \\Sigma_0)$，且条件在给定 $z$ 时是独立的，其中 $p(x_A \\mid z) = \\mathcal{N}(W_A z + b_A, \\Sigma_A)$ 且 $p(x_B \\mid z) = \\mathcal{N}(W_B z + b_B, \\Sigma_B)$。假设 $\\Sigma_0$、$\\Sigma_A$ 和 $\\Sigma_B$ 是正定协方差矩阵（为了简化计算，在下面的测试套件中它们是对角的），而 $W_A$、$W_B$ 是已知的观测矩阵。\n\n训练一个带模态丢弃的变分自编码器 (VAE) 意味着，在优化证据下界 (ELBO) 期间，会以一个固定的概率 $d \\in (0,1)$ 随机丢弃某些模态，并且编码器必须为观测模态的任何子集 $S \\subseteq \\{A, B\\}$ 生成一个有效的近似后验 $q(z \\mid x_S)$。对于线性高斯模型，一种有原则的编码器设计采用专家乘积结构，这会产生一个高斯后验，其精度等于先验精度与由观测模态贡献的各专家精度之和。在精确的线性高斯设定下，真实后验 $p(z \\mid x_S)$ 是一个高斯分布，其协方差为\n$$\n\\Sigma_{\\text{post}}(S) \\;=\\; \\left( \\Sigma_0^{-1} \\;+\\; \\sum_{i \\in S} W_i^\\top \\Sigma_i^{-1} W_i \\right)^{-1}.\n$$\n当只观测到一种模态时，后验方差应相对于两种模态都存在的情况有所增加，以进行自适应，其增加的程度与丢失的信息量成正比。\n\n你的任务是实现一个程序，对于给定的参数测试套件，计算当只观测到一种模态时的“适应因子”，该因子定义为\n$$\n\\alpha(S_{\\text{single}}) \\;=\\; \\frac{\\operatorname{tr}\\!\\left(\\Sigma_{\\text{post}}(S_{\\text{single}})\\right)}{\\operatorname{tr}\\!\\left(\\Sigma_{\\text{post}}(\\{A,B\\})\\right)}.\n$$\n迹 $\\operatorname{tr}(\\cdot)$ 作为后验方差的标量总结。请注意，对于给定的观测子集，模态丢弃概率 $d$ 并不会显式出现在精确后验协方差中；它是一种训练技巧，用于确保编码器能够处理缺失的模态。你的程序必须为指定的测试用例计算 $\\alpha(S_{\\text{single}})$。\n\n使用以下潜变量维度 $k=2$ 的测试套件和提供的矩阵：\n\n- 测试用例 1（正常情况，只观测到 $A$）：\n  - 先验协方差 $\\,\\Sigma_0 = \\operatorname{diag}(1.0, 1.0)$。\n  - 模态 $A$：$\\,W_A = \\begin{bmatrix} 1.0  0.0 \\\\ 0.5  0.6 \\\\ 0.0  1.0 \\end{bmatrix}$，$\\,\\Sigma_A = \\operatorname{diag}(0.2, 0.2, 0.2)$。\n  - 模态 $B$：$\\,W_B = \\begin{bmatrix} 0.4  0.3 \\\\ 0.7  -0.1 \\end{bmatrix}$，$\\,\\Sigma_B = \\operatorname{diag}(0.5, 0.3)$。\n\n- 测试用例 2（正常情况，只观测到 $B$）：\n  - 与测试用例 1 中的 $\\,\\Sigma_0$、$\\,W_A$、$\\,\\Sigma_A$、$\\,W_B$、$\\,\\Sigma_B$ 相同。\n\n- 测试用例 3（边界情况：$B$ 噪声极大，只观测到 $B$）：\n  - 先验协方差 $\\,\\Sigma_0 = \\operatorname{diag}(1.0, 1.0)$。\n  - 模态 $A$：$\\,W_A = \\begin{bmatrix} 1.0  0.0 \\\\ 0.5  0.6 \\\\ 0.0  1.0 \\end{bmatrix}$，$\\,\\Sigma_A = \\operatorname{diag}(0.2, 0.2, 0.2)$。\n  - 模态 $B$：$\\,W_B = \\begin{bmatrix} 0.4  0.3 \\\\ 0.7  -0.1 \\end{bmatrix}$，$\\,\\Sigma_B = \\operatorname{diag}(1000.0, 1000.0)$。\n\n- 测试用例 4（边缘情况：$B$ 无信息，只观测到 $B$）：\n  - 先验协方差 $\\,\\Sigma_0 = \\operatorname{diag}(0.5, 0.5)$。\n  - 模态 $A$：$\\,W_A = \\begin{bmatrix} 0.9  0.1 \\\\ 0.4  0.7 \\\\ 0.0  0.5 \\end{bmatrix}$，$\\,\\Sigma_A = \\operatorname{diag}(0.3, 0.3, 0.3)$。\n  - 模态 $B$：$\\,W_B = \\begin{bmatrix} 0.0  0.0 \\\\ 0.0  0.0 \\end{bmatrix}$，$\\,\\Sigma_B = \\operatorname{diag}(1.0, 1.0)$。\n\n- 测试用例 5（各向异性先验，只观测到 $A$）：\n  - 先验协方差 $\\,\\Sigma_0 = \\operatorname{diag}(0.1, 2.0)$。\n  - 模态 $A$：$\\,W_A = \\begin{bmatrix} 1.2  -0.3 \\\\ 0.0  0.8 \\\\ 0.5  0.0 \\end{bmatrix}$，$\\,\\Sigma_A = \\operatorname{diag}(0.15, 0.4, 0.25)$。\n  - 模态 $B$：$\\,W_B = \\begin{bmatrix} 0.2  0.1 \\\\ 0.3  0.5 \\end{bmatrix}$，$\\,\\Sigma_B = \\operatorname{diag}(0.6, 0.6)$。\n\n对每个测试用例，计算：\n- 每个模态的精度贡献，为 $\\,J_i = W_i^\\top \\Sigma_i^{-1} W_i$。\n- 先验精度 $\\,J_0 = \\Sigma_0^{-1}$。\n- 使用上述公式计算观测子集的后验协方差 $\\,\\Sigma_{\\text{post}}(S)$。\n- 两种模态都存在时的后验协方差 $\\,\\Sigma_{\\text{post}}(\\{A,B\\})$。\n- 按定义计算适应因子 $\\,\\alpha(S_{\\text{single}})$。\n\n你的程序应产生单行输出，其中包含测试用例 1 到 5 的适应因子，形式为方括号括起来的逗号分隔列表（例如 $[a_1,a_2,a_3,a_4,a_5]$）。输出必须是浮点数。不涉及物理单位或角度，结果应以原始十进制浮点数形式呈现，不带百分号。",
            "solution": "问题陈述已经过严格审查，并被确定为有效。它在用于线性高斯模型的贝叶斯统计理论中具有科学依据，具备所有必要信息和一致的定义，是适定的，并且表述客观。因此，我们可以继续进行推导和求解。\n\n问题要求我们计算一个适应因子 $\\alpha(S_{\\text{single}})$，它量化了在多模态生成模型中丢弃一个模态时后验方差的增加量。该模型是线性高斯形式的，这是统计建模中一个标准且易于理解的框架。\n\n生成过程定义如下：\n1.  一个潜变量 $z \\in \\mathbb{R}^k$ 从先验分布中抽取：$p(z) = \\mathcal{N}(z \\mid 0, \\Sigma_0)$。\n2.  每个模态 $i \\in \\{A, B\\}$ 的观测数据在以 $z$ 为条件下独立生成：$p(x_i \\mid z) = \\mathcal{N}(x_i \\mid W_i z + b_i, \\Sigma_i)$。\n\n我们的目标是，在给定来自模态子集 $S \\subseteq \\{A, B\\}$ 的观测值的情况下，确定潜变量的后验分布 $p(z \\mid x_S)$。根据贝叶斯定理，后验与先验和观测模态似然的乘积成正比：\n$$\np(z \\mid x_S) \\propto p(z) \\prod_{i \\in S} p(x_i \\mid z)\n$$\n对于线性高斯模型，高斯分布的乘积也是一个高斯分布（在忽略归一化常数的情况下）。处理高斯分布乘积的一种便捷方法是，以“信息形式”对其参数求和。在信息形式中，一个高斯分布 $\\mathcal{N}(\\mu, \\Sigma)$ 由其精度矩阵 $J = \\Sigma^{-1}$ 和势向量 $h = \\Sigma^{-1}\\mu$ 表示。其概率密度函数则与 $\\exp\\left(-\\frac{1}{2}z^\\top J z + h^\\top z\\right)$ 成正比。\n\n后验的精度矩阵 $J_{\\text{post}}(S)$ 是先验的精度矩阵 $J_0 = \\Sigma_0^{-1}$ 与每个观测模态似然的精度贡献之和。来自模态 $i$ 的精度贡献可以从其似然函数 $p(x_i \\mid z)$ 的指数部分推导得出：\n$$\n-\\frac{1}{2} (x_i - W_i z - b_i)^\\top \\Sigma_i^{-1} (x_i - W_i z - b_i)\n$$\n将此二次型对 $z$ 展开，会得到常数项、关于 $z$ 的线性项和关于 $z$ 的二次项。关于 $z$ 的二次项是 $-\\frac{1}{2} z^\\top (W_i^\\top \\Sigma_i^{-1} W_i) z$。这表明来自模态 $i$ 的精度贡献是 $J_i = W_i^\\top \\Sigma_i^{-1} W_i$。\n\n因此，对于一个观测到的模态集合 $S$，其后验精度矩阵是各个精度矩阵之和：\n$$\nJ_{\\text{post}}(S) = J_0 + \\sum_{i \\in S} J_i = \\Sigma_0^{-1} + \\sum_{i \\in S} W_i^\\top \\Sigma_i^{-1} W_i\n$$\n后验协方差 $\\Sigma_{\\text{post}}(S)$ 是后验精度矩阵的逆：\n$$\n\\Sigma_{\\text{post}}(S) = \\left( J_{\\text{post}}(S) \\right)^{-1} = \\left( \\Sigma_0^{-1} + \\sum_{i \\in S} W_i^\\top \\Sigma_i^{-1} W_i \\right)^{-1}\n$$\n这个公式正是问题陈述中提供的公式。协方差矩阵的迹 $\\operatorname{tr}(\\Sigma)$ 是其对角元素之和，这对应于随机向量各个分量的方差之和。它可作为后验分布总不确定性或体积的标量度量。\n\n问题将适应因子 $\\alpha(S_{\\text{single}})$ 定义为仅观测到单个模态时的总后验方差与观测到两个模态时的总后验方差之比：\n$$\n\\alpha(S_{\\text{single}}) = \\frac{\\operatorname{tr}\\! \\left(\\Sigma_{\\text{post}}(S_{\\text{single}})\\right)}{\\operatorname{tr}\\! \\left(\\Sigma_{\\text{post}}(\\{A,B\\})\\right)}\n$$\n该因子预期将大于或等于 1，因为观测更少的数据（丢弃一个模态）不会减少不确定性（即减小后验方差）。分母 $\\operatorname{tr}\\! \\left(\\Sigma_{\\text{post}}(\\{A,B\\})\\right)$ 代表使用完整数据集可实现的最小后验方差。\n\n每个测试用例的计算步骤如下：\n1.  给定参数矩阵 $\\Sigma_0$、$W_A$、$\\Sigma_A$、$W_B$ 和 $\\Sigma_B$。所有协方差矩阵都以对角矩阵形式给出，这简化了它们的求逆过程：对角矩阵的逆是其对角线元素取倒数后形成的对角矩阵。设 $k=2$。\n2.  计算先验精度：$J_0 = \\Sigma_0^{-1}$。\n3.  计算来自模态 $A$ 的精度贡献：$J_A = W_A^\\top \\Sigma_A^{-1} W_A$。\n4.  计算来自模态 $B$ 的精度贡献：$J_B = W_B^\\top \\Sigma_B^{-1} W_B$。所有 $J$ 矩阵的尺寸都将是 $k \\times k$，即 $2 \\times 2$。\n5.  计算完整观测集 $\\{A,B\\}$ 的后验协方差：\n    $$\n    \\Sigma_{\\text{post}}(\\{A,B\\}) = (J_0 + J_A + J_B)^{-1}\n    $$\n6.  计算其迹，$T_{AB} = \\operatorname{tr}\\! \\left(\\Sigma_{\\text{post}}(\\{A,B\\})\\right)$。\n7.  对于给定的单模态子集 $S_{\\text{single}}$（例如 $\\{A\\}$），计算相应的后验协方差：\n    $$\n    \\Sigma_{\\text{post}}(S_{\\text{single}}) = (J_0 + J_i)^{-1} \\quad \\text{其中 } i \\in S_{\\text{single}}\n    $$\n8.  计算其迹，$T_{S} = \\operatorname{tr}\\! \\left(\\Sigma_{\\text{post}}(S_{\\text{single}})\\right)$。\n9.  适应因子是比率 $\\alpha(S_{\\text{single}}) = T_{S} / T_{AB}$。\n\n此过程将为所提供的五个测试用例中的每一个实施。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not used.\n\ndef solve():\n    \"\"\"\n    Computes the adaptation factor for multimodal VAEs under modality dropout\n    for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Test Case 1 (happy path, only A observed)\n        {\n            \"S_single\": \"A\",\n            \"Sigma0_diag\": [1.0, 1.0],\n            \"WA\": np.array([[1.0, 0.0], [0.5, 0.6], [0.0, 1.0]]),\n            \"SigmaA_diag\": [0.2, 0.2, 0.2],\n            \"WB\": np.array([[0.4, 0.3], [0.7, -0.1]]),\n            \"SigmaB_diag\": [0.5, 0.3],\n        },\n        # Test Case 2 (happy path, only B observed)\n        {\n            \"S_single\": \"B\",\n            \"Sigma0_diag\": [1.0, 1.0],\n            \"WA\": np.array([[1.0, 0.0], [0.5, 0.6], [0.0, 1.0]]),\n            \"SigmaA_diag\": [0.2, 0.2, 0.2],\n            \"WB\": np.array([[0.4, 0.3], [0.7, -0.1]]),\n            \"SigmaB_diag\": [0.5, 0.3],\n        },\n        # Test Case 3 (boundary: extremely noisy B, only B observed)\n        {\n            \"S_single\": \"B\",\n            \"Sigma0_diag\": [1.0, 1.0],\n            \"WA\": np.array([[1.0, 0.0], [0.5, 0.6], [0.0, 1.0]]),\n            \"SigmaA_diag\": [0.2, 0.2, 0.2],\n            \"WB\": np.array([[0.4, 0.3], [0.7, -0.1]]),\n            \"SigmaB_diag\": [1000.0, 1000.0],\n        },\n        # Test Case 4 (edge case: uninformative B, only B observed)\n        {\n            \"S_single\": \"B\",\n            \"Sigma0_diag\": [0.5, 0.5],\n            \"WA\": np.array([[0.9, 0.1], [0.4, 0.7], [0.0, 0.5]]),\n            \"SigmaA_diag\": [0.3, 0.3, 0.3],\n            \"WB\": np.array([[0.0, 0.0], [0.0, 0.0]]),\n            \"SigmaB_diag\": [1.0, 1.0],\n        },\n        # Test Case 5 (anisotropic prior, only A observed)\n        {\n            \"S_single\": \"A\",\n            \"Sigma0_diag\": [0.1, 2.0],\n            \"WA\": np.array([[1.2, -0.3], [0.0, 0.8], [0.5, 0.0]]),\n            \"SigmaA_diag\": [0.15, 0.4, 0.25],\n            \"WB\": np.array([[0.2, 0.1], [0.3, 0.5]]),\n            \"SigmaB_diag\": [0.6, 0.6],\n        },\n    ]\n\n    results = []\n    \n    def calculate_adaptation_factor(params):\n        \"\"\"Helper function to perform the calculation for one test case.\"\"\"\n        # Extract parameters\n        S_single = params[\"S_single\"]\n        Sigma0 = np.diag(params[\"Sigma0_diag\"])\n        WA = params[\"WA\"]\n        SigmaA_inv = np.diag(1.0 / np.array(params[\"SigmaA_diag\"]))\n        WB = params[\"WB\"]\n        SigmaB_inv = np.diag(1.0 / np.array(params[\"SigmaB_diag\"]))\n\n        # Calculate precision matrices\n        J0 = np.linalg.inv(Sigma0)\n        JA = WA.T @ SigmaA_inv @ WA\n        JB = WB.T @ SigmaB_inv @ WB\n\n        # Calculate posterior covariance and trace for both modalities\n        J_post_AB = J0 + JA + JB\n        Sigma_post_AB = np.linalg.inv(J_post_AB)\n        trace_AB = np.trace(Sigma_post_AB)\n\n        # Calculate posterior covariance and trace for the single modality case\n        if S_single == \"A\":\n            J_post_single = J0 + JA\n        elif S_single == \"B\":\n            J_post_single = J0 + JB\n        else:\n            # This case should not be reached based on problem description\n            raise ValueError(\"Invalid single modality specified.\")\n            \n        Sigma_post_single = np.linalg.inv(J_post_single)\n        trace_single = np.trace(Sigma_post_single)\n\n        # Compute adaptation factor\n        alpha = trace_single / trace_AB\n        return alpha\n\n    for case in test_cases:\n        result = calculate_adaptation_factor(case)\n        results.append(result)\n\n    # Format the final output string\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}