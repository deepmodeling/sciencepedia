{
    "hands_on_practices": [
        {
            "introduction": "Before Independent Component Analysis can be applied, the data must be properly prepared. This practice focuses on implementing the sphering, or whitening, transform—a critical preprocessing step that decorrelates the sensor data and normalizes its variance. By transforming the covariance matrix of the data to an identity matrix, sphering simplifies the subsequent ICA task into a search for a pure rotation. This exercise will build your understanding of this fundamental process from the ground up, including how to quantify its performance and limitations when working with finite data samples .",
            "id": "4169909",
            "problem": "You will implement sphering, also called whitening, on simulated multichannel data in the context of Independent Component Analysis (ICA). The goal is to construct and verify a linear transform that makes the sample covariance of the transformed data close to the identity matrix, and to quantify deviations caused by finite sample sizes. The derivation and implementation must start from fundamental definitions and observations: A random vector $\\mathbf{x} \\in \\mathbb{R}^m$ has mean $\\boldsymbol{\\mu} = \\mathbb{E}[\\mathbf{x}]$, and covariance $\\mathbf{C}_x = \\mathbb{E}[(\\mathbf{x} - \\boldsymbol{\\mu})(\\mathbf{x} - \\boldsymbol{\\mu})^\\top]$. A sphering transform is a linear map that, applied to zero-mean data $\\mathbf{x}$, yields a transformed vector $\\mathbf{z}$ with population covariance equal to the identity matrix $\\mathbf{I}$. In practice, only finite samples are available, and one can only construct a transform from the sample mean and sample covariance that approximates this population property.\n\nYour program must:\n- Simulate $m$ statistically independent source processes $s_1, \\dots, s_m$ forming the columns of a matrix $\\mathbf{S} \\in \\mathbb{R}^{m \\times N}$, where $N$ is the number of samples. Each $s_i$ should follow a distribution or process chosen so that the components are mutually independent and not all identically Gaussian; examples include Gaussian, Laplace, Student’s $t$, deterministic sinusoids with random phase, sparse pulses, or autoregressive filtered noise. Each $s_i$ must be centered to zero mean and scaled to unit variance so that the sources are comparable.\n- Construct a square mixing matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times m}$ with a prescribed condition number by combining two orthogonal matrices and a set of singular values spanning a ratio equal to the condition number. This yields observed mixtures $\\mathbf{x}_t = \\mathbf{A} \\mathbf{s}_t + \\boldsymbol{\\varepsilon}_t$ for $t = 1, \\dots, N$, where $\\boldsymbol{\\varepsilon}_t$ is additive zero-mean Gaussian noise with specified standard deviation. Stack these as $\\mathbf{X} \\in \\mathbb{R}^{m \\times N}$.\n- Compute a sphering transform using only the sample mean and sample covariance of $\\mathbf{X}$, apply it to form $\\mathbf{Z} \\in \\mathbb{R}^{m \\times N}$, and numerically verify the identity covariance property by estimating the sample covariance $\\hat{\\mathbf{C}}_Z = \\frac{1}{N} \\sum_{t=1}^N \\mathbf{z}_t \\mathbf{z}_t^\\top$.\n- Quantify finite-sample deviations from exact identity using the following metrics computed from $\\hat{\\mathbf{C}}_Z$:\n  1. The mean absolute deviation of the diagonal entries from $1$, that is $\\frac{1}{m} \\sum_{i=1}^m |(\\hat{\\mathbf{C}}_Z)_{ii} - 1|$.\n  2. The maximum absolute off-diagonal entry, that is $\\max_{i \\neq j} |(\\hat{\\mathbf{C}}_Z)_{ij}|$.\n  3. The Frobenius norm of the difference from identity, that is $\\|\\hat{\\mathbf{C}}_Z - \\mathbf{I}\\|_F$.\n- For numerical stability, your implementation may regularize extremely small eigenvalues in constructing the sphering transform, but the regularization must be negligible compared to the scale set by the sample covariance eigenvalues so that it does not dominate the computation.\n\nUse the following test suite, where each case is a tuple $(m, N, \\text{cond}, \\sigma, \\text{seed})$:\n- Case $1$: $(6, 8192, 10, 0.05, 0)$ is the general case with sufficient samples and moderate condition number.\n- Case $2$: $(6, 64, 10, 0.05, 1)$ is a small-sample boundary condition to expose finite-sample deviation.\n- Case $3$: $(6, 4096, 1000, 0.0, 2)$ is an ill-conditioned mixing matrix with no additive noise to probe sensitivity to conditioning.\n- Case $4$: $(10, 2048, 30, 0.2, 3)$ is a higher-dimensional case with substantial noise.\n- Case $5$: $(6, 2048, 1, 0.05, 4)$ is a well-conditioned identity-like mixing matrix baseline.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a triple in the order listed above. Thus, the final output must be of the form $[[d_1,m_1,f_1],[d_2,m_2,f_2],[d_3,m_3,f_3],[d_4,m_4,f_4],[d_5,m_5,f_5]]$, where $d_k$ is the mean absolute diagonal deviation, $m_k$ is the maximum absolute off-diagonal entry, and $f_k$ is the Frobenius norm error for case $k$. All reported quantities must be dimensionless real numbers in decimal format.",
            "solution": "The problem requires the implementation and verification of a sphering (or whitening) data transformation, a crucial preprocessing step in statistical signal processing, particularly for Independent Component Analysis (ICA). The objective of sphering is to apply a linear transformation to a set of observed signals such that the resulting signals are uncorrelated and have unit variance. In other words, the covariance matrix of the sphered data is the identity matrix, $\\mathbf{I}$. This simplifies the subsequent task of ICA, which is to find a rotation of the sphered data that reveals the underlying statistically independent sources. This solution will first derive the sphering transformation from first principles and then describe its numerical implementation and verification.\n\n### Theoretical Foundation of Sphering\n\nLet $\\mathbf{x} \\in \\mathbb{R}^m$ be a random vector representing $m$ observed signals. For simplicity, we assume $\\mathbf{x}$ is centered, meaning its expected value is the zero vector, $\\mathbb{E}[\\mathbf{x}] = \\mathbf{0}$. The covariance matrix of $\\mathbf{x}$ is defined as $\\mathbf{C}_x = \\mathbb{E}[\\mathbf{x} \\mathbf{x}^\\top]$. Sphering consists of finding a linear transformation matrix $\\mathbf{W} \\in \\mathbb{R}^{m \\times m}$ such that the transformed vector $\\mathbf{z} = \\mathbf{W}\\mathbf{x}$ has an identity covariance matrix:\n$$ \\mathbf{C}_z = \\mathbb{E}[\\mathbf{z} \\mathbf{z}^\\top] = \\mathbb{E}[(\\mathbf{W}\\mathbf{x})(\\mathbf{W}\\mathbf{x})^\\top] = \\mathbf{W} \\mathbb{E}[\\mathbf{x} \\mathbf{x}^\\top] \\mathbf{W}^\\top = \\mathbf{W} \\mathbf{C}_x \\mathbf{W}^\\top = \\mathbf{I} $$\nTo find such a matrix $\\mathbf{W}$, we utilize the eigendecomposition of the covariance matrix $\\mathbf{C}_x$. Since $\\mathbf{C}_x$ is a real, symmetric, and positive semi-definite matrix, it can be decomposed as:\n$$ \\mathbf{C}_x = \\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^\\top $$\nwhere $\\mathbf{U}$ is an orthogonal matrix ($\\mathbf{U}\\mathbf{U}^\\top = \\mathbf{U}^\\top \\mathbf{U} = \\mathbf{I}$) whose columns are the eigenvectors of $\\mathbf{C}_x$, and $\\mathbf{\\Lambda}$ is a diagonal matrix whose diagonal entries $\\lambda_1, \\dots, \\lambda_m$ are the corresponding non-negative eigenvalues.\n\nWe seek $\\mathbf{W}$ such that $\\mathbf{W} \\mathbf{C}_x \\mathbf{W}^\\top = \\mathbf{I}$. Substituting the decomposition of $\\mathbf{C}_x$:\n$$ \\mathbf{W} (\\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^\\top) \\mathbf{W}^\\top = \\mathbf{I} $$\nOne valid choice for the sphering matrix $\\mathbf{W}$ is:\n$$ \\mathbf{W} = \\mathbf{\\Lambda}^{-1/2} \\mathbf{U}^\\top $$\nwhere $\\mathbf{\\Lambda}^{-1/2}$ is the diagonal matrix with entries $1/\\sqrt{\\lambda_i}$. Let's verify this choice:\n$$ \\mathbf{C}_z = (\\mathbf{\\Lambda}^{-1/2} \\mathbf{U}^\\top) (\\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^\\top) (\\mathbf{\\Lambda}^{-1/2} \\mathbf{U}^\\top)^\\top = (\\mathbf{\\Lambda}^{-1/2} \\mathbf{U}^\\top) (\\mathbf{U} \\mathbf{\\Lambda} \\mathbf{U}^\\top) (\\mathbf{U} (\\mathbf{\\Lambda}^{-1/2})^\\top) $$\nSince $\\mathbf{\\Lambda}^{-1/2}$ is diagonal, it is symmetric. Thus, $(\\mathbf{\\Lambda}^{-1/2})^\\top = \\mathbf{\\Lambda}^{-1/2}$.\n$$ \\mathbf{C}_z = \\mathbf{\\Lambda}^{-1/2} (\\mathbf{U}^\\top \\mathbf{U}) \\mathbf{\\Lambda} (\\mathbf{U}^\\top \\mathbf{U}) \\mathbf{\\Lambda}^{-1/2} = \\mathbf{\\Lambda}^{-1/2} \\mathbf{I} \\mathbf{\\Lambda} \\mathbf{I} \\mathbf{\\Lambda}^{-1/2} = \\mathbf{\\Lambda}^{-1/2} \\mathbf{\\Lambda} \\mathbf{\\Lambda}^{-1/2} = \\mathbf{I} $$\nThis confirms that $\\mathbf{W} = \\mathbf{\\Lambda}^{-1/2} \\mathbf{U}^\\top$ is a valid sphering matrix. This specific form is often referred to as ZCA-whitening. Note that the sphering matrix is not unique; any subsequent rotation applied to $\\mathbf{z}$ would preserve the identity covariance property.\n\n### Implementation from Finite Samples\n\nIn practice, we have a finite number of samples, organized as a data matrix $\\mathbf{X} \\in \\mathbb{R}^{m \\times N}$, where $N$ is the number of samples. The population parameters (mean and covariance) are unknown and must be estimated from this data.\n\n1.  **Data Centering**: First, we estimate the mean vector $\\hat{\\boldsymbol{\\mu}}_X = \\frac{1}{N} \\sum_{t=1}^N \\mathbf{x}_t$ and center the data by subtracting this mean from each sample: $\\tilde{\\mathbf{X}} = \\mathbf{X} - \\hat{\\boldsymbol{\\mu}}_X$.\n\n2.  **Sample Covariance**: Next, we compute the sample covariance matrix. Following the problem's specified formula for the transformed data's covariance, we use the estimator $\\hat{\\mathbf{C}}_X = \\frac{1}{N} \\tilde{\\mathbf{X}} \\tilde{\\mathbf{X}}^\\top$.\n\n3.  **Eigendecomposition**: We perform an eigendecomposition on the estimated covariance matrix: $\\hat{\\mathbf{C}}_X = \\hat{\\mathbf{U}} \\hat{\\mathbf{\\Lambda}} \\hat{\\mathbf{U}}^\\top$.\n\n4.  **Sphering Matrix Construction**: The sample-based sphering matrix $\\hat{\\mathbf{W}}$ is constructed analogously to the population case: $\\hat{\\mathbf{W}} = \\hat{\\mathbf{\\Lambda}}^{-1/2} \\hat{\\mathbf{U}}^\\top$. To handle numerical instability from very small or zero eigenvalues (which can occur due to finite-sample effects, high data correlation, or if $N < m$), a small regularization constant $\\epsilon > 0$ is added to the eigenvalues before taking the inverse square root. The matrix of inverse square roots of eigenvalues becomes $\\text{diag}(1/\\sqrt{\\hat{\\lambda}_i + \\epsilon})$. Thus, the regularized sphering matrix is $\\hat{\\mathbf{W}} = (\\hat{\\mathbf{\\Lambda}} + \\epsilon \\mathbf{I})^{-1/2} \\hat{\\mathbf{U}}^\\top$. The value of $\\epsilon$ should be small enough to not significantly alter the result, such as $10^{-12}$.\n\n5.  **Transformation**: The centered data $\\tilde{\\mathbf{X}}$ is then transformed to yield the sphered data $\\mathbf{Z} = \\hat{\\mathbf{W}} \\tilde{\\mathbf{X}}$.\n\n### Algorithmic Steps and Verification\n\nThe overall procedure for each test case is as follows:\n\n1.  **Generate Sources**: For a given number of channels $m$ and samples $N$, we create an $m \\times N$ source matrix S. Each row represents an independent source signal. To satisfy the ICA-related condition that sources are not all Gaussian, we use a mix of distributions (e.g., Gaussian, Laplace, Uniform, Sinusoidal). Each generated source signal is then standardized to have a sample mean of $0$ and a sample variance of $1$.\n\n2.  **Construct Mixing Matrix**: A mixing matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times m}$ with a prescribed condition number $\\kappa$ is created. This is achieved by forming $\\mathbf{A} = \\mathbf{P} \\mathbf{\\Sigma} \\mathbf{Q}^\\top$, where $\\mathbf{P}$ and $\\mathbf{Q}$ are random orthogonal matrices and $\\mathbf{\\Sigma}$ is a diagonal matrix of singular values geometrically spaced between $\\kappa$ and $1$. For instance, $\\Sigma_{ii} = \\kappa^{(m-i)/(m-1)}$ for $i=1, \\dots, m$.\n\n3.  **Mix Data**: The observed data matrix $\\mathbf{X}$ is simulated using the linear mixing model $\\mathbf{X} = \\mathbf{A}\\mathbf{S} + \\mathcal{E}$, where $\\mathcal{E}$ is an $m \\times N$ matrix of i.i.d. Gaussian noise with mean $0$ and standard deviation $\\sigma$.\n\n4.  **Apply Sphering**: The sphering procedure described above is applied to the data matrix $\\mathbf{X}$ to obtain the sphered data matrix $\\mathbf{Z}$.\n\n5.  **Evaluate Performance**: The sample covariance of the sphered data, $\\hat{\\mathbf{C}}_Z = \\frac{1}{N} \\mathbf{Z} \\mathbf{Z}^\\top$, is computed. We expect this matrix to be close to the identity matrix $\\mathbf{I}$. Deviations due to finite sample size, noise, and conditioning are quantified using three metrics:\n    a.  **Mean Absolute Diagonal Deviation**: $d = \\frac{1}{m} \\sum_{i=1}^m |(\\hat{\\mathbf{C}}_Z)_{ii} - 1|$. This measures how well the variances have been scaled to unity.\n    b.  **Maximum Absolute Off-Diagonal Entry**: $m_{od} = \\max_{i \\neq j} |(\\hat{\\mathbf{C}}_Z)_{ij}|$. This measures how well the data has been decorrelated.\n    c.  **Frobenius Norm Error**: $f = \\|\\hat{\\mathbf{C}}_Z - \\mathbf{I}\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m |(\\hat{\\mathbf{C}}_Z)_{ij} - \\delta_{ij}|^2}$, where $\\delta_{ij}$ is the Kronecker delta. This provides an aggregate measure of the deviation from identity.\n\nThese steps are repeated for each test case defined in the problem, using the specified random seed to ensure reproducibility.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to run the sphering simulation for all test cases.\n    \"\"\"\n    test_cases = [\n        # (m, N, cond, sigma, seed)\n        (6, 8192, 10, 0.05, 0),\n        (6, 64, 10, 0.05, 1),\n        (6, 4096, 1000, 0.0, 2),\n        (10, 2048, 30, 0.2, 3),\n        (6, 2048, 1, 0.05, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        m, N, cond, sigma, seed = case\n        metrics = run_sphering_simulation(m, N, cond, sigma, seed)\n        results.append(metrics)\n\n    # Format the final output string as a list of lists.\n    output_str = \"[\" + \",\".join(str(r) for r in results) + \"]\"\n    print(output_str)\n\ndef run_sphering_simulation(m, N, cond, sigma, seed):\n    \"\"\"\n    Executes one full simulation case: data generation, sphering, and metric calculation.\n\n    Args:\n        m (int): Number of channels/sources.\n        N (int): Number of samples.\n        cond (float): Condition number of the mixing matrix.\n        sigma (float): Standard deviation of additive Gaussian noise.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        list: A list containing the three calculated metrics [d, m_od, f].\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Simulate independent sources\n    S = np.zeros((m, N))\n    for i in range(m):\n        dist_type = i % 4\n        if dist_type == 0:  # Gaussian\n            s_i = rng.standard_normal(N)\n        elif dist_type == 1:  # Laplace\n            s_i = rng.laplace(0, 1, N)\n        elif dist_type == 2:  # Uniform\n            s_i = rng.uniform(-np.sqrt(3), np.sqrt(3), N)\n        else:  # Sinusoid\n            t = np.arange(N) / N\n            freq = rng.uniform(2, 6)\n            phase = rng.uniform(0, 2 * np.pi)\n            s_i = np.sqrt(2) * np.sin(2 * np.pi * freq * t + phase)\n        \n        # Standardize to zero mean and unit variance\n        s_i = (s_i - np.mean(s_i)) / np.std(s_i)\n        S[i, :] = s_i\n\n    # 2. Construct the mixing matrix A\n    U = ortho_group.rvs(dim=m, random_state=rng)\n    V = ortho_group.rvs(dim=m, random_state=rng)\n    \n    if m > 1:\n        singular_values = np.geomspace(cond, 1, m)\n    else:\n        singular_values = np.array([cond])\n\n    Sigma = np.diag(singular_values)\n    A = U @ Sigma @ V.T\n\n    # 3. Generate observed data X\n    noise = rng.normal(0, sigma, (m, N))\n    X = A @ S + noise\n\n    # 4. Compute and apply the sphering transform\n    # Center the data\n    mean_X = np.mean(X, axis=1, keepdims=True)\n    X_centered = X - mean_X\n\n    # Compute sample covariance matrix\n    C_X = (X_centered @ X_centered.T) / N\n\n    # Eigendecomposition of the covariance matrix\n    # np.linalg.eigh is used for symmetric matrices\n    eigenvalues, eigenvectors = np.linalg.eigh(C_X)\n\n    # Regularization for numerical stability\n    epsilon = 1e-12\n    \n    # Construct sphering matrix W\n    inv_sqrt_eigenvalues = 1.0 / np.sqrt(eigenvalues + epsilon)\n    W = np.diag(inv_sqrt_eigenvalues) @ eigenvectors.T\n    \n    # Apply sphering transform\n    Z = W @ X_centered\n\n    # 5. Verify and quantify deviations\n    # Compute the sample covariance of the sphered data\n    C_Z = (Z @ Z.T) / N\n\n    # Metric 1: Mean absolute deviation of diagonal entries from 1\n    diag_dev = np.mean(np.abs(np.diag(C_Z) - 1))\n\n    # Metric 2: Maximum absolute off-diagonal entry\n    C_Z_off_diag = C_Z.copy()\n    np.fill_diagonal(C_Z_off_diag, 0)\n    max_off_diag = np.max(np.abs(C_Z_off_diag))\n    \n    # Metric 3: Frobenius norm of the difference from identity\n    frobenius_norm = np.linalg.norm(C_Z - np.eye(m), 'fro')\n\n    return [diag_dev, max_off_diag, frobenius_norm]\n\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "Once ICA has successfully decomposed the observed signals into a set of statistically independent components, the central challenge becomes identifying which components correspond to neural sources and which represent artifacts. This practice guides you through the development of an automated classifier to identify ocular artifacts, a common and powerful application of ICA in EEG/MEG analysis. You will implement a classifier based on canonical features of ocular activity—such as high kurtosis and temporal autocorrelation—and evaluate its performance, providing a robust template for building custom artifact detection tools .",
            "id": "4169969",
            "problem": "You are given the task of deriving and implementing a classifier to detect ocular independent components in an Independent Component Analysis (ICA) decomposition of electroencephalography data. The classifier must rely on three measurable features of each component: kurtosis of the component time course, lag-one autocorrelation of the component time course, and the correlation of the component’s spatial map with an Electrooculogram (EOG) template. You must also implement a performance analysis using Receiver Operating Characteristic (ROC) curves and compute the Area Under the Curve (AUC).\n\nBegin from the following foundational base:\n\n- Independent Component Analysis (ICA) models observed multichannel data as a linear mixture of statistically independent sources, expressed as $\\mathbf{X} = \\mathbf{A} \\mathbf{S}$, where $\\mathbf{X} \\in \\mathbb{R}^{C \\times T}$ is the sensor data with $C$ channels and $T$ time points, $\\mathbf{A} \\in \\mathbb{R}^{C \\times N}$ is the mixing matrix whose columns are spatial maps, and $\\mathbf{S} \\in \\mathbb{R}^{N \\times T}$ is the source matrix with $N$ independent components.\n- Ocular components are characterized by heavy-tailed time courses due to blinks and saccades, slow temporal dynamics (high autocorrelation), and spatial maps that correlate with an EOG-like topography emphasizing frontal sensors.\n- Use well-tested definitions:\n  - For a time series $x_{1:T}$, sample mean is $\\mu = \\frac{1}{T} \\sum_{t=1}^{T} x_t$ and sample variance is $\\sigma^2 = \\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^2$.\n  - Excess kurtosis is $$K = \\frac{\\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^4}{\\left( \\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^2 \\right)^2} - 3$$\n  - Lag-one autocorrelation is $$\\rho_1 = \\frac{\\sum_{t=2}^{T} (x_t - \\mu)(x_{t-1} - \\mu)}{\\sum_{t=1}^{T} (x_t - \\mu)^2}$$\n  - Pearson correlation between two vectors $\\mathbf{u}, \\mathbf{v} \\in \\mathbb{R}^C$ is $$r(\\mathbf{u}, \\mathbf{v}) = \\frac{\\sum_{i=1}^{C} (u_i - \\bar{u})(v_i - \\bar{v})}{\\sqrt{\\sum_{i=1}^{C} (u_i - \\bar{u})^2} \\sqrt{\\sum_{i=1}^{C} (v_i - \\bar{v})^2}}$$, where $\\bar{u}$ and $\\bar{v}$ are means.\n\nYou must derive a decision score based on the feature vector $\\mathbf{f} = [K, \\rho_1, |\\rho_{\\text{map}}|]^\\top$, where $|\\rho_{\\text{map}}|$ is the absolute Pearson correlation between the independent component’s spatial map and an EOG template, accounting for arbitrary polarity. Under the assumption that $\\mathbf{f}$ is approximately class-conditionally Gaussian with diagonal covariance for ocular ($y=1$) and non-ocular ($y=0$) components, derive the linear log-likelihood ratio score $s(\\mathbf{f})$ up to an additive constant using class means and variances. You must implement training of the classifier weights from labeled synthetic data by estimating class means and variances. You must then compute ROC and AUC using the decision scores and ground-truth labels.\n\nTo make the problem fully testable and scientifically realistic while remaining self-contained, you must synthesize independent components as follows:\n\n- For ocular components, generate time courses by an autoregressive process of order $1$ (AR(1)) with parameter $\\phi_o \\in (0,1)$, Laplace-distributed innovations to induce heavy tails, and additive blink events modeled by localized pulses. For non-ocular components, use AR(1) with parameter $\\phi_b \\in (0,1)$ and Gaussian innovations. For each component, compute $K$ and $\\rho_1$ from the generated time course.\n- For spatial maps, construct an EOG template $\\mathbf{e} \\in \\mathbb{R}^C$ on a unit circle sensor layout by placing sensors at equally spaced angles and defining $e_i$ to emphasize the frontal half (positive $y$ axis). Generate ocular maps as $\\mathbf{m} = \\mathbf{e} + \\boldsymbol{\\eta}$ with small Gaussian noise $\\boldsymbol{\\eta}$, and non-ocular maps as Gaussian noise with weak or no correlation to $\\mathbf{e}$. Compute $|\\rho_{\\text{map}}|$ as the absolute Pearson correlation between $\\mathbf{m}$ and $\\mathbf{e}$.\n\nYour program must:\n- Implement the feature extraction and classifier derivation as above.\n- Train the linear classifier weights $\\mathbf{w} \\in \\mathbb{R}^3$ from the empirical class means and pooled diagonal variances, making the decision score $s(\\mathbf{f}) = \\mathbf{w}^\\top \\mathbf{f}$.\n- Compute the ROC by sweeping thresholds over the decision scores and report the AUC using the trapezoidal rule.\n\nDesign a test suite with diverse parameter regimes:\n- Test Case $1$ (happy path): seed $0$, $N=120$ components, $T=3000$ time points, $C=64$ channels, ocular fraction $0.25$, $\\phi_o=0.95$, $\\phi_b=0.40$, Laplace scale $0.8$, blink rate per time point $0.02$, ocular map noise standard deviation $0.20$, brain map noise standard deviation $1.00$.\n- Test Case $2$ (high map noise, overlap): seed $1$, $N=120$, $T=3000$, $C=64$, ocular fraction $0.25$, $\\phi_o=0.93$, $\\phi_b=0.45$, Laplace scale $0.7$, blink rate $0.015$, ocular map noise standard deviation $0.70$, brain map noise standard deviation $1.10$.\n- Test Case $3$ (near-perfect separation): seed $2$, $N=100$, $T=2500$, $C=64$, ocular fraction $0.25$, $\\phi_o=0.98$, $\\phi_b=0.25$, Laplace scale $1.2$, blink rate $0.020$, ocular map noise standard deviation $0.05$, brain map noise standard deviation $1.20$.\n- Test Case $4$ (small sample): seed $3$, $N=25$, $T=800$, $C=64$, ocular fraction $0.20$, $\\phi_o=0.94$, $\\phi_b=0.35$, Laplace scale $0.9$, blink rate $0.015$, ocular map noise standard deviation $0.30$, brain map noise standard deviation $1.00$.\n\nYour program should produce a single line of output containing the AUC values for Test Cases $1$ to $4$, as a comma-separated list enclosed in square brackets (e.g., $[0.95,0.88,0.99,0.82]$). No physical units are involved in this problem. Angles are in radians for sensor layout, but you do not need to output angles. All numeric outputs in the final list must be floats.",
            "solution": "The problem requires the derivation and implementation of a linear classifier to identify ocular independent components from electroencephalography (EEG) data. The classification is based on a three-dimensional feature vector, and its performance is evaluated using Receiver Operating Characteristic (ROC) analysis. The problem is well-posed, scientifically sound, and provides sufficient detail for a complete and reproducible solution.\n\n### Classifier Derivation\n\nThe objective is to classify an independent component as either ocular ($y=1$) or non-ocular ($y=0$) based on its feature vector $\\mathbf{f} = [f_1, f_2, f_3]^\\top = [K, \\rho_1, |\\rho_{\\text{map}}|]^\\top$. Here, $K$ is the excess kurtosis of the component time course, $\\rho_1$ is its lag-one autocorrelation, and $|\\rho_{\\text{map}}|$ is the absolute Pearson correlation of its spatial map with a canonical Electrooculogram (EOG) template.\n\nWe will employ Bayesian decision theory. The optimal decision rule is to classify the component as ocular if its posterior probability is higher than that of being non-ocular, i.e., $p(y=1|\\mathbf{f}) > p(y=0|\\mathbf{f})$. Using Bayes' theorem, $p(y|\\mathbf{f}) = \\frac{p(\\mathbf{f}|y)P(y)}{p(\\mathbf{f})}$, this inequality is equivalent to:\n$$\n\\log\\frac{p(y=1|\\mathbf{f})}{p(y=0|\\mathbf{f})} = \\log\\frac{p(\\mathbf{f}|y=1)}{p(\\mathbf{f}|y=0)} + \\log\\frac{P(y=1)}{P(y=0)} > 0\n$$\nThe first term is the log-likelihood ratio, and the second is the log-prior odds. The decision score, $s(\\mathbf{f})$, is typically defined from the log-posterior ratio.\n\nThe problem states to assume that the features are class-conditionally Gaussian with a diagonal covariance matrix:\n$$\np(\\mathbf{f}|y=c) \\sim \\mathcal{N}(\\boldsymbol{\\mu}_c, \\mathbf{\\Sigma}_c), \\quad \\text{where } c \\in \\{0, 1\\} \\text{ and } \\mathbf{\\Sigma}_c = \\text{diag}(\\sigma_{c,1}^2, \\sigma_{c,2}^2, \\sigma_{c,3}^2)\n$$\nThe log-probability density function for class $c$ is:\n$$\n\\log p(\\mathbf{f}|y=c) = -\\frac{1}{2} \\sum_{j=1}^{3} \\left( \\frac{(f_j - \\mu_{c,j})^2}{\\sigma_{c,j}^2} \\right) - \\frac{1}{2} \\sum_{j=1}^{3} \\log(2\\pi\\sigma_{c,j}^2)\n$$\nThe problem specifies the derivation of a *linear* classifier score, $s(\\mathbf{f}) = \\mathbf{w}^\\top \\mathbf{f}$, based on *pooled* diagonal variances. This corresponds to the framework of Linear Discriminant Analysis (LDA), which makes the simplifying assumption of a common covariance matrix for all classes: $\\mathbf{\\Sigma}_1 = \\mathbf{\\Sigma}_0 = \\mathbf{\\Sigma}_{\\text{pooled}}$.\n\nUnder this assumption, the log-likelihood ratio becomes:\n$$\n\\log\\frac{p(\\mathbf{f}|y=1)}{p(\\mathbf{f}|y=0)} = \\log p(\\mathbf{f}|y=1) - \\log p(\\mathbf{f}|y=0)\n$$\nSubstituting the Gaussian PDF and noting that the $\\log(2\\pi |\\mathbf{\\Sigma}_{\\text{pooled}}|)$ terms are identical and cancel:\n$$\n= \\left[ -\\frac{1}{2}(\\mathbf{f} - \\boldsymbol{\\mu}_1)^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} (\\mathbf{f} - \\boldsymbol{\\mu}_1) \\right] - \\left[ -\\frac{1}{2}(\\mathbf{f} - \\boldsymbol{\\mu}_0)^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} (\\mathbf{f} - \\boldsymbol{\\mu}_0) \\right]\n$$\nExpanding the quadratic forms:\n$$\n= -\\frac{1}{2} \\left[ (\\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\mathbf{f} - 2\\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_1 + \\boldsymbol{\\mu}_1^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_1) - (\\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\mathbf{f} - 2\\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_0 + \\boldsymbol{\\mu}_0^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_0) \\right]\n$$\nThe quadratic term in $\\mathbf{f}$, $\\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\mathbf{f}$, cancels out, yielding a linear function of $\\mathbf{f}$:\n$$\n= \\mathbf{f}^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0) - \\frac{1}{2} (\\boldsymbol{\\mu}_1^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0^\\top \\mathbf{\\Sigma}_{\\text{pooled}}^{-1} \\boldsymbol{\\mu}_0)\n$$\nThe decision score $s(\\mathbf{f})$ is defined as the part of the log-posterior ratio that depends on the observation $\\mathbf{f}$. Ignoring the constant bias term (which can be absorbed into the decision threshold), we obtain the linear score:\n$$\ns(\\mathbf{f}) = \\mathbf{w}^\\top \\mathbf{f} \\quad \\text{where} \\quad \\mathbf{w} = \\mathbf{\\Sigma}_{\\text{pooled}}^{-1}(\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0)\n$$\nGiven the diagonal structure of $\\mathbf{\\Sigma}_{\\text{pooled}} = \\text{diag}(\\sigma_{\\text{pooled},1}^2, \\sigma_{\\text{pooled},2}^2, \\sigma_{\\text{pooled},3}^2)$, its inverse is $\\mathbf{\\Sigma}_{\\text{pooled}}^{-1} = \\text{diag}(1/\\sigma_{\\text{pooled},1}^2, 1/\\sigma_{\\text{pooled},2}^2, 1/\\sigma_{\\text{pooled},3}^2)$. The components of the weight vector $\\mathbf{w}$ are thus:\n$$\nw_j = \\frac{\\mu_{1,j} - \\mu_{0,j}}{\\sigma_{\\text{pooled},j}^2} \\quad \\text{for } j=1, 2, 3\n$$\n\n### Parameter Estimation (Training)\n\nThe parameters $\\boldsymbol{\\mu}_0$, $\\boldsymbol{\\mu}_1$, and $\\mathbf{\\Sigma}_{\\text{pooled}}$ are estimated from a set of labeled training data containing $N_0$ non-ocular and $N_1$ ocular components.\n1.  **Class Means**: The means for each feature $j$ and class $c$ are estimated as the sample mean:\n    $$\n    \\hat{\\mu}_{c,j} = \\frac{1}{N_c} \\sum_{i \\in \\text{class } c} f_{i,j}\n    $$\n2.  **Class Variances**: The unbiased sample variance for each feature $j$ and class $c$ is:\n    $$\n    \\hat{\\sigma}_{c,j}^2 = \\frac{1}{N_c - 1} \\sum_{i \\in \\text{class } c} (f_{i,j} - \\hat{\\mu}_{c,j})^2\n    $$\n3.  **Pooled Variance**: The pooled variance for each feature $j$ is the weighted average of the class variances:\n    $$\n    \\sigma_{\\text{pooled},j}^2 = \\frac{(N_0 - 1)\\hat{\\sigma}_{0,j}^2 + (N_1 - 1)\\hat{\\sigma}_{1,j}^2}{N_0 + N_1 - 2}\n    $$\nThese estimated parameters are then used to compute the weight vector $\\mathbf{w}$, completing the classifier training.\n\n### Performance Evaluation\n\nThe Receiver Operating Characteristic (ROC) curve is used to evaluate the classifier's performance across all possible decision thresholds. The ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR).\n-   $TPR = \\frac{\\text{True Positives}}{\\text{Total Positives}} = \\frac{TP}{TP+FN}$\n-   $FPR = \\frac{\\text{False Positives}}{\\text{Total Negatives}} = \\frac{FP}{FP+TN}$\n\nThe Area Under the Curve (AUC) provides a single scalar metric for performance. An AUC of $1.0$ represents a perfect classifier, while an AUC of $0.5$ corresponds to random guessing. The AUC is calculated by integrating the ROC curve, which is numerically computed using the trapezoidal rule on the set of $(FPR, TPR)$ points generated by varying the decision threshold.\n\n### Implementation Strategy\n\nThe solution involves a simulation process for each test case:\n1.  **Data Synthesis**: Generate $N$ independent components, each with a time course, a spatial map, and a ground-truth label (ocular/non-ocular).\n    -   Time courses are generated via an AR($1$) process, $x_t = \\phi x_{t-1} + \\epsilon_t$, with specified $\\phi$ and innovation distributions (Laplace for ocular, Gaussian for non-ocular). Ocular components receive additional high-amplitude, localized pulses to simulate blinks.\n    -   Spatial maps are generated relative to an EOG template. The template can be modeled on a unit circle of sensors as $e_i = \\sin(\\theta_i)$, creating a bipolar frontal-posterior topography. Ocular maps are this template plus small noise; non-ocular maps are random noise.\n2.  **Feature Extraction**: For each synthetic component, compute the three features $K$, $\\rho_1$, and $|\\rho_{\\text{map}}|$ according to the provided formulas.\n3.  **Classifier Training**: Using the full set of generated features and labels, estimate the parameters $\\hat{\\boldsymbol{\\mu}}_0, \\hat{\\boldsymbol{\\mu}}_1, \\sigma^2_{\\text{pooled}}$ and compute the weight vector $\\mathbf{w}$.\n4.  **Scoring and Evaluation**: Calculate the decision score $s_i = \\mathbf{w}^\\top \\mathbf{f}_i$ for each component $i$. Using these scores and the ground-truth labels, compute the ROC curve and the AUC. The final output is the list of AUC values for all test cases.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import lfilter\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1 (happy path)\n        {\"seed\": 0, \"N\": 120, \"T\": 3000, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.95, \"phi_b\": 0.40, \"laplace_scale\": 0.8,\n         \"blink_rate\": 0.02, \"ocular_map_noise_std\": 0.20,\n         \"brain_map_noise_std\": 1.00},\n        # Test Case 2 (high map noise, overlap)\n        {\"seed\": 1, \"N\": 120, \"T\": 3000, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.93, \"phi_b\": 0.45, \"laplace_scale\": 0.7,\n         \"blink_rate\": 0.015, \"ocular_map_noise_std\": 0.70,\n         \"brain_map_noise_std\": 1.10},\n        # Test Case 3 (near-perfect separation)\n        {\"seed\": 2, \"N\": 100, \"T\": 2500, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.98, \"phi_b\": 0.25, \"laplace_scale\": 1.2,\n         \"blink_rate\": 0.020, \"ocular_map_noise_std\": 0.05,\n         \"brain_map_noise_std\": 1.20},\n        # Test Case 4 (small sample)\n        {\"seed\": 3, \"N\": 25, \"T\": 800, \"C\": 64, \"ocular_fraction\": 0.20,\n         \"phi_o\": 0.94, \"phi_b\": 0.35, \"laplace_scale\": 0.9,\n         \"blink_rate\": 0.015, \"ocular_map_noise_std\": 0.30,\n         \"brain_map_noise_std\": 1.00},\n    ]\n\n    results = []\n    for params in test_cases:\n        auc = run_simulation(params)\n        results.append(auc)\n        \n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\n\ndef run_simulation(params):\n    \"\"\"\n    Executes a single simulation run for a given set of parameters.\n    \"\"\"\n    np.random.seed(params[\"seed\"])\n    \n    # 1. Generate synthetic data\n    components, labels, eog_template = generate_synthetic_data(params)\n    \n    # 2. Extract features\n    features = np.array([extract_features(comp, eog_template) for comp in components])\n    \n    # 3. Train LDA classifier\n    weights = train_lda_weights(features, labels)\n    \n    # 4. Calculate decision scores\n    scores = features @ weights\n    \n    # 5. Compute AUC\n    auc = compute_auc(scores, labels)\n    \n    return auc\n\n\ndef generate_synthetic_data(params):\n    \"\"\"\n    Generates synthetic independent components (time courses and spatial maps).\n    \"\"\"\n    N = params[\"N\"]\n    T = params[\"T\"]\n    C = params[\"C\"]\n    ocular_fraction = params[\"ocular_fraction\"]\n    \n    # Determine labels for each component\n    n_ocular = int(N * ocular_fraction)\n    labels = np.array([1] * n_ocular + [0] * (N - n_ocular))\n    \n    # Generate EOG template for spatial maps\n    sensor_angles = np.linspace(0, 2 * np.pi, C, endpoint=False)\n    eog_template = np.sin(sensor_angles) # Bipolar template (frontal positive, posterior negative)\n\n    components = []\n    for i in range(N):\n        is_ocular = (labels[i] == 1)\n        \n        # Generate time course\n        if is_ocular:\n            phi = params[\"phi_o\"]\n            innovations = np.random.laplace(loc=0, scale=params[\"laplace_scale\"], size=T)\n        else:\n            phi = params[\"phi_b\"]\n            innovations = np.random.normal(loc=0, scale=1.0, size=T)\n\n        # AR(1) process: x_t = phi * x_{t-1} + e_t\n        time_course = lfilter([1], [1, -phi], innovations)\n        \n        # Add blink artifacts to ocular components\n        if is_ocular:\n            blink_rate = params[\"blink_rate\"]\n            pulse_width = 50\n            # Use Hanning window for smooth pulse shape\n            blink_pulse = np.hanning(pulse_width) * 20 * np.std(time_course) \n            blink_indices = np.where(np.random.rand(T)  blink_rate)[0]\n            for idx in blink_indices:\n                if idx + pulse_width  T:\n                    time_course[idx:idx+pulse_width] += blink_pulse\n        \n        # Generate spatial map\n        if is_ocular:\n            noise = np.random.normal(0, params[\"ocular_map_noise_std\"], size=C)\n            spatial_map = eog_template + noise\n        else:\n            spatial_map = np.random.normal(0, params[\"brain_map_noise_std\"], size=C)\n        \n        components.append((time_course, spatial_map))\n        \n    return components, labels, eog_template\n\n\ndef extract_features(component, eog_template):\n    \"\"\"\n    Extracts the three features (K, rho_1, |rho_map|) from a component.\n    \"\"\"\n    time_course, spatial_map = component\n    T = len(time_course)\n    \n    # Center the time course\n    mu = np.mean(time_course)\n    x_centered = time_course - mu\n    \n    # Calculate moments\n    m2 = np.mean(x_centered**2)\n    m4 = np.mean(x_centered**4)\n    \n    # Feature 1: Excess Kurtosis\n    if m2  1e-9: # Avoid division by zero\n        kurtosis = 0.0\n    else:\n        kurtosis = m4 / (m2**2) - 3.0\n    \n    # Feature 2: Lag-one Autocorrelation\n    # rho_1 = sum_{t=2 to T} (x_t - mu)(x_{t-1} - mu) / sum_{t=1 to T} (x_t - mu)^2\n    numerator = np.sum(x_centered[1:] * x_centered[:-1])\n    denominator = np.sum(x_centered**2)\n    if denominator  1e-9:\n        autocorr = 0.0\n    else:\n        autocorr = numerator / denominator\n\n    # Feature 3: Absolute Pearson correlation with EOG template\n    # Using np.corrcoef which returns a 2x2 matrix\n    corr_matrix = np.corrcoef(spatial_map, eog_template)\n    map_corr = abs(corr_matrix[0, 1])\n    \n    return np.array([kurtosis, autocorr, map_corr])\n\n\ndef train_lda_weights(features, labels):\n    \"\"\"\n    Trains the LDA classifier weights from feature data and labels.\n    \"\"\"\n    f_ocular = features[labels == 1]\n    f_brain = features[labels == 0]\n    \n    N0 = f_brain.shape[0]\n    N1 = f_ocular.shape[0]\n    \n    # Estimate class means\n    mu0 = np.mean(f_brain, axis=0)\n    mu1 = np.mean(f_ocular, axis=0)\n    \n    # Estimate class variances (unbiased, ddof=1)\n    var0 = np.var(f_brain, axis=0, ddof=1)\n    var1 = np.var(f_ocular, axis=0, ddof=1)\n    \n    # Compute pooled variance\n    # Handle cases where a class has 0 or 1 samples\n    if N0 + N1 > 2:\n        pooled_var = ((N0 - 1) * var0 + (N1 - 1) * var1) / (N0 + N1 - 2)\n    else:\n        # Fallback if too few samples for pooled variance\n        pooled_var = np.ones_like(mu0)\n\n    # Avoid division by zero for features with no variance\n    pooled_var[pooled_var  1e-9] = 1.0\n\n    # Compute weights\n    weights = (mu1 - mu0) / pooled_var\n    \n    return weights\n\n\ndef compute_auc(scores, labels):\n    \"\"\"\n    Computes the Area Under the ROC Curve (AUC).\n    \"\"\"\n    # Combine scores and labels for sorting\n    combined = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n    \n    P = np.sum(labels == 1)\n    N = np.sum(labels == 0)\n\n    if P == 0 or N == 0:\n        return 0.5 # Cannot compute AUC if one class is missing\n\n    tpr_list = [0.0]\n    fpr_list = [0.0]\n    \n    tp = 0\n    fp = 0\n    \n    last_score = -np.inf\n    \n    for i in range(len(combined)):\n        score, label = combined[i]\n        \n        if score != last_score:\n            tpr_list.append(tp / P)\n            fpr_list.append(fp / N)\n            last_score = score\n        \n        if label == 1:\n            tp += 1\n        else:\n            fp += 1\n            \n    tpr_list.append(tp / P)\n    fpr_list.append(fp / N)\n    \n    # Calculate AUC using trapezoidal rule\n    return np.trapz(tpr_list, fpr_list)\n\nif __name__ == '__main__':\n    solve()\n\n```"
        },
        {
            "introduction": "Removing components identified as artifacts is the final step, but is the result always an improvement? This practice addresses the crucial stage of evaluation, quantifying the effectiveness of ICA-based cleaning by measuring its impact on the Signal-to-Noise Ratio ($SNR$) of a neural event of interest. By simulating a signal corrupted by artifacts and then cleaning it, you will learn to assess whether the procedure has beneficially suppressed noise or inadvertently removed part of the desired signal. This exercise emphasizes the importance of verifying your results to ensure the integrity of your data analysis pipeline .",
            "id": "4169904",
            "problem": "You are given a linear instantaneous mixing model for multichannel neural recordings, a cleaning procedure based on Independent Component Analysis (ICA), and a definition of Signal-to-Noise Ratio (SNR). Your task is to implement a program that computes the change in SNR for a neural event of interest after ICA cleaning and to interpret whether the change indicates beneficial artifact suppression or signal loss. The solution must start from first principles: the linear mixing model for observed data, the definition of SNR as a ratio of root-mean-square (RMS) amplitudes, and the ICA cleaning procedure as zeroing selected independent components.\n\nAssume a sensor-space observation model with $m$ channels and $k$ independent sources satisfying the linear relation\n$$\n\\mathbf{X}(t) = \\mathbf{A}\\,\\mathbf{S}(t),\n$$\nwhere $\\mathbf{X}(t) \\in \\mathbb{R}^{m}$ is the observed multichannel signal at time $t$, $\\mathbf{A} \\in \\mathbb{R}^{m \\times k}$ is an invertible mixing matrix, and $\\mathbf{S}(t) \\in \\mathbb{R}^{k}$ stacks $k$ statistically independent source time courses. Assume a demixing matrix $\\mathbf{W} \\in \\mathbb{R}^{k \\times m}$ such that $\\mathbf{W} \\approx \\mathbf{A}^{-1}$. Cleaning by ICA consists of unmixing, zeroing selected components, and reconstructing:\n$$\n\\mathbf{Y}(t) = \\mathbf{W}\\,\\mathbf{X}(t), \\quad \\tilde{\\mathbf{Y}}(t) = \\mathbf{M}\\,\\mathbf{Y}(t), \\quad \\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\,\\tilde{\\mathbf{Y}}(t),\n$$\nwhere $\\mathbf{M} \\in \\mathbb{R}^{k \\times k}$ is a diagonal mask with entries in $\\{0,1\\}$ that zero the selected artifact components.\n\nDefine the event of interest as a known source indexed by $i_{\\mathrm{e}}$, whose sensor-space spatial pattern is the $i_{\\mathrm{e}}$-th column of $\\mathbf{A}$, denoted $\\mathbf{p} = \\mathbf{A}_{:,i_{\\mathrm{e}}}$. Form a unit-norm projection vector\n$$\n\\mathbf{v} = \\frac{\\mathbf{p}}{\\lVert \\mathbf{p} \\rVert_2},\n$$\nand define a scalar event-projected time series by $z(t) = \\mathbf{v}^{\\top}\\mathbf{X}(t)$ and its cleaned counterpart $\\tilde{z}(t) = \\mathbf{v}^{\\top}\\tilde{\\mathbf{X}}(t)$.\n\nUse a baseline window and an event window on the time axis to define SNR from first principles. Let the scalar baseline mean be\n$$\n\\mu_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} z(t), \\quad \\tilde{\\mu}_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} \\tilde{z}(t),\n$$\nwhere $\\mathcal{B}$ is the set of baseline indices. Let the baseline RMS be\n$$\n\\mathrm{RMS}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}.\n$$\nDefine the event RMS in the event window $\\mathcal{E}$ by\n$$\n\\mathrm{RMS}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}.\n$$\nFrom these, define pre-cleaning and post-cleaning SNRs as dimensionless ratios\n$$\n\\mathrm{SNR}_{\\mathrm{pre}} = \\frac{\\mathrm{RMS}_{\\mathrm{event}}}{\\mathrm{RMS}_{\\mathrm{base}}}, \\quad \\mathrm{SNR}_{\\mathrm{post}} = \\frac{\\widetilde{\\mathrm{RMS}}_{\\mathrm{event}}}{\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}}}.\n$$\nFinally, define the SNR change and an interpretation label by\n$$\n\\Delta \\mathrm{SNR} = \\mathrm{SNR}_{\\mathrm{post}} - \\mathrm{SNR}_{\\mathrm{pre}}, \\quad \\ell = \\begin{cases} 1,  \\Delta \\mathrm{SNR} \\ge 0, \\\\ 0,  \\Delta \\mathrm{SNR}  0, \\end{cases}\n$$\nwhere $\\ell = 1$ indicates beneficial artifact suppression and $\\ell = 0$ indicates signal loss.\n\nYou must implement these definitions in a program to compute $\\Delta \\mathrm{SNR}$ and $\\ell$ for the following deterministic simulation with shared parameters across all tests:\n- Number of sensors $m = 3$ and number of sources $k = 3$.\n- Mixing matrix\n$$\n\\mathbf{A} = \\begin{bmatrix}\n1  0.5  0.2 \\\\\n0.2  1.0  0.3 \\\\\n0.1  0.3  1.2\n\\end{bmatrix}.\n$$\n- Demixing matrix $\\mathbf{W} = \\mathbf{A}^{-1}$.\n- Sampling interval $\\Delta t = 0.001$ seconds, total duration $T = 1.0$ seconds, resulting in $N = 1000$ samples with time grid $t_n = n \\Delta t$ for $n \\in \\{0,1,\\dots,999\\}$.\n- Event source index $i_{\\mathrm{e}} = 0$, with time course\n$$\ns_0(t) = S\\,\\exp\\!\\Big(-\\frac{(t - t_0)^2}{2\\sigma^2}\\Big),\n$$\nwhere amplitude $S = 1.0$, center $t_0 = 0.5$ seconds, and width $\\sigma = 0.05$ seconds.\n- Artifact source index $i_{\\mathrm{a}} = 1$, with time course\n$$\ns_1(t) = A_{\\mathrm{art}} \\,\\sin\\!\\big(2\\pi f t\\big),\n$$\nwhere frequency $f = 50.0$ Hertz and amplitude $A_{\\mathrm{art}}$ varies per test case as specified below.\n- Background noise source index $i_{\\mathrm{n}} = 2$, with time course\n$$\ns_2(t) \\sim \\mathcal{N}(0, \\sigma_n^2) \\text{ i.i.d. over time},\n$$\nwith standard deviation $\\sigma_n = 0.2$ and a fixed pseudo-random seed of $42$ to ensure determinism across all tests.\n- Baseline window $\\mathcal{B} = \\{ t \\in [0, 0.1] \\text{ seconds} \\}$ and event window $\\mathcal{E} = \\{ t \\in [0.45, 0.55] \\text{ seconds} \\}$, implemented as index sets on the discrete time grid.\n\nCleaning is performed by unmixing $\\mathbf{Y}(t) = \\mathbf{W}\\mathbf{X}(t)$, zeroing entries $Y_i(t)$ for all $t$ and for each $i$ in the provided removal index set $\\mathcal{C}$, and reconstructing $\\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\tilde{\\mathbf{Y}}(t)$.\n\nTest Suite. For each of the following parameter sets $(A_{\\mathrm{art}}, \\mathcal{C})$, compute $\\Delta \\mathrm{SNR}$ and $\\ell$:\n1. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{1\\}$.\n2. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{0, 1\\}$.\n3. $A_{\\mathrm{art}} = 0.0$, $\\mathcal{C} = \\{1\\}$.\n4. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{2\\}$.\n\nYour program must implement the model and definitions exactly as stated, using only the above parameters. For each test case, output the pair $[\\Delta \\mathrm{SNR}, \\ell]$, where $\\Delta \\mathrm{SNR}$ is rounded to six decimal places and $\\ell$ is an integer in $\\{0,1\\}$ as defined above.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list of the four pairs in order, enclosed in square brackets, for example:\n$[[x_1, y_1],[x_2, y_2],[x_3, y_3],[x_4, y_4]]$,\nwhere each $x_i$ is a float rounded to six decimal places and each $y_i$ is an integer $0$ or $1$. No additional text should be printed.",
            "solution": "The problem requires the computation and interpretation of the change in Signal-to-Noise Ratio (SNR) for a neural event after applying an Independent Component Analysis (ICA) based cleaning procedure. The solution is developed from first principles, encompassing the linear mixing model, the definition of SNR, and the specific steps of the ICA cleaning process.\n\nFirst, we establish the mathematical framework for the simulation. The observed data at the sensors, $\\mathbf{X}(t) \\in \\mathbb{R}^{m}$, are modeled as a linear instantaneous mixture of $k$ underlying source signals $\\mathbf{S}(t) \\in \\mathbb{R}^{k}$. This relationship is expressed as:\n$$\n\\mathbf{X}(t) = \\mathbf{A}\\,\\mathbf{S}(t)\n$$\nwhere $\\mathbf{A} \\in \\mathbb{R}^{m \\times k}$ is the mixing matrix. The rows of the matrix of source time courses, $\\mathbf{S}$, which has dimensions $k \\times N$ for $N$ time samples, are given by their functional forms. The event source is $s_0(t) = S\\,\\exp\\!\\Big(-\\frac{(t - t_0)^2}{2\\sigma^2}\\Big)$, the artifact source is $s_1(t) = A_{\\mathrm{art}} \\,\\sin\\!\\big(2\\pi f t\\big)$, and the background noise is $s_2(t) \\sim \\mathcal{N}(0, \\sigma_n^2)$. These are generated on a discrete time grid $t_n = n \\Delta t$ for $n \\in \\{0, 1, \\dots, N-1\\}$.\n\nThe core of the analysis is to quantify the signal quality before and after cleaning. This is done by projecting the $m$-dimensional sensor data onto a one-dimensional time series that optimally captures the event of interest. The spatial pattern of the event source ($i_{\\mathrm{e}}=0$) in sensor space is given by the corresponding column of the mixing matrix, $\\mathbf{p} = \\mathbf{A}_{:,0}$. A unit-norm projection vector is formed:\n$$\n\\mathbf{v} = \\frac{\\mathbf{p}}{\\lVert \\mathbf{p} \\rVert_2}\n$$\nProjecting the observed data $\\mathbf{X}(t)$ with this vector yields a scalar time series $z(t) = \\mathbf{v}^{\\top}\\mathbf{X}(t)$. This projection maximizes the contribution of the event source relative to other sources whose spatial patterns are not collinear with $\\mathbf{p}$.\n\nThe Signal-to-Noise Ratio (SNR) is defined as a ratio of root-mean-square (RMS) amplitudes computed over two distinct time windows: a baseline window $\\mathcal{B}$ (where only noise is expected) and an event window $\\mathcal{E}$ (where the signal of interest occurs).\nThe baseline signal level is characterized by its mean, $\\mu_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} z(t)$. The background noise level is the standard deviation of the signal in this window:\n$$\n\\mathrm{RMS}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}\n$$\nThe signal level during the event is measured by the RMS amplitude of the baseline-corrected signal in the event window:\n$$\n\\mathrm{RMS}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}\n$$\nThe pre-cleaning SNR is the ratio of these two quantities:\n$$\n\\mathrm{SNR}_{\\mathrm{pre}} = \\frac{\\mathrm{RMS}_{\\mathrm{event}}}{\\mathrm{RMS}_{\\mathrm{base}}}\n$$\n\nThe ICA cleaning procedure is a three-step process:\n1.  **Unmixing**: The observed data $\\mathbf{X}(t)$ is transformed into estimated source signals $\\mathbf{Y}(t)$ using a demixing matrix $\\mathbf{W}$: $\\mathbf{Y}(t) = \\mathbf{W}\\,\\mathbf{X}(t)$. The problem specifies the ideal scenario where $\\mathbf{W} = \\mathbf{A}^{-1}$, which means the unmixing is perfect and we recover the original sources exactly: $\\mathbf{Y}(t) = \\mathbf{A}^{-1}(\\mathbf{A}\\,\\mathbf{S}(t)) = \\mathbf{S}(t)$.\n2.  **Masking**: A subset of the recovered components, indexed by the set $\\mathcal{C}$, are identified as artifacts and are set to zero. This is equivalent to applying a diagonal mask matrix $\\mathbf{M}$ where $M_{ii}=0$ if $i \\in \\mathcal{C}$ and $M_{ii}=1$ otherwise. This yields a cleaned set of source signals $\\tilde{\\mathbf{Y}}(t) = \\mathbf{M}\\,\\mathbf{Y}(t)$.\n3.  **Reconstruction**: The cleaned sensor-space data $\\tilde{\\mathbf{X}}(t)$ is reconstructed by mixing the modified source signals: $\\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\,\\tilde{\\mathbf{Y}}(t)$.\n\nFollowing cleaning, a new projected time series $\\tilde{z}(t) = \\mathbf{v}^{\\top}\\tilde{\\mathbf{X}}(t)$ is computed. The post-cleaning SNR, $\\mathrm{SNR}_{\\mathrm{post}}$, is calculated using the same formulas as for $\\mathrm{SNR}_{\\mathrm{pre}}$, but applied to $\\tilde{z}(t)$:\n$$\n\\tilde{\\mu}_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} \\tilde{z}(t)\n$$\n$$\n\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}\n$$\n$$\n\\mathrm{SNR}_{\\mathrm{post}} = \\frac{\\widetilde{\\mathrm{RMS}}_{\\mathrm{event}}}{\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}}}\n$$\nThe final metrics are the change in SNR, $\\Delta \\mathrm{SNR} = \\mathrm{SNR}_{\\mathrm{post}} - \\mathrm{SNR}_{\\mathrm{pre}}$, and an interpretation label $\\ell$, which is $1$ if $\\Delta \\mathrm{SNR} \\ge 0$ (beneficial) and $0$ otherwise (detrimental).\n\nThe implementation proceeds by first defining all constants and generating the time vector. The source signals $s_0(t)$ and $s_2(t)$ are computed once. The main logic is encapsulated in a loop over the four test cases. In each iteration, the artifact source $s_1(t)$ is generated based on the test case's $A_{\\mathrm{art}}$. The full source matrix $\\mathbf{S}$ is assembled, and the sensor data $\\mathbf{X}$ is computed via matrix multiplication $\\mathbf{A}\\mathbf{S}$. The cleaning procedure is then simulated: since $\\mathbf{Y}=\\mathbf{S}$, we create a copy of $\\mathbf{S}$, zero out the rows corresponding to indices in $\\mathcal{C}$, and remap to sensor space to get $\\tilde{\\mathbf{X}}$. Both $\\mathbf{X}$ and $\\tilde{\\mathbf{X}}$ are projected to obtain $z$ and $\\tilde{z}$. Finally, the RMS and SNR values are calculated from these projected time series according to the specified formulas over the defined baseline and event index sets, leading to the computation of $\\Delta \\mathrm{SNR}$ and $\\ell$ for that test case.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the change in SNR for a neural event after ICA cleaning.\n    \"\"\"\n    # ----------------------------------------------------------------------\n    # 1. Define shared parameters and simulation setup\n    # ----------------------------------------------------------------------\n    m = 3  # Number of sensors\n    k = 3  # Number of sources\n    dt = 0.001  # Sampling interval in seconds\n    T = 1.0  # Total duration in seconds\n    N = int(T / dt)  # Number of time samples\n    t = np.linspace(0, T - dt, N)  # Time vector\n\n    # Mixing and demixing matrices\n    A = np.array([\n        [1.0, 0.5, 0.2],\n        [0.2, 1.0, 0.3],\n        [0.1, 0.3, 1.2]\n    ])\n    W = np.linalg.inv(A)\n\n    # Random number generator for noise source\n    rng = np.random.default_rng(42)\n\n    # Time windows (as index sets)\n    # Baseline: t in [0, 0.1] seconds\n    baseline_indices = np.where((t >= 0.0)  (t = 0.1))[0]\n    # Event: t in [0.45, 0.55] seconds\n    event_indices = np.where((t >= 0.45)  (t = 0.55))[0]\n\n    # ----------------------------------------------------------------------\n    # 2. Generate fixed source signals\n    # ----------------------------------------------------------------------\n    # Source 0: Event of interest (Gaussian pulse)\n    S_amp = 1.0\n    t0 = 0.5\n    sigma_t = 0.05\n    s0 = S_amp * np.exp(-(t - t0)**2 / (2 * sigma_t**2))\n\n    # Source 2: Background noise (Gaussian i.i.d.)\n    sigma_n = 0.2\n    s2 = rng.normal(0, sigma_n, N)\n\n    # ----------------------------------------------------------------------\n    # 3. Define projection vector for SNR calculation\n    # ----------------------------------------------------------------------\n    i_e = 0  # Event source index\n    p = A[:, i_e]  # Spatial pattern of the event\n    v = p / np.linalg.norm(p)  # Unit-norm projection vector\n\n    # ----------------------------------------------------------------------\n    # 4. Loop through test cases and compute metrics\n    # ----------------------------------------------------------------------\n    test_cases = [\n        (3.0, {1}),      # Case 1: Strong artifact, remove artifact component\n        (3.0, {0, 1}),   # Case 2: Strong artifact, remove artifact and event\n        (0.0, {1}),      # Case 3: No artifact, remove (zero) artifact component\n        (3.0, {2})       # Case 4: Strong artifact, remove noise component\n    ]\n\n    results = []\n    for A_art, C_indices in test_cases:\n        # Generate Source 1: Artifact (sinusoid)\n        f_art = 50.0\n        s1 = A_art * np.sin(2 * np.pi * f_art * t)\n\n        # Assemble the full source matrix S (k x N)\n        S = np.vstack([s0, s1, s2])\n\n        # Mix sources to get observed data X (m x N)\n        X = A @ S\n\n        # Project observed data to get scalar time series z\n        z = v.T @ X\n\n        # --- ICA Cleaning Procedure ---\n        # Unmixing: Y = W @ X. Given W = A^-1, Y = S.\n        Y = S.copy()\n        \n        # Masking: Zero out components in C\n        Y_tilde = Y.copy()\n        for i in C_indices:\n            Y_tilde[i, :] = 0\n            \n        # Reconstruction: Remap cleaned sources to sensor space\n        X_tilde = A @ Y_tilde\n\n        # Project cleaned data to get scalar time series z_tilde\n        z_tilde = v.T @ X_tilde\n\n        # --- SNR Calculation ---\n        # Pre-cleaning SNR\n        z_base = z[baseline_indices]\n        z_event = z[event_indices]\n        mu_base = np.mean(z_base)\n        rms_base = np.std(z_base)\n        rms_event = np.sqrt(np.mean((z_event - mu_base)**2))\n        \n        snr_pre = rms_event / rms_base if rms_base > 0 else np.inf\n\n        # Post-cleaning SNR\n        z_tilde_base = z_tilde[baseline_indices]\n        z_tilde_event = z_tilde[event_indices]\n        mu_tilde_base = np.mean(z_tilde_base)\n        rms_tilde_base = np.std(z_tilde_base)\n        rms_tilde_event = np.sqrt(np.mean((z_tilde_event - mu_tilde_base)**2))\n\n        snr_post = rms_tilde_event / rms_tilde_base if rms_tilde_base > 0 else np.inf\n        \n        # --- Final Metrics ---\n        delta_snr = snr_post - snr_pre\n        label = 1 if delta_snr >= 0 else 0\n        \n        results.append([round(delta_snr, 6), label])\n\n    # ----------------------------------------------------------------------\n    # 5. Print results in the specified format\n    # ----------------------------------------------------------------------\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}