{
    "hands_on_practices": [
        {
            "introduction": "独立成分分析（ICA）在伪影去除中的最终目标是增强我们感兴趣的神经信号。本练习通过量化信噪比（SNR）的变化，为衡量ICA清洗过程的成功与否提供了一种具体方法，帮助您直观地理解伪影抑制和潜在信号损失之间的权衡。通过这个实践，您将学会如何评估ICA清洗对特定事件相关信号的真实影响。",
            "id": "4169904",
            "problem": "给定一个用于多通道神经记录的线性瞬时混合模型、一个基于独立成分分析 (ICA) 的清理程序，以及一个信噪比 (SNR) 的定义。您的任务是实现一个程序，计算感兴趣的神经事件在经过 ICA 清理后 SNR 的变化，并解释该变化是指示了有益的伪影抑制还是信号损失。解决方案必须从基本原理出发：观测数据的线性混合模型、作为均方根 (RMS) 幅值之比的 SNR 定义，以及将选定独立成分置零的 ICA 清理程序。\n\n假设一个具有 $m$ 个通道和 $k$ 个独立源的传感器空间观测模型，满足以下线性关系\n$$\n\\mathbf{X}(t) = \\mathbf{A}\\,\\mathbf{S}(t),\n$$\n其中 $\\mathbf{X}(t) \\in \\mathbb{R}^{m}$ 是在时间 $t$ 观测到的多通道信号，$\\mathbf{A} \\in \\mathbb{R}^{m \\times k}$ 是一个可逆混合矩阵，$\\mathbf{S}(t) \\in \\mathbb{R}^{k}$ 堆叠了 $k$ 个统计上独立的源时间过程。假设存在一个解混矩阵 $\\mathbf{W} \\in \\mathbb{R}^{k \\times m}$，使得 $\\mathbf{W} \\approx \\mathbf{A}^{-1}$。通过 ICA 进行清理包括解混、将选定成分置零和重构：\n$$\n\\mathbf{Y}(t) = \\mathbf{W}\\,\\mathbf{X}(t), \\quad \\tilde{\\mathbf{Y}}(t) = \\mathbf{M}\\,\\mathbf{Y}(t), \\quad \\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\,\\tilde{\\mathbf{Y}}(t),\n$$\n其中 $\\mathbf{M} \\in \\mathbb{R}^{k \\times k}$ 是一个对角掩码，其条目在 $\\{0,1\\}$ 中，用于将选定的伪影成分置零。\n\n将感兴趣的事件定义为由 $i_{\\mathrm{e}}$ 索引的已知源，其在传感器空间中的空间模式是 $\\mathbf{A}$ 的第 $i_{\\mathrm{e}}$ 列，记为 $\\mathbf{p} = \\mathbf{A}_{:,i_{\\mathrm{e}}}$。构造一个单位范数投影向量\n$$\n\\mathbf{v} = \\frac{\\mathbf{p}}{\\lVert \\mathbf{p} \\rVert_2},\n$$\n并定义一个标量事件投影时间序列 $z(t) = \\mathbf{v}^{\\top}\\mathbf{X}(t)$ 及其清理后的对应部分 $\\tilde{z}(t) = \\mathbf{v}^{\\top}\\tilde{\\mathbf{X}}(t)$。\n\n在时间轴上使用一个基线窗口和一个事件窗口，从基本原理定义 SNR。设标量基线均值为\n$$\n\\mu_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} z(t), \\quad \\tilde{\\mu}_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} \\tilde{z}(t),\n$$\n其中 $\\mathcal{B}$ 是基线索引的集合。设基线 RMS 为\n$$\n\\mathrm{RMS}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}.\n$$\n在事件窗口 $\\mathcal{E}$ 中定义事件 RMS 为\n$$\n\\mathrm{RMS}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}.\n$$\n由此，将清理前和清理后的 SNR 定义为无量纲比率\n$$\n\\mathrm{SNR}_{\\mathrm{pre}} = \\frac{\\mathrm{RMS}_{\\mathrm{event}}}{\\mathrm{RMS}_{\\mathrm{base}}}, \\quad \\mathrm{SNR}_{\\mathrm{post}} = \\frac{\\widetilde{\\mathrm{RMS}}_{\\mathrm{event}}}{\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}}}.\n$$\n最后，定义 SNR 变化和一个解释标签\n$$\n\\Delta \\mathrm{SNR} = \\mathrm{SNR}_{\\mathrm{post}} - \\mathrm{SNR}_{\\mathrm{pre}}, \\quad \\ell = \\begin{cases} 1, & \\Delta \\mathrm{SNR} \\ge 0, \\\\ 0, & \\Delta \\mathrm{SNR}  0, \\end{cases}\n$$\n其中 $\\ell = 1$ 表示有益的伪影抑制，$\\ell = 0$ 表示信号损失。\n\n您必须在一个程序中实现这些定义，以计算 $\\Delta \\mathrm{SNR}$ 和 $\\ell$，用于以下在所有测试中具有共享参数的确定性模拟：\n- 传感器数量 $m = 3$，源数量 $k = 3$。\n- 混合矩阵\n$$\n\\mathbf{A} = \\begin{bmatrix}\n1  0.5  0.2 \\\\\n0.2  1.0  0.3 \\\\\n0.1  0.3  1.2\n\\end{bmatrix}.\n$$\n- 解混矩阵 $\\mathbf{W} = \\mathbf{A}^{-1}$。\n- 采样间隔 $\\Delta t = 0.001$ 秒，总持续时间 $T = 1.0$ 秒，产生 $N = 1000$ 个样本，时间网格为 $t_n = n \\Delta t$，其中 $n \\in \\{0,1,\\dots,999\\}$。\n- 事件源索引 $i_{\\mathrm{e}} = 0$，其时间过程为\n$$\ns_0(t) = S\\,\\exp\\!\\Big(-\\frac{(t - t_0)^2}{2\\sigma^2}\\Big),\n$$\n其中振幅 $S = 1.0$，中心 $t_0 = 0.5$ 秒，宽度 $\\sigma = 0.05$ 秒。\n- 伪影源索引 $i_{\\mathrm{a}} = 1$，其时间过程为\n$$\ns_1(t) = A_{\\mathrm{art}} \\,\\sin\\!\\big(2\\pi f t\\big),\n$$\n其中频率 $f = 50.0$ 赫兹，振幅 $A_{\\mathrm{art}}$ 根据下面指定的测试用例而变化。\n- 背景噪声源索引 $i_{\\mathrm{n}} = 2$，其时间过程为\n$$\ns_2(t) \\sim \\mathcal{N}(0, \\sigma_n^2) \\text{ i.i.d. over time},\n$$\n标准差为 $\\sigma_n = 0.2$，并使用固定的伪随机种子 $42$ 以确保所有测试的确定性。\n- 基线窗口 $\\mathcal{B} = \\{ t \\in [0, 0.1] \\text{ 秒} \\}$ 和事件窗口 $\\mathcal{E} = \\{ t \\in [0.45, 0.55] \\text{ 秒} \\}$，在离散时间网格上作为索引集实现。\n\n清理过程通过解混 $\\mathbf{Y}(t) = \\mathbf{W}\\mathbf{X}(t)$，对所有 $t$ 和提供的移除索引集 $\\mathcal{C}$ 中的每个 $i$，将条目 $Y_i(t)$ 置零，然后重构 $\\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\tilde{\\mathbf{Y}}(t)$ 来执行。\n\n测试套件。对于以下每个参数集 $(A_{\\mathrm{art}}, \\mathcal{C})$，计算 $\\Delta \\mathrm{SNR}$ 和 $\\ell$：\n1. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{1\\}$。\n2. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{0, 1\\}$。\n3. $A_{\\mathrm{art}} = 0.0$, $\\mathcal{C} = \\{1\\}$。\n4. $A_{\\mathrm{art}} = 3.0$, $\\mathcal{C} = \\{2\\}$。\n\n您的程序必须完全按照所述实现模型和定义，仅使用上述参数。对于每个测试用例，输出数对 $[\\Delta \\mathrm{SNR}, \\ell]$，其中 $\\Delta \\mathrm{SNR}$ 四舍五入到六位小数，$\\ell$ 是如上定义的 $\\{0,1\\}$ 中的整数。\n\n最终输出格式。您的程序应生成单行输出，其中包含按顺序排列的四个数对的逗号分隔列表，并用方括号括起来，例如：\n$[[x_1, y_1],[x_2, y_2],[x_3, y_3],[x_4, y_4]]$，\n其中每个 $x_i$ 是四舍五入到六位小数的浮点数，每个 $y_i$ 是整数 $0$ 或 $1$。不应打印任何附加文本。",
            "solution": "该问题要求在应用基于独立成分分析 (ICA) 的清理程序后，计算并解释神经事件的信噪比 (SNR) 变化。该解决方案从基本原理出发，涵盖了线性混合模型、SNR 的定义以及 ICA 清理过程的具体步骤。\n\n首先，我们为模拟建立数学框架。在传感器处观测到的数据 $\\mathbf{X}(t) \\in \\mathbb{R}^{m}$ 被建模为 $k$ 个底层源信号 $\\mathbf{S}(t) \\in \\mathbb{R}^{k}$ 的线性瞬时混合。这种关系表示为：\n$$\n\\mathbf{X}(t) = \\mathbf{A}\\,\\mathbf{S}(t)\n$$\n对于 $N$ 个时间样本，源时间过程矩阵 $\\mathbf{S}$ 的维度为 $k \\times N$，其各行由其函数形式给出。事件源是 $s_0(t) = S\\,\\exp\\!\\Big(-\\frac{(t - t_0)^2}{2\\sigma^2}\\Big)$，伪影源是 $s_1(t) = A_{\\mathrm{art}} \\,\\sin\\!\\big(2\\pi f t\\big)$，背景噪声是 $s_2(t) \\sim \\mathcal{N}(0, \\sigma_n^2)$。这些都在离散时间网格 $t_n = n \\Delta t$（其中 $n \\in \\{0, 1, \\dots, N-1\\}$）上生成。\n\n分析的核心是量化清理前后的信号质量。这是通过将 $m$ 维传感器数据投影到一个能最佳捕获感兴趣事件的一维时间序列上来完成的。事件源 ($i_{\\mathrm{e}}=0$) 在传感器空间中的空间模式由混合矩阵的相应列给出，即 $\\mathbf{p} = \\mathbf{A}_{:,0}$。构造一个单位范数投影向量：\n$$\n\\mathbf{v} = \\frac{\\mathbf{p}}{\\lVert \\mathbf{p} \\rVert_2}\n$$\n用此向量投影观测数据 $\\mathbf{X}(t)$ 会产生一个标量时间序列 $z(t) = \\mathbf{v}^{\\top}\\mathbf{X}(t)$。此投影最大化了事件源相对于其他空间模式与 $\\mathbf{p}$ 不共线的源的贡献。\n\n信噪比 (SNR) 定义为在两个不同时间窗口上计算的均方根 (RMS) 幅值之比：一个基线窗口 $\\mathcal{B}$（预计只有噪声）和一个事件窗口 $\\mathcal{E}$（感兴趣的信号在此发生）。\n基线信号水平由其均值 $\\mu_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} z(t)$ 表征。背景噪声水平是此窗口中信号的标准差：\n$$\n\\mathrm{RMS}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}\n$$\n事件期间的信号水平由事件窗口中经基线校正的信号的 RMS 幅值来衡量：\n$$\n\\mathrm{RMS}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(z(t) - \\mu_{\\mathrm{base}}\\big)^2}\n$$\n清理前的 SNR 是这两个量的比值：\n$$\n\\mathrm{SNR}_{\\mathrm{pre}} = \\frac{\\mathrm{RMS}_{\\mathrm{event}}}{\\mathrm{RMS}_{\\mathrm{base}}}\n$$\n\nICA 清理过程是一个三步过程：\n1.  **解混**：观测数据 $\\mathbf{X}(t)$ 使用解混矩阵 $\\mathbf{W}$ 转换为估计的源信号 $\\mathbf{Y}(t)$：$\\mathbf{Y}(t) = \\mathbf{W}\\,\\mathbf{X}(t)$。问题指定了理想情况，即 $\\mathbf{W} = \\mathbf{A}^{-1}$，这意味着解混是完美的，我们能精确恢复原始源：$\\mathbf{Y}(t) = \\mathbf{A}^{-1}(\\mathbf{A}\\,\\mathbf{S}(t)) = \\mathbf{S}(t)$。\n2.  **掩蔽**：将由集合 $\\mathcal{C}$ 索引的恢复成分子集识别为伪影并置为零。这等效于应用一个对角掩码矩阵 $\\mathbf{M}$，其中如果 $i \\in \\mathcal{C}$，则 $M_{ii}=0$，否则 $M_{ii}=1$。这会产生一组清理后的源信号 $\\tilde{\\mathbf{Y}}(t) = \\mathbf{M}\\,\\mathbf{Y}(t)$。\n3.  **重构**：通过混合修改后的源信号来重构清理后的传感器空间数据 $\\tilde{\\mathbf{X}}(t)$：$\\tilde{\\mathbf{X}}(t) = \\mathbf{A}\\,\\tilde{\\mathbf{Y}}(t)$。\n\n清理之后，计算一个新的投影时间序列 $\\tilde{z}(t) = \\mathbf{v}^{\\top}\\tilde{\\mathbf{X}}(t)$。清理后的 SNR，即 $\\mathrm{SNR}_{\\mathrm{post}}$，使用与 $\\mathrm{SNR}_{\\mathrm{pre}}$ 相同的公式计算，但应用于 $\\tilde{z}(t)$：\n$$\n\\tilde{\\mu}_{\\mathrm{base}} = \\frac{1}{|\\mathcal{B}|}\\sum_{t \\in \\mathcal{B}} \\tilde{z}(t)\n$$\n$$\n\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}} = \\sqrt{\\frac{1}{|\\mathcal{B}|} \\sum_{t \\in \\mathcal{B}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}, \\quad \\widetilde{\\mathrm{RMS}}_{\\mathrm{event}} = \\sqrt{\\frac{1}{|\\mathcal{E}|} \\sum_{t \\in \\mathcal{E}} \\big(\\tilde{z}(t) - \\tilde{\\mu}_{\\mathrm{base}}\\big)^2}\n$$\n$$\n\\mathrm{SNR}_{\\mathrm{post}} = \\frac{\\widetilde{\\mathrm{RMS}}_{\\mathrm{event}}}{\\widetilde{\\mathrm{RMS}}_{\\mathrm{base}}}\n$$\n最终的指标是 SNR 的变化量 $\\Delta \\mathrm{SNR} = \\mathrm{SNR}_{\\mathrm{post}} - \\mathrm{SNR}_{\\mathrm{pre}}$，以及一个解释标签 $\\ell$，如果 $\\Delta \\mathrm{SNR} \\ge 0$（有益），则为 $1$，否则（有害）为 $0$。\n\n实现首先定义所有常量并生成时间向量。主逻辑被封装在一个遍历四个测试用例的循环中。在每次迭代中，根据测试用例的 $A_{\\mathrm{art}}$ 生成伪影源 $s_1(t)$。组装完整的源矩阵 $\\mathbf{S}$，并通过矩阵乘法 $\\mathbf{A}\\mathbf{S}$ 计算传感器数据 $\\mathbf{X}$。然后模拟清理过程：由于 $\\mathbf{Y}=\\mathbf{S}$，我们创建 $\\mathbf{S}$ 的一个副本，将与 $\\mathcal{C}$ 中索引对应的行置零，并重新映射回传感器空间以获得 $\\tilde{\\mathbf{X}}$。将 $\\mathbf{X}$ 和 $\\tilde{\\mathbf{X}}$ 都进行投影以获得 $z$ 和 $\\tilde{z}$。最后，根据指定的公式，在定义的基线和事件索引集上，从这些投影时间序列计算 RMS 和 SNR 值，从而计算出该测试用例的 $\\Delta \\mathrm{SNR}$ 和 $\\ell$。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the change in SNR for a neural event after ICA cleaning.\n    \"\"\"\n    # ----------------------------------------------------------------------\n    # 1. Define shared parameters and simulation setup\n    # ----------------------------------------------------------------------\n    m = 3  # Number of sensors\n    k = 3  # Number of sources\n    dt = 0.001  # Sampling interval in seconds\n    T = 1.0  # Total duration in seconds\n    N = int(T / dt)  # Number of time samples\n    t = np.linspace(0, T - dt, N)  # Time vector\n\n    # Mixing and demixing matrices\n    A = np.array([\n        [1.0, 0.5, 0.2],\n        [0.2, 1.0, 0.3],\n        [0.1, 0.3, 1.2]\n    ])\n    W = np.linalg.inv(A)\n\n    # Random number generator for noise source\n    rng = np.random.default_rng(42)\n\n    # Time windows (as index sets)\n    # Baseline: t in [0, 0.1] seconds\n    baseline_indices = np.where((t >= 0.0)  (t = 0.1))[0]\n    # Event: t in [0.45, 0.55] seconds\n    event_indices = np.where((t >= 0.45)  (t = 0.55))[0]\n\n    # ----------------------------------------------------------------------\n    # 2. Generate fixed source signals\n    # ----------------------------------------------------------------------\n    # Source 0: Event of interest (Gaussian pulse)\n    S_amp = 1.0\n    t0 = 0.5\n    sigma_t = 0.05\n    s0 = S_amp * np.exp(-(t - t0)**2 / (2 * sigma_t**2))\n\n    # Source 2: Background noise (Gaussian i.i.d.)\n    sigma_n = 0.2\n    s2 = rng.normal(0, sigma_n, N)\n\n    # ----------------------------------------------------------------------\n    # 3. Define projection vector for SNR calculation\n    # ----------------------------------------------------------------------\n    i_e = 0  # Event source index\n    p = A[:, i_e]  # Spatial pattern of the event\n    v = p / np.linalg.norm(p)  # Unit-norm projection vector\n\n    # ----------------------------------------------------------------------\n    # 4. Loop through test cases and compute metrics\n    # ----------------------------------------------------------------------\n    test_cases = [\n        (3.0, {1}),      # Case 1: Strong artifact, remove artifact component\n        (3.0, {0, 1}),   # Case 2: Strong artifact, remove artifact and event\n        (0.0, {1}),      # Case 3: No artifact, remove (zero) artifact component\n        (3.0, {2})       # Case 4: Strong artifact, remove noise component\n    ]\n\n    results = []\n    for A_art, C_indices in test_cases:\n        # Generate Source 1: Artifact (sinusoid)\n        f_art = 50.0\n        s1 = A_art * np.sin(2 * np.pi * f_art * t)\n\n        # Assemble the full source matrix S (k x N)\n        S = np.vstack([s0, s1, s2])\n\n        # Mix sources to get observed data X (m x N)\n        X = A @ S\n\n        # Project observed data to get scalar time series z\n        z = v.T @ X\n\n        # --- ICA Cleaning Procedure ---\n        # Unmixing: Y = W @ X. Given W = A^-1, Y = S.\n        Y = S.copy()\n        \n        # Masking: Zero out components in C\n        Y_tilde = Y.copy()\n        for i in C_indices:\n            Y_tilde[i, :] = 0\n            \n        # Reconstruction: Remap cleaned sources to sensor space\n        X_tilde = A @ Y_tilde\n\n        # Project cleaned data to get scalar time series z_tilde\n        z_tilde = v.T @ X_tilde\n\n        # --- SNR Calculation ---\n        # Pre-cleaning SNR\n        z_base = z[baseline_indices]\n        z_event = z[event_indices]\n        mu_base = np.mean(z_base)\n        rms_base = np.std(z_base)\n        rms_event = np.sqrt(np.mean((z_event - mu_base)**2))\n        \n        snr_pre = rms_event / rms_base if rms_base > 0 else np.inf\n\n        # Post-cleaning SNR\n        z_tilde_base = z_tilde[baseline_indices]\n        z_tilde_event = z_tilde[event_indices]\n        mu_tilde_base = np.mean(z_tilde_base)\n        rms_tilde_base = np.std(z_tilde_base)\n        rms_tilde_event = np.sqrt(np.mean((z_tilde_event - mu_tilde_base)**2))\n\n        snr_post = rms_tilde_event / rms_tilde_base if rms_tilde_base > 0 else np.inf\n        \n        # --- Final Metrics ---\n        delta_snr = snr_post - snr_pre\n        label = 1 if delta_snr >= 0 else 0\n        \n        results.append([round(delta_snr, 6), label])\n\n    # ----------------------------------------------------------------------\n    # 5. Print results in the specified format\n    # ----------------------------------------------------------------------\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "球化（sphering），也称白化（whitening），是许多ICA算法中一个至关重要的预处理步骤。本练习将指导您从基本原理出发，实现这一数据变换过程，它通过去除数据相关性并使方差均等化，极大地简化了后续的源信号分离任务。掌握这一技术是理解ICA内部工作机制的基础。",
            "id": "4169909",
            "problem": "您将要在独立分量分析（Independent Component Analysis，简称ICA）的背景下，对模拟的多通道数据实现球化（sphering），也称为白化（whitening）。目标是构建并验证一个线性变换，该变换能使变换后数据的样本协方差接近单位矩阵，并量化由有限样本量引起的偏差。推导和实现必须从基本定义和观察出发：一个随机向量 $x \\in \\mathbb{R}^m$ 的均值为 $\\mu = \\mathbb{E}[x]$，协方差为 $C_x = \\mathbb{E}[(x - \\mu)(x - \\mu)^\\top]$。球化变换是一个线性映射，当应用于零均值数据 $x$ 时，能得到一个变换后的向量 $z$，其总体协方差等于单位矩阵 $I$。在实践中，只有有限的样本可用，因此只能根据样本均值和样本协方差构建一个变换来近似这一总体特性。\n\n您的程序必须：\n- 模拟 $m$ 个统计独立的源过程 $s_1, \\dots, s_m$，它们构成一个矩阵 $S \\in \\mathbb{R}^{m \\times N}$ 的行，其中 $N$ 是样本数量。每个 $s_i$ 应遵循选定的分布或过程，以确保各分量相互独立且不全为相同的高斯分布；例如高斯分布、拉普拉斯分布、学生t分布、具有随机相位的确定性正弦波、稀疏脉冲或自回归滤波噪声。每个 $s_i$ 必须被中心化至零均值并缩放至单位方差，以使各源具有可比性。\n- 构建一个具有指定条件数的方阵混合矩阵 $A \\in \\mathbb{R}^{m \\times m}$，该矩阵通过组合两个正交矩阵和一组奇异值（其比率等于条件数）来生成。由此产生观测混合信号 $x_t = A s_t + \\varepsilon_t$，其中 $t = 1, \\dots, N$，$\\varepsilon_t$ 是具有指定标准差的附加零均值高斯噪声。将这些信号堆叠成矩阵 $X \\in \\mathbb{R}^{m \\times N}$。\n- 仅使用 $X$ 的样本均值和样本协方差来计算球化变换，并将其应用于 $X$ 以形成矩阵 $Z \\in \\mathbb{R}^{m \\times N}$，然后通过估计样本协方差 $\\hat{C}_Z = \\frac{1}{N} \\sum_{t=1}^N z_t z_t^\\top$ 来数值验证其单位协方差性质。\n- 使用从 $\\hat{C}_Z$ 计算出的以下指标来量化与精确单位矩阵的有限样本偏差：\n  1. 对角线元素与 $1$ 的平均绝对偏差，即 $\\frac{1}{m} \\sum_{i=1}^m |(\\hat{C}_Z)_{ii} - 1|$。\n  2. 最大绝对非对角线元素，即 $\\max_{i \\neq j} |(\\hat{C}_Z)_{ij}|$。\n  3. 与单位矩阵之差的弗罗贝尼乌斯范数，即 $\\|\\hat{C}_Z - I\\|_F$。\n- 为了数值稳定性，您的实现在构建球化变换时可以对极小的特征值进行正则化，但正则化项必须与样本协方差特征值设定的尺度相比可以忽略不计，以确保它不会主导计算。\n\n使用以下测试套件，其中每个案例都是一个元组 $(m, N, \\text{cond}, \\sigma, \\text{seed})$：\n- 案例 $1$：$(6, 8192, 10, 0.05, 0)$ 是具有足够样本和中等条件数的一般情况。\n- 案例 $2$：$(6, 64, 10, 0.05, 1)$ 是一个用于揭示有限样本偏差的小样本边界条件。\n- 案例 $3$：$(6, 4096, 1000, 0.0, 2)$ 是一个没有附加噪声的病态混合矩阵，用于探究对条件数的敏感性。\n- 案例 $4$：$(10, 2048, 30, 0.2, 3)$ 是一个具有显著噪声的更高维度情况。\n- 案例 $5$：$(6, 2048, 1, 0.05, 4)$ 是一个作为基线的良态类单位混合矩阵。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试案例贡献一个按上述顺序列出的三元组。因此，最终输出必须为以下形式：$[[d_1,m_1,f_1],[d_2,m_2,f_2],[d_3,m_3,f_3],[d_4,m_4,f_4],[d_5,m_5,f_5]]$，其中 $d_k$ 是案例 $k$ 的平均绝对对角线偏差，$m_k$ 是最大绝对非对角线元素，$f_k$ 是弗罗贝尼乌斯范数误差。所有报告的量都必须是十进制格式的无量纲实数。",
            "solution": "该问题要求实现和验证球化（或白化）数据变换，这是统计信号处理中一个关键的预处理步骤，尤其对于独立分量分析（ICA）而言。球化的目标是对一组观测信号应用线性变换，使得变换后的信号不相关且具有单位方差。换句话说，球化后数据的协方差矩阵是单位矩阵 $I$。这简化了ICA的后续任务，即找到球化后数据的旋转，以揭示潜在的统计独立源。本解决方案将首先从第一性原理推导球化变换，然后描述其数值实现和验证方法。\n\n### 球化的理论基础\n\n设 $x \\in \\mathbb{R}^m$ 是一个代表 $m$ 个观测信号的随机向量。为简单起见，我们假设 $x$ 是中心化的，即其期望值为零向量 $\\mathbb{E}[x] = 0$。$x$ 的协方差矩阵定义为 $C_x = \\mathbb{E}[x x^\\top]$。球化旨在寻找一个线性变换矩阵 $W \\in \\mathbb{R}^{m \\times m}$，使得变换后的向量 $z = Wx$ 具有单位协方差矩阵：\n$$ C_z = \\mathbb{E}[z z^\\top] = \\mathbb{E}[(Wx)(Wx)^\\top] = W \\mathbb{E}[x x^\\top] W^\\top = W C_x W^\\top = I $$\n为了找到这样的矩阵 $W$，我们利用协方差矩阵 $C_x$ 的特征分解。由于 $C_x$ 是一个实对称半正定矩阵，它可以被分解为：\n$$ C_x = U \\Lambda U^\\top $$\n其中 $U$ 是一个正交矩阵（$UU^\\top = U^\\top U = I$），其列是 $C_x$ 的特征向量；$\\Lambda$ 是一个对角矩阵，其对角线元素 $\\lambda_1, \\dots, \\lambda_m$ 是对应的非负特征值。\n\n我们寻求满足 $W C_x W^\\top = I$ 的矩阵 $W$。代入 $C_x$ 的分解：\n$$ W (U \\Lambda U^\\top) W^\\top = I $$\n球化矩阵 $W$ 的一个有效选择是：\n$$ W = \\Lambda^{-1/2} U^\\top $$\n其中 $\\Lambda^{-1/2}$ 是对角线元素为 $1/\\sqrt{\\lambda_i}$ 的对角矩阵。我们来验证这个选择：\n$$ C_z = (\\Lambda^{-1/2} U^\\top) (U \\Lambda U^\\top) (\\Lambda^{-1/2} U^\\top)^\\top = (\\Lambda^{-1/2} U^\\top) (U \\Lambda U^\\top) (U (\\Lambda^{-1/2})^\\top) $$\n由于 $\\Lambda^{-1/2}$ 是对角矩阵，所以它是对称的。因此，$(\\Lambda^{-1/2})^\\top = \\Lambda^{-1/2}$。\n$$ C_z = \\Lambda^{-1/2} (U^\\top U) \\Lambda (U^\\top U) \\Lambda^{-1/2} = \\Lambda^{-1/2} I \\Lambda I \\Lambda^{-1/2} = \\Lambda^{-1/2} \\Lambda \\Lambda^{-1/2} = I $$\n这证实了 $W = \\Lambda^{-1/2} U^\\top$ 是一个有效的球化矩阵。这种特定形式通常被称为ZCA白化。需要注意的是，球化矩阵不是唯一的；对 $z$ 应用任何后续的旋转都会保持其单位协方差性质。\n\n### 基于有限样本的实现\n\n在实践中，我们拥有有限数量的样本，这些样本被组织成一个数据矩阵 $X \\in \\mathbb{R}^{m \\times N}$，其中 $N$ 是样本数量。总体参数（均值和协方差）是未知的，必须从这些数据中进行估计。\n\n1.  **数据中心化**：首先，我们估计均值向量 $\\hat{\\mu}_X = \\frac{1}{N} \\sum_{t=1}^N x_t$，并通过从每个样本中减去该均值来对数据进行中心化：$\\tilde{X} = X - \\hat{\\mu}_X$。\n\n2.  **样本协方差**：接下来，我们计算样本协方差矩阵。遵循问题中为变换后数据的协方差指定的公式，我们使用估计量 $\\hat{C}_X = \\frac{1}{N} \\tilde{X} \\tilde{X}^\\top$。\n\n3.  **特征分解**：我们对估计的协方差矩阵进行特征分解：$\\hat{C}_X = \\hat{U} \\hat{\\Lambda} \\hat{U}^\\top$。\n\n4.  **球化矩阵构建**：基于样本的球化矩阵 $\\hat{W}$ 的构建方式与总体情况类似：$\\hat{W} = \\hat{\\Lambda}^{-1/2} \\hat{U}^\\top$。为了处理由非常小或为零的特征值（可能由有限样本效应、高数据相关性或 $N  m$ 的情况引起）导致的数值不稳定性，在取逆平方根之前，会向特征值中加入一个小的正则化常数 $\\epsilon > 0$。特征值逆平方根矩阵变为 $\\text{diag}(1/\\sqrt{\\hat{\\lambda}_i + \\epsilon})$。因此，正则化的球化矩阵为 $\\hat{W} = (\\hat{\\Lambda} + \\epsilon I)^{-1/2} \\hat{U}^\\top$。$\\epsilon$ 的值应足够小，以免显著改变结果，例如 $10^{-12}$。\n\n5.  **变换**：然后对中心化后的数据 $\\tilde{X}$ 进行变换，得到球化数据 $Z = \\hat{W} \\tilde{X}$。\n\n### 算法步骤与验证\n\n每个测试案例的总体流程如下：\n\n1.  **生成源信号**：对于给定的通道数 $m$ 和样本数 $N$，我们创建一个 $m \\times N$ 的源矩阵S。每一行代表一个独立的源信号。为了满足ICA相关的条件，即源信号不全为高斯分布，我们混合使用多种分布（例如，高斯、拉普拉斯、均匀、正弦分布）。然后，每个生成的源信号都被标准化，使其样本均值为 $0$，样本方差为 $1$。\n\n2.  **构建混合矩阵**：创建一个具有指定条件数 $\\kappa$ 的混合矩阵 $A \\in \\mathbb{R}^{m \\times m}$。这是通过构造 $A = P \\Sigma Q^\\top$ 来实现的，其中 $P$ 和 $Q$ 是随机正交矩阵，$\\Sigma$ 是一个对角矩阵，其奇异值在 $\\kappa$ 和 $1$ 之间呈几何间隔分布。例如，$\\Sigma_{ii} = \\kappa^{(m-i)/(m-1)}$，其中 $i=1, \\dots, m$。\n\n3.  **混合数据**：使用线性混合模型 $X = AS + \\mathcal{E}$ 来模拟观测数据矩阵 $X$，其中 $\\mathcal{E}$ 是一个 $m \\times N$ 的独立同分布高斯噪声矩阵，其均值为 $0$，标准差为 $\\sigma$。\n\n4.  **应用球化**：将上述球化过程应用于数据矩阵 $X$，以获得球化后的数据矩阵 $Z$。\n\n5.  **评估性能**：计算球化后数据的样本协方差 $\\hat{C}_Z = \\frac{1}{N} Z Z^\\top$。我们期望该矩阵接近单位矩阵 $I$。由有限样本量、噪声和条件数引起的偏差通过三个指标进行量化：\n    a.  **平均绝对对角线偏差**：$d = \\frac{1}{m} \\sum_{i=1}^m |(\\hat{C}_Z)_{ii} - 1|$。该指标衡量方差被缩放到单位值的程度。\n    b.  **最大绝对非对角线元素**：$m_{od} = \\max_{i \\neq j} |(\\hat{C}_Z)_{ij}|$。该指标衡量数据被去相关的程度。\n    c.  **弗罗贝尼乌斯范数误差**：$f = \\|\\hat{C}_Z - I\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^m |(\\hat{C}_Z)_{ij} - \\delta_{ij}|^2}$，其中 $\\delta_{ij}$ 是克罗内克δ函数。该指标提供了与单位矩阵偏差的综合度量。\n\n对问题中定义的每个测试案例重复这些步骤，并使用指定的随机种子以确保可复现性。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to run the sphering simulation for all test cases.\n    \"\"\"\n    test_cases = [\n        # (m, N, cond, sigma, seed)\n        (6, 8192, 10, 0.05, 0),\n        (6, 64, 10, 0.05, 1),\n        (6, 4096, 1000, 0.0, 2),\n        (10, 2048, 30, 0.2, 3),\n        (6, 2048, 1, 0.05, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        m, N, cond, sigma, seed = case\n        metrics = run_sphering_simulation(m, N, cond, sigma, seed)\n        results.append(metrics)\n\n    # Format the final output string as a list of lists.\n    output_str = \"[\" + \",\".join(str(r) for r in results) + \"]\"\n    print(output_str)\n\ndef run_sphering_simulation(m, N, cond, sigma, seed):\n    \"\"\"\n    Executes one full simulation case: data generation, sphering, and metric calculation.\n\n    Args:\n        m (int): Number of channels/sources.\n        N (int): Number of samples.\n        cond (float): Condition number of the mixing matrix.\n        sigma (float): Standard deviation of additive Gaussian noise.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        list: A list containing the three calculated metrics [d, m_od, f].\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Simulate independent sources\n    S = np.zeros((m, N))\n    for i in range(m):\n        dist_type = i % 4\n        if dist_type == 0:  # Gaussian\n            s_i = rng.standard_normal(N)\n        elif dist_type == 1:  # Laplace\n            s_i = rng.laplace(0, 1, N)\n        elif dist_type == 2:  # Uniform\n            s_i = rng.uniform(-np.sqrt(3), np.sqrt(3), N)\n        else:  # Sinusoid\n            t = np.arange(N) / N\n            freq = rng.uniform(2, 6)\n            phase = rng.uniform(0, 2 * np.pi)\n            s_i = np.sqrt(2) * np.sin(2 * np.pi * freq * t + phase)\n        \n        # Standardize to zero mean and unit variance\n        s_i = (s_i - np.mean(s_i)) / np.std(s_i)\n        S[i, :] = s_i\n\n    # 2. Construct the mixing matrix A\n    U = ortho_group.rvs(dim=m, random_state=rng)\n    V = ortho_group.rvs(dim=m, random_state=rng)\n    \n    if m > 1:\n        singular_values = np.geomspace(cond, 1, m)\n    else:\n        singular_values = np.array([cond])\n\n    Sigma = np.diag(singular_values)\n    A = U @ Sigma @ V.T\n\n    # 3. Generate observed data X\n    noise = rng.normal(0, sigma, (m, N))\n    X = A @ S + noise\n\n    # 4. Compute and apply the sphering transform\n    # Center the data\n    mean_X = np.mean(X, axis=1, keepdims=True)\n    X_centered = X - mean_X\n\n    # Compute sample covariance matrix\n    C_X = (X_centered @ X_centered.T) / N\n\n    # Eigendecomposition of the covariance matrix\n    # np.linalg.eigh is used for symmetric matrices\n    eigenvalues, eigenvectors = np.linalg.eigh(C_X)\n\n    # Regularization for numerical stability\n    epsilon = 1e-12\n    \n    # Construct sphering matrix W\n    inv_sqrt_eigenvalues = 1.0 / np.sqrt(eigenvalues + epsilon)\n    W = np.diag(inv_sqrt_eigenvalues) @ eigenvectors.T\n    \n    # Apply sphering transform\n    Z = W @ X_centered\n\n    # 5. Verify and quantify deviations\n    # Compute the sample covariance of the sphered data\n    C_Z = (Z @ Z.T) / N\n\n    # Metric 1: Mean absolute deviation of diagonal entries from 1\n    diag_dev = np.mean(np.abs(np.diag(C_Z) - 1))\n\n    # Metric 2: Maximum absolute off-diagonal entry\n    C_Z_off_diag = C_Z.copy()\n    np.fill_diagonal(C_Z_off_diag, 0)\n    max_off_diag = np.max(np.abs(C_Z_off_diag))\n    \n    # Metric 3: Frobenius norm of the difference from identity\n    frobenius_norm = np.linalg.norm(C_Z - np.eye(m), 'fro')\n\n    return [diag_dev, max_off_diag, frobenius_norm]\n\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "当ICA将数据分解为多个独立成分后，关键的下一步是准确识别哪些成分代表了需要剔除的伪影。这个高级练习模拟了一个真实的科研场景，要求您基于眼电伪影的典型特征（如统计分布特性和空间地形图），构建一个自动化分类器。这项实践将理论上的源分离技术与神经生理数据清洗的实际应用联系起来。",
            "id": "4169969",
            "problem": "您的任务是推导并实现一个分类器，用于在脑电图数据的独立分量分析（ICA）分解中检测眼动独立分量。该分类器必须依赖于每个分量的三个可测量特征：分量时间过程的峰度、分量时间过程的延迟为1的自相关，以及分量空间图与眼电图（EOG）模板的相关性。您还必须使用受试者工作特征（ROC）曲线实现性能分析，并计算曲线下面积（AUC）。\n\n请从以下基础开始：\n\n- 独立分量分析（ICA）将观测到的多通道数据建模为统计独立源的线性混合，表示为 $X = A S$，其中 $X \\in \\mathbb{R}^{C \\times T}$ 是具有 $C$ 个通道和 $T$ 个时间点的传感器数据，$A \\in \\mathbb{R}^{C \\times N}$ 是混合矩阵，其列是空间图，$S \\in \\mathbb{R}^{N \\times T}$ 是具有 $N$ 个独立分量的源矩阵。\n- 眼动分量的特征在于：由眨眼和眼跳引起的重尾时间过程、缓慢的时间动态（高自相关性），以及与强调额叶传感器的类EOG拓扑结构相关的空间图。\n- 使用经过充分检验的定义：\n  - 对于时间序列 $x_{1:T}$，样本均值为 $\\mu = \\frac{1}{T} \\sum_{t=1}^{T} x_t$，样本方差为 $\\sigma^2 = \\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^2$。\n  - 超额峰度为 $K = \\frac{\\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^4}{\\left( \\frac{1}{T} \\sum_{t=1}^{T} (x_t - \\mu)^2 \\right)^2} - 3$。\n  - 延迟为1的自相关为 $\\rho_1 = \\frac{\\sum_{t=2}^{T} (x_t - \\mu)(x_{t-1} - \\mu)}{\\sum_{t=1}^{T} (x_t - \\mu)^2}$。\n  - 两个向量 $u, v \\in \\mathbb{R}^C$ 之间的皮尔逊相关系数为 $r(u, v) = \\frac{\\sum_{i=1}^{C} (u_i - \\bar{u})(v_i - \\bar{v})}{\\sqrt{\\sum_{i=1}^{C} (u_i - \\bar{u})^2} \\sqrt{\\sum_{i=1}^{C} (v_i - \\bar{v})^2}}$，其中 $\\bar{u}$ 和 $\\bar{v}$ 是均值。\n\n您必须基于特征向量 $f = (K, \\rho_1, |\\rho_{\\text{map}}|)$ 推导出一个决策分数，其中 $|\\rho_{\\text{map}}|$ 是独立分量的空间图与EOG模板之间的皮尔逊相关系数的绝对值，以考虑任意极性。假设对于眼动（$y=1$）和非眼动（$y=0$）分量，$f$ 近似服从类条件高斯分布且协方差为对角矩阵，请使用类均值和方差，推导线性对数似然比分数 $s(f)$（可相差一个加性常数）。您必须通过估计类均值和方差，从带标签的合成数据中训练分类器权重。然后，您必须使用决策分数和真实标签计算ROC和AUC。\n\n为了使问题完全可测试、科学上真实且保持自包含，您必须按如下方式合成独立分量：\n\n- 对于眼动分量，通过一个阶数为1的自回归过程（AR(1)）生成时间过程，参数为 $\\phi_o \\in (0,1)$，使用拉普拉斯分布的新息以产生重尾，并叠加由局部脉冲建模的眨眼事件。对于非眼动分量，使用AR(1)过程，参数为 $\\phi_b \\in (0,1)$，并使用高斯新息。对于每个分量，从生成的时间过程中计算 $K$ 和 $\\rho_1$。\n- 对于空间图，在一个单位圆传感器布局上构建一个EOG模板 $e \\in \\mathbb{R}^C$，方法是将传感器放置在等距的角度上，并定义 $e_i$ 以强调前半部分（y轴正方向）。将眼动图生成为 $m = e + \\eta$，其中 $\\eta$ 是小的高斯噪声；将非眼动图生成为与 $e$ 相关性很弱或不相关的高斯噪声。计算 $|\\rho_{\\text{map}}|$ 作为 $m$ 和 $e$ 之间的皮尔逊相关系数的绝对值。\n\n您的程序必须：\n- 实现上述的特征提取和分类器推导。\n- 根据经验类均值和合并对角方差训练线性分类器权重 $w \\in \\mathbb{R}^3$，使得决策分数为 $s(f) = w^\\top f$。\n- 通过在决策分数上扫描阈值来计算ROC，并使用梯形法则报告AUC。\n\n设计一个具有不同参数 regimes 的测试套件：\n- 测试用例1（理想情况）：种子 $0$，$N=120$ 个分量，$T=3000$ 个时间点，$C=64$ 个通道，眼动分量比例 $0.25$，$\\phi_o=0.95$，$\\phi_b=0.40$，拉普拉斯分布尺度 $0.8$，每个时间点的眨眼率 $0.02$，眼动图噪声标准差 $0.20$，脑活动图噪声标准差 $1.00$。\n- 测试用例2（高空间图噪声，重叠）：种子 $1$，$N=120$，$T=3000$，$C=64$，眼动分量比例 $0.25$，$\\phi_o=0.93$，$\\phi_b=0.45$，拉普拉斯分布尺度 $0.7$，眨眼率 $0.015$，眼动图噪声标准差 $0.70$，脑活动图噪声标准差 $1.10$。\n- 测试用例3（近完美分离）：种子 $2$，$N=100$，$T=2500$，$C=64$，眼动分量比例 $0.25$，$\\phi_o=0.98$，$\\phi_b=0.25$，拉普拉斯分布尺度 $1.2$，眨眼率 $0.020$，眼动图噪声标准差 $0.05$，脑活动图噪声标准差 $1.20$。\n- 测试用例4（小样本）：种子 $3$，$N=25$，$T=800$，$C=64$，眼动分量比例 $0.20$，$\\phi_o=0.94$，$\\phi_b=0.35$，拉普拉斯分布尺度 $0.9$，眨眼率 $0.015$，眼动图噪声标准差 $0.30$，脑活动图噪声标准差 $1.00$。\n\n您的程序应生成单行输出，其中包含测试用例1到4的AUC值，形式为方括号括起来的逗号分隔列表（例如，$[0.95,0.88,0.99,0.82]$）。此问题不涉及物理单位。传感器布局中的角度以弧度为单位，但您无需输出角度。最终列表中的所有数值输出必须是浮点数。",
            "solution": "该问题要求推导并实现一个线性分类器，用以从脑电图（EEG）数据中识别眼动独立分量。分类基于一个三维特征向量，其性能使用受试者工作特征（ROC）分析进行评估。该问题定义明确、科学合理，并为完整且可复现的解决方案提供了足够的细节。\n\n### 分类器推导\n\n目标是根据独立分量的特征向量 $f = [f_1, f_2, f_3]^\\top = [K, \\rho_1, |\\rho_{\\text{map}}|]^\\top$ 将其分类为眼动（$y=1$）或非眼动（$y=0$）。其中，$K$ 是分量时间过程的超额峰度，$\\rho_1$ 是其延迟为1的自相关，而 $|\\rho_{\\text{map}}|$ 是其空间图与标准眼电图（EOG）模板的皮尔逊相关系数的绝对值。\n\n我们将采用贝叶斯决策理论。最优决策规则是，如果一个分量为眼动分量的后验概率高于其为非眼动分量的后验概率，即 $p(y=1|f)  p(y=0|f)$，则将其分类为眼动分量。使用贝叶斯定理 $p(y|f) = \\frac{p(f|y)P(y)}{p(f)}$，该不等式等价于：\n$$\n\\log\\frac{p(y=1|f)}{p(y=0|f)} = \\log\\frac{p(f|y=1)}{p(f|y=0)} + \\log\\frac{P(y=1)}{P(y=0)}  0\n$$\n第一项是对数似然比，第二项是对数先验几率。决策分数 $s(f)$ 通常根据对数后验概率比定义。\n\n问题规定，假设特征服从类条件高斯分布，且协方差矩阵为对角矩阵：\n$$\np(f|y=c) \\sim \\mathcal{N}(\\mu_c, \\Sigma_c), \\quad \\text{其中 } c \\in \\{0, 1\\} \\text{ and } \\Sigma_c = \\text{diag}(\\sigma_{c,1}^2, \\sigma_{c,2}^2, \\sigma_{c,3}^2)\n$$\n类别 $c$ 的对数概率密度函数为：\n$$\n\\log p(f|y=c) = -\\frac{1}{2} \\sum_{j=1}^{3} \\left( \\frac{(f_j - \\mu_{c,j})^2}{\\sigma_{c,j}^2} \\right) - \\frac{1}{2} \\sum_{j=1}^{3} \\log(2\\pi\\sigma_{c,j}^2)\n$$\n问题指定要基于*合并*对角方差推导一个*线性*分类器分数 $s(f) = w^\\top f$。这对应于线性判别分析（LDA）的框架，该框架做出了所有类别共享一个通用协方差矩阵的简化假设：$\\Sigma_1 = \\Sigma_0 = \\Sigma_{\\text{pooled}}$。\n\n在此假设下，对数似然比变为：\n$$\n\\log\\frac{p(f|y=1)}{p(f|y=0)} = \\log p(f|y=1) - \\log p(f|y=0)\n$$\n代入高斯概率密度函数，并注意到 $\\log(2\\pi |\\Sigma_{\\text{pooled}}|)$ 项是相同的，因此会抵消：\n$$\n= \\left[ -\\frac{1}{2}(f - \\mu_1)^\\top \\Sigma_{\\text{pooled}}^{-1} (f - \\mu_1) \\right] - \\left[ -\\frac{1}{2}(f - \\mu_0)^\\top \\Sigma_{\\text{pooled}}^{-1} (f - \\mu_0) \\right]\n$$\n展开二次型：\n$$\n= -\\frac{1}{2} \\left[ (f^\\top \\Sigma_{\\text{pooled}}^{-1} f - 2f^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_1 + \\mu_1^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_1) - (f^\\top \\Sigma_{\\text{pooled}}^{-1} f - 2f^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_0 + \\mu_0^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_0) \\right]\n$$\n关于 $f$ 的二次项 $f^\\top \\Sigma_{\\text{pooled}}^{-1} f$ 相互抵消，得到一个关于 $f$ 的线性函数：\n$$\n= f^\\top \\Sigma_{\\text{pooled}}^{-1} (\\mu_1 - \\mu_0) - \\frac{1}{2} (\\mu_1^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_1 - \\mu_0^\\top \\Sigma_{\\text{pooled}}^{-1} \\mu_0)\n$$\n决策分数 $s(f)$ 定义为对数后验概率比中依赖于观测值 $f$ 的部分。忽略常数偏置项（可以被吸收到决策阈值中），我们得到线性分数：\n$$\ns(f) = w^\\top f \\quad \\text{其中} \\quad w = \\Sigma_{\\text{pooled}}^{-1}(\\mu_1 - \\mu_0)\n$$\n鉴于 $\\Sigma_{\\text{pooled}} = \\text{diag}(\\sigma_{\\text{pooled},1}^2, \\sigma_{\\text{pooled},2}^2, \\sigma_{\\text{pooled},3}^2)$ 的对角结构，其逆矩阵为 $\\Sigma_{\\text{pooled}}^{-1} = \\text{diag}(1/\\sigma_{\\text{pooled},1}^2, 1/\\sigma_{\\text{pooled},2}^2, 1/\\sigma_{\\text{pooled},3}^2)$。因此，权重向量 $w$ 的分量为：\n$$\nw_j = \\frac{\\mu_{1,j} - \\mu_{0,j}}{\\sigma_{\\text{pooled},j}^2} \\quad \\text{对于 } j=1, 2, 3\n$$\n\n### 参数估计（训练）\n\n参数 $\\mu_0$、$\\mu_1$ 和 $\\Sigma_{\\text{pooled}}$ 是从一组包含 $N_0$ 个非眼动分量和 $N_1$ 个眼动分量的带标签训练数据中估计的。\n1.  **类均值**：每个特征 $j$ 和类别 $c$ 的均值估计为样本均值：\n    $$\n    \\hat{\\mu}_{c,j} = \\frac{1}{N_c} \\sum_{i \\in \\text{class } c} f_{i,j}\n    $$\n2.  **类方差**：每个特征 $j$ 和类别 $c$ 的无偏样本方差为：\n    $$\n    \\hat{\\sigma}_{c,j}^2 = \\frac{1}{N_c - 1} \\sum_{i \\in \\text{class } c} (f_{i,j} - \\hat{\\mu}_{c,j})^2\n    $$\n3.  **合并方差**：每个特征 $j$ 的合并方差是类方差的加权平均：\n    $$\n    \\sigma_{\\text{pooled},j}^2 = \\frac{(N_0 - 1)\\hat{\\sigma}_{0,j}^2 + (N_1 - 1)\\hat{\\sigma}_{1,j}^2}{N_0 + N_1 - 2}\n    $$\n然后使用这些估计的参数来计算权重向量 $w$，从而完成分类器的训练。\n\n### 性能评估\n\n受试者工作特征（ROC）曲线用于评估分类器在所有可能决策阈值下的性能。ROC曲线绘制了真阳性率（TPR）对假阳性率（FPR）的曲线。\n-   $TPR = \\frac{\\text{真阳性}}{\\text{总阳性}} = \\frac{TP}{TP+FN}$\n-   $FPR = \\frac{\\text{假阳性}}{\\text{总阴性}} = \\frac{FP}{FP+TN}$\n\n曲线下面积（AUC）为性能提供了一个单一的标量度量。AUC为1.0表示一个完美的分类器，而AUC为0.5则对应于随机猜测。AUC通过对ROC曲线进行积分来计算，这在数值上是通过对改变决策阈值所生成的一组$(FPR, TPR)$点使用梯形法则来完成的。\n\n### 实现策略\n\n该解决方案涉及每个测试用例的模拟过程：\n1.  **数据合成**：生成 $N$ 个独立分量，每个分量都有一个时间过程、一个空间图和一个真实标签（眼动/非眼动）。\n    -   时间过程通过AR($1$)过程 $x_t = \\phi x_{t-1} + \\epsilon_t$ 生成，具有指定的 $\\phi$ 和新息分布（眼动为拉普拉斯分布，非眼动为高斯分布）。眼动分量还叠加了高振幅的局部脉冲以模拟眨眼。\n    -   空间图相对于一个EOG模板生成。该模板可以在传感器的单位圆上建模为 $e_i = \\sin(\\theta_i)$，创建一个双极额-枕拓扑结构。眼动图是该模板加上小噪声；非眼动图是随机噪声。\n2.  **特征提取**：对于每个合成分量，根据提供的公式计算三个特征 $K$、$\\rho_1$ 和 $|\\rho_{\\text{map}}|$。\n3.  **分类器训练**：使用生成的全套特征和标签，估计参数 $\\hat{\\mu}_0, \\hat{\\mu}_1, \\sigma^2_{\\text{pooled}}$ 并计算权重向量 $w$。\n4.  **评分和评估**：为每个分量 $i$ 计算决策分数 $s_i = w^\\top f_i$。使用这些分数和真实标签，计算ROC曲线和AUC。最终输出是所有测试用例的AUC值列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import lfilter\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Test Case 1 (happy path)\n        {\"seed\": 0, \"N\": 120, \"T\": 3000, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.95, \"phi_b\": 0.40, \"laplace_scale\": 0.8,\n         \"blink_rate\": 0.02, \"ocular_map_noise_std\": 0.20,\n         \"brain_map_noise_std\": 1.00},\n        # Test Case 2 (high map noise, overlap)\n        {\"seed\": 1, \"N\": 120, \"T\": 3000, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.93, \"phi_b\": 0.45, \"laplace_scale\": 0.7,\n         \"blink_rate\": 0.015, \"ocular_map_noise_std\": 0.70,\n         \"brain_map_noise_std\": 1.10},\n        # Test Case 3 (near-perfect separation)\n        {\"seed\": 2, \"N\": 100, \"T\": 2500, \"C\": 64, \"ocular_fraction\": 0.25,\n         \"phi_o\": 0.98, \"phi_b\": 0.25, \"laplace_scale\": 1.2,\n         \"blink_rate\": 0.020, \"ocular_map_noise_std\": 0.05,\n         \"brain_map_noise_std\": 1.20},\n        # Test Case 4 (small sample)\n        {\"seed\": 3, \"N\": 25, \"T\": 800, \"C\": 64, \"ocular_fraction\": 0.20,\n         \"phi_o\": 0.94, \"phi_b\": 0.35, \"laplace_scale\": 0.9,\n         \"blink_rate\": 0.015, \"ocular_map_noise_std\": 0.30,\n         \"brain_map_noise_std\": 1.00},\n    ]\n\n    results = []\n    for params in test_cases:\n        auc = run_simulation(params)\n        results.append(auc)\n        \n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\n\ndef run_simulation(params):\n    \"\"\"\n    Executes a single simulation run for a given set of parameters.\n    \"\"\"\n    np.random.seed(params[\"seed\"])\n    \n    # 1. Generate synthetic data\n    components, labels, eog_template = generate_synthetic_data(params)\n    \n    # 2. Extract features\n    features = np.array([extract_features(comp, eog_template) for comp in components])\n    \n    # 3. Train LDA classifier\n    weights = train_lda_weights(features, labels)\n    \n    # 4. Calculate decision scores\n    scores = features @ weights\n    \n    # 5. Compute AUC\n    auc = compute_auc(scores, labels)\n    \n    return auc\n\n\ndef generate_synthetic_data(params):\n    \"\"\"\n    Generates synthetic independent components (time courses and spatial maps).\n    \"\"\"\n    N = params[\"N\"]\n    T = params[\"T\"]\n    C = params[\"C\"]\n    ocular_fraction = params[\"ocular_fraction\"]\n    \n    # Determine labels for each component\n    n_ocular = int(N * ocular_fraction)\n    labels = np.array([1] * n_ocular + [0] * (N - n_ocular))\n    \n    # Generate EOG template for spatial maps\n    sensor_angles = np.linspace(0, 2 * np.pi, C, endpoint=False)\n    eog_template = np.sin(sensor_angles) # Bipolar template (frontal positive, posterior negative)\n\n    components = []\n    for i in range(N):\n        is_ocular = (labels[i] == 1)\n        \n        # Generate time course\n        if is_ocular:\n            phi = params[\"phi_o\"]\n            innovations = np.random.laplace(loc=0, scale=params[\"laplace_scale\"], size=T)\n        else:\n            phi = params[\"phi_b\"]\n            innovations = np.random.normal(loc=0, scale=1.0, size=T)\n\n        # AR(1) process: x_t = phi * x_{t-1} + e_t\n        time_course = lfilter([1], [1, -phi], innovations)\n        \n        # Add blink artifacts to ocular components\n        if is_ocular:\n            blink_rate = params[\"blink_rate\"]\n            pulse_width = 50\n            # Use Hanning window for smooth pulse shape\n            blink_pulse = np.hanning(pulse_width) * 20 * np.std(time_course) \n            blink_indices = np.where(np.random.rand(T)  blink_rate)[0]\n            for idx in blink_indices:\n                if idx + pulse_width  T:\n                    time_course[idx:idx+pulse_width] += blink_pulse\n        \n        # Generate spatial map\n        if is_ocular:\n            noise = np.random.normal(0, params[\"ocular_map_noise_std\"], size=C)\n            spatial_map = eog_template + noise\n        else:\n            spatial_map = np.random.normal(0, params[\"brain_map_noise_std\"], size=C)\n        \n        components.append((time_course, spatial_map))\n        \n    return components, labels, eog_template\n\n\ndef extract_features(component, eog_template):\n    \"\"\"\n    Extracts the three features (K, rho_1, |rho_map|) from a component.\n    \"\"\"\n    time_course, spatial_map = component\n    T = len(time_course)\n    \n    # Center the time course\n    mu = np.mean(time_course)\n    x_centered = time_course - mu\n    \n    # Calculate moments\n    m2 = np.mean(x_centered**2)\n    m4 = np.mean(x_centered**4)\n    \n    # Feature 1: Excess Kurtosis\n    if m2  1e-9: # Avoid division by zero\n        kurtosis = 0.0\n    else:\n        kurtosis = m4 / (m2**2) - 3.0\n    \n    # Feature 2: Lag-one Autocorrelation\n    # rho_1 = sum_{t=2 to T} (x_t - mu)(x_{t-1} - mu) / sum_{t=1 to T} (x_t - mu)^2\n    numerator = np.sum(x_centered[1:] * x_centered[:-1])\n    denominator = np.sum(x_centered**2)\n    if denominator  1e-9:\n        autocorr = 0.0\n    else:\n        autocorr = numerator / denominator\n\n    # Feature 3: Absolute Pearson correlation with EOG template\n    # Using np.corrcoef which returns a 2x2 matrix\n    corr_matrix = np.corrcoef(spatial_map, eog_template)\n    map_corr = abs(corr_matrix[0, 1])\n    \n    return np.array([kurtosis, autocorr, map_corr])\n\n\ndef train_lda_weights(features, labels):\n    \"\"\"\n    Trains the LDA classifier weights from feature data and labels.\n    \"\"\"\n    f_ocular = features[labels == 1]\n    f_brain = features[labels == 0]\n    \n    N0 = f_brain.shape[0]\n    N1 = f_ocular.shape[0]\n    \n    # Estimate class means\n    mu0 = np.mean(f_brain, axis=0)\n    mu1 = np.mean(f_ocular, axis=0)\n    \n    # Estimate class variances (unbiased, ddof=1)\n    var0 = np.var(f_brain, axis=0, ddof=1)\n    var1 = np.var(f_ocular, axis=0, ddof=1)\n    \n    # Compute pooled variance\n    # Handle cases where a class has 0 or 1 samples\n    if N0 + N1 > 2:\n        pooled_var = ((N0 - 1) * var0 + (N1 - 1) * var1) / (N0 + N1 - 2)\n    else:\n        # Fallback if too few samples for pooled variance\n        pooled_var = np.ones_like(mu0)\n\n    # Avoid division by zero for features with no variance\n    pooled_var[pooled_var  1e-9] = 1.0\n\n    # Compute weights\n    weights = (mu1 - mu0) / pooled_var\n    \n    return weights\n\n\ndef compute_auc(scores, labels):\n    \"\"\"\n    Computes the Area Under the ROC Curve (AUC).\n    \"\"\"\n    # Combine scores and labels for sorting\n    combined = sorted(zip(scores, labels), key=lambda x: x[0], reverse=True)\n    \n    P = np.sum(labels == 1)\n    N = np.sum(labels == 0)\n\n    if P == 0 or N == 0:\n        return 0.5 # Cannot compute AUC if one class is missing\n\n    tpr_list = [0.0]\n    fpr_list = [0.0]\n    \n    tp = 0\n    fp = 0\n    \n    last_score = -np.inf\n    \n    for i in range(len(combined)):\n        score, label = combined[i]\n        \n        if score != last_score:\n            tpr_list.append(tp / P)\n            fpr_list.append(fp / N)\n            last_score = score\n        \n        if label == 1:\n            tp += 1\n        else:\n            fp += 1\n            \n    tpr_list.append(tp / P)\n    fpr_list.append(fp / N)\n    \n    # Calculate AUC using trapezoidal rule\n    return np.trapz(tpr_list, fpr_list)\n\nif __name__ == '__main__':\n    solve()\n\n```"
        }
    ]
}