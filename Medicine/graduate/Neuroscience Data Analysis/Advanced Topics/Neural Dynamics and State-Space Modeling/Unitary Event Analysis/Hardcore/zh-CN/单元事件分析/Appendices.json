{
    "hands_on_practices": [
        {
            "introduction": "单元事件分析的第一步是确定一个基准，即在神经元独立放电的“偶然”情况下，我们期望看到多少同步事件。这个练习将指导你从第一性原理出发，推导出在零假设（即神经元放电是独立的）下预期的巧合计数。通过这个实践，你将巩固对单元事件分析底层统计模型的理解，并明确实践中关键假设的意义 。",
            "id": "4202846",
            "problem": "考虑一个使用单元事件 (Unitary Event, UE) 分析法分析的数据集，其中脉冲序列被离散化为宽度为 $\\Delta = 5 \\times 10^{-3}$ 秒的非重叠时间窗，并且当一个指定子集中的每个神经元在同一个时间窗内至少发放一次脉冲时，定义为一次巧合事件。假设在单个时间窗 $t$ 内，不同神经元的脉冲发放被建模为独立的伯努利试验，其成功概率为 $p_i(t)$，该概率由于非平稳的发放率而可能随时间窗变化。对于子集 $S = \\{1, 2\\}$，在时间窗 $t = 1, \\dots, 12$ 内，估计的每个时间窗的脉冲概率由以下序列给出\n$p_1(1), \\dots, p_1(12) = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\n和\n$p_2(1), \\dots, p_2(12) = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$。\n从概率论的核心原理（指示随机变量和期望的线性性）以及在类泊松小时间窗假设下对每个时间窗脉冲发放的伯努利近似出发，推导在窗口 $\\mathcal{W} = \\{1, \\dots, 12\\}$ 内子集 $S$ 的期望巧合次数，并计算其数值。此外，请解释为从各时间窗的巧合概率通过求和得到期望计数提供了理由的建模和数学假设。将最终数值答案表示为无量纲的计数，并四舍五入到四位有效数字。",
            "solution": "该问题要求在使用单元事件 (UE) 分析法分析的数据集中，推导并计算期望的巧合次数。我将首先验证问题陈述，然后基于概率论的第一性原理进行严格推导，解释其基本假设，并最终计算数值。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- **分析方法：** 单元事件 (UE) 分析法。\n- **时间窗宽度：** $\\Delta = 5 \\times 10^{-3}$ 秒。\n- **巧合定义：** 对于一个神经元子集，每个神经元在同一个时间窗内至少发放一次脉冲。\n- **神经元脉冲模型：** 在单个时间窗 $t$ 内，不同神经元的脉冲发放被建模为独立的伯努利试验，其成功概率为非平稳的 $p_i(t)$。\n- **神经元子集：** $S = \\{1, 2\\}$。\n- **时间窗口：** $\\mathcal{W} = \\{1, \\dots, 12\\}$ 个时间窗。\n- **神经元1的脉冲概率：** $t=1, \\dots, 12$ 的 $p_1(t)$ 序列为 $(0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$。\n- **神经元2的脉冲概率：** $t=1, \\dots, 12$ 的 $p_2(t)$ 序列为 $(0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$。\n- **目标：** 推导在 $\\mathcal{W}$ 内的期望巧合次数，计算其数值（四舍五入到四位有效数字），并解释该方法的理由。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用了计算神经科学中的标准模型（对分箱后的脉冲序列进行伯努利近似）。数学公式是一致且自洽的，提供了所有必要的数据——概率序列 $p_1(t)$ 和 $p_2(t)$ 的长度与指定的时间窗口一致。术语精确客观。问题提法得当，可以得出一个唯一且有意义的解。它没有违反任何无效性标准。\n\n**步骤3：结论与行动**\n该问题被判定为**有效**。将提供完整解答。\n\n### 推导与求解\n\n我们按要求从概率论的核心原理开始。该分析考虑来自两个神经元（索引为 $i \\in \\{1, 2\\}$）的脉冲序列，时间窗口为 $T=12$ 个离散的时间窗。\n\n设 $X_{i,t}$ 为指示随机变量，表示神经元 $i$ 在时间窗 $t$ 内的脉冲发放，其中 $t \\in \\{1, \\dots, 12\\}$。由于脉冲发放被建模为成功概率为 $p_i(t)$ 的伯努利试验，我们有：\n$$\nX_{i,t} =\n\\begin{cases}\n1  \\text{如果神经元 } i \\text{ 在时间窗 } t \\text{ 内发放脉冲} \\\\\n0  \\text{否则}\n\\end{cases}\n$$\n发生一次脉冲的概率是 $P(X_{i,t} = 1) = p_i(t)$，不发生脉冲的概率是 $P(X_{i,t} = 0) = 1 - p_i(t)$。此指示变量的期望为 $E[X_{i,t}] = 1 \\cdot P(X_{i,t}=1) + 0 \\cdot P(X_{i,t}=0) = p_i(t)$。\n\n在时间窗 $t$ 内的一次巧合被定义为神经元1和神经元2都在该时间窗内发放脉冲的事件。设 $C_t$ 为在时间窗 $t$ 内发生巧合的指示随机变量。要发生一次巧合 ($C_t = 1$)，必须有 $X_{1,t} = 1$ 和 $X_{2,t} = 1$ 同时成立。这意味着联合事件的指示随机变量可以表示为各个指示随机变量的乘积：\n$$C_t = X_{1,t} X_{2,t}$$\n在单个时间窗 $t$ 内的期望巧合次数是 $C_t$ 的期望值，即 $E[C_t]$。由于 $C_t$ 是一个指示随机变量，其期望值等于它所指示事件的概率：\n$$E[C_t] = P(C_t = 1) = P(X_{1,t}=1 \\text{ 且 } X_{2,t}=1)$$\n问题陈述，在单个时间窗内，不同神经元的脉冲发放被建模为独立的。这是一个关键假设。在此独立性假设下，联合概率是边缘概率的乘积：\n$$P(X_{1,t}=1 \\text{ 且 } X_{2,t}=1) = P(X_{1,t}=1) \\times P(X_{2,t}=1) = p_1(t) p_2(t)$$\n因此，在时间窗 $t$ 内的期望巧合次数为：\n$$E[C_t] = p_1(t) p_2(t)$$\n在整个窗口 $\\mathcal{W}$ 内的总巧合次数 $N_C$ 是每个时间窗中巧合次数的总和：\n$$N_C = \\sum_{t=1}^{12} C_t$$\n为了求这个和的期望值 $E[N_C]$，我们应用期望的线性性原理。该原理指出，随机变量之和的期望等于它们各自期望之和，即 $E[\\sum_k Y_k] = \\sum_k E[Y_k]$。这是一个基本性质，无论随机变量 $Y_k$ 是否独立都成立。在我们的情况下，这意味着我们不需要假设不同时间窗内的巧合事件是独立的。\n将期望的线性性应用于 $N_C$：\n$$E[N_C] = E\\left[\\sum_{t=1}^{12} C_t\\right] = \\sum_{t=1}^{12} E[C_t]$$\n代入我们关于 $E[C_t]$ 的表达式，我们得到期望总巧合次数的最终公式：\n$$E[N_C] = \\sum_{t=1}^{12} p_1(t) p_2(t)$$\n\n### 假设的合理性\n\n问题明确要求为对每个时间窗的量进行求和提供理由，并陈述建模假设。\n\n1.  **对时间窗求和：** 将每个时间窗的期望值 $\\sum_{t} E[C_t]$ 相加来获得总期望计数 $E[N_C]$，其严谨性由**期望的线性性**保证。如上所述，此性质允许将总期望分解为每个时间窗的期望之和，而无需假设*跨*时间窗的脉冲活动是独立的。\n\n2.  **建模假设：**\n    -   **伯努利脉冲模型：** 将一个时间窗内的脉冲发放表示为伯努利试验是一种近似。如果时间窗宽度 $\\Delta$ 足够小，这种做法是合理的。这被称为“类泊松小时间窗假设”。如果脉冲发放是一个瞬时速率为 $\\lambda(t)$ 的泊松过程，那么在一个小区间 $\\Delta$ 内出现一次或多次脉冲的概率是 $1 - \\exp(-\\lambda(t)\\Delta)$。当 $\\lambda(t)\\Delta$ 很小时，泰勒展开给出 $1 - (1 - \\lambda(t)\\Delta + O((\\lambda(t)\\Delta)^2)) \\approx \\lambda(t)\\Delta$。这就得到了伯努利概率 $p(t) = \\lambda(t)\\Delta$。在此假设下，时间窗内出现一次以上脉冲的概率可以忽略不计。\n    -   **神经元的独立性（在时间窗内）：** 计算 $E[C_t] = p_1(t) p_2(t)$ 关键依赖于这样一个假设，即神经元1和神经元2的脉冲发放是*在同一时间窗内*的统计独立事件。在UE分析的背景下，这个假设构成了零假设（$H_0$）的基础，即巧合事件以偶然预测的速率发生。然后将观测到的巧合次数与这个期望次数进行比较，以检验是否存在超额相关（即“单元事件”）。\n\n### 数值计算\n\n现在我们使用所提供的数据计算 $E[N_C]$ 的值。\n序列为：\n$P_1 = (0.11, 0.12, 0.10, 0.09, 0.13, 0.15, 0.18, 0.16, 0.14, 0.12, 0.11, 0.10)$\n$P_2 = (0.08, 0.09, 0.07, 0.06, 0.10, 0.12, 0.15, 0.13, 0.11, 0.09, 0.08, 0.07)$\n\n我们为每个时间窗 $t=1, \\dots, 12$ 计算乘积 $p_1(t) p_2(t)$：\n- $t=1$: $0.11 \\times 0.08 = 0.0088$\n- $t=2$: $0.12 \\times 0.09 = 0.0108$\n- $t=3$: $0.10 \\times 0.07 = 0.0070$\n- $t=4$: $0.09 \\times 0.06 = 0.0054$\n- $t=5$: $0.13 \\times 0.10 = 0.0130$\n- $t=6$: $0.15 \\times 0.12 = 0.0180$\n- $t=7$: $0.18 \\times 0.15 = 0.0270$\n- $t=8$: $0.16 \\times 0.13 = 0.0208$\n- $t=9$: $0.14 \\times 0.11 = 0.0154$\n- $t=10$: $0.12 \\times 0.09 = 0.0108$\n- $t=11$: $0.11 \\times 0.08 = 0.0088$\n- $t=12$: $0.10 \\times 0.07 = 0.0070$\n\n将这些值相加：\n$$E[N_C] = 0.0088 + 0.0108 + 0.0070 + 0.0054 + 0.0130 + 0.0180 + 0.0270 + 0.0208 + 0.0154 + 0.0108 + 0.0088 + 0.0070$$\n$$E[N_C] = 0.1528$$\n问题要求答案四舍五入到四位有效数字。计算出的值 $0.1528$ 已经有四位有效数字。",
            "answer": "$$\\boxed{0.1528}$$"
        },
        {
            "introduction": "在计算出预期巧合数 $E$ 后，下一步是将其与实验中实际观测到的巧合数 $O$ 进行比较，以判断是否存在统计上显著的超额同步。本练习引入了“惊讶指数” $S$ 作为一个衡量显著性的指标，并使用泊松分布作为对巧合总数进行建模的常用近似方法。通过解决这个问题，你将学会如何将原始计数值转化为一个p值和直观的惊讶指数，这是假设检验中的一项核心技能 。",
            "id": "4202879",
            "problem": "考虑对两个同时记录的神经元中的重合脉冲进行酉事件（Unitary Event, UE）分析。假设零假设为：重合是由许多时间区间上聚合的独立泊松过程产生的，因此分析窗口中的重合次数被建模为具有均值（期望次数）$E$ 的单个泊松计数。在给定 $E$ 的情况下，观测到至少 $O$ 次重合的单边零概率是泊松上尾概率 $p(O;E)$，定义为 $p(O;E) = \\sum_{k=O}^{\\infty} \\exp(-E) \\frac{E^{k}}{k!}$。定义惊奇指数 $S$ 为 $S = -\\log_{10}(p)$，因此当且仅当 $p \\le 10^{-2}$ 时，$S \\ge 2$。\n\n假设分析窗口中期望的重合次数为 $E = 6.0$。对于观测到的重合次数 $O \\in \\{10, 11, 12, 13, 14\\}$：\n- 在泊松零模型下，从泊松分布及其尾概率的基本定义出发，计算惊奇指数 $S(O;E)$。\n- 确定最小整数阈值 $O^{\\ast}$，使得 $S(O^{\\ast};6.0) \\ge 2$。\n\n尽可能用精确的符号形式表示所有中间数学量，并仅在需要确定 $O^{\\ast}$ 时进行数值评估。最终答案必须是单个整数 $O^{\\ast}$。不需要单位。",
            "solution": "该问题是有效的，因为它在科学上基于神经科学中常用的统计分析方法，问题陈述清晰、客观且内部一致。\n\n目标是找到观测到的重合次数的最小整数 $O^{\\ast}$，使得在给定期望次数 $E = 6.0$ 的情况下，惊奇指数 $S(O^{\\ast}; E) \\ge 2$。\n\n惊奇指数 $S$ 定义为 $S = -\\log_{10}(p)$，其中 $p$ 是单边零概率。条件 $S \\ge 2$ 等价于：\n$$ -\\log_{10}(p) \\ge 2 $$\n两边乘以 $-1$ 并反转不等号得到：\n$$ \\log_{10}(p) \\le -2 $$\n对两边应用单调递增函数 $10^x$ 得出：\n$$ p \\le 10^{-2} \\quad \\text{或} \\quad p \\le 0.01 $$\n在给定期望次数 $E$ 的情况下，观测到至少 $O$ 个事件的零概率 $p(O;E)$ 由泊松上尾概率定义：\n$$ p(O;E) = \\sum_{k=O}^{\\infty} \\exp(-E) \\frac{E^{k}}{k!} $$\n因此，我们需要找到满足 $p(O; 6.0) \\le 0.01$ 的最小整数 $O$。\n\n直接计算无穷级数是不切实际的。使用互补概率更方便，因为它涉及一个有限和。所有泊松概率的总和为 $1$：\n$$ \\sum_{k=0}^{\\infty} \\exp(-E) \\frac{E^{k}}{k!} = 1 $$\n因此，尾概率可以表示为：\n$$ p(O;E) = 1 - \\sum_{k=0}^{O-1} \\exp(-E) \\frac{E^{k}}{k!} $$\n项 $\\sum_{k=0}^{O-1} \\exp(-E) \\frac{E^{k}}{k!}$ 是在 $O-1$ 处评估的泊松分布的累积分布函数 (CDF)，我们可以将其表示为 $F(O-1; E)$。\n条件变为：\n$$ 1 - F(O-1; E) \\le 0.01 $$\n$$ F(O-1; E) \\ge 0.99 $$\n我们已知 $E=6.0$，需要测试集合 $\\{10, 11, 12, 13, 14\\}$ 中的 $O$ 值，以找到满足此条件的最小整数 $O^{\\ast}$。让我们计算当 $m = O-1$ 时的累积分布函数 (CDF)，$F(m; 6) = \\exp(-6) \\sum_{k=0}^{m} \\frac{6^k}{k!}$。\n\n对于 $O=10$，我们评估 $F(9; 6)$：\n$$ F(9; 6) = \\exp(-6) \\sum_{k=0}^{9} \\frac{6^k}{k!} \\approx 0.91608 $$\n这得到 $p(10; 6) = 1 - F(9; 6) \\approx 1 - 0.91608 = 0.08392$。\n惊奇指数为 $S(10; 6) = -\\log_{10}(0.08392) \\approx 1.076$。由于 $1.076  2$，因此 $O=10$ 不是阈值。\n\n对于 $O=11$，我们评估 $F(10; 6)$：\n$$ F(10; 6) = \\exp(-6) \\sum_{k=0}^{10} \\frac{6^k}{k!} \\approx 0.95738 $$\n这得到 $p(11; 6) = 1 - F(10; 6) \\approx 1 - 0.95738 = 0.04262$。\n惊奇指数为 $S(11; 6) = -\\log_{10}(0.04262) \\approx 1.370$。由于 $1.370  2$，因此 $O=11$ 不是阈值。\n\n对于 $O=12$，我们评估 $F(11; 6)$：\n$$ F(11; 6) = \\exp(-6) \\sum_{k=0}^{11} \\frac{6^k}{k!} \\approx 0.97991 $$\n这得到 $p(12; 6) = 1 - F(11; 6) \\approx 1 - 0.97991 = 0.02009$。\n惊奇指数为 $S(12; 6) = -\\log_{10}(0.02009) \\approx 1.697$。由于 $1.697  2$，因此 $O=12$ 不是阈值。\n\n对于 $O=13$，我们评估 $F(12; 6)$：\n$$ F(12; 6) = \\exp(-6) \\sum_{k=0}^{12} \\frac{6^k}{k!} \\approx 0.99118 $$\n这里，$F(12; 6) \\approx 0.99118 \\ge 0.99$。这是满足条件的第一个 $O-1$ 的值。\n我们来计算相应的 $p$ 值和惊奇指数。\n这得到 $p(13; 6) = 1 - F(12; 6) \\approx 1 - 0.99118 = 0.00882$。\n惊奇指数为 $S(13; 6) = -\\log_{10}(0.00882) \\approx 2.055$。由于 $2.055 \\ge 2$，因此 $O=13$ 满足显著性标准。\n\n由于 $S(12; 6)  2$ 且 $S(13; 6) \\ge 2$，并且对于固定的 $E$，惊奇指数 $S(O;E)$ 是 $O$ 的单调递增函数，因此最小整数阈值为 $O^{\\ast} = 13$。\n\n为完整起见，我们也可以计算 $O=14$ 的情况：\n对于 $O=14$，我们评估 $F(13; 6)$：\n$$ F(13; 6) = \\exp(-6) \\sum_{k=0}^{13} \\frac{6^k}{k!} \\approx 0.99636 $$\n这得到 $p(14; 6) = 1 - F(13; 6) \\approx 1 - 0.99636 = 0.00364$。\n惊奇指数为 $S(14; 6) = -\\log_{10}(0.00364) \\approx 2.439$。这也满足 $S \\ge 2$，但 13 是满足此条件的最小整数。\n\n因此，最小整数阈值为 $O^{\\ast}=13$。",
            "answer": "$$\n\\boxed{13}\n$$"
        },
        {
            "introduction": "虽然泊松分布是一个方便的近似，但在更严格的分析中，特别是在各时间区间内的巧合概率差异很大时，我们需要精确的计算。这个练习介绍了泊松二项分布，它是我们问题中（独立但非均匀的伯努利试验之和）巧合总数的精确概率分布。你将通过实现一个动态规划算法来计算精确的p值，并将其与泊松近似进行比较，从而深入理解两者之间的差异 。",
            "id": "4202842",
            "problem": "考虑一个基于窗口的单元事件分析 (UEA)，其中在时间窗内条件独立的原假设下，检验超出偶然水平的同步脉冲重合。在原模型下，每个时间单元的同步重合指示变量被建模为具有非同质成功概率的独立伯努利随机变量。设窗口包含 $T$ 个离散的时间单元，索引为 $t \\in \\{1, 2, \\dots, T\\}$，并设 $q(t) \\in [0,1]$ 表示在独立性假设下，时间单元 $t$ 中发生重合的偶然概率。定义随机变量 $X = \\sum_{t=1}^{T} B_t$，其中 $B_t \\sim \\text{Bernoulli}(q(t))$ 在 $t$ 上是独立的。$X$ 的分布是泊松二项分布。假设在窗口中测量到观测重合计数 $k_{\\text{obs}}$。统计问题是计算在原假设下观测到至少 $k_{\\text{obs}}$ 次重合的尾部概率（一个单边 p 值）：\n$$\np_{\\text{PB}} = \\mathbb{P}\\big(X \\ge k_{\\text{obs}}\\big).\n$$\n神经科学数据分析中常用的一种近似方法是用泊松分布代替泊松二项分布，其率参数为 $\\lambda = \\sum_{t=1}^{T} q(t)$，从而得到近似尾部概率\n$$\np_{\\text{Pois}} = \\mathbb{P}\\big(Y \\ge k_{\\text{obs}}\\big), \\quad Y \\sim \\text{Poisson}(\\lambda).\n$$\n仅从独立伯努利试验的基本概率定律和泊松分布的定义出发，推导出一个通过基于逐次卷积各时间单元两点分布的动态规划方法来精确计算 $p_{\\text{PB}}$ 的算法。然后，对于给定的集合 $\\{q(t)\\}$ 和 $k_{\\text{obs}}$，实现精确尾部概率 $p_{\\text{PB}}$ 和泊松近似 $p_{\\text{Pois}}$，并对它们进行定量比较。\n\n您的程序必须：\n- 使用动态规划（逐次与各时间单元的分布进行卷积）计算精确的泊松二项分布尾部概率 $p_{\\text{PB}}$。\n- 使用率参数 $\\lambda = \\sum_{t=1}^{T} q(t)$ 计算泊松近似尾部概率 $p_{\\text{Pois}}$。\n- 对于每个测试用例，输出一个包含三个浮点数的列表 $[p_{\\text{PB}}, p_{\\text{Pois}}, \\lvert p_{\\text{PB}} - p_{\\text{Pois}} \\rvert]$，每个浮点数精确到小数点后 $12$ 位。\n\n使用以下测试套件，其中包括一般情况、边界条件和偏态概率情景。在每种情况下，样本窗口是指定列表 $\\{q(t)\\}$ 的长度，观测计数为 $k_{\\text{obs}}$。\n\n- 测试用例 1 (一般情况，非同质小概率):\n  - $\\{q(t)\\} = [\\, 0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015 \\,]$\n  - $k_{\\text{obs}} = 4$\n- 测试用例 2 (均匀小概率，较长窗口):\n  - $\\{q(t)\\} = [\\, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02 \\,]$\n  - $k_{\\text{obs}} = 3$\n- 测试用例 3 (偏态，包含一些大概率):\n  - $\\{q(t)\\} = [\\, 0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01 \\,]$\n  - $k_{\\text{obs}} = 5$\n- 测试用例 4 (边界条件：零阈值):\n  - $\\{q(t)\\} = [\\, 0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01 \\,]$\n  - $k_{\\text{obs}} = 0$\n- 测试用例 5 (边界条件：全部成功阈值):\n  - $\\{q(t)\\} = [\\, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10 \\,]$\n  - $k_{\\text{obs}} = 10$",
            "solution": "该问题是有效的，因为它具有科学依据、问题明确、客观，并包含推导和实现解决方案所需的所有必要信息。\n\n问题的核心是计算随机变量 $X$ 的尾部概率，$X$ 是 $T$ 个独立但不同分布的伯努利随机变量之和。\n设 $X = \\sum_{t=1}^{T} B_t$，其中 $B_t \\sim \\text{Bernoulli}(q(t))$ 对于 $t \\in \\{1, 2, \\dots, T\\}$ 是独立的。$X$ 的分布被称为泊松二项分布。我们的任务是计算精确的尾部概率 $p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}})$ 并将其与泊松近似 $p_{\\text{Pois}}$进行比较。\n\n首先，我们推导一个算法来计算 $X$ 的精确概率质量函数 (PMF)，从中可以得到 $p_{\\text{PB}}$。该算法基于动态规划，利用了逐次卷积的原理。\n设 $X_n = \\sum_{t=1}^{n} B_t$ 为前 $n$ 个伯努利变量的和。$X_n$ 的 PMF 可以递归计算。基本情况是 $n=1$，此时 $X_1 = B_1$。$X_1$ 的 PMF 由以下公式给出：\n$$ \\mathbb{P}(X_1=0) = 1 - q(1) $$\n$$ \\mathbb{P}(X_1=1) = q(1) $$\n对于递归步骤，我们将 $X_n$ 表示为 $X_{n-1}$ 和 $B_n$ 的形式：\n$$ X_n = X_{n-1} + B_n $$\n由于 $B_n$ 独立于 $X_{n-1}$（它是 $B_1, \\dots, B_{n-1}$ 的和），$X_n$ 的 PMF 是 $X_{n-1}$ 和 $B_n$ 的 PMF 的卷积。设 $P_n(k) = \\mathbb{P}(X_n=k)$。卷积公式为：\n$$ P_n(k) = \\sum_{j=0}^{k} \\mathbb{P}(X_{n-1}=j) \\cdot \\mathbb{P}(B_n=k-j) $$\n由于 $B_n$ 只能取值 $0$ 或 $1$，该和简化为两项：\n$$ P_n(k) = \\mathbb{P}(X_{n-1}=k) \\cdot \\mathbb{P}(B_n=0) + \\mathbb{P}(X_{n-1}=k-1) \\cdot \\mathbb{P}(B_n=1) $$\n代入伯努利试验 $B_n$ 的概率，我们得到递推关系：\n$$ P_n(k) = P_{n-1}(k) \\cdot (1 - q(n)) + P_{n-1}(k-1) \\cdot q(n) $$\n并且我们约定，如果 $k  0$ 或 $k  n-1$，则 $P_{n-1}(k)=0$。\n\n这个递推关系构成了动态规划算法的基础。我们可以将 $X_n$ 的 PMF 表示为一个概率数组，例如 `pmf_n`。我们从 $X_0$ 的 PMF 开始，它是一个以概率 1 等于 0 的退化随机变量。这由数组 `[1.0]` 表示。然后我们从 $n=1$ 迭代到 $T$，在每个步骤 $n$ 中，根据递推关系使用 `pmf_{n-1}` 和 $q(n)$ 来计算 `pmf_n`。\n算法流程如下：\n1. 初始化一个大小为 $T+1$ 的概率向量 `pmf` 来表示和的 PMF。对于 $X_0$，这是 `[1.0, 0.0, ..., 0.0]`。\n2. 对于从 $1$ 到 $T$ 的每次试验 $t$，其概率为 $q(t)$：更新 `pmf` 向量。设此步骤前的向量为 $P_{t-1}$。通过从 $k=t$ 向下迭代到 $1$ 来计算新向量 $P_t$：$P_t(k) \\leftarrow P_{t-1}(k) \\cdot (1 - q(t)) + P_{t-1}(k-1) \\cdot q(t)$。$k=0$ 的情况是特殊的：$P_t(0) \\leftarrow P_{t-1}(0) \\cdot (1 - q(t))$。反向迭代对于 `pmf` 数组的原地更新至关重要。\n3. 在遍历所有 $T$ 次试验后，`pmf` 向量持有 $X = X_T$ 的 PMF。\n所需的结果尾部概率则是所有大于或等于 $k_{\\text{obs}}$ 的结果的概率之和：\n$$ p_{\\text{PB}} = \\mathbb{P}(X \\ge k_{\\text{obs}}) = \\sum_{k=k_{\\text{obs}}}^{T} P_T(k) $$\n\n接下来，我们讨论泊松近似。泊松二项分布可以用一个泊松分布来近似，其率参数 $\\lambda$ 等于各个伯努利概率之和：\n$$ \\lambda = \\sum_{t=1}^{T} q(t) $$\n设 $Y \\sim \\text{Poisson}(\\lambda)$。$Y$ 的 PMF 是：\n$$ \\mathbb{P}(Y=k) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\quad \\text{for } k=0, 1, 2, \\dots $$\n近似尾部概率 $p_{\\text{Pois}}$ 是 $\\mathbb{P}(Y \\ge k_{\\text{obs}})$。通过累积分布函数 (CDF) 的补集来计算这个值在数值上更稳定：\n$$ p_{\\text{Pois}} = \\mathbb{P}(Y \\ge k_{\\text{obs}}) = 1 - \\mathbb{P}(Y  k_{\\text{obs}}) = 1 - \\sum_{k=0}^{k_{\\text{obs}}-1} \\mathbb{P}(Y=k) $$\n对于 $k_{\\text{obs}}=0$，这个和是空的，其值为 $0$，所以 $p_{\\text{Pois}}=1$。对于 $k_{\\text{obs}}0$，我们可以迭代地计算这个和。设 $S_{j} = \\sum_{k=0}^{j} \\mathbb{P}(Y=k)$。和的各项可以递归计算：\n$$ \\mathbb{P}(Y=k) = \\mathbb{P}(Y=k-1) \\cdot \\frac{\\lambda}{k} $$\n从 $\\mathbb{P}(Y=0)=e^{-\\lambda}$ 开始。我们将这些项从 $k=0$ 加到 $k_{\\text{obs}}-1$ 来得到 CDF 值，然后用 $1$ 减去它来得到尾部概率 $p_{\\text{Pois}}$。\n\n最后，定量比较是绝对差 $|p_{\\text{PB}} - p_{\\text{Pois}}|$。实现将为每个测试用例计算这三个值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_poisson_binomial_tail(q_list, k_obs):\n    \"\"\"\n    Computes the exact tail probability P(X = k_obs) for a Poisson Binomial distribution.\n    The distribution is the sum of independent Bernoulli trials with probabilities q_list.\n    This is achieved using a dynamic programming approach based on successive convolutions.\n    \"\"\"\n    T = len(q_list)\n\n    if k_obs  T:\n        return 0.0\n    if k_obs = 0:\n        k_obs = 0\n    \n    # pmf array stores P(X_n = k) at index k.\n    # Initialize for a sum of 0 trials, where P(sum=0) = 1.\n    pmf = np.zeros(T + 1, dtype=np.float64)\n    pmf[0] = 1.0\n    \n    # Iterate through each Bernoulli trial\n    # num_trials tracks the number of trials processed so far (from 1 to T)\n    num_trials = 0\n    for q_t in q_list:\n        num_trials += 1\n        # Update the pmf from a sum of num_trials-1 Bernoullis to num_trials.\n        # The recurrence is: P_n(k) = P_{n-1}(k)*(1-q_t) + P_{n-1}(k-1)*q_t\n        # We iterate backwards to use the values from the previous step (pmf_{n-1})\n        # before they are overwritten.\n        # The loop range covers a max possible sum of num_trials.\n        for k in range(num_trials, 0, -1):\n            pmf[k] = pmf[k] * (1.0 - q_t) + pmf[k - 1] * q_t\n        \n        # Update the k=0 case separately\n        pmf[0] = pmf[0] * (1.0 - q_t)\n\n    # The tail probability is the sum of probabilities from k_obs to T.\n    p_pb_tail = np.sum(pmf[k_obs:])\n    return p_pb_tail\n\ndef compute_poisson_tail(q_list, k_obs):\n    \"\"\"\n    Computes the tail probability P(Y = k_obs) for a Poisson distribution\n    approximating the Poisson Binomial distribution.\n    The rate lambda is the sum of the Bernoulli probabilities.\n    \"\"\"\n    if k_obs = 0:\n        return 1.0\n\n    lam = np.sum(q_list)\n\n    # If lambda is 0, the only possible outcome is 0.\n    # P(Y=0) = 1, P(Y0) = 0.\n    # The tail P(Y = k_obs) is 0 for k_obs  0.\n    if lam == 0.0:\n        return 0.0\n\n    # Compute CDF P(Y  k_obs) = sum_{k=0}^{k_obs-1} P(Y=k)\n    # P(Y=k) = exp(-lam) * lam^k / k!\n    # We compute terms iteratively: term_k = term_{k-1} * lam / k\n    # Start with k=0 term\n    term = np.exp(-lam)\n    cdf_sum = term\n    \n    for k in range(1, k_obs):\n        term = term * lam / k\n        cdf_sum += term\n        \n    p_pois_tail = 1.0 - cdf_sum\n    # Due to floating point errors, result can be slightly negative. Clip at 0.\n    return max(0.0, p_pois_tail)\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general, heterogeneous small probabilities)\n        ([0.02, 0.03, 0.025, 0.015, 0.04, 0.03, 0.02, 0.05, 0.01, 0.035, 0.025, 0.02, 0.03, 0.015, 0.04, 0.025, 0.02, 0.03, 0.02, 0.05, 0.015, 0.02, 0.03, 0.025, 0.02, 0.035, 0.025, 0.02, 0.015, 0.04, 0.03, 0.02, 0.015, 0.05, 0.02, 0.025, 0.03, 0.02, 0.035, 0.015], 4),\n        # Test case 2 (uniform small probabilities, longer window)\n        ([0.02] * 50, 3),\n        # Test case 3 (skewed with a few large probabilities)\n        ([0.30, 0.25, 0.20, 0.05, 0.01, 0.02, 0.01, 0.05, 0.02, 0.01, 0.03, 0.01, 0.02, 0.01, 0.01], 5),\n        # Test case 4 (boundary: zero threshold)\n        ([0.05, 0.02, 0.03, 0.04, 0.01, 0.02, 0.05, 0.03, 0.02, 0.01], 0),\n        # Test case 5 (boundary: full successes threshold)\n        ([0.10] * 10, 10),\n    ]\n\n    all_results_formatted = []\n    for q_list, k_obs in test_cases:\n        \n        p_pb = compute_poisson_binomial_tail(q_list, k_obs)\n        p_pois = compute_poisson_tail(q_list, k_obs)\n        diff = abs(p_pb - p_pois)\n        \n        case_results = [p_pb, p_pois, diff]\n        formatted_case_results = [f\"{val:.12f}\" for val in case_results]\n        all_results_formatted.append(f\"[{','.join(formatted_case_results)}]\")\n\n    print(f\"[{','.join(all_results_formatted)}]\")\n\nsolve()\n```"
        }
    ]
}