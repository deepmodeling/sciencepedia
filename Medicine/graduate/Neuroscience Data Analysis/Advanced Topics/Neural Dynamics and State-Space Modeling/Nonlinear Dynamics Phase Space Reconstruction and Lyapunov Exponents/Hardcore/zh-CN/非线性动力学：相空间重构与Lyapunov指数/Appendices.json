{
    "hands_on_practices": [
        {
            "introduction": "在应用复杂的非线性分析算法之前，深刻理解所测量物理量的基本性质至关重要。本练习聚焦于最大李雅普诺夫指数，探讨其数值如何与系统内在的时间尺度以及我们的测量参数（如采样率）相关联。通过从第一性原理出发进行推导，你将掌握如何正确地解释和转换从离散时间序列中估计出的指数，确保其物理意义的准确性。",
            "id": "4182450",
            "problem": "从微电极阵列中记录到一个皮层群体信号，它是一个标量时间序列，用于通过延迟坐标嵌入来重构状态空间。为了量化对初始条件的敏感性，我们通过附近重构轨道之间分离的短期增长来估计最大李雅普诺夫指数。具体来说，对于小的整数延迟 $k$（以样本为单位），系综平均的对数分离近似呈线性行为，即 $\\ln\\!\\big(d(k)/d(0)\\big) \\approx \\mu\\,k$，其中 $d(k)$ 是延迟 $k$ 处的平均分离，$\\mu$ 是斜率，单位是“每样本”。\n\n假设潜在的连续时间神经动力学由 $\\dot{\\mathbf{x}}(t)=\\mathbf{F}(\\mathbf{x}(t))$ 通用描述，并回顾最大李雅普诺夫指数的核心定义，即单位时间内的渐近指数分离率，\n$$\n\\lambda \\;=\\; \\lim_{t\\to\\infty}\\frac{1}{t}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right),\n$$\n对于足够小的 $\\|\\delta\\mathbf{x}(0)\\|$。您考虑通过变量替换 $t' = c\\,t$ 对时间进行一个因子为 $c0$ 的均匀重标度，这会产生一个新的流 $\\dfrac{d\\mathbf{x}}{dt'} = \\dfrac{1}{c}\\,\\mathbf{F}(\\mathbf{x})$。\n\n从上述定义出发，不使用任何快捷公式，推导在均匀时间重标度下最大李雅普诺夫指数如何变换，并解释在给定采样间隔 $\\Delta t$ 的情况下，离散时间斜率 $\\mu$（每样本）与连续时间 $\\lambda$（每秒）之间的关系。然后，将您的推导应用于以下测量量：\n- 采样间隔 $\\Delta t = 1\\,\\mathrm{ms} = 0.001\\,\\mathrm{s}$，\n- 测量的短延迟斜率 $\\mu = 0.015$（每样本），\n- 均匀时间重标度因子 $c = 5$（即 $t' = c\\,t$）。\n\n计算时间重标度系统的重标度最大李雅普诺夫指数 $\\lambda'$，单位为 $\\mathrm{s}^{-1}$。最终答案以 $\\mathrm{s}^{-1}$ 表示。无需四舍五入。",
            "solution": "该问题要求推导均匀时间重标度下最大李雅普诺夫指数的变换规则，离散测量的斜率与连续时间指数之间的关系，并最终根据给定数据计算重标度后的指数。\n\n首先，我们确定最大李雅普诺夫指数 $\\lambda$ 在均匀时间重标度下的变换方式。原始系统动力学由 $\\dot{\\mathbf{x}}(t)=\\mathbf{F}(\\mathbf{x}(t))$ 给出，最大李雅普诺夫指数定义为：\n$$ \\lambda = \\lim_{t\\to\\infty}\\frac{1}{t}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) $$\n其中 $\\delta\\mathbf{x}(t)$ 是在时间 $t$ 时两条邻近轨道之间的无穷小分离向量。\n\n引入一个新的时间变量 $t'$，使得 $t' = c\\,t$，其中常数 $c > 0$。用这个新时间变量表示的动力学为 $\\frac{d\\mathbf{x}}{dt'} = \\frac{1}{c}\\,\\mathbf{F}(\\mathbf{x})$。这个重标度系统的最大李雅普诺夫指数，我们记为 $\\lambda'$，是关于时间 $t'$ 定义的：\n$$ \\lambda' = \\lim_{t'\\to\\infty}\\frac{1}{t'}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t')\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) $$\n在重标度时间 $t'$ 时的系统状态与原始系统在时间 $t = t'/c$ 时的状态相同。因此，重标度系统中时间 $t'$ 处的分离向量 $\\delta\\mathbf{x}$ 与原始系统中时间 $t=t'/c$ 处的分离向量相同。我们可以将其表示为 $\\|\\delta\\mathbf{x}(t')\\|_{\\text{rescaled}} = \\|\\delta\\mathbf{x}(t'/c)\\|_{\\text{original}}$。将此代入 $\\lambda'$ 的定义中：\n$$ \\lambda' = \\lim_{t'\\to\\infty}\\frac{1}{t'}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t'/c)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) $$\n为了将其与 $\\lambda$ 的原始定义联系起来，我们在极限中进行变量替换，使用 $t = t'/c$。当 $t' \\to \\infty$ 且 $c>0$ 时，可知 $t \\to \\infty$。代入 $t' = ct$ 得到：\n$$ \\lambda' = \\lim_{t\\to\\infty}\\frac{1}{ct}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) $$\n常数因子 $1/c$ 与极限无关，可以提出：\n$$ \\lambda' = \\frac{1}{c} \\left( \\lim_{t\\to\\infty}\\frac{1}{t}\\,\\ln\\!\\left(\\frac{\\|\\delta\\mathbf{x}(t)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) \\right) $$\n括号中的表达式是原始李雅普诺夫指数 $\\lambda$ 的定义。因此，变换规则是：\n$$ \\lambda' = \\frac{\\lambda}{c} $$\n\n其次，我们确定离散时间斜率 $\\mu$ 与连续时间指数 $\\lambda$ 之间的关系。对于连续系统，$\\lambda$ 的定义意味着对于一个小的初始分离，分离的增长近似为 $\\|\\delta\\mathbf{x}(t)\\| \\approx \\|\\delta\\mathbf{x}(0)\\| \\exp(\\lambda t)$。取自然对数得到：\n$$ \\ln\\left(\\frac{\\|\\delta\\mathbf{x}(t)\\|}{\\|\\delta\\mathbf{x}(0)\\|}\\right) \\approx \\lambda t $$\n在实验背景下，信号是在均匀间隔 $\\Delta t$ 采样的时间序列。分离 $d(k)$ 是在 $k$ 个整数时间步后测量的，这对应于总时间 $t = k\\Delta t$。因此，$d(k)$ 对应于 $\\|\\delta\\mathbf{x}(k\\Delta t)\\|$，$d(0)$ 对应于 $\\|\\delta\\mathbf{x}(0)\\|$。将这些代入连续关系中得到：\n$$ \\ln\\left(\\frac{d(k)}{d(0)}\\right) \\approx \\lambda (k\\Delta t) $$\n问题给出了对于小 $k$ 的经验观察到的线性关系：\n$$ \\ln\\left(\\frac{d(k)}{d(0)}\\right) \\approx \\mu k $$\n其中 $\\mu$ 是以“每样本”为单位测量的无量纲斜率。通过令这两个近似的右侧相等，我们得到：\n$$ \\mu k = \\lambda k \\Delta t $$\n两边同除以非零整数 $k$ 得到关系式：\n$$ \\mu = \\lambda \\Delta t $$\n这个方程将实验测量的无量纲量 $\\mu$ 与基本的连续时间物理量 $\\lambda$ 联系起来。为了从测量的斜率中求出 $\\lambda$，我们可以将其重新排列为 $\\lambda = \\mu / \\Delta t$。\n\n第三，我们应用这些结果，使用提供的数值计算重标度指数 $\\lambda'$：\n- 采样间隔 $\\Delta t = 1\\,\\mathrm{ms} = 0.001\\,\\mathrm{s}$\n- 测量的斜率 $\\mu = 0.015$（每样本）\n- 时间重标度因子 $c = 5$\n\n首先，我们根据测量数据计算原始系统的最大李雅普诺夫指数 $\\lambda$：\n$$ \\lambda = \\frac{\\mu}{\\Delta t} = \\frac{0.015}{0.001\\,\\mathrm{s}} = 15\\,\\mathrm{s}^{-1} $$\n接下来，我们使用推导出的变换规则来计算时间重标度系统的最大李雅普诺夫指数 $\\lambda'$：\n$$ \\lambda' = \\frac{\\lambda}{c} = \\frac{15\\,\\mathrm{s}^{-1}}{5} = 3\\,\\mathrm{s}^{-1} $$\n重标度后的最大李雅普诺夫指数为 $3\\,\\mathrm{s}^{-1}$。",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "系统的最大李雅普诺夫指数揭示了其可预测性的边界，但完整的李雅普诺夫谱则描绘了系统在相空间中所有方向上的拉伸与压缩情况，提供了更为丰富的动力学画像。本练习将指导你如何利用整个谱来计算卡普兰-约克维度（$D_{KY}$），这是一个对吸引子分形维数的估计。通过这个计算，你将能够量化一个复杂系统（如此处的皮层动力学）的有效自由度，从而更深入地理解其复杂性。",
            "id": "4182471",
            "problem": "从麻醉啮齿动物的初级体感皮层记录了一段皮层局部场电位 (LFP) 时间序列 $x(t)$，时长为 $1{,}200$ 秒，采样率为 $1{,}000$ Hz。在 $1$ Hz 到 $120$ Hz 之间进行带通滤波后，根据 Takens 定理，通过延迟坐标嵌入重构了吸引子。根据伪最近邻准则，选择的时间延迟为 $\\tau = 5$ ms，嵌入维度为 $m = 12$。使用局部线性雅可比近似和 Gram–Schmidt 再正交化（Benettin 方法），从重构的动力学中估计出李雅普诺夫指数集 $\\{\\lambda_i\\}_{i=1}^{m}$，并按非递增顺序排序。估计出的谱（单位为 $\\mathrm{s}^{-1}$）为\n$$\n\\lambda_1 = 0.58,\\ \\lambda_2 = 0.17,\\ \\lambda_3 = 0.04,\\ \\lambda_4 = 0.01,\\ \\lambda_5 = -0.05,\\ \\lambda_6 = -0.22,\\ \\lambda_7 = -0.31,\\ \\lambda_8 = -0.44,\\ \\lambda_9 = -0.62,\\ \\lambda_{10} = -0.88,\\ \\lambda_{11} = -1.15,\\ \\lambda_{12} = -1.50.\n$$\n从李雅普诺夫指数作为相邻轨迹分离的渐近指数率的基本定义出发，并结合谱的部分和作为维度递增子空间中净体积增长率的概念，通过确定累积体积增长从非负过渡到负的适当索引 $j$，然后进行插值以获得 $j$ 和 $j+1$ 之间的分数维，从而确定重构吸引子的 Kaplan–Yorke (李雅普诺夫) 维度 $D_{KY}$。将计算出的 $D_{KY}$ 解释为皮层动力学的有效系统维度。将最终数值答案四舍五入至四位有效数字。最终量 $D_{KY}$ 是无量纲的；请将最终答案表示为不带单位的纯数字。",
            "solution": "任务是根据给定的李雅普诺夫指数谱计算 Kaplan–Yorke 维度，记为 $D_{KY}$。李雅普诺夫指数 $\\{\\lambda_i\\}$ 量化了重构相空间中相邻轨迹发散或收敛的平均指数率。对于一个 $m$ 维系统，定义了一组 $m$ 个指数，通常按降序排列：$\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_m$。正指数表示对初始条件的敏感依赖性（混沌），因为它们对应于相空间体积局部拉伸的方向。负指数对应于局部收缩的方向。\n\nKaplan–Yorke 维度是关于动力系统吸引子信息维度的猜想，并提供了系统有效自由度的估计。它是根据李雅普诺夫谱计算的。前 $k$ 个指数的累积和 $\\sum_{i=1}^{k} \\lambda_i$ 表示相空间中 $k$ 维体积元的平均指数变化率。Kaplan–Yorke 维度被定义为该体积变化率从非负（扩张）过渡到负（收缩）时的维度。\n\nKaplan–Yorke 维度的公式为：\n$$\nD_{KY} = j + \\frac{\\sum_{i=1}^{j} \\lambda_i}{|\\lambda_{j+1}|}\n$$\n其中 $j$ 是使前 $j$ 个李雅普诺夫指数之和为非负的最大整数，即 $\\sum_{i=1}^{j} \\lambda_i \\ge 0$ 且 $\\sum_{i=1}^{j+1} \\lambda_i  0$。整数部分 $j$ 表示平均而言是扩张或稳定的子空间的维度。小数部分表示为平衡扩张所需的第一个收缩方向的贡献，有效地“填充”了下一个维度。\n\n给定嵌入维度 $m=12$ 和排序后的李雅普诺夫谱（单位为 $\\mathrm{s}^{-1}$）：\n$\\lambda_1 = 0.58$, $\\lambda_2 = 0.17$, $\\lambda_3 = 0.04$, $\\lambda_4 = 0.01$, $\\lambda_5 = -0.05$, $\\lambda_6 = -0.22$, $\\lambda_7 = -0.31$, $\\lambda_8 = -0.44$, $\\lambda_9 = -0.62$, $\\lambda_{10} = -0.88$, $\\lambda_{11} = -1.15$, $\\lambda_{12} = -1.50$。\n\n首先，我们必须通过计算指数的累积和 $S_k = \\sum_{i=1}^{k} \\lambda_i$ 来找到索引 $j$。\n$$S_1 = \\lambda_1 = 0.58$$\n$$S_2 = S_1 + \\lambda_2 = 0.58 + 0.17 = 0.75$$\n$$S_3 = S_2 + \\lambda_3 = 0.75 + 0.04 = 0.79$$\n$$S_4 = S_3 + \\lambda_4 = 0.79 + 0.01 = 0.80$$\n$$S_5 = S_4 + \\lambda_5 = 0.80 + (-0.05) = 0.75$$\n$$S_6 = S_5 + \\lambda_6 = 0.75 + (-0.22) = 0.53$$\n$$S_7 = S_6 + \\lambda_7 = 0.53 + (-0.31) = 0.22$$\n$$S_8 = S_7 + \\lambda_8 = 0.22 + (-0.44) = -0.22$$\n\n累积和 $S_k$ 在 $k \\le 7$ 时为非负，在 $k=8$ 时变为负。因此，索引 $j$ 是 $7$。\n\n现在，我们可以应用 $j=7$ 的 Kaplan–Yorke 公式：\n$$D_{KY} = j + \\frac{\\sum_{i=1}^{j} \\lambda_i}{|\\lambda_{j+1}|} = 7 + \\frac{S_7}{|\\lambda_8|}$$\n\n我们有必要的值：\n- 直到 $j=7$ 的和是 $S_7 = 0.22$。\n- 下一个李雅普诺夫指数是 $\\lambda_8 = -0.44$。\n- 绝对值是 $|\\lambda_8| = |-0.44| = 0.44$。\n\n将这些值代入公式：\n$$D_{KY} = 7 + \\frac{0.22}{0.44} = 7 + 0.5 = 7.5$$\n\n问题要求答案四舍五入到四位有效数字。计算值为 $7.5$，按要求格式为 $7.500$。\n\n对这一结果的解释是，皮层局部场电位的复杂动力学，虽然为了分析而嵌入在一个 $12$ 维空间中，但实际上是在一个分形维数约为 $7.500$ 的几何结构（奇异吸引子）上展开的。这种非整数维度是混沌系统的一个特征。它意味着，要模拟这种神经活动的基本动力学，至少需要 $\\lceil D_{KY} \\rceil = \\lceil 7.500 \\rceil = 8$ 个常微分方程，并且吸引子并没有完全填满它所处的 $8$ 维空间。计算出的值为了解脑动力学的复杂性提供了一个定量的度量。",
            "answer": "$$\\boxed{7.500}$$"
        },
        {
            "introduction": "现实世界中的神经信号，如脑电图（EEG），其动力学特性常常随时间演变，并非总是平稳的。这项高级综合练习旨在模拟一个真实的研究任务：构建一个完整的分析流程，以识别非平稳信号中的动力学状态转变。你将首先使用递归量化分析（RQA）来分割时间序列，然后通过估算每个分段的李雅普诺夫指数来验证分割的有效性，从而揭示复杂数据背后隐藏的时间结构。",
            "id": "4182472",
            "problem": "您的任务是设计并实现一个完整的、可运行的程序，该程序使用递归量化分析将一个单变量、离散时间的类脑电图（EEG）信号分割成具有不同动态特性的区域，并通过估计的最大李雅普诺夫指数的差异来验证分割结果。该程序必须是完全自包含的，并且不应需要任何外部输入或文件。它必须为一组参数测试套件生成一行包含验证结果的输出。\n\n基本原理：\n- Takens嵌入定理指出，对于一个动力学系统的通用可观测量，在合适的嵌入维度和延迟下，延迟坐标向量可以重构出底层吸引子的一个微分同胚图像。给定一个单变量时间序列 $x_0, x_1, \\dots, x_{N-1}$，延迟嵌入由以下向量定义\n$$\n\\mathbf{y}_i = \\left( x_i, x_{i+\\tau}, x_{i+2\\tau}, \\dots, x_{i+(m-1)\\tau} \\right),\n$$\n其中 $m$ 是嵌入维度，$\\tau$ 是延迟，为 $i = 0,\\dots,M-1$ 生成 $M = N - (m-1)\\tau$ 个嵌入点 $\\mathbf{y}_i \\in \\mathbb{R}^m$。\n\n- 递归图是根据嵌入向量之间的成对距离构建的，定义了一个二元递归矩阵 $R \\in \\{0,1\\}^{M \\times M}$，其元素为\n$$\nR_{ij} =\n\\begin{cases}\n1,  \\text{如果 } \\lVert \\mathbf{y}_i - \\mathbf{y}_j \\rVert \\le \\varepsilon \\text{ 且 } |i-j|  T,\\\\\n0,  \\text{否则},\n\\end{cases}\n$$\n其中 $\\varepsilon$ 是一个固定阈值，而 $T$ 是一个Theiler窗，用于排除时间上相邻的点以避免平凡递归。\n\n- 递归量化分析（RQA）从 $R$ 计算摘要度量。特别地，定义总递归点数为 $N_R = \\sum_{i,j} R_{ij}$。确定性（Determinism）定义为属于长度至少为 $L_{\\min}$ 的对角线的递归点所占的比例，其中对角线是沿 $R_{i+k,j+k}$ 的连续的1：\n$$\n\\mathrm{DET} = \\frac{\\sum_{\\ell \\ge L_{\\min}} \\ell \\cdot \\mathcal{N}(\\ell)}{N_R},\n$$\n其中 $\\mathcal{N}(\\ell)$ 是 $R$ 中长度为 $\\ell$ 的对角线的数量。\n\n- 最大李雅普诺夫指数 $\\lambda_{\\max}$ 量化了邻近轨迹的平均指数发散率。给定两个相近的嵌入点 $\\mathbf{y}_i$ 和 $\\mathbf{y}_j$，它们在离散时间 $k$ 步后的分离距离为 $d_{ij}(k) = \\lVert \\mathbf{y}_{i+k} - \\mathbf{y}_{j+k} \\rVert$。如果系统表现出对初始条件的敏感依赖性，那么对于小的 $k$，可以预期\n$$\n\\ln d_{ij}(k) \\approx \\ln d_{ij}(0) + \\lambda_{\\max} \\cdot k.\n$$\n一种实用的估计方法是对许多最近邻对进行平均，并对初始范围内的 $k$ 将 $\\ln d(k)$ 与 $k$ 进行直线拟合。\n\n程序要求：\n1. 对时间序列的滑动窗口实现上述定义的延迟嵌入和递归图构建。在每个窗口中：\n   - 在嵌入前将数据标准化为零均值和单位方差。\n   - 标准化后对递归矩阵使用固定阈值 $\\varepsilon$。\n   - 使用 $T$ 个样本的Theiler窗来排除平凡递归。\n   - 使用最小对角线长度 $L_{\\min}$ 计算确定性 $\\mathrm{DET}$。\n\n2. 分割规则：\n   - 对整个序列，在长度为 $W$、步长为 $S$ 的重叠滑动窗口上计算 $\\mathrm{DET}$。\n   - 当 $|\\mathrm{DET}_{t} - \\mathrm{DET}_{t-1}| \\ge \\gamma$ 时，在窗口中心检测变化点，其中 $\\gamma$ 是一个指定的阈值。\n   - 在原始样本索引空间中，在变化点之间形成连续的段。\n   - 丢弃短于指定最小长度 $L_{\\text{seg}}$ 的段。\n\n3. 验证规则：\n   - 对于每个段，使用延迟嵌入、Theiler窗 $T_{\\lambda}$ 和最大演化步数 $K_{\\max}$ 来估计 $\\lambda_{\\max}$。对于每个嵌入点索引 $i$，选择满足 $|i-j|  T_{\\lambda}$ 的最近邻索引 $j$，计算 $k=1,\\dots,K_{\\max}$ 的 $d_{ij}(k)$（只要索引保持有效），在所有有效对上平均 $\\ln d_{ij}(k)$，并通过拟合一条直线来推断 $\\lambda_{\\max}$ 作为相对于离散步长 $k$ 的斜率。\n   - 如果至少有两个段具有有限的 $\\lambda_{\\max}$ 估计值，并且分段 $\\lambda_{\\max}$ 值的范围 $\\Delta \\lambda = \\max(\\lambda_{\\max}) - \\min(\\lambda_{\\max})$ 满足 $\\Delta \\lambda \\ge \\Delta_{\\min}$，则定义验证布尔值为真，其中 $\\Delta_{\\min}$ 是一个指定的最小差异。\n\n信号生成：\n- 程序必须通过连接具有不同动态特性的区域来内在地合成类EEG信号，使用经过充分研究的动力学源：\n  - 一个基线振荡区域，由 $x_n = A \\sin(2\\pi f n / F_s) + \\eta_n$ 定义，其中 $n$ 是离散时间索引， $A$ 是振幅， $f$ 是频率， $F_s$ 是采样率，$\\eta_n$ 是独立的高斯噪声。\n  - 一个混沌区域，由处于混沌状态的逻辑斯蒂映射 $x_{n+1} = r x_n (1 - x_n)$ 和可选的加性高斯噪声定义。\n  - 一个完全振荡区域，通过连接多个可能具有不同频率但保持准周期性的振荡段来定义。\n\n测试套件规范：\n提供以下三个参数集以构成测试套件。每个参数集是一个元组，包含：\n- 序列配置：一个段列表，每个段由一个类型字符串和样本长度定义，后跟控制动态和噪声的参数。合法的段类型是 \"osc\"（振荡）和 \"logistic\"（混沌逻辑斯蒂映射）。\n- 嵌入参数：$(m, \\tau)$。\n- 递归参数：$(\\varepsilon, T, L_{\\min})$。\n- 窗口和分割参数：$(W, S, \\gamma, L_{\\text{seg}})$。\n- 李雅普诺夫估计参数：$(K_{\\max}, T_{\\lambda})$。\n- 验证参数：$\\Delta_{\\min}$。\n\n使用以下确切的测试用例：\n1. 案例1（清晰的振荡-混沌-振荡交替）：\n   - 序列配置：段 $[\\text{\"osc\"}:1800,\\ \\text{\"logistic\"}:1800,\\ \\text{\"osc\"}:1800]$，振荡参数 $A=1.0$，$f=10$，$F_s=256$，噪声标准差 $\\sigma_{\\text{osc}}=0.05$；逻辑斯蒂映射参数 $r=3.9$，初始条件 $x_0=0.4$，噪声标准差 $\\sigma_{\\text{log}}=0.02$。\n   - 嵌入：$(m,\\tau)=(3,8)$。\n   - 递归：$(\\varepsilon, T, L_{\\min})=(0.5, 2, 2)$。\n   - 窗口和分割：$(W,S,\\gamma,L_{\\text{seg}})=(700, 200, 0.12, 800)$。\n   - 李雅普诺夫：$(K_{\\max}, T_{\\lambda})=(20, 12)$。\n   - 验证：$\\Delta_{\\min}=0.3$。\n\n2. 案例2（噪声更强的数据和更严格的验证差异）：\n   - 序列配置：段 $[\\text{\"osc\"}:1800,\\ \\text{\"logistic\"}:1800,\\ \\text{\"osc\"}:1800]$，振荡参数 $A=1.0$，$f=10$，$F_s=256$，噪声标准差 $\\sigma_{\\text{osc}}=0.15$；逻辑斯蒂映射参数 $r=3.7$，初始条件 $x_0=0.41$，噪声标准差 $\\sigma_{\\text{log}}=0.10$。\n   - 嵌入：$(m,\\tau)=(3,8)$。\n   - 递归：$(\\varepsilon, T, L_{\\min})=(0.5, 2, 2)$。\n   - 窗口和分割：$(W,S,\\gamma,L_{\\text{seg}})=(700, 200, 0.12, 800)$。\n   - 李雅普诺夫：$(K_{\\max}, T_{\\lambda})=(20, 12)$。\n   - 验证：$\\Delta_{\\min}=0.9$。\n\n3. 案例3（没有真实动态变化的完全振荡数据）：\n   - 序列配置：段 $[\\text{\"osc\"}:1800,\\ \\text{\"osc\"}:1800,\\ \\text{\"osc\"}:1800]$，振荡参数 $A=1.0$，第一段基频 $f=9$，第二段 $f=10$，第三段 $f=11$，$F_s=256$，所有段的噪声标准差 $\\sigma_{\\text{osc}}=0.05$。\n   - 嵌入：$(m,\\tau)=(3,8)$。\n   - 递归：$(\\varepsilon, T, L_{\\min})=(0.5, 2, 2)$。\n   - 窗口和分割：$(W,S,\\gamma,L_{\\text{seg}})=(700, 200, 0.12, 800)$。\n   - 李雅普诺夫：$(K_{\\max}, T_{\\lambda})=(20, 12)$。\n   - 验证：$\\Delta_{\\min}=0.3$。\n\n输出规范：\n- 对于三个测试用例中的每一个，计算分割和验证布尔值。最终输出必须是单行，包含一个方括号括起来的、由三个布尔值组成的逗号分隔列表，例如 $[\\text{True},\\text{False},\\text{True}]$。不得打印任何额外文本。",
            "solution": "实现将通过构建一系列函数来系统地解决所需任务：合成时间序列，根据RQA测量的动态复杂性变化对其进行分段，并通过比较各段之间的混沌发散率（最大李雅普诺夫指数）来验证此分段。\n\n### 1. 信号合成\n程序首先通过连接具有不同动态特性的段来为时间索引 $n$ 合成一个离散时间信号 $x_n$。\n-   一个**振荡区域**由一个带有加性高斯噪声的正弦波建模：\n    $$x_n = A \\sin\\left(\\frac{2\\pi f n}{F_s}\\right) + \\eta_n$$\n    其中 $A$ 是振幅，$f$ 是频率，$F_s$ 是采样率，$\\eta_n$ 是一个从均值为零、标准差为 $\\sigma_{\\text{osc}}$ 的高斯分布中抽取的样本。这个区域是周期性的，动态上是简单的。\n-   一个**混沌区域**使用逻辑斯蒂映射生成：\n    $$x_{n+1} = r x_n (1 - x_n)$$\n    对于指定的参数值（$r=3.9$ 和 $r=3.7$），该映射表现出混沌行为，其特征是对初始条件的敏感依赖性。也可以包含标准差为 $\\sigma_{\\text{log}}$ 的加性高斯噪声。\n\n### 2. 通过递归量化分析（RQA）进行时间序列分段\n\n分段逻辑的核心依赖于量化信号确定性的变化。这是通过对时间序列的滑动窗口应用RQA来实现的。\n\n**2.1. 相空间重构**\n对于时间序列中长度为 $W$ 的每个窗口，数据首先被标准化为均值为 $0$、标准差为 $1$。然后，其动态特性通过时间延迟嵌入的方法在高维相空间中重构，其合理性由Takens定理保证。一个标量时间序列 $\\{x_i\\}$ 被转换为 $\\mathbb{R}^m$ 中的一组 $M$ 个向量：\n$$\\mathbf{y}_i = (x_i, x_{i+\\tau}, x_{i+2\\tau}, \\dots, x_{i+(m-1)\\tau})$$\n对于 $i = 0, \\dots, M-1$，其中 $m$ 是嵌入维度，$\\tau$ 是时间延迟，$M = W - (m-1)\\tau$。\n\n**2.2. 递归矩阵和确定性（DET）**\n构建一个递归矩阵 $R$ 来捕捉重构相空间中状态的递归。其元素定义为：\n$$R_{ij} = \\Theta(\\varepsilon - \\lVert \\mathbf{y}_i - \\mathbf{y}_j \\rVert) \\cdot \\Theta(|i-j| - T)$$\n其中 $\\lVert \\cdot \\rVert$ 是欧几里得范数，$\\varepsilon$ 是一个距离阈值，$\\Theta$ 是亥维赛阶跃函数。涉及Theiler窗 $T$ 的项排除了时间上相近的点，从而移除了主对角线上的平凡相关性。\n\n从这个矩阵中，我们计算确定性（$\\mathrm{DET}$），它衡量了形成对角线的递归点所占的比例。这些线对应于彼此平行的轨迹段，表明存在确定性结构。$\\mathrm{DET}$ 定义为：\n$$\\mathrm{DET} = \\frac{\\sum_{\\ell \\ge L_{\\min}} \\ell \\cdot \\mathcal{N}(\\ell)}{\\sum_{i,j} R_{ij}}$$\n其中 $\\mathcal{N}(\\ell)$ 是长度恰好为 $\\ell$ 的对角线的数量，而 $L_{\\min}$ 是被认为显著的最小长度。高的 $\\mathrm{DET}$ 值是周期性或准周期性信号的特征，而较低的值则表明是混沌或随机动态。\n\n**2.3. 变化点检测**\n$\\mathrm{DET}$ 是在长度为 $W$、步长为 $S$ 的重叠窗口上计算的。这产生了一个 $\\mathrm{DET}$ 值的时间序列。如果在窗口 $t$ 中，与前一个窗口相比，确定性变化的幅度超过了阈值 $\\gamma$，则在该窗口的中心识别出一个变化点：\n$$|\\mathrm{DET}_{t} - \\mathrm{DET}_{t-1}| \\ge \\gamma$$\n这些变化点的集合，连同整个信号的起点和终点，定义了各段的边界。长度小于 $L_{\\text{seg}}$ 的段被丢弃。\n\n### 3. 通过李雅普诺夫指数进行分段验证\n\n最后阶段通过为每个段估计最大李雅普诺夫指数（$\\lambda_{\\max}$）来验证基于RQA的分段。$\\lambda_{\\max}$ 量化了无限接近的轨迹的平均指数发散率。一个正的 $\\lambda_{\\max}$ 是混沌的标志。\n\n**3.1. 估计 $\\lambda_{\\max}$**\n对于每个识别出的段，应用以下过程：\n1.  该段的时间序列被标准化，并以维度 $m$ 和延迟 $\\tau$ 嵌入到相空间中。\n2.  对于嵌入空间中的每个点 $\\mathbf{y}_i$，找到其最近邻 $\\mathbf{y}_j$，但要满足时间约束 $|i-j|  T_{\\lambda}$，以确保这些点来自轨迹的不同部分。\n3.  跟踪发散 $d_{ij}(k) = \\lVert \\mathbf{y}_{i+k} - \\mathbf{y}_{j+k} \\rVert$ 在时间上向前演化 $k=1, \\dots, K_{\\max}$ 步。\n4.  对于混沌系统，预计发散对于小的 $k$ 会呈指数增长：$d_{ij}(k) \\approx d_{ij}(0) e^{\\lambda_{\\max} k}$。这意味着对数关系是线性的：\n    $$\\ln(d_{ij}(k)) \\approx \\ln(d_{ij}(0)) + \\lambda_{\\max} k$$\n5.  为了获得一个稳健的估计，对于每个演化步长 $k$，计算在所有有效起始对 $(i,j)$ 上平均的量 $\\langle \\ln(d(k)) \\rangle$。\n6.  对 $\\langle \\ln(d(k)) \\rangle$ 与 $k$ 进行线性回归。最佳拟合线的斜率提供了 $\\lambda_{\\max}$ 的估计值。该估计是按离散时间步长计算的，如规范所述。\n\n**3.2. 验证规则**\n如果满足两个条件，则认为分段已成功验证：\n1.  至少有两个段产生了有限的、非平凡的 $\\lambda_{\\max}$ 估计值。\n2.  这些估计值的范围 $\\Delta \\lambda = \\max(\\lambda_{\\max}) - \\min(\\lambda_{\\max})$ 大于或等于指定的阈值 $\\Delta_{\\min}$。\n\n这确保了分段已识别出至少两个在混沌特性上具有量化上显著差异的独特动态区域。整个过程对一组参数测试套件自动化执行，并报告每个测试套件的布尔验证结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\nfrom scipy.spatial.distance import pdist, squareform\nfrom scipy.spatial import cKDTree\n\ndef generate_signal(config, params):\n    \"\"\"\n    Generates a time series by concatenating segments with different dynamics.\n    \"\"\"\n    np.random.seed(0)  # For reproducibility\n    full_series = []\n    time_offset = 0\n\n    osc_params_used = 0\n    for seg_type, seg_length in config:\n        n = np.arange(time_offset, time_offset + seg_length)\n        if seg_type == \"osc\":\n            if 'r_log' in params and isinstance(params.get('f_osc'), list):\n                f = params['f_osc'][osc_params_used]\n                osc_params_used += 1\n            else:\n                f = params['f_osc']\n            \n            A = params['A']\n            Fs = params['Fs']\n            sigma_osc = params['sigma_osc']\n            \n            series = A * np.sin(2 * np.pi * f * n / Fs)\n            noise = np.random.normal(0, sigma_osc, seg_length)\n            full_series.append(series + noise)\n            \n        elif seg_type == \"logistic\":\n            r = params['r_log']\n            x0 = params['x0_log']\n            sigma_log = params['sigma_log']\n            \n            series = np.zeros(seg_length)\n            series[0] = x0\n            for i in range(seg_length - 1):\n                series[i+1] = r * series[i] * (1 - series[i])\n            noise = np.random.normal(0, sigma_log, seg_length)\n            full_series.append(series + noise)\n\n        time_offset += seg_length\n        \n    return np.concatenate(full_series)\n\ndef embed_series(series, m, tau):\n    \"\"\"\n    Performs time-delay embedding on a time series.\n    \"\"\"\n    N = len(series)\n    if N  (m - 1) * tau + 1:\n        return np.array([[]])\n    M = N - (m - 1) * tau\n    embedded = np.zeros((M, m))\n    for i in range(M):\n        embedded[i] = series[i : i + m * tau : tau]\n    return embedded\n\ndef calculate_det(series, m, tau, epsilon, T_theiler, L_min):\n    \"\"\"\n    Calculates the Determinism (DET) for a time series segment.\n    \"\"\"\n    # 1. Standardize\n    std = np.std(series)\n    if std == 0: return 1.0  # Perfectly deterministic\n    standardized_series = (series - np.mean(series)) / std\n\n    # 2. Embed\n    Y = embed_series(standardized_series, m, tau)\n    if Y.shape[0]  2: return 0.0\n\n    # 3. Recurrence Matrix\n    dist_matrix = squareform(pdist(Y, 'euclidean'))\n    R = dist_matrix = epsilon\n    \n    # Apply Theiler window\n    M = R.shape[0]\n    for i in range(M):\n        for j in range(max(0, i - T_theiler), min(M, i + T_theiler + 1)):\n            R[i, j] = 0\n            \n    # 4. Calculate DET\n    N_R = np.sum(R)\n    if N_R == 0: return 0.0\n\n    diag_sum = 0\n    for offset in range(-M + 1, M):\n        diag = np.diagonal(R, offset=offset)\n        if diag.size  L_min: continue\n        \n        # Find runs of 1s\n        padded_diag = np.concatenate(([0], diag, [0]))\n        diffs = np.diff(padded_diag)\n        starts = np.where(diffs == 1)[0]\n        ends = np.where(diffs == -1)[0]\n        lengths = ends - starts\n        \n        for l in lengths:\n            if l >= L_min:\n                diag_sum += l\n                \n    return diag_sum / N_R if N_R > 0 else 0.0\n\ndef segment_series(series, m, tau, epsilon, T, L_min, W, S, gamma, L_seg):\n    \"\"\"\n    Segments the time series based on changes in DET.\n    \"\"\"\n    det_values = []\n    window_centers = []\n    \n    for i in range(0, len(series) - W + 1, S):\n        window = series[i : i + W]\n        det = calculate_det(window, m, tau, epsilon, T, L_min)\n        det_values.append(det)\n        window_centers.append(i + W // 2)\n\n    change_points = []\n    for i in range(1, len(det_values)):\n        if np.abs(det_values[i] - det_values[i-1]) >= gamma:\n            # Change is detected between window i-1 and i. Place marker at center of window i.\n            center_idx = (i * S) + W // 2\n            change_points.append(center_idx)\n    \n    boundaries = sorted(list(set([0] + change_points + [len(series)])))\n    \n    segments = []\n    for i in range(len(boundaries) - 1):\n        start, end = boundaries[i], boundaries[i+1]\n        if end - start >= L_seg:\n            segments.append((start, end))\n\n    # If no segments found, treat the whole series as one segment\n    if not segments:\n        if len(series) >= L_seg:\n            segments.append((0, len(series)))\n\n    return segments\n\ndef estimate_lambda_max(segment, m, tau, K_max, T_lambda):\n    \"\"\"\n    Estimates the maximum Lyapunov exponent for a time series segment.\n    \"\"\"\n    std = np.std(segment)\n    if std == 0: return 0.0\n    series = (segment - np.mean(segment)) / std\n    \n    Y = embed_series(series, m, tau)\n    M = Y.shape[0]\n    \n    if M  2 or M  K_max or M  T_lambda + 2:\n        return np.nan\n\n    try:\n        tree = cKDTree(Y)\n    except Exception:\n        return np.nan\n\n    log_divergences = np.zeros(K_max)\n    counts = np.zeros(K_max, dtype=int)\n    \n    # For NN search with Theiler window, query for k > T_lambda neighbors\n    k_neighbors = T_lambda + 10 if T_lambda + 10  M else M -1\n\n    for i in range(M):\n        # Find nearest neighbor respecting Theiler window\n        try:\n            dists, inds = tree.query(Y[i], k=k_neighbors)\n        except Exception:\n            continue\n            \n        neighbor_idx = -1\n        for j in range(1, len(inds)): # Start at 1 to skip self\n            if abs(i - inds[j]) > T_lambda:\n                neighbor_idx = inds[j]\n                break\n        \n        if neighbor_idx == -1:\n            continue\n\n        # Track divergence\n        for k in range(1, K_max + 1):\n            if i + k  M and neighbor_idx + k  M:\n                dist = np.linalg.norm(Y[i+k] - Y[neighbor_idx+k])\n                if dist > 1e-9: # Avoid log(0)\n                    log_divergences[k-1] += np.log(dist)\n                    counts[k-1] += 1\n\n    avg_log_d = np.full(K_max, np.nan)\n    valid_k = counts > 0\n    avg_log_d[valid_k] = log_divergences[valid_k] / counts[valid_k]\n\n    # Linear fit\n    k_steps = np.arange(1, K_max + 1)\n    \n    valid_points = ~np.isnan(avg_log_d)\n    if np.sum(valid_points)  2:\n        return np.nan\n        \n    k_fit = k_steps[valid_points]\n    d_fit = avg_log_d[valid_points]\n    \n    try:\n        slope, _, _, _, _ = linregress(k_fit, d_fit)\n    except ValueError:\n        return np.nan\n        \n    return slope\n\ndef process_case(params):\n    \"\"\"\n    Processes a single test case from generation to validation.\n    \"\"\"\n    # Unpack parameters\n    series_config = params['series_config']\n    series_params = params['series_params']\n    m, tau = params['embedding']\n    epsilon, T, L_min = params['recurrence']\n    W, S, gamma, L_seg = params['windowing']\n    K_max, T_lambda = params['lyapunov']\n    Delta_min = params['validation']\n    \n    # 1. Generate signal\n    signal = generate_signal(series_config, series_params)\n    \n    # 2. Segment series\n    segments = segment_series(signal, m, tau, epsilon, T, L_min, W, S, gamma, L_seg)\n    \n    # 3. Validate\n    lambda_estimates = []\n    for start, end in segments:\n        segment_data = signal[start:end]\n        l_max = estimate_lambda_max(segment_data, m, tau, K_max, T_lambda)\n        lambda_estimates.append(l_max)\n    \n    finite_estimates = [x for x in lambda_estimates if np.isfinite(x)]\n    \n    if len(finite_estimates)  2:\n        return False\n        \n    delta_lambda = np.max(finite_estimates) - np.min(finite_estimates)\n    \n    return delta_lambda >= Delta_min\n\ndef solve():\n    test_cases = [\n        # Case 1\n        {\n            \"series_config\": [(\"osc\", 1800), (\"logistic\", 1800), (\"osc\", 1800)],\n            \"series_params\": {\n                \"A\": 1.0, \"f_osc\": 10, \"Fs\": 256, \"sigma_osc\": 0.05,\n                \"r_log\": 3.9, \"x0_log\": 0.4, \"sigma_log\": 0.02\n            },\n            \"embedding\": (3, 8),\n            \"recurrence\": (0.5, 2, 2),\n            \"windowing\": (700, 200, 0.12, 800),\n            \"lyapunov\": (20, 12),\n            \"validation\": 0.3\n        },\n        # Case 2\n        {\n            \"series_config\": [(\"osc\", 1800), (\"logistic\", 1800), (\"osc\", 1800)],\n            \"series_params\": {\n                \"A\": 1.0, \"f_osc\": 10, \"Fs\": 256, \"sigma_osc\": 0.15,\n                \"r_log\": 3.7, \"x0_log\": 0.41, \"sigma_log\": 0.10\n            },\n            \"embedding\": (3, 8),\n            \"recurrence\": (0.5, 2, 2),\n            \"windowing\": (700, 200, 0.12, 800),\n            \"lyapunov\": (20, 12),\n            \"validation\": 0.9\n        },\n        # Case 3\n        {\n            \"series_config\": [(\"osc\", 1800), (\"osc\", 1800), (\"osc\", 1800)],\n            \"series_params\": {\n                \"A\": 1.0, \"f_osc\": [9, 10, 11], \"Fs\": 256, \"sigma_osc\": 0.05,\n                \"r_log\": 3.9, \"x0_log\": 0.4, \"sigma_log\": 0.02 # Keep structure\n            },\n            \"embedding\": (3, 8),\n            \"recurrence\": (0.5, 2, 2),\n            \"windowing\": (700, 200, 0.12, 800),\n            \"lyapunov\": (20, 12),\n            \"validation\": 0.3\n        }\n    ]\n\n    results = [process_case(case) for case in test_cases]\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}