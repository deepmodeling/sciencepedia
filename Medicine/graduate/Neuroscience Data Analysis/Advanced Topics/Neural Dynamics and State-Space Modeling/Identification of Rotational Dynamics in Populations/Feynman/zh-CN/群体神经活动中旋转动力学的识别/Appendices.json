{
    "hands_on_practices": [
        {
            "introduction": "为了在神经群体活动中识别旋转，我们首先需要一种量化它的方法。这个练习将核心的 jPCA 回归问题分解为一个简单的二维情景，让你从头开始实践。通过运用最小二乘法原理，你将推导出平均角速度 $\\bar{\\omega}$ 的表达式，从而揭示 jPCA 如何精确地量化旋转的速率，并理解为何状态向量的幅度会作为权重出现在计算中。",
            "id": "4169453",
            "problem": "考虑一个二维神经群体状态轨迹 $x(t) \\in \\mathbb{R}^{2}$，它是通过将高维放电率向量投影到一个捕获主导旋转结构的平面上得到的。假设该平面上的动力学可以由一个带有斜对称生成元的线性时不变模型很好地近似，因此时间导数 $\\dot{x}(t)$ 满足 $\\dot{x}(t) \\approx M x(t)$，其中 $M$ 是斜对称的。在二维空间中，任何斜对称矩阵都可以写成 $M = \\omega J$ 的形式，其中 $\\omega \\in \\mathbb{R}$ 是角速度，而 $J$ 是逆时针旋转 $90^{\\circ}$ 的旋转矩阵\n$$\nJ \\;=\\; \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}.\n$$\n将垂直速度定义为 $\\dot{x}_{\\perp}(t) := J^{\\top} \\dot{x}(t)$，它将 $\\dot{x}(t)$ 顺时针旋转 $90^{\\circ}$，因此对于理想的旋转动力学，$\\dot{x}_{\\perp}(t) = \\omega x(t)$ 瞬时成立。\n\n仅从这些定义和最小二乘法原理出发，推导通过在 $K$ 个样本 $\\{x(t_k), \\dot{x}(t_k)\\}_{k=1}^{K}$ 上将 $\\dot{x}_{\\perp}(t)$ 对 $x(t)$ 进行零截距回归所得到的跨时间平均角速度 $\\bar{\\omega}$ 的闭式表达式。你的推导必须阐明为什么这个斜率可以解释为平均角速度，以及状态幅值的加权是如何产生的。\n\n然后，根据以下三个样本计算 $\\bar{\\omega}$ 的数值（单位为弧度/秒）。将这些样本视为同步样本 $(x(t_k), \\dot{x}(t_k))$，并使用上述的 $J$：\n- $x(t_1) = \\begin{pmatrix} 1.0 \\\\ 0.0 \\end{pmatrix}$, $\\dot{x}(t_1) = \\begin{pmatrix} 0.05 \\\\ 2.05 \\end{pmatrix}$,\n- $x(t_2) = \\begin{pmatrix} 0.0 \\\\ 1.0 \\end{pmatrix}$, $\\dot{x}(t_2) = \\begin{pmatrix} -2.02 \\\\ -0.03 \\end{pmatrix}$,\n- $x(t_3) = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$, $\\dot{x}(t_3) = \\begin{pmatrix} -2.10 \\\\ 1.90 \\end{pmatrix}$。\n\n将最终数值答案四舍五入至四位有效数字。以弧度/秒为单位表示最终值。",
            "solution": "用户提供了一个问题陈述，在尝试解答之前需要对其进行验证。\n\n### 第 1 步：提取已知条件\n- 神经状态是一个二维轨迹 $x(t) \\in \\mathbb{R}^{2}$。\n- 动力学由一个线性时不变模型近似：$\\dot{x}(t) \\approx M x(t)$。\n- 矩阵 $M$ 是斜对称的，在二维空间中可以写成 $M = \\omega J$。\n- $\\omega \\in \\mathbb{R}$ 是角速度。\n- $J$ 是逆时针旋转 $90^{\\circ}$ 的旋转矩阵：$J = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}$。\n- 垂直速度定义为 $\\dot{x}_{\\perp}(t) := J^{\\top} \\dot{x}(t)$。\n- 理想的动力学关系由 $\\dot{x}_{\\perp}(t) = \\omega x(t)$ 给出。\n- 任务是使用最小二乘法原理，通过在 $K$ 个样本 $\\{x(t_k), \\dot{x}(t_k)\\}_{k=1}^{K}$ 上将 $\\dot{x}_{\\perp}(t)$ 对 $x(t)$ 进行零截距回归，来推导平均角速度 $\\bar{\\omega}$ 的闭式表达式。\n- 需要对 $K=3$ 个样本进行 $\\bar{\\omega}$ 的数值计算：\n    - 样本 1：$x(t_1) = \\begin{pmatrix} 1.0 \\\\ 0.0 \\end{pmatrix}$，$\\dot{x}(t_1) = \\begin{pmatrix} 0.05 \\\\ 2.05 \\end{pmatrix}$。\n    - 样本 2：$x(t_2) = \\begin{pmatrix} 0.0 \\\\ 1.0 \\end{pmatrix}$，$\\dot{x}(t_2) = \\begin{pmatrix} -2.02 \\\\ -0.03 \\end{pmatrix}$。\n    - 样本 3：$x(t_3) = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$，$\\dot{x}(t_3) = \\begin{pmatrix} -2.10 \\\\ 1.90 \\end{pmatrix}$。\n- 最终数值答案必须四舍五入到四位有效数字。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估。\n- **科学依据**：该问题是 j-主成分分析（jPCA）核心原理的直接应用，jPCA 是计算神经科学中一种成熟且科学合理的方法，用于识别神经数据中的旋转动力学。其数学公式，包括使用斜对称生成矩阵和垂直速度的定义，是该领域的标准做法。\n- **适定性**：该问题是适定的。它要求使用最小二乘法原理推导一个参数，这是一个具有唯一解的标准优化问题。为数值计算所提供的数据是完整且充分的。\n- **客观性**：问题陈述使用精确的数学语言编写，没有任何主观或模棱两可的术语。\n- **完整性与一致性**：该问题是自洽的。所有必要的定义、方程和数据都已提供。没有矛盾之处。\n\n### 第 3 步：结论与行动\n问题是**有效的**。它科学合理、适定且完整。可以开始求解过程。\n\n### 解答推导\n目标是找到标量 $\\bar{\\omega}$，以最佳拟合一组 $K$ 个离散样本的模型 $\\dot{x}_{\\perp}(t_k) \\approx \\bar{\\omega} x(t_k)$。这是一个零截距的线性回归问题。“因变量”是向量 $\\dot{x}_{\\perp}(t_k)$，“自变量”是向量 $x(t_k)$。\n\n根据最小二乘法原理，我们必须最小化误差平方和。第 $k$ 个样本的误差是向量差 $e_k = \\dot{x}_{\\perp}(t_k) - \\bar{\\omega} x(t_k)$。需要最小化的量是这些误差向量的欧几里得范数平方和：\n$$\nS(\\bar{\\omega}) = \\sum_{k=1}^{K} \\| e_k \\|^2 = \\sum_{k=1}^{K} \\| \\dot{x}_{\\perp}(t_k) - \\bar{\\omega} x(t_k) \\|^2\n$$\n向量 $v$ 的范数平方是 $v^{\\top}v$。为清楚起见，省略索引 $k$ 并展开单个样本的项：\n$$\n\\| \\dot{x}_{\\perp} - \\bar{\\omega} x \\|^2 = ( \\dot{x}_{\\perp} - \\bar{\\omega} x )^{\\top} ( \\dot{x}_{\\perp} - \\bar{\\omega} x )\n$$\n$$\n= (\\dot{x}_{\\perp}^{\\top} - \\bar{\\omega} x^{\\top}) ( \\dot{x}_{\\perp} - \\bar{\\omega} x )\n$$\n$$\n= \\dot{x}_{\\perp}^{\\top}\\dot{x}_{\\perp} - \\bar{\\omega} \\dot{x}_{\\perp}^{\\top}x - \\bar{\\omega} x^{\\top}\\dot{x}_{\\perp} + \\bar{\\omega}^2 x^{\\top}x\n$$\n由于 $x^{\\top}\\dot{x}_{\\perp}$ 是一个标量，它等于其转置：$(x^{\\top}\\dot{x}_{\\perp})^{\\top} = \\dot{x}_{\\perp}^{\\top}x$。因此，中间两项是相同的。\n$$\n\\| \\dot{x}_{\\perp} - \\bar{\\omega} x \\|^2 = \\| \\dot{x}_{\\perp} \\|^2 - 2\\bar{\\omega} x^{\\top}\\dot{x}_{\\perp} + \\bar{\\omega}^2 \\|x\\|^2\n$$\n现在，我们恢复对所有 $K$ 个样本的求和：\n$$\nS(\\bar{\\omega}) = \\sum_{k=1}^{K} \\left( \\| \\dot{x}_{\\perp}(t_k) \\|^2 - 2\\bar{\\omega} x(t_k)^{\\top}\\dot{x}_{\\perp}(t_k) + \\bar{\\omega}^2 \\|x(t_k)\\|^2 \\right)\n$$\n为了找到最小化 $S$ 的 $\\bar{\\omega}$ 值，我们将 $S$ 对 $\\bar{\\omega}$ 求导并令其为零：\n$$\n\\frac{dS}{d\\bar{\\omega}} = \\frac{d}{d\\bar{\\omega}} \\sum_{k=1}^{K} \\left( \\| \\dot{x}_{\\perp}(t_k) \\|^2 - 2\\bar{\\omega} x(t_k)^{\\top}\\dot{x}_{\\perp}(t_k) + \\bar{\\omega}^2 \\|x(t_k)\\|^2 \\right) = 0\n$$\n$$\n\\sum_{k=1}^{K} \\left( -2 x(t_k)^{\\top}\\dot{x}_{\\perp}(t_k) + 2\\bar{\\omega} \\|x(t_k)\\|^2 \\right) = 0\n$$\n除以 $2$ 并重新整理各项以求解 $\\bar{\\omega}$：\n$$\n\\bar{\\omega} \\sum_{k=1}^{K} \\|x(t_k)\\|^2 = \\sum_{k=1}^{K} x(t_k)^{\\top}\\dot{x}_{\\perp}(t_k)\n$$\n这就得出了 $\\bar{\\omega}$ 的闭式表达式：\n$$\n\\bar{\\omega} = \\frac{\\sum_{k=1}^{K} x(t_k)^{\\top}\\dot{x}_{\\perp}(t_k)}{\\sum_{k=1}^{K} \\|x(t_k)\\|^2}\n$$\n代入定义 $\\dot{x}_{\\perp}(t_k) = J^{\\top}\\dot{x}(t_k)$，我们得到：\n$$\n\\bar{\\omega} = \\frac{\\sum_{k=1}^{K} x(t_k)^{\\top} J^{\\top} \\dot{x}(t_k)}{\\sum_{k=1}^{K} x(t_k)^{\\top}x(t_k)}\n$$\n这个表达式可以解释为平均角速度。对于每个样本 $k$，可以估计瞬时角速度为 $\\omega_k = (x_k^{\\top}\\dot{x}_{\\perp,k}) / \\|x_k\\|^2$。$\\bar{\\omega}$ 的公式是这些瞬时估计值的加权平均，其中每个样本的权重是其幅值的平方 $\\|x_k\\|^2$。这种加权方案是合理的：远离原点的状态（大的 $\\|x_k\\|$）在给定角速度下具有更大的切向速度，因此为其估计提供了更鲁棒的信号。相反，靠近原点的状态更容易受噪声影响，提供的信号较弱，因此其权重被降低。\n\n### 数值计算\n我们现在将此公式应用于提供的 $K=3$ 个数据样本。\n给定 $J = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}$，其转置为 $J^{\\top} = \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix}$。\n分子是 $N = \\sum_{k=1}^{3} x(t_k)^{\\top} J^{\\top} \\dot{x}(t_k)$，分母是 $D = \\sum_{k=1}^{3} \\|x(t_k)\\|^2$。\n\n对于 $k=1$：\n- $x_1 = \\begin{pmatrix} 1.0 \\\\ 0.0 \\end{pmatrix}$, $\\dot{x}_1 = \\begin{pmatrix} 0.05 \\\\ 2.05 \\end{pmatrix}$\n- 分子项: $x_1^{\\top}J^{\\top}\\dot{x}_1 = \\begin{pmatrix} 1.0  0.0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\begin{pmatrix} 0.05 \\\\ 2.05 \\end{pmatrix} = \\begin{pmatrix} 1.0  0.0 \\end{pmatrix} \\begin{pmatrix} 2.05 \\\\ -0.05 \\end{pmatrix} = 2.05$\n- 分母项: $\\|x_1\\|^2 = (1.0)^2 + (0.0)^2 = 1.0$\n\n对于 $k=2$：\n- $x_2 = \\begin{pmatrix} 0.0 \\\\ 1.0 \\end{pmatrix}$, $\\dot{x}_2 = \\begin{pmatrix} -2.02 \\\\ -0.03 \\end{pmatrix}$\n- 分子项: $x_2^{\\top}J^{\\top}\\dot{x}_2 = \\begin{pmatrix} 0.0  1.0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\begin{pmatrix} -2.02 \\\\ -0.03 \\end{pmatrix} = \\begin{pmatrix} 0.0  1.0 \\end{pmatrix} \\begin{pmatrix} -0.03 \\\\ 2.02 \\end{pmatrix} = 2.02$\n- 分母项: $\\|x_2\\|^2 = (0.0)^2 + (1.0)^2 = 1.0$\n\n对于 $k=3$：\n- $x_3 = \\begin{pmatrix} 1.0 \\\\ 1.0 \\end{pmatrix}$, $\\dot{x}_3 = \\begin{pmatrix} -2.10 \\\\ 1.90 \\end{pmatrix}$\n- 分子项: $x_3^{\\top}J^{\\top}\\dot{x}_3 = \\begin{pmatrix} 1.0  1.0 \\end{pmatrix} \\begin{pmatrix} 0  1 \\\\ -1  0 \\end{pmatrix} \\begin{pmatrix} -2.10 \\\\ 1.90 \\end{pmatrix} = \\begin{pmatrix} 1.0  1.0 \\end{pmatrix} \\begin{pmatrix} 1.90 \\\\ 2.10 \\end{pmatrix} = 1.90 + 2.10 = 4.00$\n- 分母项: $\\|x_3\\|^2 = (1.0)^2 + (1.0)^2 = 2.0$\n\n现在，我们将各项相加来计算总分子 $N$ 和总分母 $D$：\n- $N = 2.05 + 2.02 + 4.00 = 8.07$\n- $D = 1.0 + 1.0 + 2.0 = 4.0$\n\n最后，我们计算 $\\bar{\\omega}$：\n$$\n\\bar{\\omega} = \\frac{N}{D} = \\frac{8.07}{4.0} = 2.0175\n$$\n题目要求将答案四舍五入到四位有效数字。\n$$\n\\bar{\\omega} \\approx 2.018\n$$\n单位是弧度/秒。",
            "answer": "$$\n\\boxed{2.018}\n$$"
        },
        {
            "introduction": "在应用我们推导出的公式之前，正确地准备数据是至关重要的一步。这个练习探讨了数据中心化这一关键预处理步骤的影响。你将通过分析发现，对数据进行中心化如何确保我们估计出的动力学矩阵 $A$ 所描述的旋转是围绕一个有意义的参考点（例如，一个固定点或平均状态）进行的，而不是源于坐标系原点任意选择所产生的伪影。",
            "id": "4169521",
            "problem": "您正在使用一种方法分析条件平均的神经群体轨迹，该方法在由主成分分析 (PCA) 识别的低维子空间中拟合一个线性时不变动力学系统。设状态为 $x(t) \\in \\mathbb{R}^{k}$，其中 $t \\in \\{t_{1},\\dots,t_{T}\\}$，$k$ 是保留的主成分数量，$\\dot{x}(t)$ 表示时间导数。在识别旋转动力学（如 jPCA 方法中拟合一个斜对称线性算子）时，一个常见的步骤是通过最小二乘问题来估计一个线性算子 $A \\in \\mathbb{R}^{k \\times k}$\n$$\n\\min_{A,b}\\ \\sum_{t=1}^{T} \\left\\| \\dot{x}(t) - A\\,x(t) - b \\right\\|_{2}^{2},\n$$\n其中截距 $b \\in \\mathbb{R}^{k}$ 可能被包含（$b$ 自由）或排除（$b \\equiv 0$）。考虑通过向所有时间点添加一个常数向量 $c \\in \\mathbb{R}^{k}$ 来构建数据的偏移版本，$x_{c}(t) \\equiv x(t) + c$，同时保持 $\\dot{x}(t)$ 不变。您被告知，在拟合 $A$ 之前，对数据进行跨时间（以及在适用时跨条件）的中心化是标准做法，即将 $x(t)$ 替换为 $x(t) - \\bar{x}$，将 $\\dot{x}(t)$ 替换为 $\\dot{x}(t) - \\overline{\\dot{x}}$，其中 $\\bar{x} \\equiv \\frac{1}{T}\\sum_{t=1}^{T} x(t)$ 且 $\\overline{\\dot{x}} \\equiv \\frac{1}{T}\\sum_{t=1}^{T} \\dot{x}(t)$。\n\n从涉及微分的线性和最小二乘法的正规方程等第一性原理出发，判断下列哪些陈述是正确的：\n\nA. 如果回归中包含截距 $b$，则估计的 $\\hat{A}$ 对向预测变量添加任何常数偏移 $c$ 是不变的，即从 $x(t)$ 或从 $x_{c}(t)$ 拟合 $\\dot{x}(t)$ 会得到相同的 $\\hat{A}$，而 $\\hat{b}$ 会移动以吸收该偏移。\n\nB. 如果排除截距 $b$ 且数据未中心化，添加常数偏移 $c$ 会改变 $\\hat{A}$；中心化 $x(t)$ 和 $\\dot{x}(t)$ 可以消除这种依赖性，并恢复 $\\hat{A}$ 对常数偏移的不变性。\n\nC. 向 $x(t)$ 添加常数偏移 $c$ 会改变 $\\dot{x}(t)$，因此无论是否包含 $b$ 或数据是否中心化，都必然会改变估计的 $\\hat{A}$。\n\nD. 在对 $A$ 施加斜对称约束（用于强调旋转）的情况下，该约束本身使得中心化变得不必要，因为即使在排除 $b$ 时，斜对称的 $A$ 也隐式地消除了常数偏移对 $\\hat{A}$ 的任何影响。\n\nE. 中心化对于正确解释旋转动力学至关重要，因为它将拟合的 $\\hat{A}$ 与围绕一个明确定义的工作点（例如，平均状态）的流的局域线性化（雅可比矩阵）对齐，确保提取的旋转反映的是关于该点的动力学，而不是平移造成的人为结果。\n\n选择所有适用项。",
            "solution": "我们从两个基本事实出发。首先，微分是线性的：如果 $x_{c}(t) \\equiv x(t) + c$ 且 $c \\in \\mathbb{R}^{k}$ 是常数，则 $\\dot{x}_{c}(t) = \\dot{x}(t) + \\dot{c} = \\dot{x}(t)$，因为 $\\dot{c} = 0$。其次，带有截距的普通最小二乘解等于通过将中心化的响应变量对中心化的预测变量进行回归得到的解；而正规方程明确揭示了在排除截距时均值是如何进入方程的。\n\n引入矩阵 $X \\in \\mathbb{R}^{k \\times T}$ 和 $\\dot{X} \\in \\mathbb{R}^{k \\times T}$，其列分别为 $x(t)$ 和 $\\dot{x}(t)$。设 $\\mathbf{1} \\in \\mathbb{R}^{T}$ 是全为 1 的向量，并定义中心化矩阵 $H \\equiv I - \\frac{1}{T}\\,\\mathbf{1}\\mathbf{1}^{\\top}$。那么 $XH$ 减去了列均值：$XH = [x(t) - \\bar{x}]_{t=1}^{T}$，类似地 $\\dot{X}H = [\\dot{x}(t) - \\overline{\\dot{x}}]_{t=1}^{T}$。偏移后的数据为 $X_{c} \\equiv X + c\\,\\mathbf{1}^{\\top}$，且 $X_{c}H = XH$ 因为 $H\\mathbf{1} = 0$。\n\n包含截距的情况。带有 $(A,b)$ 的最小二乘目标函数为\n$$\n\\min_{A,b}\\ \\left\\| \\dot{X} - A X - b\\,\\mathbf{1}^{\\top} \\right\\|_{F}^{2}.\n$$\n线性回归中一个标准且经过充分检验的事实是，该问题的最优 $\\hat{A}$ 等于\n$$\n\\min_{A}\\ \\left\\| \\dot{X}H - A\\,XH \\right\\|_{F}^{2},\n$$\n的最小化子，随后截距由 $\\hat{b} = \\overline{\\dot{x}} - \\hat{A}\\,\\bar{x}$ 给出。这可以直接从通过对目标函数关于 $A$ 和 $b$ 求导、将导数设为零并求解得到的正规方程中得出；或者等价地，通过注意到通过 $H$ 将预测变量和响应变量都投影到零均值子空间上可以解耦截距。关键在于，如果我们用 $X_{c} \\equiv X + c\\,\\mathbf{1}^{\\top}$ 替换 $X$，中心化的预测变量保持不变：$X_{c}H = XH$。因此 $\\|\\dot{X}H - A\\,XH\\|_{F}^{2}$ 的最小化子 $\\hat{A}$ 对于添加 $c$ 是不变的。截距会调整为 $\\hat{b}_{c} = \\overline{\\dot{x}} - \\hat{A}\\,\\overline{x_{c}} = \\overline{\\dot{x}} - \\hat{A}\\,(\\bar{x} + c) = \\hat{b} - \\hat{A}\\,c$。因此，在有截距的情况下，$\\hat{A}$ 不受影响，而 $\\hat{b}$ 会移动以吸收偏移。\n\n不含截距且不中心化的情况。如果 $b \\equiv 0$ 且我们不进行中心化，最小二乘问题为\n$$\n\\min_{A}\\ \\left\\| \\dot{X} - A X \\right\\|_{F}^{2}.\n$$\n其正规方程为\n$$\n\\dot{X} X^{\\top} = A \\, (X X^{\\top}).\n$$\n假设 $X X^{\\top}$ 可逆，解为 $\\hat{A} = \\dot{X} X^{\\top} (X X^{\\top})^{-1}$。添加常数偏移后，预测变量变为 $X_{c} = X + c\\,\\mathbf{1}^{\\top}$，正规方程为\n$$\n\\dot{X} X_{c}^{\\top} = A \\, (X_{c} X_{c}^{\\top}).\n$$\n使用 $\\sum_{t=1}^{T} x(t) = T\\,\\bar{x}$ 展开两边：\n$$\n\\dot{X} X_{c}^{\\top} = \\dot{X} X^{\\top} + \\dot{X}\\,\\mathbf{1}\\,c^{\\top} = \\dot{X} X^{\\top} + T\\,\\overline{\\dot{x}}\\,c^{\\top},\n$$\n$$\nX_{c} X_{c}^{\\top} = X X^{\\top} + X\\,\\mathbf{1}\\,c^{\\top} + c\\,\\mathbf{1}^{\\top} X^{\\top} + c\\,\\mathbf{1}^{\\top}\\mathbf{1}\\,c^{\\top} = X X^{\\top} + T\\,\\bar{x}\\,c^{\\top} + T\\,c\\,\\bar{x}^{\\top} + T\\,c\\,c^{\\top}.\n$$\n除非 $\\bar{x} = 0$ 和 $\\overline{\\dot{x}} = 0$ 同时成立，否则这些额外的依赖于均值的项会改变正规方程，从而改变 $\\hat{A}$。因此，在没有截距且不中心化的情况下，添加常数偏移通常会改变 $\\hat{A}$。\n\n中心化的作用。如果我们对 $X$ 和 $\\dot{X}$ 进行中心化，用 $XH$ 和 $\\dot{X}H$ 替换它们，那么添加任何常数偏移 $c$ 都不会改变 $XH$，因为 $X_{c}H = (X + c\\,\\mathbf{1}^{\\top})H = XH + c\\,(\\mathbf{1}^{\\top}H) = XH$。类似地，向 $\\dot{x}(t)$ 添加常数也不会影响 $\\dot{X}H$，而且无论如何，向 $x(t)$ 添加 $c$ 并不会改变 $\\dot{x}(t)$。因此，即使不包含截距，对 $A$ 的中心化最小二乘估计对常数偏移也是不变的。\n\n对旋转动力学和 jPCA 的解释。在 jPCA 中，人们约束 $A$ 为斜对称的，以分离降维状态中的旋转结构。如果数据未中心化且未拟合截距，斜对称约束并不能消除预测变量中平移的影响；驱动估计的协方差仍然依赖于均值。中心化定义了一个有意义的原点（通常靠近一个潜在的不动点或平均轨迹），使得拟合的 $\\hat{A}$ 可以被解释为围绕该工作点的流的最佳线性近似（一个雅可比矩阵）。这使得提取的旋转能够反映真实的局部动力学，而不是由任意选择原点所引入的人为结果。\n\n逐项分析：\n\nA. 有截距时，回归等价于将中心化的响应变量对中心化的预测变量进行回归。由于添加 $c$ 不会改变中心化的预测变量 $XH$，且 $\\dot{x}(t)$ 也不变，所以 $\\hat{A}$ 是不变的，而 $\\hat{b}$ 会移动 $-\\hat{A}c$。结论：正确。\n\nB. 没有截距且不进行中心化时，当 $c \\neq 0$ 时，正规方程会获得依赖于均值的项，从而改变 $\\hat{A}$。中心化可以移除这些项并恢复不变性。结论：正确。\n\nC. 向 $x(t)$ 添加 $c$ 不会改变 $\\dot{x}(t)$，因为 $\\dot{c} = 0$。因此，$\\dot{x}(t)$ 会改变这个前提是错误的。结论：错误。\n\nD. 对 $A$ 的斜对称约束本身并不能在排除 $b$ 时抵消非零均值的影响；不进行中心化，依赖于均值的项仍然存在于正规方程中。中心化仍然是必要的。结论：错误。\n\nE. 中心化建立了一个一致的原点，使得 $\\hat{A}$ 近似该点周围的雅可比矩阵，从而能够解释关于一个已定义工作点的旋转，而不是将动力学与平移混为一谈。结论：正确。",
            "answer": "$$\\boxed{ABE}$$"
        },
        {
            "introduction": "现在，让我们将前面学到的概念融会贯通。这最后一个练习将引导你完成一个完整的计算实验，以评估 jPCA 方法的统计功效。通过从零开始构建一个模拟——从生成泊松分布的脉冲序列到执行完整的 jPCA 分析流程——你将对在不同条件下（如试验次数和放电率）可靠地检测到旋转需要多少数据量，有一个深刻且实用的理解。",
            "id": "4169517",
            "problem": "您的任务是设计并实现一个完整的、可运行的程序，该程序使用jPCA（j主成分分析）对检测神经元群体活动中的旋转动力学进行功效分析。该分析必须改变试验次数和脉冲发放率，并估计在保持指定假阳性率的同时，检测到旋转所需的最少数据量。您的解决方案必须遵循下文详述的第一性原理和经过充分检验的事实，并为指定的测试套件生成结果。\n\n基本原理：\n- 群体活动被建模为一组具有泊松统计特性的脉冲序列。对于神经元 $n$、时间窗 $t_j$ 和试验 $k$，脉冲计数 $y_{n,k}(t_j)$ 被建模为一个泊松随机变量，其均值为 $\\lambda_{n}(t_j) \\Delta t$，其中 $\\lambda_{n}(t_j)$ 是瞬时发放率，$\\Delta t$ 是以秒为单位的时间窗宽度。即，$y_{n,k}(t_j) \\sim \\mathrm{Poisson}(\\lambda_n(t_j)\\Delta t)$。\n- 旋转动力学由一个二维潜变量 $z(t) \\in \\mathbb{R}^2$ 建模，其演化方式为 $z(t) = [\\cos(2\\pi f t), \\sin(2\\pi f t)]^\\top$，其中 $f$ 是以赫兹（周/秒）为单位的旋转频率，三角函数的参数以弧度为单位。\n- 每个神经元发放率由潜旋转的线性驱动加上一个基线率构成，其权重为 $\\mathbf{g}_n \\in \\mathbb{R}^2$。神经元 $n$ 在时间 $t$ 的发放率为\n$$\n\\lambda_n(t) = \\max\\left(0, r_0 + \\mathbf{g}_n^\\top z(t)\\right),\n$$\n其中 $r_0$ 是以赫兹为单位的基线率，权重从一个零均值分布中抽取，其尺度由一个调制幅度参数 $a$（单位为赫兹）设定。$\\max(0,\\cdot)$ 操作确保了发放率的非负性。\n- 每个神经元和时间窗的试验平均发放率估计值为\n$$\n\\hat{\\lambda}_n(t_j) = \\frac{1}{T \\Delta t} \\sum_{k=1}^{T} y_{n,k}(t_j),\n$$\n其中 $T$ 是试验次数。\n- 对时间中心化的试验平均活动进行主成分分析（PCA），将维度降低到 $d$ 个成分。令 $\\mathbf{x}(t_j) \\in \\mathbb{R}^d$ 表示PCA投影后的时间序列。\n- 时间导数通过有限差分进行近似：\n$$\n\\dot{\\mathbf{x}}(t_j) \\approx \\frac{\\mathbf{x}(t_{j+1}) - \\mathbf{x}(t_{j-1})}{2\\Delta t}。\n$$\n- 通过拟合一个线性时不变模型来识别旋转动力学\n$$\n\\dot{\\mathbf{x}}(t_j) \\approx \\mathbf{A}\\,\\mathbf{x}(t_j),\n$$\n其中 $\\mathbf{A} \\in \\mathbb{R}^{d \\times d}$ 被约束为反对称矩阵，即 $\\mathbf{A}^\\top = -\\mathbf{A}$。反对称生成元产生纯虚数特征值，对应于旋转。\n- 给定矩阵 $\\mathbf{X} \\in \\mathbb{R}^{d \\times M}$ 和 $\\mathbf{Y} \\in \\mathbb{R}^{d \\times M}$，它们分别收集了 $M$ 个可用时间点上的 $\\mathbf{x}(t_j)$ 和 $\\dot{\\mathbf{x}}(t_j)$，无约束最小二乘解为 $\\mathbf{M} = \\mathbf{Y}\\mathbf{X}^\\top(\\mathbf{X}\\mathbf{X}^\\top)^{-1}$。通过将 $\\mathbf{M}$ 投影到反对称矩阵空间，可以得到一个符合原理的反对称估计量：\n$$\n\\mathbf{A} = \\frac{\\mathbf{M} - \\mathbf{M}^\\top}{2}。\n$$\n- 检测统计量定义为\n$$\ns = \\max_i \\left|\\operatorname{Im}(\\lambda_i)\\right|,\n$$\n其中 $\\{\\lambda_i\\}$ 是 $\\mathbf{A}$ 的特征值。较大的 $s$ 值表示拟合动力学中的旋转速度更快。\n- 通过模拟非旋转数据集（具有相同的 $N$、$T$、$\\Delta t$、持续时间、基线率 $r_0$ 和调制尺度 $a$，其中发放率随时间变化但没有相干旋转，例如每个神经元和时间点都有独立的噪声）来构建零分布。对于指定的假阳性率 $\\alpha$，阈值 $\\tau$ 被设置为 $s$ 的零分布的上 $(1-\\alpha)$ 分位数。如果 $s > \\tau$，则宣告检测到旋转。\n- 对于给定的参数集，功效是其检测统计量超过 $\\tau$ 的独立旋转模拟所占的比例。\n\n您的程序必须：\n1. 针对试验次数网格 $T \\in \\{4, 8, 16, 32, 64\\}$，根据上述原理模拟数据集。\n2. 对于每个 $T$，通过生成多个零数据集并计算检测统计量 $s$，来估计指定假阳性率 $\\alpha$ 对应的零分布阈值 $\\tau$。\n3. 对于每个 $T$，通过生成多个旋转数据集并计算 $s > \\tau$ 的比例，来估计功效（真阳性率）。\n4. 返回达到或超过目标功效 $p^\\ast$ 的最小 $T$ 值。如果所有测试的 $T$ 值都未达到，则返回 $-1$。\n\n单位和常量：\n- 所有脉冲发放率及其参数必须以赫兹（脉冲/秒）表示。\n- 时间窗宽度必须以秒为单位表示为 $\\Delta t$。\n- 旋转频率 $f$ 必须以赫兹表示。\n- 试验持续时间 $D$ 必须以秒为单位。\n- 所有三角函数的参数均以弧度为单位。\n\n需实现的算法细节：\n- 使用 $d = \\min(6, N)$ 个主成分。\n- 在PCA之前，对跨时间的试验平均发放率应用适度的高斯平滑以稳定导数。高斯核的标准差应为1个时间窗；实现一个归一化的离散核。\n- 在PCA之前对数据进行跨时间中心化。\n- 使用无约束最小二乘解的反对称投影来获得 $\\mathbf{A}$。\n- 从 $\\mathbf{A}$ 的特征值计算检测统计量 $s$。\n- 对于每个参数集和每个 $T$，从 $K$ 个零假设重复样本中计算零分布阈值 $\\tau$，并从 $R$ 个旋转重复样本中计算功效。\n- 对于固定的 $T$，在零假设模拟和旋转模拟中使用相同的 $N$、$r_0$、$a$、$f$、$D$ 和 $\\Delta t$。\n\n测试套件：\n实现程序以解决以下四个测试案例。对于每个案例，候选试验次数为 $T \\in \\{4, 8, 16, 32, 64\\}$，零假设重复次数为 $K=150$，旋转重复次数为 $R=30$。\n\n- 案例1（典型的可检测旋转）：$N=20$，$r_0=10$ (Hz)，$a=5$ (Hz)，$f=1$ (Hz)，$\\alpha=0.05$，$p^\\ast=0.8$，$D=1.0$ (s)，$\\Delta t=0.02$ (s)。\n- 案例2（低发放率，检测更难）：$N=20$，$r_0=2$ (Hz)，$a=1$ (Hz)，$f=1$ (Hz)，$\\alpha=0.05$，$p^\\ast=0.8$，$D=1.0$ (s)，$\\Delta t=0.02$ (s)。\n- 案例3（更高频率，更严格的假阳性率）：$N=10$，$r_0=8$ (Hz)，$a=2$ (Hz)，$f=2$ (Hz)，$\\alpha=0.01$，$p^\\ast=0.9$，$D=1.0$ (s)，$\\Delta t=0.02$ (s)。\n- 案例4（更多神经元，强调制）：$N=30$，$r_0=12$ (Hz)，$a=6$ (Hz)，$f=0.5$ (Hz)，$\\alpha=0.05$，$p^\\ast=0.8$，$D=1.0$ (s)，$\\Delta t=0.02$ (s)。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[result1,result2,result3,result4]\"），其中每个结果是对应测试案例达到或超过目标功效的最小试验次数（来自候选集的一个整数），如果都未达到则为-1。\n\n不允许用户输入。程序必须按原样运行，并且只能使用指定的环境。所有中间参数、常量和函数都必须在程序内部定义。",
            "solution": "所提出的问题是计算神经科学中一个定义明确且有科学依据的任务。它要求为j-主成分分析（jPCA）方法实现一个功效分析，jPCA是一种用于识别神经元群体记录中旋转动力学的技术。该问题是有效的，因为它基于已建立的神经活动模型和标准统计程序。所有参数都已指定，目标明确。以下是对将要实现的方法的合理、分步的阐述。\n\n### 1. 神经元群体活动建模\n\n此次功效分析的基础是能够生成包含或不包含目标特征——即旋转动力学——的合成神经数据。\n\n**旋转（信号）数据生成：**\n在持续时间 $D$ 内，以 $\\Delta t$ 的时间分辨率模拟一个包含 $N$ 个神经元的群体的活动。其底层动力学由一个二维潜变量 $z(t) \\in \\mathbb{R}^2$ 控制，该变量以频率 $f$ 进行纯旋转演化：\n$$\nz(t) = \\begin{bmatrix} \\cos(2\\pi f t) \\\\ \\sin(2\\pi f t) \\end{bmatrix}\n$$\n每个神经元的发放率 $\\lambda_n(t)$ 是这个潜变量状态的线性投影，加上一个基线发放率 $r_0$，并经过整流以确保非负性：\n$$\n\\lambda_n(t) = \\max\\left(0, r_0 + \\mathbf{g}_n^\\top z(t)\\right)\n$$\n权重向量 $\\mathbf{g}_n \\in \\mathbb{R}^2$ 决定了神经元 $n$ 被潜旋转调制的强度和相位偏好。为了满足给定的条件，即权重从一个零均值分布中抽取，其尺度由调制幅度 $a$ 设定，我们将为每个向量 $\\mathbf{g}_n$ 分配一个固定的幅值 $a$ 和一个随机的方向。这通过从 $[0, 2\\pi)$ 中均匀抽取一个相位 $\\phi_n$ 并设置 $\\mathbf{g}_n = [a\\cos(\\phi_n), a\\sin(\\phi_n)]^\\top$ 来实现。\n\n对于 $T$ 次试验中的每一次，神经元 $n$ 在时间窗 $j$ 内的脉冲计数 $y_{n,k}(t_j)$ 从泊松分布中抽取，这是一个用于脉冲计数变异性的标准模型：\n$$\ny_{n,k}(t_j) \\sim \\mathrm{Poisson}(\\lambda_n(t_j)\\Delta t)\n$$\n\n**非旋转（零假设）数据生成：**\n为了构建一个特定且相关的零假设，我们需要生成与旋转数据共享关键统计特性但缺乏相干旋转结构的数据。一种常用且有效的方法是，在保持每个神经元随时间的边缘发放率分布的同时，破坏群体间的时间协调性。这可以通过首先如上所述计算理想的发放率曲线 $\\lambda_n(t)$，然后对每个神经元 $n$，随机置换其发放率向量的时间进程来实现。这种打乱操作破坏了旋转所需的一致相位演进。然后使用相同的泊松过程从这些时间上被打乱的发放率生成脉冲。这确保了零假设数据与信号数据具有相同数量的神经元、试验次数、时间点和整体发放统计数据，从而进行严格的统计比较。\n\n### 2. 用于旋转动力学识别的jPCA流程\n\n对于信号数据集和零假设数据集，应用相同的分析流程来提取一个检验统计量。\n\n**步骤1：数据预处理**\n首先将原始脉冲计数在 $T$ 次试验中取平均，并转换为以赫兹为单位的发放率估计值：\n$$\n\\hat{\\lambda}_n(t_j) = \\frac{1}{T \\Delta t} \\sum_{k=1}^{T} y_{n,k}(t_j)\n$$\n为了获得对底层动力学的更平滑估计，并稳定后续的数值微分，将这些试验平均发放率估计值与一个标准差为1个时间窗的离散、归一化高斯核进行卷积。\n\n**步骤2：通过PCA进行降维**\n高维神经数据通常充满噪声和冗余。主成分分析（PCA）用于将数据投影到一个能捕获最大方差的低维子空间上。所有 $N$ 个神经元的平滑、试验平均发放率（形成一个大小为 $N \\times (\\text{时间窗数量})$ 的数据矩阵）首先通过减去每个神经元的时间均值来进行中心化。然后执行PCA，并将数据投影到前 $d = \\min(6, N)$ 个主成分上。这将产生一个降维后的时间序列 $\\mathbf{x}(t_j) \\in \\mathbb{R}^d$。\n\n**步骤3：拟合线性动力学系统**\njPCA假定状态向量 $\\mathbf{x}(t)$ 的演化可以用一个线性时不变系统来近似：\n$$\n\\dot{\\mathbf{x}}(t) \\approx \\mathbf{A}\\,\\mathbf{x}(t)\n$$\n纯旋转动力学是由一个反对称的状态转移矩阵 $\\mathbf{A}$（即 $\\mathbf{A}^\\top = -\\mathbf{A}$）生成的，其特征值为纯虚数。\n\n状态导数 $\\dot{\\mathbf{x}}(t_j)$ 使用作用于PCA投影数据的二阶中心有限差分公式来近似：\n$$\n\\dot{\\mathbf{x}}(t_j) \\approx \\frac{\\mathbf{x}(t_{j+1}) - \\mathbf{x}(t_{j-1})}{2\\Delta t}\n$$\n这个近似除了第一个和最后一个时间点外都有效。我们将对应的状态向量 $\\mathbf{x}(t_j)$ 和它们的估计导数 $\\dot{\\mathbf{x}}(t_j)$ 收集到矩阵 $\\mathbf{X_{state}} \\in \\mathbb{R}^{d \\times M}$ 和 $\\mathbf{X_{dot}} \\in \\mathbb{R}^{d \\times M}$ 中，其中 $M$ 是有效时间点的数量。\n\n系统 $\\mathbf{X_{dot}} \\approx \\mathbf{A}\\,\\mathbf{X_{state}}$ 是超定的。通过最小二乘法可以找到无约束动力学矩阵 $\\mathbf{M}$ 的一个数值上稳健的估计。问题描述中提供了闭式解 $\\mathbf{M} = \\mathbf{X_{dot}}\\mathbf{X_{state}}^\\top(\\mathbf{X_{state}}\\mathbf{X_{state}}^\\top)^{-1}$。对 $\\mathbf{M}$ 的最佳反对称近似是其在反对称矩阵子空间上的投影：\n$$\n\\mathbf{A} = \\frac{\\mathbf{M} - \\mathbf{M}^\\top}{2}\n$$\n\n### 3. 统计检验与功效分析\n\n**步骤1：检测统计量**\n拟合的反对称矩阵 $\\mathbf{A}$ 的特征值以纯虚共轭对 $\\pm i\\omega$ 的形式出现。这些值 $\\omega$ 代表了数据中旋转分量的角频率。定义单个汇总统计量 $s$ 为 $\\mathbf{A}$ 的所有特征值中最大虚部的大小：\n$$\ns = \\max_i \\left|\\operatorname{Im}(\\lambda_i)\\right|\n$$\n其中 $\\{\\lambda_i\\}$ 是 $\\mathbf{A}$ 的特征值。较大的 $s$ 值表示更强或更快的检测到的旋转。\n\n**步骤2：零假设检验**\n为确定一个观测到的 $s$ 值是否在统计上显著，我们将其与一个零分布进行比较。该分布是通过将整个jPCA流程应用于先前描述的 $K$ 个独立的零假设数据集而生成的。这将产生一组 $K$ 个零假设统计量 $\\{s_{\\text{null}, i}\\}$。检测阈值 $\\tau$ 被设置为该经验零分布的 $(1-\\alpha)$ 分位数，其中 $\\alpha$ 是期望的假阳性率。如果来自给定数据集的统计量 $s$ 超过此阈值，即 $s > \\tau$，则宣告检测到旋转。\n\n**步骤3：功效计算**\n统计功效是在零假设为假时正确地拒绝它的概率（即真阳性率）。我们通过生成 $R$ 个独立的旋转（信号）数据集来估计给定参数集（包括试验次数 $T$）的功效。对于每个数据集，我们计算统计量 $s$ 并检查它是否超过预先计算的阈值 $\\tau$。功效被估计为这 $R$ 次模拟中导致检测的比例：\n$$\n\\text{Power} = \\frac{\\text{Number of rotational datasets with } s > \\tau}{R}\n$$\n\n**步骤4：确定所需的最小数据量**\n最终目标是从候选集 $\\{4, 8, 16, 32, 64\\}$ 中找到达到目标功效水平 $p^\\ast$ 的最小试验次数 $T$。算法按升序遍历此集合。对于每个 $T$，它计算零分布阈值 $\\tau$，然后估计功效。估计功效大于或等于 $p^\\ast$ 的第一个 $T$ 值即为结果。如果对于所有测试的 $T$ 值都未能达到目标功效，则结果为 $-1$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the power analysis for all test cases.\n    \"\"\"\n    test_cases = [\n        {'N': 20, 'r0': 10, 'a': 5, 'f': 1, 'alpha': 0.05, 'p_star': 0.8, 'D': 1.0, 'dt': 0.02},\n        {'N': 20, 'r0': 2, 'a': 1, 'f': 1, 'alpha': 0.05, 'p_star': 0.8, 'D': 1.0, 'dt': 0.02},\n        {'N': 10, 'r0': 8, 'a': 2, 'f': 2, 'alpha': 0.01, 'p_star': 0.9, 'D': 1.0, 'dt': 0.02},\n        {'N': 30, 'r0': 12, 'a': 6, 'f': 0.5, 'alpha': 0.05, 'p_star': 0.8, 'D': 1.0, 'dt': 0.02},\n    ]\n\n    # Global simulation parameters\n    candidate_trials = [4, 8, 16, 32, 64]\n    K_null_reps = 150\n    R_rot_reps = 30\n    \n    # Use a fixed seed for reproducibility of the entire analysis\n    rng = np.random.default_rng(seed=12345)\n\n    results = []\n    for params in test_cases:\n        min_T = _find_minimum_trials(params, candidate_trials, K_null_reps, R_rot_reps, rng)\n        results.append(min_T)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef _find_minimum_trials(params, T_values, K, R, rng):\n    \"\"\"\n    Finds the minimum number of trials T to achieve target power p_star.\n    \"\"\"\n    for T in T_values:\n        # 1. Estimate null threshold tau\n        null_stats = []\n        for _ in range(K):\n            avg_rates = _generate_averaged_rates(params, T, rotational=False, rng=rng)\n            s_null = _run_jpca_and_get_stat(avg_rates, params['N'], params['dt'])\n            if s_null is not None:\n                null_stats.append(s_null)\n        \n        if not null_stats:\n            continue\n            \n        tau = np.percentile(null_stats, (1 - params['alpha']) * 100)\n\n        # 2. Estimate power\n        detections = 0\n        for _ in range(R):\n            avg_rates = _generate_averaged_rates(params, T, rotational=True, rng=rng)\n            s_rot = _run_jpca_and_get_stat(avg_rates, params['N'], params['dt'])\n            if s_rot is not None and s_rot > tau:\n                detections += 1\n        \n        power = detections / R\n\n        # 3. Check if target power is met\n        if power >= params['p_star']:\n            return T\n            \n    return -1\n\ndef _generate_averaged_rates(params, T, rotational, rng):\n    \"\"\"\n    Generates trial-averaged firing rates for a single dataset.\n    \"\"\"\n    N, r0, a, f, D, dt = params['N'], params['r0'], params['a'], params['f'], params['D'], params['dt']\n    num_time_bins = int(D / dt)\n    time_vec = np.arange(num_time_bins) * dt\n    \n    # Latent dynamics\n    angles = 2 * np.pi * f * time_vec\n    z = np.array([np.cos(angles), np.sin(angles)])\n    \n    # Neuron weights\n    phases = rng.uniform(0, 2 * np.pi, size=N)\n    g_vectors = a * np.array([np.cos(phases), np.sin(phases)])\n    \n    # True firing rates\n    rates = r0 + g_vectors.T @ z\n    rates = np.maximum(0, rates)\n\n    if not rotational:\n        # Create null data by shuffling time for each neuron\n        shuffled_rates = np.zeros_like(rates)\n        for i in range(N):\n            shuffled_rates[i, :] = rng.permutation(rates[i, :])\n        rates = shuffled_rates\n        \n    # Generate spike counts and average\n    # Sum of T Poisson variables is Poisson with T*lambda\n    total_counts = rng.poisson(rates * dt * T)\n    avg_rates = total_counts / (T * dt)\n    \n    return avg_rates\n\ndef _run_jpca_and_get_stat(avg_rates, N, dt):\n    \"\"\"\n    Runs the jPCA pipeline on trial-averaged rates and returns the statistic 's'.\n    \"\"\"\n    # 1. Gaussian smoothing\n    sigma = 1.0\n    truncate = 4.0\n    kernel_size = int(2 * truncate * sigma + 1)\n    kernel_x = np.arange(kernel_size) - kernel_size // 2\n    kernel = np.exp(-kernel_x**2 / (2 * sigma**2))\n    kernel /= kernel.sum()\n    \n    smoothed_rates = np.apply_along_axis(lambda m: np.convolve(m, kernel, mode='same'), axis=1, arr=avg_rates)\n    \n    # 2. Time-centering\n    centered_rates = smoothed_rates - smoothed_rates.mean(axis=1, keepdims=True)\n    \n    # 3. PCA\n    num_time_bins = centered_rates.shape[1]\n    d = min(6, N)\n    \n    cov_matrix = (centered_rates @ centered_rates.T) / (num_time_bins - 1)\n    try:\n        eigvals, eigvecs = np.linalg.eigh(cov_matrix)\n    except np.linalg.LinAlgError:\n        return None  # Cannot proceed if decomposition fails\n\n    sorted_indices = np.argsort(eigvals)[::-1]\n    proj_matrix = eigvecs[:, sorted_indices[:d]]\n    \n    pca_proj_data = proj_matrix.T @ centered_rates\n    \n    # 4. State-space model fitting\n    # Derivative approximation\n    X_dot = (pca_proj_data[:, 2:] - pca_proj_data[:, :-2]) / (2 * dt)\n    X_state = pca_proj_data[:, 1:-1]\n    \n    # Solve for M using least squares: M * X_state = X_dot\n    try:\n        M_T, _, _, _ = np.linalg.lstsq(X_state.T, X_dot.T, rcond=None)\n        M = M_T.T\n    except np.linalg.LinAlgError:\n        return None # Least squares failed\n\n    # Antisymmetric projection\n    A = (M - M.T) / 2.0\n    \n    # 5. Compute detection statistic\n    try:\n        A_eigvals = np.linalg.eigvals(A)\n    except np.linalg.LinAlgError:\n        return None\n        \n    s = np.max(np.abs(np.imag(A_eigvals)))\n    \n    return s\n\nif __name__ == '__main__':\n    solve()\n```"
        }
    ]
}