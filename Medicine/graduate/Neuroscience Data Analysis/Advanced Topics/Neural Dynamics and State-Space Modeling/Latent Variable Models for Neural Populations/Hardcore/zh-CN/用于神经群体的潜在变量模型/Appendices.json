{
    "hands_on_practices": [
        {
            "introduction": "潜变量模型的核心思想是，未被观测到的因子会产生共享的活动模式。这个练习  为此提供了数学基础，它精确地展示了观测到的神经活动的协方差矩阵是如何由潜变量的数量和神经噪声的特性所决定的。理解这一点是掌握如何在真实数据中寻找潜变量信号的第一步。",
            "id": "4173653",
            "problem": "考虑一个用于神经元群体的线性高斯潜在变量模型。设在时间 $t$ 观测到的群体活动为 $y_t \\in \\mathbb{R}^{n}$，它由潜在变量 $x_t \\in \\mathbb{R}^{k}$ 通过以下方式生成：\n$$\ny_t \\;=\\; C x_t \\;+\\; \\epsilon_t,\n$$\n其中 $C \\in \\mathbb{R}^{n \\times k}$ 是一个固定的载荷矩阵，潜在状态满足 $x_t \\sim \\mathcal{N}(0,Q)$，其中 $Q \\in \\mathbb{R}^{k \\times k}$ 是对称半正定矩阵，观测噪声为 $\\epsilon_t \\sim \\mathcal{N}(0,R)$，其中 $R \\in \\mathbb{R}^{n \\times n}$ 是对称半正定矩阵。假设 $x_t$ 和 $\\epsilon_t$ 是独立的，并且所有过程都是广义平稳的，因此在讨论二阶矩时可以省略时间下标。\n\n从概率论和统计学的核心定义出发，包括协方差、独立性和全协方差定律的定义，推导群体协方差 $\\Sigma_y = \\operatorname{Cov}(y_t)$ 关于 $C$、$Q$ 和 $R$ 的闭式表达式。然后，在以下假设下分析 $\\Sigma_y$ 的秩如何依赖于潜在维度 $k$ 和观测噪声协方差 $R$：$Q$ 是正定的，并且 $C$ 具有满列秩 $k$。为以下两种情况提供严格的论证：\n(i) $R = 0$，\n(ii) $R = \\sigma^{2} I_{n}$，其中 $\\sigma^{2}  0$。\n\n将您的最终答案表示为一个行矩阵，其第一个元素是 $\\Sigma_y$ 的闭式表达式，第二个元素是给出情况 (i) 和 (ii) 中 $\\operatorname{rank}(\\Sigma_y)$ 的单个分段解析表达式。不需要进行数值舍入。",
            "solution": "该问题定义明确，具有科学依据，并包含唯一解所需的所有信息。\n\n首先，我们推导群体协方差 $\\Sigma_y = \\operatorname{Cov}(y_t)$。由于过程是广义平稳的，我们可以省略时间下标 $t$。模型由 $y = C x + \\epsilon$ 给出。\n问题要求从核心定义出发，包括全协方差定律，该定律指出对于随机向量 $y$ 和 $x$，有 $\\operatorname{Cov}(y) = \\mathbb{E}[\\operatorname{Cov}(y|x)] + \\operatorname{Cov}(\\mathbb{E}[y|x])$。\n\n让我们计算右侧的两项。\n\n1.  给定 $x$ 时 $y$ 的条件期望：\n    $$\n    \\mathbb{E}[y | x] = \\mathbb{E}[C x + \\epsilon | x]\n    $$\n    利用期望的线性性质，并在条件期望中将 $x$ 视为常数：\n    $$\n    \\mathbb{E}[y | x] = C x + \\mathbb{E}[\\epsilon | x]\n    $$\n    由于潜在变量 $x$ 和噪声 $\\epsilon$ 是独立的，给定 $x$ 时 $\\epsilon$ 的条件期望等于其无条件期望：$\\mathbb{E}[\\epsilon | x] = \\mathbb{E}[\\epsilon]$。我们已知 $\\epsilon \\sim \\mathcal{N}(0, R)$，因此 $\\mathbb{E}[\\epsilon] = 0$。\n    因此，条件期望为：\n    $$\n    \\mathbb{E}[y | x] = C x\n    $$\n    现在，我们求这一项的协方差。根据随机向量线性变换的协方差性质，并已知 $\\operatorname{Cov}(x) = Q$：\n    $$\n    \\operatorname{Cov}(\\mathbb{E}[y|x]) = \\operatorname{Cov}(C x) = C \\operatorname{Cov}(x) C^T = C Q C^T\n    $$\n\n2.  给定 $x$ 时 $y$ 的条件协方差：\n    $$\n    \\operatorname{Cov}(y|x) = \\operatorname{Cov}(C x + \\epsilon | x)\n    $$\n    给定 $x$，项 $C x$ 是一个常数向量。随机向量加上一个常数的协方差等于原始随机向量的协方差。\n    $$\n    \\operatorname{Cov}(y|x) = \\operatorname{Cov}(\\epsilon | x)\n    $$\n    由于 $x$ 和 $\\epsilon$ 的独立性，$\\epsilon$ 的条件协方差等于其无条件协方差：$\\operatorname{Cov}(\\epsilon | x) = \\operatorname{Cov}(\\epsilon)$。我们已知 $\\operatorname{Cov}(\\epsilon) = R$。\n    $$\n    \\operatorname{Cov}(y|x) = R\n    $$\n    现在，我们求这一项的期望。由于 $R$ 是一个常数矩阵，其期望就是其本身：\n    $$\n    \\mathbb{E}[\\operatorname{Cov}(y|x)] = \\mathbb{E}[R] = R\n    $$\n\n将这两个结果代回全协方差定律，我们得到群体协方差 $\\Sigma_y$：\n$$\n\\Sigma_y = \\operatorname{Cov}(y) = R + C Q C^T\n$$\n这就是 $\\Sigma_y$ 的闭式表达式。\n\n接下来，我们在 $Q \\in \\mathbb{R}^{k \\times k}$ 是正定矩阵且 $C \\in \\mathbb{R}^{n \\times k}$ 具有满列秩 $k$ 的假设下，分析 $\\Sigma_y$ 的秩。正定矩阵是可逆的且具有满秩，所以 $\\operatorname{rank}(Q) = k$。$C$ 具有满列秩意味着 $\\operatorname{rank}(C) = k$。注意，对于一个 $n \\times k$ 矩阵，其秩为 $k$ 的前提是 $n \\geq k$。\n\n(i) 情况 $R=0$：\n在这种情况下，协方差矩阵为 $\\Sigma_y = C Q C^T$。我们要求其秩。\n由于 $Q$ 是对称正定矩阵，存在唯一的对称正定平方根矩阵 $Q^{1/2}$，使得 $Q = Q^{1/2} Q^{1/2}$。因为 $Q$ 是可逆的，所以 $Q^{1/2}$ 也是可逆的，且 $\\operatorname{rank}(Q^{1/2}) = k$。\n我们可以将 $\\Sigma_y$ 写为：\n$$\n\\Sigma_y = C Q^{1/2} Q^{1/2} C^T = (C Q^{1/2}) (C Q^{1/2})^T\n$$\n令 $A = C Q^{1/2}$。那么 $\\Sigma_y = A A^T$。线性代数中的一个基本结论是，对于任何实矩阵 $M$，有 $\\operatorname{rank}(M M^T) = \\operatorname{rank}(M)$。因此，$\\operatorname{rank}(\\Sigma_y) = \\operatorname{rank}(A) = \\operatorname{rank}(C Q^{1/2})$。\n矩阵 $C$ 是一个 $n \\times k$ 矩阵，其秩为 $\\operatorname{rank}(C)=k$；$Q^{1/2}$ 是一个 $k \\times k$ 的可逆矩阵，其秩为 $\\operatorname{rank}(Q^{1/2})=k$。当一个矩阵乘以一个可逆方阵时，其秩不变。\n$$\n\\operatorname{rank}(C Q^{1/2}) = \\operatorname{rank}(C) = k\n$$\n因此，当 $R=0$ 时，群体协方差的秩为：\n$$\n\\operatorname{rank}(\\Sigma_y) = k\n$$\n\n(ii) 情况 $R = \\sigma^{2} I_{n}$，其中 $\\sigma^{2}  0$：\n在这种情况下，协方差矩阵为 $\\Sigma_y = C Q C^T + \\sigma^2 I_n$。\n我们来分析和式中两项的性质。\n第一项 $M = C Q C^T$ 是一个半正定矩阵。这可以通过对任意向量 $v \\in \\mathbb{R}^n$ 考虑 $v^T M v$ 来证明：\n$$\nv^T M v = v^T C Q C^T v = (C^T v)^T Q (C^T v)\n$$\n令 $w = C^T v$。那么 $v^T M v = w^T Q w$。由于 $Q$ 是正定的，对于所有 $w$，都有 $w^T Q w \\geq 0$，这意味着 $M$ 是半正定的。\n第二项 $\\sigma^2 I_n$ 是一个正定矩阵，因为 $\\sigma^2  0$。对于任意非零向量 $v \\in \\mathbb{R}^n$：\n$$\nv^T (\\sigma^2 I_n) v = \\sigma^2 v^T I_n v = \\sigma^2 v^T v = \\sigma^2 \\|v\\|_2^2  0\n$$\n一个半正定矩阵 ($C Q C^T$) 和一个正定矩阵 ($\\sigma^2 I_n$) 的和是一个正定矩阵。为了证明这一点，考虑对于任意非零向量 $v \\in \\mathbb{R}^n$ 的 $v^T \\Sigma_y v$：\n$$\nv^T \\Sigma_y v = v^T(C Q C^T + \\sigma^2 I_n) v = v^T C Q C^T v + \\sigma^2 \\|v\\|_2^2\n$$\n由于 $v^T C Q C^T v \\geq 0$ 且 $\\sigma^2 \\|v\\|_2^2  0$，它们的和必定严格为正：\n$$\nv^T \\Sigma_y v  0 \\quad \\text{for all } v \\neq 0\n$$\n这是正定矩阵的定义。正定矩阵必然是可逆的且具有满秩。由于 $\\Sigma_y$ 是一个 $n \\times n$ 矩阵，其秩为 $n$。\n因此，当 $R = \\sigma^{2} I_{n}$ 且 $\\sigma^{2}  0$ 时，秩为：\n$$\n\\operatorname{rank}(\\Sigma_y) = n\n$$\n\n结合情况 (i) 和 (ii) 的结果，我们可以写出一个关于秩的分段表达式。情况 (i) 对应于 $R=0$，情况 (ii) 对应于 $R$ 是单位矩阵的一个严格正倍数。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nC Q C^T + R,\n\n\\begin{cases}\nk   \\text{若 } R = 0 \\\\\nn   \\text{若 } R = \\sigma^2 I_n \\text{ 且 } \\sigma^2  0\n\\end{cases}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "了解理论上的特征是一回事，但我们如何确定在高维度的嘈杂神经数据中看到的模式在统计上是显著的呢？这个练习  提出了一个现实场景，并要求我们选择正确的统计工具——似然比检验——来正式地比较一个包含潜变量的模型与一个更简单的、神经元相互独立的零模型。",
            "id": "4173676",
            "problem": "你记录了在 $T = 1000$ 次重复的稳态条件试验中，$N = 50$ 个同时监测的神经元的活动，产生了均值为零的逐次试验响应 $\\{y_t \\in \\mathbb{R}^{50}\\}_{t=1}^T$ 和经验协方差 $\\hat{\\Sigma}_y = \\frac{1}{T}\\sum_{t=1}^T y_t y_t^{\\top}$。你希望检验一个 $k = 3$ 的潜因子模型相对于一个零假设的独立模型，是否解释了显著部分的共享噪声相关性。假设逐次试验的变异性服从一个多元正态生成模型，其中独立（零）模型的协方差为 $\\Sigma = \\mathrm{diag}(\\psi_1,\\dots,\\psi_N)$，而潜因子（备择）模型的协方差为 $\\Sigma = L L^{\\top} + \\mathrm{diag}(\\psi_1,\\dots,\\psi_N)$，其中 $L \\in \\mathbb{R}^{N \\times k}$。\n\n以下哪一项是一个有效的假设检验，具有正确的检验统计量和参考分布，用以评估 $k=3$ 的潜因子模型是否比独立模型有统计上显著的改进？\n\nA. 在多元正态假设下构建一个似然比检验（LRT）。在零假设下拟合最大似然估计 $\\hat{\\Sigma}_{\\text{diag}} = \\mathrm{diag}(\\hat{\\psi}_1,\\dots,\\hat{\\psi}_N)$，以及在备择假设下拟合 $\\hat{\\Sigma}_{\\text{FA}} = \\hat{L}\\hat{L}^{\\top} + \\mathrm{diag}(\\hat{\\psi}_1,\\dots,\\hat{\\psi}_N)$（$k=3$）。使用多元正态的对数似然：\n$$\n\\ell(\\Sigma) = -\\frac{T}{2}\\left[\\log|\\Sigma| + \\operatorname{tr}\\left(\\Sigma^{-1}\\hat{\\Sigma}_y\\right)\\right] + \\text{const},\n$$\n构建LRT统计量\n$$\n\\lambda = 2\\left(\\ell\\!\\left(\\hat{\\Sigma}_{\\text{FA}}\\right) - \\ell\\!\\left(\\hat{\\Sigma}_{\\text{diag}}\\right)\\right),\n$$\n并且，在正则性条件下且 $T$ 很大时，将 $\\lambda$ 与自由度为 $\\nu = Nk - \\frac{k(k-1)}{2}$ 的卡方参考分布进行比较。对于 $N=50$ 和 $k=3$，$\\nu = 150 - 3 = 147$。\n\nB. 执行主成分分析（PCA），并将 $\\hat{\\Sigma}_y$ 的前3个最大特征值与 Marchenko–Pastur 上界 $\\lambda_{+} = \\sigma^2\\left(1 + \\sqrt{N/T}\\right)^2$ 进行比较。如果前3个特征值超过 $\\lambda_{+}$，则断定 $k=3$ 个潜因子显著地解释了共享变异性。\n\nC. 计算由 $\\hat{\\Sigma}_y$ 的前3个最大特征值解释的总方差比例 $\\sum_{i=1}^3 \\lambda_i / \\sum_{i=1}^N \\lambda_i$，如果该比例超过 $0.5$，则拒绝独立模型。\n\nD. 构建一个置换检验，通过对所有神经元的试验索引进行相同的置换，将 $k=3$ 的潜因子模型重新拟合到置换后的数据上，重新计算似然改进量，并使用置换分布来获得一个 $p$ 值。如果在 $\\alpha = 0.05$ 的显著性水平上，原始的似然改进量超过了置换后改进量的 $95\\%$ 分位数，则拒绝独立模型。\n\n选择那个为本问题正确指定了有效检验程序、其检验统计量以及合适参考分布的选项。",
            "solution": "用户希望确定一个有效的统计假设检验，用以比较一个 $k=3$ 的因子模型和一个针对神经元群体数据的独立模型。\n\n### 步骤1：提取已知条件\n-   神经元数量：$N = 50$\n-   试验次数：$T = 1000$\n-   数据：均值为零的逐次试验响应 $\\{y_t \\in \\mathbb{R}^{50}\\}_{t=1}^T$\n-   经验协方差：$\\hat{\\Sigma}_y = \\frac{1}{T}\\sum_{t=1}^T y_t y_t^{\\top}$\n-   生成模型：多元正态分布\n-   零假设 ($H_0$)：独立模型。协方差矩阵为 $\\Sigma_0 = \\mathrm{diag}(\\psi_1,\\dots,\\psi_N)$。\n-   备择假设 ($H_1$)：潜因子模型。协方差矩阵为 $\\Sigma_1 = L L^{\\top} + \\mathrm{diag}(\\psi_1,\\dots,\\psi_N)$，其中 $L \\in \\mathbb{R}^{N \\times k}$ 且 $k=3$。\n-   目标：找到一个有效的假设检验（检验统计量和参考分布），用以评估 $k=3$ 的潜因子模型是否比独立模型有统计上显著的改进。\n\n### 步骤2：使用提取的已知条件进行验证\n-   **科学依据：** 该问题坚实地植根于计算神经科学和统计学。在多元正态性假设下，使用因子分析（FA）对神经元群体中的共享变异性（噪声相关性）进行建模是一种标准且被广泛接受的方法。将此模型与更简单的独立神经元零模型进行比较是一个经典的模型选择问题。\n-   **良态性：** 该问题是良态的。它提出了两个具体的、嵌套的统计模型，并要求找到一个标准程序来比较它们。在统计假设检验的框架内，存在一个唯一且有意义的答案。\n-   **目标：** 该问题以精确、客观的数学语言陈述。\n-   **未检测到缺陷：** 问题陈述在科学上是合理的，对于任务是完整的，并使用了明确定义的术语。数据维度（$N=50$, $T=1000$）对于现代神经生理学实验是现实的。没有矛盾或模糊之处。\n\n### 步骤3：结论与行动\n问题陈述是有效的。我将继续推导解决方案并评估各个选项。\n\n### 推导与逐项分析\n\n问题的核心是在两个嵌套的统计模型之间进行假设检验。零模型（$H_0$）提出了一个对角协方差矩阵，这是备择模型（$H_1$）协方差矩阵的一个约束版本。具体来说，零模型对应于因子载荷矩阵 $L$ 为零矩阵的情况。对于在指定参数分布（如多元正态分布）下的嵌套模型，似然比检验（LRT）是一种标准的、渐近最优的检验。\n\nLRT的一般步骤如下：\n1.  定义零假设（$H_0$）和备择假设（$H_1$）。这里，$H_0: \\Sigma = \\mathrm{diag}(\\psi_1, \\dots, \\psi_N)$ 且 $H_1: \\Sigma = LL^\\top + \\mathrm{diag}(\\psi_1, \\dots, \\psi_N)$，其中 $L \\in \\mathbb{R}^{N \\times k}$。\n2.  在两个模型下找到参数的最大似然估计（MLE），得到 $\\hat{\\Sigma}_{\\text{diag}}$ 和 $\\hat{\\Sigma}_{\\text{FA}}$。\n3.  计算两个模型的最大化对数似然，$\\ell(\\hat{\\Sigma}_{\\text{diag}})$ 和 $\\ell(\\hat{\\Sigma}_{\\text{FA}})$。\n4.  构建LRT统计量：$\\lambda = 2 \\left( \\ell(\\hat{\\Sigma}_{\\text{FA}}) - \\ell(\\hat{\\Sigma}_{\\text{diag}}) \\right)$。\n5.  根据 Wilks' 定理，在 $H_0$ 成立且样本量（$T$）足够大的情况下，统计量 $\\lambda$ 渐近服从卡方分布，$\\lambda \\sim \\chi^2(\\nu)$。自由度 $\\nu$ 是备择模型和零模型之间自由参数数量的差。\n\n让我们计算自由度 $\\nu$。\n-   **$H_0$ 下的参数（独立模型）：** 该模型由 $N$ 个独有方差 $\\{\\psi_i\\}_{i=1}^N$ 指定。因此，自由参数的数量为 $p_0 = N$。\n-   **$H_1$ 下的参数（因子分析模型）：** 该模型由 $N$ 个独有方差 $\\{\\psi_i\\}_{i=1}^N$ 和 $N \\times k$ 的载荷矩阵 $L$ 指定。这初步给出了 $N + Nk$ 个参数。然而，因子分析模型存在旋转模糊性：对于任何 $k \\times k$ 的正交矩阵 $R$（其中 $R R^\\top = I$），载荷矩阵 $L' = LR$ 会产生相同的协方差结构，因为 $(LR)(LR)^\\top = LRR^\\top L^\\top = LL^\\top$。为确保可识别性，必须对 $L$ 施加约束。所需的约束数量对应于 $k \\times k$ 正交矩阵群的维度，即 $\\frac{k(k-1)}{2}$。因此，FA模型中的有效自由参数数量为 $p_1 = (N + Nk) - \\frac{k(k-1)}{2}$。\n-   **自由度之差：** $\\nu = p_1 - p_0 = \\left(N + Nk - \\frac{k(k-1)}{2}\\right) - N = Nk - \\frac{k(k-1)}{2}$。\n\n对于给定的值 $N=50$ 和 $k=3$：\n$\\nu = (50)(3) - \\frac{3(3-1)}{2} = 150 - \\frac{6}{2} = 150 - 3 = 147$。\n\n现在，我们基于此框架评估每个选项。\n\n**A. 构建一个似然比检验...**\n该选项精确地描述了上面推导的LRT程序。\n-   它正确地将检验识别为LRT。\n-   它使用了多元正态分布的正确对数似然函数。注意，正态模型下协方差的MLE是经验协方差 $\\hat{\\Sigma}_y$。当将结构化协方差模型的参数MLE（$\\hat{\\Sigma}_{\\text{model}}$）代入似然函数时，项 $\\operatorname{tr}(\\hat{\\Sigma}_{\\text{model}}^{-1}\\hat{\\Sigma}_y)$ 在某些条件下会简化，但待最大化的似然函数的一般形式是正确的。该程序在零模型和备择模型的MLE处正确地评估了此函数。\n-   LRT统计量被正确地表述为 $\\lambda = 2\\left(\\ell\\!\\left(\\hat{\\Sigma}_{\\text{FA}}\\right) - \\ell\\!\\left(\\hat{\\Sigma}_{\\text{diag}}\\right)\\right)$。\n-   对于大的 $T$，参考分布被正确地识别为卡方分布。\n-   自由度的计算，$\\nu = Nk - \\frac{k(k-1)}{2} = 147$，是完全正确的。\n**结论：正确。**\n\n**B. 执行主成分分析（PCA）...**\n该选项建议使用随机矩阵理论（RMT），特别是 Marchenko-Pastur 定律，来检验显著因子。\n-   Marchenko-Pastur 定律描述了当潜在变量是独立同分布（i.i.d.）且方差为 $\\sigma^2$（即真实协方差为 $\\sigma^2 I$）时，样本协方差矩阵特征值的体分布。本问题中的零模型是 $\\Sigma_0 = \\mathrm{diag}(\\psi_1,\\dots,\\psi_N)$，其中方差可以不同，这违反了基本 Marchenko-Pastur 定律的假设。\n-   虽然存在针对异质方差的扩展，但该选项呈现的是最简单的形式，这是不适用的。\n-   这种方法主要是检验*任何*相关性是否存在，其零假设是一个非常特定的模型（i.i.d. 噪声），而不是一个特定的 $k=3$ 因子结构与一个更一般的独立模型之间的检验。\n-   RMT为模型阶数选择（估计 $k$）提供了启发式方法，但它不是与LRT在同一框架下比较预定义的 $H_0$ 和 $H_1$ 的正式假设检验。\n**结论：不正确。**\n\n**C. 计算由前3个最大特征值解释的总方差比例...**\n该选项建议使用由前3个主成分解释的方差比例（PVE）。\n-   这是一个描述性统计量，而不是一个正式的假设检验。假设检验需要一个检验统计量的零分布来计算p值或与从该分布导出的临界值进行比较。\n-   $0.5$ 的阈值是完全任意的，没有统计学上的理由。一个有意义的阈值将取决于 $N$、$T$ 和具体的零模型。例如，对于大的 $N$，即使在独立神经元的零模型下，前几个特征值也可能偶然解释了不可忽略的方差比例。\n-   这个方法将PCA与因子分析混为一谈。虽然它们相关，但却是不同的模型。PCA旨在最大化解释的方差，而FA旨在对协方差结构进行建模。\n**结论：不正确。**\n\n**D. 构建一个置换检验...**\n该选项提出了一个置换检验。一个有效的置换检验必须在保留零假设下数据结构的同时，打破备择假设下存在的统计依赖关系。\n-   零假设是在任何给定的试验 $t$ 内，$N$ 个神经元的活动是相互独立的。相关结构是跨神经元的。\n-   所提议的置换是“对所有神经元的试验索引进行相同的置换”。设原始数据矩阵为 $Y \\in \\mathbb{R}^{N \\times T}$，其中第 $t$ 列是 $y_t$。对试验索引 $\\{1, ..., T\\}$ 的一个置换 $\\pi$ 会创建一个新数据矩阵，其列是 $Y$ 的列的重新排序。数据向量集合 $\\{y_t\\}_{t=1}^T$ 保持不变。\n-   经验协方差矩阵 $\\hat{\\Sigma}_y = \\frac{1}{T} \\sum_{t=1}^T y_t y_t^\\top$ 在这种置换下是不变的，因为求和是针对同一组向量，只是顺序不同。\n-   因此，最大似然估计和LRT统计量 $\\lambda$ 对于原始数据和任何此类置换数据集都将是相同的。由此产生的“置换分布”将是一个单点，使其无法计算p值。\n-   对此问题正确的置换方案应涉及*对每个神经元的试验索引进行独立的*置换。这将保留每个神经元活动的边际分布（如 $H_0$ 所要求），同时破坏跨神经元的相关结构（在 $H_0$ 下不存在）。所提出的程序存在根本性缺陷。\n**结论：不正确。**\n\n结论：只有选项A描述了针对当前问题的有效、标准且正确指定的假设检验。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "一旦我们找到了潜变量结构存在的证据，下一个科学目标就是解释这些潜变量代表什么。如果模型过于复杂，解释可能会很困难。这个练习  探讨了一种强大的技术——稀疏性，它通过确保每个神经元只参与少数几个潜在过程来帮助创建更易于解释的模型。我们将推导由流行的稀疏性促进先验所产生的目标函数。",
            "id": "4173645",
            "problem": "一个实验室记录了一个大小为 $N$ 的神经元集群在 $T$ 个时间窗内的活动，并假设其共享变异可由 $K$ 个潜在因子捕获。他们采用了一个线性高斯潜变量模型（也称为因子分析），该模型由以下生成性假设定义：对于每个时间窗 $t \\in \\{1,\\dots,T\\}$，潜在因子 $x_{t} \\in \\mathbb{R}^{K}$ 被独立地抽取，服从 $x_{t} \\sim \\mathcal{N}(0, I_{K})$ 分布，而观测到的脉冲计数残差 $y_{t} \\in \\mathbb{R}^{N}$（通过减去一个已知的均值偏移量 $d \\in \\mathbb{R}^{N}$ 进行预处理）则生成为 $y_{t} \\mid x_{t} \\sim \\mathcal{N}(C x_{t}, R)$，其中 $C \\in \\mathbb{R}^{N \\times K}$ 是载荷矩阵，$R \\in \\mathbb{R}^{N \\times N}$ 是一个对角线元素严格为正的已知对角协方差矩阵。在一个期望最大化(EM)程序中，假设期望(E)步已经产生了固定的摘要 $\\{x_{t}\\}_{t=1}^{T}$ 并将其视为给定值，而最大化(M)步的目标是在稀疏性促进先验下，通过最大后验(MAP)估计来估计 $C$。\n\n从贝叶斯法则和高斯似然的定义出发，并将 $\\{x_{t}\\}_{t=1}^{T}$ 和 $R$ 视为固定值，推导在 $C$ 的每个元素 $\\{c_{ij}\\}$ 服从以下独立先验分布的情况下，$C$ 的 MAP 目标函数（作为 $C$ 的函数的负对数后验），推导结果可忽略不依赖于 $C$ 的加性项：\n\n1. 尺度为 $b0$ 的拉普拉斯先验，即 $p(c_{ij}) = \\frac{1}{2 b} \\exp\\!\\left(-\\frac{|c_{ij}|}{b}\\right)$。\n2. 混合权重为 $\\pi \\in (0,1)$、厚板方差为 $\\sigma_{s}^{2}0$、尖峰方差为 $\\sigma_{0}^{2} \\in (0, \\sigma_{s}^{2})$ 的尖峰-厚板高斯混合先验，即 $p(c_{ij}) = (1-\\pi)\\,\\mathcal{N}(c_{ij}; 0, \\sigma_{s}^{2}) + \\pi\\,\\mathcal{N}(c_{ij}; 0, \\sigma_{0}^{2})$。\n\n你的推导必须从高斯似然和贝叶斯法则的基本原理开始，明确展示惩罚项是如何从先验中产生的。另外，请在神经元集群分析的背景下解释，为什么对 $C$ 施加稀疏性会增强神经元在潜在因子中参与度的可解释性。\n\n提供两个最终的 MAP 目标函数，它们是 $C$, $\\{x_{t}\\}_{t=1}^{T}$, $\\{y_{t}\\}_{t=1}^{T}$, $R$, $b$, $\\pi$, $\\sigma_{s}^{2}$ 和 $\\sigma_{0}^{2}$ 的显式函数，每个函数都可忽略不依赖于 $C$ 的加性常数。最终答案必须只包含这两个目标表达式，并格式化为单行矩阵。不需要进行数值舍入。",
            "solution": "该问题是有效的，因为它在为神经科学数据建立的潜变量建模框架内，提出了一个标准的、适定的统计估计任务。它具有科学依据、客观性，并包含推导所需目标函数的全部必要信息。\n\n目标是找到载荷矩阵 $C$ 的最大后验（MAP）估计。MAP 估计 $\\hat{C}_{\\text{MAP}}$ 在给定观测数据 $\\{y_t\\}_{t=1}^{T}$ 和估计的潜在因子 $\\{x_t\\}_{t=1}^{T}$ 的条件下，最大化 $C$ 的后验概率。根据贝叶斯法则，后验概率为：\n$$\np(C \\mid \\{y_t\\}, \\{x_t\\}) \\propto p(\\{y_t\\} \\mid C, \\{x_t\\}) p(C)\n$$\n其中 $p(\\{y_t\\} \\mid C, \\{x_t\\})$ 是数据的似然，$p(C)$ 是参数的先验。为简化表示，令 $Y = \\{y_t\\}_{t=1}^{T}$ 和 $X = \\{x_t\\}_{t=1}^{T}$。\n\n最大化后验概率等价于最小化其负对数。因此，我们记为 $J(C)$ 的 MAP 目标函数是负对数后验，可忽略不依赖于 $C$ 的加性常数：\n$$\nJ(C) = -\\ln p(C \\mid Y, X) = -\\ln p(Y \\mid C, X) - \\ln p(C) + \\text{constant}\n$$\n项 $-\\ln p(Y \\mid C, X)$ 是负对数似然，而 $-\\ln p(C)$ 是负对数先验，它起到正则化项的作用。\n\n首先，我们来推导负对数似然项，这一项在问题的两个部分中是共同的。在给定 $C$ 和 $\\{x_t\\}$ 的条件下，不同时间窗的观测值 $y_t$ 是条件独立的。因此，总似然是每个时间窗似然的乘积：\n$$\np(Y \\mid C, X) = \\prod_{t=1}^{T} p(y_t \\mid C, x_t)\n$$\n模型指定 $y_t \\mid x_t \\sim \\mathcal{N}(C x_t, R)$。维度为 $N$ 的多元正态分布 $\\mathcal{N}(\\mu, \\Sigma)$ 的概率密度函数为：\n$$\np(z; \\mu, \\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^{N} \\det(\\Sigma)}} \\exp\\left(-\\frac{1}{2} (z-\\mu)^T \\Sigma^{-1} (z-\\mu)\\right)\n$$\n在我们的情况中，对于每个时间窗 $t$，变量是 $y_t$，均值是 $\\mu = C x_t$，协方差是 $\\Sigma = R$。单个时间窗的对数似然是：\n$$\n\\ln p(y_t \\mid C, x_t) = -\\frac{N}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln(\\det(R)) - \\frac{1}{2}(y_t - C x_t)^T R^{-1} (y_t - C x_t)\n$$\n前两项不依赖于 $C$，因此可以被吸收到加性常数中。所有时间窗的负对数似然是关于 $t$ 的和：\n$$\n-\\ln p(Y \\mid C, X) = \\frac{1}{2} \\sum_{t=1}^{T} (y_t - C x_t)^T R^{-1} (y_t - C x_t) + \\text{constant}\n$$\n由于 $R$ 是一个对角线元素 $R_{ii}$ 严格为正的对角矩阵，它的逆矩阵 $R^{-1}$ 也是一个对角矩阵，其元素为 $1/R_{ii}$。我们可以更明确地写出二次型。设 $c_{ij}$ 是 $C$ 的第 $i$ 行第 $j$ 列的元素，设 $y_{it}$ 是 $y_t$ 的第 $i$ 个分量，设 $x_{jt}$ 是 $x_t$ 的第 $j$ 个分量。向量 $C x_t$ 的第 $i$ 个分量是 $\\sum_{j=1}^{K} c_{ij} x_{jt}$。\n负对数似然变为：\n$$\n\\mathcal{L}(C) = -\\ln p(Y \\mid C, X) = \\frac{1}{2} \\sum_{t=1}^{T} \\sum_{i=1}^{N} \\frac{(y_{it} - \\sum_{j=1}^{K} c_{ij} x_{jt})^{2}}{R_{ii}} + \\text{constant}\n$$\n\n现在我们为每种先验推导完整的目标函数 $J(C) = \\mathcal{L}(C) - \\ln p(C)$。\n\n**1. 拉普拉斯先验**\n\n该先验假设矩阵 $C$ 的每个元素 $c_{ij}$ 都独立地从拉普拉斯分布中抽取：\n$$\np(c_{ij}) = \\frac{1}{2b} \\exp\\left(-\\frac{|c_{ij}|}{b}\\right)\n$$\n整个矩阵 $C$ 的先验是其元素先验的乘积：\n$$\np(C) = \\prod_{i=1}^{N} \\prod_{j=1}^{K} p(c_{ij}) = \\prod_{i=1}^{N} \\prod_{j=1}^{K} \\frac{1}{2b} \\exp\\left(-\\frac{|c_{ij}|}{b}\\right)\n$$\n对数先验是：\n$$\n\\ln p(C) = \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln\\left(\\frac{1}{2b} \\exp\\left(-\\frac{|c_{ij}|}{b}\\right)\\right) = \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\left(\\ln\\left(\\frac{1}{2b}\\right) - \\frac{|c_{ij}|}{b}\\right)\n$$\n负对数先验，忽略与 $C$ 无关的常数项 $\\sum_{i,j}\\ln(2b)$，为：\n$$\n-\\ln p(C) = \\frac{1}{b} \\sum_{i=1}^{N} \\sum_{j=1}^{K} |c_{ij}| + \\text{constant}\n$$\n该项与 $C$ 元素的 $L_1$ 范数成正比。与负对数似然结合，拉普拉斯先验的 MAP 目标函数为：\n$$\nJ_1(C) = \\frac{1}{2} \\sum_{t=1}^{T} \\sum_{i=1}^{N} \\frac{1}{R_{ii}} \\left(y_{it} - \\sum_{j=1}^{K} c_{ij} x_{jt}\\right)^2 + \\frac{1}{b} \\sum_{i=1}^{N} \\sum_{j=1}^{K} |c_{ij}|\n$$\n\n**2. 尖峰-厚板高斯混合先验**\n\n每个元素 $c_{ij}$ 的先验是两个零均值高斯分布的混合：\n$$\np(c_{ij}) = (1-\\pi)\\,\\mathcal{N}(c_{ij}; 0, \\sigma_{s}^{2}) + \\pi\\,\\mathcal{N}(c_{ij}; 0, \\sigma_{0}^{2})\n$$\n其中，“尖峰”分量 $\\mathcal{N}(c_{ij}; 0, \\sigma_{0}^{2})$ 的方差 $\\sigma_{0}^{2}$ 较小，用于建模接近零的系数；而“厚板”分量 $\\mathcal{N}(c_{ij}; 0, \\sigma_{s}^{2})$ 的方差 $\\sigma_{s}^{2}$ 较大，用于建模非零系数。写出高斯概率密度函数(PDF)：\n$$\n\\mathcal{N}(c_{ij}; 0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma^2}\\right)\n$$\n单个元素的先验为：\n$$\np(c_{ij}) = (1-\\pi) \\frac{1}{\\sqrt{2\\pi\\sigma_{s}^2}} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{s}^2}\\right) + \\pi \\frac{1}{\\sqrt{2\\pi\\sigma_{0}^2}} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{0}^2}\\right)\n$$\n整个矩阵 $C$ 的对数先验是 $\\ln p(C) = \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln p(c_{ij})$。因此，负对数先验为：\n$$\n-\\ln p(C) = - \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln\\left( (1-\\pi) \\frac{1}{\\sqrt{2\\pi\\sigma_{s}^2}} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{s}^2}\\right) + \\pi \\frac{1}{\\sqrt{2\\pi\\sigma_{0}^2}} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{0}^2}\\right) \\right)\n$$\n我们可以从对数内的项中提出因子 $\\frac{1}{\\sqrt{2\\pi}}$。产生的 $\\ln(1/\\sqrt{2\\pi})$ 可以作为一个加性常数被舍去。负对数先验项变为：\n$$\n-\\ln p(C) = - \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln\\left( \\frac{1-\\pi}{\\sigma_s} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{s}^2}\\right) + \\frac{\\pi}{\\sigma_0} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{0}^2}\\right) \\right) + \\text{constant}\n$$\n与负对数似然结合，尖峰-厚板先验的 MAP 目标函数为：\n$$\nJ_2(C) = \\frac{1}{2} \\sum_{t=1}^{T} \\sum_{i=1}^{N} \\frac{1}{R_{ii}} \\left(y_{it} - \\sum_{j=1}^{K} c_{ij} x_{jt}\\right)^2 - \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln\\left( \\frac{1-\\pi}{\\sigma_s} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{s}^2}\\right) + \\frac{\\pi}{\\sigma_0} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{0}^2}\\right) \\right)\n$$\n\n**稀疏载荷的可解释性**\n\n在神经元集群分析的背景下，载荷矩阵 $C \\in \\mathbb{R}^{N \\times K}$ 将 $N$ 个观测到的神经元与 $K$ 个未观测到的潜在因子联系起来。元素 $c_{ij}$ 量化了神经元 $i$ 在潜在因子 $j$ 中的参与强度。一个潜在因子代表了整个神经元集群的一种协同波动模式，据推测它对应于一个特定的计算或认知过程。\n\n如果 $C$ 是一个稠密矩阵，几乎每个神经元都会参与到每个潜在因子中。这使得解释任何单个因子的功能角色变得极其困难，因为它的活动反映了来自大量神经元的输入的复杂组合。类似地，单个神经元的活动是来自所有因子影响的混合体。\n\n对 $C$ 施加稀疏性会迫使许多 $c_{ij}$ 元素为零或可忽略不计。这会产生一个更具可解释性的结构：\n1.  **以因子为中心的视角：** 每个潜在因子（$C$ 的一列）都与一个小的、特定的神经元子集（那些具有非零载荷的神经元）相关联。这使得科学家能够将该因子解释为一个可识别的神经元集合或“细胞集合”的协同活动。然后，研究人员可以研究这个神经元子集的共同属性（例如，它们的解剖位置、调谐特性或投射目标）来理解该因子的功能。\n2.  **以神经元为中心的视角：** 每个神经元（$C$ 的一行）只参与少数几个，或者可能只有一个潜在因子。这表明神经元的活动，除了其自身的变异性外，仅受少数共享的认知或网络状态的调制，从而简化了该神经元在更广泛回路中功能作用的模型。\n\n总之，稀疏性为神经元与潜在集群动力学之间的关系提供了一个简约的描述，将一个数学上抽象的分解转变为一个科学上可解释的神经回路组织模型。拉普拉斯先验和尖峰-厚板先验是实现这种稀疏性的两种有原则的统计机制。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2} \\sum_{t=1}^{T} \\sum_{i=1}^{N} \\frac{1}{R_{ii}} \\left(y_{it} - \\sum_{j=1}^{K} c_{ij} x_{jt}\\right)^2 + \\frac{1}{b} \\sum_{i=1}^{N} \\sum_{j=1}^{K} |c_{ij}|,  \\frac{1}{2} \\sum_{t=1}^{T} \\sum_{i=1}^{N} \\frac{1}{R_{ii}} \\left(y_{it} - \\sum_{j=1}^{K} c_{ij} x_{jt}\\right)^2 - \\sum_{i=1}^{N} \\sum_{j=1}^{K} \\ln\\left( \\frac{1-\\pi}{\\sigma_s} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{s}^2}\\right) + \\frac{\\pi}{\\sigma_0} \\exp\\left(-\\frac{c_{ij}^2}{2\\sigma_{0}^2}\\right) \\right) \\end{pmatrix}}\n$$"
        }
    ]
}