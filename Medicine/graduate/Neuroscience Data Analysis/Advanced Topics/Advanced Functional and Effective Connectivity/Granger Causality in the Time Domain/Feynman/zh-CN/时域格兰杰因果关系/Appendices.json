{
    "hands_on_practices": [
        {
            "introduction": "时间域格兰杰因果分析的标准方法是基于向量自回归（Vector Autoregression, VAR）模型的参数检验。这个实践的核心是推导用于检验格兰杰因果零假设的 $F$ 统计量。通过从嵌套模型比较的基本原理出发，您将巩固对假设检验背后统计理论的理解，这对于正确应用和解释格兰杰因果分析结果至关重要 。",
            "id": "4166697",
            "problem": "考虑两个同时记录的神经时间序列 $x_t$ 和 $y_t$ (对于 $t=1,\\dots,T$)，由一个p阶二元向量自回归 (VAR) 模型建模，其中 $y_t$ 的方程为\n$$\ny_t \\;=\\; a_0 \\;+\\; \\sum_{i=1}^{p} a_i\\,y_{t-i} \\;+\\; \\sum_{i=1}^{p} b_i\\,x_{t-i} \\;+\\; \\varepsilon_t,\n$$\n而 $x_t$ 的方程有类似的设定，但对于关于 $y_t$ 的假设并非直接需要。假设在估计中 $t$ 的取值范围为 $p+1$ 到 $T$，因此有 $N = T - p$ 个可用的观测值，设计矩阵具有满列秩，并且新息项 $\\varepsilon_t$ 是独立同分布的，服从均值为 $0$、方差为 $\\sigma^2$ 的高斯分布。您希望检验从 $x_t$ 到 $y_t$ 不存在格兰杰因果关系的原假设，这对应于 $H_0: b_1=\\cdots=b_p=0$，其备择假设为至少有一个 $b_i \\neq 0$。使用普通最小二乘法 (OLS) 在无约束模型（包含 $x_t$ 的 $p$ 个滞后项）和有约束模型（不包含 $x_t$ 的 $p$ 个滞后项）下对 $y_t$ 的方程进行拟合，并令 $RSS_u$ 和 $RSS_r$ 分别表示来自无约束和有约束 $y_t$ 回归的残差平方和。\n\n从经典线性模型假设和 $H_0$ 下的平方和分布出发，用 $RSS_u$、$RSS_r$、$p$ 和 $N$ 推导检验 $H_0$ 的 $F$ 统计量。然后，用 $p$ 和 $N$ 指明在 $H_0$ 下相应 $F$ 分布的分子和分母自由度。\n\n将您的最终答案表示为 $F$ 统计量及其分子和分母自由度的单个解析表达式，以行矩阵的形式报告。不需要进行数值计算或四舍五入。",
            "solution": "该问题要求推导在一个多元回归模型中检验一组线性约束的 $F$ 统计量。其框架是经典线性模型，其中 $y_t$ 方程的参数使用普通最小二乘法 (OLS) 进行估计。\n\n首先，我们定义无约束模型和有约束模型。\n\n**无约束模型**由下式给出：\n$$\ny_t \\;=\\; a_0 \\;+\\; \\sum_{i=1}^{p} a_i\\,y_{t-i} \\;+\\; \\sum_{i=1}^{p} b_i\\,x_{t-i} \\;+\\; \\varepsilon_t\n$$\n这是一个线性回归模型。我们必须计算待估计参数的数量。有一个截距项 ($a_0$)，$p$ 个关于 $y_t$ 滞后项的参数 ($a_1, \\ldots, a_p$)，以及 $p$ 个关于 $x_t$ 滞后项的参数 ($b_1, \\ldots, b_p$)。无约束模型中回归系数的总数为 $k_u = 1 + p + p = 1 + 2p$。\n该回归基于 $N = T-p$ 个观测值进行。此模型的残差平方和记为 $RSS_u$。\n\n**有约束模型**是在原假设 $H_0: b_1 = \\cdots = b_p = 0$ 下设定的。将这些约束施加于无约束模型，得到：\n$$\ny_t \\;=\\; a_0 \\;+\\; \\sum_{i=1}^{p} a_i\\,y_{t-i} \\;+\\; \\varepsilon_t\n$$\n在此模型中，回归系数的数量为 $k_r = 1 + p$（一个截距项和 $p$ 个关于 $y_t$ 滞后项的参数）。此模型的残差平方和记为 $RSS_r$。\n\n原假设对无约束模型的参数施加了一组线性约束。约束的数量（记为 $q$）是设为零的系数个数。在本例中，我们检验 $p$ 个约束（$b_1=0, \\ldots, b_p=0$），因此 $q=p$。注意，$q = k_u - k_r = (1+2p) - (1+p) = p$，符合预期。\n\n检验线性约束的 F 检验的一般原理是基于对有约束模型和无约束模型的残差平方和的比较。在经典线性模型假设下（包括误差项 $\\varepsilon_t$ 是独立同分布的 $N(0, \\sigma^2)$ 这一假设），以下统计结果在原假设 $H_0$ 下成立：\n\n1.  来自无约束模型的归一化残差平方和服从卡方分布：\n    $$\n    \\frac{RSS_u}{\\sigma^2} \\sim \\chi^2_{(N - k_u)}\n    $$\n    其自由度为观测值数量 $N$ 减去无约束模型中的参数数量 $k_u$。在我们的例子中，自由度为 $N - (1+2p)$。\n\n2.  残差平方和的归一化差值也服从卡方分布：\n    $$\n    \\frac{RSS_r - RSS_u}{\\sigma^2} \\sim \\chi^2_{(q)}\n    $$\n    其自由度等于约束的数量 $q$。在我们的例子中，自由度为 $p$。一个已知的结果是 $RSS_r \\geq RSS_u$，因为无约束模型在更大的参数空间上最小化了误差平方和。\n\n3.  两个随机变量 $\\frac{RSS_u}{\\sigma^2}$ 和 $\\frac{RSS_r - RSS_u}{\\sigma^2}$ 在统计上是独立的。\n\n一个服从 F 分布的随机变量定义为两个独立的卡方变量分别除以其各自自由度后的比值。用于检验 $H_0$ 的 $F$ 统计量构造如下：\n$$\nF = \\frac{(\\text{Normalized difference in RSS}) / (\\text{Numerator df})}{(\\text{Normalized RSS from unrestricted model}) / (\\text{Denominator df})} = \\frac{ \\left( \\frac{RSS_r - RSS_u}{\\sigma^2} \\right) / q }{ \\left( \\frac{RSS_u}{\\sigma^2} \\right) / (N - k_u) }\n$$\n未知的误差方差 $\\sigma^2$ 可以方便地从分子和分母中约去：\n$$\nF = \\frac{ (RSS_r - RSS_u) / q }{ RSS_u / (N - k_u) }\n$$\n现在我们代入为此问题推导出的 $q$ 和 $k_u$ 的具体值：\n-   约束数量：$q = p$。\n-   无约束模型中的参数数量：$k_u = 1 + 2p$。\n\n将这些值代入 $F$ 统计量的公式，得到：\n$$\nF = \\frac{ (RSS_r - RSS_u) / p }{ RSS_u / (N - (1 + 2p)) } = \\frac{ (RSS_r - RSS_u) / p }{ RSS_u / (N - 1 - 2p) }\n$$\n在原假设 $H_0$ 下，该统计量服从一个 $F$ 分布。该分布的自由度由分子和分母中的卡方变量的自由度决定。\n-   **分子自由度**是 $q = p$。\n-   **分母自由度**是 $N - k_u = N - 1 - 2p$。\n\n因此，在 $H_0$ 下，检验统计量 $F$ 服从 $F_{p, N-1-2p}$ 分布。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{(RSS_r - RSS_u)/p}{RSS_u / (N - 1 - 2p)}  & p & N - 1 - 2p\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "尽管参数化的 $F$ 检验很常用，但它依赖于模型残差是独立同分布高斯白噪声等严格假设，而真实神经数据往往不满足这些条件。本实践介绍了一种强大的非参数替代方法：使用代理数据（surrogate data）构建零分布 。您将通过实现相位随机化来生成代理时间序列，这种方法在保留每个序列自相关结构的同时，破坏了它们之间的交叉滞后关系，从而为格兰杰因果统计量提供了一个经验的、更可靠的零分布。",
            "id": "4166692",
            "problem": "给定两个同时记录的神经时间序列，它们被建模为一个二元线性弱平稳过程。目标是在时域中检验一个时间序列 $x_t$ 是否“格兰杰因果”于另一个时间序列 $y_t$，同时通过保留单变量自相关但破坏交叉滞后依赖的相位随机化代理数据来构建一个有效的零分布。您的任务是设计并实现一个程序，对于每个提供的测试用例，该程序能够模拟数据，计算从 $x_t$ 到 $y_t$ 的时域格兰杰因果统计量，使用对每个序列进行独立相位随机化的方法构建一个基于代理数据的零分布，并最终输出一个布尔值，指示观测到的统计量是否超过零分布的第 $95$ 百分位数。\n\n基本原理：\n- 一个平稳线性过程的二阶结构由其自协方差和功率谱密度来表征。根据 Wiener–Khinchin 定理，自协方差函数是功率谱密度的傅里叶逆变换。对于一个有限的、实值的离散时间信号，保留每个单变量序列的离散傅里叶变换的幅值，就可以保留其周期图以及相关的二阶自相关结构。\n- 时域中的格兰杰因果定义如下：当且仅当 $x_t$ 的过去值提供了超出仅由 $y_t$ 的过去值所能捕获的关于 $y_t$ 的预测信息时，$x_t$ 格兰杰因果于 $y_t$。这可以通过使用普通最小二乘法（OLS）进行嵌套线性回归比较来评估。\n\n您必须实现以下组件：\n- 模拟一个阶数为 $p$ 的二元向量自回归（VAR）模型（Vector Autoregression (VAR)），该模型具有高斯新息：\n  $$ x_t = a^{(x)}_1 x_{t-1} + a^{(x)}_2 x_{t-2} + \\varepsilon^{(x)}_t, \\quad y_t = a^{(y)}_1 y_{t-1} + a^{(y)}_2 y_{t-2} + b_1 x_{t-1} + b_2 x_{t-2} + \\varepsilon^{(y)}_t, $$\n  其中 $t$ 是离散时间样本的索引，$\\varepsilon^{(x)}_t$ 和 $\\varepsilon^{(y)}_t$ 是均值为零、方差为单位的独立高斯新息，而 $(a^{(x)}_1,a^{(x)}_2,a^{(y)}_1,a^{(y)}_2,b_1,b_2)$ 是为确保稳定性而选择的模型系数。在收集 $T$ 个样本进行分析之前，使用 $B$ 个样本的“预烧期”（burn-in）以达到平稳状态。所有时间索引和计数均为整数，在测试套件中 $p=2$。\n- 为每个单变量时间序列独立生成相位随机化代理数据：\n  1. 对长度为 $T$ 的序列计算实值快速傅里叶变换（FFT）（Fast Fourier Transform (FFT)），通过实数FFT获得非负频率系数。\n  2. 保留幅值谱并独立地随机化相位，方法是为所有非直流（non-DC）、非奈奎斯特（non-Nyquist）频率从 $[0,2\\pi)$ 中均匀抽取角度，同时通过使用实数傅里叶逆变换（real inverse FFT）强制执行厄米对称性，以重建一个实值代理数据。\n  3. 对 $x_t$ 和 $y_t$ 独立重复此过程，以破坏交叉滞后依赖关系，同时保留每个序列的自相关结构。\n- 使用 OLS 计算从 $x_t$ 到 $y_t$ 的时域格兰杰因果统计量：\n  1. 仅使用 $y_{t-1},y_{t-2},\\dots,y_{t-p}$ 来预测 $y_t$ 以构建受限模型，并计算其残差平方和。\n  2. 使用 $y_{t-1},\\dots,y_{t-p}$ 和 $x_{t-1},\\dots,x_{t-p}$ 来预测 $y_t$ 以构建非受限模型，并计算其残差平方和。\n  3. 使用嵌套模型比较框架计算一个标量检验统计量，当添加 $x$ 的滞后项显著改善了对 $y_t$ 的预测（超出仅使用 $y$ 滞后项的预测效果）时，该统计量会增加。\n- 零分布构建：\n  1. 使用上述相位随机化程序生成 $S$ 个独立的代理数据对 $(\\tilde{x}^{(s)}_t,\\tilde{y}^{(s)}_t)$。\n  2. 为每个代理数据对计算相同的格兰杰因果统计量，从而在交叉滞后依赖被破坏但单变量自相关被保留的条件下，获得该统计量的代理零分布。\n  3. 确定代理分布的第 $95$ 百分位数，并将原始统计量与此阈值进行比较，以产生一个指示显著性的布尔决策。\n\n实现约束：\n- 使用带有确定性设计矩阵的普通最小二乘法。\n- 在拟合模型之前对序列进行去均值处理；不要包含截距项。\n- 使用固定的随机种子以确保可复现性。\n\n测试套件：\n对于所有测试用例，使用 $p=2$，预烧期 $B=200$ 个样本， $S=200$ 个代理数据，以及方差为单位的独立高斯新息，随机种子固定为 $1$。\n\n- 测试用例 1（理想路径，强耦合）：$T=1024$，系数 $a^{(x)}_1=0.5, a^{(x)}_2=-0.2, a^{(y)}_1=0.4, a^{(y)}_2=-0.3, b_1=0.35, b_2=0.0$。\n- 测试用例 2（零耦合）：$T=1024$，系数 $a^{(x)}_1=0.5, a^{(x)}_2=-0.2, a^{(y)}_1=0.4, a^{(y)}_2=-0.3, b_1=0.0, b_2=0.0$。\n- 测试用例 3（边界情况，短记录）：$T=128$，系数 $a^{(x)}_1=0.5, a^{(x)}_2=-0.2, a^{(y)}_1=0.3, a^{(y)}_2=-0.2, b_1=0.45, b_2=0.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含三个测试用例的显著性决策，格式为以逗号分隔的、用方括号括起来的 Python 风格布尔值列表（例如，$[True,False,True]$）。",
            "solution": "用户的问题经过严格验证，被认为是科学上合理、定义明确且客观的。它描述了一个用于非参数格兰杰因果分析的标准且完整的程序，这是神经科学和时间序列分析中的一个常见任务。所有必要的参数、模型和约束都已提供，其潜在的理论基础也得到了正确陈述。因此，我们可以着手提供一个完整的解决方案。\n\n核心目标是确定一个时间序列 $x_t$ 是否对另一个时间序列 $y_t$ 具有预测性的因果影响，这个概念由 Clive Granger 正式提出。所指定的方法包括拟合一个阶数为 $p$ 的二元向量自回归（VAR）模型，基于嵌套模型比较计算一个统计量，并根据由相位随机化代理数据构建的零分布来评估其显著性。\n\n### 1. 向量自回归（VAR）模型模拟\n\n我们首先从一个二元 VAR($p$) 过程中模拟数据。对于此问题，阶数固定为 $p=2$。模型方程如下：\n$$\nx_t = a^{(x)}_1 x_{t-1} + a^{(x)}_2 x_{t-2} + \\varepsilon^{(x)}_t\n$$\n$$\ny_t = a^{(y)}_1 y_{t-1} + a^{(y)}_2 y_{t-2} + b_1 x_{t-1} + b_2 x_{t-2} + \\varepsilon^{(y)}_t\n$$\n在这里，$\\varepsilon^{(x)}_t$ 和 $\\varepsilon^{(y)}_t$ 是从标准正态分布 $\\mathcal{N}(0, 1)$ 中抽取的独立同分布（i.i.d.）随机变量。系数 $b_1$ 和 $b_2$ 代表过去 $x_t$ 对当前 $y_t$ 的直接影响。该过程总共模拟 $T+B$ 个时间步，其中 $B$ 是预烧期，以使系统接近其平稳分布。前 $B$ 个样本被丢弃，得到两个长度均为 $T$ 的时间序列 $x_t$ 和 $y_t$。最后，根据问题的约束，通过减去各自的样本均值对两个序列进行去均值处理。\n\n### 2. 时域格兰杰因果统计量\n\n格兰杰因果假设，如果 $x_t$ 的过去值包含了有助于预测 $y_t$ 的信息，且这些信息超出了仅由 $y_t$ 过去值所包含的信息，那么 $x_t$ 就“因果”于 $y_t$。这通过使用普通最小二乘法（OLS）比较两个嵌套的线性回归模型来检验。\n\n**受限模型：** 仅使用 $y_t$ 自身直至滞后 $p$ 的过去值来预测 $y_t$。\n$$\ny_t = \\sum_{j=1}^{p} \\alpha_j y_{t-j} + \\eta_t\n$$\n我们将此模型拟合到 $t \\in [p, T-1]$ 的数据，这提供了 $N = T-p$ 个观测值。设此模型的设计矩阵为 $\\mathbf{X}_{\\text{restr}} \\in \\mathbb{R}^{N \\times p}$，目标向量为 $\\mathbf{y}_{\\text{target}} \\in \\mathbb{R}^{N}$。系数的 OLS 解为 $\\hat{\\boldsymbol{\\alpha}} = (\\mathbf{X}_{\\text{restr}}^T \\mathbf{X}_{\\text{restr}})^{-1} \\mathbf{X}_{\\text{restr}}^T \\mathbf{y}_{\\text{target}}$。残差为 $\\hat{\\boldsymbol{\\eta}} = \\mathbf{y}_{\\text{target}} - \\mathbf{X}_{\\text{restr}} \\hat{\\boldsymbol{\\alpha}}$，其残差平方和为 $RSS_{\\text{restr}} = \\sum_{t=p}^{T-1} \\hat{\\eta}_t^2$。\n\n**非受限模型：** 使用 $y_t$ 自身的过去值和 $x_t$ 的过去值来预测 $y_t$。\n$$\ny_t = \\sum_{j=1}^{p} \\alpha'_j y_{t-j} + \\sum_{j=1}^{p} \\beta_j x_{t-j} + \\xi_t\n$$\n此模型拟合到相同的 $N = T-p$ 个观测值。设计矩阵 $\\mathbf{X}_{\\text{unrestr}} \\in \\mathbb{R}^{N \\times 2p}$ 现在包括 $x_t$ 和 $y_t$ 的滞后版本。OLS 拟合产生残差 $\\hat{\\boldsymbol{\\xi}}$ 和相应的残差平方和 $RSS_{\\text{unrestr}} = \\sum_{t=p}^{T-1} \\hat{\\xi}_t^2$。\n\n非受限模型对数据的拟合效果总是至少与受限模型一样好，因此 $RSS_{\\text{unrestr}} \\le RSS_{\\text{restr}}$。当包含 $x_t$ 项时，$RSS$ 的显著下降表明 $x_t$ 增加了预测能力。一个量化这种改善的常用统计量是残差平方和之比的对数：\n$$\nG_{x \\to y} = \\ln \\left( \\frac{RSS_{\\text{restr}}}{RSS_{\\text{unrestr}}} \\right)\n$$\n该统计量是非负的，并随着 $x_t$ 的预测贡献的增长而增加。\n\n### 3. 使用相位随机化代理数据进行零假设检验\n\n为了确定观测到的 $G_{x \\to y}$ 值是否具有统计显著性，我们将其与一个零分布进行比较。零假设 $H_0$ 是 $x_t$ 不格兰杰因果于 $y_t$。一种在 $H_0$ 下生成数据的强大非参数方法是创建代理时间序列，这些序列保留了原始数据中与假设无关的属性，同时破坏了正在被检验的属性。\n\n在这里，我们希望破坏 $x_t$ 和 $y_t$ 之间的任何交叉滞后依赖关系，同时保留每个序列各自的自相关结构（也就是功率谱）。这通过在傅里叶域中进行相位随机化来实现。对于一个长度为 $T$ 的时间序列 $z_t$，其过程如下：\n\n1.  **傅里叶变换：** 计算实值序列 $z_t$ 的离散傅里叶变换（DFT），通常使用实值快速傅里叶变换（FFT）算法，得到复系数 $\\hat{z}[k]$。\n    $$\n    \\hat{z}[k] = |\\hat{z}[k]| e^{i\\theta_k}\n    $$\n2.  **相位随机化：** 通过从均匀分布 $U[0, 2\\pi)$ 中抽样，生成一组新的相位 $\\phi_k$。通过将原始幅值与新的随机相位结合，构建新的傅里叶系数 $\\hat{z}_{\\text{surr}}[k]$。\n    $$\n    \\hat{z}_{\\text{surr}}[k] = |\\hat{z}[k]| e^{i\\phi_k}\n    $$\n    为确保生成的代理时间序列是实值的，必须遵守特定的对称性。直流分量（$k=0$）和奈奎斯特分量（如果 $T$ 为偶数，则在 $k=T/2$ 处）的相位必须为零。对于所有其他正频率 $k$，其对应负频率的相位必须为 $\\phi_{-k} = -\\phi_k$。使用实数 FFT 及其逆变换（`rfft`，`irfft`）会隐式处理这些对称性。我们只需将直流和奈奎斯特频率的相位显式设置为零。根据 Wiener-Khinchin 定理，保留幅值谱 $|\\hat{z}[k]|$ 等同于保留功率谱密度，从而保留序列的自协方差函数。\n\n3.  **傅里叶逆变换：** 计算 $\\hat{z}_{\\text{surr}}[k]$ 的离散傅里叶逆变换，以获得实值代理时间序列 $\\tilde{z}_t$。\n\n此过程独立应用于 $x_t$ 和 $y_t$，以创建一对代理数据 $(\\tilde{x}_t, \\tilde{y}_t)$。由于对每个序列的相位随机化是独立的，它们之间任何系统的相位/滞后关系都被破坏了。通过重复此过程 $S$ 次，我们生成 $S$ 对代理数据。对于每一对，我们计算格兰杰因果统计量 $G^{\\text{surr}}_{x \\to y}$。这 $S$ 个值的集合构成了一个经验零分布。\n\n### 4. 统计决策\n\n从原始数据计算出的观测统计量 $G^{\\text{obs}}_{x \\to y}$ 与零分布进行比较。问题指定了 $\\alpha = 0.05$ 的显著性水平。我们找到代理分布的第 $95$ 百分位数，它作为临界值或阈值。如果观测统计量超过此阈值，我们拒绝零假设，并得出从 $x_t$ 到 $y_t$ 的格兰杰因果关系具有统计显著性的结论。\n$$\n\\text{Decision} = (G^{\\text{obs}}_{x \\to y} > \\text{percentile}( \\{G^{\\text{surr}}\\}_{s=1}^S, 95 ))\n$$\n然后，对问题陈述中定义的每个测试用例重复这整个过程。",
            "answer": "```python\nimport numpy as np\nfrom numpy.linalg import lstsq\nfrom numpy.fft import rfft, irfft\n\ndef simulate_var(T, B, coeffs, p, rng):\n    \"\"\"\n    Simulates a bivariate VAR(p) process.\n    \"\"\"\n    total_len = T + B\n    x = np.zeros(total_len)\n    y = np.zeros(total_len)\n    \n    # Generate innovations for the entire series at once\n    innovations = rng.standard_normal(size=(2, total_len))\n    \n    # Coefficients\n    ax1, ax2 = coeffs['ax1'], coeffs['ax2']\n    ay1, ay2 = coeffs['ay1'], coeffs['ay2']\n    b1, b2 = coeffs['b1'], coeffs['b2']\n    \n    # Time-stepping loop\n    for t in range(p, total_len):\n        x[t] = ax1 * x[t-1] + ax2 * x[t-2] + innovations[0, t]\n        y[t] = ay1 * y[t-1] + ay2 * y[t-2] + b1 * x[t-1] + b2 * x[t-2] + innovations[1, t]\n        \n    # Discard burn-in period\n    x_final = x[B:]\n    y_final = y[B:]\n    \n    return x_final, y_final\n\ndef generate_phase_randomized_surrogate(z, rng):\n    \"\"\"\n    Generates a phase-randomized surrogate preserving the power spectrum.\n    \"\"\"\n    T = len(z)\n    ft = rfft(z)\n    mags = np.abs(ft)\n    \n    # Generate random phases\n    phases = rng.uniform(0, 2 * np.pi, len(ft))\n    \n    # Set DC and Nyquist phases to 0 for a real-valued signal\n    phases[0] = 0\n    if T % 2 == 0:\n        phases[-1] = 0\n        \n    # Create new Fourier coefficients with original magnitudes and random phases\n    new_ft = mags * np.exp(1j * phases)\n    \n    # Inverse FFT to get the surrogate time series\n    surrogate = irfft(new_ft, n=T)\n    \n    return surrogate\n\ndef calculate_gc_stat(x, y, p):\n    \"\"\"\n    Calculates the time-domain Granger causality statistic from x to y.\n    \"\"\"\n    T = len(x)\n    n_obs = T - p\n    \n    # Construct the target vector y[t] for t=p,...,T-1\n    y_target = y[p:]\n\n    # Restricted model: y_t = f(y_{t-1}, ..., y_{t-p})\n    X_restr_cols = [y[p-k:T-k] for k in range(1, p + 1)]\n    X_restr = np.column_stack(X_restr_cols)\n    \n    # Solve OLS and compute residual sum of squares\n    beta_restr, _, _, _ = lstsq(X_restr, y_target, rcond=None)\n    residuals_restr = y_target - X_restr @ beta_restr\n    rss_restr = np.sum(residuals_restr**2)\n\n    # Unrestricted model: y_t = f(y_{t-1}, ..., y_{t-p}, x_{t-1}, ..., x_{t-p})\n    X_unrestr_cols = [y[p-k:T-k] for k in range(1, p + 1)] + \\\n                     [x[p-k:T-k] for k in range(1, p + 1)]\n    X_unrestr = np.column_stack(X_unrestr_cols)\n    \n    # Solve OLS and compute residual sum of squares\n    beta_unrestr, _, _, _ = lstsq(X_unrestr, y_target, rcond=None)\n    residuals_unrestr = y_target - X_unrestr @ beta_unrestr\n    rss_unrestr = np.sum(residuals_unrestr**2)\n    \n    # Avoid division by zero or log of non-positive\n    if rss_unrestr = 1e-10:\n        return 0.0\n\n    gc_stat = np.log(rss_restr / rss_unrestr)\n    \n    return gc_stat\n\ndef run_granger_test(T, B, S, p, coeffs, rng):\n    \"\"\"\n    Runs the full Granger causality test for a single case.\n    \"\"\"\n    # 1. Simulate data and demean\n    x_sim, y_sim = simulate_var(T, B, coeffs, p, rng)\n    x = x_sim - np.mean(x_sim)\n    y = y_sim - np.mean(y_sim)\n    \n    # 2. Compute observed Granger causality statistic\n    original_gc = calculate_gc_stat(x, y, p)\n    \n    # 3. Build null distribution from surrogates\n    surrogate_stats = []\n    for _ in range(S):\n        # Generate independent surrogates\n        x_surr = generate_phase_randomized_surrogate(x, rng)\n        y_surr = generate_phase_randomized_surrogate(y, rng)\n        \n        # Demean surrogates to match original data preprocessing\n        x_surr_demeaned = x_surr - np.mean(x_surr)\n        y_surr_demeaned = y_surr - np.mean(y_surr)\n        \n        gc_surr = calculate_gc_stat(x_surr_demeaned, y_surr_demeaned, p)\n        surrogate_stats.append(gc_surr)\n        \n    # 4. Perform the hypothesis test against the 95th percentile\n    threshold = np.percentile(surrogate_stats, 95)\n    is_significant = original_gc > threshold\n    \n    return is_significant\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Global parameters\n    SEED = 1\n    P = 2\n    B = 200\n    S = 200\n    \n    # Test suite\n    test_cases = [\n        # Case 1: Strong coupling\n        {'T': 1024, 'coeffs': {'ax1': 0.5, 'ax2': -0.2, 'ay1': 0.4, 'ay2': -0.3, 'b1': 0.35, 'b2': 0.0}},\n        # Case 2: Null coupling\n        {'T': 1024, 'coeffs': {'ax1': 0.5, 'ax2': -0.2, 'ay1': 0.4, 'ay2': -0.3, 'b1': 0.0, 'b2': 0.0}},\n        # Case 3: Boundary case, short record\n        {'T': 128, 'coeffs': {'ax1': 0.5, 'ax2': -0.2, 'ay1': 0.3, 'ay2': -0.2, 'b1': 0.45, 'b2': 0.0}}\n    ]\n\n    # Initialize a single random number generator for reproducibility\n    rng = np.random.default_rng(SEED)\n    results = []\n\n    for case in test_cases:\n        # The RNG state advances with each call, ensuring simulations are \n        # independent across test cases while the whole process remains deterministic.\n        is_significant = run_granger_test(case['T'], B, S, P, case['coeffs'], rng)\n        results.append(is_significant)\n    \n    # Format and print the final output exactly as specified\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}