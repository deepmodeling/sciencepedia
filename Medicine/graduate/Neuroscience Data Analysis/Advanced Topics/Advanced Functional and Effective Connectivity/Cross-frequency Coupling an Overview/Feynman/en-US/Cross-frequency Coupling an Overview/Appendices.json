{
    "hands_on_practices": [
        {
            "introduction": "Before any sophisticated analysis can begin, we must ensure our data is captured with sufficient fidelity. This exercise grounds us in the first principles of digital signal processing, applying the Nyquist-Shannon Sampling Theorem to the specific demands of cross-frequency coupling analysis. By working through this problem , you will see how the spectral properties of the high-frequency amplitude envelope, not just the carrier frequency itself, dictate the minimum sampling rate required to prevent irreversible data loss from aliasing.",
            "id": "4151446",
            "problem": "You are designing a data acquisition system for analyzing cross-frequency coupling (CFC) between a low-frequency phase and a high-frequency amplitude in intracranial local field potential (LFP) recordings. The high-frequency component is narrowband with energy confined to the interval $[80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$, and its amplitude envelope is band-limited by physiology and preprocessing choices such that the envelope has no frequency components above $20\\,\\mathrm{Hz}$. The low-frequency phase is extracted from a band-limited signal with energy confined to the interval $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$. You will compute the minimum sampling rate required to accurately capture both the high-frequency amplitude envelope and the low-frequency phase.\n\nUse only the following fundamental bases:\n\n- The Nyquist–Shannon Sampling Theorem (NSST): any signal band-limited to a maximum frequency $f_{\\max}$ requires a sampling rate strictly greater than $2 f_{\\max}$ to avoid aliasing.\n- In amplitude modulation of a band-limited carrier $x(t)$ with center frequencies in a band $[f_{\\mathrm{H,low}}, f_{\\mathrm{H,high}}]$ by a band-limited envelope $a(t)$ confined to $[0, B_{\\mathrm{env}}]$, the spectrum of the modulated signal is confined within sidebands whose highest frequency does not exceed $f_{\\mathrm{H,high}} + B_{\\mathrm{env}}$.\n\nAssume no other spectral content is present outside the stated bands, and that you will compute instantaneous phase and amplitude via analytic signal methods (e.g., Hilbert transform) after digital band-pass filtering, which cannot recover energy lost to aliasing in acquisition. Determine the minimum sampling rate that simultaneously satisfies the constraints implied by the low-frequency phase band and the high-frequency amplitude modulation sidebands. Express your final sampling rate in $\\mathrm{Hz}$. If you decide to round, round to four significant figures; otherwise, provide the exact value.",
            "solution": "The problem requires the determination of the minimum sampling rate, denoted as $f_s$, for a data acquisition system designed to analyze cross-frequency coupling in local field potential (LFP) recordings. The preservation of information for this analysis depends on acquiring the raw signal without aliasing, as subsequent digital filtering cannot recover information lost during sampling. The total signal contains multiple components, and the sampling rate must be sufficient to capture the highest frequency present across all of them.\n\nThe LFP signal is composed of two primary components of interest: a low-frequency component and a high-frequency component. To satisfy the Nyquist-Shannon Sampling Theorem (NSST) for the composite signal, we must first identify its maximum frequency, $f_{\\max}$. The NSST, as stated in the problem, requires that the sampling rate $f_s$ must be strictly greater than $2 f_{\\max}$.\n\nFirst, let's analyze the low-frequency component. Its energy is confined to the interval $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$. The maximum frequency for this part of the signal is therefore $f_{\\mathrm{L,max}} = 12\\,\\mathrm{Hz}$. To capture this component without aliasing, the sampling rate would need to satisfy $f_s > 2 \\times 12\\,\\mathrm{Hz} = 24\\,\\mathrm{Hz}$.\n\nNext, we analyze the high-frequency component. This component is described as a narrowband signal with carrier energy in the interval $[f_{\\mathrm{H,low}}, f_{\\mathrm{H,high}}] = [80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$. This carrier is amplitude-modulated by an envelope whose own spectral content is band-limited to a maximum frequency of $B_{\\mathrm{env}} = 20\\,\\mathrm{Hz}$. The problem provides the fundamental basis for the spectrum of such a modulated signal: the highest frequency of the resulting signal does not exceed $f_{\\mathrm{H,high}} + B_{\\mathrm{env}}$. This phenomenon is due to the process of modulation, which in the frequency domain corresponds to a convolution of the carrier spectrum with the envelope spectrum, creating upper and lower sidebands. The upper sideband extends the spectral content of the signal upwards.\n\nUsing the provided values, we can calculate the maximum frequency of this modulated high-frequency component, $f_{\\mathrm{H,max}}$:\n$$\nf_{\\mathrm{H,max}} = f_{\\mathrm{H,high}} + B_{\\mathrm{env}}\n$$\nSubstituting the given values:\n$$\nf_{\\mathrm{H,max}} = 150\\,\\mathrm{Hz} + 20\\,\\mathrm{Hz} = 170\\,\\mathrm{Hz}\n$$\nTo capture this high-frequency modulated component without aliasing, the sampling rate must satisfy $f_s > 2 \\times 170\\,\\mathrm{Hz} = 340\\,\\mathrm{Hz}$.\n\nThe data acquisition system samples the entire raw LFP signal, which is a superposition of all its components. Therefore, to prevent aliasing for the *entire* signal, the sampling rate must be chosen based on the absolute maximum frequency present in the signal. This maximum frequency, $f_{\\max}$, is the greater of the maximum frequencies of its constituent parts.\n$$\nf_{\\max} = \\max(f_{\\mathrm{L,max}}, f_{\\mathrm{H,max}})\n$$\n$$\nf_{\\max} = \\max(12\\,\\mathrm{Hz}, 170\\,\\mathrm{Hz}) = 170\\,\\mathrm{Hz}\n$$\nApplying the NSST to the entire signal, we have the condition:\n$$\nf_s > 2 f_{\\max}\n$$\n$$\nf_s > 2 \\times 170\\,\\mathrm{Hz}\n$$\n$$\nf_s > 340\\,\\mathrm{Hz}\n$$\nThe problem asks for the minimum sampling rate. This corresponds to the theoretical lower bound, or infimum, of the set of valid sampling rates, which is known as the Nyquist rate. Any sampling rate strictly greater than this value will prevent aliasing. The minimum required rate is therefore the boundary value of this inequality.\n$$\nf_{s,\\mathrm{min}} = 2 f_{\\max} = 340\\,\\mathrm{Hz}\n$$\nThis value is exact, so no rounding is necessary. This sampling rate ensures that both the low-frequency phase information (contained in the $[4\\,\\mathrm{Hz}, 12\\,\\mathrm{Hz}]$ band) and the high-frequency amplitude information (encoded in the sidebands of the $[80\\,\\mathrm{Hz}, 150\\,\\mathrm{Hz}]$ signal, extending up to $170\\,\\mathrm{Hz}$) can be recovered without distortion from aliasing during the initial acquisition.",
            "answer": "$$\\boxed{340}$$"
        },
        {
            "introduction": "A significant challenge in CFC analysis is distinguishing true neural interactions from methodological artifacts. This practice explores one of the most common sources of spurious coupling: spectral leakage from non-ideal filters. By deriving the correlation that arises when filtering pure noise , you will gain a crucial, quantitative understanding of how seemingly separate frequency bands can become artificially linked by the filtering process itself.",
            "id": "4151495",
            "problem": "Consider a zero-mean, wide-sense stationary neural field signal $x(t)$ with flat two-sided power spectral density (PSD) $S_{x}(f) = \\sigma^{2}$ for all real frequencies $f \\in \\mathbb{R}$. You analyze cross-frequency coupling (CFC) by extracting a low-frequency component and a high-frequency component using two real, zero-phase, linear time-invariant (LTI) bandpass filters. Let their magnitude responses be denoted by $H_{L}(f)$ (low-frequency) and $H_{H}(f)$ (high-frequency). Each filter has an ideal unity-gain passband of width $B$ and symmetric, linear transition bands of width $\\Delta$ on both sides of the passband, reaching zero gain outside the transition. Specifically, for the low-frequency filter,\n- $|H_{L}(f)| = 1$ for $f \\in [f_{L-}, f_{L+}]$ where $f_{L+} - f_{L-} = B_{L}$;\n- $|H_{L}(f)|$ decreases linearly from $1$ to $0$ as $f$ increases from $f_{L+}$ to $f_{L+} + \\Delta$;\n- $|H_{L}(f)|$ decreases linearly from $1$ to $0$ as $f$ decreases from $f_{L-}$ to $f_{L-} - \\Delta$;\nand analogously for the high-frequency filter with passband $[f_{H-}, f_{H+}]$ of width $B_{H}$ and transition width $\\Delta$.\n\nAssume the passbands do not overlap and that the only overlap between the two magnitude responses occurs between the upper transition band of the low-frequency filter and the lower transition band of the high-frequency filter. Let this overlap interval be $[f_{L+}, f_{H-}]$ of length $\\ell = f_{H-} - f_{L+}$, with $0 < \\ell \\leq \\Delta$. The outputs are $y_{L}(t)$ and $y_{H}(t)$, obtained by filtering $x(t)$ with $H_{L}$ and $H_{H}$, respectively.\n\nStarting from the spectral representation of second-order moments for LTI-filtered stationary processes, derive the dependence of the variance and cross-covariance of $y_{L}(t)$ and $y_{H}(t)$ on the passband widths $B_{L}$ and $B_{H}$ and the transition width $\\Delta$, and then derive the Pearson correlation coefficient\n$$\\rho = \\frac{\\operatorname{Cov}(y_{L}, y_{H})}{\\sqrt{\\operatorname{Var}(y_{L}) \\operatorname{Var}(y_{H})}}$$\nas a function of $B_{L}$, $B_{H}$, $\\Delta$, and $\\ell$. Use your derivation to explain how nonzero overlap $\\ell$ embodies spectral leakage that can create spurious cross-band dependencies even when $x(t)$ has a flat PSD.\n\nFinally, evaluate your derived expression for $\\rho$ for the parameter values $B_{L} = 6\\,\\text{Hz}$, $B_{H} = 10\\,\\text{Hz}$, $\\Delta = 8\\,\\text{Hz}$, and $\\ell = 4\\,\\text{Hz}$. Express the final answer as a single exact analytical expression with no units and do not round.",
            "solution": "We begin from the principles of filtering wide-sense stationary (WSS) random processes. For a zero-mean WSS input signal $x(t)$ with a two-sided power spectral density (PSD) $S_x(f)$, the output $y(t)$ of a linear time-invariant (LTI) filter with transfer function $H(f)$ is also a zero-mean WSS process. The variance of the output is given by the total power, which is the integral of the output PSD, $S_y(f) = |H(f)|^2 S_x(f)$, over all frequencies:\n$$ \\operatorname{Var}(y) = \\int_{-\\infty}^{\\infty} S_y(f) \\, df = \\int_{-\\infty}^{\\infty} |H(f)|^2 S_x(f) \\, df $$\nFor two outputs, $y_L(t)$ and $y_H(t)$, generated by filtering the same input $x(t)$ with filters $H_L(f)$ and $H_H(f)$ respectively, their cross-covariance at zero lag is given by the integral of the cross-power spectral density $S_{y_L y_H}(f) = H_L(f) H_H^*(f) S_x(f)$:\n$$ \\operatorname{Cov}(y_L, y_H) = \\int_{-\\infty}^{\\infty} H_L(f) H_H^*(f) S_x(f) \\, df $$\nIn this problem, the input signal $x(t)$ has a flat PSD, $S_x(f) = \\sigma^2$. The filters are specified as real and zero-phase, which implies their transfer functions $H_L(f)$ and $H_H(f)$ are real and even functions of frequency, i.e., $H(f) = H(-f)$ and $H^*(f) = H(f)$. We can assume they are non-negative, so $H(f) = |H(f)|$. The formulas simplify to:\n$$ \\operatorname{Var}(y) = \\sigma^2 \\int_{-\\infty}^{\\infty} |H(f)|^2 \\, df $$\n$$ \\operatorname{Cov}(y_L, y_H) = \\sigma^2 \\int_{-\\infty}^{\\infty} |H_L(f)| |H_H(f)| \\, df $$\nSince the magnitude responses are even, we can write these as:\n$$ \\operatorname{Var}(y) = 2\\sigma^2 \\int_{0}^{\\infty} |H(f)|^2 \\, df $$\n$$ \\operatorname{Cov}(y_L, y_H) = 2\\sigma^2 \\int_{0}^{\\infty} |H_L(f)| |H_H(f)| \\, df $$\n\nFirst, we calculate the variance of $y_L(t)$. The filter response $|H_L(f)|$ for $f > 0$ is non-zero over three regions: the lower transition band $[f_{L-} - \\Delta, f_{L-}]$, the passband $[f_{L-}, f_{L+}]$, and the upper transition band $[f_{L+}, f_{L+} + \\Delta]$.\nThe integral of $|H_L(f)|^2$ over $f \\ge 0$ is the sum of integrals over these three regions:\n1.  Passband: $\\int_{f_{L-}}^{f_{L+}} 1^2 \\, df = f_{L+} - f_{L-} = B_L$.\n2.  Upper transition band: The response is $|H_L(f)| = 1 - \\frac{f - f_{L+}}{\\Delta}$.\n    $$ \\int_{f_{L+}}^{f_{L+}+\\Delta} \\left(1 - \\frac{f - f_{L+}}{\\Delta}\\right)^2 \\, df $$\n    Let $u = f - f_{L+}$. The integral becomes $\\int_{0}^{\\Delta} \\left(1 - \\frac{u}{\\Delta}\\right)^2 \\, du = \\left[-\\frac{\\Delta}{3}\\left(1 - \\frac{u}{\\Delta}\\right)^3\\right]_0^{\\Delta} = 0 - (-\\frac{\\Delta}{3}) = \\frac{\\Delta}{3}$.\n3.  Lower transition band: The response is $|H_L(f)| = 1 - \\frac{f_{L-} - f}{\\Delta}$.\n    $$ \\int_{f_{L-}-\\Delta}^{f_{L-}} \\left(1 - \\frac{f_{L-} - f}{\\Delta}\\right)^2 \\, df $$\n    Let $u = f_{L-} - f$. The integral becomes $\\int_{\\Delta}^{0} \\left(1 - \\frac{u}{\\Delta}\\right)^2 \\, (-du) = \\int_{0}^{\\Delta} \\left(1 - \\frac{u}{\\Delta}\\right)^2 \\, du = \\frac{\\Delta}{3}$.\n\nSumming these contributions, we get $\\int_0^{\\infty} |H_L(f)|^2 \\, df = B_L + \\frac{\\Delta}{3} + \\frac{\\Delta}{3} = B_L + \\frac{2\\Delta}{3}$.\nThe variance of $y_L(t)$ is thus:\n$$ \\operatorname{Var}(y_L) = 2\\sigma^2 \\left(B_L + \\frac{2\\Delta}{3}\\right) $$\nBy analogy, the variance of $y_H(t)$ is:\n$$ \\operatorname{Var}(y_H) = 2\\sigma^2 \\left(B_H + \\frac{2\\Delta}{3}\\right) $$\n\nNext, we calculate the cross-covariance $\\operatorname{Cov}(y_L, y_H)$. The problem states that for $f>0$, the only region where both $|H_L(f)|$ and $|H_H(f)|$ are non-zero is the interval $[f_{L+}, f_{H-}]$. The length of this interval is $\\ell = f_{H-} - f_{L+}$. In this interval, $|H_L(f)|$ is in its upper transition band and $|H_H(f)|$ is in its lower transition band.\nFor $f \\in [f_{L+}, f_{H-}]$:\n$$ |H_L(f)| = 1 - \\frac{f - f_{L+}}{\\Delta} $$\n$$ |H_H(f)| = 1 - \\frac{f_{H-} - f}{\\Delta} $$\nThe integral for the covariance calculation (for $f>0$) is:\n$$ \\int_0^{\\infty} |H_L(f)||H_H(f)| \\, df = \\int_{f_{L+}}^{f_{H-}} \\left(1 - \\frac{f - f_{L+}}{\\Delta}\\right) \\left(1 - \\frac{f_{H-} - f}{\\Delta}\\right) \\, df $$\nLet $t = f - f_{L+}$. The integration variable changes from $f$ to $t$, with limits from $0$ to $\\ell$. Then $f_{H-} - f = (f_{L+} + \\ell) - (t + f_{L+}) = \\ell - t$. The integral becomes:\n$$ \\int_0^{\\ell} \\left(1 - \\frac{t}{\\Delta}\\right) \\left(1 - \\frac{\\ell-t}{\\Delta}\\right) \\, dt = \\int_0^{\\ell} \\left( 1 - \\frac{\\ell}{\\Delta} + \\frac{\\ell t - t^2}{\\Delta^2} \\right) \\, dt $$\n$$ = \\left[ t - \\frac{\\ell t}{\\Delta} + \\frac{\\ell t^2}{2\\Delta^2} - \\frac{t^3}{3\\Delta^2} \\right]_0^{\\ell} $$\n$$ = \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{2\\Delta^2} - \\frac{\\ell^3}{3\\Delta^2} = \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2} $$\nThe total cross-covariance is twice this value due to the symmetric contribution from negative frequencies:\n$$ \\operatorname{Cov}(y_L, y_H) = 2\\sigma^2 \\left( \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2} \\right) $$\n\nNow we can derive the Pearson correlation coefficient $\\rho$:\n$$ \\rho = \\frac{\\operatorname{Cov}(y_L, y_H)}{\\sqrt{\\operatorname{Var}(y_L) \\operatorname{Var}(y_H)}} = \\frac{2\\sigma^2 \\left( \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2} \\right)}{\\sqrt{2\\sigma^2 \\left(B_L + \\frac{2\\Delta}{3}\\right) \\cdot 2\\sigma^2 \\left(B_H + \\frac{2\\Delta}{3}\\right)}} $$\n$$ \\rho = \\frac{\\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2}}{\\sqrt{\\left(B_L + \\frac{2\\Delta}{3}\\right) \\left(B_H + \\frac{2\\Delta}{3}\\right)}} $$\nThis expression shows that the correlation $\\rho$ depends on the passband widths $B_L$ and $B_H$, the transition width $\\Delta$, and the overlap length $\\ell$.\n\nThe derived expression for $\\rho$ illuminates how spectral leakage can induce spurious cross-frequency dependencies. The input signal $x(t)$ is white noise, which has no inherent correlation structure across frequencies. If the filters were ideal brick-wall filters ($\\Delta=0$) with non-overlapping passbands, their outputs would be uncorrelated, and $\\rho$ would be $0$. However, realistic filters have finite transition bands ($\\Delta > 0$). If these transition bands overlap ($\\ell > 0$), both filters respond to common frequency components of the input noise process in the overlap region. This shared input creates a non-zero covariance between the filter outputs, resulting in $\\rho > 0$. This mathematically demonstrates that an apparent coupling can emerge purely as an artifact of the filtering process, a critical consideration in the analysis of genuine neural cross-frequency coupling.\n\nFinally, we evaluate $\\rho$ for the specified parameters: $B_L = 6\\,\\text{Hz}$, $B_H = 10\\,\\text{Hz}$, $\\Delta = 8\\,\\text{Hz}$, and $\\ell = 4\\,\\text{Hz}$.\nNumerator:\n$$ \\ell - \\frac{\\ell^2}{\\Delta} + \\frac{\\ell^3}{6\\Delta^2} = 4 - \\frac{4^2}{8} + \\frac{4^3}{6(8^2)} = 4 - \\frac{16}{8} + \\frac{64}{6(64)} = 4 - 2 + \\frac{1}{6} = 2 + \\frac{1}{6} = \\frac{13}{6} $$\nDenominator terms:\n$$ B_L + \\frac{2\\Delta}{3} = 6 + \\frac{2(8)}{3} = 6 + \\frac{16}{3} = \\frac{18+16}{3} = \\frac{34}{3} $$\n$$ B_H + \\frac{2\\Delta}{3} = 10 + \\frac{2(8)}{3} = 10 + \\frac{16}{3} = \\frac{30+16}{3} = \\frac{46}{3} $$\nThe denominator is:\n$$ \\sqrt{\\left(\\frac{34}{3}\\right) \\left(\\frac{46}{3}\\right)} = \\sqrt{\\frac{34 \\times 46}{9}} = \\frac{\\sqrt{1564}}{3} $$\nWe factorize $1564$: $1564 = 4 \\times 391$. We find that $391=17 \\times 23$.\nThus, $\\sqrt{1564} = \\sqrt{4 \\times 17 \\times 23} = 2\\sqrt{391}$.\nThe denominator is $\\frac{2\\sqrt{391}}{3}$.\n\nThe correlation coefficient $\\rho$ is:\n$$ \\rho = \\frac{13/6}{2\\sqrt{391}/3} = \\frac{13}{6} \\times \\frac{3}{2\\sqrt{391}} = \\frac{13}{2 \\times 2\\sqrt{391}} = \\frac{13}{4\\sqrt{391}} $$",
            "answer": "$$\\boxed{\\frac{13}{4\\sqrt{391}}}$$"
        },
        {
            "introduction": "Observing a non-zero coupling value is not enough; we must determine if it is statistically meaningful or likely due to chance. This exercise delves into the heart of hypothesis testing for PAC by formalizing the null hypothesis through surrogate data. You will derive the expected null distribution for a standard PAC estimator under the assumption of no coupling , providing the theoretical backbone for the widely-used time-shift permutation tests that are essential for robust scientific inference.",
            "id": "4151462",
            "problem": "Consider a single-channel neural time series that has been bandpass filtered into a low-frequency component and a high-frequency component. Let the analytic phase of the low-frequency component be denoted by $\\phi_{L}(t)$ and the analytic amplitude envelope of the high-frequency component be denoted by $A_{H}(t)$, both sampled at $t = 1, 2, \\dots, N$. Phase–Amplitude Coupling (PAC) refers to statistical dependence between $A_{H}(t)$ and $\\phi_{L}(t)$. A common class of PAC estimators forms a complex mean vector whose magnitude quantifies coupling.\n\nConstruct a time-shift surrogate by drawing an integer $s$ uniformly from $\\{0, 1, \\dots, N-1\\}$ and circularly shifting $A_{H}(t)$ relative to $\\phi_{L}(t)$ to obtain $\\tilde{A}_{H}(t) = A_{H}((t + s) \\bmod N)$. Define the coupling estimator as the magnitude of the complex mean vector\n$$\nR_{N} = \\left|\\frac{1}{N} \\sum_{t=1}^{N} \\tilde{A}_{H}(t) \\exp\\!\\left(i \\,\\phi_{L}(t)\\right)\\right|.\n$$\nAssume the following stationarity conditions hold over the analysis window: both $\\{A_{H}(t)\\}$ and $\\{\\phi_{L}(t)\\}$ are wide-sense stationary and ergodic; under the null hypothesis of no coupling, $A_{H}(t)$ and $\\phi_{L}(t)$ are statistically independent; and the marginal distribution of $\\phi_{L}(t)$ is uniform on $[0, 2\\pi)$. Let $m_{2} = \\mathbb{E}[A_{H}(t)^{2}]$ denote the second moment of the high-frequency amplitude envelope, which is preserved by the circular shift.\n\nUsing these assumptions and first principles from random process theory, derive the expected null probability density function of $R_{N}$ induced by the time-shift surrogate. Express your final answer as a single closed-form analytic expression for the density $f_{R_{N}}(r)$ in terms of $r$, $N$, and $m_{2}$. Do not provide an inequality or an equation as your final answer; provide only the density function expression. No numerical approximation is required.",
            "solution": "The objective is to derive the probability density function (PDF) of the estimator $R_N$. We begin by defining the complex-valued random variable $Z_N$ whose magnitude is $R_N$:\n$$\nZ_N = \\frac{1}{N} \\sum_{t=0}^{N-1} \\tilde{A}_{H}(t) \\exp(i \\phi_{L}(t))\n$$\nThe problem asks for the PDF of $R_N = |Z_N|$. $Z_N$ is an average of $N$ complex random variables. For a sufficiently large number of samples $N$, we can invoke the Central Limit Theorem (CLT). According to the CLT, the distribution of $Z_N$ will be well-approximated by a complex normal distribution if the summands are suitably behaved. Let us define the real and imaginary parts of $Z_N$:\n$$\nZ_N = X_N + i Y_N\n$$\nwhere\n$$\nX_N = \\frac{1}{N} \\sum_{t=0}^{N-1} \\tilde{A}_{H}(t) \\cos(\\phi_{L}(t))\n$$\n$$\nY_N = \\frac{1}{N} \\sum_{t=0}^{N-1} \\tilde{A}_{H}(t) \\sin(\\phi_{L}(t))\n$$\nTo characterize the distribution of $Z_N$, we must find the mean, variance, and covariance of its real and imaginary components, $X_N$ and $Y_N$.\n\n**1. Mean of $X_N$ and $Y_N$**\n\nWe first compute the expectation of $Z_N$. Under the null hypothesis, the amplitude process $\\{A_H(t)\\}$ (and thus its shifted version $\\{\\tilde{A}_H(t)\\}$) is statistically independent of the phase process $\\{\\phi_L(t)\\}$.\n$$\n\\mathbb{E}[Z_N] = \\mathbb{E}\\left[\\frac{1}{N} \\sum_{t=0}^{N-1} \\tilde{A}_{H}(t) \\exp(i \\phi_L(t))\\right] = \\frac{1}{N} \\sum_{t=0}^{N-1} \\mathbb{E}[\\tilde{A}_{H}(t)] \\mathbb{E}[\\exp(i \\phi_L(t))]\n$$\nThe expectation of the complex exponential of the phase is computed using its uniform distribution over $[0, 2\\pi)$:\n$$\n\\mathbb{E}[\\exp(i \\phi_L(t))] = \\int_{0}^{2\\pi} e^{i\\phi} \\frac{1}{2\\pi} \\,d\\phi = \\frac{1}{2\\pi i} [e^{i\\phi}]_0^{2\\pi} = \\frac{1}{2\\pi i} (1-1) = 0\n$$\nTherefore, $\\mathbb{E}[Z_N] = 0$. This implies that the means of the real and imaginary parts are also zero:\n$$\n\\mathbb{E}[X_N] = 0 \\quad \\text{and} \\quad \\mathbb{E}[Y_N] = 0\n$$\n\n**2. Variances of $X_N$ and $Y_N$**\n\nNext, we compute the variance of $X_N$. Since its mean is zero, $Var(X_N) = \\mathbb{E}[X_N^2]$.\n$$\nVar(X_N) = \\mathbb{E}\\left[\\left(\\frac{1}{N} \\sum_{t=0}^{N-1} \\tilde{A}_{H}(t) \\cos(\\phi_{L}(t))\\right)^2\\right] = \\frac{1}{N^2} \\sum_{t=0}^{N-1} \\sum_{t'=0}^{N-1} \\mathbb{E}[\\tilde{A}_{H}(t) \\tilde{A}_{H}(t') \\cos(\\phi_{L}(t)) \\cos(\\phi_{L}(t'))]\n$$\nUsing the independence of $\\{\\tilde{A}_H(t)\\}$ and $\\{\\phi_L(t)\\}$, we can separate the expectations:\n$$\nVar(X_N) = \\frac{1}{N^2} \\sum_{t=0}^{N-1} \\sum_{t'=0}^{N-1} \\mathbb{E}[\\tilde{A}_{H}(t) \\tilde{A}_{H}(t')] \\mathbb{E}[\\cos(\\phi_{L}(t)) \\cos(\\phi_{L}(t'))]\n$$\nThe problem states that $\\{\\phi_L(t)\\}$ is WSS and ergodic. For the derivation to yield a result dependent only on $m_2$, and not on the full autocorrelation structure of the processes, a simplifying condition must be met. The most direct condition is that the phase samples are uncorrelated, i.e., the phase process is white noise. This is a common assumption in this context, often implied by the properties given. If we treat the phase samples $\\{\\phi_L(t)\\}$ as independent and identically distributed (i.i.d.) from $U[0, 2\\pi)$, the expectation simplifies.\nFor $t \\neq t'$, $\\mathbb{E}[\\cos(\\phi_{L}(t)) \\cos(\\phi_{L}(t'))] = \\mathbb{E}[\\cos(\\phi_{L}(t))] \\mathbb{E}[\\cos(\\phi_{L}(t'))] = 0 \\cdot 0 = 0$.\nFor $t = t'$, $\\mathbb{E}[\\cos^2(\\phi_{L}(t))] = \\int_0^{2\\pi} \\cos^2(\\phi) \\frac{1}{2\\pi} d\\phi = \\frac{1}{2\\pi} \\int_0^{2\\pi} \\frac{1+\\cos(2\\phi)}{2} d\\phi = \\frac{1}{2}$.\nThus, the double summation collapses to a single summation over $t=t'$:\n$$\nVar(X_N) = \\frac{1}{N^2} \\sum_{t=0}^{N-1} \\mathbb{E}[\\tilde{A}_{H}(t)^2] \\cdot \\frac{1}{2}\n$$\nDue to the stationarity of $\\{A_H(t)\\}$, the second moment is constant, $\\mathbb{E}[A_H(t)^2] = m_2$. The circular shift preserves this property, so $\\mathbb{E}[\\tilde{A}_{H}(t)^2] = m_2$ for all $t$.\n$$\nVar(X_N) = \\frac{1}{2N^2} \\sum_{t=0}^{N-1} m_2 = \\frac{1}{2N^2} (N m_2) = \\frac{m_2}{2N}\n$$\nA similar calculation for $Y_N$, using $\\mathbb{E}[\\sin^2(\\phi_L(t))] = 1/2$ and $\\mathbb{E}[\\sin(\\phi_{L}(t))\\sin(\\phi_{L}(t'))] = 0$ for $t \\neq t'$, yields the same variance:\n$$\nVar(Y_N) = \\frac{m_2}{2N}\n$$\n\n**3. Covariance of $X_N$ and $Y_N$**\n\nThe covariance is $Cov(X_N, Y_N) = \\mathbb{E}[X_N Y_N]$, since the means are zero.\n$$\nCov(X_N, Y_N) = \\frac{1}{N^2} \\sum_{t=0}^{N-1} \\sum_{t'=0}^{N-1} \\mathbb{E}[\\tilde{A}_{H}(t) \\tilde{A}_{H}(t')] \\mathbb{E}[\\cos(\\phi_{L}(t)) \\sin(\\phi_{L}(t'))]\n$$\nFor $t \\neq t'$, the expectation on the phase terms is zero due to independence. For $t=t'$, the expectation is $\\mathbb{E}[\\cos(\\phi_L(t))\\sin(\\phi_L(t))] = \\mathbb{E}[\\frac{1}{2}\\sin(2\\phi_L(t))] = 0$. Thus, all terms in the sum are zero.\n$$\nCov(X_N, Y_N) = 0\n$$\n\n**4. The Distribution of $R_N$**\n\nBased on the CLT, for large $N$, $X_N$ and $Y_N$ are approximately independent, identically distributed Gaussian random variables with mean $0$ and variance $\\sigma^2 = \\frac{m_2}{2N}$.\n$$\nX_N, Y_N \\stackrel{iid}{\\sim} \\mathcal{N}\\left(0, \\frac{m_2}{2N}\\right)\n$$\nThe magnitude $R_N = \\sqrt{X_N^2 + Y_N^2}$ of such a two-dimensional Gaussian vector follows a Rayleigh distribution. The PDF of a Rayleigh-distributed random variable $r$ is given by $f(r; \\Sigma^2) = \\frac{r}{\\Sigma^2} \\exp\\left(-\\frac{r^2}{2\\Sigma^2}\\right)$, where $\\Sigma^2$ is the variance of the underlying Gaussian components.\nIn our case, $\\Sigma^2 = \\sigma^2 = \\frac{m_2}{2N}$. Substituting this into the Rayleigh PDF formula gives the null distribution for $R_N$:\n$$\nf_{R_N}(r) = \\frac{r}{\\frac{m_2}{2N}} \\exp\\left(-\\frac{r^2}{2\\left(\\frac{m_2}{2N}\\right)}\\right)\n$$\nSimplifying this expression yields the final result for $r \\ge 0$:\n$$\nf_{R_N}(r) = \\frac{2Nr}{m_2} \\exp\\left(-\\frac{Nr^2}{m_2}\\right)\n$$\nThis is the expected null probability density function induced by the time-shift surrogate procedure under the given assumptions.",
            "answer": "$$\n\\boxed{\\frac{2Nr}{m_{2}} \\exp\\left(-\\frac{Nr^{2}}{m_{2}}\\right)}\n$$"
        }
    ]
}