{
    "hands_on_practices": [
        {
            "introduction": "在我们深入研究复杂的拓扑数据分析（TDA）软件输出之前，从第一性原理出发建立坚实的直觉至关重要。本练习将指导您手动计算一个简单单纯复形的同调群，这个结构可以看作是 Mapper 算法或 Vietoris-Rips 复形在分析神经活动数据时可能产生的局部形状的简化模型。通过这个计算，您将加深对 Betti 数如何量化连通性（$\\beta_0$）和环路（$\\beta_1$）等基本拓扑特征的理解 ()。",
            "id": "4201288",
            "problem": "您正在分析一个海马体回路的神经元群体活动，其中通过对钙成像轨迹进行时间延迟嵌入，然后进行聚类，从而在高维状态空间中生成了一个点云。使用拓扑数据分析中的标准流程，您在尺度参数 $\\varepsilon$ 下构建了一个 Vietoris–Rips 复形，然后应用 Mapper 算法来可视化其粗略连通性。在一个特定的参数区域，Mapper 神经和 Vietoris–Rips $2$-骨架在一个子结构上达成一致，该子结构可以被建模为一个单纯复形 $K$，它由两个 $2$-单纯形组成，这两个单纯形恰好共享一个顶点，此外它们的顶点集不相交。具体来说，设顶点集为 $\\{v_0,v_1,v_2,v_3,v_4\\}$，其中包含两个 $2$-单纯形 $\\sigma_1=[v_0,v_1,v_2]$ 和 $\\sigma_2=[v_0,v_3,v_4]$，以及这些单纯形的所有面；不存在其他单纯形。\n\n仅从系数在 $\\mathbb{Z}_2$ 中的单纯同调的核心定义出发（即，链是系数在 $\\{0,1\\}$ 中的单纯形的形式和，边界映射是模 $2$ 约化后的交错和，同调群为 $H_k(K;\\mathbb{Z}_2)=\\ker \\partial_k / \\operatorname{im} \\partial_{k+1}$），计算 $H_0(K;\\mathbb{Z}_2)$ 和 $H_1(K;\\mathbb{Z}_2)$，并根据神经状态空间的连通性和一维循环结构来解释这些结果。\n\n最后，仅使用您已推导出的 Betti 数，计算欧拉示性数\n$$\n\\chi(K)=\\sum_{k=0}^{2} (-1)^k \\beta_k(K),\n$$\n其中 $\\beta_k(K)$ 是在 $\\mathbb{Z}_2$ 上的 $k$-阶 Betti 数。将 $\\chi(K)$ 报告为单个整数。无需四舍五入，也没有单位。您提供的最终数值答案必须是这个欧拉示性数。",
            "solution": "我们从 $\\mathbb{Z}_2$ 上的单纯同调的核心定义开始。对于每个 $k\\in \\mathbb{N}$，$k$-链 $C_k(K;\\mathbb{Z}_2)$ 是系数在 $\\mathbb{Z}_2$ 中的 $k$-单纯形的形式和。边界映射 $\\partial_k: C_k \\to C_{k-1}$ 作用于一个定向 $k$-单纯形，其结果是其 $(k-1)$-维面的交错和，并线性扩展；在 $\\mathbb{Z}_2$ 上，符号无关紧要，因此每个面都以模 $2$ 为 $1$ 的系数出现。$k$-阶同调群为 $H_k(K;\\mathbb{Z}_2)=\\ker \\partial_k / \\operatorname{im} \\partial_{k+1}$，其 Betti 数为 $\\beta_k(K)=\\dim_{\\mathbb{Z}_2} H_k(K;\\mathbb{Z}_2)$。\n\n单纯复形 $K$ 的顶点集为 $\\{v_0,v_1,v_2,v_3,v_4\\}$，有两个 $2$-单纯形 $\\sigma_1=[v_0,v_1,v_2]$ 和 $\\sigma_2=[v_0,v_3,v_4]$，以及这些单纯形的所有面。因此：\n- $0$-单纯形是 $v_0,v_1,v_2,v_3,v_4$，所以 $\\dim C_0 = 5$。\n- $1$-单纯形是两个三角形的边：$[v_0,v_1]$、$[v_1,v_2]$、$[v_2,v_0]$、$[v_0,v_3]$、$[v_3,v_4]$、$[v_4,v_0]$，所以 $\\dim C_1 = 6$。\n- $2$-单纯形是 $\\sigma_1$ 和 $\\sigma_2$，所以 $\\dim C_2 = 2$。\n- 对于 $k\\geq 3$，不存在 $k$-单纯形，所以 $C_k=\\{0\\}$。\n\n我们计算在 $\\mathbb{Z}_2$ 上的边界映射：\n- 对于边，$\\partial_1([v_i,v_j])=v_i+v_j$。\n- 对于三角形，\n$$\n\\partial_2([v_0,v_1,v_2])=[v_0,v_1]+[v_1,v_2]+[v_2,v_0], \\quad\n\\partial_2([v_0,v_3,v_4])=[v_0,v_3]+[v_3,v_4]+[v_4,v_0].\n$$\n\n首先，计算 $H_1(K;\\mathbb{Z}_2)=\\ker \\partial_1 / \\operatorname{im} \\partial_2$。\n- $1$-骨架图有 $5$ 个顶点和 $6$ 条边。其连通分支数为 $1$，因为所有顶点都通过 $v_0$ 连接。一个有限图的圈秩是 $m-n+c$，其中 $m$ 是边数，$n$ 是顶点数，$c$ 是连通分支数；这是秩-零度定理对于域上关联映射的一个标准推论。因此，$\\ker \\partial_1$ 的维数等于 $6-5+1=2$。具体来说，$\\ker \\partial_1$ 中的两个独立的 $1$-圈是两个三角形的边边界：\n$$\nz_1=[v_0,v_1]+[v_1,v_2]+[v_2,v_0], \\quad\nz_2=[v_0,v_3]+[v_3,v_4]+[v_4,v_0].\n$$\n- 像 $\\operatorname{im}\\partial_2$ 由 $\\partial_2(\\sigma_1)=z_1$ 和 $\\partial_2(\\sigma_2)=z_2$ 张成。这两个 $1$-链支撑在不相交的边集上，因此在 $\\mathbb{Z}_2$ 上线性无关，所以 $\\dim \\operatorname{im}\\partial_2 = 2$。\n\n因此，\n$$\n\\beta_1(K)=\\dim H_1=\\dim \\ker \\partial_1 - \\dim \\operatorname{im}\\partial_2 = 2-2=0,\n$$\n所以 $H_1(K;\\mathbb{Z}_2)\\cong 0$。\n\n接下来，计算 $H_0(K;\\mathbb{Z}_2)=\\ker \\partial_0 / \\operatorname{im} \\partial_1$。映射 $\\partial_0$ 是零映射，所以 $\\ker \\partial_0 = C_0$ 且 $\\dim \\ker \\partial_0 = 5$。$\\partial_1$ 的秩等于 $n-c$，其中 $n=5$ 且 $c=1$（对于一个连通图，域上关联映射的秩为 $n-1$），因此 $\\dim \\operatorname{im}\\partial_1 = 4$。因此\n$$\n\\beta_0(K)=\\dim H_0=\\dim \\ker \\partial_0 - \\dim \\operatorname{im}\\partial_1 = 5-4=1,\n$$\n所以 $H_0(K;\\mathbb{Z}_2)\\cong \\mathbb{Z}_2$。\n\n为完整起见，计算 $H_2(K;\\mathbb{Z}_2)=\\ker \\partial_2 / \\operatorname{im}\\partial_3$。由于 $C_3=\\{0\\}$，所以 $\\operatorname{im}\\partial_3=\\{0\\}$。映射 $\\partial_2$ 将两个基元素映到 $z_1$ 和 $z_2$，它们是线性无关的，所以 $\\partial_2$ 是单射，$\\ker \\partial_2=\\{0\\}$。因此 $H_2(K;\\mathbb{Z}_2)=0$ 且 $\\beta_2(K)=0$。\n\n在神经科学数据分析中的解释：$\\beta_0(K)=1$ 表示在所考察的分辨率 $\\varepsilon$ 下，神经状态空间只有一个连通分支，这与一个连贯、连通的群体活动模式相一致。$\\beta_1(K)=0$ 表示在考虑了被填充的 $2$-单纯形之后，不存在一维拓扑环，这意味着在此尺度上没有提示稳健周期性动力学的持续性循环结构；$1$-骨架中明显的 $1$-圈是 $2$-单纯形的边界，因此不是拓扑孔洞。\n\n最后，从 Betti 数计算欧拉示性数：\n$$\n\\chi(K)=\\sum_{k=0}^{2} (-1)^k \\beta_k(K) = \\beta_0 - \\beta_1 + \\beta_2 = 1 - 0 + 0 = 1.\n$$\n这就是所要求的单个整数。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "在神经科学中，一个核心任务是比较不同实验条件下的神经活动。拓扑数据分析通过持久性图（persistence diagram）为我们提供了量化和比较数据“形状”的强大工具。本练习的核心是计算两个持久性图之间的瓶颈距离（bottleneck distance），这是衡量拓扑摘要稳定性和差异性的标准度量 ()。通过显式地构建最优匹配，您将掌握比较不同条件下神经群体活动拓扑结构的核心技术。",
            "id": "4201354",
            "problem": "在两种行为情境下记录了一个海马体位置细胞群落，通过时间延迟嵌入在一个低维神经元状态空间中得到两个点云。对每个点云计算一个标准的 Vietoris–Rips 过滤，你得到以下一维持久性图（作为非对角线点的多重集），其过滤参数已归一化：图 $\\mathcal{D}_A$ 包含两个点 $(0,3)$ 和 $(1,2)$；图 $\\mathcal{D}_B$ 包含两个点 $\\left(0,\\tfrac{13}{5}\\right)$ 和 $\\left(\\tfrac{9}{10},\\tfrac{21}{10}\\right)$。假设在每个图中，对角线点 $(t,t)$ 以无限重数存在。\n\n首先，从拓扑数据分析（TDA）的核心定义出发，给出两个持久性图之间瓶颈距离 $d_B$ 的精确数学定义，即作为最小化 $L^{\\infty}$ 代价的部分匹配的下确界，并明确说明 $L^{\\infty}$ 范数如何使用以及如何处理与对角线的匹配。然后，仅使用该定义，通过构造一个显式的最优匹配并以严格的下界论证来证明其最优性，计算 $d_B\\!\\left(\\mathcal{D}_A,\\mathcal{D}_B\\right)$。将你的最终答案表示为一个精确的有理数，不要四舍五入。",
            "solution": "首先，我们给出瓶颈距离的定义。给定两个持久性图 $\\mathcal{D}_A$ 和 $\\mathcal{D}_B$（它们是 $\\mathbb{R}^2$ 中对角线 $y=x$ 上方的点的多重集），它们之间的**瓶颈距离** $d_B(\\mathcal{D}_A, \\mathcal{D}_B)$ 定义为：\n$$\nd_B(\\mathcal{D}_A, \\mathcal{D}_B) = \\inf_{\\eta} \\sup_{p \\in \\mathcal{D}_A'} \\| p - \\eta(p) \\|_{\\infty}\n$$\n这里的下确界取遍所有在扩展图 $\\mathcal{D}_A' = \\mathcal{D}_A \\cup \\Delta$ 和 $\\mathcal{D}_B' = \\mathcal{D}_B \\cup \\Delta$ 之间的**双射**（bijection）$\\eta$。其中 $\\Delta = \\{(t, t) \\in \\mathbb{R}^2\\}$ 是对角线，它被视为在每个图中都包含无穷多个点。$L^\\infty$ 范数定义为 $\\|(b_1, d_1) - (b_2, d_2)\\|_{\\infty} = \\max(|b_1 - b_2|, |d_1 - d_2|)$。将一个点 $p=(b,d)$ 匹配到对角线 $\\Delta$ 上的成本，是该点到其在对角线上最近投影点的 $L^\\infty$ 距离，即 $\\frac{d-b}{2}$。\n\n在本问题中，持久性图为：\n- $\\mathcal{D}_A = \\{ p_1=(0,3), p_2=(1,2) \\}$\n- $\\mathcal{D}_B = \\{ q_1=\\left(0,\\tfrac{13}{5}\\right), q_2=\\left(\\tfrac{9}{10},\\tfrac{21}{10}\\right) \\} = \\{ q_1=(0, 2.6), q_2=(0.9, 2.1) \\}$\n\n我们需要找到一个在 $\\mathcal{D}_A'$ 和 $\\mathcal{D}_B'$ 之间的匹配 $\\eta$，使得所有匹配对的最大距离最小。由于 $|\\mathcal{D}_A| = |\\mathcal{D}_B| = 2$，一个最优匹配要么是 $\\mathcal{D}_A$ 中的点与 $\\mathcal{D}_B$ 中的点之间的双射，要么涉及将某些点匹配到对角线 $\\Delta$。\n\n**情况 1：在非对角线点之间进行匹配**\n我们考虑两种可能的双射：\n1.  **匹配 $\\eta_1$**：$p_1 \\leftrightarrow q_1$ 和 $p_2 \\leftrightarrow q_2$。\n    - 成本 $c_1 = \\| p_1 - q_1 \\|_{\\infty} = \\| (0,3) - (0, 2.6) \\|_{\\infty} = \\max(|0-0|, |3-2.6|) = 0.4 = \\frac{2}{5}$。\n    - 成本 $c_2 = \\| p_2 - q_2 \\|_{\\infty} = \\| (1,2) - (0.9, 2.1) \\|_{\\infty} = \\max(|1-0.9|, |2-2.1|) = \\max(0.1, 0.1) = 0.1 = \\frac{1}{10}$。\n    这个匹配的代价是 $\\sup_{\\eta_1} = \\max(0.4, 0.1) = 0.4 = \\frac{2}{5}$。\n\n2.  **匹配 $\\eta_2$**：$p_1 \\leftrightarrow q_2$ 和 $p_2 \\leftrightarrow q_1$。\n    - 成本 $c_1 = \\| p_1 - q_2 \\|_{\\infty} = \\| (0,3) - (0.9, 2.1) \\|_{\\infty} = \\max(|0-0.9|, |3-2.1|) = \\max(0.9, 0.9) = 0.9$。\n    - 成本 $c_2 = \\| p_2 - q_1 \\|_{\\infty} = \\| (1,2) - (0, 2.6) \\|_{\\infty} = \\max(|1-0|, |2-2.6|) = \\max(1, 0.6) = 1$。\n    这个匹配的代价是 $\\sup_{\\eta_2} = \\max(0.9, 1) = 1$。\n\n**情况 2：涉及与对角线 $\\Delta$ 的匹配**\n我们将点匹配到对角线的成本计算如下：\n- $p_1=(0,3)$: 成本为 $(3-0)/2 = 1.5$。\n- $p_2=(1,2)$: 成本为 $(2-1)/2 = 0.5$。\n- $q_1=(0,2.6)$: 成本为 $(2.6-0)/2 = 1.3$。\n- $q_2=(0.9,2.1)$: 成本为 $(2.1-0.9)/2 = 0.6$。\n\n任何涉及与对角线匹配的方案，其代价至少是上述成本中的最小值，即 $0.5$。例如，如果我们匹配 $p_2 \\leftrightarrow \\Delta$，其成本是 $0.5$。为了完成双射，我们必须将 $p_1$ 与 $q_1$ 或 $q_2$ 中的一个匹配，并将另一个匹配到 $\\Delta$。\n- 如果 $p_1 \\leftrightarrow q_1$（成本 $0.4$），$q_2 \\leftrightarrow \\Delta$（成本 $0.6$），那么总代价为 $\\max(0.5, 0.4, 0.6) = 0.6$。\n- 如果 $p_1 \\leftrightarrow q_2$（成本 $0.9$），$q_1 \\leftrightarrow \\Delta$（成本 $1.3$），那么总代价为 $\\max(0.5, 0.9, 1.3) = 1.3$。\n在所有情况下，涉及对角线匹配的代价都大于或等于 $0.5$。\n\n**结论**\n比较所有可能匹配的代价，$\\eta_1$ 的代价 $0.4$ 是最小的。因此，瓶颈距离是 $0.4$。\n$$ d_B(\\mathcal{D}_A, \\mathcal{D}_B) = \\frac{2}{5} $$",
            "answer": "$$\\boxed{\\tfrac{2}{5}}$$"
        },
        {
            "introduction": "理论知识最终需要通过实际应用来巩固。这项综合性练习要求您构建一个完整的计算流程，用于统计比较两种实验条件下由 Mapper 算法生成的拓扑图 ()。您将实现从数据生成、滤波、Mapper 图构建到通过置换检验（permutation testing）和错误发现率（FDR）控制进行假设检验的整个过程，这模拟了在计算神经科学研究中应用 TDA 的真实场景。",
            "id": "4201320",
            "problem": "您将获得一个合成数据集的构建方法，该方法模拟了两种实验条件下神经活动的嵌入。您的任务是实现一个严谨的、基于经验的程序，用于评估从拓扑数据分析（TDA）的 Mapper 算法派生出的图拓扑中的条件差异，并控制错误发现率（FDR）。该程序必须依赖标签置换来生成零分布，并为一组局部边计数比较计算经验 $p$ 值。您的最终程序必须为指定的测试套件生成结果，并按照下面描述的精确格式将其打印在单行中。\n\n从以下基本依据和定义开始：\n\n- 拓扑数据分析 (TDA)：给定一个点云 $X \\subset \\mathbb{R}^d$ 和一个滤波器函数 $f : X \\to \\mathbb{R}$，Mapper 算法通过用重叠的区间覆盖 $f$ 的值域，对每个区间内的点进行聚类，并连接共享点的相邻区间的聚类来构建一个图。这会产生数据形状的组合表示。\n- Mapper 算法：给定一个滤波器 $f$、一个将 $\\mathrm{range}(f)$ 覆盖为 $m$ 个重叠区间的覆盖，以及一个聚类机制，节点对应于区间内的聚类，如果相邻区间的对应聚类至少共享一个数据点，则在这些节点之间连接边。设区间由 $i \\in \\{0,1,\\dots,m-1\\}$ 索引，并且只考虑相邻区间 $(i,i+1)$ 之间的边，从而产生 $m-1$ 个局部边计数。\n- 主成分分析 (PCA)：为了定义一个跨条件的通用滤波器，请使用在组合数据集上计算的第一个主成分。设 $X$ 已中心化，并设 $\\mathbf{v}_1$ 为 $X$ 的奇异值分解中的前导右奇异向量。定义 $f(\\mathbf{x}) = \\langle \\mathbf{x}, \\mathbf{v}_1 \\rangle$，并将 $f$ 线性缩放到单位区间 $[0,1]$。\n- 错误发现率 (FDR)：错误发现率 (FDR) 是所有拒绝中错误拒绝的预期比例。使用 Benjamini–Hochberg (BH) 程序控制 FDR：给定经验 $p$ 值 $p_1,\\dots,p_n$，将它们按升序排序 $p_{(1)} \\le \\dots \\le p_{(n)}$，其对应排名为 $r=1,\\dots,n$，并定义最大的 $k$ 使得 $p_{(k)} \\le \\alpha \\cdot k / n$，其中 $\\alpha$ 是期望的 FDR 水平。拒绝所有满足 $p_{(j)} \\le p_{(k)}$ 的假设。\n- 来自标签置换的经验 $p$ 值：给定一个观测到的检验统计量 $T_{\\mathrm{obs}}$ 和通过标签置换得到的 $K$ 个零复制 $T^{(1)},\\dots,T^{(K)}$，将双边经验 $p$ 值定义为 $p = \\dfrac{1 + \\#\\{k : |T^{(k)}| \\ge |T_{\\mathrm{obs}}|\\}}{K + 1}$。\n\n任务描述：\n\n1. 数据生成：对于每个测试用例，生成代表神经活动嵌入的 $\\mathbb{R}^3$ 中的 $N$ 个点的两个条件 $A$ 和 $B$。根据具体的测试用例，条件 $A$ 是一个带噪声的圆或一条带噪声的线；条件 $B$ 是一个带噪声的线或与 $A$ 相同的形状。各向同性地添加高斯噪声，以使配置在科学上是合理的。使用提供的随机种子以确保可复现性。\n\n2. 滤波器函数：在 $A \\cup B$ 的组合数据集上计算第一个主成分，将 $f(\\mathbf{x})$ 定义为在该主成分上的投影，并将 $f$ 线性缩放到 $[0,1]$。\n\n3. 覆盖构建：给定 $m$ 和重叠分数 $o$（$0 \\le o  1$），在 $[0,1]$ 上构建 $m$ 个区间 $I_i = [a_i,b_i]$，使得相邻区间的重叠分数约等于 $o$。设基本长度为 $L = 1/m$，步长为 $S = L \\cdot (1 - o)$。定义 $a_i = i S$ 和 $b_i = a_i + L$，并裁剪到 $[0,1]$ 范围内。\n\n4. 区间内聚类：对于任何区间 $I_i$，考虑其滤波器值位于 $I_i$ 内的点集。使用一个简单的连通分量规则和一个欧几里得距离阈值 $\\varepsilon$ 对这些点进行聚类：如果两个点的距离最多为 $\\varepsilon$，则它们是相邻的，聚类是该邻接图的连通分量。\n\n5. Mapper 图构建：对于每个条件，分别使用公共滤波器 $f$ 和相同的区间，将聚类构建为 Mapper 节点，并在来自相邻区间 $(i,i+1)$ 的聚类共享至少一个数据点（通过索引）时形成它们之间的边。计算每对相邻区间 $(i,i+1)$ 的边数，分别表示为 $E_A(i)$ 和 $E_B(i)$。\n\n6. 每个邻接的检验统计量：对于每对相邻区间 $(i,i+1)$，定义检验统计量 $T(i) = E_A(i) - E_B(i)$。\n\n7. 通过标签置换的零分布：通过随机置换组合数据集上的条件标签并为每对相邻区间重新计算 $T^{(k)}(i)$ 来生成 $K$ 个零复制。使用上面的公式计算双边经验 $p$ 值 $p(i)$。\n\n8. FDR 控制：对于给定的测试用例，在 $m-1$ 个经验 $p$ 值上应用水平为 $\\alpha$ 的 Benjamini–Hochberg 程序。返回一个长度为 $m-1$ 的布尔向量，指示哪些相邻区间在 FDR 控制下是显著的发现。\n\n测试套件和参数：\n\n实现您的程序以运行以下三个测试用例。每个测试用例指定 $(N, \\text{shape}_A, \\text{shape}_B, m, o, \\varepsilon, K, \\alpha, \\text{seed}, \\text{proportion}_A)$，其中 $\\text{shape} \\in \\{\\text{circle}, \\text{line}\\}$ 且 $\\text{proportion}_A$ 是分配给条件 $A$ 的点的比例。\n\n- 用例 1 (平衡，不同形状，理想情况)：$(N=180, \\text{shape}_A=\\text{circle}, \\text{shape}_B=\\text{line}, m=8, o=0.5, \\varepsilon=0.15, K=200, \\alpha=0.10, \\text{seed}=42, \\text{proportion}_A=0.5)$。圆半径 $r=1$，高斯噪声标准差 $\\sigma=0.05$。线段沿 $x$ 轴从 $-1$ 到 $1$，所有坐标上的噪声水平相同。\n\n- 用例 2 (不平衡标签，不同形状，边界情况)：$(N=160, \\text{shape}_A=\\text{circle}, \\text{shape}_B=\\text{line}, m=6, o=0.4, \\varepsilon=0.20, K=150, \\alpha=0.10, \\text{seed}=123, \\text{proportion}_A=0.25)$。圆和线如上，$\\sigma=0.05$。\n\n- 用例 3 (无差异，边缘情况)：$(N=150, \\text{shape}_A=\\text{line}, \\text{shape}_B=\\text{line}, m=5, o=0.3, \\varepsilon=0.20, K=150, \\alpha=0.10, \\text{seed}=7, \\text{proportion}_A=0.5)$。两个条件都使用相同的线构造，$\\sigma=0.05$。\n\n答案表示与输出格式：\n\n- 对于每个测试用例，生成一个长度为 $m-1$ 的布尔值列表，指示在水平为 $\\alpha$ 的 Benjamini–Hochberg FDR 控制下，哪些相邻区间对 $(i,i+1)$ 是显著的。\n- 您的程序应生成单行输出，其中包含结果，格式为用方括号括起来的这些布尔列表的逗号分隔列表。例如，如果用例 1 有 $m-1=7$ 对相邻区间，用例 2 有 $m-1=5$ 对，则打印输出必须具有 $[[b_{1,1},\\dots,b_{1,7}],[b_{2,1},\\dots,b_{2,5}],[b_{3,1},\\dots,b_{3,4}]]$ 的形式，其中每个 $b_{c,i}$ 是 $\\mathrm{True}$ 或 $\\mathrm{False}$。",
            "solution": "该任务是实现一个程序，用于统计比较从 Mapper 算法派生的两个数据集的拓扑结构，并控制错误发现率（FDR）。该方法论基于计算拓扑学和非参数统计，涉及数据生成、基于 PCA 的滤波、Mapper 图构建和置换检验。\n\n首先，我们解决数据生成问题。对于指定的两个条件 $A$ 和 $B$，我们在 $\\mathbb{R}^3$ 中生成一个点云。总点数为 $N$。条件 $A$ 包含 $N_A = \\text{round}(N \\cdot \\text{proportion}_A)$ 个点，条件 $B$ 包含剩余的 $N_B = N - N_A$ 个点。每个条件的数据的几何形状被指定为“圆”或“线”。\n对于半径为 $r=1$ 的“圆”，我们通过首先从均匀分布 $U[0, 2\\pi)$ 中为 $j \\in \\{1, \\dots, N_i\\}$ 抽取角度 $\\theta_j$ 来采样 $N_i$ 个点。初始坐标由 $(\\cos \\theta_j, \\sin \\theta_j, 0)$ 给出。对于“线”，我们通过从均匀分布 $U[-1, 1]$ 中为 $j \\in \\{1, \\dots, N_i\\}$ 抽取位置 $u_j$ 来采样 $N_i$ 个点。初始坐标为 $(u_j, 0, 0)$。为了模拟真实的测量噪声，向每个点添加一个各向同性的高斯噪声向量 $\\mathbf{\\epsilon}_j \\sim \\mathcal{N}(0, \\sigma^2 I_3)$，其中 $I_3$ 是 $3 \\times 3$ 单位矩阵，$\\sigma=0.05$ 是噪声标准差。因此，最终点为 $\\mathbf{x}_j = \\mathbf{x}_{\\text{shape}, j} + \\mathbf{\\epsilon}_j$。\n\n下一步是为组合数据集 $X = X_A \\cup X_B$（一个 $(N \\times 3)$ 矩阵）定义一个公共滤波器函数 $f$。该滤波器函数源自于主成分分析 (PCA)。我们首先通过减去其均值向量来对数据进行中心化：$\\bar{X} = X - \\mathbb{E}[X]$。然后，我们对中心化后的数据矩阵进行奇异值分解 (SVD)：$\\bar{X} = U \\Sigma V^T$。$V$ 的列是主成分（右奇异向量）。第一个主成分 $\\mathbf{v}_1$ 是方差最大的方向，即 $V$ 的第一列（或 $V^T$ 的第一行）。点 $\\mathbf{x}_i \\in X$ 的滤波器值是其在该主成分上的投影：$f(\\mathbf{x}_i) = \\langle \\mathbf{x}_i - \\mathbb{E}[X], \\mathbf{v}_1 \\rangle$。这些滤波器值随后被线性缩放到单位区间 $[0, 1]$ 内。\n\n建立滤波器函数后，我们构建 Mapper 图。这从为 $f$ 的值域（即 $[0, 1]$）定义一个覆盖开始。该覆盖由 $m$ 个重叠的区间组成。每个区间的长度是 $L = 1/m$。相邻区间之间的重叠由一个分数 $o \\in [0, 1)$ 决定，该分数决定了连续区间起点之间的步长 $S = L \\cdot (1 - o)$。第 $i$ 个区间，对于 $i \\in \\{0, \\dots, m-1\\}$，是 $I_i = [a_i, b_i]$，其中 $a_i = iS$ 且 $b_i = a_i + L$。区间边界被裁剪以保持在 $[0, 1]$ 范围内。\n\n对于每个区间 $I_i$，我们识别出其滤波器值落在该区间内的所有数据点的子集，称为拉回集 $f^{-1}(I_i)$。对于每个条件（$A$ 和 $B$），我们分别对其各自拉回集中的点进行聚类。聚类基于连通分量方法。以点为顶点形成一个无向图。如果两个顶点的欧几里得距离在 $\\mathbb{R}^3$ 中不大于指定阈值 $\\varepsilon$，则连接一条边。聚类是该图的连通分量。每个聚类是一组原始数据点的索引。\n\nMapper 图的节点是这些聚类。图的结构由对应于相邻区间的节点之间的连接定义。如果来自区间 $I_i$ 的聚类 $C_p$ 和来自区间 $I_{i+1}$ 的聚类 $C_q$ 共享至少一个公共数据点，即 $C_p \\cap C_q \\neq \\emptyset$，则它们之间存在一条边。我们计算每对相邻区间 $(i, i+1)$ 的此类边的总数。这为我们提供了每个条件的一系列局部边计数，$E_A(i)$ 和 $E_B(i)$，其中 $i \\in \\{0, \\dots, m-2\\}$。\n\n为了评估两个条件之间差异的统计显著性，我们为每个区间邻接 $i$ 定义一个检验统计量：$T(i) = E_A(i) - E_B(i)$。我们首先使用原始数据标签计算该统计量的观测值 $T_{\\text{obs}}(i)$。\n\n为了确定观测到的差异是否大于偶然预期的差异，我们使用置换检验生成一个零分布。这涉及创建 $K$ 个零复制。对于每个复制 $k \\in \\{1, \\dots, K\\}$，条件标签在 $N$ 个数据点上被随机置换，从而创建新的伪条件 $A^{(k)}$ 和 $B^{(k)}$。对于每个这样的置换数据集，重复在区间内聚类和计数 Mapper 边的整个过程，从而产生一组零统计量 $T^{(k)}(i) = E_{A^{(k)}}(i) - E_{B^{(k)}}(i)$。\n\n使用观测统计量和零分布，我们为每个邻接 $i$ 计算一个双边经验 $p$ 值。公式为 $p(i) = \\frac{1 + \\#\\{k : |T^{(k)}(i)| \\ge |T_{\\text{obs}}(i)|\\}}{K+1}$。在分子和分母上加 $1$ 是一个标准的校正，以防止 $p$ 值为 $0$ 并确保保守的推断。\n\n最后，由于我们正在进行多重比较（$m-1$ 个邻接中的每一个都进行一次），我们必须控制假阳性风险的增加。我们使用 Benjamini-Hochberg (BH) 程序在指定水平 $\\alpha$ 下控制错误发现率 (FDR)。将 $m-1$ 个 p 值 $\\{p(0), \\dots, p(m-2)\\}$ 按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m-1)}$。然后我们找到最大的秩 $k_{\\text{max}}$，使得 $p_{(k_{\\text{max)})} \\le \\frac{k_{\\text{max}}}{m-1}\\alpha$。所有对应于 p 值 $p_{(1)}, \\dots, p_{(k_{\\text{max}})}$ 的零假设都被拒绝。每个测试用例的最终输出是一个长度为 $m-1$ 的布尔向量，指示在 FDR 控制后，哪些邻接在条件 $A$ 和 $B$ 之间表现出统计上显著的差异。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom scipy.spatial.distance import pdist, squareform\n\ndef generate_data(n_points, shape, noise_sigma, rng):\n    \"\"\"Generates a 3D point cloud for a given shape with Gaussian noise.\"\"\"\n    if shape == 'circle':\n        # r=1 is specified in the problem implicitly\n        radius = 1.0\n        angles = rng.uniform(0, 2 * np.pi, n_points)\n        points = np.zeros((n_points, 3))\n        points[:, 0] = radius * np.cos(angles)\n        points[:, 1] = radius * np.sin(angles)\n    elif shape == 'line':\n        # line from -1 to 1 on x-axis\n        positions = rng.uniform(-1, 1, n_points)\n        points = np.zeros((n_points, 3))\n        points[:, 0] = positions\n    else:\n        raise ValueError(\"Unknown shape specified.\")\n    \n    noise = rng.normal(0, noise_sigma, (n_points, 3))\n    return points + noise\n\ndef get_pca_filter(points):\n    \"\"\"Computes the filter function based on the first principal component.\"\"\"\n    centered_points = points - np.mean(points, axis=0)\n    _, _, Vt = np.linalg.svd(centered_points, full_matrices=False)\n    v1 = Vt[0, :]\n    filter_values = centered_points @ v1\n    # Rescale to [0, 1]\n    min_val, max_val = np.min(filter_values), np.max(filter_values)\n    if min_val == max_val:\n        return np.zeros_like(filter_values)\n    return (filter_values - min_val) / (max_val - min_val)\n\ndef get_clusters_in_interval(point_indices, all_points, epsilon):\n    \"\"\"Clusters points within an interval using connected components.\"\"\"\n    if len(point_indices) == 0:\n        return []\n    \n    interval_points = all_points[point_indices, :]\n    \n    if len(point_indices) == 1:\n        # A single point is a single cluster\n        return [[point_indices[0]]]\n\n    dist_matrix = squareform(pdist(interval_points))\n    adj_matrix = dist_matrix = epsilon\n    \n    n_components, labels = connected_components(\n        csgraph=adj_matrix, directed=False, return_labels=True\n    )\n    \n    clusters = []\n    for i in range(n_components):\n        cluster_member_indices = np.where(labels == i)[0]\n        original_indices = [point_indices[j] for j in cluster_member_indices]\n        clusters.append(original_indices)\n        \n    return clusters\n\ndef compute_mapper_edges(point_indices, all_points, filter_values, m, o, epsilon):\n    \"\"\"Computes the number of edges for each adjacent interval pair.\"\"\"\n    intervals = []\n    L = 1.0 / m\n    S = L * (1.0 - o)\n    for i in range(m):\n        a_i = i * S\n        b_i = a_i + L\n        intervals.append((min(a_i, 1.0), min(b_i, 1.0)))\n\n    clusters_per_interval = []\n    for i in range(m):\n        a_i, b_i = intervals[i]\n        # Get points whose filter value is in the interval [a_i, b_i]\n        # Note: b_i is inclusive, except for the last interval's end\n        if i == m-1 and b_i == 1.0:\n            interval_point_mask = (filter_values[point_indices] >= a_i)  (filter_values[point_indices] = b_i)\n        else:\n            interval_point_mask = (filter_values[point_indices] >= a_i)  (filter_values[point_indices]  b_i)\n        \n        current_interval_indices = np.array(point_indices)[interval_point_mask]\n        \n        clusters = get_clusters_in_interval(list(current_interval_indices), all_points, epsilon)\n        clusters_per_interval.append(clusters)\n\n    edge_counts = np.zeros(m - 1, dtype=int)\n    for i in range(m - 1):\n        clusters1 = clusters_per_interval[i]\n        clusters2 = clusters_per_interval[i+1]\n        count = 0\n        for c1 in clusters1:\n            set_c1 = set(c1)\n            for c2 in clusters2:\n                if not set_c1.isdisjoint(c2):\n                    count += 1\n        edge_counts[i] = count\n        \n    return edge_counts\n\ndef benjamini_hochberg(p_values, alpha):\n    \"\"\"Applies the Benjamini-Hochberg FDR control procedure.\"\"\"\n    n = len(p_values)\n    if n == 0:\n        return []\n    \n    sorted_indices = np.argsort(p_values)\n    sorted_p_values = p_values[sorted_indices]\n    \n    k_vals = np.arange(1, n + 1)\n    thresholds = (k_vals / n) * alpha\n    \n    significant_mask = sorted_p_values = thresholds\n    \n    if np.any(significant_mask):\n        max_k = np.max(np.where(significant_mask))\n        significant_indices = sorted_indices[:max_k + 1]\n    else:\n        significant_indices = []\n        \n    result = np.zeros(n, dtype=bool)\n    result[significant_indices] = True\n    return result.tolist()\n\ndef run_case(params):\n    \"\"\"Runs the full analysis for a single test case.\"\"\"\n    N, shape_A, shape_B, m, o, epsilon, K, alpha, seed, prop_A = params\n    \n    rng = np.random.default_rng(seed)\n    \n    n_A = int(round(N * prop_A))\n    n_B = N - n_A\n    \n    points_A = generate_data(n_A, shape_A, 0.05, rng)\n    points_B = generate_data(n_B, shape_B, 0.05, rng)\n    \n    all_points = np.vstack([points_A, points_B])\n    labels = np.array([0] * n_A + [1] * n_B) # 0 for A, 1 for B\n    \n    indices_A = list(range(n_A))\n    indices_B = list(range(n_A, N))\n    \n    # Common filter for all computations\n    filter_values = get_pca_filter(all_points)\n    \n    # Observed statistic\n    E_A = compute_mapper_edges(indices_A, all_points, filter_values, m, o, epsilon)\n    E_B = compute_mapper_edges(indices_B, all_points, filter_values, m, o, epsilon)\n    T_obs = E_A - E_B\n    \n    # Null distribution from permutations\n    T_null = np.zeros((K, m - 1))\n    \n    # Use a separate RNG for permutations to ensure stability\n    perm_rng = np.random.default_rng(seed)\n\n    for k in range(K):\n        shuffled_labels = perm_rng.permutation(labels)\n        shuffled_indices_A = list(np.where(shuffled_labels == 0)[0])\n        shuffled_indices_B = list(np.where(shuffled_labels == 1)[0])\n        \n        E_A_shuffled = compute_mapper_edges(shuffled_indices_A, all_points, filter_values, m, o, epsilon)\n        E_B_shuffled = compute_mapper_edges(shuffled_indices_B, all_points, filter_values, m, o, epsilon)\n        T_null[k, :] = E_A_shuffled - E_B_shuffled\n        \n    # Empirical p-values\n    p_values = np.zeros(m - 1)\n    for i in range(m - 1):\n        num_more_extreme = np.sum(np.abs(T_null[:, i]) >= np.abs(T_obs[i]))\n        p_values[i] = (1 + num_more_extreme) / (K + 1)\n        \n    # FDR Control\n    return benjamini_hochberg(p_values, alpha)\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        # Case 1 (balanced, different shapes, happy path)\n        (180, 'circle', 'line', 8, 0.5, 0.15, 200, 0.10, 42, 0.5),\n        # Case 2 (imbalanced labels, different shapes, boundary)\n        (160, 'circle', 'line', 6, 0.4, 0.20, 150, 0.10, 123, 0.25),\n        # Case 3 (no difference, edge case)\n        (150, 'line', 'line', 5, 0.3, 0.20, 150, 0.10, 7, 0.5)\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = run_case(case)\n        results.append(str(result))\n    \n    # Final print statement in the exact required format.\n    # The required format is [[...],[...]], not \"['[...]', '[...]']\"\n    # So we join the string representations of the lists\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}