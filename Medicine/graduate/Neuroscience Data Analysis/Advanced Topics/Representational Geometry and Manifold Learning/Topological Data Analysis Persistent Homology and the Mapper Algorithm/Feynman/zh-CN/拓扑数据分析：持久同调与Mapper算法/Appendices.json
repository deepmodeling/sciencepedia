{
    "hands_on_practices": [
        {
            "introduction": "在我们运用强大的拓扑数据分析（TDA）软件之前，理解其核心计算原理至关重要。本练习将引导您为一个简单的几何形状手动计算其同调群，从而揭开 TDA 软件的“黑箱”。通过直接处理链群和边界映射，您将具体地理解抽象代数如何捕捉数据的连通分支（由贝蒂数 $\\beta_0$ 量化）和环路（由 $\\beta_1$ 量化）等直观形状特征。",
            "id": "4201288",
            "problem": "您正在分析一个海马体回路的神经元群体活动，其中，通过对钙成像轨迹进行时间延迟嵌入，然后进行聚类，从而在高维状态空间中生成了一个点云。使用拓扑数据分析中的标准流程，您在尺度参数 $\\varepsilon$ 下构建了一个 Vietoris–Rips 复形，然后应用 Mapper 算法来可视化其粗略连通性。在一个特定的参数体系下，Mapper 神经和 Vietoris–Rips $2$-骨架在一个子结构上达成一致，该子结构可以被建模为一个单纯复形 $K$，它由两个 $2$-单纯形组成，这两个单纯形恰好共享一个顶点，除此之外它们的顶点集是不相交的。具体来说，设顶点集为 $\\{v_0,v_1,v_2,v_3,v_4\\}$，其中有两个 $2$-单纯形 $\\sigma_1=[v_0,v_1,v_2]$ 和 $\\sigma_2=[v_0,v_3,v_4]$，并且包含了这些单纯形的所有面；不存在其他单纯形。\n\n仅从系数在 $\\mathbb{Z}_2$ 中的单纯同调的核心定义出发（即，链是系数在 $\\{0,1\\}$ 中的单纯形的形式和，边界映射是模 $2$ 约化后的交错和，同调群为 $H_k(K;\\mathbb{Z}_2)=\\ker \\partial_k / \\operatorname{im} \\partial_{k+1}$），计算 $H_0(K;\\mathbb{Z}_2)$ 和 $H_1(K;\\mathbb{Z}_2)$，并根据神经状态空间的连通性和一维循环结构来解释这些结果。\n\n最后，仅使用您推导出的 Betti 数，计算欧拉示性数\n$$\n\\chi(K)=\\sum_{k=0}^{2} (-1)^k \\beta_k(K),\n$$\n其中 $\\beta_k(K)$ 是在 $\\mathbb{Z}_2$ 上的 $k$-阶 Betti 数。将 $\\chi(K)$ 作为单个整数报告。无需四舍五入，也无单位。您提供的最终数值答案必须是这个欧拉示性数。",
            "solution": "我们从 $\\mathbb{Z}_2$ 上的单纯同调的核心定义开始。对于每个 $k\\in \\mathbb{N}$，$k$-链 $C_k(K;\\mathbb{Z}_2)$ 是系数在 $\\mathbb{Z}_2$ 中的 $k$-单纯形的形式和。边界映射 $\\partial_k: C_k \\to C_{k-1}$ 作用于一个定向 $k$-单纯形，结果是其 $(k-1)$-面的交错和，并可线性扩张；在 $\\mathbb{Z}_2$ 上，符号无关紧要，因此每个面都以模 $2$ 为 $1$ 的系数出现。$k$-阶同调为 $H_k(K;\\mathbb{Z}_2)=\\ker \\partial_k / \\operatorname{im} \\partial_{k+1}$，其 Betti 数为 $\\beta_k(K)=\\dim_{\\mathbb{Z}_2} H_k(K;\\mathbb{Z}_2)$。\n\n单纯复形 $K$ 的顶点集为 $\\{v_0,v_1,v_2,v_3,v_4\\}$，有两个 $2$-单纯形 $\\sigma_1=[v_0,v_1,v_2]$ 和 $\\sigma_2=[v_0,v_3,v_4]$，以及这些单纯形的所有面。因此：\n- $0$-单纯形是 $v_0,v_1,v_2,v_3,v_4$，所以 $\\dim C_0 = 5$。\n- $1$-单纯形是这两个三角形的边：$[v_0,v_1]$、$[v_1,v_2]$、$[v_2,v_0]$、$[v_0,v_3]$、$[v_3,v_4]$、$[v_4,v_0]$，所以 $\\dim C_1 = 6$。\n- $2$-单纯形是 $\\sigma_1$ 和 $\\sigma_2$，所以 $\\dim C_2 = 2$。\n- 对于 $k\\geq 3$ 不存在 $k$-单纯形，所以对于 $k\\geq 3$，$C_k=\\{0\\}$。\n\n我们计算在 $\\mathbb{Z}_2$ 上的边界映射：\n- 对于边，$\\partial_1([v_i,v_j])=v_i+v_j$。\n- 对于三角形，\n$$\n\\partial_2([v_0,v_1,v_2])=[v_0,v_1]+[v_1,v_2]+[v_2,v_0], \\quad\n\\partial_2([v_0,v_3,v_4])=[v_0,v_3]+[v_3,v_4]+[v_4,v_0].\n$$\n\n首先，计算 $H_1(K;\\mathbb{Z}_2)=\\ker \\partial_1 / \\operatorname{im} \\partial_2$。\n- $1$-骨架图有 $5$ 个顶点和 $6$ 条边。其连通分支数为 $1$，因为所有顶点都通过 $v_0$ 连接。一个有限图的圈秩是 $m-n+c$，其中 $m$ 是边数，$n$ 是顶点数，$c$ 是连通分支数；这是域上关联映射的秩-零度定理的一个标准推论。因此，$\\ker \\partial_1$ 的维数等于 $6-5+1=2$。\n- 具体来说，$\\ker \\partial_1$ 中的两个独立的 $1$-圈是这两个三角形的边边界：\n$$\nz_1=[v_0,v_1]+[v_1,v_2]+[v_2,v_0], \\quad\nz_2=[v_0,v_3]+[v_3,v_4]+[v_4,v_0].\n$$\n- $\\operatorname{im}\\partial_2$ 由 $\\partial_2(\\sigma_1)=z_1$ 和 $\\partial_2(\\sigma_2)=z_2$ 张成。这两个 $1$-链的支集在不相交的边集上，因此在 $\\mathbb{Z}_2$ 上是线性无关的，所以 $\\dim \\operatorname{im}\\partial_2 = 2$。\n\n因此，\n$$\n\\beta_1(K)=\\dim H_1=\\dim \\ker \\partial_1 - \\dim \\operatorname{im}\\partial_2 = 2-2=0,\n$$\n所以 $H_1(K;\\mathbb{Z}_2)\\cong 0$。\n\n接下来，计算 $H_0(K;\\mathbb{Z}_2)=\\ker \\partial_0 / \\operatorname{im} \\partial_1$。映射 $\\partial_0$ 是零映射，所以 $\\ker \\partial_0 = C_0$ 且 $\\dim \\ker \\partial_0 = 5$。$\\partial_1$ 的秩等于 $n-c$，其中 $n=5$，$c=1$（对于一个连通图，域上关联映射的秩是 $n-1$），因此 $\\dim \\operatorname{im}\\partial_1 = 4$。于是\n$$\n\\beta_0(K)=\\dim H_0=\\dim \\ker \\partial_0 - \\dim \\operatorname{im}\\partial_1 = 5-4=1,\n$$\n所以 $H_0(K;\\mathbb{Z}_2)\\cong \\mathbb{Z}_2$。\n\n为完整起见，计算 $H_2(K;\\mathbb{Z}_2)=\\ker \\partial_2 / \\operatorname{im}\\partial_3$。由于 $C_3=\\{0\\}$，所以 $\\operatorname{im}\\partial_3=\\{0\\}$。映射 $\\partial_2$ 将两个基元素映到 $z_1$ 和 $z_2$，它们是独立的，所以 $\\partial_2$ 是单射的，且 $\\ker \\partial_2=\\{0\\}$。因此 $H_2(K;\\mathbb{Z}_2)=0$ 且 $\\beta_2(K)=0$。\n\n用神经科学数据分析的术语来解释：$\\beta_0(K)=1$ 表示在所考察的分辨率 $\\varepsilon$ 下，神经状态空间只有一个连通分支，这与一个连贯、连通的群体活动模式是一致的。$\\beta_1(K)=0$ 表示在考虑了被填充的 $2$-单纯形后，不存在一维拓扑环，意味着在此尺度下没有持久的循环结构来表明鲁棒的周期性动力学；$1$-骨架中的表观 $1$-圈是 $2$-单纯形的边界，因此不是拓扑洞。\n\n最后，从 Betti 数计算欧拉示性数：\n$$\n\\chi(K)=\\sum_{k=0}^{2} (-1)^k \\beta_k(K) = \\beta_0 - \\beta_1 + \\beta_2 = 1 - 0 + 0 = 1.\n$$\n这就是所要求的单个整数。",
            "answer": "$$\\boxed{1}$$"
        },
        {
            "introduction": "本练习旨在连接抽象的单纯复形与实际的数据分析。练习模拟了一个常见场景：我们拥有一组数据点（例如，神经活动模式）之间的成对相异度。您将以不同的尺度参数 $\\epsilon$ 构建 Vietoris-Rips 复合体 ，并观察拓扑结构如何随之变化，从而对“过滤”这一核心概念获得直观感受。这个过程也揭示了 TDA 方法的一个重要优点，即它对于非度量数据同样适用。",
            "id": "4201355",
            "problem": "考虑四种神经活动模式，由点 $A$、$B$、$C$ 和 $D$ 索引，每种模式都是通过在四种实验条件下对一个固定神经元群体的试验级放电率进行平均而构建的。假设我们使用一种有界的、非度量的非相似性（例如，1减去限制在 $[0,1]$ 区间内的跨条件皮尔逊相关性），经验性地估计了成对非相似性 $\\{d_{XY}\\}_{X,Y \\in \\{A,B,C,D\\},\\,X \\neq Y}$，该非相似性不必满足三角不等式。观察到的成对非相似性如下：\n$$\nd_{AB} = 0.40,\\quad d_{BC} = 0.35,\\quad d_{AC} = 0.90,\\quad d_{AD} = 0.50,\\quad d_{BD} = 0.55,\\quad d_{CD} = 0.60.\n$$\n我们将基于这些非相似性在尺度 $\\epsilon$ 上构建 Vietoris–Rips 复形，它被定义为一个抽象单纯复形，其 $k$-单纯形对应于 $k+1$ 个点的集合，且这些点之间的所有成对非相似性都以 $\\epsilon$ 为界。\n\n将所有有序三元组 $(i,j,k)$ 中最小的三角不等式违背量值定义为\n$$\n\\delta^{*} \\equiv \\min_{(i,j,k)} \\max\\big\\{0,\\; d_{ik} - \\big(d_{ij} + d_{jk}\\big)\\big\\}.\n$$\n找出达到 $\\delta^{*}$ 的有序三元组，并设\n$$\n\\epsilon^{-} \\equiv d_{ij} + d_{jk},\\qquad \\epsilon^{+} \\equiv d_{ik}.\n$$\n将 $\\epsilon^{-}$ 解释为恰好在违背边界“之下”，$\\epsilon^{+}$ 解释为恰好在其“之上”。在 $\\epsilon = \\epsilon^{-}$ 和 $\\epsilon = \\epsilon^{+}$ 处构建 Vietoris–Rips 复形。仅使用上述基本定义，确定哪些单纯形（边、2-单纯形、3-单纯形）在这两个尺度之间出现或消失，并计算欧拉示性的变化\n$$\n\\Delta \\chi \\equiv \\chi(\\epsilon^{+}) - \\chi(\\epsilon^{-}),\n$$\n其中 $\\chi$ 是欧拉示性，由各维度单纯形数量的交错和给出。将 $\\Delta \\chi$ 的值作为最终答案报告。无需四舍五-入，您应提供不带单位的精确值。",
            "solution": "解答过程分三个阶段：首先，确定临界尺度 $\\epsilon^{-}$ 和 $\\epsilon^{+}$；其次，在这两个尺度上构建 Vietoris-Rips 复形并计算它们各自的欧拉示性；第三，计算差值。\n\n**1. 确定临界尺度 $\\epsilon^{-}$ 和 $\\epsilon^{+}$**\n\n我们必须找到有序三元组 $(i,j,k)$，以最小化非负量 $d_{ik} - (d_{ij} + d_{jk})$。这需要检查四个三点子集的所有可能三角不等式。只有当三角不等式 $d_{ik} \\leq d_{ij} + d_{jk}$ 被违背时，量 $\\max\\big\\{0,\\; d_{ik} - (d_{ij} + d_{jk})\\big\\}$ 才非零。\n\n让我们检查四个可能的三点子集：\n- **子集 $\\{A,B,C\\}$:**\n  - $d_{AC} - (d_{AB} + d_{BC}) = 0.90 - (0.40 + 0.35) = 0.90 - 0.75 = 0.15$。违背量为 $0.15$。\n  - $d_{AB} - (d_{AC} + d_{CB}) = 0.40 - (0.90 + 0.35) = -0.85$。违背量为 $0$。\n  - $d_{BC} - (d_{BA} + d_{AC}) = 0.35 - (0.40 + 0.90) = -0.95$。违背量为 $0$。\n- **子集 $\\{A,B,D\\}$:**\n  - $d_{AD} - (d_{AB} + d_{BD}) = 0.50 - (0.40 + 0.55) = -0.45$。违背量为 $0$。\n  - $d_{BD} - (d_{BA} + d_{AD}) = 0.55 - (0.40 + 0.50) = -0.35$。违背量为 $0$。\n  - $d_{AB} - (d_{AD} + d_{DB}) = 0.40 - (0.50 + 0.55) = -0.65$。违背量为 $0$。\n- **子集 $\\{A,C,D\\}$:**\n  - $d_{AC} - (d_{AD} + d_{DC}) = 0.90 - (0.50 + 0.60) = -0.20$。违背量为 $0$。\n  - $d_{AD} - (d_{AC} + d_{CD}) = 0.50 - (0.90 + 0.60) = -1.00$。违背量为 $0$。\n  - $d_{CD} - (d_{CA} + d_{AD}) = 0.60 - (0.90 + 0.50) = -0.80$。违背量为 $0$。\n- **子集 $\\{B,C,D\\}$:**\n  - $d_{BD} - (d_{BC} + d_{CD}) = 0.55 - (0.35 + 0.60) = -0.40$。违背量为 $0$。\n  - $d_{CD} - (d_{CB} + d_{BD}) = 0.60 - (0.35 + 0.55) = -0.30$。违背量为 $0$。\n  - $d_{BC} - (d_{BD} + d_{DC}) = 0.35 - (0.55 + 0.60) = -0.80$。违背量为 $0$。\n\n唯一的非零违背量是 $0.15$，因此这是最小的非零违背量。所以 $\\delta^{*} = 0.15$。这是由有序三元组 $(i,j,k) = (A,B,C)$ 达到的。\n根据定义，我们设定临界尺度：\n$$ \\epsilon^{-} = d_{ij} + d_{jk} = d_{AB} + d_{BC} = 0.40 + 0.35 = 0.75 $$\n$$ \\epsilon^{+} = d_{ik} = d_{AC} = 0.90 $$\n\n**2. Vietoris-Rips 复形和欧拉示性**\n\n我们现在在 $\\epsilon = \\epsilon^{-}$ 和 $\\epsilon = \\epsilon^{+}$ 处构建复形并计算它们的欧拉示性。对于这两个尺度，0-单纯形（顶点）的数量是恒定的，即 $k_0 = 4$。\n\n**在 $\\epsilon^{-} = 0.75$ 处的复形：**\n- **$1$-单纯形（边）：** 如果 $d_{XY} \\le 0.75$，则存在一条边 $\\{X,Y\\}$。\n  - $d_{AB}=0.40 \\le 0.75$ (存在)\n  - $d_{BC}=0.35 \\le 0.75$ (存在)\n  - $d_{AC}=0.90 > 0.75$ (不存在)\n  - $d_{AD}=0.50 \\le 0.75$ (存在)\n  - $d_{BD}=0.55 \\le 0.75$ (存在)\n  - $d_{CD}=0.60 \\le 0.75$ (存在)\n  1-单纯形的数量为 $k_1(\\epsilon^{-}) = 5$。\n- **$2$-单纯形（三角形）：** 如果三角形 $\\{X,Y,Z\\}$ 的三条边都存在，则该三角形存在。\n  - $\\{A,B,C\\}$：边 $\\{A,C\\}$ 缺失。\n  - $\\{A,B,D\\}$：边 $\\{A,B\\}, \\{A,D\\}, \\{B,D\\}$ 存在 ($0.40, 0.50, 0.55 \\le 0.75$)。\n  - $\\{A,C,D\\}$：边 $\\{A,C\\}$ 缺失。\n  - $\\{B,C,D\\}$：边 $\\{B,C\\}, \\{B,D\\}, \\{C,D\\}$ 存在 ($0.35, 0.55, 0.60 \\le 0.75$)。\n  2-单纯形的数量为 $k_2(\\epsilon^{-}) = 2$。\n- **$3$-单纯形（四面体）：** 一个四面体 $\\{A,B,C,D\\}$ 要求所有 6 条边都存在。由于边 $\\{A,C\\}$ 缺失，不存在 3-单纯形。$k_3(\\epsilon^{-}) = 0$。\n\n在 $\\epsilon^{-}$ 处的欧拉示性为：\n$$ \\chi(\\epsilon^{-}) = k_0 - k_1(\\epsilon^{-}) + k_2(\\epsilon^{-}) - k_3(\\epsilon^{-}) = 4 - 5 + 2 - 0 = 1 $$\n\n**在 $\\epsilon^{+} = 0.90$ 处的复形：**\n- **$1$-单纯形（边）：** 如果 $d_{XY} \\le 0.90$，则存在一条边 $\\{X,Y\\}$。现在，所有成对非相似性都小于或等于 $0.90$。边 $\\{A,C\\}$（其 $d_{AC}=0.90$）现在被包含在内。\n  1-单纯形的数量为 $k_1(\\epsilon^{+}) = k_1(\\epsilon^{-}) + 1 = 6$。\n- **$2$-单纯形（三角形）：** 我们检查因添加边 $\\{A,C\\}$ 而形成的新三角形。\n  - 之前的三角形 $\\{A,B,D\\}$ 和 $\\{B,C,D\\}$ 仍然存在。\n  - $\\{A,B,C\\}$：边 $\\{A,B\\},\\{B,C\\},\\{A,C\\}$ 存在 ($0.40, 0.35, 0.90 \\le 0.90$)。\n  - $\\{A,C,D\\}$：边 $\\{A,C\\},\\{C,D\\},\\{A,D\\}$ 存在 ($0.90, 0.60, 0.50 \\le 0.90$)。\n  2-单纯形的数量为 $k_2(\\epsilon^{+}) = k_2(\\epsilon^{-}) + 2 = 2 + 2 = 4$。\n- **$3$-单纯形（四面体）：**\n  - $\\{A,B,C,D\\}$：这要求所有 6 条边都存在。在 $\\epsilon = 0.90$ 时，所有成对非相似性都 $\\le 0.90$。因此，该四面体存在。\n  3-单纯形的数量为 $k_3(\\epsilon^{+}) = 1$。\n\n在 $\\epsilon^{+}$ 处的欧拉示性为：\n$$ \\chi(\\epsilon^{+}) = k_0 - k_1(\\epsilon^{+}) + k_2(\\epsilon^{+}) - k_3(\\epsilon^{+}) = 4 - 6 + 4 - 1 = 1 $$\n\n**3. 欧拉示性的变化**\n\n欧拉示性的变化是两个计算值之差：\n$$ \\Delta \\chi = \\chi(\\epsilon^{+}) - \\chi(\\epsilon^{-}) = 1 - 1 = 0 $$\n\n或者，我们可以通过从 $\\epsilon^{-}$ 过渡到 $\\epsilon^{+}$ 时各维度单纯形数量的变化来计算 $\\Delta \\chi$：\n- $\\Delta k_0 = k_0(\\epsilon^{+}) - k_0(\\epsilon^{-}) = 4 - 4 = 0$\n- $\\Delta k_1 = k_1(\\epsilon^{+}) - k_1(\\epsilon^{-}) = 6 - 5 = 1$ (边 $\\{A,C\\}$)\n- $\\Delta k_2 = k_2(\\epsilon^{+}) - k_2(\\epsilon^{-}) = 4 - 2 = 2$ (三角形 $\\{A,B,C\\}$ 和 $\\{A,C,D\\}$)\n- $\\Delta k_3 = k_3(\\epsilon^{+}) - k_3(\\epsilon^{-}) = 1 - 0 = 1$ (四面体 $\\{A,B,C,D\\}$)\n\n欧拉示性的变化是这些变化的交错和：\n$$ \\Delta\\chi = \\Delta k_0 - \\Delta k_1 + \\Delta k_2 - \\Delta k_3 = 0 - 1 + 2 - 1 = 0 $$\n两种方法得出相同的结果。从 $\\epsilon^{-}$ 处的复形到 $\\epsilon^{+}$ 处的复形的过渡涉及到同时添加一条边、两个三角形和一个四面体，其对欧拉示性的净效应为零。",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "最后的这项综合练习将引导您完成一个真实的研究级计算任务，从基本概念走向完整的应用。您将实现 Mapper 算法以比较两种实验条件下的数据，这是神经科学研究中的一个典型目标。这项练习  强调，生成拓扑摘要本身并非终点；我们必须采用如置换检验这样严谨的统计方法来判断观测到的差异是否具有统计显著性，这是任何计算科学家都应具备的关键技能。",
            "id": "4201320",
            "problem": "您将获得一个合成数据集的构建方法，该方法模拟了两种实验条件下的神经活动嵌入。您的任务是实现一个严谨且基于经验的流程，用于评估从拓扑数据分析 (TDA) 的 Mapper 算法派生的图拓扑中的条件差异，并控制错误发现率 (FDR)。该流程必须依赖标签重排来生成零分布，并为一组局部边计数比较计算经验 $p$ 值。您的最终程序必须为指定的测试套件生成结果，并按照下述确切格式单行打印。\n\n从以下基本依据和定义开始：\n\n- 拓扑数据分析 (TDA)：给定点云 $X \\subset \\mathbb{R}^d$ 和滤波器函数 $f : X \\to \\mathbb{R}$，Mapper 算法通过用重叠区间覆盖 $f$ 的值域，对每个区间内的点进行聚类，并连接共享数据点的相邻区间的聚类来构建一个图。这将生成数据形状的组合表示。\n- Mapper 算法：给定一个滤波器 $f$、一个将 $\\mathrm{range}(f)$ 覆盖为 $m$ 个重叠区间的覆盖，以及一个聚类机制，节点对应于区间内的聚类，如果来自相邻区间的节点所对应的聚类共享至少一个数据点，则在它们之间连接一条边。设区间的索引为 $i \\in \\{0,1,\\dots,m-1\\}$，并仅考虑相邻区间 $(i,i+1)$ 之间的边，从而产生 $m-1$ 个局部边计数。\n- 主成分分析 (PCA)：为了在不同条件下定义一个共同的滤波器，请使用在合并数据集上计算的第一个主成分。设 $X$ 已中心化，并设 $\\mathbf{v}_1$ 为 $X$ 的奇异值分解中的前导右奇异向量。定义 $f(\\mathbf{x}) = \\langle \\mathbf{x}, \\mathbf{v}_1 \\rangle$，并将 $f$ 线性缩放到单位区间 $[0,1]$。\n- 错误发现率 (FDR)：错误发现率 (FDR) 是在所有拒绝的假设中，错误拒绝所占的预期比例。使用 Benjamini–Hochberg (BH) 程序控制 FDR：给定经验 $p$ 值 $p_1,\\dots,p_n$，将它们按升序排序 $p_{(1)} \\le \\dots \\le p_{(n)}$，对应秩为 $r=1,\\dots,n$，并定义最大的 $k$，使得 $p_{(k)} \\le \\alpha \\cdot k / n$，其中 $\\alpha$ 是期望的 FDR 水平。拒绝所有满足 $p_{(j)} \\le p_{(k)}$ 的假设。\n- 来自标签重排的经验 $p$ 值：给定一个观测到的检验统计量 $T_{\\mathrm{obs}}$ 和通过标签重排生成的 $K$ 个零假设复制 $T^{(1)},\\dots,T^{(K)}$，将双边经验 $p$ 值定义为 $p = \\dfrac{1 + \\#\\{k : |T^{(k)}| \\ge |T_{\\mathrm{obs}}|\\}}{K + 1}$。\n\n任务描述：\n\n1. 数据生成：对于每个测试用例，在 $\\mathbb{R}^3$ 中生成代表神经活动嵌入的两个条件 $A$ 和 $B$ 的 $N$ 个点。条件 $A$ 是一个带噪声的圆形或一个带噪声的线形；条件 $B$ 是一个带噪声的线形或与 $A$ 形状相同，具体取决于特定的测试用例。各向同性地添加高斯噪声，以使配置在科学上更为合理。使用提供的随机种子以确保可复现性。\n\n2. 滤波器函数：在合并数据集 $A \\cup B$ 上计算第一个主成分，将 $f(\\mathbf{x})$ 定义为在该主成分上的投影，并将 $f$ 线性缩放到 $[0,1]$。\n\n3. 覆盖构建：给定 $m$ 和重叠分数 $o$（其中 $0 \\le o  1$），在 $[0,1]$ 上构建 $m$ 个区间 $I_i = [a_i,b_i]$，使得相邻区间的重叠比例约等于 $o$。设基本长度为 $L = 1/m$，步长为 $S = L \\cdot (1 - o)$。定义 $a_i = i S$ 和 $b_i = a_i + L$，并裁剪至 $[0,1]$ 范围内。\n\n4. 区间内聚类：对于任何区间 $I_i$，考虑其滤波器值位于 $I_i$ 内的点集。使用一个简单的连通分量规则和欧几里得距离阈值 $\\varepsilon$ 对这些点进行聚类：如果两点之间的距离至多为 $\\varepsilon$，则它们是相邻的，聚类即为此邻接图的连通分量。\n\n5. Mapper 图构建：对每个条件分别使用共同的滤波器 $f$ 和相同的区间，将聚类作为 Mapper 节点，并在来自相邻区间 $(i,i+1)$ 的聚类共享至少一个数据点（按索引）时形成边。计算每对邻接区间 $(i,i+1)$ 的边数，分别记为条件 $A$ 和 $B$ 的 $E_A(i)$ 和 $E_B(i)$。\n\n6. 每个邻接对的检验统计量：对于每个邻接对 $(i,i+1)$，定义检验统计量 $T(i) = E_A(i) - E_B(i)$。\n\n7. 通过标签重排生成零分布：通过在合并数据集上随机置换条件标签，为每个邻接对重新计算 $T^{(k)}(i)$，从而生成 $K$ 个零假设复制。使用上述公式计算双边经验 $p$ 值 $p(i)$。\n\n8. FDR 控制：对给定测试用例的 $m-1$ 个经验 $p$ 值应用水平为 $\\alpha$ 的 Benjamini-Hochberg 程序。返回一个长度为 $m-1$ 的布尔向量，指示哪些邻接对在 FDR 控制下是显著发现。\n\n测试套件和参数：\n\n实现您的程序以运行以下三个测试用例。每个测试用例指定 $(N, \\text{shape}_A, \\text{shape}_B, m, o, \\varepsilon, K, \\alpha, \\text{seed}, \\text{proportion}_A)$，其中 $\\text{shape} \\in \\{\\text{circle}, \\text{line}\\}$ 且 $\\text{proportion}_A$ 是分配给条件 $A$ 的点的比例。\n\n- 用例 1（平衡，不同形状，理想路径）：$(N=180, \\text{shape}_A=\\text{circle}, \\text{shape}_B=\\text{line}, m=8, o=0.5, \\varepsilon=0.15, K=200, \\alpha=0.10, \\text{seed}=42, \\text{proportion}_A=0.5)$。圆形半径 $r=1$，高斯噪声标准差 $\\sigma=0.05$。线段沿 $x$ 轴从 $-1$ 到 $1$，所有坐标具有相同的噪声水平。\n\n- 用例 2（标签不平衡，不同形状，边界情况）：$(N=160, \\text{shape}_A=\\text{circle}, \\text{shape}_B=\\text{line}, m=6, o=0.4, \\varepsilon=0.20, K=150, \\alpha=0.10, \\text{seed}=123, \\text{proportion}_A=0.25)$。圆形和线形如上，$\\sigma=0.05$。\n\n- 用例 3（无差异，边缘情况）：$(N=150, \\text{shape}_A=\\text{line}, \\text{shape}_B=\\text{line}, m=5, o=0.3, \\varepsilon=0.20, K=150, \\alpha=0.10, \\text{seed}=7, \\text{proportion}_A=0.5)$。两个条件均使用相同的线形构造，$\\sigma=0.05$。\n\n答案表示和输出格式：\n\n- 对于每个测试用例，生成一个长度为 $m-1$ 的布尔值列表，指示在水平为 $\\alpha$ 的 Benjamini-Hochberg FDR 控制下，哪些邻接对 $(i,i+1)$ 是显著的。\n- 您的程序应生成单行输出，其中包含结果，形式为由方括号括起来的布尔列表的逗号分隔列表。例如，如果用例 1 有 $m-1=7$ 个邻接对，用例 2 有 $m-1=5$ 个邻接对，则打印输出必须为 $[[b_{1,1},\\dots,b_{1,7}],[b_{2,1},\\dots,b_{2,5}],[b_{3,1},\\dots,b_{3,4}]]$ 的形式，其中每个 $b_{c,i}$ 是 $\\mathrm{True}$ 或 $\\mathrm{False}$。",
            "solution": "任务是实现一个流程，用于统计比较两个数据集的拓扑结构，这些结构源自 Mapper 算法，并控制错误发现率（FDR）。该方法论基于计算拓扑学和非参数统计，涉及数据生成、基于 PCA 的滤波、Mapper 图构建和置换检验。\n\n首先，我们处理数据生成问题。对于指定的两个条件 $A$ 和 $B$，我们在 $\\mathbb{R}^3$ 中生成点云。总点数为 $N$。条件 $A$ 包含 $N_A = \\text{round}(N \\cdot \\text{proportion}_A)$ 个点，条件 $B$ 包含余下的 $N_B = N - N_A$ 个点。每个条件的数据几何形状被指定为 'circle'（圆形）或 'line'（线形）。\n对于半径为 $r=1$ 的'圆形'，我们通过首先从均匀分布 $U[0, 2\\pi)$ 中抽取角度 $\\theta_j$（对于 $j \\in \\{1, \\dots, N_i\\}$）来采样 $N_i$ 个点。初始坐标由 $(\\cos \\theta_j, \\sin \\theta_j, 0)$ 给出。对于'线形'，我们通过从均匀分布 $U[-1, 1]$ 中抽取位置 $u_j$（对于 $j \\in \\{1, \\dots, N_i\\}$）来采样 $N_i$ 个点。初始坐标为 $(u_j, 0, 0)$。为了模拟真实的测量噪声，向每个点添加一个各向同性的高斯噪声向量 $\\mathbf{\\epsilon}_j \\sim \\mathcal{N}(0, \\sigma^2 I_3)$，其中 $I_3$ 是 $3 \\times 3$ 单位矩阵，$\\sigma=0.05$ 是噪声标准差。因此，最终的点为 $\\mathbf{x}_j = \\mathbf{x}_{\\text{shape}, j} + \\mathbf{\\epsilon}_j$。\n\n下一步是为合并的数据集 $X = X_A \\cup X_B$（一个 $(N \\times 3)$ 矩阵）定义一个共同的滤波器函数 $f$。该滤波器函数源自于主成分分析 (PCA)。我们首先通过减去其均值向量来对数据进行中心化：$\\bar{X} = X - \\mathbb{E}[X]$。然后，我们对中心化后的数据矩阵执行奇异值分解 (SVD)：$\\bar{X} = U \\Sigma V^T$。$V$ 的列是主成分（右奇异向量）。第一个主成分 $\\mathbf{v}_1$ 是方差最大的方向，即 $V$ 的第一列（或 $V^T$ 的第一行）。对于点 $\\mathbf{x}_i \\in X$，其滤波器值是它在该主成分上的投影：$f(\\mathbf{x}_i) = \\langle \\mathbf{x}_i - \\mathbb{E}[X], \\mathbf{v}_1 \\rangle$。随后，这些滤波器值被线性缩放到单位区间 $[0, 1]$ 内。\n\n建立滤波器函数后，我们构建 Mapper 图。这首先要为 $f$ 的值域（即 $[0, 1]$）定义一个覆盖。该覆盖由 $m$ 个重叠区间组成。每个区间的长度为 $L = 1/m$。相邻区间之间的重叠由一个分数 $o \\in [0, 1)$ 决定，该分数决定了连续区间起点之间的步长 $S = L \\cdot (1 - o)$。第 $i$ 个区间（对于 $i \\in \\{0, \\dots, m-1\\}$）是 $I_i = [a_i, b_i]$，其中 $a_i = iS$ 且 $b_i = a_i + L$。区间边界被裁剪以保持在 $[0, 1]$ 范围内。\n\n对于每个区间 $I_i$，我们识别出其滤波器值落在该区间内的数据点子集，称为拉回集 $f^{-1}(I_i)$。对每个条件（$A$ 和 $B$）分别地，我们对其各自拉回集中的点进行聚类。聚类基于连通分量方法。以点为顶点形成一个无向图。如果两个顶点在 $\\mathbb{R}^3$ 中的欧几里得距离不大于指定的阈值 $\\varepsilon$，则连接一条边。聚类就是这个图的连通分量。每个聚类是一组原始数据点的索引。\n\nMapper 图的节点是这些聚类。图的结构由对应于相邻区间的节点之间的连接定义。如果来自区间 $I_i$ 的聚类 $C_p$ 和来自区间 $I_{i+1}$ 的聚类 $C_q$ 共享至少一个公共数据点（即 $C_p \\cap C_q \\neq \\emptyset$），则它们之间存在一条边。我们为每对相邻区间 $(i, i+1)$ 计算此类边的总数。这为我们提供了每个条件的一系列局部边计数 $E_A(i)$ 和 $E_B(i)$，其中 $i \\in \\{0, \\dots, m-2\\}$。\n\n为了评估两个条件之间差异的统计显著性，我们为每个区间邻接 $i$ 定义一个检验统计量：$T(i) = E_A(i) - E_B(i)$。我们首先使用原始数据标签计算该统计量的观测值 $T_{\\text{obs}}(i)$。\n\n为了确定观测到的差异是否大于偶然预期的差异，我们使用置换检验生成一个零分布。这包括创建 $K$ 个零假设复制。对于每个复制 $k \\in \\{1, \\dots, K\\}$，条件标签在 $N$ 个数据点上被随机置换，从而创建新的伪条件 $A^{(k)}$ 和 $B^{(k)}$。对于每个这样的重排数据集，重复执行在区间内聚类和计算 Mapper 边的整个过程，得到一组零统计量 $T^{(k)}(i) = E_{A^{(k)}}(i) - E_{B^{(k)}}(i)$。\n\n使用观测统计量和零分布，我们为每个邻接 $i$ 计算一个双边经验 $p$ 值。公式为 $p(i) = \\frac{1 + \\#\\{k : |T^{(k)}(i)| \\ge |T_{\\text{obs}}(i)|\\}}{K+1}$。在分子和分母上加 $1$ 是一种标准的修正，以防止出现 $p$ 值为 $0$ 并确保保守的推断。\n\n最后，由于我们正在进行多重比较（$m-1$ 个邻接中的每一个都进行一次），我们必须控制假阳性风险的增加。我们使用 Benjamini-Hochberg (BH) 程序在指定的水平 $\\alpha$ 上控制错误发现率 (FDR)。将 $m-1$ 个 p 值 $\\{p(0), \\dots, p(m-2)\\}$ 按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m-1)}$。然后我们找到最大的秩 $k_{\\text{max}}$，使得 $p_{(k_{\\text{max)})} \\le \\frac{k_{\\text{max}}}{m-1}\\alpha$。所有对应于 p 值 $p_{(1)}, \\dots, p_{(k_{\\text{max}})}$ 的零假设都被拒绝。每个测试用例的最终输出是一个长度为 $m-1$ 的布尔向量，指示在 FDR 控制后，哪些邻接在条件 $A$ 和 $B$ 之间表现出统计上显著的差异。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse.csgraph import connected_components\nfrom scipy.spatial.distance import pdist, squareform\n\ndef generate_data(n_points, shape, noise_sigma, rng):\n    \"\"\"Generates a 3D point cloud for a given shape with Gaussian noise.\"\"\"\n    if shape == 'circle':\n        # r=1 is specified in the problem implicitly\n        radius = 1.0\n        angles = rng.uniform(0, 2 * np.pi, n_points)\n        points = np.zeros((n_points, 3))\n        points[:, 0] = radius * np.cos(angles)\n        points[:, 1] = radius * np.sin(angles)\n    elif shape == 'line':\n        # line from -1 to 1 on x-axis\n        positions = rng.uniform(-1, 1, n_points)\n        points = np.zeros((n_points, 3))\n        points[:, 0] = positions\n    else:\n        raise ValueError(\"Unknown shape specified.\")\n    \n    noise = rng.normal(0, noise_sigma, (n_points, 3))\n    return points + noise\n\ndef get_pca_filter(points):\n    \"\"\"Computes the filter function based on the first principal component.\"\"\"\n    centered_points = points - np.mean(points, axis=0)\n    _, _, Vt = np.linalg.svd(centered_points, full_matrices=False)\n    v1 = Vt[0, :]\n    filter_values = centered_points @ v1\n    # Rescale to [0, 1]\n    min_val, max_val = np.min(filter_values), np.max(filter_values)\n    if min_val == max_val:\n        return np.zeros_like(filter_values)\n    return (filter_values - min_val) / (max_val - min_val)\n\ndef get_clusters_in_interval(point_indices, all_points, epsilon):\n    \"\"\"Clusters points within an interval using connected components.\"\"\"\n    if len(point_indices) == 0:\n        return []\n    \n    interval_points = all_points[point_indices, :]\n    \n    if len(point_indices) == 1:\n        # A single point is a single cluster\n        return [[point_indices[0]]]\n\n    dist_matrix = squareform(pdist(interval_points))\n    adj_matrix = dist_matrix = epsilon\n    \n    n_components, labels = connected_components(\n        csgraph=adj_matrix, directed=False, return_labels=True\n    )\n    \n    clusters = []\n    for i in range(n_components):\n        cluster_member_indices = np.where(labels == i)[0]\n        original_indices = [point_indices[j] for j in cluster_member_indices]\n        clusters.append(original_indices)\n        \n    return clusters\n\ndef compute_mapper_edges(point_indices, all_points, filter_values, m, o, epsilon):\n    \"\"\"Computes the number of edges for each adjacent interval pair.\"\"\"\n    intervals = []\n    L = 1.0 / m\n    S = L * (1.0 - o)\n    for i in range(m):\n        a_i = i * S\n        b_i = a_i + L\n        intervals.append((min(a_i, 1.0), min(b_i, 1.0)))\n\n    clusters_per_interval = []\n    for i in range(m):\n        a_i, b_i = intervals[i]\n        # Get points whose filter value is in the interval [a_i, b_i]\n        # Note: b_i is inclusive, except for the last interval's end\n        if i == m-1 and b_i == 1.0:\n            interval_point_mask = (filter_values[point_indices] >= a_i)  (filter_values[point_indices] = b_i)\n        else:\n            interval_point_mask = (filter_values[point_indices] >= a_i)  (filter_values[point_indices]  b_i)\n        \n        current_interval_indices = np.array(point_indices)[interval_point_mask]\n        \n        clusters = get_clusters_in_interval(list(current_interval_indices), all_points, epsilon)\n        clusters_per_interval.append(clusters)\n\n    edge_counts = np.zeros(m - 1, dtype=int)\n    for i in range(m - 1):\n        clusters1 = clusters_per_interval[i]\n        clusters2 = clusters_per_interval[i+1]\n        count = 0\n        for c1 in clusters1:\n            set_c1 = set(c1)\n            for c2 in clusters2:\n                if not set_c1.isdisjoint(c2):\n                    count += 1\n        edge_counts[i] = count\n        \n    return edge_counts\n\ndef benjamini_hochberg(p_values, alpha):\n    \"\"\"Applies the Benjamini-Hochberg FDR control procedure.\"\"\"\n    n = len(p_values)\n    if n == 0:\n        return []\n    \n    p_values_array = np.array(p_values)\n    sorted_indices = np.argsort(p_values_array)\n    sorted_p_values = p_values_array[sorted_indices]\n    \n    k_vals = np.arange(1, n + 1)\n    thresholds = (k_vals / n) * alpha\n    \n    significant_mask = sorted_p_values = thresholds\n    \n    if np.any(significant_mask):\n        max_k = np.max(np.where(significant_mask))\n        significant_indices_sorted = sorted_indices[:max_k + 1]\n    else:\n        significant_indices_sorted = []\n        \n    result = np.zeros(n, dtype=bool)\n    result[significant_indices_sorted] = True\n    return result.tolist()\n\ndef run_case(params):\n    \"\"\"Runs the full analysis for a single test case.\"\"\"\n    N, shape_A, shape_B, m, o, epsilon, K, alpha, seed, prop_A = params\n    \n    rng = np.random.default_rng(seed)\n    \n    n_A = int(round(N * prop_A))\n    n_B = N - n_A\n    \n    points_A = generate_data(n_A, shape_A, 0.05, rng)\n    points_B = generate_data(n_B, shape_B, 0.05, rng)\n    \n    all_points = np.vstack([points_A, points_B])\n    labels = np.array([0] * n_A + [1] * n_B) # 0 for A, 1 for B\n    \n    indices_A = list(range(n_A))\n    indices_B = list(range(n_A, N))\n    \n    # Common filter for all computations\n    filter_values = get_pca_filter(all_points)\n    \n    # Observed statistic\n    E_A = compute_mapper_edges(indices_A, all_points, filter_values, m, o, epsilon)\n    E_B = compute_mapper_edges(indices_B, all_points, filter_values, m, o, epsilon)\n    T_obs = E_A - E_B\n    \n    # Null distribution from permutations\n    T_null = np.zeros((K, m - 1))\n    \n    # Use a separate RNG for permutations to ensure stability\n    perm_rng = np.random.default_rng(seed)\n\n    for k in range(K):\n        shuffled_labels = perm_rng.permutation(labels)\n        shuffled_indices_A = list(np.where(shuffled_labels == 0)[0])\n        shuffled_indices_B = list(np.where(shuffled_labels == 1)[0])\n        \n        E_A_shuffled = compute_mapper_edges(shuffled_indices_A, all_points, filter_values, m, o, epsilon)\n        E_B_shuffled = compute_mapper_edges(shuffled_indices_B, all_points, filter_values, m, o, epsilon)\n        T_null[k, :] = E_A_shuffled - E_B_shuffled\n        \n    # Empirical p-values\n    p_values = np.zeros(m - 1)\n    for i in range(m - 1):\n        num_more_extreme = np.sum(np.abs(T_null[:, i]) >= np.abs(T_obs[i]))\n        p_values[i] = (1 + num_more_extreme) / (K + 1)\n        \n    # FDR Control\n    return benjamini_hochberg(p_values, alpha)\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        # Case 1 (balanced, different shapes, happy path)\n        (180, 'circle', 'line', 8, 0.5, 0.15, 200, 0.10, 42, 0.5),\n        # Case 2 (imbalanced labels, different shapes, boundary)\n        (160, 'circle', 'line', 6, 0.4, 0.20, 150, 0.10, 123, 0.25),\n        # Case 3 (no difference, edge case)\n        (150, 'line', 'line', 5, 0.3, 0.20, 150, 0.10, 7, 0.5)\n    ]\n    \n    results = []\n    for case in test_cases:\n        result = run_case(case)\n        results.append(str(result).replace(\"'\", \"\")) # Remove single quotes\n    \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}