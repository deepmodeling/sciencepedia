## Applications and Interdisciplinary Connections

Now that we have grappled with the principles of constructing a Representational Dissimilarity Matrix, we might find ourselves asking a simple but profound question: "So what?" What good is this abstract checkerboard of numbers? The true beauty of the RDM is not as an end product, but as a tool—a kind of informational Rosetta Stone. It provides a common language, a shared format, in which we can express the structure of information from vastly different sources. Whether the information comes from the firing of a single neuron, the intricate dance of activity across a brain region, the layers of an artificial neural network, the judgment of a human mind, or a purely theoretical model, its representational geometry can be captured in an RDM. And once translated into this common language, these disparate worlds can finally speak to each other.

This chapter is a journey through the applications that this "translation" makes possible. We will see how the RDM allows us to look at the brain with a new kind of lens, how it builds bridges between minds and models, and how its principles extend even beyond the realm of neuroscience, offering a universal tool for understanding the nature of representation itself.

### A New Lens for Looking at the Brain

At its heart, Representational Similarity Analysis (RSA) is a method for testing hypotheses about how the brain works. Imagine you have a theory. Perhaps you hypothesize that the visual cortex represents faces based on their emotional expression. You can formalize this theory by building a *model RDM*, where the dissimilarity between any two faces is, say, the difference in their rated happiness. You then measure the brain's response to these same faces using fMRI and construct a *neural RDM* from the patterns of brain activity. The core of RSA is the comparison of these two matrices. If the pattern of dissimilarities in your theoretical model RDM matches the pattern of dissimilarities in the brain's RDM, you have found evidence that your theory holds water—that the brain region in question really does organize its representation of faces according to their emotional expression . This simple but powerful idea—of comparing the geometry of a model to the geometry of the brain—is the foundation of countless studies.

But what does this "geometry" actually look like? An RDM is a table of numbers, which is not very intuitive. To make it tangible, we can use visualization techniques. One powerful method is **Multidimensional Scaling (MDS)**. Starting from the dissimilarity values in an RDM, MDS attempts to place each stimulus as a point on a 2D or 3D "map" such that the distances between the points on the map correspond as closely as possible to the dissimilarities in the RDM . The result is a striking visualization of the "mind's space"—we can literally see which concepts the brain considers to be close together and which it places far apart. Another approach is **Hierarchical Clustering**, which uses the RDM to build a "family tree," or [dendrogram](@entry_id:634201), of the stimuli. It iteratively merges the two most similar stimuli or clusters, with the height of the merge representing their dissimilarity. The final tree reveals a nested taxonomy of how the brain categorizes the world, showing which items belong to tight-knit families and which are distant cousins .

These analyses can be performed on a specific, pre-defined brain region, but what if we don't know where to look? To answer this, we can turn the analysis into a microscope and scan the entire brain. This is the logic of **searchlight RSA**. Instead of using all the voxels in a large brain region, we take a small, spherical "searchlight" (a neighborhood of voxels) and center it on a single voxel. We compute a local RDM from the activity patterns just within that sphere and compare it to our model RDM. We then assign the resulting correlation value—the model fit—to that center voxel. By sliding this searchlight across every single voxel in the brain, we create a rich, whole-brain map that shows us *where* the [representational geometry](@entry_id:1130876) of our model is implemented . We are no longer asking *if* the brain represents a certain feature, but precisely *where* it does so.

Of course, the brain is not a static object; it is a dynamic, living system. Thoughts unfold in time. To capture this, we can apply RSA to time-resolved data from methods like Magnetoencephalography (MEG) or Electroencephalography (EEG). By computing an RDM at each millisecond, we can create a "movie" of the [representational geometry](@entry_id:1130876) as it evolves. By correlating these RDMs across time, we can build a **Temporal Generalization Matrix (TGM)**. This matrix reveals the dynamics of a neural code: a strong diagonal indicates a rapidly changing sequence of representations, while strong off-diagonal blocks reveal stable representations that are sustained over time  . We can watch as an initial sensory representation transforms into a more abstract, categorical one.

The remarkable flexibility of the RDM framework is that it scales across measurement modalities. While we can use it to understand the activity of millions of neurons at once with fMRI, we can also apply the very same logic to recordings from populations of individual neurons. By converting the spike trains of recorded neurons into feature vectors (for example, by counting spikes in different time bins), we can construct an RDM that captures the representational geometry at the single-cell level . This allows us to unify our understanding of neural coding across vast spatial and temporal scales.

### Bridging Minds, Models, and Machines

The power of the RDM as a "common language" truly shines when it is used to connect the brain to other complex systems.

Perhaps the most exciting dialogue is between neuroscience and artificial intelligence. Modern **Deep Neural Networks (DNNs)** trained on tasks like [object recognition](@entry_id:1129025) have shown a surprising ability to predict brain activity. RSA provides the perfect tool to investigate this correspondence. We can present the same set of images to both a human and a DNN. We construct a neural RDM from brain activity and, for each layer of the DNN, we can construct a model RDM from its unit activations. By comparing the brain's RDM to the RDMs from each network layer, we can ask: Which layer of the network best corresponds to a given brain region? Do the hierarchical stages of processing in the brain's [visual pathway](@entry_id:895544) map onto the successive layers of the network? RSA allows us to open up the "black box" of AI and place it in a direct, quantitative dialogue with the brain .

The RDM can also bridge the gap between objective neural measurements and subjective human experience. How similar do you find a cat and a dog? An apple and an orange? By collecting **behavioral similarity judgments** from people, we can construct a *behavioral RDM* that captures our conscious, perceptual sense of the world's structure. This behavioral RDM can then be compared to a neural RDM from the same individuals. If they match, we have found a neural correlate of our subjective reality . When combining data from many people, we must be careful. Simple averaging of dissimilarity scores might be misleading if different people use the rating scale differently. A more robust approach is to convert each person's dissimilarities to ranks first, and then average the ranks. This focuses on the shared ordinal structure across individuals, making the [group-level analysis](@entry_id:914439) more reliable .

Often, we don't have just one theory of how the brain works; we may have several competing models. For instance, the representation of animals in the brain could be based on their visual shape, their taxonomic category (mammal, insect), or even their perceived threat. Each of these theories can be turned into a model RDM. Instead of just comparing them one by one, **regression RSA** allows us to model the brain RDM as a weighted sum of all the model RDMs. By fitting this regression, we can estimate the unique contribution of each model, effectively asking the brain, "How much of your representation is explained by shape, and how much is explained by category?" This lets us adjudicate between theories and understand how different features contribute to a unified neural code .

Finally, we can scale up from individual regions to study the interactions between them. **Representational connectivity** is an approach that builds a network of the entire brain, not based on raw activity, but on shared information. In this graph, the nodes are brain regions, and the weight of the edge between any two regions is the similarity of their RDMs. A strong edge means two regions share a similar "view" of the world; they organize information in the same way. By analyzing this network, we can find "communities" or modules of brain regions that form functional networks, not because they are active at the same time, but because they are speaking the same representational language .

### Beyond the Brain: A Universal Tool

The abstract nature of the RDM means its usefulness is not confined to neuroscience. It is a universal tool for comparing the geometry of any system that represents information. This is powerfully demonstrated by its application in a completely different field: materials science and artificial intelligence. Imagine training a Graph Neural Network (GNN) to predict a property of battery materials, like their [formation energy](@entry_id:142642). Now, you want to transfer this knowledge to a new task, like predicting their [diffusion barrier](@entry_id:148409). Should you freeze the learned weights of the network, or fine-tune them? RSA can help decide. By computing RDMs from the network's internal [embeddings](@entry_id:158103) in both the "frozen" and "fine-tuned" states, and comparing them to an RDM of the target property (the [diffusion barriers](@entry_id:1123706)), we can quantify which layers benefit from [fine-tuning](@entry_id:159910). This turns RSA into a powerful tool for **AI [interpretability](@entry_id:637759)**, helping us understand how and where knowledge is stored inside a machine learning model and how to best adapt it to new problems .

### The Deeper Meaning of Dissimilarity

Throughout this journey, we have treated the RDM as a geometric object. But what does it mean for two patterns to be "dissimilar" in the brain? There is a beautiful and deep connection between the geometric view of RSA and the information-theoretic view of [neural decoding](@entry_id:899984). If we model the neural responses to two conditions as Gaussian distributions, it can be proven that the accuracy of an [optimal linear decoder](@entry_id:1129170) in telling the two conditions apart is a direct, [monotonic function](@entry_id:140815) of the **Mahalanobis distance** between their response patterns. The formula is beautifully simple: the accuracy is given by $\Phi(\sqrt{d^2}/2)$, where $d^2$ is the squared Mahalanobis distance and $\Phi$ is the [cumulative distribution function](@entry_id:143135) of the [standard normal distribution](@entry_id:184509) .

This formal link is the conceptual anchor for the entire RSA framework. It tells us that a larger dissimilarity in an RDM is not just a geometric quirk. It means that the underlying neural representations are more separable, more distinct, and contain more information that a downstream neural population could use to tell them apart. The geometry *is* the information. The RDM, our Rosetta Stone, does more than just translate; it reveals the very structure of knowledge as it is written into the fabric of biological and artificial minds.