{
    "hands_on_practices": [
        {
            "introduction": "Effective variant filtering requires navigating the fundamental trade-off between sensitivity and precision. This exercise provides a practical scenario to quantify filter performance by calculating key metrics like sensitivity, precision, and the $F_1$ score. By working through this problem, you will learn how to make an evidence-based decision to select an optimal quality threshold that balances the need to detect true variants against the cost of including false positives .",
            "id": "4340112",
            "problem": "In a benchmarking study for precision medicine and genomic diagnostics, you evaluate variant filtering thresholds applied to a somatic Single-Nucleotide Variant (SNV) call set against a curated ground-truth panel from Genome in a Bottle (GIAB). A calibrated filter based on the Phred-scaled variant quality score $q$ is applied at five candidate thresholds $q \\in \\{10, 20, 30, 40, 50\\}$. For each threshold, the comparison to the ground truth yields counts of true positives (TP), false positives (FP), and false negatives (FN). The ground-truth set contains $10{,}000$ true variants, so $\\text{TP} + \\text{FN} = 10{,}000$ at every threshold. The measured counts are as follows: at $q=10$, $\\text{TP}=9{,}800$, $\\text{FP}=1{,}300$, $\\text{FN}=200$; at $q=20$, $\\text{TP}=9{,}700$, $\\text{FP}=900$, $\\text{FN}=300$; at $q=30$, $\\text{TP}=9{,}500$, $\\text{FP}=600$, $\\text{FN}=500$; at $q=40$, $\\text{TP}=9{,}300$, $\\text{FP}=400$, $\\text{FN}=700$; at $q=50$, $\\text{TP}=9{,}000$, $\\text{FP}=280$, $\\text{FN}=1{,}000$. \n\nUse only foundational definitions to derive, for each threshold, the sensitivity (also called recall), the precision (also called Positive Predictive Value (PPV)), and the $F_1$ score, where the $F_1$ score is defined as the harmonic mean of precision and sensitivity. Then, subject to the minimum sensitivity requirement $S_{\\min}=0.95$ (i.e., sensitivity at least $0.95$), select the single threshold $q$ that maximizes the $F_1$ score among those that satisfy the sensitivity requirement. \n\nReport only the selected threshold $q$ as a pure number with no units, and do not round the final answer. All intermediate computations should be justified from first principles without invoking shortcut formulas.",
            "solution": "The problem is assessed to be valid as it is scientifically grounded in the principles of diagnostic test evaluation, is well-posed with a complete and consistent set of data and constraints, and seeks a determinate, objective answer. We may therefore proceed with a formal solution.\n\nThe problem requires the evaluation of five variant filtering thresholds, $q \\in \\{10, 20, 30, 40, 50\\}$, based on their performance metrics, which are derived from the counts of true positives ($\\text{TP}$), false positives ($\\text{FP}$), and false negatives ($\\text{FN}$). The total number of true variants in the ground-truth set is constant, $N = \\text{TP} + \\text{FN} = 10{,}000$.\n\nFirst, we define the required performance metrics.\nSensitivity ($S$), also known as recall, is the fraction of true variants that are correctly identified by the filter. It is defined as:\n$$S = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$\nPrecision ($P$), also known as the Positive Predictive Value (PPV), is the fraction of called variants that are true. It is defined as:\n$$P = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\nThe $F_1$ score is the harmonic mean of sensitivity and precision, given by:\n$$F_1 = 2 \\cdot \\frac{P \\cdot S}{P + S}$$\nFor computational convenience, we can express the $F_1$ score directly in terms of $\\text{TP}$, $\\text{FP}$, and $\\text{FN}$. Substituting the definitions of $P$ and $S$ into the $F_1$ formula yields:\n$$F_1 = 2 \\cdot \\frac{\\left(\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\\right) \\left(\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\\right)}{\\frac{\\text{TP}}{\\text{TP} + \\text{FP}} + \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}} = \\frac{2 \\cdot \\text{TP}}{\\left(\\text{TP} + \\text{FP}\\right) + \\left(\\text{TP} + \\text{FN}\\right)} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}}$$\nWe will now calculate the sensitivity and $F_1$ score for each candidate threshold $q$.\n\nFor $q=10$:\nThe given counts are $\\text{TP}_{10} = 9{,}800$, $\\text{FP}_{10} = 1{,}300$, and $\\text{FN}_{10} = 200$.\nThe sensitivity is $S_{10} = \\frac{9{,}800}{9{,}800 + 200} = \\frac{9{,}800}{10{,}000} = 0.98$.\nThe $F_1$ score is $F_{1,10} = \\frac{2 \\cdot 9{,}800}{2 \\cdot 9{,}800 + 1{,}300 + 200} = \\frac{19{,}600}{19{,}600 + 1{,}500} = \\frac{19{,}600}{21{,}100} = \\frac{196}{211}$.\n\nFor $q=20$:\nThe given counts are $\\text{TP}_{20} = 9{,}700$, $\\text{FP}_{20} = 900$, and $\\text{FN}_{20} = 300$.\nThe sensitivity is $S_{20} = \\frac{9{,}700}{9{,}700 + 300} = \\frac{9{,}700}{10{,}000} = 0.97$.\nThe $F_1$ score is $F_{1,20} = \\frac{2 \\cdot 9{,}700}{2 \\cdot 9{,}700 + 900 + 300} = \\frac{19{,}400}{19{,}400 + 1{,}200} = \\frac{19{,}400}{20{,}600} = \\frac{194}{206} = \\frac{97}{103}$.\n\nFor $q=30$:\nThe given counts are $\\text{TP}_{30} = 9{,}500$, $\\text{FP}_{30} = 600$, and $\\text{FN}_{30} = 500$.\nThe sensitivity is $S_{30} = \\frac{9{,}500}{9{,}500 + 500} = \\frac{9{,}500}{10{,}000} = 0.95$.\nThe $F_1$ score is $F_{1,30} = \\frac{2 \\cdot 9{,}500}{2 \\cdot 9{,}500 + 600 + 500} = \\frac{19{,}000}{19{,}000 + 1{,}100} = \\frac{19{,}000}{20{,}100} = \\frac{190}{201}$.\n\nFor $q=40$:\nThe given counts are $\\text{TP}_{40} = 9{,}300$, $\\text{FP}_{40} = 400$, and $\\text{FN}_{40} = 700$.\nThe sensitivity is $S_{40} = \\frac{9{,}300}{9{,}300 + 700} = \\frac{9{,}300}{10{,}000} = 0.93$.\nThe $F_1$ score is $F_{1,40} = \\frac{2 \\cdot 9{,}300}{2 \\cdot 9{,}300 + 400 + 700} = \\frac{18{,}600}{18{,}600 + 1{,}100} = \\frac{18{,}600}{19{,}700} = \\frac{186}{197}$.\n\nFor $q=50$:\nThe given counts are $\\text{TP}_{50} = 9{,}000$, $\\text{FP}_{50} = 280$, and $\\text{FN}_{50} = 1{,}000$.\nThe sensitivity is $S_{50} = \\frac{9{,}000}{9{,}000 + 1{,}000} = \\frac{9{,}000}{10{,}000} = 0.90$.\nThe $F_1$ score is $F_{1,50} = \\frac{2 \\cdot 9{,}000}{2 \\cdot 9{,}000 + 280 + 1{,}000} = \\frac{18{,}000}{18{,}000 + 1{,}280} = \\frac{18{,}000}{19{,}280} = \\frac{450}{482} = \\frac{225}{241}$.\n\nNext, we apply the selection criteria. The first criterion is a minimum sensitivity requirement of $S_{\\min} = 0.95$. We evaluate each threshold against this constraint:\n- $S_{10} = 0.98 \\ge 0.95$: Threshold $q=10$ is retained.\n- $S_{20} = 0.97 \\ge 0.95$: Threshold $q=20$ is retained.\n- $S_{30} = 0.95 \\ge 0.95$: Threshold $q=30$ is retained.\n- $S_{40} = 0.93  0.95$: Threshold $q=40$ is rejected.\n- $S_{50} = 0.90  0.95$: Threshold $q=50$ is rejected.\n\nThe set of candidate thresholds is thus reduced to $\\{10, 20, 30\\}$. The second criterion is to select the threshold from this set that maximizes the $F_1$ score. We must compare $F_{1,10}$, $F_{1,20}$, and $F_{1,30}$.\nThe values to compare are:\n$F_{1,10} = \\frac{196}{211}$\n$F_{1,20} = \\frac{97}{103}$\n$F_{1,30} = \\frac{190}{201}$\n\nWe compare $F_{1,10}$ and $F_{1,20}$ by cross-multiplication:\n$196 \\times 103 = 20{,}188$\n$97 \\times 211 = 20{,}467$\nSince $20{,}467 > 20{,}188$, we have $\\frac{97}{103} > \\frac{196}{211}$, so $F_{1,20} > F_{1,10}$.\n\nNext, we compare the larger value, $F_{1,20}$, with $F_{1,30}$:\n$97 \\times 201 = 19{,}497$\n$190 \\times 103 = 19{,}570$\nSince $19{,}570 > 19{,}497$, we have $\\frac{190}{201} > \\frac{97}{103}$, so $F_{1,30} > F_{1,20}$.\n\nThe ordering of the $F_1$ scores for the eligible thresholds is $F_{1,30} > F_{1,20} > F_{1,10}$. The maximum $F_1$ score is achieved at the threshold $q=30$.\nTherefore, the optimal threshold according to the specified criteria is $30$.",
            "answer": "$$\\boxed{30}$$"
        },
        {
            "introduction": "One of the most powerful filters in genomic analysis, particularly for rare diseases, is a variant's frequency in the general population. This practice challenges you to apply principles of population genetics to a clinical scenario, deriving a maximum credible allele frequency threshold based on disease prevalence, penetrance, and genetic heterogeneity. Mastering this calculation is essential for correctly interpreting variants according to established guidelines and distinguishing rare pathogenic alleles from common, benign polymorphisms .",
            "id": "4340090",
            "problem": "A clinical genetics team is evaluating a single-nucleotide variant observed in the Genome Aggregation Database (gnomAD). The disease of interest is autosomal dominant, with population prevalence $P = 1 \\times 10^{-4}$, and the variant has incomplete penetrance in heterozygotes, with penetrance $f = 0.8$. The disease is genetically heterogeneous across multiple genes; the gene harboring this variant is estimated to account for a fraction $g = 0.2$ of all cases. Within that gene, no single pathogenic variant is expected to account for more than a fraction $a = 0.05$ of cases in that gene. Assume Hardy–Weinberg equilibrium and that the allele frequency $p$ is sufficiently small that the homozygote frequency is negligible compared to the heterozygote frequency.\n\nThe ancestry-specific allele frequencies from gnomAD are:\n- African/African American: $3.3 \\times 10^{-6}$\n- Latino/Admixed American: $2.8 \\times 10^{-6}$\n- Non-Finnish European: $1.1 \\times 10^{-6}$\n- East Asian: $8.2 \\times 10^{-7}$\n- South Asian: $9.5 \\times 10^{-7}$\n\nThe overall gnomAD allele frequency is $1.9 \\times 10^{-6}$, but for clinical filtering you must consider the highest ancestry-specific frequency rather than the overall frequency.\n\nStarting from fundamental definitions, use Hardy–Weinberg genotype frequencies and penetrance to derive an inequality ensuring that the expected prevalence contributed by one variant does not exceed its maximal allowed share of disease prevalence given $g$ and $a$. From this inequality, obtain the maximum credible allele frequency threshold $p_{\\max}$ for a single autosomal dominant variant under these assumptions.\n\nThen, compute the ratio $R$ of the largest ancestry-specific observed allele frequency to $p_{\\max}$. Round your final numeric answer for $R$ to four significant figures. Express your final answer as a pure number with no units.",
            "solution": "The foundational starting point is the Hardy–Weinberg equilibrium for a bi-allelic locus with allele frequency $p$ for the variant and $q = 1 - p$ for the reference allele. The genotype frequencies are $p^{2}$ (homozygous variant), $2pq$ (heterozygous), and $q^{2}$ (homozygous reference). For a rare variant, $p \\ll 1$, so $q \\approx 1$ and $2pq \\approx 2p$, while $p^{2}$ is negligible compared to $2p$.\n\nFor an autosomal dominant disorder with penetrance $f$ in heterozygotes (and with homozygotes exceedingly rare when $p$ is small), the expected proportion of the population affected due to this single variant is\n$$\n\\text{variant-contributed prevalence} \\approx f \\left(2p(1-p) + p^{2}\\right).\n$$\nFor small $p$, $2p(1-p) + p^{2} = 2p - p^{2} \\approx 2p$, so\n$$\n\\text{variant-contributed prevalence} \\approx 2 f p.\n$$\n\nThe total disease prevalence is $P$. Genetic heterogeneity implies that the gene containing this variant accounts for a fraction $g$ of cases. Within that gene, the maximum allelic contribution $a$ indicates that no single variant accounts for more than an $a$ fraction of cases attributable to the gene. Therefore, the maximal allowed prevalence attributable to any one variant in this gene is\n$$\n\\text{allowed variant prevalence} = a \\cdot g \\cdot P.\n$$\n\nTo ensure that the variant is not too common to be a plausible cause of a dominant disease under these assumptions, we require\n$$\nf \\left(2p(1-p) + p^{2}\\right) \\leq a g P.\n$$\nUsing the small-$p$ approximation, this simplifies to\n$$\n2 f p \\leq a g P.\n$$\nSolving for $p$ yields the maximum credible allele frequency threshold:\n$$\np_{\\max} = \\frac{a g P}{2 f}.\n$$\n\nInsert the given values $a = 0.05$, $g = 0.2$, $P = 1 \\times 10^{-4}$, and $f = 0.8$:\n$$\na g P = 0.05 \\times 0.2 \\times 1 \\times 10^{-4} = 1 \\times 10^{-6},\n$$\nand\n$$\n2 f = 1.6.\n$$\nTherefore,\n$$\np_{\\max} = \\frac{1 \\times 10^{-6}}{1.6} = 6.25 \\times 10^{-7}.\n$$\n\nWe must compare ancestry-specific observed allele frequencies to $p_{\\max}$ using the highest ancestry-specific frequency. From the provided values, the largest ancestry-specific allele frequency is African/African American at $3.3 \\times 10^{-6}$. Define the ratio\n$$\nR = \\frac{\\max\\{\\text{ancestry-specific AF}\\}}{p_{\\max}} = \\frac{3.3 \\times 10^{-6}}{6.25 \\times 10^{-7}}.\n$$\nCompute $R$:\n$$\nR = \\frac{3.3}{0.625} = 5.28.\n$$\n\nRound $R$ to four significant figures:\n$$\nR \\approx 5.280.\n$$\n\nNote on approximation validity: at $p_{\\max} \\approx 6.25 \\times 10^{-7}$, the squared term $p^{2} \\approx 3.90625 \\times 10^{-13}$ is negligible relative to $2p \\approx 1.25 \\times 10^{-6}$, justifying the use of the small-$p$ approximation.",
            "answer": "$$\\boxed{5.280}$$"
        },
        {
            "introduction": "While simple \"hard filters\" on individual metrics are common, a more sophisticated approach involves probabilistically integrating multiple lines of evidence. This advanced problem introduces a Bayesian framework for variant quality control, mirroring the logic behind tools like GATK's Variant Quality Score Recalibration (VQSR). You will use Bayes’ theorem to calculate a variant's posterior probability of being a true positive by combining a prior belief with observed data from orthogonal metrics like Quality by Depth ($QD$) and Fisher Strand bias ($FS$) .",
            "id": "4340151",
            "problem": "A clinical laboratory is assessing whether to report a single nucleotide variant in a clinically actionable gene, observed in a tumor sample. The laboratory performs quality control using two orthogonal metrics: Quality by Depth ($QD$) and Fisher Strand bias ($FS$). Quality by Depth ($QD$) is the variant quality score normalized by read depth, and Fisher Strand bias ($FS$) is the Phred-scaled Fisher's exact test statistic for strand bias. Based on prior gene-level evidence and case phenotype, the laboratory assigns a prior probability $P(T)$ that the call is a true positive (a real biological variant) of $P(T) = 0.40$. The prior probability that the call is an artifact is therefore $P(A) = 1 - P(T)$.\n\nFrom calibration against Genome in a Bottle (GIAB) truth sets and orthogonal validation, the laboratory has estimated the following conditional distributions for these metrics:\n\n- For true positives, $QD$ is modeled as a Gaussian (normal) distribution with mean $\\mu_{QD,T} = 18$ and standard deviation $\\sigma_{QD,T} = 3$, and $FS$ is modeled as a log-normal distribution with $\\ln(FS)$ having mean $\\mu_{\\ln FS,T} = 2.5$ and standard deviation $\\sigma_{\\ln FS,T} = 0.6$.\n\n- For artifacts, $QD$ is modeled as a Gaussian distribution with mean $\\mu_{QD,A} = 10$ and standard deviation $\\sigma_{QD,A} = 2$, and $FS$ is modeled as a log-normal distribution with $\\ln(FS)$ having mean $\\mu_{\\ln FS,A} = 3.5$ and standard deviation $\\sigma_{\\ln FS,A} = 0.7$.\n\nAssume that, conditional on truth status (true positive versus artifact), the metrics $QD$ and $FS$ are independent. The observed metrics for this variant are $QD = 12$ and $FS = 35$.\n\nUsing Bayes’ theorem and the stated models, compute the adjusted posterior probability $P(T \\mid QD = 12, FS = 35)$ that the call is a true positive. The laboratory’s reporting policy is to report the variant if and only if the posterior probability is at least $0.95$. Provide the posterior probability as a decimal fraction. Round your answer to four significant figures. No units are required.",
            "solution": "The problem requires the computation of the posterior probability that a genomic variant call is a true positive, given measurements from two quality control metrics, $QD$ and $FS$. This is a classic application of Bayes' theorem.\n\nLet $T$ be the event that the variant call is a true positive, and $A$ be the event that it is an artifact. Let $D$ represent the observed data, which consists of the measured values $QD_{obs} = 12$ and $FS_{obs} = 35$. We are asked to compute the posterior probability $P(T \\mid D) = P(T \\mid QD=12, FS=35)$.\n\nAccording to Bayes' theorem, the posterior probability is given by:\n$$ P(T \\mid D) = \\frac{P(D \\mid T) P(T)}{P(D)} $$\n\nThe denominator, $P(D)$, is the marginal probability of the evidence, which can be expressed using the law of total probability:\n$$ P(D) = P(D \\mid T) P(T) + P(D \\mid A) P(A) $$\nThus, the full formula for the posterior probability is:\n$$ P(T \\mid D) = \\frac{P(D \\mid T) P(T)}{P(D \\mid T) P(T) + P(D \\mid A) P(A)} $$\n\nThe problem provides the prior probabilities:\n- Prior probability of a true positive: $P(T) = 0.40$\n- Prior probability of an artifact: $P(A) = 1 - P(T) = 1 - 0.40 = 0.60$\n\nThe terms $P(D \\mid T)$ and $P(D \\mid A)$ are the likelihoods of observing the data given that the variant is a true positive or an artifact, respectively. Since $QD$ and $FS$ are continuous variables, we use their probability density functions (PDFs), which we will denote by $f(\\cdot)$.\n\nThe problem states that, conditional on the truth status, $QD$ and $FS$ are independent. Therefore, the joint likelihood is the product of the individual likelihoods:\n$$ P(D \\mid C) = f(QD=12, FS=35 \\mid C) = f_{QD}(12 \\mid C) \\cdot f_{FS}(35 \\mid C) $$\nwhere $C$ can be either $T$ or $A$.\n\nWe now calculate the four required density values.\n\n**1. Likelihood components for a True Positive (T):**\n- **Metric $QD$:** The distribution is Gaussian, $QD \\mid T \\sim \\mathcal{N}(\\mu_{QD,T} = 18, \\sigma_{QD,T}^2 = 3^2)$. The PDF is $f(q) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(q-\\mu)^2}{2\\sigma^2}\\right)$. At $q=12$:\n$$ f_{QD}(12 \\mid T) = \\frac{1}{3\\sqrt{2\\pi}} \\exp\\left(-\\frac{(12-18)^2}{2 \\cdot 3^2}\\right) = \\frac{1}{3\\sqrt{2\\pi}} \\exp\\left(-\\frac{36}{18}\\right) = \\frac{1}{3\\sqrt{2\\pi}} \\exp(-2) $$\n- **Metric $FS$:** The distribution is Log-normal, meaning $\\ln(FS) \\mid T \\sim \\mathcal{N}(\\mu_{\\ln FS,T} = 2.5, \\sigma_{\\ln FS,T}^2 = 0.6^2)$. The PDF is $f(f) = \\frac{1}{f\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(f)-\\mu)^2}{2\\sigma^2}\\right)$. At $f=35$:\n$$ f_{FS}(35 \\mid T) = \\frac{1}{35 \\cdot 0.6 \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(35)-2.5)^2}{2 \\cdot 0.6^2}\\right) = \\frac{1}{21\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(35)-2.5)^2}{0.72}\\right) $$\nThe total likelihood for a true positive is $L_T = P(D \\mid T) = f_{QD}(12 \\mid T) \\cdot f_{FS}(35 \\mid T)$.\n$$ L_T = \\left(\\frac{1}{3\\sqrt{2\\pi}} \\exp(-2)\\right) \\left(\\frac{1}{21\\sqrt{2\\pi}}\\right) \\exp\\left(-\\frac{(\\ln(35)-2.5)^2}{0.72}\\right) = \\frac{1}{63 \\cdot 2\\pi} \\exp\\left(-2 - \\frac{(\\ln(35)-2.5)^2}{0.72}\\right) $$\n\n**2. Likelihood components for an Artifact (A):**\n- **Metric $QD$:** The distribution is Gaussian, $QD \\mid A \\sim \\mathcal{N}(\\mu_{QD,A} = 10, \\sigma_{QD,A}^2 = 2^2)$. At $q=12$:\n$$ f_{QD}(12 \\mid A) = \\frac{1}{2\\sqrt{2\\pi}} \\exp\\left(-\\frac{(12-10)^2}{2 \\cdot 2^2}\\right) = \\frac{1}{2\\sqrt{2\\pi}} \\exp\\left(-\\frac{4}{8}\\right) = \\frac{1}{2\\sqrt{2\\pi}} \\exp(-0.5) $$\n- **Metric $FS$:** The distribution is Log-normal, meaning $\\ln(FS) \\mid A \\sim \\mathcal{N}(\\mu_{\\ln FS,A} = 3.5, \\sigma_{\\ln FS,A}^2 = 0.7^2)$. At $f=35$:\n$$ f_{FS}(35 \\mid A) = \\frac{1}{35 \\cdot 0.7 \\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(35)-3.5)^2}{2 \\cdot 0.7^2}\\right) = \\frac{1}{24.5\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\ln(35)-3.5)^2}{0.98}\\right) $$\nThe total likelihood for an artifact is $L_A = P(D \\mid A) = f_{QD}(12 \\mid A) \\cdot f_{FS}(35 \\mid A)$.\n$$ L_A = \\left(\\frac{1}{2\\sqrt{2\\pi}} \\exp(-0.5)\\right) \\left(\\frac{1}{24.5\\sqrt{2\\pi}}\\right) \\exp\\left(-\\frac{(\\ln(35)-3.5)^2}{0.98}\\right) = \\frac{1}{49 \\cdot 2\\pi} \\exp\\left(-0.5 - \\frac{(\\ln(35)-3.5)^2}{0.98}\\right) $$\n\n**3. Numerical evaluation and calculation of the posterior probability:**\nWe have the priors $P(T)=0.4$ and $P(A)=0.6$. Now we substitute numerical values. We use $\\ln(35) \\approx 3.555348$.\n- Numerator term: $P(D \\mid T) P(T) = L_T \\cdot P(T)$\nExponent for $L_T$: $-2 - \\frac{(3.555348 - 2.5)^2}{0.72} \\approx -2 - 1.546889 = -3.546889$.\n$L_T = \\frac{1}{126\\pi} \\exp(-3.546889) \\approx \\frac{1}{395.84} \\cdot 0.028816 \\approx 7.2796 \\times 10^{-5}$.\n$P(D \\mid T) P(T) \\approx (7.2796 \\times 10^{-5}) \\cdot 0.4 = 2.9118 \\times 10^{-5}$.\n\n- Denominator term for A: $P(D \\mid A) P(A) = L_A \\cdot P(A)$\nExponent for $L_A$: $-0.5 - \\frac{(3.555348 - 3.5)^2}{0.98} \\approx -0.5 - 0.003126 = -0.503126$.\n$L_A = \\frac{1}{98\\pi} \\exp(-0.503126) \\approx \\frac{1}{307.88} \\cdot 0.60464 \\approx 1.9642 \\times 10^{-3}$.\n$P(D \\mid A) P(A) \\approx (1.9642 \\times 10^{-3}) \\cdot 0.6 = 1.1785 \\times 10^{-3}$.\n\nNow, we compute the posterior probability:\n$$ P(T \\mid D) = \\frac{P(D \\mid T) P(T)}{P(D \\mid T) P(T) + P(D \\mid A) P(A)} \\approx \\frac{2.9118 \\times 10^{-5}}{2.9118 \\times 10^{-5} + 1.1785 \\times 10^{-3}} $$\n$$ P(T \\mid D) \\approx \\frac{2.9118 \\times 10^{-5}}{1.2076 \\times 10^{-3}} \\approx 0.02411685 $$\n\nRounding the result to four significant figures gives $0.02412$. This very low probability indicates that the variant is overwhelmingly likely to be an artifact, based on the provided data and models.",
            "answer": "$$\\boxed{0.02412}$$"
        }
    ]
}