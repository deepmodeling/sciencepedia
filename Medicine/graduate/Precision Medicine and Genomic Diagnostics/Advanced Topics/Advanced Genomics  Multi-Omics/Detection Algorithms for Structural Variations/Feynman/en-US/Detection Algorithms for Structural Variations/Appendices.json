{
    "hands_on_practices": [
        {
            "introduction": "Read-depth analysis is a cornerstone of copy number variation (CNV) detection, relying on the principle that the number of sequencing reads in a region is proportional to its copy number. This exercise  provides foundational practice in converting an observed change in read coverage into a standardized statistical score. By working from the first principles of a Poisson data model, you will see how a raw signal is transformed into a quantifiable measure of deviation, a critical first step for any read-depth based SV caller.",
            "id": "4332052",
            "problem": "A read-depth based structural variation detector standardizes windowed counts using a normal approximation rooted in a Poisson sampling model. Assume a whole-genome sequencing experiment with uniform mappability and independent coverage across base pairs, where per-base coverage is modeled as a Poisson random variable with mean $\\lambda$ and variance $\\lambda$. Let the genome-wide mean coverage be $30\\times$, i.e., $\\lambda = 30$. Consider a window of length $100\\,\\text{kb}$, where $1\\,\\text{kb} = 10^{3}$ base pairs, and suppose the observed mean coverage in this window is reduced by $0.15$ relative to the genome-wide mean, yielding an observed mean coverage of $0.85 \\times 30$ in the window.\n\nStarting from the fundamental properties of the Poisson distribution (mean and variance equality) and the additivity of independent Poisson variables across base pairs, derive the standardized normal score (z-score) for the total coverage in this window under the null hypothesis that the window’s coverage follows the genome-wide mean. Use the central limit theorem justification for the normal approximation of the sum of independent Poisson variables when the window length is large.\n\nExpress your final z-score as a real number rounded to four significant figures. No units are required.",
            "solution": "The problem statement has been evaluated and is deemed valid. It is scientifically grounded in standard biostatistical models for genomic data, is well-posed, and provides all necessary information for a unique solution.\n\nThe objective is to compute the standardized normal score (z-score) for the total read coverage observed in a specified genomic window. The z-score is a measure of how many standard deviations an observation is from the mean of a distribution. It is defined as:\n$$Z = \\frac{X - \\mu}{\\sigma}$$\nwhere $X$ is the observed value, $\\mu$ is the expected value (mean) under the null hypothesis, and $\\sigma$ is the standard deviation under the null hypothesis.\n\nFirst, we must define the random variable of interest and its distribution under the null hypothesis, $H_0$. The null hypothesis states that the genomic window in question has a coverage profile identical to the genome-wide average.\n\nLet $C_i$ be the random variable representing the number of reads covering base pair $i$. According to the problem statement, $C_i$ follows a Poisson distribution with a mean and variance equal to the genome-wide mean coverage, $\\lambda$.\n$$C_i \\sim \\text{Poisson}(\\lambda)$$\nThe givens state that $\\lambda = 30$. Therefore, for each base pair $i$:\n$$E[C_i] = \\lambda = 30$$\n$$\\text{Var}(C_i) = \\lambda = 30$$\n\nThe problem considers a window of length $L = 100\\,\\text{kb}$. We convert this length to base pairs (bp):\n$$L = 100\\,\\text{kb} \\times \\frac{10^3\\,\\text{bp}}{1\\,\\text{kb}} = 100 \\times 10^3\\,\\text{bp} = 10^5\\,\\text{bp}$$\n\nThe total coverage in the window, which we denote as $T$, is the sum of the coverages at each base pair within that window. Assuming the coverage at each base pair is independent, as stated in the problem:\n$$T = \\sum_{i=1}^{L} C_i$$\n\nA fundamental property of the Poisson distribution is that the sum of independent Poisson random variables is also a Poisson random variable, with a mean equal to the sum of the individual means. Under the null hypothesis, all $C_i$ are independent and identically distributed (i.i.d.) with parameter $\\lambda$. Therefore, the total coverage $T$ follows a Poisson distribution with parameter $L\\lambda$.\n$$T \\sim \\text{Poisson}(L\\lambda)$$\n\nThe mean ($\\mu_T$) and variance ($\\sigma_T^2$) of the total coverage $T$ under the null hypothesis are:\n$$\\mu_T = E[T] = L\\lambda$$\n$$\\sigma_T^2 = \\text{Var}(T) = L\\lambda$$\nThe standard deviation ($\\sigma_T$) is the square root of the variance:\n$$\\sigma_T = \\sqrt{L\\lambda}$$\n\nWe can now substitute the given values:\n$$\\mu_T = (10^5) \\times (30) = 3 \\times 10^6$$\n$$\\sigma_T = \\sqrt{(10^5) \\times (30)} = \\sqrt{3 \\times 10^6} = \\sqrt{3} \\times 10^3$$\n\nThe problem states that we should use the central limit theorem (CLT) to justify a normal approximation. For a sufficiently large value of the Poisson parameter $L\\lambda$, the Poisson distribution $\\text{Poisson}(L\\lambda)$ can be accurately approximated by a normal distribution with the same mean and variance, $\\mathcal{N}(L\\lambda, L\\lambda)$. In our case, $L\\lambda = 3 \\times 10^6$, which is a very large number, making the normal approximation exceptionally accurate.\n\nNext, we must determine the observed total coverage in the window, which we denote $T_{\\text{obs}}$. The problem states that the observed *mean* coverage in the window is $0.85$ times the genome-wide mean of $30$.\n$$\\text{Observed mean coverage} = 0.85 \\times 30 = 25.5$$\nThe total observed coverage is this mean coverage multiplied by the window length $L$:\n$$T_{\\text{obs}} = (\\text{Observed mean coverage}) \\times L = 25.5 \\times 10^5 = 2.55 \\times 10^6$$\n\nFinally, we calculate the z-score for the total coverage. We use the formula for $Z$ with our calculated values for the observed total coverage ($T_{\\text{obs}}$), the expected total coverage under $H_0$ ($\\mu_T$), and the standard deviation of total coverage under $H_0$ ($\\sigma_T$):\n$$Z = \\frac{T_{\\text{obs}} - \\mu_T}{\\sigma_T}$$\n$$Z = \\frac{2.55 \\times 10^6 - 3 \\times 10^6}{\\sqrt{3} \\times 10^3}$$\n$$Z = \\frac{-0.45 \\times 10^6}{\\sqrt{3} \\times 10^3}$$\n$$Z = \\frac{-4.5 \\times 10^5}{\\sqrt{3} \\times 10^3}$$\n$$Z = \\frac{-450}{\\sqrt{3}}$$\n\nTo obtain the numerical value, we can rationalize the denominator or compute the value directly:\n$$Z = \\frac{-450}{\\sqrt{3}} = \\frac{-450\\sqrt{3}}{3} = -150\\sqrt{3}$$\nUsing the approximate value $\\sqrt{3} \\approx 1.7320508$:\n$$Z \\approx -150 \\times 1.7320508 \\approx -259.80762$$\nThe problem requires the answer to be rounded to four significant figures.\n$$Z \\approx -259.8$$\nThis z-score indicates that the observed total coverage in the window is approximately $259.8$ standard deviations below the expected coverage under the null hypothesis, which represents an extremely significant deviation.",
            "answer": "$$\\boxed{-259.8}$$"
        },
        {
            "introduction": "While basic SV detection operates on idealized models, real-world precision medicine often involves analyzing complex, heterogeneous tumor samples. In these cases, observed signals like read depth and B-allele frequency (BAF) are a composite mixture from normal cells and various tumor subclones. This advanced practice  challenges you to build a quantitative \"forward model\" to predict the expected genomic signals from a tumor with a specific subclonal architecture, a skill essential for developing algorithms that infer tumor composition from patient data.",
            "id": "4332078",
            "problem": "A sequencing-based structural variation caller integrates read depth and B-allele frequency to infer copy-number states in heterogeneous tumor samples. Consider a tumor-normal mixture with tumor purity $p=0.6$ (that is, tumor cell fraction $0.6$ and normal cell fraction $0.4$), where the normal cells are diploid and the tumor’s baseline ploidy is $3$. At a locus containing a germline heterozygous Single Nucleotide Polymorphism (SNP) with alleles $A$ and $B$, assume the following biology: the clonal baseline tumor genotype at this locus is $AAB$ (that is, total copy number $3$ with one $B$ copy), and a single-copy gain subclone affecting $40\\%$ of tumor cells duplicates the $A$ allele at this locus, producing an $AAAB$ genotype (that is, total copy number $4$ with one $B$ copy) in that subclone. The remaining $60\\%$ of tumor cells retain the $AAB$ state. Normal cells are $AB$ at the locus (that is, total copy number $2$ with one $B$ copy). Assume no allelic mapping bias, uniform per-copy sequencing yield, and that expected read depth is proportional to total copy number.\n\nUsing only the fundamental definitions that (i) expected read depth at a locus is proportional to the expected total copy number contributed by all cells, and (ii) B-allele frequency (BAF) is the ratio of the expected number of reads from the $B$ allele to the expected total reads at the locus under uniform per-copy yield, derive the expected read-depth ratio $R$ at this locus (defined as tumor expected read depth divided by the matched-normal expected read depth) and the expected B-allele frequency at this locus in the tumor-normal mixture. Express your final numerical answers rounded to four significant figures. Do not include units in your final answer.",
            "solution": "We start from the definitions and mixture composition. Let $p$ be the tumor fraction, so the normal fraction is $1-p$. The tumor baseline ploidy at the locus is $3$ with genotype $AAB$ (one $B$ copy), and a subclone comprising $0.4$ of tumor cells gains one additional $A$ copy, resulting in genotype $AAAB$ (still one $B$ copy but total copy number $4$). The remaining $0.6$ of tumor cells remain $AAB$. Normal cells are diploid with genotype $AB$ (one $B$ copy).\n\nBy the assumption of uniform per-copy sequencing yield, expected read depth at a locus is proportional to expected total copy number, and expected reads from allele $B$ are proportional to the expected number of $B$ copies.\n\nDefine the absolute fractions of each cellular compartment in the sample:\n- Normal cells: fraction $f_{N} = 1-p$.\n- Tumor cells without gain: fraction $f_{T,3} = p \\times 0.6$.\n- Tumor cells with gain: fraction $f_{T,4} = p \\times 0.4$.\n\nWith $p=0.6$, these are\n$$\nf_{N} = 0.4,\\quad f_{T,3} = 0.6 \\times 0.6 = 0.36,\\quad f_{T,4} = 0.6 \\times 0.4 = 0.24.\n$$\n\nLet $C_{i}$ denote total copy number and $B_{i}$ denote the number of $B$-allele copies in compartment $i$. By the problem setup,\n- Normal: $C_{N} = 2$, $B_{N} = 1$.\n- Tumor without gain ($AAB$): $C_{T,3} = 3$, $B_{T,3} = 1$.\n- Tumor with gain ($AAAB$): $C_{T,4} = 4$, $B_{T,4} = 1$.\n\n1) Expected read-depth ratio $R$.\n\nThe expected total copy number per cell in the mixed sample is the weighted average\n$$\n\\overline{C} \\equiv f_{N} C_{N} + f_{T,3} C_{T,3} + f_{T,4} C_{T,4}.\n$$\nSubstituting values,\n$$\n\\overline{C} = 0.4 \\times 2 + 0.36 \\times 3 + 0.24 \\times 4 = 0.8 + 1.08 + 0.96 = 2.84.\n$$\nA matched-normal sample at this locus has expected total copy number $2$. With equal per-copy yield and appropriate global normalization, the expected read-depth ratio is the ratio of expected copy numbers,\n$$\nR = \\frac{\\overline{C}}{2} = \\frac{2.84}{2} = 1.42.\n$$\n\n2) Expected B-allele frequency.\n\nBy definition, B-allele frequency is the ratio of expected reads from $B$ to expected total reads. Under uniform per-copy yield, this equals the ratio of the expected number of $B$ copies to the expected total copy number in the mixture:\n$$\n\\text{BAF} = \\frac{\\overline{B}}{\\overline{C}},\n$$\nwhere\n$$\n\\overline{B} \\equiv f_{N} B_{N} + f_{T,3} B_{T,3} + f_{T,4} B_{T,4}.\n$$\nSubstituting values,\n$$\n\\overline{B} = 0.4 \\times 1 + 0.36 \\times 1 + 0.24 \\times 1 = 0.4 + 0.36 + 0.24 = 1.0.\n$$\nThus,\n$$\n\\text{BAF} = \\frac{1.0}{2.84} \\approx 0.3521126761\\ldots\n$$\nRounded to four significant figures,\n$$\nR = 1.420,\\quad \\text{BAF} = 0.3521.\n$$\nThese are dimensionless quantities as required.",
            "answer": "$$\\boxed{\\begin{pmatrix}1.420  0.3521\\end{pmatrix}}$$"
        },
        {
            "introduction": "Developing a novel SV detection algorithm is incomplete without a rigorous evaluation of its performance. This final exercise  shifts the focus from signal detection to validation, guiding you through the calculation of essential performance metrics like precision, recall, and the $F1$ score. Understanding how to quantify a caller's accuracy against a gold-standard truth set is an indispensable skill for critically assessing the clinical and research utility of any bioinformatics tool.",
            "id": "4332017",
            "problem": "A clinical whole-genome sequencing pipeline evaluates a Structural Variation (SV) caller on a tumor-normal pair to support Precision Medicine decision-making. An SV event is characterized by two genomic breakpoints and a type label (e.g., deletion, duplication, inversion). The evaluation protocol defines a predicted SV as a correct detection of a truth SV if and only if: (i) the SV types match, (ii) both predicted breakpoints are within a tolerance of $\\delta$ base pairs of the corresponding true breakpoints, and (iii) the breakpoint orientations are consistent. To avoid multiple counting of either predictions or truth events, matches are enforced to be one-to-one via maximum bipartite matching over the prediction-truth pairs that satisfy the tolerance and type constraints.\n\nFor a fixed breakpoint tolerance of $\\delta = 75$ base pairs, the gold-standard truth set contains $N_{\\text{true}} = 400$ SVs, and the caller outputs $N_{\\text{pred}} = 380$ SVs. After performing one-to-one matching under the above protocol, the number of matched pairs is $TP = 312$ (true positives). All unmatched predictions are considered false positives and all unmatched truth events are considered false negatives under this evaluation definition.\n\nUsing only the fundamental definitions of confusion counts and set-based evaluation, derive expressions for precision, recall, and the $F1$ measure in terms of $TP$, $FP$, and $FN$, and compute their values for the given counts. Express each metric as a decimal in the interval $[0,1]$, and round your final reported values to four significant figures. Present your final answer as a row vector in the order: precision, recall, $F1$.",
            "solution": "The problem statement has been critically examined and is determined to be valid. It is scientifically grounded in the standard practices of bioinformatics and genomics for evaluating algorithm performance. The problem is well-posed, objective, and provides a complete and consistent set of data necessary for its solution. There are no logical contradictions, scientific inaccuracies, or ill-defined terms. We may therefore proceed with a formal solution.\n\nThe problem asks for the calculation of three standard performance metrics—precision, recall, and the $F1$ measure—for a structural variation (SV) caller based on a set of evaluation counts. The fundamental quantities provided are:\n- The total number of true SVs in the gold-standard set: $N_{\\text{true}} = 400$.\n- The total number of SVs predicted by the caller: $N_{\\text{pred}} = 380$.\n- The number of true positive ($TP$) detections, established via a one-to-one matching protocol: $TP = 312$.\n\nThe problem defines false positives ($FP$) as unmatched predictions and false negatives ($FN$) as unmatched truth events. These definitions are standard in set-based evaluation protocols.\n\nFirst, we derive the expressions for the number of false positives ($FP$) and false negatives ($FN$) using the provided data.\n\nThe set of all predictions, with size $N_{\\text{pred}}$, is partitioned into two disjoint subsets: those that are correct matches to a true SV (true positives) and those that are not (false positives). Therefore, the total number of predictions is the sum of true positives and false positives:\n$$N_{\\text{pred}} = TP + FP$$\nFrom this fundamental relationship, we can express the number of false positives in terms of the given quantities:\n$$FP = N_{\\text{pred}} - TP$$\nSubstituting the given values:\n$$FP = 380 - 312 = 68$$\n\nSimilarly, the set of all true SVs, with size $N_{\\text{true}}$, is partitioned into two disjoint subsets: those that were correctly detected by the caller (true positives) and those that were missed (false negatives). This gives the relationship:\n$$N_{\\text{true}} = TP + FN$$\nFrom this, we express the number of false negatives in terms of the given quantities:\n$$FN = N_{\\text{true}} - TP$$\nSubstituting the given values:\n$$FN = 400 - 312 = 88$$\n\nNow we define and compute the required metrics.\n\n**1. Precision (Positive Predictive Value)**\nPrecision measures the accuracy of the positive predictions made by the caller. It is the fraction of predicted SVs that are actual true SVs. The expression for precision is:\n$$\\text{Precision} = \\frac{TP}{TP + FP}$$\nNote that the denominator, $TP + FP$, is the total number of predictions, $N_{\\text{pred}}$.\n$$\\text{Precision} = \\frac{TP}{N_{\\text{pred}}} = \\frac{312}{380}$$\nCalculating the decimal value:\n$$\\text{Precision} = 0.8210526...$$\nRounding to four significant figures, we get $0.8211$.\n\n**2. Recall (Sensitivity or True Positive Rate)**\nRecall measures the ability of the caller to find all the true SVs. It is the fraction of all true SVs that were correctly detected. The expression for recall is:\n$$\\text{Recall} = \\frac{TP}{TP + FN}$$\nNote that the denominator, $TP + FN$, is the total number of true events, $N_{\\text{true}}$.\n$$\\text{Recall} = \\frac{TP}{N_{\\text{true}}} = \\frac{312}{400}$$\nCalculating the decimal value:\n$$\\text{Recall} = 0.78$$\nTo express this with four significant figures, we write $0.7800$.\n\n**3. $F1$ Measure**\nThe $F1$ measure is the harmonic mean of precision and recall. It provides a single score that balances both metrics. The general formula is:\n$$F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\nA more direct expression in terms of the confusion matrix counts ($TP$, $FP$, $FN$) can be derived:\n$$F1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}$$\nThis form is often preferred as it avoids using intermediate rounded values for precision and recall. Substituting the values for $TP$, $FP$, and $FN$:\n$$F1 = \\frac{2 \\cdot 312}{2 \\cdot 312 + 68 + 88} = \\frac{624}{624 + 156} = \\frac{624}{780}$$\nCalculating the decimal value:\n$$F1 = 0.8$$\nTo express this with four significant figures, we write $0.8000$.\n\nThe computed values, rounded to four significant figures, are:\n- Precision: $0.8211$\n- Recall: $0.7800$\n- $F1$ Measure: $0.8000$\n\nThese values will be presented as a row vector in the specified order.",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.8211  0.7800  0.8000 \\end{pmatrix}}$$"
        }
    ]
}