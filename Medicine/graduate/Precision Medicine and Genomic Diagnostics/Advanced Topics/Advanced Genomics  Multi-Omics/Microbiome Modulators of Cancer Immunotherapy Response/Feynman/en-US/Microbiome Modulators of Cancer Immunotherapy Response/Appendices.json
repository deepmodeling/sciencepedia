{
    "hands_on_practices": [
        {
            "introduction": "Before embarking on any experiment, a critical first step is to determine the necessary sample size. This practice is not just about resource management; it is a cornerstone of ethical and rigorous science, ensuring a study is sufficiently powered to detect a meaningful effect if one truly exists. In this exercise , you will step into the role of a preclinical study designer to calculate the minimum number of subjects required for a mouse model experiment, grounding your design in the core principles of hypothesis testing, effect size, and statistical power.",
            "id": "4359715",
            "problem": "Investigators are studying whether colonization with responder microbiota modulates the antitumor efficacy of an Immune Checkpoint Inhibitor (ICI). Immunotherapy-treated mice are randomized to be colonized with microbiota from human responders or from non-responders. For each mouse indexed by $i$, longitudinal tumor volumes $V_{i}(t)$ are measured at regular intervals from day $t=0$ to $t=T$, with $T=28$. To obtain a single mouse-level measure of tumor control that respects within-mouse temporal correlation and avoids pseudo-replication, the investigators will summarize each trajectory by the area under the tumor volume curve normalized by baseline, $A_{i}=\\int_{0}^{T} \\frac{V_{i}(t)}{V_{i}(0)}\\,dt$. Let group $R$ denote mice colonized with responder microbiota and group $N$ denote mice colonized with non-responder microbiota. Assume that the mouse-level summaries $A_{i}$ in each group are independent and approximately Gaussian with a common standard deviation $\\sigma$, and let $\\mu_{R}$ and $\\mu_{N}$ be the corresponding group means. The investigators wish to design a statistical test to detect differential tumor control, formalized as a difference in mean $A_{i}$ between the groups, and to power the study to detect a standardized effect size $d=0.8$ at a two-sided significance level $\\alpha=0.05$ with target power $1-\\beta=0.80$, using equal per-arm sample sizes.\n\nStarting from core definitions of hypothesis testing and standardized effect size, derive the minimum equal per-arm sample size $n$ required under the normal approximation for a two-sample comparison of means based on the $A_{i}$ summaries. You may assume the standardized effect size is $d=\\frac{|\\mu_{R}-\\mu_{N}|}{\\sigma}$. Use the standard normal quantiles for the two-sided test. For any needed numerical approximations of standard normal quantiles, round each quantile to four significant figures before proceeding with the calculation. After computing the continuous $n$, round the final required per-arm sample size up to the next whole mouse.\n\nProvide the final answer as the minimum integer $n$ (number of mice per arm) needed to achieve the specified $\\alpha$ and power, with no units.",
            "solution": "The problem requires the derivation of the minimum per-arm sample size, $n$, for a two-sample test of means, given a specified significance level $\\alpha$, power $1-\\beta$, and standardized effect size $d$. The analysis will be based on the normal approximation for the sample means of the summary measure $A_i$.\n\nLet $\\mu_R$ and $\\mu_N$ be the true mean values of the summary statistic $A_i = \\int_{0}^{T} \\frac{V_{i}(t)}{V_{i}(0)}\\,dt$ for the responder ($R$) and non-responder ($N$) groups, respectively. The common standard deviation is $\\sigma$. We are testing for a difference in these means.\n\nThe null and alternative hypotheses for the two-sided test are:\n$$ H_0: \\mu_R = \\mu_N \\quad \\text{or} \\quad \\mu_R - \\mu_N = 0 $$\n$$ H_A: \\mu_R \\neq \\mu_N \\quad \\text{or} \\quad \\mu_R - \\mu_N \\neq 0 $$\n\nLet $n_R = n_N = n$ be the equal sample sizes per arm. Let $\\bar{A}_R$ and $\\bar{A}_N$ be the sample means. The estimator for the difference in population means is $\\bar{A}_R - \\bar{A}_N$. Since the individual measurements $A_i$ are assumed to be independent and normally distributed, the sampling distribution of the difference in means, $\\bar{A}_R - \\bar{A}_N$, is also normal.\n\nThe mean of this sampling distribution is $E[\\bar{A}_R - \\bar{A}_N] = \\mu_R - \\mu_N$.\nThe variance is $\\text{Var}(\\bar{A}_R - \\bar{A}_N) = \\text{Var}(\\bar{A}_R) + \\text{Var}(\\bar{A}_N) = \\frac{\\sigma^2}{n_R} + \\frac{\\sigma^2}{n_N} = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$.\nThe standard error of the difference is $SE = \\sqrt{\\frac{2\\sigma^2}{n}} = \\sigma\\sqrt{\\frac{2}{n}}$.\n\nUnder the null hypothesis $H_0$, the mean difference is $0$. The test statistic is:\n$$ Z = \\frac{(\\bar{A}_R - \\bar{A}_N) - 0}{SE} = \\frac{\\bar{A}_R - \\bar{A}_N}{\\sigma\\sqrt{\\frac{2}{n}}} $$\nUnder $H_0$, $Z$ follows a standard normal distribution, $Z \\sim N(0, 1)$.\n\nFor a two-sided test at a significance level $\\alpha$, we reject $H_0$ if the observed test statistic $|Z|$ is greater than the critical value $z_{1-\\alpha/2}$. The value $z_{q}$ denotes the $q$-th quantile of the standard normal distribution.\nGiven $\\alpha=0.05$, we have $\\alpha/2 = 0.025$, and the critical value is $z_{1-0.025} = z_{0.975}$. As per the problem statement, we use the approximation rounded to four significant figures:\n$$ z_{0.975} \\approx 1.960 $$\nThe rejection region is thus defined by $|\\bar{A}_R - \\bar{A}_N| / (\\sigma\\sqrt{2/n}) > 1.960$.\n\nPower is the probability of correctly rejecting $H_0$ when $H_A$ is true. Let $1-\\beta$ be the desired power. We evaluate power under a specific alternative hypothesis, where the true difference is $|\\mu_R - \\mu_N| = \\delta$. The standardized effect size is given as $d = \\frac{|\\mu_R - \\mu_N|}{\\sigma} = \\frac{\\delta}{\\sigma}$.\nFrom the problem, $d = 0.8$ and $1-\\beta = 0.80$, which implies $\\beta=0.20$.\n\nUnder this alternative hypothesis, the statistic $\\bar{A}_R - \\bar{A}_N$ is normally distributed with mean $\\delta$ and standard error $\\sigma\\sqrt{2/n}$.\nPower is the probability that our test statistic falls into the rejection region, given that the true difference is $\\delta$.\n$$ 1 - \\beta = P\\left( |Z| > z_{1-\\alpha/2} \\mid |\\mu_R - \\mu_N| = \\delta \\right) $$\nWithout loss of generality, assume $\\mu_R - \\mu_N = \\delta > 0$. The power is primarily contributed by the upper tail of the rejection region, as the probability of the test statistic falling into the lower tail is negligible.\n$$ 1 - \\beta \\approx P\\left( \\frac{\\bar{A}_R - \\bar{A}_N}{\\sigma\\sqrt{\\frac{2}{n}}} > z_{1-\\alpha/2} \\bigg| \\mu_R - \\mu_N = \\delta \\right) $$\nTo evaluate this probability, we standardize the random variable $\\bar{A}_R - \\bar{A}_N$ under the alternative hypothesis by subtracting its true mean $\\delta$ and dividing by its standard error:\n$$ Z' = \\frac{(\\bar{A}_R - \\bar{A}_N) - \\delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\sim N(0, 1) $$\nWe rewrite the inequality from the power definition in terms of $Z'$:\n$$ \\bar{A}_R - \\bar{A}_N > z_{1-\\alpha/2} \\cdot \\sigma\\sqrt{\\frac{2}{n}} $$\n$$ (\\bar{A}_R - \\bar{A}_N) - \\delta > z_{1-\\alpha/2} \\cdot \\sigma\\sqrt{\\frac{2}{n}} - \\delta $$\n$$ \\frac{(\\bar{A}_R - \\bar{A}_N) - \\delta}{\\sigma\\sqrt{\\frac{2}{n}}} > z_{1-\\alpha/2} - \\frac{\\delta}{\\sigma\\sqrt{\\frac{2}{n}}} $$\n$$ Z' > z_{1-\\alpha/2} - \\frac{d}{\\sqrt{\\frac{2}{n}}} $$\nThe probability of this event is the power, $1-\\beta$. By definition of quantiles, $P(Z' > z_{\\beta}) = 1-\\beta$. By symmetry of the normal distribution, $z_{\\beta} = -z_{1-\\beta}$. Therefore, $P(Z' > -z_{1-\\beta}) = 1-\\beta$.\nThis implies:\n$$ -z_{1-\\beta} = z_{1-\\alpha/2} - \\frac{d}{\\sqrt{\\frac{2}{n}}} $$\nRearranging to solve for $n$, we get the general formula for sample size:\n$$ \\frac{d}{\\sqrt{\\frac{2}{n}}} = z_{1-\\alpha/2} + z_{1-\\beta} $$\n$$ \\sqrt{n} = \\frac{\\sqrt{2}(z_{1-\\alpha/2} + z_{1-\\beta})}{d} $$\n$$ n = \\frac{2(z_{1-\\alpha/2} + z_{1-\\beta})^2}{d^2} $$\nNow we substitute the given values. The power is $1-\\beta = 0.80$, so we need the quantile $z_{1-\\beta} = z_{0.80}$. Rounding to four significant figures, this value is:\n$$ z_{0.80} \\approx 0.8416 $$\nWe have the values:\n$d = 0.8$\n$z_{1-\\alpha/2} = z_{0.975} \\approx 1.960$\n$z_{1-\\beta} = z_{0.80} \\approx 0.8416$\n\nSubstituting these into the formula for $n$:\n$$ n = \\frac{2(1.960 + 0.8416)^2}{(0.8)^2} $$\n$$ n = \\frac{2(2.8016)^2}{0.64} $$\n$$ n = \\frac{2 \\times 7.84896256}{0.64} $$\n$$ n = \\frac{15.69792512}{0.64} $$\n$$ n \\approx 24.528008 $$\nThe problem requires rounding the final required per-arm sample size up to the next whole mouse. A sample size of $24$ would provide slightly less than the target power, so we must round up to ensure the power requirement is met.\n$$ n = 25 $$\nTherefore, a minimum of $25$ mice per group is required.",
            "answer": "$$\\boxed{25}$$"
        },
        {
            "introduction": "Once data is collected, the analytical challenge is to isolate the true association between a microbial feature and a clinical outcome, untangled from the influence of other variables. Confounders, such as a patient's prior antibiotic exposure, can create spurious associations or mask real ones. This hands-on coding exercise  will guide you through implementing a logistic regression model to compute an adjusted odds ratio, a fundamental technique for controlling for confounding and making more robust inferences from observational data.",
            "id": "4359570",
            "problem": "You are provided with binary cohort data representing objective response to immune checkpoint inhibitor therapy and the baseline presence of the gut microbe Akkermansia muciniphila, along with recent antibiotic exposure. Your task is to compute the adjusted association between Akkermansia presence and objective response using a logistic regression model that includes an intercept term and adjusts for antibiotic exposure. The final goal is to report the adjusted odds ratio for Akkermansia presence, its Wald $95\\%$ confidence interval bounds, and the two-sided Wald $p$-value, for each defined test cohort.\n\nStart from the following fundamental base:\n- The Central Dogma of molecular biology defines information flow but does not directly determine clinical response; instead, we use statistical modeling grounded in well-tested clinical observations: responders and non-responders can be modeled as independent Bernoulli outcomes.\n- For an individual $i$, let $Y_i \\in \\{0,1\\}$ denote the objective response indicator ($Y_i=1$ if response, $Y_i=0$ otherwise), $A_i \\in \\{0,1\\}$ denote Akkermansia presence ($A_i=1$ if present, $A_i=0$ otherwise), and $B_i \\in \\{0,1\\}$ denote antibiotic exposure ($B_i=1$ if exposed, $B_i=0$ otherwise).\n- Assume conditional independence of outcomes given covariates and model the conditional probability of response via a Generalized Linear Model (GLM) with a logit link: the Bernoulli probability $p_i$ satisfies the canonical logit link, and inference proceeds by maximum likelihood.\n- The antibiotic exposure is treated as a confounder. You must adjust for it by including it as a covariate, together with an intercept and the Akkermansia presence indicator.\n\nModel specification to implement:\n- The logistic regression model is $ \\mathrm{logit}(p_i) = \\beta_0 + \\beta_1 A_i + \\beta_2 B_i $, where $ \\mathrm{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right) $.\n- The adjusted odds ratio for Akkermansia presence is $ \\exp(\\beta_1) $.\n- Use maximum likelihood estimation with a weak ridge stabilization (penalty on $ \\beta_1 $ and $ \\beta_2 $, but not on $ \\beta_0 $) to ensure numerical stability in edge cases. The ridge strength should be $ \\lambda = 10^{-6} $.\n\nInference to report:\n- Report the adjusted odds ratio $ \\exp(\\beta_1) $.\n- Report the Wald $95\\%$ confidence interval bounds, computed as $ \\exp\\left(\\beta_1 \\pm 1.96 \\cdot \\mathrm{SE}(\\beta_1)\\right) $ where $ \\mathrm{SE}(\\beta_1) $ is the standard error derived from the inverse of the observed Fisher information (allowing the weak ridge stabilization as specified).\n- Report the two-sided Wald $p$-value for testing $ H_0: \\beta_1 = 0 $ using the standard Normal approximation, computed from the test statistic $ z = \\beta_1 / \\mathrm{SE}(\\beta_1) $.\n\nData format and construction:\n- For each test case, you are given group-level counts as tuples $(A,B, r, n)$ meaning Akkermansia indicator $A \\in \\{0,1\\}$, antibiotic indicator $B \\in \\{0,1\\}$, number of responders $r$, and number of non-responders $n$. From these, construct individual-level data by creating $r$ instances with $Y=1$ and $n$ instances with $Y=0$, each with the corresponding $A$ and $B$ values.\n\nTest suite:\n- Case $1$ (balanced association, moderate confounding):\n  - $(A,B,r,n)$ groups:\n    - $(1,0,6,4)$\n    - $(1,1,2,3)$\n    - $(0,0,3,5)$\n    - $(0,1,2,5)$\n- Case $2$ (near separation, strong signal):\n  - $(A,B,r,n)$ groups:\n    - $(1,0,7,1)$\n    - $(1,1,3,1)$\n    - $(0,0,1,7)$\n    - $(0,1,0,4)$\n- Case $3$ (antibiotic covariate constant zero):\n  - $(A,B,r,n)$ groups:\n    - $(1,0,3,3)$\n    - $(0,0,1,5)$\n- Case $4$ (high confounding, correlated covariates):\n  - $(A,B,r,n)$ groups:\n    - $(1,0,7,5)$\n    - $(1,1,1,1)$\n    - $(0,0,2,4)$\n    - $(0,1,2,8)$\n\nYour program must:\n- Implement maximum likelihood fitting for the specified logistic regression with weak ridge stabilization $ \\lambda = 10^{-6} $ on $ \\beta_1 $ and $ \\beta_2 $, but not on $ \\beta_0 $.\n- Compute and return, for each case in the test suite, the list $[\\exp(\\beta_1), \\mathrm{CI}_{\\mathrm{lower}}, \\mathrm{CI}_{\\mathrm{upper}}, p\\text{-value}]$, where the confidence interval is the Wald $95\\%$ interval and the $p$-value is two-sided based on the Normal approximation.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each item is itself a list formatted as $[\\text{OR},\\text{CI}_{\\text{lower}},\\text{CI}_{\\text{upper}},\\text{p-value}]$ with each floating-point number rounded to $6$ decimal places. For example, a line with two items should look like $[[1.234000,0.789000,1.932000,0.045000],[\\dots]]$.",
            "solution": "The user has provided a well-defined biostatistical problem that is scientifically grounded and computationally tractable. The problem is validated as sound, complete, and well-posed. The task is to compute the adjusted odds ratio, its confidence interval, and a $p$-value for the association between the presence of a microbe and a clinical outcome, adjusting for a confounder.\n\nThe solution is implemented by developing a logistic regression model and fitting it using a penalized maximum likelihood approach. The analytical steps are detailed below.\n\n### 1. Model Specification\n\nThe relationship between the binary clinical response $Y_i \\in \\{0, 1\\}$ and the covariates is modeled using a Generalized Linear Model (GLM) with a Bernoulli response distribution and a logit link function. For each individual $i$, the probability of response, $p_i = P(Y_i=1)$, is linked to a linear combination of predictors:\n$$ \\mathrm{logit}(p_i) = \\log\\left(\\frac{p_i}{1-p_i}\\right) = \\beta_0 + \\beta_1 A_i + \\beta_2 B_i $$\nHere, $A_i \\in \\{0,1\\}$ is the indicator for *Akkermansia* presence, $B_i \\in \\{0,1\\}$ is the indicator for antibiotic exposure, and $\\boldsymbol{\\beta} = (\\beta_0, \\beta_1, \\beta_2)^T$ is the vector of regression coefficients. The coefficient of primary interest is $\\beta_1$, as its exponential, $\\exp(\\beta_1)$, represents the odds ratio for *Akkermansia* presence, adjusted for antibiotic exposure.\n\n### 2. Estimation via Penalized Maximum Likelihood\n\nThe model parameters $\\boldsymbol{\\beta}$ are estimated by maximizing a penalized log-likelihood function. The data is provided in a grouped format, consisting of $k$ unique strata, each defined by a distinct combination of covariates $(A_j, B_j)$. For each stratum $j \\in \\{1,...,k\\}$, we are given the number of responders, $r_j$, and the total number of subjects, $N_j$. The log-likelihood function for this grouped data is:\n$$ \\ell(\\boldsymbol{\\beta}) = \\sum_{j=1}^{k} \\left[ r_j \\log(p_j) + (N_j - r_j) \\log(1-p_j) \\right] $$\nwhere $p_j = \\sigma(\\eta_j)$ is the modeled probability of response for stratum $j$, $\\eta_j = \\beta_0 + \\beta_1 A_j + \\beta_2 B_j$ is the linear predictor, and $\\sigma(z)=(1+e^{-z})^{-1}$ is the logistic sigmoid function.\n\nTo ensure numerical stability, particularly in cases of data separation where maximum likelihood estimates may not converge to finite values, a weak ridge (L2) penalty is applied. The problem specifies a penalty on $\\beta_1$ and $\\beta_2$ with strength $\\lambda = 10^{-6}$. The penalized log-likelihood function is:\n$$ \\ell_{\\text{pen}}(\\boldsymbol{\\beta}) = \\ell(\\boldsymbol{\\beta}) - \\frac{\\lambda}{2}(\\beta_1^2 + \\beta_2^2) $$\nThis can be written in matrix form as $\\ell_{\\text{pen}}(\\boldsymbol{\\beta}) = \\ell(\\boldsymbol{\\beta}) - \\frac{1}{2}\\boldsymbol{\\beta}^T P \\boldsymbol{\\beta}$, where $P$ is a diagonal penalty matrix with diagonal entries $(0, \\lambda, \\lambda)$.\n\n### 3. Numerical Optimization: Newton-Raphson Method\n\nThe vector $\\hat{\\boldsymbol{\\beta}}$ that maximizes $\\ell_{\\text{pen}}(\\boldsymbol{\\beta})$ is found using the Newton-Raphson iterative algorithm. This method requires the gradient (score vector) and the Hessian matrix of the penalized log-likelihood.\n\nThe gradient of $\\ell_{\\text{pen}}(\\boldsymbol{\\beta})$ is:\n$$ \\nabla \\ell_{\\text{pen}}(\\boldsymbol{\\beta}) = \\frac{\\partial \\ell_{\\text{pen}}}{\\partial \\boldsymbol{\\beta}} = X^T(R - N \\odot P_{\\text{vec}}) - P\\boldsymbol{\\beta} $$\nwhere $X$ is the $k \\times 3$ design matrix for the unique strata, $R$ is the $k \\times 1$ vector of responder counts ($r_j$), $N$ is the $k \\times 1$ vector of total counts ($N_j$), $P_{\\text{vec}}$ is the $k \\times 1$ vector of probabilities ($p_j$), and $\\odot$ denotes element-wise multiplication.\n\nThe Hessian matrix of $\\ell_{\\text{pen}}(\\boldsymbol{\\beta})$ is:\n$$ H_{\\text{pen}}(\\boldsymbol{\\beta}) = \\frac{\\partial^2 \\ell_{\\text{pen}}}{\\partial \\boldsymbol{\\beta} \\partial \\boldsymbol{\\beta}^T} = -X^T W X - P $$\nwhere $W$ is a $k \\times k$ diagonal matrix with weights $W_{jj} = N_j p_j (1-p_j)$.\n\nThe Newton-Raphson update at each iteration $t$ is:\n$$ \\boldsymbol{\\beta}_{t+1} = \\boldsymbol{\\beta}_t - [H_{\\text{pen}}(\\boldsymbol{\\beta}_t)]^{-1} \\nabla \\ell_{\\text{pen}}(\\boldsymbol{\\beta}_t) $$\nThis is equivalent to an Iteratively Reweighted Least Squares (IRLS) update. The iterative process starts with an initial guess, typically $\\boldsymbol{\\beta}_0 = \\mathbf{0}$, and continues until the change in $\\boldsymbol{\\beta}$ between successive iterations falls below a predefined tolerance.\n\n### 4. Statistical Inference\n\nUpon convergence of the algorithm to the final estimate $\\hat{\\boldsymbol{\\beta}}$, we perform statistical inference on $\\beta_1$. The asymptotic covariance matrix of the estimator is given by the inverse of the penalized observed Fisher information matrix, which is the negative of the Hessian evaluated at the final estimate:\n$$ \\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\beta}}) = [-H_{\\text{pen}}(\\hat{\\boldsymbol{\\beta}})]^{-1} = (X^T W X + P)^{-1} $$\nwhere $W$ is calculated using the probabilities from the final $\\hat{\\boldsymbol{\\beta}}$.\n\nThe standard error of $\\hat{\\beta}_1$ is the square root of the second diagonal element of this covariance matrix:\n$$ \\mathrm{SE}(\\hat{\\beta}_1) = \\sqrt{[\\widehat{\\mathrm{Cov}}(\\hat{\\boldsymbol{\\beta}})]_{1,1}} $$\n\nFrom $\\hat{\\beta}_1$ and its standard error, we compute the required quantities:\n1.  **Adjusted Odds Ratio (OR):** $\\mathrm{OR} = \\exp(\\hat{\\beta}_1)$\n2.  **$95\\%$ Wald Confidence Interval (CI) for OR:** $\\exp(\\hat{\\beta}_1 \\pm 1.96 \\cdot \\mathrm{SE}(\\hat{\\beta}_1))$\n3.  **Two-sided Wald $p$-value:** This tests the null hypothesis $H_0: \\beta_1 = 0$. The test statistic $z = \\hat{\\beta}_1 / \\mathrm{SE}(\\hat{\\beta}_1)$ is compared to a standard normal distribution, $Z \\sim N(0,1)$. The $p$-value is calculated as $2 \\cdot P(Z \\ge |z|)$.\n\nThis complete procedure is applied to each test case provided in the problem statement to generate the final results.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It defines the test cases, iterates through them, computes the required statistics,\n    and prints the formatted results.\n    \"\"\"\n    test_cases = [\n        # Case 1 (balanced association, moderate confounding)\n        [\n            (1, 0, 6, 4),\n            (1, 1, 2, 3),\n            (0, 0, 3, 5),\n            (0, 1, 2, 5)\n        ],\n        # Case 2 (near separation, strong signal)\n        [\n            (1, 0, 7, 1),\n            (1, 1, 3, 1),\n            (0, 0, 1, 7),\n            (0, 1, 0, 4)\n        ],\n        # Case 3 (antibiotic covariate constant zero)\n        [\n            (1, 0, 3, 3),\n            (0, 0, 1, 5)\n        ],\n        # Case 4 (high confounding, correlated covariates)\n        [\n            (1, 0, 7, 5),\n            (1, 1, 1, 1),\n            (0, 0, 2, 4),\n            (0, 1, 2, 8)\n        ]\n    ]\n\n    results = []\n    for case_data in test_cases:\n        analysis_result = analyze_cohort(grouped_data=case_data, lambda_ridge=1e-6)\n        results.append(analysis_result)\n\n    # Format the final output string as specified\n    output_parts = []\n    for res_list in results:\n        formatted_nums = [f\"{num:.6f}\" for num in res_list]\n        output_parts.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output = f\"[{','.join(output_parts)}]\"\n    print(final_output)\n\ndef analyze_cohort(grouped_data, lambda_ridge, tol=1e-9, max_iter=100):\n    \"\"\"\n    Fits a penalized logistic regression model to grouped cohort data.\n\n    Args:\n        grouped_data (list of tuples): Each tuple is (A, B, r, n) representing\n                                       Akkermansia status, antibiotic status,\n                                       number of responders, and number of non-responders.\n        lambda_ridge (float): The strength of the L2 penalty.\n        tol (float): The convergence tolerance for the optimization.\n        max_iter (int): The maximum number of iterations for the solver.\n\n    Returns:\n        list: A list containing [odds_ratio, ci_lower, ci_upper, p_value].\n    \"\"\"\n    # 1. Construct data matrices from grouped counts\n    X_list, R_list, N_list = [], [], []\n    for A, B, r, n in grouped_data:\n        X_list.append([1, A, B])  # Design matrix row: [intercept, Akk, Abx]\n        R_list.append(r)          # Responders count\n        N_list.append(r + n)      # Total count\n    \n    X_unique = np.array(X_list, dtype=float)\n    R_counts = np.array(R_list, dtype=float)\n    N_counts = np.array(N_list, dtype=float)\n\n    # 2. Initialize parameters for the Newton-Raphson algorithm\n    num_params = X_unique.shape[1]\n    beta = np.zeros(num_params)\n    \n    # 3. Define the penalty matrix (no penalty on the intercept)\n    P = np.diag([0] + [lambda_ridge] * (num_params - 1))\n\n    # 4. Run the Newton-Raphson (IRLS) optimization loop\n    for _ in range(max_iter):\n        # Calculate linear predictor and probabilities\n        eta = X_unique @ beta\n        p = expit(eta)\n        \n        # Calculate weights for the Hessian (and Fisher information)\n        # Add a small epsilon to prevent weights from being exactly zero\n        w = N_counts * p * (1 - p) + np.finfo(float).eps\n        W = np.diag(w)\n        \n        # Calculate the gradient (score vector) of the penalized log-likelihood\n        score = X_unique.T @ (R_counts - N_counts * p) - P @ beta\n        \n        # Calculate the penalized observed Fisher information matrix (-Hessian)\n        fisher_info = X_unique.T @ W @ X_unique + P\n        \n        # Solve for the update step and update beta\n        try:\n            delta_beta = np.linalg.solve(fisher_info, score)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudo-inverse if matrix is singular (unlikely with ridge)\n            delta_beta = np.linalg.pinv(fisher_info) @ score\n        \n        beta += delta_beta\n        \n        # Check for convergence\n        if np.linalg.norm(delta_beta)  tol:\n            break\n            \n    # 5. Compute final statistics after convergence\n    # (Re)calculate final Fisher information matrix at the converged beta estimate\n    eta = X_unique @ beta\n    p = expit(eta)\n    w = N_counts * p * (1 - p) + np.finfo(float).eps\n    W = np.diag(w)\n    final_fisher_info = X_unique.T @ W @ X_unique + P\n    \n    # Covariance matrix is the inverse of the Fisher information matrix\n    try:\n        cov_beta = np.linalg.inv(final_fisher_info)\n    except np.linalg.LinAlgError:\n        cov_beta = np.linalg.pinv(final_fisher_info)\n    \n    # Extract results for beta_1 (Akkermansia effect)\n    beta_1 = beta[1]\n    se_beta_1 = np.sqrt(max(0, cov_beta[1, 1]))\n    \n    # Adjusted Odds Ratio\n    odds_ratio = np.exp(beta_1)\n    \n    # Wald 95% Confidence Interval for the Odds Ratio\n    z_critical = 1.96\n    ci_lower = np.exp(beta_1 - z_critical * se_beta_1)\n    ci_upper = np.exp(beta_1 + z_critical * se_beta_1)\n    \n    # Two-sided Wald p-value for H0: beta_1 = 0\n    wald_z = beta_1 / se_beta_1 if se_beta_1 > 0 else 0\n    p_value = 2 * norm.sf(np.abs(wald_z)) # sf is survival function (1 - cdf)\n    \n    return [odds_ratio, ci_lower, ci_upper, p_value]\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Demonstrating an association is a crucial step, but understanding the underlying biological mechanism is the ultimate goal of precision medicine. Causal mediation analysis provides a powerful framework to dissect *how* an exposure influences an outcome by quantifying the extent to which its effect is transmitted through an intermediate variable, or mediator. This advanced practice  challenges you to derive and compute direct and indirect effects within a temporally ordered causal system, providing a quantitative window into the pathways connecting the microbiome to immunotherapy response.",
            "id": "4359687",
            "problem": "You are given a temporally ordered causal system motivated by microbiome modulators of cancer immunotherapy response. Consider a baseline exposure $E$ (for example, a baseline microbiome feature), a baseline confounder $C$ (for example, a genomic or clinical covariate), an on-treatment mediator $M$ (for example, an early on-treatment immune readout), and a post-treatment outcome $Y$ (for example, a clinical response score). The temporal ordering is baseline $E$ and $C$, then on-treatment $M$, then post-treatment $Y$. Assume the following:\n\n- Structural equations (linear, additive, with interaction between exposure and mediator in the outcome model):\n  - Mediator: $M = \\alpha_{0} + \\alpha_{1} E + \\alpha_{2} C + \\varepsilon_{M}$,\n  - Outcome: $Y = \\beta_{0} + \\beta_{1} E + \\beta_{2} M + \\beta_{3} (E \\cdot M) + \\beta_{4} C + \\varepsilon_{Y}$.\n- Error terms are mean-zero and independent of $(E, C)$ and of each other, with $\\varepsilon_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2})$ and $\\varepsilon_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2})$.\n- The confounder is distributed as $C \\sim \\mathcal{N}(\\mu_{C}, \\sigma_{C}^{2})$.\n- The exposure $E$ is binary and temporally precedes $M$, which precedes $Y$.\n- Sequential ignorability holds given $C$ and the temporal ordering, that is, there are no unmeasured confounders of the exposure–mediator, exposure–outcome, or mediator–outcome relationships beyond $C$, consistent with the causal sequence from baseline to on-treatment to post-treatment.\n\nUsing the potential outcomes framework, define for any fixed $c$ the potential mediator under exposure $e$ as $M(e,c)$, and the potential outcome under exposure $e$ and mediator $m$ as $Y(e,m,c)$. Using these, define the following causal estimands that respect temporal ordering:\n\n- Average Causal Mediation Effect (ACME) under exposure fixed at $0$: $\\text{ACME}_{0} = \\mathbb{E} \\left[ Y(0, M(1)) - Y(0, M(0)) \\right]$.\n- Average Causal Mediation Effect (ACME) under exposure fixed at $1$: $\\text{ACME}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(1, M(0)) \\right]$.\n- Average Direct Effect (ADE) under the mediator fixed at its value under $E=0$: $\\text{ADE}_{0} = \\mathbb{E} \\left[ Y(1, M(0)) - Y(0, M(0)) \\right]$.\n- Average Direct Effect (ADE) under the mediator fixed at its value under $E=1$: $\\text{ADE}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(0, M(1)) \\right]$.\n\nYour task is to implement, from first principles under the above assumptions, a program that computes $\\text{ACME}_{0}$, $\\text{ACME}_{1}$, $\\text{ADE}_{0}$, and $\\text{ADE}_{1}$ for each parameter configuration in the test suite below. The computation must proceed by logically deriving these averages from the specified temporal ordering and model, without violating the ordering and without introducing shortcuts that assume results not derived from the stated assumptions.\n\nThere are no physical units or angles in this problem. All outputs must be real numbers rounded to six decimal places.\n\nTest suite (each test case provides ($\\alpha_{0}, \\alpha_{1}, \\alpha_{2}, \\sigma_{M}; \\beta_{0}, \\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4}, \\sigma_{Y}; \\mu_{C}, \\sigma_{C}$)):\n\n- Case $1$ (general case with nonzero interaction): ($\\alpha_{0}=0.2$, $\\alpha_{1}=0.8$, $\\alpha_{2}=0.5$, $\\sigma_{M}=0.6$; $\\beta_{0}=-0.1$, $\\beta_{1}=0.5$, $\\beta_{2}=1.2$, $\\beta_{3}=-0.4$, $\\beta_{4}=0.3$, $\\sigma_{Y}=1.0$; $\\mu_{C}=0.0$, $\\sigma_{C}=1.0$).\n- Case $2$ (boundary case with no mediator effect on outcome): ($\\alpha_{0}=0.2$, $\\alpha_{1}=0.9$, $\\alpha_{2}=-0.4$, $\\sigma_{M}=0.5$; $\\beta_{0}=0.0$, $\\beta_{1}=1.0$, $\\beta_{2}=0.0$, $\\beta_{3}=0.0$, $\\beta_{4}=-0.2$, $\\sigma_{Y}=1.2$; $\\mu_{C}=1.5$, $\\sigma_{C}=0.7$).\n- Case $3$ (boundary case with no exposure effect on mediator): ($\\alpha_{0}=0.0$, $\\alpha_{1}=0.0$, $\\alpha_{2}=0.7$, $\\sigma_{M}=0.9$; $\\beta_{0}=0.1$, $\\beta_{1}=0.3$, $\\beta_{2}=1.1$, $\\beta_{3}=0.5$, $\\beta_{4}=0.0$, $\\sigma_{Y}=0.8$; $\\mu_{C}=-0.5$, $\\sigma_{C}=1.3$).\n- Case $4$ (interaction-dominant scenario with shifted confounder mean): ($\\alpha_{0}=-0.3$, $\\alpha_{1}=0.4$, $\\alpha_{2}=1.2$, $\\sigma_{M}=0.4$; $\\beta_{0}=0.0$, $\\beta_{1}=-0.2$, $\\beta_{2}=0.6$, $\\beta_{3}=0.8$, $\\beta_{4}=0.1$, $\\sigma_{Y}=0.9$; $\\mu_{C}=2.0$, $\\sigma_{C}=0.5$).\n\nFinal output format:\n\n- For each test case, output a list with the four values $[\\text{ACME}_{0}, \\text{ACME}_{1}, \\text{ADE}_{0}, \\text{ADE}_{1}]$, each rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list of these per-case lists, enclosed in a single pair of square brackets. For example, an output with two cases would look like $[[a_{11},a_{12},a_{13},a_{14}],[a_{21},a_{22},a_{23},a_{24}]]$ where each $a_{ij}$ is a decimal rounded to six places.",
            "solution": "The user's request is to critically validate a problem statement concerning causal mediation analysis and, if valid, provide a reasoned solution and a final Python implementation.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\nThe problem provides the following information:\n- A causal system with temporal ordering: baseline exposure $E$ and confounder $C$, then on-treatment mediator $M$, then post-treatment outcome $Y$.\n- Structural Equations:\n  - Mediator: $M = \\alpha_{0} + \\alpha_{1} E + \\alpha_{2} C + \\varepsilon_{M}$\n  - Outcome: $Y = \\beta_{0} + \\beta_{1} E + \\beta_{2} M + \\beta_{3} (E \\cdot M) + \\beta_{4} C + \\varepsilon_{Y}$\n- Error Term Distributions: $\\varepsilon_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2})$ and $\\varepsilon_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2})$. They are mean-zero and independent of $(E, C)$ and each other.\n- Confounder Distribution: $C \\sim \\mathcal{N}(\\mu_{C}, \\sigma_{C}^{2})$.\n- Exposure Variable: $E$ is binary.\n- Causal Assumption: Sequential ignorability holds given $C$ and the temporal ordering. This implies no unmeasured confounding.\n- Definitions of Causal Estimands:\n  - Average Causal Mediation Effect (ACME) under exposure $0$: $\\text{ACME}_{0} = \\mathbb{E} \\left[ Y(0, M(1)) - Y(0, M(0)) \\right]$\n  - Average Causal Mediation Effect (ACME) under exposure $1$: $\\text{ACME}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(1, M(0)) \\right]$\n  - Average Direct Effect (ADE) under mediator from $E=0$: $\\text{ADE}_{0} = \\mathbb{E} \\left[ Y(1, M(0)) - Y(0, M(0)) \\right]$\n  - Average Direct Effect (ADE) under mediator from $E=1$: $\\text{ADE}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(0, M(1)) \\right]$\n- Test Cases: Four sets of parameters $(\\alpha_{0}, \\alpha_{1}, \\alpha_{2}, \\sigma_{M}; \\beta_{0}, \\beta_{1}, \\beta_{2}, \\beta_{3}, \\beta_{4}, \\sigma_{Y}; \\mu_{C}, \\sigma_{C})$ are provided.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded**: The problem is based on the well-established framework of causal mediation analysis, specifically using linear structural equation models. This is a standard and rigorous methodology in statistics, econometrics, and epidemiology, and is frequently applied in the biomedical context described. The assumptions (e.g., sequential ignorability) and definitions are standard in this field.\n- **Well-Posed**: The problem is clearly defined. The structural equations, distributions, and definitions of the estimands are provided, allowing for a unique analytical solution for the quantities of interest. The parameters for all test cases are specified.\n- **Objective**: The problem is stated in precise mathematical and statistical language, free of ambiguity or subjective claims.\n\nThe problem does not exhibit any of the invalidity flaws. It is scientifically sound, formalizable, complete, and well-structured.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be derived and implemented.\n\n### Derivation of Causal Estimands\n\nThe objective is to derive expressions for $\\text{ACME}_{0}$, $\\text{ACME}_{1}$, $\\text{ADE}_{0}$, and $\\text{ADE}_{1}$ in terms of the model parameters. The derivation relies on the potential outcomes framework, where the potential outcomes are determined by the structural equations under the assumption of sequential ignorability.\n\nThe potential mediator $M(e)$ for an exposure level $E=e$ is given by substituting $e$ into the mediator equation:\n$$M(e) = \\alpha_{0} + \\alpha_{1} e + \\alpha_{2} C + \\varepsilon_{M}$$\nThe potential outcome $Y(e, m)$ for an exposure level $E=e$ and mediator level $M=m$ is given by substituting $e$ and $m$ into the outcome equation:\n$$Y(e, m) = \\beta_{0} + \\beta_{1} e + \\beta_{2} m + \\beta_{3} (e \\cdot m) + \\beta_{4} C + \\varepsilon_{Y}$$\n\nWe now derive each estimand by taking the expectation over the distributions of the random variables $C$, $\\varepsilon_M$, and $\\varepsilon_Y$. We use the properties $\\mathbb{E}[C] = \\mu_{C}$, $\\mathbb{E}[\\varepsilon_{M}] = 0$, and $\\mathbb{E}[\\varepsilon_{Y}] = 0$.\n\n**1. Average Causal Mediation Effect under Exposure $0$ ($\\text{ACME}_0$)**\n\nBy definition, $\\text{ACME}_{0} = \\mathbb{E} \\left[ Y(0, M(1)) - Y(0, M(0)) \\right]$.\nFirst, let's express the terms inside the expectation. For $e=0$, the outcome equation for a general mediator value $m$ is:\n$Y(0, m) = \\beta_{0} + \\beta_{1}(0) + \\beta_{2} m + \\beta_{3}(0 \\cdot m) + \\beta_{4} C + \\varepsilon_{Y} = \\beta_{0} + \\beta_{2} m + \\beta_{4} C + \\varepsilon_{Y}$.\nSubstituting $m=M(1)$ and $m=M(0)$:\n$$Y(0, M(1)) = \\beta_{0} + \\beta_{2} M(1) + \\beta_{4} C + \\varepsilon_{Y}$$\n$$Y(0, M(0)) = \\beta_{0} + \\beta_{2} M(0) + \\beta_{4} C + \\varepsilon_{Y}$$\nThe difference is:\n$$Y(0, M(1)) - Y(0, M(0)) = \\beta_{2} (M(1) - M(0))$$\nThe difference between the potential mediators is:\n$$M(1) - M(0) = (\\alpha_{0} + \\alpha_{1}(1) + \\alpha_{2} C + \\varepsilon_{M}) - (\\alpha_{0} + \\alpha_{1}(0) + \\alpha_{2} C + \\varepsilon_{M}) = \\alpha_{1}$$\nThis difference is a constant. Therefore:\n$$Y(0, M(1)) - Y(0, M(0)) = \\beta_{2} \\alpha_{1}$$\nTaking the expectation of a constant yields the constant itself:\n$$\\text{ACME}_{0} = \\mathbb{E}[\\alpha_{1} \\beta_{2}] = \\alpha_{1} \\beta_{2}$$\n\n**2. Average Causal Mediation Effect under Exposure $1$ ($\\text{ACME}_1$)**\n\nBy definition, $\\text{ACME}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(1, M(0)) \\right]$.\nFor $e=1$, the outcome equation for a general mediator value $m$ is:\n$Y(1, m) = \\beta_{0} + \\beta_{1}(1) + \\beta_{2} m + \\beta_{3}(1 \\cdot m) + \\beta_{4} C + \\varepsilon_{Y} = \\beta_{0} + \\beta_{1} + (\\beta_{2} + \\beta_{3})m + \\beta_{4} C + \\varepsilon_{Y}$.\nSubstituting $m=M(1)$ and $m=M(0)$:\n$$Y(1, M(1)) = \\beta_{0} + \\beta_{1} + (\\beta_{2} + \\beta_{3})M(1) + \\beta_{4} C + \\varepsilon_{Y}$$\n$$Y(1, M(0)) = \\beta_{0} + \\beta_{1} + (\\beta_{2} + \\beta_{3})M(0) + \\beta_{4} C + \\varepsilon_{Y}$$\nThe difference is:\n$$Y(1, M(1)) - Y(1, M(0)) = (\\beta_{2} + \\beta_{3})(M(1) - M(0))$$\nSince $M(1) - M(0) = \\alpha_{1}$, the difference is the constant $(\\beta_{2} + \\beta_{3})\\alpha_{1}$.\nTaking the expectation:\n$$\\text{ACME}_{1} = \\mathbb{E}[\\alpha_{1} (\\beta_{2} + \\beta_{3})] = \\alpha_{1} (\\beta_{2} + \\beta_{3})$$\n\n**3. Average Direct Effect under Mediator from $E=0$ ($\\text{ADE}_0$)**\n\nBy definition, $\\text{ADE}_{0} = \\mathbb{E} \\left[ Y(1, M(0)) - Y(0, M(0)) \\right]$.\nWe have the expressions for the two potential outcomes:\n$$Y(1, M(0)) = \\beta_{0} + \\beta_{1} + (\\beta_{2} + \\beta_{3})M(0) + \\beta_{4} C + \\varepsilon_{Y}$$\n$$Y(0, M(0)) = \\beta_{0} + \\beta_{2} M(0) + \\beta_{4} C + \\varepsilon_{Y}$$\nThe difference is:\n$$Y(1, M(0)) - Y(0, M(0)) = \\beta_{1} + \\beta_{3} M(0)$$\nThis difference is a random variable because it depends on $M(0)$. We must take its expectation:\n$$\\text{ADE}_{0} = \\mathbb{E}[\\beta_{1} + \\beta_{3} M(0)] = \\beta_{1} + \\beta_{3} \\mathbb{E}[M(0)]$$\nWe compute the expectation of the potential mediator $M(0)$:\n$$\\mathbb{E}[M(0)] = \\mathbb{E}[\\alpha_{0} + \\alpha_{1}(0) + \\alpha_{2} C + \\varepsilon_{M}] = \\alpha_{0} + \\alpha_{2} \\mathbb{E}[C] + \\mathbb{E}[\\varepsilon_{M}] = \\alpha_{0} + \\alpha_{2} \\mu_{C}$$\nSubstituting this back into the expression for $\\text{ADE}_{0}$:\n$$\\text{ADE}_{0} = \\beta_{1} + \\beta_{3} (\\alpha_{0} + \\alpha_{2} \\mu_{C})$$\n\n**4. Average Direct Effect under Mediator from $E=1$ ($\\text{ADE}_1$)**\n\nBy definition, $\\text{ADE}_{1} = \\mathbb{E} \\left[ Y(1, M(1)) - Y(0, M(1)) \\right]$.\nThe potential outcomes are:\n$$Y(1, M(1)) = \\beta_{0} + \\beta_{1} + (\\beta_{2} + \\beta_{3})M(1) + \\beta_{4} C + \\varepsilon_{Y}$$\n$$Y(0, M(1)) = \\beta_{0} + \\beta_{2} M(1) + \\beta_{4} C + \\varepsilon_{Y}$$\nThe difference is:\n$$Y(1, M(1)) - Y(0, M(1)) = \\beta_{1} + \\beta_{3} M(1)$$\nTaking the expectation:\n$$\\text{ADE}_{1} = \\mathbb{E}[\\beta_{1} + \\beta_{3} M(1)] = \\beta_{1} + \\beta_{3} \\mathbb{E}[M(1)]$$\nWe compute the expectation of the potential mediator $M(1)$:\n$$\\mathbb{E}[M(1)] = \\mathbb{E}[\\alpha_{0} + \\alpha_{1}(1) + \\alpha_{2} C + \\varepsilon_{M}] = \\alpha_{0} + \\alpha_{1} + \\alpha_{2} \\mathbb{E}[C] + \\mathbb{E}[\\varepsilon_{M}] = \\alpha_{0} + \\alpha_{1} + \\alpha_{2} \\mu_{C}$$\nSubstituting this back into the expression for $\\text{ADE}_{1}$:\n$$\\text{ADE}_{1} = \\beta_{1} + \\beta_{3} (\\alpha_{0} + \\alpha_{1} + \\alpha_{2} \\mu_{C})$$\n\n### Summary of Formulas\n\n- $\\text{ACME}_{0} = \\alpha_{1} \\beta_{2}$\n- $\\text{ACME}_{1} = \\alpha_{1} (\\beta_{2} + \\beta_{3})$\n- $\\text{ADE}_{0} = \\beta_{1} + \\beta_{3} (\\alpha_{0} + \\alpha_{2} \\mu_{C})$\n- $\\text{ADE}_{1} = \\beta_{1} + \\beta_{3} (\\alpha_{0} + \\alpha_{1} + \\alpha_{2} \\mu_{C})$\n\nNote that the variance parameters $\\sigma_{M}^{2}$, $\\sigma_{Y}^{2}$, and $\\sigma_{C}^{2}$ do not appear in the final expressions for these average effects. This is a characteristic of linear models where expectations are being computed. These parameters would be necessary for calculating variances or confidence intervals of the estimators. The implementation will apply these derived formulas to the provided test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes causal mediation effects for a linear system based on derived formulas.\n    \"\"\"\n    # Test suite: (alpha0, alpha1, alpha2, sigma_M; beta0, beta1, beta2, beta3, beta4, sigma_Y; mu_C, sigma_C)\n    test_cases = [\n        # Case 1 (general case with nonzero interaction)\n        (0.2, 0.8, 0.5, 0.6, -0.1, 0.5, 1.2, -0.4, 0.3, 1.0, 0.0, 1.0),\n        # Case 2 (boundary case with no mediator effect on outcome)\n        (0.2, 0.9, -0.4, 0.5, 0.0, 1.0, 0.0, 0.0, -0.2, 1.2, 1.5, 0.7),\n        # Case 3 (boundary case with no exposure effect on mediator)\n        (0.0, 0.0, 0.7, 0.9, 0.1, 0.3, 1.1, 0.5, 0.0, 0.8, -0.5, 1.3),\n        # Case 4 (interaction-dominant scenario with shifted confounder mean)\n        (-0.3, 0.4, 1.2, 0.4, 0.0, -0.2, 0.6, 0.8, 0.1, 0.9, 2.0, 0.5),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        # Unpack parameters, ignoring variance parameters which are not needed for point estimates.\n        alpha0, alpha1, alpha2, _, _, beta1, beta2, beta3, _, _, mu_C, _ = case\n\n        # Calculate ACME_0: Average Causal Mediation Effect under exposure 0\n        # Formula: alpha1 * beta2\n        acme0 = alpha1 * beta2\n\n        # Calculate ACME_1: Average Causal Mediation Effect under exposure 1\n        # Formula: alpha1 * (beta2 + beta3)\n        acme1 = alpha1 * (beta2 + beta3)\n\n        # Calculate ADE_0: Average Direct Effect under mediator from E=0\n        # Formula: beta1 + beta3 * (alpha0 + alpha2 * mu_C)\n        ade0 = beta1 + beta3 * (alpha0 + alpha2 * mu_C)\n\n        # Calculate ADE_1: Average Direct Effect under mediator from E=1\n        # Formula: beta1 + beta3 * (alpha0 + alpha1 + alpha2 * mu_C)\n        ade1 = beta1 + beta3 * (alpha0 + alpha1 + alpha2 * mu_C)\n\n        # Append the list of four results for the current case\n        all_results.append([acme0, acme1, ade0, ade1])\n\n    # Format the output string to match the required format: [[d.dddddd,...],[...]]\n    # Each number is formatted to six decimal places.\n    outer_list_str = []\n    for res_list in all_results:\n        inner_list_str = \"[\" + \",\".join([f\"{val:.6f}\" for val in res_list]) + \"]\"\n        outer_list_str.append(inner_list_str)\n    \n    final_output_str = \"[\" + \",\".join(outer_list_str) + \"]\"\n    \n    # Print the final formatted string.\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}