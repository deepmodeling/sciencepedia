{
    "hands_on_practices": [
        {
            "introduction": "在启动一项耗资巨大的全基因组关联研究（GWAS）之前，至关重要的是要进行功效（power）分析，以估算成功检测到真实遗传效应所需的样本量。本练习将指导您从第一性原理出发，为基于逻辑斯蒂回归的GWAS推导样本量计算公式，这是研究设计阶段的一项基本技能。通过这个实践，您将应用渐近正态理论和Wald检验的非中心性参数来连接效应大小、显著性水平、统计功效和样本量。",
            "id": "4370897",
            "problem": "一个群体规模的生物样本库计划进行一项全基因组关联研究（Genome-Wide Association Study (GWAS)），该研究针对一种二元疾病结局，采用逻辑斯谛回归和加性遗传模型进行分析。单个双等位基因位点上的基因型被编码为 $g \\in \\{0,1,2\\}$ 个次要等位基因。假设在次要等位基因频率（minor allele frequency (MAF)）为 $p$ 时满足 Hardy–Weinberg 平衡（HWE），个体之间相互独立，并且将组建一个巢式病例对照样本，其中病例和对照的数量相等，因此分析数据集中的病例比例为 $c = 1/2$。真实的每等位基因比值比为 $\\mathrm{OR}$，因此对数比值比回归系数为 $\\beta = \\ln(\\mathrm{OR})$。该生物样本库将采用双侧全基因组显著性阈值 $\\alpha = 5 \\times 10^{-8}$，并针对 $H_{0} : \\beta = 0$ 与 $H_{1} : \\beta \\neq 0$ 的 Wald 检验设定目标功效为 $0.8$。\n\n从逻辑斯谛回归的基本原理、最大似然估计量的渐近正态性以及 Fisher 信息的定义出发，基于这些基础推导出 Wald 检验的非中心参数的近似值，并用它来获得一个闭式表达式，用于计算达到指定显著性水平和功效所需的总样本量 $N$（病例加对照）。你可以使用以下事实：在 HWE 条件下，加性编码下 $g$ 的方差是 $p$ 的函数；并且 Wald 统计量在原假设下渐近服从标准正态分布，在备择假设下服从均值非零的正态分布。请将你的最终答案表示为一个关于 $p$ 和 $\\mathrm{OR}$ 的单一解析表达式，使用标准正态累积分布函数 $\\Phi(\\cdot)$ 及其分位数函数 $\\Phi^{-1}(\\cdot)$。不需要进行数值四舍五入。",
            "solution": "我们使用逻辑斯谛回归和加性遗传效应来对二元结局 $Y \\in \\{0,1\\}$ 进行建模：\n$$\n\\operatorname{logit}\\big(\\Pr(Y=1 \\mid g)\\big) \\;=\\; \\alpha_{0} + \\beta g,\n$$\n其中 $\\beta = \\ln(\\mathrm{OR})$ 是每等位基因的对数比值比效应。检验 $H_{0}:\\beta=0$ 的 Wald 检验使用统计量\n$$\nW \\;=\\; \\frac{\\hat{\\beta}}{\\operatorname{SE}(\\hat{\\beta})},\n$$\n其中 $\\hat{\\beta}$ 是最大似然估计量 (MLE)，$\\operatorname{SE}(\\hat{\\beta})$ 是其标准误。根据经过充分检验的 MLE 渐近理论，$\\hat{\\beta}$ 近似服从均值为 $\\beta$、方差为 $\\beta$ 的 Fisher 信息的倒数的正态分布，\n$$\n\\hat{\\beta} \\;\\dot{\\sim}\\; \\mathcal{N}\\!\\left(\\beta, \\left[I(\\beta)\\right]^{-1}\\right),\n$$\n因此\n$$\nW \\;\\dot{\\sim}\\; \\mathcal{N}\\!\\left(\\delta,\\,1\\right), \\quad \\text{其中} \\quad \\delta \\;=\\; \\frac{\\beta}{\\operatorname{SE}(\\hat{\\beta})} \\;=\\; \\beta \\sqrt{I(\\beta)}.\n$$\n\n我们现在近似计算逻辑斯谛回归中单个预测变量 $g$ 和一个截距项的 $I(\\beta)$。逻辑斯谛回归中 $(\\alpha_{0}, \\beta)$ 的 Fisher 信息矩阵可以写为 $X^{\\top} W X$，其中 $X$ 是列为 $(1, g)$ 的 $N \\times 2$ 设计矩阵，$W$ 是对角矩阵，其对角线上的元素为 $w_{i} = \\pi_{i}(1-\\pi_{i})$，其中 $\\pi_{i} = \\Pr(Y_{i}=1 \\mid g_{i}) = \\operatorname{logit}^{-1}(\\alpha_{0} + \\beta g_{i})$。在考虑截距项后，$\\beta$ 的信息是 $X^{\\top} W X$ 的 $(2,2)$ 元素，可以（使用带有截距项的回归的标准结果）表示为\n$$\nI(\\beta) \\;\\approx\\; \\sum_{i=1}^{N} w_{i} \\left(g_{i} - \\bar{g}\\right)^{2},\n$$\n其中 $\\bar{g}$ 是 $g$ 的样本均值。在病例比例为 $c$ 且 $\\beta$ 为小到中等的情况下，对于巢式病例对照设计，我们统一近似 $w_{i} \\approx c(1-c)$，这反映了在抽样病例比例下结局的伯努利方差。然后对基因型分布取期望得到\n$$\nI(\\beta) \\;\\approx\\; N \\, c(1-c) \\, \\operatorname{Var}(g).\n$$\n\n在次要等位基因频率为 $p$ 的 Hardy–Weinberg 平衡下，加性编码下的基因型 $g$ 具有概率 $\\Pr(g=0)=(1-p)^{2}$，$\\Pr(g=1)=2p(1-p)$ 和 $\\Pr(g=2)=p^{2}$。可以计算出\n$$\n\\mathbb{E}[g] \\;=\\; 2p, \\quad \\mathbb{E}[g^{2}] \\;=\\; 2p(1-p) + 4p^{2},\n$$\n所以\n$$\n\\operatorname{Var}(g) \\;=\\; \\mathbb{E}[g^{2}] - \\big(\\mathbb{E}[g]\\big)^{2} \\;=\\; \\big(2p(1-p) + 4p^{2}\\big) - 4p^{2} \\;=\\; 2p(1-p).\n$$\n\n综合这些，Wald 统计量的非中心参数为\n$$\n\\delta \\;=\\; \\beta \\sqrt{I(\\beta)} \\;\\approx\\; \\beta \\sqrt{N \\, c(1-c) \\, 2p(1-p)}.\n$$\n对于计划的病例对照数量相等的抽样，有 $c = 1/2$，\n$$\nc(1-c) \\;=\\; \\frac{1}{4}, \\quad \\text{所以} \\quad \\delta \\;\\approx\\; \\beta \\sqrt{N \\cdot \\frac{1}{4} \\cdot 2p(1-p)} \\;=\\; \\beta \\sqrt{N \\cdot \\frac{1}{2} p(1-p)}.\n$$\n\n对于显著性水平为 $\\alpha$ 的双侧 Wald 检验，拒绝阈值为 $|W|  z_{1-\\alpha/2}$，其中 $z_{q} = \\Phi^{-1}(q)$，$\\Phi$ 是标准正态累积分布函数。在 $H_{1}$ 下，$W \\dot{\\sim} \\mathcal{N}(\\delta,1)$。功效 $1 - \\beta_{\\text{pow}}$（这里是 $0.8$）满足标准正态近似\n$$\n1 - \\beta_{\\text{pow}} \\;\\approx\\; \\Pr\\!\\left(|Z|  z_{1-\\alpha/2} \\,\\big|\\, Z \\sim \\mathcal{N}(\\delta,1)\\right),\n$$\n根据 $\\Phi$ 的对称性和单调性，这大约在以下情况实现\n$$\n\\delta \\;\\approx\\; z_{1-\\alpha/2} + z_{1-\\beta_{\\text{pow}}}.\n$$\n令 $\\delta$ 的表达式相等并求解 $N$ 可得\n$$\n\\beta \\sqrt{N \\cdot \\frac{1}{2} p(1-p)} \\;=\\; z_{1-\\alpha/2} + z_{1-\\beta_{\\text{pow}}}\n\\quad \\Longrightarrow \\quad\nN \\;=\\; \\frac{\\big(z_{1-\\alpha/2} + z_{1-\\beta_{\\text{pow}}}\\big)^{2}}{\\frac{1}{2} p(1-p) \\beta^{2}}.\n$$\n代入 $\\beta = \\ln(\\mathrm{OR})$，$\\alpha = 5 \\times 10^{-8}$（因此 $z_{1-\\alpha/2} = \\Phi^{-1}(1 - 2.5 \\times 10^{-8})$），以及 $1 - \\beta_{\\text{pow}} = 0.8$（因此 $z_{1-\\beta_{\\text{pow}}} = \\Phi^{-1}(0.8)$），我们得到所需的总样本量：\n$$\nN \\;=\\; \\frac{\\big(\\,\\Phi^{-1}(1 - 2.5 \\times 10^{-8}) + \\Phi^{-1}(0.8)\\,\\big)^{2}}{\\frac{1}{2} \\, p(1-p) \\, \\big(\\ln(\\mathrm{OR})\\big)^{2}}\n\\;=\\;\n\\frac{2 \\, \\big(\\,\\Phi^{-1}(1 - 2.5 \\times 10^{-8}) + \\Phi^{-1}(0.8)\\,\\big)^{2}}{p(1-p) \\, \\big(\\ln(\\mathrm{OR})\\big)^{2}}.\n$$\n这是一个用 $p$ 和 $\\mathrm{OR}$ 表示的闭式解析表达式，具有指定的 $\\alpha$ 和功效，它是从逻辑斯谛回归的 Fisher 信息和 Wald 检验的渐近分布推导出来的。",
            "answer": "$$\\boxed{\\frac{2\\left(\\Phi^{-1}\\!\\left(1-2.5\\times 10^{-8}\\right)+\\Phi^{-1}\\!\\left(0.8\\right)\\right)^{2}}{p\\left(1-p\\right)\\left(\\ln\\!\\left(\\mathrm{OR}\\right)\\right)^{2}}}$$"
        },
        {
            "introduction": "在人群规模的生物样本库中，确保测序数据的质量是分析成功的基石，而样本污染是高通量流程中常见的技术问题。本练习提供了一个基于模型的实用方法，利用在纯合位点观察到的次要等位基因读数来估计样本间的污染比例。掌握这种质量控制技术对于维护大规模测序项目的数据完整性至关重要。",
            "id": "4370879",
            "problem": "一个国家级的人群生物样本库对大量参与者进行测序，并通过分析索引样本中纯合位点的等位基因平衡来监控高通量流程中的样本污染。考虑一个经过筛选的双等位基因单核苷酸多态性（SNP）组合，这些SNP被选中是因为其在人群中具有较高的预期杂合度。对于一个给定的样本，在该组合的所有索引样本纯合位点上，定义汇集的次要等位基因读数计数为 $X$，汇集的总读数计数为 $D$（因此，任何观察到的次要等位基因读数都源于测序错误或污染）。假设以下基本前提：\n\n- 每个读数都是一次独立的伯努利试验，这反映了短读长测序中分子的标准随机抽样过程。每个读数出现次要等位基因的概率取决于该读数是源自索引样本还是污染物。\n- 设污染比例为 $c \\in [0,1]$，意味着任何给定读数源自污染物基因组的概率为 $c$，源自索引基因组的概率为 $1 - c$。\n- 设每个碱基的测序错误率为 $\\epsilon \\in (0, 0.5)$，并假设该值通过对照数据的校准已知。\n- 设 $h \\in [0,1]$ 表示在生物样本库人群中随机抽取的污染物基因组在选定SNP组合上的杂合度概率，并假设该值从群体规模的等位基因频率数据中已知。在杂合的污染物基因型处，每个读数的预期次要等位基因概率为 $0.5$；在这些位点的纯合污染物基因型处，次要等位基因读数仅由错误产生，错误率为 $\\epsilon$。\n\n在这些假设下，每个读数的次要等位基因概率在读数水平上是一个双组分混合模型：一个读数有 $1-c$ 的概率来自索引基因组，并以 $\\epsilon$ 的概率贡献一个次要等位基因；有 $c$ 的概率来自污染物，并根据该SNP组合的群体杂合度结构贡献一个次要等位基因。由于读数的独立性，$D$ 个读数中汇集的次要等位基因计数 $X$ 服从二项分布，其成功参数是 $c$ 的一个仿射函数。仅使用这些基本假设，从第一性原理推导：\n\n1) 在由读数水平的双组分混合模型所隐含的二项模型下，给定 $X$ 和 $D$ 时 $c$ 的汇集似然函数，以及用观测到的汇集次要等位基因比例 $X/D$、$\\epsilon$ 和 $h$ 表示的 $c$ 的最大似然估计（MLE）。该估计值必须被裁剪到区间 $[0,1]$ 内。\n\n2) 使用精确的 Clopper–Pearson 方法，为汇集的二项分布次要等位基因概率参数构建一个双侧等尾 $100(1-\\alpha)\\%$ 置信区间，并通过反转仿射映射将其转换为 $c$ 的置信区间。将转换后的边界裁剪到 $[0,1]$ 内。\n\n3) 一个适用于群体规模生物样本库质量控制的排除规则：当且仅当污染的点估计值 $c$ 大于或等于指定的阈值 $\\tau$ 时，排除一个样本（所有污染值均以小数表示，而非百分比）。\n\n实现一个程序，对于固定的 SNP 组合和质量控制配置，为每个测试样本计算：\n- 污染的点估计值 $\\hat{c}$，\n- $c$ 的双侧 Clopper–Pearson $100(1-\\alpha)\\%$ 置信区间的下界和上界，\n- 根据上述规则得出的排除决策（布尔值）。\n\n使用以下固定参数，这些参数由高质量的短读长测序流程和从生物样本库筛选的高杂合度SNP组合所支持：\n- 测序错误率 $\\epsilon = 0.002$，\n- SNP组合杂合度概率 $h = 0.5$，\n- 置信水平 $1-\\alpha = 0.95$（即 $\\alpha = 0.05$），\n- 排除阈值 $\\tau = 0.03$。\n\n测试套件。对于每个测试用例，给定索引样本所有纯合位点上的汇集总数 $(D, X)$：\n- 用例 A（典型的低污染）：$D = 150000, X = 487$。\n- 用例 B（接近排除阈值）：$D = 120000, X = 1136$。\n- 用例 C（高污染）：$D = 100000, X = 2192$。\n- 用例 D（无污染但有抽样波动）：$D = 180000, X = 355$。\n- 用例 E（在较低覆盖度下的临界情况）：$D = 5000, X = 45$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应于从 A 到 E 的一个测试用例，并且本身是一个包含四个元素的列表：$[\\hat{c}, c_{\\text{low}}, c_{\\text{high}}, \\text{exclude}]$。三个污染值必须四舍五入到恰好 $6$ 位小数，布尔值必须是语言原生的布尔值。例如，两个假设用例的输出应如下所示：$[[0.012345,0.010000,0.015000,False],[0.045678,0.043000,0.048500,True]]$。",
            "solution": "该问题被认为是有效的，因为它在科学上基于测序数据的标准模型，信息完备、问题适定，并且表达客观。我们接下来进行求解。\n\n解答过程遵循问题陈述，分为三个部分。首先，我们推导污染比例 $c$ 的最大似然估计（MLE）。其次，我们推导 $c$ 的置信区间。第三，我们明确排除规则。\n\n### 第1部分：污染估计量（$\\hat{c}$）的推导\n\n该模型的核心是确定在索引样本中为纯合的位点上，单个读数显示次要等位基因的概率（我们称之为 $p$）。这个概率 $p$ 是一个二项分布的成功参数，该二项分布决定了总共 $D$ 个读数中汇集的次要等位基因计数 $X$。\n\n概率 $p$ 是一个混合概率，取决于读数的来源（索引样本或污染物）。\n设 $c$ 为污染比例。一个读数源自污染物的概率为 $c$，源自索引样本的概率为 $1-c$。\n设 $\\epsilon$ 为每个碱基的测序错误率。\n设 $h$ 为污染物在给定SNP组合位点上是杂合子的概率。\n\n在单个读数中观察到次要等位基因的概率 $p$ 由全概率公式给出：\n$$p(c) = P(\\text{minor allele} | \\text{read from index}) P(\\text{read from index}) + P(\\text{minor allele} | \\text{read from contaminant}) P(\\text{read from contaminant})$$\n\n1.  如果读数来自索引样本（概率为 $1-c$）：索引样本在选定位点上是主要等位基因的纯合子。只有在发生测序错误时才能观察到次要等位基因。因此，$P(\\text{minor allele} | \\text{read from index}) = \\epsilon$。\n\n2.  如果读数来自污染物（概率为 $c$）：观察到次要等位基因的概率取决于污染物的基因型。\n    -   污染物是杂合子（例如，在 A/A 索引位点处为 A/T）的概率为 $h$。在这种情况下，抽样到次要等位基因的概率是 $0.5$。\n    -   污染物与索引样本具有相同的主要等位基因纯合子（例如，在 A/A 索引位点处为 A/A）的概率为 $1-h$。在这种情况下，只有在发生测序错误时才会观察到次要等位基因，其概率为 $\\epsilon$。\n    因此，给定读数来自污染物，观察到次要等位基因的概率为：\n    $$P(\\text{minor allele} | \\text{read from contaminant}) = h \\cdot 0.5 + (1-h) \\cdot \\epsilon$$\n\n结合这些项，总的次要等位基因概率 $p$ 是：\n$$p(c) = \\epsilon (1-c) + \\left( 0.5h + \\epsilon(1-h) \\right) c$$\n展开并简化表达式：\n$$p(c) = \\epsilon - \\epsilon c + 0.5hc + \\epsilon c - h\\epsilon c$$\n$$p(c) = \\epsilon + c(0.5h - h\\epsilon)$$\n$$p(c) = \\epsilon + ch(0.5 - \\epsilon)$$\n这证实了 $p$ 是 $c$ 的一个仿射函数。设常数斜率为 $A = h(0.5 - \\epsilon)$。关系式为 $p(c) = \\epsilon + Ac$。\n\n在总共 $D$ 个读数中，次要等位基因读数的数量 $X$ 被建模为一个二项随机变量：\n$$X \\sim \\text{Binomial}(D, p(c))$$\n给定数据 $(X, D)$ 时，$c$ 的似然函数为：\n$$L(c; X, D) = \\binom{D}{X} [p(c)]^X [1 - p(c)]^{D-X}$$\n为了找到 $c$ 的最大似然估计（MLE），我们最大化对数似然 $\\ell(c) = \\log L(c)$。众所周知，二项比例 $p$ 的 MLE 是 $\\hat{p} = X/D$。我们可以通过对对数似然函数关于 $p$（并延伸至 $c$）求导来证明这一点：\n$$\\frac{d\\ell}{dc} = \\frac{d\\ell}{dp} \\frac{dp}{dc} = \\left( \\frac{X}{p} - \\frac{D-X}{1-p} \\right) A$$\n将导数设为零（并假设 $A \\neq 0$），我们发现括号中的项必须为零，这得出 $\\hat{p} = X/D$。\n\n将此代入我们关于 $p(c)$ 的仿射关系式中：\n$$\\hat{p} = \\epsilon + \\hat{c}h(0.5 - \\epsilon)$$\n求解 MLE $\\hat{c}$：\n$$\\hat{c} = \\frac{\\hat{p} - \\epsilon}{h(0.5 - \\epsilon)} = \\frac{X/D - \\epsilon}{h(0.5 - \\epsilon)}$$\n由于 $c$ 是一个比例，其估计值必须位于区间 $[0,1]$ 内。我们通过裁剪估计值来强制执行这一点：\n$$\\hat{c}_{\\text{clipped}} = \\max\\left(0, \\min\\left(1, \\frac{X/D - \\epsilon}{h(0.5 - \\epsilon)}\\right)\\right)$$\n\n### 第2部分：$c$ 的置信区间的推导\n\n我们首先使用精确的 Clopper-Pearson 方法，计算二项比例 $p$ 的一个 $100(1-\\alpha)\\%$ 置信区间，记为 $[p_{\\text{low}}, p_{\\text{high}}]$。该方法通过对二项检验进行反演来定义区间边界。\n-   下界 $p_{\\text{low}}$ 是这样一个 $p$ 值，使得观察到 $X$ 或更多次成功的概率为 $\\alpha/2$：\n    $$P(Y \\ge X | Y \\sim \\text{Binomial}(D, p_{\\text{low}})) = \\sum_{k=X}^{D} \\binom{D}{k} p_{\\text{low}}^k (1-p_{\\text{low}})^{D-k} = \\frac{\\alpha}{2}$$\n-   上界 $p_{\\text{high}}$ 是这样一个 $p$ 值，使得观察到 $X$ 或更少次成功的概率为 $\\alpha/2$：\n    $$P(Y \\le X | Y \\sim \\text{Binomial}(D, p_{\\text{high}})) = \\sum_{k=0}^{X} \\binom{D}{k} p_{\\text{high}}^k (1-p_{\\text{high}})^{D-k} = \\frac{\\alpha}{2}$$\n\n这些方程可以使用 Beta 分布的分位数来求解。\n-   $p_{\\text{low}} = B(\\frac{\\alpha}{2}; X, D-X+1)$，其中 $B(q; a, b)$ 是形状参数为 $a$ 和 $b$ 的 Beta 分布的 $q$-分位数。如果 $X=0$，则 $p_{\\text{low}}=0$。\n-   $p_{\\text{high}} = B(1-\\frac{\\alpha}{2}; X+1, D-X)$。如果 $X=D$，则 $p_{\\text{high}}=1$。\n\n接下来，我们将 $p$ 的这个区间转换为 $c$ 的置信区间。关系式 $c(p) = \\frac{p - \\epsilon}{h(0.5 - \\epsilon)}$ 是关于 $p$ 单调递增的，因为对于给定的参数（$h=0.5 > 0$ 和 $\\epsilon=0.002  0.5$），分母 $h(0.5 - \\epsilon)$ 是正数。\n因此，$c$ 的置信区间 $[c_{\\text{low}}, c_{\\text{high}}]$ 是通过将该变换应用于 $p$ 的区间边界得到的：\n$$c_{\\text{low}} = \\frac{p_{\\text{low}} - \\epsilon}{h(0.5 - \\epsilon)}$$\n$$c_{\\text{high}} = \\frac{p_{\\text{high}} - \\epsilon}{h(0.5 - \\epsilon)}$$\n与点估计一样，这些边界也被裁剪到有效范围 $[0, 1]$ 内：\n$$c_{\\text{low, clipped}} = \\max(0, \\min(1, c_{\\text{low}}))$$\n$$c_{\\text high, clipped}} = \\max(0, \\min(1, c_{\\text{high}}))$$\n\n### 第3部分：排除规则\n\n质量控制规则是，如果一个样本的污染点估计值 $\\hat{c}$ 大于或等于指定的阈值 $\\tau$，则排除该样本。\n$$\\text{exclude} = (\\hat{c} \\ge \\tau)$$\n\n使用固定参数：\n-   $\\epsilon = 0.002$\n-   $h = 0.5$\n-   $1-\\alpha = 0.95 \\implies \\alpha = 0.05 \\implies \\alpha/2 = 0.025$\n-   $\\tau = 0.03$\n\n用于变换的分母是 $h(0.5 - \\epsilon) = 0.5(0.5 - 0.002) = 0.249$。\n\n使用推导出的公式来处理这些测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import beta\n\ndef solve():\n    \"\"\"\n    Solves the contamination estimation problem for a series of test cases.\n    \"\"\"\n\n    # Fixed parameters from the problem statement\n    epsilon = 0.002  # sequencing error rate\n    h = 0.5          # panel heterozygosity probability\n    alpha = 0.05     # for 95% confidence interval\n    tau = 0.03       # exclusion threshold\n\n    # Test cases: (D, X)\n    # D: pooled total read count\n    # X: pooled minor-allele read count\n    test_cases = [\n        (150000, 487),   # Case A\n        (120000, 1136),  # Case B\n        (100000, 2192),  # Case C\n        (180000, 355),   # Case D\n        (5000, 45)       # Case E\n    ]\n\n    # Pre-calculate the constant denominator for the transformation\n    # c = (p - epsilon) / denom\n    denom = h * (0.5 - epsilon)\n\n    results_as_strings = []\n    for D, X in test_cases:\n        # 1. Calculate the Maximum Likelihood Estimate (MLE) of c\n        p_hat = X / D\n        c_hat_raw = (p_hat - epsilon) / denom\n        c_hat = max(0.0, min(1.0, c_hat_raw))\n\n        # 2. Calculate the Clopper-Pearson confidence interval for c\n\n        # Calculate CI for the binomial proportion p\n        if X == 0:\n            p_low = 0.0\n        else:\n            p_low = beta.ppf(alpha / 2, X, D - X + 1)\n        \n        if X == D:\n            p_high = 1.0\n        else:\n            p_high = beta.ppf(1 - alpha / 2, X + 1, D - X)\n\n        # Transform the CI for p to a CI for c\n        c_low_raw = (p_low - epsilon) / denom\n        c_high_raw = (p_high - epsilon) / denom\n        \n        # Clip the CI bounds to the [0, 1] interval\n        c_low = max(0.0, min(1.0, c_low_raw))\n        c_high = max(0.0, min(1.0, c_high_raw))\n\n        # 3. Apply the exclusion rule\n        exclude = c_hat >= tau\n\n        # Format the results for this case\n        result_string = (\n            f\"[{c_hat:.6f},\"\n            f\"{c_low:.6f},\"\n            f\"{c_high:.6f},\"\n            f\"{exclude}]\"\n        )\n        results_as_strings.append(result_string)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results_as_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "高质量的基因型数据中往往隐藏着复杂的群体结构，即不同祖源亚群之间存在系统性的等位基因频率差异，这可能导致在关联分析中出现虚假阳性结果。主成分分析（PCA）是揭示和校正这种混杂因素的标准工具。本练习将通过模拟混合祖源人群的基因型数据，并应用奇异值分解（SVD）来执行PCA，从而量化由主要主成分解释的遗传变异，这是现代遗传学分析中不可或缺的一步。",
            "id": "4370918",
            "problem": "一个人群规模级别的生物样本库收集了大量个体在众多基因组变异位点上的基因型剂量。考虑一个由多个大陆级别祖源群体组成的混合血统队列。该队列由一个基因型矩阵表示，其中行是样本，列是变异。每个条目是每个样本每个变异的变异等位基因计数，取值为 $\\{0,1,2\\}$。对标准化基因型数据进行主成分分析（PCA）是捕获群体结构的常用方法，如果未加考虑，可能会干扰下游的精准医疗分析。您的任务是通过奇异值分解计算主成分，并量化在几种情景下，顶部主成分所解释的总方差比例。\n\n使用以下基本原理：\n- 基因型剂量 $g_{ij} \\in \\{0,1,2\\}$ 是样本 $i$ 和变异 $j$ 的变异等位基因计数。\n- 所有样本中变异 $j$ 的等位基因频率为 $p_j = \\frac{1}{2n} \\sum_{i=1}^{n} g_{ij}$，其中 $n$ 是样本数。\n- 在哈迪-温伯格平衡下，变异 $j$ 的基因型剂量的期望方差为 $2 p_j (1 - p_j)$，这被广泛用于PCA中基因型列的标准化。\n- 设标准化数据矩阵为 $X \\in \\mathbb{R}^{n \\times m}$，其条目为 $x_{ij} = \\frac{g_{ij} - 2 p_j}{\\sqrt{2 p_j (1 - p_j)}}$，适用于所有 $0  p_j  1$ 的变异。$p_j \\in \\{0,1\\}$ 的变异方差为零，必须从PCA中排除。\n- 对 $X$ 的主成分分析可以通过奇异值分解 $X = U \\Sigma V^{\\top}$ 获得，其中 $\\Sigma$ 具有非负奇异值 $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq 0$。\n\n根据这些原理，推导出如何从奇异值计算每个主成分解释的方差比例，并以算法形式实现。您必须：\n1. 根据指定参数，为一个具有大陆级别祖源的混合血统队列构建合成基因型矩阵。对于每个祖源群体 $g$，通过从二项分布中抽样生成每个基因型 $g_{ij}$，其中试验次数为 $2$，成功概率等于该群体特定的等位基因频率 $p_{j}^{(g)}$。每个测试用例使用固定的伪随机种子以确保确定性输出。\n2. 使用上述哈迪-温伯格缩放方法标准化基因型矩阵，移除单态性变异（$p_j \\in \\{0,1\\}$）。\n3. 计算标准化矩阵的奇异值分解，并计算前 $k$ 个主成分解释的总方差比例。将每个比例表示为四舍五入到四位小数的小数（不带百分号）。\n\n测试套件与参数：\n实现以下三个测试用例。每个用例由群体大小、变异数量、具有特定群体等位基因频率的祖源信息标记（AIM）块、其余变异在各群体间共享的中性等位基因频率、一个伪随机种子以及 $k$（要报告的顶部主成分数量）定义。\n\n- 用例 1（一般的混合双祖源队列）：\n    - 群体数量：$2$ 个，群体大小为 $[100, 100]$。\n    - 变异数量：$500$。\n    - AIM 块：一个块，数量为 $80$，两个群体的特定群体等位基因频率分别为 $[0.1, 0.9]$。\n    - 其余变异的中性等位基因频率：两个群体均为 $0.3$。\n    - 种子：$123$。\n    - 报告前 $k = 3$ 个主成分。\n\n- 用例 2（边界情况：单一祖源群体，结构极小）：\n    - 群体数量：$1$ 个，群体大小为 $[120]$。\n    - 变异数量：$400$。\n    - AIM 块：无（即，所有变异在单一群体中具有相同的等位基因频率）。\n    - 所有变异的中性等位基因频率：$0.3$。\n    - 种子：$456$。\n    - 报告前 $k = 3$ 个主成分。\n\n- 用例 3（具有两个正交AIM块的三祖源队列）：\n    - 群体数量：$3$ 个，群体大小为 $[80, 80, 40]$。\n    - 变异数量：$600$。\n    - AIM 块：两个块：\n        - 块 1：数量 $30$，特定群体等位基因频率为 $[0.1, 0.9, 0.9]$。\n        - 块 2：数量 $30$，特定群体等位基因频率为 $[0.9, 0.1, 0.9]$。\n    - 其余变异的中性等位基因频率：所有群体均为 $0.3$。\n    - 种子：$789$。\n    - 报告前 $k = 3$ 个主成分。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素对应一个测试用例，必须是一个由方括号括起来、逗号分隔的前 $k$ 个方差解释比例列表，四舍五入到四位小数，无空格。例如：“[[0.3210,0.1205,0.0800],[0.0155,0.0132,0.0121],[0.2501,0.1700,0.1200]]”。",
            "solution": "该问题要求实现一个标准的群体遗传学工作流程来分析模拟的基因型数据。这包括为混合群体生成合成基因型，对数据进行标准化，通过奇异值分解（SVD）执行主成分分析（PCA），并通过计算前几个主成分解释的总方差比例来量化群体结构。\n\n首先，我们建立从奇异值计算方差解释比例的理论基础。设标准化基因型矩阵为 $X \\in \\mathbb{R}^{n \\times m'}$，其中 $n$ 是样本数量，$m'$ 是多态性变异（即等位基因频率 $p_j$ 满足 $0  p_j  1$ 的变异）的数量。该矩阵的条目由 $x_{ij} = \\frac{g_{ij} - 2 p_j}{\\sqrt{2 p_j (1 - p_j)}}$ 给出。根据构造，$X$ 的每一列都经过中心化，均值为 $0$，并已标准化。\n\n数据中的总方差是数据点总离散程度的度量。在PCA的背景下，它被定义为样本协方差矩阵 $\\frac{1}{n-1}X^{\\top}X$ 的迹。与总方差成比例的总平方和，可以通过矩阵 $X$ 的弗罗贝尼乌斯范数的平方来计算：\n$$ \\|X\\|_F^2 = \\sum_{i=1}^{n} \\sum_{j=1}^{m'} x_{ij}^2 $$\n$X$ 的奇异值分解由 $X = U \\Sigma V^{\\top}$ 给出，其中 $U \\in \\mathbb{R}^{n \\times n}$ 和 $V \\in \\mathbb{R}^{m' \\times m'}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{n \\times m'}$ 是一个矩形对角矩阵，其对角线上有非负奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r > 0$，其中 $r$ 是 $X$ 的秩。\n\nSVD 的一个关键性质是，矩阵的弗罗贝尼乌斯范数的平方等于其奇异值平方的总和：\n$$ \\|X\\|_F^2 = \\text{Tr}(X^{\\top}X) = \\text{Tr}((U\\Sigma V^{\\top})^{\\top}(U\\Sigma V^{\\top})) = \\text{Tr}(V\\Sigma^{\\top}U^{\\top}U\\Sigma V^{\\top}) = \\text{Tr}(V\\Sigma^{\\top}\\Sigma V^{\\top}) $$\n利用迹的循环性质 $\\text{Tr}(ABC) = \\text{Tr}(CAB)$，我们有：\n$$ \\text{Tr}(V(\\Sigma^{\\top}\\Sigma) V^{\\top}) = \\text{Tr}((\\Sigma^{\\top}\\Sigma)V^{\\top}V) = \\text{Tr}(\\Sigma^{\\top}\\Sigma) = \\sum_{k=1}^{r} \\sigma_k^2 $$\n第 $k$ 个主成分捕获的方差与第 $k$ 个奇异值 $\\sigma_k^2$ 的平方成正比。因此，第 $k$ 个主成分解释的总方差比例是 $\\sigma_k^2$ 与所有奇异值平方和的比值。\n$$ \\text{方差比例 (PC}_k\\text{)} = \\frac{\\sigma_k^2}{\\sum_{l=1}^{r} \\sigma_l^2} $$\n该公式提供了一种从标准化基因型矩阵的奇异值直接计算所需量的方法。\n\n针对每个测试用例解决问题的算法流程如下：\n1.  **数据模拟**：构建一个基因型矩阵 $G \\in \\mathbb{R}^{n \\times m}$，其中 $n$ 是所有群体的总样本数，$m$ 是总变异数。\n    - 创建一个大小为 $m \\times (\\text{群体数量})$ 的等位基因频率矩阵，用指定的祖源信息标记（AIM）块和中性背景频率填充。\n    - 建立从每个样本索引 $i \\in \\{1, \\dots, n\\}$ 到其对应祖源群体 $g$ 的映射。\n    - 对于群体 $g$ 中的每个样本 $i$ 和每个变异 $j$，从二项分布中抽取一个基因型剂量 $g_{ij}$，$g_{ij} \\sim \\text{Binomial}(2, p_{j}^{(g)})$，其中 $p_{j}^{(g)}$ 是群体 $g$ 中变异 $j$ 的等位基因频率。为确保每个用例的可复现性，使用固定的伪随机种子。\n2.  **数据标准化**：\n    - 使用公式 $p_j = \\frac{1}{2n} \\sum_{i=1}^{n} g_{ij}$ 计算每个变异 $j$ 在所有 $n$ 个样本中的总体等位基因频率。\n    - 识别并从矩阵 $G$ 中排除单态性变异（即 $p_j = 0$ 或 $p_j = 1$），得到一个大小为 $n \\times m'$ 的新矩阵 $G'$，其中 $m' \\le m$。\n    - 对矩阵 $G'$ 进行列标准化，生成矩阵 $X$，其条目为 $x_{ij} = \\frac{g'_{ij} - 2 p'_j}{\\sqrt{2 p'_j (1 - p'_j)}}$，其中 $p'_j$ 是多态性变异的频率。\n3.  **SVD与方差计算**：\n    - 对标准化矩阵 $X$ 计算奇异值分解以获得奇异值 $\\sigma_k$。我们只需要奇异值，而不需要完整的 $U$ 和 $V$ 矩阵。\n    - 计算奇异值的平方 $\\sigma_k^2$。总方差计算为它们的和，$V_{\\text{total}} = \\sum_k \\sigma_k^2$。\n    - 计算前 $k$ 个主成分各自解释的方差比例，即 $\\sigma_k^2 / V_{\\text{total}}$。\n4.  **报告**：收集前 $k$ 个主成分的所得比例，并按要求四舍五入到四位小数。对每个提供的测试用例重复此过程。\n\n这种有原则的方法确保了实现的正确性和稳健性，它直接源于PCA和SVD的数学定义。",
            "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n\n    def _solve_case(group_sizes, num_variants, aim_blocks, neutral_af, seed, k):\n        \"\"\"\n        Solves a single test case for genotype simulation and PCA variance analysis.\n        \"\"\"\n        # Initialize a random number generator with the specified seed for reproducibility\n        rng = np.random.default_rng(seed)\n        \n        num_groups = len(group_sizes)\n        n_total_samples = sum(group_sizes)\n        m_total_variants = num_variants\n\n        # 1. Construct allele frequency matrix (p_jg): variants x groups\n        p_variants_groups = np.zeros((m_total_variants, num_groups))\n        \n        current_variant_idx = 0\n        if aim_blocks:\n            for block in aim_blocks:\n                count, freqs = block['count'], block['freqs']\n                p_variants_groups[current_variant_idx:current_variant_idx + count, :] = freqs\n                current_variant_idx += count\n        \n        # Fill remaining variants with the neutral allele frequency\n        if current_variant_idx  m_total_variants:\n            p_variants_groups[current_variant_idx:, :] = neutral_af\n            \n        # 2. Generate genotype matrix G\n        # Create a map from sample index to group index\n        sample_to_group_map = np.repeat(np.arange(num_groups), group_sizes)\n        \n        # Generate genotypes g_ij ~ Binomial(2, p_j^(g))\n        G = np.zeros((n_total_samples, m_total_variants), dtype=np.float64)\n        for i in range(n_total_samples):\n            group_idx = sample_to_group_map[i]\n            # Get all allele frequencies for the variants for that sample's group\n            allele_freqs_for_sample = p_variants_groups[:, group_idx]\n            G[i, :] = rng.binomial(2, p=allele_freqs_for_sample)\n            \n        # 3. Standardize the genotype matrix\n        # Calculate overall allele frequencies p_j for each variant\n        # Use np.sum(G, axis=0, dtype=np.float64) to prevent potential overflow with integer types\n        p_j = np.sum(G, axis=0) / (2 * n_total_samples)\n        \n        # Identify and filter out monomorphic variants (where p_j is 0 or 1)\n        is_polymorphic = (p_j > 0)  (p_j  1)\n        \n        G_poly = G[:, is_polymorphic]\n        p_j_poly = p_j[is_polymorphic]\n        \n        # If no polymorphic variants remain, variance is zero.\n        if G_poly.shape[1] == 0:\n            return [0.0] * k\n            \n        # Standardize G_poly to create matrix X\n        mean_g = 2 * p_j_poly\n        std_g = np.sqrt(2 * p_j_poly * (1 - p_j_poly))\n        \n        X = (G_poly - mean_g) / std_g\n        \n        # 4. Compute SVD and calculate variance fractions\n        # We only need the singular values, so compute_uv=False is efficient.\n        singular_values = svd(X, compute_uv=False)\n        \n        # The number of non-zero singular values cannot exceed min(n, m')\n        num_components = len(singular_values)\n        if num_components == 0:\n            return [0.0] * k\n\n        squared_sv = singular_values**2\n        total_variance = np.sum(squared_sv)\n\n        if total_variance == 0:\n            return [0.0] * k\n            \n        variance_fractions = squared_sv / total_variance\n        \n        # 5. Format results for the top k components\n        top_k_fractions = list(variance_fractions[:k])\n        \n        # Pad with zeros if the rank of the matrix is less than k\n        if len(top_k_fractions)  k:\n            top_k_fractions.extend([0.0] * (k - len(top_k_fractions)))\n            \n        return top_k_fractions\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"group_sizes\": [100, 100], \"num_variants\": 500,\n            \"aim_blocks\": [{'count': 80, 'freqs': [0.1, 0.9]}],\n            \"neutral_af\": 0.3, \"seed\": 123, \"k\": 3\n        },\n        # Case 2\n        {\n            \"group_sizes\": [120], \"num_variants\": 400,\n            \"aim_blocks\": [],\n            \"neutral_af\": 0.3, \"seed\": 456, \"k\": 3\n        },\n        # Case 3\n        {\n            \"group_sizes\": [80, 80, 40], \"num_variants\": 600,\n            \"aim_blocks\": [\n                {'count': 30, 'freqs': [0.1, 0.9, 0.9]},\n                {'count': 30, 'freqs': [0.9, 0.1, 0.9]}\n            ],\n            \"neutral_af\": 0.3, \"seed\": 789, \"k\": 3\n        }\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = _solve_case(**params)\n        all_results.append(result)\n\n    # Format the final output string according to the specified format.\n    # \"[[res1_1,res1_2,...],[res2_1,res2_2,...],...]\"\n    # with each fraction rounded to four decimal places.\n    formatted_case_results = []\n    for res_list in all_results:\n        # Format each number to exactly four decimal places\n        formatted_list_str = [f\"{x:.4f}\" for x in res_list]\n        # Join numbers with commas and enclose in brackets\n        formatted_case_results.append(f\"[{','.join(formatted_list_str)}]\")\n    \n    # Join all case results and enclose in the final brackets\n    final_output_string = f\"[{','.join(formatted_case_results)}]\"\n    print(final_output_string)\n\nsolve()\n```"
        }
    ]
}