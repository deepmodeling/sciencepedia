{
    "hands_on_practices": [
        {
            "introduction": "This exercise focuses on a fundamental preprocessing step for single-cell RNA-sequencing data. By converting raw Unique Molecular Identifier (UMI) counts into log-normalized expression values, we stabilize variance and make gene expression levels comparable across cells with different library sizes. This normalization is a crucial prerequisite for nearly all downstream analyses, including multi-omics integration, and ensures that biological variation, rather than technical noise, drives the results. ",
            "id": "4607704",
            "problem": "A clinical study aims to integrate single-cell RNA sequencing (scRNA-seq) and single-cell Assay for Transposase-Accessible Chromatin using sequencing (scATAC-seq) profiles to discover gene regulatory programs associated with therapy response in a heterogeneous tumor microenvironment. To construct a joint latent space, the scRNA-seq modality must first be transformed to a stabilized, relative abundance scale that is comparable across cells of varying sequencing depths. In scRNA-seq, Unique Molecular Identifier (UMI) counts $c_{ig}$ for gene $g$ in cell $i$ are proportional to the number of captured transcript molecules, and the total $\\sum_{g} c_{ig}$ reflects the library size for cell $i$.\n\nStarting from the following well-tested processing steps grounded in standard practice for single-cell transcript quantification:\n- Relative abundance is obtained by dividing the raw count for a gene by the cell’s total UMI count, yielding a fraction $c_{ig} / \\sum_{g} c_{ig}$.\n- To render the scale interpretable and mitigate the extreme sparsity typical in single-cell data while maintaining comparability across cells, this fraction is rescaled to counts per $10^{4}$ by multiplying by $10^{4}$.\n- To stabilize variance and dampen the influence of highly expressed genes, apply a logarithm with base $2$ to the rescaled quantity, adding a pseudocount of $1$ before the log to avoid taking a logarithm of zero.\n\nUsing these definitions, derive the symbolic expression for the log-normalized expression $\\tilde{x}_{ig}$ and then compute its value for a cell with raw UMI count $c_{ig} = 50$ for a particular gene and total UMI count $\\sum_{g} c_{ig} = 5000$. Express your final answer as a dimensionless value and round to four significant figures.",
            "solution": "The problem statement is a valid and well-posed request within the domain of bioinformatics and computational biology. It describes a standard procedure for single-cell RNA sequencing (scRNA-seq) data normalization, a critical preprocessing step for downstream analyses such as multi-omics integration. All provided information is scientifically sound, self-contained, and sufficient to derive a unique solution.\n\nThe task is to first derive the symbolic expression for the log-normalized expression, denoted as $\\tilde{x}_{ig}$, for gene $g$ in cell $i$, and then to compute its numerical value given specific UMI counts. We will follow the prescribed sequence of operations.\n\nLet $c_{ig}$ be the raw Unique Molecular Identifier (UMI) count for gene $g$ in cell $i$.\nLet $C_i = \\sum_{g} c_{ig}$ be the total UMI count for cell $i$, which is also referred to as the library size of the cell.\n\nThe normalization process consists of three defined steps:\n\nStep 1: Compute the relative abundance of the gene's transcripts in the cell. This is achieved by dividing the raw count for the gene by the total UMI count for the cell.\n$$ \\text{Relative Abundance} = \\frac{c_{ig}}{C_i} = \\frac{c_{ig}}{\\sum_{g} c_{ig}} $$\n\nStep 2: Rescale the relative abundance to a common scale, typically \"counts per 10,000\" (CP10k) or \"transcripts per 10,000\" (TP10k), to facilitate comparison across cells with different library sizes. This is done by multiplying the relative abundance by a scale factor of $10^4$.\n$$ \\text{Rescaled Value} = \\left( \\frac{c_{ig}}{\\sum_{g} c_{ig}} \\right) \\times 10^4 $$\n\nStep 3: Apply a log-transformation to the rescaled value. This transformation helps to stabilize the variance across genes with different expression levels and reduces the skewness of the data distribution. A pseudocount of $1$ is added before taking the logarithm to ensure that the argument of the logarithm is always positive, thus avoiding issues with genes that have zero counts. The base of the logarithm is specified as $2$.\nThe log-normalized expression $\\tilde{x}_{ig}$ is therefore:\n$$ \\tilde{x}_{ig} = \\log_{2}\\left( \\left( \\frac{c_{ig}}{\\sum_{g} c_{ig}} \\right) \\times 10^4 + 1 \\right) $$\nThis is the required symbolic expression.\n\nNow, we will compute the value of $\\tilde{x}_{ig}$ for the given data:\n- Raw UMI count for the gene of interest: $c_{ig} = 50$\n- Total UMI count for the cell: $\\sum_{g} c_{ig} = 5000$\n\nSubstituting these values into the symbolic expression:\n$$ \\tilde{x}_{ig} = \\log_{2}\\left( \\left( \\frac{50}{5000} \\right) \\times 10^4 + 1 \\right) $$\n\nFirst, we calculate the fraction:\n$$ \\frac{50}{5000} = \\frac{5}{500} = \\frac{1}{100} = 0.01 $$\n\nNext, we perform the rescaling:\n$$ 0.01 \\times 10^4 = 0.01 \\times 10000 = 100 $$\n\nThen, we add the pseudocount of $1$:\n$$ 100 + 1 = 101 $$\n\nFinally, we take the logarithm with base $2$:\n$$ \\tilde{x}_{ig} = \\log_{2}(101) $$\n\nTo compute the numerical value, we can use the change of base formula for logarithms, $\\log_{b}(a) = \\frac{\\ln(a)}{\\ln(b)}$:\n$$ \\tilde{x}_{ig} = \\frac{\\ln(101)}{\\ln(2)} $$\n\nUsing standard values for natural logarithms:\n$$ \\ln(101) \\approx 4.6151205168 $$\n$$ \\ln(2) \\approx 0.6931471806 $$\n\n$$ \\tilde{x}_{ig} \\approx \\frac{4.6151205168}{0.6931471806} \\approx 6.6582115934 $$\n\nThe problem requires the answer to be rounded to four significant figures. The first four significant figures are $6$, $6$, $5$, and $8$. The fifth significant figure is $2$, which is less than $5$, so we round down (i.e., we do not change the last digit).\n\nTherefore, the log-normalized expression value is approximately $6.658$. This value is dimensionless, as the units of counts in the numerator and denominator of the initial fraction cancel out.",
            "answer": "$$\n\\boxed{6.658}\n$$"
        },
        {
            "introduction": "Moving beyond preprocessing, this practice delves into a predictive integration task using data conceptually similar to that from CITE-seq experiments. You will build a ridge regression model to predict protein abundance from gene expression, a powerful technique for imputing missing modalities and understanding regulatory relationships. This exercise provides hands-on experience with fitting a regularized linear model and evaluating its performance, a core skill in computational biology. ",
            "id": "4607720",
            "problem": "You are integrating single-cell multi-omics measurements, predicting a surface protein abundance from messenger ribonucleic acid (RNA) expression using a linear model. Consider data obtained from Cellular Indexing of Transcriptomes and Epitopes by Sequencing (CITE-seq), where RNA features are standardized and the protein target is scaled to comparable units. Assume the following joint linear model of protein on RNA holds: $y = X\\beta + \\varepsilon$, where $X \\in \\mathbb{R}^{n \\times p}$ is the feature matrix of RNA expressions across $n$ cells and $p$ genes, $y \\in \\mathbb{R}^{n}$ is the corresponding protein abundance, $\\beta \\in \\mathbb{R}^{p}$ are the coefficients, and $\\varepsilon$ is a mean-zero noise term. To prevent overfitting under collinearity and high-dimensionality, use ridge regression, which minimizes the penalized least-squares objective based on the squared Euclidean norm of $\\beta$.\n\nYou are given a training set with $n_{\\mathrm{train}} = 3$ cells and $p = 2$ RNA features,\n$$\nX_{\\mathrm{train}} = \\begin{bmatrix}\n1 & 2 \\\\\n0 & 1 \\\\\n2 & 0\n\\end{bmatrix}, \\quad\ny_{\\mathrm{train}} = \\begin{bmatrix}\n3 \\\\\n1 \\\\\n4\n\\end{bmatrix},\n$$\nand a test set with $n_{\\mathrm{test}} = 2$ cells,\n$$\nX_{\\mathrm{test}} = \\begin{bmatrix}\n1 & 1 \\\\\n3 & 0\n\\end{bmatrix}, \\quad\ny_{\\mathrm{test}} = \\begin{bmatrix}\n2.0 \\\\\n5.2\n\\end{bmatrix}.\n$$\nUse a ridge penalty parameter $\\lambda = 1$.\n\nTasks:\n1. Starting from the principle of minimizing the penalized least-squares objective with an $\\ell_{2}$ penalty, derive the estimator for $\\beta$ in terms of $X$, $y$, and $\\lambda$.\n2. Compute the ridge regression estimator $\\beta$ using $X_{\\mathrm{train}}$, $y_{\\mathrm{train}}$, and $\\lambda = 1$.\n3. Using the fitted $\\beta$, compute the test predictions $\\hat{y}_{\\mathrm{test}} = X_{\\mathrm{test}}\\beta$.\n4. Evaluate imputation accuracy on the test set using the root mean squared error (RMSE) defined as $\\mathrm{RMSE} = \\sqrt{\\frac{1}{n_{\\mathrm{test}}}\\sum_{i=1}^{n_{\\mathrm{test}}}(y_{i} - \\hat{y}_{i})^{2}}$.\n\nRound the final RMSE to four significant figures. Express the final answer as a pure number with no units.",
            "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It provides a standard task in statistical learning applied to bioinformatics with complete and consistent data. We will proceed with the four tasks outlined.\n\nTask 1: Derive the ridge regression estimator for $\\beta$.\nThe objective function for ridge regression, $L(\\beta)$, is the sum of the residual sum of squares (RSS) and an $\\ell_2$ penalty term on the coefficient vector $\\beta$. The RSS measures the squared difference between the observed values $y$ and the predicted values $X\\beta$. The penalty term, $\\lambda \\left\\|\\beta\\right\\|_2^2$, penalizes large coefficients to prevent overfitting.\n\nThe objective function is given by:\n$$\nL(\\beta) = (y - X\\beta)^T(y - X\\beta) + \\lambda \\beta^T\\beta\n$$\nHere, $y \\in \\mathbb{R}^{n}$, $X \\in \\mathbb{R}^{n \\times p}$, $\\beta \\in \\mathbb{R}^{p}$, and $\\lambda \\geq 0$ is the regularization parameter.\n\nTo find the estimator $\\hat{\\beta}$ that minimizes $L(\\beta)$, we first expand the expression:\n$$\nL(\\beta) = (y^T - \\beta^T X^T)(y - X\\beta) + \\lambda \\beta^T\\beta\n$$\n$$\nL(\\beta) = y^T y - y^T X\\beta - \\beta^T X^T y + \\beta^T X^T X \\beta + \\lambda \\beta^T\\beta\n$$\nSince $y^T X\\beta$ is a scalar ($1 \\times 1$ matrix), it is equal to its transpose, $(y^T X\\beta)^T = \\beta^T X^T y$. Thus, we can combine the two middle terms:\n$$\nL(\\beta) = y^T y - 2\\beta^T X^T y + \\beta^T X^T X \\beta + \\lambda \\beta^T\\beta\n$$\nTo find the minimum, we compute the gradient of $L(\\beta)$ with respect to $\\beta$ and set it to zero. Using matrix calculus rules ($\\frac{\\partial(\\mathbf{a}^T\\mathbf{x})}{\\partial\\mathbf{x}} = \\mathbf{a}$ and $\\frac{\\partial(\\mathbf{x}^T\\mathbf{A}\\mathbf{x})}{\\partial\\mathbf{x}} = 2\\mathbf{A}\\mathbf{x}$ for symmetric $\\mathbf{A}$), we get:\n$$\n\\frac{\\partial L(\\beta)}{\\partial \\beta} = -2X^T y + 2X^T X \\beta + 2\\lambda I \\beta\n$$\nwhere $I$ is the $p \\times p$ identity matrix. Setting the gradient to zero to find the critical point:\n$$\n-2X^T y + 2X^T X \\hat{\\beta} + 2\\lambda I \\hat{\\beta} = 0\n$$\nDividing by $2$:\n$$\n-X^T y + (X^T X) \\hat{\\beta} + (\\lambda I) \\hat{\\beta} = 0\n$$\nRearranging the terms to solve for $\\hat{\\beta}$:\n$$\n(X^T X + \\lambda I) \\hat{\\beta} = X^T y\n$$\nThe matrix $(X^T X + \\lambda I)$ is invertible for $\\lambda > 0$. Therefore, we can pre-multiply by its inverse to isolate $\\hat{\\beta}$:\n$$\n\\hat{\\beta} = (X^T X + \\lambda I)^{-1} X^T y\n$$\nThis is the ridge regression estimator for $\\beta$.\n\nTask 2: Compute the ridge regression estimator $\\beta$.\nWe are given the training data:\n$$\nX_{\\mathrm{train}} = \\begin{bmatrix}\n1 & 2 \\\\\n0 & 1 \\\\\n2 & 0\n\\end{bmatrix}, \\quad\ny_{\\mathrm{train}} = \\begin{bmatrix}\n3 \\\\\n1 \\\\\n4\n\\end{bmatrix}\n$$\nand the ridge penalty parameter $\\lambda = 1$. Let's denote $X = X_{\\mathrm{train}}$ and $y = y_{\\mathrm{train}}$ for this part.\nFirst, we compute $X^T X$:\n$$\nX^T X = \\begin{bmatrix}\n1 & 0 & 2 \\\\\n2 & 1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 2 \\\\\n0 & 1 \\\\\n2 & 0\n\\end{bmatrix}\n= \\begin{bmatrix}\n1^2 + 0^2 + 2^2 & 1 \\cdot 2 + 0 \\cdot 1 + 2 \\cdot 0 \\\\\n2 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 2 & 2^2 + 1^2 + 0^2\n\\end{bmatrix}\n= \\begin{bmatrix}\n5 & 2 \\\\\n2 & 5\n\\end{bmatrix}\n$$\nNext, we form the matrix $(X^T X + \\lambda I)$ with $\\lambda = 1$ and $I$ as the $2 \\times 2$ identity matrix:\n$$\nX^T X + \\lambda I = \\begin{bmatrix}\n5 & 2 \\\\\n2 & 5\n\\end{bmatrix} + 1 \\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix} = \\begin{bmatrix}\n6 & 2 \\\\\n2 & 6\n\\end{bmatrix}\n$$\nNow, we find the inverse of this matrix. The determinant is $\\det(X^T X + \\lambda I) = (6)(6) - (2)(2) = 36 - 4 = 32$.\nThe inverse is:\n$$\n(X^T X + \\lambda I)^{-1} = \\frac{1}{32} \\begin{bmatrix}\n6 & -2 \\\\\n-2 & 6\n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{6}{32} & \\frac{-2}{32} \\\\\n\\frac{-2}{32} & \\frac{6}{32}\n\\end{bmatrix} = \\begin{bmatrix}\n\\frac{3}{16} & -\\frac{1}{16} \\\\\n-\\frac{1}{16} & \\frac{3}{16}\n\\end{bmatrix}\n$$\nNext, we compute $X^T y$:\n$$\nX^T y = \\begin{bmatrix}\n1 & 0 & 2 \\\\\n2 & 1 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n3 \\\\\n1 \\\\\n4\n\\end{bmatrix}\n= \\begin{bmatrix}\n1 \\cdot 3 + 0 \\cdot 1 + 2 \\cdot 4 \\\\\n2 \\cdot 3 + 1 \\cdot 1 + 0 \\cdot 4\n\\end{bmatrix}\n= \\begin{bmatrix}\n11 \\\\\n7\n\\end{bmatrix}\n$$\nFinally, we compute $\\hat{\\beta}$:\n$$\n\\hat{\\beta} = (X^T X + \\lambda I)^{-1} X^T y = \\begin{bmatrix}\n\\frac{3}{16} & -\\frac{1}{16} \\\\\n-\\frac{1}{16} & \\frac{3}{16}\n\\end{bmatrix}\n\\begin{bmatrix}\n11 \\\\\n7\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{3 \\cdot 11 - 1 \\cdot 7}{16} \\\\\n\\frac{-1 \\cdot 11 + 3 \\cdot 7}{16}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{33 - 7}{16} \\\\\n\\frac{-11 + 21}{16}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{26}{16} \\\\\n\\frac{10}{16}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{13}{8} \\\\\n\\frac{5}{8}\n\\end{bmatrix}\n$$\nThe estimated coefficient vector is $\\hat{\\beta} = \\begin{bmatrix} 1.625 \\\\ 0.625 \\end{bmatrix}$.\n\nTask 3: Compute the test predictions $\\hat{y}_{\\mathrm{test}}$.\nUsing the fitted $\\hat{\\beta}$ and the test set features $X_{\\mathrm{test}}$, we compute the predicted protein abundances $\\hat{y}_{\\mathrm{test}} = X_{\\mathrm{test}}\\hat{\\beta}$.\n$$\nX_{\\mathrm{test}} = \\begin{bmatrix}\n1 & 1 \\\\\n3 & 0\n\\end{bmatrix}\n$$\n$$\n\\hat{y}_{\\mathrm{test}} = \\begin{bmatrix}\n1 & 1 \\\\\n3 & 0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\frac{13}{8} \\\\\n\\frac{5}{8}\n\\end{bmatrix}\n= \\begin{bmatrix}\n1 \\cdot \\frac{13}{8} + 1 \\cdot \\frac{5}{8} \\\\\n3 \\cdot \\frac{13}{8} + 0 \\cdot \\frac{5}{8}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{13+5}{8} \\\\\n\\frac{39}{8}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{18}{8} \\\\\n\\frac{39}{8}\n\\end{bmatrix}\n= \\begin{bmatrix}\n\\frac{9}{4} \\\\\n\\frac{39}{8}\n\\end{bmatrix}\n= \\begin{bmatrix}\n2.25 \\\\\n4.875\n\\end{bmatrix}\n$$\n\nTask 4: Evaluate imputation accuracy using RMSE.\nThe root mean squared error (RMSE) is defined as $\\mathrm{RMSE} = \\sqrt{\\frac{1}{n_{\\mathrm{test}}}\\sum_{i=1}^{n_{\\mathrm{test}}}(y_{i} - \\hat{y}_{i})^{2}}$.\nWe have $n_{\\mathrm{test}} = 2$, the observed test values $y_{\\mathrm{test}} = \\begin{bmatrix} 2.0 \\\\ 5.2 \\end{bmatrix}$, and the predicted values $\\hat{y}_{\\mathrm{test}} = \\begin{bmatrix} 2.25 \\\\ 4.875 \\end{bmatrix}$.\n\nFirst, we calculate the residuals $(y_i - \\hat{y}_i)$:\nFor cell $i=1$: $y_1 - \\hat{y}_1 = 2.0 - 2.25 = -0.25$.\nFor cell $i=2$: $y_2 - \\hat{y}_2 = 5.2 - 4.875 = 0.325$.\n\nNext, we square the residuals:\n$(y_1 - \\hat{y}_1)^2 = (-0.25)^2 = 0.0625$.\n$(y_2 - \\hat{y}_2)^2 = (0.325)^2 = 0.105625$.\n\nNow, we compute the mean of the squared errors (MSE):\n$$\n\\mathrm{MSE} = \\frac{1}{n_{\\mathrm{test}}}\\sum_{i=1}^{n_{\\mathrm{test}}}(y_{i} - \\hat{y}_{i})^{2} = \\frac{1}{2}(0.0625 + 0.105625) = \\frac{0.168125}{2} = 0.0840625\n$$\nFinally, we take the square root to find the RMSE:\n$$\n\\mathrm{RMSE} = \\sqrt{0.0840625} \\approx 0.28993533...\n$$\nThe problem requires rounding the final answer to four significant figures. The first four significant figures are $2$, $8$, $9$, and $9$. The fifth significant digit is $3$, which is less than $5$, so we do not round up.\n$$\n\\mathrm{RMSE} \\approx 0.2899\n$$",
            "answer": "$$\\boxed{0.2899}$$"
        },
        {
            "introduction": "This final practice tackles a cornerstone of multi-omics integration: creating a unified representation of cells from different data types. Using the Weighted Nearest Neighbor (WNN) method, you will fuse single-cell RNA-seq and ATAC-seq data by constructing a single, weighted graph that respects the information content of each modality. This approach allows for a more holistic analysis of cell states and identities than is possible from either modality alone. ",
            "id": "4607733",
            "problem": "Consider five single cells, labeled $C_{1}, C_{2}, C_{3}, C_{4}, C_{5}$. For each pair of cells, you are given their modality-specific dissimilarities measured as Euclidean distances after standard normalization in the Ribonucleic Acid (RNA) space and in the Assay for Transposase-Accessible Chromatin using sequencing (ATAC-seq) space. The goal is to construct a fused directed $k$-Nearest Neighbors (kNN) graph using the Weighted Nearest Neighbor (WNN) integration approach for $k=2$.\n\nFundamental base to use:\n- A $k$-Nearest Neighbors graph on a metric space assigns to each query point its $k$ smallest-distance neighbors under the specified query-to-candidate distance.\n- Weighted Nearest Neighbor integration defines, for each query cell, an integrated query-to-candidate dissimilarity as a convex combination of modality-specific dissimilarities, with modality weights reflecting the query cell’s modality-specific signal strength. The weights are determined from the provided per-cell signal-to-noise values by normalization so that they are nonnegative and sum to $1$ for each query cell.\n\nData:\n- Pairwise RNA distances $d_{\\mathrm{RNA}}(C_{i}, C_{j})$ for $i<j$:\n  - $d_{\\mathrm{RNA}}(C_{1}, C_{2}) = 1.2$, $d_{\\mathrm{RNA}}(C_{1}, C_{3}) = 3.5$, $d_{\\mathrm{RNA}}(C_{1}, C_{4}) = 2.0$, $d_{\\mathrm{RNA}}(C_{1}, C_{5}) = 3.0$.\n  - $d_{\\mathrm{RNA}}(C_{2}, C_{3}) = 2.8$, $d_{\\mathrm{RNA}}(C_{2}, C_{4}) = 1.5$, $d_{\\mathrm{RNA}}(C_{2}, C_{5}) = 2.7$.\n  - $d_{\\mathrm{RNA}}(C_{3}, C_{4}) = 3.2$, $d_{\\mathrm{RNA}}(C_{3}, C_{5}) = 1.1$.\n  - $d_{\\mathrm{RNA}}(C_{4}, C_{5}) = 2.9$.\n- Pairwise ATAC-seq distances $d_{\\mathrm{ATAC}}(C_{i}, C_{j})$ for $i<j$:\n  - $d_{\\mathrm{ATAC}}(C_{1}, C_{2}) = 2.6$, $d_{\\mathrm{ATAC}}(C_{1}, C_{3}) = 2.9$, $d_{\\mathrm{ATAC}}(C_{1}, C_{4}) = 3.4$, $d_{\\mathrm{ATAC}}(C_{1}, C_{5}) = 1.3$.\n  - $d_{\\mathrm{ATAC}}(C_{2}, C_{3}) = 1.0$, $d_{\\mathrm{ATAC}}(C_{2}, C_{4}) = 2.2$, $d_{\\mathrm{ATAC}}(C_{2}, C_{5}) = 2.5$.\n  - $d_{\\mathrm{ATAC}}(C_{3}, C_{4}) = 2.4$, $d_{\\mathrm{ATAC}}(C_{3}, C_{5}) = 2.0$.\n  - $d_{\\mathrm{ATAC}}(C_{4}, C_{5}) = 1.7$.\n- Modality-specific signal-to-noise values for each cell $C_{i}$:\n  - RNA signal strengths: $s_{\\mathrm{RNA}}(C_{1}) = 4$, $s_{\\mathrm{RNA}}(C_{2}) = 6$, $s_{\\mathrm{RNA}}(C_{3}) = 3$, $s_{\\mathrm{RNA}}(C_{4}) = 9$, $s_{\\mathrm{RNA}}(C_{5}) = 2$.\n  - ATAC-seq signal strengths: $s_{\\mathrm{ATAC}}(C_{1}) = 1$, $s_{\\mathrm{ATAC}}(C_{2}) = 7$, $s_{\\mathrm{ATAC}}(C_{3}) = 8$, $s_{\\mathrm{ATAC}}(C_{4}) = 3$, $s_{\\mathrm{ATAC}}(C_{5}) = 3$.\n\nTasks:\n1. Using the Weighted Nearest Neighbor principle described above, derive the per-cell modality weights and compute, for each query cell $C_{i}$, the integrated directed dissimilarity to each other cell $C_{j}$ as a convex combination of $d_{\\mathrm{RNA}}(C_{i}, C_{j})$ and $d_{\\mathrm{ATAC}}(C_{i}, C_{j})$ with the derived weights for $C_{i}$.\n2. For $k=2$, determine the fused directed $k$-Nearest Neighbors graph by selecting, for each $C_{i}$, the two cells $C_{j}$ with the smallest integrated directed dissimilarities. List each cell’s integrated neighbor set.\n3. Finally, compute the total number of mutual nearest neighbor pairs in the fused graph, where an unordered pair $\\{C_{i}, C_{j}\\}$ counts if $C_{j}$ is in $C_{i}$’s two-neighbor set and $C_{i}$ is in $C_{j}$’s two-neighbor set. Express the final answer as a single integer. No rounding is required.",
            "solution": "The solution follows the three tasks outlined in the problem statement. The provided modality-specific distances are Euclidean, hence symmetric: $d(C_{i}, C_{j}) = d(C_{j}, C_{i})$.\n\n**Task 1: Derive per-cell modality weights and compute integrated dissimilarities.**\n\nFirst, we calculate the modality weights for each cell $C_{i}$. For a given cell $C_i$, the weights for RNA and ATAC-seq modalities, denoted $w_{\\mathrm{RNA}}(C_{i})$ and $w_{\\mathrm{ATAC}}(C_{i})$, are determined by normalizing the respective signal strengths $s_{\\mathrm{RNA}}(C_{i})$ and $s_{\\mathrm{ATAC}}(C_{i})$ to sum to $1$.\nThe formula for the weights is:\n$$w_{\\mathrm{RNA}}(C_{i}) = \\frac{s_{\\mathrm{RNA}}(C_{i})}{s_{\\mathrm{RNA}}(C_{i}) + s_{\\mathrm{ATAC}}(C_{i})}, \\quad w_{\\mathrm{ATAC}}(C_{i}) = \\frac{s_{\\mathrm{ATAC}}(C_{i})}{s_{\\mathrm{RNA}}(C_{i}) + s_{\\mathrm{ATAC}}(C_{i})}$$\n\n- For $C_{1}$: $s_{\\mathrm{RNA}}(C_{1}) = 4, s_{\\mathrm{ATAC}}(C_{1}) = 1$.\n  $w_{\\mathrm{RNA}}(C_{1}) = \\frac{4}{4+1} = \\frac{4}{5}$, $w_{\\mathrm{ATAC}}(C_{1}) = \\frac{1}{4+1} = \\frac{1}{5}$.\n- For $C_{2}$: $s_{\\mathrm{RNA}}(C_{2}) = 6, s_{\\mathrm{ATAC}}(C_{2}) = 7$.\n  $w_{\\mathrm{RNA}}(C_{2}) = \\frac{6}{6+7} = \\frac{6}{13}$, $w_{\\mathrm{ATAC}}(C_{2}) = \\frac{7}{6+7} = \\frac{7}{13}$.\n- For $C_{3}$: $s_{\\mathrm{RNA}}(C_{3}) = 3, s_{\\mathrm{ATAC}}(C_{3}) = 8$.\n  $w_{\\mathrm{RNA}}(C_{3}) = \\frac{3}{3+8} = \\frac{3}{11}$, $w_{\\mathrm{ATAC}}(C_{3}) = \\frac{8}{3+8} = \\frac{8}{11}$.\n- For $C_{4}$: $s_{\\mathrm{RNA}}(C_{4}) = 9, s_{\\mathrm{ATAC}}(C_{4}) = 3$.\n  $w_{\\mathrm{RNA}}(C_{4}) = \\frac{9}{9+3} = \\frac{9}{12} = \\frac{3}{4}$, $w_{\\mathrm{ATAC}}(C_{4}) = \\frac{3}{9+3} = \\frac{3}{12} = \\frac{1}{4}$.\n- For $C_{5}$: $s_{\\mathrm{RNA}}(C_{5}) = 2, s_{\\mathrm{ATAC}}(C_{5}) = 3$.\n  $w_{\\mathrm{RNA}}(C_{5}) = \\frac{2}{2+3} = \\frac{2}{5}$, $w_{\\mathrm{ATAC}}(C_{5}) = \\frac{3}{2+3} = \\frac{3}{5}$.\n\nNext, we compute the integrated directed dissimilarity $d_{\\mathrm{WNN}}(C_{i}, C_{j})$ from each query cell $C_{i}$ to each candidate cell $C_{j}$ ($i \\neq j$) using the formula:\n$$d_{\\mathrm{WNN}}(C_{i}, C_{j}) = w_{\\mathrm{RNA}}(C_{i}) \\cdot d_{\\mathrm{RNA}}(C_{i}, C_{j}) + w_{\\mathrm{ATAC}}(C_{i}) \\cdot d_{\\mathrm{ATAC}}(C_{i}, C_{j})$$\nSince distances are symmetric, $d_{\\mathrm{RNA}}(C_{i}, C_{j}) = d_{\\mathrm{RNA}}(C_{j}, C_{i})$ and $d_{\\mathrm{ATAC}}(C_{i}, C_{j}) = d_{\\mathrm{ATAC}}(C_{j}, C_{i})$.\n\nCalculations for each query cell $C_{i}$:\n\n- **Query $C_{1}$** ($w_{\\mathrm{RNA}}=\\frac{4}{5}, w_{\\mathrm{ATAC}}=\\frac{1}{5}$):\n  - $d_{\\mathrm{WNN}}(C_{1}, C_{2}) = \\frac{4}{5}(1.2) + \\frac{1}{5}(2.6) = \\frac{4.8 + 2.6}{5} = \\frac{7.4}{5} = 1.48$\n  - $d_{\\mathrm{WNN}}(C_{1}, C_{3}) = \\frac{4}{5}(3.5) + \\frac{1}{5}(2.9) = \\frac{14.0 + 2.9}{5} = \\frac{16.9}{5} = 3.38$\n  - $d_{\\mathrm{WNN}}(C_{1}, C_{4}) = \\frac{4}{5}(2.0) + \\frac{1}{5}(3.4) = \\frac{8.0 + 3.4}{5} = \\frac{11.4}{5} = 2.28$\n  - $d_{\\mathrm{WNN}}(C_{1}, C_{5}) = \\frac{4}{5}(3.0) + \\frac{1}{5}(1.3) = \\frac{12.0 + 1.3}{5} = \\frac{13.3}{5} = 2.66$\n\n- **Query $C_{2}$** ($w_{\\mathrm{RNA}}=\\frac{6}{13}, w_{\\mathrm{ATAC}}=\\frac{7}{13}$):\n  - $d_{\\mathrm{WNN}}(C_{2}, C_{1}) = \\frac{6}{13}(1.2) + \\frac{7}{13}(2.6) = \\frac{7.2 + 18.2}{13} = \\frac{25.4}{13}$\n  - $d_{\\mathrm{WNN}}(C_{2}, C_{3}) = \\frac{6}{13}(2.8) + \\frac{7}{13}(1.0) = \\frac{16.8 + 7.0}{13} = \\frac{23.8}{13}$\n  - $d_{\\mathrm{WNN}}(C_{2}, C_{4}) = \\frac{6}{13}(1.5) + \\frac{7}{13}(2.2) = \\frac{9.0 + 15.4}{13} = \\frac{24.4}{13}$\n  - $d_{\\mathrm{WNN}}(C_{2}, C_{5}) = \\frac{6}{13}(2.7) + \\frac{7}{13}(2.5) = \\frac{16.2 + 17.5}{13} = \\frac{33.7}{13}$\n\n- **Query $C_{3}$** ($w_{\\mathrm{RNA}}=\\frac{3}{11}, w_{\\mathrm{ATAC}}=\\frac{8}{11}$):\n  - $d_{\\mathrm{WNN}}(C_{3}, C_{1}) = \\frac{3}{11}(3.5) + \\frac{8}{11}(2.9) = \\frac{10.5 + 23.2}{11} = \\frac{33.7}{11}$\n  - $d_{\\mathrm{WNN}}(C_{3}, C_{2}) = \\frac{3}{11}(2.8) + \\frac{8}{11}(1.0) = \\frac{8.4 + 8.0}{11} = \\frac{16.4}{11}$\n  - $d_{\\mathrm{WNN}}(C_{3}, C_{4}) = \\frac{3}{11}(3.2) + \\frac{8}{11}(2.4) = \\frac{9.6 + 19.2}{11} = \\frac{28.8}{11}$\n  - $d_{\\mathrm{WNN}}(C_{3}, C_{5}) = \\frac{3}{11}(1.1) + \\frac{8}{11}(2.0) = \\frac{3.3 + 16.0}{11} = \\frac{19.3}{11}$\n\n- **Query $C_{4}$** ($w_{\\mathrm{RNA}}=\\frac{3}{4}, w_{\\mathrm{ATAC}}=\\frac{1}{4}$):\n  - $d_{\\mathrm{WNN}}(C_{4}, C_{1}) = \\frac{3}{4}(2.0) + \\frac{1}{4}(3.4) = \\frac{6.0 + 3.4}{4} = \\frac{9.4}{4} = 2.35$\n  - $d_{\\mathrm{WNN}}(C_{4}, C_{2}) = \\frac{3}{4}(1.5) + \\frac{1}{4}(2.2) = \\frac{4.5 + 2.2}{4} = \\frac{6.7}{4} = 1.675$\n  - $d_{\\mathrm{WNN}}(C_{4}, C_{3}) = \\frac{3}{4}(3.2) + \\frac{1}{4}(2.4) = \\frac{9.6 + 2.4}{4} = \\frac{12.0}{4} = 3.0$\n  - $d_{\\mathrm{WNN}}(C_{4}, C_{5}) = \\frac{3}{4}(2.9) + \\frac{1}{4}(1.7) = \\frac{8.7 + 1.7}{4} = \\frac{10.4}{4} = 2.6$\n\n- **Query $C_{5}$** ($w_{\\mathrm{RNA}}=\\frac{2}{5}, w_{\\mathrm{ATAC}}=\\frac{3}{5}$):\n  - $d_{\\mathrm{WNN}}(C_{5}, C_{1}) = \\frac{2}{5}(3.0) + \\frac{3}{5}(1.3) = \\frac{6.0 + 3.9}{5} = \\frac{9.9}{5} = 1.98$\n  - $d_{\\mathrm{WNN}}(C_{5}, C_{2}) = \\frac{2}{5}(2.7) + \\frac{3}{5}(2.5) = \\frac{5.4 + 7.5}{5} = \\frac{12.9}{5} = 2.58$\n  - $d_{\\mathrm{WNN}}(C_{5}, C_{3}) = \\frac{2}{5}(1.1) + \\frac{3}{5}(2.0) = \\frac{2.2 + 6.0}{5} = \\frac{8.2}{5} = 1.64$\n  - $d_{\\mathrm{WNN}}(C_{5}, C_{4}) = \\frac{2}{5}(2.9) + \\frac{3}{5}(1.7) = \\frac{5.8 + 5.1}{5} = \\frac{10.9}{5} = 2.18$\n\n**Task 2: Determine the fused directed $k$-Nearest Neighbors graph for $k=2$.**\n\nFor each cell $C_{i}$, we identify the two cells $C_{j}$ with the smallest values of $d_{\\mathrm{WNN}}(C_{i}, C_{j})$.\n\n- **Neighbors of $C_{1}$**:\n  - Distances: $d(C_{1}, C_{2})=1.48$, $d(C_{1}, C_{4})=2.28$, $d(C_{1}, C_{5})=2.66$, $d(C_{1}, C_{3})=3.38$.\n  - The two nearest neighbors are $C_{2}$ and $C_{4}$. Neighbor set $N(C_{1}) = \\{C_{2}, C_{4}\\}$.\n\n- **Neighbors of $C_{2}$**:\n  - Distances: $d(C_{2}, C_{3})=\\frac{23.8}{13} \\approx 1.831$, $d(C_{2}, C_{4})=\\frac{24.4}{13} \\approx 1.877$, $d(C_{2}, C_{1})=\\frac{25.4}{13} \\approx 1.954$, $d(C_{2}, C_{5})=\\frac{33.7}{13} \\approx 2.592$.\n  - The two nearest neighbors are $C_{3}$ and $C_{4}$. Neighbor set $N(C_{2}) = \\{C_{3}, C_{4}\\}$.\n\n- **Neighbors of $C_{3}$**:\n  - Distances: $d(C_{3}, C_{2})=\\frac{16.4}{11} \\approx 1.491$, $d(C_{3}, C_{5})=\\frac{19.3}{11} \\approx 1.755$, $d(C_{3}, C_{4})=\\frac{28.8}{11} \\approx 2.618$, $d(C_{3}, C_{1})=\\frac{33.7}{11} \\approx 3.064$.\n  - The two nearest neighbors are $C_{2}$ and $C_{5}$. Neighbor set $N(C_{3}) = \\{C_{2}, C_{5}\\}$.\n\n- **Neighbors of $C_{4}$**:\n  - Distances: $d(C_{4}, C_{2})=1.675$, $d(C_{4}, C_{1})=2.35$, $d(C_{4}, C_{5})=2.6$, $d(C_{4}, C_{3})=3.0$.\n  - The two nearest neighbors are $C_{2}$ and $C_{1}$. Neighbor set $N(C_{4}) = \\{C_{1}, C_{2}\\}$.\n\n- **Neighbors of $C_{5}$**:\n  - Distances: $d(C_{5}, C_{3})=1.64$, $d(C_{5}, C_{1})=1.98$, $d(C_{5}, C_{4})=2.18$, $d(C_{5}, C_{2})=2.58$.\n  - The two nearest neighbors are $C_{3}$ and $C_{1}$. Neighbor set $N(C_{5}) = \\{C_{3}, C_{1}\\}$.\n\nSummary of the $2$-NN sets:\n- $N(C_{1}) = \\{C_{2}, C_{4}\\}$\n- $N(C_{2}) = \\{C_{3}, C_{4}\\}$\n- $N(C_{3}) = \\{C_{2}, C_{5}\\}$\n- $N(C_{4}) = \\{C_{1}, C_{2}\\}$\n- $N(C_{5}) = \\{C_{1}, C_{3}\\}$\n\n**Task 3: Compute the total number of mutual nearest neighbor pairs.**\n\nAn unordered pair $\\{C_{i}, C_{j}\\}$ is a mutual nearest neighbor pair if $C_{j}$ is in the $2$-NN set of $C_{i}$ (i.e., $C_{j} \\in N(C_i)$) and $C_{i}$ is in the $2$-NN set of $C_{j}$ (i.e., $C_{i} \\in N(C_j)$). We check all $\\binom{5}{2}=10$ unordered pairs.\n\n- $\\{C_{1}, C_{2}\\}$: $C_{2} \\in N(C_{1})$? Yes. $C_{1} \\in N(C_{2})$? No. Not mutual.\n- $\\{C_{1}, C_{3}\\}$: $C_{3} \\in N(C_{1})$? No. Not mutual.\n- $\\{C_{1}, C_{4}\\}$: $C_{4} \\in N(C_{1})$? Yes. $C_{1} \\in N(C_{4})$? Yes. **This is a mutual pair.**\n- $\\{C_{1}, C_{5}\\}$: $C_{5} \\in N(C_{1})$? No. (Even though $C_{1} \\in N(C_{5})$, it's not mutual).\n- $\\{C_{2}, C_{3}\\}$: $C_{3} \\in N(C_{2})$? Yes. $C_{2} \\in N(C_{3})$? Yes. **This is a mutual pair.**\n- $\\{C_{2}, C_{4}\\}$: $C_{4} \\in N(C_{2})$? Yes. $C_{2} \\in N(C_{4})$? Yes. **This is a mutual pair.**\n- $\\{C_{2}, C_{5}\\}$: $C_{5} \\in N(C_{2})$? No. Not mutual.\n- $\\{C_{3}, C_{4}\\}$: $C_{4} \\in N(C_{3})$? No. Not mutual.\n- $\\{C_{3}, C_{5}\\}$: $C_{5} \\in N(C_{3})$? Yes. $C_{3} \\in N(C_{5})$? Yes. **This is a mutual pair.**\n- $\\{C_{4}, C_{5}\\}$: $C_{5} \\in N(C_{4})$? No. Not mutual.\n\nThe mutual nearest neighbor pairs are $\\{C_{1}, C_{4}\\}$, $\\{C_{2}, C_{3}\\}$, $\\{C_{2}, C_{4}\\}$, and $\\{C_{3}, C_{5}\\}$.\nThe total number of mutual nearest neighbor pairs is $4$.",
            "answer": "$$\\boxed{4}$$"
        }
    ]
}