{
    "hands_on_practices": [
        {
            "introduction": "The first step in integrating data from multiple genomic studies, such as a Genome-Wide Association Study (GWAS) and an expression Quantitative Trait Loci (eQTL) analysis, is ensuring the data \"speak the same language.\" This conceptual exercise  addresses the critical task of allele harmonization, exploring how inconsistencies in which allele is designated as the \"effect\" allele or how the DNA strand is reported can create misleading or entirely false results. Mastering the principles of harmonization is essential for any researcher working with genomic summary statistics, as it prevents fundamental errors that can invalidate downstream analyses like colocalization and fine-mapping.",
            "id": "4341877",
            "problem": "A research team is integrating summary statistics from a Genome-Wide Association Study (GWAS) and an expression quantitative trait loci (eQTL) analysis to identify causal variants at a locus implicated in an autoimmune phenotype. The goal is to perform cross-trait colocalization and single-trait fine-mapping. The team suspects that strand flips and allele coding differences may distort the inference.\n\nConsider a biallelic single nucleotide polymorphism with alleles described relative to the reference genome, where one dataset counts the reference allele and the other counts the alternate allele. Under an additive model, define the genotype count variable as the number of copies of the chosen effect allele, denoted by $G \\in \\{0, 1, 2\\}$. The trait outcome $Y$ is modeled by a linear (or generalized linear) regression\n$$\nY = \\alpha + \\beta G + \\varepsilon,\n$$\nwhere $\\beta$ is the per-allele effect and $\\varepsilon$ is a mean-zero error term. Summary statistics provide the per-allele effect size $\\hat{\\beta}$ and its standard error $\\mathrm{SE}$, and the $Z$-score $Z = \\hat{\\beta} / \\mathrm{SE}$. Strand orientation refers to whether alleles are reported on the forward reference genome strand or its reverse complement. Palindromic single nucleotide polymorphisms are those with allele pairs that are reverse complements of each other, specifically $\\{A, T\\}$ and $\\{C, G\\}$.\n\nSuppose dataset $D_1$ (GWAS) reports the variant with effect allele $A$, other allele $G$, minor allele frequency $p_1 = 0.45$, per-allele log-odds effect $\\hat{\\beta}_1 = 0.12$ and $\\mathrm{SE}_1 = 0.03$. Dataset $D_2$ (eQTL) reports the same variant with effect allele $G$, other allele $A$, minor allele frequency $p_2 = 0.46$, per-allele expression effect $\\hat{\\beta}_2 = 0.20$ and $\\mathrm{SE}_2 = 0.05$.\n\nStarting from the core definition of genotype coding and the additive model, reason about how flipping the counted allele or reporting alleles on opposite strands affects the sign of $\\hat{\\beta}$ and the directionality of $Z$. Then, using the well-tested fact that single-trait fine-mapping often summarizes evidence through functions of $Z^2$ at each variant, and that cross-trait colocalization relies on the expected pattern of $Z$ across variants induced by linkage disequilibrium (LD) tagging, analyze the consequences of inconsistent allele coding for colocalization versus single-trait fine-mapping.\n\nFinally, select the checklist items that, if implemented, will ensure harmonized effect alleles across datasets and protect colocalization and fine-mapping from artifacts due to strand flips and allele coding inconsistencies.\n\nWhich options should be included in the validation checklist?\n\nA. Enforce a consistent reference genome strand orientation across all datasets, harmonize to a common chosen effect allele per variant, flipping the sign of $\\hat{\\beta}$ where necessary, and exclude palindromic variants with minor allele frequency near $0.5$ unless resolvable by high-confidence allele frequency concordance.\n\nB. Compare only the magnitude $\\lvert Z \\rvert$ across datasets because both colocalization and fine-mapping depend solely on $\\lvert Z \\rvert$ and are invariant to allele coding, so harmonization is unnecessary.\n\nC. Check allele frequency concordance and perform LD-based sign diagnostics: after harmonization, verify that the cross-trait $Z$ patterns agree with the LD sign structure from a matched-ancestry reference panel, using the expectation that $Z_t(j) \\approx r_{j j^\\ast} \\beta_t(j^\\ast) / \\mathrm{SE}_t(j)$ for trait $t$ and variants $j$ tagging the causal variant $j^\\ast$.\n\nD. Accept mixed-strand reporting because complementary bases do not alter $\\beta$ if the allele letters are the same; flipping between $\\{A, G\\}$ and $\\{T, C\\}$ strands has no impact on direction of effect.\n\nE. Verify and standardize the genotype coding scheme to additive $0/1/2$ counts of the same allele across datasets, and filter out variants with poor imputation metrics that can confound allele assignment; document all allele flips applied.\n\nSelect all that apply.",
            "solution": "The problem statement is critically evaluated for its validity before proceeding to a solution.\n\n### Step 1: Extract Givens\n\nThe problem provides the following information:\n-   **Model**: An additive genetic model where genotype $G \\in \\{0, 1, 2\\}$ represents the count of the effect allele.\n-   **Regression**: A linear (or generalized linear) model for a trait $Y$: $Y = \\alpha + \\beta G + \\varepsilon$, where $\\beta$ is the per-allele effect and $\\varepsilon$ is a mean-zero error term.\n-   **Summary Statistics**: Per-allele effect size $\\hat{\\beta}$, its standard error $\\mathrm{SE}$, and the $Z$-score $Z = \\hat{\\beta} / \\mathrm{SE}$.\n-   **Terminology**:\n    -   Strand orientation: Alleles reported on the forward reference strand or its reverse complement.\n    -   Palindromic SNPs: Allele pairs are reverse complements, specifically $\\{A, T\\}$ and $\\{C, G\\}$.\n-   **Dataset $D_1$ (GWAS)**:\n    -   Variant: Alleles $A$ (effect) and $G$ (other).\n    -   Minor allele frequency: $p_1 = 0.45$.\n    -   Per-allele log-odds effect: $\\hat{\\beta}_1 = 0.12$.\n    -   Standard error: $\\mathrm{SE}_1 = 0.03$.\n-   **Dataset $D_2$ (eQTL)**:\n    -   Variant: Same variant, but alleles are $G$ (effect) and $A$ (other).\n    -   Minor allele frequency: $p_2 = 0.46$.\n    -   Per-allele expression effect: $\\hat{\\beta}_2 = 0.20$.\n    -   Standard error: $\\mathrm{SE}_2 = 0.05$.\n-   **Analysis Context**:\n    -   Single-trait fine-mapping often summarizes evidence through functions of $Z^2$.\n    -   Cross-trait colocalization relies on the expected pattern of $Z$ across variants induced by linkage disequilibrium (LD).\n\n### Step 2: Validate Using Extracted Givens\n\nThe problem is evaluated against the validation criteria:\n-   **Scientifically Grounded**: The problem is well-grounded in the field of statistical genetics and bioinformatics. The concepts of GWAS, eQTL, additive models, summary statistics ($Z$-scores), allele harmonization, strand issues, palindromic SNPs, colocalization, and fine-mapping are all standard and accurately described. The provided data values for $\\hat{\\beta}$, $\\mathrm{SE}$, and allele frequencies are realistic. The hints about fine-mapping using $Z^2$ and colocalization using $Z$-score patterns accurately reflect the principles behind methods like FINEMAP/SuSiE and COLOC, respectively.\n-   **Well-Posed**: The problem is well-posed. It presents a common, concrete challenge in genomics (integrating two datasets with potentially conflicting allele coding) and asks for the correct procedures from a given list to resolve this challenge. The question is specific and answerable.\n-   **Objective**: The problem is stated in precise, objective, and technical language, free from ambiguity or subjective claims.\n\nThe problem does not exhibit any invalidating flaws:\n1.  **Scientific or Factual Unsoundness**: No violations are present. The logic and terminology are correct.\n2.  **Non-Formalizable or Irrelevant**: The problem is directly relevant to the topic of causal variant identification from GWAS hits, a core task in precision medicine.\n3.  **Incomplete or Contradictory Setup**: The setup is complete and internally consistent. The two datasets describe the same variant with very similar minor allele frequencies ($p_1 = 0.45$ and $p_2 = 0.46$), which is expected. The core of the problem lies in the fact that the chosen \"effect allele\" is different between the two studies, which is precisely the situation that requires harmonization.\n4.  **Unrealistic or Infeasible**: The scenario is highly realistic. Data integration from different consortia is a routine task fraught with exactly these types of harmonization challenges.\n5.  **Ill-Posed or Poorly Structured**: The structure is logical, moving from a specific example to the general principles required to solve the class of problems it represents.\n6.  **Pseudo-Profound, Trivial, or Tautological**: The problem is non-trivial. Failing to address allele harmonization correctly can invalidate the entire analysis, leading to false negative or false positive colocalization results. The distinction between the needs of fine-mapping and colocalization is a subtle but critical point.\n7.  **Outside Scientific Verifiability**: All concepts and proposed solutions are testable and standard practice in the field.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A full solution will be derived.\n\n### Derivation of Principles\n\nBefore evaluating the options, we must first establish the principles of allele and strand harmonization.\n\n1.  **Effect of Flipping the Coded Allele**: Let a variant have two alleles, which we will call $R$ (reference) and $A$ (alternate). Let the genotype variable $G_A$ be the count of the $A$ allele in an individual, so $G_A \\in \\{0, 1, 2\\}$. The corresponding genotype variable for the $R$ allele, $G_R$, must satisfy $G_A + G_R = 2$, since each individual has two copies of the chromosome at that locus. Thus, $G_R = 2 - G_A$.\n\n    Let the model for a trait $Y$ using $G_A$ be $Y = \\alpha_A + \\beta_A G_A + \\varepsilon$.\n    If we instead use $G_R$ as the predictor, the model becomes:\n    $$Y = \\alpha_A + \\beta_A (2 - G_R) + \\varepsilon = (\\alpha_A + 2\\beta_A) - \\beta_A G_R + \\varepsilon$$\n    This is a new linear model, $Y = \\alpha_R + \\beta_R G_R + \\varepsilon$, where the intercept is $\\alpha_R = \\alpha_A + 2\\beta_A$ and, critically, the effect size is $\\beta_R = -\\beta_A$.\n\n    Therefore, switching the effect allele from $A$ to $R$ negates the per-allele effect size $\\beta$. Since the standard error $\\mathrm{SE}$ is an estimate of the standard deviation of $\\hat{\\beta}$ and is always positive, the $Z$-score also flips its sign: $Z_R = \\hat{\\beta}_R / \\mathrm{SE} = -\\hat{\\beta}_A / \\mathrm{SE} = -Z_A$.\n\n    In the given problem, $D_1$ uses allele $A$ as the effect allele, while $D_2$ uses allele $G$. To harmonize $D_2$ to match $D_1$, one must flip the sign of its effect size: $\\hat{\\beta}_{2, \\text{harmonized to A}} = -\\hat{\\beta}_2 = -0.20$.\n\n2.  **Effect of Strand**: An SNP such as $A/G$ on the forward ('+') strand corresponds to a $T/C$ SNP on the reverse complement ('-') strand. If one dataset reports $A/G$ (effect allele $A$) and another reports $T/C$ (effect allele $T$), the effects are concordant because $T$ is the complement of $A$. `β` should have the same sign. However, if the second dataset reports $T/C$ but uses $C$ as the effect allele, this corresponds to the $G$ allele on the forward strand, which was the *other* allele in the first dataset. This is equivalent to the allele flip scenario described above, and the sign of $\\beta$ must be inverted for harmonization. This demonstrates that simply knowing the allele letters (e.g., $A$, $G$) is insufficient; one must know the strand and which allele is coded.\n\n3.  **Ambiguity of Palindromic SNPs**: For a palindromic SNP, e.g., $A/T$, the reverse complement is $T/A$. If Study $1$ reports $A/T$ with effect allele $A$ and Study $2$ reports $A/T$ with effect allele $T$, it is impossible to know from the letters alone whether this is an allele flip ($T$ is the other allele on the same strand) or a strand flip ($T$ is the complement of $A$ on the opposite strand). However, if the minor allele frequency (MAF) is, for example, $0.1$ and we know that $A$ is the minor allele, we can use this information. If Study $2$ reports that allele $T$ has a frequency of $\\approx 0.9$, we infer that $T$ is the major allele and thus corresponds to the 'other' allele from Study $1$. This implies an allele flip is needed. If the MAF is close to $0.5$ (e.g., $p=0.48$), the frequencies of the two alleles ($0.48$ and $0.52$) are too similar to reliably distinguish them, making harmonization ambiguous. This is why such variants are often excluded.\n\n4.  **Impact on Downstream Analyses**:\n    -   **Single-trait fine-mapping**: As stated in the problem, many statistical methods for fine-mapping (e.g., those based on Wakefield's approximate Bayes factors) use summary statistics that depend on $Z^2$. For example, the approximate Bayes factor is proportional to $\\exp(Z^2/2)$. Since $(-Z)^2 = Z^2$, these methods are insensitive to the sign of $Z$. Thus, random, uncorrected allele flips within a single study might not alter the posterior probabilities of causality for the variants, although interpreting the direction of the effect becomes impossible.\n    -   **Cross-trait colocalization**: Colocalization methods test the hypothesis that two traits share a single causal variant. They do so by comparing the full vector of association statistics (e.g., $\\hat{\\beta}$ or $Z$) across all variants in a locus for both traits. Under the shared causal variant hypothesis, the effect sizes for trait $1$ ($\\vec{\\beta}_1$) and trait $2$ ($\\vec{\\beta}_2$) are expected to be proportional, i.e., $\\vec{\\beta}_1 \\propto \\vec{\\beta}_2$. Any inconsistency in allele coding for a subset of variants will flip the sign of their corresponding $\\beta_j$ values in one vector but not the other, destroying the proportionality and leading to a false rejection of colocalization. Therefore, precise allele harmonization is absolutely critical for colocalization.\n\n### Option-by-Option Analysis\n\n**A. Enforce a consistent reference genome strand orientation across all datasets, harmonize to a common chosen effect allele per variant, flipping the sign of $\\hat{\\beta}$ where necessary, and exclude palindromic variants with minor allele frequency near $0.5$ unless resolvable by high-confidence allele frequency concordance.**\nThis option presents a complete and correct workflow for allele harmonization.\n-   `Enforce a consistent reference genome strand orientation`: This is the standard first step to remove strand ambiguity.\n-   `harmonize to a common chosen effect allele ..., flipping the sign of \\hat{\\beta} where necessary`: This correctly applies the principle derived above. If the reported effect allele in a study is not the chosen common effect allele, its $\\hat{\\beta}$ (and $Z$) must be sign-flipped.\n-   `exclude palindromic variants with minor allele frequency near 0.5`: This correctly identifies the ambiguous case where harmonization is unreliable and advocates for the standard, conservative solution of exclusion.\n-   `unless resolvable by high-confidence allele frequency concordance`: This correctly notes the exception: when allele frequencies are sufficiently different from $0.5$, they can be used to resolve the ambiguity.\n**Verdict: Correct.**\n\n**B. Compare only the magnitude $\\lvert Z \\rvert$ across datasets because both colocalization and fine-mapping depend solely on $\\lvert Z \\rvert$ and are invariant to allele coding, so harmonization is unnecessary.**\nThis statement contains a critical flaw.\n-   `colocalization ... depend[s] solely on |Z|`: This is false. As derived above, colocalization fundamentally depends on comparing the vector of signed association statistics across a locus between two traits. The relative signs of the $Z$-scores, which are determined by LD structure and the direction of the causal effect, are essential information. Discarding the signs by using $|Z|$ would make the analysis meaningless.\n-   `fine-mapping depend solely on |Z|`: While partially true for some posterior probability calculations, it is an oversimplification. Full interpretation requires knowing the effect direction. More importantly, the premise that this makes harmonization unnecessary is wrong, as harmonization is required for many other applications, including colocalization.\n**Verdict: Incorrect.**\n\n**C. Check allele frequency concordance and perform LD-based sign diagnostics: after harmonization, verify that the cross-trait $Z$ patterns agree with the LD sign structure from a matched-ancestry reference panel, using the expectation that $Z_t(j) \\approx r_{j j^\\ast} \\beta_t(j^\\ast) / \\mathrm{SE}_t(j)$ for trait $t$ and variants $j$ tagging the causal variant $j^\\ast$.**\nThis option describes an essential quality control (QC) procedure to validate the results of a harmonization workflow like the one in option A.\n-   `Check allele frequency concordance`: This is a primary tool for harmonization, as discussed for palindromic SNPs.\n-   `LD-based sign diagnostics`: This is a powerful secondary check. Within a locus containing a single causal variant $j^\\ast$, the $Z$-score of a tagging SNP $j$ is approximately $Z_j \\approx r_{jj^\\ast} Z_{j^\\ast}$, where $r_{jj^\\ast}$ is the LD correlation. This implies that the signs of the $Z$-scores across the locus should be correlated with the LD structure. Verifying that the sign of $Z_j$ relative to $Z_k$ matches the sign of the LD $r_{jk}$ within each study after harmonization is a powerful check against residual allele or strand errors. The expression given is a valid (though slightly rephrased) representation of this principle. A robust checklist for harmonization should include such verification steps.\n**Verdict: Correct.**\n\n**D. Accept mixed-strand reporting because complementary bases do not alter $\\beta$ if the allele letters are the same; flipping between $\\{A, G\\}$ and $\\{T, C\\}$ strands has no impact on direction of effect.**\nThis statement is based on a misunderstanding of sequence complementarity.\n-   `flipping between {A, G} and {T, C} strands has no impact on direction of effect`: This is false. As analyzed in the principles section, changing from an $A/G$ SNP on the '+' strand to a $T/C$ SNP on the '-' strand requires careful mapping. If the effect allele for $A/G$ was $A$, and for $T/C$ it becomes $C$, the effect size sign must be flipped, because $C$ on the '-' strand corresponds to $G$ on the '+' strand, which was the non-effect allele. The statement is misleading and promotes a dangerous practice. Mixed-strand reporting must be resolved, not accepted.\n**Verdict: Incorrect.**\n\n**E. Verify and standardize the genotype coding scheme to additive $0/1/2$ counts of the same allele across datasets, and filter out variants with poor imputation metrics that can confound allele assignment; document all allele flips applied.**\nThis option lists fundamental best practices for data preparation and integrity.\n-   `Verify and standardize the genotype coding`: This is the core goal of harmonization, ensuring that the genotype variable $G$ refers to the same biological entity in all datasets.\n-   `filter out variants with poor imputation metrics`: This is a critical data quality control step. SNPs with low imputation quality scores (e.g., INFO $< 0.8$) have less certain genotype calls and allele frequency estimates. These errors can directly lead to incorrect allele harmonization, for instance, by providing a noisy frequency estimate that is used to resolve a palindromic SNP. Filtering is essential for a robust analysis.\n-   `document all allele flips applied`: This pertains to scientific reproducibility and provenance. Any data transformation must be meticulously recorded. This is a hallmark of rigorous scientific analysis.\n**Verdict: Correct.**\n\nThe set of correct options comprises the necessary steps for preparing, harmonizing, validating, and documenting the data for a rigorous colocalization and fine-mapping analysis. Options A, C, and E together form a comprehensive and robust checklist.",
            "answer": "$$\\boxed{ACE}$$"
        },
        {
            "introduction": "After identifying a GWAS locus containing multiple statistically significant variants, the key question becomes: are there several independent causal signals, or is one true causal variant simply \"tagging\" its neighbors through Linkage Disequilibrium (LD)? This practice problem  introduces conditional analysis, a fundamental statistical technique used to address this challenge. By mathematically adjusting a variant's association signal for the signal of a lead variant, we can test whether the secondary variant retains an independent effect, helping to distinguish true secondary signals from echoes of the primary one.",
            "id": "4341984",
            "problem": "In a fine-mapping analysis within precision medicine and genomic diagnostics, you are given marginal association statistics from a Genome-Wide Association Study (GWAS) for a locus with four Single-Nucleotide Polymorphisms (SNPs). Assume genotypes are standardized and that, under large-sample theory for linear association testing, the vector of marginal $z$-scores across SNPs is approximately multivariate normal with correlation equal to the Linkage Disequilibrium (LD) matrix.\n\nThe marginal $z$-scores are\n$$\n\\boldsymbol{z} = \\begin{pmatrix} 6.10 \\\\ 4.30 \\\\ 2.10 \\\\ -1.20 \\end{pmatrix},\n$$\nand the LD correlation matrix is\n$$\nR = \\begin{pmatrix}\n1 & 0.20 & 0.05 & -0.02 \\\\\n0.20 & 1 & 0.10 & -0.01 \\\\\n0.05 & 0.10 & 1 & 0 \\\\\n-0.02 & -0.01 & 0 & 1\n\\end{pmatrix}.\n$$\n\nIdentify the lead SNP as the one with the largest absolute marginal $z$-score and consider SNP $2$ as a candidate secondary signal. Using only first principles about conditioning in a multivariate normal distribution and the assumption that the covariance of $\\boldsymbol{z}$ equals $R$, derive the appropriate conditional test statistic for SNP $2$ after conditioning on the lead SNP. Then determine whether the candidate secondary signal remains significant at a two-sided Bonferroni-corrected family-wise error rate of $\\alpha = 0.05$ across $M = 20$ tests.\n\nReport only the conditional $z$-score for SNP $2$ as your final answer. Round your final answer to four significant figures. No units are required.",
            "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. The underlying model, which treats GWAS $z$-scores as draws from a multivariate normal distribution with a covariance structure equal to the Linkage Disequilibrium (LD) matrix, is a standard and widely accepted framework in statistical genetics for fine-mapping and conditional analysis. The provided data are consistent and realistic. Therefore, the problem is valid, and I will proceed with a full solution.\n\nThe goal is to compute the conditional test statistic for SNP $2$ after accounting for the effect of the lead SNP. This procedure, known as conditional analysis, helps to distinguish between a single association signal that affects multiple correlated SNPs through LD, and multiple distinct association signals at a locus.\n\nFirst, we identify the lead SNP, defined as the one with the largest absolute marginal $z$-score. The given vector of $z$-scores is:\n$$\n\\boldsymbol{z} = \\begin{pmatrix} z_1 \\\\ z_2 \\\\ z_3 \\\\ z_4 \\end{pmatrix} = \\begin{pmatrix} 6.10 \\\\ 4.30 \\\\ 2.10 \\\\ -1.20 \\end{pmatrix}\n$$\nThe absolute values are $|z_1| = 6.10$, $|z_2| = 4.30$, $|z_3| = 2.10$, and $|z_4| = |-1.20| = 1.20$. The maximum of these is $6.10$, which corresponds to SNP $1$. Thus, SNP $1$ is the lead SNP.\n\nNext, we derive the conditional test statistic for the candidate secondary signal, SNP $2$, given the observed statistic for the lead SNP, SNP $1$. Let the random variables for the $z$-scores of SNP $1$ and SNP $2$ be $Z_1$ and $Z_2$, respectively. Based on the problem statement, their joint distribution is bivariate normal, with a mean vector that reflects their true genetic effects and a covariance matrix extracted from the provided LD matrix $R$:\n$$\n\\begin{pmatrix} Z_1 \\\\ Z_2 \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\lambda_1 \\\\ \\lambda_2 \\end{pmatrix}, \\begin{pmatrix} R_{11} & R_{12} \\\\ R_{21} & R_{22} \\end{pmatrix} \\right)\n$$\nwhere $\\lambda_1$ and $\\lambda_2$ are the non-centrality parameters representing the true effects, and the covariance submatrix is:\n$$\n\\begin{pmatrix} R_{11} & R_{12} \\\\ R_{21} & R_{22} \\end{pmatrix} = \\begin{pmatrix} 1 & 0.20 \\\\ 0.20 & 1 \\end{pmatrix}\n$$\nThe conditional test statistic for SNP $2$, which we denote $z_{2|1}$, is a standardized measure of the association at SNP $2$ that is not explained by its LD with SNP $1$. This is derived from the properties of the conditional normal distribution. The conditional statistic is the observed value of $Z_2$ minus its expected value given $Z_1$, all divided by the conditional standard deviation.\nThe expected value of $Z_2$ given $Z_1 = z_1$ is $E[Z_2 | Z_1=z_1] = \\lambda_2 + R_{21} R_{11}^{-1} (z_1 - \\lambda_1)$. The conditional variance is $\\text{Var}(Z_2 | Z_1=z_1) = R_{22} - R_{21} R_{11}^{-1} R_{12}$.\n\nTo form a test statistic for the null hypothesis that SNP $2$ has no independent effect (i.e., $H_0: \\lambda_2 = 0$), we proceed by approximating the unknown true effect of the lead SNP, $\\lambda_1$, with its observed statistic, $z_1$. This is a standard approximation in methods such as GCTA-COJO. The expected value of $Z_2$ under this approximation, due to LD with SNP $1$, is $R_{21}R_{11}^{-1}z_1$. The conditional statistic is constructed by standardizing the difference between the observed $z_2$ and this expectation:\n$$\nz_{2|1} = \\frac{z_2 - E[Z_2 | Z_1=z_1, \\lambda_1=z_1, \\lambda_2=0]}{\\sqrt{\\text{Var}(Z_2 | Z_1=z_1)}} = \\frac{z_2 - R_{21} R_{11}^{-1} z_1}{\\sqrt{R_{22} - R_{21} R_{11}^{-1} R_{12}}}\n$$\nSince $R$ is a correlation matrix, the diagonal elements $R_{11}$ and $R_{22}$ are equal to $1$. Substituting these values simplifies the formula:\n$$\nz_{2|1} = \\frac{z_2 - R_{21} z_1}{\\sqrt{1 - R_{21}^2}}\n$$\nThis formula effectively computes a standardized residual of the regression of $z_2$ on $z_1$, which represents the portion of the $z_2$ signal that is statistically independent of the $z_1$ signal.\n\nWe now substitute the given numerical values: $z_1 = 6.10$, $z_2 = 4.30$, and $R_{21} = 0.20$.\n$$\nz_{2|1} = \\frac{4.30 - (0.20)(6.10)}{\\sqrt{1 - (0.20)^2}}\n$$\nFirst, calculate the numerator:\n$$\n4.30 - (0.20)(6.10) = 4.30 - 1.22 = 3.08\n$$\nNext, calculate the denominator:\n$$\n\\sqrt{1 - (0.20)^2} = \\sqrt{1 - 0.04} = \\sqrt{0.96}\n$$\nThe conditional $z$-score is therefore:\n$$\nz_{2|1} = \\frac{3.08}{\\sqrt{0.96}} \\approx \\frac{3.08}{0.9797959} \\approx 3.14351\n$$\nRounding to four significant figures, we get $z_{2|1} = 3.144$.\n\nFinally, the problem asks to determine if this secondary signal is significant at a Bonferroni-corrected threshold. The family-wise error rate is $\\alpha = 0.05$ for $M = 20$ tests. The corrected significance level for a single test's $p$-value is $p_{\\text{thresh}} = \\frac{\\alpha}{M} = \\frac{0.05}{20} = 0.0025$.\nThe two-sided $p$-value for our conditional statistic $z_{2|1} \\approx 3.144$ is $p = 2 \\times P(Z > |3.144|)$, where $Z \\sim \\mathcal{N}(0,1)$. This $p$-value is approximately $0.00167$. Since $0.00167 < 0.0025$, the conditional signal for SNP $2$ is indeed statistically significant after accounting for the lead SNP $1$ and correcting for multiple testing. The final answer required is the value of the conditional $z$-score itself.",
            "answer": "$$\n\\boxed{3.144}\n$$"
        },
        {
            "introduction": "Sophisticated fine-mapping and conditional analyses depend critically on an accurate Linkage Disequilibrium (LD) matrix. But where does this matrix come from, and how do we account for the inherent statistical uncertainty in its estimation? This hands-on coding exercise  guides you through the process of calculating an LD matrix from raw genotype data and applying a technique known as shrinkage regularization. Regularization helps to mitigate estimation errors that arise from using a finite reference panel, leading to more stable and reliable fine-mapping results.",
            "id": "4341798",
            "problem": "You are given genotype dosage matrices for a small set of individuals in a reference panel and corresponding external allele frequencies for a subset of single-nucleotide polymorphisms (SNPs). Your task is to implement a program that computes the pairwise Linkage Disequilibrium (LD) correlation matrix $R$ for each test case, evaluates the impact of using external versus sample allele frequencies on $R$, and applies a shrinkage-based regularization to $R$ to mitigate sampling variance. Your program must output summary metrics per test case as specified below.\n\nFoundational base and definitions:\n- A Single-Nucleotide Polymorphism (SNP) is coded in a genotype matrix $G \\in \\mathbb{R}^{n \\times m}$ with entries in $\\{0,1,2\\}$ representing the alternate allele dosages for $n$ individuals and $m$ SNPs.\n- Under Hardy–Weinberg Equilibrium (HWE), for a SNP with alternate allele frequency $p \\in (0,1)$, the genotype dosage has expected mean $2p$ and variance $2p(1-p)$.\n- Let $p_j$ denote the allele frequency for SNP $j$, either provided externally or estimated from the sample as $\\hat{p}_j = \\frac{1}{2n}\\sum_{i=1}^{n} G_{ij}$. Define the standardized genotype matrix $X \\in \\mathbb{R}^{n \\times m}$ by\n$$\nX_{ij} \\;=\\; \\frac{G_{ij} - 2p_j}{\\sqrt{2p_j(1-p_j)}} \\, ,\n$$\nwhere the denominator is stabilized by adding a small positive constant $\\varepsilon$ inside the square root if needed to avoid division by zero.\n- The sample LD correlation matrix is estimated as\n$$\nR \\;=\\; \\frac{1}{n-1} X^\\top X \\, ,\n$$\nwhich equals the sample correlation when the standardization is exact.\n- Finite-sample estimation error induces sampling variance in $R$. A commonly used regularization is shrinkage toward the identity matrix:\n$$\nR_{\\lambda} \\;=\\; (1-\\lambda) R \\;+\\; \\lambda I_m \\, ,\n$$\nwhere $I_m$ is the $m \\times m$ identity matrix and $\\lambda \\in [0,1]$ is the shrinkage intensity.\n- Assume a Gaussian–Wishart model for the standardized data. An approximate plug-in estimator of the optimal shrinkage intensity toward $I_m$ minimizes the expected squared Frobenius error and can be implemented as\n$$\n\\lambda^\\star \\;=\\; \\min\\!\\Bigg( 1, \\; \\max\\!\\Big( 0, \\; \\frac{\\phi}{\\delta + \\eta} \\Big) \\Bigg) \\, ,\n$$\nwith small $\\eta > 0$ for numerical stability, and\n$$\n\\phi \\;=\\; \\frac{1}{n-1} \\sum_{i \\neq j} \\big( R_{ij}^2 + 1 \\big) \\, , \\qquad\n\\delta \\;=\\; \\sum_{i \\neq j} R_{ij}^2 \\, .\n$$\n\nRequired computations per test case:\n1. Given $G$ and external allele frequencies $\\{p_j\\}_{j=1}^{m}$, compute $R_{\\text{ext}}$ using the external frequencies in the standardization.\n2. Compute $R_{\\text{samp}}$ by standardizing with sample allele frequencies $\\{\\hat{p}_j\\}_{j=1}^{m}$ instead of the external frequencies.\n3. Using $R_{\\text{ext}}$, compute the shrinkage intensity $\\lambda^\\star$ and the regularized matrix\n$$\nR_{\\text{reg}} \\;=\\; (1-\\lambda^\\star) R_{\\text{ext}} \\;+\\; \\lambda^\\star I_m \\, .\n$$\n\nYour program must output, for each test case, the following three quantities:\n- The maximum absolute entrywise deviation between $R_{\\text{ext}}$ and $R_{\\text{samp}}$:\n$$\nd \\;=\\; \\max_{i,j} \\big| \\big(R_{\\text{ext}}\\big)_{ij} - \\big(R_{\\text{samp}}\\big)_{ij} \\big| \\, .\n$$\n- The Frobenius norm of the difference between $R_{\\text{ext}}$ and $R_{\\text{reg}}$:\n$$\nf \\;=\\; \\big\\| R_{\\text{ext}} - R_{\\text{reg}} \\big\\|_{\\mathrm{F}} \\, .\n$$\n- A boolean indicating whether $R_{\\text{reg}}$ is strictly positive definite, defined as all eigenvalues strictly greater than a threshold $\\tau$, where $\\tau = 10^{-8}$:\n$$\n\\text{is\\_spd} \\;=\\; \\big( \\lambda_{\\min}(R_{\\text{reg}}) > \\tau \\big) \\, .\n$$\n\nNumerical conventions:\n- Use $\\varepsilon = 10^{-8}$ in the variance denominator stabilization of $X_{ij}$ if needed.\n- Use $\\eta = 10^{-12}$ in the denominator of $\\lambda^\\star$ to avoid division by zero.\n- Use $\\tau = 10^{-8}$ to test strict positive definiteness.\n\nTest suite:\nProvide the following four test cases. Each contains $n$, $m$, the genotype matrix $G$ (row-major order: $n$ rows and $m$ columns), and the vector of external allele frequencies $(p_1,\\ldots,p_m)$.\n\n- Test case A (general case; moderate correlations): $n=8$, $m=4$,\n  $$\n  G \\;=\\; \\begin{bmatrix}\n  0 & 0 & 2 & 1 \\\\\n  1 & 1 & 1 & 1 \\\\\n  2 & 2 & 0 & 2 \\\\\n  0 & 1 & 1 & 0 \\\\\n  1 & 1 & 2 & 2 \\\\\n  2 & 2 & 1 & 2 \\\\\n  0 & 0 & 0 & 0 \\\\\n  1 & 1 & 1 & 1\n  \\end{bmatrix} \\, , \\quad\n  (p_1,p_2,p_3,p_4) \\;=\\; (0.4,\\, 0.45,\\, 0.52,\\, 0.55) \\, .\n  $$\n- Test case B (rare allele present): $n=10$, $m=3$,\n  $$\n  G \\;=\\; \\begin{bmatrix}\n  0 & 0 & 2 \\\\\n  0 & 1 & 1 \\\\\n  0 & 1 & 1 \\\\\n  0 & 0 & 2 \\\\\n  0 & 1 & 0 \\\\\n  0 & 0 & 1 \\\\\n  0 & 1 & 2 \\\\\n  0 & 0 & 0 \\\\\n  1 & 0 & 1 \\\\\n  0 & 1 & 2\n  \\end{bmatrix} \\, , \\quad\n  (p_1,p_2,p_3) \\;=\\; (0.04,\\, 0.3,\\, 0.55) \\, .\n  $$\n- Test case C (rank-deficient $R$ with $m > n$): $n=5$, $m=6$,\n  $$\n  G \\;=\\; \\begin{bmatrix}\n  0 & 1 & 2 & 0 & 1 & 2 \\\\\n  1 & 2 & 1 & 1 & 2 & 1 \\\\\n  2 & 1 & 0 & 2 & 1 & 0 \\\\\n  0 & 0 & 1 & 0 & 0 & 1 \\\\\n  1 & 1 & 2 & 1 & 1 & 2\n  \\end{bmatrix} \\, , \\quad\n  (p_1,\\ldots,p_6) \\;=\\; (0.2,\\, 0.5,\\, 0.6,\\, 0.3,\\, 0.5,\\, 0.6) \\, .\n  $$\n- Test case D (perfect correlation between two SNPs): $n=6$, $m=3$,\n  $$\n  G \\;=\\; \\begin{bmatrix}\n  0 & 0 & 0 \\\\\n  0 & 0 & 1 \\\\\n  1 & 1 & 0 \\\\\n  1 & 1 & 1 \\\\\n  2 & 2 & 0 \\\\\n  2 & 2 & 1\n  \\end{bmatrix} \\, , \\quad\n  (p_1,p_2,p_3) \\;=\\; (0.5,\\, 0.5,\\, 0.5) \\, .\n  $$\n\nFinal output format:\n- For each test case, compute $(d, f, \\text{is\\_spd})$ as defined above. Your program must produce a single line of output containing a list of four lists, one per test case, in order A, B, C, D. Each inner list must be of the form $[d,f,\\text{is\\_spd}]$, where $d$ and $f$ are rounded to exactly $6$ decimal places, and $\\text{is\\_spd}$ is a boolean. For example,\n$$\n\\big[ [d_A, f_A, \\text{is\\_spd}_A], [d_B, f_B, \\text{is\\_spd}_B], [d_C, f_C, \\text{is\\_spd}_C], [d_D, f_D, \\text{is\\_spd}_D] \\big] \\, .\n$$\n\nScientific realism requirement:\n- Your implementation should adhere to the definitions above and must be numerically stable given the constants $\\varepsilon$, $\\eta$, and $\\tau$. No stochastic components may be used.",
            "solution": "The problem is deemed valid as it is scientifically grounded in statistical genetics, well-posed with all necessary information provided, and objective in its formulation. It presents a clear, algorithmically defined task without internal contradictions or infeasible requirements. We will proceed with a complete solution.\n\nThe task is to analyze genotype data for several test cases by computing and comparing different estimates of the Linkage Disequilibrium (LD) correlation matrix, $R$. The process involves standardizing the genotype data, calculating correlation matrices, and applying a shrinkage regularization technique. For each case, we must report three summary metrics: the maximum deviation between two LD estimates ($d$), the magnitude of the regularization adjustment ($f$), and a test for strict positive definiteness of the regularized matrix ($\\text{is\\_spd}$).\n\nLet us formalize the step-by-step procedure.\n\nA given test case provides a genotype matrix $G \\in \\mathbb{R}^{n \\times m}$ for $n$ individuals and $m$ SNPs, and a vector of external allele frequencies $p_{\\text{ext}} = (p_1, \\ldots, p_m)$. The constants $\\varepsilon = 10^{-8}$, $\\eta = 10^{-12}$, and $\\tau = 10^{-8}$ are specified for numerical stability and testing.\n\n**Step 1: Standardization of the Genotype Matrix**\n\nThe first step is to standardize the genotype matrix $G$. The standardization formula is given as:\n$$\nX_{ij} = \\frac{G_{ij} - 2p_j}{\\sqrt{2p_j(1-p_j)}}\n$$\nwhere $p_j$ is the alternate allele frequency for SNP $j$. The denominator, representing the standard deviation under Hardy-Weinberg Equilibrium (HWE), is stabilized to prevent division by zero or by very small numbers. We implement this by calculating the denominator as $\\sqrt{2p_j(1-p_j) + \\varepsilon}$.\n\nThis standardization must be performed twice for each test case:\n1.  Using the provided external allele frequencies $\\{p_j\\}_{j=1}^{m}$ to produce a matrix $X_{\\text{ext}}$.\n2.  Using sample-estimated allele frequencies $\\{\\hat{p}_j\\}_{j=1}^{m}$ to produce a matrix $X_{\\text{samp}}$. The sample allele frequency for SNP $j$ is estimated from the data as:\n    $$\n    \\hat{p}_j = \\frac{1}{2n} \\sum_{i=1}^{n} G_{ij}\n    $$\n\n**Step 2: Computation of LD Correlation Matrices**\n\nWith the standardized matrices, we compute the two LD correlation matrices, $R_{\\text{ext}}$ and $R_{\\text{samp}}$, using the formula for the sample covariance of the standardized data:\n$$\nR = \\frac{1}{n-1} X^\\top X\n$$\nThis yields:\n$$\nR_{\\text{ext}} = \\frac{1}{n-1} X_{\\text{ext}}^\\top X_{\\text{ext}}\n$$\n$$\nR_{\\text{samp}} = \\frac{1}{n-1} X_{\\text{samp}}^\\top X_{\\text{samp}}\n$$\nBoth $R_{\\text{ext}}$ and $R_{\\text{samp}}$ are $m \\times m$ symmetric matrices.\n\n**Step 3: Calculation of Deviation Metric $d$**\n\nThe first required output metric, $d$, quantifies the difference between the LD matrices derived from external versus sample frequencies. It is the maximum absolute entrywise difference:\n$$\nd = \\max_{i,j} \\left| \\left(R_{\\text{ext}}\\right)_{ij} - \\left(R_{\\text{samp}}\\right)_{ij} \\right|\n$$\n\n**Step 4: Shrinkage Regularization**\n\nThe matrix $R_{\\text{ext}}$ is regularized to reduce estimation error due to finite sample size ($n$). The regularization is performed via shrinkage towards the identity matrix $I_m$:\n$$\nR_{\\text{reg}} = (1-\\lambda^\\star) R_{\\text{ext}} + \\lambda^\\star I_m\n$$\nThe optimal shrinkage intensity, $\\lambda^\\star$, is estimated using the provided plug-in formulas. First, we compute the intermediate quantities $\\phi$ and $\\delta$ based on $R_{\\text{ext}}$:\n$$\n\\delta = \\sum_{i \\neq j} \\left(R_{\\text{ext}}\\right)_{ij}^2\n$$\n$$\n\\phi = \\frac{1}{n-1} \\sum_{i \\neq j} \\left( \\left(R_{\\text{ext}}\\right)_{ij}^2 + 1 \\right)\n$$\nThe term $\\sum_{i \\neq j} (\\cdot)$ denotes the sum over all off-diagonal elements of the matrix. This can be computed by taking the sum over all elements and subtracting the sum over the diagonal elements. Let $S = \\sum_{i,j} \\left(R_{\\text{ext}}\\right)_{ij}^2$ and $S_{\\text{diag}} = \\sum_{i} \\left(R_{\\text{ext}}\\right)_{ii}^2$. Then $\\delta = S - S_{\\text{diag}}$. The sum $\\sum_{i \\neq j} 1$ is the number of off-diagonal elements, which is $m(m-1)$. Thus, $\\phi$ can be computed as:\n$$\n\\phi = \\frac{1}{n-1} \\left( \\delta + m(m-1) \\right)\n$$\nThe shrinkage intensity $\\lambda^\\star$ is then calculated, with clipping to the interval $[0,1]$ and numerical stabilization using $\\eta$:\n$$\n\\lambda^\\star = \\min\\left( 1, \\max\\left( 0, \\frac{\\phi}{\\delta + \\eta} \\right) \\right)\n$$\nWith $\\lambda^\\star$, we can now compute the regularized matrix $R_{\\text{reg}}$.\n\n**Step 5: Calculation of Regularization Effect Metric $f$**\n\nThe second output metric, $f$, measures the magnitude of the change applied by the regularization. It is the Frobenius norm of the difference between the original and regularized matrices:\n$$\nf = \\left\\| R_{\\text{ext}} - R_{\\text{reg}} \\right\\|_{\\mathrm{F}}\n$$\nSubstituting the definition of $R_{\\text{reg}}$, we can see that $R_{\\text{ext}} - R_{\\text{reg}} = \\lambda^\\star (R_{\\text{ext}} - I_m)$. Therefore:\n$$\nf = \\lambda^\\star \\left\\| R_{\\text{ext}} - I_m \\right\\|_{\\mathrm{F}}\n$$\nwhere the norm is calculated as $\\|A\\|_{\\mathrm{F}} = \\sqrt{\\sum_{i,j} A_{ij}^2}$.\n\n**Step 6: Test for Strict Positive Definiteness (SPD)**\n\nThe final metric, $\\text{is\\_spd}$, is a boolean value indicating whether $R_{\\text{reg}}$ is strictly positive definite. A matrix is strictly positive definite if all its eigenvalues are strictly positive. We test this condition against a small positive threshold $\\tau = 10^{-8}$:\n$$\n\\text{is\\_spd} = \\left( \\lambda_{\\min}(R_{\\text{reg}}) > \\tau \\right)\n$$\nwhere $\\lambda_{\\min}(R_{\\text{reg}})$ is the minimum eigenvalue of $R_{\\text{reg}}$. Since $R_{\\text{reg}}$ is symmetric by construction, its eigenvalues are real, and efficient numerical algorithms can be used to find them.\n\nWe will apply this entire sequence of computations to each of the four test cases provided and format the results $(d, f, \\text{is\\_spd})$ as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the final output.\n    \"\"\"\n    \n    # Numerical conventions\n    epsilon = 1e-8\n    eta = 1e-12\n    tau = 1e-8\n\n    # Test suite definition\n    test_cases = [\n        (8, 4, np.array([\n            [0, 0, 2, 1], [1, 1, 1, 1], [2, 2, 0, 2], [0, 1, 1, 0],\n            [1, 1, 2, 2], [2, 2, 1, 2], [0, 0, 0, 0], [1, 1, 1, 1]\n        ]), np.array([0.4, 0.45, 0.52, 0.55])),\n        (10, 3, np.array([\n            [0, 0, 2], [0, 1, 1], [0, 1, 1], [0, 0, 2], [0, 1, 0],\n            [0, 0, 1], [0, 1, 2], [0, 0, 0], [1, 0, 1], [0, 1, 2]\n        ]), np.array([0.04, 0.3, 0.55])),\n        (5, 6, np.array([\n            [0, 1, 2, 0, 1, 2], [1, 2, 1, 1, 2, 1], [2, 1, 0, 2, 1, 0],\n            [0, 0, 1, 0, 0, 1], [1, 1, 2, 1, 1, 2]\n        ]), np.array([0.2, 0.5, 0.6, 0.3, 0.5, 0.6])),\n        (6, 3, np.array([\n            [0, 0, 0], [0, 0, 1], [1, 1, 0], [1, 1, 1],\n            [2, 2, 0], [2, 2, 1]\n        ]), np.array([0.5, 0.5, 0.5]))\n    ]\n    \n    all_results = []\n\n    for n, m, G, p_ext in test_cases:\n        G_float = G.astype(np.float64)\n\n        # Helper function for standardization\n        def standardize(genotypes, freqs):\n            mean = 2 * freqs\n            # Stabilized variance term: add epsilon inside square root\n            variance = 2 * freqs * (1 - freqs)\n            std_dev = np.sqrt(variance + epsilon)\n            # Handle cases where std_dev might be zero for monomorphic SNPs\n            std_dev[std_dev  epsilon] = 1.0 # Avoid division by zero, resulting X will be 0\n            return (genotypes - mean) / std_dev\n        \n        # Helper function for LD matrix calculation\n        def calculate_R(X_mat, n_samples):\n            return (1 / (n_samples - 1)) * (X_mat.T @ X_mat)\n\n        # 1. Compute R_ext\n        X_ext = standardize(G_float, p_ext)\n        R_ext = calculate_R(X_ext, n)\n\n        # 2. Compute R_samp\n        p_samp = np.sum(G_float, axis=0) / (2 * n)\n        X_samp = standardize(G_float, p_samp)\n        R_samp = calculate_R(X_samp, n)\n        \n        # 3. Compute metric d\n        d = np.max(np.abs(R_ext - R_samp))\n\n        # 4. Compute shrinkage intensity lambda_star using R_ext\n        # Sum of squared off-diagonal elements\n        off_diag_sq_sum = np.sum(R_ext**2) - np.sum(np.diag(R_ext)**2)\n        \n        delta = off_diag_sq_sum\n        phi_sum_term = 0\n        for i in range(m):\n            for j in range(m):\n                if i != j:\n                    phi_sum_term += (R_ext[i, j]**2 + 1)\n\n        phi = (1 / (n - 1)) * phi_sum_term\n        \n        lambda_val = phi / (delta + eta)\n        lambda_star = np.clip(lambda_val, 0, 1)\n        \n        # 5. Compute R_reg\n        I_m = np.identity(m)\n        R_reg = (1 - lambda_star) * R_ext + lambda_star * I_m\n\n        # 6. Compute metric f\n        f = np.linalg.norm(R_ext - R_reg, 'fro')\n\n        # 7. Compute metric is_spd\n        # Use eigvalsh for symmetric matrices; it's faster and returns sorted eigenvalues\n        eigenvalues = np.linalg.eigvalsh(R_reg)\n        is_spd = bool(eigenvalues[0] > tau)\n        \n        all_results.append([d, f, is_spd])\n\n    # Format the final output string as a list of lists representation\n    formatted_results = []\n    for d_val, f_val, s_val in all_results:\n        # Create a list with formatted numbers and boolean to be converted to a string\n        # Python's str(bool) gives 'True' or 'False' as required\n        formatted_sublist = [f\"{d_val:.6f}\", f\"{f_val:.6f}\", str(s_val)]\n        # Create the string for the sublist\n        formatted_results.append(f\"[{','.join(formatted_sublist)}]\")\n\n    print(f\"[[{all_results[0][0]:.6f},{all_results[0][1]:.6f},{all_results[0][2]}],[{all_results[1][0]:.6f},{all_results[1][1]:.6f},{all_results[1][2]}],[{all_results[2][0]:.6f},{all_results[2][1]:.6f},{all_results[2][2]}],[{all_results[3][0]:.6f},{all_results[3][1]:.6f},{all_results[3][2]}]]\")\n\n```"
        }
    ]
}