{
    "hands_on_practices": [
        {
            "introduction": "深度学习模型的原始输出（通常是一个概率值）本身并不是最终的诊断结论。为了将变异分类为“致病性”或“良性”，我们必须选择一个决策阈值。这个选择本质上是在不同类型的错误之间进行权衡，例如在灵敏度（召回率）和精确率之间取得平衡。这个实践练习将指导你从第一性原理出发，推导出一个能最大化$F_1$分数的最佳阈值，从而将分类器的理论性能与实际临床决策联系起来。",
            "id": "4330573",
            "problem": "在基因组诊断的精准医疗流程中，一个深度学习分类器会输出一个校准后的后验概率 $p \\in [0,1]$，该概率表示在给定观测到的分子特征的条件下，某个单核苷酸变异确实是致病的。考虑一个留出的评估队列，其构成是均衡的，即真正致病的变异和真正良性的变异以相等的比例存在。令 $Y \\in \\{1,0\\}$ 表示真实类别（$Y=1$ 为致病，$Y=0$ 为良性），并假设模型的校准分数具有以下类条件分布：\n- 对于致病变异（$Y=1$），$p \\mid Y=1 \\sim \\operatorname{Beta}(2,1)$。\n- 对于良性变异（$Y=0$），$p \\mid Y=0 \\sim \\operatorname{Beta}(1,2)$。\n\n假设Beta分布的密度函数为 $f(p; a,b) = \\frac{1}{B(a,b)} p^{a-1} (1-p)^{b-1}$（对于 $0 \\leq p \\leq 1$），其中 $B(a,b)$ 是Beta函数。同时假设校准意味着对于任何决策阈值 $\\tau \\in [0,1]$，以下基本定义成立：\n- 真阳性率（召回率）为 $\\operatorname{TPR}(\\tau) = \\mathbb{P}(p \\geq \\tau \\mid Y=1)$。\n- 假阳性率是 $\\operatorname{FPR}(\\tau) = \\mathbb{P}(p \\geq \\tau \\mid Y=0)$。\n- 流行率是 $\\pi = \\mathbb{P}(Y=1)$，根据均衡队列设计，此处等于 $\\pi = \\frac{1}{2}$。\n- 在阈值 $\\tau$ 下的精确率（阳性预测值）为 $\\operatorname{PPV}(\\tau) = \\mathbb{P}(Y=1 \\mid p \\geq \\tau)$，它可以通过贝叶斯法则由上述概率和 $\\pi$ 得到。\n- 在 $\\tau$ 下的 $F_{1}$ 分数是精确率和召回率的调和平均数，$F_{1}(\\tau) = \\frac{2 \\,\\operatorname{PPV}(\\tau)\\,\\operatorname{TPR}(\\tau)}{\\operatorname{PPV}(\\tau) + \\operatorname{TPR}(\\tau)}$。\n\n变异分类的决策规则是，当且仅当 $p \\geq \\tau$ 时，将一个变异判定为“致病”。仅使用这些基本定义和给定的分数分布，从第一性原理推导出能使该队列上 $F_{1}$ 分数最大化的操作阈值 $\\tau^{\\star}$。请以 $\\tau^{\\star}$ 的单个精确解析表达式的形式提供最终结果，不带单位。如果您选择给出数值近似值，也请包含精确形式；除非您明确同时提供两者，否则不要四舍五入，并且不要包含任何单位。最终答案必须是单个数字或单个闭式表达式。",
            "solution": "该问题陈述具有科学依据、提法恰当、客观且内部一致。所有给定的定义和分布在统计学和机器学习中都是标准的，并且基因组诊断的背景是合适的。分类器分数的分布不仅有效，而且对于给定的均衡队列满足完美校准的条件，这是一个优雅的性质。因此，该问题是有效的，我们可以着手求解。\n\n目标是找到使 $F_{1}$ 分数最大化的操作阈值 $\\tau^{\\star} \\in [0,1]$。$F_{1}$ 分数的定义为：\n$$F_{1}(\\tau) = \\frac{2 \\,\\operatorname{PPV}(\\tau)\\,\\operatorname{TPR}(\\tau)}{\\operatorname{PPV}(\\tau) + \\operatorname{TPR}(\\tau)}$$\n其中 $\\operatorname{PPV}(\\tau)$ 是精确率（阳性预测值），$\\operatorname{TPR}(\\tau)$ 是在决策阈值 $\\tau$ 下的真阳性率（召回率）。\n\n首先，我们推导真阳性率 $\\operatorname{TPR}(\\tau)$ 的表达式。根据定义，$\\operatorname{TPR}(\\tau) = \\mathbb{P}(p \\geq \\tau \\mid Y=1)$。致病变异（$Y=1$）的分数分布为 $p \\mid Y=1 \\sim \\operatorname{Beta}(2,1)$。\n$\\operatorname{Beta}(a,b)$ 分布的概率密度函数（PDF）是 $f(p; a,b) = \\frac{1}{B(a,b)} p^{a-1} (1-p)^{b-1}$。\nBeta函数 $B(a,b)$ 由 $\\int_{0}^{1} x^{a-1}(1-x)^{b-1} dx$ 给出。\n对于 $a=2$ 和 $b=1$，$B(2,1) = \\int_{0}^{1} p^{2-1}(1-p)^{1-1} dp = \\int_{0}^{1} p \\,dp = [\\frac{p^2}{2}]_{0}^{1} = \\frac{1}{2}$。\n因此，致病变异的PDF为 $f(p \\mid Y=1) = \\frac{p^{1}}{1/2} = 2p$（对于 $p \\in [0,1]$）。\n我们现在可以计算 $\\operatorname{TPR}(\\tau)$：\n$$\\operatorname{TPR}(\\tau) = \\int_{\\tau}^{1} f(p \\mid Y=1) \\,dp = \\int_{\\tau}^{1} 2p \\,dp = [p^2]_{\\tau}^{1} = 1 - \\tau^2$$\n\n接下来，我们推导精确率 $\\operatorname{PPV}(\\tau) = \\mathbb{P}(Y=1 \\mid p \\geq \\tau)$ 的表达式。使用贝叶斯法则和全概率定律：\n$$\\operatorname{PPV}(\\tau) = \\frac{\\mathbb{P}(p \\geq \\tau \\mid Y=1)\\mathbb{P}(Y=1)}{\\mathbb{P}(p \\geq \\tau \\mid Y=1)\\mathbb{P}(Y=1) + \\mathbb{P}(p \\geq \\tau \\mid Y=0)\\mathbb{P}(Y=0)}$$\n这等价于：\n$$\\operatorname{PPV}(\\tau) = \\frac{\\operatorname{TPR}(\\tau)\\pi}{\\operatorname{TPR}(\\tau)\\pi + \\operatorname{FPR}(\\tau)(1-\\pi)}$$\n我们已知流行率 $\\pi = \\mathbb{P}(Y=1) = \\frac{1}{2}$。我们需要计算假阳性率 $\\operatorname{FPR}(\\tau) = \\mathbb{P}(p \\geq \\tau \\mid Y=0)$。\n良性变异（$Y=0$）的分数分布为 $p \\mid Y=0 \\sim \\operatorname{Beta}(1,2)$。\n对于 $a=1$ 和 $b=2$，$B(1,2) = \\int_{0}^{1} p^{1-1}(1-p)^{2-1} dp = \\int_{0}^{1} (1-p) \\,dp = [p - \\frac{p^2}{2}]_{0}^{1} = 1 - \\frac{1}{2} = \\frac{1}{2}$。\n良性变异的PDF为 $f(p \\mid Y=0) = \\frac{(1-p)^{1}}{1/2} = 2(1-p)$（对于 $p \\in [0,1]$）。\n我们现在可以计算 $\\operatorname{FPR}(\\tau)$：\n$$\\operatorname{FPR}(\\tau) = \\int_{\\tau}^{1} f(p \\mid Y=0) \\,dp = \\int_{\\tau}^{1} 2(1-p) \\,dp = 2[p - \\frac{p^2}{2}]_{\\tau}^{1} = 2\\left( (1-\\frac{1}{2}) - (\\tau - \\frac{\\tau^2}{2}) \\right) = 2(\\frac{1}{2} - \\tau + \\frac{\\tau^2}{2}) = 1 - 2\\tau + \\tau^2 = (1-\\tau)^2$$\n现在，我们将 $\\operatorname{TPR}(\\tau)$、$\\operatorname{FPR}(\\tau)$ 和 $\\pi$ 代入 $\\operatorname{PPV}(\\tau)$ 的表达式中：\n$$\\operatorname{PPV}(\\tau) = \\frac{(1-\\tau^2)(\\frac{1}{2})}{(1-\\tau^2)(\\frac{1}{2}) + (1-\\tau)^2(\\frac{1}{2})} = \\frac{1-\\tau^2}{1-\\tau^2 + (1-\\tau)^2}$$\n对于 $\\tau \\neq 1$，我们可以进行因式分解 $1-\\tau^2 = (1-\\tau)(1+\\tau)$ 和 $(1-\\tau)^2 = (1-\\tau)(1-\\tau)$：\n$$\\operatorname{PPV}(\\tau) = \\frac{(1-\\tau)(1+\\tau)}{(1-\\tau)(1+\\tau) + (1-\\tau)(1-\\tau)} = \\frac{1+\\tau}{(1+\\tau) + (1-\\tau)} = \\frac{1+\\tau}{2}$$\n\n现在我们可以将 $F_1(\\tau)$ 完全写成 $\\tau$ 的函数：\n$$F_{1}(\\tau) = \\frac{2 \\left(\\frac{1+\\tau}{2}\\right)(1-\\tau^2)}{\\frac{1+\\tau}{2} + (1-\\tau^2)} = \\frac{(1+\\tau)(1-\\tau^2)}{\\frac{1+\\tau+2(1-\\tau^2)}{2}} = \\frac{2(1+\\tau)(1-\\tau^2)}{1+\\tau+2-2\\tau^2} = \\frac{2(1+\\tau)(1-\\tau)(1+\\tau)}{-2\\tau^2+\\tau+3}$$\n分母可以因式分解为 $-2\\tau^2+\\tau+3 = (3-2\\tau)(1+\\tau)$。对于 $\\tau \\in [0,1)$，$1+\\tau \\neq 0$，所以我们可以化简：\n$$F_{1}(\\tau) = \\frac{2(1+\\tau)(1-\\tau)(1+\\tau)}{(3-2\\tau)(1+\\tau)} = \\frac{2(1-\\tau)(1+\\tau)}{3-2\\tau} = \\frac{2(1-\\tau^2)}{3-2\\tau}$$\n为了找到最大值，我们计算 $F_{1}(\\tau)$ 关于 $\\tau$ 的导数并令其为0。使用商法则：\n$$\\frac{dF_1}{d\\tau} = 2 \\frac{(-2\\tau)(3-2\\tau) - (1-\\tau^2)(-2)}{(3-2\\tau)^2} = 2 \\frac{-6\\tau+4\\tau^2+2-2\\tau^2}{(3-2\\tau)^2} = \\frac{2(2\\tau^2-6\\tau+2)}{(3-2\\tau)^2} = \\frac{4(\\tau^2-3\\tau+1)}{(3-2\\tau)^2}$$\n为了使导数为零，分子必须为零：\n$$\\tau^2 - 3\\tau + 1 = 0$$\n我们解这个关于 $\\tau$ 的二次方程：\n$$\\tau = \\frac{-(-3) \\pm \\sqrt{(-3)^2 - 4(1)(1)}}{2(1)} = \\frac{3 \\pm \\sqrt{9-4}}{2} = \\frac{3 \\pm \\sqrt{5}}{2}$$\n这给出两个潜在解：$\\tau_1 = \\frac{3 + \\sqrt{5}}{2}$ 和 $\\tau_2 = \\frac{3 - \\sqrt{5}}{2}$。\n$\\sqrt{5}$ 的值约等于 $2.236$。\n$\\tau_1 \\approx \\frac{3+2.236}{2} \\approx 2.618$。这个值超出了概率阈值的有效域 $[0,1]$。\n$\\tau_2 \\approx \\frac{3-2.236}{2} \\approx 0.382$。这个值在域 $[0,1]$ 内。\n因此，有效范围内的唯一临界点是 $\\tau^{\\star} = \\frac{3 - \\sqrt{5}}{2}$。\n\n为了确认这是一个最大值，我们可以检验一阶导数的符号。分母 $(3-2\\tau)^2$ 对于 $\\tau \\neq 3/2$ 总是正的。导数的符号由分子 $g(\\tau) = \\tau^2-3\\tau+1$ 决定，这是一个开口向上的抛物线。对于 $\\tau  \\tau_2$，$g(\\tau) > 0$（例如，$g(0)=1$），所以 $F_1(\\tau)$ 是递增的。对于 $\\tau > \\tau_2$（但小于 $\\tau_1$），$g(\\tau)  0$，所以 $F_1(\\tau)$ 是递减的。这证实了 $\\tau^{\\star} = \\frac{3 - \\sqrt{5}}{2}$ 对应一个局部最大值。由于它是区间 $[0,1)$ 内唯一的临界点，并且 $F_1(0)=2/3 \\approx 0.667$ 和 $F_1(1)=0$，所以这个局部最大值是该区间上的全局最大值。\n\n使 $F_1$ 分数最大化的最优阈值 $\\tau^{\\star}$ 是 $\\frac{3 - \\sqrt{5}}{2}$。",
            "answer": "$$\\boxed{\\frac{3 - \\sqrt{5}}{2}}$$"
        },
        {
            "introduction": "在临床诊断等高风险应用中，准确量化预测的不确定性至关重要。相比于提供一个可能错误的单点预测，一个更安全、更负责任的做法是提供一个包含所有可能标签的预测集，并附带统计保证。本练习将介绍一种强大的现代技术——“保形预测”（conformal prediction），用于构建具有预先指定的置信水平的预测集。你将通过实践，学习如何构建一个保证误差率上限的决策规则，这对于在医疗领域开发可信赖的人工智能系统至关重要。",
            "id": "4330543",
            "problem": "您的任务是设计并实现一个基于原则的聚合器，用于整合来自独立深度学习模型的、旨在评估基因组变异致病性的多模态证据。目标是通过一种与概率论和最优估计相符的方式，结合多个特定于模态的输出，为每个变异生成一个单一的致病性后验概率。\n\n从适合上下文的基本基础开始：\n- 来自 Bayes' theorem 的后验概率定义：对于一个二进制标签 $Y \\in \\{0,1\\}$ 和证据 $x$，后验几率满足 $$\\frac{\\mathbb{P}(Y=1 \\mid x)}{\\mathbb{P}(Y=0 \\mid x)} = \\frac{\\pi}{1-\\pi} \\cdot \\Lambda(x),$$ 其中 $\\pi \\in (0,1)$ 是致病性的先验概率，$\\Lambda(x)$ 是由观测证据贡献的似然比。\n- 一个概率的 logit 变换是其对数几率的性质：$$\\operatorname{logit}(p) = \\log\\left(\\frac{p}{1-p}\\right)。$$\n- Gauss–Markov theorem (最佳线性无偏估计量)：对于一个共同的潜在量，给定具有已知方差的独立、无偏估计量，反方差加权平均在线性无偏估计量中能够最小化均方误差。\n\n假设存在以下模态模型。您有 $M$ 个模态，由 $m \\in \\{1,\\dots,M\\}$ 索引。在隐含的中性先验为 $0.5$ 的情况下，每个模态仅基于其模态特定的证据，生成一个变异致病性的估计概率 $p_m \\in (0,1)$。经过一个使用正温度 $t_m  0$ 的校准步骤后，校准后的模态特定对数几率为 $$z_m = \\frac{\\operatorname{logit}(p_m)}{t_m}。$$ 假设每个 $z_m$ 是该变异的一个共同潜在对数似然比 $\\ell^\\star$ 的无偏噪声估计，即 $$z_m = \\ell^\\star + \\varepsilon_m,$$ 其中噪声项满足 $\\varepsilon_m \\sim \\mathcal{N}(0,\\sigma_m^2)$ 且在 $m$ 之间相互独立，标准差 $\\sigma_m  0$ 为已知。在这些假设下，Gauss–Markov theorem 所蕴含的反方差加权方法可得出一个潜在对数似然比的单一综合估计。通过 Bayes' theorem 将此综合估计与指定的先验概率 $\\pi$ 相结合，即可产生最终的致病性后验概率。\n\n您的任务是实现一个程序，该程序：\n- 接收一个固定的参数集测试套件。\n- 对于每个参数集，使用从上述基本假设推导出的基于原则的方法，计算出综合的致病性后验概率，结果为 $(0,1)$ 内的一个小数。\n- 当任何 $p_m$ 等于 $0$ 或 $1$ 时，通过在应用 logit 变换之前将 $p_m$ 裁剪到 $[\\varepsilon, 1-\\varepsilon]$（其中 $\\varepsilon = 10^{-12}$）来处理数值边界条件。\n\n具体来说，对于每个具有以下参数的变异：\n- 致病性的先验概率 $\\pi \\in (0,1)$。\n- 模态概率输出 $\\{p_m\\}_{m=1}^M$，每个值都在 $(0,1)$ 内，必须作为不带百分号的小数处理。\n- 校准温度 $\\{t_m\\}_{m=1}^M$，每个值都在 $\\mathbb{R}_{0}$ 内。\n- 模态噪声标准差 $\\{\\sigma_m\\}_{m=1}^M$，每个值都在 $\\mathbb{R}_{0}$ 内。\n\n您必须按如下方式为每个变异生成一个单一的后验概率 $\\hat{p} \\in (0,1)$，纯粹以不带百分号的小数单位表示：\n- 使用上述基本原则推导出潜在对数似然比的综合估计量，然后通过 Bayes' theorem 推导出后验概率。不要引入任何与基本假设相矛盾的启发式组合规则。\n\n测试套件：\n请精确使用以下六个测试用例，每个用例由元组 $(\\pi, \\{p_m\\}_{m=1}^M, \\{t_m\\}_{m=1}^M, \\{\\sigma_m\\}_{m=1}^M)$ 指定，其中 $M=3$：\n1. $(\\pi = 0.01, \\{p_m\\} = \\{0.8, 0.75, 0.6\\}, \\{t_m\\} = \\{1.2, 1.0, 1.5\\}, \\{\\sigma_m\\} = \\{0.6, 0.4, 0.8\\})$,\n2. $(\\pi = 0.5, \\{p_m\\} = \\{0.99, 0.02, 0.01\\}, \\{t_m\\} = \\{1.0, 1.1, 1.3\\}, \\{\\sigma_m\\} = \\{0.5, 0.3, 0.3\\})$,\n3. $(\\pi = 0.001, \\{p_m\\} = \\{1.0, 0.0, 0.5\\}, \\{t_m\\} = \\{1.0, 1.0, 1.0\\}, \\{\\sigma_m\\} = \\{0.2, 0.2, 1.0\\})$,\n4. $(\\pi = 0.9, \\{p_m\\} = \\{0.5, 0.5, 0.5\\}, \\{t_m\\} = \\{1.0, 1.0, 1.0\\}, \\{\\sigma_m\\} = \\{10.0, 10.0, 10.0\\})$,\n5. $(\\pi = 0.05, \\{p_m\\} = \\{0.7, 0.4, 0.65\\}, \\{t_m\\} = \\{2.0, 0.8, 1.4\\}, \\{\\sigma_m\\} = \\{1.5, 0.6, 0.9\\})$,\n6. $(\\pi = 0.2, \\{p_m\\} = \\{0.51, 0.49, 0.5\\}, \\{t_m\\} = \\{1.3, 1.3, 1.3\\}, \\{\\sigma_m\\} = \\{0.1, 5.0, 10.0\\})$.\n\n最终输出规范：\n您的程序应生成单行输出，其中包含六个测试用例的六个后验概率，形式为用方括号括起来的逗号分隔列表。每个概率都必须格式化为小数点后保留六位的小数。例如，输出行应类似于 $[\\text{result}_1,\\text{result}_2,\\dots,\\text{result}_6]$，其中每个 $\\text{result}_i$ 是一个在 $(0,1)$ 内的小数。",
            "solution": "我们首先将多模态整合问题形式化，即从特定于模态的深度学习模型产生的多个独立的、带噪声的估计中，估计一个潜在的对数似然比。\n\n设 $Y \\in \\{0,1\\}$ 表示二进制的致病性标签。设致病性的先验概率为 $\\pi \\in (0,1)$，因此先验几率为 $\\frac{\\pi}{1-\\pi}$，先验对数几率为 $$\\eta = \\log\\left(\\frac{\\pi}{1-\\pi}\\right)。$$ 考虑 $M$ 个模态，由 $m \\in \\{1,\\dots,M\\}$ 索引。在隐含的中性先验为 $0.5$ 的情况下，每个模态仅使用其证据生成一个输出概率 $p_m \\in (0,1)$，该概率反映了特定于模态的后验信念。此概率的 logit 变换是模态特定对数几率的一个估计。为校正校准差异，我们应用温度 $t_m  0$ 进行缩放，得到校准后的模态对数几率\n$$\nz_m = \\frac{\\operatorname{logit}(p_m)}{t_m} = \\frac{1}{t_m} \\log\\left(\\frac{p_m}{1-p_m}\\right).\n$$\n我们设定模型\n$$\nz_m = \\ell^\\star + \\varepsilon_m,\n$$\n其中 $\\ell^\\star$ 是跨模态证据所贡献的潜在对数似然比，$\\varepsilon_m \\sim \\mathcal{N}(0,\\sigma_m^2)$ 是独立的噪声项，其标准差 $\\sigma_m  0$ 已知。在用于聚合无偏估计的统计建模中，独立性和高斯噪声假设都经过了充分检验，它们使我们能够应用 Gauss–Markov theorem。\n\n根据 Gauss–Markov theorem，在 $\\ell^\\star$ 的线性无偏估计量中，反方差加权平均能够最小化均方误差。定义权重\n$$\nw_m = \\frac{1}{\\sigma_m^2}.\n$$\n那么 $\\ell^\\star$ 的最佳线性无偏估计量为\n$$\n\\hat{\\ell} = \\frac{\\sum_{m=1}^M w_m z_m}{\\sum_{m=1}^M w_m}.\n$$\n这个 $\\hat{\\ell}$ 将特定于模态的校准对数几率聚合成一个单一的综合对数似然比估计。\n\nBayes' theorem 将似然比与后验几率联系起来。给定联合证据 $x$ 的后验几率为\n$$\n\\frac{\\mathbb{P}(Y=1 \\mid x)}{\\mathbb{P}(Y=0 \\mid x)} = \\frac{\\pi}{1-\\pi} \\cdot \\Lambda(x),\n$$\n取对数得到后验对数几率\n$$\n\\log\\left(\\frac{\\mathbb{P}(Y=1 \\mid x)}{\\mathbb{P}(Y=0 \\mid x)}\\right) = \\eta + \\log \\Lambda(x).\n$$\n在我们的模型下，$\\hat{\\ell}$ 可作为 $\\log \\Lambda(x)$ 的估计量。因此，综合后验对数几率为\n$$\n\\hat{z} = \\eta + \\hat{\\ell}.\n$$\n最后，我们使用 logistic 函数（logit 的逆函数）将 $\\hat{z}$ 映射回概率，\n$$\n\\hat{p} = \\frac{1}{1 + \\exp(-\\hat{z})}.\n$$\n\n数值稳定性：\nlogit 函数在 $p_m = 0$ 或 $p_m = 1$ 时无定义。为确保数值稳定性同时尊重概率语义，我们在应用 logit 变换之前将每个 $p_m$ 裁剪到区间 $[\\varepsilon, 1-\\varepsilon]$ 内，其中 $\\varepsilon = 10^{-12}$。这种裁剪操作在避免计算中出现无穷大的同时，保留了预期的极值行为。\n\n每个测试用例的算法步骤：\n1. 读取 $\\pi$、$\\{p_m\\}_{m=1}^M$、$\\{t_m\\}_{m=1}^M$ 和 $\\{\\sigma_m\\}_{m=1}^M$。\n2. 计算先验对数几率 $\\eta = \\log\\left(\\frac{\\pi}{1-\\pi}\\right)$。\n3. 对每个模态 $m$，将 $p_m$ 裁剪到 $[\\varepsilon,1-\\varepsilon]$（其中 $\\varepsilon = 10^{-12}$），然后计算 $$z_m = \\frac{1}{t_m} \\log\\left(\\frac{p_m}{1-p_m}\\right)。$$\n4. 计算权重 $w_m = \\frac{1}{\\sigma_m^2}$ 和综合估计量 $$\\hat{\\ell} = \\frac{\\sum_{m=1}^M w_m z_m}{\\sum_{m=1}^M w_m}。$$\n5. 计算综合后验对数几率 $\\hat{z} = \\eta + \\hat{\\ell}$ 和后验概率 $$\\hat{p} = \\frac{1}{1 + \\exp(-\\hat{z})}。$$\n6. 将 $\\hat{p}$ 四舍五入到小数点后六位并输出。\n\n所提供测试套件中的边缘情况：\n- 当 $\\pi$ 非常小（例如 $\\pi = 0.001$）时，即使是强烈冲突的模态也可能在 $\\hat{\\ell}$ 中相互抵消，此时后验概率由先验主导，导致 $\\hat{p}$ 接近 $\\pi$。\n- 当所有模态都产生 $p_m = 0.5$ 且具有较大的 $\\sigma_m$ 时，综合证据不具信息量，输出 $\\hat{p}$ 趋向于先验 $\\pi$。\n- 当一个模态高度可靠（$\\sigma_m$ 小）而其他模态不可靠（$\\sigma_m$ 大）时，综合估计会适当地侧重于可靠的模态。\n\n该程序为六个指定用例实现了这些步骤，并打印单行输出，其中包含用方括号括起来的、以逗号分隔的六个结果。每个结果都是一个在 $(0,1)$ 内、四舍五入到小数点后六位的小数，满足最终的输出规范。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef clip_probabilities(p_array, eps=1e-12):\n    # Clip probabilities to avoid logit singularities at 0 and 1.\n    return np.clip(p_array, eps, 1.0 - eps)\n\ndef logit(p):\n    # Compute logit safely: log(p/(1-p))\n    return np.log(p) - np.log1p(-p)\n\ndef integrate_multimodal(pi, p_list, t_list, sigma_list, eps=1e-12):\n    # Convert inputs to numpy arrays\n    p = clip_probabilities(np.array(p_list, dtype=float), eps=eps)\n    t = np.array(t_list, dtype=float)\n    sigma = np.array(sigma_list, dtype=float)\n\n    # Prior log-odds\n    prior_log_odds = np.log(pi) - np.log(1.0 - pi)\n\n    # Calibrated modality log-odds\n    z = logit(p) / t\n\n    # Inverse-variance weights\n    w = 1.0 / (sigma ** 2)\n\n    # Integrated latent log-likelihood ratio via inverse-variance weighted average\n    ell_hat = np.sum(w * z) / np.sum(w)\n\n    # Posterior log-odds and probability\n    z_total = prior_log_odds + ell_hat\n    p_hat = 1.0 / (1.0 + np.exp(-z_total))\n    return p_hat\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (pi, p_list, t_list, sigma_list)\n        (0.01, [0.8, 0.75, 0.6], [1.2, 1.0, 1.5], [0.6, 0.4, 0.8]),\n        (0.5, [0.99, 0.02, 0.01], [1.0, 1.1, 1.3], [0.5, 0.3, 0.3]),\n        (0.001, [1.0, 0.0, 0.5], [1.0, 1.0, 1.0], [0.2, 0.2, 1.0]),\n        (0.9, [0.5, 0.5, 0.5], [1.0, 1.0, 1.0], [10.0, 10.0, 10.0]),\n        (0.05, [0.7, 0.4, 0.65], [2.0, 0.8, 1.4], [1.5, 0.6, 0.9]),\n        (0.2, [0.51, 0.49, 0.5], [1.3, 1.3, 1.3], [0.1, 5.0, 10.0]),\n    ]\n\n    results = []\n    for case in test_cases:\n        pi, p_list, t_list, sigma_list = case\n        result = integrate_multimodal(pi, p_list, t_list, sigma_list, eps=1e-12)\n        # Format to six decimal places\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在临床诊断等高风险应用中，准确量化预测的不确定性至关重要。相比于提供一个可能错误的单点预测，一个更安全、更负责任的做法是提供一个包含所有可能标签的预测集，并附带统计保证。本练习将介绍一种强大的现代技术——“保形预测”（conformal prediction），用于构建具有预先指定的置信水平的预测集。你将通过实践，学习如何构建一个保证误差率上限的决策规则，这对于在医疗领域开发可信赖的人工智能系统至关重要。",
            "id": "4330594",
            "problem": "一个用于基因组变异解读的深度学习分类器，对每个变异会输出一对估计的类别概率，分别对应良性状态和致病性状态。设两个标签分别为$0$（良性）和$1$（致病性）。考虑使用类别条件的分割归纳式保形预测法为测试变异构建一个预测集。其基本基础是校准数据和测试变异之间的可交换性假设（等价于在校准和测试阶段的独立同分布），以及非符合性分数相对于错误风险的单调性。具体来说，假设一个模型为任何变异$x$提供一个估计的概率向量$\\hat{p}(x) = (\\hat{p}_0(x), \\hat{p}_1(x))$，其中$\\hat{p}_0(x) + \\hat{p}_1(x) = 1$。为任何候选标签$y \\in \\{0,1\\}$定义一个非符合性分数$A(x,y) = 1 - \\hat{p}_y(x)$，当分类器对标签$y$的置信度较低时，该分数较大。对于每个类别$y \\in \\{0,1\\}$，仅从真实标签为$y$的校准变异中收集校准分数；将这些分数的多重集表示为$\\mathcal{S}_y$。对于一个测试变异$x^{\\ast}$，通过将$A(x^{\\ast}, y)$与$\\mathcal{S}_y$的经验分布进行比较来计算特定类别的符合性评估。在目标误覆盖水平$\\alpha \\in (0,1)$下的决策集是通过包含所有在$\\mathcal{S}_y$下的尾部概率足够大以控制误覆盖的标签$y$来获得的。\n\n你的任务是，根据上述的可交换性假设和$A(x,y)$的定义，推导出一个有限样本有效的、非随机化的类别条件决策规则，该规则产生一个预测集$\\Gamma_{\\alpha}(x^{\\ast}) \\subseteq \\{0,1\\}$，其边际覆盖率至少为$1 - \\alpha$，并实现它。你必须遵守以下约束和澄清。\n\n- 使用的基本基础：校准实例和测试实例的可交换性，非符合性分数$A(x,y) = 1 - \\hat{p}_y(x)$的定义，以及归纳式保形方法在可交换性下基于排序的有效性。除这些基础外，不要假设任何渐近性或参数化似然模型。\n- 你必须仅用$\\mathcal{S}_y$上的计数和测试分数$A(x^{\\ast}, y)$来表达决策规则，只使用基于可交换性排序论证所证明的操作。\n- 该规则必须是类别条件的，意味着每个候选标签$y$的校准分数仅与$\\mathcal{S}_y$进行比较。\n- 所有满足该规则的候选标签$y$都必须包含在最终决策集$\\Gamma_{\\alpha}(x^{\\ast})$中，且不得包含其他任何标签。\n\n使用以下测试套件。在每种情况下，你都会得到：\n- 每个类别的校准数组：对于良性（$y=0$），一个值列表，其值等于真实标签为$0$的校准变异的$\\hat{p}_0(x_i)$；对于致病性（$y=1$），一个值列表，其值等于真实标签为$1$的校准变异的$\\hat{p}_1(x_i)$。你必须通过应用$A(x_i,y) = 1 - \\hat{p}_y(x_i)$将这些值转换为非符合性分数。\n- 一个测试变异的致病性估计概率$\\hat{p}_1(x^{\\ast})$；根据守恒性，$\\hat{p}_0(x^{\\ast}) = 1 - \\hat{p}_1(x^{\\ast})$。\n- 一个目标误覆盖率$\\alpha$。\n\n为每种情况如上构建$\\Gamma_{\\alpha}(x^{\\ast})$。将最终决策集编码为一个升序排列的整数列表，其中良性编码为$0$，致病性编码为$1$。\n\n测试用例：\n\n- 用例1（顺利情况）：良性校准集 $\\{\\hat{p}_0\\} = [0.85, 0.75, 0.65, 0.55, 0.50]$，致病性校准集 $\\{\\hat{p}_1\\} = [0.92, 0.80, 0.70, 0.60]$，测试 $\\hat{p}_1(x^{\\ast}) = 0.88$，目标 $\\alpha = 0.20$。\n- 用例2（边界平局情况）：良性校准集 $\\{\\hat{p}_0\\} = [0.70]$，致病性校准集 $\\{\\hat{p}_1\\} = [0.70]$，测试 $\\hat{p}_1(x^{\\ast}) = 0.60$，目标 $\\alpha = 0.50$。\n- 用例3（模糊包含情况）：良性校准集 $\\{\\hat{p}_0\\} = [0.52, 0.62]$，致病性校准集 $\\{\\hat{p}_1\\} = [0.55, 0.65]$，测试 $\\hat{p}_1(x^{\\ast}) = 0.58$，目标 $\\alpha = 0.25$。\n\n你的程序必须按所列顺序计算这三个决策集，并生成一行输出，其中包含这三个结果，形式为用方括号括起来的逗号分隔列表，每个决策集本身打印为方括号括起来的、逗号分隔的、升序排列的整数列表，且不含任何空格。例如，三个结果的有效输出格式是 `[[],[],[]]`。因此，你的程序的输出必须看起来像 `[[\\dots],[\\dots],[\\dots]]`，其中每个内部方括号包含零个、一个或两个从$\\{0,1\\}$中选取的整数。",
            "solution": "该问题要求推导并实现一个类别条件的分割归纳式保形预测规则。推导必须基于可交换性原理。\n\n设两个类别为$y \\in \\{0, 1\\}$，分别代表良性和致病性变异。一个机器学习模型为任何变异$x$提供一个估计的概率向量$\\hat{p}(x) = (\\hat{p}_0(x), \\hat{p}_1(x))$，其中$\\hat{p}_0(x) + \\hat{p}_1(x) = 1$。数据点$(x,y)$相对于其真实标签$y$的非符合性分数定义为$A(x,y) = 1 - \\hat{p}_y(x)$。这个分数衡量了观测值的“异常”程度，分数越高表示非符合性越大。\n\n该过程是类别条件的，并在分割归纳式设置下操作。对于每个类别$y \\in \\{0,1\\}$，我们给定一个校准集$\\mathcal{C}_y$，其包含真实标签为$y$的样本。设$n_y = |\\mathcal{C}_y|$是类别$y$的校准样本数量。类别$y$的非符合性分数的多重集计算为$\\mathcal{S}_y = \\{A(x_i, y_i) | (x_i, y_i) \\in \\mathcal{C}_y \\text{ and } y_i=y\\}$。\n\n归纳式保形预测的基本原理基于可交换性。对于一个新的测试点$x^{\\ast}$，我们希望确定一个候选标签$y$是否应包含在其预测集中。我们构建一个假设，即$x^{\\ast}$的真实标签是$y$。如果这个假设为真，那么由类别$y$的$n_y$个校准点和测试点$(x^{\\ast}, y)$组成的$n_y+1$个数据点的集合是一个可交换序列。因此，它们的非符合性分数序列$\\{s_{y,1}, \\dots, s_{y,n_y}, s_y^{\\ast}\\}$，其中$s_{y,i} = A(x_i, y)$是校准点的分数，$s_y^{\\ast} = A(x^{\\ast}, y)$是测试点的分数，也是一个可交换随机变量序列。\n\n在可交换性下，测试分数$s_y^{\\ast}$在$n_y+1$个分数的组合集中的秩在整数$\\{1, 2, \\dots, n_y+1\\}$上服从均匀分布。这个性质允许我们为“$x^{\\ast}$的真实标签是$y$”这一假设定义一个“p值”。一个提供有限样本有效性的非随机化p值被定义为组合集中至少与测试分数同样不符合的分数的比例。\n\n设$k_y$是类别$y$的校准分数中大于或等于该类别假设下测试分数的数量：\n$$k_y = |\\{s \\in \\mathcal{S}_y : s \\ge s_y^{\\ast}\\}| = |\\{s \\in \\mathcal{S}_y : s \\ge A(x^{\\ast}, y)\\}|$$\n“$x^{\\ast}$的真实标签是$y$”这一假设的p值，记为$\\pi_y(x^{\\ast})$，由下式给出：\n$$\\pi_y(x^{\\ast}) = \\frac{k_y + 1}{n_y + 1}$$\n项$k_y$计算了与测试分数同样不符合的校准分数的数量，而分子中的“`$+1$`”则计入了测试分数本身。\n\n保形预测集$\\Gamma_{\\alpha}(x^{\\ast})$的构建方法是，在给定的显著性水平$\\alpha \\in (0,1)$下，包含所有不“太意外”的标签$y$。如果一个标签的p值大于$\\alpha$，则认为它不太意外。因此，决策规则是：\n$$\\text{将 } y \\text{ 包含在 } \\Gamma_{\\alpha}(x^{\\ast}) \\text{ 中} \\iff \\pi_y(x^{\\ast})  \\alpha$$\n代入p值的表达式，我们得到最终规则：\n$$\\text{将 } y \\text{ 包含在 } \\Gamma_{\\alpha}(x^{\\ast}) \\text{ 中} \\iff \\frac{k_y + 1}{n_y + 1}  \\alpha$$\n这个不等式也可以写成$k_y + 1  \\alpha(n_y + 1)$。\n\n这个过程对每个候选标签$y \\in \\{0, 1\\}$独立进行。\n对于$y=0$（良性）：\n1.  计算校准分数：$\\mathcal{S}_0 = \\{1 - \\hat{p}_0(x_i) \\text{ 对于良性校准集中的每个 } x_i\\}$。设$n_0=|\\mathcal{S}_0|$。\n2.  计算测试分数：$s_0^{\\ast} = A(x^{\\ast}, 0) = 1 - \\hat{p}_0(x^{\\ast}) = 1 - (1 - \\hat{p}_1(x^{\\ast})) = \\hat{p}_1(x^{\\ast})$。\n3.  计算$k_0 = |\\{s \\in \\mathcal{S}_0 : s \\ge s_0^{\\ast}\\}|$。\n4.  如果$\\frac{k_0 + 1}{n_0 + 1}  \\alpha$，则将$0$包含在$\\Gamma_{\\alpha}(x^{\\ast})$中。\n\n对于$y=1$（致病性）：\n1.  计算校准分数：$\\mathcal{S}_1 = \\{1 - \\hat{p}_1(x_i) \\text{ 对于致病性校准集中的每个 } x_i\\}$。设$n_1=|\\mathcal{S}_1|$。\n2.  计算测试分数：$s_1^{\\ast} = A(x^{\\ast}, 1) = 1 - \\hat{p}_1(x^{\\ast})$。\n3.  计算$k_1 = |\\{s \\in \\mathcal{S}_1 : s \\ge s_1^{\\ast}\\}|$。\n4.  如果$\\frac{k_1 + 1}{n_1 + 1}  \\alpha$，则将$1$包含在$\\Gamma_{\\alpha}(x^{\\ast})$中。\n\n最终得到的集合$\\Gamma_{\\alpha}(x^{\\ast})$是满足各自条件的所有标签的并集。这种构建方法保证了边际覆盖率，即对于任何类别$y$，将真实标签包含在预测集中的概率至少为$1-\\alpha$，即$P(y \\in \\Gamma_{\\alpha}(X) | Y=y) \\ge 1-\\alpha$。",
            "answer": "```python\nimport numpy as np\n\ndef compute_prediction_set(calib_p0, calib_p1, test_p1, alpha):\n    \"\"\"\n    Computes the class-conditional conformal prediction set.\n\n    Args:\n        calib_p0 (list): List of p_0 probabilities for benign calibration set.\n        calib_p1 (list): List of p_1 probabilities for pathogenic calibration set.\n        test_p1 (float): The p_1 probability for the test variant.\n        alpha (float): The target miscoverage level.\n\n    Returns:\n        list: The prediction set, a list of integers (0 or 1).\n    \"\"\"\n    prediction_set = []\n\n    # ----------- Label 0 (Benign) -----------\n    n0 = len(calib_p0)\n    if n0 > 0:\n        # Nonconformity score for calibration is 1 - p_0\n        scores_0 = 1 - np.array(calib_p0)\n        \n        # Test score for hypothesis y=0 is A(x*, 0) = 1 - p_0(x*) = p_1(x*)\n        test_score_0 = test_p1\n        \n        # Count calibration scores >= test score\n        k0 = np.sum(scores_0 >= test_score_0)\n        \n        # p-value check\n        p_value_0 = (k0 + 1) / (n0 + 1)\n        if p_value_0 > alpha:\n            prediction_set.append(0)\n    # If n0 is 0, p-value is 1/(0+1)=1, which is > alpha. The rule includes the label.\n    # However, problem cases have n_y > 0. The definition is upheld for n_y=0.\n    elif n0 == 0:\n         # p-value = 1/(0+1) = 1. Since alpha is in (0,1), 1 > alpha is always true.\n         prediction_set.append(0)\n\n\n    # ----------- Label 1 (Pathogenic) -----------\n    n1 = len(calib_p1)\n    if n1 > 0:\n        # Nonconformity score for calibration is 1 - p_1\n        scores_1 = 1 - np.array(calib_p1)\n        \n        # Test score for hypothesis y=1 is A(x*, 1) = 1 - p_1(x*)\n        test_score_1 = 1 - test_p1\n        \n        # Count calibration scores >= test score\n        k1 = np.sum(scores_1 >= test_score_1)\n        \n        # p-value check\n        p_value_1 = (k1 + 1) / (n1 + 1)\n        if p_value_1 > alpha:\n            prediction_set.append(1)\n    elif n1 == 0:\n        prediction_set.append(1)\n        \n    prediction_set.sort()\n    return prediction_set\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases and prints the result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'calib_p0': [0.85, 0.75, 0.65, 0.55, 0.50],\n            'calib_p1': [0.92, 0.80, 0.70, 0.60],\n            'test_p1': 0.88,\n            'alpha': 0.20\n        },\n        {\n            'calib_p0': [0.70],\n            'calib_p1': [0.70],\n            'test_p1': 0.60,\n            'alpha': 0.50\n        },\n        {\n            'calib_p0': [0.52, 0.62],\n            'calib_p1': [0.55, 0.65],\n            'test_p1': 0.58,\n            'alpha': 0.25\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_prediction_set(\n            case['calib_p0'],\n            case['calib_p1'],\n            case['test_p1'],\n            case['alpha']\n        )\n        results.append(str(result).replace(\" \", \"\"))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        }
    ]
}