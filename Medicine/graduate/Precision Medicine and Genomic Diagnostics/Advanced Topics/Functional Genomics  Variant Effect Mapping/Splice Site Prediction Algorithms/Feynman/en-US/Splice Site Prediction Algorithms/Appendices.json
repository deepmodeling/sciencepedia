{
    "hands_on_practices": [
        {
            "introduction": "The first step in building any splice site predictor is to define a scoring function that quantifies the strength of a potential splice site. This practice guides you through constructing a classic log-likelihood ratio score from first principles, based on a position-specific probability model. You will then apply this score to a practical problem: measuring how much a single nucleotide variant (SNV) is expected to perturb the score at different positions within a donor motif, giving you a hands-on understanding of positional conservation and variant impact .",
            "id": "4385861",
            "problem": "You are tasked with designing and implementing a complete simulation and analysis pipeline, grounded in first principles of molecular genetics and probabilistic modeling, to quantify position-wise functional sensitivity of the $5'$ splice donor motif to single-nucleotide changes. The computational objective is to identify, from a provided set of sequences, the motif positions at which single-nucleotide variants (SNVs) induce the largest expected perturbation in a log-likelihood ratio score defined under a position-specific multinomial model with independent columns and a fixed genomic background.\n\nStart from the following foundational bases: the Central Dogma of Molecular Biology (deoxyribonucleic acid to ribonucleic acid to protein), the existence of conserved splice site motifs around exon-intron junctions, and the widely used sequence motif scoring paradigm based on log-likelihood ratios under independent-position multinomial models with a fixed background nucleotide distribution. You may use these to construct a fully specified definition of the scoring function and the induced change in score caused by a single-nucleotide substitution. Do not assume any other specialized results.\n\nYour program must implement the following, adhering to scientific realism and internal consistency:\n- Model the $5'$ donor motif as a length-$L$ position-specific multinomial model with independent columns. Use $L=9$ and the alphabet $\\{A,C,G,T\\}$.\n- For any sequence $x$ of length $L$, define a log-likelihood ratio score $S(x)$ that sums contributions across positions by comparing the position-specific probabilities to the fixed background. You must derive this score from the above modeling assumptions without importing any unproven shortcut formulae.\n- For a single-nucleotide variant at position $i$ that changes the reference base $b$ to an alternate base $a \\neq b$, define the score change $\\Delta S = S(x^{(i \\rightarrow a)}) - S(x)$, where $x^{(i \\rightarrow a)}$ is the sequence with the base at position $i$ replaced by $a$. Derive from first principles how to compute $\\Delta S$ in this model.\n- For each position $i \\in \\{0,1,\\ldots,L-1\\}$ in a given reference sequence $x$, enumerate all three possible alternate nucleotides to generate the $\\Delta S$ values at that position. Use these to define a per-position sensitivity metric $E_i$ as the expected absolute score change at position $i$ under a uniform distribution over the three alternate bases, i.e., the mean of the three absolute values of $\\Delta S$ at that position.\n- Let $\\tau$ be the empirical $q$-quantile of the set $\\{E_0,\\ldots,E_{L-1}\\}$ with $q=0.75$. A position $i$ is labeled \"high-sensitivity\" if $E_i \\ge \\tau$.\n- Your implementation must use natural logarithms for all computations of log-likelihood ratios and must assume that all provided probabilities are strictly positive, ensuring numerical well-posedness.\n\nUse the following fixed parameters for all computations:\n- Length $L=9$ with positions indexed $0$ through $8$.\n- Background nucleotide distribution $q$ given by $q(A)=0.3$, $q(C)=0.2$, $q(G)=0.2$, $q(T)=0.3$.\n- Position-specific motif probabilities $P_i(b)$ for each position $i \\in \\{0,\\ldots,8\\}$ and base $b \\in \\{A,C,G,T\\}$:\n    - Position $0$: $P_0(A)=0.4$, $P_0(C)=0.4$, $P_0(G)=0.1$, $P_0(T)=0.1$.\n    - Position $1$: $P_1(A)=0.8$, $P_1(C)=0.0666666667$, $P_1(G)=0.0666666667$, $P_1(T)=0.0666666667$.\n    - Position $2$: $P_2(A)=0.0666666667$, $P_2(C)=0.0666666667$, $P_2(G)=0.8$, $P_2(T)=0.0666666667$.\n    - Position $3$: $P_3(A)=0.0166666667$, $P_3(C)=0.0166666667$, $P_3(G)=0.95$, $P_3(T)=0.0166666667$.\n    - Position $4$: $P_4(A)=0.0166666667$, $P_4(C)=0.0166666667$, $P_4(G)=0.0166666667$, $P_4(T)=0.95$.\n    - Position $5$: $P_5(A)=0.45$, $P_5(C)=0.05$, $P_5(G)=0.45$, $P_5(T)=0.05$.\n    - Position $6$: $P_6(A)=0.6$, $P_6(C)=0.1$, $P_6(G)=0.2$, $P_6(T)=0.1$.\n    - Position $7$: $P_7(A)=0.2$, $P_7(C)=0.1$, $P_7(G)=0.6$, $P_7(T)=0.1$.\n    - Position $8$: $P_8(A)=0.1$, $P_8(C)=0.1$, $P_8(G)=0.2$, $P_8(T)=0.6$.\n\nTest suite. Your program must compute the sets of high-sensitivity positions for each of the following reference sequences (each of length $9$ over $\\{A,C,G,T\\}$), using the above $P_i(b)$ and $q$:\n- Case $1$: $x^{(1)} = \\text{\"CAGGTAAGT\"}$.\n- Case $2$: $x^{(2)} = \\text{\"CAGGTCAGT\"}$.\n- Case $3$: $x^{(3)} = \\text{\"TTAGGTCGT\"}$.\n\nFor each case, output the list of $0$-indexed positions labeled as high-sensitivity.\n\nFinal output format. Your program should produce a single line of output containing a comma-separated list enclosed in square brackets, without spaces, where each element is itself a list of integer positions for one test case, in order of the cases. The lists for individual cases should have their elements in strictly increasing order. For example, a valid shape is a list-of-lists with no spaces. The output must aggregate the results for the three cases in order into a single bracketed list. No units are involved, and angles are not used. All returned values are integers as specified.",
            "solution": "The problem statement is assessed to be valid. It is scientifically grounded in established principles of molecular genetics and probabilistic modeling, internally consistent, and well-posed, providing all necessary information for a unique solution.\n\nThe task is to identify positions in a deoxyribonucleic acid (DNA) sequence that are highly sensitive to single-nucleotide variants (SNVs) with respect to a splice site scoring model. The analysis is based on a log-likelihood ratio score derived from a position-specific multinomial model.\n\nWe begin by formally deriving the required mathematical quantities from first principles.\n\n**1. Log-Likelihood Ratio Score $S(x)$**\n\nThe problem specifies a scoring paradigm based on the log-likelihood ratio between a motif model ($H_M$) and a background model ($H_B$). Let $x = x_0x_1...x_{L-1}$ be a DNA sequence of length $L=9$ over the alphabet $\\mathcal{A} = \\{A, C, G, T\\}$.\n\nUnder the motif model, the probability of observing sequence $x$ is given by the product of position-specific probabilities, due to the assumption of independent columns:\n$$P(x | H_M) = \\prod_{i=0}^{L-1} P_i(x_i)$$\nwhere $P_i(b)$ is the given probability of observing base $b \\in \\mathcal{A}$ at position $i$.\n\nUnder the background model, the probability of observing sequence $x$ is given by the product of fixed background probabilities:\n$$P(x | H_B) = \\prod_{i=0}^{L-1} q(x_i)$$\nwhere $q(b)$ is the given background probability of base $b$.\n\nThe likelihood ratio ($LR$) is the ratio of these two probabilities:\n$$LR(x) = \\frac{P(x | H_M)}{P(x | H_B)} = \\frac{\\prod_{i=0}^{L-1} P_i(x_i)}{\\prod_{i=0}^{L-1} q(x_i)} = \\prod_{i=0}^{L-1} \\frac{P_i(x_i)}{q(x_i)}$$\n\nThe log-likelihood ratio score, $S(x)$, is defined as the natural logarithm of the likelihood ratio. Using the property $\\ln(ab) = \\ln(a) + \\ln(b)$, the product becomes a sum:\n$$S(x) = \\ln(LR(x)) = \\ln\\left(\\prod_{i=0}^{L-1} \\frac{P_i(x_i)}{q(x_i)}\\right) = \\sum_{i=0}^{L-1} \\ln\\left(\\frac{P_i(x_i)}{q(x_i)}\\right)$$\nThis decomposes the total score into a sum of position-wise scores, $S_i(b) = \\ln(P_i(b)/q(b))$, such that $S(x) = \\sum_{i=0}^{L-1} S_i(x_i)$.\n\n**2. Score Change $\\Delta S$ due to a Single-Nucleotide Variant (SNV)**\n\nConsider a reference sequence $x$ and a variant sequence $x^{(i \\rightarrow a)}$ that is identical to $x$ except at position $i$, where the original base $b = x_i$ is replaced by an alternate base $a \\neq b$.\n\nThe score of the reference sequence is $S(x) = \\sum_{j=0}^{L-1} S_j(x_j)$.\nThe score of the variant sequence is $S(x^{(i \\rightarrow a)}) = \\sum_{j=0}^{L-1} S_j(x^{(i \\rightarrow a)}_j)$.\n\nSince $x_j = x^{(i \\rightarrow a)}_j$ for all $j \\neq i$, the terms in the sum are identical for all positions except $i$. The score change, $\\Delta S$, is defined as the difference between the variant and reference scores:\n$$\\Delta S = S(x^{(i \\rightarrow a)}) - S(x)$$\n$$\\Delta S = \\left(S_i(a) + \\sum_{j \\neq i} S_j(x_j)\\right) - \\left(S_i(b) + \\sum_{j \\neq i} S_j(x_j)\\right)$$\nThe summation terms cancel, yielding a simple expression that depends only on the scores at the mutated position $i$:\n$$\\Delta S = S_i(a) - S_i(b) = \\ln\\left(\\frac{P_i(a)}{q(a)}\\right) - \\ln\\left(\\frac{P_i(b)}{q(b)}\\right)$$\n\n**3. Position-Wise Sensitivity Metric $E_i$**\n\nFor each position $i \\in \\{0, 1, \\ldots, L-1\\}$ in a given reference sequence $x$, the sensitivity $E_i$ is defined as the expected absolute score change, assuming a uniform probability distribution over the three possible alternate bases. Let $b = x_i$ be the reference base at position $i$.\n$$E_i = \\mathbb{E}[|\\Delta S|] = \\frac{1}{3} \\sum_{a \\in \\mathcal{A}, a \\neq b} |\\Delta S_{i, a}|$$\nwhere $\\Delta S_{i, a}$ is the score change at position $i$ when base $b$ is changed to base $a$. Substituting the expression for $\\Delta S$:\n$$E_i = \\frac{1}{3} \\sum_{a \\in \\mathcal{A}, a \\neq b} \\left| \\ln\\left(\\frac{P_i(a)}{q(a)}\\right) - \\ln\\left(\\frac{P_i(b)}{q(b)}\\right) \\right|$$\nThis metric quantifies the average magnitude of perturbation to the splice site score caused by a random SNV at position $i$.\n\n**4. High-Sensitivity Position Identification**\n\nTo identify which positions are most sensitive, we first compute the set of sensitivity scores $\\{E_0, E_1, \\ldots, E_{L-1}\\}$ for a given reference sequence. A threshold $\\tau$ is then established as the empirical $q$-quantile of this set, with $q=0.75$. For a set of $n=9$ values, the $0.75$-quantile corresponds to the value at index $(n-1)q = (9-1)(0.75) = 6$ in the sorted list of $E_i$ values (using $0$-based indexing).\n\nA position $i$ is classified as \"high-sensitivity\" if its sensitivity score $E_i$ meets or exceeds this threshold: $E_i \\ge \\tau$.\n\n**Computational Procedure**\n\nThe overall algorithm for each test case is as follows:\n1.  For the given reference sequence $x$ of length $L=9$.\n2.  For each position $i$ from $0$ to $8$:\n    a. Identify the reference base $b = x_i$.\n    b. Calculate the three $\\Delta S$ values for mutating $b$ to each of the three alternate bases $a$.\n    c. Compute $E_i$ by taking the arithmetic mean of the absolute values of the three $\\Delta S$ values.\n3.  Collect the nine sensitivity scores $\\{E_0, E_1, \\ldots, E_8\\}$.\n4.  Sort these scores to find the threshold $\\tau$, which is the 7th value in the sorted list (index $6$).\n5.  Identify all positions $i$ for which $E_i \\ge \\tau$.\n6.  Return the list of these positions, sorted in increasing order.\n\nThis procedure will be applied to each of the three provided reference sequences using the specified model parameters.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the splice site sensitivity problem by implementing the derived model.\n    \"\"\"\n    # Define problem parameters\n    L = 9\n    ALPHABET = ['A', 'C', 'G', 'T']\n    BASE_TO_IDX = {base: i for i, base in enumerate(ALPHABET)}\n\n    # Background probabilities q(b)\n    q_dist = np.array([0.3, 0.2, 0.2, 0.3])\n\n    # Position-specific probabilities P_i(b)\n    p_matrix = np.array([\n        # A, C, G, T\n        [0.4, 0.4, 0.1, 0.1],                       # Pos 0\n        [0.8, 1/15, 1/15, 1/15],                     # Pos 1\n        [1/15, 1/15, 0.8, 1/15],                     # Pos 2\n        [1/60, 1/60, 0.95, 1/60],                    # Pos 3\n        [1/60, 1/60, 1/60, 0.95],                    # Pos 4\n        [0.45, 0.05, 0.45, 0.05],                    # Pos 5\n        [0.6, 0.1, 0.2, 0.1],                        # Pos 6\n        [0.2, 0.1, 0.6, 0.1],                        # Pos 7\n        [0.1, 0.1, 0.2, 0.6]                         # Pos 8\n    ])\n\n    test_cases = [\n        \"CAGGTAAGT\",\n        \"CAGGTCAGT\",\n        \"TTAGGTCGT\",\n    ]\n\n    # Pre-compute the log-likelihood ratio matrix S_i(b) = ln(P_i(b)/q(b))\n    # Using broadcasting for element-wise division.\n    log_ratio_matrix = np.log(p_matrix / q_dist)\n\n    def calculate_high_sensitivity_positions(ref_seq, l, alphabet, base_to_idx, log_ratios):\n        \"\"\"\n        Calculates high-sensitivity positions for a single reference sequence.\n        \"\"\"\n        e_scores = np.zeros(l)\n\n        for i in range(l):\n            ref_base = ref_seq[i]\n            ref_base_idx = base_to_idx[ref_base]\n            ref_score = log_ratios[i, ref_base_idx]\n            \n            abs_delta_s_sum = 0.0\n            num_alternates = 0\n\n            for alt_base in alphabet:\n                if alt_base != ref_base:\n                    alt_base_idx = base_to_idx[alt_base]\n                    alt_score = log_ratios[i, alt_base_idx]\n                    delta_s = alt_score - ref_score\n                    abs_delta_s_sum += abs(delta_s)\n                    num_alternates += 1\n            \n            e_scores[i] = abs_delta_s_sum / num_alternates\n\n        # Calculate the threshold tau (0.75-quantile)\n        tau = np.quantile(e_scores, 0.75, method='linear')\n        \n        # Find positions where E_i >= tau\n        # Use a small tolerance for floating point comparisons to be robust\n        high_sensitivity_indices = np.where(e_scores >= tau - 1e-9)[0]\n        \n        return sorted(list(high_sensitivity_indices))\n\n    # Process each test case\n    all_results = []\n    for seq in test_cases:\n        result = calculate_high_sensitivity_positions(seq, L, ALPHABET, BASE_TO_IDX, log_ratio_matrix)\n        all_results.append(result)\n\n    # Format the final output string as specified: [[pos1,pos2],[pos3],...]\n    result_strings = []\n    for res_list in all_results:\n        inner_str = \",\".join(map(str, res_list))\n        result_strings.append(f\"[{inner_str}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "A raw score from a model is not a clinical prediction; to make a decision, we must apply a threshold, which inevitably creates a trade-off between sensitivity and specificity. This practice explores the real-world consequences of this trade-off by calculating a predictor's Positive and Negative Predictive Values (PPV and NPV). By working through this exercise, you will see how a test's clinical utility is profoundly shaped by the prevalence of the condition in the target population, a critical concept for interpreting variant predictions in any diagnostic setting .",
            "id": "4385835",
            "problem": "In a clinical genomic diagnostics pipeline for rare disease, a machine learning splice site predictor is used to triage candidate Single Nucleotide Variants (SNVs) located within $\\pm 10$ nucleotides of exon-intron junctions. The predictor outputs a calibrated probability that a variant disrupts splicing. The pipeline applies a threshold $\\tau$, classifying a variant as “predicted splice-disrupting” if its predicted probability is at least $\\tau$. In validation against functional splicing assays, the operating characteristics at two thresholds are empirically measured as follows: at $\\tau_{1} = 0.4$, sensitivity is $0.90$ and specificity is $0.85$; at $\\tau_{2} = 0.7$, sensitivity is $0.75$ and specificity is $0.95$. Let the prevalence $\\pi$ of truly splice-disrupting variants among the candidate SNVs evaluated in this pipeline be $\\pi = 0.08$. Assume that these operating characteristics generalize to the clinical cohort and that the prevalence is stable across thresholds.\n\nUsing only the fundamental definitions of conditional probability and the definitions of sensitivity and specificity, derive the expressions for positive predictive value (PPV) and negative predictive value (NPV) in terms of sensitivity, specificity, and prevalence, and compute the PPV and NPV at thresholds $\\tau_{1}$ and $\\tau_{2}$. Report the ordered quadruple $\\left(\\mathrm{PPV}_{\\tau_{1}}, \\mathrm{PPV}_{\\tau_{2}}, \\mathrm{NPV}_{\\tau_{1}}, \\mathrm{NPV}_{\\tau_{2}}\\right)$ as decimal values rounded to four significant figures. Do not use the percentage sign anywhere in your final reported values.",
            "solution": "The problem as stated is scientifically grounded, well-posed, and objective. All necessary data for a unique solution are provided, and the scenario is a standard application of diagnostic test theory in bioinformatics. The given values are consistent with the typical trade-off between sensitivity and specificity. Therefore, the problem is valid.\n\nWe begin by defining the relevant events and probabilities based on the problem statement.\nLet $D$ be the event that a Single Nucleotide Variant (SNV) is truly splice-disrupting.\nLet $D^c$ be the event that an SNV is not splice-disrupting.\nLet $T^+$ be the event that the predictor classifies an SNV as \"predicted splice-disrupting\" (a positive test result).\nLet $T^-$ be the event that the predictor does not classify an SNV as \"predicted splice-disrupting\" (a negative test result).\n\nFrom the problem statement, we are given:\nThe prevalence of truly splice-disrupting variants, $\\pi = P(D) = 0.08$.\nThe probability of a variant not being splice-disrupting is therefore $P(D^c) = 1 - P(D) = 1 - 0.08 = 0.92$.\n\nThe operating characteristics of the predictor are given at two distinct thresholds, $\\tau_1$ and $\\tau_2$.\nSensitivity is the true positive rate: $Sens = P(T^+ | D)$.\nSpecificity is the true negative rate: $Spec = P(T^- | D^c)$.\n\nAt threshold $\\tau_1 = 0.4$:\nSensitivity $Sens_1 = P(T^+ | D)_{\\tau_1} = 0.90$.\nSpecificity $Spec_1 = P(T^- | D^c)_{\\tau_1} = 0.85$.\n\nAt threshold $\\tau_2 = 0.7$:\nSensitivity $Sens_2 = P(T^+ | D)_{\\tau_2} = 0.75$.\nSpecificity $Spec_2 = P(T^- | D^c)_{\\tau_2} = 0.95$.\n\nThe problem requires the derivation of expressions for the Positive Predictive Value (PPV) and Negative Predictive Value (NPV), and their computation at both thresholds.\n\nFirst, we derive the general expression for PPV. PPV is the probability that a variant is truly splice-disrupting given that it was predicted to be so:\n$PPV = P(D | T^+)$.\nUsing the definition of conditional probability (Bayes' theorem):\n$$PPV = \\frac{P(T^+ | D) P(D)}{P(T^+)}$$\nThe denominator, $P(T^+)$, is the total probability of a positive prediction. It can be found using the law of total probability:\n$P(T^+) = P(T^+ | D)P(D) + P(T^+ | D^c)P(D^c)$.\nWe recognize $P(T^+ | D)$ as the sensitivity ($Sens$). The term $P(T^+ | D^c)$ is the false positive rate, which is equal to $1 - P(T^- | D^c) = 1 - Spec$.\nSubstituting these into the expression for $P(T^+)$:\n$P(T^+) = (Sens)(\\pi) + (1 - Spec)(1 - \\pi)$.\nSubstituting this back into the expression for PPV, we obtain the desired formula:\n$$PPV = \\frac{(Sens)(\\pi)}{(Sens)(\\pi) + (1 - Spec)(1 - \\pi)}$$\n\nSecond, we derive the general expression for NPV. NPV is the probability that a variant is truly not splice-disrupting given that it was predicted not to be so:\n$NPV = P(D^c | T^-)$.\nUsing Bayes' theorem again:\n$$NPV = \\frac{P(T^- | D^c) P(D^c)}{P(T^-)}$$\nThe denominator, $P(T^-)$, is the total probability of a negative prediction. Using the law of total probability:\n$P(T^-) = P(T^- | D)P(D) + P(T^- | D^c)P(D^c)$.\nWe recognize $P(T^-|D^c)$ as the specificity ($Spec$). The term $P(T^- | D)$ is the false negative rate, which is equal to $1 - P(T^+ | D) = 1 - Sens$.\nSubstituting these into the expression for $P(T^-)$:\n$P(T^-) = (1 - Sens)(\\pi) + (Spec)(1 - \\pi)$.\nSubstituting this back into the expression for NPV, we obtain the desired formula:\n$$NPV = \\frac{(Spec)(1 - \\pi)}{(Spec)(1 - \\pi) + (1 - Sens)(\\pi)}$$\n\nNow, we compute the numerical values for PPV and NPV at each threshold.\n\nAt threshold $\\tau_1 = 0.4$:\n$Sens_1 = 0.90$, $Spec_1 = 0.85$, $\\pi = 0.08$.\n$$PPV_{\\tau_1} = \\frac{(0.90)(0.08)}{(0.90)(0.08) + (1 - 0.85)(1 - 0.08)} = \\frac{0.072}{0.072 + (0.15)(0.92)} = \\frac{0.072}{0.072 + 0.138} = \\frac{0.072}{0.21} \\approx 0.342857$$\n$$NPV_{\\tau_1} = \\frac{(0.85)(1 - 0.08)}{(0.85)(1 - 0.08) + (1 - 0.90)(0.08)} = \\frac{(0.85)(0.92)}{(0.85)(0.92) + (0.10)(0.08)} = \\frac{0.782}{0.782 + 0.008} = \\frac{0.782}{0.79} \\approx 0.989873$$\n\nAt threshold $\\tau_2 = 0.7$:\n$Sens_2 = 0.75$, $Spec_2 = 0.95$, $\\pi = 0.08$.\n$$PPV_{\\tau_2} = \\frac{(0.75)(0.08)}{(0.75)(0.08) + (1 - 0.95)(1 - 0.08)} = \\frac{0.06}{0.06 + (0.05)(0.92)} = \\frac{0.06}{0.06 + 0.046} = \\frac{0.06}{0.106} \\approx 0.566037$$\n$$NPV_{\\tau_2} = \\frac{(0.95)(1 - 0.08)}{(0.95)(1 - 0.08) + (1 - 0.75)(0.08)} = \\frac{(0.95)(0.92)}{(0.95)(0.92) + (0.25)(0.08)} = \\frac{0.874}{0.874 + 0.02} = \\frac{0.874}{0.894} \\approx 0.977628$$\n\nThe problem asks for the ordered quadruple $\\left(\\mathrm{PPV}_{\\tau_{1}}, \\mathrm{PPV}_{\\tau_{2}}, \\mathrm{NPV}_{\\tau_{1}}, \\mathrm{NPV}_{\\tau_{2}}\\right)$ with values rounded to four significant figures.\n$PPV_{\\tau_1} \\approx 0.3429$\n$PPV_{\\tau_2} \\approx 0.5660$\n$NPV_{\\tau_1} \\approx 0.9899$\n$NPV_{\\tau_2} \\approx 0.9776$\n\nThe final ordered quadruple is $(0.3429, 0.5660, 0.9899, 0.9776)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.3429 & 0.5660 & 0.9899 & 0.9776\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "When comparing different splice prediction algorithms, especially for genome-wide applications where true splice sites are rare, standard evaluation metrics can be deceptive. This practice demonstrates the pitfalls of relying solely on the Receiver Operating Characteristic (ROC) curve under conditions of extreme class imbalance. By deriving the relationship between precision, recall, and prevalence, you will understand why the Precision-Recall (PR) curve offers a more discriminative and meaningful assessment of model performance for tasks like identifying rare, disease-causing variants from a vast genomic background .",
            "id": "4385852",
            "problem": "In a whole-genome clinical pipeline for variant interpretation, a splice site predictor ranks candidate donor sites genome-wide. Let the prevalence of true donor sites among all candidate loci be $\\pi$, with $\\pi = 10^{-4}$, reflecting extreme class imbalance. Two models, $M_1$ and $M_2$, output continuous scores that are thresholded to call positives. At a clinically considered operating threshold $\\tau_1$, $M_1$ achieves $\\mathrm{TPR} = 0.95$ and $\\mathrm{FPR} = 10^{-3}$. At another clinically considered threshold $\\tau_2$, $M_2$ achieves $\\mathrm{TPR} = 0.85$ and $\\mathrm{FPR} = 10^{-5}$. Both models have similarly high Receiver Operating Characteristic Area Under the Curve (ROC-AUC) near $0.99$ when evaluated on held-out data. Using only first principles—namely, the definitions of True Positive Rate ($\\mathrm{TPR}$), False Positive Rate ($\\mathrm{FPR}$), precision (positive predictive value; $\\mathrm{PPV}$), recall (sensitivity), and Bayes’ theorem for conditional probabilities—derive how class imbalance (i.e., small $\\pi$) governs precision as a function of $\\mathrm{TPR}$, $\\mathrm{FPR}$, and $\\pi$. Then, use your derivation to compute the expected precision at $(\\mathrm{TPR}=0.95,\\ \\mathrm{FPR}=10^{-3},\\ \\pi=10^{-4})$ and at $(\\mathrm{TPR}=0.85,\\ \\mathrm{FPR}=10^{-5},\\ \\pi=10^{-4})$. Finally, based on your derivation and computations, identify all correct statements about why Precision-Recall Area Under the Curve (PR-AUC) is preferable to ROC-AUC for comparing splice site predictors under extreme imbalance.\n\nSelect ALL that apply.\n\nA. With $\\pi = 10^{-4}$, the expected precision at $(\\mathrm{TPR}=0.95,\\ \\mathrm{FPR}=10^{-3})$ is approximately $0.087$, whereas at $(\\mathrm{TPR}=0.85,\\ \\mathrm{FPR}=10^{-5})$ it is approximately $0.895$; therefore, under extreme imbalance, reducing $\\mathrm{FPR}$ has a dominant effect on precision.\n\nB. ROC-AUC is invariant to $\\pi$ and can rate both models similarly even when one yields many more false positives in absolute terms; PR-AUC has a chance baseline equal to $\\pi$ and thus better contextualizes performance when $\\pi \\ll 1$.\n\nC. When $\\pi$ is extremely small, precision is well approximated by $\\mathrm{TPR}/\\mathrm{FPR}$ and therefore does not depend on $\\pi$.\n\nD. The baseline PR-AUC of a non-informative classifier equals $1/2$, just like ROC-AUC, so PR-AUC offers no advantage for imbalanced data.\n\nE. In genome-wide splice site scanning, clinically useful thresholds often require $\\mathrm{FPR}$ in $[0, 10^{-5}]$; two models with similar ROC-AUC can have markedly different PR-AUC if one concentrates gains in this ultra–low $\\mathrm{FPR}$ regime, making PR-AUC more discriminative for model selection.",
            "solution": "The problem statement is evaluated to be valid. It is scientifically grounded in the principles of machine learning model evaluation and biostatistics, specifically within the context of genomic diagnostics. The problem is well-posed, providing all necessary data ($\\pi$, $\\mathrm{TPR}$, $\\mathrm{FPR}$) for the required derivations and calculations. The language used is objective and precise. Therefore, a full solution will be derived.\n\nThe core of the problem is to relate precision, or positive predictive value ($\\mathrm{PPV}$), to the true positive rate ($\\mathrm{TPR}$), false positive rate ($\\mathrm{FPR}$), and the class prevalence ($\\pi$).\n\nLet $D$ be the event that a candidate locus is a true donor site (the positive class), and let $N$ be the event that it is not (the negative class). Let $+$ denote a positive prediction from a model. We are given the following definitions and values:\n-   Prevalence: $\\pi = P(D) = 10^{-4}$. Consequently, $P(N) = 1 - \\pi = 1 - 10^{-4} = 0.9999$.\n-   True Positive Rate (Recall, Sensitivity): $\\mathrm{TPR} = P(+|D)$.\n-   False Positive Rate: $\\mathrm{FPR} = P(+|N)$.\n-   Precision (Positive Predictive Value): $\\mathrm{PPV} = P(D|+)$.\n\nUsing Bayes' theorem for conditional probabilities, we can express the precision as:\n$$ \\mathrm{PPV} = P(D|+) = \\frac{P(+|D) P(D)}{P(+)} $$\nThe denominator, $P(+)$, is the overall probability of a positive prediction, which can be found using the law of total probability:\n$$ P(+) = P(+|D)P(D) + P(+|N)P(N) $$\nSubstituting the standard terminology and given variables:\n$$ P(+) = (\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi) $$\nSubstituting this back into the expression for $\\mathrm{PPV}$, we derive the governing relationship:\n$$ \\mathrm{PPV} = \\frac{(\\mathrm{TPR})(\\pi)}{(\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi)} $$\nThis formula demonstrates how precision is governed by $\\mathrm{TPR}$, $\\mathrm{FPR}$, and the prevalence $\\pi$.\n\nNext, we compute the expected precision for the two models at their respective operating thresholds.\n\nFor model $M_1$ at threshold $\\tau_1$:\n$\\mathrm{TPR}_1 = 0.95$, $\\mathrm{FPR}_1 = 10^{-3}$, and $\\pi = 10^{-4}$.\n$$ \\mathrm{PPV}_1 = \\frac{(0.95)(10^{-4})}{(0.95)(10^{-4}) + (10^{-3})(1 - 10^{-4})} $$\n$$ \\mathrm{PPV}_1 = \\frac{9.5 \\times 10^{-5}}{9.5 \\times 10^{-5} + (10^{-3})(0.9999)} $$\n$$ \\mathrm{PPV}_1 = \\frac{9.5 \\times 10^{-5}}{9.5 \\times 10^{-5} + 9.999 \\times 10^{-4}} = \\frac{9.5 \\times 10^{-5}}{0.95 \\times 10^{-4} + 9.999 \\times 10^{-4}} = \\frac{0.95}{0.95 + 9.999} = \\frac{0.95}{10.949} \\approx 0.08676... $$\nSo, the precision for $M_1$ is approximately $0.087$.\n\nFor model $M_2$ at threshold $\\tau_2$:\n$\\mathrm{TPR}_2 = 0.85$, $\\mathrm{FPR}_2 = 10^{-5}$, and $\\pi = 10^{-4}$.\n$$ \\mathrm{PPV}_2 = \\frac{(0.85)(10^{-4})}{(0.85)(10^{-4}) + (10^{-5})(1 - 10^{-4})} $$\n$$ \\mathrm{PPV}_2 = \\frac{8.5 \\times 10^{-5}}{8.5 \\times 10^{-5} + (10^{-5})(0.9999)} $$\n$$ \\mathrm{PPV}_2 = \\frac{8.5 \\times 10^{-5}}{8.5 \\times 10^{-5} + 0.9999 \\times 10^{-5}} = \\frac{8.5}{8.5 + 0.9999} = \\frac{8.5}{9.4999} \\approx 0.8947... $$\nSo, the precision for $M_2$ is approximately $0.895$.\n\nNow, we evaluate each statement.\n\nA. With $\\pi = 10^{-4}$, the expected precision at $(\\mathrm{TPR}=0.95,\\ \\mathrm{FPR}=10^{-3})$ is approximately $0.087$, whereas at $(\\mathrm{TPR}=0.85,\\ \\mathrm{FPR}=10^{-5})$ it is approximately $0.895$; therefore, under extreme imbalance, reducing $\\mathrm{FPR}$ has a dominant effect on precision.\nOur calculations confirm the precision values of $\\approx 0.087$ for $M_1$ and $\\approx 0.895$ for $M_2$. Model $M_2$ achieves a vastly superior precision (by a factor of more than $10$) compared to $M_1$. This dramatic improvement is achieved despite a modest decrease in $\\mathrm{TPR}$ (from $0.95$ to $0.85$) because its $\\mathrm{FPR}$ is $100$ times lower (from $10^{-3}$ to $10^{-5}$). This demonstrates that, under extreme imbalance where $\\pi$ is very small, the $\\mathrm{FPR}$ term in the denominator of the precision formula, $(\\mathrm{FPR})(1-\\pi)$, can dominate the $(\\mathrm{TPR})(\\pi)$ term. To achieve high precision, $\\mathrm{FPR}$ must be reduced to a level comparable to or smaller than $\\mathrm{TPR} \\cdot \\pi$. Thus, the conclusion that reducing $\\mathrm{FPR}$ has a dominant effect is strongly supported by the calculation.\nVerdict: **Correct**.\n\nB. ROC-AUC is invariant to $\\pi$ and can rate both models similarly even when one yields many more false positives in absolute terms; PR-AUC has a chance baseline equal to $\\pi$ and thus better contextualizes performance when $\\pi \\ll 1$.\nThe $ROC$ curve plots $\\mathrm{TPR} = P(+|D)$ against $\\mathrm{FPR} = P(+|N)$. Neither of these quantities depends on the class prevalence $\\pi = P(D)$. Thus, the $ROC$ curve and its area (ROC-AUC) are invariant to class imbalance. The problem states both models have high ROC-AUC near $0.99$, rating them similarly. The ratio of absolute numbers of false positives to true positives is $\\frac{N_{FP}}{N_{TP}} = \\frac{P(+|N)P(N)}{P(+|D)P(D)} = \\frac{\\mathrm{FPR}}{\\mathrm{TPR}}\\frac{1-\\pi}{\\pi}$. Given $\\pi=10^{-4}$, this ratio is $\\approx \\frac{\\mathrm{FPR}}{\\mathrm{TPR}} \\times 10^4$. For $M_1$, this is $\\approx \\frac{10^{-3}}{0.95} \\times 10^4 \\approx 10.5$. For $M_2$, this is $\\approx \\frac{10^{-5}}{0.85} \\times 10^4 \\approx 0.12$. So $M_1$ produces far more false positives per true positive. A random classifier has a constant expected precision equal to the prevalence $\\pi$. The corresponding Precision-Recall curve is a horizontal line at precision $=\\pi$, so the baseline PR-AUC is $\\pi$. When $\\pi=10^{-4}$, the baseline is extremely low. PR-AUC measures performance relative to this low baseline, making it much more sensitive to differences in precision, which is the key challenge in imbalanced problems. All parts of this statement are correct.\nVerdict: **Correct**.\n\nC. When $\\pi$ is extremely small, precision is well approximated by $\\mathrm{TPR}/\\mathrm{FPR}$ and therefore does not depend on $\\pi$.\nThe derived formula is $\\mathrm{PPV} = \\frac{(\\mathrm{TPR})(\\pi)}{(\\mathrm{TPR})(\\pi) + (\\mathrm{FPR})(1-\\pi)}$. When $\\pi \\ll 1$, this can be approximated as $\\mathrm{PPV} \\approx \\frac{\\mathrm{TPR} \\cdot \\pi}{\\mathrm{TPR} \\cdot \\pi + \\mathrm{FPR}}$. For this to be further approximated by $\\mathrm{TPR}/\\mathrm{FPR}$, it would require $\\pi \\cdot (\\mathrm{TPR} \\cdot \\pi + \\mathrm{FPR}) \\approx (\\mathrm{TPR})^2$, which is nonsensical. A more common approximation, valid when false positives vastly outnumber true positives (i.e., $\\mathrm{FPR} \\gg \\mathrm{TPR} \\cdot \\pi$, as for $M_1$), is $\\mathrm{PPV} \\approx \\frac{\\mathrm{TPR} \\cdot \\pi}{\\mathrm{FPR}} = \\pi \\left(\\frac{\\mathrm{TPR}}{\\mathrm{FPR}}\\right)$. This approximation explicitly shows that precision is proportional to $\\pi$. A small prevalence $\\pi$ directly suppresses precision, contradicting the claim that precision does not depend on $\\pi$. Using our computed values, for $M_1$, $\\mathrm{TPR}/\\mathrm{FPR} = 950$ while $\\mathrm{PPV}_1 \\approx 0.087$. These are not approximately equal. The statement is fundamentally incorrect.\nVerdict: **Incorrect**.\n\nD. The baseline PR-AUC of a non-informative classifier equals $1/2$, just like ROC-AUC, so PR-AUC offers no advantage for imbalanced data.\nThe baseline ROC-AUC for a non-informative classifier (which performs at random) is indeed $1/2$, corresponding to the area under the diagonal line $\\mathrm{TPR}=\\mathrm{FPR}$. However, as established in the analysis of option B, the baseline for a Precision-Recall curve is the prevalence of the positive class, $\\pi$. A non-informative classifier achieves an average precision of $\\pi$ across all recall levels, yielding a PR-AUC of $\\pi$. The statement that the baseline PR-AUC is $1/2$ is false. The fact that its baseline is $\\pi$ is precisely why PR-AUC is advantageous for imbalanced data, as it correctly frames the performance in the context of a low prior probability of the positive class.\nVerdict: **Incorrect**.\n\nE. In genome-wide splice site scanning, clinically useful thresholds often require $\\mathrm{FPR}$ in $[0, 10^{-5}]$; two models with similar ROC-AUC can have markedly different PR-AUC if one concentrates gains in this ultra–low $\\mathrm{FPR}$ regime, making PR-AUC more discriminative for model selection.\nThe premise is sound: in a genome-wide scan with billions of loci, only a very low $\\mathrm{FPR}$ is tolerable to avoid a deluge of false positives. As shown by our calculations for $M_1$ and $M_2$, performance in the ultra-low $\\mathrm{FPR}$ regime has a dramatic impact on precision ($\\mathrm{PPV}$). The $PR$ curve directly plots $\\mathrm{PPV}$ against recall ($\\mathrm{TPR}$). A model like $M_2$ that achieves useful $\\mathrm{TPR}$ at a much smaller $\\mathrm{FPR}$ than $M_1$ will have a substantially higher $PR$ curve. The ROC-AUC integrates over the entire $[0, 1]$ range of $\\mathrm{FPR}$, and performance in the high-FPR region (e.g., $\\mathrm{FPR} > 0.01$) can contribute significantly to the area, obscuring critical differences at the clinically relevant low-FPR end. Because the $PR$ curve is sensitive to performance in this critical low-FPR, high-precision region, the resulting PR-AUC will be a much more discriminative metric for comparing models like $M_1$ and $M_2$, even if their ROC-AUCs are nearly identical.\nVerdict: **Correct**.",
            "answer": "$$\\boxed{ABE}$$"
        }
    ]
}