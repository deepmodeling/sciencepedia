{
    "hands_on_practices": [
        {
            "introduction": "Many widely-used prediction tools, such as SIFT, are built upon the principle of evolutionary conservation, which posits that functionally important amino acid positions are less likely to tolerate change over evolutionary time. This practice demonstrates not only how to apply a prediction rule based on a conservation score but, more importantly, how to critically assess the confidence of that prediction based on the depth of the underlying sequence alignment . Understanding the relationship between evidence quantity and prediction certainty is a fundamental skill for the responsible interpretation of computational predictions.",
            "id": "4371763",
            "problem": "A conservation-based predictor such as Sorting Intolerant From Tolerant (SIFT) classifies missense substitutions using a threshold on the estimated probability that a substitution is tolerated given a Multiple Sequence Alignment (MSA). Let the standard SIFT decision threshold be $\\tau = 0.05$, with substitutions predicted as functionally damaging (deleterious) when the tolerated probability estimate $\\hat{p} \\le \\tau$, and as tolerated (benign) when $\\hat{p} > \\tau$. Consider a particular missense substitution for which a simplified alignment-derived tolerated probability is $\\hat{p} = 0.02$. Let $n_{\\mathrm{eff}}$ denote the effective number of independent informative sequences contributing at this position in the MSA (for example, adjusted for redundancy and phylogenetic relatedness). Assume a binomial-proportion model in which the sampling variability of $\\hat{p}$ around the true tolerated probability $p$ is approximately $\\mathrm{Var}(\\hat{p}) \\approx p(1-p)/n_{\\mathrm{eff}}$, and for purposes of uncertainty assessment you may use the normal approximation to construct an approximate $95\\%$ confidence interval for $p$ as $\\hat{p} \\pm 1.96 \\sqrt{\\hat{p}(1-\\hat{p})/n_{\\mathrm{eff}}}$.\n\nWhich option best states the SIFT classification for this substitution and correctly characterizes the uncertainty as a function of alignment depth?\n\nA. The substitution is predicted deleterious because $\\hat{p} = 0.02 \\le \\tau = 0.05$. Moreover, under the normal approximation, the upper $95\\%$ confidence bound for $p$ falls below $\\tau$ only if $n_{\\mathrm{eff}} \\gtrsim 84$; for smaller $n_{\\mathrm{eff}}$ the confidence interval overlaps $\\tau$, so the deleterious call should be flagged as low confidence.\n\nB. The substitution is predicted tolerated because $\\hat{p} = 0.02$ is smaller than $\\tau = 0.05$, and lower alignment depth reduces false negatives, increasing confidence in tolerance.\n\nC. The substitution is predicted deleterious; uncertainty is minimized at low $n_{\\mathrm{eff}}$ because fewer sequences reduce sampling noise, so confidence increases as $n_{\\mathrm{eff}}$ decreases.\n\nD. The result is inconclusive regardless of $n_{\\mathrm{eff}}$ because SIFT scores below $\\tau$ cannot be trusted without a functional assay; alignment depth does not inform uncertainty in any principled way.",
            "solution": "The problem asks for the classification of a missense substitution according to the Sorting Intolerant From Tolerant (SIFT) algorithm and for a characterization of the uncertainty in this classification as a function of alignment depth.\n\n**Step 1: Problem Validation**\n\nFirst, I will validate the problem statement.\nThe givens are:\n-   A conservation-based predictor, Sorting Intolerant From Tolerant (SIFT).\n-   The SIFT decision threshold is $\\tau = 0.05$.\n-   A substitution is predicted as functionally damaging (deleterious) if the estimated tolerated probability $\\hat{p} \\le \\tau$.\n-   A substitution is predicted as tolerated (benign) if $\\hat{p} > \\tau$.\n-   For the specific substitution, the estimated tolerated probability is $\\hat{p} = 0.02$.\n-   The effective number of independent sequences is $n_{\\mathrm{eff}}$.\n-   The sampling variability of $\\hat{p}$ is modeled by the variance $\\mathrm{Var}(\\hat{p}) \\approx p(1-p)/n_{\\mathrm{eff}}$, where $p$ is the true tolerated probability.\n-   An approximate $95\\%$ confidence interval for $p$ is given by the normal approximation: $\\hat{p} \\pm 1.96 \\sqrt{\\hat{p}(1-\\hat{p})/n_{\\mathrm{eff}}}$.\n\nThe problem is scientifically grounded, describing the actual logic of the SIFT predictor and using standard statistical methods (binomial proportion variance, normal approximation for a confidence interval) to assess uncertainty. The problem is well-posed, providing all necessary definitions, values, and formulas to arrive at a unique conclusion. The terminology is precise and objective. There are no logical contradictions, factual errors, or ambiguities in the problem statement. Therefore, the problem is valid.\n\n**Step 2: Derivation of the Solution**\n\nFirst, I will determine the SIFT classification for the given substitution.\nThe prediction rule states that a substitution is deleterious if $\\hat{p} \\le \\tau$.\nWe are given $\\hat{p} = 0.02$ and $\\tau = 0.05$.\nSince $0.02 \\le 0.05$, the substitution is classified as **deleterious**.\n\nNext, I will characterize the uncertainty of this classification. The uncertainty is related to the width of the confidence interval for the true probability $p$. A wider interval implies higher uncertainty. The confidence in the deleterious call is high if the entire $95\\%$ confidence interval for $p$ is below the threshold $\\tau$. Since $\\hat{p} < \\tau$, this is equivalent to the condition that the upper bound of the confidence interval is less than or equal to $\\tau$.\n\nThe upper $95\\%$ confidence bound for $p$ is given by:\n$$p_{\\text{upper}} = \\hat{p} + 1.96 \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n_{\\mathrm{eff}}}}$$\n\nFor the deleterious call to be considered high-confidence (at the $95\\%$ level), we require $p_{\\text{upper}} \\le \\tau$. Let's determine the condition on $n_{\\mathrm{eff}}$ for this to hold.\nSubstituting the given values $\\hat{p} = 0.02$ and $\\tau = 0.05$:\n$$0.02 + 1.96 \\sqrt{\\frac{0.02(1-0.02)}{n_{\\mathrm{eff}}}} \\le 0.05$$\n\nNow, I will solve this inequality for $n_{\\mathrm{eff}}$:\n$$1.96 \\sqrt{\\frac{0.02(0.98)}{n_{\\mathrm{eff}}}} \\le 0.05 - 0.02$$\n$$1.96 \\sqrt{\\frac{0.0196}{n_{\\mathrm{eff}}}} \\le 0.03$$\n$$\\sqrt{\\frac{0.0196}{n_{\\mathrm{eff}}}} \\le \\frac{0.03}{1.96}$$\n\nSquaring both sides of the inequality:\n$$\\frac{0.0196}{n_{\\mathrm{eff}}} \\le \\left(\\frac{0.03}{1.96}\\right)^2$$\n\nTo solve for $n_{\\mathrm{eff}}$, we can invert the inequality (which reverses the inequality sign):\n$$\\frac{n_{\\mathrm{eff}}}{0.0196} \\ge \\left(\\frac{1.96}{0.03}\\right)^2$$\n$$n_{\\mathrm{eff}} \\ge 0.0196 \\times \\left(\\frac{1.96}{0.03}\\right)^2$$\n\nNow, I will calculate the numerical value:\n$$n_{\\mathrm{eff}} \\ge 0.0196 \\times (65.333...)^2$$\n$$n_{\\mathrm{eff}} \\ge 0.0196 \\times 4268.444...$$\n$$n_{\\mathrm{eff}} \\ge 83.6615...$$\n\nThis means that for the upper $95\\%$ confidence bound to be at or below the threshold of $0.05$, the effective number of sequences $n_{\\mathrm{eff}}$ must be at least approximately $84$. If $n_{\\mathrm{eff}}$ is smaller than this value, the confidence interval for $p$ will contain the threshold $\\tau = 0.05$, indicating that we cannot be $95\\%$ confident that the true probability $p$ is less than $0.05$. In such a case, the deleterious prediction would be flagged as having low confidence.\n\nThe analysis shows that larger alignment depth ($n_{\\mathrm{eff}}$) leads to a narrower confidence interval, which reduces uncertainty and increases confidence in the prediction, provided the point estimate is not too close to the threshold.\n\n**Step 3: Option-by-Option Analysis**\n\nA. The substitution is predicted deleterious because $\\hat{p} = 0.02 \\le \\tau = 0.05$. Moreover, under the normal approximation, the upper $95\\%$ confidence bound for $p$ falls below $\\tau$ only if $n_{\\mathrm{eff}} \\gtrsim 84$; for smaller $n_{\\mathrm{eff}}$ the confidence interval overlaps $\\tau$, so the deleterious call should be flagged as low confidence.\n- The classification as deleterious is correct, as $0.02 \\le 0.05$.\n- The calculation that $n_{\\mathrm{eff}}$ must be approximately $84$ or greater for the upper confidence bound to be below $\\tau$ is correct, based on my derivation ($n_{\\mathrm{eff}} \\ge 83.66...$).\n- The interpretation that for smaller $n_{\\mathrm{eff}}$ the CI overlaps the threshold and the call is low confidence is also correct. This directly follows from the properties of confidence intervals.\n- Verdict: **Correct**.\n\nB. The substitution is predicted tolerated because $\\hat{p} = 0.02$ is smaller than $\\tau = 0.05$, and lower alignment depth reduces false negatives, increasing confidence in tolerance.\n- The classification as \"tolerated\" is incorrect. According to the rule $\\hat{p} \\le \\tau$, the prediction is \"deleterious\".\n- The statement that lower alignment depth increases confidence is incorrect. Lower alignment depth (smaller $n_{\\mathrm{eff}}$) increases the variance of the estimate, widens the confidence interval, and therefore *decreases* confidence.\n- Verdict: **Incorrect**.\n\nC. The substitution is predicted deleterious; uncertainty is minimized at low $n_{\\mathrm{eff}}$ because fewer sequences reduce sampling noise, so confidence increases as $n_{\\mathrm{eff}}$ decreases.\n- The classification as deleterious is correct.\n- The statement that uncertainty is minimized at low $n_{\\mathrm{eff}}$ is fundamentally incorrect. From the formula for the variance, $\\mathrm{Var}(\\hat{p}) \\approx p(1-p)/n_{\\mathrm{eff}}$, it is clear that variance (a measure of uncertainty) is inversely proportional to $n_{\\mathrm{eff}}$. Thus, uncertainty increases as $n_{\\mathrm{eff}}$ decreases. The claim that fewer sequences reduce sampling noise is the opposite of a basic statistical principle.\n- Verdict: **Incorrect**.\n\nD. The result is inconclusive regardless of $n_{\\mathrm{eff}}$ because SIFT scores below $\\tau$ cannot be trusted without a functional assay; alignment depth does not inform uncertainty in any principled way.\n- The claim that the result is inconclusive is contrary to the problem statement, which provides a deterministic rule for classification based on the threshold $\\tau$.\n- The claim that alignment depth ($n_{\\mathrm{eff}}$) does not inform uncertainty in a principled way is false. The problem explicitly provides a statistical model where the confidence interval width, and thus uncertainty, is a direct inverse function of $\\sqrt{n_{\\mathrm{eff}}}$. This is a standard and principled way to model uncertainty.\n- Verdict: **Incorrect**.\n\nBased on the detailed analysis, only option A is fully consistent with the problem statement and correct principles of statistics.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Beyond sequence conservation, a variant's impact can be predicted by its effect on the protein's three-dimensional structure. This practice explores how changes to a key structural property—the Relative Solvent Accessibility (RSA) of an amino acid residue—can serve as a powerful predictive feature. You will first calculate the change in RSA resulting from a mutation and then use this value within a Bayesian classification model to compute the probability of the variant being deleterious . This exercise provides hands-on experience linking a biophysical structural change to a probabilistic measure of functional impact.",
            "id": "4371740",
            "problem": "A single amino acid substitution in a structurally characterized protein replaces an arginine residue with valine. Solvent-Accessible Surface Area (SASA) is the surface area of a residue that can be touched by a solvent probe, typically approximated by a sphere of radius $1.4\\,\\mathrm{\\AA}$. Relative Solvent Accessibility (RSA) is defined as the SASA of a residue divided by a reference maximum SASA for that amino acid type under a standardized normalization. Consider the widely used Rost–Sander normalization of maximum SASA values for amino acids. Let the maximum SASA for arginine be $A^{\\max}_{\\mathrm{Arg}} = 265\\,\\mathrm{\\AA}^{2}$ and for valine be $A^{\\max}_{\\mathrm{Val}} = 155\\,\\mathrm{\\AA}^{2}$.\n\nA structural analysis (with side-chain modeling for the mutant) provides the following SASA measurements at the mutated position:\n- Wild-type arginine SASA: $A_{\\mathrm{wt}} = 82\\,\\mathrm{\\AA}^{2}$.\n- Mutant valine SASA: $A_{\\mathrm{mut}} = 15\\,\\mathrm{\\AA}^{2}$.\n\nUnder a gene- and context-specific predictive framework for functional impact in precision medicine, suppose the change in relative solvent accessibility, $\\Delta \\mathrm{RSA}$, defined as $\\mathrm{RSA}_{\\mathrm{mut}} - \\mathrm{RSA}_{\\mathrm{wt}}$, is used as a single-feature classifier for deleterious impact. Assume a prior probability of deleterious impact of $p_{0} = 0.20$. Conditional on the class, model $\\Delta \\mathrm{RSA}$ as Gaussian with parameters:\n- Deleterious class: mean $\\mu_{D} = -0.20$, standard deviation $\\sigma_{D} = 0.08$.\n- Neutral class: mean $\\mu_{N} = 0.00$, standard deviation $\\sigma_{N} = 0.10$.\n\nStarting from the definitions of SASA and RSA, and using Bayes’ theorem with normally distributed likelihoods, compute the posterior probability that the variant is deleterious given the observed $\\Delta \\mathrm{RSA}$. Express your final answer as a decimal and round your answer to four significant figures. No percent sign is permitted in the final answer.",
            "solution": "The problem statement has been validated and is determined to be sound, well-posed, and scientifically grounded. It presents a standard problem in computational biology and genomic diagnostics involving the application of Bayesian statistical inference. All necessary data, definitions, and model parameters are provided.\n\nThe objective is to compute the posterior probability that the given missense variant is deleterious, conditioned on the observed change in Relative Solvent Accessibility ($\\Delta \\mathrm{RSA}$). Let $D$ be the event that the variant is deleterious and $N$ be the event that it is neutral. We are asked to find $P(D | \\Delta \\mathrm{RSA}_{\\mathrm{obs}})$.\n\nFirst, we must calculate the observed feature value, $\\Delta \\mathrm{RSA}_{\\mathrm{obs}}$. The Relative Solvent Accessibility ($\\mathrm{RSA}$) for a residue is defined as its Solvent-Accessible Surface Area ($\\mathrm{SASA}$) divided by a reference maximum $\\mathrm{SASA}$ for that amino acid type.\n\nThe givens for this calculation are:\n- Wild-type (Arginine) SASA: $A_{\\mathrm{wt}} = 82\\,\\mathrm{\\AA}^{2}$.\n- Maximum SASA for Arginine: $A^{\\max}_{\\mathrm{Arg}} = 265\\,\\mathrm{\\AA}^{2}$.\n- Mutant (Valine) SASA: $A_{\\mathrm{mut}} = 15\\,\\mathrm{\\AA}^{2}$.\n- Maximum SASA for Valine: $A^{\\max}_{\\mathrm{Val}} = 155\\,\\mathrm{\\AA}^{2}$.\n\nThe RSA for the wild-type residue is:\n$$\n\\mathrm{RSA}_{\\mathrm{wt}} = \\frac{A_{\\mathrm{wt}}}{A^{\\max}_{\\mathrm{Arg}}} = \\frac{82}{265}\n$$\nThe RSA for the mutant residue is:\n$$\n\\mathrm{RSA}_{\\mathrm{mut}} = \\frac{A_{\\mathrm{mut}}}{A^{\\max}_{\\mathrm{Val}}} = \\frac{15}{155} = \\frac{3}{31}\n$$\nThe change in RSA, which is our observed feature value $x$, is:\n$$\nx = \\Delta \\mathrm{RSA}_{\\mathrm{obs}} = \\mathrm{RSA}_{\\mathrm{mut}} - \\mathrm{RSA}_{\\mathrm{wt}} = \\frac{3}{31} - \\frac{82}{265}\n$$\nNumerically, this is:\n$$\nx \\approx 0.096774 - 0.309434 \\approx -0.21266\n$$\nWe will use this numerical value in subsequent calculations.\n\nNext, we apply Bayes' theorem to find the posterior probability $P(D|x)$:\n$$\nP(D|x) = \\frac{p(x|D) P(D)}{p(x|D) P(D) + p(x|N) P(N)}\n$$\nThe components of this formula are:\n- Prior probabilities: $P(D) = p_0 = 0.20$ and $P(N) = 1 - P(D) = 0.80$.\n- Conditional probabilities (likelihoods), which are modeled as Gaussian distributions. The probability density function (PDF) for a Gaussian distribution with mean $\\mu$ and standard deviation $\\sigma$ is $$p(x; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n\nThe likelihood for the deleterious class ($D$) is given by a Gaussian with $\\mu_D = -0.20$ and $\\sigma_D = 0.08$:\n$$\np(x|D) = \\frac{1}{\\sigma_D \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu_D)^2}{2\\sigma_D^2}\\right)\n$$\nThe likelihood for the neutral class ($N$) is given by a Gaussian with $\\mu_N = 0.00$ and $\\sigma_N = 0.10$:\n$$\np(x|N) = \\frac{1}{\\sigma_N \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu_N)^2}{2\\sigma_N^2}\\right)\n$$\nWe can substitute these into the Bayes' formula. The term $\\frac{1}{\\sqrt{2\\pi}}$ appears in both the numerator and the denominator and thus cancels out.\n$$\nP(D|x) = \\frac{\\frac{P(D)}{\\sigma_D} \\exp\\left(-\\frac{(x - \\mu_D)^2}{2\\sigma_D^2}\\right)}{\\frac{P(D)}{\\sigma_D} \\exp\\left(-\\frac{(x - \\mu_D)^2}{2\\sigma_D^2}\\right) + \\frac{P(N)}{\\sigma_N} \\exp\\left(-\\frac{(x - \\mu_N)^2}{2\\sigma_N^2}\\right)}\n$$\nLet's calculate the exponential arguments for our observed value $x \\approx -0.21266$:\nFor the deleterious class:\n$$\n\\frac{(x - \\mu_D)^2}{2\\sigma_D^2} = \\frac{(-0.21266 - (-0.20))^2}{2(0.08)^2} = \\frac{(-0.01266)^2}{0.0128} \\approx \\frac{0.0001602756}{0.0128} \\approx 0.01252\n$$\nFor the neutral class:\n$$\n\\frac{(x - \\mu_N)^2}{2\\sigma_N^2} = \\frac{(-0.21266 - 0.00)^2}{2(0.10)^2} = \\frac{0.0452243}{0.02} \\approx 2.2612\n$$\nNow we compute the terms in the numerator and denominator of the posterior probability expression. Let $U_D = \\frac{P(D)}{\\sigma_D}\\exp(-0.01252)$ and $U_N = \\frac{P(N)}{\\sigma_N}\\exp(-2.2612)$.\n$$\nU_D = \\frac{0.20}{0.08} \\exp(-0.01252) = 2.5 \\times \\exp(-0.01252) \\approx 2.5 \\times 0.98756 \\approx 2.4689\n$$\n$$\nU_N = \\frac{0.80}{0.10} \\exp(-2.2612) = 8.0 \\times \\exp(-2.2612) \\approx 8.0 \\times 0.10423 \\approx 0.83384\n$$\nThe posterior probability is then:\n$$\nP(D|x) = \\frac{U_D}{U_D + U_N} \\approx \\frac{2.4689}{2.4689 + 0.83384} = \\frac{2.4689}{3.30274} \\approx 0.74753\n$$\nRounding the final answer to four significant figures gives $0.7475$.",
            "answer": "$$\\boxed{0.7475}$$"
        },
        {
            "introduction": "In clinical genetics, a definitive conclusion about a variant's pathogenicity rarely relies on a single piece of information. The final and most crucial step is the synthesis of all available data. This practice simulates the evidence integration framework recommended by the American College of Medical Genetics and Genomics (ACMG), demonstrating how to quantitatively combine a prior probability with multiple independent lines of evidence—such as conservation scores, functional data, and population frequency—using a Bayesian framework to derive a final posterior probability of pathogenicity . This exercise encapsulates the logic at the heart of modern variant classification.",
            "id": "4371766",
            "problem": "A missense variant in a clinically actionable gene is being evaluated for pathogenicity in a precision medicine setting following the American College of Medical Genetics and Genomics (ACMG) framework. Let the hypothesis $H$ denote that the variant is pathogenic and $\\bar{H}$ denote that the variant is not pathogenic. A curated gene- and phenotype-informed prior analysis yields a prior odds of pathogenicity $O_{\\text{prior}}=\\frac{P(H)}{P(\\bar{H})}$ equal to $O_{\\text{prior}}=\\frac{1}{49}$. Three independent evidence sources are available: evolutionary conservation across vertebrates (conservation), a quantitative in vitro functional assay, and high-resolution population allele frequency data. These sources are calibrated to yield likelihood ratios, defined as $LR=\\frac{P(\\text{evidence}\\mid H)}{P(\\text{evidence}\\mid \\bar{H})}$, with values $LR_{1}=6.5$ (conservation), $LR_{2}=80$ (functional assay), and $LR_{3}=0.2$ (population data). Assume conditional independence of these evidence sources given $H$ and given $\\bar{H}$, and that the prior odds $O_{\\text{prior}}$ are appropriately specified for the gene–phenotype context without double-counting any of the three evidence sources.\n\nUsing Bayes theorem and the likelihood ratio framework as the fundamental base, infer the posterior probability of pathogenicity $P(H\\mid \\text{data})$ implied by these inputs. Express the final posterior probability as a decimal, and round your answer to four significant figures. No units are required.",
            "solution": "The problem requires the calculation of the posterior probability of pathogenicity, denoted as $P(H\\mid \\text{data})$, for a missense variant. This is achieved by integrating a prior probability with three independent sources of evidence using the Bayesian framework, specifically its formulation in terms of odds and likelihood ratios.\n\nLet $H$ be the hypothesis that the variant is pathogenic, and $\\bar{H}$ be the hypothesis that it is not. The prior odds of pathogenicity are given as:\n$$O_{\\text{prior}} = \\frac{P(H)}{P(\\bar{H})} = \\frac{1}{49}$$\n\nAccording to Bayes' theorem, when new evidence (data) is introduced, the prior odds are updated to posterior odds, $O_{\\text{post}}$, by multiplication with a likelihood ratio, $LR$:\n$$O_{\\text{post}} = \\frac{P(H \\mid \\text{data})}{P(\\bar{H} \\mid \\text{data})} = O_{\\text{prior}} \\times LR$$\nThe likelihood ratio is defined as the probability of observing the evidence given the hypothesis is true, divided by the probability of observing the evidence given the hypothesis is false:\n$$LR = \\frac{P(\\text{data} \\mid H)}{P(\\text{data} \\mid \\bar{H})}$$\n\nIn this problem, we have three distinct sources of evidence: conservation, functional assay, and population data. A critical piece of information is that these evidence sources are conditionally independent given both $H$ and $\\bar{H}$. This assumption allows us to calculate a combined likelihood ratio, $LR_{\\text{total}}$, by taking the product of the individual likelihood ratios, $LR_{1}$, $LR_{2}$, and $LR_{3}$:\n$$LR_{\\text{total}} = LR_{1} \\times LR_{2} \\times LR_{3}$$\n\nThe specific values for the likelihood ratios are provided:\n$LR_{1} = 6.5$ (conservation)\n$LR_{2} = 80$ (functional assay)\n$LR_{3} = 0.2$ (population data)\n\nWe can now compute the total likelihood ratio:\n$$LR_{\\text{total}} = 6.5 \\times 80 \\times 0.2$$\n$$LR_{\\text{total}} = 520 \\times 0.2$$\n$$LR_{\\text{total}} = 104$$\n\nWith the total likelihood ratio determined, we can calculate the posterior odds of pathogenicity:\n$$O_{\\text{post}} = O_{\\text{prior}} \\times LR_{\\text{total}}$$\n$$O_{\\text{post}} = \\frac{1}{49} \\times 104 = \\frac{104}{49}$$\n\nThe final step is to convert the posterior odds into a posterior probability. The relationship between a probability $P$ and its corresponding odds $O$ is given by the formula $$P = \\frac{O}{1+O}$$ Applying this to our posterior odds, we find the posterior probability of pathogenicity, $P(H\\mid \\text{data})$:\n$$P(H\\mid \\text{data}) = \\frac{O_{\\text{post}}}{1 + O_{\\text{post}}}$$\nSubstituting the value of $O_{\\text{post}}$:\n$$P(H\\mid \\text{data}) = \\frac{\\frac{104}{49}}{1 + \\frac{104}{49}}$$\nTo simplify this complex fraction, we find a common denominator in the denominator:\n$$P(H\\mid \\text{data}) = \\frac{\\frac{104}{49}}{\\frac{49}{49} + \\frac{104}{49}} = \\frac{\\frac{104}{49}}{\\frac{49 + 104}{49}} = \\frac{104}{153}$$\nThe problem requires the answer as a decimal rounded to four significant figures. We perform the division:\n$$P(H\\mid \\text{data}) = 0.67973856...$$\nRounding to four significant figures, we get:\n$$P(H\\mid \\text{data}) \\approx 0.6797$$",
            "answer": "$$\\boxed{0.6797}$$"
        }
    ]
}