{
    "hands_on_practices": [
        {
            "introduction": "在研究可移动遗传元件之前，我们首先需要能从海量的基因组数据中准确地识别它们。这项实践将引导你构建一个计算流程，这是现代基因组学研究的基石。通过整合多种类型的测序证据并应用严谨的统计模型，你将学习如何发现可移动元件的插入，为后续任何基因组分析提供一项基础而重要的技能 ()。",
            "id": "4361003",
            "problem": "您的任务是形式化并实现一个基于特定原则的移动元件插入（MEI）变异检测流程，该流程使用源自短读长全基因组测序数据的特征。该流程整合了软剪切读段、不一致读段对、局部组装重叠群以及靶位点重复（TSD）检测。您的程序必须实现一个统计上一致的模型来计算 MEI 存在的后验概率，并通过 Benjamini–Hochberg 程序控制伪发现率（FDR）。\n\n基本依据与假设：\n- 核心概率建模假设：在候选位点存在 MEI 的假设（记为 $H_1$）下，证据特征会富集；在不存在 MEI 的假设（记为 $H_0$）下，证据特征源于背景噪声。\n- 读段的生成遵循以局部覆盖度为条件的泊松过程。支持性软剪切读段计数 $S$、不一致读段对计数 $D$ 和支持性局部组装重叠群计数 $A$ 被建模为以局部测序深度 $c$ 为条件的独立泊松随机变量。\n- 靶位点重复（TSD）检测由一个二元指示符 $T \\in \\{0,1\\}$ 和一个 TSD 长度 $L \\in \\{0,1,2,\\dots,L_{\\max}\\}$ 表示，其中 $L=0$ 意味着未检测到 TSD。事件 $T=1$ 在 $H_1$ 假设下比在 $H_0$ 假设下更可能发生，并且合理的 TSD 长度集中在一个对于逆转录转座介导的插入而言生物学上合理的范围内。\n\n核心定义与参数：\n- 设 $S, D, A$ 为代表计数的非负整数。\n- 设 $c$ 为局部覆盖度（一个正实数）。\n- 在 $H_1$ 假设下，泊松均值为 $\\lambda^{(1)}_S = c \\, p_S$，$\\lambda^{(1)}_D = c \\, p_D$ 和 $\\lambda^{(1)}_A = c \\, p_A$。\n- 在 $H_0$ 假设下，泊松均值为 $\\lambda^{(0)}_S = c \\, e_S$，$\\lambda^{(0)}_D = c \\, e_D$ 和 $\\lambda^{(0)}_A = c \\, e_A$。\n- TSD 模型参数如下：\n  - 在 $H_1$ 假设下：$\\Pr(T=1) = q_1$，$\\Pr(T=0) = 1 - q_1$。在 $T=1$ 的条件下，TSD 长度 $L$ 以 $(1-\\epsilon)$ 的概率质量均匀分布在合理集合 $\\{l_{\\min}, l_{\\min}+1, \\dots, l_{\\max}\\}$ 上，并以 $\\epsilon$ 的概率质量均匀分布在非合理集合 $\\{1,\\dots,L_{\\max}\\} \\setminus \\{l_{\\min},\\dots,l_{\\max}\\}$ 上。\n  - 在 $H_0$ 假设下：$\\Pr(T=1) = q_0$，$\\Pr(T=0) = 1 - q_0$。在 $T=1$ 的条件下，TSD 长度 $L$ 均匀分布在 $\\{1,2,\\dots,L_{\\max}\\}$ 上。\n- 独立性假设：在给定假设的条件下，$S, D, A, (T,L)$ 是独立的。\n- 候选位点存在 MEI 的先验概率为 $\\pi$，因此先验优势比为 $\\pi / (1-\\pi)$。\n- 对于均值为 $\\lambda^{(1)}$ 和 $\\lambda^{(0)}$ 的泊松分布，观测计数 $x$ 的对数似然比为\n  $$\\mathrm{LLR}_{\\mathrm{Pois}}(x;\\lambda^{(1)},\\lambda^{(0)}) = x \\log\\left(\\frac{\\lambda^{(1)}}{\\lambda^{(0)}}\\right) - \\left(\\lambda^{(1)} - \\lambda^{(0)}\\right).$$\n- TSD 似然比定义如下。设 $P = l_{\\max}-l_{\\min}+1$ 为合理集合的大小， $U = L_{\\max} - P$ 为其补集的大小。\n  - 若 $T=1$ 且 $L \\in \\{l_{\\min},\\dots,l_{\\max}\\}$，则\n    $$\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{q_1 \\cdot \\frac{1-\\epsilon}{P}}{q_0 \\cdot \\frac{1}{L_{\\max}}}.$$\n  - 若 $T=1$ 且 $L \\notin \\{l_{\\min},\\dots,l_{\\max}\\}$ (其中 $L \\in \\{1,\\dots,L_{\\max}\\}$)，则\n    $$\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{q_1 \\cdot \\frac{\\epsilon}{U}}{q_0 \\cdot \\frac{1}{L_{\\max}}}.$$\n  - 若 $T=0$，则\n    $$\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{1-q_1}{1-q_0}.$$\n- 总对数似然比为\n  $$\\mathrm{LLR}_{\\mathrm{total}} = \\sum_{X \\in \\{S,D,A\\}} \\mathrm{LLR}_{\\mathrm{Pois}}(X;\\lambda^{(1)}_X,\\lambda^{(0)}_X) + \\log\\left(\\mathrm{LR}_{\\mathrm{TSD}}\\right).$$\n- 后验优势比和后验概率为\n  $$\\text{odds}_{\\text{post}} = \\frac{\\pi}{1-\\pi} \\cdot \\exp\\left(\\mathrm{LLR}_{\\mathrm{total}}\\right), \\quad \\Pr(H_1 \\mid \\text{data}) = \\frac{\\text{odds}_{\\text{post}}}{1 + \\text{odds}_{\\text{post}}}.$$\n\n伪发现率控制：\n- 对于每个候选位点，使用独立的单边 $p$ 值计算在 $H_0$ 下的组合显著性：\n  - 对于 $H_0$ 下的泊松计数（均值为 $\\lambda^{(0)}_X$），使用生存函数 $p_X = \\Pr\\{X' \\ge X \\mid X' \\sim \\mathrm{Pois}(\\lambda^{(0)}_X)\\}$，其中 $X \\in \\{S,D,A\\}$。\n  - 对于 TSD，定义一个单边 $p$ 值，当检测到合理的 TSD 时该值很小，否则该值很大：\n    $$p_{\\mathrm{TSD}} = \\begin{cases}\n    q_0 \\cdot \\frac{P}{L_{\\max}},  \\text{if } T=1 \\text{ and } L \\in \\{l_{\\min},\\dots,l_{\\max}\\},\\\\\n    1 - q_0 \\cdot \\frac{P}{L_{\\max}},  \\text{otherwise.}\n    \\end{cases}$$\n- 使用 Fisher 方法组合四个 $p$ 值。对于 $m = 4$ 个检验，\n  $$\\chi^2 = -2 \\sum_{i=1}^{m} \\log(p_i), \\quad p_{\\mathrm{combined}} = 1 - F_{\\chi^2_{2m}}(\\chi^2),$$\n  其中 $F_{\\chi^2_{2m}}$ 是自由度为 $2m$ 的卡方分布的累积分布函数。\n- 对所有候选位点，使用组合 $p$ 值集合 $p_{\\mathrm{combined}}$，在目标 FDR 水平 $\\alpha$ 下应用 Benjamini–Hochberg 程序。设 $m_{\\mathrm{cand}}$ 为候选位点数，$p_{(1)} \\le \\dots \\le p_{(m_{\\mathrm{cand}})}$ 为其顺序统计量。找到满足以下条件的最大 $k$\n  $$p_{(k)} \\le \\frac{k}{m_{\\mathrm{cand}}} \\alpha.$$\n  将 $p_{(i)} \\le \\frac{k}{m_{\\mathrm{cand}}} \\alpha$ 的候选位点声明为发现。\n\n本问题的数值常量：\n- 使用 $p_S = 0.2$, $p_D = 0.1$, $p_A = 0.05$。\n- 使用 $e_S = 0.01$, $e_D = 0.005$, $e_A = 0.0015$。\n- 使用 $q_1 = 0.7$, $q_0 = 0.02$, $\\epsilon = 10^{-3}$, $l_{\\min} = 6$, $l_{\\max} = 20$, $L_{\\max} = 30$。\n- 使用先验概率 $\\pi = 10^{-3}$。\n- 使用目标伪发现率水平 $\\alpha = 0.1$。\n- 所有对数均为自然对数。\n\n测试套件：\n每个测试用例是一个元组 $(c,S,D,A,T,L)$，其中 $c$ 的单位是覆盖倍数（无量纲），$S, D, A$ 为非负整数，$T \\in \\{0,1\\}$，$L \\in \\{0,1,\\dots,L_{\\max}\\}$ 且 $L=0$ 表示未检测到 TSD。\n- 用例 1：$(40, 10, 5, 3, 1, 12)$\n- 用例 2：$(30, 4, 2, 1, 1, 7)$\n- 用例 3：$(30, 0, 0, 0, 0, 0)$\n- 用例 4：$(50, 11, 6, 3, 0, 0)$\n- 用例 5：$(35, 2, 1, 0, 1, 25)$\n- 用例 6：$(60, 20, 1, 0, 1, 10)$\n- 用例 7：$(10, 2, 1, 1, 1, 18)$\n- 用例 8：$(20, 0, 1, 0, 1, 4)$\n\n要求的输出：\n- 对每个测试用例，计算后验概率 $\\Pr(H_1 \\mid \\text{data})$ 以及使用所有用例的组合 $p$ 值在 $\\alpha = 0.1$ 下的 Benjamini–Hochberg 发现决策。\n- 您的程序应生成单行输出，包含一个含有两个子列表的列表：\n  - 第一个子列表包含每个测试用例的后验概率，以小数形式四舍五入到六位小数。\n  - 第二个子列表包含每个测试用例的 Benjamini–Hochberg 决策，以整数形式表示，其中 $1$ 表示发现，$0$ 表示未发现。\n- 输出格式示例（非实际值）：`[[p1,p2,p3,p4,p5,p6,p7,p8],[d1,d2,d3,d4,d5,d6,d7,d8]]`。\n\n实现说明：\n- 确保所有概率都在闭区间 $[0,1]$ 内，并在计算 Fisher 统计量时，通过将 $p$ 值限制在一个小的正常数上来避免对数下溢（例如，在组合过程中将任何 $p_i$ 替换为 $\\max(p_i, 10^{-300})$）。\n- 本问题不涉及角度。本问题中没有物理单位。",
            "solution": "该问题要求实现一个用于从全基因组测序数据中检测移动元件插入（MEIs）的综合统计框架。该框架整合了两种主要方法：一种是用于计算候选位点存在 MEI 的后验概率的贝叶斯方法，另一种是使用多重检验校正程序来控制伪发现率（FDR）的频率派方法。解决方案分为这两个计算部分，然后将它们应用于提供的测试套件。\n\n所有数学符号严格遵守 LaTeX 标准。\n\n**第 1 部分：后验概率的贝叶斯推断**\n\n贝叶斯模型的核心是利用观测数据来更新关于 MEI 是否存在的先验信念。我们区分两种互斥的假设：$H_1$，即存在 MEI，和 $H_0$，即不存在 MEI。更新通过贝叶斯定理完成，以优势比（odds）的形式表示：\n\n$$\n\\text{后验优势比} = \\text{先验优势比} \\times \\text{似然比}\n$$\n\n先验优势比由在任何给定候选位点存在 MEI 的先验概率 $\\pi$ 决定：\n$$\n\\text{odds}_{\\text{prior}} = \\frac{\\Pr(H_1)}{\\Pr(H_0)} = \\frac{\\pi}{1-\\pi}\n$$\n\n似然比（$LR$）量化了数据所提供证据的强度，这些数据包括四个特征：软剪切读段计数（$S$）、不一致读段对计数（$D$）、支持性局部组装重叠群计数（$A$），以及由二元指示符（$T$）及其长度（$L$）表示的靶位点重复（TSD）信息。一个基本假设是，在给定假设（$H_1$ 或 $H_0$）的条件下，这些特征是条件独立的。这使得总似然比可以分解为各个似然比的乘积：\n\n$$\n\\mathrm{LR}_{\\mathrm{total}} = \\mathrm{LR}_S \\times \\mathrm{LR}_D \\times \\mathrm{LR}_A \\times \\mathrm{LR}_{\\mathrm{TSD}}\n$$\n\n为计算稳定性和方便起见，我们使用对数似然比（$\\mathrm{LLR}$）：\n$$\n\\mathrm{LLR}_{\\mathrm{total}} = \\mathrm{LLR}_S + \\mathrm{LLR}_D + \\mathrm{LLR}_A + \\log(\\mathrm{LR}_{\\mathrm{TSD}})\n$$\n\n读段计数（$S, D, A$）被建模为泊松分布变量。泊松分布的均值取决于局部覆盖度 $c$ 以及假设是 $H_1$（信号）还是 $H_0$（噪声）。对于一个通用计数特征 $X \\in \\{S,D,A\\}$，其均值在 $H_1$ 下为 $\\lambda^{(1)}_X = c \\cdot p_X$，在 $H_0$ 下为 $\\lambda^{(0)}_X = c \\cdot e_X$。对于一个观测到的计数 $x$，其对数似然比由下式给出：\n$$\n\\mathrm{LLR}_{\\mathrm{Pois}}(x; \\lambda^{(1)}, \\lambda^{(0)}) = \\log\\left(\\frac{\\mathrm{Pois}(x|\\lambda^{(1)})}{\\mathrm{Pois}(x|\\lambda^{(0)})}\\right) = x \\log\\left(\\frac{\\lambda^{(1)}}{\\lambda^{(0)}}\\right) - (\\lambda^{(1)} - \\lambda^{(0)})\n$$\n\nTSD 似然比 $\\mathrm{LR}_{\\mathrm{TSD}}$ 取决于 TSD 数据 $(T, L)$。设 $P = l_{\\max}-l_{\\min}+1$ 为合理 TSD 长度的数量， $U = L_{\\max} - P$ 为非合理（但非零）长度的数量。似然比是分段定义的：\n- 如果观测到合理的 TSD（$T=1$ 且 $L \\in \\{l_{\\min}, ..., l_{\\max}\\}$）：\n$$\n\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{\\Pr(\\text{data}|H_1)}{\\Pr(\\text{data}|H_0)} = \\frac{q_1 \\cdot \\frac{1-\\epsilon}{P}}{q_0 \\cdot \\frac{1}{L_{\\max}}}\n$$\n- 如果观测到非合理的 TSD（$T=1$ 且 $L \\notin \\{l_{\\min}, ..., l_{\\max}\\}$）：\n$$\n\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{q_1 \\cdot \\frac{\\epsilon}{U}}{q_0 \\cdot \\frac{1}{L_{\\max}}}\n$$\n- 如果未观测到 TSD（$T=0$）：\n$$\n\\mathrm{LR}_{\\mathrm{TSD}} = \\frac{1-q_1}{1-q_0}\n$$\n\n然后使用总对数似然比计算后验优势比：\n$$\n\\text{odds}_{\\text{post}} = \\text{odds}_{\\text{prior}} \\cdot \\exp(\\mathrm{LLR}_{\\mathrm{total}})\n$$\n\n最后，从后验优势比导出 MEI 的后验概率 $\\Pr(H_1 | \\text{data})$：\n$$\n\\Pr(H_1 | \\text{data}) = \\frac{\\text{odds}_{\\text{post}}}{1 + \\text{odds}_{\\text{post}}}\n$$\n\n**第 2 部分：伪发现率控制**\n\n为了提供一个频率派的显著性度量，我们在零假设 $H_0$ 下为每个候选位点计算一个 $p$ 值。由于我们有四个独立的证据来源，我们首先为每个证据来源计算一个 $p$ 值，然后将它们组合起来。\n\n泊松计数 $X \\in \\{S,D,A\\}$ 的 $p$ 值使用生存函数（单边检验）计算，因为高计数值预示着 MEI 的存在：\n$$\np_X = \\Pr\\{X' \\ge X \\mid X' \\sim \\mathrm{Pois}(\\lambda^{(0)}_X)\\}\n$$\n其中 $\\lambda^{(0)}_X = c \\cdot e_X$ 是在 $H_0$ 下的均值。\n\nTSD 证据的 $p$ 值 $p_{\\mathrm{TSD}}$ 被定义为在 $H_1$ 下更可能出现的结果具有较小的 $p$ 值。最“显著”的结果是检测到一个具有合理长度的 TSD。在 $H_0$ 下此事件的概率为 $q_0 \\cdot \\frac{P}{L_{\\max}}$。这导致了如下定义：\n$$\np_{\\mathrm{TSD}} = \\begin{cases}\nq_0 \\cdot \\frac{P}{L_{\\max}},  \\text{if } T=1 \\text{ and } L \\in \\{l_{\\min},\\dots,l_{\\max}\\}\\\\\n1 - q_0 \\cdot \\frac{P}{L_{\\max}},  \\text{otherwise}\n\\end{cases}\n$$\n\n四个独立的 $p$ 值（$p_S, p_D, p_A, p_{\\mathrm{TSD}}$）使用 Fisher 方法进行组合。检验统计量 $\\chi^2$ 服从自由度为 $2m$ 的卡方分布，其中 $m=4$ 是检验的数量。\n$$\n\\chi^2 = -2 \\sum_{i=1}^{m} \\log(p_i)\n$$\n组合 $p$ 值 $p_{\\mathrm{combined}}$ 是该统计量的生存函数：\n$$\np_{\\mathrm{combined}} = \\Pr\\{\\chi'^2_{2m} \\ge \\chi^2\\} = 1 - F_{\\chi^2_{2m}}(\\chi^2)\n$$\n其中 $F_{\\chi^2_{2m}}$ 是自由度为 $2m=8$ 的卡方分布的累积分布函数（CDF）。为了数值稳定性，在取对数之前，任何 $p_i=0$ 的值都被限制为一个小的正常数（例如 $10^{-300}$）。\n\n对于每个候选位点，我们得到一个组合 $p$ 值，从而形成一个包含 $m_{\\mathrm{cand}}$ 个 $p$ 值的集合。然后应用 Benjamini–Hochberg (BH) 程序，以在指定水平 $\\alpha$ 下控制 FDR。该程序如下：\n1.  将 $m_{\\mathrm{cand}}$ 个组合 $p$ 值排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m_{\\mathrm{cand}})}$。\n2.  找到最大的秩 $k$，使其对应的有序 $p$ 值满足：\n    $$\n    p_{(k)} \\le \\frac{k}{m_{\\mathrm{cand}}} \\alpha\n    $$\n3.  如果存在这样的 $k$，则所有对应于 $p$ 值 $p_{(1)}, \\dots, p_{(k)}$ 的候选位点都被声明为“发现”（即，拒绝零假设 $H_0$）。否则，不做出任何发现。\n\n这种双重方法既为单个位点提供了信念度量（后验概率），又为所有检测到的 MEI 集合提供了集体错误控制保证（FDR）。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import poisson, chi2\n\ndef solve():\n    \"\"\"\n    Implements a variant-calling pipeline for Mobile Element Insertions (MEIs)\n    by computing posterior probabilities and controlling the False Discovery Rate.\n    \"\"\"\n\n    # --- Numerical constants from the problem statement ---\n    # Signal probabilities under H1\n    P_S = 0.2\n    P_D = 0.1\n    P_A = 0.05\n    # Noise rates under H0\n    E_S = 0.01\n    E_D = 0.005\n    E_A = 0.0015\n    # TSD model parameters\n    Q1 = 0.7\n    Q0 = 0.02\n    EPSILON = 1e-3\n    L_MIN = 6\n    L_MAX = 20\n    L_MAX_TOTAL = 30\n    # Prior and FDR\n    PRIOR_PI = 1e-3\n    ALPHA = 0.1\n    # Numerical stability\n    P_CLAMP = 1e-300\n\n    # --- Test suite ---\n    test_cases = [\n        # (c, S, D, A, T, L)\n        (40, 10, 5, 3, 1, 12),\n        (30, 4, 2, 1, 1, 7),\n        (30, 0, 0, 0, 0, 0),\n        (50, 11, 6, 3, 0, 0),\n        (35, 2, 1, 0, 1, 25),\n        (60, 20, 1, 0, 1, 10),\n        (10, 2, 1, 1, 1, 18),\n        (20, 0, 1, 0, 1, 4),\n    ]\n\n    # Lists to store results for all candidates\n    posterior_probabilities = []\n    combined_p_values = []\n\n    # --- Pre-calculated constants for TSD model ---\n    P_plausible_count = L_MAX - L_MIN + 1\n    U_unplausible_count = L_MAX_TOTAL - P_plausible_count\n    \n    # Calculate values for each candidate locus\n    for c, S, D, A, T, L in test_cases:\n        \n        # === Part 1: Posterior Probability Calculation ===\n        \n        # Poisson Log-Likelihood Ratios (LLRs)\n        def calc_poisson_llr(x, c_local, p_signal, e_noise):\n            lambda1 = c_local * p_signal\n            lambda0 = c_local * e_noise\n            # Handle case where lambda0 is 0 to avoid division by zero\n            # In this problem, c > 0 and e_noise > 0, so lambda0 > 0\n            return x * np.log(lambda1 / lambda0) - (lambda1 - lambda0)\n\n        llr_S = calc_poisson_llr(S, c, P_S, E_S)\n        llr_D = calc_poisson_llr(D, c, P_D, E_D)\n        llr_A = calc_poisson_llr(A, c, P_A, E_A)\n\n        # TSD Log-Likelihood Ratio\n        if T == 1:\n            if L_MIN = L = L_MAX: # Plausible TSD\n                lr_tsd_num = Q1 * (1 - EPSILON) / P_plausible_count\n                lr_tsd_den = Q0 * (1 / L_MAX_TOTAL)\n            else: # Non-plausible TSD (L outside plausible range, but > 0)\n                # Handle U=0 case, though not possible with given parameters\n                if U_unplausible_count == 0:\n                    lr_tsd_num = 0\n                else:\n                    lr_tsd_num = Q1 * EPSILON / U_unplausible_count\n                lr_tsd_den = Q0 * (1 / L_MAX_TOTAL)\n        else: # T == 0 (No TSD)\n            lr_tsd_num = 1 - Q1\n            lr_tsd_den = 1 - Q0\n        \n        lr_tsd = lr_tsd_num / lr_tsd_den\n        llr_tsd = np.log(lr_tsd)\n\n        # Total LLR and posterior probability\n        llr_total = llr_S + llr_D + llr_A + llr_tsd\n        prior_odds = PRIOR_PI / (1 - PRIOR_PI)\n        posterior_odds = prior_odds * np.exp(llr_total)\n        posterior_prob = posterior_odds / (1 + posterior_odds)\n        posterior_probabilities.append(posterior_prob)\n\n        # === Part 2: Combined P-value Calculation for FDR Control ===\n        \n        # P-values for Poisson counts under H0\n        p_val_S = poisson.sf(S - 1, c * E_S)\n        p_val_D = poisson.sf(D - 1, c * E_D)\n        p_val_A = poisson.sf(A - 1, c * E_A)\n\n        # P-value for TSD under H0\n        p_tsd_signal_region_prob = Q0 * P_plausible_count / L_MAX_TOTAL\n        if T == 1 and L_MIN = L = L_MAX:\n            p_val_tsd = p_tsd_signal_region_prob\n        else:\n            p_val_tsd = 1.0 - p_tsd_signal_region_prob\n\n        # Combine p-values using Fisher's method\n        p_values = [p_val_S, p_val_D, p_val_A, p_val_tsd]\n        # Clamp p-values to avoid log(0)\n        p_values_clamped = [max(p, P_CLAMP) for p in p_values]\n        \n        chi_squared_stat = -2 * np.sum(np.log(p_values_clamped))\n        # Degrees of freedom is 2 * number of tests\n        df = 2 * len(p_values)\n        combined_p = chi2.sf(chi_squared_stat, df)\n        combined_p_values.append(combined_p)\n\n    # === Part 3: Benjamini-Hochberg Procedure ===\n    \n    m_cand = len(test_cases)\n    # Store tuples of (p_value, original_index) for sorting\n    indexed_p_values = sorted([(p, i) for i, p in enumerate(combined_p_values)])\n\n    # Find the largest k such that p_(k) = (k/m) * alpha\n    k_bh = 0\n    for i in range(m_cand, 0, -1):\n        p_i = indexed_p_values[i - 1][0]\n        bh_threshold = (i / m_cand) * ALPHA\n        if p_i = bh_threshold:\n            k_bh = i\n            break\n            \n    # Determine discoveries. Discoveries are those with rank 1 to k_bh.\n    discoveries = set()\n    if k_bh > 0:\n        for i in range(k_bh):\n            original_index = indexed_p_values[i][1]\n            discoveries.add(original_index)\n\n    # Prepare final output list\n    bh_decisions = [1 if i in discoveries else 0 for i in range(m_cand)]\n    \n    # Format and print the final result\n    rounded_probs = [round(p, 6) for p in posterior_probabilities]\n    final_output = [rounded_probs, bh_decisions]\n    print(str(final_output).replace(\" \", \"\"))\n\nsolve()\n```"
        },
        {
            "introduction": "可移动遗传元件是追踪人类演化历史和理解群体结构的有力标记。这项实践将视角从个体层面扩展到群体层面，要求你计算群体遗传学中的一个关键指标——固定指数 ($F_{ST}$)。通过分析同一个插入事件在不同人群中的频率差异，你将深入了解可移动元件如何塑造遗传多样性，并揭示其所反映的古老迁移模式 ()。",
            "id": "4360984",
            "problem": "一个 LINE-1（长散布核元件-1，L1）逆转录转座子插入事件，记为等位基因 $I$（表示插入存在）和等位基因 $A$（表示插入缺失），使用位点特异性检测进行基因分型，以区分纯合插入型 ($II$)、杂合型 ($IA$) 和纯合缺失型 ($AA$)。对代表不同群体的三个人类队列进行了抽样：群体 $1$（西非队列）、群体 $2$（欧洲队列）和群体 $3$（东南亚队列）。观察到的基因型计数如下：\n- 群体 $1$：$II = 18$，$IA = 36$，$AA = 66$，总数 $n_1 = 120$。\n- 群体 $2$：$II = 4$，$IA = 12$，$AA = 64$，总数 $n_2 = 80$。\n- 群体 $3$：$II = 35$，$IA = 40$，$AA = 25$，总数 $n_3 = 100$。\n\n假设群体内随机交配并处于哈迪-温伯格平衡（HWE）状态，基因分型准确无确认偏倚，且为便于聚合，抽样比例与群体大小成正比。从固定指数用于量化因群体亚结构导致的预期杂合度相对于合并后总群体的预期杂合度的比例损失这一定义出发，计算该双等位基因移动元件插入在这三个群体间的固定指数（$F_{ST}$），并对群体内数量使用样本量加权。将您的数值答案四舍五入至四位有效数字，并以小数形式表示。此外，请在精准医疗和基因组诊断的背景下，简要解释计算出的值对该插入事件的群体结构和可能的迁移历史有何启示。您的最终数值答案必须不带任何单位报告。",
            "solution": "该问题提问恰当且有科学依据，提供了计算固定指数（$F_{ST}$）所需的所有数据。计算过程通过确定群体内部和群体之间的预期杂合度来进行。\n\n设 LINE-1 插入的等位基因为 $I$，其缺失的等位基因为 $A$。三个群体的基因型计数如下：\n- 群体 $1$：$N_{II,1}=18$，$N_{IA,1}=36$，$N_{AA,1}=66$，总样本量 $n_1=120$。\n- 群体 $2$：$N_{II,2}=4$，$N_{IA,2}=12$，$N_{AA,2}=64$，总样本量 $n_2=80$。\n- 群体 $3$：$N_{II,3}=35$，$N_{IA,3}=40$，$N_{AA,3}=25$，总样本量 $n_3=100$。\n\n固定指数 $F_{ST}$ 定义为由群体结构引起的亚群体中杂合度相对于总群体的比例减少。它使用以下公式计算：\n$$ F_{ST} = \\frac{H_T - H_S}{H_T} $$\n其中 $H_S$ 是每个亚群体内部预期杂合度的加权平均值，而 $H_T$ 是合并后总群体的预期杂合度。\n\n首先，我们计算每个亚群体 $i$ 中插入等位基因 $p$（对于等位基因 $I$）的等位基因频率。频率 $p_i$ 由下式给出：\n$$ p_i = \\frac{2 \\times N_{II,i} + N_{IA,i}}{2 \\times n_i} $$\n缺失等位基因 $q_i$（对于等位基因 $A$）的频率为 $1 - p_i$。\n\n对于群体 $1$：\n$$ p_1 = \\frac{2 \\times 18 + 36}{2 \\times 120} = \\frac{72}{240} = 0.3 $$\n$$ q_1 = 1 - 0.3 = 0.7 $$\n\n对于群体 $2$：\n$$ p_2 = \\frac{2 \\times 4 + 12}{2 \\times 80} = \\frac{20}{160} = 0.125 $$\n$$ q_2 = 1 - 0.125 = 0.875 $$\n\n对于群体 $3$：\n$$ p_3 = \\frac{2 \\times 35 + 40}{2 \\times 100} = \\frac{110}{200} = 0.55 $$\n$$ q_3 = 1 - 0.55 = 0.45 $$\n\n接下来，我们计算 $H_S$，即跨亚群体的平均预期杂合度。在哈迪-温伯格平衡下，亚群体 $i$ 的预期杂合度为 $H_{e,i} = 2 p_i q_i$。$H_S$ 是这些值的加权平均值，使用样本量作为权重。\n$$ H_S = \\sum_{i=1}^{3} \\frac{n_i}{n_{total}} H_{e,i} $$\n其中 $n_{total} = n_1 + n_2 + n_3 = 120 + 80 + 100 = 300$。\n\n各个预期的杂合度为：\n$$ H_{e,1} = 2 \\times 0.3 \\times 0.7 = 0.42 $$\n$$ H_{e,2} = 2 \\times 0.125 \\times 0.875 = 0.21875 $$\n$$ H_{e,3} = 2 \\times 0.55 \\times 0.45 = 0.495 $$\n\n现在，我们计算加权平均值 $H_S$：\n$$ H_S = \\frac{120}{300}(0.42) + \\frac{80}{300}(0.21875) + \\frac{100}{300}(0.495) $$\n$$ H_S = \\frac{1}{300} (120 \\times 0.42 + 80 \\times 0.21875 + 100 \\times 0.495) $$\n$$ H_S = \\frac{1}{300} (50.4 + 17.5 + 49.5) = \\frac{117.4}{300} \\approx 0.39133 $$\n\n接下来，我们计算 $H_T$，即总群体的预期杂合度。这需要整个样本的平均等位基因频率 $\\bar{p}$ 和 $\\bar{q}$。\n$$ \\bar{p} = \\frac{\\sum_{i=1}^{3} (2 \\times N_{II,i} + N_{IA,i})}{2 \\times n_{total}} = \\frac{72 + 20 + 110}{2 \\times 300} = \\frac{202}{600} = \\frac{101}{300} $$\n$$ \\bar{q} = 1 - \\bar{p} = 1 - \\frac{101}{300} = \\frac{199}{300} $$\n\n那么总预期杂合度 $H_T$ 为：\n$$ H_T = 2 \\bar{p} \\bar{q} = 2 \\left(\\frac{101}{300}\\right) \\left(\\frac{199}{300}\\right) = \\frac{2 \\times 101 \\times 199}{90000} = \\frac{40198}{90000} \\approx 0.44664 $$\n\n最后，我们计算 $F_{ST}$：\n$$ F_{ST} = \\frac{H_T - H_S}{H_T} = \\frac{\\frac{40198}{90000} - \\frac{117.4}{300}}{ \\frac{40198}{90000} } $$\n为了减去分子中的项，我们可以使用分数：\n$H_S = \\frac{117.4}{300} = \\frac{1174}{3000} = \\frac{587}{1500}$。\n$H_T - H_S = \\frac{40198}{90000} - \\frac{587}{1500} = \\frac{40198}{90000} - \\frac{587 \\times 60}{1500 \\times 60} = \\frac{40198 - 35220}{90000} = \\frac{4978}{90000}$。\n等等，这里有一个计算错误。让我们使用更高精度的小数值重新计算 $H_T - H_S$。\n$H_S \\approx 0.3913333...$\n$H_T \\approx 0.4466222...$\n$H_T - H_S \\approx 0.4466222 - 0.3913333 = 0.0552889$。\n让我们使用分数重新计算，检查数学运算。$1500 \\times 60 = 90000$。所以缩放因子是正确的。\n$587 \\times 60 = 35220$。正确。\n$40198 - 35220 = 4978$。正确。\n所以 $H_T - H_S = \\frac{4978}{90000}$。\n那么 $F_{ST} = \\frac{4978/90000}{40198/90000} = \\frac{4978}{40198}$。让我们做除法：$4978 / 40198 \\approx 0.123837$。\n\n让我重新检查一下 $H_S$ 的加权平均值。\n$H_S = \\frac{120}{300}(0.42) + \\frac{80}{300}(0.21875) + \\frac{100}{300}(0.495)$\n$120 \\times 0.42 = 50.4$\n$80 \\times 0.21875 = 17.5$\n$100 \\times 0.495 = 49.5$\n总和 = $50.4 + 17.5 + 49.5 = 117.4$。\n$H_S = 117.4 / 300 = 0.391333...$。这是正确的。\n\n让我重新检查一下 $H_T$ 的计算。\n$\\bar{p} = 101/300$。正确。\n$\\bar{q} = 199/300$。正确。\n$H_T = 2 \\times (101/300) \\times (199/300) = (2 \\times 101 \\times 199) / 90000 = 40198/90000$。正确。\n\n让我使用 $F_{ST}$ 的另一个定义，即使用等位基因频率的方差：\n$F_{ST} = \\frac{\\text{Var}(p)}{\\bar{p}(1-\\bar{p})}$。方差需要按样本量加权。\n$\\text{Var}(p) = \\sum \\frac{n_i}{n_{total}} (p_i - \\bar{p})^2$\n$\\bar{p} = 101/300 \\approx 0.33667$\n$p_1 - \\bar{p} = 0.3 - 101/300 = 90/300 - 101/300 = -11/300$\n$p_2 - \\bar{p} = 0.125 - 101/300 = 37.5/300 - 101/300 = -63.5/300$\n$p_3 - \\bar{p} = 0.55 - 101/300 = 165/300 - 101/300 = 64/300$\n$\\text{Var}(p) = \\frac{120}{300} (\\frac{-11}{300})^2 + \\frac{80}{300} (\\frac{-63.5}{300})^2 + \\frac{100}{300} (\\frac{64}{300})^2$\n$\\text{Var}(p) = \\frac{1}{300 \\times 300^2} [120(-11)^2 + 80(-63.5)^2 + 100(64)^2]$\n$\\text{Var}(p) = \\frac{1}{27000000} [120(121) + 80(4032.25) + 100(4096)]$\n$\\text{Var}(p) = \\frac{1}{27000000} [14520 + 322580 + 409600] = \\frac{746700}{27000000} = \\frac{7467}{270000} \\approx 0.027655$\n分母是 $\\bar{p}\\bar{q} = H_T/2 = (40198/90000)/2 = 20099/90000 \\approx 0.223322$。\n$F_{ST} = 0.027655 / 0.223322 \\approx 0.123837$。\n结果匹配。最初的计算是正确的。\n\n$F_{ST} = \\frac{4978}{40198} \\approx 0.12383700...$\n四舍五入到四位有效数字，我们得到 $0.1238$。\n\n解释：\n计算出的固定指数 $F_{ST} \\approx 0.1238$，量化了这三个群体在该 LINE-1 位点上的遗传分化程度。这个量级的值通常被解释为中等程度的遗传分化。它意味着，在该位点观察到的总遗传变异中，约有 $12.4\\%$ 是由于西非、欧洲和东南亚队列之间的等位基因频率差异造成的，而其余的 $87.6\\%$ 则表现为这些单个群体内部的变异。\n\n这种水平的群体结构与已知的人类迁徙历史一致，在“走出非洲”扩张后，大陆群体间的基因流有限，使得等位基因频率因遗传漂变和潜在的不同选择压力而发生分化。插入等位基因的频率（$p_1=0.3$，$p_2=0.125$，$p_3=0.55$）差异显著，强调了这种分化。\n\n在精准医疗和基因组诊断的背景下，$F_{ST}$ 值为 $0.1238$ 是高度相关的。这表明，任何基于此 L1 插入的诊断测试、疾病风险评估或药物基因组学预测都不能在没有谨慎考虑的情况下推广到所有人群。例如，如果这个 L1 插入与药物不良反应相关，那么它的流行率和相关的临床风险在这些群体中将有很大差异。临床指南和基因组筛查策略将需要针对特定的祖源进行调整，以确保医疗保健结果的有效性和公平性。这一发现再次强调了在基因组研究中实现多样性的迫切需求，以便全面了解遗传变异如何影响所有人类群体的健康。",
            "answer": "$$ \\boxed{0.1238} $$"
        }
    ]
}