{
    "hands_on_practices": [
        {
            "introduction": "在表观遗传学研究中，区分5-甲基胞嘧啶（$5\\text{mC}$）和5-羟甲基胞嘧啶（$5\\text{hmC}$）等不同的胞嘧啶修饰形式至关重要，因为它们具有不同的生物学功能。标准的重亚硫酸盐测序（BS-seq）无法区分这两种修饰，但将其与氧化重亚硫酸盐测序（oxBS-seq）相结合，则可以实现对它们的精确定量。本练习  将指导您完成一个核心的定量生物信息学任务：如何通过统计建模，从这两项实验的原始测序读数中推导出 $5\\text{hmC}$ 的真实组分，并评估其估计的置信度。",
            "id": "4337409",
            "problem": "一个临床基因组学实验室应用亚硫酸氢盐测序 (BS) 和氧化亚硫酸氢盐测序 (oxBS) 来量化一个药物基因组学相关基因启动子中单个胞嘧啶-磷酸-鸟嘌呤 (CpG) 位点的胞嘧啶修饰。在 BS 中，5-甲基胞嘧啶和 5-羟甲基胞嘧啶受到保护并被读作胞嘧啶，而未修饰的胞嘧啶则被转化并读作胸腺嘧啶。在 oxBS 中，5-羟甲基胞嘧啶被选择性氧化并随后被转化，因此受保护的胞嘧啶检出仅报告 5-甲基胞嘧啶。设该位点上 5-甲基胞嘧啶的真实比例为 $\\theta_{m}$，5-羟甲基胞嘧啶的真实比例为 $\\theta_{h}$，未修饰胞嘧啶的真实比例为 $\\theta_{u}$，且满足 $\\theta_{m} + \\theta_{h} + \\theta_{u} = 1$。假设转化和氧化化学反应是理想的，且读数是独立的。\n\n在该 CpG 位点，实验室观察到以下读数计数：\n- BS：总读数为 $n_{\\mathrm{BS}} = 120$，其中 $x_{\\mathrm{BS}} = 90$ 个被记为胞嘧啶，$n_{\\mathrm{BS}} - x_{\\mathrm{BS}} = 30$ 个被记为胸腺嘧啶。\n- oxBS：总读数为 $n_{\\mathrm{ox}} = 100$，其中 $x_{\\mathrm{ox}} = 60$ 个被记为胞嘧啶，$n_{\\mathrm{ox}} - x_{\\mathrm{ox}} = 40$ 个被记为胸腺嘧啶。\n\n将每个实验的胞嘧啶检出计数建模为一个二项随机变量，其成功概率等于上述化学反应下相应的受保护比例。从这些定义和二项模型出发，推导该 CpG 位点上 5-羟甲基胞嘧啶比例 $\\theta_{h}$ 的最大似然估计，以及一个基于独立二项比例之差的大样本正态近似的双侧置信水平为 $0.95$ 的 $\\theta_{h}$ 置信区间。将您的最终数值结果表示为小数，将点估计和两个置信界限四舍五入至四位有效数字。在您的最终答案中，按顺序报告三个数：$\\hat{\\theta}_{h}$、下界、上界。",
            "solution": "该问题要求基于亚硫酸氢盐测序 (BS) 和氧化亚硫酸氢盐测序 (oxBS) 实验的数据，推导特定 CpG 位点上 5-羟甲基胞嘧啶比例 $\\theta_h$ 的最大似然估计 (MLE) 和一个置信水平为 $0.95$ 的置信区间。\n\n首先，我们按规定将每个实验的概率模型形式化。每个实验中检出胞嘧啶的次数被建模为二项随机变量。设 $p_{\\mathrm{BS}}$ 为在 BS 实验中观察到胞嘧啶的概率，$p_{\\mathrm{ox}}$ 为在 oxBS 实验中观察到胞嘧啶的概率。\n\n根据问题描述：\n在 BS 中，5-甲基胞嘧啶（比例为 $\\theta_m$）和 5-羟甲基胞嘧啶（比例为 $\\theta_h$）都受到保护不被转化，并被读作胞嘧啶。因此，检出胞嘧啶的概率是这些比例之和：\n$$p_{\\mathrm{BS}} = \\theta_{m} + \\theta_{h}$$\n在 oxBS 中，5-羟甲基胞嘧啶被氧化和转化，而只有 5-甲基胞嘧啶受到保护。因此，检出胞嘧啶的概率是：\n$$p_{\\mathrm{ox}} = \\theta_{m}$$\n未修饰胞嘧啶的比例 $\\theta_u$ 通过约束条件 $\\theta_{m} + \\theta_{h} + \\theta_{u} = 1$ 相关联。在 BS 中读到胸腺嘧啶的概率是 $1 - p_{\\mathrm{BS}} = \\theta_u$，在 oxBS 中是 $1 - p_{\\mathrm{ox}} = \\theta_h + \\theta_u$。\n\n设 $X_{\\mathrm{BS}}$ 和 $X_{\\mathrm{ox}}$ 分别为 BS 和 oxBS 实验中检出胞嘧啶次数的随机变量。模型如下：\n$$X_{\\mathrm{BS}} \\sim \\mathrm{Binomial}(n_{\\mathrm{BS}}, p_{\\mathrm{BS}})$$\n$$X_{\\mathrm{ox}} \\sim \\mathrm{Binomial}(n_{\\mathrm{ox}}, p_{\\mathrm{ox}})$$\n其中观测数据为 $n_{\\mathrm{BS}} = 120$，$x_{\\mathrm{BS}} = 90$，$n_{\\mathrm{ox}} = 100$ 和 $x_{\\mathrm{ox}} = 60$。\n\n对于二项分布 $\\mathrm{Binomial}(n, p)$，基于观测值 $x$ 的成功概率 $p$ 的最大似然估计由 $\\hat{p} = \\frac{x}{n}$ 给出。将此应用于我们的两个独立实验，我们得到 $p_{\\mathrm{BS}}$ 和 $p_{\\mathrm{ox}}$ 的最大似然估计：\n$$\\hat{p}_{\\mathrm{BS}} = \\frac{x_{\\mathrm{BS}}}{n_{\\mathrm{BS}}} = \\frac{90}{120} = 0.75$$\n$$\\hat{p}_{\\mathrm{ox}} = \\frac{x_{\\mathrm{ox}}}{n_{\\mathrm{ox}}} = \\frac{60}{100} = 0.60$$\n\n我们主要感兴趣的参数是 $\\theta_h$。我们可以将 $\\theta_h$ 表示为 $p_{\\mathrm{BS}}$ 和 $p_{\\mathrm{ox}}$ 的函数：\n$$\\theta_{h} = (\\theta_{m} + \\theta_{h}) - \\theta_{m} = p_{\\mathrm{BS}} - p_{\\mathrm{ox}}$$\n根据最大似然估计量的不变性，参数函数的最大似然估计是在这些参数的最大似然估计值处求得的相同函数。因此，$\\theta_h$ 的最大似然估计是：\n$$\\hat{\\theta}_{h} = \\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}$$\n代入数值：\n$$\\hat{\\theta}_{h} = 0.75 - 0.60 = 0.15$$\n\n接下来，我们为 $\\theta_h$ 构建一个双侧置信水平为 $0.95$ 的置信区间。问题指定使用大样本正态近似来处理两个独立二项比例之差。这种置信区间的一般形式是：\n$$\\text{点估计} \\pm (\\text{临界值}) \\times (\\text{标准误})$$\n点估计是 $\\hat{\\theta}_{h} = \\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}$。这个估计的标准误 $\\mathrm{SE}(\\hat{\\theta}_h)$ 是从两个独立样本比例之差的方差推导出来的。\n$$\\mathrm{Var}(\\hat{\\theta}_h) = \\mathrm{Var}(\\hat{p}_{\\mathrm{BS}} - \\hat{p}_{\\mathrm{ox}}) = \\mathrm{Var}(\\hat{p}_{\\mathrm{BS}}) + \\mathrm{Var}(\\hat{p}_{\\mathrm{ox}})$$\n样本比例 $\\hat{p}$ 的方差是 $\\frac{p(1-p)}{n}$。我们通过用样本比例 $\\hat{p}$ 替代真实比例 $p$ 来估计此方差。估计的标准误是：\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{\\hat{p}_{\\mathrm{BS}}(1-\\hat{p}_{\\mathrm{BS}})}{n_{\\mathrm{BS}}} + \\frac{\\hat{p}_{\\mathrm{ox}}(1-\\hat{p}_{\\mathrm{ox}})}{n_{\\mathrm{ox}}}}$$\n代入数值：\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{0.75(1-0.75)}{120} + \\frac{0.60(1-0.60)}{100}}$$\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{\\frac{0.75 \\times 0.25}{120} + \\frac{0.60 \\times 0.40}{100}} = \\sqrt{\\frac{0.1875}{120} + \\frac{0.24}{100}}$$\n$$\\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) = \\sqrt{0.0015625 + 0.0024} = \\sqrt{0.0039625} \\approx 0.062948$$\n\n对于置信水平为 $0.95$ 的置信区间，置信度为 $1-\\alpha = 0.95$，因此 $\\alpha = 0.05$。临界值是对应于上尾概率为 $\\alpha/2 = 0.025$ 的 z 分数，即 $z_{1-\\alpha/2} = z_{0.975}$。从标准正态分布中，这个值是 $z_{0.975} \\approx 1.96$。\n\n误差范围 (ME) 是：\n$$\\mathrm{ME} = z_{0.975} \\times \\widehat{\\mathrm{SE}}(\\hat{\\theta}_h) \\approx 1.96 \\times 0.062948 \\approx 0.123378$$\n$\\theta_h$ 的置信区间是 $\\hat{\\theta}_{h} \\pm \\mathrm{ME}$：\n$$0.15 \\pm 0.123378$$\n下界是：\n$$L = 0.15 - 0.123378 = 0.026622$$\n上界是：\n$$U = 0.15 + 0.123378 = 0.273378$$\n\n最后，我们按要求将点估计和置信界限四舍五入到四位有效数字。\n- 点估计： $\\hat{\\theta}_{h} = 0.15$。保留四位有效数字，即为 $0.1500$。\n- 下界：$0.026622...$ 四舍五入为 $0.02662$。\n- 上界：$0.273378...$ 四舍五入为 $0.2734$。\n\n5-羟甲基胞嘧啶比例的最大似然估计是 $\\hat{\\theta}_{h} \\approx 0.1500$，置信水平为 $0.95$ 的置信区间大约是 $(0.02662, 0.2734)$。\n其他比例的估计和区间也可以类似地推导出来：$\\hat{\\theta}_m = \\hat{p}_{\\mathrm{ox}} = 0.6000$ 以及 $\\hat{\\theta}_u = 1 - \\hat{p}_{\\mathrm{BS}} = 1 - 0.75 = 0.2500$。所有估计值都是非负的，与其作为比例的定义相符。",
            "answer": "$$\\boxed{\\begin{pmatrix} 0.1500  0.02662  0.2734 \\end{pmatrix}}$$"
        },
        {
            "introduction": "癌症表观遗传学的一个核心目标是识别那些因表观遗传机制而失调的关键基因，其中一个经典的模式是肿瘤抑制基因因其启动子区域的超甲基化而被转录沉默。要从全基因组数据中可靠地识别出这些基因，需要整合DNA甲基化和基因表达等多组学数据，并应用一系列严格的统计筛选标准。本练习  模拟了一个真实的生物信息学分析项目，指导您构建一个完整的数据分析流程，通过结合效应大小、统计显著性和多重检验校正等方法，从复杂的基因组数据中筛选出符合该模式的候选肿瘤抑制基因。",
            "id": "4337352",
            "problem": "给定代表成对的启动子DNA甲基化和基因表达谱的数组，这些数据针对多个基因，在肿瘤和正常组织队列中进行测量。这些数组按测试用例和基因进行分组。对于每个基因，都有肿瘤甲基化值、正常甲基化值、肿瘤表达值、正常表达值，以及一个指示是否存在抑制性组蛋白修饰（组蛋白H3赖氨酸27三甲基化，写作Histone H3K27me3）的二进制指标。\n\n推导的基本依据：\n- 表观遗传调控将启动子DNA甲基化与转录沉默联系起来。启动子高甲基化通常与转录产出减少相关，尤其是在具有肿瘤抑制作用的基因中。\n- 基因表达遵循分子生物学中心法则，其中信使核糖核酸（mRNA）的丰度反映了转录水平。\n- 甲基化值是有界的（bounded）分数测量值，通常表示为在无单位区间$[0,1]$内的β值。\n- 统计检验和多重假设校正使用成熟的频率派程序。\n\n使用的定义：\n- 如果一个基因的启动子甲基化在肿瘤中比在正常组织中高出具有实际意义的量，基因表达在肿瘤中比在正常组织中低了具有实际意义的量，并且在肿瘤样本中启动子甲基化与肿瘤基因表达之间存在负相关关系，则该基因被视为候选的甲基化沉默的肿瘤抑制基因。对甲基化分布使用非参数检验，对表达差异使用参数检验，并对每个测试用例进行多重假设校正。\n- 在每个测试用例中，对所有基因的甲基化和表达的$p$值，独立使用Benjamini–Hochberg假发现率（FDR）校正。\n\n决策阈值（在所有测试用例中一致应用）：\n- 甲基化效应量阈值：均值差异 $\\Delta \\beta \\geq 0.2$，其中 $\\Delta \\beta = \\overline{\\beta}_{\\text{tumor}} - \\overline{\\beta}_{\\text{normal}}$。β值必须被视为$[0,1]$内的小数，而不是百分比。\n- 甲基化显著性：双侧Mann–Whitney $U$检验$p$值，经FDR校正后的$q$值 $\\leq 0.05$。\n- 表达效应量阈值：以2为底的对数倍数变化 $\\log_{2}\\left(\\overline{E}_{\\text{tumor}} + \\epsilon\\right) - \\log_{2}\\left(\\overline{E}_{\\text{normal}} + \\epsilon\\right) \\leq -1.0$，其中 $\\epsilon = 10^{-3}$以避免除以零。\n- 表达显著性：双侧Welch’s $t$检验（不等方差）$p$值，经FDR校正后的$q$值 $\\leq 0.05$。\n- 相关性标准：Spearman等级相关系数 $\\rho \\leq -0.5$，且双侧相关性$p$值 $\\leq 0.05$。此项仅在肿瘤样本中计算，将每个肿瘤的启动子甲基化值与其肿瘤表达值配对。\n- 高置信度分类：满足上述所有标准并且存在Histone H3K27me3的基因为高置信度；否则，仅为标准置信度。\n\n算法要求：\n- 对于每个测试用例，计算每个基因的$\\Delta \\beta$、甲基化Mann–Whitney $U$检验$p$值、表达的以2为底的对数倍数变化、表达的Welch’s $t$检验$p$值、肿瘤甲基化与肿瘤表达之间的Spearman $\\rho$值以及相关的相关性$p$值。在该测试用例内，对甲基化和表达的$p$值独立应用Benjamini–Hochberg程序以获得$q$值。\n- 如果一个基因满足所有三个条件：肿瘤中甲基化上调（效应量和校正后显著性）、肿瘤中表达下调（效应量和校正后显著性）、以及肿瘤中的负相关性（效应量和显著性），则将其标记为标准置信度命中。如果Histone H3K27me3存在，则额外将其标记为高置信度命中。\n\n在你的程序中直接实现的输入（测试套件）：\n- 测试用例$1$包含$4$个基因，每个基因有$6$个肿瘤样本和$6$个正常样本。每个基因的数组（肿瘤甲基化、正常甲基化、肿瘤表达、正常表达）和组蛋白指标如下：\n  - 基因 $0$：肿瘤甲基化 $[0.80,0.82,0.83,0.85,0.86,0.88]$，正常甲基化 $[0.12,0.18,0.15,0.22,0.17,0.19]$，肿瘤表达 $[2.6,2.4,2.3,2.1,2.0,1.9]$，正常表达 $[6.0,6.5,5.8,6.2,6.4,6.1]$，组蛋白 $1$ (True)。\n  - 基因 $1$：肿瘤甲基化 $[0.60,0.62,0.61,0.59,0.58,0.62]$，正常甲基化 $[0.40,0.42,0.41,0.39,0.38,0.42]$，肿瘤表达 $[6.0,5.8,6.1,5.9,6.2,6.0]$，正常表达 $[5.5,5.7,5.4,5.6,5.5,5.6]$，组蛋白 $0$ (False)。\n  - 基因 $2$：肿瘤甲基化 $[0.74,0.75,0.76,0.77,0.78,0.79]$，正常甲基化 $[0.20,0.21,0.22,0.22,0.23,0.24]$，肿瘤表达 $[2.0,2.1,2.2,2.3,2.4,2.5]$，正常表达 $[6.0,6.1,6.2,6.3,6.1,6.2]$，组蛋白 $1$ (True)。\n  - 基因 $3$：肿瘤甲基化 $[0.70,0.72,0.74,0.75,0.71,0.73]$，正常甲基化 $[0.25,0.27,0.26,0.28,0.24,0.26]$，肿瘤表达 $[3.0,2.8,2.6,2.5,2.7,2.6]$，正常表达 $[5.5,5.2,5.1,5.3,5.4,5.2]$，组蛋白 $0$ (False)。\n- 测试用例$2$包含$3$个基因，每个基因有$6$个肿瘤样本和$6$个正常样本：\n  - 基因 $0$：肿瘤甲基化 $[0.60,0.61,0.62,0.59,0.58,0.60]$，正常甲基化 $[0.40,0.41,0.42,0.39,0.38,0.40]$，肿瘤表达 $[4.0,3.9,4.1,3.8,4.0,3.9]$，正常表达 $[4.2,4.1,4.2,4.3,4.1,4.2]$，组蛋白 $1$ (True)。\n  - 基因 $1$：肿瘤甲基化 $[0.85,0.83,0.84,0.86,0.87,0.85]$，正常甲基化 $[0.30,0.29,0.31,0.28,0.32,0.30]$，肿瘤表达 $[2.5,2.4,2.3,2.2,2.1,2.0]$，正常表达 $[5.0,5.1,5.2,5.1,5.0,5.2]$，组蛋白 $0$ (False)。\n  - 基因 $2$：肿瘤甲基化 $[0.77,0.78,0.79,0.80,0.81,0.82]$，正常甲基化 $[0.20,0.21,0.19,0.22,0.21,0.20]$，肿瘤表达 $[0.20,0.18,0.15,0.12,0.10,0.08]$，正常表达 $[3.0,3.2,3.1,3.3,3.2,3.1]$，组蛋白 $1$ (True)。\n- 测试用例$3$包含$3$个基因，每个基因有$3$个肿瘤样本和$3$个正常样本：\n  - 基因 $0$：肿瘤甲基化 $[0.70,0.72,0.74]$，正常甲基化 $[0.40,0.42,0.41]$，肿瘤表达 $[3.0,2.8,2.6]$，正常表达 $[5.0,5.2,5.1]$，组蛋白 $0$ (False)。\n  - 基因 $1$：肿瘤甲基化 $[0.68,0.70,0.69]$，正常甲基化 $[0.50,0.49,0.51]$，肿瘤表达 $[4.5,4.6,4.4]$，正常表达 $[4.6,4.5,4.4]$，组蛋白 $0$ (False)。\n  - 基因 $2$：肿瘤甲基化 $[0.85,0.87,0.86]$，正常甲基化 $[0.30,0.32,0.31]$，肿瘤表达 $[1.5,1.4,1.6]$，正常表达 $[5.0,4.8,4.9]$，组蛋白 $1$ (True)。\n\n程序要求：\n- 按照规定实现流程，计算每个测试用例中每个基因的标志，并为每个测试用例返回两个列表：第一个列表包含按升序排列的满足标准置信度标准的基因的整数索引；第二个列表包含按升序排列的满足高置信度标准的基因的整数索引。\n- 最终输出格式：您的程序应生成单行输出，包含一个逗号分隔的各测试用例结果列表，每个测试用例结果本身是一个包含两个整数列表的双元素列表，并且输出字符串中没有任何空格。例如，如果第一个测试用例产生标准置信度基因$[0,3]$和高置信度基因$[0]$，第二个测试用例产生标准置信度基因$[1]$和高置信度基因$[]$，则单行输出应为精确格式$[[[0,3],[0]],[[1],[]],...]$。\n\n注意：所有类似百分比的量必须表示为小数或分数，不得使用百分号。此问题中没有物理单位或角度。确保数值计算严格遵守所述的阈值和程序。",
            "solution": "该问题在科学和数学上是适定的，为从配对的甲基化和表达数据中识别候选的甲基化沉默基因提供了一套完整的数据、定义和程序要求。该问题是有效的。解决方案需要系统地实现一个多步骤的生物信息学流程，涉及统计检验、效应量计算和多重假设校正。其核心原理植根于分子生物学（基因表达的表观遗传调控）和生物统计学。\n\n解决方案的步骤如下：\n首先，对于每个测试用例，我们必须处理所有基因以收集必要的统计数据。对于每个基因，我们执行三种类型的分析：差异甲基化、差异表达和相关性。\n\n1.  **差异甲基化分析**：\n    -   效应量是肿瘤和正常样本之间平均甲基化水平的差异，$\\Delta \\beta = \\overline{\\beta}_{\\text{tumor}} - \\overline{\\beta}_{\\text{normal}}$。\n    -   统计显著性通过双侧Mann-Whitney $U$检验确定，这是一种非参数检验，适用于比较两个独立组，当数据可能不呈正态分布时。该检验为甲基化产生一个$p$值，$p_{\\text{meth}}$。\n\n2.  **差异表达分析**：\n    -   效应量是以2为底的对数倍数变化，计算公式为 $\\log_{2}\\left(\\overline{E}_{\\text{tumor}} + \\epsilon\\right) - \\log_{2}\\left(\\overline{E}_{\\text{normal}} + \\epsilon\\right)$。加入一个小数 $\\epsilon = 10^{-3}$是为了避免$\\log(0)$的问题。使用对数尺度是处理基因表达数据的标准做法，因为它有助于使偏态分布正常化，并对称地表示上调和下调。\n    -   统计显著性通过双侧Welch's $t$检验评估。这种参数检验适用于比较两个独立组的均值，并且不假定方差相等，使其比标准的Student's $t$检验更为稳健。该检验为表达产生一个$p$值，$p_{\\text{expr}}$。\n\n3.  **相关性分析**：\n    -   在肿瘤队列中，启动子甲基化和基因表达之间的关系使用Spearman等级相关系数 $\\rho$ 进行量化。这种非参数度量评估了两个变量之间单调关系的强度和方向。\n    -   计算一个$p$值，$p_{\\text{corr}}$，以检验观察到的相关性的显著性。\n\n在计算完单个测试用例中所有基因的这些统计数据后，我们必须对多重假设检验进行校正。这一点至关重要，因为执行大量统计检验会增加偶然观察到显著结果（I类错误）的概率。\n\n4.  **多重假设校正**：\n    -   应用Benjamini-Hochberg (BH) 程序来控制假发现率 (FDR)。FDR是被拒绝的原假设中实际上是假阳性的预期比例。\n    -   BH程序独立应用于测试用例中所有基因的$p_{\\text{meth}}$值集合和$p_{\\text{expr}}$值集合。这将原始的$p$值转换为经过FDR校正的$q$值，$q_{\\text{meth}}$和$q_{\\text{expr}}$。\n    -   从一组$m$个$p$值计算$q$值的程序如下：\n        i.  将$p$值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n        ii. 计算每个秩次$i$的BH校正$p$值，即$q_{(i)}^{\\text{raw}} = \\frac{p_{(i)} \\cdot m}{i}$。\n        iii. 为强制单调性，秩次$i$的最终$q$值为$q_{(i)} = \\min(q_{(i+1)}, q_{(i)}^{\\text{raw}})$，其中$i = m-1, \\dots, 1$，且$q_{(m)} = q_{(m)}^{\\text{raw}}$。更简单地说，$q_{(i)}$是从秩次$i$到$m$的原始校正$p$值的累积最小值。\n    -   恢复原始顺序，以便将每个基因与其正确的$q$值关联起来。请注意，在此问题的设计中，相关性$p$值$p_{\\text{corr}}$不进行多重检验校正，因为它是一个基因级别的过滤器。\n\n最后，我们应用决策阈值对每个基因进行分类。\n\n5.  **分类**：\n    -   如果一个基因满足以下所有标准，则被标记为**标准置信度**命中：\n        a. **甲基化高调控**：$\\Delta\\beta \\geq 0.2$ **且** $q_{\\text{meth}} \\leq 0.05$。\n        b. **表达下调控**：$\\log_2(\\text{Fold Change}) \\leq -1.0$ **且** $q_{\\text{expr}} \\leq 0.05$。\n        c. **负相关**：$\\rho \\leq -0.5$ **且** $p_{\\text{corr}} \\leq 0.05$。\n    -   如果一个基因是标准置信度命中 **且** 存在抑制性组蛋白标记H3K27me3（由二进制标志$1$指示），则被标记为**高置信度**命中。\n\n这整个流程独立地应用于每个测试用例。最终输出的结构是为每个测试用例呈现标准置信度和高置信度基因索引的列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef benjamini_hochberg(p_values):\n    \"\"\"\n    Performs the Benjamini-Hochberg FDR correction.\n\n    Args:\n        p_values (list or np.ndarray): A list of p-values.\n\n    Returns:\n        np.ndarray: An array of FDR-adjusted q-values, in the same order as the input p_values.\n    \"\"\"\n    p_values = np.asarray(p_values)\n    m = len(p_values)\n    if m == 0:\n        return np.array([])\n    \n    # Sort p-values and keep track of original indices\n    original_indices = np.argsort(p_values)\n    sorted_p_values = p_values[original_indices]\n    \n    # Calculate q-values\n    q_values = np.zeros(m)\n    for i, p_val in enumerate(sorted_p_values):\n        rank = i + 1\n        q_values[i] = (p_val * m) / rank\n    \n    # Enforce monotonicity\n    # q_i = min(q_{i+1}, q_i) for i = m-1 ... 1\n    # This is equivalent to taking the cumulative minimum from the end of the sorted list\n    q_values = np.minimum.accumulate(q_values[::-1])[::-1]\n    \n    # Restore original order\n    final_q_values = np.zeros(m)\n    final_q_values[original_indices] = q_values\n    \n    # Clamp values to be at most 1.0\n    return np.clip(final_q_values, a_min=None, a_max=1.0)\n\ndef solve():\n    \"\"\"\n    Main function to run the epigenetic analysis pipeline on the provided test cases.\n    \"\"\"\n    # Input data structured as:\n    # list of test cases -> list of genes -> tuple of (tumor_meth, normal_meth, tumor_expr, normal_expr, histone_flag)\n    test_cases = [\n        # Test case 1\n        [\n            (np.array([0.80,0.82,0.83,0.85,0.86,0.88]), np.array([0.12,0.18,0.15,0.22,0.17,0.19]), np.array([2.6,2.4,2.3,2.1,2.0,1.9]), np.array([6.0,6.5,5.8,6.2,6.4,6.1]), 1),\n            (np.array([0.60,0.62,0.61,0.59,0.58,0.62]), np.array([0.40,0.42,0.41,0.39,0.38,0.42]), np.array([6.0,5.8,6.1,5.9,6.2,6.0]), np.array([5.5,5.7,5.4,5.6,5.5,5.6]), 0),\n            (np.array([0.74,0.75,0.76,0.77,0.78,0.79]), np.array([0.20,0.21,0.22,0.22,0.23,0.24]), np.array([2.0,2.1,2.2,2.3,2.4,2.5]), np.array([6.0,6.1,6.2,6.3,6.1,6.2]), 1),\n            (np.array([0.70,0.72,0.74,0.75,0.71,0.73]), np.array([0.25,0.27,0.26,0.28,0.24,0.26]), np.array([3.0,2.8,2.6,2.5,2.7,2.6]), np.array([5.5,5.2,5.1,5.3,5.4,5.2]), 0),\n        ],\n        # Test case 2\n        [\n            (np.array([0.60,0.61,0.62,0.59,0.58,0.60]), np.array([0.40,0.41,0.42,0.39,0.38,0.40]), np.array([4.0,3.9,4.1,3.8,4.0,3.9]), np.array([4.2,4.1,4.2,4.3,4.1,4.2]), 1),\n            (np.array([0.85,0.83,0.84,0.86,0.87,0.85]), np.array([0.30,0.29,0.31,0.28,0.32,0.30]), np.array([2.5,2.4,2.3,2.2,2.1,2.0]), np.array([5.0,5.1,5.2,5.1,5.0,5.2]), 0),\n            (np.array([0.77,0.78,0.79,0.80,0.81,0.82]), np.array([0.20,0.21,0.19,0.22,0.21,0.20]), np.array([0.20,0.18,0.15,0.12,0.10,0.08]), np.array([3.0,3.2,3.1,3.3,3.2,3.1]), 1),\n        ],\n        # Test case 3\n        [\n            (np.array([0.70,0.72,0.74]), np.array([0.40,0.42,0.41]), np.array([3.0,2.8,2.6]), np.array([5.0,5.2,5.1]), 0),\n            (np.array([0.68,0.70,0.69]), np.array([0.50,0.49,0.51]), np.array([4.5,4.6,4.4]), np.array([4.6,4.5,4.4]), 0),\n            (np.array([0.85,0.87,0.86]), np.array([0.30,0.32,0.31]), np.array([1.5,1.4,1.6]), np.array([5.0,4.8,4.9]), 1),\n        ]\n    ]\n\n    # --- Decision Thresholds ---\n    METH_EFFECT_THRESHOLD = 0.2\n    Q_VALUE_THRESHOLD = 0.05\n    EXPR_EFFECT_THRESHOLD = -1.0\n    CORR_EFFECT_THRESHOLD = -0.5\n    CORR_P_VALUE_THRESHOLD = 0.05\n    EPSILON = 1e-3\n\n    overall_results = []\n\n    for case_data in test_cases:\n        num_genes = len(case_data)\n        \n        # Lists to store per-gene statistics for the current test case\n        meth_p_values = []\n        expr_p_values = []\n        gene_stats = []\n\n        # Step 1: Calculate all stats for each gene\n        for gene_idx in range(num_genes):\n            t_meth, n_meth, t_expr, n_expr, histone_flag = case_data[gene_idx]\n\n            # Methylation analysis\n            delta_beta = np.mean(t_meth) - np.mean(n_meth)\n            _, meth_p = stats.mannwhitneyu(t_meth, n_meth, alternative='two-sided')\n            meth_p_values.append(meth_p)\n\n            # Expression analysis\n            mean_t_expr = np.mean(t_expr)\n            mean_n_expr = np.mean(n_expr)\n            log2fc = np.log2(mean_t_expr + EPSILON) - np.log2(mean_n_expr + EPSILON)\n            _, expr_p = stats.ttest_ind(t_expr, n_expr, equal_var=False, alternative='two-sided')\n            expr_p_values.append(expr_p)\n            \n            # Correlation analysis\n            spearman_rho, spearman_p = stats.spearmanr(t_meth, t_expr)\n\n            gene_stats.append({\n                'delta_beta': delta_beta,\n                'log2fc': log2fc,\n                'spearman_rho': spearman_rho,\n                'spearman_p': spearman_p,\n                'histone_flag': histone_flag\n            })\n\n        # Step 2: Apply Benjamini-Hochberg correction\n        meth_q_values = benjamini_hochberg(meth_p_values)\n        expr_q_values = benjamini_hochberg(expr_p_values)\n\n        # Step 3: Classify genes based on thresholds\n        standard_confidence_indices = []\n        high_confidence_indices = []\n\n        for gene_idx in range(num_genes):\n            stats_dict = gene_stats[gene_idx]\n            \n            meth_hyper = (stats_dict['delta_beta'] >= METH_EFFECT_THRESHOLD) and (meth_q_values[gene_idx] = Q_VALUE_THRESHOLD)\n            expr_down = (stats_dict['log2fc'] = EXPR_EFFECT_THRESHOLD) and (expr_q_values[gene_idx] = Q_VALUE_THRESHOLD)\n            neg_corr = (stats_dict['spearman_rho'] = CORR_EFFECT_THRESHOLD) and (stats_dict['spearman_p'] = CORR_P_VALUE_THRESHOLD)\n\n            if meth_hyper and expr_down and neg_corr:\n                standard_confidence_indices.append(gene_idx)\n                if stats_dict['histone_flag'] == 1:\n                    high_confidence_indices.append(gene_idx)\n        \n        overall_results.append([sorted(standard_confidence_indices), sorted(high_confidence_indices)])\n\n    # Format output string\n    output_str = str(overall_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "在发现表观遗传标记（如DNA甲基化）与疾病风险之间存在强关联后，一个更深层次的关键问题是：这种关联是否是因果性的？孟德尔随机化（Mendelian Randomization, MR）是一种强有力的统计遗传学方法，它利用遗传变异作为“工具变量”，帮助我们从观测数据中推断暴露因素与结局之间的因果关系。在这个高级练习  中，您将实施一个双样本孟德尔随机化分析，以估计DNA甲基化水平对疾病风险的因果效应。这不仅能让您掌握一种前沿的因果推断技术，还能训练您如何批判性地评估其分析背后关键假设的有效性。",
            "id": "4337382",
            "problem": "您的任务是实现一个两样本孟德尔随机化（MR）分析，使用甲基化数量性状基因座（mQTL）作为工具变量，以估计生物标志物胞嘧啶-磷酸-鸟嘌呤（CpG）位点的DNA甲基化对疾病风险的因果效应。背景设定在精准医疗和基因组诊断领域，重点关注表观遗传机制（DNA甲基化和组蛋白修饰）。您的程序必须计算一个基于工具变量的因果估计值，并评估工具变量强度及是否可能违反工具变量的假设。\n\n必须使用的基本核心定义如下：\n- 工具变量（IV）的假设：相关性、独立性、排他性限制。相关性要求遗传工具变量与暴露相关；独立性要求工具变量独立于暴露-结局关系中的混杂因素；排他性限制要求工具变量仅通过暴露来影响结局。\n- 孟德尔随机化（MR）在这些假设下，使用胚系遗传变异作为工具变量，在观测数据中推断因果效应。\n- 汇总水平数据的两样本MR使用来自独立样本的单核苷酸多态性（SNPs）与暴露和结局的关联估计值。\n- 线性因果暴露-结局模型：对于每个SNP工具变量索引 $i \\in \\{1,\\dots,k\\}$，汇总的关联估计值被建模为 $b_{X,i}$（SNP-暴露效应）和 $b_{Y,i}$（SNP-结局效应），它们各自的标准误分别为 $se_{X,i}$ 和 $se_{Y,i}$，权重为 $w_i = 1 / se_{Y,i}^{2}$。\n\n您的程序必须实现以下计算：\n1. 逆方差加权（IVW）估计量，截距为零（有约束的回归）：\n   - 通过对 $b_{Y,i}$ 关于 $b_{X,i}$ 进行加权最小二乘法估计因果效应 $\\beta_{\\text{IVW}}$，权重为 $w_i$，并约束截距为 $0$。具体来说，\n     $$\\beta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{k} w_i b_{X,i} b_{Y,i}}{\\sum_{i=1}^{k} w_i b_{X,i}^{2}}.$$\n   - 计算其标准误，\n     $$se_{\\text{IVW}} = \\sqrt{\\frac{1}{\\sum_{i=1}^{k} w_i b_{X,i}^{2}}},$$\n     并使用正态近似 $z = \\beta_{\\text{IVW}} / se_{\\text{IVW}}$ 计算双侧 $p$ 值。\n   - 计算用于异质性检验的Cochran’s $Q$ 统计量，\n     $$Q = \\sum_{i=1}^{k} w_i \\left(b_{Y,i} - \\beta_{\\text{IVW}} b_{X,i}\\right)^{2},$$\n     其自由度为 $df = k - 1$，并使用卡方分布计算其 $p$ 值。\n\n2. MR-Egger回归（$b_{Y,i}$ 对 $b_{X,i}$ 的带截距的加权线性回归）：\n   - 计算加权平均值 $\\bar{x}_w = \\frac{\\sum_{i=1}^{k} w_i b_{X,i}}{\\sum_{i=1}^{k} w_i}$ 和 $\\bar{y}_w = \\frac{\\sum_{i=1}^{k} w_i b_{Y,i}}{\\sum_{i=1}^{k} w_i}$，加权中心化和 $S_{xx} = \\sum_{i=1}^{k} w_i (b_{X,i} - \\bar{x}_w)^2$ 和 $S_{xy} = \\sum_{i=1}^{k} w_i (b_{X,i} - \\bar{x}_w)(b_{Y,i} - \\bar{y}_w)$，然后计算斜率和截距，\n     $$\\beta_{\\text{Egger}} = \\frac{S_{xy}}{S_{xx}}, \\quad \\alpha_{\\text{Egger}} = \\bar{y}_w - \\beta_{\\text{Egger}} \\bar{x}_w.$$\n   - 在权重 $w_i = 1/se_{Y,i}^{2}$ 下，计算标准误\n     $$se(\\beta_{\\text{Egger}}) = \\sqrt{\\frac{1}{S_{xx}}}, \\quad se(\\alpha_{\\text{Egger}}) = \\sqrt{\\frac{1}{\\sum_{i=1}^{k} w_i} + \\frac{\\bar{x}_w^{2}}{S_{xx}}},$$\n     并对截距使用正态近似 $z = \\alpha_{\\text{Egger}} / se(\\alpha_{\\text{Egger}})$ 计算双侧 $p$ 值。\n\n3. 评估每个工具变量的强度：\n   - 对于每个工具变量 $i$，计算第一阶段 $F$ 统计量\n     $$F_i = \\frac{b_{X,i}^{2}}{se_{X,i}^{2}}.$$\n   - 报告所有工具变量的平均值 $\\overline{F}$ 和最小值 $\\min(F)$，以及一个布尔指示符，表示是否为强工具变量，定义为 $[\\min(F)  10]$。\n\n程序输出中的所有量都必须是无量纲的，并表示为普通数字。不涉及任何物理单位或角度单位。不要使用百分比；将所有比例和概率表示为十进制数。\n\n测试套件和参数值：\n您的程序必须在以下三个测试用例上运行（每个用例提供每个工具变量的汇总统计数据数组）。对于每个标量和数组条目，将所有数字视为无量纲。\n\n- 测试用例 $1$ （理想情况，强工具变量，最小的多效性）：\n  - $b_X = [\\,0.25,\\,0.18,\\,0.30\\,]$\n  - $se_X = [\\,0.03,\\,0.04,\\,0.02\\,]$\n  - $b_Y = [\\,0.052,\\,0.031,\\,0.065\\,]$\n  - $se_Y = [\\,0.020,\\,0.015,\\,0.020\\,]$\n\n- 测试用例 $2$ （边界情况，接近违反相关性假设的弱工具变量）：\n  - $b_X = [\\,0.020,\\,-0.015\\,]$\n  - $se_X = [\\,0.030,\\,0.030\\,]$\n  - $b_Y = [\\,0.016,\\,-0.0095\\,]$\n  - $se_Y = [\\,0.020,\\,0.020\\,]$\n\n- 测试用例 $3$ （边缘情况，存在水平多效性，截距非零）：\n  - $b_X = [\\,0.12,\\,0.20,\\,-0.15,\\,0.10\\,]$\n  - $se_X = [\\,0.02,\\,0.03,\\,0.02,\\,0.02\\,]$\n  - $b_Y = [\\,0.052,\\,0.070,\\,-0.005,\\,0.040\\,]$\n  - $se_Y = [\\,0.020,\\,0.020,\\,0.020,\\,0.020\\,]$\n\n最终输出规范：\n对于每个测试用例，按顺序生成一个包含以下 $12$ 个结果的列表：\n- $\\beta_{\\text{IVW}}$ (浮点数)\n- $se_{\\text{IVW}}$ (浮点数)\n- $p_{\\text{IVW}}$ (浮点数)\n- $\\beta_{\\text{Egger}}$ (浮点数)\n- $se(\\beta_{\\text{Egger}})$ (浮点数)\n- $\\alpha_{\\text{Egger}}$ (浮点数)\n- $p(\\alpha_{\\text{Egger}})$ (浮点数)\n- $\\overline{F}$ (浮点数)\n- $\\min(F)$ (浮点数)\n- 强工具变量指示符 $[\\min(F)  10]$ (布尔值)\n- $Q$ (浮点数)\n- $p_Q$ (浮点数)\n\n您的程序应生成单行输出，其中包含由三个按用例划分的列表组成的逗号分隔列表，并用方括号括起来，例如，$[[\\dots],[\\dots],[\\dots]]$。不应打印任何其他文本。",
            "solution": "该问题陈述经评估是有效的。它在科学上基于已建立的生物统计学方法论，即两样本孟德尔随机化（MR）。所给出的定义、公式和数据清晰、自洽且在数学上是一致的。任务是实现该领域中一系列标准的、良构的计算。\n\n该解决方案被构建为对所需计算的系统性实现。对于每个测试用例，我们都得到四个数组：SNP-暴露效应（$b_X$）、其标准误（$se_X$）、SNP-结局效应（$b_Y$）及其标准误（$se_Y$）。设作为工具变量的SNP数量为 $k$。每个SNP由索引 $i$（从 $1$ 到 $k$）标识。\n\n计算过程分为以下逻辑步骤：\n\n1.  **工具变量强度与加权**\n    每个工具变量 $i$ 的强度通过第一阶段 $F$ 统计量来量化，该统计量是SNP-暴露关联的 $z$ 分数的平方：\n    $$F_i = \\left( \\frac{b_{X,i}}{se_{X,i}} \\right)^2$$\n    一个常见的启发式法则是，如果一个工具变量的 $F$ 统计量超过 $10$，则该工具变量是“强的”。我们将计算所有 $k$ 个工具变量的这些统计量的平均值 $\\overline{F}$ 和最小值 $\\min(F)$，以及一个布尔指示符 $[\\min(F)  10]$ 来评估整体工具变量强度。弱工具变量（$F_i \\le 10$）表明相关性假设可能被违反。\n\n    对于加权回归方法（IVW和MR-Egger），每个工具变量 $i$ 的权重定义为SNP-结局效应方差的倒数：\n    $$w_i = \\frac{1}{se_{Y,i}^2}$$\n\n2.  **逆方差加权（IVW）因果效应估计**\n    IVW方法在所有工具变量均有效（即满足相关性、独立性和排他性限制假设）且不存在方向性多效性的假设下，提供了对因果效应的有效估计。它等同于将结局效应 $b_{Y,i}$ 对暴露效应 $b_{X,i}$ 进行加权线性回归，并约束回归线通过原点。\n\n    因果效应估计值 $\\beta_{\\text{IVW}}$ 计算如下：\n    $$\\beta_{\\text{IVW}} = \\frac{\\sum_{i=1}^{k} w_i b_{X,i} b_{Y,i}}{\\sum_{i=1}^{k} w_i b_{X,i}^{2}}$$\n    该估计值的标准误由估计量的分母导出：\n    $$se_{\\text{IVW}} = \\sqrt{\\frac{1}{\\sum_{i=1}^{k} w_i b_{X,i}^{2}}}$$\n    对于原假设 $H_0: \\beta_{\\text{IVW}} = 0$，使用检验统计量 $z = \\beta_{\\text{IVW}} / se_{\\text{IVW}}$ 和标准正态分布计算双侧 $p$ 值，$p_{\\text{IVW}} = 2 \\cdot (1 - \\Phi(|z|))$，其中 $\\Phi$ 是标准正态分布的累积分布函数。\n\n3.  **使用Cochran's Q进行异质性分析**\n    来自单个工具变量的因果估计值之间的异质性可能表明IV假设被违反，特别是存在多效性。Cochran's $Q$ 统计量量化了这种异质性：\n    $$Q = \\sum_{i=1}^{k} w_i \\left(b_{Y,i} - \\beta_{\\text{IVW}} b_{X,i}\\right)^{2}$$\n    在无异质性的原假设下，$Q$ 服从自由度为 $df = k - 1$ 的卡方（$\\chi^2$）分布。一个小的 $p_Q$ 值表明，各工具变量的因果效应估计值之间的差异比偶然预期的要大，这可能指向存在无效的工具变量。\n\n4.  **用于多效性检测的MR-Egger回归**\n    MR-Egger回归是一种敏感性分析，可以检测并校正方向性多效性。它放宽了排他性限制假设，允许工具变量对结局有不通过暴露介导的直接效应。这是通过对 $b_{Y,i}$ 关于 $b_{X,i}$ 进行*带*截距项 $\\alpha_{\\text{Egger}}$ 的加权线性回归来实现的。\n\n    回归模型为 $b_{Y,i} = \\alpha_{\\text{Egger}} + \\beta_{\\text{Egger}} b_{X,i} + \\epsilon_i$。斜率 $\\beta_{\\text{Egger}}$ 提供了一个经多效性校正的因果效应估计，而截距 $\\alpha_{\\text{Egger}}$ 代表了平均多效性效应。一个非零的截距（$p(\\alpha_{\\text{Egger}})$ 很小）是存在方向性多效性的证据。\n\n    参数使用标准的加权最小二乘法公式计算：\n    -   加权平均值: $\\bar{x}_w = \\frac{\\sum w_i b_{X,i}}{\\sum w_i}$，$\\bar{y}_w = \\frac{\\sum w_i b_{Y,i}}{\\sum w_i}$\n    -   加权平方和/交叉积和: $S_{xx} = \\sum w_i (b_{X,i} - \\bar{x}_w)^2$，$S_{xy} = \\sum w_i (b_{X,i} - \\bar{x}_w)(b_{Y,i} - \\bar{y}_w)$\n    -   估计量: $\\beta_{\\text{Egger}} = \\frac{S_{xy}}{S_{xx}}$，$\\alpha_{\\text{Egger}} = \\bar{y}_w - \\beta_{\\text{Egger}} \\bar{x}_w$\n\n    指定的标准误为：\n    $$se(\\beta_{\\text{Egger}}) = \\sqrt{\\frac{1}{S_{xx}}}$$\n    $$se(\\alpha_{\\text{Egger}}) = \\sqrt{\\frac{1}{\\sum w_i} + \\frac{\\bar{x}_w^2}{S_{xx}}}$$\n    截距的 $p$ 值由其 $z$ 分数 $z_\\alpha = \\alpha_{\\text{Egger}} / se(\\alpha_{\\text{Egger}})$ 使用标准正态分布计算。值得注意的是，MR-Egger参数的估计要求工具变量-暴露关联存在变异性，即 $S_{xx}  0$。这与“工具变量强度独立于直接效应”（InSIDE）假设有关。提供的测试用例满足此条件。\n\n实现将通过按顺序应用这些公式来处理每个测试用例，将 $12$ 个所需的输出（$\\beta_{\\text{IVW}}$, $se_{\\text{IVW}}$, $p_{\\text{IVW}}$, $\\beta_{\\text{Egger}}$, $se(\\beta_{\\text{Egger}})$, $\\alpha_{\\text{Egger}}$, $p(\\alpha_{\\text{Egger}})$, $\\overline{F}$, $\\min(F)$, $[\\min(F)  10]$, $Q$, $p_Q$）打包到一个列表中。最终输出将是这些列表的列表。",
            "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run MR analysis on predefined test cases and print results.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"b_X\": [0.25, 0.18, 0.30],\n            \"se_X\": [0.03, 0.04, 0.02],\n            \"b_Y\": [0.052, 0.031, 0.065],\n            \"se_Y\": [0.020, 0.015, 0.020]\n        },\n        {\n            \"b_X\": [0.020, -0.015],\n            \"se_X\": [0.030, 0.030],\n            \"b_Y\": [0.016, -0.0095],\n            \"se_Y\": [0.020, 0.020]\n        },\n        {\n            \"b_X\": [0.12, 0.20, -0.15, 0.10],\n            \"se_X\": [0.02, 0.03, 0.02, 0.02],\n            \"b_Y\": [0.052, 0.070, -0.005, 0.040],\n            \"se_Y\": [0.020, 0.020, 0.020, 0.020]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_list = analyze_mr_case(\n            b_X=case[\"b_X\"],\n            se_X=case[\"se_X\"],\n            b_Y=case[\"b_Y\"],\n            se_Y=case[\"se_Y\"]\n        )\n        all_results.append(result_list)\n\n    # Format output as a string representation of a list of lists.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef analyze_mr_case(b_X, se_X, b_Y, se_Y):\n    \"\"\"\n    Performs the two-sample Mendelian Randomization analysis for a single case.\n\n    Args:\n        b_X (list): SNP-exposure effects.\n        se_X (list): Standard errors for b_X.\n        b_Y (list): SNP-outcome effects.\n        se_Y (list): Standard errors for b_Y.\n\n    Returns:\n        list: A list of 12 computed results in the specified order.\n    \"\"\"\n    b_X = np.array(b_X, dtype=float)\n    se_X = np.array(se_X, dtype=float)\n    b_Y = np.array(b_Y, dtype=float)\n    se_Y = np.array(se_Y, dtype=float)\n    \n    k = len(b_X)\n\n    # Instrument strength and weights\n    w = 1.0 / se_Y**2\n    f_stats = (b_X / se_X)**2\n    mean_F = np.mean(f_stats)\n    min_F = np.min(f_stats)\n    is_strong = min_F > 10\n\n    # Inverse-Variance Weighted (IVW) analysis\n    ivw_numerator = np.sum(w * b_X * b_Y)\n    ivw_denominator = np.sum(w * b_X**2)\n    \n    beta_ivw = ivw_numerator / ivw_denominator\n    se_ivw = np.sqrt(1.0 / ivw_denominator)\n    z_ivw = beta_ivw / se_ivw\n    p_ivw = 2 * stats.norm.sf(np.abs(z_ivw))\n\n    # Cochran's Q for heterogeneity\n    q_stat = np.sum(w * (b_Y - beta_ivw * b_X)**2)\n    df_q = k - 1\n    p_q = stats.chi2.sf(q_stat, df_q) if df_q > 0 else 1.0\n\n    # MR-Egger regression\n    sum_w = np.sum(w)\n    x_w_mean = np.sum(w * b_X) / sum_w\n    y_w_mean = np.sum(w * b_Y) / sum_w\n\n    S_xx = np.sum(w * (b_X - x_w_mean)**2)\n    S_xy = np.sum(w * (b_X - x_w_mean) * (b_Y - y_w_mean))\n\n    if S_xx == 0:\n        # Cannot estimate slope; this edge case is not in the test suite\n        # but is handled for robustness.\n        beta_egger, se_beta_egger = np.nan, np.nan\n        alpha_egger, p_alpha_egger = np.nan, np.nan\n    else:\n        beta_egger = S_xy / S_xx\n        alpha_egger = y_w_mean - beta_egger * x_w_mean\n        \n        se_beta_egger = np.sqrt(1.0 / S_xx)\n        \n        se_alpha_egger_var = (1.0 / sum_w) + (x_w_mean**2 / S_xx)\n        se_alpha_egger = np.sqrt(se_alpha_egger_var)\n        \n        z_alpha_egger = alpha_egger / se_alpha_egger if se_alpha_egger > 0 else 0\n        p_alpha_egger = 2 * stats.norm.sf(np.abs(z_alpha_egger))\n\n    # Assemble results in the specified order\n    results = [\n        beta_ivw,\n        se_ivw,\n        p_ivw,\n        beta_egger,\n        se_beta_egger,\n        alpha_egger,\n        p_alpha_egger,\n        mean_F,\n        min_F,\n        is_strong,\n        q_stat,\n        p_q\n    ]\n    \n    return results\n\nsolve()\n```"
        }
    ]
}