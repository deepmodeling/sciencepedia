{
    "hands_on_practices": [
        {
            "introduction": "不成比例分析是自发报告系统（Spontaneous Reporting Systems, SRS）中信号检测的基石。信息熵（Information Component, IC）作为一种先进的贝叶斯方法，相比于传统的频率派方法具有一定优势。本练习将引导你深入该方法的内部机制，从第一性原理出发，推导其点估计和不确定性，从而加深对贝叶斯信号检测理论的理解。",
            "id": "4520104",
            "problem": "一个自发报告数据库由药物 $D$ 和不良事件 $E$ 的 $2 \\times 2$ 列联表总结，总报告数为 $N$，联合计数为 $n_{DE}$，边际计数为 $n_{D \\cdot}$ 和 $n_{\\cdot E}$。考虑一个针对四个单元格概率 $(p_{11}, p_{10}, p_{01}, p_{00})$ 的贝叶斯收缩模型，该模型对每个单元格使用带有伪计数 $\\alpha$ 的对称狄利克雷先验，其中数据被建模为多项式分布。对于贝叶斯置信度传播神经网络 (BCPNN) 不成比例度量，信息分量 (IC) 定义为 $IC = \\log_{2}\\!\\left(\\frac{p_{11}}{(p_{11}+p_{10})(p_{11}+p_{01})}\\right)$。\n\n从多项式似然和狄利克雷共轭先验的定义出发，使用 $(p_{11}, p_{10}, p_{01}, p_{00})$ 的后验分布来：\n- 通过在 $(p_{11}, p_{10}, p_{01}, p_{00})$ 的后验均值处评估定义函数，计算 $IC$ 的点估计值，以及\n- 通过将狄利克雷分布的后验协方差通过上述变换进行传播，计算 $IC$ 的 delta 方法标准误。\n\n给定 $n_{DE} = 20$，$n_{D \\cdot} = 200$，$n_{\\cdot E} = 150$，$N = 5000$，以及对四个单元格中每个单元格均为 $\\alpha = 1$ 的对称狄利克雷先验。报告由 $IC$ 的点估计值及其 delta 方法标准误组成的数对。将两个值都四舍五入到四位有效数字。不需要单位。",
            "solution": "该问题要求在贝叶斯框架内计算信息分量 ($IC$) 的点估计值和标准误。\n\n首先，我们建立 $2 \\times 2$ 列联表的表示法并计算所有四个单元格的计数。设单元格 $(i, j)$ 对应于药物状态 $i$ 和事件状态 $j$，其中 $i=1$ 表示存在药物 $D$，$i=0$ 表示不存在药物 $D$；同样，$j=1$ 表示存在事件 $E$，$j=0$ 表示不存在事件 $E$。\n\n给定的计数为：\n总报告数：$N=5000$\n药物 $D$ 和事件 $E$：$n_{11} = n_{DE} = 20$\n药物 $D$ 边际：$n_{D \\cdot} = n_{11} + n_{10} = 200$\n事件 $E$ 边际：$n_{\\cdot E} = n_{11} + n_{01} = 150$\n\n由此，我们推导出其他单元格的计数：\n药物 $D$，无事件 $E$：$n_{10} = n_{D \\cdot} - n_{11} = 200 - 20 = 180$\n无药物 $D$，有事件 $E$：$n_{01} = n_{\\cdot E} - n_{11} = 150 - 20 = 130$\n无药物 $D$，无事件 $E$：$n_{00} = N - n_{11} - n_{10} - n_{01} = 5000 - 20 - 180 - 130 = 4670$\n完整的计数集为 $(n_{11}, n_{10}, n_{01}, n_{00}) = (20, 180, 130, 4670)$。\n\n模型假设数据 $\\mathbf{n} = (n_{11}, n_{10}, n_{01}, n_{00})$ 服从参数为 $N$ 和单元格概率为 $\\mathbf{p} = (p_{11}, p_{10}, p_{01}, p_{00})$ 的多项式分布。$\\mathbf{p}$ 的先验是对称狄利克雷分布，$\\mathbf{p} \\sim \\text{Dir}(\\alpha, \\alpha, \\alpha, \\alpha)$，其中 $\\alpha=1$。\n\n狄利克雷分布是多项式似然的共轭先验。因此，给定数据 $\\mathbf{n}$ 的 $\\mathbf{p}$ 的后验分布也是一个狄利克雷分布：\n$$ \\mathbf{p} \\,|\\, \\mathbf{n} \\sim \\text{Dir}(\\alpha'_{11}, \\alpha'_{10}, \\alpha'_{01}, \\alpha'_{00}) $$\n其中后验参数为 $\\alpha'_{ij} = n_{ij} + \\alpha$。\n当 $\\alpha=1$ 时，后验参数为：\n$\\alpha'_{11} = 20 + 1 = 21$\n$\\alpha'_{10} = 180 + 1 = 181$\n$\\alpha'_{01} = 130 + 1 = 131$\n$\\alpha'_{00} = 4670 + 1 = 4671$\n\n后验参数的总和是 $\\alpha'_0 = \\sum_{i,j} \\alpha'_{ij} = 21 + 181 + 131 + 4671 = 5004$。注意，这也等于 $N + 4\\alpha = 5000 + 4(1) = 5004$。\n\n**1. IC 的点估计**\n\n点估计是通过将概率的后验均值代入 $IC$ 的定义来计算的。$p_{ij}$ 的后验均值为 $E[p_{ij} | \\mathbf{n}] = \\hat{p}_{ij} = \\frac{\\alpha'_{ij}}{\\alpha'_0}$。\nIC 定义为 $g(\\mathbf{p}) = IC = \\log_{2}\\!\\left(\\frac{p_{11}}{p_{D\\cdot} p_{\\cdot E}}\\right)$，其中 $p_{D\\cdot} = p_{11}+p_{10}$ 且 $p_{\\cdot E} = p_{11}+p_{01}$。\n点估计 $\\widehat{IC}$ 为：\n$$ \\widehat{IC} = g(\\hat{\\mathbf{p}}) = \\log_{2}\\!\\left(\\frac{\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}}\\right) $$\n边际概率的后验均值为 $\\hat{p}_{D\\cdot} = \\hat{p}_{11}+\\hat{p}_{10} = \\frac{\\alpha'_{11}+\\alpha'_{10}}{\\alpha'_0}$ 和 $\\hat{p}_{\\cdot E} = \\hat{p}_{11}+\\hat{p}_{01} = \\frac{\\alpha'_{11}+\\alpha'_{01}}{\\alpha'_0}$。\n令 $\\alpha'_{D\\cdot} = \\alpha'_{11}+\\alpha'_{10} = 21+181 = 202$ 且 $\\alpha'_{\\cdot E} = \\alpha'_{11}+\\alpha'_{01} = 21+131 = 152$。\n则，\n$$ \\widehat{IC} = \\log_{2}\\!\\left(\\frac{\\alpha'_{11}/\\alpha'_{0}}{(\\alpha'_{D\\cdot}/\\alpha'_{0})(\\alpha'_{\\cdot E}/\\alpha'_{0})}\\right) = \\log_{2}\\!\\left(\\frac{\\alpha'_{11}\\alpha'_0}{\\alpha'_{D\\cdot}\\alpha'_{\\cdot E}}\\right) $$\n代入数值：\n$$ \\widehat{IC} = \\log_{2}\\!\\left(\\frac{21 \\times 5004}{202 \\times 152}\\right) = \\log_{2}\\!\\left(\\frac{105084}{30704}\\right) \\approx \\log_{2}(3.42248567) $$\n$$ \\widehat{IC} = \\frac{\\ln(3.42248567)}{\\ln(2)} \\approx 1.775193 $$\n四舍五入到四位有效数字，点估计值为 $1.775$。\n\n**2. IC 的 Delta 方法标准误**\n\nDelta 方法将函数 $g(\\mathbf{p})$ 的方差近似为 $\\text{Var}(g(\\mathbf{p})) \\approx (\\nabla g)^T \\Sigma_{\\mathbf{p}} (\\nabla g)$，在后验均值 $\\hat{\\mathbf{p}}$ 处求值。对于后验狄利克雷分布，这可以简化为：\n$$ \\text{Var}(g(\\mathbf{p})) \\approx \\frac{1}{\\alpha'_0+1} \\left[ \\sum_{i,j} \\hat{p}_{ij} \\left(\\frac{\\partial g}{\\partial p_{ij}}\\right)^2 - \\left(\\sum_{i,j} \\hat{p}_{ij} \\frac{\\partial g}{\\partial p_{ij}}\\right)^2 \\right] $$\n首先，我们用自然对数表示 $g(\\mathbf{p})$：$g(\\mathbf{p}) = \\frac{1}{\\ln(2)}[\\ln(p_{11}) - \\ln(p_{11}+p_{10}) - \\ln(p_{11}+p_{01})]$。令 $C = 1/\\ln(2)$。\n在后验均值 $\\hat{\\mathbf{p}}$ 处求值的偏导数是：\n$\\frac{\\partial g}{\\partial p_{11}} = C \\left(\\frac{1}{p_{11}} - \\frac{1}{p_{D\\cdot}} - \\frac{1}{p_{\\cdot E}}\\right)$\n$\\frac{\\partial g}{\\partial p_{10}} = C \\left(-\\frac{1}{p_{D\\cdot}}\\right)$\n$\\frac{\\partial g}{\\partial p_{01}} = C \\left(-\\frac{1}{p_{\\cdot E}}\\right)$\n$\\frac{\\partial g}{\\partial p_{00}} = 0$\n\n让我们计算方差公式中的两项。第一项是 $E_{\\hat{\\mathbf{p}}}[\\nabla g] = \\sum \\hat{p}_{ij}\\frac{\\partial g}{\\partial p_{ij}}$：\n$$ \\sum_{i,j} \\hat{p}_{ij}\\frac{\\partial g}{\\partial p_{ij}} = C \\left[ \\hat{p}_{11}\\left(\\frac{1}{\\hat{p}_{11}} - \\frac{1}{\\hat{p}_{D\\cdot}} - \\frac{1}{\\hat{p}_{\\cdot E}}\\right) - \\hat{p}_{10}\\frac{1}{\\hat{p}_{D\\cdot}} - \\hat{p}_{01}\\frac{1}{\\hat{p}_{\\cdot E}} \\right] $$\n$$ = C \\left[ 1 - \\frac{\\hat{p}_{11}}{\\hat{p}_{D\\cdot}} - \\frac{\\hat{p}_{11}}{\\hat{p}_{\\cdot E}} - \\frac{\\hat{p}_{10}}{\\hat{p}_{D\\cdot}} - \\frac{\\hat{p}_{01}}{\\hat{p}_{\\cdot E}} \\right] = C \\left[ 1 - \\frac{\\hat{p}_{11}+\\hat{p}_{10}}{\\hat{p}_{D\\cdot}} - \\frac{\\hat{p}_{11}+\\hat{p}_{01}}{\\hat{p}_{\\cdot E}} \\right] $$\n$$ = C [1 - 1 - 1] = -C $$\n第二项是 $E_{\\hat{\\mathbf{p}}}[(\\nabla g)^2] = \\sum \\hat{p}_{ij}(\\frac{\\partial g}{\\partial p_{ij}})^2$：\n$$ \\sum_{i,j} \\hat{p}_{ij}\\left(\\frac{\\partial g}{\\partial p_{ij}}\\right)^2 = C^2 \\left[ \\hat{p}_{11}\\left(\\frac{1}{\\hat{p}_{11}}-\\frac{1}{\\hat{p}_{D\\cdot}}-\\frac{1}{\\hat{p}_{\\cdot E}}\\right)^2 + \\frac{\\hat{p}_{10}}{\\hat{p}_{D\\cdot}^2} + \\frac{\\hat{p}_{01}}{\\hat{p}_{\\cdot E}^2} \\right] $$\n展开并简化此表达式可得：\n$$ \\sum_{i,j} \\hat{p}_{ij}\\left(\\frac{\\partial g}{\\partial p_{ij}}\\right)^2 \\approx C^2 \\left( \\frac{1}{\\hat{p}_{11}} - \\frac{1}{\\hat{p}_{D\\cdot}} - \\frac{1}{\\hat{p}_{\\cdot E}} \\right) $$\n这是一个常用近似，更精确的计算需要展开平方项。让我们使用更精确的展开：\n$$ \\text{展开} = C^2 \\left[ \\hat{p}_{11}\\left(\\frac{1}{\\hat{p}_{11}^2} + \\frac{1}{\\hat{p}_{D\\cdot}^2} + \\frac{1}{\\hat{p}_{\\cdot E}^2} - \\frac{2}{\\hat{p}_{11}\\hat{p}_{D\\cdot}} - \\frac{2}{\\hat{p}_{11}\\hat{p}_{\\cdot E}} + \\frac{2}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}}\\right) + \\frac{\\hat{p}_{10}}{\\hat{p}_{D\\cdot}^2} + \\frac{\\hat{p}_{01}}{\\hat{p}_{\\cdot E}^2} \\right] $$\n$$ = C^2 \\left[ \\frac{1}{\\hat{p}_{11}} + \\frac{\\hat{p}_{11}+\\hat{p}_{10}}{\\hat{p}_{D\\cdot}^2} + \\frac{\\hat{p}_{11}+\\hat{p}_{01}}{\\hat{p}_{\\cdot E}^2} - \\frac{2}{\\hat{p}_{D\\cdot}} - \\frac{2}{\\hat{p}_{\\cdot E}} + \\frac{2\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}} \\right] = C^2 \\left[ \\frac{1}{\\hat{p}_{11}} - \\frac{1}{\\hat{p}_{D\\cdot}} - \\frac{1}{\\hat{p}_{\\cdot E}} + \\frac{2\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}} \\right] $$\n现在，将这些简化形式代入方差公式：\n$$ \\text{Var}(IC) \\approx \\frac{1}{\\alpha'_0+1} \\left[ C^2 \\left( \\frac{1}{\\hat{p}_{11}} - \\frac{1}{\\hat{p}_{D\\cdot}} - \\frac{1}{\\hat{p}_{\\cdot E}} + \\frac{2\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}} \\right) - (-C)^2 \\right] $$\n$$ \\text{Var}(IC) \\approx \\frac{C^2}{\\alpha'_0+1} \\left[ \\frac{1}{\\hat{p}_{11}} - \\frac{1}{\\hat{p}_{D\\cdot}} - \\frac{1}{\\hat{p}_{\\cdot E}} + \\frac{2\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}} - 1 \\right] $$\n让我们将数值代入括号中的项。\n$\\frac{1}{\\hat{p}_{11}} = \\frac{\\alpha'_0}{\\alpha'_{11}} = \\frac{5004}{21} \\approx 238.2857$\n$\\frac{1}{\\hat{p}_{D\\cdot}} = \\frac{\\alpha'_0}{\\alpha'_{D\\cdot}} = \\frac{5004}{202} \\approx 24.7723$\n$\\frac{1}{\\hat{p}_{\\cdot E}} = \\frac{\\alpha'_0}{\\alpha'_{\\cdot E}} = \\frac{5004}{152} \\approx 32.9211$\n$\\frac{2\\hat{p}_{11}}{\\hat{p}_{D\\cdot}\\hat{p}_{\\cdot E}} = \\frac{2\\alpha'_{11}\\alpha'_0}{\\alpha'_{D\\cdot}\\alpha'_{\\cdot E}} = \\frac{2 \\times 21 \\times 5004}{202 \\times 152} \\approx 6.8450$\n括号中的项是 $238.2857 - 24.7723 - 32.9211 + 6.8450 - 1 = 186.4373$\n所以，方差为：\n$$ \\text{Var}(IC) \\approx \\frac{1}{(\\ln(2))^2} \\frac{186.4373}{5004+1} \\approx \\frac{1}{0.480453} \\frac{186.4373}{5005} \\approx 2.081368 \\times 0.0372502 \\approx 0.0775317 $$\n标准误是方差的平方根：\n$$ SE(IC) = \\sqrt{\\text{Var}(IC)} \\approx \\sqrt{0.0775317} \\approx 0.278445 $$\n四舍五入到四位有效数字，标准误为 $0.2784$。\n\n由点估计值及其 delta 方法标准误组成的数对是 $(1.775, 0.2784)$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.775 & 0.2784\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "现实世界中的药物安全信号常常表现为一系列相关的药物不良事件，而不仅仅是单个术语。本练习旨在解决评估此类信号的挑战，即在“标准MedDRA查询”（Standardized MedDRA Query, SMQ）的框架下对数据进行汇总分析。你将应用经典的流行病学工具——Mantel–Haenszel合并估计量，来计算合并的报告比例比（Proportional Reporting Ratio, PRR），并深入探讨各术语间的异质性如何对汇总估计值产生偏倚。",
            "id": "4520157",
            "problem": "一个药物警戒团队正在使用MedDRA®标准检索式（SMQ）的窄域范围，评估一种目标药物（记为 $D$）是否存在潜在的心律失常信号。该SMQ包含三个不重叠的首选术语（PT），计数来自一个去重后的自发报告系统，因此每份独立报告在SMQ内最多只对应一个PT。对于单个PT，报告比值比（PRR）定义为使用药物 $D$ 的报告中该PT的报告比例与使用所有其他药物的报告中该PT的报告比例之比。对于每个PT，其 $2 \\times 2$ 表格中，暴露组（使用药物 $D$ 的报告）的样本量为 $N_{1}$，非暴露组（使用其他药物的报告）的样本量为 $N_{0}$。对于PT $i$，记 $a_{i}$ 为使用药物 $D$ 且出现PT $i$ 的报告数，$c_{i}$ 为未使用药物 $D$ 但出现PT $i$ 的报告数，其互补计数由 $b_{i} = N_{1} - a_{i}$ 和 $d_{i} = N_{0} - c_{i}$ 给出。\n\n现提供以下符合科学合理性的计数：\n- 使用药物 $D$ 的总报告数：$N_{1} = 8000$。\n- 使用其他药物的总报告数：$N_{0} = 160000$。\n- PT $1$（例如，室性心律失常）：$a_{1} = 120$, $c_{1} = 480$。\n- PT $2$（例如，心电图QT间期延长）：$a_{2} = 35$, $c_{2} = 80$。\n- PT $3$（例如，尖端扭转型室性心动过速）：$a_{3} = 12$, $c_{3} = 20$。\n\n从单个分层中PRR作为风险比的定义出发，并假设在各PT分层间存在一个固定效应的共同风险比，请根据第一性原理推导用于汇总SMQ范围内PRR的固定效应Mantel–Haenszel合并估计量，并使用上述数据计算其值。然后，简要讨论即使在固定效应假设下，PT分层间的异质性如何通过构成效应和加权效应对汇总估计值产生偏倚。\n\n将您最终的PRR数值四舍五入至四位有效数字，并以无量纲量的形式表示。答案只需提供最终的数值。",
            "solution": "本题要求推导并计算跨越三个由首选术语（PT）定义的分层的报告比值比（PRR）的Mantel-Haenszel合并估计量，并讨论潜在的偏倚。\n\n**1. 推导与计算**\n\n报告比值比（PRR）被定义为一种风险比（Risk Ratio, RR），即暴露组中的事件比例与非暴露组中事件比例的比值。对于分层数据，Mantel-Haenszel (MH) 方法提供了一种计算共同风险比的加权平均估计量。\n\n对于第 $i$ 个分层（即第 $i$ 个PT），$2 \\times 2$ 表如下：\n| | PT $i$ 出现 | PT $i$ 未出现 | 总计 |\n| :--- | :--- | :--- | :--- |\n| 药物 D | $a_i$ | $b_i$ | $N_1 = a_i+b_i$ |\n| 其他药物 | $c_i$ | $d_i$ | $N_0 = c_i+d_i$ |\n| 总计 | $M_{1i}=a_i+c_i$ | $M_{0i}=b_i+d_i$ | $T_i = N_1+N_0$ |\n\nMantel-Haenszel合并风险比的公式为：\n$$ \\text{PRR}_{\\text{MH}} = \\frac{\\sum_{i} R_i}{\\sum_{i} S_i} = \\frac{\\sum_{i} a_i(c_i+d_i)/T_i}{\\sum_{i} c_i(a_i+b_i)/T_i} $$\n\n在本问题中，样本量 $N_1$（药物 D 的报告总数）和 $N_0$（其他药物的报告总数）在所有分层中是固定的。因此，$T_i = N_1 + N_0$ 也是一个常数。公式可以简化：\n$$ \\text{PRR}_{\\text{MH}} = \\frac{\\sum_{i} a_i N_0 / T_i}{\\sum_{i} c_i N_1 / T_i} = \\frac{(N_0/T_i) \\sum_{i} a_i}{(N_1/T_i) \\sum_{i} c_i} = \\frac{N_0 \\sum_{i} a_i}{N_1 \\sum_{i} c_i} $$\n这表明，在这种特定情况下（即分层不改变暴露组和非暴露组的总人数），MH估计量等于对数据进行简单汇总后计算的“粗”PRR。\n\n现在，我们代入数据进行计算：\n- 药物 D 的总报告数 $N_1 = 8000$。\n- 其他药物的总报告数 $N_0 = 160000$。\n- 药物 D 相关的SMQ事件总数 $\\sum a_i = a_1 + a_2 + a_3 = 120 + 35 + 12 = 167$。\n- 其他药物相关的SMQ事件总数 $\\sum c_i = c_1 + c_2 + c_3 = 480 + 80 + 20 = 580$。\n\n代入公式：\n$$ \\text{PRR}_{\\text{MH}} = \\frac{160000 \\times 167}{8000 \\times 580} = \\frac{20 \\times 167}{580} = \\frac{3340}{580} \\approx 5.7586206... $$\n\n四舍五入到四位有效数字，结果为 $5.759$。\n\n**2. 偏倚讨论**\n\n即使在固定效应假设下，合并估计值也可能存在偏倚。主要原因在于**异质性（Heterogeneity）**。\n- **构成效应 (Constitutional Effect)**：固定效应模型假定各PT层之间存在一个共同的PRR。然而，如果真实的PRR在各层之间存在显著异质性（例如，药物对“室性心律失常”的风险远高于对“QT间期延长”的风险），则该假设不成立。此时，Mantel-Haenszel合并估计值可被看作是各层PRR的某种加权平均，但这个平均值可能不代表任何一个真实的效应大小，其解释性会降低。\n- **加权效应 (Weighting Effect)**：MH估计量的权重（$c_i N_1 / T_i$）取决于各层中的事件数和样本量。如果某个基线报告频率非常高的PT（即$c_i$很大）其PRR恰好与其他PT不同，那么这个PT将对合并估计值产生不成比例的影响，可能导致合并值偏离“典型”的效应大小。\n\n因此，在解释合并PRR时，必须同时检查各层PRR的一致性，并进行异质性检验（如Cochran's Q检验），以评估合并分析的合理性。",
            "answer": "$$\\boxed{5.759}$$"
        },
        {
            "introduction": "药物警戒并非一次性的静态分析，而是一个持续的动态监测过程。本练习将视角从横断面分析转向动态的时间序列监测。你将亲手构建一个指数加权移动平均（Exponentially Weighted Moving Average, EWMA）控制图——这是一种强大的统计过程控制工具，用于从月度报告流中发现新出现的信号，并学习如何推导和应用时变控制限。",
            "id": "4520144",
            "problem": "要求您基于概率论和统计学的第一性原理，为药物警戒信号检测构建并应用指数加权移动平均 (EWMA) 控制图。考虑一个每月监测的药物-事件对。设第 $t$ 个月的观测计数为 $X_t$，零假设（无真实变化）下的期望计数为 $\\mu_t$。假设在零假设下，$X_t$ 是独立的，并服从均值为 $\\mu_t$ 的泊松分布，即 $X_t \\sim \\text{Poisson}(\\mu_t)$，且序列 $\\{X_t\\}$ 随时间独立。\n\n从期望的线性性质、独立随机变量的方差以及 EWMA 统计量的基本定义出发：\n- 通过平滑参数 $\\lambda \\in (0,1)$ 递归定义 EWMA 统计量 $Z_t$ 为 $Z_t = \\lambda X_t + (1-\\lambda) Z_{t-1}$，启动值为 $Z_0 = \\mu_1$。\n- 使用期望的线性性质和独立性假设，从第一性原理出发递归推导期望值 $m_t = \\mathbb{E}[Z_t]$。\n- 使用 $\\text{Var}(aY + bZ) = a^2 \\text{Var}(Y) + b^2 \\text{Var}(Z) + 2ab\\,\\text{Cov}(Y,Z)$、 $X_t$ 与过去观测值的独立性，以及对于泊松随机变量 $Y \\sim \\text{Poisson}(\\theta)$ 有 $\\text{Var}(Y) = \\theta$ 这一事实，从第一性原理出发递归推导方差 $v_t = \\text{Var}(Z_t)$。\n- 使用这些推导出的递归式，计算每个月 $t$ 的时变双侧控制限 $m_t \\pm L \\sqrt{v_t}$，其中宽度乘数 $L = 3$。如果在第 $t$ 个月，$Z_t > m_t + L \\sqrt{v_t}$，则标记一个潜在的上行信号；如果在第 $t$ 个月，$Z_t < m_t - L \\sqrt{v_t}$，则标记一个潜在的下行信号。\n\n取平滑参数 $\\lambda = 0.2$。所有量均为无量纲的月度计数；无需物理单位。不涉及角度。不涉及百分比。\n\n为以下三个测试案例（每个案例跨度为24个月）实现此逻辑。对于每个案例，将序列 $\\{\\mu_t\\}$ 视为已知和固定的，并将观测计数 $\\{x_t\\}$ 作为给定数据代入 EWMA 递归式。\n\n测试套件：\n- 案例1（恒定基线，单个极端尖峰）：\n    - 对于 $t=1,\\dots,24$，$\\mu_t = 5$。\n    - $x_t = [5,5,5,5,5,5,5,5,5,5,5,5,50,5,5,5,5,5,5,5,5,5,5,5]$。\n- 案例2（极低基线，零值中的单个尖峰）：\n    - 对于 $t=1,\\dots,24$，$\\mu_t = 0.2$。\n    - $x_t = [0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0]$。\n- 案例3（阶梯式变化的基线，阶跃变化后的单个极端尖峰）：\n    - $\\mu_t = [2,2,2,2,2,2,4,4,4,4,4,4,6,6,6,6,6,6,8,8,8,8,8,8]$。\n    - $x_t$ 在所有月份都等于 $\\mu_t$，除了第19个月出现一个尖峰，即 $x_t = [2,2,2,2,2,2,4,4,4,4,4,4,6,6,6,6,6,6,40,8,8,8,8,8]$。\n\n要求的计算步骤：\n1. 对于每个案例，初始化 $Z_0 = \\mu_1$，设置 $m_0 = \\mu_1$ 和 $v_0 = 0$。\n2. 对于 $t = 1,\\dots,24$，仅使用基本定律（期望的线性性质和独立和的方差）以及泊松计数的 $\\text{Var}(X_t) = \\mu_t$ 来更新 $Z_t$、$m_t$ 和 $v_t$。\n3. 在每个 $t$，计算上、下控制限，如果出现如上定义的潜在信号，则记录月份索引 $t$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个由三个元素（每个测试案例一个）组成的列表的类JSON表示。\n- 每个元素本身必须是一个包含两个列表的列表：第一个是出现上行信号的月份列表（使用从1开始的索引），第二个是出现下行信号的月份列表。\n- 例如，输出格式必须为：\"[[ [u1_1,u1_2,...], [l1_1,l1_2,...] ], [ [u2_1,...], [l2_1,...] ], [ [u3_1,...], [l3_1,...] ]]\"，不含空格。",
            "solution": "我们从 $Z_t$ 的定义出发，应用期望和方差的基本性质来构建指数加权移动平均 (EWMA) 统计量及其控制限。\n\n指数加权移动平均 (EWMA) 的定义：\n对于平滑参数 $\\lambda \\in (0,1)$ 和启动值 $Z_0 = \\mu_1$，定义递归统计量\n$$\nZ_t = \\lambda X_t + (1 - \\lambda) Z_{t-1}, \\quad t = 1,2,\\dots,24.\n$$\n这是指数加权移动平均 (EWMA) 的标准定义，它强调最近的观测值，同时保留过去的信息。\n\n零假设下的假设（除了指定的 $\\mu_t$ 外，基础过程没有真实变化）：\n- 在时间 $t$ 的观测计数 $X_t$ 是一个均值为 $\\mu_t$ 的泊松随机变量，即 $X_t \\sim \\text{Poisson}(\\mu_t)$。\n- 序列 $\\{X_t\\}$ 随时间独立。\n\n我们现在从第一性原理出发推导期望值 $m_t = \\mathbb{E}[Z_t]$ 和方差 $v_t = \\text{Var}(Z_t)$。\n\n期望值递归式：\n利用期望的线性性质，\n$$\nm_t = \\mathbb{E}[Z_t] = \\mathbb{E}[\\lambda X_t + (1-\\lambda) Z_{t-1}]\n= \\lambda \\mathbb{E}[X_t] + (1-\\lambda) \\mathbb{E}[Z_{t-1}]\n= \\lambda \\mu_t + (1-\\lambda) m_{t-1},\n$$\n初始化为 $m_0 = \\mathbb{E}[Z_0] = \\mu_1$，因为 $Z_0$ 固定为 $\\mu_1$。\n\n方差递归式：\n使用线性组合的方差和独立性假设，注意到 $Z_{t-1}$ 仅依赖于 $X_1,\\dots,X_{t-1}$，而 $X_t$ 与过去无关。因此 $\\text{Cov}(Z_{t-1}, X_t) = 0$。使用 $\\text{Var}(aY + bZ) = a^2 \\text{Var}(Y) + b^2 \\text{Var}(Z) + 2ab \\,\\text{Cov}(Y,Z)$，我们得到\n$$\nv_t = \\text{Var}(Z_t) = \\text{Var}(\\lambda X_t + (1-\\lambda) Z_{t-1})\n= \\lambda^2 \\text{Var}(X_t) + (1-\\lambda)^2 \\text{Var}(Z_{t-1}) + 2 \\lambda (1-\\lambda) \\text{Cov}(X_t, Z_{t-1}).\n$$\n根据独立性，$\\text{Cov}(X_t, Z_{t-1}) = 0$。对于泊松分布的 $X_t$，$\\text{Var}(X_t) = \\mu_t$。因此，\n$$\nv_t = (1-\\lambda)^2 v_{t-1} + \\lambda^2 \\mu_t,\n$$\n初始化为 $v_0 = \\text{Var}(Z_0) = 0$，因为 $Z_0$ 是一个固定值。\n\n时间 $t$ 的控制限：\n在每个时间 $t$，我们计算时变的中心线和控制限如下\n$$\n\\text{中心线: } m_t, \\quad\n\\text{标准差: } s_t = \\sqrt{v_t}, \\quad\n\\text{上控制限: } \\text{UCL}_t = m_t + L s_t, \\quad\n\\text{下控制限: } \\text{LCL}_t = m_t - L s_t,\n$$\n其中 $L = 3$ 是宽度乘数。\n\n信号逻辑：\n- 如果在第 $t$ 个月 $Z_t > \\text{UCL}_t$，则为上行信号。\n- 如果在第 $t$ 个月 $Z_t < \\text{LCL}_t$，则为下行信号。\n\n现在我们将此应用于指定的测试案例，其中 $\\lambda = 0.2$。通过数值计算，我们得出每个案例的结果。\n\n- **案例 1 结果**: 上行信号出现在月份 $[13,14,15,16,17,18,19]$。无下行信号。\n- **案例 2 结果**: 上行信号出现在月份 $[11,12,13]$。无下行信号。\n- **案例 3 结果**: 上行信号出现在月份 $[19,20,21,22]$。无下行信号。\n\n汇总结果的JSON字符串为：`[[[13,14,15,16,17,18,19],[]],[[11,12,13],[]],[[19,20,21,22],[]]]`。\n\n以下是实现该逻辑的Python代码。\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport json\nimport math\n\ndef ewma_signals(x, mu, lam=0.2, L=3.0):\n    n = len(x)\n    # Initialize\n    z_prev = mu[0]\n    m_prev = mu[0]\n    v_prev = 0.0\n\n    upper_signal_months = []\n    lower_signal_months = []\n\n    for t in range(1, n + 1):\n        xt = x[t - 1]\n        mut = mu[t - 1]\n\n        # Update EWMA\n        z_t = lam * xt + (1.0 - lam) * z_prev\n\n        # Update mean and variance under null\n        m_t = (1.0 - lam) * m_prev + lam * mut\n        v_t = (1.0 - lam) ** 2 * v_prev + (lam ** 2) * mut\n\n        s_t = math.sqrt(v_t)\n        ucl = m_t + L * s_t\n        lcl = m_t - L * s_t\n\n        # Check signals (1-based month index)\n        if z_t > ucl:\n            upper_signal_months.append(t)\n        if z_t  lcl:\n            lower_signal_months.append(t)\n\n        # Prepare for next iteration\n        z_prev = z_t\n        m_prev = m_t\n        v_prev = v_t\n\n    return upper_signal_months, lower_signal_months\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Case 1\n    mu1 = [5.0] * 24\n    x1 = [5,5,5,5,5,5,5,5,5,5,5,5,50,5,5,5,5,5,5,5,5,5,5,5]\n\n    # Case 2\n    mu2 = [0.2] * 24\n    x2 = [0,0,0,0,0,0,0,0,0,0,5,0,0,0,0,0,0,0,0,0,0,0,0,0]\n\n    # Case 3\n    mu3 = [2.0,2.0,2.0,2.0,2.0,2.0,4.0,4.0,4.0,4.0,4.0,4.0,6.0,6.0,6.0,6.0,6.0,6.0,8.0,8.0,8.0,8.0,8.0,8.0]\n    x3 = [2,2,2,2,2,2,4,4,4,4,4,4,6,6,6,6,6,6,40,8,8,8,8,8]\n\n    lam = 0.2\n    L = 3.0\n\n    results = []\n    for x, mu in [(x1, mu1), (x2, mu2), (x3, mu3)]:\n        upper, lower = ewma_signals(x, mu, lam=lam, L=L)\n        results.append([upper, lower])\n\n    # Final print statement in the exact required format (no spaces).\n    # This would be printed by the function if run.\n    # print(json.dumps(results, separators=(',',':')))\n\n# The expected output from running solve() is:\n# [[[13,14,15,16,17,18,19],[]],[[11,12,13],[]],[[19,20,21,22],[]]]]\n```",
            "answer": "$$\\boxed{\\texttt{[[[13,14,15,16,17,18,19],[]],[[11,12,13],[]],[[19,20,21,22],[]]]}}$$"
        }
    ]
}