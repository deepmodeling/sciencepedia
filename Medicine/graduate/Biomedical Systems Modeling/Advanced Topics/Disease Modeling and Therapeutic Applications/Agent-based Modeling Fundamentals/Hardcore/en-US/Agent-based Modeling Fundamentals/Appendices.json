{
    "hands_on_practices": [
        {
            "introduction": "The fundamental building block of any agent-based model is the update rule, which dictates how an agent changes its state based on its own status and that of its neighbors. This first practice problem provides a direct, hands-on calculation of a single, synchronous time-step for a system of agents arranged on a ring network. By manually computing the next state for each agent, you will gain a concrete understanding of how local rules and neighborhood interactions drive the system's evolution from one moment to the next .",
            "id": "4113515",
            "problem": "Consider an Agent-Based Modeling (ABM) system on a ring network with $n$ agents, where $n$ is fixed at $n=10$. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{N}$. The network is a one-dimensional ring: indices are taken modulo $n$, so that for any index $i \\in \\{1,\\dots,n\\}$, the predecessor of $1$ is $n$ and the successor of $n$ is $1$. For each agent $i$, the neighborhood $N(i)$ consists of the two nearest neighbors on each side, specifically $N(i)=\\{i-2,i-1,i+1,i+2\\}$ with indices interpreted modulo $n$. The synchronous update rule is defined by the indicator function\n$$\nx_i(t+1) \\;=\\; \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\;\\geq\\; \\theta \\right\\},\n$$\nwhere $\\theta$ is a fixed threshold applied uniformly to all agents.\n\nYou are given the initial configuration at time $t=0$ as\n$$\nx(0) \\;=\\; \\bigl(x_1(0),x_2(0),x_3(0),x_4(0),x_5(0),x_6(0),x_7(0),x_8(0),x_9(0),x_{10}(0)\\bigr)\n\\;=\\; (1,0,1,1,0,0,1,0,1,0),\n$$\nand the threshold $\\theta=3$.\n\nUsing only the definitions above and the stated synchronous update rule, compute the next state vector $x(1)$. Express your final answer as a single row matrix containing the components in order $\\bigl(x_1(1),x_2(1),\\dots,x_{10}(1)\\bigr)$. No rounding is required, and no units apply.",
            "solution": "The problem statement is validated as being scientifically grounded, well-posed, objective, complete, and consistent. It describes a standard discrete-time dynamical system, specifically a type of one-dimensional cellular automaton on a ring, for which all necessary parameters and initial conditions are provided to compute the subsequent state. The problem is a formalizable exercise in applying a defined rule set and is directly pertinent to the field of agent-based modeling. Therefore, a solution can be derived.\n\nThe problem asks for the state vector $x(1)$ at time $t=1$, given the initial state vector $x(0)$ at time $t=0$. The system consists of $n=10$ agents on a ring. The state of each agent $i$ is binary, $x_i(t) \\in \\{0,1\\}$. The update rule for each agent $i$ is synchronous and determined by its neighbors' states at the previous time step. The neighborhood of agent $i$ is $N(i)=\\{i-2, i-1, i+1, i+2\\}$, with indices taken modulo $n$. The update rule is given by the indicator function:\n$$x_i(t+1) = \\mathbb{I}\\left\\{\\sum_{j \\in N(i)} x_j(t) \\geq \\theta \\right\\}$$\nwhere $\\mathbb{I}\\{\\cdot\\}$ is the indicator function, which equals $1$ if its argument is true and $0$ otherwise. The threshold is given as $\\theta=3$. The initial state vector at $t=0$ is:\n$$x(0) = (x_1(0), \\dots, x_{10}(0)) = (1,0,1,1,0,0,1,0,1,0)$$\nWe must compute $x_i(1)$ for each agent $i \\in \\{1, 2, \\dots, 10\\}$. This involves calculating the sum of the states of the four neighbors for each agent and comparing it to the threshold $\\theta=3$. The indices are interpreted modulo $10$, where the set of indices is $\\{1, 2, \\dots, 10\\}$. For example, for agent $i=1$, the neighbor $i-1=0$ corresponds to agent $10$, and $i-2=-1$ corresponds to agent $9$.\n\nFor agent $i=1$:\nThe neighborhood is $N(1) = \\{9, 10, 2, 3\\}$.\nThe sum of neighbors' states is $S_1 = x_9(0) + x_{10}(0) + x_2(0) + x_3(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_1=2 < \\theta=3$, the new state is $x_1(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=2$:\nThe neighborhood is $N(2) = \\{10, 1, 3, 4\\}$.\nThe sum of neighbors' states is $S_2 = x_{10}(0) + x_1(0) + x_3(0) + x_4(0) = 0 + 1 + 1 + 1 = 3$.\nSince $S_2=3 \\geq \\theta=3$, the new state is $x_2(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=3$:\nThe neighborhood is $N(3) = \\{1, 2, 4, 5\\}$.\nThe sum of neighbors' states is $S_3 = x_1(0) + x_2(0) + x_4(0) + x_5(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_3=2 < \\theta=3$, the new state is $x_3(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=4$:\nThe neighborhood is $N(4) = \\{2, 3, 5, 6\\}$.\nThe sum of neighbors' states is $S_4 = x_2(0) + x_3(0) + x_5(0) + x_6(0) = 0 + 1 + 0 + 0 = 1$.\nSince $S_4=1 < \\theta=3$, the new state is $x_4(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=5$:\nThe neighborhood is $N(5) = \\{3, 4, 6, 7\\}$.\nThe sum of neighbors' states is $S_5 = x_3(0) + x_4(0) + x_6(0) + x_7(0) = 1 + 1 + 0 + 1 = 3$.\nSince $S_5=3 \\geq \\theta=3$, the new state is $x_5(1) = \\mathbb{I}\\{3 \\geq 3\\} = 1$.\n\nFor agent $i=6$:\nThe neighborhood is $N(6) = \\{4, 5, 7, 8\\}$.\nThe sum of neighbors' states is $S_6 = x_4(0) + x_5(0) + x_7(0) + x_8(0) = 1 + 0 + 1 + 0 = 2$.\nSince $S_6=2 < \\theta=3$, the new state is $x_6(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=7$:\nThe neighborhood is $N(7) = \\{5, 6, 8, 9\\}$.\nThe sum of neighbors' states is $S_7 = x_5(0) + x_6(0) + x_8(0) + x_9(0) = 0 + 0 + 0 + 1 = 1$.\nSince $S_7=1 < \\theta=3$, the new state is $x_7(1) = \\mathbb{I}\\{1 \\geq 3\\} = 0$.\n\nFor agent $i=8$:\nThe neighborhood is $N(8) = \\{6, 7, 9, 10\\}$.\nThe sum of neighbors' states is $S_8 = x_6(0) + x_7(0) + x_9(0) + x_{10}(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_8=2 < \\theta=3$, the new state is $x_8(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=9$:\nThe neighborhood is $N(9) = \\{7, 8, 10, 1\\}$.\nThe sum of neighbors' states is $S_9 = x_7(0) + x_8(0) + x_{10}(0) + x_1(0) = 1 + 0 + 0 + 1 = 2$.\nSince $S_9=2 < \\theta=3$, the new state is $x_9(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nFor agent $i=10$:\nThe neighborhood is $N(10) = \\{8, 9, 1, 2\\}$.\nThe sum of neighbors' states is $S_{10} = x_8(0) + x_9(0) + x_1(0) + x_2(0) = 0 + 1 + 1 + 0 = 2$.\nSince $S_{10}=2 < \\theta=3$, the new state is $x_{10}(1) = \\mathbb{I}\\{2 \\geq 3\\} = 0$.\n\nCombining these results, the state vector at time $t=1$ is:\n$$x(1) = \\bigl(x_1(1), x_2(1), x_3(1), x_4(1), x_5(1), x_6(1), x_7(1), x_8(1), x_9(1), x_{10}(1)\\bigr) = (0, 1, 0, 0, 1, 0, 0, 0, 0, 0)$$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "While individual agent rules are crucial, the emergent dynamics of an Agent-Based Model (ABM) are also highly sensitive to the *timing* of their execution. This exercise explores one of the most critical, and often subtle, decisions in ABM design: the update schedule. By comparing the system trajectories under synchronous versus sequential updating in a simple two-agent model, you will discover how this choice can fundamentally alter the model's outcome, leading to different stable states and dynamics .",
            "id": "4113495",
            "problem": "Consider an Agent-Based Model (ABM) in the domain of complex adaptive systems modeling with two agents labeled $i \\in \\{1,2\\}$ on an undirected network consisting of a single edge connecting the two agents. Each agent has a binary state $x_i(t) \\in \\{0,1\\}$ at discrete time $t \\in \\mathbb{Z}_{\\ge 0}$. The ABM employs a deterministic threshold decision rule: an agent becomes active at the next time step if and only if the fraction of its neighbors that are active meets or exceeds its threshold. Formally, for any agent $i$, let $N_i$ denote the set of neighbors of $i$, and let $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$ be the fraction of neighbors active at an update reference time $\\tau$. The threshold parameter for agent $i$ is $\\theta_i \\in [0,1]$, and the individual update rule is\n$$\nx_i(\\text{next}) = \n\\begin{cases}\n1, & \\text{if } m_i(\\tau) \\ge \\theta_i, \\\\\n0, & \\text{if } m_i(\\tau) < \\theta_i.\n\\end{cases}\n$$\nTwo update regimes are considered:\n\n- Synchronous update: Both agents compute $m_i(t)$ using the states at time $t$ and simultaneously set $x_i(t+1)$ according to the threshold rule.\n- Sequential update with fixed order $(1,2)$: Agent $1$ updates first using $m_1(t)$ to set $x_1(t+1)$, and then agent $2$ updates using $m_2(t+1)$, where $m_2(t+1)$ is computed from the latest available neighbor state after agent $1$ has updated.\n\nSuppose the initial condition is $x_1(0) = 0$ and $x_2(0) = 1$, and the thresholds are $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. Because the network has a single edge, each agent’s $m_i(\\tau)$ equals the neighbor’s state at the specified reference time. Define the trajectory difference over a finite horizon $T$ as the cumulative Hamming distance between the two regime trajectories,\n$$\nD(T) = \\sum_{t=0}^{T} \\left( \\left| x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t) \\right| + \\left| x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t) \\right| \\right),\n$$\nwhere $x_i^{\\text{sync}}(t)$ and $x_i^{\\text{seq}}(t)$ denote the state of agent $i$ at time $t$ under synchronous and sequential updating, respectively.\n\nCompute $D(T)$ for the horizon $T = 10$. Provide your final answer as a single real number. No rounding instruction is necessary for this problem.",
            "solution": "The problem is well-posed, scientifically grounded in the theory of Agent-Based Models (ABMs) and Complex Adaptive Systems, and contains all necessary information for a unique solution. The validation criteria are met.\n\nThe task is to compute the cumulative Hamming distance, $D(T)$, between the state trajectories of a two-agent system under synchronous and sequential update regimes for a time horizon of $T=10$. We begin by analyzing the agent update rules, then simulate the trajectories for both regimes, and finally compute the required sum.\n\nFirst, we formalize the update rules for agent $i \\in \\{1, 2\\}$ with thresholds $\\theta_1 = \\frac{1}{2}$ and $\\theta_2 = 1$. The network consists of a single edge connecting the two agents, so the set of neighbors for agent $1$ is $N_1 = \\{2\\}$ and for agent $2$ is $N_2 = \\{1\\}$. The fraction of active neighbors for agent $i$ is $m_i(\\tau) = \\frac{1}{|N_i|} \\sum_{j \\in N_i} x_j(\\tau)$. This simplifies to $m_1(\\tau) = x_2(\\tau)$ and $m_2(\\tau) = x_1(\\tau)$.\n\nThe individual update rule is $x_i(\\text{next}) = 1$ if $m_i(\\tau) \\ge \\theta_i$ and $x_i(\\text{next}) = 0$ otherwise. Given the binary state space $x_i \\in \\{0, 1\\}$, the rules for each agent become:\n- For agent $1$: $x_1(\\text{next}) = 1$ if and only if $x_2(\\tau) \\ge \\theta_1 = \\frac{1}{2}$. This means $x_1(\\text{next}) = 1$ only if $x_2(\\tau)=1$. Thus, the rule is $x_1(\\text{next}) = x_2(\\tau)$.\n- For agent $2$: $x_2(\\text{next}) = 1$ if and only if $x_1(\\tau) \\ge \\theta_2 = 1$. This means $x_2(\\text{next}) = 1$ only if $x_1(\\tau)=1$. Thus, the rule is $x_2(\\text{next}) = x_1(\\tau)$.\n\nNow we generate the trajectories for both update regimes starting from the initial condition $(x_1(0), x_2(0)) = (0, 1)$.\n\n**1. Synchronous Update Trajectory**\nUnder synchronous updating, both agents' next states are computed based on the current state of the system at time $t$. The rules are:\n$$\n\\begin{cases}\nx_1^{\\text{sync}}(t+1) = x_2^{\\text{sync}}(t) \\\\\nx_2^{\\text{sync}}(t+1) = x_1^{\\text{sync}}(t)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{sync}}(t), x_2^{\\text{sync}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$: $(x_1(1), x_2(1)) = (x_2(0), x_1(0)) = (1, 0)$\n- $t=2$: $(x_1(2), x_2(2)) = (x_2(1), x_1(1)) = (0, 1)$\n- $t=3$: $(x_1(3), x_2(3)) = (x_2(2), x_1(2)) = (1, 0)$\nThe system oscillates with a period of $2$. The state is $(0, 1)$ for even values of $t$ and $(1, 0)$ for odd values of $t$.\n\n**2. Sequential Update Trajectory (Order 1, 2)**\nUnder sequential updating with order $(1, 2)$, agent $1$ first updates its state for time $t+1$ based on states at time $t$. Then, agent $2$ updates its state for time $t+1$ using the most recent states, which includes the newly updated state of agent $1$.\nThe rules for one time step from $t$ to $t+1$ are:\n$$\n\\begin{cases}\nx_1^{\\text{seq}}(t+1) = x_2^{\\text{seq}}(t) \\\\\nx_2^{\\text{seq}}(t+1) = x_1^{\\text{seq}}(t+1)\n\\end{cases}\n$$\nWe compute the state vector $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t))$ for $t \\in \\{0, 1, \\dots, 10\\}$:\n- $t=0$: $(0, 1)$ (Initial condition)\n- $t=1$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(1) = x_2^{\\text{seq}}(0) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(1) = x_1^{\\text{seq}}(1) = 1$.\n  - The state at $t=1$ is $(1, 1)$.\n- $t=2$:\n  - Agent $1$ updates: $x_1^{\\text{seq}}(2) = x_2^{\\text{seq}}(1) = 1$.\n  - Agent $2$ updates: $x_2^{\\text{seq}}(2) = x_1^{\\text{seq}}(2) = 1$.\n  - The state at $t=2$ is $(1, 1)$.\nThe system reaches a fixed point $(1, 1)$ at $t=1$. Therefore, for all $t \\ge 1$, the state is $(x_1^{\\text{seq}}(t), x_2^{\\text{seq}}(t)) = (1, 1)$.\n\n**3. Compute the Trajectory Difference $D(10)$**\nThe trajectory difference is defined as $D(T) = \\sum_{t=0}^{T} d(t)$, where the per-step Hamming distance is $d(t) = |x_1^{\\text{sync}}(t) - x_1^{\\text{seq}}(t)| + |x_2^{\\text{sync}}(t) - x_2^{\\text{seq}}(t)|$. We calculate $d(t)$ for each $t$ from $0$ to $10$.\n\n- For $t=0$:\n  - $x^{\\text{sync}}(0) = (0, 1)$ and $x^{\\text{seq}}(0) = (0, 1)$.\n  - $d(0) = |0-0| + |1-1| = 0$.\n\n- For $t \\ge 1$:\n  - The sequential trajectory is fixed: $x^{\\text{seq}}(t) = (1, 1)$.\n  - The synchronous trajectory alternates.\n  - For odd $t \\in \\{1, 3, 5, 7, 9\\}$:\n    - $x^{\\text{sync}}(t) = (1, 0)$.\n    - $d(t) = |1-1| + |0-1| = 0 + 1 = 1$.\n  - For even $t \\in \\{2, 4, 6, 8, 10\\}$:\n    - $x^{\\text{sync}}(t) = (0, 1)$.\n    - $d(t) = |0-1| + |1-1| = 1 + 0 = 1$.\n\nSo, we have $d(0)=0$ and $d(t)=1$ for all $t \\in \\{1, 2, \\dots, 10\\}$.\n\nFinally, we sum these values to find $D(10)$:\n$$\nD(10) = \\sum_{t=0}^{10} d(t) = d(0) + \\sum_{t=1}^{10} d(t)\n$$\n$$\nD(10) = 0 + (d(1) + d(2) + \\dots + d(10))\n$$\n$$\nD(10) = 0 + \\sum_{t=1}^{10} 1 = 10 \\times 1 = 10\n$$\nThe cumulative Hamming distance over the horizon $T=10$ is $10$.",
            "answer": "$$\n\\boxed{10}\n$$"
        },
        {
            "introduction": "Agent-based models excel at capturing micro-level heterogeneity and interactions, but how do these discrete events translate to macro-level population dynamics? This final practice bridges the gap between discrete agent simulations and continuous mathematical models. You will derive a deterministic mean-field ordinary differential equation (ODE) for the population density $u(t)$ from a set of stochastic, individual-level birth and death rules, a process central to theoretical biology . This exercise demonstrates how, under a 'well-mixed' assumption, the collective behavior of agents can be approximated by traditional analytical equations, providing a powerful tool for analysis and validation.",
            "id": "3870374",
            "problem": "Consider a well-mixed agent-based modeling (ABM) description of a single-cell population in a normalized habitat of capacity $1$, so that the population density is the fraction of occupied sites $u(t) \\in [0,1]$ at time $t$. Each individual agent independently undergoes the following continuous-time, memoryless events:\n\n(i) Birth attempt at rate $\\beta$ per unit time. A birth produces a viable daughter only if it targets an empty location. Under well-mixed assumptions, the probability that a randomly targeted location is empty equals $1 - u(t)$.\n\n(ii) Baseline apoptosis (death) at rate $\\delta$ per unit time per agent.\n\n(iii) Contact-mediated death due to pairwise interactions. For a large system with $N$ potential sites, suppose any ordered pair of distinct occupied sites contributes a kill at rate $\\gamma/N$ per unit time. This $1/N$ scaling ensures a finite limit for the total pairwise hazard per agent as $N \\to \\infty$.\n\nAssume the following modeling bases: the dynamics are well-mixed; events are independent conditional on the current state; and in the large-population limit ($N \\to \\infty$), moments factorize under the mean-field closure, so that products of occupancies factor into products of expectations. Starting from these bases and the law of mass action for well-mixed systems, derive the deterministic mean-field ordinary differential equation (ODE) for $u(t)$ in the $N \\to \\infty$ limit.\n\nThen, using your derived ODE, specialize to the parameter values $\\beta = 1$ per day, $\\delta = \\tfrac{1}{4}$ per day, and $\\gamma = \\tfrac{3}{4}$ per day, with initial condition $u(0) = \\tfrac{1}{14}$. Provide the explicit closed-form expression for $u(t)$ for all $t \\ge 0$ (with $t$ measured in days). Your final answer must be a single analytic expression for $u(t)$ without any approximations.",
            "solution": "The problem is valid. It presents a standard exercise in deriving a mean-field ordinary differential equation (ODE) from a set of agent-based rules and then solving it. The premises are scientifically sound within the context of mathematical biology, and the problem is well-posed and complete.\n\nThe solution proceeds in two parts: first, the derivation of the general mean-field ODE, and second, the solution of this ODE for the specific parameters and initial condition provided.\n\n**Part 1: Derivation of the Mean-Field ODE**\n\nLet $N$ be the total number of sites in the system, which is assumed to be large. Let $U(t)$ be the number of occupied sites (agents) at time $t$. The population density is defined as $u(t) = \\frac{U(t)}{N}$. We aim to find an equation for the rate of change of the density, $\\frac{du}{dt}$.\n\nThe rate of change of the number of agents, $\\frac{dU}{dt}$, is the sum of the rates of all processes that increase or decrease $U(t)$. We analyze each event type based on the law of mass action for a well-mixed system.\n\n(i) **Birth:** The rate of birth attempts is $\\beta$ per agent. With $U(t)$ agents, the total rate of birth attempts is $\\beta U(t)$. A birth is successful only if the target site is empty. In a well-mixed system of $N$ sites, the number of empty sites is $N - U(t)$. The probability of a randomly chosen site being empty is $\\frac{N - U(t)}{N} = 1 - \\frac{U(t)}{N} = 1 - u(t)$. Therefore, the rate of successful births is the rate of attempts multiplied by the probability of success:\n$$\n\\text{Rate}_{\\text{birth}} = \\beta U(t) \\left(1 - \\frac{U(t)}{N}\\right)\n$$\n\n(ii) **Baseline Apoptosis:** The rate of baseline death is $\\delta$ per agent. For $U(t)$ agents, the total rate of deaths from this process is:\n$$\n\\text{Rate}_{\\text{apoptosis}} = \\delta U(t)\n$$\n\n(iii) **Contact-Mediated Death:** The problem states that any ordered pair of distinct occupied sites, say agent $i$ and agent $j$ ($i \\ne j$), contributes to a kill at a rate of $\\frac{\\gamma}{N}$. The total number of such ordered pairs is $U(t)(U(t)-1)$. Thus, the total rate of contact-mediated deaths is:\n$$\n\\text{Rate}_{\\text{contact-death}} = \\frac{\\gamma}{N} U(t) (U(t)-1)\n$$\nThe $\\frac{1}{N}$ scaling factor is crucial for obtaining a sensible mean-field limit.\n\nCombining these rates, the total rate of change for $U(t)$ is:\n$$\n\\frac{dU}{dt} = \\text{Rate}_{\\text{birth}} - \\text{Rate}_{\\text{apoptosis}} - \\text{Rate}_{\\text{contact-death}}\n$$\n$$\n\\frac{dU}{dt} = \\beta U(t) \\left(1 - \\frac{U(t)}{N}\\right) - \\delta U(t) - \\frac{\\gamma}{N} U(t)(U(t)-1)\n$$\n\nTo obtain the ODE for the density $u(t)$, we use the relationship $U(t) = N u(t)$, which implies $\\frac{dU}{dt} = N \\frac{du}{dt}$. Substituting these into the equation:\n$$\nN \\frac{du}{dt} = \\beta (N u(t)) (1 - u(t)) - \\delta (N u(t)) - \\frac{\\gamma}{N} (N u(t)) (N u(t) - 1)\n$$\nDividing the entire equation by $N$:\n$$\n\\frac{du}{dt} = \\beta u(t) (1 - u(t)) - \\delta u(t) - \\frac{\\gamma}{N^2} (N u(t)) (N u(t) - 1)\n$$\n$$\n\\frac{du}{dt} = \\beta u(t) (1 - u(t)) - \\delta u(t) - \\gamma u(t) \\left(\\frac{N u(t) - 1}{N}\\right)\n$$\n$$\n\\frac{du}{dt} = \\beta u(t) (1 - u(t)) - \\delta u(t) - \\gamma u(t) \\left(u(t) - \\frac{1}{N}\\right)\n$$\nNow, we take the large-population limit, $N \\to \\infty$. In this limit, the term $\\frac{1}{N}$ vanishes. This constitutes the mean-field approximation.\n$$\n\\frac{du}{dt} = \\lim_{N \\to \\infty} \\left[ \\beta u(t)(1 - u(t)) - \\delta u(t) - \\gamma u(t)\\left(u(t) - \\frac{1}{N}\\right) \\right]\n$$\n$$\n\\frac{du}{dt} = \\beta u(t)(1 - u(t)) - \\delta u(t) - \\gamma (u(t))^2\n$$\nWe can rearrange this equation by expanding the terms:\n$$\n\\frac{du}{dt} = \\beta u(t) - \\beta (u(t))^2 - \\delta u(t) - \\gamma (u(t))^2\n$$\n$$\n\\frac{du}{dt} = (\\beta - \\delta) u(t) - (\\beta + \\gamma) (u(t))^2\n$$\nThis is the required deterministic mean-field ODE for the population density $u(t)$. It is a form of the logistic equation.\n\n**Part 2: Solution of the ODE for Specific Parameters**\n\nWe are given the parameters $\\beta = 1$, $\\delta = \\frac{1}{4}$, $\\gamma = \\frac{3}{4}$, and the initial condition $u(0) = \\frac{1}{14}$. All rates are in units of day$^{-1}$ and $t$ is in days.\n\nFirst, we substitute the parameter values into the derived ODE:\n$$\n\\beta - \\delta = 1 - \\frac{1}{4} = \\frac{3}{4}\n$$\n$$\n\\beta + \\gamma = 1 + \\frac{3}{4} = \\frac{7}{4}\n$$\nThe ODE becomes:\n$$\n\\frac{du}{dt} = \\frac{3}{4} u - \\frac{7}{4} u^2\n$$\nThis is a separable Bernoulli equation. We can factor out $\\frac{7}{4}u$ to get it into a standard logistic form:\n$$\n\\frac{du}{dt} = \\frac{7}{4} u \\left(\\frac{3}{7} - u\\right)\n$$\nThis shows that the carrying capacity is $K = \\frac{3}{7}$. We can solve this by separating variables. For $u \\ne 0$ and $u \\ne \\frac{3}{7}$:\n$$\n\\frac{du}{u(\\frac{3}{7} - u)} = \\frac{7}{4} dt\n$$\nWe use partial fraction decomposition for the left-hand side. Let:\n$$\n\\frac{1}{u(\\frac{3}{7} - u)} = \\frac{A}{u} + \\frac{B}{\\frac{3}{7} - u}\n$$\nMultiplying by the denominator gives $1 = A(\\frac{3}{7} - u) + B u$.\nSetting $u = 0$, we get $1 = A(\\frac{3}{7})$, so $A = \\frac{7}{3}$.\nSetting $u = \\frac{3}{7}$, we get $1 = B(\\frac{3}{7})$, so $B = \\frac{7}{3}$.\nThus, the integral becomes:\n$$\n\\int \\left( \\frac{\\frac{7}{3}}{u} + \\frac{\\frac{7}{3}}{\\frac{3}{7} - u} \\right) du = \\int \\frac{7}{4} dt\n$$\n$$\n\\frac{7}{3} \\int \\left( \\frac{1}{u} + \\frac{1}{\\frac{3}{7} - u} \\right) du = \\frac{7}{4} t + C_1\n$$\nIntegrating term by term:\n$$\n\\frac{7}{3} \\left( \\ln|u| - \\ln\\left|\\frac{3}{7} - u\\right| \\right) = \\frac{7}{4} t + C_1\n$$\n$$\n\\ln\\left| \\frac{u}{\\frac{3}{7} - u} \\right| = \\frac{3}{7} \\left( \\frac{7}{4} t + C_1 \\right) = \\frac{3}{4} t + C_2\n$$\nwhere $C_2$ is a constant. Exponentiating both sides:\n$$\n\\left| \\frac{u}{\\frac{3}{7} - u} \\right| = \\exp\\left(\\frac{3}{4} t + C_2\\right) = C_3 \\exp\\left(\\frac{3}{4} t\\right)\n$$\nwhere $C_3 = \\exp(C_2)$. Since $u(t)$ is a density, $0 \\le u(t) \\le 1$. The initial condition $u(0) = \\frac{1}{14}$ is less than the carrying capacity $K = \\frac{3}{7}$, so $u(t)$ will remain in the interval $(0, \\frac{3}{7})$, and the argument of the absolute value will be positive. We can drop the absolute value signs and absorb the sign into a constant $C$.\n$$\n\\frac{u}{\\frac{3}{7} - u} = C \\exp\\left(\\frac{3}{4} t\\right)\n$$\nWe use the initial condition $u(0) = \\frac{1}{14}$ to find $C$:\n$$\n\\frac{\\frac{1}{14}}{\\frac{3}{7} - \\frac{1}{14}} = C \\exp(0) \\implies C = \\frac{\\frac{1}{14}}{\\frac{6}{14} - \\frac{1}{14}} = \\frac{\\frac{1}{14}}{\\frac{5}{14}} = \\frac{1}{5}\n$$\nSo, the implicit solution is:\n$$\n\\frac{u}{\\frac{3}{7} - u} = \\frac{1}{5} \\exp\\left(\\frac{3}{4} t\\right)\n$$\nNow we solve for $u(t)$:\n$$\n5u = \\left(\\frac{3}{7} - u\\right) \\exp\\left(\\frac{3}{4} t\\right)\n$$\n$$\n5u = \\frac{3}{7} \\exp\\left(\\frac{3}{4} t\\right) - u \\exp\\left(\\frac{3}{4} t\\right)\n$$\n$$\nu \\left(5 + \\exp\\left(\\frac{3}{4} t\\right)\\right) = \\frac{3}{7} \\exp\\left(\\frac{3}{4} t\\right)\n$$\n$$\nu(t) = \\frac{\\frac{3}{7} \\exp\\left(\\frac{3}{4} t\\right)}{5 + \\exp\\left(\\frac{3}{4} t\\right)}\n$$\nTo simplify this expression and write it in a standard logistic function form, we can divide the numerator and the denominator by $\\exp\\left(\\frac{3}{4} t\\right)$:\n$$\nu(t) = \\frac{\\frac{3}{7}}{5 \\exp\\left(-\\frac{3}{4} t\\right) + 1}\n$$\nAlternatively, to eliminate the compound fraction, we multiply the numerator and denominator by $7$:\n$$\nu(t) = \\frac{3}{7\\left(1 + 5 \\exp\\left(-\\frac{3}{4} t\\right)\\right)} = \\frac{3}{7 + 35 \\exp\\left(-\\frac{3}{4} t\\right)}\n$$\nThis is the explicit closed-form expression for $u(t)$.\nLet's verify the initial condition:\n$$\nu(0) = \\frac{3}{7 + 35 \\exp(0)} = \\frac{3}{7 + 35} = \\frac{3}{42} = \\frac{1}{14}\n$$\nThe initial condition is satisfied.\nAs $t \\to \\infty$, $\\exp\\left(-\\frac{3}{4} t\\right) \\to 0$, so $u(t) \\to \\frac{3}{7 + 0} = \\frac{3}{7}$, which is the carrying capacity, as expected.",
            "answer": "$$\\boxed{\\frac{3}{7 + 35 \\exp\\left(-\\frac{3}{4} t\\right)}}$$"
        }
    ]
}