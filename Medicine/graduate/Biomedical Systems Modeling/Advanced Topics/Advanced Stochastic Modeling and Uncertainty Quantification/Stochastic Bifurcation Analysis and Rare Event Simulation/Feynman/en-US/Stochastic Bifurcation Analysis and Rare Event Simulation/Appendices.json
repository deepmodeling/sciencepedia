{
    "hands_on_practices": [
        {
            "introduction": "Understanding rare transitions between cellular states, such as from a healthy to a diseased phenotype, often begins with estimating the transition rate. This exercise introduces a powerful semi-analytical method based on the Fokker-Planck equation, which describes the evolution of the probability distribution of a system governed by a stochastic differential equation. By numerically finding the leading eigenvalue of the discretized Fokker-Planck operator, you will directly compute the slowest relaxation time of the system, which corresponds to the rare transition rate of interest .",
            "id": "3931104",
            "problem": "Consider a one-dimensional stochastic differential equation modeling a bistable gene regulatory motif subjected to molecular noise, written in dimensionless form as $dx_t = a(x_t)\\,dt + \\sqrt{2D}\\,dW_t$, where $x_t$ is the state, $a(x)$ is the deterministic drift, $D$ is the diffusion coefficient (noise strength), and $W_t$ is standard Brownian motion. For bistability, let the drift be derived from a tilted quartic potential $U(x;\\alpha)$ defined by $U(x;\\alpha) = \\frac{1}{4}(x^2 - 1)^2 + \\alpha x$, so that $a(x) = -\\frac{dU}{dx} = -(x^3 - x + \\alpha)$. The forward time evolution of the probability density $p(x,t)$ is governed by the Fokker–Planck equation $ \\frac{\\partial p}{\\partial t} = \\mathcal{L}p$, with the Fokker–Planck operator $\\mathcal{L}$ acting on densities defined by $\\mathcal{L}p = -\\frac{\\partial}{\\partial x}\\left(a(x)\\,p\\right) + D\\,\\frac{\\partial^2 p}{\\partial x^2}$.\n\nTo approximate rare transitions from the low-expression basin to the high-expression basin, restrict the state space to a bounded interval $[x_L,x_R]$ that contains the left well minimum and the central barrier top, and impose absorbing boundary conditions at both ends, $p(x_L,t) = 0$ and $p(x_R,t) = 0$. Absorbing boundaries emulate killing upon exit from the interval, so that the total probability mass inside $[x_L,x_R]$ decays over time. Under these conditions, the spectral decomposition of $\\mathcal{L}$ yields eigenpairs $(\\lambda_k,\\phi_k)$ satisfying $\\mathcal{L}\\phi_k = \\lambda_k \\phi_k$ with Dirichlet boundary conditions. The leading eigenvalue $\\lambda_0$ has the largest real part and is negative, and the associated eigenfunction $\\phi_0(x)$ can be normalized to define a quasi-stationary distribution $q(x)$ over $[x_L,x_R]$, given by $q(x) = \\phi_0(x)\\Big/\\int_{x_L}^{x_R}\\phi_0(y)\\,dy$. The exponential decay rate of the total probability mass inside the interval is $-\\lambda_0$, which serves as an estimate of the transition rate out of the left basin toward the right basin in the rare-event regime.\n\nYour task is to implement a numerical spectral decomposition of the Fokker–Planck operator on a uniform grid over $[x_L,x_R]$ using second-order central finite differences for spatial derivatives and Dirichlet boundary conditions at both endpoints. Specifically:\n- Discretize $\\mathcal{L}$ on interior grid points $\\{x_i\\}_{i=1}^{N-2}$ with $x_0=x_L$ and $x_{N-1}=x_R$ held at zero density (absorbing boundaries). Use the formula $\\mathcal{L}p \\approx -\\frac{(a_{i+1}p_{i+1} - a_{i-1}p_{i-1})}{2\\Delta x} + D\\,\\frac{p_{i+1} - 2p_i + p_{i-1}}{\\Delta x^2}$ for each interior node, where $a_i = a(x_i)$ and $\\Delta x$ is the grid spacing. Construct the resulting sparse matrix representation of $\\mathcal{L}$ acting on the interior unknowns.\n- Compute the eigenvalue of $\\mathcal{L}$ with the largest real part, denoted by $\\lambda_0$, and the associated eigenvector $\\phi_0$. Estimate the transition rate by $k = -\\operatorname{Re}(\\lambda_0)$ and ensure $k$ is reported as a nonnegative real number. Interpret the leading eigenfunction as the quasi-stationary distribution by normalizing it to integrate to unity with respect to $\\Delta x$.\n\nThe quantities are dimensionless; report all results in unitless values. Angles are not used in this problem. Do not report percentages.\n\nImplement the above for the following test suite of parameter values, using the fixed interval and grid:\n- Interval endpoints $x_L = -2.0$, $x_R = 0.0$; number of grid points $N = 401$ (so that the interior has $N-2$ unknowns); diffusion coefficient $D$ and tilt parameter $\\alpha$ vary per test case as listed below.\n- Test cases:\n    1. $D = 0.02$, $\\alpha = 0.0$ (symmetric double-well; rare event regime).\n    2. $D = 0.05$, $\\alpha = 0.0$ (symmetric double-well; increased noise).\n    3. $D = 0.02$, $\\alpha = 0.2$ (tilted double-well; lower barrier out of the left well).\n    4. $D = 0.02$, $\\alpha = 0.6$ (beyond the saddle-node threshold; left well collapses).\n\nYour program must:\n- Construct the discretized operator for each test case.\n- Compute the leading eigenpair and estimate the transition rate $k$ as $-\\operatorname{Re}(\\lambda_0)$ for each.\n- Aggregate the four rates into a single Python list and print it as one line in the exact format: \"[r1,r2,r3,r4]\" where each entry is a floating-point number.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\").",
            "solution": "The problem requires the computation of the transition rate for a particle in a one-dimensional bistable potential, modeled by a stochastic differential equation (SDE). This rate is determined by finding the leading eigenvalue of the associated Fokker-Planck operator. The problem is well-posed, scientifically grounded, and provides all necessary information for a numerical solution.\n\nThe dynamics of the system are described by the SDE:\n$$\ndx_t = a(x_t)\\,dt + \\sqrt{2D}\\,dW_t\n$$\nwhere $a(x_t)$ is the drift term, $D$ is the diffusion coefficient representing noise strength, and $W_t$ is a standard Wiener process. The drift $a(x)$ is derived from a quartic potential $U(x;\\alpha)$, given by:\n$$\nU(x;\\alpha) = \\frac{1}{4}(x^2 - 1)^2 + \\alpha x\n$$\nwhich yields the drift $a(x) = -\\frac{dU}{dx} = -(x^3 - x + \\alpha)$. This potential has two wells for small $|\\alpha|$, creating a bistable system.\n\nThe time evolution of the probability density function $p(x,t)$ of the particle's position is governed by the Fokker-Planck equation:\n$$\n\\frac{\\partial p}{\\partial t} = \\mathcal{L}p = -\\frac{\\partial}{\\partial x}\\left[a(x)p(x,t)\\right] + D\\,\\frac{\\partial^2 p(x,t)}{\\partial x^2}\n$$\nwhere $\\mathcal{L}$ is the Fokker-Planck operator.\n\nTo calculate the transition rate from the left potential well (centered near $x=-1$) to the right well, we analyze the system on a restricted interval $[x_L, x_R]$ that includes the left well and the central potential barrier. We impose absorbing boundary conditions, $p(x_L, t) = 0$ and $p(x_R, t) = 0$. With these conditions, the total probability of finding the particle within the interval, $P(t) = \\int_{x_L}^{x_R} p(x,t)\\,dx$, decays over time.\n\nThe solution to the Fokker-Planck equation can be expressed as a sum over the eigenfunctions $\\phi_k(x)$ of the operator $\\mathcal{L}$:\n$$\np(x,t) = \\sum_{k=0}^{\\infty} c_k \\phi_k(x) e^{\\lambda_k t}\n$$\nwhere $\\mathcal{L}\\phi_k = \\lambda_k \\phi_k$. For a decay process, all eigenvalues $\\lambda_k$ have non-positive real parts. At long times, the behavior is dominated by the term with the eigenvalue $\\lambda_0$ having the largest real part (i.e., closest to zero). The total probability then decays approximately as $P(t) \\propto e^{\\lambda_0 t}$. The decay rate is $-\\lambda_0$, which is interpreted as the transition rate $k$ out of the well. Therefore, we can estimate the rate by calculating $k = -\\operatorname{Re}(\\lambda_0)$. The corresponding eigenfunction $\\phi_0(x)$ is the quasi-stationary distribution (QSD), representing the shape of the probability distribution as it slowly leaks out of the domain.\n\nTo solve this eigenvalue problem numerically, we discretize the operator $\\mathcal{L}$ on a uniform grid of $N$ points, $\\{x_i\\}_{i=0}^{N-1}$, spanning the interval $[x_L, x_R]$. The grid spacing is $\\Delta x = (x_R - x_L)/(N-1)$. The absorbing boundary conditions imply $p_0 = p(x_0)=0$ and $p_{N-1} = p(x_{N-1})=0$. We solve for the probability densities $p_i = p(x_i)$ at the $N-2$ interior grid points.\n\nThe problem specifies using second-order central finite differences. The operator $\\mathcal{L}$ acting on $p$ at an interior grid point $x_i$ is approximated as:\n$$\n(\\mathcal{L}p)_i \\approx -\\frac{a_{i+1}p_{i+1} - a_{i-1}p_{i-1}}{2\\Delta x} + D\\,\\frac{p_{i+1} - 2p_i + p_{i-1}}{\\Delta x^2}\n$$\nThis linear transformation on the vector of interior densities $\\vec{p} = [p_1, p_2, \\dots, p_{N-2}]^T$ is represented by a matrix $L$, and the eigenvalue problem becomes $L\\vec{p} = \\lambda\\vec{p}$. The matrix $L$ is a tridiagonal, non-symmetric matrix of size $(N-2) \\times (N-2)$. For a given interior grid point $x_i$, the stencil connects $p_{i-1}, p_i,$ and $p_{i+1}$. The corresponding row in the matrix $L$ will have three non-zero entries based on the coefficients of these terms:\n- Coefficient for $p_{i-1}$: $\\frac{a_{i-1}}{2\\Delta x} + \\frac{D}{(\\Delta x)^2}$ (sub-diagonal)\n- Coefficient for $p_i$: $-\\frac{2D}{(\\Delta x)^2}$ (main diagonal)\n- Coefficient for $p_{i+1}$: $-\\frac{a_{i+1}}{2\\Delta x} + \\frac{D}{(\\Delta x)^2}$ (super-diagonal)\nThe boundary conditions $p_0=0$ and $p_{N-1}=0$ are incorporated by omitting terms that would involve them in the first and last rows of the matrix equation.\n\nThe solution proceeds by constructing this matrix $L$ for each given test case $(\\alpha, D)$ and then employing a numerical eigensolver to find the eigenvalue $\\lambda_0$ with the largest real part. The transition rate is then computed as $k = -\\operatorname{Re}(\\lambda_0)$. This procedure is repeated for all four test cases, and the resulting rates are aggregated into a list.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags\nfrom scipy.sparse.linalg import eigs\n\ndef solve():\n    \"\"\"\n    Computes the transition rate for a stochastic process in a bistable potential\n    by finding the leading eigenvalue of the discretized Fokker-Planck operator.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (D, alpha)\n        (0.02, 0.0),\n        (0.05, 0.0),\n        (0.02, 0.2),\n        (0.02, 0.6),\n    ]\n\n    # Fixed parameters for the numerical simulation\n    x_L = -2.0\n    x_R = 0.0\n    N = 401  # Total number of grid points\n\n    results = []\n    \n    # Setup the spatial grid\n    x = np.linspace(x_L, x_R, N)\n    dx = x[1] - x[0]\n    \n    # The number of interior points, which is the size of the matrix\n    M = N - 2\n    \n    for D, alpha in test_cases:\n        # Define the drift function a(x) = -(x^3 - x + alpha)\n        a = -(x**3 - x + alpha)\n\n        # Construct the diagonals of the discretized Fokker-Planck operator matrix L.\n        # The matrix L acts on the vector of probabilities at the interior points.\n        # Let the vector of unknowns be p = [p_1, ..., p_{N-2}].\n        # The matrix L is of size M x M, where M = N - 2.\n        # Matrix row index j corresponds to grid point x_{j+1}.\n        \n        # Main diagonal term: coefficient of p_i\n        # This is constant for all interior points.\n        main_diag = (-2.0 * D / dx**2) * np.ones(M)\n        \n        # Sub-diagonal term: coefficient of p_{i-1}\n        # Based on the formula: a_{i-1}/(2*dx) + D/dx^2\n        # The sub-diagonal has M-1 elements, corresponding to coefficients for p_1...p_{M-1}\n        # in the equations for p_2...p_M. The code implements this correctly.\n        sub_diag = a[1:-2] / (2.0 * dx) + D / dx**2\n        \n        # Super-diagonal term: coefficient of p_{i+1}\n        # Based on the formula: -a_{i+1}/(2*dx) + D/dx^2\n        sup_diag = -a[2:-1] / (2.0 * dx) + D / dx**2\n        \n        # Assemble the sparse matrix L from the diagonals\n        L = diags(\n            [sub_diag, main_diag, sup_diag],\n            [-1, 0, 1],\n            shape=(M, M),\n            format='csc'\n        )\n        \n        # Compute the eigenvalue with the largest real part.\n        # k=1 asks for one eigenvalue.\n        # which='LR' specifies to find the eigenvalue with the Largest Real part.\n        # The operator is not symmetric, so eigenvalues can be complex.\n        try:\n            evals, _ = eigs(L, k=1, which='LR')\n            lambda_0 = evals[0]\n        except Exception as e:\n            # Fallback to dense solver if sparse solver fails (e.g., convergence)\n            # This is good practice for robustness, though unlikely here.\n            L_dense = L.toarray()\n            evals = np.linalg.eigvals(L_dense)\n            lambda_0 = evals[np.argmax(np.real(evals))]\n\n        # The transition rate k is the negative of the real part of the leading eigenvalue.\n        # As lambda_0 corresponds to a decay process, its real part is negative.\n        rate = -np.real(lambda_0)\n        results.append(rate)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "While a single transition rate offers a valuable first approximation, the full story of a stochastic process is told by its distribution of event times. This practice moves from theory to data analysis, equipping you to test a fundamental assumption: whether escape times follow a simple exponential distribution, which implies a memoryless process dominated by a single escape pathway. You will implement a suite of diagnostic tools to analyze simulated first passage times and learn to identify when more complex dynamics, such as multi-well interactions, are at play .",
            "id": "3931108",
            "problem": "Consider an overdamped stochastic dynamics model for a single biochemical state variable governed by a one-dimensional stochastic differential equation with additive white noise, defined by the Itô overdamped Langevin equation $dx_t = -U'(x_t)\\,dt + \\sqrt{2D}\\,dW_t$, where $U(x)$ is a smooth potential, $U'(x)$ is the derivative of the potential, $D$ is the noise intensity, and $W_t$ is a standard Wiener process. Rare event simulation for escape from a basin of attraction is defined by the first passage time $T$ to cross an absorbing threshold from the left basin to the right basin. In the regime of a single dominant quasistationary mode, the escape time distribution is approximately exponential with a constant hazard rate. However, when multiwell interactions create multiple comparable slow modes or slow modulation of barriers, the escape time distribution can become a nontrivial mixture of exponentials with time-varying hazard, leading to non-exponential survival curves. \n\nStarting from the fundamental definitions of the overdamped Langevin equation, the Fokker–Planck operator, and the first-passage time, test and diagnose the memoryless property through the survival function and the hazard function. The survival function is $S(t) = \\mathbb{P}(T > t)$, and the hazard function is $h(t) = f(t)/S(t)$, where $f(t)$ is the probability density function of $T$. A constant hazard function corresponds to an exponential distribution of escape times, while a time-varying hazard indicates non-exponential behavior due to multiple timescales and interactions.\n\nYour task is to write a complete, runnable program that:\n- Simulates $N$ independent trajectories of the overdamped Langevin equation for each specified potential, using Euler–Maruyama with time step $dt$ and noise intensity $D$.\n- Records the first passage time $T$ to cross the absorbing threshold $x \\geq x_{\\mathrm{th}}$ starting from $x_0$.\n- Constructs an empirical survival function $\\hat{S}(t)$ on a regular grid of $M$ points between the empirical $5$th and $95$th percentiles of the sample of $T$.\n- Computes a non-exponentiality score $s$ as the normalized root mean square deviation of $\\log \\hat{S}(t)$ from the best-fit straight line on the grid. Concretely, let $\\{\\,(t_j, y_j)\\,\\}_{j=1}^M$ denote grid points with $y_j = \\log \\hat{S}(t_j)$ and let the least-squares fit be $y_j^{\\mathrm{fit}} = \\alpha + \\beta t_j$. Define \n$$\ns = \\sqrt{\\frac{\\sum_{j=1}^M \\left(y_j - y_j^{\\mathrm{fit}}\\right)^2}{\\sum_{j=1}^M \\left(y_j - \\bar{y}\\right)^2}},\n$$\nwhere $\\bar{y} = \\frac{1}{M}\\sum_{j=1}^M y_j$.\n- Estimates a piecewise hazard by finite differences $h_j \\approx \\frac{-(y_{j+1}-y_j)}{t_{j+1}-t_j}$ for $j=1,\\dots,M-1$ and computes its coefficient of variation $c = \\mathrm{std}(h_j)/\\mathrm{mean}(h_j)$.\n- Performs a Kolmogorov–Smirnov goodness-of-fit test of the empirical $T$ against the exponential distribution with scale parameter equal to the sample mean $\\hat{\\mu} = \\frac{1}{N}\\sum_i T_i$. Use a significance level $\\alpha = 0.05$.\n\nDefine the diagnostic rule to classify the distribution as approximately exponential if and only if the following three conditions hold simultaneously: the Kolmogorov–Smirnov test $p$-value is at least $\\alpha$, the non-exponentiality score is at most the threshold $\\tau$, and the hazard coefficient of variation is at most the threshold $\\eta$. Use the specific thresholds $\\tau = 0.08$ and $\\eta = 0.25$. Otherwise, classify the distribution as non-exponential.\n\nSimulate the following test suite of potentials and parameters. In all cases, use Euler–Maruyama, and express time in seconds. Ensure numerical stability by choosing $dt$ and $t_{\\max}$ such that most trajectories escape within $t_{\\max}$.\n\n- Case $1$ (single dominant well-to-well escape, expected approximately exponential): Potential $U(x) = a(x^2 - 1)^2$ with $a = 1$, noise intensity $D = 0.25$, initial condition $x_0 = -1.0$, absorbing threshold $x_{\\mathrm{th}} = 0.0$, time step $dt = 0.01\\,\\mathrm{s}$, maximum simulation time $t_{\\max} = 40.0\\,\\mathrm{s}$, number of trajectories $N = 800$.\n- Case $2$ (multiwell interactions creating multiple slow modes, expected non-exponential): Potential $U(x) = a(x^2 - 1)^2 + h \\exp\\!\\left(-\\frac{(x+1.5)^2}{2\\sigma^2}\\right)$ with $a = 1$, $h = 2.5$, $\\sigma = 0.2$, noise intensity $D = 0.25$, initial condition $x_0 = -1.8$, absorbing threshold $x_{\\mathrm{th}} = 0.0$, time step $dt = 0.01\\,\\mathrm{s}$, maximum simulation time $t_{\\max} = 50.0\\,\\mathrm{s}$, number of trajectories $N = 800$.\n- Case $3$ (near-bifurcation tilt weakens the left barrier producing non-exponential transients): Potential $U(x) = a(x^2 - 1)^2 + v x$ with $a = 1$, $v = 1.2$, noise intensity $D = 0.12$, initial condition $x_0 = -0.9$, absorbing threshold $x_{\\mathrm{th}} = 0.0$, time step $dt = 0.01\\,\\mathrm{s}$, maximum simulation time $t_{\\max} = 15.0\\,\\mathrm{s}$, number of trajectories $N = 800$.\n\nYour program should produce a single line of output containing the classification results for the three cases as a comma-separated list enclosed in square brackets; for each case output the boolean `True` if the escape time distribution is approximately exponential according to the diagnostic rule above, and `False` otherwise. For example, the output must be of the form `[True,False,False]`, with no additional text.",
            "solution": "We begin with the overdamped Langevin equation $dx_t = -U'(x_t)\\,dt + \\sqrt{2D}\\,dW_t$, where $U(x)$ is a smooth potential, $U'(x)$ its derivative, $D$ the noise intensity, and $W_t$ a standard Wiener process. This dynamical system induces a probability density $p(x,t)$ evolving under the Fokker–Planck equation $\\partial_t p = \\mathcal{L}p$ with generator $\\mathcal{L} = \\partial_x\\left(U'(x)\\cdot\\right) + D\\,\\partial_{xx}$. Escape from a basin to an absorbing set is captured by imposing an absorbing boundary at the threshold $x \\geq x_{\\mathrm{th}}$, thereby restricting dynamics to the domain $x < x_{\\mathrm{th}}$ until first passage.\n\nIn the weak-noise metastable regime where there is a single dominant slow mode, the exit time distribution is approximately exponential. This follows from the spectral representation of the Fokker–Planck operator with absorbing boundary. Let $\\lambda_1 < \\lambda_2 \\leq \\lambda_3 \\leq \\dots$ denote the eigenvalues of $-\\mathcal{L}$ on the absorbing domain with relevant boundary conditions. The survival probability $S(t) = \\mathbb{P}(T > t)$ admits the representation\n$$\nS(t) = \\sum_{k\\geq 1} c_k e^{-\\lambda_k t},\n$$\nfor coefficients $c_k$ determined by the initial condition and eigenfunctions. If the spectral gap is large, meaning $\\lambda_2 \\gg \\lambda_1$, then for times larger than an initial transient the survival is dominated by the leading term and $S(t) \\approx c_1 e^{-\\lambda_1 t}$, so the hazard $h(t) = -\\frac{d}{dt}\\log S(t)$ is approximately constant and equal to $\\lambda_1$. This yields exponential exit times.\n\nNon-exponential behavior arises when multiwell interactions create multiple comparable slow modes, so that $\\lambda_2$ is not much larger than $\\lambda_1$. A common mechanism is a basin split into subwells separated by a small internal barrier, where the internal interchange rate $k_{AB}$ between subwells becomes comparable to the escape rate $k_E$ across the main barrier. In such cases, the survival function is a nontrivial mixture of exponentials,\n$$\nS(t) \\approx c_1 e^{-\\lambda_1 t} + c_2 e^{-\\lambda_2 t} + \\dots,\n$$\nwith $c_2$ not negligible and $\\lambda_2$ close to $\\lambda_1$, which yields time-varying hazard $h(t)$ and curvature in $\\log S(t)$. Near-bifurcation conditions, such as a tilt $v$ that weakens or removes a local minimum, can also produce non-exponential transients because deterministic drift dominates over stochastic exploration, leading to exit times that depend on initial conditions and temporal inhomogeneities before quasi-stationarity is attained.\n\nDiagnostic design follows from these principles. A purely exponential distribution has constant hazard and a strictly linear $\\log S(t)$ versus $t$. Therefore, a robust diagnostic combines three indicators:\n- A Kolmogorov–Smirnov goodness-of-fit test of the empirical $T$ against the exponential distribution with scale parameter equal to the empirical mean $\\hat{\\mu}$, at significance level $\\alpha = 0.05$. This tests the overall distribution shape without specifying binning.\n- A non-exponentiality score $s$ defined as the normalized root mean square deviation of $\\log \\hat{S}(t)$ from the best linear fit on an internal grid, which quantifies curvature beyond noise. Explicitly,\n$$\ns = \\sqrt{\\frac{\\sum_{j=1}^M \\left(y_j - y_j^{\\mathrm{fit}}\\right)^2}{\\sum_{j=1}^M \\left(y_j - \\bar{y}\\right)^2}},\n$$\nwhere $y_j = \\log \\hat{S}(t_j)$ are the empirical log-survival values and $y_j^{\\mathrm{fit}}$ is the least-squares linear fit, with $t_j$ taken on a regular grid. A small $s$ indicates near-linearity.\n- A hazard variability measure $c$ defined as the coefficient of variation of piecewise hazards estimated via finite differences $h_j \\approx \\frac{-(y_{j+1}-y_j)}{t_{j+1}-t_j}$, namely $c = \\mathrm{std}(h_j)/\\mathrm{mean}(h_j)$. Exponential behavior yields near-constant hazard and small $c$.\n\nWe adopt thresholds $\\tau = 0.08$ for the non-exponentiality score and $\\eta = 0.25$ for the hazard coefficient of variation, and require the Kolmogorov–Smirnov test $p$-value to be at least $\\alpha = 0.05$. If all three tests agree, we classify the distribution as approximately exponential; otherwise, non-exponential.\n\nSimulation methodology uses Euler–Maruyama discretization:\n$$\nx_{n+1} = x_n - U'(x_n)\\,dt + \\sqrt{2D\\,dt}\\,\\xi_n,\n$$\nwhere $\\xi_n \\sim \\mathcal{N}(0,1)$ are independent. The first passage time $T$ is recorded as the discrete time the trajectory first satisfies $x \\geq x_{\\mathrm{th}}$. To maintain numerical stability and efficiency for rare events, one should choose $dt$ sufficiently small, $t_{\\max}$ sufficiently large, and $N$ sufficiently large to ensure accurate empirical survival estimates while keeping runtime acceptable.\n\nWe test three scientifically plausible conditions:\n- Case $1$: $U(x) = a(x^2-1)^2$ with $a = 1$, a symmetric double well. The exit from the left well to the right well across the barrier near $x=0$ with $D = 0.25$ is expected to have a dominant slow mode, yielding an approximately exponential distribution for $T$.\n- Case $2$: $U(x) = a(x^2-1)^2 + h\\exp\\!\\left(-\\frac{(x+1.5)^2}{2\\sigma^2}\\right)$ with $a = 1$, $h = 2.5$, $\\sigma = 0.2$, which introduces an internal barrier splitting the left basin into two subwells near $x \\approx -2$ and $x \\approx -1$. With $D = 0.25$, this creates comparable internal and escape timescales, producing non-exponential survival due to multiple slow modes.\n- Case $3$: $U(x) = a(x^2-1)^2 + v x$ with $a = 1$, $v = 1.2$, which tilts the potential, weakening the left barrier and approaching a saddle-node-like bifurcation. With $D = 0.12$, this yields non-exponential transients dominated by drift and initial condition effects.\n\nAlgorithmic steps for each case:\n1. Initialize $N$ trajectories at $x_0$ and integrate until the threshold is crossed or $t_{\\max}$ is reached.\n2. Collect the first passage times $\\{T_i\\}$ and form the empirical survival function $\\hat{S}(t)$ on a grid of $M$ linearly spaced points between the empirical $5$th and $95$th percentiles to avoid extreme-bin artifacts.\n3. Compute the log-survival $\\log \\hat{S}(t)$, fit a least-squares line, and compute the non-exponentiality score $s$.\n4. Compute the piecewise hazards $h_j$ via finite differences and derive $c$.\n5. Perform the Kolmogorov–Smirnov test against an exponential with scale $\\hat{\\mu}$ and record the $p$-value.\n6. Classify exponential versus non-exponential according to $p \\geq \\alpha$, $s \\leq \\tau$, and $c \\leq \\eta$.\n\nExpected qualitative outcomes:\n- Case $1$: approximately exponential with a single dominant slow mode, hence a near-linear log-survival, small $s$, small $c$, and nonsignificant Kolmogorov–Smirnov deviation, yielding `True`.\n- Case $2$: non-exponential due to multiwell interaction and internal subwell transitions, yielding curvature in log-survival, larger $s$, larger $c$, and significant Kolmogorov–Smirnov deviation, yielding `False`.\n- Case $3$: non-exponential transient due to tilt near bifurcation with time-varying hazard, yielding `False`.\n\nThe final program implements this simulation and diagnostic, aggregates the boolean results, and prints them in the required single-line format `[True,False,False]`.",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import kstest, expon\n\n# Set a global random seed for reproducibility\nnp.random.seed(12345)\n\ndef grad_double(x, a):\n    # U(x) = a (x^2 - 1)^2 -> U'(x) = 4 a x (x^2 - 1)\n    return 4.0 * a * x * (x**2 - 1.0)\n\ndef grad_split_left(x, a, h, sigma):\n    # U(x) = a (x^2 - 1)^2 + h * exp(- (x+1.5)^2 / (2 sigma^2))\n    # U'(x) = 4 a x (x^2 - 1) - h * ((x+1.5)/sigma^2) * exp(- (x+1.5)^2 / (2 sigma^2))\n    gauss = np.exp(-((x + 1.5)**2) / (2.0 * sigma**2))\n    return 4.0 * a * x * (x**2 - 1.0) - h * ((x + 1.5) / (sigma**2)) * gauss\n\ndef grad_tilted(x, a, v):\n    # U(x) = a (x^2 - 1)^2 + v x -> U'(x) = 4 a x (x^2 - 1) + v\n    return 4.0 * a * x * (x**2 - 1.0) + v\n\ndef simulate_escape_times(potential_type, params):\n    \"\"\"\n    Simulate first passage times for N trajectories using Euler-Maruyama.\n    potential_type: 'double', 'split_left', or 'tilted'\n    params: dict containing a, D, x0, threshold, dt, t_max, N, and potential-specific parameters\n    Returns an array of escape times for trajectories that crossed the threshold.\n    \"\"\"\n    a = params.get('a', 1.0)\n    D = params['D']\n    x0 = params['x0']\n    threshold = params['threshold']\n    dt = params['dt']\n    t_max = params['t_max']\n    N = params['N']\n\n    # Initialize state\n    x = np.full(N, x0, dtype=np.float64)\n    alive = np.ones(N, dtype=bool)\n    times = np.zeros(N, dtype=np.float64)\n\n    n_steps = int(np.ceil(t_max / dt))\n    sqrt_term = np.sqrt(2.0 * D * dt)\n    t = 0.0\n\n    # Simulate in vectorized fashion\n    for _ in range(n_steps):\n        if not np.any(alive):\n            break\n        idx_alive = np.where(alive)[0]\n        xa = x[idx_alive]\n        if potential_type == 'double':\n            drift = -grad_double(xa, a)\n        elif potential_type == 'split_left':\n            h = params['h']\n            sigma = params['sigma']\n            drift = -grad_split_left(xa, a, h, sigma)\n        elif potential_type == 'tilted':\n            v = params['v']\n            drift = -grad_tilted(xa, a, v)\n        else:\n            raise ValueError(\"Unknown potential type\")\n\n        xi = np.random.randn(xa.size)\n        xa_new = xa + drift * dt + sqrt_term * xi\n        ta_new = t + dt\n\n        crossed = xa_new >= threshold\n        # Record times for those that crossed at this step\n        times[idx_alive[crossed]] = ta_new\n\n        # Update survivors\n        survivors_idx = idx_alive[~crossed]\n        x[survivors_idx] = xa_new[~crossed]\n        alive[:] = False\n        alive[survivors_idx] = True\n\n        t = ta_new\n\n    # Return only successful escape times (exclude zeros)\n    return times[times > 0.0]\n\ndef empirical_survival(times, M=50):\n    \"\"\"\n    Compute empirical survival S_hat(t) on a grid of M points\n    between the 5th and 95th percentile of times.\n    Returns t_grid, S_values.\n    \"\"\"\n    times_sorted = np.sort(times)\n    N = times_sorted.size\n    if N < 5:\n        # Degenerate case: return trivial survival on a minimal grid\n        t_grid = np.linspace(times_sorted.min(), times_sorted.max(), max(3, M))\n        # Survival computed via counts\n        idx = np.searchsorted(times_sorted, t_grid, side='right')\n        S = (N - idx) / N\n        return t_grid, S\n\n    t_lo = np.percentile(times_sorted, 5.0)\n    t_hi = np.percentile(times_sorted, 95.0)\n    if t_hi <= t_lo:\n        t_lo = times_sorted.min()\n        t_hi = times_sorted.max()\n    t_grid = np.linspace(t_lo, t_hi, M)\n    idx = np.searchsorted(times_sorted, t_grid, side='right')\n    S = (N - idx) / N\n    # Prevent zero survival to avoid log singularity\n    eps = 1e-12\n    S = np.clip(S, eps, 1.0)\n    return t_grid, S\n\ndef non_exponentiality_score(t_grid, S_values):\n    \"\"\"\n    Compute normalized RMS deviation of log survival from best-fit line,\n    and hazard coefficient of variation.\n    \"\"\"\n    logS = np.log(S_values)\n    # Least squares linear fit: logS ~ alpha + beta * t\n    coeffs = np.polyfit(t_grid, logS, 1)\n    logS_fit = np.polyval(coeffs, t_grid)\n    # Normalized RMS deviation\n    numerator = np.mean((logS - logS_fit)**2)\n    denom = np.var(logS)\n    s = np.sqrt(numerator / denom) if denom > 0 else 0.0\n\n    # Piecewise hazard via finite differences\n    dlogS = np.diff(logS)\n    dt = np.diff(t_grid)\n    # Hazard estimates h_j = -(d logS) / dt\n    with np.errstate(divide='ignore', invalid='ignore'):\n        hazards = -dlogS / dt\n    hazards = hazards[np.isfinite(hazards)]\n    if hazards.size == 0:\n        c = np.inf\n    else:\n        mean_h = np.mean(hazards)\n        std_h = np.std(hazards)\n        c = (std_h / mean_h) if mean_h > 0 else np.inf\n    return s, c\n\ndef ks_test_exponential(times):\n    \"\"\"\n    Perform KS test against exponential with scale equal to sample mean.\n    Returns p-value.\n    \"\"\"\n    mean_T = np.mean(times)\n    if mean_T <= 0:\n        return 0.0\n    # scipy.stats.kstest with distribution 'expon' uses args=(loc, scale)\n    result = kstest(times, 'expon', args=(0.0, mean_T))\n    return result.pvalue\n\ndef classify_exponential(times, tau=0.08, eta=0.25, alpha=0.05, M=50):\n    \"\"\"\n    Classify whether the escape time distribution is approximately exponential.\n    Criteria: KS p >= alpha, non-exponentiality score s <= tau, hazard CV c <= eta.\n    \"\"\"\n    if times.size < 10:\n        # Not enough data, conservative classify as non-exponential\n        return False\n    t_grid, S_vals = empirical_survival(times, M=M)\n    s, c = non_exponentiality_score(t_grid, S_vals)\n    pval = ks_test_exponential(times)\n    is_exp = (pval >= alpha) and (s <= tau) and (c <= eta)\n    return is_exp\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'case_id': 1,\n            'potential': 'double',\n            'a': 1.0,\n            'D': 0.25,\n            'x0': -1.0,\n            'threshold': 0.0,\n            'dt': 0.01,\n            't_max': 40.0,\n            'N': 800\n        },\n        {\n            'case_id': 2,\n            'potential': 'split_left',\n            'a': 1.0,\n            'h': 2.5,\n            'sigma': 0.2,\n            'D': 0.25,\n            'x0': -1.8,\n            'threshold': 0.0,\n            'dt': 0.01,\n            't_max': 50.0,\n            'N': 800\n        },\n        {\n            'case_id': 3,\n            'potential': 'tilted',\n            'a': 1.0,\n            'v': 1.2,\n            'D': 0.12,\n            'x0': -0.9,\n            'threshold': 0.0,\n            'dt': 0.01,\n            't_max': 15.0,\n            'N': 800\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Simulate escape times for one case\n        times = simulate_escape_times(case['potential'], case)\n        # Classify using diagnostic\n        is_exp = classify_exponential(times, tau=0.08, eta=0.25, alpha=0.05, M=50)\n        results.append(is_exp)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```"
        },
        {
            "introduction": "Directly simulating extremely rare events, like the spontaneous activation of a dormant gene, is often computationally infeasible. This exercise introduces importance sampling, a sophisticated variance reduction technique that makes the impossible possible by intelligently biasing simulations toward the event of interest. You will implement an importance sampling algorithm guided by the slow-fast structure of a biomedical model, learning how to use a likelihood ratio to recover an unbiased estimate of an exceedingly small probability with remarkable efficiency .",
            "id": "3931138",
            "problem": "Consider a slow–fast stochastic model of a biomedical module in dimensionless form, where a fast activator variable $x_t$ is coupled to a slow epigenetic state $y_t$. The system evolves according to the stochastic differential equations\n$$\n\\mathrm{d}x_t = \\left(x_t - x_t^3 - y_t\\right)\\,\\mathrm{d}t + \\sqrt{2\\,\\epsilon}\\,\\mathrm{d}W^{x}_t,\\quad\n\\mathrm{d}y_t = \\delta\\left(x_t - \\lambda\\,y_t\\right)\\,\\mathrm{d}t + \\sqrt{2\\,\\epsilon\\,\\delta}\\,\\mathrm{d}W^{y}_t,\n$$\nwhere $\\epsilon > 0$ is a noise intensity, $\\delta \\ll 1$ induces slow dynamics in $y_t$, $\\lambda > 0$ is a stability parameter for the slow variable $y_t$, and $W^{x}_t$ and $W^{y}_t$ are independent standard Wiener processes. Assume initial conditions $x_0$ and $y_0$ are given. Define the rare excursion event as the crossing of a threshold $x_{\\mathrm{thr}}$ by the fast variable within a finite horizon $[0,T]$:\n$$\n\\mathcal{E} = \\left\\{\\sup_{t \\in [0,T]} x_t \\geq x_{\\mathrm{thr}}\\right\\}.\n$$\nYour task is to implement an estimator for the probability $\\mathbb{P}(\\mathcal{E})$ based on direct Monte Carlo and on importance sampling guided by a reduced slow dynamics principle. Use the Euler–Maruyama time discretization with step size $\\Delta t$:\n$$\nx_{n+1} = x_n + \\left(x_n - x_n^3 - y_n\\right)\\Delta t + \\sigma_x\\,\\Delta W^{x}_n,\\quad\ny_{n+1} = y_n + \\delta\\left(x_n - \\lambda\\,y_n\\right)\\Delta t + \\sigma_y\\left(u_{y,n}\\,\\Delta t + \\Delta W^{y}_n\\right),\n$$\nwhere $\\sigma_x = \\sqrt{2\\,\\epsilon}$, $\\sigma_y = \\sqrt{2\\,\\epsilon\\,\\delta}$, and $\\Delta W^{x}_n, \\Delta W^{y}_n \\sim \\mathcal{N}(0,\\Delta t)$ independently at each time step $n$. The term $u_{y,n}$ is a control to be chosen for importance sampling, which should bias sample paths in the slow variable direction using the reduced slow manifold heuristic: the fast subsystem approximately equilibrates along the slow manifold defined by the root of $x - x^3 - y = 0$. In particular, use the target slow state $y_{\\star}$ implied by the threshold $x_{\\mathrm{thr}}$ via the slow manifold condition $x_{\\mathrm{thr}} - x_{\\mathrm{thr}}^3 - y_{\\star} = 0$, i.e.,\n$$\ny_{\\star} = x_{\\mathrm{thr}} - x_{\\mathrm{thr}}^3,\n$$\nand construct an importance sampling control of the form\n$$\nu_{y,n} = \\kappa\\left(y_{\\star} - y_n\\right),\n$$\nwhere $\\kappa \\ge 0$ is a tilting strength parameter. The importance sampling estimator must be unbiased under the change of measure, which requires inclusion of a likelihood ratio consistent with the drift modification applied along the slow variable. Compute $\\mathbb{P}(\\mathcal{E})$ using:\n1. Direct Monte Carlo with $u_{y,n} \\equiv 0$.\n2. Importance sampling with moderate tilting $\\kappa > 0$.\n3. Importance sampling with stronger tilting $\\kappa$.\n4. A boundary case with smaller $\\delta$ to test behavior as the slow timescale separation increases.\n\nAll quantities are dimensionless; report the probability estimates as decimals. Implement your program to simulate $N$ independent trajectories for each test case, detect whether $\\mathcal{E}$ occurs on each trajectory, and aggregate results appropriately. Your implementation must:\n1. Use the Euler–Maruyama scheme as specified.\n2. Use independent Gaussian increments $\\Delta W^{x}_n$ and $\\Delta W^{y}_n$ with variance $\\Delta t$.\n3. For importance sampling, incorporate the unbiased likelihood ratio associated with the implemented control in the slow variable.\n\nTest suite parameter sets to be used by your program:\n- Case A (baseline Monte Carlo): $\\epsilon = 0.01$, $\\delta = 0.05$, $\\lambda = 1.0$, $x_0 = -1.0$, $y_0 = 0.2$, $x_{\\mathrm{thr}} = 0.8$, $T = 2.5$, $\\Delta t = 0.01$, $N = 3000$, $\\kappa = 0.0$.\n- Case B (importance sampling, moderate): same as Case A but with $\\kappa = 2.0$.\n- Case C (importance sampling, strong): same as Case A but with $\\kappa = 5.0$.\n- Case D (boundary in slow timescale): same as Case B but with $\\delta = 0.02$.\n\nYour program should produce a single line of output containing the four estimated probabilities as a comma-separated list enclosed in square brackets (e.g., \"[pA,pB,pC,pD]\").",
            "solution": "The objective is to estimate the probability of a rare excursion event for a slow-fast stochastic system using both Direct Monte Carlo (DMC) simulation and Importance Sampling (IS). The system is described by a pair of coupled stochastic differential equations (SDEs) for a fast variable $x_t$ and a slow variable $y_t$.\n\nThe governing SDEs in dimensionless form are:\n$$\n\\mathrm{d}x_t = \\left(x_t - x_t^3 - y_t\\right)\\,\\mathrm{d}t + \\sqrt{2\\,\\epsilon}\\,\\mathrm{d}W^{x}_t,\n$$\n$$\n\\mathrm{d}y_t = \\delta\\left(x_t - \\lambda\\,y_t\\right)\\,\\mathrm{d}t + \\sqrt{2\\,\\epsilon\\,\\delta}\\,\\mathrm{d}W^{y}_t,\n$$\nwhere $x_t, y_t$ are the state variables, $\\epsilon > 0$ is the noise intensity, $\\delta \\ll 1$ is the timescale separation parameter, $\\lambda > 0$ is a stability parameter, and $W^{x}_t, W^{y}_t$ are independent standard Wiener processes.\n\nThe rare event $\\mathcal{E}$ is defined as the fast variable $x_t$ exceeding a threshold $x_{\\mathrm{thr}}$ within the time horizon $[0,T]$:\n$$\n\\mathcal{E} = \\left\\{\\sup_{t \\in [0,T]} x_t \\geq x_{\\mathrm{thr}}\\right\\}.\n$$\nWe seek to compute $\\mathbb{P}(\\mathcal{E}) = \\mathbb{E}[\\mathbf{1}_{\\mathcal{E}}]$, where $\\mathbf{1}_{\\mathcal{E}}$ is the indicator function of the event $\\mathcal{E}$.\n\nThe numerical simulation of the SDEs is performed using the Euler–Maruyama scheme with a time step $\\Delta t$. The Direct Monte Carlo (DMC) estimator for $\\mathbb{P}(\\mathcal{E})$ is the sample mean of the indicator function over $N$ independent trajectories:\n$$\n\\hat{P}_{\\mathrm{DMC}} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}_{\\mathcal{E}}^{(i)}.\n$$\nFor each trajectory $i$, $\\mathbf{1}_{\\mathcal{E}}^{(i)}=1$ if $\\max_{n} x_n^{(i)} \\geq x_{\\mathrm{thr}}$, and $0$ otherwise. This approach is computationally expensive for rare events.\n\nTo improve efficiency, we employ Importance Sampling (IS). The core principle is to simulate the system under a new, biased probability measure $\\mathbb{Q}$ where the rare event is more frequent, and then correct for this bias using a likelihood ratio. The change of measure is achieved by adding a control term to the drift of the slow variable $y_t$. The controlled SDE for $y_t$ under $\\mathbb{Q}$ becomes:\n$$\n\\mathrm{d}\\tilde{y}_t = \\left[\\delta\\left(\\tilde{x}_t - \\lambda\\,\\tilde{y}_t\\right) + g(\\tilde{x}_t, \\tilde{y}_t) \\right]\\,\\mathrm{d}t + \\sigma_y\\,\\mathrm{d}\\tilde{W}^{y}_t,\n$$\nwhere $\\tilde{W}^{y}_t$ is a standard Wiener process under $\\mathbb{Q}$, and $g$ is the added drift. The control strategy is to steer the slow variable $y_t$ towards a target value $y_{\\star}$ that makes the threshold crossing for $x_t$ more likely. This target is derived from the slow manifold condition at $x=x_{\\mathrm{thr}}$: $y_{\\star} = x_{\\mathrm{thr}} - x_{\\mathrm{thr}}^3$. The added drift is implemented via a proportional feedback term $g_n = \\sigma_y u_{y,n}$, with $u_{y,n} = \\kappa(y_{\\star} - y_n)$.\n\nThe change of measure from $\\mathbb{P}$ to $\\mathbb{Q}$ introduces a likelihood ratio $L_T = \\mathrm{d}\\mathbb{Q}/\\mathrm{d}\\mathbb{P}$. The unbiased IS estimator for $\\mathbb{P}(\\mathcal{E})$ is $\\hat{P}_{\\mathrm{IS}} = \\frac{1}{N}\\sum_{i=1}^{N} \\mathbf{1}_{\\mathcal{E}}^{(i)} L_T^{-1,(i)}$. According to Girsanov's theorem, for an added drift $g_t$ and diffusion coefficient $\\sigma_t$, the Girsanov control process is $h_t = g_t/\\sigma_t$. In our case, the added drift to the $y$-dynamics is $g_n = \\sigma_y u_{y,n}$ and the diffusion coefficient is $\\sigma_y$, so the control process is simply $h_n = u_{y,n}$. The log-likelihood ratio for a path up to time $T = M\\Delta t$ is given by the discrete sum:\n$$\n\\log L_M^{-1} = -\\sum_{n=0}^{M-1} u_{y,n}\\,\\Delta \\tilde{W}_n^y - \\frac{1}{2}\\sum_{n=0}^{M-1} u_{y,n}^2\\,\\Delta t\n$$\nwhere $\\Delta \\tilde{W}_n^y$ is the Wiener increment under the biased measure $\\mathbb{Q}$, which is generated in the simulation. This formula is used to update the weight of each simulated trajectory.\n\nThe algorithm for each test case is as follows:\n1. Initialize parameters and pre-compute constants: $\\sigma_x, \\sigma_y, N_{\\mathrm{steps}}, y_{\\star}$.\n2. For each of the $N$ simulations:\n    a. Initialize state $(x, y) = (x_0, y_0)$ and log-likelihood $\\log L^{-1} = 0$.\n    b. For each time step, generate Wiener increments, calculate the control $u_{y,n}$, update the log-likelihood, and update the state variables using the controlled Euler-Maruyama scheme.\n    c. If $x_{n+1} \\geq x_{\\mathrm{thr}}$, the event occurs. The trajectory is terminated, and its contribution to the estimator, $\\exp(\\log L^{-1})$, is recorded.\n3. The final estimate is the average of contributions over all $N$ trajectories. This procedure is repeated for all four test cases.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n\n    # Test suite parameter sets:\n    # (epsilon, delta, lambda, x0, y0, x_thr, T, dt, N, kappa)\n    test_cases = [\n        (0.01, 0.05, 1.0, -1.0, 0.2, 0.8, 2.5, 0.01, 3000, 0.0), # Case A\n        (0.01, 0.05, 1.0, -1.0, 0.2, 0.8, 2.5, 0.01, 3000, 2.0), # Case B\n        (0.01, 0.05, 1.0, -1.0, 0.2, 0.8, 2.5, 0.01, 3000, 5.0), # Case C\n        (0.01, 0.02, 1.0, -1.0, 0.2, 0.8, 2.5, 0.01, 3000, 2.0), # Case D\n    ]\n\n    results = []\n    # Use a fixed seed for reproducibility of the results.\n    rng = np.random.default_rng(seed=42)\n\n    for params in test_cases:\n        prob = run_simulation(params, rng)\n        results.append(prob)\n\n    # Format the output as specified\n    print(f\"[{','.join(f'{p:.7f}' for p in results)}]\")\n\n\ndef run_simulation(params, rng):\n    \"\"\"\n    Runs a Monte Carlo or Importance Sampling simulation for a single parameter set.\n\n    Args:\n        params (tuple): A tuple containing the simulation parameters.\n        rng (np.random.Generator): The random number generator instance.\n\n    Returns:\n        float: The estimated probability of the rare event.\n    \"\"\"\n    epsilon, delta, lam, x0, y0, x_thr, T, dt, N, kappa = params\n\n    # Pre-calculate constants for the simulation\n    num_steps = int(T / dt)\n    sigma_x = np.sqrt(2 * epsilon)\n    sigma_y = np.sqrt(2 * epsilon * delta)\n    sqrt_dt = np.sqrt(dt)\n\n    # Target slow state y_star for importance sampling control\n    y_star = x_thr - x_thr**3\n\n    total_weighted_indicators = 0.0\n\n    for _ in range(N):\n        x, y = x0, y0\n        log_L_inv = 0.0\n        crossed = False\n\n        for _ in range(num_steps):\n            # Generate Wiener increments dW ~ N(0, dt)\n            dw_x = rng.normal(0.0, sqrt_dt)\n            dw_y = rng.normal(0.0, sqrt_dt)\n            \n            # This dw_y corresponds to the increment of the Wiener process under the\n            # biased measure Q, i.e., dW_tilde in the theoretical formulation.\n\n            # Calculate IS control (kappa=0.0 for Direct Monte Carlo)\n            u_y = kappa * (y_star - y)\n\n            # Update the logarithm of the likelihood ratio L^-1 = dP/dQ\n            # log(L_inv) -= u * dW_tilde + 0.5 * u^2 * dt\n            if kappa > 0:\n                log_L_inv -= (u_y * dw_y + 0.5 * u_y**2 * dt)\n\n            # Update state variables using the Euler-Maruyama scheme\n            # Drift terms\n            drift_x = x - x**3 - y\n            drift_y = delta * (x - lam * y)\n            \n            # Update x\n            x_next = x + drift_x * dt + sigma_x * dw_x\n            \n            # Update y with the control term\n            # The controlled drift is (drift_y + sigma_y * u_y)\n            y_next = y + (drift_y + sigma_y * u_y) * dt + sigma_y * dw_y\n            \n            x, y = x_next, y_next\n\n            # Check for threshold crossing\n            if x >= x_thr:\n                crossed = True\n                break\n        \n        if crossed:\n            # For IS, add the weighted indicator. For DMC (kappa=0), L_inv=1.\n            total_weighted_indicators += np.exp(log_L_inv)\n\n    # The probability is the mean of the (weighted) indicators\n    probability_estimate = total_weighted_indicators / N\n    \n    return probability_estimate\n\n# Run the full solution\nsolve()\n```"
        }
    ]
}