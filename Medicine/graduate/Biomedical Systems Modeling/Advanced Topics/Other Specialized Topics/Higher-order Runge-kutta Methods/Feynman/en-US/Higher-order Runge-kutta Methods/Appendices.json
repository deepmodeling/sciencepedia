{
    "hands_on_practices": [
        {
            "introduction": "The classical fourth-order Runge-Kutta method (RK4) is a cornerstone of numerical integration. To truly understand what \"fourth-order\" means and to quantify its accuracy, we can analyze its performance on the simple yet powerful linear test equation, $y' = \\lambda y$. This exercise  guides you through deriving the method's stability polynomial and comparing it to the exact solution's Taylor series to reveal the leading-order error term, providing a concrete measure of the method's local accuracy.",
            "id": "3890894",
            "problem": "A common step in simulating biochemical reaction networks in biomedical systems modeling is to integrate stiff or mildly stiff modes that arise from linearization around an equilibrium. Consider a single linearized mode governed by the Ordinary Differential Equation (ODE) $y' = \\lambda y$, where $\\lambda \\in \\mathbb{C}$ models the local eigenvalue of the linearized dynamics near equilibrium in a biochemical pathway. The simulation employs the classical Runge-Kutta fourth-order method (RK4) with fixed step size $h > 0$. Let $z = \\lambda h$ and denote the one-step exact amplification factor by $\\exp(z)$ and the RK4 amplification factor by the stability polynomial $R(z)$. The leading-order local truncation error of the RK4 one-step map for this test equation can be extracted by comparing the series expansion of the exact amplification factor with that of the RK4 stability polynomial.\n\nStarting from first principles for $y' = \\lambda y$, derive $R(z)$ by applying the classical RK4 stages to this test equation, and then compute the leading-order error constant $c$ in the expansion\n$$\n\\exp(z) - R(z) = c\\, z^{5} + \\mathcal{O}\\!\\left(z^{6}\\right).\n$$\nYour final answer must be the exact value of $c$ as a single real-valued number or a closed-form analytic expression. Express your answer as an exact fraction. No rounding is required, and no units are needed because $c$ is dimensionless.",
            "solution": "The problem requires the derivation of the leading-order error constant for the classical fourth-order Runge-Kutta (RK4) method when applied to the test equation $y' = \\lambda y$. This involves deriving the stability polynomial $R(z)$ for RK4 and comparing its series expansion to that of the exact amplification factor, $\\exp(z)$, where $z = \\lambda h$.\n\nFirst, we state the classical RK4 method for a general ordinary differential equation (ODE) of the form $y' = f(t, y)$. The one-step update from $y_n$ at time $t_n$ to $y_{n+1}$ at time $t_{n+1} = t_n + h$ is given by:\n$$y_{n+1} = y_n + \\frac{h}{6}(k_1 + 2k_2 + 2k_3 + k_4)$$\nwhere the stages $k_i$ are defined as:\n$$k_1 = f(t_n, y_n)$$\n$$k_2 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_1\\right)$$\n$$k_3 = f\\left(t_n + \\frac{h}{2}, y_n + \\frac{h}{2}k_2\\right)$$\n$$k_4 = f\\left(t_n + h, y_n + h k_3\\right)$$\n\nWe apply this method to the specific test equation $y' = \\lambda y$, where $f(t, y) = \\lambda y$. Let $z = \\lambda h$. We now compute the stages $k_i$ in terms of $y_n$, $\\lambda$, and $h$:\n\n1.  The first stage, $k_1$:\n    $$k_1 = \\lambda y_n$$\n\n2.  The second stage, $k_2$:\n    $$k_2 = \\lambda \\left(y_n + \\frac{h}{2}k_1\\right) = \\lambda \\left(y_n + \\frac{h}{2}(\\lambda y_n)\\right) = \\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\right) = \\lambda y_n \\left(1 + \\frac{z}{2}\\right)$$\n\n3.  The third stage, $k_3$:\n    $$k_3 = \\lambda \\left(y_n + \\frac{h}{2}k_2\\right) = \\lambda \\left(y_n + \\frac{h}{2}\\left[\\lambda y_n \\left(1 + \\frac{z}{2}\\right)\\right]\\right) = \\lambda y_n \\left(1 + \\frac{\\lambda h}{2}\\left(1 + \\frac{z}{2}\\right)\\right) = \\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right)$$\n\n4.  The fourth stage, $k_4$:\n    $$k_4 = \\lambda (y_n + h k_3) = \\lambda \\left(y_n + h\\left[\\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right)\\right]\\right) = \\lambda y_n \\left(1 + \\lambda h\\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right)\\right) = \\lambda y_n \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)$$\n\nNow, we substitute these expressions back into the update formula for $y_{n+1}$:\n$$y_{n+1} = y_n + \\frac{h}{6} \\left[\\lambda y_n + 2\\lambda y_n \\left(1 + \\frac{z}{2}\\right) + 2\\lambda y_n \\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) + \\lambda y_n \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\\right]$$\nWe can factor out $y_n$ from the right-hand side to find the amplification factor $R(z) = y_{n+1}/y_n$:\n$$\\frac{y_{n+1}}{y_n} = 1 + \\frac{\\lambda h}{6} \\left[1 + 2\\left(1 + \\frac{z}{2}\\right) + 2\\left(1 + \\frac{z}{2} + \\frac{z^2}{4}\\right) + \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\\right]$$\nSubstituting $z = \\lambda h$:\n$$R(z) = 1 + \\frac{z}{6} \\left[1 + (2+z) + \\left(2+z + \\frac{z^2}{2}\\right) + \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{4}\\right)\\right]$$\nNow, we collect terms inside the brackets according to powers of $z$:\n$$R(z) = 1 + \\frac{z}{6} \\left[(1+2+2+1) + (1+1+1)z + \\left(\\frac{1}{2}+\\frac{1}{2}\\right)z^2 + \\left(\\frac{1}{4}\\right)z^3\\right]$$\n$$R(z) = 1 + \\frac{z}{6} \\left[6 + 3z + z^2 + \\frac{z^3}{4}\\right]$$\nDistributing the $\\frac{z}{6}$ term, we obtain the stability polynomial for RK4:\n$$R(z) = 1 + z + \\frac{3z^2}{6} + \\frac{z^3}{6} + \\frac{z^4}{24}$$\n$$R(z) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}$$\nThis can be written using factorials:\n$$R(z) = 1 + \\frac{z}{1!} + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!}$$\n\nThe problem requires us to find the leading-order error constant $c$ from the expression $\\exp(z) - R(z) = c z^5 + \\mathcal{O}(z^6)$. The exact amplification factor for one step of size $h$ for the ODE $y'=\\lambda y$ is $\\exp(\\lambda h) = \\exp(z)$. The Taylor series expansion of $\\exp(z)$ around $z=0$ is:\n$$\\exp(z) = \\sum_{k=0}^{\\infty} \\frac{z^k}{k!} = 1 + \\frac{z}{1!} + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!} + \\frac{z^5}{5!} + \\mathcal{O}(z^6)$$\nSubstituting the known values for the factorials:\n$$\\exp(z) = 1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24} + \\frac{z^5}{120} + \\mathcal{O}(z^6)$$\nThe difference $\\exp(z) - R(z)$ represents the local truncation error for a single step:\n$$\\exp(z) - R(z) = \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24} + \\frac{z^5}{120} + \\mathcal{O}(z^6)\\right) - \\left(1 + z + \\frac{z^2}{2} + \\frac{z^3}{6} + \\frac{z^4}{24}\\right)$$\nThe terms up to order $z^4$ cancel out, which is expected for a fourth-order method. The first non-zero term is the $z^5$ term:\n$$\\exp(z) - R(z) = \\frac{z^5}{120} + \\mathcal{O}(z^6)$$\nComparing this result to the given form $\\exp(z) - R(z) = c z^5 + \\mathcal{O}(z^6)$, we can directly identify the constant $c$:\n$$c = \\frac{1}{120}$$\nThis is the leading-order error constant for the classical RK4 method.",
            "answer": "$$\\boxed{\\frac{1}{120}}$$"
        },
        {
            "introduction": "Beyond analyzing existing methods, a deeper understanding comes from constructing one from first principles. This practice  challenges you to derive the coefficients for a family of third-order explicit Runge-Kutta methods by solving the underlying algebraic order conditions. Furthermore, it pushes you to consider a crucial constraint in biomedical modeling—positivity—and investigate how this practical requirement restricts the design choices for a provably accurate method.",
            "id": "3890888",
            "problem": "A pharmacokinetic one-compartment model with elimination is governed by the ordinary differential equation (ODE) $dx/dt = f(t,x)$ with $x(t) \\ge 0$ representing the drug amount. In biomedical systems modeling of such dynamics, one often seeks time-stepping schemes that are accurate and that preserve nonnegativity of stage evaluations and weights to avoid introducing artificial negative concentrations. Consider an explicit $3$-stage Runge-Kutta (RK) method for approximating solutions of $dx/dt = f(t,x)$ over a stepsize $h>0$, specified by a strictly lower-triangular Butcher matrix $A \\in \\mathbb{R}^{3 \\times 3}$, weights $b \\in \\mathbb{R}^{3}$, and nodes $c \\in \\mathbb{R}^{3}$ with $c_1 = 0$, $c_2 \\in (0,1)$, and $c_3 = 1$. The method is required to satisfy the third-order conditions up to order $3$ (using the standard rooted-tree moment constraints): $b^{\\top}\\mathbf{1} = 1$, $b^{\\top} c = 1/2$, $b^{\\top} c^{[2]} = 1/3$, and $b^{\\top} A c = 1/6$, where $\\mathbf{1} = (1,1,1)^{\\top}$ and $c^{[2]}$ denotes the elementwise square of $c$. Assume the method is explicit so that $c_2 = a_{21}$ and $c_3 = a_{31} + a_{32}$.\n\nDerive, from first principles starting at the definition of explicit Runge-Kutta methods and the above order conditions, explicit expressions for $b_2$ and $b_3$ in terms of $c_2$ and $c_3$, then specialize to $c_3 = 1$ to obtain $b_2(c_2)$ and $b_3(c_2)$. Next, use the condition $b^{\\top} A c = 1/6$ to express $a_{32}$ and $a_{31}$ in terms of $c_2$ and $b_3$. Discuss the feasibility of the resulting $(A,b,c)$ under the biomedical nonnegativity desiderata, including whether $a_{31}$ can be nonnegative, and identify any restrictions on $c_2$ required for the weights to be nonnegative.\n\nFinally, report the supremum of $c_2 \\in (0,1)$ for which all weights $b_1$, $b_2$, and $b_3$ are nonnegative and the order conditions admit a finite explicit scheme with $c_3 = 1$. Your final answer must be a single number written exactly (no rounding). No units are required. If you use any approximations in intermediate steps, do not round the final result.",
            "solution": "The problem requires the derivation of coefficients for a family of 3-stage, third-order explicit Runge-Kutta methods, subject to specific constraints on the nodes, and an analysis of nonnegativity conditions.\n\n**1. Derivation of the weights $b_i$**\n\nThe first three order conditions provide a linear system for the weights $b_1, b_2, b_3$:\n1. $b_1 + b_2 + b_3 = 1$\n2. $b_1 c_1 + b_2 c_2 + b_3 c_3 = 1/2$\n3. $b_1 c_1^2 + b_2 c_2^2 + b_3 c_3^2 = 1/3$\n\nGiven $c_1 = 0$ and specializing to $c_3 = 1$, the system becomes:\n1. $b_1 + b_2 + b_3 = 1$\n2. $b_2 c_2 + b_3 = 1/2$\n3. $b_2 c_2^2 + b_3 = 1/3$\n\nSubtracting the third equation from the second gives:\n$b_2(c_2 - c_2^2) = 1/2 - 1/3 = 1/6$\n$b_2 c_2(1 - c_2) = 1/6$\nSince $c_2 \\in (0,1)$, we can solve for $b_2$:\n$$b_2 = \\frac{1}{6c_2(1 - c_2)}$$\nFrom the second simplified equation, we find $b_3$:\n$$b_3 = \\frac{1}{2} - b_2 c_2 = \\frac{1}{2} - \\frac{c_2}{6c_2(1 - c_2)} = \\frac{1}{2} - \\frac{1}{6(1 - c_2)} = \\frac{3(1-c_2) - 1}{6(1-c_2)} = \\frac{2 - 3c_2}{6(1-c_2)}$$\nFinally, we use the first equation to find $b_1$:\n$$b_1 = 1 - b_2 - b_3 = 1 - \\frac{1}{6c_2(1 - c_2)} - \\frac{2 - 3c_2}{6(1 - c_2)}$$\nUsing a common denominator $6c_2(1-c_2)$:\n$$b_1 = \\frac{6c_2(1-c_2) - 1 - c_2(2 - 3c_2)}{6c_2(1-c_2)} = \\frac{6c_2 - 6c_2^2 - 1 - 2c_2 + 3c_2^2}{6c_2(1-c_2)} = \\frac{-3c_2^2 + 4c_2 - 1}{6c_2(1-c_2)}$$\nThe numerator is $-(3c_2^2 - 4c_2 + 1) = -(3c_2 - 1)(c_2 - 1)$.\n$$b_1 = \\frac{-(3c_2 - 1)(c_2 - 1)}{6c_2(1-c_2)} = \\frac{(3c_2 - 1)(1 - c_2)}{6c_2(1-c_2)}$$\nSince $c_2 \\neq 1$, we can simplify:\n$$b_1 = \\frac{3c_2 - 1}{6c_2}$$\n\n**2. Derivation of the matrix coefficients $a_{31}$ and $a_{32}$**\n\nThe fourth order condition is $b^{\\top} A c = 1/6$. For a 3-stage explicit method with $c_1=0, c_2, c_3=1$, this is:\n$b_2 a_{21} c_2 + b_3(a_{31} c_2 + a_{32} c_3) = 1/6$\nUsing the simplifying conditions $a_{21}=c_2$ and $c_3=1$:\n$b_2 c_2^2 + b_3(a_{31} c_2 + a_{32}) = 1/6$\nWe also have $a_{31} + a_{32} = c_3 = 1$. Let's solve for $a_{32}$.\n$a_{31} c_2 + a_{32} = (1-a_{32})c_2 + a_{32} = c_2 + a_{32}(1-c_2)$.\nSubstituting this into the order condition:\n$b_2 c_2^2 + b_3(c_2 + a_{32}(1-c_2)) = 1/6$\n$a_{32} b_3(1-c_2) = 1/6 - b_2 c_2^2 - b_3 c_2$\n$$a_{32} = \\frac{1/6 - b_2 c_2^2 - b_3 c_2}{b_3(1-c_2)}$$\nLet's evaluate the numerator and denominator.\nDenominator: $b_3(1-c_2) = \\frac{2 - 3c_2}{6(1-c_2)}(1-c_2) = \\frac{2-3c_2}{6}$.\nNumerator:\n$1/6 - \\left(\\frac{1}{6c_2(1 - c_2)}\\right)c_2^2 - \\left(\\frac{2 - 3c_2}{6(1-c_2)}\\right)c_2 = \\frac{1}{6} - \\frac{c_2}{6(1-c_2)} - \\frac{c_2(2-3c_2)}{6(1-c_2)}$\n$= \\frac{1}{6} \\left( 1 - \\frac{c_2 + 2c_2 - 3c_2^2}{1-c_2} \\right) = \\frac{1}{6} \\left( \\frac{1-c_2 - (3c_2 - 3c_2^2)}{1-c_2} \\right) = \\frac{1-4c_2+3c_2^2}{6(1-c_2)}$\nThe numerator of this fraction is $(1-c_2)(1-3c_2)$.\nSo, Numerator $= \\frac{(1-c_2)(1-3c_2)}{6(1-c_2)} = \\frac{1-3c_2}{6}$.\nThus,\n$$a_{32} = \\frac{(1-3c_2)/6}{(2-3c_2)/6} = \\frac{1-3c_2}{2-3c_2}$$\nAnd $a_{31} = 1 - a_{32} = 1 - \\frac{1-3c_2}{2-3c_2} = \\frac{2-3c_2 - (1-3c_2)}{2-3c_2} = \\frac{1}{2-3c_2}$.\n\n**3. Feasibility and Nonnegativity Analysis**\n\nThe problem asks for restrictions on $c_2 \\in (0,1)$ required for the weights to be nonnegative.\n- $b_1 = \\frac{3c_2 - 1}{6c_2} \\ge 0 \\implies 3c_2 - 1 \\ge 0 \\implies c_2 \\ge \\frac{1}{3}$.\n- $b_2 = \\frac{1}{6c_2(1 - c_2)} > 0$ for all $c_2 \\in (0,1)$.\n- $b_3 = \\frac{2 - 3c_2}{6(1-c_2)} \\ge 0 \\implies 2 - 3c_2 \\ge 0 \\implies c_2 \\le \\frac{2}{3}$.\nCombining these, for all weights to be nonnegative, $c_2$ must be in the interval $[\\frac{1}{3}, \\frac{2}{3}]$.\n\nThe problem also asks to discuss the feasibility of non-negative $a_{ij}$.\n- $a_{31} = \\frac{1}{2-3c_2} \\ge 0 \\implies 2-3c_2 > 0 \\implies c_2  \\frac{2}{3}$.\n- $a_{32} = \\frac{1-3c_2}{2-3c_2} \\ge 0$. This requires the numerator and denominator to have the same sign. Given $c_2  2/3$ (for $a_{31} \\ge 0$), the denominator is positive. Thus, we need the numerator $1-3c_2 \\ge 0$, which implies $c_2 \\le 1/3$.\nFor a fully non-negative scheme ($b_i \\ge 0$ and $a_{ij} \\ge 0$), we need $c_2 \\in [1/3, 2/3]$ AND $c_2  2/3$ AND $c_2 \\le 1/3$. This is satisfied only at the single point $c_2 = 1/3$.\n\n**4. Supremum of $c_2$**\n\nThe final question asks for the supremum of $c_2 \\in (0,1)$ for which all weights $b_i$ are nonnegative and the scheme is finite (i.e., has finite coefficients).\n- The condition for non-negative weights is $c_2 \\in [\\frac{1}{3}, \\frac{2}{3}]$.\n- The scheme coefficients are finite as long as the denominators are non-zero. The denominators are $c_2$, $1-c_2$, and $2-3c_2$. The constraints $c_2 \\in (0,1)$ already handle the first two. The third requires $c_2 \\neq \\frac{2}{3}$.\n- Therefore, the set of $c_2$ values satisfying both conditions is $[\\frac{1}{3}, \\frac{2}{3})$.\nThe supremum of this set is the least upper bound, which is $\\frac{2}{3}$.",
            "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$"
        },
        {
            "introduction": "The ultimate test of a numerical method lies in its performance on a representative scientific problem. This hands-on coding practice  moves from theory to simulation, tasking you with implementing and comparing two different higher-order methods on a metabolic pathway model. You will see firsthand how a method specifically designed with structural properties in mind (a Strong Stability Preserving method) behaves differently from a general-purpose one, especially regarding the physical constraints of positivity and mass conservation.",
            "id": "3890900",
            "problem": "A sequential metabolic pathway with three metabolites is modeled as an ordinary differential equation (ODE) under first-order mass-action kinetics. Let the metabolite concentrations be $x_1(t)$, $x_2(t)$, and $x_3(t)$, each in millimolar (mM), and let the rate constants be $k_1$ and $k_2$, each in inverse seconds ($\\text{s}^{-1}$). The pathway is $x_1 \\rightarrow x_2 \\rightarrow x_3$, resulting in the autonomous system\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\nx_3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-k_1 x_1 \\\\\nk_1 x_1 - k_2 x_2 \\\\\nk_2 x_2\n\\end{bmatrix},\n$$\nwith initial condition $x(0) = [x_1(0), x_2(0), x_3(0)]^\\top$ and terminal time $T  0$. This system preserves the invariant $I(t) = x_1(t) + x_2(t) + x_3(t)$, so that $I(t) = I(0)$ for all $t \\ge 0$, and the exact solution maintains positivity $x_i(t) \\ge 0$ for all $i \\in \\{1,2,3\\}$ and all $t \\ge 0$.\n\nYou must implement two explicit time-integration methods:\n- A Strong Stability Preserving Runge-Kutta (SSP RK) method of order $3$ with $3$ stages (denoted SSPRK$(3,3)$).\n- The classical Runge-Kutta method of order $4$ (denoted RK$4$), which is not Strong Stability Preserving.\n\nBoth methods must be run under identical adaptive tolerance control. Use the following step-doubling local error estimator: given a current state $x$ at time $t$, a proposed step size $h  0$, and a Runge-Kutta method of order $p$, compute one full step $y_h$ with step size $h$ and two half steps $y_{h/2}$ with step size $h/2$ applied twice. Define the local error estimate\n$$\ne = \\|y_{h/2} - y_h\\|_{\\infty}.\n$$\nAccept the step if $e \\le \\tau$, where $\\tau  0$ is the given tolerance. On acceptance, advance the solution using the more accurate two-half-step value $y_{h/2}$. Update the step size using the identical control law for both methods,\n$$\nh_{\\text{new}} = s \\, h \\left(\\frac{\\tau}{\\max(e, \\epsilon)}\\right)^{\\frac{1}{p+1}},\n$$\nwhere $s$ is a safety factor and $\\epsilon$ is a small positive floor to avoid division by zero. On rejection, do not advance time and reduce $h$ using the same formula. Ensure that the last step exactly reaches $T$ by truncating $h$ if necessary. Do not clamp or otherwise modify negative states; any negativity must be recorded.\n\nDefine positivity preservation as the condition that for all accepted step endpoints $t_n$, the minimum component satisfies $\\min_i x_i(t_n) \\ge 0$, within a strict absolute threshold $\\epsilon_p = 10^{-12}$. Declare positivity preserved if and only if $\\min_i x_i(t_n) \\ge -\\epsilon_p$ for all $n$. Define invariant error as the absolute deviation of the invariant at the terminal time,\n$$\nE_{\\text{inv}} = \\left| \\left(x_1(T) + x_2(T) + x_3(T)\\right) - \\left(x_1(0) + x_2(0) + x_3(0)\\right) \\right|.\n$$\n\nImplement both methods with the same adaptive tolerance $\\tau$, the same safety factor $s$, and the same $\\epsilon$. Use the same initial step size selection strategy for both methods. The program must evaluate and report, for each test case, the positivity preservation booleans and the invariant errors for both methods.\n\nUse the following test suite:\n- Case $1$: $k_1 = 1.0$, $k_2 = 0.5$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 10.0$, $\\tau = 10^{-6}$.\n- Case $2$: $k_1 = 1.0$, $k_2 = 0.5$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 10.0$, $\\tau = 10^{-3}$.\n- Case $3$: $k_1 = 10.0$, $k_2 = 1.0$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 2.0$, $\\tau = 10^{-5}$.\n- Case $4$: $k_1 = 0.1$, $k_2 = 0.1$, $x(0) = [1.0, 0.0, 0.0]^\\top$, $T = 100.0$, $\\tau = 10^{-6}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist in the order\n$$\n[\\text{pos}_{\\text{SSP}}, \\text{pos}_{\\text{RK4}}, E_{\\text{inv,SSP}}, E_{\\text{inv,RK4}}],\n$$\nwith booleans $\\text{pos}_{\\text{SSP}}$ and $\\text{pos}_{\\text{RK4}}$, and floats $E_{\\text{inv,SSP}}$ and $E_{\\text{inv,RK4}}$. The final output must be a list of these four-element lists for the four cases, for example\n$$\n[[\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}], [\\text{bool},\\text{bool},\\text{float},\\text{float}]].\n$$\nNo physical units are required in the output; report only the specified booleans and floats.",
            "solution": "The sequential metabolic pathway with first-order mass-action kinetics is a linear compartment model in which the state vector $x(t) = [x_1(t), x_2(t), x_3(t)]^\\top$ evolves under\n$$\n\\frac{d x}{d t} = f(x) =\n\\begin{bmatrix}\n-k_1 x_1 \\\\\nk_1 x_1 - k_2 x_2 \\\\\nk_2 x_2\n\\end{bmatrix},\n$$\nwith $x(0) = x_0$. This formulation is grounded in the widely accepted law of mass action, which dictates that a unimolecular reaction $X \\rightarrow Y$ proceeds at a rate $v = k \\, x$, where $k$ is the rate constant and $x$ is the concentration of the reactant. The system matrix is Metzler (nonnegative off-diagonals), which implies that the positive orthant is forward invariant for the exact dynamics, and the invariant $I(t) = x_1(t) + x_2(t) + x_3(t)$ is conserved because the net flux is internal to the pathway, yielding\n$$\n\\frac{d}{dt} \\left( x_1 + x_2 + x_3 \\right) = -k_1 x_1 + \\left(k_1 x_1 - k_2 x_2\\right) + k_2 x_2 = 0.\n$$\n\nTo numerically approximate $x(T)$, we use explicit Runge-Kutta methods. A method of order $p$ satisfies that its local truncation error scales as $\\mathcal{O}(h^{p+1})$ for step size $h$. The Strong Stability Preserving (SSP) Runge-Kutta method SSPRK$(3,3)$ is constructed so that, under the same time-step restriction that guarantees stability for the forward Euler method, it preserves certain monotonicity properties such as positivity for suitable classes of problems (including linear systems with a Metzler matrix). In Shu-Osher form, SSPRK$(3,3)$ can be written as a convex combination of forward Euler steps:\n1. $u^{(1)} = u^n + h f(u^n)$,\n2. $u^{(2)} = \\frac{3}{4} u^n + \\frac{1}{4} \\left( u^{(1)} + h f(u^{(1)}) \\right)$,\n3. $u^{n+1} = \\frac{1}{3} u^n + \\frac{2}{3} \\left( u^{(2)} + h f(u^{(2)}) \\right)$.\nEach stage is a convex combination with nonnegative coefficients, so if forward Euler preserves positivity under a given step size bound, the SSP scheme will also preserve positivity under that bound.\n\nThe classical Runge-Kutta method of order $4$ (RK$4$) is defined by its stages\n$$\nk_1 = f(u^n), \\quad\nk_2 = f\\left(u^n + \\frac{h}{2} k_1\\right), \\quad\nk_3 = f\\left(u^n + \\frac{h}{2} k_2\\right), \\quad\nk_4 = f\\left(u^n + h k_3\\right),\n$$\nand update\n$$\nu^{n+1} = u^n + \\frac{h}{6} \\left( k_1 + 2 k_2 + 2 k_3 + k_4 \\right).\n$$\nThis method is not Strong Stability Preserving; it can violate monotonicity or positivity even when forward Euler would not, depending on step size.\n\nTo enforce identical tolerance control across both methods, we use step doubling to estimate the local error. Given a proposed $h$ at state $x$, compute $y_h$ using one step of the method and $y_{h/2}$ using two consecutive half steps. The infinity-norm error estimate is $e = \\|y_{h/2} - y_h\\|_\\infty$. Accept the step if $e \\le \\tau$ and advance the solution using $y_{h/2}$, as it is the more accurate approximation. The step size update uses the fact that local error scales as $h^{p+1}$:\n$$\nh_{\\text{new}} = s \\, h \\left(\\frac{\\tau}{\\max(e, \\epsilon)}\\right)^{\\frac{1}{p+1}},\n$$\nwith a safety factor $s$ to avoid aggressive changes and a small floor $\\epsilon$ to handle vanishing error estimates. On rejection ($e  \\tau$), the same update formula reduces $h$, and the state and time are not advanced.\n\nPositivity preservation is evaluated by checking the minimum state component at every accepted step endpoint. Define $\\epsilon_p = 10^{-12}$; if $\\min_i x_i(t_n) \\ge -\\epsilon_p$ for all accepted times $t_n$, we declare positivity preserved. Invariant preservation is evaluated by computing $E_{\\text{inv}} = |(x_1(T) + x_2(T) + x_3(T)) - (x_1(0) + x_2(0) + x_3(0))|$.\n\nAlgorithmic steps:\n- Initialize $t = 0$, $x = x_0$, and set $h$ to a reasonable initial guess (for example, $h = \\min(0.1, T/10)$), safety factor $s$ (for example, $s = 0.9$), and floor $\\epsilon$ (for example, $\\epsilon = 10^{-16}$).\n- While $t  T$:\n  - Set $h = \\min(h, T - t)$ to ensure $t$ does not overshoot $T$.\n  - Compute $y_h$ via one full step and $y_{h/2}$ via two half steps.\n  - Compute $e = \\|y_{h/2} - y_h\\|_\\infty$.\n  - If $e \\le \\tau$ or $h$ is at the numerical floor:\n    - Accept: set $x \\leftarrow y_{h/2}$, update the running minimum $\\min_i x_i$, and $t \\leftarrow t + h$.\n    - Update $h$ using $h_{\\text{new}}$ with exponent $1/(p+1)$.\n  - Else:\n    - Reject: reduce $h$ using the same update formula and repeat without advancing $t$ or $x$.\n- After reaching $T$, compute $E_{\\text{inv}}$ and $\\text{pos}$ using the saved minimum.\n\nThis design ensures a principled, method-agnostic tolerance control while isolating the impact of SSP structure on positivity and invariant preservation. The test suite covers a typical pathway ($k_1 = 1.0$, $k_2 = 0.5$) under both stringent ($\\tau = 10^{-6}$) and coarse ($\\tau = 10^{-3}$) tolerances, a faster upstream reaction ($k_1 = 10.0$, $k_2 = 1.0$) to probe stiffness-like behavior, and a slow, long-duration scenario ($k_1 = 0.1$, $k_2 = 0.1$, $T = 100.0$) to examine cumulative invariant errors. The outputs are booleans and floats that quantify positivity and invariant preservation for both SSPRK$(3,3)$ and RK$4$ under identical tolerances.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x, k1, k2):\n    # RHS of the metabolic pathway ODE: x1 - x2 - x3\n    dx1 = -k1 * x[0]\n    dx2 = k1 * x[0] - k2 * x[1]\n    dx3 = k2 * x[1]\n    return np.array([dx1, dx2, dx3], dtype=float)\n\ndef ssprk3_step(x, h, k1, k2):\n    # SSPRK(3,3) in Shu-Osher form\n    f1 = f(x, k1, k2)\n    u1 = x + h * f1\n    f2 = f(u1, k1, k2)\n    u2 = (3.0/4.0) * x + (1.0/4.0) * (u1 + h * f2)\n    f3 = f(u2, k1, k2)\n    u3 = (1.0/3.0) * x + (2.0/3.0) * (u2 + h * f3)\n    return u3\n\ndef rk4_step(x, h, k1, k2):\n    # Classical RK4\n    k1v = f(x, k1, k2)\n    k2v = f(x + 0.5 * h * k1v, k1, k2)\n    k3v = f(x + 0.5 * h * k2v, k1, k2)\n    k4v = f(x + h * k3v, k1, k2)\n    return x + (h / 6.0) * (k1v + 2.0 * k2v + 2.0 * k3v + k4v)\n\ndef integrate(method_step, order, x0, T, tau, k1, k2,\n              safety=0.9, eps_floor=1e-16, min_h=1e-16, max_growth=2.0):\n    # Adaptive integration using step-doubling error estimate\n    t = 0.0\n    x = x0.copy()\n    total0 = float(np.sum(x))\n    min_comp = float(np.min(x))\n    # Initial step heuristic\n    h = min(0.1, T / 10.0) if T  0 else 0.0\n\n    # Guard against T == 0\n    if T == 0.0:\n        inv_err = abs(float(np.sum(x)) - total0)\n        pos_preserved = (min_comp = -1e-12)\n        return pos_preserved, inv_err\n\n    while t  T:\n        # Prevent overshoot\n        h = min(h, T - t)\n        if h  min_h:\n            # Accept tiny step to avoid stalling\n            y_full = method_step(x, h, k1, k2)\n            y_half = method_step(method_step(x, 0.5 * h, k1, k2), 0.5 * h, k1, k2)\n            x = y_half\n            t += h\n            min_comp = min(min_comp, float(np.min(x)))\n            # Attempt to grow step modestly\n            h = min(max_growth * h, T - t if T - t  0 else h)\n            continue\n\n        # One full step\n        y_full = method_step(x, h, k1, k2)\n        # Two half steps\n        y_half = method_step(method_step(x, 0.5 * h, k1, k2), 0.5 * h, k1, k2)\n\n        # Infinity-norm error estimate\n        e = float(np.max(np.abs(y_half - y_full)))\n\n        if e = tau or h = min_h:\n            # Accept: advance with the more accurate two-half-step value\n            x = y_half\n            t += h\n            min_comp = min(min_comp, float(np.min(x)))\n            # Update step size\n            exponent = 1.0 / (order + 1)\n            h_candidate = safety * h * (tau / max(e, eps_floor))**exponent\n            # Limit excessive growth\n            h = min(h_candidate, max_growth * h)\n        else:\n            # Reject: reduce h and retry\n            exponent = 1.0 / (order + 1)\n            h = safety * h * (tau / e)**exponent\n            if h  min_h:\n                h = min_h\n\n    inv_err = abs(float(np.sum(x)) - total0)\n    pos_preserved = (min_comp = -1e-12)\n    return pos_preserved, inv_err\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (k1, k2, x0, T, tau)\n        (1.0, 0.5, np.array([1.0, 0.0, 0.0], dtype=float), 10.0, 1e-6),\n        (1.0, 0.5, np.array([1.0, 0.0, 0.0], dtype=float), 10.0, 1e-3),\n        (10.0, 1.0, np.array([1.0, 0.0, 0.0], dtype=float), 2.0, 1e-5),\n        (0.1, 0.1, np.array([1.0, 0.0, 0.0], dtype=float), 100.0, 1e-6),\n    ]\n\n    results = []\n    for k1, k2, x0, T, tau in test_cases:\n        # SSPRK(3,3): order = 3\n        pos_ssp, inv_ssp = integrate(ssprk3_step, 3, x0, T, tau, k1, k2)\n        # RK4: order = 4\n        pos_rk4, inv_rk4 = integrate(rk4_step, 4, x0, T, tau, k1, k2)\n        results.append([pos_ssp, pos_rk4, inv_ssp, inv_rk4])\n\n    # Final print statement in the exact required format.\n    # Produces a single line: list of per-case lists [bool,bool,float,float]\n    print(f\"[{','.join([str(r) for r in results])}]\")\n\nsolve()\n```"
        }
    ]
}