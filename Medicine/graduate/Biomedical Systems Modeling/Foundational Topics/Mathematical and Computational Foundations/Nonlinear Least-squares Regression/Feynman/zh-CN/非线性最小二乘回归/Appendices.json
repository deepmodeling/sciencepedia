{
    "hands_on_practices": [
        {
            "introduction": "非线性最小二乘问题通常通过迭代求解，每一步都涉及对模型的线性近似。本练习将深入探讨 Levenberg-Marquardt 算法的核心，这是一种计算迭代步长的稳健方法。通过使用奇异值分解 (SVD)，你不仅能找到数值上稳定的解，还能深入了解该算法如何处理参数难以被数据确定的病态问题 。",
            "id": "3911613",
            "problem": "考虑一个生物医学系统中的基于微透析的细胞因子浓度传感器的双参数非线性模型，其参数向量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^{2}$ 描述了输运速率和结合亲和力效应。该模型拟合了在时间 $t_{1}, t_{2}, t_{3}$ 处的 $m=3$ 个测量值，产生一个残差向量 $\\boldsymbol{r}(\\boldsymbol{\\theta}) \\in \\mathbb{R}^{3}$，其分量为 $r_{i}(\\boldsymbol{\\theta}) = y_{i}^{\\text{obs}} - y(t_{i}; \\boldsymbol{\\theta})$。在非线性最小二乘回归中，目标是最小化 $S(\\boldsymbol{\\theta}) = \\frac{1}{2}\\|\\boldsymbol{r}(\\boldsymbol{\\theta})\\|_{2}^{2}$。\n\n在当前迭代点 $\\boldsymbol{\\theta}_{0}$ 处，残差为 $\\boldsymbol{r} = \\begin{pmatrix}0.5  -0.3  0.1\\end{pmatrix}^{\\mathsf{T}}$，关于参数的偏导数雅可比矩阵 $\\boldsymbol{J}(\\boldsymbol{\\theta}_{0}) \\in \\mathbb{R}^{3 \\times 2}$ 可进行薄奇异值分解（singular value decomposition, SVD）\n$$\n\\boldsymbol{J} = \\boldsymbol{U}\\,\\boldsymbol{\\Sigma}\\,\\boldsymbol{V}^{\\mathsf{T}},\n$$\n其中 $\\boldsymbol{U} \\in \\mathbb{R}^{3 \\times 2}$ 的列是标准正交的，$\\boldsymbol{\\Sigma} \\in \\mathbb{R}^{2 \\times 2}$ 是对角线元素为正的对角矩阵，$\\boldsymbol{V} \\in \\mathbb{R}^{2 \\times 2}$ 是正交矩阵。具体的因子为\n$$\n\\boldsymbol{U} = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\\n\\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{6}} \\\\\n0  \\frac{2}{\\sqrt{6}}\n\\end{pmatrix},\\quad\n\\boldsymbol{\\Sigma} = \\begin{pmatrix}\n10  0 \\\\\n0  \\frac{1}{10}\n\\end{pmatrix},\\quad\n\\boldsymbol{V} = \\begin{pmatrix}\n1  0 \\\\\n0  1\n\\end{pmatrix}.\n$$\n\n从非线性最小二乘目标及其 Gauss–Newton 线性化的基本定义出发，通过在 SVD 基中求解，使用正阻尼参数 $\\lambda$，从基本原理推导阻尼最小二乘 (Levenberg–Marquardt) 步长 $\\boldsymbol{p} \\in \\mathbb{R}^{2}$。明确展示奇异值如何进入表达式，并解释阻尼如何处理小奇异值。然后，对于给定的因子和残差，计算当 $\\lambda = \\frac{9}{10}$ 时的阻尼步长。\n\n将你的最终答案表示为代表 $\\boldsymbol{p}$ 的单个行向量，使用精确的解析值，不要进行舍入。在此计算中，参数是无单位的，因此最终答案不应包含任何物理单位。",
            "solution": "该问题是有效的。这是一个在数值优化领域中适定且自洽的问题，具体涉及使用 Levenberg-Marquardt 算法的非线性最小二乘回归。问题背景有科学依据，并且提供了推导和计算所需的所有数据。\n\n非线性最小二乘的目标是找到参数向量 $\\boldsymbol{\\theta}$，以最小化由函数 $S(\\boldsymbol{\\theta})$ 给出的残差平方和：\n$$\nS(\\boldsymbol{\\theta}) = \\frac{1}{2} \\|\\boldsymbol{r}(\\boldsymbol{\\theta})\\|_{2}^{2} = \\frac{1}{2} \\boldsymbol{r}(\\boldsymbol{\\theta})^{\\mathsf{T}}\\boldsymbol{r}(\\boldsymbol{\\theta})\n$$\n使用迭代方法来寻找最小值。给定当前迭代点 $\\boldsymbol{\\theta}_{k}$，我们寻找一个步长 $\\boldsymbol{p}$ 来找到下一个迭代点 $\\boldsymbol{\\theta}_{k+1} = \\boldsymbol{\\theta}_{k} + \\boldsymbol{p}$。Gauss-Newton 方法在 $\\boldsymbol{\\theta}_{k}$ 附近对残差函数进行线性化：\n$$\n\\boldsymbol{r}(\\boldsymbol{\\theta}_{k} + \\boldsymbol{p}) \\approx \\boldsymbol{r}(\\boldsymbol{\\theta}_{k}) + \\boldsymbol{J}(\\boldsymbol{\\theta}_{k})\\boldsymbol{p}\n$$\n其中 $\\boldsymbol{J}(\\boldsymbol{\\theta}_{k})$ 是 $\\boldsymbol{r}$ 在 $\\boldsymbol{\\theta}_{k}$ 处的雅可比矩阵。令 $\\boldsymbol{r}_k = \\boldsymbol{r}(\\boldsymbol{\\theta}_k)$ 和 $\\boldsymbol{J}_k = \\boldsymbol{J}(\\boldsymbol{\\theta}_k)$。我们最小化线性化的目标函数：\n$$\n\\min_{\\boldsymbol{p}} \\frac{1}{2} \\|\\boldsymbol{r}_k + \\boldsymbol{J}_k \\boldsymbol{p}\\|_2^2\n$$\n这是一个线性最小二乘问题，其解 $\\boldsymbol{p}$ 满足正规方程：\n$$\n(\\boldsymbol{J}_k^{\\mathsf{T}}\\boldsymbol{J}_k)\\boldsymbol{p} = -\\boldsymbol{J}_k^{\\mathsf{T}}\\boldsymbol{r}_k\n$$\n阻尼最小二乘法，或称 Levenberg-Marquardt 方法，通过添加一个正的阻尼项 $\\lambda > 0$ 来解决矩阵 $\\boldsymbol{J}_k^{\\mathsf{T}}\\boldsymbol{J}_k$ 可能存在的病态问题。然后通过求解修正后的系统来找到步长 $\\boldsymbol{p}$。对于当前迭代点 $\\boldsymbol{\\theta}_0$，我们省略下标 $k$。\n$$\n(\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{J} + \\lambda \\boldsymbol{I})\\boldsymbol{p} = -\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n这是我们推导解的基础方程。给定雅可比矩阵的薄奇异值分解（SVD），$\\boldsymbol{J} = \\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}}$。我们将其代入方程中。\n\n首先，我们使用 SVD 因子来表示 $\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{J}$ 和 $\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{r}$ 这两项：\n$$\n\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{J} = (\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}})^{\\mathsf{T}}(\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}}) = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\mathsf{T}}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}}\n$$\n由于 $\\boldsymbol{U}$ 的列是标准正交的，所以 $\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{U} = \\boldsymbol{I}$。此外，$\\boldsymbol{\\Sigma}$ 是对角矩阵，因此 $\\boldsymbol{\\Sigma}^{\\mathsf{T}} = \\boldsymbol{\\Sigma}$。\n$$\n\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{J} = \\boldsymbol{V}\\boldsymbol{\\Sigma}\\boldsymbol{I}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}} = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{2}\\boldsymbol{V}^{\\mathsf{T}}\n$$\n方程的右边变为：\n$$\n\\boldsymbol{J}^{\\mathsf{T}}\\boldsymbol{r} = (\\boldsymbol{U}\\boldsymbol{\\Sigma}\\boldsymbol{V}^{\\mathsf{T}})^{\\mathsf{T}}\\boldsymbol{r} = \\boldsymbol{V}\\boldsymbol{\\Sigma}^{\\mathsf{T}}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r} = \\boldsymbol{V}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n将这些代入 Levenberg-Marquardt 方程得到：\n$$\n(\\boldsymbol{V}\\boldsymbol{\\Sigma}^{2}\\boldsymbol{V}^{\\mathsf{T}} + \\lambda \\boldsymbol{I})\\boldsymbol{p} = -\\boldsymbol{V}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n由于 $\\boldsymbol{V}$ 是一个正交矩阵，$\\boldsymbol{V}\\boldsymbol{V}^{\\mathsf{T}} = \\boldsymbol{I}$。我们可以将 $\\lambda \\boldsymbol{I}$ 写成 $\\lambda \\boldsymbol{V}\\boldsymbol{V}^{\\mathsf{T}}$ 并将其代入方程左侧：\n$$\n(\\boldsymbol{V}\\boldsymbol{\\Sigma}^{2}\\boldsymbol{V}^{\\mathsf{T}} + \\lambda \\boldsymbol{V}\\boldsymbol{V}^{\\mathsf{T}})\\boldsymbol{p} = \\boldsymbol{V}(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p} = -\\boldsymbol{V}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n用 $\\boldsymbol{V}^{\\mathsf{T}}$ (即 $\\boldsymbol{V}^{-1}$) 左乘，以分离出包含 $\\boldsymbol{p}$ 的项：\n$$\n\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{V}(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p} = -\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{V}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n$$\n(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p} = -\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n矩阵 $(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})$ 是一个对角矩阵，其对角线元素为 $(\\sigma_j^2 + \\lambda)$，其中 $\\sigma_j$ 是奇异值。它的逆矩阵也是一个对角矩阵，对角线元素为 $1/(\\sigma_j^2 + \\lambda)$。我们可以解出 $\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p}$：\n$$\n\\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p} = -(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})^{-1}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n最后，用 $\\boldsymbol{V}$ 左乘，得到步长 $\\boldsymbol{p}$ 的表达式：\n$$\n\\boldsymbol{p} = -\\boldsymbol{V}(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})^{-1}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}\n$$\n为了明确显示奇异值如何进入表达式，我们可以将 $\\boldsymbol{p}$ 写成一个和式。令 $\\boldsymbol{u}_j$ 和 $\\boldsymbol{v}_j$ 分别为 $\\boldsymbol{U}$ 和 $\\boldsymbol{V}$ 的列向量。步长向量 $\\boldsymbol{p}$ 为：\n$$\n\\boldsymbol{p} = \\sum_{j=1}^{n} \\left( \\frac{-\\sigma_j}{\\sigma_j^2 + \\lambda} \\right) (\\boldsymbol{u}_j^{\\mathsf{T}}\\boldsymbol{r}) \\boldsymbol{v}_j\n$$\n该表达式表明，步长 $\\boldsymbol{p}$ 是右奇异向量 $\\boldsymbol{v}_j$ 的线性组合。每个 $\\boldsymbol{v}_j$ 的系数由相应的奇异值 $\\sigma_j$、阻尼参数 $\\lambda$ 以及残差 $\\boldsymbol{r}$ 在相应左奇异向量 $\\boldsymbol{u}_j$ 上的投影共同决定。\n\n当存在小奇异值时，阻尼的作用是稳定步长的计算。第 $j$ 个分量的缩放因子是 $\\frac{\\sigma_j}{\\sigma_j^2 + \\lambda}$。\n如果 $\\sigma_j$ 很大（即 $\\sigma_j^2 \\gg \\lambda$），该因子约等于 $\\frac{\\sigma_j}{\\sigma_j^2} = \\frac{1}{\\sigma_j}$。这与无阻尼的 Gauss-Newton 步长的缩放比例相同。\n如果 $\\sigma_j$ 很小（即 $\\sigma_j^2 \\ll \\lambda$），该因子约等于 $\\frac{\\sigma_j}{\\lambda}$。如果没有阻尼，该因子将是 $\\frac{1}{\\sigma_j}$，这个值会非常大，导致在 $\\boldsymbol{v}_j$ 方向上产生一个巨大且不可靠的步长。分母中的阻尼参数 $\\lambda$ 确保了与小奇异值相关的方向的贡献被抑制，防止步长 $\\boldsymbol{p}$ 变得过大。这会带来一个更稳定和稳健的优化过程。\n\n现在，我们根据给定数据计算阻尼步长 $\\boldsymbol{p}$。\n残差为 $\\boldsymbol{r} = \\begin{pmatrix} 0.5 \\\\ -0.3 \\\\ 0.1 \\end{pmatrix}$。阻尼参数为 $\\lambda = \\frac{9}{10}$。\nSVD 因子为：\n$\\boldsymbol{U} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{6}} \\\\ \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{6}} \\\\ 0  \\frac{2}{\\sqrt{6}} \\end{pmatrix}$, $\\boldsymbol{\\Sigma} = \\begin{pmatrix} 10  0 \\\\ 0  \\frac{1}{10} \\end{pmatrix}$, $\\boldsymbol{V} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}$。\n$\\boldsymbol{U}$ 的列向量为 $\\boldsymbol{u}_1 = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}$ 和 $\\boldsymbol{u}_2 = \\begin{pmatrix} \\frac{1}{\\sqrt{6}} \\\\ -\\frac{1}{\\sqrt{6}} \\\\ \\frac{2}{\\sqrt{6}} \\end{pmatrix}$。\n奇异值为 $\\sigma_1 = 10$ 和 $\\sigma_2 = \\frac{1}{10}$。\n由于 $\\boldsymbol{V} = \\boldsymbol{I}$，我们有 $\\boldsymbol{p} = \\boldsymbol{V}^{\\mathsf{T}}\\boldsymbol{p}$，因此 $\\boldsymbol{p}$ 可以直接通过 $\\boldsymbol{p} = -(\\boldsymbol{\\Sigma}^{2} + \\lambda \\boldsymbol{I})^{-1}\\boldsymbol{\\Sigma}\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}$ 计算。\n\n首先，计算向量 $\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r}$：\n$$\n\\boldsymbol{u}_1^{\\mathsf{T}}\\boldsymbol{r} = \\frac{1}{\\sqrt{2}}(0.5) + \\frac{1}{\\sqrt{2}}(-0.3) + 0(0.1) = \\frac{0.2}{\\sqrt{2}} = \\frac{2}{10\\sqrt{2}} = \\frac{1}{5\\sqrt{2}}\n$$\n$$\n\\boldsymbol{u}_2^{\\mathsf{T}}\\boldsymbol{r} = \\frac{1}{\\sqrt{6}}(0.5) - \\frac{1}{\\sqrt{6}}(-0.3) + \\frac{2}{\\sqrt{6}}(0.1) = \\frac{1}{\\sqrt{6}}(0.5 + 0.3 + 0.2) = \\frac{1}{\\sqrt{6}}\n$$\n因此，$\\boldsymbol{U}^{\\mathsf{T}}\\boldsymbol{r} = \\begin{pmatrix} \\frac{1}{5\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{6}} \\end{pmatrix}$。\n\n接下来，我们计算 $\\boldsymbol{p}$ 的分量。\n对于第一个分量 $p_1$：\n$$\np_1 = -\\left( \\frac{\\sigma_1}{\\sigma_1^2 + \\lambda} \\right) (\\boldsymbol{u}_1^{\\mathsf{T}}\\boldsymbol{r}) = -\\left( \\frac{10}{10^2 + \\frac{9}{10}} \\right) \\left( \\frac{1}{5\\sqrt{2}} \\right) = -\\left( \\frac{10}{100 + \\frac{9}{10}} \\right) \\left( \\frac{1}{5\\sqrt{2}} \\right)\n$$\n$$\np_1 = -\\left( \\frac{10}{\\frac{1000+9}{10}} \\right) \\left( \\frac{1}{5\\sqrt{2}} \\right) = -\\left( \\frac{100}{1009} \\right) \\left( \\frac{1}{5\\sqrt{2}} \\right) = -\\frac{20}{1009\\sqrt{2}} = -\\frac{20\\sqrt{2}}{1009 \\cdot 2} = -\\frac{10\\sqrt{2}}{1009}\n$$\n对于第二个分量 $p_2$：\n$$\np_2 = -\\left( \\frac{\\sigma_2}{\\sigma_2^2 + \\lambda} \\right) (\\boldsymbol{u}_2^{\\mathsf{T}}\\boldsymbol{r}) = -\\left( \\frac{\\frac{1}{10}}{(\\frac{1}{10})^2 + \\frac{9}{10}} \\right) \\left( \\frac{1}{\\sqrt{6}} \\right) = -\\left( \\frac{\\frac{1}{10}}{\\frac{1}{100} + \\frac{90}{100}} \\right) \\left( \\frac{1}{\\sqrt{6}} \\right)\n$$\n$$\np_2 = -\\left( \\frac{\\frac{1}{10}}{\\frac{91}{100}} \\right) \\left( \\frac{1}{\\sqrt{6}} \\right) = -\\left( \\frac{1}{10} \\cdot \\frac{100}{91} \\right) \\left( \\frac{1}{\\sqrt{6}} \\right) = -\\frac{10}{91\\sqrt{6}} = -\\frac{10\\sqrt{6}}{91 \\cdot 6} = -\\frac{10\\sqrt{6}}{546} = -\\frac{5\\sqrt{6}}{273}\n$$\n步长向量 $\\boldsymbol{p}$ 为 $\\begin{pmatrix} -\\frac{10\\sqrt{2}}{1009} \\\\ -\\frac{5\\sqrt{6}}{273} \\end{pmatrix}$。\n题目要求以单个行向量的形式给出答案。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{10\\sqrt{2}}{1009}  & -\\frac{5\\sqrt{6}}{273}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "有效的建模需要融入先验知识，例如对参数的物理约束。许多生物医学参数，如反应速率或浓度，必须为正值。本练习介绍了一种优雅的技术——重参数化，通过将约束优化问题转化为无约束问题来强制施加此类约束，使其适用于标准的优化算法 。",
            "id": "3911605",
            "problem": "一位研究人员正在校准生物医学检测中一个酶催化反应的机理模型。在底物浓度为 $s_i$ 时测得的初始反应速率，由 Michaelis–Menten 关系式 $f(s_i;\\boldsymbol{\\theta}) = \\dfrac{\\theta_1 s_i}{\\theta_2 + s_i}$ 建模，其中 $\\boldsymbol{\\theta} = (\\theta_1,\\theta_2)^{\\top}$ 的分量严格为正，分别对应于最大速率和米氏常数。设观测到的速率为 $y_i$（其中 $i=1,\\dots,n$），并假设存在方差恒定的独立加性噪声。该研究人员使用非线性最小二乘回归，通过最小化目标函数 $J(\\boldsymbol{\\theta}) = \\dfrac{1}{2}\\sum_{i=1}^{n}\\left(y_i - f(s_i;\\boldsymbol{\\theta})\\right)^2$ 来估计 $\\boldsymbol{\\theta}$。\n\n为了以数值稳定的方式强制参数为正，研究人员通过逐元素的指数映射 $\\boldsymbol{\\theta} = \\exp(\\boldsymbol{\\phi})$ 对 $\\boldsymbol{\\theta}$ 进行重新参数化，其中 $\\boldsymbol{\\phi} = (\\phi_1,\\phi_2)^{\\top} \\in \\mathbb{R}^2$，指数函数逐分量作用，即 $\\theta_j = \\exp(\\phi_j)$（$j=1,2$）。\n\n从非线性最小二乘的定义和多元微积分的基本法则（乘法法则、链式法则）出发，推导变换后的目标函数 $J(\\boldsymbol{\\phi}) = J(\\exp(\\boldsymbol{\\phi}))$ 及其关于 $\\boldsymbol{\\phi}$ 的梯度。将你的最终结果明确地用数据 $\\{(s_i,y_i)\\}_{i=1}^{n}$ 和重新参数化的变量 $\\phi_1$ 和 $\\phi_2$ 表示，不要引入任何额外的参数。你的推导应严谨，并从第一性原理出发清楚地证明每一步。\n\n最终答案应提供三个表达式：标量目标函数 $J(\\boldsymbol{\\phi})$，以及梯度向量 $\\nabla_{\\boldsymbol{\\phi}} J(\\boldsymbol{\\phi})$ 的两个标量分量，即 $\\dfrac{\\partial J}{\\partial \\phi_1}$ 和 $\\dfrac{\\partial J}{\\partial \\phi_2}$。无需进行数值计算，也无需四舍五入。最终表达式中不要包含单位。",
            "solution": "该问题陈述具有科学依据、问题适定且客观。它描述了生物化学建模和参数估计中的一个标准场景。使用 Michaelis-Menten 动力学、非线性最小二乘法和指数重参数化来强制参数为正都是成熟且有效的方法。该任务是多元微积分的直接应用，并且已完全明确。因此，该问题被认为是有效的，并将提供解答。\n\n目标是推导变换后的目标函数 $J(\\boldsymbol{\\phi})$ 及其关于重新参数化的变量 $\\boldsymbol{\\phi} = (\\phi_1, \\phi_2)^{\\top}$ 的梯度 $\\nabla_{\\boldsymbol{\\phi}} J(\\boldsymbol{\\phi})$。\n\n原始模型和参数为：\n$$f(s_i;\\boldsymbol{\\theta}) = \\frac{\\theta_1 s_i}{\\theta_2 + s_i}$$\n其中 $\\boldsymbol{\\theta} = (\\theta_1, \\theta_2)^{\\top}$。\n\n重新参数化由逐元素的指数映射给出：\n$$\\theta_1 = \\exp(\\phi_1)$$\n$$\\theta_2 = \\exp(\\phi_2)$$\n对于任意实数值的 $\\phi_1$ 和 $\\phi_2$，此变换都能正确地强制施加正值约束 $\\theta_1 > 0$ 和 $\\theta_2 > 0$。\n\n首先，我们用新参数 $\\boldsymbol{\\phi}$ 来表示模型函数 $f$：\n$$f(s_i; \\boldsymbol{\\phi}) = \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}$$\n\n非线性最小二乘的目标函数 $J(\\boldsymbol{\\theta})$ 由下式给出：\n$$J(\\boldsymbol{\\theta}) = \\frac{1}{2}\\sum_{i=1}^{n}\\left(y_i - f(s_i;\\boldsymbol{\\theta})\\right)^2$$\n代入重新参数化的模型，我们得到变换后的目标函数 $J(\\boldsymbol{\\phi})$：\n$$J(\\boldsymbol{\\phi}) = \\frac{1}{2}\\sum_{i=1}^{n}\\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right)^2$$\n这是第一个要求的表达式。\n\n接下来，我们推导 $J(\\boldsymbol{\\phi})$ 的梯度，它由偏导数 $\\frac{\\partial J}{\\partial \\phi_1}$ 和 $\\frac{\\partial J}{\\partial \\phi_2}$ 组成。我们应用链式法则。对于一个通用分量 $\\phi_j$（其中 $j=1$ 或 $j=2$）：\n$$\\frac{\\partial J}{\\partial \\phi_j} = \\frac{\\partial}{\\partial \\phi_j} \\left[ \\frac{1}{2}\\sum_{i=1}^{n}\\left(y_i - f(s_i;\\boldsymbol{\\phi})\\right)^2 \\right]$$\n应用链式法则和求和法则：\n$$\\frac{\\partial J}{\\partial \\phi_j} = \\frac{1}{2}\\sum_{i=1}^{n} 2 \\left(y_i - f(s_i;\\boldsymbol{\\phi})\\right) \\left(-\\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_j}\\right)$$\n$$\\frac{\\partial J}{\\partial \\phi_j} = -\\sum_{i=1}^{n} \\left(y_i - f(s_i;\\boldsymbol{\\phi})\\right) \\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_j}$$\n\n为继续进行，我们必须计算模型函数 $f$ 关于 $\\phi_1$ 和 $\\phi_2$ 的偏导数。我们再次使用链式法则，将 $f$ 视为复合函数 $f(\\boldsymbol{\\theta}(\\boldsymbol{\\phi}))$。\n$$\\frac{\\partial f}{\\partial \\phi_j} = \\frac{\\partial f}{\\partial \\theta_1}\\frac{\\partial \\theta_1}{\\partial \\phi_j} + \\frac{\\partial f}{\\partial \\theta_2}\\frac{\\partial \\theta_2}{\\partial \\phi_j}$$\n重新参数化的导数为：\n$$\\frac{\\partial \\theta_1}{\\partial \\phi_1} = \\frac{\\partial}{\\partial \\phi_1}(\\exp(\\phi_1)) = \\exp(\\phi_1) = \\theta_1; \\quad \\frac{\\partial \\theta_1}{\\partial \\phi_2} = 0$$\n$$\\frac{\\partial \\theta_2}{\\partial \\phi_2} = \\frac{\\partial}{\\partial \\phi_2}(\\exp(\\phi_2)) = \\exp(\\phi_2) = \\theta_2; \\quad \\frac{\\partial \\theta_2}{\\partial \\phi_1} = 0$$\n\n$f$ 关于原始参数 $\\boldsymbol{\\theta}$ 的偏导数为：\n$$\\frac{\\partial f}{\\partial \\theta_1} = \\frac{\\partial}{\\partial \\theta_1}\\left(\\frac{\\theta_1 s_i}{\\theta_2 + s_i}\\right) = \\frac{s_i}{\\theta_2 + s_i}$$\n$$\\frac{\\partial f}{\\partial \\theta_2} = \\frac{\\partial}{\\partial \\theta_2}\\left(\\frac{\\theta_1 s_i}{\\theta_2 + s_i}\\right) = \\theta_1 s_i \\frac{\\partial}{\\partial \\theta_2}(\\theta_2 + s_i)^{-1} = -\\frac{\\theta_1 s_i}{(\\theta_2 + s_i)^2}$$\n\n现在我们可以计算 $\\frac{\\partial f}{\\partial \\phi_1}$ 和 $\\frac{\\partial f}{\\partial \\phi_2}$。\n对于 $\\phi_1$：\n$$\\frac{\\partial f}{\\partial \\phi_1} = \\frac{\\partial f}{\\partial \\theta_1}\\frac{\\partial \\theta_1}{\\partial \\phi_1} + \\frac{\\partial f}{\\partial \\theta_2}\\frac{\\partial \\theta_2}{\\partial \\phi_1} = \\left(\\frac{s_i}{\\theta_2 + s_i}\\right) \\theta_1 + 0 = \\frac{\\theta_1 s_i}{\\theta_2 + s_i} = f(s_i;\\boldsymbol{\\theta})$$\n将 $\\theta_j = \\exp(\\phi_j)$ 代回：\n$$\\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_1} = \\frac{\\exp(\\phi_1)s_i}{\\exp(\\phi_2) + s_i}$$\n\n对于 $\\phi_2$：\n$$\\frac{\\partial f}{\\partial \\phi_2} = \\frac{\\partial f}{\\partial \\theta_1}\\frac{\\partial \\theta_1}{\\partial \\phi_2} + \\frac{\\partial f}{\\partial \\theta_2}\\frac{\\partial \\theta_2}{\\partial \\phi_2} = 0 + \\left(-\\frac{\\theta_1 s_i}{(\\theta_2 + s_i)^2}\\right) \\theta_2 = -\\frac{\\theta_1 \\theta_2 s_i}{(\\theta_2 + s_i)^2}$$\n将 $\\theta_j = \\exp(\\phi_j)$ 代回：\n$$\\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_2} = -\\frac{\\exp(\\phi_1) \\exp(\\phi_2) s_i}{(\\exp(\\phi_2) + s_i)^2}$$\n\n最后，我们将这些导数代入 $J(\\boldsymbol{\\phi})$ 的梯度分量的表达式中。\n梯度的第一个分量是：\n$$\\frac{\\partial J}{\\partial \\phi_1} = -\\sum_{i=1}^{n} \\left(y_i - f(s_i;\\boldsymbol{\\phi})\\right) \\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_1}$$\n$$\\frac{\\partial J}{\\partial \\phi_1} = -\\sum_{i=1}^{n} \\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right) \\left(\\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right)$$\n这可以写成：\n$$\\frac{\\partial J}{\\partial \\phi_1} = \\sum_{i=1}^{n} \\left(\\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i} - y_i\\right) \\left(\\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right)$$\n\n梯度的第二个分量是：\n$$\\frac{\\partial J}{\\partial \\phi_2} = -\\sum_{i=1}^{n} \\left(y_i - f(s_i;\\boldsymbol{\\phi})\\right) \\frac{\\partial f(s_i;\\boldsymbol{\\phi})}{\\partial \\phi_2}$$\n$$\\frac{\\partial J}{\\partial \\phi_2} = -\\sum_{i=1}^{n} \\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right) \\left(-\\frac{\\exp(\\phi_1) \\exp(\\phi_2) s_i}{(\\exp(\\phi_2) + s_i)^2}\\right)$$\n$$\\frac{\\partial J}{\\partial \\phi_2} = \\sum_{i=1}^{n} \\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right) \\left(\\frac{\\exp(\\phi_1) \\exp(\\phi_2) s_i}{(\\exp(\\phi_2) + s_i)^2}\\right)$$\n\n这些就是所要求的目标函数及其梯度两个分量的表达式，用数据和参数 $\\phi_1$ 和 $\\phi_2$ 明确表示。",
            "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{1}{2}\\sum_{i=1}^{n}\\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right)^2 & \\sum_{i=1}^{n} \\left(\\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i} - y_i\\right) \\left(\\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right) & \\sum_{i=1}^{n} \\left(y_i - \\frac{\\exp(\\phi_1) s_i}{\\exp(\\phi_2) + s_i}\\right) \\left(\\frac{\\exp(\\phi_1) \\exp(\\phi_2) s_i}{(\\exp(\\phi_2) + s_i)^2}\\right) \\end{pmatrix} } $$"
        },
        {
            "introduction": "找到最佳拟合参数只是第一步，一个可靠的科学结论还需要量化其不确定性。这最后一个练习将演示如何构建置信区间，用以表达参数估计的可靠性。你将学习计算这些区间的标准流程，特别是针对在优化过程中经过变换的参数，从而确保对模型进行统计上合理的解释 。",
            "id": "3911614",
            "problem": "血浆浓度的药代动力学单室静脉推注模型由 $C(t;\\theta)=\\frac{D}{V}\\exp(-k t)$ 给出，其中 $D$ 为已知剂量，$V$ 为分布容积，$k$ 为消除速率常数。为在估计过程中确保正性，消除速率被参数化为 $\\xi=\\ln(k)$。浓度测量值被建模为 $y_i=C(t_i;\\theta)+\\varepsilon_i$，其中测量误差 $\\varepsilon_i$ 是独立同分布的，服从 $\\varepsilon_i\\sim\\mathcal{N}(0,\\sigma^2)$。\n\n参数通过非线性最小二乘法（NLS）进行估计，得到 $\\xi$ 的估计值 $\\hat{\\xi}$。在非线性回归中 NLS 估计量的标准大样本正则性假设下，$\\hat{\\xi}$ 是渐近正态的，其协方差可通过模型的 Gauss–Newton 线性化，利用残差方差和模型关于参数的灵敏度（雅可比矩阵）来近似。\n\n假设一次数据集拟合产生了 $\\hat{\\xi}=-2.40$ 以及 $\\hat{\\xi}$ 的估计渐近方差为 $\\widehat{\\Sigma}_{\\xi\\xi}=0.0081$。利用 $\\hat{\\xi}$ 的渐近正态性以及将 $\\xi$ 映射到 $k=\\exp(\\xi)$ 的指数变换的单调性，首先为 $\\xi$ 构建区间，然后将其端点映射到 $k$ 的尺度上，从而为 $k$ 构建一个置信水平为 $0.95$ 的双侧置信区间。计算这个为 $k$ 构建的 $0.95$ 置信区间的上端点。\n\n你的最终答案以 $\\mathrm{min}^{-1}$ 为单位表示。将最终数值四舍五入到四位有效数字。",
            "solution": "该问题要求基于消除速率常数 $k$ 的对数 $\\xi = \\ln(k)$ 的估计值，为 $k$ 构建一个 $0.95$ 置信区间。该过程首先需要为 $\\xi$ 建立一个置信区间，然后将其端点变换到 $k$ 的尺度上。\n\n我们已知 $\\xi$ 的估计值为 $\\hat{\\xi} = -2.40$，其估计的渐近方差为 $\\widehat{\\Sigma}_{\\xi\\xi} = 0.0081$。\n\n在估计量 $\\hat{\\xi}$ 服从渐近正态分布的假设下，其分布可以近似为：\n$$\n\\hat{\\xi} \\sim \\mathcal{N}(\\xi, \\widehat{\\Sigma}_{\\xi\\xi})\n$$\n其中 $\\xi$ 是参数的真实（未知）值。估计值 $\\hat{\\xi}$ 的标准误是其方差的平方根：\n$$\nSE(\\hat{\\xi}) = \\sqrt{\\widehat{\\Sigma}_{\\xi\\xi}} = \\sqrt{0.0081} = 0.09\n$$\n\n置信水平为 $1-\\alpha$ 的 $\\xi$ 的双侧置信区间构建如下：\n$$\n[\\hat{\\xi} - z_{1-\\alpha/2} \\cdot SE(\\hat{\\xi}), \\quad \\hat{\\xi} + z_{1-\\alpha/2} \\cdot SE(\\hat{\\xi})]\n$$\n对于 $0.95$ 的置信水平，我们有 $1-\\alpha = 0.95$，即 $\\alpha = 0.05$。来自标准正态分布的临界值是 $z_{1-\\alpha/2} = z_{1-0.025} = z_{0.975}$。该值约为 $1.96$。\n\n因此，$\\xi$ 的 $0.95$ 置信区间为：\n$$\n[\\xi_L, \\xi_U] = [-2.40 - 1.96 \\times 0.09, \\quad -2.40 + 1.96 \\times 0.09]\n$$\n$$\n[\\xi_L, \\xi_U] = [-2.40 - 0.1764, \\quad -2.40 + 0.1764]\n$$\n$$\n[\\xi_L, \\xi_U] = [-2.5764, \\quad -2.2236]\n$$\n\n$k$ 与 $\\xi$ 之间的关系由 $k = \\exp(\\xi)$ 给出。由于指数函数 $\\exp(\\cdot)$ 是一个严格单调递增函数，因此可以通过对 $\\xi$ 的置信区间端点应用该变换来获得 $k$ 的置信区间。\n$k$ 的置信区间为 $[k_L, k_U]$，其中：\n$$\nk_L = \\exp(\\xi_L)\n$$\n$$\nk_U = \\exp(\\xi_U)\n$$\n问题要求计算该置信区间的上端点 $k_U$。\n\n我们使用 $\\xi_U$ 的值来计算 $k_U$：\n$$\nk_U = \\exp(\\xi_U) = \\exp(-2.2236)\n$$\n进行数值计算：\n$$\nk_U \\approx 0.10822605...\n$$\n问题要求将最终答案四舍五入到四位有效数字。\n$$\nk_U \\approx 0.1082\n$$\n$k$ 的单位指定为 $\\mathrm{min}^{-1}$，这与消除速率常数的单位一致。",
            "answer": "$$\n\\boxed{0.1082}\n$$"
        }
    ]
}