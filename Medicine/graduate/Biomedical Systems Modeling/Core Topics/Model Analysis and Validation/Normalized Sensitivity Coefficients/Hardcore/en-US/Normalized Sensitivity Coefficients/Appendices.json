{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we will start with a foundational application: quantifying the responsiveness of a dose-response relationship. The following exercise uses the ubiquitous Hill equation, a cornerstone of pharmacology, to derive the normalized sensitivity of a system's effect with respect to agonist concentration. This practice will solidify your ability to apply the core definition of normalized sensitivity and interpret its behavior in different operational regimes, such as low-concentration versus saturation .",
            "id": "3912165",
            "problem": "In a receptor-mediated pharmacodynamic model in biomedical systems modeling, the effect as a function of agonist concentration is often represented by a Hill-type input-output map. Consider the effect function $y(p)$ defined by\n$$\ny(p) \\;=\\; \\frac{E_{\\max}\\,p^{n}}{EC_{50}^{n} + p^{n}},\n$$\nwhere $p$ is the agonist concentration, $E_{\\max}$ is the maximal achievable effect, $EC_{50}$ is the half-maximal effective concentration (EC50), and $n$ is the Hill coefficient that reflects cooperativity of binding.\n\nStarting from the fundamental definition of the normalized (logarithmic) sensitivity coefficient $S_{y}^{p}$ with respect to $p$,\n$$\nS_{y}^{p} \\;=\\; \\frac{\\partial \\ln y}{\\partial \\ln p},\n$$\nderive a closed-form expression for $S_{y}^{p}$ in terms of $p$, $EC_{50}$, and $n$ for the given $y(p)$. Then determine the limits of $S_{y}^{p}$ as $p \\to 0$ and as $p \\to \\infty$, and interpret these limits in terms of how the effect responds to infinitesimal relative changes in concentration in the low-concentration and high-concentration regimes.\n\nProvide your final answer as a row matrix containing, in order: the expression for $S_{y}^{p}(p)$, the limit $\\lim_{p \\to 0} S_{y}^{p}(p)$, and the limit $\\lim_{p \\to \\infty} S_{y}^{p}(p)$. No numerical rounding is required, and no units are needed in the final answer.",
            "solution": "The user has provided a problem that requires the derivation of a normalized sensitivity coefficient for a Hill-type pharmacodynamic model and the analysis of its limiting behavior.\n\n### Step 1: Problem Validation\n\nFirst, I must validate the problem statement.\n\n**Givens Extracted Verbatim:**\n- Effect function: $y(p) \\;=\\; \\frac{E_{\\max}\\,p^{n}}{EC_{50}^{n} + p^{n}}$\n- $p$: agonist concentration\n- $E_{\\max}$: maximal achievable effect\n- $EC_{50}$: half-maximal effective concentration (EC50)\n- $n$: Hill coefficient\n- Definition of normalized (logarithmic) sensitivity coefficient: $S_{y}^{p} \\;=\\; \\frac{\\partial \\ln y}{\\partial \\ln p}$\n\n**Validation against Criteria:**\n1.  **Scientific or Factual Soundness**: The problem is scientifically sound. The Hill equation is a cornerstone of quantitative pharmacology and biochemistry, used to model dose-response relationships and cooperative binding. The definition of the normalized (or logarithmic) sensitivity coefficient is a standard and fundamental concept in sensitivity analysis, widely used in systems biology and engineering.\n2.  **Formalizability and Relevance**: The problem is mathematical in nature, requiring calculus to derive an expression and evaluate limits. It is directly relevant to the topic of *normalized sensitivity coefficients* within the field of *biomedical systems modeling*.\n3.  **Completeness and Consistency**: The problem is self-contained. It provides the function $y(p)$ and the definition of the sensitivity coefficient $S_{y}^{p}$, which are all that is needed for the derivation. There are no contradictions.\n4.  **Realism and Feasibility**: The model and parameters are standard in the field and do not represent any physically impossible or implausible conditions.\n5.  **Well-Posed and Structured**: The problem is well-posed. The function is differentiable for $p > 0$, and a unique, stable, and meaningful expression for the sensitivity can be derived. The limits are well-defined.\n6.  **Non-triviality**: The problem requires a correct application of calculus and an understanding of the concepts of sensitivity and limiting behavior in a biophysical context. It is not trivial or tautological.\n7.  **Verifiability**: The derivation and limit calculations are mathematically verifiable.\n\n**Verdict:**\nThe problem is valid. It is a standard exercise in a quantitative biology or bioengineering curriculum. I will proceed with the solution.\n\n### Step 2: Derivation and Analysis\n\nThe objective is to derive an expression for the normalized sensitivity coefficient $S_{y}^{p}$ of the effect $y$ with respect to the agonist concentration $p$, and to analyze its behavior at very low and very high concentrations.\n\nThe normalized sensitivity coefficient is defined as:\n$$\nS_{y}^{p} \\;=\\; \\frac{\\partial \\ln y}{\\partial \\ln p}\n$$\nThis expression can be rewritten using the chain rule of differentiation. Let $u = \\ln p$, so $p = \\exp(u)$ and $\\frac{dp}{du} = \\exp(u) = p$. Then,\n$$\nS_{y}^{p} = \\frac{\\partial (\\ln y)}{\\partial u} = \\frac{\\partial (\\ln y)}{\\partial p} \\frac{dp}{du} = p \\frac{\\partial (\\ln y)}{\\partial p}\n$$\nWe start by taking the natural logarithm of the effect function $y(p)$:\n$$\ny(p) = \\frac{E_{\\max}\\,p^{n}}{EC_{50}^{n} + p^{n}}\n$$\n$$\n\\ln y(p) = \\ln \\left( \\frac{E_{\\max}\\,p^{n}}{EC_{50}^{n} + p^{n}} \\right)\n$$\nUsing the properties of logarithms, we can expand this expression:\n$$\n\\ln y(p) = \\ln(E_{\\max}) + \\ln(p^{n}) - \\ln(EC_{50}^{n} + p^{n})\n$$\n$$\n\\ln y(p) = \\ln(E_{\\max}) + n \\ln(p) - \\ln(EC_{50}^{n} + p^{n})\n$$\nNow, we differentiate $\\ln y(p)$ with respect to $p$:\n$$\n\\frac{\\partial}{\\partial p} \\big( \\ln y(p) \\big) = \\frac{\\partial}{\\partial p} \\left( \\ln(E_{\\max}) + n \\ln(p) - \\ln(EC_{50}^{n} + p^{n}) \\right)\n$$\nThe derivative of the constant term $\\ln(E_{\\max})$ is $0$. The derivative of $n\\ln(p)$ is $\\frac{n}{p}$. For the last term, we use the chain rule:\n$$\n\\frac{\\partial}{\\partial p} \\big( \\ln y(p) \\big) = 0 + \\frac{n}{p} - \\frac{1}{EC_{50}^{n} + p^{n}} \\cdot \\frac{\\partial}{\\partial p} (EC_{50}^{n} + p^{n})\n$$\n$$\n\\frac{\\partial}{\\partial p} \\big( \\ln y(p) \\big) = \\frac{n}{p} - \\frac{n p^{n-1}}{EC_{50}^{n} + p^{n}}\n$$\nNow we can compute $S_{y}^{p}$ by multiplying this result by $p$:\n$$\nS_{y}^{p} = p \\left( \\frac{n}{p} - \\frac{n p^{n-1}}{EC_{50}^{n} + p^{n}} \\right)\n$$\nDistributing the $p$ inside the parentheses gives:\n$$\nS_{y}^{p} = n - \\frac{n p \\cdot p^{n-1}}{EC_{50}^{n} + p^{n}} = n - \\frac{n p^{n}}{EC_{50}^{n} + p^{n}}\n$$\nTo simplify this expression, we combine the terms over a common denominator:\n$$\nS_{y}^{p} = \\frac{n(EC_{50}^{n} + p^{n}) - n p^{n}}{EC_{50}^{n} + p^{n}} = \\frac{n EC_{50}^{n} + n p^{n} - n p^{n}}{EC_{50}^{n} + p^{n}}\n$$\nThis simplifies to the final closed-form expression for the normalized sensitivity:\n$$\nS_{y}^{p}(p) = \\frac{n EC_{50}^{n}}{EC_{50}^{n} + p^{n}}\n$$\n\nNext, we determine the limits of $S_{y}^{p}$ as $p \\to 0$ and as $p \\to \\infty$.\n\n**Limit as $p \\to 0$ (Low-Concentration Regime):**\n$$\n\\lim_{p \\to 0} S_{y}^{p}(p) = \\lim_{p \\to 0} \\frac{n EC_{50}^{n}}{EC_{50}^{n} + p^{n}}\n$$\nAs $p \\to 0$, the term $p^{n}$ also goes to $0$ (assuming $n > 0$, which is physically required for the Hill model).\n$$\n\\lim_{p \\to 0} S_{y}^{p}(p) = \\frac{n EC_{50}^{n}}{EC_{50}^{n} + 0} = \\frac{n EC_{50}^{n}}{EC_{50}^{n}} = n\n$$\n**Interpretation:** The normalized sensitivity $S_{y}^{p}$ quantifies the fractional change in effect $y$ for a given fractional change in concentration $p$, i.e., $\\frac{dy}{y} \\approx S_{y}^{p} \\frac{dp}{p}$. A value of $n$ means that at very low concentrations, a $1\\%$ increase in agonist concentration leads to an $n\\%$ increase in the effect. This corresponds to the initial steep portion of the dose-response curve, where the effect is highly responsive to changes in concentration. For $p \\ll EC_{50}$, $y(p) \\approx (E_{\\max}/EC_{50}^n) p^n$, a power-law relationship, for which a logarithmic sensitivity of $n$ is characteristic.\n\n**Limit as $p \\to \\infty$ (High-Concentration Regime):**\n$$\n\\lim_{p \\to \\infty} S_{y}^{p}(p) = \\lim_{p \\to \\infty} \\frac{n EC_{50}^{n}}{EC_{50}^{n} + p^{n}}\n$$\nAs $p \\to \\infty$, the $p^{n}$ term in the denominator dominates. To evaluate the limit formally, we can divide the numerator and the denominator by $p^{n}$:\n$$\n\\lim_{p \\to \\infty} S_{y}^{p}(p) = \\lim_{p \\to \\infty} \\frac{\\frac{n EC_{50}^{n}}{p^{n}}}{\\frac{EC_{50}^{n}}{p^{n}} + 1}\n$$\nAs $p \\to \\infty$, the term $\\frac{EC_{50}^{n}}{p^{n}}$ goes to $0$.\n$$\n\\lim_{p \\to \\infty} S_{y}^{p}(p) = \\frac{0}{0 + 1} = 0\n$$\n**Interpretation:** A sensitivity of $0$ means that at very high concentrations, changes in agonist concentration have a negligible effect on the response. This is the saturation regime, where the effect $y$ approaches its maximum value $E_{\\max}$. The system is insensitive to further increases in $p$ because the receptors are fully occupied. This corresponds to the flat plateau of the dose-response curve.\n\nThe three required results are the expression for $S_{y}^{p}(p)$, its limit as $p \\to 0$, and its limit as $p \\to \\infty$.\n1.  $S_{y}^{p}(p) = \\frac{n EC_{50}^{n}}{EC_{50}^{n} + p^{n}}$\n2.  $\\lim_{p \\to 0} S_{y}^{p}(p) = n$\n3.  $\\lim_{p \\to \\infty} S_{y}^{p}(p) = 0$\nThese will be presented in a row matrix as requested.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{n EC_{50}^{n}}{EC_{50}^{n} + p^{n}} & n & 0\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Moving from the sensitivity of an output to an input variable, we now turn to parameter sensitivity, a critical aspect of model analysis and validation. This next problem investigates a simple but representative metabolic system governed by Michaelis-Menten kinetics, a fundamental model in enzyme biochemistry. By first determining the system's steady-state concentration and then deriving its sensitivity to the key parameters $V_{\\max}$ and $K_{M}$, you will practice assessing how a system's equilibrium state is controlled by its underlying biological constants .",
            "id": "3912179",
            "problem": "Consider a well-mixed single-compartment biochemical system modeling a substrate undergoing enzymatic conversion in a biomedical context (for example, a metabolic precursor in a hepatocyte). Let the substrate concentration be denoted by $S(t)$, and assume the compartment receives a constant inflow of substrate at rate $I$ (with units of concentration per unit time). Substrate is enzymatically converted following the classical Michaelis–Menten rate law characterized by the maximum rate $V_{\\max}$ and the Michaelis constant $K_{M}$. The dynamics of $S(t)$ are governed by an Ordinary Differential Equation (ODE) expressing mass balance between the constant inflow and the enzymatic consumption. Assume that the parameters satisfy $V_{\\max} > I$ so that a positive, finite steady-state exists.\n\nStarting from the mass balance and the standard form of the enzymatic rate law, derive the steady-state substrate concentration $S^{\\ast}$, and then obtain the normalized sensitivity coefficients of $S^{\\ast}$ with respect to $V_{\\max}$ and $K_{M}$, based only on first principles and core definitions. Your derivation must be mathematically justified at each step, and it must not rely on pre-stated sensitivity formulas. Provide the final sensitivity coefficients as closed-form analytic expressions. No numerical evaluation or rounding is required. The final answer must contain the two analytic expressions corresponding to the normalized sensitivities of $S^{\\ast}$ with respect to $V_{\\max}$ and $K_{M}$ arranged as a single row matrix.",
            "solution": "The problem requires the derivation of the steady-state substrate concentration, $S^{\\ast}$, in a single-compartment biochemical system, and the subsequent derivation of the normalized sensitivity coefficients of $S^{\\ast}$ with respect to the parameters $V_{\\max}$ and $K_{M}$.\n\nThe system is described by the dynamics of the substrate concentration, $S(t)$. The rate of change of $S(t)$ is governed by the principle of mass balance, which states that the rate of accumulation is equal to the rate of inflow minus the rate of outflow (or consumption).\n\nThe rate of inflow is given as a constant, $I$.\nThe rate of consumption follows the Michaelis–Menten rate law, which is given by the expression $v(S) = \\frac{V_{\\max} S}{K_{M} + S}$.\n\nThus, the Ordinary Differential Equation (ODE) for the substrate concentration $S(t)$ is:\n$$\n\\frac{dS}{dt} = I - \\frac{V_{\\max} S(t)}{K_{M} + S(t)}\n$$\n\nTo find the steady-state concentration, denoted as $S^{\\ast}$, we set the rate of change of the concentration to zero, i.e., $\\frac{dS}{dt} = 0$. At steady state, the system is in equilibrium, and the inflow rate is exactly balanced by the consumption rate.\n$$\n0 = I - \\frac{V_{\\max} S^{\\ast}}{K_{M} + S^{\\ast}}\n$$\nRearranging this equation to solve for $S^{\\ast}$:\n$$\nI = \\frac{V_{\\max} S^{\\ast}}{K_{M} + S^{\\ast}}\n$$\nMultiplying both sides by $(K_{M} + S^{\\ast})$ yields:\n$$\nI (K_{M} + S^{\\ast}) = V_{\\max} S^{\\ast}\n$$\nExpanding the left-hand side:\n$$\nI K_{M} + I S^{\\ast} = V_{\\max} S^{\\ast}\n$$\nTo isolate $S^{\\ast}$, we group the terms containing $S^{\\ast}$ on one side of the equation:\n$$\nI K_{M} = V_{\\max} S^{\\ast} - I S^{\\ast}\n$$\nFactoring out $S^{\\ast}$:\n$$\nI K_{M} = S^{\\ast} (V_{\\max} - I)\n$$\nThe problem statement provides the condition that $V_{\\max} > I$, which ensures that the term $(V_{\\max} - I)$ is a positive, non-zero constant. We can therefore divide by this term to obtain the expression for the steady-state concentration $S^{\\ast}$:\n$$\nS^{\\ast} = \\frac{I K_{M}}{V_{\\max} - I}\n$$\nThis is the closed-form analytic expression for the steady-state substrate concentration.\n\nNext, we derive the normalized sensitivity coefficients. The normalized sensitivity coefficient of a variable $y$ with respect to a parameter $p$, denoted as $S_{y}^{p}$, is defined as the ratio of the fractional change in $y$ to the fractional change in $p$. Mathematically, this is expressed as:\n$$\nS_{y}^{p} = \\frac{\\partial y / y}{\\partial p / p} = \\frac{p}{y} \\frac{\\partial y}{\\partial p}\n$$\nAn equivalent definition is $S_{y}^{p} = \\frac{\\partial (\\ln y)}{\\partial (\\ln p)}$. We will use the first definition.\n\nFirst, we calculate the normalized sensitivity of $S^{\\ast}$ with respect to $V_{\\max}$, which is $S_{S^{\\ast}}^{V_{\\max}}$.\n$$\nS_{S^{\\ast}}^{V_{\\max}} = \\frac{V_{\\max}}{S^{\\ast}} \\frac{\\partial S^{\\ast}}{\\partial V_{\\max}}\n$$\nWe need to compute the partial derivative of $S^{\\ast}$ with respect to $V_{\\max}$. Treating $S^{\\ast}$ as a function of $V_{\\max}$: $S^{\\ast}(V_{\\max}) = I K_{M} (V_{\\max} - I)^{-1}$.\nUsing the chain rule for derivatives:\n$$\n\\frac{\\partial S^{\\ast}}{\\partial V_{\\max}} = I K_{M} \\cdot (-1) (V_{\\max} - I)^{-2} \\cdot \\frac{\\partial}{\\partial V_{\\max}}(V_{\\max} - I)\n$$\n$$\n\\frac{\\partial S^{\\ast}}{\\partial V_{\\max}} = -I K_{M} (V_{\\max} - I)^{-2} \\cdot (1) = -\\frac{I K_{M}}{(V_{\\max} - I)^2}\n$$\nNow, substitute this derivative and the expression for $S^{\\ast}$ into the sensitivity formula:\n$$\nS_{S^{\\ast}}^{V_{\\max}} = \\frac{V_{\\max}}{\\frac{I K_{M}}{V_{\\max} - I}} \\left( -\\frac{I K_{M}}{(V_{\\max} - I)^2} \\right)\n$$\n$$\nS_{S^{\\ast}}^{V_{\\max}} = \\frac{V_{\\max} (V_{\\max} - I)}{I K_{M}} \\left( -\\frac{I K_{M}}{(V_{\\max} - I)^2} \\right)\n$$\nThe terms $I K_{M}$ and one factor of $(V_{\\max} - I)$ cancel out:\n$$\nS_{S^{\\ast}}^{V_{\\max}} = - \\frac{V_{\\max}}{V_{\\max} - I}\n$$\n\nSecond, we calculate the normalized sensitivity of $S^{\\ast}$ with respect to $K_{M}$, which is $S_{S^{\\ast}}^{K_{M}}$.\n$$\nS_{S^{\\ast}}^{K_{M}} = \\frac{K_{M}}{S^{\\ast}} \\frac{\\partial S^{\\ast}}{\\partial K_{M}}\n$$\nWe compute the partial derivative of $S^{\\ast}$ with respect to $K_{M}$. From the expression $S^{\\ast} = \\frac{I K_{M}}{V_{\\max} - I}$, we can see that $S^{\\ast}$ is directly proportional to $K_{M}$. The term $\\frac{I}{V_{\\max} - I}$ is a constant with respect to $K_{M}$.\n$$\n\\frac{\\partial S^{\\ast}}{\\partial K_{M}} = \\frac{\\partial}{\\partial K_{M}} \\left( \\frac{I}{V_{\\max} - I} K_{M} \\right) = \\frac{I}{V_{\\max} - I}\n$$\nSubstituting this derivative and the expression for $S^{\\ast}$ into the sensitivity formula:\n$$\nS_{S^{\\ast}}^{K_{M}} = \\frac{K_{M}}{\\frac{I K_{M}}{V_{\\max} - I}} \\left( \\frac{I}{V_{\\max} - I} \\right)\n$$\n$$\nS_{S^{\\ast}}^{K_{M}} = \\frac{K_{M} (V_{\\max} - I)}{I K_{M}} \\left( \\frac{I}{V_{\\max} - I} \\right)\n$$\nAll terms cancel out, leaving:\n$$\nS_{S^{\\ast}}^{K_{M}} = 1\n$$\nThe derived normalized sensitivity coefficients are $S_{S^{\\ast}}^{V_{\\max}} = -\\frac{V_{\\max}}{V_{\\max} - I}$ and $S_{S^{\\ast}}^{K_{M}} = 1$. The final answer should present these as a single row matrix.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\frac{V_{\\max}}{V_{\\max} - I} & 1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Finally, we transition from analytical derivations on simple systems to a powerful computational framework suitable for the complex, multi-state models common in modern biomedical research. This advanced practice introduces a general method for computing the entire matrix of steady-state sensitivities by leveraging Jacobian matrices and linear algebra, rooted in the implicit function theorem. The exercise not only demonstrates how to handle larger systems but also addresses the crucial, real-world issue of numerical conditioning, providing a robust strategy for obtaining reliable results from complex models .",
            "id": "3912151",
            "problem": "Consider a deterministic, coarse-grained biochemical regulation model written as a system of ordinary differential equations (ODEs) for three state variables, $x = (x_1, x_2, x_3)$, which represent messenger ribonucleic acid ($x_1$), protein concentration ($x_2$), and activated protein ($x_3$). The system depends on seven positive parameters $p = (p_0, p_1, p_2, p_3, p_4, p_5, p_6)$ and is given by\n$$\n\\frac{dx_1}{dt} = p_0 - p_1 x_1,\n\\quad\n\\frac{dx_2}{dt} = p_2 x_1 - p_3 x_2,\n\\quad\n\\frac{dx_3}{dt} = \\frac{p_4 x_2}{p_5 + x_2} - p_6 x_3.\n$$\nAssume a steady state $x^{*}(p)$ exists for each parameter vector $p$, defined by $f(x^{*},p) = 0$ where $f(x,p)$ denotes the right-hand side of the ODE. Define three outputs of interest $y = (y_1,y_2,y_3)$ at steady state by\n$$\ny_1 = x_2^{*},\n\\quad\ny_2 = x_3^{*},\n\\quad\ny_3 = \\frac{p_4 x_2^{*}}{p_5 + x_2^{*}},\n$$\nwhere $x^{*} = (x_1^{*}, x_2^{*}, x_3^{*})$ are the steady-state values. The normalized sensitivity coefficient of an output $y_i$ with respect to a parameter $p_k$ at steady state is defined by\n$$\nS_{i,k} = \\frac{p_k}{y_i} \\frac{\\partial y_i}{\\partial p_k},\n$$\nwhich is dimensionless. Your task is to compute the full matrix of steady-state normalized sensitivity coefficients $S \\in \\mathbb{R}^{3 \\times 7}$ for the outputs $y$ with respect to the parameters $p$, using a method that arises from first principles: begin from the definition of steady state $f(x^{*},p)=0$, treat $x^{*}$ as an implicit function of $p$, and use appropriate Jacobian matrices evaluated at $x^{*}$ to set up and solve a linear system for the steady-state state sensitivities. Then use the chain rule to map state sensitivities to output sensitivities and apply the normalization above.\n\nNumerical conditioning must be explicitly addressed. Specifically, when the Jacobian of $f$ with respect to $x$ evaluated at $x^{*}$, denoted $J_x(x^{*},p)$, is ill-conditioned (in the $2$-norm sense with a large condition number), you must avoid unstable solves. In such cases, use a numerically stabilizing approach based on Singular Value Decomposition (SVD) and a small Tikhonov regularization scaled to the matrix norm to solve the linear system that yields the state sensitivities. When $J_x(x^{*},p)$ is well-conditioned, a direct linear solver is acceptable.\n\nFor this model, to ensure scientific realism and reproducibility, you must compute the steady state analytically before evaluating Jacobians. The steady state values are determined by algebraic balance of production and degradation in each equation, yielding\n$$\nx_1^{*} = \\frac{p_0}{p_1}, \n\\quad\nx_2^{*} = \\frac{p_2}{p_3} x_1^{*},\n\\quad\nx_3^{*} = \\frac{p_4}{p_6} \\frac{x_2^{*}}{p_5 + x_2^{*}},\n$$\nfor every parameter vector $p$ with positive entries.\n\nYour program must implement the following steps for each parameter vector $p$ in the test suite:\n- Compute $x^{*}(p)$ using the algebraic expressions above.\n- Evaluate the Jacobian matrices $J_x(x^{*},p)$ and $J_p(x^{*},p)$, where $J_x$ is the matrix of partial derivatives of $f$ with respect to $x$, and $J_p$ is the matrix of partial derivatives of $f$ with respect to $p$.\n- For each parameter $p_k$, solve the linear system implied by the sensitivity analysis at steady state to obtain $\\frac{\\partial x^{*}}{\\partial p_k}$, using a numerically stable method as required by the conditioning of $J_x(x^{*},p)$.\n- Compute $\\frac{\\partial y}{\\partial p_k}$ via the chain rule at steady state using the Jacobian of $y$ with respect to $x$ and with respect to $p$.\n- Compute $S_{i,k}$ using the normalization above.\n\nThe final outputs $S_{i,k}$ are pure numbers without physical units. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one parameter vector from the test suite and is itself a list-of-lists representing the $3 \\times 7$ matrix of normalized sensitivities arranged by output rows. For example, an output of the correct shape should look like\n$$\n[[\\text{row}_1], [\\text{row}_2], [\\text{row}_3]]\n$$\nfor each parameter set, and the entire line should be\n$$\n[[\\dots],[\\dots],[\\dots]].\n$$\n\nTest suite (three parameter sets):\n- Case A (general well-conditioned): $p = (10.0, 2.0, 5.0, 1.0, 3.0, 1.0, 0.5)$.\n- Case B (ill-conditioning with slow degradation): $p = (10.0, 10^{-6}, 5.0, 10^{-6}, 3.0, 1.0, 0.5)$.\n- Case C (small activation constant and fast deactivation): $p = (10.0, 2.0, 5.0, 1.0, 3.0, 10^{-3}, 100.0)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the form\n$$\n[\\,[S^{(A)}],\\,[S^{(B)}],\\,[S^{(C)}]\\,],\n$$\nwhere each $[S^{(\\cdot)}]$ is represented as a list of three rows, each row containing seven floating-point numbers.",
            "solution": "The user-provided problem has been analyzed and is determined to be valid. It is scientifically grounded, well-posed, and objective. The problem describes a standard biochemical model and requests the calculation of normalized sensitivity coefficients, a well-defined task in systems biology and control theory. The instructions are complete, consistent, and require a formal mathematical procedure involving implicit differentiation and linear algebra, with specific instructions for handling numerical conditioning. All required data and definitions are provided.\n\nThe problem requires the computation of the normalized sensitivity matrix $S \\in \\mathbb{R}^{3 \\times 7}$ for a system of three outputs $y_i$ with respect to seven parameters $p_k$. The sensitivity is defined at steady state $x^*$ as:\n$$\nS_{i,k} = \\frac{p_k}{y_i} \\frac{\\partial y_i}{\\partial p_k}\n$$\nThe core of the method relies on the implicit function theorem applied to the steady-state condition $f(x^*(p), p) = 0$.\n\n**Step 1: Steady-State Analysis**\nThe system of ordinary differential equations (ODEs) is given by:\n$$\nf(x, p) = \\begin{pmatrix} f_1 \\\\ f_2 \\\\ f_3 \\end{pmatrix} = \\begin{pmatrix} p_0 - p_1 x_1 \\\\ p_2 x_1 - p_3 x_2 \\\\ \\frac{p_4 x_2}{p_5 + x_2} - p_6 x_3 \\end{pmatrix}\n$$\nAt steady state, $f(x^*, p) = 0$. The problem provides the analytical solution for the steady-state vector $x^* = (x_1^*, x_2^*, x_3^*)$:\n$$\nx_1^{*} = \\frac{p_0}{p_1}, \\quad x_2^{*} = \\frac{p_2}{p_3} x_1^{*} = \\frac{p_0 p_2}{p_1 p_3}, \\quad x_3^{*} = \\frac{1}{p_6} \\frac{p_4 x_2^{*}}{p_5 + x_2^{*}}\n$$\nThese expressions are used to compute the specific steady-state point for each given parameter vector $p$.\n\n**Step 2: Derivation of State Sensitivities**\nWe treat the steady-state solution $x^*$ as an implicit function of the parameters $p$. Taking the total derivative of the steady-state condition $f(x^*(p), p) = 0$ with respect to a parameter $p_k$ yields:\n$$\n\\frac{d}{dp_k} f(x^*(p), p) = \\frac{\\partial f}{\\partial x} \\frac{\\partial x^*}{\\partial p_k} + \\frac{\\partial f}{\\partial p_k} = 0\n$$\nwhere $\\frac{\\partial f}{\\partial x}$ is the Jacobian matrix of $f$ with respect to $x$, denoted $J_x$, and $\\frac{\\partial x^*}{\\partial p_k}$ is the vector of state sensitivities with respect to $p_k$. Rearranging this equation gives a linear system for the state sensitivities:\n$$\nJ_x(x^*, p) \\frac{\\partial x^*}{\\partial p_k} = - \\frac{\\partial f}{\\partial p_k}\n$$\nThis system must be solved for each parameter $p_k$, where $k=0, 1, \\dots, 6$.\n\nFirst, we compute the Jacobian matrix $J_x = \\frac{\\partial f}{\\partial x}$ and evaluate it at the steady state $x^*$:\n$$\nJ_x(x^*, p) = \\begin{pmatrix}\n-p_1 & 0 & 0 \\\\\np_2 & -p_3 & 0 \\\\\n0 & \\frac{p_4 p_5}{(p_5 + x_2^*)^2} & -p_6\n\\end{pmatrix}\n$$\nThis is a lower triangular matrix, which simplifies the solution of the linear system.\n\nNext, we compute the vectors $\\frac{\\partial f}{\\partial p_k}$ for each $k$:\n$$\n\\frac{\\partial f}{\\partial p_0} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\frac{\\partial f}{\\partial p_1} = \\begin{pmatrix} -x_1^* \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad\n\\frac{\\partial f}{\\partial p_2} = \\begin{pmatrix} 0 \\\\ x_1^* \\\\ 0 \\end{pmatrix}, \\quad\n\\frac{\\partial f}{\\partial p_3} = \\begin{pmatrix} 0 \\\\ -x_2^* \\\\ 0 \\end{pmatrix}\n$$\n$$\n\\frac{\\partial f}{\\partial p_4} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{x_2^*}{p_5 + x_2^*} \\end{pmatrix}, \\quad\n\\frac{\\partial f}{\\partial p_5} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -\\frac{p_4 x_2^*}{(p_5 + x_2^*)^2} \\end{pmatrix}, \\quad\n\\frac{\\partial f}{\\partial p_6} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -x_3^* \\end{pmatrix}\n$$\n\n**Step 3: Solving the Linear System for State Sensitivities**\nFor each $k \\in \\{0, \\dots, 6\\}$, we solve the system $J_x z_k = b_k$, where $z_k = \\frac{\\partial x^*}{\\partial p_k}$ and $b_k = -\\frac{\\partial f}{\\partial p_k}$. The problem requires a numerically stable approach based on the condition number of $J_x$.\nThe condition number (in the $2$-norm) is calculated as $\\text{cond}(J_x) = \\|J_x\\|_2 \\|J_x^{-1}\\|_2$. If $\\text{cond}(J_x)$ is large, indicating ill-conditioning, a regularized solution is required. We use Tikhonov regularization, which solves $(J_x^T J_x + \\alpha I) z_k = J_x^T b_k$. A numerically robust way to compute this is via Singular Value Decomposition (SVD). Let $J_x = U \\Sigma V^T$. The regularized solution is:\n$$\nz_k = V (\\Sigma^2 + \\alpha I)^{-1} \\Sigma^T U^T b_k = \\sum_{j=1}^{3} \\frac{\\sigma_j}{\\sigma_j^2 + \\alpha} (u_j^T b_k) v_j\n$$\nwhere $\\sigma_j$ are the singular values, and $u_j, v_j$ are the columns of $U$ and $V$. The regularization parameter $\\alpha$ is chosen as a small value scaled by the matrix norm, e.g., $\\alpha = \\epsilon \\sigma_1$ with a small $\\epsilon$, like $10^{-8}$. If $J_x$ is well-conditioned, a standard linear solver is sufficient.\n\n**Step 4: Calculation of Output Sensitivities**\nThe outputs $y$ are functions of the state $x^*$ and parameters $p$: $y = g(x^*, p)$.\n$$\ny_1 = x_2^*, \\quad y_2 = x_3^*, \\quad y_3 = \\frac{p_4 x_2^*}{p_5 + x_2^*}\n$$\nUsing the chain rule, the sensitivity of the output vector $y$ to a parameter $p_k$ is:\n$$\n\\frac{\\partial y}{\\partial p_k} = \\frac{\\partial g}{\\partial x} \\frac{\\partial x^*}{\\partial p_k} + \\frac{\\partial g}{\\partial p_k}\n$$\nWe compute the Jacobian of $g$ with respect to $x$, $J_{g,x}$, and the partial derivatives of $g$ with respect to $p$, $J_{g,p}$.\n$$\nJ_{g,x} = \\frac{\\partial g}{\\partial x} = \\begin{pmatrix}\n0 & 1 & 0 \\\\\n0 & 0 & 1 \\\\\n0 & \\frac{p_4 p_5}{(p_5 + x_2^*)^2} & 0\n\\end{pmatrix}\n$$\nThe partial derivatives $\\frac{\\partial g}{\\partial p_k}$ are non-zero only for $y_3$ with respect to $p_4$ and $p_5$:\n$$\n\\frac{\\partial g}{\\partial p_4} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\frac{x_2^*}{p_5 + x_2^*} \\end{pmatrix}, \\quad\n\\frac{\\partial g}{\\partial p_5} = \\begin{pmatrix} 0 \\\\ 0 \\\\ -\\frac{p_4 x_2^*}{(p_5 + x_2^*)^2} \\end{pmatrix}\n$$\nFor all other $k$, $\\frac{\\partial g}{\\partial p_k}$ is a zero vector. The matrix of unnormalized output sensitivities, $\\frac{\\partial y}{\\partial p}$, is computed as $J_{g,x} \\left(\\frac{\\partial x^*}{\\partial p}\\right) + J_{g,p}$, where $\\frac{\\partial x^*}{\\partial p}$ is the $3 \\times 7$ matrix of state sensitivities.\n\n**Step 5: Normalization**\nFinally, the normalized sensitivity matrix $S$ is computed element-wise. For each output $y_i$ and parameter $p_k$:\n$$\nS_{i,k} = \\frac{p_k}{y_i^*} \\left(\\frac{\\partial y}{\\partial p}\\right)_{i,k}\n$$\nwhere $y_i^*$ are the steady-state output values:\n$$\ny_1^* = x_2^*, \\quad y_2^* = x_3^*, \\quad y_3^* = \\frac{p_4 x_2^*}{p_5 + x_2^*} = p_6 x_3^*\n$$\nSince all parameters $p_j$ are positive, the steady-state values $x_i^*$ and $y_i^*$ are also positive, preventing division by zero. The resulting $3 \\times 7$ matrix $S$ is computed for each test case.",
            "answer": "```python\nimport numpy as np\nfrom typing import List, Tuple\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the sensitivity analysis for the given test cases.\n    \"\"\"\n\n    def compute_sensitivity_matrix(p: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Computes the 3x7 normalized sensitivity matrix S for a given parameter vector p.\n        \n        Args:\n            p: A 1D numpy array of 7 parameters (p0, ..., p6).\n\n        Returns:\n            A 2D numpy array (3x7) representing the matrix S.\n        \"\"\"\n        p0, p1, p2, p3, p4, p5, p6 = p\n\n        # Step 1: Compute steady state x_star\n        if p1 == 0 or p3 == 0:\n            # Avoid division by zero, though problem statement guarantees positive params\n            raise ValueError(\"Parameters p1 and p3 must be non-zero.\")\n        \n        x1_star = p0 / p1\n        x2_star = (p2 / p3) * x1_star\n        \n        if p6 == 0 or (p5 + x2_star) == 0:\n            raise ValueError(\"Parameters p6 and (p5 + x2_star) must be non-zero.\")\n        \n        x3_star = (p4 / p6) * x2_star / (p5 + x2_star)\n        x_star = np.array([x1_star, x2_star, x3_star])\n\n        # Step 2: Assemble Jacobian J_x(x_star, p)\n        Jx_f = np.zeros((3, 3))\n        Jx_f[0, 0] = -p1\n        Jx_f[1, 0] = p2\n        Jx_f[1, 1] = -p3\n        Jx_f[2, 1] = (p4 * p5) / ((p5 + x2_star)**2)\n        Jx_f[2, 2] = -p6\n\n        # Step 3: Solve for state sensitivities dx*/dp_k\n        dx_dp = np.zeros((3, 7))\n        \n        # Calculate condition number to decide on solver\n        cond_Jx = np.linalg.cond(Jx_f)\n        ILL_CONDITIONED_THRESHOLD = 1e12\n\n        for k in range(7):\n            # Form the right-hand side vector b_k = -df/dp_k\n            b_k = np.zeros(3)\n            if k == 0:  # p0\n                b_k[0] = -1.0\n            elif k == 1:  # p1\n                b_k[0] = x1_star\n            elif k == 2:  # p2\n                b_k[1] = -x1_star\n            elif k == 3:  # p3\n                b_k[1] = x2_star\n            elif k == 4:  # p4\n                b_k[2] = -x2_star / (p5 + x2_star)\n            elif k == 5:  # p5\n                b_k[2] = p4 * x2_star / ((p5 + x2_star)**2)\n            elif k == 6:  # p6\n                b_k[2] = x3_star\n            \n            # Solve the linear system\n            if cond_Jx > ILL_CONDITIONED_THRESHOLD:\n                # Use SVD with Tikhonov regularization for ill-conditioned system\n                U, s, Vh = np.linalg.svd(Jx_f)\n                # Regularization parameter alpha, scaled by the largest singular value\n                alpha = 1e-8 * s[0]\n                s_reg = s / (s**2 + alpha)\n                # Reconstruct z_k = V * diag(s_reg) * U.T * b_k\n                z_k = Vh.T @ (np.diag(s_reg) @ (U.T @ b_k))\n            else:\n                # Use standard direct solver for well-conditioned system\n                z_k = np.linalg.solve(Jx_f, b_k)\n            \n            dx_dp[:, k] = z_k\n\n        # Step 4: Compute output sensitivities dy/dp\n        # y = g(x*, p), dy/dp = (dg/dx)*(dx*/dp) + (dg/dp)\n        \n        # Jacobian dg/dx evaluated at x_star\n        Jg_x = np.zeros((3, 3))\n        Jg_x[0, 1] = 1.0\n        Jg_x[1, 2] = 1.0\n        Jg_x[2, 1] = (p4 * p5) / ((p5 + x2_star)**2)\n        \n        # Partial derivatives dg/dp\n        Jg_p = np.zeros((3, 7))\n        Jg_p[2, 4] = x2_star / (p5 + x2_star)\n        Jg_p[2, 5] = -p4 * x2_star / ((p5 + x2_star)**2)\n\n        # Matrix of un-normalized output sensitivities\n        dy_dp = Jg_x @ dx_dp + Jg_p\n        \n        # Step 5: Normalization\n        # Compute steady-state outputs y_star\n        y1_star = x2_star\n        y2_star = x3_star\n        y3_star = p4 * x2_star / (p5 + x2_star)\n        y_star = np.array([y1_star, y2_star, y3_star])\n\n        S = np.zeros((3, 7))\n        for i in range(3):\n            if y_star[i] == 0:\n                # This should not happen for positive parameters\n                S[i, :] = 0.0\n            else:\n                for k in range(7):\n                    S[i, k] = (p[k] / y_star[i]) * dy_dp[i, k]\n                    \n        return S\n\n    # Test suite from the problem statement\n    test_cases: List[Tuple[float, ...]] = [\n        # Case A: Well-conditioned\n        (10.0, 2.0, 5.0, 1.0, 3.0, 1.0, 0.5),\n        # Case B: Ill-conditioned\n        (10.0, 1e-6, 5.0, 1e-6, 3.0, 1.0, 0.5),\n        # Case C: Potentially stiff/extreme values\n        (10.0, 2.0, 5.0, 1.0, 3.0, 1e-3, 100.0)\n    ]\n\n    results = []\n    for case_params in test_cases:\n        p_vec = np.array(case_params)\n        S_matrix = compute_sensitivity_matrix(p_vec)\n        results.append(S_matrix.tolist())\n\n    # Format the final output exactly as required\n    # Creates a string representation of a list of lists of lists.\n    # Ex: '[[[...],[...]], [[...],[...]]]'\n    formatted_results = str(results).replace(\"], [\", \"],\\n [\") # for readability, not required\n    formatted_results = str(results)\n\n    print(formatted_results)\n\nsolve()\n```"
        }
    ]
}