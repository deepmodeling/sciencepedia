{
    "hands_on_practices": [
        {
            "introduction": "要有效应用赤池信息准则（AIC），首先必须理解其公式以及如何利用它来比较模型。本练习将通过一个实际的药代动力学模型选择问题，引导您从理论上的Kullback-Leibler散度推导出实用的AIC公式。通过这个过程，您将亲手实践如何在模型的拟合优度（通过对数似然体现）和复杂性（通过参数数量体现）之间进行权衡。",
            "id": "3903661",
            "problem": "一个药代动力学建模团队正在比较用于一组患者肝脏药物清除的两种候选群体模型。每个候选模型都是通过最大似然 (ML) 估计的非线性混合效应 (NLME) 模型。第一个模型包含清除率和分布容积的固定效应和随机效应，共有 $k=14$ 个自由估计参数。第二个模型在清除率上增加了一个随机效应协方差项和一个非线性协变量效应，从而得到 $k=16$ 个自由估计参数。最大似然拟合得到的最大化对数似然值，第一个模型为 $\\ell_{1}=-1020.5$，第二个模型为 $\\ell_{2}=-1018.0$，其中 $\\ell$ 表示在最大似然估计值处计算的自然对数似然。\n\n从未知数据生成机制与参数候选模型之间的期望 Kullback–Leibler (KL) 散度的定义出发，并基于最大似然估计可最大化样本对数似然的原理，推导适用于最大似然拟合的参数模型的模型选择准则，即赤池信息准则 (AIC)。利用此推导计算两个模型的 AIC，根据 AIC 确定更优的模型，然后报告两个模型之间的 AIC 差异，该差异定义为较差（非首选）模型的 AIC 减去较好（首选）模型的 AIC。\n\n将您最终报告的差异四舍五入到四位有效数字。最终量无需物理单位。",
            "solution": "本题要求从与 Kullback–Leibler (KL) 散度相关的基本原理出发，推导赤池信息准则 (AIC)，并将其应用于药代动力学建模中的模型选择问题。\n\n首先，进行 AIC 的理论推导。AIC 的基础是信息论。假设真实、未知的数据生成过程由概率密度函数 (pdf) $f(x)$ 表示。我们的目标是用一个参数模型来近似这个过程，该模型来自一个以 $g(x|\\theta)$ 表示的 pdf 族，其中 $\\theta$ 是一个参数向量。Kullback–Leibler (KL) 散度，或称相对熵，量化了当使用模型 $g(x|\\theta)$ 来近似真实过程 $f(x)$ 时所损失的信息。它被定义为，关于真实分布 $f$ 的，两个密度比值的对数的期望：\n$$ D_{KL}(f || g(\\cdot|\\theta)) = E_f\\left[\\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right)\\right] = \\int f(x) \\ln(f(x)) dx - \\int f(x) \\ln(g(x|\\theta)) dx $$\n在这个表达式中，$\\int f(x) \\ln(f(x)) dx$ 项是真实分布的熵。由于对于给定的真实过程 $f(x)$，该项是常数，并且不依赖于模型 $g(x|\\theta)$，因此最小化 KL 散度等价于最大化第二项 $E_f[\\ln(g(x|\\theta))]$。该项表示在真实数据生成分布下模型的期望对数似然。\n\n在实践中，真实分布 $f(x)$ 以及理想化模型所应具有的真实参数 $\\theta_0$ 是未知的。我们有一组观测数据，记为 $y$，它是来自分布 $f(x)$ 的一个实现。利用这些数据，我们通常通过最大似然 (ML) 法得到参数的估计值 $\\hat{\\theta}$。ML 估计值 $\\hat{\\theta}_{ML}$ 是使观测数据的对数似然函数 $\\ell(\\theta|y) = \\ln g(y|\\theta)$ 最大化的 $\\theta$ 值。\n\n最大化的对数似然 $\\ell(\\hat{\\theta}_{ML}|y)$ 衡量了模型对用于拟合的数据的拟合优度。然而，它对于模型在同样来自 $f(x)$ 的一个新的、独立数据集 $y_{new}$ 上的预测准确性来说，是一个过于乐观的有偏估计量。我们为模型选择真正希望最大化的量是期望预测对数似然，它可以表示为关于原始数据 $y$ 的分布的期望：$E_y \\left[ E_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{ML}(y))] \\right]$。\n\nAkaike 证明，在某些正则性条件下且对于大样本量，样本内最大化对数似然会高估这个目标量。他建立了两者之间的渐近关系：\n$$ E_y \\left[ \\ell(\\hat{\\theta}_{ML}(y)|y) \\right] - E_y \\left[ E_{y_{new}}[\\ln g(y_{new}|\\hat{\\theta}_{ML}(y))] \\right] \\approx k $$\n其中 $k$ 是参数向量 $\\theta$ 中自由估计参数的数量。这意味着最大化对数似然 $\\ell(\\hat{\\theta}_{ML}|y)$ 作为期望预测对数似然的估计，平均而言存在向上的偏差，偏差量约等于 $k$。\n\n为了获得对预测准确性的一个偏差较小的估计，我们可以通过从最大化对数似然中减去偏差项 $k$ 来校正这种乐观性。因此，期望预测对数似然的一个近似无偏估计量是 $\\ell(\\hat{\\theta}_{ML}|y) - k$。最大化这个量是模型选择的一个合理原则。\n\n由于与偏差 (deviance) 和似然比检验相关的历史原因，Akaike 通过将这个经偏差校正的对数似然乘以 $-2$ 来定义他的准则。这将目标从最大化转变为最小化。因此，赤池信息准则 (AIC) 定义为：\n$$ AIC = -2 (\\ell - k) = -2\\ell + 2k $$\n其中 $\\ell$ 是模型的最大化对数似然值，k 是自由估计参数的数量。AIC 值最低的模型被选为在拟合优度（高 $\\ell$）和简约性（低 $k$）之间达到最佳平衡的模型。\n\n现在，我们将此公式应用于题目中描述的两个候选模型。\n\n对于模型 1：\n参数数量，$k_1 = 14$。\n最大化对数似然，$\\ell_1 = -1020.5$。\n模型 1 的 AIC 为：\n$$ AIC_1 = -2\\ell_1 + 2k_1 = -2(-1020.5) + 2(14) $$\n$$ AIC_1 = 2041.0 + 28 = 2069.0 $$\n\n对于模型 2：\n参数数量，$k_2 = 16$。\n最大化对数似然，$\\ell_2 = -1018.0$。\n模型 2 的 AIC 为：\n$$ AIC_2 = -2\\ell_2 + 2k_2 = -2(-1018.0) + 2(16) $$\n$$ AIC_2 = 2036.0 + 32 = 2068.0 $$\n\n为了选择更优的模型，我们比较它们的 AIC 值。AIC 值较低的模型被认为是更优的。\n$AIC_1 = 2069.0$\n$AIC_2 = 2068.0$\n由于 $AIC_2  AIC_1$，模型 2 是更优的模型。根据 AIC，拟合度的提升（对数似然增加 2.5）足以证明增加 2 个额外参数是合理的。\n\n最后一步是计算较差（非首选）模型与较好（首选）模型之间的 AIC 差异。\n较差模型：模型 1 ($AIC_1 = 2069.0$)\n较好模型：模型 2 ($AIC_2 = 2068.0$)\n差异 $\\Delta AIC$ 为：\n$$ \\Delta AIC = AIC_{worse} - AIC_{better} = AIC_1 - AIC_2 $$\n$$ \\Delta AIC = 2069.0 - 2068.0 = 1.0 $$\n题目要求将此结果报告为四位有效数字。数值 $1.0$ 必须写成 $1.000$ 以满足此精度要求。\n$$ \\Delta AIC = 1.000 $$",
            "answer": "$$\n\\boxed{1.000}\n$$"
        },
        {
            "introduction": "计算出AIC值后，下一步是进行有意义的解读，而不仅仅是选择AIC值最小的模型。本练习将演示如何使用AIC差值（$\\Delta \\mathrm{AIC}$）和证据比来量化比较不同模型的相对支持度。这使我们能够超越“某个模型更好”的简单结论，精确地说明一个模型比另一个模型受数据支持的可能性大多少。",
            "id": "3903626",
            "problem": "一个转化生理学小组正在利用连续血糖监测和胰岛素输注记录，为成人构建葡萄糖-胰岛素调节的系统级模型。他们使用最大似然法将三个机制性候选模型拟合到相同的队列和数据集上：一个简约的单室摄取模型，一个具有远程胰岛素动力学的双室最小模型，以及一个具有可饱和葡萄糖转运的非线性摄取模型。这三个模型在参数数量和结构上有所不同，但根据现有数据，每个模型都是可辨识的。模型拟合后，三个候选模型的赤池信息准则值分别为 $134.2$、$135.0$ 和 $141.3$。\n\n从赤池信息准则的核心定义出发，即它是在最大似然法下对拟合模型的期望Kullback–Leibler信息的一个偏差校正估计量，并且模型的支持度可以通过比较不同模型的准则值差异来评估，请完成以下任务：\n\n1. 计算这三个模型的 $\\Delta \\mathrm{AIC}$ 值集合。\n2. 从基于似然信息的首要原则出发，推导出一个一致的模型支持度度量，并利用这些差异来量化每个模型的相对支持度，然后用它来计算这三个模型之间的两两支持度比较。\n3. 基于您的定量比较，解释在此生物医学背景下每个模型的实际支持水平，并明确评论哪些模型可被认为是基本无法区分的、支持度中等偏低的或支持度相当低的。\n\n为便于评分，请报告支持度最高的模型相对于支持度最低的模型的证据比，并四舍五入到四位有效数字。证据比是无量纲的；最终答案中不要包含单位。",
            "solution": "该问题提供了三个葡萄糖-胰岛素调节候选模型的赤池信息准则（AIC）值，并要求基于信息论原理对其相对支持度进行定量和解释性比较。该问题具有科学依据，表述清晰，并包含了完整解答所需的所有信息。\n\n设三个模型分别表示为 $M_1$、$M_2$ 和 $M_3$。给出的AIC值为：\n$\\mathrm{AIC}_1 = 134.2$ (简约单室摄取模型)\n$\\mathrm{AIC}_2 = 135.0$ (双室最小模型)\n$\\mathrm{AIC}_3 = 141.3$ (非线性摄取模型)\n\n该过程按要求分为三个不同的任务。\n\n**1. 计算 $\\Delta \\mathrm{AIC}$ 值**\n\n使用AIC进行模型比较的第一步是计算每个模型的AIC值与候选模型集中观察到的最小AIC值之间的差值。这个差值，对于模型 $i$ 记为 $\\Delta \\mathrm{AIC}_i$，量化了使用模型 $M_i$ 而非该集合中最佳拟合模型时所产生的信息损失。\n\n最小AIC值为：\n$$\n\\mathrm{AIC}_{\\min} = \\min(\\mathrm{AIC}_1, \\mathrm{AIC}_2, \\mathrm{AIC}_3) = \\min(134.2, 135.0, 141.3) = 134.2\n$$\n因此，该集合中的最佳模型是 $M_1$。\n\n这三个模型的 $\\Delta \\mathrm{AIC}$ 值为：\n$$\n\\Delta \\mathrm{AIC}_1 = \\mathrm{AIC}_1 - \\mathrm{AIC}_{\\min} = 134.2 - 134.2 = 0\n$$\n$$\n\\Delta \\mathrm{AIC}_2 = \\mathrm{AIC}_2 - \\mathrm{AIC}_{\\min} = 135.0 - 134.2 = 0.8\n$$\n$$\n\\Delta \\mathrm{AIC}_3 = \\mathrm{AIC}_3 - \\mathrm{AIC}_{\\min} = 141.3 - 134.2 = 7.1\n$$\n$\\Delta \\mathrm{AIC}$ 值的集合是 $\\{0, 0.8, 7.1\\}$。\n\n**2. 相对模型支持度的推导与计算**\n\n问题要求从基于似然信息的首要原则推导模型支持度的度量。AIC源于Kullback-Leibler（KL）信息论。其核心思想是，给定数据 $D$，模型 $M_i$ 的似然 $\\mathcal{L}(M_i|D)$ 与其相对于真实数据生成过程的估计KL信息损失的负值的指数成正比。Akaike证明了，这个相对期望信息的无偏估计量是 $\\frac{1}{2} \\mathrm{AIC}_i$。\n\n因此，给定数据下模型 $M_i$ 的似然 $\\mathcal{L}(M_i|D)$ 可以通过以下变换与其AIC值相关联：\n$$\n\\mathcal{L}(M_i|D) \\propto \\exp\\left(-\\frac{1}{2}\\mathrm{AIC}_i\\right)\n$$\n这个变换将模型置于一个似然尺度上，从而可以直接进行比较。一个模型（$M_i$）相对于另一个模型（$M_j$）的相对支持度通过证据比来量化，即它们似然的比值：\n$$\n\\frac{\\mathcal{L}(M_i|D)}{\\mathcal{L}(M_j|D)} = \\frac{\\exp(-\\frac{1}{2}\\mathrm{AIC}_i)}{\\exp(-\\frac{1}{2}\\mathrm{AIC}_j)} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_i - \\mathrm{AIC}_j)\\right) = \\exp\\left(-\\frac{1}{2}\\Delta_{ij}\\right)\n$$\n其中 $\\Delta_{ij} = \\mathrm{AIC}_i - \\mathrm{AIC}_j$。这个证据比就是所要求的一致的模型支持度度量。\n\n利用这个推导出的关系，我们计算两两支持度的比较，在适当的情况下以最佳模型 $M_1$ 作为参考：\n-   **模型 $M_1$ vs. 模型 $M_2$**：$M_1$ 相对于 $M_2$ 的证据比是\n    $$\n    E_{1,2} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_2)\\right) = \\exp\\left(-\\frac{1}{2}(134.2 - 135.0)\\right) = \\exp(0.4) \\approx 1.492\n    $$\n-   **模型 $M_1$ vs. 模型 $M_3$**：$M_1$ 相对于 $M_3$ 的证据比是\n    $$\n    E_{1,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_3)\\right) = \\exp\\left(-\\frac{1}{2}(134.2 - 141.3)\\right) = \\exp(3.55) \\approx 34.813\n    $$\n-   **模型 $M_2$ vs. 模型 $M_3$**：$M_2$ 相对于 $M_3$ 的证据比是\n    $$\n    E_{2,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_2 - \\mathrm{AIC}_3)\\right) = \\exp\\left(-\\frac{1}{2}(135.0 - 141.3)\\right) = \\exp(3.15) \\approx 23.336\n    $$\n\n**3. 实际支持水平的解释**\n\n对定量结果的解释依赖于针对 $\\Delta \\mathrm{AIC}$ 值的既定经验法则（例如，Burnham 和 Anderson 在2002年提出的）。\n-   $\\Delta \\mathrm{AIC} \\in [0, 2]$：模型具有充分的支持度，与最佳模型基本无法区分。\n-   $\\Delta \\mathrm{AIC} \\in [4, 7]$：模型的支持度相当低。\n-   $\\Delta \\mathrm{AIC}  10$：模型基本没有支持度，可以被排除。\n\n将这些经验法则应用于当前的生物医学建模背景：\n-   **模型 $M_1$（单室模型）** 的 $\\Delta \\mathrm{AIC}_1 = 0$，根据定义，它是该集合中支持度最高的模型。\n-   **模型 $M_2$（双室模型）** 的 $\\Delta \\mathrm{AIC}_2 = 0.8$，完全落在具有充分支持度的范围内。约等于 $1.5$ 的证据比表明，$M_1$ 的合理性仅略高于 $M_2$。在实际应用中，这两个模型将被认为是**基本无法区分的**。数据并未提供强有力的依据来拒绝结构稍复杂的双室模型 $M_2$，而支持更简约的单室模型 $M_1$。\n-   **模型 $M_3$（非线性模型）** 的 $\\Delta \\mathrm{AIC}_3 = 7.1$，处于“支持度相当低”类别的上边界。约等于 $35$ 的证据比表明，最佳模型 $M_1$ 得到数据的支持度几乎是 $M_3$ 的 $35$ 倍。这代表了强有力的证据差异。在此生物医学背景下，模型 $M_3$ 将被认为是**支持度相当低的**，并且是解释所观察到的葡萄糖-胰岛素动力学的一个不佳候选者，很可能应该被排除在进一步的考虑之外。\n\n最终要求的答案是支持度最高的模型（$M_1$）相对于支持度最低的模型（$M_3$）的证据比。这在第2部分中计算为 $E_{1,3}$。\n$$\nE_{1,3} = \\exp\\left(-\\frac{1}{2}(\\mathrm{AIC}_1 - \\mathrm{AIC}_3)\\right) = \\exp(3.55) \\approx 34.813395\n$$\n将此值四舍五入到四位有效数字得到 $34.81$。",
            "answer": "$$\\boxed{34.81}$$"
        },
        {
            "introduction": "标准的AIC是基于大样本假设的，但在生物医学研究中，数据量有限是常态。本练习将聚焦于这一常见情况，介绍小样本校正的赤池信息准则（AICc）。通过计算校正项的大小，您将理解为什么需要这种校正来防止模型过拟合，并体会到它在模型选择中的重要作用。",
            "id": "3903628",
            "problem": "一个生物医学系统建模小组正在使用来自 $n=30$ 名患者的实验时间序列数据来校准一个细胞因子信号动力学的机理模型。该候选机理模型有 $k=8$ 个自由参数。设 $\\ell(\\hat{\\theta})$ 表示在该候选模型的最大似然估计 (MLE) $\\hat{\\theta}$ 处评估的最大化对数似然，并假设 $\\ell(\\hat{\\theta})=-120$。从通过Kullback–Leibler (KL) 散度测量的最小化期望信息损失原理出发，推导Akaike信息准则 (AIC) 和小样本校正的Akaike信息准则 (AICc) 的形式。然后，对给定的 $(n,k,\\ell(\\hat{\\theta}))$ 计算 $AIC$ 和 $AICc$，并从绝对和相对两个方面解释小样本校正相对于 $AIC$ 的大小。精确表达您的最终数值计算结果，不要四舍五入。仅提供 $AIC$ 和 $AICc$ 的最终数值结果。",
            "solution": "该问题是有效的，因为它在统计信息论方面有科学依据，提供了所有必要信息，是适定的，并且没有任何事实或逻辑上的不一致。\n\nAkaike信息准则 (AIC) 及其小样本校正版本 (AICc) 是基于信息论的模型选择准则。它们提供了当使用给定模型来表示生成数据的过程时，期望的、相对的信息损失的估计。推导从Kullback-Leibler (KL) 散度开始。\n\n设真实的、未知的数据生成过程具有一个概率分布函数（或密度），记为 $f(x)$。设我们的候选模型由一个分布族 $g(x|\\theta)$ 表示，该分布族由向量 $\\theta$ 参数化。KL散度，或使用$g$来近似$f$的信息损失，定义为：\n$$\nI(f,g) = \\int f(x) \\ln\\left(\\frac{f(x)}{g(x|\\theta)}\\right) dx\n$$\n这个表达式可以展开为：\n$$\nI(f,g) = \\int f(x) \\ln(f(x)) dx - \\int f(x) \\ln(g(x|\\theta)) dx\n$$\n第一项 $\\int f(x) \\ln(f(x)) dx$ 仅取决于真实分布 $f$，并且相对于模型 $g$ 是一个常数。因此，最小化KL散度 $I(f,g)$ 等价于最大化第二项，即模型 $g(x|\\theta)$ 的期望对数似然，其中期望是关于真实分布 $f$ 计算的：\n$$\nE_{x \\sim f}[\\ln(g(x|\\theta))] = \\int f(x) \\ln(g(x|\\theta)) dx\n$$\n在实践中，我们不知道模型族的真实参数向量 $\\theta$。我们从数据中估计它，通常使用最大似然估计 (MLE)，记为 $\\hat{\\theta}$。然后，带有估计参数的模型 $g(x|\\hat{\\theta})$ 的质量通过其在从相同真实分布 $f$ 中抽取的新数据 $y$ 上的期望表现来评估。这就是期望信息损失：\n$$\nE_{y \\sim f} \\left[ E_{x \\sim f}[\\ln(g(y|\\hat{\\theta}(x)))] \\right]\n$$\n其中双重期望意味着我们同时对训练数据 $x$（它决定了 $\\hat{\\theta}$）和新的、独立的验证数据 $y$ 进行平均。\n\nAkaike 证明，来自训练数据的最大化对数似然 $\\ell(\\hat{\\theta}) = \\ln(\\mathcal{L}(\\hat{\\theta}|x))$（其中 $\\mathcal{L}$ 是似然函数）是此目标量的一个有偏估计量。对于大样本量 $n$，渐近偏差约等于模型中可估计参数的数量 $k$。即：\n$$\nE[\\ell(\\hat{\\theta})] \\approx E_{y \\sim f} \\left[ E_{x \\sim f}[\\ln(g(y|\\hat{\\theta}(x)))] \\right] + k\n$$\n因此，用于预测目的的期望对数似然的偏差校正估计是 $\\ell(\\hat{\\theta}) - k$。Akaike 出于与偏差统计相关的历史原因，将此量乘以 $-2$ 来定义他的准则：\n$$\nAIC = -2 (\\ell(\\hat{\\theta}) - k) = -2\\ell(\\hat{\\theta}) + 2k\n$$\n这就是Akaike信息准则。较低的AIC值表示模型在拟合优度（高 $\\ell(\\hat{\\theta})$）和复杂度（低 $k$）之间有更好的期望权衡。\n\n偏差校正项 $k$ 是一个渐近结果。对于较小的样本量，当比率 $n/k$ 不大时（通常当 $n/k \\le 40$ 时），这种校正是不充分的。一个考虑了样本量的二阶校正项，提供了对信息损失更准确的估计。这就导出了小样本校正的Akaike信息准则，即AICc。更准确的偏差校正不是 $k$，而是 $k \\frac{n}{n-k-1}$。AICc定义为：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k \\frac{n}{n-k-1}\n$$\nAICc和AIC之间的关系可以通过分离出额外的惩罚项来表示：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k + 2k\\left(\\frac{n}{n-k-1} - 1\\right)\n$$\n$$\nAICc = AIC + 2k\\left(\\frac{n - (n-k-1)}{n-k-1}\\right) = AIC + 2k\\left(\\frac{k+1}{n-k-1}\\right)\n$$\n$$\nAICc = AIC + \\frac{2k(k+1)}{n-k-1}\n$$\n这种形式明确地显示了小样本校正惩罚项，它同时取决于参数数量 $k$ 和样本量 $n$。当 $n \\to \\infty$ 时，校正项消失，并且 $AICc \\to AIC$。\n\n现在我们为给定的问题计算这些值。所提供的值是：\n- 样本量, $n = 30$\n- 自由参数数量, $k = 8$\n- 最大化对数似然, $\\ell(\\hat{\\theta}) = -120$\n\n首先，我们计算AIC：\n$$\nAIC = -2\\ell(\\hat{\\theta}) + 2k = -2(-120) + 2(8) = 240 + 16 = 256\n$$\n接下来，我们计算AICc：\n$$\nAICc = -2\\ell(\\hat{\\theta}) + 2k \\frac{n}{n-k-1} = -2(-120) + 2(8) \\frac{30}{30-8-1}\n$$\n$$\nAICc = 240 + 16 \\left(\\frac{30}{21}\\right) = 240 + 16 \\left(\\frac{10}{7}\\right) = 240 + \\frac{160}{7}\n$$\n为了将其表示为单个分数：\n$$\nAICc = \\frac{240 \\times 7}{7} + \\frac{160}{7} = \\frac{1680 + 160}{7} = \\frac{1840}{7}\n$$\n问题要求对小样本校正进行解释。比率 $n/k = 30/8 = 3.75$。由于该比率远小于通常的经验法则阈值40，因此强烈推荐使用AICc而不是AIC。\n\n小样本校正的大小是AICc和AIC之间的差异：\n$$\n\\text{绝对校正} = AICc - AIC = \\frac{1840}{7} - 256 = \\frac{1840 - 256 \\times 7}{7} = \\frac{1840 - 1792}{7} = \\frac{48}{7}\n$$\n这个 $\\frac{48}{7} \\approx 6.86$ 的绝对差异是相当大的。模型选择决策通常基于AIC值的差异（例如，大于2的差异被认为是有意义的），因此这个校正大到足以可能改变关于哪个模型是最佳的结论。\n\n相对于AIC的相对校正是：\n$$\n\\text{相对校正} = \\frac{AICc - AIC}{AIC} = \\frac{48/7}{256} = \\frac{48}{7 \\times 256} = \\frac{3 \\times 16}{7 \\times 16 \\times 16} = \\frac{3}{7 \\times 16} = \\frac{3}{112}\n$$\n这对应于大约 $\\frac{3}{112} \\approx 2.68\\%$ 的相对增加。AICc值高于AIC值，反映了对模型复杂度的更大惩罚。这种增加的惩罚有助于防止过拟合，这是一种模型对特定数据集中的噪声拟合得过于紧密，从而导致其在新数据上预测性能较差的现象。在 $n/k$ 比率较低的情况下，这种风险尤其高，使得AICc校正对于稳健的模型选择至关重要。\n最终要求的输出是 $AIC$ 和 $AICc$ 的数值。\n\n$AIC = 256$\n$AICc = \\frac{1840}{7}$",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 256  \\frac{1840}{7} \\end{pmatrix}}\n$$"
        }
    ]
}