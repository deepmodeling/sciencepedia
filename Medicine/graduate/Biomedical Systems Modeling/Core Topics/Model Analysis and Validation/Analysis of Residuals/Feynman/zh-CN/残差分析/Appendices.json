{
    "hands_on_practices": [
        {
            "introduction": "在普通最小二乘法 (OLS) 回归中，理解残差的性质是进行模型验证的第一步。其中一个基本性质是，对于任何包含截距项的模型，原始残差的总和在数学上必须为零。本练习提供了一个通过计算来凭经验验证这一基本原理的动手实践机会，从而弥合了代数理论与实际应用之间的差距，并强调了截距项的关键作用。",
            "id": "4982788",
            "problem": "考虑一个临床建模场景，其中使用普通最小二乘法 (OLS) 对收缩压与年龄和身体质量指数进行回归。设 $n$ 表示患者数量，$\\mathbf{y} \\in \\mathbb{R}^{n}$ 是以毫米汞柱 (mmHg) 为单位的实测收缩压值的向量，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是预测变量的设计矩阵。当包含截距项时，$\\mathbf{X}$ 的第一列是全为1的常数向量，其余列是观测到的协变量。OLS 估计量 $\\hat{\\boldsymbol{\\beta}}$ 最小化残差平方和 $\\sum_{i=1}^{n} \\left(y_{i} - \\hat{y}_{i}\\right)^{2}$，其中拟合值定义为 $\\hat{\\mathbf{y}} = \\mathbf{X} \\hat{\\boldsymbol{\\beta}}$，残差定义为 $e_{i} = y_{i} - \\hat{y}_{i}$，对于 $i=1,\\dots,n$。\n\n从 OLS 的基本设置和定义出发，您必须通过经验验证，在包含截距项时，残差之和为零。您将实现计算过程，对每个测试数据集，拟合 OLS 模型（根据指定是否包含截距项），构建残差 $e_{i} = y_{i} - \\hat{y}_{i}$，然后计算标量 $\\sum_{i=1}^{n} e_{i}$。您必须使用弧度来表示三角函数中使用的角度。每个测试数据集的最终结果必须以布尔值的形式报告，当且仅当残差和的绝对值至多为 $\\tau = 10^{-10}$ (单位为 mmHg) 时，结果为 true，否则为 false。数值计算必须使用 Moore–Penrose 伪逆来获得 OLS 解。\n\n实现一个程序，为每个测试用例执行以下操作：\n- 根据是否包含截距项来构建设计矩阵 $\\mathbf{X}$。\n- 计算 $\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+} \\mathbf{y}$，其中 $\\mathbf{X}^{+}$ 表示 Moore–Penrose 伪逆。\n- 计算残差 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X} \\hat{\\boldsymbol{\\beta}}$ 和标量 $S = \\sum_{i=1}^{n} e_{i}$。\n- 返回一个布尔值，表示是否满足 $\\lvert S \\rvert \\le \\tau$。\n\n使用以下五个测试用例，所有数据均在物理现实范围内，并确保所有三角函数参数均以弧度为单位。在每个案例中，年龄以年为单位，身体质量指数以千克/平方米为单位，收缩压以毫米汞柱为单位。\n\n测试用例 1 (一般情况，异方差噪声，包含截距):\n- 样本量 $n_{1} = 26$。\n- 年龄: $a_{i} = 30 + 2i$，对于 $i = 0, 1, \\dots, 25$。\n- 身体质量指数: $b_{i} = 25 + 0.1(a_{i} - 50) + 2 \\sin(a_{i} / 10)$。\n- 噪声: $\\eta_{i} = 0.1 \\left(1 + 0.05 b_{i}\\right) \\sin(0.3 a_{i})$。\n- 收缩压: $y_{i} = 95 + 0.6 a_{i} + 1.1 b_{i} + \\eta_{i}$。\n- 包含截距。\n\n测试用例 2 (完美线性拟合，包含截距):\n- 样本量 $n_{2} = 8$。\n- 年龄: $a_{i} \\in \\{20, 25, 30, 35, 40, 45, 50, 55\\}$ (按顺序)。\n- 身体质量指数: $b_{i} = 22 + 0.3 i$，对于 $i = 0, 1, \\dots, 7$。\n- 收缩压: $y_{i} = 90 + 0.5 a_{i} + 1.3 b_{i}$。\n- 包含截距。\n\n测试用例 3 (小样本，欠定，包含截距):\n- 样本量 $n_{3} = 3$。\n- 年龄: $(40, 60, 80)$。\n- 身体质量指数: $(22, 30, 28)$。\n- 噪声向量: $(\\nu_{1}, \\nu_{2}, \\nu_{3}) = (0.1 \\times (-0.5), 0.1 \\times 0.3, 0.1 \\times (-0.2))$。\n- 收缩压: $y_{i} = 100 + 0.4 a_{i} + 1.0 b_{i} + \\nu_{i}$。\n- 包含截距。\n\n测试用例 4 (对比案例，数据与测试用例 1 相同但不含截距):\n- 使用与测试用例 1 相同的 $a_{i}$、$b_{i}$ 和 $y_{i}$。\n- 不包含截距。\n\n测试用例 5 (预测变量间存在强共线性，包含截距):\n- 样本量 $n_{5} = 12$。\n- 年龄: $a_{i} = 30 + 5i$，对于 $i = 0, 1, \\dots, 11$。\n- 身体质量指数: $b_{i} = 15 + 0.2 a_{i} + 0.1 \\sin(a_{i})$。\n- 噪声: $\\xi_{i} = 0.05 \\cos(0.5 a_{i})$。\n- 收缩压: $y_{i} = 80 + 0.7 a_{i} + 0.5 b_{i} + \\xi_{i}$。\n- 包含截距。\n\n您的程序应生成单行输出，其中包含五个测试用例的结果，结果按所列顺序排列，形式为方括号内以逗号分隔的列表，例如，“[result1,result2,result3,result4,result5]”。每个元素必须是一个布尔值，表示残差和是否在上述定义的容差 $\\tau$ 之内。不应产生任何其他输出。",
            "solution": "用户希望通过经验验证普通最小二乘 (OLS) 回归的一个基本性质：当模型包含截距项时，残差之和为零。此验证将通过对几个测试数据集进行数值计算来完成。\n\n### 步骤 1：OLS 残差的理论基础\n\nOLS 方法旨在找到使残差平方和 (SSR) 最小化的系数向量 $\\hat{\\boldsymbol{\\beta}}$。给定响应向量 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 和设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$，残差向量定义为 $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$，其中 $\\hat{\\mathbf{y}} = \\mathbf{X}\\boldsymbol{\\beta}$ 是拟合值。\n\nSSR 由下式给出：\n$$SSR(\\boldsymbol{\\beta}) = \\mathbf{e}^\\top\\mathbf{e} = (\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})^\\top(\\mathbf{y} - \\mathbf{X}\\boldsymbol{\\beta})$$\n$$SSR(\\boldsymbol{\\beta}) = \\mathbf{y}^\\top\\mathbf{y} - 2\\boldsymbol{\\beta}^\\top\\mathbf{X}^\\top\\mathbf{y} + \\boldsymbol{\\beta}^\\top\\mathbf{X}^\\top\\mathbf{X}\\boldsymbol{\\beta}$$\n\n为求最小值，我们将 $SSR(\\boldsymbol{\\beta})$ 对 $\\boldsymbol{\\beta}$ 求导，并令梯度为零：\n$$\\nabla_{\\boldsymbol{\\beta}} SSR = -2\\mathbf{X}^\\top\\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\boldsymbol{\\beta} = \\mathbf{0}$$\n\n这就得到了**正规方程**：\n$$\\mathbf{X}^\\top\\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^\\top\\mathbf{y}$$\n\nOLS 残差向量为 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$。通过左乘 $\\mathbf{X}^\\top$ 可以推导出这些残差的一个关键性质：\n$$\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{X}^\\top(\\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}) = \\mathbf{X}^\\top\\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\hat{\\boldsymbol{\\beta}}$$\n\n将正规方程代入此表达式，我们得到：\n$$\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{X}^\\top\\mathbf{y} - \\mathbf{X}^\\top\\mathbf{y} = \\mathbf{0}$$\n\n这个结果 $\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{0}$ 表明残差向量 $\\mathbf{e}$ 与设计矩阵 $\\mathbf{X}$ 的每个列向量正交。\n\n### 步骤 2：截距项的作用\n\n当回归模型包含截距时，设计矩阵 $\\mathbf{X}$ 包含一个全为 1 的列向量，我们将其表示为 $\\mathbf{1} \\in \\mathbb{R}^{n}$。\n$$\\mathbf{X} = [\\mathbf{1} \\mid \\mathbf{x}_1 \\mid \\dots \\mid \\mathbf{x}_{p-1}]$$\n\n由于残差向量 $\\mathbf{e}$ 与 $\\mathbf{X}$ 的每一列都正交，因此它也必须与第一列 $\\mathbf{1}$ 正交：\n$$\\mathbf{1}^\\top\\mathbf{e} = 0$$\n\n展开这个点积可以得到各个残差之和：\n$$\\mathbf{1}^\\top\\mathbf{e} = \\sum_{i=1}^{n} 1 \\cdot e_i = \\sum_{i=1}^{n} e_i$$\n\n因此，对于任何包含截距的 OLS 模型，残差之和为零在数学上是必然的：\n$$\\sum_{i=1}^{n} e_i = 0$$\n\n如果模型不包含截距（即 $\\mathbf{X}$ 不包含全为 1 的列），正交条件 $\\mathbf{X}^\\top\\mathbf{e} = \\mathbf{0}$ 仍然成立，但我们不能再得出 $\\mathbf{1}^\\top\\mathbf{e} = 0$ 的结论。残差之和通常不为零。\n\n### 步骤 3：计算策略与 Moore-Penrose 伪逆\n\n问题要求使用 Moore-Penrose 伪逆 $\\mathbf{X}^{+}$ 求解 OLS 系数。OLS 系数估计量由下式给出：\n$$\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+}\\mathbf{y}$$\n\n这种方法比通过矩阵求逆来解正规方程（例如 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top\\mathbf{y}$）更具通用性，因为它在数值上更稳定，并且即使在 $\\mathbf{X}$ 不是满列秩（例如，由于多重共线性）或不是高矩阵的情况下也能提供唯一解。\n\n残差向量计算如下：\n$$\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{y} - \\mathbf{X}\\mathbf{X}^{+}\\mathbf{y}$$\n\n对于包含截距的模型，$\\sum e_i = 0$ 的理论性质在这种计算方法下仍然有效。然而，由于有限精度的浮点运算，计算出的和可能是一个非常小的非零数。因此，我们将通过检查和的绝对值是否小于或等于一个小容差 $\\tau = 10^{-10}$ 来测试该条件。\n\n每个测试用例的流程如下：\n1.  生成响应向量 $\\mathbf{y}$ 和预测变量（年龄和 BMI）。\n2.  构建设计矩阵 $\\mathbf{X}$。如果包含截距，则在预测变量矩阵前添加一列全为 1 的向量。\n3.  使用 `numpy.linalg.pinv` 计算 $\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}^{+}\\mathbf{y}$。\n4.  计算残差 $\\mathbf{e} = \\mathbf{y} - \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$。\n5.  计算总和 $S = \\sum_{i=1}^{n} e_i$。\n6.  评估布尔条件 $|S| \\le \\tau$。\n\n该程序将应用于五个不同的测试用例。用例 1、2、3 和 5 包含截距，预期会满足条件。用例 4 省略了截距，预期不满足条件，作为一个关键的对照。用例 2（完美拟合）和用例 3（饱和模型，$n=p$）是特殊情况，其中残差本身应该接近于零，从而保证总和为零。用例 5 测试了该性质在强多重共线性下的稳健性。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Empirically verifies the OLS property that residuals sum to zero for models\n    with an intercept.\n    \"\"\"\n\n    def get_test_cases():\n        \"\"\"Generates data for the five specified test cases.\"\"\"\n        cases = []\n        \n        # Test case 1: General case with heteroscedastic noise, intercept included.\n        n1 = 26\n        i1 = np.arange(n1)\n        a1 = 30.0 + 2.0 * i1\n        b1 = 25.0 + 0.1 * (a1 - 50.0) + 2.0 * np.sin(a1 / 10.0)\n        eta1 = 0.1 * (1.0 + 0.05 * b1) * np.sin(0.3 * a1)\n        y1 = 95.0 + 0.6 * a1 + 1.1 * b1 + eta1\n        predictors1 = np.stack([a1, b1], axis=1)\n        cases.append({'y': y1, 'predictors': predictors1, 'intercept': True, 'name': 'Case 1'})\n\n        # Test case 2: Perfect linear fit, intercept included.\n        n2 = 8\n        a2 = np.array([20.0, 25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0])\n        i2 = np.arange(n2)\n        b2 = 22.0 + 0.3 * i2\n        y2 = 90.0 + 0.5 * a2 + 1.3 * b2\n        predictors2 = np.stack([a2, b2], axis=1)\n        cases.append({'y': y2, 'predictors': predictors2, 'intercept': True, 'name': 'Case 2'})\n\n        # Test case 3: Small sample, saturated model (n=p), intercept included.\n        n3 = 3\n        a3 = np.array([40.0, 60.0, 80.0])\n        b3 = np.array([22.0, 30.0, 28.0])\n        nu3 = 0.1 * np.array([-0.5, 0.3, -0.2])\n        y3 = 100.0 + 0.4 * a3 + 1.0 * b3 + nu3\n        predictors3 = np.stack([a3, b3], axis=1)\n        cases.append({'y': y3, 'predictors': predictors3, 'intercept': True, 'name': 'Case 3'})\n\n        # Test case 4: Contrast case, same data as case 1 but without intercept.\n        cases.append({'y': y1, 'predictors': predictors1, 'intercept': False, 'name': 'Case 4'})\n\n        # Test case 5: Strong collinearity, intercept included.\n        n5 = 12\n        i5 = np.arange(n5)\n        a5 = 30.0 + 5.0 * i5\n        b5 = 15.0 + 0.2 * a5 + 0.1 * np.sin(a5)\n        xi5 = 0.05 * np.cos(0.5 * a5)\n        y5 = 80.0 + 0.7 * a5 + 0.5 * b5 + xi5\n        predictors5 = np.stack([a5, b5], axis=1)\n        cases.append({'y': y5, 'predictors': predictors5, 'intercept': True, 'name': 'Case 5'})\n\n        return cases\n\n    test_cases = get_test_cases()\n    results = []\n    tau = 1.0e-10\n\n    for case in test_cases:\n        y = case['y']\n        predictors = case['predictors']\n        include_intercept = case['intercept']\n\n        # Construct the design matrix X\n        if include_intercept:\n            n_obs = predictors.shape[0]\n            intercept_col = np.ones((n_obs, 1))\n            X = np.hstack([intercept_col, predictors])\n        else:\n            X = predictors\n\n        # Compute OLS solution using Moore-Penrose pseudoinverse\n        X_pinv = np.linalg.pinv(X)\n        beta_hat = X_pinv @ y\n        \n        # Compute residuals and their sum\n        residuals = y - (X @ beta_hat)\n        residual_sum = np.sum(residuals)\n        \n        # Check if the sum is within the tolerance\n        is_zero = abs(residual_sum) = tau\n        results.append(is_zero)\n    \n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "虽然原始残差告诉我们每个数据点的误差大小，但它们并不能直接进行比较，因为具有较高杠杆值的观测点其残差方差更小。为了建立一个公平的基础来识别异常观测值（离群点），我们计算标准化残差，该残差考虑了每个数据点的影响力。本实践将指导您完成标准化残差的计算及其解释，这是回归诊断中一项至关重要的技能，用于标记那些模型解释不佳的数据点。",
            "id": "4982808",
            "problem": "考虑一项临床流行病学中的队列研究，其中生物标志物C反应蛋白（CRP）以毫克/升为单位进行测量，然后进行对数变换以稳定方差。将对数变换后的CRP记为 $y_i$，年龄（单位：年）记为 $x_i$，吸烟状态指示变量记为 $z_i$，其中 $z_i \\in \\{0,1\\}$，$z_i=1$ 表示当前吸烟者，$z_i=0$ 表示其他情况。我们考虑一个适用于 $i=1,\\dots,n$ 的线性模型，定义为 $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中误差项 $\\varepsilon_i$ 假定为独立同分布的高斯分布，均值为 $0$，方差为 $\\sigma^2$。使用普通最小二乘法（OLS），从数据中获得拟合值和残差，帽子矩阵的对角元素 $h_{ii}$ 用于量化杠杆值。标准化残差 $r_i$ 用于回归诊断，以评估模型充分性和离群值。诸如 $|r_i|2$ 之类的数值阈值通常根据标准正态参考分布下的近似尾部概率来解释。\n\n根据高斯-马尔可夫（Gauss–Markov）假设的基本原理和OLS估计量的性质，实现一个算法，该算法能够：\n- 使用设计矩阵 $X$（其列分别为截距项、年龄 $x_i$ 和吸烟指示变量 $z_i$）拟合线性模型，以获得 $\\hat{\\beta}$。\n- 计算残差 $e_i$ 和帽子矩阵 $H$ 以获得 $h_{ii}$。\n- 使用 $n-p$自由度，通过残差均方 $s^2$ 估计 $\\sigma^2$，其中 $p$ 是包括截距在内的回归系数数量（此处 $p=3$）。\n- 计算所有观测值的标准化残差 $r_i$。\n- 通过报告在标准正态参考分布下的近似双侧尾部概率 $2\\{1 - \\Phi(2)\\}$ 来解释阈值 $|r_i|2$，其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。此外，报告每个残差的近似双侧尾部概率 $p_i = 2\\Phi(-|r_i|)$。\n\n所有年龄 $x_i$ 必须以年为单位处理。由于 $y_i$ 是对数值，输出是无单位的。\n\n您的程序必须将上述步骤应用于以下包含三个数据集的测试套件，每个数据集均以三元组 $(\\{x_i\\},\\{z_i\\},\\{y_i\\})$ 的形式指定：\n\n- 测试用例1（典型变异性，$n=10$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[22,34,47,51,36,63,41,55,29,68]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1,0,1,0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.79,1.35,1.24,1.59,1.15,1.85,1.26,1.80,0.96,1.97]$\n\n- 测试用例2（一个高杠杆离群值，$n=8$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[25,40,45,50,55,60,65,95]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,0,1,0,1,0,1,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.93,1.16,1.61,1.41,1.70,1.62,1.95,0.80]$\n\n- 测试用例3（近边界小样本，$n=4$, $p=3$）：\n  - 年龄 $\\{x_i\\}$: $[30,50,70,60]$ (年)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[1.01,1.64,1.78,1.86]$\n\n对于每个测试用例，生成：\n- 标准化残差列表 $[r_1,\\dots,r_n]$，四舍五入到6位小数。\n- 近似双侧尾部概率列表 $[p_1,\\dots,p_n]$，其中 $p_i = 2\\Phi(-|r_i|)$，四舍五入到6位小数。\n- 绝对值大于2的残差整数计数 $c$。\n- 浮点数 $\\pi_2 = 2\\{1 - \\Phi(2)\\}$，四舍五入到6位小数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，其本身也是一个按上述顺序排列的列表。例如，总体格式为 $[[\\text{case1\\_residuals},\\text{case1\\_pvals},c_1,\\pi_2],[\\text{case2\\_residuals},\\text{case2\\_pvals},c_2,\\pi_2],[\\text{case3\\_residuals},\\text{case3\\_pvals},c_3,\\pi_2]]$。所有概率都必须以小数形式表示，不能使用百分号。",
            "solution": "本问题要求对给定的临床数据进行线性回归分析，并计算标准化残差以识别潜在的离群点。该过程遵循标准的回归诊断步骤。\n\n### 步骤 1：构建模型\n对于每个测试用例，我们首先构建设计矩阵 $\\mathbf{X}$ 和响应向量 $\\mathbf{y}$。设计矩阵 $\\mathbf{X}$ 是一个 $n \\times p$ 的矩阵，其中 $n$ 是观测数量，$p=3$ 是参数数量。它的列分别是：\n1.  一个全为1的截距项列。\n2.  年龄 $\\{x_i\\}$。\n3.  吸烟状态指示变量 $\\{z_i\\}$。\n\n### 步骤 2：普通最小二乘 (OLS) 拟合\n我们使用 OLS 估计系数向量 $\\hat{\\boldsymbol{\\beta}}$。OLS 解最小化了残差平方和，由正规方程给出：\n$$ \\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y} $$\n\n### 步骤 3：计算残差和杠杆值\n利用估计的系数，我们计算：\n-   **拟合值**: $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$\n-   **原始残差**: $\\mathbf{e} = \\mathbf{y} - \\hat{\\mathbf{y}}$\n-   **帽子矩阵**: $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}$\n-   **杠杆值**: $h_{ii}$ 是帽子矩阵 $\\mathbf{H}$ 的第 $i$ 个对角元素。\n\n### 步骤 4：估计误差方差\n误差项的方差 $\\sigma^2$ 由残差均方 (MSE) 或 $s^2$ 估计：\n$$ s^2 = \\frac{\\mathbf{e}^{\\top}\\mathbf{e}}{n-p} = \\frac{\\text{RSS}}{n-p} $$\n其中 RSS 是残差平方和，自由度为 $n-p$。残差标准误为 $s = \\sqrt{s^2}$。\n\n### 步骤 5：计算标准化残差\n标准化残差 $r_i$ 通过将每个原始残差 $e_i$ 除以其标准误的估计值来计算，该估计值考虑了杠杆值：\n$$ r_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}} $$\n在误差项服从正态分布的假设下，这些标准化残差近似服从标准正态分布 $N(0,1)$。\n\n### 步骤 6：计算和解释\n-   **尾部概率**: 对于每个 $r_i$，计算近似的双侧尾部概率 $p_i = 2\\Phi(-|r_i|)$，其中 $\\Phi$ 是标准正态累积分布函数。这告诉我们，在一个拟合良好的模型中，观测到至少与当前残差一样极端的残差的概率。\n-   **离群点计数**: 统计 $|r_i| > 2$ 的观测数量。这是一种常用的启发式方法，因为在正态分布下，大约只有5%的观测值会落在 $\\pm 2$ 标准差之外。\n-   **阈值概率**: 计算与阈值 $|r_i|=2$ 对应的精确概率 $\\pi_2 = 2(1 - \\Phi(2))$，作为参考。\n\n此算法将应用于所有三个测试用例，以生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (typical variability, n=10, p=3)\n        (\n            [22, 34, 47, 51, 36, 63, 41, 55, 29, 68],  # Ages {x_i}\n            [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],          # Smoking indicators {z_i}\n            [0.79, 1.35, 1.24, 1.59, 1.15, 1.85, 1.26, 1.80, 0.96, 1.97] # Log-CRP {y_i}\n        ),\n        # Test case 2 (one high-leverage outlier, n=8, p=3)\n        (\n            [25, 40, 45, 50, 55, 60, 65, 95],         # Ages {x_i}\n            [0, 0, 1, 0, 1, 0, 1, 1],                 # Smoking indicators {z_i}\n            [0.93, 1.16, 1.61, 1.41, 1.70, 1.62, 1.95, 0.80] # Log-CRP {y_i}\n        ),\n        # Test case 3 (near-boundary small sample, n=4, p=3)\n        (\n            [30, 50, 70, 60],                         # Ages {x_i}\n            [0, 1, 0, 1],                             # Smoking indicators {z_i}\n            [1.01, 1.64, 1.78, 1.86]                  # Log-CRP {y_i}\n        )\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        result = process_case(case_data)\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The str() of a list automatically includes spaces, e.g., '[1, 2]'.\n    # To get a compact representation, we can build the string manually.\n    result_strings = []\n    for res in all_results:\n        r_list_str = f\"[{','.join(map(str, res[0]))}]\"\n        p_list_str = f\"[{','.join(map(str, res[1]))}]\"\n        c_str = str(res[2])\n        pi2_str = str(res[3])\n        result_strings.append(f\"[{r_list_str},{p_list_str},{c_str},{pi2_str}]\")\n    \n    # The problem example implies that str(list) is fine. Let's use the simpler approach.\n    print(str(all_results).replace(\" \", \"\"))\n\n\ndef process_case(case_data):\n    \"\"\"\n    Implements OLS regression and diagnostics for a single dataset.\n\n    Args:\n        case_data (tuple): A tuple containing lists for ages, smoking indicators,\n                           and log-CRP values.\n\n    Returns:\n        list: A list containing [standardized_residuals, tail_probabilities, count, pi_2].\n    \"\"\"\n    x_i, z_i, y_i = case_data\n    \n    # Convert input lists to numpy arrays for vector/matrix operations.\n    x_vec = np.array(x_i)\n    z_vec = np.array(z_i)\n    y_vec = np.array(y_i)\n    \n    n = len(y_vec)  # Number of observations\n    p = 3           # Number of parameters (beta_0, beta_1, beta_2)\n    \n    # Construct the n x p design matrix X.\n    X = np.ones((n, p))\n    X[:, 1] = x_vec\n    X[:, 2] = z_vec\n    \n    # Step 1: Fit the linear model using OLS to get beta_hat.\n    # beta_hat = (X'X)^-1 * X'y\n    XTX = X.T @ X\n    XTX_inv = np.linalg.inv(XTX)\n    XTY = X.T @ y_vec\n    beta_hat = XTX_inv @ XTY\n    \n    # Step 2: Compute residuals and hat matrix.\n    # Fitted values: y_hat = X * beta_hat\n    y_hat = X @ beta_hat\n    # Raw residuals: e = y - y_hat\n    residuals = y_vec - y_hat\n    # Hat matrix: H = X * (X'X)^-1 * X'\n    hat_matrix = X @ XTX_inv @ X.T\n    # Leverage values (diagonal of H): h_ii\n    leverages = np.diag(hat_matrix)\n    \n    # Step 3: Estimate error variance sigma^2.\n    # Residual Sum of Squares (RSS)\n    rss = residuals.T @ residuals\n    # Degrees of freedom for error\n    df = n - p\n    # Residual Mean Square (s^2)\n    s_squared = rss / df\n    # Residual standard error (s)\n    s = np.sqrt(s_squared)\n    \n    # Step 4: Compute standardized residuals.\n    # r_i = e_i / (s * sqrt(1 - h_ii))\n    denom = s * np.sqrt(1 - leverages)\n    # Avoid division by zero in case of h_ii=1 (not expected here)\n    # Adding a small epsilon would be robust, but not necessary for these test cases.\n    standardized_residuals = residuals / denom\n    \n    # Step 5  6: Compute tail probabilities and count.\n    # The two-sided tail probability is P(|Z|  |x|) = 2 * (1 - Phi(|x|))\n    # which simplifies to 1 - erf(|x|/sqrt(2)).\n    \n    # For the threshold |r_i|  2\n    pi_2 = 1.0 - erf(2.0 / np.sqrt(2.0))\n    \n    # For each standardized residual\n    tail_probabilities = 1.0 - erf(np.abs(standardized_residuals) / np.sqrt(2.0))\n    \n    # Count of residuals with absolute value greater than 2.\n    count_gt_2 = np.sum(np.abs(standardized_residuals) > 2)\n\n    # Prepare the output lists and values, rounded to 6 decimal places.\n    r_list = np.round(standardized_residuals, 6).tolist()\n    p_vals_list = np.round(tail_probabilities, 6).tolist()\n    \n    return [r_list, p_vals_list, int(count_gt_2), round(pi_2, 6)]\n\n# Execute the solver\nsolve()\n```"
        },
        {
            "introduction": "一个观测值的重要性不仅在于它与模型的拟合程度（其残差），还在于它对模型参数的影响程度（其影响力）。库克距离 (Cook's distance) 是一个典型的度量标准，它将一个观测值的杠杆值和残差大小巧妙地结合成一个单一的影响力指标。这项高级实践要求从第一性原理出发推导库克距离，从而深刻理解为何杠杆值和残差大小共同决定了影响力，然后应用它来量化单个数据点对整体模型的影响。",
            "id": "3871239",
            "problem": "一个生物医学系统模型用于在队列研究中将一个暴露向量与一个多生物标志物响应关联起来。在某个工作点附近进行线性化后，单个生物标志物的模型表示为标准线性回归，\n$$\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon},\n$$\n其中 $\\mathbf{y} \\in \\mathbb{R}^{n}$ 是测量的经对数转换后的响应向量，$\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ 是编码暴露和协变量（包括截距）的设计矩阵，$\\boldsymbol{\\beta} \\in \\mathbb{R}^{p}$ 是未知参数向量，而 $\\boldsymbol{\\varepsilon} \\in \\mathbb{R}^{n}$ 是满足 $\\mathbb{E}[\\boldsymbol{\\varepsilon}]=\\mathbf{0}$ 和 $\\operatorname{Var}(\\boldsymbol{\\varepsilon})=\\sigma^{2}\\mathbf{I}_{n}$ 的噪声向量。普通最小二乘 (OLS) 估计量为 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}$，其拟合值为 $\\hat{\\mathbf{y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}}$，残差为 $\\mathbf{r} = \\mathbf{y} - \\hat{\\mathbf{y}}$。令帽子矩阵为 $\\mathbf{H} = \\mathbf{X}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}$，第 $i$ 个观测值的杠杆值为 $h_{ii} = \\mathbf{x}_{i}^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_{i}$，其中 $\\mathbf{x}_{i}^{\\top}$ 是 $\\mathbf{X}$ 的第 $i$ 行。\n\n考虑删除观测值 $i$，得到留一法估计量 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 和拟合值 $\\hat{\\mathbf{y}}_{(i)}$。仅从线性模型、上述 OLS 定义和标准矩阵恒等式出发，推导观测值 $i$ 的库克距离，将其作为基于个案删除引起的拟合值变化的标量度量。明确地将此标量与残差 $r_{i}$、杠杆值 $h_{ii}$ 以及由 $\\boldsymbol{\\beta}$ 的变化量化的参数影响联系起来。根据需要使用参数数量 $p$ 和全模型残差方差估计 $\\hat{\\sigma}^{2} = \\|\\mathbf{r}\\|^{2}/(n-p)$。\n\n然后，对于一个药物基因组学子研究中的特定患者，其参数为 $p=4$，残差 $r_{i}=0.85$，杠杆值 $h_{ii}=0.12$，全模型方差估计 $\\hat{\\sigma}^{2}=0.30$，计算此观测值的库克距离。将您的最终数值答案四舍五入至四位有效数字。库克距离是无量纲的；请将最终值表示为一个无量纲量。",
            "solution": "### 库克距离的推导\n库克距离 $D_i$ 衡量观测值 $i$ 对模型参数的影响。它可以根据包含和不包含第 $i$ 个观测值时计算出的拟合值向量之间的欧几里得距离平方来定义，并由模型的方差和自由度进行缩放。一个等效且更具洞察力的定义是基于参数向量 $\\boldsymbol{\\beta}$ 的位移：\n$$\nD_i = \\frac{(\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)})^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})(\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)})}{p\\hat{\\sigma}^{2}}\n$$\n这种形式量化了观测值 $i$ 对参数估计 $\\hat{\\boldsymbol{\\beta}}$ 的影响。我们的目标是用残差 $r_i$ 和杠杆值 $h_{ii}$ 来表示它。\n\n关键是找到系数变化 $\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)}$ 的表达式。留一法估计量 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 是使用移除了第 $i$ 个观测值的数据计算的。令 $\\mathbf{X}_{(i)}$ 和 $\\mathbf{y}_{(i)}$ 表示删除了第 $i$ 个个案的设计矩阵和响应向量。我们可以写出：\n$$\n\\mathbf{X}^{\\top}\\mathbf{X} = \\sum_{j=1}^{n} \\mathbf{x}_j \\mathbf{x}_j^{\\top} = \\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)} + \\mathbf{x}_i \\mathbf{x}_i^{\\top}\n$$\n$$\n\\mathbf{X}^{\\top}\\mathbf{y} = \\sum_{j=1}^{n} \\mathbf{x}_j y_j = \\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)} + \\mathbf{x}_i y_i\n$$\n由此，我们得到 $\\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)} = \\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top}$ 和 $\\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)} = \\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i$。\n\n留一法估计量是 $\\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}_{(i)}^{\\top}\\mathbf{X}_{(i)})^{-1}\\mathbf{X}_{(i)}^{\\top}\\mathbf{y}_{(i)}$。代入上述表达式：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1}(\\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i)\n$$\n为了处理秩为1的更新矩阵的逆，我们使用Sherman-Morrison-Woodbury公式：$(\\mathbf{A} - \\mathbf{u}\\mathbf{v}^{\\top})^{-1} = \\mathbf{A}^{-1} + \\frac{\\mathbf{A}^{-1}\\mathbf{u}\\mathbf{v}^{\\top}\\mathbf{A}^{-1}}{1 - \\mathbf{v}^{\\top}\\mathbf{A}^{-1}\\mathbf{u}}$。\n令 $\\mathbf{A} = \\mathbf{X}^{\\top}\\mathbf{X}$ 和 $\\mathbf{u} = \\mathbf{v} = \\mathbf{x}_i$，我们得到：\n$$\n(\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - \\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i}\n$$\n分母中包含杠杆值 $h_{ii} = \\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i$。所以，\n$$\n(\\mathbf{X}^{\\top}\\mathbf{X} - \\mathbf{x}_i \\mathbf{x}_i^{\\top})^{-1} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - h_{ii}}\n$$\n现在，将其代回 $\\hat{\\boldsymbol{\\beta}}_{(i)}$ 的表达式中：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\left[ (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}}{1 - h_{ii}} \\right] (\\mathbf{X}^{\\top}\\mathbf{y} - \\mathbf{x}_i y_i)\n$$\n展开此乘积得到四项：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\underbrace{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}}_{\\hat{\\boldsymbol{\\beta}}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i y_i + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\mathbf{x}_i^{\\top}\\overbrace{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{X}^{\\top}\\mathbf{y}}^{\\hat{\\boldsymbol{\\beta}}}}{1 - h_{ii}} - \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i\\overbrace{\\mathbf{x}_i^{\\top}(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i}^{h_{ii}} y_i}{1 - h_{ii}}\n$$\n认识到拟合值 $\\hat{y}_i = \\mathbf{x}_i^{\\top}\\hat{\\boldsymbol{\\beta}}$，第三项简化为：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i y_i + \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\hat{y}_i}{1 - h_{ii}} - \\frac{(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i h_{ii} y_i}{1 - h_{ii}}\n$$\n提出公因子 $(\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i$：\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( y_i - \\frac{\\hat{y}_i}{1 - h_{ii}} + \\frac{h_{ii} y_i}{1 - h_{ii}} \\right)\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i(1 - h_{ii}) - \\hat{y}_i + h_{ii} y_i}{1 - h_{ii}} \\right) = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i - y_i h_{ii} - \\hat{y}_i + h_{ii} y_i}{1 - h_{ii}} \\right)\n$$\n$$\n\\hat{\\boldsymbol{\\beta}}_{(i)} = \\hat{\\boldsymbol{\\beta}} - (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\left( \\frac{y_i - \\hat{y}_i}{1 - h_{ii}} \\right)\n$$\n使用残差的定义 $r_i = y_i - \\hat{y}_i$，我们得到系数变化的表达式：\n$$\n\\hat{\\boldsymbol{\\beta}} - \\hat{\\boldsymbol{\\beta}}_{(i)} = (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}}\n$$\n这个方程明确地量化了观测值 $i$ 的参数影响。现在我们将其代入库克距离的定义中：\n$$\nD_i = \\frac{1}{p\\hat{\\sigma}^{2}} \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}} \\right)^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X}) \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\frac{r_i}{1-h_{ii}} \\right)\n$$\n$$\nD_i = \\frac{1}{p\\hat{\\sigma}^{2}} \\left( \\frac{r_i}{1-h_{ii}} \\right)^2 \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\right)^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X}) \\left( (\\mathbf{X}^{\\top}\\mathbf{X})^{-1}\\mathbf{x}_i \\right)\n$$\n$$\nD_i = \\frac{r_i^2}{p\\hat{\\sigma}^{2}(1-h_{ii})^2} \\left( \\mathbf{x}_i^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} (\\mathbf{X}^{\\top}\\mathbf{X}) (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{x}_i \\right)\n$$\n括号中的表达式简化为 $\\mathbf{x}_i^{\\top} (\\mathbf{X}^{\\top}\\mathbf{X})^{-1} \\mathbf{x}_i = h_{ii}$。因此，我们得到库克距离的最终期望形式：\n$$\nD_i = \\frac{r_i^2}{p\\hat{\\sigma}^{2}} \\frac{h_{ii}}{(1-h_{ii})^2}\n$$\n这个结果优雅地表明，一个观测值的影响力 $D_i$ 是其残差平方（衡量其拟合得有多差）、其杠杆值（其在预测变量空间中与中心的距离）、参数数量以及整体模型误差的函数。\n\n### 数值计算\n对于一个特定患者，我们有以下给定值：\n- 参数数量 $p = 4$\n- 残差 $r_i = 0.85$\n- 杠杆值 $h_{ii} = 0.12$\n- 全模型残差方差估计 $\\hat{\\sigma}^{2} = 0.30$\n\n我们将这些值代入推导出的库克距离公式中：\n$$\nD_i = \\frac{(0.85)^2}{(4)(0.30)} \\frac{0.12}{(1 - 0.12)^2}\n$$\n首先，计算表达式的各个组成部分：\n- $r_i^2 = (0.85)^2 = 0.7225$\n- $p\\hat{\\sigma}^2 = 4 \\times 0.30 = 1.2$\n- $1 - h_{ii} = 1 - 0.12 = 0.88$\n- $(1 - h_{ii})^2 = (0.88)^2 = 0.7744$\n\n现在，将这些值代回 $D_i$ 的表达式中：\n$$\nD_i = \\frac{0.7225}{1.2} \\times \\frac{0.12}{0.7744}\n$$\n$$\nD_i \\approx (0.6020833...) \\times (0.1549651...)\n$$\n$$\nD_i \\approx 0.09330357...\n$$\n题目要求将最终答案四舍五入到四位有效数字。\n$$\nD_i \\approx 0.09330\n$$\n此观测值的库克距离约为 $0.09330$。",
            "answer": "$$\n\\boxed{0.09330}\n$$"
        }
    ]
}