{
    "hands_on_practices": [
        {
            "introduction": "Before applying any advanced metric, it is crucial to ensure the fundamental validity of the evaluation process itself. A common and critical error in validating dynamic models is \"data leakage,\" where information from the future is inadvertently used to make predictions about the present, leading to overly optimistic performance estimates. This exercise provides a foundational understanding of this pitfall by asking you to analytically derive the bias introduced by such leakage in a simple dynamic system, reinforcing the absolute necessity of temporally rigorous validation designs like rolling-origin evaluation .",
            "id": "3921440",
            "problem": "Consider a dynamic biomedical system in which a latent biomarker process evolves in discrete time. Let $X_t$ denote the biomarker at time $t$, and let the clinical outcome of interest at the next time point be $Y_{t+1}$. The biomarker follows an autoregressive process of order one,\n$$\nX_{t+1} = \\phi X_t + \\eta_{t+1},\n$$\nwhere $\\eta_{t+1}$ is a zero-mean innovation with variance $\\sigma_{\\eta}^{2}$ and is independent of $X_t$. The clinical outcome is generated according to\n$$\nY_{t+1} = \\beta X_{t+1} + \\epsilon_{t+1},\n$$\nwhere $\\epsilon_{t+1}$ is zero-mean noise with variance $\\sigma_{\\epsilon}^{2}$, independent of $X_t$ and $\\eta_{t+1}$. At prediction time $t$, the true information set available to the model is $\\mathcal{I}_t = \\{X_t\\}$.\n\nSuppose a practitioner mistakenly uses a feature engineered with future covariates (a data leakage), specifically the future biomarker $X_{t+1}$ itself, to estimate predictive performance under mean squared error. That is, they evaluate the model using the information set $\\mathcal{I}_{t+1}^{\\mathrm{leak}} = \\{X_{t+1}\\}$, which is unavailable at time $t$ in a real deployment. Assume models are optimally constructed under squared loss in the sense that they achieve the conditional expectation of the outcome given the available features.\n\nUsing only fundamental definitions of conditional expectation and variance under squared loss, and the independence relationships stated, derive a closed-form analytic expression for the bias in the estimated mean squared error introduced by this leakage, defined as\n$$\n\\mathrm{Bias} = \\mathbb{E}\\!\\left[\\mathrm{MSE}_{\\mathrm{leak}}\\right] - \\mathbb{E}\\!\\left[\\mathrm{MSE}_{\\mathrm{deploy}}\\right],\n$$\nwhere $\\mathrm{MSE}_{\\mathrm{leak}}$ is the mean squared error when evaluating with $\\mathcal{I}_{t+1}^{\\mathrm{leak}} = \\{X_{t+1}\\}$ and $\\mathrm{MSE}_{\\mathrm{deploy}}$ is the mean squared error when predicting at time $t$ with only $\\mathcal{I}_t = \\{X_t\\}$. Express the final answer as a symbolic expression in terms of $\\beta$ and $\\sigma_{\\eta}^{2}$. No rounding is required, and no physical units are needed.\n\nFinally, propose a scientifically sound predictive validation design that avoids such leakage in dynamic biomedical modeling, ensuring that training, feature engineering, and evaluation respect the time-indexed data availability.",
            "solution": "The problem requires the derivation of the bias in mean squared error estimation when future information is leaked into the feature set for a dynamic biomedical model. The bias is defined as the difference between the expected mean squared error (MSE) with leakage and the expected MSE in a proper deployment scenario. We will first derive the expressions for both expected MSE values and then compute their difference. Finally, a proper validation protocol will be described.\n\nThe system is defined by two equations:\nThe biomarker process: $X_{t+1} = \\phi X_t + \\eta_{t+1}$, where $\\mathbb{E}[\\eta_{t+1}] = 0$ and $\\mathrm{Var}(\\eta_{t+1}) = \\sigma_{\\eta}^{2}$.\nThe outcome process: $Y_{t+1} = \\beta X_{t+1} + \\epsilon_{t+1}$, where $\\mathbb{E}[\\epsilon_{t+1}] = 0$ and $\\mathrm{Var}(\\epsilon_{t+1}) = \\sigma_{\\epsilon}^{2}$.\nThe random variables $\\eta_{t+1}$ and $\\epsilon_{t+1}$ are independent of each other and of $X_t$.\n\nThe problem states that models are optimal under squared loss, meaning the prediction is the conditional expectation of the outcome given the available information.\n\nFirst, we calculate the expected MSE under data leakage, $\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{leak}}]$.\nIn this scenario, the practitioner incorrectly uses the information set $\\mathcal{I}_{t+1}^{\\mathrm{leak}} = \\{X_{t+1}\\}$. The optimal predictor is $\\hat{Y}_{t+1}^{\\mathrm{leak}} = \\mathbb{E}[Y_{t+1} | X_{t+1}]$.\nWe substitute the definition of $Y_{t+1}$:\n$$\n\\hat{Y}_{t+1}^{\\mathrm{leak}} = \\mathbb{E}[\\beta X_{t+1} + \\epsilon_{t+1} | X_{t+1}]\n$$\nUsing the linearity of conditional expectation:\n$$\n\\hat{Y}_{t+1}^{\\mathrm{leak}} = \\mathbb{E}[\\beta X_{t+1} | X_{t+1}] + \\mathbb{E}[\\epsilon_{t+1} | X_{t+1}]\n$$\nSince $X_{t+1}$ is given in the conditioning set, $\\mathbb{E}[\\beta X_{t+1} | X_{t+1}] = \\beta X_{t+1}$.\nThe noise term $\\epsilon_{t+1}$ is independent of $X_t$ and $\\eta_{t+1}$, and therefore independent of $X_{t+1} = \\phi X_t + \\eta_{t+1}$. Thus, conditioning on $X_{t+1}$ does not change the expectation of $\\epsilon_{t+1}$:\n$$\n\\mathbb{E}[\\epsilon_{t+1} | X_{t+1}] = \\mathbb{E}[\\epsilon_{t+1}] = 0\n$$\nSo, the predictor with leaked information is $\\hat{Y}_{t+1}^{\\mathrm{leak}} = \\beta X_{t+1}$.\n\nThe mean squared error in this case is $\\mathrm{MSE}_{\\mathrm{leak}} = (Y_{t+1} - \\hat{Y}_{t+1}^{\\mathrm{leak}})^2$. Its expectation is:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{leak}}] = \\mathbb{E}\\left[\\left( (\\beta X_{t+1} + \\epsilon_{t+1}) - \\beta X_{t+1} \\right)^2\\right] = \\mathbb{E}[\\epsilon_{t+1}^2]\n$$\nSince $\\epsilon_{t+1}$ has a mean of $0$, its expected square is equal to its variance:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{leak}}] = \\mathrm{Var}(\\epsilon_{t+1}) = \\sigma_{\\epsilon}^{2}\n$$\nThis result is intuitive: if the future biomarker $X_{t+1}$ is known, the only source of prediction error is the irreducible noise $\\epsilon_{t+1}$.\n\nNext, we calculate the expected MSE for a proper deployment scenario, $\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}]$.\nIn deployment at time $t$, the available information is correctly specified as $\\mathcal{I}_t = \\{X_t\\}$. The optimal predictor is $\\hat{Y}_{t+1}^{\\mathrm{deploy}} = \\mathbb{E}[Y_{t+1} | X_t]$.\nWe substitute the expressions for $Y_{t+1}$ and $X_{t+1}$:\n$$\n\\hat{Y}_{t+1}^{\\mathrm{deploy}} = \\mathbb{E}[\\beta X_{t+1} + \\epsilon_{t+1} | X_t] = \\mathbb{E}[\\beta(\\phi X_t + \\eta_{t+1}) + \\epsilon_{t+1} | X_t]\n$$\nUsing linearity of expectation and distributing the conditioning:\n$$\n\\hat{Y}_{t+1}^{\\mathrm{deploy}} = \\mathbb{E}[\\beta \\phi X_t | X_t] + \\mathbb{E}[\\beta \\eta_{t+1} | X_t] + \\mathbb{E}[\\epsilon_{t+1} | X_t]\n$$\nSince $X_t$ is given in the conditioning set, $\\mathbb{E}[\\beta \\phi X_t | X_t] = \\beta \\phi X_t$.\nThe innovation $\\eta_{t+1}$ is independent of $X_t$, so $\\mathbb{E}[\\beta \\eta_{t+1} | X_t] = \\beta \\mathbb{E}[\\eta_{t+1}] = \\beta \\cdot 0 = 0$.\nThe noise $\\epsilon_{t+1}$ is also independent of $X_t$, so $\\mathbb{E}[\\epsilon_{t+1} | X_t] = \\mathbb{E}[\\epsilon_{t+1}] = 0$.\nTherefore, the correct predictor is $\\hat{Y}_{t+1}^{\\mathrm{deploy}} = \\beta \\phi X_t$.\n\nThe mean squared error for deployment is $\\mathrm{MSE}_{\\mathrm{deploy}} = (Y_{t+1} - \\hat{Y}_{t+1}^{\\mathrm{deploy}})^2$. Its expectation is:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\mathbb{E}\\left[\\left( Y_{t+1} - \\beta \\phi X_t \\right)^2\\right]\n$$\nSubstitute $Y_{t+1} = \\beta(\\phi X_t + \\eta_{t+1}) + \\epsilon_{t+1}$:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\mathbb{E}\\left[\\left( \\beta(\\phi X_t + \\eta_{t+1}) + \\epsilon_{t+1} - \\beta \\phi X_t \\right)^2\\right]\n$$\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\mathbb{E}\\left[\\left( \\beta \\eta_{t+1} + \\epsilon_{t+1} \\right)^2\\right]\n$$\nExpanding the square:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\mathbb{E}[\\beta^2 \\eta_{t+1}^2 + 2\\beta \\eta_{t+1}\\epsilon_{t+1} + \\epsilon_{t+1}^2]\n$$\nBy linearity of expectation:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\beta^2 \\mathbb{E}[\\eta_{t+1}^2] + 2\\beta \\mathbb{E}[\\eta_{t+1}\\epsilon_{t+1}] + \\mathbb{E}[\\epsilon_{t+1}^2]\n$$\nWe know $\\mathbb{E}[\\eta_{t+1}^2] = \\mathrm{Var}(\\eta_{t+1}) = \\sigma_{\\eta}^2$ and $\\mathbb{E}[\\epsilon_{t+1}^2] = \\mathrm{Var}(\\epsilon_{t+1}) = \\sigma_{\\epsilon}^2$ as both are zero-mean. Since $\\eta_{t+1}$ and $\\epsilon_{t+1}$ are independent, the expectation of their product is the product of their expectations: $\\mathbb{E}[\\eta_{t+1}\\epsilon_{t+1}] = \\mathbb{E}[\\eta_{t+1}]\\mathbb{E}[\\epsilon_{t+1}] = 0 \\cdot 0 = 0$.\nSubstituting these values, we get:\n$$\n\\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}] = \\beta^2 \\sigma_{\\eta}^2 + 0 + \\sigma_{\\epsilon}^2 = \\beta^2 \\sigma_{\\eta}^2 + \\sigma_{\\epsilon}^2\n$$\nThe deployment error consists of two components: the irreducible error $\\sigma_{\\epsilon}^2$ and the error from the uncertainty in the future biomarker's evolution, $\\beta^2 \\sigma_{\\eta}^2$.\n\nFinally, we compute the bias in the estimated MSE due to leakage.\n$$\n\\mathrm{Bias} = \\mathbb{E}[\\mathrm{MSE}_{\\mathrm{leak}}] - \\mathbb{E}[\\mathrm{MSE}_{\\mathrm{deploy}}]\n$$\nSubstituting the derived expressions:\n$$\n\\mathrm{Bias} = \\sigma_{\\epsilon}^{2} - \\left(\\beta^2 \\sigma_{\\eta}^2 + \\sigma_{\\epsilon}^2\\right) = -\\beta^2 \\sigma_{\\eta}^2\n$$\nThe bias is negative, indicating that the leaked MSE estimate is optimistically biased, underestimating the true prediction error. The magnitude of this bias is proportional to the square of the biomarker's effect size, $\\beta^2$, and the variance of the biomarker's innovation process, $\\sigma_{\\eta}^2$.\n\nTo prevent such leakage, a scientifically sound predictive validation design for dynamic models must rigorously respect the temporal causality of the data. A standard and robust method is **rolling-origin validation** (also known as time-series cross-validation or walk-forward validation). This procedure mimics the real-world scenario where a model is periodically retrained as new data becomes available.\n\nThe steps are as follows:\n$1$. The dataset is ordered chronologically from time $t=1$ to $T$.\n$2$. An initial training set is defined from time $t=1$ to $t=T_0$, where $T_0 < T$.\n$3$. The model, including all feature engineering steps, is trained using only data from the interval $[1, T_0]$. Crucially, any features for predicting the outcome at time $t+1$ must be derived from information available at or before time $t$.\n$4$. The trained model is used to predict the outcome at the next time point, $Y_{T_0+1}$. The prediction error, e.g., $(Y_{T_0+1} - \\hat{Y}_{T_0+1})^2$, is calculated and stored.\n$5$. The time window is advanced by one step. The new data point at $T_0+1$ is incorporated into the training set, which now spans $[1, T_0+1]$ (an expanding window) or $[2, T_0+1]$ (a sliding window of fixed size).\n$6$. The model is retrained on this updated training set, and a prediction is made for $Y_{T_0+2}$. The error is recorded.\n$7$. This process of rolling the origin, retraining, and predicting the next point is repeated until predictions have been made for the entire desired evaluation period (e.g., up to time $T$).\n$8$. The overall model performance metric, such as the mean squared error, is then computed by averaging the stored prediction errors from each step.\n\nThis methodology ensures that at every point of evaluation, the model is only exposed to information that would have been available in the past, thereby preventing any form of contamination from future data and providing a realistic, unbiased estimate of the model's true deployment performance.",
            "answer": "$$\n\\boxed{- \\beta^{2} \\sigma_{\\eta}^{2}}\n$$"
        },
        {
            "introduction": "Once a proper validation framework is in place, we need robust metrics to evaluate the quality of a model's probabilistic forecasts. Rather than assessing a single point estimate, we must evaluate the entire predictive distribution. This practice introduces two of the most important tools for this task: the Logarithmic Score and the Continuous Ranked Probability Score (CRPS). By deriving these strictly proper scoring rules from first principles for a Gaussian forecast, you will gain a deep, practical understanding of how they penalize different aspects of predictive performance, such as calibration and sharpness .",
            "id": "3921410",
            "problem": "Consider a validated state-space model for glucose-insulin regulation in a person with Type 2 Diabetes, where the one-step-ahead predictive distribution for the capillary blood glucose measurement at time $t+1$, denoted $y_{t+1}$, is the marginal forecast $p(y_{t+1}\\mid \\mathcal{D}_t)$ obtained from the filtering distribution at time $t$ given the past data $\\mathcal{D}_t$. Assume the model yields a Gaussian forecast $y_{t+1}\\sim \\mathcal{N}(\\mu_{t+1\\mid t},\\sigma_{t+1\\mid t}^2)$ with $\\mu_{t+1\\mid t}=105$ and $\\sigma_{t+1\\mid t}=15$ (both in milligrams per deciliter, $\\mathrm{mg/dL}$). The realized measurement is $y_{t+1}=130$ $\\mathrm{mg/dL}$.\n\nBased on first principles of predictive validation using strictly proper scoring rules, define the logarithmic score as the natural logarithm of the predictive density evaluated at the observation, and define the Continuous Ranked Probability Score (CRPS) as the integrated squared difference between the predictive cumulative distribution function and the empirical cumulative distribution function of the realization. Starting from these core definitions and the properties of the Gaussian distribution, derive closed-form expressions for both the logarithmic score and the CRPS for a Gaussian predictive distribution in terms of $\\mu_{t+1\\mid t}$, $\\sigma_{t+1\\mid t}$, and $y_{t+1}$, and then evaluate them numerically for the values given above.\n\nExplain scientifically what aspects of predictive performance each score penalizes and how they complement each other in assessing calibration and sharpness for dynamic biomedical models.\n\nReport the numerical values of the logarithmic score in natural units of information (“nats”) and the CRPS in $\\mathrm{mg/dL}$, and round both to four significant figures. Provide your final numeric answers as a single row matrix with the first entry equal to the logarithmic score and the second entry equal to the CRPS.",
            "solution": "The objective is to derive and evaluate two strictly proper scoring rules, the logarithmic score ($S_{log}$) and the Continuous Ranked Probability Score ($S_{CRPS}$), for a given Gaussian predictive forecast and a realized observation. We will also provide a scientific interpretation of these scores.\n\nThe predictive distribution for the blood glucose level $y_{t+1}$ is given as a Gaussian distribution, $y_{t+1} \\sim \\mathcal{N}(\\mu, \\sigma^2)$, with mean $\\mu = \\mu_{t+1\\mid t} = 105$ and standard deviation $\\sigma = \\sigma_{t+1\\mid t} = 15$. The observed value is $y = y_{t+1} = 130$.\n\nFirst, we address the logarithmic score. The definition of the logarithmic score is the natural logarithm of the predictive probability density function (PDF), $p(y|\\mu, \\sigma^2)$, evaluated at the actual observation $y$. The PDF for a Gaussian distribution is:\n$$p(y|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)$$\nThe logarithmic score $S_{log}$ is therefore:\n$$S_{log} = \\ln(p(y|\\mu, \\sigma^2)) = \\ln\\left(\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y-\\mu)^2}{2\\sigma^2}\\right)\\right)$$\nUsing the properties of the logarithm, we can separate the terms to obtain the closed-form expression:\n$$S_{log} = \\ln\\left((2\\pi\\sigma^2)^{-1/2}\\right) - \\frac{(y-\\mu)^2}{2\\sigma^2} = -\\frac{1}{2}\\ln(2\\pi\\sigma^2) - \\frac{(y-\\mu)^2}{2\\sigma^2}$$\nThis can be further written as:\n$$S_{log} = -\\ln(\\sigma) - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\left(\\frac{y-\\mu}{\\sigma}\\right)^2$$\nNow, we substitute the given numerical values: $\\mu=105$, $\\sigma=15$, and $y=130$.\n$$S_{log} = -\\ln(15) - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\left(\\frac{130 - 105}{15}\\right)^2$$\n$$S_{log} = -\\ln(15) - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\left(\\frac{25}{15}\\right)^2 = -\\ln(15) - \\frac{1}{2}\\ln(2\\pi) - \\frac{1}{2}\\left(\\frac{5}{3}\\right)^2$$\n$$S_{log} \\approx -2.70805 - \\frac{1}{2}(1.83788) - \\frac{1}{2}(2.77778) \\approx -2.70805 - 0.91894 - 1.38889 \\approx -5.01588$$\nRounding to four significant figures, the logarithmic score is $-5.016$ nats.\n\nNext, we address the Continuous Ranked Probability Score ($S_{CRPS}$). The CRPS is defined as the integrated squared difference between the predictive cumulative distribution function (CDF), $F(z)$, and the empirical CDF of the observation, which is a Heaviside function $H(z-y)$ centered at $y$:\n$$S_{CRPS} = \\int_{-\\infty}^{\\infty} (F(z) - H(z-y))^2 dz$$\nAn alternative, and for this derivation more convenient, representation is $S_{CRPS} = E_F[|X-y|] - \\frac{1}{2} E_F[|X-X'|]$, where $X$ and $X'$ are independent random variables drawn from the predictive distribution $F$. For our Gaussian case, $X, X' \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n\nLet's derive each term. The second term, $\\frac{1}{2} E_F[|X-X'|]$, depends only on the spread of the predictive distribution. The difference of two independent Gaussian variables $X-X'$ follows a Gaussian distribution with mean $\\mu-\\mu=0$ and variance $\\sigma^2+\\sigma^2=2\\sigma^2$. Let $D = X-X' \\sim \\mathcal{N}(0, 2\\sigma^2)$. We need to compute $E[|D|]$, which is the mean of a folded normal distribution.\n$$E[|D|] = \\int_{-\\infty}^{\\infty} |d| \\frac{1}{\\sqrt{2\\pi(2\\sigma^2)}} \\exp\\left(-\\frac{d^2}{2(2\\sigma^2)}\\right) dd = 2 \\int_{0}^{\\infty} d \\frac{1}{2\\sigma\\sqrt{\\pi}} \\exp\\left(-\\frac{d^2}{4\\sigma^2}\\right) dd = \\frac{2\\sigma}{\\sqrt{\\pi}}$$\nThus, the second term is $\\frac{1}{2}E[|D|] = \\frac{\\sigma}{\\sqrt{\\pi}}$.\n\nThe first term, $E_F[|X-y|]$, depends on both the forecast and the observation. Let $z_{std} = (X-\\mu)/\\sigma$ be a standard normal variable, $z_{std} \\sim \\mathcal{N}(0, 1)$. Then $X = \\sigma z_{std} + \\mu$. The expectation becomes:\n$$E_F[|X-y|] = E[|\\sigma z_{std} + \\mu - y|] = \\sigma E[|z_{std} - \\frac{y-\\mu}{\\sigma}|]$$\nLet the standardized observation be $z = \\frac{y-\\mu}{\\sigma}$. We need to compute $E[|z_{std}-z|]$.\n$$E[|z_{std}-z|] = \\int_{-\\infty}^{\\infty} |x-z|\\phi(x)dx = \\int_{-\\infty}^{z} (z-x)\\phi(x)dx + \\int_{z}^{\\infty} (x-z)\\phi(x)dx$$\nwhere $\\phi(x)$ is the standard normal PDF. Using the facts that $\\int x\\phi(x)dx = -\\phi(x)$ and $\\int \\phi(x)dx = \\Phi(x)$, where $\\Phi(x)$ is the standard normal CDF, we get:\n$$E[|z_{std}-z|] = z\\Phi(z) + \\phi(z) - z(1-\\Phi(z)) + \\phi(z) = z(2\\Phi(z)-1) + 2\\phi(z)$$\nSubstituting this back, $E_F[|X-y|] = \\sigma \\left( z(2\\Phi(z)-1) + 2\\phi(z) \\right)$.\n\nCombining both terms, the closed-form expression for the CRPS of a Gaussian forecast is:\n$$S_{CRPS} = \\sigma \\left[ z(2\\Phi(z) - 1) + 2\\phi(z) - \\frac{1}{\\sqrt{\\pi}} \\right]$$\nwhere $z = \\frac{y-\\mu}{\\sigma}$. We now substitute the numerical values:\n$$z = \\frac{130 - 105}{15} = \\frac{25}{15} = \\frac{5}{3}$$\nWe need the values of the standard normal PDF $\\phi(z)$ and CDF $\\Phi(z)$ at $z=5/3 \\approx 1.6667$.\n$\\phi(5/3) = \\frac{1}{\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}(\\frac{5}{3})^2\\right) \\approx 0.099471$\n$\\Phi(5/3) \\approx 0.952210$\nSubstituting these into the CRPS formula:\n$$S_{CRPS} = 15 \\left[ \\frac{5}{3}(2(0.952210) - 1) + 2(0.099471) - \\frac{1}{\\sqrt{\\pi}} \\right]$$\n$$S_{CRPS} \\approx 15 \\left[ 1.6667(0.90442) + 0.198942 - \\frac{1}{1.77245} \\right]$$\n$$S_{CRPS} \\approx 15 [1.50737 + 0.19894 - 0.56419] \\approx 15 [1.14212] \\approx 17.1318$$\nRounding to four significant figures, the CRPS is $17.13$ $\\mathrm{mg/dL}$.\n\nFinally, a scientific explanation of the scores.\nThe logarithmic score, $S_{log} = \\ln(p(y))$, evaluates the predictive model based on the density it assigns to the single realized outcome. It severely penalizes forecasts that deem the observed outcome to be very unlikely (i.e., assign it a low probability density). A single observation in the extreme tail of a predictive distribution can result in a score of large negative magnitude, potentially dominating the average score over many forecasts. This makes it an excellent diagnostic for **calibration**, as a well-calibrated model should not be systematically \"surprised\" by outcomes. The score is composed of a term penalizing inaccuracy (distance of $y$ from $\\mu$) and a term penalizing lack of sharpness (large $\\sigma$), but its extreme sensitivity to tail performance makes it a sharp tool for identifying miscalibration.\n\nThe Continuous Ranked Probability Score, $S_{CRPS} = \\int (F(z) - H(z-y))^2 dz$, evaluates the entire predictive distribution against the observation. It generalizes the mean absolute error; should the forecast be a deterministic point estimate $\\mu$ (i.e., $F(z)$ is a step function at $\\mu$), the CRPS reduces to $|y-\\mu|$. CRPS is less sensitive to single unlikely events than the log score and provides a more robust measure of overall performance. Its decomposition into $E|X-y| - \\frac{1}{2} E|X-X'|$ reveals that it rewards **calibration** and **accuracy** (by minimizing the expected distance between the prediction and a draw from the forecast distribution) while also rewarding **sharpness** (the second term is a penalty for the spread of the distribution; a smaller spread leads to a smaller penalty). An important practical advantage is that CRPS is in the units of the measurement itself ($\\mathrm{mg/dL}$ in this case), making it directly interpretable as a generalized error magnitude.\n\nIn biomedical modeling, using both scores is complementary. CRPS provides a robust, interpretable summary of overall predictive performance, balancing the need for forecasts to be both centered on the outcome (accurate) and concentrated (sharp). The logarithmic score serves as a more stringent test of probabilistic calibration, flagging models that fail to assign appropriate probabilities across the full range of possible outcomes, which is critical for risk assessment and decision-making under uncertainty.\n\nThe calculated scores, rounded to four significant figures, are:\nLogarithmic score: $-5.016$ nats.\nCRPS: $17.13$ $\\mathrm{mg/dL}$.",
            "answer": "$$\\boxed{\\begin{pmatrix} -5.016 & 17.13 \\end{pmatrix}}$$"
        },
        {
            "introduction": "A model's predictive uncertainty is not arbitrary; it often stems directly from the uncertainty in its calibrated parameter estimates. This final practice explores the crucial link between parameter uncertainty and predictive variance, a key aspect of mechanistic model validation. Using local sensitivity analysis, you will derive how the covariance structure of model parameters—specifically, their correlations—propagates to the final uncertainty of the model's output, and under what conditions ignoring these correlations can lead to a dangerous misestimation of predictive confidence .",
            "id": "3921403",
            "problem": "Consider a dynamic biomedical systems model for the clearance of a circulating biomarker in a single well-mixed compartment with volume $V$ and first-order elimination rate constant $k$. The state $X(t)$ denotes the total biomarker amount and obeys the ordinary differential equation $dX/dt=-k\\,X$ with initial condition $X(0)=X_{0}$. The observable concentration is $y(t)=X(t)/V$. The parameter vector is $\\theta=\\begin{pmatrix}k & V\\end{pmatrix}^{\\top}$, and calibration to independent training data yields a joint Gaussian (normal) posterior for $\\theta$ with mean $\\hat{\\theta}=\\begin{pmatrix}\\hat{k} & \\hat{V}\\end{pmatrix}^{\\top}$ and covariance matrix $\\Sigma\\in\\mathbb{R}^{2\\times 2}$ that has marginal standard deviations $\\sigma_{k}>0$, $\\sigma_{V}>0$ and correlation coefficient $\\rho\\in[-1,1]$, that is\n$$\n\\Sigma=\\begin{pmatrix}\n\\sigma_{k}^{2} & \\rho\\,\\sigma_{k}\\sigma_{V} \\\\\n\\rho\\,\\sigma_{k}\\sigma_{V} & \\sigma_{V}^{2}\n\\end{pmatrix}.\n$$\nPredictive validation of the model at a future time $t>0$ uses the local (first-order) propagation of parametric uncertainty to approximate the predictive variance of $y(t)$ under $\\theta\\sim\\mathcal{N}(\\hat{\\theta},\\Sigma)$. Starting from a first-order Taylor expansion of $y(t;\\theta)$ around $\\hat{\\theta}$, derive the linearized predictive variance at time $t$ in terms of the local sensitivity vector $s(t)=\\left(\\frac{\\partial y}{\\partial k}(t;\\hat{\\theta}),\\,\\frac{\\partial y}{\\partial V}(t;\\hat{\\theta})\\right)^{\\top}$ and the covariance matrix $\\Sigma$.\n\nThen, specialize to the model $y(t)=\\frac{X_{0}}{V}\\,\\exp(-k\\,t)$ and explicitly compute the sensitivities $s_{k}(t)=\\frac{\\partial y}{\\partial k}(t;\\hat{\\theta})$ and $s_{V}(t)=\\frac{\\partial y}{\\partial V}(t;\\hat{\\theta})$ evaluated at $\\hat{\\theta}=(\\hat{k},\\hat{V})^{\\top}$. Using these, write down the linearized predictive variance that includes the correlation $\\rho$ and the variance computed by ignoring correlations (i.e., using only the diagonal of $\\Sigma$). Define the misestimation factor as the ratio\n$$\nF(t)\\equiv\\frac{\\text{variance ignoring correlations}}{\\text{variance including correlations}},\n$$\nand derive a closed-form expression for $F(t)$ in terms of $t$, $\\hat{V}$, $\\sigma_{k}$, $\\sigma_{V}$, and $\\rho$.\n\nFinally, using your expression and first principles about covariances, determine the conditions on $\\rho$ and $t$ under which ignoring correlations strictly overestimates versus strictly underestimates the predictive variance for this model. Explain the role of the signs and magnitudes of the sensitivity components in your conclusion. Provide your final answer as the closed-form expression for $F(t)$ (unitless). Do not provide any numerical approximations.",
            "solution": "The model output $y(t)$ is a function of the parameter vector $\\theta$, denoted $y(t; \\theta)$. For predictive validation, we approximate the variance of $y(t; \\theta)$ when $\\theta$ is a random variable with distribution $\\mathcal{N}(\\hat{\\theta}, \\Sigma)$. A first-order Taylor series expansion of $y(t; \\theta)$ around the mean $\\hat{\\theta}$ gives:\n$$\ny(t; \\theta) \\approx y(t; \\hat{\\theta}) + \\nabla_{\\theta} y(t; \\hat{\\theta})^{\\top} (\\theta - \\hat{\\theta})\n$$\nwhere $\\nabla_{\\theta} y(t; \\hat{\\theta})$ is the gradient of $y$ with respect to $\\theta$, evaluated at $\\hat{\\theta}$. This gradient is the sensitivity vector $s(t) = \\left( \\frac{\\partial y}{\\partial k}(t;\\hat{\\theta}), \\frac{\\partial y}{\\partial V}(t;\\hat{\\theta}) \\right)^{\\top}$. So, we can write:\n$$\ny(t; \\theta) \\approx y(t; \\hat{\\theta}) + s(t)^{\\top} (\\theta - \\hat{\\theta})\n$$\nThe predictive variance, denoted $\\text{Var}[y(t)]$, is the variance of this expression. Since $y(t; \\hat{\\theta})$ and $s(t)$ are constants with respect to the random variable $\\theta$, the variance is:\n$$\n\\text{Var}[y(t)] \\approx \\text{Var}[y(t; \\hat{\\theta}) + s(t)^{\\top} (\\theta - \\hat{\\theta})] = \\text{Var}[s(t)^{\\top} (\\theta - \\hat{\\theta})]\n$$\nUsing the property of variance for a linear transformation of a random vector, $\\text{Var}[A\\mathbf{Z}] = A \\text{Var}[\\mathbf{Z}] A^{\\top}$, with $A = s(t)^{\\top}$ and $\\mathbf{Z} = \\theta - \\hat{\\theta}$, we get:\n$$\n\\text{Var}[y(t)] \\approx s(t)^{\\top} \\text{Var}[\\theta - \\hat{\\theta}] s(t)\n$$\nSince $\\text{Var}[\\theta - \\hat{\\theta}] = \\text{Var}[\\theta] = \\Sigma$, the general expression for the linearized predictive variance is:\n$$\n\\text{Var}[y(t)] \\approx s(t)^{\\top} \\Sigma s(t)\n$$\nThis completes the first part of the task.\n\nNext, we specialize to the model $y(t) = \\frac{X_{0}}{V}\\,\\exp(-k\\,t)$. We solve the differential equation $\\frac{dX}{dt} = -k\\,X$ with $X(0)=X_0$, which gives $X(t) = X_0 \\exp(-kt)$. The observable is $y(t) = \\frac{X(t)}{V} = \\frac{X_0}{V}\\,\\exp(-k\\,t)$. We now compute the components of the sensitivity vector $s(t)$ by taking partial derivatives with respect to $k$ and $V$, and evaluating them at $\\hat{\\theta} = (\\hat{k}, \\hat{V})^{\\top}$.\n\nThe sensitivity with respect to $k$ is:\n$$\ns_k(t) = \\frac{\\partial y}{\\partial k}(t;\\hat{\\theta}) = \\left. \\frac{\\partial}{\\partial k} \\left( \\frac{X_0}{V}\\,\\exp(-k\\,t) \\right) \\right|_{\\theta=\\hat{\\theta}} = \\left. \\frac{X_0}{V}\\,\\exp(-k\\,t) (-t) \\right|_{\\theta=\\hat{\\theta}} = -t \\frac{X_0}{\\hat{V}}\\,\\exp(-\\hat{k}\\,t)\n$$\nThe sensitivity with respect to $V$ is:\n$$\ns_V(t) = \\frac{\\partial y}{\\partial V}(t;\\hat{\\theta}) = \\left. \\frac{\\partial}{\\partial V} \\left( \\frac{X_0}{V}\\,\\exp(-k\\,t) \\right) \\right|_{\\theta=\\hat{\\theta}} = \\left. X_0\\,\\exp(-k\\,t) \\left( -\\frac{1}{V^2} \\right) \\right|_{\\theta=\\hat{\\theta}} = -\\frac{1}{\\hat{V}} \\left( \\frac{X_0}{\\hat{V}}\\,\\exp(-\\hat{k}\\,t) \\right)\n$$\nLet's denote the model prediction at the mean parameters as $y(t;\\hat{\\theta}) = \\frac{X_0}{\\hat{V}}\\,\\exp(-\\hat{k}\\,t)$. The sensitivities can be written compactly as $s_k(t) = -t \\cdot y(t;\\hat{\\theta})$ and $s_V(t) = -\\frac{1}{\\hat{V}} \\cdot y(t;\\hat{\\theta})$.\n\nNow, we compute the linearized predictive variance including correlations, which we denote $\\text{Var}_{\\text{corr}}(y(t))$:\n$$\n\\text{Var}_{\\text{corr}}(y(t)) = s(t)^{\\top} \\Sigma s(t) = \\begin{pmatrix} s_k(t) & s_V(t) \\end{pmatrix} \\begin{pmatrix} \\sigma_{k}^{2} & \\rho\\sigma_{k}\\sigma_{V} \\\\ \\rho\\sigma_{k}\\sigma_{V} & \\sigma_{V}^{2} \\end{pmatrix} \\begin{pmatrix} s_k(t) \\\\ s_V(t) \\end{pmatrix}\n$$\n$$\n\\text{Var}_{\\text{corr}}(y(t)) = s_k(t)^2 \\sigma_k^2 + s_V(t)^2 \\sigma_V^2 + 2 s_k(t) s_V(t) \\rho \\sigma_k \\sigma_V\n$$\nThe variance computed by ignoring correlations, $\\text{Var}_{\\text{no-corr}}(y(t))$, uses only the diagonal elements of $\\Sigma$:\n$$\n\\text{Var}_{\\text{no-corr}}(y(t)) = s_k(t)^2 \\sigma_k^2 + s_V(t)^2 \\sigma_V^2\n$$\nThe misestimation factor $F(t)$ is the ratio of these two quantities:\n$$\nF(t) = \\frac{\\text{Var}_{\\text{no-corr}}(y(t))}{\\text{Var}_{\\text{corr}}(y(t))} = \\frac{s_k(t)^2 \\sigma_k^2 + s_V(t)^2 \\sigma_V^2}{s_k(t)^2 \\sigma_k^2 + s_V(t)^2 \\sigma_V^2 + 2 s_k(t) s_V(t) \\rho \\sigma_k \\sigma_V}\n$$\nTo obtain the closed-form expression for $F(t)$, we substitute the expressions for the sensitivities. The term $y(t;\\hat{\\theta})^2$ will be a common factor.\n$s_k(t)^2 = (-t \\cdot y(t;\\hat{\\theta}))^2 = t^2 \\cdot y(t;\\hat{\\theta})^2$\n$s_V(t)^2 = (-\\frac{1}{\\hat{V}} \\cdot y(t;\\hat{\\theta}))^2 = \\frac{1}{\\hat{V}^2} \\cdot y(t;\\hat{\\theta})^2$\n$s_k(t)s_V(t) = (-t \\cdot y(t;\\hat{\\theta}))(-\\frac{1}{\\hat{V}} \\cdot y(t;\\hat{\\theta})) = \\frac{t}{\\hat{V}} \\cdot y(t;\\hat{\\theta})^2$\nSubstituting these into the expression for $F(t)$:\n$$\nF(t) = \\frac{ (t^2 \\sigma_k^2 + \\frac{1}{\\hat{V}^2} \\sigma_V^2) y(t;\\hat{\\theta})^2 }{ (t^2 \\sigma_k^2 + \\frac{1}{\\hat{V}^2} \\sigma_V^2 + 2 \\frac{t}{\\hat{V}} \\rho \\sigma_k \\sigma_V) y(t;\\hat{\\theta})^2 }\n$$\nAssuming $y(t;\\hat{\\theta}) \\neq 0$ (which is true for any finite $t$ since $X_0 > 0, \\hat{V} > 0$), we can cancel this term:\n$$\nF(t) = \\frac{t^2 \\sigma_k^2 + \\frac{\\sigma_V^2}{\\hat{V}^2}}{t^2 \\sigma_k^2 + \\frac{\\sigma_V^2}{\\hat{V}^2} + 2 \\rho \\frac{t \\sigma_k \\sigma_V}{\\hat{V}}}\n$$\nThis can be written as:\n$$\nF(t) = \\frac{t^2\\sigma_{k}^{2} + \\hat{V}^{-2}\\sigma_{V}^{2}}{t^2\\sigma_{k}^{2} + \\hat{V}^{-2}\\sigma_{V}^{2} + 2 \\rho t \\hat{V}^{-1} \\sigma_{k} \\sigma_{V}}\n$$\nThis is the required closed-form expression for $F(t)$.\n\nFinally, we analyze the conditions for over- and underestimation.\nIgnoring correlations leads to an **overestimation** of the predictive variance when $\\text{Var}_{\\text{no-corr}}(y(t)) > \\text{Var}_{\\text{corr}}(y(t))$, which corresponds to $F(t) > 1$. This inequality holds if the denominator is smaller than the numerator. Given that the numerator is $t^2\\sigma_{k}^{2} + \\hat{V}^{-2}\\sigma_{V}^{2}$, which is strictly positive for $t>0$, the condition $F(t)>1$ requires the term $2 \\rho t \\hat{V}^{-1} \\sigma_{k} \\sigma_{V}$ in the denominator to be negative.\n$$\n2 \\rho t \\hat{V}^{-1} \\sigma_{k} \\sigma_{V} < 0\n$$\nSince $t>0$, $\\hat{V}>0$, $\\sigma_k > 0$, and $\\sigma_V > 0$, the sign of this term is determined solely by the sign of $\\rho$. Thus, overestimation occurs when $\\rho < 0$.\n\nIgnoring correlations leads to an **underestimation** of the predictive variance when $\\text{Var}_{\\text{no-corr}}(y(t)) < \\text{Var}_{\\text{corr}}(y(t))$, which corresponds to $F(t) < 1$. This requires the term $2 \\rho t \\hat{V}^{-1} \\sigma_{k} \\sigma_{V}$ to be positive. This occurs when $\\rho > 0$.\n\nThe condition for over/underestimation does not depend on the magnitude of $t$, only that $t>0$.\n\nThe role of the sensitivity components is crucial. The term added to the variance due to correlation is $2 \\cdot \\text{Cov}(k,V) \\cdot s_k(t) \\cdot s_V(t)$. We have $\\text{Cov}(k,V) = \\rho \\sigma_k \\sigma_V$. The product of the sensitivities is $s_k(t) s_V(t) = (-t \\cdot y(t;\\hat{\\theta}))(-\\frac{1}{\\hat{V}} \\cdot y(t;\\hat{\\theta})) = \\frac{t}{\\hat{V}} y(t;\\hat{\\theta})^2$. For $t>0$, this product is strictly positive.\nThis means that the sign of the covariance contribution to the total variance is the same as the sign of $\\rho$. This is because both an increase in the elimination rate $k$ and an increase in the volume of distribution $V$ lead to a decrease in the biomarker concentration $y(t)$ for $t>0$. Consequently, both sensitivities $s_k(t)$ and $s_V(t)$ are negative. When two parameters affect the output in the same direction (i.e., their sensitivities have the same sign), a positive correlation between them will lead to an increased predictive variance, and a negative correlation will lead to a decreased predictive variance. Ignoring a positive correlation $(\\rho > 0)$ thus leads to underestimation, and ignoring a negative correlation $(\\rho < 0)$ leads to overestimation.",
            "answer": "$$\n\\boxed{\\frac{t^{2}\\sigma_{k}^{2} + \\hat{V}^{-2}\\sigma_{V}^{2}}{t^{2}\\sigma_{k}^{2} + \\hat{V}^{-2}\\sigma_{V}^{2} + 2 \\rho t \\hat{V}^{-1} \\sigma_{k} \\sigma_{V}}}\n$$"
        }
    ]
}