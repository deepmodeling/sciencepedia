{
    "hands_on_practices": [
        {
            "introduction": "The Rescorla-Wagner model provides a powerful mathematical framework for understanding classical conditioning. This first exercise  moves beyond single-cue learning to a more realistic scenario involving a compound stimulus, where multiple cues are present simultaneously. By working through this calculation, you will see how the model formalizes the idea of competition between cues, as they vie for limited associative strength based on their individual salience and a shared prediction error.",
            "id": "4721764",
            "problem": "A therapist implementing exposure-based treatment for panic disorder uses a formal associative learning framework to track how a patient's conditioned responses change when confronted with compound cues that have previously acquired predictive value for interoceptive distress. Consider a single reinforced compound trial in which two cues, $A$ (an interoceptive sensation) and $B$ (an exteroceptive context), are presented together and followed by a panic response treated as the unconditioned stimulus. The associative strengths of the cues prior to the trial are $V_{A}=0.4$ and $V_{B}=0.2$. The therapist assigns cue-specific salience parameters $\\alpha_{A}=0.3$ and $\\alpha_{B}=0.1$, and uses a common learning rate parameter $\\beta=0.5$ for the unconditioned stimulus. The magnitude of reinforcement for the unconditioned stimulus on the trial is $\\lambda=1$. Using the principles of prediction error and the Rescorla–Wagner associative learning framework, derive the update rule from first principles and compute the associative strength changes $\\Delta V_{A}$ and $\\Delta V_{B}$ for this compound trial. Express your final answer for $(\\Delta V_{A}, \\Delta V_{B})$ as a row matrix. No rounding is required.",
            "solution": "The problem statement is evaluated as scientifically valid. It is grounded in the well-established Rescorla-Wagner model of associative learning, a cornerstone of learning theory with direct applications in clinical psychology and computational psychiatry. The problem is well-posed, providing all necessary parameters ($\\alpha_A$, $\\alpha_B$, $\\beta$, $\\lambda$, $V_A$, $V_B$) to compute a unique solution. The terminology is objective and formal, consistent with the scientific domain. Therefore, a solution can be derived.\n\nThe Rescorla-Wagner model posits that the change in associative strength ($\\Delta V$) of a stimulus on a learning trial is determined by the discrepancy between the actual outcome and the expected outcome. This discrepancy is termed the prediction error. The update rule for the associative strength of a single cue $i$, present on a given trial, is derived from this principle.\n\nThe change in associative strength, $\\Delta V_i$, is proportional to the salience of the cue $i$, denoted by $\\alpha_i$, and the learning rate parameter associated with the unconditioned stimulus (US), denoted by $\\beta$. Crucially, this change is driven by the prediction error term, $(\\lambda - V_{total})$, where $\\lambda$ is the asymptotic level of associative strength that the US can support, and $V_{total}$ is the sum of the associative strengths of all cues present on that trial.\n\nThe general form of the Rescorla-Wagner update rule for a cue $i$ is:\n$$\n\\Delta V_i = \\alpha_i \\beta (\\lambda - V_{total})\n$$\n\nIn this problem, we are considering a compound trial where two cues, $A$ and $B$, are presented simultaneously. Therefore, the total associative strength on this trial, $V_{total}$, is the sum of the individual strengths of the cues present:\n$$\nV_{total} = V_A + V_B\n$$\nThis sum represents the total expectation of the US occurring. The reinforcement is given by $\\lambda$, the magnitude of the panic response.\n\nSubstituting the expression for $V_{total}$ into the general update rule, we obtain the specific equations for the change in associative strength for cue $A$ ($\\Delta V_A$) and cue $B$ ($\\Delta V_B$):\n$$\n\\Delta V_A = \\alpha_A \\beta (\\lambda - (V_A + V_B))\n$$\n$$\n\\Delta V_B = \\alpha_B \\beta (\\lambda - (V_A + V_B))\n$$\nNote that the prediction error term, $(\\lambda - (V_A + V_B))$, is the same for both cues, as they are part of the same compound stimulus event. The differential change in their strengths arises from their different salience values, $\\alpha_A$ and $\\alpha_B$.\n\nThe problem provides the following values:\n- Initial associative strength of cue $A$: $V_A = 0.4$\n- Initial associative strength of cue $B$: $V_B = 0.2$\n- Salience of cue $A$: $\\alpha_A = 0.3$\n- Salience of cue $B$: $\\alpha_B = 0.1$\n- Learning rate for the US: $\\beta = 0.5$\n- Magnitude of reinforcement: $\\lambda = 1$\n\nFirst, we compute the total associative strength of the compound cue $AB$ before the reinforced trial:\n$$\nV_{total} = V_A + V_B = 0.4 + 0.2 = 0.6\n$$\nNext, we calculate the prediction error:\n$$\n\\text{Prediction Error} = \\lambda - V_{total} = 1 - 0.6 = 0.4\n$$\nA positive prediction error indicates that the outcome was stronger than expected, leading to an increase in the associative strengths of the cues present (excitatory conditioning).\n\nNow, we can compute the change in associative strength for each cue.\nFor cue $A$:\n$$\n\\Delta V_A = \\alpha_A \\beta (\\lambda - V_{total}) = (0.3)(0.5)(0.4)\n$$\n$$\n\\Delta V_A = (0.15)(0.4) = 0.06\n$$\nFor cue $B$:\n$$\n\\Delta V_B = \\alpha_B \\beta (\\lambda - V_{total}) = (0.1)(0.5)(0.4)\n$$\n$$\n\\Delta V_B = (0.05)(0.4) = 0.02\n$$\nThus, the changes in associative strength for the compound trial are $\\Delta V_A = 0.06$ and $\\Delta V_B = 0.02$. The results are presented as a row matrix $(\\Delta V_A, \\Delta V_B)$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.06 & 0.02\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Building on the foundational mechanics of associative learning, this practice applies the Rescorla-Wagner model to a complex clinical challenge in the treatment of PTSD. Here, you will analyze the phenomenon of \"blocking,\" where a well-established predictor prevents learning about a new cue, and then evaluate therapeutic strategies designed to \"unblock\" or enable new learning. This exercise  bridges theory and practice, demonstrating how computational models can be used to predict treatment obstacles and design more effective exposure-based interventions.",
            "id": "4721800",
            "problem": "A patient with Posttraumatic Stress Disorder (PTSD) reports intense distress when exposed to urban emergency reminders. Three trauma-related conditioned stimuli (CSs) are identified: a siren sound ($A$), the smell of diesel exhaust ($B$), and flashing blue lights ($C$). The unconditioned stimulus (US) is the therapist-guided imaginal replay of the worst moment of the index trauma. The therapist uses controlled exposure sessions to systematically alter the intensity of the imaginal US and the composition of CS compounds to study and leverage associative learning mechanisms.\n\nHistorical learning prior to therapy has produced a dominant association between the siren ($A$) and the trauma memory, such that the associative strength of $A$ is near asymptote on a normalized scale, with $V_A \\approx 1.0$ when the imaginal US intensity is $\\lambda = 1.0$. Other cues have negligible associative strength at baseline, $V_B \\approx 0$ and $V_C \\approx 0$. Salience parameters for the CSs are stable across sessions, with $A$ moderately salient ($\\alpha_A = 0.4$), $B$ less salient ($\\alpha_B = 0.3$), and $C$ least salient ($\\alpha_C = 0.2$). The US processing parameter is set by session pacing and is constant across sessions ($\\beta_{\\mathrm{US}} = 0.5$).\n\nAcross four phases, the therapist plans the following manipulations:\n\n- Phase $1$: Ten compound sessions present $A$ and $B$ together ($AB$) while evoking the imaginal US at the same intensity as baseline, $\\lambda = 1.0$.\n- Phase $2$: Ten compound sessions present $A$ and $C$ together ($AC$) while intentionally increasing the imaginal US intensity to $\\lambda' = 1.4$ to induce surprise.\n- Phase $3$: Extinction of $A$ is conducted by presenting $A$ repeatedly without the US until $V_A$ decreases to approximately $0.6$.\n- Phase $4$: Several sessions present $B$ with the US in isolation (no $A$ or $C$ present), at $\\lambda = 1.0$.\n\nUsing prediction-error driven associative learning principles applicable to classical conditioning in psychiatry, identify which cues will exhibit blocking during Phase $1$ and specify the single manipulation among the described phases that most directly unblocks learning about $B$ (i.e., produces a positive change in $V_B$ attributable to increased prediction error). Choose the option that correctly states the blocking outcomes in Phase $1$ and the most effective unblocking design for $B$.\n\nA. In Phase $1$, $B$ will be blocked by $A$ because the compound $AB$ does not increase surprise at $\\lambda = 1.0$ when $V_A \\approx 1.0$. In Phase $2$, $C$ will acquire associative strength because increasing the US to $\\lambda' = 1.4$ creates prediction error despite $A$’s dominance. The most direct unblocking for $B$ is achieved by first reducing $V_A$ via extinction (Phase $3$) and then presenting $B$ with the US in isolation (Phase $4$), so that $\\sum V$ during $B$–US trials is low and $V_B$ increases.\n\nB. In Phase $1$, $B$ will not be blocked because $\\alpha_B = 0.3$ is sufficient for learning even if $A$ is dominant. Continued $AB$ sessions at $\\lambda = 1.0$ will gradually un-block $B$ without additional manipulations, and increasing the US in Phase $2$ is unnecessary.\n\nC. In Phase $1$, both $B$ and $C$ will be blocked whenever $A$ is present, regardless of US intensity changes. To un-block $B$, introduce a novel cue $D$ in $ABD$ compounds, because adding novelty to the compound increases learning about $B$ more than removing $A$ or changing $\\lambda$.\n\nD. In Phase $1$, $B$ will be blocked, and in Phase $2$, $C$ will also be blocked because $A$’s associative strength remains high. The optimal unblocking for $B$ is to reduce the imaginal US intensity below baseline (e.g., to $\\lambda = 0.6$) so that $B$ can learn without overwhelming fear responses; extinguishing $A$ is not necessary.",
            "solution": "The problem is governed by the principles of prediction-error driven associative learning, as formalized by the Rescorla-Wagner model. The change in associative strength, $\\Delta V_i$, of a conditioned stimulus (CS) $i$ on any given learning trial is determined by the equation:\n$$ \\Delta V_i = \\alpha_i \\beta (\\lambda - V_{total}) $$\nwhere $\\alpha_i$ is the salience of CS $i$, $\\beta$ is a rate parameter related to the unconditioned stimulus (US), $\\lambda$ is the magnitude of the US, and $V_{total}$ is the sum of the associative strengths of all CSs present on that trial, $\\sum V_j$. The term $(\\lambda - V_{total})$ represents the prediction error.\n\nThe problem provides the following initial conditions and parameters:\n- Initial associative strengths: $V_A \\approx 1.0$, $V_B \\approx 0$, $V_C \\approx 0$.\n- US magnitude at baseline: $\\lambda = 1.0$.\n- Salience parameters: $\\alpha_A = 0.4$, $\\alpha_B = 0.3$, $\\alpha_C = 0.2$.\n- US processing parameter: $\\beta_{\\mathrm{US}} = 0.5$.\n\n**Analysis of Phase $1$: Blocking**\nIn Phase $1$, the compound stimulus $AB$ is presented with the US at an intensity of $\\lambda = 1.0$. At the beginning of this phase, the total associative strength of the compound is $V_{total} = V_A + V_B \\approx 1.0 + 0 = 1.0$.\nThe prediction error is therefore:\n$$ \\lambda - V_{total} \\approx 1.0 - 1.0 = 0 $$\nThe change in associative strength for cue $B$ on the first trial of this phase is:\n$$ \\Delta V_B = \\alpha_B \\beta (\\lambda - (V_A + V_B)) \\approx (0.3)(0.5)(1.0 - (1.0 + 0)) = 0 $$\nSince the prediction error is approximately $0$, no new learning will occur for cue $B$. The pre-existing associative strength of cue $A$ fully predicts the US, thereby \"blocking\" the acquisition of associative strength by cue $B$. This confirms that $B$ will be blocked by $A$ in Phase $1$.\n\n**Analysis of Unblocking Mechanisms**\nThe core principle of unblocking is to create a non-zero prediction error in a situation where blocking would otherwise occur. The problem describes two distinct methods for achieving this.\n\n1.  **Increasing US Magnitude (Phase $2$):** In Phase $2$, the compound $AC$ is paired with a US of increased intensity, $\\lambda' = 1.4$. The initial total associative strength is $V_{total} = V_A + V_C \\approx 1.0 + 0 = 1.0$. The prediction error becomes:\n    $$ \\lambda' - V_{total} \\approx 1.4 - 1.0 = 0.4 $$\n    This positive prediction error (\"surprise\") drives new learning for all present cues. For cue $C$, the change in strength is:\n    $$ \\Delta V_C = \\alpha_C \\beta (\\lambda' - (V_A + V_C)) \\approx (0.2)(0.5)(0.4) = 0.04 $$\n    Thus, $V_C$ will increase. This demonstrates unblocking by increasing the US magnitude.\n\n2.  **Decreasing the Blocker's Strength (Phases $3$ and $4$):** This strategy aims to enable learning about cue $B$.\n    - **Phase $3$ (Extinction of $A$):** Cue $A$ is presented alone without the US ($\\lambda = 0$). The prediction error is $\\lambda - V_A = 0 - V_A$. This negative prediction error causes $V_A$ to decrease. The phase proceeds until $V_A$ is reduced to approximately $0.6$.\n    - **Phase $4$ (Acquisition for $B$):** Cue $B$ is then presented alone with the US at the original intensity, $\\lambda = 1.0$. At the start of this phase, $V_B \\approx 0$. The total associative strength is simply $V_B$. The prediction error is:\n      $$ \\lambda - V_B \\approx 1.0 - 0 = 1.0 $$\n      The change in associative strength for $B$ is:\n      $$ \\Delta V_B = \\alpha_B \\beta (\\lambda - V_B) \\approx (0.3)(0.5)(1.0 - 0) = 0.15 $$\n      This large positive change shows that cue $B$ will now readily acquire associative strength. This procedure, comprising the extinction of the blocker followed by conditioning trials with the target cue, is an effective method to overcome blocking and allow the previously blocked cue to gain strength by ensuring a large prediction error during its pairings with the US.\n\nThe question asks to identify the blocking in Phase $1$ and the manipulation that most directly unblocks learning about $B$. Based on our analysis, $B$ is blocked in Phase $1$. The manipulation to unblock learning for $B$ described in the problem is the sequence of Phase $3$ followed by Phase $4$.\n\n**Evaluation of Options:**\n\n-   **A.** This option states that in Phase $1$, $B$ is blocked by $A$ because the compound $AB$ does not generate surprise. This is correct. It correctly explains that in Phase $2$, increasing $\\lambda$ to $1.4$ unblocks learning for $C$. Finally, it accurately describes the logic of the Phase $3$ and Phase $4$ procedure as the direct method for unblocking $B$, by reducing $V_A$ and then pairing $B$ with the US, ensuring a high prediction error during $B$-US trials. This option is fully consistent with our derivation. **Correct**.\n\n-   **B.** This option incorrectly claims that $B$ will not be blocked due to its salience $\\alpha_B = 0.3$. The Rescorla-Wagner model dictates that learning is a product of salience and prediction error. If prediction error is zero, learning is zero, regardless of salience. **Incorrect**.\n\n-   **C.** This option makes several errors. It incorrectly states that $C$ is blocked in Phase $1$ (it is not present). It incorrectly claims that changes in US intensity do not affect blocking. Phase $2$ is a direct counterexample. The suggestion to add a novel cue $D$ is not a valid unblocking method within the standard Rescorla-Wagner model, as adding a cue with $V_D=0$ does not change the prediction error. **Incorrect**.\n\n-   **D.** This option correctly states that $B$ is blocked in Phase $1$ but incorrectly claims that $C$ is also blocked in Phase $2$. As analyzed, $C$ is unblocked in Phase $2$. Furthermore, it proposes reducing the US intensity (e.g., to $\\lambda=0.6$) to unblock $B$. This would create a negative prediction error $(\\lambda - (V_A+V_B)) \\approx 0.6 - 1.0 = -0.4$, which would lead to inhibitory conditioning (a decrease in $V_B$), not excitatory conditioning. **Incorrect**.\n\nTherefore, option A provides the only accurate and complete description of the phenomena according to the specified learning model.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "We now transition from classical conditioning to reinforcement learning, a framework that models how we learn from the consequences of our actions. This exercise  introduces Temporal Difference (TD) learning, a cornerstone of modern computational psychiatry, to quantify how an individual updates their valuation of a situation based on experience. You will calculate the reward prediction error ($\\delta_t$), a key \"surprise\" signal, and see how it drives changes in value estimates, providing a direct link between abstract learning theory and the neural mechanisms implicated in disorders like depression.",
            "id": "4721727",
            "problem": "A patient with major depressive disorder engages in a reinforcement-based decision-making task that is modeled as a Markov Decision Process (MDP). The clinician uses Temporal Difference (TD) learning to quantify how the patient updates state values from trial to trial, under the assumption of discounted cumulative return and Bellman consistency. On trial $t$, the patient is in state $s_t$ with current value estimate $V(s_t) = 0.5$, receives an immediate outcome $r_t = 1$ after choosing an action, and transitions to state $s_{t+1}$ with value estimate $V(s_{t+1}) = 0.6$. The learning rate is $\\alpha = 0.2$ and the discount factor is $\\gamma = 0.9$. Using the foundational definition of expected discounted return and the Bellman consistency principle, derive the sample-based discrepancy between observed return and the current estimate (reward prediction error), and compute the one-step TD update to $V(s_t)$. Report the numerical value of the reward prediction error and the updated value estimate for $V(s_t)$. Additionally, interpret the clinical meaning of the sign of the reward prediction error in terms of patient learning (approach versus avoidance) and plausible neuromodulatory signaling in psychiatric models. Express your final numeric answer as a row matrix containing the reward prediction error followed by the updated value estimate. No rounding is required.",
            "solution": "The problem will be validated by first extracting the given parameters and conditions, then assessing its scientific and logical integrity.\n\n### Step 1: Extract Givens\n- Modeling framework: Markov Decision Process (MDP)\n- Learning algorithm: Temporal Difference (TD) learning\n- State at trial $t$: $s_t$\n- Current value estimate of state $s_t$: $V(s_t) = 0.5$\n- Immediate outcome (reward) on trial $t$: $r_t = 1$\n- Subsequent state: $s_{t+1}$\n- Value estimate of state $s_{t+1}$: $V(s_{t+1}) = 0.6$\n- Learning rate: $\\alpha = 0.2$\n- Discount factor: $\\gamma = 0.9$\n- Objective: Derive and compute the reward prediction error, compute the updated value $V(s_t)$, and interpret the clinical meaning.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is grounded in the well-established reinforcement learning framework, specifically Temporal Difference (TD) learning. This model is a cornerstone of computational neuroscience and computational psychiatry for studying decision-making and learning, particularly in relation to dopaminergic function. The parameters and update rule are standard components of this model. The problem is scientifically sound.\n- **Well-Posedness**: The problem provides all necessary numerical values and a clearly defined task. The standard TD learning equations allow for the calculation of a unique solution for the reward prediction error and the updated state value.\n- **Objectivity**: The problem is stated objectively, defining a computational task based on a formal model. The clinical context provided is for interpretation and does not introduce subjectivity into the mathematical procedure.\n- **Conclusion**: The problem is valid. It is a well-posed, scientifically grounded problem that can be solved using standard principles of reinforcement learning.\n\n### Step 3: Derivation and Solution\n\nThe problem requires the application of the one-step Temporal Difference (TD) learning algorithm, often referred to as TD($0$). This algorithm updates the value estimate of a state, $V(s_t)$, based on the experience of a single transition, which is composed of the current state $s_t$, the received reward $r_t$, and the next state $s_{t+1}$.\n\nThe underlying principle is Bellman consistency, which states that the value of a state should be equal to the expected immediate reward plus the discounted value of the expected next state. The TD algorithm uses a sample of this expectation to update its current estimate. The sample-based estimate of the true value of $s_t$ is called the \"TD target\". For a one-step lookahead, the TD target is defined as:\n$$\n\\text{TD Target} = r_t + \\gamma V(s_{t+1})\n$$\nThis expression represents the total discounted return observed from this one step of experience.\n\nThe discrepancy between this new, experienced-based estimate and the old value estimate is the Reward Prediction Error (RPE), denoted by $\\delta_t$. The RPE quantifies the \"surprise\" of the outcome. Its formal definition is:\n$$\n\\delta_t = (\\text{TD Target}) - V(s_t) = [r_t + \\gamma V(s_{t+1})] - V(s_t)\n$$\nUsing the values provided in the problem statement:\n- $r_t = 1$\n- $\\gamma = 0.9$\n- $V(s_{t+1}) = 0.6$\n- $V(s_t) = 0.5$\n\nWe can compute the numerical value of the RPE:\n$$\n\\delta_t = [1 + (0.9)(0.6)] - 0.5\n$$\n$$\n\\delta_t = [1 + 0.54] - 0.5\n$$\n$$\n\\delta_t = 1.54 - 0.5\n$$\n$$\n\\delta_t = 1.04\n$$\nThe first required value, the reward prediction error, is $1.04$.\n\nThe TD update rule modifies the original value estimate $V(s_t)$ by moving it partially towards the TD Target. The size of this adjustment is controlled by the learning rate, $\\alpha$. The updated value, which we may denote as $V_{\\text{new}}(s_t)$, is calculated as:\n$$\nV_{\\text{new}}(s_t) = V(s_t) + \\alpha \\delta_t\n$$\nSubstituting the known values and the calculated RPE:\n- $V(s_t) = 0.5$\n- $\\alpha = 0.2$\n- $\\delta_t = 1.04$\n\nWe compute the updated value estimate:\n$$\nV_{\\text{new}}(s_t) = 0.5 + (0.2)(1.04)\n$$\n$$\nV_{\\text{new}}(s_t) = 0.5 + 0.208\n$$\n$$\nV_{\\text{new}}(s_t) = 0.708\n$$\nThe second required value, the updated value estimate for $V(s_t)$, is $0.708$.\n\n### Clinical Interpretation\n\nThe sign of the reward prediction error ($\\delta_t$) is fundamental to its interpretation. Here, $\\delta_t = 1.04$, which is positive.\n\n1.  **Meaning in Patient Learning**: A positive RPE indicates that the outcome was \"better than expected\". The patient's model of the world, represented by the value function $V$, underestimated the value of being in state $s_t$. The experienced return ($1.54$) was significantly higher than the expected return ($0.5$). This positive surprise signal serves to reinforce the behavior (the action chosen in state $s_t$) that led to this favorable outcome. It promotes \"approach\" behavior, increasing the probability that the patient will make similar choices in the future when faced with state $s_t$. The value of state $s_t$ is updated upwards (from $0.5$ to $0.708$), reflecting this new learning.\n\n2.  **Plausible Neuromodulatory Signaling**: In computational psychiatry, the RPE is hypothesized to be encoded by the phasic firing of midbrain dopamine neurons. A positive RPE, as calculated here, corresponds to a phasic burst of dopamine release in target brain regions like the striatum and prefrontal cortex. This dopamine signal is thought to be the neurobiological substrate for learning from positive outcomes and for motivating future goal-directed behavior. In the context of major depressive disorder, a key hypothesis (anhedonia) is that this reward system is blunted. Observing a robust positive RPE in this patient's task performance could suggest that at least this component of the reward learning circuitry is responsive, providing a quantitative target for assessing treatment effects or disease progression. Conversely, a consistently lower-than-expected RPE for positive outcomes across many trials could be a biomarker for anhedonia.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 1.04 & 0.708 \\end{pmatrix}}\n$$"
        }
    ]
}