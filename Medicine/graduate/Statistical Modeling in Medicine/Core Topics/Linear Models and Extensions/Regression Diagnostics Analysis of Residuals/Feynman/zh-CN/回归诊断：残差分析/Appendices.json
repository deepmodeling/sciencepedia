{
    "hands_on_practices": [
        {
            "introduction": "在构建任何统计模型后，我们的首要任务是评估其拟合优度。残差分析是这一过程的核心，而标准化残差是识别与模型假设严重偏离的观测值（即异常值）的基本工具。这项动手实践()将指导您从第一性原理出发，在一个实际的临床场景中计算和解释标准化残差，从而巩固您对线性回归诊断基础的理解。",
            "id": "4982808",
            "problem": "考虑一项临床流行病学中的队列研究，其中生物标志物C反应蛋白（CRP）的测量单位为毫克/升，然后进行对数变换以稳定方差。记对数变换后的CRP为$y_i$，年龄（单位：年）为$x_i$，吸烟状态指示变量为$z_i$，其中$z_i \\in \\{0,1\\}$，$z_i=1$表示当前吸烟者，$z_i=0$表示非当前吸烟者。我们考虑一个线性模型，对$i=1,\\dots,n$定义为$y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中误差项$\\varepsilon_i$被假定为独立同分布的高斯分布，均值为$0$，方差为$\\sigma^2$。使用普通最小二乘法（OLS），从数据中获得拟合值和残差，帽子矩阵的对角元素$h_{ii}$用于量化杠杆值。标准化残差$r_i$用于回归诊断，以评估模型充分性和离群值，而诸如$|r_i|>2$之类的数值阈值通常根据标准正态参照下的近似尾部概率来解释。\n\n根据高斯-马尔可夫（Gauss–Markov）假定和OLS估计量的性质，从第一性原理出发，实现一个算法，该算法能够：\n- 使用设计矩阵$X$拟合线性模型以获得$\\hat{\\beta}$，该矩阵的列分别为截距项、年龄$x_i$和吸烟指示变量$z_i$。\n- 计算残差$e_i$和帽子矩阵$H$以获得$h_{ii}$。\n- 使用$n-p$自由度，通过残差均方$s^2$来估计$\\sigma^2$，其中$p$是包括截距在内的回归系数数量（此处$p=3$）。\n- 计算所有观测值的标准化残差$r_i$。\n- 通过报告在标准正态参照下的近似双侧尾部概率$2\\{1 - \\Phi(2)\\}$来解释阈值$|r_i|>2$，其中$\\Phi(\\cdot)$是标准正态累积分布函数。此外，还需报告每个残差的近似双侧尾部概率$p_i = 2\\Phi(-|r_i|)$。\n\n所有年龄$x_i$必须以年为单位处理。由于$y_i$是对数值，输出是无单位的。\n\n您的程序必须将上述步骤应用于以下包含三个数据集的测试套件，每个数据集都指定为三元组$(\\{x_i\\},\\{z_i\\},\\{y_i\\})$：\n\n- 测试用例1（典型变异性，$n=10, p=3$）：\n  - 年龄 $\\{x_i\\}$: $[22,34,47,51,36,63,41,55,29,68]$ (岁)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1,0,1,0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.79,1.35,1.24,1.59,1.15,1.85,1.26,1.80,0.96,1.97]$\n\n- 测试用例2（一个高杠杆离群值，$n=8, p=3$）：\n  - 年龄 $\\{x_i\\}$: $[25,40,45,50,55,60,65,95]$ (岁)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,0,1,0,1,0,1,1]$\n  - 对数CRP $\\{y_i\\}$: $[0.93,1.16,1.61,1.41,1.70,1.62,1.95,0.80]$\n\n- 测试用例3（接近边界的小样本，$n=4, p=3$）：\n  - 年龄 $\\{x_i\\}$: $[30,50,70,60]$ (岁)\n  - 吸烟指示变量 $\\{z_i\\}$: $[0,1,0,1]$\n  - 对数CRP $\\{y_i\\}$: $[1.01,1.64,1.78,1.86]$\n\n对于每个测试用例，生成：\n- 标准化残差列表$[r_1,\\dots,r_n]$，四舍五入到6位小数。\n- 近似双侧尾部概率列表$[p_1,\\dots,p_n]$，其中$p_i = 2\\Phi(-|r_i|)$，四舍五入到6位小数。\n- 绝对值大于2的残差整数计数$c$。\n- 浮点数$\\pi_2 = 2\\{1 - \\Phi(2)\\}$，四舍五入到6位小数。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且本身也是一个按上述顺序排列的列表。例如，总体格式为 $[[\\text{case1\\_residuals},\\text{case1\\_pvals},c_1,\\pi_2],[\\text{case2\\_residuals},\\text{case2\\_pvals},c_2,\\pi_2],[\\text{case3\\_residuals},\\text{case3\\_pvals},c_3,\\pi_2]]$。所有概率都必须以小数形式表示，不得使用百分号。",
            "solution": "用户提供了一个关于统计回归诊断领域的问题，要求实现一个算法来计算和解释多元线性回归模型的标准化残差。问题陈述已经过严格验证，并被确定为有效。\n\n### 验证结论：\n此问题是 **有效的**。\n- **科学依据**：该问题基于线性模型、普通最小二乘（OLS）估计和标准回归诊断的经典理论。所有概念，包括高斯-马尔可夫模型（Gauss-Markov model）、帽子矩阵、杠杆值和标准化残差，都是统计学的基础。\n- **定义明确**：该问题定义清晰，所有必要的数据和数学公式要么已提供，要么是该领域的标准。对于所提供的数据集，OLS解存在且唯一，因为设计矩阵具有满列秩（$n>p$ 且不存在完全共线性）。\n- **客观性**：该问题使用精确无歧义的数学语言陈述，不含主观论斷。\n- **完整与一致**：提供了三个测试用例的所有必需数据，并明确概述了算法的步骤。方差估计量$s^2$及其自由度的定义与标准OLS理论一致。标准化残差的定义默认为标准定义$r_i = e_i / (s \\sqrt{1-h_{ii}})$，这是恰当的。\n\n该问题是已建立的统计方法的直接应用，并且被完全指定，从而允许一个唯一且可验证的解。\n\n### 解题推导\n解决方案将遵循问题陈述中概述的算法步骤来实现，这些步骤基于普通最小二乘（OLS）回归的原理。\n\n对于每个包含$n$个观测值$(y_i, x_i, z_i)$的数据集，我们将模型定义为：\n$y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i + \\varepsilon_i$，其中$\\varepsilon_i \\sim \\text{i.i.d. } N(0, \\sigma^2)$。\n\n这可以用矩阵形式表示为$y = X\\beta + \\varepsilon$，其中：\n- $y$是$n \\times 1$的响应向量$\\{y_i\\}$。\n- $X$是$n \\times p$的设计矩阵，其中$p=3$。$X$的列分别是一个全为1的向量（用于截距$\\beta_0$）、年龄向量$\\{x_i\\}$和吸烟指示变量向量$\\{z_i\\}$。\n- $\\beta = (\\beta_0, \\beta_1, \\beta_2)^T$是系数向量。\n- $\\varepsilon$是误差项向量。\n\n算法流程如下：\n\n**1. $\\beta$的OLS估计**：\nOLS估计量$\\hat{\\beta}$最小化残差平方和$RSS = \\sum e_i^2 = (y - X\\beta)^T(y - X\\beta)$。解由正规方程给出：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n$$\n\n**2. 计算残差和帽子矩阵**：\n- 拟合值计算为$\\hat{y} = X\\hat{\\beta}$。\n- 原始残差是观测值与拟合值之间的差：$e = y - \\hat{y}$。\n- 帽子矩阵$H$将观测值$y$投影到由$X$的列所张成的空间上，以产生拟合值：$\\hat{y} = Hy$。它定义为：\n$$\nH = X(X^T X)^{-1} X^T\n$$\n帽子矩阵的对角元素$h_{ii}$是每个观测值的杠杆分数。它们满足$0 \\le h_{ii} \\le 1$和$\\sum_{i=1}^n h_{ii} = p$。\n\n**3. 误差方差$\\sigma^2$的估计**：\n未知误差方差$\\sigma^2$通过残差均方$s^2$来估计：\n$$\ns^2 = \\frac{RSS}{n-p} = \\frac{e^T e}{n-p}\n$$\n其中$n-p$是残差自由度。误差的标准差的估计量为$s = \\sqrt{s^2}$。\n\n**4. 标准化残差的计算**：\n第$i$个原始残差$e_i$的方差是$\\text{Var}(e_i) = \\sigma^2(1-h_{ii})$。标准化残差$r_i$是原始残差除以其估计的标准差：\n$$\nr_i = \\frac{e_i}{s \\sqrt{1 - h_{ii}}}\n$$\n在模型假设下，每个$r_i$的均值约为$0$，方差约为$1$。对于大的$n$，它们的分布可以很好地由标准正态分布$N(0, 1)$近似。\n\n**5. 概率计算**：\n- 阈值$|r_i| > 2$的参考概率是在标准正态近似下计算的：\n$$\n\\pi_2 = P(|Z| > 2) = 2 \\cdot P(Z < -2) = 2 \\Phi(-2)\n$$\n其中$Z \\sim N(0,1)$且$\\Phi(\\cdot)$是标准正态累积分布函数（CDF）。\n- 对于每个标准化残差$r_i$，相应的近似双侧尾部概率是：\n$$\np_i = P(|Z| > |r_i|) = 2 \\Phi(-|r_i|)\n$$\n标准正态CDF使用其与`scipy.special`中提供的误差函数$\\text{erf}(x)$的关系进行计算：\n$$\n\\Phi(z) = \\frac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right)\n$$\n这导致双侧尾部概率的表达式为：\n$$\np_i = 2(1 - \\Phi(|r_i|)) = 2\\left(1 - \\frac{1}{2}\\left(1 + \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\\right)\\right) = 1 - \\text{erf}\\left(\\frac{|r_i|}{\\sqrt{2}}\\right)\n$$\n一个类似的公式对$\\pi_2$也成立。实现将使用这种基于`erf`的计算。\n\n最后一步是计算$|r_i| > 2$的残差数量$c$，并将所有结果组合成指定的输出格式。这个完整的过程将应用于三个测试用例中的每一个。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1 (typical variability, n=10, p=3)\n        (\n            [22, 34, 47, 51, 36, 63, 41, 55, 29, 68],  # Ages {x_i}\n            [0, 1, 0, 1, 0, 1, 0, 1, 0, 1],          # Smoking indicators {z_i}\n            [0.79, 1.35, 1.24, 1.59, 1.15, 1.85, 1.26, 1.80, 0.96, 1.97] # Log-CRP {y_i}\n        ),\n        # Test case 2 (one high-leverage outlier, n=8, p=3)\n        (\n            [25, 40, 45, 50, 55, 60, 65, 95],         # Ages {x_i}\n            [0, 0, 1, 0, 1, 0, 1, 1],                 # Smoking indicators {z_i}\n            [0.93, 1.16, 1.61, 1.41, 1.70, 1.62, 1.95, 0.80] # Log-CRP {y_i}\n        ),\n        # Test case 3 (near-boundary small sample, n=4, p=3)\n        (\n            [30, 50, 70, 60],                         # Ages {x_i}\n            [0, 1, 0, 1],                             # Smoking indicators {z_i}\n            [1.01, 1.64, 1.78, 1.86]                  # Log-CRP {y_i}\n        )\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        result = process_case(case_data)\n        all_results.append(result)\n\n    # Format the final output string exactly as specified.\n    # The str() of a list automatically includes spaces, e.g., '[1, 2]'.\n    # To get a compact representation, we can build the string manually.\n    result_strings = []\n    for res in all_results:\n        r_list_str = f\"[{','.join(map(str, res[0]))}]\"\n        p_list_str = f\"[{','.join(map(str, res[1]))}]\"\n        c_str = str(res[2])\n        pi2_str = str(res[3])\n        result_strings.append(f\"[{r_list_str},{p_list_str},{c_str},{pi2_str}]\")\n    \n    # The problem example implies that str(list) is fine. Let's use the simpler approach.\n    print(str(all_results).replace(\" \", \"\"))\n\n\ndef process_case(case_data):\n    \"\"\"\n    Implements OLS regression and diagnostics for a single dataset.\n\n    Args:\n        case_data (tuple): A tuple containing lists for ages, smoking indicators,\n                           and log-CRP values.\n\n    Returns:\n        list: A list containing [standardized_residuals, tail_probabilities, count, pi_2].\n    \"\"\"\n    x_i, z_i, y_i = case_data\n    \n    # Convert input lists to numpy arrays for vector/matrix operations.\n    x_vec = np.array(x_i)\n    z_vec = np.array(z_i)\n    y_vec = np.array(y_i)\n    \n    n = len(y_vec)  # Number of observations\n    p = 3           # Number of parameters (beta_0, beta_1, beta_2)\n    \n    # Construct the n x p design matrix X.\n    X = np.ones((n, p))\n    X[:, 1] = x_vec\n    X[:, 2] = z_vec\n    \n    # Step 1: Fit the linear model using OLS to get beta_hat.\n    # beta_hat = (X'X)^-1 * X'y\n    XTX = X.T @ X\n    XTX_inv = np.linalg.inv(XTX)\n    XTY = X.T @ y_vec\n    beta_hat = XTX_inv @ XTY\n    \n    # Step 2: Compute residuals and hat matrix.\n    # Fitted values: y_hat = X * beta_hat\n    y_hat = X @ beta_hat\n    # Raw residuals: e = y - y_hat\n    residuals = y_vec - y_hat\n    # Hat matrix: H = X * (X'X)^-1 * X'\n    hat_matrix = X @ XTX_inv @ X.T\n    # Leverage values (diagonal of H): h_ii\n    leverages = np.diag(hat_matrix)\n    \n    # Step 3: Estimate error variance sigma^2.\n    # Residual Sum of Squares (RSS)\n    rss = residuals.T @ residuals\n    # Degrees of freedom for error\n    df = n - p\n    # Residual Mean Square (s^2)\n    s_squared = rss / df\n    # Residual standard error (s)\n    s = np.sqrt(s_squared)\n    \n    # Step 4: Compute standardized residuals.\n    # r_i = e_i / (s * sqrt(1 - h_ii))\n    denom = s * np.sqrt(1 - leverages)\n    # Avoid division by zero in case of h_ii=1 (not expected here)\n    # Adding a small epsilon would be robust, but not necessary for these test cases.\n    standardized_residuals = residuals / denom\n    \n    # Step 5  6: Compute tail probabilities and count.\n    # The two-sided tail probability is P(|Z| > |x|) = 2 * (1 - Phi(|x|))\n    # which simplifies to 1 - erf(|x|/sqrt(2)).\n    \n    # For the threshold |r_i| > 2\n    pi_2 = 1.0 - erf(2.0 / np.sqrt(2.0))\n    \n    # For each standardized residual\n    tail_probabilities = 1.0 - erf(np.abs(standardized_residuals) / np.sqrt(2.0))\n    \n    # Count of residuals with absolute value greater than 2.\n    count_gt_2 = np.sum(np.abs(standardized_residuals) > 2)\n\n    # Prepare the output lists and values, rounded to 6 decimal places.\n    r_list = np.round(standardized_residuals, 6).tolist()\n    p_vals_list = np.round(tail_probabilities, 6).tolist()\n    \n    return [r_list, p_vals_list, int(count_gt_2), round(pi_2, 6)]\n\n# Execute the solver\nsolve()\n```"
        },
        {
            "introduction": "残差分析的原理是普适的，但诊断工具必须与我们所使用的模型相匹配。对于像死亡率这样的二元结局，在医学统计中无处不在，逻辑回归是标准方法。这项实践()将展示残差的概念如何通过“偏差残差”扩展到广义线性模型中，该残差源于模型的似然函数。您将亲自推导并计算这一重要的诊断统计量，以评估一个脓毒症死亡率模型的有效性。",
            "id": "4982785",
            "problem": "您正在使用逻辑斯谛回归对脓毒症的院内死亡率进行建模，这是一个二元结局，预测变量为年龄和序贯器官衰竭评估 (SOFA) 评分。设每个观测值的索引为 $i \\in \\{1,\\dots,n\\}$，其二元结局为 $y_i \\in \\{0,1\\}$。该回归模型假设 $Y_i \\mid \\mathbf{x}_i \\sim \\mathrm{Bernoulli}(\\pi_i)$，其中 $\\pi_i = \\mathbb{P}(Y_i = 1 \\mid \\mathbf{x}_i)$，且标准链接函数为 $\\mathrm{logit}(\\pi_i) = \\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta}$，其中 $\\mathbf{x}_i = (1, \\mathrm{age}_i, \\mathrm{sofa}_i)^\\top$ 且 $\\boldsymbol{\\beta} = (\\beta_0,\\beta_1,\\beta_2)^\\top$。\n\n仅从以下基本要素出发：\n- 单个观测值的伯努利似然函数：$L_i(\\pi_i \\mid y_i) = \\pi_i^{y_i} (1-\\pi_i)^{1-y_i}$ 及其对数似然函数 $\\ell_i(\\pi_i \\mid y_i) = y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)$。\n- 广义线性模型 (GLM) 偏差的定义：饱和模型（一个能精确拟合每个 $y_i$ 的模型）的对数似然与拟合模型的对数似然之差的两倍，并对所有观测值求和。\n\n您的任务是：\n1) 从第一性原理出发，为逻辑斯谛回归的单个偏差残差 $r_i$ 推导出一个显式闭式表达式。该表达式应表示为单个观测值偏差贡献的带符号平方根，并以 $y_i$ 和 $\\hat{\\pi}_i$ 表示，其中 $\\hat{\\pi}_i = \\mathrm{logistic}(\\hat{\\eta}_i)$ 且 $\\hat{\\eta}_i = \\mathbf{x}_i^\\top \\hat{\\boldsymbol{\\beta}}$。\n2) 然后，对于一个固定的已知系数向量 $\\hat{\\boldsymbol{\\beta}} = (\\hat{\\beta}_0,\\hat{\\beta}_1,\\hat{\\beta}_2) = (-7.0, 0.04, 0.35)$，计算下面测试集中每个观测值的偏差残差。年龄以年为单位，SOFA 为一个无单位评分。残差是无量纲的；报告的残差需四舍五入到六位小数。\n\n实现说明和数值稳定性要求：\n- 使用逻辑斯谛函数 $\\mathrm{logistic}(z) = \\dfrac{1}{1+\\exp(-z)}$ 从 $\\hat{\\eta}_i$ 计算 $\\hat{\\pi}_i$。\n- 确保数值稳定性，避免对 $0$ 进行对数运算。对于二元变量 $y_i \\in \\{0,1\\}$，您可以使用任何数学上等价的稳定形式来避免出现未定义的项，同时保留偏差残差的精确定义。\n- 对于每个测试用例，按观测值列出的顺序计算并返回残差列表，并将每个残差四舍五入到六位小数。\n\n测试集：\n- 测试用例 1 (一般混合风险队列，5 个观测值)：\n  - 观测值 1：年龄 65 岁，SOFA 6，结局 y=1。\n  - 观测值 2：年龄 72 岁，SOFA 10，结局 y=1。\n  - 观测值 3：年龄 50 岁，SOFA 4，结局 y=0。\n  - 观测值 4：年龄 34 岁，SOFA 2，结局 y=0。\n  - 观测值 5：年龄 80 岁，SOFA 12，结局 y=1。\n- 测试用例 2 (探测稳定性的近边界概率，5 个观测值)：\n  - 观测值 1：年龄 22 岁，SOFA 0，结局 y=1。\n  - 观测值 2：年龄 90 岁，SOFA 18，结局 y=0。\n  - 观测值 3：年龄 85 岁，SOFA 20，结局 y=1。\n  - 观测值 4：年龄 25 岁，SOFA 1，结局 y=0。\n  - 观测值 5：年龄 78 岁，SOFA 22，结局 y=1。\n- 测试用例 3 (具有不一致结局的重复协变量，4 个观测值)：\n  - 观测值 1：年龄 60 岁，SOFA 8，结局 y=0。\n  - 观测值 2：年龄 60 岁，SOFA 8，结局 y=1。\n  - 观测值 3：年龄 40 岁，SOFA 5，结局 y=0。\n  - 观测值 4：年龄 40 岁，SOFA 5，结局 y=1。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例结果列表的逗号分隔列表，并包含在一对单独的方括号中。例如，格式应如下所示：$[[a_{11},\\dots,a_{1m_1}],[a_{21},\\dots,a_{2m_2}],[a_{31},\\dots,a_{3m_3}]]$，其中每个 $a_{jk}$ 是一个四舍五入到六位小数的浮点数。不应打印任何额外的文本。",
            "solution": "用户提供的问题经评估有效。该问题在科学上基于广义线性模型 (GLM) 理论，提法明确，提供了所有必要的数据和参数，且陈述客观。任务涉及逻辑斯谛回归中偏差残差的标准推导和应用，这是统计建模中的一个核心概念。\n\n### **第 1 部分：逻辑斯谛回归偏差残差的推导**\n\nGLM 的偏差定义为 $D = 2 \\sum_{i=1}^n [\\ell(\\boldsymbol{\\beta}_{sat}; y_i) - \\ell(\\hat{\\boldsymbol{\\beta}}; y_i)]$，其中 $\\ell(\\cdot)$ 是对数似然函数，$\\hat{\\boldsymbol{\\beta}}$ 是模型参数的最大似然估计，$\\boldsymbol{\\beta}_{sat}$ 代表*饱和*模型的参数。饱和模型是能完美拟合数据的模型，每个观测值都有一个参数。总偏差 $D$ 是单个偏差贡献 $d_i = 2 [\\ell(\\boldsymbol{\\beta}_{sat}; y_i) - \\ell(\\hat{\\boldsymbol{\\beta}}; y_i)]$ 的总和。\n\n观测值 $i$ 的偏差残差，记为 $r_i$，定义为其对偏差的贡献的带符号平方根：\n$$\nr_i = \\mathrm{sign}(y_i - \\hat{\\pi}_i) \\sqrt{d_i}\n$$\n其中 $y_i$ 是观测结局，$\\hat{\\pi}_i$ 是模型的拟合概率。\n\n我们接下来为逻辑斯谛回归推导 $d_i$ 的形式，逻辑斯谛回归使用伯努利分布对二元结局 $y_i \\in \\{0, 1\\}$ 进行建模。\n\n**1. 饱和模型的对数似然**\n\n对于伯努利试验，观测值 $i$ 的对数似然由 $\\ell_i(\\pi_i \\mid y_i) = y_i \\log(\\pi_i) + (1-y_i)\\log(1-\\pi_i)$ 给出。饱和模型能完美解释数据，这意味着其对观测值 $i$ 的拟合概率（我们称之为 $\\tilde{\\pi}_i$）等于观测结局 $y_i$。因此，$\\tilde{\\pi}_i = y_i$。\n\n观测值 $i$ 的饱和模型的对数似然是对数似然函数的最大可能值，该值在 $\\pi_i=y_i$ 时取到。将 $\\pi_i = y_i$ 代入对数似然函数可得：\n$$\n\\ell(\\boldsymbol{\\beta}_{sat}; y_i) = y_i \\log(y_i) + (1-y_i) \\log(1-y_i)\n$$\n如果 $y_i = 1$，表达式变为 $1 \\log(1) + 0 \\log(0)$。如果 $y_i=0$，则为 $0 \\log(0) + 1 \\log(1)$。根据约定 $\\lim_{x\\to 0} x \\log x = 0$，任何单个伯努利观测的饱和模型的对数似然均为 $0$。\n$$\n\\ell(\\boldsymbol{\\beta}_{sat}; y_i) = 0\n$$\n\n**2. 拟合模型的对数似然**\n\n拟合的逻辑斯谛回归模型为每个观测值提供一个估计概率 $\\hat{\\pi}_i$，其中 $\\hat{\\pi}_i = \\mathrm{logistic}(\\mathbf{x}_i^\\top \\hat{\\boldsymbol{\\beta}})$。在拟合模型下，观测值 $i$ 的对数似然是：\n$$\n\\ell(\\hat{\\boldsymbol{\\beta}}; y_i) = y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i)\n$$\n\n**3. 单个偏差贡献 ($d_i$)**\n\n结合对数似然，观测值 $i$ 的偏差贡献为：\n$$\nd_i = 2 [0 - (y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i))]\n$$\n$$\nd_i = -2 [y_i \\log(\\hat{\\pi}_i) + (1-y_i)\\log(1-\\hat{\\pi}_i)]\n$$\n这是逻辑斯谛回归中单个观测值的偏差分量的一般表达式。\n\n**4. 偏差残差 ($r_i$)**\n\n现在我们构建偏差残差 $r_i = \\mathrm{sign}(y_i - \\hat{\\pi}_i) \\sqrt{d_i}$。为了获得显式形式，我们考虑二元结局 $y_i$ 的两种情况。\n\n- **情况 1：$y_i = 1$ (例如，发生死亡)**\n  在这种情况下，偏差贡献为 $d_i = -2 [1 \\cdot \\log(\\hat{\\pi}_i) + 0 \\cdot \\log(1-\\hat{\\pi}_i)] = -2 \\log(\\hat{\\pi}_i)$。\n  符号项为 $\\mathrm{sign}(1 - \\hat{\\pi}_i)$。由于 $\\hat{\\pi}_i \\in (0,1)$，该符号始终为 $+1$。\n  因此残差为：\n  $$\n  r_i = \\sqrt{-2 \\log(\\hat{\\pi}_i)} \\quad \\text{当 } y_i = 1 \\text{ 时}\n  $$\n\n- **情况 2：$y_i = 0$ (例如，存活)**\n  在这种情况下，偏差贡献为 $d_i = -2 [0 \\cdot \\log(\\hat{\\pi}_i) + 1 \\cdot \\log(1-\\hat{\\pi}_i)] = -2 \\log(1 - \\hat{\\pi}_i)$。\n  符号项为 $\\mathrm{sign}(0 - \\hat{\\pi}_i)$。由于 $\\hat{\\pi}_i \\in (0,1)$，该符号始终为 $-1$。\n  因此残差为：\n  $$\n  r_i = -\\sqrt{-2 \\log(1 - \\hat{\\pi}_i)} \\quad \\text{当 } y_i = 0 \\text{ 时}\n  $$\n\n这两个表达式提供了逻辑斯谛回归中偏差残差的显式闭式公式，符合要求。\n\n### **第 2 部分：偏差残差的计算**\n\n对每个观测值 $(\\mathrm{age}_i, \\mathrm{sofa}_i, y_i)$ 的计算过程如下，使用给定的系数向量 $\\hat{\\boldsymbol{\\beta}} = (-7.0, 0.04, 0.35)^\\top$。\n\n1.  **计算线性预测器 $\\hat{\\eta}_i$**：\n    $$\n    \\hat{\\eta}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot \\mathrm{age}_i + \\hat{\\beta}_2 \\cdot \\mathrm{sofa}_i = -7.0 + 0.04 \\cdot \\mathrm{age}_i + 0.35 \\cdot \\mathrm{sofa}_i\n    $$\n2.  **计算拟合概率 $\\hat{\\pi}_i$**：\n    $$\n    \\hat{\\pi}_i = \\mathrm{logistic}(\\hat{\\eta}_i) = \\frac{1}{1 + \\exp(-\\hat{\\eta}_i)}\n    $$\n3.  **计算偏差残差 $r_i$**，使用基于 $y_i$ 值的推导分段公式：\n    $$\n    r_i = \\begin{cases} \\sqrt{-2 \\log(\\hat{\\pi}_i)}  \\text{if } y_i=1 \\\\ -\\sqrt{-2 \\log(1-\\hat{\\pi}_i)}  \\text{if } y_i=0 \\end{cases}\n    $$\n4.  **四舍五入**结果至六位小数。\n\n提供的 Python 代码为给定测试集中的每个观测值实现了此过程。通过使用标准的 `numpy` 函数，确保了数值稳定性，这些函数能为本问题中遇到的输入范围稳健地处理浮点运算。对于任何有限的 $\\hat{\\eta}_i$，$\\hat{\\pi}_i$ 都严格介于 $0$ 和 $1$ 之间，因此表达式 $\\log(\\hat{\\pi}_i)$ 和 $\\log(1-\\hat{\\pi}_i)$ 都有明确定义。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes deviance residuals for logistic regression based on fixed coefficients.\n    \"\"\"\n    \n    # The given fixed coefficient vector beta_hat = (beta_0, beta_1, beta_2)\n    # corresponding to (intercept, age, sofa).\n    beta_hat = np.array([-7.0, 0.04, 0.35])\n\n    # Test suites as a list of lists of tuples. Each tuple is (age, sofa, y).\n    test_cases = [\n        # Test case 1: General mixed-risk cohort\n        [\n            (65, 6, 1),   # Observation 1\n            (72, 10, 1),  # Observation 2\n            (50, 4, 0),   # Observation 3\n            (34, 2, 0),   # Observation 4\n            (80, 12, 1)   # Observation 5\n        ],\n        # Test case 2: Near-boundary probabilities\n        [\n            (22, 0, 1),   # Observation 1\n            (90, 18, 0),  # Observation 2\n            (85, 20, 1),  # Observation 3\n            (25, 1, 0),   # Observation 4\n            (78, 22, 1)   # Observation 5\n        ],\n        # Test case 3: Duplicate covariates with discordant outcomes\n        [\n            (60, 8, 0),   # Observation 1\n            (60, 8, 1),   # Observation 2\n            (40, 5, 0),   # Observation 3\n            (40, 5, 1)    # Observation 4\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        case_residuals = []\n        for age, sofa, y in case_data:\n            # Construct the design vector x_i with an intercept term\n            x_i = np.array([1, age, sofa])\n            \n            # Step 1: Compute the linear predictor eta_hat_i\n            eta_hat_i = x_i @ beta_hat\n            \n            # Step 2: Compute the fitted probability pi_hat_i\n            pi_hat_i = 1 / (1 + np.exp(-eta_hat_i))\n            \n            # Step 3: Compute the deviance residual r_i\n            # The piecewise formula derived in the solution is used.\n            if y == 1:\n                # Per-observation deviance for y=1\n                d_i = -2 * np.log(pi_hat_i)\n                # sign(y - pi_hat) is sign(1 - pi_hat) which is +1\n                residual = np.sqrt(d_i)\n            else: # y == 0\n                # Per-observation deviance for y=0.\n                # np.log1p(-pi_hat_i) is equivalent to np.log(1 - pi_hat_i) but\n                # can be more accurate for pi_hat_i close to 0. Here, 1-pi_hat_i\n                # is not extremely close to 1, so np.log is sufficient.\n                d_i = -2 * np.log(1 - pi_hat_i)\n                # sign(y - pi_hat) is sign(0 - pi_hat) which is -1\n                residual = -np.sqrt(d_i)\n\n            # Step 4: Round and store the result\n            case_residuals.append(round(residual, 6))\n        \n        all_results.append(case_residuals)\n\n    # Format the final output string as specified in the problem.\n    # e.g., [[-1.2,3.4],[5.6,7.8]]\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, res))}]' for res in all_results])}]\"\n    \n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "当模型变得更加复杂，例如用于处理住院次数等计数数据的模型时，传统的解析残差可能不足以进行全面的诊断。这项实践()引入了一种现代且强大的模拟技术——随机化分位数残差（DHARMa残差）。该方法的核心思想是通过模拟，将任何模型的残差转化为在模型正确时应服从标准均匀分布的形式，从而使我们能够轻松地检测如零膨胀或错误的分散度等更微妙的模型设定问题。",
            "id": "4982829",
            "problem": "您的任务是在医疗背景下，借鉴分层回归模型诊断（Diagnostics for HierArchical Regression Models, DHARMa）的理论思想，为计数数据实现基于模拟的回归诊断。该诊断依赖于根据拟合的住院次数负二项模型构建的随机化分位数残差。下文详细说明了设定和任务。\n\n基本原理：\n- 均值为 $ \\mu $ 且“size”（也称为逆离散度）为 $ \\theta $ 的负二项分布满足 $ \\operatorname{Var}(Y \\mid \\mu, \\theta) = \\mu + \\mu^2 / \\theta $。一个使用对数连接函数的广义线性模型将 $ \\mu_i = \\exp(\\eta_i) $ 编码，其中 $ \\eta_i = \\beta_0 + \\beta_1 x_i + \\log(\\text{offset}_i) $，$ \\beta_0 $ 和 $ \\beta_1 $ 是回归系数，$ \\text{offset}_i $ 是已知的暴露量。\n- 对于以 $ \\mu_i $ 和 $ \\theta $ 为条件的离散响应 $ Y_i $，随机化分位数残差（DHARMa 残差）定义为\n$$ U_i = F_{Y_i \\mid \\mu_i, \\theta}(Y_i - 1) + V_i \\cdot \\mathbb{P}(Y_i \\mid \\mu_i, \\theta), $$\n其中 $ V_i \\sim \\text{Uniform}(0, 1) $，$ F $ 是累积分布函数，$ \\mathbb{P} $ 表示概率质量函数。在模型设定正确的情况下，$ U_i $ 是在 $ [0,1] $ 上独立同分布的均匀分布。\n- 均匀性可以通过分布检验来评估，例如对 $ H_0: U_i \\sim \\text{Uniform}(0,1) $ 进行 Kolmogorov–Smirnov 检验。零膨胀可以通过将观测到的零的数量与通过在拟合模型下进行模拟所构建的模型隐含的零计数分布进行比较来评估。离散度可以通过将一个离散度统计量（例如，皮尔逊残差平方和）与其在拟合模型下通过参数化模拟获得的抽样分布进行比较来评估。\n\n您的实现必须：\n- 使用对数连接广义线性模型定义 $ \\mu_i = \\exp(\\beta_0 + \\beta_1 x_i + \\log(\\text{offset}_i)) $ 来为每个观测值计算 $ \\mu_i $。\n- 使用由 $(\\mu_i, \\theta)$ 参数化的负二项分布，其与“成功次数” $ n = \\theta $ 和成功概率 $ p_i = \\theta / (\\theta + \\mu_i) $ 的关系使得 $ \\mathbb{E}[Y_i] = \\mu_i $ 和 $ \\operatorname{Var}(Y_i) = \\mu_i + \\mu_i^2 / \\theta $。\n- 构建 DHARMa 残差 $ U_i $ 并计算一个针对 $ \\text{Uniform}(0,1) $ 的 Kolmogorov–Smirnov 检验。\n- 通过在拟合模型下模拟重复数据集（使用给定的 $ \\mu_i $ 和 $ \\theta $）来实现零膨胀诊断，以获得总零计数的经验分布。根据观测到的零计数计算一个双边蒙特卡洛 p 值。\n- 通过计算一个皮尔逊型统计量来实现离散度诊断\n$$ R_{\\text{obs}} = \\sum_{i=1}^n \\frac{(Y_i - \\mu_i)^2}{\\mu_i + \\mu_i^2 / \\theta}, $$\n并将其与在拟合模型下通过参数化模拟获得的经验抽样分布进行比较。报告一个双边蒙特卡洛 p 值。\n\n显著性阈值和报告：\n- 使用显著性水平 $ \\alpha = 0.05 $。\n- 对于每个测试用例，返回三个布尔指标 $ [b_1, b_2, b_3] $，其中如果 Kolmogorov–Smirnov 检验在水平 $ \\alpha $ 上拒绝，则 $ b_1 $ 为 $ \\text{True} $；如果零膨胀检验在水平 $ \\alpha $ 上拒绝，则 $ b_2 $ 为 $ \\text{True} $；如果离散度检验在水平 $ \\alpha $ 上拒绝，则 $ b_3 $ 为 $ \\text{True} $。否则，返回 $ \\text{False} $。\n\n模拟细节和测试套件：\n- 令 $ S $ 表示为构建零膨胀和离散度检验的参考分布而进行的参数化模拟次数。对所有情况使用 $ S = 3000 $。\n- 使用 Gamma-Poisson 混合表示来模拟负二项随机变量：如果 $ \\Lambda_i \\sim \\text{Gamma}(\\text{shape}=\\theta, \\text{scale}=\\mu_i/\\theta) $ 且 $ Y_i \\mid \\Lambda_i \\sim \\text{Poisson}(\\Lambda_i) $，则 $ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $。这应用于跨 $ S $ 次重复和 $ n $ 个观测值进行高效的向量化模拟。\n\n测试用例：\n- 用例 A（设定良好的负二项模型）：\n    - 数据生成种子：$ 12345 $。\n    - 样本大小：$ n = 800 $。\n    - 协变量：$ x_i \\sim \\text{Uniform}(0,1) $，独立。\n    - 偏移量：$ \\text{offset}_i \\sim \\text{Uniform}(0.5, 2.0) $，独立。\n    - 拟合参数：$ \\beta_0 = -1.0 $，$ \\beta_1 = 0.8 $，$ \\theta = 12.0 $。\n    - 生成观测计数：$ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $，其中 $ \\mu_i = \\exp(\\beta_0 + \\beta_1 x_i + \\log(\\text{offset}_i)) $。\n- 用例 B（相对于拟合的负二项模型存在零膨胀的计数）：\n    - 数据生成种子：$ 424242 $。\n    - 样本大小：$ n = 800 $。\n    - 协变量：$ x_i \\sim \\text{Uniform}(0,1) $，独立。\n    - 偏移量：$ \\text{offset}_i \\sim \\text{Uniform}(0.5, 2.0) $，独立。\n    - 拟合参数：$ \\beta_0 = -1.0 $，$ \\beta_1 = 0.8 $，$ \\theta = 12.0 $。\n    - 零膨胀概率：$ \\pi = 0.5 $。\n    - 生成观测计数：以概率 $ \\pi $，设 $ Y_i = 0 $；否则如上所述从 $ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $ 中抽样。\n- 用例 C（相对于拟合的负二项模型存在低度离散）：\n    - 数据生成种子：$ 999 $。\n    - 样本大小：$ n = 600 $。\n    - 协变量：$ x_i \\sim \\text{Uniform}(0,1) $，独立。\n    - 偏移量：$ \\text{offset}_i \\equiv 5.0 $ (常数)。\n    - 拟合参数：$ \\beta_0 = 1.0 $，$ \\beta_1 = 0.3 $，$ \\theta = 1.5 $。\n    - 生成观测计数：$ Y_i \\sim \\text{Poisson}(\\mu_i) $，其中 $ \\mu_i = \\exp(\\beta_0 + \\beta_1 x_i + \\log(\\text{offset}_i)) $。\n\n角度单位和物理单位不适用。没有百分比输出；显著性是通过将 p 值与 $ \\alpha $直接比较来确定的。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素是按 A、B、C 顺序排列的三个布尔值 $ [b_1,b_2,b_3] $ 的列表。例如，格式应类似于 $ [[\\ldots],[\\ldots],[\\ldots]] $，除非列表格式要求，否则程序不插入空格。实际的布尔值必须由您的程序根据上述规范计算得出，使用 $ S = 3000 $ 次参数化模拟和 $ \\alpha = 0.05 $。",
            "solution": "用户提供的问题陈述经过了严格的验证过程。\n\n### 步骤 1：提取给定条件\n- **模型框架**：指定了带有对数连接函数的负二项广义线性模型。响应 $Y_i$ 的均值为 $ \\mu_i = \\exp(\\beta_0 + \\beta_1 x_i + \\log(\\text{offset}_i)) $。方差为 $ \\operatorname{Var}(Y_i \\mid \\mu_i, \\theta) = \\mu_i + \\mu_i^2 / \\theta $，其中 $ \\theta $ 是逆离散参数。\n- **负二项参数化**：为与标准软件库兼容，负二项分布由成功次数 $n = \\theta$ 和成功概率 $p_i = \\theta / (\\theta + \\mu_i)$ 参数化。\n- **随机化分位数 (DHARMa) 残差**：观测值 $i$ 的残差定义为 $ U_i = F_{Y_i \\mid \\mu_i, \\theta}(Y_i - 1) + V_i \\cdot \\mathbb{P}(Y_i \\mid \\mu_i, \\theta) $，其中 $ F $ 是累积分布函数 (CDF)，$ \\mathbb{P} $ 是概率质量函数 (PMF)，$ V_i $ 是从 $ \\text{Uniform}(0, 1) $ 分布中抽取的随机变量。\n- **诊断检验 1 (均匀性)**：使用 Kolmogorov-Smirnov (KS) 检验评估计算出的残差 $ U_i $ 是否服从 $ \\text{Uniform}(0,1) $ 分布。\n- **诊断检验 2 (零膨胀)**：一个蒙特卡洛检验，将数据中观测到的零计数与从拟合模型的参数化模拟中获得的零计数分布进行比较。需要计算双边 p 值。\n- **诊断检验 3 (离散度)**：一个蒙特卡洛检验，将观测到的皮尔逊型离散度统计量 $ R_{\\text{obs}} = \\sum_{i=1}^n \\frac{(Y_i - \\mu_i)^2}{\\mu_i + \\mu_i^2 / \\theta} $ 与其通过参数化模拟得出的抽样分布进行比较。需要计算双边 p 值。\n- **模拟参数**：蒙特卡洛检验的模拟次数为 $ S = 3000 $。所有检验的显著性水平均为 $ \\alpha = 0.05 $。\n- **模拟方法**：负二项随机变量应使用 Gamma-Poisson 混合公式生成：如果 $ \\Lambda_i \\sim \\text{Gamma}(\\text{shape}=\\theta, \\text{scale}=\\mu_i/\\theta) $ 且 $ Y_i \\mid \\Lambda_i \\sim \\text{Poisson}(\\Lambda_i) $，则 $ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $。\n- **测试用例**：\n    - **用例 A (设定良好)**：$ \\text{seed}=12345 $，$ n=800 $，$ x_i \\sim \\text{Uniform}(0,1) $，$ \\text{offset}_i \\sim \\text{Uniform}(0.5, 2.0) $，$ \\beta_0 = -1.0 $，$ \\beta_1 = 0.8 $，$ \\theta = 12.0 $。数据从 $ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $ 生成。\n    - **用例 B (零膨胀)**：$ \\text{seed}=424242 $，$ n=800 $，$ x_i \\sim \\text{Uniform}(0,1) $，$ \\text{offset}_i \\sim \\text{Uniform}(0.5, 2.0) $，$ \\beta_0 = -1.0 $，$ \\beta_1 = 0.8 $，$ \\theta = 12.0 $。数据以概率 $ \\pi = 0.5 $ 生成为 $ Y_i=0 $，以概率 $ 1-\\pi $ 从 $ Y_i \\sim \\text{NB}(\\mu_i, \\theta) $ 生成。\n    - **用例 C (低度离散)**：$ \\text{seed}=999 $，$ n=600 $，$ x_i \\sim \\text{Uniform}(0,1) $，$ \\text{offset}_i = 5.0 $，$ \\beta_0 = 1.0 $，$ \\beta_1 = 0.3 $，$ \\theta = 1.5 $。数据从 $ Y_i \\sim \\text{Poisson}(\\mu_i) $ 生成。\n- **输出**：一个布尔值的列表的列表，例如 $ [[b_{A1}, b_{A2}, b_{A3}], [b_{B1}, b_{B2}, b_{B3}], [b_{C1}, b_{C2}, b_{C3}]] $，其中如果相应的检验拒绝原假设，则 $ b_{j} $ 为真。\n\n### 步骤 2：使用提取的给定条件进行验证\n根据既定的验证标准对问题进行评估。\n1.  **科学依据**：该问题是合理的。它基于公认的统计学原理，包括广义线性模型 (GLM)、负二项分布和基于模拟的诊断方法（特别是 DHARMa 框架）。这些是应用统计学中的标准、无争议的方法。\n2.  **适定性**：该问题是适定的。所有参数、种子、分布和诊断程序都得到了明确的规定，没有歧义。任务是实现一个确定性（给定种子）算法并报告结果，这会导向唯一的解决方案。\n3.  **客观性**：该问题以精确、客观、形式化的数学语言陈述。它不含主观主张或意见。\n4.  **不完整或矛盾的设置**：该问题是完整且自洽的。提供了生成数据和执行诊断所需的所有必要信息。数据生成过程与用于诊断的“拟合模型”之间的区别是评估模型设定错误的一个标准和有意的部分。没有矛盾之处。\n5.  **不切实际或不可行**：该问题是可行的。模型和参数对于流行病学等领域的计数数据分析是现实的。计算负载（$n \\le 800$ 时进行 $S=3000$ 次模拟）在标准硬件的能力范围之内。\n6.  **其他缺陷**：该问题并非微不足道、非隐喻性，也没有超出科学验证的范围。它代表了计算统计学中一个具体而实质性的任务。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将开发并提出解决方案。\n\n### 基于原则的设计\n解决方案将围绕一个中心函数构建，该函数为单个测试用例执行整个诊断流程。该函数将封装数据生成和模型检查的序列，以提高代码的重用性和清晰度。三个主要的诊断检验将按顺序实现。\n\n1.  **数据生成**：对于每种情况，使用特定的随机数生成器种子以确保可复现性。按规定生成协变量 ($x_i$)、偏移量 ($\\text{offset}_i$) 和真实均值 ($\\mu_i$)。然后从为该情况定义的分布（负二项、零膨胀负二项或泊松分布）中抽样观测数据 ($Y_i$)。\n\n2.  **DHARMa 残差计算和 KS 检验**：此步骤的核心是随机化分位数残差的公式，$ U_i = F(Y_i-1) + V_i \\cdot \\mathbb{P}(Y_i) $。使用 `scipy.stats.nbinom` 计算拟合负二项模型的 PMF ($\\mathbb{P}$) 和 CDF ($F$)，该函数能正确处理指定的参数化。生成残差向量 $U$ 后，使用 `scipy.stats.kstest` 函数检验其均匀性。将得出的 p 值与显著性水平 $ \\alpha $ 进行比较，以确定是否拒绝。\n\n3.  **参数化模拟和蒙特卡洛检验**：为了评估零膨胀和离散度，需要每个检验统计量的参考分布。这是通过从*拟合的*负二项模型进行参数化模拟来构建的。为了高效地完成此操作，我们利用指定的 Gamma-Poisson 混合属性和 `numpy` 的向量化操作。\n    - 生成一个包含 $S$ 个模拟数据集的矩阵，每个数据集大小为 $n$。对于每个观测值 $i$，我们为每个模拟 $j \\in \\{1, \\dots, S\\}$ 抽取一个率 $ \\Lambda_{ji} \\sim \\text{Gamma}(\\theta, \\mu_i/\\theta) $，然后抽取一个计数 $Y_{ji} \\sim \\text{Poisson}(\\Lambda_{ji})$。\n    - **零膨胀检验**：计算观测数据中的零的数量。然后，为 $S$ 个模拟数据集中的每一个计算零的数量，从而得到在零假设模型下零计数的经验分布。通过将观测统计量的秩与此经验分布进行比较来计算双边蒙特卡洛 p 值。\n    - **离散度检验**：为观测数据计算皮尔逊型统计量 $R_{\\text{obs}}$。然后为 $S$ 个模拟数据集中的每一个计算相同的统计量，从而创建 $R$ 在零假设下的经验分布。与零膨胀检验类似地计算双边蒙特卡洛 p 值。\n\n最后，为每种情况收集三个检验的布尔结果（拒绝或不拒绝），并将其格式化为所需的输出字符串。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import nbinom, kstest\n\ndef _generate_data_nb(rng, mu, theta, **kwargs):\n    \"\"\"Generates data from a negative binomial distribution.\"\"\"\n    # The parameterization of numpy's negative_binomial (mean = n*(1-p)/p)\n    # matches the problem's definition for E[Y] = mu when n=theta and p=theta/(theta+mu).\n    p = theta / (theta + mu)\n    return rng.negative_binomial(n=theta, p=p)\n\ndef _generate_data_zinb(rng, mu, theta, n, pi, **kwargs):\n    \"\"\"Generates data from a zero-inflated negative binomial process.\"\"\"\n    # Generate the NB part of the data.\n    p = theta / (theta + mu)\n    nb_draws = rng.negative_binomial(n=theta, p=p, size=n)\n    \n    # Generate the zero-inflation mask. With probability pi, the value is 0.\n    zero_mask = rng.random(size=n)  pi\n    \n    # Where the mask is True, set value to 0; otherwise, use the NB draw.\n    return np.where(zero_mask, 0, nb_draws)\n\ndef _generate_data_poisson(rng, mu, **kwargs):\n    \"\"\"Generates data from a Poisson distribution.\"\"\"\n    return rng.poisson(lam=mu)\n\ndef _run_diagnostics(params):\n    \"\"\"\n    Runs the full diagnostic pipeline for a single test case.\n    \"\"\"\n    # 1. Setup RNG and extract parameters\n    rng = np.random.default_rng(params['seed'])\n    n, beta0, beta1, theta = params['n'], params['beta0'], params['beta1'], params['theta']\n    offset_params = params['offset_params']\n    S, alpha = params['S'], params['alpha']\n    \n    # 2. Generate predictors and mu based on fitted model parameters\n    x = rng.uniform(0, 1, size=n)\n    if isinstance(offset_params, tuple):\n        offset = rng.uniform(offset_params[0], offset_params[1], size=n)\n    else:\n        offset = np.full(n, offset_params)\n    mu = np.exp(beta0 + beta1 * x + np.log(offset))\n    \n    # 3. Generate observed data Y using the case-specific function\n    Y = params['data_gen_func'](rng, mu=mu, **params)\n\n    # --- Start Diagnostics against the fitted NB(mu, theta) model ---\n\n    # 4. DHARMa Residuals and KS Test (b1)\n    p_nb = theta / (theta + mu)\n    cdf_at_y_minus_1 = nbinom.cdf(Y - 1, n=theta, p=p_nb)\n    pmf_at_y = nbinom.pmf(Y, n=theta, p=p_nb)\n    v = rng.uniform(size=n)\n    U = cdf_at_y_minus_1 + v * pmf_at_y\n    _, ks_pvalue = kstest(U, 'uniform')\n    b1 = ks_pvalue  alpha\n\n    # 5. Parametric Simulations for reference distributions\n    shape = theta\n    scale = mu / theta\n    gamma_draws = rng.gamma(shape, scale, size=(S, n))\n    Y_sims = rng.poisson(lam=gamma_draws)\n\n    # 6. Zero-Inflation Test (b2)\n    observed_zeros = np.sum(Y == 0)\n    simulated_zeros = np.sum(Y_sims == 0, axis=1)\n    p_upper_zi = (np.sum(simulated_zeros >= observed_zeros) + 1) / (S + 1)\n    p_lower_zi = (np.sum(simulated_zeros = observed_zeros) + 1) / (S + 1)\n    zi_pvalue = 2 * np.min([p_upper_zi, p_lower_zi])\n    b2 = zi_pvalue  alpha\n\n    # 7. Dispersion Test (b3)\n    nb_variance = mu + mu**2 / theta\n    R_obs = np.sum((Y - mu)**2 / nb_variance)\n    R_sims = np.sum((Y_sims - mu)**2 / nb_variance, axis=1)\n    p_upper_disp = (np.sum(R_sims >= R_obs) + 1) / (S + 1)\n    p_lower_disp = (np.sum(R_sims = R_obs) + 1) / (S + 1)\n    disp_pvalue = 2 * np.min([p_upper_disp, p_lower_disp])\n    b3 = disp_pvalue  alpha\n\n    return [b1, b2, b3]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run diagnostics, and print results.\n    \"\"\"\n    # Define common simulation parameters\n    S = 3000\n    alpha = 0.05\n    \n    # Define parameters for each test case as a list of dictionaries\n    test_cases = [\n        # Case A: Well-specified Negative Binomial\n        {\n            \"seed\": 12345, \"n\": 800, \"beta0\": -1.0, \"beta1\": 0.8, \"theta\": 12.0,\n            \"offset_params\": (0.5, 2.0), \"data_gen_func\": _generate_data_nb,\n            \"S\": S, \"alpha\": alpha\n        },\n        # Case B: Zero-inflated relative to the fitted Negative Binomial\n        {\n            \"seed\": 424242, \"n\": 800, \"beta0\": -1.0, \"beta1\": 0.8, \"theta\": 12.0,\n            \"offset_params\": (0.5, 2.0), \"data_gen_func\": _generate_data_zinb,\n            \"S\": S, \"alpha\": alpha, \"pi\": 0.5\n        },\n        # Case C: Underdispersed (Poisson) relative to the fitted Negative Binomial\n        {\n            \"seed\": 999, \"n\": 600, \"beta0\": 1.0, \"beta1\": 0.3, \"theta\": 1.5,\n            \"offset_params\": 5.0, \"data_gen_func\": _generate_data_poisson,\n            \"S\": S, \"alpha\": alpha\n        }\n    ]\n    \n    results = []\n    for case_params in test_cases:\n        case_result = _run_diagnostics(case_params)\n        results.append(case_result)\n        \n    # Format the final output string to remove spaces, as per spec hint.\n    formatted_results = [f\"[{b1},{b2},{b3}]\" for b1, b2, b3 in results]\n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    print(final_output)\n\nsolve()\n```"
        }
    ]
}