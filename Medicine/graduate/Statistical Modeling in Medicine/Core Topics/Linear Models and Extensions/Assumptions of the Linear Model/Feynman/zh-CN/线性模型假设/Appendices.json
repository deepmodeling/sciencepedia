{
    "hands_on_practices": [
        {
            "introduction": "在任何回归分析中，评估我们的结论是否过度依赖于少数几个特定的数据点是至关重要的。这项练习深入探讨了影响力诊断的核心，您将推导出删除单个观测值如何改变回归系数的精确数学表达式。通过理解这种关系，您将深入了解杠杆率和残差在确定数据点影响力方面的基本作用，这是构建稳健医学模型的关键技能。",
            "id": "4952702",
            "problem": "考虑一项多中心随机对照试验（RCT），其中收缩压通过一个线性预测变量进行建模，该模型满足经典高斯-马尔可夫条件：条件均值的线性性、设计矩阵的列满秩、误差 $\\varepsilon$ 独立同分布且均值为 $0$、方差为常数 $\\sigma^{2}$，以及协变量的测量无误差。设设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，其中 $p=3$ 列，分别对应于截距项、中心化后的年龄以及一个二元处理指示变量。普通最小二乘估计量定义为 $\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。\n\n您删除了单个患者 $j$，其行向量为 $x_{j} \\in \\mathbb{R}^{3}$，并观察到其残差为 $r_{j} = y_{j} - x_{j}^{\\top}\\hat{\\beta}$。从高斯-马尔可夫框架和普通最小二乘法正规方程出发，并仅使用秩为1的谢尔曼-莫里森恒等式来更新矩阵的逆，推导因删除患者 $j$ 而导致的系数变化的精确解析表达式，即 $\\,\\hat{\\beta}_{(j)} - \\hat{\\beta}\\,$，该表达式需用 $x_{j}$、$(X^{\\top}X)^{-1}$、$r_{j}$ 和杠杆值 $h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j}$ 来表示。解释该表达式如何揭示杠杆值和残差在医学回归诊断中使用的标准影响度量中的作用。\n\n然后，对于一个特定的研究中心，假设在全样本上估计出以下量：\n$$\n(X^{\\top}X)^{-1} \\;=\\;\n\\begin{pmatrix}\n0.052  0  0 \\\\\n0  0.00225  0 \\\\\n0  0  0.008\n\\end{pmatrix},\n\\qquad\nx_{j} \\;=\\; \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix},\n\\qquad\nr_{j} \\;=\\; 2.1.\n$$\n计算因删除患者 $j$ 而引起的治疗效应系数（$\\hat{\\beta}$ 的第三个分量）变化的数值。治疗效应系数的单位是毫米汞柱 (mmHg)。将您的最终数值答案四舍五入到四位有效数字。给出最终数值；带框的答案中不要包含单位。",
            "solution": "该问题要求推导删除单个观测值后普通最小二乘（OLS）回归系数的变化量，然后进行数值计算。此过程始于对问题陈述的形式化验证。\n\n### 第一步：提取已知条件\n- **模型**：收缩压的线性回归模型。\n- **假设**：经典高斯-马尔可夫条件成立。\n- **设计矩阵**：$X \\in \\mathbb{R}^{n \\times p}$，其中 $p=3$。各列分别为截距项、中心化后的年龄和一个二元处理指示变量。\n- **OLS估计量**：$\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。\n- **观测值删除**：删除行向量为 $x_{j} \\in \\mathbb{R}^{3}$ 的患者 $j$。\n- **残差**：$r_{j} = y_{j} - x_{j}^{\\top}\\hat{\\beta}$。\n- **杠杆值**：$h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j}$。\n- **任务1（推导）**：使用谢尔曼-莫里森恒等式推导 $\\hat{\\beta}_{(j)} - \\hat{\\beta}$，用 $x_{j}$、$(X^{\\top}X)^{-1}$、$r_{j}$ 和 $h_{jj}$ 表示。\n- **任务2（解释）**：解释推导出的表达式如何揭示杠杆值和残差在影响度量中的作用。\n- **任务3（计算）**：根据以下给定数据，计算第三个系数（治疗效应）的数值变化：\n$$ (X^{\\top}X)^{-1} = \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix}, \\qquad x_{j} = \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix}, \\qquad r_{j} = 2.1 $$\n- **四舍五入**：将最终数值答案四舍五入到四位有效数字。\n\n### 第二步：使用提取的已知条件进行验证\n依据验证标准对问题进行评估。\n- **科学性**：该问题设定在线性回归理论和诊断的标准、成熟框架内。OLS、高斯-马尔可夫条件、残差、杠杆值和影响诊断（如此次推导产生的DFBETAS）等概念是统计建模的基础。医学试验的应用背景是恰当的。\n- **适定性**：问题陈述清晰。它要求一个特定的标准推导和随后的数值计算。两部分所需的所有信息均已提供。存在唯一、稳定且有意义的解。\n- **客观性**：问题以精确的数学和统计语言表达，没有歧义或主观内容。\n\n### 第三步：结论与行动\n该问题具有科学性、适定性、客观性和完整性。因此，它被判定为**有效**。将继续进行求解。\n\n### 系数变化量的推导\n设 $X$ 和 $y$ 为完整的数据矩阵。OLS估计量是正规方程的解：$X^{\\top}X \\hat{\\beta} = X^{\\top}y$。\n设 $X_{(j)}$ 和 $y_{(j)}$ 表示移除了第 $j$ 个观测值后的数据。新的估计量 $\\hat{\\beta}_{(j)}$ 由下式给出：\n$$ \\hat{\\beta}_{(j)} = (X_{(j)}^{\\top}X_{(j)})^{-1} X_{(j)}^{\\top}y_{(j)} $$\n缩减数据集的矩阵可以用完整数据集的矩阵和被删除观测值的数据 $x_j$ 和 $y_j$ 来表示：\n$$ X^{\\top}X = \\sum_{i=1}^{n} x_i x_i^{\\top} = X_{(j)}^{\\top}X_{(j)} + x_j x_j^{\\top} \\implies X_{(j)}^{\\top}X_{(j)} = X^{\\top}X - x_j x_j^{\\top} $$\n$$ X^{\\top}y = \\sum_{i=1}^{n} x_i y_i = X_{(j)}^{\\top}y_{(j)} + x_j y_j \\implies X_{(j)}^{\\top}y_{(j)} = X^{\\top}y - x_j y_j $$\n为了求 $X_{(j)}^{\\top}X_{(j)}$ 的逆，我们使用秩为1更新的谢尔曼-莫里森恒等式：$(A - uv^{\\top})^{-1} = A^{-1} + \\frac{A^{-1}uv^{\\top}A^{-1}}{1 - v^{\\top}A^{-1}u}$。\n令 $A = X^{\\top}X$，$u = x_j$，$v = x_j$。该恒等式变为：\n$$ (X^{\\top}X - x_j x_j^{\\top})^{-1} = (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - x_j^{\\top}(X^{\\top}X)^{-1}x_j} $$\n识别出杠杆值 $h_{jj} = x_j^{\\top}(X^{\\top}X)^{-1}x_j$，我们有：\n$$ (X_{(j)}^{\\top}X_{(j)})^{-1} = (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - h_{jj}} $$\n现在，我们将这些表达式代入 $\\hat{\\beta}_{(j)}$ 的公式中：\n$$ \\hat{\\beta}_{(j)} = \\left[ (X^{\\top}X)^{-1} + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}}{1 - h_{jj}} \\right] (X^{\\top}y - x_j y_j) $$\n展开乘积得到四项：\n$$ \\hat{\\beta}_{(j)} = (X^{\\top}X)^{-1}(X^{\\top}y) - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}(X^{\\top}y)}{1 - h_{jj}} - \\frac{(X^{\\top}X)^{-1}x_j x_j^{\\top}(X^{\\top}X)^{-1}x_j y_j}{1 - h_{jj}} $$\n我们简化每一项：\n1. $(X^{\\top}X)^{-1}(X^{\\top}y) = \\hat{\\beta}$\n2. $x_j^{\\top}(X^{\\top}X)^{-1}(X^{\\top}y) = x_j^{\\top}\\hat{\\beta} = \\hat{y}_j$ (观测值 $j$ 的拟合值)\n3. $x_j^{\\top}(X^{\\top}X)^{-1}x_j = h_{jj}$ (观测值 $j$ 的杠杆值)\n\n将这些代回：\n$$ \\hat{\\beta}_{(j)} = \\hat{\\beta} - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j \\hat{y}_j}{1 - h_{jj}} - \\frac{(X^{\\top}X)^{-1}x_j h_{jj} y_j}{1 - h_{jj}} $$\n我们关心的是变化量 $\\hat{\\beta}_{(j)} - \\hat{\\beta}$：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = - (X^{\\top}X)^{-1}x_j y_j + \\frac{(X^{\\top}X)^{-1}x_j (\\hat{y}_j - h_{jj} y_j)}{1 - h_{jj}} $$\n提出公因子向量 $(X^{\\top}X)^{-1}x_j$：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = (X^{\\top}X)^{-1}x_j \\left[ -y_j + \\frac{\\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] $$\n将方括号内的项合并到同一个分母下：\n$$ \\left[ \\frac{-y_j(1 - h_{jj}) + \\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] = \\left[ \\frac{-y_j + y_j h_{jj} + \\hat{y}_j - h_{jj} y_j}{1 - h_{jj}} \\right] = \\frac{\\hat{y}_j - y_j}{1 - h_{jj}} $$\n残差定义为 $r_j = y_j - \\hat{y}_j$，因此 $\\hat{y}_j - y_j = -r_j$。于是，方括号内的表达式简化为 $\\frac{-r_j}{1 - h_{jj}}$。\n将此结果代回，得到系数变化量的最终表达式：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = -\\frac{(X^{\\top}X)^{-1}x_j r_j}{1 - h_{jj}} $$\n\n### 影响的解释\n这个精确表达式，有时记作 DFBETA$_j$，量化了观测值 $j$ 对估计系数向量 $\\hat{\\beta}$ 的影响。它揭示了一个观测值的影响是两个关键量的函数：\n1.  **残差 ($r_j$)**：变化量与残差 $r_j$ 成正比。只有当一个观测值不能被拟合了完整数据的模型很好地预测时，它才具有影响力。一个远离数据总体趋势的点（即 $|r_j|$ 很大）有潜力成为影响点。如果 $r_j=0$，那么无论该观测值具有何种其他属性，它对系数都没有影响。\n2.  **杠杆值 ($h_{jj}$)**：变化量被因子 $1/(1 - h_{jj})$ 放大。杠杆值 $h_{jj}$ 衡量了一个观测值的协变量值 ($x_j$) 有多么不寻常或极端。由于 $0 \\le h_{jj} \\le 1$，分母 $1 - h_{jj}$ 总是非负的。当 $h_{jj} \\to 1$ 时，分母趋近于 $0$，对系数的影响可能变得任意大。因此，具有高杠杆值（协变量离群点）的点有更大的潜力成为影响点。\n\n总之，如果一个观测值具有大残差（它是响应维度上的离群点）和/或高杠杆值（它是预测变量空间中的离群点），那么它就是有影响力的。推导出的公式表明，当一个观测值同时具有高杠杆值和大残差时，其影响力最大。\n\n### 数值计算\n我们需要计算第三个系数（治疗效应）的变化量，我们将其记为 $(\\hat{\\beta}_{(j)} - \\hat{\\beta})_3$。完整的变化向量是：\n$$ \\hat{\\beta}_{(j)} - \\hat{\\beta} = -\\frac{r_j}{1 - h_{jj}} (X^{\\top}X)^{-1}x_j $$\n首先，我们计算杠杆值 $h_{jj}$：\n$$ h_{jj} = x_{j}^{\\top}(X^{\\top}X)^{-1}x_{j} $$\n$$ h_{jj} = \\begin{pmatrix} 1  -0.3  1 \\end{pmatrix} \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix} $$\n由于 $(X^{\\top}X)^{-1}$ 是对角矩阵，计算简化为：\n$$ h_{jj} = (1)^2(0.052) + (-0.3)^2(0.00225) + (1)^2(0.008) $$\n$$ h_{jj} = 0.052 + (0.09)(0.00225) + 0.008 $$\n$$ h_{jj} = 0.052 + 0.0002025 + 0.008 = 0.0602025 $$\n接下来，我们计算向量 $(X^{\\top}X)^{-1}x_j$：\n$$ (X^{\\top}X)^{-1}x_j = \\begin{pmatrix} 0.052  0  0 \\\\ 0  0.00225  0 \\\\ 0  0  0.008 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -0.3 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0.052 \\times 1 \\\\ 0.00225 \\times (-0.3) \\\\ 0.008 \\times 1 \\end{pmatrix} = \\begin{pmatrix} 0.052 \\\\ -0.000675 \\\\ 0.008 \\end{pmatrix} $$\n该向量的第三个分量是 $0.008$。\n现在，我们可以使用给定的 $r_j = 2.1$ 来计算第三个系数的变化量：\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{r_j}{1 - h_{jj}} \\times \\left( (X^{\\top}X)^{-1}x_j \\right)_3 $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{2.1}{1 - 0.0602025} \\times 0.008 $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 = -\\frac{2.1 \\times 0.008}{0.9397975} = -\\frac{0.0168}{0.9397975} $$\n$$ (\\hat{\\beta}_{(j)} - \\hat{\\beta})_3 \\approx -0.01787618... $$\n四舍五入到四位有效数字，我们得到 $-0.01788$。",
            "answer": "$$\\boxed{-0.01788}$$"
        },
        {
            "introduction": "普通最小二乘法的基石之一是等方差性，即误差方差恒定。这个动手编码练习将引导您完成处理异方差性的完整工作流程，异方差性是医学数据中的一个常见问题，其变异性可能取决于预测变量的值。您将实施加权最小二乘法 (WLS) 作为补救措施，然后应用一套专业级的诊断测试来验证转换是否成功地恢复了等方差性。",
            "id": "4952713",
            "problem": "要求您形式化一个拟合后验证计划，用于评估在线性回归应用于医学数据的背景下，加权最小二乘法（WLS）是否已近似实现同方差残差。您的任务是实现一个完整的程序来执行此计划，该程序需生成合成数据，拟合WLS模型，对变换后的残差进行拟合后诊断，并判断同方差性假设是否近似满足。您的实现必须基于基本定义和经过充分检验的公式，不得依赖外部文件或用户输入。\n\n基本原理：\n- 线性模型定义为 $y_i = \\mathbf{x}_i^{\\top}\\boldsymbol{\\beta} + \\varepsilon_i$，其中 $i = 1,\\dots,n$，$\\mathbf{x}_i \\in \\mathbb{R}^p$ 是已知预测变量，$\\boldsymbol{\\beta} \\in \\mathbb{R}^p$ 是未知系数，$\\varepsilon_i$ 是随机误差。\n- 同方差性是假设 $\\mathrm{Var}(\\varepsilon_i) = \\sigma^2$ 对所有 $i$ 保持恒定。\n- 当误差是异方差的，即 $\\mathrm{Var}(\\varepsilon_i)=\\sigma^2 v_i$，且 $v_i$ 在相差一个常数倍数的情况下是已知的，加权最小二乘法 (WLS) 通过权重 $w_i = v_i^{-1/2}$ 进行重新缩放，以获得变换后的模型 $y_i^{\\ast} = w_i y_i$ 和 $\\mathbf{x}_i^{\\ast} = w_i \\mathbf{x}_i$。在正确设定的情况下，该模型满足 $\\mathrm{Var}(y_i^{\\ast} - \\mathbf{x}_i^{\\ast \\top}\\boldsymbol{\\beta}) = \\sigma^2$。这是 WLS 的核心依据。\n\n您的程序必须：\n1. 在具有潜在异方差误差的线性模型下生成数据，使用指定的随机种子 $s$、样本量 $n$、系数向量 $\\boldsymbol{\\beta} = (\\beta_0,\\beta_1)^{\\top}$、基线尺度 $\\sigma_0$ 以及异方差模式 $v_i = 1 + a |x_i|$（其中 $x_i \\sim \\mathcal{N}(0,1)$）。误差必须从 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_0^2 v_i)$ 中独立抽取。结果变量为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$。\n2. 使用权重 $w_i = (1 + a |x_i|)^{-p}$ 拟合加权最小二乘法 (WLS) 模型，其中 $p$ 由每个测试用例指定。通过用 $w_i$ 变换 $y_i$ 和 $\\mathbf{x}_i$，并使用线性代数对变换后的数据拟合普通最小二乘法 (OLS) 来实现 WLS。令 $\\widehat{\\boldsymbol{\\beta}}$ 表示系数估计值，$\\widehat{y}_i = \\mathbf{x}_i^{\\top}\\widehat{\\boldsymbol{\\beta}}$ 表示拟合值，$e_i = y_i - \\widehat{y}_i$ 表示原始残差。定义变换后的残差为 $r_i = w_i e_i$。以下所有拟合后诊断都必须使用 $\\{r_i\\}$ 和 $\\{\\widehat{y}_i\\}$ 进行计算。\n3. 计算以下拟合后诊断，以评估 $r_i$ 是否近似同方差：\n   - Breusch–Pagan 检验：将 $r_i^2$ 对截距项和原始预测变量 $x_i$ 进行回归，以获得决定系数 $R^2$。构建拉格朗日乘数统计量 $LM = n R^2$，并将其与自由度为 $k$ 的卡方分布进行比较，其中 $k$ 是非截距项回归变量的数量（此处 $k=1$）。使用卡方分布计算 $p$ 值。使用显著性水平 $\\alpha = 0.05$。\n   - 基于秩的趋势检验：计算 $|\\!r_i\\!|$ 和 $\\widehat{y}_i$ 之间的 Spearman 秩相关，以检验残差相对于拟合值的单调尺度趋势。记录相关系数 $\\rho_S$ 及其 $p$ 值。使用相关性大小阈值 $\\rho_{\\max} = 0.1$ 和显著性水平 $\\alpha = 0.05$。\n   - 分箱方差比：将拟合值 $\\{\\widehat{y}_i\\}$ 划分为四分位数。计算最低四分位数区间和最高四分位数区间中 $r_i^2$ 的均值，记为 $\\bar{v}_{\\mathrm{low}}$ 和 $\\bar{v}_{\\mathrm{high}}$，并构建比率 $Q = \\bar{v}_{\\mathrm{high}}/\\bar{v}_{\\mathrm{low}}$。使用接受界限 $Q \\in [0.7, 1.4]$。\n4. 决策规则：当且仅当以下所有条件同时成立时，宣布 WLS 已近似实现同方差残差：Breusch–Pagan 检验的 $p$ 值至少为 $\\alpha$，Spearman 检验的 $p$ 值至少为 $\\alpha$ 且 $|\\rho_S| \\le \\rho_{\\max}$，并且分箱方差比 $Q$ 位于区间 $[0.7, 1.4]$ 内。\n\n不涉及角度单位。不涉及物理单位。所有概率必须以小数表示。所有阈值均已在上方明确给出。\n\n测试套件：\n实现您的程序以运行以下四个测试用例，每个用例由 $(n, s, \\beta_0, \\beta_1, \\sigma_0, a, p)$ 定义：\n- 用例 1（理想路径，对强异方差数据使用正确设定的WLS）：$(n, s, \\beta_0, \\beta_1, \\sigma_0, a, p) = (800, 202311, 1.0, 2.0, 1.0, 4.0, 0.5)$。\n- 用例 2（异方差数据，使用未加权的 OLS 作为阴性对照）：$(800, 202311, 1.0, 2.0, 1.0, 4.0, 0.0)$。\n- 用例 3（异方差数据，错误设定的过度加权）：$(800, 202311, 1.0, 2.0, 1.0, 4.0, 1.0)$。\n- 用例 4（同方差数据，OLS 基线）：$(600, 909, 0.5, -1.0, 1.0, 0.0, 0.0)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为按上述用例顺序排列的结果，布尔文字使用小写。例如，如果第一个、第二个和第四个用例满足决策规则，而第三个不满足，则输出必须严格采用以下形式：[true,false,false,true]。",
            "solution": "该问题是有效的。它提出了一个统计建模中明确定义的任务：实现一个程序化的验证计划，用以评估在线性模型应用加权最小二乘法 (WLS) 后，同方差性假设是否成立。该问题基于成熟的统计理论，具有科学依据，提供了所有必要的参数和定义，并概述了一个清晰、客观的决策过程。\n\n解决方案是指定验证计划的逐步实现。WLS 的核心原理是通过对每个观测值应用与其误差项标准差成反比的权重，来对抗异方差性（即误差的非恒定方差）。如果权重被正确指定，变换后的模型将呈现同方差残差，这是后续统计推断有效性的一个关键假设。以下过程将此流程形式化。\n\n步骤 1：数据生成\n对于每个测试用例，我们根据指定的线性模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 生成合成数据。\n- 从标准正态分布 $x_i \\sim \\mathcal{N}(0, 1)$ 中抽取一个包含 $n$ 个预测变量 $x_i$ 的向量。设计矩阵为 $\\mathbf{X} \\in \\mathbb{R}^{n \\times 2}$，其第一列全为 1（用于截距 $\\beta_0$），第二列包含 $x_i$ 的值。\n- 误差项 $\\varepsilon_i$ 从均值为 0、方差非恒定的正态分布中生成，其中 $\\mathrm{Var}(\\varepsilon_i) = \\sigma_0^2 v_i$，异方差模式由 $v_i = 1 + a |x_i|$ 给出。因此，误差从 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma_0^2 (1 + a |x_i|))$ 中抽取。\n- 响应变量 $y_i$ 计算为确定性部分 $\\beta_0 + \\beta_1 x_i$ 与随机误差 $\\varepsilon_i$ 之和。\n\n步骤 2：加权最小二乘法 (WLS) 估计\nWLS 过程旨在找到最小化加权残差平方和 $\\sum_{i=1}^n w_i^2 (y_i - \\mathbf{x}_i^{\\top} \\boldsymbol{\\beta})^2$ 的系数向量 $\\widehat{\\boldsymbol{\\beta}}$。这等价于对一个变换后的模型执行普通最小二乘法 (OLS) 回归。\n- 权重定义为 $w_i = (1 + a |x_i|)^{-p}$。参数 $p$ 控制加权的强度。为对抗指定的异方差性，理论上的最优选择是 $p=0.5$，因为这使得 $w_i \\propto v_i^{-1/2}$。\n- 数据被变换：变换后的预测变量为 $\\mathbf{x}_i^{\\ast} = w_i \\mathbf{x}_i$，变换后的响应为 $y_i^{\\ast} = w_i y_i$。用矩阵表示法，$\\mathbf{X}^{\\ast} = \\mathbf{W}\\mathbf{X}$ 且 $\\mathbf{y}^{\\ast} = \\mathbf{W}\\mathbf{y}$，其中 $\\mathbf{W}$ 是一个对角元素为 $w_i$ 的对角矩阵。\n- WLS 估计值 $\\widehat{\\boldsymbol{\\beta}}$ 是通过将 OLS 公式应用于变换后的数据得到的：\n$$ \\widehat{\\boldsymbol{\\beta}} = (\\mathbf{X}^{\\ast\\top} \\mathbf{X}^{\\ast})^{-1} \\mathbf{X}^{\\ast\\top} \\mathbf{y}^{\\ast} $$\n- 从 $\\widehat{\\boldsymbol{\\beta}}$ 出发，我们计算原始尺度上的拟合值 $\\widehat{y}_i = \\mathbf{x}_i^{\\top}\\widehat{\\boldsymbol{\\beta}}$ 和原始残差 $e_i = y_i - \\widehat{y}_i$。用于诊断的关键对象是变换后的残差 $r_i = w_i e_i$，它们是变换后模型拟合的残差。如果 WLS 成功，集合 $\\{r_i\\}$ 应近似为同方差。\n\n步骤 3：拟合后诊断检验\n我们对变换后的残差 $\\{r_i\\}$ 执行三个检验，以评估是否已实现同方差性。\n\n- **Breusch–Pagan 检验**：该检验用于检查一种特定形式的异方差性，即残差方差与一个或多个预测变量呈线性关系。我们将平方变换残差 $r_i^2$ 对一个截距项和原始预测变量 $x_i$ 进行回归：$r_i^2 = \\gamma_0 + \\gamma_1 x_i + u_i$。从此辅助回归中得到的决定系数 $R^2$ 用于构建拉格朗日乘数统计量 $LM = n R^2$。在同方差性的原假设下，$LM$ 服从自由度为 $k=1$（因为只有一个回归变量 $x_i$）的卡方分布。根据此 $\\chi^2_1$ 分布计算一个 $p$ 值。如果该 $p$ 值大于或等于显著性水平 $\\alpha=0.05$，我们则认为同方差性是合理的。\n\n- **基于秩的趋势检验**：该检验用于检测残差大小相对于拟合值的单调趋势，这是异方差性的另一个迹象。我们计算绝对变换残差 $|\\!r_i\\!|$ 与拟合值 $\\widehat{y}_i$ 之间的 Spearman 秩相关系数 $\\rho_S$。如果满足两个条件，则认为检验通过：相关性在统计上不显著（即其 $p$ 值至少为 $\\alpha=0.05$），且其绝对值很小（$|\\rho_S| \\le \\rho_{\\max}=0.1$）。\n\n- **分箱方差比**：这是一种用于检查方差趋势的直接、启发式方法。数据按其拟合值 $\\widehat{y}_i$ 排序，并划分为四分位数。我们计算最低四分位数区间 ($\\bar{v}_{\\mathrm{low}}$) 和最高四分位数区间 ($\\bar{v}_{\\mathrm{high}}$) 内观测值的平方变换残差均值 $\\mathrm{mean}(r_i^2)$。然后构建比率 $Q = \\bar{v}_{\\mathrm{high}} / \\bar{v}_{\\mathrm{low}}$。如果残差是同方差的，这个比率应该接近 1。如果 $Q$ 落在接受区间 $[0.7, 1.4]$ 内，则检验通过。\n\n步骤 4：最终决策\n当且仅当所有三个诊断检验同时通过时，一个测试用例才被认为成功实现了近似同方差残差。最终输出是一个布尔值（`true` 或 `false`），指示测试套件中每个用例的结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import chi2, spearmanr\n\ndef run_wls_validation(n, s, beta0, beta1, sigma0, a, p):\n    \"\"\"\n    Runs the full WLS validation plan for a single test case.\n    \n    Args:\n        n (int): Sample size.\n        s (int): Random seed.\n        beta0 (float): True intercept.\n        beta1 (float): True slope.\n        sigma0 (float): Baseline error scale.\n        a (float): Heteroscedasticity parameter.\n        p (float): Weighting power for WLS.\n\n    Returns:\n        bool: True if all homoscedasticity checks pass, False otherwise.\n    \"\"\"\n    # 1. Generate Data\n    rng = np.random.default_rng(s)\n    \n    # Generate predictors x_i ~ N(0,1)\n    x = rng.normal(loc=0.0, scale=1.0, size=n)\n    \n    # Construct design matrix X = [1, x]\n    X = np.c_[np.ones(n), x]\n    \n    # Define true heteroscedastic variance pattern v_i = 1 + a*|x_i|\n    v = 1.0 + a * np.abs(x)\n    \n    # Generate heteroscedastic errors e_i ~ N(0, sigma0^2 * v_i)\n    error_std_devs = sigma0 * np.sqrt(v)\n    epsilon = rng.normal(loc=0.0, scale=error_std_devs, size=n)\n    \n    # Generate outcome y_i = beta0 + beta1*x_i + epsilon_i\n    beta_true = np.array([beta0, beta1])\n    y = X @ beta_true + epsilon\n    \n    # 2. Fit Weighted Least Squares (WLS)\n    # Define weights w_i = (1 + a*|x_i|)^(-p)\n    weights = (1.0 + a * np.abs(x)) ** (-p)\n    \n    # Transform data: X* = WX, y* = Wy\n    X_star = weights[:, np.newaxis] * X\n    y_star = weights * y\n    \n    # Compute WLS coefficients via OLS on transformed data\n    # beta_hat = (X*^T X*)^-1 X*^T y*\n    try:\n        beta_hat = np.linalg.inv(X_star.T @ X_star) @ X_star.T @ y_star\n    except np.linalg.LinAlgError:\n        # Failsafe for singular matrix, unlikely here.\n        return False\n\n    # Calculate fitted values on original scale and transformed residuals\n    y_hat = X @ beta_hat\n    raw_residuals = y - y_hat\n    transformed_residuals = weights * raw_residuals\n    \n    # 3. Perform Post-fit Diagnostics on transformed residuals\n    \n    # 3a. Breusch-Pagan Test\n    r_sq = transformed_residuals**2\n    # Auxiliary regression: r_sq on an intercept and x\n    Z_bp = np.c_[np.ones(n), x]\n    \n    try:\n        # beta_bp = (Z_bp^T Z_bp)^-1 Z_bp^T r_sq\n        gamma_hat = np.linalg.inv(Z_bp.T @ Z_bp) @ Z_bp.T @ r_sq\n    except np.linalg.LinAlgError:\n        return False\n        \n    r_sq_hat = Z_bp @ gamma_hat\n    ss_res_bp = np.sum((r_sq - r_sq_hat)**2)\n    ss_tot_bp = np.sum((r_sq - np.mean(r_sq))**2)\n    \n    R2_bp = 1.0 - ss_res_bp / ss_tot_bp if ss_tot_bp > 0 else 0.0\n        \n    LM_statistic = n * R2_bp\n    bp_p_value = 1.0 - chi2.cdf(LM_statistic, df=1)\n    bp_pass = bp_p_value >= 0.05\n\n    # 3b. Rank-based Trend Test (Spearman)\n    spearman_result = spearmanr(np.abs(transformed_residuals), y_hat)\n    rho_S = spearman_result.correlation\n    spearman_p_value = spearman_result.pvalue\n    spearman_pass = (spearman_p_value >= 0.05) and (np.abs(rho_S) = 0.1)\n\n    # 3c. Binned Variance Ratio\n    q1 = np.percentile(y_hat, 25)\n    q3 = np.percentile(y_hat, 75)\n    \n    low_quartile_mask = y_hat = q1\n    high_quartile_mask = y_hat >= q3\n    \n    # Failsafe for empty bins\n    if not np.any(low_quartile_mask) or not np.any(high_quartile_mask):\n        return False\n        \n    v_low = np.mean(r_sq[low_quartile_mask])\n\n    # Failsafe for division by zero\n    if v_low == 0:\n        return False\n\n    v_high = np.mean(r_sq[high_quartile_mask])\n    Q = v_high / v_low\n    binned_pass = (Q >= 0.7) and (Q = 1.4)\n\n    # 4. Final Decision Rule\n    return bp_pass and spearman_pass and binned_pass\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Correctly specified WLS\n        (800, 202311, 1.0, 2.0, 1.0, 4.0, 0.5),\n        # Case 2: OLS on heteroscedastic data (negative control)\n        (800, 202311, 1.0, 2.0, 1.0, 4.0, 0.0),\n        # Case 3: Mis-specified WLS (overweighting)\n        (800, 202311, 1.0, 2.0, 1.0, 4.0, 1.0),\n        # Case 4: OLS on homoscedastic data (baseline)\n        (600, 909, 0.5, -1.0, 1.0, 0.0, 0.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, s, beta0, beta1, sigma0, a, p = case\n        result = run_wls_validation(n, s, beta0, beta1, sigma0, a, p)\n        results.append(str(result).lower())\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "医学研究通常涉及对同一名患者随时间进行重复测量，这违反了误差独立的关键假设。这项高级练习将指导您实施一种强大的技术，即可行广义最小二乘法 (FGLS)，以正确地对此类序列相关性进行建模。通过明确处理纵向数据中常见的 AR(1) 误差结构，您将学会在复杂的数据环境中获得更有效、更可靠的估计。",
            "id": "4952775",
            "problem": "一个医学研究团队研究在每位患者内部、按相等时间间隔的门诊中进行的重复实验室测量，并将这些测量数据在患者间汇总。考虑一个由跨患者堆叠观测值构成的线性模型，表示为 $y = X \\beta + \\varepsilon$，其中 $y$ 是一个 $n \\times 1$ 的响应向量，$X$ 是一个 $n \\times p$ 的设计矩阵，$\\beta$ 是一个 $p \\times 1$ 的系数向量，$\\varepsilon$ 是一个 $n \\times 1$ 的误差项向量。假设 $E[\\varepsilon] = 0$ 且误差在患者间是独立的。在每位患者内部，误差由一个平稳的一阶自回归过程（滞后一阶）生成，这意味着对于由 $|t-s|$ 次等间隔访视分开的患者内时间指数 $t$ 和 $s$，其协方差为 $\\text{Cov}(\\varepsilon_t,\\varepsilon_s) = \\sigma^2 \\rho^{|t-s|}$，其中 $|\\rho|  1$ 且 $\\sigma^2 > 0$。Gauss–Markov 定理和广义最小二乘法理论表明，当协方差结构已知时，最小化均方误差的线性无偏估计量使用逆协方差对观测值进行加权。当相关参数未知但结构形式已指定时，可行广义最小二乘法程序会从数据中估计相关参数，并将其代入加权最小二乘准则。\n\n您的任务是，从第一性原理出发，推导并实现一个专门针对上述患者内自回归设定的两步可行广义最小二乘算法，并将其应用于三个固定的测试数据集。从线性无偏估计、高斯误差下的二次损失最小化以及一阶自回归相关的核心定义开始。不要依赖任何预先编码的线性模型快捷方式。您必须显式地构建并应用一个患者内的线性变换，如果代入的相关性是正确的，该变换将使误差变得不相关，然后在变换后的系统上计算普通最小二乘估计量。\n\n科学真实性约束：将每次访视视为在每位患者内部等间隔发生，将患者视为独立的聚类，并将测量时间视为无单位的访视指数。在 $X$ 中使用一个截距项和一个单一的时间协变量。不允许使用其他协变量。\n\n待推导和实现的算法规范：\n- 构建包含两列的 $X$：一列全为1（截距项），另一列包含患者内的访视指数 $t \\in \\{0,1,2,\\dots\\}$。\n- 对未经变换的堆叠数据进行初始普通最小二乘拟合以获得残差。\n- 通过最小化由一阶自回归在所有患者中引发的单步前向线性预测误差的平方和来估计自回归参数，仅聚合同一患者内的相邻对。将估计值约束在 $(-1,1)$ 严格区间内。\n- 使用代入的相关性估计，构建一个按患者的线性变换，将原始模型映射到一个在自回归模型下误差不相关的模型。将此变换应用于 $y$ 和 $X$。\n- 在变换后的系统上进行普通最小二乘拟合，以获得 $\\beta$ 的可行广义最小二乘估计，并将变换后残差平方和除以 $n - p$ 来计算残差方差估计。\n\n测试套件和数据：\n您必须在以下三个固定的数据集上运行您的实现。每个数据集由从 $t=0$ 开始、访视间隔相等的患者组成，按所列顺序堆叠。对于每位患者，响应值按访视顺序列出。\n\n- 测试案例1（平衡面板，3名患者，每人5次访视）：\n  - 患者1：响应 $\\{\\,10.0,9.55,9.25,8.95,8.7\\,\\}$\n  - 患者2：响应 $\\{\\,11.0,10.5,10.2,9.9,9.6\\,\\}$\n  - 患者3：响应 $\\{\\,9.2,8.9,8.6,8.4,8.1\\,\\}$\n\n- 测试案例2（非平衡面板，长度可变）：\n  - 患者1（访视 $t = 0,1,2,3$）：响应 $\\{\\,7.5,7.6,7.4,7.3\\,\\}$\n  - 患者2（访视 $t = 0,1,2$）：响应 $\\{\\,8.0,7.7,7.5\\,\\}$\n  - 患者3（访视 $t = 0,1,2,3,4,5$）：响应 $\\{\\,6.0,6.2,6.1,5.9,5.8,5.6\\,\\}$\n\n- 测试案例3（患者内接近单位根的持久性）：\n  - 患者1（访视 $t = 0,1,2,3,4,5,6,7$）：响应 $\\{\\,12.0,11.9,11.85,11.8,11.78,11.77,11.75,11.74\\,\\}$\n  - 患者2（访视 $t = 0,1,2,3,4,5,6,7$）：响应 $\\{\\,10.0,9.95,9.92,9.9,9.88,9.87,9.86,9.85\\,\\}$\n\n在所有数据集中，使用 $X = [\\mathbf{1}, t]$，其中 $t$ 对每位患者从0重新开始，并在患者内部每次访视递增1。将患者视为独立的聚类。\n\n输出规范：\n对于每个测试案例，按此顺序生成一个包含四个值的列表：代入的相关性估计 $\\hat{\\rho}$，可行广义最小二乘系数估计 $\\hat{\\beta}_0$（截距项）和 $\\hat{\\beta}_1$（时间斜率），以及变换后残差的方差估计 $\\hat{\\sigma}^2$。将每个值四舍五入到6位小数。您的程序应生成单行输出，其中包含所有三个测试案例的结果，格式为方括号括起来的逗号分隔的列表的列表，例如 $[\\,[r\\_1, r\\_2, r\\_3, r\\_4], [\\dots], [\\dots]\\,]$，其中每个 $r\\_j$ 是一个四舍五入到6位小数的实数。\n\n边缘情况和边界要求：\n- 通过将任何在 $(-1,1)$ 之外的估计值截断回最接近的内部值来强制执行 $|\\hat{\\rho}|  1$。\n- 如果患者只有一个观测值，则应用与较长序列的第一个观测值相同的第一行变换，并将其包含在变换后的拟合中。\n- 在计算 $\\hat{\\sigma}^2$ 的自由度时，对每个数据集使用 $p = 2$ 和相应的总 $n$。\n\n您的实现必须是一个完整的、可运行的程序，该程序根据提供的响应构建设计矩阵，精确执行一次可行广义最小二乘算法（无进一步迭代），并打印指定的单行输出。不允许用户输入或外部文件。所有量都必须报告为无单位的数字，并四舍五入到6位小数。",
            "solution": "该问题要求针对一个线性模型推导并实现一个两步可行广义最小二乘（FGLS）算法，该模型在独立的患者聚类内部存在序列相关的误差。误差结构被指定为一阶自回归过程，即 AR(1) 过程。\n\n**1. 问题验证**\n\n首先，我将根据指定标准验证问题陈述。\n\n**步骤1：提取的已知条件**\n- **模型：** $y = X \\beta + \\varepsilon$，其中 $y$ 是一个 $n \\times 1$ 的堆叠响应向量，$X$ 是一个 $n \\times p$ 的设计矩阵，$\\beta$ 是一个 $p \\times 1$ 的系数向量，$\\varepsilon$ 是一个 $n \\times 1$ 的误差项向量。\n- **误差假设：** $E[\\varepsilon] = 0$。误差在患者间是独立的。在任何患者内部，对于时间 $t$ 和 $s$ 的观测值，协方差为 $\\text{Cov}(\\varepsilon_t,\\varepsilon_s) = \\sigma^2 \\rho^{|t-s|}$，其中 $|\\rho|  1$ 且 $\\sigma^2 > 0$。\n- **设计矩阵 ($X$)：** 一列为1用于截距项，一列为患者内部的访视指数 $t \\in \\{0,1,2,\\dots\\}$。因此，$p=2$。\n- **算法规范：**\n    1.  计算初始普通最小二乘法（OLS）残差。\n    2.  通过将残差对其一阶滞后项进行回归，利用患者内部所有相邻对来从 OLS 残差中估计 $\\rho$。估计值 $\\hat{\\rho}$ 必须被约束在 $(-1, 1)$ 区间内。\n    3.  使用 $\\hat{\\rho}$ 构建一个按患者的线性变换矩阵，该矩阵可以消除误差的相关性（Prais-Winsten 变换）。将其应用于 $y$ 和 $X$。\n    4.  在变换后的数据上拟合 OLS，以获得 $\\beta$ 的 FGLS 估计。\n    5.  将残差方差估计为 $\\hat{\\sigma}^2 = \\frac{RSS^*}{n-p}$，其中 $RSS^*$ 是变换后模型的残差平方和。\n- **数据：** 提供了三个测试数据集，患者数量和访视次数各不相同。\n- **输出：** 对于每个案例，报告 $[\\hat{\\rho}, \\hat{\\beta}_0, \\hat{\\beta}_1, \\hat{\\sigma}^2]$，四舍五入到6位小数。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了 FGLS 的应用，这是计量经济学和生物统计学中处理回归模型中序列相关误差的标准和基础技术。AR(1) 误差结构是此类相关的经典模型。指定的两步程序（通常与 Cochrane-Orcutt 或 Prais-Winsten 相关）是教科书级别的内容。该问题在科学上和统计上是合理的。\n- **适定性：** 问题陈述是自洽的。它提供了模型、误差结构、具体数据和一个清晰的、分步的算法。所有术语在统计学中都有明确定义。预期会有一个唯一的解。\n- **客观性：** 问题以客观的数学语言表述，没有偏见或主观断言。\n\n该问题不违反任何无效性标准。它在科学上是合理的、适定的、客观的、完整的并且计算上是可验证的。\n\n**步骤3：结论与行动**\n问题是有效的。我现在将进行推导和求解。\n\n**2. 可行广义最小二乘（FGLS）算法的推导**\n\n指定的线性模型是 $y = X \\beta + \\varepsilon$。观测值按患者聚类，患者间的观测值是独立的，但患者内部的观测值是相关的。对于具有 $n_i$ 个观测值的单个患者 $i$，模型为 $y_i = X_i \\beta + \\varepsilon_i$。误差向量 $\\varepsilon_i$ 的协方差矩阵为 $\\text{Cov}(\\varepsilon_i) = \\Omega_i = \\sigma^2 V_i$，其中 $V_i$ 是 $n_i \\times n_i$ 的相关矩阵，其元素为 $(V_i)_{ts} = \\rho^{|t-s|}$。\n\n广义最小二乘（GLS）估计量是最佳线性无偏估计量（BLUE），由下式给出：\n$$\n\\hat{\\beta}_{GLS} = (X^T \\Omega^{-1} X)^{-1} X^T \\Omega^{-1} y\n$$\n因为 $\\Omega = \\sigma^2 V$，这可以简化为 $\\hat{\\beta}_{GLS} = (X^T V^{-1} X)^{-1} X^T V^{-1} y$。\n\nGLS 估计量可以作为变换后模型上的 OLS 估计量来计算。我们为整个系统寻找一个变换矩阵 $P$，使得变换后的误差 $P\\varepsilon$ 是同方差且不相关的，即 $\\text{Cov}(P\\varepsilon) = \\sigma_u^2 I$。由于误差在患者间是独立的，全局变换矩阵 $P$ 是由特定于患者的变换矩阵 $P_i$ 组成的块对角矩阵。对于每个患者 $i$，我们需要 $P_i$ 使得 $\\text{Cov}(P_i \\varepsilon_i) = P_i (\\sigma^2 V_i) P_i^T = \\sigma_u^2 I_{n_i}$，其中 $I_{n_i}$ 是 $n_i \\times n_i$ 的单位矩阵。\n\nAR(1) 误差过程 $\\varepsilon_t = \\rho \\varepsilon_{t-1} + u_t$（其中 $u_t$ 是均值为0、方差为 $\\sigma_u^2$ 的独立同分布随机变量）为该变换提供了基础。方差之间的关系是 $\\sigma^2 = \\text{Var}(\\varepsilon_t) = \\frac{\\sigma_u^2}{1-\\rho^2}$。\n\n对于观测值 $t = 1, \\dots, n_i-1$（使用基于0的索引），我们可以通过差分来消除序列相关性：\n$$\n\\varepsilon_{i,t} - \\rho \\varepsilon_{i,t-1} = u_{i,t}\n$$\n这些变换后的误差方差为 $\\sigma_u^2$。第一个误差项 $\\varepsilon_{i,0}$ 的方差为 $\\sigma^2 = \\frac{\\sigma_u^2}{1-\\rho^2}$。为了使其方差也为 $\\sigma_u^2$，我们将其乘以 $\\sqrt{1-\\rho^2}$：\n$$\n\\sqrt{1-\\rho^2} \\varepsilon_{i,0}\n$$\n这定义了 Prais-Winsten 变换。对于患者 $i$，其变换矩阵 $P_i$ 为：\n$$\nP_i(\\rho) =\n\\begin{pmatrix}\n\\sqrt{1-\\rho^2}  0  0  \\dots  0 \\\\\n-\\rho  1  0  \\dots  0 \\\\\n0  -\\rho  1  \\dots  0 \\\\\n\\vdots   \\ddots   \\vdots \\\\\n0  \\dots  0  -\\rho  1\n\\end{pmatrix}\n$$\n将此变换应用于模型 $y_i = X_i \\beta + \\varepsilon_i$，得到患者 $i$ 的变换后模型：\n$$\nP_i y_i = (P_i X_i) \\beta + P_i \\varepsilon_i \\quad \\implies \\quad y_i^* = X_i^* \\beta + \\varepsilon_i^*\n$$\n变换后的误差向量 $\\varepsilon_i^*$ 的协方差矩阵为 $\\text{Cov}(\\varepsilon_i^*) = \\sigma^2(1-\\rho^2)I_{n_i} = \\sigma_u^2 I_{n_i}$。在将所有变换后的患者数据堆叠以得到 $y^* = X^* \\beta + \\varepsilon^*$ 之后，我们可以应用 OLS 来求解 $\\beta$。\n\n由于 $\\rho$ 未知，我们必须从数据中估计它。这就引出了两步 FGLS 程序。\n\n**步骤1：初始 OLS 拟合**\n首先，我们忽略相关性并计算 $\\beta$ 的初始 OLS 估计：\n$$\n\\hat{\\beta}_{OLS} = (X^T X)^{-1} X^T y\n$$\n此拟合的残差 $e = y - X\\hat{\\beta}_{OLS}$ 可作为真实误差 $\\varepsilon$ 的一致估计。\n\n**步骤2：估计自回归参数 $\\rho$**\n我们从 OLS 残差中的 AR(1) 关系来估计 $\\rho$：$e_{i,t} \\approx \\rho e_{i,t-1} + \\text{noise}$。$\\rho$ 的最小二乘估计量是通过将 $e_{i,t}$ 对 $e_{i,t-1}$ 进行回归得到的，使用了患者内部所有可用的相邻对：\n$$\n\\hat{\\rho} = \\frac{\\sum_{i=1}^N \\sum_{t=1}^{n_i-1} e_{i,t} e_{i,t-1}}{\\sum_{i=1}^N \\sum_{t=1}^{n_i-1} e_{i,t-1}^2}\n$$\n其中 $N$ 是患者数量。问题要求将此估计值严格约束在 $(-1, 1)$ 内，以确保平稳性条件和变换项 $\\sqrt{1-\\hat{\\rho}^2}$ 的有效性。任何在此范围之外的估计值都将被截断到区间内最接近的值，例如 $\\pm(1 - 10^{-9})$。\n\n**步骤3：数据变换**\n使用估计的 $\\hat{\\rho}$，我们对每个患者 $i$ 的数据进行变换：\n- 第一个观测值 ($t=0$):\n  $y_{i,0}^* = \\sqrt{1-\\hat{\\rho}^2} \\, y_{i,0}$\n  $X_{i,0}^* = \\sqrt{1-\\hat{\\rho}^2} \\, X_{i,0}$\n- 后续观测值 ($t = 1, \\dots, n_i-1$):\n  $y_{i,t}^* = y_{i,t} - \\hat{\\rho} \\, y_{i,t-1}$\n  $X_{i,t}^* = X_{i,t} - \\hat{\\rho} \\, X_{i,t-1}$\n对于只有一个观测值 ($n_i=1$) 的患者，只应用第一个观测值的变换。然后将变换后的数据 $(y^*, X^*)$ 在所有患者间堆叠。\n\n**步骤4：FGLS 估计与方差计算**\n$\\beta$ 的 FGLS 估计是通过对变换后的模型应用 OLS 获得的：\n$$\n\\hat{\\beta}_{FGLS} = ((X^*)^T X^*)^{-1} (X^*)^T y^*\n$$\n变换后的残差是 $e^* = y^* - X^* \\hat{\\beta}_{FGLS}$。残差平方和是 $RSS^* = (e^*)^T e^*$。\n问题将最终的方差估计指定为变换后残差的方差，它估计的是 $\\sigma_u^2 = \\sigma^2(1-\\rho^2)$。尽管通常可能会对此进行缩放以估计 $\\sigma^2$，但指令要求报告 $\\hat{\\sigma}^2 = \\frac{RSS^*}{n-p}$，其中 $n$ 是总观测数，$p=2$ 是模型参数的数量。我将遵循这一明确指令。\n\n推导到此完成。实现将精确遵循这些步骤。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the FGLS procedure on all test cases and print the results.\n    \"\"\"\n\n    test_cases = [\n        # Test case 1 (balanced panel)\n        [\n            [10.0, 9.55, 9.25, 8.95, 8.7],\n            [11.0, 10.5, 10.2, 9.9, 9.6],\n            [9.2, 8.9, 8.6, 8.4, 8.1]\n        ],\n        # Test case 2 (unbalanced panel)\n        [\n            [7.5, 7.6, 7.4, 7.3],\n            [8.0, 7.7, 7.5],\n            [6.0, 6.2, 6.1, 5.9, 5.8, 5.6]\n        ],\n        # Test case 3 (near-unit persistence)\n        [\n            [12.0, 11.9, 11.85, 11.8, 11.78, 11.77, 11.75, 11.74],\n            [10.0, 9.95, 9.92, 9.9, 9.88, 9.87, 9.86, 9.85]\n        ]\n    ]\n\n    def run_fgls(patient_data):\n        \"\"\"\n        Implements the two-step feasible generalized least squares algorithm for one dataset.\n        \"\"\"\n        # Step 1: Construct stacked y vector and X matrix from patient data\n        y_list = []\n        X_list = []\n        patient_indices = []\n        current_idx = 0\n        for responses in patient_data:\n            ni = len(responses)\n            y_list.extend(responses)\n            t = np.arange(ni)\n            X_patient = np.column_stack((np.ones(ni, dtype=float), t.astype(float)))\n            X_list.append(X_patient)\n            patient_indices.append((current_idx, current_idx + ni))\n            current_idx += ni\n\n        y = np.array(y_list)\n        X = np.vstack(X_list)\n        n = len(y)\n        p = X.shape[1]\n\n        # Step 2: Compute initial OLS fit to obtain residuals\n        try:\n            beta_ols = np.linalg.solve(X.T @ X, X.T @ y)\n        except np.linalg.LinAlgError:\n            # Fallback for singular matrix, though not expected with given data\n            beta_ols = np.linalg.pinv(X.T @ X) @ X.T @ y\n        \n        residuals = y - X @ beta_ols\n\n        # Step 3: Estimate the autoregressive parameter rho\n        e_current_list = []\n        e_lagged_list = []\n        for start, end in patient_indices:\n            if end - start > 1:\n                patient_residuals = residuals[start:end]\n                e_current_list.extend(patient_residuals[1:])\n                e_lagged_list.extend(patient_residuals[:-1])\n        \n        e_current = np.array(e_current_list)\n        e_lagged = np.array(e_lagged_list)\n\n        if len(e_lagged) == 0:\n            rho_hat_raw = 0.0\n        else:\n            denominator = e_lagged @ e_lagged\n            if np.isclose(denominator, 0):\n                rho_hat_raw = 0.0\n            else:\n                rho_hat_raw = (e_lagged @ e_current) / denominator\n\n        # Constrain rho to be strictly within (-1, 1)\n        rho_hat = np.clip(rho_hat_raw, -1.0 + 1e-9, 1.0 - 1e-9)\n\n        # Step 4: Apply the Prais-Winsten transformation to y and X\n        y_star_list = []\n        X_star_list = []\n        rho_transform_factor = np.sqrt(1.0 - rho_hat**2)\n\n        for i, (start, end) in enumerate(patient_indices):\n            y_patient = y[start:end]\n            X_patient = X[start:end, :]\n            ni = end - start\n\n            if ni >= 1:\n                # First observation transformation\n                y_star_first = rho_transform_factor * y_patient[0]\n                X_star_first = rho_transform_factor * X_patient[0, :]\n                y_star_list.append(y_star_first)\n                X_star_list.append(X_star_first)\n            \n            if ni > 1:\n                # Subsequent observations transformation\n                y_star_rest = y_patient[1:] - rho_hat * y_patient[:-1]\n                X_star_rest = X_patient[1:, :] - rho_hat * X_patient[:-1, :]\n                y_star_list.extend(y_star_rest)\n                X_star_list.extend(X_star_rest)\n\n        y_star = np.array(y_star_list)\n        X_star = np.array(X_star_list)\n\n        # Step 5: Fit OLS on the transformed system to get FGLS estimates\n        try:\n            beta_fgls = np.linalg.solve(X_star.T @ X_star, X_star.T @ y_star)\n        except np.linalg.LinAlgError:\n            beta_fgls = np.linalg.pinv(X_star.T @ X_star) @ X_star.T @ y_star\n\n        # Step 6: Compute the residual variance estimate\n        residuals_star = y_star - X_star @ beta_fgls\n        rss_star = residuals_star.T @ residuals_star\n        sigma_sq_hat = rss_star / (n - p)\n        \n        return [rho_hat, beta_fgls[0], beta_fgls[1], sigma_sq_hat]\n\n    # Process all test cases\n    all_results = [run_fgls(case_data) for case_data in test_cases]\n\n    # Format and print the final output string\n    list_of_list_strings = []\n    for single_case_results in all_results:\n        formatted_nums = [f\"{val:.6f}\" for val in single_case_results]\n        list_of_list_strings.append(f\"[{','.join(formatted_nums)}]\")\n    \n    final_output_str = f\"[{','.join(list_of_list_strings)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}