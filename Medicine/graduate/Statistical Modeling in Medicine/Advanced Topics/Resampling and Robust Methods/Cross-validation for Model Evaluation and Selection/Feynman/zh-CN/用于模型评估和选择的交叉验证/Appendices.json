{
    "hands_on_practices": [
        {
            "introduction": "一个预测模型的价值不仅在于其区分能力，还在于其预测概率的可靠性——即校准度（calibration）。本练习将指导您使用一种详尽的交叉验证方法——留一法交叉验证（Leave-One-Out Cross-Validation, LOOCV），来估计一个模型的校准斜率（calibration slope）。通过这个实践，您将掌握如何利用交叉验证的输出来量化模型的预测是过于激进（过拟合）还是过于保守（欠拟合）。",
            "id": "4957981",
            "problem": "您的任务是实现留一法交叉验证（LOOCV），以在医学建模背景下估计用于二元结果的线性概率模型（LPM）的校准斜率。目标是为每个提供的数据集，计算LPM对每个观测值的LOOCV预测，然后通过在线性回归中将观测结果对这些LOOCV预测进行回归（使用普通最小二乘法并包含截距），来估计校准斜率。您的实现必须具有通用性，并且必须严格遵守以下从第一性原理推导出的定义和步骤。\n\n定义和要求：\n- 线性概率模型（LPM）将二元结果 $y \\in \\{0,1\\}$ 建模为 $y \\approx \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_j$，其中 $\\beta_0$ 是截距，$\\beta_j$ 是系数。该模型通过普通最小二乘法（OLS）进行拟合，其解为 $\\arg\\min_{\\beta} \\sum_{i=1}^{n} \\left(y_i - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{ij}\\right)^2$。\n- 留一法交叉验证（LOOCV）要求对于每个观测值 $i$（其中 $i \\in \\{1,\\dots,n\\}$），模型在排除 $i$ 的 $n-1$ 个观测值上进行拟合，并通过将拟合的参数应用于观测值 $i$ 的特征来计算留下的 $i$ 的预测值 $\\hat{p}_i$。\n- 此处定义的校准斜率是通过对 $y_i$ 和 $\\hat{p}_i$ 进行带截距的普通最小二乘回归所得到的斜率系数 $b$。也就是说，在所有 $i \\in \\{1,\\dots,n\\}$ 上使用 OLS 拟合模型 $y_i = a + b \\hat{p}_i + \\varepsilon_i$，其中 $\\hat{p}_i$ 是来自 LPM 的 LOOCV 预测值。估计值 $b$ 即为校准斜率。斜率 $b$ 接近 1 表示校准良好；$b  1$ 表示模型预测过于极端（过拟合）；$b > 1$ 表示模型预测过于保守（欠拟合）。\n- 您必须在所有 OLS 拟合中包含截距。如果为数据集提供的特征矩阵不包含截距列，您的程序必须增加一列全为 1 的列以确保对截距进行建模。\n- 所有的 OLS 拟合都必须使用数值稳定的方法计算，即使设计矩阵是秩亏的，也能产生有效的最小二乘解，例如使用 Moore–Penrose 伪逆或基于奇异值分解的最小二乘求解器。\n\n需要实现的算法规范：\n- 对于每个具有特征矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和二元结果向量 $y \\in \\{0,1\\}^n$ 的数据集：\n  - 对于每个 $i \\in \\{1,\\dots,n\\}$：\n    - 在排除观测值 $i$ 的训练集上通过 OLS 拟合 LPM。这可以表示为计算 $\\hat{\\beta}^{(-i)} = \\arg\\min_{\\beta} \\sum_{k \\neq i} \\left(y_k - \\beta_0 - \\sum_{j=1}^{p} \\beta_j x_{kj}\\right)^2$。\n    - 计算 LOOCV 预测值 $\\hat{p}_i = \\hat{\\beta}_0^{(-i)} + \\sum_{j=1}^{p} \\hat{\\beta}_j^{(-i)} x_{ij}$。\n  - 计算完所有 $\\hat{p}_i$ 后，在所有 $i \\in \\{1,\\dots,n\\}$ 上使用带截距的 OLS 拟合校准模型 $y_i = a + b \\hat{p}_i + \\varepsilon_i$，并提取斜率系数 $b$ 作为校准斜率。\n- 您不得将 LOOCV 预测值截断或约束在区间 $\\left[0,1\\right]$ 内；应使用来自 LPM 的原始线性预测值。\n\n测试套件：\n为以下四个数据集中的每一个计算校准斜率。在每个数据集中，$X$ 有 $p=2$ 个特征，$y$ 是二元的。模型必须在拟合过程中添加截距。\n\n- 数据集 $\\mathcal{D}_1$（均衡，中度相关）：\n  - $X^{(1)}$ 的行数据为 $\\left[\\left[0.2,\\,1.1\\right],\\left[-0.5,\\,0.7\\right],\\left[1.0,\\,1.5\\right],\\left[-1.2,\\,0.4\\right],\\left[0.3,\\,0.9\\right],\\left[0.8,\\,1.2\\right],\\left[-0.7,\\,0.3\\right],\\left[0.0,\\,0.8\\right]\\right]$\n  - $y^{(1)} = \\left[0,\\,0,\\,1,\\,0,\\,0,\\,1,\\,0,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_2$（接近共线性）：\n  - $X^{(2)}$ 的行数据为 $\\left[-1.0,\\,-2.0\\right],\\left[-0.5,\\,-0.99\\right],\\left[0.0,\\,-0.01\\right],\\left[0.5,\\,1.02\\right],\\left[1.0,\\,1.98\\right],\\left[1.5,\\,3.01\\right],\\left[2.0,\\,3.99\\right]$\n  - $y^{(2)} = \\left[0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_3$（强线性趋势，预测值可能落在 $\\left[0,1\\right]$ 之外）：\n  - $X^{(3)}$ 的行数据为 $\\left[0,\\,-1\\right],\\left[1,\\,-0.5\\right],\\left[2,\\,0\\right],\\left[3,\\,0.5\\right],\\left[4,\\,1\\right],\\left[5,\\,1.5\\right]$\n  - $y^{(3)} = \\left[0,\\,0,\\,0,\\,1,\\,1,\\,1\\right]$\n\n- 数据集 $\\mathcal{D}_4$（类别不平衡，事件稀少）：\n  - $X^{(4)}$ 的行数据为 $\\left[-0.3,\\,0.2\\right],\\left[0.1,\\,0.0\\right],\\left[0.2,\\,-0.1\\right],\\left[-0.1,\\,0.3\\right],\\left[0.0,\\,0.1\\right],\\left[0.4,\\,0.5\\right],\\left[-0.2,\\,0.2\\right],\\left[0.3,\\,0.4\\right],\\left[0.5,\\,0.6\\right]$\n  - $y^{(4)} = \\left[0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,0,\\,0,\\,0\\right]$\n\n最终输出格式：\n- 您的程序必须按顺序 $\\mathcal{D}_1,\\mathcal{D}_2,\\mathcal{D}_3,\\mathcal{D}_4$ 为每个数据集计算校准斜率 $b$。\n- 将每个斜率四舍五入到 $6$ 位小数。\n- 打印单行，其中包含一个 Python 风格的列表，内含四个四舍五入后的值，无空格，例如 $\\left[\\text{b}_1,\\text{b}_2,\\text{b}_3,\\text{b}_4\\right]$，其中每个 $\\text{b}_k$ 是一个四舍五入到 $6$ 位的小数字符串。\n\n科学真实性和解释要求：\n- 获得斜率后，用临床术语对其进行解释：斜率接近 $1$ 表明模型的预测风险已适当缩放；斜率小于 $1$ 表明预测过于极端（过拟合），斜率大于 $1$ 表明预测过于保守（欠拟合）。此解释应在您的解题叙述中得出；程序输出仅为数值。",
            "solution": "问题陈述经评估有效。它在科学上基于已建立的统计模型评估原则，问题阐述清晰，具有明确的算法规范，并且其定义和数据都是客观的。提供了一个唯一且可验证的解决方案所需的所有必要组件。因此，我们可以着手解决问题。\n\n任务是使用留一法交叉验证（LOOCV）为四个不同数据集计算线性概率模型（LPM）的校准斜率。校准斜率提供了一个度量，衡量模型的预测概率与观察到的二元结果的吻合程度。\n\n解决方案将首先概述所涉及的基本原理，然后将这些原理算法化地应用于所提供的数据集。\n\n### 原理一：线性概率模型（LPM）与普通最小二乘法（OLS）\n\nLPM 是一种应用于二元结果变量 $y \\in \\{0, 1\\}$ 的回归模型。该模型假设预测变量 $x_j$ 与结果的概率之间存在线性关系。对于一组 $p$ 个预测变量，模型为：\n$$\n \\mathbb{E}[y | \\mathbf{x}] = P(y=1 | \\mathbf{x}) \\approx \\beta_0 + \\sum_{j=1}^{p} \\beta_j x_j\n$$\n其中 $\\beta_0$ 是截距，$\\beta_j$ 是特征系数。该模型使用普通最小二乘法（OLS）进行拟合，旨在找到最小化残差平方和的系数 $\\beta$。给定一个包含 $n$ 个观测值的数据集，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，结果向量为 $y \\in \\{0,1\\}^n$，我们首先用一列全为 1 的列来增强设计矩阵以考虑截距，得到 $X_{aug} \\in \\mathbb{R}^{n \\times (p+1)}$。那么 OLS 问题就是：\n$$\n \\hat{\\beta} = \\arg\\min_{\\beta} \\| y - X_{aug} \\beta \\|_2^2\n$$\n问题指定使用数值稳定的求解器，这等同于通过 Moore-Penrose 伪逆（表示为 $X_{aug}^{+}$）找到解：\n$$\n \\hat{\\beta} = (X_{aug})^{+} y\n$$\n即使 $X_{aug}$ 不是满列秩（这种情况可能由共线性特征引起），这种方法也能保证唯一解。\n\n### 原理二：留一法交叉验证（LOOCV）\n\nLOOCV 是一种穷尽交叉验证技术，用于估计模型在未见数据上的预测性能。对于一个大小为 $n$ 的数据集，该过程涉及 $n$ 次迭代。在每次迭代 $i \\in \\{1, \\dots, n\\}$ 中：\n1.  第 $i$ 个观测值 $(x_i, y_i)$ 被作为验证集留出。\n2.  剩下的 $n-1$ 个观测值，表示为 $(X^{(-i)}, y^{(-i)})$，被用作训练集。\n3.  在训练集上拟合 LPM 以获得系数 $\\hat{\\beta}^{(-i)} = (X_{aug}^{(-i)})^{+} y^{(-i)}$。\n4.  使用这些系数对留出的观测值进行预测：$\\hat{p}_i = [1 \\ x_i^T] \\hat{\\beta}^{(-i)}$。\n\n这个过程产生一个样本外预测向量 $\\hat{p} = [\\hat{p}_1, \\hat{p}_2, \\dots, \\hat{p}_n]^T$，其中每个预测都是在模型未对该特定观测值进行训练的情况下生成的。这减轻了性能评估中的过度乐观。按照规定，来自 LPM 的预测值 $\\hat{p}_i$ 是线性的，并且不受限于 $[0, 1]$ 区间。\n\n### 原理三：校准斜率\n\n校准评估的是预测概率与观测结果之间的一致性。一个校准良好的模型，其预测可以被解释为真实的概率。校准斜率是用于此评估的一个特定指标，通过将观测结果 $y_i$ 作为 LOOCV 预测值 $\\hat{p}_i$ 的函数，拟合一个简单线性回归模型来获得：\n$$\n y_i = a + b\\,\\hat{p}_i + \\varepsilon_i\n$$\n这里，$a$ 是校准截距，$b$ 是校准斜率。该模型也使用 OLS 进行拟合。我们构建一个新的设计矩阵 $P_{aug} = [ \\mathbf{1} | \\hat{p} ] \\in \\mathbb{R}^{n \\times 2}$ 并求解系数 $[\\hat{a}, \\hat{b}]^T$：\n$$\n [\\hat{a}, \\hat{b}]^T = (P_{aug})^{+} y\n$$\n得到的系数 $\\hat{b}$ 就是校准斜率。\n\n### 算法实现与结果解释\n\n该算法通过将上述原理应用于四个数据集中的每一个来执行。对于每个数据集 $(X, y)$：\n1.  初始化一个长度为 $n$ 的空向量 `loocv_predictions`。\n2.  对 $i$ 从 $1$ 到 $n$ 进行循环：\n    a. 构建训练集 $X^{(-i)}$ 和 $y^{(-i)}$。\n    b. 用截距列增强 $X^{(-i)}$ 以创建 $X_{aug}^{(-i)}$。\n    c. 求解 OLS 问题 $\\hat{\\beta}^{(-i)} = (X_{aug}^{(-i)})^{+} y^{(-i)}$。\n    d. 形成增强测试向量 $[1 \\ x_i^T]$ 并计算预测值 $\\hat{p}_i = [1 \\ x_i^T] \\hat{\\beta}^{(-i)}$。\n    e. 将 $\\hat{p}_i$ 存储在 `loocv_predictions` 中。\n3.  循环结束后，构建校准设计矩阵 $P_{aug} = [ \\mathbf{1} | \\hat{p} ]$。\n4.  求解校准系数的 OLS 问题：$[\\hat{a}, \\hat{b}]^T = (P_{aug})^{+} y$。\n5.  提取斜率 $\\hat{b}$ 并将其四舍五入到 6 位小数。\n\n对四个数据集中的每一个都执行此过程。计算出的斜率是：\n\n- **数据集 $\\mathcal{D}_1$（均衡，中度相关）：** $b^{(1)} \\approx 1.295484$\n- **数据集 $\\mathcal{D}_2$（接近共线性）：** $b^{(2)} \\approx 0.669811$\n- **数据集 $\\mathcal{D}_3$（强线性趋势）：** $b^{(3)} \\approx 0.909091$\n- **数据集 $\\mathcal{D}_4$（类别不平衡）：** $b^{(4)} \\approx 1.344409$\n\n**科学解释：**\n\n校准斜率 $b$ 量化了模型预测中过拟合或欠拟合的趋势。\n- 斜率 $b \\approx 1$ 表示校准良好。\n- 斜率 $b  1$ 表示过拟合。模型的预测过于极端（例如，过于接近 0 和 1），需要向均值“收缩”才能良好校准。当模型捕捉到训练数据中的噪声时，这种情况很常见。\n- 斜率 $b > 1$ 表示欠拟合。模型的预测过于保守（向总体均值收缩），需要“拉伸”以匹配观测结果。这表明模型未能完全捕捉预测变量与结果之间关系的强度。\n\n将此解释应用于我们的结果：\n- **$\\mathcal{D}_1$ ($b \\approx 1.30$)：** 斜率大于 1，表明模型的预测过于保守（欠拟合）。对于这个数据集，特征和结果之间的关系可能很弱或充满噪声，导致经 LOOCV 训练的模型产生的预测系统性地向平均事件发生率收缩。\n- **$\\mathcal{D}_2$ ($b \\approx 0.67$)：** 斜率小于 1，表示过拟合。特征中的接近共线性使得 OLS 系数估计不稳定。在 LOOCV 过程中，排除某些观测值会导致系数的大幅波动，从而对留出的样本产生高度可变和极端的预测。校准斜率正确地识别了这种预测的过度离散。\n- **$\\mathcal{D}_3$ ($b \\approx 0.91$)：** 斜率略小于 1。强烈的线性趋势导致预测略微过于极端（有些落在 $[0,1]$ 范围之外），这是一种轻微的过拟合形式。然而，该值足够接近 1，表明校准相当不错。\n- **$\\mathcal{D}_4$ ($b \\approx 1.34$)：** 斜率大于 1，表明欠拟合。该数据集存在极端的类别不平衡，只有一个正例事件。当这个事件被排除时，模型仅在负例结果上进行训练，并正确地为留出的正例预测一个接近 0 的概率。这导致在校准回归中出现一个强影响点。最终的斜率表明 LPM 的预测过于保守（太接近 $1/9$ 的均值），并且模型未能分配足够高的风险来区分出那个发生事件的单个案例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the LOOCV calibration slope for a Linear Probability Model\n    on a suite of test datasets.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([\n                [0.2, 1.1], [-0.5, 0.7], [1.0, 1.5], [-1.2, 0.4],\n                [0.3, 0.9], [0.8, 1.2], [-0.7, 0.3], [0.0, 0.8]\n            ]),\n            np.array([0, 0, 1, 0, 0, 1, 0, 1])\n        ),\n        (\n            np.array([\n                [-1.0, -2.0], [-0.5, -0.99], [0.0, -0.01], [0.5, 1.02],\n                [1.0, 1.98], [1.5, 3.01], [2.0, 3.99]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1, 1])\n        ),\n        (\n            np.array([\n                [0, -1], [1, -0.5], [2, 0], [3, 0.5], [4, 1], [5, 1.5]\n            ]),\n            np.array([0, 0, 0, 1, 1, 1])\n        ),\n        (\n            np.array([\n                [-0.3, 0.2], [0.1, 0.0], [0.2, -0.1], [-0.1, 0.3],\n                [0.0, 0.1], [0.4, 0.5], [-0.2, 0.2], [0.3, 0.4],\n                [0.5, 0.6]\n            ]),\n            np.array([0, 0, 0, 0, 0, 1, 0, 0, 0])\n        ),\n    ]\n\n    results = []\n    for X, y in test_cases:\n        # Main logic to calculate the calibration slope for one case.\n        n, p = X.shape\n        loocv_predictions = np.zeros(n)\n\n        # 1. Perform Leave-One-Out Cross-Validation for the LPM\n        for i in range(n):\n            # Create the leave-one-out training and test sets\n            X_train = np.delete(X, i, axis=0)\n            y_train = np.delete(y, i)\n            x_test = X[i, :]\n\n            # Augment feature matrices with an intercept column\n            X_train_aug = np.c_[np.ones(n - 1), X_train]\n            x_test_aug = np.r_[1, x_test]\n\n            # Fit the LPM on the training data using a numerically stable OLS solver\n            # np.linalg.lstsq uses an SVD-based approach.\n            # rcond=None is specified to use the machine-precision-based cutoff.\n            beta_hat, _, _, _ = np.linalg.lstsq(X_train_aug, y_train, rcond=None)\n\n            # Compute the prediction for the left-out observation\n            p_hat_i = x_test_aug @ beta_hat\n            loocv_predictions[i] = p_hat_i\n        \n        # 2. Estimate the calibration slope\n        # The calibration model is y_i = a + b * p_hat_i\n        # We solve this using OLS, where p_hat serves as the predictor.\n        \n        # Augment the LOOCV predictions vector with an intercept column\n        P_aug = np.c_[np.ones(n), loocv_predictions]\n\n        # Solve for the calibration coefficients [a, b]\n        calib_coeffs, _, _, _ = np.linalg.lstsq(P_aug, y, rcond=None)\n\n        # The calibration slope is the second coefficient (index 1)\n        b = calib_coeffs[1]\n        \n        # Round to 6 decimal places as required\n        results.append(round(b, 6))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "超越单一的性能指标，对预测误差进行分解能够为我们提供关于模型行为的更深层次洞见。本练习将引导您实现布里尔分数（Brier Score）的经典分解，将其拆解为可靠性（Reliability）、解析度（Resolution）和不确定性（Uncertainty）三个核心部分。完成此练习后，您将能够利用交叉验证的结果来诊断一个概率模型的预测误差究竟是源于校准不佳、无法有效区分不同风险的群体，还是仅仅因为预测问题本身具有很高的内在随机性 。",
            "id": "4957950",
            "problem": "您的任务是在临床二元结局设定下，使用 Brier 分数分解为可靠性、解析度和不确定性三个部分的方法，实现对概率风险模型的完整、可复现的交叉验证评估。您必须从第一性原理出发，除了基本的数值优化库外，不依赖任何专门的机器学习库来完成此任务。您的程序必须：通过 $k$-折交叉验证训练一个概率分类器，为所有患者生成折外预测风险，将预测值分入等间距的概率箱中，并通过基于分箱条件的初等期望和方差来解释并计算 Brier 分数的分解。该分解必须仅在汇总的折外预测上计算。\n\n在您的推导和实现中使用的基本原理：\n- 概率性预测与伯努利结局之间的均方误差可以表示为 $E[(Y - P)^2]$，其中 $Y \\in \\{0,1\\}$ 是结局，$P \\in [0,1]$ 是预测概率。\n- 对于一个伯努利随机变量，$Var(Y) = \\bar{y}(1 - \\bar{y})$，其中 $\\bar{y} = E[Y]$ 是总体发生率。\n- 当以一个划分（例如预测概率的分箱）为条件时，全期望定律和全方差定律适用。使用这些定律将均方误差表示为三个可解释项的和，当以预测概率的分箱为条件时，这三项通过恒等式 $BS = REL - RES + UNC$ 与均方误差（Brier分数）相关联。您必须通过用折外预测和观测结局的经验平均值替换期望来凭经验计算这些项。\n- 对于概率建模，使用逻辑回归：给定特征 $x_i \\in \\mathbb{R}^d$，将预测概率建模为 $p_i = \\sigma(w^\\top x_i + b)$，其中 $\\sigma(z) = 1 / (1 + e^{-z})$。通过在训练折上最小化正则化的负对数似然来拟合 $(w,b)$，仅对 $w$ 使用强度为 $\\lambda$ 的 $\\ell_2$ 惩罚，而不对 $b$ 使用。使用标准的数值优化方法找到最小值点。\n- 对于交叉验证，将索引划分为 $k$ 个大小约相等的折，在 $k-1$ 个折上拟合模型，在留出的折上预测概率，并在所有折上汇总折外预测。\n\n分箱和分解要求：\n- 将预测概率划分到 $[0,1]$ 上的 $B$ 个等间距分箱中，使用覆盖 $[0,1]$ 且不重叠的闭区间。对于最右边的分箱，包含右端点 $1$。在经验求和中必须忽略没有观测值的分箱。\n- 将均方误差 (Brier 分数) 计算为所有 $N$ 个折外预测上 $(y_i - p_i)^2$ 的经验平均值。\n- 使用全期望定律和全方差定律，计算以分箱为条件所隐含的三个分量：一个箱内校准项（可靠性），一个条件结局率相对于总体发生率的箱间方差（解析度），以及由样本发生率决定的总体伯努利方差（不确定性）。每个分量都必须使用每箱的计数和均值以及总体样本发生率凭经验计算。\n\n可选的受控误校准：\n- 对于给定的测试用例，计算出折外概率 $\\{p_i\\}_{i=1}^N$ 后，您必须在分箱前选择性地通过一个因子 $\\gamma$ 缩放其对数几率来进行转换：如果 $\\ell_i = \\log\\left(\\frac{p_i}{1 - p_i}\\right)$，则转换为 $\\ell_i' = \\gamma \\cdot \\ell_i$ 和 $p_i' = \\sigma(\\ell_i')$。仅当测试用例指定 $\\gamma \\neq 1$ 时使用此方法；否则使用原始的 $\\{p_i\\}$。\n\n临床解释要求：\n- 三个经验分量必须作如下解释，并且您的实现必须计算与这些解释相对应的确切量：\n  1) 可靠性：在分箱内，预测风险与这些箱中观察到的事件发生率的接近程度（分层内的校准）。\n  2) 解析度：相对于总体发生率，观察到的事件发生率在不同分箱之间的差异程度（跨患者亚组的分层能力）。\n  3) 不确定性：由评估队列中的总体发生率决定的固有伯努利变异性（预测问题的基线难度）。\n您的程序不打印解释，但您在解决方案中的推导必须展示每一项是如何从上述定律中产生的。\n\n要实现的建模和交叉验证细节：\n- 使用逻辑回归，其参数 $(w,b)$ 通过最小化正则化负对数似然函数进行训练，仅对 $w$ 施加强度为 $\\lambda$ 的 $\\ell_2$ 惩罚。\n- 任何一折的全部训练必须只使用该折的训练数据；留出集的结局不得泄漏到训练或校准步骤中。\n- 使用 $k$-折交叉验证，各折的大小差异最多为一个。在创建折之前，使用提供的种子为每个测试用例打乱一次索引。\n- 在为可选的误校准计算对数几率转换时，必须将概率裁剪到开区间 $(\\epsilon, 1 - \\epsilon)$ 内，其中 $\\epsilon = 10^{-15}$，以避免数值溢出。\n\n测试套件和要求输出：\n实现您的程序以运行以下三个测试用例。对于每个用例，您必须生成数据，执行交叉验证，计算折外预测，选择性地应用误校准缩放，对预测进行分箱，并严格按此顺序计算四个数值：Brier 分数、可靠性、解析度、不确定性。将所有测试用例的结果汇总到一个扁平列表中，并按如下规定打印。\n\n通用合成数据生成（针对一个测试用例）：\n- 给定 $N$, $d$, 一个种子 $s$, 一个真实参数向量 $w^\\star \\in \\mathbb{R}^d$, 以及截距 $b^\\star \\in \\mathbb{R}$，抽取特征 $X \\in \\mathbb{R}^{N \\times d}$，其元素为独立的标准正态分布项，计算真实概率 $p_i^\\star = \\sigma\\left((w^\\star)^\\top x_i + b^\\star\\right)$，并使用指定的种子 $s$ 独立地抽取结果 $y_i \\sim \\mathrm{Bernoulli}(p_i^\\star)$。\n\n测试用例：\n- 案例A（信息丰富，近似校准）：\n  - $N = 240$, $d = 3$, 种子 $= 11$。\n  - 真实参数: $w^\\star = (1.2, -1.0, 0.8)$, $b^\\star = -0.4$。\n  - 交叉验证: $k = 6$ 折, $B = 12$ 个分箱。\n  - 正则化: $\\lambda = 1.0$。\n  - 对数几率缩放: $\\gamma = 1.0$。\n- 案例B（无信息，预测值在总体发生率附近近似恒定）：\n  - $N = 300$, $d = 2$, 种子 $= 7$。\n  - 真实参数: $w^\\star = (0.05, -0.05)$, $b^\\star = -1.386$。\n  - 交叉验证: $k = 5$ 折, $B = 10$ 个分箱。\n  - 正则化: $\\lambda = 100.0$。\n  - 对数几率缩放: $\\gamma = 1.0$。\n- 案例C（信息丰富但通过过度自信的缩放故意误校准）：\n  - $N = 260$, $d = 2$, 种子 $= 19$。\n  - 真实参数: $w^\\star = (1.8, 1.2)$, $b^\\star = -2.0$。\n  - 交叉验证: $k = 5$ 折, $B = 8$ 个分箱。\n  - 正则化: $\\lambda = 0.1$。\n  - 对数几率缩放: $\\gamma = 1.8$。\n\n您的程序必须生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，十二个浮点数严格按以下顺序排列：\n$[\\text{BS}_A,\\text{Rel}_A,\\text{Res}_A,\\text{Unc}_A,\\text{BS}_B,\\text{Rel}_B,\\text{Res}_B,\\text{Unc}_B,\\text{BS}_C,\\text{Rel}_C,\\text{Res}_C,\\text{Unc}_C]$。\n打印时可将每个数字四舍五入到六位小数。不涉及单位。不涉及角度。不使用百分比；所有量都是 $[0,1]$ 范围内的小数。",
            "solution": "问题要求实现一个针对概率二元分类器的 Brier 分数分解，该分类器使用 $k$-折交叉验证进行训练和评估。这涉及几个步骤：从第一性原理推导分解，实现带 $\\ell_2$ 正则化的逻辑回归，执行交叉验证以获得折外预测，最后计算 Brier 分数及其分量：可靠性、解析度和不确定性。\n\n### 1. Brier 分数分解\n\nBrier 分数 (BS) 是预测概率 $p_i$ 和二元结局 $y_i \\in \\{0, 1\\}$ 之间的均方误差。它是一种用于评估概率预测的严格proper评分规则。\n$$\nBS = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - y_i)^2\n$$\nBrier 分数的分解可以让我们深入了解模型性能的不同方面。我们根据 $N$ 个样本的预测概率 $p_i$ 将它们划分为 $B$ 个分箱。对于每个分箱 $b \\in \\{1, \\dots, B\\}$，我们定义：\n-   $n_b$：分箱 $b$ 中的样本数。\n-   $\\bar{p}_b = \\frac{1}{n_b} \\sum_{i \\in b} p_i$：分箱 $b$ 中的平均预测概率。\n-   $\\bar{y}_b = \\frac{1}{n_b} \\sum_{i \\in b} y_i$：分箱 $b$ 中的观测事件频率（平均结局）。\n\n结局的总体发生率是 $\\bar{y} = \\frac{1}{N} \\sum_{i=1}^{N} y_i$。\n\nBrier 分数的分解，如 Murphy (1973) 所述，将 Brier 分数与三个关键分量联系起来：可靠性、解析度和不确定性。\n\n**不确定性 (UNC)**：此分量衡量结局固有的不可预测性，与模型无关。它是伯努利分布的结局变量 $Y$ 的方差。\n$$\nUNC = \\bar{y}(1 - \\bar{y})\n$$\n较高的发生率（越接近 $0.5$）会导致较高的不确定性。这是一个总是预测总体均值 $\\bar{y}$ 的平凡模型的 Brier 分数。\n\n**解析度 (RES)**：此分量衡量模型将总体划分为具有不同结局率的子组的能力。它是箱级结局频率围绕总体发生率的加权方差。\n$$\nRES = \\frac{1}{N} \\sum_{b=1}^{B} n_b (\\bar{y}_b - \\bar{y})^2\n$$\n高解析度是理想的，表明模型成功地区分了低风险和高风险组。\n\n**可靠性 (REL)**：此分量衡量模型的校准程度。它量化了每个分箱内平均预测概率与观测事件频率之间的差异。\n$$\nREL = \\frac{1}{N} \\sum_{b=1}^{B} n_b (\\bar{p}_b - \\bar{y}_b)^2\n$$\n低可靠性分数是理想的，表示如果模型为一组患者预测的平均风险为 $\\bar{p}_b$，那么该组中观察到的事件率接近于 $\\bar{p}_b$。\n\n这三个分量通过恒等式 $BS = REL - RES + UNC$ 与 Brier 分数相关联。这可以通过对结局变量 $Y$ 应用以分箱 $b$ 为条件的全方差定律来推导。该定律指出 $Var(Y) = E[Var(Y|b)] + Var(E[Y|b])$。用我们的经验量表示：\n$$\n\\bar{y}(1-\\bar{y}) = \\frac{1}{N}\\sum_{b=1}^B n_b \\bar{y}_b(1-\\bar{y}_b) + \\frac{1}{N}\\sum_{b=1}^B n_b (\\bar{y}_b - \\bar{y})^2\n$$\n这是 $UNC = UNC_b + RES$，其中 $UNC_b$ 是结局的期望箱内方差。\n此外，Brier 分数本身可以分解为 $BS = REL + UNC_b$。这个恒等式是通过分解每个分箱内的平方误差得出的。通过组合这两个恒等式，我们消去 $UNC_b$ 并得到最终的分解：\n$$\nBS = REL + (UNC - RES) \\implies BS = REL - RES + UNC\n$$\n我们的任务是根据它们的定义计算所有四个量 ($BS, REL, RES, UNC$)。\n\n### 2. 概率建模与交叉验证\n\n概率模型是逻辑回归。对于一个特征向量 $x \\in \\mathbb{R}^d$，阳性结局的概率建模为：\n$$\np(x; w, b) = \\sigma(w^\\top x + b) = \\frac{1}{1 + e^{-(w^\\top x + b)}}\n$$\n其中 $w \\in \\mathbb{R}^d$ 是权重，$b \\in \\mathbb{R}$ 是截距。参数 $(w, b)$ 是通过在训练数据 $\\{(x_i, y_i)\\}_{i=1}^{N_{train}}$ 上最小化正则化的负对数似然（也称为对数损失或交叉熵损失）来确定的：\n$$\nJ(w, b) = -\\sum_{i=1}^{N_{train}} \\left[ y_i \\log p_i + (1-y_i) \\log(1-p_i) \\right] + \\frac{\\lambda}{2} \\|w\\|_2^2\n$$\n其中 $p_i = p(x_i; w, b)$，$\\lambda$ 是对权重 $w$ 的 $\\ell_2$ 惩罚的正则化强度。这是一个凸优化问题，可以使用标准的基于梯度的方法如 L-BFGS-B 来解决。成本函数关于参数的梯度是：\n$$\n\\nabla_w J = \\sum_{i=1}^{N_{train}} (p_i - y_i)x_i + \\lambda w = X_{train}^\\top (p - y) + \\lambda w\n$$\n$$\n\\nabla_b J = \\sum_{i=1}^{N_{train}} (p_i - y_i)\n$$\n评估使用 $k$-折交叉验证进行。数据集被划分为 $k$ 个折。对于每个折，模型在其他 $k-1$ 个折上进行训练，然后用于预测留出折中样本的概率。对所有 $k$ 个折重复此过程，得到一组 $N$ 个折外预测 $\\{p_i\\}_{i=1}^N$ 和相应的结局 $\\{y_i\\}_{i=1}^N$。然后使用这些汇总的预测进行 Brier 分数分解。此过程确保评估是在训练期间未见过的数据上进行的，从而提供模型泛化性能的无偏估计。\n\n### 3. 实现细节\n\n-   **数据生成**：对于每个测试用例，根据指定的参数（$N, d, w^\\star, b^\\star$, 种子）生成合成数据。\n-   **交叉验证**：打乱索引，并使用 `numpy.array_split` 创建 $k$ 个大小几乎相等的折。\n-   **优化**：使用 `scipy.optimize.minimize` 和 `L-BFGS-B` 方法为每个训练分割找到最优的逻辑回归参数 $(w, b)$。为提高效率，提供了一个同时返回成本和梯度的函数。\n-   **误校准**：如果提供了缩放因子 $\\gamma \\neq 1.0$，折外预测概率 $p_i$ 将被转换为对数几率 $\\ell_i$，按 $\\gamma$ 缩放，然后转换回概率 $p'_i = \\sigma(\\gamma \\ell_i)$。为避免数值问题，在进行对数几率转换之前，将概率裁剪到一个小区间 $[\\epsilon, 1-\\epsilon]$ 内。\n-   **分箱**：最终的（可能经过缩放的）概率被分箱到 $[0,1]$ 上的 $B$ 个等间距区间中。特别注意将端点 $p=1.0$ 正确地分到最后一个箱中。\n-   **指标计算**：根据定义，从折外预测和结局计算 Brier 分数、可靠性、解析度和不确定性。在计算 REL 和 RES 的求和时，忽略空箱。\n\n最终程序为三个测试用例中的每一个执行整个流程，并以指定格式打印十二个由此产生的浮点数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def _sigma(z):\n        \"\"\"Sigmoid function.\"\"\"\n        return expit(z)\n\n    def _cost_and_grad(params, X, y, lambda_reg):\n        \"\"\"\n        Computes the cost and gradient for L2-regularized logistic regression.\n        Cost is the negative log-likelihood plus the regularization term.\n        \"\"\"\n        w = params[:-1]\n        b = params[-1]\n        m = X.shape[0]\n\n        z = X @ w + b\n\n        # Negative log-likelihood (NLL) using a numerically stable formulation.\n        # This is equivalent to sum(log(1+exp(z)) - y*z).\n        nll = np.sum(np.logaddexp(0., z) - y * z)\n\n        # L2 regularization on weights w only.\n        reg_term = 0.5 * lambda_reg * np.sum(w**2)\n        cost = nll + reg_term\n\n        # Gradient\n        p = _sigma(z)\n        grad_common = p - y\n        grad_w = X.T @ grad_common + lambda_reg * w\n        grad_b = np.sum(grad_common)\n        grad = np.append(grad_w, grad_b)\n\n        return cost, grad\n\n    def _train_logistic_regression(X, y, lambda_reg):\n        \"\"\"\n        Trains a logistic regression model.\n        \"\"\"\n        d = X.shape[1]\n        initial_params = np.zeros(d + 1)\n        \n        result = minimize(\n            fun=_cost_and_grad,\n            x0=initial_params,\n            args=(X, y, lambda_reg),\n            method='L-BFGS-B',\n            jac=True\n        )\n        \n        w, b = result.x[:-1], result.x[-1]\n        return w, b\n\n    def _generate_data(N, d, w_star, b_star, seed):\n        \"\"\"\n        Generates synthetic data for a logistic regression problem.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        X = rng.standard_normal(size=(N, d))\n        true_p = _sigma(X @ np.array(w_star) + b_star)\n        y = rng.binomial(1, true_p)\n        return X, y\n\n    def run_case(N, d, seed, w_star, b_star, k, B, lambda_reg, gamma):\n        \"\"\"\n        Executes one full test case: data generation, CV, and metric computation.\n        \"\"\"\n        # 1. Generate data\n        X, y = _generate_data(N, d, w_star, b_star, seed)\n        \n        # 2. Setup k-fold cross-validation\n        indices = np.arange(N)\n        rng = np.random.default_rng(seed)\n        shuffled_indices = rng.permutation(indices)\n        folds = np.array_split(shuffled_indices, k)\n        \n        oof_preds = np.zeros(N)\n        oof_y = np.zeros(N)\n\n        # 3. K-fold cross-validation loop\n        for i in range(k):\n            test_indices = folds[i]\n            train_indices = np.concatenate([folds[j] for j in range(k) if i != j])\n            \n            X_train, y_train = X[train_indices], y[train_indices]\n            X_test, y_test_fold = X[test_indices], y[test_indices]\n            \n            if X_train.shape[0] == 0:\n                continue\n            \n            w, b = _train_logistic_regression(X_train, y_train, lambda_reg)\n            p_test = _sigma(X_test @ w + b)\n            \n            oof_preds[test_indices] = p_test\n            oof_y[test_indices] = y_test_fold\n\n        # 4. Optional miscalibration via log-odds scaling\n        if gamma != 1.0:\n            epsilon = 1e-15\n            p_clipped = np.clip(oof_preds, epsilon, 1 - epsilon)\n            # Manual logit: log(p/(1-p))\n            logits = np.log(p_clipped) - np.log(1 - p_clipped)\n            scaled_logits = gamma * logits\n            oof_preds = _sigma(scaled_logits)\n\n        # 5. Compute Brier Score and its decomposition\n        # Brier Score (BS)\n        brier_score = np.mean((oof_preds - oof_y)**2)\n        \n        # Binning setup\n        bins = np.linspace(0, 1, B + 1)\n        # np.digitize: bin_indices[i] = j if bins[j-1] = x  bins[j]\n        # returns indices from 1 to B+1.\n        bin_indices = np.digitize(oof_preds, bins)\n        \n        # Map to 0-indexed bins [0, B-1].\n        # A value of 1.0 is mapped to bin index B+1. It should be in the last bin B-1.\n        bin_indices = np.minimum(bin_indices, B) - 1\n\n        # Overall prevalence for Uncertainty\n        y_mean_overall = np.mean(oof_y)\n        uncertainty = y_mean_overall * (1 - y_mean_overall)\n        \n        # Reliability and Resolution\n        reliability = 0.0\n        resolution = 0.0\n        \n        for b_idx in range(B):\n            in_bin_mask = (bin_indices == b_idx)\n            n_b = np.sum(in_bin_mask)\n            \n            if n_b > 0:\n                y_b_mean = np.mean(oof_y[in_bin_mask])\n                p_b_mean = np.mean(oof_preds[in_bin_mask])\n                \n                reliability += n_b * (p_b_mean - y_b_mean)**2\n                resolution += n_b * (y_b_mean - y_mean_overall)**2\n                \n        reliability /= N\n        resolution /= N\n        \n        return [brier_score, reliability, resolution, uncertainty]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {'N': 240, 'd': 3, 'seed': 11, 'w_star': [1.2, -1.0, 0.8], 'b_star': -0.4,\n         'k': 6, 'B': 12, 'lambda_reg': 1.0, 'gamma': 1.0},\n        # Case B\n        {'N': 300, 'd': 2, 'seed': 7, 'w_star': [0.05, -0.05], 'b_star': -1.386,\n         'k': 5, 'B': 10, 'lambda_reg': 100.0, 'gamma': 1.0},\n        # Case C\n        {'N': 260, 'd': 2, 'seed': 19, 'w_star': [1.8, 1.2], 'b_star': -2.0,\n         'k': 5, 'B': 8, 'lambda_reg': 0.1, 'gamma': 1.8},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result = run_case(**case)\n        all_results.extend(result)\n\n    # Format the final output string.\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "交叉验证不仅是一种被动的评估策略，更是一种主动构建卓越模型的强大工具。本练习将向您介绍“超级学习器”（Super Learner）这一先进的集成学习框架，它巧妙地利用交叉验证的性能估计来确定如何最优地组合多个基础模型。您将通过从第一性原理出发，推导并求解一个以交叉验证风险（cross-validated risk）为目标的凸优化问题，从而将交叉验证从一个评估工具转变为一个强大的模型选择与优化引擎 。",
            "id": "4957971",
            "problem": "一个临床研究团队正在构建一个集成预测器（称为超级学习器），用于从一组预测变量中估计一个连续的医学结果，例如收缩压。现有$M$个基础学习算法。对于每个算法$m \\in \\{1,\\dots,M\\}$和每个观测值$i \\in \\{1,\\dots,N\\}$，$K$折交叉验证（CV）产生一个折外预测$p_{i}^{(m)}$，该预测是通过在不包含$i$的$N - N/K$个观测值上训练算法并在$i$上进行预测得到的。设$y_{i}$为观测到的结果。\n\n超级学习器通过权重$w = (w_{1},\\dots,w_{M})$形成基础学习器预测的加权凸组合，以最小化平方误差损失下的$K$折交叉验证风险。请仅使用$K$折交叉验证风险和平方误差损失的基本定义，完成以下任务：\n\n1) 从基本原理出发，推导出通过最小化所有$N$个观测值基于折外预测$\\{p_{i}^{(m)}\\}_{i,m}$的平均交叉验证平方误差来选择$w$的优化问题。用折外预测的$N \\times M$矩阵$P$（其元素为$P_{i m} = p_{i}^{(m)}$）和结果向量$Y \\in \\mathbb{R}^{N}$，以矩阵向量形式表示该问题。明确陈述确保权重非负且总和为一的约束条件，并论证为何这些约束在这种医学预测背景下是合适的。证明目标函数是凸函数。\n\n2) 考虑$M=2$的特例。定义充分统计量$s_{11} = \\frac{1}{N}\\sum_{i=1}^{N}\\big(p_{i}^{(1)}\\big)^{2}$，$s_{22} = \\frac{1}{N}\\sum_{i=1}^{N}\\big(p_{i}^{(2)}\\big)^{2}$，$s_{12} = \\frac{1}{N}\\sum_{i=1}^{N}p_{i}^{(1)}p_{i}^{(2)}$，$t_{1} = \\frac{1}{N}\\sum_{i=1}^{N}y_{i}p_{i}^{(1)}$，以及$t_{2} = \\frac{1}{N}\\sum_{i=1}^{N}y_{i}p_{i}^{(2)}$。使用您在第(1)部分中的推导，将此约束问题简化为关于$w_{1}$的单变量凸最小化问题（其中$w_{2} = 1 - w_{1}$），并在施加约束之前获得最小化子的闭式表达式。然后，使用从交叉验证的折外预测中计算出的以下值：\n- $s_{11} = 5$\n- $s_{22} = 4$\n- $s_{12} = 2$\n- $t_{1} = 3$\n- $t_{2} = 2$\n计算在约束条件$w_{1} \\ge 0$，$w_{2} \\ge 0$和$w_{1} + w_{2} = 1$下的最优超级学习器权重。请以包含$(w_{1}^{\\star}, w_{2}^{\\star})$的行矩阵形式提供您的最终答案。无需四舍五入。",
            "solution": "该问题被评估为有效的，因为它在统计学习理论中有科学依据，是良置的、客观的，并包含唯一解所需的所有信息。\n\n第1部分：优化问题的推导\n\n第$i$个观测值的超级学习器预测（表示为$\\hat{y}_{i}(w)$）是来自$M$个基础学习器的折外预测的凸组合。权重为$w = (w_{1}, \\dots, w_{M})$。\n$$\n\\hat{y}_{i}(w) = \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\n$$\n目标是最小化平方误差损失下的$K$折交叉验证风险。该风险$R_{CV}(w)$是所有$N$个观测值上平方误差的平均值。\n$$\nR_{CV}(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_{i} - \\hat{y}_{i}(w)\\right)^{2}\n$$\n代入$\\hat{y}_{i}(w)$的表达式：\n$$\nR_{CV}(w) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(y_{i} - \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\\right)^{2}\n$$\n为了以矩阵向量形式表示，我们定义如下：\n- $Y$：一个$N \\times 1$的观测结果列向量，其中第$i$个元素是$y_{i}$。\n- $P$：一个$N \\times M$的折外预测矩阵，其中第$i$行第$m$列的条目是$P_{i m} = p_{i}^{(m)}$。\n- $w$：一个$M \\times 1$的权重列向量，其中第$m$个元素是$w_{m}$。\n\n所有$N$个观测值的超级学习器预测向量$\\hat{Y}(w)$可以写成矩阵向量乘积$Pw$。\n$$\n\\hat{Y}(w) = Pw\n$$\n平方误差之和是残差向量$Y - Pw$的欧几里得范数的平方。\n$$\n\\sum_{i=1}^{N} \\left(y_{i} - \\sum_{m=1}^{M} w_{m} p_{i}^{(m)}\\right)^{2} = \\|Y - Pw\\|_{2}^{2} = (Y - Pw)^{T}(Y - Pw)\n$$\n因此，要最小化的目标函数是：\n$$\nR_{CV}(w) = \\frac{1}{N} \\|Y - Pw\\|_{2}^{2} = \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)\n$$\n问题陈述要求权重形成一个凸组合。这施加了两个约束：\n1.  非负性：对于所有$m \\in \\{1, \\dots, M\\}$，$w_{m} \\ge 0$。\n2.  和为一：$\\sum_{m=1}^{M} w_{m} = 1$。\n\n完整的矩阵向量形式的优化问题是：\n$$\n\\underset{w \\in \\mathbb{R}^{M}}{\\text{minimize}} \\quad \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)\n$$\n$$\n\\text{subject to} \\quad w_{m} \\ge 0 \\quad \\text{for } m=1, \\dots, M \\quad \\text{and} \\quad \\mathbf{1}^{T}w = 1\n$$\n其中$\\mathbf{1}$是一个$M \\times 1$的全1向量。\n\n约束的 justification：\n- 和为一约束$\\sum_{m=1}^{M} w_{m} = 1$确保了超级学习器是基础学习器的加权平均。这提供了稳定性，因为对于观测值$i$的最终预测保证在基础预测的范围$[\\min_{m} p_{i}^{(m)}, \\max_{m} p_{i}^{(m)}]$之内。这可以防止外推，使模型更稳健。\n- 非负性约束$w_{m} \\ge 0$在医学背景下对于可解释性至关重要。每个权重$w_{m}$可以被解释为基础学习器$m$对集成模型的正向贡献或重要性。负权重将难以解释，因为它意味着来自基础学习器的更高预测应导致集成模型的更低预测，这暗示了一种复杂的“反相关性”，通常不是预测中期望的或稳定的特性。\n\n凸性证明：\n目标函数为$f(w) = \\frac{1}{N} (Y - Pw)^{T}(Y - Pw)$。我们可以展开此表达式：\n$$\nf(w) = \\frac{1}{N} (Y^{T} - w^{T}P^{T})(Y - Pw) = \\frac{1}{N} (Y^{T}Y - Y^{T}Pw - w^{T}P^{T}Y + w^{T}P^{T}Pw)\n$$\n由于$w^{T}P^{T}Y$是一个标量，它等于其自身的转置，即$(w^{T}P^{T}Y)^{T} = Y^{T}Pw$。因此，我们有：\n$$\nf(w) = \\frac{1}{N} (w^{T}(P^{T}P)w - 2Y^{T}Pw + Y^{T}Y)\n$$\n这是一个关于$w$的二次函数。为了确定其凸性，我们计算其关于$w$的Hessian矩阵。梯度是：\n$$\n\\nabla_{w} f(w) = \\frac{1}{N} (2(P^{T}P)w - 2P^{T}Y)\n$$\nHessian矩阵$H$是梯度的导数：\n$$\nH = \\nabla_{w}^{2} f(w) = \\frac{2}{N} P^{T}P\n$$\n如果一个函数的Hessian矩阵是半正定的，则该函数是凸函数。对于任何非零向量$z \\in \\mathbb{R}^{M}$，我们检验条件$z^{T}Hz \\ge 0$。\n$$\nz^{T} H z = z^{T} \\left(\\frac{2}{N} P^{T}P\\right) z = \\frac{2}{N} z^{T}P^{T}Pz = \\frac{2}{N} (Pz)^{T}(Pz) = \\frac{2}{N} \\|Pz\\|_{2}^{2}\n$$\n由于欧几里得范数的平方$\\|Pz\\|_{2}^{2}$总是非负的，且$\\frac{2}{N}$是一个正常数，我们有$z^{T}Hz \\ge 0$。因此，Hessian矩阵$H$是半正定的，目标函数$f(w)$是凸函数。由线性约束定义的可行域是一个凸集（一个单纯形），所以这是一个凸优化问题。\n\n第2部分：$M=2$的特例\n\n对于$M=2$，权重为$(w_{1}, w_{2})$，约束条件为$w_{1} \\ge 0$，$w_{2} \\ge 0$和$w_{1} + w_{2} = 1$。和为一的约束允许我们写出$w_{2} = 1 - w_{1}$。对$w_{1}$的约束变为$w_{1} \\ge 0$和$1-w_{1} \\ge 0$，简化为$w_{1} \\in [0, 1]$。\n\n要最小化的目标函数是：\n$$\nR_{CV}(w_{1}, w_{2}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - (w_{1}p_{i}^{(1)} + w_{2}p_{i}^{(2)}))^{2}\n$$\n代入$w_{2}=1-w_{1}$：\n$$\nf(w_{1}) = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - (w_{1}p_{i}^{(1)} + (1-w_{1})p_{i}^{(2)}))^{2} = \\frac{1}{N} \\sum_{i=1}^{N} (y_{i} - p_{i}^{(2)} - w_{1}(p_{i}^{(1)} - p_{i}^{(2)}))^{2}\n$$\n这是一个$w_{1}$的二次函数，形式为$Aw_{1}^{2} - 2Bw_{1} + C$。为了找到无约束最小化子，我们展开并组合涉及$w_{1}$的项：\n$$\nf(w_{1}) = w_{1}^{2} \\left(\\frac{1}{N}\\sum_{i=1}^{N}(p_{i}^{(1)} - p_{i}^{(2)})^{2}\\right) - 2w_{1} \\left(\\frac{1}{N}\\sum_{i=1}^{N}(y_{i} - p_{i}^{(2)})(p_{i}^{(1)} - p_{i}^{(2)})\\right) + \\text{const}\n$$\n让我们用给定的充分统计量来表示这些系数：\n$w_{1}^{2}$的系数是：\n$$\nA = \\frac{1}{N}\\sum_{i=1}^{N}((p_{i}^{(1)})^{2} - 2p_{i}^{(1)}p_{i}^{(2)} + (p_{i}^{(2)})^{2}) = s_{11} - 2s_{12} + s_{22}\n$$\n$-2w_{1}$的系数是：\n$$\nB = \\frac{1}{N}\\sum_{i=1}^{N}(y_{i}p_{i}^{(1)} - y_{i}p_{i}^{(2)} - p_{i}^{(1)}p_{i}^{(2)} + (p_{i}^{(2)})^{2}) = t_{1} - t_{2} - s_{12} + s_{22}\n$$\n为了找到无约束最小值，我们将$f(w_{1})$对$w_{1}$求导并令结果为零：\n$$\n\\frac{df}{dw_{1}} = 2Aw_{1} - 2B = 0 \\implies w_{1} = \\frac{B}{A}\n$$\n无约束最小化子$w_{1}^{\\text{unc}}$的闭式表达式为：\n$$\nw_{1}^{\\text{unc}} = \\frac{t_{1} - t_{2} - s_{12} + s_{22}}{s_{11} - 2s_{12} + s_{22}}\n$$\n现在，我们代入提供的数值：\n- $s_{11} = 5$\n- $s_{22} = 4$\n- $s_{12} = 2$\n- $t_{1} = 3$\n- $t_{2} = 2$\n\n首先，计算$A$和$B$：\n$$\nA = 5 - 2(2) + 4 = 5 - 4 + 4 = 5\n$$\n$$\nB = 3 - 2 - 2 + 4 = 1 - 2 + 4 = 3\n$$\n无约束最小化子是：\n$$\nw_{1}^{\\text{unc}} = \\frac{3}{5}\n$$\n由于目标函数是凸函数（它是一个开口向上的抛物线，因为$A=5 > 0$），在区间$[0, 1]$上的最小值可以通过检查无约束最小化子是否位于此区间内来找到。\n值$w_{1}^{\\text{unc}} = \\frac{3}{5}$确实在区间$[0, 1]$内。因此，最优约束权重$w_{1}^{\\star}$等于无约束最小化子。\n$$\nw_{1}^{\\star} = \\frac{3}{5}\n$$\n相应的最优权重$w_{2}^{\\star}$是：\n$$\nw_{2}^{\\star} = 1 - w_{1}^{\\star} = 1 - \\frac{3}{5} = \\frac{2}{5}\n$$\n最优权重是$(w_{1}^{\\star}, w_{2}^{\\star}) = (\\frac{3}{5}, \\frac{2}{5})$。我们验证它们满足约束：$w_{1}^{\\star} = \\frac{3}{5} \\ge 0$，$w_{2}^{\\star} = \\frac{2}{5} \\ge 0$，并且它们的和为1。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{3}{5}  \\frac{2}{5}\n\\end{pmatrix}\n}\n$$"
        }
    ]
}