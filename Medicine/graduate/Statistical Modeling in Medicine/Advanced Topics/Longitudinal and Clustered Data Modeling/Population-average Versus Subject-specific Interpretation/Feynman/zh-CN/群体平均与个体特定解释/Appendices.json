{
    "hands_on_practices": [
        {
            "introduction": "我们首先通过一个理想化的模型来建立对群体平均效应和特定个体效应之间关系的基本理解。在广义线性混合模型中，连接函数的选择决定了这两种效应之间的数学关系。 这个练习将探讨一个特殊但极具启发性的案例：probit-正态随机截距模型。在这种模型中，条件（特定个体）效应参数和边际（群体平均）效应参数之间存在一个精确的、可解析的数学关系。通过推导并验证这个关系，你将清晰地看到个体间的异质性（由随机效应的方差度量）如何系统性地“衰减”或缩小群体平均效应的强度，为理解更复杂模型中的近似关系打下坚实基础。",
            "id": "4978731",
            "problem": "考虑一个用于医学研究中重复测量的二元结果模型，其中受试者特异性异质性由一个随机截距表示。令 $Y \\in \\{0,1\\}$ 表示协变量值为 $x \\in \\mathbb{R}$ 的受试者的二元结果。条件（受试者特异性）模型是一个带有Probit链接的广义线性混合模型（GLMM），在潜变量层面规定如下：引入一个不可观测的潜变量 $L$，使得 $Y = \\mathbf{1}\\{L > 0\\}$，并且\n$$\nL = \\alpha + \\beta^{\\mathrm{cond}} x + b + \\varepsilon,\n$$\n其中 $b \\sim \\mathcal{N}(0,\\sigma^2)$ 是一个受试者特异性随机截距，$\\varepsilon \\sim \\mathcal{N}(0,1)$ 是一个独立的潜在误差（用于固定Probit尺度），$\\alpha \\in \\mathbb{R}$ 和 $\\beta^{\\mathrm{cond}} \\in \\mathbb{R}$ 是固定效应参数。这定义了一个受试者特异性的解释：$\\beta^{\\mathrm{cond}}$ 量化了对于一个给定受试者（即固定 $b$），Probit线性预测变量的变化。\n\n群体平均（边际）的解释通过对 $b$ 进行积分来获得概率 $p(x) = \\mathbb{P}(Y=1 \\mid x)$，并寻求一个Probit表示 $p(x) = \\Phi\\!\\left(\\alpha^{\\mathrm{marg}} + \\beta^{\\mathrm{marg}} x\\right)$，其中 $\\Phi(\\cdot)$ 是标准正态分布的累积分布函数。你的任务有两部分：\n1. 从关于正态分布和独立性的已知事实出发，推导出近似关系\n$$\n\\beta^{\\mathrm{marg}} \\approx \\frac{\\beta^{\\mathrm{cond}}}{\\sqrt{1 + c \\sigma^2}},\n$$\n为Probit随机截距GLMM确定一个合适的常数 $c$，并解释此关系所蕴含的群体平均与受试者特异性解释之间的区别。\n2. 通过数值方法验证该近似。具体步骤为：使用高斯-埃尔米特求积法对 $b$进行数值积分来计算 $p(x)$，使用逆累积分布函数 $\\Phi^{-1}(\\cdot)$ 将 $p(x)$ 转换回Probit尺度，然后通过对 $\\Phi^{-1}(p(x))$ 关于 $x$ 进行普通最小二乘回归来估计经验边际斜率。将此经验斜率与上述近似值进行比较，并报告每个测试用例的绝对误差。\n\n使用以下参数值测试套件 $(\\alpha, \\beta^{\\mathrm{cond}}, \\sigma^2)$：\n- 测试用例 1：$(0.5, 1.0, 0.0)$\n- 测试用例 2：$(-0.2, 0.8, 0.5)$\n- 测试用例 3：$(1.0, -0.7, 4.0)$\n- 测试用例 4：$(0.0, 2.0, 9.0)$\n- 测试用例 5：$(0.3, 0.1, 10^{-6})$\n\n对于所有计算，使用在 $-2$ 到 $2$ 之间等距分布的网格上的 $x$ 值，并使用足够多的节点数来评估高斯-埃尔米特求积，以实现高精度的数值积分。不涉及物理单位或角度。测试套件的最终程序输出必须是单行：一个由方括号括起来的逗号分隔列表，包含五个测试用例中，经验估计的 $\\beta^{\\mathrm{marg}}$ 与近似值 $\\beta^{\\mathrm{cond}}/\\sqrt{1+c\\sigma^2}$ 之间的绝对误差。例如，一个可接受的格式是 $[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5]$，其中每个 $\\text{result}_i$ 是一个浮点数。",
            "solution": "该问题定义明确且有科学依据，是纵向数据或聚类数据统计建模中的一个标准课题。它要求推导Probit随机截距模型中受试者特异性参数和群体平均参数之间的关系，并进行数值验证。提供了一个唯一且有意义的解决方案所需的所有必要组成部分。\n\n### 第1部分：参数关系的推导与解释\n\n该问题的核心是针对二元结果 $Y \\in \\{0, 1\\}$ 的广义线性混合模型（GLMM）。该模型通过一个潜变量 $L$ 定义，使得 $Y = \\mathbf{1}\\{L > 0\\}$。潜变量方程为：\n$$\nL = \\alpha + \\beta^{\\mathrm{cond}} x + b + \\varepsilon\n$$\n其中 $b \\sim \\mathcal{N}(0, \\sigma^2)$ 是一个受试者特异性随机截距，$\\varepsilon \\sim \\mathcal{N}(0, 1)$ 是定义Probit链接函数的误差项。\n\n首先，我们建立条件（受试者特异性）模型。以受试者的随机效应 $b$ 为条件，正向结果的概率为：\n$$\n\\mathbb{P}(Y=1 \\mid x, b) = \\mathbb{P}(L > 0 \\mid x, b) = \\mathbb{P}(\\alpha + \\beta^{\\mathrm{cond}} x + b + \\varepsilon > 0)\n$$\n对误差项 $\\varepsilon$ 进行整理，我们得到：\n$$\n\\mathbb{P}(Y=1 \\mid x, b) = \\mathbb{P}(\\varepsilon > -(\\alpha + \\beta^{\\mathrm{cond}} x + b))\n$$\n由于 $\\varepsilon \\sim \\mathcal{N}(0, 1)$，其累积分布函数（CDF）为 $\\Phi(z) = \\mathbb{P}(\\varepsilon \\le z)$。根据标准正态分布关于 $0$ 的对称性，我们有 $\\mathbb{P}(\\varepsilon > -z) = \\mathbb{P}(\\varepsilon < z) = \\Phi(z)$。因此，条件概率为：\n$$\np(x \\mid b) = \\Phi(\\alpha + \\beta^{\\mathrm{cond}} x + b)\n$$\n系数 $\\beta^{\\mathrm{cond}}$ 是受试者特异性效应。它量化了对于特定受试者（即保持 $b$ 不变），当 $x$ 增加一个单位时，结果概率的Probit值的变化。\n\n接下来，我们推导边际（群体平均）模型。这需要对随机效应 $b$ 在其分布上进行积分：\n$$\np(x) = \\mathbb{P}(Y=1 \\mid x) = \\mathbb{E}_{b}[\\mathbb{P}(Y=1 \\mid x, b)] = \\int_{-\\infty}^{\\infty} p(x \\mid b) f(b) db\n$$\n其中 $f(b)$ 是 $\\mathcal{N}(0, \\sigma^2)$ 分布的概率密度函数。\n$$\np(x) = \\int_{-\\infty}^{\\infty} \\Phi(\\alpha + \\beta^{\\mathrm{cond}} x + b) \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{b^2}{2\\sigma^2}\\right) db\n$$\n虽然问题陈述暗示这会导出一个*近似*关系，但对于带有正态随机效应的Probit链接（一个Probit-正态模型）这一特定情况，该积分可以精确求解，从而得到一个同样是Probit形式的边际模型。\n\n为了证明这一点，我们使用一个概率论证。令 $U \\sim \\mathcal{N}(0, 1)$ 是一个独立于 $b$ 的标准正态变量。对于 $\\mu = \\alpha + \\beta^{\\mathrm{cond}} x$，我们可以写出 $\\Phi(\\mu+b) = \\mathbb{P}(U \\le \\mu+b \\mid b)$。因此，边际概率为：\n$$\np(x) = \\mathbb{E}_{b}[\\mathbb{P}(U \\le \\alpha + \\beta^{\\mathrm{cond}} x + b \\mid b)] = \\mathbb{P}(U \\le \\alpha + \\beta^{\\mathrm{cond}} x + b)\n$$\n这等价于：\n$$\np(x) = \\mathbb{P}(U - b \\le \\alpha + \\beta^{\\mathrm{cond}} x)\n$$\n令 $W = U - b$。由于 $U$ 和 $b$ 是独立的`正态变量，它们的线性组合 $W$ 也呈正态分布。\n$W$ 的均值为 $\\mathbb{E}[W] = \\mathbb{E}[U] - \\mathbb{E}[b] = 0 - 0 = 0$。\n$W$ 的方差为 $\\mathrm{Var}(W) = \\mathrm{Var}(U) + \\mathrm{Var}(-b) = \\mathrm{Var}(U) + (-1)^2\\mathrm{Var}(b) = 1 + \\sigma^2$。\n因此，$W \\sim \\mathcal{N}(0, 1+\\sigma^2)$。\n\n概率变为 $p(x) = \\mathbb{P}(W \\le \\alpha + \\beta^{\\mathrm{cond}} x)$。为了用标准正态CDF $\\Phi$ 来表示，我们对不等式进行标准化：\n$$\np(x) = \\mathbb{P}\\left(\\frac{W}{\\sqrt{1+\\sigma^2}} \\le \\frac{\\alpha + \\beta^{\\mathrm{cond}} x}{\\sqrt{1+\\sigma^2}}\\right)\n$$\n由于 $W/\\sqrt{1+\\sigma^2} \\sim \\mathcal{N}(0, 1)$，我们有：\n$$\np(x) = \\Phi\\left(\\frac{\\alpha}{\\sqrt{1+\\sigma^2}} + \\frac{\\beta^{\\mathrm{cond}} x}{\\sqrt{1+\\sigma^2}}\\right)\n$$\n这个结果恰好是 $p(x) = \\Phi(\\alpha^{\\mathrm{marg}} + \\beta^{\\mathrm{marg}} x)$ 的形式，其中：\n$$\n\\alpha^{\\mathrm{marg}} = \\frac{\\alpha}{\\sqrt{1+\\sigma^2}} \\quad \\text{and} \\quad \\beta^{\\mathrm{marg}} = \\frac{\\beta^{\\mathrm{cond}}}{\\sqrt{1+\\sigma^2}}\n$$\n将这个精确结果与所要求的形式 $\\beta^{\\mathrm{marg}} \\approx \\frac{\\beta^{\\mathrm{cond}}}{\\sqrt{1 + c \\sigma^2}}$ 进行比较，我们发现对于该模型，此关系是精确的，并且常数 $c=1$。\n\n关系式 $|\\beta^{\\mathrm{marg}}| = |\\beta^{\\mathrm{cond}}| / \\sqrt{1+\\sigma^2} \\le |\\beta^{\\mathrm{cond}}|$ 表明，相对于受试者特异性效应，群体平均效应被衰减（向零收缩）。这种衰减的幅度随着随机截距的方差 $\\sigma^2$ 的增加而增加，$\\sigma^2$ 代表了受试者之间的异质性程度。如果没有异质性（$\\sigma^2=0$），那么 $\\beta^{\\mathrm{marg}} = \\beta^{\\mathrm{cond}}$，因为群体模型和个体模型重合。\n\n### 第2部分：数值验证程序\n\n我们现在将通过数值方法验证这个精确的理论关系。该程序包括三个主要步骤：\n1.  对于一组给定的参数 $(\\alpha, \\beta^{\\mathrm{cond}}, \\sigma^2)$ 和一组网格化的 $x$ 值，使用高精度的高斯-埃尔米特求積法数值计算边际概率 $p(x) = \\int \\Phi(\\alpha + \\beta^{\\mathrm{cond}} x + b)f(b)db$。\n2.  通过计算 $z(x) = \\Phi^{-1}(p(x))$ 将计算出的概率 $p(x)$ 转换回Probit尺度。由于 $p(x)$ 的理论模型是一个完美的Probit函数，得到的 $z(x)$ 值应该位于一条直线上，$z(x) = \\alpha^{\\mathrm{marg}} + \\beta^{\\mathrm{marg}} x$。\n3.  对计算出的 $z(x)$ 值关于 $x$ 值执行普通最小二乘（OLS）回归，以获得经验估计值 $\\hat{\\beta}^{\\mathrm{marg}}_{\\text{empirical}}$。该回归的斜率由 $\\hat{\\beta} = \\frac{\\sum (x_i - \\bar{x})(z_i - \\bar{z})}{\\sum (x_i - \\bar{x})^2}$ 给出。\n4.  最后一步是计算此经验估计斜率与理论边际斜率之间的绝对误差：$|\\hat{\\beta}^{\\mathrm{marg}}_{\\text{empirical}} - \\beta^{\\mathrm{marg}}|$。这个误差将量化我们数值程序（在离散网格上的求积和回归）的准确性。\n\n通过变量替换 $b = \\sqrt{2}\\sigma t$ 来评估 $p(x)$ 的积分，将积分转换为高斯-埃尔米特求积的标准形式：\n$$\np(x) = \\frac{1}{\\sqrt{\\pi}} \\int_{-\\infty}^{\\infty} \\Phi(\\alpha + \\beta^{\\mathrm{cond}} x + \\sqrt{2}\\sigma t) e^{-t^2} dt \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{i=1}^{N} w_i \\Phi(\\alpha + \\beta^{\\mathrm{cond}} x + \\sqrt{2}\\sigma t_i)\n$$\n其中 $t_i$ 和 $w_i$ 是求积的节点和权重，而 $N$ 是节点数。\n\n以下Python代码为指定的测试用例实现了此验证程序。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# numpy.polynomial.hermite.hermgauss is part of the numpy library\n# specified in the environment and is permissible.\nfrom numpy.polynomial.hermite import hermgauss\n\ndef solve():\n    \"\"\"\n    Solves the problem of validating the relationship between subject-specific and\n    population-average parameters in a probit random-intercept model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, beta_cond, sigma^2)\n        (0.5, 1.0, 0.0),\n        (-0.2, 0.8, 0.5),\n        (1.0, -0.7, 4.0),\n        (0.0, 2.0, 9.0),\n        (0.3, 0.1, 1e-6)\n    ]\n\n    # Parameters for the numerical procedure\n    x_grid_points = 200\n    x_grid = np.linspace(-2.0, 2.0, x_grid_points)\n    gh_nodes_count = 100\n\n    # Pre-calculate Gauss-Hermite nodes and weights for numerical integration\n    # These are used to approximate integrals of the form integral(f(t)exp(-t^2), -inf, inf)\n    gh_nodes, gh_weights = hermgauss(gh_nodes_count)\n\n    results = []\n    for alpha, beta_cond, sigma2 in test_cases:\n        sigma = np.sqrt(sigma2)\n        \n        # 1. Calculate marginal probabilities p(x) via numerical integration.\n        # This computes p(x) for each x in x_grid.\n        p_values = np.zeros_like(x_grid)\n\n        # Handle the sigma=0 case separately to maintain precision and avoid unnecessary computation.\n        # When sigma=0, the random effect b=0, so the integral collapses.\n        if sigma  1e-12:\n            p_values = norm.cdf(alpha + beta_cond * x_grid)\n        else:\n            for i, x in enumerate(x_grid):\n                # The argument of Phi() inside the integral\n                integrand_arg = alpha + beta_cond * x + np.sqrt(2) * sigma * gh_nodes\n                \n                # The function f(t) in the Gauss-Hermite formula\n                f_values = norm.cdf(integrand_arg)\n                \n                # The integral is (1/sqrt(pi)) * sum(w_i * f(t_i))\n                integral_value = np.sum(gh_weights * f_values) / np.sqrt(np.pi)\n                p_values[i] = integral_value\n        \n        # 2. Transform p(x) back to the probit scale z(x) = Phi^-1(p(x)).\n        # Clip probabilities to avoid returning `inf` from norm.ppf for values of 0 or 1.\n        p_values = np.clip(p_values, 1e-15, 1.0 - 1e-15)\n        z_values = norm.ppf(p_values)\n\n        # 3. Estimate the empirical marginal slope via Ordinary Least Squares (OLS).\n        # Since x_grid is symmetric around 0, its mean is 0.\n        # The OLS slope formula simplifies to sum(x*z) / sum(x^2).\n        beta_marg_empirical = np.dot(x_grid, z_values) / np.dot(x_grid, x_grid)\n        \n        # 4. Compare with the theoretical marginal slope.\n        # For the probit-normal model, the relationship is exact: beta_marg = beta_cond / sqrt(1 + sigma^2).\n        beta_marg_theoretical = beta_cond / np.sqrt(1.0 + sigma2)\n        \n        # Compute the absolute error between the numerically estimated and theoretical slopes.\n        # This error primarily reflects the precision of the numerical methods used.\n        error = np.abs(beta_marg_empirical - beta_marg_theoretical)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) is used to format each float as a string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在掌握了特定个体与群体平均效应的基本区别后，我们进一步探讨一个在纵向数据分析中更为精细和关键的概念。在许多临床情境中，改变某个患者自身的暴露水平所产生的效应（例如，调整药物剂量），可能不同于比较具有不同平均暴露水平的患者群体时观察到的效应。 本练习引入了一个能够明确区分“组内”（within-cluster）效应和“组间”（between-cluster）效应的模型。通过这种分解，我们可以理解如何将特定个体的解释与指导个体化治疗决策的“组内”效应联系起来，同时认识到基于群体的比较为何可能受到“组间”差异的混淆。这项实践对于设计和解释能够同时为个体化医疗和公共卫生政策提供信息的纵向研究至关重要。",
            "id": "4978657",
            "problem": "考虑一个二元临床终点，例如慢性病患者在随访时疾病是否成功缓解。假设随访嵌套在患者（簇）中，并令 $Y_{ij} \\in \\{0,1\\}$ 表示患者 $i$ 第 $j$ 次随访的缓解状态。令 $x_{ij}$ 为一个连续的临床暴露（例如，标准化剂量强度），并将其分解为患者水平的均值和患者内部的偏差，即 $x_{ij} = \\bar{x}_i + \\tilde{x}_{ij}$，其中 $\\bar{x}_i = \\frac{1}{n_i}\\sum_j x_{ij}$ 且 $\\tilde{x}_{ij} = x_{ij} - \\bar{x}_i$。考虑一个具有独立簇内和簇间系数的随机截距 probit 回归模型：\n$$\n\\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}, \\bar{x}_i, b_i) \\;=\\; \\Phi\\!\\left(\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i + b_i\\right),\n$$\n其中 $\\Phi(\\cdot)$ 是标准正态随机变量的累积分布函数，$b_i \\sim \\mathcal{N}(0,\\sigma_b^2)$ 是一个患者特异性的随机截距，独立于 $x_{ij}$，而 $\\epsilon_{ij} \\sim \\mathcal{N}(0,1)$ 是 probit 误差。参数 $\\beta_0$、$\\beta_w$、$\\beta_b$ 和 $\\sigma_b^2$ 是未知常数。\n\n您的任务是，对于指定的参数值和指定的暴露单步变化 $\\Delta$，为每个测试案例计算以下四个量：\n\n- 特定主体簇内概率变化：在给定患者内，当暴露变化 $\\Delta$ 而患者均值保持固定时，缓解概率的变化。该变化在具有 $b_i = 0$ 和基线偏差 $\\tilde{x}_{ij}=0$ 的典型患者处进行评估，即：\n$$\n\\Delta p_{\\text{SS,within}} \\;=\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=\\Delta, \\bar{x}_i, b_i=0) \\;-\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i, b_i=0).\n$$\n\n- 特定主体簇间概率变化：在不同患者间，当患者水平的平均暴露变化 $\\Delta$ 而患者内部偏差保持为零时，缓解概率的变化。该变化在具有 $b_i = 0$ 的典型患者处进行评估，即：\n$$\n\\Delta p_{\\text{SS,between}} \\;=\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i+\\Delta, b_i=0) \\;-\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i, b_i=0).\n$$\n\n- 群体平均簇内概率变化：在对 $b_i$ 的分布进行积分后，患者内部暴露变化 $\\Delta$ 导致的缓解概率变化，即：\n$$\n\\Delta p_{\\text{PA,within}} \\;=\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=\\Delta, \\bar{x}_i) \\;-\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i).\n$$\n\n- 群体平均簇间概率变化：在对 $b_i$ 进行积分后，患者水平的平均暴露变化 $\\Delta$ 导致的缓解概率变化，即：\n$$\n\\Delta p_{\\text{PA,between}} \\;=\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i+\\Delta) \\;-\\; \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i).\n$$\n\n从 probit 模型的潜变量公式、正态分布的标准性质以及全概率定律出发，推导出实现这四个量所需的表达式。然后，编写一个程序，为每个测试案例计算这四个变化，结果为保留 $6$ 位小数的小数。不涉及物理单位。所有概率必须表示为小数（例如，$0.123456$），而不是百分比。\n\n测试套件参数化：对于每个案例，您将获得 $(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta)$。使用以下五个测试案例，这些案例旨在探测不同的情况，包括一般情况、近线性塌陷、高异质性、仅簇间效应以及符号反转边缘情况：\n\n- 案例 1：$(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta) = (-0.5, 0.8, -0.8, 1.0, 0.0, 1.0)$。\n- 案例 2：$(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta) = (-0.2, 0.5, 0.5, 0.1, 0.5, 1.0)$。\n- 案例 3：$(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta) = (-0.7, -0.2, 1.2, 4.0, -0.5, 1.0)$。\n- 案例 4：$(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta) = (-0.4, 0.0, 1.0, 0.5, -0.2, 1.0)$。\n- 案例 5：$(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta) = (-0.1, 0.3, -0.6, 2.0, 0.3, -1.0)$。\n\n您的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的列表组成的列表，每个内部列表按 $[\\Delta p_{\\text{SS,within}}, \\Delta p_{\\text{SS,between}}, \\Delta p_{\\text{PA,within}}, \\Delta p_{\\text{PA,between}}]$ 的顺序列出，每个数字都四舍五入到 $6$ 位小数。例如，一个有效的输出格式是 $[[a,b,c,d],[e,f,g,h],\\dots]$，其中 $a,b,c,d,e,f,g,h$ 是小数。不应打印其他文本。\n\n最后，在计算之后，请反思其含义：当由 $\\beta_b$ 控制的簇间效应与由 $\\beta_w$ 控制的簇内效应不同时，解释为什么基于跨患者比较的群体平均策略建议可能与指导患者内部剂量滴定的特定主体建议产生分歧，以及异质性参数 $\\sigma_b^2$ 如何通过边缘化来调节这种差异。",
            "solution": "该问题经彻底审查后被认为是有效的。它在科学上基于广义线性混合模型（GLMMs）的统计理论，提法良好，提供了所有必要信息，并且其表述是客观的。该任务是在非线性模型中推导和比较特定主体（条件）效应和群体平均（边缘）效应的一项标准的、非平凡的练习，这是纵向或聚类数据分析中的核心概念。\n\n解决方案分为三个部分：首先，推导所要求的四个概率变化的分析公式；其次，概述计算实现；第三，按要求反思结果的概念性含义。\n\n### 第1部分：公式推导\n\n该模型将患者 $i$ 第 $j$ 次随访在给定协变量和患者特异性随机截距 $b_i$ 的条件下的缓解概率指定为 probit 回归：\n$$\n\\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}, \\bar{x}_i, b_i) \\;=\\; \\Phi\\!\\left(\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i + b_i\\right)\n$$\n其中 $Y_{ij} \\in \\{0, 1\\}$，$\\tilde{x}_{ij}$ 是暴露 $x_{ij}$ 的患者内部偏差，$\\bar{x}_i$ 是患者水平的平均暴露，$\\Phi(\\cdot)$ 是标准正态累积分布函数（CDF），$b_i \\sim \\mathcal{N}(0, \\sigma_b^2)$ 是随机截距。\n\n**1.1 特定主体（SS）效应**\n\n特定主体效应是通过将随机截距 $b_i$ 固定在一个特定值来计算的。问题要求使用 $b_i=0$，这代表一个具有平均随机效应的患者。在这种情况下，$\\Phi(\\cdot)$ 的参数是 $\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i$。\n\n对于 $\\tilde{x}_{ij}=0$ 的典型患者，其基线概率为：\n$$\np_{\\text{SS,base}} = \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i, b_i=0) = \\Phi(\\beta_0 + \\beta_b \\bar{x}_i)\n$$\n\n对于簇内变化，$\\tilde{x}_{ij}$ 从 $0$ 变为 $\\Delta$，而 $\\bar{x}_i$ 保持不变。新的概率为：\n$$\np_{\\text{SS,after\\_within}} = \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=\\Delta, \\bar{x}_i, b_i=0) = \\Phi(\\beta_0 + \\beta_w \\Delta + \\beta_b \\bar{x}_i)\n$$\n变化是这两个概率之差：\n$$\n\\Delta p_{\\text{SS,within}} = \\Phi(\\beta_0 + \\beta_b \\bar{x}_i + \\beta_w \\Delta) - \\Phi(\\beta_0 + \\beta_b \\bar{x}_i)\n$$\n\n对于簇间变化，$\\bar{x}_i$ 从 $\\bar{x}_i$ 变为 $\\bar{x}_i+\\Delta$，而 $\\tilde{x}_{ij}=0$。新的概率为：\n$$\np_{\\text{SS,after\\_between}} = \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i+\\Delta, b_i=0) = \\Phi(\\beta_0 + \\beta_b (\\bar{x}_i + \\Delta))\n$$\n变化是这个概率与基线概率之差：\n$$\n\\Delta p_{\\text{SS,between}} = \\Phi(\\beta_0 + \\beta_b \\bar{x}_i + \\beta_b \\Delta) - \\Phi(\\beta_0 + \\beta_b \\bar{x}_i)\n$$\n\n**1.2 群体平均（PA）效应**\n\n群体平均效应需要对随机截距 $b_i$ 的分布进行边缘化。我们需要计算边缘概率 $\\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}, \\bar{x}_i)$。这可以通过对条件概率在 $b_i$ 的分布上积分得到：\n$$\n\\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}, \\bar{x}_i) = \\mathbb{E}_{b_i}\\left[\\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}, \\bar{x}_i, b_i)\\right] = \\int_{-\\infty}^{\\infty} \\Phi(\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i + b) f(b) \\, db\n$$\n其中 $f(b)$ 是 $\\mathcal{N}(0, \\sigma_b^2)$ 分布的概率密度函数。\n\n这个积分有一个众所周知的闭式解，可以使用 probit 模型的潜变量表述来推导。令 $Y_{ij}^*$ 为一个潜变量，使得 $Y_{ij}=1$ 当且仅当 $Y_{ij}^*  0$。该模型为：\n$$\nY_{ij}^* = \\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i + b_i + \\epsilon_{ij}\n$$\n其中 $b_i \\sim \\mathcal{N}(0, \\sigma_b^2)$ 和 $\\epsilon_{ij} \\sim \\mathcal{N}(0, 1)$ 是独立的误差项。这两个独立正态随机变量的和也是一个正态随机变量：$b_i + \\epsilon_{ij} \\sim \\mathcal{N}(0, \\sigma_b^2 + 1)$。\n\n因此，$Y_{ij}^*$ 在给定协变量下的边缘分布是：\n$$\nY_{ij}^* \\mid \\tilde{x}_{ij}, \\bar{x}_i \\sim \\mathcal{N}(\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i, \\, 1 + \\sigma_b^2)\n$$\n成功的边缘概率则是：\n$$\n\\Pr(Y_{ij}^*  0) = \\Pr\\left( \\mathcal{N}(0,1)  -\\frac{\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i}{\\sqrt{1 + \\sigma_b^2}} \\right) = \\Phi\\left(\\frac{\\beta_0 + \\beta_w \\tilde{x}_{ij} + \\beta_b \\bar{x}_i}{\\sqrt{1 + \\sigma_b^2}}\\right)\n$$\n这个结果表明，边缘模型也是一个 probit 模型，但其系数被因子 $c = \\sqrt{1 + \\sigma_b^2}$ 衰减。\n\n使用这个边缘概率表达式，我们可以推导出 PA 概率变化。在 $\\tilde{x}_{ij}=0$ 时的基线边缘概率是：\n$$\np_{\\text{PA,base}} = \\Pr(Y_{ij}=1 \\mid \\tilde{x}_{ij}=0, \\bar{x}_i) = \\Phi\\left(\\frac{\\beta_0 + \\beta_b \\bar{x}_i}{\\sqrt{1 + \\sigma_b^2}}\\right)\n$$\n\n对于簇内变化，$\\tilde{x}_{ij}$ 从 $0$ 变为 $\\Delta$：\n$$\n\\Delta p_{\\text{PA,within}} = \\Phi\\left(\\frac{\\beta_0 + \\beta_b \\bar{x}_i + \\beta_w \\Delta}{\\sqrt{1 + \\sigma_b^2}}\\right) - \\Phi\\left(\\frac{\\beta_0 + \\beta_b \\bar{x}_i}{\\sqrt{1 + \\sigma_b^2}}\\right)\n$$\n\n对于簇间变化，$\\bar{x}_i$ 变为 $\\bar{x}_i+\\Delta$：\n$$\n\\Delta p_{\\text{PA,between}} = \\Phi\\left(\\frac{\\beta_0 + \\beta_b \\bar{x}_i + \\beta_b \\Delta}{\\sqrt{1 + \\sigma_b^2}}\\right) - \\Phi\\left(\\frac{\\beta_0 + \\beta_b \\bar{x}_i}{\\sqrt{1 + \\sigma_b^2}}\\right)\n$$\n\n### 第2部分：计算策略\n\n推导出的公式在一个 Python 程序中实现。标准正态 CDF $\\Phi(z)$ 使用 `scipy.stats.norm.cdf(z)` 计算。对于由元组 $(\\beta_0, \\beta_w, \\beta_b, \\sigma_b^2, \\bar{x}_i, \\Delta)$ 定义的每个测试案例，程序计算四个概率变化：$\\Delta p_{\\text{SS,within}}$、$\\Delta p_{\\text{SS,between}}$、$\\Delta p_{\\text{PA,within}}$ 和 $\\Delta p_{\\text{PA,between}}$。每个测试案例的结果被收集、四舍五入到 $6$ 位小数，并格式化为所需的输出字符串。\n\n### 第3部分：含义反思\n\n区分簇内（$\\beta_w$）和簇间（$\\beta_b$）效应对于正确的推断和决策至关重要。当 $\\beta_w \\neq \\beta_b$ 时，意味着在患者*内部*改变暴露（例如，滴定药物剂量）的效果与通过比较具有不同平均暴露水平的不同患者所观察到的效果不同。这种差异通常被称为簇或背景混淆，其产生原因在于影响平均暴露 $\\bar{x}_i$ 的患者特征也可能独立地影响结果。\n\n- **特定主体（SS）建议**：系数 $\\beta_w$ 控制患者内部的变化。为特定患者滴定剂量的临床医生关心的是这种效应。基于 $\\beta_w$ 的建议指导如何为个体调整治疗以优化其结果。\n\n- **群体平均（PA）建议**：系数 $\\beta_b$ 控制跨患者或患者间的变化。决定是否推荐一种治疗方法在人群中广泛使用的公共卫生官员可能会依赖于这种比较。这是从忽略数据纵向结构的横断面研究中估计出的效应。\n\n当 $\\beta_w$ 和 $\\beta_b$ 不同时，基于一种效应的策略如果应用于另一种效应的背景下可能会产生误导。例如，如果通常给病情更重的患者更高的平均剂量（$\\bar{x}_i$），$\\beta_b$ 可能会很小甚至是负数（更高剂量与更差结果相关）。然而，在任何给定患者内部，增加剂量可能是有益的，导致正的 $\\beta_w$。横断面分析可能错误地得出结论，认为该药物无效或有害，而纵向分析则会揭示其对个体患者的益处。\n\n异质性参数 $\\sigma_b^2$ 在调节特定主体效应和群体平均效应之间的关系中起着关键作用。边缘化过程（即对随机效应 $b_i$ 的分布进行平均）导致回归系数被因子 $c = \\sqrt{1+\\sigma_b^2}$ 衰减。\n- 如果没有主体间异质性（$\\sigma_b^2 = 0$），那么 $c=1$。随机效应消失，每个主体在先验上是相同的，群体平均效应在 probit 尺度上等于特定主体效应。概率变化 $\\Delta p_{\\text{PA}}$ 和 $\\Delta p_{\\text{SS}}$ 变得相同。\n- 随着异质性增加（$\\sigma_b^2  0$），衰减因子 $c$ 变得大于 $1$。这会“拉平”边缘剂量反应曲线。对于线性预测变量的给定变化，相应的边缘概率变化小于条件（特定主体）概率的变化。在极端异质性的极限情况下（$\\sigma_b^2 \\to \\infty$），边缘效应被衰减到零，这意味着观察患者的协变量平均而言不能提供关于其结果的任何信息，因为结果被非常大的个体特异性随机变异所主导。因此，$\\sigma_b^2$ 量化了群体水平关于概率变化的陈述与主体水平的陈述相比被减弱的程度。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes subject-specific and population-average probability changes for a \n    random-intercept probit model based on a set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (beta_0, beta_w, beta_b, sigma_b^2, x_bar_i, Delta)\n        (-0.5, 0.8, -0.8, 1.0, 0.0, 1.0),\n        (-0.2, 0.5, 0.5, 0.1, 0.5, 1.0),\n        (-0.7, -0.2, 1.2, 4.0, -0.5, 1.0),\n        (-0.4, 0.0, 1.0, 0.5, -0.2, 1.0),\n        (-0.1, 0.3, -0.6, 2.0, 0.3, -1.0),\n    ]\n\n    results = []\n\n    def calculate_changes(params):\n        \"\"\"\n        Calculates the four probability changes for a single parameter set.\n        \"\"\"\n        beta_0, beta_w, beta_b, sigma_b2, x_bar_i, delta = params\n\n        # Standard normal CDF\n        phi = norm.cdf\n\n        # --- Subject-Specific (SS) Calculations ---\n        # Baseline linear predictor for SS model at x_tilde_ij = 0, b_i = 0\n        lp_ss_base = beta_0 + beta_b * x_bar_i\n        # Baseline probability\n        p_ss_base = phi(lp_ss_base)\n\n        # SS within-cluster change\n        lp_ss_after_within = lp_ss_base + beta_w * delta\n        p_ss_after_within = phi(lp_ss_after_within)\n        delta_p_ss_within = p_ss_after_within - p_ss_base\n\n        # SS between-cluster change\n        lp_ss_after_between = lp_ss_base + beta_b * delta\n        p_ss_after_between = phi(lp_ss_after_between)\n        delta_p_ss_between = p_ss_after_between - p_ss_base\n\n        # --- Population-Average (PA) Calculations ---\n        # Attenuation factor due to marginalization\n        c = np.sqrt(1.0 + sigma_b2)\n\n        # Baseline linear predictor for PA model\n        lp_pa_base = lp_ss_base / c\n        # Baseline probability\n        p_pa_base = phi(lp_pa_base)\n\n        # PA within-cluster change\n        lp_pa_after_within = lp_ss_after_within / c\n        p_pa_after_within = phi(lp_pa_after_within)\n        delta_p_pa_within = p_pa_after_within - p_pa_base\n\n        # PA between-cluster change\n        lp_pa_after_between = lp_ss_after_between / c\n        p_pa_after_between = phi(lp_pa_after_between)\n        delta_p_pa_between = p_pa_after_between - p_pa_base\n        \n        return [\n            delta_p_ss_within,\n            delta_p_ss_between,\n            delta_p_pa_within,\n            delta_p_pa_between\n        ]\n\n    for case in test_cases:\n        case_results = calculate_changes(case)\n        results.append(case_results)\n\n    # Format the output as specified: [[a,b,c,d],[e,f,g,h],...] with 6 decimal places.\n    output_parts = []\n    for res_list in results:\n        formatted_list = [f\"{num:.6f}\" for num in res_list]\n        output_parts.append(f\"[{','.join(formatted_list)}]\")\n    \n    final_output_string = f\"[{','.join(output_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```"
        },
        {
            "introduction": "在探讨了两种效应的数学关系和概念区别后，最后一个实践练习将展示这些差异在临床风险预测中的实际影响。我们将使用在医学研究中广泛应用的 logistic 随机效应模型。 由于 logistic 连接函数的非线性特性，根据琴生不等式（Jensen's inequality），对条件概率进行平均所得到的边际概率会发生系统性偏移。这个练习将量化这种偏移导致的后果：使用群体平均模型而非特定个体模型进行风险评估，会导致患者的风险分层发生改变。通过计算“风险重分类”指标，你将具体地体会到，模型的选择和解释不仅是理论上的细微差别，更直接关系到临床决策和患者管理。",
            "id": "4978732",
            "problem": "您正在研究一种常用于医学领域的二元结果模型中，群体平均风险和受试者特定风险解释之间的差异。请考虑以下基于伯努利随机变量和带有逻辑斯蒂链接的广义线性模型基本定义所建立的框架。\n\n令 $Y \\in \\{0,1\\}$ 表示一个二元临床结局，令 $X \\in \\mathbb{R}$ 为一个标量协变量。假设在给定一个潜在的受试者特定随机截距 $B$ 的条件下，$Y$ 在给定 $X=x$ 和 $B=b$ 时的条件分布遵循伯努利分布，其成功概率为\n$$\np_{\\mathrm{cond}}(x \\mid b) \\;=\\; \\operatorname{logit}^{-1}\\!\\big(\\beta_0 + \\beta_1 x + b\\big) \\;=\\; \\frac{1}{1 + \\exp\\!\\big(-(\\beta_0 + \\beta_1 x + b)\\big)}.\n$$\n假设随机截距 $B$ 服从均值为 $0$、方差为 $\\sigma^2$ 的高斯分布，即 $B \\sim \\mathcal{N}(0,\\sigma^2)$。将一个典型受试者（即条件为 $B=0$）的受试者特定风险定义为\n$$\np_{\\mathrm{SS}}(x) \\;=\\; \\operatorname{logit}^{-1}\\!\\big(\\beta_0 + \\beta_1 x\\big).\n$$\n将群体平均（边际）风险定义为条件风险在 $B$ 的分布上的期望：\n$$\np_{\\mathrm{PA}}(x) \\;=\\; \\mathbb{E}\\!\\left[\\operatorname{logit}^{-1}\\!\\big(\\beta_0 + \\beta_1 x + B\\big)\\right] \\;=\\; \\int_{-\\infty}^{\\infty} \\frac{1}{1+\\exp\\!\\big(-(\\beta_0 + \\beta_1 x + b)\\big)} \\,\\phi\\!\\left(b;0,\\sigma^2\\right)\\, \\mathrm{d}b,\n$$\n其中 $\\phi(\\cdot;0,\\sigma^2)$ 表示均值为 $0$、方差为 $\\sigma^2$ 的高斯概率密度函数。\n\n您将研究在固定的分类阈值 $t \\in (0,1)$ 下，对于相同的协变量特征 $x$，使用 $p_{\\mathrm{PA}}(x)$ 代替 $p_{\\mathrm{SS}}(x)$ 时，二元风险分层会如何变化。对于一组由索引 $i$ 标记、协变量值为 $x_i$ 的受试者，定义\n- 受试者特定分类 $C_{\\mathrm{SS},i} = \\mathbf{1}\\{\\,p_{\\mathrm{SS}}(x_i) \\ge t\\,\\}$，\n- 群体平均分类 $C_{\\mathrm{PA},i} = \\mathbf{1}\\{\\,p_{\\mathrm{PA}}(x_i) \\ge t\\,\\}$，\n- 向上重分类计数 $U = \\sum_i \\mathbf{1}\\{\\,C_{\\mathrm{SS},i}=0 \\;\\wedge\\; C_{\\mathrm{PA},i}=1\\,\\}$，\n- 向下重分类计数 $D = \\sum_i \\mathbf{1}\\{\\,C_{\\mathrm{SS},i}=1 \\;\\wedge\\; C_{\\mathrm{PA},i}=0\\,\\}$，\n- 以及净重分类变化 $R = (U - D)/N$，其中 $N$ 是受试者数量。\n\n从上述定义出发，并且不假定定义 $p_{\\mathrm{PA}}(x)$ 的积分有任何闭式解，设计一个使用高斯求积法数值计算 $p_{\\mathrm{PA}}(x)$ 的算法，该算法需与积分定义一致。然后，实现一个程序，对下面的每个测试用例，计算元组 $\\big(U, D, R\\big)$ 并汇总结果。\n\n积分的数值要求：使用高斯-埃尔米特求积法来近似关于高斯随机截距的期望。如果对于权重函数 $\\exp(-z^2)$，求积节点为 $z_j$ 且权重为 $w_j$，那么对于任何可测函数 $f$ 和任何 $\\sigma \\ge 0$，近似\n$$\n\\mathbb{E}\\big[f(B)\\big] \\;=\\; \\int_{-\\infty}^{\\infty} f(b)\\,\\phi\\!\\left(b;0,\\sigma^2\\right)\\,\\mathrm{d}b\n\\;\\approx\\; \\frac{1}{\\sqrt{\\pi}} \\sum_{j=1}^{m} w_j\\, f\\!\\big(\\sqrt{2}\\,\\sigma\\, z_j\\big),\n$$\n其中节点数 $m$ 为整数且 $m \\ge 64$。根据定义一致地处理 $\\sigma^2 = 0$ 的特殊情况。\n\n测试套件。对于每个用例，使用提供的参数值和 $x_i$ 的协变量列表，并在阈值 $t$ 下进行分类：\n- 用例 1：$\\beta_0 = -2.0$, $\\beta_1 = 1.2$, $\\sigma^2 = 0.7$, $t = 0.2$，以及协变量 $x = \\big[-1.0,\\,-0.5,\\,0.0,\\,0.2,\\,0.5,\\,1.0,\\,1.5,\\,2.0\\big]$。\n- 用例 2（群体平均值等于受试者特定值的边界情况）：$\\beta_0 = -2.0$, $\\beta_1 = 1.2$, $\\sigma^2 = 0.0$, $t = 0.2$，以及协变量 $x = \\big[-1.0,\\,-0.5,\\,0.0,\\,0.2,\\,0.5,\\,1.0,\\,1.5,\\,2.0\\big]$。\n- 用例 3：$\\beta_0 = -1.0$, $\\beta_1 = 0.9$, $\\sigma^2 = 2.0$, $t = 0.5$，以及协变量 $x = \\big[-2.0,\\,-1.0,\\,0.0,\\,0.5,\\,1.0,\\,1.5,\\,2.5\\big]$。\n- 用例 4：$\\beta_0 = 0.5$, $\\beta_1 = 0.8$, $\\sigma^2 = 1.0$, $t = 0.9$，以及协变量 $x = \\big[0.0,\\,0.5,\\,1.0,\\,1.5,\\,2.0,\\,3.0\\big]$。\n- 用例 5（相同的协变量特征）：$\\beta_0 = -1.0$, $\\beta_1 = 2.0$, $\\sigma^2 = 1.0$, $t = 0.4$，以及协变量 $x = \\big[0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5,\\,0.5\\big]$。\n\n答案规格和输出格式：\n- 对于每个用例，计算 $\\big(U,D,R\\big)$，其中 $U$ 和 $D$ 是整数，$R$ 是一个实数。\n- 将 $R$ 表示为小数点后精确到 $6$ 位的小数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。此列表中的每个元素必须是对应一个用例的三元素列表，按上述用例的顺序排列，格式为 $\\big[U,D,R\\big]$。例如，一个有效的输出行形式为 $\\big[[U_1,D_1,R_1],[U_2,D_2,R_2],\\dots\\big]$。\n- 不涉及物理单位。\n- 不涉及角度。\n- 不要读取任何输入；仅使用上面指定的参数和协变量值。",
            "solution": "该问题已经过验证，被认为是有效的。它科学地基于统计建模（特别是广义线性混合模型）的既定原则，问题阐述清晰，提供了所有必要的信息，并使用了明确、客观的定义。任务是计算通过比较受试者特定风险预测和群体平均风险预测而产生的重分类指标，这是医学统计学和流行病学中的一个标准且重要的话题。\n\n此问题的核心在于理解对统计模型预测的受试者特定（SS）解释与群体平均（PA）解释之间的区别。这种区别对于非线性模型（例如此处提出的逻辑斯蒂回归模型）至关重要，特别是当它们包含随机效应以解释受试者层面的异质性时。\n\n令具有协变量 $x$ 和随机截距 $b$ 的受试者的线性预测变量为 $\\eta(x, b) = \\beta_0 + \\beta_1 x + b$。条件风险由逆-logit函数给出，$p_{\\mathrm{cond}}(x \\mid b) = g^{-1}(\\eta(x, b))$，其中 $g^{-1}(z) = (1 + \\exp(-z))^{-1}$。\n\n受试者特定风险 $p_{\\mathrm{SS}}(x)$ 是为一个“典型”受试者定义的，对此类受试者而言，随机效应等于其均值 $0$。因此，它是对特定（或典型）个体模型的直接评估：\n$$\np_{\\mathrm{SS}}(x) = g^{-1}(\\beta_0 + \\beta_1 x) = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta_1 x))}\n$$\n\n群体平均风险 $p_{\\mathrm{PA}}(x)$ 是边际风险，通过在整个随机效应群体上对条件风险进行平均而获得。在数学上，这是条件风险关于随机截距 $B \\sim \\mathcal{N}(0, \\sigma^2)$ 分布的期望：\n$$\np_{\\mathrm{PA}}(x) = \\mathbb{E}_{B} \\left[ p_{\\mathrm{cond}}(x \\mid B) \\right] = \\mathbb{E}_{B} \\left[ g^{-1}(\\beta_0 + \\beta_1 x + B) \\right]\n$$\n由于逆-logit函数 $g^{-1}$ 是非线性的，根据琴生不等式，对于随机变量 $Z$，有 $\\mathbb{E}[g^{-1}(Z)] \\neq g^{-1}(\\mathbb{E}[Z])$。在逻辑斯蒂模型的背景下，对随机效应分布进行平均的效果是响应曲线的衰减或“扁平化”。得到的 $p_{\\mathrm{PA}}(x)$ 曲线将不如 $p_{\\mathrm{SS}}(x)$ 曲线陡峭，其值将被拉向 $0.5$。这意味着，如果 $p_{\\mathrm{SS}}(x)  0.5$，则 $p_{\\mathrm{SS}}(x)  p_{\\mathrm{PA}}(x)  0.5$。反之，如果 $p_{\\mathrm{SS}}(x)  0.5$，则 $p_{\\mathrm{SS}}(x)  p_{\\mathrm{PA}}(x)  0.5$。这种系统性差异正是我们需要量化的重分类事件的来源。\n\n定义 $p_{\\mathrm{PA}}(x)$ 的积分通常没有闭式解，必须进行数值近似。问题指定使用高斯-埃尔米特求积法，这是一种适用于形式为 $\\int_{-\\infty}^{\\infty} e^{-z^2} h(z) dz$ 的积分的合适方法。问题提供了正确的变换，以将此方法应用于对高斯随机变量 $B \\sim \\mathcal{N}(0, \\sigma^2)$ 的期望。令 $f(b) = g^{-1}(\\beta_0 + \\beta_1 x + b)$，则期望近似为：\n$$\np_{\\mathrm{PA}}(x) = \\mathbb{E}\\big[f(B)\\big] \\approx \\frac{1}{\\sqrt{\\pi}} \\sum_{j=1}^{m} w_j\\, f\\!\\big(\\sqrt{2}\\,\\sigma\\, z_j\\big)\n$$\n其中 $z_j$ 和 $w_j$ 是针对权重函数 $e^{-z^2}$ 的 $m$ 点高斯-埃尔米特求积的节点和权重，且 $\\sigma = \\sqrt{\\sigma^2}$。在 $\\sigma^2 = 0$ 的特殊情况下，我们有 $\\sigma=0$，因此 $f$ 的参数始终为 $0$。该公式正确地简化为 $f(0) \\frac{1}{\\sqrt{\\pi}}\\sum_j w_j = f(0) \\frac{\\sqrt{\\pi}}{\\sqrt{\\pi}} = f(0) = p_{\\mathrm{SS}}(x)$，从而确保了一致性。\n\n对于每个测试用例，总体算法流程如下：\n$1.$ 获取 $m \\ge 64$ 个高斯-埃尔米特求积节点 $z_j$ 和权重 $w_j$。\n$2.$ 初始化重分类计数 $U=0$ 和 $D=0$。令 $N$ 为受试者总数（即协变量列表的长度）。\n$3.$ 对于所提供列表中的每个协变量值 $x_i$：\n    a. 计算受试者特定风险 $p_{\\mathrm{SS}}(x_i) = (1 + \\exp(-(\\beta_0 + \\beta_1 x_i)))^{-1}$。\n    b. 使用高斯-埃尔米特求积公式计算群体平均风险 $p_{\\mathrm{PA}}(x_i)$。如果 $\\sigma^2=0$，则设置 $p_{\\mathrm{PA}}(x_i) = p_{\\mathrm{SS}}(x_i)$。否则，计算总和 $\\frac{1}{\\sqrt{\\pi}} \\sum_{j=1}^{m} w_j (1 + \\exp(-(\\beta_0 + \\beta_1 x_i + \\sqrt{2}\\sigma z_j)))^{-1}$。\n    c. 应用分类阈值 $t$ 来确定分类：$C_{\\mathrm{SS},i} = \\mathbf{1}\\{p_{\\mathrm{SS}}(x_i) \\ge t\\}$ 和 $C_{\\mathrm{PA},i} = \\mathbf{1}\\{p_{\\mathrm{PA}}(x_i) \\ge t\\}$。\n    d. 更新计数：如果 $C_{\\mathrm{SS},i}=0$ 且 $C_{\\mathrm{PA},i}=1$，则 $U$ 加一；如果 $C_{\\mathrm{SS},i}=1$ 且 $C_{\\mathrm{PA},i}=0$，则 $D$ 加一。\n$4.$ 遍历所有协变量后，计算净重分类变化 $R = (U - D) / N$。\n$5.$ 存储结果元组 $(U, D, R)$，确保 $R$ 四舍五入到小数点后 $6$ 位。\n\n对所有测试用例重复此过程，将生成所需的输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_hermite\n\ndef solve():\n    \"\"\"\n    Solves the reclassification problem for all test cases specified.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"beta0\": -2.0, \"beta1\": 1.2, \"sigma_sq\": 0.7, \"t\": 0.2,\n            \"x_covariates\": [-1.0, -0.5, 0.0, 0.2, 0.5, 1.0, 1.5, 2.0]\n        },\n        {\n            \"beta0\": -2.0, \"beta1\": 1.2, \"sigma_sq\": 0.0, \"t\": 0.2,\n            \"x_covariates\": [-1.0, -0.5, 0.0, 0.2, 0.5, 1.0, 1.5, 2.0]\n        },\n        {\n            \"beta0\": -1.0, \"beta1\": 0.9, \"sigma_sq\": 2.0, \"t\": 0.5,\n            \"x_covariates\": [-2.0, -1.0, 0.0, 0.5, 1.0, 1.5, 2.5]\n        },\n        {\n            \"beta0\": 0.5, \"beta1\": 0.8, \"sigma_sq\": 1.0, \"t\": 0.9,\n            \"x_covariates\": [0.0, 0.5, 1.0, 1.5, 2.0, 3.0]\n        },\n        {\n            \"beta0\": -1.0, \"beta1\": 2.0, \"sigma_sq\": 1.0, \"t\": 0.4,\n            \"x_covariates\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n        }\n    ]\n\n    # Use a number of quadrature nodes m = 64.\n    m_nodes = 100\n    nodes, weights = roots_hermite(m_nodes)\n\n    def logit_inv(z):\n        \"\"\"Computes the inverse logit (sigmoid) function.\"\"\"\n        # Clip z to avoid overflow in exp\n        z = np.clip(z, -500, 500)\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def compute_pa_risk(eta, sigma, nodes, weights):\n        \"\"\"\n        Computes the population-average risk using Gauss-Hermite quadrature.\n        eta: The fixed-effects part of the linear predictor (beta0 + beta1*x).\n        sigma: The standard deviation of the random effect (sqrt of sigma_sq).\n        \"\"\"\n        if sigma == 0.0:\n            return logit_inv(eta)\n        \n        # Transformation for the quadrature rule\n        b_values = np.sqrt(2.0) * sigma * nodes\n        # Calculate the function values at each transformed node\n        f_values = logit_inv(eta + b_values)\n        # Compute the weighted sum\n        integral_approx = np.sum(weights * f_values) / np.sqrt(np.pi)\n        \n        return integral_approx\n\n    results = []\n    for case in test_cases:\n        beta0 = case[\"beta0\"]\n        beta1 = case[\"beta1\"]\n        sigma_sq = case[\"sigma_sq\"]\n        t = case[\"t\"]\n        x_covariates = case[\"x_covariates\"]\n\n        N = len(x_covariates)\n        U = 0\n        D = 0\n        sigma = np.sqrt(sigma_sq)\n\n        for x_i in x_covariates:\n            # Linear predictor for the fixed part\n            eta_i = beta0 + beta1 * x_i\n\n            # 1. Subject-specific risk and classification\n            p_ss = logit_inv(eta_i)\n            c_ss = 1 if p_ss = t else 0\n\n            # 2. Population-average risk and classification\n            p_pa = compute_pa_risk(eta_i, sigma, nodes, weights)\n            c_pa = 1 if p_pa = t else 0\n\n            # 3. Check for reclassification\n            if c_ss == 0 and c_pa == 1:\n                U += 1\n            elif c_ss == 1 and c_pa == 0:\n                D += 1\n        \n        # 4. Net reclassification change\n        R = (U - D) / N if N  0 else 0.0\n        \n        results.append([U, D, R])\n\n    # Format the final output string exactly as specified\n    formatted_results = []\n    for u, d, r in results:\n        # Round R to 6 decimal places and format\n        formatted_results.append(f\"[{u},{d},{r:.6f}]\")\n    \n    # Print the single line of output\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}