{
    "hands_on_practices": [
        {
            "introduction": "The ability to correctly read conditional independencies from a graph is the foundational skill in causal modeling with Directed Acyclic Graphs (DAGs). This practice sharpens that skill by focusing on the \"collider,\" a node where two arrows meet. Understanding how conditioning on a collider uniquely affects the path between two variables is crucial for correctly applying concepts like the backdoor criterion and identifying sources of bias. ",
            "id": "4557701",
            "problem": "In a causal analysis for medical data, consider a Directed Acyclic Graph (DAG) representing a simplified pathway in translational bioinformatics where $X$ denotes a genetic variant, $Y$ denotes an environmental exposure, $Z$ denotes a molecular biomarker, and $W$ denotes a downstream clinical outcome. The DAG has node set $\\{X, Y, Z, W\\}$ and directed edges $X \\to Z$, $Y \\to Z$, $Z \\to W$, and no other edges. Using the formal definition of $d$-separation in Directed Acyclic Graphs, proceed as follows:\n\n- Enumerate all simple paths (paths with no repeated nodes) between $X$ and $Y$.\n- For each simple path $p$ between $X$ and $Y$, let $I(p)$ be an indicator defined by $I(p) = 1$ if the path is blocked when conditioning on $Z$ under $d$-separation, and $I(p) = 0$ otherwise.\n- Define the quantity $D$ by\n$$\nD \\;=\\; \\prod_{p \\in \\mathcal{P}(X,Y)} I(p),\n$$\nwhere $\\mathcal{P}(X,Y)$ is the set of all simple paths between $X$ and $Y$.\n\nCompute the value of $D$. The final answer must be reported as a single real number. No rounding is required and no units are to be included in the final answer.",
            "solution": "The problem requires the computation of a quantity $D$ related to the concept of $d$-separation in a specified Directed Acyclic Graph (DAG). We must first validate the problem statement.\n\nThe problem provides the following givens:\n- A set of nodes $V = \\{X, Y, Z, W\\}$, representing a genetic variant ($X$), an environmental exposure ($Y$), a molecular biomarker ($Z$), and a clinical outcome ($W$).\n- A set of directed edges $E = \\{(X,Z), (Y,Z), (Z,W)\\}$, which correspond to the graphical structure $X \\to Z$, $Y \\to Z$, and $Z \\to W$.\n- The constraint that no other edges exist in the graph.\n- A definition for an indicator function $I(p)$ for any simple path $p$ between $X$ and $Y$. $I(p)=1$ if path $p$ is blocked by conditioning on $Z$, and $I(p)=0$ otherwise.\n- A definition for the quantity $D = \\prod_{p \\in \\mathcal{P}(X,Y)} I(p)$, where $\\mathcal{P}(X,Y)$ is the set of all simple paths between $X$ and $Y$.\n\nThe problem is scientifically grounded, as it uses standard, well-defined concepts from the theory of graphical models and causal inference, specifically DAGs and $d$-separation. The structure and variables are typical of a simplified model in bioinformatics. The problem is well-posed, with a fully specified graph and a clear objective. It is objective, complete, and contains no contradictions. Therefore, the problem is deemed valid and we may proceed with the solution.\n\nThe solution process involves three steps:\n1.  Identify the set of all simple paths between $X$ and $Y$, denoted $\\mathcal{P}(X,Y)$.\n2.  For each path in this set, determine if it is blocked by conditioning on $Z$.\n3.  Compute the value of $D$ based on these determinations.\n\nStep 1: Enumerate simple paths between $X$ and $Y$.\nA path in a graph is a sequence of nodes connected by edges, where the direction of the edges is disregarded for the purpose of path traversal. A simple path is one that does not contain repeated nodes.\nThe graph structure is given by the edges $X \\to Z$, $Y \\to Z$, and $Z \\to W$.\nTo find a path from $X$ to $Y$, we start at $X$. The only node adjacent to $X$ is $Z$. From $Z$, the adjacent nodes are $X$, $Y$, and $W$. To reach $Y$ without repeating nodes, the only possible next step from $Z$ is to $Y$.\nThus, there is exactly one simple path between $X$ and $Y$: the path $p_1 = (X, Z, Y)$.\nThe set of all simple paths is $\\mathcal{P}(X,Y) = \\{p_1\\}$.\n\nStep 2: Apply the rules of $d$-separation to the path $p_1$.\nThe path $p_1 = (X, Z, Y)$ consists of the edges $X \\to Z$ and $Y \\to Z$. When viewed as a segment of a path, this structure is $X \\to Z \\leftarrow Y$.\nIn the terminology of $d$-separation, the node $Z$ is a **collider** on this path, because two arrowheads meet at $Z$.\n\nThe rules for a path being blocked by a conditioning set $S$ are as follows:\nA path is blocked if it contains a node $N$ such that:\n(a) $N$ is a chain node ($\\to N \\to$) or a fork node ($\\leftarrow N \\to$) on the path, and $N \\in S$.\n(b) $N$ is a collider node ($\\to N \\leftarrow$) on the path, and neither $N$ nor any of its descendants are in $S$.\n\nWe are asked to determine if the path $p_1$ is blocked when conditioning on the set $S = \\{Z\\}$.\nThe path $p_1$ contains the collider node $Z$. We apply rule (b).\nFor the path to be blocked by the collider, the condition is that neither the collider itself ($Z$) nor any of its descendants must be in the conditioning set $S$.\nIn this case, the conditioning set is $S = \\{Z\\}$. The collider node $Z$ is itself in the conditioning set.\nTherefore, the condition for the path to be blocked is not met. A path that is not blocked is said to be open or unblocked.\nConditioning on a collider (or one of its descendants) opens the path of association.\nSo, the path $p_1$ is **not blocked** when conditioning on $Z$.\n\nStep 3: Compute the value of $D$.\nThe indicator function $I(p)$ is defined as $I(p)=1$ if the path $p$ is blocked, and $I(p)=0$ otherwise.\nFor our path $p_1$, since it is not blocked by conditioning on $Z$, the value of the indicator is $I(p_1) = 0$.\n\nThe quantity $D$ is the product of these indicator values over all simple paths between $X$ and $Y$.\n$$\nD = \\prod_{p \\in \\mathcal{P}(X,Y)} I(p)\n$$\nSince $\\mathcal{P}(X,Y) = \\{p_1\\}$, this product simplifies to:\n$$\nD = I(p_1)\n$$\nSubstituting the value we found for $I(p_1)$:\n$$\nD = 0\n$$\nThe final value is $0$.",
            "answer": "$$\\boxed{0}$$"
        },
        {
            "introduction": "A central challenge in medical research is distinguishing the causal effect of a treatment from mere statistical association. This practice moves from graphical rules to their primary application: calculating the effect of an intervention, denoted by the $do$-operator, in the presence of a confounder. By working through the adjustment formula, you will quantify the difference between the observational relationship $P(Y=1 \\mid X=1)$ and the causal effect $P(Y=1 \\mid do(X=1))$, gaining a practical understanding of confounding bias. ",
            "id": "4557745",
            "problem": "In a study of transcriptomic response in an oncology cohort, consider a directed acyclic graph with baseline inflammatory genotype $A$, targeted therapy administration $X$, and a binary gene expression outcome $Y$ indicating upregulation of an interleukin transcript. The causal diagram is $A \\to X \\to Y$ and $A \\to Y$, reflecting a confounding path from $A$ to $Y$ and a direct treatment effect $X \\to Y$. Assume all variables are binary with state space $\\{0,1\\}$, and the joint observational distribution factorizes according to the causal Markov property as $P(A,X,Y) = P(A) P(X \\mid A) P(Y \\mid X, A)$. The following conditional distributions are known from a well-calibrated propensity model and a calibrated predictive model:\n- Baseline genotype prevalence: $P(A=1) = \\tfrac{1}{3}$ and $P(A=0) = \\tfrac{2}{3}$.\n- Treatment assignment mechanism: $P(X=1 \\mid A=1) = \\tfrac{3}{4}$, $P(X=0 \\mid A=1) = \\tfrac{1}{4}$, $P(X=1 \\mid A=0) = \\tfrac{1}{4}$, and $P(X=0 \\mid A=0) = \\tfrac{3}{4}$.\n- Gene expression model: $P(Y=1 \\mid X=1, A=1) = \\tfrac{4}{5}$, $P(Y=1 \\mid X=0, A=1) = \\tfrac{2}{5}$, $P(Y=1 \\mid X=1, A=0) = \\tfrac{3}{10}$, and $P(Y=1 \\mid X=0, A=0) = \\tfrac{1}{10}$, with complements given by $P(Y=0 \\mid X, A) = 1 - P(Y=1 \\mid X, A)$.\n\nUsing only the core definition of intervention on a directed acyclic graph and standard probability rules:\n1. Compute the interventional probability $P(Y=1 \\mid do(X=1))$ under the intervention that sets $X$ to $1$.\n2. Compute the observational probability $P(Y=1 \\mid X=1)$.\n\nDefine the contrast\n$$\\Delta \\equiv P(Y=1 \\mid do(X=1)) - P(Y=1 \\mid X=1).$$\nExpress your final answer for $\\Delta$ as a single reduced fraction. No rounding is required and no units are needed. Submit only the value of $\\Delta$ as your final answer.",
            "solution": "The problem will first be validated for scientific soundness, well-posedness, and objectivity.\n\n### Step 1: Extract Givens\n- **Causal Structure:** Directed acyclic graph (DAG) with variables $A$ (baseline inflammatory genotype), $X$ (targeted therapy administration), and $Y$ (binary gene expression outcome). The causal diagram is $A \\to X \\to Y$ and $A \\to Y$.\n- **Variable States:** All variables are binary with state space $\\{0,1\\}$.\n- **Joint Distribution Factorization:** $P(A,X,Y) = P(A) P(X \\mid A) P(Y \\mid X, A)$.\n- **Baseline Genotype Prevalence:**\n  - $P(A=1) = \\frac{1}{3}$\n  - $P(A=0) = \\frac{2}{3}$\n- **Treatment Assignment Mechanism (Propensity Model):**\n  - $P(X=1 \\mid A=1) = \\frac{3}{4}$\n  - $P(X=0 \\mid A=1) = \\frac{1}{4}$\n  - $P(X=1 \\mid A=0) = \\frac{1}{4}$\n  - $P(X=0 \\mid A=0) = \\frac{3}{4}$\n- **Gene Expression Model (Predictive Model):**\n  - $P(Y=1 \\mid X=1, A=1) = \\frac{4}{5}$\n  - $P(Y=1 \\mid X=0, A=1) = \\frac{2}{5}$\n  - $P(Y=1 \\mid X=1, A=0) = \\frac{3}{10}$\n  - $P(Y=1 \\mid X=0, A=0) = \\frac{1}{10}$\n- **Quantities to compute:**\n  1. $P(Y=1 \\mid do(X=1))$\n  2. $P(Y=1 \\mid X=1)$\n- **Final quantity to express:**\n  $\\Delta \\equiv P(Y=1 \\mid do(X=1)) - P(Y=1 \\mid X=1)$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed against the validation criteria.\n- **Scientifically Grounded:** The problem is firmly rooted in the established principles of causal inference, specifically using directed acyclic graphs (DAGs) and the `do`-calculus framework developed by Judea Pearl. The application context—bioinformatics and medical data analytics—is a primary field for such causal modeling. The concepts of confounding (the path $A \\to Y$), adjustment for confounders, and the distinction between observational ($P(Y \\mid X)$) and interventional ($P(Y \\mid do(X))$) probabilities are all standard and fundamental to the discipline. The factorization of the joint probability distribution is consistent with the causal Markov property for the given DAG. All premises are scientifically sound.\n- **Well-Posed:** The problem is fully specified. It provides a complete set of conditional probability distributions required to compute the joint distribution $P(A,X,Y)$ and any marginal or conditional quantities derived from it. The tasks are to compute two specific probabilities and their difference. The questions are unambiguous, and a unique, stable, and meaningful solution can be derived from the given information.\n- **Objective:** The problem is stated using precise, formal, and unbiased mathematical language. There are no subjective elements or opinions.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-defined and standard problem in applied causal inference. I will now proceed with the solution.\n\nThe objective is to compute the contrast $\\Delta = P(Y=1 \\mid do(X=1)) - P(Y=1 \\mid X=1)$. This requires computing two terms separately.\n\n**1. Computation of the interventional probability $P(Y=1 \\mid do(X=1))$**\n\nThe intervention $do(X=1)$ corresponds to setting the value of variable $X$ to $1$ for the entire population, irrespective of the value of its parent variable $A$. In the graphical model, this is represented by removing the edge from $A$ to $X$. The post-interventional joint distribution over the remaining variables $A$ and $Y$ is given by $P(A, Y \\mid do(X=1)) = P(A) P(Y \\mid X=1, A)$, where the factor $P(X \\mid A)$ is removed from the original factorization and $X$ is fixed to $1$.\n\nTo find the marginal probability $P(Y=1 \\mid do(X=1))$, we must marginalize over the confounder $A$. This is known as the adjustment formula or application of the backdoor criterion, since the set $\\{A\\}$ blocks the backdoor path $X \\leftarrow A \\rightarrow Y$.\n$$P(Y=1 \\mid do(X=1)) = \\sum_{a \\in \\{0,1\\}} P(Y=1 \\mid X=1, A=a) P(A=a)$$\nWe substitute the given values:\n$$P(Y=1 \\mid do(X=1)) = P(Y=1 \\mid X=1, A=1)P(A=1) + P(Y=1 \\mid X=1, A=0)P(A=0)$$\n$$P(Y=1 \\mid do(X=1)) = \\left(\\frac{4}{5}\\right) \\left(\\frac{1}{3}\\right) + \\left(\\frac{3}{10}\\right) \\left(\\frac{2}{3}\\right)$$\n$$P(Y=1 \\mid do(X=1)) = \\frac{4}{15} + \\frac{6}{30} = \\frac{4}{15} + \\frac{1}{5}$$\nTo sum these fractions, we find a common denominator, which is $15$:\n$$P(Y=1 \\mid do(X=1)) = \\frac{4}{15} + \\frac{3 \\times 1}{3 \\times 5} = \\frac{4}{15} + \\frac{3}{15} = \\frac{7}{15}$$\n\n**2. Computation of the observational probability $P(Y=1 \\mid X=1)$**\n\nThe observational probability $P(Y=1 \\mid X=1)$ is a standard conditional probability, which can be computed using the formula:\n$$P(Y=1 \\mid X=1) = \\frac{P(Y=1, X=1)}{P(X=1)}$$\nWe must compute the numerator and the denominator separately.\n\nFirst, we compute the denominator, $P(X=1)$, using the law of total probability, marginalizing over $A$:\n$$P(X=1) = \\sum_{a \\in \\{0,1\\}} P(X=1, A=a) = \\sum_{a \\in \\{0,1\\}} P(X=1 \\mid A=a) P(A=a)$$\n$$P(X=1) = P(X=1 \\mid A=1)P(A=1) + P(X=1 \\mid A=0)P(A=0)$$\n$$P(X=1) = \\left(\\frac{3}{4}\\right) \\left(\\frac{1}{3}\\right) + \\left(\\frac{1}{4}\\right) \\left(\\frac{2}{3}\\right)$$\n$$P(X=1) = \\frac{3}{12} + \\frac{2}{12} = \\frac{5}{12}$$\n\nNext, we compute the numerator, $P(Y=1, X=1)$, by marginalizing the joint distribution $P(A,X,Y)$ over $A$:\n$$P(Y=1, X=1) = \\sum_{a \\in \\{0,1\\}} P(Y=1, X=1, A=a)$$\nUsing the given factorization $P(A,X,Y) = P(Y \\mid X,A) P(X \\mid A) P(A)$:\n$$P(Y=1, X=1) = P(Y=1 \\mid X=1, A=1)P(X=1 \\mid A=1)P(A=1) + P(Y=1 \\mid X=1, A=0)P(X=1 \\mid A=0)P(A=0)$$\n$$P(Y=1, X=1) = \\left(\\frac{4}{5}\\right) \\left(\\frac{3}{4}\\right) \\left(\\frac{1}{3}\\right) + \\left(\\frac{3}{10}\\right) \\left(\\frac{1}{4}\\right) \\left(\\frac{2}{3}\\right)$$\n$$P(Y=1, X=1) = \\frac{12}{60} + \\frac{6}{120} = \\frac{1}{5} + \\frac{1}{20}$$\n$$P(Y=1, X=1) = \\frac{4}{20} + \\frac{1}{20} = \\frac{5}{20} = \\frac{1}{4}$$\n\nNow, we can compute the conditional probability $P(Y=1 \\mid X=1)$:\n$$P(Y=1 \\mid X=1) = \\frac{P(Y=1, X=1)}{P(X=1)} = \\frac{1/4}{5/12} = \\frac{1}{4} \\times \\frac{12}{5} = \\frac{12}{20} = \\frac{3}{5}$$\n\n**3. Computation of the contrast $\\Delta$**\n\nFinally, we compute the difference $\\Delta$:\n$$\\Delta = P(Y=1 \\mid do(X=1)) - P(Y=1 \\mid X=1)$$\n$$\\Delta = \\frac{7}{15} - \\frac{3}{5}$$\nTo subtract, we use the common denominator $15$:\n$$\\Delta = \\frac{7}{15} - \\frac{3 \\times 3}{3 \\times 5} = \\frac{7}{15} - \\frac{9}{15} = -\\frac{2}{15}$$\nThe negative value of $\\Delta$ indicates that the observational association between treatment and outcome is more positive than the true causal effect, a classic signature of confounding where the confounder is positively associated with both treatment and outcome.",
            "answer": "$$\\boxed{-\\frac{2}{15}}$$"
        },
        {
            "introduction": "Beyond confounding, DAGs help us identify more subtle sources of bias, such as that induced by conditioning on a collider. This advanced practice explores the phenomenon of collider-stratification bias, where controlling for a variable that is a common effect of two others can create a spurious statistical association. Using a quantitative framework, you will calculate how this form of conditioning can not only introduce bias but even reverse the direction of the underlying association, a critical warning for designing statistical analyses. ",
            "id": "4960221",
            "problem": "A clinician triages patients to specialty care based on laboratory markers. Consider the Directed Acyclic Graph (DAG) where an unobserved inflammatory burden $L$ causes both the C-reactive protein $X$ and the erythrocyte sedimentation rate $Y$, and the triage decision $M$ is a function of $X$ and $Y$: $L \\rightarrow X$, $L \\rightarrow Y$, $X \\rightarrow M$, $Y \\rightarrow M$. In Structural Equation Model (SEM) form, assume joint Gaussian random variables and the following linear relations with independent noise terms:\n$$\nL \\sim \\mathcal{N}(0,1),\\quad e_{X} \\sim \\mathcal{N}(0,\\sigma_{X}^{2}),\\quad e_{Y} \\sim \\mathcal{N}(0,\\sigma_{Y}^{2}),\\quad e_{M} \\sim \\mathcal{N}(0,\\sigma_{M}^{2}),\n$$\n$$\nX = a\\,L + e_{X},\\quad Y = b\\,L + e_{Y},\\quad M = c_{X}\\,X + c_{Y}\\,Y + e_{M},\n$$\nwith parameters $a=1.2$, $b=1.0$, $\\sigma_{X}^{2}=0.5$, $\\sigma_{Y}^{2}=0.5$, $c_{X}=1.5$, $c_{Y}=1.2$, and $\\sigma_{M}^{2}=0.2$. This DAG encodes that $M$ is a collider on the path $X \\rightarrow M \\leftarrow Y$.\n\nStarting only from the definitions of Directed Acyclic Graphs (DAGs), colliders, and the properties of multivariate Gaussian distributions, determine the unconditional association between $X$ and $Y$ and the association between $X$ and $Y$ conditional on $M$. Use correlation as the measure of association. Then, define the magnitude of reversal as\n$$\n\\Delta \\equiv \\left| \\rho_{XY\\mid M} - \\rho_{XY} \\right|,\n$$\nwhere $\\rho_{XY}$ is the unconditional correlation and $\\rho_{XY\\mid M}$ is the correlation conditional on $M$. Compute $\\Delta$ for the given parameters. Round your final numeric answer to four significant figures.",
            "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It presents a standard problem in causal inference involving a linear Structural Equation Model (SEM) with Gaussian variables, commonly used to illustrate the phenomenon of collider bias. All necessary parameters and distributional assumptions are provided, and the task is to compute well-defined statistical quantities. Therefore, I will proceed with a full solution.\n\nThe problem requires the computation of the unconditional correlation $\\rho_{XY}$ and the conditional correlation $\\rho_{XY\\mid M}$. The variables $X$, $Y$, and $M$ are linear combinations of independent Gaussian random variables ($L, e_X, e_Y, e_M$), and as such, they form a multivariate Gaussian system. We can determine the correlations by calculating the relevant variances and covariances. All variables have a mean of $0$ since they are linear combinations of zero-mean variables.\n\nFirst, we calculate the unconditional variances and covariance of $X$ and $Y$.\nThe variance of $X$ is given by:\n$$\n\\mathrm{Var}(X) = \\mathrm{Var}(aL + e_{X})\n$$\nSince $L$ and $e_X$ are independent, we have:\n$$\n\\mathrm{Var}(X) = a^2\\mathrm{Var}(L) + \\mathrm{Var}(e_{X}) = a^2(1) + \\sigma_{X}^{2}\n$$\nSubstituting the given parameter values, $a=1.2$ and $\\sigma_{X}^{2}=0.5$:\n$$\n\\mathrm{Var}(X) = (1.2)^2 + 0.5 = 1.44 + 0.5 = 1.94\n$$\nSimilarly, the variance of $Y$ is:\n$$\n\\mathrm{Var}(Y) = \\mathrm{Var}(bL + e_{Y}) = b^2\\mathrm{Var}(L) + \\mathrm{Var}(e_{Y}) = b^2(1) + \\sigma_{Y}^{2}\n$$\nSubstituting the given parameter values, $b=1.0$ and $\\sigma_{Y}^{2}=0.5$:\n$$\n\\mathrm{Var(Y)} = (1.0)^2 + 0.5 = 1.0 + 0.5 = 1.5\n$$\nThe covariance of $X$ and $Y$ is:\n$$\n\\mathrm{Cov}(X, Y) = \\mathrm{Cov}(aL + e_{X}, bL + e_{Y})\n$$\nBy the bilinearity of covariance and the independence of $L$, $e_X$, and $e_Y$:\n$$\n\\mathrm{Cov}(X, Y) = ab\\,\\mathrm{Cov}(L, L) + a\\,\\mathrm{Cov}(L, e_Y) + b\\,\\mathrm{Cov}(e_X, L) + \\mathrm{Cov}(e_X, e_Y) = ab\\,\\mathrm{Var}(L) = ab\n$$\nSubstituting the given parameter values, $a=1.2$ and $b=1.0$:\n$$\n\\mathrm{Cov}(X, Y) = (1.2)(1.0) = 1.2\n$$\nThe unconditional correlation $\\rho_{XY}$ is the ratio of the covariance to the product of the standard deviations:\n$$\n\\rho_{XY} = \\frac{\\mathrm{Cov}(X, Y)}{\\sqrt{\\mathrm{Var}(X)\\mathrm{Var}(Y)}} = \\frac{1.2}{\\sqrt{(1.94)(1.5)}} = \\frac{1.2}{\\sqrt{2.91}}\n$$\nNumerically, this is $\\rho_{XY} \\approx 0.70345$.\n\nNext, we determine the association between $X$ and $Y$ conditional on $M$. The conditional correlation $\\rho_{XY\\mid M}$ is given by the formula for partial correlation in a multivariate Gaussian distribution:\n$$\n\\rho_{XY\\mid M} = \\frac{\\mathrm{Cov}(X, Y \\mid M)}{\\sqrt{\\mathrm{Var}(X \\mid M)\\mathrm{Var}(Y \\mid M)}}\n$$\nThe terms of this expression are given by:\n$$\n\\mathrm{Var}(X \\mid M) = \\mathrm{Var}(X) - \\frac{\\mathrm{Cov}(X, M)^2}{\\mathrm{Var}(M)}\n$$\n$$\n\\mathrm{Var}(Y \\mid M) = \\mathrm{Var}(Y) - \\frac{\\mathrm{Cov}(Y, M)^2}{\\mathrm{Var}(M)}\n$$\n$$\n\\mathrm{Cov}(X, Y \\mid M) = \\mathrm{Cov}(X, Y) - \\frac{\\mathrm{Cov}(X, M)\\mathrm{Cov}(Y, M)}{\\mathrm{Var}(M)}\n$$\nWe must first compute the moments involving $M$.\nThe covariance between $X$ and $M$:\n$$\n\\mathrm{Cov}(X, M) = \\mathrm{Cov}(X, c_X X + c_Y Y + e_M) = c_X\\mathrm{Var}(X) + c_Y\\mathrm{Cov}(X, Y) + \\mathrm{Cov}(X, e_M)\n$$\nSince $X=aL+e_X$, $X$ is independent of $e_M$, so $\\mathrm{Cov}(X, e_M) = 0$.\n$$\n\\mathrm{Cov}(X, M) = c_X\\mathrm{Var}(X) + c_Y\\mathrm{Cov}(X, Y) = (1.5)(1.94) + (1.2)(1.2) = 2.91 + 1.44 = 4.35\n$$\nThe covariance between $Y$ and $M$:\n$$\n\\mathrm{Cov}(Y, M) = \\mathrm{Cov}(Y, c_X X + c_Y Y + e_M) = c_X\\mathrm{Cov}(X, Y) + c_Y\\mathrm{Var}(Y) + \\mathrm{Cov}(Y, e_M)\n$$\nSince $Y=bL+e_Y$, $Y$ is independent of $e_M$, so $\\mathrm{Cov}(Y, e_M) = 0$.\n$$\n\\mathrm{Cov}(Y, M) = c_X\\mathrm{Cov}(X, Y) + c_Y\\mathrm{Var}(Y) = (1.5)(1.2) + (1.2)(1.5) = 1.8 + 1.8 = 3.6\n$$\nThe variance of $M$:\n$$\n\\mathrm{Var}(M) = \\mathrm{Var}(c_X X + c_Y Y + e_M)\n$$\nSince $X$ and $Y$ are functions of $L, e_X, e_Y$, they are independent of $e_M$.\n$$\n\\mathrm{Var}(M) = \\mathrm{Var}(c_X X + c_Y Y) + \\mathrm{Var}(e_M) = c_X^2\\mathrm{Var}(X) + c_Y^2\\mathrm{Var}(Y) + 2c_X c_Y \\mathrm{Cov}(X, Y) + \\sigma_M^2\n$$\nSubstituting the numerical values:\n$$\n\\mathrm{Var}(M) = (1.5^2)(1.94) + (1.2^2)(1.5) + 2(1.5)(1.2)(1.2) + 0.2\n$$\n$$\n\\mathrm{Var}(M) = (2.25)(1.94) + (1.44)(1.5) + (3.6)(1.2) + 0.2 = 4.365 + 2.16 + 4.32 + 0.2 = 11.045\n$$\nNow we can compute the conditional variances and covariance:\n$$\n\\mathrm{Cov}(X, Y \\mid M) = 1.2 - \\frac{(4.35)(3.6)}{11.045} = 1.2 - \\frac{15.66}{11.045} \\approx 1.2 - 1.417836 = -0.217836\n$$\n$$\n\\mathrm{Var}(X \\mid M) = 1.94 - \\frac{(4.35)^2}{11.045} = 1.94 - \\frac{18.9225}{11.045} \\approx 1.94 - 1.713255 = 0.226745\n$$\n$$\n\\mathrm{Var}(Y \\mid M) = 1.5 - \\frac{(3.6)^2}{11.045} = 1.5 - \\frac{12.96}{11.045} \\approx 1.5 - 1.173382 = 0.326618\n$$\nNow, we compute the conditional correlation $\\rho_{XY\\mid M}$:\n$$\n\\rho_{XY\\mid M} \\approx \\frac{-0.217836}{\\sqrt{(0.226745)(0.326618)}} = \\frac{-0.217836}{\\sqrt{0.074059}} \\approx \\frac{-0.217836}{0.272138} \\approx -0.80046\n$$\nThe problem asks for the magnitude of reversal, $\\Delta = \\left| \\rho_{XY\\mid M} - \\rho_{XY} \\right|$.\n$$\n\\Delta \\approx \\left| -0.80046 - 0.70345 \\right| = \\left| -1.50391 \\right| = 1.50391\n$$\nRounding to four significant figures, we get $1.504$.\n\nThe unconditional correlation $\\rho_{XY}$ is positive, reflecting the common cause $L$. The conditional correlation $\\rho_{XY\\mid M}$ is negative. This sign reversal is a classic example of collider bias. Conditioning on the common effect $M$ of two variables $X$ and $Y$ induces an association between them, which in this case is negative and strong enough to overwhelm the initial positive association.",
            "answer": "$$\\boxed{1.504}$$"
        }
    ]
}