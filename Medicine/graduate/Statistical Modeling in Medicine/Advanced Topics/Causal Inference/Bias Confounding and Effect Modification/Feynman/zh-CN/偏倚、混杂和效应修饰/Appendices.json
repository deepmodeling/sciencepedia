{
    "hands_on_practices": [
        {
            "introduction": "混杂是观察性研究中的一个核心挑战，它可能导致对因果效应的估计产生偏差。本练习超越了对混杂的定性描述，通过一个清晰的线性结构方程模型，从第一性原理出发，推导出由一个未测量的混杂因素所引起的偏倚的精确数学形式。通过完成这个推导，你将深刻理解为何调整混杂因素是必要的，以及偏倚的大小如何取决于混杂路径的强度。",
            "id": "4954330",
            "problem": "考虑一项观察性队列研究，其中为 $n$ 名患者测量了一个连续暴露量 $A$（例如，生物标志物水平）和一个连续结果 $Y$（例如，临床严重程度指数）。令 $U$ 表示一个患者层面的潜在因子（例如，基线脆弱性评分），它是 $A$ 和 $Y$ 的共同原因。假设数据生成过程由以下线性结构方程给出\n$$\nA \\;=\\; \\alpha_U\\,U \\;+\\; \\epsilon_A,\\qquad\nY \\;=\\; \\beta_A\\,A \\;+\\; \\beta_U\\,U \\;+\\; \\epsilon_Y,\n$$\n其中 $U$、$\\epsilon_A$ 和 $\\epsilon_Y$ 在患者间是独立同分布的（i.i.d.），并且 $E[U]=E[\\epsilon_A]=E[\\epsilon_Y]=0$，$\\operatorname{Var}(U)=\\sigma_U^2$，$\\operatorname{Var}(\\epsilon_A)=\\sigma_A^2$，以及 $\\operatorname{Var}(\\epsilon_Y)=\\sigma_Y^2$。再假设对于每位患者，$U$、$\\epsilon_A$ 和 $\\epsilon_Y$ 是相互独立的，并且观测值在患者间是独立同分布的。不存在 $A$ 或 $Y$ 的其他原因。\n\n将 $\\beta_A$ 的未调整估计量定义为忽略 $U$ 的情况下，$Y$ 对 $A$ 进行简单线性回归（带截距）所得的普通最小二乘（OLS）斜率。在所述假设下，并且当 $n \\to \\infty$ 时，从第一性原理出发，推导该未调整估计量的概率极限，并由此推导出其渐近偏差（定义为该估计量的大样本极限减去真实的 $\\beta_A$）。然后，假设 $U$ 是可观测的，运用相同的原理论证，在上述数据生成过程中，通过 $Y$ 对 $(A,U)$ 进行多元线性回归得到的 $A$ 的 OLS 系数对于 $\\beta_A$ 是否存在渐近偏差。\n\n请用包含 $\\alpha_U$、$\\beta_U$、$\\sigma_U^2$ 和 $\\sigma_A^2$ 的单个封闭形式解析表达式给出未调整估计量的渐近偏差。最终表达式中不应包含任何其他符号。不需要进行数值近似；请勿四舍五入。",
            "solution": "该问题陈述已经过严格验证，被认为是科学可靠、问题明确且客观的。它提出了统计建模中一个关于遗漏变量偏差（混杂的一种形式）的标准、典型问题，并且没有任何使其无效的缺陷。因此可以开始求解。\n\n问题要求我们求出回归系数的未调整估计量的渐近偏差，并就调整后估计量的偏差进行论证。我们将依次解决这两个部分。\n\n首先，考虑 $\\beta_A$ 的未调整估计量，即 $Y$ 对 $A$ 进行简单线性回归得到的普通最小二乘（OLS）斜率。记该未调整估计量为 $\\hat{\\beta}_{A, \\text{unadj}}$。对于大小为 $n$ 的样本，该估计量的公式为：\n$$\n\\hat{\\beta}_{A, \\text{unadj}} = \\frac{\\sum_{i=1}^n (A_i - \\bar{A})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (A_i - \\bar{A})^2} \\equiv \\frac{\\widehat{\\operatorname{Cov}}(A,Y)}{\\widehat{\\operatorname{Var}}(A)}\n$$\n其中 $\\bar{A}$ 和 $\\bar{Y}$ 分别是 $A$ 和 $Y$ 的样本均值，$\\widehat{\\operatorname{Cov}}$ 和 $\\widehat{\\operatorname{Var}}$ 表示样本协方差和样本方差。\n\n为了求出渐近偏差，我们首先需要确定当样本量 $n \\to \\infty$ 时该估计量的概率极限（$\\text{plim}$）。由于观测值 $(A_i, Y_i)$ 是独立同分布的，根据大数定律，样本矩依概率收敛于相应的总体矩。根据连续映射定理（引用斯卢茨基定理），这些样本矩的比率依概率收敛于总体矩的比率：\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{\\beta}_{A, \\text{unadj}} = \\frac{\\operatorname{Cov}(A,Y)}{\\operatorname{Var}(A)}\n$$\n现在我们必须利用给定的结构方程和统计假设，从第一性原理出发推导 $\\operatorname{Var}(A)$ 和 $\\operatorname{Cov}(A,Y)$ 的表达式。\n\n$A$ 的结构方程是 $A = \\alpha_U U + \\epsilon_A$。假设变量 $U$ 和 $\\epsilon_A$ 相互独立，其方差分别为 $\\operatorname{Var}(U) = \\sigma_U^2$ 和 $\\operatorname{Var}(\\epsilon_A) = \\sigma_A^2$。因此，$A$ 的方差为：\n$$\n\\operatorname{Var}(A) = \\operatorname{Var}(\\alpha_U U + \\epsilon_A)\n$$\n由于 $U$ 和 $\\epsilon_A$ 的独立性，和的方差等于方差的和：\n$$\n\\operatorname{Var}(A) = \\operatorname{Var}(\\alpha_U U) + \\operatorname{Var}(\\epsilon_A) = \\alpha_U^2 \\operatorname{Var}(U) + \\operatorname{Var}(\\epsilon_A) = \\alpha_U^2 \\sigma_U^2 + \\sigma_A^2\n$$\n\n接下来，我们推导 $A$ 和 $Y$ 之间的协方差。我们从 $Y$ 的结构方程 $Y = \\beta_A A + \\beta_U U + \\epsilon_Y$ 开始。利用协方差的性质，我们有：\n$$\n\\operatorname{Cov}(A,Y) = \\operatorname{Cov}(A, \\beta_A A + \\beta_U U + \\epsilon_Y) = \\beta_A \\operatorname{Cov}(A,A) + \\beta_U \\operatorname{Cov}(A,U) + \\operatorname{Cov}(A,\\epsilon_Y)\n$$\n这可以简化为：\n$$\n\\operatorname{Cov}(A,Y) = \\beta_A \\operatorname{Var}(A) + \\beta_U \\operatorname{Cov}(A,U) + \\operatorname{Cov}(A,\\epsilon_Y)\n$$\n我们需要计算这两个协方差项。对于 $\\operatorname{Cov}(A,U)$，我们代入 $A$ 的表达式：\n$$\n\\operatorname{Cov}(A,U) = \\operatorname{Cov}(\\alpha_U U + \\epsilon_A, U) = \\alpha_U \\operatorname{Cov}(U,U) + \\operatorname{Cov}(\\epsilon_A, U)\n$$\n由于 $U$ 和 $\\epsilon_A$ 是独立的，所以 $\\operatorname{Cov}(\\epsilon_A, U) = 0$。因此：\n$$\n\\operatorname{Cov}(A,U) = \\alpha_U \\operatorname{Var}(U) = \\alpha_U \\sigma_U^2\n$$\n对于 $\\operatorname{Cov}(A,\\epsilon_Y)$，我们再次代入 $A$ 的表达式：\n$$\n\\operatorname{Cov}(A,\\epsilon_Y) = \\operatorname{Cov}(\\alpha_U U + \\epsilon_A, \\epsilon_Y) = \\alpha_U \\operatorname{Cov}(U, \\epsilon_Y) + \\operatorname{Cov}(\\epsilon_A, \\epsilon_Y)\n$$\n根据假设，$U$、$\\epsilon_A$ 和 $\\epsilon_Y$ 是相互独立的。这意味着 $\\operatorname{Cov}(U, \\epsilon_Y) = 0$ 且 $\\operatorname{Cov}(\\epsilon_A, \\epsilon_Y) = 0$。因此：\n$$\n\\operatorname{Cov}(A,\\epsilon_Y) = 0\n$$\n将这些协方差结果代回 $\\operatorname{Cov}(A,Y)$ 的表达式中：\n$$\n\\operatorname{Cov}(A,Y) = \\beta_A \\operatorname{Var}(A) + \\beta_U (\\alpha_U \\sigma_U^2) + 0 = \\beta_A (\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2) + \\alpha_U \\beta_U \\sigma_U^2\n$$\n\n现在我们可以求出未调整估计量的概率极限：\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{\\beta}_{A, \\text{unadj}} = \\frac{\\operatorname{Cov}(A,Y)}{\\operatorname{Var}(A)} = \\frac{\\beta_A (\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2) + \\alpha_U \\beta_U \\sigma_U^2}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2}\n$$\n分离各项可得：\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{\\beta}_{A, \\text{unadj}} = \\frac{\\beta_A (\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2)}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2} + \\frac{\\alpha_U \\beta_U \\sigma_U^2}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2} = \\beta_A + \\frac{\\alpha_U \\beta_U \\sigma_U^2}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2}\n$$\n渐近偏差定义为估计量的概率极限减去真实参数值 $\\beta_A$。\n$$\n\\text{Asymptotic Bias} = \\left( \\operatorname{plim}_{n \\to \\infty} \\hat{\\beta}_{A, \\text{unadj}} \\right) - \\beta_A = \\frac{\\alpha_U \\beta_U \\sigma_U^2}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2}\n$$\n这种偏差的产生是因为未观测到的混杂因素 $U$ 导致了回归量 $A$ 与简单回归模型误差项之间的相关性。在朴素模型 $Y = \\beta_0 + \\beta_A A + \\text{error}$ 中，误差项是 $\\beta_U U + \\epsilon_Y$。回归量 $A = \\alpha_U U + \\epsilon_A$ 通过共同因子 $U$ 与该误差项相关，这违反了 OLS 的外生性基本假设。当且仅当 $\\alpha_U \\neq 0$（混杂因素影响暴露）和 $\\beta_U \\neq 0$（混杂因素影响结果）时，偏差非零。\n\n第二，考虑 $Y$ 对 $A$ 和 $U$ 的多元线性回归，假设 $U$ 是可观测的。拟合的模型是：\n$$\nY = \\gamma_0 + \\gamma_A A + \\gamma_U U + \\nu\n$$\n如果在总体模型中，回归量与误差项 $\\nu$ 不相关，那么 $\\gamma_A$ 和 $\\gamma_U$ 的 OLS 估计量是真实参数的一致估计。真实的数据生成过程由以下结构方程给出：\n$$\nY = \\beta_A A + \\beta_U U + \\epsilon_Y\n$$\n当我们拟合多元回归模型时，我们试图估计这个真实结构关系的参数。通过将回归模型与真实数据生成过程进行比较，我们发现真实的系数是 $\\beta_A$ 和 $\\beta_U$（真实截距为 $0$），误差项 $\\nu$ 对应于 $\\epsilon_Y$。\n\n为了使 $A$ 的系数的 OLS 估计量（我们称之为 $\\hat{\\beta}_{A, \\text{adj}}$）成为真实参数 $\\beta_A$ 的一致估计，模型中的回归量（$A$ 和 $U$）必须与误差项（$\\epsilon_Y$）不相关。我们验证这些条件：\n$1.$ $\\operatorname{Cov}(A, \\epsilon_Y)$：如前所述，$\\operatorname{Cov}(A, \\epsilon_Y) = \\operatorname{Cov}(\\alpha_U U + \\epsilon_A, \\epsilon_Y) = \\alpha_U \\operatorname{Cov}(U, \\epsilon_Y) + \\operatorname{Cov}(\\epsilon_A, \\epsilon_Y) = 0$，这是由于 $U$、$\\epsilon_A$ 和 $\\epsilon_Y$ 的相互独立性。\n$2.$ $\\operatorname{Cov}(U, \\epsilon_Y)$：根据 $U$ 和 $\\epsilon_Y$ 独立的假设，该协方差直接为 $0$。\n\n由于多元回归模型中的所有回归量都与误差项不相关，因此满足了 OLS 一致性的基本条件。因此，$Y$ 对 $(A, U)$ 进行多元回归得到的 $A$ 的系数的 OLS 估计量的概率极限是真实参数 $\\beta_A$。\n$$\n\\operatorname{plim}_{n \\to \\infty} \\hat{\\beta}_{A, \\text{adj}} = \\beta_A\n$$\n这个调整后估计量的渐近偏差是 $\\beta_A - \\beta_A = 0$。因此，一个包含了混杂因素 $U$ 的、正确设定的多元回归模型可以提供对因果效应 $\\beta_A$ 的渐近无偏估计。\n\n所要求的最终答案是未调整估计量的渐近偏差。",
            "answer": "$$\n\\boxed{\\frac{\\alpha_U \\beta_U \\sigma_U^2}{\\alpha_U^2 \\sigma_U^2 + \\sigma_A^2}}\n$$"
        },
        {
            "introduction": "除了混杂偏倚，选择偏倚是另一种在统计建模中必须警惕的陷阱，其中一种棘手的类型是“对撞偏倚”(collider bias)。这种偏倚并非源于共同原因，而是由于对一个共同效应（即对撞节点）进行条件限制而产生。本练习通过一个具体的数值案例，生动地展示了对撞偏倚的强大威力：在一个假设的临床数据集中，对样本的选择本身就能完全逆转暴露与结局之间的真实关联方向，将一个有害的暴露因素错误地呈现为保护性因素。",
            "id": "4954359",
            "problem": "考虑一个二元暴露 $X \\in \\{0,1\\}$，一个未测量的二元结局原因 $U \\in \\{0,1\\}$，一个二元结局 $Y \\in \\{0,1\\}$，以及一个表示进入临床数据集（例如，急诊入院）的二元选择指示变量 $S \\in \\{0,1\\}$。假设 $S$ 是一个对撞因子，它是 $X$ 和 $U$ 的共同效应。假设在源人群中，$X$ 和 $U$ 是独立的。给定以下数据生成机制：\n- 边际分布：$P(X=1)=0.5$ 和 $P(U=1)=0.2$。\n- 结局机制（风险模型）：\n  - $P(Y=1 \\mid X=0, U=0)=0.05$，\n  - $P(Y=1 \\mid X=1, U=0)=0.20$，\n  - $P(Y=1 \\mid X=0, U=1)=0.90$，\n  - $P(Y=1 \\mid X=1, U=1)=0.95$。\n- 选择机制（对撞因子）：\n  - $P(S=1 \\mid X=0, U=0)=0.01$，\n  - $P(S=1 \\mid X=0, U=1)=0.99$，\n  - $P(S=1 \\mid X=1, U=0)=0.50$，\n  - $P(S=1 \\mid X=1, U=1)=0.99$。\n\n仅使用概率公理、全概率定律、贝叶斯法则以及优势、优势比和条件概率的定义，推导在被选择的个体中，比较 $X=1$ 与 $X=0$ 时 $Y$ 的条件优势比，即计算\n$$\n\\text{OR}_{Y,X \\mid S=1} \\equiv \\frac{\\displaystyle \\frac{P(Y=1 \\mid X=1, S=1)}{P(Y=0 \\mid X=1, S=1)}}{\\displaystyle \\frac{P(Y=1 \\mid X=0, S=1)}{P(Y=0 \\mid X=0, S=1)}}.\n$$\n为了证明以对撞因子 $S$ 为条件会反转估计的效应方向，你可以在推导过程中验证边际优势比 $\\text{OR}_{Y,X}$（不以 $S$ 为条件）大于1，而条件优势比 $\\text{OR}_{Y,X \\mid S=1}$ 小于1。然而，你必须报告的最终数值答案是 $\\text{OR}_{Y,X \\mid S=1}$ 的值。\n\n将你报告的 $\\text{OR}_{Y,X \\mid S=1}$ 最终值四舍五入到四位有效数字。无需单位。",
            "solution": "该问题是有效的，因为它提出了一个统计建模中良定且有科学依据的情景，具体展示了对撞分层偏倚现象。所有需要的数据和定义都已提供，问题没有矛盾或歧义。\n\n目标是计算在被选入数据集的条件下，结局 $Y$ 对暴露 $X$ 的条件优势比 $\\text{OR}_{Y,X \\mid S=1}$。该量定义为：\n$$\n\\text{OR}_{Y,X \\mid S=1} = \\frac{\\text{Odds}(Y=1 \\mid X=1, S=1)}{\\text{Odds}(Y=1 \\mid X=0, S=1)} = \\frac{\\displaystyle \\frac{P(Y=1 \\mid X=1, S=1)}{P(Y=0 \\mid X=1, S=1)}}{\\displaystyle \\frac{P(Y=1 \\mid X=0, S=1)}{P(Y=0 \\mid X=0, S=1)}}\n$$\n核心任务是确定 $x \\in \\{0, 1\\}$ 的条件概率 $P(Y=1 \\mid X=x, S=1)$。由于结局 $Y$ 是由 $X$ 和未测量变量 $U$ 因果决定的，而不是直接由选择变量 $S$ 决定，我们可以说在给定 $X$ 和 $U$ 的条件下，$Y$ 与 $S$ 是条件独立的。这是此类因果模型中的一个标准假设，记为 $Y \\perp S \\mid (X, U)$。因此，我们可以应用全概率定律，对未测量的原因 $U$ 进行边际化：\n$$\nP(Y=1 \\mid X=x, S=1) = \\sum_{u \\in \\{0,1\\}} P(Y=1 \\mid X=x, S=1, U=u) \\, P(U=u \\mid X=x, S=1)\n$$\n使用条件独立性假设 $P(Y=1 \\mid X=x, S=1, U=u) = P(Y=1 \\mid X=x, U=u)$，表达式简化为：\n$$\nP(Y=1 \\mid X=x, S=1) = \\sum_{u \\in \\{0,1\\}} P(Y=1 \\mid X=x, U=u) \\, P(U=u \\mid X=x, S=1)\n$$\n项 $P(Y=1 \\mid X=x, U=u)$ 是给定的。我们必须计算 $P(U=u \\mid X=x, S=1)$。该项表示在被选择个体的分层中未测量原因 $U$ 的概率，由于对撞效应，这与边际概率 $P(U=u)$ 不同。我们使用贝叶斯法则：\n$$\nP(U=u \\mid X=x, S=1) = \\frac{P(S=1 \\mid X=x, U=u) \\, P(U=u \\mid X=x)}{P(S=1 \\mid X=x)}\n$$\n问题陈述 $X$ 和 $U$ 在源人群中是独立的，所以 $P(U=u \\mid X=x) = P(U=u)$。分母通过对 $U$ 进行边际化得到：\n$$\nP(S=1 \\mid X=x) = \\sum_{u \\in \\{0,1\\}} P(S=1 \\mid X=x, U=u) \\, P(U=u)\n$$\n我们根据给定的概率进行计算：$P(X=1)=0.5$，$P(U=1)=0.2$（因此 $P(U=0)=0.8$）。\n\n首先，我们计算 $x \\in \\{0, 1\\}$ 的 $P(S=1 \\mid X=x)$。\n对于 $x=0$：\n$$\nP(S=1 \\mid X=0) = P(S=1 \\mid X=0, U=0)P(U=0) + P(S=1 \\mid X=0, U=1)P(U=1)\n$$\n$$\nP(S=1 \\mid X=0) = (0.01)(0.8) + (0.99)(0.2) = 0.008 + 0.198 = 0.206\n$$\n对于 $x=1$：\n$$\nP(S=1 \\mid X=1) = P(S=1 \\mid X=1, U=0)P(U=0) + P(S=1 \\mid X=1, U=1)P(U=1)\n$$\n$$\nP(S=1 \\mid X=1) = (0.50)(0.8) + (0.99)(0.2) = 0.400 + 0.198 = 0.598\n$$\n接下来，我们计算 $P(U=u \\mid X=x, S=1)$。\n对于 $x=0$：\n$$\nP(U=0 \\mid X=0, S=1) = \\frac{P(S=1 \\mid X=0, U=0)P(U=0)}{P(S=1 \\mid X=0)} = \\frac{(0.01)(0.8)}{0.206} = \\frac{0.008}{0.206} = \\frac{4}{103}\n$$\n$$\nP(U=1 \\mid X=0, S=1) = \\frac{P(S=1 \\mid X=0, U=1)P(U=1)}{P(S=1 \\mid X=0)} = \\frac{(0.99)(0.2)}{0.206} = \\frac{0.198}{0.206} = \\frac{99}{103}\n$$\n对于 $x=1$：\n$$\nP(U=0 \\mid X=1, S=1) = \\frac{P(S=1 \\mid X=1, U=0)P(U=0)}{P(S=1 \\mid X=1)} = \\frac{(0.50)(0.8)}{0.598} = \\frac{0.4}{0.598} = \\frac{200}{299}\n$$\n$$\nP(U=1 \\mid X=1, S=1) = \\frac{P(S=1 \\mid X=1, U=1)P(U=1)}{P(S=1 \\mid X=1)} = \\frac{(0.99)(0.2)}{0.598} = \\frac{0.198}{0.598} = \\frac{99}{299}\n$$\n现在我们计算 $P(Y=1 \\mid X=x, S=1)$。\n对于 $x=0$：\n$$\nP(Y=1 \\mid X=0, S=1) = P(Y=1 \\mid X=0, U=0)P(U=0 \\mid X=0, S=1) + P(Y=1 \\mid X=0, U=1)P(U=1 \\mid X=0, S=1)\n$$\n$$\nP(Y=1 \\mid X=0, S=1) = (0.05)\\left(\\frac{4}{103}\\right) + (0.90)\\left(\\frac{99}{103}\\right) = \\frac{0.20 + 89.1}{103} = \\frac{89.3}{103}\n$$\n对于 $x=1$：\n$$\nP(Y=1 \\mid X=1, S=1) = P(Y=1 \\mid X=1, U=0)P(U=0 \\mid X=1, S=1) + P(Y=1 \\mid X=1, U=1)P(U=1 \\mid X=1, S=1)\n$$\n$$\nP(Y=1 \\mid X=1, S=1) = (0.20)\\left(\\frac{200}{299}\\right) + (0.95)\\left(\\frac{99}{299}\\right) = \\frac{40 + 94.05}{299} = \\frac{134.05}{299}\n$$\n我们现在可以计算条件优势。\n对于 $x=0, S=1$：\n$$\nP(Y=0 \\mid X=0, S=1) = 1 - \\frac{89.3}{103} = \\frac{13.7}{103}\n$$\n$$\n\\text{Odds}(Y=1 \\mid X=0, S=1) = \\frac{89.3/103}{13.7/103} = \\frac{89.3}{13.7}\n$$\n对于 $x=1, S=1$：\n$$\nP(Y=0 \\mid X=1, S=1) = 1 - \\frac{134.05}{299} = \\frac{164.95}{299}\n$$\n$$\n\\text{Odds}(Y=1 \\mid X=1, S=1) = \\frac{134.05/299}{164.95/299} = \\frac{134.05}{164.95}\n$$\n最后，条件优势比是：\n$$\n\\text{OR}_{Y,X \\mid S=1} = \\frac{\\text{Odds}(Y=1 \\mid X=1, S=1)}{\\text{Odds}(Y=1 \\mid X=0, S=1)} = \\frac{134.05 / 164.95}{89.3 / 13.7} = \\frac{134.05 \\times 13.7}{164.95 \\times 89.3} \\approx 0.124676\n$$\n作为证明要求，我们通过计算边际优势比 $\\text{OR}_{Y,X}$ 来验证效应反转。\n首先，在 $X \\perp U$ 的源人群中，通过对 $U$ 进行边际化来求得 $P(Y=1 \\mid X=x)$。\n对于 $x=0$：\n$$\nP(Y=1 \\mid X=0) = P(Y=1 \\mid X=0, U=0)P(U=0) + P(Y=1 \\mid X=0, U=1)P(U=1)\n$$\n$$\nP(Y=1 \\mid X=0) = (0.05)(0.8) + (0.90)(0.2) = 0.04 + 0.18 = 0.22\n$$\n对于 $x=1$：\n$$\nP(Y=1 \\mid X=1) = P(Y=1 \\mid X=1, U=0)P(U=0) + P(Y=1 \\mid X=1, U=1)P(U=1)\n$$\n$$\nP(Y=1 \\mid X=1) = (0.20)(0.8) + (0.95)(0.2) = 0.16 + 0.19 = 0.35\n$$\n边际优势是：\n$$\n\\text{Odds}(Y=1 \\mid X=0) = \\frac{0.22}{1-0.22} = \\frac{0.22}{0.78} = \\frac{11}{39}\n$$\n$$\n\\text{Odds}(Y=1 \\mid X=1) = \\frac{0.35}{1-0.35} = \\frac{0.35}{0.65} = \\frac{7}{13}\n$$\n边际优势比是：\n$$\n\\text{OR}_{Y,X} = \\frac{7/13}{11/39} = \\frac{7}{13} \\times \\frac{39}{11} = \\frac{7 \\times 3}{11} = \\frac{21}{11} \\approx 1.909\n$$\n我们已经验证了边际优势比 $\\text{OR}_{Y,X} \\approx 1.909 > 1$，表明在源人群中 $X$ 是 $Y$ 的一个风险因素。然而，条件优势比 $\\text{OR}_{Y,X \\mid S=1} \\approx 0.1247  1$，表明在被选择的个体中 $X$ 似乎是一个保护性因素。这种反转是对撞分层偏倚的一个标志。\n\n要求的最终数值答案是 $\\text{OR}_{Y,X \\mid S=1}$，四舍五入到四位有效数字。\n值：$0.124676...$\n四舍五入值：$0.1247$。",
            "answer": "$$\n\\boxed{0.1247}\n$$"
        },
        {
            "introduction": "在实践中，即使我们调整了所有已知的混杂因素，由未测量混杂所带来的威胁依然存在。因此，敏感性分析成为评估研究结果稳健性的关键步骤，而 E-值 (E-value) 则是为此目的而设计的核心工具。本练习将指导你从一个基本的偏倚边界公式出发，亲手推导出 E-值的计算公式，从而不仅学会如何计算它，更能理解其背后的逻辑和假设。掌握 E-值有助于你更批判性地解读和报告自己或他人的研究发现。",
            "id": "4954364",
            "problem": "一项观察性队列研究评估了一种新型炎症生物标志物的术前升高是否与成年手术患者$30$天全因死亡率增加相关。在对已测量的混杂因素进行调整后，拟合的对数二项模型得出，高生物标志物与低生物标志物相比，死亡的风险比（RR）为 $RR_{\\text{obs}}=2.35$。您担心存在一个单一的、未测量的二元混杂因素 $U$，它可能在已测量协变量的条件下，同时与暴露 $E$（高生物标志物）和结局 $D$（死亡率）相关联。\n\n根据定义，风险比的E值是指，在已测量协变量的条件下，一个未测量的混杂因素需要与暴露和结局同时具有的、以风险比为尺度的最小关联强度，才能将真实的因果风险比降至$1$（即完全解释掉观察到的关联）。\n\n采用以下经过充分检验的偏倚界定结果：在单一未测量二元混杂因素的乘性混杂标准条件下，该混杂因素可导致的最大乘性偏倚因子 $B$ 满足\n\n$$\nB \\le \\frac{RR_{EU}\\times RR_{UD}}{RR_{EU} + RR_{UD} - 1},\n$$\n\n其中 $RR_{EU}$ 是在已测量协变量条件下 $U$ 与 $E$ 的风险比关联，而 $RR_{UD}$ 是在已测量协变量条件下 $U$ 与 $D$ 的风险比关联。\n\n仅从E值的定义和上述偏倚界定结果出发，推导当 $RR_{\\text{obs}}1$ 时，E值作为 $RR_{\\text{obs}}$ 函数的闭式表达式。然后，在 $RR_{\\text{obs}}=2.35$ 处计算该表达式的值。将您的数值答案四舍五入到四位有效数字，并以纯数字形式报告（无单位）。",
            "solution": "观察到的风险比（$RR_{\\text{obs}}$）、真实的因果风险比（$RR_{\\text{true}}$）以及由未测量的混杂因素引起的偏倚因子（$B$）之间的关系可以表示为：\n$$RR_{\\text{obs}} = RR_{\\text{true}} \\times B$$\n根据E值的定义，我们需要找到能够“完全解释掉”观察到的关联的条件。这意味着，我们假设真实的因果风险比为1（即 $RR_{\\text{true}} = 1$）。在这种情况下，要使未测量的混杂成为观察到关联的唯一解释，偏倚因子必须等于观察到的风险比：\n$$B = RR_{\\text{obs}}$$\n问题中给出了由单一二元混杂因素 $U$ 能够产生的最大偏倚因子 $B$ 的上限：\n$$B \\le \\frac{RR_{EU} \\times RR_{UD}}{RR_{EU} + RR_{UD} - 1}$$\n其中 $RR_{EU}$ 和 $RR_{UD}$ 分别是混杂因素与暴露和结局的风险比关联，且假设它们都大于或等于1。\n\n要完全解释掉观察到的效应，可能的最大偏倚必须至少与 $RR_{\\text{obs}}$ 一样大。因此，我们得到以下必要条件：\n$$RR_{\\text{obs}} \\le \\frac{RR_{EU} \\times RR_{UD}}{RR_{EU} + RR_{UD} - 1}$$\nE值被定义为，要满足此条件，$RR_{EU}$ 和 $RR_{UD}$ 必须共同达到的最小值。我们设这个最小值为 $E$。由于不等式右侧的表达式是关于 $RR_{EU}$ 和 $RR_{UD}$ 的增函数（当它们 $\\ge 1$ 时），要找到满足条件的最小 $E$，我们只需考虑 $RR_{EU} = RR_{UD} = E$ 的情况。将此代入不等式，并将不等号变为等号以求临界值：\n$$RR_{\\text{obs}} = \\frac{E^2}{2E - 1}$$\n现在，我们求解这个关于 $E$ 的方程：\n$$E^2 - (2 \\cdot RR_{\\text{obs}})E + RR_{\\text{obs}} = 0$$\n使用二次公式 $E = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$，其中 $a=1$，$b = -2 \\cdot RR_{\\text{obs}}$，$c = RR_{\\text{obs}}$：\n$$E = \\frac{2 \\cdot RR_{\\text{obs}} \\pm \\sqrt{4 \\cdot RR_{\\text{obs}}^2 - 4 \\cdot RR_{\\text{obs}}}}{2}$$\n$$E = RR_{\\text{obs}} \\pm \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$$\n由于E值代表一个风险比，它必须大于或等于1。在 $RR_{\\text{obs}} > 1$ 的条件下，只有较大的根 $RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$ 满足此条件。因此，E值的闭式表达式为：\n$$E\\text{-value} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$$\n代入给定的观察风险比 $RR_{\\text{obs}} = 2.35$：\n$$E\\text{-value} = 2.35 + \\sqrt{2.35 \\times (2.35 - 1)} = 2.35 + \\sqrt{3.1725} \\approx 4.13115$$\n将结果四舍五入到四位有效数字，我们得到 $4.131$。",
            "answer": "$$ \\boxed{4.131} $$"
        }
    ]
}