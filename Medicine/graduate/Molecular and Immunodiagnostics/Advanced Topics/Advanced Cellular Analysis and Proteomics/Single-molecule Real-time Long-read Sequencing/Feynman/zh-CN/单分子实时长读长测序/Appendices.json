{
    "hands_on_practices": [
        {
            "introduction": "在任何测序项目的规划阶段，一个至关重要的问题是：我们需要多少测序数据？本练习将指导你推导一个基本但功能强大的模型，用于估算测序覆盖度 $C$，并将读长 $L$、读长数量 $N$、基因组大小 $G$ 和仪器产出等基本测序指标联系起来。通过这个实践 ，你将掌握如何为一个具体的临床免疫基因组学应用（如MHC区域分型）计算所需的仪器运行时间，这是确保数据质量和有效分配资源的一项核心技能。",
            "id": "5163228",
            "problem": "一家临床免疫基因组学实验室计划使用单分子实时（SMRT）长读长测序来表征扩展的主要组织相容性复合体（MHC）区域。设目标区域长度为 $G$ 个碱基对。将随机选择的碱基上的预期覆盖度 $C$ 定义为与该碱基重叠的测序碱基的期望数量，其标准假设为读长起始位点在区域上均匀分布，且由于 $G \\gg L$（其中 $L$ 是平均读长长度），边缘效应可以忽略。从此定义出发，仅使用期望的线性性质和读长起始位点均匀分布的假设，推导一个用读长数量 $N$、平均读长长度 $L$ 和区域长度 $G$ 表示 $C$ 的表达式。\n\n该实验室的检测方案靶向经典的人类白细胞抗原（HLA）区域，其长度为 $G = 3.9 \\times 10^{6}$ 个碱基对。为了在免疫诊断环境中实现可靠的单倍型定相，他们需要 $C^{\\star} = 47$ 的预期覆盖度。他们的SMRT仪器和文库制备平均每小时产生 $r_{N} = 2.5 \\times 10^{4}$ 条聚合酶读长，平均读长长度为 $L = 1.8 \\times 10^{4}$ 个碱基对，其中经过质量过滤和杂交捕获特异性筛选后，有 $f_{u} = 0.51$ 的可用且靶向的比例贡献于目标区域。假设读长产出率和可用比例不随时间变化，且独立于靶标。\n\n使用您推导出的表达式和第一性原理，计算在上述仪器性能下，在长度为 $G$ 个碱基对的区域上达到目标预期覆盖度 $C^{\\star}$ 所需的总运行时间（以小时为单位）。将您的最终运行时间四舍五入到四位有效数字。用小时表示您的答案。",
            "solution": "该问题陈述具有科学依据，提法明确，并包含了获得唯一解所需的所有信息。所提供的参数对于所述的免疫基因组学应用是切合实际的。下面我将进行推导和计算。\n\n问题分为两部分。首先，我们必须推导出预期覆盖度 $C$ 作为读长数量 $N$、平均读长长度 $L$ 和目标区域长度 $G$ 的函数的表达式。其次，我们必须使用这个表达式来计算达到特定目标覆盖度 $C^{\\star}$ 所需的仪器运行时间。\n\n第一部分：预期覆盖度公式的推导\n\n设目标区域由区间 $[0, G]$ 表示。考虑该区域内位于位置 $x$ 的一个任意碱基。我们需要求出覆盖位置 $x$ 的读长的期望数量。这就是预期覆盖度 $C$ 的定义。\n\n假设总共有 $N$ 条读长。我们考虑一条索引为 $i$ 的读长，其中 $i \\in \\{1, 2, ..., N\\}$。该读长的长度为 $L_i$。问题陈述平均读长长度为 $L$，这意味着 $L = E[L_i] = \\frac{1}{N} \\sum_{i=1}^{N} L_i$。\n\n读长 $i$ 的起始位置（记为 $s_i$）被假定在目标区域上均匀分布。鉴于边缘效应可以忽略的假设（$G \\gg L$），我们可以将起始位置建模为在区间 $[0, G]$ 上均匀分布。\n\n为了让读长 $i$ 覆盖位置 $x$ 处的碱基，其起始位置 $s_i$ 必须落在区间 $[x - L_i + 1, x]$ 内。这个有效起始位置区间的长度是 $L_i$。一个随机选择的起始位置 $s_i$ 落入此区间的概率 $p_i$ 是有效区间长度与起始位置所有可能区间总长度的比值。\n$$p_i = P(\\text{读长 } i \\text{ 覆盖 } x) = \\frac{L_i}{G}$$\n\n让我们为每条读长定义一个指示随机变量 $I_i$：\n$$I_i = \\begin{cases} 1  \\text{如果读长 } i \\text{ 覆盖位置 } x \\\\ 0  \\text{否则} \\end{cases}$$\n该指示变量的期望值是事件发生的概率：\n$$E[I_i] = 1 \\cdot P(I_i=1) + 0 \\cdot P(I_i=0) = P(I_i=1) = p_i = \\frac{L_i}{G}$$\n\n位置 $x$ 处的总覆盖度，记为 $C_x$，是所有 $N$ 条读长的指示变量之和：\n$$C_x = \\sum_{i=1}^{N} I_i$$\n预期覆盖度 $C$ 是 $C_x$ 的期望。利用期望的线性性质（它允许我们将和的期望写为期望的和），我们有：\n$$C = E[C_x] = E\\left[\\sum_{i=1}^{N} I_i\\right] = \\sum_{i=1}^{N} E[I_i]$$\n代入 $E[I_i]$ 的表达式：\n$$C = \\sum_{i=1}^{N} \\frac{L_i}{G} = \\frac{1}{G} \\sum_{i=1}^{N} L_i$$\n我们知道测序碱基的总数是 $\\sum_{i=1}^{N} L_i$。这个和可以用平均读长长度 $L$ 和读长总数 $N$ 来表示：\n$$\\sum_{i=1}^{N} L_i = N \\cdot L$$\n将此代入 $C$ 的表达式，我们得到所需的公式：\n$$C = \\frac{N L}{G}$$\n这个表达式将预期覆盖度 $C$ 与读长数量 $N$、平均读长长度 $L$ 以及基因组或区域长度 $G$ 联系起来。\n\n第二部分：所需运行时间的计算\n\n目标是在长度为 $G = 3.9 \\times 10^{6}$ 个碱基对的区域上达到 $C^{\\star} = 47$ 的目标预期覆盖度。测序过程产生的平均读长长度为 $L = 1.8 \\times 10^{4}$ 个碱基对。\n\n首先，我们计算达到覆盖度 $C^{\\star}$ 所需的*可用、靶向*读长的总数，我们称之为 $N_{\\text{usable}}$。使用我们刚刚推导的公式：\n$$C^{\\star} = \\frac{N_{\\text{usable}} L}{G}$$\n整理以求解 $N_{\\text{usable}}$：\n$$N_{\\text{usable}} = \\frac{C^{\\star} G}{L}$$\n代入给定值：\n$$N_{\\text{usable}} = \\frac{47 \\cdot (3.9 \\times 10^{6})}{(1.8 \\times 10^{4})} = \\frac{183.3 \\times 10^{6}}{1.8 \\times 10^{4}} = 101.833... \\times 10^{2} = 10183.33...$$\n因此，大约需要 $10183$ 条可用读长。\n\n接下来，我们必须确定这些可用读长的生成速率。仪器每小时总共产生 $r_{N} = 2.5 \\times 10^{4}$ 条聚合酶读长。然而，其中只有 $f_{u} = 0.51$ 的比例是可用且靶向的。因此，可用读长的有效生成速率 $r_{\\text{usable}}$ 是：\n$$r_{\\text{usable}} = r_{N} \\cdot f_{u} = (2.5 \\times 10^{4} \\text{ 读长/小时}) \\cdot 0.51 = 12750 \\text{ 读长/小时}$$\n\n总运行时间 $T$ 是所需可用读长总数除以它们的生成速率：\n$$T = \\frac{N_{\\text{usable}}}{r_{\\text{usable}}}$$\n代入 $N_{\\text{usable}}$ 和 $r_{\\text{usable}}$ 的表达式：\n$$T = \\frac{C^{\\star} G / L}{r_{N} f_{u}} = \\frac{C^{\\star} G}{L r_{N} f_{u}}$$\n现在，我们代入所有数值：\n$$T = \\frac{47 \\cdot (3.9 \\times 10^{6})}{(1.8 \\times 10^{4}) \\cdot (2.5 \\times 10^{4}) \\cdot 0.51}$$\n$$T = \\frac{1.833 \\times 10^{8}}{(1.8 \\times 10^{4}) \\cdot (2.5 \\times 10^{4}) \\cdot 0.51} = \\frac{1.833 \\times 10^{8}}{(4.5 \\times 10^{8}) \\cdot 0.51} = \\frac{1.833 \\times 10^{8}}{2.295 \\times 10^{8}}$$\n$$T = \\frac{1.833}{2.295} \\approx 0.7986928... \\text{ 小时}$$\n\n问题要求最终运行时间四舍五入到四位有效数字。第五位有效数字是 $9$，所以我们将第四位数字向上取整。\n$$T \\approx 0.7987 \\text{ 小时}$$",
            "answer": "$$\\boxed{0.7987}$$"
        },
        {
            "introduction": "单分子实时（SMRT）测序的一个标志性优势是其环形一致性测序（Circular Consensus Sequencing, CCS）模式，它能生成错误率极低的高保真（HiFi）读长。这种高精度并非源于单次读取的完美无瑕，而是来自对同一分子多次独立测序的统计力量。本练习  让你从第一性原理出发，运用二项分布来量化这一过程，你将推导出单次通过错误率 $p$ 与最终一致性序列错误率 $p_c$ 之间的关系，并计算为了达到临床诊断级别的质量（以Phred质量值 $QV$ 衡量），需要多少次的测序循环。",
            "id": "5163237",
            "problem": "一家临床实验室正在评估单分子实时 (SMRT) 环形一致性测序技术，用于单核苷酸变异基因分型检测。聚合酶每次环绕环化模板都会产生一次独立的子读长遍次。假设在某个给定的基因组位置，每次遍次独立地以概率 $(1-p)$ 检出正确碱基，以概率 $p$ 检出错误碱基，其中 $0  p  1/2$。最终的一致性碱基是通过对 $n$ 次独立遍次的“多数投票”来确定的，其中 $n$ 是一个奇数。如果大多数遍次报告的是错误碱基，则发生一致性错误。\n\n1.  推导一致性错误率 $p_c$ 的解析表达式，该表达式是单次遍次错误率 $p$ 和奇数遍次数 $n$ 的函数。\n2.  实验室要求一致性序列的 Phred 质量值 $(QV)$ 至少为 $30$，其中 $QV = -10\\log_{10}(p_c)$。如果单次遍次错误率 $p = 0.15$，那么为了达到这一质量目标，所需的最小奇数遍次数 $n$ 是多少？",
            "solution": "该问题是有效的，因为它科学地基于分子诊断和概率论的原理，问题提出得很好，目标明确，数据充分，并且没有任何事实或逻辑上的不一致。\n\n按照要求，任务分两部分解决。第一，推导一致性错误率 $p_c$ 的解析表达式。第二，计算满足指定质量阈值所需的最小遍次数 $n$。\n\n第 1 部分：推导 $p_c$ 的解析表达式。\n\n在单个基因组位置上，通过 $n$ 次独立遍次确定碱基的过程可以建模为一系列 $n$ 次伯努利试验。对于每次试验（遍次），有两种结果：错误的碱基检出（“错误”）或正确的碱基检出（就获得正确碱基而言是“成功”）。\n\n设 $p$ 为任何单次遍次中检出错误碱基的概率。给定条件为 $0  p  1/2$。\n因此，检出正确碱基的概率为 $1-p$。\n\n设 $K$ 为代表 $n$ 次独立遍次中错误碱基检出总数的随机变量。由于各次遍次是独立的，且每次出错的概率 $p$ 是恒定的，因此 $K$ 服从参数为 $n$（试验次数）和 $p$（每次试验出错的概率）的二项分布。记为 $K \\sim B(n, p)$。\n\n$K$ 的概率质量函数 (PMF) 由二项式公式给出：\n$$P(K=k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n其中 $k$ 是一个整数，代表错误检出的次数，$k \\in \\{0, 1, 2, \\dots, n\\}$。\n\n如果大多数遍次报告的是错误碱基，则发生一致性错误。错误检出的次数为 $k$，正确检出的次数为 $n-k$。大多数检出为错误意味着 $k > n-k$，可简化为 $2k > n$ 或 $k > \\frac{n}{2}$。\n\n问题指定 $n$ 为一个奇数。设 $n = 2m+1$，其中 $m$ 为某个非负整数。发生错误的条件变为 $k > \\frac{2m+1}{2} = m + \\frac{1}{2}$。由于 $k$ 必须是整数，满足此不等式的最小整数值 $k$ 为 $m+1$。代入 $m = \\frac{n-1}{2}$，一致性错误的条件是 $k \\ge \\frac{n-1}{2} + 1 = \\frac{n+1}{2}$。\n\n一致性错误率 $p_c$ 是所有导致一致性序列错误的结果的总概率。也就是随机变量 $K$ 大于或等于 $\\frac{n+1}{2}$ 的概率。我们可以通过对所有相关的 $k$ 值求和来表达这一点：\n$$p_c(n, p) = P(K \\ge \\frac{n+1}{2}) = \\sum_{k=\\frac{n+1}{2}}^{n} P(K=k)$$\n代入二项分布的概率质量函数，我们得到 $p_c$ 的最终解析表达式：\n$$p_c(n, p) = \\sum_{k=\\frac{n+1}{2}}^{n} \\binom{n}{k} p^k (1-p)^{n-k}$$\n\n第 2 部分：确定最小奇数 $n$。\n\n给定单次遍次错误率 $p = 0.15$ 和目标 Phred 质量值 $QV^{\\ast} = 30$。质量值定义为 $QV = -10\\log_{10}(p_c)$。实验室要求一致性序列的质量至少达到此目标值，因此我们必须有 $QV \\ge QV^{\\ast}$。\n$$-10\\log_{10}(p_c) \\ge 30$$\n两边同除以 $-10$ 会使不等号反向：\n$$\\log_{10}(p_c) \\le -3$$\n对两边应用以 10 为底的指数函数：\n$$p_c \\le 10^{-3}$$\n因此，我们必须找到最小的奇数 $n$，使得一致性错误率不大于 $0.001$。当 $p=0.15$ 时，单次遍次正确的概率为 $1-p = 0.85$。需要求解的不等式是：\n$$p_c(n) = \\sum_{k=\\frac{n+1}{2}}^{n} \\binom{n}{k} (0.15)^k (0.85)^{n-k} \\le 0.001$$\n由于 $p=0.15  0.5$，增加遍次数 $n$ 会降低多数错误发生的概率。因此，$p_c(n)$ 是 $n$ 的单调递减函数。我们可以通过测试连续的奇数来找到最小的 $n$。\n\n对于 $n=1$，$p_c(1) = 0.15$，大于 $0.001$。\n对于 $n=3$，$p_c(3) \\approx 0.06075$，大于 $0.001$。\n我们继续测试 $n=5, 7, 9, 11, \\dots$。让我们检查阈值附近的值。\n\n对于 $n=13$：\n导致一致性序列失败所需的错误次数为 $k \\ge \\frac{13+1}{2} = 7$。\n$$p_c(13) = \\sum_{k=7}^{13} \\binom{13}{k} (0.15)^k (0.85)^{13-k}$$\n这个总和是 $B(13, 0.15)$ 分布的尾部概率，对其进行数值计算可得：\n$$p_c(13) \\approx 0.001265$$\n由于 $0.001265 > 0.001$，$n=13$ 次遍次不足以满足质量要求。\n\n对于下一个奇数 $n=15$：\n导致一致性序列失败所需的错误次数为 $k \\ge \\frac{15+1}{2} = 8$。\n$$p_c(15) = \\sum_{k=8}^{15} \\binom{15}{k} (0.15)^k (0.85)^{15-k}$$\n对 $B(15, 0.15)$ 分布的这个总和进行数值计算可得：\n$$p_c(15) \\approx 0.000608$$\n由于 $0.000608 \\le 0.001$，$n=15$ 次遍次足以满足质量要求。\n\n鉴于 $p_c(n)$ 是一个随 $n$ 增大而减小的函数，并且已知 $n=13$ 不足而 $n=15$ 足够，因此所需的最小奇数遍次数为 $15$。",
            "answer": "$$\\boxed{15}$$"
        },
        {
            "introduction": "长读长测序的真正威力在于其解析复杂基因组区域的能力，例如具有高度多态性的人类白细胞抗原（HLA）区域，这些区域用传统的线性参考基因组难以准确表示。为了应对这种复杂性，生物信息学发展了基于图谱的参考基因组。本练习  将带你进入高级生物信息学领域，通过从动态规划的基本原理出发，推导并实现部分有序比对（Partial Order Alignment, POA）算法，将长读长序列与代表等位基因变异的图谱基因组进行比对。这项实践揭示了长读长技术独特优势背后的计算核心。",
            "id": "5163278",
            "problem": "给定一个代表人类白细胞抗原（HLA）等位基因偏序基因组的有向无环图（DAG），以及一条单分子实时（SMRT）长读长序列。请从第一性原理出发，推导并实现一个偏序比对程序，该程序将经典的全局比对推广到节点标记的有向无环图，并使用线性空位罚分。你的推导必须基于动态规划的最优性原理，不得假定任何预先推导出的图比对公式。对于每个测试用例，你的实现必须计算两个量：(i) 读长与 DAG 中任意路径的最优全局比对得分，以及 (ii) 下面定义的计算量的量化估计，以证实理论时间复杂度。\n\n使用的基本原理：\n- 动态规划中的最优子结构原理和贝尔曼最优性。\n- 当图是线性链时，Needleman–Wunsch 全局比对作为特例。\n- 每次插入或删除具有恒定罚分的线性空位模型。\n- 有向无环图的拓扑排序。\n\n定义和约束：\n- 该图是一个节点标记的有向无环图，其中每个节点带有一个来自字母表 $\\{A,C,G,T\\}$ 的核苷酸。比对将读长映射到图中的一条路径，允许匹配、错配和空位（读长中的插入或图路径中的删除）。\n- 使用线性空位罚分模型：每次插入或删除产生一个恒定的罚分。\n- 令 $V$ 为节点数，$E$ 为有向边数，$L$ 为读长长度。\n- 根据动态规划的第一性原理，为每个节点和读长位置定义三个动态规划状态：\n  - $M$：通过消耗一个图节点和一个读长字符结束的比对，\n  - $I$：通过消耗一个读长字符结束的比对（图中出现空位），\n  - $D$：通过消耗一个图节点结束的比对（读长中出现空位）。\n- 使用整个读长与 DAG 中某条路径的全局比对，对所有空位（包括两端的空位）应用线性罚分。\n\n计算量度量标准：\n- 将计算量定义为在整个动态规划过程中，在所有动态规划状态转移中为求取最大值而评估的标量前驱状态候选者的确切计数总和。候选者计数方式如下：\n  - 对于每个节点 $v$ 和 $\\{0,1,\\dots,L\\}$ 中的位置 $j$，如果 $\\deg^{-}(v) > 0$，$D$ 状态考虑 $\\deg^{-}(v)$ 个候选前驱；否则，考虑 1 个起始候选。\n  - 对于每个节点 $v$ 和 $\\{1,\\dots,L\\}$ 中的位置 $j$，$I$ 状态考虑在 $(v,j-1)$ 处的 3 个前驱状态候选。\n  - 对于每个节点 $v$ 和 $\\{1,\\dots,L\\}$ 中的位置 $j$，如果 $\\deg^{-}(v) > 0$，$M$ 状态考虑 $3 \\cdot \\deg^{-}(v)$ 个候选前驱；否则，考虑 1 个起始候选。\n- 该度量标准不计算加法，仅计算在求取最大值时所比较的标量值的数量，如上所述。\n\n计分：\n- 匹配得分：$+2$。\n- 错配罚分：$-2$。\n- 空位罚分：$-3$。\n\n测试套件：\n- 测试用例 1（SNP 气泡 DAG，类似 HLA-A 的外显子）：\n  - 节点（索引对应标签）：$0{:}A$, $1{:}C$, $2{:}G$, $3{:}T$, $4{:}A$, $5{:}C$, $6{:}G$。\n  - 有向边 $(u \\rightarrow v)$：$(0 \\rightarrow 1)$、$(1 \\rightarrow 2)$、$(1 \\rightarrow 3)$、$(2 \\rightarrow 4)$、$(3 \\rightarrow 4)$、$(4 \\rightarrow 5)$、$(5 \\rightarrow 6)$。\n  - 读长：$ACGACG$，因此 $L = 6$。\n- 测试用例 2（插入缺失气泡 DAG，跳过一个节点的替代路径）：\n  - 节点：$0{:}A$, $1{:}C$, $2{:}G$, $3{:}A$, $4{:}C$, $5{:}G$。\n  - 边：$(0 \\rightarrow 1)$、$(1 \\rightarrow 2)$、$(2 \\rightarrow 3)$、$(3 \\rightarrow 4)$、$(2 \\rightarrow 4)$、$(4 \\rightarrow 5)$。\n  - 读长：$ACGCG$，因此 $L = 5$。\n- 测试用例 3（在测试用例 1 的 DAG 上的重度错配读长）：\n  - 使用与测试用例 1 相同的图。\n  - 读长：$TTTTTT$，因此 $L = 6$。\n\n任务：\n- 对于每个测试用例，计算：\n  1. 使用上述计分方式的最优全局比对得分（整数）。\n  2. 如定义的计算量度量标准。\n- 理论复杂度：从第一性原理出发，推导你的动态规划程序关于 $V$、$E$ 和 $L$ 的渐近时间复杂度。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。按顺序聚合所有测试用例的结果，将每对结果平铺为两个连续的整数。例如，输出必须看起来像 $[s_1,c_1,s_2,c_2,s_3,c_3]$，其中 $s_i$ 是比对得分，$c_i$ 是测试用例 $i$ 的计算量。",
            "solution": "该问题要求推导并实现一个偏序比对（POA）算法，用于将一条 DNA 序列（读长）与一个偏序图进行比对，该偏序图表示为一个节点标记的有向无环图（DAG）。比对必须是全局的，覆盖整个读长，并且必须使用线性空位罚分模型。解决方案必须从动态规划（DP）的第一性原理推导得出，特别是最优性原理。\n\n### 1. 最优性原理与状态定义\n\n我们动态规划方法的基础是最优子结构原理，该原理指出，一个问题的最优解可以由其子问题的最优解构造而成。在序列比对的背景下，这意味着一个读长前缀与图路径的最优比对得分可以通过扩展一个更小子问题的最优比对来计算。\n\n在任何给定点，一个读长与 DAG 中路径的比对可以以三种方式之一结束：\n1.  匹配或错配：读长前缀的最后一个字符与图路径的最后一个节点比对。\n2.  插入：读长前缀的最后一个字符与一个空位比对。\n3.  删除：图路径的最后一个节点与一个空位比对。\n\n为了捕捉这些可能性，我们为图中的每个节点 $v$ 和读长中的每个位置 $j$（代表长度为 $j$ 的前缀，即 $read[1 \\dots j]$）定义三个 DP 状态。设 $V$ 为节点集合，$L$ 为读长长度。设 $g$ 为线性空位罚分，$s(c_1, c_2)$ 为比对字符 $c_1$ 和 $c_2$ 的得分。\n\n-   $M(v, j)$：将读长前缀 $read[1 \\dots j]$ 与一个在 DAG 中以节点 $v$ 结束的路径进行比对的最优得分，其中读长字符 $read[j]$ 与节点 $v$ 的字符标签比对。\n-   $I(v, j)$：将 $read[1 \\dots j]$ 与一个以 $v$ 结束的路径进行比对的最优得分，其中 $read[j]$ 与一个空位比对（相对于图路径是插入）。\n-   $D(v, j)$：将 $read[1 \\dots j]$ 与一个以 $v$ 结束的路径进行比对的最优得分，其中 $v$ 的字符标签与一个空位比对（相对于读长是删除）。\n\n### 2. 递推关系的推导\n\n我们通过考虑如何扩展一个比对来推导每个状态的递推关系。设 $Pred(v)$ 为节点 $v$ 的直接前驱节点集合。\n\n**$I(v, j)$ 状态（插入）：**一个在节点 $v$ 处以 $read[j]$ 的插入结束的比对，必须扩展一个已经结束于节点 $v$ 的对 $read[1 \\dots j-1]$ 的比对。这个之前的比对可能以匹配/错配（$M(v, j-1)$）、插入（$I(v, j-1)$）或删除（$D(v, j-1)$）结束。我们取这些可能性的最大值，并加上空位罚分 $g$。\n$$I(v, j) = g + \\max \\left\\{ M(v, j-1), I(v, j-1), D(v, j-1) \\right\\}$$\n根据问题规定，此最大化操作的计算量为 3 个候选者。\n\n**$M(v, j)$ 状态（匹配/错配）：**一个以 $read[j]$ 与节点 $v$ 匹配结束的比对，必须扩展一个对 $read[1 \\dots j-1]$ 与以一个前驱节点 $u \\in Pred(v)$ 结束的路径的比对。对于每个前驱 $u$，之前的比对可能是三种状态中的任意一种。我们取所有前驱和所有三种状态的最大值，并加上比对字符的得分。\n$$M(v, j) = s(\\text{label}(v), read[j]) + \\max_{u \\in Pred(v)} \\left\\{ M(u, j-1), I(u, j-1), D(u, j-1) \\right\\}$$\n此操作的计算量为 $3 \\cdot \\deg^{-}(v)$ 个候选者，其中 $\\deg^{-}(v)$ 是 $v$ 的入度。如果 $v$ 是一个源节点（$\\deg^{-}(v) = 0$），此转移作为特殊的基础情况处理。\n\n**$D(v, j)$ 状态（删除）：**一个以删除节点 $v$ 来比对读长前缀 $read[1 \\dots j]$ 结束的比对，必须扩展一个对相同读长前缀与以一个前驱节点 $u \\in Pred(v)$ 结束的路径的比对。\n$$D(v, j) = g + \\max_{u \\in Pred(v)} \\left\\{ M(u, j), I(u, j), D(u, j) \\right\\}$$\n问题为此状态指定了 $\\deg^{-}(v)$ 个候选者的计算量。这意味着一个简化的递推，其中每个前驱只考虑一个最佳分数。令 $S(u,j) = \\max\\{M(u,j), I(u,j), D(u,j)\\}$。递推变为：\n$$D(v, j) = g + \\max_{u \\in Pred(v)} \\left\\{ S(u, j) \\right\\}$$\n这与指定的计算量计数一致。\n\n### 3. 拓扑排序与算法结构\n\n$D(v,j)$ 的计算依赖于在相同读长位置 $j$ 的前驱节点 $u$ 的状态。这在给定 $j$ 的 DP 表“切片”内部产生了依赖关系。为解决此问题，必须按拓扑顺序处理节点。设拓扑排序后的节点为 $v_1, v_2, \\dots, v_{|V|}$。\n\n整个算法如下：\n1.  计算图节点的拓扑排序。\n2.  初始化 $j=0$ 的 DP 表 $M$、$I$ 和 $D$。\n3.  从 $1$ 到 $L$ 迭代 $j$。在每次迭代中：\n4.  按拓扑顺序遍历节点 $v$。对于每个 $v$：\n5.  使用递推关系计算 $I(v, j)$，然后是 $M(v, j)$，最后是 $D(v, j)$。拓扑排序确保在计算 $v$ 的状态时，其所有前驱 $u$ 所需的状态都已可用。\n\n### 4. 初始化（基础情况）\n\n-   **DP 表初始化：** 大小为 $|V| \\times (L+1)$ 的表 $M, I, D$ 被初始化为一个非常大的负数，代表 $-\\infty$。\n\n-   **与空读长的比对 ($j=0$)：** 一个空读长与图路径的比对只能包含删除。\n    -   对于一个源节点 $v$（$\\deg^{-}(v)=0$），长度为一的路径仅包含 $v$。将其与空读长比对意味着一次删除。因此，$D(v, 0) = g$。根据“起始候选”的计算量度量标准规范，这可以概念化为 $D(v,0) = g + \\max\\{0\\}$，其中 $0$ 是虚拟起始状态的得分。\n    -   对于任何其他节点 $v$，一个以 $v$ 结束的全是删除的路径必须扩展一个以其某个前驱结束的全是删除的路径。\n      $$D(v, 0) = g + \\max_{u \\in Pred(v)} \\{D(u, 0)\\}$$\n    -   状态 $M(v,0)$ 和 $I(v,0)$ 是不可能的，保持为 $-\\infty$。\n\n-   **源节点（$deg^-(v)=0$）对于 $j>0$：** 对于源节点 $v$，没有前驱可以扩展。这对应于开始一条新的比对路径。\n    -   **$M(v,j)$：** 比对从节点 $v$ 开始，匹配 $read[j]$。前面的读长字符 $read[1 \\dots j-1]$ 必须是插入。得分为 $M(v,j) = s(\\text{label}(v), read[j]) + (j-1) \\cdot g$。计算量为 1 个起始候选。\n    -   **$D(v,j)$：** 在比对 $read[1 \\dots j]$ 后删除 $v$，前缀 $read[1 \\dots j]$ 必须与空路径比对（即全是插入）。得分为 $D(v,j) = g + j \\cdot g$。计算量为 1 个起始候选。\n\n### 5. 最终得分计算\n\n问题要求的是与 DAG 中*任意路径*的全局比对的最优得分。路径不一定从源节点延伸到汇点。因此，在填充完直到 $j=L$ 的 DP 表后，最终的最优得分是所有节点在最终读长位置 $L$ 处所有状态的最大值。\n$$ \\text{Score}_{\\text{optimal}} = \\max_{v \\in V} \\{ M(v, L), I(v, L), D(v, L) \\} $$\n\n### 6. 计算复杂度分析\n\n1.  **拓扑排序：** 可以使用 Kahn 算法或 DFS 在 $O(V+E)$ 时间内完成。\n2.  **初始化 ($j=0$)：** 按拓扑顺序遍历所有节点。对于每个节点，我们遍历其前驱。前驱查找的总次数是 $\\sum_{v \\in V} \\deg^-(v) = E$。此步骤为 $O(V+E)$。\n3.  **主循环：** 外层循环运行 $L$ 次。内层循环遍历所有 $V$ 个节点。\n    -   对于每个 $(v, j)$，计算 $I(v,j)$ 需要 $O(1)$ 时间。总计：$O(VL)$。\n    -   对于每个 $(v, j)$，计算 $M(v,j)$ 需要 $O(\\deg^{-}(v))$ 时间。对于固定的 $j$，遍历所有 $v$ 的总时间是 $\\sum_{v \\in V} O(\\deg^{-}(v)) = O(E)$。总计：$O(EL)$。\n    -   类似地，计算 $D(v,j)$ 需要 $O(\\deg^{-}(v))$ 时间。总计：$O(EL)$。\n总时间复杂度由主循环主导，为 $O(VL + EL) = O(L(V+E))$。\n\n### 7. 计算量度量标准\n\n实现将维护一个计数器 `effort`。在计算每个 DP 状态时，此计数器将严格按照问题陈述中指定的规则递增。这确保了所实现的递推和基础情况与问题的形式化定义完全匹配。对于在源节点处没有明确 `max` 定义的基础情况，我们将其实现为对单个候选者的 `max` 操作，以符合计算量度量标准。",
            "answer": "```python\nimport numpy as np\n\ndef topological_sort(graph):\n    \"\"\"\n    Performs a topological sort on the graph using Kahn's algorithm.\n    \"\"\"\n    num_nodes = len(graph['nodes'])\n    in_degree = dict(graph['in_degree'])\n    queue = [i for i in range(num_nodes) if in_degree[i] == 0]\n    topo_order = []\n    \n    while queue:\n        u = queue.pop(0)\n        topo_order.append(u)\n        \n        for v in sorted(graph['adj'].get(u, [])): # sorted for determinism\n            in_degree[v] -= 1\n            if in_degree[v] == 0:\n                queue.append(v)\n                \n    if len(topo_order) != num_nodes:\n        raise ValueError(\"Graph has a cycle\")\n        \n    return topo_order\n\ndef partial_order_alignment(graph, read, match_score, mismatch_penalty, gap_penalty):\n    \"\"\"\n    Performs partial order alignment of a read to a DAG.\n    \"\"\"\n    V = len(graph['nodes'])\n    L = len(read)\n    g = gap_penalty\n    \n    # Initialize DP tables with a large negative number\n    NEG_INF = -10**9\n    M = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    I = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    D = np.full((V, L + 1), NEG_INF, dtype=np.int64)\n    \n    effort = 0\n    \n    topo_order = topological_sort(graph)\n    \n    # Initialization for j=0 (empty read prefix)\n    for v in topo_order:\n        preds = graph['pred'].get(v, [])\n        if not preds: # Source node\n            # Conceptually, D[v,0] = g + 0 (score from virtual start node)\n            max_pred_D0 = 0 \n            D[v, 0] = g + max_pred_D0\n            effort += 1 # 1 start candidate\n        else:\n            pred_scores = [D[u, 0] for u in preds]\n            if pred_scores:\n                max_pred_D0 = max(pred_scores)\n                if max_pred_D0 > NEG_INF:\n                   D[v, 0] = g + max_pred_D0\n                effort += len(preds)\n\n    # Main DP loop\n    for j in range(1, L + 1):\n        for v in topo_order:\n            preds = graph['pred'].get(v, [])\n            \n            # State I: Insertion\n            prev_score_I = max(M[v, j-1], I[v, j-1], D[v, j-1])\n            if prev_score_I > NEG_INF:\n                I[v, j] = g + prev_score_I\n                effort += 3\n            \n            # State M: Match/Mismatch\n            v_char = graph['nodes'][v]\n            read_char = read[j-1]\n            score_s = match_score if v_char == read_char else mismatch_penalty\n            \n            max_pred_M = NEG_INF\n            if not preds: # Source node\n                # Alignment starts here, after j-1 insertions\n                max_pred_M = (j - 1) * g\n                effort += 1 # 1 start candidate\n            else:\n                pred_scores_M = []\n                for u in preds:\n                    pred_scores_M.extend([M[u, j-1], I[u, j-1], D[u, j-1]])\n                max_pred_M = max(pred_scores_M) if pred_scores_M else NEG_INF\n                effort += 3 * len(preds)\n            \n            if max_pred_M > NEG_INF:\n                M[v, j] = score_s + max_pred_M\n\n            # State D: Deletion\n            max_pred_D = NEG_INF\n            if not preds: # Source node\n                # To delete v, read[0...j-1] must all be insertions\n                max_pred_D = j * g\n                effort += 1 # 1 start candidate\n            else:\n                # Per effort spec, this takes max over a single score from each predecessor\n                S_u_j = []\n                for u in preds:\n                    s_val = max(M[u, j], I[u, j], D[u, j])\n                    if s_val > NEG_INF:\n                        S_u_j.append(s_val)\n                if S_u_j:\n                    max_pred_D = max(S_u_j)\n                effort += len(preds)\n            \n            if max_pred_D > NEG_INF:\n                D[v, j] = g + max_pred_D\n\n    # Final score is the max over all states at j=L for any node v\n    final_score = NEG_INF\n    if V > 0:\n        final_scores = np.concatenate((M[:, L], I[:, L], D[:, L]))\n        final_score = np.max(final_scores)\n\n    return int(final_score), effort\n\n\ndef solve():\n    \"\"\"\n    Sets up and solves the partial order alignment problem for the given test cases.\n    \"\"\"\n    match_score = 2\n    mismatch_penalty = -2\n    gap_penalty = -3\n\n    def build_graph(nodes, edges):\n        num_nodes = len(nodes)\n        adj = {i: [] for i in range(num_nodes)}\n        pred = {i: [] for i in range(num_nodes)}\n        in_degree = {i: 0 for i in range(num_nodes)}\n        for u, v in edges:\n            adj[u].append(v)\n            pred[v].append(u)\n            in_degree[v] += 1\n        return {'nodes': nodes, 'adj': adj, 'pred': pred, 'in_degree': in_degree}\n\n    test_cases = [\n        {\n            \"nodes\": ['A', 'C', 'G', 'T', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6)],\n            \"read\": \"ACGACG\"\n        },\n        {\n            \"nodes\": ['A', 'C', 'G', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (2, 3), (3, 4), (2, 4), (4, 5)],\n            \"read\": \"ACGCG\"\n        },\n        {\n            \"nodes\": ['A', 'C', 'G', 'T', 'A', 'C', 'G'],\n            \"edges\": [(0, 1), (1, 2), (1, 3), (2, 4), (3, 4), (4, 5), (5, 6)],\n            \"read\": \"TTTTTT\"\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        graph = build_graph(case[\"nodes\"], case[\"edges\"])\n        score, effort = partial_order_alignment(graph, case[\"read\"], match_score, mismatch_penalty, gap_penalty)\n        results.extend([score, effort])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}