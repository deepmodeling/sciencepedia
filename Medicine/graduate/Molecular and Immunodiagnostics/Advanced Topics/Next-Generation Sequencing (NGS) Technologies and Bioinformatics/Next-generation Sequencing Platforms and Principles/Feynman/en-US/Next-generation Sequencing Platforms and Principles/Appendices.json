{
    "hands_on_practices": [
        {
            "introduction": "Understanding the relationship between instrument parameters and the final data output is a fundamental skill for any NGS practitioner. This exercise  demonstrates how to calculate the expected sequencing yield from first principles, connecting the physical process on the flow cell to the final gigabase output. Mastering this calculation is essential for planning experiments, verifying run performance, and troubleshooting.",
            "id": "5140026",
            "problem": "A core principle of high-throughput sequencing by synthesis in Next-Generation Sequencing (NGS) is that each sequencing cycle adds one nucleotide to each cluster that passes the instrument’s quality screen, commonly called passing filter (PF). Index cycles do not contribute to the reported genomic yield if yield is defined strictly as the sum of bases in Read 1 and Read 2. A patterned flow cell on an Illumina-style instrument is segmented into tiles within lanes; the number of clusters per tile and the PF fraction determine the number of usable clusters that generate base calls per cycle.\n\nConsider a run with the following scientifically realistic and internally consistent parameters:\n- Lanes: $2$ lanes per flow cell.\n- Tiles: $400$ imaging tiles per lane.\n- Clusters: an average of $5.0 \\times 10^{5}$ clusters per tile at the end of cluster generation and prior to PF filtering, uniformly distributed across tiles and lanes.\n- Passing filter (PF) fraction: $0.82$ of clusters pass the vendor’s chastity filter, assumed to apply uniformly across all tiles and lanes.\n- Read structure and cycles: Read $1$ uses $150$ cycles, Index $1$ uses $8$ cycles, Index $2$ uses $8$ cycles, and Read $2$ uses $150$ cycles. Only Read $1$ and Read $2$ contribute to the reported yield.\n- Manufacturer’s listed specification for this flow cell and read structure: $100$ gigabases per flow cell as the nominal yield target.\n\nStarting from first principles that one base is produced per PF cluster per sequencing cycle that contributes to the reported reads, and that the total number of PF clusters equals the product of lanes, tiles per lane, clusters per tile, and the PF fraction, compute the expected total number of bases produced by this run and convert the result to gigabases. Use $1$ gigabase $=$ $10^{9}$ bases.\n\nState in your reasoning whether the result is within $\\pm 10\\%$ of the instrument’s listed specification, but provide only the numerical value of the expected yield in gigabases as your final answer. Round your final answer to four significant figures and express it in gigabases (Gb).",
            "solution": "The fundamental basis of the calculation is that in sequencing by synthesis, each sequencing cycle appends one nucleotide to each cluster that passes quality metrics, and thus contributes one base call per PF cluster per applicable cycle. Index cycles add bases to index reads but do not contribute to the reported genomic yield if the yield is defined as bases in Read $1$ and Read $2$ only. Therefore, the total number of reported bases is the number of PF clusters multiplied by the total number of cycles in Read $1$ and Read $2$.\n\nFirst, compute the total number of clusters across the entire flow cell prior to PF filtering. With $2$ lanes, $400$ tiles per lane, and $5.0 \\times 10^{5}$ clusters per tile, the total is\n$$\nN_{\\text{clusters, total}} \\;=\\; 2 \\times 400 \\times \\left(5.0 \\times 10^{5}\\right) \\;=\\; 4.0 \\times 10^{8}.\n$$\n\nNext, apply the passing filter fraction $0.82$ to obtain the number of usable clusters:\n$$\nN_{\\text{PF}} \\;=\\; 0.82 \\times \\left(4.0 \\times 10^{8}\\right) \\;=\\; 3.28 \\times 10^{8}.\n$$\n\nNow determine the number of cycles that contribute to the reported yield. Read $1$ contributes $150$ cycles and Read $2$ contributes $150$ cycles, while Index $1$ ($8$ cycles) and Index $2$ ($8$ cycles) are excluded from the reported yield under the stated definition. Thus, the total number of reporting cycles is\n$$\nC_{\\text{reporting}} \\;=\\; 150 + 150 \\;=\\; 300.\n$$\n\nThe total number of bases reported is the product of the number of PF clusters and the number of reporting cycles:\n$$\nB_{\\text{total}} \\;=\\; N_{\\text{PF}} \\times C_{\\text{reporting}} \\;=\\; \\left(3.28 \\times 10^{8}\\right)\\times 300 \\;=\\; 9.84 \\times 10^{10} \\;\\text{bases}.\n$$\n\nConvert this to gigabases using $1$ gigabase $=$ $10^{9}$ bases:\n$$\nY_{\\text{Gb}} \\;=\\; \\frac{9.84 \\times 10^{10}}{10^{9}} \\;=\\; 98.4 \\;\\text{gigabases}.\n$$\n\nTo verify consistency with the instrument’s specification, compare $98.4$ gigabases to the nominal $100$ gigabases. The fractional deviation is\n$$\n\\frac{98.4 - 100}{100} \\;=\\; -0.016 \\;=\\; -1.6 \\times 10^{-2},\n$$\nwhich corresponds to a deviation of magnitude $0.016$, i.e., $1.6 \\times 10^{-2}$ in fractional terms, which lies within $\\pm 0.10$ (the $\\pm 10\\%$ tolerance). Therefore, the expected yield is consistent with the instrument’s listed specification.\n\nFinally, round the numerical yield to four significant figures. The value $98.4$ gigabases has three significant figures; to report four significant figures, write $98.40$.\n\nThus, the expected yield, rounded to four significant figures, is $98.40$ gigabases.",
            "answer": "$$\\boxed{98.40}$$"
        },
        {
            "introduction": "While average sequencing depth is a useful metric, the random nature of sequencing means that coverage is not uniform across a genome. This problem  challenges you to derive a classic model for coverage distribution, which explains why some genomic bases may have zero coverage even in a deeply sequenced experiment. Understanding this statistical principle is crucial for assessing the completeness of a dataset and estimating the probability of missing a variant in a diagnostic assay.",
            "id": "5139940",
            "problem": "A laboratory specializing in molecular and immunodiagnostics deploys Next-Generation Sequencing (NGS) to interrogate a uniform genomic region of length $G$ bases in a targeted immune gene panel. A total of $N$ independent reads of fixed length $L$ are generated, and the read start positions are assumed to be uniformly distributed across the $G$-base region, with independence between reads and negligible boundary effects (that is, $G \\gg L$ so end effects can be ignored). Define the nominal average coverage as $c = \\frac{N L}{G}$, which represents the expected number of read bases landing on any given genomic base under uniform random sampling.\n\nStarting only from these assumptions, the definition of $c$, and basic probabilistic limits, derive a closed-form analytic expression for the probability that a specific base in this uniform region receives zero coverage. Express your final answer as a simplified function of $c$. No numerical substitution is required; present the final expression symbolically. The answer has no physical units and should be given in its exact form without rounding.",
            "solution": "Let us consider a single, specific base at an arbitrary position within the genomic region of length $G$. Our goal is to determine the probability that this base is not covered by any of the $N$ reads.\n\nFirst, we calculate the probability that a single read covers this specific base. A read has a length of $L$ bases. For our specific base to be covered by this read, the read's starting position must fall within a particular window. If the target base is at position $x$, a read starting at position $s$ will cover $x$ if and only if $s \\le x < s+L$, or equivalently, $x-L < s \\le x$. In a discrete base-counting framework, this corresponds to a window of $L$ possible starting positions.\n\nThe starting position of any given read is assumed to be chosen uniformly at random from the $G$ possible positions in the entire genomic region. The assumption that $G \\gg L$ allows us to neglect boundary effects, meaning we can assume that for any target base, there is a full window of $L$ starting positions that would result in its coverage, without worrying about reads \"falling off\" the end of the region.\n\nTherefore, the probability, $p$, that a single randomly placed read covers our specific base is the ratio of the number of favorable start positions to the total number of possible start positions:\n$$p = \\frac{L}{G}$$\n\nConsequently, the probability that a single read *does not* cover our specific base is:\n$$1 - p = 1 - \\frac{L}{G}$$\n\nThe problem states that there are $N$ independent reads. The event of zero coverage at our specific base means that the first read does not cover it, AND the second read does not cover it, ..., AND the $N$-th read does not cover it. Due to the independence of the reads, the probability of this compound event is the product of the individual probabilities.\n\nLet $P_0$ be the probability of zero coverage. We have:\n$$P_0 = \\left(1 - \\frac{L}{G}\\right) \\times \\left(1 - \\frac{L}{G}\\right) \\times \\dots \\times \\left(1 - \\frac{L}{G}\\right) \\quad (N \\text{ times})$$\n$$P_0 = \\left(1 - \\frac{L}{G}\\right)^{N}$$\n\nThe problem requires the final expression to be a function of the nominal average coverage, $c$, which is defined as $c = \\frac{NL}{G}$. We can rearrange this definition to express the ratio $\\frac{L}{G}$ in terms of $c$ and $N$:\n$$\\frac{L}{G} = \\frac{c}{N}$$\n\nSubstituting this into our expression for $P_0$:\n$$P_0 = \\left(1 - \\frac{c}{N}\\right)^{N}$$\n\nThis expression gives the exact probability for a finite number of reads, $N$. However, the context of NGS implies a scenario where $N$ is very large, while the ratio $\\frac{L}{G}$ is very small. This is a classic setup for the Poisson approximation to the binomial distribution. The problem's reference to \"basic probabilistic limits\" directs us to evaluate the behavior of this expression as $N$ becomes large. We take the limit of $P_0$ as $N \\to \\infty$, while keeping the average coverage $c$ constant.\n\n$$P_0(c) = \\lim_{N\\to\\infty} \\left(1 - \\frac{c}{N}\\right)^{N}$$\n\nThis is a standard limit definition for the exponential function. Recalling the fundamental limit $\\lim_{n\\to\\infty} \\left(1 + \\frac{x}{n}\\right)^{n} = \\exp(x)$, we can identify $x = -c$ and $n = N$.\n\nApplying this limit, we obtain the closed-form expression for the probability of zero coverage:\n$$P_0(c) = \\exp(-c)$$\n\nThis result indicates that the number of reads covering a specific site follows a Poisson distribution with a mean of $c$. The probability of observing zero events in a Poisson distribution with mean $\\lambda$ is $e^{-\\lambda}$. In our case, the mean is the average coverage $c$, so the probability of zero coverage is $\\exp(-c)$.",
            "answer": "$$\\boxed{\\exp(-c)}$$"
        },
        {
            "introduction": "Multiplexing, or pooling multiple samples in one run, is standard practice in NGS, but it introduces the risk of \"index hopping,\" where reads are misattributed to the wrong sample. In this practice , you will model the impact of index hopping and quantify the resulting sample cross-contamination for both single and unique dual indexing strategies. This analysis is critically important in clinical diagnostics, where even low levels of contamination can lead to false-positive results.",
            "id": "5139951",
            "problem": "A multiplexed Next-Generation Sequencing (NGS) run pools $N$ equally sized samples, each tagged by index sequences to enable demultiplexing. Consider two demultiplexing strategies:\n- Single indexing using one index (e.g., the Illumina i7 index).\n- Unique dual indexing (UDI) using two independent indexes (e.g., both i7 and i5), with demultiplexing requiring exact pair matches.\n\nIndex hopping is defined as follows: for each index present on a read, with probability $h$ the index is replaced by a randomly chosen index from the other $N-1$ index sequences present in the pool (that is, the replacement never equals the original index), and with probability $1-h$ it remains unchanged. For dual indexing, the two indexes hop independently according to the same rule. Demultiplexing assigns reads to samples by exact index match for single indexing, and by exact pair match for UDI; any read whose observed index (single indexing) or observed index pair (UDI) does not match any sample’s assigned tag(s) is discarded and does not contribute to contamination.\n\nDefine the contamination fraction for a given sample as the expected fraction of reads assigned to that sample that originated from other samples in the pool. Using only the axioms of probability, the law of total probability, and independence of index hopping events, derive closed-form expressions for the contamination fraction under single indexing and under UDI, as functions of the hopping rate $h$ and pool size $N$. Assume all samples contribute equally to the pool.\n\nExpress the contamination fractions as decimals or fractions. Provide your final answers in terms of $h$ and $N$ as a single row matrix $\\begin{pmatrix}C_{\\text{single}} & C_{\\text{dual}}\\end{pmatrix}$.",
            "solution": "Let $N$ be the number of samples in the pool. Let $h$ be the probability that a single index hops. All samples are assumed to contribute equally to the initial pool of sequencing reads.\n\nThe contamination fraction for a given sample, let us say sample $1$, is defined as the expected fraction of reads assigned to that sample that originated from other samples. Let $R_i$ be the event that a read originates from sample $i$, and let $A_j$ be the event that a read is assigned to sample $j$ after demultiplexing. The contamination fraction for sample $1$, denoted $C$, can be expressed as the ratio of the expected number of contaminating reads assigned to sample $1$ to the total expected number of reads assigned to sample $1$.\n\n$$C = \\frac{\\sum_{i=2}^{N} E[\\text{reads from } i \\text{ assigned to } 1]}{E[\\text{reads from } 1 \\text{ assigned to } 1] + \\sum_{i=2}^{N} E[\\text{reads from } i \\text{ assigned to } 1]}$$\n\nDue to the assumption of equally sized samples, all samples contribute an equal number of reads. Therefore, the expected numbers are directly proportional to the conditional probabilities of assignment given the true origin. Let $P(A_j | R_i)$ be the probability that a read from sample $i$ is assigned to sample $j$. The contamination fraction is then:\n\n$$C = \\frac{\\sum_{i=2}^{N} P(A_1 | R_i)}{\\sum_{i=1}^{N} P(A_1 | R_i)} = \\frac{\\sum_{i=2}^{N} P(A_1 | R_i)}{P(A_1 | R_1) + \\sum_{i=2}^{N} P(A_1 | R_i)}$$\n\nBy symmetry, the probability of a read from any contaminating sample $i \\neq 1$ being mis-assigned to sample $1$ is the same. Let this probability be $P_{\\text{contam}} = P(A_1 | R_i)$ for any $i \\neq 1$. Let the probability of a read from sample $1$ being correctly assigned to sample $1$ be $P_{\\text{correct}} = P(A_1 | R_1)$. The expression simplifies to:\n\n$$C = \\frac{(N-1) P_{\\text{contam}}}{P_{\\text{correct}} + (N-1) P_{\\text{contam}}}$$\n\nWe will now derive expressions for $P_{\\text{correct}}$ and $P_{\\text{contam}}$ for both single and unique dual indexing.\n\n**Single Indexing ($C_{\\text{single}}$)**\n\nIn this case, a read has one index. Demultiplexing assigns a read to sample $1$ if its observed index matches the index originally assigned to sample $1$.\n\n1.  **$P_{\\text{correct, single}}$**: A read originates from sample $1$. To be correctly assigned, its index must not hop. The probability of an index not hopping is given as $1-h$.\n    $$P_{\\text{correct, single}} = 1-h$$\n\n2.  **$P_{\\text{contam, single}}$**: A read originates from another sample, $i \\neq 1$. To be mis-assigned to sample $1$, its index must change to that of sample $1$. This requires two events:\n    a) The index must hop. The probability of this is $h$.\n    b) The hopped index must be replaced by the specific index of sample $1$. The problem states the replacement is a random choice from the other $N-1$ indexes in the pool. The probability of choosing the index of sample $1$ is therefore $\\frac{1}{N-1}$.\n    The combined probability is the product of these independent steps:\n    $$P_{\\text{contam, single}} = h \\times \\frac{1}{N-1} = \\frac{h}{N-1}$$\n\nNow we substitute these into the general formula for the contamination fraction:\n\n$$C_{\\text{single}} = \\frac{(N-1) P_{\\text{contam, single}}}{P_{\\text{correct, single}} + (N-1) P_{\\text{contam, single}}} = \\frac{(N-1) \\left(\\frac{h}{N-1}\\right)}{(1-h) + (N-1) \\left(\\frac{h}{N-1}\\right)} = \\frac{h}{1-h+h} = h$$\n\nThus, the contamination fraction for single indexing is simply the index hopping rate $h$.\n\n**Unique Dual Indexing ($C_{\\text{dual}}$)**\n\nIn this case, a read has two independent indexes. Demultiplexing requires an exact match for the pair of indexes assigned to a sample. The two indexes hop independently, each with probability $h$.\n\n1.  **$P_{\\text{correct, dual}}$**: A read originates from sample $1$. To be correctly assigned, its observed index pair must match the original index pair of sample $1$. This requires that *neither* of the two indexes hops. Since the hopping events are independent, we multiply their probabilities.\n    $$P_{\\text{correct, dual}} = (1-h)(1-h) = (1-h)^2$$\n\n2.  **$P_{\\text{contam, dual}}$**: A read originates from another sample, $i \\neq 1$. To be mis-assigned to sample $1$, its observed index pair must exactly match the index pair of sample $1$. This requires that *both* of its indexes hop to the specific corresponding indexes of sample $1$.\n    a) The first index must hop to sample $1$'s first index. The probability for this is $h \\times \\frac{1}{N-1}$.\n    b) The second index must hop to sample $1$'s second index. The probability for this is also $h \\times \\frac{1}{N-1}$.\n    Since the two hops are independent events, the total probability is the product:\n    $$P_{\\text{contam, dual}} = \\left(\\frac{h}{N-1}\\right) \\left(\\frac{h}{N-1}\\right) = \\frac{h^2}{(N-1)^2}$$\n\nNow we substitute these into the general formula for the contamination fraction:\n\n$$C_{\\text{dual}} = \\frac{(N-1) P_{\\text{contam, dual}}}{P_{\\text{correct, dual}} + (N-1) P_{\\text{contam, dual}}} = \\frac{(N-1) \\frac{h^2}{(N-1)^2}}{(1-h)^2 + (N-1) \\frac{h^2}{(N-1)^2}}$$\n$$C_{\\text{dual}} = \\frac{\\frac{h^2}{N-1}}{(1-h)^2 + \\frac{h^2}{N-1}}$$\n\nTo simplify, we multiply the numerator and denominator by $N-1$:\n\n$$C_{\\text{dual}} = \\frac{h^2}{(N-1)(1-h)^2 + h^2}$$\n\nThe final expressions for the contamination fractions are $C_{\\text{single}} = h$ and $C_{\\text{dual}} = \\frac{h^2}{(N-1)(1-h)^2 + h^2}$.",
            "answer": "$$\\boxed{\\begin{pmatrix}h & \\frac{h^2}{(N-1)(1-h)^2 + h^2}\\end{pmatrix}}$$"
        }
    ]
}