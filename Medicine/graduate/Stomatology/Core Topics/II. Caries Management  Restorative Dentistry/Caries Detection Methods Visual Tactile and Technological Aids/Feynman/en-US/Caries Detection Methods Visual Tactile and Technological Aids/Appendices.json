{
    "hands_on_practices": [
        {
            "introduction": "Before a new diagnostic technology can be adopted, it must be rigorously evaluated. This practice delves into the crucial planning phase of a diagnostic accuracy study, focusing on how to ensure the study has enough statistical power to detect a meaningful improvement over existing methods . By deriving the formula for statistical power from first principles, you will gain a deep understanding of the interplay between sample size, effect size, and the probabilities of Type I ($ \\alpha $) and Type II ($ \\beta $) errors in a clinical research context.",
            "id": "4698147",
            "problem": "An investigator designs an accuracy study in stomatology to assess three modalities for detecting early enamel caries on occlusal surfaces: visual inspection, tactile probing with a dental explorer, and the technological aid Optical Coherence Tomography (OCT). Micro-Computed Tomography (micro-CT) is used as the reference standard. Each tooth surface is verified by micro-CT, and then classified as carious or sound. For sensitivity analysis, a stratified sampling plan ensures that exactly $n_{D} = 120$ surfaces with micro-CT–verified early enamel caries are included. Assume independence across surfaces and absence of verification bias.\n\nLet sensitivity be defined as $S = \\Pr(T^{+} \\mid D^{+})$, where $T^{+}$ denotes a positive test by OCT and $D^{+}$ denotes disease presence by micro-CT. The estimator $\\hat{S}$ is the sample proportion of OCT positives among the $n_{D}$ diseased surfaces. The investigator plans a one-sided hypothesis test of sensitivity, with null $H_{0}: S = S_{0}$ and alternative $H_{1}: S = S_{1} > S_{0}$. The design targets a superiority margin consistent with clinically meaningful improvement over visual-tactile methods, setting $S_{0} = 0.75$ and $S_{1} = 0.85$. The test uses significance level $\\alpha = 0.05$ and the asymptotic normal approximation for the binomial proportion under large $n_{D}$, with the usual standardization based on the null variance.\n\nStarting from first principles and core definitions (Bernoulli sampling for a proportion, the Central Limit Theorem for the binomial, and quantiles of the standard normal distribution), derive the analytic expression for the asymptotic power of this test under $S = S_{1}$, and then compute its numerical value for $n_{D} = 120$. Round your final numerical answer for the power to four significant figures and express it as a decimal.",
            "solution": "The problem requires the derivation of the asymptotic power of a one-sided hypothesis test for a binomial proportion and its numerical calculation.\n\n### Step 1: Problem Formulation and Model Specification\n\nLet $S$ be the true sensitivity of Optical Coherence Tomography (OCT), defined as the probability of a positive test result ($T^{+}$) given the presence of disease ($D^{+}$), i.e., $S = \\Pr(T^{+} \\mid D^{+})$. We have a sample of $n_{D} = 120$ diseased surfaces. Let $X$ be the number of surfaces in this sample that test positive by OCT. The random variable $X$ follows a binomial distribution, $X \\sim \\text{Bin}(n_{D}, S)$.\n\nThe estimator for the sensitivity is the sample proportion $\\hat{S} = \\frac{X}{n_{D}}$. According to the Central Limit Theorem, for a large sample size $n_{D}$, the sampling distribution of $\\hat{S}$ can be approximated by a normal distribution with mean $E[\\hat{S}] = S$ and variance $\\text{Var}(\\hat{S}) = \\frac{S(1-S)}{n_{D}}$.\n$$ \\hat{S} \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left(S, \\frac{S(1-S)}{n_{D}}\\right) $$\n\n### Step 2: Hypothesis Test and Rejection Region\n\nThe investigator is performing a one-sided superiority test with the following hypotheses:\n- Null hypothesis $H_{0}: S = S_{0}$, where $S_{0} = 0.75$.\n- Alternative hypothesis $H_{1}: S = S_{1} > S_{0}$, with a specific alternative of interest $S_{1} = 0.85$.\n\nThe test is conducted at a significance level of $\\alpha = 0.05$. Under the null hypothesis, the distribution of the estimator is $\\hat{S} \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left(S_{0}, \\frac{S_{0}(1-S_{0})}{n_{D}}\\right)$.\n\nThe test statistic, standardized under $H_{0}$, is:\n$$ Z = \\frac{\\hat{S} - S_{0}}{\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}}} $$\nUnder $H_{0}$, $Z$ follows a standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$.\n\nFor a one-sided test with significance level $\\alpha$, we reject the null hypothesis $H_{0}$ if the observed value of the test statistic $Z$ is greater than the critical value $z_{1-\\alpha}$, which is the $(1-\\alpha)$-quantile of the standard normal distribution.\nThe rejection rule is: Reject $H_{0}$ if $Z > z_{1-\\alpha}$.\n\nThis rule can be expressed in terms of the estimator $\\hat{S}$. We reject $H_{0}$ if:\n$$ \\frac{\\hat{S} - S_{0}}{\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}}} > z_{1-\\alpha} $$\n$$ \\hat{S} > S_{0} + z_{1-\\alpha}\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}} $$\nLet $C$ be the critical value for $\\hat{S}$:\n$$ C = S_{0} + z_{1-\\alpha}\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}} $$\nThe null hypothesis is rejected if the observed sample proportion $\\hat{S}$ exceeds this value $C$.\n\n### Step 3: Derivation of the Analytic Expression for Power\n\nThe power of the test is the probability of correctly rejecting $H_{0}$ when the alternative hypothesis is true. We are asked to evaluate the power for the specific alternative $S = S_{1}$.\n$$ \\text{Power} = \\Pr(\\text{Reject } H_{0} \\mid S=S_{1}) = \\Pr(\\hat{S} > C \\mid S=S_{1}) $$\nWhen $S=S_{1}$, the estimator $\\hat{S}$ is approximately distributed as $\\hat{S} \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left(S_{1}, \\frac{S_{1}(1-S_{1})}{n_{D}}\\right)$.\n\nTo calculate the power, we standardize the inequality $\\hat{S} > C$ using the distribution parameters under $S=S_{1}$:\n$$ \\text{Power} = \\Pr\\left( \\frac{\\hat{S} - S_{1}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} > \\frac{C - S_{1}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} \\mid S=S_{1} \\right) $$\nLet $Z'$ be a standard normal random variable. The expression becomes:\n$$ \\text{Power} = \\Pr\\left( Z' > \\frac{C - S_{1}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} \\right) $$\nSubstituting the expression for the critical value $C$:\n$$ \\text{Power} = \\Pr\\left( Z' > \\frac{\\left(S_{0} + z_{1-\\alpha}\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}}\\right) - S_{1}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} \\right) $$\nLet $\\Phi(z)$ be the cumulative distribution function (CDF) of the standard normal distribution. Then $\\Pr(Z' > k) = 1 - \\Phi(k)$. Using the property $\\Phi(-k) = 1 - \\Phi(k)$, we can rewrite the power as:\n$$ \\text{Power} = \\Phi\\left( -\\frac{S_{0} - S_{1} + z_{1-\\alpha}\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} \\right) $$\nThis simplifies to the final analytic expression for the asymptotic power:\n$$ \\text{Power} = \\Phi\\left( \\frac{S_{1} - S_{0} - z_{1-\\alpha}\\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}}}{\\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}}} \\right) $$\n\n### Step 4: Numerical Computation\n\nWe are given the following values:\n- $n_{D} = 120$\n- $S_{0} = 0.75$\n- $S_{1} = 0.85$\n- $\\alpha = 0.05$\n\nThe critical value $z_{1-\\alpha}$ for $\\alpha = 0.05$ is $z_{0.95}$. From standard normal tables, $z_{0.95} \\approx 1.64485$.\n\nFirst, we calculate the standard error of $\\hat{S}$ under the null hypothesis ($SE_{0}$):\n$$ SE_{0} = \\sqrt{\\frac{S_{0}(1-S_{0})}{n_{D}}} = \\sqrt{\\frac{0.75(1-0.75)}{120}} = \\sqrt{\\frac{0.1875}{120}} = \\sqrt{0.0015625} = 0.03952847... $$\nNext, we calculate the standard error of $\\hat{S}$ under the specified alternative hypothesis ($SE_{1}$):\n$$ SE_{1} = \\sqrt{\\frac{S_{1}(1-S_{1})}{n_{D}}} = \\sqrt{\\frac{0.85(1-0.85)}{120}} = \\sqrt{\\frac{0.1275}{120}} = \\sqrt{0.0010625} \\approx 0.03259601... $$\nNow, we compute the argument of the $\\Phi$ function in the power expression:\n$$ \\text{Argument} = \\frac{S_{1} - S_{0} - z_{0.95} \\cdot SE_{0}}{SE_{1}} $$\n$$ \\text{Argument} = \\frac{0.85 - 0.75 - (1.64485)(0.03952847)}{0.03259601} $$\n$$ \\text{Argument} = \\frac{0.1 - 0.0650175...}{0.03259601} = \\frac{0.0349824...}{0.03259601} \\approx 1.073215 $$\nFinally, we calculate the power by evaluating the standard normal CDF at this value:\n$$ \\text{Power} = \\Phi(1.073215) \\approx 0.858444 $$\nRounding the result to four significant figures as requested, we obtain $0.8584$.",
            "answer": "$$\\boxed{0.8584}$$"
        },
        {
            "introduction": "Clinical diagnosis is rarely based on a single piece of information; it is a process of synthesizing multiple evidentiary streams. This exercise demonstrates the formal process of this synthesis at the patient level using Bayes’ theorem, a cornerstone of modern medical decision-making . You will practice combining a prior probability of disease with new data from multiple, imperfect diagnostic tests—including both binary and continuous measurements—to calculate a precise posterior probability, which serves as a quantitative measure of diagnostic confidence.",
            "id": "4698129",
            "problem": "A clinician evaluates an occlusal surface in a high-caries-risk adolescent. Three evidentiary streams are obtained for the same surface: a visual assessment at the International Caries Detection and Assessment System (ICDAS) threshold for early non-cavitated lesions is positive, a gentle tactile probe does not detect surface roughness, and a laser fluorescence reading yields a quantitative value of $x = 18$. The patient belongs to a well-characterized cohort with a prior prevalence of early enamel caries on occlusal surfaces of $\\pi = 0.35$. For the visual assessment, assume sensitivity $= 0.78$ and specificity $= 0.85$. For the tactile assessment, assume sensitivity $= 0.65$ and specificity $= 0.90$. For the laser fluorescence measurement, assume the quantitative reading $X$ is modeled as conditionally normal with $X \\mid D=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^{2})$ and $X \\mid D=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$, where $(\\mu_{1}, \\sigma_{1}) = (22, 6)$ and $(\\mu_{0}, \\sigma_{0}) = (8, 4)$. Here, $D=1$ denotes a truly carious (active, early enamel) surface and $D=0$ denotes a sound surface. Assume conditional independence of the three evidentiary streams given $D$.\n\nStarting only from the definitions of sensitivity and specificity, conditional probability, and Bayes’ theorem, derive a principled expression for the posterior probability $\\mathbb{P}(D=1 \\mid \\text{visual positive}, \\text{tactile negative}, X=x)$, then evaluate it at the provided numerical values. Treat the posterior probability as the quantitative measure of diagnostic confidence. Round your final posterior probability to four significant figures and express it as a decimal without a percentage sign.",
            "solution": "The objective is to compute the posterior probability of a surface being carious given evidence from three conditionally independent diagnostic tests. Let $D$ be a binary random variable representing the status of the tooth surface, where $D=1$ indicates caries and $D=0$ indicates a sound surface. The prior probability of caries, or prevalence, is given as $\\mathbb{P}(D=1) = \\pi = 0.35$. Consequently, the prior probability of a sound surface is $\\mathbb{P}(D=0) = 1-\\pi = 1-0.35 = 0.65$.\n\nThe evidence consists of three observations:\n1.  A positive visual assessment. Let $V$ be a binary variable for this test, where $V=1$ for a positive result. The observation is $V=1$.\n2.  A negative tactile assessment. Let $T$ be a binary variable for this test, where $T=0$ for a negative result. The observation is $T=0$.\n3.  A laser fluorescence reading. Let $X$ be a continuous random variable for this measurement. The observation is $X=x=18$.\n\nWe are asked to derive an expression for and calculate the posterior probability $\\mathbb{P}(D=1 \\mid V=1, T=0, X=x)$.\n\nAccording to Bayes' theorem, the posterior probability is given by:\n$$ \\mathbb{P}(D=1 \\mid V=1, T=0, X=x) = \\frac{\\mathbb{P}(V=1, T=0, X=x \\mid D=1) \\mathbb{P}(D=1)}{\\mathbb{P}(V=1, T=0, X=x)} $$\nThe denominator is the marginal probability of the evidence, which is computed using the law of total probability:\n$$ \\mathbb{P}(V=1, T=0, X=x) = \\sum_{d \\in \\{0,1\\}} \\mathbb{P}(V=1, T=0, X=x \\mid D=d) \\mathbb{P}(D=d) $$\nThe problem states that the three tests are conditionally independent given the disease status $D$. This allows us to express the joint likelihood as the product of the individual likelihoods:\n$$ \\mathbb{P}(V=1, T=0, X=x \\mid D=d) = \\mathbb{P}(V=1 \\mid D=d) \\cdot \\mathbb{P}(T=0 \\mid D=d) \\cdot f_{X}(x \\mid D=d) $$\nwhere $f_{X}(x \\mid D=d)$ is the conditional probability density function (PDF) of the continuous variable $X$.\n\nLet us define the components of this expression based on the provided data.\n\nThe likelihood for the carious state ($D=1$):\n- Visual: $\\mathbb{P}(V=1 \\mid D=1)$ is the sensitivity, $\\text{Se}_V = 0.78$.\n- Tactile: $\\mathbb{P}(T=0 \\mid D=1)$ is the false negative rate, $1 - \\text{Se}_T = 1 - 0.65 = 0.35$.\n- Fluorescence: $X \\mid D=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^{2})$ with $(\\mu_1, \\sigma_1) = (22, 6)$. The PDF is $f_{X}(x \\mid D=1) = \\frac{1}{\\sigma_1 \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu_1)^2}{2\\sigma_1^2}\\right)$.\n\nThe likelihood for the sound state ($D=0$):\n- Visual: $\\mathbb{P}(V=1 \\mid D=0)$ is the false positive rate, $1 - \\text{Sp}_V = 1 - 0.85 = 0.15$.\n- Tactile: $\\mathbb{P}(T=0 \\mid D=0)$ is the specificity, $\\text{Sp}_T = 0.90$.\n- Fluorescence: $X \\mid D=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$ with $(\\mu_0, \\sigma_0) = (8, 4)$. The PDF is $f_{X}(x \\mid D=0) = \\frac{1}{\\sigma_0 \\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - \\mu_0)^2}{2\\sigma_0^2}\\right)$.\n\nCombining these, the posterior probability $P_{\\text{post}}$ is:\n$$ P_{\\text{post}} = \\frac{\\left[ \\mathbb{P}(V=1|D=1) \\mathbb{P}(T=0|D=1) f_X(x|D=1) \\right] \\mathbb{P}(D=1)}{\\sum_{d=0}^{1} \\left[ \\mathbb{P}(V=1|D=d) \\mathbb{P}(T=0|D=d) f_X(x|D=d) \\right] \\mathbb{P}(D=d)} $$\nLet $N_1$ be the numerator and $N_0$ be the corresponding term for the $D=0$ state in the denominator's sum.\n$$ N_1 = (\\text{Se}_V)(1-\\text{Se}_T)f_X(x|D=1)\\pi $$\n$$ N_0 = (1-\\text{Sp}_V)(\\text{Sp}_T)f_X(x|D=0)(1-\\pi) $$\nSo, $P_{\\text{post}} = \\frac{N_1}{N_1 + N_0}$.\n\nWe now substitute the numerical values with $x=18$:\nFor $N_1$:\n$$ f_{X}(18 \\mid D=1) = \\frac{1}{6\\sqrt{2\\pi}} \\exp\\left(-\\frac{(18-22)^2}{2 \\cdot 6^2}\\right) = \\frac{1}{6\\sqrt{2\\pi}} \\exp\\left(-\\frac{16}{72}\\right) = \\frac{1}{6\\sqrt{2\\pi}} \\exp\\left(-\\frac{2}{9}\\right) $$\n$$ N_1 = (0.78)(0.35) \\left[ \\frac{1}{6\\sqrt{2\\pi}} \\exp\\left(-\\frac{2}{9}\\right) \\right] (0.35) = (0.78)(0.35)^2 \\frac{1}{6\\sqrt{2\\pi}} \\exp\\left(-\\frac{2}{9}\\right) $$\n\nFor $N_0$:\n$$ f_{X}(18 \\mid D=0) = \\frac{1}{4\\sqrt{2\\pi}} \\exp\\left(-\\frac{(18-8)^2}{2 \\cdot 4^2}\\right) = \\frac{1}{4\\sqrt{2\\pi}} \\exp\\left(-\\frac{100}{32}\\right) = \\frac{1}{4\\sqrt{2\\pi}} \\exp\\left(-\\frac{25}{8}\\right) $$\n$$ N_0 = (0.15)(0.90) \\left[ \\frac{1}{4\\sqrt{2\\pi}} \\exp\\left(-\\frac{25}{8}\\right) \\right] (0.65) = (0.15)(0.90)(0.65) \\frac{1}{4\\sqrt{2\\pi}} \\exp\\left(-\\frac{25}{8}\\right) $$\n\nThe common factor of $1/\\sqrt{2\\pi}$ cancels in the fraction for $P_{\\text{post}}$:\n$$ P_{\\text{post}} = \\frac{(0.78)(0.35)^2 \\frac{1}{6} \\exp(-2/9)}{(0.78)(0.35)^2 \\frac{1}{6} \\exp(-2/9) + (0.15)(0.90)(0.65) \\frac{1}{4} \\exp(-25/8)} $$\nLet's evaluate the coefficients for each term:\n- Coefficient for the $D=1$ term: $C_1 = (0.78)(0.35)^2/6 = (0.78)(0.1225)/6 = 0.09555/6 = 0.015925$.\n- Coefficient for the $D=0$ term: $C_0 = (0.15)(0.90)(0.65)/4 = 0.08775/4 = 0.0219375$.\n\nThe expression becomes:\n$$ P_{\\text{post}} = \\frac{C_1 \\exp(-2/9)}{C_1 \\exp(-2/9) + C_0 \\exp(-25/8)} $$\nNow, we compute the numerical values:\n- $\\exp(-2/9) \\approx 0.8007374$\n- $\\exp(-25/8) = \\exp(-3.125) \\approx 0.0439260$\n- Numerator: $0.015925 \\times 0.8007374 \\approx 0.01275219$\n- Denominator: $(0.015925 \\times 0.8007374) + (0.0219375 \\times 0.0439260) \\approx 0.01275219 + 0.00096363 \\approx 0.01371582$\n\n$$ P_{\\text{post}} \\approx \\frac{0.01275219}{0.01371582} \\approx 0.929741 $$\nRounding the final result to four significant figures gives $0.9297$.",
            "answer": "$$\n\\boxed{0.9297}\n$$"
        },
        {
            "introduction": "A posterior probability is not a final answer, but an input into a decision about clinical action. This advanced practice challenges you to move from diagnostic inference to optimal strategy by implementing a one-step Bayesian decision policy . By building a model that weighs the costs of testing against the expected losses from misdiagnosis ($ L_{FN} $ and $ L_{FP} $), you will explore the principles of expected loss minimization and learn how to formally decide whether to diagnose now or to invest in gathering more information.",
            "id": "4698143",
            "problem": "Design a program that implements a one-step Bayesian decision policy for choosing among caries detection options grounded in decision theory for stomatology. The policy must decide whether to stop now and issue a diagnosis or to perform one additional test among standard clinical modalities, taking into account sensitivity, specificity, and test cost, as well as misclassification losses. The scientific base must be Bayes’ theorem and expected loss minimization from statistical decision theory. The clinical modalities and their characteristics are fixed and given below; the class-conditional test outcomes are modeled as independent Bernoulli observations conditioned on the latent disease state and the chosen modality.\n\nFundamental definitions to use as the base:\n- Let the latent disease indicator be $D \\in \\{0,1\\}$ with prior probability $p=\\mathbb{P}(D=1)$, representing presence of dentinal caries. A diagnostic decision $a \\in \\{0,1\\}$ incurs misclassification loss $L_{FN}$ if $(a=0, D=1)$ and $L_{FP}$ if $(a=1, D=0)$, and zero otherwise.\n- For a binary test outcome $Y \\in \\{0,1\\}$ with $Y=1$ denoting a positive test (indicative of caries) and $Y=0$ denoting a negative test, each test modality $t$ is characterized by sensitivity $\\mathrm{Se}_t=\\mathbb{P}(Y=1\\mid D=1,t)$ and specificity $\\mathrm{Sp}_t=\\mathbb{P}(Y=0\\mid D=0,t)$, and incurs a nonnegative cost $c_t$.\n- Bayes’ theorem governs posterior updates: given $p$ and a test $t$, the posterior after $Y=1$ is $p^{+}_t=\\mathbb{P}(D=1\\mid Y=1,t)$ and after $Y=0$ is $p^{-}_t=\\mathbb{P}(D=1\\mid Y=0,t)$. The predictive probabilities are $\\pi^{+}_t=\\mathbb{P}(Y=1\\mid t)$ and $\\pi^{-}_t=\\mathbb{P}(Y=0\\mid t)$.\n\nDecision options at the current posterior $p$ with remaining budget $B$:\n- Stopping options: choose $a=0$ (no caries) or $a=1$ (caries). The program must compute the immediate expected loss of $a=0$ as $p\\cdot L_{FN}$ and of $a=1$ as $(1-p)\\cdot L_{FP}$, and select the smaller as the optimal stop loss at $p$. Ties must be broken by choosing $a=0$.\n- Testing options: for each modality $t$ with $c_t \\le B$, compute the one-step lookahead Bayes risk as $c_t$ plus the expected misclassification loss if you were to stop immediately after observing the test result. Concretely, for each feasible $t$: compute $\\pi^{+}_t$, $p^{+}_t$ and $\\pi^{-}_t$, $p^{-}_t$ using Bayes’ theorem; for each possible result, compute the minimum of $p^{+}_t\\cdot L_{FN}$ and $(1-p^{+}_t)\\cdot L_{FP}$ (if $Y=1$), and similarly for $p^{-}_t$ (if $Y=0$). Take the expectation over $Y$ and add $c_t$ to obtain the one-step risk of testing with $t$ at $p$. Among all feasible tests, identify the minimal such risk. If the minimal testing risk is strictly less than the optimal stop loss, the policy recommends that test; otherwise, the policy stops with the decision that yields the optimal stop loss. Ties between testing and stopping must be resolved in favor of stopping.\n\nClinical modalities and parameters to use:\n- Visual inspection $(V)$: sensitivity $\\mathrm{Se}_V=0.65$, specificity $\\mathrm{Sp}_V=0.85$, cost $c_V=1.0$.\n- Tactile exploration $(T)$: sensitivity $\\mathrm{Se}_T=0.55$, specificity $\\mathrm{Sp}_T=0.90$, cost $c_T=1.5$.\n- Near-infrared transillumination $(TI)$: sensitivity $\\mathrm{Se}_{TI}=0.80$, specificity $\\mathrm{Sp}_{TI}=0.80$, cost $c_{TI}=3.5$.\n- Fluorescence-based detection $(FL)$: sensitivity $\\mathrm{Se}_{FL}=0.90$, specificity $\\mathrm{Sp}_{FL}=0.75$, cost $c_{FL}=4.0$.\n\nCoding of actions for output:\n- $0$: stop now and diagnose no caries $(a=0)$.\n- $1$: stop now and diagnose caries $(a=1)$.\n- $2$: perform Visual inspection $(V)$.\n- $3$: perform Tactile exploration $(T)$.\n- $4$: perform Near-infrared transillumination $(TI)$.\n- $5$: perform Fluorescence-based detection $(FL)$.\n\nTest suite:\n- Case $1$: prior $p=0.3$, losses $L_{FN}=10$, $L_{FP}=1$, budget $B=10$.\n- Case $2$: prior $p=0.3$, losses $L_{FN}=10$, $L_{FP}=5$, budget $B=10$.\n- Case $3$: prior $p=0.8$, losses $L_{FN}=10$, $L_{FP}=1$, budget $B=10$.\n- Case $4$: prior $p=0.3$, losses $L_{FN}=10$, $L_{FP}=5$, budget $B=0.5$.\n- Case $5$: prior $p=0.5$, losses $L_{FN}=2$, $L_{FP}=2$, budget $B=10$.\n\nTask:\n- Implement the above one-step Bayesian decision policy. For each test case, return a two-element list consisting of the chosen action code and the corresponding minimal expected Bayes risk rounded to six decimal places. Risks are dimensionless loss units.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each element must itself be a two-element list in the form $[a,r]$ where $a$ is the integer action code and $r$ is the float risk rounded to six decimal places. For example, a valid overall output looks like $[[0,1.000000],[2,2.575000]]$.",
            "solution": "The task is to design a one-step Bayesian decision policy for caries detection. This policy decides between stopping to make a diagnosis or performing one additional test to gather more information. The decision is based on minimizing the expected total loss (Bayes risk), which combines test costs and misclassification losses. The intellectual foundation for this problem is statistical decision theory, specifically employing Bayes' theorem.\n\nThe state of knowledge about the patient's latent disease status $D \\in \\{0, 1\\}$ (where $D=1$ indicates caries) is captured by the prior probability $p = \\mathbb{P}(D=1)$. At any point, we can choose an action from a set of available options.\n\nThe available actions are of two types: stopping actions and testing actions.\n\n1.  **Stopping Actions**:\n    We can stop and make a terminal diagnosis, $a \\in \\{0, 1\\}$, where $a=0$ is a diagnosis of 'no caries' and $a=1$ is a diagnosis of 'caries'.\n    The expected loss (or risk) of making a decision $a$ given the current probability $p$ is calculated based on the provided misclassification losses, $L_{FN}$ (false negative) and $L_{FP}$ (false positive).\n\n    -   The risk of deciding 'no caries' ($a=0$) is the probability of the patient having caries ($p$) multiplied by the loss of a false negative:\n        $$R(a=0 \\mid p) = p L_{FN}$$\n    -   The risk of deciding 'caries' ($a=1$) is the probability of the patient not having caries ($1-p$) multiplied by the loss of a false positive:\n        $$R(a=1 \\mid p) = (1-p) L_{FP}$$\n\n    The optimal stopping policy is to choose the action that minimizes this risk. The optimal stopping risk, $R_{stop}(p)$, is therefore:\n    $$R_{stop}(p) = \\min(p L_{FN}, (1-p) L_{FP})$$\n    The problem specifies a tie-breaking rule: if $p L_{FN} = (1-p) L_{FP}$, the decision should be $a=0$. Thus, the optimal stopping action $a_{stop}$ is $0$ if $p L_{FN} \\le (1-p) L_{FP}$, and $1$ otherwise.\n\n2.  **Testing Actions**:\n    We can choose to perform an additional test $t$ from a set of available modalities. Each test $t$ is characterized by its sensitivity $\\mathrm{Se}_t = \\mathbb{P}(Y=1 \\mid D=1, t)$, specificity $\\mathrm{Sp}_t = \\mathbb{P}(Y=0 \\mid D=0, t)$, and cost $c_t$. A test is only feasible if its cost $c_t$ does not exceed the remaining budget $B$.\n\n    The value of a test lies in its ability to update our belief $p$ to a posterior belief, potentially leading to a better terminal decision with a lower expected loss. The one-step lookahead Bayes risk for a test $t$, denoted $R_{test}(t \\mid p)$, is the sum of the immediate test cost $c_t$ and the expected future misclassification loss after observing the test's outcome $Y \\in \\{0, 1\\}$.\n\n    To calculate this, we first need the posterior probabilities of disease, conditioned on the test outcome. Using Bayes' theorem:\n    -   The probability of a positive test outcome ($Y=1$) is given by the law of total probability:\n        $$\\pi^{+}_t = \\mathbb{P}(Y=1 \\mid t) = \\mathbb{P}(Y=1 \\mid D=1, t)p + \\mathbb{P}(Y=1 \\mid D=0, t)(1-p) = \\mathrm{Se}_t p + (1-\\mathrm{Sp}_t)(1-p)$$\n    -   The posterior probability of caries given a positive test is:\n        $$p^{+}_t = \\mathbb{P}(D=1 \\mid Y=1, t) = \\frac{\\mathbb{P}(Y=1 \\mid D=1, t)p}{\\mathbb{P}(Y=1 \\mid t)} = \\frac{\\mathrm{Se}_t p}{\\pi^{+}_t}$$\n    -   Similarly, for a negative test outcome ($Y=0$):\n        $$\\pi^{-}_t = \\mathbb{P}(Y=0 \\mid t) = (1-\\mathrm{Se}_t)p + \\mathrm{Sp}_t(1-p)$$\n        $$p^{-}_t = \\mathbb{P}(D=1 \\mid Y=0, t) = \\frac{(1-\\mathrm{Se}_t)p}{\\pi^{-}_t}$$\n\n    After observing the outcome $Y$, we will make an optimal stopping decision based on the new posterior probability ($p_t^+$ or $p_t^-$). The expected future loss is the expectation of these new optimal stopping risks over the possible test outcomes:\n    $$E[\\text{future loss}] = \\pi^{+}_t R_{stop}(p_t^+) + \\pi^{-}_t R_{stop}(p_t^-)$$\n    Substituting the definition of $R_{stop}$, this becomes:\n    $$E[\\text{future loss}] = \\pi^{+}_t \\min(p_t^+ L_{FN}, (1-p_t^+) L_{FP}) + \\pi^{-}_t \\min(p_t^- L_{FN}, (1-p_t^-) L_{FP})$$\n    A more direct calculation is possible by distributing $\\pi_t^\\pm$ inside the $\\min$ functions and using identities like $\\pi_t^+ p_t^+ = \\mathrm{Se}_t p$:\n    $$E[\\text{future loss}] = \\min(\\mathrm{Se}_t p L_{FN}, (1-\\mathrm{Sp}_t)(1-p)L_{FP}) + \\min((1-\\mathrm{Se}_t)p L_{FN}, \\mathrm{Sp}_t(1-p)L_{FP})$$\n\n    The total risk for testing with modality $t$ is then:\n    $$R_{test}(t \\mid p) = c_t + E[\\text{future loss}]$$\n\n3.  **Final Decision Policy**:\n    The final step is to compare the best available options.\n    -   First, find the minimal risk among all feasible tests: $R_{test, min} = \\min_{t : c_t \\le B} R_{test}(t \\mid p)$. If no test is feasible, this value is taken as infinite.\n    -   Then, compare this minimal testing risk with the optimal stopping risk, $R_{stop}(p)$.\n    -   If $R_{test, min} < R_{stop}(p)$, the optimal action is to perform the test that achieves this minimum risk.\n    -   If $R_{test, min} \\ge R_{stop}(p)$, the optimal action is to stop and make the diagnosis $a_{stop}$ that yields the risk $R_{stop}(p)$. This incorporates the tie-breaking rule that favors stopping.\n\nThe implementation will systematically calculate these two primary risks ($R_{stop}(p)$ and $R_{test, min}$) for each test case and select the action and its corresponding risk according to this decision rule.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a one-step Bayesian decision policy for caries detection.\n    \"\"\"\n\n    # Clinical modalities: Sensitivity, Specificity, Cost, Action Code\n    modalities = [\n        {'name': 'V', 'Se': 0.65, 'Sp': 0.85, 'c': 1.0, 'code': 2},\n        {'name': 'T', 'Se': 0.55, 'Sp': 0.90, 'c': 1.5, 'code': 3},\n        {'name': 'TI', 'Se': 0.80, 'Sp': 0.80, 'c': 3.5, 'code': 4},\n        {'name': 'FL', 'Se': 0.90, 'Sp': 0.75, 'c': 4.0, 'code': 5},\n    ]\n\n    # Test suite parameters: prior probability, losses, budget\n    test_cases = [\n        {'p': 0.3, 'L_FN': 10, 'L_FP': 1, 'B': 10},\n        {'p': 0.3, 'L_FN': 10, 'L_FP': 5, 'B': 10},\n        {'p': 0.8, 'L_FN': 10, 'L_FP': 1, 'B': 10},\n        {'p': 0.3, 'L_FN': 10, 'L_FP': 5, 'B': 0.5},\n        {'p': 0.5, 'L_FN': 2, 'L_FP': 2, 'B': 10},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        p, L_FN, L_FP, B = case['p'], case['L_FN'], case['L_FP'], case['B']\n\n        # Part 1: Calculate the optimal stopping risk and action\n        risk_stop_0 = p * L_FN        # Risk of diagnosing no caries (a=0)\n        risk_stop_1 = (1 - p) * L_FP  # Risk of diagnosing caries (a=1)\n\n        # Apply tie-breaking rule for stopping: choose a=0\n        if risk_stop_0 <= risk_stop_1:\n            optimal_stop_risk = risk_stop_0\n            optimal_stop_action = 0\n        else:\n            optimal_stop_risk = risk_stop_1\n            optimal_stop_action = 1\n\n        # Part 2: Calculate the risk for each feasible test\n        min_test_risk = float('inf')\n        best_test_action = -1\n\n        for mod in modalities:\n            if mod['c'] <= B:\n                Se, Sp, c = mod['Se'], mod['Sp'], mod['c']\n                \n                # Calculate expected future loss using the simplified formula:\n                # E[loss] = min(P(Y=1,D=1)L_FN, P(Y=1,D=0)L_FP) + min(P(Y=0,D=1)L_FN, P(Y=0,D=0)L_FP)\n                # where P(Y,D) = P(Y|D)P(D)\n                \n                # Contribution from a positive test result (Y=1)\n                term_pos = min(p * Se * L_FN, (1 - p) * (1 - Sp) * L_FP)\n                \n                # Contribution from a negative test result (Y=0)\n                term_neg = min(p * (1 - Se) * L_FN, (1 - p) * Sp * L_FP)\n                \n                expected_future_loss = term_pos + term_neg\n                \n                total_test_risk = c + expected_future_loss\n\n                if total_test_risk < min_test_risk:\n                    min_test_risk = total_test_risk\n                    best_test_action = mod['code']\n\n        # Part 3: Make the final decision by comparing stopping vs. testing\n        # The policy recommends a test only if its risk is strictly less than stopping.\n        if min_test_risk < optimal_stop_risk:\n            final_action = best_test_action\n            final_risk = min_test_risk\n        else:\n            final_action = optimal_stop_action\n            final_risk = optimal_stop_risk\n            \n        results.append([final_action, final_risk])\n\n    # Format the final output string exactly as specified\n    output_parts = []\n    for action, risk in results:\n        output_parts.append(f\"[{int(action)},{risk:.6f}]\")\n    print(f\"[{','.join(output_parts)}]\")\n\n\nsolve()\n```"
        }
    ]
}