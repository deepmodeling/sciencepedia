{
    "hands_on_practices": [
        {
            "introduction": "在分析功能性磁共振成像（fMRI）数据之前，我们必须首先以最优化的方式采集它。这项练习将深入探讨血氧水平依赖（BOLD）信号背后的磁共振物理学原理，重点关注如何调整一个关键的采集参数——回波时间（$TE$），以最大化我们对神经活动的敏感度。通过推导最佳$TE$值，本练习揭示了磁共振物理学与功能性数据质量之间的关键联系 。",
            "id": "4445739",
            "problem": "一个神经学研究团队正在设计一种在 $B_0 = 3\\,\\mathrm{T}$ 静态磁场下，使用回波平面成像 (EPI) 的梯度回波功能性磁共振成像 (fMRI) 采集方案。对于皮质灰质，他们预计包含静态去相位的横向弛豫时间 $T_2^*$ 约为 $30\\,\\mathrm{ms}$。血氧水平依赖 (BOLD) 对比度源于脱氧血红蛋白变化引起的局部磁化率的微小变化，这些变化会调节有效横向弛豫率 $R_2^*$，其中 $R_2^* = 1/T_2^*$。假设梯度回波信号幅度随回波时间 $TE$ 呈单指数衰减，其关系式为 $S(TE) = S_0 \\exp(-TE/T_2^*) = S_0 \\exp(-TE\\,R_2^*)$，并且主要图像噪声近似为热噪声且与 $TE$ 无关。请使用第一性原理和针对 $R_2^*$ 中 BOLD 效应引起的变化的小扰动近似，推导出用于检测微小 BOLD 效应时可使对比度噪声比 (CNR) 最大化的回波时间 $TE$。然后在给定 $T_2^* = 30\\,\\mathrm{ms}$ 的条件下计算其数值。最后，结合梯度回波 EPI 的物理机制，简要讨论在 $B_0 = 3\\,\\mathrm{T}$ 磁场下，选择此 $TE$ 在信噪比 (SNR) 和磁化率相关失真方面的权衡。以 $\\mathrm{ms}$ 为单位表示最佳 $TE$，并将您的数值答案四舍五入到三位有效数字。",
            "solution": "该问题要求推导在梯度回波功能性磁共振成像中，对于微小的血氧水平依赖 (BOLD) 效应，能够使对比度噪声比 (CNR) 最大化的最佳回波时间 ($TE$)，然后进行数值计算并讨论相关的权衡。\n\n首先，我们必须规范化 CNR 的定义。CNR 是两种状态（例如，神经激活与静息）之间信号差异的绝对值除以图像噪声的标准差 $\\sigma_{noise}$。\n$$\nCNR = \\frac{|\\Delta S|}{\\sigma_{noise}}\n$$\n设静息状态为基线条件，激活状态为我们关注的条件。BOLD 效应表现为有效横向弛豫率 $R_2^* = 1/T_2^*$ 的变化。具体来说，神经活动导致局部脱氧血红蛋白浓度降低，从而使局部磁场更加均匀。这会增加 $T_2^*$，从而降低 $R_2^*$。\n\n设 $R_{2,rest}^*$ 为静息状态下的弛豫率，$R_{2,act}^*$ 为激活状态下的弛豫率。其变化量为 $\\Delta R_2^* = R_{2,act}^* - R_{2,rest}^*$。根据其生理学基础，$\\Delta R_2^*$ 是一个很小的负值。为简化表示，我们将 $R_{2,rest}^*$ 记为 $R_2^*$。信号幅度作为回波时间 $TE$ 的函数由 $S(TE) = S_0 \\exp(-TE \\cdot R_2^*)$ 给出，其中 $S_0$ 包含了质子密度和 $T_1$ 弛豫效应，在本分析中假定为常数。\n\n静息状态下的信号为：\n$$\nS_{rest}(TE) = S_0 \\exp(-TE \\cdot R_2^*)\n$$\n激活状态下的信号为：\n$$\nS_{act}(TE) = S_0 \\exp(-TE \\cdot R_{2,act}^*) = S_0 \\exp(-TE \\cdot (R_2^* + \\Delta R_2^*))\n$$\n信号变化 $\\Delta S$ 则为：\n$$\n\\Delta S = S_{act} - S_{rest} = S_0 \\left[ \\exp(-TE \\cdot (R_2^* + \\Delta R_2^*)) - \\exp(-TE \\cdot R_2^*) \\right]\n$$\n提出公因式 $\\exp(-TE \\cdot R_2^*)$：\n$$\n\\Delta S = S_0 \\exp(-TE \\cdot R_2^*) \\left[ \\exp(-TE \\cdot \\Delta R_2^*) - 1 \\right]\n$$\n题目指定对 BOLD 引起的变化使用小扰动近似。这意味着 BOLD 效应很小，所以 $|\\Delta R_2^*|$ 很小，因此指数 $|-TE \\cdot \\Delta R_2^*|$ 也很小。因此，对于小的 $x$，我们可以使用指数函数的一阶泰勒展开式 $\\exp(x) \\approx 1 + x$。\n令 $x = -TE \\cdot \\Delta R_2^*$，我们有：\n$$\n\\exp(-TE \\cdot \\Delta R_2^*) \\approx 1 - TE \\cdot \\Delta R_2^*\n$$\n将此近似代入 $\\Delta S$ 的表达式中：\n$$\n\\Delta S \\approx S_0 \\exp(-TE \\cdot R_2^*) \\left[ (1 - TE \\cdot \\Delta R_2^*) - 1 \\right] = -S_0 \\cdot \\Delta R_2^* \\cdot TE \\cdot \\exp(-TE \\cdot R_2^*)\n$$\n由于 $\\Delta R_2^*$ 是负数，$\\Delta S$ 是正数，这与 BOLD 信号增加的预期相符。信号变化的绝对值为：\n$$\n|\\Delta S| \\approx S_0 |\\Delta R_2^*| \\cdot TE \\cdot \\exp(-TE \\cdot R_2^*)\n$$\n题目指出，主要图像噪声是热噪声，且与 $TE$ 无关。因此，$\\sigma_{noise}$ 是一个常数。就 $TE$ 而言，最大化 $CNR = |\\Delta S|/\\sigma_{noise}$ 等价于最大化 $|\\Delta S|$。$S_0$ 和 $|\\Delta R_2^*|$ 是关于 $TE$ 的常数，所以我们需要找到函数 $f(TE) = TE \\cdot \\exp(-TE \\cdot R_2^*)$ 的最大值。\n\n为了找到最大值，我们计算 $f(TE)$ 对 $TE$ 的一阶导数，并将其设为零。使用微分的乘法法则 $(uv)' = u'v + uv'$，其中 $u=TE$，$v=\\exp(-TE \\cdot R_2^*)$：\n$$\n\\frac{df}{d(TE)} = \\frac{d}{d(TE)} \\left( TE \\cdot \\exp(-TE \\cdot R_2^*) \\right)\n$$\n$$\n\\frac{df}{d(TE)} = (1) \\cdot \\exp(-TE \\cdot R_2^*) + TE \\cdot (-R_2^* \\cdot \\exp(-TE \\cdot R_2^*))\n$$\n$$\n\\frac{df}{d(TE)} = \\exp(-TE \\cdot R_2^*) (1 - TE \\cdot R_2^*)\n$$\n将导数设为零以找到临界点：\n$$\n\\exp(-TE \\cdot R_2^*) (1 - TE \\cdot R_2^*) = 0\n$$\n由于对于任何有限的 $TE$，$\\exp(-TE \\cdot R_2^*) > 0$，因此该表达式仅在以下情况下为零：\n$$\n1 - TE \\cdot R_2^* = 0\n$$\n解出 $TE$，我们得到最佳回波时间 $TE_{opt}$：\n$$\nTE_{opt} = \\frac{1}{R_2^*}\n$$\n根据定义 $R_2^* = 1/T_2^*$，我们可以将其代入我们的结果：\n$$\nTE_{opt} = \\frac{1}{1/T_2^*} = T_2^*\n$$\n因此，使 BOLD CNR 最大化的回波时间等于组织的基线 $T_2^*$。为确认这是一个最大值，我们可以检查二阶导数，但这是一个众所周知的结论，即此处为最大值。\n\n接下来，我们计算其数值。题目给出 $T_2^* = 30\\,\\mathrm{ms}$。因此，最佳回波时间是：\n$$\nTE_{opt} = 30\\,\\mathrm{ms}\n$$\n四舍五入到三位有效数字得到 $30.0\\,\\mathrm{ms}$。\n\n最后，我们讨论选择 $TE = T_2^*$ 的权衡。\n\n1.  **信噪比 (SNR):** 对于给定的体素信号 $S$，信噪比为 $SNR = S/\\sigma_{noise}$。由于噪声 $\\sigma_{noise}$ 假定为常数，SNR 与信号本身成正比：$S(TE) = S_0 \\exp(-TE/T_2^*)$。这是一个关于 $TE$ 的单调递减函数。因此，为了最大化 SNR，应选择尽可能短的 $TE$。通过选择 $TE = T_2^* = 30\\,\\mathrm{ms}$，信号已衰减至 $S(T_2^*) = S_0 \\exp(-1) \\approx 0.37 S_0$。与使用非常短的 $TE$ 所能达到的信号相比，这是一个显著的信号降低。这说明了在最大化功能激活的 CNR（对变化的敏感性）与最大化图像本身的原始 SNR 之间存在根本性的权衡。\n\n2.  **磁化率相关失真：** 问题指定了在场强为 $B_0 = 3\\,\\mathrm{T}$ 时使用梯度回波回波平面成像 (GE-EPI)。GE-EPI 对磁场不均匀性高度敏感，这种不均匀性源于磁化率的变化，尤其是在空气-组织界面处（例如，鼻窦和耳道附近）。这些磁场不均匀性会导致离共振效应，从而产生两种主要伪影：信号脱落（由体素内去相位引起）和几何失真（相位编码方向上的像素位移）。这些效应的程度与回波时间 $TE$ 成正比，因为更长的 $TE$ 允许离共振相位累积更多的时间。这些效应也随主磁场强度 $B_0$ 增强，使其在 $3\\,\\mathrm{T}$ 场强下成为一个突出问题。选择 $30\\,\\mathrm{ms}$ 的 $TE$ 是一个中等长度的回波时间，虽然对于灰质中的 BOLD 对比度是最佳的，但将不可避免地导致大脑区域（如眶额皮质和内侧颞叶）出现显著的信号损失和失真。较短的 $TE$ 会减轻这些伪影，但代价是牺牲最佳的 BOLD 敏感性 (CNR)。因此，这一选择代表了功能敏感性与图像保真度之间的折衷。",
            "answer": "$$\\boxed{30.0}$$"
        },
        {
            "introduction": "采集到数据后，下一步是为我们期望看到的信号建立模型。这项练习将指导您从基本原理出发，使用标准的线性时不变（LTI）系统方法，构建一个BOLD信号的计算模型。您将通过实现刺激函数与经典血液动力学响应函数（HRF）的卷积，掌握在通用线性模型（GLM）中构建回归量（regressor）的核心技能 。",
            "id": "4445761",
            "problem": "本任务要求实现一个数值模型，用于预测功能性磁共振成像 (fMRI) 中由短暂外部刺激产生的血氧水平依赖 (BOLD) 响应。该模型基于线性时不变系统和规范血流动力学响应函数 (HRF)。请从以下基本定义和事实出发：\n\n1. 连续时间线性卷积：对于一个输入 (刺激) $x(t)$ 和一个脉冲响应 $h(t)$，输出 $y(t)$ 定义为\n$$\ny(t) = \\int_{-\\infty}^{+\\infty} x(\\tau)\\,h(t-\\tau)\\,d\\tau.\n$$\n\n2. 伽马函数 $\\Gamma(\\cdot)$ 和伽马概率密度函数：对于形状参数 $a>0$ 和尺度参数 $b>0$，\n$$\ng(t;a,b) = \\begin{cases}\n\\dfrac{t^{a-1} e^{-t/b}}{b^a\\,\\Gamma(a)},  t \\ge 0,\\\\\n0,  t < 0.\n\\end{cases}\n$$\n\n3. 规范双伽马血流动力学响应函数 (HRF) 是两个归一化伽马密度之差，并具有固定的振幅比。给定参数 $a_1$、$b_1$、$a_2$、$b_2$ 和一个比率 $c>0$，定义\n$$\nh(t) = g(t; a_1, b_1) \\;-\\; \\frac{1}{c}\\, g(t; a_2, b_2).\n$$\n这个 $h(t)$ 是因果的 (即当 $t<0$ 时为零)。对于规范选择，使用 $a_1=6$，$b_1=1$，$a_2=16$，$b_2=1$，以及 $c=6$。\n\n4. 通过黎曼和进行离散时间近似：采用一个采样间隔 $\\Delta t>0$ 和一个有限的仿真时域 $T_{\\max} > 0$。令 $t_n = n\\,\\Delta t$，对于整数 $n=0,1,\\dots,N-1$，其中 $N = \\lfloor T_{\\max}/\\Delta t \\rfloor + 1$。通过离散和来近似连续时间卷积\n$$\ny[n] \\approx \\sum_{k=0}^{n} s[k]\\, h[n-k]\\, \\Delta t,\n$$\n其中 $h[n] := h(t_n)$ 且 $s[k]$ 是刺激的离散表示。\n\n5. 刺激模型：一个从 $t=0$ 开始、持续时间为 $W$ 秒、单位振幅的短暂事件被建模为\n$$\nx(t) = \\begin{cases}\n1,  0 \\le t  W,\\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\n为最小化离散化偏差，通过每箱平均值将 $x(t)$ 表示为离散时间形式\n$$\ns[k] := \\frac{1}{\\Delta t} \\int_{k\\Delta t}^{(k+1)\\Delta t} x(\\tau)\\,d\\tau = \\frac{\\text{length}\\left([k\\Delta t,(k+1)\\Delta t)\\cap[0,W)\\right]}{\\Delta t}.\n$$\n注意 $0 \\le s[k] \\le 1$ 且 $\\sum_k s[k]\\,\\Delta t = W$。\n\n任务：\n\nA. 根据上述定义，推导出使用黎曼和近似从 $s[k]$ 和 $h[n]$ 预测 BOLD 时间进程 $y[n]$ 的离散时间卷积公式。您的实现必须使用上面定义的每箱平均值 $s[k]$。\n\nB. 实现一个程序，使用规范双伽马 HRF 参数 $a_1=6$, $b_1=1$, $a_2=16$, $b_2=1$, $c=6$ 来计算指定 $\\Delta t$、$T_{\\max}$ 和 $W$ 下的 $y[n]$。\n\nC. 对每个测试用例，报告：\n- 在指定查询时间点 $y(t)$ 的值，通过规则 $n=\\operatorname{round}(t/\\Delta t)$ 索引最近的离散样本获得。\n- 峰值时间 $t_{\\text{peak}}$ (秒) 和峰值振幅 $y_{\\text{peak}}$，其中峰值定义为在仿真窗口内 $y[n]$ 的最大值。\n- 在仿真窗口内 $y(t)$ 下的数值面积，计算为 $\\sum_{n=0}^{N-1} y[n]\\,\\Delta t$。该面积的单位是秒。\n\n单位：\n- 所有时间必须以秒为单位表示。\n- 不使用角度。\n- 将所有要求的量报告为实数 (浮点数)。不要使用百分比。\n\n测试套件：\n所有案例均使用 $W=0.1$ 秒和上述规范 HRF 参数。对于每个案例，程序必须按顺序计算并返回以下内容：一个在指定查询时间点的样本列表 $[y(t_1), y(t_2), \\dots]$，其后是 $t_{\\text{peak}}$，然后是 $y_{\\text{peak}}$，最后是面积。测试用例如下：\n\n- 案例 1 (基线分辨率)：$\\Delta t = 0.1$, $T_{\\max}=40.0$, 查询时间 $[0.0, 6.0, 12.0, 20.0]$。\n- 案例 2 (高分辨率)：$\\Delta t = 0.01$, $T_{\\max}=40.0$, 查询时间 $[6.0]$。\n- 案例 3 (粗分辨率，子箱事件)：$\\Delta t = 0.4$, $T_{\\max}=40.0$, 查询时间 $[6.0]$。\n- 案例 4 (短窗口截断)：$\\Delta t = 0.1$, $T_{\\max}=10.0$, 查询时间 $[0.0, 6.0, 9.9]$。\n\n最终输出格式：\n您的程序应生成一行输出，包含所有四个案例的结果，形式为一个逗号分隔的列表，其中包含四个子列表。每个子列表包含：在指定查询时间点的采样值列表，其后是 $t_{\\text{peak}}$、$y_{\\text{peak}}$ 和面积。整个输出必须用方括号括起来。例如，一个使用示意性占位符的输出看起来像这样：\n[[[y_1(t_1),y_1(t_2),...],t1_peak,y1_peak,area1],[[y_2(t_1),...],t2_peak,y2_peak,area2],[[...],t3_peak,y3_peak,area3],[[...],t4_peak,y4_peak,area4]].",
            "solution": "该问题要求基于线性时不变 (LTI) 系统方法，实现一个用于fMRI中血氧水平依赖 (BOLD) 响应的数值模型。该模型的核心是将一个刺激信号与一个规范血流动力学响应函数 (HRF) 进行卷积。通过对连续时间模型进行离散化，可以系统地推导出解决方案。\n\n### 步骤1：连续时间模型构建\n\n输入刺激 $x(t)$ 与产生的 BOLD 响应 $y(t)$ 之间的关系由卷积积分描述，这是 LTI 系统理论的基石：\n$$\ny(t) = (x * h)(t) = \\int_{-\\infty}^{+\\infty} x(\\tau)\\,h(t-\\tau)\\,d\\tau\n$$\n在这里，$h(t)$ 是系统的脉冲响应，在此背景下称为血流动力学响应函数 (HRF)。\n\n刺激 $x(t)$ 是一个短暂事件，建模为持续时间为 $W$、单位振幅的盒状函数：\n$$\nx(t) = \\begin{cases}\n1,  0 \\le t  W \\\\\n0,  \\text{otherwise}\n\\end{cases}\n$$\n\nHRF $h(t)$ 被定义为两个伽马概率密度函数之差，这是一个标准的生物物理模型。伽马概率密度函数 (PDF) 由下式给出：\n$$\ng(t;a,b) = \\frac{t^{a-1} e^{-t/b}}{b^a\\,\\Gamma(a)} \\quad \\text{for } t \\ge 0\n$$\n其中 $a$ 是形状参数，$b$ 是尺度参数，$\\Gamma(\\cdot)$ 是欧拉伽马函数。由此产生的规范双伽马 HRF 为：\n$$\nh(t) = g(t; a_1, b_1) - \\frac{1}{c}\\, g(t; a_2, b_2)\n$$\n问题指定了规范参数：形状参数 $a_1=6$ 和 $a_2=16$，尺度参数 $b_1=1$ 和 $b_2=1$，以及振幅比 $c=6$。由于两个形状参数都大于1，因此 $h(0) = 0$。HRF是因果的，即对于 $t0$，$h(t)=0$。\n\n### 步骤2：模型离散化\n\n为了进行数值计算，必须将连续模型离散化。我们引入一个均匀采样间隔 $\\Delta t > 0$ 和一个有限的仿真时域 $T_{\\max} > 0$。\n\n时间轴被离散化为一系列点 $t_n = n\\,\\Delta t$，对于 $n = 0, 1, 2, \\dots, N-1$，其中总点数为 $N = \\lfloor T_{\\max}/\\Delta t \\rfloor + 1$。\n\n在这些时间点上对连续HRF $h(t)$ 进行采样，以获得离散脉冲响应序列：\n$$\nh[n] = h(t_n) = h(n\\,\\Delta t)\n$$\n\n连续刺激 $x(t)$ 使用分箱平均法进行离散化，以确保准确性，特别是当刺激持续时间 $W$ 与 $\\Delta t$ 相当或更小时。该方法保留了刺激的总“能量”，其中 $\\sum_k s[k] \\Delta t = W$。每个离散箱 $s[k]$ 的值是 $x(t)$ 在相应时间间隔内的平均值：\n$$\ns[k] = \\frac{1}{\\Delta t} \\int_{k\\Delta t}^{(k+1)\\Delta t} x(\\tau)\\,d\\tau\n$$\n对于给定的盒状刺激 $x(t)$，此积分对应于区间 $[k\\Delta t, (k+1)\\Delta t)$ 与刺激区间 $[0, W)$ 之间交集的长度。其计算方式如下：\n$$\ns[k] = \\frac{\\max(0, \\min((k+1)\\Delta t, W) - \\max(k\\Delta t, 0))}{\\Delta t}\n$$\n由于时间是非负的 ($k \\ge 0$)，这可以简化为：\n$$\ns[k] = \\frac{\\max(0, \\min((k+1)\\Delta t, W) - k\\Delta t)}{\\Delta t}\n$$\n\n### 步骤3：离散卷积\n\n连续卷积积分通过离散卷积和来近似。在每个时间点 $t_n$ 的预测 BOLD 响应为：\n$$\ny[n] \\approx \\Delta t \\sum_{k=0}^{n} s[k]\\,h[n-k]\n$$\n此表达式是采样间隔 $\\Delta t$ 与序列 $s$ 和 $h$ 的标准离散卷积（表示为 $(s*h)[n]$）的乘积。此操作可使用标准数值库（如 `numpy.convolve`）高效实现。求和上限为 $n$ 表示因果卷积，这是 $s[k]$ 和 $h[k]$ 均为因果信号（负索引处为零）的自然结果。两个长度为 $N$ 的序列的完整卷积会产生一个长度为 $2N-1$ 的序列；我们关心的是仿真窗口内的响应，因此将结果截断为前 $N$ 个点。\n\n### 步骤4：输出量计算\n\n一旦计算出离散 BOLD 响应 $y[n]$（对于 $n=0, \\dots, N-1$），即可按如下方式计算每个测试用例所需的输出：\n\n1.  **查询时间点的值**：对于每个指定的查询时间 $t_{query}$，通过最近邻规则确定相应的数组索引 $n$：$n = \\operatorname{round}(t_{query} / \\Delta t)$。然后 BOLD 响应即为 $y[n]$。\n\n2.  **峰值时间和振幅**：峰值振幅 $y_{\\text{peak}}$ 是序列 $y[n]$ 的最大值。该最大值的索引 $n_{\\text{peak}} = \\operatorname{argmax}_n y[n]$ 用于找到峰值时间 $t_{\\text{peak}} = n_{\\text{peak}} \\Delta t$。\n\n3.  **曲线下面积**：连续响应曲线 $y(t)$ 下的数值面积通过离散响应在仿真窗口内的黎曼和来近似：\n    $$\n    \\text{Area} = \\sum_{n=0}^{N-1} y[n]\\,\\Delta t\n    $$\n这个过程提供了一个完整的算法来仿真 BOLD 响应并提取指定的量化特征。实现时会将此逻辑封装在一个函数中，并为每组测试用例参数执行该函数。",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import gamma\n\ndef solve():\n    \"\"\"\n    Main function to solve the BOLD response modeling problem for all test cases.\n    \"\"\"\n    # Canonical double-gamma HRF parameters\n    A1, B1 = 6, 1\n    A2, B2 = 16, 1\n    C_RATIO = 6\n\n    def gamma_pdf(t, a, b):\n        \"\"\"\n        Computes the Gamma probability density function in a vectorized manner.\n        g(t; a, b) = t^(a-1) * exp(-t/b) / (b^a * gamma(a)) for t = 0.\n        \"\"\"\n        # Ensure t is a numpy array for vectorized operations\n        t = np.asarray(t, dtype=float)\n        \n        # The function is causal, so response is 0 for t  0.\n        # Initialize response array with zeros.\n        response = np.zeros_like(t)\n\n        # Denominator is constant\n        denom = (b**a) * gamma(a)\n        if denom == 0:\n            return response\n\n        # Calculate for t  0 to avoid potential issues at t=0\n        # (e.g., 0**k where k  0, which is not the case here as a  1)\n        positive_t_mask = t  0\n        t_pos = t[positive_t_mask]\n\n        response[positive_t_mask] = (t_pos**(a - 1) * np.exp(-t_pos / b)) / denom\n        \n        return response\n\n    def hrf(t):\n        \"\"\"\n        Computes the canonical double-gamma Hemodynamic Response Function (HRF).\n        h(t) = g(t; a1, b1) - (1/c) * g(t; a2, b2)\n        \"\"\"\n        g1 = gamma_pdf(t, A1, B1)\n        g2 = gamma_pdf(t, A2, B2)\n        return g1 - (1 / C_RATIO) * g2\n\n    def calculate_bold_response(dt, t_max, W, query_times):\n        \"\"\"\n        Calculates the BOLD response for a given set of parameters.\n        \"\"\"\n        # 1. Create the discretized time vector\n        num_points = int(np.floor(t_max / dt)) + 1\n        t = np.linspace(0.0, (num_points - 1) * dt, num_points)\n\n        # 2. Compute the discrete HRF sequence h[n]\n        h_n = hrf(t)\n\n        # 3. Compute the discrete stimulus sequence s[k] using per-bin averaging\n        bin_starts = t\n        bin_ends = t + dt\n        \n        # Calculate the length of the intersection of each bin [t_k, t_{k+1}) with [0, W)\n        overlap_starts = np.maximum(bin_starts, 0.0)\n        overlap_ends = np.minimum(bin_ends, W)\n        overlap_lengths = np.maximum(0.0, overlap_ends - overlap_starts)\n        \n        s_k = overlap_lengths / dt\n\n        # 4. Compute the discrete BOLD response y[n] via convolution\n        # y[n] = dt * (s * h)[n]\n        y_n_full = np.convolve(s_k, h_n, mode='full')\n        # Truncate the result to the length of the simulation window\n        y_n = dt * y_n_full[:num_points]\n\n        # 5. Calculate the required output quantities\n        \n        # Sampled values at query times\n        query_indices = np.round(np.array(query_times) / dt).astype(int)\n        # Clip indices to prevent out-of-bounds access\n        query_indices = np.minimum(query_indices, num_points - 1)\n        sampled_values = y_n[query_indices].tolist()\n\n        # Peak time and amplitude\n        if y_n.size  0:\n            peak_idx = np.argmax(y_n)\n            y_peak = y_n[peak_idx]\n            t_peak = peak_idx * dt\n        else:\n            t_peak, y_peak = 0.0, 0.0\n            \n        # Area under the curve (Riemann sum)\n        area = np.sum(y_n) * dt\n\n        return [sampled_values, t_peak, y_peak, area]\n\n    # Define the test cases from the problem statement\n    test_cases = [\n        {'dt': 0.1, 't_max': 40.0, 'W': 0.1, 'query_times': [0.0, 6.0, 12.0, 20.0]},\n        {'dt': 0.01, 't_max': 40.0, 'W': 0.1, 'query_times': [6.0]},\n        {'dt': 0.4, 't_max': 40.0, 'W': 0.1, 'query_times': [6.0]},\n        {'dt': 0.1, 't_max': 10.0, 'W': 0.1, 'query_times': [0.0, 6.0, 9.9]},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = calculate_bold_response(\n            case['dt'], case['t_max'], case['W'], case['query_times']\n        )\n        results.append(result)\n\n    # Format the output string exactly as specified, using repr and removing spaces.\n    # This generates a compact, JSON-like list-of-lists string.\n    final_output_str = repr(results).replace(' ', '')\n    print(final_output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "当我们有了数据和模型之后，就需要进行统计检验来得出结论。这最后一项练习将介绍一种强大而灵活的非参数统计推断方法，该方法在现代神经影像学中被广泛使用。您将从零开始实现一个置换检验，以控制全脑多重比较的错误率，从而深入理解如何在不依赖参数假设的情况下获得统计上稳健的结论 。",
            "id": "4445740",
            "problem": "给定来自功能性磁共振成像 (fMRI) 和脑磁图 (MEG) 任务的成对、被试内测量数据，这些数据被抽象为逐特征的条件差异。对于每个被试，一个特征差异代表了两种条件（例如，任务和基线）之间的被试内对比，数据排列成一个矩阵，其中行是受试者，列是特征。您必须为被试内对比构建一个基于符号翻转的非参数置换检验，并计算跨特征的最大绝对检验统计量的分布，以通过 Westfall–Young 方法实现族系误差率 (FWER) 控制。然后，对于每个测试用例，确定在指定的显著性水平下，通过 FWER 控制有多少特征是显著的。\n\n使用以下基础理论：\n\n- 在没有条件效应的原假设下，被试内条件差异围绕零对称，因此对每个被试的差异进行符号翻转是分布保持的。因此，在原假设下，逐被试的符号翻转是可交换的。这产生了一个由所有符号组合构建的非参数参考分布。\n- 对于由 $f$ 索引的给定特征，其被试差异为 $d_{1,f}, d_{2,f}, \\dots, d_{n,f}$，样本均值 $\\bar{d}_f$ 和样本标准差 $s_f$ 定义为\n  $$\\bar{d}_f = \\frac{1}{n}\\sum_{i=1}^{n} d_{i,f}, \\quad s_f = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(d_{i,f} - \\bar{d}_f\\right)^2}.$$\n- 对于特征 $f$ 的被试内对比，其单样本检验统计量由学生氏 t-统计量给出，\n  $$t_f = \\frac{\\bar{d}_f}{s_f / \\sqrt{n}},$$\n  该统计量用于评估均值差异是否偏离零，其唯一假设是原假设能导出置换有效性所需的对称性和可交换性。\n- 为控制 $m$ 个特征的多重比较，可以通过计算每个符号翻转模式 $p \\in \\{-1,+1\\}^n$ 的置换差异 $p_i d_{i,f}$、相应的逐特征统计量 $t_f^{(p)}$ 以及最大绝对统计量来获得一个非参数分布\n  $$T_{\\max}^{(p)} = \\max_{1 \\le f \\le m} \\left|t_f^{(p)}\\right|.$$\n- 设有 $R$ 个符号翻转置换。在显著性水平 $\\alpha$ 下，FWER 临界阈值 $c_\\alpha$ 是通过从 $\\{T_{\\max}^{(p)}\\}_{p=1}^{R}$ 的经验分布中选取 $(1-\\alpha)$ 分位数得到的，该分位数使用控制族系误差率的顺序统计量来确定。如果 $\\left|t_f\\right| \\ge c_\\alpha$，则特征 $f$ 被宣告为显著。\n\n您的任务是实现上述非参数过程，并将其应用于下面的测试套件。对于每个测试用例，使用最大绝对统计量的双边准则，在指定的 $\\alpha$ 水平下计算显著特征的数量。精确枚举所有符号翻转置换；不要进行子抽样。\n\n答案格式要求：\n- 程序必须生成单行输出，其中包含所有测试用例的结果，格式为方括号内由逗号分隔的列表。\n- 每个测试用例的结果必须是一个整数，等于该用例的显著特征数。\n\n测试套件：\n- 案例 $1$：$n=4$, $m=3$, $\\alpha = 0.05$，各特征的被试差异如下：\n  - 特征 $1$：$(0.8, 0.6, 0.7, 0.9)$\n  - 特征 $2$：$(0.2, -0.1, 0.0, 0.3)$\n  - 特征 $3$：$(1.2, 1.0, 1.1, 0.9)$\n- 案例 $2$：$n=5$, $m=2$, $\\alpha = 0.05$，差异如下：\n  - 特征 $1$：$(0.05, -0.02, 0.01, -0.03, 0.00)$\n  - 特征 $2$：$(0.4, 0.45, 0.35, 0.5, 0.38)$\n- 案例 $3$：$n=6$, $m=1$, $\\alpha = 0.05$，差异如下：\n  - 特征 $1$：$(-0.5, -0.6, -0.4, -0.55, -0.45, -0.5)$\n- 案例 $4$：$n=3$, $m=4$, $\\alpha = 0.05$，差异如下：\n  - 特征 $1$：$(1.0, 0.0, -1.0)$\n  - 特征 $2$：$(0.5, -0.5, 0.0)$\n  - 特征 $3$：$(0.2, -0.2, 0.0)$\n  - 特征 $4$：$(0.3, -0.3, 0.0)$\n\n您的程序应生成一行输出，其中包含一个由逗号分隔并用方括号括起来的结果列表（例如，$[r_1,r_2,r_3,r_4]$），其中每个 $r_k$ 是使用所述的非参数最大统计量 FWER 程序计算出的案例 $k$ 的显著特征的整数数量。",
            "solution": "该问题要求实现一个非参数置换检验，用于从成对的被试内 fMRI 和 MEG 数据中识别显著特征，同时控制族系误差率 (FWER)。所提供的方法论基于符号翻转和最大统计量方法，通常与 Westfall-Young 程序相关联。该问题在科学上是合理的，定义明确，并为确定性解决方案提供了所有必要信息。\n\n核心原则和算法步骤如下：\n\n首先，我们为置换检验建立理论基础。该问题涉及被试内对比，表示为每个被试 $i \\in \\{1, \\dots, n\\}$ 和每个特征 $f \\in \\{1, \\dots, m\\}$ 的差异 $d_{i,f}$。原假设 $H_0$ 假定成对条件之间没有真实差异。在 $H_0$ 下，假设每个差异 $d_{i,f}$ 都来自一个关于 0 对称的分布。这种对称性的一个直接结果是，每个被试跨所有特征的差异向量的符号是任意的；也就是说，翻转任何被试测量值的符号都不会改变数据的统计分布。此属性被称为符号翻转可交换性。它允许我们通过考虑应用于被试数据的所有 $2^n$ 种可能的符号翻转组合来生成一个参考分布。\n\n其次，我们定义一个合适的检验统计量来量化每个特征反对原假设的证据。为此选择了单样本学生氏 t-统计量。对于每个特征 $f$，其计算公式为：\n$$t_f = \\frac{\\bar{d}_f}{s_f / \\sqrt{n}}$$\n其中 $\\bar{d}_f$ 是特征 $f$ 在 $n$ 个被试中的差异样本均值，而 $s_f$ 是相应的样本标准差，定义为 $s_f = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^{n}\\left(d_{i,f} - \\bar{d}_f\\right)^2}$。该统计量以其标准误为单位来衡量均值差异，提供了一个标准化的效应大小度量。$t_f$ 的绝对值较大表明均值差异不太可能为零。\n\n第三，我们解决多重比较问题。当同时检验 $m$ 个特征时，至少出现一个假阳性发现（第一类错误）的概率会膨胀。为了应对这个问题，我们控制 FWER，即在所有 $m$ 个检验中犯一个或多个第一类错误的概率。指定的方法通过构建*最大绝对检验统计量*的零分布来实现这一点。对于 $R=2^n$ 个符号翻转置换中的每一个（由 $p$ 索引），我们为每个特征重新计算 t-统计量，记为 $t_f^{(p)}$。然后，对于每个置换，我们找出所有特征中的最大绝对值：\n$$T_{\\max}^{(p)} = \\max_{1 \\le f \\le m} \\left|t_f^{(p)}\\right|$$\n这些 $R$ 个值的集合 $\\{T_{\\max}^{(p)}\\}_{p=1}^{R}$ 构成了经验零分布。该分布代表了在原假设下，在所有特征中可以观察到的最极端 t-统计量的预期范围。\n\n最后，我们推导出一个决策规则。FWER 为 $\\alpha$ 的临界阈值 $c_\\alpha$ 是从最大统计量的零分布中确定的。具体来说，$c_\\alpha$ 是 $\\{T_{\\max}^{(p)}\\}$ 分布排序后的 $(1-\\alpha)$ 分位数。设排序后的值为 $T_{(1)} \\le T_{(2)} \\le \\dots \\le T_{(R)}$。临界值 $c_\\alpha$ 被选为第 $k$ 个顺序统计量 $T_{(k)}$，其中 $k = \\lceil R(1-\\alpha) \\rceil$。这种保守的选择确保了在原假设下最大统计量超过 $c_\\alpha$ 的概率不大于 $\\alpha$。如果一个特征 $f$ 的原始观测绝对 t-统计量 $|t_f|$ 达到或超过这个严格的阈值：$|t_f| \\ge c_\\alpha$，则该特征被宣告为统计显著。\n\n每个测试用例需要实现的算法过程如下：\n1.  对于给定的包含 $n$ 个被试和 $m$ 个特征的差异数据矩阵 $D$，计算每个特征 $f=1, \\dots, m$ 的观测 t-统计量 $t_f$。\n2.  生成所有 $R=2^n$ 个唯一的符号翻转向量 $p \\in \\{-1, +1\\}^n$。\n3.  初始化一个空列表来存储最大统计量的分布。\n4.  对于每个符号翻转向量 $p$：\n    a. 将符号翻转应用于数据矩阵 $D$ 以获得置换数据矩阵 $D^{(p)}$，其中 $D_{i,f}^{(p)} = p_i d_{i,f}$。\n    b. 基于 $D^{(p)}$ 计算每个特征的 t-统计量 $t_f^{(p)}$。对于标准差为零的情况需要特别处理，此时 t-统计量定义为 $0$。\n    c. 确定此次置换的最大绝对统计量 $T_{\\max}^{(p)} = \\max_f |t_f^{(p)}|$，并将其添加到列表中。\n5.  将 $R$ 个最大统计量的列表按升序排序。\n6.  在排序后的、0-索引的列表中，将索引为 $\\lceil R(1-\\alpha)\\rceil - 1$ 处的值计算为临界值 $c_\\alpha$。\n7.  将每个原始观测 t-统计量的绝对值 $|t_f|$ 与 $c_\\alpha$ 进行比较。\n8.  测试用例的最终结果是满足 $|t_f| \\ge c_\\alpha$ 的特征数量。\n\n这个完整的、精确的置换过程将应用于问题陈述中指定的全部 4 个测试用例。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport itertools\n\ndef calculate_significant_features(D, alpha):\n    \"\"\"\n    Performs a nonparametric permutation test with FWER control.\n\n    Args:\n        D (np.ndarray): A 2D numpy array of shape (n_subjects, n_features)\n                        containing the within-subject differences.\n        alpha (float): The desired significance level for FWER control.\n\n    Returns:\n        int: The number of features significant at the specified alpha level.\n    \"\"\"\n    D = np.asarray(D)\n    n, m = D.shape\n    \n    # Define a helper function to compute t-statistics for a data matrix\n    def compute_t_stats(data):\n        n_subjects = data.shape[0]\n        if n_subjects  2:\n            return np.zeros(data.shape[1])\n            \n        means = np.mean(data, axis=0)\n        stds = np.std(data, axis=0, ddof=1)\n        \n        # Denominator of the t-statistic\n        sems = stds / np.sqrt(n_subjects)\n        \n        # Handle division by zero for features with zero variance\n        t_stats = np.divide(means, sems, out=np.zeros_like(means), where=sems != 0)\n        \n        return t_stats\n\n    # 1. Calculate observed t-statistics\n    t_observed = compute_t_stats(D)\n    abs_t_observed = np.abs(t_observed)\n\n    # 2. Generate all 2^n sign-flip permutations\n    R = 2**n\n    sign_flips = list(itertools.product([-1, 1], repeat=n))\n\n    # 3. Build the null distribution of the maximal absolute t-statistic\n    max_t_distribution = []\n    for signs in sign_flips:\n        signs_array = np.array(signs).reshape(-1, 1)\n        permuted_data = D * signs_array\n        \n        t_permuted = compute_t_stats(permuted_data)\n        \n        max_abs_t = np.max(np.abs(t_permuted))\n        max_t_distribution.append(max_abs_t)\n\n    # 4. Sort the distribution and find the critical value c_alpha\n    max_t_distribution.sort()\n    \n    # The critical value is the (1-alpha) quantile of the permutation distribution.\n    # We use ceiling to be conservative, ensuring P(T_max = c_alpha) = alpha.\n    quantile_index = int(np.ceil((1 - alpha) * R)) - 1\n    \n    # Ensure index is within bounds\n    if quantile_index  0:\n        quantile_index = 0\n    if quantile_index = R:\n        quantile_index = R-1\n        \n    c_alpha = max_t_distribution[quantile_index]\n\n    # 5. Count how many observed t-statistics exceed the critical threshold\n    significant_count = np.sum(abs_t_observed = c_alpha)\n    \n    return int(significant_count)\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the permutation test on all provided test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"data\": [\n                [0.8, 0.2, 1.2],\n                [0.6, -0.1, 1.0],\n                [0.7, 0.0, 1.1],\n                [0.9, 0.3, 0.9]\n            ],\n            \"alpha\": 0.05\n        },\n        {\n            \"data\": [\n                [0.05, 0.4],\n                [-0.02, 0.45],\n                [0.01, 0.35],\n                [-0.03, 0.5],\n                [0.00, 0.38]\n            ],\n            \"alpha\": 0.05\n        },\n        {\n            \"data\": [\n                [-0.5],\n                [-0.6],\n                [-0.4],\n                [-0.55],\n                [-0.45],\n                [-0.5]\n            ],\n            \"alpha\": 0.05\n        },\n        {\n            \"data\": [\n                [1.0, 0.5, 0.2, 0.3],\n                [0.0, -0.5, -0.2, -0.3],\n                [-1.0, 0.0, 0.0, 0.0]\n            ],\n            \"alpha\": 0.05\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        D = np.array(case[\"data\"])\n        alpha = case[\"alpha\"]\n        result = calculate_significant_features(D, alpha)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}