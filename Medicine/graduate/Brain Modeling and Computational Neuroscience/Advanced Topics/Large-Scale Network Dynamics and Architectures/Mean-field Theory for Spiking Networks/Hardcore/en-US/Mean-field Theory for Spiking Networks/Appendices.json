{
    "hands_on_practices": [
        {
            "introduction": "The foundation of mean-field theory rests on abstracting the barrage of discrete synaptic inputs into a few statistical moments. This first exercise provides practice with the essential tool for this abstraction: Campbell's theorem. By calculating the stationary mean and variance of the synaptic current driven by a Poisson process of spikes, you will see firsthand how microscopic synaptic parameters translate into the macroscopic drift and diffusion terms that govern a neuron's dynamics in the mean-field limit .",
            "id": "4051240",
            "problem": "Consider a stationary presynaptic spike train modeled as a homogeneous Poisson point process with rate $\\nu$ (events per unit time). Let the postsynaptic response to a single spike be governed by the causal single-exponential synaptic kernel $\\alpha(t) = \\exp(-t/\\tau_s) H(t)$, where $H(t)$ is the Heaviside step function and $\\tau_s > 0$ is the synaptic time constant. Two synaptic models are considered:\n\n1. A current-based synapse, in which the postsynaptic current is given by $I(t) = J \\sum_{k} \\alpha(t - t_k)$, where $J$ is a constant current increment per spike and $\\{t_k\\}$ are the presynaptic spike times.\n\n2. A conductance-based synapse, in which the postsynaptic conductance is given by $g(t) = g_0 \\sum_{k} \\alpha(t - t_k)$, where $g_0$ is a constant conductance increment per spike.\n\nStarting only from:\n- The definition of a homogeneous Poisson point process and its stationarity.\n- Well-tested properties of sums over Poisson point processes (e.g., the expectation of sums and second moments over independent points), and the fact that $\\alpha(t)$ is integrable and square-integrable on $[0,\\infty)$.\n\nDerive the stationary mean and variance of the synaptic current $I(t)$ for the current-based synapse, and the stationary mean and variance of the synaptic conductance $g(t)$ for the conductance-based synapse. Express your final answer as closed-form analytic expressions in terms of $\\nu$, $\\tau_s$, $J$, and $g_0$. Do not substitute any numerical values. Provide the final answer as a row matrix with entries in the order $\\langle I \\rangle$, $\\mathrm{Var}(I)$, $\\langle g \\rangle$, $\\mathrm{Var}(g)$. No rounding is required. Express the answer symbolically only.",
            "solution": "The problem asks for the stationary mean and variance of the synaptic current $I(t)$ and synaptic conductance $g(t)$, which are driven by a homogeneous Poisson spike train with rate $\\nu$. Both quantities can be represented as linear filtered Poisson processes, also known as shot noise. A general shot noise process $X(t)$ is defined as $X(t) = \\sum_{k} h(t - t_k)$, where $\\{t_k\\}$ are the event times of a Poisson process with rate $\\nu$, and $h(t)$ is the response function.\n\nFor a stationary, homogeneous Poisson process, Campbell's theorems give the stationary mean $\\langle X \\rangle$ and variance $\\mathrm{Var}(X)$ of the process $X(t)$:\n$$ \\langle X \\rangle = \\nu \\int_{-\\infty}^{\\infty} h(s) ds $$\n$$ \\mathrm{Var}(X) = \\nu \\int_{-\\infty}^{\\infty} h(s)^2 ds $$\nThe synaptic kernel is given as $\\alpha(t) = \\exp(-t/\\tau_s) H(t)$, where $H(t)$ is the Heaviside step function. We first calculate the necessary integrals of this kernel.\n$$ \\int_{-\\infty}^{\\infty} \\alpha(s) ds = \\int_0^{\\infty} \\exp(-s/\\tau_s) ds = \\left[ -\\tau_s \\exp(-s/\\tau_s) \\right]_0^{\\infty} = \\tau_s $$\n$$ \\int_{-\\infty}^{\\infty} \\alpha(s)^2 ds = \\int_0^{\\infty} \\exp(-2s/\\tau_s) ds = \\left[ -\\frac{\\tau_s}{2} \\exp(-2s/\\tau_s) \\right]_0^{\\infty} = \\frac{\\tau_s}{2} $$\nNow we apply Campbell's theorems to each model.\n\n1.  **Current-Based Synapse**\nThe response kernel is $h_I(t) = J \\alpha(t)$.\nThe mean current, $\\langle I \\rangle$, is:\n$$ \\langle I \\rangle = \\nu \\int_{-\\infty}^{\\infty} J \\alpha(s) ds = \\nu J \\tau_s $$\nThe variance of the current, $\\mathrm{Var}(I)$, is:\n$$ \\mathrm{Var}(I) = \\nu \\int_{-\\infty}^{\\infty} (J \\alpha(s))^2 ds = \\nu J^2 \\left( \\frac{\\tau_s}{2} \\right) = \\frac{\\nu J^2 \\tau_s}{2} $$\n\n2.  **Conductance-Based Synapse**\nThe response kernel is $h_g(t) = g_0 \\alpha(t)$. The structure of the calculation is identical to the current-based case.\nThe mean conductance, $\\langle g \\rangle$, is:\n$$ \\langle g \\rangle = \\nu \\int_{-\\infty}^{\\infty} g_0 \\alpha(s) ds = \\nu g_0 \\tau_s $$\nThe variance of the conductance, $\\mathrm{Var}(g)$, is:\n$$ \\mathrm{Var}(g) = \\nu \\int_{-\\infty}^{\\infty} (g_0 \\alpha(s))^2 ds = \\nu g_0^2 \\left( \\frac{\\tau_s}{2} \\right) = \\frac{\\nu g_0^2 \\tau_s}{2} $$\n\nThe four requested quantities in order are:\n- Mean current: $\\langle I \\rangle = \\nu J \\tau_s$\n- Variance of current: $\\mathrm{Var}(I) = \\frac{\\nu J^2 \\tau_s}{2}$\n- Mean conductance: $\\langle g \\rangle = \\nu g_0 \\tau_s$\n- Variance of conductance: $\\mathrm{Var}(g) = \\frac{\\nu g_0^2 \\tau_s}{2}$\n\nThese are presented as a row matrix in the final answer.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\nu J \\tau_s  \\frac{\\nu J^2 \\tau_s}{2}  \\nu g_0 \\tau_s  \\frac{\\nu g_0^2 \\tau_s}{2}\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "A central assumption in many mean-field theories is the diffusion approximation, which models the discrete \"shot noise\" of synaptic arrivals as a continuous Gaussian process. This practice delves into the mathematical justification for this step, using the Kramers-Moyal expansion to formalize the connection between shot-noise dynamics and a continuous stochastic process. By deriving the first few coefficients, you will not only identify the drift and diffusion terms but also quantify the leading-order error of the approximation, providing a criterion for its validity .",
            "id": "4051248",
            "problem": "Consider a single-compartment neuron receiving a large number of statistically independent synaptic inputs that can be aggregated into a single homogeneous Poisson point process (PPP) of rate $\\nu$. Each presynaptic spike causes a postsynaptic current jump of amplitude $J$ followed by an exponential decay with synaptic time constant $\\tau_s$. The total synaptic current $I(t)$ obeys the linear shot-noise dynamics\n$$\n\\frac{d I(t)}{dt} \\;=\\; -\\frac{I(t)}{\\tau_s} \\;+\\; J \\sum_k \\delta\\!\\left(t-t_k\\right),\n$$\nwhere $\\{t_k\\}$ are the Poisson event times. Equivalently, in differential form with respect to the counting process $N_t$ of the PPP,\n$$\ndI(t) \\;=\\; -\\frac{I(t)}{\\tau_s}\\,dt \\;+\\; J\\,dN_t,\n$$\nwith $\\mathbb{E}[dN_t] = \\nu\\,dt$.\n\nStarting from the definition of the Kramers–Moyal expansion (KME), the $n$-th Kramers–Moyal coefficient $a_n(I)$ is\n$$\na_n(I) \\;=\\; \\lim_{dt\\to 0} \\frac{1}{dt}\\,\\mathbb{E}\\!\\left[ \\big(\\Delta I\\big)^{n} \\,\\big|\\, I(t)=I \\right],\n$$\nwhere $\\Delta I \\equiv I(t+dt)-I(t)$.\n\n1) Using only the dynamics above and the properties of a homogeneous Poisson process in an infinitesimal interval, derive the first three Kramers–Moyal coefficients $a_1(I)$, $a_2(I)$, and $a_3(I)$.\n\n2) In the stationary regime, the synaptic current can be represented as the linear superposition\n$$\nI(t) \\;=\\; \\sum_{t_k  t} J \\exp\\!\\left(-\\frac{t-t_k}{\\tau_s}\\right).\n$$\nUsing well-tested results for Poisson shot noise, compute the first three equal-time cumulants $\\kappa_1$, $\\kappa_2$, and $\\kappa_3$ of $I(t)$.\n\n3) The diffusion approximation neglects third and higher Kramers–Moyal terms, hence an error indicator is the standardized third cumulant (skewness magnitude)\n$$\n\\gamma \\;\\equiv\\; \\frac{|\\kappa_3|}{\\kappa_2^{3/2}}.\n$$\nExpress $\\gamma$ as a closed-form analytic expression in terms of $J$, $\\nu$, and $\\tau_s$. Provide your final answer as a single symbolic expression. No numerical evaluation or rounding is required, and no units should be included in the final expression.",
            "solution": "We begin from the stochastic differential form\n$$\ndI(t) \\;=\\; -\\frac{I(t)}{\\tau_s}\\,dt \\;+\\; J\\,dN_t,\n$$\nwhere $N_t$ is the counting process of a homogeneous Poisson point process (PPP) with rate $\\nu$. Over an infinitesimal interval $[t,t+dt)$, the increment is $\\Delta I = -\\frac{I}{\\tau_s}\\,dt + J\\,\\Delta N$, with $\\Delta N \\equiv N_{t+dt}-N_t$. For a homogeneous PPP, $\\mathbb{P}(\\Delta N=1)=\\nu\\,dt + o(dt)$, $\\mathbb{P}(\\Delta N=0)=1-\\nu\\,dt+o(dt)$, and $\\mathbb{P}(\\Delta N \\ge 2)=o(dt)$.\n\n1) Computation of the first three Kramers–Moyal coefficients.\nBy definition, $a_n(I) = \\lim_{dt\\to 0}\\frac{1}{dt}\\,\\mathbb{E}\\!\\left[ (\\Delta I)^n \\mid I(t)=I \\right]$.\nFor $n=1$, $\\mathbb{E}[\\Delta I \\mid I] = -\\frac{I}{\\tau_s}\\,dt + J\\,\\mathbb{E}[\\Delta N] = -\\frac{I}{\\tau_s}\\,dt + J\\,\\nu\\,dt$, thus\n$$ a_1(I) = -\\frac{I}{\\tau_s} + J\\,\\nu. $$\nFor $n \\ge 2$, the leading $O(dt)$ contribution arises from $(J\\Delta N)^n$, since terms involving $(dt)^2$ or higher vanish in the limit. For a PPP, $\\Delta N$ can only be 0 or 1 to order $dt$, so $(\\Delta N)^n = \\Delta N$ for any $n \\ge 1$.\n$$ \\mathbb{E}\\!\\left[(\\Delta I)^n \\mid I\\right] = \\mathbb{E}\\!\\left[(J \\Delta N)^n\\right] + o(dt) = J^n \\mathbb{E}[(\\Delta N)^n] + o(dt) = J^n \\mathbb{E}[\\Delta N] + o(dt) = J^n \\nu\\,dt + o(dt). $$\nTherefore, for $n=2$ and $n=3$:\n$$ a_2(I) = J^2 \\nu, \\qquad a_3(I) = J^3 \\nu. $$\n\n2) Stationary equal-time cumulants of $I(t)$.\nIn steady state, $I(t)$ is a Poisson shot noise process with kernel $h(s) = J \\exp(-s/\\tau_s)\\,\\mathbf{1}_{\\{s\\ge 0\\}}$. The $n$-th equal-time cumulant $\\kappa_n$ is given by Campbell's theorem for cumulants:\n$$ \\kappa_n = \\nu \\int_{0}^{\\infty} (h(s))^n\\,ds = \\nu \\int_{0}^{\\infty} J^n \\exp\\left(-\\frac{n s}{\\tau_s}\\right)\\,ds = \\nu\\,J^n\\,\\frac{\\tau_s}{n}. $$\nIn particular,\n$$ \\kappa_1 = \\nu J \\tau_s,\\qquad \\kappa_2 = \\nu J^2 \\frac{\\tau_s}{2},\\qquad \\kappa_3 = \\nu J^3 \\frac{\\tau_s}{3}. $$\n\n3) Standardized third cumulant (skewness magnitude).\nThe skewness magnitude $\\gamma$ is defined as $\\gamma = \\frac{|\\kappa_3|}{\\kappa_2^{3/2}}$.\nSubstituting the expressions from part 2):\n$$ \\gamma = \\frac{\\left|\\nu J^3 \\frac{\\tau_s}{3}\\right|}{\\left(\\nu J^2 \\frac{\\tau_s}{2}\\right)^{3/2}} = \\frac{\\nu |J|^3 \\tau_s / 3}{|J|^3 (\\nu \\tau_s)^{3/2} / 2^{3/2}} = \\frac{2^{3/2}}{3}\\,\\frac{\\nu \\tau_s}{(\\nu \\tau_s)^{3/2}} = \\frac{2\\sqrt{2}}{3}\\,\\frac{1}{\\sqrt{\\nu \\tau_s}}. $$\nThe final expression is independent of $J$ and indicates that the diffusion approximation is better for larger values of the product $\\nu \\tau_s$, which represents the number of synaptic events arriving within one synaptic time constant.",
            "answer": "$$\\boxed{\\frac{2^{3/2}}{3}\\,(\\nu\\,\\tau_s)^{-1/2}}$$"
        },
        {
            "introduction": "Once we establish the mean-field equations for a network, a critical next step is to analyze the stability of its stationary states. This exercise demonstrates how to use the mean-field framework to perform a linear stability analysis on the asynchronous state of an excitatory-inhibitory network. By examining how the dominant eigenvalue of the system's Jacobian changes with inhibitory strength, you will gain a powerful tool for predicting whether a network state is stable or prone to oscillations, revealing the crucial role of inhibition in stabilizing network activity .",
            "id": "3996543",
            "problem": "Consider a two-population excitatory-inhibitory network of leaky integrate-and-fire neurons in the asynchronous state. In the diffusion mean-field approximation, small perturbations $\\delta r_{E}(t)$ and $\\delta r_{I}(t)$ of the population-averaged firing rates around a fixed point $(r_{E}^{\\ast}, r_{I}^{\\ast})$ evolve according to a linear system that results from first-order Taylor expansion of the transfer functions around the fixed point. Let $g_{E} > 0$ and $g_{I} > 0$ denote the slope (gain) of the excitatory and inhibitory population transfer functions at $(r_{E}^{\\ast}, r_{I}^{\\ast})$, respectively, and let $\\tau_{E} > 0$ and $\\tau_{I} > 0$ be their effective rate time constants. Synaptic strengths are parameterized by positive magnitudes $J_{EE} > 0$, $J_{EI} > 0$, $J_{IE} > 0$, and $J_{II} > 0$, where the negative sign of inhibition is carried explicitly in the linearized dynamics. Specifically, the linearized mean-field dynamics are\n$$\n\\begin{aligned}\n\\delta \\dot{r}_{E}(t) = -\\frac{1}{\\tau_{E}} \\, \\delta r_{E}(t) + g_{E} \\left( J_{EE} \\, \\delta r_{E}(t) - J_{EI} \\, \\delta r_{I}(t) \\right), \\\\\n\\delta \\dot{r}_{I}(t) = -\\frac{1}{\\tau_{I}} \\, \\delta r_{I}(t) + g_{I} \\left( J_{IE} \\, \\delta r_{E}(t) - J_{II} \\, \\delta r_{I}(t) \\right).\n\\end{aligned}\n$$\nThese equations define the Jacobian matrix $\\mathbf{A}$ of the linearized system at the fixed point via $\\delta \\dot{\\mathbf{r}}(t) = \\mathbf{A} \\, \\delta \\mathbf{r}(t)$ with $\\delta \\mathbf{r} = (\\delta r_{E}, \\delta r_{I})^{\\top}$. Assume the parameter regime is such that the eigenvalues of $\\mathbf{A}$ are real (the discriminant of the characteristic polynomial is nonnegative). Using only the fundamental definition of linearization and eigenvalues for a $2 \\times 2$ matrix, calculate the effect of increasing the inhibitory self-coupling magnitude $J_{II}$ on the dominant eigenvalue (the larger real eigenvalue) of $\\mathbf{A}$ by deriving a closed-form analytic expression for $\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}}$ in terms of $(\\tau_{E}, \\tau_{I}, g_{E}, g_{I}, J_{EE}, J_{EI}, J_{IE}, J_{II})$. Your final answer must be a single analytical expression. Then, interpret the sign of your expression in terms of stabilization of the asynchronous fixed point. No numerical evaluation is required and no rounding is needed. Express the final derivative as a dimensionless symbolic expression.",
            "solution": "The problem requires calculating the derivative of the dominant eigenvalue of the network's Jacobian matrix with respect to the inhibitory self-coupling strength, $J_{II}$, and interpreting the result.\n\nFirst, we write the linearized system in matrix form, $\\delta\\dot{\\mathbf{r}}(t) = \\mathbf{A} \\, \\delta\\mathbf{r}(t)$, by identifying the Jacobian matrix $\\mathbf{A}$.\n$$\n\\mathbf{A} = \\begin{pmatrix} g_{E} J_{EE} - \\frac{1}{\\tau_{E}}  -g_{E} J_{EI} \\\\ g_{I} J_{IE}  -g_{I} J_{II} - \\frac{1}{\\tau_{I}} \\end{pmatrix}\n$$\nLet the elements of the matrix be $A_{11}$, $A_{12}$, $A_{21}$, and $A_{22}$. The eigenvalues $\\lambda$ are the roots of the characteristic equation $\\lambda^2 - \\text{Tr}(\\mathbf{A})\\lambda + \\det(\\mathbf{A}) = 0$. Since the eigenvalues are assumed to be real, the dominant eigenvalue $\\lambda_{\\max}$ is given by:\n$$\n\\lambda_{\\max} = \\frac{\\text{Tr}(\\mathbf{A}) + \\sqrt{\\text{Tr}(\\mathbf{A})^2 - 4\\det(\\mathbf{A})}}{2}\n$$\nTo find $\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}}$, we first compute the derivatives of the trace and determinant with respect to $J_{II}$.\nThe trace is $\\text{Tr}(\\mathbf{A}) = A_{11} + A_{22} = \\left(g_{E} J_{EE} - \\frac{1}{\\tau_{E}}\\right) + \\left(-g_{I} J_{II} - \\frac{1}{\\tau_{I}}\\right)$.\n$$\n\\frac{\\partial \\text{Tr}(\\mathbf{A})}{\\partial J_{II}} = -g_{I}\n$$\nThe determinant is $\\det(\\mathbf{A}) = A_{11}A_{22} - A_{12}A_{21}$. Only $A_{22}$ depends on $J_{II}$.\n$$\n\\frac{\\partial \\det(\\mathbf{A})}{\\partial J_{II}} = A_{11} \\frac{\\partial A_{22}}{\\partial J_{II}} = A_{11}(-g_I) = -g_I \\left( g_{E} J_{EE} - \\frac{1}{\\tau_{E}} \\right)\n$$\nNow we differentiate $\\lambda_{\\max}$ using the chain rule. Let $\\Delta = \\text{Tr}(\\mathbf{A})^2 - 4\\det(\\mathbf{A})$ be the discriminant.\n$$\n\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}} = \\frac{1}{2} \\left( \\frac{\\partial \\text{Tr}(\\mathbf{A})}{\\partial J_{II}} + \\frac{1}{2\\sqrt{\\Delta}} \\frac{\\partial \\Delta}{\\partial J_{II}} \\right)\n$$\nThe derivative of the discriminant is:\n$$\n\\frac{\\partial \\Delta}{\\partial J_{II}} = 2\\text{Tr}(\\mathbf{A}) \\frac{\\partial \\text{Tr}(\\mathbf{A})}{\\partial J_{II}} - 4 \\frac{\\partial \\det(\\mathbf{A})}{\\partial J_{II}} = 2\\text{Tr}(\\mathbf{A})(-g_I) - 4(-g_I A_{11}) = -2g_I (\\text{Tr}(\\mathbf{A}) - 2A_{11})\n$$\nSince $\\text{Tr}(\\mathbf{A}) = A_{11} + A_{22}$, this simplifies to $\\frac{\\partial \\Delta}{\\partial J_{II}} = -2g_I (A_{22} - A_{11})$.\nSubstituting back into the derivative of $\\lambda_{\\max}$:\n$$\n\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}} = \\frac{1}{2} \\left( -g_{I} + \\frac{-2g_I(A_{22} - A_{11})}{2\\sqrt{\\Delta}} \\right) = -\\frac{g_{I}}{2} \\left( 1 + \\frac{A_{22} - A_{11}}{\\sqrt{\\Delta}} \\right)\n$$\nThis expression can be rewritten by substituting $A_{11}-A_{22}$ and $\\Delta = (A_{11}-A_{22})^2+4A_{12}A_{21}$ to match the structure of the provided answer.\n\n**Interpretation:**\nThe stability of the fixed point is determined by the sign of $\\lambda_{\\max}$. A negative value of $\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}}$ indicates that increasing inhibitory self-coupling $J_{II}$ makes the network more stable (or less unstable).\n\nLet's analyze the sign of the derivative. The term $-g_I/2$ is negative. The sign depends on the term in the parenthesis: $S = 1 + \\frac{A_{22} - A_{11}}{\\sqrt{(A_{22}-A_{11})^2 + 4A_{12}A_{21}}}$.\nAll synaptic strengths are positive, so $A_{12} = -g_E J_{EI}  0$ and $A_{21} = g_I J_{IE} > 0$. Therefore, the term $4A_{12}A_{21}$ is negative.\nLet $X = A_{22} - A_{11}$ and $P = -4A_{12}A_{21} > 0$. The term becomes $S = 1 + \\frac{X}{\\sqrt{X^2-P}}$.\nThe condition of real eigenvalues means $\\Delta = X^2-P \\ge 0$, so $|X| \\ge \\sqrt{P}$. This implies that the magnitude of the fraction $\\left|\\frac{X}{\\sqrt{X^2-P}}\\right| \\ge 1$.\n- If $X = A_{22} - A_{11} > 0$, then $\\frac{X}{\\sqrt{X^2-P}} \\ge 1$, so $S \\ge 2$. The derivative $\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}}$ is negative.\n- If $X = A_{22} - A_{11}  0$, then $\\frac{X}{\\sqrt{X^2-P}} \\le -1$, so $S \\le 0$. The derivative $\\frac{\\partial \\lambda_{\\max}}{\\partial J_{II}}$ is non-negative (zero or positive).\n\nTherefore, increasing inhibitory self-coupling is stabilizing if and only if $A_{22} > A_{11}$. This condition, $-g_{I} J_{II} - \\frac{1}{\\tau_{I}} > g_{E} J_{EE} - \\frac{1}{\\tau_{E}}$, is met when the decay/self-inhibition term of the I-population is stronger than the net self-excitation term of the E-population. While not universally guaranteed, this condition holds in many relevant network regimes, particularly those that are not strongly dominated by runaway excitation. In such cases, increasing $J_{II}$ serves as a powerful stabilizing mechanism, damping perturbations and promoting a stable asynchronous state.",
            "answer": "$$\n\\boxed{-\\frac{g_{I}}{2} \\left( 1 - \\frac{g_{E} J_{EE} + g_{I} J_{II} - \\frac{1}{\\tau_{E}} + \\frac{1}{\\tau_{I}}}{\\sqrt{\\left(g_{E} J_{EE} + g_{I} J_{II} - \\frac{1}{\\tau_{E}} + \\frac{1}{\\tau_{I}}\\right)^{2} - 4 g_{E} g_{I} J_{EI} J_{IE}}} \\right)}\n$$"
        }
    ]
}