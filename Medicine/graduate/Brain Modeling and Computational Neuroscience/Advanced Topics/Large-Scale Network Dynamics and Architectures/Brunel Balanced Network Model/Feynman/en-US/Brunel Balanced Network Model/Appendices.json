{
    "hands_on_practices": [
        {
            "introduction": "The cornerstone of the Brunel model is the concept of a balanced state, where large, opposing synaptic currents from excitatory and inhibitory populations cancel each other out on average. This foundational practice guides you through the analytical calculation to determine the precise conditions for this balance. By exploring this exercise , you will derive the critical ratio of inhibitory to excitatory synaptic strength, denoted as $g^{\\ast}$, that nullifies the mean input to a neuron, leaving firing to be driven purely by input fluctuations.",
            "id": "3966912",
            "problem": "Consider a large sparse recurrent network in the Brunel balanced network model, composed of excitatory and inhibitory neurons and driven by an external Poisson input. Each presynaptic spike produces an instantaneous postsynaptic change of membrane potential modeled as a jump of fixed amplitude. Excitatory synapses contribute a positive jump of amplitude $J$, inhibitory synapses contribute a negative jump of amplitude $-gJ$, where $g$ is a dimensionless ratio characterizing the relative strength of inhibitory to excitatory synapses, and external inputs contribute a positive jump of amplitude $J_{ext}$. Presynaptic spike trains are modeled as independent homogeneous Poisson processes.\n\nStarting from the definition of a homogeneous Poisson process and the linear superposition of independent shot noise processes, derive the expression for the net mean input per unit time to a representative neuron as the sum of expected increments from excitatory, inhibitory, and external sources. Impose the mean balance condition that the net mean input per unit time equals zero and solve for the inhibitory strength ratio $g^{\\ast}$ that nulls the net mean input.\n\nUse the following scientifically plausible parameters, consistent with the Brunel model:\n- Excitatory synaptic amplitude: $J = 0.1\\,\\mathrm{mV}$.\n- External synaptic amplitude: $J_{ext} = 0.08\\,\\mathrm{mV}$.\n- Number of excitatory presynaptic partners: $K_{E} = 800$.\n- Number of inhibitory presynaptic partners: $K_{I} = 200$.\n- Number of external presynaptic inputs: $K_{ext} = 800$.\n- Mean firing rate of excitatory presynaptic neurons: $\\nu_{E} = 4\\,\\mathrm{Hz}$.\n- Mean firing rate of inhibitory presynaptic neurons: $\\nu_{I} = 6\\,\\mathrm{Hz}$.\n- Mean firing rate of external presynaptic inputs: $\\nu_{ext} = 4\\,\\mathrm{Hz}$.\n\nCompute $g^{\\ast}$ that satisfies the mean balance requirement. Express the final value as a unitless scalar, and round your answer to $4$ significant figures.",
            "solution": "The problem statement is first validated against the required criteria.\n\n### Problem Validation\n**Step 1: Extract Givens**\n- Model: A large sparse recurrent network based on the Brunel balanced network model.\n- Neuron types: Excitatory and inhibitory.\n- Input: An external Poisson input.\n- Synaptic mechanism: Instantaneous postsynaptic potential jump of fixed amplitude upon a presynaptic spike.\n- Excitatory synaptic amplitude: $J$.\n- Inhibitory synaptic amplitude: $-gJ$, where $g$ is the relative strength ratio.\n- External synaptic amplitude: $J_{ext}$.\n- Spike train model: Independent homogeneous Poisson processes.\n- Task: Derive the net mean input per unit time, impose a mean balance condition ($\\text{net mean input} = 0$), and solve for the inhibitory strength ratio $g^{\\ast}$.\n- Parameters:\n    - $J = 0.1\\,\\mathrm{mV}$\n    - $J_{ext} = 0.08\\,\\mathrm{mV}$\n    - $K_{E} = 800$ (Number of excitatory presynaptic partners)\n    - $K_{I} = 200$ (Number of inhibitory presynaptic partners)\n    - $K_{ext} = 800$ (Number of external presynaptic inputs)\n    - $\\nu_{E} = 4\\,\\mathrm{Hz}$ (Mean firing rate of excitatory neurons)\n    - $\\nu_{I} = 6\\,\\mathrm{Hz}$ (Mean firing rate of inhibitory neurons)\n    - $\\nu_{ext} = 4\\,\\mathrm{Hz}$ (Mean firing rate of external inputs)\n- Final computation: Calculate $g^{\\ast}$ and round to $4$ significant figures.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is a standard, canonical exercise within computational neuroscience, rooted in the foundational Brunel (2000) model of balanced cortical networks. All concepts, including Poisson processes, synaptic integration, and the balance of excitation and inhibition, are well-established principles. The provided parameters are explicitly stated as \"scientifically plausible\" and are consistent with values used in the literature for modeling cortical circuits.\n- **Well-Posed:** The problem is clearly stated. It provides all necessary parameters and a precise condition (mean balance) to derive a unique analytical expression and subsequently compute a single numerical value for $g^{\\ast}$.\n- **Objective:** The problem is expressed in objective, mathematical language, free from any subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically sound, well-posed, objective, and complete. It is therefore deemed **valid**. The solution process will now proceed.\n\n### Derivation and Solution\nThe total afferent input to a representative neuron is the sum of inputs from three distinct populations: recurrent excitatory, recurrent inhibitory, and external excitatory. The presynaptic spike trains from each source are modeled as independent homogeneous Poisson processes.\n\nFor a single source firing as a Poisson process with mean rate $\\nu$, the expected number of spikes in a small time interval $dt$ is $\\nu dt$. If each spike causes a postsynaptic potential change of amplitude $A$, the expected change in membrane potential from this single source over the interval $dt$ is $A(\\nu dt)$. The mean input per unit time from this source is therefore $A\\nu$.\n\nDue to the assumption of independent spike trains, the total mean input per unit time, which we denote as $\\mu_{net}$, is the linear superposition of the mean inputs from all presynaptic partners.\n\n1.  **Mean input from the excitatory population ($\\mu_E$)**: There are $K_E$ excitatory presynaptic partners, each firing at an average rate of $\\nu_E$. Each excitatory spike causes a potential jump of amplitude $J$. The total mean input per unit time from this population is the sum of contributions from all $K_E$ neurons:\n    $$ \\mu_E = K_E \\nu_E J $$\n\n2.  **Mean input from the inhibitory population ($\\mu_I$)**: There are $K_I$ inhibitory presynaptic partners, each firing at an average rate of $\\nu_I$. Each inhibitory spike causes a potential jump of amplitude $-gJ$. The total mean input per unit time from this population is:\n    $$ \\mu_I = K_I \\nu_I (-gJ) = -g K_I \\nu_I J $$\n\n3.  **Mean input from the external population ($\\mu_{ext}$)**: There are $K_{ext}$ external inputs, each firing at an average rate of $\\nu_{ext}$. Each external spike causes a potential jump of amplitude $J_{ext}$. The total mean input per unit time from this population is:\n    $$ \\mu_{ext} = K_{ext} \\nu_{ext} J_{ext} $$\n\nThe net mean input per unit time, $\\mu_{net}$, is the sum of these three components:\n$$ \\mu_{net} = \\mu_E + \\mu_I + \\mu_{ext} = K_E \\nu_E J - g K_I \\nu_I J + K_{ext} \\nu_{ext} J_{ext} $$\nThis expression represents the net mean input per unit time to the neuron.\n\nThe mean balance condition requires that this net mean input is zero. We denote the specific value of $g$ that satisfies this condition as $g^{\\ast}$.\n$$ \\mu_{net} = K_E \\nu_E J - g^{\\ast} K_I \\nu_I J + K_{ext} \\nu_{ext} J_{ext} = 0 $$\n\nWe solve this equation for $g^{\\ast}$:\n$$ g^{\\ast} K_I \\nu_I J = K_E \\nu_E J + K_{ext} \\nu_{ext} J_{ext} $$\n$$ g^{\\ast} = \\frac{K_E \\nu_E J + K_{ext} \\nu_{ext} J_{ext}}{K_I \\nu_I J} $$\n\nNow, we substitute the provided numerical values:\n- $J = 0.1$\n- $J_{ext} = 0.08$\n- $K_E = 800$\n- $K_I = 200$\n- $K_{ext} = 800$\n- $\\nu_E = 4$\n- $\\nu_I = 6$\n- $\\nu_{ext} = 4$\n\nSubstituting these into the expression for $g^{\\ast}$:\n$$ g^{\\ast} = \\frac{(800)(4)(0.1) + (800)(4)(0.08)}{(200)(6)(0.1)} $$\n\nFirst, calculate the numerator:\n$$ \\text{Numerator} = (3200)(0.1) + (3200)(0.08) = 320 + 256 = 576 $$\n\nNext, calculate the denominator:\n$$ \\text{Denominator} = (1200)(0.1) = 120 $$\n\nFinally, compute the ratio:\n$$ g^{\\ast} = \\frac{576}{120} = 4.8 $$\n\nThe problem requires the answer to be rounded to $4$ significant figures. The exact value $4.8$ is written as $4.800$ to meet this requirement.",
            "answer": "$$\\boxed{4.800}$$"
        },
        {
            "introduction": "While balancing the mean input is a crucial first step, a complete description of the network's stationary state requires that the population firing rates are self-consistent. The rates that generate the synaptic input statistics must, in turn, be produced by those same statistics via the neuron's transfer function. This comprehensive coding practice  walks you through implementing the full mean-field theory to numerically solve for this self-consistent fixed-point, which represents the network's dynamic Asynchronous Irregular (AI) operating point.",
            "id": "3966869",
            "problem": "You are tasked to implement a complete program that, for the Brunel balanced network model, computes the Asynchronous Irregular (AI) fixed-point by iterating a single-neuron transfer function until convergence for a set of parameter configurations. The network comprises two homogeneous populations, excitatory and inhibitory, each modeled as Leaky Integrate-and-Fire (LIF) neurons receiving inputs from excitatory neurons, inhibitory neurons, and external Poisson sources. The AI fixed-point is defined as the self-consistent pair of stationary firing rates $\\left(r_E, r_I\\right)$, in which the output firing rate of each population equals the firing rate predicted by the single-neuron transfer function under the mean and variance of its synaptic input generated by the current firing rates of all sources.\n\nYour program must adhere to the following model assumptions and fundamental bases:\n\n- The neuron dynamics are governed by the Leaky Integrate-and-Fire (LIF) model with constant membrane time constant, hard reset at a reset potential, and absolute refractory time.\n- The inputs to each neuron are the superposition of many independent spike trains (excitatory, inhibitory, and external) approximated, by the Central Limit Theorem, as a Gaussian white-noise drive with well-defined mean and variance.\n- The single-neuron stationary firing rate (transfer function) for the LIF neuron under Gaussian white-noise input is obtained from the first-passage time formulation for the membrane potential crossing the threshold, with an additive absolute refractory period.\n- Connectivity is random and homogeneous. Each neuron receives, on average, $K_E = p_E N_E$ excitatory inputs and $K_I = p_I N_I$ inhibitory inputs; external input consists of $K_{\\mathrm{ext}}$ independent Poisson sources at rate $\\nu_{\\mathrm{ext}}$.\n\nDefinitions and parameterization:\n\n- $N_E$ and $N_I$ are the sizes of the excitatory and inhibitory populations, respectively.\n- $p_E$ and $p_I$ are the connection probabilities from excitatory and inhibitory populations, respectively.\n- $J$ is the excitatory synaptic efficacy in millivolts; inhibitory synapses have efficacy $-g J$ where $g > 0$.\n- $\\tau_m$ is the membrane time constant in seconds.\n- $\\theta$ is the firing threshold in millivolts.\n- $V_r$ is the reset potential in millivolts.\n- $\\tau_{\\mathrm{ref}}$ is the absolute refractory period in seconds.\n- $K_{\\mathrm{ext}}$ is the number of external Poisson inputs per neuron.\n- $\\nu_{\\mathrm{ext}}$ is the external Poisson rate in $\\mathrm{s}^{-1}$.\n- The AI fixed-point is the pair $\\left(r_E, r_I\\right)$ in $\\mathrm{s}^{-1}$ such that applying the LIF transfer function to each populationâ€™s input statistics yields the same firing rates.\n\nImplementation requirements:\n\n- For each test case, compute the mean and variance of the total synaptic input to excitatory and inhibitory neurons from their sources, using the diffusion approximation with instantaneous synapses. You must use scientifically consistent expressions for the input mean and variance based on the parameters $\\left(N_E, N_I, p_E, p_I, J, g, \\tau_m, \\theta, V_r, \\tau_{\\mathrm{ref}}, K_{\\mathrm{ext}}, \\nu_{\\mathrm{ext}}\\right)$ and current firing rates $\\left(r_E, r_I\\right)$.\n- Implement the LIF transfer function that maps the input mean and variance to a stationary firing rate. Use a numerically stable form of the first-passage time integral for the LIF neuron under Gaussian input.\n- Use fixed-point iteration with relaxation to update $\\left(r_E, r_I\\right)$ until convergence. Convergence criterion: the maximum absolute change in the rates between successive iterations is less than $10^{-9}$ in $\\mathrm{s}^{-1}$, or a maximum number of $200$ iterations is reached. Use a relaxation coefficient in the open interval $(0, 1)$.\n- All firing rates in the final output must be expressed in $\\mathrm{s}^{-1}$.\n\nTest suite:\n\nYour program must solve the AI fixed-point for the following three parameter sets. For each set, start the iteration from the initial guess $r_E^{(0)} = r_I^{(0)} = \\nu_{\\mathrm{ext}}$.\n\n- Test case $1$ (typical balanced regime):\n  - $N_E = 4000$, $N_I = 1000$, $p_E = 0.1$, $p_I = 0.1$, $J = 0.1$ $\\mathrm{mV}$, $g = 5$, $\\tau_m = 0.02$ $\\mathrm{s}$, $\\theta = 20$ $\\mathrm{mV}$, $V_r = 10$ $\\mathrm{mV}$, $\\tau_{\\mathrm{ref}} = 0.002$ $\\mathrm{s}$, $K_{\\mathrm{ext}} = 1000$, $\\nu_{\\mathrm{ext}} = 10$ $\\mathrm{s}^{-1}$.\n- Test case $2$ (weak synapses with stronger inhibition and stronger external drive):\n  - $N_E = 8000$, $N_I = 2000$, $p_E = 0.05$, $p_I = 0.05$, $J = 0.05$ $\\mathrm{mV}$, $g = 6$, $\\tau_m = 0.02$ $\\mathrm{s}$, $\\theta = 20$ $\\mathrm{mV}$, $V_r = 10$ $\\mathrm{mV}$, $\\tau_{\\mathrm{ref}} = 0.002$ $\\mathrm{s}$, $K_{\\mathrm{ext}} = 1200$, $\\nu_{\\mathrm{ext}} = 12$ $\\mathrm{s}^{-1}$.\n- Test case $3$ (reduced external drive with moderate inhibition):\n  - $N_E = 4000$, $N_I = 1000$, $p_E = 0.1$, $p_I = 0.1$, $J = 0.1$ $\\mathrm{mV}$, $g = 4$, $\\tau_m = 0.02$ $\\mathrm{s}$, $\\theta = 20$ $\\mathrm{mV}$, $V_r = 10$ $\\mathrm{mV}$, $\\tau_{\\mathrm{ref}} = 0.002$ $\\mathrm{s}$, $K_{\\mathrm{ext}} = 800$, $\\nu_{\\mathrm{ext}} = 8$ $\\mathrm{s}^{-1}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the pair $\\left[r_E, r_I\\right]$ for the corresponding test case, expressed in $\\mathrm{s}^{-1}$. For example, the output format must be `[[r_E,1,r_I,1],[r_E,2,r_I,2],[r_E,3,r_I,3]]` with no additional text.",
            "solution": "The user-provided problem is a valid and well-posed task from the field of computational neuroscience. It requires the numerical computation of the stationary state (the Asynchronous Irregular fixed-point) of a Brunel network model. The problem statement is scientifically grounded, internally consistent, and provides all necessary parameters and methodological constraints to arrive at a unique, verifiable solution.\n\nThe core of the problem is to find a pair of firing rates, $(r_E, r_I)$, for the excitatory and inhibitory populations, respectively, that are self-consistent. This means that if the network populations fire at these rates, the resulting synaptic input to any given neuron must, in turn, produce an output firing rate equal to the one assumed. This self-consistency condition defines a fixed-point problem.\n\nThe solution proceeds in three main stages:\n1.  **Modeling Synaptic Input**: The total synaptic input to a neuron is approximated as a Gaussian white noise process. This is the \"diffusion approximation,\" justified by the Central Limit Theorem for a neuron receiving a large number of independent spike trains. The input is fully characterized by its mean ($\\mu$) and variance ($\\sigma^2$).\n2.  **Neuron Transfer Function**: The response of a single Leaky Integrate-and-Fire (LIF) neuron to this statistical input is captured by a transfer function, $\\Phi(\\mu, \\sigma)$, which gives the neuron's stationary output firing rate. This function is derived from the mean first-passage time of the neuron's membrane potential to cross the firing threshold.\n3.  **Fixed-Point Iteration**: The fixed-point rates $(r_E, r_I)$ are found by iteratively applying the transfer function. Starting with an initial guess, one computes the input statistics $(\\mu, \\sigma^2)$ generated by the current rates, then uses the transfer function to find the updated rates, and repeats this process until the rates converge.\n\nLet us formalize the steps.\n\n**1. Input Statistics $(\\mu, \\sigma^2)$**\n\nA neuron in either population (E or I) receives inputs from $K_E = p_E N_E$ excitatory neurons firing at rate $r_E$, $K_I = p_I N_I$ inhibitory neurons firing at rate $r_I$, and $K_{\\mathrm{ext}}$ external neurons firing at rate $\\nu_{\\mathrm{ext}}$.\nThe synaptic efficacies are $J$ (excitatory), $-gJ$ (inhibitory), and $J$ (external). The dynamics are described with instantaneous synapses.\nUnder the diffusion approximation, the mean input potential $\\mu_V$ and its variance $\\sigma_V^2$ are:\n$$\n\\mu_V(r_E, r_I) = \\tau_m \\left( (p_E N_E) J r_E - (p_I N_I) g J r_I + K_{\\mathrm{ext}} J \\nu_{\\mathrm{ext}} \\right)\n$$\n$$\n\\sigma_V^2(r_E, r_I) = \\tau_m \\left( (p_E N_E) J^2 r_E + (p_I N_I) (-gJ)^2 r_I + K_{\\mathrm{ext}} J^2 \\nu_{\\mathrm{ext}} \\right)\n$$\nSince the problem specifies that the connection probabilities ($p_E, p_I$) depend only on the source population and not the target, and all other parameters ($J, g, K_{\\mathrm{ext}}, \\nu_{\\mathrm{ext}}$) are also global, the input statistics are identical for both excitatory and inhibitory neurons. Let's denote them $\\mu(r_E, r_I)$ and $\\sigma^2(r_E, r_I)$.\n$$\n\\mu(r_E, r_I) = \\tau_m J (p_E N_E r_E - g p_I N_I r_I + K_{\\mathrm{ext}} \\nu_{\\mathrm{ext}})\n$$\n$$\n\\sigma^2(r_E, r_I) = \\tau_m J^2 (p_E N_E r_E + g^2 p_I N_I r_I + K_{\\mathrm{ext}} \\nu_{\\mathrm{ext}})\n$$\n\n**2. LIF Transfer Function $\\Phi(\\mu, \\sigma)$**\n\nThe stationary firing rate $\\nu$ for an LIF neuron is the reciprocal of the sum of the mean first-passage time and the absolute refractory period $\\tau_{\\mathrm{ref}}$. The mean first-passage time $\\langle T \\rangle$ is given by the Siegert formula:\n$$\n\\langle T \\rangle = \\tau_m \\sqrt{\\pi} \\int_{\\frac{V_r - \\mu}{\\sigma}}^{\\frac{\\theta - \\mu}{\\sigma}} e^{x^2} (1 + \\mathrm{erf}(x)) dx\n$$\nwhere $\\theta$ is the threshold, $V_r$ is the reset potential, and $\\mathrm{erf}(x)$ is the error function. The firing rate is then:\n$$\n\\nu = \\Phi(\\mu, \\sigma) = \\left( \\tau_{\\mathrm{ref}} + \\langle T \\rangle \\right)^{-1}\n$$\nThis integral must be computed numerically. Care must be taken as the term $e^{x^2}$ can lead to overflow if the upper integration limit, $(\\theta - \\mu)/\\sigma$, is large and positive. This corresponds to the mean input $\\mu$ being far below the threshold $\\theta$, in which case the firing rate is practically zero. A check is implemented to handle this case by returning a rate of $0$. A special case for zero noise ($\\sigma \\to 0$) is also handled.\n\n**3. Fixed-Point Iteration**\n\nWe seek the rates $(r_E, r_I)$ that satisfy the self-consistency equations:\n$$\nr_E = \\Phi(\\mu(r_E, r_I), \\sigma(r_E, r_I))\n$$\n$$\nr_I = \\Phi(\\mu(r_E, r_I), \\sigma(r_E, r_I))\n$$\nAs established, the input statistics and thus the transfer function's output are identical for both populations. If we start the iteration with $r_E^{(0)} = r_I^{(0)}$ (as specified by the problem, with $\\nu_{\\mathrm{ext}}$), all subsequent iterates will also have $r_E^{(k)} = r_I^{(k)}$. Therefore, the problem simplifies to finding a single fixed-point rate $r = r_E = r_I$.\n\nThe iteration scheme is:\n1.  Initialize $r^{(0)} = \\nu_{\\mathrm{ext}}$.\n2.  For $k=0, 1, 2, ...$:\n    a. Compute $\\mu_k = \\mu(r^{(k)}, r^{(k)})$ and $\\sigma_k = \\sqrt{\\sigma^2(r^{(k)}, r^{(k)})}$.\n    b. Compute the candidate new rate $r'_{new} = \\Phi(\\mu_k, \\sigma_k)$.\n    c. Update the rate using relaxation to improve stability: $r^{(k+1)} = (1-\\alpha) r^{(k)} + \\alpha r'_{new}$, where $\\alpha \\in (0,1)$ is the relaxation coefficient (chosen as $0.5$).\n3.  The iteration stops when $|r^{(k+1)} - r^{(k)}| < 10^{-9}$ or after $200$ iterations.\n\nThe final converged rate $r$ gives the solution $[r_E, r_I] = [r, r]$. This procedure is applied for each parameter set provided in the test suite.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\nfrom scipy.integrate import quad\n\ndef lif_transfer_function(mu, sigma, tau_m, V_r, theta, tau_ref):\n    \"\"\"\n    Calculates the stationary firing rate of a Leaky Integrate-and-Fire (LIF) neuron\n    driven by Gaussian white noise.\n\n    Args:\n        mu (float): Mean input potential (mV).\n        sigma (float): Standard deviation of input potential fluctuations (mV).\n        tau_m (float): Membrane time constant (s).\n        V_r (float): Reset potential (mV).\n        theta (float): Firing threshold (mV).\n        tau_ref (float): Absolute refractory period (s).\n\n    Returns:\n        float: The stationary firing rate in s^-1.\n    \"\"\"\n    # Handle the deterministic (zero noise) case\n    if sigma < 1e-12:\n        if mu <= theta:\n            return 0.0\n        else:\n            # Rate for constant super-threshold input\n            t_isi = tau_ref + tau_m * np.log((mu - V_r) / (mu - theta))\n            # Avoid division by zero or negative ISI\n            if t_isi <= 1e-12: return 1e9  # Effectively infinite rate, capped\n            return 1.0 / t_isi\n\n    # Define integration bounds for the first-passage time formula\n    low_bound = (V_r - mu) / sigma\n    high_bound = (theta - mu) / sigma\n\n    # If the mean input is far below threshold, the rate is effectively zero.\n    # This also prevents numerical overflow from exp(x^2) for large positive x.\n    if high_bound > 8: # A conservative heuristic cutoff\n        return 0.0\n        \n    # The integrand in the Siegert formula for the mean first-passage time\n    integrand = lambda x: np.exp(x**2) * (1.0 + erf(x))\n    \n    try:\n        integral_val, _ = quad(integrand, low_bound, high_bound)\n    except Exception:\n        # In case of integration failure, assume a negligible rate\n        return 0.0\n\n    # Mean first-passage time\n    tau_fp = tau_m * np.sqrt(np.pi) * integral_val\n    \n    # Total mean inter-spike interval\n    mean_isi = tau_ref + tau_fp\n    \n    # Avoid division by zero or negative ISI (due to numerical inaccuracies)\n    if mean_isi <= 1e-12:\n        return 1e9  # Capped \"infinite\" rate for safety\n        \n    rate = 1.0 / mean_isi\n    \n    return rate\n\ndef solve_fixed_point_brunel(params):\n    \"\"\"\n    Solves for the AI fixed-point of the Brunel network model using fixed-point iteration.\n    \"\"\"\n    # Unpack model parameters\n    N_E, N_I, p_E, p_I, J, g, tau_m, theta, V_r, tau_ref, K_ext, nu_ext = params\n\n    # Iteration control parameters\n    max_iter = 200\n    tolerance = 1e-9\n    relaxation = 0.5  # Relaxation coefficient for stability\n\n    # As derived in the solution, the input statistics for E and I populations\n    # are identical, leading to r_E = r_I at the fixed point. We solve for a single rate `r`.\n    r = float(nu_ext) # Initial guess\n\n    # Pre-calculate constant connection numbers\n    K_E_conn = p_E * N_E\n    K_I_conn = p_I * N_I\n\n    for _ in range(max_iter):\n        r_old = r\n        \n        # Calculate mean and variance of the input potential based on current rate `r`\n        mu_r_term = K_E_conn * r - g * K_I_conn * r\n        sigma_sq_r_term = K_E_conn * r + (g**2) * K_I_conn * r\n        \n        ext_input_mean_contrib = K_ext * nu_ext\n        ext_input_var_contrib = K_ext * nu_ext\n        \n        mu = tau_m * J * (mu_r_term + ext_input_mean_contrib)\n        sigma_sq = tau_m * J**2 * (sigma_sq_r_term + ext_input_var_contrib)\n        \n        sigma = np.sqrt(sigma_sq) if sigma_sq > 0 else 0.0\n        \n        # Compute the new candidate rate from the transfer function\n        r_new_candidate = lif_transfer_function(mu, sigma, tau_m, V_r, theta, tau_ref)\n        \n        # Apply relaxation to the update step\n        r = (1.0 - relaxation) * r_old + relaxation * r_new_candidate\n        \n        # Check for convergence\n        if abs(r - r_old) < tolerance:\n            break\n    \n    # The fixed-point rates for E and I populations are the same\n    return [r, r]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N_E, N_I, p_E, p_I, J, g, tau_m, theta, V_r, tau_ref, K_ext, nu_ext)\n        (4000, 1000, 0.1, 0.1, 0.1, 5.0, 0.02, 20.0, 10.0, 0.002, 1000, 10.0),\n        (8000, 2000, 0.05, 0.05, 0.05, 6.0, 0.02, 20.0, 10.0, 0.002, 1200, 12.0),\n        (4000, 1000, 0.1, 0.1, 0.1, 4.0, 0.02, 20.0, 10.0, 0.002, 800, 8.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Calculate the fixed-point rates for the current case.\n        result = solve_fixed_point_brunel(case)\n        results.append(result)\n\n    # Format the results into the exact required string format.\n    results_str_list = [f\"[{r_e},{r_i}]\" for r_e, r_i in results]\n    final_output = f\"[{','.join(results_str_list)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```"
        },
        {
            "introduction": "After identifying a stationary state for the network, the next critical question is whether this state is stable. Will the network return to its operating point after a small perturbation, or will the perturbation grow, leading to different dynamics like oscillations? This advanced practice  delves into the linear stability analysis of the network's fixed point, accounting for the crucial role of synaptic transmission delays. You will learn to determine stability by finding the roots of the system's characteristic equation and examining their real parts.",
            "id": "3966918",
            "problem": "Consider a linearization of the Brunel balanced network model around an asynchronous fixed point, modeled at the population rate level. Let $W \\in \\mathbb{C}^{n \\times n}$ denote the effective synaptic connectivity matrix between $n$ populations (excitatory and inhibitory), and let $g \\in \\mathbb{R}$ be the constant neuronal transfer function gain obtained from the linearization of the input-output relation of the spiking populations. Assume a uniform axonal and synaptic transmission delay $D > 0$ shared by all connections. Under small perturbations $\\delta r(t)$ of the population rates, the linearized delayed system can be expressed as\n$$\n\\delta r(t) - g\\,W\\,\\delta r(t-D) = 0.\n$$\nSeeking modal solutions of the form $\\delta r(t) = v e^{\\lambda t}$ with $v \\neq 0$ leads to the characteristic equation\n$$\n\\det\\!\\left(I - g\\,W\\,e^{-\\lambda D}\\right) = 0,\n$$\nwhere $I$ is the identity matrix, $\\lambda \\in \\mathbb{C}$ is an eigenvalue of the delayed linearized system, and $e^{-\\lambda D}$ is understood as the complex exponential with the angle in radians. The system is linearly stable if and only if $\\mathrm{Re}(\\lambda) < 0$ for all characteristic roots $\\lambda$, and unstable if there exists at least one $\\lambda$ with $\\mathrm{Re}(\\lambda) > 0$. Borderline cases with $\\mathrm{Re}(\\lambda) = 0$ are not considered stable.\n\nStarting from fundamental principles of linear systems with delay and the above characteristic equation, implement a program that for each test case:\n- Computes all eigenvalues $\\lambda \\in \\mathbb{C}$ implied by the characteristic equation within a bounded imaginary frequency window $|\\mathrm{Im}(\\lambda)| \\leq \\Omega_{\\max}$, where angles are in radians.\n- Interprets stability strictly in terms of the real parts $\\mathrm{Re}(\\lambda)$ as described above.\n\nUse the following test suite, where matrices are given as lists of lists. All delays $D$ must be treated in seconds, $g$ is unitless, and $\\Omega_{\\max}$ is an angular frequency bound in radians per second.\n\nTest cases:\n1. $W = \\begin{bmatrix}0.6 & 0.0 \\\\ 0.0 & -0.7\\end{bmatrix}$, $g = 0.8$, $D = 0.003$ s, $\\Omega_{\\max} = 6000$ rad/s.\n2. $W = \\begin{bmatrix}1.6 & 0.0 \\\\ 0.0 & -0.9\\end{bmatrix}$, $g = 0.9$, $D = 0.004$ s, $\\Omega_{\\max} = 6000$ rad/s.\n3. $W = \\begin{bmatrix}1.25 & 0.0 \\\\ 0.0 & 0.0\\end{bmatrix}$, $g = 0.8$, $D = 0.005$ s, $\\Omega_{\\max} = 6000$ rad/s.\n4. $W = \\begin{bmatrix}0.5 & -0.8 \\\\ 0.8 & 0.5\\end{bmatrix}$, $g = 0.9$, $D = 0.0025$ s, $\\Omega_{\\max} = 8000$ rad/s.\n\nRequirements for computation and output:\n- For each test case, treat the connectivity as $g\\,W$ and compute all characteristic roots $\\lambda$ within the specified imaginary bound. Your algorithm must account for the multivalued nature of the complex logarithm induced by the delay, ensuring that all branches of solutions within the window are covered.\n- Determine stability by checking whether the maximum real part among all computed $\\lambda$ is strictly negative.\n- The final output from your program must be a single line containing a comma-separated list of the stability result for each test case, in the order listed above, enclosed in square brackets. Each result must be a boolean. For example, a possible output format is `[True,False,True,True]`.\n\nYour program must be self-contained and must not require any user input. Angles must be interpreted in radians, and delays must be in seconds throughout.",
            "solution": "The problem requires an analysis of the linear stability of a delayed network model. The stability is determined by the roots $\\lambda \\in \\mathbb{C}$ of the characteristic equation:\n$$\n\\det\\!\\left(I - g\\,W\\,e^{-\\lambda D}\\right) = 0\n$$\nwhere $I$ is the $n \\times n$ identity matrix, $W \\in \\mathbb{C}^{n \\times n}$ is the effective connectivity matrix, $g \\in \\mathbb{R}$ is the neuronal gain, and $D > 0$ is a uniform delay. A solution of the form $\\delta r(t) = v e^{\\lambda t}$ represents a mode of the linearized system. The system is stable if and only if $\\mathrm{Re}(\\lambda) < 0$ for all such characteristic roots $\\lambda$. A root with $\\mathrm{Re}(\\lambda) \\geq 0$ implies instability.\n\nThe core of the problem is to find the roots $\\lambda$ of this transcendental equation. This can be simplified by considering the eigenvalues of the matrix $W$. Let $\\mu_j$ for $j=1, \\dots, n$ be the eigenvalues of $W$. The eigenvalues of the matrix $I - g\\,W\\,e^{-\\lambda D}$ are then $1 - g\\,\\mu_j\\,e^{-\\lambda D}$. The determinant of a matrix is the product of its eigenvalues. Therefore, the characteristic equation is satisfied if and only if at least one of these eigenvalues is zero:\n$$\n1 - g\\,\\mu_j\\,e^{-\\lambda D} = 0 \\quad \\text{for some } j \\in \\{1, \\dots, n\\}\n$$\nThis reduces the problem from solving a complex matrix-valued equation to solving a set of scalar equations, one for each eigenvalue $\\mu_j$ of $W$.\n\nFor any non-zero eigenvalue $\\mu_j$, we can rearrange the scalar equation as:\n$$\ng\\,\\mu_j\\,e^{-\\lambda D} = 1\n$$\nor\n$$\ne^{\\lambda D} = g\\,\\mu_j\n$$\nIf $\\mu_j = 0$, the equation becomes $1 = 0$, which is impossible. Thus, zero eigenvalues of $W$ do not generate any characteristic roots $\\lambda$ for the system.\n\nTo solve for $\\lambda \\in \\mathbb{C}$, we take the complex natural logarithm of both sides. For a non-zero complex number $z = |z|e^{i\\arg(z)}$, its logarithm is a multi-valued function given by $\\ln(z) = \\ln|z| + i(\\arg(z) + 2\\pi k)$ for any integer $k \\in \\mathbb{Z}$. Applying this to our equation gives:\n$$\n\\lambda D = \\ln(g\\,\\mu_j) = \\ln|g\\,\\mu_j| + i(\\arg(g\\,\\mu_j) + 2\\pi k)\n$$\nThis yields an infinite set of solutions for $\\lambda$, indexed by $j$ and $k$:\n$$\n\\lambda_{j,k} = \\frac{\\ln|g\\,\\mu_j|}{D} + i \\frac{\\arg(g\\,\\mu_j) + 2\\pi k}{D}\n$$\nThe real part $\\mathrm{Re}(\\lambda)$ and imaginary part $\\mathrm{Im}(\\lambda)$ of each root are:\n$$\n\\mathrm{Re}(\\lambda_{j,k}) = \\frac{\\ln|g\\,\\mu_j|}{D}\n$$\n$$\n\\mathrm{Im}(\\lambda_{j,k}) = \\frac{\\arg(g\\,\\mu_j) + 2\\pi k}{D}\n$$\nA crucial observation is that for a given eigenvalue $\\mu_j$ of $W$, the real part of every corresponding root $\\lambda_{j,k}$ is constant, independent of the branch index $k$. Stability is determined by the sign of this real part. The system is stable if and only if $\\mathrm{Re}(\\lambda_{j,k}) < 0$ for all $j$ and $k$. This is equivalent to requiring $\\ln|g\\,\\mu_j|/D < 0$ for all $j$, which simplifies to $|g\\,\\mu_j| < 1$ for all eigenvalues $\\mu_j$ of $W$.\n\nThe problem requires us to find all roots within a specified frequency window $|\\mathrm{Im}(\\lambda)| \\leq \\Omega_{\\max}$. For each eigenvalue $\\mu_j$, we must find all integers $k$ that satisfy this condition:\n$$\n\\left| \\frac{\\arg(g\\,\\mu_j) + 2\\pi k}{D} \\right| \\leq \\Omega_{\\max}\n$$\nThis inequality can be solved for $k$:\n$$\n-D\\Omega_{\\max} \\leq \\arg(g\\,\\mu_j) + 2\\pi k \\leq D\\Omega_{\\max}\n$$\n$$\n\\frac{-D\\Omega_{\\max} - \\arg(g\\,\\mu_j)}{2\\pi} \\leq k \\leq \\frac{D\\Omega_{\\max} - \\arg(g\\,\\mu_j)}{2\\pi}\n$$\nThe range of valid integers for $k$ is found by taking the ceiling of the lower bound and the floor of the upper bound.\n\nThe computational algorithm for each test case is as follows:\n1.  Given the parameters $W$, $g$, $D$, and $\\Omega_{\\max}$.\n2.  Compute the set of eigenvalues $\\{\\mu_j\\}$ of the matrix $W$.\n3.  Initialize an empty list to store the computed characteristic roots $\\lambda$.\n4.  For each eigenvalue $\\mu_j$:\n    a. If $|\\mu_j|$ is close to $0$, this branch contributes no roots, so we skip it.\n    b. Calculate the complex value $c_j = g\\,\\mu_j$.\n    c. Calculate the real part for this family of roots: $\\alpha_j = \\ln|c_j|/D$.\n    d. Determine the integer range $[k_{\\min}, k_{\\max}]$ for the index $k$ using the bounds derived from $\\Omega_{\\max}$.\n    e. For each integer $k$ from $k_{\\min}$ to $k_{\\max}$, compute the imaginary part $\\omega_{j,k} = (\\arg(c_j) + 2\\pi k)/D$.\n    f. Construct the root $\\lambda_{j,k} = \\alpha_j + i \\omega_{j,k}$ and add it to the list of roots.\n5.  After iterating through all $\\mu_j$, find the maximum real part among all computed roots in the list.\n6.  If the list of roots is empty, the stability condition is vacuously satisfied, and the system is deemed stable. This can happen if all $\\mu_j=0$.\n7.  If the maximum real part is strictly less than $0$, the system is stable. Otherwise, it is unstable. The result is recorded as a boolean value.\n\nThis procedure correctly identifies all characteristic roots within the specified frequency window and determines the system's stability based on the specified criterion.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the stability of a linearized Brunel balanced network model\n    for a series of test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"W\": np.array([[0.6, 0.0], [0.0, -0.7]]),\n            \"g\": 0.8,\n            \"D\": 0.003,\n            \"Omega_max\": 6000.0,\n        },\n        {\n            \"W\": np.array([[1.6, 0.0], [0.0, -0.9]]),\n            \"g\": 0.9,\n            \"D\": 0.004,\n            \"Omega_max\": 6000.0,\n        },\n        {\n            \"W\": np.array([[1.25, 0.0], [0.0, 0.0]]),\n            \"g\": 0.8,\n            \"D\": 0.005,\n            \"Omega_max\": 6000.0,\n        },\n        {\n            \"W\": np.array([[0.5, -0.8], [0.8, 0.5]]),\n            \"g\": 0.9,\n            \"D\": 0.0025,\n            \"Omega_max\": 8000.0,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        W = case[\"W\"]\n        g = case[\"g\"]\n        D = case[\"D\"]\n        Omega_max = case[\"Omega_max\"]\n\n        # Step 1: Compute eigenvalues of the connectivity matrix W\n        mu_eigenvalues = np.linalg.eigvals(W)\n\n        all_lambdas = []\n        \n        # Step 2: For each eigenvalue mu_j of W, find all system roots lambda\n        for mu_j in mu_eigenvalues:\n            # A zero eigenvalue mu_j leads to 1 = 0, so no solutions.\n            # We use a small tolerance for floating point comparison.\n            if np.abs(mu_j) < 1e-15:\n                continue\n\n            # Calculate the complex factor c_j = g * mu_j\n            c_j = g * mu_j\n            \n            # The real part of lambda is constant for all branches k from mu_j\n            alpha_j = np.log(np.abs(c_j)) / D\n            \n            # The principal argument of c_j\n            arg_c_j = np.angle(c_j)\n            \n            # Step 3: Determine the range of integer indices k for the frequency window\n            k_lower_bound = (-D * Omega_max - arg_c_j) / (2 * np.pi)\n            k_upper_bound = (D * Omega_max - arg_c_j) / (2 * np.pi)\n            \n            k_min = int(np.ceil(k_lower_bound))\n            k_max = int(np.floor(k_upper_bound))\n\n            # Step 4: Compute all lambda roots within the window\n            if k_min <= k_max:\n                for k in range(k_min, k_max + 1):\n                    omega_jk = (arg_c_j + 2 * np.pi * k) / D\n                    lambda_jk = alpha_j + 1j * omega_jk\n                    all_lambdas.append(lambda_jk)\n\n        # Step 5: Determine stability based on the maximum real part\n        is_stable = True\n        if not all_lambdas:\n            # If no roots are found (e.g., all mu_j are 0), the condition\n            # Re(lambda) < 0 for all lambda is vacuously true.\n            is_stable = True\n        else:\n            max_real_part = -np.inf\n            for lam in all_lambdas:\n                if lam.real > max_real_part:\n                    max_real_part = lam.real\n            \n            # Stability requires the maximum real part to be strictly negative.\n            # Borderline cases Re(lambda) = 0 are considered unstable.\n            if max_real_part >= -1e-9: # Use a small tolerance for zero\n                is_stable = False\n        \n        results.append(is_stable)\n\n    # Format the final output as a string representing a list of booleans\n    output_str = f\"[{','.join(str(r).lower() for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        }
    ]
}