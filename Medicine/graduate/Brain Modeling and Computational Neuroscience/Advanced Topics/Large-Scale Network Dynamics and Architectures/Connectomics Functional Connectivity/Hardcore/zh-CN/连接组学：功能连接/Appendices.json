{
    "hands_on_practices": [
        {
            "introduction": "在连接组学中，一个核心的挑战是区分真实的神经交互和由共同输入引起的虚假相关性。这个练习通过一个动手模拟来建立对这个概念的直观理解。通过构建包含和不包含直接连接的场景，我们将看到偏相关（与简单相关不同）如何帮助我们揭示真实的底层网络结构，这是解释功能连接图谱时至关重要的一步 。",
            "id": "3972305",
            "problem": "您将构建并分析来自线性高斯结构方程模型的模拟数据，以研究潜在的共同驱动因素如何引发虚假的成对关联，以及对该驱动因素进行条件化如何消除这些关联。该设定直接适用于功能连接性分析，其中观察到的节点活动可能共同受到未观察到或观察到的共同输入的影响。\n\n从以下基本原理开始：\n- 对于一个均值为零的随机向量 $X \\in \\mathbb{R}^p$，其协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$，分量 $X_i$ 和 $X_j$ 之间的协方差是 $\\operatorname{Cov}(X_i,X_j) = \\Sigma_{ij}$，方差是 $\\operatorname{Var}(X_i) = \\Sigma_{ii}$。\n- $X_i$ 和 $X_j$ 之间的皮尔逊相关性定义为 $\\rho_{ij} = \\dfrac{\\Sigma_{ij}}{\\sqrt{\\Sigma_{ii}\\Sigma_{jj}}}$。\n- 对于联合高斯向量，在给定条件集 $S$ 的情况下，$X_i$ 和 $X_j$ 之间的偏相关等于将 $X_i$ 和 $X_j$ 对 $X_S$ 进行线性回归后残差的相关性。等价地，对于一个精度矩阵为 $K = \\Sigma^{-1}$ 的联合高斯向量，在给定所有其他变量的情况下，$X_i$ 和 $X_j$ 之间的偏相关是 $\\rho_{ij \\cdot \\text{others}} = -\\dfrac{K_{ij}}{\\sqrt{K_{ii} K_{jj}}}$。\n\n您的任务是实现一个程序，该程序模拟四个测试用例，从模拟数据中估计样本协方差，并计算由观测集和条件集决定的样本相关性和样本偏相关性。当您对观测集中除感兴趣的两个变量之外的所有变量进行条件化时，必须使用偏相关的精度矩阵表征。数据生成模型遵循具有独立高斯噪声和零均值的线性结构方程。所有变量都是无量纲的。不涉及角度。不存在物理单位。\n\n设 $\\varepsilon_x, \\varepsilon_y, \\varepsilon_w$ 表示相互独立的高斯噪声项，其方差分别为 $\\sigma_x^2, \\sigma_y^2, \\sigma_w^2$。设 $Z$ 表示一个方差为 $\\sigma_z^2$ 的高斯共同驱动因素。设 $W$ 是一个存在时的独立高斯控制变量。设 $a, b, c$ 表示标量系数。测试套件的模拟参数如下：\n\n- 测试 A（观察到的共同驱动因素，无直接边）：\n  - 结构方程：$Z \\sim \\mathcal{N}(0,\\sigma_z^2)$, $X = a Z + \\varepsilon_x$, $Y = b Z + \\varepsilon_y$。\n  - 参数：$a = 0.9$, $b = 0.7$, $\\sigma_z^2 = 1.0$, $\\sigma_x^2 = 1.0$, $\\sigma_y^2 = 1.0$。\n  - 样本量：$N = 100000$。\n  - 观测变量：$[X,Y,Z]$；计算 $X$ 和 $Y$ 之间的相关性，以及在给定 $Z$ 的条件下 $X$ 和 $Y$ 之间的偏相关性。\n\n- 测试 B（潜在共同驱动因素未被观察到，对无关控制变量进行条件化）：\n  - 结构方程：$Z \\sim \\mathcal{N}(0,\\sigma_z^2)$, $W \\sim \\mathcal{N}(0,\\sigma_w^2)$ 独立于 $Z$, $X = a Z + \\varepsilon_x$, $Y = b Z + \\varepsilon_y$。\n  - 参数：$a = 0.9$, $b = 0.7$, $\\sigma_z^2 = 1.0$, $\\sigma_x^2 = 1.0$, $\\sigma_y^2 = 1.0$, $\\sigma_w^2 = 1.0$。\n  - 样本量：$N = 100000$。\n  - 观测变量：$[X,Y,W]$（共同驱动因素 $Z$ 未被观察到）；计算 $X$ 和 $Y$ 之间的相关性，以及在给定 $W$ 的条件下 $X$ 和 $Y$ 之间的偏相关性。\n\n- 测试 C（观察到的共同驱动因素，并附加一条直接边）：\n  - 结构方程：$Z \\sim \\mathcal{N}(0,\\sigma_z^2)$, $X = a Z + \\varepsilon_x$, $Y = b Z + c X + \\varepsilon_y$。\n  - 参数：$a = 0.9$, $b = 0.7$, $c = 0.5$, $\\sigma_z^2 = 1.0$, $\\sigma_x^2 = 1.0$, $\\sigma_y^2 = 1.0$。\n  - 样本量：$N = 100000$。\n  - 观测变量：$[X,Y,Z]$；计算 $X$ 和 $Y$ 之间的相关性，以及在给定 $Z$ 的条件下 $X$ 和 $Y$ 之间的偏相关性。\n\n- 测试 D（无共同驱动因素，无直接边）：\n  - 结构方程：$X = \\varepsilon_x$, $Y = \\varepsilon_y$, $W = \\varepsilon_w$。\n  - 参数：$\\sigma_x^2 = 1.0$, $\\sigma_y^2 = 1.0$, $\\sigma_w^2 = 1.0$。\n  - 样本量：$N = 100000$。\n  - 观测变量：$[X,Y,W]$；计算 $X$ 和 $Y$ 之间的相关性，以及在给定 $W$ 的条件下 $X$ 和 $Y$ 之间的偏相关性。\n\n对于每个测试，计算：\n- 从该测试的观测变量中估计出的 $X$ 和 $Y$ 之间的样本皮尔逊相关性。\n- 在给定该测试的指定条件集的情况下，$X$ 和 $Y$ 之间的样本偏相关性，通过观测变量的样本协方差矩阵的逆及其对应的精度子矩阵条目计算。\n\n为每个测试报告三个输出：\n- $X$ 和 $Y$ 之间的样本相关性，四舍五入到三位小数。\n- 在给定指定条件集的情况下，$X$ 和 $Y$ 之间的样本偏相关性，四舍五入到三位小数。\n- 一个布尔标志，定义为 $\\lvert \\text{偏相关} \\rvert  \\tau$，阈值为 $\\tau = 0.05$，表示条件化是否移除了虚假边。\n\n您的程序必须：\n- 使用固定的随机种子以保证可复现性。\n- 根据上述结构方程和参数模拟高斯数据。\n- 从模拟数据中估计所需的量。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序必须完全如下：\n  $[\\text{corr}\\_A, \\text{pcor}\\_A, \\text{removed}\\_A, \\text{corr}\\_B, \\text{pcor}\\_B, \\text{removed}\\_B, \\text{corr}\\_C, \\text{pcor}\\_C, \\text{removed}\\_C, \\text{corr}\\_D, \\text{pcor}\\_D, \\text{removed}\\_D]$。\n所有浮点值必须四舍五入到三位小数。布尔值必须是未四舍五入的逻辑值。\n\n最终输出必须是包含此列表的单行，且无附加文本。不涉及物理单位，也不需要角度或百分比。",
            "solution": "任务是从四个不同的线性高斯结构方程模型 (SEMs) 中模拟数据，以在功能连接性的背景下探索边际相关和偏相关的概念。具体来说，我们将研究一个共同驱动因素如何能在两个变量之间引发虚假相关，以及对该驱动因素进行条件化如何能正确识别出直接联系的缺失。反之，我们也将看到一个真实的直接联系如何以非零偏相关的形式持续存在。该分析依赖于多元高斯分布的基本原理。\n\n对于一组p个均值为零的联合高斯随机变量，设其向量为 $V \\in \\mathbb{R}^p$，协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{p \\times p}$。两个变量 $V_i$ 和 $V_j$ 之间的皮尔逊相关性定义为：\n$$\n\\rho_{ij} = \\frac{\\operatorname{Cov}(V_i, V_j)}{\\sqrt{\\operatorname{Var}(V_i)\\operatorname{Var}(V_j)}} = \\frac{\\Sigma_{ij}}{\\sqrt{\\Sigma_{ii}\\Sigma_{jj}}}\n$$\n在给定集合中所有其他变量（表示为 $V_{\\setminus \\{i, j\\}}$）的情况下，$V_i$ 和 $V_j$ 之间的偏相关是剔除所有其他变量的线性效应后，它们之间线性关联的度量。对于多元高斯分布，这可以方便地通过精度矩阵 $K = \\Sigma^{-1}$ 计算得出：\n$$\n\\rho_{ij \\cdot \\text{rest}} = -\\frac{K_{ij}}{\\sqrt{K_{ii}K_{jj}}}\n$$\n我们将为四个测试用例中的每一个模拟数据，从模拟数据向量中估计样本协方差矩阵 $\\hat{\\Sigma}$，然后使用上述公式，将 $\\hat{\\Sigma}$ 及其逆矩阵（即样本精度矩阵 $\\hat{K} = \\hat{\\Sigma}^{-1}$）代入，计算样本皮尔逊相关性和样本偏相关性。使用固定的随机种子和 $N=100000$ 的大样本量以确保结果的可复现性和统计稳定性。\n\n每个测试用例的流程如下：\n1.  为具有指定方差的独立高斯变量（$Z$, $W$, $\\varepsilon_x$, $\\varepsilon_y$, $\\varepsilon_w$）生成 $N=100000$ 个样本。\n2.  根据该测试用例给定的结构方程构造观测变量（$X$, $Y$, 以及 $Z$ 或 $W$）。\n3.  将观测变量排列成形状为 $(p, N)$ 的数据矩阵，其中 $p=3$。\n4.  从该数据计算 $3 \\times 3$ 的样本协方差矩阵 $\\hat{\\Sigma}$ 和样本相关矩阵。皮尔逊相关性 $\\rho_{XY}$ 是相关矩阵的 $(0,1)$ 项（假设 $X$ 是第一个变量，$Y$ 是第二个变量）。\n5.  对样本协方差矩阵求逆以获得样本精度矩阵 $\\hat{K} = \\hat{\\Sigma}^{-1}$。\n6.  使用 $\\hat{K}$ 的相应条目计算样本偏相关 $\\rho_{XY \\cdot \\text{given}}$。\n7.  确定一个布尔标志 `removed`，定义为 $|\\rho_{XY \\cdot \\text{given}}|  \\tau$，阈值为 $\\tau = 0.05$。\n\n以下是每个具体测试用例的分析。\n\n测试 A：观察到的共同驱动因素 ($X \\leftarrow Z \\rightarrow Y$)\n模型为 $X = aZ + \\varepsilon_x$ 和 $Y = bZ + \\varepsilon_y$，其中 $a=0.9$，$b=0.7$。共同驱动因素 $Z$ 是可观察的。$X$ 和 $Y$ 之间没有直接联系。$X$ 和 $Y$ 之间的相关性完全是因为它们共享一个共同原因 $Z$。理论相关性为 $\\operatorname{Corr}(X,Y) = \\frac{ab\\sigma_z^2}{\\sqrt{(a^2\\sigma_z^2+\\sigma_x^2)(b^2\\sigma_z^2+\\sigma_y^2)}} \\approx 0.384$。当我们以 $Z$ 为条件时，我们阻断了连接 $X$ 和 $Y$ 的唯一路径。它们的条件关系由独立的残差 $\\varepsilon_x$ 和 $\\varepsilon_y$ 决定。因此，偏相关 $\\rho_{XY|Z}$ 预期为 $0$。样本估计值应非常接近 $0$，并且 `removed` 标志应为 `True`。\n\n测试 B：潜在共同驱动因素 ($X \\leftarrow Z \\rightarrow Y$，以无关变量 $W$ 为条件)\n$X$ 和 $Y$ 的模型与测试 A 相同，但共同驱动因素 $Z$ 是未被观察到的（潜在的）。取而代之，我们观察一个独立变量 $W$。由于潜在的共同原因，$X$ 和 $Y$ 之间的相关性与测试 A 中相同（$\\approx 0.384$）。以 $W$ 为条件，而 $W$ 在统计上独立于 $X$、$Y$ 和 $Z$，这不会提供关于它们之间关系的任何信息。因此，偏相关 $\\rho_{XY|W}$ 预期与边际相关 $\\rho_{XY}$ 相同。偏相关的样本估计值应接近样本边际相关值，并且 `removed` 标志应为 `False`。\n\n测试 C：共同驱动因素和直接边 ($X \\leftarrow Z \\rightarrow Y \\leftarrow X$)\n模型为 $X = aZ + \\varepsilon_x$ 和 $Y = bZ + cX + \\varepsilon_y$，其中 $a=0.9$，$b=0.7$，$c=0.5$。在这里，$Y$ 受 $Z$ 的影响，既有直接影响，也有通过 $X$ 的间接影响。有两条路径在 $X$ 和 $Y$ 之间产生相关性：混杂路径 $X \\leftarrow Z \\rightarrow Y$ 和直接路径 $X \\rightarrow Y$。边际相关 $\\rho_{XY}$ 会很强，反映了这两种贡献。当我们以共同驱动因素 $Z$ 为条件时，我们阻断了混杂路径。然而，$X$ 对 $Y$ 的直接影响（项 $cX$）仍然存在。因此，偏相关 $\\rho_{XY|Z}$ 将非零，捕捉了这种直接联系的强度。预期的偏相关约为 $\\approx 0.447$。`removed` 标志应为 `False`。\n\n测试 D：独立变量\n模型为 $X = \\varepsilon_x$，$Y = \\varepsilon_y$，$W = \\varepsilon_w$。根据定义，所有三个观测变量都是相互独立的。没有结构路径连接 $X$ 和 $Y$。因此，边际相关 $\\rho_{XY}$ 和偏相关 $\\rho_{XY|W}$ 的理论值都为 $0$。由于抽样变异性，样本估计值将是在 $0$ 附近波动的很小的值。两者都应远低于阈值 $\\tau=0.05$，因此 `removed` 标志预期为 `True`。\n\n现在，实现将继续从模拟数据中计算这些值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Simulates data from four structural equation models, computes sample\n    correlation and partial correlation, and determines if conditioning removes\n    the association.\n    \"\"\"\n    \n    # Set up global parameters\n    N = 100000\n    rng = np.random.default_rng(seed=0)\n    tau = 0.05\n    all_results = []\n\n    # --- Test Case A: Observed Common Driver ---\n    a = 0.9\n    b = 0.7\n    sigma_z_sq, sigma_x_sq, sigma_y_sq = 1.0, 1.0, 1.0\n\n    Z = rng.normal(loc=0, scale=np.sqrt(sigma_z_sq), size=N)\n    eps_x = rng.normal(loc=0, scale=np.sqrt(sigma_x_sq), size=N)\n    eps_y = rng.normal(loc=0, scale=np.sqrt(sigma_y_sq), size=N)\n\n    X = a * Z + eps_x\n    Y = b * Z + eps_y\n    \n    # Observed variables: [X, Y, Z]\n    data_A = np.vstack([X, Y, Z])\n    \n    # Pearson correlation rho(X, Y)\n    corr_mat_A = np.corrcoef(data_A)\n    corr_A = corr_mat_A[0, 1]\n\n    # Partial correlation rho(X, Y | Z) via precision matrix\n    cov_mat_A = np.cov(data_A)\n    prec_mat_A = np.linalg.inv(cov_mat_A)\n    pcorr_A = -prec_mat_A[0, 1] / np.sqrt(prec_mat_A[0, 0] * prec_mat_A[1, 1])\n\n    removed_A = abs(pcorr_A)  tau\n    all_results.extend([round(corr_A, 3), round(pcorr_A, 3), removed_A])\n\n    # --- Test Case B: Latent Common Driver ---\n    a = 0.9\n    b = 0.7\n    sigma_z_sq, sigma_x_sq, sigma_y_sq, sigma_w_sq = 1.0, 1.0, 1.0, 1.0\n\n    Z_latent = rng.normal(loc=0, scale=np.sqrt(sigma_z_sq), size=N)\n    W = rng.normal(loc=0, scale=np.sqrt(sigma_w_sq), size=N)\n    eps_x = rng.normal(loc=0, scale=np.sqrt(sigma_x_sq), size=N)\n    eps_y = rng.normal(loc=0, scale=np.sqrt(sigma_y_sq), size=N)\n\n    X = a * Z_latent + eps_x\n    Y = b * Z_latent + eps_y\n\n    # Observed variables: [X, Y, W]\n    data_B = np.vstack([X, Y, W])\n\n    # Pearson correlation rho(X, Y)\n    corr_mat_B = np.corrcoef(data_B)\n    corr_B = corr_mat_B[0, 1]\n\n    # Partial correlation rho(X, Y | W)\n    cov_mat_B = np.cov(data_B)\n    prec_mat_B = np.linalg.inv(cov_mat_B)\n    pcorr_B = -prec_mat_B[0, 1] / np.sqrt(prec_mat_B[0, 0] * prec_mat_B[1, 1])\n\n    removed_B = abs(pcorr_B)  tau\n    all_results.extend([round(corr_B, 3), round(pcorr_B, 3), removed_B])\n\n    # --- Test Case C: Common Driver and Direct Edge ---\n    a = 0.9\n    b = 0.7\n    c = 0.5\n    sigma_z_sq, sigma_x_sq, sigma_y_sq = 1.0, 1.0, 1.0\n    \n    Z = rng.normal(loc=0, scale=np.sqrt(sigma_z_sq), size=N)\n    eps_x = rng.normal(loc=0, scale=np.sqrt(sigma_x_sq), size=N)\n    eps_y = rng.normal(loc=0, scale=np.sqrt(sigma_y_sq), size=N)\n\n    X = a * Z + eps_x\n    Y = b * Z + c * X + eps_y\n    \n    # Observed variables: [X, Y, Z]\n    data_C = np.vstack([X, Y, Z])\n\n    # Pearson correlation rho(X, Y)\n    corr_mat_C = np.corrcoef(data_C)\n    corr_C = corr_mat_C[0, 1]\n\n    # Partial correlation rho(X, Y | Z)\n    cov_mat_C = np.cov(data_C)\n    prec_mat_C = np.linalg.inv(cov_mat_C)\n    pcorr_C = -prec_mat_C[0, 1] / np.sqrt(prec_mat_C[0, 0] * prec_mat_C[1, 1])\n\n    removed_C = abs(pcorr_C)  tau\n    all_results.extend([round(corr_C, 3), round(pcorr_C, 3), removed_C])\n\n    # --- Test Case D: No Common Driver, No Direct Edge ---\n    sigma_x_sq, sigma_y_sq, sigma_w_sq = 1.0, 1.0, 1.0\n\n    X = rng.normal(loc=0, scale=np.sqrt(sigma_x_sq), size=N)\n    Y = rng.normal(loc=0, scale=np.sqrt(sigma_y_sq), size=N)\n    W = rng.normal(loc=0, scale=np.sqrt(sigma_w_sq), size=N)\n\n    # Observed variables: [X, Y, W]\n    data_D = np.vstack([X, Y, W])\n    \n    # Pearson correlation rho(X, Y)\n    corr_mat_D = np.corrcoef(data_D)\n    corr_D = corr_mat_D[0, 1]\n\n    # Partial correlation rho(X, Y | W)\n    cov_mat_D = np.cov(data_D)\n    prec_mat_D = np.linalg.inv(cov_mat_D)\n    pcorr_D = -prec_mat_D[0, 1] / np.sqrt(prec_mat_D[0, 0] * prec_mat_D[1, 1])\n\n    removed_D = abs(pcorr_D)  tau\n    all_results.extend([round(corr_D, 3), round(pcorr_D, 3), removed_D])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在功能连接分析中，仅仅计算相关性是不够的；我们还必须对其统计显著性进行评估。诸如功能性磁共振成像（fMRI）等神经时间序列数据通常表现出强烈的时间自相关性，这违反了标准统计检验的独立性假设。本练习通过为自相关过程推导“有效样本量”的概念，深入探讨了这个问题，这是在功能连接研究中获得有效 $p$ 值和置信区间的关键步骤 。",
            "id": "3972358",
            "problem": "考虑两个大脑区域，它们的自发活动通过功能性磁共振成像（fMRI）测量，并通过时间去均值和方差归一化进行预处理。假设得到的时间序列 $\\{X_t\\}_{t=1}^{n}$ 和 $\\{Y_t\\}_{t=1}^{n}$ 被建模为两个零均值、单位方差、独立、平稳的一阶高斯自回归（AR）过程，\n$$\nX_t = \\phi_x X_{t-1} + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0,\\sigma_x^2), \\quad |\\phi_x|1,\n$$\n$$\nY_t = \\phi_y Y_{t-1} + \\eta_t, \\quad \\eta_t \\sim \\mathcal{N}(0,\\sigma_y^2), \\quad |\\phi_y|1,\n$$\n其中 $\\epsilon_t$ 和 $\\eta_t$ 相互独立且在时间上独立，并且选择 $\\sigma_x^2$ 和 $\\sigma_y^2$ 以使得 $\\operatorname{Var}(X_t)=\\operatorname{Var}(Y_t)=1$。功能连接性通过由标准化序列构建的零延迟 Pearson 相关性估计来评估，\n$$\n\\widehat{r} = \\frac{1}{n}\\sum_{t=1}^{n} X_t Y_t.\n$$\n将 $\\widehat{r}$ 的有效样本量 $n_{\\text{eff}}$ 定义为能够产生与实际自相关数据相同的 $\\widehat{r}$ 的大样本方差的独立观测数量。从弱平稳性、自协方差和 AR(1) 自相关函数的核心定义出发，在两个序列相互独立且均为平稳的假设下，推导出 $n_{\\text{eff}}$ 关于 $n$、$\\phi_x$ 和 $\\phi_y$ 的解析表达式。然后，简要解释这个 $n_{\\text{eff}}$ 如何影响关于 $\\widehat{r}$ 的统计推断，例如假设检验和置信区间。将最终的 $n_{\\text{eff}}$ 表示为一个闭式解析表达式。不需要四舍五入。",
            "solution": "该问题被认为是有效的，因为它科学地基于时间序列分析的原理及其在计算神经科学中的应用，问题提出得很好，提供了所有必要的信息，并以客观、正式的语言表达。我们可以开始求解。\n\n目标是推导两个独立、平稳、零均值、单位方差的 AR(1) 过程 $\\{X_t\\}$ 和 $\\{Y_t\\}$ 之间 Pearson 相关性估计 $\\widehat{r}$ 的有效样本量 $n_{\\text{eff}}$ 的表达式。有效样本量的定义是，自相关序列的 $\\widehat{r}$ 的方差等于来自 $n_{\\text{eff}}$ 个独立同分布（i.i.d.）观测值的相关性估计的方差。\n\n标准化序列之间的 Pearson 相关性估计量给出如下：\n$$\n\\widehat{r} = \\frac{1}{n}\\sum_{t=1}^{n} X_t Y_t\n$$\n让我们定义一个新的时间序列 $Z_t = X_t Y_t$。由于 $\\{X_t\\}$ 和 $\\{Y_t\\}$ 是独立过程且均值为零，$\\{Z_t\\}$ 的均值为：\n$$\nE[Z_t] = E[X_t Y_t] = E[X_t] E[Y_t] = 0 \\cdot 0 = 0\n$$\n估计量 $\\widehat{r}$ 是过程 $\\{Z_t\\}$ 的样本均值。$\\widehat{r}$ 的方差由下式给出：\n$$\n\\operatorname{Var}(\\widehat{r}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{t=1}^{n} Z_t\\right) = \\frac{1}{n^2} \\operatorname{Var}\\left(\\sum_{t=1}^{n} Z_t\\right) = \\frac{1}{n^2} \\sum_{t=1}^{n}\\sum_{s=1}^{n} \\operatorname{Cov}(Z_t, Z_s)\n$$\n为了计算这个值，我们首先需要 $\\{Z_t\\}$ 的自协方差函数。对于任意两个时间点 $t$ 和 $s$，协方差为：\n$$\n\\operatorname{Cov}(Z_t, Z_s) = E[(X_t Y_t)(X_s Y_s)] - E[X_t Y_t]E[X_s Y_s]\n$$\n由于 $E[Z_t]=0$，第二项为零。由于过程 $\\{X_t\\}$ 和 $\\{Y_t\\}$ 的独立性，乘积的期望可以分开：\n$$\n\\operatorname{Cov}(Z_t, Z_s) = E[X_t X_s Y_t Y_s] = E[X_t X_s] E[Y_t Y_s]\n$$\n项 $E[X_t X_s]$ 和 $E[Y_t Y_s]$ 分别是 $\\{X_t\\}$ 和 $\\{Y_t\\}$ 的自协方差函数。设 $\\gamma_x(k)$ 是 $\\{X_t\\}$ 在延迟 $k$ 时的自协方差，$\\gamma_y(k)$ 是 $\\{Y_t\\}$ 的自协方差。由于过程是平稳的，这些函数仅取决于时间延迟 $k = t-s$：\n$$\n\\gamma_x(t-s) = E[X_t X_s] \\quad \\text{and} \\quad \\gamma_y(t-s) = E[Y_t Y_s]\n$$\n所以，$\\operatorname{Cov}(Z_t, Z_s) = \\gamma_x(t-s) \\gamma_y(t-s)$。\n\n接下来，我们为指定的 AR(1) 过程推导自协方差函数。对于 $X_t = \\phi_x X_{t-1} + \\epsilon_t$，方差为 $\\operatorname{Var}(X_t) = \\gamma_x(0) = 1$。延迟 $k0$ 时的自协方差为：\n$$\n\\gamma_x(k) = E[X_t X_{t-k}] = E[(\\phi_x X_{t-1} + \\epsilon_t) X_{t-k}] = \\phi_x E[X_{t-1} X_{t-k}] + E[\\epsilon_t X_{t-k}]\n$$\n由于 $X_{t-k}$ 由直到时间 $t-k$ 的噪声项决定，它与 $k0$ 时的噪声项 $\\epsilon_t$ 不相关。因此，$E[\\epsilon_t X_{t-k}] = E[\\epsilon_t]E[X_{t-k}] = 0$。方程变为：\n$$\n\\gamma_x(k) = \\phi_x \\gamma_x(k-1)\n$$\n这是一个递推关系。从 $\\gamma_x(0)=1$ 开始，我们发现 $\\gamma_x(1)=\\phi_x$，$\\gamma_x(2)=\\phi_x^2$，一般地，对于 $k \\ge 0$ 有 $\\gamma_x(k) = \\phi_x^k$。由于 $\\gamma_x(k) = \\gamma_x(-k)$，其一般形式为 $\\gamma_x(k) = \\phi_x^{|k|}$。\n类似地，对于 $\\{Y_t\\}$ 过程，$\\gamma_y(k) = \\phi_y^{|k|}$。\n自相关函数 $\\rho_x(k)$ 和 $\\rho_y(k)$ 与自协方差函数相同，因为方差为单位1：$\\rho_x(k) = \\gamma_x(k)/\\gamma_x(0) = \\phi_x^{|k|}$ 和 $\\rho_y(k) = \\gamma_y(k)/\\gamma_y(0) = \\phi_y^{|k|}$。\n\n现在我们可以将 $\\{Z_t\\}$ 的自协方差写为 $\\operatorname{Cov}(Z_t, Z_{t-k}) = \\gamma_x(k)\\gamma_y(k) = (\\phi_x \\phi_y)^{|k|}$。\n\n问题指定使用 $\\widehat{r}$ 的大样本方差。对于大的 $n$，平稳过程样本均值的方差由时间序列分析中的一个著名结果（与 Bartlett's formula 相关）给出：\n$$\n\\operatorname{Var}(\\widehat{r}) \\approx \\frac{1}{n} \\sum_{k=-\\infty}^{\\infty} \\operatorname{Cov}(Z_t, Z_{t-k})\n$$\n代入 $Z_t$ 的自协方差表达式：\n$$\n\\operatorname{Var}(\\widehat{r}) \\approx \\frac{1}{n} \\sum_{k=-\\infty}^{\\infty} (\\phi_x \\phi_y)^{|k|}\n$$\n设 $\\rho = \\phi_x \\phi_y$。条件 $|\\phi_x|1$ 和 $|\\phi_y|1$ 确保了 $|\\rho|1$。我们可以计算这个无穷级数：\n$$\n\\sum_{k=-\\infty}^{\\infty} \\rho^{|k|} = \\sum_{k=-\\infty}^{-1} \\rho^{-k} + \\rho^0 + \\sum_{k=1}^{\\infty} \\rho^k = \\sum_{j=1}^{\\infty} \\rho^{j} + 1 + \\sum_{k=1}^{\\infty} \\rho^k = 1 + 2\\sum_{k=1}^{\\infty} \\rho^k\n$$\n这是一个几何级数，所以 $\\sum_{k=1}^{\\infty} \\rho^k = \\frac{\\rho}{1-\\rho}$。\n$$\n\\sum_{k=-\\infty}^{\\infty} \\rho^{|k|} = 1 + 2\\frac{\\rho}{1-\\rho} = \\frac{1-\\rho+2\\rho}{1-\\rho} = \\frac{1+\\rho}{1-\\rho}\n$$\n将 $\\rho = \\phi_x \\phi_y$ 代回，自相关序列的 $\\widehat{r}$ 的大样本方差为：\n$$\n\\operatorname{Var}(\\widehat{r})_{\\text{autocorr}} \\approx \\frac{1}{n} \\frac{1+\\phi_x \\phi_y}{1-\\phi_x \\phi_y}\n$$\n现在，考虑 $n_{\\text{eff}}$ 个独立同分布观测的参考情况。设 $\\{X'_t\\}$ 和 $\\{Y'_t\\}$ 是零均值和单位方差的独立同分布序列。这对应于设置 $\\phi_x=0$ 和 $\\phi_y=0$。相关性估计将是 $\\widehat{r}_{\\text{iid}} = \\frac{1}{n_{\\text{eff}}} \\sum_{t=1}^{n_{\\text{eff}}} X'_t Y'_t$。设 $Z'_t = X'_t Y'_t$。$\\{Z'_t\\}$ 是独立同分布的，其均值为 $E[Z'_t]=0$，方差为：\n$$\n\\operatorname{Var}(Z'_t) = E[(Z'_t)^2] - (E[Z'_t])^2 = E[(X'_t)^2 (Y'_t)^2] = E[(X'_t)^2] E[(Y'_t)^2]\n$$\n由于 $X'_t$ 和 $Y'_t$ 具有单位方差和零均值，$E[(X'_t)^2] = \\operatorname{Var}(X'_t) = 1$ 且 $E[(Y'_t)^2] = \\operatorname{Var}(Y'_t) = 1$。因此，$\\operatorname{Var}(Z'_t) = 1$。$n_{\\text{eff}}$ 个这样的独立同分布变量的样本均值的方差是：\n$$\n\\operatorname{Var}(\\widehat{r})_{\\text{iid}} = \\operatorname{Var}\\left(\\frac{1}{n_{\\text{eff}}} \\sum_{t=1}^{n_{\\text{eff}}} Z'_t\\right) = \\frac{1}{n_{\\text{eff}}^2} \\sum_{t=1}^{n_{\\text{eff}}} \\operatorname{Var}(Z'_t) = \\frac{1}{n_{\\text{eff}}^2} (n_{\\text{eff}} \\cdot 1) = \\frac{1}{n_{\\text{eff}}}\n$$\n根据 $n_{\\text{eff}}$ 的定义，我们令两个方差相等：\n$$\n\\operatorname{Var}(\\widehat{r})_{\\text{autocorr}} = \\operatorname{Var}(\\widehat{r})_{\\text{iid}}\n$$\n$$\n\\frac{1}{n} \\frac{1+\\phi_x \\phi_y}{1-\\phi_x \\phi_y} = \\frac{1}{n_{\\text{eff}}}\n$$\n求解 $n_{\\text{eff}}$ 得到最终表达式：\n$$\nn_{\\text{eff}} = n \\frac{1-\\phi_x \\phi_y}{1+\\phi_x \\phi_y}\n$$\n关于对统计推断的影响：\n对于 fMRI 数据，AR(1) 系数 $\\phi_x$ 和 $\\phi_y$ 通常是正的，这反映了 BOLD 信号的低频特性。当 $\\phi_x  0$ 且 $\\phi_y  0$ 时，乘积 $\\phi_x \\phi_y$ 也是正的。因此，因子 $\\frac{1-\\phi_x \\phi_y}{1+\\phi_x \\phi_y}$ 小于1。这意味着 $n_{\\text{eff}}  n$。有效独立观测数小于名义上的时间点数。\n\n这对关于 $\\widehat{r}$ 的统计推断具有关键影响：\n1.  **标准误：** 在无相关性的零假设下，$\\widehat{r}$ 的真实标准误约为 $1/\\sqrt{n_{\\text{eff}}}$。如果天真地忽略自相关并使用名义样本量 $n$，标准误将被错误地计算为 $1/\\sqrt{n}$。由于 $n_{\\text{eff}}  n$，我们有 $1/\\sqrt{n_{\\text{eff}}}  1/\\sqrt{n}$。这种天真的方法系统性地低估了 $\\widehat{r}$ 的抽样变异性。\n2.  **假设检验：** 对相关性显著性的检验（例如，$H_0: r=0$）通常涉及一个检验统计量，如 $T = \\widehat{r} / \\text{SE}(\\widehat{r})$。使用被低估的天真标准误会导致检验统计量被夸大。这反过来又导致p值过小，从而导致 I 类错误率的膨胀（假阳性率增加）。研究人员会错误地以高于所选显著性水平 $\\alpha$ 的频率得出存在显著相关性的结论。\n3.  **置信区间：** 真实相关性的置信区间构造为 $\\text{transform}(\\widehat{r}) \\pm z_{\\alpha/2} \\times \\text{SE}(\\text{transform}(\\widehat{r}))$。此计算中的标准误项也与 $1/\\sqrt{n_{\\text{eff}}}$ 成正比。使用 $n$ 而不是 $n_{\\text{eff}}$ 会产生人为狭窄的置信区间。这意味着对估计值的精度的错误感觉，并导致区间以低于名义率的概率覆盖真实参数值（例如，一个 $95\\%$ 的置信区间覆盖真实相关性的时间将少于 $95\\%$）。\n\n总而言之，通过使用 $n$ 而不是正确的 $n_{\\text{eff}}$ 来忽略时间自相关，会导致反保守的统计推断，其特点是过多的假阳性和误导性的狭窄置信区间。",
            "answer": "$$\n\\boxed{n \\frac{1-\\phi_x \\phi_y}{1+\\phi_x \\phi_y}}\n$$"
        },
        {
            "introduction": "本练习将我们的视角从成对连接扩展到全脑网络图。功能性脑网络被认为是稀疏的，但样本协方差矩阵通常是稠密且充满噪声的。本练习介绍了图套索（graphical lasso）这一现代技术，用于估计稀疏的精度矩阵，从而揭示条件独立关系。我们将探讨模型选择的关键任务，结合使用信息论标准（如贝叶斯信息准则，BIC）和基于数据的稳定性分析，以选择一个既能拟合数据又具有可复现性的网络模型 。",
            "id": "3972302",
            "problem": "考虑一个用于来自 $p=4$ 个感兴趣区域的神经时间序列的零均值多元高斯模型，该模型通过一个稀疏精度（逆协方差）矩阵来推断功能连接性。令 $X \\in \\mathbb{R}^{n \\times p}$ 表示 $n=200$ 个独立样本，$S = \\frac{1}{n} X^{\\top} X$ 为样本协方差矩阵。图最小绝对收缩和选择算子（graphical lasso）通过最大化一个带惩罚项的高斯对数似然函数来估计精度矩阵 $\\hat{\\Theta}_{\\lambda}$，其中强度为 $\\lambda  0$ 的 $\\ell_{1}$ 惩罚项应用于非对角线元素。\n\n为您提供了三个候选正则化参数 $\\lambda \\in \\{0.10, 0.25, 0.50\\}$。对于每个 $\\lambda$，相应的解 $\\hat{\\Theta}_{\\lambda}$ 具有以下摘要统计量（根据数据和 $\\hat{\\Theta}_{\\lambda}$ 计算得出）：\n\n- 对于 $\\lambda = 0.10$：\n  - $\\log \\det(\\hat{\\Theta}_{0.10}) = 1.20$，\n  - $\\operatorname{tr}\\!\\left(S \\hat{\\Theta}_{0.10}\\right) = 4.60$，\n  - 估计的边集 $E_{0.10} = \\{(1,2), (2,3), (3,4)\\}$，其中 $|E_{0.10}| = 3$。\n\n- 对于 $\\lambda = 0.25$：\n  - $\\log \\det(\\hat{\\Theta}_{0.25}) = 1.00$，\n  - $\\operatorname{tr}\\!\\left(S \\hat{\\Theta}_{0.25}\\right) = 4.55$，\n  - 估计的边集 $E_{0.25} = \\{(1,2), (3,4)\\}$，其中 $|E_{0.25}| = 2$。\n\n- 对于 $\\lambda = 0.50$：\n  - $\\log \\det(\\hat{\\Theta}_{0.50}) = 0.85$，\n  - $\\operatorname{tr}\\!\\left(S \\hat{\\Theta}_{0.50}\\right) = 4.60$，\n  - 估计的边集 $E_{0.50} = \\{(3,4)\\}$，其中 $|E_{0.50}| = 1$。\n\n为了通过基于子采样的稳定性选择来评估可复现性，假设您生成了 $B=100$ 个半样本子样本。对于每个潜在的无向边 $(i,j)$ 和每个 $\\lambda$，在估计的边集中出现 $(i,j)$ 的子样本比例定义了选择概率 $\\pi_{ij}(\\lambda) \\in [0,1]$。观测到的选择概率如下：\n\n- 对于 $\\lambda = 0.10$：$\\pi_{12}=0.78$, $\\pi_{23}=0.81$, $\\pi_{34}=0.83$, $\\pi_{13}=0.30$, $\\pi_{14}=0.10$, $\\pi_{24}=0.25$。\n- 对于 $\\lambda = 0.25$：$\\pi_{12}=0.86$, $\\pi_{34}=0.88$, $\\pi_{23}=0.40$, $\\pi_{13}=0.18$, $\\pi_{14}=0.08$, $\\pi_{24}=0.20$。\n- 对于 $\\lambda = 0.50$：$\\pi_{34}=0.90$, $\\pi_{12}=0.52$, $\\pi_{23}=0.22$, $\\pi_{13}=0.12$, $\\pi_{14}=0.05$, $\\pi_{24}=0.10$。\n\n任务：\n\n1. 从高斯图模型和 $\\ell_{1}$ 惩罚项对精度矩阵非对角线元素的影响出发，解释当 $\\lambda$ 变化时 $\\hat{\\Theta}_{\\lambda}$ 的稀疏模式如何演变，以及为什么随着 $\\lambda$ 的增加，边会被单调地修剪。\n\n2. 从高斯对数似然和信息准则的定义出发，推导具有精度矩阵 $\\Theta$ 的高斯图模型的贝叶斯信息准则 (BIC)，并说明模型维度（自由度）如何与 $\\Theta$ 中非零唯一参数的数量相关。请明确说明您的计数约定。\n\n3. 定义一个基于阈值 $\\pi_{\\mathrm{thr}} = 0.80$ 的稳定性选择规则，该规则规定，当且仅当 $E_{\\lambda}$ 中的每条边的选择概率至少为 $\\pi_{\\mathrm{thr}}$，且不在 $E_{\\lambda}$ 中的每条边的选择概率小于 $\\pi_{\\mathrm{thr}}$ 时，才宣布给定 $\\lambda$ 下的模型是稳定的。\n\n4. 使用您的推导，在候选的 $\\lambda \\in \\{0.10, 0.25, 0.50\\}$ 中，选择在满足任务3中稳定性规则的条件下使BIC最小化的单个 $\\lambda$。将所选的 $\\lambda$ 报告为一个实数。将您的答案四舍五入到三位有效数字。",
            "solution": "该问题需要一个多步骤的分析，涉及对graphical lasso的解释、高斯图模型的贝叶斯信息准则（BIC）的推导，以及应用稳定性选择准则来选择最优正则化参数 $\\lambda$。我们将依次解决这四个任务。\n\n首先，我们来解释稀疏模式作为正则化参数 $\\lambda$ 的函数。Graphical lasso通过解决以下优化问题来估计精度矩阵 $\\hat{\\Theta}_{\\lambda}$：\n$$\n\\hat{\\Theta}_{\\lambda} = \\arg \\max_{\\Theta \\succ 0} \\left\\{ \\log \\det(\\Theta) - \\operatorname{tr}(S \\Theta) - \\lambda \\sum_{i \\neq j} |\\Theta_{ij}| \\right\\}\n$$\n其中 $\\Theta$ 是一个正定矩阵, $S$ 是样本协方差矩阵, 且 $\\lambda  0$ 是正则化参数。项 $\\log \\det(\\Theta) - \\operatorname{tr}(S \\Theta)$ 与高斯对数似然成正比。项 $\\lambda \\sum_{i \\neq j} |\\Theta_{ij}|$，也写作 $\\lambda \\|\\Theta\\|_{\\text{off},1}$，是一个应用于精度矩阵非对角线元素的$\\ell_1$范数惩罚项。这个惩罚项鼓励稀疏性，意味着它会驱使一些非对角线元素 $\\Theta_{ij}$ 精确地变为零。一个元素 $\\Theta_{ij}$ 为零对应于在给定所有其他变量的情况下变量 $i$ 和 $j$ 之间的条件独立性，这转化为空中关联的依赖图中节点 $i$ 和 $j$ 之间没有边。参数 $\\lambda$ 控制这个惩罚的强度。随着 $\\lambda$ 的增加，拥有一个非零非对角线元素的成本也随之增加。因此，为了最大化目标函数，算法会将更多的非对角线元素设为零。这导致了更稀疏的图。边集是单调修剪的，因为对于任意两个正则化参数 $\\lambda_1  \\lambda_2$，估计的边集 $E_{\\lambda_2}$ 是 $E_{\\lambda_1}$ 的一个子集（即 $E_{\\lambda_2} \\subseteq E_{\\lambda_1}$）。这是lasso解路径的一个基本属性：一旦某个元素在给定的 $\\lambda$ 下被设为零，它在所有更强的惩罚下都将保持为零。提供的数据展示了这个属性：$|E_{0.10}|=3$，$|E_{0.25}|=2$ 和 $|E_{0.50}|=1$，其中 $E_{0.50} \\subset E_{0.25} \\subset E_{0.10}$（注意：$E_{0.25} = \\{(1,2), (3,4)\\}$ 并不是 $E_{0.10} = \\{(1,2), (2,3), (3,4)\\}$ 的子集，这表明与理论路径有轻微偏差，可能是由于数值优化或特定的数据特性。然而，边的数量是单调递减的，这是增加 $\\lambda$ 的关键结果）。\n\n第二，我们推导该模型的贝叶斯信息准则（BIC）。BIC的一般形式是：\n$$\n\\text{BIC} = k \\ln(n) - 2 \\mathcal{L}_{\\text{max}}\n$$\n其中 $k$ 是模型中的自由参数数量，$n$ 是样本数量，$\\mathcal{L}_{\\text{max}}$ 是对数似然函数的最大化值。对于来自精度矩阵为 $\\Theta$ 的零均值$p$元高斯分布的 $n$ 个独立同分布样本 $\\mathbf{x}_1, \\dots, \\mathbf{x}_n$，其对数似然为：\n$$\n\\mathcal{L}(\\Theta) = \\sum_{i=1}^n \\log p(\\mathbf{x}_i | \\Theta) = \\sum_{i=1}^n \\left( \\frac{1}{2} \\log \\det(\\Theta) - \\frac{p}{2} \\log(2\\pi) - \\frac{1}{2} \\mathbf{x}_i^\\top \\Theta \\mathbf{x}_i \\right)\n$$\n对 $n$ 个样本求和，我们得到：\n$$\n\\mathcal{L}(\\Theta) = \\frac{n}{2} \\log \\det(\\Theta) - \\frac{np}{2} \\log(2\\pi) - \\frac{1}{2} \\operatorname{tr}\\left( \\Theta \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top \\right)\n$$\n使用样本协方差矩阵的定义 $S = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i \\mathbf{x}_i^\\top$，上式变为：\n$$\n\\mathcal{L}(\\Theta) = \\frac{n}{2} \\left( \\log \\det(\\Theta) - \\operatorname{tr}(S\\Theta) \\right) - \\frac{np}{2} \\log(2\\pi)\n$$\n对于用给定 $\\lambda$ 估计的模型，我们使用相应的估计值 $\\hat{\\Theta}_{\\lambda}$。最大化的对数似然是 $\\mathcal{L}_{\\text{max}} = \\mathcal{L}(\\hat{\\Theta}_{\\lambda})$。然后我们将这个值代入BIC公式。请注意，BIC的某些定义使用 $-2\\mathcalL_{\\text{max}} + k \\ln(n)$ 并寻求最小化它，这是等价的。我们将采用最小化形式。\n$$\n\\text{BIC} = -2 \\mathcal{L}(\\hat{\\Theta}_{\\lambda}) + k \\ln(n) = -n \\left( \\log \\det(\\hat{\\Theta}_{\\lambda}) - \\operatorname{tr}(S\\hat{\\Theta}_{\\lambda}) \\right) + np \\log(2\\pi) + k \\ln(n)\n$$\n由于对于给定的数据集，项 $np \\log(2\\pi)$ 对所有模型都是一个常数，因此在比较BIC值时可以省略。因此，用于比较的BIC是：\n$$\n\\text{BIC}(\\lambda) = n \\left( \\operatorname{tr}(S\\hat{\\Theta}_{\\lambda}) - \\log \\det(\\hat{\\Theta}_{\\lambda}) \\right) + k \\ln(n)\n$$\n必须确定自由参数的数量 $k$。我们的计数约定如下：精度矩阵 $\\Theta$ 是对称的。一个模型由其非零项定义。我们总是估计 $p$ 个对角线项。非对角线结构由边集 $E_{\\lambda}$ 定义。由于 $\\Theta_{ij} = \\Theta_{ji}$，唯一的非零非对角线参数的数量是 $|E_{\\lambda}|$。因此，自由参数的总数是 $k = p + |E_{\\lambda}|$。\n\n第三，我们陈述稳定性选择规则。一个对应于 $\\hat{\\Theta}_{\\lambda}$ 及其边集 $E_{\\lambda}$ 的模型被宣布为稳定的，当且仅当关于阈值 $\\pi_{\\mathrm{thr}} = 0.80$ 同时满足以下两个条件：\n1. 对于 $E_{\\lambda}$ 中的每一条边 $(i, j)$，相应的选择概率必须满足 $\\pi_{ij}(\\lambda) \\ge \\pi_{\\mathrm{thr}}$。\n2. 对于不在 $E_{\\lambda}$ 中的每一条潜在边 $(i, j)$，相应的选择概率必须满足 $\\pi_{ij}(\\lambda)  \\pi_{\\mathrm{thr}}$。\n\n第四，我们从集合 $\\{0.10, 0.25, 0.50\\}$ 中选择最优的 $\\lambda$，方法是首先根据稳定性进行筛选，然后最小化BIC。我们使用给定的数据：$n=200$, $p=4$, $\\pi_{\\mathrm{thr}} = 0.80$。\n\n我们测试每个 $\\lambda$ 的稳定性：\n- **对于 $\\lambda = 0.10$**：\n  - $E_{0.10} = \\{(1,2), (2,3), (3,4)\\}$。\n  - 条件1检查：我们需要对 $E_{0.10}$ 中所有的边，$\\pi_{ij}(0.10) \\ge 0.80$。\n  - 我们有 $\\pi_{12}(0.10) = 0.78$，它小于 $0.80$。\n  - 因此，$\\lambda = 0.10$ 的模型是 **不稳定** 的。\n\n- **对于 $\\lambda = 0.25$**：\n  - $E_{0.25} = \\{(1,2), (3,4)\\}$。\n  - 条件1检查：\n    - $\\pi_{12}(0.25) = 0.86 \\ge 0.80$。(通过)\n    - $\\pi_{34}(0.25) = 0.88 \\ge 0.80$。(通过)\n  - 条件2检查：我们需要对所有不在 $E_{0.25}$ 中的边，$\\pi_{ij}(0.25)  0.80$。这些边是 $(2,3), (1,3), (1,4), (2,4)$。\n    - $\\pi_{23}(0.25) = 0.40  0.80$。(通过)\n    - $\\pi_{13}(0.25) = 0.18  0.80$。(通过)\n    - $\\pi_{14}(0.25) = 0.08  0.80$。(通过)\n    - $\\pi_{24}(0.25) = 0.20  0.80$。(通过)\n  - 所有条件都满足。$\\lambda = 0.25$ 的模型是 **稳定** 的。\n\n- **对于 $\\lambda = 0.50$**：\n  - $E_{0.50} = \\{(3,4)\\}$。\n  - 条件1检查：\n    - $\\pi_{34}(0.50) = 0.90 \\ge 0.80$。(通过)\n  - 条件2检查：我们需要对所有其他的边，$\\pi_{ij}(0.50)  0.80$。\n    - $\\pi_{12}(0.50) = 0.52  0.80$。(通过)\n    - $\\pi_{23}(0.50) = 0.22  0.80$。(通过)\n    - $\\pi_{13}(0.50) = 0.12  0.80$。(通过)\n    - $\\pi_{14}(0.50) = 0.05  0.80$。(通过)\n    - $\\pi_{24}(0.50) = 0.10  0.80$。(通过)\n  - 所有条件都满足。$\\lambda = 0.50$ 的模型是 **稳定** 的。\n\n现在我们比较两个稳定模型 $\\lambda = 0.25$ 和 $\\lambda = 0.50$ 的BIC。\n公式为 $\\text{BIC}(\\lambda) = n \\left( \\operatorname{tr}(S\\hat{\\Theta}_{\\lambda}) - \\log \\det(\\hat{\\Theta}_{\\lambda}) \\right) + (p + |E_{\\lambda}|) \\ln(n)$。\n我们有 $n=200$, $p=4$, 且 $\\ln(200) \\approx 5.2983$。\n\n- **对于 $\\lambda = 0.25$ 的BIC**：\n  - $\\operatorname{tr}(S\\hat{\\Theta}_{0.25}) - \\log \\det(\\hat{\\Theta}_{0.25}) = 4.55 - 1.00 = 3.55$。\n  - $|E_{0.25}|=2$，所以 $k = p + |E_{0.25}| = 4 + 2 = 6$。\n  - $\\text{BIC}(0.25) = 200 \\times (3.55) + 6 \\times \\ln(200) = 710 + 6 \\ln(200)$。\n  - $\\text{BIC}(0.25) \\approx 710 + 6 \\times 5.2983 = 710 + 31.7898 = 741.7898$。\n\n- **对于 $\\lambda = 0.50$ 的BIC**：\n  - $\\operatorname{tr}(S\\hat{\\Theta}_{0.50}) - \\log \\det(\\hat{\\Theta}_{0.50}) = 4.60 - 0.85 = 3.75$。\n  - $|E_{0.50}|=1$，所以 $k = p + |E_{0.50}| = 4 + 1 = 5$。\n  - $\\text{BIC}(0.50) = 200 \\times (3.75) + 5 \\times \\ln(200) = 750 + 5 \\ln(200)$。\n  - $\\text{BIC}(0.50) \\approx 750 + 5 \\times 5.2983 = 750 + 26.4915 = 776.4915$。\n\n比较这两个值，$\\text{BIC}(0.25) \\approx 741.79$ 和 $\\text{BIC}(0.50) \\approx 776.49$。\n由于 $741.79  776.49$，$\\lambda = 0.25$ 的模型具有更低的BIC，因此是首选。\n\n所选的 $\\lambda$ 值为 $0.25$。作为一个四舍五入到三位有效数字的实数，这是 $0.250$。",
            "answer": "$$\n\\boxed{0.250}\n$$"
        }
    ]
}