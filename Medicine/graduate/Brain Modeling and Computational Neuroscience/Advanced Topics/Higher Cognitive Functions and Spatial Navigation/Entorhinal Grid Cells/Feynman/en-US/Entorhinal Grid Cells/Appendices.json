{
    "hands_on_practices": [
        {
            "introduction": "The beautiful hexagonal symmetry of a grid cell's firing map is not just visually striking; it produces a unique signature in the frequency domain. This first exercise invites you to perform a two-dimensional Fourier transform on an idealized grid cell rate map. By deriving the locations and amplitudes of the resulting spectral peaks, you will gain a first-principles understanding of why Fourier analysis is an indispensable tool for identifying and characterizing grid cells from experimental data .",
            "id": "3978907",
            "problem": "A neuron in the medial entorhinal cortex exhibits a hexagonal array of firing fields in the plane. Model the spatial firing rate as a sum of identical fields located on a triangular Bravais lattice plus a constant baseline. Specifically, let the triangular lattice be generated by the basis vectors $\\mathbf{a}_{1} = a(1,0)$ and $\\mathbf{a}_{2} = a\\left(\\frac{1}{2}, \\frac{\\sqrt{3}}{2}\\right)$, where $a > 0$ is the nearest-neighbor lattice spacing and the angle between $\\mathbf{a}_{1}$ and $\\mathbf{a}_{2}$ is $60^\\circ$. The firing rate is\n$$\nr(\\mathbf{x}) \\;=\\; r_{b} \\;+\\; \\sum_{\\mathbf{R}\\in\\Lambda} A \\,\\exp\\!\\left(-\\frac{|\\mathbf{x}-\\mathbf{R}|^{2}}{2\\sigma^{2}}\\right),\n$$\nwhere $\\Lambda = \\{n_{1}\\mathbf{a}_{1} + n_{2}\\mathbf{a}_{2} \\,:\\, n_{1},n_{2}\\in\\mathbb{Z}\\}$, $A>0$ is the peak height of each Gaussian field above baseline at its center, $\\sigma>0$ is the field width, and $r_{b}\\ge 0$ is the baseline rate.\n\nUsing only the definition of the two-dimensional Fourier transform\n$$\n\\hat{r}(\\mathbf{k}) \\;=\\; \\int_{\\mathbb{R}^{2}} r(\\mathbf{x}) \\,\\exp\\!\\big(-i\\,\\mathbf{k}\\cdot\\mathbf{x}\\big)\\,d^{2}\\mathbf{x},\n$$\nand well-tested results from the Poisson summation formula for Bravais lattices, derive the spectral representation of $\\hat{r}(\\mathbf{k})$ and identify the locations of its Bragg peaks. Then, focusing on the first reciprocal-lattice shell (the six shortest nonzero reciprocal vectors of the triangular lattice), determine the amplitude coefficient multiplying the Dirac delta at any one of these six wavevectors as a closed-form analytic expression in terms of $A$, $a$, and $\\sigma$ only. Your final answer must be a single closed-form expression. Do not approximate or round. No units are required. State angles, where needed, in degrees.",
            "solution": "The problem statement is evaluated to be scientifically grounded, well-posed, objective, and self-contained. The model represents a canonical representation of entorhinal grid cell firing fields, a cornerstone of computational neuroscience. The task is a standard application of Fourier analysis to periodic structures, a technique widely used in physics and engineering. All parameters and conditions are clearly defined, leading to a unique and meaningful solution. The problem is valid.\n\nThe spatial firing rate $r(\\mathbf{x})$ is given by:\n$$\nr(\\mathbf{x}) = r_{b} + \\sum_{\\mathbf{R}\\in\\Lambda} A \\,\\exp\\left(-\\frac{|\\mathbf{x}-\\mathbf{R}|^{2}}{2\\sigma^{2}}\\right)\n$$\nwhere $r_b$ is a constant baseline rate and the sum represents the periodic arrangement of firing fields. We can separate the function into two parts: $r(\\mathbf{x}) = r_b + f(\\mathbf{x})$, where\n$$\nf(\\mathbf{x}) = \\sum_{\\mathbf{R}\\in\\Lambda} A g(\\mathbf{x}-\\mathbf{R})\n$$\nwith $g(\\mathbf{x}) = \\exp\\left(-\\frac{|\\mathbf{x}|^{2}}{2\\sigma^{2}}\\right)$.\n\nThe Fourier transform is a linear operator, so the Fourier transform of $r(\\mathbf{x})$, denoted $\\hat{r}(\\mathbf{k})$, is the sum of the transforms of its parts:\n$$\n\\hat{r}(\\mathbf{k}) = \\mathcal{F}\\{r_b\\} + \\mathcal{F}\\{f(\\mathbf{x})\\}\n$$\nThe Fourier transform of the constant baseline rate $r_b$ is a Dirac delta function at the origin of the frequency domain:\n$$\n\\mathcal{F}\\{r_b\\} = \\int_{\\mathbb{R}^2} r_b e^{-i\\mathbf{k}\\cdot\\mathbf{x}} d^2\\mathbf{x} = r_b (2\\pi)^2 \\delta(\\mathbf{k})\n$$\nwhere $\\delta(\\mathbf{k})$ is the two-dimensional Dirac delta function. This term contributes only to the DC component ($\\mathbf{k}=\\mathbf{0}$) of the spectrum.\n\nThe second term, $f(\\mathbf{x})$, can be expressed as a convolution of the single field shape $A g(\\mathbf{x})$ with a Dirac comb $S(\\mathbf{x})$ representing the lattice points:\n$$\nf(\\mathbf{x}) = A \\cdot (g * S)(\\mathbf{x})\n$$\nwhere $S(\\mathbf{x}) = \\sum_{\\mathbf{R}\\in\\Lambda} \\delta(\\mathbf{x}-\\mathbf{R})$.\n\nBy the convolution theorem, the Fourier transform of a convolution is the product of the individual Fourier transforms:\n$$\n\\hat{f}(\\mathbf{k}) = A \\cdot \\hat{g}(\\mathbf{k}) \\cdot \\hat{S}(\\mathbf{k})\n$$\nFirst, we find the Fourier transform of the Gaussian function $g(\\mathbf{x})$. This is a standard result: the Fourier transform of a Gaussian is also a Gaussian. For a 2D Gaussian $g(\\mathbf{x}) = \\exp(-\\alpha|\\mathbf{x}|^2)$, the Fourier transform is $\\hat{g}(\\mathbf{k}) = \\frac{\\pi}{\\alpha}\\exp(-|\\mathbf{k}|^2/(4\\alpha))$. In our case, $\\alpha = 1/(2\\sigma^2)$, so:\n$$\n\\hat{g}(\\mathbf{k}) = \\frac{\\pi}{1/(2\\sigma^2)} \\exp\\left( -\\frac{|\\mathbf{k}|^2}{4/(2\\sigma^2)} \\right) = 2\\pi\\sigma^2 \\exp\\left( -\\frac{\\sigma^2|\\mathbf{k}|^2}{2} \\right)\n$$\nNext, we find the Fourier transform of the Dirac comb $S(\\mathbf{x})$. The Poisson summation formula for a Bravais lattice states that the Fourier transform of a lattice of delta functions in real space is a lattice of delta functions in reciprocal space. The result is:\n$$\n\\hat{S}(\\mathbf{k}) = \\frac{(2\\pi)^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nwhere $\\Lambda^*$ is the reciprocal lattice and $V_{\\text{cell}}$ is the area of the real-space unit cell.\n\nThe real-space unit cell is the parallelogram spanned by the basis vectors $\\mathbf{a}_{1} = a(1,0)$ and $\\mathbf{a}_{2} = a(1/2, \\sqrt{3}/2)$. Its area is given by the magnitude of their cross product, or in 2D, the determinant of the matrix formed by them:\n$$\nV_{\\text{cell}} = \\left| \\det \\begin{pmatrix} a & a/2 \\\\ 0 & a\\sqrt{3}/2 \\end{pmatrix} \\right| = \\left| a \\cdot \\frac{a\\sqrt{3}}{2} - 0 \\cdot \\frac{a}{2} \\right| = \\frac{\\sqrt{3}}{2}a^2\n$$\nThe reciprocal lattice $\\Lambda^*$ is spanned by basis vectors $\\mathbf{b}_1, \\mathbf{b}_2$ satisfying $\\mathbf{a}_i \\cdot \\mathbf{b}_j = 2\\pi \\delta_{ij}$. Solving this system yields a set of reciprocal basis vectors. For the triangular lattice, the reciprocal lattice is also a triangular (hexagonal) lattice. The first shell of the reciprocal lattice consists of the six shortest non-zero wavevectors $\\mathbf{K}$. All vectors in this shell have the same magnitude, which we denote as $K_1$. For a triangular lattice with nearest-neighbor spacing $a$, this magnitude is known to be:\n$$\nK_1 = |\\mathbf{K}| = \\frac{4\\pi}{a\\sqrt{3}}\n$$\nTherefore, the magnitude squared is:\n$$\n|\\mathbf{K}|^2 = K_1^2 = \\frac{16\\pi^2}{3a^2}\n$$\nNow, we combine the expressions for $\\hat{g}(\\mathbf{k})$ and $\\hat{S}(\\mathbf{k})$ to find $\\hat{f}(\\mathbf{k})$:\n$$\n\\hat{f}(\\mathbf{k}) = A \\left( 2\\pi\\sigma^2 \\exp\\left(-\\frac{\\sigma^2|\\mathbf{k}|^2}{2}\\right) \\right) \\left( \\frac{(2\\pi)^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\delta(\\mathbf{k}-\\mathbf{K}) \\right)\n$$\nUsing the sifting property of the delta function, $h(\\mathbf{k})\\delta(\\mathbf{k}-\\mathbf{K}) = h(\\mathbf{K})\\delta(\\mathbf{k}-\\mathbf{K})$, we get:\n$$\n\\hat{f}(\\mathbf{k}) = \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\exp\\left(-\\frac{\\sigma^2|\\mathbf{K}|^2}{2}\\right) \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nThe full spectrum $\\hat{r}(\\mathbf{k})$ is:\n$$\n\\hat{r}(\\mathbf{k}) = (2\\pi)^2 r_b \\delta(\\mathbf{k}) + \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\sum_{\\mathbf{K}\\in\\Lambda^*} \\exp\\left(-\\frac{\\sigma^2|\\mathbf{K}|^2}{2}\\right) \\delta(\\mathbf{k}-\\mathbf{K})\n$$\nThis expression shows that the spectrum consists of discrete Bragg peaks at the locations of the reciprocal lattice vectors $\\mathbf{K}$.\n\nThe problem asks for the amplitude coefficient of the Dirac delta at any one of the six wavevectors in the first reciprocal-lattice shell. These correspond to the six nonzero vectors $\\mathbf{K}$ with the smallest magnitude, $|\\mathbf{K}| = K_1$. Let $C_{K_1}$ be this coefficient. From the expression for $\\hat{f}(\\mathbf{k})$, this coefficient is:\n$$\nC_{K_1} = \\frac{A(2\\pi)^3\\sigma^2}{V_{\\text{cell}}} \\exp\\left(-\\frac{\\sigma^2 K_1^2}{2}\\right)\n$$\nSubstituting $V_{\\text{cell}} = \\frac{\\sqrt{3}}{2}a^2$ and $K_1^2 = \\frac{16\\pi^2}{3a^2}$:\n$$\nC_{K_1} = \\frac{A(8\\pi^3)\\sigma^2}{\\frac{\\sqrt{3}}{2}a^2} \\exp\\left(-\\frac{\\sigma^2}{2} \\cdot \\frac{16\\pi^2}{3a^2}\\right)\n$$\nSimplifying the pre-factor and the exponent gives the final expression:\n$$\nC_{K_1} = \\frac{16\\pi^3 A \\sigma^2}{\\sqrt{3} a^2} \\exp\\left(-\\frac{8\\pi^2\\sigma^2}{3a^2}\\right)\n$$\nThis is the closed-form analytic expression for the amplitude coefficient of any of the six primary Bragg peaks in the spatial frequency domain, in terms of the given parameters $A$, $a$, and $\\sigma$.",
            "answer": "$$\n\\boxed{\\frac{16 \\pi^3 A \\sigma^2}{\\sqrt{3} a^2} \\exp\\left(-\\frac{8\\pi^2\\sigma^2}{3a^2}\\right)}\n$$"
        },
        {
            "introduction": "Grid cells are widely believed to support navigation by integrating an animal's velocity, a process known as path integration. This theoretical exercise explores a fundamental consequence of this mechanism: the accumulation of error due to noise in the velocity signal. Starting from a simple model of a continuous attractor network, you will derive how the positional error grows over time, revealing the characteristic diffusive drift that is inherent to any noisy integrator .",
            "id": "3978900",
            "problem": "Consider a minimal path-integration model of Entorhinal cortex grid cells implemented by a Continuous Attractor Network (CAN). The CAN encodes a two-dimensional position estimate $\\hat{\\mathbf{r}}(t) \\in \\mathbb{R}^{2}$ by integrating velocity-coded inputs according to the kinematic identity $\\frac{d\\hat{\\mathbf{r}}}{dt}=\\mathbf{v}_{\\text{obs}}(t)$, where $\\mathbf{v}_{\\text{obs}}(t)$ is the observed velocity signal delivered by upstream neurons. Assume the true velocity is constant, $\\mathbf{v}_{0} \\in \\mathbb{R}^{2}$, and the observation noise is additive Gaussian white noise, so that $\\mathbf{v}_{\\text{obs}}(t)=\\mathbf{v}_{0}+\\boldsymbol{\\eta}(t)$ with $\\mathbb{E}[\\boldsymbol{\\eta}(t)]=\\mathbf{0}$ and component-wise covariance $\\mathbb{E}[\\eta_{i}(t)\\eta_{j}(t^{\\prime})]=2D\\,\\delta_{ij}\\,\\delta(t-t^{\\prime})$, where $D>0$ is a diffusion constant, $\\delta_{ij}$ is the Kronecker delta, and $\\delta(\\cdot)$ is the Dirac delta. The true position obeys $\\frac{d\\mathbf{r}}{dt}=\\mathbf{v}_{0}$.\n\nDefine the position error $\\mathbf{e}(t)=\\hat{\\mathbf{r}}(t)-\\mathbf{r}(t)$. Starting from the above definitions and properties of Gaussian white noise, derive the closed-form expression for the root-mean-square error magnitude $\\sqrt{\\mathbb{E}[|\\mathbf{e}(t)|^{2}]}$ in the two-dimensional case ($d=2$), expressed in terms of $D$ and $t$. Your answer must be a single analytic expression. Express the final magnitude in meters. No intermediate or target formulas are provided; base your derivation on first principles of stochastic integration and the given noise statistics.",
            "solution": "The Continuous Attractor Network (CAN) implements path integration via the kinematic relation $\\frac{d\\hat{\\mathbf{r}}}{dt}=\\mathbf{v}_{\\text{obs}}(t)$. With $\\mathbf{v}_{\\text{obs}}(t)=\\mathbf{v}_{0}+\\boldsymbol{\\eta}(t)$ and the true position obeying $\\frac{d\\mathbf{r}}{dt}=\\mathbf{v}_{0}$, we integrate both to obtain the position estimate and true position:\n$$\n\\hat{\\mathbf{r}}(t)=\\hat{\\mathbf{r}}(0)+\\int_{0}^{t}\\mathbf{v}_{\\text{obs}}(s)\\,ds=\\hat{\\mathbf{r}}(0)+\\int_{0}^{t}\\mathbf{v}_{0}\\,ds+\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds,\n$$\n$$\n\\mathbf{r}(t)=\\mathbf{r}(0)+\\int_{0}^{t}\\mathbf{v}_{0}\\,ds.\n$$\nSubtracting, the error is\n$$\n\\mathbf{e}(t)=\\hat{\\mathbf{r}}(t)-\\mathbf{r}(t)=\\left[\\hat{\\mathbf{r}}(0)-\\mathbf{r}(0)\\right]+\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds.\n$$\nIf the initial alignment is exact, $\\hat{\\mathbf{r}}(0)=\\mathbf{r}(0)$, then\n$$\n\\mathbf{e}(t)=\\int_{0}^{t}\\boldsymbol{\\eta}(s)\\,ds.\n$$\nWe seek the root-mean-square error magnitude $\\sqrt{\\mathbb{E}[|\\mathbf{e}(t)|^{2}]}$. Since $\\boldsymbol{\\eta}(t)$ is zero-mean Gaussian white noise with covariance $\\mathbb{E}[\\eta_{i}(t)\\eta_{j}(t^{\\prime})]=2D\\,\\delta_{ij}\\,\\delta(t-t^{\\prime})$, the integral of white noise yields a Wiener process with variance growing linearly in time. Compute the second moment of $\\mathbf{e}(t)$ component-wise. Let $e_{i}(t)=\\int_{0}^{t}\\eta_{i}(s)\\,ds$. Then\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\mathbb{E}\\left[\\int_{0}^{t}\\int_{0}^{t}\\eta_{i}(s)\\eta_{j}(s^{\\prime})\\,ds\\,ds^{\\prime}\\right].\n$$\nUsing the given covariance,\n$$\n\\mathbb{E}\\left[\\eta_{i}(s)\\eta_{j}(s^{\\prime})\\right]=2D\\,\\delta_{ij}\\,\\delta(s-s^{\\prime}),\n$$\nwe substitute:\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\int_{0}^{t}\\int_{0}^{t}2D\\,\\delta_{ij}\\,\\delta(s-s^{\\prime})\\,ds\\,ds^{\\prime}.\n$$\nEvaluate the inner integral using the sifting property of the Dirac delta. For fixed $s$, $\\int_{0}^{t}\\delta(s-s^{\\prime})\\,ds^{\\prime}=1$ for $s\\in[0,t]$, hence\n$$\n\\mathbb{E}\\left[e_{i}(t)e_{j}(t)\\right]=\\delta_{ij}\\int_{0}^{t}2D\\,ds=2D\\,t\\,\\delta_{ij}.\n$$\nTherefore, each component has variance $\\mathbb{E}[e_{i}(t)^{2}]=2D\\,t$, and different components are uncorrelated. The squared magnitude of the error is $|\\mathbf{e}(t)|^{2}=e_{1}(t)^{2}+e_{2}(t)^{2}$ in two dimensions. Its expectation is the sum of the component variances:\n$$\n\\mathbb{E}\\left[|\\mathbf{e}(t)|^{2}\\right]=\\mathbb{E}\\left[e_{1}(t)^{2}\\right]+\\mathbb{E}\\left[e_{2}(t)^{2}\\right]=2D\\,t+2D\\,t=4D\\,t.\n$$\nThe root-mean-square (RMS) error magnitude is\n$$\n\\sqrt{\\mathbb{E}\\left[|\\mathbf{e}(t)|^{2}\\right]}=\\sqrt{4D\\,t}=2\\sqrt{D\\,t}.\n$$\nThis expression has units of meters because $D$ carries units of $\\text{m}^{2}\\,\\text{s}^{-1}$ and $t$ has units of $\\text{s}$, yielding $\\text{m}^{2}$ inside the square root and thus meters after taking the root. The time dependence is $\\propto \\sqrt{t}$ via the square-root factor, characteristic of diffusive growth arising from integrating white noise.",
            "answer": "$$\\boxed{2\\sqrt{D\\,t}}$$"
        },
        {
            "introduction": "Bridging the gap from theoretical models to experimental data requires robust statistical tools. This practice challenges you to think like a data analyst by deriving a method to estimate a grid cell's fundamental spacing, $\\lambda$, from a list of observed spike locations. You will develop a maximum likelihood estimator and then use the Cramér-Rao bound to find the theoretical limit on its precision, providing deep insight into how the quality and quantity of data constrain our knowledge of the neural code .",
            "id": "3978983",
            "problem": "A single medial entorhinal cortex grid cell is recorded while a rodent uniformly explores a square arena of side length $L$ with periodic boundary identification, so that the position domain is $\\Omega = [-L/2,L/2] \\times [-L/2,L/2]$ of area $A = L^{2}$. Let $N$ denote the total number of spikes observed. Assume the spike train is generated by an inhomogeneous spatial Poisson point process whose intensity is a hexagonally symmetric modulation of a constant baseline, specifically\n$$\nr(\\mathbf{x};\\lambda) \\;=\\; \\rho_{0}\\left[\\,1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right],\n$$\nwhere $\\rho_{0} > 0$ is the baseline rate, $0<\\alpha<\\frac{1}{3}$ is a small modulation amplitude, $\\lambda>0$ is the grid spacing, and $\\mathbf{u}_{m}$ are unit vectors at $0^{\\circ}$, $60^{\\circ}$, and $120^{\\circ}$ relative to an arbitrary reference axis. Assume the animal’s occupancy is uniform over $\\Omega$ and the exploration covers many grid periods so that spatial averages of trigonometric functions over $\\Omega$ behave as their cycle averages.\n\nStarting from fundamental definitions of the inhomogeneous Poisson point process and the likelihood function for independently and identically distributed spike positions conditioned on $N$, do the following:\n\n1. Derive the form of the log-likelihood for $\\lambda$ based on the observed spike locations $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$, and design a maximum likelihood estimator (MLE) for $\\lambda$ that operates by selecting the spatial wavenumber magnitude $k$ that maximizes the ring power of the spike-position Fourier components aligned with the three grid axes, then maps $k$ to $\\lambda$ via $k = 2\\pi/\\lambda$. Provide the estimator in closed form as an optimization over $k>0$.\n\n2. Under the regime of small modulation amplitude $0<\\alpha\\ll 1$ and many-period coverage, derive the Cramér-Rao bound (CRB) for estimating $\\lambda$ based on $N$ spikes, and obtain the asymptotic variance of the MLE by equating it to the CRB under regularity and efficiency conditions. Express your final asymptotic variance formula in closed form in terms of $N$, $\\alpha$, $\\lambda$, and $A=L^{2}$. No numerical evaluation is required.\n\nYour final answer must be a single closed-form analytic expression.",
            "solution": "The problem is evaluated to be scientifically grounded, well-posed, objective, and internally consistent. It is a valid problem in computational neuroscience and statistical inference. We now proceed with the solution.\n\nThe problem is divided into two parts. First, we design a Maximum Likelihood Estimator (MLE) for the grid spacing $\\lambda$. Second, we derive the Cramér-Rao Bound (CRB) for $\\lambda$ and determine the asymptotic variance of the MLE.\n\n**Part 1: Derivation of the Maximum Likelihood Estimator**\n\nThe spike locations $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$ are described as being independently and identically distributed (i.i.d.) conditioned on the total number of spikes $N$. For an inhomogeneous spatial Poisson process with rate function $r(\\mathbf{x};\\lambda)$, the probability density function for a single spike location $\\mathbf{x}$ within the domain $\\Omega$ is given by:\n$$\np(\\mathbf{x}|\\lambda) = \\frac{r(\\mathbf{x};\\lambda)}{\\int_{\\Omega} r(\\mathbf{x}';\\lambda) d\\mathbf{x}'}\n$$\nThe rate function is given as:\n$$\nr(\\mathbf{x};\\lambda) = \\rho_{0}\\left[\\,1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right]\n$$\nwhere $\\rho_{0} > 0$ is the baseline rate, $0 < \\alpha < 1/3$ is the modulation amplitude, $\\lambda > 0$ is the grid spacing, and $\\mathbf{u}_{m}$ are unit vectors separated by $60^\\circ$.\n\nFirst, we compute the integral of the rate function over the domain $\\Omega = [-L/2, L/2] \\times [-L/2, L/2]$ of area $A = L^2$.\n$$\n\\int_{\\Omega} r(\\mathbf{x};\\lambda) d\\mathbf{x} = \\int_{\\Omega} \\rho_{0}\\left[\\,1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right] d\\mathbf{x}\n$$\n$$\n= \\rho_{0} \\int_{\\Omega} d\\mathbf{x} \\;+\\; \\rho_{0}\\alpha \\sum_{m=1}^{3} \\int_{\\Omega} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right) d\\mathbf{x}\n$$\nThe problem states that the exploration covers many grid periods. This implies that the spatial average of each cosine term over the large domain $\\Omega$ is approximately zero, as the function oscillates many times.\n$$\n\\int_{\\Omega} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right) d\\mathbf{x} \\approx 0\n$$\nThus, the integral of the rate function simplifies to:\n$$\n\\int_{\\Omega} r(\\mathbf{x};\\lambda) d\\mathbf{x} \\approx \\rho_{0} A\n$$\nThis quantity is independent of the parameter $\\lambda$. The probability density for a single spike is therefore:\n$$\np(\\mathbf{x}|\\lambda) \\approx \\frac{r(\\mathbf{x};\\lambda)}{\\rho_{0}A} = \\frac{1}{A} \\left[\\,1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right]\n$$\nThe log-likelihood for the $N$ observed i.i.d. spike locations $\\{\\mathbf{x}_{i}\\}_{i=1}^{N}$ is the sum of the individual log-probabilities:\n$$\n\\mathcal{L}(\\lambda) = \\sum_{i=1}^{N} \\ln p(\\mathbf{x}_{i}|\\lambda) = \\sum_{i=1}^{N} \\ln \\left( \\frac{r(\\mathbf{x}_{i};\\lambda)}{\\rho_{0}A} \\right) = \\sum_{i=1}^{N} \\ln r(\\mathbf{x}_{i};\\lambda) - N\\ln(\\rho_{0}A)\n$$\nTo find the MLE for $\\lambda$, we maximize $\\mathcal{L}(\\lambda)$. Since the term $N\\ln(\\rho_{0}A)$ is constant with respect to $\\lambda$, this is equivalent to maximizing the first term:\n$$\n\\hat{\\lambda}_{\\text{MLE}} = \\arg\\max_{\\lambda>0} \\sum_{i=1}^{N} \\ln r(\\mathbf{x}_{i};\\lambda) = \\arg\\max_{\\lambda>0} \\sum_{i=1}^{N} \\ln \\left( \\rho_{0}\\left[\\,1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}_i\\right)\\right] \\right)\n$$\nThis is equivalent to maximizing:\n$$\n\\mathcal{L}_{\\text{eff}}(\\lambda) = \\sum_{i=1}^{N} \\ln \\left( 1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}_i\\right) \\right)\n$$\nThe problem asks to design an MLE that operates by maximizing \"ring power\". This suggests a simplification based on the given condition that the modulation amplitude $\\alpha$ is small ($0 < \\alpha \\ll 1$). Using the Taylor expansion $\\ln(1+z) \\approx z$ for small $z$, where $z = \\alpha \\sum_{m} \\cos(\\dots)$, the objective function is approximately:\n$$\n\\mathcal{L}_{\\text{eff}}(\\lambda) \\approx \\alpha \\sum_{i=1}^{N} \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}_i\\right)\n$$\nThis approximation is valid to first order in $\\alpha$. Standard methods for grid cell analysis often use estimators based on the Fourier power spectrum of the spike map. The problem directs us to such an estimator. Let the spatial wavenumber be $k = 2\\pi/\\lambda$. The estimator for $k$ is designed to maximize the \"ring power of the spike-position Fourier components aligned with the three grid axes\". The Fourier component at a wavevector $\\mathbf{k}$ is $\\mathcal{F}(\\mathbf{k}) = \\sum_{i=1}^{N} \\exp(-i \\mathbf{k} \\cdot \\mathbf{x}_i)$. The power is $|\\mathcal{F}(\\mathbf{k})|^2$. The three grid axes correspond to wavevectors $\\mathbf{k}_m = k \\mathbf{u}_m$. The estimator is constructed by maximizing the sum of powers at these three aligned components for a given wavenumber magnitude $k$.\n\nThus, the MLE for the wavenumber $k$ is given by the optimization problem:\n$$\n\\hat{k} = \\arg\\max_{k>0} \\sum_{m=1}^{3} \\left| \\sum_{i=1}^{N} \\exp(-i k \\mathbf{u}_m \\cdot \\mathbf{x}_i) \\right|^2\n$$\nThe corresponding estimator for the grid spacing $\\lambda$ is then $\\hat{\\lambda} = 2\\pi/\\hat{k}$. This formulation corresponds to finding the radius of the \"ring\" in Fourier space that contains the most power, concentrated at the three principal directions of the grid.\n\n**Part 2: Cramér-Rao Bound and Asymptotic Variance**\n\nThe Cramér-Rao Bound (CRB) provides a lower bound on the variance of any unbiased estimator. For an efficient estimator, which the MLE is asymptotically, its variance equals the CRB. The CRB is the reciprocal of the Fisher Information $I(\\lambda)$.\n$$\n\\text{Var}(\\hat{\\lambda}) \\ge \\frac{1}{I(\\lambda)}\n$$\nThe Fisher Information for $N$ i.i.d. observations is $N$ times the Fisher Information for a single observation, $I(\\lambda) = N I_1(\\lambda)$. For a single observation,\n$$\nI_1(\\lambda) = E\\left[ \\left(\\frac{\\partial}{\\partial \\lambda} \\ln p(\\mathbf{x}|\\lambda)\\right)^2 \\right] = \\int_{\\Omega} \\left(\\frac{\\partial}{\\partial \\lambda} \\ln p(\\mathbf{x}|\\lambda)\\right)^2 p(\\mathbf{x}|\\lambda) d\\mathbf{x}\n$$\nThe log-probability is $\\ln p(\\mathbf{x}|\\lambda) = \\ln r(\\mathbf{x};\\lambda) - \\ln(\\rho_0 A)$. Its derivative with respect to $\\lambda$ is:\n$$\n\\frac{\\partial}{\\partial \\lambda} \\ln p(\\mathbf{x}|\\lambda) = \\frac{\\partial}{\\partial \\lambda} \\ln \\left( 1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right) \\right)\n$$\nUsing the chain rule and the derivative of cosine:\n$$\n\\frac{\\partial}{\\partial \\lambda} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right) = -\\sin\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right) \\left( -\\frac{2\\pi}{\\lambda^2}(\\mathbf{u}_{m}\\cdot\\mathbf{x}) \\right) = \\frac{2\\pi}{\\lambda^2}(\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\n$$\nSo,\n$$\n\\frac{\\partial}{\\partial \\lambda} \\ln p(\\mathbf{x}|\\lambda) = \\frac{\\alpha \\sum_{m=1}^{3} \\frac{2\\pi}{\\lambda^2}(\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)}{1 \\;+\\; \\alpha \\sum_{m=1}^{3} \\cos\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)}\n$$\nFor small $\\alpha \\ll 1$, we can approximate the denominator by $1$ and the probability density $p(\\mathbf{x}|\\lambda)$ by $1/A$. The calculation of the Fisher information requires terms up to order $\\alpha^2$.\n$$\n\\left(\\frac{\\partial}{\\partial \\lambda} \\ln p(\\mathbf{x}|\\lambda)\\right)^2 \\approx \\alpha^2 \\left(\\sum_{m=1}^{3} \\frac{2\\pi}{\\lambda^2}(\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin\\!\\left(\\frac{2\\pi}{\\lambda}\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right)^2\n$$\nThe expectation is taken with respect to $p(\\mathbf{x}|\\lambda) \\approx 1/A$ for the leading order term:\n$$\nI_1(\\lambda) \\approx \\int_{\\Omega} \\alpha^2 \\left( \\frac{2\\pi}{\\lambda^2} \\sum_{m=1}^{3} (\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin\\!\\left(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right)^2 \\frac{d\\mathbf{x}}{A}\n$$\n$$\n= \\frac{4\\pi^2 \\alpha^2}{A\\lambda^4} \\int_{\\Omega} \\left( \\sum_{m=1}^{3} (\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin\\!\\left(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}\\right)\\right)^2 d\\mathbf{x}\n$$\nwhere $k=2\\pi/\\lambda$. Expanding the square gives diagonal and cross terms. Due to the \"many periods\" assumption, the oscillatory cross terms integrate to zero:\n$$\n\\int_{\\Omega} (\\mathbf{u}_{m}\\cdot\\mathbf{x})(\\mathbf{u}_{n}\\cdot\\mathbf{x})\\sin(k\\mathbf{u}_{m}\\cdot\\mathbf{x})\\sin(k\\mathbf{u}_{n}\\cdot\\mathbf{x}) d\\mathbf{x} \\approx 0 \\quad \\text{for } m \\neq n\n$$\nWe are left with the sum of the diagonal terms:\n$$\nI_1(\\lambda) \\approx \\frac{4\\pi^2 \\alpha^2}{A\\lambda^4} \\sum_{m=1}^{3} \\int_{\\Omega} (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\sin^2(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}) d\\mathbf{x}\n$$\nTo evaluate the integral, we use the \"many periods\" assumption again to approximate the spatial average as a product of averages:\n$$\n\\int_{\\Omega} (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\sin^2(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}) d\\mathbf{x} \\approx A \\cdot \\left\\langle (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\right\\rangle \\cdot \\left\\langle \\sin^2(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}) \\right\\rangle\n$$\nThe average of $\\sin^2(\\cdot)$ over many cycles is $1/2$. To find $\\langle (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\rangle$ over the square domain $\\Omega$, we first find the moments of the coordinates $x$ and $y$.\n$$\n\\langle x^2 \\rangle = \\frac{1}{A} \\int_{-L/2}^{L/2}\\int_{-L/2}^{L/2} x^2 dx dy = \\frac{L}{L^2} \\left[\\frac{x^3}{3}\\right]_{-L/2}^{L/2} = \\frac{1}{L} \\frac{L^3}{12} = \\frac{L^2}{12} = \\frac{A}{12}\n$$\nBy symmetry, $\\langle y^2 \\rangle = A/12$ and $\\langle xy \\rangle = 0$. Let $\\mathbf{u}_m = (\\cos \\theta_m, \\sin \\theta_m)^T$.\n$$\n\\langle (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\rangle = \\langle (x\\cos\\theta_m + y\\sin\\theta_m)^2 \\rangle = \\langle x^2 \\rangle \\cos^2\\theta_m + \\langle y^2 \\rangle \\sin^2\\theta_m = \\frac{A}{12} (\\cos^2\\theta_m + \\sin^2\\theta_m) = \\frac{A}{12}\n$$\nThis average is independent of the direction $\\mathbf{u}_m$. Substituting back into the integral:\n$$\n\\int_{\\Omega} (\\mathbf{u}_{m}\\cdot\\mathbf{x})^2 \\sin^2(k\\,\\mathbf{u}_{m}\\cdot\\mathbf{x}) d\\mathbf{x} \\approx A \\cdot \\frac{A}{12} \\cdot \\frac{1}{2} = \\frac{A^2}{24}\n$$\nNow we can compute $I_1(\\lambda)$:\n$$\nI_1(\\lambda) \\approx \\frac{4\\pi^2 \\alpha^2}{A\\lambda^4} \\sum_{m=1}^{3} \\frac{A^2}{24} = \\frac{4\\pi^2 \\alpha^2}{A\\lambda^4} \\cdot 3 \\cdot \\frac{A^2}{24} = \\frac{12\\pi^2 \\alpha^2 A}{24\\lambda^4} = \\frac{\\pi^2 \\alpha^2 A}{2\\lambda^4}\n$$\nThe total Fisher Information for $N$ spikes is:\n$$\nI(\\lambda) = N I_1(\\lambda) = \\frac{N \\pi^2 \\alpha^2 A}{2\\lambda^4}\n$$\nThe asymptotic variance of an efficient estimator, such as the MLE, is given by the CRB, which is the reciprocal of the Fisher Information.\n$$\n\\text{Var}(\\hat{\\lambda}) \\approx \\frac{1}{I(\\lambda)} = \\frac{2\\lambda^4}{N \\pi^2 \\alpha^2 A}\n$$\nThis is the asymptotic variance of the MLE for $\\lambda$ in the regime of small modulation $\\alpha$ and a large number of spikes $N$.",
            "answer": "$$\n\\boxed{\\frac{2\\lambda^4}{N \\pi^2 \\alpha^2 A}}\n$$"
        }
    ]
}