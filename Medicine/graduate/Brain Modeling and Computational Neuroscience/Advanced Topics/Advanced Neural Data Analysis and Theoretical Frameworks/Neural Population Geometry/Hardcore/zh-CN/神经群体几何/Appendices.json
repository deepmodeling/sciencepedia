{
    "hands_on_practices": [
        {
            "introduction": "研究神经群体几何的第一步是构建分析的主要对象：神经轨迹。本练习提供了从模拟脉冲数据构建此轨迹的实践操作，从一个低维潜在过程开始。通过计算轨迹的弧长，您将对如何量化神经状态空间的变化有一个具体的理解。",
            "id": "4003652",
            "problem": "给定从一个神经元群体记录的试次平均脉冲计数，您的任务是构建一个神经元群体状态空间轨迹并计算其弧长。在每个时间窗中，神经元群体由一个状态向量 $x(t) \\in \\mathbb{R}^N$ 表示，其分量是 $N$ 个神经元在时间窗 $t$ 的试次平均脉冲计数，其中 $t \\in \\{1,2,\\dots,T\\}$。状态空间轨迹的弧长由欧几里得度量定义为\n$$\nL \\;=\\; \\sum_{t=1}^{T-1} \\left\\| x(t+1) - x(t) \\right\\|_2 \\, .\n$$\n从以下基础开始：\n\n- 欧几里得空间 $\\mathbb{R}^N$ 和对于 $y \\in \\mathbb{R}^N$ 的欧几里得范数 $\\|y\\|_2 = \\sqrt{\\sum_{i=1}^N y_i^2}$。\n- 一个标准的脉冲点过程模型，其中在试次 $k$ 和时间窗 $t$ 中，神经元 $i$ 的观测脉冲计数 $s_i^{(k)}(t)$ 是独立的泊松随机变量，其均值等于一个非负发放率 $\\lambda_i(t)$ 乘以时间窗宽度 $\\Delta$（单位为秒），即 $s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t)\\Delta)$。\n- 一个驱动发放率的低维潜在动力学过程 $z(t) \\in \\mathbb{R}^d$。该过程通过一个线性映射加偏移量，然后经过一个指数非线性函数以确保正值性：$\\lambda(t) = \\exp\\!\\big(W z(t) + b\\big)$，其中 $W \\in \\mathbb{R}^{N \\times d}$ 且 $b \\in \\mathbb{R}^{N}$，指数函数逐分量应用。\n\n对于下面的每个测试用例，根据指定的动力学确定性地构建 $z(t)$，使用给定的随机种子生成 $W$ 和 $b$，计算 $\\lambda(t)$，采样 $K$ 个独立试次以获得脉冲计数 $s_i^{(k)}(t)$，形成试次平均脉冲计数状态向量\n$$\nx(t) \\;=\\; \\frac{1}{K} \\sum_{k=1}^K s^{(k)}(t) \\in \\mathbb{R}^N \\, ,\n$$\n并计算弧长 $L$。将每个弧长以脉冲（计数）为单位表示为一个四舍五入到六位小数的实数。\n\n您的程序必须实现上述步骤，并为以下测试套件生成输出。请使用指定的确切参数值，所有随机数生成均由提供的种子控制，以确保可复现性。在实现中，时间索引应使用整数 $t \\in \\{0,1,\\dots,T-1\\}$，对应于上述公式中的 $t \\in \\{1,2,\\dots,T\\}$。\n\n参数化用例的测试套件：\n\n- 用例 A（正常路径，旋转加斜坡潜在动力学）：\n  - $N = 100$， $T = 1000$， $K = 50$， $d = 3$， $\\Delta = 0.01$ 秒。\n  - 潜在动力学：$z_1(t) = A_1 \\cos(\\omega t)$ 其中 $A_1 = 1.0$，$z_2(t) = A_2 \\sin(\\omega t)$ 其中 $A_2 = 0.8$，$z_3(t) = \\alpha \\left(t - \\frac{T}{2}\\right)$ 其中 $\\alpha = 0.001$，$\\omega = 0.02$ 弧度/时间窗。\n  - 权重和偏移量：使用种子 $\\mathrm{seed}_W = 1$ 构建 $W$ 和 $b$。用独立的 $\\mathcal{N}(0,\\sigma_W^2)$ 条目（其中 $\\sigma_W = 0.2$）构建 $W$，并将 $b$ 构建为 $b_i = \\log(5.0) + \\epsilon_i$（其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma_b^2)$，$\\sigma_b = 0.3$），对于 $i = 1,\\dots,N$ 独立。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 11$。\n\n- 用例 B（边界跳跃，最小 $T$）：\n  - $N = 100$， $T = 2$， $K = 50$， $d = 1$， $\\Delta = 0.01$ 秒。\n  - 潜在动力学：$z_1(0) = 0$，$z_1(1) = A_{\\mathrm{step}}$ 其中 $A_{\\mathrm{step}} = 2.0$。\n  - 权重和偏移量：$W$，$b$ 使用 $\\mathrm{seed}_W = 2$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 22$。\n\n- 用例 C（恒定潜在变量，测试纯噪声轨迹）：\n  - $N = 100$， $T = 1000$， $K = 100$， $d = 1$， $\\Delta = 0.01$ 秒。\n  - 潜在动力学：对于所有 $t$，$z_1(t) = 0$。\n  - 权重和偏移量：$W$，$b$ 使用 $\\mathrm{seed}_W = 3$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 33$。\n\n- 用例 D（单神经元正弦波，小 $T$）：\n  - $N = 1$，$T = 10$，$K = 1000$，$d = 1$，$\\Delta = 0.02$ 秒。\n  - 潜在动力学：$z_1(t) = A \\sin(\\omega t)$ 其中 $A = 3.0$，$\\omega = 0.5$ 弧度/时间窗。\n  - 权重和偏移量：$W$，$b$ 使用 $\\mathrm{seed}_W = 4$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 44$。\n\n- 用例 E（边界情况，$T=1$ 产生零弧长）：\n  - $N = 100$， $T = 1$， $K = 20$， $d = 1$， $\\Delta = 0.01$ 秒。\n  - 潜在动力学：$z_1(0) = 0$。\n  - 权重和偏移量：$W$，$b$ 使用 $\\mathrm{seed}_W = 5$，分布与用例 A 相同。\n  - 脉冲采样种子：$\\mathrm{seed}_{\\mathrm{spk}} = 55$。\n\n实现细节：\n\n- 对构建 $W$、$b$ 和进行脉冲采样使用独立的随机数生成器，并为每个用例指定种子。\n- 构建 $\\lambda(t) = \\exp(W z(t) + b)$，指数函数逐分量应用以确保正值性。\n- 独立地对神经元、时间窗和试次进行脉冲计数采样 $s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t)\\Delta)$；然后通过跨试次平均计算 $x(t)$。\n- 完全按照上述欧几里得弧长公式计算 $L$。\n- 将每个 $L$ 以脉冲为单位表示为一个四舍五入到六位小数的浮点数。\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含按用例 A到E顺序排列的结果，以逗号分隔并用方括号括起，例如，\"[result_A,result_B,result_C,result_D,result_E]\"。每个条目必须四舍五入到六位小数。",
            "solution": "经过彻底的验证过程，该问题被认定为有效。它在科学上基于计算神经科学的原理，特别是关于神经元群体活动的建模。所有参数和程序都明确定义，使得问题定义良好且客观。它没有矛盾、歧义和事实上的不健全之处。该问题要求实现一个标准的神经脉冲序列生成模型，并计算由此产生的状态空间轨迹的几何属性——弧长。\n\n解决方案首先构建一个低维潜在轨迹，然后将其映射到高维神经发放率，从一个随机过程中采样脉冲计数，最后计算试次平均活动的几何形状。每个步骤详述如下。\n\n神经元群体活动的状态空间表示为理解信息处理方式提供了一个几何框架。在这个模型中，一个由 $N$ 个神经元组成的群体在给定时间 $t$ 的状态是一个向量 $x(t) \\in \\mathbb{R}^N$。这些向量随时间变化的序列 $\\{x(0), x(1), \\dots, x(T-1)\\}$ 在这个 $N$ 维状态空间中形成一条轨迹。该轨迹的几何属性，如其长度，可以揭示计算上的目标。\n\n目标是计算该轨迹的弧长 $L$，它被定义为连续状态向量之间欧几里得距离的总和：\n$$\nL = \\sum_{t=0}^{T-2} \\| x(t+1) - x(t) \\|_2\n$$\n其中 $\\| \\cdot \\|_2$ 表示 $\\mathbb{R}^N$ 中的标准欧几里得范数。请注意，为符合实现规范，求和已调整为基于零的时间索引 $t \\in \\{0, 1, \\dots, T-1\\}$。\n\n状态向量 $x(t)$ 的生成遵循脑建模中典型的多步生成过程：\n\n1.  **潜在动力学 (Latent Dynamics)**：首先定义一个低维时间序列 $z(t) \\in \\mathbb{R}^d$，其中 $d \\ll N$。这个潜在变量被假定为捕捉了神经回路的基本、潜在的计算过程。对于每个测试用例，$z(t)$ 的动力学都是确定性给出的。例如，在用例 A 中，动力学是正弦函数和线性函数的组合，在 $d=3$ 维潜在空间中创建了一条螺旋轨迹：\n    $$\n    z(t) = \\begin{pmatrix} A_1 \\cos(\\omega t) \\\\ A_2 \\sin(\\omega t) \\\\ \\alpha(t - T/2) \\end{pmatrix}\n    $$\n\n2.  **发放率生成 (Firing Rate Generation)**：潜在动力学 $z(t)$ 驱动 $N$ 个神经元的发放率 $\\lambda(t) \\in \\mathbb{R}^N$。此映射被建模为一个线性变换后跟一个非线性函数，以确保发放率为非负值。\n    $$\n    \\lambda(t) = \\exp(W z(t) + b)\n    $$\n    这里，$W \\in \\mathbb{R}^{N \\times d}$ 是一个权重矩阵，$b \\in \\mathbb{R}^N$ 是一个偏置向量。指数函数是逐分量应用的。$W$ 和 $b$ 从指定的正态分布中抽取，并使用由 $\\mathrm{seed}_W$ 设定的专用随机数生成器以保证可复现性。\n\n3.  **脉冲计数采样 (Spike Count Sampling)**：单个神经元的活动是随机的。我们将神经元 $i$ 在试次 $k$、时间 $t$ 的脉冲计数 $s_i^{(k)}(t)$ 建模为从泊松分布中的一次独立抽取。该分布的均值是发放率 $\\lambda_i(t)$ 乘以时间窗宽度 $\\Delta$。\n    $$\n    s_i^{(k)}(t) \\sim \\mathrm{Poisson}(\\lambda_i(t) \\Delta)\n    $$\n    此步骤对 $K$ 个独立试次、$N$ 个神经元和 $T$ 个时间窗中的每一个都执行。为此次随机采样使用第二个独立的、由 $\\mathrm{seed}_{\\mathrm{spk}}$ 设定的随机数生成器。\n\n4.  **状态向量构建 (State Vector Construction)**：为了获得一个噪声较小的群体状态表示，将脉冲计数在 $K$ 个试次上进行平均。这产生了状态向量 $x(t)$：\n    $$\n    x(t) = \\frac{1}{K} \\sum_{k=1}^K s^{(k)}(t)\n    $$\n    其中 $s^{(k)}(t)$ 是在试次 $k$、时间 $t$ 时所有 $N$ 个神经元的脉冲计数向量。由此产生的向量集 $\\{x(0), \\dots, x(T-1)\\}$ 构成了神经轨迹。\n\n5.  **弧长计算 (Arc Length Calculation)**：最后，通过对轨迹上连续点之间的欧几里得距离求和来计算弧长 $L$，如初始公式所定义。对于 $T \\le 1$ 的边界情况，轨迹最多只包含一个点，此时对空集段的求和定义为 $L=0$。\n\n实现将为每个测试用例系统地执行这些步骤。为了效率，将使用 `numpy` 库进行向量化操作。将为模型参数生成（$W, b$）和脉冲计数采样初始化独立的随机数生成器，以确保精确遵守指定的种子并获得可复现的结果。每个用例的最终弧长将四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the arc length of neural population state-space trajectories\n    for a suite of test cases based on a generative model.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"params\": {\n                \"N\": 100, \"T\": 1000, \"K\": 50, \"d\": 3, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"rotational_ramp\",\n                \"A1\": 1.0, \"A2\": 0.8, \"omega\": 0.02, \"alpha\": 0.001\n            },\n            \"seeds\": {\"seed_W\": 1, \"seed_spk\": 11}\n        },\n        {\n            \"name\": \"Case B\",\n            \"params\": {\n                \"N\": 100, \"T\": 2, \"K\": 50, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"step\",\n                \"A_step\": 2.0\n            },\n            \"seeds\": {\"seed_W\": 2, \"seed_spk\": 22}\n        },\n        {\n            \"name\": \"Case C\",\n            \"params\": {\n                \"N\": 100, \"T\": 1000, \"K\": 100, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"constant_zero\"\n            },\n            \"seeds\": {\"seed_W\": 3, \"seed_spk\": 33}\n        },\n        {\n            \"name\": \"Case D\",\n            \"params\": {\n                \"N\": 1, \"T\": 10, \"K\": 1000, \"d\": 1, \"delta\": 0.02,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"sinusoid\",\n                \"A\": 3.0, \"omega\": 0.5\n            },\n            \"seeds\": {\"seed_W\": 4, \"seed_spk\": 44}\n        },\n        {\n            \"name\": \"Case E\",\n            \"params\": {\n                \"N\": 100, \"T\": 1, \"K\": 20, \"d\": 1, \"delta\": 0.01,\n                \"sigma_W\": 0.2, \"sigma_b\": 0.3, \"log_base_rate\": np.log(5.0)\n            },\n            \"latent_dynamics\": {\n                \"type\": \"constant_zero\"\n            },\n            \"seeds\": {\"seed_W\": 5, \"seed_spk\": 55}\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        p = case[\"params\"]\n        ld = case[\"latent_dynamics\"]\n        s = case[\"seeds\"]\n\n        # Unpack parameters for clarity\n        N, T, K, d, delta = p[\"N\"], p[\"T\"], p[\"K\"], p[\"d\"], p[\"delta\"]\n        sigma_W, sigma_b, log_base_rate = p[\"sigma_W\"], p[\"sigma_b\"], p[\"log_base_rate\"]\n        seed_W, seed_spk = s[\"seed_W\"], s[\"seed_spk\"]\n        \n        # 1. Initialize random number generators with specified seeds\n        rng_W = np.random.default_rng(seed_W)\n        rng_spk = np.random.default_rng(seed_spk)\n\n        # 2. Generate weight matrix W and offset vector b\n        W = rng_W.normal(loc=0.0, scale=sigma_W, size=(N, d))\n        epsilon = rng_W.normal(loc=0.0, scale=sigma_b, size=N)\n        b = log_base_rate + epsilon\n\n        # 3. Generate the latent trajectory z(t)\n        t_steps = np.arange(T)\n        z = np.zeros((T, d))\n        \n        if ld[\"type\"] == \"rotational_ramp\":\n            z[:, 0] = ld[\"A1\"] * np.cos(ld[\"omega\"] * t_steps)\n            z[:, 1] = ld[\"A2\"] * np.sin(ld[\"omega\"] * t_steps)\n            z[:, 2] = ld[\"alpha\"] * (t_steps - T / 2.0)\n        elif ld[\"type\"] == \"step\":\n            if T > 1:\n                z[1, 0] = ld[\"A_step\"]\n        elif ld[\"type\"] == \"constant_zero\":\n            # z is already initialized to zeros\n            pass\n        elif ld[\"type\"] == \"sinusoid\":\n            z[:, 0] = ld[\"A\"] * np.sin(ld[\"omega\"] * t_steps)\n\n        # 4. Compute firing rates lambda(t)\n        # z is (T, d), W is (N, d). We need z @ W.T which is (T, N)\n        # b is (N,). Broadcasting adds b to each row.\n        lambda_t = np.exp(z @ W.T + b)\n\n        # 5. Compute Poisson means\n        poisson_means = lambda_t * delta\n\n        # 6. Generate spike counts s_i^(k)(t)\n        # `poisson_means` is (T, N). `size=(K, T, N)` broadcasts correctly.\n        s_counts = rng_spk.poisson(lam=poisson_means, size=(K, T, N))\n\n        # 7. Compute trial-averaged state vector x(t)\n        # Average over the trials axis (axis 0)\n        x = s_counts.mean(axis=0)\n\n        # 8. Compute the arc length L\n        if T == 1:\n            L = 0.0\n        else:\n            # x is (T, N). Differences between consecutive time points.\n            diffs = x[1:] - x[:-1]  # Shape (T-1, N)\n            # Calculate Euclidean norm for each time step difference along neuron axis\n            segment_lengths = np.linalg.norm(diffs, axis=1) # Shape (T-1,)\n            L = np.sum(segment_lengths)\n            \n        results.append(f\"{L:.6f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "除了连续动态，群体几何还为理解大脑如何表示离散信息（例如不同的感觉刺激）提供了一个强大的框架。本练习探讨了如何通过忽略总体活动水平，转而关注群体向量之间的角度关系来量化这些表示的结构。您将实现一个聚类指数，以评估相关刺激的神经模式是否在超球面上几何地聚集在一起。",
            "id": "4003560",
            "problem": "给定一组在多次重复试验中测量的、对离散刺激条件的多神经元响应。每个刺激条件都与一个表示假设类别的簇标签相关联。您需要计算条件平均响应向量，通过欧几里得归一化将它们映射到单位超球面上，计算这些单位向量之间的成对余弦相似度，然后评估一个量化表征聚类的超球面聚类指数。\n\n基本原理：\n- 神经群体响应向量被建模为 $\\mathbb{R}^N$ 中的实值向量。\n- 向量 $\\mathbf{x} \\in \\mathbb{R}^N$ 的欧几里得范数为 $\\lVert \\mathbf{x} \\rVert_2 = \\sqrt{\\sum_{n=1}^N x_n^2}$。\n- 两个非零向量 $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^N$ 之间的余弦相似度为 $\\cos \\theta = \\dfrac{\\mathbf{x}^\\top \\mathbf{y}}{\\lVert \\mathbf{x} \\rVert_2 \\lVert \\mathbf{y} \\rVert_2}$，这等于归一化后单位超球面上相应单位向量的点积。\n\n定义和计算要求：\n1. 设有 $C$ 个刺激条件，每个条件在 $N$ 个神经元上重复测量 $T$ 次试验。令 $\\mathbf{R} \\in \\mathbb{R}^{C \\times T \\times N}$ 表示原始响应，其元素为 $R_{c,t,n}$，其中条件 $c \\in \\{0,\\dots,C-1\\}$，试验 $t \\in \\{0,\\dots,T-1\\}$，神经元 $n \\in \\{0,\\dots,N-1\\}$。\n2. 对每个条件 $c$，计算条件平均响应向量\n$$\n\\boldsymbol{\\mu}_c = \\frac{1}{T}\\sum_{t=0}^{T-1} \\mathbf{R}_{c,t,:} \\in \\mathbb{R}^N.\n$$\n3. 通过欧几里得归一化将每个 $\\boldsymbol{\\mu}_c$ 映射到单位超球面上：\n$$\n\\mathbf{m}_c = \\frac{\\boldsymbol{\\mu}_c}{\\lVert \\boldsymbol{\\mu}_c \\rVert_2} \\in \\mathbb{S}^{N-1},\n$$\n假设在提供的测试套件中，所有 $c$ 的 $\\lVert \\boldsymbol{\\mu}_c \\rVert_2 \\neq 0$。\n4. 计算超球面上条件均值之间的成对余弦相似度：\n$$\ns_{ij} = \\mathbf{m}_i^\\top \\mathbf{m}_j \\in [-1,1], \\quad \\text{for } 0 \\le i,j \\le C-1.\n$$\n5. 令 $\\mathbf{y} \\in \\{0,1,2,\\dots\\}^C$ 为簇标签向量，其中 $y_c$ 是条件 $c$ 的标签。定义簇内索引集\n$$\nW = \\{(i,j) \\mid 0 \\le i  j \\le C-1,\\; y_i = y_j\\},\n$$\n和簇间索引集\n$$\nB = \\{(i,j) \\mid 0 \\le i  j \\le C-1,\\; y_i \\ne y_j\\}.\n$$\n假设在所有提供的测试用例中，$W$ 和 $B$ 均不为空。\n6. 定义超球面聚类指数\n$$\nH = \\frac{1}{|W|} \\sum_{(i,j)\\in W} s_{ij} - \\frac{1}{|B|} \\sum_{(i,j)\\in B} s_{ij}.\n$$\n\n您的任务是：实现一个程序，为下方的每个测试用例计算上述定义的标量值 $H$。不涉及物理单位；所有量均为无量纲。通过余弦相似度隐式涉及的角度应以弧度处理，但仅需要余弦相似度的值。\n\n测试套件：\n为以下四个独立的测试用例提供输出。在每个用例中，一个条件下的所有试验都与一个指定的基础向量相同，这确保了条件均值等于该基础向量。\n\n- 测试用例 1：\n  - $C = 4$, $T = 3$, $N = 3$。\n  - 条件基础向量（每个条件重复 $T$ 次）：\n    - $c = 0$: $\\begin{bmatrix} 2 \\\\ 0 \\\\ 0 \\end{bmatrix}$，\n    - $c = 1$: $\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$，\n    - $c = 2$: $\\begin{bmatrix} 0 \\\\ 3 \\\\ 0 \\end{bmatrix}$，\n    - $c = 3$: $\\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}$。\n  - 簇标签：$\\mathbf{y} = [0, 0, 1, 1]$。\n- 测试用例 2：\n  - $C = 3$, $T = 2$, $N = 2$。\n  - 条件基础向量：\n    - $c = 0$: $\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$，\n    - $c = 1$: $\\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$，\n    - $c = 2$: $\\begin{bmatrix} -3 \\\\ 0 \\end{bmatrix}$。\n  - 簇标签：$\\mathbf{y} = [0, 0, 1]$。\n- 测试用例 3：\n  - $C = 3$, $T = 1$, $N = 3$。\n  - 条件基础向量：\n    - $c = 0$: $\\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$，\n    - $c = 1$: $\\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}$，\n    - $c = 2$: $\\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\end{bmatrix}$。\n  - 簇标签：$\\mathbf{y} = [0, 0, 1]$。\n- 测试用例 4：\n  - $C = 4$, $T = 2$, $N = 3$。\n  - 条件基础向量：\n    - $c = 0$: $\\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix}$，\n    - $c = 1$: $\\begin{bmatrix} 2 \\\\ 1 \\\\ 0 \\end{bmatrix}$，\n    - $c = 2$: $\\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$，\n    - $c = 3$: $\\begin{bmatrix} 0 \\\\ 2 \\\\ 1 \\end{bmatrix}$。\n  - 簇标签：$\\mathbf{y} = [0, 0, 1, 1]$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含四个结果，格式为方括号内的逗号分隔列表，每个数字四舍五入到六位小数，例如：$\\texttt{[1.234567,0.000000,2.500000,0.333333]}$。",
            "solution": "该问题是有效的，因为它在计算神经科学方面有科学依据，在数学上是适定 (well-posed) 的，并且其所有组成部分都有清晰客观的定义。它要求实现一个特定的神经群体分析度量，即超球面聚类指数 $H$。\n\n该指数背后的核心原理是量化神经响应模式在超球面上的几何分离。分析始于对一组 $C$ 个不同刺激条件的原始多神经元响应。这些高维响应首先在重复试验中进行平均，为每个条件 $c$ 生成一个平均响应向量 $\\boldsymbol{\\mu}_c \\in \\mathbb{R}^N$，其中 $N$ 是神经元的数量。这个平均步骤旨在减少试验间的变异性，并为每个条件提取一个稳定的表征。该问题通过直接以“基础向量”的形式提供这些平均向量来简化此过程。\n\n下一个关键步骤是将这些平均向量投影到单位超球面 $\\mathbb{S}^{N-1}$ 上。这是通过欧几里得归一化 $\\mathbf{m}_c = \\boldsymbol{\\mu}_c / \\lVert \\boldsymbol{\\mu}_c \\rVert_2$ 来完成的。通过将向量归一化为单位长度，该分析特意丢弃了关于神经群体总体活动幅度或发放率的信息，转而专注于方向信息，即神经群体间的相对活动模式。这一做法的动机是基于这样的假设：神经状态向量之间的几何关系（而非其绝对位置）编码了功能上相关的信息。\n\n一旦所有条件平均向量都表示为超球面上的点，它们之间的成对几何关系就通过余弦相似度 $s_{ij} = \\mathbf{m}_i^\\top \\mathbf{m}_j$ 来量化。对于单位向量，这只是它们的点积，取值范围从-1（反平行向量）到1（平行向量），0表示正交性。高的余弦相似度意味着两个条件引发了相似的神经激活模式。\n\n最后阶段是评估这些几何关系是否与条件的假设聚类一致。给定一组簇标签 $\\mathbf{y}$，所有条件对 $(i, j)$ 被划分为两个集合：$W$，即“簇内”对的集合，其中条件 $i$ 和 $j$ 属于同一簇 ($y_i = y_j$)；以及 $B$，即“簇间”对的集合，其中它们属于不同簇 ($y_i \\ne y_j$)。超球面聚类指数 $H$ 被定义为簇内对的平均相似度与簇间对的平均相似度之差：\n$$\nH = \\underbrace{\\frac{1}{|W|} \\sum_{(i,j)\\in W} s_{ij}}_{\\text{簇内平均相似度}} - \\underbrace{\\frac{1}{|B|} \\sum_{(i,j)\\in B} s_{ij}}_{\\text{簇间平均相似度}}\n$$\n一个大的正 $H$ 值表示神经表征根据标签 $\\mathbf{y}$ 进行了良好的聚类，意味着来自同一簇的向量在几何上比来自不同簇的向量更接近（具有更高的余弦相似度）。接近 $0$ 的 $H$ 值表示没有这样的聚类结构，而负值则表明平均而言，跨簇向量比簇内向量更相似。\n\n实现将系统地遵循这些步骤。对于每个测试用例，我们将：\n1. 定义条件平均向量 $\\boldsymbol{\\mu}_c$ 和簇标签 $\\mathbf{y}$。\n2. 归一化每个 $\\boldsymbol{\\mu}_c$ 以获得相应的单位向量 $\\mathbf{m}_c$。这可以使用 `numpy` 中的向量操作高效完成。\n3. 计算所有成对余弦相似度 $s_{ij}$ 的 $C \\times C$ 矩阵。这可以通过一次矩阵乘法完成：如果 $M$ 是一个行向量为 $\\mathbf{m}_c^\\top$ 的矩阵，则相似度矩阵为 $S = M M^\\top$。\n4. 遍历唯一的条件对 $(i, j)$（其中 $i  j$），根据它们的簇标签将 $s_{ij}$ 分配到簇内或簇间组，并计算每组的平均值。\n5. 从簇内平均相似度中减去簇间平均相似度以获得最终的 $H$ 值。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_hyperspherical_clustering_index(mean_vectors, cluster_labels):\n    \"\"\"\n    Computes the hyperspherical clustering index H for a set of condition-mean vectors.\n\n    Args:\n        mean_vectors (list of list of float): A list of C condition-mean vectors,\n                                              each of length N.\n        cluster_labels (list of int): A list of C cluster labels.\n\n    Returns:\n        float: The scalar value of the hyperspherical clustering index H.\n    \"\"\"\n    # 1. Convert inputs to numpy arrays for efficient computation.\n    # The problem statement ensures that the \"base vectors\" are the condition means.\n    mus = np.array(mean_vectors, dtype=float)\n    y = np.array(cluster_labels)\n    C = mus.shape[0]  # Number of conditions\n\n    # 2. Map each mean vector onto the unit hypersphere by Euclidean normalization.\n    # The problem guarantees that no mean vector has a zero norm.\n    norms = np.linalg.norm(mus, axis=1, keepdims=True)\n    ms = mus / norms\n\n    # 3. Compute pairwise cosine similarities.\n    # For unit vectors, this is their dot product.\n    # The similarity matrix S = M @ M.T\n    s_matrix = ms @ ms.T\n\n    # 4.  5. Partition pairs into within-cluster and between-cluster sets\n    # and compute average similarities.\n    within_cluster_sum = 0.0\n    within_cluster_count = 0\n    between_cluster_sum = 0.0\n    between_cluster_count = 0\n\n    # Iterate over unique pairs (i, j) where i  j.\n    # np.triu_indices gives the indices of the upper triangle of a matrix.\n    # k=1 excludes the diagonal.\n    rows, cols = np.triu_indices(C, k=1)\n\n    for i, j in zip(rows, cols):\n        similarity = s_matrix[i, j]\n        if y[i] == y[j]:\n            # This pair is within the same cluster.\n            within_cluster_sum += similarity\n            within_cluster_count += 1\n        else:\n            # This pair is between different clusters.\n            between_cluster_sum += similarity\n            between_cluster_count += 1\n\n    # The problem guarantees that both W and B are nonempty, so counts > 0.\n    avg_within_similarity = within_cluster_sum / within_cluster_count\n    avg_between_similarity = between_cluster_sum / between_cluster_count\n    \n    # 6. Define the hyperspherical clustering index H.\n    H = avg_within_similarity - avg_between_similarity\n    \n    return H\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite of four cases.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        {\n            \"mean_vectors\": [[2, 0, 0], [1, 0, 0], [0, 3, 0], [0, 1, 0]],\n            \"cluster_labels\": [0, 0, 1, 1],\n        },\n        # Test case 2\n        {\n            \"mean_vectors\": [[1, 0], [2, 0], [-3, 0]],\n            \"cluster_labels\": [0, 0, 1],\n        },\n        # Test case 3\n        {\n            \"mean_vectors\": [[1, 0, 0], [0, 1, 0], [0, 0, 1]],\n            \"cluster_labels\": [0, 0, 1],\n        },\n        # Test case 4\n        {\n            \"mean_vectors\": [[1, 1, 0], [2, 1, 0], [0, 1, 1], [0, 2, 1]],\n            \"cluster_labels\": [0, 0, 1, 1],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        h_value = compute_hyperspherical_clustering_index(\n            case[\"mean_vectors\"], case[\"cluster_labels\"]\n        )\n        results.append(h_value)\n\n    # Format the final output string as specified, with 6 decimal places.\n    output_str = f\"[{','.join(f'{r:.6f}' for r in results)}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "神经表示的几何排列对于可靠的计算具有直接的功能意义。这最后一个练习通过将分类器间隔的概念与解码器对噪声的鲁棒性联系起来，弥合了几何与功能之间的鸿沟。通过推导和计算几何分离度与可容忍噪声水平之间的关系，您将理解为什么广泛分离的神经状态对于鲁棒的神经编码至关重要。",
            "id": "4003672",
            "problem": "考虑神经元群体中的两种实验条件，每种条件由一个实数 $n$ 维空间中的平均响应向量表示。设正条件和负条件的平均响应向量分别为 $\\mathbf{m}_{+} \\in \\mathbb{R}^{n}$ 和 $\\mathbf{m}_{-} \\in \\mathbb{R}^{n}$。假设分类由线性支持向量机 (SVM) 执行，它为线性可分的数据找到一个具有最大几何间隔的分离超平面。对于带有标签 $y_{i} \\in \\{+1, -1\\}$ 的线性可分标记数据 $\\{ (\\mathbf{x}_{i}, y_{i}) \\}_{i=1}^{N}$，支持向量机 (SVM) 的原始优化问题是最小化 $\\frac{1}{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}$，约束条件为 $y_{i} \\left( \\mathbf{w}^{\\top} \\mathbf{x}_{i} + b \\right) \\geq 1$，其中 $\\mathbf{w} \\in \\mathbb{R}^{n}$ 是分离超平面的法向量，$b \\in \\mathbb{R}$ 是偏移量。由 $(\\mathbf{w}, b)$ 定义的超平面的几何间隔是数据点到超平面沿法线方向的最小距离，在规范缩放下等于 $\\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}}$。\n\n模型的噪声鲁棒性通过在神经元群体响应上添加加性各向同性高斯噪声来评估，即观测到的响应为 $\\mathbf{x}' = \\mathbf{x} + \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n})$，$\\sigma > 0$ 是每个坐标的标准差，$\\mathbf{I}_{n}$ 是 $n \\times n$ 的单位矩阵。线性分类器的决策变量是 $d(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$。在加性噪声模型下，决策变量的波动由 $\\mathbf{w}^{\\top} \\boldsymbol{\\eta}$ 的分布和正态分布的标准性质决定。\n\n仅从上述定义以及关于正态分布和线性分类的公认事实出发，推导一个算法以：\n1. 在线性可分的情况下，计算条件平均响应对 $\\mathbf{m}_{+}$ 和 $\\mathbf{m}_{-}$ 的 SVM 几何间隔 $m$。\n2. 通过确定最大的 $\\sigma$ (记为 $\\sigma_{\\text{max}}$)，将间隔 $m$ 与对加性各向同性高斯噪声的鲁棒性联系起来。该 $\\sigma_{\\text{max}}$ 需满足：当分类器应用于条件平均响应时，任一均值下的误分类概率不超过以小数表示的指定容错率 $\\tau \\in (0, 0.5)$。\n\n您的程序必须实现上述推导，并为下面的每个测试用例计算 $(m, \\sigma_{\\text{max}})$。如果数据在条件均值层面不是线性可分的（例如，如果 $\\mathbf{m}_{+} = \\mathbf{m}_{-}$），则将几何间隔定义为 $m = 0$，并对任何 $\\tau \\in (0, 0.5)$ 报告 $\\sigma_{\\text{max}} = 0$。\n\n测试套件（每个用例由 $(\\mathbf{m}_{+}, \\mathbf{m}_{-}, \\tau)$ 指定）：\n- 用例 1：$\\mathbf{m}_{+} = (1, 0, 0, 0, 0)$，$\\mathbf{m}_{-} = (-1, 0, 0, 0, 0)$，$\\tau = 0.1$。\n- 用例 2：$\\mathbf{m}_{+} = (0.1, 0, 0)$，$\\mathbf{m}_{-} = (0, 0, 0)$，$\\tau = 0.01$。\n- 用例 3：$\\mathbf{m}_{+} = (0.5, 0.5, \\dots, 0.5) \\in \\mathbb{R}^{50}$，$\\mathbf{m}_{-} = (-0.5, -0.5, \\dots, -0.5) \\in \\mathbb{R}^{50}$，$\\tau = 0.001$。\n- 用例 4：$\\mathbf{m}_{+} = (0, 0, 0)$，$\\mathbf{m}_{-} = (0, 0, 0)$，$\\tau = 0.1$。\n\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表，列表中的每个元素本身是一个对应于一个测试用例的双元素列表 $[m, \\sigma_{\\text{max}}]$。所有浮点数必须四舍五入到六位小数。例如，两个假设用例的输出应如下所示：$[[0.500000,0.300000],[1.250000,0.800000]]$。",
            "solution": "问题陈述已经过验证，并被认为是合理的。它在科学上基于线性代数、统计决策理论和支持向量机几何学的原理。该问题是适定的、客观的，并包含推导唯一解所需的所有必要信息。\n\n按要求，推导分两部分进行：首先，计算两个条件平均响应的几何间隔 $m$；其次，将此间隔与最大可容忍噪声 $\\sigma_{\\text{max}}$ 联系起来。\n\n### 第1部分：SVM 几何间隔 ($m$) 的推导\n\n给定两个条件平均响应向量 $\\mathbf{m}_{+} \\in \\mathbb{R}^{n}$ 和 $\\mathbf{m}_{-} \\in \\mathbb{R}^{n}$。这可以被视为一个包含两个点 $(\\mathbf{m}_{+}, +1)$ 和 $(\\mathbf{m}_{-}, -1)$ 的数据集。线性支持向量机 (SVM) 的目标是找到一个由法向量 $\\mathbf{w} \\in \\mathbb{R}^{n}$ 和偏移量 $b \\in \\mathbb{R}$ 定义的超平面，以最大化几何间隔。间隔最大化问题表述为：\n$$\n\\min_{\\mathbf{w}, b} \\frac{1}{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}\n$$\n约束条件为：\n$$\n\\begin{cases}\n(+1) (\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) \\geq 1 \\\\\n(-1) (\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b) \\geq 1\n\\end{cases}\n$$\n对于两个线性可分的点，在最大间隔的情况下，这两个点本身就成为支持向量，这意味着不等式约束变为活动等式：\n$$\n\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b = 1 \\\\\n\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b = -1\n$$\n这是一个由两个线性方程组成的方程组。用第一个方程减去第二个方程得到：\n$$\n(\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) - (\\mathbf{w}^{\\top} \\mathbf{m}_{-} + b) = 1 - (-1)\n$$\n$$\n\\mathbf{w}^{\\top} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) = 2\n$$\n要在关于 $\\mathbf{w}$ 的这个单线性约束下最小化 $\\lVert \\mathbf{w} \\rVert_{2}^{2}$，向量 $\\mathbf{w}$ 必须与定义该约束的向量 $(\\mathbf{m}_{+} - \\mathbf{m}_{-})$ 平行。这是使用拉格朗日乘子法进行优化或应用柯西-施瓦茨不等式的一个标准结果。因此，我们可以写出 $\\mathbf{w} = k (\\mathbf{m}_{+} - \\mathbf{m}_{-})$，其中 $k \\in \\mathbb{R}$ 是某个标量。将此形式代入约束方程：\n$$\n(k (\\mathbf{m}_{+} - \\mathbf{m}_{-}))^{\\top} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) = 2\n$$\n$$\nk \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2} = 2\n$$\n如果 $\\mathbf{m}_{+} \\neq \\mathbf{m}_{-}$，我们可以解出 $k$：\n$$\nk = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}}\n$$\n这给出了最优权重向量：\n$$\n\\mathbf{w} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} (\\mathbf{m}_{+} - \\mathbf{m}_{-})\n$$\n几何间隔 $m$ 定义为 $m = \\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}}$。我们计算 $\\mathbf{w}$ 的范数：\n$$\n\\lVert \\mathbf{w} \\rVert_{2} = \\left\\lVert \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} (\\mathbf{m}_{+} - \\mathbf{m}_{-}) \\right\\rVert_{2} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}^{2}} \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2} = \\frac{2}{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}}\n$$\n因此，几何间隔为：\n$$\nm = \\frac{1}{\\lVert \\mathbf{w} \\rVert_{2}} = \\frac{\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}}{2}\n$$\n这个结果很直观：两点的最大间隔是它们之间欧几里得距离的一半。如果两点相同（$\\mathbf{m}_{+} = \\mathbf{m}_{-}$），那么它们在非平凡意义上是线性不可分的。在这种情况下，$\\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2} = 0$，导致 $m=0$，这与问题对此边界情况的指定处理方式一致。\n\n### 第2部分：最大噪声标准差 ($\\sigma_{\\text{max}}$) 的推导\n\n我们现在评估分类器对加性各向同性高斯噪声的鲁棒性。观测到的响应是 $\\mathbf{x}' = \\mathbf{x} + \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^{2} \\mathbf{I}_{n})$。分类使用决策函数 $d(\\mathbf{x}') = \\mathbf{w}^{\\top}\\mathbf{x}' + b$ 来执行。\n\n考虑正均值附近的一个带噪观测 $\\mathbf{x}'_{+} = \\mathbf{m}_{+} + \\boldsymbol{\\eta}$。决策变量为：\n$$\nd(\\mathbf{x}'_{+}) = \\mathbf{w}^{\\top} (\\mathbf{m}_{+} + \\boldsymbol{\\eta}) + b = (\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b) + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}\n$$\n根据活动 SVM 约束，我们知道 $\\mathbf{w}^{\\top} \\mathbf{m}_{+} + b = 1$。因此，\n$$\nd(\\mathbf{x}'_{+}) = 1 + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}\n$$\n如果 $d(\\mathbf{x}'_{+})  0$（因为真实标签是 $+1$），则发生误分类。误分类概率为 $P(1 + \\mathbf{w}^{\\top} \\boldsymbol{\\eta}  0) = P(\\mathbf{w}^{\\top} \\boldsymbol{\\eta}  -1)$。\n\n我们来描述随机变量 $Z = \\mathbf{w}^{\\top} \\boldsymbol{\\eta}$ 的特征。由于它是独立高斯随机变量的线性组合，$Z$ 也是高斯分布的。它的均值为 $\\mathbb{E}[Z] = \\mathbf{w}^{\\top} \\mathbb{E}[\\boldsymbol{\\eta}] = \\mathbf{w}^{\\top} \\mathbf{0} = 0$。它的方差为 $\\text{Var}(Z) = \\mathbf{w}^{\\top} \\text{Cov}(\\boldsymbol{\\eta}) \\mathbf{w} = \\mathbf{w}^{\\top} (\\sigma^{2} \\mathbf{I}_{n}) \\mathbf{w} = \\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}$。\n所以，$Z \\sim \\mathcal{N}(0, \\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2})$。\n\n误分类概率 $P_{\\text{error}}$ 为：\n$$\nP_{\\text{error}} = P(Z  -1) = \\Phi\\left(\\frac{-1 - 0}{\\sqrt{\\sigma^{2} \\lVert \\mathbf{w} \\rVert_{2}^{2}}}\\right) = \\Phi\\left(\\frac{-1}{\\sigma \\lVert \\mathbf{w} \\rVert_{2}}\\right)\n$$\n其中 $\\Phi$ 是标准正态分布 $\\mathcal{N}(0, 1)$ 的累积分布函数 (CDF)。代入 $\\lVert \\mathbf{w} \\rVert_{2} = 1/m$，我们得到：\n$$\nP_{\\text{error}} = \\Phi\\left(\\frac{-m}{\\sigma}\\right)\n$$\n对负均值 $\\mathbf{m}_{-}$ 的对称分析得出误分类概率 $P(\\mathbf{w}^{\\top} \\boldsymbol{\\eta} > 1) = 1 - \\Phi(m/\\sigma) = \\Phi(-m/\\sigma)$，结果是相同的。\n\n我们要求这个概率不超过容错率 $\\tau \\in (0, 0.5)$：\n$$\n\\Phi\\left(\\frac{-m}{\\sigma}\\right) \\leq \\tau\n$$\n由于 $\\Phi$ 是单调递增的，我们可以对其两边应用其反函数 $\\Phi^{-1}$（概率单位函数或分位数函数）：\n$$\n\\frac{-m}{\\sigma} \\leq \\Phi^{-1}(\\tau)\n$$\n我们想找到满足此条件的最大 $\\sigma$。设 $z_{\\tau} = \\Phi^{-1}(\\tau)$。由于 $\\tau \\in (0, 0.5)$，$z_{\\tau}$ 是负数。为求解 $\\sigma > 0$ 重新整理不等式时需要反转不等号：\n$$\n\\sigma \\leq \\frac{-m}{z_{\\tau}} \\implies \\sigma \\leq \\frac{-m}{\\Phi^{-1}(\\tau)}\n$$\n因此，$\\sigma$ 的最大允许值为：\n$$\n\\sigma_{\\text{max}} = \\frac{-m}{\\Phi^{-1}(\\tau)}\n$$\n如果 $m=0$，那么显然 $\\sigma_{\\text{max}}=0$，这与问题陈述一致。\n\n### 算法摘要\n对于每个测试用例 $(\\mathbf{m}_{+}, \\mathbf{m}_{-}, \\tau)$：\n1.  计算欧几里得距离 $d = \\lVert \\mathbf{m}_{+} - \\mathbf{m}_{-} \\rVert_{2}$。\n2.  计算几何间隔 $m = d/2$。\n3.  如果 $m = 0$，则结果为 $(m, \\sigma_{\\text{max}}) = (0, 0)$。\n4.  如果 $m > 0$，计算标准正态分位数 $z_{\\tau} = \\Phi^{-1}(\\tau)$，然后计算 $\\sigma_{\\text{max}} = -m/z_{\\tau}$。\n5.  返回数对 $(m, \\sigma_{\\text{max}})$。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the SVM geometric margin and maximum noise robustness for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([1.0, 0.0, 0.0, 0.0, 0.0]), np.array([-1.0, 0.0, 0.0, 0.0, 0.0]), 0.1),\n        (np.array([0.1, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]), 0.01),\n        (np.full(50, 0.5), np.full(50, -0.5), 0.001),\n        (np.array([0.0, 0.0, 0.0]), np.array([0.0, 0.0, 0.0]), 0.1),\n    ]\n\n    results_str = []\n    for m_plus, m_minus, tau in test_cases:\n        # Step 1  2: Calculate the geometric margin m.\n        # The margin is half the Euclidean distance between the two mean vectors.\n        distance = np.linalg.norm(m_plus - m_minus)\n        margin = distance / 2.0\n\n        sigma_max = 0.0\n        # Step 3  4: Calculate sigma_max based on the margin.\n        if margin > 0:\n            # For a margin > 0, calculate the maximum tolerable noise standard deviation.\n            # Find the z-score corresponding to the cumulative probability tau.\n            # This is the inverse of the standard normal CDF, also known as the percent point function (ppf).\n            z_tau = norm.ppf(tau)\n            \n            # The derivation yields sigma_max = -m / z_tau.\n            # Since tau is in (0, 0.5), z_tau is negative, making sigma_max positive.\n            sigma_max = -margin / z_tau\n        # If margin is 0, sigma_max remains 0 as per the problem statement.\n\n        # Append the formatted result string for the current case.\n        results_str.append(f\"[{margin:.6f},{sigma_max:.6f}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```"
        }
    ]
}