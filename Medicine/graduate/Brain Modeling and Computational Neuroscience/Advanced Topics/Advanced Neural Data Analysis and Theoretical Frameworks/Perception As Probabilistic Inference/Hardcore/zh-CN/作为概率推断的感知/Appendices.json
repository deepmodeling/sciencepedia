{
    "hands_on_practices": [
        {
            "introduction": "在概率建模中，第一步是形式化地描述感官数据如何由世界中隐藏的原因生成。这个练习将指导你将一个简单的知觉情景（例如探测一个目标）转化为一个精确的数学模型，这是所有后续推断的基础。",
            "id": "4008976",
            "problem": "考虑一个单次试验的视觉检测任务，其中一个潜在的二元变量 $z \\in \\{0,1\\}$ 编码目标是否缺失 ($z=0$) 或存在 ($z=1$)。测量值 $x \\in \\mathbb{R}$ 是一个标量感官观测值。假设测量噪声是高斯加性噪声，当目标缺失时，基线测量的均值为 $0$，而当目标存在时，测量的均值为 $\\mu_1 \\in \\mathbb{R}$。设目标存在的先验概率为 $\\pi \\in (0,1)$，噪声方差为 $\\sigma^2 \\in (0,\\infty)$。将参数向量定义为 $\\theta = (\\pi, \\mu_1, \\sigma^2)$。哪个选项正确地指定了一个科学上合理的联合生成模型 $p(x,z \\mid \\theta)$，使得潜在原因 $z$ 通过高斯噪声影响观测值 $x$，并对规范中的每一项给出清晰的解释？\n\nA. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 对先验和似然进行参数化。\n\nB. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，对于 $z \\in \\{0,1\\}$，条件分布 $x \\mid z$ 都是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\sigma^2)$ 对先验和似然进行参数化。\n\nC. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、尺度为 $b>0$ 的拉普拉斯分布，并且 $\\theta=(\\pi,\\mu_1,b)$ 对先验和似然进行参数化。\n\nD. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 在比例上是高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 对先验和似然进行参数化。\n\nE. $p(x,z \\mid \\theta) = p(x \\mid \\theta)\\,p(z \\mid x,\\theta)$，其中 $p(x \\mid \\theta) = \\pi\\,\\mathcal{N}(x; \\mu_1, \\sigma^2) + (1-\\pi)\\,\\mathcal{N}(x; 0, \\sigma^2)$ 且 $p(z=1 \\mid x,\\theta) = \\frac{1}{1+\\exp(-\\alpha x)}$，其中 $\\alpha \\in \\mathbb{R}$ 控制斜率，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2,\\alpha)$ 对混合模型和后验分类器进行参数化。\n\n选择正确的选项。",
            "solution": "用户要求对问题陈述进行严格验证，然后对一个关于计算神经科学中生成模型的问题所提供的选项进行全面推导和评估。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n问题陈述提供了以下信息：\n- 一个潜在的二元变量 $z \\in \\{0,1\\}$。\n- $z=0$ 代表目标缺失。\n- $z=1$ 代表目标存在。\n- 一个标量感官观测值 $x \\in \\mathbb{R}$。\n- 测量噪声是高斯加性噪声。\n- 当目标缺失时($z=0$)，测量的均值为 $0$。\n- 当目标存在时($z=1$)，测量的均值为 $\\mu_1 \\in \\mathbb{R}$。\n- 目标存在的先验概率是 $P(z=1) = \\pi$，其中 $\\pi \\in (0,1)$。\n- 噪声方差是 $\\sigma^2$，其中 $\\sigma^2 \\in (0,\\infty)$。\n- 参数向量定义为 $\\theta = (\\pi, \\mu_1, \\sigma^2)$。\n- 任务是确定哪个选项正确地指定了联合生成模型 $p(x,z \\mid \\theta)$ 及其解释，其中潜在原因 $z$ 通过高斯噪声影响观测值 $x$。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了信号检测论 (SDT) 中的一个经典模型，该理论是心理物理学、知觉和计算神经科学中用于建模不确定性下决策的基本框架。它是将知觉视为概率推断的一个经典例子。该模型在科学上是合理的，并被广泛使用。\n- **适定性：** 这个问题是适定的。它为变量 ($z, x$)、参数 ($\\pi, \\mu_1, \\sigma^2$) 和概率关系的结构（二元变量的先验，高斯条件分布）提供了清晰的定义。其目标——构建联合概率分布 $p(x,z \\mid \\theta)$——是概率论中一个标准的、可解的任务。\n- **客观性：** 语言是形式化的、数学化的且无歧义的。没有主观或基于观点的陈述。\n\n问题陈述没有违反任何无效标准。它在科学上是合理的、适定的、客观的、完整的并且可形式化的。\n\n**步骤3：结论和行动**\n问题陈述是**有效的**。现在开始求解过程。\n\n### 联合生成模型的推导\n\n目标是构建联合概率分布 $p(x,z \\mid \\theta)$。生成模型指定了如何从潜在原因生成数据。这可以很自然地使用概率的链式法则表示为：\n$$p(x,z \\mid \\theta) = p(x \\mid z, \\theta) \\, p(z \\mid \\theta)$$\n这种分解代表了生成序列：首先，从其先验分布 $p(z \\mid \\theta)$ 中抽取一个潜在原因 $z$，然后从似然（或条件分布）$p(x \\mid z, \\theta)$ 中生成一个观测值 $x$。\n\n1.  **先验分布 $p(z \\mid \\theta)$：**\n    潜在变量 $z$ 是二元的，$z \\in \\{0, 1\\}$。我们已知目标存在的先验概率为 $P(z=1) = \\pi$。由于只有两种结果，目标缺失的概率为 $P(z=0) = 1-\\pi$。这描述了一个伯努利分布。伯努利变量的概率质量函数的一个紧凑数学表达式是：\n    $$p(z \\mid \\theta) = \\pi^z (1-\\pi)^{1-z}$$\n    这个表达式对于 $z=1$ 正确地得到 $\\pi$，对于 $z=0$ 正确地得到 $1-\\pi$。与先验相关的参数 $\\theta$ 是 $\\pi$。\n\n2.  **似然函数 $p(x \\mid z, \\theta)$：**\n    问题陈述指出，观测值 $x$ 是从一个包含加性高斯噪声的过程中生成的。这个过程的均值取决于潜在变量 $z$ 的状态。\n    -   当 $z=0$ (目标缺失) 时，$x$ 的均值为 $0$。$x$ 的分布是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布。其概率密度函数 (PDF) 为：\n        $$p(x \\mid z=0, \\theta) = \\mathcal{N}(x; 0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - 0)^2}{2\\sigma^2}\\right)$$\n    -   当 $z=1$ (目标存在) 时，$x$ 的均值为 $\\mu_1$。$x$ 的分布是均值为 $\\mu_1$、方差为 $\\sigma^2$ 的高斯分布。其概率密度函数 (PDF) 为：\n        $$p(x \\mid z=1, \\theta) = \\mathcal{N}(x; \\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - \\mu_1)^2}{2\\sigma^2}\\right)$$\n    我们可以写一个单一的表达式来涵盖这两种情况。高斯分布的均值在 $z=0$ 时为 $0$，在 $z=1$ 时为 $\\mu_1$。这可以紧凑地写为 $z\\,\\mu_1$。因此，似然函数的一般形式是：\n    $$p(x \\mid z, \\theta) = \\mathcal{N}(x; z\\,\\mu_1, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$$\n    与似然相关的参数 $\\theta$ 是 $\\mu_1$ 和 $\\sigma^2$。\n\n3.  **联合分布 $p(x,z \\mid \\theta)$：**\n    结合先验和似然，我们得到联合分布：\n    $$p(x,z \\mid \\theta) = p(z \\mid \\theta) \\, p(x \\mid z, \\theta) = \\left[ \\pi^z (1-\\pi)^{1-z} \\right] \\left[ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right) \\right]$$\n\n### 选项评估\n\n**A. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 对先验和似然进行参数化。**\n-   **数学表达式：** 该表达式与从第一性原理推导出的表达式完全匹配。项 $\\pi^z(1-\\pi)^{1-z}$ 正确地表示了伯努利先验 $p(z \\mid \\theta)$。项 $\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$ 正确地表示了均值为 $z\\,\\mu_1$（当 $z=0$ 时为 $0$，当 $z=1$ 时为 $\\mu_1$）和方差为 $\\sigma^2$ 的高斯似然 $p(x \\mid z, \\theta)$。\n-   **解释：** 所提供的解释与问题陈述和数学推导完全一致。$\\pi$ 是 $z=1$ 的先验，给定 $z$ 时 $x$ 的条件分布确实是均值为 $z\\mu_1$、方差为 $\\sigma^2$ 的高斯分布，并且参数 $\\theta$ 在先验和似然之间被正确划分。\n-   **结论：** **正确**。\n\n**B. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，对于 $z \\in \\{0,1\\}$，条件分布 $x \\mid z$ 都是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布，并且 $\\theta=(\\pi,\\sigma^2)$ 对先验和似然进行参数化。**\n-   **数学表达式：** 这个表达式的似然部分，$\\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\!\\left(-\\frac{x^2}{2\\sigma^2}\\right)$，对应于一个对所有 $z$ 值均值为 $0$ 的高斯分布。这意味着观测值 $x$ 独立于潜在原因 $z$，即 $p(x \\mid z, \\theta) = p(x \\mid \\theta)$。\n-   **解释：** 这与问题陈述中“当目标存在时，测量的均值为 $\\mu_1$”相矛盾。该选项中指定的模型意味着潜在原因 $z$ 对观测值 $x$ 的均值没有影响。\n-   **结论：** **不正确**。\n\n**C. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 是均值为 $z\\,\\mu_1$、尺度为 $b>0$ 的拉普拉斯分布，并且 $\\theta=(\\pi,\\mu_1,b)$ 对先验和似然进行参数化。**\n-   **数学表达式：** 这个表达式的似然部分，$\\frac{1}{2b} \\exp\\!\\left(-\\frac{|x - z\\,\\mu_1|}{b}\\right)$，是拉普拉斯分布的概率密度函数，而不是高斯分布。\n-   **解释：** 这与问题明确要求的“测量噪声是高斯加性噪声”相矛盾。\n-   **结论：** **不正确**。\n\n**D. $p(x,z \\mid \\theta) = \\big[\\pi^{z}(1-\\pi)^{1-z}\\big] \\,\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$，其中 $\\pi$ 是 $z=1$ 的先验概率，条件分布 $x \\mid z$ 在比例上是高斯分布，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2)$ 对先验和似然进行参数化。**\n-   **数学表达式：** 似然的表达式 $\\exp\\!\\left(-\\frac{(x - z\\,\\mu_1)^2}{2\\sigma^2}\\right)$ 缺少归一化常数 $\\frac{1}{\\sqrt{2\\pi\\sigma^2}}$。一个包含连续变量（如 $x$）的联合概率密度函数必须被归一化，使其在连续变量上的积分和在离散变量上的求和等于 $1$。没有这个常数，该函数不是一个有效的联合概率密度函数。问题要求正确地指定生成模型，这意味着一个被恰当定义的概率分布。\n-   **解释：** 尽管“在比例上是高斯分布”这一陈述承认了缺失的项，但它描述了一个不完整、因而不正确的概率密度函数规范。\n-   **结论：** **不正确**。\n\n**E. $p(x,z \\mid \\theta) = p(x \\mid \\theta)\\,p(z \\mid x,\\theta)$，其中 $p(x \\mid \\theta) = \\pi\\,\\mathcal{N}(x; \\mu_1, \\sigma^2) + (1-\\pi)\\,\\mathcal{N}(x; 0, \\sigma^2)$ 且 $p(z=1 \\mid x,\\theta) = \\frac{1}{1+\\exp(-\\alpha x)}$，其中 $\\alpha \\in \\mathbb{R}$ 控制斜率，并且 $\\theta=(\\pi,\\mu_1,\\sigma^2,\\alpha)$ 对混合模型和后验分类器进行参数化。**\n-   **数学表达式：** 此选项使用了分解 $p(x,z) = p(x)p(z|x)$。这在数学上是有效的，但它代表了“诊断”或“判别”方向 ($x \\to z$)，而不是潜在原因影响观测的“生成”方向 ($z \\to x$)。问题明确要求的是生成模型。此外，后验概率 $p(z=1 \\mid x,\\theta)$ 被指定为 $x$ 的一个简单逻辑斯蒂函数，这是一种近似。从选项A的生成模型推导出的真实后验是 $x$ 的一个线性函数的逻辑斯蒂函数，具体来说还包含一个偏移项。引入一个独立的参数 $\\alpha$ 也与原始参数集 $\\theta$ 不一致。\n-   **解释：** 这种表述描述了一个在概念上与所要求的生成过程不同的模型结构。它将一个边缘分布（证据）与一个单独参数化的后验（分类器）混合在一起。这不是联合生成模型本身的标准规范。\n-   **结论：** **不正确**。",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "一旦建立了生成模型，下一步就是利用观测数据来更新我们对世界隐藏状态的信念。这个练习将引导你完成一个完整的贝叶斯推断过程：通过解析地推导后验分布来更新信念，并从这个后验信念中得出一个最优的点估计值。",
            "id": "4008982",
            "problem": "在知觉决策的一项二元检测任务中，观察者将任何给定试验中检测到刺激的概率建模为一个潜参数 $z \\in (0,1)$。观察者假设 $z$ 服从形状参数为 $\\alpha > 0$ 和 $\\beta > 0$ 的贝塔先验分布，因此先验密度为 $p(z) = \\mathrm{Beta}(z;\\alpha,\\beta)$，并观测到在 $z$ 条件下生成的 $n$ 次独立伯努利试验 $x_{1},\\dots,x_{n} \\in \\{0,1\\}$。\n\n从概率论的基本定律（特别是贝叶斯法则和独立性定义）出发，并且只使用关于伯努利似然和贝塔分布族的经过充分检验的事实，执行以下操作：\n\n1. 以闭合形式推导精确、归一化的后验密度 $p(z \\mid x_{1:n})$，作为 $\\alpha$、$\\beta$ 和数据的函数。你的推导应明确指出后验分布的归一化常数（用贝塔函数表示），并将后验密度简化为某个已知分布族的一员。\n\n2. 在估计 $z$ 的二次损失（即损失函数 $\\ell(\\hat{z},z) = (\\hat{z}-z)^{2}$）下，计算贝叶斯估计量，并给出其作为 $\\alpha$、$\\beta$ 和数据的函数的显式公式。然后，在以下具体参数和数据摘要下对此估计量进行数值计算：先验参数 $\\alpha = 0.8$，$\\beta = 1.2$，试验次数 $n = 20$，以及检测（成功）次数 $s = \\sum_{i=1}^{n} x_{i} = 13$。\n\n将你的数值答案四舍五入至 $4$ 位有效数字。将最终答案表示为无量纲量。",
            "solution": "我们从贝叶斯法则开始。令 $x_{1:n} = (x_{1},\\dots,x_{n})$ 表示观测到的二元数据。给定数据下 $z$ 的后验密度为\n$$\np(z \\mid x_{1:n}) \\propto p(x_{1:n} \\mid z)\\, p(z).\n$$\n根据给定 $z$ 时伯努利试验的条件独立性，\n$$\np(x_{1:n} \\mid z) = \\prod_{i=1}^{n} p(x_{i} \\mid z) = \\prod_{i=1}^{n} z^{x_{i}} (1-z)^{1-x_{i}} = z^{\\sum_{i=1}^{n} x_{i}} (1-z)^{n - \\sum_{i=1}^{n} x_{i}}.\n$$\n记 $s = \\sum_{i=1}^{n} x_{i}$ 为检测（成功）次数。$z$ 的先验密度是参数为 $\\alpha,\\beta$ 的贝塔分布：\n$$\np(z) = \\mathrm{Beta}(z;\\alpha,\\beta) = \\frac{1}{B(\\alpha,\\beta)} z^{\\alpha - 1} (1-z)^{\\beta - 1},\n$$\n其中 $B(\\alpha,\\beta)$ 是贝塔函数，它可以表示为伽马函数的形式 $B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}$。\n\n将似然与先验相乘，\n$$\np(z \\mid x_{1:n}) \\propto \\left[z^{s} (1-z)^{n-s}\\right] \\left[\\frac{1}{B(\\alpha,\\beta)} z^{\\alpha - 1} (1-z)^{\\beta - 1}\\right]\n= \\frac{1}{B(\\alpha,\\beta)} z^{\\alpha + s - 1} (1-z)^{\\beta + n - s - 1}.\n$$\n为了归一化，我们使用定义贝塔函数的积分恒等式：\n$$\n\\int_{0}^{1} z^{a-1} (1-z)^{b-1} \\, dz = B(a,b),\n$$\n其中 $a = \\alpha + s$ 且 $b = \\beta + n - s$。因此，归一化的后验密度为\n$$\np(z \\mid x_{1:n}) = \\frac{1}{B(\\alpha + s,\\; \\beta + n - s)} z^{\\alpha + s - 1} (1-z)^{\\beta + n - s - 1}.\n$$\n这是一个具有更新后参数的贝塔分布：\n$$\nz \\mid x_{1:n} \\sim \\mathrm{Beta}(\\alpha + s,\\; \\beta + n - s).\n$$\n\n接下来，我们计算二次损失下的贝叶斯估计量。对于平方误差损失 $\\ell(\\hat{z},z) = (\\hat{z}-z)^{2}$，贝叶斯估计量是后验均值：\n$$\n\\hat{z}_{\\text{Bayes}} = \\mathbb{E}[z \\mid x_{1:n}].\n$$\n对于参数为 $a$ 和 $b$ 的贝塔分布，其均值为 $\\frac{a}{a+b}$。在我们的情况下，$a = \\alpha + s$ 且 $b = \\beta + n - s$，因此\n$$\n\\hat{z}_{\\text{Bayes}} = \\frac{\\alpha + s}{\\alpha + \\beta + n}.\n$$\n\n我们现在用给定的数值 $\\alpha = 0.8$，$\\beta = 1.2$，$n = 20$ 和 $s = 13$ 来计算这个表达式：\n$$\n\\hat{z}_{\\text{Bayes}} = \\frac{0.8 + 13}{0.8 + 1.2 + 20} = \\frac{13.8}{22}.\n$$\n计算其小数值：\n$$\n\\frac{13.8}{22} = 0.6272727\\ldots\n$$\n四舍五入到 $4$ 位有效数字，得到\n$$\n0.6273.\n$$\n因此，对于指定的先验和数据，二次损失下的贝叶斯估计量是 $0.6273$（无量纲）。",
            "answer": "$$\\boxed{0.6273}$$"
        },
        {
            "introduction": "拥有后验信念本身并非最终目标；大脑必须利用这种信念来指导行为。这个最终的练习探讨了不同的任务目标（形式化为损失函数 $L(\\hat{z},z)$）如何导致不同的最优决策，即使潜在的信念（后验分布 $p(z|x)$）是相同的。它强调了在存在不对称成本的情景下，推断和决策之间的关键区别。",
            "id": "4008950",
            "problem": "考虑一个潜在刺激变量 $z \\in \\mathbb{R}$（例如，视觉方向）和一个感官观测值 $x \\in \\mathbb{R}$。感知系统通过贝叶斯法则将似然 $p(x \\mid z)$ 与先验 $p(z)$ 相结合，形成后验 $p(z \\mid x)$。在贝叶斯决策理论中，最优估计量 $\\hat{z}(x)$ 最小化后验期望损失，其由风险泛函 $\\mathcal{R}(\\hat{z};x) = \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$ 定义，其中 $L(\\hat{z},z)$ 是一个与任务相关的损失。两个典型的估计量是最大后验 (MAP) 估计量 $\\hat{z}_{\\mathrm{MAP}}(x) = \\arg\\max_{z} p(z \\mid x)$ 和最小均方误差 (MMSE) 估计量 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，它们在不同的损失设定下产生。在高级感知情境中，损失可能是非对称的：例如，由于运动或安全约束，对 $z$ 的低估可能比高估的代价更高。考虑非对称线性损失\n$$\nL(\\hat{z},z) = c_{+} \\, (z - \\hat{z})_{+} + c_{-} \\, (\\hat{z} - z)_{+},\n$$\n其中 $(a)_{+} = \\max\\{a,0\\}$, $c_{+} > 0$ 是真实值 $z$ 超过估计值 $\\hat{z}$（低估）时的代价权重，而 $c_{-} > 0$ 是 $\\hat{z}$ 超过 $z$（高估）时的代价权重。假设 $p(z \\mid x)$ 是连续的，其累积分布函数为 $F_{Z \\mid X}(z \\mid x)$。选择所有关于 $\\hat{z}_{\\mathrm{MAP}}$ 和 $\\hat{z}_{\\mathrm{MMSE}}$ 如何对比，以及它们在非对称损失下何时存在差异的正确陈述。\n\nA. 最小化后验期望损失的贝叶斯估计量是 $\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$；在平方误差损失 $L(\\hat{z},z) = (z - \\hat{z})^{2}$ 下，它是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$；在连续情况下，在0-1损失的邻域极限形式下，它是后验众数 $\\hat{z}_{\\mathrm{MAP}}(x)$；在非对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 下，它是求解 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$ 的后验分位数，该分位数仅当 $p(z \\mid x)$ 是对称单峰且 $c_{+} = c_{-}$ 时才与 $\\hat{z}_{\\mathrm{MMSE}}$ 和 $\\hat{z}_{\\mathrm{MAP}}$ 一致。\n\nB. MAP估计量 $\\hat{z}_{\\mathrm{MAP}}(x)$ 最小化任何损失函数 $L(\\hat{z},z)$ 的期望损失，因为它最大化了 $p(z \\mid x)$。\n\nC. 对于任何凸损失函数 $L(\\hat{z},z)$，贝叶斯最优估计量总是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，因此损失的非对称性不会改变最优估计量。\n\nD. 对于非对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 且 $c_{+} > c_{-}$，贝叶斯最优估计量满足 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{-}}{c_{+} + c_{-}}$，这意味着估计量相对于 $\\mathbb{E}[z \\mid x]$ 向下偏移。\n\nE. 如果 $p(z \\mid x)$ 是高斯的且损失为平方误差，那么 $\\hat{z}_{\\mathrm{MAP}}(x) = \\hat{z}_{\\mathrm{MMSE}}(x)$；在非对称线性损失且 $c_{+} \\neq c_{-}$ 的情况下，贝叶斯最优估计量是一个后验分位数而不是后验均值，因此 $\\hat{z}_{\\mathrm{MMSE}}(x)$ 对于该损失不是最优的。",
            "solution": "问题陈述是贝叶斯决策理论中的一个有效且适定的问题，该理论是计算神经科学和统计学中的一个标准框架。所提供的定义和概念具有科学依据、内部一致，并且足以进行严谨的分析。我们将继续为指定的损失函数推导最优估计量，然后评估每个陈述。\n\n### 贝叶斯估计量的推导\n\n贝叶斯最优估计量 $\\hat{z}(x)$ 是使后验期望损失（或风险）$\\mathcal{R}(\\hat{z};x)$ 最小化的值：\n$$\n\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\mathcal{R}(\\hat{z};x) = \\arg\\min_{\\hat{z}} \\int_{-\\infty}^{\\infty} L(\\hat{z},z) \\, p(z \\mid x) \\, dz\n$$\n我们分析由损失函数 $L(\\hat{z},z)$ 的不同选择所产生的具体估计量。\n\n**1. 平方误差损失：** $L(\\hat{z},z) = (z - \\hat{z})^{2}$\n风险为 $\\mathcal{R}(\\hat{z};x) = \\int (z - \\hat{z})^{2} p(z \\mid x) \\, dz$。为了找到最小值，我们将关于 $\\hat{z}$ 的导数设为零：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = \\frac{\\partial}{\\partial \\hat{z}} \\int (z^2 - 2z\\hat{z} + \\hat{z}^2) p(z \\mid x) \\, dz = \\int (-2z + 2\\hat{z}) p(z \\mid x) \\, dz\n$$\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = 2\\hat{z} \\int p(z \\mid x) \\, dz - 2 \\int z p(z \\mid x) \\, dz = 2\\hat{z} - 2\\mathbb{E}[z \\mid x]\n$$\n将导数设为零得到 $\\hat{z} = \\mathbb{E}[z \\mid x]$。二阶导数为 $\\frac{\\partial^2 \\mathcal{R}}{\\partial \\hat{z}^2} = 2 > 0$，确认了这是一个最小值。因此，平方误差损失的最优估计量是后验均值 $\\hat{z}_{\\mathrm{MMSE}}(x)$。\n\n**2. 0-1 损失（极限情况）：** $L(\\hat{z},z) = \\begin{cases} 0  \\text{if } |z - \\hat{z}| \\le \\epsilon \\\\ 1  \\text{if } |z - \\hat{z}| > \\epsilon \\end{cases}$ 对于一个小的 $\\epsilon > 0$。\n风险为 $\\mathcal{R}(\\hat{z};x) = \\int_{|z - \\hat{z}| > \\epsilon} 1 \\cdot p(z \\mid x) \\, dz = 1 - \\int_{\\hat{z}-\\epsilon}^{\\hat{z}+\\epsilon} p(z \\mid x) \\, dz$。\n最小化风险等价于最大化项 $\\int_{\\hat{z}-\\epsilon}^{\\hat{z}+\\epsilon} p(z \\mid x) \\, dz$。当 $\\epsilon \\to 0$ 时，通过选择 $\\hat{z}$ 为密度 $p(z \\mid x)$ 最高处的值，可以使该积分最大化。根据定义，这就是后验众数。因此，该损失的最优估计量是最大后验 (MAP) 估计量 $\\hat{z}_{\\mathrm{MAP}}(x) = \\arg\\max_z p(z \\mid x)$。\n\n**3. 非对称线性损失：** $L(\\hat{z},z) = c_{+} \\, (z - \\hat{z})_{+} + c_{-} \\, (\\hat{z} - z)_{+}$\n风险可以写为：\n$$\n\\mathcal{R}(\\hat{z};x) = \\int_{-\\infty}^{\\hat{z}} c_{-} (\\hat{z} - z) p(z \\mid x) \\, dz + \\int_{\\hat{z}}^{\\infty} c_{+} (z - \\hat{z}) p(z \\mid x) \\, dz\n$$\n我们使用莱布尼茨积分法则对 $\\hat{z}$ 求导：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = \\int_{-\\infty}^{\\hat{z}} c_{-} p(z \\mid x) \\, dz - \\int_{\\hat{z}}^{\\infty} c_{+} p(z \\mid x) \\, dz\n$$\n令 $F_{Z \\mid X}(z \\mid x)$ 为后验 $p(z \\mid x)$ 的累积分布函数 (CDF)。导数为：\n$$\n\\frac{\\partial \\mathcal{R}}{\\partial \\hat{z}} = c_{-} F_{Z \\mid X}(\\hat{z} \\mid x) - c_{+} [1 - F_{Z \\mid X}(\\hat{z} \\mid x)]\n$$\n将此设为零以求最优的 $\\hat{z}$：\n$$\nc_{-} F_{Z \\mid X}(\\hat{z} \\mid x) = c_{+} - c_{+} F_{Z \\mid X}(\\hat{z} \\mid x)\n$$\n$$\n(c_{+} + c_{-}) F_{Z \\mid X}(\\hat{z} \\mid x) = c_{+}\n$$\n$$\nF_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}\n$$\n二阶导数为 $(c_{+} + c_{-})p(\\hat{z} \\mid x) > 0$，确认了这是一个最小值。最优估计量是后验分布中对应于累积概率 $\\frac{c_{+}}{c_{+} + c_{-}}$ 的分位数。\n\n### 选项评估\n\n**A. 最小化后验期望损失的贝叶斯估计量是 $\\hat{z}(x) = \\arg\\min_{\\hat{z}} \\int L(\\hat{z},z) \\, p(z \\mid x) \\, dz$；在平方误差损失 $L(\\hat{z},z) = (z - \\hat{z})^{2}$ 下，它是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$；在连续情况下，在0-1损失的邻域极限形式下，它是后验众数 $\\hat{z}_{\\mathrm{MAP}}(x)$；在非对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 下，它是求解 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$ 的后验分位数，该分位数仅当 $p(z \\mid x)$ 是对称单峰且 $c_{+} = c_{-}$ 时才与 $\\hat{z}_{\\mathrm{MMSE}}$ 和 $\\hat{z}_{\\mathrm{MAP}}$ 一致。**\n该陈述是一个全面的总结。\n- 初始的贝叶斯估计量定义是正确的。\n- 对平方误差损失的MMSE估计量的识别是正确的，如我们的推导所示。\n- 对0-1损失的MAP估计量的识别是正确的，如我们的推导所示。\n- 对非对称线性损失的分位数估计量的识别，以及正确的公式 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$，是正确的，如我们的推导所示。\n- 关于一致性的最终条件：如果 $p(z \\mid x)$ 是对称且单峰的，其均值 ($\\hat{z}_{\\mathrm{MMSE}}$)、中位数和众数 ($\\hat{z}_{\\mathrm{MAP}}$) 都相等。如果 $c_{+} = c_{-}$，最优分位数位于概率 $\\frac{c_{+}}{c_{+} + c_{-}} = \\frac{1}{2}$ 处，即中位数。因此，在这些条件下，所有三个估计量都一致。“仅当”部分对于此类模型中通常使用的一大类表现良好的单峰分布是成立的。为了使估计量一致，我们需要均值=众数=$q$-分位数。对于单峰分布，均值=众数意味着对称性。对称性意味着均值=中位数。因此，$q$-分位数必须是中位数，这要求 $q=1/2$，从而 $c_+=c_-$。该陈述在标准情境下是准确的。\n判定：**正确**。\n\n**B. MAP估计量 $\\hat{z}_{\\mathrm{MAP}}(x)$ 最小化任何损失函数 $L(\\hat{z},z)$ 的期望损失，因为它最大化了 $p(z \\mid x)$。**\n这个陈述是错误的。最优贝叶斯估计量取决于具体的损失函数。如上所述，平方误差损失导致的是后验均值 ($\\hat{z}_{\\mathrm{MMSE}}$)，而不是后验众数 ($\\hat{z}_{\\mathrm{MAP}}$)，除非后验分布是对称且单峰的。对于一般损失函数而言，最大化后验密度与最小化后验期望损失是不同的优化准则。\n判定：**不正确**。\n\n**C. 对于任何凸损失函数 $L(\\hat{z},z)$，贝叶斯最优估计量总是 $\\hat{z}_{\\mathrm{MMSE}}(x) = \\mathbb{E}[z \\mid x]$，因此损失的非对称性不会改变最优估计量。**\n这个陈述是错误的。非对称线性损失函数关于 $\\hat{z}$ 是凸的，但正如我们所推导的，其最优估计量是后验分位数，而不是后验均值（除非该分位数恰好等于均值）。另一个反例是绝对误差损失 $L(\\hat{z},z) = |z-\\hat{z}|$，它也是凸的，并以后验中位数作为最优估计量。“非对称性不改变估计量”这一断言也是错误的；如果 $c_{+} \\neq c_{-}$，分位数就不是中位数，这展示了非对称性的影响。\n判定：**不正确**。\n\n**D. 对于非对称线性损失 $L(\\hat{z},z) = c_{+} (z - \\hat{z})_{+} + c_{-} (\\hat{z} - z)_{+}$ 且 $c_{+} > c_{-}$，贝叶斯最优估计量满足 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{-}}{c_{+} + c_{-}}$，这意味着估计量相对于 $\\mathbb{E}[z \\mid x]$ 向下偏移。**\n这个陈述包含两个错误。首先，我们的推导表明正确的公式是 $F_{Z \\mid X}(\\hat{z} \\mid x) = \\frac{c_{+}}{c_{+} + c_{-}}$。陈述中的分子错误地写成了 $c_{-}$。其次，对低估的高昂代价 ($c_{+} > c_{-}$) 直观上应该导致估计值有向上的偏差，以避免代价高昂的低估。正确的公式证实了这一点：如果 $c_{+} > c_{-}$，那么 $\\frac{c_{+}}{c_{+} + c_{-}} > \\frac{1}{2}$，所以最优估计是一个高于中位数的分位数，对于对称的后验分布代表着向上偏移。陈述中不正确的公式将意味着一个低于中位数的分位数，从而导致“向下偏移”的错误结论。\n判定：**不正确**。\n\n**E. 如果 $p(z \\mid x)$ 是高斯的且损失为平方误差，那么 $\\hat{z}_{\\mathrm{MAP}}(x) = \\hat{z}_{\\mathrm{MMSE}}(x)$；在非对称线性损失且 $c_{+} \\neq c_{-}$ 的情况下，贝叶斯最优估计量是一个后验分位数而不是后验均值，因此 $\\hat{z}_{\\mathrm{MMSE}}(x)$ 对于该损失不是最优的。**\n- 第一部分：高斯后验分布是一种对称且单峰的分布。其均值、中位数和众数都位于分布的中心。因此，对于高斯后验分布，$\\hat{z}_{\\mathrm{MAP}}(x)$（众数）等于 $\\hat{z}_{\\mathrm{MMSE}}(x)$（均值）。这是正确的。\n- 第二部分：对于非对称线性损失且 $c_{+} \\neq c_{-}$，最优估计量是位于 $q = \\frac{c_{+}}{c_{+} + c_{-}} \\neq \\frac{1}{2}$ 的分位数。对于高斯分布（或任何对称分布），均值就是中位数（即 $1/2$-分位数）。由于最优估计量是一个不同于中位数的分位数，因此它不是后验均值。这是正确的。\n- 结论：因此，对于这种非对称损失，MMSE估计量不是最优的。这是一个正确的逻辑结论。\n整个陈述在事实上是正确的。\n判定：**正确**。",
            "answer": "$$\\boxed{AE}$$"
        }
    ]
}