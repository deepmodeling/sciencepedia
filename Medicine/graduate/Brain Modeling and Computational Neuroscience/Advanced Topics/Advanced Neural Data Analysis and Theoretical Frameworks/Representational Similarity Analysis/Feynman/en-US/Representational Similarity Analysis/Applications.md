## Applications and Interdisciplinary Connections

In our previous discussion, we acquainted ourselves with the principles of Representational Similarity Analysis. We learned how to distill the complex, high-dimensional activity of a neural population into a single, elegant object: the Representational Dissimilarity Matrix, or RDM. This matrix, you'll recall, is a fingerprint of sorts—a map of the geometric relationships between the brain's representations of different things. It captures the *shape* of information.

But a new tool is only as good as the questions it can answer. So, what can we *do* with this RDM? The true power and beauty of this framework, as we are about to see, lie in its extraordinary versatility. By translating the messy, idiosyncratic languages of different brains, models, and even species into the common currency of representational geometry, RSA becomes a kind of universal translator. It allows us to hold up the "informational fingerprint" from one system and compare it to another, asking a question of profound simplicity and power: "Are these two systems organizing information in the same way?" This comparison of RDMs is what we call **second-order analysis**, and it forms the foundation for a stunning array of applications that span the breadth of cognitive science and beyond . Let's embark on a journey to explore this new landscape.

### Mapping the Brain's Informational Landscape

Before we venture outside the brain, let’s first use RSA to chart its internal world with newfound precision. Neuroscientists have long sought to build maps of the brain, but these have traditionally been maps of anatomy or coarse functional activation. RSA allows us to draw a new kind of map: a map of *information*.

#### Where is the information? The Informational Searchlight

A classic question in fMRI research is "Where does the brain process X?". Traditionally, this was answered by looking for blobs of activation. But what if a region processes two different stimuli, say a picture of a cat and a picture of a dog, with the same overall level of activity? A traditional analysis would see nothing, yet the *patterns* of activity for the cat and dog might be entirely distinct.

This is where the **[searchlight analysis](@entry_id:1131333)** comes in. Instead of analyzing a large, predefined region of interest, we can sweep a small, spherical "searchlight" across the entire brain, voxel by voxel. At each location, the searchlight defines a small local population of voxels. We can then construct a local neural RDM from these voxels and compare it to a model RDM that hypothesizes a certain kind of information (e.g., a model where cats and dogs are dissimilar). By assigning the resulting correlation score to the center of the searchlight and repeating this for every point in the brain, we create a rich, [continuous map](@entry_id:153772). This map doesn't show where the brain is "active"; it shows where the brain’s local representational geometry matches our hypothesis . We can literally "search" the brain for the local circuits that represent the visual world, the meaning of words, or the structure of a decision. This is a powerful shift from mapping energy consumption to mapping [information content](@entry_id:272315).

#### When does information emerge? The Geometry of Thought in Time

The brain is not a static object; it is a dynamic, ever-changing process. While fMRI gives us excellent spatial resolution, its timescale is sluggish. To watch a representation being born, we can turn to techniques with millisecond precision, like Magnetoencephalography (MEG) or Electroencephalography (EEG).

By applying RSA not just once, but at every single time point in a trial, we can create a movie of the brain's representational geometry. We can compute an RDM for the neural-sensor patterns at 50 milliseconds after a stimulus appears, then at 51 milliseconds, 52, and so on . By comparing this evolving neural RDM to various model RDMs, we can watch as the brain's representation of a visual object transforms from a geometry based on simple pixels and edges to one organized by abstract categories. We can literally track the "aha!" moment when a stimulus is recognized, not as a change in overall activity, but as the moment the neural geometry "snaps" into a meaningful configuration.

#### How do brain areas communicate? A Conversation of Geometries

Brain areas do not work in isolation; they are in constant conversation. But what are they saying to each other? Functional connectivity has traditionally measured this conversation by correlating the raw activity levels between regions. But this is like trying to understand a phone call by only measuring the volume of the speakers.

**Representational connectivity** offers a far richer picture. Instead of correlating raw signals, we compute time-resolved RDMs for two different brain regions, A and B. We can then ask: does the representational geometry in region B at time $t$ look like the geometry in region A at time $t - \tau$? By correlating the RDMs between regions, optionally with a time lag, we can trace the flow of *structured information* through the brain . We can see not just that A is "talking" to B, but that it is transmitting a specific representational format—a particular way of organizing the world.

### Bridging Minds, Models, and Machines

Having charted the brain's internal information space, we can now use RSA to build bridges to the outside world—to our abstract theories of the mind and to the artificial minds we are creating in computers.

#### Testing Theories of Memory and Consciousness

Cognitive science is rich with elegant theories, but they are often difficult to test directly at the neural level. The Complementary Learning Systems theory, for instance, posits that our brain has two memory systems: a fast-learning hippocampus that captures the unique details of individual experiences ([pattern separation](@entry_id:199607)) and a slow-learning neocortex that gradually extracts general statistical knowledge over time.

RSA allows us to translate these abstract principles into concrete, testable hypotheses about RDMs. We can predict that immediately after learning, hippocampal RDMs should be highly item-specific, showing high dissimilarity between all unique items, even those from the same category. The neocortex, in contrast, should initially show little structure. But after a period of consolidation (like a night's sleep), we would predict that the neocortical RDM will have changed, now reflecting the semantic category structure, as it has integrated the new memories into its world model . RSA gives us a direct window into this dialogue between the specific and the general in the brain.

This approach can even shed light on one of the deepest mysteries of all: consciousness. How is it that some neural processing is associated with subjective experience, while other processing is not? A key hypothesis is that consciousness involves the creation of an explicit, abstract, and stable representation. Using RSA, we can test this by comparing neural RDMs for stimuli that are consciously perceived versus those that are not. A sophisticated study might find that a categorical model RDM (e.g., face vs. tool) shows a strong correlation with the neural RDM only for consciously seen trials. However, this requires immense methodological care, as conscious trials often have a better signal-to-noise ratio (SNR). A rigorous analysis must control for this, for instance by normalizing model fits by a "noise ceiling" that estimates the best possible performance given the data quality, and by using [partial correlation](@entry_id:144470) to rule out confounding low-level features that might distinguish the categories .

#### Comparing Brains to AI: The Rise of "Neuro-AI"

In recent years, deep neural networks (DNNs) have achieved brain-like performance on many tasks, especially in vision. This raises a tantalizing question: are they doing so using brain-like computations? RSA provides the perfect tool to answer this.

We can take a DNN, present it with the same images we show to a human subject, and extract the activation patterns from each of its layers. For each layer, we can compute a "DNN-RDM" . Now we have a stack of RDMs from the artificial system and a set of RDMs from a biological brain (perhaps from different visual cortical areas like V1, V4, and IT). We can simply correlate them. We might find that the early layers of the DNN have a geometry similar to early visual cortex (V1), representing simple features like edges, while deeper layers of the DNN develop a [representational geometry](@entry_id:1130876) that looks remarkably like that in higher visual cortex, organized by object categories.

This cross-system comparison is a two-way street. It allows neuroscientists to use DNNs as explicit, testable models of brain function. And it allows AI researchers to use the brain as a gold standard, debugging their networks by asking where and why their internal representations diverge from our own. When we have multiple competing models, RSA can act as a neutral arbiter. By vectorizing the RDMs from the brain and from several different models, we can use [multiple regression](@entry_id:144007) to ask which combination of models best explains the neural geometry, and use [partial correlation](@entry_id:144470) to discover what unique contribution each model makes  .

### The Unity of Representation: Beyond the Brain

The true intellectual climax of RSA is the realization that it is not just a tool for neuroscience. It is a general framework for understanding any system that transforms information.

#### A Tale of Two Minds: Comparing Species

How can you compare the mind of a bird to that of a primate? Their brains are built so differently. While we may know that a crow's nidopallium caudolaterale (NCL) and a macaque's prefrontal cortex (PFC) share a deep evolutionary origin ([deep homology](@entry_id:139107)), are the *computations* they perform for a task like estimating numbers also homologous, or did they evolve similar solutions independently (analogy)?

This is a classic problem in evolutionary biology. RSA provides a potential answer. We can record from the NCL and PFC while both animals perform a numerosity task and construct neural RDMs. If the RDM from the crow's brain shows a strong correlation with the RDM from the macaque's brain, it suggests they are using a similar representational code, a shared "number line" geometry. This provides powerful, mechanistic evidence for cognitive homology that goes beyond simple behavioral similarity .

Of course, such a profound claim requires profound scrutiny. A high correlation could be spurious, driven by shared sensitivity to low-level features in the stimuli rather than a shared high-level code. To make a convincing case, we must demonstrate that this similarity generalizes across different stimulus sets and tasks, and we must control for simpler explanations . The ultimate test might be to build a model of the representation in one species and show that it can predict the representational geometry in the other—a truly demanding form of cross-species validation .

#### Aligning the Unalignable: Overcoming Individuality

A thorny problem for all of neuroscience is that every brain is unique. My "face patch" is not in the exact same anatomical location as yours, and the specific neurons that code for a given face are different. This subject-to-subject variability has been a major barrier to finding common representational principles. If we naively average brain activity, we wash out the fine-grained patterns. How, then, can we compare our RDMs if our underlying neural "hardware" is different ?

An elegant and powerful solution, known as **[hyperalignment](@entry_id:1126288)**, uses the logic of RSA to solve this very problem. Instead of aligning brains based on their anatomy (which fails), we align them based on their *function*. The method finds a mathematical transformation for each individual's brain data that projects their unique, high-dimensional voxel space into a common, shared representational space. It does this by finding the rotations that best align the geometric clouds of responses to a shared stimulus, like a movie. In this common space, my pattern for "seeing a house" is now directly comparable to your pattern. Hyperalignment, in essence, creates a functional "Rosetta Stone" for brains , a testament to the idea that beneath our individual differences, there may lie universal geometric principles of thought.

#### From Brains to Batteries: A Universal Framework

To cap our journey, let us take one final, dramatic leap. The principles of RSA are not limited to brains, or even to things that think. Consider the challenge of designing new battery materials. Scientists use powerful Graph Neural Networks (GNNs) to predict material properties like [formation energy](@entry_id:142642) or ion [diffusion barriers](@entry_id:1123706). A key question in machine learning is "transfer learning": if we have a GNN trained to predict property A, can we re-purpose it to predict property B? Which layers of the network contain generalizable knowledge, and which need to be fine-tuned?

We can answer this with RSA. We can take a set of materials, get their true [diffusion barrier](@entry_id:148409) values, and compute a "label RDM" based on the pairwise differences. Then, we can look inside the GNN, extract the embeddings (representations) for each material at each layer, and compute a "representation RDM". By correlating the label RDM with the representation RDMs from a "frozen" (pre-trained) network and a "fine-tuned" network, we can precisely quantify which layers benefited from [fine-tuning](@entry_id:159910). We might find that early layers, which learn basic chemical structures, are already well-aligned and are best left frozen, while deeper layers, which encode more task-specific properties, show a large improvement in their [representational geometry](@entry_id:1130876) after fine-tuning .

This final example reveals the deepest truth of Representational Similarity Analysis. It is a tool not just for neuroscientists, but for any student of complex systems. It teaches us that the concept of "information" can be given a concrete, geometric form, and that by comparing these geometric forms, we can uncover profound similarities in the computational principles governing systems as different as a human brain, a crow's brain, a deep neural network, and a model that designs the materials of our future. It is a beautiful expression of the underlying unity of information processing across the natural and artificial worlds.