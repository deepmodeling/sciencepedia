{
    "hands_on_practices": [
        {
            "introduction": "At the heart of Representational Similarity Analysis is the Representational Dissimilarity Matrix (RDM), a tool for visualizing the geometry of neural codes. This first exercise provides a concrete, step-by-step guide to computing an RDM from a small set of multi-voxel patterns using the fundamental Euclidean distance. By completing this practice, you will see how the RDM's structure can immediately reveal how the brain organizes information, such as separating experimental conditions into distinct categories. ",
            "id": "4015383",
            "problem": "A core tool in Representational Similarity Analysis (RSA) is the representational dissimilarity matrix (RDM), which summarizes pairwise dissimilarities between condition-evoked multivoxel patterns. Consider the condition-by-voxel response matrix $X \\in \\mathbb{R}^{4 \\times 3}$ for $4$ experimental conditions measured over $3$ voxels:\n$$\nX \\;=\\;\n\\begin{pmatrix}\n5 & 1 & 0 \\\\\n4 & 2 & 0 \\\\\n0 & 4 & 5 \\\\\n1 & 5 & 4\n\\end{pmatrix}.\n$$\nAssume conditions $1$ and $2$ belong to category $\\mathcal{A}$ and conditions $3$ and $4$ belong to category $\\mathcal{B}$. Using the Euclidean distance across voxel responses, compute the $4 \\times 4$ RDM whose $(i,j)$ entry is the distance between the multivoxel patterns of conditions $i$ and $j$. Then, quantify category separability by first computing the within-category average dissimilarity as the mean of the distances for the pairs $\\{(1,2),(3,4)\\}$, and the between-category average dissimilarity as the mean of the distances for the pairs $\\{(1,3),(1,4),(2,3),(2,4)\\}$. Define the separability index\n$$\nS \\;=\\; \\frac{d_{\\mathrm{between}} - d_{\\mathrm{within}}}{d_{\\mathrm{within}}}.\n$$\nDiscuss how the structure of the RDM reflects category separability in this dataset, based on these distances. Report the single numerical value of $S$ as your final answer, rounded to $4$ significant figures. The answer is a dimensionless ratio.",
            "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n- The condition-by-voxel response matrix $X \\in \\mathbb{R}^{4 \\times 3}$ is given:\n$$\nX \\;=\\;\n\\begin{pmatrix}\n5 & 1 & 0 \\\\\n4 & 2 & 0 \\\\\n0 & 4 & 5 \\\\\n1 & 5 & 4\n\\end{pmatrix}\n$$\n- The problem involves $4$ conditions and $3$ voxels.\n- Category memberships are defined: conditions $1$ and $2$ belong to category $\\mathcal{A}$, and conditions $3$ and $4$ belong to category $\\mathcal{B}$.\n- The dissimilarity measure is the Euclidean distance.\n- The task is to compute the $4 \\times 4$ representational dissimilarity matrix (RDM).\n- The within-category average dissimilarity, $d_{\\mathrm{within}}$, is the mean of distances for the pairs $\\{(1,2),(3,4)\\}$.\n- The between-category average dissimilarity, $d_{\\mathrm{between}}$, is the mean of distances for the pairs $\\{(1,3),(1,4),(2,3),(2,4)\\}$.\n- The separability index is defined as $S = \\frac{d_{\\mathrm{between}} - d_{\\mathrm{within}}}{d_{\\mathrm{within}}}$.\n- The final answer required is the numerical value of $S$, rounded to $4$ significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, as Representational Similarity Analysis (RSA), RDMs, and category separability are standard concepts in computational neuroscience and brain modeling. The problem is well-posed, providing all necessary data (the matrix $X$), definitions (category assignments), and formulas (Euclidean distance, $d_{\\mathrm{within}}$, $d_{\\mathrm{between}}$, and $S$) to arrive at a unique solution. The language is objective and precise. The problem is self-contained, consistent, and does not violate any fundamental principles.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution\nThe multivoxel response patterns for the $4$ conditions are the row vectors of the matrix $X$. Let these vectors be denoted by $\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3, \\mathbf{x}_4 \\in \\mathbb{R}^3$:\n$$\n\\mathbf{x}_1 = (5, 1, 0)\n$$\n$$\n\\mathbf{x}_2 = (4, 2, 0)\n$$\n$$\n\\mathbf{x}_3 = (0, 4, 5)\n$$\n$$\n\\mathbf{x}_4 = (1, 5, 4)\n$$\nThe $(i,j)$ entry of the RDM is the Euclidean distance $d_{ij}$ between the response vectors $\\mathbf{x}_i$ and $\\mathbf{x}_j$. The formula for the Euclidean distance between two vectors $\\mathbf{a}=(a_1, a_2, a_3)$ and $\\mathbf{b}=(b_1, b_2, b_3)$ is $d(\\mathbf{a}, \\mathbf{b}) = \\sqrt{(a_1-b_1)^2 + (a_2-b_2)^2 + (a_3-b_3)^2}$.\n\nFirst, we compute the pairwise distances required for the analysis. These distances form the off-diagonal elements of the $4 \\times 4$ RDM. The RDM is symmetric ($d_{ij} = d_{ji}$) with zeros on the diagonal ($d_{ii}=0$).\n\nThe within-category distances are $d_{12}$ (for category $\\mathcal{A}$) and $d_{34}$ (for category $\\mathcal{B}$):\n$$\nd_{12} = \\sqrt{(5-4)^2 + (1-2)^2 + (0-0)^2} = \\sqrt{1^2 + (-1)^2 + 0^2} = \\sqrt{1+1} = \\sqrt{2}\n$$\n$$\nd_{34} = \\sqrt{(0-1)^2 + (4-5)^2 + (5-4)^2} = \\sqrt{(-1)^2 + (-1)^2 + 1^2} = \\sqrt{1+1+1} = \\sqrt{3}\n$$\n\nThe between-category distances are $d_{13}$, $d_{14}$, $d_{23}$, and $d_{24}$:\n$$\nd_{13} = \\sqrt{(5-0)^2 + (1-4)^2 + (0-5)^2} = \\sqrt{5^2 + (-3)^2 + (-5)^2} = \\sqrt{25+9+25} = \\sqrt{59}\n$$\n$$\nd_{14} = \\sqrt{(5-1)^2 + (1-5)^2 + (0-4)^2} = \\sqrt{4^2 + (-4)^2 + (-4)^2} = \\sqrt{16+16+16} = \\sqrt{48}\n$$\n$$\nd_{23} = \\sqrt{(4-0)^2 + (2-4)^2 + (0-5)^2} = \\sqrt{4^2 + (-2)^2 + (-5)^2} = \\sqrt{16+4+25} = \\sqrt{45}\n$$\n$$\nd_{24} = \\sqrt{(4-1)^2 + (2-5)^2 + (0-4)^2} = \\sqrt{3^2 + (-3)^2 + (-4)^2} = \\sqrt{9+9+16} = \\sqrt{34}\n$$\n\nThe full RDM is:\n$$\n\\mathrm{RDM} =\n\\begin{pmatrix}\n0 & \\sqrt{2} & \\sqrt{59} & \\sqrt{48} \\\\\n\\sqrt{2} & 0 & \\sqrt{45} & \\sqrt{34} \\\\\n\\sqrt{59} & \\sqrt{45} & 0 & \\sqrt{3} \\\\\n\\sqrt{48} & \\sqrt{34} & \\sqrt{3} & 0\n\\end{pmatrix}\n$$\n\nNext, we compute the within-category and between-category average dissimilarities.\nThe within-category average dissimilarity, $d_{\\mathrm{within}}$, is the mean of the dissimilarities for pairs within the same category, which are $(1,2)$ and $(3,4)$.\n$$\nd_{\\mathrm{within}} = \\frac{d_{12} + d_{34}}{2} = \\frac{\\sqrt{2} + \\sqrt{3}}{2}\n$$\nThe between-category average dissimilarity, $d_{\\mathrm{between}}$, is the mean of dissimilarities for pairs in different categories, which are $(1,3)$, $(1,4)$, $(2,3)$, and $(2,4)$.\n$$\nd_{\\mathrm{between}} = \\frac{d_{13} + d_{14} + d_{23} + d_{24}}{4} = \\frac{\\sqrt{59} + \\sqrt{48} + \\sqrt{45} + \\sqrt{34}}{4}\n$$\n\nThe structure of the RDM reflects category separability. If the conditions are ordered by category, the RDM takes on a block structure. The on-diagonal blocks contain within-category dissimilarities (e.g., the top-left $2 \\times 2$ block for category $\\mathcal{A}$ and the bottom-right $2 \\times 2$ block for category $\\mathcal{B}$). The off-diagonal blocks contain between-category dissimilarities. For this dataset, the within-category dissimilarities ($\\sqrt{2} \\approx 1.414$ and $\\sqrt{3} \\approx 1.732$) are considerably smaller than the between-category dissimilarities ($\\sqrt{59} \\approx 7.68$, $\\sqrt{48} \\approx 6.93$, $\\sqrt{45} \\approx 6.71$, $\\sqrt{34} \\approx 5.83$). This visual pattern in the RDM, with low values on the diagonal blocks and high values on the off-diagonal blocks, indicates that the neural representation patterns for items within the same category are more similar to each other than to patterns for items in a different category. This implies a strong categorical structure is present in the data.\n\nFinally, we compute the separability index $S$:\n$$\nS = \\frac{d_{\\mathrm{between}} - d_{\\mathrm{within}}}{d_{\\mathrm{within}}}\n$$\nWe substitute the expressions for $d_{\\mathrm{within}}$ and $d_{\\mathrm{between}}$:\n$$\nS = \\frac{\\frac{\\sqrt{59} + \\sqrt{48} + \\sqrt{45} + \\sqrt{34}}{4} - \\frac{\\sqrt{2} + \\sqrt{3}}{2}}{\\frac{\\sqrt{2} + \\sqrt{3}}{2}}\n$$\nTo obtain the final numerical answer, we evaluate these expressions:\n$$\nd_{\\mathrm{within}} \\approx \\frac{1.41421 + 1.73205}{2} = \\frac{3.14626}{2} \\approx 1.57313\n$$\n$$\nd_{\\mathrm{between}} \\approx \\frac{7.68115 + 6.92820 + 6.70820 + 5.83095}{4} = \\frac{27.14850}{4} \\approx 6.78713\n$$\nNow, we compute $S$:\n$$\nS \\approx \\frac{6.78713 - 1.57313}{1.57313} = \\frac{5.21400}{1.57313} \\approx 3.31441\n$$\nRounding to $4$ significant figures, we get $S \\approx 3.314$. The large positive value of $S$ quantitatively confirms the strong category separability observed qualitatively from the RDM structure.",
            "answer": "$$\\boxed{3.314}$$"
        },
        {
            "introduction": "While Euclidean distance is intuitive, it assumes that all data channels (e.g., voxels) are independent and equally noisy, which is rarely true for neural recordings. The Mahalanobis distance offers a more sophisticated approach by normalizing for the estimated noise covariance, effectively \"whitening\" the data to weight more reliable channels more heavily. This practice demystifies this important technique by guiding you through the computation of the whitening matrix and its application, building a crucial skill for conducting more robust and neuroscientifically plausible similarity analyses. ",
            "id": "4015346",
            "problem": "In Representational Similarity Analysis (RSA), a common approach to quantify dissimilarity between multivariate neural patterns is to use the Euclidean distance in a whitened space, which corresponds to the Mahalanobis distance under an empirically estimated noise covariance. Consider a toy dataset of voxel patterns across $2$ voxels for $3$ experimental conditions, with condition-specific response vectors given by $x_{1} = \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}$, $x_{2} = \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}$, and $x_{3} = \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}$. Suppose the empirical noise covariance across voxels estimated from baseline measurements is \n$$\n\\Sigma = \\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2 \\end{pmatrix}.\n$$\nStarting from the definitions of covariance and the spectral properties of symmetric positive-definite matrices, construct the inverse square root $\\,\\Sigma^{-1/2}\\,$ via orthogonal diagonalization, use it to whiten the patterns $y_{i} = \\Sigma^{-1/2} x_{i}$, compute the pairwise Euclidean distances $d_{12}$, $d_{13}$, and $d_{23}$ between the whitened patterns, and then compute the arithmetic mean of these three distances. Round your final numerical answer to four significant figures. Express the final quantity as a dimensionless number.",
            "solution": "Representational Similarity Analysis (RSA) compares condition-specific multivariate patterns via a dissimilarity measure. When an empirical noise covariance $\\,\\Sigma\\,$ is available, the Mahalanobis distance between two patterns $\\,x\\,$ and $\\,x'\\,$ is \n$$\nd_{M}(x,x') \\equiv \\left( (x - x')^{\\top} \\Sigma^{-1} (x - x') \\right)^{1/2},\n$$\nwhich is equal to the Euclidean distance between whitened patterns $\\,y = \\Sigma^{-1/2} x\\,$ and $\\,y' = \\Sigma^{-1/2} x'\\,$:\n$$\n\\|y - y'\\|_{2} = \\left\\| \\Sigma^{-1/2} (x - x') \\right\\|_{2} = d_{M}(x,x').\n$$\nThus, to compute whitened distances, we require $\\,\\Sigma^{-1/2}\\,$.\n\nFundamental base: The empirical covariance matrix $\\,\\Sigma\\,$ is symmetric positive-definite. By the spectral theorem, any symmetric positive-definite matrix admits an orthogonal diagonalization $\\,\\Sigma = U \\Lambda U^{\\top}\\,$, where $\\,U\\,$ is orthonormal and $\\,\\Lambda\\,$ is diagonal with positive entries. It follows that\n$$\n\\Sigma^{-1/2} = U \\Lambda^{-1/2} U^{\\top},\n$$\nwhere $\\,\\Lambda^{-1/2}\\,$ is the diagonal matrix formed by taking the inverse square roots of the eigenvalues.\n\nStep 1: Eigen-decomposition of $\\,\\Sigma\\,$. The matrix \n$$\n\\Sigma = \\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2 \\end{pmatrix}\n$$\nis of the form $\\,\\begin{pmatrix} a & b \\\\ b & a \\end{pmatrix}\\,$ with $\\,a = 2\\,$ and $\\,b = 0.5\\,$. Its eigenvectors are $\\,u_{1} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\,$ and $\\,u_{2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}\\,$, with corresponding eigenvalues \n$$\n\\lambda_{1} = a + b = 2.5, \\quad \\lambda_{2} = a - b = 1.5.\n$$\nThus,\n$$\nU = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}, \\quad \\Lambda = \\begin{pmatrix} 2.5 & 0 \\\\ 0 & 1.5 \\end{pmatrix}.\n$$\nDefine $\\,\\alpha = \\lambda_{1}^{-1/2} = \\frac{1}{\\sqrt{2.5}} = \\frac{\\sqrt{2}}{\\sqrt{5}}\\,$ and $\\,\\beta = \\lambda_{2}^{-1/2} = \\frac{1}{\\sqrt{1.5}} = \\frac{\\sqrt{2}}{\\sqrt{3}}\\,$. Then\n$$\n\\Lambda^{-1/2} = \\begin{pmatrix} \\alpha & 0 \\\\ 0 & \\beta \\end{pmatrix}.\n$$\nTherefore,\n$$\n\\Sigma^{-1/2} = U \\Lambda^{-1/2} U^{\\top} = \\frac{1}{2} \n\\begin{pmatrix}\n\\alpha + \\beta & \\alpha - \\beta \\\\\n\\alpha - \\beta & \\alpha + \\beta\n\\end{pmatrix}\n= \\frac{1}{\\sqrt{2}}\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{5}} + \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{5}} - \\frac{1}{\\sqrt{3}} \\\\\n\\frac{1}{\\sqrt{5}} - \\frac{1}{\\sqrt{3}} & \\frac{1}{\\sqrt{5}} + \\frac{1}{\\sqrt{3}}\n\\end{pmatrix}.\n$$\n\nStep 2: Whiten the patterns $\\,y_{i} = \\Sigma^{-1/2} x_{i}\\,$. Denote $\\,a' \\equiv \\frac{1}{\\sqrt{5}} + \\frac{1}{\\sqrt{3}}\\,$ and $\\,b' \\equiv \\frac{1}{\\sqrt{5}} - \\frac{1}{\\sqrt{3}}\\,$ so that\n$$\n\\Sigma^{-1/2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} a' & b' \\\\ b' & a' \\end{pmatrix}.\n$$\nCompute each $\\,y_{i}$:\n$$\ny_{1} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} a' & b' \\\\ b' & a' \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 1 \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3a' + b' \\\\ 3b' + a' \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{4}{\\sqrt{5}} + \\frac{2}{\\sqrt{3}} \\\\ \\frac{4}{\\sqrt{5}} - \\frac{2}{\\sqrt{3}} \\end{pmatrix},\n$$\n$$\ny_{2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} a' & b' \\\\ b' & a' \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2(a' + b') \\\\ 2(a' + b') \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{4}{\\sqrt{5}} \\\\ \\frac{4}{\\sqrt{5}} \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{\\sqrt{10}} \\\\ \\frac{4}{\\sqrt{10}} \\end{pmatrix},\n$$\n$$\ny_{3} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} a' & b' \\\\ b' & a' \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} -b' \\\\ -a' \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{1}{\\sqrt{3}} - \\frac{1}{\\sqrt{5}} \\\\ -\\left( \\frac{1}{\\sqrt{5}} + \\frac{1}{\\sqrt{3}} \\right) \\end{pmatrix}.\n$$\n\nStep 3: Compute pairwise Euclidean distances in whitened space. The Euclidean distance between $\\,y_{i}\\,$ and $\\,y_{j}\\,$ is $\\,d_{ij} = \\|y_{i} - y_{j}\\|_{2}\\,$.\n\nFirst,\n$$\ny_{1} - y_{2} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{4}{\\sqrt{5}} + \\frac{2}{\\sqrt{3}} \\\\ \\frac{4}{\\sqrt{5}} - \\frac{2}{\\sqrt{3}} \\end{pmatrix}\n- \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{4}{\\sqrt{5}} \\\\ \\frac{4}{\\sqrt{5}} \\end{pmatrix}\n= \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{2}{\\sqrt{3}} \\\\ -\\frac{2}{\\sqrt{3}} \\end{pmatrix}.\n$$\nThus,\n$$\nd_{12}^{2} = \\left\\| \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\frac{2}{\\sqrt{3}} \\\\ -\\frac{2}{\\sqrt{3}} \\end{pmatrix} \\right\\|_{2}^{2}\n= \\frac{1}{2} \\left( \\frac{4}{3} + \\frac{4}{3} \\right) = \\frac{4}{3}, \\quad d_{12} = \\frac{2}{\\sqrt{3}}.\n$$\n\nNext, we compute the difference vector $y_1 - y_3$:\n$$\ny_{1} - y_{3} = \\frac{1}{\\sqrt{2}} \\left( \\begin{pmatrix} 3a'+b' \\\\ 3b'+a' \\end{pmatrix} - \\begin{pmatrix} -b' \\\\ -a' \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3a'+2b' \\\\ 3b'+2a' \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\sqrt{5} + \\frac{1}{\\sqrt{3}} \\\\ \\sqrt{5} - \\frac{1}{\\sqrt{3}} \\end{pmatrix},\n$$\nso\n$$\nd_{13}^{2} = \\frac{1}{2} \\left[ \\left( \\sqrt{5} + \\frac{1}{\\sqrt{3}} \\right)^{2} + \\left( \\sqrt{5} - \\frac{1}{\\sqrt{3}} \\right)^{2} \\right]\n= \\frac{1}{2} \\cdot 2 \\left( 5 + \\frac{1}{3} \\right) = \\frac{16}{3},\n\\quad d_{13} = \\frac{4}{\\sqrt{3}}.\n$$\n\nSimilarly, for $y_2 - y_3$:\n$$\ny_{2} - y_{3} = \\frac{1}{\\sqrt{2}} \\left( \\begin{pmatrix} 2(a'+b') \\\\ 2(a'+b') \\end{pmatrix} - \\begin{pmatrix} -b' \\\\ -a' \\end{pmatrix} \\right) = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2a'+3b' \\\\ 3a'+2b' \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} \\sqrt{5} - \\frac{1}{\\sqrt{3}} \\\\ \\sqrt{5} + \\frac{1}{\\sqrt{3}} \\end{pmatrix},\n$$\nyielding\n$$\nd_{23}^{2} = \\frac{1}{2} \\left[ \\left( \\sqrt{5} - \\frac{1}{\\sqrt{3}} \\right)^{2} + \\left( \\sqrt{5} + \\frac{1}{\\sqrt{3}} \\right)^{2} \\right] = \\frac{16}{3},\n\\quad d_{23} = \\frac{4}{\\sqrt{3}}.\n$$\n\nStep 4: Compute the arithmetic mean of the three distances,\n$$\n\\bar{d} = \\frac{d_{12} + d_{13} + d_{23}}{3} = \\frac{ \\frac{2}{\\sqrt{3}} + \\frac{4}{\\sqrt{3}} + \\frac{4}{\\sqrt{3}} }{3} = \\frac{10}{3 \\sqrt{3}}.\n$$\nNumerically, $\\,\\sqrt{3} \\approx 1.7320508075688772\\,$, so\n$$\n\\bar{d} \\approx \\frac{10}{3 \\cdot 1.7320508075688772} \\approx \\frac{10}{5.196152422706632} \\approx 1.924500897 \\ldots\n$$\nRounded to four significant figures,\n$$\n\\bar{d} \\approx 1.925.\n$$\nThis final quantity is dimensionless.",
            "answer": "$$\\boxed{1.925}$$"
        },
        {
            "introduction": "After mastering the calculation of RDMs for a single brain region, the next step is to map representational geometries across the entire brain. Searchlight RSA accomplishes this by systematically moving a small spherical \"spotlight\" through the brain's volume, computing a local RDM at each position and comparing it to a theoretical model RDM that encapsulates a specific hypothesis. This comprehensive exercise transitions from single RDM computations to a full-scale, efficient analysis pipeline, teaching you how to implement a searchlight analysis to discover where specific representational structures are located. ",
            "id": "4190845",
            "problem": "You are given a scenario in which searchlight Representational Similarity Analysis (RSA) must be implemented efficiently on high-resolution datasets by exploiting precomputed pattern estimates and vectorized distance computations. The goal is to compute, for each test case, the maximum agreement between a local empirical Representational Dissimilarity Matrix (RDM) and a target model RDM, where agreement is quantified by the Spearman rank correlation between the vectorized upper-triangle entries of the two RDMs.\n\nFundamental base and definitions:\n- Representational Similarity Analysis (RSA) compares the geometric relationships between stimulus-evoked patterns across conditions. Let there be $C$ conditions and $V$ voxels. A precomputed pattern estimate is a matrix $X \\in \\mathbb{R}^{C \\times V}$ whose row $x_i \\in \\mathbb{R}^V$ is the pattern vector for condition $i$ across $V$ voxels.\n- A Representational Dissimilarity Matrix (RDM) $D \\in \\mathbb{R}^{C \\times C}$ captures pairwise dissimilarities between condition vectors. A widely used choice is the Euclidean distance, defined by $D_{ij} = \\lVert x_i - x_j \\rVert_2$. To compute $D$ efficiently, use the Gram matrix $G = X X^\\top \\in \\mathbb{R}^{C \\times C}$ and the identity\n$$\nD_{ij}^2 = G_{ii} + G_{jj} - 2 G_{ij},\n$$\nfollowed by $D_{ij} = \\sqrt{\\max(D_{ij}^2, 0)}$ to preserve non-negativity under floating-point arithmetic.\n- Searchlight RSA considers local neighborhoods of voxels around each center voxel. Let the grid be a three-dimensional lattice with shape $(N_x, N_y, N_z)$ and total voxels $V = N_x N_y N_z$. For a center voxel at coordinate $(u_x, u_y, u_z)$ and a radius $r \\in \\mathbb{N}$, the searchlight neighborhood $\\mathcal{N}(u)$ includes all voxels $(v_x, v_y, v_z)$ such that $(v_x - u_x)^2 + (v_y - u_y)^2 + (v_z - u_z)^2 \\le r^2$ and the coordinates are within grid bounds. For each center voxel $u$, we form the local pattern matrix $X^{(u)} \\in \\mathbb{R}^{C \\times K(u)}$ by restricting columns of $X$ to those voxels in $\\mathcal{N}(u)$, where $K(u) = |\\mathcal{N}(u)|$.\n- A model RDM $M \\in \\mathbb{R}^{C \\times C}$ encodes hypothesized structure among conditions. In this problem, $M$ is defined by category labels $g_1, \\dots, g_C \\in \\{0, 1, \\dots, G-1\\}$ via\n$$\nM_{ij} = \\begin{cases}\n0 & \\text{if } g_i = g_j,\\\\\n1 & \\text{if } g_i \\ne g_j.\n\\end{cases}\n$$\n- Agreement between empirical and model RDMs is quantified by the Spearman rank correlation, computed by mapping the upper-triangle elements (excluding the diagonal) of each RDM to a vector, ranking those elements, and then computing the Pearson correlation between the rank vectors. If either rank vector has zero variance, the correlation should be defined to be $0$.\n\nTask:\n- For each test case described below, synthesize a precomputed pattern estimate $X$ by drawing category prototype vectors and adding condition-specific noise. Specifically, let there be $G$ categories, and for each category $g$ draw a prototype vector $p_g \\in \\mathbb{R}^V$ from a standard normal distribution. For each condition $i$ with label $g_i$, set the pattern vector $x_i = p_{g_i} + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2 I_V)$ is independent Gaussian noise with standard deviation $\\sigma_n$. In the special case where the prototypes are specified to be identical, set $p_g = 0$ for all $g$ so that all conditions share the same underlying pattern.\n- For each center voxel $u$ in the grid, compute the local empirical RDM $D^{(u)}$ from $X^{(u)}$ using the vectorized Gram-matrix identity above. Extract the upper-triangle vector $d^{(u)}$. Let $m$ be the fixed upper-triangle vector of the model RDM $M$. Compute the Spearman correlation $\\rho^{(u)}$ between $d^{(u)}$ and $m$, using average ranks for ties. If either $d^{(u)}$ or $m$ is constant, set $\\rho^{(u)} = 0$. The result for the test case is $\\max_u \\rho^{(u)}$, the maximum correlation over all searchlight centers.\n\nTest suite and parameters:\n- The random number generator must be seeded as specified for reproducibility.\n- For all test cases, the searchlight radius $r$ is an integer and uses the Euclidean metric in the grid coordinate system.\n\nProvide four test cases:\n1. Happy path:\n    - Grid shape $(10, 10, 10)$, conditions $C = 6$, labels $(0, 0, 1, 1, 2, 2)$, radius $r = 1$, noise standard deviation $\\sigma_n = 0.1$, seed $7$.\n2. Boundary case (single-voxel neighborhood):\n    - Grid shape $(6, 6, 6)$, conditions $C = 4$, labels $(0, 1, 0, 1)$, radius $r = 0$, noise standard deviation $\\sigma_n = 0.05$, seed $13$.\n3. Edge case (identical patterns across conditions):\n    - Grid shape $(5, 5, 5)$, conditions $C = 5$, labels $(0, 1, 2, 0, 1)$, radius $r = 1$, noise standard deviation $\\sigma_n = 0.0$, seed $29$, with all prototypes identical (set $p_g = 0$ for all $g$).\n4. High-resolution case:\n    - Grid shape $(12, 12, 12)$, conditions $C = 5$, labels $(0, 0, 1, 1, 2)$, radius $r = 1$, noise standard deviation $\\sigma_n = 0.2$, seed $101$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for the four test cases as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"). Each result must be a float.\n\nScientific realism and constraints:\n- The construction of $X$ via category prototypes plus noise is a standard generative model consistent with commonly used precomputed pattern estimates (for example, General Linear Model parameter estimates) in neuroscience. The Euclidean distance and Spearman rank correlation are well-tested choices in RSA. The Gram-matrix identity provides the fundamental vectorized computation needed for efficiency on high-resolution data. \n- There are no physical units involved in this problem. Angles are not used. Percentages are not used.",
            "solution": "The problem is subjected to rigorous validation.\n\n### Step 1: Extract Givens\n- **Pattern Estimate Matrix**: $X \\in \\mathbb{R}^{C \\times V}$, where $C$ is the number of conditions and $V$ is the number of voxels. Row $x_i$ is the pattern for condition $i$.\n- **RDM Definition**: A Representational Dissimilarity Matrix $D \\in \\mathbb{R}^{C \\times C}$ with entries $D_{ij} = \\lVert x_i - x_j \\rVert_2$.\n- **RDM Computation**: Using the Gram matrix $G = X X^\\top$, the squared Euclidean distances are $D_{ij}^2 = G_{ii} + G_{jj} - 2 G_{ij}$. The final RDM is $D_{ij} = \\sqrt{\\max(D_{ij}^2, 0)}$.\n- **Searchlight Grid**: A 3D lattice of shape $(N_x, N_y, N_z)$, with total voxels $V = N_x N_y N_z$.\n- **Searchlight Neighborhood**: For a center voxel $u=(u_x, u_y, u_z)$ and radius $r \\in \\mathbb{N}$, the neighborhood $\\mathcal{N}(u)$ contains all voxels $v=(v_x, v_y, v_z)$ such that $(v_x - u_x)^2 + (v_y - u_y)^2 + (v_z - u_z)^2 \\le r^2$ and $v$ is within grid bounds.\n- **Local Pattern Matrix**: $X^{(u)} \\in \\mathbb{R}^{C \\times K(u)}$ is formed by restricting columns of $X$ to voxels in $\\mathcal{N}(u)$, where $K(u) = |\\mathcal{N}(u)|$.\n- **Model RDM**: $M \\in \\mathbb{R}^{C \\times C}$ is defined by category labels $g_1, \\dots, g_C \\in \\{0, 1, \\dots, G-1\\}$ as $M_{ij} = 0$ if $g_i = g_j$ and $M_{ij} = 1$ if $g_i \\ne g_j$.\n- **Agreement Metric**: Spearman rank correlation $\\rho$ between the vectorized upper-triangle elements (excluding the diagonal) of the empirical RDM $D^{(u)}$ and the model RDM $M$.\n- **Spearman Correlation Definition**: Computed by ranking the elements of the upper-triangle vectors and then computing the Pearson correlation between the rank vectors. Use average ranks for ties. If either rank vector has zero variance, $\\rho = 0$.\n- **Task**: For each test case, find $\\max_u \\rho^{(u)}$, the maximum correlation over all searchlight centers $u$.\n- **Data Generation**:\n    - For each of $G$ categories, draw a prototype $p_g \\in \\mathbb{R}^V$ from $\\mathcal{N}(0, I_V)$.\n    - For condition $i$ with label $g_i$, the pattern is $x_i = p_{g_i} + \\epsilon_i$, where $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2 I_V)$.\n    - For the \"identical prototypes\" case, set $p_g = 0$ for all $g$.\n- **Test Case 1**: Grid $(10, 10, 10)$, $C = 6$, labels $(0, 0, 1, 1, 2, 2)$, $r = 1$, $\\sigma_n = 0.1$, seed $7$.\n- **Test Case 2**: Grid $(6, 6, 6)$, $C = 4$, labels $(0, 1, 0, 1)$, $r = 0$, $\\sigma_n = 0.05$, seed $13$.\n- **Test Case 3**: Grid $(5, 5, 5)$, $C = 5$, labels $(0, 1, 2, 0, 1)$, $r = 1$, $\\sigma_n = 0.0$, seed $29$, identical prototypes.\n- **Test Case 4**: Grid $(12, 12, 12)$, $C = 5$, labels $(0, 0, 1, 1, 2)$, $r = 1$, $\\sigma_n = 0.2$, seed $101$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity.\n- **Scientifically Grounded**: The problem is an accurate and standard formulation of searchlight RSA, a widely used technique in computational neuroscience. The generative model for neural patterns ($X$), the choice of Euclidean distance for the empirical RDM ($D$), the binary structure for the model RDM ($M$), and the use of Spearman correlation as the agreement metric are all established practices. The Gram matrix identity is a standard and crucial optimization. The problem is scientifically sound.\n- **Well-Posed**: The problem is specified with mathematical precision. All parameters, data generation procedures, and computational steps are explicitly defined. The handling of potential division-by-zero in the correlation calculation (i.e., when a rank vector has zero variance) is clearly stipulated, ensuring a well-defined output for all inputs. Given a random number generator seed, the output is deterministic and unique.\n- **Objective**: The problem statement is purely objective and quantitative, free of any subjective or ambiguous language.\n\nThe problem does not exhibit any of the invalidity flags. It is scientifically sound, well-posed, objective, complete, and computationally feasible. The task is a non-trivial application of the specified principles.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be developed.\n\nThe solution proceeds by first implementing the data generation and then the searchlight analysis loop for each test case. The core of the algorithm is to efficiently compute the local empirical RDM for each searchlight neighborhood and compare it to the fixed model RDM.\n\n**1. Data Synthesis and Model RDM Construction**\n\nFor each test case, we begin by setting the random number generator seed for reproducibility. The total number of voxels is $V = N_x \\times N_y \\times N_z$.\n\nFirst, we construct the model RDM, $M \\in \\mathbb{R}^{C \\times C}$. Given the vector of condition labels $g = (g_1, \\dots, g_C)$, the entries of $M$ are given by $M_{ij} = 1$ if $g_i \\neq g_j$ and $M_{ij} = 0$ if $g_i = g_j$. We extract the elements of the upper triangle of $M$ (excluding the diagonal) into a vector $m$. This vector $m$ is fixed for a given test case.\n\nNext, we synthesize the full-brain pattern matrix $X \\in \\mathbb{R}^{C \\times V}$. The number of unique categories is $G = \\max(g) + 1$. We generate $G$ prototype vectors $\\{p_g\\}_{g=0}^{G-1}$, each drawn from a standard normal distribution, i.e., $p_g \\sim \\mathcal{N}(0, I_V)$. For the special case of identical prototypes, we set $p_g = 0$ for all $g$. For each of the $C$ conditions, the pattern vector $x_i$ is constructed as $x_i = p_{g_i} + \\epsilon_i$, where $g_i$ is the label for condition $i$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2 I_V)$ is a noise vector. These $C$ vectors form the rows of the matrix $X$.\n\n**2. Searchlight Neighborhood Definition**\n\nThe searchlight analysis iterates over every voxel in the grid, treating each as a center $u = (u_x, u_y, u_z)$. For each center, we must identify the indices of the voxels in its neighborhood $\\mathcal{N}(u)$. For a given radius $r$, we can pre-compute a set of relative coordinate offsets $\\{\\delta = (\\delta_x, \\delta_y, \\delta_z)\\}$ that satisfy $\\delta_x^2 + \\delta_y^2 + \\delta_z^2 \\le r^2$. Then, for any center $u$, the coordinates of a potential neighbor are $v = u + \\delta$. We retain only those neighbors whose coordinates are within the grid bounds $0 \\le v_x < N_x$, $0 \\le v_y < N_y$, and $0 \\le v_z < N_z$. These 3D coordinates are then converted to 1D linear indices to select columns from the data matrix $X$.\n\n**3. Local RDM Computation and Correlation**\n\nFor each center voxel $u$, the following steps are performed:\n- A local pattern matrix $X^{(u)} \\in \\mathbb{R}^{C \\times K(u)}$ is created by selecting the columns of $X$ corresponding to the voxel indices in $\\mathcal{N}(u)$.\n- The local Gram matrix is computed: $G^{(u)} = X^{(u)} (X^{(u)})^\\top$. This is a $C \\times C$ matrix.\n- The squared Euclidean distances are computed without loops using the identity $D_{ij}^{(u)2} = G_{ii}^{(u)} + G_{jj}^{(u)} - 2 G_{ij}^{(u)}$. Let $d_G$ be the diagonal of $G^{(u)}$. This can be vectorized as $D^{(u)2} = d_G \\cdot \\mathbf{1}^\\top + \\mathbf{1} \\cdot d_G^\\top - 2 G^{(u)}$, where $\\mathbf{1}$ is a column vector of ones.\n- The local empirical RDM is $D^{(u)} = \\sqrt{\\max(D^{(u)2}, 0)}$. The $\\max$ operation ensures robustness against minor negative values arising from floating-point inaccuracies.\n- The upper-triangle elements of $D^{(u)}$ are extracted into a vector $d^{(u)}$.\n- The Spearman rank correlation, $\\rho^{(u)}$, between $d^{(u)}$ and the model RDM vector $m$ is computed. This involves:\n    a. Ranking the elements of $d^{(u)}$ and $m$ to get rank vectors $r_d$ and $r_m$, using the average for ties.\n    b. Checking if the standard deviation of either $r_d$ or $r_m$ is zero. If so, $\\rho^{(u)} = 0$.\n    c. Otherwise, computing the Pearson correlation between $r_d$ and $r_m$.\n\n**4. Final Result**\n\nThe process is repeated for all possible center voxels $u$. The final result for the test case is the maximum correlation found across all searchlights, $\\max_{u} \\rho^{(u)}$. This entire procedure is encapsulated and executed for each of the four test cases provided.\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import rankdata\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for searchlight RSA.\n    \"\"\"\n    test_cases = [\n        # 1. Happy path\n        {\"grid_shape\": (10, 10, 10), \"C\": 6, \"labels\": (0, 0, 1, 1, 2, 2), \"r\": 1, \"sigma_n\": 0.1, \"seed\": 7, \"identical_prototypes\": False},\n        # 2. Boundary case (single-voxel neighborhood)\n        {\"grid_shape\": (6, 6, 6), \"C\": 4, \"labels\": (0, 1, 0, 1), \"r\": 0, \"sigma_n\": 0.05, \"seed\": 13, \"identical_prototypes\": False},\n        # 3. Edge case (identical patterns)\n        {\"grid_shape\": (5, 5, 5), \"C\": 5, \"labels\": (0, 1, 2, 0, 1), \"r\": 1, \"sigma_n\": 0.0, \"seed\": 29, \"identical_prototypes\": True},\n        # 4. High-resolution case\n        {\"grid_shape\": (12, 12, 12), \"C\": 5, \"labels\": (0, 0, 1, 1, 2), \"r\": 1, \"sigma_n\": 0.2, \"seed\": 101, \"identical_prototypes\": False},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_searchlight_rsa(**case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef spearman_correlation(x, y):\n    \"\"\"\n    Computes Spearman rank correlation, handling zero variance as specified.\n    \"\"\"\n    rx = rankdata(x, method='average')\n    ry = rankdata(y, method='average')\n\n    if np.std(rx) == 0 or np.std(ry) == 0:\n        return 0.0\n    \n    # Pearson correlation on ranks\n    corr_matrix = np.corrcoef(rx, ry)\n    return corr_matrix[0, 1]\n\ndef run_searchlight_rsa(grid_shape, C, labels, r, sigma_n, seed, identical_prototypes):\n    \"\"\"\n    Executes one full searchlight RSA test case.\n    \"\"\"\n    # Initialize random number generator\n    rng = np.random.default_rng(seed)\n\n    # --- 1. Data Synthesis and Model RDM ---\n    Nx, Ny, Nz = grid_shape\n    V = Nx * Ny * Nz\n    labels = np.array(labels)\n    num_categories = np.max(labels) + 1\n\n    # Generate Model RDM\n    model_rdm = np.array([[0 if labels[i] == labels[j] else 1 \n                           for j in range(C)] for i in range(C)], dtype=np.float64)\n    triu_indices = np.triu_indices(C, k=1)\n    model_rdm_vec = model_rdm[triu_indices]\n\n    # Generate Pattern Matrix X\n    if identical_prototypes:\n        prototypes = np.zeros((num_categories, V))\n    else:\n        prototypes = rng.normal(loc=0.0, scale=1.0, size=(num_categories, V))\n    \n    noise = rng.normal(loc=0.0, scale=sigma_n, size=(C, V))\n    \n    X = np.zeros((C, V))\n    for i in range(C):\n        X[i, :] = prototypes[labels[i], :] + noise[i, :]\n\n    # --- 2. Searchlight Neighborhood Definition ---\n    # Pre-compute relative offsets for the sphere\n    r_squared = r * r\n    offsets = []\n    for dz in range(-r, r + 1):\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dx**2 + dy**2 + dz**2 <= r_squared:\n                    offsets.append((dx, dy, dz))\n    \n    all_voxel_coords = np.array(list(np.ndindex(grid_shape)))\n    \n    max_corr = -np.inf\n\n    # --- 3. Searchlight Iteration ---\n    for center_idx in range(V):\n        center_coord = all_voxel_coords[center_idx]\n        \n        # Determine neighborhood voxel indices\n        neighbor_indices = []\n        for offset in offsets:\n            neighbor_coord = center_coord + offset\n            if (0 <= neighbor_coord[0] < Nx and\n                0 <= neighbor_coord[1] < Ny and\n                0 <= neighbor_coord[2] < Nz):\n                \n                # Convert 3D coord to 1D index\n                idx = np.ravel_multi_index(neighbor_coord, grid_shape)\n                neighbor_indices.append(idx)\n        \n        if not neighbor_indices:\n            continue\n\n        X_local = X[:, neighbor_indices]\n        \n        # --- 4. Local RDM Computation ---\n        # Gram matrix G = X * X_transpose\n        G = X_local @ X_local.T\n        \n        # Squared Euclidean distances D_ij^2 = G_ii + G_jj - 2*G_ij\n        G_diag = np.diag(G).reshape(-1, 1)\n        D_sq = G_diag + G_diag.T - 2 * G\n        \n        # RDM: D_ij = sqrt(max(0, D_ij^2))\n        D = np.sqrt(np.maximum(0, D_sq))\n        \n        # Vectorize upper triangle\n        d_vec = D[triu_indices]\n\n        # --- 5. Compute Correlation ---\n        corr = spearman_correlation(d_vec, model_rdm_vec)\n        if corr > max_corr:\n            max_corr = corr\n\n    return max_corr if max_corr > -np.inf else 0.0\n\nsolve()\n```",
            "answer": "[0.9631578947368421,0.8,0.0,0.9]"
        }
    ]
}