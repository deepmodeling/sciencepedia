{
    "hands_on_practices": [
        {
            "introduction": "The Free-energy Principle recasts perception as a process of Bayesian inference. To make this computationally feasible, the brain must use approximations. This first exercise  delves into the core mechanics of one such method, coordinate ascent variational inference (CAVI), using a mean-field approximation. By manually calculating the updates for a simple generative model, you will gain a concrete understanding of how beliefs about hidden states are iteratively refined to better explain sensory evidence.",
            "id": "4028571",
            "problem": "Consider a binary latent-state generative model grounded in the free-energy principle for perception, with factorization $p(s_1,s_2,o)=p(s_1)\\,p(s_2)\\,p(o\\mid s_1,s_2)$, where $s_1\\in\\{0,1\\}$ and $s_2\\in\\{0,1\\}$ denote latent states and $o\\in\\{0,1\\}$ denotes an observed sensory outcome. Assume an observation $o=1$ has been recorded. The priors are $p(s_1=1)=0.3$ and $p(s_2=1)=0.6$ (hence $p(s_1=0)=0.7$ and $p(s_2=0)=0.4$). The likelihood table is specified by\n$$\np(o=1\\mid s_1,s_2)=\n\\begin{cases}\n0.2 & \\text{if } (s_1,s_2)=(0,0),\\\\\n0.5 & \\text{if } (s_1,s_2)=(0,1),\\\\\n0.6 & \\text{if } (s_1,s_2)=(1,0),\\\\\n0.9 & \\text{if } (s_1,s_2)=(1,1).\n\\end{cases}\n$$\nAdopt a mean-field variational approximation $q(s_1,s_2)=q_1(s_1)\\,q_2(s_2)$, and perform one full coordinate-ascent iteration as follows: initialize $q_2(s_2=1)=\\frac{1}{2}$ (so $q_2(s_2=0)=\\frac{1}{2}$), update $q_1(s_1)$ holding $q_2(s_2)$ fixed, and then update $q_2(s_2)$ using the newly updated $q_1(s_1)$.\n\nUsing only foundational variational principles (variational free energy minimization and mean-field factorization) to derive the update rules and then applying the given numerical specifications, compute the updated posterior means $q_1(s_1=1)$ and $q_2(s_2=1)$ after this single iteration. Round your numerical answers to four significant figures. Express your final results as a row matrix using the LaTeX $\\texttt{pmatrix}$ environment, with the first entry $q_1(s_1=1)$ and the second entry $q_2(s_2=1)$.",
            "solution": "The objective is to iteratively update the parameters of the mean-field recognition density $q(s_1, s_2) = q_1(s_1)q_2(s_2)$ to minimize variational free energy. In coordinate ascent variational inference (CAVI), we optimize each factor $q_j(s_j)$ while holding the others fixed. The general update rule for a factor is:\n$$ \\ln q_j^*(s_j) = \\mathbb{E}_{q_{\\neg j}}[\\ln p(\\mathbf{s}, o)] + \\text{constant} $$\nwhere the expectation is over all latent variables except $s_j$. For our model, the joint probability is $\\ln p(s_1,s_2,o) = \\ln p(s_1) + \\ln p(s_2) + \\ln p(o|s_1,s_2)$.\n\n**Step 1: Derive and Perform Update for $q_1(s_1)$**\n\nThe update for $q_1(s_1)$ is derived as:\n$$ \\ln q_1^*(s_1) \\propto \\ln p(s_1) + \\mathbb{E}_{q_2(s_2)}[\\ln p(o=1|s_1,s_2)] $$\n$$ \\ln q_1^*(s_1) \\propto \\ln p(s_1) + \\sum_{s_2 \\in \\{0,1\\}} q_2(s_2)\\ln p(o=1|s_1,s_2) $$\nWe are given the initialization $q_2(s_2=1) = 0.5$ and $q_2(s_2=0)=0.5$. Let's compute the unnormalized log probabilities (logits) for $s_1=1$ and $s_1=0$.\n-   For $s_1=1$: $\\lambda_1(1) = \\ln(0.3) + (0.5 \\times \\ln(0.6) + 0.5 \\times \\ln(0.9)) \\approx -1.2040 + 0.5(-0.5108 - 0.1054) = -1.5121$.\n-   For $s_1=0$: $\\lambda_1(0) = \\ln(0.7) + (0.5 \\times \\ln(0.2) + 0.5 \\times \\ln(0.5)) \\approx -0.3567 + 0.5(-1.6094 - 0.6931) = -1.50795$.\n\nThe updated probability $q_1^*(s_1=1)$ is given by the logistic sigmoid function of the log-odds, $\\lambda_1(1) - \\lambda_1(0)$:\n$$ q_1^*(s_1=1) = \\frac{1}{1 + \\exp(-(\\lambda_1(1)-\\lambda_1(0)))} = \\frac{1}{1 + \\exp(-(-1.5121 - (-1.50795)))} = \\frac{1}{1 + \\exp(0.00415)} \\approx 0.49896 $$\nRounding to four significant figures, the updated mean is $q_1(s_1=1) = 0.4990$. Thus, $q_1(s_1=0)=0.5010$.\n\n**Step 2: Derive and Perform Update for $q_2(s_2)$**\n\nThe update for $q_2(s_2)$ is symmetric:\n$$ \\ln q_2^*(s_2) \\propto \\ln p(s_2) + \\mathbb{E}_{q_1^*(s_1)}[\\ln p(o=1|s_1,s_2)] $$\nWe use the newly updated $q_1^*(s_1)$: $q_1^*(s_1=1) \\approx 0.4990$ and $q_1^*(s_1=0) \\approx 0.5010$.\n-   For $s_2=1$: $\\lambda_2(1) = \\ln(0.6) + (0.5010 \\times \\ln(0.5) + 0.4990 \\times \\ln(0.9)) \\approx -0.5108 + 0.5010(-0.6931) + 0.4990(-0.1054) = -0.9106$.\n-   For $s_2=0$: $\\lambda_2(0) = \\ln(0.4) + (0.5010 \\times \\ln(0.2) + 0.4990 \\times \\ln(0.6)) \\approx -0.9163 + 0.5010(-1.6094) + 0.4990(-0.5108) = -1.9775$.\n\nThe updated probability $q_2^*(s_2=1)$ is:\n$$ q_2^*(s_2=1) = \\frac{1}{1 + \\exp(-(\\lambda_2(1)-\\lambda_2(0)))} = \\frac{1}{1 + \\exp(-(-0.9106 - (-1.9775)))} = \\frac{1}{1 + \\exp(-1.0669)} \\approx 0.7440 $$\nRounding to four significant figures, the updated mean is $q_2(s_2=1) = 0.7440$.\n\n**Final Result**\nAfter one full iteration, the updated posterior means are $q_1(s_1=1) \\approx 0.4990$ and $q_2(s_2=1) \\approx 0.7440$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4990 & 0.7440\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Building upon the foundational inference mechanism, we now turn to a dynamic and neurally plausible implementation of the Free-energy Principle: predictive coding. This framework models the brain as a hierarchical prediction machine that continuously works to minimize sensory prediction errors. This coding exercise  asks you to implement a single update step of this process, providing direct insight into how top-down predictions and bottom-up error signals interact to update an agent's internal model of the world.",
            "id": "4028586",
            "problem": "Consider a linear-Gaussian generative model suitable for predictive coding under the Free-Energy Principle. Let the latent state vector be $\\mathbf{s} \\in \\mathbb{R}^m$ with a zero-mean Gaussian prior $\\mathbf{s} \\sim \\mathcal{N}(\\mathbf{0}, I)$, where $I$ is the $m \\times m$ identity matrix. Let the observation vector be $\\mathbf{y} \\in \\mathbb{R}^n$, generated according to $\\mathbf{y} \\mid \\mathbf{s} \\sim \\mathcal{N}(W \\mathbf{s}, \\Sigma)$, where $W \\in \\mathbb{R}^{n \\times m}$ is a known generative mapping and $\\Sigma \\in \\mathbb{R}^{n \\times n}$ is a known positive-definite observation noise covariance. Consider a Gaussian variational posterior $q(\\mathbf{s}) = \\mathcal{N}(\\mu_q, \\Sigma_q)$ with mean $\\mu_q \\in \\mathbb{R}^m$ and positive-definite covariance $\\Sigma_q \\in \\mathbb{R}^{m \\times m}$.\n\nFrom first principles, relying only on Bayes' rule for linear-Gaussian models, the definition of the negative variational free energy as a lower bound on the log model evidence, and the Laplace approximation (Gaussian approximation around the mode), derive the continuous-time predictive coding dynamics for the mean parameter $\\mu_q$ under a natural gradient preconditioning by $\\Sigma_q$ and identity prior covariance $I$. Use these dynamics to define a single discrete update that corresponds to one explicit Euler step of size $\\eta = 1$, and compute the change in the mean parameter, denoted $\\Delta \\mu_q$, for one iteration as applied to the model above. Your program must implement the computation of $\\Delta \\mu_q$ given $(W, \\Sigma, \\mu_q, \\Sigma_q, \\mathbf{y})$, and it must not rely on any formula not derivable from the fundamental laws and definitions described.\n\nImplement the computation for the following test suite. Each case provides $(W, \\Sigma, \\mu_q, \\Sigma_q, \\mathbf{y})$ with dimensions $n = 2$ and $m = 2$:\n\n- Case $1$ (general well-conditioned case):\n  - $W = \\begin{bmatrix} 1.0 & 0.2 \\\\ 0.0 & 1.0 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.5 & 0.0 \\\\ 0.0 & 0.5 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.8 & 0.0 \\\\ 0.0 & 0.6 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.5 \\\\ -0.5 \\end{bmatrix}$.\n\n- Case $2$ (high observation noise):\n  - $W = \\begin{bmatrix} 1.0 & -0.5 \\\\ 0.3 & 1.2 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 5.0 & 0.0 \\\\ 0.0 & 5.0 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} -0.3 \\\\ 0.4 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 1.1 & 0.0 \\\\ 0.0 & 0.9 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 0.2 \\\\ -1.0 \\end{bmatrix}$.\n\n- Case $3$ (correlated posterior covariance):\n  - $W = \\begin{bmatrix} 0.7 & 0.4 \\\\ -0.2 & 1.3 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.6 & 0.0 \\\\ 0.0 & 0.4 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 0.5 \\\\ 0.1 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.7 & 0.3 \\\\ 0.3 & 0.9 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$.\n\n- Case $4$ (rank-deficient generative mapping):\n  - $W = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 0.0 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.1 & 0.0 \\\\ 0.0 & 0.1 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} 2.0 \\\\ -1.0 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 1.0 \\\\ 0.0 \\end{bmatrix}$.\n\n- Case $5$ (strong sensory precision):\n  - $W = \\begin{bmatrix} 0.9 & -0.1 \\\\ 0.2 & 0.8 \\end{bmatrix}$,\n  - $\\Sigma = \\begin{bmatrix} 0.01 & 0.0 \\\\ 0.0 & 0.02 \\end{bmatrix}$,\n  - $\\mu_q = \\begin{bmatrix} -0.1 \\\\ 0.2 \\end{bmatrix}$,\n  - $\\Sigma_q = \\begin{bmatrix} 0.5 & 0.0 \\\\ 0.0 & 0.5 \\end{bmatrix}$,\n  - $\\mathbf{y} = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is the two-dimensional change vector $\\Delta \\mu_q$ for a test case, rounded to six decimal places, represented as a Python-style list. For example, the format should be $[\\,[\\delta\\mu_{1,1}, \\delta\\mu_{1,2}], [\\delta\\mu_{2,1}, \\delta\\mu_{2,2}], \\dots\\,]$. There are no physical units involved. Angles are not used. All numerical outputs must be real-valued floats. The algorithm must be implemented from the foundational definitions given, without invoking any pre-specified shortcut formulas.",
            "solution": "We begin with a linear-Gaussian generative model and a Gaussian variational posterior. The latent state is $\\mathbf{s} \\in \\mathbb{R}^m$ with prior $p(\\mathbf{s}) = \\mathcal{N}(\\mathbf{0}, I)$, where $I$ is the $m \\times m$ identity. The likelihood is $p(\\mathbf{y} \\mid \\mathbf{s}) = \\mathcal{N}(W \\mathbf{s}, \\Sigma)$, with $W \\in \\mathbb{R}^{n \\times m}$ and $\\Sigma \\in \\mathbb{R}^{n \\times n}$ a positive-definite covariance. The variational posterior is $q(\\mathbf{s}) = \\mathcal{N}(\\mu_q, \\Sigma_q)$, with $\\mu_q \\in \\mathbb{R}^m$ and $\\Sigma_q \\in \\mathbb{R}^{m \\times m}$ positive-definite.\n\nThe Free-Energy Principle employs variational free energy to bound the log-evidence. The negative variational free energy (the evidence lower bound) is given by\n$$\n\\mathcal{L}(\\mu_q, \\Sigma_q) = \\mathbb{E}_{q(\\mathbf{s})}[\\log p(\\mathbf{y}, \\mathbf{s})] - \\mathbb{E}_{q(\\mathbf{s})}[\\log q(\\mathbf{s})].\n$$\nUnder the Laplace approximation and natural gradient dynamics, predictive coding emerges by performing gradient ascent on $\\mathcal{L}$ with respect to the variational parameters, often preconditioned by the Fisher information metric for Gaussian families, which here is represented by $\\Sigma_q$ for the mean parameter. To derive the update, we work from fundamental probabilistic definitions.\n\nFirst, write the joint density:\n$$\n\\log p(\\mathbf{y}, \\mathbf{s}) = \\log p(\\mathbf{y}\\mid \\mathbf{s}) + \\log p(\\mathbf{s}).\n$$\nFor Gaussian terms,\n$$\n\\log p(\\mathbf{y}\\mid \\mathbf{s}) = -\\tfrac{1}{2}(\\mathbf{y} - W \\mathbf{s})^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mathbf{s}) + \\text{const},\n$$\n$$\n\\log p(\\mathbf{s}) = -\\tfrac{1}{2}\\mathbf{s}^\\top I \\mathbf{s} + \\text{const} = -\\tfrac{1}{2}\\mathbf{s}^\\top \\mathbf{s} + \\text{const}.\n$$\nThe variational posterior is\n$$\n\\log q(\\mathbf{s}) = -\\tfrac{1}{2}(\\mathbf{s} - \\mu_q)^\\top \\Sigma_q^{-1}(\\mathbf{s} - \\mu_q) + \\text{const}.\n$$\nWe focus on the mean update. Under the Laplace approximation for the mean, consider the negative free energy (which is equivalent, up to constants, to the expected negative log posterior) as a function of $\\mu_q$, approximating the expectation by evaluating at the mean (this is standard in Laplace variational schemes). Define the energy function\n$$\nF(\\mu_q) = \\tfrac{1}{2}(\\mathbf{y} - W \\mu_q)^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) + \\tfrac{1}{2}\\mu_q^\\top I \\mu_q,\n$$\nwhich is the negative log posterior evaluated at $\\mu_q$ (the first term corresponds to the likelihood and the second to the prior, with $I$ as the prior precision). Minimizing $F(\\mu_q)$ corresponds to maximizing the posterior probability and, equivalently, maximizing the evidence lower bound with respect to $\\mu_q$ under the Laplace approximation.\n\nCompute the gradient of $F(\\mu_q)$ with respect to $\\mu_q$. Using standard matrix calculus,\n$$\n\\nabla_{\\mu_q} F(\\mu_q) = - W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) + I \\mu_q.\n$$\nPredictive coding can be expressed as gradient descent on $F(\\mu_q)$ or gradient ascent on $\\mathcal{L}$ with a natural gradient preconditioning by $\\Sigma_q$. The natural gradient step for the mean parameter in an exponential family Gaussian can be approximated by premultiplying the ordinary Euclidean gradient by $\\Sigma_q$, yielding a direction that accounts for the local curvature implied by the posterior covariance. Thus, the continuous-time dynamics for $\\mu_q$ under natural gradient ascent on $\\mathcal{L}$ (equivalently, natural gradient descent on $F$) becomes\n$$\n\\frac{d\\mu_q}{dt} = \\Sigma_q\\left[ W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) - I \\mu_q \\right].\n$$\nTaking a single explicit Euler step with step size $\\eta = 1$ yields the discrete change\n$$\n\\Delta \\mu_q = \\Sigma_q\\left[ W^\\top \\Sigma^{-1}(\\mathbf{y} - W \\mu_q) - I \\mu_q \\right].\n$$\nThis $\\Delta \\mu_q$ is the requested change in the posterior mean for one predictive coding iteration under the stipulated assumptions: linear-Gaussian model, identity prior covariance, Laplace approximation, and natural gradient preconditioning by $\\Sigma_q$.\n\nAlgorithmic design:\n- Input: matrices $W$, $\\Sigma$, $\\Sigma_q$ and vectors $\\mu_q$, $\\mathbf{y}$.\n- Validate dimensions: $W$ is $n \\times m$, $\\Sigma$ is $n \\times n$, $\\Sigma_q$ is $m \\times m$, $\\mu_q \\in \\mathbb{R}^m$, $\\mathbf{y} \\in \\mathbb{R}^n$.\n- Compute the sensory prediction error $\\mathbf{e}_y = \\mathbf{y} - W \\mu_q$.\n- Compute the precision-weighted error $\\mathbf{r}_y = \\Sigma^{-1} \\mathbf{e}_y$.\n- Compute the back-propagated precision-weighted error at latent level $\\mathbf{g} = W^\\top \\mathbf{r}_y$.\n- Compute the prior contribution $\\mathbf{p} = I \\mu_q = \\mu_q$.\n- Combine to form the Euclidean gradient direction $\\mathbf{d} = \\mathbf{g} - \\mathbf{p}$.\n- Precondition by $\\Sigma_q$ to obtain the natural gradient step $\\Delta \\mu_q = \\Sigma_q \\mathbf{d}$.\n- Output $\\Delta \\mu_q$ with numerical rounding as specified.\n\nEdge cases are included in the test suite:\n- Case $1$ verifies a general, well-conditioned scenario.\n- Case $2$ uses large observation noise $\\Sigma$, suppressing the sensory term relative to the prior term.\n- Case $3$ uses correlated $\\Sigma_q$, exercising natural gradient preconditioning across dimensions.\n- Case $4$ uses a rank-deficient $W$, restricting sensory information to a subspace.\n- Case $5$ uses very small observation noise (high precision), emphasizing the sensory term and leading to a large correction.\n\nThe final program implements the above steps for each test case and prints the results in the required single-line format, as a comma-separated list of lists with each component rounded to six decimal places.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef predictive_coding_delta_mu(W, Sigma, mu_q, Sigma_q, y):\n    \"\"\"\n    Compute one predictive coding iteration change in posterior mean (Delta mu_q)\n    under a linear-Gaussian generative model with identity prior covariance,\n    Laplace approximation, and natural gradient preconditioning by Sigma_q.\n\n    Delta mu_q = Sigma_q * [ W^T * Sigma^{-1} * (y - W * mu_q) - mu_q ]\n    \"\"\"\n    # Sensory prediction error\n    e_y = y - W @ mu_q\n    # Precision-weighted error\n    r_y = np.linalg.solve(Sigma, e_y)\n    # Backpropagated precision-weighted error to latent space\n    g = W.T @ r_y\n    # Prior term (identity prior precision)\n    p = mu_q\n    # Euclidean gradient direction\n    d = g - p\n    # Natural gradient step preconditioned by Sigma_q\n    delta_mu = Sigma_q @ d\n    return delta_mu\n\ndef format_vector(vec):\n    # Round to six decimals and format as Python-style list\n    return \"[\" + \",\".join(f\"{x:.6f}\" for x in vec.tolist()) + \"]\"\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([[1.0, 0.2],\n                      [0.0, 1.0]]),\n            np.array([[0.5, 0.0],\n                      [0.0, 0.5]]),\n            np.array([0.1, -0.2]),\n            np.array([[0.8, 0.0],\n                      [0.0, 0.6]]),\n            np.array([1.5, -0.5])\n        ),\n        # Case 2\n        (\n            np.array([[1.0, -0.5],\n                      [0.3,  1.2]]),\n            np.array([[5.0, 0.0],\n                      [0.0, 5.0]]),\n            np.array([-0.3, 0.4]),\n            np.array([[1.1, 0.0],\n                      [0.0, 0.9]]),\n            np.array([0.2, -1.0])\n        ),\n        # Case 3\n        (\n            np.array([[ 0.7, 0.4],\n                      [-0.2, 1.3]]),\n            np.array([[0.6, 0.0],\n                      [0.0, 0.4]]),\n            np.array([0.5, 0.1]),\n            np.array([[0.7, 0.3],\n                      [0.3, 0.9]]),\n            np.array([1.0, 0.0])\n        ),\n        # Case 4\n        (\n            np.array([[1.0, 0.0],\n                      [0.0, 0.0]]),\n            np.array([[0.1, 0.0],\n                      [0.0, 0.1]]),\n            np.array([2.0, -1.0]),\n            np.array([[1.0, 0.0],\n                      [0.0, 1.0]]),\n            np.array([1.0, 0.0])\n        ),\n        # Case 5\n        (\n            np.array([[0.9, -0.1],\n                      [0.2,  0.8]]),\n            np.array([[0.01, 0.0],\n                      [0.0,  0.02]]),\n            np.array([-0.1, 0.2]),\n            np.array([[0.5, 0.0],\n                      [0.0, 0.5]]),\n            np.array([0.0, 1.0])\n        ),\n    ]\n\n    results = []\n    for W, Sigma, mu_q, Sigma_q, y in test_cases:\n        delta_mu = predictive_coding_delta_mu(W, Sigma, mu_q, Sigma_q, y)\n        results.append(format_vector(delta_mu))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "The Free-energy Principle is not just a theory of perception; it is a unified theory of perception and action. In this final practice , we explore active inference, where agents select actions to minimize their expected future free energy. You will calculate this quantity for different policies, seeing firsthand how it decomposes into two crucial components: the drive to fulfill preferences (extrinsic value) and the drive to reduce uncertainty about the world (epistemic value).",
            "id": "4028595",
            "problem": "Consider a single-step decision problem formulated under the Free-Energy Principle (FEP) in brain modeling and computational neuroscience. Hidden states are binary, $s \\in \\{s_{0}, s_{1}\\}$, with a current belief (recognition density) $Q(s)$ given by $Q(s_{0}) = 0.6$ and $Q(s_{1}) = 0.4$. Observations are binary, $o \\in \\{0,1\\}$, and there are two candidate one-step policies $\\pi_{1}$ and $\\pi_{2}$ corresponding to two actions $a_{1}$ and $a_{2}$ that modulate the likelihood mapping $P(o \\mid s, a)$ as follows:\n- Under action $a_{1}$: $P(o=1 \\mid s_{0}, a_{1}) = 0.8$, $P(o=0 \\mid s_{0}, a_{1}) = 0.2$, $P(o=1 \\mid s_{1}, a_{1}) = 0.3$, $P(o=0 \\mid s_{1}, a_{1}) = 0.7$.\n- Under action $a_{2}$: $P(o=1 \\mid s_{0}, a_{2}) = 0.6$, $P(o=0 \\mid s_{0}, a_{2}) = 0.4$, $P(o=1 \\mid s_{1}, a_{2}) = 0.1$, $P(o=0 \\mid s_{1}, a_{2}) = 0.9$.\n\nPreferred outcomes are encoded by a prior preference distribution $P^{\\ast}(o)$ with $P^{\\ast}(1) = 0.9$ and $P^{\\ast}(0) = 0.1$. Assume a single time step, and that the prior over hidden states used in scoring expected free energy matches the current belief, i.e., $P(s) = Q(s)$. Use the natural logarithm $\\ln$.\n\nStarting from the definition of variational free energy for a single observation in terms of a recognition distribution $Q(s \\mid o, \\pi)$ and a generative model with outcome preferences $P^{\\ast}(o)$, and using only core definitions from variational Bayesian inference (e.g., Kullbackâ€“Leibler divergence (KLD), mutual information, and law of total expectation), derive an expression for the one-step expected free energy $\\mathcal{G}(\\pi)$ of a policy $\\pi$ that separates into (i) an extrinsic term that depends on $P^{\\ast}(o)$ and the predictive distribution $Q(o \\mid \\pi)$ and (ii) an epistemic term that is the mutual information between hidden states and outcomes under $\\pi$. Then compute $\\mathcal{G}(\\pi_{1})$ and $\\mathcal{G}(\\pi_{2})$ numerically, and determine which policy minimizes $\\mathcal{G}(\\pi)$.\n\nAs your final answer, report the index $i \\in \\{1,2\\}$ of the minimizing policy $\\pi_{i}$. No rounding instruction is needed for the final index. If intermediate numerical computations are required, use exact arithmetic and $\\ln$ evaluations; any approximations should be clearly indicated within your derivation.",
            "solution": "The expected free energy $\\mathcal{G}(\\pi)$ of a policy $\\pi$ is the free energy that is expected to be accumulated under that policy. It is defined as the expectation of the free energy $F(o|\\pi)$ over the predicted outcomes $Q(o|\\pi)$:\n$$ \\mathcal{G}(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[F(o|\\pi)] $$\nThe free energy of a future outcome $o$ is the divergence between the approximate posterior beliefs $Q(s|o,\\pi)$ and the agent's generative model, which incorporates preferences. With preferred outcomes $P^*(o)$, the free energy is:\n$$ F(o|\\pi) = D_{KL}[Q(s|o,\\pi) \\| P(s,o)] = \\mathbb{E}_{Q(s|o,\\pi)} \\left[ \\ln \\frac{Q(s|o,\\pi)}{P(s)P^*(o)} \\right] $$\nExpanding this expression gives:\n$$ F(o|\\pi) = \\mathbb{E}_{Q(s|o,\\pi)} \\left[ \\ln \\frac{Q(s|o,\\pi)}{P(s)} \\right] - \\ln P^*(o) = D_{KL}[Q(s|o,\\pi) \\| P(s)] - \\ln P^*(o) $$\nTaking the expectation over outcomes $Q(o|\\pi)$ yields the expected free energy:\n$$ \\mathcal{G}(\\pi) = \\mathbb{E}_{Q(o|\\pi)}[D_{KL}[Q(s|o,\\pi) \\| P(s)]] + \\mathbb{E}_{Q(o|\\pi)}[-\\ln P^*(o)] $$\nThis expression decomposes into two terms. Assuming the prior over states is the current belief ($P(s)=Q(s)$), the first term is the expected information gain about the hidden states, which is the mutual information $I(s; o|\\pi)$. This is the **epistemic value** (a cost, or negative value). The second term is the cross-entropy between predicted and preferred outcomes, representing the degree to which a policy fails to achieve preferred outcomes. This is the **extrinsic value** (also a cost).\n\n$$ \\mathcal{G}(\\pi) = \\underbrace{I(s; o | \\pi)}_{\\text{Epistemic Cost}} + \\underbrace{\\sum_{o} Q(o|\\pi)(-\\ln P^*(o))}_{\\text{Extrinsic Cost}} $$\nAn agent selects the policy that minimizes this total expected cost.\n\n**Computation for Policy $\\pi_1$**\n1.  **Predictive outcome distribution $Q(o|\\pi_1)$**:\n    $Q(o=1|\\pi_1) = P(o=1|s_0, a_1)Q(s_0) + P(o=1|s_1, a_1)Q(s_1) = (0.8)(0.6) + (0.3)(0.4) = 0.6$.\n    $Q(o=0|\\pi_1) = 1 - 0.6 = 0.4$.\n\n2.  **Extrinsic Cost $\\mathcal{G}_E(\\pi_1)$**:\n    $\\mathcal{G}_E(\\pi_1) = 0.4(-\\ln 0.1) + 0.6(-\\ln 0.9) \\approx 0.4(2.3026) + 0.6(0.1054) \\approx 0.9843$.\n\n3.  **Epistemic Cost $\\mathcal{G}_I(\\pi_1)$**: This is the mutual information $I(s;o|\\pi_1) = H(s) - H(s|o,\\pi_1)$.\n    -   $H(s) = -(0.6\\ln 0.6 + 0.4\\ln 0.4) \\approx 0.6730$.\n    -   $H(s|o,\\pi_1) = \\sum_o Q(o|\\pi_1)H(s|o,\\pi_1)$.\n    -   $Q(s_0|o=1,\\pi_1) = (0.8 \\times 0.6)/0.6 = 0.8$. $Q(s_1|o=1,\\pi_1) = 0.2$. $H(s|o=1,\\pi_1) \\approx 0.5004$.\n    -   $Q(s_0|o=0,\\pi_1) = (0.2 \\times 0.6)/0.4 = 0.3$. $Q(s_1|o=0,\\pi_1) = 0.7$. $H(s|o=0,\\pi_1) \\approx 0.6109$.\n    -   $H(s|o,\\pi_1) \\approx 0.6(0.5004) + 0.4(0.6109) \\approx 0.5446$.\n    -   $\\mathcal{G}_I(\\pi_1) \\approx 0.6730 - 0.5446 \\approx 0.1284$.\n\n4.  **Total Expected Free Energy $\\mathcal{G}(\\pi_1)$**:\n    $\\mathcal{G}(\\pi_1) = \\mathcal{G}_E(\\pi_1) + \\mathcal{G}_I(\\pi_1) \\approx 0.9843 + 0.1284 \\approx 1.1127$.\n\n**Computation for Policy $\\pi_2$**\n1.  **Predictive outcome distribution $Q(o|\\pi_2)$**:\n    $Q(o=1|\\pi_2) = (0.6)(0.6) + (0.1)(0.4) = 0.4$.\n    $Q(o=0|\\pi_2) = 1 - 0.4 = 0.6$.\n\n2.  **Extrinsic Cost $\\mathcal{G}_E(\\pi_2)$**:\n    $\\mathcal{G}_E(\\pi_2) = 0.6(-\\ln 0.1) + 0.4(-\\ln 0.9) \\approx 0.6(2.3026) + 0.4(0.1054) \\approx 1.4237$.\n\n3.  **Epistemic Cost $\\mathcal{G}_I(\\pi_2)$**:\n    -   $H(s) \\approx 0.6730$.\n    -   $Q(s_0|o=1,\\pi_2) = (0.6 \\times 0.6)/0.4 = 0.9$. $Q(s_1|o=1,\\pi_2) = 0.1$. $H(s|o=1,\\pi_2) \\approx 0.3251$.\n    -   $Q(s_0|o=0,\\pi_2) = (0.4 \\times 0.6)/0.6 = 0.4$. $Q(s_1|o=0,\\pi_2) = 0.6$. $H(s|o=0,\\pi_2) \\approx 0.6730$.\n    -   $H(s|o,\\pi_2) \\approx 0.4(0.3251) + 0.6(0.6730) \\approx 0.5338$.\n    -   $\\mathcal{G}_I(\\pi_2) \\approx 0.6730 - 0.5338 \\approx 0.1392$.\n\n4.  **Total Expected Free Energy $\\mathcal{G}(\\pi_2)$**:\n    $\\mathcal{G}(\\pi_2) = \\mathcal{G}_E(\\pi_2) + \\mathcal{G}_I(\\pi_2) \\approx 1.4237 + 0.1392 \\approx 1.5629$.\n\n**Conclusion**\nComparing the total expected free energies:\n-   $\\mathcal{G}(\\pi_1) \\approx 1.1127$\n-   $\\mathcal{G}(\\pi_2) \\approx 1.5629$\n\nSince $\\mathcal{G}(\\pi_1)  \\mathcal{G}(\\pi_2)$, policy $\\pi_1$ minimizes the expected free energy. Therefore, the agent selects policy 1.",
            "answer": "$$\\boxed{1}$$"
        }
    ]
}