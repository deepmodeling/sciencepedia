{
    "hands_on_practices": [
        {
            "introduction": "The Ornstein-Uhlenbeck (OU) process is a cornerstone for modeling variables that fluctuate around a mean, making it an ideal representation for a neuron's subthreshold membrane potential. This practice solidifies your understanding of stochastic differential equations by guiding you through the explicit solution of the OU process from first principles. By deriving the full transition probability density, you will gain a clear, probabilistic picture of how the membrane potential evolves over time under the influence of both deterministic drift and stochastic synaptic noise .",
            "id": "4023191",
            "problem": "Consider the subthreshold membrane potential of a single-compartment neuron modeled as an Ornstein–Uhlenbeck (OU) process. The dynamics are given by the stochastic differential equation (SDE)\n$$\n\\mathrm{d}V_t \\;=\\; -\\frac{1}{\\tau_m}\\big(V_t - V_{\\infty}\\big)\\,\\mathrm{d}t \\;+\\; \\sqrt{2D}\\,\\mathrm{d}W_t,\n$$\nwhere $V_t$ is the membrane potential at time $t$, $\\tau_m  0$ is the membrane time constant, $V_{\\infty} \\in \\mathbb{R}$ is the asymptotic (drift) potential, $D  0$ is the synaptic noise intensity, and $W_t$ is a standard Wiener process (also called Brownian motion). Assume the initial condition $V_0 = x_0$ is given and deterministic. Using only the fundamental definition of a stochastic differential equation, properties of the Wiener process, and the variation-of-constants (integrating factor) method, derive the explicit solution for $V_t$ and then compute the transition probability density $p(x,t \\mid x_0)$ for $t  0$.\n\nYour derivation must proceed from first principles, including the computation of the time-dependent mean and variance of $V_t$. Express your final answer as a single closed-form analytic expression for $p(x,t \\mid x_0)$ in terms of $x$, $t$, $x_0$, $\\tau_m$, $V_{\\infty}$, and $D$. No numerical rounding is required, and no physical units should be included in the expression.",
            "solution": "The problem statement is evaluated and determined to be valid. It is a well-posed problem in the field of computational neuroscience and stochastic processes, grounded in established mathematical and physical principles. The problem is self-contained, with all necessary parameters and conditions defined, and free of contradictions or ambiguities. It requests a standard, albeit non-trivial, derivation for which a unique and meaningful solution exists.\n\nThe problem asks for the transition probability density $p(x,t \\mid x_0)$ of a process $V_t$ governed by the Ornstein-Uhlenbeck (OU) stochastic differential equation (SDE):\n$$\n\\mathrm{d}V_t = -\\frac{1}{\\tau_m}(V_t - V_{\\infty})\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t\n$$\nwith initial condition $V_0 = x_0$. Here, $V_t$ is the membrane potential, $\\tau_m$ is the membrane time constant, $V_{\\infty}$ is the asymptotic potential, $D$ is the noise intensity, and $W_t$ is a standard Wiener process.\n\nOur strategy is to first solve the SDE for $V_t$ using the integrating factor method. Then, we will determine the statistical properties of the solution, specifically its mean and variance. Since the SDE is linear in $V_t$ and driven by Gaussian white noise (the formal derivative of $W_t$), the resulting process $V_t$ for a deterministic initial condition $x_0$ is a Gaussian process. A Gaussian process is fully characterized by its mean and covariance function. For a fixed time $t$, the distribution of $V_t$ is a normal distribution, which is defined by its mean $\\mu(t)$ and variance $\\sigma^2(t)$. The transition probability density $p(x,t \\mid x_0)$ is the probability density function (PDF) of this normal distribution.\n\nFirst, we rearrange the SDE into a standard linear form:\n$$\n\\mathrm{d}V_t + \\frac{1}{\\tau_m}V_t\\,\\mathrm{d}t = \\frac{V_{\\infty}}{\\tau_m}\\,\\mathrm{d}t + \\sqrt{2D}\\,\\mathrm{d}W_t\n$$\nWe introduce the integrating factor $I(t) = \\exp\\left(\\int \\frac{1}{\\tau_m} \\mathrm{d}t\\right) = \\exp(t/\\tau_m)$. Multiplying the SDE by $I(t)$ yields:\n$$\n\\exp(t/\\tau_m)\\,\\mathrm{d}V_t + \\frac{1}{\\tau_m}\\exp(t/\\tau_m)V_t\\,\\mathrm{d}t = \\frac{V_{\\infty}}{\\tau_m}\\exp(t/\\tau_m)\\,\\mathrm{d}t + \\sqrt{2D}\\exp(t/\\tau_m)\\,\\mathrm{d}W_t\n$$\nThe left-hand side is the exact differential of the product $\\exp(t/\\tau_m)V_t$. This can be confirmed using Itô's product rule for a function $f(t, v) = g(t)v$. In our case, $g(t) = \\exp(t/\\tau_m)$ and Itô's rule simplifies to the standard product rule since the second derivative with respect to $v$ is zero: $\\mathrm{d}(\\exp(t/\\tau_m)V_t) = (\\frac{1}{\\tau_m}\\exp(t/\\tau_m)V_t)\\mathrm{d}t + \\exp(t/\\tau_m)\\mathrm{d}V_t$.\nThus, the equation becomes:\n$$\n\\mathrm{d}(\\exp(t/\\tau_m)V_t) = \\frac{V_{\\infty}}{\\tau_m}\\exp(t/\\tau_m)\\,\\mathrm{d}t + \\sqrt{2D}\\exp(t/\\tau_m)\\,\\mathrm{d}W_t\n$$\nWe now integrate both sides from time $s=0$ to $s=t$:\n$$\n\\int_0^t \\mathrm{d}(\\exp(s/\\tau_m)V_s) = \\int_0^t \\frac{V_{\\infty}}{\\tau_m}\\exp(s/\\tau_m)\\,\\mathrm{d}s + \\int_0^t \\sqrt{2D}\\exp(s/\\tau_m)\\,\\mathrm{d}W_s\n$$\nEvaluating the integrals gives:\n$$\n[\\exp(s/\\tau_m)V_s]_{s=0}^{s=t} = \\frac{V_{\\infty}}{\\tau_m}\\left[\\tau_m \\exp(s/\\tau_m)\\right]_{s=0}^{s=t} + \\sqrt{2D}\\int_0^t \\exp(s/\\tau_m)\\,\\mathrm{d}W_s\n$$\n$$\n\\exp(t/\\tau_m)V_t - \\exp(0)V_0 = V_{\\infty}(\\exp(t/\\tau_m) - \\exp(0)) + \\sqrt{2D}\\int_0^t \\exp(s/\\tau_m)\\,\\mathrm{d}W_s\n$$\nSubstituting the initial condition $V_0 = x_0$:\n$$\n\\exp(t/\\tau_m)V_t - x_0 = V_{\\infty}(\\exp(t/\\tau_m) - 1) + \\sqrt{2D}\\int_0^t \\exp(s/\\tau_m)\\,\\mathrm{d}W_s\n$$\nFinally, we solve for $V_t$ by multiplying by $\\exp(-t/\\tau_m)$:\n$$\nV_t = x_0\\exp(-t/\\tau_m) + V_{\\infty}(1 - \\exp(-t/\\tau_m)) + \\sqrt{2D}\\exp(-t/\\tau_m)\\int_0^t \\exp(s/\\tau_m)\\,\\mathrm{d}W_s\n$$\nThis expression can be written more compactly by bringing the factor $\\exp(-t/\\tau_m)$ inside the stochastic integral:\n$$\nV_t = x_0\\exp(-t/\\tau_m) + V_{\\infty}(1 - \\exp(-t/\\tau_m)) + \\sqrt{2D}\\int_0^t \\exp\\left(-\\frac{t-s}{\\tau_m}\\right)\\,\\mathrm{d}W_s\n$$\nThis is the explicit solution for $V_t$. Now we compute its mean and variance.\n\nThe mean of $V_t$, denoted $\\mu(t) = \\mathbb{E}[V_t]$, is found by taking the expectation of the solution. The first two terms are deterministic. The expectation of the Itô integral is zero, a fundamental property of the Wiener process.\n$$\n\\mu(t) = \\mathbb{E}\\left[x_0\\exp(-t/\\tau_m) + V_{\\infty}(1 - \\exp(-t/\\tau_m))\\right] + \\mathbb{E}\\left[\\sqrt{2D}\\int_0^t \\exp\\left(-\\frac{t-s}{\\tau_m}\\right)\\,\\mathrm{d}W_s\\right]\n$$\n$$\n\\mu(t) = x_0\\exp(-t/\\tau_m) + V_{\\infty}(1 - \\exp(-t/\\tau_m)) + 0\n$$\nSo, the mean is $\\mu(t) = V_{\\infty} + (x_0 - V_{\\infty})\\exp(-t/\\tau_m)$.\n\nThe variance of $V_t$, denoted $\\sigma^2(t) = \\text{Var}[V_t]$, is the variance of the stochastic part of the solution, as the other terms are deterministic.\n$$\n\\sigma^2(t) = \\text{Var}\\left[\\sqrt{2D}\\int_0^t \\exp\\left(-\\frac{t-s}{\\tau_m}\\right)\\,\\mathrm{d}W_s\\right] = \\mathbb{E}\\left[\\left(\\sqrt{2D}\\int_0^t \\exp\\left(-\\frac{t-s}{\\tau_m}\\right)\\,\\mathrm{d}W_s\\right)^2\\right]\n$$\nUsing the Itô isometry property, which states that $\\mathbb{E}\\left[(\\int_0^t f(s)\\,\\mathrm{d}W_s)^2\\right] = \\int_0^t \\mathbb{E}[f(s)^2]\\,\\mathrm{d}s$, and since our integrand $f(s) = \\exp(-(t-s)/\\tau_m)$ is deterministic, this simplifies to $\\int_0^t f(s)^2\\,\\mathrm{d}s$:\n$$\n\\sigma^2(t) = 2D \\int_0^t \\left(\\exp\\left(-\\frac{t-s}{\\tau_m}\\right)\\right)^2\\,\\mathrm{d}s = 2D \\int_0^t \\exp\\left(-\\frac{2(t-s)}{\\tau_m}\\right)\\,\\mathrm{d}s\n$$\n$$\n\\sigma^2(t) = 2D \\exp(-2t/\\tau_m) \\int_0^t \\exp(2s/\\tau_m)\\,\\mathrm{d}s\n$$\nEvaluating the integral:\n$$\n\\int_0^t \\exp(2s/\\tau_m)\\,\\mathrm{d}s = \\left[\\frac{\\tau_m}{2}\\exp(2s/\\tau_m)\\right]_0^t = \\frac{\\tau_m}{2}(\\exp(2t/\\tau_m) - 1)\n$$\nSubstituting this back into the expression for the variance:\n$$\n\\sigma^2(t) = 2D \\exp(-2t/\\tau_m) \\left(\\frac{\\tau_m}{2}(\\exp(2t/\\tau_m) - 1)\\right) = D\\tau_m (1 - \\exp(-2t/\\tau_m))\n$$\nSince $V_t$ is a Gaussian random variable with mean $\\mu(t)$ and variance $\\sigma^2(t)$, its probability density function is given by the normal distribution formula:\n$$\np(x,t \\mid x_0) = \\mathcal{N}(x; \\mu(t), \\sigma^2(t)) = \\frac{1}{\\sqrt{2\\pi\\sigma^2(t)}} \\exp\\left( -\\frac{(x-\\mu(t))^2}{2\\sigma^2(t)} \\right)\n$$\nSubstituting the derived expressions for $\\mu(t)$ and $\\sigma^2(t)$:\n$$\np(x,t \\mid x_0) = \\frac{1}{\\sqrt{2\\pi D\\tau_m(1 - \\exp(-2t/\\tau_m))}} \\exp\\left( -\\frac{\\left(x - \\left(V_{\\infty} + (x_0 - V_{\\infty})\\exp(-t/\\tau_m)\\right)\\right)^2}{2D\\tau_m(1 - \\exp(-2t/\\tau_m))} \\right)\n$$\nThis is the final expression for the transition probability density of the Ornstein-Uhlenbeck process.",
            "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{2\\pi D\\tau_m(1 - \\exp(-2t/\\tau_m))}} \\exp\\left(-\\frac{\\left(x - V_{\\infty} - (x_0 - V_{\\infty})\\exp(-t/\\tau_m)\\right)^2}{2D\\tau_m(1 - \\exp(-2t/\\tau_m))}\\right)}\n$$"
        },
        {
            "introduction": "After modeling how a neuron's potential fluctuates, the next critical question is: when does it fire? This exercise tackles this question by analyzing the first passage time of a simplified process—drifted Brownian motion—to a firing threshold. You will derive the mean and variance of this waiting time, providing fundamental insights into how a neuron's average input ($\\mu$) and noise level ($\\sigma$) together determine its firing statistics . This is a foundational problem for understanding integrate-and-fire models and the timing of neural events.",
            "id": "4023143",
            "problem": "A single-compartment neuron model can be approximated near rest by a one-dimensional Stochastic Differential Equation (SDE) for its membrane potential, driven by constant input and fast synaptic noise. Let the membrane potential be modeled by a drifted Brownian motion satisfying the SDE $dX_t = \\mu\\, dt + \\sigma\\, dW_t$, where $X_0 = x_0$ with $x_0  a$, $\\mu  0$ is a constant drift reflecting net input current, $\\sigma  0$ quantifies synaptic noise amplitude, and $W_t$ is a standard Brownian motion. Define the first passage time $\\tau$ to a firing threshold $a$ by $\\tau := \\inf\\{t \\ge 0 : X_t = a\\}$. Use a derivation grounded in the infinitesimal generator of the process and the Laplace transform of the stopping time (without invoking any pre-stated closed-form hitting-time distributions) to obtain closed-form analytic expressions for the mean $\\mathbb{E}[\\tau]$ and the variance $\\operatorname{Var}(\\tau)$ in terms of $\\mu$, $\\sigma$, $x_0$, and $a$. Express the mean in seconds and the variance in seconds squared. Your final answer must be a single closed-form analytic expression collecting both quantities as entries of a row matrix. No numerical approximation is required.",
            "solution": "The user wants to solve the following problem:\nA single-compartment neuron model can be approximated near rest by a one-dimensional Stochastic Differential Equation (SDE) for its membrane potential, driven by constant input and fast synaptic noise. Let the membrane potential be modeled by a drifted Brownian motion satisfying the SDE $dX_t = \\mu\\, dt + \\sigma\\, dW_t$, where $X_0 = x_0$ with $x_0  a$, $\\mu  0$ is a constant drift reflecting net input current, $\\sigma  0$ quantifies synaptic noise amplitude, and $W_t$ is a standard Brownian motion. Define the first passage time $\\tau$ to a firing threshold $a$ by $\\tau := \\inf\\{t \\ge 0 : X_t = a\\}$. Use a derivation grounded in the infinitesimal generator of the process and the Laplace transform of the stopping time (without invoking any pre-stated closed-form hitting-time distributions) to obtain closed-form analytic expressions for the mean, $\\mathbb{E}[\\tau]$, and the variance, $\\operatorname{Var}(\\tau)$. Express the mean in seconds and the variance in seconds squared. Your final answer must be a single closed-form analytic expression collecting both quantities as entries of a row matrix. No numerical approximation is required.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- Stochastic Differential Equation (SDE): $dX_t = \\mu\\, dt + \\sigma\\, dW_t$\n- Initial Condition: $X_0 = x_0$, where $x_0  a$\n- Drift Parameter: $\\mu  0$\n- Noise Amplitude Parameter: $\\sigma  0$\n- Stochastic Process: $W_t$ is a standard Brownian motion.\n- First Passage Time (Stopping Time): $\\tau := \\inf\\{t \\ge 0 : X_t = a\\}$\n- Objective: Find closed-form analytic expressions for the mean, $\\mathbb{E}[\\tau]$, and the variance, $\\operatorname{Var}(\\tau)$.\n- Methodological Constraint: The derivation must use the infinitesimal generator of the process and the Laplace transform of the stopping time. Pre-stated closed-form hitting-time distributions are forbidden.\n- Output Format: The mean and variance are to be collected as entries of a row matrix.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem describes the first passage time of a drifted Brownian motion. This is a canonical model in stochastic processes and is frequently used as a simplified model for neuronal firing, known as the \"perfect integrate-and-fire\" model with noise. The underlying physics and mathematics are sound.\n- **Well-Posed:** The problem is well-posed. Given the parameters $\\mu  0$ and $x_0  a$, the particle will reach the threshold $a$ with probability $1$, ensuring that the stopping time $\\tau$ is a proper random variable with finite moments. The task is to compute the first two moments, which is a standard problem in stochastic calculus with a unique solution.\n- **Objective:** The problem statement is formulated using precise, unambiguous mathematical language.\n- **Flaws Checklist:**\n    1.  **Scientific/Factual Unsoundness:** None. The model is a valid and widely used simplification.\n    2.  **Non-Formalizable/Irrelevant:** None. The problem is a formal mathematical question directly relevant to stochastic processes in computational neuroscience.\n    3.  **Incomplete/Contradictory:** None. The setup provides all necessary parameters and consistent conditions.\n    4.  **Unrealistic/Infeasible:** None. The problem is theoretical and does not involve physically impossible conditions.\n    5.  **Ill-Posed/Poorly Structured:** None. A unique, stable, and meaningful solution exists.\n    6.  **Pseudo-Profound/Trivial:** None. The required derivation, while classic, is non-trivial and requires a solid understanding of stochastic differential equations and their generators.\n    7.  **Outside Scientific Verifiability:** None. The results are mathematically derivable and verifiable.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full, reasoned solution will be provided.\n\n### Solution Derivation\n\nLet $X_t$ be the process governed by the SDE $dX_t = \\mu\\, dt + \\sigma\\, dW_t$, with initial state $X_0 = x_0$. We are interested in the moments of the first passage time to a threshold $a  x_0$, defined as $\\tau = \\inf\\{t \\geq 0 : X_t = a\\}$.\n\nThe derivation will proceed as follows:\n1. Define the Laplace transform of the stopping time $\\tau$.\n2. Use the infinitesimal generator of the process $X_t$ to establish a differential equation for this Laplace transform.\n3. Solve this differential equation with appropriate boundary conditions.\n4. Use the moment-generating properties of the Laplace transform to find the mean $\\mathbb{E}[\\tau]$ and variance $\\operatorname{Var}(\\tau)$.\n\nThe infinitesimal generator $\\mathcal{L}$ for the Itô diffusion $X_t$ is given by:\n$$\n\\mathcal{L}f(x) = \\mu \\frac{df}{dx} + \\frac{1}{2}\\sigma^2 \\frac{d^2f}{dx^2}\n$$\n\nLet $u(x_0; \\lambda) = \\mathbb{E}_{x_0}[\\exp(-\\lambda \\tau)]$ be the Laplace transform of $\\tau$ for a given starting position $x_0$ and a parameter $\\lambda  0$. The notation $\\mathbb{E}_{x_0}[\\cdot]$ denotes the expectation conditional on $X_0=x_0$. It is a standard result from the theory of stochastic processes that $u(x; \\lambda)$ satisfies the ordinary differential equation (ODE):\n$$\n\\mathcal{L}u(x; \\lambda) - \\lambda u(x; \\lambda) = 0\n$$\nSubstituting the expression for the generator $\\mathcal{L}$, we get:\n$$\n\\frac{1}{2}\\sigma^2 u''(x; \\lambda) + \\mu u'(x; \\lambda) - \\lambda u(x; \\lambda) = 0\n$$\nwhere primes denote differentiation with respect to $x$.\n\nWe need to solve this second-order linear homogeneous ODE for $x  a$. This requires two boundary conditions.\n1.  If the process starts at the threshold, $x_0 = a$, the time to reach it is $\\tau = 0$. Thus, $u(a; \\lambda) = \\mathbb{E}_a[\\exp(-\\lambda \\cdot 0)] = 1$.\n2.  For the second condition, we consider the behavior as $x_0 \\to -\\infty$. The time to reach $a$ will approach infinity, so $\\tau \\to \\infty$. For $\\lambda  0$, this implies $\\exp(-\\lambda \\tau) \\to 0$. Therefore, we expect $u(x_0; \\lambda) \\to 0$ as $x_0 \\to -\\infty$. More formally, we require the solution to be bounded.\n\nThe characteristic equation for the ODE is:\n$$\n\\frac{1}{2}\\sigma^2 r^2 + \\mu r - \\lambda = 0\n$$\nThe roots are given by the quadratic formula:\n$$\nr = \\frac{-\\mu \\pm \\sqrt{\\mu^2 - 4(\\frac{1}{2}\\sigma^2)(-\\lambda)}}{\\sigma^2} = \\frac{-\\mu \\pm \\sqrt{\\mu^2 + 2\\sigma^2\\lambda}}{\\sigma^2}\n$$\nLet's denote the two roots as $r_1$ and $r_2$:\n$$\nr_1 = \\frac{-\\mu + \\sqrt{\\mu^2 + 2\\sigma^2\\lambda}}{\\sigma^2}  0\n$$\n$$\nr_2 = \\frac{-\\mu - \\sqrt{\\mu^2 + 2\\sigma^2\\lambda}}{\\sigma^2}  0\n$$\nThe general solution to the ODE is:\n$$\nu(x; \\lambda) = C_1 \\exp(r_1 x) + C_2 \\exp(r_2 x)\n$$\nApplying the boundary condition at $x \\to -\\infty$: for the solution to remain bounded (specifically, to not diverge to infinity), the coefficient of the term that grows as $x \\to -\\infty$ must be zero. Since $r_2  0$, $\\exp(r_2 x)$ diverges as $x \\to -\\infty$. Therefore, we must set $C_2 = 0$.\n\nThe solution simplifies to $u(x; \\lambda) = C_1 \\exp(r_1 x)$. Now, we apply the boundary condition at $x=a$:\n$$\nu(a; \\lambda) = C_1 \\exp(r_1 a) = 1 \\implies C_1 = \\exp(-r_1 a)\n$$\nThus, the Laplace transform of $\\tau$ for a starting point $x_0$ is:\n$$\nu(x_0; \\lambda) = \\exp(-r_1 a) \\exp(r_1 x_0) = \\exp(r_1(x_0-a))\n$$\nSubstituting the expression for $r_1$:\n$$\nu(x_0; \\lambda) = \\mathbb{E}_{x_0}[\\exp(-\\lambda \\tau)] = \\exp\\left( \\left(\\frac{-\\mu + \\sqrt{\\mu^2 + 2\\sigma^2\\lambda}}{\\sigma^2}\\right)(x_0 - a) \\right)\n$$\nThe moments of $\\tau$ can be found by taking derivatives of $u(x_0; \\lambda)$ with respect to $\\lambda$ and evaluating at $\\lambda = 0$. Specifically:\n$$\n\\mathbb{E}_{x_0}[\\tau^k] = (-1)^k \\frac{d^k}{d\\lambda^k} u(x_0; \\lambda) \\bigg|_{\\lambda=0}\n$$\n\n**Mean First Passage Time, $\\mathbb{E}[\\tau]$**\nThe mean is the negative of the first derivative at $\\lambda=0$:\n$$\n\\mathbb{E}[\\tau] = -\\frac{d}{d\\lambda} u(x_0; \\lambda) \\bigg|_{\\lambda=0}\n$$\n(From here on, we drop the subscript on $\\mathbb{E}$ for brevity, as the starting point $x_0$ is fixed). Let $g(\\lambda) = r_1(x_0-a)$. Then $u(x_0; \\lambda) = \\exp(g(\\lambda))$.\n$$\n\\frac{du}{d\\lambda} = u(x_0; \\lambda) \\cdot \\frac{dg}{d\\lambda}\n$$\nFirst, we find $\\frac{dg}{d\\lambda}$:\n$$\n\\frac{dg}{d\\lambda} = \\frac{d}{d\\lambda} \\left[ \\left(\\frac{x_0 - a}{\\sigma^2}\\right) \\left(-\\mu + \\sqrt{\\mu^2 + 2\\sigma^2\\lambda}\\right) \\right] = \\left(\\frac{x_0 - a}{\\sigma^2}\\right) \\left( \\frac{1}{2\\sqrt{\\mu^2 + 2\\sigma^2\\lambda}} \\cdot 2\\sigma^2 \\right) = \\frac{x_0 - a}{\\sqrt{\\mu^2 + 2\\sigma^2\\lambda}}\n$$\nEvaluating at $\\lambda=0$:\n$$\n\\frac{dg}{d\\lambda}\\bigg|_{\\lambda=0} = \\frac{x_0 - a}{\\sqrt{\\mu^2}} = \\frac{x_0 - a}{\\mu}\n$$\nAlso, we note that $u(x_0; 0) = \\mathbb{E}[\\exp(0)] = 1$. This corresponds to the probability of hitting the threshold, which is $1$ for $\\mu  0$.\nSo,\n$$\n\\frac{du}{d\\lambda}\\bigg|_{\\lambda=0} = u(x_0; 0) \\cdot \\frac{dg}{d\\lambda}\\bigg|_{\\lambda=0} = 1 \\cdot \\frac{x_0 - a}{\\mu} = \\frac{x_0 - a}{\\mu}\n$$\nThe mean first passage time is:\n$$\n\\mathbb{E}[\\tau] = - \\left( \\frac{x_0 - a}{\\mu} \\right) = \\frac{a - x_0}{\\mu}\n$$\n\n**Variance of the First Passage Time, $\\operatorname{Var}(\\tau)$**\nFirst, we find the second moment $\\mathbb{E}[\\tau^2] = \\frac{d^2}{d\\lambda^2} u(x_0; \\lambda) \\bigg|_{\\lambda=0}$.\n$$\n\\frac{d^2u}{d\\lambda^2} = \\frac{d}{d\\lambda}\\left( u \\cdot \\frac{dg}{d\\lambda} \\right) = \\left(\\frac{du}{d\\lambda}\\right) \\left(\\frac{dg}{d\\lambda}\\right) + u \\left(\\frac{d^2g}{d\\lambda^2}\\right) = u \\left(\\frac{dg}{d\\lambda}\\right)^2 + u \\left(\\frac{d^2g}{d\\lambda^2}\\right)\n$$\nWe need to calculate the second derivative of $g(\\lambda)$:\n$$\n\\frac{d^2g}{d\\lambda^2} = \\frac{d}{d\\lambda} \\left[ (x_0-a)(\\mu^2 + 2\\sigma^2\\lambda)^{-1/2} \\right] = (x_0-a) \\left(-\\frac{1}{2}\\right) (\\mu^2 + 2\\sigma^2\\lambda)^{-3/2} (2\\sigma^2) = -(x_0-a)\\sigma^2 (\\mu^2 + 2\\sigma^2\\lambda)^{-3/2}\n$$\nEvaluating at $\\lambda=0$:\n$$\n\\frac{d^2g}{d\\lambda^2}\\bigg|_{\\lambda=0} = -(x_0-a)\\sigma^2 (\\mu^2)^{-3/2} = -(x_0-a)\\frac{\\sigma^2}{\\mu^3} = (a-x_0)\\frac{\\sigma^2}{\\mu^3}\n$$\nNow we can compute the second moment:\n$$\n\\mathbb{E}[\\tau^2] = \\frac{d^2u}{d\\lambda^2}\\bigg|_{\\lambda=0} = u(x_0; 0) \\left( \\frac{dg}{d\\lambda}\\bigg|_{\\lambda=0} \\right)^2 + u(x_0; 0) \\left( \\frac{d^2g}{d\\lambda^2}\\bigg|_{\\lambda=0} \\right)\n$$\n$$\n\\mathbb{E}[\\tau^2] = 1 \\cdot \\left(\\frac{x_0 - a}{\\mu}\\right)^2 + 1 \\cdot \\left((a-x_0)\\frac{\\sigma^2}{\\mu^3}\\right) = \\frac{(a-x_0)^2}{\\mu^2} + \\frac{(a-x_0)\\sigma^2}{\\mu^3}\n$$\nThe variance is $\\operatorname{Var}(\\tau) = \\mathbb{E}[\\tau^2] - (\\mathbb{E}[\\tau])^2$.\n$$\n\\operatorname{Var}(\\tau) = \\left( \\frac{(a-x_0)^2}{\\mu^2} + \\frac{(a-x_0)\\sigma^2}{\\mu^3} \\right) - \\left( \\frac{a - x_0}{\\mu} \\right)^2\n$$\n$$\n\\operatorname{Var}(\\tau) = \\left( \\frac{(a-x_0)^2}{\\mu^2} + \\frac{(a-x_0)\\sigma^2}{\\mu^3} \\right) - \\frac{(a - x_0)^2}{\\mu^2} = \\frac{(a-x_0)\\sigma^2}{\\mu^3}\n$$\n\nThe final expressions are:\nMean: $\\mathbb{E}[\\tau] = \\frac{a-x_0}{\\mu}$\nVariance: $\\operatorname{Var}(\\tau) = \\frac{(a-x_0)\\sigma^2}{\\mu^3}$\n\nThe units are consistent. For membrane potential in volts ($V$) and time in seconds ($s$), $[\\mu]$ is $V/s$ and $[\\sigma]$ is $V/s^{1/2}$.\n$[\\mathbb{E}[\\tau]] = [V] / [V/s] = s$.\n$[\\operatorname{Var}(\\tau)] = [V] \\cdot [V^2/s] / [V^3/s^3] = [V^3/s] / [V^3/s^3] = s^2$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{a - x_0}{\\mu}  \\frac{(a - x_0)\\sigma^2}{\\mu^3} \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Stochastic processes are not only useful for modeling single-neuron biophysics but also for understanding higher-level cognitive functions like decision-making. This practice applies the classic \"gambler's ruin\" problem to model evidence accumulation, where a decision variable performs a random walk between two choice boundaries. By solving for the hitting probabilities and the expected decision time, you will learn how to analyze discrete-time Markov chains and connect their mathematical properties to measurable behaviors in cognitive tasks .",
            "id": "4023192",
            "problem": "In a simplified model of bounded evidence accumulation in a two-alternative decision circuit, the aggregated decision variable evolves as a discrete-time, nearest-neighbor random walk on the finite state space $\\{0,1,\\dots,N\\}$ with absorbing boundaries at $0$ and $N$. At each time step, the state increments by $+1$ with probability $p \\in (0,1)$ (evidence favoring the upper choice) and decrements by $-1$ with probability $q=1-p$ (evidence favoring the lower choice). The boundary states $0$ and $N$ are absorbing and represent commitment to the corresponding choice. The process starts at a known interior state $X_0=i_0$ with $i_0 \\in \\{1,2,\\dots,N-1\\}$. Let $H_i$ denote the probability that the walk, starting from state $i$, is absorbed at $N$ before $0$, and let $T_i$ denote the expected number of steps until absorption (at either boundary), starting from $i$.\n\nUsing only the Markov property, the law of total probability, and linearity of expectation, perform the following:\n\n1. Derive the recurrence relations satisfied by $H_i$ and $T_i$ for $i \\in \\{1,2,\\dots,N-1\\}$ together with the absorbing boundary conditions at $i=0$ and $i=N$.\n2. Solve these recurrences to obtain closed-form expressions for $H_i$ and $T_i$ valid for all $i \\in \\{0,1,\\dots,N\\}$ and all $p \\in (0,1)$. Your expressions must explicitly address the symmetric case $p=\\tfrac{1}{2}$ and the biased case $p \\neq \\tfrac{1}{2}$.\n3. Evaluate the expressions at $N=100$, $i_0=20$, and $p=0.55$. \n\nAnswer specification:\n- Provide your final answer as a two-entry row vector $\\big[H_{i_0},\\,T_{i_0}\\big]$, in this order.\n- Round each entry to four significant figures.\n- No physical units are required.",
            "solution": "The problem is first validated and found to be well-posed, scientifically grounded, and internally consistent.\n\n**1. Derivation of Recurrence Relations**\n\nLet the state space be $\\{0, 1, \\dots, N\\}$, where states $0$ and $N$ are absorbing. For any interior state $i \\in \\{1, 2, \\dots, N-1\\}$, the process moves to state $i+1$ with probability $p$ and to state $i-1$ with probability $q=1-p$.\n\n**Recurrence for Hitting Probability $H_i$**\n\nLet $H_i$ be the probability that the process, starting from state $i$, is absorbed at $N$ before being absorbed at $0$. To find the recurrence relation for $H_i$, we condition on the first step from state $i$. By the law of total probability and the Markov property:\n$$H_i = P(\\text{hit } N \\text{ first} | X_0=i)$$\n$$H_i = P(\\text{hit } N \\text{ first} | X_1=i+1)P(X_1=i+1|X_0=i) + P(\\text{hit } N \\text{ first} | X_1=i-1)P(X_1=i-1|X_0=i)$$\nBy definition of $H_i$ and the transition probabilities, this becomes:\n$$H_i = H_{i+1} \\cdot p + H_{i-1} \\cdot q$$\nThis relation holds for $i \\in \\{1, 2, \\dots, N-1\\}$.\n\nThe boundary conditions are determined by the definition of absorption. If the process starts at $i=N$, it is already absorbed at $N$, so the probability of being absorbed at $N$ first is $1$. If it starts at $i=0$, it is absorbed at $0$, so the probability of being absorbed at $N$ first is $0$.\n$$H_N = 1$$\n$$H_0 = 0$$\n\n**Recurrence for Expected Absorption Time $T_i$**\n\nLet $T_i$ be the expected number of steps until absorption at either boundary, starting from state $i$. We again condition on the first step, which takes exactly $1$ time step. By the law of total expectation and the Markov property:\n$$T_i = E[\\text{steps to absorption} | X_0=i]$$\n$$T_i = 1 + E[\\text{remaining steps to absorption from next state}]$$\n$$T_i = 1 + T_{i+1} \\cdot p + T_{i-1} \\cdot q$$\nThis relation holds for $i \\in \\{1, 2, \\dots, N-1\\}$.\n\nThe boundary conditions are that if the process starts at an absorbing state, the time to absorption is $0$.\n$$T_N = 0$$\n$$T_0 = 0$$\n\n**2. Solving the Recurrence Relations**\n\n**Solution for $H_i$**\n\nThe recurrence $H_i = p H_{i+1} + q H_{i-1}$ can be rewritten as a homogeneous linear second-order difference equation: $p H_{i+1} - H_i + q H_{i-1} = 0$.\nWe can rearrange this as $p(H_{i+1} - H_i) = q(H_i - H_{i-1})$. Let $\\Delta_i = H_i - H_{i-1}$. Then $\\Delta_{i+1} = (q/p) \\Delta_i$, which implies $\\Delta_i = (q/p)^{i-1} \\Delta_1$.\nThe solution $H_i$ is found by summing the differences: $H_i = H_0 + \\sum_{k=1}^{i} \\Delta_k = \\sum_{k=1}^{i} (q/p)^{k-1} \\Delta_1$.\n\nCase 1: $p = 1/2$.\nIn this case, $q=p=1/2$, so $q/p=1$. The recurrence simplifies to $H_{i+1} - 2H_i + H_{i-1} = 0$, meaning the sequence $H_i$ is an arithmetic progression. The general solution is $H_i = A i + B$.\nUsing the boundary conditions:\n$H_0 = 0 \\implies A \\cdot 0 + B = 0 \\implies B=0$.\n$H_N = 1 \\implies A \\cdot N = 1 \\implies A=1/N$.\nThus, for $p=1/2$, the solution is:\n$$H_i = \\frac{i}{N}$$\n\nCase 2: $p \\neq 1/2$.\nIn this case, $\\rho = q/p \\neq 1$. The sum is a geometric series:\n$H_i = \\Delta_1 \\sum_{j=0}^{i-1} \\rho^j = \\Delta_1 \\frac{1-\\rho^i}{1-\\rho}$.\nTo find $\\Delta_1$, we use the boundary condition $H_N = 1$:\n$1 = H_N = \\Delta_1 \\frac{1-\\rho^N}{1-\\rho} \\implies \\Delta_1 = \\frac{1-\\rho}{1-\\rho^N}$.\nSubstituting this back gives the solution for $H_i$:\n$$H_i = \\left(\\frac{1-\\rho}{1-\\rho^N}\\right) \\frac{1-\\rho^i}{1-\\rho} = \\frac{1 - (q/p)^i}{1 - (q/p)^N}$$\nThese expressions are valid for all $i \\in \\{0, 1, \\dots, N\\}$.\n\n**Solution for $T_i$**\n\nThe recurrence $T_i = 1 + p T_{i+1} + q T_{i-1}$ is an inhomogeneous linear second-order difference equation: $p T_{i+1} - T_i + q T_{i-1} = -1$.\nThe solution is the sum of a homogeneous solution $T_i^{(h)}$ and a particular solution $T_i^{(p)}$. The homogeneous equation is the same as for $H_i$.\n\nCase 1: $p=1/2$.\nThe recurrence is $\\frac{1}{2} T_{i+1} - T_i + \\frac{1}{2} T_{i-1} = -1$, or $T_{i+1} - 2T_i + T_{i-1} = -2$.\nThe homogeneous solution is $T_i^{(h)} = Ai + B$. Since this form is linear, we try a particular solution of the form $T_i^{(p)} = C i^2$. Substituting this into the recurrence gives $C(i+1)^2 - 2Ci^2 + C(i-1)^2 = -2$, which simplifies to $2C=-2$, so $C=-1$.\nThe general solution is $T_i = Ai + B - i^2$.\nUsing the boundary conditions $T_0=0, T_N=0$:\n$T_0 = 0 \\implies A \\cdot 0 + B - 0 = 0 \\implies B=0$.\n$T_N = 0 \\implies A \\cdot N - N^2 = 0 \\implies A=N$.\nThus, for $p=1/2$, the solution is:\n$$T_i = N i - i^2 = i(N-i)$$\n\nCase 2: $p \\neq 1/2$.\nThe homogeneous solution is $T_i^{(h)} = A + B(q/p)^i$. We seek a particular solution of the form $T_i^{(p)} = C i$. Substituting this into $p T_{i+1} - T_i + q T_{i-1} = -1$ gives:\n$pC(i+1) - Ci + qC(i-1) = -1$\n$C(pi + p - i + qi - q) = -1$\n$C(i(p+q-1) + p-q) = -1$. Since $p+q=1$, this simplifies to $C(p-q) = -1$, so $C = \\frac{1}{q-p}$.\nThe general solution is $T_i = A + B(q/p)^i + \\frac{i}{q-p}$.\nUsing the boundary conditions $T_0=0, T_N=0$:\n$T_0 = 0 \\implies A+B=0 \\implies B=-A$.\n$T_N = 0 \\implies A+B(q/p)^N + \\frac{N}{q-p} = 0$.\nSubstituting $B=-A$ gives $A(1-(q/p)^N) + \\frac{N}{q-p} = 0$, so $A = \\frac{-N}{(q-p)(1-(q/p)^N)}$.\nThe full solution is therefore:\n$$T_i = \\frac{-N}{(q-p)(1-(q/p)^N)} + \\frac{N(q/p)^i}{(q-p)(1-(q/p)^N)} + \\frac{i}{q-p}$$\n$$T_i = \\frac{i}{q-p} - \\frac{N}{q-p} \\left( \\frac{1-(q/p)^i}{1-(q/p)^N} \\right)$$\nRecognizing the expression for $H_i$, we can write this more compactly as:\n$$T_i = \\frac{i - N H_i}{q-p} = \\frac{N H_i - i}{p-q}$$\nThese expressions are valid for all $i \\in \\{0, 1, \\dots, N\\}$.\n\n**3. Numerical Evaluation**\n\nThe problem provides the parameters $N=100$, $i_0=20$, and $p=0.55$.\nSince $p=0.55 \\neq 0.5$, we use the formulae for the biased walk.\nFirst, we compute the relevant constants:\n$q = 1-p = 1 - 0.55 = 0.45$.\nThe ratio $\\rho = q/p = 0.45 / 0.55 = 9/11$.\nThe initial state is $i_0=20$.\n\n**Evaluation of $H_{20}$**\n$$H_{20} = \\frac{1 - (9/11)^{20}}{1 - (9/11)^{100}}$$\nWe compute the powers of the ratio:\n$(9/11)^{20} \\approx 0.01807154$\n$(9/11)^{100} \\approx 1.92301 \\times 10^{-9}$\nSubstituting these values:\n$$H_{20} = \\frac{1 - 0.01807154}{1 - 1.92301 \\times 10^{-9}} = \\frac{0.98192846}{0.999999998077} \\approx 0.98192846$$\nRounding to four significant figures, $H_{20} = 0.9819$.\n\n**Evaluation of $T_{20}$**\nWe use the compact formula for $T_i$:\n$$T_{20} = \\frac{20 - N H_{20}}{q-p} = \\frac{20 - 100 H_{20}}{0.45 - 0.55} = \\frac{20 - 100 H_{20}}{-0.1}$$\n$$T_{20} = 10(100 H_{20} - 20) = 1000 H_{20} - 200$$\nUsing the unrounded value of $H_{20}$:\n$$T_{20} = 1000 \\times (0.98192846) - 200 = 981.92846 - 200 = 781.92846$$\nRounding to four significant figures, $T_{20} = 781.9$.\n\nThe final answer is the row vector $[H_{20}, T_{20}]$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.9819  781.9\n\\end{pmatrix}\n}\n$$"
        }
    ]
}