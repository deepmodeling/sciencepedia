{
    "hands_on_practices": [
        {
            "introduction": "A crucial first step in applying Marr's framework is learning to correctly categorize different types of explanations. This exercise builds that foundational skill by asking you to apply the levels of analysis to the canonical problem of sound localization in the auditory system. By distinguishing the computational goal from the algorithm and its physical implementation, you solidify your understanding of what each level seeks to explain .",
            "id": "3995698",
            "problem": "A research team aims to model human horizontal sound localization by mapping binaural cues to azimuth. Let the inputs be $X$ representing binaural cues such as Interaural Time Difference (ITD) and Interaural Level Difference (ILD), and let the outputs be $Y$ representing the perceived azimuth. The task is to differentiate the targets of explanation at each of David Marr’s three levels of analysis (computational, algorithmic, implementational) for the mapping from $X$ to $Y$, and to state what constitutes a successful specification at each level. Choose the option that most accurately and completely characterizes (i) what each level is explaining for the task $X \\mapsto Y$ and (ii) what counts as success at that level, using the following context-appropriate base: the computational level characterizes the goal and constraints of the task, the algorithmic level characterizes the representation of $X$ and $Y$ and the procedures that compute the mapping, and the implementational level characterizes the physical substrate that realizes those procedures.\n\nA. Computational level: specify the functional goal of mapping $X$ to $Y$ and the environmental and sensory constraints that make this goal well-posed, including the criterion by which solutions are judged (for example, minimizing azimuth error under plausible sensory noise and scene statistics). Success: predictions from the specified goal correspond to psychophysical performance across conditions. Algorithmic level: specify representational choices for $X$ and $Y$ (for example, using phase and amplitude features of binaural signals) and a finite, well-defined procedure that transforms those representations to yield $Y$ (for example, temporal cross-correlation and a decision rule), together with resource trade-offs. Success: the procedure demonstrably and reproducibly computes the intended mapping from $X$ to $Y$ under the stated constraints. Implementational level: specify neural substrates and biophysical mechanisms that realize the procedure (for example, brainstem circuits including the Medial Superior Olive (MSO) and Lateral Superior Olive (LSO), their connectivity, and synaptic dynamics). Success: empirical evidence shows that these substrates causally implement the procedure and generate behavior consistent with the computational specification.\n\nB. Computational level: detail the specific neuron types, membrane currents, and synaptic connectivity in auditory brainstem nuclei involved in binaural processing. Success: accurate reproduction of known firing patterns. Algorithmic level: state that $Y$ is obtained by minimizing total synaptic energy in the network. Success: a low-energy state is found. Implementational level: explain that the purpose of the system is to aid survival by orienting toward sound sources. Success: the stated purpose is plausible.\n\nC. Computational level: define the mapping from $X$ to $Y$ as whatever function reproduces known physiological tuning curves in superior olive nuclei. Success: close match to measured spiking rates. Algorithmic level: list membrane time constants, conductances, and channel kinetics. Success: parameter fitting reproduces azimuth judgments. Implementational level: specify a normative estimator for $Y$ given $X$ without reference to neural hardware. Success: the estimator achieves optimality.\n\nD. Computational level: set the goal as maximizing the mutual information between $X$ and $Y$ to ensure informative cues. Success: mutual information is high. Algorithmic level: use any flexible machine learning mapping from $X$ to $Y$ (for example, a deep neural network) without specifying representations or internal procedures beyond training. Success: high test accuracy on localization tasks. Implementational level: regard physical realization as optional since behavior is already matched. Success: none required.\n\nE. Computational level: specify microcircuit parameters and dynamics that transform $X$ to $Y$ and argue why the chosen dynamics are optimal. Success: parameters match published values. Algorithmic level: justify that the result of computation is the most rational $Y$ for given $X$. Success: a proof of optimality is provided. Implementational level: show correlational neural recordings during the task. Success: statistical correlation with cues is strong.",
            "solution": "Option A provides the correct and complete characterization of the three levels for the sound localization problem.\n\n*   **Computational Level:** Option A correctly defines the goal as mapping cues ($X$) to azimuth ($Y$) and specifies the success criterion as matching psychophysical data, which aligns with Marr's definition of understanding the 'what' and 'why' of the problem.\n*   **Algorithmic Level:** It correctly focuses on the representations (e.g., binaural features) and the specific procedure (e.g., cross-correlation) used to compute the mapping, aligning with the 'how'.\n*   **Implementational Level:** It correctly identifies the physical substrate (e.g., MSO and LSO circuits) and sets the high standard of causal evidence for success, aligning with the 'with what'.\n\nThe other options are incorrect because they misassign concepts to the levels:\n*   Option B places implementational details (neuron types) at the computational level.\n*   Option C places implementational details (physiology) at the computational level and computational theory (normative estimator) at the implementational level.\n*   Option D dismisses the implementational level, which violates the core principle of a complete tri-level explanation, and advocates for a \"black box\" algorithm.\n*   Option E places implementational details (microcircuit parameters) at the computational level.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "Neuroscience experiments often produce results that require careful interpretation, and Marr's levels provide a powerful lens for this analysis. This problem presents a scenario where lesioning a brain circuit has no effect on behavior, a common finding that challenges simple notions of localization of function . Your task is to reason about what this null result does—and does not—tell us, sharpening your ability to separate implementational evidence from computational claims and introducing the critical concept of degeneracy.",
            "id": "3995619",
            "problem": "In a lesion experiment within brain modeling and computational neuroscience, a focal inhibitory intervention is applied to a well-characterized cortico-striatal circuit $C$ during a decision-making task. The intervention reduces circuit-specific activity measures but leaves measured task performance unchanged. Let the following quantities be defined: the computational goal $G$ (what is computed in the abstract, e.g., a function $F$ mapping sensory inputs $S$ to optimal actions $R$), the algorithm $A$ (the representational scheme and stepwise procedure realizing $G$), and the implementation $I$ (the physical substrate and its dynamics). Let $B$ denote a scalar behavioral performance metric (e.g., accuracy) that is a function of $S$ and the internal states and outputs of $A$ and $I$. The intervention is modeled by a binary variable $L \\in \\{0,1\\}$ with $L=1$ indicating the lesion condition. Let $M$ denote a circuit-specific physiological measure (e.g., local field potential coherence or spike rate) derived from circuit $C$. Consider the following structural causal dependencies: the abstract goal $G$ constrains the set of algorithms $A$, which constrain possible implementations $I$; implementation $I$ produces behavior $B$ under inputs $S$; the lesion $L$ directly perturbs $I$ and hence $M$, and may or may not affect $B$ depending on compensatory pathways. Assume the observed data satisfy $p(M \\mid L=1) \\neq p(M \\mid L=0)$ and $p(B \\mid L=1) \\approx p(B \\mid L=0)$ for the tested task family. Let $H_C$ denote a computational-level hypothesis stating a particular function $F$ that the system computes across tasks, and let $H_I^{\\text{nec}}$ denote an implementational-level hypothesis stating that circuit $C$ is necessary for producing $B$ in these tasks, while $H_I^{\\text{deg}}$ denotes an implementational-level hypothesis stating that $C$ is one of multiple redundant substrates (degeneracy) capable of supporting $B$. Using the core definitions of David Marr’s levels of analysis and the basic rules of Bayesian evidence (likelihoods and Bayes factors), reason from first principles about what the data do and do not support. Which option(s) correctly specify what counts as computational-level evidence versus implementational-level evidence in this lesion study?\n\nA. Because $p(B \\mid L=1) \\approx p(B \\mid L=0)$, the data provide positive evidence for $H_C$; unchanged $B$ implies that the computational goal $G$ is preserved and thus supports the specific computational theory $H_C$ over alternatives.\n\nB. Because $p(M \\mid L=1) \\neq p(M \\mid L=0)$ while $p(B \\mid L=1) \\approx p(B \\mid L=0)$, the data provide implementational-level evidence consistent with $H_I^{\\text{deg}}$ (redundant realization), and they do not, by themselves, adjudicate among competing computational-level hypotheses $H_C$.\n\nC. Because $B$ is unchanged, the data falsify any claim that circuit $C$ contributes to the computation at any level; they are evidence against both $H_I^{\\text{nec}}$ and $H_C$.\n\nD. The data provide little to no Bayesian evidence for $H_C$ (the likelihood of $B$ under $L=1$ is approximately equal under different computational theories) but do provide evidence against $H_I^{\\text{nec}}$ (necessity) and in favor of $H_I^{\\text{deg}}$ (degeneracy), hence they should be interpreted primarily at the implementational level.\n\nE. To obtain computational-level evidence, one would need task manipulations that selectively engage the hypothesized function $F$: if for tasks $T_F$ that require $F$ one observes $p(B \\mid L=1, T_F) \\ll p(B \\mid L=0, T_F)$ while for control tasks $T_0$ one has $p(B \\mid L=1, T_0) \\approx p(B \\mid L=0, T_0)$, then the data would support $H_C$; in the present study, unchanged $B$ does not provide such evidence.",
            "solution": "The experimental observation is that a targeted lesion to circuit $C$ affects its physiological state ($p(M \\mid L=1) \\neq p(M \\mid L=0)$) but does not impair overall task performance ($p(B \\mid L=1) \\approx p(B \\mid L=0)$). This set of findings has distinct implications for hypotheses at the implementational and computational levels.\n\n*   **At the Implementational Level:** The fact that behavior is preserved despite a successful lesion provides strong evidence *against* the hypothesis that circuit $C$ is necessary ($H_I^{\\text{nec}}$). Instead, it supports the hypothesis of degeneracy or redundancy ($H_I^{\\text{deg}}$), where the system has multiple or compensatory pathways to achieve the same behavioral output. Therefore, the data are highly informative about the physical implementation. Options B and D correctly identify this. Option D provides a more formal Bayesian interpretation, stating that the evidence favors $H_I^{\\text{deg}}$ over $H_I^{\\text{nec}}$.\n\n*   **At the Computational Level:** The experiment does *not* provide evidence to adjudicate between different computational-level hypotheses (e.g., what function $F$ the brain is computing). The system, as a whole, continues to perform the task successfully. The experiment manipulates the implementation, not the computational problem itself. Therefore, the data are silent on the validity of any specific computational theory $H_C$. Option B correctly states this.\n\n*   **How to Obtain Computational-Level Evidence:** To test a computational hypothesis $H_C$, one must manipulate the task in a way that specifically taxes the proposed computation $F$. Option E correctly describes such an experiment: showing that the lesion impairs performance *only* on tasks requiring $F$ ($T_F$) but not on control tasks ($T_0$). Since the current study did not do this, it does not provide computational-level evidence for or against $H_C$.\n\nBased on this analysis, options B, D, and E all make correct statements about the nature and interpretation of evidence in this context.\n*   **B** correctly separates the implementational evidence (for degeneracy) from the lack of computational evidence.\n*   **D** correctly frames the implementational evidence in Bayesian terms (evidence against necessity, for degeneracy) and notes the lack of computational evidence.\n*   **E** correctly explains *why* the evidence is not computational by contrasting the experiment with one that would provide such evidence.\n\nTherefore, all three options (B, D, E) are correct.",
            "answer": "$$\\boxed{BDE}$$"
        },
        {
            "introduction": "Often, a simple heuristic algorithm can produce behavior that perfectly mimics an optimal, computationally intensive strategy. This practice provides hands-on experience with this phenomenon of \"model mimicry\" by asking you to derive the exact conditions under which a simple thresholding rule becomes indistinguishable from a full Bayesian model . The exercise culminates in the essential skill of a computational neuroscientist: proposing new experiments that can break this equivalence and reveal the brain's true strategy.",
            "id": "3995657",
            "problem": "Consider a binary perceptual categorization task in which the latent category variable $C \\in \\{-1,+1\\}$ and the scalar stimulus $s \\in \\mathbb{R}$ are related by a generative process at the level of the environment. The generative model is specified by the following well-tested facts: the conditional stimulus distributions are Gaussian with equal variance, $p(s \\mid C=+1) = \\mathcal{N}(\\mu,\\sigma^{2})$ and $p(s \\mid C=-1) = \\mathcal{N}(-\\mu,\\sigma^{2})$, where $\\mu > 0$ and $\\sigma > 0$. The prior over categories is $p(C=+1) = \\pi$ and $p(C=-1) = 1-\\pi$, with $\\pi \\in (0,1)$.\n\nAt the computational level (in the sense of Marr's levels of analysis), the observer aims to maximize expected accuracy under this generative model by using Bayes' rule. To capture bounded rationality, suppose that the observer’s choice probability is a soft decision obtained by applying a logistic transform with inverse temperature $\\beta_{B} > 0$ to the log posterior odds, yielding a choice probability $P_{B}(+1 \\mid s)$ that is a function of $s$.\n\nAt the algorithmic level (in Marr's sense), consider a heuristic decision algorithm that compares the stimulus to a threshold $T \\in \\mathbb{R}$ after additive internal noise: the internal decision variable is $d(s) = s - T + \\varepsilon$, where $\\varepsilon$ is a random variable with a logistic distribution of scale parameter $b > 0$ (so that the cumulative distribution function of $\\varepsilon$ is $F(\\varepsilon) = 1/(1+\\exp(-\\varepsilon/b))$). This yields a choice probability $P_{H}(+1 \\mid s)$ that is a logistic function of $s$.\n\nYour tasks are:\n- Starting from the core definitions of Bayes’ rule and the Gaussian generative model, derive conditions on $(\\mu,\\sigma,\\pi,\\beta_{B},b,T)$ under which the computational-level Bayesian observer and the algorithmic-level heuristic yield indistinguishable behavior, in the sense that $P_{B}(+1 \\mid s) = P_{H}(+1 \\mid s)$ for all $s \\in \\mathbb{R}$.\n- Using the structure of the derived equivalence, propose scientifically plausible experiments that would separate computational-level from algorithmic-level explanations. Frame these experiments by manipulations that break the equivalence (for example, changes in stimulus distribution structure, prior changes over time, or constraints on internal noise), and define an analytic identifiability metric (for example, an integral over stimulus space of a divergence between $P_{B}(+1 \\mid s)$ and $P_{H}(+1 \\mid s)$). You do not need to compute numerical values; provide symbolic expressions and principled reasoning for why the experiments isolate the levels.\n- Provide, as your final answer, the closed-form expression for the heuristic threshold $T$ in terms of $\\mu$, $\\sigma$, $\\pi$, and $\\beta_{B}$ that guarantees indistinguishable behavior across all $s$ when the heuristic noise scale $b$ is chosen to satisfy the derived equivalence conditions.\n\nNo numerical rounding is required. The final answer must be a single analytic expression without units.",
            "solution": "We begin from the computational-level objective under Bayes’ rule. The posterior odds of $C=+1$ versus $C=-1$ given $s$ are\n$$\n\\frac{p(C=+1 \\mid s)}{p(C=-1 \\mid s)} \\;=\\; \\frac{p(s \\mid C=+1)\\,p(C=+1)}{p(s \\mid C=-1)\\,p(C=-1)} \\;=\\; \\frac{\\mathcal{N}(s;\\mu,\\sigma^{2})\\,\\pi}{\\mathcal{N}(s;-\\mu,\\sigma^{2})\\,(1-\\pi)}.\n$$\nTaking the natural logarithm yields the log posterior odds\n$$\n\\Lambda(s) \\;=\\; \\ln\\!\\left(\\frac{p(C=+1 \\mid s)}{p(C=-1 \\mid s)}\\right) \\;=\\; \\ln\\!\\left(\\frac{p(s \\mid C=+1)}{p(s \\mid C=-1)}\\right) \\;+\\; \\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right).\n$$\nFor equal-variance Gaussians with means at $\\pm\\mu$, the log-likelihood ratio is linear in $s$. Specifically,\n\\begin{align*}\n\\ln\\!\\left(\\frac{p(s \\mid C=+1)}{p(s \\mid C=-1)}\\right)\n&= -\\frac{(s-\\mu)^{2}}{2\\sigma^{2}} + \\frac{(s+\\mu)^{2}}{2\\sigma^{2}} \\\\\n&= -\\frac{s^{2} - 2\\mu s + \\mu^{2}}{2\\sigma^{2}} + \\frac{s^{2} + 2\\mu s + \\mu^{2}}{2\\sigma^{2}} \\\\\n&= \\frac{4\\mu s}{2\\sigma^{2}} \\\\\n&= \\frac{2\\mu}{\\sigma^{2}}\\,s.\n\\end{align*}\nTherefore,\n$$\n\\Lambda(s) \\;=\\; \\frac{2\\mu}{\\sigma^{2}}\\,s \\;+\\; \\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right).\n$$\nTo model bounded rationality, assume a soft decision rule in which the choice probability is a logistic function of the log posterior odds scaled by an inverse temperature $\\beta_{B}$. This yields\n$$\nP_{B}(+1 \\mid s) \\;=\\; \\frac{1}{1 + \\exp\\!\\Big(-\\beta_{B}\\,\\Lambda(s)\\Big)} \\;=\\; \\frac{1}{1 + \\exp\\!\\left(-\\beta_{B}\\left(\\frac{2\\mu}{\\sigma^{2}}\\,s + \\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right)\\right)\\right)}.\n$$\nThus, at the computational level under these assumptions, $P_{B}(+1 \\mid s)$ is a logistic function in $s$ with slope parameter $\\beta_{B}\\,\\frac{2\\mu}{\\sigma^{2}}$ and offset $\\beta_{B}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right)$.\n\nAt the algorithmic level, consider the heuristic decision variable $d(s) = s - T + \\varepsilon$, where $\\varepsilon$ has a logistic distribution with scale $b > 0$. The observer chooses $+1$ if $d(s) > 0$. The probability of choosing $+1$ is \n\\begin{align*}\nP_{H}(+1 \\mid s) &= \\Pr\\big[\\,s - T + \\varepsilon > 0 \\,\\big] \\\\\n&= \\Pr\\big[\\,\\varepsilon > T - s \\,\\big] \\\\\n&= 1 - F(T - s),\n\\end{align*}\nwhere $F$ is the cumulative distribution function of the logistic distribution with scale $b$, $F(x) = \\frac{1}{1 + \\exp(-x/b)}$. Therefore,\n\\begin{align*}\nP_{H}(+1 \\mid s) &= 1 - \\frac{1}{1 + \\exp\\!\\left(-(T - s)/b\\right)} \\\\\n&= \\frac{\\exp\\!\\left(-(T - s)/b\\right)}{1 + \\exp\\!\\left(-(T - s)/b\\right)} \\\\\n&= \\frac{1}{1 + \\exp\\!\\left((T - s)/b\\right)} \\\\\n&= \\frac{1}{1 + \\exp\\!\\left(-\\frac{s}{b} + \\frac{T}{b}\\right)}.\n\\end{align*}\nHence, the heuristic algorithm’s choice probability is logistic in $s$ with slope parameter $\\frac{1}{b}$ and offset $\\frac{T}{b}$ (note the sign conventions).\n\nIndistinguishability across all stimuli $s \\in \\mathbb{R}$ requires that $P_{B}(+1 \\mid s) = P_{H}(+1 \\mid s)$ for all $s$. Since both are logistic functions of $s$, equality for all $s$ demands that the slope and offset parameters match exactly. Comparing\n$$\nP_{B}(+1 \\mid s) \\;=\\; \\frac{1}{1 + \\exp\\!\\left(-\\beta_{B}\\,\\frac{2\\mu}{\\sigma^{2}}\\,s \\;-\\; \\beta_{B}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right)\\right)}\n$$\nwith\n$$\nP_{H}(+1 \\mid s) \\;=\\; \\frac{1}{1 + \\exp\\!\\left(-\\frac{s}{b} \\;+\\; \\frac{T}{b}\\right)},\n$$\nwe must have\n\\begin{align*}\n\\text{slope match:}\\quad & \\frac{1}{b} \\;=\\; \\beta_{B}\\,\\frac{2\\mu}{\\sigma^{2}}, \\\\\n\\text{offset match:}\\quad & \\frac{T}{b} \\;=\\; -\\,\\beta_{B}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right).\n\\end{align*}\nThese two equalities are the conditions under which the computational-level Bayesian and the algorithmic-level heuristic yield indistinguishable behavior across all $s$.\n\nSolving the slope match for $b$ gives\n$$\nb \\;=\\; \\frac{\\sigma^{2}}{2\\mu\\,\\beta_{B}}.\n$$\nSubstituting this into the offset match yields\n\\begin{align*}\n\\frac{T}{b} &= -\\,\\beta_{B}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right), \\\\\nT &= -\\,b\\,\\beta_{B}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right) \\\\\n&= -\\,\\frac{\\sigma^{2}}{2\\mu}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right).\n\\end{align*}\nThus, the heuristic threshold required for indistinguishability is determined entirely by the generative model’s prior odds and stimulus distribution parameters, independent of the inverse temperature $\\beta_{B}$ once $b$ is chosen to match slopes.\n\nWe next propose experiments to separate computational-level from algorithmic-level explanations. The above equivalence hinges on the linearity of the log posterior odds in $s$ and the logistic internal noise assumption. Breaking either feature can separate explanations.\n\nExperiment $1$: Unequal-variance categories. Manipulate the stimulus statistics so that $p(s \\mid C=+1) = \\mathcal{N}(\\mu_{+},\\sigma_{+}^{2})$ and $p(s \\mid C=-1) = \\mathcal{N}(\\mu_{-},\\sigma_{-}^{2})$ with $\\sigma_{+}^{2} \\neq \\sigma_{-}^{2}$. Under Bayes’ rule, the log posterior odds becomes quadratic in $s$:\n$$\n\\Lambda_{\\text{uv}}(s) \\;=\\; \\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right) \\;+\\; \\ln\\!\\left(\\frac{\\sigma_{-}}{\\sigma_{+}}\\right) \\;-\\; \\frac{(s-\\mu_{+})^{2}}{2\\sigma_{+}^{2}} \\;+\\; \\frac{(s-\\mu_{-})^{2}}{2\\sigma_{-}^{2}},\n$$\nwhich cannot be represented exactly by a logistic with a linear argument in $s$ for all $s$. A threshold-plus-logistic-noise heuristic produces a linear logistic psychometric $P_{H}(+1 \\mid s)$ and will fail to match the Bayesian $P_{B}(+1 \\mid s)$ for all $s$. An identifiability metric can be the Kullback–Leibler divergence between the induced choice distributions over $s$ under a stimulus ensemble $q(s)$,\n$$\nD_{\\text{KL}} \\;=\\; \\int q(s)\\,\\ln\\!\\left(\\frac{P_{B}(+1 \\mid s)}{P_{H}(+1 \\mid s)}\\right)\\,\\mathrm{d}s,\n$$\nwhich will be strictly positive if $P_{B}(+1 \\mid s) \\neq P_{H}(+1 \\mid s)$ on a set of positive measure. Observing nonzero divergence when variances are unequal supports a computational-level explanation that utilizes the generative model structure.\n\nExperiment $2$: Noise distribution perturbation. Impose manipulations (for example, time pressure or dual-task interference) known to alter internal noise characteristics and test whether the psychometric is better fit by a probit (Gaussian noise) or logistic (logistic noise). If the heuristic relies on logistic noise with scale $b$, replacing it with Gaussian noise of standard deviation $\\sigma_{h}$ yields a probit psychometric\n$$\nP_{H}^{\\text{probit}}(+1 \\mid s) \\;=\\; \\Phi\\!\\left(\\frac{s-T}{\\sigma_{h}}\\right),\n$$\nwhere $\\Phi$ is the standard normal cumulative distribution function. The computational-level Bayesian soft decision remains logistic in the equal-variance case. A divergence metric such as the Jensen–Shannon divergence (the square root of which is a metric) between $P_{B}$ and $P_{H}^{\\text{probit}}$,\n$$\nD_{\\text{JS}} \\;=\\; \\frac{1}{2}\\,\\int q(s)\\,\\left[ P_{B}(+1 \\mid s) \\ln\\!\\left(\\frac{2\\,P_{B}(+1 \\mid s)}{P_{B}(+1 \\mid s) + P_{H}^{\\text{probit}}(+1 \\mid s)}\\right) + P_{H}^{\\text{probit}}(+1 \\mid s) \\ln\\!\\left(\\frac{2\\,P_{H}^{\\text{probit}}(+1 \\mid s)}{P_{B}(+1 \\mid s) + P_{H}^{\\text{probit}}(+1 \\mid s)}\\right) \\right]\\,\\mathrm{d}s,\n$$\nwill generally be nonzero, revealing that the algorithmic noise assumption, not the computational objective, explains the observed psychometric shape.\n\nExperiment $3$: Prior-cue manipulation with dynamic adaptation. Vary $\\pi$ across blocks using explicit cues and analyze how the psychometric offset changes over time. The computational-level model predicts a shift proportional to $\\ln(\\pi/(1-\\pi))$ in $\\Lambda(s)$, producing a logistic offset $\\beta_{B}\\,\\ln(\\pi/(1-\\pi))$ if $\\beta_{B}$ is fixed. The heuristic threshold that matches this is $T = -(\\sigma^{2}/(2\\mu))\\,\\ln(\\pi/(1-\\pi))$. If the organism’s adaptation is sluggish or context-dependent, the threshold inferred from behavior may lag behind the computational prescription. Measure the lag as an $L^{2}$ discrepancy over trial index $t$,\n$$\n\\Delta \\;=\\; \\sum_{t=1}^{T_{\\text{tot}}} \\left[P_{\\text{obs}}(+1 \\mid s_{t}) - \\frac{1}{1 + \\exp\\!\\left(-\\beta_{B}\\left(\\frac{2\\mu}{\\sigma^{2}}\\,s_{t} + \\ln\\!\\left(\\frac{\\pi_{t}}{1-\\pi_{t}}\\right)\\right)\\right)}\\right]^{2},\n$$\nwhere $P_{\\text{obs}}$ is the observed choice probability estimated from sequences. Systematic lag or context dependence supports an algorithmic-level explanation involving threshold dynamics rather than purely computational-level optimality.\n\nIn all cases, the key strategy is to manipulate the environment or internal constraints to induce regime changes that break the linear logistic equivalence. Under the original equal-variance conditions, the equivalence requires matching both slope and offset. Solving those matching conditions yields the heuristic threshold\n$$\nT \\;=\\; -\\,\\frac{\\sigma^{2}}{2\\mu}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right),\n$$\nwith the heuristic noise scale set to $b = \\frac{\\sigma^{2}}{2\\mu\\,\\beta_{B}}$. The requested final answer is the expression for $T$.",
            "answer": "$$\\boxed{-\\frac{\\sigma^{2}}{2\\mu}\\,\\ln\\!\\left(\\frac{\\pi}{1-\\pi}\\right)}$$"
        }
    ]
}