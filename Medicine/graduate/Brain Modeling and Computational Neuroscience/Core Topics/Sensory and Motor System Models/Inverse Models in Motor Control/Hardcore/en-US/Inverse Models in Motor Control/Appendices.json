{
    "hands_on_practices": [
        {
            "introduction": "At its core, learning an inverse model is a process of iterative refinement, where the brain adjusts motor commands to reduce performance errors. This practice delves into the mathematical engine driving this process: gradient-based learning. By deriving how a small change in a motor command propagates through a nonlinear system to affect the final task error, we can understand how the nervous system might systematically update its commands to improve accuracy. This exercise provides foundational skills in applying the chain rule and linearization to analyze and build learning rules for complex motor tasks .",
            "id": "3992041",
            "problem": "Consider a brain-inspired inverse model for motor control that selects a command vector $u \\in \\mathbb{R}^{3}$ to achieve a desired task output $y^{\\star} \\in \\mathbb{R}^{2}$ through a nonlinear plant $x = f(u) \\in \\mathbb{R}^{2}$ and a task mapping $y = h(x) \\in \\mathbb{R}^{2}$. The Central Nervous System (CNS) is hypothesized to learn an inverse model that maps $y^{\\star}$ to a command $u$ by reducing a scalar task error defined as $E(u) = \\frac{1}{2} \\|h(f(u)) - y^{\\star}\\|^{2}$. Assume small command variations are evaluated using the first-order linearization of the plant around a nominal command $u_{0}$, namely $x \\approx f(u_{0}) + J_{u}(u_{0})(u - u_{0})$, where $J_{u}(u_{0})$ is the Jacobian of $f$ with respect to $u$ at $u_{0}$. Starting from first principles (the chain rule and the definition of the gradient and directional derivative), derive the first-order sensitivity of the task error $E$ to small command changes, and explain how this local approximation supports gradient-based inverse-model updates.\n\nWork with the following scientifically plausible nonlinear mappings and parameters:\n- $f(u) = \\begin{pmatrix} \\tanh(u_{1}) + u_{2} u_{3} \\\\ u_{1}^{2} - \\cos(u_{2}) \\end{pmatrix}$,\n- $h(x) = \\begin{pmatrix} x_{1}^{2} + \\sin(x_{2}) \\\\ \\exp(x_{1}) + x_{2} \\end{pmatrix}$,\n- $u_{0} = \\begin{pmatrix} 0.3 \\\\ 0.2 \\\\ -0.5 \\end{pmatrix}$,\n- $y^{\\star} = \\begin{pmatrix} 0.2 \\\\ 0.4 \\end{pmatrix}$,\n- Direction of command change $\\Delta u = \\begin{pmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{pmatrix}$.\n\nUsing the linearization and the chain rule, compute the directional derivative of $E$ at $u_{0}$ along $\\Delta u$, that is, $\\left.\\frac{d}{d\\epsilon} E(u_{0} + \\epsilon \\Delta u)\\right|_{\\epsilon = 0}$, and round your numerical answer to four significant figures. Express the answer without any units.",
            "solution": "The problem statement is scientifically grounded, well-posed, and complete. It describes a standard problem in computational motor control, employing valid mathematical concepts such as nonlinear function composition, Jacobian matrices, the chain rule, and gradient-based optimization. All necessary functions, parameters, and initial conditions are provided, and there are no internal contradictions. Therefore, the problem is valid, and we may proceed with the solution.\n\nThe core of the problem is to determine the first-order sensitivity of the task error, $E$, to a small change in the command vector, $u$. This sensitivity along a specific direction of change, $\\Delta u$, is given by the directional derivative.\n\nFirst, let us formalize the components.\nThe task error is a scalar function of the command vector $u$:\n$$E(u) = \\frac{1}{2} \\|h(f(u)) - y^{\\star}\\|^{2}$$\nLet the composite function representing the full forward model from command to task output be $y(u) = h(f(u))$. Let the error vector be $e(u) = y(u) - y^{\\star}$. The task error can then be written as:\n$$E(u) = \\frac{1}{2} e(u)^T e(u)$$\nWe are asked to find the directional derivative of $E$ at a nominal command $u_0$ in the direction of a command change $\\Delta u$. This is defined as:\n$$\\nabla_{\\Delta u} E(u_0) = \\left.\\frac{d}{d\\epsilon} E(u_0 + \\epsilon \\Delta u)\\right|_{\\epsilon = 0}$$\nBy the properties of directional derivatives, this is equivalent to the dot product of the gradient of $E$ at $u_0$ and the direction vector $\\Delta u$:\n$$\\nabla_{\\Delta u} E(u_0) = \\nabla E(u_0)^T \\Delta u$$\nOur first step is to derive the gradient of the error function, $\\nabla E(u)$. We use the chain rule for multivariable functions. The differential of $E$ is:\n$$dE = \\frac{\\partial E}{\\partial e} de = e(u)^T de$$\nThe differential of the error vector $e(u)$ is $de = dy$, since $y^{\\star}$ is a constant vector.\nThe differential of the task output $y(u) = h(f(u))$ is found by applying the chain rule twice. Let $x = f(u)$.\nFirst, $dy = J_h(x) dx$, where $J_h(x)$ is the Jacobian of $h$ with respect to $x$.\nSecond, $dx = J_f(u) du$, where $J_f(u)$ is the Jacobian of $f$ with respect to $u$.\nSubstituting these back, we get:\n$$dy = J_h(f(u)) J_f(u) du$$\nLet $J_y(u) = J_h(f(u)) J_f(u)$ be the Jacobian of the complete forward model $y(u)$.\nThen, $dE = e(u)^T J_y(u) du$.\nThe definition of the gradient $\\nabla E(u)$ is that $dE = \\nabla E(u)^T du$. By comparing the two expressions for $dE$, we identify:\n$$\\nabla E(u)^T = e(u)^T J_y(u) = e(u)^T J_h(f(u)) J_f(u)$$\nTaking the transpose gives the gradient vector:\n$$\\nabla E(u) = J_f(u)^T J_h(f(u))^T e(u)$$\nThis gradient vector $\\nabla E(u)$ points in the direction of the steepest ascent of the task error $E$. For gradient-based learning, the CNS would update the motor command in the opposite direction, $u_{k+1} = u_k - \\eta \\nabla E(u_k)$, where $\\eta$ is a small positive learning rate. This process iteratively adjusts the command to minimize the task error, thereby learning the inverse model that maps a desired output $y^{\\star}$ to the required command $u$.\n\nThe directional derivative is then:\n$$\\nabla_{\\Delta u} E(u_0) = \\nabla E(u_0)^T \\Delta u = e(u_0)^T J_h(x_0) J_f(u_0) \\Delta u$$\nwhere $x_0 = f(u_0)$. We now proceed with the numerical computation.\n\nThe given values are:\n$u_0 = \\begin{pmatrix} 0.3 \\\\ 0.2 \\\\ -0.5 \\end{pmatrix}$, $y^{\\star} = \\begin{pmatrix} 0.2 \\\\ 0.4 \\end{pmatrix}$, $\\Delta u = \\begin{pmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{pmatrix}$.\n\nStep 1: Compute $x_0 = f(u_0)$.\n$f(u) = \\begin{pmatrix} \\tanh(u_{1}) + u_{2} u_{3} \\\\ u_{1}^{2} - \\cos(u_{2}) \\end{pmatrix}$\n$x_0 = f(u_0) = \\begin{pmatrix} \\tanh(0.3) + (0.2)(-0.5) \\\\ (0.3)^{2} - \\cos(0.2) \\end{pmatrix} = \\begin{pmatrix} \\tanh(0.3) - 0.1 \\\\ 0.09 - \\cos(0.2) \\end{pmatrix}$\nUsing numerical values, $\\tanh(0.3) \\approx 0.29131$ and $\\cos(0.2) \\approx 0.98007$.\n$x_0 \\approx \\begin{pmatrix} 0.29131 - 0.1 \\\\ 0.09 - 0.98007 \\end{pmatrix} = \\begin{pmatrix} 0.19131 \\\\ -0.89007 \\end{pmatrix}$. Let's name components $x_{0,1}$ and $x_{0,2}$.\n\nStep 2: Compute the Jacobians $J_f(u_0)$ and $J_h(x_0)$.\n$J_f(u) = \\begin{pmatrix} \\frac{\\partial f_1}{\\partial u_1} & \\frac{\\partial f_1}{\\partial u_2} & \\frac{\\partial f_1}{\\partial u_3} \\\\ \\frac{\\partial f_2}{\\partial u_1} & \\frac{\\partial f_2}{\\partial u_2} & \\frac{\\partial f_2}{\\partial u_3} \\end{pmatrix} = \\begin{pmatrix} 1-\\tanh^2(u_1) & u_3 & u_2 \\\\ 2u_1 & \\sin(u_2) & 0 \\end{pmatrix}$\nAt $u_0$:\n$J_f(u_0) = \\begin{pmatrix} 1-\\tanh^2(0.3) & -0.5 & 0.2 \\\\ 2(0.3) & \\sin(0.2) & 0 \\end{pmatrix} \\approx \\begin{pmatrix} 1-(0.29131)^2 & -0.5 & 0.2 \\\\ 0.6 & 0.19867 & 0 \\end{pmatrix} = \\begin{pmatrix} 0.91515 & -0.5 & 0.2 \\\\ 0.6 & 0.19867 & 0 \\end{pmatrix}$.\n\n$h(x) = \\begin{pmatrix} x_{1}^{2} + \\sin(x_{2}) \\\\ \\exp(x_{1}) + x_{2} \\end{pmatrix}$\n$J_h(x) = \\begin{pmatrix} \\frac{\\partial h_1}{\\partial x_1} & \\frac{\\partial h_1}{\\partial x_2} \\\\ \\frac{\\partial h_2}{\\partial x_1} & \\frac{\\partial h_2}{\\partial x_2} \\end{pmatrix} = \\begin{pmatrix} 2x_1 & \\cos(x_2) \\\\ \\exp(x_1) & 1 \\end{pmatrix}$\nAt $x_0$:\n$J_h(x_0) = \\begin{pmatrix} 2x_{0,1} & \\cos(x_{0,2}) \\\\ \\exp(x_{0,1}) & 1 \\end{pmatrix} \\approx \\begin{pmatrix} 2(0.19131) & \\cos(-0.89007) \\\\ \\exp(0.19131) & 1 \\end{pmatrix} = \\begin{pmatrix} 0.38262 & \\cos(0.89007) \\\\ 1.21085 & 1 \\end{pmatrix} \\approx \\begin{pmatrix} 0.38262 & 0.62933 \\\\ 1.21085 & 1 \\end{pmatrix}$.\n\nStep 3: Compute the error vector $e(u_0) = h(f(u_0)) - y^{\\star} = h(x_0) - y^{\\star}$.\n$y_0 = h(x_0) \\approx \\begin{pmatrix} (0.19131)^2 + \\sin(-0.89007) \\\\ \\exp(0.19131) + (-0.89007) \\end{pmatrix} = \\begin{pmatrix} 0.03660 - 0.77712 \\\\ 1.21085 - 0.89007 \\end{pmatrix} = \\begin{pmatrix} -0.74052 \\\\ 0.32078 \\end{pmatrix}$.\n$e(u_0) = y_0 - y^{\\star} \\approx \\begin{pmatrix} -0.74052 - 0.2 \\\\ 0.32078 - 0.4 \\end{pmatrix} = \\begin{pmatrix} -0.94052 \\\\ -0.07922 \\end{pmatrix}$.\n\nStep 4: Compute the full product $e(u_0)^T J_h(x_0) J_f(u_0) \\Delta u$.\nWe first compute the vector $v = J_f(u_0) \\Delta u$:\n$v \\approx \\begin{pmatrix} 0.91515 & -0.5 & 0.2 \\\\ 0.6 & 0.19867 & 0 \\end{pmatrix} \\begin{pmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{pmatrix} = \\begin{pmatrix} (0.91515)(0.1) + (-0.5)(-0.2) + (0.2)(0.05) \\\\ (0.6)(0.1) + (0.19867)(-0.2) + (0)(0.05) \\end{pmatrix} = \\begin{pmatrix} 0.091515 + 0.1 + 0.01 \\\\ 0.06 - 0.039734 + 0 \\end{pmatrix} = \\begin{pmatrix} 0.201515 \\\\ 0.020266 \\end{pmatrix}$.\n\nNext, we compute the row vector $w^T = e(u_0)^T J_h(x_0)$:\n$w^T \\approx \\begin{pmatrix} -0.94052 & -0.07922 \\end{pmatrix} \\begin{pmatrix} 0.38262 & 0.62933 \\\\ 1.21085 & 1 \\end{pmatrix}$\n$w^T = \\begin{pmatrix} (-0.94052)(0.38262) + (-0.07922)(1.21085) & (-0.94052)(0.62933) + (-0.07922)(1) \\end{pmatrix}$\n$w^T = \\begin{pmatrix} -0.35987 - 0.09592 & -0.59190 - 0.07922 \\end{pmatrix} = \\begin{pmatrix} -0.45579 & -0.67112 \\end{pmatrix}$.\n\nFinally, the directional derivative is $w^T v$:\n$\\nabla_{\\Delta u} E(u_0) \\approx \\begin{pmatrix} -0.45579 & -0.67112 \\end{pmatrix} \\begin{pmatrix} 0.201515 \\\\ 0.020266 \\end{pmatrix}$\n$= (-0.45579)(0.201515) + (-0.67112)(0.020266)$\n$= -0.091849 - 0.013601 = -0.10545$.\n\nUsing higher precision for all intermediate steps:\n$x_0 = \\begin{pmatrix} 0.19131260 \\\\ -0.89006658 \\end{pmatrix}$\n$e(u_0) = \\begin{pmatrix} -0.94051586 \\\\ -0.07921628 \\end{pmatrix}$\n$J_f(u_0) = \\begin{pmatrix} 0.9151523 & -0.5 & 0.2 \\\\ 0.6 & 0.19866933 & 0 \\end{pmatrix}$\n$J_h(x_0) = \\begin{pmatrix} 0.3826252 & 0.6293315 \\\\ 1.2108503 & 1 \\end{pmatrix}$\n$J_y(u_0) = J_h(x_0) J_f(u_0) = \\begin{pmatrix} 0.7277589 & -0.0662836 & 0.07652504 \\\\ 1.7081498 & -0.4067558 & 0.24217006 \\end{pmatrix}$\n$J_y(u_0) \\Delta u = \\begin{pmatrix} 0.08985895 \\\\ 0.2642747 \\end{pmatrix}$\n$e(u_0)^T (J_y(u_0) \\Delta u) = (-0.94051586)(0.08985895) + (-0.07921628)(0.2642747) = -0.08451336 - 0.02093498 = -0.10544834$.\n\nRounding to four significant figures, the result is $-0.1054$.\nThe negative value indicates that moving the command vector from $u_0$ in the direction of $\\Delta u$ results in a decrease in the task error $E$. This is a desirable change from the perspective of learning.",
            "answer": "$$\\boxed{-0.1054}$$"
        },
        {
            "introduction": "A key test for any theory of motor control is its ability to explain classic experimental phenomena. This practice applies the concept of an inverse model to visuomotor rotation, a paradigm that powerfully reveals how the brain adapts to novel sensory-motor relationships. By modeling the internal compensation learned during adaptation, you will predict the magnitude of the resulting \"aftereffects\" that occur when the perturbation is unexpectedly removed, demonstrating how a simple computational model can quantitatively account for complex adaptive behaviors .",
            "id": "3992055",
            "problem": "A participant adapts to a constant visuomotor rotation of $30^{\\circ}$ in a two-dimensional planar reaching task. The plant mapping from motor commands $\\mathbf{u} \\in \\mathbb{R}^{2}$ to hand kinematics is assumed to be the identity, and the displayed cursor is rotated relative to the hand by the rotation matrix $R(\\theta)$, so the observed cursor motion is $\\mathbf{y} = R(\\theta)\\,\\mathbf{u}$. An inverse model in motor control is assumed to compute motor commands from desired cursor states $\\mathbf{x}_{d}$ using an internal parameter estimate $\\hat{\\theta}$ of the external rotation. After adaptation to the constant perturbation $\\theta = 30^{\\circ}$, the internal estimate is modeled as $\\hat{\\theta} = \\phi\\,\\theta$, where $\\phi \\in [0,1]$ is a learned parameter that encodes the fraction of the perturbation compensated by the inverse model.\n\nAt test, the rotation is removed, so the environment presents no perturbation, and the actual mapping becomes $\\mathbf{y} = R(0)\\,\\mathbf{u}$. Assume the inverse model continues to use the learned estimate $\\hat{\\theta}$ when computing $\\mathbf{u}$ for a desired straight reach, so that $\\mathbf{u} = R(-\\hat{\\theta})\\,\\mathbf{x}_{d}$. Under these modeling assumptions, derive the angular aftereffect (the angular deviation between $\\mathbf{y}$ and $\\mathbf{x}_{d}$) as a function of $\\phi$ and $\\theta$ when the rotation is removed, and then evaluate it for $\\theta = 30^{\\circ}$. Express your final angular aftereffect in radians. The final answer must be a single closed-form analytic expression.",
            "solution": "The problem statement has been analyzed and validated against the specified criteria.\n\n**Step 1: Extract Givens**\n- Constant visuomotor rotation during adaptation: $\\theta = 30^{\\circ}$.\n- Task type: Two-dimensional planar reaching.\n- Motor commands: $\\mathbf{u} \\in \\mathbb{R}^{2}$.\n- Plant mapping (assumed): Identity.\n- Observed cursor motion during adaptation: $\\mathbf{y} = R(\\theta)\\,\\mathbf{u}$, where $R(\\theta)$ is the rotation matrix for angle $\\theta$.\n- Desired cursor state: $\\mathbf{x}_{d}$.\n- Inverse model computes $\\mathbf{u}$ from $\\mathbf{x}_{d}$ using an internal estimate $\\hat{\\theta}$.\n- Learned internal estimate after adaptation: $\\hat{\\theta} = \\phi\\,\\theta$, where $\\phi \\in [0,1]$ is the learned fraction of compensation.\n- At test, the external rotation is removed: The actual mapping is $\\mathbf{y} = R(0)\\,\\mathbf{u}$.\n- At test, the inverse model computes motor commands as $\\mathbf{u} = R(-\\hat{\\theta})\\,\\mathbf{x}_{d}$ for a desired straight reach.\n- The objective is to derive the angular aftereffect as a function of $\\phi$ and $\\theta$, evaluate it for the given $\\theta$, and express the result in radians.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is firmly rooted in computational neuroscience, specifically the study of motor control and adaptation. The concepts of visuomotor rotation, internal models (specifically an inverse model), adaptation, and aftereffects are standard and well-established in the field. The provided mathematical formalization is a common and valid simplification used in modeling these phenomena.\n- **Well-Posed:** The problem is self-contained and provides all necessary relationships to derive a unique solution. The connection between the desired state $\\mathbf{x}_{d}$ and the resulting state $\\mathbf{y}$ is explicitly defined through a chain of mathematical operations.\n- **Objective:** The problem is stated in precise, formal, and unbiased mathematical language. All terms are standard within the relevant scientific domain.\n\n**Step 3: Verdict and Action**\nThe problem is scientifically grounded, well-posed, objective, and internally consistent. It does not violate any of the invalidity criteria. Therefore, the problem is deemed **valid**. A solution will be derived below.\n\n**Derivation of the Solution**\nThe goal is to determine the angular aftereffect, which is the angular deviation of the actual cursor motion, $\\mathbf{y}$, from the desired cursor motion, $\\mathbf{x}_{d}$, during the test phase.\n\nAt test, the external visuomotor rotation is removed. The physical mapping from the motor command $\\mathbf{u}$ to the cursor motion $\\mathbf{y}$ is given by:\n$$\n\\mathbf{y} = R(0)\\,\\mathbf{u}\n$$\nThe rotation matrix for an angle of $0$, $R(0)$, is the $2 \\times 2$ identity matrix, $I$. Therefore, the mapping simplifies to:\n$$\n\\mathbf{y} = I\\,\\mathbf{u} = \\mathbf{u}\n$$\nThis means the final cursor motion is identical to the motor command generated by the central nervous system.\n\nThe problem states that the participant has adapted to a previous rotation $\\theta$. The internal inverse model has formed an estimate $\\hat{\\theta}$ of this rotation, given by:\n$$\n\\hat{\\theta} = \\phi\\,\\theta\n$$\nwhere $\\phi$ is the fraction of the perturbation that has been learned.\n\nDuring the test phase, the participant intends to make a straight reach to a desired target $\\mathbf{x}_{d}$. The inverse model, retaining its learned state, compensates for the *expected* rotation by generating a motor command $\\mathbf{u}$. This command is computed by applying the inverse of the learned rotation to the desired state vector:\n$$\n\\mathbf{u} = R(-\\hat{\\theta})\\,\\mathbf{x}_{d}\n$$\nSubstituting the expression for $\\hat{\\theta}$, we get:\n$$\n\\mathbf{u} = R(-\\phi\\,\\theta)\\,\\mathbf{x}_{d}\n$$\nSince we found that $\\mathbf{y} = \\mathbf{u}$ during the test phase, we can establish a direct relationship between the desired state $\\mathbf{x}_{d}$ and the actual resulting state $\\mathbf{y}$:\n$$\n\\mathbf{y} = R(-\\phi\\,\\theta)\\,\\mathbf{x}_{d}\n$$\nThis equation shows that the actual cursor vector $\\mathbf{y}$ is the result of rotating the desired cursor vector $\\mathbf{x}_{d}$ by an angle of $-\\phi\\,\\theta$. The angular aftereffect is defined as the angular deviation of $\\mathbf{y}$ relative to $\\mathbf{x}_{d}$. By the definition of rotation, this deviation is precisely the angle of the rotation transform.\n\nLet $\\alpha_{AE}$ denote the angular aftereffect. Then:\n$$\n\\alpha_{AE} = -\\phi\\,\\theta\n$$\nThis expression provides the aftereffect as a function of the learning parameter $\\phi$ and the original rotation angle $\\theta$. The negative sign indicates that the aftereffect is in the direction opposite to the original perturbation, which is a hallmark experimental observation.\n\nThe problem requires us to evaluate this expression for the given adaptation angle $\\theta = 30^{\\circ}$ and to express the result in radians. First, we convert $\\theta$ to radians:\n$$\n\\theta_{\\text{rad}} = 30^{\\circ} \\times \\frac{\\pi}{180^{\\circ}} = \\frac{\\pi}{6} \\text{ radians}\n$$\nSubstituting this value into our expression for the aftereffect yields:\n$$\n\\alpha_{AE} = -\\phi \\left(\\frac{\\pi}{6}\\right)\n$$\nThis is the final closed-form analytic expression for the angular aftereffect as a function of the learning parameter $\\phi$.",
            "answer": "$$\n\\boxed{-\\frac{\\phi \\pi}{6}}\n$$"
        },
        {
            "introduction": "While powerful, inverse models based on simple matrix inversion face significant challenges, especially when controlling multi-joint limbs that can adopt singular configurations. This practice explores the critical issue of kinematic singularities, where the mapping from joint velocities to end-effector velocities becomes ill-conditioned. By computing the Jacobian's condition number near an elbow-straight posture, you will develop a rigorous understanding of why such configurations compromise control stability and can lead to physiologically unrealistic motor commands .",
            "id": "3992093",
            "problem": "Consider a planar, two-degree-of-freedom arm with link lengths $l_1$ and $l_2$, shoulder joint angle $\\theta_1$, and elbow joint angle $\\theta_2$. The end-effector position is given by the forward kinematics $x(\\theta_1,\\theta_2) = l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2)$ and $y(\\theta_1,\\theta_2) = l_1 \\sin(\\theta_1) + l_2 \\sin(\\theta_1 + \\theta_2)$. The inverse model for task-space velocity control uses the Jacobian $J(\\theta_1,\\theta_2)$ mapping joint velocities $\\dot{\\theta} = (\\dot{\\theta}_1,\\dot{\\theta}_2)$ to end-effector velocities $\\dot{\\mathbf{r}} = (\\dot{x},\\dot{y})$ via $\\dot{\\mathbf{r}} = J \\dot{\\theta}$, and the pseudoinverse $J^+$ to solve $\\dot{\\theta} = J^+ \\dot{\\mathbf{r}}$. The numerical stability of this inverse mapping depends on the condition number $\\kappa(J)$, defined as the ratio of the largest to the smallest singular value of $J$.\n\nStarting strictly from the given forward kinematics and the standard definitions of Jacobian, singular values, and condition number, derive the Jacobian $J$, compute $J^{\\top}J$, and determine $\\kappa(J)$ near the elbow-straight configuration $\\theta_2 \\approx 0$. Using a leading-order asymptotic analysis in $|\\theta_2|$, obtain a closed-form expression for $\\kappa(J)$ that captures its divergence as $\\theta_2 \\to 0$, expressed in terms of $l_1$, $l_2$, and $\\theta_2$ only. Finally, explain based on this derivation how the behavior of $\\kappa(J)$ affects the numerical stability of inverse kinematics and inverse models for motor control near elbow-straight postures. The final answer must be a single analytic expression for the leading-order asymptotic of $\\kappa(J)$ in $|\\theta_2|$. No rounding is required, and no units are necessary.",
            "solution": "The problem is well-posed and scientifically grounded in the principles of robotic kinematics and linear algebra. We may proceed with the derivation.\n\nThe forward kinematics for the planar two-degree-of-freedom arm are given by the end-effector position coordinates $(x, y)$ as a function of the joint angles $(\\theta_1, \\theta_2)$:\n$$x(\\theta_1, \\theta_2) = l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2)$$\n$$y(\\theta_1, \\theta_2) = l_1 \\sin(\\theta_1) + l_2 \\sin(\\theta_1 + \\theta_2)$$\nwhere $l_1$ and $l_2$ are the lengths of the first and second links, respectively.\n\nFirst, we derive the Jacobian matrix $J$, which relates joint velocities $\\dot{\\theta} = (\\dot{\\theta}_1, \\dot{\\theta}_2)^{\\top}$ to end-effector velocities $\\dot{\\mathbf{r}} = (\\dot{x}, \\dot{y})^{\\top}$ via the equation $\\dot{\\mathbf{r}} = J \\dot{\\theta}$. The Jacobian is the matrix of partial derivatives of the position vector with respect to the joint angles:\n$$J = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\theta_1} & \\frac{\\partial x}{\\partial \\theta_2} \\\\ \\frac{\\partial y}{\\partial \\theta_1} & \\frac{\\partial y}{\\partial \\theta_2} \\end{pmatrix}$$\nCalculating the individual partial derivatives:\n$\\frac{\\partial x}{\\partial \\theta_1} = -l_1 \\sin(\\theta_1) - l_2 \\sin(\\theta_1 + \\theta_2)$\n$\\frac{\\partial x}{\\partial \\theta_2} = -l_2 \\sin(\\theta_1 + \\theta_2)$\n$\\frac{\\partial y}{\\partial \\theta_1} = l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2)$\n$\\frac{\\partial y}{\\partial \\theta_2} = l_2 \\cos(\\theta_1 + \\theta_2)$\n\nThus, the Jacobian matrix is:\n$$J = \\begin{pmatrix} -l_1 \\sin(\\theta_1) - l_2 \\sin(\\theta_1 + \\theta_2) & -l_2 \\sin(\\theta_1 + \\theta_2) \\\\ l_1 \\cos(\\theta_1) + l_2 \\cos(\\theta_1 + \\theta_2) & l_2 \\cos(\\theta_1 + \\theta_2) \\end{pmatrix}$$\n\nThe condition number $\\kappa(J)$ is defined as the ratio of the largest singular value $\\sigma_{\\text{max}}$ to the smallest singular value $\\sigma_{\\text{min}}$ of $J$. The singular values are the square roots of the eigenvalues of the matrix $J^{\\top}J$. We now compute $J^{\\top}J$.\nLet's denote $s_1 = \\sin(\\theta_1)$, $c_1 = \\cos(\\theta_1)$, $s_{12} = \\sin(\\theta_1 + \\theta_2)$, and $c_{12} = \\cos(\\theta_1 + \\theta_2)$.\n$J^{\\top}J = \\begin{pmatrix} -l_1 s_1 - l_2 s_{12} & l_1 c_1 + l_2 c_{12} \\\\ -l_2 s_{12} & l_2 c_{12} \\end{pmatrix} \\begin{pmatrix} -l_1 s_1 - l_2 s_{12} & -l_2 s_{12} \\\\ l_1 c_1 + l_2 c_{12} & l_2 c_{12} \\end{pmatrix}$\n\nThe elements of $J^{\\top}J$ are:\n$(J^{\\top}J)_{11} = (-l_1 s_1 - l_2 s_{12})^2 + (l_1 c_1 + l_2 c_{12})^2 = l_1^2(s_1^2+c_1^2) + l_2^2(s_{12}^2+c_{12}^2) + 2l_1 l_2 (s_1 s_{12} + c_1 c_{12})$\nUsing trigonometric identities, this simplifies to:\n$(J^{\\top}J)_{11} = l_1^2 + l_2^2 + 2l_1 l_2 \\cos(\\theta_2)$\n\n$(J^{\\top}J)_{22} = (-l_2 s_{12})^2 + (l_2 c_{12})^2 = l_2^2 (s_{12}^2 + c_{12}^2) = l_2^2$\n\n$(J^{\\top}J)_{12} = (J^{\\top}J)_{21} = (-l_1 s_1 - l_2 s_{12})(-l_2 s_{12}) + (l_1 c_1 + l_2 c_{12})(l_2 c_{12})$\n$= l_1 l_2 s_1 s_{12} + l_2^2 s_{12}^2 + l_1 l_2 c_1 c_{12} + l_2^2 c_{12}^2 = l_1 l_2 (s_1 s_{12} + c_1 c_{12}) + l_2^2 (s_{12}^2+c_{12}^2)$\n$= l_1 l_2 \\cos(\\theta_2) + l_2^2$\n\nSo, the matrix is:\n$$J^{\\top}J = \\begin{pmatrix} l_1^2 + l_2^2 + 2l_1 l_2 \\cos(\\theta_2) & l_2^2 + l_1 l_2 \\cos(\\theta_2) \\\\ l_2^2 + l_1 l_2 \\cos(\\theta_2) & l_2^2 \\end{pmatrix}$$\n\nThe squared singular values, $\\sigma^2$, are the eigenvalues $\\lambda$ of $J^{\\top}J$. They are the roots of the characteristic equation $\\det(J^{\\top}J - \\lambda I) = 0$. The eigenvalues are given by $\\lambda^2 - \\text{Tr}(J^{\\top}J)\\lambda + \\det(J^{\\top}J) = 0$.\n\nLet's compute the trace and determinant of $J^{\\top}J$:\n$\\text{Tr}(J^{\\top}J) = (l_1^2 + l_2^2 + 2l_1 l_2 \\cos(\\theta_2)) + l_2^2 = l_1^2 + 2l_2^2 + 2l_1 l_2 \\cos(\\theta_2)$\n$\\det(J^{\\top}J) = (l_1^2 + l_2^2 + 2l_1 l_2 \\cos(\\theta_2))(l_2^2) - (l_2^2 + l_1 l_2 \\cos(\\theta_2))^2$\n$= l_1^2 l_2^2 + l_2^4 + 2l_1 l_2^3 \\cos(\\theta_2) - (l_2^4 + 2l_1 l_2^3 \\cos(\\theta_2) + l_1^2 l_2^2 \\cos^2(\\theta_2))$\n$= l_1^2 l_2^2 - l_1^2 l_2^2 \\cos^2(\\theta_2) = l_1^2 l_2^2 (1 - \\cos^2(\\theta_2)) = l_1^2 l_2^2 \\sin^2(\\theta_2)$\nNote that $\\det(J^{\\top}J) = (\\det J)^2$, which is consistent since $\\det J = l_1 l_2 \\sin(\\theta_2)$.\n\nWe are interested in the behavior near the elbow-straight configuration, i.e., for $\\theta_2 \\approx 0$. We perform a leading-order asymptotic analysis. For small $\\theta_2$:\n$\\cos(\\theta_2) \\approx 1 - \\frac{\\theta_2^2}{2}$\n$\\sin(\\theta_2) \\approx \\theta_2$\n\nThe trace becomes:\n$\\text{Tr}(J^{\\top}J) \\approx l_1^2 + 2l_2^2 + 2l_1 l_2 (1 - \\frac{\\theta_2^2}{2}) = (l_1^2 + 2l_2^2 + 2l_1 l_2) - l_1 l_2 \\theta_2^2$\nThe leading-order term of the trace is constant:\n$\\text{Tr}_0 = \\lim_{\\theta_2 \\to 0} \\text{Tr}(J^{\\top}J) = l_1^2 + 2l_1 l_2 + 2l_2^2 = (l_1+l_2)^2 + l_2^2$\n\nThe determinant becomes:\n$\\det(J^{\\top}J) \\approx l_1^2 l_2^2 \\theta_2^2$\n\nThe eigenvalues are $\\lambda_{\\text{max,min}} = \\frac{1}{2}(\\text{Tr} \\pm \\sqrt{\\text{Tr}^2 - 4\\det})$.\nFor small $\\det$, we can approximate the eigenvalues. The larger eigenvalue is approximately the trace, and the smaller eigenvalue is approximately the determinant divided by the trace.\n$\\lambda_{\\text{max}} = \\sigma_{\\text{max}}^2 \\approx \\text{Tr}(J^{\\top}J) \\approx \\text{Tr}_0 = l_1^2 + 2l_1 l_2 + 2l_2^2$\n$\\lambda_{\\text{min}} = \\sigma_{\\text{min}}^2 \\approx \\frac{\\det(J^{\\top}J)}{\\text{Tr}(J^{\\top}J)} \\approx \\frac{l_1^2 l_2^2 \\theta_2^2}{l_1^2 + 2l_1 l_2 + 2l_2^2}$\n\nThe condition number is $\\kappa(J) = \\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}} = \\sqrt{\\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}}}$.\nUsing our asymptotic expressions:\n$\\kappa(J)^2 \\approx \\frac{l_1^2 + 2l_1 l_2 + 2l_2^2}{\\frac{l_1^2 l_2^2 \\theta_2^2}{l_1^2 + 2l_1 l_2 + 2l_2^2}} = \\frac{(l_1^2 + 2l_1 l_2 + 2l_2^2)^2}{l_1^2 l_2^2 \\theta_2^2}$\n\nTaking the square root, and noting that singular values are non-negative, we obtain the leading-order asymptotic expression for the condition number:\n$\\kappa(J) \\approx \\frac{l_1^2 + 2l_1 l_2 + 2l_2^2}{l_1 l_2 |\\theta_2|}$\n\nThis expression reveals that as $\\theta_2 \\to 0$, the condition number $\\kappa(J)$ diverges as $1/|\\theta_2|$. This has profound implications for numerical stability and motor control.\n\nExplanation:\n1.  **Ill-Conditioning near Singularity**: The configuration $\\theta_2 = 0$ is a kinematic singularity, where the arm is fully extended. At this point, the Jacobian loses rank, meaning the end-effector loses the ability to move in all directions. Specifically, it can only move perpendicular to the arm's axis. Our analysis shows that as we approach this singularity, $\\kappa(J) \\to \\infty$, indicating the Jacobian matrix becomes ill-conditioned.\n\n2.  **Amplification of Errors**: The condition number bounds the amplification of relative errors when solving a linear system. For the inverse velocity problem $\\dot{\\theta} = J^{+} \\dot{\\mathbf{r}}$, a large $\\kappa(J)$ implies that small errors in the desired end-effector velocity $\\dot{\\mathbf{r}}$ (which could arise from sensor noise, planning errors, or numerical floating-point inaccuracies) can be magnified into very large errors in the computed joint velocities $\\dot{\\theta}$. This would lead to erratic and unstable movements.\n\n3.  **Unfeasible Joint Velocities**: A large $\\kappa(J)$ also means that the norm of the pseudoinverse, $||J^{+}||$, is large. Consequently, to achieve a modest end-effector velocity $\\dot{\\mathbf{r}}$ in certain directions (particularly, radially along the arm's axis), the required joint velocities $\\dot{\\theta}$ become enormous and potentially unachievable by biological or mechanical actuators. The control signal \"explodes\" near the singularity.\n\n4.  **Implications for Inverse Models of Motor Control**: If the brain's motor control system relies on an internal inverse model analogous to $J^{+}$, this inherent instability at kinematic singularities poses a significant computational problem. The divergence of $\\kappa(J)$ implies that a naive inversion is not a viable strategy for controlling movements through or near such postures. This suggests that the central nervous system must employ more sophisticated strategies, such as:\n    -   Avoiding singular postures during movement planning.\n    -   Using regularization techniques (e.g., damped least squares, $J^{\\top}(JJ^{\\top} + \\lambda^2 I)^{-1}$), which trade off tracking accuracy for solution stability, preventing joint velocities from exploding.\n    -   Relying on different control paradigms, such as impedance control or forward models, especially near singularities.\nThe behavior of $\\kappa(J)$ thus provides a formal mathematical basis for understanding why certain postures are difficult to control and why neural control strategies must be robust to such computational challenges.",
            "answer": "$$\n\\boxed{\\frac{l_1^2 + 2 l_1 l_2 + 2 l_2^2}{l_1 l_2 |\\theta_2|}}\n$$"
        }
    ]
}