## 引言
在复杂多变的环境中，大脑如何稳定地感知世界并高效地处理信息？[计算神经科学](@entry_id:274500)的一个核心答案在于“[标准化](@entry_id:637219)”（Normalization）——一种在整个神经系统中普遍存在的“标准计算”。这种计算动态地调整神经元的响应，使其适应当前的上下文环境，从而实现稳健而高效的[神经编码](@entry_id:263658)。标准化主要通过两种基本形式实现：除法标准化（Divisive Normalization）和减法[标准化](@entry_id:637219)（Subtractive Normalization）。理解这两种机制的原理、区别与联系，是揭示大脑计算奥秘的关键一步。

本文旨在系统性地剖析这两种[标准化](@entry_id:637219)电路。我们将从第一章“原理与机制”出发，深入探讨它们的数学范式、功能角色以及[生物物理学](@entry_id:154938)基础。随后，在第二章“应用与跨学科联系”中，我们将展示这些原理如何解释从感觉恒常性到高级认知功能的多种神经现象，并探索其与人工智能等领域的深刻联系。最后，通过第三章“动手实践”中的具体问题，您将有机会亲手应用这些理论，巩固对这一基本计算模块的理解。

## 原理与机制

本章将深入探讨其核心原理与机制，重点阐述两种主要的标准化形式：除法标准化（divisive normalization）和减法标准化（subtractive normalization）。我们将从它们的数学范式出发，逐步揭示其功能角色、对神经元调谐特性的影响，并最终追溯其在生物物理及环路层面上的实现机制。

### 标准化模型的范式

为了系统地理解[标准化](@entry_id:637219)，我们首先需要建立其精确的数学描述。这些模型虽然是简化和抽象的，但它们捕捉了神经计算的基本特性，并为后续的生物物理学和[功能分析](@entry_id:164849)提供了坚实的基础。

#### 除法标准化的范式

除法[标准化](@entry_id:637219)被认为是皮层计算的一个“标准模型”，它描述了神经元的响应如何被其自身驱动以及一个汇集的抑制性信号所共同调节。其标准数学形式如下 ：

$$
r_i = \frac{g \cdot x_i^n}{\sigma^n + \sum_{j} w_{ij} x_j^n}
$$

在这个模型中，各个参数具有明确的计算意义：

*   $r_i$ 是神经元 $i$ 的输出响应（例如，发放率），且根据生物物理现实，$r_i \ge 0$。
*   $x_i$ 是对神经元 $i$ 的兴奋性驱动（例如，来自感受野的刺激能量或对比度），且 $x_i \ge 0$。
*   $g$ 是一个输出增益常数。
*   $n$ 是一个大于零的指数，它决定了[响应函数](@entry_id:142629)的[非线性](@entry_id:637147)程度。在[初级视皮层](@entry_id:908756)（V1）的模型中， $n$ 的取值通常在 $[1, 3]$ 范围内，一个常见的选择是 $n \approx 2$。
*   $\sigma$ 是一个正的[半饱和常数](@entry_id:1125887)。当其他神经元的驱动为零时（即 $\forall j \ne i, x_j = 0$），并且权重 $w_{ii}=1$ 时，$\sigma$ 的值使得当输入 $x_i=\sigma$ 时，响应达到最大值的一半。它控制了神经元响应的敏感度。
*   $w_{ij}$ 是非负的池化权重（$w_{ij} \ge 0$），描述了神经元 $j$ 的活动对神经元 $i$ 的抑制强度。这个池（pool）通常包括神经元自身（$j=i$）以及在[特征和](@entry_id:189446)空间上相邻的神经元。

此模型的几个关键特性值得关注：

1.  **饱和性（Saturation）**：当输入 $x_i$ 变得非常大时，如果其他输入保持不变，分母中的 $x_i^n$ 项将占主导地位，使得响应 $r_i$ 趋近于一个饱和值 $g/w_{ii}$。这符合生物神经元发放率有上限的特性。
2.  **[单调性](@entry_id:143760)（Monotonicity）**：响应 $r_i$ 随其自身驱动 $x_i$ 的增加而单调增加。
3.  **尺度[协变](@entry_id:634097)性（Scale Covariance）**：这是除法标准化的一个核心特性。如果我们将所有输入都乘以一个正的标量 $\alpha$（即 $x_k \to \alpha x_k$），响应函数变为：
    $$
    r'_i = \frac{g \cdot (\alpha x_i)^n}{\sigma^n + \sum_{j} w_{ij} (\alpha x_j)^n} = \frac{g \cdot \alpha^n x_i^n}{\sigma^n + \alpha^n \sum_{j} w_{ij} x_j^n} = \frac{g \cdot x_i^n}{(\sigma/\alpha)^n + \sum_j w_{ij} x_j^n}
    $$
    此结果表明，对输入进行全局缩放，其效果等同于将[半饱和常数](@entry_id:1125887)从 $\sigma$ 变为 $\sigma/\alpha$。这意味着[响应函数](@entry_id:142629)的基本形状（例如，对比度响应曲线的形状）得以保持，只是在输入轴上发生了平移。这一特性对于在不同光照或刺激强度下维持稳健的感知至关重要。为了保证这种尺度[协变](@entry_id:634097)性，分子的[驱动项](@entry_id:165986) $x_i^n$ 和分母中依赖于输入的池化项 $\sum_j w_{ij} x_j^n$ 必须是关于输入的同次齐次函数，即指数 $n$ 必须相同 。

#### 减法[标准化](@entry_id:637219)的范式

与除法标准化不同，减法标准化通过直接相减来整合抑制性影响。其最简单的[线性形式](@entry_id:276136)可以表示为 ：

$$
r_i = x_i - \sum_{j} w_{ij} x_j
$$

其中 $x_i$ 是驱动输入，$w_{ij} \ge 0$ 是抑制性权重。这个模型描述了一个简单的线性抑制过程。然而，作为一个[神经计算模型](@entry_id:1128632)，它必须服从一个基本的生物物理约束：神经元的发放率不能为负，即 $r_i \ge 0$。

当我们考虑一个神经元群体，其中每个神经元的输入 $x_j$ 都可以独立变化时，上述线性模型会面临一个严峻的挑战。假设存在任何一个非对角线权重 $w_{ij} > 0$（即 $i \neq j$），代表神经元 $j$ 对神经元 $i$ 的抑制。我们可以构造一个特定的输入场景：只让神经元 $j$ 被驱动（$x_j > 0$），而所有其他神经元（包括神经元 $i$）的直接驱动为零（$x_k = 0$ for $k \ne j$）。在这种情况下，神经元 $i$ 的响应为：

$$
r_i = x_i - \sum_{k} w_{ik} x_k = 0 - w_{ij} x_j = -w_{ij} x_j
$$

由于 $w_{ij} > 0$ 且 $x_j > 0$，我们得到了一个负的发放率 $r_i  0$，这在生物学上是不可能的。因此，纯线性的减法标准化模型只有在非常特殊的情况下才能保证非负输出，即当权重矩阵 $W=(w_{ij})$ 是一个对角矩阵且对角元素 $0 \le w_{ii} \le 1$ 时。

在更普遍、更现实的神经网络中，存在侧向抑制（$w_{ij} > 0$ for $i \ne j$）。为了解决负发放率的问题，模型必须引入一个**[非线性](@entry_id:637147)**的修正。最常见的修正是在减法操作之后应用一个**[整流](@entry_id:197363)线性单元（Rectified Linear Unit, ReLU）**，其函数形式为 $f(z) = \max(0, z)$。修正后的减法[标准化](@entry_id:637219)模型为 ：

$$
r_i = \max\left(0, x_i - \sum_{j} w_{ij} x_j\right)
$$

这个简单的[非线性](@entry_id:637147)步骤确保了输出始终为非负，从而使模型在生物学上更加合理。这一点凸显了在构建[计算模型](@entry_id:637456)时，必须将生物物理约束考虑在内的重要性。

### 功能角色：增益控制与基线移除

除法和减法标准化不仅在数学形式上有所不同，它们在神经信息处理中扮演的功能角色也截然不同。一个经典的思想实验可以清晰地阐明这一点 。

想象一个感觉神经元群体，其接收到的驱动信号 $d_i$ 同时受到一个乘性因子 $g$（代表刺激的整体“增益”或“对比度”）和一个加性偏移 $b$（代表“基线”或背景水平）的影响：

$$
d_i = g s_i + b
$$

其中 $s_i$ 是与特定特征相关的刺激分量。我们的目标是构建一个能够对 $g$ 和 $b$ 的变化保持不变性的神经表征。

#### 减法标准化：对基线偏移的不变性

首先，我们考虑一个减法标准化机制，它通过从每个神经元的驱动中减去整个群体的平均驱动来实现。群体的平均驱动 $\langle d \rangle$ 为：

$$
\langle d \rangle = \frac{1}{N} \sum_{j=1}^{N} d_j = \frac{1}{N} \sum_{j=1}^{N} (g s_j + b) = g \langle s \rangle + b
$$

其中 $\langle s \rangle$ 是刺激分量的均值。经过减法[标准化](@entry_id:637219)后，神经元 $i$ 的有效输入 $e_i$ 变为：

$$
e_i = d_i - \langle d \rangle = (g s_i + b) - (g \langle s \rangle + b) = g(s_i - \langle s \rangle)
$$

在这个结果中，加性基线项 $b$ 被完全消除了。这表明，**通过减去群体平均值，减法[标准化](@entry_id:637219)可以实现对输入信号中共同基线漂移的[不变性](@entry_id:140168)**。

#### 除法标准化：对[乘性](@entry_id:187940)增益的[不变性](@entry_id:140168)

接下来，我们对经过减法处理后的有效输入 $e_i$ 应用除法标准化。假设最终的响应 $r_i$ 是由 $e_i$ 除以整个有效输入向量 $\mathbf{e} = (e_1, \dots, e_N)$ 的[欧几里得范数](@entry_id:172687)（$||\mathbf{e}||$）得到的：

$$
r_i = \frac{e_i}{||\mathbf{e}||}
$$

我们来计算分母 $||\mathbf{e}||$：

$$
||\mathbf{e}|| = \sqrt{\sum_{j=1}^{N} e_j^2} = \sqrt{\sum_{j=1}^{N} [g(s_j - \langle s \rangle)]^2} = \sqrt{g^2 \sum_{j=1}^{N} (s_j - \langle s \rangle)^2} = |g| \sqrt{\sum_{j=1}^{N} (s_j - \langle s \rangle)^2}
$$

将 $e_i$ 和 $||\mathbf{e}||$ 的表达式代入 $r_i$ 的计算中（假设 $g0$）：

$$
r_i = \frac{g(s_i - \langle s \rangle)}{g \sqrt{\sum_{j=1}^{N} (s_j - \langle s \rangle)^2}} = \frac{s_i - \langle s \rangle}{\sqrt{\sum_{j=1}^{N} (s_j - \langle s \rangle)^2}}
$$

最终的响应 $r_i$ 完全不依赖于[乘性](@entry_id:187940)增益因子 $g$。这清晰地证明了，**通过除以一个反映[群体活动](@entry_id:1129935)总能量的信号，除法[标准化](@entry_id:637219)可以实现对输入信号整体增益或对比度的不变性**。

综上所述，减法标准化主要用于消除背景噪声或基线漂移，而除法标准化则主要用于实现增益控制，使得神经表征在面对刺激整体强度变化时保持稳定。

### 对神经元调谐特性的影响

[标准化](@entry_id:637219)的功能角色也直接体现在它们如何塑造神经元的调谐特性上。一个神经元的调谐曲线描述了其对不同刺激特征（如方向、空间频率）的响应强度。

考虑一个具有余弦调谐曲线的神经元，其基线响应为 $r_0(\theta) = b + A\cos(\theta - \theta_p)$，其中 $\theta_p$ 是该神经元的“偏好特征”，$b$ 是基线发放率，$A$ 是调谐幅度 。

一个重要的观察是，无论是除法[标准化](@entry_id:637219)还是减法[标准化](@entry_id:637219)，它们通常都**保留神经元的偏好特征**。这是因为标准化操作（无论是乘以一个常数还是减去一个常数）通常不会改变调谐曲线[最大值点](@entry_id:634610)的位置。神经元最“喜欢”的那个刺激特征依然是它最喜欢的。

然而，这两种标准化方式对响应调制的相对强度有着不同的影响。我们可以通过**峰谷比（Peak-to-Trough Ratio, PTR）**来量化这一点，其定义为[调谐曲线](@entry_id:1133474)的最大响应与最小响应之比。

*   **除法[标准化](@entry_id:637219)**通常表现为对响应的缩放，例如 $r_d(\theta) \propto r_0(\theta)$。这种操作可以被看作是一种纯粹的**增益控制**。由于整个调谐曲线被同比例缩放，其峰值和谷值也被同比例缩放，因此峰谷比保持不变。
    $$
    \mathrm{PTR}[r_d] = \frac{\max r_d(\theta)}{\min r_d(\theta)} = \frac{k \cdot \max r_0(\theta)}{k \cdot \min r_0(\theta)} = \frac{b+A}{b-A} = \mathrm{PTR}[r_0]
    $$

*   **减法[标准化](@entry_id:637219)**表现为对响应的平移，即 $r_s(\theta) = r_0(\theta) - C$。这种操作虽然也降低了整体响应，但它不成比例地减小了谷值（最小响应）相对于峰值（最大响应）的比例。因此，**减法[标准化](@entry_id:637219)会增大峰谷比**，从而在效果上**锐化**了调谐曲线。
    $$
    \mathrm{PTR}[r_s] = \frac{\max r_s(\theta)}{\min r_s(\theta)} = \frac{(b+A) - C}{(b-A) - C}  \frac{b+A}{b-A} \quad (\text{for } A0, C0)
    $$

因此，通过分析[标准化](@entry_id:637219)对[调谐曲线](@entry_id:1133474)的影响，我们能够进一步区分这两种计算的功能后果：除法标准化调节响应的整体幅度，而减法标准化在调节响应的同时，还能增强神经元对特定特征的选择性。

### 生物物理与环路机制

到目前为止，我们讨论的都是抽象的[计算模型](@entry_id:637456)。一个核心问题是：这些计算是如何在真实的神经环路中实现的？神经元的生物物理特性和它们之间的连接方式为这些计算提供了基础。

#### 减法[标准化](@entry_id:637219)的生物物理基础

减法[标准化](@entry_id:637219)可以在单个神经元层面，通过突触**电流**的线性叠加来实现 。根据基于电导的神经元模型，总[突触电流](@entry_id:1132766)是兴奋性电流 $I_E$ 和抑制性电流 $I_I$ 的和。每个电流由其电导 $g_{syn}$ 和驱动力 $(E_{rev} - V)$ 决定：

$$
I_{syn} = g_{E}(E_E - V) + g_{I}(E_I - V)
$$

其中 $E_E$ 和 $E_I$ 分别是兴奋性和抑制性突触的翻转电位，$V$ 是膜电位。

如果在神经元的正常工作电压范围内，突触的翻转电位（例如，兴奋性的 $E_E \approx 0$ mV，抑制性的 $E_I \approx -75$ mV）与膜电位 $V$（例如，在 $-65$ mV 到 $-50$ mV 之间波动）**相距甚远**，那么驱动力 $(E_E - V)$ 和 $(E_I - V)$ 可以被近似为常数。在这种情况下，突触电流就近似与[突触电导](@entry_id:193384)成正比：

$$
I_E \approx g_E \cdot \text{const}_E \quad \text{and} \quad I_I \approx g_I \cdot \text{const}_I
$$

如果兴奋性电导 $g_E$ 正比于驱动输入 $x_i$，而抑制性电导 $g_I$ 正比于池化输入 $\sum_j w_{ij} x_j$，那么净输入电流就变成了这两个输入的线性加权差：

$$
I_{net} \approx \kappa_E x_i - \kappa_I \sum_j w_{ij} x_j
$$

当这个净电流通过一个近似线性的频率-电流（f-I）转换函数时，最终的发放率 $r_i$ 就表现为减法[标准化](@entry_id:637219)的形式。因此，**当突触翻转电位远离神经元的工作电压时，抑制性输入主要表现为减法效应**。

#### 除法标准化的生物物理基础

与减法标准化不同，除法[标准化](@entry_id:637219)通常与一种称为**分流抑制（shunting inhibition）**的机制有关。当抑制性突触的翻转电位 $E_I$ **非常接近**神经元的静息电位或工作电位时，这种机制最为显著。

在这种情况下，抑制性突触激活时，其驱动力 $(E_I - V)$ 很小，因此不会产生很大的直接超[极化电流](@entry_id:196744)。然而，它会显著增加[细胞膜](@entry_id:146704)的总电导 $g_{total} = g_{leak} + g_E + g_I$。根据[欧姆定律](@entry_id:276027)的简化形式，神经元的[稳态](@entry_id:139253)电压响应正比于输入电流，反比于总电导：

$$
\Delta V \propto \frac{I_E}{g_{total}} = \frac{I_E}{g_{leak} + g_E + g_I}
$$

当抑制性电导 $g_I$ 随池化活动 $\sum_j w_{ij} x_j$ 增加时，它出现在了分母项中，从而对兴奋性驱动 $I_E$ 产生了**除法**效应。

一个简单的兴奋-抑制（E-I）环路模型可以清晰地展示这一点 。假设一个兴奋性神经元群体 $r_E$ 接收外部驱动 $x$，其兴奋性输入电流为 $I_E = W_{EE} x$。同时，一个抑制性神经元群体 $r_I$ 也被 $x$ 驱动（$r_I = W_{EI} x$），并向兴奋性群体提供分流抑制，其抑制性电导为 $g_I = W_{IE} r_I$。兴奋性群体的[稳态响应](@entry_id:173787) $r_E$ 可近似为：

$$
r_E \approx \frac{I_E}{\sigma + g_I} = \frac{W_{EE} x}{\sigma + W_{IE} r_I} = \frac{W_{EE} x}{\sigma + W_{IE} W_{EI} x}
$$

这个结果明确地呈现了除法标准化的形式。分母中的 $x$ 依赖项 $W_{IE} W_{EI} x$ 来自于[前馈抑制](@entry_id:922820)环路的增益，它动态地调节了兴奋性神经元的响应。

#### 动态调节神经元敏感度

除法标准化模型不仅是一个静态的输入-输出函数，它还揭示了一种动态调节神经元敏感度的机制。通过将除法[标准化](@entry_id:637219)模型与经典的**Naka-Rushton方程**进行比较，我们可以更深刻地理解这一点 。

一个经过标准化的除法模型可以写为：

$$
R(x) = \frac{x^n}{(\sigma_0^n + \Pi) + x^n}
$$

其中 $\Pi$ 代表来自其他神经元的恒定池化抑制。这个形式与Naka-Rushton方程 $R(x) = \frac{x^n}{C_{eff}^n + x^n}$ 完全对应。通过比较，我们可以发现，有效[半饱和常数](@entry_id:1125887) $C_{eff}$ 为：

$$
C_{eff} = (\sigma_0^n + \Pi)^{1/n}
$$

这个关系的核心洞见在于：**来自其他神经元的池化抑制（$\Pi$）通过增大有效[半饱和常数](@entry_id:1125887)（$C_{eff}$），从而降低了神经元对其自身驱动 $x$ 的敏感度**。当周围神经元活动增强时（$\Pi$ 增大），$C_{eff}$ 也随之增大，这意味着需要更强的输入 $x$ 才能使该神经元达到相同的响应水平。这是一种强大的、基于上下文的增益控制机制，被认为在注意力和[多感觉整合](@entry_id:153710)等认知功能中扮演着关键角色。

### 环路结构与动态特性的深入探讨

虽然我们区分了减法和除法[标准化](@entry_id:637219)，但在复杂的神经环路中，二者的界限可能变得模糊，并且环路的具体结构（前馈 vs. 反馈）对其动态行为有着深远的影响。

#### [前馈抑制](@entry_id:922820) vs. 侧向/[反馈抑制](@entry_id:136838)

我们之前讨论的抑制性池化可以由不同的环路结构实现。例如，**减法[标准化](@entry_id:637219)**可以被看作一种**前馈**计算，其中抑制信号与兴奋信号并行地从输入端计算并汇集到输出神经元 。而经典的**侧向抑制**则是一种**反馈（或循环）**结构，其中神经元的输出活动被用来抑制其邻近的神经元。

数学上，前馈减法标准化的输出 $\mathbf{y}$ 是对输入 $\mathbf{s}$ 的函数：$\mathbf{y} = f(\mathbf{s} - W\mathbf{s})$。而反馈侧向抑制的[稳态](@entry_id:139253)输出 $\mathbf{r}$ 是对自身输出的函数：$\mathbf{r} = f(\mathbf{s} - W\mathbf{r})$。这两种结构在计算上是不同的，除非在特定条件下（例如，当 $W$ 非常弱时），它们才会产生相似的结果。

更有趣的是，即使两种结构（前馈与反馈）被精心设计以产生完全相同的**[稳态](@entry_id:139253)输出**，它们的**瞬态动力学**通常也会有所不同 。这是因为[瞬态响应](@entry_id:165150)由系统的本征动力学模式（由其特征值决定）控制，而这些模式直接依赖于环路的连接结构。一个[前馈环路](@entry_id:271330)和一个反馈环路即使在平衡点上表现相同，它们对时变输入的响应路径和速度也可能大相径庭。这表明，仅仅研究神经元的[稳态响应](@entry_id:173787)不足以完全理解神经环路的计算功能，动力学特性同样至关重要。

#### 从减法环路中涌现的除法标准化

最后，在包含[非线性](@entry_id:637147)单元的循环网络中，减法和除法之间的界限会变得更加模糊。即使一个环路的连接在结构上是“减法”的，其整体计算也可能表现出“除法”的效应。

考虑一个具有[反馈抑制](@entry_id:136838)的Wilson-Cowan群体模型，其[动力学方程](@entry_id:751029)为 $\tau \dot{r} = -r + f(W_E x - W_I r)$ 。在这个方程中，抑制项 $W_I r$ 是从兴奋性驱动 $W_E x$ 中减去的。然而，由于[非线性](@entry_id:637147)增益函数 $f$ 的存在，系统的[稳态响应](@entry_id:173787) $r$ 并非 $x$ 的线性或简单的减法函数。通过在低输入和弱反馈的条件下进行[泰勒展开](@entry_id:145057)分析，可以证明[稳态响应](@entry_id:173787)可以被一个有效的除法标准化模型很好地近似：

$$
r(x) \approx \frac{A \cdot x}{B + C \cdot x}
$$

其中常数 $A, B, C$ 由环路参数（$W_E, W_I$）和增益函数 $f$ 的局部特性（如其一阶和二阶导数）共同决定。这说明，**除法标准化可以作为一种涌现特性，在具有减法连接和[饱和非线性](@entry_id:271106)的循环网络中自发产生**。这一发现模糊了两种标准化类型的严格划分，并提示我们，在神经网络中观察到的计算功能可能是底层环路结构和神经元[非线性](@entry_id:637147)特性复杂相互作用的结果。

本章通过剖析除法和减法[标准化](@entry_id:637219)的范式、功能、生物物理基础和环路实现，为理解大脑如何通过规范化神经活动来执行稳健高效的计算提供了系统性的框架。这些原理和机制是现代[计算神经科学](@entry_id:274500)的基石，为我们探索更复杂的认知现象提供了理论工具。