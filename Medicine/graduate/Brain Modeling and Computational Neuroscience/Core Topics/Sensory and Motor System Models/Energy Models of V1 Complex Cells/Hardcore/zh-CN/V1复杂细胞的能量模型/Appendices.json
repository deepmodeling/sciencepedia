{
    "hands_on_practices": [
        {
            "introduction": "一个好的科学模型不仅能解释已知现象，还应能做出可检验的预测。这项练习将引导你运用能量模型的核心特性——相位不变性，来设计一个思想实验。你将学习如何利用反相光栅这一视觉神经科学中的经典刺激，来明确区分简单细胞和复杂细胞的响应模式，从而将抽象的数学模型与具体的实验验证联系起来 。",
            "id": "3978675",
            "problem": "考虑一个位于初级视皮层 (V1) 的一维模型神经元，该神经元由复杂细胞的经典能量模型描述。刺激是一个反相光栅，由下式给出\n$$\ns(x,t) \\;=\\; A \\cos(k_0 x + \\phi)\\,\\cos(\\omega t),\n$$\n其中，$A$ 是对比度振幅，$k_0$ 是空间频率，$\\phi$ 是空间相位（单位为弧度），$\\omega$ 是时间角频率（单位为弧度/秒）。该神经元有两个线性亚基，其空间感受野 (RFs) 分别为 $g_{e}(x)$ 和 $g_{o}(x)$，它们在空间频率 $k_0$ 处形成一个空间正交对。线性响应为\n$$\nr_{e}(t;\\phi)\\;=\\;\\int_{-\\infty}^{\\infty} g_{e}(x)\\,s(x,t)\\,dx,\\qquad\nr_{o}(t;\\phi)\\;=\\;\\int_{-\\infty}^{\\infty} g_{o}(x)\\,s(x,t)\\,dx,\n$$\n复杂细胞的输出是能量\n$$\nE(t;\\phi)\\;=\\;r_{e}(t;\\phi)^{2}\\;+\\;r_{o}(t;\\phi)^{2}.\n$$\n假设两个亚基都是线性且空间时不变的，正交特性在 $k_0$ 处精确成立（即增益相等且空间相位差为 $\\pi/2$），并且每个线性响应的时间依赖性仅来自于刺激中的 $\\cos(\\omega t)$ 因子。定义在一个时间周期 $T = 2\\pi/\\omega$ 内的时间平均响应为\n$$\n\\overline{E}(\\phi)\\;=\\;\\frac{1}{T}\\int_{0}^{T} E(t;\\phi)\\,dt,\n$$\n并定义相位不变性指数为\n$$\n\\mathrm{PI}\\;=\\;\\frac{R_{\\min}}{R_{\\max}},\n$$\n其中 $R_{\\min}$ 和 $R_{\\max}$ 分别是 $\\overline{E}(\\phi)$ 在 $\\phi \\in [0,2\\pi)$ 上的最小值和最大值。\n\n仅使用线性系统的第一性原理和正交特性，完成以下任务。首先，通过指明时间平均响应对空间相位 $\\phi$ 的依赖性有何不同，来构建一个可证伪的实验预测，用以在反相光栅刺激下区分简单细胞和复杂细胞。其次，推导能量模型神经元的 $\\overline{E}(\\phi)$，并计算上述理想情况对应的 $\\mathrm{PI}$。\n\n将你的最终答案表示为一个无量纲数。无需四舍五入。",
            "solution": "首先根据所需标准对问题进行验证。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   刺激：$s(x,t) \\;=\\; A \\cos(k_0 x + \\phi)\\,\\cos(\\omega t)$\n-   变量：对比度振幅 $A$，空间频率 $k_0$，空间相位 $\\phi$，时间角频率 $\\omega$。\n-   神经元模型：由能量模型描述的复杂细胞。\n-   亚基：两个线性亚基，其空间感受野 (RFs) 分别为 $g_{e}(x)$ 和 $g_{o}(x)$。\n-   正交特性：在空间频率 $k_0$ 处，亚基形成一个空间正交对，意味着它们具有相等的增益和 $\\pi/2$ 的空间相位差。\n-   线性响应：$r_{e}(t;\\phi)\\;=\\;\\int_{-\\infty}^{\\infty} g_{e}(x)\\,s(x,t)\\,dx$ 和 $r_{o}(t;\\phi)\\;=\\;\\int_{-\\infty}^{\\infty} g_{o}(x)\\,s(x,t)\\,dx$。\n-   复杂细胞输出（能量）：$E(t;\\phi)\\;=\\;r_{e}(t;\\phi)^{2}\\;+\\;r_{o}(t;\\phi)^{2}$。\n-   假设：\n    1.  亚基是线性且空间时不变的。\n    2.  每个线性响应的时间依赖性仅来自于刺激因子 $\\cos(\\omega t)$。\n-   时间平均响应：$\\overline{E}(\\phi)\\;=\\;\\frac{1}{T}\\int_{0}^{T} E(t;\\phi)\\,dt$，时间周期 $T = 2\\pi/\\omega$。\n-   相位不变性指数：$\\mathrm{PI}\\;=\\;\\frac{R_{\\min}}{R_{\\max}}$，其中 $R_{\\min} = \\min_{\\phi} \\overline{E}(\\phi)$ 且 $R_{\\max} = \\max_{\\phi} \\overline{E}(\\phi)$，对于 $\\phi \\in [0,2\\pi)$。\n\n**步骤2：使用提取的已知条件进行验证**\n\n-   **科学依据：** 该问题描述了 V1 复杂细胞的经典 Adelson-Bergen 能量模型，这是计算神经科学的基石。使用反相光栅作为刺激是视觉生理学中的一种标准技术。该问题在科学上是合理的。\n-   **良态问题：** 问题定义清晰，提供了推导所需量所必需的所有函数、定义和假设。目标具体，并能导出一个唯一的解。\n-   **客观性：** 问题以精确的数学语言陈述，没有任何主观或模棱两可的术语。\n-   **结论：** 问题陈述是完整的、一致的并且在科学上是有效的。它是一个良态问题，适合进行严格求解。\n\n**步骤3：结论与行动**\n\n问题有效。将提供解答。\n\n### 解答\n\n本解答处理问题的两个部分：首先，构建一个可证伪的预测来区分简单细胞和复杂细胞；其次，推导时间平均响应 $\\overline{E}(\\phi)$ 并计算理想复杂细胞模型的相位不变性指数 $(\\mathrm{PI})$。\n\n**第1部分：区分简单细胞和复杂细胞的可证伪预测**\n\n简单细胞通常被建模为单个线性滤波器后跟一个静态非线性环节，例如整流或平方。其响应对刺激的空间相位高度敏感。相比之下，复杂细胞的能量模型汇集了具有不同相位偏好的多个线性滤波器的平方输出。据推测，这种汇集操作会产生一个对空间相位不变的响应。这种差异导出了一个清晰的实验预测。\n\n一个简单细胞的响应可以建模为 $S(t;\\phi) = f(r_e(t;\\phi))$，其中 $r_e(t;\\phi)$ 是某个单一线性响应，$f$ 是一个非线性函数。如下文所示，$r_e(t;\\phi)$ 与 $\\cos(\\phi)$ 成正比。因此，其时间平均响应 $\\overline{S}(\\phi)$ 会受到 $\\phi$ 的强烈调制，在某个偏好相位达到峰值，而在其他相位为零。例如，如果 $f(z)=z^2$，则时间平均的简单细胞响应将与 $\\cos^2(\\phi)$ 成正比，其最小响应与最大响应之比为 $0$。\n\n复杂细胞的响应由 $E(t;\\phi)$ 给出。下面的推导将表明其时间平均响应 $\\overline{E}(\\phi)$ 是一个常数。\n\n**可证伪的预测：** 可以设计一个实验，向 V1 神经元呈现一个反相光栅刺激 $s(x,t) = A \\cos(k_0 x + \\phi)\\cos(\\omega t)$，其空间频率为该神经元的偏好空间频率 $k_0$。在空间相位 $\\phi$ 在 $[0, 2\\pi)$ 范围内变化时，记录神经元的时间平均发放率（作为响应的度量）。\n-   **如果该细胞是简单细胞**，其时间平均响应将随 $\\phi$ 显示出强烈的调制，表现出明显的峰值和谷值。相位不变性指数 $\\mathrm{PI}$ 将接近 $0$。\n-   **如果该细胞是理想的复杂细胞**，其时间平均响应将是恒定的，不随 $\\phi$ 发生调制。相位不变性指数 $\\mathrm{PI}$ 将为 $1$。\n这提供了一种直接、定量且可证伪的方法，用于根据神经元对此刺激的响应将其分类为简单细胞或复杂细胞。\n\n**第2部分：$\\overline{E}(\\phi)$ 和相位不变性指数 $(\\mathrm{PI})$ 的推导**\n\n我们首先计算线性响应 $r_{e}(t;\\phi)$ 和 $r_{o}(t;\\phi)$。给定刺激 $s(x,t) = A \\cos(k_0 x + \\phi) \\cos(\\omega t)$以及时间动态仅源于刺激的假设，我们可以从空间积分中分解出时间分量。\n$$\nr_{j}(t;\\phi) = \\int_{-\\infty}^{\\infty} g_{j}(x) A \\cos(k_0 x + \\phi) \\cos(\\omega t) dx = A \\cos(\\omega t) \\int_{-\\infty}^{\\infty} g_j(x) \\cos(k_0 x + \\phi) dx\n$$\n对于 $j \\in \\{e, o\\}$。让我们通过展开余弦来分析空间积分项：\n$$\n\\int_{-\\infty}^{\\infty} g_j(x) [\\cos(k_0 x)\\cos(\\phi) - \\sin(k_0 x)\\sin(\\phi)] dx = \\cos(\\phi)\\int_{-\\infty}^{\\infty} g_j(x)\\cos(k_0 x)dx - \\sin(\\phi)\\int_{-\\infty}^{\\infty} g_j(x)\\sin(k_0 x)dx\n$$\n正交特性意味着 $g_e(x)$ 是一个偶对称滤波器（如余弦 Gabor 函数），而 $g_o(x)$ 是一个奇对称滤波器（如正弦 Gabor 函数）。对于偶函数 $g_e(x)$， $g_e(x)\\sin(k_0 x)$ 在 $(-\\infty, \\infty)$ 上的积分是零，因为被积函数是奇函数。对于奇函数 $g_o(x)$，$g_o(x)\\cos(k_0 x)$ 的积分是零，因为被积函数是奇函数。\n这简化了响应的空间分量：\n-   对于 $r_e(t;\\phi)$：含有 $\\sin(\\phi)$ 的项消失。令 $C_e = \\int_{-\\infty}^{\\infty} g_e(x)\\cos(k_0 x)dx$。响应变为 $r_e(t;\\phi) = A C_e \\cos(\\phi) \\cos(\\omega t)$。\n-   对于 $r_o(t;\\phi)$：含有 $\\cos(\\phi)$ 的项消失。令 $S_o = \\int_{-\\infty}^{\\infty} g_o(x)\\sin(k_0 x)dx$。响应变为 $r_o(t;\\phi) = -A S_o \\sin(\\phi) \\cos(\\omega t)$。\n\n正交特性还指出滤波器具有“相等增益”。这转化为它们对其偏好输入的响应幅度相等。常数 $C_e$ 表示偶滤波器对余弦光栅的响应，$S_o$ 表示奇滤波器对正弦光栅的响应。相等增益意味着 $|C_e| = |S_o|$。我们定义这个增益为 $K  0$。如有必要，通过调整 $g_e$ 和 $g_o$ 的符号，我们可以设定 $C_e = K$ 和 $S_o = K$。\n因此，线性响应为：\n$$\nr_e(t;\\phi) = A K \\cos(\\phi) \\cos(\\omega t)\n$$\n$$\nr_o(t;\\phi) = -A K \\sin(\\phi) \\cos(\\omega t)\n$$\n现在，我们计算能量 $E(t;\\phi) = r_e(t;\\phi)^2 + r_o(t;\\phi)^2$：\n$$\nE(t;\\phi) = [A K \\cos(\\phi) \\cos(\\omega t)]^2 + [-A K \\sin(\\phi) \\cos(\\omega t)]^2\n$$\n$$\nE(t;\\phi) = (A K)^2 \\cos^2(\\omega t) \\cos^2(\\phi) + (A K)^2 \\cos^2(\\omega t) \\sin^2(\\phi)\n$$\n提出公因子：\n$$\nE(t;\\phi) = (A K)^2 \\cos^2(\\omega t) [\\cos^2(\\phi) + \\sin^2(\\phi)]\n$$\n使用三角恒等式 $\\cos^2(\\phi) + \\sin^2(\\phi) = 1$：\n$$\nE(t;\\phi) = (A K)^2 \\cos^2(\\omega t)\n$$\n值得注意的是，瞬时能量 $E(t;\\phi)$ 与空间相位 $\\phi$ 无关。\n\n接下来，我们计算一个时间周期 $T=2\\pi/\\omega$ 内的时间平均响应 $\\overline{E}(\\phi)$：\n$$\n\\overline{E}(\\phi) = \\frac{1}{T} \\int_0^T E(t;\\phi) dt = \\frac{1}{T} \\int_0^T (A K)^2 \\cos^2(\\omega t) dt\n$$\n$\\cos^2(\\theta)$ 在一个完整周期内的平均值是 $1/2$。形式上：\n$$\n\\frac{1}{T} \\int_0^T \\cos^2(\\omega t) dt = \\frac{1}{T} \\int_0^T \\frac{1+\\cos(2\\omega t)}{2} dt = \\frac{1}{2T} \\left[t + \\frac{\\sin(2\\omega t)}{2\\omega}\\right]_0^T\n$$\n$$\n= \\frac{1}{2T} \\left[T + \\frac{\\sin(2\\omega (2\\pi/\\omega))}{2\\omega} - 0\\right] = \\frac{1}{2T} \\left[T + \\frac{\\sin(4\\pi)}{2\\omega}\\right] = \\frac{1}{2}\n$$\n因此，时间平均响应为：\n$$\n\\overline{E}(\\phi) = (A K)^2 \\cdot \\frac{1}{2} = \\frac{(A K)^2}{2}\n$$\n时间平均响应 $\\overline{E}(\\phi)$ 是一个常数，与空间相位 $\\phi$ 无关。\n\n最后，我们计算相位不变性指数 $\\mathrm{PI} = R_{\\min}/R_{\\max}$：\n$$\nR_{\\max} = \\max_{\\phi \\in [0,2\\pi)} \\overline{E}(\\phi) = \\max_{\\phi} \\frac{(A K)^2}{2} = \\frac{(A K)^2}{2}\n$$\n$$\nR_{\\min} = \\min_{\\phi \\in [0,2\\pi)} \\overline{E}(\\phi) = \\min_{\\phi} \\frac{(A K)^2}{2} = \\frac{(A K)^2}{2}\n$$\n$$\n\\mathrm{PI} = \\frac{R_{\\min}}{R_{\\max}} = \\frac{(A K)^2 / 2}{(A K)^2 / 2} = 1\n$$\n对于由能量模型描述的理想复杂细胞，相位不变性指数恰好为 $1$。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "在理解了能量模型的功能特性后，下一个关键步骤是如何从实验数据中估计模型的参数，即感受野滤波器。这个过程称为系统辨识，而基于梯度的优化方法是完成此任务的核心工具。这项练习将让你实践最基本的一步：推导能量函数相对于其参数的梯度，这是训练所有此类模型的必备基础技能 。",
            "id": "3978680",
            "problem": "考虑一个初级视皮层（V1）复杂细胞的标准能量模型。设刺激为一个向量 $x \\in \\mathbb{R}^{n}$，两个线性子单元滤波器为 $h_{1} \\in \\mathbb{R}^{n}$ 和 $h_{2} \\in \\mathbb{R}^{n}$。子单元的响应是内积 $y_{1} = h_{1}^{\\top} x$ 和 $y_{2} = h_{2}^{\\top} x$。模型的能量输出定义为\n$$\nE(x) = y_{1}^{2} + y_{2}^{2} = \\left(h_{1}^{\\top} x\\right)^{2} + \\left(h_{2}^{\\top} x\\right)^{2}.\n$$\n从线性滤波作为内积的核心定义以及复合函数微分的链式法则出发，推导 $E(x)$ 关于刺激 $x$ 以及关于滤波器参数 $h_{1}$ 和 $h_{2}$ 的梯度的闭式表达式。然后，简要说明如何使用这些梯度，通过基于梯度的优化方法，从包含已知刺激下测得的复杂细胞响应的数据中，对滤波器进行系统辨识。\n\n请将三个梯度的最终答案按 $\\left(\\nabla_{x} E, \\nabla_{h_{1}} E, \\nabla_{h_{2}} E\\right)$ 的顺序放在一个单行矩阵中。不需要进行数值取整，也没有物理单位。请将您的最终答案表示为一个简化的、闭式的解析表达式。",
            "solution": "该问题是有效的，因为它科学地基于已建立的 V1 复杂细胞能量模型，在数学上是适定的、客观的且自洽的。任务是推导该模型的标准梯度，并解释其在系统辨识中的应用，这是计算神经科学中的一个核心概念。\n\nV1 复杂细胞模型的能量输出由下式给出：\n$$\nE(x) = \\left(h_{1}^{\\top} x\\right)^{2} + \\left(h_{2}^{\\top} x\\right)^{2}\n$$\n其中 $x \\in \\mathbb{R}^{n}$ 是刺激向量，$h_{1}, h_{2} \\in \\mathbb{R}^{n}$ 是线性滤波器向量。为了推导梯度，我们将应用向量值函数的微分链式法则。对于一个复合函数 $f(g(z))$，其关于 $z$ 的梯度是 $\\nabla_z f = \\frac{\\partial f}{\\partial g} \\nabla_z g$。我们还使用两个标准的向量微积分恒等式：$\\nabla_z(a^\\top z) = a$ 和 $\\nabla_z(z^\\top a) = a$。\n\n1.  **关于刺激 $x$ 的梯度：** $\\nabla_{x} E(x)$\n\n能量 $E(x)$ 是两项之和。和的梯度是梯度的和。我们分别计算每一项关于 $x$ 的梯度。\n\n对于第一项，令 $y_{1}(x) = h_{1}^{\\top} x$。该项为 $y_{1}^{2}$。使用链式法则：\n$$\n\\nabla_{x} \\left(y_{1}^{2}\\right) = \\frac{d(y_{1}^{2})}{dy_{1}} \\nabla_{x} y_{1}\n$$\n$y_{1}^{2}$ 关于 $y_{1}$ 的导数是 $2y_{1}$。线性函数 $y_{1}(x) = h_{1}^{\\top} x$ 关于 $x$ 的梯度是：\n$$\n\\nabla_{x} \\left(h_{1}^{\\top} x\\right) = h_{1}\n$$\n结合这些，第一项的梯度是：\n$$\n\\nabla_{x} \\left(\\left(h_{1}^{\\top} x\\right)^{2}\\right) = 2y_{1} h_{1} = 2\\left(h_{1}^{\\top} x\\right) h_{1}\n$$\n根据对称性，第二项 $\\left(h_{2}^{\\top} x\\right)^{2}$ 的梯度是：\n$$\n\\nabla_{x} \\left(\\left(h_{2}^{\\top} x\\right)^{2}\\right) = 2\\left(h_{2}^{\\top} x\\right) h_{2}\n$$\n$E(x)$ 关于 $x$ 的总梯度是这两个结果的和：\n$$\n\\nabla_{x} E(x) = 2\\left(h_{1}^{\\top} x\\right) h_{1} + 2\\left(h_{2}^{\\top} x\\right) h_{2}\n$$\n\n2.  **关于滤波器 $h_{1}$ 的梯度：** $\\nabla_{h_{1}} E$\n\n为了求关于 $h_{1}$ 的梯度，我们注意到第二项 $\\left(h_{2}^{\\top} x\\right)^{2}$ 不依赖于 $h_{1}$，因此其梯度为零向量。我们只需要对第一项 $\\left(h_{1}^{\\top} x\\right)^{2}$ 求导。\n\n令 $y_{1}(h_{1}) = h_{1}^{\\top} x$。对关于 $h_{1}$ 的梯度使用链式法则：\n$$\n\\nabla_{h_{1}} \\left(y_{1}^{2}\\right) = \\frac{d(y_{1}^{2})}{dy_{1}} \\nabla_{h_{1}} y_{1} = 2y_{1} \\nabla_{h_{1}} y_{1}\n$$\n为了求 $y_{1}(h_{1}) = h_{1}^{\\top} x$ 的梯度，我们可以将内积重写为 $x^{\\top}h_{1}$。这个线性函数关于 $h_{1}$ 的梯度是：\n$$\n\\nabla_{h_{1}} \\left(x^{\\top} h_{1}\\right) = x\n$$\n将其代回，我们得到 $E$ 关于 $h_{1}$ 的梯度：\n$$\n\\nabla_{h_{1}} E = 2y_{1} x = 2\\left(h_{1}^{\\top} x\\right) x\n$$\n\n3.  **关于滤波器 $h_{2}$ 的梯度：** $\\nabla_{h_{2}} E$\n\n$\\nabla_{h_{2}} E$ 的推导与 $\\nabla_{h_{1}} E$ 的推导是对称的。第一项 $\\left(h_{1}^{\\top} x\\right)^{2}$ 不依赖于 $h_{2}$。我们对第二项 $\\left(h_{2}^{\\top} x\\right)^{2}$ 关于 $h_{2}$ 求导。\n$$\n\\nabla_{h_{2}} E = \\nabla_{h_{2}} \\left(\\left(h_{2}^{\\top} x\\right)^{2}\\right)\n$$\n遵循与 $h_{1}$ 相同的逻辑：\n$$\n\\nabla_{h_{2}} \\left(\\left(h_{2}^{\\top} x\\right)^{2}\\right) = 2\\left(h_{2}^{\\top} x\\right) \\nabla_{h_{2}}\\left(h_{2}^{\\top} x\\right) = 2\\left(h_{2}^{\\top} x\\right) x\n$$\n因此，$E$ 关于 $h_{2}$ 的梯度是：\n$$\n\\nabla_{h_{2}} E = 2\\left(h_{2}^{\\top} x\\right) x\n$$\n\n**使用梯度进行系统辨识**\n\n系统辨识是根据实验数据建立系统数学模型的过程。在此背景下，它意味着找到能够最好地解释一组已知刺激下 V1 复杂细胞观测响应的滤波器参数 $h_{1}$ 和 $h_{2}$。\n\n我们推导出的梯度 $\\nabla_{h_{1}} E$ 和 $\\nabla_{h_{2}} E$ 在使用基于梯度的优化方法时对这一过程至关重要。其步骤如下：\n\n1.  **定义损失函数：** 首先，定义一个损失函数 $L(h_{1}, h_{2})$ 来量化模型的预测能量输出 $E(x^{(i)})$ 与一个刺激-响应对数据集 $\\{ (x^{(i)}, r^{(i)}) \\}_{i=1}^{N}$ 中的实际测量神经响应 $r^{(i)}$ 之间的差异。一个常见的选择是均方误差（MSE）：\n    $$\n    L(h_{1}, h_{2}) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(r^{(i)} - E(x^{(i)})\\right)^{2}\n    $$\n2.  **基于梯度的优化：** 目标是找到使该损失函数最小化的参数 $h_{1}$ 和 $h_{2}$。梯度下降是一种迭代算法，它通过沿损失函数梯度的反方向重复更新参数来实现这一目标。每个滤波器的更新规则是：\n    $$\n    h_{1} \\leftarrow h_{1} - \\alpha \\nabla_{h_{1}} L \\\\\n    h_{2} \\leftarrow h_{2} - \\alpha \\nabla_{h_{2}} L\n    $$\n    其中 $\\alpha$ 是一个称为学习率的小正数。\n\n3.  **计算损失梯度：** 损失函数的梯度 $\\nabla_{h_{1}} L$ 和 $\\nabla_{h_{2}} L$ 使用链式法则计算，这需要我们已经推导出的能量模型 $E$ 的梯度。例如，对于 $h_{1}$：\n    $$\n    \\nabla_{h_{1}} L = \\frac{\\partial L}{\\partial E} \\nabla_{h_{1}} E\n    $$\n    对于单个数据点 $(x, r)$，MSE 损失关于 $h_{1}$ 的梯度是：\n    $$\n    \\nabla_{h_{1}} L = \\frac{\\partial}{\\partial h_{1}} \\left(r - E(x)\\right)^{2} = 2(r - E(x))(-\\nabla_{h_{1}} E) = -2(r - E(x)) \\left(2(h_{1}^{\\top} x) x\\right)\n    $$\n    $\\nabla_{h_{2}} L$ 也有类似的表达式。通过在数据集上对这些梯度进行平均，并迭代地应用更新规则，算法会收敛到一组能够最佳地表征复杂细胞响应特性的滤波器 $h_{1}$ 和 $h_{2}$。",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 2\\left(h_{1}^{\\top} x\\right) h_{1} + 2\\left(h_{2}^{\\top} x\\right) h_{2}  2\\left(h_{1}^{\\top} x\\right) x  2\\left(h_{2}^{\\top} x\\right) x \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "经典的能量模型与现代的深度学习并非毫无关联；相位不变性等计算原理，正在卷积神经网络（ConvNets）中被重新发现或被直接构建。这项动手编程练习将向你展示，如何通过设计一个明确惩罚相位敏感性的学习目标，来引导神经网络自主学习出具有正交对结构的滤波器，这恰恰是经典能量模型所预测的 。通过这个练习，你将把理论知识转化为可运行的代码，加深对模型学习动态的理解。",
            "id": "3978686",
            "problem": "您将使用卷积神经网络（ConvNets）中的最小双滤波器能量模型和正弦数据增强方案，对初级视皮层（V1）复杂细胞的相位不变能量机制进行建模。目标是设计一个目标函数，该函数惩罚特征响应能量中的相位调制，并通过在合成正弦输入上进行优化来证明所学得的滤波器收敛于正交关系。所有角度必须以弧度为单位。\n\n从以下基本和核心定义开始。\n\n1. 线性滤波：给定一个输入向量 $x \\in \\mathbb{R}^{T}$ 和一个滤波器 $f \\in \\mathbb{R}^{T}$，线性响应为 $r = f^{\\top} x$。\n2. 带相位增强的正弦数据集：对于一个固定的角频率 $\\omega \\in (0,\\pi)$ 和一组在 $[0,2\\pi)$ 上均匀采样的相位 $\\Phi = \\{\\phi_{p}\\}_{p=1}^{P}$，构建输入 $x_{\\phi} \\in \\mathbb{R}^{T}$，其分量为 $x_{\\phi}[t] = \\sin(\\omega t + \\phi)$，其中 $t \\in \\{0,1,\\dots,T-1\\}$ 且 $\\phi \\in \\Phi$。\n3. 双滤波器能量模型：定义两个滤波器 $f_{1}, f_{2} \\in \\mathbb{R}^{T}$ 及其响应 $r_{i}(\\phi) = f_{i}^{\\top} x_{\\phi}$（$i \\in \\{1,2\\}$）；定义能量 $y(\\phi) = r_{1}(\\phi)^{2} + r_{2}(\\phi)^{2}$。\n4. 相位不变性期望：能量 $y(\\phi)$ 应与相位 $\\phi$ 无关。\n\n您的任务是：\n\nA. 提出并实现一个目标函数，该函数在保持滤波器非退化的同时，惩罚能量在不同相位上的相位调制。您的目标函数必须是滤波器 $f_{1}$ 和 $f_{2}$ 以及数据集 $\\{x_{\\phi}\\}$ 的函数，并包括：\n- 一个通过最小化 $y(\\phi)$ 在相位 $\\phi$ 上的跨相位可变性来惩罚其调制的项。\n- 一个鼓励 $(f_{1}, f_{2})$ 的总平方范数保持固定的范数约束。\n- 一个温和的均衡项，鼓励两个滤波器在均方响应中贡献相等。\n\nB. 在正弦数据集上使用基于梯度的优化来优化滤波器。您必须从上述核心定义出发，以 $f_{1}$、$f_{2}$ 和 $\\{x_{\\phi}\\}$ 的形式显式实现梯度。不允许使用自动微分。\n\nC. 优化后，评估所学得的滤波器在训练频率下是否形成近似的正交对。对于每个滤波器 $f_{i}$，将其在角频率 $\\omega$ 处的复傅里葉系数定义为\n$$\n\\hat{c}_{i}(\\omega) = \\sum_{t=0}^{T-1} f_{i}[t] \\, e^{-j \\omega t}, \\quad i \\in \\{1,2\\}。\n$$\n令滤波器相位为 $\\theta_{i} = \\arg\\big(\\hat{c}_{i}(\\omega)\\big)$。将与正交的相位偏差定义为\n$$\n\\Delta_{\\text{phase}} = \\left| \\left( \\left( \\theta_{2} - \\theta_{1} \\right) \\bmod \\pi \\right) - \\frac{\\pi}{2} \\right|。\n$$\n将振幅比误差定义为\n$$\n\\Delta_{\\text{mag}} = \\left| \\frac{|\\hat{c}_{1}(\\omega)|}{|\\hat{c}_{2}(\\omega)|} - 1 \\right|。\n$$\n将残余调制指数定义为\n$$\n\\Delta_{\\text{mod}} = \\frac{\\operatorname{std}_{\\phi \\in \\Phi_{\\text{eval}}} \\left[ y(\\phi) \\right]}{\\operatorname{mean}_{\\phi \\in \\Phi_{\\text{eval}}} \\left[ y(\\phi) \\right]},\n$$\n其中 $\\Phi_{\\text{eval}}$ 是在 $[0,2\\pi)$ 上均匀采样的 256 个相位的密集评估网格。\n\n程序要求：\n\n1. 实现一个基于梯度的优化器（您可以实现带动量的随机梯度下降的变体或自适应方法），为每个测试用例最小化关于 $(f_{1}, f_{2})$ 的目标函数。使用确定性初始化，通过设置固定的随机种子以保证可复现性。角度必须以弧度为单位。\n\n2. 计算并报告每个测试用例训练后的三个标量指标 $(\\Delta_{\\text{phase}}, \\Delta_{\\text{mag}}, \\Delta_{\\text{mod}})$，并按此顺序排列。\n\n3. 测试套件。在以下测试用例上运行您的程序，每个用例由 $(T,\\ \\omega,\\ P,\\ \\text{steps},\\ \\text{lr},\\ \\alpha,\\ \\beta)$ 指定：\n- 用例 1: $(33,\\ 0.3\\pi,\\ 64,\\ 2000,\\ 0.02,\\ 1.0,\\ 0.1)$。\n- 用例 2: $(33,\\ 0.1\\pi,\\ 64,\\ 2000,\\ 0.02,\\ 1.0,\\ 0.1)$。\n- 用例 3: $(33,\\ 0.45\\pi,\\ 64,\\ 2500,\\ 0.015,\\ 1.0,\\ 0.1)$。\n- 用例 4: $(33,\\ 0.3\\pi,\\ 8,\\ 3000,\\ 0.015,\\ 1.0,\\ 0.2)$。\n\n在上述参数中，$T$ 是输入长度，$\\omega$ 是每样本的角频率（以弧度为单位），$P$ 是训练相位的数量，steps 是优化步数，lr 是学习率，$\\alpha$ 是范数约束的系数，$\\beta$ 是均衡项的系数。\n\n4. 最终输出格式。您的程序应生成单行输出，其中包含所有四个用例的所有指标，按顺序排列并展平为一个逗号分隔的列表：\n$$\n\\left[\\Delta_{\\text{phase}}^{(1)},\\ \\Delta_{\\text{mag}}^{(1)},\\ \\Delta_{\\text{mod}}^{(1)},\\ \\Delta_{\\text{phase}}^{(2)},\\ \\Delta_{\\text{mag}}^{(2)},\\ \\Delta_{\\text{mod}}^{(2)},\\ \\Delta_{\\text{phase}}^{(3)},\\ \\Delta_{\\text{mag}}^{(3)},\\ \\Delta_{\\text{mod}}^{(3)},\\ \\Delta_{\\text{phase}}^{(4)},\\ \\Delta_{\\text{mag}}^{(4)},\\ \\Delta_{\\text{mod}}^{(4)}\\right]。\n$$\n角度必须以弧度为单位，所有结果必须报告为不带单位的浮点数。程序不得读取任何输入，也不得打印任何其他内容。",
            "solution": "该问题要求我们对V1复杂细胞的相位不变能量机制进行建模。这通过定义一个目标函数来实现，该函数惩罚来自双滤波器系统的相位相关能量响应，在合成正弦数据集上使用梯度下降优化滤波器，并评估所得滤波器的正交结构。\n\n### A. 目标函数设计\n\n目标是找到两个线性滤波器 $f_{1}, f_{2} \\in \\mathbb{R}^{T}$，使得对于所有相位 $\\phi$ 的输入正弦波 $x_{\\phi}[t] = \\sin(\\omega t + \\phi)$，能量响应 $y(\\phi) = (f_{1}^{\\top} x_{\\phi})^{2} + (f_{2}^{\\top} x_{\\phi})^{2}$ 是恒定的。我们构建一个复合目标函数 $L(f_1, f_2)$，它是三个项的加权和 $L = L_{\\text{mod}} + \\alpha L_{\\text{norm}} + \\beta L_{\\text{eq}}$，旨在强制实现此期望并确保滤波器是良态的。\n\n1.  **相位调制惩罚项 ($L_{\\text{mod}}$):** 为惩罚能量 $y(\\phi)$ 随相位 $\\phi$ 的调制，我们最小化其在训练相位集 $\\Phi = \\{\\phi_{p}\\}_{p=1}^{P}$ 上的方差。令 $\\bar{y} = \\frac{1}{P} \\sum_{p=1}^{P} y(\\phi_p)$ 为平均能量。方差是调制的有效度量。\n    $$\n    L_{\\text{mod}} = \\operatorname{Var}_{\\phi \\in \\Phi}[y(\\phi)] = \\frac{1}{P} \\sum_{p=1}^{P} \\left( y(\\phi_p) - \\bar{y} \\right)^2\n    $$\n\n2.  **范数约束惩罚项 ($L_{\\text{norm}}$):** 为保持滤波器非退化并使其幅度受约束，我们惩罚滤波器对的总平方范数与目标常数的偏差。为简单起见，我们选择目标总平方范数为 $C=1$。\n    $$\n    L_{\\text{norm}} = \\left( \\|f_1\\|^2 + \\|f_2\\|^2 - 1 \\right)^2 = \\left( \\sum_{t=0}^{T-1} f_1[t]^2 + \\sum_{t=0}^{T-1} f_2[t]^2 - 1 \\right)^2\n    $$\n    系数 $\\alpha$ 控制此约束的强度。\n\n3.  **响应均衡惩罚项 ($L_{\\text{eq}}$):** 为鼓励两个滤波器对能量贡献均等，我们惩罚它们均方响应之间的差异。令 $\\langle r_i^2 \\rangle_P = \\frac{1}{P} \\sum_{p=1}^{P} r_i(\\phi_p)^2$ 为滤波器 $f_i$ 在训练相位上的均方响应。\n    $$\n    L_{\\text{eq}} = \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right)^2\n    $$\n    系数 $\\beta$ 控制此均衡的强度。\n\n待最小化的总目标函数是：\n$$\nL(f_1, f_2) = \\frac{1}{P} \\sum_{p=1}^{P} \\left( y(\\phi_p) - \\bar{y} \\right)^2 + \\alpha \\left( \\|f_1\\|^2 + \\|f_2\\|^2 - 1 \\right)^2 + \\beta \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right)^2\n$$\n\n### B. 基于梯度的优化\n\n我们使用带动量的梯度下降法，针对滤波器 $f_1$ 和 $f_2$ 最小化目标函数 $L$。这需要计算偏导数 $\\frac{\\partial L}{\\partial f_1}$ 和 $\\frac{\\partial L}{\\partial f_2}$。我们使用链式法则分别推导每一项的梯度。下面，$k \\in \\{1,2\\}$。\n\n**1. $L_{\\text{mod}}$ 的梯度：**\n$$\n\\frac{\\partial L_{\\text{mod}}}{\\partial f_k} = \\frac{\\partial}{\\partial f_k} \\left[ \\frac{1}{P} \\sum_{p=1}^{P} \\left( y(\\phi_p) - \\bar{y} \\right)^2 \\right] = \\frac{2}{P} \\sum_{p=1}^{P} \\left( y(\\phi_p) - \\bar{y} \\right) \\left( \\frac{\\partial y(\\phi_p)}{\\partial f_k} - \\frac{\\partial \\bar{y}}{\\partial f_k} \\right)\n$$\n所需的导数是 $\\frac{\\partial y(\\phi)}{\\partial f_k} = 2 r_k(\\phi) x_{\\phi}$ 和 $\\frac{\\partial \\bar{y}}{\\partial f_k} = \\frac{1}{P} \\sum_{p=1}^{P} \\frac{\\partial y(\\phi_p)}{\\partial f_k} = \\frac{2}{P} \\sum_{p=1}^P r_k(\\phi_p) x_{\\phi_p}$。\n代入并利用属性 $\\sum_p (y(\\phi_p) - \\bar{y}) = 0$，表达式简化为：\n$$\n\\frac{\\partial L_{\\text{mod}}}{\\partial f_k} = \\frac{4}{P} \\sum_{p=1}^{P} \\left( y(\\phi_p) - \\bar{y} \\right) r_k(\\phi_p) x_{\\phi_p}\n$$\n\n**2. $L_{\\text{norm}}$ 的梯度：**\n$$\n\\frac{\\partial L_{\\text{norm}}}{\\partial f_k} = \\frac{\\partial}{\\partial f_k} \\left[ \\left( \\|f_1\\|^2 + \\|f_2\\|^2 - 1 \\right)^2 \\right] = 2 \\left( \\|f_1\\|^2 + \\|f_2\\|^2 - 1 \\right) \\frac{\\partial}{\\partial f_k} \\left( \\|f_1\\|^2 + \\|f_2\\|^2 \\right)\n$$\n由于当 $j=k$ 时 $\\frac{\\partial \\|f_j\\|^2}{\\partial f_k}$ 是 $2f_k$，否则为 $0$，我们得到：\n$$\n\\frac{\\partial L_{\\text{norm}}}{\\partial f_k} = 4 \\left( \\|f_1\\|^2 + \\|f_2\\|^2 - 1 \\right) f_k\n$$\n\n**3. $L_{\\text{eq}}$ 的梯度：**\n关于 $f_1$ 的导数是：\n$$\n\\frac{\\partial L_{\\text{eq}}}{\\partial f_1} = 2 \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right) \\frac{\\partial \\langle r_1^2 \\rangle_P}{\\partial f_1} = 2 \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right) \\left( \\frac{1}{P} \\sum_{p=1}^{P} 2 r_1(\\phi_p) x_{\\phi_p} \\right)\n$$\n$$\n\\frac{\\partial L_{\\text{eq}}}{\\partial f_1} = \\frac{4}{P} \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right) \\sum_{p=1}^{P} r_1(\\phi_p) x_{\\phi_p}\n$$\n根据对称性，关于 $f_2$ 的导数是：\n$$\n\\frac{\\partial L_{\\text{eq}}}{\\partial f_2} = -\\frac{4}{P} \\left( \\langle r_1^2 \\rangle_P - \\langle r_2^2 \\rangle_P \\right) \\sum_{p=1}^{P} r_2(\\phi_p) x_{\\phi_p}\n$$\n\n**总梯度和更新规则：**\n总梯度是各分量梯度的加权和：\n$$\n\\frac{\\partial L}{\\partial f_k} = \\frac{\\partial L_{\\text{mod}}}{\\partial f_k} + \\alpha \\frac{\\partial L_{\\text{norm}}}{\\partial f_k} + \\beta \\frac{\\partial L_{\\text{eq}}}{\\partial f_k}\n$$\n滤波器使用带动量的梯度下降法进行迭代更新。令 $g_k^{(s)}$ 为第 $s$ 步的梯度 $\\frac{\\partial L}{\\partial f_k}$。速度 $v_k$ 和滤波器 $f_k$ 更新如下：\n$$\nv_k^{(s)} = \\mu v_k^{(s-1)} + g_k^{(s)}\n$$\n$$\nf_k^{(s+1)} = f_k^{(s)} - \\eta v_k^{(s)}\n$$\n其中 $\\mu$ 是动量系数（例如，$0.9$），$\\eta$ 是学习率 (`lr`)。\n\n### C. 滤波器评估\n\n优化后，使用三个指标评估所学得的滤波器 $(f_1, f_2)$，以量化它们与正交对的一致性以及所得能量响应的相位不变性。\n\n1.  **与正交的相位偏差 ($\\Delta_{\\text{phase}}$):** 理想的正交对在目标频率 $\\omega$ 处具有 $\\pi/2$ ($90^{\\circ}$) 的相移。我们计算每个滤波器的复傅里葉系数 $\\hat{c}_{i}(\\omega) = \\sum_{t=0}^{T-1} f_{i}[t] \\, e^{-j \\omega t}$ 并提取它们的相位 $\\theta_{i} = \\arg(\\hat{c}_{i}(\\omega))$。与正交的偏差度量为它们的相位差与 $\\pi/2$ 之差，模 $\\pi$。\n    $$\n    \\Delta_{\\text{phase}} = \\left| \\left( \\left( \\theta_{2} - \\theta_{1} \\right) \\bmod \\pi \\right) - \\frac{\\pi}{2} \\right|\n    $$\n\n2.  **振幅比误差 ($\\Delta_{\\text{mag}}$):** 理想的正交对在目标频率下也具有相等的振幅响应。这通过其傅里叶系数幅值之比与 $1$ 的偏差来度量。\n    $$\n    \\Delta_{\\text{mag}} = \\left| \\frac{|\\hat{c}_{1}(\\omega)|}{|\\hat{c}_{2}(\\omega)|} - 1 \\right|\n    $$\n\n3.  **残余调制指数 ($\\Delta_{\\text{mod}}$):** 该指标直接测量优化后能量函数的剩余相位依赖性。它是能量 $y(\\phi)$ 在密集的评估相位网格 $\\Phi_{\\text{eval}}$ 上计算的变异系数（标准差除以均值）。接近 $0$ 的值表示高度的相位不变性。\n    $$\n    \\Delta_{\\text{mod}} = \\frac{\\operatorname{std}_{\\phi \\in \\Phi_{\\text{eval}}} \\left[ y(\\phi) \\right]}{\\operatorname{mean}_{\\phi \\in \\Phi_{\\text{eval}}} \\left[ y(\\phi) \\right]}\n    $$\n\n这些指标的组合为优化过程学习期望的相位不变表示的成功程度提供了全面的评估。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef run_optimization(T, omega_pi, P, steps, lr, alpha, beta, seed=42):\n    \"\"\"\n    Optimizes two filters to form a phase-invariant energy model and evaluates them.\n\n    Args:\n        T (int): Time dimension of inputs and filters.\n        omega_pi (float): Angular frequency in units of pi (e.g., 0.3 means 0.3*pi).\n        P (int): Number of phases in the training dataset.\n        steps (int): Number of optimization steps.\n        lr (float): Learning rate.\n        alpha (float): Weight for the norm constraint penalty.\n        beta (float): Weight for the response equalization penalty.\n        seed (int): Random seed for deterministic initialization.\n\n    Returns:\n        tuple: A tuple containing the three evaluation metrics\n               (delta_phase, delta_mag, delta_mod).\n    \"\"\"\n    omega = omega_pi * np.pi\n\n    # Set seed for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # A. Generate training dataset\n    t = np.arange(T)\n    train_phases = np.linspace(0, 2 * np.pi, P, endpoint=False)\n    X_train = np.sin(omega * t[None, :] + train_phases[:, None])  # Shape (P, T)\n\n    # B. Initialize filters and optimizer state\n    # Initialize with small random values. Scale ensures variance is ~1/T.\n    f1 = rng.normal(size=T, scale=1.0 / np.sqrt(T))\n    f2 = rng.normal(size=T, scale=1.0 / np.sqrt(T))\n    \n    mu = 0.9  # Momentum coefficient\n    v1 = np.zeros(T)\n    v2 = np.zeros(T)\n\n    # C. Optimization loop\n    for _ in range(steps):\n        # 1. Forward pass: compute responses and energy\n        r1 = X_train @ f1  # Shape (P,)\n        r2 = X_train @ f2  # Shape (P,)\n        y = r1**2 + r2**2   # Shape (P,)\n\n        # 2. Compute intermediates for loss and gradients\n        y_mean = np.mean(y)\n        r1_ms = np.mean(r1**2)\n        r2_ms = np.mean(r2**2)\n        f_norm_sq = np.sum(f1**2) + np.sum(f2**2)\n\n        # 3. Compute gradients for each loss component\n        # Gradient of L_mod\n        y_dev = y - y_mean\n        dL_mod_df1 = (4 / P) * (X_train.T @ (y_dev * r1))\n        dL_mod_df2 = (4 / P) * (X_train.T @ (y_dev * r2))\n\n        # Gradient of L_norm\n        dL_norm_df1 = 4 * (f_norm_sq - 1.0) * f1\n        dL_norm_df2 = 4 * (f_norm_sq - 1.0) * f2\n        \n        # Gradient of L_eq\n        eq_diff = r1_ms - r2_ms\n        dL_eq_df1 = (4 / P) * eq_diff * (X_train.T @ r1)\n        dL_eq_df2 = -(4 / P) * eq_diff * (X_train.T @ r2)\n\n        # Total gradient with coefficients alpha and beta\n        grad_f1 = dL_mod_df1 + alpha * dL_norm_df1 + beta * dL_eq_df1\n        grad_f2 = dL_mod_df2 + alpha * dL_norm_df2 + beta * dL_eq_df2\n        \n        # 4. Update filters with momentum\n        v1 = mu * v1 + grad_f1\n        v2 = mu * v2 + grad_f2\n        f1 -= lr * v1\n        f2 -= lr * v2\n\n    # D. Evaluation of the learned filters\n    eps = 1e-9 # Small constant for numerical stability\n\n    # 1. Fourier coefficients and derived metrics\n    exp_vec = np.exp(-1j * omega * t)\n    c1_hat = np.dot(f1, exp_vec)\n    c2_hat = np.dot(f2, exp_vec)\n    \n    # Delta_phase\n    theta1 = np.angle(c1_hat)\n    theta2 = np.angle(c2_hat)\n    delta_phase = np.abs(np.mod(theta2 - theta1, np.pi) - np.pi / 2)\n\n    # Delta_mag\n    c1_abs = np.abs(c1_hat)\n    c2_abs = np.abs(c2_hat)\n    delta_mag = np.abs(c1_abs / (c2_abs + eps) - 1)\n\n    # 2. Residual modulation\n    P_eval = 256\n    eval_phases = np.linspace(0, 2 * np.pi, P_eval, endpoint=False)\n    X_eval = np.sin(omega * t[None, :] + eval_phases[:, None])\n    \n    r1_eval = X_eval @ f1\n    r2_eval = X_eval @ f2\n    y_eval = r1_eval**2 + r2_eval**2\n    \n    y_eval_mean = np.mean(y_eval)\n    delta_mod = np.std(y_eval) / (y_eval_mean + eps)\n\n    return delta_phase, delta_mag, delta_mod\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, omega_as_multiple_of_pi, P, steps, lr, alpha, beta)\n        (33, 0.3, 64, 2000, 0.02, 1.0, 0.1),\n        (33, 0.1, 64, 2000, 0.02, 1.0, 0.1),\n        (33, 0.45, 64, 2500, 0.015, 1.0, 0.1),\n        (33, 0.3, 8, 3000, 0.015, 1.0, 0.2),\n    ]\n\n    results = []\n    # Use a fixed seed for all optimization runs for reproducibility.\n    # The problem asks for deterministic initialization. Using the same\n    # seed for each test case means they all start from the same f1, f2.\n    fixed_seed = 42 \n    for case in test_cases:\n        T, omega_pi, P, steps, lr, alpha, beta = case\n        metrics = run_optimization(T, omega_pi, P, steps, lr, alpha, beta, seed=fixed_seed)\n        results.extend(metrics)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}