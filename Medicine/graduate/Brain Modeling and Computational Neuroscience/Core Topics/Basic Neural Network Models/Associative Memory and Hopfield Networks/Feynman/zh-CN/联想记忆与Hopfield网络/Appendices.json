{
    "hands_on_practices": [
        {
            "introduction": "要理解 Hopfield 网络如何作为联想记忆模型工作，我们必须从其最基本的操作入手。本练习将指导您完成两个核心步骤：首先，使用 Hebbian 学习规则根据给定的记忆模式计算突触权重矩阵；其次，对单个神经元执行一次异步更新。通过这个具体的计算，您将亲身体验信息是如何编码在网络连接中，以及记忆检索过程是如何在微观层面启动的 。",
            "id": "3962571",
            "problem": "考虑一个由霍普菲尔德网络（Hopfield network）建模的二元联想记忆，其中每个神经元的状态为 $s_i \\in \\{-1,+1\\}$，并根据其局部场的符号进行异步更新。设网络中有 $N=4$ 个神经元，两个存储的记忆模式为 $\\xi^{1}=(1,1,-1,-1)$ 和 $\\xi^{2}=(1,-1,1,-1)$，所有神经元的阈值 $\\theta_i=0$。突触权重采用标准的赫布学习规则（Hebbian learning rule），且无自耦合，即当 $i\\neq j$ 时，$w_{ij}=\\frac{1}{N}\\sum_{\\mu=1}^{2}\\xi_i^{\\mu}\\xi_j^{\\mu}$，且 $w_{ii}=0$。异步确定性更新规则为：计算局部场 $h_i(s)=\\sum_{j=1}^{N}w_{ij}s_j-\\theta_i$，然后设置 $s_i \\leftarrow \\operatorname{sign}(h_i(s))$，并约定如果 $h_i(s)=0$，则 $s_i$ 保持不变。\n\n从网络状态 $s=(1,-1,-1,-1)$ 开始，执行以下任务：\n- 计算完整的 $4\\times 4$ 权重矩阵 $W=(w_{ij})$。\n- 使用上述规则对神经元 $3$ 进行一次异步更新。\n\n将神经元 $3$ 更新后的值作为你的最终数值答案，表示为 $-1$ 或 $+1$。无需四舍五入，不涉及物理单位。",
            "solution": "问题提供了对标准霍普菲尔德网络的完整且有效的描述。所有参数和规则都定义明确。我们可以开始求解。\n\n问题要求完成两个任务：首先，计算权重矩阵 $W$；其次，从给定的初始状态开始，对神经元 $3$ 进行一次异步更新。\n\n该网络有 $N=4$ 个神经元，其状态为 $s_i \\in \\{-1, +1\\}$。\n两个存储的记忆模式是：\n$$\n\\xi^{1} = (1, 1, -1, -1)\n$$\n$$\n\\xi^{2} = (1, -1, 1, -1)\n$$\n突触权重由无自耦合的赫布学习规则确定 ($w_{ii}=0$)：\n$$\nw_{ij} = \\frac{1}{N} \\sum_{\\mu=1}^{2} \\xi_i^{\\mu} \\xi_j^{\\mu} \\quad \\text{for } i \\neq j\n$$\n\n**第一部分：计算权重矩阵 $W$**\n\n当 $N=4$ 时，权重的公式为 $w_{ij} = \\frac{1}{4} (\\xi_i^1 \\xi_j^1 + \\xi_i^2 \\xi_j^2)$（对于 $i \\neq j$）。对角线元素 $w_{ii}$ 均为 $0$。我们来计算非对角线元素：\n\n$w_{12} = \\frac{1}{4} [(\\xi_1^1 \\xi_2^1) + (\\xi_1^2 \\xi_2^2)] = \\frac{1}{4} [(1)(1) + (1)(-1)] = \\frac{1}{4} [1-1] = 0$。\n$w_{13} = \\frac{1}{4} [(\\xi_1^1 \\xi_3^1) + (\\xi_1^2 \\xi_3^2)] = \\frac{1}{4} [(1)(-1) + (1)(1)] = \\frac{1}{4} [-1+1] = 0$。\n$w_{14} = \\frac{1}{4} [(\\xi_1^1 \\xi_4^1) + (\\xi_1^2 \\xi_4^2)] = \\frac{1}{4} [(1)(-1) + (1)(-1)] = \\frac{1}{4} [-1-1] = -\\frac{2}{4} = -\\frac{1}{2}$。\n$w_{23} = \\frac{1}{4} [(\\xi_2^1 \\xi_3^1) + (\\xi_2^2 \\xi_3^2)] = \\frac{1}{4} [(1)(-1) + (-1)(1)] = \\frac{1}{4} [-1-1] = -\\frac{2}{4} = -\\frac{1}{2}$。\n$w_{24} = \\frac{1}{4} [(\\xi_2^1 \\xi_4^1) + (\\xi_2^2 \\xi_4^2)] = \\frac{1}{4} [(1)(-1) + (-1)(-1)] = \\frac{1}{4} [-1+1] = 0$。\n$w_{34} = \\frac{1}{4} [(\\xi_3^1 \\xi_4^1) + (\\xi_3^2 \\xi_4^2)] = \\frac{1}{4} [(-1)(-1) + (1)(-1)] = \\frac{1}{4} [1-1] = 0$。\n\n由于权重矩阵必须是对称的 ($w_{ij} = w_{ji}$)，我们便得到了所有分量。完整的 $4 \\times 4$ 权重矩阵 $W$ 为：\n$$\nW =\n\\begin{pmatrix}\nw_{11}  w_{12}  w_{13}  w_{14} \\\\\nw_{21}  w_{22}  w_{23}  w_{24} \\\\\nw_{31}  w_{32}  w_{33}  w_{34} \\\\\nw_{41}  w_{42}  w_{43}  w_{44}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0  0  0  -\\frac{1}{2} \\\\\n0  0  -\\frac{1}{2}  0 \\\\\n0  -\\frac{1}{2}  0  0 \\\\\n-\\frac{1}{2}  0  0  0\n\\end{pmatrix}\n$$\n\n**第二部分：神经元 3 的异步更新**\n\n网络的初始状态给定为 $s = (s_1, s_2, s_3, s_4) = (1, -1, -1, -1)$。\n我们需要更新神经元 $i=3$。更新规则为 $s_3 \\leftarrow \\operatorname{sign}(h_3(s))$，其中 $h_3(s)$ 是神经元 $3$ 的局部场。\n阈值给定为 $\\theta_i = 0$（对所有 $i$）。局部场计算如下：\n$$\nh_i(s) = \\sum_{j=1}^{N} w_{ij}s_j - \\theta_i\n$$\n对于神经元 $3$，这变为：\n$$\nh_3(s) = \\sum_{j=1}^{4} w_{3j}s_j - \\theta_3 = w_{31}s_1 + w_{32}s_2 + w_{33}s_3 + w_{34}s_4 - 0\n$$\n代入矩阵 $W$ 第三行的权重值和初始状态向量 $s$ 的分量：\n$w_{31} = 0$, $w_{32} = -\\frac{1}{2}$, $w_{33} = 0$, $w_{34} = 0$。\n$s_1 = 1$, $s_2 = -1$, $s_3 = -1$, $s_4 = -1$。\n\n局部场为：\n$$\nh_3(s) = (0)(1) + \\left(-\\frac{1}{2}\\right)(-1) + (0)(-1) + (0)(-1) = 0 + \\frac{1}{2} + 0 + 0 = \\frac{1}{2}\n$$\n神经元 $3$ 的更新后状态，我们称之为 $s_3'$，由局部场的符号给出：\n$$\ns_3' = \\operatorname{sign}\\left(h_3(s)\\right) = \\operatorname{sign}\\left(\\frac{1}{2}\\right)\n$$\n因为 $\\frac{1}{2}$ 是一个正数，其符号为 $+1$。\n$$\ns_3' = 1\n$$\n问题规定，如果 $h_i(s)=0$，则神经元状态保持不变。这里情况并非如此，因为 $h_3(s) = \\frac{1}{2} \\neq 0$。\n因此，神经元 $3$ 的更新值为 $1$。",
            "answer": "$$\n\\boxed{1}\n$$"
        },
        {
            "introduction": "Hopfield 网络的一个关键特性是其动态演化可以被一个能量函数（或称 Lyapunov 函数）所描述。在异步更新模式下，网络总是向着能量降低的方向演化，最终稳定在一个能量极小点，即一个记忆模式。本练习  要求您通过显式计算来验证这一定理，您将计算一个神经元更新前后的网络总能量，从而直观地理解能量最小化是如何驱动记忆联想过程的。",
            "id": "3962539",
            "problem": "考虑一个全连接的 Hopfield 网络，该网络有三个二元神经元，其状态为 $s_{i} \\in \\{-1,+1\\}$，突触权重为对称的 $w_{ij} = w_{ji}$，且自耦合为零 $w_{ii}=0$。网络能量由标准的 Hopfield 能量函数定义\n$$\nE(\\mathbf{s}) = -\\frac{1}{2}\\sum_{i=1}^{3}\\sum_{j=1}^{3} w_{ij} s_i s_j + \\sum_{i=1}^{3} \\theta_i s_i,\n$$\n其中 $\\theta_i$ 是固定的阈值。异步更新规则是确定性符号规则\n$$\ns_i \\leftarrow \\operatorname{sgn}\\Big(\\sum_{j=1}^{3} w_{ij} s_j - \\theta_i\\Big),\n$$\n其中，如果 $x>0$，则 $\\operatorname{sgn}(x)=+1$；如果 $x0$，则 $\\operatorname{sgn}(x)=-1$。如果参数为零，神经元状态保持不变。\n\n令所有 $i$ 的 $\\theta_i=0$，非零权重为 $w_{12}=w_{21}=1$，$w_{13}=w_{31}=-1$，$w_{23}=w_{32}=1$。从状态 $\\mathbf{s}=(s_1,s_2,s_3)=(1,-1,1)$ 开始。根据确定性符号规则，仅对神经元 1 执行一次异步更新，在此更新期间保持神经元 2 和 3 固定。\n\n仅使用上面给出的定义，明确证明此异步更新降低了网络能量，并计算由此产生的新状态 $\\mathbf{s}'$ 及其能量 $E(\\mathbf{s}')$。以四元行矩阵 $\\begin{pmatrix} s_1'  s_2'  s_3'  E(\\mathbf{s}') \\end{pmatrix}$ 的形式提供最终答案。无需四舍五入。",
            "solution": "该问题要求我们分析一个 3 神经元 Hopfield 网络中的单次异步更新。验证过程确认了该问题是适定的、有科学依据的，并提供了所有必要的信息。我们可以继续进行求解。\n\n该网络由三个神经元组成，其状态为 $s_i \\in \\{-1, +1\\}$。能量函数由下式给出：\n$$\nE(\\mathbf{s}) = -\\frac{1}{2}\\sum_{i=1}^{3}\\sum_{j=1}^{3} w_{ij} s_i s_j + \\sum_{i=1}^{3} \\theta_i s_i\n$$\n问题指明阈值为零，即对所有 $i$ 都有 $\\theta_i = 0$。能量函数简化为：\n$$\nE(\\mathbf{s}) = -\\frac{1}{2}\\sum_{i=1}^{3}\\sum_{j=1}^{3} w_{ij} s_i s_j\n$$\n在对称权重 ($w_{ij} = w_{ji}$) 和零自耦合 ($w_{ii}=0$) 的条件下，我们可以将 3 神经元情况的双重求和展开为：\n$$\nE(\\mathbf{s}) = -\\frac{1}{2} (w_{12}s_1s_2 + w_{13}s_1s_3 + w_{21}s_2s_1 + w_{23}s_2s_3 + w_{31}s_3s_1 + w_{32}s_3s_2)\n$$\n$$\nE(\\mathbf{s}) = -\\frac{1}{2} (2 w_{12}s_1s_2 + 2 w_{13}s_1s_3 + 2 w_{23}s_2s_3)\n$$\n$$\nE(\\mathbf{s}) = -(w_{12}s_1s_2 + w_{13}s_1s_3 + w_{23}s_2s_3)\n$$\n给定的非零权重为 $w_{12}=1$，$w_{13}=-1$ 和 $w_{23}=1$。网络的初始状态为 $\\mathbf{s} = (s_1, s_2, s_3) = (1, -1, 1)$。\n\n首先，我们计算初始状态的能量 $E(\\mathbf{s})$：\n$$\nE(\\mathbf{s}) = -((1)(1)(-1) + (-1)(1)(1) + (1)(-1)(1))\n$$\n$$\nE(\\mathbf{s}) = -(-1 - 1 - 1) = -(-3) = 3\n$$\n因此，初始能量为 $E(\\mathbf{s}) = 3$。\n\n接下来，我们对神经元 1 执行一次异步更新。更新规则由下式给出：\n$$\ns_i \\leftarrow \\operatorname{sgn}\\Big(\\sum_{j=1}^{3} w_{ij} s_j - \\theta_i\\Big)\n$$\n对于神经元 1 且 $\\theta_1=0$，该规则变为：\n$$\ns_1' = \\operatorname{sgn}\\Big(\\sum_{j=1}^{3} w_{1j} s_j\\Big) = \\operatorname{sgn}(w_{11}s_1 + w_{12}s_2 + w_{13}s_3)\n$$\n由于 $w_{11}=0$，我们计算作用于神经元 1 的局部场 $h_1$：\n$$\nh_1 = w_{12}s_2 + w_{13}s_3\n$$\n使用当前状态值 $s_2 = -1$ 和 $s_3 = 1$，以及权重 $w_{12}=1$，$w_{13}=-1$：\n$$\nh_1 = (1)(-1) + (-1)(1) = -1 - 1 = -2\n$$\n那么神经元 1 的新状态 $s_1'$ 为：\n$$\ns_1' = \\operatorname{sgn}(-2) = -1\n$$\n在此异步更新步骤中，其他神经元保持不变，因此 $s_2' = s_2 = -1$ 且 $s_3' = s_3 = 1$。网络的新状态为 $\\mathbf{s}' = (s_1', s_2', s_3') = (-1, -1, 1)$。\n\n现在，我们计算这个新状态的能量 $E(\\mathbf{s}')$：\n$$\nE(\\mathbf{s}') = -(w_{12}s_1's_2' + w_{13}s_1's_3' + w_{23}s_2's_3')\n$$\n代入新状态 $\\mathbf{s}' = (-1, -1, 1)$ 的值：\n$$\nE(\\mathbf{s}') = -((1)(-1)(-1) + (-1)(-1)(1) + (1)(-1)(1))\n$$\n$$\nE(\\mathbf{s}') = - (1 + 1 - 1) = -1\n$$\n新状态的能量为 $E(\\mathbf{s}') = -1$。\n\n为了明确证明更新降低了网络能量，我们比较初始能量和最终能量：\n初始能量：$E(\\mathbf{s}) = 3$。\n最终能量：$E(\\mathbf{s}') = -1$。\n由于 $-1  3$，我们有 $E(\\mathbf{s}')  E(\\mathbf{s})$，这证实了确定性异步更新降低了网络能量，正如 Hopfield 网络所预期的那样。能量的变化为 $\\Delta E = E(\\mathbf{s}') - E(\\mathbf{s}) = -1 - 3 = -4$。\n\n问题要求提供四元行矩阵 $\\begin{pmatrix} s_1'  s_2'  s_3'  E(\\mathbf{s}') \\end{pmatrix}$。\n各分量为：\n$s_1' = -1$\n$s_2' = -1$\n$s_3' = 1$\n$E(\\mathbf{s}') = -1$\n将这些组合成最终的矩阵形式即可得到答案。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-1  -1  1  -1\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "单个神经元的更新规则在宏观尺度上会涌现出怎样的集体行为？本练习  将视角从微观的神经元提升到宏观的整体网络。您将使用一个源自平均场理论的迭代映射来模拟记忆恢复的完整动态过程，这个映射描述了网络状态与目标模式的重叠度（overlap）如何随时间演化。通过这个编程实践，您将能探索网络的收敛速度以及初始状态（记忆的损坏程度）对成功检索的影响。",
            "id": "3962552",
            "problem": "考虑一个具有 $N=1000$ 个二元神经元的 Hopfield 网络 (HN)，它通过 Hebbian 学习存储了 $p=50$ 个独立的随机二元模式。设在异步扫描第 $t$ 步时，神经元 $i$ 的二元状态为 $s_i(t) \\in \\{-1, +1\\}$，目标模式为 $\\boldsymbol{\\xi}^1 \\in \\{-1, +1\\}^N$。将第 $t$ 步扫描时与目标模式的宏观重叠度定义为 $m_t = \\frac{1}{N} \\sum_{i=1}^{N} \\xi_i^1 s_i(t)$。假设采用标准的符号更新规则的零温确定性异步动力学。在大 $N$ 极限下，根据中心极限定理 (CLT) 对串扰噪声的近似，重叠度的演化由以下迭代映射给出\n$$\nm_{t+1} = \\operatorname{erf}\\left(\\frac{m_t}{\\sqrt{2 \\alpha}}\\right),\n$$\n其中 $\\alpha = \\frac{p}{N}$ 是负载，$\\operatorname{erf}(\\cdot)$ 是高斯误差函数。\n\n给定一个初始损坏水平 $\\rho \\in [0,1]$，意味着 $\\boldsymbol{\\xi}^1$ 中有比例为 $\\rho$ 的比特位被翻转以初始化 $s_i(0)$，因此初始重叠度为 $m_0 = 1 - 2\\rho$。一次完整的异步扫描对应于上述映射的一次迭代。\n\n任务：\n- 对于每个指定的 $\\rho$，从 $m_0 = 1 - 2\\rho$ 开始，使用 $\\alpha = p/N$ 迭代映射 $m_{t+1} = \\operatorname{erf}\\big(m_t / \\sqrt{2 \\alpha}\\big)$，直到重叠度超过目标阈值 $m_t > 0.9$，并报告达到此条件所需的异步扫描次数 $t$。\n- 如果 $m_0 \\leq 0$，或者如果在最多 $T_{\\max} = 1000$ 次扫描内 $m_t$ 从未超过 $0.9$，则报告 $-1$。\n- 使用 $N=1000$ 和 $p=50$ 来计算 $\\alpha = p/N$。\n\n测试集：\n- 使用以下初始损坏水平 $\\rho$ 集合：$\\{0, 0.05, 0.1, 0.2, 0.3, 0.495, 0.51\\}$。\n\n答案类型：\n- 对于每个 $\\rho$，答案必须是一个整数，表示达到 $m_t > 0.9$ 所需的异步扫描次数；如果未能在 $T_{\\max} = 1000$ 次扫描内达到该阈值，则为 $-1$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与 $\\rho$ 的测试集顺序相同。例如，输出应类似于 $[a_1,a_2,a_3,a_4,a_5,a_6,a_7]$，其中每个 $a_k$ 是对应于测试集中第 $k$ 个 $\\rho$ 的整数结果。",
            "solution": "该问题要求我们确定一个 Hopfield 网络 (HN) 从一个损坏的目标模式版本开始，需要多少次异步扫描才能恢复该模式。该动力学过程通过一个为宏观重叠度建立的、且行之有效的迭代映射来建模，该映射源自对网络行为的平均场近似。\n\n### 基于原理的设计\n\n1.  **系统定义**：该系统是一个由 $N=1000$ 个二元神经元 $s_i \\in \\{-1, +1\\}$ 组成的 Hopfield 网络，设计用于存储 $p=50$ 个随机二元模式 $\\boldsymbol{\\xi}^\\mu$。\n\n2.  **宏观序参量**：在给定时间，整个网络的状态不是逐个神经元跟踪的。相反，它由一个称为重叠度 $m_t$ 的单一宏观变量来表征。重叠度衡量当前网络状态 $\\boldsymbol{s}(t)$ 与我们标记为 $\\boldsymbol{\\xi}^1$ 的特定目标模式之间的相似性。它被定义为相应神经元状态乘积的平均值：\n    $$\n    m_t = \\frac{1}{N} \\sum_{i=1}^{N} \\xi_i^1 s_i(t)\n    $$\n    重叠度 $m_t=1$ 意味着网络状态与目标模式完全相同，$m_t=-1$ 意味着它是完全相反的模式，而 $m_t=0$ 则意味着没有相关性。\n\n3.  **初始状态与损坏**：网络被初始化为一个目标模式 $\\boldsymbol{\\xi}^1$ 的损坏版本。其中比例为 $\\rho$ 的神经元状态被翻转。如果神经元 $i$ 的状态 $s_i$ 从 $\\xi_i^1$ 翻转为 $-\\xi_i^1$，其对重叠度总和的贡献 $\\xi_i^1 s_i$ 从 $+1$ 变为 $-1$，净变化为 $-2$。当 $N$ 个神经元中有比例为 $\\rho$ 的被翻转时，重叠度总和减少了 $N \\rho \\times 2$。因此，平均重叠度从其理想值 $1$ 减少了 $2\\rho$。这给出了初始重叠度：\n    $$\n    m_0 = 1 - 2\\rho\n    $$\n\n4.  **回忆动力学（平均场近似）**：网络状态的演化由异步更新规则控制，其中每个神经元的状态根据其局部场进行更新。在大量神经元（$N \\to \\infty$）的极限下，其他存储模式（$\\mu = 2, \\dots, p$）对某个神经元局部场的集体效应可以近似为高斯噪声（即“串扰噪声”），这是中心极限定理的一个推论。该噪声的方差与网络负载 $\\alpha = p/N$ 成正比。\n\n    在此近似下，宏观重叠度从一次完整的异步扫描（$t$）到下一次（$t+1$）的演化不是随机的，而是遵循一个确定性的迭代映射：\n    $$\n    m_{t+1} = \\operatorname{erf}\\left(\\frac{m_t}{\\sqrt{2 \\alpha}}\\right)\n    $$\n    这里，$\\operatorname{erf}(\\cdot)$ 是高斯误差函数，它源于对高斯噪声分布进行积分，以求得神经元与目标模式正确对齐的概率。`erf` 函数的参数代表信噪比，其中 $m_t$ 是信号强度，$\\sqrt{\\alpha}$ 与噪声标准差成正比。\n\n5.  **算法求解**：任务是找到重叠度 $m_t$ 超过阈值 $0.9$ 所需的扫描次数 $t$。这可以通过直接迭代该映射来解决。\n\n    - 首先，我们计算常数参数：负载 $\\alpha = p/N = 50/1000 = 0.05$。`erf` 参数分母中的项是 $\\sqrt{2\\alpha} = \\sqrt{2 \\times 0.05} = \\sqrt{0.1}$。\n\n    - 对于测试集 $\\{0, 0.05, 0.1, 0.2, 0.3, 0.495, 0.51\\}$ 中给定的每个初始损坏水平 $\\rho$，我们计算初始重叠度 $m_0 = 1 - 2\\rho$。\n\n    - 然后我们应用模拟逻辑：\n        a. 如果 $m_0 \\leq 0$，则模式恢复是不可能的，因为初始状态与目标没有正相关（或呈反相关）。动力学将使重叠度趋向于 $0$ 或一个负的不动点。在这种情况下，根据问题规则我们报告 $-1$。\n        b. 如果 $m_0 > 0$，我们开始迭代。我们初始化一个扫描计数器 $t=0$。\n        c. 我们检查条件 $m_t > 0.9$。\n        d. 如果当前 $t$ 满足条件，我们记录 $t$ 作为结果并停止。必须从 $t=0$ 开始对初始状态 $m_0$ 进行检查。\n        e. 如果条件不满足，并且我们没有超过最大扫描次数（$t  T_{\\max}=1000$），我们计算下一个重叠度 $m_{t+1} = \\operatorname{erf}(m_t / \\sqrt{2\\alpha})$ 并将扫描计数器增加 $t \\to t+1$。\n        f. 如果循环在 $T_{\\max}$ 次扫描后重叠度仍未超过 $0.9$，我们报告 $-1$。这意味着检查了状态 $m_0, m_1, \\dots, m_{1000}$。\n\n对测试集中的每个 $\\rho$ 值执行此过程，以生成最终的结果列表。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Calculates the number of sweeps required for a Hopfield Network's overlap\n    to exceed a threshold, based on an iterative map derived from mean-field theory.\n    \"\"\"\n    \n    # Define the parameters from the problem statement.\n    N = 1000\n    p = 50\n    T_max = 1000\n    m_threshold = 0.9\n    \n    # Define the test suite of initial corruption levels rho.\n    test_cases = [0, 0.05, 0.1, 0.2, 0.3, 0.495, 0.51]\n    \n    # Calculate the network load alpha\n    alpha = p / N\n    \n    # Pre-calculate the constant denominator for the erf argument\n    # for improved efficiency inside the loop.\n    denominator = np.sqrt(2 * alpha)\n\n    results = []\n    for rho in test_cases:\n        # Calculate the initial overlap m_0 from the corruption level rho.\n        m_0 = 1 - 2 * rho\n        \n        # If the initial overlap is non-positive, retrieval fails immediately.\n        if m_0 = 0:\n            results.append(-1)\n            continue\n            \n        m = m_0\n        converged = False\n        \n        # Iterate through sweeps from t=0 up to T_max.\n        # The loop runs T_max + 1 times to check states m_0, m_1, ..., m_T_max.\n        for t in range(T_max + 1):\n            # Check if the overlap exceeds the target threshold.\n            if m  m_threshold:\n                results.append(t)\n                converged = True\n                break\n            \n            # Update the overlap for the next sweep using the iterative map.\n            # This update is not performed on the last check (t=T_max).\n            if t  T_max:\n                m = erf(m / denominator)\n        \n        # If the loop completes without convergence, report failure.\n        if not converged:\n            results.append(-1)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}