{
    "hands_on_practices": [
        {
            "introduction": "To begin our hands-on exploration, we first seek to build intuition about the fundamental properties of a stable activity bump. This exercise () guides you through an analytical derivation of the bump's width in a simplified, yet powerful, model. By using a sharp threshold nonlinearity, the governing equations become tractable, allowing you to derive a closed-form solution that explicitly links the bump width to network parameters, revealing the core principle of self-consistency where the activity profile generates the very input that sustains it.",
            "id": "4016930",
            "problem": "Consider a continuous neural field representation of a ring attractor on a one-dimensional circle of circumference $2\\pi$, parameterized by an angular coordinate $\\theta \\in (-\\pi,\\pi]$. Let the steady-state synaptic input field $u(\\theta)$ be determined by translationally invariant recurrent interactions and a uniform inhibitory bias according to\n$$\nu(\\theta) = \\int_{-\\pi}^{\\pi} w(\\theta - \\theta')\\,\\phi\\big(u(\\theta')\\big)\\,d\\theta' - h,\n$$\nwhere $w(\\Delta)$ is the synaptic weight kernel and $h>0$ is a constant bias current. Assume the synaptic kernel is purely first Fourier mode,\n$$\nw(\\Delta) = w\\,\\cos(\\Delta),\n$$\nwith $w>0$, and the neuronal response nonlinearity is a threshold function,\n$$\n\\phi(u) = H(u),\n$$\nwhere $H(\\cdot)$ is the Heaviside step function, so that $\\phi(u)=1$ if $u>0$ and $\\phi(u)=0$ if $u\\le 0$. Suppose the network supports a localized stationary “bump” solution centered at some $\\theta_0$ such that $u(\\theta)>0$ for $|\\theta - \\theta_0|<\\alpha$ and $u(\\theta)\\le 0$ for $|\\theta - \\theta_0|\\ge \\alpha$, with $u(\\theta)$ crossing $0$ continuously at the boundaries $\\theta=\\theta_0\\pm\\alpha$. Using this model, derive an exact expression for the bump half-width $\\alpha$ in terms of the parameters $w$ and $h$. Express your answer in radians. No numerical rounding is required; provide a closed-form analytic expression.",
            "solution": "The problem asks for an expression for the bump half-width $\\alpha$ in a specific ring attractor model. The model is defined by the steady-state synaptic input field $u(\\theta)$ on a circle parameterized by $\\theta \\in (-\\pi, \\pi]$.\n\nThe governing equation for the synaptic input is:\n$$\nu(\\theta) = \\int_{-\\pi}^{\\pi} w(\\theta - \\theta')\\,\\phi\\big(u(\\theta')\\big)\\,d\\theta' - h\n$$\nThe problem provides the specific forms for the synaptic weight kernel $w(\\Delta)$ and the neuronal response nonlinearity $\\phi(u)$.\nThe weight kernel is given by:\n$$\nw(\\Delta) = w\\,\\cos(\\Delta)\n$$\nwhere $w>0$.\n\nThe nonlinearity is the Heaviside step function:\n$$\n\\phi(u) = H(u)\n$$\nwhich means $\\phi(u)=1$ for $u>0$ and $\\phi(u)=0$ for $u \\le 0$.\n\nThe network is assumed to support a localized stationary \"bump\" solution. This solution is characterized by a region of activity of half-width $\\alpha$ centered at some angle $\\theta_0$. According to the problem statement, this means:\n$$\nu(\\theta) > 0 \\quad \\text{for } |\\theta - \\theta_0| < \\alpha\n$$\n$$\nu(\\theta) \\le 0 \\quad \\text{for } |\\theta - \\theta_0| \\ge \\alpha\n$$\nFrom this, the value of the firing rate function $\\phi(u(\\theta'))$ is determined:\n$$\n\\phi(u(\\theta')) =\n\\begin{cases}\n1 & \\text{if } |\\theta' - \\theta_0| < \\alpha \\\\\n0 & \\text{if } |\\theta' - \\theta_0| \\ge \\alpha\n\\end{cases}\n$$\nDue to the translational invariance of the kernel $w(\\theta-\\theta')$, we can, without loss of generality, center the bump at $\\theta_0 = 0$. The active region is then the interval $(-\\alpha, \\alpha)$.\n\nSubstituting the expressions for $w(\\Delta)$ and $\\phi(u)$ into the governing integral equation, and adjusting the integration limits to the active region, we get:\n$$\nu(\\theta) = \\int_{-\\alpha}^{\\alpha} w\\,\\cos(\\theta - \\theta') \\cdot 1 \\,d\\theta' - h\n$$\nWe proceed to evaluate this integral:\n$$\nu(\\theta) = w \\int_{-\\alpha}^{\\alpha} \\cos(\\theta - \\theta') \\,d\\theta' - h\n$$\nThe antiderivative of $\\cos(\\theta - \\theta')$ with respect to $\\theta'$ is $-\\sin(\\theta - \\theta')$. Evaluating the definite integral:\n$$\nu(\\theta) = w \\left[ -\\sin(\\theta - \\theta') \\right]_{\\theta'=-\\alpha}^{\\theta'=\\alpha} - h\n$$\n$$\nu(\\theta) = w \\left( (-\\sin(\\theta - \\alpha)) - (-\\sin(\\theta - (-\\alpha))) \\right) - h\n$$\n$$\nu(\\theta) = w \\left( -\\sin(\\theta - \\alpha) + \\sin(\\theta + \\alpha) \\right) - h\n$$\nUsing the trigonometric sum-to-product identity $\\sin(A+B) - \\sin(A-B) = 2\\cos(A)\\sin(B)$, with $A=\\theta$ and $B=\\alpha$:\n$$\nu(\\theta) = w \\left( 2\\cos(\\theta)\\sin(\\alpha) \\right) - h\n$$\nSo, the explicit form for the synaptic input field is:\n$$\nu(\\theta) = 2w\\sin(\\alpha)\\cos(\\theta) - h\n$$\nThe problem states that $u(\\theta)$ crosses $0$ at the boundaries of the bump, which are at $\\theta = \\pm\\alpha$. We apply this boundary condition, for instance at $\\theta = \\alpha$:\n$$\nu(\\alpha) = 0\n$$\n$$\n2w\\sin(\\alpha)\\cos(\\alpha) - h = 0\n$$\nUsing the double-angle identity for sine, $2\\sin(\\alpha)\\cos(\\alpha) = \\sin(2\\alpha)$, we have:\n$$\nw\\sin(2\\alpha) - h = 0\n$$\nThis equation relates the bump half-width $\\alpha$ to the model parameters $w$ and $h$. We can now solve for $\\alpha$.\n$$\nw\\sin(2\\alpha) = h\n$$\n$$\n\\sin(2\\alpha) = \\frac{h}{w}\n$$\nSince $\\alpha$ represents a physical half-width, we must have $\\alpha > 0$. The existence of a solution requires $0 < h/w \\le 1$. Assuming a solution exists as per the problem statement, we can take the inverse sine of both sides.\n$$\n2\\alpha = \\arcsin\\left(\\frac{h}{w}\\right)\n$$\nIsolating $\\alpha$ gives the final expression:\n$$\n\\alpha = \\frac{1}{2}\\arcsin\\left(\\frac{h}{w}\\right)\n$$\nThe result is in radians, as the arcsin function returns a value in radians, which is consistent with the angular parameterization. This expression is the exact closed-form solution for the bump half-width.",
            "answer": "$$\n\\boxed{\\frac{1}{2}\\arcsin\\left(\\frac{h}{w}\\right)}\n$$"
        },
        {
            "introduction": "Moving from analytical theory to computational practice, this exercise () challenges you to simulate the formation of a stable bump from the ground up. You will implement an iterative algorithm to solve the neural field equations for a network with a more realistic Rectified Linear Unit (ReLU) nonlinearity. This hands-on coding task demonstrates how a localized pattern of activity can spontaneously emerge and stabilize from a nearly uniform state, providing direct insight into the dynamic process of pattern formation in attractor networks.",
            "id": "4016951",
            "problem": "Consider a one-dimensional ring attractor neural field model defined on the angle coordinate $\\theta \\in [0,2\\pi)$ with a spatially homogeneous external bias current and a cosine-modulated, phase-shifted synaptic kernel. The steady-state firing rate profile $r(\\theta)$ is modeled by the fixed-point condition\n$$\nr(\\theta) \\;=\\; f\\!\\left( b \\;+\\; \\int_{0}^{2\\pi} W(\\theta - \\theta')\\, r(\\theta')\\, d\\theta' \\right),\n$$\nwhere $f(x)$ is the Rectified Linear Unit (ReLU) nonlinearity with gain $g$, given by $f(x) = \\max(0, g\\,x)$, the stimulus bias $b$ is a constant, and the synaptic kernel is\n$$\nW(\\Delta) \\;=\\; w_0 \\;+\\; w_1 \\cos(\\Delta - \\phi).\n$$\nAll angles must be treated in radians.\n\nStarting from the neural field definition and the properties of circular convolution on the ring, the fixed point can be approximated via iterative substitution on a uniform discretization of $[0,2\\pi)$ with $N$ points, where the integral is approximated by a Riemann sum with step size $\\Delta\\theta = 2\\pi/N$. The iterative scheme is:\n$$\nr^{(n+1)}(\\theta_i) \\;=\\; \\max\\!\\Big(0,\\, g\\Big[ b \\;+\\; \\Delta\\theta \\Big( w_0 \\sum_{j=0}^{N-1} r^{(n)}(\\theta_j) \\;+\\; w_1 \\,\\Re\\!\\Big( e^{i(\\theta_i - \\phi)} \\sum_{j=0}^{N-1} r^{(n)}(\\theta_j) e^{-i\\theta_j} \\Big)\\Big) \\Big]\\Big),\n$$\nfor $i=0,1,\\dots,N-1$, with an initial condition that breaks rotational symmetry. The bump amplitude is defined as the magnitude of the first Fourier mode of the firing rate profile,\n$$\nA \\;=\\; 2\\left|\\frac{1}{N}\\sum_{j=0}^{N-1} r(\\theta_j) e^{-i\\theta_j}\\right|.\n$$\nConvergence must be assessed numerically by monitoring the relative change\n$$\n\\frac{\\| r^{(n+1)} - r^{(n)} \\|_2}{\\| r^{(n)} \\|_2 + \\varepsilon} < \\text{tol},\n$$\nwhere $\\varepsilon$ is a small positive constant to avoid division by zero and $\\text{tol}$ is a prescribed tolerance. To guard against divergence, the iteration should terminate if $\\| r^{(n)} \\|_2$ exceeds a fixed threshold.\n\nFrom first principles of Fourier analysis on the ring and the linear part of the operator, the eigenvalues associated with the zeroth and first Fourier modes of the integral operator $\\int W(\\theta-\\theta')(\\cdot)\\,d\\theta'$ are $2\\pi w_0$ and $\\pi w_1$, respectively. A sufficient contraction condition for global convergence in the linear regime is $g\\,\\rho < 1$, where $\\rho = \\max(|2\\pi w_0|, |\\pi w_1|)$. In the presence of the Rectified Linear Unit (ReLU), the nonlinearity can introduce piecewise linear behavior and bump solutions even when the linear regime is not contractive; numerical assessment is required.\n\nImplement a program that:\n- Discretizes the ring with $N$ equally spaced points.\n- Iteratively computes $r^{(n)}(\\theta)$ using the above update rule until convergence or divergence.\n- On convergence, computes the bump amplitude $A$ as defined above.\n- Outputs, for each test case, a pair $[c,a]$ where $c$ is $1$ if the iteration converges and $0$ otherwise, and $a$ is the bump amplitude rounded to six decimal places (dimensionless). If $c=0$, then $a$ must be $0.0$.\n\nUse the following test suite of parameter values (all angles in radians):\n- Case $1$: $w_0=0.05$, $w_1=0.4$, $\\phi=0.0$, $b=0.02$, $g=0.6$.\n- Case $2$: $w_0=0.05$, $w_1=0.35$, $\\phi=0.7$, $b=0.01$, $g=0.9$.\n- Case $3$: $w_0=0.05$, $w_1=0.35$, $\\phi=0.3$, $b=0.01$, $g=1.1$.\n- Case $4$: $w_0=0.0$, $w_1=0.4$, $\\phi=1.5$, $b=0.02$, $g=0.6$.\n- Case $5$: $w_0=0.1$, $w_1=0.0$, $\\phi=2.0$, $b=0.02$, $g=0.6$.\n\nAlgorithmic requirements:\n- Use $N=512$ and $\\Delta\\theta = 2\\pi/N$.\n- Use an initial condition $r^{(0)}(\\theta_i) = \\delta \\big(1 + \\cos(\\theta_i)\\big)$ with $\\delta = 10^{-6}$.\n- Use $\\text{tol} = 10^{-10}$, $\\varepsilon = 10^{-12}$, a maximum of $2000$ iterations, and a divergence threshold $\\| r^{(n)} \\|_2 > 10^{3}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is the ordered pair for a test case as specified above (for example, $[[1,0.123456],[0,0.0],\\dots]$). Angles must be handled in radians, and amplitudes must be dimensionless floats rounded to six decimal places.",
            "solution": "The problem statement is scientifically and mathematically well-posed, providing a complete and consistent set of definitions, equations, and parameters for simulating a ring attractor neural field model. The model is a standard framework in computational neuroscience used to study phenomena such as spatial working memory and head-direction cells. The provided iterative scheme is a correct numerical discretization of the governing integro-differential equation. All necessary conditions for implementation, including discretization size, initial conditions, and convergence/divergence criteria, are unambiguously specified. The problem is therefore valid.\n\nThe solution is obtained by implementing the specified iterative numerical simulation. We begin by formalizing the discrete system.\n\nThe continuous angular domain $\\theta \\in [0, 2\\pi)$ is discretized into $N$ equidistant points, $\\theta_i = i \\cdot \\Delta\\theta$ for $i = 0, 1, \\dots, N-1$, where the angular step size is $\\Delta\\theta = 2\\pi/N$. The continuous firing rate function $r(\\theta)$ is represented by a vector $\\mathbf{r} \\in \\mathbb{R}^N$, where the $i$-th component is $r_i = r(\\theta_i)$.\n\nThe core of the problem is the fixed-point equation:\n$$\nr(\\theta) \\;=\\; f\\!\\left( b \\;+\\; \\int_{0}^{2\\pi} W(\\theta - \\theta')\\, r(\\theta')\\, d\\theta' \\right)\n$$\nwhere $f(x) = \\max(0, g\\,x)$ and $W(\\Delta) = w_0 + w_1 \\cos(\\Delta - \\phi)$.\n\nThe integral term represents a circular convolution of the kernel $W$ with the firing rate profile $r$. The problem provides the correct discrete approximation of this integral, leading to the iterative update rule for the vector $\\mathbf{r}^{(n)}$ at iteration $n$. Let's analyze the terms within the update rule for efficient computation.\n$$\nr_{i}^{(n+1)} \\;=\\; \\max\\!\\Big(0,\\, g\\Big[ b \\;+\\; \\Delta\\theta \\Big( w_0 \\sum_{j=0}^{N-1} r_{j}^{(n)} \\;+\\; w_1 \\,\\Re\\!\\Big( e^{\\mathrm{i}(\\theta_i - \\phi)} \\sum_{j=0}^{N-1} r_{j}^{(n)} e^{-\\mathrm{i}\\theta_j} \\Big)\\Big) \\Big]\\Big)\n$$\nThe two sums can be pre-calculated at each iteration step:\n$1$. The total activity, $S_0 = \\sum_{j=0}^{N-1} r_{j}^{(n)}$. This is a scalar value.\n$2$. The unnormalized first complex Fourier mode, $S_1 = \\sum_{j=0}^{N-1} r_{j}^{(n)} e^{-\\mathrm{i}\\theta_j}$. This is a complex scalar value.\n\nSubstituting these into the update rule, we get the expression for the input to the $i$-th neuron:\n$$\nx_i^{(n)} = b \\;+\\; \\Delta\\theta \\left( w_0 S_0 \\;+\\; w_1 \\Re\\left( S_1 e^{\\mathrm{i}(\\theta_i - \\phi)} \\right) \\right)\n$$\nThe update for the entire firing rate vector $\\mathbf{r}$ can then be written as:\n$$\n\\mathbf{r}^{(n+1)} = \\max(0, g \\, \\mathbf{x}^{(n)})\n$$\nwhere $\\mathbf{x}^{(n)}$ is the vector with components $x_i^{(n)}$, and the $\\max$ operation is performed element-wise. This vector formulation is highly suitable for implementation using numerical libraries like NumPy.\n\nThe simulation proceeds as follows:\n$1$. **Initialization**: The angular grid $\\mathbf{\\theta}$ is created with $N=512$ points. The firing rate vector $\\mathbf{r}^{(0)}$ is initialized according to $r^{(0)}(\\theta_i) = \\delta (1 + \\cos(\\theta_i))$ with $\\delta = 10^{-6}$. This small, non-uniform initial activity is necessary to break the rotational symmetry of the system and allow a localized bump of activity to form.\n$2$. **Iteration**: The simulation iterates the update rule for a maximum of $2000$ steps. In each step $n$:\n    a. The current rate vector $\\mathbf{r}^{(n)}$ is stored.\n    b. The scalars $S_0$ and $S_1$ are computed from $\\mathbf{r}^{(n)}$.\n    c. The input vector $\\mathbf{x}^{(n)}$ is calculated.\n    d. The new rate vector $\\mathbf{r}^{(n+1)}$ is computed by applying the ReLU activation function.\n    e. **Divergence Check**: The L2 norm, $\\|\\mathbf{r}^{(n+1)}\\|_2$, is calculated. If it exceeds the threshold $10^3$, the simulation is terminated, and the result is marked as non-convergent ($c=0$).\n    f. **Convergence Check**: The relative change in the L2 norm, $\\frac{\\| \\mathbf{r}^{(n+1)} - \\mathbf{r}^{(n)} \\|_2}{\\| \\mathbf{r}^{(n)} \\|_2 + \\varepsilon}$, is calculated. If it falls below the tolerance $\\text{tol} = 10^{-10}$ (with $\\varepsilon = 10^{-12}$ for numerical stability), the simulation has converged ($c=1$).\n$3$. **Termination**: If the loop completes the maximum number of iterations without meeting the convergence criterion, the simulation is also considered non-convergent ($c=0$).\n$4$. **Amplitude Calculation**: If the simulation converges ($c=1$), the bump amplitude $A$ is calculated using the steady-state firing rate profile $\\mathbf{r}_{\\text{final}}$:\n$$\nA \\;=\\; 2\\left|\\frac{1}{N}\\sum_{j=0}^{N-1} r_{\\text{final}}(\\theta_j) e^{-\\mathrm{i}\\theta_j}\\right| \\;=\\; \\frac{2}{N} \\left| S_{1, \\text{final}} \\right|\n$$\nThe result is rounded to six decimal places. If the simulation did not converge, the amplitude is set to $a=0.0$.\n\nThis entire procedure is applied to each of the five test cases provided.",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the ring attractor model problem for a given set of test cases.\n    \"\"\"\n\n    def simulate_ring_attractor(params):\n        \"\"\"\n        Simulates a single instance of the ring attractor model.\n\n        Args:\n            params (dict): A dictionary containing model parameters w0, w1, phi, b, g.\n\n        Returns:\n            list: A list [c, a] where c is the convergence flag (1 or 0) and a is\n                  the rounded bump amplitude or 0.0 for non-convergence.\n        \"\"\"\n        # Algorithmic requirements\n        N = 512\n        delta = 1e-6\n        tol = 1e-10\n        epsilon = 1e-12\n        max_iter = 2000\n        divergence_thresh = 1e3\n\n        # Unpack parameters\n        w0, w1, phi, b, g = params['w0'], params['w1'], params['phi'], params['b'], params['g']\n\n        # Discretize the ring\n        delta_theta = 2 * np.pi / N\n        theta = np.linspace(0, 2 * np.pi, N, endpoint=False)\n        \n        # Initial condition to break rotational symmetry\n        r_n = delta * (1 + np.cos(theta))\n\n        # Complex exponential factor for Fourier mode calculation\n        exp_neg_i_theta = np.exp(-1j * theta)\n        \n        # Complex exponential factor for the kernel evaluation\n        exp_i_theta_minus_phi = np.exp(1j * (theta - phi))\n\n        for _ in range(max_iter):\n            r_prev = r_n\n\n            # Calculate the zeroth and first order Fourier components\n            s0 = np.sum(r_n)\n            s1 = np.sum(r_n * exp_neg_i_theta)\n\n            # Calculate the input to the nonlinearity\n            kernel_input = delta_theta * (w0 * s0 + w1 * np.real(exp_i_theta_minus_phi * s1))\n            x = b + kernel_input\n\n            # Apply the ReLU nonlinearity\n            r_n = np.maximum(0, g * x)\n\n            # Check for divergence\n            norm_r_n = np.linalg.norm(r_n)\n            if norm_r_n > divergence_thresh:\n                return [0, 0.0]\n\n            # Check for convergence\n            norm_r_prev = np.linalg.norm(r_prev)\n            diff_norm = np.linalg.norm(r_n - r_prev)\n            \n            if diff_norm / (norm_r_prev + epsilon) < tol:\n                # Converged: calculate bump amplitude\n                s1_final = np.sum(r_n * exp_neg_i_theta)\n                A = 2 * np.abs(s1_final) / N\n                return [1, round(A, 6)]\n\n        # Did not converge within max_iter\n        return [0, 0.0]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'w0': 0.05, 'w1': 0.4, 'phi': 0.0, 'b': 0.02, 'g': 0.6},   # Case 1\n        {'w0': 0.05, 'w1': 0.35, 'phi': 0.7, 'b': 0.01, 'g': 0.9},  # Case 2\n        {'w0': 0.05, 'w1': 0.35, 'phi': 0.3, 'b': 0.01, 'g': 1.1},  # Case 3\n        {'w0': 0.0, 'w1': 0.4, 'phi': 1.5, 'b': 0.02, 'g': 0.6},   # Case 4\n        {'w0': 0.1, 'w1': 0.0, 'phi': 2.0, 'b': 0.02, 'g': 0.6},   # Case 5\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = simulate_ring_attractor(case_params)\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # Each result is a [c, a] pair, which needs to be formatted to '[c,a.######]'\n    formatted_results = [f\"[{c},{a:.6f}]\" for c, a in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Real neural systems are inherently noisy. Our final practice () addresses the functional consequences of this noise on the stability of a ring attractor's memory. You will explore how microscopic noise at the single-neuron level translates into a macroscopic random drift of the activity bump along the attractor manifold, a phenomenon known as angular diffusion. By deriving and applying the effective diffusion coefficient, you will quantify the precision of the network's representation and understand the trade-offs that govern its ability to function as a reliable integrator or memory store.",
            "id": "4016944",
            "problem": "Consider a one-dimensional continuous ring attractor network that supports a localized \"bump\" of activity whose center can be parameterized by an angle $\\,\\theta(t)\\,$ on the circle. The neural population is indexed by a preferred angle $\\,\\phi \\in [0, 2\\pi)\\,$. The firing-rate dynamics are modeled, in the continuum limit, by a first-order linear time-invariant equation with a synaptic kernel that is translation-invariant on the ring and an additive Gaussian white-noise drive. Let the stationary bump profile be well approximated by the first Fourier mode $\\,r^*(\\phi - \\theta) = R_0 + R_1 \\cos(\\phi - \\theta)\\,$, where $\\,R_0\\,$ and $\\,R_1\\,$ are positive constants. The temporal dynamics have a single-neuron time constant $\\,\\tau > 0\\,$ and a per-neuron independent white-noise drive $\\,\\eta_i(t)\\,$ with zero mean and intensity $\\,q\\,$ such that $\\,\\mathbb{E}[\\eta_i(t)\\eta_j(t')] = q \\,\\delta_{ij}\\,\\delta(t-t')\\,$, where $\\,i,j \\in \\{1,\\dots,N\\}\\,$ index $\\,N\\,$ neurons uniformly spaced on the ring. Assume the synaptic kernel is self-adjoint in the continuum limit so that the translation mode is neutrally stable.\n\nA velocity-modulated external drive produces a phase evolution with an effective gain $\\,k\\,$ so that the input angular velocity $\\,\\omega\\,$ induces a deterministic drift contribution $\\,k\\,\\omega\\,$ to the phase velocity. Over a finite time window of duration $\\,T > 0\\,$, model the emergent phase dynamics by a stochastic differential equation of the form\n$$\nd\\theta(t) = k\\,\\omega\\,dt + \\sqrt{2D}\\,dW_t,\n$$\nwhere $\\,D\\,$ is the effective angular diffusion coefficient and $\\,W_t\\,$ is a standard Wiener process. You may assume that angle wrap-around does not occur over the time windows considered.\n\nYour tasks are:\n- Starting from the firing-rate dynamics, the bump ansatz $\\,r^*(\\phi-\\theta)\\,$, and the self-adjointness of the linearized operator around the bump, derive the effective diffusion coefficient $\\,D\\,$ of the phase variable $\\,\\theta(t)\\,$ in terms of $\\,N\\,$, $\\,\\tau\\,$, $\\,R_1\\,$, and $\\,q\\,$, by projecting the independent per-neuron noise onto the translation (Goldstone) mode. Express $\\,D\\,$ in units of $\\text{radians}^2/\\text{second}$.\n- Using the derived $\\,D\\,$, compute over a window of length $\\,T\\,$ the following quantities:\n  1. The expected deterministic angular drift magnitude, $\\,|k\\,\\omega\\,T|\\,$, in $\\text{radians}$.\n  2. The standard deviation of the stochastic angular drift, $\\,\\sqrt{2DT}\\,$, in $\\text{radians}$.\n  3. The expected root-mean-square tracking error with respect to a stimulus angle $\\,\\theta_s(T) = \\omega T\\,$, defined as\n     $$\n     \\mathrm{RMSE}(T) = \\sqrt{\\big((k-1)\\,\\omega\\,T\\big)^2 + 2DT},\n     $$\n     in $\\text{radians}$.\n  4. The probability that the absolute tracking error at time $\\,T\\,$ is within a tolerance $\\,\\delta\\,$, namely $\\,\\mathbb{P}\\big(|\\theta(T)-\\theta_s(T)| \\le \\delta\\big)\\,$, treated under the Gaussian approximation of the error distribution. Express this probability as a decimal in $[0,1]$.\n\nAll angles must be expressed in $\\text{radians}$, all time quantities in $\\text{seconds}$, and probabilities as decimals.\n\nYour program must implement the above computations and produce results for the following test suite of parameter sets $\\,\\{(N,\\tau,R_1,q,\\omega,k,T,\\delta)\\}\\,$:\n\n- Test case 1 (general case): $\\,N=1000\\,$, $\\,\\tau=0.02\\,$, $\\,R_1=8\\,$, $\\,q=1.0\\,$, $\\,\\omega=0.5\\,$, $\\,k=1.0\\,$, $\\,T=1.0\\,$, $\\,\\delta=0.2\\,$.\n- Test case 2 (zero noise, miscalibrated gain boundary): $\\,N=1200\\,$, $\\,\\tau=0.02\\,$, $\\,R_1=10\\,$, $\\,q=0.0\\,$, $\\,\\omega=0.3\\,$, $\\,k=0.9\\,$, $\\,T=2.0\\,$, $\\,\\delta=0.05\\,$.\n- Test case 3 (high noise, static stimulus): $\\,N=200\\,$, $\\,\\tau=0.05\\,$, $\\,R_1=6\\,$, $\\,q=4.0\\,$, $\\,\\omega=0.0\\,$, $\\,k=1.0\\,$, $\\,T=1.5\\,$, $\\,\\delta=0.4\\,$.\n- Test case 4 (large network, strong bump, over-gain): $\\,N=5000\\,$, $\\,\\tau=0.01\\,$, $\\,R_1=15\\,$, $\\,q=0.5\\,$, $\\,\\omega=1.2\\,$, $\\,k=1.05\\,$, $\\,T=0.75\\,$, $\\,\\delta=0.3\\,$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a sublist of four values $[|k\\omega T|,\\sqrt{2DT},\\mathrm{RMSE}(T),\\mathbb{P}(|\\theta(T)-\\theta_s(T)| \\le \\delta)]$. For example, the output format must look like\n$$\n[\\,[d_1,s_1,r_1,p_1],[d_2,s_2,r_2,p_2],[d_3,s_3,r_3,p_3],[d_4,s_4,r_4,p_4]\\,].\n$$",
            "solution": "The problem is subjected to validation.\n\n**Step 1: Extract Givens**\n-   **System**: One-dimensional continuous ring attractor network.\n-   **Phase Variable**: $\\theta(t)$, center of an activity bump.\n-   **Neural Population Index**: Preferred angle $\\phi \\in [0, 2\\pi)$.\n-   **Dynamics**: First-order linear time-invariant equation for firing rates.\n-   **Synaptic Kernel**: Translation-invariant and self-adjoint in the continuum limit.\n-   **Stationary Bump Ansatz**: $r^*(\\phi - \\theta) = R_0 + R_1 \\cos(\\phi - \\theta)$, with $R_0, R_1 > 0$.\n-   **Time Constant**: $\\tau > 0$.\n-   **Noise**: Independent per-neuron Gaussian white noise $\\eta_i(t)$ with zero mean and intensity $q$.\n-   **Noise Correlation**: $\\mathbb{E}[\\eta_i(t)\\eta_j(t')] = q \\,\\delta_{ij}\\,\\delta(t-t')$.\n-   **Neuron Count**: $N$ neurons, uniformly spaced.\n-   **Stability**: The translation (Goldstone) mode is neutrally stable.\n-   **External Drive**: Velocity-modulated with gain $k$ and input angular velocity $\\omega$.\n-   **Phase Dynamics SDE**: $d\\theta(t) = k\\,\\omega\\,dt + \\sqrt{2D}\\,dW_t$, where $W_t$ is a standard Wiener process.\n-   **Assumption**: No angle wrap-around over the observation time window of duration $T$.\n-   **Task 1**: Derive the effective diffusion coefficient $D$ in terms of $N$, $\\tau$, $R_1$, and $q$.\n-   **Task 2**: Compute four specific quantities:\n    1.  Expected deterministic angular drift magnitude: $|k\\,\\omega\\,T|$.\n    2.  Standard deviation of stochastic angular drift: $\\sqrt{2DT}$.\n    3.  RMS tracking error: $\\mathrm{RMSE}(T) = \\sqrt{\\big((k-1)\\,\\omega\\,T\\big)^2 + 2DT}$ with respect to $\\theta_s(T) = \\omega T$.\n    4.  Probability of error tolerance: $\\mathbb{P}\\big(|\\theta(T)-\\theta_s(T)| \\le \\delta\\big)$.\n-   **Parameter Sets**: Four test cases for $(N,\\tau,R_1,q,\\omega,k,T,\\delta)$ are provided.\n-   **Output Format**: A list of lists, `[[d1,s1,r1,p1],[d2,s2,r2,p2],...]`.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded**: The problem describes a standard, albeit simplified, model of a ring attractor network, a cornerstone of theoretical and computational neuroscience for explaining head direction, spatial navigation, and working memory. The formulation using a phase variable, a Goldstone mode, and projection of noise is a canonical approach. The model is scientifically sound.\n-   **Well-Posed**: The problem is well-posed. It asks for a derivation of a physical parameter ($D$) based on the microscopic model, a standard task in statistical physics and neuroscience. The subsequent calculations are direct applications of the derived parameter and basic principles of stochastic calculus and statistics. All necessary information is provided to achieve a unique solution.\n-   **Objective**: The problem is stated in precise, objective, mathematical language, free from ambiguity or subjective content.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is a well-defined theoretical exercise in computational neuroscience, grounded in established principles. I will now proceed with the solution.\n\nThe solution is divided into two parts: first, the derivation of the angular diffusion coefficient $D$, and second, the computation of the required quantities.\n\n**Part 1: Derivation of the Angular Diffusion Coefficient $D$**\n\nThe state of the network is described by the firing rates of $N$ neurons, denoted by the vector $\\mathbf{r}(t) = (r_1(t), \\dots, r_N(t))^T$. The dynamics are governed by a system of Langevin equations, which can be written generically as:\n$$\n\\tau \\frac{d\\mathbf{r}}{dt} = \\mathbf{F}(\\mathbf{r}) + \\boldsymbol{\\eta}(t)\n$$\nwhere $\\tau$ is the single-neuron time constant, $\\mathbf{F}(\\mathbf{r})$ represents the deterministic part of the dynamics (self-couplings, synaptic interactions, and external inputs), and $\\boldsymbol{\\eta}(t)$ is the vector of independent white noise terms with $\\mathbb{E}[\\eta_i(t)\\eta_j(t')] = q\\,\\delta_{ij}\\,\\delta(t-t')$.\n\nDue to the translation-invariant connectivity, the network possesses a continuous family of stationary states (an attractor manifold), which are localized \"bumps\" of activity. These states, $\\mathbf{r}^*$, can be parameterized by the phase angle $\\theta$. The problem provides the ansatz for the bump profile in the continuum limit: $r^*(\\phi - \\theta) = R_0 + R_1 \\cos(\\phi - \\theta)$. For $N$ discrete neurons with preferred angles $\\phi_i = 2\\pi(i-1)/N$, the stationary firing rate of neuron $i$ is $r_i^*(\\theta) = R_0 + R_1 \\cos(\\phi_i - \\theta)$.\n\nThe effect of noise is to cause the system's state to diffuse along the attractor manifold. This diffusion corresponds to a random walk of the phase $\\theta(t)$. To find the dynamics of $\\theta(t)$, we project the noise term $\\boldsymbol{\\eta}(t)$ onto the direction of translation along the attractor. This direction is given by the \"Goldstone mode,\" which is the tangent vector to the manifold:\n$$\n\\mathbf{u}_0(\\theta) = \\frac{d\\mathbf{r}^*(\\theta)}{d\\theta}\n$$\nThe $i$-th component of this vector is:\n$$\nu_{0,i}(\\theta) = \\frac{d}{d\\theta} \\left( R_0 + R_1 \\cos(\\phi_i - \\theta) \\right) = R_1 \\sin(\\phi_i - \\theta)\n$$\nThe evolution of the phase $\\theta$ due to the noise is determined by projecting the neural dynamics onto the null left-eigenvector of the linearized dynamics matrix. The problem states the synaptic kernel is self-adjoint, which implies that the left and right eigenvectors are identical. The null eigenvector is the Goldstone mode $\\mathbf{u}_0(\\theta)$. The projection yields the stochastic differential equation for $\\theta$ (in the absence of deterministic drift):\n$$\n\\frac{d\\theta}{dt} = \\frac{\\mathbf{u}_0(\\theta) \\cdot \\boldsymbol{\\eta}(t)}{\\tau ||\\mathbf{u}_0(\\theta)||^2}\n$$\nThe effective noise driving the phase is $\\xi(t) = \\frac{d\\theta}{dt}$. We compare this to the form $d\\theta = \\sqrt{2D} dW_t$, which implies that $\\mathbb{E}[\\xi(t)\\xi(t')] = 2D \\delta(t-t')$. Let's compute the autocorrelation of our derived $\\xi(t)$:\n$$\n\\mathbb{E}[\\xi(t)\\xi(t')] = \\mathbb{E}\\left[ \\left(\\frac{\\sum_i u_{0,i} \\eta_i(t)}{\\tau ||\\mathbf{u}_0||^2}\\right) \\left(\\frac{\\sum_j u_{0,j} \\eta_j(t')}{\\tau ||\\mathbf{u}_0||^2}\\right) \\right] = \\frac{1}{\\tau^2 ( ||\\mathbf{u}_0||^2 )^2} \\sum_{i,j} u_{0,i} u_{0,j} \\mathbb{E}[\\eta_i(t)\\eta_j(t')]\n$$\nSubstituting the noise correlation $\\mathbb{E}[\\eta_i(t)\\eta_j(t')] = q \\delta_{ij} \\delta(t-t')$:\n$$\n\\mathbb{E}[\\xi(t)\\xi(t')] = \\frac{q \\delta(t-t')}{\\tau^2 ( ||\\mathbf{u}_0||^2 )^2} \\sum_{i,j} u_{0,i} u_{0,j} \\delta_{ij} = \\frac{q \\delta(t-t')}{\\tau^2 ( ||\\mathbf{u}_0||^2 )^2} \\sum_i u_{0,i}^2 = \\frac{q \\delta(t-t')}{\\tau^2 ||\\mathbf{u}_0||^2}\n$$\nBy comparing this with $\\mathbb{E}[\\xi(t)\\xi(t')] = 2D \\delta(t-t')$, we find:\n$$\n2D = \\frac{q}{\\tau^2 ||\\mathbf{u}_0||^2} \\implies D = \\frac{q}{2\\tau^2 ||\\mathbf{u}_0||^2}\n$$\nThe final step is to compute the squared norm of the Goldstone mode, $||\\mathbf{u}_0||^2 = \\sum_{i=1}^N u_{0,i}^2$:\n$$\n||\\mathbf{u}_0||^2 = \\sum_{i=1}^N \\left( R_1 \\sin(\\phi_i - \\theta) \\right)^2 = R_1^2 \\sum_{i=1}^N \\sin^2(\\phi_i - \\theta)\n$$\nFor neurons uniformly distributed on a ring, the sum $\\sum_{i=1}^N \\sin^2(x + 2\\pi (i-1)/N)$ is a standard trigonometric sum. For any $x$ and $N>2$, this sum evaluates to $N/2$. Thus:\n$$\n||\\mathbf{u}_0||^2 = R_1^2 \\frac{N}{2}\n$$\nSubstituting this into the expression for $D$:\n$$\nD = \\frac{q}{2\\tau^2 \\left( R_1^2 \\frac{N}{2} \\right)} = \\frac{q}{N \\tau^2 R_1^2}\n$$\nThis is the desired expression for the effective angular diffusion coefficient, with units of $\\text{radians}^2/\\text{second}$.\n\n**Part 2: Computation of Derived Quantities**\n\nWith the formula for $D$ established, we can compute the four required quantities for each parameter set.\n\n1.  **Expected deterministic angular drift magnitude**: The SDE $d\\theta(t) = k\\,\\omega\\,dt + \\sqrt{2D}\\,dW_t$ shows that the deterministic part of the evolution is $d\\theta_{det} = k\\omega dt$. Integrating over a time window of duration $T$, the total deterministic drift is $\\Delta\\theta_{det} = k\\omega T$. The magnitude is $|k\\omega T|$.\n\n2.  **Standard deviation of stochastic angular drift**: The stochastic part of the evolution is $d\\theta_{stoch} = \\sqrt{2D} dW_t$. The total stochastic drift at time $T$ is the Itô integral $\\Delta\\theta_{stoch}(T) = \\int_0^T \\sqrt{2D} dW_t = \\sqrt{2D} W_T$. The Wiener process $W_T$ is a Gaussian random variable with mean $0$ and variance $T$. Thus, $\\Delta\\theta_{stoch}(T)$ is a Gaussian random variable with mean $\\mathbb{E}[\\Delta\\theta_{stoch}(T)] = 0$ and variance $\\text{Var}(\\Delta\\theta_{stoch}(T)) = \\mathbb{E}[(\\sqrt{2D} W_T)^2] = 2D \\mathbb{E}[W_T^2] = 2DT$. The standard deviation is the square root of the variance, $\\sigma_{stoch}(T) = \\sqrt{2DT}$.\n\n3.  **Root-mean-square tracking error**: The tracking error is defined as $E(T) = \\theta(T) - \\theta_s(T)$, where $\\theta_s(T) = \\omega T$. Assuming $\\theta(0) = \\theta_s(0) = 0$, the solution to the SDE is $\\theta(T) = k\\omega T + \\sqrt{2D}W_T$. The error is:\n    $$\n    E(T) = (k\\omega T + \\sqrt{2D}W_T) - \\omega T = (k-1)\\omega T + \\sqrt{2D}W_T\n    $$\n    The error $E(T)$ is a Gaussian random variable. Its mean (bias) is $\\mu_E = \\mathbb{E}[E(T)] = (k-1)\\omega T$. Its variance is $\\sigma_E^2 = \\text{Var}(E(T)) = 2DT$. The mean-squared error (MSE) is $\\mathbb{E}[E(T)^2] = (\\mu_E)^2 + \\sigma_E^2$. The root-mean-square error (RMSE) is:\n    $$\n    \\mathrm{RMSE}(T) = \\sqrt{\\mathbb{E}[E(T)^2]} = \\sqrt{((k-1)\\omega T)^2 + 2DT}\n    $$\n    This matches the formula provided in the problem statement.\n\n4.  **Probability of tracking error within tolerance**: We need to compute $\\mathbb{P}(|E(T)| \\le \\delta)$. Since $E(T) \\sim \\mathcal{N}(\\mu_E, \\sigma_E^2)$, we can standardize the variable. Let $Z = (E(T) - \\mu_E)/\\sigma_E \\sim \\mathcal{N}(0,1)$.\n    $$\n    \\mathbb{P}(-\\delta \\le E(T) \\le \\delta) = \\mathbb{P}\\left(\\frac{-\\delta - \\mu_E}{\\sigma_E} \\le Z \\le \\frac{\\delta - \\mu_E}{\\sigma_E}\\right)\n    $$\n    This probability is given by the difference of the cumulative distribution function (CDF) of the standard normal distribution, $\\Phi(z)$:\n    $$\n    P = \\Phi\\left(\\frac{\\delta - \\mu_E}{\\sigma_E}\\right) - \\Phi\\left(\\frac{-\\delta - \\mu_E}{\\sigma_E}\\right)\n    $$\n    where $\\mu_E=(k-1)\\omega T$ and $\\sigma_E=\\sqrt{2DT}$. The CDF can be computed using the error function, $\\text{erf}(x)$, as $\\Phi(z) = \\frac{1}{2}(1 + \\text{erf}(z/\\sqrt{2}))$. This leads to:\n    $$\n    P = \\frac{1}{2}\\left[\\text{erf}\\left(\\frac{\\delta - \\mu_E}{\\sigma_E\\sqrt{2}}\\right) - \\text{erf}\\left(\\frac{-\\delta - \\mu_E}{\\sigma_E\\sqrt{2}}\\right)\\right]\n    $$\n    If the noise intensity $q=0$, then $D=0$ and $\\sigma_E = 0$. In this case, the error is deterministic, $E(T) = \\mu_E$. The probability is $1$ if $|\\mu_E| \\le \\delta$ and $0$ otherwise.\n\nThe implementation will compute these four quantities for each test case.",
            "answer": "```python\nimport numpy as np\nfrom scipy.special import erf\n\ndef solve():\n    \"\"\"\n    Solves the ring attractor problem for the given test cases.\n    It first calculates the diffusion coefficient D and then computes\n    the four required metrics: deterministic drift, stochastic drift standard\n    deviation, RMSE, and the probability of the tracking error being within\n    a tolerance.\n    \"\"\"\n    test_cases = [\n        # (N, tau, R1, q, omega, k, T, delta)\n        (1000, 0.02, 8., 1.0, 0.5, 1.0, 1.0, 0.2),   # Test case 1\n        (1200, 0.02, 10., 0.0, 0.3, 0.9, 2.0, 0.05),  # Test case 2\n        (200, 0.05, 6., 4.0, 0.0, 1.0, 1.5, 0.4),    # Test case 3\n        (5000, 0.01, 15., 0.5, 1.2, 1.05, 0.75, 0.3)  # Test case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        N, tau, R1, q, omega, k, T, delta = case\n\n        # Derived formula for the angular diffusion coefficient D.\n        # D = q / (N * tau^2 * R1^2)\n        # Denominator will not be zero based on problem constraints (N>0, tau>0, R1>0)\n        # but q can be zero.\n        if q == 0.0:\n            D = 0.0\n        else:\n            D = q / (N * tau**2 * R1**2)\n\n        # 1. Expected deterministic angular drift magnitude\n        deterministic_drift_mag = np.abs(k * omega * T)\n\n        # 2. Standard deviation of the stochastic angular drift\n        stochastic_drift_std = np.sqrt(2 * D * T)\n\n        # 3. Root-mean-square tracking error\n        mean_error_sq = ((k - 1) * omega * T)**2\n        variance_error = 2 * D * T\n        rmse = np.sqrt(mean_error_sq + variance_error)\n\n        # 4. Probability that the absolute tracking error is within a tolerance delta\n        mean_error = (k - 1) * omega * T\n        std_error = np.sqrt(variance_error)\n        \n        if std_error == 0.0:\n            # Deterministic case (zero noise)\n            probability = 1.0 if np.abs(mean_error) <= delta else 0.0\n        else:\n            # Standard Normal CDF is Phi(x) = 0.5 * (1 + erf(x / sqrt(2)))\n            z_upper = (delta - mean_error) / std_error\n            z_lower = (-delta - mean_error) / std_error\n            \n            prob_upper = 0.5 * (1 + erf(z_upper / np.sqrt(2)))\n            prob_lower = 0.5 * (1 + erf(z_lower / np.sqrt(2)))\n            \n            probability = prob_upper - prob_lower\n            \n        results.append([\n            deterministic_drift_mag,\n            stochastic_drift_std,\n            rmse,\n            probability\n        ])\n\n    # Format the final output as a string representing a list of lists.\n    # e.g., [[val1,val2,...], [val1,val2,...]]\n    output_str = f\"[{','.join(map(str, results))}]\"\n    print(output_str)\n\nsolve()\n\n```"
        }
    ]
}