{
    "hands_on_practices": [
        {
            "introduction": "在构建复杂的神经模型之前，理解其所代表的系统的基本属性至关重要。可控性和可观测性是两个核心概念，前者探讨我们能否通过外部输入将系统驱动到任意状态，后者则关注我们能否通过系统输出推断其内部状态。这项练习提供了计算这些属性的具体实践，这对于确定神经系统动力学的最小有效表征至关重要。",
            "id": "4022537",
            "problem": "考虑一个不动点附近的神经群体线性时不变（LTI）潜态模型，其中潜在动力学由底层生物物理过程的一阶线性化产生，观测值代表线性混合的放电率。离散时间状态空间模型为\n$$\nx_{t+1} = A x_t + B u_t,\\quad y_t = C x_t,\n$$\n其中 $x_t \\in \\mathbb{R}^{n}$ 是潜态，$u_t \\in \\mathbb{R}^{m}$ 是外源输入，$y_t \\in \\mathbb{R}^{p}$ 是观测到的活动。矩阵 $A \\in \\mathbb{R}^{n \\times n}$、$B \\in \\mathbb{R}^{n \\times m}$ 和 $C \\in \\mathbb{R}^{p \\times n}$ 由下式给出\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}.\n$$\n使用线性时不变系统的能控性和能观性的基本定义：由 $A$ 作用下 $B$ 生成的可达（能控）子空间是 $\\{A^{k} B\\}_{k=0}^{n-1}$ 的张成空间，而在 $C$ 和 $A$ 作用下的不可观子空间是 $\\{C A^{k}\\}_{k=0}^{n-1}$ 的核的交集。基于这些基础，计算：\n1. 对 $(A,B)$ 的能控性矩阵的秩。\n2. 对 $(A,C)$ 的能观性矩阵的秩。\n3. 与 $(A,B,C)$ 可生成的输入-输出行为一致的最小潜维数，这被理解为系统的能控且能观部分的维数（即传递行为 $u_t \\mapsto y_t$ 的最小实现）。\n\n将您的最终答案表示为一个行矩阵，按顺序包含能控性秩、能观性秩和最小潜维数。无需四舍五入。不要包含单位。",
            "solution": "该问题要求分析一个给定的离散时间线性时不变（LTI）状态空间模型，以确定其能控性、能观性以及表示其输入-输出行为所需的最小维数。\n\n状态空间模型由以下方程定义：\n$$\nx_{t+1} = A x_t + B u_t\n$$\n$$\ny_t = C x_t\n$$\n其中状态维数为 $n=3$，输入维数为 $m=1$，输出维数为 $p=1$。给定的矩阵如下：\n$$\nA = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n$$\n\n我们将按顺序计算这三个所要求的量。\n\n1. 对 $(A, B)$ 的能控性矩阵的秩。\n\n根据问题定义，能控子空间是能控性矩阵 $\\mathcal{C}$ 各列的张成空间。对于一个状态维数为 $n=3$ 的系统，该矩阵构造如下：\n$$\n\\mathcal{C} = \\begin{pmatrix} B  AB  A^2B \\end{pmatrix}\n$$\n首先，我们计算矩阵乘积 $AB$ 和 $A^2B$。\n$$\nAB = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\n0\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\\\\n0 \\\\\n0\n\\end{pmatrix}\n$$\n为计算 $A^2B$，我们首先求出 $A^2$：\n$$\nA^2 = A \\cdot A = \\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix} = \\mathbf{0}\n$$\n由于 $A^2$ 是零矩阵，因此 $A^2B = \\mathbf{0} \\cdot B = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$。\n现在，我们构造能控性矩阵 $\\mathcal{C}$：\n$$\n\\mathcal{C} = \\begin{pmatrix}\n0  1  0 \\\\\n1  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n矩阵的秩是线性无关的列（或行）的数量。前两列，$\\begin{pmatrix} 0  1  0 \\end{pmatrix}^T$ 和 $\\begin{pmatrix} 1  0  0 \\end{pmatrix}^T$，是正交的，因此是线性无关的。第三列是零向量，它线性依赖于其他列。因此，能控性矩阵的秩为 $2$。\n$$\n\\text{rank}(\\mathcal{C}) = 2\n$$\n\n2. 对 $(A, C)$ 的能观性矩阵的秩。\n\n不可观子空间定义为 $k=0, \\dots, n-1$ 时 $CA^k$ 的核的交集。这等价于能观性矩阵 $\\mathcal{O}$ 的零空间，对于 $n=3$，该矩阵为：\n$$\n\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ CA^2 \\end{pmatrix}\n$$\n我们计算矩阵乘积 $CA$ 和 $CA^2$。\n$$\nCA = \\begin{pmatrix}\n1  0  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  1  0\n\\end{pmatrix}\n$$\n由于 $A^2 = \\mathbf{0}$，我们有：\n$$\nCA^2 = C \\cdot \\mathbf{0} = \\begin{pmatrix} 0  0  0 \\end{pmatrix}\n$$\n现在，我们构造能观性矩阵 $\\mathcal{O}$：\n$$\n\\mathcal{O} = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n$$\n该矩阵的秩是线性无关的行的数量。前两行，$\\begin{pmatrix} 1  0  0 \\end{pmatrix}$ 和 $\\begin{pmatrix} 0  1  0 \\end{pmatrix}$，是正交的，因此是线性无关的。第三行是零向量。该矩阵已经处于行阶梯形，有两个主元。因此，能观性矩阵的秩为 $2$。\n$$\n\\text{rank}(\\mathcal{O}) = 2\n$$\n\n3. 与输入-输出行为一致的最小潜维数。\n\n该维数被定义为系统的能控且能观部分的维数。这可以使用状态空间的 Kalman 分解来找到。状态空间 $\\mathbb{R}^n$ 可以分解为四个子空间的直和：能控且能观 ($S_{co}$)、能控但不可观 ($S_{c\\bar{o}}$)、不能控但能观 ($S_{\\bar{c}o}$)，以及不能控且不可观 ($S_{\\bar{c}\\bar{o}}$)。最小维数对应于 $\\dim(S_{co})$。\n\n能控子空间是能控性矩阵的像空间，$\\mathcal{R} = \\text{Im}(\\mathcal{C})$。根据我们在第 1 部分的计算：\n$$\n\\mathcal{R} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\\right\\} = \\text{span}\\{e_1, e_2\\}\n$$\n其中 $e_1, e_2, e_3$ 是 $\\mathbb{R}^3$ 中的标准基向量。能控子空间的维数为 $\\dim(\\mathcal{R}) = \\text{rank}(\\mathcal{C}) = 2$。\n\n不可观子空间是能观性矩阵的零空间，$\\mathcal{N} = \\text{Ker}(\\mathcal{O})$。我们求解 $\\mathcal{O}x = 0$：\n$$\n\\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  0\n\\end{pmatrix}\n\\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n这得出 $x_1=0$ 和 $x_2=0$，而 $x_3$ 是一个自由变量。因此，不可观子空间为：\n$$\n\\mathcal{N} = \\text{span}\\left\\{\\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\\right\\} = \\text{span}\\{e_3\\}\n$$\n能观子空间，记为 $\\mathcal{O}_s$，是不可观子空间 $\\mathcal{N}$ 的正交补，或者等价地，是 $\\mathcal{O}^T$ 的像空间。\n$$\n\\mathcal{O}_s = \\mathcal{N}^{\\perp} = (\\text{span}\\{e_3\\})^{\\perp} = \\text{span}\\{e_1, e_2\\}\n$$\n 能观子空间的维数为 $\\dim(\\mathcal{O}_s) = \\text{rank}(\\mathcal{O}) = 2$。\n\n能控且能观子空间 $S_{co}$ 是能控子空间 $\\mathcal{R}$ 和能观子空间 $\\mathcal{O}_s$ 的交集：\n$$\nS_{co} = \\mathcal{R} \\cap \\mathcal{O}_s = \\text{span}\\{e_1, e_2\\} \\cap \\text{span}\\{e_1, e_2\\} = \\text{span}\\{e_1, e_2\\}\n$$\n这个子空间的维数是基向量的数量，即 $2$。\n\n或者，最小维数是系统传递函数 $H(z) = C(zI - A)^{-1}B$ 的阶数。我们计算 $(zI - A)^{-1}$：\n$$\nzI - A = \\begin{pmatrix} z  -1  0 \\\\ 0  z  0 \\\\ 0  0  z \\end{pmatrix}\n$$\n$$\n(zI - A)^{-1} = \\frac{1}{\\det(zI-A)} \\text{adj}(zI-A) = \\frac{1}{z^3} \\begin{pmatrix} z^2  z  0 \\\\ 0  z^2  0 \\\\ 0  0  z^2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix}\n$$\n现在我们计算传递函数：\n$$\nH(z) = C (zI - A)^{-1} B = \\begin{pmatrix} 1  0  0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\\\ 0  \\frac{1}{z}  0 \\\\ 0  0  \\frac{1}{z} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nH(z) = \\begin{pmatrix} \\frac{1}{z}  \\frac{1}{z^2}  0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{z^2}\n$$\n传递函数是 $H(z) = z^{-2}$。这是一个二阶系统。该系统的最小实现维数为 $2$。这证实了从状态空间分解得到的结果。\n\n所求的三个值是：\n1. 能控性秩：$2$\n2. 能观性秩：$2$\n3. 最小潜维数：$2$",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  2  2\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "神经活动与其潜在的大脑状态之间通常存在非线性关系，因此简单的线性模型往往不够用，需要更高级的滤波技术。扩展卡尔曼滤波器（EKF）和无迹卡尔曼滤波器（UKF）是处理这类非线性问题的两种常用算法。这项练习将通过为一个常见的神经非线性函数（饱和函数）实现这两种滤波器，让你对它们的工作机制有更具体的认识，并亲身体验它们的不同近似方法如何在不同条件下（尤其是在高度非线性或饱和区域）导致性能差异。",
            "id": "4022569",
            "problem": "考虑一个适用于神经数据分析的非线性状态观测设置中的单步测量更新。设潜在神经状态为标量 $x \\in \\mathbb{R}$，其高斯先验为 $x \\sim \\mathcal{N}(m, P)$，观测值 $y \\in \\mathbb{R}$ 由一个饱和非线性加上噪声生成，即 $y = h(x) + \\varepsilon$，其中 $h(x) = \\tanh(x)$ 且 $\\varepsilon \\sim \\mathcal{N}(0, R)$。目标是使用扩展卡尔曼滤波器 (EKF) 和无迹卡尔曼滤波器 (UKF) 实现单个后验更新步骤，并比较每种方法所实现的后验方差减小量。\n\n从基本贝叶斯原理出发，EKF 对观测模型构建一个局部线性近似并应用高斯更新。UKF 为先验构建 sigma 点，并将它们通过非线性观测函数传播，以近似测量均值和协方差。使用无迹变换参数 $\\alpha = 0.3$，$\\beta = 2$ 和 $\\kappa = 0$。\n\n你的程序必须为每个测试用例计算由 EKF 和 UKF 更新产生的后验方差，然后报告每种方法的方差减小率，其定义为 $(P - P_{\\text{post}})/P$，其中 $P$ 是先验方差，$P_{\\text{post}}$ 是相应滤波器的后验方差。\n\n使用以下参数集测试套件，为 EKF 和 UKF 实现不带任何随机性的更新，其中每个测试用例指定为 $(m, P, R, y)$：\n\n- 靠近中等非线性度的正常情况：$(0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$。\n- 具有大先验均值的饱和边界情况：$(3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$。\n- 极低测量噪声的边界情况：$(-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$。\n- 极高测量噪声的边界情况：$(0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$。\n- 小先验方差的边界情况：$(0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$。\n\n不涉及物理单位；将所有量视为无量纲实数。若有角度，必须以弧度为单位进行解释，但本问题仅需要实值标量。\n\n对于每个测试用例，计算两个十进制数：EKF 方差减小率和 UKF 方差减小率。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个元素是一个双元素列表，对应于该测试用例的 $[\\text{EKF 减小率}, \\text{UKF 减小率}]$。例如，输出格式必须类似于 $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$，其中每个 $r$ 是一个十进制数。",
            "solution": "我们从状态空间模型的贝叶斯滤波原理开始。潜在标量状态 $x \\in \\mathbb{R}$ 具有高斯先验 $x \\sim \\mathcal{N}(m, P)$，其先验均值为 $m$，先验方差为 $P$。测量模型为 $y = h(x) + \\varepsilon$，其中 $h(x) = \\tanh(x)$ 代表一个饱和非线性，通常用作神经元发放率非线性的代理，而 $\\varepsilon \\sim \\mathcal{N}(0, R)$ 是方差为 $R$ 的高斯观测噪声。单个测量更新的目标是通过扩展卡尔曼滤波器 (EKF) 或无迹卡尔曼滤波器 (UKF) 生成一个保持高斯性的近似后验 $p(x \\mid y)$，然后比较每种方法所实现的后验方差减小量 $(P - P_{\\text{post}})/P$。\n\n其基本依据是贝叶斯法则：\n$$\np(x \\mid y) \\propto p(y \\mid x) p(x).\n$$\n在线性高斯模型中，精确后验保持高斯性，并可通过卡尔曼滤波器求得。对于非线性观测函数 $h(x)$，EKF 和 UKF 提供了对后验的高斯近似。\n\n扩展卡尔曼滤波器 (EKF) 的测量更新源于对非线性观测函数的局部线性化。在先验均值 $m$ 处，我们将 $h(x)$ 线性化为\n$$\nh(x) \\approx h(m) + H (x - m),\n$$\n其中 $H$ 是在 $m$ 处求值的雅可比矩阵（对于标量 $x$，即为导数），\n$$\nH = \\frac{d}{dx} \\tanh(x) \\bigg|_{x=m} = 1 - \\tanh^2(m).\n$$\n在此局部线性模型和高斯噪声下，测量预测值为 $h(m)$，新息为 $v = y - h(m)$。标量新息协方差为\n$$\nS = H P H + R,\n$$\n标量卡尔曼增益为\n$$\nK = \\frac{P H}{S}.\n$$\n后验均值和方差则为\n$$\nm_{\\text{post,EKF}} = m + K v,\n\\quad\nP_{\\text{post,EKF}} = P - K H P.\n$$\nEKF 的方差减小率为\n$$\nr_{\\text{EKF}} = \\frac{P - P_{\\text{post,EKF}}}{P}.\n$$\n\n无迹卡尔曼滤波器 (UKF) 使用无迹变换，通过将确定性选择的 sigma 点在非线性函数中传播，来近似测量的均值和协方差。对于标量状态 ($n = 1$)，选择参数 $\\alpha = 0.3$，$\\beta = 2$ 和 $\\kappa = 0$。定义\n$$\n\\lambda = \\alpha^2 (n + \\kappa) - n,\n\\quad\nc = n + \\lambda.\n$$\n构建 sigma 点：\n$$\nX_0 = m, \\quad X_1 = m + \\sqrt{c P}, \\quad X_2 = m - \\sqrt{c P}.\n$$\n定义均值和协方差的权重：\n$$\nW^{(m)}_0 = \\frac{\\lambda}{c}, \\quad W^{(c)}_0 = \\frac{\\lambda}{c} + (1 - \\alpha^2 + \\beta),\n\\quad\nW^{(m)}_i = W^{(c)}_i = \\frac{1}{2c} \\ \\text{for} \\ i \\in \\{1,2\\}.\n$$\n将 sigma 点通过测量函数传播：\n$$\nY_i = h(X_i) = \\tanh(X_i).\n$$\n计算预测的测量均值和协方差：\n$$\n\\hat{y} = \\sum_{i=0}^{2} W^{(m)}_i Y_i,\n\\quad\nS = \\sum_{i=0}^{2} W^{(c)}_i \\left(Y_i - \\hat{y}\\right)^2 + R.\n$$\n计算状态和测量之间的互协方差：\n$$\nC = \\sum_{i=0}^{2} W^{(c)}_i \\left(X_i - m\\right)\\left(Y_i - \\hat{y}\\right).\n$$\n标量卡尔曼增益、后验均值和后验方差为\n$$\nK = \\frac{C}{S},\n\\quad\nm_{\\text{post,UKF}} = m + K \\left(y - \\hat{y}\\right),\n\\quad\nP_{\\text{post,UKF}} = P - K S K.\n$$\nUKF 的方差减小率为\n$$\nr_{\\text{UKF}} = \\frac{P - P_{\\text{post,UKF}}}{P}.\n$$\n\n我们在一个确定性测试套件上评估这两种方法，该套件涵盖了与非线性神经观测模型相关的典型情况和边界情况：\n- 在 $m = 0.2$ 附近具有中等非线性度的正常情况，\n- 在 $m = 3.0$ 处的饱和边界情况，此时 $h'(m)$ 很小，\n- 测量噪声极低 ($R = 10^{-6}$) 的边界情况，\n- 测量噪声非常高 ($R = 10.0$) 的边界情况，\n- 先验方差非常小 ($P = 10^{-4}$) 的边界情况。\n\n对于每个测试用例，测量值 $y$ 被确定性地设置为 $y = h(m) + \\delta$，其中 $\\delta$ 被指定以避免随机性：\n- 情况 1：$(m, P, R, y) = (0.2, 0.5, 0.1, \\tanh(0.2) + 0.05)$，\n- 情况 2：$(m, P, R, y) = (3.0, 0.5, 0.1, \\tanh(3.0) - 0.02)$，\n- 情况 3：$(m, P, R, y) = (-1.0, 0.3, 10^{-6}, \\tanh(-1.0) + 0.0)$，\n- 情况 4：$(m, P, R, y) = (0.0, 1.0, 10.0, \\tanh(0.0) + 0.5)$，\n- 情况 5：$(m, P, R, y) = (0.5, 10^{-4}, 0.1, \\tanh(0.5) + 0.02)$。\n\n每个用例需要实现的算法步骤：\n1. 使用 EKF 线性化和标量卡尔曼更新计算 $r_{\\text{EKF}}$。\n2. 使用无迹变换、指定参数和标量卡尔曼更新计算 $r_{\\text{UKF}}$。\n3. 报告数对 $[r_{\\text{EKF}}, r_{\\text{UKF}}]$。\n\n最后，将所有结果聚合成一个列表的列表，并以精确的所需格式 $[[r_{1,\\text{EKF}}, r_{1,\\text{UKF}}],[r_{2,\\text{EKF}}, r_{2,\\text{UKF}}],\\dots]$ 将它们作为单行打印出来，其中每个 $r$ 是一个十进制数。",
            "answer": "```python\nimport numpy as np\n\ndef h(x):\n    # Nonlinear observation function: tanh\n    return np.tanh(x)\n\ndef dh_dx_at(m):\n    # Derivative of tanh is 1 - tanh(m)^2\n    t = np.tanh(m)\n    return 1.0 - t * t\n\ndef ekf_variance_reduction(m, P, R, y):\n    # EKF single measurement update in 1D\n    H = dh_dx_at(m)\n    y_hat = h(m)\n    v = y - y_hat  # innovation\n    S = H * P * H + R\n    K = (P * H) / S\n    P_post = P - K * H * P\n    # Variance reduction ratio\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0):\n    # UKF single measurement update in 1D\n    n = 1\n    lam = alpha**2 * (n + kappa) - n\n    c = n + lam\n    # Sigma points\n    gamma = np.sqrt(c) * np.sqrt(P)\n    X = np.array([m, m + gamma, m - gamma])\n    # Weights\n    Wm = np.array([lam / c, 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    Wc = np.array([lam / c + (1.0 - alpha**2 + beta), 1.0 / (2.0 * c), 1.0 / (2.0 * c)])\n    # Propagate through measurement\n    Y = h(X)\n    y_hat = np.sum(Wm * Y)\n    # Measurement covariance\n    S = np.sum(Wc * (Y - y_hat)**2) + R\n    # Cross covariance\n    C = np.sum(Wc * (X - m) * (Y - y_hat))\n    # Kalman gain and posterior variance\n    K = C / S\n    P_post = P - K * S * K  # scalar case\n    reduction = (P - P_post) / P\n    return float(reduction)\n\ndef solve():\n    # Define deterministic test cases: (m, P, R, y)\n    test_cases = [\n        # Happy-path case near moderate nonlinearity\n        (0.2, 0.5, 0.1, np.tanh(0.2) + 0.05),\n        # Saturation boundary case with large prior mean\n        (3.0, 0.5, 0.1, np.tanh(3.0) - 0.02),\n        # Very low measurement noise edge case\n        (-1.0, 0.3, 1e-6, np.tanh(-1.0) + 0.0),\n        # Very high measurement noise edge case\n        (0.0, 1.0, 10.0, np.tanh(0.0) + 0.5),\n        # Small prior variance boundary case\n        (0.5, 1e-4, 0.1, np.tanh(0.5) + 0.02),\n    ]\n\n    results = []\n    for m, P, R, y in test_cases:\n        r_ekf = ekf_variance_reduction(m, P, R, y)\n        r_ukf = ukf_variance_reduction(m, P, R, y, alpha=0.3, beta=2.0, kappa=0.0)\n        results.append([r_ekf, r_ukf])\n\n    # Final print statement in the exact required format.\n    # Produce a single line with list of lists of decimal numbers.\n    print(str(results))\n\nsolve()\n```"
        },
        {
            "introduction": "学习了如何构建状态空间模型之后，一个关键的实践问题随之而来：我们应如何选择合适的模型复杂度，例如潜在状态的维度 $k$？这个选择对模型的解释力和泛化能力至关重要。这项练习探讨了交叉验证这一强大的模型选择工具，并特别关注了在处理时间序列数据时必须谨慎处理的时间依赖性问题。通过设计一个严谨的验证策略，你将直面并解决时间数据中信息泄漏的挑战，这是构建可靠的、具有预测能力的神经活动模型的关键技能。",
            "id": "4022517",
            "problem": "考虑在宽度为 $\\Delta$ 秒的时间窗内聚合的多神经元尖峰计数数据。令 $y_{t} \\in \\mathbb{N}^{N}$ 表示在时间索引 $t \\in \\{1,\\dots,T\\}$ 时来自 $N$ 个神经元的计数向量，并令 $x_{t} \\in \\mathbb{R}^{k}$ 是一个维度为 $k$ 的潜状态，其根据线性高斯动态演化\n$$\nx_{t} = A x_{t-1} + w_{t}, \\quad w_{t} \\sim \\mathcal{N}(0, Q),\n$$\n其先验为 $x_{1} \\sim \\mathcal{N}(m_{1}, P_{1})$。给定潜状态，观测模型在神经元之间是条件独立的，并由一个带有泊松观测的广义线性模型 (GLM) 定义，\n$$\ny_{t,n} \\mid x_{t} \\sim \\mathrm{Poisson}\\big(\\lambda_{t,n}\\big), \\quad \\lambda_{t,n} = \\exp\\big(c_{n}^{\\top} x_{t} + d_{n}\\big),\n$$\n其中 $C = [c_{1}^{\\top};\\dots;c_{N}^{\\top}] \\in \\mathbb{R}^{N \\times k}$ 和 $d \\in \\mathbb{R}^{N}$ 是观测参数，而 $(A, Q)$ 是动态参数。假设我们将使用期望最大化 (EM) 算法，为一系列候选潜维度 $k \\in \\{1,2,\\dots,k_{\\max}\\}$ 拟合这样一个状态空间模型，从而对每个 $k$ 得到参数估计 $\\hat{\\theta}_{k} = (\\hat{A}_{k}, \\hat{Q}_{k}, \\hat{C}_{k}, \\hat{d}_{k})$。\n\n请你提出并论证一个交叉验证的预测对数似然准则，用以选择能够最准确预测留出尖峰的潜维度 $k$，并说明在构建交叉验证折时如何处理时间依赖性。你的提议必须从状态空间模型中预测分布的定义出发，不得将留出数据中的信息泄露到训练或评估中，并且对于神经尖峰序列必须是科学上合理的。\n\n以下哪项是​​最合适的准则和折叠构建方法？\n\nA. 使用分块和带缓冲区的滚动交叉验证。将时间轴划分为 $K$ 个长度相等的连续测试块 $\\{T_{f}\\}_{f=1}^{K}$；对于每个测试块 $T_{f}$，从训练中排除其两侧大小为 $L$ 的缓冲区，以减轻时间泄露并允许潜动态混合。对于每个候选 $k$，在训练索引 $\\mathcal{I}_{\\text{train}}^{(f)} = \\{1,\\dots,T\\} \\setminus \\big(T_{f} \\cup \\text{buffer}(T_{f}, L)\\big)$ 上拟合 $\\hat{\\theta}_{k}$。通过一步向前预测分布评估该块的预测对数似然，\n$$\n\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big), \\quad p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big) = \\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}.\n$$\n通过 $\\mathrm{PLL}(k) = \\sum_{f=1}^{K} \\mathrm{PLL}_{f}(k)$ 在各折上进行汇总，或按时间窗和神经元取平均。选择使 $\\mathrm{PLL}(k)$ 最大化的 $k$。对于泊松观测，使用滤波均值周围的拉普拉斯近似来近似积分；对于高斯观测，由于共轭性，积分为闭合形式。根据潜混合时间设置 $L$，例如，使 $\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$（对于一个小的 $\\varepsilon$）成立的最小 $L$。\n\nB. 随机打乱时间窗以分成 $K$ 折，从而打破时间依赖性。对于每个候选 $k$，在训练折上拟合 $\\hat{\\theta}_{k}$，并通过代入使用所有数据（训练和测试）计算出的平滑后验均值 $\\hat{x}_{t}$ 来计算留出对数似然，以在测试点评估 $\\log p\\big(y_{t} \\mid \\hat{x}_{t}, \\hat{\\theta}_{k}\\big)$，然后选择具有最大平均留出对数似然的 $k$。\n\nC. 避免交叉验证，通过最大化仅由静态模型选择项（如赤池信息准则 (AIC)）惩罚的训练边际对数似然 $\\log p\\big(y_{1:T} \\mid \\hat{\\theta}_{k}\\big)$ 来选择 $k$，忽略状态演化和时间依赖性。\n\nD. 使用不带缓冲区的分块 $K$ 折交叉验证。对于每个候选 $k$，在除连续测试块之外的所有数据上拟合 $\\hat{\\theta}_{k}$，然后使用双边平滑后验 $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$ 来计算留出对数似然，以在测试块中的 $t$ 处评估 $\\log p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)$，并选择使测试窗总和最大化的 $k$。\n\n选择唯一最佳选项，并准备好从状态空间建模的第一性原理、预测分布的定义以及交叉验证中时间依赖性的适当处理等方面来论证你的选择。",
            "solution": "问题陈述在计算神经科学和时间序列分析领域提出了一个有效且定义明确的问题。它描述了一个用于神经尖峰计数的标准状态空间模型（一个带有潜在线性高斯动态的泊松观测广义线性模型），并要求选择最合适的交叉验证策略来确定潜状态维度 $k$。模型的所有组成部分都得到了清晰的定义，其目标在科学上是有意义的。\n\n该问题具有科学依据，提法恰当且客观。它不包含任何不一致或模糊之处。因此，我将进行全面分析。\n\n问题的核心是根据模型预测未见数据的能力来选择模型参数 ($k$)。对于时间序列数据，这需要仔细处理时间依赖性，以避免信息泄露并获得对泛化性能的无偏估计。\n\n一个有效的程序必须满足三个关键原则：\n1.  **保持时间顺序**：交叉验证结构不能随机打乱数据。在某种意义上，测试集应该是训练集的“未来”。这需要采用分块或滚动折叠的结构。\n2.  **无信息泄露**：在测试点 $y_t$ 上的模型评估必须只使用截至时间 $t-1$ 可用的信息。以 $t' \\geq t$ 的数据 $y_{t'}$ 为条件（即使用平滑后验）会将预测任务变为插值任务，这会夸大性能指标并导致选择过于复杂的模型。参数 $\\hat{\\theta}_k$ 本身必须只在每个折叠指定的训练数据上进行训练。\n3.  **正确的预测分布**：给定过去观测值 $y_{1:t-1}$ 和参数 $\\theta$ 的情况下，观测值 $y_t$ 的预测对数似然是 $\\log p(y_t | y_{1:t-1}, \\theta)$。对于潜变量模型，这通过将潜状态边缘化来计算：\n    $$\n    p(y_t | y_{1:t-1}, \\theta) = \\int p(y_t | x_t, \\theta) p(x_t | y_{1:t-1}, \\theta) dx_t\n    $$\n    此处，$p(x_t | y_{1:t-1}, \\theta)$ 是潜状态的一步向前预测后验，由滤波分布推导得出。\n\n基于这些原则，我将评估每个选项。\n\n**选项 A 评估**\n-   **交叉验证方案**：“分块和带缓冲区的滚动交叉验证”是一种适用于时间序列的先进且恰当的方法。分块保留了时间顺序。在训练集和测试集之间使用大小为 $L$ 的缓冲区对于状态空间模型至关重要，因为它减轻了测试块开始时状态对训练块结束时状态的直接依赖。这可以防止由于短期状态记忆而导致的人为高分。根据潜混合时间（$\\lVert \\hat{A}_{k}^{L} \\rVert \\approx \\varepsilon$）设置 $L$ 的理由是符合原则的。\n-   **参数拟合**：参数 $\\hat{\\theta}_k$ 正确地仅在每个折叠的训练索引 $\\mathcal{I}_{\\text{train}}^{(f)}$ 上拟合。\n-   **评估指标**：提议的指标是一步向前预测对数似然，$\\mathrm{PLL}_{f}(k) = \\sum_{t \\in T_{f}} \\log p\\big(y_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)$。这正确定义了预测目标。提供的积分形式 $\\int p\\big(y_{t} \\mid x_{t}, \\hat{\\theta}_{k}\\big)\\, p\\big(x_{t} \\mid y_{1:(t-1)}^{\\text{train}}, \\hat{\\theta}_{k}\\big)\\, dx_{t}$，是该预测概率的严格数学定义。它正确地使用了通过训练数据滤波得到的状态的一步向前预测分布。没有信息泄露。关于对棘手的积分使用拉普拉斯近似的说明是针对该模型类别的一个正确且实用的细节。\n-   **结论**：该选项正确地指定了在此背景下进行交叉验证预测模型选择的最新、科学严谨的程序。**正确**。\n\n**选项 B 评估**\n-   **交叉验证方案**：“随机打乱时间窗以分成 $K$ 折，从而打破时间依赖性。”这在根本上是错误的。模型的目的是捕捉时间动态 $x_t = A x_{t-1} + w_t$。打乱数据会使观测值近似独立同分布 (i.i.d.)，从而破坏了模型旨在学习和预测的结构。\n-   **评估指标**：提议使用“所有数据（训练和测试）”计算的平滑后验均值 $\\hat{x}_t$。这构成了严重的信息泄露。平滑后验 $p(x_t | y_{1:T})$ 是以相对于 $t$ 的未来观测为条件的。用它来“预测”$y_t$ 是无效的。此外，使用点估计 $\\hat{x}_t$ 而不是对后验分布进行边缘化，忽略了不确定性，并提供了对数似然的较差近似。\n-   **结论**：该选项的交叉验证结构及其评估指标存在缺陷，后者会泄露信息。**不正确**。\n\n**选项 C 评估**\n-   **交叉验证方案**：该选项明确“避免交叉验证”。这与问题要求提出交叉验证准则相矛盾，并且通常被认为是一种不如样本外验证稳健的模型选择方法。\n-   **评估指标**：它建议使用像 AIC 这样的样本内信息准则。虽然 AIC 是一种有效的模型选择方法，但它依赖于渐近近似，并且可能不如直接交叉验证表现得好，特别是对于复杂模型或有限数据集。关于“忽略状态演化和时间依赖性”的说法有点误导，因为对 AIC 的边际对数似然的正确计算*会*涉及状态动态（例如，通过卡尔曼滤波器）。然而，主要缺陷是它拒绝了更稳健的交叉验证范式，而采用纯粹的样本内指标。\n-   **结论**：该选项提出了一种非交叉验证方法，未能满足问题的核心要求，并且通常被认为不如执行良好的交叉验证可靠。**不正确**。\n\n**选项 D 评估**\n-   **交叉验证方案**：“不带缓冲区的分块 $K$ 折”。这比随机打乱（选项 B）有所改进，因为它保留了时间块。然而，缺少缓冲区可能导致性能评估中的乐观偏差，因为测试块的初始状态受到相邻训练块最终状态的严重约束。\n-   **评估指标**：关键缺陷是使用了“双边平滑后验 $p\\big(x_{t} \\mid y_{\\text{train}} \\cup y_{\\text{test}}, \\hat{\\theta}_{k}\\big)$”。这在原则上与选项 B 的缺陷相同。它使用来自测试集（以及其他未来数据）的数据来推断潜状态 $x_t$，然后用它来评估 $y_t$ 的似然。这不是一种预测性度量，而是一种衡量模型解释其已被条件化的数据的能力的度量。这构成了从测试集到其自身评估的直接且显著的信息泄露。\n-   **结论**：使用平滑后验进行评估使得该方法在评估预测性能方面无效。**不正确**。\n\n总而言之，选项 A 是唯一一个提出了方法论上合理且严谨的方法，尊重了时间序列分析的原则，禁止了信息泄露，并正确定义了预测似然。它代表了解决此问题的最佳实践。",
            "answer": "$$\\boxed{A}$$"
        }
    ]
}