{
    "hands_on_practices": [
        {
            "introduction": "这第一个实践是一项奠基性的练习。我们将模拟一个具有余弦调谐特性的神经元群体，生成合成的发放数据，然后逆向这个过程。通过对模拟数据应用线性回归，我们将估计神经元的调谐属性，并最终使用这些估计值来构建和测试一个向量平均解码器，从而提供一个计算神经科学中这一基本技术的完整端到端实现。",
            "id": "4010760",
            "problem": "您将执行一项计算神经科学任务，内容是关于平面方向刺激的神经元群体编码。假设存在一个神经元群体，其中每个神经元都对刺激方向表现出余弦调谐特性，并且脉冲发放被建模为泊松点过程。任务目标是根据训练数据估计每个神经元的调谐参数和偏好方向，然后使用矢量平均解码器对新刺激进行解码。整个任务必须实现为单个可运行的程序。\n\n基本原理和假设：\n- 每个神经元 $i$ 有一个未知的偏好方向 $\\theta_i$，并根据带基线的余弦调谐定律产生脉冲。期望发放率是刺激方向的函数。在试验 $t$ 中的神经元响应被建模为泊松随机变量，其均值等于该试验中刺激下的发放率。\n- 刺激方向在圆上表示，角度必须以弧度处理。基于群体矢量和矢量平均的解码器每次试验产生一个单一的方向估计值。\n\n您的程序必须为测试套件中的每个测试用例执行以下步骤：\n1. 生成训练数据：\n   - 构建一个由 $N$ 个神经元组成的群体，其具有指定的偏好方向 $\\{\\theta_i\\}_{i=1}^N$、基线 $\\{b_i\\}_{i=1}^N$（单位：脉冲/秒）和增益 $\\{g_i\\}_{i=1}^N$（单位：脉冲/秒），其中在刺激角度 $\\phi$ 下，神经元 $i$ 的期望发放率为 $b_i + g_i \\cos(\\phi - \\theta_i)$。\n   - 模拟 $T$ 次训练试验。在每次试验 $t$ 中，从区间 $[-\\pi, \\pi)$ 均匀抽取一个刺激角度 $\\phi_t$，并对每个神经元 $i$，根据均值为 $b_i + g_i \\cos(\\phi_t - \\theta_i)$ 的泊松分布抽取一个脉冲计数 $k_{i,t}$。\n2. 估计调谐参数：\n   - 使用训练数据 $\\{(\\phi_t, k_{i,t})\\}$，为每个神经元 $i$ 估计其基线 $\\hat{b}_i$、增益 $\\hat{g}_i$ 和偏好方向 $\\hat{\\theta}_i$。此过程仅依赖于余弦调谐结构和线性回归原理，该原理基于一个三角恒等式，它将相移余弦转换为 $\\cos(\\phi)$ 和 $\\sin(\\phi)$ 项的线性组合。\n   - 为保证数值稳定性，忽略任何估计增益低于一个很小阈值 $\\varepsilon$ 的神经元；使用 $\\varepsilon = 10^{-3}$ 脉冲/秒。\n3. 生成测试数据并解码：\n   - 模拟 $K$ 次测试试验，使用从 $[-\\pi, \\pi)$ 均匀抽取的新刺激角度 $\\phi'_u$，并使用真实参数 $(b_i, g_i, \\theta_i)$ 生成泊松脉冲计数 $k'_{i,u}$。\n   - 使用源自群体矢量概念的矢量平均解码器对每个测试刺激角度进行解码：将每个神经元的贡献视为一个朝向其估计偏好方向的单位矢量，并由一个与其减去基线的脉冲计数成正比的非负活动加权。具体来说，对神经元 $i$，使用权重 $\\max(0, k'_{i,u} - \\hat{b}_i)$，并且仅组合满足 $\\hat{g}_i \\ge \\varepsilon$ 的神经元。\n   - 解码器必须为每次测试试验 $u$ 产生一个以弧度为单位的单一角度估计值 $\\hat{\\phi}'_u$。\n4. 评估性能：\n   - 计算测试试验的平均绝对环形误差，其中解码角度 $\\hat{\\phi}$ 与真实角度 $\\phi$ 之间的绝对环形误差为 $d(\\hat{\\phi}, \\phi) = \\min_{k \\in \\mathbb{Z}} |\\hat{\\phi} - \\phi + 2\\pi k|$。结果以弧度表示。\n\n角度单位要求：所有角度必须以弧度处理和报告。\n\n物理单位要求：所有发放率必须以“脉冲/秒”为单位处理。\n\n最终输出格式：您的程序应生成单行输出，其中包含每个测试用例的平均绝对环形误差，格式为逗号分隔的列表并用方括号括起（例如 $[result_1,result_2,result_3]$），其中每个 $result_j$ 是一个以弧度为单位的浮点数。\n\n测试套件：\n- 用例 1（理想路径，增益多样，训练充分）：\n  - $N = 8$, $T = 200$, $K = 50$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布，即对 $i = 1, \\dots, N$，有 $\\theta_i = -\\pi + \\frac{2\\pi (i-1)}{N}$。\n  - 基线：对所有 $i$，$b_i = 20$（脉冲/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_8) = (14, 12, 16, 10, 18, 11, 15, 13)$（脉冲/秒）。\n  - 伪随机数生成器种子：训练种子 $= 101$，测试种子 $= 202$。\n- 用例 2（边界条件，包含零增益神经元）：\n  - $N = 8$, $T = 60$, $K = 40$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布。\n  - 基线：对所有 $i$，$b_i = 20$（脉冲/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_8) = (0, 0, 12, 10, 8, 0, 6, 0)$（脉冲/秒）。\n  - 伪随机数生成器种子：训练种子 $= 303$，测试种子 $= 404$。\n- 用例 3（小样本，低增益，噪声更强的设置）：\n  - $N = 6$, $T = 30$, $K = 30$。\n  - 偏好方向：$\\theta_i$ 在 $[-\\pi, \\pi)$ 上均匀分布。\n  - 基线：对所有 $i$，$b_i = 15$（脉冲/秒）。\n  - 增益：$(g_1, g_2, \\dots, g_6) = (5, 4, 3, 2, 5, 4)$（脉冲/秒）。\n  - 伪随机数生成器种子：训练种子 $= 505$，测试种子 $= 606$。\n\n科学真实性约束：\n- 对脉冲计数使用具有指定平均发放率的泊松分布，以确保计数值为非负整数。\n- 确保所有计算和解码均以弧度进行。\n- 避免使用任何外部数据或用户输入；使用指定的种子以实现可复现的随机性。\n\n您的程序必须生成单行输出，将三个平均绝对环形误差（单位为弧度）总结为 $[e_1,e_2,e_3]$。",
            "solution": "该问题经评估具有科学依据、定义明确、客观且自成体系，因此被认为是有效的。以下解决方案概述了指定的建模、估计和解码的分步过程。\n\n### 第 1 步：神经元响应模型\n群体中每个神经元的活动由一个余弦调谐模型控制。神经元 $i$ 对刺激方向 $\\phi$（单位为弧度）的响应的期望发放率 $r_i$（单位为脉冲/秒，解释为每次试验的脉冲数）由以下公式给出：\n$$\nr_i(\\phi) = b_i + g_i \\cos(\\phi - \\theta_i)\n$$\n其中 $b_i$ 是神经元的基线发放率，$g_i$ 是其增益（调制深度），而 $\\theta_i$ 是其偏好方向。在给定试验 $t$ 中，神经元 $i$ 对刺激 $\\phi_t$ 发出的脉冲数 $k_{i,t}$ 被建模为一个从泊松分布中抽取的随机变量，其均值等于期望发放率：\n$$\nk_{i,t} \\sim \\text{Poisson}(r_i(\\phi_t))\n$$\n所有测试用例的问题参数确保 $b_i \\ge g_i$，从而保证了非负的发放率 $r_i(\\phi) \\ge 0$。\n\n### 第 2 步：训练数据生成\n对于每个测试用例，我们首先合成一个训练数据集。这涉及模拟 $T$ 次试验。在每次试验 $t \\in \\{1, \\dots, T\\}$ 中，从 $[-\\pi, \\pi)$ 上的均匀分布中抽取一个刺激角度 $\\phi_t$。随后，对于 $N$ 个神经元中的每一个，使用真实、预设的参数，通过从泊松分布 $\\text{Poisson}(b_i + g_i \\cos(\\phi_t - \\theta_i))$ 中抽取生成脉冲计数 $k_{i,t}$。\n\n### 第 3 步：调谐参数估计\n此步骤的核心任务是从生成的训练数据 $\\{(\\phi_t, k_{i,t})\\}_{t=1}^T$ 中为每个神经元估计调谐参数 $(\\hat{b}_i, \\hat{g}_i, \\hat{\\theta}_i)$。这是通过基于调谐曲线的三角展开式的线性回归来完成的。\n\n余弦项展开为 $\\cos(\\phi - \\theta_i) = \\cos\\phi \\cos\\theta_i + \\sin\\phi \\sin\\theta_i$。将其代入发放率方程，得到：\n$$\nr_i(\\phi) = b_i + (g_i \\cos\\theta_i) \\cos\\phi + (g_i \\sin\\theta_i) \\sin\\phi\n$$\n该方程具有线性模型 $r_i(\\phi) = \\beta_{i,0} \\cdot 1 + \\beta_{i,1} \\cos\\phi + \\beta_{i,2} \\sin\\phi$ 的形式，其系数定义如下：\n- $\\beta_{i,0} = b_i$\n- $\\beta_{i,1} = g_i \\cos\\theta_i$\n- $\\beta_{i,2} = g_i \\sin\\theta_i$\n\n我们通过最小化观测到的脉冲计数 $k_{i,t}$ 与模型预测值之间的平方误差和来估计这些系数。这对每个神经元来说都是一个多元线性回归问题，可以对所有试验表示为矩阵形式：\n$$\n\\mathbf{k}_i \\approx \\mathbf{X} \\boldsymbol{\\beta}_i\n$$\n这里，$\\mathbf{k}_i = [k_{i,1}, \\dots, k_{i,T}]^T$ 是神经元 $i$ 的观测脉冲计数向量，$\\boldsymbol{\\beta}_i = [\\beta_{i,0}, \\beta_{i,1}, \\beta_{i,2}]^T$ 是待估计的系数向量，$\\mathbf{X}$ 是一个 $T \\times 3$ 的设计矩阵，包含所有试验的预测变量：\n$$\n\\mathbf{X} = \\begin{pmatrix}\n1  \\cos(\\phi_1)  \\sin(\\phi_1) \\\\\n1  \\cos(\\phi_2)  \\sin(\\phi_2) \\\\\n\\vdots  \\vdots  \\vdots \\\\\n1  \\cos(\\phi_T)  \\sin(\\phi_T)\n\\end{pmatrix}\n$$\n系数向量的标准最小二乘解为 $\\hat{\\boldsymbol{\\beta}}_i = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{k}_i$。我们对所有 $N$ 个神经元求解该系统，以获得每个神经元 $i$ 的估计系数 $(\\hat{\\beta}_{i,0}, \\hat{\\beta}_{i,1}, \\hat{\\beta}_{i,2})$。\n\n从这些估计出的系数，我们恢复对原始调谐参数的估计：\n- 估计基线：$\\hat{b}_i = \\hat{\\beta}_{i,0}$\n- 估计增益：$\\hat{g}_i = \\sqrt{\\hat{\\beta}_{i,1}^2 + \\hat{\\beta}_{i,2}^2}$\n- 估计偏好方向：$\\hat{\\theta}_i = \\text{atan2}(\\hat{\\beta}_{i,2}, \\hat{\\beta}_{i,1})$\n\n### 第 4 步：解码测试刺激\n参数估计后，我们生成一组新的 $K$ 次测试试验。对于每次试验 $u \\in \\{1, \\dots, K\\}$，从 $[-\\pi, \\pi)$ 均匀抽取一个刺激角度 $\\phi'_u$，并使用真实参数生成脉冲计数 $k'_{i,u}$。\n\n然后使用矢量平均解码器对每次测试试验的刺激角度进行解码。该方法通过对所有被认为已充分调谐的神经元的矢量贡献求和，为每次试验 $u$ 计算一个群体矢量 $\\vec{V}_u$：\n$$\n\\vec{V}_u = \\sum_{i=1}^N w_{i,u} \\cdot \\vec{d}_i\n$$\n- 只有当神经元 $i$ 的估计增益 $\\hat{g}_i$ 高于阈值，即 $\\hat{g}_i \\ge \\varepsilon$（其中 $\\varepsilon=10^{-3}$）时，它才会对总和做出贡献。\n- 每个有效神经元的贡献是一个矢量 $\\vec{d}_i = [\\cos(\\hat{\\theta}_i), \\sin(\\hat{\\theta}_i)]^T$，它指向其估计的偏好角度 $\\hat{\\theta}_i$ 的方向。\n- 该矢量由神经元的经修正的、减去基线的活动加权：$w_{i,u} = \\max(0, k'_{i,u} - \\hat{b}_i)$。\n\n该试验的解码角度 $\\hat{\\phi}'_u$ 是合力群体矢量 $\\vec{V}_u = [V_{u,x}, V_{u,y}]^T$ 的角度：\n$$\n\\hat{\\phi}'_u = \\text{atan2}(V_{u,y}, V_{u,x})\n$$\n\n### 第 5 步：性能评估\n解码器的准确性通过计算所有 $K$ 次测试试验的平均绝对环形误差来评估。单次试验的绝对环形误差是真实刺激角度 $\\phi'_u$ 和解码角度 $\\hat{\\phi}'_u$ 之间的最短角距离：\n$$\nd(\\hat{\\phi}'_u, \\phi'_u) = \\min_{k \\in \\mathbb{Z}} |\\hat{\\phi}'_u - \\phi'_u + 2\\pi k|\n$$\n这等效于将角度差 $\\hat{\\phi}'_u - \\phi'_u$ 包裹到区间 $[-\\pi, \\pi]$ 内，并取其绝对值。每个测试用例最终报告的值是这些误差在 $K$ 次测试试验中的平均值。整个过程被封装在一个程序中，该程序执行所有三个测试用例，并根据指定格式报告结果。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_case(N, T, K, thetas, bs, gs, train_seed, test_seed, epsilon):\n    \"\"\"\n    Solves a single test case for the neural decoding problem.\n\n    This function performs training data generation, parameter estimation,\n    test data generation, decoding, and performance evaluation.\n    \"\"\"\n    # === Step 1: Generate training data ===\n    rng_train = np.random.default_rng(train_seed)\n    train_stimuli = rng_train.uniform(-np.pi, np.pi, size=T)\n    \n    # train_spikes will have shape (N, T)\n    train_spikes = np.zeros((N, T))\n    for i in range(N):\n        # The problem statement's parameters ensure b_i >= g_i, so rates are non-negative.\n        rates = bs[i] + gs[i] * np.cos(train_stimuli - thetas[i])\n        train_spikes[i, :] = rng_train.poisson(rates)\n\n    # === Step 2: Estimate tuning parameters ===\n    # Design matrix X, shape (T, 3) for linear regression\n    X = np.vstack([np.ones(T), np.cos(train_stimuli), np.sin(train_stimuli)]).T\n    \n    # Solve the least squares problem for all neurons simultaneously.\n    # The model is k_counts.T (shape T,N) = X (shape T,3) @ beta_matrix.T (shape 3,N)\n    # np.linalg.lstsq solves ax=b for x. Here a=X, b=train_spikes.T, x=beta_matrix.\n    beta_matrix, _, _, _ = np.linalg.lstsq(X, train_spikes.T, rcond=None)\n    \n    # beta_matrix has shape (3, N). Rows correspond to b_hat, c_hat, s_hat.\n    b_hat = beta_matrix[0, :]\n    c_hat = beta_matrix[1, :]\n    s_hat = beta_matrix[2, :]\n    \n    g_hat = np.sqrt(c_hat**2 + s_hat**2)\n    theta_hat = np.arctan2(s_hat, c_hat)\n\n    # === Step 3: Generate test data and decode ===\n    rng_test = np.random.default_rng(test_seed)\n    test_stimuli = rng_test.uniform(-np.pi, np.pi, size=K)\n    \n    # test_spikes will have shape (N, K)\n    test_spikes = np.zeros((N, K))\n    for i in range(N):\n        rates = bs[i] + gs[i] * np.cos(test_stimuli - thetas[i])\n        test_spikes[i, :] = rng_test.poisson(rates)\n        \n    # Decoding using vector averaging\n    valid_neurons_mask = g_hat >= epsilon\n    \n    # Weights for population vector, shape (N, K)\n    weights = test_spikes - b_hat[:, np.newaxis]\n    weights[weights < 0] = 0.0\n    weights[~valid_neurons_mask, :] = 0.0  # Zero out weights for invalid neurons\n    \n    # Preferred direction vectors, one x and one y component per neuron\n    pref_dir_vectors_x = np.cos(theta_hat)\n    pref_dir_vectors_y = np.sin(theta_hat)\n    \n    # Population vector components, summed over neurons for each trial, shape (K,)\n    pop_vector_x = pref_dir_vectors_x @ weights\n    pop_vector_y = pref_dir_vectors_y @ weights\n    \n    decoded_stimuli = np.arctan2(pop_vector_y, pop_vector_x)\n\n    # === Step 4: Evaluate performance ===\n    # Calculate absolute circular error\n    error_diff = decoded_stimuli - test_stimuli\n    circular_errors = np.abs((error_diff + np.pi) % (2 * np.pi) - np.pi)\n    \n    mean_abs_error = np.mean(circular_errors)\n    \n    return mean_abs_error\n\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path, diverse gains, ample training\n        {\n            \"N\": 8, \"T\": 200, \"K\": 50,\n            \"b_val\": 20.0, \"gs\": [14.0, 12.0, 16.0, 10.0, 18.0, 11.0, 15.0, 13.0],\n            \"train_seed\": 101, \"test_seed\": 202\n        },\n        # Case 2: boundary condition with zero-gain neurons\n        {\n            \"N\": 8, \"T\": 60, \"K\": 40,\n            \"b_val\": 20.0, \"gs\": [0.0, 0.0, 12.0, 10.0, 8.0, 0.0, 6.0, 0.0],\n            \"train_seed\": 303, \"test_seed\": 404\n        },\n        # Case 3: small-sample, low-gain, noisier setting\n        {\n            \"N\": 6, \"T\": 30, \"K\": 30,\n            \"b_val\": 15.0, \"gs\": [5.0, 4.0, 3.0, 2.0, 5.0, 4.0],\n            \"train_seed\": 505, \"test_seed\": 606\n        }\n    ]\n\n    results = []\n    epsilon = 1e-3\n\n    for case in test_cases:\n        N = case[\"N\"]\n        # True preferred directions are evenly spaced on [-pi, pi)\n        thetas = -np.pi + (2 * np.pi * np.arange(N)) / N\n        bs = np.full(N, case[\"b_val\"])\n        gs = np.array(case[\"gs\"])\n        \n        result = solve_case(\n            N=N, T=case[\"T\"], K=case[\"K\"],\n            thetas=thetas, bs=bs, gs=gs,\n            train_seed=case[\"train_seed\"], test_seed=case[\"test_seed\"],\n            epsilon=epsilon\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "现实世界中的感知不仅仅是处理感官输入，还涉及将证据与先验信念或期望相结合。本实践演示了如何将向量平均解码器扩展到贝叶斯框架中。我们将通过结合神经数据的似然（由群体向量表示）和一个关于刺激的非均匀先验信念，来计算最大后验（MAP）估计，从而阐释一个更复杂且神经上更合理的解码模型。",
            "id": "4010755",
            "problem": "初级视皮层中一个由 $N=8$ 个方向调谐神经元组成的群体编码一个圆形变量（方向）$\\theta \\in [0,2\\pi)$。对于 $k=1,\\dots,8$，这些神经元具有均匀间隔的偏好方向 $\\phi_{k} \\in \\{0,\\frac{\\pi}{4},\\frac{\\pi}{2},\\frac{3\\pi}{4},\\pi,\\frac{5\\pi}{4},\\frac{3\\pi}{2},\\frac{7\\pi}{4}\\}$。假设神经元发放是独立的泊松过程，具有相同的基线发放率和相同形状与增益的余弦类调谐曲线，并且偏好方向的分布是密集的、近似均匀的。在这些条件下，对数似然中依赖于 $\\theta$ 的部分可以由其圆形傅里叶级数的一阶谐波很好地近似，并且与使用发放计数作为偏好方向权重的向量平均解码器兼容。在单个观测窗口内记录的发放计数为\n$$\nn_{1}=14,\\quad n_{2}=23,\\quad n_{3}=21,\\quad n_{4}=10,\\quad n_{5}=7,\\quad n_{6}=5,\\quad n_{7}=8,\\quad n_{8}=12.\n$$\n此外，观察者对 $\\theta$ 有一个非均匀先验，该先验是冯·米塞斯分布，其平均方向为 $\\theta_{0}=\\frac{\\pi}{6}$，集中参数为 $\\kappa_{0}=10$，即 $\\pi(\\theta)\\propto \\exp\\!\\big(\\kappa_{0}\\cos(\\theta-\\theta_{0})\\big)$。使用贝叶斯法则和所述的建模假设，确定一个结合了此先验的向量平均解码器所产生的 $\\theta$ 的最大后验（MAP）估计。以弧度表示你的最终答案，并四舍五入到四位有效数字。",
            "solution": "该问题要求在给定一组神经元群体的发放计数和 $\\theta$ 的一个先验分布的情况下，求出刺激方向 $\\theta$ 的最大后验（MAP）估计。这是贝叶斯推断中的一个典型问题。\n\n根据贝叶斯法则，给定观测到的发放计数 $\\mathbf{n} = (n_1, \\dots, n_N)$，刺激 $\\theta$ 的后验概率由下式给出：\n$$\nP(\\theta|\\mathbf{n}) = \\frac{P(\\mathbf{n}|\\theta)\\pi(\\theta)}{P(\\mathbf{n})}\n$$\n其中 $P(\\mathbf{n}|\\theta)$ 是在给定刺激下观测到该发放计数的似然，$\\pi(\\theta)$ 是刺激的先验概率，而 $P(\\mathbf{n})$ 是数据的边缘概率，它作为一个归一化常数。\n\nMAP 估计 $\\hat{\\theta}_{MAP}$ 是使后验概率 $P(\\theta|\\mathbf{n})$ 最大化的 $\\theta$ 值。由于分母 $P(\\mathbf{n})$ 与 $\\theta$ 无关，这等价于最大化似然与先验的乘积：\n$$\n\\hat{\\theta}_{MAP} = \\underset{\\theta}{\\arg\\max} \\, [P(\\mathbf{n}|\\theta)\\pi(\\theta)]\n$$\n这也等价于最大化对数后验概率，$\\ln P(\\theta|\\mathbf{n}) = \\ln P(\\mathbf{n}|\\theta) + \\ln \\pi(\\theta) - \\ln P(\\mathbf{n})$。\n\n问题陈述解码过程与向量平均解码器兼容，且对数似然中依赖于 $\\theta$ 的部分可以由其一阶谐波很好地近似。对于具有余弦调谐的独立泊松神经元，可以证明对数似然近似正比于 $\\sum_{k=1}^{N} n_k \\cos(\\theta - \\phi_k)$，其中 $n_k$ 是发放计数，$\\phi_k$ 是偏好方向。这个表达式可以改写为：\n$$\n\\sum_{k=1}^{N} n_k \\cos(\\theta - \\phi_k) = \\cos\\theta \\left(\\sum_{k=1}^{N} n_k \\cos\\phi_k\\right) + \\sin\\theta \\left(\\sum_{k=1}^{N} n_k \\sin\\phi_k\\right)\n$$\n括号中的项是群体向量 $V_{pop} = (V_{pop,x}, V_{pop,y})$ 的分量，其中 $V_{pop,x} = \\sum_k n_k \\cos\\phi_k$ 且 $V_{pop,y} = \\sum_k n_k \\sin\\phi_k$。因此，该表达式等价于 $|V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML})$，其中 $|V_{pop}|$ 是群体向量的模，$\\hat{\\theta}_{ML} = \\text{atan2}(V_{pop,y}, V_{pop,x})$ 是其角度，对应于 $\\theta$ 的最大似然（ML）估计。\n\n因此，似然函数可以建模为一个冯·米塞斯分布，其中心位于 $\\hat{\\theta}_{ML}$，集中参数与 $|V_{pop}|$ 成正比：\n$$\nP(\\mathbf{n}|\\theta) \\propto \\exp(|V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML}))\n$$\n这是使用向量平均解码器的数学形式化。来自神经数据的“证据”被封装在群体向量 $V_{pop}$ 中。\n\n先验分布被给定为一个冯·米塞斯分布，其平均方向为 $\\theta_0 = \\frac{\\pi}{6}$，集中参数为 $\\kappa_0=10$：\n$$\n\\pi(\\theta) \\propto \\exp(\\kappa_0 \\cos(\\theta - \\theta_0))\n$$\n\n因此，对数后验为：\n$$\n\\ln P(\\theta|\\mathbf{n}) \\propto |V_{pop}|\\cos(\\theta - \\hat{\\theta}_{ML}) + \\kappa_0\\cos(\\theta - \\theta_0)\n$$\n最大化此表达式等价于求两个向量之和的角度。第一个向量是群体向量 $V_{pop}$（代表似然），第二个向量 $V_{prior}$ 的模等于先验的集中参数 $\\kappa_0$，方向等于先验的平均方向 $\\theta_0$。\n\n令 $V_{MAP} = V_{pop} + V_{prior}$。MAP估计 $\\hat{\\theta}_{MAP}$ 是这个合向量的角度。\n\n首先，我们使用给定的发放计数 $n_k$ 和偏好方向 $\\phi_k$ 计算群体向量 $V_{pop} = (V_{pop,x}, V_{pop,y})$。\n偏好方向为 $\\phi_k = (k-1)\\frac{\\pi}{4}$，其中 $k=1, \\dots, 8$：\n$\\{0, \\frac{\\pi}{4}, \\frac{\\pi}{2}, \\frac{3\\pi}{4}, \\pi, \\frac{5\\pi}{4}, \\frac{3\\pi}{2}, \\frac{7\\pi}{4}\\}$。\n发放计数为 $n = \\{14, 23, 21, 10, 7, 5, 8, 12\\}$。\n\n群体向量的 x 分量是：\n$$\nV_{pop,x} = \\sum_{k=1}^{8} n_k \\cos(\\phi_k) = 14\\cos(0) + 23\\cos(\\frac{\\pi}{4}) + 21\\cos(\\frac{\\pi}{2}) + 10\\cos(\\frac{3\\pi}{4}) + 7\\cos(\\pi) + 5\\cos(\\frac{5\\pi}{4}) + 8\\cos(\\frac{3\\pi}{2}) + 12\\cos(\\frac{7\\pi}{4})\n$$\n$$\nV_{pop,x} = 14(1) + 23(\\frac{\\sqrt{2}}{2}) + 21(0) + 10(-\\frac{\\sqrt{2}}{2}) + 7(-1) + 5(-\\frac{\\sqrt{2}}{2}) + 8(0) + 12(\\frac{\\sqrt{2}}{2})\n$$\n$$\nV_{pop,x} = (14-7) + (23-10-5+12)\\frac{\\sqrt{2}}{2} = 7 + 20\\frac{\\sqrt{2}}{2} = 7 + 10\\sqrt{2}\n$$\n\n群体向量的 y 分量是：\n$$\nV_{pop,y} = \\sum_{k=1}^{8} n_k \\sin(\\phi_k) = 14\\sin(0) + 23\\sin(\\frac{\\pi}{4}) + 21\\sin(\\frac{\\pi}{2}) + 10\\sin(\\frac{3\\pi}{4}) + 7\\sin(\\pi) + 5\\sin(\\frac{5\\pi}{4}) + 8\\sin(\\frac{3\\pi}{2}) + 12\\sin(\\frac{7\\pi}{4})\n$$\n$$\nV_{pop,y} = 14(0) + 23(\\frac{\\sqrt{2}}{2}) + 21(1) + 10(\\frac{\\sqrt{2}}{2}) + 7(0) + 5(-\\frac{\\sqrt{2}}{2}) + 8(-1) + 12(-\\frac{\\sqrt{2}}{2})\n$$\n$$\nV_{pop,y} = (21-8) + (23+10-5-12)\\frac{\\sqrt{2}}{2} = 13 + 16\\frac{\\sqrt{2}}{2} = 13 + 8\\sqrt{2}\n$$\n\n接下来，我们定义先验向量 $V_{prior} = (V_{prior,x}, V_{prior,y})$，其模为 $\\kappa_0=10$，角度为 $\\theta_0=\\frac{\\pi}{6}$。\n$$\nV_{prior,x} = \\kappa_0 \\cos(\\theta_0) = 10\\cos(\\frac{\\pi}{6}) = 10(\\frac{\\sqrt{3}}{2}) = 5\\sqrt{3}\n$$\n$$\nV_{prior,y} = \\kappa_0 \\sin(\\theta_0) = 10\\sin(\\frac{\\pi}{6}) = 10(\\frac{1}{2}) = 5\n$$\n\n用于 MAP 估计的合向量是 $V_{MAP} = V_{pop} + V_{prior}$。\n其分量为：\n$$\nV_{MAP,x} = V_{pop,x} + V_{prior,x} = (7 + 10\\sqrt{2}) + 5\\sqrt{3} = 7 + 10\\sqrt{2} + 5\\sqrt{3}\n$$\n$$\nV_{MAP,y} = V_{pop,y} + V_{prior,y} = (13 + 8\\sqrt{2}) + 5 = 18 + 8\\sqrt{2}\n$$\n\n现在，我们计算这些分量的数值：\n$$\nV_{MAP,x} \\approx 7 + 10(1.41421) + 5(1.73205) = 7 + 14.1421 + 8.66025 = 29.80235\n$$\n$$\nV_{MAP,y} \\approx 18 + 8(1.41421) = 18 + 11.31368 = 29.31368\n$$\n\nMAP 估计是这个合向量的角度：\n$$\n\\hat{\\theta}_{MAP} = \\text{atan2}(V_{MAP,y}, V_{MAP,x}) = \\text{atan2}(29.31368, 29.80235)\n$$\n由于两个分量都为正，所以角度在第一象限。\n$$\n\\hat{\\theta}_{MAP} = \\arctan\\left(\\frac{29.31368}{29.80235}\\right) \\approx \\arctan(0.983603) \\approx 0.777095 \\text{ radians}\n$$\n\n将结果四舍五入到四位有效数字，我们得到 $0.7771$。",
            "answer": "$$\\boxed{0.7771}$$"
        },
        {
            "introduction": "构建解码器只是工作的一半，严格评估其性能同样至关重要。这最后一个实践介绍了模型评估的专业标准：K折交叉验证。我们将实施此程序以防止过拟合，并获得对我们解码器准确性的无偏估计，同时计算关键性能指标，如平均绝对环形误差（MACE），从而全面了解解码器的优缺点。",
            "id": "4010791",
            "problem": "您的任务是使用一个真实的余弦调谐神经元群体，实现并评估一个用于方向性刺激的向量平均解码器（Vector Averaging Decoder, VAD）。评估必须使用 K 折交叉验证（K-fold cross-validation, CV）并产出明确定义的性能指标。所有角度必须以弧度表示。每个数值结果必须四舍五入到六位小数。\n\n建模基础：\n- 神经元的方向调谐通过余弦调谐建模。对于偏好方向为 $\\phi_i$ 的神经元 $i$，其对刺激方向 $\\theta$ 的平均发放率是一个形式为 $b + k \\cos(\\theta - \\phi_i)$ 的修正余弦函数，其中 $b \\ge 0$ 是基线发放率，$k \\ge 0$ 是调制幅度。为确保发放率非负，通过 $\\max(0, b + k \\cos(\\theta - \\phi_i))$ 进行修正。\n- 脉冲发放的可变性遵循以平均发放率为条件的泊松过程。对于试验 $t$ 和神经元 $i$，观测到的脉冲计数 $r_{i,t}$ 是一个泊松随机变量，其均值等于修正后的调谐率。\n- 向量平均解码器（VAD）通过减去基线的神经活动和神经元特定的偏好方向单位向量来构建一个群体向量，并通过计算所得向量的角度来解码刺激方向，该角度通过双参数反正切函数计算。\n- K 折交叉验证（CV）将 $T$ 次试验划分为 $K$ 个连续且大小相等的折。对于每一折，训练集通过对训练试验中的脉冲计数取平均来估计每个神经元的基线，然后将解码器应用于留出的测试集。聚合所有折的留出试验以计算指标。\n\n解码与评估协议要求：\n1. 按如下方式为每个测试案例生成一个合成数据集：\n   - 从 $[0, 2\\pi)$ 中独立且均匀地抽取 $N$ 个偏好方向 $\\phi_i$。\n   - 从 $[0, 2\\pi)$ 中独立且均匀地抽取 $T$ 个刺激方向 $\\theta_t$。\n   - 计算平均发放率 $\\lambda_{i,t} = \\max(0, b + k \\cos(\\theta_t - \\phi_i))$。\n   - 采样脉冲计数 $r_{i,t} \\sim \\mathrm{Poisson}(\\lambda_{i,t})$。\n2. 使用连续的折执行 K 折交叉验证。设 $L = T/K$ 为折的长度（假设 $K$ 能整除 $T$）。对于折 $f \\in \\{0, 1, \\ldots, K-1\\}$，定义测试索引为 $t \\in \\{fL, fL+1, \\ldots, (f+1)L - 1\\}$，训练索引为所有其他索引。对于每一折：\n   - 将在训练试验中 $r_{i,t}$ 的均值作为每个神经元的基线估计值 $\\hat{b}_i$。\n   - 对于每个测试试验 $t$，通过使用减去基线的脉冲计数和对应于 $\\phi_i$ 的单位向量形成群体向量，并使用双参数反正切函数取其角度，来计算解码角度 $\\hat{\\theta}_t$。如果所得向量的模为零，按约定将 $\\hat{\\theta}_t$ 设置为 $0$。\n3. 对于所有留出的试验（跨折聚合），计算：\n   - 平均绝对圆形误差（Mean Absolute Circular Error, MACE）：$\\frac{1}{T} \\sum_{t=1}^{T} \\left| \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) \\right|$，其中 $\\mathrm{wrap}(\\alpha)$ 使用恒等式 $\\mathrm{wrap}(\\alpha) = \\arctan2(\\sin(\\alpha), \\cos(\\alpha))$ 将 $\\alpha$ 映射到 $(-\\pi, \\pi]$ 区间内。\n   - 圆形偏差（Circular Bias, BIAS）：$\\frac{1}{T} \\sum_{t=1}^{T} \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t)$。\n   - 容差 $\\tau$ 内的比例（Fraction within tolerance, FRAC）：满足 $\\left| \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) \\right| \\le \\tau$ 的留出试验所占的比例。\n4. 输入和输出的角度单位均为弧度。基线估计、VAD 解码和误差计算必须严格遵循上述定义。\n\n您的程序必须实现上述协议，并为以下测试套件生成结果。在每个案例中，使用一个独立的随机数生成器，其固定种子等于 $42 + s$，其中 $s$ 是从 $0$ 开始的测试案例索引。\n\n测试套件（每个元组为 $(N, T, K, b, k, \\tau)$）：\n- 案例 $0$：$(50, 200, 5, 15, 10, 0.5)$\n- 案例 $1$：$(8, 120, 6, 10, 12, 0.5)$\n- 案例 $2$：$(4, 100, 4, 10, 10, 0.4)$\n- 案例 $3$：$(60, 240, 8, 20, 0, 0.5)$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个外层列表，内含每个测试案例的结果。每个测试案例的结果是一个列表 $[\\mathrm{MACE}, \\mathrm{BIAS}, \\mathrm{FRAC}]$，所有条目均四舍五入到六位小数。该行必须是一个用方括号括起来的、以逗号分隔的列表，且不含空格。例如：$[[0.123456,-0.000001,0.987654],[\\ldots],[\\ldots],[\\ldots]]$。",
            "solution": "问题陈述经评估有效。它在科学上是合理的，在数学上是适定的，并为计算神经科学模拟提供了完整且无歧义的规范。因此，我们可以着手提供解决方案。\n\n目标是为一个编码方向性刺激的神经元群体实现并评估一个向量平均解码器（VAD）。评估将在一个合成生成的数据集上使用 K 折交叉验证协议。\n\n**1. 基础模型**\n\n首先，我们定义神经编码模型的组成部分。\n\n**神经元调谐模型：**\n每个神经元的发放率都调谐到一个特定方向。对于一个偏好方向为 $\\phi_i$ 的给定神经元 $i$，其对呈现在方向 $\\theta_t$ 的刺激的平均发放率 $\\lambda_{i,t}$ 由一个修正余弦调谐曲线描述。这是方向选择性神经元（例如运动皮层中的神经元）的一个标准模型。公式为：\n$$\n\\lambda_{i,t} = \\max(0, b + k \\cos(\\theta_t - \\phi_i))\n$$\n这里，$b \\ge 0$ 代表基线发放率（在没有方向调制时神经元的活动），$k \\ge 0$ 是调制幅度，它决定了神经元的发放率受刺激方向影响的强度。$\\max(0, \\cdot)$ 函数确保了作为物理量的发放率不会是负数。\n\n**脉冲发放可变性模型：**\n神经脉冲序列表现出固有的随机性。这种可变性使用泊松过程建模。在试验 $t$ 期间从神经元 $i$ 记录到的脉冲数量（计数）$r_{i,t}$ 是一个从泊松分布中抽取的随机变量，其均值由调谐曲线 $\\lambda_{i,t}$ 给出：\n$$\nr_{i,t} \\sim \\mathrm{Poisson}(\\lambda_{i,t})\n$$\n\n**2. 数据生成协议**\n\n对于每个测试案例，我们根据以下规范生成一个合成数据集：\n- 创建一个包含 $N$ 个神经元的群体。为每个神经元 $i$ 分配一个偏好方向 $\\phi_i$，该方向从区间 $[0, 2\\pi)$ 中独立且均匀地抽取。\n- 模拟一个包含 $T$ 次试验的序列。对于每次试验 $t$，从 $[0, 2\\pi)$ 中独立且均匀地抽取一个刺激方向 $\\theta_t$。\n- 对于每个神经元 $i$ 和试验 $t$，使用修正余弦调谐模型计算平均发放率 $\\lambda_{i,t}$。\n- 然后从均值为 $\\lambda_{i,t}$ 的泊松分布中采样相应的脉冲计数 $r_{i,t}$。\n这个过程生成脉冲计数矩阵 $r_{i,t}$，以及真实的刺激方向 $\\theta_t$ 和神经元偏好方向 $\\phi_i$。\n\n**3. 解码与交叉验证**\n\n为了稳健地评估解码器的性能，我们采用 K 折交叉验证程序。该方法通过确保用于训练解码器（即估计其参数）的数据与用于测试它的数据相分离，来防止过拟合。\n\n**分区：** 将 $T$ 次试验划分为 $K$ 个不重叠、连续且大小相等的块（折），每个块的大小为 $L = T/K$。\n\n**迭代：** 该过程迭代 $K$ 次。在每次迭代 $f \\in \\{0, 1, \\ldots, K-1\\}$ 中，将一个折指定为测试集，其余 $K-1$ 个折构成训练集。\n\n**基线估计：** VAD 的一个关键参数是每个神经元的基线发放率。问题指定了一种经验估计方法。对于每个神经元 $i$，其基线发放率 $\\hat{b}_i$ 通过计算其在当前训练集所有试验 $t$ 中的观测脉冲计数 $r_{i,t}$ 的平均值来估计：\n$$\n\\hat{b}_i = \\frac{1}{T_{\\text{train}}} \\sum_{t \\in \\text{train}} r_{i,t}\n$$\n其中 $T_{\\text{train}}$ 是训练集中的试验次数。\n\n**向量平均解码器（VAD）：** 对于测试集中的每次试验 $t$，解码刺激方向。VAD 算法的工作原理如下：\n- 对于每个神经元 $i$，其对群体活动的贡献是其减去基线后的发放率，即 $(r_{i,t} - \\hat{b}_i)$。这个值代表了该神经元的活动偏离其平均水平的程度。\n- 通过对指向每个神经元偏好方向的单位向量进行加权求和，形成一个群体向量 $\\vec{P}_t$。每个神经元的权重是其减去基线后的发放率。\n$$\n\\vec{P}_t = \\sum_{i=1}^{N} (r_{i,t} - \\hat{b}_i) \\vec{c}_i = \\sum_{i=1}^{N} (r_{i,t} - \\hat{b}_i) \\begin{bmatrix} \\cos(\\phi_i) \\\\ \\sin(\\phi_i) \\end{bmatrix} = \\begin{bmatrix} P_{t,x} \\\\ P_{t,y} \\end{bmatrix}\n$$\n- 解码角度 $\\hat{\\theta}_t$ 是所得群体向量 $\\vec{P}_t$ 的方向。这通过使用双参数反正切函数 $\\mathrm{atan2}$ 计算，该函数能正确解析所有四个象限中的角度。\n$$\n\\hat{\\theta}_t = \\mathrm{atan2}(P_{t,y}, P_{t,x})\n$$\n- 根据约定，如果群体向量的模为零，即 $\\|\\vec{P}_t\\| = 0$，则解码角度设为 $\\hat{\\theta}_t = 0$。\n\n对所有 $K$ 个折重复此过程，从而为每次试验 $t=1, \\ldots, T$ 得到一个解码角度 $\\hat{\\theta}_t$。\n\n**4. 性能评估指标**\n\n交叉验证后，通过比较所有 $T$ 次试验的解码角度 $\\hat{\\theta}_t$ 与真实刺激角度 $\\theta_t$ 来量化解码器的性能。由于我们处理的是循环数据（角度），需要使用专门的误差指标。\n\n**圆形误差：** 对于每次试验 $t$，圆形误差 $\\Delta\\theta_t$ 是 $\\hat{\\theta}_t$ 和 $\\theta_t$ 之间的最短角度。它通过将其差值包裹到区间 $(-\\pi, \\pi]$ 内来计算：\n$$\n\\Delta\\theta_t = \\mathrm{wrap}(\\hat{\\theta}_t - \\theta_t) = \\mathrm{atan2}(\\sin(\\hat{\\theta}_t - \\theta_t), \\cos(\\hat{\\theta}_t - \\theta_t))\n$$\n使用这些误差，我们计算三个聚合指标：\n\n- **平均绝对圆形误差（MACE）：** 解码误差的平均绝对大小。它衡量解码器的精度。\n$$\n\\mathrm{MACE} = \\frac{1}{T} \\sum_{t=1}^{T} |\\Delta\\theta_t|\n$$\n\n- **圆形偏差（BIAS）：** 平均带符号解码误差。它衡量解码器高估或低估角度的任何系统性趋势。\n$$\n\\mathrm{BIAS} = \\frac{1}{T} \\sum_{t=1}^{T} \\Delta\\theta_t\n$$\n\n- **容差内比例（FRAC）：** 绝对圆形误差在指定容差 $\\tau$ 内的试验所占的比例。\n$$\n\\mathrm{FRAC} = \\frac{1}{T} \\sum_{t=1}^{T} \\mathbb{I}(|\\Delta\\theta_t| \\le \\tau)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数，当其参数为真时为 $1$，否则为 $0$。\n\n该实现将为问题中定义的每个测试案例执行这整个协议，并为每个案例使用不同的随机种子以确保可复现性。所有数值结果将按要求四舍五入到六位小数。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates a Vector Averaging Decoder (VAD) for\n    directional stimuli using a population of cosine-tuned neurons.\n    The evaluation uses K-fold cross-validation and computes MACE, BIAS, and FRAC metrics.\n    \"\"\"\n\n    test_cases = [\n        # (N, T, K, b, k, tau)\n        (50, 200, 5, 15, 10, 0.5), # Case 0\n        (8, 120, 6, 10, 12, 0.5), # Case 1\n        (4, 100, 4, 10, 10, 0.4), # Case 2\n        (60, 240, 8, 20, 0, 0.5),  # Case 3\n    ]\n\n    all_results_formatted = []\n\n    for s, case in enumerate(test_cases):\n        N, T, K, b, k, tau = case\n        seed = 42 + s\n        rng = np.random.default_rng(seed)\n\n        # Step 1: Generate synthetic dataset\n        # Preferred directions for N neurons, phi_i ~ U[0, 2*pi)\n        phi = rng.uniform(0, 2 * np.pi, size=N)  # Shape: (N,)\n        \n        # Stimulus directions for T trials, theta_t ~ U[0, 2*pi)\n        theta = rng.uniform(0, 2 * np.pi, size=T)  # Shape: (T,)\n\n        # Compute mean firing rates lambda_it = max(0, b + k*cos(theta_t - phi_i))\n        # Use broadcasting to compute difference for all (i, t) pairs\n        # theta[np.newaxis, :] -> shape (1, T)\n        # phi[:, np.newaxis]   -> shape (N, 1)\n        # Difference results in shape (N, T)\n        angle_diff = theta[np.newaxis, :] - phi[:, np.newaxis]\n        mean_rates = b + k * np.cos(angle_diff)\n        mean_rates[mean_rates < 0] = 0  # Rectification\n        \n        # Sample spike counts r_it ~ Poisson(lambda_it)\n        r = rng.poisson(mean_rates)  # Shape: (N, T)\n\n        # Arrays to store aggregated results from all test folds\n        all_theta_true = np.zeros(T)\n        all_theta_decoded = np.zeros(T)\n        \n        # Step 2: Perform K-fold cross-validation\n        fold_length = T // K\n        indices = np.arange(T)\n        \n        for f in range(K):\n            test_indices = indices[f * fold_length : (f + 1) * fold_length]\n            train_indices = np.setdiff1d(indices, test_indices, assume_unique=True)\n            \n            # Estimate per-neuron baselines b_hat_i from training data\n            # Average spike counts for each neuron over training trials\n            r_train = r[:, train_indices]\n            b_hat = np.mean(r_train, axis=1)  # Shape: (N,)\n            \n            # Decode each trial in the current test fold\n            r_test = r[:, test_indices]      # Shape: (N, fold_length)\n            theta_test = theta[test_indices] # Shape: (fold_length,)\n            \n            # Subtract estimated baselines from test counts\n            r_subtracted = r_test - b_hat[:, np.newaxis] # Broadcasting b_hat\n            \n            # Create unit vectors for preferred directions [c_x, c_y]\n            c_vectors = np.vstack([np.cos(phi), np.sin(phi)]) # Shape: (2, N)\n            \n            # Compute population vector P_t by summing weighted unit vectors\n            # P = c_vectors @ r_subtracted\n            # (2, N) @ (N, fold_length) results in (2, fold_length)\n            P = c_vectors @ r_subtracted\n            \n            # Decode angle as the angle of the population vector\n            theta_decoded_fold = np.arctan2(P[1, :], P[0, :])\n            \n            # Convention for zero-magnitude vectors\n            magnitudes = np.linalg.norm(P, axis=0)\n            theta_decoded_fold[magnitudes == 0] = 0.0\n\n            # Store true and decoded angles for this fold\n            all_theta_true[test_indices] = theta_test\n            all_theta_decoded[test_indices] = theta_decoded_fold\n\n        # Step 3: Compute performance metrics over all T trials\n        # Calculate circular error: wrap(decoded - true)\n        error = all_theta_decoded - all_theta_true\n        wrapped_error = np.arctan2(np.sin(error), np.cos(error))\n\n        # MACE: Mean Absolute Circular Error\n        mace = np.mean(np.abs(wrapped_error))\n        \n        # BIAS: Circular Bias\n        bias = np.mean(wrapped_error)\n        \n        # FRAC: Fraction of trials with absolute error <= tau\n        frac = np.mean(np.abs(wrapped_error) <= tau)\n        \n        # Format results for this test case\n        case_results_str = f\"[{mace:.6f},{bias:.6f},{frac:.6f}]\"\n        all_results_formatted.append(case_results_str)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results_formatted)}]\")\n\nsolve()\n```"
        }
    ]
}