{
    "hands_on_practices": [
        {
            "introduction": "When implementing Linear-Nonlinear-Poisson (LNP) models, we often discretize time into small bins to facilitate computation. This practice relies on a key approximation: treating the spike generation within each bin as a simple binary event. This exercise  challenges you to formalize this common simplification, connecting the underlying continuous-time Poisson process to a discrete-time Bernoulli trial and quantifying the error introduced by this approximation.",
            "id": "3995097",
            "problem": "Consider a Linear-Nonlinear-Poisson (LNP) cascade model of neural encoding. A time-varying stimulus $s(t)$ is passed through a linear filter $k(\\tau)$ to produce a generator signal $u(t) = \\int k(\\tau)\\,s(t-\\tau)\\,d\\tau$, which is then transformed by a static nonlinearity $f(\\cdot)$ to yield a conditional intensity (instantaneous firing rate) $\\lambda(t) = f(u(t))$. The spike train is generated by an inhomogeneous Poisson process with rate $\\lambda(t)$. In discrete-time implementations, time is partitioned into bins of width $\\Delta > 0$, and it is common to approximate spiking within each bin by a Bernoulli random variable that indicates the occurrence of at least one spike.\n\nStarting from the definition of a Poisson process and the fact that counts in a time bin of width $\\Delta$ are Poisson distributed with mean $\\lambda(t)\\Delta$ when $\\lambda(t)$ is approximately constant within the bin, derive the exact probability $p_{\\mathrm{Pois}}(t)$ that the bin contains at least one spike. Then justify the Bernoulli approximation $p_{\\mathrm{Bern}}(t) = \\lambda(t)\\Delta$ under low firing rates and small $\\Delta$ by invoking a principled asymptotic expansion. Finally, define the approximation error $\\varepsilon(t) = p_{\\mathrm{Bern}}(t) - p_{\\mathrm{Pois}}(t)$ and compute its leading-order term as $\\Delta \\to 0$, retaining the first nonzero term in the expansion. Express your final answer as a closed-form analytic expression in terms of $\\lambda$ and $\\Delta$, where $\\lambda$ denotes the value $\\lambda(t)$ within the bin. No numerical evaluation is required.",
            "solution": "The Linear-Nonlinear-Poisson (LNP) framework posits that spikes are generated by an inhomogeneous Poisson process with conditional intensity $\\lambda(t)$ determined by the stimulus through a linear filter and a static nonlinearity. For a small time bin of width $\\Delta$, if $\\lambda(t)$ is approximately constant across the bin, the spike count $N$ within the bin is distributed as a Poisson random variable with mean $\\mu = \\lambda \\Delta$, where $\\lambda$ denotes $\\lambda(t)$ evaluated within the bin.\n\nBy the defining property of a Poisson process, the probability of observing zero spikes in the bin is\n$$\n\\mathbb{P}(N = 0) = \\exp(-\\lambda \\Delta).\n$$\nTherefore, the exact probability of observing at least one spike in the bin is\n$$\np_{\\mathrm{Pois}} = \\mathbb{P}(N \\geq 1) = 1 - \\mathbb{P}(N = 0) = 1 - \\exp(-\\lambda \\Delta).\n$$\n\nIn discrete-time modeling, a common approximation is to treat the binary event of at least one spike as a Bernoulli random variable with parameter $p_{\\mathrm{Bern}} = \\lambda \\Delta$. This is motivated by the low-rate, small-bin limit. To justify this approximation, we use the Taylor expansion of the exponential function about $0$:\n$$\n\\exp(-x) = 1 - x + \\frac{x^{2}}{2} - \\frac{x^{3}}{6} + \\frac{x^{4}}{24} - \\cdots,\n$$\nwhere $x = \\lambda \\Delta$. Substituting gives\n$$\np_{\\mathrm{Pois}} = 1 - \\exp(-\\lambda \\Delta) = \\lambda \\Delta - \\frac{(\\lambda \\Delta)^{2}}{2} + \\frac{(\\lambda \\Delta)^{3}}{6} - \\cdots.\n$$\nThe Bernoulli approximation $p_{\\mathrm{Bern}} = \\lambda \\Delta$ corresponds to truncating this series at its first term. The approximation error is then\n$$\n\\varepsilon = p_{\\mathrm{Bern}} - p_{\\mathrm{Pois}} = \\lambda \\Delta - \\left(\\lambda \\Delta - \\frac{(\\lambda \\Delta)^{2}}{2} + \\frac{(\\lambda \\Delta)^{3}}{6} - \\cdots\\right)\n= \\frac{(\\lambda \\Delta)^{2}}{2} - \\frac{(\\lambda \\Delta)^{3}}{6} + \\cdots.\n$$\nAs $\\Delta \\to 0$ with $\\lambda$ bounded (the low firing rate, small-bin regime), the leading nonzero term in the error is\n$$\n\\varepsilon \\sim \\frac{(\\lambda \\Delta)^{2}}{2}.\n$$\nThis term quantifies the first-order (in the asymptotic sense of the leading nonvanishing contribution) deviation of the Bernoulli approximation from the true Poisson probability of at least one spike. It reflects the neglected probability mass of observing two or more spikes within a bin, which scales as $\\mathcal{O}((\\lambda \\Delta)^{2})$.\n\nThus, the leading-order approximation error in the probability of at least one spike, expressed in terms of $\\lambda$ and $\\Delta$, is\n$$\n\\frac{1}{2}\\lambda^{2}\\Delta^{2}.\n$$",
            "answer": "$$\\boxed{\\frac{1}{2}\\lambda^{2}\\Delta^{2}}$$"
        },
        {
            "introduction": "Estimating a neural filter in the high-dimensional regime, where the number of model parameters $p$ far exceeds the number of data points $n$ ($p \\gg n$), requires regularization to ensure a stable and generalizable solution. The choice of a regularization penalty is not merely technical; it encodes a scientific hypothesis about the filter's underlying structure. This exercise  challenges you to connect different regularization methods to distinct structural priors on a receptive field and to identify a statistically sound procedure for model selection.",
            "id": "3995053",
            "problem": "A laboratory is fitting a Linear-Nonlinear (LN) cascade model to spiking responses elicited by high-dimensional visual stimuli. The stimuli at times $t \\in \\{1,\\dots,n\\}$ are represented as vectors $x_t \\in \\mathbb{R}^p$ (obtained by vectorizing a $2$-dimensional pixel grid), and the spike counts $y_t \\in \\{0,1,2,\\dots\\}$ are modeled by a Poisson Generalized Linear Model (GLM) with log link, so that the conditional intensity is $\\lambda_t = \\exp\\{k^\\top x_t + b\\}$, where $k \\in \\mathbb{R}^p$ is the unknown receptive field and $b \\in \\mathbb{R}$ is a bias. The available data satisfy $n \\ll p$ (limited data), and the stimulus vectors have been whitened so that the empirical covariance of $\\{x_t\\}$ is approximately the identity. The laboratory is considering three regularization penalties to estimate $k$: (i) ridge, which uses an $\\ell_2$ penalty on $k$, (ii) elastic net, which uses a convex combination of $\\ell_1$ and $\\ell_2$ penalties on $k$, and (iii) Total Variation (TV), which penalizes the sum of absolute discrete spatial gradients of $k$ across the $2$-dimensional pixel grid. The team contemplates three plausible ground-truth structures for $k$: (S$1$) dense and distributed weights forming a smooth, oscillatory Gabor-like pattern; (S$2$) piecewise-constant patches with a small number of sharp boundaries; (S$3$) a small number of isolated, nonzero pixels with no contiguity. They must also decide how to select both the penalty family and its hyperparameters under limited data.\n\nWhich option below correctly matches the penalties to the ground-truth structures they are best aligned with and proposes a statistically sound selection criterion in this Poisson LN setting with $n \\ll p$?\n\nA. Prefer ridge for (S$2$), elastic net for (S$1$), and TV for (S$3$); select the penalty and hyperparameters by minimizing the penalized training negative log-likelihood on the full dataset to avoid variance from data splits.\n\nB. Prefer TV for (S$2$), elastic net for (S$3$), and ridge for (S$1$); select the penalty family and hyperparameters by nested $K$-fold cross-validation maximizing held-out predictive log-likelihood (or, equivalently, minimizing held-out Poisson deviance) of the full LN model.\n\nC. Prefer TV for (S$3$) because it enforces coefficient sparsity, ridge for (S$2$) to blur edges, and elastic net for (S$1$) to stabilize dense patterns; select the penalty by picking the model with the smallest in-sample Akaike Information Criterion (AIC) computed using the number of nonzeros in $k$ as the degrees of freedom for all penalties.\n\nD. Ridge and elastic net are equivalent under stimulus whitening, so either suffices for (S$1$) and (S$3$); TV is unsuitable for (S$2$) because it over-smooths edges; select among the three by a single $K$-fold cross-validation on training data that simultaneously tunes hyperparameters and reports the final test performance on the same folds.",
            "solution": "The problem asks to match three regularization penalties (ridge, elastic net, TV) to three plausible structures for a neural receptive field ($k$) and to identify a sound model selection procedure in a high-dimensional ($n \\ll p$) setting.\n\n**Part 1: Matching Penalties to Structural Priors**\n\n1.  **Ridge ($\\ell_2$ penalty):** The penalty is $\\|k\\|_2^2$. It shrinks all coefficients towards zero but rarely sets them to exactly zero. It favors solutions where the signal energy is distributed across many small coefficients, making it ideal for **dense and smooth** signals. This matches structure **(S$1$)**: a Gabor-like pattern is dense, smooth, and oscillatory.\n\n2.  **Elastic Net ($\\ell_1 + \\ell_2$ penalty):** The dominant component for structure selection is the $\\ell_1$ penalty, which is known to induce **sparsity** by driving many coefficients to exactly zero. This makes it ideal for signals where only a few components are non-zero. This matches structure **(S$3$)**: a small number of isolated, non-contiguous active pixels.\n\n3.  **Total Variation (TV):** The TV penalty penalizes the sum of the magnitudes of the gradient of $k$. This penalty is small for images or fields that are **piecewise-constant** (flat within regions). It is particularly effective at preserving sharp edges between these constant regions, which is a property not well-captured by ridge or LASSO. This matches structure **(S$2$)**: piecewise-constant patches with sharp boundaries.\n\nTherefore, the correct matching is: Ridge $\\to$ (S$1$), TV $\\to$ (S$2$), and Elastic Net $\\to$ (S$3$).\n\n**Part 2: Choosing a Model Selection Procedure**\n\nThe setting is high-dimensional ($n \\ll p$), where overfitting is a major risk. Any model selection procedure must estimate out-of-sample generalization performance.\n\n*   **In-sample metrics (A, C) are incorrect:** Minimizing the training-set objective function (A) or using an in-sample information criterion like AIC (C) are unreliable in the $n \\ll p$ regime. These methods do not adequately penalize for overfitting and will favor overly complex models. Furthermore, the degrees of freedom for regularized models are not simply the number of non-zero coefficients, making the AIC calculation in (C) problematic.\n\n*   **Single cross-validation loop (D) is incorrect:** Using the same cross-validation procedure to both tune hyperparameters (and select the model family) and to report the final performance leads to an optimistically biased performance estimate. The model has been chosen because it performed best on the validation folds, so its performance on those same folds is not a fair estimate of how it would do on truly new data.\n\n*   **Nested cross-validation (B) is correct:** This is the gold-standard procedure for this situation.\n    *   An **outer loop** splits the data to create a final, held-out test set for unbiased performance evaluation.\n    *   An **inner loop** is run on the training data from the outer loop to perform model selection: it finds the best hyperparameters for each penalty family (Ridge, EN, TV) and then selects the family that performs best on the inner validation sets.\n    *   The final chosen model (e.g., TV with its optimal hyperparameter) is then retrained on the full outer-loop training set and evaluated once on the outer-loop test set.\n    *   Averaging the performance over the outer folds gives an unbiased estimate of the generalization performance of the entire selection pipeline.\n    *   The performance metric—held-out predictive log-likelihood or Poisson deviance—is the correct choice for a Poisson GLM.\n\n**Conclusion:**\n\nOption B correctly matches the penalties to the structures (TV for S2, elastic net for S3, ridge for S1) and proposes the statistically rigorous method of nested cross-validation to select the model family and its hyperparameters while providing an unbiased estimate of generalization performance. The other options contain incorrect matches or flawed statistical reasoning.",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "A model is only as good as its ability to predict new, unseen data, and cross-validation is our primary tool for assessing this power. When applying this technique to neural data collected over time, however, standard random splits are invalid and can lead to deceptively high performance due to temporal correlations. This exercise  presents a realistic scenario where you must design a cross-validation scheme that carefully avoids this 'temporal leakage' by accounting for both the filter's memory and the stimulus's autocorrelation.",
            "id": "3995071",
            "problem": "A laboratory records a single continuous stimulus time series $s(t)$ for $T = 600\\,\\mathrm{s}$ at sampling interval $\\Delta t = 10\\,\\mathrm{ms}$, presented to a sensory neuron. The neuron is modeled by a linear-nonlinear cascade, where the predicted conditional intensity (instantaneous firing rate) under a Poisson observation model is $ \\lambda(t) = f\\big((k * s)(t)\\big) $, with $k(\\tau)$ a causal finite impulse response kernel supported on $\\tau \\in [0, L]$ and $f(\\cdot)$ a static nonlinearity. The kernel support is known to be $L = 300\\,\\mathrm{ms}$. The measured stimulus autocorrelation function is $R_s(\\tau) = \\mathbb{E}[s(t)s(t+\\tau)] = \\sigma^2 e^{-|\\tau|/\\tau_c}$ with time constant $\\tau_c = 200\\,\\mathrm{ms}$ and variance $\\sigma^2 = \\mathbb{E}[s(t)^2]$. You intend to estimate the generalization performance of the model with $k$-fold cross-validation for $k = 5$, using Poisson log-likelihood on held-out data as the metric.\n\nDefine temporal leakage as the situation in which training and test sets share overlapping or strongly correlated stimulus segments within the effective memory of the model, which can induce optimistic bias in held-out performance. Your goal is to choose a cross-validation protocol that accounts for the stimulus autocorrelation and the model’s finite memory, so that training and test statistics are approximately independent for the purpose of estimating generalization performance.\n\nWhich option best specifies a scientifically sound $k$-fold cross-validation procedure that prevents temporal leakage and accounts for stimulus autocorrelation, given the quantities above and a tolerance level chosen so that $|R_s(\\tau)| \\le \\epsilon$ for all $|\\tau| \\ge \\tau^\\star$, with $\\epsilon = 0.01\\,\\sigma^2$?\n\nA. Randomly permute all time indices into $k = 5$ folds, fit the model on $4/5$ of the permuted time points and evaluate on the remaining $1/5$, repeating across folds. Normalize $s(t)$ by z-scoring using the full $T = 600\\,\\mathrm{s}$ stimulus and do not use any buffer around test samples.\n\nB. Partition the time axis into $k = 5$ contiguous, equal-length blocks of $T/5$ each; for each fold, use one block as test and the remaining four as training. To avoid leakage, exclude training samples within a buffer of width $B_{\\mathrm{buf}} = L = 300\\,\\mathrm{ms}$ on either side of the held-out block. Compute stimulus normalization (mean and variance) on the combined training blocks and apply it to the test block.\n\nC. Partition the time axis into $k = 5$ contiguous, equal-length blocks; for each fold, designate one block as the test block. To prevent leakage, remove from the training set all samples within a symmetric buffer of width $B_{\\mathrm{buf}}$ around the test block, where $B_{\\mathrm{buf}}$ is chosen so that any stimulus sample used by the test block’s convolution window is separated from the training samples by at least $\\tau^\\star$, and also accounts for the kernel memory $L$. Specifically, take $B_{\\mathrm{buf}} = L + \\tau^\\star$, with $\\tau^\\star$ the minimal lag satisfying $|R_s(\\tau)| \\le \\epsilon$, i.e., for the exponential $R_s(\\tau)$, $\\tau^\\star = \\tau_c \\ln(\\sigma^2/\\epsilon) = \\tau_c \\ln(100)$. With $\\tau_c = 200\\,\\mathrm{ms}$ and $\\epsilon = 0.01\\,\\sigma^2$, this yields $B_{\\mathrm{buf}} \\approx 300\\,\\mathrm{ms} + 200\\,\\mathrm{ms}\\times \\ln(100) \\approx 1.221\\,\\mathrm{s}$. Estimate any stimulus preprocessing (mean removal, scaling) solely from the training data of that fold, fit the model, and evaluate Poisson log-likelihood on the test block only.\n\nD. Transform $s(t)$ to the frequency domain via the Discrete Fourier Transform, randomly partition the set of Fourier frequencies into $k = 5$ folds, fit the model using inverse-transformed stimuli from $4/5$ of the randomly selected frequencies, and evaluate on inverse-transformed stimuli from the remaining $1/5$ of frequencies. No time-domain buffers are needed because different frequencies are orthogonal.\n\nE. Fit an autoregressive model of order $p$ to $s(t)$ on the full $T = 600\\,\\mathrm{s}$ series, prewhiten the stimulus to produce residuals $\\tilde{s}(t)$ with approximately zero autocorrelation, then perform random $k = 5$-fold cross-validation by permuting time indices of $\\tilde{s}(t)$, training the linear-nonlinear model on $4/5$ of permuted residual time points and evaluating on $1/5$. Finally, evaluate the fitted model’s log-likelihood on the original unwhitened held-out time points, since predictions are needed in the original domain. No buffers are used.",
            "solution": "This problem requires identifying the most scientifically rigorous cross-validation procedure for time-series data, specifically for an LN model where both model memory and stimulus autocorrelation are present.\n\n*   **Analysis of Option A:** This proposes random permutation of time points. This is fundamentally incorrect for time-series data. It completely ignores the temporal dependencies. A time point in the test set could have its immediate temporal neighbors in the training set. Given the filter length ($L$) and stimulus autocorrelation ($\\tau_c$), this will cause massive information leakage from the training set to the test set, leading to a highly inflated and invalid estimate of generalization performance. Furthermore, normalizing using the full dataset also represents data leakage.\n\n*   **Analysis of Option B:** This option correctly identifies that contiguous blocks (blocked cross-validation) should be used for time-series data. It also correctly proposes using a buffer to prevent leakage. However, the proposed buffer width $B_{\\mathrm{buf}} = L = 300\\,\\mathrm{ms}$ is insufficient. This buffer only accounts for the direct memory of the filter. It completely ignores the fact that the stimulus itself is autocorrelated with a time constant $\\tau_c = 200\\,\\mathrm{ms}$. Stimulus segments just outside the buffer are still highly correlated with segments just inside the buffer, which in turn affect the test block responses. This residual correlation constitutes temporal leakage.\n\n*   **Analysis of Option D:** This proposes cross-validation in the frequency domain. While the Discrete Fourier Transform diagonalizes convolution, making stimulus frequency components orthogonal for a purely *linear* system, this property breaks down in a Linear-Nonlinear model. The static nonlinearity $f(\\cdot)$ couples different frequencies, meaning that training on a subset of frequencies can still provide information about the response to the held-out frequencies. This approach is invalid for nonlinear systems.\n\n*   **Analysis of Option E:** This proposes prewhitening the stimulus. While this is a valid technique to decorrelate data, the described procedure is flawed. Fitting the whitening model on the full dataset leaks information from the test set into the training process. More critically, the procedure for evaluation is incorrect: a model trained to find a filter for the whitened stimulus residuals $\\tilde{s}(t)$ cannot be directly evaluated on the original, unwhitened stimulus $s(t)$ in the test set. The filter and data domains do not match.\n\n*   **Analysis of Option C:** This option presents the most complete and rigorous protocol.\n    1.  **Blocked Cross-Validation:** It correctly uses contiguous blocks of time, which preserves the temporal structure of the data.\n    2.  **Sufficient Buffer:** It correctly identifies that the buffer must account for two sources of temporal dependence: the model's filter memory ($L$) and the stimulus autocorrelation time ($\\tau^\\star$). A test point's response depends on stimuli in the preceding $L$ interval. To ensure independence, the nearest training point must be far enough away that its influential stimulus window does not contain any stimulus values correlated with those influencing the test point. This requires a separation of at least $L$ (for the filter memory) plus $\\tau^\\star$ (the time for stimulus correlation to decay to a negligible level). The calculation for $\\tau^\\star \\approx 921\\,\\mathrm{ms}$ is correct, leading to a total buffer of $B_{\\mathrm{buf}} \\approx 1.221\\,\\mathrm{s}$.\n    3.  **Proper Data Hygiene:** It correctly states that any stimulus preprocessing (like z-scoring) must be estimated *only* from the training data for that specific fold and then applied to the test data. This prevents leaking statistical information from the test set into the model fitting process.\n\nTherefore, option C describes the gold-standard, scientifically sound procedure for cross-validating a model on autocorrelated time-series data.",
            "answer": "$$\\boxed{C}$$"
        }
    ]
}