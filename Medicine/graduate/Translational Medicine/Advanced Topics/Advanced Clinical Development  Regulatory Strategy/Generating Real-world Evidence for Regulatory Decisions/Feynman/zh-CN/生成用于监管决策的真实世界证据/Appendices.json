{
    "hands_on_practices": [
        {
            "introduction": "可靠的真实世界证据 (RWE) 的基石是准确的数据。在基于电子健康记录 (EHR) 的研究中，临床结局通常通过算法（即“表型”）来识别，而这些算法并非完美无缺。本练习将指导您完成验证此类算法的重要过程，更关键的是，学习如何利用其性能特征（敏感性 $Se$ 和特异性 $Sp$）来校正观察到的发生率，从而获得更精确、更符合监管要求的发病率估计值 。这一技能对于任何处理真实世界数据的研究人员都至关重要。",
            "id": "5017986",
            "problem": "一个转化医学团队正在生成真实世界证据（RWE），以支持向美国食品药品监督管理局（FDA）提交关于一种新批准疗法的安全性特征的监管申请。该团队使用基于电子健康记录（EHR）的表型分析算法，在一个大型队列中识别药物性肝损伤（DILI）的新发病例。为确保该算法在监管级别推断中的有效性，团队进行了一次病例审查，得出了一个混淆矩阵，该矩阵将算法与金标准临床裁定进行了验证。\n\n从一个包含 $1{,}200$ 份患者记录的验证样本中，获得了以下计数：\n- 真阳性 ($TP$): $272$\n- 假阳性 ($FP$): $8$\n- 真阴性 ($TN$): $904$\n- 假阴性 ($FN$): $16$\n\n完整研究队列贡献了 $52{,}000$ 人年的随访，在此期间，该算法标记了 $1{,}040$ 起新发DILI事件。\n\n从第一性原理出发——即灵敏度、特异度、阳性预测值（PPV）和阴性预测值（NPV）的核心定义，以及二元错分的全概率定律——完成以下任务：\n1. 使用验证样本计算该算法的灵敏度、特异度、PPV和NPV。\n2. 假设错分是非差异性且不随时间变化的（即在所有患者-时间单位中灵敏度和特异度恒定），并且事件足够罕见，可将每人年视为一次伯努利试验，请推导一个表达式，使用从验证中得出的灵敏度和特异度来校正观察到的新发事件比例。将此表达式应用于完整队列，以获得校正后每 $1{,}000$ 人年的发生率。\n\n以每 $1{,}000$ 人年事件数作为单位表示最终的校正后发生率，并将您的最终数值答案四舍五入到四位有效数字。仅报告校正后的发生率作为最终答案。",
            "solution": "该问题要求完成两项主要任务：首先，根据一项验证研究计算表型分析算法的性能指标；其次，使用这些指标推导并应用一个校正，以修正更大队列中观察到的发生率。\n\n设 $D^+$ 表示药物性肝损伤（DILI）的真实存在，即“病例阳性”，$D^-$ 表示其不存在。设 $T^+$ 表示算法给出的阳性结果（即算法标记了一次DILI事件），$T^-$ 表示阴性结果。\n\n验证样本 $1,200$ 条记录的已知数据如下：\n- 真阳性 ($TP$): 金标准和算法都识别出DILI的病例数。$TP = 272$。\n- 假阳性 ($FP$): 算法识别出DILI，但金标准未识别出的病例数。$FP = 8$。\n- 真阴性 ($TN$): 金标准和算法都同意不存在DILI的病例数。$TN = 904$。\n- 假阴性 ($FN$): 算法未能识别出DILI，但金标准确认其存在的病例数。$FN = 16$。\n\n真实DILI记录总数为 $P = TP + FN = 272 + 16 = 288$。\n无真实DILI记录总数为 $N = TN + FP = 904 + 8 = 912$。\n总样本量为 $P + N = 288 + 912 = 1,200$，与问题陈述一致。\n\n### 第1部分：算法性能指标\n\n我们根据它们的基本定义计算所要求的四个性能指标。\n\n1.  **灵敏度 ($Se$)**: 在疾病真实存在的情况下，算法检测为阳性的概率。也称为真阳性率。\n    $$Se = P(T^+ | D^+) = \\frac{TP}{TP + FN} = \\frac{272}{272 + 16} = \\frac{272}{288} = \\frac{17}{18}$$\n\n2.  **特异度 ($Sp$)**: 在疾病真实不存在的情况下，算法检测为阴性的概率。也称为真阴性率。\n    $$Sp = P(T^- | D^-) = \\frac{TN}{TN + FP} = \\frac{904}{904 + 8} = \\frac{904}{912} = \\frac{113}{114}$$\n\n3.  **阳性预测值 ($PPV$)**: 在算法检测为阳性的情况下，疾病真实存在的概率。\n    $$PPV = P(D^+ | T^+) = \\frac{TP}{TP + FP} = \\frac{272}{272 + 8} = \\frac{272}{280} = \\frac{34}{35}$$\n\n4.  **阴性预测值 ($NPV$)**: 在算法检测为阴性的情况下，疾病真实不存在的概率。\n    $$NPV = P(D^- | T^-) = \\frac{TN}{TN + FN} = \\frac{904}{904 + 16} = \\frac{904}{920} = \\frac{113}{115}$$\n\n### 第2部分：发生率的校正\n\n第二项任务是推导一个表达式，用于校正因错分而观察到的发生比例，并将其应用于完整队列。\n\n设 $I_{true}$ 为队列中DILI的真实发生比例，即一个人年为真实病例的概率， $P(D^+)$。设 $I_{obs}$ 为基于该算法观察到的发生比例，即一个人年被算法标记的概率， $P(T^+)$。\n\n我们可以使用全概率定律将 $I_{obs}$ 表示为 $I_{true}$ 的函数：\n$$P(T^+) = P(T^+|D^+)P(D^+) + P(T^+|D^-)P(D^-)$$\n代入灵敏度、特异度、$I_{true}$ 和 $I_{obs}$ 的定义：\n- $P(T^+) = I_{obs}$\n- $P(D^+) = I_{true}$\n- $P(T^+|D^+) = Se$\n- $P(D^-) = 1 - P(D^+) = 1 - I_{true}$\n- $P(T^+|D^-) = 1 - P(T^-|D^-) = 1 - Sp$\n\n方程变为：\n$$I_{obs} = Se \\cdot I_{true} + (1 - Sp) \\cdot (1 - I_{true})$$\n我们的目标是解出 $I_{true}$。我们对表达式进行代数重排：\n$$I_{obs} = Se \\cdot I_{true} + 1 - Sp - (1 - Sp) \\cdot I_{true}$$\n$$I_{obs} = I_{true} \\cdot (Se - (1 - Sp)) + 1 - Sp$$\n$$I_{obs} = I_{true} \\cdot (Se + Sp - 1) + 1 - Sp$$\n$$I_{obs} - (1 - Sp) = I_{true} \\cdot (Se + Sp - 1)$$\n$$I_{true} = \\frac{I_{obs} + Sp - 1}{Se + Sp - 1}$$\n这就是推导出的用于校正观察到的错分比例的表达式，也称为 Rogan-Gladen 估计量。\n\n现在，我们将此公式应用于完整的研究队列。\n- 总随访量：$52,000$ 人年。\n- 算法标记的事件：$1,040$。\n观察到的发生比例为：\n$$I_{obs} = \\frac{1,040}{52,000} = \\frac{104}{5,200} = \\frac{1}{50} = 0.02$$\n使用从验证研究中得出的 $Se$ 和 $Sp$ 值：\n- $Se = \\frac{17}{18}$\n- $Sp = \\frac{113}{114}$\n\n我们将这些值代入校正公式：\n$$I_{true} = \\frac{0.02 + \\frac{113}{114} - 1}{\\frac{17}{18} + \\frac{113}{114} - 1}$$\n为保持精度，我们使用分数进行计算。\n分子：\n$$I_{obs} + Sp - 1 = \\frac{1}{50} + \\frac{113}{114} - 1 = \\frac{1}{50} - \\left(1 - \\frac{113}{114}\\right) = \\frac{1}{50} - \\frac{1}{114} = \\frac{114 - 50}{50 \\times 114} = \\frac{64}{5,700}$$\n分母：\n$$Se + Sp - 1 = \\frac{17}{18} + \\frac{113}{114} - 1$$\n$18 = 2 \\cdot 3^2$ 和 $114 = 2 \\cdot 3 \\cdot 19$ 的最小公倍数是 $2 \\cdot 3^2 \\cdot 19 = 342$。\n$$Se + Sp - 1 = \\frac{17 \\cdot 19}{18 \\cdot 19} + \\frac{113 \\cdot 3}{114 \\cdot 3} - \\frac{342}{342} = \\frac{323}{342} + \\frac{339}{342} - \\frac{342}{342} = \\frac{323 + 339 - 342}{342} = \\frac{320}{342}$$\n现在，我们计算 $I_{true}$ 的比率：\n$$I_{true} = \\frac{\\frac{64}{5,700}}{\\frac{320}{342}} = \\frac{64}{5,700} \\cdot \\frac{342}{320}$$\n由于 $320 = 5 \\times 64$，我们可以简化：\n$$I_{true} = \\frac{1}{5,700} \\cdot \\frac{342}{5} = \\frac{342}{28,500}$$\n我们通过分子分母同除以公因数来简化此分数。\n$$I_{true} = \\frac{342 \\div 6}{28,500 \\div 6} = \\frac{57}{4,750}$$\n由于 $4,750 = 475 \\times 10 = (25 \\times 19) \\times 10 = 250 \\times 19$，且 $57 = 3 \\times 19$：\n$$I_{true} = \\frac{3 \\times 19}{250 \\times 19} = \\frac{3}{250} = 0.012$$\n这是校正后的发生比例，表示每人年有 $0.012$ 个真实事件。\n\n最后，我们必须将其表示为每 $1,000$ 人年的发生率。\n校正后发生率 = $I_{true} \\times 1,000$\n校正后发生率 = $0.012 \\times 1,000 = 12$ 事件/每 $1,000$ 人年。\n\n问题要求最终答案四舍五入到四位有效数字。因此，$12$ 必须表示为 $12.00$。",
            "answer": "$$\\boxed{12.00}$$"
        },
        {
            "introduction": "在确保数据质量之后，下一步是选择能够最大限度减少偏倚的研究设计。本练习将介绍一种精巧的设计——自控病例系列 (SCCS) 方法，它通过将个体作为自身的对照，从而在设计上控制所有不随时间变化的混杂因素（如基因、基础健康状况）。您将从第一性原理出发，通过编程实现条件似然估计，以推导出经年龄分层调整的发生率比，从而获得处理这种用于药物安全性研究的强大工具的实践经验 。",
            "id": "5017970",
            "problem": "要求您实现一个完整的、可运行的程序，该程序使用个体内部不良事件的周计数，并对年龄分层进行调整，以计算暴露的自控病例系列（SCCS）发病率比。其背景是为转化医学中的监管决策生成真实世界证据（RWE）。该程序必须从基础的随机过程定义出发，不得依赖于封闭形式的简化公式；相反，它必须推导并实现一个基于似然的、有原则的估计器。\n\n此任务的基础如下：\n\n1.  一个个体内部复发性不良事件的计数过程可由泊松过程很好地近似。个体 $i$ 在时间 $t$ 的瞬时发生率（风险）建模为\n$$\\lambda_i(t) = \\alpha_i \\cdot \\nu\\big(a_i(t)\\big)\\cdot \\exp\\big(\\beta \\cdot x_i(t)\\big),$$\n其中 $\\alpha_i$ 是一个捕捉静态脆弱性的个体特异性正常数，$\\nu\\big(a_i(t)\\big)$ 是一个在年龄分层内呈分段常数的基线年龄效应，$x_i(t) \\in \\{0,1\\}$ 是时间 $t$ 的暴露指示变量，而 $\\beta$ 是待估计的对数发病率比参数。\n\n2.  自控病例系列（SCCS）方法以每个个体的总事件数为条件，并利用个体内部暴露和未暴露时间区间之间的对比。在具有分段常数风险的泊松模型下，给定个体总事件数，事件在各分层间的条件分布是多项式分布，其单元权重与 $\\nu_s t_{i,s} \\exp(\\beta d_s)$ 成正比，其中 $s$ 是分层的索引，$t_{i,s}$ 是个体 $i$ 在分层 $s$ 的风险时间，$d_s$ 是分层 $s$ 的暴露指示变量，$\\nu_s$ 是分层 $s$ 的基线年龄效应。参数 $\\beta$ 通过求解得分方程来估计，该方程是将条件对数似然关于 $\\beta$ 的导数设为零。年龄效应 $\\nu_s$ 是一个讨厌函数，必须通过分层进行调整。\n\n您的程序必须：\n\n- 在上述条件似然框架下，推导并实现一个数值求根算法来求解关于 $\\beta$ 的得分方程，并进行年龄分层调整。您不能假设 $\\beta$ 有任何封闭形式。\n\n- 对每个分层，使用基于泊松模型的有原则的估计器来估计基线年龄效应 $\\nu_s$。具体来说，对于分层 $s$，使用最大似然估计器\n$$\\hat{\\nu}_s = \\frac{\\sum_i y_{i,s}^{(0)}}{\\sum_i t_{i,s}^{(0)}},$$\n其中 $y_{i,s}^{(0)}$ 和 $t_{i,s}^{(0)}$ 分别是个体 $i$ 在 $x_i(t)=0$（未暴露）时，在分层 $s$ 的事件数和风险时间。如果某个分层在所有个体中的总未暴露时间为零，则将 $\\hat{\\nu}_s$ 设置为所有其他具有正未暴露时间的分层的汇集未暴露率，\n$$\\hat{\\nu}_s = \\frac{\\sum_{r:\\sum_i t_{i,r}^{(0)} > 0} \\sum_i y_{i,r}^{(0)}}{\\sum_{r:\\sum_i t_{i,r}^{(0)} > 0} \\sum_i t_{i,r}^{(0)}}.$$\n\n- 对于每个个体 $i$，计算经基线年龄加权的暴露和未暴露时间：\n$$T_{i}^{(1)} = \\sum_s \\hat{\\nu}_s \\, t_{i,s}^{(1)}, \\quad T_{i}^{(0)} = \\sum_s \\hat{\\nu}_s \\, t_{i,s}^{(0)},$$\n其中 $t_{i,s}^{(1)}$ 是分层 $s$ 中的暴露时间。同时计算暴露事件数 $Y_i^{(1)} = \\sum_s y_{i,s}^{(1)}$ 和总事件数 $N_i = \\sum_s y_{i,s}^{(0)} + \\sum_s y_{i,s}^{(1)}$。\n\n- 根据 $T_{i}^{(1)}$、$T_{i}^{(0)}$、$Y_i^{(1)}$ 和 $N_i$ 定义 $\\beta$ 的条件得分函数，并使用稳健的数值方法（例如，二分法）求解其根，从而得到 $\\hat{\\beta}$。发病率比的估计值为 $\\widehat{\\text{IRR}} = \\exp(\\hat{\\beta})$。\n\n- 如果 $\\sum_i Y_i^{(1)} = 0$（所有个体中没有暴露事件），则返回 $\\widehat{\\text{IRR}}=0$ 作为极限估计值。\n\n- 风险时间必须以周为单位处理，发生率是每周的事件数；最终输出的估计值是无量纲的发病率比。\n\n测试套件和输入：\n\n完全按照规定实现以下三个测试用例。每个测试用例由一个包含多个个体的列表组成，每个个体都有四个长度相等的列表，分别对应于年龄分层：未暴露时间（周）、暴露时间（周）、未暴露事件计数（整数）和暴露事件计数（整数）。在单个测试用例中，年龄分层的索引是一致的。\n\n测试用例1（正常路径，两个年龄分层，两个分层信息均充足）：\n- 个体：\n  - 个体1：$t^{(0)}=[20,10]$，$t^{(1)}=[10,5]$，$y^{(0)}=[4,6]$，$y^{(1)}=[3,5]$。\n  - 个体2：$t^{(0)}=[15,20]$，$t^{(1)}=[5,10]$，$y^{(0)}=[3,12]$，$y^{(1)}=[2,9]$。\n  - 个体3：$t^{(0)}=[30,5]$，$t^{(1)}=[10,5]$，$y^{(0)}=[6,3]$，$y^{(1)}=[3,5]$。\n\n测试用例2（边界情况，某个分层没有未暴露时间；需要汇集）：\n- 个体：\n  - 个体1：$t^{(0)}=[20,10,0]$，$t^{(1)}=[0,0,10]$，$y^{(0)}=[2,2,0]$，$y^{(1)}=[0,0,10]$。\n  - 个体2：$t^{(0)}=[5,20,0]$，$t^{(1)}=[0,0,20]$，$y^{(0)}=[1,4,0]$，$y^{(1)}=[0,0,20]$。\n\n测试用例3（边界情况，相对于暴露时间，暴露事件非常少）：\n- 个体：\n  - 个体1：$t^{(0)}=[20,20]$，$t^{(1)}=[10,10]$，$y^{(0)}=[6,6]$，$y^{(1)}=[0,1]$。\n  - 个体2：$t^{(0)}=[10,10]$，$t^{(1)}=[10,10]$，$y^{(0)}=[3,2]$，$y^{(1)}=[0,0]$。\n\n输出规范：\n\n您的程序应生成单行输出，其中包含三个测试用例的 SCCS 发病率比估计值，格式为用方括号括起来的逗号分隔列表。每个值必须四舍五入到六位小数。例如：\"[1.234567,0.987654,3.210000]\"。",
            "solution": "目标是通过从第一性原理实现一个基于似然的估计器，来计算自控病例系列（SCCS）发病率比（IRR），表示为 $\\exp(\\beta)$。该方法包括以每个个体的事件数为条件来消除个体特异性效应，对年龄分层进行调整，并数值求解由此产生的关于参数 $\\beta$ 的得分方程。\n\n个体 $i$ 的事件计数过程的基础模型假设在时间 $t$ 的瞬时发生率 $\\lambda_i(t)$ 服从比例风险模型：\n$$\n\\lambda_i(t) = \\alpha_i \\cdot \\nu\\big(a_i(t)\\big) \\cdot \\exp\\big(\\beta \\cdot x_i(t)\\big)\n$$\n这里，$\\alpha_i$ 是个体的基线脆弱性，$\\nu\\big(a_i(t)\\big)$ 是一个关于年龄的分段常数基线风险函数，$x_i(t) \\in \\{0,1\\}$ 指示暴露状态，而 $\\beta$ 是与暴露相关的对数IRR。\n\nSCCS方法的核心原理是以个体 $i$ 在其观察期内观察到的总事件数 $N_i$ 为条件进行分析。这种条件化处理从似然函数中移除了静态脆弱性项 $\\alpha_i$，从而允许在个体内部比较暴露期间与未暴露期间的事件发生率。\n\n对于个体 $i$，设观察期根据年龄分层 $s$ 和暴露状态（$0$ 表示未暴露，$1$ 表示暴露）划分为不相交的时间区间。设 $t_{i,s}^{(0)}$ 和 $t_{i,s}^{(1)}$ 分别为个体 $i$ 在年龄分层 $s$ 的未暴露和暴露时间长度。基线年龄效应在每个分层内是恒定的，记为 $\\nu_s$。个体 $i$ 在暴露期间的期望事件数为 $\\sum_s \\int_{t \\in t_{i,s}^{(1)}} \\lambda_i(t) dt = \\sum_s \\alpha_i \\nu_s e^\\beta t_{i,s}^{(1)}$。类似地，在未暴露期间的期望事件数为 $\\sum_s \\alpha_i \\nu_s t_{i,s}^{(0)}$。\n\n给定个体 $i$ 发生一个事件，该事件发生在暴露期间的条件概率 $p_i$ 是暴露期间的总期望事件数与总期望事件数的比值：\n$$\np_i(\\beta) = \\frac{\\sum_s \\alpha_i \\nu_s e^\\beta t_{i,s}^{(1)}}{\\sum_s \\alpha_i \\nu_s t_{i,s}^{(0)} + \\sum_s \\alpha_i \\nu_s e^\\beta t_{i,s}^{(1)}} = \\frac{e^\\beta \\sum_s \\nu_s t_{i,s}^{(1)}}{\\sum_s \\nu_s t_{i,s}^{(0)} + e^\\beta \\sum_s \\nu_s t_{i,s}^{(1)}}\n$$\n讨厌参数 $\\nu_s$ 必须被估计。按照规定，我们使用基于未暴露事件计数和人-时的最大似然估计器。通过汇集所有个体的数据来估计率 $\\nu_s$：\n$$\n\\hat{\\nu}_s = \\frac{\\sum_i y_{i,s}^{(0)}}{\\sum_i t_{i,s}^{(0)}}\n$$\n其中 $y_{i,s}^{(0)}$ 是个体 $i$ 在分层 $s$ 的未暴露事件数。如果一个分层 $s$ 的总未暴露时间为零（$\\sum_i t_{i,s}^{(0)} = 0$），则使用所有其他具有非零未暴露时间的分层的汇集率来填补 $\\hat{\\nu}_s$。\n\n有了这些估计值，我们为每个个体 $i$ 定义年龄调整后的汇总人-时：\n$$\nT_{i}^{(1)} = \\sum_s \\hat{\\nu}_s t_{i,s}^{(1)} \\quad \\text{和} \\quad T_{i}^{(0)} = \\sum_s \\hat{\\nu}_s t_{i,s}^{(0)}\n$$\n将这些代入 $p_i(\\beta)$ 的表达式中，可将其简化为：\n$$\np_i(\\beta) = \\frac{e^\\beta T_{i}^{(1)}}{T_{i}^{(0)} + e^\\beta T_{i}^{(1)}}\n$$\n以个体 $i$ 的总事件数 $N_i$ 为条件，发生在暴露期间的事件数 $Y_i^{(1)}$ 服从二项分布：$Y_i^{(1)} | N_i \\sim \\text{Binomial}(N_i, p_i(\\beta))$。来自个体 $i$ 的条件对数似然贡献（省略不依赖于 $\\beta$ 的项）是：\n$$\n\\ell_i(\\beta) = Y_i^{(1)} \\log(p_i(\\beta)) + (N_i - Y_i^{(1)}) \\log(1 - p_i(\\beta))\n$$\n总条件对数似然是所有个体的总和：$\\ell(\\beta) = \\sum_i \\ell_i(\\beta)$。为了找到 $\\beta$ 的最大似然估计，我们推导得分函数 $S(\\beta) = \\frac{d\\ell(\\beta)}{d\\beta}$ 并求解得分方程 $S(\\beta) = 0$ 的根。\n\n个体 $i$ 的对数似然贡献的导数是：\n$$\n\\frac{d\\ell_i(\\beta)}{d\\beta} = \\left( \\frac{Y_i^{(1)}}{p_i(\\beta)} - \\frac{N_i - Y_i^{(1)}}{1 - p_i(\\beta)} \\right) \\frac{dp_i(\\beta)}{d\\beta}\n$$\n$p_i(\\beta)$ 的导数是 $\\frac{dp_i(\\beta)}{d\\beta} = p_i(\\beta)(1 - p_i(\\beta))$。将其代入可显著简化表达式：\n$$\n\\frac{d\\ell_i(\\beta)}{d\\beta} = Y_i^{(1)}(1 - p_i(\\beta)) - (N_i - Y_i^{(1)})p_i(\\beta) = Y_i^{(1)} - N_i p_i(\\beta)\n$$\n这个简洁的结果表明，得分贡献是观察到的暴露事件数减去期望的暴露事件数。总得分函数是：\n$$\nS(\\beta) = \\sum_i \\left( Y_i^{(1)} - N_i p_i(\\beta) \\right) = \\sum_i Y_i^{(1)} - \\sum_i N_i \\frac{e^\\beta T_{i}^{(1)}}{T_{i}^{(0)} + e^\\beta T_{i}^{(1)}}\n$$\n对数似然的二阶导数 $\\frac{d^2\\ell(\\beta)}{d\\beta^2} = \\sum_i -N_i p_i(\\beta)(1 - p_i(\\beta))$ 始终为非正，这意味着对数似然是凹的，得分函数 $S(\\beta)$ 是单调递减的。这保证了 $\\beta$ 存在唯一的根，可以使用像二分法这样的数值算法高效地找到。\n\n实现二分法来求解 $S(\\beta)=0$。它需要一个区间 $[a, b]$，其中 $S(a)$ 和 $S(b)$ 的符号相反。鉴于其单调性，一个宽泛的区间如 $[-20, 20]$ 通常足以将根置于其中。该算法通过保持根被包围的同时迭代地将区间减半，最终收敛到解 $\\hat{\\beta}$。最终的IRR则为 $\\widehat{\\text{IRR}} = \\exp(\\hat{\\beta})$。处理了一个特殊情况，即如果总暴露事件数 $\\sum_i Y_i^{(1)}$ 为零，则IRR估计值为 $0$。这与得分方程一致，因为对于所有有限的 $\\beta$，$S(\\beta)  0$，意味着对数似然在 $\\beta \\to -\\infty$ 时最大化。",
            "answer": "```python\nimport numpy as np\n\ndef calculate_sccs_irr(individuals_data):\n    \"\"\"\n    Computes the age-adjusted SCCS Incidence Rate Ratio (IRR).\n\n    Args:\n        individuals_data: A list of tuples, where each tuple represents an \n                          individual and contains four lists: unexposed times, \n                          exposed times, unexposed events, and exposed events,\n                          each stratified by age.\n\n    Returns:\n        The estimated IRR, a float.\n    \"\"\"\n    if not individuals_data:\n        return 1.0  # Or handle as an error\n\n    # 1. Unpack data and convert to NumPy arrays for vectorized operations\n    t0_list, t1_list, y0_list, y1_list = zip(*individuals_data)\n    t0_data = np.array(t0_list, dtype=float)\n    t1_data = np.array(t1_list, dtype=float)\n    y0_data = np.array(y0_list, dtype=float)\n    y1_data = np.array(y1_list, dtype=float)\n\n    num_individuals, num_strata = t0_data.shape\n\n    # 2. Handle the edge case of zero exposed events\n    total_exposed_events = np.sum(y1_data)\n    if total_exposed_events == 0:\n        return 0.0\n\n    # 3. Estimate baseline age effects (nuisance parameters)\n    sum_t0_per_stratum = np.sum(t0_data, axis=0)\n    sum_y0_per_stratum = np.sum(y0_data, axis=0)\n    \n    nu_hat = np.zeros(num_strata)\n    \n    # Identify strata with positive unexposed time for robust pooling\n    valid_strata_mask = sum_t0_per_stratum > 0\n    \n    # Calculate pooled rate from valid strata\n    pooled_events = np.sum(sum_y0_per_stratum[valid_strata_mask])\n    pooled_time = np.sum(sum_t0_per_stratum[valid_strata_mask])\n    \n    if pooled_time > 0:\n        pooled_rate = pooled_events / pooled_time\n    else:\n        # This case (no unexposed time at all) makes nu estimation impossible.\n        # The model is not identifiable. Assume it won't happen in valid problems.\n        # A plausible fallback could be nu=1, but we follow the spec.\n        # If all t0 are 0, we can't estimate any nu. The problem implies we can.\n        # Let's set the pooled rate to 1 if no information is available\n        pooled_rate = 1.0\n\n    # Estimate nu for each stratum\n    for s in range(num_strata):\n        if sum_t0_per_stratum[s] > 0:\n            nu_hat[s] = sum_y0_per_stratum[s] / sum_t0_per_stratum[s]\n        else:\n            nu_hat[s] = pooled_rate\n    \n    # 4. Compute age-adjusted summary times and event counts per individual\n    T0 = np.dot(t0_data, nu_hat)  # T_i^{(0)}\n    T1 = np.dot(t1_data, nu_hat)  # T_i^{(1)}\n    Y1 = np.sum(y1_data, axis=1)  # Y_i^{(1)}\n    N = np.sum(y0_data, axis=1) + np.sum(y1_data, axis=1) # N_i\n\n    # Filter out individuals with no events (N_i = 0), as they don't contribute to the likelihood\n    informative_mask = N > 0\n    if not np.any(informative_mask):\n      return 1.0 # No events, no information on IRR\n    \n    T0 = T0[informative_mask]\n    T1 = T1[informative_mask]\n    Y1 = Y1[informative_mask]\n    N = N[informative_mask]\n    \n    # 5. Define the score function S(beta)\n    def score_function(beta):\n        exp_beta = np.exp(beta)\n        denominator = T0 + exp_beta * T1\n        # Calculate expected number of exposed events for each individual\n        # Use np.divide for safe division, returning 0 where denominator is 0\n        expected_Y1 = np.divide(N * exp_beta * T1, denominator, \n                                out=np.zeros_like(N), where=denominator!=0)\n        return np.sum(Y1) - np.sum(expected_Y1)\n\n    # 6. Implement bisection method to find the root of the score function\n    def bisection_solver(f, a, b, tol=1e-12, max_iter=100):\n        fa = f(a)\n        fb = f(b)\n\n        if fa * fb >= 0:\n            # Root is not bracketed or is at a boundary\n            if abs(fa)  tol: return a\n            if abs(fb)  tol: return b\n            if fa > 0 and fb > 0: return float('inf')  # Suggests beta -> inf\n            if fa  0 and fb  0: return float('-inf')  # Suggests beta -> -inf\n            return None # Should not happen for monotonic score function\n\n        for _ in range(max_iter):\n            c = (a + b) / 2.0\n            fc = f(c)\n            if abs(fc)  tol or (b - a) / 2.0  tol:\n                return c\n            if np.sign(fc) == np.sign(fa):\n                a = c\n                fa = fc\n            else:\n                b = c\n        return (a + b) / 2.0\n    \n    # Solve for beta\n    beta_hat = bisection_solver(score_function, a=-20.0, b=20.0)\n    \n    # 7. Compute the IRR\n    if beta_hat is None:\n        # Fallback if solver fails, though unlikely for this problem\n        return float('nan')\n        \n    irr = np.exp(beta_hat)\n    \n    return irr\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # Test Case 1: Happy path\n    test_case_1 = [\n        ([20, 10], [10, 5], [4, 6], [3, 5]),\n        ([15, 20], [5, 10], [3, 12], [2, 9]),\n        ([30, 5], [10, 5], [6, 3], [3, 5]),\n    ]\n\n    # Test Case 2: Stratum with zero unexposed time\n    test_case_2 = [\n        ([20, 10, 0], [0, 0, 10], [2, 2, 0], [0, 0, 10]),\n        ([5, 20, 0], [0, 0, 20], [1, 4, 0], [0, 0, 20]),\n    ]\n\n    # Test Case 3: Few exposed events\n    test_case_3 = [\n        ([20, 20], [10, 10], [6, 6], [0, 1]),\n        ([10, 10], [10, 10], [3, 2], [0, 0]),\n    ]\n\n    test_cases = [test_case_1, test_case_2, test_case_3]\n    \n    results = []\n    for case in test_cases:\n        irr = calculate_sccs_irr(case)\n        results.append(\"{:.6f}\".format(irr))\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "即使拥有高质量的数据和严谨的研究设计，观察性研究中未测量混杂的威胁始终存在。最后一个练习将直面这一挑战，介绍用于敏感性分析的关键指标——E-值。您将学习计算和解读 E-值，以量化一个未测量的混杂因素需要多强才能完全“解释掉”观测到的关联，从而为评估研究结果在监管决策中的稳健性提供一个关键的量化指标 。",
            "id": "5017951",
            "problem": "一个大型综合医疗系统进行了一项观察性队列研究，旨在为美国食品药品监督管理局（FDA）的一项潜在药品说明书扩展决策生成真实世界证据（RWE）。在有症状感染的高风险成年人中，在使用倾向性得分加权和结局回归进行广泛调整后，$5$天内开始口服抗病毒药物治疗与$28$天住院率调整后风险比$\\widehat{\\mathrm{RR}}=0.72$相关，其$95\\%$置信区间为$[0.58,\\,0.89]$。假设满足正性假设、一致性假设，且无选择偏倚或结局错分。为评估观察到的调整集未对其进行条件控制的单个二元未测量混杂因素的潜在影响，您需要使用E-值来量化其稳健性。\n\n从风险、风险比的核心定义，以及经过充分检验的、由单个二元未测量混雜因素引起的风险比尺度上的混杂效应的精确界限出发，推导与点风险比$\\mathrm{RR}$（其中$\\mathrm{RR}\\geq 1$）相对应的E-值的闭式表达式，并描述当$\\mathrm{RR}1$时如何对其进行调整。然后应用您的推导来计算：\n- 点估计值$\\widehat{\\mathrm{RR}}=0.72$对应的E-值，以及\n- 所报告区间$[0.58,\\,0.89]$中最接近无效假设的置信限对应的E-值。\n\n将每个数值结果四舍五入至四位有效数字。以$\\big[$点估计的E-值, 置信限的E-值$\\big]$的顺序，用行矩阵的形式表示您的最终答案。报告的E-值为不带单位的纯数字。",
            "solution": "该问题要求推导 E-值公式，并将其应用于一项观察性研究的特定场景。\n\n### 第一步：提取已知条件\n- 为获取真实世界证据 (RWE) 进行的观察性队列研究。\n- 暴露：在出现症状感染的 $5$ 天内开始口服抗病毒药物治疗。\n- 结局：28天内的住院情况。\n- 调整后的风险比：$\\widehat{\\mathrm{RR}} = 0.72$。\n- 风险比的 $95\\%$ 置信区间：$[0.58, 0.89]$。\n- 假设：正性假设、一致性假设、无选择偏倚、无结局错分。\n- 任务：使用 E-值量化对于单个二元未测量混杂因素的稳健性。\n- 要求的推导：针对观察到的风险比 $\\mathrm{RR}$ (其中 $\\mathrm{RR} \\ge 1$) 的 E-值的闭式表达式。\n- 要求的调整：描述当 $\\mathrm{RR}  1$ 时如何处理。\n- 要求的计算：\n  1. 点估计值 $\\widehat{\\mathrm{RR}}=0.72$ 的 E-值。\n  2. 最接近无效假设的置信限（即 $0.89$）的 E-值。\n- 要求的舍入：数值结果保留四位有效数字。\n- 最终答案格式：一个包含两个按指定顺序排列的 E-值的行矩阵。\n\n### 第二步：使用提取的已知条件进行验证\n该问题具有科学依据。它探讨了观察性研究中的混杂偏倚，这是流行病学和生物统计学中的一个核心课题。E-值是一种成熟的敏感性分析指标，由 VanderWeele 和 Ding (2017) 在 Cornfield 等人的基础性工作上建立并引入。该问题提法得当，提供了所有必要的数据（$\\widehat{\\mathrm{RR}}$、置信区间）和一组明确的任务（推导和计算）。语言客观且精确。提供的数值是一致的；点估计值 $0.72$ 位于给定的置信区间 $[0.58, 0.89]$ 内。该场景是现实的，并且与转化医学和监管科学相关。问题完整、一致，且不违反任何科学原理。\n\n### 第三步：结论与行动\n该问题有效。将提供完整的解决方案。\n\n### 求解推导与计算\n\n设 $E$ 表示二元暴露（$E=1$ 为处理组，$E=0$ 为未处理组），$D$ 表示二元结局（$D=1$ 为发生事件，$D=0$ 为未发生事件），$U$ 表示单个二元未测量混杂因素（$U=1$ 为存在，$U=0$ 为不存在）。观察到的风险比为 $\\mathrm{RR}_{\\text{obs}} = \\frac{P(D=1|E=1)}{P(D=1|E=0)}$。\n\n未测量混杂因素的敏感性分析旨在量化混杂因素 $U$ 与暴露 $E$ 和结局 $D$ 之间的关联强度，这种强度需足以“解释掉”观察到的关联。这些关联的强度是在风险比尺度上测量的：\n1.  混杂因素与暴露之间关联的风险比为 $\\mathrm{RR}_{EU} = \\frac{P(U=1|E=1)}{P(U=1|E=0)}$。\n2.  在暴露条件下，混杂因素与结局之间关联的风险比为 $\\mathrm{RR}_{UD|E}$。在同质性假设下，对于 $e=0$ 或 $e=1$，$\\mathrm{RR}_{UD} = \\frac{P(D=1|U=1, E=e)}{P(D=1|U=0, E=e)}$。\n\n观察到的风险比 $\\mathrm{RR}_{\\text{obs}}$ 与真实的、无混杂的风险比 $\\mathrm{RR}_{\\text{true}}$ 之间的关系由一个偏倚因子 $B$ 介导，即 $\\mathrm{RR}_{\\text{obs}} = \\mathrm{RR}_{\\text{true}} \\times B$。如果一个未测量的混杂因素能够产生一个偏倚因子 $B$ 使得 $\\mathrm{RR}_{\\text{true}} = 1$，那么它就可以解释掉观察到的关联，这意味着 $B = \\mathrm{RR}_{\\text{obs}}$。\n\n由单个二元混杂因素 $U$ 引起的偏倚因子 $B$ 的一个精确（最坏情况）上限由下式给出：\n$$ B \\le \\frac{\\mathrm{RR}_{EU} \\cdot \\mathrm{RR}_{UD}}{\\mathrm{RR}_{EU} + \\mathrm{RR}_{UD} - 1} $$\n这个不等式假设 $\\mathrm{RR}_{EU} > 1$ 和 $\\mathrm{RR}_{UD} > 1$ 都成立，即该混杂因素是暴露和结局的共同风险因素。\n\nE-值定义为 $\\mathrm{RR}_{EU}$ 和 $\\mathrm{RR}_{UD}$ 为了解释掉观察到的关联所必须达到的最小值 $\\gamma$。也就是说，我们寻求最小的 $\\gamma \\ge 1$，使得 $\\mathrm{RR}_{EU} = \\gamma$ 和 $\\mathrm{RR}_{UD} = \\gamma$ 能够产生一个至少为 $\\mathrm{RR}_{\\text{obs}}$ 的偏倚因子。此分析首先针对观察到的风险比 $\\mathrm{RR} \\ge 1$ 进行。\n\n设 $\\mathrm{RR}_{EU} = \\mathrm{RR}_{UD} = \\gamma$，并要求偏倚至少达到观察到的风险比 $\\mathrm{RR}$ 的大小，我们有：\n$$ \\mathrm{RR} \\le \\frac{\\gamma \\cdot \\gamma}{\\gamma + \\gamma - 1} = \\frac{\\gamma^2}{2\\gamma - 1} $$\n为了找到这样的最小 $\\gamma$，我们求解等式：\n$$ \\mathrm{RR} = \\frac{\\gamma^2}{2\\gamma - 1} $$\n整理后得到一个关于 $\\gamma$ 的二次方程：\n$$ \\mathrm{RR}(2\\gamma - 1) = \\gamma^2 $$\n$$ 2\\mathrm{RR}\\gamma - \\mathrm{RR} = \\gamma^2 $$\n$$ \\gamma^2 - 2\\mathrm{RR}\\gamma + \\mathrm{RR} = 0 $$\n使用二次公式求解 $\\gamma$：\n$$ \\gamma = \\frac{-(-2\\mathrm{RR}) \\pm \\sqrt{(-2\\mathrm{RR})^2 - 4(1)(\\mathrm{RR})}}{2(1)} $$\n$$ \\gamma = \\frac{2\\mathrm{RR} \\pm \\sqrt{4\\mathrm{RR}^2 - 4\\mathrm{RR}}}{2} $$\n$$ \\gamma = \\mathrm{RR} \\pm \\sqrt{\\mathrm{RR}^2 - \\mathrm{RR}} $$\n根据定义，E-值必须大于或等于 $1$。对于观察到的 $\\mathrm{RR} > 1$，两个根都是实数。函数 $f(\\gamma) = \\frac{\\gamma^2}{2\\gamma-1}$ 在 $\\gamma > 1$ 时是递增的。我们正在寻求这个函数的反函数。较大的根 $\\gamma = \\mathrm{RR} + \\sqrt{\\mathrm{RR}^2 - \\mathrm{RR}}$ 对应于 $\\gamma \\ge 1$ 的解。这就是针对观察到的风险比 $\\mathrm{RR} \\ge 1$ 推导出的 E-值的闭式表达式。\n\n当观察到的风险比小于 $1$（保护效应）时，必须调整该框架。一个使观察到的 $\\mathrm{RR}  1$ 向无效值 $1$ 产生偏倚的混杂因素，与一个使观察到的 $\\mathrm{RR} > 1$ 远离无效值产生偏倚的混杂因素具有相同的性质。为了使用推导出的公式，我们将风险比取倒数，使其转换到有害效应的尺度（即 $>1$）。如果观察到的风险比为 $\\mathrm{RR}_{\\text{obs}}  1$，我们为其倒数 $1/\\mathrm{RR}_{\\text{obs}}$ 计算 E-值。其解释保持不变：混杂因素必须与暴露和结局都具有的最小关联强度，才能解释掉观察到的保护效应，即将估计值移至无效值。因此，对于 $\\mathrm{RR}  1$，E-值计算如下：\n$$ \\mathrm{E\\text{-}value} = \\left(\\frac{1}{\\mathrm{RR}}\\right) + \\sqrt{\\left(\\frac{1}{\\mathrm{RR}}\\right)^2 - \\left(\\frac{1}{\\mathrm{RR}}\\right)} $$\n\n现在，我们将这些公式应用于给定的问题。\n\n1.  **点估计值 $\\widehat{\\mathrm{RR}} = 0.72$ 的 E-值**\n    由于 $\\widehat{\\mathrm{RR}} = 0.72  1$，我们使用调整后的公式，并采用倒数风险比 $1/0.72$。\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} = \\frac{1}{0.72} + \\sqrt{\\left(\\frac{1}{0.72}\\right)^2 - \\frac{1}{0.72}} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} \\approx 1.388889 + \\sqrt{(1.388889)^2 - 1.388889} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} \\approx 1.388889 + \\sqrt{1.929012 - 1.388889} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} \\approx 1.388889 + \\sqrt{0.540123} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} \\approx 1.388889 + 0.734931 $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{point}} \\approx 2.123820 $$\n    四舍五入到四位有效数字，点估计的 E-值为 $2.124$。这意味着，在已测量的混杂因素之外，一个未测量的混杂因素如果与抗病毒治疗和住院率的关联风险比均至少为 $2.124$，就可以解释掉观察到的点估计值。\n\n2.  **最接近无效假设的置信限的 E-值**\n    $95\\%$ 置信区间为 $[0.58, 0.89]$。无效假设为 $\\mathrm{RR}=1$。置信区间的限值中最接近 $1$ 的是 $0.89$。我们为这个限值计算 E-值，即 $\\mathrm{RR}_{\\text{CI}} = 0.89$。\n    由于 $\\mathrm{RR}_{\\text{CI}} = 0.89  1$，我们再次使用调整后的公式，并采用倒数风险比 $1/0.89$。\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} = \\frac{1}{0.89} + \\sqrt{\\left(\\frac{1}{0.89}\\right)^2 - \\frac{1}{0.89}} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} \\approx 1.123596 + \\sqrt{(1.123596)^2 - 1.123596} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} \\approx 1.123596 + \\sqrt{1.262467 - 1.123596} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} \\approx 1.123596 + \\sqrt{0.138871} $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} \\approx 1.123596 + 0.372654 $$\n    $$ \\mathrm{E\\text{-}value}_{\\text{CI}} \\approx 1.496250 $$\n    四舍五入到四位有效数字，置信限的 E-值为 $1.496$。这意味着，要将置信区间的上限移至无效值 $1$，一个未测量的混杂因素需要与暴露和结局的关联风险比均至少为 $1.496$。由于这个值相对较小，因此关于保护效应的推断对未测量的混杂因素比点估计所显示的更为敏感。\n\n最终答案按要求以行矩阵形式呈现。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2.124  1.496\n\\end{pmatrix}\n}\n$$"
        }
    ]
}