{
    "hands_on_practices": [
        {
            "introduction": "The immense power of DNA-encoded library (DEL) technology stems from its ability to generate astronomically large collections of molecules. This first practice delves into the combinatorial mathematics used to calculate a library's theoretical size based on its synthetic route. By also factoring in a hypothetical, cumulative probability of reaction failure, this exercise provides a crucial, realistic perspective on the difference between the enumerated chemical space and the actual diversity achieved in the final library pool. ",
            "id": "5011254",
            "problem": "A discovery campaign in translational medicine employs DNA-encoded library (DEL) technology to enumerate small molecules for screening against a clinically validated protein target. The library is designed by appending building blocks across sequential synthesis cycles, with each appended building block covalently coupled to a unique DNA tag recording the synthetic history. In this design, the number of unique small molecules that can, in principle, be formed is determined by the Cartesian product of building block choices across cycles, assuming that every unique path through the synthesis tree yields a chemically and informationally unique construct.\n\nConsider a DEL constructed in $c=4$ cycles with per-cycle building block set sizes $[200, 400, 800, 1600]$. Each cycle involves a coupling and encoding step, and each intended coupling has an independent per-cycle reaction failure probability $p=0.02$ (expressed as a decimal), such that a failure at any cycle aborts growth and removes that partial sequence from the final pooled library of fully assembled constructs.\n\nUsing only the definitions of combinatorial enumeration and independence of Bernoulli events:\n- Compute the total enumerated library size that would be achieved in the absence of any failures.\n- Compute the expected fraction of enumerated sequences that are lost from the final library due to cumulative reaction failures across all cycles.\n\nExpress your final answers together, in the order $(\\text{library size}, \\text{lost fraction})$. Report the library size as an exact integer, and round the lost fraction to six significant figures. Do not include units in the final reported pair.",
            "solution": "The problem is deemed valid as it is scientifically grounded in the principles of combinatorial chemistry and probability theory, well-posed with all necessary information provided, and objective in its formulation. It presents a standard, formalizable scenario in the context of DNA-encoded library (DEL) technology.\n\nThe solution is partitioned into two components as requested by the problem statement: first, the computation of the total enumerated library size, and second, the computation of the expected fraction of lost sequences.\n\nLet $c$ be the number of synthesis cycles, given as $c=4$.\nLet $n_i$ be the number of unique building blocks available for cycle $i$, for $i \\in \\{1, 2, 3, 4\\}$. The given set sizes are:\n$n_1 = 200$\n$n_2 = 400$\n$n_3 = 800$\n$n_4 = 1600$\nLet $p$ be the independent, per-cycle reaction failure probability, given as $p=0.02$.\n\n**Part 1: Total Enumerated Library Size**\n\nThe problem states that the total number of unique small molecules, $N_{total}$, is the Cartesian product of the building block choices across all cycles. This corresponds to the fundamental principle of counting, where the total number of outcomes for a sequence of independent events is the product of the number of outcomes for each event.\n\nThus, the total enumerated library size is calculated as the product of the number of building blocks in each cycle:\n$$N_{total} = n_1 \\times n_2 \\times n_3 \\times n_4$$\nSubstituting the given values:\n$$N_{total} = 200 \\times 400 \\times 800 \\times 1600$$\nTo compute this product:\n$$N_{total} = (2 \\times 10^2) \\times (4 \\times 10^2) \\times (8 \\times 10^2) \\times (16 \\times 10^2)$$\n$$N_{total} = (2 \\times 4 \\times 8 \\times 16) \\times 10^{2+2+2+2}$$\n$$N_{total} = 1024 \\times 10^8$$\n$$N_{total} = 102,400,000,000$$\nThis is the total theoretical library size in the absence of any synthesis failures.\n\n**Part 2: Expected Fraction of Lost Sequences**\n\nA sequence is considered \"lost\" if a reaction failure occurs at any of the $c=4$ cycles. Conversely, a sequence is successfully formed only if all $c$ reaction steps are successful.\n\nThe per-cycle failure probability is $p=0.02$. Therefore, the per-cycle success probability, $s$, is:\n$$s = 1 - p = 1 - 0.02 = 0.98$$\nSince the reaction steps at each cycle are independent events (a Bernoulli trial for each cycle), the probability that a single, specific synthetic path is successfully completed through all $c=4$ cycles, $P_{success}$, is the product of the individual success probabilities:\n$$P_{success} = s \\times s \\times s \\times s = s^c = (1-p)^c$$\nSubstituting the given values:\n$$P_{success} = (0.98)^4$$\nCalculating this value:\n$$(0.98)^2 = 0.9604$$\n$$(0.98)^4 = (0.9604)^2 = 0.92236816$$\nThis probability, $P_{success}$, represents the expected fraction of the total enumerated sequences that are successfully synthesized to completion.\n\nThe problem asks for the expected fraction of lost sequences, $F_{lost}$. This is the complement of the expected fraction of successful sequences:\n$$F_{lost} = 1 - P_{success}$$\n$$F_{lost} = 1 - (0.98)^4$$\n$$F_{lost} = 1 - 0.92236816 = 0.07763184$$\nThe problem requires this fraction to be rounded to six significant figures. The first six significant digits of $0.07763184$ are $7, 7, 6, 3, 1, 8$. The digit following this sequence is $4$, which is less than $5$, so we do not round up the last significant digit.\nTherefore, the rounded fraction of lost sequences is:\n$$F_{lost} \\approx 0.0776318$$\n\nThe final answers are the pair $(\\text{library size}, \\text{lost fraction})$.\nThe library size is the exact integer $102,400,000,000$.\nThe lost fraction, rounded to six significant figures, is $0.0776318$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n102400000000 & 0.0776318\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Synthesizing a vast library is only the first step; the subsequent challenge is identifying successful binders from a complex mixture via sequencing. This practice models the sequencing process as a large-scale sampling experiment, exploring the stochastic nature of hit detection. By calculating the probability of failing to observe a specific molecule, you will gain a concrete understanding of sequencing depth and its critical role in minimizing false negatives, a central challenge in the design and interpretation of any DEL screen. ",
            "id": "5011222",
            "problem": "In a DNA-encoded library (DEL) screen within translational medicine, affinity selection against a target yields a pool of bound compounds, each tagged by a unique DNA barcode representing one of $10^{8}$ distinct compounds. Suppose that subsequent Next-Generation Sequencing (NGS) produces $M$ independent reads, and each read maps uniformly at random to one of the $10^{8}$ barcodes, consistent with equal representation and random sampling of amplicons (sampling with replacement and no read-to-read dependence). Consider a specific barcode corresponding to a true high-affinity ligand present in the bound pool. Using only the core definitions of independent Bernoulli trials and the binomial model for repeated independent sampling, derive the exact probability that this true high-affinity ligand is completely missed (zero occurrences) in the $M$ reads due to undersampling. Express your final result as a closed-form analytic expression in terms of $M$ and $10^{8}$. No numerical approximation is required, and no units are involved. The final answer must be a single expression.",
            "solution": "The problem statement will first be validated for scientific soundness, clarity, and logical consistency.\n\n### Step 1: Extract Givens\n- Total number of distinct DNA barcodes, $N$: $10^{8}$.\n- Total number of independent Next-Generation Sequencing (NGS) reads: $M$.\n- Sampling model: Each read maps uniformly at random to one of the $N$ barcodes. This constitutes sampling with replacement, and each read is an independent event.\n- Objective: Derive the exact probability that a specific, pre-determined barcode (representing a true high-affinity ligand) is observed zero times in the $M$ reads.\n- Constraint: The derivation must be based on the principles of independent Bernoulli trials and the binomial model.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Grounding**: The problem is scientifically grounded. It presents a simplified but standard statistical model used in the analysis of high-throughput sequencing data, specifically in the context of DNA-encoded library (DEL) screening. The concepts of uniform random sampling, independent trials, and calculating the probability of non-detection are fundamental to bioinformatics and statistical genomics. The numbers provided ($10^{8}$ compounds, variable $M$ reads) are representative of the scale of modern DEL experiments.\n2.  **Well-Posedness**: The problem is well-posed. All necessary information is provided to construct a probability model and derive a unique solution. The parameters ($M$ and $10^8$) are clearly defined, and the question asks for a specific probability under a fully specified sampling model.\n3.  **Objectivity**: The problem is stated in precise, objective language, free of ambiguity or subjective claims.\n\nThe problem statement does not violate any criteria for invalidity. It is a well-defined problem in applied probability, relevant to the field of translational medicine. It is not incomplete, contradictory, unrealistic, or ill-posed.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\n### Derivation\nThe problem asks for the probability that a specific barcode is not observed in a set of $M$ independent NGS reads. This scenario can be modeled as a sequence of $M$ independent Bernoulli trials.\n\nA single Bernoulli trial is an experiment with exactly two possible outcomes: \"success\" or \"failure\". Let's define the trial and its outcomes in the context of one NGS read:\n- A single trial is the event of sequencing one read.\n- There are $N = 10^{8}$ possible barcodes a read can map to.\n- The sampling is uniform and random, so the probability of a single read mapping to any specific barcode is $\\frac{1}{N}$.\n\nLet's focus on the specific barcode of interest. We can define a \"success\" and \"failure\" for a single trial (one read) as follows:\n- **Failure**: The read maps to the specific barcode of interest.\n- **Success**: The read maps to any of the other $N-1$ barcodes.\n\nThe probability of a \"failure\" in a single trial, which we will denote by $p$, is the probability of hitting the specific barcode:\n$$p = \\frac{1}{N} = \\frac{1}{10^{8}}$$\nThe probability of a \"success\" in a single trial, which we will denote by $1-p$, is the probability of not hitting the specific barcode:\n$$1 - p = 1 - \\frac{1}{N} = 1 - \\frac{1}{10^{8}}$$\n\nThe problem asks for the probability that the specific barcode is completely missed in $M$ reads. This is equivalent to the event that we have $M$ \"successes\" (as defined above) in $M$ independent trials. Since the trials (reads) are independent, the probability of this compound event is the product of the probabilities of each individual event.\n\nLet $P(\\text{miss on all } M \\text{ reads})$ be the desired probability.\n$$P(\\text{miss on all } M \\text{ reads}) = \\underbrace{(1-p) \\times (1-p) \\times \\dots \\times (1-p)}_{M \\text{ times}}$$\n$$P(\\text{miss on all } M \\text{ reads}) = (1-p)^{M}$$\nSubstituting the value of $p$, we get:\n$$P(\\text{miss on all } M \\text{ reads}) = \\left(1 - \\frac{1}{10^{8}}\\right)^{M}$$\n\nThis result can be formally derived using the binomial distribution, as requested. The binomial distribution gives the probability of observing exactly $k$ \"failures\" (as per our initial definition of failure) in $M$ independent Bernoulli trials. Let $X$ be the random variable representing the number of times our specific barcode is observed in $M$ reads. The probability mass function for a binomial distribution is:\n$$P(X=k) = \\binom{M}{k} p^{k} (1-p)^{M-k}$$\nHere:\n- $M$ is the number of trials (reads).\n- $k$ is the number of occurrences of our specific barcode.\n- $p = \\frac{1}{10^{8}}$ is the probability of a single read mapping to our specific barcode.\n- $1-p = 1 - \\frac{1}{10^{8}}$ is the probability of a single read not mapping to our specific barcode.\n\nWe are interested in the probability of zero occurrences, so we set $k=0$.\n$$P(X=0) = \\binom{M}{0} p^{0} (1-p)^{M-0}$$\nThe components of this expression are:\n- The binomial coefficient $\\binom{M}{0} = \\frac{M!}{0!(M-0)!} = 1$.\n- The term $p^{0} = \\left(\\frac{1}{10^{8}}\\right)^{0} = 1$.\n- The term $(1-p)^{M} = \\left(1 - \\frac{1}{10^{8}}\\right)^{M}$.\n\nSubstituting these back into the formula for $P(X=0)$:\n$$P(X=0) = 1 \\cdot 1 \\cdot \\left(1 - \\frac{1}{10^{8}}\\right)^{M}$$\n$$P(X=0) = \\left(1 - \\frac{1}{10^{8}}\\right)^{M}$$\nThis is the final, closed-form analytic expression for the probability that the true high-affinity ligand is completely missed in $M$ reads.",
            "answer": "$$\\boxed{\\left(1 - \\frac{1}{10^{8}}\\right)^{M}}$$"
        },
        {
            "introduction": "Raw sequencing data is not a perfect representation of molecular abundance but is affected by systematic biases that can obscure true signals. This advanced exercise demonstrates a powerful, regression-based approach to normalize read counts, correcting for common artifacts such as GC-content bias. You will then apply the rigorous Benjamini–Hochberg procedure to control the false discovery rate, mirroring the sophisticated statistical workflows required to confidently identify genuine drug candidates from noisy high-throughput data. ",
            "id": "5011223",
            "problem": "A DNA-encoded library (DEL) selection experiment is analyzed by Next-Generation Sequencing (NGS). For each unique DNA tag indexed by $i$, two sequencing runs are obtained: a target-binding selection with observed read count $T_i$ and a matched control selection with observed read count $C_i$. Each tag has a measured guanine-cytosine fraction $g_i \\in [0,1]$. It is empirically observed in NGS that polymerase chain reaction amplification and cluster formation introduce a multiplicative bias that depends on $g_i$, causing read counts to deviate from true molecular abundance. You may assume that, within each run $r \\in \\{\\text{target}, \\text{control}\\}$, the expected read count for tag $i$ follows a generalized linear model with a log link, in which the log of the expectation is an affine function of $g_i$. You may also assume that read counts are approximately Poisson when conditioned on their expectations and that the library size for each run acts as an offset (exposure) on the expected counts. Using these assumptions as the fundamental base, derive a regression-based normalization for read counts as a function of $g_i$ that removes the $g_i$-dependent bias and yields a normalized log-enrichment for each tag. Clearly present a closed-form expression for the normalized log-enrichment in terms of the fitted regression functions and observed counts. Then, to assess the impact of the GC bias correction on hit calling and false discovery rate (FDR), suppose six candidate tags have the following one-sided $p$-values for enrichment before and after GC correction (obtained from Wald tests on the normalized log-enrichment):\nBefore correction: $0.006$, $0.015$, $0.028$, $0.044$, $0.090$, $0.240$.\nAfter correction: $0.0008$, $0.0040$, $0.0110$, $0.0320$, $0.0800$, $0.2100$.\nApply the Benjamini–Hochberg (BH) procedure at target FDR level $\\alpha = 0.050$ to both sets to determine how many hits would be called before versus after correction. Finally, compute the BH-adjusted $q$-value for the most significant tag after GC correction. Round your final numeric answer to four significant figures and express it as a decimal.",
            "solution": "The user has provided a problem statement that requires both a theoretical derivation and a numerical calculation in the context of DNA-encoded library (DEL) data analysis.\n\n### Step 1: Extract Givens\n- For each unique DNA tag $i$:\n  - Target-binding selection observed read count: $T_i$\n  - Control selection observed read count: $C_i$\n  - Guanine-cytosine fraction: $g_i \\in [0,1]$\n- A multiplicative bias dependent on $g_i$ affects read counts.\n- For each run $r \\in \\{\\text{target}, \\text{control}\\}$, the expected read count for tag $i$, $E[Y_{r,i}]$, follows a generalized linear model (GLM) with a log link.\n- The log of the expectation is an affine function of $g_i$: $\\ln(E[Y_{r,i}])$ is affine in $g_i$.\n- Read counts are approximately Poisson conditioned on their expectations.\n- Library size for each run acts as an offset (exposure).\n- Before-correction one-sided $p$-values for enrichment: $\\{0.006, 0.015, 0.028, 0.044, 0.090, 0.240\\}$.\n- After-correction one-sided $p$-values for enrichment: $\\{0.0008, 0.0040, 0.0110, 0.0320, 0.0800, 0.2100\\}$.\n- Target False Discovery Rate (FDR) level: $\\alpha = 0.050$.\n- Required tasks:\n  1. Derive a closed-form expression for the normalized log-enrichment.\n  2. Apply the Benjamini–Hochberg (BH) procedure to determine the number of hits before and after correction.\n  3. Compute the BH-adjusted $q$-value for the most significant tag after correction.\n  4. Round the final numerical answer to four significant figures.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is evaluated against the validation criteria.\n- **Scientifically Grounded**: The problem is deeply rooted in computational biology and bioinformatics, specifically the analysis of Next-Generation Sequencing (NGS) data. GC-content bias is a well-documented artifact in sequencing, and the use of Poisson GLMs with log links and library size offsets is the standard and state-of-the-art methodology for modeling such count data (e.g., in RNA-Seq analysis with tools like DESeq2 or edgeR, which is directly analogous). The Benjamini-Hochberg procedure is the canonical method for controlling the FDR in multiple hypothesis testing scenarios common in genomics. The problem is scientifically sound and directly relevant to translational medicine via DEL technology.\n- **Well-Posed**: The problem is clearly structured, providing sufficient theoretical assumptions for the derivation and complete numerical data for the statistical analysis. The tasks are specific and lead to a unique, meaningful solution.\n- **Objective**: The problem is stated in precise, quantitative, and unbiased technical language. It is free from subjective claims.\n\nThe problem does not exhibit any of the listed flaws (e.g., unsoundness, incompleteness, ambiguity). All terms are standard in the field.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A full solution will be provided.\n\n### Derivation of Normalized Log-Enrichment\n\nLet $T_i$ and $C_i$ be the observed read counts for tag $i$ in the target and control experiments, respectively. Let $N_T$ and $N_C$ be the total library sizes (total read counts) for the target and control runs. The guanine-cytosine fraction for tag $i$ is $g_i$.\n\nThe problem states that the counts follow a Poisson distribution and are modeled by a GLM with a log link, an affine dependency on $g_i$, and a library size offset. For the target run, the model for the expected count $\\mu_{T,i}$ of tag $i$ is:\n$$ \\ln(\\mu_{T,i}) = \\ln(N_T) + f_T(g_i) $$\nFor the control run, the model for the expected count $\\mu_{C,i}$ is:\n$$ \\ln(\\mu_{C,i}) = \\ln(N_C) + f_C(g_i) $$\nThe term $\\ln(N_r)$ is the offset, accounting for sequencing depth. The functions $f_T(g_i)$ and $f_C(g_i)$ are affine, meaning they have the form $f_r(g_i) = \\beta_{r,0} + \\beta_{r,1}g_i$. These functions model the combination of baseline log-abundance and the systematic, $g_i$-dependent bias.\n\nTo remove the bias, we first fit these models to the data to obtain estimates of the functions, denoted $\\hat{f}_T(g_i)$ and $\\hat{f}_C(g_i)$. These functions represent the expected log-count for a given $g_i$ after accounting for library size.\n\nThe enrichment of a tag is the increase in its relative abundance in the target selection compared to the control. The uncorrected log-enrichment, or log-fold-change, is typically calculated as $\\ln\\left(\\frac{T_i/N_T}{C_i/N_C}\\right)$. This can be expanded as:\n$$ L_i^{\\text{uncorrected}} = \\ln(T_i) - \\ln(C_i) - (\\ln(N_T) - \\ln(N_C)) $$\nThis expression is biased because $T_i$ and $C_i$ are affected by the $g_i$-dependent bias. The core idea of the normalization is to correct the observed log-counts by subtracting the predicted contribution from the GC-bias trend. The corrected log-abundances are the residuals on the log scale, representing deviations from the systematic trend.\n\nThe normalized log-abundance for tag $i$ in the target run is:\n$$ l_{T,i}^{\\text{norm}} = \\ln\\left(\\frac{T_i}{N_T}\\right) - \\hat{f}_T(g_i) $$\nAnd for the control run:\n$$ l_{C,i}^{\\text{norm}} = \\ln\\left(\\frac{C_i}{N_C}\\right) - \\hat{f}_C(g_i) $$\nThe normalized log-enrichment, $L_i^{\\text{norm}}$, is the difference between these two normalized log-abundances:\n$$ L_i^{\\text{norm}} = l_{T,i}^{\\text{norm}} - l_{C,i}^{\\text{norm}} = \\left( \\ln\\left(\\frac{T_i}{N_T}\\right) - \\hat{f}_T(g_i) \\right) - \\left( \\ln\\left(\\frac{C_i}{N_C}\\right) - \\hat{f}_C(g_i) \\right) $$\nRearranging the terms gives the closed-form expression for the normalized log-enrichment:\n$$ L_i^{\\text{norm}} = \\ln\\left(\\frac{T_i}{C_i}\\right) - \\ln\\left(\\frac{N_T}{N_C}\\right) - \\left( \\hat{f}_T(g_i) - \\hat{f}_C(g_i) \\right) $$\nHere, $\\hat{f}_T(g_i)$ and $\\hat{f}_C(g_i)$ are the fitted values from the separate Poisson regressions for the target and control data, respectively, evaluated at $g_i$.\n\n### Benjamini–Hochberg (BH) Analysis\n\nThe BH procedure is used to control the FDR. Let there be $m$ tests with $p$-values $p_1, \\dots, p_m$. The procedure is:\n1. Sort the $p$-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$.\n2. For a target FDR $\\alpha$, find the largest integer $k$ such that $p_{(k)} \\le \\frac{k}{m}\\alpha$.\n3. Declare the tests corresponding to $p_{(1)}, \\dots, p_{(k)}$ as significant discoveries (\"hits\").\n\nIn this problem, $m=6$ and $\\alpha=0.050$. The critical value for the $k$-th sorted $p$-value is $\\frac{k}{6} \\times 0.050$.\n\n**Analysis Before Correction:**\nThe sorted $p$-values are: $p_{(1)}=0.006$, $p_{(2)}=0.015$, $p_{(3)}=0.028$, $p_{(4)}=0.044$, $p_{(5)}=0.090$, $p_{(6)}=0.240$.\n- $k=1$: $p_{(1)}=0.006 \\le \\frac{1}{6}(0.050) \\approx 0.00833$. Condition met.\n- $k=2$: $p_{(2)}=0.015 \\le \\frac{2}{6}(0.050) \\approx 0.01667$. Condition met.\n- $k=3$: $p_{(3)}=0.028 > \\frac{3}{6}(0.050) = 0.025$. Condition not met.\nThe largest $k$ for which the condition holds is $k=2$. Thus, **$2$ hits** would be called before correction.\n\n**Analysis After Correction:**\nThe sorted $p$-values are: $p_{(1)}=0.0008$, $p_{(2)}=0.0040$, $p_{(3)}=0.0110$, $p_{(4)}=0.0320$, $p_{(5)}=0.0800$, $p_{(6)}=0.2100$.\n- $k=1$: $p_{(1)}=0.0008 \\le \\frac{1}{6}(0.050) \\approx 0.00833$. Condition met.\n- $k=2$: $p_{(2)}=0.0040 \\le \\frac{2}{6}(0.050) \\approx 0.01667$. Condition met.\n- $k=3$: $p_{(3)}=0.0110 \\le \\frac{3}{6}(0.050) = 0.02500$. Condition met.\n- $k=4$: $p_{(4)}=0.0320 \\le \\frac{4}{6}(0.050) \\approx 0.03333$. Condition met.\n- $k=5$: $p_{(5)}=0.0800 > \\frac{5}{6}(0.050) \\approx 0.04167$. Condition not met.\nThe largest $k$ for which the condition holds is $k=4$. Thus, **$4$ hits** would be called after correction.\n\n### BH-Adjusted $q$-value Calculation\n\nThe BH-adjusted $p$-value, or $q$-value, for the $i$-th sorted raw $p$-value $p_{(i)}$ is given by:\n$$ q_{(i)} = \\min_{j \\ge i} \\left( \\frac{m}{j} p_{(j)} \\right) $$\nThis calculation ensures that the resulting $q$-values are monotonic ($q_{(1)} \\le q_{(2)} \\le \\dots \\le q_{(m)}$).\n\nWe need to compute the $q$-value for the most significant tag after GC correction, which corresponds to the smallest $p$-value, $p_{(1)}=0.0008$.\nFor $i=1$, the formula simplifies to:\n$$ q_{(1)} = \\min_{j=1, \\dots, 6} \\left( \\frac{6}{j} p_{(j)} \\right) $$\nLet's compute the terms $\\frac{6}{j} p_{(j)}$:\n- $j=1$: $\\frac{6}{1} p_{(1)} = 6 \\times 0.0008 = 0.0048$\n- $j=2$: $\\frac{6}{2} p_{(2)} = 3 \\times 0.0040 = 0.0120$\n- $j=3$: $\\frac{6}{3} p_{(3)} = 2 \\times 0.0110 = 0.0220$\n- $j=4$: $\\frac{6}{4} p_{(4)} = 1.5 \\times 0.0320 = 0.0480$\n- $j=5$: $\\frac{6}{5} p_{(5)} = 1.2 \\times 0.0800 = 0.0960$\n- $j=6$: $\\frac{6}{6} p_{(6)} = 1 \\times 0.2100 = 0.2100$\n\nThe $q$-value $q_{(1)}$ is the minimum of these values:\n$$ q_{(1)} = \\min\\{0.0048, 0.0120, 0.0220, 0.0480, 0.0960, 0.2100\\} = 0.0048 $$\nThe problem requires the answer to be rounded to four significant figures. The calculated value is $0.0048$. To express this with four significant figures, we append zeros: $0.004800$.",
            "answer": "$$\n\\boxed{0.004800}\n$$"
        }
    ]
}