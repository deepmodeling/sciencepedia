{
    "hands_on_practices": [
        {
            "introduction": "Biological networks are rarely observed directly; they are typically inferred from high-throughput experimental data. This process involves testing thousands of potential interactions simultaneously, creating a significant multiple hypothesis testing problem. This exercise  guides you through a crucial step in network construction: applying the Benjamini-Hochberg procedure to control the false discovery rate ($FDR$), ensuring that the resulting network model is statistically robust and enriched for true biological connections.",
            "id": "5002377",
            "problem": "A translational oncology study seeks to construct an undirected, unweighted signaling network among $6$ phospho-proteins $\\{g_{1}, g_{2}, g_{3}, g_{4}, g_{5}, g_{6}\\}$ measured in matched tumor biopsies before and after a targeted therapy. For each candidate undirected edge $(g_{i}, g_{j})$ with $ij$, a hypothesis test was performed for conditional association controlling for treatment arm and batch, producing a $p$-value for that edge. The study will move forward only with those edges that pass control of the Benjamini–Hochberg (BH) false discovery rate (FDR) at level $\\alpha=0.05$, based on translational constraints described below. The $15$ candidate edges and their $p$-values are:\n$(g_{1}, g_{2}): 0.041$,\n$(g_{1}, g_{3}): 0.003$,\n$(g_{1}, g_{4}): 0.073$,\n$(g_{1}, g_{5}): 0.009$,\n$(g_{1}, g_{6}): 0.14$,\n$(g_{2}, g_{3}): 0.021$,\n$(g_{2}, g_{4}): 0.001$,\n$(g_{2}, g_{5}): 0.061$,\n$(g_{2}, g_{6}): 0.081$,\n$(g_{3}, g_{4}): 0.052$,\n$(g_{3}, g_{5}): 0.012$,\n$(g_{3}, g_{6}): 0.091$,\n$(g_{4}, g_{5}): 0.033$,\n$(g_{4}, g_{6}): 0.007$,\n$(g_{5}, g_{6}): 0.018$.\n\nUsing only the foundational definition of the false discovery rate and the Benjamini–Hochberg step-up control principle, do the following:\n- Apply BH-FDR at level $\\alpha=0.05$ to determine which edges are retained, and construct the binary adjacency matrix $\\mathbf{A}\\in\\{0,1\\}^{6\\times 6}$ (ordered as $[g_{1}, g_{2}, g_{3}, g_{4}, g_{5}, g_{6}]$) with $A_{ii}=0$ and $A_{ij}=A_{ji}=1$ if and only if $(g_{i}, g_{j})$ is retained.\n- Briefly justify, from first principles relevant to translational medicine, why $\\alpha=0.05$ is an appropriate choice in this setting, referencing constraints on downstream experimental validation and the interpretation of the expected proportion of false discoveries.\n\nProvide as your final reported quantity the total number of retained edges, that is, the sum of the strictly upper-triangular entries of $\\mathbf{A}$. No rounding is required. The final answer must be a single real-valued number.",
            "solution": "The problem statement is evaluated for validity prior to attempting a solution.\n\n### Step 1: Extract Givens\n-   Number of phospho-proteins: $6$, denoted as $\\{g_{1}, g_{2}, g_{3}, g_{4}, g_{5}, g_{6}\\}$.\n-   Network type: Undirected, unweighted.\n-   Number of candidate edges and hypotheses: $m = \\binom{6}{2} = 15$.\n-   Set of $15$ $p$-values for the candidate edges:\n    -   $(g_{1}, g_{2}): 0.041$, $(g_{1}, g_{3}): 0.003$, $(g_{1}, g_{4}): 0.073$, $(g_{1}, g_{5}): 0.009$, $(g_{1}, g_{6}): 0.14$,\n    -   $(g_{2}, g_{3}): 0.021$, $(g_{2}, g_{4}): 0.001$, $(g_{2}, g_{5}): 0.061$, $(g_{2}, g_{6}): 0.081$,\n    -   $(g_{3}, g_{4}): 0.052$, $(g_{3}, g_{5}): 0.012$, $(g_{3}, g_{6}): 0.091$,\n    -   $(g_{4}, g_{5}): 0.033$, $(g_{4}, g_{6}): 0.007$,\n    -   $(g_{5}, g_{6}): 0.018$.\n-   Statistical control method: Benjamini–Hochberg (BH) false discovery rate (FDR).\n-   Significance level: $\\alpha = 0.05$.\n-   Task 1: Determine the set of retained edges using BH-FDR.\n-   Task 2: Construct the binary adjacency matrix $\\mathbf{A}\\in\\{0,1\\}^{6\\times 6}$.\n-   Task 3: Justify the choice of $\\alpha=0.05$ from a translational medicine perspective.\n-   Final reported quantity: The total number of retained edges, which is the sum of the strictly upper-triangular entries of $\\mathbf{A}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard bioinformatics workflow in translational oncology: network inference from high-throughput data with multiple hypothesis test correction. The Benjamini-Hochberg procedure is a well-defined, established statistical method for controlling the false discovery rate. All necessary data (the set of $15$ $p$-values, the number of hypotheses $m=15$, and the control level $\\alpha=0.05$) are provided and are mutually consistent. The context is realistic and the question is specific and formalizable. The problem does not violate any scientific principles, is not incomplete or contradictory, and does not contain any subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A solution will be furnished.\n\n### Solution\nThe first task is to apply the Benjamini-Hochberg (BH) procedure to control the false discovery rate (FDR) at level $\\alpha = 0.05$. The total number of hypotheses tested is $m=15$.\n\nThe BH procedure involves the following steps:\n1.  Order the $m$ $p$-values from smallest to largest: $p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$.\n2.  Find the largest integer $k$ such that the $k$-th ordered $p$-value, $p_{(k)}$, satisfies the condition $p_{(k)} \\le \\frac{k}{m}\\alpha$.\n3.  Declare the hypotheses corresponding to the $p$-values $p_{(1)}, p_{(2)}, \\dots, p_{(k)}$ as significant (i.e., reject the null hypotheses).\n\nLet us list the $15$ $p$-values and sort them in ascending order. The threshold for the $i$-th p-value is $\\frac{i}{15} \\times 0.05 = \\frac{i}{300}$.\n\n-   $p_{(1)} = 0.001$ for edge $(g_{2}, g_{4})$. The BH threshold is $\\frac{1}{15}(0.05) \\approx 0.00333$. Since $0.001 \\le 0.00333$, this edge is significant.\n-   $p_{(2)} = 0.003$ for edge $(g_{1}, g_{3})$. The BH threshold is $\\frac{2}{15}(0.05) \\approx 0.00667$. Since $0.003 \\le 0.00667$, this edge is significant.\n-   $p_{(3)} = 0.007$ for edge $(g_{4}, g_{6})$. The BH threshold is $\\frac{3}{15}(0.05) = 0.01$. Since $0.007 \\le 0.01$, this edge is significant.\n-   $p_{(4)} = 0.009$ for edge $(g_{1}, g_{5})$. The BH threshold is $\\frac{4}{15}(0.05) \\approx 0.01333$. Since $0.009 \\le 0.01333$, this edge is significant.\n-   $p_{(5)} = 0.012$ for edge $(g_{3}, g_{5})$. The BH threshold is $\\frac{5}{15}(0.05) \\approx 0.01667$. Since $0.012 \\le 0.01667$, this edge is significant.\n-   $p_{(6)} = 0.018$ for edge $(g_{5}, g_{6})$. The BH threshold is $\\frac{6}{15}(0.05) = 0.02$. Since $0.018 \\le 0.02$, this edge is significant.\n-   $p_{(7)} = 0.021$ for edge $(g_{2}, g_{3})$. The BH threshold is $\\frac{7}{15}(0.05) \\approx 0.02333$. Since $0.021 \\le 0.02333$, this edge is significant.\n-   $p_{(8)} = 0.033$ for edge $(g_{4}, g_{5})$. The BH threshold is $\\frac{8}{15}(0.05) \\approx 0.02667$. Since $0.033  0.02667$, this edge is not significant, and we stop here.\n\nThe largest $k$ for which $p_{(k)} \\le \\frac{k}{m}\\alpha$ is $k=7$. Therefore, we retain the $7$ edges corresponding to the $7$ smallest $p$-values.\n\nThe set of retained edges is:\n$\\{ (g_{1}, g_{3}), (g_{1}, g_{5}), (g_{2}, g_{3}), (g_{2}, g_{4}), (g_{3}, g_{5}), (g_{4}, g_{6}), (g_{5}, g_{6}) \\}$.\n\nThe total number of retained edges is $7$.\n\nNext, we construct the binary adjacency matrix $\\mathbf{A}$ for the network with proteins ordered as $[g_{1}, g_{2}, g_{3}, g_{4}, g_{5}, g_{6}]$. The entries $A_{ij}$ and $A_{ji}$ are $1$ if edge $(g_{i}, g_{j})$ is retained, and $0$ otherwise. All diagonal entries $A_{ii}$ are $0$.\n-   $g_1$ is connected to $g_3$ and $g_5$: $A_{13}=A_{31}=1$, $A_{15}=A_{51}=1$.\n-   $g_2$ is connected to $g_3$ and $g_4$: $A_{23}=A_{32}=1$, $A_{24}=A_{42}=1$.\n-   $g_3$ is connected to $g_1$, $g_2$, and $g_5$: $A_{31}=A_{13}=1$, $A_{32}=A_{23}=1$, $A_{35}=A_{53}=1$. (These are already accounted for by symmetry).\n-   $g_4$ is connected to $g_2$ and $g_6$: $A_{42}=A_{24}=1$, $A_{46}=A_{64}=1$.\n-   $g_5$ is connected to $g_1$, $g_3$, and $g_6$: $A_{51}=A_{15}=1$, $A_{53}=A_{35}=1$, $A_{56}=A_{65}=1$.\n-   $g_6$ is connected to $g_4$ and $g_5$: $A_{64}=A_{46}=1$, $A_{65}=A_{56}=1$.\n\nThe resulting adjacency matrix $\\mathbf{A}$ is:\n$$ \\mathbf{A} = \\begin{pmatrix}\n0  0  1  0  1  0 \\\\\n0  0  1  1  0  0 \\\\\n1  1  0  0  1  0 \\\\\n0  1  0  0  0  1 \\\\\n1  0  1  0  0  1 \\\\\n0  0  0  1  1  0\n\\end{pmatrix} $$\nThe sum of the strictly upper-triangular entries of $\\mathbf{A}$ is $A_{13} + A_{15} + A_{23} + A_{24} + A_{35} + A_{46} + A_{56} = 1+1+1+1+1+1+1=7$, which confirms our count of retained edges.\n\nFinally, we justify the choice of $\\alpha=0.05$ from first principles relevant to translational medicine.\nThe objective of translational medicine is to bridge the gap between basic research and clinical practice. In this context, the construction of a signaling network is an exploratory, hypothesis-generating step. The \"discoveries\" are the retained edges, which represent putative protein-protein interactions or functional associations worthy of further investigation.\n\n1.  **Definition of FDR**: The False Discovery Rate (FDR) is the expected proportion of false positives among all declared discoveries. Controlling FDR at $\\alpha=0.05$ means we accept that, on average, no more than $5\\%$ of the retained edges will be spurious. This is fundamentally different from controlling the Family-Wise Error Rate (FWER), the probability of making even a single false discovery, which would be overly conservative for an exploratory study with many hypotheses ($m=15$). FWER control would severely reduce statistical power, leading to a sparse network that likely misses many true biological interactions.\n\n2.  **Balancing Discovery and Resources**: Translational research is a pipeline. The output of one stage (network inference) becomes the input for the next, more targeted, and expensive stage (e.g., experimental validation using techniques like immunoprecipitation, or functional studies in cell lines). Setting $\\alpha=0.05$ represents a pragmatic trade-off. A much higher $\\alpha$ would generate a dense network with many false positives, wasting precious time and resources on validating dead ends. A much lower $\\alpha$ would yield too few candidates, potentially causing the entire project to stall for lack of hypotheses. An FDR of $5\\%$ is conventionally accepted as a reasonable balance, yielding a list of discoveries that is enriched for true signals but not so large as to be intractable for follow-up. For the $7$ edges discovered, we expect on average $7 \\times 0.05 = 0.35$ false positives, which is a highly favorable outcome for downstream validation efforts.\n\n3.  **Scientific Context**: The goal is not to prove the network's structure with absolute certainty from this single dataset, but to generate a high-quality model that can be used to formulate new, testable hypotheses about the therapy's mechanism of action. An FDR of $5\\%$ is a standard that allows for meaningful progress in this iterative process of discovery and validation, which is the essence of translational science.\n\nThe final reported quantity is the total number of retained edges. As calculated, this number is $7$.",
            "answer": "$$ \\boxed{7} $$"
        },
        {
            "introduction": "Once a network is constructed, the next step is to analyze its topology to uncover biological meaning. This practice  focuses on calculating fundamental node-level metrics—degree centrality and the local clustering coefficient—from a network's adjacency matrix. By computing these values, you will learn to distinguish nodes that are central to dense, tightly-knit functional modules from those that act as critical bridges connecting different biological pathways.",
            "id": "5002394",
            "problem": "A disease-specific Protein-Protein Interaction (PPI) network is constructed from a cohort in translational medicine by integrating physical binding data and condition-specific co-expression. The resulting undirected, unweighted network among $6$ gene products is represented by the symmetric adjacency matrix $A \\in \\{0,1\\}^{6 \\times 6}$ with zero diagonal:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0  0  0\\\\\n1  0  1  0  0  0\\\\\n1  1  0  1  0  0\\\\\n0  0  1  0  1  1\\\\\n0  0  0  1  0  1\\\\\n0  0  0  1  1  0\n\\end{pmatrix}.\n$$\nNodes are indexed by $i \\in \\{1,2,3,4,5,6\\}$. Using core graph-theoretic definitions appropriate for undirected simple graphs, perform the following:\n- For each node $i$, compute the normalized degree centrality $C_{D}(i)$ based on $k_{i}$, the degree of node $i$, using the normalization by the maximum possible degree in a graph with $n=6$ nodes.\n- For each node $i$, compute the local clustering coefficient $C_{i}$ defined as the fraction of realized connections among the neighbors of $i$ out of all possible connections among those neighbors. Adopt the convention that $C_{i}=0$ when $k_{i}2$.\n- Based on your calculations, interpret which nodes likely lie in dense functional modules and which nodes act as inter-module connectors in the sense of translational network biology, where high local clustering suggests membership in a functional complex or pathway, and lower local clustering in high-degree nodes can suggest bridging roles.\n\nFinally, report the network average of the local clustering coefficients $\\bar{C} = \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$ as a decimal rounded to $4$ significant figures. No units are required for the final reported value.",
            "solution": "The problem is subjected to validation and is deemed valid. It is scientifically grounded in graph theory and its application to biological network analysis, is well-posed with all necessary information provided, and is expressed in objective, formal language. We may therefore proceed with the solution.\n\nThe problem requires a multi-step analysis of a given biological network represented by an adjacency matrix $A$. The network has $n=6$ nodes.\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0  0  0\\\\\n1  0  1  0  0  0\\\\\n1  1  0  1  0  0\\\\\n0  0  1  0  1  1\\\\\n0  0  0  1  0  1\\\\\n0  0  0  1  1  0\n\\end{pmatrix}\n$$\nThe analysis involves computing node-specific metrics, interpreting their biological significance, and calculating a global network property.\n\nFirst, we compute the degree $k_i$ for each node $i$, which is the number of connections it has. For an undirected graph represented by a symmetric adjacency matrix $A$, the degree of node $i$ is the sum of the elements in the $i$-th row (or column).\n$k_i = \\sum_{j=1}^{n} A_{ij}$\n- $k_1 = 1+1 = 2$\n- $k_2 = 1+1 = 2$\n- $k_3 = 1+1+1 = 3$\n- $k_4 = 1+1+1 = 3$\n- $k_5 = 1+1 = 2$\n- $k_6 = 1+1 = 2$\n\nNext, we compute the normalized degree centrality $C_D(i)$ for each node. This is defined as the node's degree $k_i$ divided by the maximum possible degree in a simple graph of $n$ nodes, which is $n-1$. Here, $n=6$, so the maximum possible degree is $n-1 = 5$.\n$C_D(i) = \\frac{k_i}{n-1}$\n- $C_D(1) = \\frac{k_1}{5} = \\frac{2}{5} = 0.4$\n- $C_D(2) = \\frac{k_2}{5} = \\frac{2}{5} = 0.4$\n- $C_D(3) = \\frac{k_3}{5} = \\frac{3}{5} = 0.6$\n- $C_D(4) = \\frac{k_4}{5} = \\frac{3}{5} = 0.6$\n- $C_D(5) = \\frac{k_5}{5} = \\frac{2}{5} = 0.4$\n- $C_D(6) = \\frac{k_6}{5} = \\frac{2}{5} = 0.4$\n\nNow, we compute the local clustering coefficient $C_i$ for each node. This coefficient measures the density of connections among a node's neighbors. It is defined as the number of existing edges between the neighbors of node $i$, denoted $E_i$, divided by the total number of possible edges between them. For an undirected graph, this is given by the formula:\n$C_i = \\frac{2 E_i}{k_i (k_i - 1)}$\nThe problem specifies the convention that $C_i = 0$ if $k_i  2$. Since all nodes have a degree of at least $2$, this convention is not invoked.\n\n- **Node 1**: $k_1=2$. Neighbors are $N(1) = \\{2, 3\\}$. There is $E_1=1$ edge between them (the edge $(2,3)$ since $A_{23}=1$).\n$C_1 = \\frac{2 \\times 1}{2 \\times (2 - 1)} = \\frac{2}{2} = 1$\n\n- **Node 2**: $k_2=2$. Neighbors are $N(2) = \\{1, 3\\}$. There is $E_2=1$ edge between them (the edge $(1,3)$ since $A_{13}=1$).\n$C_2 = \\frac{2 \\times 1}{2 \\times (2 - 1)} = \\frac{2}{2} = 1$\n\n- **Node 3**: $k_3=3$. Neighbors are $N(3) = \\{1, 2, 4\\}$. The possible edges are $(1,2)$, $(1,4)$, and $(2,4)$. We check the adjacency matrix: $A_{12}=1$, $A_{14}=0$, $A_{24}=0$. Thus, there is only $E_3=1$ edge among the neighbors.\n$C_3 = \\frac{2 \\times 1}{3 \\times (3 - 1)} = \\frac{2}{6} = \\frac{1}{3}$\n\n- **Node 4**: $k_4=3$. Neighbors are $N(4) = \\{3, 5, 6\\}$. The possible edges are $(3,5)$, $(3,6)$, and $(5,6)$. We check the adjacency matrix: $A_{35}=0$, $A_{36}=0$, $A_{56}=1$. Thus, there is only $E_4=1$ edge among the neighbors.\n$C_4 = \\frac{2 \\times 1}{3 \\times (3 - 1)} = \\frac{2}{6} = \\frac{1}{3}$\n\n- **Node 5**: $k_5=2$. Neighbors are $N(5) = \\{4, 6\\}$. There is $E_5=1$ edge between them (the edge $(4,6)$ since $A_{46}=1$).\n$C_5 = \\frac{2 \\times 1}{2 \\times (2 - 1)} = \\frac{2}{2} = 1$\n\n- **Node 6**: $k_6=2$. Neighbors are $N(6) = \\{4, 5\\}$. There is $E_6=1$ edge between them (the edge $(4,5)$ since $A_{45}=1$).\n$C_6 = \\frac{2 \\times 1}{2 \\times (2 - 1)} = \\frac{2}{2} = 1$\n\nBased on these calculations, we can interpret the roles of the nodes.\n- **Nodes 1, 2, 5, 6**: These nodes have a local clustering coefficient of $C_i = 1$. This maximal value indicates that their neighbors are fully connected, forming a clique. These nodes are deeply embedded within dense functional modules. Specifically, nodes $\\{1, 2, 3\\}$ form a triangle, and nodes $\\{4, 5, 6\\}$ form another triangle. Nodes $1$ and $2$ belong to the first module, and nodes $5$ and $6$ belong to the second.\n- **Nodes 3, 4**: These nodes have the highest degree centrality in the network ($C_D(3) = C_D(4) = 0.6$). However, their local clustering coefficients are relatively low ($C_3 = C_4 = 1/3$). This pattern—high degree and low local clustering—is characteristic of nodes that act as \"bridges\" or inter-module connectors. Node $3$ is part of the first functional module but also connects to node $4$. Similarly, node $4$ is part of the second module and connects to node $3$. The edge $(3,4)$ is the sole connection linking the two dense triangular modules, confirming the bridging role of nodes $3$ and $4$.\n\nFinally, we compute the network average of the local clustering coefficients, $\\bar{C}$.\n$\\bar{C} = \\frac{1}{n}\\sum_{i=1}^{n} C_{i}$\n$\\bar{C} = \\frac{1}{6} (C_1 + C_2 + C_3 + C_4 + C_5 + C_6)$\n$\\bar{C} = \\frac{1}{6} \\left(1 + 1 + \\frac{1}{3} + \\frac{1}{3} + 1 + 1\\right)$\n$\\bar{C} = \\frac{1}{6} \\left(4 + \\frac{2}{3}\\right)$\n$\\bar{C} = \\frac{1}{6} \\left(\\frac{12}{3} + \\frac{2}{3}\\right) = \\frac{1}{6} \\left(\\frac{14}{3}\\right) = \\frac{14}{18} = \\frac{7}{9}$\n\nTo report this value as a decimal rounded to $4$ significant figures:\n$\\frac{7}{9} \\approx 0.777777...$\nRounding to $4$ significant figures gives $0.7778$.",
            "answer": "$$\\boxed{0.7778}$$"
        },
        {
            "introduction": "Beyond describing structure, a key application of biological networks is to generate novel, testable hypotheses. This exercise  implements the powerful Random Walk with Restart ($RWR$) algorithm, a cornerstone of network medicine for prioritizing new disease gene candidates. By simulating how information flows from a set of known \"seed\" genes, you will learn how to leverage the network's global structure to quantify the functional proximity of all other genes to a disease of interest.",
            "id": "5002343",
            "problem": "You are given small protein-protein interaction (PPI) networks and disease seed gene sets. Construct a principled, reproducible Random Walk with Restart (RWR) method to prioritize candidate genes by steady-state probability. Your program must implement the following, derived from the foundational theory of discrete-time Markov chains and stochastic matrices.\n\nDefinitions and foundational base:\n- A PPI network over $n$ genes is represented by a symmetric, nonnegative adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$ with entries $A_{ij} \\ge 0$ and $A_{ij} = A_{ji}$. The diagonal may be zero. The nonzero entries represent undirected interaction strengths.\n- A column-stochastic matrix $W \\in \\mathbb{R}^{n \\times n}$ satisfies $\\sum_{i=1}^{n} W_{ij} = 1$ for each column $j$ and $W_{ij} \\ge 0$. Such a matrix defines a Markov chain transition operator acting on a probability vector $p \\in \\mathbb{R}^{n}$ via the update $p^{(t+1)} = W p^{(t)}$, preserving $\\sum_{i=1}^{n} p^{(t)}_i = 1$ and $p^{(t)}_i \\ge 0$.\n- Given $A$, construct $W$ by column-normalization: for each column $j$ with column sum $\\sum_{i=1}^{n} A_{ij} > 0$, set $W_{ij} = A_{ij} / \\sum_{k=1}^{n} A_{kj}$. For any column $j$ with $\\sum_{i=1}^{n} A_{ij} = 0$ (an isolated node), set $W_{jj} = 1$ and $W_{ij} = 0$ for $i \\ne j$; this adds a self-loop that preserves probability mass at isolated nodes and ensures $W$ is column-stochastic.\n- Let the seed set be $S \\subset \\{0,1,\\dots,n-1\\}$. Define the seed distribution vector $s \\in \\mathbb{R}^{n}$ by $s_i = 1/|S|$ if $i \\in S$ and $s_i = 0$ otherwise, so that $\\sum_{i=1}^{n} s_i = 1$ and $s_i \\ge 0$.\n- Consider a Markov process on the network with restart parameter $\\gamma \\in (0,1]$ such that at each time step, with probability $\\gamma$ the walk restarts to the seeds according to $s$, and with probability $(1 - \\gamma)$ it follows a single network transition according to $W$. From the foundational definition of stationary distributions of Markov chains with teleportation, the unique steady-state distribution $p^\\star \\in \\mathbb{R}^{n}$ satisfies the fixed point equation $p^\\star = (1 - \\gamma) \\, W \\, p^\\star + \\gamma \\, s$ and is guaranteed to exist uniquely because the spectral radius of $(1 - \\gamma) \\, W$ is strictly less than $1$ when $\\gamma \\in (0,1]$ and $W$ is column-stochastic.\n\nProgram requirements:\n- For each test case below, construct $W$ from $A$ as specified, form $s$ from the provided seed set, and compute the unique $p^\\star$ exactly by solving the linear system implied by the fixed point condition without using iterative heuristics. Rank all non-seed nodes in descending order by $p^\\star_i$; break ties by ascending index $i$. Return the top-$k$ ranked non-seed indices for each case using zero-based indexing.\n- If all non-seed nodes have identical scores (for example, exactly $0$), use the tie-breaking rule to select indices in ascending order.\n- Numerical stability: if numerical round-off produces tiny negative entries in $p^\\star$, treat them as $0$ by clipping, and then renormalize to ensure $\\sum_{i=1}^{n} p^\\star_i = 1$.\n\nTest suite (use exactly these cases):\n1) Case 1 (happy path, connected, unweighted):\n   - $n = 6$; adjacency matrix $A \\in \\mathbb{R}^{6 \\times 6}$ with entries\n     $$A = \\begin{bmatrix}\n     0  1  0  0  0  1 \\\\\n     1  0  1  1  0  0 \\\\\n     0  1  0  1  0  0 \\\\\n     0  1  1  0  1  0 \\\\\n     0  0  0  1  0  1 \\\\\n     1  0  0  0  1  0\n     \\end{bmatrix}.$$\n   - Seed set $S = \\{0, 3\\}$.\n   - Restart $\\gamma = 0.35$.\n   - Top-$k$: $k = 3$.\n\n2) Case 2 (edge case, isolated seed):\n   - $n = 5$; adjacency matrix $A \\in \\mathbb{R}^{5 \\times 5}$ with entries\n     $$A = \\begin{bmatrix}\n     0  1  0  0  0 \\\\\n     1  0  1  0  0 \\\\\n     0  1  0  1  0 \\\\\n     0  0  1  0  0 \\\\\n     0  0  0  0  0\n     \\end{bmatrix}.$$\n   - Seed set $S = \\{4\\}$.\n   - Restart $\\gamma = 0.7$.\n   - Top-$k$: $k = 2$.\n\n3) Case 3 (weighted network, strong restart):\n   - $n = 7$; adjacency matrix $A \\in \\mathbb{R}^{7 \\times 7}$ with entries\n     $$A = \\begin{bmatrix}\n     0  2.0  1.0  0  0  0  0 \\\\\n     2.0  0  0  1.5  0  0  0 \\\\\n     1.0  0  0  0.5  0  0  1.0 \\\\\n     0  1.5  0.5  0  2.0  0  0 \\\\\n     0  0  0  2.0  0  1.0  0 \\\\\n     0  0  0  0  1.0  0  0.5 \\\\\n     0  0  1.0  0  0  0.5  0\n     \\end{bmatrix}.$$\n   - Seed set $S = \\{1, 4\\}$.\n   - Restart $\\gamma = 0.9$.\n   - Top-$k$: $k = 3$.\n\n4) Case 4 (boundary, full restart):\n   - Use the same $A$ as in Case $1$.\n   - Seed set $S = \\{0, 3\\}$.\n   - Restart $\\gamma = 1.0$.\n   - Top-$k$: $k = 2$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is a list of top-$k$ indices for the corresponding test case. For example: \"[$[i_{1,1},i_{1,2},\\dots]$, $[i_{2,1},\\dots]$, $[i_{3,1},\\dots]$, $[i_{4,1},\\dots]$]\". The final output must contain no spaces.",
            "solution": "The problem requires the implementation of the Random Walk with Restart (RWR) algorithm to prioritize candidate genes in a protein-protein interaction (PPI) network. The method leverages the mathematical framework of discrete-time Markov chains to quantify the proximity of network nodes to a predefined set of \"seed\" genes associated with a disease. The core of the task is to compute the unique steady-state probability distribution of this process and use it to rank non-seed genes.\n\nThe foundation of the model is a Markov process on the graph representing the PPI network. A network of $n$ genes is described by an adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$, where $A_{ij} \\ge 0$ represents the strength of the interaction between gene $i$ and gene $j$. Since interactions are undirected, $A$ is symmetric, i.e., $A_{ij} = A_{ji}$.\n\nFirst, we construct a column-stochastic transition matrix $W \\in \\mathbb{R}^{n \\times n}$ from $A$. This matrix $W$ defines the transition probabilities of a random walk on the network. A walker at node $j$ will move to node $i$ with probability $W_{ij}$. To ensure that the total probability of moving from node $j$ to any other node is $1$, each column of $W$ must sum to $1$. This is achieved by normalizing each column of $A$ by its sum:\n$$ W_{ij} = \\frac{A_{ij}}{\\sum_{k=1}^{n} A_{kj}} $$\nThis normalization is performed for every column $j$ whose sum $\\sum_{k=1}^{n} A_{kj}$ is greater than $0$. If a column $j$ has a sum of $0$, it corresponds to an isolated node with no outgoing connections. To conserve probability, such a node is modeled as a sink with a self-loop, meaning $W_{jj} = 1$ and $W_{ij} = 0$ for $i \\neq j$.\n\nThe RWR process modifies the standard random walk by introducing a \"restart\" mechanism. At each step, the walker has two choices:\n$1$. With probability $1 - \\gamma$, it follows a transition according to the matrix $W$.\n$2$. With probability $\\gamma$, it teleports back to one of the seed nodes.\n\nThe restart probability $\\gamma \\in (0, 1]$ is a crucial parameter. The distribution of restarts is governed by the seed vector $s \\in \\mathbb{R}^n$. Given a set of seed genes $S$, $s$ is defined as a uniform distribution over these genes: $s_i = 1/|S|$ if gene $i \\in S$, and $s_i = 0$ otherwise.\n\nLet $p^{(t)} \\in \\mathbb{R}^n$ be the probability distribution vector across all $n$ genes at step $t$, where $p_i^{(t)}$ is the probability of the walker being at node $i$. The distribution at the next step, $p^{(t+1)}$, is given by the recursive formula:\n$$ p^{(t+1)} = (1 - \\gamma) W p^{(t)} + \\gamma s $$\nThe process eventually converges to a unique steady-state distribution $p^\\star$, which no longer changes with further steps. This $p^\\star$ satisfies the fixed-point equation:\n$$ p^\\star = (1 - \\gamma) W p^\\star + \\gamma s $$\nThe components $p^\\star_i$ of this vector represent the long-term probability of finding the walker at node $i$ and are used as the scores for gene prioritization. A higher score implies stronger functional relevance to the seed set.\n\nTo find $p^\\star$ exactly, as required by the problem, we do not iterate the recurrence relation. Instead, we rearrange the fixed-point equation into a system of linear equations:\n$$ p^\\star - (1 - \\gamma) W p^\\star = \\gamma s $$\n$$ (I - (1 - \\gamma) W) p^\\star = \\gamma s $$\nwhere $I$ is the $n \\times n$ identity matrix. This is a standard linear system of the form $M x = b$, where the matrix $M = I - (1 - \\gamma) W$, the unknown vector is $x = p^\\star$, and the constant vector is $b = \\gamma s$. As established in the theory of Markov chains with teleportation, for any $\\gamma \\in (0,1]$, the matrix $M$ is guaranteed to be invertible, ensuring a unique solution for $p^\\star$. This solution can be computed efficiently using standard linear algebra solvers. The special case where $\\gamma = 1$ leads to $p^\\star = s$, as the walker always restarts and never traverses the network.\n\nThe algorithm to solve the problem is as follows:\n$1$. For a given adjacency matrix $A$, construct the transition matrix $W$ by normalizing the columns of $A$. For any column that sums to $0$, set the corresponding diagonal element of $W$ to $1$.\n$2$. For a given seed set $S$, construct the seed vector $s$ with uniform probabilities on the seed nodes.\n$3$. Form the matrix $M = I - (1 - \\gamma) W$ and the vector $b = \\gamma s$. For the boundary case $\\gamma=1$, $p^{\\star}$ is simply $s$.\n$4$. Solve the linear system $M p^\\star = b$ to find the steady-state vector $p^\\star$.\n$5$. For numerical robustness, any small negative values in the computed $p^\\star$ resulting from floating-point inaccuracies are clipped to $0$. The vector is then renormalized to ensure its elements sum to $1$.\n$6$. Identify all non-seed nodes. Create a list of pairs $(p^\\star_i, i)$ for each non-seed node $i$.\n$7$. Sort this list in descending order of the score $p^\\star_i$. Ties are broken by sorting in ascending order of the node index $i$.\n$8$. The final result is the list of the first $k$ indices from the sorted list.\n\nThis principled approach provides a reproducible and mathematically rigorous method for gene prioritization, directly addressing the problem as stated. It correctly handles edge cases such as isolated nodes and the boundary value of the restart parameter $\\gamma$.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the solving of all test cases.\n    \"\"\"\n\n    def _solve_rwr(A, S, gamma, k):\n        \"\"\"\n        Computes the Random Walk with Restart top-k gene ranking.\n\n        Args:\n            A (np.ndarray): The adjacency matrix of the network.\n            S (set): A set of integer indices for the seed nodes.\n            gamma (float): The restart probability.\n            k (int): The number of top non-seed nodes to return.\n\n        Returns:\n            list: A list of the top-k ranked non-seed node indices.\n        \"\"\"\n        n = A.shape[0]\n\n        # Step 1: Construct the column-stochastic transition matrix W\n        W = np.zeros_like(A, dtype=float)\n        col_sums = A.sum(axis=0)\n        \n        non_zero_sum_cols = col_sums  1e-9 # Use a tolerance for floating point\n        zero_sum_cols = ~non_zero_sum_cols\n\n        # Normalize columns with non-zero sum\n        W[:, non_zero_sum_cols] = A[:, non_zero_sum_cols] / col_sums[non_zero_sum_cols]\n\n        # Handle isolated nodes (columns with zero sum)\n        for j in np.where(zero_sum_cols)[0]:\n            W[j, j] = 1.0\n\n        # Step 2: Construct the seed vector s\n        s = np.zeros(n)\n        if len(S)  0:\n            s[list(S)] = 1.0 / len(S)\n\n        # Step 3  4: Solve the linear system (I - (1-gamma)W)p* = gamma*s\n        if gamma == 1.0:\n            p_star = s\n        else:\n            M = np.identity(n) - (1 - gamma) * W\n            b = gamma * s\n            p_star = np.linalg.solve(M, b)\n\n        # Step 5: Numerical stability post-processing\n        p_star = np.clip(p_star, a_min=0, a_max=None)\n        p_sum = p_star.sum()\n        if p_sum  1e-9: # Avoid division by zero\n            p_star /= p_sum\n\n        # Step 6: Rank non-seed nodes\n        non_seed_indices = [i for i in range(n) if i not in S]\n        \n        if not non_seed_indices:\n            return []\n\n        candidates = [(p_star[i], i) for i in non_seed_indices]\n\n        # Step 7: Sort candidates: primary key score (desc), secondary key index (asc)\n        candidates.sort(key=lambda x: (-x[0], x[1]))\n        \n        # Step 8: Extract top-k indices\n        top_k_indices = [idx for score, idx in candidates[:k]]\n        \n        return top_k_indices\n\n    # Test suite definition\n    case1_A = np.array([\n        [0, 1, 0, 0, 0, 1],\n        [1, 0, 1, 1, 0, 0],\n        [0, 1, 0, 1, 0, 0],\n        [0, 1, 1, 0, 1, 0],\n        [0, 0, 0, 1, 0, 1],\n        [1, 0, 0, 0, 1, 0]\n    ], dtype=float)\n    case1_S = {0, 3}\n    case1_gamma = 0.35\n    case1_k = 3\n\n    case2_A = np.array([\n        [0, 1, 0, 0, 0],\n        [1, 0, 1, 0, 0],\n        [0, 1, 0, 1, 0],\n        [0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0]\n    ], dtype=float)\n    case2_S = {4}\n    case2_gamma = 0.7\n    case2_k = 2\n\n    case3_A = np.array([\n        [0. , 2. , 1. , 0. , 0. , 0. , 0. ],\n        [2. , 0. , 0. , 1.5, 0. , 0. , 0. ],\n        [1. , 0. , 0. , 0.5, 0. , 0. , 1. ],\n        [0. , 1.5, 0.5, 0. , 2. , 0. , 0. ],\n        [0. , 0. , 0. , 2. , 0. , 1. , 0. ],\n        [0. , 0. , 0. , 0. , 1. , 0. , 0.5],\n        [0. , 0. , 1. , 0. , 0. , 0.5, 0. ]\n    ], dtype=float)\n    case3_S = {1, 4}\n    case3_gamma = 0.9\n    case3_k = 3\n\n    case4_A = case1_A.copy()\n    case4_S = {0, 3}\n    case4_gamma = 1.0\n    case4_k = 2\n    \n    test_cases = [\n        (case1_A, case1_S, case1_gamma, case1_k),\n        (case2_A, case2_S, case2_gamma, case2_k),\n        (case3_A, case3_S, case3_gamma, case3_k),\n        (case4_A, case4_S, case4_gamma, case4_k)\n    ]\n    \n    all_results = []\n    for A, S, gamma, k in test_cases:\n        result = _solve_rwr(A, S, gamma, k)\n        all_results.append(result)\n\n    # Format the final output string according to the specification (no spaces)\n    result_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```"
        }
    ]
}