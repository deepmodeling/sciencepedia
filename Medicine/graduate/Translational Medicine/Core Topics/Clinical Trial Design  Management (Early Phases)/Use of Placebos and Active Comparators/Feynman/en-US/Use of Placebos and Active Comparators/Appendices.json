{
    "hands_on_practices": [
        {
            "introduction": "The credibility of any non-inferiority trial hinges on the justification of its non-inferiority margin, the pre-specified degree of efficacy loss that is considered clinically acceptable. This margin cannot be arbitrary; it must be rigorously derived from historical evidence demonstrating the active comparator's superiority to a placebo. This exercise  provides hands-on practice with the standard two-step process used in regulatory settings: first, establishing a conservative estimate of the comparator's effect ($M_{1}$), and second, defining the final margin ($M_{2}$) by preserving a pre-specified fraction of that effect.",
            "id": "5074743",
            "problem": "A translational medicine team is planning a noninferiority trial comparing a new therapy to an established active comparator. To set margins grounded in historical evidence and clinical relevance, they rely on a meta-analytic synthesis of rigorously conducted, placebo-controlled trials of the active comparator. The meta-analysis yields an estimated mean true effect of the active comparator relative to placebo of $\\Delta_{H} = 2.0$ (in the same continuous outcome units as the primary endpoint of the planned trial), and a between-study standard deviation of true effects (heterogeneity) of $s_{H} = 0.5$. Assume that trial-level true effects for the active comparator against placebo are well approximated by a normal distribution centered at $\\Delta_{H}$ with dispersion $s_{H}$, and that the historical and planned trial contexts satisfy the constancy assumptions (including assay sensitivity, measurement invariance, and alignment of patient populations, endpoints, and care standards) needed to transport evidence.\n\nStarting from core definitions of noninferiority and using well-tested principles of meta-analysis and probability, derive a conservative historical margin $M_{1}$ representing the smallest plausible true effect of the active comparator versus placebo across the distribution of trial contexts that match the planned trial, and then construct a conservative noninferiority margin $M_{2}$ that preserves a fraction $p = 0.5$ of that effect. Provide a clear justification of the assumptions required for these constructions, including why the chosen bound for $M_{1}$ is appropriate for assay sensitivity and transportability, and how preserving a fraction of $M_{1}$ protects against dilution of efficacy.\n\nCompute and report numerical values for $M_{1}$ and $M_{2}$. Round both values to three significant figures. Express $M_{1}$ and $M_{2}$ in the same outcome units as $\\Delta_{H}$. Write your final numerical answers as two entries in a single row matrix.",
            "solution": "The problem requires the derivation and calculation of two noninferiority margins, $M_{1}$ and $M_{2}$, based on a meta-analytic synthesis of historical data for an active comparator. This process is a cornerstone of modern clinical trial design, particularly for establishing noninferiority in a manner that ensures the new therapy retains a clinically meaningful effect. The derivation proceeds in two steps, as outlined in regulatory guidance such as ICH E10.\n\nFirst, we determine the historical margin, $M_{1}$. This margin represents a conservative estimate of the effect of the active comparator relative to placebo. The problem states that the true effects of the active comparator from placebo-controlled trials are well-approximated by a normal distribution, $\\mathcal{N}(\\Delta_{H}, s_{H}^2)$, where the mean effect is $\\Delta_{H} = 2.0$ and the between-study standard deviation (heterogeneity) is $s_{H} = 0.5$. This distribution models our knowledge about the comparator's effect across a range of trial contexts.\n\nThe task is to find the \"smallest plausible true effect\" of the comparator. In this statistical framework, this corresponds to a lower-bound of a prediction interval for the true effect in a future trial. A prediction interval is appropriate because it accounts for both the uncertainty in the estimation of the mean effect $\\Delta_{H}$ (which is assumed to be negligible here, as $\\Delta_H$ is given as a point estimate) and, critically, the random, trial-to-trial variability represented by $s_{H}$.\n\nTo ensure a conservative margin, which is paramount for patient safety and assuring efficacy, we select a high confidence level for this lower bound. A standard and appropriately conservative choice in regulatory science is a one-sided $97.5\\%$ confidence level. This corresponds to the lower limit of a two-sided $95\\%$ interval and ensures that there is only a $2.5\\%$ chance that the true effect of the comparator in the new trial is less than $M_{1}$. The critical value from the standard normal distribution for a cumulative probability of $1 - 0.025 = 0.975$ is $z_{0.025} \\approx 1.960$.\n\nThus, the historical margin $M_{1}$ is calculated as:\n$$M_{1} = \\Delta_{H} - z_{0.025} \\cdot s_{H}$$\nThis formulation is justified because it establishes a floor for the comparator's effect with high confidence. The satisfaction of the \"constancy assumption\" is critical here; it posits that the historical trial contexts are sufficiently similar to the planned trial's context, making the predictive distribution $\\mathcal{N}(\\Delta_{H}, s_{H}^2)$ applicable. By using this lower bound $M_{1}$, we ensure assay sensitivity: if $M_{1} > 0$, we are confident that the active comparator is effective in the planned trial's setting, which is a prerequisite for a noninferiority comparison.\n\nSecond, we construct the noninferiority margin, $M_{2}$. This margin is the largest acceptable loss of efficacy for the new therapy compared to the active comparator. The guiding principle is that the new therapy must preserve a pre-specified fraction, $p$, of the active comparator's effect, $M_{1}$. Let $\\Delta_{T}$ be the effect of the new therapy versus placebo and $\\Delta_{A}$ be the effect of the active comparator versus placebo. We require that the new therapy's effect is at least a fraction $p$ of the comparator's effect:\n$$\\Delta_{T} \\ge p \\cdot \\Delta_{A}$$\nThe noninferiority hypothesis is tested on the difference in effects, $\\delta = \\Delta_{A} - \\Delta_{T}$. Rearranging the preservation requirement, we get:\n$$\\Delta_{A} - \\delta \\ge p \\cdot \\Delta_{A}$$\n$$\\delta \\le \\Delta_{A} (1-p)$$\nTo be conservative, we must base this on the smallest plausible effect of the comparator, which is $M_{1}$. Therefore, the noninferiority margin $M_{2}$ is set as:\n$$M_{2} = M_{1} (1-p)$$\nThe problem specifies that a fraction $p=0.5$ of the effect must be preserved. This practice protects against \"bio-creep\" or the dilution of efficacy, where a new drug that is non-inferior to a weakly effective comparator might itself have little to no clinically relevant effect over placebo. By requiring the new therapy to preserve at least $50\\%$ of the comparator's minimal plausible effect, we ensure it is demonstrably efficacious.\n\nNow, we compute the numerical values.\nGiven:\nMean historical effect, $\\Delta_{H} = 2.0$.\nHeterogeneity standard deviation, $s_{H} = 0.5$.\nFraction to preserve, $p = 0.5$.\nChosen critical value, $z_{0.025} \\approx 1.960$.\n\nCalculation of $M_{1}$:\n$$M_{1} = 2.0 - 1.960 \\times 0.5 = 2.0 - 0.98 = 1.02$$\n\nCalculation of $M_{2}$:\n$$M_{2} = M_{1} (1 - 0.5) = 1.02 \\times 0.5 = 0.51$$\n\nThe problem requires rounding to three significant figures.\n$M_{1} = 1.02$ is already stated with three significant figures.\n$M_{2} = 0.51$ needs to be expressed with three significant figures, which is $0.510$.\n\nSo, the conservative historical margin is $M_{1} = 1.02$, and the conservative noninferiority margin is $M_{2} = 0.510$.",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.02 & 0.510\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "Once a non-inferiority margin is established, the next crucial step in trial design is to calculate the sample size required to test the hypothesis with adequate statistical power. This practice  challenges you to derive the sample size formula from first principles, a foundational skill for any trialist. It also delves into the critical distinction between the Intention-To-Treat (ITT) and Per-Protocol (PP) analysis populations, highlighting why this choice has profound implications for the validity of non-inferiority conclusions.",
            "id": "5074690",
            "problem": "A team in translational medicine is planning a noninferiority evaluation of a novel anti-inflammatory compound against an established active comparator where placebo use is ethically unacceptable. The continuous clinical endpoint is measured on a validated scale. The established comparator is considered the Standard Of Care (SOC). The noninferiority margin is set at $\\Delta_{NI} = 0.5$ units based on clinical and biological plausibility, and prior translational work suggests a common standard deviation $\\sigma = 1.5$ units for the endpoint. The design is a two-arm parallel trial with equal allocation. Assume the expected true mean difference between the novel compound and the SOC is $\\delta = 0$ and that the sampling distribution of the difference in arm means is well-approximated by a Gaussian model. The test is one-sided with type I error level $\\alpha = 0.025$ and desired power $1 - \\beta = 0.90$ to conclude noninferiority.\n\nStarting from first principles, namely the definition of the noninferiority hypothesis for a difference in means, the Gaussian approximation for the sampling distribution of the difference under equal allocation, and the critical value characterization of a one-sided test, derive the sample size requirement for each arm to achieve the stated operating characteristics. Compute the minimum per-arm sample size that satisfies the requirement. Report the smallest integer per arm that achieves at least the target power.\n\nThen, based on the same first-principles framework, explain how analyzing the trial by Intention-To-Treat (ITT) versus Per-Protocol (PP) affects the quantity that governs power in a noninferiority test. Your explanation should explicitly connect how protocol deviations and treatment nonadherence alter the numerator and denominator of the standardized test statistic that determines power, and should interpret the implications for the use of active comparators in translational medicine where placebo controls are impractical or unethical.\n\nNo units are required for the sample size. If any intermediate numerical approximations are needed, retain at least four significant figures in the calculations; however, the final sample size must be an exact integer per arm.",
            "solution": "The problem presents two distinct tasks: first, to derive and compute the required sample size for a noninferiority trial under specific operating characteristics; second, to explain the differential impact of Intention-To-Treat (ITT) and Per-Protocol (PP) analysis populations on the validity of a noninferiority conclusion.\n\n### Part 1: Sample Size Calculation\n\nWe begin by establishing the statistical framework from first principles.\n\n**1. Hypotheses and Test Setup**\nLet $\\mu_T$ be the true mean clinical endpoint for the novel test compound and $\\mu_C$ be the true mean for the standard of care (SOC) active comparator. A lower value of the endpoint is considered better. The objective is to show that the novel compound is not unacceptably worse than the SOC. The noninferiority margin, $\\Delta_{NI} > 0$, defines the largest clinically acceptable difference by which the new compound can be worse than the SOC.\n\nThe hypotheses for a one-sided noninferiority test are:\n- Null Hypothesis ($H_0$): The new compound is inferior to the SOC. This means the mean for the test compound exceeds the mean for the comparator by at least the noninferiority margin.\n$$H_0: \\mu_T - \\mu_C \\ge \\Delta_{NI}$$\n- Alternative Hypothesis ($H_A$): The new compound is non-inferior to the SOC.\n$$H_A: \\mu_T - \\mu_C < \\Delta_{NI}$$\n\nWe reject $H_0$ in favor of $H_A$ if the evidence suggests the true difference is smaller than $\\Delta_{NI}$.\n\n**2. Test Statistic and Sampling Distribution**\nLet $\\bar{X}_T$ and $\\bar{X}_C$ be the sample means from the two arms, each with sample size $n$ due to equal allocation. The estimator for the difference in means is $\\hat{\\delta} = \\bar{X}_T - \\bar{X}_C$. Based on the problem statement, the sampling distribution of this estimator is well-approximated by a Gaussian distribution.\n\nThe mean of the sampling distribution is $E[\\hat{\\delta}] = \\mu_T - \\mu_C$.\nThe variance is $\\text{Var}(\\hat{\\delta}) = \\text{Var}(\\bar{X}_T) + \\text{Var}(\\bar{X}_C) = \\frac{\\sigma^2}{n} + \\frac{\\sigma^2}{n} = \\frac{2\\sigma^2}{n}$.\nThe standard error of the difference is $SE(\\hat{\\delta}) = \\sigma\\sqrt{\\frac{2}{n}}$.\n\n**3. Derivation of the Rejection Rule (Type I Error Control)**\nThe Type I error is the probability of incorrectly rejecting $H_0$ when it is true. We control this probability at level $\\alpha$. The condition for rejecting $H_0$ is based on the upper confidence bound for the difference $\\mu_T - \\mu_C$. Equivalently, we define a critical value $C$ for the observed difference $\\hat{\\delta}$ such that we reject $H_0$ if $\\hat{\\delta}  C$.\n\nTo control the Type I error at $\\alpha$, we consider the \"worst-case\" scenario under $H_0$, which is the boundary condition $\\mu_T - \\mu_C = \\Delta_{NI}$. Under this condition, the sampling distribution is $\\hat{\\delta} \\sim \\mathcal{N}(\\Delta_{NI}, \\frac{2\\sigma^2}{n})$.\n\nThe probability of a Type I error is:\n$$P(\\text{Reject } H_0 | \\mu_T - \\mu_C = \\Delta_{NI}) = P(\\hat{\\delta}  C | \\mu_T - \\mu_C = \\Delta_{NI}) = \\alpha$$\nStandardizing the variable $\\hat{\\delta}$, we get:\n$$P\\left( \\frac{\\hat{\\delta} - \\Delta_{NI}}{\\sigma\\sqrt{\\frac{2}{n}}}  \\frac{C - \\Delta_{NI}}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) = \\alpha$$\nThe term on the left is a standard normal variable, $Z \\sim \\mathcal{N}(0, 1)$. Let $z_\\alpha$ be the upper $\\alpha$-quantile of the standard normal distribution, i.e., $P(Z > z_\\alpha) = \\alpha$. Then $P(Z  -z_\\alpha) = \\alpha$. Thus, we have:\n$$\\frac{C - \\Delta_{NI}}{\\sigma\\sqrt{\\frac{2}{n}}} = -z_\\alpha$$\nThis defines the critical value $C$ for the rejection rule:\n$$C = \\Delta_{NI} - z_\\alpha \\sigma \\sqrt{\\frac{2}{n}}$$\n\n**4. Derivation of the Power Requirement (Type II Error Control)**\nPower ($1-\\beta$) is the probability of correctly rejecting $H_0$ when $H_A$ is true. This probability is calculated under a specific assumption for the true difference, given as $\\delta = \\mu_T - \\mu_C = 0$. Under this assumption, the sampling distribution is $\\hat{\\delta} \\sim \\mathcal{N}(\\delta, \\frac{2\\sigma^2}{n})$.\n\nThe power is given by:\n$$\\text{Power} = P(\\text{Reject } H_0 | \\mu_T - \\mu_C = \\delta) = P(\\hat{\\delta}  C | \\mu_T - \\mu_C = \\delta) = 1-\\beta$$\nStandardizing $\\hat{\\delta}$ under this alternative hypothesis:\n$$P\\left( \\frac{\\hat{\\delta} - \\delta}{\\sigma\\sqrt{\\frac{2}{n}}}  \\frac{C - \\delta}{\\sigma\\sqrt{\\frac{2}{n}}} \\right) = 1-\\beta$$\nLet $z_\\beta$ be the upper $\\beta$-quantile of the standard normal distribution, i.e., $P(Z > z_\\beta) = \\beta$. Then $P(Z  z_\\beta) = 1-\\beta$. Therefore:\n$$\\frac{C - \\delta}{\\sigma\\sqrt{\\frac{2}{n}}} = z_\\beta$$\nThis gives a second expression for the critical value $C$:\n$$C = \\delta + z_\\beta \\sigma \\sqrt{\\frac{2}{n}}$$\n\n**5. Solving for Sample Size, n**\nBy equating the two expressions for the critical value $C$, we can solve for the sample size $n$:\n$$\\Delta_{NI} - z_\\alpha \\sigma \\sqrt{\\frac{2}{n}} = \\delta + z_\\beta \\sigma \\sqrt{\\frac{2}{n}}$$\nRearranging the terms to isolate $n$:\n$$\\Delta_{NI} - \\delta = (z_\\alpha + z_\\beta) \\sigma \\sqrt{\\frac{2}{n}}$$\n$$\\sqrt{n} = \\frac{(z_\\alpha + z_\\beta) \\sigma \\sqrt{2}}{\\Delta_{NI} - \\delta}$$\nSquaring both sides gives the formula for the per-arm sample size:\n$$n = \\frac{2\\sigma^2 (z_\\alpha + z_\\beta)^2}{(\\Delta_{NI} - \\delta)^2}$$\n\n**6. Computation**\nWe substitute the given values into the derived formula:\n- Noninferiority margin: $\\Delta_{NI} = 0.5$\n- Standard deviation: $\\sigma = 1.5$\n- Assumed true difference: $\\delta = 0$\n- Type I error: $\\alpha = 0.025$. The corresponding critical value is $z_{0.025} = 1.95996... \\approx 1.96$.\n- Power: $1-\\beta = 0.90$, so Type II error is $\\beta = 0.10$. The corresponding critical value is $z_{0.10} = 1.28155... \\approx 1.2816$.\n\nSubstituting these values:\n$$n = \\frac{2(1.5)^2 (1.95996 + 1.28155)^2}{(0.5 - 0)^2}$$\n$$n = \\frac{2(2.25) (3.24151)^2}{(0.5)^2}$$\n$$n = \\frac{4.5 \\times 10.507387}{0.25}$$\n$$n = 18 \\times 10.507387$$\n$$n \\approx 189.133$$\nSince the sample size must be an integer and must achieve at least the target power of $0.90$, we must round up to the next whole number.\n$$n = 190$$\nThe minimum required sample size for each arm is $190$.\n\n### Part 2: Intention-To-Treat (ITT) vs. Per-Protocol (PP) Analysis\n\nThe framework for assessing power relies on a standardized test statistic. For a noninferiority test, power is driven by the non-centrality parameter of the test statistic's distribution under the alternative hypothesis. Let's analyze the quantity that governs power, which is effectively a signal-to-noise ratio for noninferiority.\n\nPower is a monotonically increasing function of the term $\\frac{\\Delta_{NI} - \\delta}{SE(\\hat{\\delta})}$, where $\\delta = \\mu_T - \\mu_C$ is the true effect and $SE(\\hat{\\delta})$ is the standard error of the estimated effect. We analyze how ITT and PP analyses affect the numerator, $\\Delta_{NI} - \\hat{\\delta}$, and the denominator, $SE(\\hat{\\delta})$.\n\n**Intention-To-Treat (ITT) Analysis:**\nThe ITT principle dictates that all randomized subjects are analyzed in the group to which they were assigned, regardless of nonadherence to the protocol, treatment discontinuation, or other deviations.\n- **Effect on the Numerator ($\\Delta_{NI} - \\hat{\\delta}$):** Protocol deviations and nonadherence (e.g., subjects in the test arm taking the comparator, or subjects in either arm ceasing treatment) generally dilute the true pharmacological effects of the treatments. This causes the outcomes in the two arms to become more similar. Consequently, the observed difference in means, $\\hat{\\delta}_{ITT} = \\bar{X}_{T, ITT} - \\bar{X}_{C, ITT}$, is biased toward the null hypothesis of no difference, i.e., toward $0$. If the true effect is $\\delta$, the ITT estimate $\\hat{\\delta}_{ITT}$ will be attenuated such that $|\\hat{\\delta}_{ITT}|  |\\delta|$. In the context of a noninferiority test where we aim to show $\\mu_T - \\mu_C  \\Delta_{NI}$, this bias toward zero is anti-conservative. It makes it easier to declare noninferiority, as the observed difference is artificially closer to zero, and thus further from the inferiority boundary $\\Delta_{NI}$. This inflates the probability of a Type I error – a false claim of noninferiority.\n- **Effect on the Denominator ($SE(\\hat{\\delta})$):** In an ITT analysis, the sample size $n$ is the total number of randomized subjects, which maximizes the denominator of the standard error formula ($SE \\propto 1/\\sqrt{n}$). However, the heterogeneity introduced by nonadherence and varied responses can increase the observed variance $\\sigma^2_{obs}$, which would increase the standard error. The dominant concern, however, remains the bias in the numerator.\n\n**Per-Protocol (PP) Analysis:**\nThe PP analysis includes only subjects who sufficiently adhered to the protocol, received the intended treatment for a minimum duration, and have valid outcome measurements.\n- **Effect on the Numerator ($\\Delta_{NI} - \\hat{\\delta}$):** By excluding non-adherent subjects, the PP analysis provides a less biased estimate of the true physiological effect of the treatment as intended. The estimated difference, $\\hat{\\delta}_{PP}$, is a better reflection of the true difference $\\delta$ in a compliant population. This approach is conservative for noninferiority because it does not benefit from the artificial dilution of effect seen in ITT analysis. It assesses the drug's performance under ideal conditions, which is essential for ensuring it is genuinely not inferior.\n- **Effect on the Denominator ($SE(\\hat{\\delta})$):** The PP sample size ($n_{PP}$) is, by definition, smaller than or equal to the ITT sample size ($n_{ITT}$). This reduction in $n$ increases the standard error ($SE \\propto 1/\\sqrt{n_{PP}}$), which reduces statistical power and makes it harder to demonstrate noninferiority. While the variance $\\sigma^2_{PP}$ in the more homogeneous PP population might be smaller, the loss of sample size is often the more significant factor.\n\n**Implications for Translational Medicine:**\nIn translational research, when a placebo is ethically unacceptable, an active comparator noninferiority trial is a common pathway to establish the value of a new compound. The primary risk in such a trial is falsely concluding that an inferior drug is non-inferior.\n\nThe ITT analysis, while standard for preserving the benefits of randomization in superiority trials, poses a significant danger in noninferiority trials. Poor trial conduct (leading to high rates of non-adherence) can make a genuinely inferior drug appear non-inferior by biasing the effect estimate towards zero. This is a critical failure mode, as it could lead to the approval and use of an ineffective or substandard treatment.\n\nTherefore, for noninferiority trials, regulatory bodies and scientific consensus require evaluation of both ITT and PP populations. The PP analysis serves as a crucial sensitivity analysis. A conclusion of noninferiority is considered robust only if it holds in both the ITT and PP datasets. If a drug appears non-inferior in the ITT analysis but fails to do so in the PP analysis, it strongly suggests that the finding was an artifact of trial sloppiness and protocol deviations, not a true property of the compound. For translational science, which bridges the gap from bench to bedside, this dual-analysis requirement is a critical safeguard to ensure that only genuinely effective and safe new therapies advance.",
            "answer": "$$\n\\boxed{190}\n$$"
        },
        {
            "introduction": "Real-world clinical trials are often complicated by \"intercurrent events\"—events occurring after randomization that can affect the interpretation of the results, such as the use of rescue medication by participants. This practice  introduces the modern \"estimand\" framework, which forces clarity about the scientific question a trial is designed to answer. By modeling the impact of rescue medication, you will learn to quantify the resulting bias and distinguish between the ideal, hypothetical effect of a drug and the effect observed under a real-world treatment policy.",
            "id": "5074680",
            "problem": "A randomized, double-blind, parallel-group, 12-week trial in inflammatory disease compares an investigational anti-inflammatory agent to placebo. The primary endpoint is the change from baseline in C-reactive protein (CRP) at week $12$, expressed in mg/L. A standard-of-care corticosteroid is permitted as rescue medication starting at week $6$ for inadequate responders. In translational medicine analysis, you are asked to compare two estimands: (i) the hypothetical estimand under no rescue (the de jure effect), defined as the difference in expected week-$12$ CRP change between investigational treatment and placebo if no participant were rescued, and (ii) the treatment-policy estimand with rescue allowed, defined as the difference in the observed week-$12$ CRP change between investigational treatment and placebo as implemented in the trial.\n\nAssume the following, all of which are standard in mixture-model sensitivity analyses:\n- The mean change from baseline at week $12$ if a participant were to receive the investigational treatment for the full $12$ weeks is $\\mu_{T}$ (in mg/L).\n- The mean change from baseline at week $12$ if a participant were to receive placebo for the full $12$ weeks is $\\mu_{P}$ (in mg/L).\n- The mean change from baseline at week $12$ if a participant were to receive the rescue corticosteroid for the full $12$ weeks is $\\mu_{R}$ (in mg/L).\n- In the trial, a participant randomized to arm $A \\in \\{T,P\\}$ is rescued with probability $p_{A}$ by week $6$. Model the observed week-$12$ outcomes in each arm as a two-component mixture between the arm’s no-rescue potential outcome and the rescue medication’s potential outcome, with mixture weights given by the arm-specific rescue probabilities.\n- You may assume independence of potential outcomes from rescue assignment beyond the specified mixture assumption and that there is no missing data.\n\nStarting from the definitions of expectation and the mixture model described above (do not invoke any pre-derived bias formulas), perform the following:\n1. Derive an expression for the observed between-arm mean difference at week $12$ under the treatment-policy strategy (rescue allowed), in terms of $\\mu_{T}$, $\\mu_{P}$, $\\mu_{R}$, $p_{T}$, and $p_{P}$.\n2. Define the bias as the difference between this observed mean difference and the de jure estimand $\\mu_{T}-\\mu_{P}$. Derive a simplified algebraic expression for the bias.\n3. Using the parameter values $\\mu_{T} = -7.2$, $\\mu_{P} = -1.5$, $\\mu_{R} = -9.1$ (all in mg/L), $p_{T} = 0.18$, and $p_{P} = 0.55$, compute the numerical value of the bias. Round your answer to four significant figures and express the final bias in mg/L.",
            "solution": "The problem statement is a well-posed exercise in statistical modeling, specifically concerning the analysis of clinical trial data in the presence of intercurrent events (use of rescue medication). It is scientifically grounded in the principles of estimands and sensitivity analysis used in translational medicine and biostatistics. The problem provides a clear, self-contained set of definitions, assumptions, and data, and asks for a logical derivation and subsequent calculation. All conditions for a valid problem are met.\n\nLet $A$ denote the treatment arm, where $A \\in \\{T, P\\}$ for the investigational treatment and placebo, respectively. Let $Y_{obs, A}$ be the random variable representing the observed change from baseline in C-reactive protein (CRP) at week $12$ for a participant randomized to arm $A$. The problem provides the following parameters:\n- $\\mu_{T}$: The mean change from baseline at week $12$ under full adherence to the investigational treatment.\n- $\\mu_{P}$: The mean change from baseline at week $12$ under full adherence to the placebo.\n- $\\mu_{R}$: The mean change from baseline at week $12$ under full adherence to the rescue corticosteroid.\n- $p_{T}$: The probability of a participant in the treatment arm being rescued.\n- $p_{P}$: The probability of a participant in the placebo arm being rescued.\n\nThe problem states that the observed week-$12$ outcome in each arm is to be modeled as a two-component mixture. For a participant in arm $A$, their outcome is considered to be drawn from a distribution with mean $\\mu_A$ if they are not rescued (with probability $1-p_A$) and from a distribution with mean $\\mu_R$ if they are rescued (with probability $p_A$).\n\n1.  Derivation of the observed between-arm mean difference (treatment-policy estimand).\n\nThe expected observed outcome in the investigational treatment arm, $E[Y_{obs, T}]$, can be calculated using the law of total expectation, based on the provided mixture model:\n$$E[Y_{obs, T}] = (1-p_T) \\cdot \\mu_T + p_T \\cdot \\mu_R$$\nThis equation states that the overall expected outcome is a weighted average of the expected outcome without rescue, $\\mu_T$, and the expected outcome with rescue, $\\mu_R$, weighted by their respective probabilities.\n\nSimilarly, the expected observed outcome in the placebo arm, $E[Y_{obs, P}]$, is:\n$$E[Y_{obs, P}] = (1-p_P) \\cdot \\mu_P + p_P \\cdot \\mu_R$$\n\nThe treatment-policy estimand is defined as the difference in these observed expected outcomes. Let's denote this estimand by $\\Delta_{TP}$:\n$$\\Delta_{TP} = E[Y_{obs, T}] - E[Y_{obs, P}]$$\nSubstituting the expressions for the expected values:\n$$\\Delta_{TP} = \\left[ (1-p_T)\\mu_T + p_T\\mu_R \\right] - \\left[ (1-p_P)\\mu_P + p_P\\mu_R \\right]$$\nThis is the expression for the observed between-arm mean difference under the treatment-policy strategy.\n\n2.  Derivation of the bias.\n\nThe de jure estimand, which represents the hypothetical effect if no participant were rescued, is given as $\\Delta_{DJ} = \\mu_T - \\mu_P$.\nThe bias is defined as the difference between the treatment-policy estimand and the de jure estimand:\n$$\\text{Bias} = \\Delta_{TP} - \\Delta_{DJ}$$\nSubstituting the expressions for $\\Delta_{TP}$ and $\\Delta_{DJ}$:\n$$\\text{Bias} = \\left( \\left[ (1-p_T)\\mu_T + p_T\\mu_R \\right] - \\left[ (1-p_P)\\mu_P + p_P\\mu_R \\right] \\right) - (\\mu_T - \\mu_P)$$\nWe can expand the terms and simplify:\n$$\\text{Bias} = (\\mu_T - p_T\\mu_T + p_T\\mu_R) - (\\mu_P - p_P\\mu_P + p_P\\mu_R) - \\mu_T + \\mu_P$$\nNow, we collect like-terms. The $\\mu_T$ and $-\\mu_T$ terms cancel, and the $-\\mu_P$ and $+\\mu_P$ terms cancel.\n$$\\text{Bias} = -p_T\\mu_T + p_T\\mu_R + p_P\\mu_P - p_P\\mu_R$$\nTo obtain a more interpretable form, we can group terms by $p_T$ and $p_P$:\n$$\\text{Bias} = p_T(\\mu_R - \\mu_T) + p_P(\\mu_P - \\mu_R)$$\nThis can be rewritten to highlight the effect of the rescue medication relative to the assigned treatment in each arm:\n$$\\text{Bias} = p_T(\\mu_R - \\mu_T) - p_P(\\mu_R - \\mu_P)$$\nThis is the simplified algebraic expression for the bias. It represents the sum of two components: the bias introduced in the treatment arm, $p_T(\\mu_R - \\mu_T)$, and the bias introduced in the placebo arm, $-p_P(\\mu_R - \\mu_P)$.\n\n3.  Computation of the numerical value of the bias.\n\nThe problem provides the following parameter values:\n- $\\mu_{T} = -7.2$ mg/L\n- $\\mu_{P} = -1.5$ mg/L\n- $\\mu_{R} = -9.1$ mg/L\n- $p_{T} = 0.18$\n- $p_{P} = 0.55$\n\nWe substitute these values into our derived expression for the bias:\n$$\\text{Bias} = p_T(\\mu_R - \\mu_T) - p_P(\\mu_R - \\mu_P)$$\nFirst, calculate the differences in the means:\n$$\\mu_R - \\mu_T = -9.1 - (-7.2) = -9.1 + 7.2 = -1.9$$\n$$\\mu_R - \\mu_P = -9.1 - (-1.5) = -9.1 + 1.5 = -7.6$$\nNow substitute these intermediate results and the probabilities into the bias equation:\n$$\\text{Bias} = (0.18)(-1.9) - (0.55)(-7.6)$$\nPerform the multiplications:\n$$(0.18)(-1.9) = -0.342$$\n$$(0.55)(-7.6) = -4.18$$\nFinally, compute the bias:\n$$\\text{Bias} = -0.342 - (-4.18) = -0.342 + 4.18 = 3.838$$\nThe result $3.838$ has four significant figures, as required. The units are mg/L. A positive bias indicates that the observed treatment effect (treatment-policy estimand) is larger (more positive or less negative) than the de jure treatment effect. In this case, the more frequent use of a highly effective rescue medication in the placebo arm ($p_P > p_T$) compared to the investigational arm masks the true difference between the two, biasing the result.",
            "answer": "$$\\boxed{3.838}$$"
        }
    ]
}