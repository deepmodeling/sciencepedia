{
    "hands_on_practices": [
        {
            "introduction": "在生物医学研究中，严谨的研究设计是因果推断的基石。有向无环图（DAGs）为我们提供了一种强大的可视化语言，用以明确表达关于变量间因果关系的假设。本练习将引导你应用d-分离和后门准则，以识别和处理混杂路径，同时警惕因调整不当（如对撞因子或中介变量）而引入偏倚的常见陷阱 。",
            "id": "5001872",
            "problem": "一项转化医学领域的观察性队列研究评估了一种抗炎疗法 $A$ 对六个月功能性结局 $Y$ 的总因果效应。基线协变量 $L$ 总结了治疗前的疾病严重程度和合并症，中间生物标志物 $M$ 是在治疗一个月时测量的对治疗有反应的炎症标志物，而 $U$ 代表一种未测量的、在分子水平上影响生物学的促炎倾向。其因果结构由一个有向无环图（DAG）表示，该图包含以下有向边：$L \\rightarrow A$、$L \\rightarrow Y$、$A \\rightarrow M \\rightarrow Y$ 以及 $U \\rightarrow M$、$U \\rightarrow Y$。图中没有其他箭头。假设 $U$ 未被测量，且科学目标是从观察数据中识别 $A$ 对 $Y$ 的总因果效应。\n\n根据 $d$-分离和后门准则的定义，判断在估计 $A$ 对 $Y$ 的总因果效应时，同时对 $L$ 和 $M$ 进行条件化是否足以控制混杂。选择唯一的最佳答案。\n\nA. 是的。对 $\\{L, M\\}$ 进行调整会阻断所有从 $A$ 到 $Y$ 的后门路径，因此足以估计总效应。\n\nB. 不是。对 $M$ 进行条件化会通过 $U$ 打开一条对撞路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，从而引入偏倚；单独使用 $\\{L\\}$ 就足以估计总效应。\n\nC. 是的。对中介变量 $M$ 进行调整会移除中介路径，从而分离出一个直接效应，在该图中这个直接效应等于总效应。\n\nD. 不是。因为 $U$ 混杂了 $M$ 和 $Y$，所以 $A \\rightarrow Y$ 关系存在不可避免的混杂，并且在不测量 $U$ 的情况下，无法根据此DAG从观察数据中识别出总效应。",
            "solution": "问题询问在估计治疗 $A$ 对结局 $Y$ 的总因果效应时，对协变量集 $\\{L, M\\}$ 进行条件化是否足以控制混杂。因果关系由一个有向无环图（DAG）描述，其边如下：$L \\rightarrow A$、$L \\rightarrow Y$、$A \\rightarrow M$、$M \\rightarrow Y$、$U \\rightarrow M$ 和 $U \\rightarrow Y$。变量 $U$ 未被测量。\n\n为了识别 $A$ 对 $Y$ 的总因果效应，我们必须找到一个满足后门准则的协变量集 $Z$。相对于 $(A, Y)$，如果一个集合 $Z$ 满足以下两个条件，则它满足后门准则：\n1.  $Z$ 中没有变量是 $A$ 的后代。\n2.  $Z$ 中的变量阻断了 $A$ 和 $Y$ 之间每一条包含指向 $A$ 的箭头（即“后门路径”）的路径。\n\n如果存在这样的集合 $Z$，则总因果效应可以通过调整公式从观察数据中识别：\n$$ P(Y|do(A=a)) = \\sum_{z} P(Y|A=a, Z=z)P(Z=z) $$\n\n让我们首先识别给定DAG中 $A$ 和 $Y$ 之间的所有路径。\n- **路径1（因果路径）：** $A \\rightarrow M \\rightarrow Y$。这是一条从 $A$ 到 $Y$ 的有向路径，代表了由生物标志物 $M$ 中介的 $A$ 对 $Y$ 的因果效应。总因果效应必须包括通过此路径传递的效应。\n\n- **路径2（后门路径）：** $A \\leftarrow L \\rightarrow Y$。这条路径是一条非因果的“后门路径”，因为它包含一个指向 $A$ 的箭头。变量 $L$ 是 $A$ 和 $Y$ 的共同原因，因此充当混杂因素。\n\n- **路径3（非因果路径）：** $A \\rightarrow M \\leftarrow U \\rightarrow Y$。这条路径连接了 $A$ 和 $Y$，但不是从 $A$ 到 $Y$ 的有向因果路径。此路径上的变量 $M$ 是一个“对撞点”，因为它有两个指向它的箭头（$A \\rightarrow M$ 和 $U \\rightarrow M$）。根据 $d$-分离的规则，包含对撞点的路径默认是阻塞的（即，除非对该对撞点或其后代进行条件化）。\n\n现在，让我们确定用于总因果效应的正确调整集。为了满足后门准则，我们必须阻断路径2（$A \\leftarrow L \\rightarrow Y$），同时不对 $A$ 的任何后代进行条件化。\n- 集合 $Z = \\{L\\}$ 满足这些条件。对 $L$ 进行条件化会阻断路径 $A \\leftarrow L \\rightarrow Y$。此外，$L$ 不是 $A$ 的后代。因此，$\\{L\\}$ 是一个足以识别 $A$ 对 $Y$ 的总因果效应的调整集。\n\n问题询问集合 $\\{L, M\\}$ 是否是一个充分的调整集。让我们根据后门准则的两个条件来评估这个集合。\n1.  **$\\{L, M\\}$ 中是否有任何变量是 $A$ 的后代？** 是的。在DAG中，存在一条路径 $A \\rightarrow M$。这意味着 $M$ 是 $A$ 的后代。因此，集合 $\\{L, M\\}$ 违反了后门准则的第一个条件。对因果路径上的变量（如中介变量 $M$）进行调整将阻断该路径，从而得到直接效应的估计，而不是总效应。\n\n2.  **对 $\\{L, M\\}$ 进行条件化是否会引入偏倚？** 是的。考虑路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$。如前所述，$M$ 是此路径上的一个对撞点，因此该路径天然是阻塞的。然而，通过对对撞点 $M$ 进行条件化，我们*打开*了这条路径。这通过 $M$ 和 $Y$ 的未测量共同原因 $U$ 在 $A$ 和 $Y$ 之间产生了一个非因果关联。这种现象被称为对撞分层偏倚（collider-stratification bias）。因此，对 $M$ 进行调整会引入一个新的偏倚源。\n\n总之，对 $\\{L, M\\}$ 进行条件化是错误的，主要有两个原因：\n- 它包含一个中介变量（$M$），这会阻断部分我们感兴趣的因果效应，从而无法估计总效应。\n- 它包含路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$ 上的一个对撞点（$M$），这会打开该路径，并由于未测量的变量 $U$ 而引入偏倚。\n\n估计总因果效应的正确程序是仅对 $\\{L\\}$ 进行调整。\n\n让我们基于此分析评估所提供的选项。\n\n**A. 是的。对 $\\{L, M\\}$ 进行调整会阻断所有从 $A$ 到 $Y$ 的后门路径，因此足以估计总效应。**\n这个说法是不正确的。虽然对 $\\{L, M\\}$ 进行条件化确实阻断了后门路径 $A \\leftarrow L \\rightarrow Y$，但它未能满足估计总效应的条件。首先，$M$ 是 $A$ 的后代，违反了后门准则。其次，对 $M$ 进行条件化会通过对撞点 $M$ 打开一条新的偏倚路径。因此，这种调整不足以估计总效应。**不正确**。\n\n**B. 不是。对 $M$ 进行条件化会通过 $U$ 打开一条对撞路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，从而引入偏倚；单独使用 $\\{L\\}$ 就足以估计总效应。**\n这个说法正确地指出了两个关键问题。它正确地指出，对对撞点 $M$ 进行条件化会打开路径 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，通过未测量的混杂因素 $U$ 引入偏倚。它还正确地指出，仅对 $\\{L\\}$ 进行调整就足以识别总效应，因为 $\\{L\\}$ 满足后门准则。**正确**。\n\n**C. 是的。对中介变量 $M$ 进行调整会移除中介路径，从而分离出一个直接效应，在该图中这个直接效应等于总效应。**\n这个说法是不正确的。对中介变量 $M$ 进行调整确实会移除中介路径 $A \\rightarrow M \\rightarrow Y$，并有助于分离出直接效应。然而，总效应是直接效应和间接（中介）效应之和。由于该图中存在一条中介路径，因此直接效应不等于总效应。目标是估计总效应，因此移除中介成分与目标相悖。**不正确**。\n\n**D. 不是。因为 $U$ 混杂了 $M$ 和 $Y$，所以 $A \\rightarrow Y$ 关系存在不可避免的混杂，并且在不测量 $U$ 的情况下，无法根据此DAG从观察数据中识别出总效应。**\n这个说法是不正确的。虽然 $U$ 确实混杂了 $M$ 和 $Y$ 之间的关系，但它并没有为 $A$ 对 $Y$ 的总效应造成混杂。涉及 $U$ 的路径是 $A \\rightarrow M \\leftarrow U \\rightarrow Y$，该路径被对撞点 $M$ 阻断。只要我们不对 $M$ 进行条件化，这条路径就保持阻塞状态，$U$ 也不会混杂 $A \\rightarrow Y$ 的关系。如前所述，仅通过对 $\\{L\\}$ 进行调整，总效应是可识别的。**不正确**。",
            "answer": "$$\\boxed{B}$$"
        },
        {
            "introduction": "在通过DAGs识别出需要调整的混杂因素后，下一步便是如何在分析中实际执行这种调整。稳定化处理概率倒数加权（stabilized IPTW）是一种核心方法，它通过构建一个“伪人群”来平衡协变量分布，从而模拟随机试验。本练习是一个真正的计算实践，不仅要求你从第一性原理推导权重公式，还要通过编程实现并评估权重分布的诊断指标，这对于确保分析结果的稳健性至关重要 。",
            "id": "5001916",
            "problem": "您将处理一个转化医学背景下的因果推断任务。考虑一个目标试验模拟，其中每个受试者 $i \\in \\{1,\\dots,N\\}$ 都有一个估计的倾向性得分 $e_i$，该得分定义为在给定已测量协变量的情况下接受治疗 $A=1$ 的估计概率。二元治疗由 $A \\in \\{0,1\\}$ 表示，受试者 $i$ 的观察治疗为 $A_i$。已知治疗的边际概率为 $P(A=1)=p$，其中 $p$ 是指定的。您的目标是根据概率论和因果推断的基本原理，推导、实现并评估稳定化逆概率治疗加权。\n\n您的推导应基于以下基本定义和事实，不使用任何预先提供的特定于加权公式的结果：\n- 生物医学因果推断的潜在结果框架：每个受试者都有潜在结果 $\\{Y^0,Y^1\\}$，在一致性假设下，观察结果为 $Y=Y^A$。\n- 可交换性（条件可忽略性）：在给定已测量协变量 $X$ 的条件下，治疗分配 $A$ 是“近似”随机的，因此 $\\{Y^0,Y^1\\} \\perp\\!\\!\\!\\perp A \\mid X$。\n- 正性：对于所有具有正密度的协变量模式，$0  P(A=1 \\mid X)  1$。\n- 全概率定律、迭代期望定律，以及用于构建重加权以恢复目标边际分布的概率测度之间的拉东-尼科迪姆导数定义。\n- 通过一个边际因子进行稳定化，以控制方差膨胀，同时保留目标边际治疗分布。\n\n基于这些原则，推导如何构建一个受试者水平的稳定化权重，该权重使用边际治疗概率与条件治疗概率之比，使得重加权后的数据近似于一个伪人群，在该伪人群中治疗与已测量的协变量无关。然后按照下文所述，实现计算和诊断。\n\n计算规格：\n- 对于每个测试用例，从参数为 $(\\alpha,\\beta)$ 的Beta分布中独立生成 $N$ 个受试者，其个体估计倾向性得分为 $\\{e_i\\}_{i=1}^N$，使得Beta均值等于 $\\alpha/(\\alpha+\\beta)=0.4$。对每个受试者 $i$，从成功概率为 $e_i$ 的伯努利分布中模拟观察治疗 $A_i$。在任何需要边际治疗概率的地方，使用已知的边际治疗概率 $p=0.4$。\n- 对每个受试者 $i$，使用您推导出的仅依赖于 $p$、$A_i$ 和 $e_i$ 的表达式，计算稳定化逆概率治疗权重。\n- 极端权重诊断：计算以下权重分布的摘要统计量，以评估对正性假设的潜在违反和方差膨胀。\n  1. 权重的均值（一个浮点数）。\n  2. 权重的方差，使用除数为 $N$ 的总体方差（一个浮点数）。\n  3. 权重的 $0.99$ 分位数（一个浮点数）。\n  4. 严格大于阈值 $T$ 的权重比例，表示为 $[0,1]$ 区间内的小数而非百分比（一个浮点数）。\n  5. 有效样本量 $\\mathrm{ESS} = \\left(\\sum_{i=1}^N w_i\\right)^2 \\big/ \\left(\\sum_{i=1}^N w_i^2\\right)$（一个浮点数）。\n  6. 变异系数 $\\mathrm{CV} = \\mathrm{sd}(w)/\\mathrm{mean}(w)$，使用总体标准差（一个浮点数）。\n  7. 一个极端权重标志，定义为 $\\{0,1\\}$ 中的整数，如果以下任一条件成立则为 $1$，否则为 $0$：$0.99$ 分位数至少为 $10$，或高于 $T$ 的比例至少为 $0.01$，或 $\\mathrm{ESS} \\leq 0.5 N$。\n- 所有用例均使用 $N=1000$ 和 $p=0.4$。对于高于阈值比例的诊断，使用阈值 $T=10$。\n\n测试套件：\n- 用例 1（理想情况，中等离散度）：$(\\alpha,\\beta)=(4,6)$，随机种子为 $20231101$。\n- 用例 2（边缘情况，接近边界的极端离散度）：$(\\alpha,\\beta)=(0.2,0.3)$，随机种子为 $20231102$。\n- 用例 3（低方差情况，集中在均值附近）：$(\\alpha,\\beta)=(40,60)$，随机种子为 $20231103$。\n\n算法要求：\n- 对每个用例使用按指定种子初始化的可复现伪随机数生成器。\n- 对于每个测试用例，按上述顺序生成一个包含恰好 $7$ 个条目的列表：$[\\text{均值},\\text{方差},\\text{q}_{0.99},\\text{大于T的比例},\\mathrm{ESS},\\mathrm{CV},\\text{标志}]$。对于高于阈值的比例，报告一个小数（例如，$0.03$），而不是百分比。对于标志，报告 $1$ 或 $0$。\n- 您的程序应生成单行输出，其中包含所有给定测试用例的结果，格式为一个由三个用例列表组成的逗号分隔列表，并用方括号括起来，不含空格。例如，输出格式必须严格为 $[[r_{11},\\dots,r_{17}],[r_{21},\\dots,r_{27}],[r_{31},\\dots,r_{37}]]$ 的形式，其中每个 $r_{jk}$ 是一个数字，内部列表的顺序与上述测试套件的顺序一致。\n\n角度单位不适用。百分比必须始终表示为小数或分数，不能使用百分号。\n\n本说明中的所有数字字面量，包括 $N$、$p$、$T$、种子和Beta分布参数，都是精确的，必须按给定值使用。最终输出是无单位的实数或整数，如规定所示，不含任何额外文本。程序必须是完整的、自包含的，且不需要任何输入。",
            "solution": "该问题陈述被评估为有效。它在科学上基于成熟的因果推断潜在结果框架，问题设定良好，计算任务清晰，表述客观。所有必要的数据、参数和定义均已提供，使问题成为一个自包含且可解决的问题。\n\n**1. 稳定化逆概率治疗权重的推导**\n\n逆概率治疗加权（IPTW）的目标是通过创建一个伪人群来估计因果效应，在这个伪人群中，治疗分配 $A$ 与已测量的协变量 $X$ 无关。此过程校正了观察性研究中因治疗的非随机分配而引入的混淆偏倚。\n\n设观察人群中治疗 $A$ 和协变量 $X$ 的联合概率分布由测度 $P$ 表示。相应的联合概率密度（或质量）函数为 $p(a, x) = p(a \\mid x) p(x)$。这里，$p(a \\mid x)$ 是在给定协变量 $x$ 的情况下接受治疗 $a$ 的条件概率，$p(x)$ 是协变量的边际概率密度。条件概率 $P(A=1 \\mid X=x)$ 即为倾向性得分，记作 $e(x)$。\n\n目标是一个由测度 $P^*$ 描述的伪人群，其中治疗和协变量在统计上是独立的。在这个目标人群中，联合密度为 $p^*(a, x) = p^*(a) p^*(x)$。为了保留原始研究的边际特征，我们将目标边际分布设置为与观察到的边际分布相等：$p^*(a) = P(A=a)$ 且 $p^*(x) = p(x)$。问题指定治疗的边际概率 $P(A=1)$ 为 $p$。因此，$p^*(a=1) = p$ 且 $p^*(a=0) = 1-p$。\n\n对于一个具有观察治疗 $A_i$ 和协变量 $X_i$ 的受试者，其权重由目标测度 $P^*$ 相对于观察测度 $P$ 的拉东-尼科迪姆导数给出。该导数表示目标世界与观察世界中概率密度的比率：\n$$\nw(a, x) = \\frac{d P^*}{d P}(a, x) = \\frac{p^*(a, x)}{p(a, x)}\n$$\n代入联合密度的表达式：\n$$\nw(a, x) = \\frac{p^*(a) p^*(x)}{p(a \\mid x) p(x)} = \\frac{P(A=a) p(x)}{P(A=a \\mid X=x) p(x)}\n$$\n协变量密度 $p(x)$ 被消去，得到稳定化权重的一般公式：\n$$\nw(a, x) = \\frac{P(A=a)}{P(A=a \\mid X=x)}\n$$\n对于具有观察治疗 $A_i$ 和估计倾向性得分 $e_i = P(A=1 \\mid X_i)$ 的单个受试者 $i$，我们可以将其权重 $w_i$ 写成其观察数据的函数。\n\n如果受试者 $i$ 接受治疗（$A_i=1$）：\n分子是边际概率 $P(A=1) = p$。\n分母是条件概率 $P(A=1 \\mid X_i) = e_i$。\n权重为 $w_i = \\frac{p}{e_i}$。\n\n如果受试者 $i$ 未接受治疗（$A_i=0$）：\n分子是边际概率 $P(A=0) = 1-p$。\n分母是条件概率 $P(A=0 \\mid X_i) = 1 - P(A=1 \\mid X_i) = 1 - e_i$。\n权重为 $w_i = \\frac{1-p}{1-e_i}$。\n\n这两种情况可以合并为受试者 $i$ 的稳定化权重 $w_i$ 的单一表达式：\n$$\nw_i = A_i \\frac{p}{e_i} + (1-A_i) \\frac{1-p}{1-e_i}\n$$\n术语“稳定化”指的是在分子中包含边际概率 $p$ 和 $1-p$。与非稳定化权重（其中分子为 $1$）相比，这些因子会压缩权重，减小其方差，从而缓解加权估计器中的方差膨胀问题。这些权重的一个关键特性是其均值期望为 $1$。\n\n**2. 计算与诊断规格**\n\n指定的任务涉及模拟数据并计算这些权重，然后对权重分布进行分析。\n\n**数据生成：**\n对于三个测试用例中的每一个，我们为 $N=1000$ 个受试者生成数据。\n1.  为保证可复现性，使用指定的种子初始化伪随机数生成器。\n2.  倾向性得分 $\\{e_i\\}_{i=1}^N$ 从Beta分布 $e_i \\sim \\text{Beta}(\\alpha, \\beta)$ 中独立抽取，其中每个用例都提供了参数 $(\\alpha, \\beta)$。\n3.  对于每个受试者 $i$，观察治疗 $A_i \\in \\{0,1\\}$ 从参数为 $e_i$ 的伯努利分布中抽取，即 $A_i \\sim \\text{Bernoulli}(e_i)$。\n\n**权重计算：**\n对于每个受试者 $i$，使用推导的公式计算稳定化权重 $w_i$，其中已知的边际概率 $p=0.4$：\n$$\nw_i = A_i \\frac{0.4}{e_i} + (1-A_i) \\frac{1-0.4}{1-e_i}\n$$\n\n**诊断指标：**\n计算完权重 $\\{w_i\\}_{i=1}^N$ 后，计算以下七个摘要统计量以评估权重分布。较大的权重可能表示对正性假设的实际违反（$e_i$ 或 $1-e_i$ 过于接近 $0$），并可能导致最终效应估计的高方差和不稳定性。\n1.  **权重均值**：$\\bar{w} = \\frac{1}{N} \\sum_{i=1}^N w_i$。此值应接近 $1$。\n2.  **权重方差**：$\\sigma^2_w = \\frac{1}{N} \\sum_{i=1}^N (w_i - \\bar{w})^2$。使用除数为 $N$ 的总体方差。\n3.  **权重 $0.99$ 分位数**：值 $q_{0.99}$，使得 $99\\%$ 的权重小于或等于该值。\n4.  **大于 $T$ 的权重比例**：严格大于阈值 $T=10$ 的权重比例。计算公式为 $\\frac{1}{N}\\sum_{i=1}^N \\mathbb{I}(w_i  10)$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。\n5.  **有效样本量 (ESS)**：衡量因加权导致的精度损失的指标。其公式为 $\\mathrm{ESS} = \\frac{(\\sum_{i=1}^N w_i)^2}{\\sum_{i=1}^N w_i^2}$。相对于 $N$ 而言，较小的 ESS 表示权重方差较大。\n6.  **变异系数 (CV)**：一种标准化的离散度度量，定义为 $\\mathrm{CV} = \\frac{\\sigma_w}{\\bar{w}}$，其中 $\\sigma_w = \\sqrt{\\sigma^2_w}$ 是总体标准差。\n7.  **极端权重标志**：一个整数指示器，如果满足以下三个条件中的任何一个，则设置为 $1$，否则为 $0$：\n    - $0.99$ 分位数至少为 $10$ ($q_{0.99} \\ge 10$)。\n    - 大于 $T=10$ 的权重比例至少为 $0.01$。\n    - 有效样本量小于或等于名义样本量的一半（$\\mathrm{ESS} \\le 0.5N$）。\n\n对三个测试用例中的每一个执行这些步骤，并将所得的七个诊断值在每个用例的列表中报告。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the causal inference problem by deriving and applying stabilized IPTW,\n    and computes the specified diagnostic statistics for three test cases.\n    \"\"\"\n    \n    # Define the problem constants and test cases.\n    # Each case is a tuple of (alpha, beta, seed).\n    test_cases = [\n        (4, 6, 20231101),      # Case 1: Moderate dispersion\n        (0.2, 0.3, 20231102),  # Case 2: Extreme dispersion (U-shaped)\n        (40, 60, 20231103),    # Case 3: Low dispersion (concentrated)\n    ]\n    \n    N = 1000\n    p = 0.4\n    T = 10.0\n    \n    all_results = []\n    \n    for alpha, beta, seed in test_cases:\n        # Initialize the pseudo-random number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # 1. Generate N subjects with propensity scores from a Beta distribution.\n        #    The mean is alpha / (alpha + beta) = 0.4, matching p.\n        e = rng.beta(alpha, beta, size=N)\n        \n        # 2. Simulate observed treatment A_i from a Bernoulli distribution\n        #    with success probability e_i for each subject.\n        A = rng.binomial(1, p=e)\n        \n        # 3. Compute the stabilized inverse probability of treatment weights (SIPTW).\n        #    w_i = A_i * (p / e_i) + (1 - A_i) * ((1 - p) / (1 - e_i))\n        # np.divide with where clause handles potential division by zero,\n        # though Beta(a,b) with a,b > 0 should not produce exact 0 or 1.\n        # This is a robust practice.\n        weights_treated = np.divide(p, e, out=np.zeros_like(e, dtype=float), where=e!=0)\n        weights_control = np.divide(1 - p, 1 - e, out=np.zeros_like(e, dtype=float), where=(1-e)!=0)\n        weights = A * weights_treated + (1 - A) * weights_control\n        \n        # 4. Compute the required diagnostic measures.\n        \n        # 1. Mean of the weights\n        mean_w = np.mean(weights)\n        \n        # 2. Variance of the weights (population variance, divisor N)\n        var_w = np.var(weights, ddof=0)\n        \n        # 3. 0.99 quantile of the weights\n        q99_w = np.quantile(weights, 0.99)\n        \n        # 4. Fraction of weights strictly greater than threshold T\n        frac_gt_T = np.mean(weights > T)\n        \n        # 5. Effective Sample Size (ESS)\n        ess = np.sum(weights)**2 / np.sum(weights**2)\n        \n        # 6. Coefficient of Variation (CV)\n        #    Using population standard deviation (sqrt of population variance)\n        sd_w = np.std(weights, ddof=0)\n        cv_w = sd_w / mean_w if mean_w != 0 else np.inf\n        \n        # 7. Extreme-weight flag\n        ess_threshold = 0.5 * N\n        frac_threshold = 0.01\n        quantile_threshold = 10.0\n        \n        flag = int(\n            (q99_w >= quantile_threshold) or\n            (frac_gt_T >= frac_threshold) or\n            (ess = ess_threshold)\n        )\n        \n        case_results = [\n            mean_w, var_w, q99_w, frac_gt_T, ess, cv_w, flag\n        ]\n        all_results.append(case_results)\n        \n    # Format the final output as specified.\n    # e.g., [[r11,...,r17],[r21,...,r27],[r31,...,r37]]\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, res))}]' for res in all_results])}]\"\n    print(output_str)\n\nsolve()\n```"
        },
        {
            "introduction": "即使我们已经对所有已测量的混杂因素进行了调整，观察性研究的结果仍然可能受到未测量混杂的威胁。E-值作为一种敏感性分析工具，为评估这种潜在偏倚的强度提供了一个量化指标。通过本练习，你将学会计算并解释E-值，从而能够判断一个未测量的混杂因素需要多强才能完全“解释掉”观测到的关联，这是审慎解读观察性研究证据的一项关键技能 。",
            "id": "5001897",
            "problem": "一个转化医学研究团队进行了一项观察性队列研究，评估在慢性肺病患者中启用一种新的抗炎疗法（$E$）是否与降低一年期死亡率（$Y$）相关。在对一组丰富的已测量协变量进行调整后，观察到的无治疗与接受治疗的风险比为 $RR_{\\text{obs}} = 2.0$（因此 $RR_{\\text{obs}}  1$ 表示未治疗组的风险更高）。\n\n由于该研究不是随机对照试验（RCT），团队使用E值（E-value）的概念对未测量的混杂因素进行敏感性分析。在使用有向无环图（DAGs）进行因果推断的标准框架中，设 $U$ 表示一个单一的、二元的、未测量的混杂因素。定义 $RR_{EU}$ 为在已测量协变量的条件下，暴露 $E$ 和混杂因素 $U$ 之间在风险比尺度上的关联；定义 $RR_{UY}$ 为在已测量协变量和 $E$ 的各水平下，混杂因素 $U$ 和结局 $Y$ 之间在风险比尺度上的关联。E值被定义为：在最坏的混杂情况下，未测量的混杂因素与 $E$ 和 $Y$（在已测量协变量的条件下）必须同时具有的最小关联强度（以风险比衡量），才能将真实的因果风险比 $RR$ 降至 $1$。\n\n仅从存在混杂时的风险比基本定义，以及关于风险比尺度上未测量混杂的广为接受的偏倚界限结果出发，推导当 $RR_{\\text{obs}} = 2.0$ 时的E值，并给出E值的精确、闭合形式的解析表达式。将最终答案表示为单个解析表达式；不要近似，也不要包含单位。",
            "solution": "本题要求推导当观察到的风险比 $RR_{\\text{obs}}$ 为 $2.0$ 时的E值。此任务需要从观察到的关联、真实因果效应和混杂偏倚之间的基本关系出发，然后应用敏感性分析中的一个标准结果。\n\n设 $E$ 表示暴露（治疗），$Y$ 表示结局（死亡率），$U$ 表示一个单一的、二元的、未测量的混杂因素。所有的关联都以一组已测量的协变量为条件，为清晰起见，在符号表示中省略了这些协变量。题目提供了一个观察到的风险比 $RR_{\\text{obs}}$，表示无治疗（$E=0$）与接受治疗（$E=1$）对一年期死亡率（$Y=1$）的关联。\n$$ RR_{\\text{obs}} = \\frac{P(Y=1|E=0)}{P(Y=1|E=1)} = 2.0 $$\n为了便于使用标准公式（这些公式通常是为大于1的风险比定义的，对应于有害暴露或风险因素），我们将使用给定的 $RR_{\\text{obs}} = 2.0$ 进行计算。无论这代表的是有害暴露，还是以倒数形式表示的保护性暴露，其数学推导过程都是相同的。\n\n观察到的风险比（$RR_{\\text{obs}}$）、真实的因果风险比（$RR_{\\text{true}}$）以及由未测量混杂因素 $U$ 引起的偏倚因子（$B$）之间的关系由下式给出：\n$$ RR_{\\text{obs}} = RR_{\\text{true}} \\times B $$\n敏感性分析的目标是确定需要多大强度的混杂才能“解释掉”观察到的关联。这对应于真实因果风险比为空（即 $RR_{\\text{true}} = 1$）的情景。在这个零假设下，观察到的风险比完全是由混杂偏倚造成的：\n$$ RR_{\\text{obs}} = 1 \\times B \\implies B = RR_{\\text{obs}} $$\n对于我们的具体情况，偏倚因子必须为 $B = 2.0$。\n\n接下来，我们使用一个广为接受的结果来限定偏倚因子的大小。对于单个未测量的混杂因素 $U$，偏倚因子 $B$ 的界限取决于其与暴露和结局的关联强度。设 $RR_{EU}$ 为混杂因素与暴露之间关联的风险比，设 $RR_{UY}$ 为混杂因素与结局之间关联的风险比。按照此框架的惯例，$RR_{EU}$ 和 $RR_{UY}$ 都被定义为大于或等于 $1$。可以产生的最大偏倚 $B_{\\max}$ 由以下不等式给出：\n$$ B \\le B_{\\max} = \\frac{RR_{EU} \\cdot RR_{UY}}{RR_{EU} + RR_{UY} - 1} $$\n要使观察到的关联完全由混杂来解释，最大可能偏倚必须至少与观察到的风险比一样大，即 $B_{\\max} \\ge RR_{\\text{obs}}$。\n\nE值被正式定义为：如果 $RR_{EU} \\ge x$ 且 $RR_{UY} \\ge x$，观察到的关联就可以被解释掉，那么 $x$ 的这个最小值就是E值。这个最小值在 $RR_{EU} = RR_{UY} = x$ 时出现。为了求得这个值，我们将用这些参数可实现的最大偏倚设为等于观察到的风险比：\n$$ RR_{\\text{obs}} = \\frac{x \\cdot x}{x + x - 1} = \\frac{x^2}{2x - 1} $$\n我们必须解这个关于 $x$ 的方程。整理各项，我们得到一个一元二次方程：\n$$ RR_{\\text{obs}}(2x - 1) = x^2 $$\n$$ x^2 - 2(RR_{\\text{obs}})x + RR_{\\text{obs}} = 0 $$\n我们使用求根公式 $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$ 来解 $x$，其中 $a=1$，$b=-2 \\cdot RR_{\\text{obs}}$，$c=RR_{\\text{obs}}$：\n$$ x = \\frac{2 \\cdot RR_{\\text{obs}} \\pm \\sqrt{(-2 \\cdot RR_{\\text{obs}})^2 - 4(1)(RR_{\\text{obs}})}}{2} $$\n$$ x = \\frac{2 \\cdot RR_{\\text{obs}} \\pm \\sqrt{4 \\cdot RR_{\\text{obs}}^2 - 4 \\cdot RR_{\\text{obs}}}}{2} $$\n$$ x = RR_{\\text{obs}} \\pm \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}} $$\n这会得到 $x$ 的两个数学解。然而，参数 $RR_{EU}$ 和 $RR_{UY}$，以及它们的共同值 $x$，被定义为风险比，必须大于或等于 $1$。我们必须检查两个解中哪一个满足这个约束条件。\n\n题目中指出 $RR_{\\text{obs}} = 2.0$，严格大于 $1$。\n第一个解是 $x_{+} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$。因为 $RR_{\\text{obs}}  1$，所以平方根下的项为正，因此 $x_{+}  RR_{\\text{obs}}  1$。这个解总是有效的。\n\n第二个解是 $x_{-} = RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)}$。我们来检验条件 $x_{-} \\ge 1$：\n$$ RR_{\\text{obs}} - \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}} \\ge 1 $$\n$$ RR_{\\text{obs}} - 1 \\ge \\sqrt{RR_{\\text{obs}}^2 - RR_{\\text{obs}}} $$\n由于 $RR_{\\text{obs}}  1$，不等式两边都为非负，我们可以对它们进行平方而不改变不等式的方向：\n$$ (RR_{\\text{obs}} - 1)^2 \\ge RR_{\\text{obs}}^2 - RR_{\\text{obs}} $$\n$$ RR_{\\text{obs}}^2 - 2 \\cdot RR_{\\text{obs}} + 1 \\ge RR_{\\text{obs}}^2 - RR_{\\text{obs}} $$\n$$ -2 \\cdot RR_{\\text{obs}} + 1 \\ge -RR_{\\text{obs}} $$\n$$ 1 \\ge RR_{\\text{obs}} $$\n这个结果与 $RR_{\\text{obs}}  1$ 的前提相矛盾。因此，假设 $x_{-} \\ge 1$ 是错误的。解 $x_{-}$ 仅在 $RR_{\\text{obs}} \\le 1$ 时有效。由于我们正在评估一个 $RR_{\\text{obs}}1$ 的关联，因此在此框架中，$x_{-}$ 不是混杂因素关联的有效强度值。\n\n唯一有效的解是 $x_{+}$，它给出了对于给定的 $RR_{\\text{obs}}  1$ 的E值的一般解析表达式：\n$$ \\text{E-value} = RR_{\\text{obs}} + \\sqrt{RR_{\\text{obs}}(RR_{\\text{obs}} - 1)} $$\n现在，我们将具体值 $RR_{\\text{obs}} = 2.0$ 代入这个推导出的表达式中：\n$$ \\text{E-value} = 2 + \\sqrt{2(2 - 1)} $$\n$$ \\text{E-value} = 2 + \\sqrt{2(1)} $$\n$$ \\text{E-value} = 2 + \\sqrt{2} $$\n这就是与观察到的风险比 $2.0$ 相对应的E值的精确、闭合形式的解析表达式。",
            "answer": "$$\n\\boxed{2 + \\sqrt{2}}\n$$"
        }
    ]
}