{
    "hands_on_practices": [
        {
            "introduction": "The first step in validating any biomarker is to quantify its fundamental performance characteristics. This practice focuses on calculating the core metrics of diagnostic accuracy—sensitivity, specificity, predictive values, and overall accuracy—from a standard confusion matrix. Mastering these calculations  is essential for interpreting validation studies and understanding how well a test distinguishes between individuals with and without a condition.",
            "id": "4999473",
            "problem": "A blood-based prognostic biomarker is being clinically validated for a screening Context of Use (COU), defined as early identification of individuals with a latent disease where missing a case would carry a high clinical cost. In a prospective cohort of $300$ participants, gold-standard adjudication after testing yields the following counts: True Positives (TP) $=68$, False Positives (FP) $=12$, False Negatives (FN) $=22$, True Negatives (TN) $=198$. Using fundamental definitions of conditional probability and classification performance grounded in frequentist counting, compute the following performance characteristics for the biomarker within this validation cohort: sensitivity, specificity, Positive Predictive Value (PPV), Negative Predictive Value (NPV), and accuracy. Then, identify which single performance metric is most aligned with the stated screening COU in which the clinical consequence of false negatives dominates decision-making. For output encoding, use the following numerical codes for the COU-aligned metric: $1$ for sensitivity, $2$ for specificity, $3$ for PPV, $4$ for NPV, $5$ for accuracy. Report all five metric values as decimals (not percentages) and round each to four significant figures. Provide your final output as a single row matrix in the order: sensitivity, specificity, PPV, NPV, accuracy, followed by the COU metric code.",
            "solution": "The clinical validation task relies on core definitions from classification and conditional probability. Let $D$ denote disease presence and $\\overline{D}$ denote disease absence, and let $T^{+}$ and $T^{-}$ denote a positive and negative test result, respectively. The confusion matrix counts map to empirical probabilities via relative frequencies.\n\nSensitivity is the conditional probability $P(T^{+} \\mid D)$, interpreted as the probability the test is positive given disease is present. By the frequentist definition of conditional probability,\n$$\nP(T^{+} \\mid D) = \\frac{\\text{number of diseased with positive test}}{\\text{number of diseased}} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}.\n$$\nWith the given counts, $\\text{TP} = 68$ and $\\text{FN} = 22$, so\n$$\n\\text{sensitivity} = \\frac{68}{68 + 22} = \\frac{68}{90}.\n$$\nThis equals $0.755\\overline{5}$, which rounded to four significant figures is $0.7556$.\n\nSpecificity is the conditional probability $P(T^{-} \\mid \\overline{D})$, the probability the test is negative given disease is absent. By the same principle,\n$$\nP(T^{-} \\mid \\overline{D}) = \\frac{\\text{number of non-diseased with negative test}}{\\text{number of non-diseased}} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}}.\n$$\nWith $\\text{TN} = 198$ and $\\text{FP} = 12$,\n$$\n\\text{specificity} = \\frac{198}{198 + 12} = \\frac{198}{210} = 0.942857\\ldots,\n$$\nwhich rounds to four significant figures as $0.9429$.\n\nPositive Predictive Value (PPV) is the conditional probability $P(D \\mid T^{+})$, the probability of disease given a positive test. In a cohort with fixed counts, this equals the fraction of positive tests that are true positives:\n$$\n\\text{PPV} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}.\n$$\nWith $\\text{TP} = 68$ and $\\text{FP} = 12$,\n$$\n\\text{PPV} = \\frac{68}{68 + 12} = \\frac{68}{80} = 0.85.\n$$\nTo four significant figures, this is $0.8500$.\n\nNegative Predictive Value (NPV) is the conditional probability $P(\\overline{D} \\mid T^{-})$, the probability of no disease given a negative test. Similarly,\n$$\n\\text{NPV} = \\frac{\\text{TN}}{\\text{TN} + \\text{FN}}.\n$$\nWith $\\text{TN} = 198$ and $\\text{FN} = 22$,\n$$\n\\text{NPV} = \\frac{198}{198 + 22} = \\frac{198}{220} = 0.9,\n$$\nwhich to four significant figures is $0.9000$.\n\nAccuracy is the overall fraction of correct classifications among all tested individuals. Let $N$ denote the total number of individuals. Then\n$$\n\\text{accuracy} = \\frac{\\text{TP} + \\text{TN}}{N}.\n$$\nHere, $N = \\text{TP} + \\text{FP} + \\text{FN} + \\text{TN} = 68 + 12 + 22 + 198 = 300$, and $\\text{TP} + \\text{TN} = 68 + 198 = 266$, so\n$$\n\\text{accuracy} = \\frac{266}{300} = 0.886666\\ldots,\n$$\nwhich rounds to four significant figures as $0.8867$.\n\nFor the COU decision, in screening where the clinical consequence of false negatives is dominant, the alignment is to prioritize identifying as many true cases as possible, which is quantified by sensitivity, $P(T^{+} \\mid D)$. While Negative Predictive Value may also be relevant in low-prevalence settings to reassure negatives, the explicit emphasis on minimizing false negatives places sensitivity as the primary COU-aligned metric. Using the provided encoding, sensitivity corresponds to the code $1$.\n\nAssembling the requested outputs in order (sensitivity, specificity, PPV, NPV, accuracy, COU metric code) and rounding each metric to four significant figures yields:\n$$\n\\left(0.7556,\\ 0.9429,\\ 0.8500,\\ 0.9000,\\ 0.8867,\\ 1\\right).\n$$",
            "answer": "$$\\boxed{\\begin{pmatrix}0.7556 & 0.9429 & 0.8500 & 0.9000 & 0.8867 & 1\\end{pmatrix}}$$"
        },
        {
            "introduction": "A biomarker's performance in the real world is not static; it is profoundly influenced by the clinical context. This exercise moves beyond the intrinsic test properties of sensitivity and specificity to explore how a test's predictive values ($PPV$ and $NPV$) are dependent on the disease prevalence within a population. By applying Bayes' theorem, you will derive and quantify this relationship , a critical skill for understanding why a good test might perform poorly in a low-prevalence setting, or vice-versa.",
            "id": "4999450",
            "problem": "In a biomarker-driven translational study, a binary diagnostic assay is being clinically validated to stratify patients for a targeted therapy. Let the disease status be denoted by $D \\in \\{1,0\\}$ (present, absent) and the test outcome by $T \\in \\{+, -\\}$. The assay has sensitivity $S_{e} = \\mathbb{P}(T=+ \\mid D=1)$ and specificity $S_{p} = \\mathbb{P}(T=- \\mid D=0)$. The prevalence of the condition in the intended use population is $p = \\mathbb{P}(D=1)$. Positive Predictive Value (PPV) is defined as $\\mathbb{P}(D=1 \\mid T=+)$ and Negative Predictive Value (NPV) is defined as $\\mathbb{P}(D=0 \\mid T=-)$. \n\nUsing only the probability axioms and Bayes’ theorem as foundational principles, derive expressions showing how $PPV$ and $NPV$ depend on $p$, $S_{e}$, and $S_{p}$. Explain, in terms of the derived formulas, why $PPV$ and $NPV$ necessarily change with $p$ when $S_{e}$ and $S_{p}$ are fixed. Then, for an assay with $S_{e} = 0.90$ and $S_{p} = 0.95$, compute the absolute change in $PPV$ when the prevalence increases from $p=0.05$ to $p=0.20$. Express your final numerical result as an exact fraction. Do not approximate.",
            "solution": "The derivation of the Positive Predictive Value ($PPV$) and Negative Predictive Value ($NPV$) begins with their definitions and the application of Bayes' theorem.\n\nFirst, for $PPV = \\mathbb{P}(D=1 \\mid T=+)$, Bayes' theorem states:\n$$PPV = \\frac{\\mathbb{P}(T=+ \\mid D=1) \\mathbb{P}(D=1)}{\\mathbb{P}(T=+)}$$\nThe terms in the numerator are given directly: $\\mathbb{P}(T=+ \\mid D=1) = S_e$ and $\\mathbb{P}(D=1) = p$.\nThe denominator, $\\mathbb{P}(T=+)$, is the overall probability of a positive test. It can be expanded using the law of total probability:\n$$\\mathbb{P}(T=+) = \\mathbb{P}(T=+ \\mid D=1) \\mathbb{P}(D=1) + \\mathbb{P}(T=+ \\mid D=0) \\mathbb{P}(D=0)$$\nWe have $\\mathbb{P}(D=1)=p$, so $\\mathbb{P}(D=0) = 1-p$. The term $\\mathbb{P}(T=+ \\mid D=0)$ is the false positive rate, which equals $1 - S_p$. Substituting these components:\n$$\\mathbb{P}(T=+) = (S_e)(p) + (1-S_p)(1-p)$$\nFinally, substituting this back into the formula for $PPV$:\n$$PPV = \\frac{S_e p}{S_e p + (1-S_p)(1-p)}$$\n\nNext, for $NPV = \\mathbb{P}(D=0 \\mid T=-)$, Bayes' theorem states:\n$$NPV = \\frac{\\mathbb{P}(T=- \\mid D=0) \\mathbb{P}(D=0)}{\\mathbb{P}(T=-)}$$\nThe terms in the numerator are $\\mathbb{P}(T=- \\mid D=0) = S_p$ and $\\mathbb{P}(D=0) = 1-p$.\nThe denominator, $\\mathbb{P}(T=-)$, is expanded using the law of total probability:\n$$\\mathbb{P}(T=-) = \\mathbb{P}(T=- \\mid D=0) \\mathbb{P}(D=0) + \\mathbb{P}(T=- \\mid D=1) \\mathbb{P}(D=1)$$\nThe term $\\mathbb{P}(T=- \\mid D=1)$ is the false negative rate, which equals $1 - S_e$. Substituting these components:\n$$\\mathbb{P}(T=-) = (S_p)(1-p) + (1-S_e)(p)$$\nFinally, substituting this back into the formula for $NPV$:\n$$NPV = \\frac{S_p(1-p)}{S_p(1-p) + (1-S_e)p}$$\n\nThe derived formulas explicitly show that for fixed test characteristics ($S_e$ and $S_p$), both $PPV$ and $NPV$ are functions of prevalence, $p$. As $p$ appears in both the numerator and denominator, the predictive values are not constant. As prevalence increases, the pre-test probability of disease rises, causing the post-test probability after a positive test ($PPV$) to also increase. Conversely, a negative test result is less conclusive in a high-prevalence setting, causing $NPV$ to decrease.\n\nNow, we compute the absolute change in $PPV$ for $S_e = 0.90 = \\frac{9}{10}$ and $S_p = 0.95 = \\frac{19}{20}$, as prevalence changes from $p_1 = 0.05 = \\frac{1}{20}$ to $p_2 = 0.20 = \\frac{1}{5}$.\n\nFirst, calculate $PPV_1$ at $p_1 = \\frac{1}{20}$:\n$$PPV_1 = \\frac{S_e p_1}{S_e p_1 + (1-S_p)(1-p_1)} = \\frac{(\\frac{9}{10})(\\frac{1}{20})}{(\\frac{9}{10})(\\frac{1}{20}) + (\\frac{1}{20})(\\frac{19}{20})} = \\frac{\\frac{9}{200}}{\\frac{9}{200} + \\frac{19}{400}} = \\frac{\\frac{18}{400}}{\\frac{18+19}{400}} = \\frac{18}{37}$$\n\nNext, calculate $PPV_2$ at $p_2 = \\frac{1}{5}$:\n$$PPV_2 = \\frac{S_e p_2}{S_e p_2 + (1-S_p)(1-p_2)} = \\frac{(\\frac{9}{10})(\\frac{1}{5})}{(\\frac{9}{10})(\\frac{1}{5}) + (\\frac{1}{20})(\\frac{4}{5})} = \\frac{\\frac{9}{50}}{\\frac{9}{50} + \\frac{4}{100}} = \\frac{\\frac{18}{100}}{\\frac{18+4}{100}} = \\frac{18}{22} = \\frac{9}{11}$$\n\nThe absolute change in $PPV$ is $\\Delta PPV = PPV_2 - PPV_1$:\n$$\\Delta PPV = \\frac{9}{11} - \\frac{18}{37} = \\frac{9 \\times 37 - 18 \\times 11}{11 \\times 37} = \\frac{333 - 198}{407} = \\frac{135}{407}$$",
            "answer": "$$\\boxed{\\frac{135}{407}}$$"
        },
        {
            "introduction": "Does a biomarker offer true clinical value? Answering this question requires moving beyond accuracy metrics to assess whether using the biomarker to guide treatment decisions leads to better outcomes. This advanced practice introduces Decision Curve Analysis (DCA), a powerful framework for quantifying a biomarker's net benefit . By deriving the net benefit from fundamental decision-theoretic principles, you will learn to evaluate a biomarker's utility in a way that directly relates to clinical consequences.",
            "id": "4999460",
            "problem": "A translational medicine team is evaluating whether a candidate blood-based biomarker is clinically useful for guiding an invasive therapy in a heterogeneous patient population. The team plans to use Decision Curve Analysis (DCA) to quantify clinical utility across risk thresholds. In this framework, a decision rule treats patients whose predicted risk of disease is at least a chosen threshold probability. Assume the following fundamental decision-theoretic base for DCA: for an individual with disease probability $p$, the expected utility of treating is $p\\,B - (1-p)\\,H$, where $B$ is the clinical benefit accrued when a truly diseased patient is treated and $H$ is the clinical harm accrued when an unnecessary treatment is given to a patient without disease. No action yields zero utility by convention. The threshold probability $p_t$ is defined as the smallest $p$ at which the expected utility of treating equals that of not treating. A population-level performance summary is based on counts of true positives and false positives, with net clinical value expressed on the scale of benefit equivalents per patient.\n\nStarting from these definitions and no others, derive an expression for the net benefit of a model-based decision rule that treats if and only if $p \\ge p_t$, written solely in terms of the population size $N$, the number of true positives $TP$, the number of false positives $FP$, and the threshold probability $p_t$. Then, in a validation cohort of size $N = 1000$, suppose the model yields $TP = 80$ and $FP = 50$ when evaluated at $p_t = 0.15$. Compute the net benefit for this model at this threshold. Express the final answer as a per-patient net benefit (i.e., true positives per patient) and round to $4$ significant figures.",
            "solution": "To derive the expression for the net benefit of a model-based decision rule, we start from the fundamental definitions provided.\n\nFirst, we establish the relationship between benefit ($B$), harm ($H$), and the threshold probability ($p_t$). The threshold probability $p_t$ is the probability where a decision-maker is indifferent between treating and not treating, which occurs when the expected utilities are equal:\n$$ U_{treat}(p_t) = U_{not\\_treat} $$\n$$ p_t B - (1 - p_t)H = 0 $$\nRearranging this gives the trade-off between harm and benefit at the threshold:\n$$ \\frac{H}{B} = \\frac{p_t}{1 - p_t} $$\nThis ratio quantifies the number of units of benefit one is willing to forsake to avoid one unit of harm.\n\nNext, we calculate the total net utility for a population of size $N$. The rule is to treat patients if their predicted risk is $\\ge p_t$. This results in $TP$ (true positives) and $FP$ (false positives) being treated.\n- Each of the $TP$ patients is diseased and treated, yielding a total benefit of $TP \\times B$.\n- Each of the $FP$ patients is not diseased but is treated, incurring a total harm of $FP \\times H$.\n\nThe total net utility for the population is the sum of benefits minus the sum of harms:\n$$ \\text{Total Net Utility} = (TP \\times B) - (FP \\times H) $$\nNet Benefit ($NB$) is expressed in units of benefit ($B$). To achieve this, we divide the total utility by $B$:\n$$ \\text{Total Net Benefit (in B units)} = \\frac{(TP \\times B) - (FP \\times H)}{B} = TP - FP \\left(\\frac{H}{B}\\right) $$\nSubstituting the expression for the ratio $\\frac{H}{B}$:\n$$ \\text{Total Net Benefit} = TP - FP \\left(\\frac{p_t}{1 - p_t}\\right) $$\nTo find the per-patient net benefit, we divide this total by the population size $N$:\n$$ NB = \\frac{\\text{Total Net Benefit}}{N} = \\frac{TP}{N} - \\frac{FP}{N} \\left(\\frac{p_t}{1 - p_t}\\right) $$\nThis is the desired expression for the per-patient net benefit, representing the net gain in true positives per patient, after accounting for the harm of false positives weighted by the chosen risk threshold.\n\nNow, we calculate the net benefit for the validation cohort:\n- Population size: $N = 1000$\n- True positives: $TP = 80$\n- False positives: $FP = 50$\n- Threshold probability: $p_t = 0.15$\n\nSubstitute these values into the derived formula:\n$$ NB = \\frac{80}{1000} - \\frac{50}{1000} \\left(\\frac{0.15}{1 - 0.15}\\right) $$\n$$ NB = 0.08 - 0.05 \\left(\\frac{0.15}{0.85}\\right) $$\nSimplify the fraction:\n$$ \\frac{0.15}{0.85} = \\frac{15}{85} = \\frac{3}{17} $$\nSubstitute back into the equation:\n$$ NB = 0.08 - 0.05 \\left(\\frac{3}{17}\\right) = 0.08 - \\frac{0.15}{17} $$\nPerforming the division and subtraction:\n$$ NB \\approx 0.08 - 0.008823529... $$\n$$ NB \\approx 0.07117647... $$\nRounding to $4$ significant figures, we get:\n$$ NB \\approx 0.07118 $$",
            "answer": "$$\\boxed{0.07118}$$"
        }
    ]
}