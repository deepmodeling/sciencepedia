{
    "hands_on_practices": [
        {
            "introduction": "Biological soft tissues like muscle and fascia exhibit a characteristic \"strain-stiffening\" behavior, where their resistance to stretch increases as they are elongated. This nonlinear response means that a single value for stiffness is inadequate. This exercise  provides a foundational practice in quantifying this behavior by asking you to calculate and compare the tangent and secant moduli for a common exponential stress-strain model, helping you grasp the difference between instantaneous and average tissue stiffness.",
            "id": "4197239",
            "problem": "In passive uniaxial tensile testing of human crural fascia, the Cauchy stress–engineering strain response can be captured over small-to-moderate strains by the convex exponential relation $\\sigma(\\epsilon)=A\\big(\\exp(B\\epsilon)-1\\big)$, where $\\sigma$ is stress, $\\epsilon$ is engineering strain, $A$ is a stiffness scale, and $B$ is a nonlinearity parameter. Consider a specimen whose fitted parameters are $A=4.5\\,\\text{kPa}$ and $B=15$ (dimensionless). Using standard continuum mechanics definitions of the tangent modulus (instantaneous slope of the stress–strain curve) and the secant modulus (average slope from the origin), determine both moduli at $\\epsilon=0.1$. Express both moduli in kilopascals ($\\text{kPa}$) and round your answers to four significant figures. Then, interpret the differences between these moduli in terms of the nonlinearity of the tissue’s passive response. Your final numeric answers must be provided for the moduli only, without interpretation, while the interpretation should be included in your reasoning.",
            "solution": "The problem is deemed valid as it is scientifically grounded in continuum mechanics and biomechanics, is well-posed with all necessary information provided, and is expressed in objective, formal language.\n\nThe passive stress-strain relationship for the crural fascia is given by the constitutive equation:\n$$\n\\sigma(\\epsilon) = A(\\exp(B\\epsilon) - 1)\n$$\nwhere $\\sigma$ is the Cauchy stress, $\\epsilon$ is the engineering strain, and the material parameters are given as $A = 4.5 \\, \\text{kPa}$ and $B = 15$. We are asked to determine the tangent modulus and the secant modulus at a strain of $\\epsilon = 0.1$.\n\nFirst, we define the tangent modulus, $E_t$. The tangent modulus is the instantaneous slope of the stress-strain curve at a specific point, which is mathematically defined as the first derivative of the stress with respect to strain.\n$$\nE_t(\\epsilon) = \\frac{d\\sigma}{d\\epsilon}\n$$\nWe compute this derivative from the given stress function:\n$$\nE_t(\\epsilon) = \\frac{d}{d\\epsilon} \\left[ A(\\exp(B\\epsilon) - 1) \\right] = A \\frac{d}{d\\epsilon} \\left[ \\exp(B\\epsilon) - 1 \\right]\n$$\nApplying the chain rule for differentiation, we find:\n$$\nE_t(\\epsilon) = A (B \\exp(B\\epsilon) - 0) = AB \\exp(B\\epsilon)\n$$\nNow, we evaluate the tangent modulus at the specified strain, $\\epsilon = 0.1$.\n$$\nE_t(0.1) = AB \\exp(B \\times 0.1) = (4.5 \\, \\text{kPa})(15) \\exp(15 \\times 0.1)\n$$\n$$\nE_t(0.1) = 67.5 \\exp(1.5) \\, \\text{kPa}\n$$\nCalculating the numerical value:\n$$\nE_t(0.1) \\approx 67.5 \\times 4.48168907 = 302.514012... \\, \\text{kPa}\n$$\nRounding to four significant figures, the tangent modulus is $302.5 \\, \\text{kPa}$.\n\nSecond, we define the secant modulus, $E_s$. The secant modulus represents the average stiffness from the origin $(\\epsilon_1=0, \\sigma_1=0)$ to a specific point on the curve $(\\epsilon_2=\\epsilon, \\sigma_2=\\sigma(\\epsilon))$. It is the slope of the chord connecting these two points.\n$$\nE_s(\\epsilon) = \\frac{\\sigma(\\epsilon) - \\sigma(0)}{\\epsilon - 0} = \\frac{\\sigma(\\epsilon)}{\\epsilon}\n$$\nNote that $\\sigma(0) = A(\\exp(B \\times 0) - 1) = A(1-1) = 0$, which is consistent with the material being in an unstressed state at zero strain.\nSubstituting the expression for $\\sigma(\\epsilon)$:\n$$\nE_s(\\epsilon) = \\frac{A(\\exp(B\\epsilon) - 1)}{\\epsilon}\n$$\nNow, we evaluate the secant modulus at the specified strain, $\\epsilon = 0.1$.\n$$\nE_s(0.1) = \\frac{A(\\exp(B \\times 0.1) - 1)}{0.1} = \\frac{4.5 \\, \\text{kPa} (\\exp(15 \\times 0.1) - 1)}{0.1}\n$$\n$$\nE_s(0.1) = 45 (\\exp(1.5) - 1) \\, \\text{kPa}\n$$\nCalculating the numerical value:\n$$\nE_s(0.1) \\approx 45 \\times (4.48168907 - 1) = 45 \\times 3.48168907 = 156.676008... \\, \\text{kPa}\n$$\nRounding to four significant figures, the secant modulus is $156.7 \\, \\text{kPa}$.\n\nFinally, we interpret the difference between the two moduli. At $\\epsilon = 0.1$, we found $E_t \\approx 302.5 \\, \\text{kPa}$ and $E_s \\approx 156.7 \\, \\text{kPa}$. The tangent modulus is significantly greater than the secant modulus ($E_t > E_s$). This is characteristic of a material with a \"strain-stiffening\" response. The stress-strain curve is convex, meaning it curves upward. The convexity can be confirmed by examining the second derivative of stress with respect to strain:\n$$\n\\frac{d^2\\sigma}{d\\epsilon^2} = \\frac{d}{d\\epsilon}(AB \\exp(B\\epsilon)) = AB^2 \\exp(B\\epsilon)\n$$\nSince $A > 0$ and $B > 0$, the second derivative is always positive, confirming the strict convexity of the stress-strain curve. For a convex function passing through the origin, the slope of the tangent line at any point $\\epsilon > 0$ is always greater than the slope of the secant line from the origin to that point.\nIn physical terms, the secant modulus $E_s$ represents the average stiffness of the tissue over the strain range from $0$ to $0.1$. The tangent modulus $E_t$ represents the material's instantaneous stiffness at the specific strain of $0.1$. The fact that $E_t$ is nearly double $E_s$ indicates that the tissue becomes markedly stiffer as it is stretched. This nonlinear, strain-stiffening behavior is a critical functional property of many biological soft tissues like fascia, ligaments, and tendons.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 302.5 & 156.7 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond simple elasticity, the mechanical response of muscle and fascia is also time-dependent, a property known as viscoelasticity. This means their stiffness is not constant but changes with the speed of deformation. This exercise  introduces this concept through the Kelvin-Voigt model, a fundamental building block in biomechanics, to show how apparent stiffness is influenced by strain rate during a ramp-loading scenario.",
            "id": "4197291",
            "problem": "A passive muscle–fascia unit undergoing small, uniaxial extension is tested in a ramp-and-hold protocol within a strain regime where linearization is appropriate. In this regime, the composite tissue can be approximated by a Kelvin–Voigt element consisting of a linear elastic spring of modulus $E$ (units: kilopascals) in parallel with a Newtonian dashpot of viscosity $\\eta$ (units: kilopascal-seconds). Assume quasi-static conditions (negligible inertia) and isothermal behavior.\n\nA prescribed strain history is applied as a linear ramp from zero strain at time $t=0$ to a terminal strain $\\epsilon_{f}$ at time $t=t_{f}$, with constant strain rate $\\dot{\\epsilon}$, i.e., $\\epsilon(t)=\\dot{\\epsilon}\\,t$ for $0 \\le t \\le t_{f}$, where $t_{f}=\\epsilon_{f}/\\dot{\\epsilon}$. The stress is measured continuously, and the “peak stress” is defined as the stress attained at the end of the ramp, evaluated as the left-limit at $t=t_{f}^{-}$.\n\nUsing only the mechanical constitution of the spring and dashpot and the parallel connection rules, derive the expression for the peak stress during the ramp and then compute how the apparent stiffness, defined as $K_{\\mathrm{app}}=\\sigma_{\\mathrm{peak}}/\\epsilon_{f}$ at $t=t_{f}^{-}$, changes with strain rate. Let $E=120$ kilopascals, $\\eta=4.5$ kilopascal-seconds, and $\\epsilon_{f}=0.12$. Consider two strain rates: a “slow” ramp with $\\dot{\\epsilon}_{1}=0.01$ per second and a “fast” ramp with $\\dot{\\epsilon}_{2}=2.0$ per second. Compute the ratio $R=K_{\\mathrm{app}}(\\dot{\\epsilon}_{2})/K_{\\mathrm{app}}(\\dot{\\epsilon}_{1})$. Express the final answer as a unitless ratio and round your answer to four significant figures.",
            "solution": "The Kelvin–Voigt model consists of a linear elastic spring and a Newtonian dashpot in parallel. For elements in parallel, the total stress is the sum of the element stresses, and both elements experience the same strain. The constitutive relation of a linear elastic spring is $\\sigma_{\\mathrm{spring}}=E\\,\\epsilon$, where $E$ is the elastic modulus and $\\epsilon$ is the strain. The constitutive relation of a Newtonian dashpot is $\\sigma_{\\mathrm{dashpot}}=\\eta\\,\\dot{\\epsilon}$, where $\\eta$ is the viscosity and $\\dot{\\epsilon}$ is the strain rate. Because the elements are in parallel, the total stress is\n$$\n\\sigma(t)=\\sigma_{\\mathrm{spring}}(t)+\\sigma_{\\mathrm{dashpot}}(t)=E\\,\\epsilon(t)+\\eta\\,\\dot{\\epsilon}(t).\n$$\n\nUnder the prescribed ramp, the strain is $\\epsilon(t)=\\dot{\\epsilon}\\,t$ for $0\\le t\\le t_{f}$, with $\\dot{\\epsilon}$ constant during the ramp. Thus, during the ramp, the stress evolves as\n$$\n\\sigma(t)=E\\,\\dot{\\epsilon}\\,t+\\eta\\,\\dot{\\epsilon}.\n$$\nThe “peak stress” during the ramp occurs at the end of the ramp, evaluated as the left-limit at $t=t_{f}^{-}$. Substituting $t_{f}=\\epsilon_{f}/\\dot{\\epsilon}$ yields\n$$\n\\sigma_{\\mathrm{peak}}=\\lim_{t\\to t_{f}^{-}}\\sigma(t)=E\\,\\dot{\\epsilon}\\,t_{f}+\\eta\\,\\dot{\\epsilon}=E\\,\\epsilon_{f}+\\eta\\,\\dot{\\epsilon}.\n$$\nDefine the apparent stiffness at the end of the ramp as\n$$\nK_{\\mathrm{app}}=\\frac{\\sigma_{\\mathrm{peak}}}{\\epsilon_{f}}=\\frac{E\\,\\epsilon_{f}+\\eta\\,\\dot{\\epsilon}}{\\epsilon_{f}}=E+\\frac{\\eta\\,\\dot{\\epsilon}}{\\epsilon_{f}}.\n$$\nTherefore, the apparent stiffness depends on the strain rate through the term $\\eta\\,\\dot{\\epsilon}/\\epsilon_{f}$. The ratio of apparent stiffnesses at two different strain rates $\\dot{\\epsilon}_{2}$ and $\\dot{\\epsilon}_{1}$ is\n$$\nR=\\frac{K_{\\mathrm{app}}(\\dot{\\epsilon}_{2})}{K_{\\mathrm{app}}(\\dot{\\epsilon}_{1})}\n=\\frac{E+\\dfrac{\\eta\\,\\dot{\\epsilon}_{2}}{\\epsilon_{f}}}{E+\\dfrac{\\eta\\,\\dot{\\epsilon}_{1}}{\\epsilon_{f}}}.\n$$\n\nNow substitute the given values $E=120$ kilopascals, $\\eta=4.5$ kilopascal-seconds, $\\epsilon_{f}=0.12$, $\\dot{\\epsilon}_{1}=0.01$ per second, and $\\dot{\\epsilon}_{2}=2.0$ per second.\n\nFirst compute the numerator:\n$$\nK_{\\mathrm{app}}(\\dot{\\epsilon}_{2})=E+\\frac{\\eta\\,\\dot{\\epsilon}_{2}}{\\epsilon_{f}}=120+\\frac{4.5\\times 2.0}{0.12}=120+\\frac{9.0}{0.12}=120+75=195.\n$$\nThen compute the denominator:\n$$\nK_{\\mathrm{app}}(\\dot{\\epsilon}_{1})=E+\\frac{\\eta\\,\\dot{\\epsilon}_{1}}{\\epsilon_{f}}=120+\\frac{4.5\\times 0.01}{0.12}=120+\\frac{0.045}{0.12}=120+0.375=120.375.\n$$\nThus,\n$$\nR=\\frac{195}{120.375}.\n$$\nEvaluate this ratio:\n$$\nR\\approx 1.61994\\ldots\n$$\nRounded to four significant figures, the unitless ratio is\n$$\nR=1.620.\n$$\n\nConceptual interpretation: In the Kelvin–Voigt representation of passive muscle–fascia, the spring contributes a rate-independent term $E\\,\\epsilon_{f}$, while the dashpot contributes a rate-dependent term $\\eta\\,\\dot{\\epsilon}$. The apparent stiffness $K_{\\mathrm{app}}$ defined from the peak stress at the end of a ramp thus increases with strain rate by an amount proportional to $\\eta\\,\\dot{\\epsilon}/\\epsilon_{f}$. The computed ratio quantifies the increase in apparent stiffness between the fast and slow ramps for the given parameters.",
            "answer": "$$\\boxed{1.620}$$"
        },
        {
            "introduction": "Theoretical models are only as good as their ability to describe real-world phenomena, which requires fitting them to experimental data. This hands-on computational practice  bridges theory and application by tasking you with estimating the parameters of the exponential stress-strain model from a set of synthetic data points. You will implement a nonlinear least-squares procedure and, crucially, learn to quantify the uncertainty of your estimates by calculating their confidence intervals, a core skill in modern biomechanical research.",
            "id": "4197305",
            "problem": "Consider uniaxial extension measurements of the passive stress–strain response of a muscle–fascia specimen. Let engineering strain be denoted by $\\varepsilon$ (dimensionless) and Cauchy stress be denoted by $\\sigma$ (in kilopascals, kPa). A widely used phenomenological model for passive stiffness is the exponential form\n$$\n\\sigma(\\varepsilon; A, B) = A\\left(e^{B \\varepsilon} - 1\\right),\n$$\nwhere $A$ (in kPa) scales the stress magnitude and $B$ (dimensionless) controls the nonlinearity. Assume measurement errors in stress are independent and identically distributed (i.i.d.) Gaussian with zero mean and constant variance across strains. Starting from first principles of least squares, construct a procedure to estimate $A$ and $B$ by minimizing the sum of squared residuals between measured stresses and model predictions and then assess $95\\%$ confidence intervals for both $A$ and $B$ based on a local linearization of the model at the optimum.\n\nYour program must implement the following steps using only the provided data for each test case:\n1. Formulate the nonlinear least squares objective over the parameter vector $(A, B)$.\n2. Compute the parameter estimates $(\\hat{A}, \\hat{B})$ via a suitable iterative method that uses the model and its sensitivity to parameters.\n3. Using the Jacobian of the residuals evaluated at $(\\hat{A}, \\hat{B})$, compute an estimate of the parameter covariance matrix under the i.i.d. Gaussian error assumption.\n4. Report the $95\\%$ confidence intervals (defined as estimate $\\pm$ critical value times standard error) for both $\\hat{A}$ and $\\hat{B}$, where the critical value is taken from the Student's $t$ distribution with degrees of freedom equal to the number of data points minus the number of parameters.\n\nAll answers for $A$ and its confidence interval bounds must be expressed in kPa. All answers for $B$ and its confidence interval bounds must be expressed as dimensionless numbers.\n\nUse the following test suite of measured strain–stress pairs, provided as lists of $(\\varepsilon_i, \\sigma_i)$ with stress in kPa and strain dimensionless:\n\nTest case 1 (muscle-like specimen, moderate nonlinearity):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.02, 2.356833)$\n  - $(0.04, 6.101896)$\n  - $(0.06, 9.465426)$\n  - $(0.08, 15.206491)$\n  - $(0.10, 20.519382)$\n  - $(0.12, 27.841403)$\n  - $(0.15, 42.080269)$\n  - $(0.18, 59.995770)$\n  - $(0.22, 96.700162)$\n  - $(0.26, 149.264857)$\n  - $(0.30, 227.826443)$\n\nTest case 2 (fascia-like specimen, higher nonlinearity):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.01, 3.344346)$\n  - $(0.02, 9.066586)$\n  - $(0.03, 13.420137)$\n  - $(0.04, 22.288664)$\n  - $(0.05, 27.692062)$\n  - $(0.06, 39.593606)$\n  - $(0.08, 63.313900)$\n  - $(0.10, 102.792940)$\n  - $(0.13, 185.627600)$\n  - $(0.16, 339.285400)$\n  - $(0.20, 706.964680)$\n\nTest case 3 (edge case: low strain range and small sample size):\n- Data points:\n  - $(0.00, 0.000000)$\n  - $(0.01, 0.524692)$\n  - $(0.02, 0.999975)$\n  - $(0.03, 1.617739)$\n  - $(0.05, 2.738870)$\n\nYour program should produce a single line of output containing, for each test case in order, a list of six floating point values $[\\hat{A}, \\hat{B}, A_{\\text{low}}, A_{\\text{high}}, B_{\\text{low}}, B_{\\text{high}}]$, where $A_{\\text{low}}$ and $A_{\\text{high}}$ are the lower and upper bounds of the $95\\%$ confidence interval for $A$ (in kPa), and $B_{\\text{low}}$ and $B_{\\text{high}}$ are the corresponding bounds for $B$ (dimensionless). Aggregate the three test case results into a single comma-separated list enclosed in square brackets. For example, the final output format must be exactly\n$$\n[\\,[\\hat{A}_1,\\hat{B}_1,A_{\\text{low},1},A_{\\text{high},1},B_{\\text{low},1},B_{\\text{high},1}],\\,[\\hat{A}_2,\\hat{B}_2,A_{\\text{low},2},A_{\\text{high},2},B_{\\text{low},2},B_{\\text{high},2}],\\,[\\hat{A}_3,\\hat{B}_3,A_{\\text{low},3},A_{\\text{high},3},B_{\\text{low},3},B_{\\text{high},3}]\\,]\n$$\nwhere each numeric entry is a floating point number. The printed line must contain no additional text.",
            "solution": "The user's request is a valid problem in numerical optimization and statistical inference, specifically nonlinear regression analysis applied to a biomechanics model. The problem is scientifically grounded, well-posed, objective, and contains all necessary information for a unique solution.\n\n### Principle-Based Design\n\nThe task is to estimate the parameters $A$ and $B$ of the exponential stress-strain model $\\sigma(\\varepsilon) = A(e^{B\\varepsilon} - 1)$ and to determine their $95\\%$ confidence intervals, given experimental data. This is a classic nonlinear least squares (NLLS) problem. The solution is structured according to the following principles.\n\n#### 1. Nonlinear Least Squares (NLLS) Formulation\n\nThe fundamental principle is to find the parameter values $(\\hat{A}, \\hat{B})$ that best fit the model to the measured data $(\\varepsilon_i, \\sigma_i)$, where $i=1, \\dots, n$. \"Best fit\" is defined in the sense of least squares, which assumes that the measurement errors are independent and identically distributed (i.i.d.) Gaussian random variables with zero mean. The goal is to minimize the sum of the squared residuals (RSS), which is the sum of the squared differences between the observed stresses $\\sigma_i$ and the stresses predicted by the model $\\sigma(\\varepsilon_i; A, B)$.\n\nThe objective function to minimize is the RSS, denoted by $S(A, B)$:\n$$\nS(A, B) = \\sum_{i=1}^{n} \\left[ \\sigma_i - \\sigma(\\varepsilon_i; A, B) \\right]^2 = \\sum_{i=1}^{n} r_i(A, B)^2\n$$\nwhere $r_i(A, B) = \\sigma_i - A(e^{B\\varepsilon_i} - 1)$ is the $i$-th residual. Let $\\mathbf{p} = [A, B]^T$ be the vector of parameters. The objective is to find $\\hat{\\mathbf{p}} = \\arg\\min_{\\mathbf{p}} S(\\mathbf{p})$.\n\n#### 2. Iterative Optimization Algorithm\n\nUnlike linear least squares, NLLS problems generally do not have a closed-form solution. They must be solved iteratively. The Gauss-Newton algorithm and its variants (e.g., Levenberg-Marquardt) are standard methods. These algorithms start with an initial guess $\\mathbf{p}_0$ and iteratively generate a sequence of parameter estimates $\\mathbf{p}_k$ that converge to the minimum $\\hat{\\mathbf{p}}$.\n\nThe core of these methods is a local linear approximation of the model. At each iteration $k$, the update step $\\Delta\\mathbf{p}$ is found by solving a linear least squares problem. The Gauss-Newton update rule is given by:\n$$\n\\mathbf{p}_{k+1} = \\mathbf{p}_k + \\Delta\\mathbf{p}_k \\quad \\text{where} \\quad (\\mathbf{J}_k^T \\mathbf{J}_k) \\Delta\\mathbf{p}_k = \\mathbf{J}_k^T \\mathbf{r}_k\n$$\nHere, $\\mathbf{r}_k$ is the vector of residuals evaluated at $\\mathbf{p}_k$, and $\\mathbf{J}_k$ is the Jacobian matrix of the *model function* with respect to the parameters, also evaluated at $\\mathbf{p}_k$. The elements of the Jacobian are the model's sensitivities to parameter changes:\n$$\n\\mathbf{J}_{ij} = \\frac{\\partial \\sigma(\\varepsilon_i; \\mathbf{p})}{\\partial p_j}\n$$\nFor our model, the two columns of the Jacobian matrix $\\mathbf{J}$ are:\n$$\n\\frac{\\partial \\sigma}{\\partial A} = e^{B\\varepsilon_i} - 1\n$$\n$$\n\\frac{\\partial \\sigma}{\\partial B} = A \\varepsilon_i e^{B\\varepsilon_i}\n$$\nThe implementation will utilize the `scipy.optimize.least_squares` function, which employs a robust trust-region reflective algorithm, a sophisticated variant of the Gauss-Newton approach. We will supply the analytic Jacobian to ensure accuracy and efficiency.\n\n#### 3. Confidence Interval Estimation\n\nAfter finding the optimal parameters $\\hat{\\mathbf{p}} = [\\hat{A}, \\hat{B}]^T$, we assess the uncertainty of these estimates by constructing confidence intervals. This is based on the statistical properties of the least squares estimator under the assumption of i.i.d. Gaussian errors.\n\nThe procedure relies on linearizing the model around the optimal solution $\\hat{\\mathbf{p}}$. In this linearized regime, the estimator $\\hat{\\mathbf{p}}$ is approximately normally distributed. The covariance matrix of the parameter estimates, $\\mathbf{C}$, quantifies their uncertainty and correlation. It is estimated by:\n$$\n\\mathbf{C} = s^2 (\\mathbf{J}^T \\mathbf{J})^{-1}\n$$\nwhere:\n- $\\mathbf{J}$ is the Jacobian matrix of the model, evaluated at the optimal parameters $\\hat{\\mathbf{p}}$. Note that some libraries work with the Jacobian of the residuals, $\\mathbf{J}_r = -\\mathbf{J}$. Since $\\mathbf{J}_r^T\\mathbf{J}_r = \\mathbf{J}^T\\mathbf{J}$, the formula remains the same.\n- $s^2$ is the unbiased estimate of the error variance $\\sigma_{\\text{error}}^2$. It is calculated from the minimum sum of squared residuals, $S(\\hat{\\mathbf{p}})$:\n  $$\n  s^2 = \\frac{S(\\hat{\\mathbf{p}})}{n-p}\n  $$\n  where $n$ is the number of data points and $p$ is the number of parameters (here, $p=2$). The term $n-p$ represents the degrees of freedom.\n\nThe diagonal elements of the covariance matrix, $C_{11}$ and $C_{22}$, are the estimated variances of $\\hat{A}$ and $\\hat{B}$, respectively. The standard error (SE) for each parameter is the square root of its variance:\n$$\n\\text{SE}(\\hat{A}) = \\sqrt{C_{11}} \\quad \\text{and} \\quad \\text{SE}(\\hat{B}) = \\sqrt{C_{22}}\n$$\n\nA $(1-\\alpha) \\times 100\\%$ confidence interval for a parameter estimate $\\hat{p}_j$ is constructed as:\n$$\n\\left[ \\hat{p}_j - t_{1-\\alpha/2, n-p} \\cdot \\text{SE}(\\hat{p}_j), \\quad \\hat{p}_j + t_{1-\\alpha/2, n-p} \\cdot \\text{SE}(\\hat{p}_j) \\right]\n$$\nHere, $t_{1-\\alpha/2, n-p}$ is the critical value from the Student's $t$-distribution for a confidence level of $1-\\alpha$ (for $95\\%$ confidence, $\\alpha=0.05$) and $n-p$ degrees of freedom. The use of the $t$-distribution is appropriate because the error variance $\\sigma_{\\text{error}}^2$ was estimated from the data.\n\nThe implementation will execute these steps for each test case to compute the parameter estimates and their corresponding $95\\%$ confidence intervals.",
            "answer": "```python\nimport numpy as np\nfrom scipy.optimize import least_squares\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Solves for the parameters and confidence intervals for a series of\n    nonlinear regression problems based on a biomechanical model.\n    \"\"\"\n    test_cases = [\n        # Test case 1\n        [\n            (0.00, 0.000000), (0.02, 2.356833), (0.04, 6.101896),\n            (0.06, 9.465426), (0.08, 15.206491), (0.10, 20.519382),\n            (0.12, 27.841403), (0.15, 42.080269), (0.18, 59.995770),\n            (0.22, 96.700162), (0.26, 149.264857), (0.30, 227.826443)\n        ],\n        # Test case 2\n        [\n            (0.00, 0.000000), (0.01, 3.344346), (0.02, 9.066586),\n            (0.03, 13.420137), (0.04, 22.288664), (0.05, 27.692062),\n            (0.06, 39.593606), (0.08, 63.313900), (0.10, 102.792940),\n            (0.13, 185.627600), (0.16, 339.285400), (0.20, 706.964680)\n        ],\n        # Test case 3\n        [\n            (0.00, 0.000000), (0.01, 0.524692), (0.02, 0.999975),\n            (0.03, 1.617739), (0.05, 2.738870)\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        data_points = np.array(case_data, dtype=float)\n        epsilon = data_points[:, 0]\n        sigma_obs = data_points[:, 1]\n\n        def model(params, eps):\n            A, B = params\n            return A * (np.exp(B * eps) - 1)\n\n        def residuals(params, eps, sig):\n            return sig - model(params, eps)\n\n        def jacobian_residuals(params, eps, sig):\n            A, B = params\n            jac = np.empty((len(eps), 2), dtype=float)\n            exp_term = np.exp(B * eps)\n            jac[:, 0] = -(exp_term - 1)\n            jac[:, 1] = -A * eps * exp_term\n            return jac\n        \n        # Initial guess for parameters [A, B]\n        # A simple, fixed guess is often sufficient for a robust solver.\n        # Bounds ensure physically plausible (non-negative) parameters.\n        p0 = [10.0, 10.0]\n        bounds = ([0, 0], [np.inf, np.inf])\n\n        # Perform nonlinear least squares optimization\n        res = least_squares(\n            residuals, \n            p0, \n            jac=jacobian_residuals, \n            args=(epsilon, sigma_obs),\n            method='trf',\n            bounds=bounds\n        )\n        A_hat, B_hat = res.x\n        \n        # Calculate confidence intervals\n        n = len(epsilon)  # number of data points\n        p = len(p0)       # number of parameters\n\n        dof = n - p # degrees of freedom\n        \n        # Sum of squared residuals at the optimum\n        S_min = np.sum(res.fun**2)\n        \n        # Estimate of the error variance\n        s2 = S_min / dof\n        \n        # Jacobian of residuals evaluated at the solution\n        Jr = res.jac\n        \n        A_low, A_high, B_low, B_high = (np.nan,) * 4\n        try:\n            # Check for singularity/ill-conditioning\n            if np.linalg.cond(Jr.T @ Jr) < 1e15:\n                # Parameter covariance matrix\n                cov_matrix = s2 * np.linalg.inv(Jr.T @ Jr)\n                \n                # Standard errors of parameters\n                se = np.sqrt(np.diag(cov_matrix))\n                se_A, se_B = se\n\n                # Critical value from Student's t-distribution for 95% CI\n                alpha = 0.05\n                t_crit = t.ppf(1 - alpha / 2, df=dof)\n\n                # Confidence intervals\n                A_low = A_hat - t_crit * se_A\n                A_high = A_hat + t_crit * se_A\n                B_low = B_hat - t_crit * se_B\n                B_high = B_hat + t_crit * se_B\n        except (np.linalg.LinAlgError, ValueError):\n            # If matrix is singular or sqrt(negative) (numerical artifact),\n            # CIs cannot be computed. np.nan will be used.\n            pass\n\n        case_results = [A_hat, B_hat, A_low, A_high, B_low, B_high]\n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified\n    # The format requires a list of lists, with no spaces.\n    outer_list_str = []\n    for res_list in all_results:\n        # Use str() which is sufficient for float representation\n        inner_list_str = f\"[{','.join(map(str, res_list))}]\"\n        outer_list_str.append(inner_list_str)\n    \n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n    print(final_output_str)\n\nsolve()\n```"
        }
    ]
}