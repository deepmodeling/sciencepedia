{
    "hands_on_practices": [
        {
            "introduction": "在评估迁移学习模型时，一个核心问题是在“完全微调”所有层和仅“选择性微调”顶层之间做出选择。这个问题  提供了一个动手实践，引导我们应用贝叶斯统计方法来严谨地量化一种策略相对于另一种策略的预期性能提升。通过这种方式，我们可以超越简单的性能平均值，考虑训练过程中的随机性，从而做出更稳健的决策。",
            "id": "4615261",
            "problem": "一个研究小组正在评估用于胸部X光片肺结节检测的医学成像任务中卷积神经网络(CNN)的迁移学习策略。该网络从一个大型自然图像预训练语料库中初始化，然后使用带标签的医学图像进行训练。考虑了两种训练配置：对所有层进行全层微调(FF)和仅对顶层进行选择性微调同时冻结早期层(SF)。验证性能通过受试者工作特征曲线下面积(AUROC)来衡量。为了控制初始化和数据顺序效应带来的随机性，训练在$5$个独立的随机种子上重复进行，并且对于每个种子，在$3$个交叉验证折上计算验证AUROC。\n\n令 $A_{s,f}^{\\mathrm{SF}}$ 和 $A_{s,f}^{\\mathrm{FF}}$ 分别表示在选择性微调和全层微调下，种子 $s \\in \\{1,2,3,4,5\\}$ 和折 $f \\in \\{1,2,3\\}$ 的折级别AUROC。将种子级别的平均验证性能差异定义为\n$$\nd_{s} \\equiv \\frac{1}{3}\\sum_{f=1}^{3}A_{s,f}^{\\mathrm{SF}} - \\frac{1}{3}\\sum_{f=1}^{3}A_{s,f}^{\\mathrm{FF}}.\n$$\n假设差异 $\\{d_{s}\\}$ 是来自正态似然 $d_{s} \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ 的独立同分布抽样，其中 $\\mu$ 是选择性微调相对于全层微调的期望改进，而 $\\sigma^{2}$ 捕捉了不同种子间的随机变异性。采用共轭正态-逆伽马先验，\n$$\n\\mu \\mid \\sigma^{2} \\sim \\mathcal{N}\\!\\left(m_{0},\\frac{\\sigma^{2}}{\\kappa_{0}}\\right), \\quad \\sigma^{2} \\sim \\mathrm{Inv\\!\\text{-}\\Gamma}(\\alpha_{0},\\beta_{0}),\n$$\n超参数为 $m_{0}=0$, $\\kappa_{0}=2$, $\\alpha_{0}=2$, $\\beta_{0}=10^{-5}$。在此模型下，贝叶斯期望改进是后验期望 $\\mathbb{E}[\\mu \\mid \\{d_{s}\\}]$。\n\n给定以下折级别的验证AUROC测量值：\n- 种子 $1$：$A_{1,1}^{\\mathrm{SF}}=0.892$, $A_{1,2}^{\\mathrm{SF}}=0.887$, $A_{1,3}^{\\mathrm{SF}}=0.894$; $A_{1,1}^{\\mathrm{FF}}=0.888$, $A_{1,2}^{\\mathrm{FF}}=0.883$, $A_{1,3}^{\\mathrm{FF}}=0.890$。\n- 种子 $2$：$A_{2,1}^{\\mathrm{SF}}=0.901$, $A_{2,2}^{\\mathrm{SF}}=0.896$, $A_{2,3}^{\\mathrm{SF}}=0.900$; $A_{2,1}^{\\mathrm{FF}}=0.897$, $A_{2,2}^{\\mathrm{FF}}=0.892$, $A_{2,3}^{\\mathrm{FF}}=0.895$。\n- 种子 $3$：$A_{3,1}^{\\mathrm{SF}}=0.880$, $A_{3,2}^{\\mathrm{SF}}=0.885$, $A_{3,3}^{\\mathrm{SF}}=0.882$; $A_{3,1}^{\\mathrm{FF}}=0.874$, $A_{3,2}^{\\mathrm{FF}}=0.878$, $A_{3,3}^{\\mathrm{FF}}=0.876$。\n- 种子 $4$：$A_{4,1}^{\\mathrm{SF}}=0.895$, $A_{4,2}^{\\mathrm{SF}}=0.898$, $A_{4,3}^{\\mathrm{SF}}=0.897$; $A_{4,1}^{\\mathrm{FF}}=0.890$, $A_{4,2}^{\\mathrm{FF}}=0.892$, $A_{4,3}^{\\mathrm{FF}}=0.891$。\n- 种子 $5$：$A_{5,1}^{\\mathrm{SF}}=0.888$, $A_{5,2}^{\\mathrm{SF}}=0.889$, $A_{5,3}^{\\mathrm{SF}}=0.891$; $A_{5,1}^{\\mathrm{FF}}=0.884$, $A_{5,2}^{\\mathrm{FF}}=0.885$, $A_{5,3}^{\\mathrm{FF}}=0.886$。\n\n从基础的统计定义（期望、正态似然和共轭贝叶斯更新）出发，计算这些数据和先验所蕴含的贝叶斯期望改进 $\\mathbb{E}[\\mu \\mid \\{d_{s}\\}]$。将最终数值答案四舍五入到四位有效数字。",
            "solution": "用户提供了一个需要在贝叶斯框架内计算后验期望的问题。\n\n### 步骤1：提取给定信息\n- **任务**：计算贝叶斯期望改进 $\\mathbb{E}[\\mu \\mid \\{d_{s}\\}]$。\n- **数据**：种子 $s \\in \\{1,2,3,4,5\\}$ 和折 $f \\in \\{1,2,3\\}$ 的折级别AUROC分数 $A_{s,f}^{\\mathrm{SF}}$ 和 $A_{s,f}^{\\mathrm{FF}}$。\n  - 种子 $1$：$\\{A_{1,f}^{\\mathrm{SF}}\\} = \\{0.892, 0.887, 0.894\\}$；$\\{A_{1,f}^{\\mathrm{FF}}\\} = \\{0.888, 0.883, 0.890\\}$。\n  - 种子 $2$：$\\{A_{2,f}^{\\mathrm{SF}}\\} = \\{0.901, 0.896, 0.900\\}$；$\\{A_{2,f}^{\\mathrm{FF}}\\} = \\{0.897, 0.892, 0.895\\}$。\n  - 种子 $3$：$\\{A_{3,f}^{\\mathrm{SF}}\\} = \\{0.880, 0.885, 0.882\\}$；$\\{A_{3,f}^{\\mathrm{FF}}\\} = \\{0.874, 0.878, 0.876\\}$。\n  - 种子 $4$：$\\{A_{4,f}^{\\mathrm{SF}}\\} = \\{0.895, 0.898, 0.897\\}$；$\\{A_{4,f}^{\\mathrm{FF}}\\} = \\{0.890, 0.892, 0.891\\}$。\n  - 种子 $5$：$\\{A_{5,f}^{\\mathrm{SF}}\\} = \\{0.888, 0.889, 0.891\\}$；$\\{A_{5,f}^{\\mathrm{FF}}\\} = \\{0.884, 0.885, 0.886\\}$。\n- **派生数据定义**：种子级别的平均验证性能差异是 $d_{s} \\equiv \\frac{1}{3}\\sum_{f=1}^{3}A_{s,f}^{\\mathrm{SF}} - \\frac{1}{3}\\sum_{f=1}^{3}A_{s,f}^{\\mathrm{FF}}$。\n- **似然模型**：差异 $\\{d_{s}\\}$ 是来自正态分布 $d_{s} \\sim \\mathcal{N}(\\mu,\\sigma^{2})$ 的独立同分布(i.i.d.)抽样。种子数量为 $n=5$。\n- **先验模型**：为参数 $(\\mu, \\sigma^2)$ 指定了共轭正态-逆伽马先验：\n  $$\n  \\mu \\mid \\sigma^{2} \\sim \\mathcal{N}\\!\\left(m_{0},\\frac{\\sigma^{2}}{\\kappa_{0}}\\right), \\quad \\sigma^{2} \\sim \\mathrm{Inv\\!\\text{-}\\Gamma}(\\alpha_{0},\\beta_{0})\n  $$\n- **先验超参数**：$m_{0}=0$, $\\kappa_{0}=2$, $\\alpha_{0}=2$, $\\beta_{0}=10^{-5}$。\n- **要求**：将最终数值答案四舍五入到四位有效数字。\n\n### 步骤2：使用提取的给定信息进行验证\n该问题具有科学依据、定义明确且客观。\n- **科学依据**：该问题使用了机器学习和贝叶斯统计中的标准方法（迁移学习、CNN、AUROC、正态-逆伽马共轭先验分析），并将其应用于一个现实的医学成像场景（肺结节检测）。\n- **定义明确**：该问题提供了所有必要的数据、一个完整的统计模型（似然和先验）以及一个明确的目标（计算$\\mu$的后验期望）。共轭先验的使用确保了存在一个定义明确的后验分布，并且其参数可以解析计算。\n- **客观性**：该问题使用精确的数学定义和客观的数值数据进行陈述。没有主观或模糊的陈述。\n\n该问题有效，因为它没有违反任何指定的无效标准。\n\n### 步骤3：行动\n问题有效。我现在将继续进行解答。\n\n目标是计算平均改进的后验期望 $\\mathbb{E}[\\mu \\mid \\{d_{s}\\}]$。统计模型包括数据 $d_s$ 的正态似然和参数 $(\\mu, \\sigma^2)$ 的正态-逆伽马先验。这是一个标准的共轭设置。\n\n后验分布 $p(\\mu, \\sigma^2 \\mid \\{d_s\\})$ 也是一个正态-逆伽马分布，即 $p(\\mu, \\sigma^2 \\mid \\{d_s\\}) = \\mathrm{NIG}(\\mu, \\sigma^2 \\mid m_n, \\kappa_n, \\alpha_n, \\beta_n)$，具有更新后的超参数。在对 $\\sigma^2$ 进行积分后，$\\mu$ 的边缘后验分布是一个以 $m_n$ 为中心的非标准化学生t分布。该分布的期望是其中心 $m_n$。因此，我们需要计算的量是：\n$$\n\\mathbb{E}[\\mu \\mid \\{d_{s}\\}] = m_n\n$$\n后验均值参数 $m_n$ 的更新规则由先验均值 $m_0$ 和数据样本均值 $\\bar{d}$ 的加权平均给出：\n$$\nm_n = \\frac{\\kappa_0 m_0 + n \\bar{d}}{\\kappa_0 + n}\n$$\n其中 $n$ 是数据点（种子）的数量，$\\bar{d} = \\frac{1}{n}\\sum_{s=1}^{n} d_s$。\n\n解决过程包括三个步骤：\n1. 计算每个种子 $s=1, \\dots, 5$ 的观测差异 $d_s$。\n2. 计算这些差异的样本均值 $\\bar{d}$。\n3. 将 $n$、$\\kappa_0$、$m_0$ 和 $\\bar{d}$ 的值代入 $m_n$ 的公式中。\n\n**步骤1：计算种子级别的差异 $d_s$。**\n差异 $d_s$ 由 $d_s = \\frac{1}{3}\\sum_{f=1}^{3} (A_{s,f}^{\\mathrm{SF}} - A_{s,f}^{\\mathrm{FF}})$ 给出。\n\n对于种子 $s=1$：\n$$\nd_1 = \\frac{1}{3}((0.892-0.888) + (0.887-0.883) + (0.894-0.890)) = \\frac{1}{3}(0.004 + 0.004 + 0.004) = \\frac{0.012}{3} = 0.004\n$$\n对于种子 $s=2$：\n$$\nd_2 = \\frac{1}{3}((0.901-0.897) + (0.896-0.892) + (0.900-0.895)) = \\frac{1}{3}(0.004 + 0.004 + 0.005) = \\frac{0.013}{3}\n$$\n对于种子 $s=3$：\n$$\nd_3 = \\frac{1}{3}((0.880-0.874) + (0.885-0.878) + (0.882-0.876)) = \\frac{1}{3}(0.006 + 0.007 + 0.006) = \\frac{0.019}{3}\n$$\n对于种子 $s=4$：\n$$\nd_4 = \\frac{1}{3}((0.895-0.890) + (0.898-0.892) + (0.897-0.891)) = \\frac{1}{3}(0.005 + 0.006 + 0.006) = \\frac{0.017}{3}\n$$\n对于种子 $s=5$：\n$$\nd_5 = \\frac{1}{3}((0.888-0.884) + (0.889-0.885) + (0.891-0.886)) = \\frac{1}{3}(0.004 + 0.004 + 0.005) = \\frac{0.013}{3}\n$$\n\n**步骤2：计算样本均值 $\\bar{d}$。**\n样本均值是基于 $n=5$ 个观测到的差异 $\\{d_s\\}$ 计算的。\n$$\n\\sum_{s=1}^{5} d_s = \\frac{0.012}{3} + \\frac{0.013}{3} + \\frac{0.019}{3} + \\frac{0.017}{3} + \\frac{0.013}{3} = \\frac{0.012 + 0.013 + 0.019 + 0.017 + 0.013}{3} = \\frac{0.074}{3}\n$$\n样本均值 $\\bar{d}$ 是：\n$$\n\\bar{d} = \\frac{1}{n} \\sum_{s=1}^{5} d_s = \\frac{1}{5} \\left( \\frac{0.074}{3} \\right) = \\frac{0.074}{15}\n$$\n\n**步骤3：计算后验均值 $m_n$。**\n使用 $m_n$ 的公式以及给定的超参数和计算出的统计量：\n- 观测数量：$n=5$\n- 先验均值：$m_0=0$\n- 先验精度伪计数：$\\kappa_0=2$\n- 样本均值：$\\bar{d} = \\frac{0.074}{15}$\n\n$$\nm_n = \\frac{\\kappa_0 m_0 + n \\bar{d}}{\\kappa_0 + n} = \\frac{2 \\cdot 0 + 5 \\cdot \\left(\\frac{0.074}{15}\\right)}{2+5} = \\frac{5 \\cdot \\frac{0.074}{15}}{7} = \\frac{\\frac{0.074}{3}}{7} = \\frac{0.074}{21}\n$$\n\n现在，我们计算数值并按要求四舍五入到四位有效数字。\n$$\nm_n = \\frac{0.074}{21} \\approx 0.00352380952...\n$$\n第一个有效数字是千分位的3。前四位有效数字是3、5、2、3。第五位有效数字是8，它 $\\ge 5$，所以我们将第四位有效数字向上取整。\n$$\n\\mathbb{E}[\\mu \\mid \\{d_{s}\\}] \\approx 0.003524\n$$",
            "answer": "$$\\boxed{0.003524}$$"
        },
        {
            "introduction": "一个高AUC的模型在临床上可能并不可靠，如果其预测的概率值与其真实风险不符。这个问题  探讨了模型校准度的关键概念，指导我们计算预期校准误差（ECE）和布里尔分数（Brier score）等关键指标。通过这个练习，你将理解为什么一个未校准的模型，即使排序能力很强，也可能导致次优的临床决策。",
            "id": "4615254",
            "problem": "一个在一个大型自然图像语料库上预训练，然后在源医院的胸部X光片上进行微调的卷积神经网络，被部署到目标医院用于检测肺炎。在一个大小为 $N = 12$ 的留出目标域审计集上，迁移后的模型输出了肺炎的预测概率 $\\{p_i\\}_{i=1}^{N}$，以及对应的真实标签 $\\{y_i\\}_{i=1}^{N}$（其中 $y_i \\in \\{0,1\\}$），记录为以下配对 $(p_i, y_i)$:\n$(0.92, 0)$, $(0.88, 1)$, $(0.83, 1)$, $(0.77, 0)$, $(0.65, 1)$, $(0.58, 0)$, $(0.41, 1)$, $(0.36, 0)$, $(0.24, 0)$, $(0.18, 1)$, $(0.12, 0)$, $(0.05, 0)$.\n你需要使用 $B = 5$ 个等宽的区间（将 $[0,1)$ 划分为 $[0,0.2)$, $[0.2,0.4)$, $[0.4,0.6)$, $[0.6,0.8)$ 和 $[0.8,1.0]$）来评估迁移模型在该目标域数据集上的校准度。\n\n仅使用基本概率概念和合适评分规则的定义，完成以下任务：\n1. 从真实条件风险 $r(x) = \\mathbb{P}(Y=1 \\mid X=x)$ 的概念和校准度作为预测概率与经验事件频率之间一致性的定义出发，推导出一个基于分箱的有限样本期望校准误差估计器，并将布里尔分数定义为概率分类的严格合适评分规则。不要假设任何预先给定的公式；从第一性原理（全期望定律和经验近似）推导这些。\n2. 使用指定的分箱计算给定数据上的经验期望校准误差，并为相同数据计算经验布里尔分数。\n3. 使用贝叶斯决策理论和非对称的错分成本（$c_{01}$ 为假阳性成本，$c_{10}$ 为假阴性成本），解释为什么一个模型即使在迁移后其病例排序得以保留，仍能保持较高的ROC曲线下面积（AUC-ROC），但在校准不良时却会产生较差的预期临床决策效用。你的论证必须从基于估计风险的阈值决策规则的第一性原理出发，并说明校准不良如何扰动成本最优的操作点。\n\n将你最终计算出的校准度量表示为一个行向量 $\\big(\\mathrm{ECE}, \\mathrm{Brier}\\big)$，四舍五入到四位有效数字，不带单位。最终答案必须仅包含这两个按顺序排列的四舍五入后的数字。",
            "solution": "此问题经评估为有效，因为它具有科学依据、问题明确、客观，并包含了唯一解所需的所有必要信息。校准、布里尔分数和贝叶斯决策理论是机器学习模型评估中的标准概念。\n\n### 第1部分：估计器的推导\n\n#### 期望校准误差 (ECE)\n\n如果一个模型对某一事件的预测概率等于该事件的真实长期频率，那么该模型就是完美校准的。令 $X$ 为输入特征，$Y \\in \\{0, 1\\}$ 为二元输出。模型产生一个预测 $\\hat{P} = f(X)$，它是事件真实条件概率 $r(X) = \\mathbb{P}(Y=1 \\mid X)$ 的估计。完美校准要求对于任何概率值 $p \\in [0, 1]$，以下等式成立：\n$$\n\\mathbb{P}(Y=1 \\mid \\hat{P}=p) = p\n$$\n这个条件表明，在模型预测概率为 $p$ 的所有实例中，阳性实例的实际比例恰好是 $p$。\n\n对于特定的预测水平 $p$，校准误差是绝对差 $|\\mathbb{P}(Y=1 \\mid \\hat{P}=p) - p|$。为了获得模型校准度的单一汇总统计量，我们计算该误差在模型预测 $\\hat{P}$ 的分布上的期望。这就是期望校准误差 (ECE)：\n$$\n\\mathrm{ECE} = \\mathbb{E}_{\\hat{P}} \\big[ |\\mathbb{P}(Y=1 \\mid \\hat{P}) - \\hat{P}| \\big]\n$$\n外层期望是关于随机变量 $\\hat{P}$ 的。使用全期望定律，这可以写成对所有可能的预测概率值 $p$ 的积分：\n$$\n\\mathrm{ECE} = \\int_{0}^{1} |\\mathbb{P}(Y=1 \\mid \\hat{P}=p) - p| \\, f_{\\hat{P}}(p) \\, dp\n$$\n其中 $f_{\\hat{P}}(p)$ 是预测分数的概率密度函数。\n\n在实践中，对于大小为 $N$ 的有限数据集，我们无法直接计算这个积分。我们采用基于分箱的估计方法。将区间 $[0, 1]$ 划分为 $B$ 个不相交的箱体 $I_m$（$m=1, \\dots, B$）。然后，ECE 近似为每个箱体内校准误差的加权和：\n$$\n\\mathrm{ECE} \\approx \\sum_{m=1}^{B} \\mathbb{P}(\\hat{P} \\in I_m) \\cdot \\mathbb{E}\\big[ |\\mathbb{P}(Y=1 \\mid \\hat{P}) - \\hat{P}| \\mid \\hat{P} \\in I_m \\big]\n$$\n在每个箱体 $I_m$ 内，我们做两个近似。我们用该箱内预测的平均准确率 $\\mathrm{acc}(I_m) = \\mathbb{E}[Y \\mid \\hat{P} \\in I_m]$ 来近似真实条件概率 $\\mathbb{P}(Y=1 \\mid \\hat{P}=p)$（对于 $p \\in I_m$）。我们用该箱内预测的平均置信度 $\\mathrm{conf}(I_m) = \\mathbb{E}[\\hat{P} \\mid \\hat{P} \\in I_m]$ 来近似预测值 $p$。这样得到：\n$$\n\\mathrm{ECE} \\approx \\sum_{m=1}^{B} \\mathbb{P}(\\hat{P} \\in I_m) \\cdot |\\mathrm{acc}(I_m) - \\mathrm{conf}(I_m)|\n$$\n给定一个包含 $N$ 个预测 $\\{p_i\\}_{i=1}^{N}$ 和标签 $\\{y_i\\}_{i=1}^{N}$ 的有限样本，我们可以计算每一项的经验估计。令 $S_m$ 为预测 $p_i$ 落入箱体 $I_m$ 的样本索引集合，并令 $N_m = |S_m|$ 为该箱体中的样本数量。\n经验估计如下：\n\\begin{itemize}\n    \\item 箱体 $m$ 中样本的比例：$\\hat{\\mathbb{P}}(\\hat{P} \\in I_m) = \\frac{N_m}{N}$\n    \\item 箱体 $m$ 中的经验准确率：$\\widehat{\\mathrm{acc}}(I_m) = \\frac{1}{N_m} \\sum_{i \\in S_m} y_i$\n    \\item 箱体 $m$ 中的经验置信度：$\\widehat{\\mathrm{conf}}(I_m) = \\frac{1}{N_m} \\sum_{i \\in S_m} p_i$\n\\end{itemize}\n将这些代入近似式，得到 ECE 的有限样本分箱估计器：\n$$\n\\widehat{\\mathrm{ECE}} = \\sum_{m=1}^{B} \\frac{N_m}{N} \\left| \\left( \\frac{1}{N_m} \\sum_{i \\in S_m} y_i \\right) - \\left( \\frac{1}{N_m} \\sum_{i \\in S_m} p_i \\right) \\right| = \\frac{1}{N} \\sum_{m=1}^{B} \\left| \\sum_{i \\in S_m} y_i - \\sum_{i \\in S_m} p_i \\right|\n$$\n\n#### 布里尔分数\n\n一个评分规则 $S(p, y)$ 为二元结果 $y \\in \\{0, 1\\}$ 的概率性预测 $p$ 赋一个分。如果通过报告真实概率可以使期望得分最小化，则该评分规则是*合适的*（proper）。令事件的真实概率为 $q = \\mathbb{P}(Y=1)$。对于一个预测 $p$，期望得分为：\n$$\n\\mathbb{E}[S(p, Y)] = q \\cdot S(p, 1) + (1-q) \\cdot S(p, 0)\n$$\n如果 $p=q$ 使得这个期望最小化，则该规则是合适的。如果最小值是唯一的，则它是*严格合适的*（strictly proper）。\n\n布里尔分数的定义是预测与结果之间的均方误差：\n$$\nS(p, y) = (p - y)^2\n$$\n在真实概率为 $q$ 的情况下，对预测 $p$ 的期望布里尔分数为：\n$$\n\\mathbb{E}[S(p, Y)] = q(p-1)^2 + (1-q)(p-0)^2 = q(p^2 - 2p + 1) + (1-q)p^2\n$$\n为了找到使这个期望最小化的 $p$ 值，我们对 $p$ 求导并令结果为零：\n$$\n\\frac{d}{dp}\\mathbb{E}[S(p, Y)] = q(2p - 2) + (1-q)(2p) = 2qp - 2q + 2p - 2qp = 2p - 2q\n$$\n令导数为零得到 $2p - 2q = 0$，这意味着 $p=q$。二阶导数为 $\\frac{d^2}{dp^2}\\mathbb{E}[S(p, Y)] = 2$，为正值，证实了这是一个唯一的最小值。因此，布里尔分数是一个严格合适的评分规则，因为它在预测概率等于真实概率时被唯一地最小化。\n\n对于一个包含 $N$ 对 $(p_i, y_i)$ 的数据集，经验布里尔分数是各单个平方误差的平均值：\n$$\n\\mathrm{Brier} = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - y_i)^2\n$$\n\n### 第2部分：度量计算\n\n数据集包含 $N=12$ 对 $(p_i, y_i)$：\n$(0.92, 0)$, $(0.88, 1)$, $(0.83, 1)$, $(0.77, 0)$, $(0.65, 1)$, $(0.58, 0)$, $(0.41, 1)$, $(0.36, 0)$, $(0.24, 0)$, $(0.18, 1)$, $(0.12, 0)$, $(0.05, 0)$.\n箱体为 $I_1 = [0, 0.2)$, $I_2 = [0.2, 0.4)$, $I_3 = [0.4, 0.6)$, $I_4 = [0.6, 0.8)$ 和 $I_5 = [0.8, 1.0]$。\n\n**数据分箱：**\n*   **箱体 1: $I_1 = [0, 0.2)$**\n    样本: $(0.18, 1), (0.12, 0), (0.05, 0)$.\n    $N_1 = 3$.\n    $\\widehat{\\mathrm{acc}}(I_1) = \\frac{1+0+0}{3} = \\frac{1}{3}$.\n    $\\widehat{\\mathrm{conf}}(I_1) = \\frac{0.18+0.12+0.05}{3} = \\frac{0.35}{3}$.\n*   **箱体 2: $I_2 = [0.2, 0.4)$**\n    样本: $(0.36, 0), (0.24, 0)$.\n    $N_2 = 2$.\n    $\\widehat{\\mathrm{acc}}(I_2) = \\frac{0+0}{2} = 0$.\n    $\\widehat{\\mathrm{conf}}(I_2) = \\frac{0.36+0.24}{2} = \\frac{0.60}{2} = 0.3$.\n*   **箱体 3: $I_3 = [0.4, 0.6)$**\n    样本: $(0.58, 0), (0.41, 1)$.\n    $N_3 = 2$.\n    $\\widehat{\\mathrm{acc}}(I_3) = \\frac{0+1}{2} = 0.5$.\n    $\\widehat{\\mathrm{conf}}(I_3) = \\frac{0.58+0.41}{2} = \\frac{0.99}{2} = 0.495$.\n*   **箱体 4: $I_4 = [0.6, 0.8)$**\n    样本: $(0.77, 0), (0.65, 1)$.\n    $N_4 = 2$.\n    $\\widehat{\\mathrm{acc}}(I_4) = \\frac{0+1}{2} = 0.5$.\n    $\\widehat{\\mathrm{conf}}(I_4) = \\frac{0.77+0.65}{2} = \\frac{1.42}{2} = 0.71$.\n*   **箱体 5: $I_5 = [0.8, 1.0]$**\n    样本: $(0.92, 0), (0.88, 1), (0.83, 1)$.\n    $N_5 = 3$.\n    $\\widehat{\\mathrm{acc}}(I_5) = \\frac{0+1+1}{3} = \\frac{2}{3}$.\n    $\\widehat{\\mathrm{conf}}(I_5) = \\frac{0.92+0.88+0.83}{3} = \\frac{2.63}{3}$.\n\n**期望校准误差 (ECE):**\n$$\n\\widehat{\\mathrm{ECE}} = \\sum_{m=1}^{5} \\frac{N_m}{N} |\\widehat{\\mathrm{acc}}(I_m) - \\widehat{\\mathrm{conf}}(I_m)|\n$$\n$$\n\\widehat{\\mathrm{ECE}} = \\frac{3}{12}\\left|\\frac{1}{3} - \\frac{0.35}{3}\\right| + \\frac{2}{12}|0 - 0.3| + \\frac{2}{12}|0.5 - 0.495| + \\frac{2}{12}|0.5 - 0.71| + \\frac{3}{12}\\left|\\frac{2}{3} - \\frac{2.63}{3}\\right|\n$$\n$$\n\\widehat{\\mathrm{ECE}} = \\frac{1}{12} \\left( 3 \\cdot \\frac{|1-0.35|}{3} + 2 \\cdot 0.3 + 2 \\cdot 0.005 + 2 \\cdot 0.21 + 3 \\cdot \\frac{|2-2.63|}{3} \\right)\n$$\n$$\n\\widehat{\\mathrm{ECE}} = \\frac{1}{12} \\left( 0.65 + 0.6 + 0.01 + 0.42 + 0.63 \\right) = \\frac{2.31}{12} = 0.1925\n$$\n\n**布里尔分数:**\n$$\n\\mathrm{Brier} = \\frac{1}{12} \\sum_{i=1}^{12} (p_i - y_i)^2\n$$\n$$\n\\mathrm{Brier} = \\frac{1}{12} \\Big[ (0.92-0)^2 + (0.88-1)^2 + (0.83-1)^2 + (0.77-0)^2 + (0.65-1)^2 + (0.58-0)^2 + (0.41-1)^2 + (0.36-0)^2 + (0.24-0)^2 + (0.18-1)^2 + (0.12-0)^2 + (0.05-0)^2 \\Big]\n$$\n$$\n\\mathrm{Brier} = \\frac{1}{12} \\Big[ 0.8464 + 0.0144 + 0.0289 + 0.5929 + 0.1225 + 0.3364 + 0.3481 + 0.1296 + 0.0576 + 0.6724 + 0.0144 + 0.0025 \\Big]\n$$\n$$\n\\mathrm{Brier} = \\frac{3.1661}{12} \\approx 0.26384166...\n$$\n四舍五入到四位有效数字，布里尔分数为 $0.2638$。\n\n### 第3部分：校准不良与临床效用\n\nROC曲线下面积（AUC-ROC）是衡量模型区分不同类别能力的一个指标。它的计算方法是对所有假阳性率（FPR）值积分真阳性率（TPR），这等价于一个随机选择的阳性样本排名高于一个随机选择的阴性样本的概率。因此，AUC-ROC 对模型输出分数的任何严格递增的单调变换都是不变的，因为这种变换保留了样本的排序。\n\n然而，临床决策效用并不仅仅取决于排序。它取决于最小化决策的期望成本。根据贝叶斯决策理论，我们定义错分成本：$c_{01}$ 为假阳性（真实值为0时预测为1）的成本，$c_{10}$ 为假阴性（真实值为1时预测为0）的成本。对于一个具有特征 $X$ 的给定病例，预测“肺炎”（$Y=1$）或“无肺炎”（$Y=0$）的决策是基于最小化期望成本。\n\n令 $r(X) = \\mathbb{P}(Y=1 \\mid X)$ 为真实条件风险。\n预测 $Y=1$ 的期望成本是 $C_1(X) = c_{01} \\cdot \\mathbb{P}(Y=0 \\mid X) = c_{01}(1-r(X))$。\n预测 $Y=0$ 的期望成本是 $C_0(X) = c_{10} \\cdot \\mathbb{P}(Y=1 \\mid X) = c_{10} r(X)$。\n\n贝叶斯最优决策规则是，如果 $C_1(X) < C_0(X)$，则预测 $Y=1$，即：\n$$\nc_{01}(1-r(X)) < c_{10} r(X) \\implies c_{01} < (c_{10} + c_{01}) r(X) \\implies r(X) > \\frac{c_{01}}{c_{01} + c_{10}}\n$$\n这在真实风险 $r(X)$ 上定义了一个最优决策阈值 $\\tau^* = \\frac{c_{01}}{c_{01} + c_{10}}$。由于我们不知道 $r(X)$，我们使用模型的输出 $p(X)$ 作为估计。实际的决策规则变为：如果 $p(X) > \\tau^*$，则预测 $Y=1$。这个规则只有在模型完美校准时，即 $p(X) = r(X)$ 时，才是最优的。\n\n当一个模型被迁移到一个新的领域时，由于领域漂移，它可能会变得校准不良。这意味着预测概率和真实风险之间的关系被扭曲了，例如，$p(X) = f(r(X))$ 其中 $f(z) \\ne z$。例如，模型可能会系统性地变得过于自信，因此 $p(X) > r(X)$。即使这种扭曲 $f$ 是单调的（保留了病例的排序，从而保留了AUC-ROC），决策效用也会受到损害。\n\n通过将阈值 $\\tau^*$ 应用于校准不良的分数 $p(X)$，决策规则是 $p(X) > \\tau^*$，这等价于 $f(r(X)) > \\tau^*$。假设 $f$ 是可逆的，这变为 $r(X) > f^{-1}(\\tau^*)$。应用于真实风险的有效阈值是 $\\tau_{eff} = f^{-1}(\\tau^*)$。\n\n如果模型校准不良，$f(z) \\ne z$，这意味着 $f^{-1}(z) \\ne z$，因此 $\\tau_{eff} \\ne \\tau^*$。我们现在是在ROC曲线上的一个次优点上操作，这意味着我们的决策规则不再是最小化期望成本。例如，如果模型过于自信（$f(z) > z$），那么 $f^{-1}(z) < z$，导致 $\\tau_{eff} < \\tau^*$。这意味着我们在预测肺炎时过于激进，导致更多的假阳性，以及比最优情况更高的总期望成本。\n\n总之，即使一个模型在迁移后保持了较高的AUC-ROC（良好的排序），其校准不良也会导致成本最优决策阈值与模型输出尺度之间的不匹配。将理论上的最优阈值应用于校准不良的概率会导致次优的决策策略，从而降低模型的预期临床效用。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.1925  0.2638\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "评估一个医学影像模型最终要回答的问题是：它在临床实践中真的有用吗？决策曲线分析（DCA）为我们提供了一个量化模型临床效用的强大框架。在这个练习  中，你将学习如何计算“净获益”（net benefit），这是一个关键指标，它衡量了使用模型进行决策相对于“全部干预”或“全不干预”等默认策略所带来的额外价值。",
            "id": "4615284",
            "problem": "一个用于乳腺X线摄影中恶性肿瘤检测的深度卷积神经网络，在一个大型公共数据集上进行了预训练，然后使用迁移学习（TL）适应了一家新医院的数据。由于域偏移，该模型在目标域中的预测概率需要使用逻辑斯谛重新校准进行校准，从而在对数优势比标度上产生一个校准截距 $\\alpha$ 和斜率 $\\beta$。临床采纳基于一个决策规则：如果预测的恶性肿瘤概率至少为阈值概率 $p_t$，则进行干预。决策曲线分析（DCA）通过量化模型在选定 $p_t$ 下的净获益来评估临床效用，该 $p_t$ 编码了假阳性与真阳性之间的相对危害-效益权衡。\n\n在包含 $N = 3000$ 名患者的目标域测试集中，疾病患病率为 $0.12$。在阈值概率 $p_t = 0.20$ 时，重新校准的迁移模型产生 $TP = 230$ 个真阳性和 $FP = 220$ 个假阳性。为了可解释性，未校准的迁移模型在相同阈值下产生 $TP = 240$ 和 $FP = 360$。\n\n仅使用二元决策的预期效用基本定义以及阈值概率 $p_t$ 如何编码危害与效益的相对权重，计算重新校准的迁移模型在此目标域测试集上，在 $p_t = 0.20$ 时的净获益。将您的答案表示为小数，并四舍五入到五位有效数字。不需要单位。",
            "solution": "问题陈述已经过验证，被认为是科学上合理的、问题定义明确且客观的。它呈现了医疗机器学习模型评估中的一个标准场景。计算所需的所有数据均已提供，并且内部一致。该问题是有效的。\n\n任务是计算重新校准的迁移模型在给定决策阈值下的净获益。净获益的概念是决策曲线分析（DCA）的核心，它源于预期效用理论。对于一个二元分类问题，决策规则是：如果事件的预测概率 $p$ 大于或等于阈值概率 $p_t$，则进行干预。这个阈值 $p_t$ 意味着在真阳性（治疗患病患者）的益处与假阳性（治疗未患病患者）的危害之间存在特定的权衡。\n\n净获益是真阳性比例与加权假阳性比例之间的差值，其中权重因子由阈值 $p_t$ 决定。净获益 $\\text{NB}$ 的基本公式如下：\n$$\n\\text{NB}(p_t) = \\frac{TP}{N} - \\frac{FP}{N} \\left( \\frac{p_t}{1-p_t} \\right)\n$$\n其中：\n- $TP$ 是真阳性的数量。\n- $FP$ 是假阳性的数量。\n- $N$ 是队列中患者的总数。\n- $p_t$ 是决策规则的阈值概率。\n\n项 $\\frac{p_t}{1-p_t}$ 表示在阈值下事件的优势比。在DCA的背景下，它被解释为交换率，即为了检测到每一个真阳性，愿意容忍的假阳性数量。\n\n问题为在目标域集上测试的重新校准模型提供了以下值：\n- 患者总数, $N = 3000$。\n- 真阳性数量, $TP = 230$。\n- 假阳性数量, $FP = 220$。\n- 决策阈值概率, $p_t = 0.20$。\n\n有关未校准模型（$TP = 240$, $FP = 360$）、疾病患病率（$0.12$）以及模型性质（深度卷积神经网络、迁移学习、逻辑斯谛重新校准）的信息提供了背景，但由于已明确给出 $TP$ 和 $FP$ 值，因此对于计算指定重新校准模型的净获益并非直接必需。\n\n首先，我们根据阈值概率 $p_t$ 计算权重因子：\n$$\n\\frac{p_t}{1-p_t} = \\frac{0.20}{1 - 0.20} = \\frac{0.20}{0.80} = \\frac{1}{4} = 0.25\n$$\n接下来，我们将给定值代入净获益公式：\n$$\n\\text{NB}(0.20) = \\frac{230}{3000} - \\frac{220}{3000} \\left( 0.25 \\right)\n$$\n我们可以提出因子 $\\frac{1}{3000}$ 来简化计算：\n$$\n\\text{NB}(0.20) = \\frac{1}{3000} \\left( 230 - (220 \\times 0.25) \\right)\n$$\n计算括号内的乘积：\n$$\n220 \\times 0.25 = 220 \\times \\frac{1}{4} = 55\n$$\n现在将此结果代回净获益的表达式中：\n$$\n\\text{NB}(0.20) = \\frac{1}{3000} (230 - 55) = \\frac{175}{3000}\n$$\n为了得到最终的小数值，我们执行除法运算：\n$$\n\\text{NB}(0.20) = \\frac{175}{3000} = 0.058333...\n$$\n问题要求答案以小数形式表示，并四舍五入到五位有效数字。计算结果为 0.058333...。将此数值四舍五入到五位有效数字，得到 0.05833。",
            "answer": "$$\\boxed{0.05833}$$"
        }
    ]
}