{
    "hands_on_practices": [
        {
            "introduction": "This first practice grounds the abstract definition of $\\epsilon$-differential privacy in a tangible computational exercise. You will start by deriving the scale parameter for the Laplace mechanism, the workhorse of $\\epsilon$-DP, directly linking the privacy parameter $\\epsilon$ to the magnitude of noise. By simulating the noise and comparing it to the analytical probability, this exercise provides a concrete intuition for the trade-offs between privacy levels and data accuracy. ",
            "id": "4556484",
            "problem": "Consider releasing an integer-valued count derived from a health registry query (for example, the number of individuals with a specific diagnosis in a hospital’s database) under the mathematical framework of Differential Privacy (DP). Let two datasets be called neighboring datasets if they differ in the records of exactly one individual. Let the query function be a deterministic count with global sensitivity defined as the maximum change in the function’s output over all neighboring datasets. Suppose a mechanism releases the noisy result by adding noise drawn from a centered Laplace distribution. Starting from the formal definition of $\\epsilon$-Differential Privacy (DP) and the definition of global sensitivity, derive the necessary condition on the noise distribution such that the mechanism satisfies $\\epsilon$-DP, and from this condition, derive the scale parameter of the Laplace distribution required for a count query with a given sensitivity. Then, for the specific parameter values provided below, compute the Laplace noise scale and estimate, by Monte Carlo simulation, the probability that the absolute deviation between the released value and the true count is at least a specified nonnegative threshold. The probability must be expressed as a decimal.\n\nFundamental base to use:\n- The formal definition of $\\epsilon$-Differential Privacy (DP): for all measurable sets $S$ and all neighboring datasets $D$ and $D'$, the mechanism $\\mathcal{M}$ must satisfy $\\Pr[\\mathcal{M}(D) \\in S] \\leq e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S]$.\n- The global sensitivity of a function $f$ is $\\Delta f = \\max_{D,D'} \\lvert f(D) - f(D') \\rvert$ over all neighboring datasets $D$ and $D'$.\n- The Laplace distribution with location $0$ and scale $b$ has probability density function $p(x) = \\frac{1}{2b} \\exp\\!\\left(-\\frac{\\lvert x \\rvert}{b}\\right)$.\n\nTasks:\n- Using the above foundational definitions, derive the scale parameter $b$ of the Laplace distribution required to achieve $\\epsilon$-DP for a deterministic count query with global sensitivity $\\Delta f$.\n- For each test case, compute the scale $b$ and estimate, by Monte Carlo with a fixed random seed, the probability $\\Pr(\\lvert X \\rvert \\geq \\tau)$ where $X$ is the Laplace noise added to the true count and $\\tau \\ge 0$ is the threshold. Also compute the exact probability analytically as a function of $b$ and $\\tau$ derived from the Laplace distribution.\n\nSimulation protocol:\n- For each test case, draw $N$ independent samples from $\\mathrm{Laplace}(0,b)$ and estimate the deviation probability as the fraction of samples with $\\lvert X \\rvert \\geq \\tau$.\n- Use a fixed random seed of $123456$ for reproducibility.\n\nTest suite:\n- Case $1$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $2$: $\\epsilon = 0.05$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $3$: $\\epsilon = 5.0$, $\\Delta f = 1$, $\\tau = 3$, $N = 200000$.\n- Case $4$: $\\epsilon = 0.5$, $\\Delta f = 2$, $\\tau = 3$, $N = 200000$.\n- Case $5$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 0$, $N = 200000$.\n- Case $6$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 3.5$, $N = 200000$.\n- Case $7$: $\\epsilon = 0.5$, $\\Delta f = 1$, $\\tau = 50$, $N = 200000$.\n\nAnswer specification:\n- For each test case, output a list containing three floating-point numbers: the Laplace scale $b$, the simulated probability estimate, and the exact analytical probability. Each number must be reported as a decimal, and each result must be rounded to six decimal places.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list of the three rounded decimals in the order $[b, p_{\\text{sim}}, p_{\\text{exact}}]$. For example, the format is $[[b_1,p_{\\text{sim},1},p_{\\text{exact},1}],[b_2,p_{\\text{sim},2},p_{\\text{exact},2}],\\dots]$.",
            "solution": "The problem requires a formal derivation of the scale parameter for the Laplace mechanism in differential privacy, followed by a computational analysis for several test cases. The analysis involves both a Monte Carlo simulation and an analytical calculation of a deviation probability.\n\n### Step 1: Derivation of the Laplace Scale Parameter\n\nThe objective is to determine the scale parameter $b$ of a centered Laplace distribution such that adding noise drawn from this distribution to the output of a function $f$ satisfies $\\epsilon$-differential privacy ($\\epsilon$-DP).\n\nLet $f: \\mathcal{D}^n \\to \\mathbb{Z}$ be a deterministic integer-valued count query. The mechanism $\\mathcal{M}$ releases a noisy version of the query result: $\\mathcal{M}(D) = f(D) + X$, where $X$ is a random variable drawn from a Laplace distribution with location $0$ and scale $b > 0$. The probability density function (PDF) of this noise is $p(x) = \\frac{1}{2b} \\exp(-\\frac{\\lvert x \\rvert}{b})$.\n\nThe probability of the mechanism $\\mathcal{M}$ on a database $D$ producing an output $z \\in \\mathbb{R}$ is given by the PDF of the noise evaluated at $z - f(D)$:\n$$\np(z|D) = \\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D) \\rvert}{b}\\right)\n$$\n\nThe definition of $\\epsilon$-DP states that for any two neighboring datasets $D$ and $D'$ (differing by one individual's record) and for any set of possible outputs $S$, the following inequality must hold:\n$$\n\\Pr[\\mathcal{M}(D) \\in S] \\leq e^{\\epsilon} \\Pr[\\mathcal{M}(D') \\in S]\n$$\nThis condition is satisfied if, for any possible output $z$, the ratio of the probability densities is bounded:\n$$\n\\frac{p(z|D)}{p(z|D')} \\leq e^{\\epsilon}\n$$\nLet us evaluate this ratio:\n$$\n\\frac{p(z|D)}{p(z|D')} = \\frac{\\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D) \\rvert}{b}\\right)}{\\frac{1}{2b} \\exp\\left(-\\frac{\\lvert z - f(D') \\rvert}{b}\\right)} = \\exp\\left(\\frac{\\lvert z - f(D') \\rvert - \\lvert z - f(D) \\rvert}{b}\\right)\n$$\nTo ensure the DP condition, we must bound the term in the exponent. By the reverse triangle inequality, $\\lvert a \\rvert - \\lvert c \\rvert \\leq \\lvert a - c \\rvert$. Let $a = z - f(D')$ and $c = z - f(D)$. Then:\n$$\n\\lvert z - f(D') \\rvert - \\lvert z - f(D) \\rvert \\leq \\lvert (z - f(D')) - (z - f(D)) \\rvert = \\lvert f(D) - f(D') \\rvert\n$$\nThe global sensitivity, $\\Delta f$, is defined as the maximum possible value of this difference over all pairs of neighboring datasets $D, D'$:\n$$\n\\Delta f = \\max_{D,D'} \\lvert f(D) - f(D') \\rvert\n$$\nFor a simple count query, where adding or removing one individual's record changes the count by at most $1$, the global sensitivity is $\\Delta f = 1$.\n\nSubstituting this maximum into our inequality for the exponent yields the upper bound for the probability ratio:\n$$\n\\frac{p(z|D)}{p(z|D')} \\leq \\exp\\left(\\frac{\\Delta f}{b}\\right)\n$$\nTo satisfy $\\epsilon$-DP, this bound must be no greater than $e^{\\epsilon}$:\n$$\n\\exp\\left(\\frac{\\Delta f}{b}\\right) \\leq e^{\\epsilon}\n$$\nTaking the natural logarithm of both sides gives:\n$$\n\\frac{\\Delta f}{b} \\leq \\epsilon\n$$\nTo add the minimum amount of noise that satisfies the privacy guarantee (i.e., to maximize utility), we select the smallest possible value for $b$, which is achieved at equality:\n$$\nb = \\frac{\\Delta f}{\\epsilon}\n$$\nThis is the required scale parameter for the Laplace mechanism to achieve $\\epsilon$-DP for a function with global sensitivity $\\Delta f$.\n\n### Step 2: Analytical Calculation of Deviation Probability\n\nThe problem asks for the probability that the absolute deviation of the noise, $\\lvert X \\rvert$, is at least some threshold $\\tau \\geq 0$, where $X \\sim \\mathrm{Laplace}(0,b)$.\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau)\n$$\nThis is equivalent to $1 - \\Pr(\\lvert X \\rvert < \\tau) = 1 - \\Pr(-\\tau < X < \\tau)$. Alternatively, due to the symmetry of the Laplace distribution around $0$, we can write:\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau) = \\Pr(X \\geq \\tau) + \\Pr(X \\leq -\\tau) = 2 \\Pr(X \\geq \\tau)\n$$\nWe compute $\\Pr(X \\geq \\tau)$ by integrating the PDF from $\\tau$ to $\\infty$. For $x \\geq \\tau \\geq 0$, $\\lvert x \\rvert = x$:\n$$\n\\Pr(X \\geq \\tau) = \\int_{\\tau}^{\\infty} \\frac{1}{2b} \\exp\\left(-\\frac{x}{b}\\right) dx\n$$\n$$\n= \\frac{1}{2b} \\left[ -b \\exp\\left(-\\frac{x}{b}\\right) \\right]_{\\tau}^{\\infty} = -\\frac{1}{2} \\left[ \\lim_{x \\to \\infty} \\exp\\left(-\\frac{x}{b}\\right) - \\exp\\left(-\\frac{\\tau}{b}\\right) \\right]\n$$\n$$\n= -\\frac{1}{2} \\left[ 0 - \\exp\\left(-\\frac{\\tau}{b}\\right) \\right] = \\frac{1}{2} \\exp\\left(-\\frac{\\tau}{b}\\right)\n$$\nTherefore, the total probability is:\n$$\n\\Pr(\\lvert X \\rvert \\geq \\tau) = 2 \\times \\frac{1}{2} \\exp\\left(-\\frac{\\tau}{b}\\right) = \\exp\\left(-\\frac{\\tau}{b}\\right)\n$$\nFor the special case where $\\tau = 0$, the probability is $\\exp(0) = 1$, as expected.\n\n### Step 3: Computational Implementation\n\nFor each test case defined by parameters $(\\epsilon, \\Delta f, \\tau, N)$:\n1.  The Laplace scale parameter is computed as $b = \\Delta f / \\epsilon$.\n2.  A Monte Carlo simulation is performed. A total of $N=200000$ random samples are drawn from the $\\mathrm{Laplace}(0, b)$ distribution using a fixed random seed of $123456$ for reproducibility.\n3.  The simulated probability, $p_{\\text{sim}}$, is estimated as the fraction of samples whose absolute value is greater than or equal to the threshold $\\tau$.\n4.  The exact analytical probability, $p_{\\text{exact}}$, is computed using the derived formula $p_{\\text{exact}} = \\exp(-\\tau/b)$.\n5.  The results for each test case, consisting of the scale $b$, the simulated probability $p_{\\text{sim}}$, and the exact probability $p_{\\text{exact}}$, are rounded to six decimal places. The final output is a list of these results, formatted as specified.",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the differential privacy problem for the given test suite.\n    \n    For each case, it computes:\n    1. The Laplace scale parameter 'b'.\n    2. The simulated probability that the noise exceeds a threshold.\n    3. The exact analytical probability for the same event.\n    \"\"\"\n\n    # Test suite as specified in the problem statement.\n    # Each case is a tuple: (epsilon, delta_f, tau, N)\n    test_cases = [\n        (0.5, 1, 3, 200000),   # Case 1\n        (0.05, 1, 3, 200000),  # Case 2\n        (5.0, 1, 3, 200000),   # Case 3\n        (0.5, 2, 3, 200000),   # Case 4\n        (0.5, 1, 0, 200000),   # Case 5\n        (0.5, 1, 3.5, 200000), # Case 6\n        (0.5, 1, 50, 200000)   # Case 7\n    ]\n\n    # Initialize the random number generator with a fixed seed for reproducibility.\n    # The use of default_rng is the modern, recommended practice in NumPy.\n    rng = np.random.default_rng(123456)\n\n    all_results = []\n\n    for epsilon, delta_f, tau, N in test_cases:\n        # Step 1: Compute the Laplace scale parameter 'b'.\n        # b = sensitivity / epsilon\n        if epsilon <= 0:\n            # Epsilon must be positive. Handle this edge case, though not in test suite.\n            b = np.inf\n        else:\n            b = delta_f / epsilon\n\n        # Step 2: Estimate the probability via Monte Carlo simulation.\n        # Draw N samples from the Laplace distribution with location 0 and scale b.\n        laplace_samples = rng.laplace(loc=0.0, scale=b, size=N)\n        \n        # Count the number of samples where the absolute value is >= tau.\n        deviation_count = np.sum(np.abs(laplace_samples) >= tau)\n        \n        # The simulated probability is the fraction of such samples.\n        p_sim = deviation_count / N\n\n        # Step 3: Compute the exact analytical probability.\n        # The probability is P(|X| >= tau) = exp(-tau / b) for X ~ Laplace(0, b).\n        if b == 0: # Sensitivity is 0\n            p_exact = 1.0 if tau == 0 else 0.0\n        elif np.isinf(b): # Epsilon is 0\n            p_exact = 1.0 # Infinite noise, always deviates\n        else:\n            p_exact = np.exp(-tau / b)\n\n        # Store the results, rounded to six decimal places, as required.\n        result_triplet = [b, p_sim, p_exact]\n        all_results.append(result_triplet)\n\n    # Format the final output string as a list of lists of floats,\n    # with each number formatted to six decimal places.\n    case_strings = []\n    for res in all_results:\n        # rounding is done here before formatting to match the requirement\n        b_rounded = round(res[0], 6)\n        psim_rounded = round(res[1], 6)\n        pexact_rounded = round(res[2], 6)\n\n        # f-string formatting ensures trailing zeros are printed for 6 decimal places\n        b_str = f\"{b_rounded:.6f}\"\n        psim_str = f\"{psim_rounded:.6f}\"\n        pexact_str = f\"{pexact_rounded:.6f}\"\n        case_strings.append(f\"[{b_str},{psim_str},{pexact_str}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "Building on the understanding of noise calibration, we now turn to a critical question of utility: how does the added noise affect the reliability of our analysis? This exercise is particularly relevant for health data, where we often study rare conditions. You will formally derive the expected relative error for a differentially private count, revealing a fundamental challenge of DP: the difficulty of accurately measuring small populations while preserving privacy. ",
            "id": "4556467",
            "problem": "A national health registry contains records for $N$ individuals. Let $f(D)$ denote the count query that returns the number of individuals in dataset $D$ who have a particular rare disease. The agency wishes to publish a privacy-preserving estimate of this count under Differential Privacy (DP), specifically $\\epsilon$-differential privacy, using the Laplace mechanism with no post-processing such as clipping or rounding. Adjacency is defined by the addition or removal of a single individual’s record.\n\nStarting from the formal definition of $\\epsilon$-differential privacy and the notion of global sensitivity for a function $f$, justify the calibration of the Laplace mechanism for count queries and explain, from first principles, why rare disease count queries have high relative error under DP. Then, derive the expected relative error of the released count when the true count is $c \\geq 1$, the function’s global sensitivity is $1$, and the Laplace mechanism is used with the standard scale calibration to privacy parameter $\\epsilon$.\n\nFormally, let the released count be $\\hat{c} = c + Z$, where $Z$ is a Laplace random variable centered at $0$ with the scale chosen to satisfy $\\epsilon$-differential privacy for a function with global sensitivity $1$. Define the relative error for a fixed true count $c$ as\n$$\nR(c,\\epsilon) \\equiv \\mathbb{E}\\left[\\frac{|\\hat{c} - c|}{c}\\right],\n$$\nwhere the expectation is taken over the randomness of the mechanism. Derive $R(c,\\epsilon)$ in closed form as a function of $c$ and $\\epsilon$. Express your final answer as an analytic expression; no rounding is required. In your derivation, clearly state any assumptions you make and ensure scientific realism in the context of health data.",
            "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded in the established mathematical theory of differential privacy, is well-posed with a clear objective, and contains all necessary information for a rigorous derivation.\n\nThe problem requires a three-part response: a justification for the calibration of the Laplace mechanism, an explanation for the high relative error in rare event counts, and a formal derivation of the expected relative error. We will address each in turn.\n\nFirst, we establish the foundational principles. The mechanism $\\mathcal{M}$ provides $\\epsilon$-differential privacy if for any two adjacent datasets $D_1$ and $D_2$ (differing by one individual's record), and for any set of possible outputs $S$, the following inequality holds:\n$$\n\\text{Pr}[\\mathcal{M}(D_1) \\in S] \\le \\exp(\\epsilon) \\cdot \\text{Pr}[\\mathcal{M}(D_2) \\in S]\n$$\nThe Laplace mechanism adds noise to the output of a function $f$. It is defined as $\\mathcal{M}(D) = f(D) + Z$, where $Z$ is a random variable drawn from a Laplace distribution with mean $0$ and scale parameter $b$, denoted $Z \\sim \\text{Lap}(0, b)$. The probability density function (PDF) of $Z$ is $p(z) = \\frac{1}{2b} \\exp\\left(-\\frac{|z|}{b}\\right)$.\n\nThe amount of noise required is determined by the global sensitivity of the function $f$, denoted $\\Delta f$. Global sensitivity is the maximum possible change in the function's output when one individual's record is added or removed from the dataset. For a real-valued function, it is defined as:\n$$\n\\Delta f = \\max_{D_1, D_2} |f(D_1) - f(D_2)|\n$$\nwhere the maximum is taken over all pairs of adjacent datasets $D_1$ and $D_2$. For a count query, such as counting individuals with a specific disease, adding or removing a single record can change the total count by at most $1$. Thus, the global sensitivity is $\\Delta f = 1$.\n\nNow, we justify the calibration of the scale parameter $b$. For any output value $y$, the ratio of probabilities for the Laplace mechanism on adjacent datasets $D_1$ and $D_2$ is:\n$$\n\\frac{\\text{Pr}[\\mathcal{M}(D_1) = y]}{\\text{Pr}[\\mathcal{M}(D_2) = y]} = \\frac{\\frac{1}{2b} \\exp\\left(-\\frac{|y - f(D_1)|}{b}\\right)}{\\frac{1}{2b} \\exp\\left(-\\frac{|y - f(D_2)|}{b}\\right)} = \\exp\\left(\\frac{|y - f(D_2)| - |y - f(D_1)|}{b}\\right)\n$$\nBy the reverse triangle inequality, we have $|y - f(D_2)| - |y - f(D_1)| \\le |f(D_1) - f(D_2)|$. The right-hand side is bounded by the global sensitivity, $|f(D_1) - f(D_2)| \\le \\Delta f$. Therefore,\n$$\n\\frac{\\text{Pr}[\\mathcal{M}(D_1) = y]}{\\text{Pr}[\\mathcal{M}(D_2) = y]} \\le \\exp\\left(\\frac{\\Delta f}{b}\\right)\n$$\nTo satisfy $\\epsilon$-differential privacy, we require this ratio to be no more than $\\exp(\\epsilon)$. This leads to the condition $\\exp\\left(\\frac{\\Delta f}{b}\\right) \\le \\exp(\\epsilon)$, which simplifies to $\\frac{\\Delta f}{b} \\le \\epsilon$, or $b \\ge \\frac{\\Delta f}{\\epsilon}$. The standard calibration uses the minimum amount of noise necessary to satisfy the privacy guarantee, so we choose $b = \\frac{\\Delta f}{\\epsilon}$. For a count query with $\\Delta f = 1$, the scale parameter is precisely $b = \\frac{1}{\\epsilon}$. This completes the justification of the mechanism's calibration.\n\nSecond, we explain why rare disease count queries have high relative error. The noise added by the Laplace mechanism has a magnitude whose scale is determined by $b = \\frac{\\Delta f}{\\epsilon}$. For a count query, this noise scale is $b = \\frac{1}{\\epsilon}$. Crucially, the magnitude of the noise is independent of the true count $c = f(D)$. The absolute error is given by $|\\hat{c} - c| = |Z|$, and its expected value is $\\mathbb{E}[|Z|] = b = \\frac{1}{\\epsilon}$. The relative error, however, is the ratio of the absolute error to the true count, $\\frac{|\\hat{c} - c|}{c}$. When a disease is rare, the true count $c$ is a small integer. A constant expected absolute error of $\\frac{1}{\\epsilon}$ divided by a small value $c$ results in a large relative error. For instance, if $\\epsilon = 0.1$ and the true count is $c=2$, the expected absolute error is $10$, which is five times the true count, indicating extremely poor utility. Formally, the expected relative error is approximately $\\frac{\\mathbb{E}[|Z|]}{c} = \\frac{1}{c\\epsilon}$, which is inversely proportional to $c$. As $c \\to 0$ (for $c \\ge 1$), this error diverges.\n\nThird, we derive the exact expression for the expected relative error $R(c, \\epsilon)$. The definition is given as:\n$$\nR(c, \\epsilon) \\equiv \\mathbb{E}\\left[\\frac{|\\hat{c} - c|}{c}\\right]\n$$\nThe problem states that the released count is $\\hat{c} = c + Z$, where $c$ is the true count and $Z$ is the Laplace noise. Substituting this into the definition:\n$$\n|\\hat{c} - c| = |(c + Z) - c| = |Z|\n$$\nThe expression for $R(c, \\epsilon)$ becomes:\n$$\nR(c, \\epsilon) = \\mathbb{E}\\left[\\frac{|Z|}{c}\\right]\n$$\nSince $c$ is a fixed, non-random quantity (the true count is assumed to be a specific value for this expectation), we can factor it out of the expectation:\n$$\nR(c, \\epsilon) = \\frac{1}{c} \\mathbb{E}[|Z|]\n$$\nWe must now calculate the expected absolute value of the Laplace noise variable $Z$. As established, $Z \\sim \\text{Lap}(0, b)$ with $b = \\frac{\\Delta f}{\\epsilon} = \\frac{1}{\\epsilon}$ for a count query. The PDF of $Z$ is:\n$$\np(z) = \\frac{1}{2b} \\exp\\left(-\\frac{|z|}{b}\\right) = \\frac{\\epsilon}{2} \\exp(-\\epsilon|z|)\n$$\nThe expectation $\\mathbb{E}[|Z|]$ is computed by the integral:\n$$\n\\mathbb{E}[|Z|] = \\int_{-\\infty}^{\\infty} |z| p(z) dz = \\int_{-\\infty}^{\\infty} |z| \\frac{\\epsilon}{2} \\exp(-\\epsilon|z|) dz\n$$\nSince the integrand is an even function of $z$, we can simplify the integral:\n$$\n\\mathbb{E}[|Z|] = 2 \\int_{0}^{\\infty} z \\frac{\\epsilon}{2} \\exp(-\\epsilon z) dz = \\epsilon \\int_{0}^{\\infty} z \\exp(-\\epsilon z) dz\n$$\nThis integral can be solved using integration by parts. Let $u = z$ and $dv = \\exp(-\\epsilon z) dz$. Then $du = dz$ and $v = -\\frac{1}{\\epsilon}\\exp(-\\epsilon z)$.\n$$\n\\int z \\exp(-\\epsilon z) dz = z \\left(-\\frac{1}{\\epsilon}\\exp(-\\epsilon z)\\right) - \\int \\left(-\\frac{1}{\\epsilon}\\exp(-\\epsilon z)\\right) dz = -\\frac{z}{\\epsilon}\\exp(-\\epsilon z) - \\frac{1}{\\epsilon^2}\\exp(-\\epsilon z)\n$$\nEvaluating the definite integral from $0$ to $\\infty$:\n$$\n\\int_{0}^{\\infty} z \\exp(-\\epsilon z) dz = \\left[-\\frac{z}{\\epsilon}\\exp(-\\epsilon z) - \\frac{1}{\\epsilon^2}\\exp(-\\epsilon z)\\right]_{0}^{\\infty}\n$$\nAt the upper limit $z \\to \\infty$, both terms go to $0$ because the exponential decay dominates the linear term $z$. At the lower limit $z=0$, the first term is $0$ and the second term is $-\\frac{1}{\\epsilon^2}\\exp(0) = -\\frac{1}{\\epsilon^2}$.\n$$\n\\int_{0}^{\\infty} z \\exp(-\\epsilon z) dz = (0) - \\left(0 - \\frac{1}{\\epsilon^2}\\right) = \\frac{1}{\\epsilon^2}\n$$\nSubstituting this result back into the expression for $\\mathbb{E}[|Z|]$:\n$$\n\\mathbb{E}[|Z|] = \\epsilon \\left(\\frac{1}{\\epsilon^2}\\right) = \\frac{1}{\\epsilon}\n$$\nThis confirms that the mean absolute deviation for a Laplace distribution with scale $b$ is indeed $b$. In our case $b=1/\\epsilon$.\n\nFinally, we substitute this result into our expression for the expected relative error:\n$$\nR(c, \\epsilon) = \\frac{1}{c} \\mathbb{E}[|Z|] = \\frac{1}{c} \\left(\\frac{1}{\\epsilon}\\right) = \\frac{1}{c\\epsilon}\n$$\nThis is the closed-form expression for the expected relative error of a differentially private count query using the Laplace mechanism, for a true count $c \\geq 1$.",
            "answer": "$$\\boxed{\\frac{1}{c\\epsilon}}$$"
        },
        {
            "introduction": "Our final practice generalizes from simple counts to the more complex, vector-valued queries common in real-world data analysis, such as generating a histogram of diagnostic codes. The core challenge in applying differential privacy to such queries is correctly calculating the global sensitivity, which determines the amount of noise needed. This exercise will guide you through calculating the $L_1$ sensitivity for a contingency table under a realistic per-patient contribution limit, a crucial skill for implementing DP in practice. ",
            "id": "4556485",
            "problem": "A health system maintains a de-identified dataset of patients with diagnostic codes from the International Classification of Diseases, 10th Revision (ICD-10). Let there be $m$ distinct ICD-10 codes of interest, indexed by $j \\in \\{1,2,\\dots,m\\}$. Consider a dataset $\\mathcal{D}$ consisting of $n$ patients, where each patient $i$ contributes a set $S_i \\subseteq \\{1,2,\\dots,m\\}$ of unique codes present in that patient’s record. Prior to aggregation, a contribution bounding step is applied so that for every patient $i$, $|S_i| \\leq k$, that is, each patient can contribute to at most $k$ distinct codes.\n\nDefine the query function $f$ that maps a dataset to the contingency table of code counts,\n$$\nf(\\mathcal{D}) = \\big(c_1, c_2, \\dots, c_m\\big),\n$$\nwhere $c_j$ is the number of patients in $\\mathcal{D}$ whose set $S_i$ contains code $j$. Two datasets $\\mathcal{D}$ and $\\mathcal{D}'$ are said to be user-level adjacent if they differ by the addition or removal of exactly one patient record (including all codes contributed by that patient).\n\nStarting from first principles of differential privacy, compute the global sensitivity of $f$ with respect to the $L_1$ norm under user-level adjacency, expressed as a closed-form symbolic expression in terms of $k$. The final answer must be a single closed-form expression with no units. Do not round.",
            "solution": "The goal is to compute the global sensitivity of the contingency table query $f$ under user-level adjacency with respect to the $L_1$ norm, using foundational definitions from differential privacy.\n\nFirst, recall the core definition of global sensitivity for a function $f$ under a specified adjacency relation. For vector-valued queries and the $L_1$ norm, the global sensitivity is defined as\n$$\n\\Delta_1(f) = \\sup_{\\mathcal{D} \\sim \\mathcal{D}'} \\left\\| f(\\mathcal{D}) - f(\\mathcal{D}') \\right\\|_1,\n$$\nwhere $\\mathcal{D} \\sim \\mathcal{D}'$ indicates that $\\mathcal{D}$ and $\\mathcal{D}'$ are adjacent datasets as per the user-level adjacency relation (they differ in the addition or removal of exactly one user/patient), and $\\|\\cdot\\|_1$ denotes the $L_1$ norm.\n\nWe now analyze the structure of $f(\\mathcal{D})$ for the contingency table of ICD-10 code counts. By construction, for each code $j \\in \\{1,2,\\dots,m\\}$, the count $c_j$ is the number of patients in $\\mathcal{D}$ whose set $S_i$ contains $j$. Under the contribution bounding step, each patient contributes to at most $k$ distinct codes, that is, for every $i$, $|S_i| \\leq k$.\n\nConsider two adjacent datasets $\\mathcal{D}$ and $\\mathcal{D}'$ that differ by exactly one patient record. Without loss of generality, suppose $\\mathcal{D}'$ is obtained from $\\mathcal{D}$ by removing a single patient $i^{\\star}$ with code set $S_{i^{\\star}}$. Then, the difference in the contingency table is\n$$\nf(\\mathcal{D}) - f(\\mathcal{D}') = \\big(\\delta_1, \\delta_2, \\dots, \\delta_m\\big),\n$$\nwhere for each $j$,\n$$\n\\delta_j =\n\\begin{cases}\n1, & \\text{if } j \\in S_{i^{\\star}}, \\\\\n0, & \\text{if } j \\notin S_{i^{\\star}}.\n\\end{cases}\n$$\nThis is because removing the patient $i^{\\star}$ decrements by $1$ exactly those code counts that the patient contributed to, and leaves all other code counts unchanged. Equivalently, if we consider addition of a patient rather than removal, the difference vector has entries $-1$ in the same positions; in either case, the absolute differences are $1$ on the coordinates corresponding to codes in $S_{i^{\\star}}$ and $0$ elsewhere.\n\nTherefore, the $L_1$ norm of the difference is\n$$\n\\left\\| f(\\mathcal{D}) - f(\\mathcal{D}') \\right\\|_1 = \\sum_{j=1}^{m} |\\delta_j| = \\sum_{j=1}^{m} \\mathbf{1}\\{ j \\in S_{i^{\\star}} \\} = |S_{i^{\\star}}|.\n$$\nBy the contribution bound, $|S_{i^{\\star}}| \\leq k$. Consequently,\n$$\n\\left\\| f(\\mathcal{D}) - f(\\mathcal{D}') \\right\\|_1 \\leq k\n$$\nfor any pair of user-level adjacent datasets. The global sensitivity is the supremum of this quantity over all such adjacent pairs. The worst case is attained when the removed (or added) patient contributes to the maximum allowed number $k$ of distinct codes, that is, when $|S_{i^{\\star}}| = k$. Thus,\n$$\n\\Delta_1(f) = k.\n$$\nThis completes the derivation from the foundational definition of global sensitivity, using the user-level adjacency and the bounded per-user contribution property.",
            "answer": "$$\\boxed{k}$$"
        }
    ]
}