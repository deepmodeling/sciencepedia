{
    "hands_on_practices": [
        {
            "introduction": "本练习旨在提供量化微生物多样性的基础实践。你将亲手计算“希尔数”（Hill numbers），这是一个统一了多种多样性指数的框架，它将原始丰度数据转换为直观的“有效物种数”。通过这个过程，你将能深入理解不同的多样性指标是如何权衡稀有和常见分类单元的。",
            "id": "4584534",
            "problem": "一项关于肠道微生物组的临床研究使用扩增子测序来分析细菌群落。经过质量控制后，每条读数（read）被去噪处理成一个扩增子序列变体（Amplicon Sequence Variant, ASV），并使用核糖体数据库项目（Ribosomal Database Project, RDP）朴素贝叶斯分类器，在置信度阈值为 $0.8$ 的条件下，为其分配属级（genus level）的分类学标签。将两个粪便样本，即群落 $A$ 和群落 $B$，在 $7$ 个属的层级上汇总成相对丰度向量（每个条目是分配给该属的总读数所占的比例，且所有条目都严格为正并总和为 $1$）：对群落 $A$，向量为 $\\mathbf{p}^{(A)} = (0.30, 0.25, 0.15, 0.10, 0.08, 0.07, 0.05)$；对群落 $B$，向量为 $\\mathbf{p}^{(B)} = (0.40, 0.20, 0.15, 0.10, 0.06, 0.05, 0.04)$。从多样性测度的基本性质（包括复制原理和物种标签不变性）以及 Rényi 熵族与等丰度物种有效数量之间经过充分检验的联系出发，推导阶数 $q=0$、$q=1$ 和 $q=2$ 的 Hill 数 $\\,{}^{q}D\\,$ 的相应表达式。然后，使用所提供的向量计算每个群落的 $\\,{}^{0}D$、$\\,{}^{1}D$ 和 $\\,{}^{2}D$。最后，基于第一性原理，解释阶数 $q$ 如何控制对稀有和常见分类单元的敏感性，并用您的计算值说明群落 $A$ 和 $B$ 的这种敏感性。按照 $\\left({}^{0}D_{A}, {}^{1}D_{A}, {}^{2}D_{A}, {}^{0}D_{B}, {}^{1}D_{B}, {}^{2}D_{B}\\right)$ 的顺序报告这六个数值，并四舍五入到四位有效数字。多样性量是无单位的。",
            "solution": "该问题具有科学依据、提法明确、客观，并包含了推导和计算所需量的所有必要信息。数据向量在内部是一致的，因为每个向量中的相对丰度之和为 $1$。因此，该问题是有效的，我们可以着手求解。\n\n现代多样性测度背后的基本概念是“物种有效数量”或“真实多样性”的思想，记为 $D$。真实多样性测度将原始丰度数据转换为一个更直观的单位：产生相同多样性值的等丰度物种的数量。如果一个测度满足复制原理，则它被认为是真实多样性：如果通过合并 $N$ 个大小相等、多样性相同且不共享物种的群落来形成一个混合群落，则该混合群落的多样性应为单个群落多样性的 $N$ 倍。通过将多样性定义为广义熵的指数，可以满足此性质。\n\nRényi 熵族提供了一个合适的框架。对于一个拥有 $S$ 个物种且相对丰度为 $p_i$（其中 $i = 1, \\dots, S$ 且 $\\sum_{i=1}^{S} p_i = 1$）的群落，其 $q$ 阶 Rényi 熵定义为：\n$$ H_q = \\frac{1}{1-q} \\ln\\left(\\sum_{i=1}^{S} p_i^q\\right) \\quad \\text{for } q \\ge 0, q \\neq 1 $$\n熵的一个关键性质是，对于一个由 $M$ 个等丰度物种组成的群落（即对所有 $i$，$p_i = 1/M$），其熵应等于 $\\ln(M)$。让我们为 Rényi 熵验证这一点：\n$$ H_q = \\frac{1}{1-q} \\ln\\left(\\sum_{i=1}^{M} \\left(\\frac{1}{M}\\right)^q\\right) = \\frac{1}{1-q} \\ln\\left(M \\cdot \\frac{1}{M^q}\\right) = \\frac{1}{1-q} \\ln\\left(M^{1-q}\\right) = \\frac{1-q}{1-q} \\ln(M) = \\ln(M) $$\n这个性质允许我们将 $q$ 阶真实多样性（也称为 Hill 数 $\\,{}^{q}D$）定义为在一个具有相同 Rényi 熵值的等丰度群落中的物种数量。也就是说，我们设 $H_q(\\text{群落}) = \\ln(\\,{}^{q}D)$。\n$$ \\ln(\\,{}^{q}D) = \\frac{1}{1-q} \\ln\\left(\\sum_{i=1}^{S} p_i^q\\right) $$\n对两边取指数，得到 $q \\neq 1$ 时 Hill 数的通用公式：\n$$ \\,{}^{q}D = \\exp\\left(H_q\\right) = \\left(\\sum_{i=1}^{S} p_i^q\\right)^{\\frac{1}{1-q}} $$\n\n现在我们推导 $q=0$、$q=1$ 和 $q=2$ 的具体表达式。对于两个群落，属的数量均为 $S=7$。\n\n**情况1：$q=0$（物种丰富度）**\n对于 $q=0$，我们可以直接代入通用公式：\n$$ \\,{}^{0}D = \\left(\\sum_{i=1}^{S} p_i^0\\right)^{\\frac{1}{1-0}} = \\sum_{i=1}^{S} p_i^0 $$\n由于所有给定的丰度 $p_i$ 都严格为正，所以 $p_i^0 = 1$。因此，该总和是所有非零丰度属的数量。\n$$ \\,{}^{0}D = \\sum_{i=1}^{S} 1 = S $$\n这就是群落的物种丰富度。\n\n**情况2：$q=2$（Simpson 多样性指数的倒数）**\n对于 $q=2$，代入通用公式可得：\n$$ \\,{}^{2}D = \\left(\\sum_{i=1}^{S} p_i^2\\right)^{\\frac{1}{1-2}} = \\left(\\sum_{i=1}^{S} p_i^2\\right)^{-1} = \\frac{1}{\\sum_{i=1}^{S} p_i^2} $$\n项 $\\sum_{i=1}^{S} p_i^2$ 是 Simpson 集中度指数，通常用 $\\lambda$ 表示。因此，$\\,{}^{2}D$ 是 Simpson 指数的倒数。\n\n**情况3：$q=1$（Shannon 熵的指数）**\n通用公式在 $q=1$ 处无定义。我们必须计算当 $q \\to 1$ 时的极限：\n$$ \\,{}^{1}D = \\lim_{q\\to1} \\left(\\sum_{i=1}^{S} p_i^q\\right)^{\\frac{1}{1-q}} $$\n这是 $1^\\infty$ 型的不定式。处理其对数 $\\ln(\\,{}^{q}D) = \\frac{\\ln(\\sum p_i^q)}{1-q}$ 会更容易。当 $q \\to 1$ 时，这是 $0/0$ 型，因此我们可以应用洛必达法则（L'Hôpital's rule）。令 $f(q) = \\ln(\\sum_i p_i^q)$ 和 $g(q) = 1-q$。\n导数为 $g'(q) = -1$ 和 $f'(q) = \\frac{\\sum_i p_i^q \\ln(p_i)}{\\sum_i p_i^q}$。\n$$ \\lim_{q\\to1} \\ln(\\,{}^{q}D) = \\lim_{q\\to1} \\frac{f'(q)}{g'(q)} = \\frac{\\frac{\\sum_i p_i^1 \\ln(p_i)}{\\sum_i p_i^1}}{-1} = -\\sum_{i=1}^{S} p_i \\ln(p_i) $$\n这个结果是 Shannon 熵 $H'$。因此，Hill 数的极限是：\n$$ \\,{}^{1}D = \\exp\\left(-\\sum_{i=1}^{S} p_i \\ln(p_i)\\right) = \\exp(H') $$\n\n现在我们为群落 A 和 B 计算这些值。\n令 $\\mathbf{p}^{(A)} = (0.30, 0.25, 0.15, 0.10, 0.08, 0.07, 0.05)$ 和 $\\mathbf{p}^{(B)} = (0.40, 0.20, 0.15, 0.10, 0.06, 0.05, 0.04)$。对两者而言，$S=7$。\n\n**群落 A 的计算：**\n$${}^{0}D_A = S = 7$$\n$${}^{2}D_A = \\frac{1}{\\sum (p_i^{(A)})^2} = \\frac{1}{0.30^2 + 0.25^2 + 0.15^2 + 0.10^2 + 0.08^2 + 0.07^2 + 0.05^2}$$\n$${}^{2}D_A = \\frac{1}{0.09 + 0.0625 + 0.0225 + 0.01 + 0.0064 + 0.0049 + 0.0025} = \\frac{1}{0.1988} \\approx 5.03018$$\n$$H'_A = -\\sum p_i^{(A)} \\ln(p_i^{(A)}) = - (0.30\\ln(0.30) + 0.25\\ln(0.25) + \\dots + 0.05\\ln(0.05)) \\approx 1.76059$$\n$${}^{1}D_A = \\exp(H'_A) = \\exp(1.76059) \\approx 5.81593$$\n\n**群落 B 的计算：**\n$${}^{0}D_B = S = 7$$\n$${}^{2}D_B = \\frac{1}{\\sum (p_i^{(B)})^2} = \\frac{1}{0.40^2 + 0.20^2 + 0.15^2 + 0.10^2 + 0.06^2 + 0.05^2 + 0.04^2}$$\n$${}^{2}D_B = \\frac{1}{0.16 + 0.04 + 0.0225 + 0.01 + 0.0036 + 0.0025 + 0.0016} = \\frac{1}{0.2402} \\approx 4.16320$$\n$$H'_B = -\\sum p_i^{(B)} \\ln(p_i^{(B)}) = - (0.40\\ln(0.40) + 0.20\\ln(0.20) + \\dots + 0.04\\ln(0.04)) \\approx 1.65059$$\n$${}^{1}D_B = \\exp(H'_B) = \\exp(1.65059) \\approx 5.21004$$\n\n四舍五入到四位有效数字，我们有：\n$\\left({}^{0}D_{A}, {}^{1}D_{A}, {}^{2}D_{A}\\right) = (7.000, 5.816, 5.030)$\n$\\left({}^{0}D_{B}, {}^{1}D_{B}, {}^{2}D_{B}\\right) = (7.000, 5.210, 4.163)$\n\n**关于阶数 $q$ 的解释：**\n阶数 $q$ 调节 Hill 数对物种相对丰度的敏感性。该公式的核心是加权丰度之和，$\\sum p_i^q = \\sum p_i \\cdot p_i^{q-1}$。\n- 对于 $q > 1$，项 $p_i^{q-1}$ 给予高丰度（$p_i$）物种不成比例的高权重。例如，在 $q=2$ 时，丰度由其自身（$p_i$）加权。这意味着当 $q>1$ 时，$\\,{}^{q}D$ 对最常见物种的数量和丰度最敏感。\n- 对于 $q < 1$，项 $p_i^{q-1}$ 的指数为负。这给予低丰度（$p_i$）物种不成比例的高权重。例如，在 $q=0$ 时，权重是 $p_i^{-1}$，这对稀有物种来说非常大。在极限情况下，$\\,{}^{0}D$ 完全忽略丰度，只计算所有存在的物种，因此仅凭其存在就给予最稀有物种最大的重要性。\n- 对于 $q=1$，权重是均匀的（实际上是 $p_i^0=1$），意味着每个个体都被同等加权。这被解释为精确地按每个物种在群落中的比例丰度进行加权，不偏向稀有或常见物种。\n\n**使用计算值进行说明：**\n计算出的值证明了这一原理。\n- 对于 $q=0$，$\\,{}^{0}D_{A} = \\,{}^{0}D_{B} = 7.000$。该指标对丰度不敏感，仅反映了两个群落具有相同数量的属。\n- 对于 $q=1$ 和 $q=2$，我们看到 $\\,{}^{1}D_{A} > \\,{}^{1}D_{B}$（$5.816 > 5.210$）以及 $\\,{}^{2}D_{A} > \\,{}^{2}D_{B}$（$5.030 > 4.163$）。群落 B 有一个更具优势的顶端属（丰度为 $40\\%$，而 A 为 $30\\%$），使其均匀度较低。$q \\ge 1$ 的指标会惩罚这种不均匀性，从而正确地识别出群落 A 在均匀度方面更具多样性。\n- 对优势度的敏感性随 $q$ 的增加而增加。A 和 B 之间多样性的百分比差异在 $q=2$ 时比在 $q=1$ 时更大。对于 $q=1$，A 的多样性比 B 高 $(5.816 - 5.210)/5.210 \\approx 11.6\\%$。对于 $q=2$，A 的多样性比 B 高 $(5.030 - 4.163)/4.163 \\approx 20.8\\%$。更高的 $q$ 值更强烈地惩罚了群落 B 中的高优势度，导致其多样性值更低，并且两个群落之间的差距更大。这证实了增加 $q$ 会放大最丰盛物种对多样性计算的影响。在一定 $q$ 值范围内的 $\\,{}^{q}D$ 值的完整图谱比单一指数更能提供一个群落多样性结构的完整画面。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n7.000  5.816  5.030  7.000  5.210  4.163\n\\end{pmatrix}\n}\n$$"
        },
        {
            "introduction": "微生物组数据本质上是“成分数据”（compositional data），这意味着原始的测序读数（read counts）不能在样本间直接比较。本练习通过一个精心设计的场景，展示了基于原始计数的简单比较为何会导致错误的发现。同时，它引入了“加性对数比”（additive log-ratio, ALR）变换，作为一种解决这一关键挑战的原则性方法。",
            "id": "4584543",
            "problem": "一项临床微生物组研究比较了两组粪便样本：一个对照组和一个病例组。测序文库的制备过程中，加入了一个恒定数量的合成分类单元作为加标（spike-in），以实现绝对丰度的参考。假设三个生物分类单元$A$、$B$、$C$和一个加标分类单元$S$在每个样本中的真实绝对丰度已知。观测到的读数计数是通过与真实绝对丰度成比例的抽样产生的，其中包含一个反映文库大小和效率的样本特异性缩放因子。具体来说，假设两个对照样本和两个病例样本获得了以下绝对丰度（细胞数）和观测读数计数。\n\n对照样本$1$：绝对丰度$A=1000$，$B=1000$，$C=1000$，$S=500$。测序深度因子产生的观测计数为$A=4000$，$B=4000$，$C=4000$，$S=2000$。\n\n对照样本$2$：绝对丰度$A=2000$，$B=2000$，$C=2000$，$S=500$。测序深度因子产生的观测计数为$A=4000$，$B=4000$，$C=4000$，$S=1000$。\n\n病例样本$3$：绝对丰度$A=10000$，$B=1000$，$C=1000$，$S=500$。测序深度因子产生的观测计数为$A=10000$，$B=1000$，$C=1000$，$S=500$。\n\n病例样本$4$：绝对丰度$A=20000$，$B=2000$，$C=2000$，$S=500$。测序深度因子产生的观测计数为$A=40000$，$B=4000$，$C=4000$，$S=1000$。\n\n假设由于测序深度因子（该因子在样本间可以不同），每个样本内的观测计数与绝对丰度完全成正比。\n\n仅使用成分数据的基本原理，不调用任何特定的归一化公式，分析以下内容。\n\n1. 通过明确计算解释，为什么一个基于比较不同条件下组均值原始计数的朴素检验会错误地将分类单元$B$识别为差异丰度，尽管其绝对丰度在对照样本和病例样本之间没有变化。\n\n2. 使用成分数据分析（CoDA），并采用以加标分类单元$S$为参考组分的加性对数比（ALR）变换。从基本原理出发，论证为什么在所述假设下，ALR对数比可以消除样本特异性缩放和成分效应，并计算病例组和对照组之间分类单元$A$的ALR组均值之差。\n\n请以单个封闭形式的解析表达式给出最终答案，该表达式表示分类单元$A$基于ALR的病例组减去对照组的组均值之差，使用自然对数。不要四舍五入。不需要单位。",
            "solution": "问题陈述已经过评估，被认为是有效的。它在科学上基于微生物组分析的原理，问题设定良好，数据充分且一致，表述客观。所提供的数据与绝对丰度和观测计数通过样本特异性缩放因子成正比的模型在内部是一致的。\n\n设样本中分类单元$i$的真实绝对丰度为$N_i$，对应的观测读数计数为$C_i$。问题陈述指出，对于任何给定样本，存在一个样本特异性测序深度因子$k$，使得该样本中所有分类单元$i$都满足$C_i = k \\cdot N_i$。加标分类单元$S$被说明在所有样本中具有恒定的真实绝对丰度，给定为$N_S = 500$。\n\n提供的数据如下：\n对照样本$1$ (s1)：丰度$(N_A, N_B, N_C, N_S) = (1000, 1000, 1000, 500)$。观测计数$(C_A, C_B, C_C, C_S) = (4000, 4000, 4000, 2000)$。缩放因子为$k_1 = 4000/1000 = 4$。\n对照样本$2$ (s2)：丰度$(N_A, N_B, N_C, N_S) = (2000, 2000, 2000, 500)$。观测计数$(C_A, C_B, C_C, C_S) = (4000, 4000, 4000, 1000)$。缩放因子为$k_2 = 4000/2000 = 2$。\n病例样本$3$ (s3)：丰度$(N_A, N_B, N_C, N_S) = (10000, 1000, 1000, 500)$。观测计数$(C_A, C_B, C_C, C_S) = (10000, 1000, 1000, 500)$。缩放因子为$k_3 = 10000/10000 = 1$。\n病例样本$4$ (s4)：丰度$(N_A, N_B, N_C, N_S) = (20000, 2000, 2000, 500)$。观测计数$(C_A, C_B, C_C, C_S) = (40000, 4000, 4000, 1000)$。缩放因子为$k_4 = 40000/20000 = 2$。\n\n对照组由样本s1和s2组成。病例组由样本s3和s4组成。\n\n**1. 对分类单元B的原始计数进行朴素检验的分析**\n\n首先，有必要验证问题的基本前提，即分类单元$B$的绝对丰度在两组之间没有变化。\n对于对照组，分类单元$B$的绝对丰度为$N_{B,s1} = 1000$和$N_{B,s2} = 2000$。平均绝对丰度为$\\bar{N}_{B, \\text{control}} = \\frac{1000 + 2000}{2} = 1500$。\n对于病例组，分类单元$B$的绝对丰度为$N_{B,s3} = 1000$和$N_{B,s4} = 2000$。平均绝对丰度为$\\bar{N}_{B, \\text{case}} = \\frac{1000 + 2000}{2} = 1500$。\n平均绝对丰度是相同的。实际上，分类单元$B$的绝对丰度分布在两组中都是$\\{1000, 2000\\}$。因此，病例组和对照组之间分类单元$B$没有真正的差异丰度。\n\n一个朴素检验会直接比较观测到的原始读数计数的组均值。\n对照组中分类单元$B$的观测计数为$C_{B,s1} = 4000$和$C_{B,s2} = 4000$。\n对照组中分类单元$B$的平均原始计数为：\n$$\n\\bar{C}_{B, \\text{control}} = \\frac{C_{B,s1} + C_{B,s2}}{2} = \\frac{4000 + 4000}{2} = 4000\n$$\n病例组中分类单元$B$的观测计数为$C_{B,s3} = 1000$和$C_{B,s4} = 4000$。\n病例组中分类单元$B$的平均原始计数为：\n$$\n\\bar{C}_{B, \\text{case}} = \\frac{C_{B,s3} + C_{B,s4}}{2} = \\frac{1000 + 4000}{2} = 2500\n$$\n比较组均值，$\\bar{C}_{B, \\text{case}} = 2500$远低于$\\bar{C}_{B, \\text{control}} = 4000$。这种明显的下降会导致朴素的统计分析错误地得出结论，即分类单元$B$在病例组中丰度较低。\n\n这种错误识别的产生是因为原始计数不能在样本间直接比较。计数是真实丰度和样本特异性缩放因子的乘积（$C_i = k \\cdot N_i$）。缩放因子$k$包含了测序深度、文库制备效率和总生物量的变化，并且它在不同样本间是不同的（$k_1=4$, $k_2=2$, $k_3=1$, $k_4=2$）。例如，样本s1（对照）和样本s3（病例）具有相同的分类单元$B$的绝对丰度（$N_B=1000$），但它们的观测计数却截然不同（$C_{B,s1}=4000$ vs. $C_{B,s3}=1000$），这仅仅是因为它们的缩放因子不同（$k_1=4$ vs. $k_3=1$）。这种差异是成分效应的一个例子：病例样本中分类单元$A$绝对丰度的巨大增加改变了所有分类单元的比例表征，这与变化的测序深度相结合，在原始计数数据中产生了误导性的信号。\n\n**2. 使用加性对数比（ALR）变换的成分数据分析（CoDA）**\n\n加性对数比（ALR）变换是一种分析成分数据的方法，它对上述问题具有稳健性。它通过对成分组合中各组分的比率取对数来进行操作。\n\n**从基本原理出发的论证：**\n设一个样本的观测计数向量为$\\mathbf{C} = [C_1, C_2, \\dots, C_D]$，其中$D$是分类单元的数量。这是一个成分，因为它所携带的信息是相对的。使用分类单元$S$作为参考，ALR变换对任何其他分类单元$i$定义为：\n$$\n\\text{alr}(i) = \\ln\\left(\\frac{C_i}{C_S}\\right)\n$$\n我们可以将观测计数的模型，$C_i = k \\cdot N_i$和$C_S = k \\cdot N_S$，代入此定义：\n$$\n\\text{alr}(i) = \\ln\\left(\\frac{k \\cdot N_i}{k \\cdot N_S}\\right)\n$$\n样本特异性缩放因子$k$，作为单个样本内所有分类单元的公共乘数，在比率中被约掉：\n$$\n\\text{alr}(i) = \\ln\\left(\\frac{N_i}{N_S}\\right)\n$$\n这个结果值是分类单元$i$和加标分类单元$S$的真实绝对丰度之比的对数。问题陈述中说明，加标物$S$是以恒定量加入的，并且提供的数据显示其真实绝对丰度$N_S$在所有样本中恒定为$500$。因此，ALR值可以写为：\n$$\n\\text{alr}(i) = \\ln(N_i) - \\ln(N_S)\n$$\n由于$\\ln(N_S)$在所有样本中是一个常数，因此$\\text{alr}(i)$在样本或组间的任何变化都直接反映了$\\ln(N_i)$的变化，即分类单元$i$的真实绝对丰度的对数。ALR变换通过使用与恒定加标物的比率，有效地消除了样本特异性的缩放假象$k$，并将相对计数数据转换为与真实绝对丰度的对数成正比的表示。这使其成为跨样本和组比较丰度的有效基础。\n\n**分类单元A的计算：**\n我们被要求计算病例组和对照组之间分类单元$A$的ALR组均值之差，$\\Delta_{\\text{ALR}}(A) = \\overline{\\text{alr}(A)}_{\\text{case}} - \\overline{\\text{alr}(A)}_{\\text{control}}$。\n\n首先，我们计算每个对照样本中分类单元$A$的ALR值：\n对于样本s1：$C_{A,s1} = 4000$，$C_{S,s1} = 2000$。\n$$\n\\text{alr}_{s1}(A) = \\ln\\left(\\frac{4000}{2000}\\right) = \\ln(2)\n$$\n对于样本s2：$C_{A,s2} = 4000$，$C_{S,s2} = 1000$。\n$$\n\\text{alr}_{s2}(A) = \\ln\\left(\\frac{4000}{1000}\\right) = \\ln(4)\n$$\n对照组的平均ALR为：\n$$\n\\overline{\\text{alr}(A)}_{\\text{control}} = \\frac{\\ln(2) + \\ln(4)}{2} = \\frac{\\ln(2) + \\ln(2^2)}{2} = \\frac{\\ln(2) + 2\\ln(2)}{2} = \\frac{3\\ln(2)}{2}\n$$\n接下来，我们计算每个病例样本中分类单元$A$的ALR值：\n对于样本s3：$C_{A,s3} = 10000$，$C_{S,s3} = 500$。\n$$\n\\text{alr}_{s3}(A) = \\ln\\left(\\frac{10000}{500}\\right) = \\ln(20)\n$$\n对于样本s4：$C_{A,s4} = 40000$，$C_{S,s4} = 1000$。\n$$\n\\text{alr}_{s4}(A) = \\ln\\left(\\frac{40000}{1000}\\right) = \\ln(40)\n$$\n病例组的平均ALR为：\n$$\n\\overline{\\text{alr}(A)}_{\\text{case}} = \\frac{\\ln(20) + \\ln(40)}{2}\n$$\n现在，我们计算差值：\n$$\n\\Delta_{\\text{ALR}}(A) = \\overline{\\text{alr}(A)}_{\\text{case}} - \\overline{\\text{alr}(A)}_{\\text{control}} = \\frac{\\ln(20) + \\ln(40)}{2} - \\frac{3\\ln(2)}{2}\n$$\n使用性质$\\ln(x) + \\ln(y) = \\ln(xy)$:\n$$\n\\Delta_{\\text{ALR}}(A) = \\frac{\\ln(20 \\times 40)}{2} - \\frac{3\\ln(2)}{2} = \\frac{\\ln(800)}{2} - \\frac{\\ln(2^3)}{2} = \\frac{\\ln(800) - \\ln(8)}{2}\n$$\n使用性质$\\ln(x) - \\ln(y) = \\ln(x/y)$:\n$$\n\\Delta_{\\text{ALR}}(A) = \\frac{1}{2}\\ln\\left(\\frac{800}{8}\\right) = \\frac{1}{2}\\ln(100)\n$$\n使用性质$\\ln(x^y) = y\\ln(x)$:\n$$\n\\Delta_{\\text{ALR}}(A) = \\frac{1}{2}\\ln(10^2) = \\frac{1}{2}(2\\ln(10)) = \\ln(10)\n$$\n这个结果代表了$A$相对于$S$的绝对丰度对数比率的平均差异。因为$N_S$是恒定的，所以这个值反映了病例组和对照组之间分类单元$A$绝对丰度的平均对数倍数变化。",
            "answer": "$$\\boxed{\\ln(10)}$$"
        },
        {
            "introduction": "在分析多样性或物种组成之前，我们必须首先为原始的DNA序列读数（reads）分配物种分类。本编码练习将揭开这一过程的神秘面纱，指导你从零开始实现两种基本方法：一种是基于 $k$-mer 的朴素贝叶斯分类器，另一种是基于序列比对的最低共同祖先（LCA）法。通过这个过程，你将能够比较它们的性能和内在假设。",
            "id": "4584519",
            "problem": "给定一个合成的分类系统和代表四个微生物物种的 DNA 参考序列，这些物种分属于两个属和两个门。您的任务是实现两种物种分类算法——一种基于 $k$-mer 计数的朴素贝叶斯分类，另一种基于类似基本局部比对搜索工具 (BLAST) 的最低共同祖先 (LCA) 规则——然后在一个确定性的测试套件上，按分类级别评估这两种方法的精确率和召回率。所有算法步骤必须从基本定义和经过充分测试的公式开始，所有输出必须按规定表示为浮点数或浮点数列表。不涉及任何物理单位或角度单位。任何分数或比例必须表示为小数。\n\n将使用的基本定义：\n- 贝叶斯定理：对于类别 $c$ 和观测值 $x$，后验概率为 $P(c \\mid x) = \\dfrac{P(x \\mid c) P(c)}{P(x)}$。\n- 朴素独立性假设：$x$ 的特征（此处为 $k$-mers）在给定类别 $c$ 的条件下是相互独立的。\n- $k$-mer 计数的多项式模型：$P(x \\mid c)$ 可分解为每个 $k$-mer 的概率的乘积，幂次为其观测到的计数。\n- 改编的基本局部比对搜索工具（BLAST）概念：一个读段与参考序列的相似性通过其最大局部一致性得分来量化，此处定义为该读段与参考序列的所有局部比对中匹配位置的最高比例。\n- 最低共同祖先（LCA）：给定一组分类单元，LCA 是分类系统中最深的分类单元，使得该组中的所有分类单元都共享它。\n\n分类系统：\n- 门 $F$ (厚壁菌门)，属 $B$ (芽孢杆菌属):\n  - 种 $BS$：枯草芽孢杆菌\n  - 种 $BL$：地衣芽孢杆菌\n- 门 $P$ (变形菌门):\n  - 属 $E$ (埃希氏菌属):\n    - 种 $EC$：大肠杆菌\n  - 属 $S$ (沙门氏菌属):\n    - 种 $SE$：肠道沙门氏菌\n\n参考序列（长度 $60$）：\n- 构建基序 $\\text{motif}_1 = \\text{\"ACGTACGTGACA\"}$（长度 12）和修改后的基序 $\\text{motif}_{1,\\text{mod}}$，方法是将索引 4（从零开始）处的字符从 $\\text{\"A\"}$ 改为 $\\text{\"T\"}$，得到 $\\text{\"ACGTTCGTGACA\"}$。然后定义：\n  - $BS$ 参考序列：$\\text{BS} = \\text{motif}_1$ 重复 $5$ 次。\n  - $BL$ 参考序列：$\\text{BL} = \\text{motif}_{1,\\text{mod}}$ 重复 $5$ 次。\n- 构建基序 $\\text{motif}_2 = \\text{\"TTGACAGCTGAA\"}$（长度 12）和修改后的基序 $\\text{motif}_{2,\\text{mod}}$，方法是将索引 6（从零开始）处的字符从 $\\text{\"G\"}$ 改为 $\\text{\"T\"}$，得到 $\\text{\"TTGACATCTGAA\"}$。然后定义：\n  - $EC$ 参考序列：$\\text{EC} = \\text{motif}_2$ 重复 $5$ 次。\n  - $SE$ 参考序列：$\\text{SE} = \\text{motif}_{2,\\text{mod}}$ 重复 $5$ 次。\n\n明确地说，四个参考序列是：\n- $BS$: $\\text{\"ACGTACGTGACAACGTACGTGACAACGTACGTGACAACGTACGTGACAACGTACGTGACA\"}$\n- $BL$: $\\text{\"ACGTTCGTGACAACGTTCGTGACAACGTTCGTGACAACGTTCGTGACAACGTTCGTGACA\"}$\n- $EC$: $\\text{\"TTGACAGCTGAATTGACAGCTGAATTGACAGCTGAATTGACAGCTGAATTGACAGCTGAA\"}$\n- $SE$: $\\text{\"TTGACATCTGAATTGACATCTGAATTGACATCTGAATTGACATCTGAATTGACATCTGAA\"}$\n\n读段生成程序（确定性），读段长度 $L = 30$，偏移量为 $\\{0, 12, 24\\}$：\n- 对于每个物种 $c \\in \\{BS, BL, EC, SE\\}$：\n  - 生成一个读段 $R_{c,0} = \\text{ref}_c[0:30]$（无突变）。\n  - 生成一个读段 $R_{c,12} = \\text{ref}_c[12:42]$，并通过替换函数 $f$（定义为 $f(\\text{\"A\"})=\\text{\"G\"}$, $f(\\text{\"C\"})=\\text{\"T\"}$, $f(\\text{\"G\"})=\\text{\"A\"}$, $f(\\text{\"T\"})=\\text{\"C\"}$）对读段内索引 5 和 20（从零开始）的位置进行突变。\n  - 生成一个读段 $R_{c,24} = \\text{ref}_c[24:54]$（无突变）。\n- 添加一个跨属模糊读段 $R_{\\text{chim}} = \\text{BS}[0:15] \\, || \\, \\text{BL}[15:30]$（串联），其真实物种标签设为 $BS$。这样总共得到 $13$ 个读段。\n\n真实标签：\n- 对于每个读段 $R_{c,\\cdot}$，其真实物种标签是 $c$，真实属标签是 $c$ 的属，真实门标签是 $c$ 的门。\n- 对于 $R_{\\text{chim}}$，其真实物种标签是 $BS$，真实属标签是 $B$ (芽孢杆菌属)，真实门标签是 $F$ (厚壁菌门)。\n\n朴素贝叶斯分类器规范：\n- 令 $k$ 为所选的 $k$-mer 长度。\n- 将词汇表 $\\mathcal{V}$ 定义为在四个参考序列中观察到的所有 $k$-mers 的并集。\n- 对于每个物种 $c$，令 $N_{c,w}$ 为物种 $c$ 的参考序列中 $k$-mer $w \\in \\mathcal{V}$ 的计数，并令 $M_c = \\sum_{w \\in \\mathcal{V}} N_{c,w}$ 为该参考序列中 $k$-mers 的总数。\n- 使用拉普拉斯平滑，参数为 $\\alpha > 0$，因此条件概率为\n$$\nP(w \\mid c) = \\frac{N_{c,w} + \\alpha}{M_c + \\alpha \\, |\\mathcal{V}|}.\n$$\n- 假设四个物种的类先验概率均匀，即 $P(c) = 1/4$。\n- 对于一个读段 $R$，令 $n_R(w)$ 为 $R$ 中 $k$-mer $w$ 的计数。多项式朴素贝叶斯模型给出\n$$\n\\log P(c \\mid R) = \\log P(c) + \\sum_{w \\in \\mathcal{V}} n_R(w) \\, \\log P(w \\mid c) + \\text{constant},\n$$\n分类器预测使上述值最大化的物种 $\\hat{c}$。通过在最大化项中选择字典序最小的物种标识符来确定性地打破平局。预测的属和门通过将预测的物种映射到其属和门来获得。\n\n类 BLAST-LCA 分配规范：\n- 对于一个长度为 $L$ 的读段 $R$ 和一个长度为 $|S_c|$ 的物种参考序列 $S_c$，定义局部一致性得分\n$$\ns(c; R) = \\max_{0 \\leq i \\leq |S_c| - L} \\frac{1}{L} \\sum_{j=0}^{L-1} \\mathbf{1}\\{ R[j] = S_c[i+j] \\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 令 $s_{\\max} = \\max_c s(c; R)$ 和一个下降参数 $\\delta \\in [0,1]$。构建候选集\n$$\n\\mathcal{H} = \\{ c \\mid s_{\\max} - s(c; R) \\leq \\delta \\}.\n$$\n如果 $|\\mathcal{H}|$ 超过给定的数量上限 $N$，则仅保留 $\\mathcal{H}$ 中具有最大 $s(c; R)$ 的 $N$ 个物种（通过物种标识符的字典序打破平局）。\n- 令 $\\pi(c)$ 表示物种 $c$ 的分类路径，记为元组 $(\\text{门}, \\text{属}, \\text{种})$。最低共同祖先（LCA）深度 $d \\in \\{0,1,2,3\\}$ 是最大的 $d$，使得集合 $\\{ \\pi(c) \\mid c \\in \\mathcal{H} \\}$ 中的所有路径共享前 $d$ 个组成部分。如果 $d=0$，则 LCA 为根节点，任何级别上都无法预测分类单元。如果 $d \\geq 1$，则可以进行门预测；如果 $d \\geq 2$，则可以进行属预测；如果 $d=3$，则可以进行物种预测。\n- 每个级别的预测标签如下：\n  - 物种：如果 $d=3$，则预测该物种；否则，无物种预测。\n  - 属：如果 $d \\geq 2$，则预测该属；否则，无属预测。\n  - 门：如果 $d \\geq 1$，则预测该门；否则，无门预测。\n\n评估指标：\n- 对于每种方法和每个级别 $r \\in \\{\\text{物种}, \\text{属}, \\text{门}\\}$：\n  - 令 $C_r$ 为级别 $r$ 上所有读段中正确预测标签的计数。\n  - 令 $P_r$ 为级别 $r$ 处非空预测标签的总数（对于朴素贝叶斯， $P_r$ 等于读段总数，因为该方法总是预测一个物种；对于类 BLAST-LCA 方法， $P_r$ 可能小于读段总数）。\n  - 令 $T$ 为读段总数。\n  - 级别 $r$ 的精确率定义为 $\\text{precision}_r = \\begin{cases} C_r / P_r  \\text{if } P_r > 0 \\\\ 0  \\text{if } P_r = 0 \\end{cases}$。\n  - 级别 $r$ 的召回率定义为 $\\text{recall}_r = C_r / T$。\n\n测试套件：\n- 您将评估三组参数 $\\{(k, \\alpha, \\delta, N)\\}$，选择这些参数是为了覆盖一个通用的“理想路径”、一个边界条件和一个边缘案例：\n  1. 案例 1：$(k, \\alpha, \\delta, N) = (5, 1.0, 0.05, 3)$。\n  2. 案例 2：$(k, \\alpha, \\delta, N) = (6, 0.1, 0.02, 4)$。\n  3. 案例 3：$(k, \\alpha, \\delta, N) = (3, 2.0, 0.10, 2)$。\n\n所需输出：\n- 对于每种情况，计算以下 12 个浮点数，每个浮点数四舍五入到三位小数：$[\\text{prec}_{\\text{species}}^{\\text{NB}}, \\text{rec}_{\\text{species}}^{\\text{NB}}, \\text{prec}_{\\text{genus}}^{\\text{NB}}, \\text{rec}_{\\text{genus}}^{\\text{NB}}, \\text{prec}_{\\text{phylum}}^{\\text{NB}}, \\text{rec}_{\\text{phylum}}^{\\text{NB}}, \\text{prec}_{\\text{species}}^{\\text{LCA}}, \\text{rec}_{\\text{species}}^{\\text{LCA}}, \\text{prec}_{\\text{genus}}^{\\text{LCA}}, \\text{rec}_{\\text{genus}}^{\\text{LCA}}, \\text{prec}_{\\text{phylum}}^{\\text{LCA}}, \\text{rec}_{\\text{phylum}}^{\\text{LCA}}]$。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素本身是上述一种情况的列表。例如，外部列表包含三个内部列表（每个测试案例一个），并打印为单行，如 $[\\,[\\dots],\\,[\\dots],\\,[\\dots]\\,]$，其中数值条目四舍五入到三位小数。\n\n请完全按照上述定义，使用指定的分类系统、参考序列和读段生成程序来实现这两种方法和评估。所有计算必须是确定性的。",
            "solution": "这是一个确定性的生物信息学算法实现问题，要求执行并评估两种物种分类方法。解决方案包括数据生成、两种分类器的实现，以及在指定测试套件上进行评估。\n\n### 步骤 1：数据生成与设置\n根据问题规范，首先构建分类系统、参考序列和包含13个读段的测试集。\n- **分类系统**：定义了四个物种（BS, BL, EC, SE）及其对应的属（B, E, S）和门（F, P）。\n- **参考序列**：为四个物种分别生成长度为60的DNA序列。\n- **读段集**：为每个物种生成3个长度为30的读段（2个无突变，1个有两个点突变），外加一个嵌合读段，总共13个读段。每个读段都附有一个明确的“真实”分类标签。\n\n### 步骤 2：实现并执行朴素贝叶斯分类器\n对于每个测试用例中的$k$和$\\alpha$值，实现多项式朴素贝叶斯分类器。\n- **训练阶段**：\n  1.  从所有四个参考序列中提取所有长度为$k$的$k$-mer，构建一个词汇表。\n  2.  为每个物种，计算其参考序列中每个$k$-mer的出现频率。\n  3.  使用拉普拉斯平滑（$\\alpha$），计算每个$k$-mer在给定物种下的对数条件概率 $\\log P(w \\mid c)$。\n- **预测阶段**：\n  1.  对于测试集中的每个读段，计算其包含的每个$k$-mer的数量。\n  2.  对于每个可能的物种，通过将读段中$k$-mer计数的加权对数条件概率与均匀对数先验相加，计算其对数后验概率。\n  3.  预测为后验概率最高的物种，并根据字典序打破平局。\n  4.  从预测的物种推断出属和门的标签。\n\n### 步骤 3：实现并执行类BLAST-LCA方法\n对于每个测试用例中的$\\delta$和$N$值，实现基于比对和最低共同祖先（LCA）的分类器。\n- **比对评分阶段**：\n  1.  对于每个读段，将其与每个参考序列进行“滑动窗口”比对。\n  2.  计算每个比对的一致性得分（匹配位置的比例），并记录每个读段-参考序列对的最高得分。\n- **LCA分配阶段**：\n  1.  对于每个读段，找到最高比对得分$s_{\\max}$。\n  2.  构建一个候选物种集$\\mathcal{H}$，其中包含所有得分在$s_{\\max} - s(c; R) \\leq \\delta$范围内的物种。\n  3.  如果候选集的大小超过$N$，则根据得分和字典序进行修剪，保留前$N$个候选者。\n  4.  找到候选集中所有物种的最低共同祖先（LCA）。\n  5.  根据LCA的深度进行预测：如果所有候选者共享同一个物种，则预测该物种；如果只共享一个属，则预测该属；如果只共享一个门，则预测该门。如果无法在某个级别上达成共识，则该级别的预测为空。\n\n### 步骤 4：评估与结果生成\n对于每个测试用例，将两种方法的预测结果与真实标签进行比较。\n- 对每个分类级别（物种、属、门），计算正确预测的数量（$C_r$）和做出的非空预测的总数（$P_r$）。\n- 根据公式计算精确率（$C_r / P_r$）和召回率（$C_r / T$）。\n- 将每个测试用例的12个评估指标（2种方法 x 3个级别 x 2个指标）收集起来，四舍五入到三位小数，并按要求格式化输出。\n\n以下是执行这些步骤的Python代码。",
            "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates two taxonomic assignment algorithms based on a\n    deterministic set of synthetic microbial data, as specified in the problem.\n    The entire process, from data generation to final evaluation and output\n    formatting, is self-contained within this function.\n    \"\"\"\n\n    # --------------------------------------------------------------------------\n    # Step 1: Data Generation and Setup\n    # --------------------------------------------------------------------------\n\n    # Taxonomy: species -> (phylum, genus, species)\n    taxonomy = {\n        'BS': ('F', 'B', 'BS'),\n        'BL': ('F', 'B', 'BL'),\n        'EC': ('P', 'E', 'EC'),\n        'SE': ('P', 'S', 'SE'),\n    }\n    # For deterministic tie-breaking and iteration\n    species_list_sorted = sorted(taxonomy.keys())  # ['BL', 'BS', 'EC', 'SE']\n    # For deterministic read generation from source\n    species_list_generation_order = ['BS', 'BL', 'EC', 'SE']\n\n    # Reference sequence construction\n    motif1 = \"ACGTACGTGACA\"\n    motif1_mod = motif1[:4] + 'T' + motif1[5:]\n    motif2 = \"TTGACAGCTGAA\"\n    motif2_mod = motif2[:6] + 'T' + motif2[7:]\n\n    ref_seqs = {\n        'BS': motif1 * 5,\n        'BL': motif1_mod * 5,\n        'EC': motif2 * 5,\n        'SE': motif2_mod * 5,\n    }\n\n    # Deterministic read generation\n    L = 30\n    reads = []\n    ground_truths = []\n    \n    def mutate_char(c):\n        mapping = {'A': 'G', 'C': 'T', 'G': 'A', 'T': 'C'}\n        return mapping.get(c, c)\n\n    for species_id in species_list_generation_order:\n        ref = ref_seqs[species_id]\n        gt = {'species': species_id, 'genus': taxonomy[species_id][1], 'phylum': taxonomy[species_id][0]}\n\n        reads.append(ref[0:L])\n        ground_truths.append(gt)\n\n        read_12_list = list(ref[12:12 + L])\n        read_12_list[5] = mutate_char(read_12_list[5])\n        read_12_list[20] = mutate_char(read_12_list[20])\n        reads.append(\"\".join(read_12_list))\n        ground_truths.append(gt)\n\n        reads.append(ref[24:24 + L])\n        ground_truths.append(gt)\n\n    read_chim = ref_seqs['BS'][0:15] + ref_seqs['BL'][15:30]\n    reads.append(read_chim)\n    ground_truths.append({'species': 'BS', 'genus': 'B', 'phylum': 'F'})\n    \n    T = len(reads)\n\n    # Test suite parameters\n    test_cases = [\n        (5, 1.0, 0.05, 3),\n        (6, 0.1, 0.02, 4),\n        (3, 2.0, 0.10, 2),\n    ]\n\n    all_case_results = []\n    \n    def count_kmers(seq, k):\n        counts = {}\n        for i in range(len(seq) - k + 1):\n            kmer = seq[i:i+k]\n            counts[kmer] = counts.get(kmer, 0) + 1\n        return counts\n\n    # --------------------------------------------------------------------------\n    # Step 2: Loop Through Test Cases and Evaluate\n    # --------------------------------------------------------------------------\n    for k, alpha, delta, N in test_cases:\n\n        # --- Naive Bayes Classifier ---\n        kmer_vocab = set()\n        ref_kmer_counts = {}\n        total_ref_kmers = {}\n        for sp in species_list_sorted:\n            counts = count_kmers(ref_seqs[sp], k)\n            ref_kmer_counts[sp] = counts\n            total_ref_kmers[sp] = len(ref_seqs[sp]) - k + 1\n            kmer_vocab.update(counts.keys())\n        \n        vocab_size = len(kmer_vocab)\n        \n        log_cond_probs = {}\n        for sp in species_list_sorted:\n            log_cond_probs[sp] = {}\n            denominator = np.log(total_ref_kmers[sp] + alpha * vocab_size)\n            for kmer in kmer_vocab:\n                count = ref_kmer_counts[sp].get(kmer, 0)\n                numerator = np.log(count + alpha)\n                log_cond_probs[sp][kmer] = numerator - denominator\n        \n        log_prior = np.log(1.0 / len(species_list_sorted))\n\n        nb_predictions = []\n        for read in reads:\n            read_kmer_counts = count_kmers(read, k)\n            scores = {}\n            for sp in species_list_sorted:\n                log_posterior = log_prior\n                for kmer, count in read_kmer_counts.items():\n                    if kmer in log_cond_probs[sp]:\n                        log_posterior += count * log_cond_probs[sp][kmer]\n                scores[sp] = log_posterior\n            \n            max_score = -np.inf\n            best_species_set = []\n            for sp, score in scores.items():\n                if score > max_score:\n                    max_score = score\n                    best_species_set = [sp]\n                elif score == max_score:\n                    best_species_set.append(sp)\n            \n            predicted_species = sorted(best_species_set)[0]\n            \n            nb_predictions.append({\n                'species': predicted_species,\n                'genus': taxonomy[predicted_species][1],\n                'phylum': taxonomy[predicted_species][0]\n            })\n\n        # --- BLAST-LCA-like Method ---\n        lca_predictions = []\n        for read in reads:\n            scores = {}\n            for sp in species_list_sorted:\n                ref = ref_seqs[sp]\n                max_identity = 0.0\n                for i in range(len(ref) - L + 1):\n                    sub_ref = ref[i:i + L]\n                    matches = sum(1 for j in range(L) if read[j] == sub_ref[j])\n                    identity = matches / L\n                    if identity > max_identity:\n                        max_identity = identity\n                scores[sp] = max_identity\n            \n            s_max = max(scores.values()) if scores else 0.0\n            H = {sp for sp, score in scores.items() if s_max - score <= delta}\n            \n            if len(H) > N:\n                sorted_candidates = sorted(list(H), key=lambda sp: (-scores[sp], sp))\n                H = set(sorted_candidates[:N])\n\n            pred = {'species': None, 'genus': None, 'phylum': None}\n            if H:\n                paths = [taxonomy[sp] for sp in H]\n                lca_depth = 0\n                if paths:\n                    first_path = paths[0]\n                    for d in range(1, 4):\n                        prefix = first_path[:d]\n                        if all(p[:d] == prefix for p in paths):\n                            lca_depth = d\n                        else:\n                            break\n                \n                if lca_depth >= 1: pred['phylum'] = paths[0][0]\n                if lca_depth >= 2: pred['genus'] = paths[0][1]\n                if lca_depth == 3: pred['species'] = paths[0][2]\n            \n            lca_predictions.append(pred)\n\n        # --- Evaluation ---\n        case_results = []\n        ranks = ['species', 'genus', 'phylum']\n        \n        for rank in ranks:\n            C_r_nb = sum(1 for i in range(T) if nb_predictions[i][rank] == ground_truths[i][rank])\n            P_r_nb = T\n            case_results.extend([C_r_nb / P_r_nb if P_r_nb > 0 else 0.0, C_r_nb / T])\n            \n        for rank in ranks:\n            C_r_lca = sum(1 for i in range(T) if lca_predictions[i][rank] is not None and lca_predictions[i][rank] == ground_truths[i][rank])\n            P_r_lca = sum(1 for i in range(T) if lca_predictions[i][rank] is not None)\n            case_results.extend([C_r_lca / P_r_lca if P_r_lca > 0 else 0.0, C_r_lca / T])\n        \n        all_case_results.append(case_results)\n\n    # --------------------------------------------------------------------------\n    # Step 3: Format and Print Final Output\n    # --------------------------------------------------------------------------\n    formatted_case_results = []\n    for case_res in all_case_results:\n        formatted_nums = [f\"{x:.3f}\" for x in case_res]\n        formatted_case_results.append(f\"[{','.join(formatted_nums)}]\")\n    \n    print(f\"[{','.join(formatted_case_results)}]\")\n\nsolve()\n```"
        }
    ]
}