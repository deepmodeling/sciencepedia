{
    "hands_on_practices": [
        {
            "introduction": "When analyzing thousands of genes or pathways simultaneously, the chance of finding \"significant\" results purely by accident increases dramatically. This exercise tackles this fundamental challenge by guiding you through the Benjamini-Hochberg procedure, a cornerstone of modern bioinformatics for controlling the False Discovery Rate ($FDR$). Mastering this technique is essential for distinguishing true biological signals from statistical noise in any high-throughput study .",
            "id": "4565348",
            "problem": "A case-control gene set enrichment analysis evaluates functional pathways in a disease cohort, producing nominal pathway $p$-values from independent tests of association for $m=12$ predefined pathways. In high-dimensional multiple testing, the False Discovery Rate (FDR) is defined as the expected proportion of rejected null hypotheses that are actually true among all rejections. To control FDR at a target level, the Benjamini-Hochberg (BH) procedure assigns adjusted $q$-values to each pathway. Using the following pathway list and their nominal $p$-values, compute the BH-adjusted $q$-values for all pathways and then determine how many pathways would be declared significant at an FDR threshold $\\alpha=0.05$. Report the count of significant pathways as your final answer.\n\nThe pathways and their $p$-values are:\nDNA damage response: $0.0009$; Interferon gamma response: $0.004$; Nuclear factor kappa-light-chain-enhancer of activated B cells (NF-$\\kappa$B) signaling: $0.012$; Glycolysis and glucose metabolism: $0.018$; Apoptosis: $0.021$; Mitogen-Activated Protein Kinase (MAPK) cascade: $0.035$; T cell receptor signaling: $0.048$; Hypoxia: $0.06$; Phosphoinositide 3-Kinase - Protein Kinase B (PI3K-AKT) signaling: $0.11$; Mechanistic Target of Rapamycin (mTOR) signaling: $0.17$; Wingless-related integration site (WNT) signaling: $0.24$; Angiogenesis: $0.5$.\n\nAssume the pathway-level tests are independent or satisfy positive regression dependence on a subset, so that the BH procedure controls the FDR at the nominal level. Provide a scientifically grounded interpretation of FDR control when explaining your reasoning, but the final reported quantity must be the integer count of significant pathways at $\\alpha=0.05$. No rounding is required for the final answer.",
            "solution": "The problem requires the application of the Benjamini-Hochberg (BH) procedure to a set of nominal $p$-values from a gene set enrichment analysis in order to control the False Discovery Rate (FDR), and then to determine the number of pathways that are statistically significant at a specified FDR threshold.\n\nFirst, we establish the theoretical background. In multiple hypothesis testing, where many statistical tests are performed simultaneously, there is an increased risk of making Type I errors (false positives). The False Discovery Rate is a statistical method used to correct for this. The FDR is defined as the expected value of the proportion of falsely rejected null hypotheses (false discoveries) among all rejected null hypotheses (total discoveries). Let $V$ be the number of true null hypotheses that are incorrectly rejected, and $R$ be the total number of rejected null hypotheses. The FDR is given by $E\\left[\\frac{V}{R}\\right]$, where the fraction is taken to be $0$ if $R=0$. The Benjamini-Hochberg procedure provides a way to control this FDR at a specified level $\\alpha$.\n\nThe problem provides $m=12$ pathways and their corresponding nominal $p$-values. The procedure is as follows:\n1.  Let the individual $p$-values be $p_1, p_2, \\ldots, p_m$.\n2.  Order these $p$-values in ascending order: $p_{(1)} \\le p_{(2)} \\le \\ldots \\le p_{(m)}$.\n3.  For each ordered $p$-value $p_{(k)}$, the corresponding BH-adjusted $p$-value, or $q$-value, is calculated. The $q$-value for the test with the $k$-th smallest $p$-value, denoted $q_{(k)}$, is given by the formula:\n$$q_{(k)} = \\min_{j=k, \\dots, m} \\left( \\frac{m \\cdot p_{(j)}}{j} \\right)$$\nThis formula ensures that the sequence of adjusted $q$-values is monotonically non-decreasing, i.e., $q_{(1)} \\le q_{(2)} \\le \\ldots \\le q_{(m)}$. A practical way to compute this is to first calculate the intermediate values $\\frac{m \\cdot p_{(k)}}{k}$ for each rank $k$, and then enforce the monotonicity by iterating backwards from $k=m$ to $k=1$. Specifically, $q_{(m)} = p_{(m)}$, and for $k = m-1, \\ldots, 1$, we have $q_{(k)} = \\min\\left(q_{(k+1)}, \\frac{m \\cdot p_{(k)}}{k}\\right)$.\n4.  A hypothesis is rejected (i.e., a pathway is declared significant) if its adjusted $q$-value is less than or equal to the FDR threshold $\\alpha$.\n\nThe given data are:\nTotal number of tests (pathways), $m = 12$.\nFDR threshold, $\\alpha = 0.05$.\nThe nominal $p$-values are already sorted in ascending order:\n$p_{(1)} = 0.0009$\n$p_{(2)} = 0.004$\n$p_{(3)} = 0.012$\n$p_{(4)} = 0.018$\n$p_{(5)} = 0.021$\n$p_{(6)} = 0.035$\n$p_{(7)} = 0.048$\n$p_{(8)} = 0.06$\n$p_{(9)} = 0.11$\n$p_{(10)} = 0.17$\n$p_{(11)} = 0.24$\n$p_{(12)} = 0.5$\n\nWe now compute the adjusted $q$-values, $q_{(k)}$, for each rank $k$ from $1$ to $12$. We will compute them by iterating from $k=12$ down to $k=1$.\n\nFor $k=12$: $q_{(12)} = \\frac{12 \\cdot p_{(12)}}{12} = p_{(12)} = 0.5$.\nFor $k=11$: $q_{(11)} = \\min\\left(q_{(12)}, \\frac{12 \\cdot p_{(11)}}{11}\\right) = \\min\\left(0.5, \\frac{12 \\cdot 0.24}{11}\\right) = \\min\\left(0.5, \\frac{2.88}{11}\\right) \\approx \\min(0.5, 0.2618) \\approx 0.2618$.\nFor $k=10$: $q_{(10)} = \\min\\left(q_{(11)}, \\frac{12 \\cdot p_{(10)}}{10}\\right) = \\min\\left(0.2618, \\frac{12 \\cdot 0.17}{10}\\right) = \\min(0.2618, 0.204) = 0.204$.\nFor $k=9$: $q_{(9)} = \\min\\left(q_{(10)}, \\frac{12 \\cdot p_{(9)}}{9}\\right) = \\min\\left(0.204, \\frac{12 \\cdot 0.11}{9}\\right) \\approx \\min(0.204, 0.1467) \\approx 0.1467$.\nFor $k=8$: $q_{(8)} = \\min\\left(q_{(9)}, \\frac{12 \\cdot p_{(8)}}{8}\\right) = \\min\\left(0.1467, \\frac{12 \\cdot 0.06}{8}\\right) = \\min(0.1467, 0.09) = 0.09$.\nFor $k=7$: $q_{(7)} = \\min\\left(q_{(8)}, \\frac{12 \\cdot p_{(7)}}{7}\\right) = \\min\\left(0.09, \\frac{12 \\cdot 0.048}{7}\\right) = \\min\\left(0.09, \\frac{0.576}{7}\\right) \\approx \\min(0.09, 0.0823) \\approx 0.0823$.\nFor $k=6$: $q_{(6)} = \\min\\left(q_{(7)}, \\frac{12 \\cdot p_{(6)}}{6}\\right) = \\min\\left(0.0823, \\frac{12 \\cdot 0.035}{6}\\right) = \\min(0.0823, 0.07) = 0.07$.\nFor $k=5$: $q_{(5)} = \\min\\left(q_{(6)}, \\frac{12 \\cdot p_{(5)}}{5}\\right) = \\min\\left(0.07, \\frac{12 \\cdot 0.021}{5}\\right) = \\min(0.07, 0.0504) = 0.0504$.\nFor $k=4$: $q_{(4)} = \\min\\left(q_{(5)}, \\frac{12 \\cdot p_{(4)}}{4}\\right) = \\min\\left(0.0504, \\frac{12 \\cdot 0.018}{4}\\right) = \\min(0.0504, 0.054) = 0.0504$.\nFor $k=3$: $q_{(3)} = \\min\\left(q_{(4)}, \\frac{12 \\cdot p_{(3)}}{3}\\right) = \\min\\left(0.0504, \\frac{12 \\cdot 0.012}{3}\\right) = \\min(0.0504, 0.048) = 0.048$.\nFor $k=2$: $q_{(2)} = \\min\\left(q_{(3)}, \\frac{12 \\cdot p_{(2)}}{2}\\right) = \\min\\left(0.048, \\frac{12 \\cdot 0.004}{2}\\right) = \\min(0.048, 0.024) = 0.024$.\nFor $k=1$: $q_{(1)} = \\min\\left(q_{(2)}, \\frac{12 \\cdot p_{(1)}}{1}\\right) = \\min\\left(0.024, \\frac{12 \\cdot 0.0009}{1}\\right) = \\min(0.024, 0.0108) = 0.0108$.\n\nThe complete list of BH-adjusted $q$-values corresponding to the ordered $p$-values is:\n$q_{(1)} = 0.0108$ (DNA damage response)\n$q_{(2)} = 0.024$ (Interferon gamma response)\n$q_{(3)} = 0.048$ (NF-$\\kappa$B signaling)\n$q_{(4)} = 0.0504$ (Glycolysis and glucose metabolism)\n$q_{(5)} = 0.0504$ (Apoptosis)\n$q_{(6)} = 0.07$ (MAPK cascade)\n$q_{(7)} \\approx 0.0823$ (T cell receptor signaling)\n$q_{(8)} = 0.09$ (Hypoxia)\n$q_{(9)} \\approx 0.1467$ (PI3K-AKT signaling)\n$q_{(10)} = 0.204$ (mTOR signaling)\n$q_{(11)} \\approx 0.2618$ (WNT signaling)\n$q_{(12)} = 0.5$ (Angiogenesis)\n\nThe final step is to identify the pathways that are significant at the FDR threshold $\\alpha = 0.05$. We reject the null hypothesis for any pathway whose $q$-value is less than or equal to $0.05$.\n- Pathway 1 (DNA damage response): $q_{(1)} = 0.0108 \\le 0.05$. Significant.\n- Pathway 2 (Interferon gamma response): $q_{(2)} = 0.024 \\le 0.05$. Significant.\n- Pathway 3 (NF-$\\kappa$B signaling): $q_{(3)} = 0.048 \\le 0.05$. Significant.\n- Pathway 4 (Glycolysis and glucose metabolism): $q_{(4)} = 0.0504 > 0.05$. Not significant.\n\nSince the $q$-values are monotonically non-decreasing, all subsequent pathways (from rank $5$ to $12$) will also have $q$-values greater than $0.05$. Therefore, they are not significant.\n\nCounting the number of significant pathways, we find there are $3$.",
            "answer": "$$\\boxed{3}$$"
        },
        {
            "introduction": "Gene Set Enrichment Analysis (GSEA) is a powerful computational method for determining whether a predefined set of genes shows statistically significant, concordant differences between two biological states. This hands-on practice demystifies the GSEA algorithm by having you calculate an enrichment score from first principles. By working through the running-sum statistic, you will gain an intuitive understanding of how GSEA detects subtle but coordinated expression changes that single-gene analyses might miss .",
            "id": "4565335",
            "problem": "A cohort study of a complex disease generates a ranked list of genes based on differential expression using a signed statistic $r_{i}$ (for gene $i$), where positive values indicate higher expression in cases relative to controls and negative values indicate lower expression in cases. You will evaluate a single pathway using Gene Set Enrichment Analysis (GSEA) from first principles.\n\nConsider the ordered genome-wide list of $N=12$ genes $(g_{1},\\dots,g_{12})$ with their signed statistics\n$$\n\\begin{aligned}\n&g_{1}: r_{1}=2.8, &g_{2}: r_{2}=2.6, &g_{3}: r_{3}=2.1, &g_{4}: r_{4}=1.9, &g_{5}: r_{5}=1.5, &g_{6}: r_{6}=0.9, \\\\\n&g_{7}: r_{7}=0.3, &g_{8}: r_{8}=-0.2, &g_{9}: r_{9}=-0.8, &g_{10}: r_{10}=-1.2, &g_{11}: r_{11}=-1.9, &g_{12}: r_{12}=-2.4\n\\end{aligned}\n$$\nordered from $g_{1}$ (most positive) to $g_{12}$ (most negative). The pathway gene set is $S=\\{g_{2},g_{5},g_{9},g_{11}\\}$.\n\nStarting from foundational principles for enrichment over a ranked list, define a running-sum statistic $R_{k}$ over positions $k=1,\\dots,N$ that (i) increases at positions $k$ where the gene $g_{k}\\in S$ by a positive weight proportional to $|r_{k}|^{p}$ and scaled so that the total increments over $S$ sum to $1$, (ii) decreases at positions $k$ where $g_{k}\\notin S$ by a constant step scaled so that the total decrements over the complement of $S$ sum to $-1$, and (iii) starts at $R_{0}=0$ and returns to $R_{N}=0$. Adopt the classic weighting exponent $p=1$.\n\nUsing these definitions, compute the enrichment score $ES$ as the maximum positive deviation of $R_{k}$ from $0$ across $k=1,\\dots,N$. Then, given five null enrichment scores obtained from phenotype-label permutations for this same pathway,\n$$\nES_{\\text{null}}=\\{0.21,\\,-0.12,\\,0.25,\\,0.19,\\,-0.08\\},\n$$\ncompute the normalized enrichment score $NES$ by dividing the observed $ES$ by the mean of the positive values in $ES_{\\text{null}}$.\n\nFinally, interpret the leading-edge subset in quantitative terms by determining the number of pathway genes that occur at or before the position $k$ where the maximum positive deviation $ES$ is attained.\n\nExpress your final answer as a row matrix using the $\\mathrm{pmatrix}$ environment with entries $(ES,\\,NES,\\,\\text{leading-edge count})$. Round $ES$ and $NES$ to four significant figures.",
            "solution": "The problem requires us to perform a Gene Set Enrichment Analysis (GSEA) calculation from first principles for a single gene pathway. We are given a ranked list of $N=12$ genes with associated signed statistics $r_i$, and a gene set $S=\\{g_{2},g_{5},g_{9},g_{11}\\}$.\n\nFirst, we define and compute the running-sum statistic $R_k$ for the ordered gene list, from $k=1$ to $N=12$. The initial condition is $R_0 = 0$. The update rule for $R_k$ depends on whether the gene $g_k$ is in the gene set $S$ ('hit') or not ('miss').\n\nThe number of genes in the set $S$ is $|S|=4$. The number of genes not in $S$ is $|S^c| = N - |S| = 12 - 4 = 8$.\n\nFor a hit (i.e., $g_k \\in S$), the running sum increases by a step $\\Delta R_k^{\\text{hit}}$ proportional to $|r_k|^p$ with the exponent $p=1$. The sum of all such positive increments must equal $1$. We first compute the normalization factor, which is the sum of the weighted scores for all genes in $S$:\n$$\nN_S = \\sum_{g_i \\in S} |r_i|^p = |r_2|^1 + |r_5|^1 + |r_9|^1 + |r_{11}|^1\n$$\nUsing the given values:\n$$\nN_S = |2.6| + |1.5| + |-0.8| + |-1.9| = 2.6 + 1.5 + 0.8 + 1.9 = 6.8\n$$\nThe increment for a hit at position $k$ is therefore:\n$$\n\\Delta R_k^{\\text{hit}} = \\frac{|r_k|}{N_S} = \\frac{|r_k|}{6.8}\n$$\n\nFor a miss (i.e., $g_k \\notin S$), the running sum decreases by a constant step $\\Delta R_k^{\\text{miss}}$. The sum of all such negative decrements must equal $-1$. Since there are $|S^c|=8$ genes not in $S$, the constant decrement is:\n$$\n\\Delta R_k^{\\text{miss}} = \\frac{-1}{|S^c|} = \\frac{-1}{8} = -0.125\n$$\n\nNow we can compute the running sum $R_k = R_{k-1} + \\Delta R_k$ for $k=1, \\dots, 12$, starting with $R_0 = 0$.\n\n$k=1$: $g_1 \\notin S$. $R_1 = R_0 + \\Delta R_1^{\\text{miss}} = 0 - 0.125 = -0.125$.\n\n$k=2$: $g_2 \\in S$. $|r_2|=2.6$. $R_2 = R_1 + \\Delta R_2^{\\text{hit}} = -0.125 + \\frac{2.6}{6.8} \\approx -0.125 + 0.3824 \\approx 0.2574$.\n\n$k=3$: $g_3 \\notin S$. $R_3 = R_2 + \\Delta R_3^{\\text{miss}} \\approx 0.2574 - 0.125 = 0.1324$.\n\n$k=4$: $g_4 \\notin S$. $R_4 = R_3 + \\Delta R_4^{\\text{miss}} \\approx 0.1324 - 0.125 = 0.0074$.\n\n$k=5$: $g_5 \\in S$. $|r_5|=1.5$. $R_5 = R_4 + \\Delta R_5^{\\text{hit}} \\approx 0.0074 + \\frac{1.5}{6.8} \\approx 0.0074 + 0.2206 \\approx 0.2280$.\n\n$k=6$: $g_6 \\notin S$. $R_6 = R_5 + \\Delta R_6^{\\text{miss}} \\approx 0.2280 - 0.125 = 0.1030$.\n\n$k=7$: $g_7 \\notin S$. $R_7 = R_6 + \\Delta R_7^{\\text{miss}} \\approx 0.1030 - 0.125 = -0.0220$.\n\n$k=8$: $g_8 \\notin S$. $R_8 = R_7 + \\Delta R_8^{\\text{miss}} \\approx -0.0220 - 0.125 = -0.1470$.\n\n$k=9$: $g_9 \\in S$. $|r_9|=0.8$. $R_9 = R_8 + \\Delta R_9^{\\text{hit}} \\approx -0.1470 + \\frac{0.8}{6.8} \\approx -0.1470 + 0.1176 \\approx -0.0294$.\n\n$k=10$: $g_{10} \\notin S$. $R_{10} = R_9 + \\Delta R_{10}^{\\text{miss}} \\approx -0.0294 - 0.125 = -0.1544$.\n\n$k=11$: $g_{11} \\in S$. $|r_{11}|=1.9$. $R_{11} = R_{10} + \\Delta R_{11}^{\\text{hit}} \\approx -0.1544 + \\frac{1.9}{6.8} \\approx -0.1544 + 0.2794 = 0.125$.\n\n$k=12$: $g_{12} \\notin S$. $R_{12} = R_{11} + \\Delta R_{12}^{\\text{miss}} = 0.125 - 0.125 = 0$.\nThe condition $R_N=0$ is satisfied, confirming the calculations.\n\nThe Enrichment Score ($ES$) is the maximum positive deviation of the running sum from $0$, which is the maximum value in the set $\\{R_1, \\dots, R_{12}\\}$.\n$$\nES = \\max_{k \\in \\{1, \\dots, 12\\}} R_k = R_2 \\approx 0.25735...\n$$\nRounding to four significant figures, $ES \\approx 0.2574$.\n\nNext, we calculate the Normalized Enrichment Score ($NES$). We are given a set of null enrichment scores: $ES_{\\text{null}}=\\{0.21, -0.12, 0.25, 0.19, -0.08\\}$. We need the mean of the positive values in this set.\nThe positive values are $\\{0.21, 0.25, 0.19\\}$.\n$$\n\\text{mean}(ES_{\\text{null, pos}}) = \\frac{0.21 + 0.25 + 0.19}{3} = \\frac{0.65}{3} \\approx 0.21666...\n$$\nThe $NES$ is the observed $ES$ divided by this mean:\n$$\nNES = \\frac{ES}{\\text{mean}(ES_{\\text{null, pos}})} \\approx \\frac{0.25735}{0.21666...} \\approx 1.18778...\n$$\nRounding to four significant figures, $NES \\approx 1.188$.\n\nFinally, we identify the leading-edge subset. This subset consists of the genes in $S$ that appear in the ranked list at or before the position where the $ES$ is attained. The maximum value of the running sum, $ES$, occurred at position $k=2$. The genes in the ranked list up to this position are $\\{g_1, g_2\\}$.\nWe find the intersection of this set with the gene set $S$:\n$$\n\\text{Leading-Edge Genes} = \\{g_k | k \\le 2\\} \\cap S = \\{g_1, g_2\\} \\cap \\{g_2, g_5, g_9, g_{11}\\} = \\{g_2\\}\n$$\nThe number of genes in the leading-edge subset is the count of elements in this set.\n$$\n\\text{leading-edge count} = |\\{g_2\\}| = 1\n$$\n\nThe final required values are $ES \\approx 0.2574$, $NES \\approx 1.188$, and the leading-edge count is $1$.",
            "answer": "$$\n\\boxed{\\begin{pmatrix} 0.2574 & 1.188 & 1 \\end{pmatrix}}\n$$"
        },
        {
            "introduction": "Beyond testing predefined pathways, a powerful approach in systems biology is to construct biological networks directly from omics data. This practice guides you through the foundational steps of building a weighted gene co-expression network, a technique popularized by methods like WGCNA. You will learn how to apply soft-thresholding to correlation data and calculate the scale-free topology fit index, a crucial metric for creating biologically meaningful network models .",
            "id": "4565386",
            "problem": "You are given normalized transcript abundance measurements from Ribonucleic Acid sequencing (RNA-seq) representing genes by samples. Your task is to construct a weighted gene co-expression network by soft-thresholding absolute Pearson correlations and to quantify how well the resulting network approximates a scale-free topology using the scale-free topology fit index. The derivation and implementation must start from the following base: Pearson correlation as a measure of linear dependence between two variables, adjacency construction by monotonic transformation of similarity, degree as the sum of edge weights for each node in a weighted network, empirical probability mass function estimated by a histogram of degrees, and ordinary least squares linear regression with coefficient of determination as a measure of goodness-of-fit.\n\nFrom the base definitions, implement the following procedure. Given a genes-by-samples matrix $X \\in \\mathbb{R}^{G \\times S}$ with genes indexed by $i \\in \\{1,\\dots,G\\}$ and samples indexed by $s \\in \\{1,\\dots,S\\}$:\n1. Remove any gene $i$ whose sample variance across $s \\in \\{1,\\dots,S\\}$ is exactly zero to avoid undefined correlation.\n2. Compute the Pearson correlation matrix $R = (r_{ij})$ across genes, where $r_{ij}$ is the Pearson correlation between rows $i$ and $j$ of $X$, with $r_{ii} = 1$.\n3. For each provided soft-threshold power $\\beta \\in \\mathbb{R}_{>0}$, construct a weighted, unsigned adjacency matrix $A^{(\\beta)} = (a^{(\\beta)}_{ij})$ with $a^{(\\beta)}_{ij} = |r_{ij}|^{\\beta}$ for $i \\neq j$ and $a^{(\\beta)}_{ii} = 0$.\n4. For each node $i$, compute its weighted degree $k^{(\\beta)}_i = \\sum_{j=1}^{G} a^{(\\beta)}_{ij}$.\n5. Using only nodes with strictly positive degree (that is, $k^{(\\beta)}_i > 0$), estimate the empirical degree distribution by an equally spaced histogram with $B \\in \\mathbb{N}$ bins whose edges span from $\\min\\{k^{(\\beta)}_i : k^{(\\beta)}_i > 0\\}$ to $\\max\\{k^{(\\beta)}_i : k^{(\\beta)}_i > 0\\}$. Let $c_\\ell$ denote the center of bin $\\ell$ and $p_\\ell$ denote the empirical probability mass in bin $\\ell$, where $p_\\ell$ equals the count in bin $\\ell$ divided by the total count of nodes with strictly positive degree. Discard any bins with zero count so that $\\log_{10}(p_\\ell)$ is defined.\n6. Fit the linear model $\\log_{10}(p_\\ell) = \\alpha + \\gamma \\log_{10}(c_\\ell) + \\varepsilon_\\ell$ by ordinary least squares using only bins with nonzero counts. Define the scale-free topology fit index for power $\\beta$ as the coefficient of determination $R^2 \\in [0,1]$ from this fit, computed as $R^2 = 1 - \\dfrac{\\sum_{\\ell} (\\hat{y}_\\ell - y_\\ell)^2}{\\sum_{\\ell} (y_\\ell - \\bar{y})^2}$ with $y_\\ell = \\log_{10}(p_\\ell)$ and $\\hat{y}_\\ell$ the fitted values. If there are fewer than $2$ nonempty bins or if the sample variance of either $\\{\\log_{10}(c_\\ell)\\}$ or $\\{\\log_{10}(p_\\ell)\\}$ is zero, define $R^2 = 0$.\n7. Repeat steps $3$ through $6$ for each provided $\\beta$ for each test case.\n\nYour program must implement the above for the following test suite. Each test case supplies the expression matrix $X$, a list of soft-threshold powers $\\{\\beta\\}$, and the number of histogram bins $B$.\n\nTest case $1$:\n- $X \\in \\mathbb{R}^{6 \\times 8}$ with rows\n  - $[\\,1,2,3,4,5,6,7,8\\,]$\n  - $[\\,2,4,6,8,10,12,14,16\\,]$\n  - $[\\,8,7,6,5,4,3,2,1\\,]$\n  - $[\\,1,1,2,2,3,3,4,4\\,]$\n  - $[\\,5,5,5,5,5,5,5,5\\,]$\n  - $[\\,1,0,1,0,1,0,1,0\\,]$\n- Soft-threshold powers $\\{\\beta\\} = \\{2,4,6,8,10\\}$\n- Histogram bins $B = 10$\n\nTest case $2$:\n- $X \\in \\mathbb{R}^{5 \\times 8}$ with rows\n  - $[\\,0.1,2.1,1.2,3.2,2.8,1.7,3.0,2.5\\,]$\n  - $[\\,2.0,1.1,2.2,1.3,2.1,1.4,2.0,1.6\\,]$\n  - $[\\,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0\\,]$\n  - $[\\,1.5,1.4,1.6,1.5,1.7,1.6,1.8,1.7\\,]$\n  - $[\\,3.2,2.9,3.1,3.0,3.3,3.1,3.2,3.0\\,]$\n- Soft-threshold powers $\\{\\beta\\} = \\{1,2,3,4,5\\}$\n- Histogram bins $B = 8$\n\nTest case $3$:\n- $X \\in \\mathbb{R}^{4 \\times 6}$ with rows\n  - $[\\,1,2,3,4,5,6\\,]$\n  - $[\\,2,3,4,5,6,7\\,]$\n  - $[\\,3,4,5,6,7,8\\,]$\n  - $[\\,10,10,10,10,10,10\\,]$\n- Soft-threshold powers $\\{\\beta\\} = \\{1,3,6\\}$\n- Histogram bins $B = 5$\n\nFinal output specification:\n- For each test case, in the given order, compute the scale-free topology fit index $R^2$ for each $\\beta$ in the order provided. Round each $R^2$ to $4$ decimal places (round half away from zero is not required; standard round-to-nearest with ties to even is acceptable). Aggregate all $R^2$ values across all test cases into a single flat list in the same sequence they are computed.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, `[r2_1,r2_2,r2_3]`.",
            "solution": "The user-provided problem is assessed to be **valid**. It is scientifically grounded in the principles of bioinformatics and network theory, specifically Weighted Gene Co-expression Network Analysis (WGCNA). The problem is well-posed, objective, and provides a complete, self-contained algorithmic specification. The procedure is computationally feasible and leads to a unique, verifiable solution.\n\nThe solution proceeds by implementing the specified algorithm. The core task is to compute a scale-free topology fit index, $R^2$, for a gene co-expression network constructed from a given gene expression matrix $X \\in \\mathbb{R}^{G \\times S}$. This is repeated for several soft-thresholding powers $\\beta$.\n\n**Step 1: Gene Filtering**\nFirst, the input expression matrix $X$ is processed to remove genes that exhibit no variation across samples. The sample variance for each gene $i$ (row $i$) is calculated. Any gene $i$ for which this variance is exactly zero, $\\sigma^2_i = 0$, is removed from the matrix. This step is crucial because the Pearson correlation coefficient is undefined for variables with zero variance. Let the filtered matrix be $X_{filt} \\in \\mathbb{R}^{G_{filt} \\times S}$, where $G_{filt}$ is the number of genes with non-zero variance.\n\n**Step 2: Pearson Correlation Matrix**\nUsing the filtered data $X_{filt}$, a similarity matrix is constructed. The similarity measure is the Pearson correlation coefficient, $r_{ij}$, which quantifies the linear relationship between the expression profiles of gene $i$ and gene $j$. This results in a $G_{filt} \\times G_{filt}$ symmetric correlation matrix $R = (r_{ij})$, where $r_{ij} = \\frac{\\sum_{s=1}^S (X_{is} - \\bar{X}_i)(X_{js} - \\bar{X}_j)}{\\sqrt{\\sum_{s=1}^S (X_{is} - \\bar{X}_i)^2 \\sum_{s=1}^S (X_{js} - \\bar{X}_j)^2}}$. By definition, the diagonal elements are $r_{ii} = 1$.\n\n**Step 3: Weighted Adjacency Matrix**\nThe correlation matrix $R$ is transformed into a weighted adjacency matrix $A^{(\\beta)}$ for each specified soft-thresholding power $\\beta > 0$. This problem specifies an unsigned network, so the transformation is $a^{(\\beta)}_{ij} = |r_{ij}|^\\beta$. This operation amplifies strong correlations and suppresses weak ones, a process known as soft-thresholding. The diagonal elements are set to zero, $a^{(\\beta)}_{ii} = 0$, to remove self-loops in the network.\n\n**Step 4: Weighted Node Degree**\nFor each gene (node) $i$ in the network, its connectivity or degree $k_i$ is calculated. In a weighted network, the degree is the sum of weights of all edges connected to the node: $k^{(\\beta)}_i = \\sum_{j=1}^{G_{filt}} a^{(\\beta)}_{ij}$.\n\n**Step 5: Degree Distribution**\nThe scale-free property of a network is assessed by examining its degree distribution, $P(k)$, which gives the probability that a randomly chosen node has degree $k$. For scale-free networks, this distribution follows a power law, $P(k) \\propto k^{-\\gamma}$. To check this, we analyze the distribution of the calculated degrees $\\{k^{(\\beta)}_i\\}$.\nFirst, we consider only nodes with positive degrees, $\\{k^{(\\beta)}_i : k^{(\\beta)}_i > 0\\}$. The empirical probability distribution of these degrees is estimated using a histogram with a specified number of bins, $B$. The bins are equally spaced, spanning the range from the minimum to the maximum positive degree. For each bin $\\ell$, we determine its center, $c_\\ell$, and the empirical probability, $p_\\ell$, which is the number of nodes whose degrees fall into bin $\\ell$ divided by the total number of nodes with positive degrees. Bins with zero counts are discarded.\n\n**Step 6: Scale-Free Topology Fit Index ($R^2$)**\nTo test for a power-law relationship, we take the logarithm of both axes of the degree distribution plot. If $P(k) \\propto k^{-\\gamma}$, then $\\log(P(k)) = C - \\gamma \\log(k)$, which is a linear relationship. We therefore fit an ordinary least squares (OLS) linear model to the log-transformed histogram data: $\\log_{10}(p_\\ell) = \\alpha + \\gamma \\log_{10}(c_\\ell) + \\varepsilon_\\ell$.\nThe goodness-of-fit of this linear model is quantified by the coefficient of determination, $R^2$. The scale-free topology fit index is defined as this $R^2$ value. For a simple linear regression, $R^2$ is simply the square of the Pearson correlation between the independent variable, $x_\\ell = \\log_{10}(c_\\ell)$, and the dependent variable, $y_\\ell = \\log_{10}(p_\\ell)$.\nThe problem defines specific edge cases for the calculation: if there are fewer than $2$ non-empty bins for the histogram, or if the sample variance of either the set of $\\log_{10}(c_\\ell)$ values or the set of $\\log_{10}(p_\\ell)$ values is zero, the fit index $R^2$ is defined to be $0$. This prevents undefined calculations, such as fitting a line to a single point or division by zero in the $R^2$ formula.\n\nThis entire procedure (Steps 3-6) is repeated for each value of $\\beta$ in the provided list for each test case. The final results are aggregated and formatted as specified.",
            "answer": "```python\nimport numpy as np\n\ndef calculate_sft_fit(X, betas, B):\n    \"\"\"\n    Calculates the scale-free topology fit index R^2 for a series of soft-thresholding powers.\n    \n    The function implements the full procedure described in the problem:\n    1. Filter genes with zero variance.\n    2. Compute the Pearson correlation matrix.\n    3. For each beta, construct the adjacency matrix.\n    4. Compute weighted node degrees.\n    5. Estimate the degree distribution using a histogram.\n    6. Fit a linear model to the log-log transformed distribution and compute R^2.\n    \"\"\"\n    X_np = np.array(X, dtype=float)\n\n    # Step 1: Remove any gene whose sample variance is exactly zero.\n    # We use ddof=1 for sample variance, although ddof=0 would yield the same filter.\n    variances = np.var(X_np, axis=1, ddof=1)\n    X_filtered = X_np[variances > 0]\n    \n    # If fewer than 2 genes remain, correlation is not meaningful for a network.\n    if X_filtered.shape[0]  2:\n        return [0.0] * len(betas)\n    \n    # Step 2: Compute the Pearson correlation matrix.\n    R_matrix = np.corrcoef(X_filtered)\n    \n    # Handle the case where corrcoef might return a scalar if only one gene passed filtering.\n    if R_matrix.ndim  2:\n        return [0.0] * len(betas)\n\n    r_squared_values = []\n\n    for beta in betas:\n        # Step 3: Construct a weighted, unsigned adjacency matrix.\n        A = np.power(np.abs(R_matrix), beta)\n        np.fill_diagonal(A, 0)\n        \n        # Step 4: Compute the weighted degree for each node.\n        k = np.sum(A, axis=1)\n        \n        # Step 5: Estimate the empirical degree distribution.\n        # Use only nodes with strictly positive degree.\n        k_pos = k[k > 0]\n        \n        if len(k_pos) == 0:\n            r_squared_values.append(0.0)\n            continue\n            \n        k_min, k_max = np.min(k_pos), np.max(k_pos)\n\n        # If all positive degrees are identical, they will fall into a single bin.\n        # This is handled by the num_non_empty_bins  2 check below.\n        if np.isclose(k_min, k_max):\n            r_squared_values.append(0.0)\n            continue\n            \n        bin_edges = np.linspace(k_min, k_max, B + 1)\n        counts, _ = np.histogram(k_pos, bins=bin_edges)\n        \n        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n        \n        # Discard bins with zero count.\n        non_empty_mask = counts > 0\n        p_counts = counts[non_empty_mask]\n        c_ell = bin_centers[non_empty_mask]\n        \n        num_non_empty_bins = len(c_ell)\n        \n        # Step 6: Fit the linear model and compute the scale-free topology fit index (R^2).\n        \n        # Condition: If there are fewer than 2 nonempty bins, R^2 = 0.\n        if num_non_empty_bins  2:\n            r_squared_values.append(0.0)\n            continue\n            \n        # Calculate empirical probability mass p_ell.\n        p_ell = p_counts / len(k_pos)\n        \n        # Log-transform coordinates for linear model fitting.\n        y_log = np.log10(p_ell)\n        x_log = np.log10(c_ell)\n        \n        # Condition: If sample variance of log-coords is zero, R^2 = 0.\n        # We use ddof=1 for sample variance, matching the problem's language.\n        if np.var(x_log, ddof=1) == 0 or np.var(y_log, ddof=1) == 0:\n            r_squared_values.append(0.0)\n            continue\n            \n        # For simple linear regression, R^2 is the square of the Pearson correlation\n        # between the independent and dependent variables.\n        corr_matrix = np.corrcoef(x_log, y_log)\n        correlation = corr_matrix[0, 1]\n        \n        # Safeguard against potential NaN from corrcoef, though variance checks should prevent this.\n        if np.isnan(correlation):\n            r_squared_values.append(0.0)\n            continue\n            \n        r_squared = correlation**2\n        r_squared_values.append(r_squared)\n        \n    return r_squared_values\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"X\": [\n                [1, 2, 3, 4, 5, 6, 7, 8],\n                [2, 4, 6, 8, 10, 12, 14, 16],\n                [8, 7, 6, 5, 4, 3, 2, 1],\n                [1, 1, 2, 2, 3, 3, 4, 4],\n                [5, 5, 5, 5, 5, 5, 5, 5],\n                [1, 0, 1, 0, 1, 0, 1, 0]\n            ],\n            \"betas\": [2, 4, 6, 8, 10],\n            \"B\": 10\n        },\n        {\n            \"X\": [\n                [0.1, 2.1, 1.2, 3.2, 2.8, 1.7, 3.0, 2.5],\n                [2.0, 1.1, 2.2, 1.3, 2.1, 1.4, 2.0, 1.6],\n                [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0],\n                [1.5, 1.4, 1.6, 1.5, 1.7, 1.6, 1.8, 1.7],\n                [3.2, 2.9, 3.1, 3.0, 3.3, 3.1, 3.2, 3.0]\n            ],\n            \"betas\": [1, 2, 3, 4, 5],\n            \"B\": 8\n        },\n        {\n            \"X\": [\n                [1, 2, 3, 4, 5, 6],\n                [2, 3, 4, 5, 6, 7],\n                [3, 4, 5, 6, 7, 8],\n                [10, 10, 10, 10, 10, 10]\n            ],\n            \"betas\": [1, 3, 6],\n            \"B\": 5\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = calculate_sft_fit(case[\"X\"], case[\"betas\"], case[\"B\"])\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    formatted_results = [f\"{r:.4f}\" for r in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"
        }
    ]
}