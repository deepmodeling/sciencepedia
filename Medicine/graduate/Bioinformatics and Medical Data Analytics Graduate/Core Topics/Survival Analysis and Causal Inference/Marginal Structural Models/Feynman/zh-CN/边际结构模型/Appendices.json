{
    "hands_on_practices": [
        {
            "introduction": "要掌握边际结构模型，第一步是精通其核心机制——逆概率加权（IPW）的计算。本练习提供了一个具体的情景，让您通过亲手计算来巩固对非稳定权重和稳定权重的理解，这两种权重是构建伪总体以校正时变混杂的关键。通过这个基础练习，您将为后续更复杂的应用打下坚实的基础 。",
            "id": "4971107",
            "problem": "考虑一项医学领域的观察性纵向队列研究，该研究包含一个二元、时变处理过程 $A_t, t \\in \\{0,1\\}$ 和时变协变量（潜在混杂因素）$L_t, t \\in \\{0,1\\}$。测量的时间顺序为 $L_0$，然后是 $A_0$，接着是 $L_1$，然后是 $A_1$。假设因果识别条件，即一致性、正性和序贯可交换性均成立，并且数据生成过程遵循指定的时间顺序，因此给定历史信息的条件处理分配概率是良定的。目标是拟合一个边际结构模型 (MSM)，并使用逆概率处理加权 (IPTW) 来构建权重，以消除由 $L_t$ 引起的混杂，同时保留边际处理过程。\n\n对于一个观测历史为 $(L_0=1, A_0=1, L_1=1, A_1=1)$ 且时间范围为两个时间点 ($t=0, 1$) 的特定个体，假设以下处理分配概率成立：\n- 基线边际处理概率 $P(A_0=1)=0.6$，\n- 给定基线协变量的基线条件处理概率 $P(A_0=1 \\mid L_0=1)=0.8$，\n- 给定既往处理的随访边际处理概率 $P(A_1=1 \\mid A_0=1)=0.7$，\n- 给定既往处理和当前协变量的随访条件处理概率 $P(A_1=1 \\mid A_0=1, L_1=1)=0.9$。\n\n利用条件概率的核心定义以及 IPTW 用于 MSM 的目的，从基本原理出发，推导该个体的非稳定权重 $w_u$ 和稳定权重 $w_s$ 的表达式，然后计算它们的精确值。请将最终答案表示为最简分数形式的单行矩阵。无需四舍五入；请提供精确值。",
            "solution": "### 解答推导\n目标是使用逆概率处理加权 (IPTW) 方法为一个特定个体计算非稳定权重 ($w_u$) 和稳定权重 ($w_s$)。IPTW 创建一个伪群体，在该群体中，时变混杂因素 $L_t$ 不能预测后续的处理 $A_t$，从而消除随时间变化的混杂。\n\n令 $\\bar{A}_k = (A_0, A_1, \\dots, A_k)$ 表示截至时间点 $k$ 的处理历史，$\\bar{L}_k = (L_0, L_1, \\dots, L_k)$ 表示协变量历史。对于一个在最终时间点 $K$ 之前具有观测历史的个体，其权重的一般形式由特定时间点概率的乘积给出。\n\n非稳定权重 $w_u$ 定义为在给定既往处理和混杂因素历史的条件下，该个体在每个时间点接受其观测到的处理的条件概率乘积的倒数。\n$$w_u = \\prod_{k=0}^{K} \\frac{1}{P(A_k=a_k \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1}, \\bar{L}_k=\\bar{l}_k)}$$\n\n稳定权重 $w_s$ 在此基础上增加了一个分子项，该分子项是仅给定既往处理历史的条件下，个体接受其观测到的处理的条件概率的乘积。这种稳定化处理可以减小方差，并通常使得权重的期望值为 $1$。\n$$w_s = \\prod_{k=0}^{K} \\frac{P(A_k=a_k \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1})}{P(A_k=a_k \\mid \\bar{A}_{k-1}=\\bar{a}_{k-1}, \\bar{L}_k=\\bar{l}_k)}$$\n\n在本问题中，时间范围包含两个时间点 $t=0$ 和 $t=1$，因此我们设 $K=1$。该个体的观测历史为 $(L_0=1, A_0=1, L_1=1, A_1=1)$。因此，$a_0=1, l_0=1, a_1=1, l_1=1$。\n\n对于 $k=0$，历史 $\\bar{A}_{-1}$ 为空。公式变为：\n$$w_u = \\frac{1}{P(A_0=a_0 \\mid L_0=l_0) \\times P(A_1=a_1 \\mid A_0=a_0, \\bar{L}_1=\\bar{l}_1)}$$\n$$w_s = \\frac{P(A_0=a_0) \\times P(A_1=a_1 \\mid A_0=a_0)}{P(A_0=a_0 \\mid L_0=l_0) \\times P(A_1=a_1 \\mid A_0=a_0, \\bar{L}_1=\\bar{l}_1)}$$\n\n问题提供了 $P(A_1=1 \\mid A_0=1, L_1=1)=0.9$。这意味着一个特定的处理分配模型，其中 $A_1$ 的概率取决于当前的混杂因素 $L_1$ 和既往处理 $A_0$，而不取决于基线混杂因素 $L_0$。也就是说，$P(A_1=a_1 \\mid A_0=a_0, \\bar{L}_1=\\bar{l}_1) = P(A_1=a_1 \\mid A_0=a_0, L_1=l_1)$。这是一个常见且有效的设定。\n\n现在我们可以代入给定个体的特定概率。\n\n**计算非稳定权重 ($w_u$)**\n\n对于历史为 $(L_0=1, A_0=1, L_1=1, A_1=1)$ 的个体，权重的分母是以下两项的乘积：\n1. $P(A_0=1 \\mid L_0=1) = 0.8$\n2. $P(A_1=1 \\mid A_0=1, L_1=1) = 0.9$\n\n因此，非稳定权重为：\n$$w_u = \\frac{1}{P(A_0=1 \\mid L_0=1) \\times P(A_1=1 \\mid A_0=1, L_1=1)}$$\n$$w_u = \\frac{1}{0.8 \\times 0.9} = \\frac{1}{0.72}$$\n为将其表示为最简分数：\n$$w_u = \\frac{1}{\\frac{72}{100}} = \\frac{100}{72} = \\frac{25 \\times 4}{18 \\times 4} = \\frac{25}{18}$$\n\n**计算稳定权重 ($w_s$)**\n\n$w_s$ 的分母与用于 $w_u$ 的分母相同。分子是以下两项的乘积：\n1. $P(A_0=1) = 0.6$\n2. $P(A_1=1 \\mid A_0=1) = 0.7$\n\n因此，稳定权重为：\n$$w_s = \\frac{P(A_0=1) \\times P(A_1=1 \\mid A_0=1)}{P(A_0=1 \\mid L_0=1) \\times P(A_1=1 \\mid A_0=1, L_1=1)}$$\n$$w_s = \\frac{0.6 \\times 0.7}{0.8 \\times 0.9} = \\frac{0.42}{0.72}$$\n为将其表示为最简分数：\n$$w_s = \\frac{42}{72} = \\frac{7 \\times 6}{12 \\times 6} = \\frac{7}{12}$$\n\n该个体的非稳定权重为 $w_u = \\frac{25}{18}$，稳定权重为 $w_s = \\frac{7}{12}$。",
            "answer": "$$\\boxed{\\begin{pmatrix} \\frac{25}{18} & \\frac{7}{12} \\end{pmatrix}}$$"
        },
        {
            "introduction": "将理论应用于实际数据是掌握任何统计方法的关键一步。本练习将指导您从零开始，在一个模拟的纵向数据集中实施完整的边际结构模型分析流程，包括计算权重和执行加权最小二乘法（WLS）估计。通过编写代码来解决这个问题，您将把抽象的公式转化为具体的因果效应估计，并探索不同权重设置和模型设定对结果的影响 。",
            "id": "4581093",
            "problem": "您的任务是在一个纵向观测性医学数据集中，针对具有时变暴露的边际结构模型 (MSM)，为连续结局实施加权最小二乘法 (WLS)。目标是估计与用户指定的暴露历史摘要相关的因果参数。您的实现应基于潜在结局框架的基本原则，包括一致性、可交换性和正性，并通过构建从处理分配模型中导出的逆概率权重来进行。\n\n考虑一个由 $n = 8$ 名个体组成的队列，在由 $t \\in \\{1, 2\\}$ 索引的 $2$ 个时间点进行观察。二元暴露序列为 $\\bar A = (A_1, A_2)$，其中对所有个体 $A_t \\in \\{0,1\\}$。基线混杂因素为 $L_0$，时变混杂因素为 $L_1$，由 $L_0$ 和 $A_1$ 确定性地定义。在随访结束时测量的连续最终结局为 $Y$。为数据定义以下数组：\n- 基线混杂因素向量：$L_0 = [-0.5, 0.3, 1.2, -1.0, 0.0, 2.5, -0.8, 1.1]$。\n- 时间点 $1$ 的暴露：$A_1 = [1, 0, 1, 0, 1, 0, 1, 0]$。\n- 时间点 $2$ 的暴露：$A_2 = [1, 1, 0, 0, 1, 0, 0, 1]$。\n- 时变混杂因素由结构方程 $L_1 = \\alpha_0 + \\alpha_1 L_0 + \\alpha_2 A_1$ 确定性地构建，系数为 $\\alpha_0 = 0.2$，$\\alpha_1 = 0.5$ 和 $\\alpha_2 = 0.7$。\n- 连续结局由 $Y = \\theta_0 + \\theta_1 (A_1 + A_2) + \\theta_2 L_0 + \\theta_3 L_1$ 确定性地构建，系数为 $\\theta_0 = 3.0$，$\\theta_1 = 1.8$，$\\theta_2 = 0.6$ 和 $\\theta_3 = 0.4$。\n\n您将拟合工作边际结构模型 (MSM)：$\\mathbb{E}[Y^{\\bar a}] = \\beta_0 + \\beta_1 f(\\bar a)$，其中 $Y^{\\bar a}$ 表示在暴露历史 $\\bar a$ 下的潜在结局，$f(\\bar a)$ 是一个用户指定的函数，用于总结暴露历史。估计应通过使用逆概率权重的 WLS 进行。权重来源于带有 logistic 链接函数的伯努利处理模型。对于在时间点 $t$ 观察到处理 $A_t \\in \\{0,1\\}$ 的个体，其观察到的处理值的概率在分子模型和分母模型下均使用 logistic 函数 $\\text{expit}(x) = \\frac{1}{1 + e^{-x}}$ 进行建模。个体的稳定权重是在 $t \\in \\{1,2\\}$ 上，观察到的 $A_t$ 的分子概率除以观察到的 $A_t$ 的分母概率的乘积。非稳定权重将所有分子概率设置为 $1$。\n\n分母模型使用完整的处理历史和混杂因素：\n- 对于 $t = 1$：$P(A_1 = 1 \\mid L_0) = \\text{expit}(\\gamma_{10} + \\gamma_{11} L_0)$。\n- 对于 $t = 2$：$P(A_2 = 1 \\mid A_1, L_1) = \\text{expit}(\\gamma_{20} + \\gamma_{21} A_1 + \\gamma_{22} L_1)$。\n\n分子模型使用简化的历史来稳定权重：\n- 对于 $t = 1$：$P(A_1 = 1) = \\text{expit}(\\nu_{10})$。\n- 对于 $t = 2$：$P(A_2 = 1 \\mid A_1) = \\text{expit}(\\nu_{20} + \\nu_{21} A_1)$。\n\n对于每个个体，稳定权重为\n$$\nW = \\prod_{t=1}^{2} \\frac{P_{\\text{num}}(A_t \\mid \\text{reduced history})}{P_{\\text{den}}(A_t \\mid \\text{full history})},\n$$\n其中 $P_{\\text{num}}(A_t \\mid \\cdot)$ 和 $P_{\\text{den}}(A_t \\mid \\cdot)$ 分别表示在分子和分母模型下观察到的处理值 $A_t$ 的概率，并且对于 $A_t = 0$，$\\Pr(A_t=0 \\mid \\cdot) = 1 - \\Pr(A_t=1 \\mid \\cdot)$。非稳定权重将分子设置为 $1$。\n\n您必须通过最小化加权残差平方和来实施 WLS 以估计 $(\\beta_0, \\beta_1)$，其设计矩阵的列对应于截距项和暴露摘要 $f(\\bar A)$。通过使用小数表示法来防止概率中出现精确的零或一，以确保数值稳定性；不允许使用百分号。\n\n通过线性组合 $f(\\bar A) = c_1 A_1 + c_2 A_2$ 为每个测试用例定义暴露摘要函数 $f(\\bar A)$，其中系数 $(c_1, c_2)$ 按测试用例指定。\n\n测试套件。为以下四种情况中的每一种计算 $(\\hat \\beta_0, \\hat \\beta_1)$：\n\n- 情况 1 (正常路径):\n  - 稳定权重。\n  - 分母系数：$(\\gamma_{10}, \\gamma_{11}) = (-0.3, 0.8)$ 和 $(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-0.1, 0.7, 0.9)$。\n  - 分子系数：$\\nu_{10} = -0.2$ 和 $(\\nu_{20}, \\nu_{21}) = (-0.05, 0.5)$。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$，因此 $f(\\bar A) = A_1 + A_2$。\n\n- 情况 2 (后期暴露强调):\n  - 稳定权重。\n  - 分母系数：与情况 1 相同。\n  - 分子系数：与情况 1 相同。\n  - 暴露摘要：$(c_1, c_2) = (1, 2)$，因此 $f(\\bar A) = A_1 + 2 A_2$。\n\n- 情况 3 (非稳定权重):\n  - 非稳定权重（分子设置为 $1$）。\n  - 分母系数：与情况 1 相同。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$。\n\n- 情况 4 (边界正性压力测试):\n  - 稳定权重。\n  - 分母系数：$(\\gamma_{10}, \\gamma_{11}) = (-3.0, 3.0)$ 和 $(\\gamma_{20}, \\gamma_{21}, \\gamma_{22}) = (-2.5, 2.0, 2.0)$。\n  - 分子系数：$\\nu_{10} = -0.2$ 和 $(\\nu_{20}, \\nu_{21}) = (-0.05, 0.5)$。\n  - 暴露摘要：$(c_1, c_2) = (1, 1)$。\n\n您的程序应根据具体情况计算稳定或非稳定权重，构建设计矩阵，其列为 $[1, f(\\bar A)]$，并执行 WLS 以估计每种情况的 $(\\hat \\beta_0, \\hat \\beta_1)$。最终输出必须是单行，包含一个逗号分隔的列表的列表，每个案例一个列表，其中每个内部列表按顺序包含两个浮点系数估计值 $[\\hat \\beta_0, \\hat \\beta_1]$，并用方括号括起来。例如，输出格式应为 $[[b_{0,1}, b_{1,1}],[b_{0,2}, b_{1,2}],[b_{0,3}, b_{1,3}],[b_{0,4}, b_{1,4}]]]$, 所有数字都以小数形式表示。",
            "solution": "### 设计与实现\n\n目标是估计一个边际结构模型 (MSM) $\\mathbb{E}[Y^{\\bar a}] = \\beta_0 + \\beta_1 f(\\bar a)$ 的因果参数 $(\\beta_0, \\beta_1)$，该模型用于描述时变二元暴露 $\\bar A$ 下的连续结局 $Y$。估计是在一个存在混杂因素的模拟纵向数据集上进行的。处理本身受过去暴露影响的时变混杂的标准方法是使用逆概率加权 (IPW)。该方法创建一个伪总体，其中暴露与混杂因素无关，从而可以对暴露对结局的边际（无混杂）效应进行无偏估计。估计通过加权最小二乘法 (WLS) 进行。\n\n解决方案分四个主要步骤进行：数据准备、权重计算、WLS 估计以及应用于指定的测试用例。\n\n#### 第 1 步：数据准备\n首先，我们为 $n=8$ 名个体的队列生成完整的数据集。问题提供了基线混杂因素 $L_0$ 和暴露历史 $(A_1, A_2)$。时变混杂因素 $L_1$ 和最终结局 $Y$ 使用指定的结构方程确定性地生成：\n- $L_{1i} = \\alpha_0 + \\alpha_1 L_{0i} + \\alpha_2 A_{1i}$，其中 $\\alpha_0 = 0.2, \\alpha_1 = 0.5, \\alpha_2 = 0.7$。\n- $Y_i = \\theta_0 + \\theta_1 (A_{1i} + A_{2i}) + \\theta_2 L_{0i} + \\theta_3 L_{1i}$，其中 $\\theta_0 = 3.0, \\theta_1 = 1.8, \\theta_2 = 0.6, \\theta_3 = 0.4$。\n这些计算对每个个体 $i=1, \\dots, n$ 执行。\n\n#### 第 2 步：逆概率权重 (IPW) 计算\n对于每个个体 $i$，计算一个逆概率权重 $W_i$。该权重是在给定一组协变量的条件下，在每个时间点观察到的暴露概率的乘积。稳定权重的一般形式是：\n$$\nW_i = \\prod_{t=1}^{2} \\frac{P(A_t = A_{ti} \\mid \\text{Reduced History}_t)}{P(A_t = A_{ti} \\mid \\text{Full History}_t)}\n$$\n概率源自 logistic 模型，$P(A_t=1 | \\mathbf{X}) = \\text{expit}(\\boldsymbol{\\theta}^T \\mathbf{X})$，其中 $\\text{expit}(x) = 1/(1+e^{-x})$。观察到的暴露 $A_{ti}$ 的概率由似然项 $L(A_{ti}) = (p_{ti})^{A_{ti}}(1-p_{ti})^{1-A_{ti}}$ 给出，其中 $p_{ti} = P(A_t=1 | \\text{history})$。\n\n对于每个个体 $i$：\n1.  **分母贡献**：这些概率以混杂因素和过去暴露的完整历史为条件。\n    - 在 $t=1$ 时，观察到的暴露 $A_{1i}$ 的概率由 $P(A_1=1|L_{0i}) = \\text{expit}(\\gamma_{10} + \\gamma_{11}L_{0i})$ 计算。\n    - 在 $t=2$ 时，观察到的暴露 $A_{2i}$ 的概率由 $P(A_2=1|A_{1i}, L_{1i}) = \\text{expit}(\\gamma_{20} + \\gamma_{21}A_{1i} + \\gamma_{22}L_{1i})$ 计算。\n    总的分母项是这两个概率的乘积。\n\n2.  **分子贡献**：这些概率以简化的变量集（仅过去暴露）为条件，以稳定权重，减小其方差。\n    - 在 $t=1$ 时，$A_{1i}$ 的概率来自 $P(A_1=1) = \\text{expit}(\\nu_{10})$。\n    - 在 $t=2$ 时，$A_{2i}$ 的概率来自 $P(A_2=1|A_{1i}) = \\text{expit}(\\nu_{20} + \\nu_{21}A_{1i})$。\n    总的分子项是这两个概率的乘积。\n\n对于**非稳定权重**，如情况 3 所要求，每个时间点的分子贡献就是 $1$，导致总分子为 $1$。权重则变为在给定完整历史的情况下观察到的暴露序列的联合概率的倒数。\n\n#### 第 3 步：加权最小二乘法 (WLS) 估计\nMSM 的参数 $(\\beta_0, \\beta_1)$ 是通过使用 WLS 拟合模型 $Y_i = \\beta_0 + \\beta_1 f(\\bar A_i) + \\epsilon_i$ 来估计的，其中权重 $W_i$ 在上一步中计算。参数向量 $\\boldsymbol{\\beta} = [\\beta_0, \\beta_1]^T$ 的 WLS 估计量由闭式解给出：\n$$\n\\hat{\\boldsymbol{\\beta}} = (X^T \\mathbf{W} X)^{-1} X^T \\mathbf{W} \\mathbf{y}\n$$\n这里，$\\mathbf{y}$ 是结局 $Y_i$ 的 $n \\times 1$ 向量。$X$ 是 $n \\times 2$ 的设计矩阵，其中第一列是全为一的向量（用于截距项 $\\beta_0$），第二列是暴露摘要函数值 $f(\\bar A_i)$ 的向量。$\\mathbf{W}$ 是一个 $n \\times n$ 的对角矩阵，对角线上是权重 $W_i$。在计算上，这个系统可以高效求解而无需显式求逆，例如，通过求解线性系统 $(X^T \\mathbf{W} X)\\hat{\\boldsymbol{\\beta}} = X^T \\mathbf{W} \\mathbf{y}$。\n\n#### 第 4 步：应用于测试用例\n对四个测试用例中的每一个执行步骤 1-3 中概述的程序。每个用例都为权重模型（$\\gamma$ 系数、$\\nu$ 系数）、权重类型（稳定或非稳定）以及暴露摘要函数 $f(\\bar A)$ 提供了一组特定的参数。每个用例得到的估计值 $(\\hat{\\beta}_0, \\hat{\\beta}_1)$ 被收集起来，并以要求的格式呈现。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit\n\ndef solve():\n    \"\"\"\n    Implements Weighted Least Squares (WLS) for a Marginal Structural Model (MSM)\n    to estimate causal parameters from a simulated longitudinal dataset.\n    \"\"\"\n    \n    # Step 1: Define initial data and generate the full dataset\n    # Given data from the problem statement\n    L0 = np.array([-0.5, 0.3, 1.2, -1.0, 0.0, 2.5, -0.8, 1.1])\n    A1 = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n    A2 = np.array([1, 1, 0, 0, 1, 0, 0, 1])\n    n = len(L0)\n\n    # Deterministic generation of L1 and Y\n    alpha = {'a0': 0.2, 'a1': 0.5, 'a2': 0.7}\n    L1 = alpha['a0'] + alpha['a1'] * L0 + alpha['a2'] * A1\n\n    theta = {'th0': 3.0, 'th1': 1.8, 'th2': 0.6, 'th3': 0.4}\n    Y = theta['th0'] + theta['th1'] * (A1 + A2) + theta['th2'] * L0 + theta['th3'] * L1\n\n    # Test suite definition\n    test_cases = [\n        # Case 1: stabilized, f(A) = A1+A2\n        {'type': 'stabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 1)},\n        # Case 2: stabilized, f(A) = A1+2*A2\n        {'type': 'stabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 2)},\n        # Case 3: unstabilized, f(A) = A1+A2\n        {'type': 'unstabilized', \n         'gamma1': (-0.3, 0.8), 'gamma2': (-0.1, 0.7, 0.9),\n         'nu1': None, 'nu2': None, # Not used\n         'c_coeffs': (1, 1)},\n        # Case 4: positivity stress test\n        {'type': 'stabilized', \n         'gamma1': (-3.0, 3.0), 'gamma2': (-2.5, 2.0, 2.0),\n         'nu1': (-0.2,), 'nu2': (-0.05, 0.5),\n         'c_coeffs': (1, 1)},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Step 2: Compute Inverse Probability Weights (W)\n        \n        # Denominator probabilities\n        gamma10, gamma11 = case['gamma1']\n        p_den_t1 = expit(gamma10 + gamma11 * L0)\n        \n        gamma20, gamma21, gamma22 = case['gamma2']\n        p_den_t2 = expit(gamma20 + gamma21 * A1 + gamma22 * L1)\n\n        # Likelihood of observed treatment in denominator\n        like_den_t1 = A1 * p_den_t1 + (1 - A1) * (1 - p_den_t1)\n        like_den_t2 = A2 * p_den_t2 + (1 - A2) * (1 - p_den_t2)\n        \n        total_den_like = like_den_t1 * like_den_t2\n\n        # Numerator probabilities and total likelihood\n        if case['type'] == 'stabilized':\n            nu10, = case['nu1']\n            p_num_t1 = expit(nu10)\n            \n            nu20, nu21 = case['nu2']\n            p_num_t2 = expit(nu20 + nu21 * A1)\n            \n            like_num_t1 = A1 * p_num_t1 + (1 - A1) * (1 - p_num_t1)\n            like_num_t2 = A2 * p_num_t2 + (1 - A2) * (1 - p_num_t2)\n            \n            total_num_like = like_num_t1 * like_num_t2\n        else: # unstabilized\n            total_num_like = 1.0\n\n        # Final weights\n        weights = total_num_like / total_den_like\n\n        # Step 3: Weighted Least Squares (WLS) Estimation\n        c1, c2 = case['c_coeffs']\n        f_A = c1 * A1 + c2 * A2\n        \n        # Design matrix X with intercept and exposure summary\n        X = np.c_[np.ones(n), f_A]\n        \n        # Solve the normal equations for WLS: (X'WX)b = X'Wy\n        # This is more stable than direct inversion.\n        # Let X_w = sqrt(W) * X and Y_w = sqrt(W) * Y. Then solve (X_w'X_w)b = X_w'Y_w\n        sqrt_w = np.sqrt(weights)\n        X_w = X * sqrt_w[:, np.newaxis]\n        Y_w = Y * sqrt_w\n        \n        beta_hat = np.linalg.solve(X_w.T @ X_w, X_w.T @ Y_w)\n        \n        results.append(beta_hat.tolist())\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        }
    ]
}