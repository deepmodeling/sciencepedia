{
    "hands_on_practices": [
        {
            "introduction": "逆概率加权 (Inverse Probability Weighting, IPW) 是根据观测数据估计因果效应的一项基本技术。它通过创建一个伪总体，使得在该伪总体中，处理分配与已测混杂因素无关，从而模拟随机试验。本练习  是理解 IPW 的关键第一步，你将正式证明，当倾向得分模型被正确指定时，该估计量是平均处理效应 (Average Treatment Effect, ATE) 的无偏估计。",
            "id": "4545088",
            "problem": "考虑一项生物信息学和医学数据分析领域的观察性队列研究，该研究评估一个二元处理（用 $A \\in \\{0,1\\}$ 表示）对一个在处理后测量的连续生物标志物结局 $Y \\in \\mathbb{R}$ 的影响。每个受试者都具有处理前的协变量 $X \\in \\mathbb{R}^{p}$，并且处理分配机制由真实倾向性得分 $e(X) = \\Pr(A=1 \\mid X)$ 描述。设潜在结局为 $Y(1)$ 和 $Y(0)$，并将平均处理效应 (Average Treatment Effect, ATE) 定义为 $\\tau = \\mathbb{E}[Y(1) - Y(0)]$。假设满足以下标准的可识别性条件：稳定单元处理值假设 (Stable Unit Treatment Value Assumption, SUTVA)、一致性 ($Y = A Y(1) + (1-A) Y(0)$)、条件可忽略性 ($(Y(1), Y(0)) \\perp A \\mid X$) 和正值性 ($0  e(X)  1$ 几乎必然成立)。您从该数据生成过程中观察到一个独立同分布的样本 $\\{(X_i, A_i, Y_i)\\}_{i=1}^{n}$。\n\n假设估计的倾向性得分 $\\hat{e}(X)$ 是正确设定的，以至于 $\\hat{e}(X) = e(X)$ 几乎必然成立。将平均处理效应 (ATE) 的逆概率加权 (Inverse Probability Weighting, IPW) 估计量定义为\n$$\n\\hat{\\tau} \\;=\\; \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{A_i Y_i}{\\hat{e}(X_i)} \\;-\\; \\frac{(1 - A_i) Y_i}{1 - \\hat{e}(X_i)} \\right).\n$$\n在所述条件和 $\\hat{e}(X)$ 正确设定的情况下，推导其无条件期望 $\\mathbb{E}[\\hat{\\tau}]$。将您的最终答案表示为关于潜在结局的单一封闭形式解析表达式。无需四舍五入，也不涉及物理单位。",
            "solution": "首先根据所提供的信息评估问题陈述的有效性。\n\n### 步骤 1：提取已知条件\n- **处理：** 一个二元变量 $A \\in \\{0,1\\}$。\n- **结局：** 一个连续生物标志物 $Y \\in \\mathbb{R}$。\n- **协变量：** 一个处理前协变量的向量 $X \\in \\mathbb{R}^{p}$。\n- **真实倾向性得分：** $e(X) = \\Pr(A=1 \\mid X)$。\n- **潜在结局：** $Y(1)$ 和 $Y(0)$。\n- **平均处理效应 (ATE)：** $\\tau = \\mathbb{E}[Y(1) - Y(0)]$。\n- **可识别性假设：**\n    1.  稳定单元处理值假设 (SUTVA)。\n    2.  一致性：$Y = A Y(1) + (1-A) Y(0)$。\n    3.  条件可忽略性：$(Y(1), Y(0)) \\perp A \\mid X$。\n    4.  正值性：$0  e(X)  1$ 几乎必然成立。\n- **数据：** 一个独立同分布 (i.i.d.) 的样本 $\\{(X_i, A_i, Y_i)\\}_{i=1}^{n}$。\n- **估计量设定：** 估计的倾向性得分是正确设定的，即 $\\hat{e}(X) = e(X)$ 几乎必然成立。\n- **估计量定义：** 逆概率加权 (IPW) 估计量为 $\\hat{\\tau} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{A_i Y_i}{\\hat{e}(X_i)} - \\frac{(1 - A_i) Y_i}{1 - \\hat{e}(X_i)} \\right)$。\n- **目标：** 推导无条件期望 $\\mathbb{E}[\\hat{\\tau}]$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，是因果推断领域的一个标准理论问题，而因果推断是生物统计学和生物信息学的核心领域。这是一个适定问题，提供了所有必要的假设（SUTVA、一致性、可忽略性、正值性）以及一个正确设定的倾向性得分模型，这些都是推导 IPW 估计量期望所需的充分条件。该问题是客观的，用精确的数学语言陈述。它不违反任何基本原则，不是不完整或矛盾的，并且代表了该主题领域的一个基础性推导。条件 $\\hat{e}(X) = e(X)$ 是分析此类估计量偏差的标准简化假设，代表了一个理想化但理论上重要的场景。\n\n### 步骤 3：结论与行动\n问题是有效的。将提供一个完整的、有理有据的解决方案。\n\n### $\\mathbb{E}[\\hat{\\tau}]$ 的推导\n目标是计算 IPW 估计量的期望 $\\mathbb{E}[\\hat{\\tau}]$。\n估计量由下式给出：\n$$\n\\hat{\\tau} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{A_i Y_i}{\\hat{e}(X_i)} - \\frac{(1 - A_i) Y_i}{1 - \\hat{e}(X_i)} \\right)\n$$\n根据倾向性得分模型被正确设定的假设，我们有 $\\hat{e}(X_i) = e(X_i)$。估计量可以写成：\n$$\n\\hat{\\tau} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{A_i Y_i}{e(X_i)} - \\frac{(1 - A_i) Y_i}{1 - e(X_i)} \\right)\n$$\n根据期望的线性性质，我们有：\n$$\n\\mathbb{E}[\\hat{\\tau}] = \\mathbb{E}\\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left( \\frac{A_i Y_i}{e(X_i)} - \\frac{(1 - A_i) Y_i}{1 - e(X_i)} \\right) \\right] = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{E}\\left[ \\frac{A_i Y_i}{e(X_i)} - \\frac{(1 - A_i) Y_i}{1 - e(X_i)} \\right]\n$$\n由于观测值是独立同分布的，所以对所有 $i$ 的期望都是相同的。因此，我们可以省略下标 $i$，分析单个观测值的期望：\n$$\n\\mathbb{E}[\\hat{\\tau}] = \\mathbb{E}\\left[ \\frac{A Y}{e(X)} - \\frac{(1 - A) Y}{1 - e(X)} \\right] = \\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\right] - \\mathbb{E}\\left[ \\frac{(1 - A) Y}{1 - e(X)} \\right]\n$$\n我们将使用全期望定律 $\\mathbb{E}[Z] = \\mathbb{E}_X[\\mathbb{E}[Z \\mid X]]$ 分别计算这两项。\n\n对于第一项 $\\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\right]$：\n$$\n\\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\right] = \\mathbb{E}_X\\left[ \\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\mid X \\right] \\right]\n$$\n在以 $X$ 为条件时，倾向性得分 $e(X)$ 是一个固定值。因此，\n$$\n\\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\mid X \\right] = \\frac{1}{e(X)} \\mathbb{E}[A Y \\mid X]\n$$\n使用一致性假设 $Y = A Y(1) + (1-A) Y(0)$，我们可以写出 $AY = A(A Y(1) + (1-A) Y(0)) = A^2 Y(1) + A(1-A) Y(0)$。由于 $A$ 是二元的，所以 $A^2 = A$ 且 $A(1-A) = 0$。这可以简化为 $AY = AY(1)$。\n将此代入条件期望中：\n$$\n\\mathbb{E}[A Y \\mid X] = \\mathbb{E}[A Y(1) \\mid X]\n$$\n接下来，我们应用条件可忽略性假设 $(Y(1), Y(0)) \\perp A \\mid X$，这意味着在给定 $X$ 的条件下，$A$ 与 $Y(1)$ 独立。因此，我们可以分解这个期望：\n$$\n\\mathbb{E}[A Y(1) \\mid X] = \\mathbb{E}[A \\mid X] \\mathbb{E}[Y(1) \\mid X]\n$$\n根据定义，倾向性得分是 $e(X) = \\Pr(A=1 \\mid X) = \\mathbb{E}[A \\mid X]$。所以，\n$$\n\\mathbb{E}[A Y(1) \\mid X] = e(X) \\mathbb{E}[Y(1) \\mid X]\n$$\n将此代回第一项的条件期望表达式中：\n$$\n\\mathbb{E}\\left[ \\frac{A Y}{e(X)} \\mid X \\right] = \\frac{1}{e(X)} \\left( e(X) \\mathbb{E}[Y(1) \\mid X] \\right) = \\mathbb{E}[Y(1) \\mid X]\n$$\n对 $X$ 取外层期望：\n$$\n\\mathbb{E}_X\\left[ \\mathbb{E}[Y(1) \\mid X] \\right] = \\mathbb{E}[Y(1)]\n$$\n因此，第一项的计算结果为 $\\mathbb{E}[Y(1)]$。\n\n对于第二项 $-\\mathbb{E}\\left[ \\frac{(1 - A) Y}{1 - e(X)} \\right]$，过程是类似的：\n$$\n\\mathbb{E}\\left[ \\frac{(1 - A) Y}{1 - e(X)} \\right] = \\mathbb{E}_X\\left[ \\mathbb{E}\\left[ \\frac{(1 - A) Y}{1 - e(X)} \\mid X \\right] \\right] = \\mathbb{E}_X\\left[ \\frac{1}{1-e(X)} \\mathbb{E}[(1-A)Y \\mid X] \\right]\n$$\n使用一致性，$(1-A)Y = (1-A)(A Y(1) + (1-A) Y(0)) = (1-A)A Y(1) + (1-A)^2 Y(0)$。由于 $A$ 是二元的，这简化为 $(1-A)Y = (1-A)Y(0)$。\n条件期望变为：\n$$\n\\mathbb{E}[(1-A)Y \\mid X] = \\mathbb{E}[(1-A)Y(0) \\mid X]\n$$\n使用条件可忽略性 $(Y(1), Y(0)) \\perp A \\mid X$，我们分解这个期望：\n$$\n\\mathbb{E}[(1-A)Y(0) \\mid X] = \\mathbb{E}[1-A \\mid X] \\mathbb{E}[Y(0) \\mid X]\n$$\n项 $\\mathbb{E}[1-A \\mid X] = 1 - \\mathbb{E}[A \\mid X] = 1 - e(X)$。所以，\n$$\n\\mathbb{E}[(1-A)Y(0) \\mid X] = (1 - e(X)) \\mathbb{E}[Y(0) \\mid X]\n$$\n将此代回：\n$$\n\\frac{1}{1-e(X)} \\mathbb{E}[(1-A)Y \\mid X] = \\frac{1}{1-e(X)} \\left( (1-e(X)) \\mathbb{E}[Y(0) \\mid X] \\right) = \\mathbb{E}[Y(0) \\mid X]\n$$\n对 $X$ 取外层期望：\n$$\n\\mathbb{E}_X\\left[ \\mathbb{E}[Y(0) \\mid X] \\right] = \\mathbb{E}[Y(0)]\n$$\n因此，第二项的计算结果为 $\\mathbb{E}[Y(0)]$。\n\n最后，结合两项的结果：\n$$\n\\mathbb{E}[\\hat{\\tau}] = \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]\n$$\n这个表达式就是平均处理效应 $\\tau$ 的定义。因此，在所述条件下，IPW 估计量是 ATE 的一个无偏估计量，其中最关键的条件是真实倾向性得分已知。\n\n最终答案是推导出的以潜在结局表示的估计量期望的表达式。",
            "answer": "$$\n\\boxed{\\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)]}\n$$"
        },
        {
            "introduction": "虽然像 IPW 这样的方法通过加权样本来处理混杂，但另一种流行的方法是结果回归建模，常用于 g-computation。然而，这种方法的有效性取决于一个关键假设：结果模型被正确指定。本实践问题  探讨了违反此假设的后果，要求你推导当模型中忽略了一个关键的交互项时所产生的偏误的解析表达式。",
            "id": "4545155",
            "problem": "考虑一项生物信息学和医学数据分析领域的观察性队列研究，旨在评估一种二元抗炎治疗 $A \\in \\{0,1\\}$ 对连续临床结局 $Y$（例如，经对数转换的C-reactive protein）的因果效应，其中分子协变量 $X$ 表示一个标准化的基因表达得分。假设采用潜在结局框架，其中 $Y^{a}$ 表示在治疗水平 $a$ 下的结局。假设以下核心识别条件成立：条件可交换性（可忽略性）$Y^{a} \\perp A \\,|\\, X$、一致性 $Y = Y^{A}$ 以及正值性 $0  \\mathbb{P}(A=1 \\,|\\, X)  1$ 几乎必然成立。\n\n假设真实的结局回归函数是线性的，并且包含治疗与协变量之间的交互作用，由下式给出\n$$\n\\mathbb{E}[Y \\,|\\, A, X] \\;=\\; \\beta_{0} \\;+\\; \\beta_{1} A \\;+\\; \\beta_{2} X \\;+\\; \\beta_{3} A X,\n$$\n其中 $\\mathbb{E}[\\varepsilon \\,|\\, A, X] = 0$ 且 $Y = \\mathbb{E}[Y \\,|\\, A, X] + \\varepsilon$。然而，一位分析师拟合了一个错误设定的线性结局模型，该模型忽略了交互作用项：\n$$\n\\mathbb{E}[Y \\,|\\, A, X] \\approx \\alpha_{0} \\;+\\; \\alpha_{1} A \\;+\\; \\alpha_{2} X.\n$$\n基于这个错误设定的模型，该分析师使用参数 g-计算来估计平均治疗效应 (ATE)，其定义为 $\\tau := \\mathbb{E}[Y^{1} - Y^{0}]$，估计方法如下\n$$\n\\hat{\\tau} \\;=\\; \\frac{1}{n} \\sum_{i=1}^{n} \\left\\{ \\widehat{\\mathbb{E}}[Y \\,|\\, A=1, X_{i}] \\;-\\; \\widehat{\\mathbb{E}}[Y \\,|\\, A=0, X_{i}] \\right\\},\n$$\n在上述错误设定的线性模型下，该式可简化为 $\\hat{\\tau} = \\alpha_{1}$。\n\n设 $(A, X)$ 的联合分布是任意的，但满足所述的识别条件，并定义以下总体矩：\n$$\np := \\mathbb{E}[A], \\quad m := \\mathbb{E}[X], \\quad q := \\mathbb{E}[X^{2}], \\quad c := \\mathbb{E}[A X], \\quad d := \\mathbb{E}[A X^{2}].\n$$\n仅从识别条件、真实结局模型以及普通最小二乘估计量的大数定律出发，推导错误设定的结局回归 g-计算估计量的大样本偏差，\n$$\nB \\;:=\\; \\lim_{n \\to \\infty} \\hat{\\tau} \\;-\\; \\tau,\n$$\n并将其表示为仅含 $\\beta_{3}$ 和上述定义的矩 $p, m, q, c, d$ 的单个闭式解析表达式。您的最终答案必须是单个解析表达式。最终答案中不要提供中间等式。无需四舍五入。最终答案以无单位形式表示。",
            "solution": "用户希望在结局回归模型设定错误的情况下，求出平均治疗效应 (ATE) 估计量的大样本偏差。偏差定义为 $B := \\lim_{n \\to \\infty} \\hat{\\tau} - \\tau$。\n\n首先，我们推导真实的平均治疗效应 $\\tau := \\mathbb{E}[Y^{1} - Y^{0}]$。\n在所述的识别条件（条件可交换性和一致性）下，潜在结局均值 $\\mathbb{E}[Y^a]$ 可以从观测分布中识别出来。根据迭代期望定律：\n$$\n\\mathbb{E}[Y^{a}] = \\mathbb{E}_{X}[\\mathbb{E}[Y^{a} | X]]\n$$\n根据条件可交换性 $Y^{a} \\perp A \\,|\\, X$，可得 $\\mathbb{E}[Y^{a} | X] = \\mathbb{E}[Y^{a} | A=a, X]$。\n根据一致性 $Y = Y^{A}$，可得 $\\mathbb{E}[Y^{a} | A=a, X] = \\mathbb{E}[Y | A=a, X]$。\n因此，我们有 $\\mathbb{E}[Y^{a}] = \\mathbb{E}_{X}[\\mathbb{E}[Y | A=a, X]]$。\n\n我们使用给定的真实结局回归模型：\n$$\n\\mathbb{E}[Y | A, X] = \\beta_{0} + \\beta_{1} A + \\beta_{2} X + \\beta_{3} A X\n$$\n对于 $A=1$：\n$$\n\\mathbb{E}[Y | A=1, X] = \\beta_{0} + \\beta_{1}(1) + \\beta_{2} X + \\beta_{3}(1)X = \\beta_{0} + \\beta_{1} + \\beta_{2} X + \\beta_{3} X\n$$\n对于 $A=0$：\n$$\n\\mathbb{E}[Y | A=0, X] = \\beta_{0} + \\beta_{1}(0) + \\beta_{2} X + \\beta_{3}(0)X = \\beta_{0} + \\beta_{2} X\n$$\n现在我们通过对 $X$ 的分布进行边缘化来计算期望 $\\mathbb{E}[Y^1]$ 和 $\\mathbb{E}[Y^0]$：\n$$\n\\mathbb{E}[Y^{1}] = \\mathbb{E}_{X}[\\beta_{0} + \\beta_{1} + \\beta_{2} X + \\beta_{3} X] = \\beta_{0} + \\beta_{1} + \\beta_{2} \\mathbb{E}[X] + \\beta_{3} \\mathbb{E}[X]\n$$\n$$\n\\mathbb{E}[Y^{0}] = \\mathbb{E}_{X}[\\beta_{0} + \\beta_{2} X] = \\beta_{0} + \\beta_{2} \\mathbb{E}[X]\n$$\n真实的 ATE, $\\tau$, 是两者之差：\n$$\n\\tau = \\mathbb{E}[Y^{1}] - \\mathbb{E}[Y^{0}] = (\\beta_{0} + \\beta_{1} + \\beta_{2} \\mathbb{E}[X] + \\beta_{3} \\mathbb{E}[X]) - (\\beta_{0} + \\beta_{2} \\mathbb{E}[X]) = \\beta_{1} + \\beta_{3} \\mathbb{E}[X]\n$$\n使用给定的矩定义 $m := \\mathbb{E}[X]$，真实的 ATE 为：\n$$\n\\tau = \\beta_{1} + \\beta_{3} m\n$$\n\n接下来，我们确定估计量 $\\hat{\\tau}$ 的大样本极限。该估计量基于一个错误设定的线性模型：\n$$\n\\mathbb{E}[Y | A, X] \\approx \\alpha_{0} + \\alpha_{1} A + \\alpha_{2} X\n$$\n使用该模型的 g-计算所得的 ATE 估计量为 $\\hat{\\tau} = \\hat{\\alpha}_{1}$，其中 $\\hat{\\alpha}_{1}$ 是对 $A$ 的系数的普通最小二乘 (OLS) 估计。根据 OLS 估计量的大数定律，当样本量 $n \\to \\infty$ 时，估计值 $\\hat{\\alpha}_{1}$ 依概率收敛于总体参数 $\\alpha_{1}$。\n因此，$\\lim_{n \\to \\infty} \\hat{\\tau} = \\alpha_{1}$。\n\n总体参数 $(\\alpha_{0}, \\alpha_{1}, \\alpha_{2})$ 是 $Y$ 对 $1$, $A$ 和 $X$ 进行总体 OLS 回归所得的系数。关于遗漏变量偏差的一个标准结论指出，如果真实模型是 $Y = X\\beta + W\\gamma + \\varepsilon$ 而我们拟合的模型是 $Y = X\\alpha + \\nu$，那么估计系数向量 $\\alpha$ 的总体值为 $\\alpha = \\beta + P\\gamma$，其中 $P$ 是遗漏变量 $W$ 对包含变量 $X$ 进行总体回归所得的系数。\n\n在我们的例子中，真实模型是 $Y = \\beta_{0} + \\beta_{1} A + \\beta_{2} X + \\beta_{3} AX + \\varepsilon$。\n拟合的模型是 $Y = \\alpha_{0} + \\alpha_{1} A + \\alpha_{2} X + \\text{error}$。\n包含的回归量是 $(1, A, X)$，遗漏的回归量是 $AX$。遗漏变量的系数是 $\\beta_{3}$。估计系数与真实系数的关系如下：\n$$\n\\begin{pmatrix} \\alpha_{0} \\\\ \\alpha_{1} \\\\ \\alpha_{2} \\end{pmatrix} = \\begin{pmatrix} \\beta_0 \\\\ \\beta_1 \\\\ \\beta_2 \\end{pmatrix} + \\beta_3 \\begin{pmatrix} \\delta_0 \\\\ \\delta_1 \\\\ \\delta_2 \\end{pmatrix}\n$$\n其中 $(\\delta_0, \\delta_1, \\delta_2)$ 是将遗漏变量 $AX$ 对包含变量 $(1, A, X)$ 进行辅助 OLS 回归得到的总体系数：\n$$\nAX = \\delta_{0} + \\delta_{1} A + \\delta_{2} X + \\text{residual}\n$$\n由此可知 $\\alpha_{1} = \\beta_{1} + \\beta_{3} \\delta_{1}$。\n那么偏差就是：\n$B = \\lim_{n \\to \\infty} \\hat{\\tau} - \\tau = \\alpha_{1} - \\tau = (\\beta_{1} + \\beta_{3} \\delta_{1}) - (\\beta_{1} + \\beta_{3} m) = \\beta_{3}(\\delta_{1} - m)$。\n\n为了求出 $\\delta_1$，我们求解将 $AX$ 对 $(1, A, X)$ 进行辅助回归的总体正规方程。设回归量向量为 $W = (1, A, X)^T$。系数 $\\delta = (\\delta_0, \\delta_1, \\delta_2)^T$ 满足 $\\mathbb{E}[W W^T]\\delta = \\mathbb{E}[W(AX)]$。\n方程组为：\n$$\n\\begin{pmatrix} \\mathbb{E}[1]  \\mathbb{E}[A]  \\mathbb{E}[X] \\\\ \\mathbb{E}[A]  \\mathbb{E}[A^2]  \\mathbb{E}[AX] \\\\ \\mathbb{E}[X]  \\mathbb{E}[AX]  \\mathbb{E}[X^2] \\end{pmatrix} \\begin{pmatrix} \\delta_0 \\\\ \\delta_1 \\\\ \\delta_2 \\end{pmatrix} = \\begin{pmatrix} \\mathbb{E}[AX] \\\\ \\mathbb{E}[A(AX)] \\\\ \\mathbb{E}[X(AX)] \\end{pmatrix}\n$$\n由于 $A$ 是二元的 ($A \\in \\{0,1\\}$)，我们有 $A^2=A$。使用给定的矩定义（$p=\\mathbb{E}[A]$, $m=\\mathbb{E}[X]$, $q=\\mathbb{E}[X^2]$, $c=\\mathbb{E}[AX]$, $d=\\mathbb{E}[AX^2]$），该方程组变为：\n$$\n\\begin{pmatrix} 1  p  m \\\\ p  p  c \\\\ m  c  q \\end{pmatrix} \\begin{pmatrix} \\delta_0 \\\\ \\delta_1 \\\\ \\delta_2 \\end{pmatrix} = \\begin{pmatrix} c \\\\ c \\\\ d \\end{pmatrix}\n$$\n我们只需要解出 $\\delta_1$。我们可以使用克莱姆法则。系数 $\\delta_1$ 由两个行列式的比值给出。\n主矩阵的行列式为 $D_{M} = \\det \\begin{pmatrix} 1  p  m \\\\ p  p  c \\\\ m  c  q \\end{pmatrix} = 1(pq-c^2) - p(pq-mc) + m(pc-mp) = pq-c^2-p^2q+2mpc-m^2p$。这可以用方差和协方差表示：$D_{M} = (p-p^2)(q-m^2) - (c-pm)^2$。\n\n为了求出 $\\delta_1$，我们将第二列替换为右侧向量：\n$$\n\\delta_1 = \\frac{\\det \\begin{pmatrix} 1  c  m \\\\ p  c  c \\\\ m  d  q \\end{pmatrix}}{D_{M}} = \\frac{1(cq - cd) - c(pq - mc) + m(pd - mc)}{D_{M}}\n$$\n$$\n\\delta_1 = \\frac{cq - cd - cpq + mc^2 + mpd - m^2c}{(p-p^2)(q-m^2) - (c-pm)^2}\n$$\n对这个分子进行因式分解是繁琐的。一个更直接的方法是，在剔除截距后，先求解我们得到的关于中心化变量的 $2 \\times 2$ 方程组。这给出：\n$$\n\\begin{pmatrix} \\text{Var}(A)  \\text{Cov}(A,X) \\\\ \\text{Cov}(A,X)  \\text{Var}(X) \\end{pmatrix} \\begin{pmatrix} \\delta_1 \\\\ \\delta_2 \\end{pmatrix} = \\begin{pmatrix} \\text{Cov}(A,AX) \\\\ \\text{Cov}(X,AX) \\end{pmatrix}\n$$\n各项为：\n$\\text{Var}(A) = \\mathbb{E}[A^2] - (\\mathbb{E}[A])^2 = p-p^2$。\n$\\text{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = q-m^2$。\n$\\text{Cov}(A,X) = \\mathbb{E}[AX] - \\mathbb{E}[A]\\mathbb{E}[X] = c-pm$。\n$\\text{Cov}(A,AX) = \\mathbb{E}[A(AX)] - \\mathbb{E}[A]\\mathbb{E}[AX] = \\mathbb{E}[A^2X] - p c = \\mathbb{E}[AX] - pc = c-pc = c(1-p)$。\n$\\text{Cov}(X,AX) = \\mathbb{E}[X(AX)] - \\mathbb{E}[X]\\mathbb{E}[AX] = \\mathbb{E}[AX^2] - mc = d-mc$。\n\n对这个 $2 \\times 2$ 方程组使用克莱姆法则求解 $\\delta_1$：\n$$\n\\delta_1 = \\frac{\\det \\begin{pmatrix} c(1-p)  c-pm \\\\ d-mc  q-m^2 \\end{pmatrix}}{\\det \\begin{pmatrix} p-p^2  c-pm \\\\ c-pm  q-m^2 \\end{pmatrix}} = \\frac{c(1-p)(q-m^2) - (c-pm)(d-mc)}{(p-p^2)(q-m^2) - (c-pm)^2}\n$$\n现在我们计算偏差 $B = \\beta_{3}(\\delta_{1} - m)$：\n$$\nB = \\beta_{3} \\left[ \\frac{c(1-p)(q-m^2) - (c-pm)(d-mc)}{(p-p^2)(q-m^2) - (c-pm)^2} - m \\right]\n$$\n为了将其写成单个分数的形式，我们通分：\n$$\nB = \\beta_{3} \\frac{c(1-p)(q-m^2) - (c-pm)(d-mc) - m \\left[ (p-p^2)(q-m^2) - (c-pm)^2 \\right]}{(p-p^2)(q-m^2) - (c-pm)^2}\n$$\n这就是偏差关于指定量的最终闭式表达式。",
            "answer": "$$\n\\boxed{\\beta_{3} \\frac{c(1-p)(q-m^2) - (c-pm)(d-mc) - m \\left( (p-p^2)(q-m^2) - (c-pm)^2 \\right)}{(p-p^2)(q-m^2) - (c-pm)^2}}\n$$"
        },
        {
            "introduction": "除了参数模型设定不当之外，即使出于良好意图，协变量调整中的不当选择也可能引入偏误。因果有向无环图 (Directed Acyclic Graphs, DAGs) 是驾驭这些结构复杂性的重要工具。本练习  展示了一个被称为 M-偏误的经典“对撞偏误” (collider bias) 案例，其中对某个特定变量进行调整会错误地打开一条暴露与结果之间的非因果路径，从而引入虚假的关联。",
            "id": "4145189",
            "problem": "在一项关于静息态脑活动的功能性磁共振成像 (fMRI) 研究中，考虑一个包含变量 $X$、$A$、$U$、$B$ 和 $Y$ 的有向无环图 (DAG)，其排列方式为 $X \\to A \\leftarrow U \\to B \\to Y$。此处，$X$ 表示根据帧间位移计算的头部运动幅度，$U$ 表示未观测到的生理唤醒，$A$ 表示一个受运动和唤醒共同影响的数据驱动的图像质量指标（例如，独立成分分析伪影成分），$B$ 表示受唤醒影响的全局信号回归量，$Y$ 表示在感兴趣皮层区域内平均的血氧水平依赖 (BOLD) 信号。假设一个与该图一致的结构因果模型 (SCM)，其中每个节点都由一个线性结构方程生成，并带有相互独立、零均值的高斯噪声：\n$$\nX = \\varepsilon_X,\\quad U = \\varepsilon_U,\\quad A = \\alpha_X X + \\alpha_U U + \\varepsilon_A,\\quad B = \\beta U + \\varepsilon_B,\\quad Y = \\gamma B + \\varepsilon_Y,\n$$\n其中所有噪声 $\\varepsilon_X,\\varepsilon_U,\\varepsilon_A,\\varepsilon_B,\\varepsilon_Y$ 都是相互独立、零均值、具有有限正方差的高斯变量。在 DAG 中，从 $X$到 $Y$ 没有直接的因果箭头。请仅使用因果图模型的基本定义（例如，d-分离、对撞路径、后门准则）和线性高斯模型的公认事实（例如，多元正态分布中协方差和条件协方差的性质）来推断统计关联。\n\n在这种情况下，以下哪些陈述是正确的？选择所有适用的选项。\n\nA. 在特殊情况下，即 $\\alpha_X=\\alpha_U=\\beta=\\gamma=1$ 且 $\\operatorname{Var}(\\varepsilon_X)=\\operatorname{Var}(\\varepsilon_U)=\\operatorname{Var}(\\varepsilon_A)=\\operatorname{Var}(\\varepsilon_B)=\\operatorname{Var}(\\varepsilon_Y)=1$ 时，$X$ 和 $Y$ 之间的边缘协方差为 $0$，但以 $A$ 为条件的 $X$ 和 $Y$ 之间的协方差是非零且为负的。\n\nB. 以 $A$ 为条件阻断了 $X$ 和 $Y$ 之间的任何非因果路径，因此对 $A$ 进行调整可以消除 $X$ 和 $Y$ 之间的伪关联。\n\nC. 以 $B$ 为条件（不以 $A$ 为条件）会打开 $X$ 和 $Y$ 之间的一条非因果路径，从而即使不存在直接效应，也会导致伪关联。\n\nD. 在 fMRI 伪影校正中，将 $A$ 作为干扰回归量引入，可以通过一条经由 $U$ 和 $B$ 的被打开的路径，在运动回归量 $X$ 和神经结果 $Y$ 之间导致一种在边缘上本不存在的关联。\n\nE. 在此 DAG 中估计 $X$ 对 $Y$ 的因果效应，一个有效的调整集是空集；对 $A$ 进行调整对偏差有害，而对 $B$ 进行调整对于减少偏差是不必要的。",
            "solution": "问题陈述内部一致，在 fMRI 数据分析和因果推断的原则上有科学依据，并且是良定的。所提供的有向无环图 (DAG) 和相应的线性结构因果模型 (SCM) 定义清晰，可以进行严谨的数学和图形分析。因此，该问题是有效的。我们进行推导。\n\n问题的核心在于理解由给定因果图 $X \\to A \\leftarrow U \\to B \\to Y$ 所决定的头部运动 ($X$) 和局部 BOLD 信号 ($Y$) 之间的统计关联。$X$ 对 $Y$ 的真实因果效应为零，因为从 $X$ 到 $Y$ 没有有向路径。我们将分析在不同条件化场景下 $X$ 和 $Y$ 之间的统计关联（协方差）。\n\n首先，让我们使用 d-分离的规则来分析 $X$ 和 $Y$ 之间的路径。$X$ 和 $Y$ 之间只有一条路径：$X \\to A \\leftarrow U \\to B \\to Y$。这是一条非因果路径。节点 $A$ 是这条路径上的一个对撞节点，因为它有两个指向它的箭头（$X \\to A$ 和 $U \\to A$）。根据 d-分离，如果一条路径包含一个不在条件集中且其后代也都不在条件集中的对撞节点，则该路径被阻断。\n\n让我们也使用所提供的线性 SCM 进行数学分析：\n$$\nX = \\varepsilon_X,\\quad U = \\varepsilon_U,\\quad A = \\alpha_X X + \\alpha_U U + \\varepsilon_A,\\quad B = \\beta U + \\varepsilon_B,\\quad Y = \\gamma B + \\varepsilon_Y\n$$\n所有噪声项 $\\varepsilon_X, \\varepsilon_U, \\varepsilon_A, \\varepsilon_B, \\varepsilon_Y$ 都是相互独立、零均值、具有有限正方差的高斯变量，我们将其方差记为 $\\sigma^2_V = \\operatorname{Var}(\\varepsilon_V)$，其中 $V \\in \\{X, U, A, B, Y\\}$。\n\n通过代入，我们可以用外生变量表示 $Y$：\n$Y = \\gamma B + \\varepsilon_Y = \\gamma(\\beta U + \\varepsilon_B) + \\varepsilon_Y = \\gamma \\beta \\varepsilon_U + \\gamma \\varepsilon_B + \\varepsilon_Y$。\n注意 $X = \\varepsilon_X$ 且 $U = \\varepsilon_U$。\n\n**边缘协方差, $\\operatorname{Cov}(X, Y)$**\n$X$ 和 $Y$ 之间的边缘关联由它们的协方差给出。\n$$\n\\operatorname{Cov}(X, Y) = \\operatorname{Cov}(\\varepsilon_X, \\gamma \\beta \\varepsilon_U + \\gamma \\varepsilon_B + \\varepsilon_Y)\n$$\n利用协方差的线性和所有噪声项的相互独立性：\n$$\n\\operatorname{Cov}(X, Y) = \\gamma \\beta \\operatorname{Cov}(\\varepsilon_X, \\varepsilon_U) + \\gamma \\operatorname{Cov}(\\varepsilon_X, \\varepsilon_B) + \\operatorname{Cov}(\\varepsilon_X, \\varepsilon_Y) = 0 + 0 + 0 = 0\n$$\n这与 d-分离一致：当我们不以任何变量为条件时，路径 $X \\to A \\leftarrow U \\to B \\to Y$ 被对撞节点 $A$ 阻断。因此，$X$ 和 $Y$ 是边缘独立（且不相关）的。\n\n**条件协方差, $\\operatorname{Cov}(X, Y | A)$**\n以对撞节点 $A$ 为条件会打开 $X$ 和 $Y$ 之间的路径。在线性高斯模型中，条件协方差由 $\\operatorname{Cov}(X, Y | A) = \\operatorname{Cov}(X, Y) - \\frac{\\operatorname{Cov}(X, A)\\operatorname{Cov}(Y, A)}{\\operatorname{Var}(A)}$ 给出。由于 $\\operatorname{Cov}(X, Y)=0$，这可以简化为：\n$$\n\\operatorname{Cov}(X, Y | A) = - \\frac{\\operatorname{Cov}(X, A)\\operatorname{Cov}(Y, A)}{\\operatorname{Var}(A)}\n$$\n我们计算必要的项：\n- $\\operatorname{Cov}(X, A) = \\operatorname{Cov}(X, \\alpha_X X + \\alpha_U U + \\varepsilon_A) = \\alpha_X \\operatorname{Var}(X) = \\alpha_X \\sigma^2_X$。\n- $\\operatorname{Cov}(Y, A) = \\operatorname{Cov}(\\gamma\\beta U + \\gamma\\varepsilon_B + \\varepsilon_Y, \\alpha_X X + \\alpha_U U + \\varepsilon_A)$。由于噪声项的独立性，这可以简化为 $\\operatorname{Cov}(\\gamma\\beta U, \\alpha_U U) = \\gamma\\beta\\alpha_U \\operatorname{Var}(U) = \\gamma\\beta\\alpha_U \\sigma^2_U$。\n- $\\operatorname{Var}(A) = \\operatorname{Var}(\\alpha_X X + \\alpha_U U + \\varepsilon_A) = \\alpha_X^2 \\operatorname{Var}(X) + \\alpha_U^2 \\operatorname{Var}(U) + \\operatorname{Var}(\\varepsilon_A) = \\alpha_X^2 \\sigma^2_X + \\alpha_U^2 \\sigma^2_U + \\sigma^2_A$。\n\n将这些代入条件协方差的公式：\n$$\n\\operatorname{Cov}(X, Y | A) = - \\frac{(\\alpha_X \\sigma^2_X)(\\gamma\\beta\\alpha_U \\sigma^2_U)}{\\alpha_X^2 \\sigma^2_X + \\alpha_U^2 \\sigma^2_U + \\sigma^2_A} = - \\frac{\\alpha_X \\alpha_U \\beta \\gamma \\sigma^2_X \\sigma^2_U}{\\operatorname{Var}(A)}\n$$\n由于所有方差都为正，且路径系数 $\\alpha_X, \\alpha_U, \\beta, \\gamma$ 隐含为非零（因为图中存在箭头），所以这个条件协方差是非零的。它的符号与路径系数的乘积 $\\alpha_X \\alpha_U \\beta \\gamma$ 的符号相反。\n\n**条件协方差, $\\operatorname{Cov}(X, Y | B)$**\n以 $B$ 为条件不会打开对撞路径，因为 $B$ 不是对撞节点 $A$，也不是 $A$ 的后代。从图上看，给定 $B$ 时，$X$ 和 $Y$ 是 d-分离的。让我们通过计算来验证这一点：\n$$\n\\operatorname{Cov}(X, Y | B) = \\operatorname{Cov}(X, Y) - \\frac{\\operatorname{Cov}(X, B)\\operatorname{Cov}(Y, B)}{\\operatorname{Var}(B)}\n$$\n我们需要 $\\operatorname{Cov}(X, B)$:\n- $\\operatorname{Cov}(X, B) = \\operatorname{Cov}(X, \\beta U + \\varepsilon_B) = \\beta \\operatorname{Cov}(X, U) + \\operatorname{Cov}(X, \\varepsilon_B) = \\beta \\operatorname{Cov}(\\varepsilon_X, \\varepsilon_U) + \\operatorname{Cov}(\\varepsilon_X, \\varepsilon_B) = 0$。\n由于 $\\operatorname{Cov}(X, B)=0$ 且 $\\operatorname{Cov}(X, Y)=0$，整个表达式为零：\n$$\n\\operatorname{Cov}(X, Y | B) = 0 - \\frac{0 \\cdot \\operatorname{Cov}(Y, B)}{\\operatorname{Var}(B)} = 0\n$$\n以 $B$ 为条件不会在 $X$ 和 $Y$ 之间导致关联。\n\n现在我们评估每个陈述。\n\n**A. 在特殊情况下，即 $\\alpha_X=\\alpha_U=\\beta=\\gamma=1$ 且 $\\operatorname{Var}(\\varepsilon_X)=\\operatorname{Var}(\\varepsilon_U)=\\operatorname{Var}(\\varepsilon_A)=\\operatorname{Var}(\\varepsilon_B)=\\operatorname{Var}(\\varepsilon_Y)=1$ 时，$X$ 和 $Y$ 之间的边缘协方差为 $0$，但以 $A$ 为条件的 $X$ 和 $Y$ 之间的协方差是非零且为负的。**\n- 边缘协方差 $\\operatorname{Cov}(X, Y)$ 确实为 $0$，如上文一般推导所示。\n- 让我们用给定的参数计算条件协方差 $\\operatorname{Cov}(X, Y | A)$：$\\alpha_X=1$、$\\alpha_U=1$、$\\beta=1$、$\\gamma=1$，且所有方差均为 $1$。\n$$\n\\operatorname{Cov}(X, Y | A) = - \\frac{(1)(1)(1)(1)(1)(1)}{(1)^2(1) + (1)^2(1) + 1} = - \\frac{1}{1 + 1 + 1} = -\\frac{1}{3}\n$$\n这个值非零且为负。该陈述与我们的推导完全一致。\n**结论：正确。**\n\n**B. 以 $A$ 为条件阻断了 $X$ 和 $Y$ 之间的任何非因果路径，因此对 $A$ 进行调整可以消除 $X$ 和 $Y$ 之间的伪关联。**\n这个陈述曲解了对撞节点的规则。路径 $X \\to A \\leftarrow U \\to B \\to Y$ 是一条非因果路径。以对撞节点 $A$ 为条件会*打开*这条路径，而不是阻断它。这会在边缘上本不存在关联的地方导致一种伪关联。因此，对 $A$ 进行调整会*产生*一个伪关联，而不是消除一个。\n**结论：不正确。**\n\n**C. 以 $B$ 为条件（不以 $A$ 为条件）会打开 $X$ 和 $Y$ 之间的一条非因果路径，从而即使不存在直接效应，也会导致伪关联。**\n正如 d-分离逻辑和我们的协方差计算所显示的，以 $B$ 为条件并不会打开对撞路径 $X \\to A \\leftarrow U \\to B \\to Y$。$B$ 不是对撞节点 $A$，也不是 $A$ 的后代。我们计算出 $\\operatorname{Cov}(X, Y | B) = 0$。因此，以 $B$ 为条件不会导致关联。\n**结论：不正确。**\n\n**D. 在 fMRI 伪影校正中，将 $A$ 作为干扰回归量引入，可以通过一条经由 $U$ 和 $B$ 的被打开的路径，在运动回归量 $X$ 和神经结果 $Y$ 之间导致一种在边缘上本不存在的关联。**\n这个陈述准确地描述了在指定情境下的对撞偏倚现象。\n- “将 $A$ 作为干扰回归量引入”意味着以 $A$ 为条件。\n- “导致一种在边缘上本不存在的关联”：我们证明了 $\\operatorname{Cov}(X, Y | A) \\neq 0$ 而 $\\operatorname{Cov}(X, Y) = 0$。这是正确的。\n- “通过一条经由 $U$ 和 $B$ 的被打开的路径”：以 $A$ 为条件打开的路径正是 $X \\to A \\leftarrow U \\to B \\to Y$，它通过未观测到的唤醒 $U$ 和全局信号 $B$ 连接了 $X$ 和 $Y$。该陈述是对我们研究结果的正确定性描述。\n**结论：正确。**\n\n**E. 在此 DAG 中估计 $X$ 对 $Y$ 的因果效应，一个有效的调整集是空集；对 $A$ 进行调整对偏差有害，而对 $B$ 进行调整对于减少偏差是不必要的。**\n要估计 $X$ 对 $Y$ 的因果效应，我们必须阻断所有非因果的“后门”路径。后门路径是连接 $X$ 和 $Y$ 的一条路径，它以一个指向 $X$ 的箭头开始。在这个 DAG 中，$X$ 是一个外生变量（$X = \\varepsilon_X$），所以没有指向 $X$ 的箭头。因此，没有后门路径。\n- “一个有效的调整集是空集”：后门准则要求阻断所有后门路径。由于不存在后门路径，空集 $\\emptyset$ 是一个有效的调整集。从边缘关联（即 $Y$ 对 $X$ 的回归）估计效应是无偏的。回归系数将与 $\\operatorname{Cov}(X,Y) = 0$ 成正比，从而正确地识别出零因果效应。\n- “对 $A$ 进行调整对偏差有害”：如前所示，对对撞节点 $A$ 进行调整会导致一个非零关联 $\\operatorname{Cov}(X, Y | A) \\neq 0$。这导致 $X$ 的回归系数非零，这是对真实零因果效应的有偏估计。因此，它是有害的。\n- “对 $B$ 进行调整对于减少偏差是不必要的”：由于未经调整的估计已经是无偏的，因此不需要进行任何调整。对 $B$ 进行调整仍然会得到一个无偏估计，因为 $\\operatorname{Cov}(X, Y | B) = 0$，但这对减少偏差来说不是必需的。该陈述是正确的。\n**结论：正确。**",
            "answer": "$$\\boxed{ADE}$$"
        }
    ]
}