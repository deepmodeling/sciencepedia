{
    "hands_on_practices": [
        {
            "introduction": "Validating a protein structure begins with its most fundamental feature: the backbone conformation. The Ramachandran plot provides a powerful visual and quantitative assessment of the stereochemical quality of the main-chain dihedral angles, $\\phi$ and $\\psi$. This exercise challenges you to move beyond a simple, one-size-fits-all plot by applying context-specific rules for different residue types, such as the flexible glycine and the rigid pre-proline, mirroring the sophisticated analysis performed by modern validation software. ",
            "id": "4601598",
            "problem": "A structural validation pipeline for a single-chain protein of $N=200$ residues uses the Ramachandran probability density function (PDF) specific to residue context to classify backbone dihedral angle pairs $(\\phi,\\psi)$ as either allowed or outliers. The pipeline recognizes three residue context classes: glycine residues ($G$), residues immediately preceding proline in sequence (pre-proline, $PP$), and all other residues (general, $Gen$). For classification, the pipeline defines context-specific allowed regions derived from a curated Ramachandran reference PDF as follows, with angles measured in degrees: \n- For general residues $Gen$: the allowed set is the union $A \\cup B$, where \n$$A=\\{(\\phi,\\psi)\\mid -90 \\le \\phi \\le -30,\\,-70 \\le \\psi \\le -10\\},\\quad B=\\{(\\phi,\\psi)\\mid -180 \\le \\phi \\le -90,\\,90 \\le \\psi \\le 180\\}.$$\n- For glycine residues $G$: the allowed set is $A \\cup B \\cup L$, where \n$$L=\\{(\\phi,\\psi)\\mid 30 \\le \\phi \\le 90,\\,0 \\le \\psi \\le 90\\}.$$\n- For pre-proline residues $PP$: the allowed set is $A_{\\text{narrow}} \\cup B$, where \n$$A_{\\text{narrow}}=\\{(\\phi,\\psi)\\mid -80 \\le \\phi \\le -40,\\,-60 \\le \\psi \\le -20\\}.$$\nAny $(\\phi,\\psi)$ that falls outside the context-appropriate allowed set is classified as an outlier. A list of $(\\phi,\\psi)$ pairs for all $N=200$ residues has been summarized by context and bin occupancy (obtained by mapping each pair to one of the disjoint bins $A$, $B$, $L$, or the complement $O$ defined by $O=\\mathbb{R}^{2}\\setminus (A\\cup B\\cup L)$), with the following counts:\n- Glycine residues ($G$): total $n_{G}=30$, with $16$ in $A$, $8$ in $B$, $4$ in $L$, and $2$ in $O$.\n- Pre-proline residues ($PP$): total $n_{PP}=20$, with $12$ in $A$ (of which $9$ lie in $A_{\\text{narrow}}$ and $3$ lie in $A\\setminus A_{\\text{narrow}}$), $6$ in $B$, $0$ in $L$, and $2$ in $O$.\n- General residues ($Gen$): total $n_{Gen}=150$, with $92$ in $A$, $44$ in $B$, $4$ in $L$, and $10$ in $O$.\n\nUsing only the definitions above and the provided counts, compute the overall fraction of outliers across all $N=200$ residues, correctly stratifying by $G$ and $PP$ contexts to apply the appropriate allowed sets. Express your final answer as a decimal fraction and round your result to four significant figures.",
            "solution": "The objective is to compute the overall fraction of outlier residues. This requires determining the number of outliers for each of the three residue contexts—glycine ($G$), pre-proline ($PP$), and general ($Gen$)—and summing these counts. An outlier is defined as a residue whose backbone dihedral angle pair $(\\phi,\\psi)$ lies outside the context-specific allowed region.\n\nThe total number of residues is $N=200$. This total is composed of $n_G=30$ glycine residues, $n_{PP}=20$ pre-proline residues, and $n_{Gen}=150$ general residues.\n\nThe problem provides residue counts within a fixed partitioning of the $(\\phi,\\psi)$ space into four disjoint bins: $A$, $B$, $L$, and $O$. The bin $O$ is the complement of the union of the other three bins, $O = \\mathbb{R}^{2} \\setminus (A \\cup B \\cup L)$. We must carefully use these counts in conjunction with the specific allowed regions for each context to identify outliers.\n\nLet $N_{\\text{out}, G}$, $N_{\\text{out}, PP}$, and $N_{\\text{out}, Gen}$ be the number of outliers for glycine, pre-proline, and general residues, respectively.\n\n1.  **Glycine ($G$) Residues:**\n    The allowed region for glycine residues is $S_G = A \\cup B \\cup L$. A glycine residue is an outlier if its $(\\phi,\\psi)$ coordinates fall outside this region. By the definition of the binning scheme, the region outside $A \\cup B \\cup L$ is exactly the bin $O$. Therefore, the number of glycine outliers is the number of glycine residues found in bin $O$.\n    According to the provided data, the count of glycine residues in bin $O$ is $2$.\n    $$N_{\\text{out}, G} = 2$$\n\n2.  **Pre-proline ($PP$) Residues:**\n    The allowed region for pre-proline residues is $S_{PP} = A_{\\text{narrow}} \\cup B$. A pre-proline residue is an outlier if its coordinates are not in $S_{PP}$. We analyze the provided counts for the $n_{PP}=20$ residues based on the bins $A, B, L, O$:\n    -   Residues in bin $A$: The problem states there are $12$ such residues. The allowed region for these is $A_{\\text{narrow}}$. Residues in $A$ but not in $A_{\\text{narrow}}$ (i.e., in $A \\setminus A_{\\text{narrow}}$) are outliers. The problem gives this count directly as $3$.\n    -   Residues in bin $B$: There are $6$ such residues. Since $B \\subset S_{PP}$, these are all allowed. The number of outliers from this group is $0$.\n    -   Residues in bin $L$: There are $0$ such residues. The region $L$ is not part of $S_{PP}$. Any residues here would be outliers, so the contribution is $0$.\n    -   Residues in bin $O$: There are $2$ such residues. The region $O$ is, by definition, outside of $A \\cup B \\cup L$. Since $S_{PP} = A_{\\text{narrow}} \\cup B \\subset A \\cup B$, the region $O$ is entirely outside of $S_{PP}$. Thus, both residues in bin $O$ are outliers.\n    The total number of pre-proline outliers is the sum of these counts:\n    $$N_{\\text{out}, PP} = 3 + 0 + 0 + 2 = 5$$\n\n3.  **General ($Gen$) Residues:**\n    The allowed region for general residues is $S_{Gen} = A \\cup B$. A general residue is an outlier if its coordinates are not in $S_{Gen}$. We analyze the counts for the $n_{Gen}=150$ residues:\n    -   Residues in bin $A$: There are $92$ such residues. Since $A \\subset S_{Gen}$, these are allowed. The number of outliers is $0$.\n    -   Residues in bin $B$: There are $44$ such residues. Since $B \\subset S_{Gen}$, these are allowed. The number of outliers is $0$.\n    -   Residues in bin $L$: There are $4$ such residues. Region $L$ is not part of $S_{Gen}$. Therefore, all $4$ of these residues are outliers.\n    -   Residues in bin $O$: There are $10$ such residues. Region $O$ is outside $A \\cup B \\cup L$, and thus also outside $S_{Gen} = A \\cup B$. Therefore, all $10$ of these residues are outliers.\n    The total number of general outliers is the sum of these counts:\n    $$N_{\\text{out}, Gen} = 0 + 0 + 4 + 10 = 14$$\n\nNow, we compute the total number of outliers, $N_{\\text{out}}$, by summing the outliers from each class:\n$$N_{\\text{out}} = N_{\\text{out}, G} + N_{\\text{out}, PP} + N_{\\text{out}, Gen} = 2 + 5 + 14 = 21$$\nThe overall fraction of outliers, $f_{\\text{out}}$, is the total number of outliers divided by the total number of residues, $N=200$:\n$$f_{\\text{out}} = \\frac{N_{\\text{out}}}{N} = \\frac{21}{200}$$\nConverting this fraction to a decimal gives:\n$$f_{\\text{out}} = 0.105$$\nThe problem requires the answer to be rounded to four significant figures.\n$$f_{\\text{out}} = 0.1050$$",
            "answer": "$$\n\\boxed{0.1050}\n$$"
        },
        {
            "introduction": "Beyond plausible backbone geometry, a protein model must also exhibit realistic atomic packing. A critical validation step is to check for steric clashes, where non-bonded atoms are too close together, representing physically unfavorable overlaps. The clashscore is a widely adopted metric that quantifies the severity of these steric problems, normalizing them across the entire structure. This practice will guide you through the calculation and interpretation of a clashscore, helping you develop a sense for what constitutes an acceptable level of steric strain in a high-quality model. ",
            "id": "4601603",
            "problem": "A structural biologist performs all-atom contact analysis, following the standard protocol used by the MolProbity validation suite, on a protein model for downstream medical data analytics. After adding hydrogen atoms and excluding covalently bonded neighbors, the analysis identifies $35$ atom pairs with serious steric overlap, each defined by an interatomic separation shorter than the sum of their van der Waals radii minus $0.4\\,\\text{\\AA}$. The model has $2500$ atoms in total after hydrogen placement. Using the core definition that clashscore is the count of serious steric overlaps normalized per $1000$ atoms, compute the clashscore and determine whether the model exceeds a typical acceptable threshold for modern, well-refined structures at approximately $2.0\\,\\text{\\AA}$ resolution in the Protein Data Bank (PDB). Choose the best option.\n\n- A. The clashscore is $14.0$ and it exceeds a typical acceptable threshold (commonly taken as $<10$), indicating nontrivial steric issues.\n\n- B. The clashscore is $14.0$ but it does not exceed a typical acceptable threshold (commonly taken as $<20$), so the model is acceptable.\n\n- C. The clashscore is $28.0$ because each overlap involves two atoms, and it exceeds the acceptable threshold.\n\n- D. The clashscore is $1.4$ because clashes should be normalized by $1000$ residues rather than $1000$ atoms, so it does not exceed the threshold.\n\n- E. The clashscore cannot be computed without the total number of residues, so threshold comparison is not possible.",
            "solution": "The core task is to compute the clashscore based on the provided definition and data, and then to evaluate its standing relative to typical quality thresholds for protein structures.\n\nFirst, we calculate the clashscore. The problem defines clashscore as \"the count of serious steric overlaps normalized per $1000$ atoms\".\n\nLet $N_{clashes}$ be the number of serious steric overlaps and $N_{atoms}$ be the total number of atoms in the model.\nThe formula for the clashscore, which we can denote as $C_{score}$, is:\n$$ C_{score} = \\frac{N_{clashes}}{N_{atoms}} \\times 1000 $$\n\nFrom the problem statement, we are given:\n- The number of serious steric overlaps, $N_{clashes} = 35$.\n- The total number of atoms after hydrogen placement, $N_{atoms} = 2500$.\n\nSubstituting these values into the formula:\n$$ C_{score} = \\frac{35}{2500} \\times 1000 $$\n$$ C_{score} = \\frac{35000}{2500} $$\n$$ C_{score} = \\frac{350}{25} = 14 $$\nThe calculated clashscore is $14.0$.\n\nNext, we must evaluate this score in the context of a \"typical acceptable threshold for modern, well-refined structures at approximately $2.0\\,\\text{\\AA}$ resolution\". While thresholds can vary, for high-quality, well-refined structures, a lower clashscore is expected. A score of $14.0$ is not catastrophic but is higher than what is typically seen for the best structures in this resolution range, which often have single-digit clashscores. Therefore, it indicates the presence of \"nontrivial steric issues\" that would warrant further refinement.\n\nNow, we will evaluate each option.\n\n**A. The clashscore is $14.0$ and it exceeds a typical acceptable threshold (commonly taken as $<10$), indicating nontrivial steric issues.**\n- The calculated clashscore of $14.0$ is correct.\n- The statement that it exceeds a threshold of $<10$ is a reasonable interpretation for a \"well-refined\" structure, as a single-digit clashscore is often a goal. Since $14.0 > 10$, this part is valid under this interpretation.\n- The conclusion that a clashscore of $14.0$ indicates \"nontrivial steric issues\" is an accurate assessment in structural biology. It represents a significant number of atomic clashes that should be addressed.\n- **Verdict: Correct.** This option provides both the correct numerical answer and a sound, professionally cautious interpretation of its meaning for a high-quality model.\n\n**B. The clashscore is $14.0$ but it does not exceed a typical acceptable threshold (commonly taken as $<20$), so the model is acceptable.**\n- The calculated clashscore of $14.0$ is correct.\n- The statement that it does not exceed a threshold of $<20$ is also factually correct, as $14.0 < 20$. This threshold is often cited as a more general upper limit for acceptability.\n- However, the conclusion \"so the model is acceptable\" is an oversimplification. While a score of $14.0$ might not cause the model to be rejected outright, it points to significant local errors. Describing the model as simply \"acceptable\" without qualification is less precise than stating it has \"nontrivial steric issues\" as in option A. Option A's description is more informative and aligned with the goals of structure validation, which is to identify areas for improvement.\n- **Verdict: Incorrect.** While the numerical parts are correct, the conclusion is weak and less accurate than that of option A.\n\n**C. The clashscore is $28.0$ because each overlap involves two atoms, and it exceeds the acceptable threshold.**\n- The calculated clashscore of $28.0$ is incorrect. This value appears to be derived by incorrectly doubling the number of clashes ($35 \\times 2 = 70$) before normalization: $(\\frac{70}{2500}) \\times 1000 = 28.0$. The clashscore definition counts the number of clashing *pairs* (or contacts), not the number of atoms participating in those clashes.\n- **Verdict: Incorrect.** The calculation is based on a fundamental misunderstanding of the clashscore definition.\n\n**D. The clashscore is $1.4$ because clashes should be normalized by $1000$ residues rather than $1000$ atoms, so it does not exceed the threshold.**\n- The premise that clashscore is normalized by residues is incorrect. The problem correctly states, in alignment with the standard MolProbity definition, that it is normalized per $1000$ atoms.\n- The calculated value of $1.4$ is also incorrect and appears to be an arbitrary division of the correct result ($14.0$) by $10$. Normalizing by residues would require the number of residues, which is not given, and would likely yield a much different number.\n- **Verdict: Incorrect.** This option misrepresents the definition of clashscore.\n\n**E. The clashscore cannot be computed without the total number of residues, so threshold comparison is not possible.**\n- This statement is false. The definition of clashscore, as provided in the problem and in standard use, depends on the total number of *atoms*, which is given as $2500$. The number of residues is not required for the calculation.\n- Since the clashscore can be computed, a comparison to a threshold is possible.\n- **Verdict: Incorrect.** The premise is factually wrong.\n\nIn summary, Option A is the only one that provides the correct calculation and the most accurate and professionally sound interpretation of the result in the context of high-quality protein structure validation.",
            "answer": "$$\\boxed{A}$$"
        },
        {
            "introduction": "For structures derived from experimental methods like X-ray crystallography, internal geometric quality is not enough; the model must faithfully represent the experimental data. The crystallographic $R_{\\text{work}}$ and $R_{\\text{free}}$ factors measure this agreement, with the gap between them serving as a crucial indicator of overfitting—a phenomenon where the model fits the noise in the data rather than the true signal. This advanced problem asks you to statistically quantify the significance of this gap, providing a rigorous method for diagnosing overfitting and guiding further refinement. ",
            "id": "4601611",
            "problem": "A macromolecular X-ray crystallography refinement at $2.2\\,\\text{\\AA}$ resolution yields a working crystallographic residual factor $R_{\\text{work}} = 0.185$ and a cross-validated free crystallographic residual factor $R_{\\text{free}} = 0.263$. The free set fraction is $f_{\\text{free}} = 0.10$, and the total number of unique reflections is $N_{\\text{total}} = 5.0 \\times 10^{4}$. Define the per-reflection normalized residuals by $r_{i} = \\frac{|F_{\\text{obs},i} - F_{\\text{calc},i}|}{|F_{\\text{obs},i}|}$, where $F_{\\text{obs},i}$ and $F_{\\text{calc},i}$ are the observed and calculated structure factor amplitudes for reflection $i$. Over the entire dataset, the empirically estimated per-reflection standard deviation of $r_{i}$ is $\\sigma = 0.28$ (dimensionless), assumed to be approximately common to the working and free sets. \n\nStarting from the definitions of $R_{\\text{work}}$ and $R_{\\text{free}}$ as sample means of $\\{r_{i}\\}$ over their respective sets, and invoking the Central Limit Theorem to relate the sampling variability of these means to $\\sigma$ and the sample sizes, derive an expression for a standardized overfitting score $Z$ that quantifies the observed gap $R_{\\text{free}} - R_{\\text{work}}$ in units of its expected sampling fluctuation under an unbiased model. Then evaluate $Z$ numerically using the given data.\n\nFinally, based on the magnitude of the computed $Z$, briefly justify whether there is substantial overfitting and name two specific refinement adjustments you would prioritize to reduce the gap between $R_{\\text{work}}$ and $R_{\\text{free}}$ in a scientifically realistic manner at $2.2\\,\\text{\\AA}$ resolution. \n\nReport only the numerical value of the standardized overfitting score $Z$ as your final answer. Express $Z$ as a pure number (dimensionless) and round your result to three significant figures.",
            "solution": "### Derivation of the Standardized Overfitting Score $Z$\n\nThe problem defines $R_{\\text{work}}$ and $R_{\\text{free}}$ as the sample means of the per-reflection normalized residuals, $r_i$, over the working and free sets of reflections, respectively. Let $W$ be the working set and $F$ be the free set.\n\nThe number of reflections in the free set, $N_{\\text{free}}$, and in the working set, $N_{\\text{work}}$, are given by:\n$$N_{\\text{free}} = f_{\\text{free}} N_{\\text{total}}$$\n$$N_{\\text{work}} = (1 - f_{\\text{free}}) N_{\\text{total}}$$\n\nThe R-factors are the sample means:\n$$R_{\\text{free}} = \\frac{1}{N_{\\text{free}}} \\sum_{i \\in F} r_i$$\n$$R_{\\text{work}} = \\frac{1}{N_{\\text{work}}} \\sum_{i \\in W} r_i$$\n\nAccording to the Central Limit Theorem, for large sample sizes ($N_{\\text{free}}$ and $N_{\\text{work}}$ are both large), the sampling distribution of the sample mean is approximately normal. The variance of the sampling distribution of a sample mean is given by $\\frac{\\sigma^2}{N}$, where $\\sigma^2$ is the variance of the individual observations and $N$ is the sample size.\n\nThe variances of the sampling distributions for $R_{\\text{free}}$ and $R_{\\text{work}}$ are:\n$$\\text{Var}(R_{\\text{free}}) = \\frac{\\sigma^2}{N_{\\text{free}}}$$\n$$\\text{Var}(R_{\\text{work}}) = \\frac{\\sigma^2}{N_{\\text{work}}}$$\nHere, $\\sigma$ is the common standard deviation of the individual residuals $r_i$.\n\nWe are interested in the difference, $\\Delta R = R_{\\text{free}} - R_{\\text{work}}$. Since the free and working sets are independent, the variance of the difference of these two random variables is the sum of their variances:\n$$\\text{Var}(\\Delta R) = \\text{Var}(R_{\\text{free}} - R_{\\text{work}}) = \\text{Var}(R_{\\text{free}}) + \\text{Var}(R_{\\text{work}})$$\n$$\\text{Var}(\\Delta R) = \\frac{\\sigma^2}{N_{\\text{free}}} + \\frac{\\sigma^2}{N_{\\text{work}}} = \\sigma^2 \\left( \\frac{1}{N_{\\text{free}}} + \\frac{1}{N_{\\text{work}}} \\right)$$\n\nThe standard deviation of this difference, which represents the expected sampling fluctuation of the gap under the null hypothesis of no systematic difference (i.e., no overfitting), is the standard error of the difference:\n$$\\sigma_{\\Delta R} = \\sqrt{\\text{Var}(\\Delta R)} = \\sigma \\sqrt{\\frac{1}{N_{\\text{free}}} + \\frac{1}{N_{\\text{work}}}}$$\n\nThe standardized overfitting score, $Z$, quantifies the observed difference, $R_{\\text{free}} - R_{\\text{work}}$, in units of this standard error. This is the definition of a Z-score for the difference between two sample means, assuming the true means are equal (the null hypothesis $H_0: \\mu_{\\text{free}} = \\mu_{\\text{work}}$):\n$$Z = \\frac{(R_{\\text{free}} - R_{\\text{work}}) - 0}{\\sigma_{\\Delta R}}$$\nSubstituting the expression for $\\sigma_{\\Delta R}$, we obtain the final desired expression for $Z$:\n$$Z = \\frac{R_{\\text{free}} - R_{\\text{work}}}{\\sigma \\sqrt{\\frac{1}{N_{\\text{free}}} + \\frac{1}{N_{\\text{work}}}}}$$\n\n### Numerical Evaluation of $Z$\n\nFirst, we calculate the sizes of the free and working sets:\n$$N_{\\text{free}} = f_{\\text{free}} N_{\\text{total}} = 0.10 \\times (5.0 \\times 10^4) = 5000$$\n$$N_{\\text{work}} = (1 - f_{\\text{free}}) N_{\\text{total}} = (1 - 0.10) \\times (5.0 \\times 10^4) = 0.90 \\times (5.0 \\times 10^4) = 45000$$\n\nNext, we evaluate the term inside the square root:\n$$\\frac{1}{N_{\\text{free}}} + \\frac{1}{N_{\\text{work}}} = \\frac{1}{5000} + \\frac{1}{45000} = \\frac{9}{45000} + \\frac{1}{45000} = \\frac{10}{45000} = \\frac{1}{4500}$$\n\nNow, substitute all numerical values into the expression for $Z$:\n$$Z = \\frac{0.263 - 0.185}{0.28 \\sqrt{\\frac{1}{4500}}}$$\n$$Z = \\frac{0.078}{0.28 \\times \\frac{1}{\\sqrt{4500}}}$$\n\nLet's calculate the value of the denominator:\n$$\\sqrt{4500} = \\sqrt{900 \\times 5} = 30\\sqrt{5}$$\nSo, the denominator is $0.28 \\times \\frac{1}{30\\sqrt{5}}$.\n$$Z = \\frac{0.078 \\times 30\\sqrt{5}}{0.28}$$\n$$Z = \\frac{2.34 \\sqrt{5}}{0.28}$$\nUsing the numerical value $\\sqrt{5} \\approx 2.236068$:\n$$Z \\approx \\frac{2.34 \\times 2.236068}{0.28} \\approx \\frac{5.2324}{0.28} \\approx 18.6871$$\n\nRounding the result to three significant figures, we get $Z \\approx 18.7$.\n\n### Interpretation and Refinement Recommendations\n\nA standardized score of $Z \\approx 18.7$ is exceptionally large. In the context of a standard normal distribution, a Z-score of this magnitude corresponds to a vanishingly small p-value, indicating that the observed gap of $0.078$ between $R_{\\text{free}}$ and $R_{\\text{work}}$ is extremely unlikely to be a result of random sampling fluctuation. The overwhelming conclusion is that there is substantial, statistically significant overfitting. The model has been excessively tuned to fit noise and minor features in the working set data, at the expense of its ability to generalize to the cross-validation (free) set.\n\nTo address this overfitting and reduce the gap between $R_{\\text{work}}$ and $R_{\\text{free}}$, one must introduce more chemically and physically realistic constraints into the model, or reduce the number of free parameters. At a resolution of $2.2\\,\\text{\\AA}$, two priority adjustments would be:\n\n1.  **Increase the weight on geometric restraints**: Overfitting often manifests as a chemically unreasonable geometry that strains to fit ambiguous electron density. By increasing the weight of the stereochemical target function (which includes terms for bond lengths, bond angles, torsion angles, and chirality) relative to the X-ray target function, the model is penalized more heavily for deviations from ideal geometry. This reduces the effective flexibility of the model, forcing it to be more physically plausible and thereby improving its generalizability.\n\n2.  **Employ a more conservative B-factor model**: Individual atomic B-factors (atomic displacement parameters) add a large number of parameters to the model ($1$ per atom for isotropic, more for anisotropic). These parameters can easily \"absorb\" noise from the density map, a classic symptom of overfitting. At $2.2\\,\\text{\\AA}$, refining individual anisotropic B-factors is generally inadvisable. A robust strategy is to use TLS (Translation/Libration/Screw) refinement, which models the concerted motion of rigid groups of atoms (e.g., protein domains or helices), supplemented by restrained group or individual isotropic B-factor refinement. This drastically reduces the number of parameters associated with thermal motion and imposes a more realistic physical model, which typically reduces the $R_{\\text{free}}-R_{\\text{work}}$ gap.",
            "answer": "$$\\boxed{18.7}$$"
        }
    ]
}