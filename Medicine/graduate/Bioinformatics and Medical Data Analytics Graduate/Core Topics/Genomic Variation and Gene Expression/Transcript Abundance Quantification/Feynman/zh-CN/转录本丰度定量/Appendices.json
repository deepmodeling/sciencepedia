{
    "hands_on_practices": [
        {
            "introduction": "准确的转录本定量始于稳健的数据预处理。唯一分子标识符（Unique Molecular Identifiers, UMIs）是纠正聚合酶链式反应（PCR）扩增偏倚的有力工具，但测序过程本身会引入错误，从而破坏这些UMIs。这项练习  提供了一个动手实践的机会，让您实现一种常见的基于图的去重算法，将错误校正这一抽象问题置于具体的计算任务中，从而加深理解。",
            "id": "4614673",
            "problem": "在一个转录本丰度定量的场景中，给定与脱氧核糖核酸 (DNA) 或核糖核酸 (RNA) 片段相关联的唯一分子标识符 (UMI) 序列的观测计数。这些序列是基于字母表 $\\{A,C,G,T\\}$ 的固定长度为 $L$ 的字符串。假设采用标准的独立单碱基替换错误模型：每个碱基的测序是独立的，错误概率为 $\\epsilon$，当发生错误时，它会以均等的概率被错配为其他三种核苷酸中的一种。设两个序列之间的汉明距离为它们对应位置上字符不同的数量。\n\n从分子生物学的中心法则以及标准实验设计（即在扩增和测序前，每个原始分子都用一个UMI进行标记）出发，我们知道，合成的UMI序列旨在对每个原始分子都是唯一的；然而，聚合酶和测序过程会引入错误。您必须构建并实现一个基于邻接关系的UMI去重算法，该算法使用以下规则：\n\n- 构建一个无向邻接图 $G$，其节点为观测到的UMI序列。如果两个节点之间的汉明距离恰好为 $1$，则在这两个节点之间添加一条边。\n- 按观测计数的降序处理节点（若计数相同，则按序列的字典序确定性地打破平局）。当访问一个节点 $u$ 时，如果 $u$ 尚未被移除，则宣布 $u$ 是一个唯一原始分子的代表。然后，对于 $u$ 的每个邻居 $v$，如果 $u$ 的计数严格大于 $v$ 的计数，则移除 $v$（将 $v$ 合并到 $u$ 中）。如果计数相等，则在此步骤中不基于该邻接关系移除任何一方。\n- 继续此过程，直到所有节点都被访问过。该集合去重后的计数是此过程宣布的代表数量。\n\n根据独立的单碱基错误模型，论证当 $\\epsilon$ 很小时，基于汉明距离为1、从高计数指向低计数的有向邻接关系进行合并在统计上是合理的，并解释为什么计数相同时不应合并。\n\n您的程序必须实现此算法，并将其应用于以下测试套件。每个测试用例指定了 $(L,\\epsilon,\\text{UMI\\_counts})$，其中 $\\text{UMI\\_counts}$ 是一个 $(\\text{sequence},\\text{count})$ 对的列表。对于每个用例，计算去重后的计数值（一个整数）。不涉及任何物理单位。错误概率值应被解释为小数，而非百分比。\n\n测试套件:\n- 用例 $1$: $L=8$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"ACGTACGT\"},10),(\\text{\"ACGTACGA\"},2),(\\text{\"TCGTACGT\"},1),(\\text{\"GGGGGGGG\"},5)]$。\n- 用例 $2$: $L=4$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"ACGT\"},5),(\\text{\"ACGG\"},5),(\\text{\"ACGA\"},1)]$。\n- 用例 $3$: $L=4$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"AAAA\"},8),(\\text{\"AAAT\"},3),(\\text{\"AATT\"},1)]$。\n- 用例 $4$: $L=1$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"A\"},4),(\\text{\"C\"},1),(\\text{\"G\"},1)]$。\n- 用例 $5$: $L=4$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"TTTT\"},20),(\\text{\"TTTA\"},3),(\\text{\"TTAT\"},2),(\\text{\"TATT\"},1),(\\text{\"ATTT\"},1)]$。\n- 用例 $6$: $L=4$, $\\epsilon=0.01$, $\\text{UMI\\_counts}=[(\\text{\"CATC\"},6),(\\text{\"CATT\"},6),(\\text{\"CCTC\"},1),(\\text{\"GATC\"},1)]$。\n\n您的程序应生成单行输出，其中包含用例1到6的去重计数值，形式为一个用方括号括起来的逗号分隔列表（例如，$\\text{\"[r_1,r_2,r_3,r_4,r_5,r_6]\"}$），其中每个 $r_i$ 是按顺序对应于用例 $i$ 的整数结果。",
            "solution": "该问题要求实现并论证一种特定的、基于邻接关系的唯一分子标识符（UMI）去重算法。在转录本丰度定量中，此过程至关重要，用以校正由实验室流程（特别是聚合酶链式反应（PCR）扩增和高通量测序）引入的假象。\n\n其核心原则是区分真实的、不同的UMI序列（每个序列代表一个原始分子）和由测序错误产生的错误副本。所提供的算法将一种常见的启发式方法形式化：一个观测到的、计数较低的UMI，如果它是一个计数高得多的UMI的微小（汉明距离为1）变体，那么它很可能是一个源自该高计数UMI的错误。\n\n**算法的统计学论证**\n\n问题定义了一个独立的单碱基替换错误模型。设 $L$ 为基于字母表 $\\{\\text{A,C,G,T}\\}$ 的UMI序列的长度。每个碱基的测序错误概率为 $\\epsilon$。当某个位置发生错误时，该碱基会以均等的概率被错配为其他3种核苷酸中的一种。\n\n设 $S_{true}$ 为一个真实UMI分子的序列。正确测序任何单个碱基的概率是 $1-\\epsilon$。它被替换为其他3个碱基中某一个特定碱基的概率是 $\\epsilon/3$。\n完美观测到序列 $S_{true}$ 的概率，$P(S_{true} | S_{true})$，是 $L$ 次独立的正确碱基读取的概率：\n$$P(S_{true} | S_{true}) = (1-\\epsilon)^L$$\n现在，考虑另一个序列 $S_{error}$，它与 $S_{true}$ 的汉明距离为 $h=1$。观测到这个源自 $S_{true}$ 的特定序列 $S_{error}$ 的概率，$P(S_{error} | S_{true})$，要求一个特定位置被错配为一个特定碱基（概率为 $\\epsilon/3$），而其他 $L-1$ 个位置都正确（每个的概率为 $1-\\epsilon$）：\n$$P(S_{error} | S_{true}) \\text{ for } d(S_{true}, S_{error})=1 \\text{ is } (1-\\epsilon)^{L-1} \\left(\\frac{\\epsilon}{3}\\right)^1$$\n为了论证该算法主要规则的合理性，我们比较观测到真实序列与观测到单个错误变体的可能性。这些概率的比值为：\n$$\\frac{P(S_{error} | S_{true})}{P(S_{true} | S_{true})} = \\frac{(1-\\epsilon)^{L-1} (\\epsilon/3)}{(1-\\epsilon)^L} = \\frac{\\epsilon}{3(1-\\epsilon)}$$\n对于一个小的错误概率，例如给定的 $\\epsilon=0.01$，这个比值大约是 $\\epsilon/3$：\n$$\\frac{0.01}{3(1-0.01)} = \\frac{0.01}{3 \\times 0.99} = \\frac{0.01}{2.97} \\approx 0.003367$$\n这个非常小的比值表明，对于原始分子的每一个副本，生成一个对应于单个错误变体的读数（read）的可能性比生成一个对应于正确序列的读数的可能性要小290多倍。因此，如果一个真实的UMI被多次扩增和测序，其真实序列的期望计数将远大于由测序错误产生的任何汉明距离为1的邻居的计数。所以，如果 $\\text{count}(u) > \\text{count}(v)$，就将节点 $v$ 合并到其邻居 $u$ 中的规则在统计上是可靠的。它将 $v$ 识别为可能源自更丰富的序列 $u$ 的一个错误。\n\n当计数相等时（即 $\\text{count}(u) = \\text{count}(v)$）不进行合并的规则也是合理的。考虑到概率上的巨大差异，如果两个汉明距离为1的序列中一个是另一个的错误产物，那么观测到它们的计数相等在统计上是不太可能的，特别是对于中等到高的计数值。一个更简约的解释是，$u$ 和 $v$ 代表了两个不同的原始分子，它们碰巧以相似的初始浓度存在。将它们合并会有将两个真实的生物信号合并成一个的风险。因此，不合并计数相同者的保守做法可以防止去重过程中的假阳性，其代价是可能允许一些罕见的、由错误衍生的UMI被计为真实UMI。\n\n**算法流程**\n\n该算法按以下步骤进行：\n$1$. **初始化**: 输入是一个 (序列, 计数) 对的列表。使用一个字典来存储每个唯一UMI的计数，并初始化一个集合来跟踪已被移除的节点（UMI）。\n\n$2$. **图的构建**: 构建一个无向图 $G$。$G$ 的节点是唯一的UMI序列。当且仅当任意两个节点 $u$ 和 $v$ 之间的汉明距离 $d(u,v)$ 恰好为 $1$ 时，才在它们之间创建一条边。使用邻接表来表示该图是合适的。\n\n$3$. **节点排序**:对所有UMI节点进行排序，以创建一个确定性的处理顺序。主排序键是UMI的观测计数（降序排列）。次排序键是UMI序列本身的字典序（字母序），用于打破计数上的平局。\n\n$4$. **迭代去重**: 逐一处理排序后的节点。对于每个节点 $u$：\n    a. 如果 $u$ 已经在已移除节点的集合中，则跳过它。\n    b. 如果 $u$尚未被移除，则宣布它为一个真实分子的代表，并将代表的总数加一。\n    c. 随后，检查图中 $u$ 的所有邻居 $v$。如果当前节点 $u$ 的计数严格大于邻居 $v$ 的计数（即 $\\text{count}(u) > \\text{count}(v)$），则将 $v$ 添加到已移除节点的集合中。\n\n$5$. **最终计数**: 遍历所有节点后，所宣布的代表的最终数量就是去重的结果。这个计数代表了估计的唯一原始分子的数量。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np # numpy is permitted but not strictly needed for this implementation\n\ndef solve():\n    \"\"\"\n    Solves the UMI deduplication problem for the given test suite.\n    \"\"\"\n    \n    test_cases = [\n        # Case 1\n        (8, 0.01, [(\"ACGTACGT\", 10), (\"ACGTACGA\", 2), (\"TCGTACGT\", 1), (\"GGGGGGGG\", 5)]),\n        # Case 2\n        (4, 0.01, [(\"ACGT\", 5), (\"ACGG\", 5), (\"ACGA\", 1)]),\n        # Case 3\n        (4, 0.01, [(\"AAAA\", 8), (\"AAAT\", 3), (\"AATT\", 1)]),\n        # Case 4\n        (1, 0.01, [(\"A\", 4), (\"C\", 1), (\"G\", 1)]),\n        # Case 5\n        (4, 0.01, [(\"TTTT\", 20), (\"TTTA\", 3), (\"TTAT\", 2), (\"TATT\", 1), (\"ATTT\", 1)]),\n        # Case 6\n        (4, 0.01, [(\"CATC\", 6), (\"CATT\", 6), (\"CCTC\", 1), (\"GATC\", 1)]),\n    ]\n\n    def hamming_distance(s1, s2):\n        \"\"\"Calculates the Hamming distance between two strings of equal length.\"\"\"\n        return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n\n    results = []\n    for case_num, (L, epsilon, umi_counts_list) in enumerate(test_cases):\n        \n        # Step 1: Parse input and get unique UMIs\n        counts = {seq: count for seq, count in umi_counts_list}\n        unique_umis = list(counts.keys())\n        \n        # Step 2: Build the adjacency graph\n        adj_list = {umi: [] for umi in unique_umis}\n        for i in range(len(unique_umis)):\n            for j in range(i + 1, len(unique_umis)):\n                umi1 = unique_umis[i]\n                umi2 = unique_umis[j]\n                if hamming_distance(umi1, umi2) == 1:\n                    adj_list[umi1].append(umi2)\n                    adj_list[umi2].append(umi1)\n\n        # Step 3: Process nodes in descending order of count, with lexicographic tie-breaking\n        # The key for sorting is a tuple: (-count, sequence).\n        # The negative count achieves descending order for counts, and the sequence achieves\n        # ascending (lexicographical) order for tie-breaking.\n        sorted_umis = sorted(unique_umis, key=lambda umi: (-counts[umi], umi))\n        \n        # Step 4: Iterative deduplication\n        removed_nodes = set()\n        representative_count = 0\n        \n        for u in sorted_umis:\n            # If a node has been removed, it cannot be a representative\n            if u in removed_nodes:\n                continue\n            \n            # This node is a representative\n            representative_count += 1\n            \n            # Remove neighbors with lower counts\n            for v in adj_list[u]:\n                if counts[u] > counts[v]:\n                    removed_nodes.add(v)\n        \n        results.append(representative_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```"
        },
        {
            "introduction": "数据预处理之后，核心任务是从片段计数中估计转录本丰度。这个问题  剥离了迭代算法的复杂性，让您专注于基本的统计学原理：最大似然估计（Maximum Likelihood Estimation, MLE）。通过处理一个小的、假设的转录组，您将直接从比对数据（等价类）推导出似然函数，并求解最能解释观测计数的丰度值。这为理解更复杂的方法奠定了坚实的理论基础。",
            "id": "4614663",
            "problem": "一位研究人员正在对一个由三个转录本（标记为 $T_{1}$、$T_{2}$ 和 $T_{3}$）组成的小型“玩具”转录组进行核糖核酸测序 (RNA-Seq) 数据的转录本丰度定量。目标是计算转录本分数 $\\pi = (\\pi_{1}, \\pi_{2}, \\pi_{3})$ 的最大似然估计，其中 $\\pi_{i}$ 表示一个随机抽样的片段源自转录本 $T_{i}$ 的概率，且满足约束条件 $\\sum_{i=1}^{3} \\pi_{i} = 1$ 和 $\\pi_{i} \\geq 0$。\n\n假设采用标准的 RNA-Seq 抽样模型，片段的起始位点在每个转录本的有效长度上均匀分布，并且观测到的片段通过伪比对程序被划分到等价类中。三个等价类如下：\n- $E_{1}$：唯一伪比对到 $T_{1}$ 的片段，\n- $E_{2}$：模糊地伪比对到 $\\{T_{2}, T_{3}\\}$ 的片段，\n- $E_{3}$：唯一伪比对到 $T_{2}$ 的片段。\n\n转录本的有效长度（以核苷酸为单位）如下：\n- $\\tilde{\\ell}_{1} = 900$,\n- $\\tilde{\\ell}_{2} = 600$,\n- $\\tilde{\\ell}_{3} = 300$.\n\n定义了每个转录本对各个等价类的读数贡献量的兼容性足迹（以核苷酸为单位）如下：\n- 来自 $T_{1}$：$900$ 到 $E_{1}$，$0$ 到 $E_{2}$，$0$ 到 $E_{3}$，\n- 来自 $T_{2}$：$0$ 到 $E_{1}$，$180$ 到 $E_{2}$，$420$ 到 $E_{3}$，\n- 来自 $T_{3}$：$0$ 到 $E_{1}$，$300$ 到 $E_{2}$，$0$ 到 $E_{3}$。\n\n观测到一个包含 $N = 1000$ 个片段的文库，其等价类计数如下：\n- $c_{E_{1}} = 400$,\n- $c_{E_{2}} = 500$,\n- $c_{E_{3}} = 100$.\n\n仅根据给定的抽样假设和数据进行第一性原理推导，计算转录本分数 $\\pi = (\\pi_{1}, \\pi_{2}, \\pi_{3})$ 的最大似然估计。将最终数值结果四舍五入到四位有效数字。将结果表示为无量纲的概率。",
            "solution": "问题是确定转录本分数 $\\pi = (\\pi_{1}, \\pi_{2}, \\pi_{3})$ 的最大似然估计 (MLE)，这些分数分别代表一个随机抽样的片段源自转录本 $T_{1}$、$T_{2}$ 和 $T_{3}$ 的概率。\n\n首先验证问题。\n**步骤1：提取已知条件**\n- 转录本集合：$\\{T_{1}, T_{2}, T_{3}\\}$\n- 待估计参数：$\\pi = (\\pi_{1}, \\pi_{2}, \\pi_{3})$，约束条件为 $\\sum_{i=1}^{3} \\pi_{i} = 1$ 和 $\\pi_{i} \\geq 0$。\n- 等价类：$E_{1}$ (唯一对应于 $T_{1}$)，$E_{2}$ (模糊对应于 $\\{T_{2}, T_{3}\\}$)，$E_{3}$ (唯一对应于 $T_{2}$)。\n- 转录本有效长度：$\\tilde{\\ell}_{1} = 900$, $\\tilde{\\ell}_{2} = 600$, $\\tilde{\\ell}_{3} = 300$。\n- 兼容性足迹 $f_{ij}$ (转录本 $i$ 与类别 $j$ 兼容的长度):\n  - $T_1$：$f_{11}=900$, $f_{12}=0$, $f_{13}=0$。\n  - $T_2$：$f_{21}=0$, $f_{22}=180$, $f_{23}=420$。\n  - $T_3$：$f_{31}=0$, $f_{32}=300$, $f_{33}=0$。\n- 观测到的片段总数：$N = 1000$。\n- 等价类计数：$c_{E_{1}} = 400$, $c_{E_{2}} = 500$, $c_{E_{3}} = 100$。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题具有科学依据，属于生物信息学中转录本丰度定量的标准框架。在此背景下，所有术语都有明确的定义。所提供的数据是自洽且内部一致的；对于每个转录本 $T_i$，其兼容性足迹之和等于其有效长度（$\\sum_{j} f_{ij} = \\tilde{\\ell}_i$）。该问题是一个适定的最大似然估计任务。未发现任何缺陷。\n\n**步骤3：结论与行动**\n问题有效。将提供完整解答。\n\n**最大似然估计的推导**\n\n问题的核心是为观测到的等价类计数构建似然函数，并相对于转录本分数 $\\pi$ 将其最大化。\n\n首先，我们确定条件概率 $p(E_{j} | T_{i})$，即一个源自转录本 $T_{i}$ 的片段被归类到等价类 $E_{j}$ 的概率。该概率是兼容性足迹 $f_{ij}$ 与转录本有效长度 $\\tilde{\\ell}_{i}$ 的比值：\n$$p(E_{j} | T_{i}) = \\frac{f_{ij}}{\\tilde{\\ell}_{i}}$$\n使用所提供的数据：\n- 对于 $T_{1}$：$p(E_{1} | T_{1}) = \\frac{900}{900} = 1$；$p(E_{2} | T_{1}) = 0$；$p(E_{3} | T_{1}) = 0$。\n- 对于 $T_{2}$：$p(E_{1} | T_{2}) = 0$；$p(E_{2} | T_{2}) = \\frac{180}{600} = 0.3$；$p(E_{3} | T_{2}) = \\frac{420}{600} = 0.7$。\n- 对于 $T_{3}$：$p(E_{1} | T_{3}) = 0$；$p(E_{2} | T_{3}) = \\frac{300}{300} = 1$；$p(E_{3} | T_{3}) = 0$。\n\n接下来，我们使用全概率公式，通过对所有可能的来源转录本求和，来表示一个随机片段属于等价类 $E_{j}$ 的总概率 $p(E_{j})$：\n$$p(E_{j}) = \\sum_{i=1}^{3} p(E_{j} | T_{i}) \\pi_{i}$$\n由此可得：\n- $p(E_{1}) = p(E_{1} | T_{1}) \\pi_{1} + p(E_{1} | T_{2}) \\pi_{2} + p(E_{1} | T_{3}) \\pi_{3} = (1) \\pi_{1} + (0) \\pi_{2} + (0) \\pi_{3} = \\pi_{1}$\n- $p(E_{2}) = p(E_{2} | T_{1}) \\pi_{1} + p(E_{2} | T_{2}) \\pi_{2} + p(E_{2} | T_{3}) \\pi_{3} = (0) \\pi_{1} + (0.3) \\pi_{2} + (1) \\pi_{3} = 0.3 \\pi_{2} + \\pi_{3}$\n- $p(E_{3}) = p(E_{3} | T_{1}) \\pi_{1} + p(E_{3} | T_{2}) \\pi_{2} + p(E_{3} | T_{3}) \\pi_{3} = (0) \\pi_{1} + (0.7) \\pi_{2} + (0) \\pi_{3} = 0.7 \\pi_{2}$\n\n观测到的计数 $(c_{E_{1}}, c_{E_{2}}, c_{E_{3}})$ 服从参数为 $N=1000$、概率为 $(p(E_{1}), p(E_{2}), p(E_{3}))$ 的多项分布。观测数据的对数似然函数 $\\mathcal{L}(\\pi)$ 在不考虑常数项的情况下为：\n$$\\mathcal{L}(\\pi) = \\sum_{j=1}^{3} c_{E_{j}} \\ln(p(E_{j}))$$\n代入 $p(E_{j})$ 的表达式和给定的计数：\n$$\\mathcal{L}(\\pi_{1}, \\pi_{2}, \\pi_{3}) = 400 \\ln(\\pi_{1}) + 500 \\ln(0.3 \\pi_{2} + \\pi_{3}) + 100 \\ln(0.7 \\pi_{2})$$\n我们必须在约束条件 $\\pi_{1} + \\pi_{2} + \\pi_{3} = 1$ 和 $\\pi_{i} \\geq 0$（对于 $i \\in \\{1, 2, 3\\}$）下最大化此函数。\n\n从 $p(E_1)$ 的结构来看，项 $400 \\ln(\\pi_1)$ 与其他项是解耦的。对于多项模型，一个类别概率的 MLE 是其观测频率。一个片段落入类别 $E_1$ 的概率是 $\\pi_1$，其观测频率是 $c_{E_1}/N$。因此，$\\pi_{1}$ 的 MLE 是：\n$$\\hat{\\pi}_{1} = \\frac{c_{E_{1}}}{N} = \\frac{400}{1000} = 0.4$$\n这简化了问题。剩余分数的约束条件变为 $\\pi_{2} + \\pi_{3} = 1 - \\hat{\\pi}_{1} = 1 - 0.4 = 0.6$。我们可以用 $\\pi_{2}$ 来表示 $\\pi_{3}$：\n$$\\pi_{3} = 0.6 - \\pi_{2}$$\n$\\pi_{2}$ 的定义域是 $[0, 0.6]$。我们将其代入对数似然函数中涉及 $\\pi_{2}$ 和 $\\pi_{3}$ 的部分，我们将其记为 $\\mathcal{L}_{23}$：\n$$\\mathcal{L}_{23}(\\pi_{2}) = 500 \\ln(0.3 \\pi_{2} + (0.6 - \\pi_{2})) + 100 \\ln(0.7 \\pi_{2})$$\n$$\\mathcal{L}_{23}(\\pi_{2}) = 500 \\ln(0.6 - 0.7 \\pi_{2}) + 100 \\ln(0.7 \\pi_{2})$$\n为了找到最大值，我们计算关于 $\\pi_{2}$ 的导数并将其设为零：\n$$\\frac{d\\mathcal{L}_{23}}{d\\pi_{2}} = 500 \\cdot \\frac{-0.7}{0.6 - 0.7 \\pi_{2}} + 100 \\cdot \\frac{0.7}{0.7 \\pi_{2}} = \\frac{-350}{0.6 - 0.7 \\pi_{2}} + \\frac{100}{\\pi_{2}}$$\n将导数设为零：\n$$\\frac{100}{\\pi_{2}} = \\frac{350}{0.6 - 0.7 \\pi_{2}}$$\n$$100(0.6 - 0.7 \\pi_{2}) = 350 \\pi_{2}$$\n$$60 - 70 \\pi_{2} = 350 \\pi_{2}$$\n$$60 = 420 \\pi_{2}$$\n$$\\hat{\\pi}_{2} = \\frac{60}{420} = \\frac{1}{7}$$\n该值在有效范围 $[0, 0.6]$ 内。二阶导数为负，确认这是一个最大值。现在我们求解 $\\pi_{3}$ 的估计值：\n$$\\hat{\\pi}_{3} = 0.6 - \\hat{\\pi}_{2} = \\frac{3}{5} - \\frac{1}{7} = \\frac{21 - 5}{35} = \\frac{16}{35}$$\n转录本分数的最大似然估计为 $\\hat{\\pi} = (\\frac{2}{5}, \\frac{1}{7}, \\frac{16}{35})$。\n\n最后，我们按要求将这些精确的分数转换为小数，并四舍五入到四位有效数字：\n- $\\hat{\\pi}_{1} = 0.4 = 0.4000$\n- $\\hat{\\pi}_{2} = \\frac{1}{7} \\approx 0.142857 \\dots \\rightarrow 0.1429$\n- $\\hat{\\pi}_{3} = \\frac{16}{35} \\approx 0.457142 \\dots \\rightarrow 0.4571$\n四舍五入后值的总和是 $0.4000 + 0.1429 + 0.4571 = 1.0000$。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.4000  0.1429  0.4571\n\\end{pmatrix}\n}\n$$"
        }
    ]
}