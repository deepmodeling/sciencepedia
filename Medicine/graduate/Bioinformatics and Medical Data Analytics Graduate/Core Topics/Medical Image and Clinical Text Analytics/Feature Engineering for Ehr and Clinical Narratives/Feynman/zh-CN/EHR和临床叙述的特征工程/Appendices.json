{
    "hands_on_practices": [
        {
            "introduction": "临床数据，无论是来自结构化字段还是临床叙述，都充满了本地特有的、非标准化的术语。为了在分析中有效地利用这些数据，我们必须将这些局部代码映射到标准化的医学术语体系，如 SNOMED CT 或 ICD。这个实践将指导你构建一个现实世界中的代码映射流程，该流程结合了语言学相似性（如Jaccard和Levenshtein距离）和统计先验知识，以一种有原则的方式处理未映射和模糊的代码。这项技能对于统一来自不同来源的数据和确保分析的可重复性至关重要。",
            "id": "4563113",
            "problem": "您的任务是构建一个确定性映射流程，该流程使用概念词典和一套处理未映射和歧义代码的原则性策略，将本地电子健康记录（EHR）代码规范化为标准化的术语概念标识符。您的程序必须实现该流程，并针对指定的测试套件产生定量结果，结果的输出格式需严格遵循本问题末尾的描述。\n\n基本核心定义：\n- 概念词典是一个有限的对集 $\\{(c, L_c)\\}$，其中 $c$ 是一个标准化的概念标识符（一个整数），$L_c$ 是与概念 $c$ 相关联的规范表面形式（同义标签）的有限集合。\n- 先验 $p(c)$ 是概念 $c$ 的一个非负实值先验权重，反映了其在语料库中的频率或流行度。这些先验值不必总和为 $1$，仅用于决胜时的偏好选择。\n- 本地 EHR 代码是一个自由文本字符串。该流程将每个本地代码映射到一个单一的概念标识符，或者在没有合适匹配时映射到一个指定的未知哨兵值 $0$。\n\n字符串规范化和分词：\n- 设 $g(s)$ 是一个对字符串 $s$ 进行操作的确定性规范化和分词函数，它按顺序应用以下转换：\n  $1.$ 将所有字符转换为小写。\n  $2.$ 展开缩写，用其扩展短语替换已知的词元；例如，\"hbp\" $\\to$ \"high blood pressure\"，\"ckd\" $\\to$ \"chronic kidney disease\"，\"akd\" $\\to$ \"acute kidney disease\"，\"dz\" $\\to$ \"disease\"，\"t2dm\" $\\to$ \"type 2 diabetes mellitus\"，\"t1dm\" $\\to$ \"type 1 diabetes mellitus\"。\n  $3.$ 将最高到 $10$ 的罗马数字（$\\mathrm{I}, \\mathrm{II}, \\mathrm{III}, \\mathrm{IV}, \\mathrm{V}, \\mathrm{VI}, \\mathrm{VII}, \\mathrm{VIII}, \\mathrm{IX}, \\mathrm{X}$）转换为其阿拉伯数字等价形式（$1,2,3,4,5,6,7,8,9,10$）。\n  $4.$ 将所有非字母数字字符替换为空格，并按空白字符进行分割，得到词元。\n  $5.$ 移除已知的停用词，如 \"nos\" 和 \"unspecified\"。\n  输出 $g(s)$ 是通过上述步骤产生的词元集合（在相似度计算中作为集合处理）。\n\n加权词元相似度：\n- 对于一个概念词典 $\\{(c,L_c)\\}$，将词元 $t$ 的文档频率 $\\mathrm{df}(t)$ 定义为在 $\\bigcup_{c} L_c$ 中，其规范化词元集（通过 $g$ 函数处理后）包含 $t$ 的不同概念标签的数量。定义一个权重\n$$\nw(t) = \\frac{1}{1+\\mathrm{df}(t)}.\n$$\n- 对于两个规范化词元集 $X$ 和 $Y$，定义加权 Jaccard 相似度\n$$\nJ(X,Y) = \\frac{\\sum_{t \\in X \\cap Y} w(t)}{\\sum_{t \\in X \\cup Y} w(t)},\n$$\n约定当分母为零时，$J(\\varnothing,Y)=0$。\n\n字符级相似度：\n- 设 $d(a,b)$ 是字符串 $a$ 和 $b$ 之间的 Levenshtein 编辑距离，并让 $|a|$ 表示字符串长度。定义归一化字符级相似度\n$$\nr(a,b) = \n\\begin{cases}\n0,  \\text{if } \\max(|a|,|b|)=0,\\\\\n1 - \\frac{d(a,b)}{\\max(|a|,|b|)},  \\text{otherwise}.\n\\end{cases}\n$$\n- 对于字符相似度，使用经过缩写展开、罗马数字规范化和移除空白字符后的字符串规范化形式。\n\n组合相似度和概念评分：\n- 对于一个本地代码 $s$ 和一个带有标签集 $L_c$ 的概念 $c$，定义概念分数\n$$\nS_c(s) = \\max_{\\ell \\in L_c} \\left[ \\alpha \\cdot J\\big(g(s), g(\\ell)\\big) + (1-\\alpha) \\cdot r\\big(\\tilde{s}, \\tilde{\\ell}\\big) \\right],\n$$\n其中 $\\alpha \\in [0,1]$，$\\tilde{s}$ 和 $\\tilde{\\ell}$ 分别是 $s$ 和 $\\ell$ 的字符规范化形式（经过缩写展开、罗马数字规范化和移除空白字符）。\n\n决策规则、歧义处理和未映射策略：\n- 给定一个阈值 $\\tau \\in [0,1]$ 和一个并列容差 $\\epsilon > 0$，定义候选集\n$$\n\\mathcal{C}(s) = \\{ c \\mid S_c(s) \\ge \\tau \\}.\n$$\n- 如果 $\\mathcal{C}(s)=\\varnothing$，则将未知哨兵值 $0$ 分配给 $s$（这是一个未映射代码）。\n- 否则，令 $S_{\\max}(s) = \\max_{c \\in \\mathcal{C}(s)} S_c(s)$ 并定义最高分候选集\n$$\n\\mathcal{T}(s) = \\{ c \\in \\mathcal{C}(s) \\mid S_{\\max}(s) - S_c(s) \\le \\epsilon \\}.\n$$\n- 如果 $|\\mathcal{T}(s)|=1$，则将该唯一概念分配给 $s$。\n- 如果 $|\\mathcal{T}(s)|>1$（歧义），则选择 $\\mathcal{T}(s)$ 中具有最大先验 $p(c)$ 的概念。如果多个候选者在 $p(c)$ 上仍然并列，则选择具有最小标识符 $c$ 的候选者（确定性决胜规则）。将每个此类实例计数为“歧义已解决”。\n\n定量输出：\n- 对于一批本地代码，定义 $M$ 为映射到非零概念标识符（即非未知哨兵值）的代码的整数数量，$U$ 为映射到未知哨兵值 $0$ 的代码的整数数量，以及 $A$ 为存在歧义（即 $|\\mathcal{T}(s)|>1$）但通过决胜策略解决的代码的整数数量。对于每个测试用例，程序必须输出列表 $[M,U,A]$。\n\n测试套件规范：\n为以下四个测试用例实现您的程序。每个测试用例指定了概念词典、先验、本地代码以及参数 $\\alpha$ 和 $\\tau$。\n\n- 测试用例 1：\n  - 概念标识符和标签：\n    $1001$: {\"Type 2 diabetes mellitus\", \"T2DM\"},\n    $1002$: {\"Type 1 diabetes mellitus\", \"T1DM\"},\n    $2001$: {\"Hypertension\", \"High blood pressure\"}.\n  - 先验 $p(c)$：\n    $p(1001)=0.6$, $p(1002)=0.2$, $p(2001)=0.4$.\n  - 本地代码：\n    \"type II diabetes\", \"HBP\", \"diabetes type 1\", \"unknown diagnosis\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.5$, 未知哨兵值 $0$, 并列容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 2：\n  - 概念标识符和标签：\n    $3001$: {\"Chronic kidney disease\", \"CKD\", \"Chronic renal disease\"},\n    $3002$: {\"Acute kidney disease\", \"AKD\", \"Acute renal disease\"},\n    $4001$: {\"Chronic renal insufficiency\"}.\n  - 先验 $p(c)$：\n    $p(3001)=0.55$, $p(3002)=0.25$, $p(4001)=0.30$.\n  - 本地代码：\n    \"renal disease\", \"ckd stage\", \"acute kidney dz\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.55$, 未知哨兵值 $0$, 并列容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 3：\n  - 概念标识符和标签：\n    $5001$: {\"Fever\", \"Pyrexia\"},\n    $5002$: {\"Hypothermia\", \"Cold\"},\n    $5003$: {\"Cold\", \"Common cold\"}.\n  - 先验 $p(c)$：\n    $p(5001)=0.5$, $p(5002)=0.5$, $p(5003)=0.5$.\n  - 本地代码：\n    \"fever\", \"\", \"pyrexia\", \"cold\".\n  - 参数：\n    $\\alpha=0.7$, $\\tau=0.6$, 未知哨兵值 $0$, 并列容差 $\\epsilon=10^{-12}$.\n\n- 测试用例 4：\n  - 概念标识符和标签：\n    $6001$: {\"Myocardial infarction\", \"Heart attack\"},\n    $6002$: {\"Angina\", \"Anginal pain\"}.\n  - 先验 $p(c)$：\n    $p(6001)=0.4$, $p(6002)=0.6$.\n  - 本地代码：\n    \"heart attak\", \"anginal pain\".\n  - 参数：\n    $\\alpha=0.5$, $\\tau=0.5$, 未知哨兵值 $0$, 并列容差 $\\epsilon=10^{-12}$.\n\n最终输出格式要求：\n- 您的程序应生成单行输出，其中包含一个由逗号分隔的列表，列表被方括号包围，每个结果都是一个 $[M,U,A]$ 列表，按测试用例的顺序排列。例如，输出必须类似于 \"[[x1,y1,z1],[x2,y2,z2],[x3,y3,z3],[x4,y4,z4]]\"，不含空格。",
            "solution": "该问题要求实现一个确定性流程，用于将本地电子健康记录（EHR）文本代码映射到标准化的概念标识符。解决方案的构建方法是系统地实现指定流程的每个组件，从字符串规范化到最终的决策逻辑，然后将此流程应用于一组测试用例，以生成定量评估指标。\n\n总体方法是首先建立一组预计算步骤来准备必要的数据结构，如词元权重，然后通过评分和决策流程处理每个本地代码。\n\n### 步骤 1：字符串规范化和预计算\n\n映射流程的基础是一个确定性的字符串规范化函数 $g(s)$ 和一个字符规范化形式 $\\tilde{s}$。它们的实现如下：\n\n1.  **通用预处理**：首先对 $g(s)$ 和 $\\tilde{s}$ 应用一个共享的规范化序列。对于给定的字符串 $s$，处理过程如下：\n    a. 转换为小写。\n    b. 展开已知的缩写（例如，“t2dm” $\\to$ “type 2 diabetes mellitus”）。这通过使用能感知词边界的正则表达式替换来实现，以防止单词内部的错误替换。\n    c. 转换最高到 $10$ 的罗马数字（例如，“ix” $\\to$ “$9$”）。为确保正确性（例如，在处理“i”之前处理“ix”），在替换前按长度降序对罗马数字列表进行排序。\n\n2.  **词元集生成 $g(s)$**：在通用预处理之后，通过将所有非字母数字字符替换为空格并按空白进行分割，来对结果字符串进行分词。然后移除已知的停用词（“nos”，“unspecified”）。最终输出是一个唯一的词元集合。\n\n3.  **字符规范化字符串 $\\tilde{s}$**：在通用预处理之后，从字符串中移除所有非字母数字字符以产生 $\\tilde{s}$。\n\n在处理本地代码之前，为了提高效率，预先计算了几个组件：\n-   **词元权重 $w(t)$**：计算每个词元 $t$ 的文档频率 $\\mathrm{df}(t)$。这是概念词典 $\\bigcup_{c} L_c$ 中，其规范化形式 $g(\\ell)$ 包含 $t$ 的不同标签的数量。词元权重则为 $w(t) = \\frac{1}{1+\\mathrm{df}(t)}$。对词典标签中存在的所有词元预先计算这些权重。\n-   **处理过的概念词典**：对于每个概念 $c$，其标签集 $L_c$ 都经过预处理。对于 $L_c$ 中的每个标签 $\\ell$，我们计算并存储其词元集表示 $g(\\ell)$ 和其字符规范化形式 $\\tilde{\\ell}$。这避免了在评分阶段的重复计算。\n\n### 步骤 2：相似度与评分\n\n利用预先计算好的数据，我们可以高效地为给定的本地代码 $s$ 和概念 $c$ 计算分数 $S_c(s)$。\n\n1.  **Levenshtein 距离 $d(a,b)$**：实现一个标准的动态规划算法来计算两个字符串之间的 Levenshtein 编辑距离。该函数是计算字符级相似度的前提。\n\n2.  **加权 Jaccard 相似度 $J(X,Y)$**：对于一个本地代码的词元集 $X=g(s)$ 和一个标签的词元集 $Y=g(\\ell)$，相似度计算如下：\n    $$\n    J(X,Y) = \\frac{\\sum_{t \\in X \\cap Y} w(t)}{\\sum_{t \\in X \\cup Y} w(t)}\n    $$\n    分子是两个集合共有词元的权重之和，分母是两个集合所有唯一词元的权重之和。如果并集为空（即 $X$ 和 $Y$ 均为空），则 $J(X, Y)$ 为 $0$。\n\n3.  **字符级相似度 $r(a,b)$**：对于一个本地代码的字符规范化形式 $a=\\tilde{s}$ 和一个标签的形式 $b=\\tilde{\\ell}$，相似度为：\n    $$\n    r(a,b) = 1 - \\frac{d(a,b)}{\\max(|a|,|b|)}\n    $$\n    仅当 $\\max(|a|,|b|) > 0$ 时才进行计算；否则为 $0$。\n\n4.  **概念分数 $S_c(s)$**：概念 $c$ 的最终分数是其所有标签 $\\ell \\in L_c$ 中组合相似度分数的最大值。单个标签的组合分数是两种相似度指标的加权平均：\n    $$\n    S_c(s) = \\max_{\\ell \\in L_c} \\left[ \\alpha \\cdot J\\big(g(s), g(\\ell)\\big) + (1-\\alpha) \\cdot r\\big(\\tilde{s}, \\tilde{\\ell}\\big) \\right]\n    $$\n\n### 步骤 3：决策逻辑和定量指标\n\n对于每个本地代码 $s$，在为词典中所有概念 $c$ 计算出 $S_c(s)$ 后，通过一个多步骤的决策规则来确定最终的映射。已映射（$M$）、未映射（$U$）和歧义（$A$）代码的计数器会相应更新。\n\n1.  **候选选择**：候选概念集由 $\\mathcal{C}(s) = \\{ c \\mid S_c(s) \\ge \\tau \\}$ 形成，其中 $\\tau$ 是给定的相似度阈值。\n\n2.  **未映射代码**：如果 $\\mathcal{C}(s)$ 为空，则该代码被视为未映射。它被分配未知哨兵值 $0$，并且计数器 $U$ 递增。\n\n3.  **最高分候选者**：如果 $\\mathcal{C}(s)$ 不为空，该代码将被映射。计数器 $M$ 递增。我们找到最大分数 $S_{\\max}(s) = \\max_{c \\in \\mathcal{C}(s)} S_c(s)$。然后最高分候选集为 $\\mathcal{T}(s) = \\{ c \\in \\mathcal{C}(s) \\mid S_{\\max}(s) - S_c(s) \\le \\epsilon \\}$，其中 $\\epsilon$ 是一个很小的容差。\n\n4.  **歧义解决**：\n    -   如果 $|\\mathcal{T}(s)|=1$，则映射是明确的，指向 $\\mathcal{T}(s)$ 中的唯一概念。\n    -   如果 $|\\mathcal{T}(s)|>1$，则映射是歧义的。计数器 $A$ 递增。通过从 $\\mathcal{T}(s)$ 中选择具有最高先验权重 $p(c)$ 的概念来解决歧义。如果先验权重存在并列，则选择数值标识符 $c$ 最小的概念。这种两级决胜规则确保了单一、确定性的映射。\n\n通过此流程处理每个测试用例中的所有本地代码，最终生成计数 $[M, U, A]$。",
            "answer": "```python\nimport re\nimport numpy as np\nfrom collections import defaultdict\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    test_cases = [\n        {\n            \"concepts\": {\n                1001: {\"Type 2 diabetes mellitus\", \"T2DM\"},\n                1002: {\"Type 1 diabetes mellitus\", \"T1DM\"},\n                2001: {\"Hypertension\", \"High blood pressure\"},\n            },\n            \"priors\": {1001: 0.6, 1002: 0.2, 2001: 0.4},\n            \"codes\": [\"type II diabetes\", \"HBP\", \"diabetes type 1\", \"unknown diagnosis\"],\n            \"alpha\": 0.7, \"tau\": 0.5, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                3001: {\"Chronic kidney disease\", \"CKD\", \"Chronic renal disease\"},\n                3002: {\"Acute kidney disease\", \"AKD\", \"Acute renal disease\"},\n                4001: {\"Chronic renal insufficiency\"},\n            },\n            \"priors\": {3001: 0.55, 3002: 0.25, 4001: 0.30},\n            \"codes\": [\"renal disease\", \"ckd stage\", \"acute kidney dz\"],\n            \"alpha\": 0.7, \"tau\": 0.55, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                5001: {\"Fever\", \"Pyrexia\"},\n                5002: {\"Hypothermia\", \"Cold\"},\n                5003: {\"Cold\", \"Common cold\"},\n            },\n            \"priors\": {5001: 0.5, 5002: 0.5, 5003: 0.5},\n            \"codes\": [\"fever\", \"\", \"pyrexia\", \"cold\"],\n            \"alpha\": 0.7, \"tau\": 0.6, \"epsilon\": 1e-12\n        },\n        {\n            \"concepts\": {\n                6001: {\"Myocardial infarction\", \"Heart attack\"},\n                6002: {\"Angina\", \"Anginal pain\"},\n            },\n            \"priors\": {6001: 0.4, 6002: 0.6},\n            \"codes\": [\"heart attak\", \"anginal pain\"],\n            \"alpha\": 0.5, \"tau\": 0.5, \"epsilon\": 1e-12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _solve_case(\n            case[\"concepts\"], case[\"priors\"], case[\"codes\"], \n            case[\"alpha\"], case[\"tau\"], case[\"epsilon\"]\n        )\n        results.append(result)\n\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef _solve_case(concept_dict, priors, local_codes, alpha, tau, epsilon):\n    \"\"\"\n    Solves a single test case based on the problem specification.\n    \"\"\"\n    \n    # Memoization caches for normalization functions\n    memo_g = {}\n    memo_char_norm = {}\n\n    ABBREVIATIONS = {\n        \"hbp\": \"high blood pressure\", \"ckd\": \"chronic kidney disease\",\n        \"akd\": \"acute kidney disease\", \"dz\": \"disease\",\n        \"t2dm\": \"type 2 diabetes mellitus\", \"t1dm\": \"type 1 diabetes mellitus\",\n    }\n    ROMAN_NUMERALS = {\n        \"i\": \"1\", \"ii\": \"2\", \"iii\": \"3\", \"iv\": \"4\", \"v\": \"5\",\n        \"vi\": \"6\", \"vii\": \"7\", \"viii\": \"8\", \"ix\": \"9\", \"x\": \"10\",\n    }\n    ROMAN_KEYS_SORTED = sorted(ROMAN_NUMERALS.keys(), key=len, reverse=True)\n    STOPWORDS = {\"nos\", \"unspecified\"}\n\n    def _normalize_common(s):\n        norm_s = s.lower()\n        for abbr, expansion in ABBREVIATIONS.items():\n            norm_s = re.sub(r'\\b' + re.escape(abbr) + r'\\b', expansion, norm_s)\n        for r_key in ROMAN_KEYS_SORTED:\n            norm_s = re.sub(r'\\b' + r_key + r'\\b', ROMAN_NUMERALS[r_key], norm_s)\n        return norm_s\n    \n    def g(s):\n        if s in memo_g: return memo_g[s]\n        norm_s = _normalize_common(s)\n        tokens = re.sub(r'[^a-zA-Z0-9]', ' ', norm_s).split()\n        final_tokens = {token for token in tokens if token not in STOPWORDS}\n        memo_g[s] = final_tokens\n        return final_tokens\n\n    def char_normalize(s):\n        if s in memo_char_norm: return memo_char_norm[s]\n        norm_s = _normalize_common(s)\n        result = re.sub(r'[^a-zA-Z0-9]', '', norm_s)\n        memo_char_norm[s] = result\n        return result\n\n    def levenshtein(s1, s2):\n        m, n = len(s1), len(s2)\n        dp = np.zeros((m + 1, n + 1), dtype=int)\n        for i in range(m + 1):\n            dp[i, 0] = i\n        for j in range(n + 1):\n            dp[0, j] = j\n        for i in range(1, m + 1):\n            for j in range(1, n + 1):\n                cost = 0 if s1[i - 1] == s2[j - 1] else 1\n                dp[i, j] = min(dp[i - 1, j] + 1,\n                               dp[i, j - 1] + 1,\n                               dp[i - 1, j - 1] + cost)\n        return dp[m, n]\n\n    # Pre-computation steps\n    all_labels = {label for labels in concept_dict.values() for label in labels}\n    \n    df = defaultdict(int)\n    for label in all_labels:\n        for token in g(label):\n            df[token] += 1\n            \n    all_dict_tokens = df.keys()\n    w = {t: 1.0 / (1.0 + df.get(t, 0)) for t in all_dict_tokens}\n\n    processed_concepts = {}\n    for cid, labels in concept_dict.items():\n        processed_labels = [\n            {\"g\": g(label), \"char_norm\": char_normalize(label)}\n            for label in labels\n        ]\n        processed_concepts[cid] = processed_labels\n\n    M, U, A = 0, 0, 0\n    for s in local_codes:\n        if not s.strip():\n            U += 1\n            continue\n        \n        s_g = g(s)\n        s_char_norm = char_normalize(s)\n        \n        scores = {}\n        for cid, p_labels in processed_concepts.items():\n            max_label_score = 0.0\n            for label_data in p_labels:\n                l_g = label_data[\"g\"]\n                l_char_norm = label_data[\"char_norm\"]\n                \n                intersect = s_g.intersection(l_g)\n                union = s_g.union(l_g)\n                sum_w_intersect = sum(w.get(t, 1.0) for t in intersect)\n                sum_w_union = sum(w.get(t, 1.0) for t in union)\n                j_sim = sum_w_intersect / sum_w_union if sum_w_union > 0 else 0.0\n                \n                lev_dist = levenshtein(s_char_norm, l_char_norm)\n                max_len = max(len(s_char_norm), len(l_char_norm))\n                r_sim = (1.0 - lev_dist / max_len) if max_len > 0 else 0.0\n\n                combined_score = alpha * j_sim + (1 - alpha) * r_sim\n                if combined_score > max_label_score:\n                    max_label_score = combined_score\n            scores[cid] = max_label_score\n\n        candidate_set = {cid for cid, score in scores.items() if score >= tau}\n        \n        if not candidate_set:\n            U += 1\n            continue\n        \n        M += 1\n        max_score = max(scores[cid] for cid in candidate_set)\n        top_candidates = {cid for cid in candidate_set if max_score - scores[cid] <= epsilon}\n\n        if len(top_candidates) > 1:\n            A += 1\n            # Ambiguity resolution not needed for counting, but included for completeness:\n            # resolved_candidate = sorted(list(top_candidates), key=lambda cid: (-priors[cid], cid))[0]\n    \n    return [M, U, A]\n\nif __name__ == '__main__':\n    solve()\n```"
        },
        {
            "introduction": "电子健康记录（EHR）本质上是在不规则时间点发生的事件集合，但许多先进的机器学习模型（如循环神经网络）需要固定尺寸、规则采样的输入。本实践探讨了如何将这些稀疏、不规则的事件流转换为一个规整的特征张量。你将根据不同数据的临床语义（例如，瞬时测量值、累积剂量或状态变化）实施不同的重采样策略，这是为高级时间序列分析准备数据的关键一步。",
            "id": "4563173",
            "problem": "给定一组不规则采样的临床事件流，要求您根据特定事件类型的语义构建时间对齐的特征张量，以保留底层临床过程的含义。这些事件流来自电子健康记录（EHR; Electronic Health Records），包括瞬时实验室测量值、离散的药物剂量、二元事件标志和分类模态状态。您的任务是从第一性原理出发，形式化重采样规则，实现这些规则，并验证反映语义保留的不变式。\n\n基本基础。将临床时间序列视为具有事件语义的底层连续时间信号的实现。设 $t \\in \\mathbb{R}$ 表示以小时为单位的时间，并设 $G = \\{ g_j \\}_{j=0}^{J-1}$ 是一个步长为 $\\Delta > 0$ 小时的均匀时间网格。对于每个特征 $k$，设事件流为 $S_k = \\{ (t_i^{(k)}, v_i^{(k)}) \\}_{i=1}^{N_k}$，其中 $t_i^{(k)}$ 是以小时为单位的事件时间，$v_i^{(k)}$ 是事件值。我们假设以下广泛的语义，这些语义与测量理论和时间序列信号处理中经过充分检验的事实相一致：\n\n- 强度量（例如，血清钠等实验室测量值）是状态变量 $x_k(t)$ 的瞬时值，其中 $x_k(t)$ 的单位与观测持续时间无关。强度量的插值应仅在临床有效范围内反映连续性。\n- 广延量（例如，离散剂量）是随时间累积的总量，表示为脉冲度量。在重采样下，总量守恒必须成立。\n- 二元事件标志表示在检测窗口内事件的发生，不应作为连续值进行插值。\n- 分类状态（例如，通气模式）是阶跃过程；它们会向前延续直到发生变化，并且不应在类别之间进行插值。\n\n重采样的核心定义。定义特定于语义的重采样算子：\n\n- 带有效范围的强度量插值：给定一个强度量流 $S_k$ 和一个有效范围 $\\tau_k > 0$，将在 $g_j$ 处的对齐值定义为\n$$\nx_k(g_j) = \\begin{cases}\nv_{\\text{prev}} + \\dfrac{v_{\\text{next}} - v_{\\text{prev}}}{t_{\\text{next}} - t_{\\text{prev}}} \\cdot (g_j - t_{\\text{prev}}),  \\text{若 } \\exists\\, t_{\\text{prev}} \\le g_j \\le t_{\\text{next}},\\ g_j - t_{\\text{prev}} \\le \\tau_k,\\ t_{\\text{next}} - g_j \\le \\tau_k, \\\\\nv_i,  \\text{若 } \\exists\\, i \\text{ s.t. } t_i = g_j \\text{ 完全匹配}, \\\\\n\\text{缺失},  \\text{其他情况}.\n\\end{cases}\n$$\n这是受临床有效范围约束的线性插值；它不允许在没有未来锚点的情况下进行前向填充，也不允许在有效范围之外进行外推。\n\n- 带守恒的广延量速率聚合：将离散量表示为脉冲。在窗口 $[g_j, g_{j+1})$ 上，定义速率\n$$\nr_k(g_j) = \\frac{1}{\\Delta} \\sum_{i: t_i^{(k)} \\in [g_j, g_{j+1})} v_i^{(k)}.\n$$\n守恒要求\n$$\n\\sum_{j=0}^{J-2} r_k(g_j) \\cdot \\Delta = \\sum_{i=1}^{N_k} v_i^{(k)}.\n$$\n对于没有后续窗口的终端网格点，我们设置 $r_k(g_{J-1}) = 0$。\n\n- 二元检测窗口：对于窗口为 $\\omega > 0$ 的二元事件流，定义\n$$\nb_k(g_j) = \\mathbf{1}\\left( \\exists\\, i \\text{ with } t_i^{(k)} \\in (g_j - \\omega, g_j] \\right),\n$$\n即，如果在严格晚于 $g_j - \\omega$ 且不晚于 $g_j$ 的时间内有任何事件发生，则 $b_k(g_j)$ 等于 $1$，否则为 $0$。\n\n- 分类阶跃前向填充：对于编码为整数的分类状态，定义\n$$\nc_k(g_j) = \\begin{cases}\n\\text{时间 } \\le g_j \\text{ 的最后一个已知类别},  \\text{如果存在}, \\\\\n-1,  \\text{如果在首次观测前未知}.\n\\end{cases}\n$$\n\n构建特征张量。对于一个固定的网格 $G$ 和四个特征（强度量实验室值、广延量剂量、二元事件、分类状态），定义对齐的张量 $X \\in \\mathbb{R}^{J \\times 4}$，其列分别为插值的强度量值、广延量速率、二元标志和分类代码。\n\n您的实现必须：\n\n- 在重采样前对不规则的事件时间进行排序。\n- 应用带有指定有效范围 $\\tau$ 的强度量插值规则。\n- 在半开窗口 $[g_j, g_{j+1})$ 上应用带守恒的广延量速率聚合。\n- 在 $(g_j - \\omega, g_j]$ 上应用二元窗口化。\n- 应用分类前向填充，用 $-1$ 表示首次观测前的未知状态。\n\n单位。时间单位为小时。广延量速率的单位是每小时的总量。所有比较在这些单位下都应是精确的。\n\n测试套件。使用以下三个测试用例来构建张量并验证不变式。对于所有用例，使用网格 $G = [0, 4, 8, 12, 16, 20]$ 小时（即 $J = 6$ 且 $\\Delta = 4$ 小时），二元窗口 $\\omega = 4$ 小时，以及分类编码 $\\{\\text{\"VC\"} \\mapsto 0, \\text{\"PS\"} \\mapsto 1\\}$。\n\n- 测试用例 1（一般情况）：\n    - 强度量（血清钠）：$S_{\\text{Na}} = \\{(1, 140), (9, 138), (15, 142)\\}$，有效范围 $\\tau = 8$。\n    - 广延量（胰岛素剂量）：$S_{\\text{dose}} = \\{(2, 5), (6, 3), (11, 4), (19, 2)\\}$。\n    - 二元（发热峰值）：$S_{\\text{fever}} = \\{(3, 1), (10, 1), (17, 1)\\}$。\n    - 分类（通气模式）：$S_{\\text{vent}} = \\{(5, \\text{\"VC\"}), (14, \\text{\"PS\"})\\}$.\n    - 预期检查：\n        - 守恒性：$\\left| \\sum_{j=0}^{4} r_{\\text{dose}}(g_j)\\cdot 4 - (5 + 3 + 4 + 2) \\right| = 0$。\n        - 在 $g = 12$ 处的强度量：预期为 $140.0$，通过在 $(9, 138)$ 和 $(15, 142)$ 之间在有效范围内进行线性插值得到。\n        - 在 $g = 12$ 处的二元值：预期为 $1$。\n        - 在 $g = 16$ 处的分类值：预期为 $1$。\n\n- 测试用例 2（有效范围边界和窗口边界行为）：\n    - 强度量（血清钠）：$S_{\\text{Na}} = \\{(0, 135), (12, 145)\\}$，有效范围 $\\tau = 4$。\n    - 广延量（剂量）：$S_{\\text{dose}} = \\{(4, 1), (8, 1), (12, 1), (16, 1)\\}$。\n    - 二元（事件）：$S_{\\text{fever}} = \\{(4, 1), (7, 1)\\}$。\n    - 分类：$S_{\\text{vent}} = \\{(0, \\text{\"PS\"})\\}$.\n    - 预期检查：\n        - 守恒性：$\\left| \\sum_{j=0}^{4} r_{\\text{dose}}(g_j)\\cdot 4 - (1 + 1 + 1 + 1) \\right| = 0$。\n        - 在 $g = 4$ 处的强度量：预期为缺失，因为未来锚点不满足有效范围要求（距离前一个点正好 4 小时，但距离后一个点 8 小时，因此前向有效范围检查失败）。\n        - 在 $g = 4$ 处的二元值：预期为 $1$。\n        - 在 $g = 20$ 处的分类值：预期为 $1$。\n\n- 测试用例 3（窗口内多个事件和延迟的分类起始）：\n    - 强度量（血清钠）：$S_{\\text{Na}} = \\{(9, 139)\\}$，有效范围 $\\tau = 12$。\n    - 广延量（剂量）：$S_{\\text{dose}} = \\{(5, 2), (6, 1), (6, 3), (7, 1), (15, 2), (15, 3)\\}$。\n    - 二元（事件）：$S_{\\text{fever}} = \\{(1, 1), (20, 1)\\}$。\n    - 分类：$S_{\\text{vent}} = \\{(10, \\text{\"VC\"})\\}$.\n    - 预期检查：\n        - 守恒性：$\\left| \\sum_{j=0}^{4} r_{\\text{dose}}(g_j)\\cdot 4 - (2 + 1 + 3 + 1 + 2 + 3) \\right| = 0$。\n        - 在 $g = 12$ 处的强度量：预期为缺失（没有用于插值的未来锚点）。\n        - 在 $g = 20$ 处的二元值：预期为 $1$。\n        - 在 $g = 12$ 处的分类值：预期为 $0$。\n\n您的程序必须：\n\n- 实现所定义的重采样算子。\n- 对于每个测试用例，构建对齐的张量 $X$ 并计算四个不变式误差：\n    - $e_{\\text{dose}} = \\left| \\sum_{j=0}^{4} r_{\\text{dose}}(g_j)\\cdot 4 - \\sum_i v_i^{(\\text{dose})} \\right|$.\n    - 如果在网格时间 $g^*$ 的期望是数值 $v^*$，则 $e_{\\text{Na}} = |x_{\\text{Na}}(g^*) - v^*|$；如果期望是缺失，当 $x_{\\text{Na}}(g^*)$ 缺失时设 $e_{\\text{Na}} = 0$，否则设 $e_{\\text{Na}} = 1$。\n    - 对于指定的网格时间 $g^\\dagger$ 和期望的二元值 $b^*$，$e_{\\text{bin}} = |b(g^\\dagger) - b^*|$。\n    - 对于指定的网格时间 $g^\\ddagger$ 和期望的分类代码 $c^*$，$e_{\\text{cat}} = |c(g^\\ddagger) - c^*|$。\n- 每个测试用例报告一个浮点数，等于四个误差中的最大值。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，即 $\\texttt{[r_1,r_2,r_3]}$，其中 $r_1$、$r_2$ 和 $r_3$ 分别是测试用例 1、2 和 3 的最大不变式误差（浮点数）。",
            "solution": "用户提供了一个问题陈述，要求实现几种针对不同类型临床数据的时间序列重采样算法。问题在于从不规则采样的事件流中构建一个时间对齐的特征张量，并根据提供的测试用例和不变式来验证实现的正确性。\n\n### 步骤1：提取已知条件\n\n-   **时间网格**：一个步长为 $\\Delta > 0$ 小时的均匀网格 $G = \\{ g_j \\}_{j=0}^{J-1}$。\n-   **事件流**：对于每个特征 $k$，事件流给定为 $S_k = \\{ (t_i^{(k)}, v_i^{(k)}) \\}_{i=1}^{N_k}$。\n-   **重采样算子**：根据事件语义定义了四种类型的重采样算子：\n    1.  **强度量插值**：对于一个数据流 $S_k$ 和有效范围 $\\tau_k$，在网格点 $g_j$ 处的值为：\n        $$\n        x_k(g_j) = \\begin{cases}\n        v_{\\text{prev}} + \\dfrac{v_{\\text{next}} - v_{\\text{prev}}}{t_{\\text{next}} - t_{\\text{prev}}} \\cdot (g_j - t_{\\text{prev}}),  \\text{若 } \\exists\\, t_{\\text{prev}} \\le g_j \\le t_{\\text{next}},\\ g_j - t_{\\text{prev}} \\le \\tau_k,\\ t_{\\text{next}} - g_j \\le \\tau_k, \\\\\n        v_i,  \\text{若 } \\exists\\, i \\text{ s.t. } t_i = g_j \\text{ 完全匹配}, \\\\\n        \\text{缺失},  \\text{其他情况}.\n        \\end{cases}\n        $$\n        其中 $(t_{\\text{prev}}, v_{\\text{prev}})$ 和 $(t_{\\text{next}}, v_{\\text{next}})$ 是紧邻 $g_j$ 前后的事件。\n    2.  **广延量速率聚合**：对于网格步长 $\\Delta$，在窗口 $[g_j, g_{j+1})$ 上的速率为：\n        $$\n        r_k(g_j) = \\frac{1}{\\Delta} \\sum_{i: t_i^{(k)} \\in [g_j, g_{j+1})} v_i^{(k)}.\n        $$\n        对于终端点，$r_k(g_{J-1}) = 0$。守恒性要求 $\\sum_{j=0}^{J-2} r_k(g_j) \\cdot \\Delta = \\sum_{i=1}^{N_k} v_i^{(k)}$。\n    3.  **二元检测窗口**：对于一个窗口 $\\omega > 0$，在 $g_j$ 处的二元标志为：\n        $$\n        b_k(g_j) = \\mathbf{1}\\left( \\exists\\, i \\text{ with } t_i^{(k)} \\in (g_j - \\omega, g_j] \\right).\n        $$\n    4.  **分类阶跃前向填充**：在 $g_j$ 处的状态为：\n        $$\n        c_k(g_j) = \\begin{cases}\n        \\text{时间 } \\le g_j \\text{ 的最后一个已知类别},  \\text{如果存在}, \\\\\n        -1,  \\text{如果在首次观测前未知}.\n        \\end{cases}\n        $$\n-   **通用参数**：网格 $G = [0, 4, 8, 12, 16, 20]$ 小时（$J=6, \\Delta=4$），二元窗口 $\\omega = 4$ 小时，分类编码 $\\{\\text{\"VC\"} \\mapsto 0, \\text{\"PS\"} \\mapsto 1\\}$。\n-   **测试用例**：提供了三个不同的测试用例，包含特定的事件流和参数，以及用于在某些网格点进行验证的期望值。\n-   **误差度量**：定义了四个误差度量（$e_{\\text{dose}}, e_{\\text{Na}}, e_{\\text{bin}}, e_{\\text{cat}}$）来量化与预期检查的偏差。\n-   **最终输出**：程序必须为每个测试用例报告一个浮点数，代表计算出的四个误差中的最大值。输出格式为方括号内的逗号分隔列表：`[r_1,r_2,r_3]`。\n\n### 步骤2：使用提取的已知条件进行验证\n\n1.  **科学基础**：该问题在应用于医疗数据的时间序列分析和信号处理原理方面有很好的基础。强度量和广延量之间的区分，以及对二元和分类数据的特殊处理，是该领域的标准和有效概念。所有定义在科学和数学上都是合理的。\n2.  **适定性与客观性**：该问题是适定的。重采样规则以数学精度定义，包括处理边界条件和时间间隔的规范（例如，$[g_j, g_{j+1})$ vs. $(g_j-\\omega, g_j]$）。给定输入，可以确定性地计算出唯一的输出张量。语言是客观的，没有主观论断。\n3.  **不完整性或矛盾**：强度量插值的规范提出了多种情况。在评估这些情况的顺序上可能会出现潜在的歧义。具体来说，如果一个测量值正好出现在一个网格点上，它也可能被考虑用于插值。然而，其结构暗示了这些情况是互斥的，唯一合乎逻辑且不矛盾的解释是，精确匹配优先于插值，从而防止插值公式中出现除以零的情况。这是此类问题中的一个标准假设。广延量的守恒定律定义在区间 $[g_0, g_{J-1})$ 上，测试数据正确地落在这个范围内，避免了矛盾。总的来说，该问题是自洽和一致的。\n4.  **不切实际的条件**：数据值和时间尺度对于临床场景是现实的。不存在物理或科学上的不可能性。\n5.  **病态结构**：问题结构良好，能导出一个唯一的解。术语定义清晰。\n\n### 步骤3：结论与行动\n该问题是**有效的**。这是一个定义明确的计算任务，基于临床时间序列数据工程的可靠原则。将开发并实现一个解决方案。\n\n### 解决方案与实现\n\n该解决方案涉及为每种数据类型实现四个独立的重采样函数，以及一个处理测试用例的主函数。利用 NumPy 进行高效的数组操作和数值计算。\n\n1.  **强度量重采样 (`resample_intensive`)**：该函数首先检查事件和网格点之间是否存在精确的时间匹配。如果对于网格点 $g_j$ 不存在精确匹配，它会找到紧邻的前一个事件 $(t_{\\text{prev}}, v_{\\text{prev}})$ 和后一个事件 $(t_{\\text{next}}, v_{\\text{next}})$。然后，它验证两个事件都位于距 $g_j$ 指定的有效范围 $\\tau$ 内（即 $g_j - t_{\\text{prev}} \\le \\tau$ 和 $t_{\\text{next}} - g_j \\le \\tau$）。如果所有条件都满足，则执行线性插值。否则，该值被标记为缺失（用 `np.nan` 表示）。使用排序后的事件时间和 `np.searchsorted` 来实现高效查找。\n\n2.  **广延量重采样 (`resample_extensive`)**：该函数计算广延量的速率。它聚合落在每个半开网格区间 $[g_j, g_{j+1})$ 内的所有事件的总值。然后将此总和除以区间时长 $\\Delta$ 以得到速率 $r(g_j)$。根据问题定义，最后一个网格点 $g_{J-1}$ 的速率 $r(g_{J-1})$ 设置为 $0$。使用 `np.searchsorted` 可以高效地将事件时间映射到其对应的网格区间，确保半开区间定义的正确性。\n\n3.  **二元量重采样 (`resample_binary`)**：对于每个网格点 $g_j$，该函数确定在回顾性窗口 $(g_j-\\omega, g_j]$ 内是否有任何事件发生。如果找到至少一个事件，则结果为 $1$，否则为 $0$。在排序后的事件时间上使用 `np.searchsorted`，可以高效地查询每个窗口内的事件数量，而无需重复扫描。\n\n4.  **分类量重采样 (`resample_categorical`)**：该函数实现了“末次观测值结转”（LOCF）逻辑。对于每个网格点 $g_j$，它找到时间戳小于或等于 $g_j$ 的最近事件。然后将该事件的值赋给 $g_j$。如果不存在在前的事件，则使用默认值 $-1$。这通过使用带 `side='right'` 参数的 `np.searchsorted` 得以高效实现。\n\n最后，一个主函数 `solve` 负责协调每个测试用例的处理过程。它调用相应的重采样函数，根据问题中提供的检查项计算四个指定的误差度量（$e_{\\text{dose}}, e_{\\text{Na}}, e_{\\text{bin}}, e_{\\text{cat}}$），确定该用例的最大误差，并格式化结果以供最终输出。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are used.\n\ndef solve():\n    \"\"\"\n    Main function to solve the clinical time-series resampling problem.\n    It contains resampling helpers and processes the test cases.\n    \"\"\"\n\n    def resample_intensive(events, grid, tau):\n        \"\"\"\n        Resamples an intensive quantity stream using linear interpolation\n        with a clinical validity horizon.\n        \"\"\"\n        if not events:\n            return np.full(len(grid), np.nan)\n        \n        times = np.array([e[0] for e in events])\n        values = np.array([e[1] for e in events])\n        \n        resampled_values = np.full(len(grid), np.nan)\n        \n        for i, g in enumerate(grid):\n            # Precedence 1: Exact match on the grid point.\n            exact_match_indices = np.where(times == g)[0]\n            if exact_match_indices.size > 0:\n                resampled_values[i] = values[exact_match_indices[0]]\n                continue\n\n            # Precedence 2: Interpolation between two existing points.\n            idx = np.searchsorted(times, g)\n            \n            if idx == 0 or idx == len(times):\n                continue\n\n            t_prev, v_prev = times[idx - 1], values[idx - 1]\n            t_next, v_next = times[idx], values[idx]\n\n            # Check horizon constraints\n            if (g - t_prev) <= tau and (t_next - g) <= tau:\n                resampled_values[i] = v_prev + (v_next - v_prev) / (t_next - t_prev) * (g - t_prev)\n                \n        return resampled_values\n\n    def resample_extensive(events, grid, delta):\n        \"\"\"\n        Resamples an extensive quantity stream via rate aggregation.\n        \"\"\"\n        num_grid_points = len(grid)\n        rates = np.zeros(num_grid_points)\n        if not events:\n            return rates\n\n        num_bins = num_grid_points - 1\n        bin_sums = np.zeros(num_bins)\n        \n        for t, v in events:\n            if t < grid[0] or t >= grid[-1]:\n                continue\n            \n            j = np.searchsorted(grid, t, side='right') - 1\n            if 0 <= j < num_bins:\n                 bin_sums[j] += v\n            \n        rates[:num_bins] = bin_sums / delta\n        return rates\n\n    def resample_binary(events, grid, omega):\n        \"\"\"\n        Resamples a binary event stream using a detection window.\n        \"\"\"\n        num_grid_points = len(grid)\n        flags = np.zeros(num_grid_points, dtype=int)\n        if not events:\n            return flags\n\n        times = np.array([e[0] for e in events])\n\n        for i, g in enumerate(grid):\n            window_start = g - omega\n            # Find events t in (window_start, g]\n            start_idx = np.searchsorted(times, window_start, side='right')\n            end_idx = np.searchsorted(times, g, side='right')\n            \n            if start_idx < end_idx:\n                flags[i] = 1\n                \n        return flags\n\n    def resample_categorical(events, grid, cat_map):\n        \"\"\"\n        Resamples a categorical state stream using last-observation-carried-forward.\n        \"\"\"\n        num_grid_points = len(grid)\n        codes = np.full(num_grid_points, -1, dtype=int)\n        if not events:\n            return codes\n\n        coded_events = sorted([(t, cat_map[v_str]) for t, v_str in events])\n        times = np.array([e[0] for e in coded_events])\n        values = np.array([e[1] for e in coded_events])\n\n        indices = np.searchsorted(times, grid, side='right')\n        \n        for i, idx in enumerate(indices):\n            if idx > 0:\n                codes[i] = values[idx - 1]\n                \n        return codes\n\n    # Define the common grid and parameters\n    grid = np.array([0.0, 4.0, 8.0, 12.0, 16.0, 20.0])\n    delta = 4.0\n    omega = 4.0\n    cat_map = {\"VC\": 0, \"PS\": 1}\n\n    # Define the three test cases from the problem statement.\n    test_cases = [\n        {\n            \"s_na\": [(1, 140), (9, 138), (15, 142)], \"tau\": 8,\n            \"s_dose\": [(2, 5), (6, 3), (11, 4), (19, 2)],\n            \"s_fever\": [(3, 1), (10, 1), (17, 1)],\n            \"s_vent\": [(5, \"VC\"), (14, \"PS\")],\n            \"checks\": {\n                \"dose_conservation_sum\": 5 + 3 + 4 + 2,\n                \"na_check\": {\"g\": 12, \"val\": 140.0},\n                \"bin_check\": {\"g\": 12, \"val\": 1},\n                \"cat_check\": {\"g\": 16, \"val\": 1},\n            }\n        },\n        {\n            \"s_na\": [(0, 135), (12, 145)], \"tau\": 4,\n            \"s_dose\": [(4, 1), (8, 1), (12, 1), (16, 1)],\n            \"s_fever\": [(4, 1), (7, 1)],\n            \"s_vent\": [(0, \"PS\")],\n            \"checks\": {\n                \"dose_conservation_sum\": 1 + 1 + 1 + 1,\n                \"na_check\": {\"g\": 4, \"val\": \"missing\"},\n                \"bin_check\": {\"g\": 4, \"val\": 1},\n                \"cat_check\": {\"g\": 20, \"val\": 1},\n            }\n        },\n        {\n            \"s_na\": [(9, 139)], \"tau\": 12,\n            \"s_dose\": [(5, 2), (6, 1), (6, 3), (7, 1), (15, 2), (15, 3)],\n            \"s_fever\": [(1, 1), (20, 1)],\n            \"s_vent\": [(10, \"VC\")],\n            \"checks\": {\n                \"dose_conservation_sum\": 2 + 1 + 3 + 1 + 2 + 3,\n                \"na_check\": {\"g\": 12, \"val\": \"missing\"},\n                \"bin_check\": {\"g\": 20, \"val\": 1},\n                \"cat_check\": {\"g\": 12, \"val\": 0},\n            }\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Sort event streams by time, as required by the problem\n        s_na = sorted(case[\"s_na\"])\n        s_dose = sorted(case[\"s_dose\"])\n        s_fever = sorted(case[\"s_fever\"])\n        s_vent = sorted(case[\"s_vent\"])\n\n        # Perform resampling for each feature type\n        x_na = resample_intensive(s_na, grid, case[\"tau\"])\n        r_dose = resample_extensive(s_dose, grid, delta)\n        b_fever = resample_binary(s_fever, grid, omega)\n        c_vent = resample_categorical(s_vent, grid, cat_map)\n\n        # Calculate the four invariant errors\n        \n        # e_dose: Conservation error\n        total_grid_amount = np.sum(r_dose[:-1]) * delta\n        total_original_amount = case[\"checks\"][\"dose_conservation_sum\"]\n        e_dose = abs(total_grid_amount - total_original_amount)\n\n        # e_na: Intensive value error\n        check_na = case[\"checks\"][\"na_check\"]\n        g_idx_na = np.where(grid == check_na[\"g\"])[0][0]\n        val_na_calc = x_na[g_idx_na]\n        if check_na[\"val\"] == \"missing\":\n            e_na = 0.0 if np.isnan(val_na_calc) else 1.0\n        else:\n            e_na = abs(val_na_calc - check_na[\"val\"])\n            \n        # e_bin: Binary flag error\n        check_bin = case[\"checks\"][\"bin_check\"]\n        g_idx_bin = np.where(grid == check_bin[\"g\"])[0][0]\n        val_bin_calc = b_fever[g_idx_bin]\n        e_bin = abs(val_bin_calc - check_bin[\"val\"])\n\n        # e_cat: Categorical code error\n        check_cat = case[\"checks\"][\"cat_check\"]\n        g_idx_cat = np.where(grid == check_cat[\"g\"])[0][0]\n        val_cat_calc = c_vent[g_idx_cat]\n        e_cat = abs(val_cat_calc - check_cat[\"val\"])\n\n        # The result for this test case is the maximum of the four errors\n        max_error = max(e_dose, e_na, float(e_bin), float(e_cat))\n        results.append(max_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        },
        {
            "introduction": "在使用纵向EHR数据构建预测模型时，一个常见且严重的陷阱是“不朽时间偏倚”（immortal time bias），即在构建特征时不慎泄露了未来的信息，导致模型表现过于乐观且在现实中无效。这个高级实践将向你介绍“地标分析”（landmark analysis）方法，这是一种强大的技术，通过在特定时间点（地标）严格地构建特征和定义结局来避免这种偏倚。掌握这种方法对于开发有效且可靠的临床预测模型至关重要。",
            "id": "4563190",
            "problem": "您将获得多名受试者的电子健康记录（EHR）数据和临床随访的简化抽象，目标是在一个固定的地标时间构建地标特征，并定义规则以避免在后续结果标注中出现永生时间偏倚。核心任务是实现一个地标分析程序，该程序使用原则性的生存分析定义，在固定的时间原点构建时间依赖性协变量，并在固定的时间窗内标注结果。\n\n基本原理和定义：\n- 生存分析通过事件时间 $T_i$ 和删失时间 $C_i$ 来定义每个受试者，其中观测时间为 $X_i = \\min(T_i, C_i)$，事件指示符为 $\\Delta_i = \\mathbb{1}\\{T_i \\le C_i\\}$。当使用基线后信息对暴露或结果进行分类，且这种分类方式要求受试者存活到信息记录之时，就会产生永生时间偏倚；为避免此问题，地标分析在源自地标的固定原点构建协变量和标签。\n- 地标分析固定一个地标时间 $L$，并将风险集定义为在 $L$ 时无事件且未删失的受试者。结果是相对于 $L$ 定义的，而不是原始的开始时间。\n\n任务：\n- 您必须实现一个程序，使用以下固定参数来构建地标特征和标注结果：\n  1. 地标时间 $L = 100$ 天。\n  2. 结果观察期 $H = 30$ 天。\n  3. 收缩压回溯窗口 $W_{\\mathrm{sbp}} = 60$ 天。\n  4. 就诊次数回溯窗口 $W_{\\mathrm{vis}} = 90$ 天。\n  5. 指数衰减参数 $\\lambda = 0.05$ 每天。\n  6. 参考收缩压 $r_{\\mathrm{sbp}} = 120$ 毫米汞柱（mmHg）。\n\n- 对于每个受试者 $i$，程序必须强制执行以下数学表达的规则以避免永生时间偏倚：\n  1. 资格（风险集）：当且仅当 $\\min(T_i, C_i) > L$ 且（若 $T_i$ 有定义）$T_i > L$ 且 $C_i > L$ 时，才将受试者纳入。如果 $T_i = L$ 或 $C_i \\le L$，则该受试者在地标时间不符合资格。\n  2. 时间原点和延迟进入：在地标时间，通过定义 $t' = t - L$ 将时间重置为 $0$。只有来自时间 $t \\le L$ 的协变量信息才可用于特征构建。\n  3. 观察期内的结果标签：对于符合资格的受试者，定义标签 $Y_i = \\mathbb{1}\\{L < T_i \\le \\min(C_i, L + H)\\}$。这将在删失前，把区间 $(L, L + H]$ 内发生的事件标记出来。对于不符合资格的受试者，按照惯例将标签设为 $0$，并用资格标志表示其被排除在风险集之外。\n\n从允许的地标前数据构建特征（所有时间单位为天，所有收缩压值单位为毫米汞柱）：\n- 收缩压特征：\n  1. 窗口内末次观测值结转：设 $\\{(t_{ij}, x_{ij})\\}$ 为收缩压测量值，其中 $t_{ij} \\in [L - W_{\\mathrm{sbp}}, L]$。末次观测值结转为 $x_{i,\\mathrm{last}} = x_{ij^*}$，其中 $j^* = \\arg\\max_j t_{ij}$。如果在窗口内没有测量值，则设 $x_{i,\\mathrm{last}} = r_{\\mathrm{sbp}}$。\n  2. 窗口内指数加权平均值：对于 $t_{ij} \\in [L - W_{\\mathrm{sbp}}, L]$，定义权重 $w_{ij} = \\exp(-\\lambda (L - t_{ij}))$。指数加权平均值为 $$\\bar{x}_{i,\\mathrm{ewm}} = \\begin{cases}\\frac{\\sum_j w_{ij} x_{ij}}{\\sum_j w_{ij}},  \\text{如果存在 } j \\text{ 使得 } t_{ij} \\in [L - W_{\\mathrm{sbp}}, L],\\\\ r_{\\mathrm{sbp}},  \\text{其他情况。}\\end{cases}$$\n- 药物暴露特征：\n  1. 地标时有效：给定用药区间 $\\{[a_{ik}, b_{ik})\\}$，定义 $m_{i,\\mathrm{active}} = \\mathbb{1}\\{\\exists k: a_{ik} \\le L < b_{ik}\\}$，即如果有任何区间覆盖了 $L$，则在地标时为有效状态。\n- 就诊次数特征：\n  1. 窗口内就诊次数：给定就诊时间 $\\{v_{i\\ell}\\}$，定义 $n_{i,\\mathrm{vis}} = \\left|\\{v_{i\\ell} \\in [L - W_{\\mathrm{vis}}, L]\\}\\right|$。\n\n单位：\n- 所有时间均以天为单位。\n- 收缩压值以毫米汞柱（mmHg）为单位。\n- 输出的浮点数必须四舍五入到三位小数。\n\n测试套件：\n- 使用以下四个具有科学合理数值的受试者。\n\n受试者1：\n- 事件时间 $T_1 = 115$，删失时间 $C_1 = 200$。\n- 收缩压时间 $[20, 85, 95, 99]$ 和值 $[130, 140, 135, 138]$。\n- 用药区间 $[[50, 120]]$。\n- 就诊时间 $[30, 70, 80, 95]$。\n\n受试者2（边界情况：事件发生在地标时间）：\n- 事件时间 $T_2 = 100$，删失时间 $C_2 = 300$。\n- 收缩压时间 $[40, 55, 100]$ 和值 $[128, 132, 129]$。\n- 用药区间 $[[101, 200]]$。\n- 就诊时间 $[99, 100]$。\n\n受试者3（回溯窗口内缺少收缩压数据，在观察期内删失）：\n- 未观察到事件；视为 $T_3 = +\\infty$，删失时间 $C_3 = 120$。\n- 收缩压时间 $[10, 20, 30]$ 和值 $[125, 127, 126]$。\n- 用药区间 $[[0, 90]]$。\n- 就诊时间 $[5, 15, 25, 35, 45]$。\n\n受试者4（事件发生在观察期之后）：\n- 事件时间 $T_4 = 160$，删失时间 $C_4 = 200$。\n- 收缩压时间 $[70, 110]$ 和值 $[150, 149]$。\n- 用药区间 $[[20, 80], [95, 105]]$。\n- 就诊时间 $[40, 100, 101]$。\n\n输出规格：\n- 对于每个受试者 $i$，计算并输出一个列表 $[\\,\\text{eligible}_i,\\, Y_i,\\, x_{i,\\mathrm{last}},\\, \\bar{x}_{i,\\mathrm{ewm}},\\, m_{i,\\mathrm{active}},\\, n_{i,\\mathrm{vis}}\\,]$，其中布尔值为标准逻辑值，浮点数四舍五入到三位小数。\n- 最终程序输出必须是单行，包含一个由方括号括起来的、以逗号分隔的受试者级别列表，例如 $[[\\dots],[\\dots],[\\dots],[\\dots]]$。",
            "solution": "该解决方案通过原则性地应用生存分析和精心构建的特征工程规则来实施，这些规则明确地避免了在地标时间的永生时间偏倚。其科学基础如下：\n\n1. 使用生存分析定义事件时间和删失时间。对于每个受试者 $i$，设 $T_i$ 为事件时间， $C_i$ 为删失时间。观测时间为 $X_i = \\min(T_i, C_i)$，事件指示符为 $\\Delta_i = \\mathbb{1}\\{T_i \\le C_i\\}$。如果我们使用在基线或地标时间之后发生的信息来对暴露或结果进行分类，从而要求受试者存活到观察到此类信息之时，就会产生永生时间偏倚。地标分析通过在 $L$ 固定一个原点，并将特征构建和结果标注限制在 $L$ 时或之前可用的信息以及相对于 $L$ 定义的结果，来缓解此问题。\n\n2. 地标时间的资格判定使用延迟进入（左截断）逻辑：仅纳入那些在 $L$ 时无事件且未删失的受试者。形式上，如果 $X_i > L$ 且当 $T_i$ 有定义时 $T_i > L$，则受试者 $i$ 符合资格。$T_i = L$ 的受试者 $i$ 在地标时间并非无事件，必须排除。$C_i \\le L$ 的受试者 $i$ 在地标时间或之前被删失，必须排除。\n\n3. 我们通过将任何时间 $t$ 映射到 $t' = t - L$ 在 $L$ 处将时间原点重置为 $0$。协变量仅使用原始时间 $t \\le L$ 的数据计算。对于符合资格的受试者，观察期 $H$ 内的结果标签为 $Y_i = \\mathbb{1}\\{L < T_i \\le \\min(C_i, L + H)\\}$，对应于删失前在区间 $(L, L + H]$ 内发生的事件。对于不符合资格的受试者，我们按照惯例将 $Y_i$ 设为 $0$，并使用资格标志表示他们被排除在风险集之外。这一定义确保了科学的真实性，因为它不会将地标时间后的暴露或未来的生存归因于地标时间前的风险。\n\n4. 特征工程：\n   - 在窗口 $[L - W_{\\mathrm{sbp}}, L]$ 内的收缩压末次观测值结转：设 $\\{(t_{ij}, x_{ij})\\}$ 为 $t_{ij}$ 在有效窗口内的测量值。特征 $x_{i,\\mathrm{last}}$ 是与窗口内最大 $t_{ij}$ 相关联的值。如果窗口内没有测量值，则设 $x_{i,\\mathrm{last}} = r_{\\mathrm{sbp}}$。\n   - 在同一窗口内使用衰减参数 $\\lambda$ 的指数加权平均值：权重为 $w_{ij} = \\exp(-\\lambda (L - t_{ij}))$。加权平均值为 $$\\bar{x}_{i,\\mathrm{ewm}} = \\begin{cases}\\frac{\\sum_j w_{ij} x_{ij}}{\\sum_j w_{ij}},  \\text{如果 } j \\text{ 的集合非空，}\\\\ r_{\\mathrm{sbp}},  \\text{其他情况。}\\end{cases}$$ 通过权重总和进行归一化，可确保得到一个恰当的加权平均值，并避免偏向于更近期的值，因为越接近 $L$ 的 $t_{ij}$ 权重越大。\n   - 地标时有效的药物：给定暴露区间 $[a_{ik}, b_{ik})$，定义 $m_{i,\\mathrm{active}} = \\mathbb{1}\\{\\exists k: a_{ik} \\le L < b_{ik}\\}$ 以仅捕获在 $L$ 时的活动状态。这避免了如果我们将暴露定义为“随访期间曾暴露”时可能发生的永生时间偏倚，因为这种定义将要求受试者存活过 $L$ 才能被划分为暴露组。\n   - 窗口 $[L - W_{\\mathrm{vis}}, L]$ 内的就诊次数：$n_{i,\\mathrm{vis}} = \\left|\\{v_{i\\ell} \\in [L - W_{\\mathrm{vis}}, L]\\}\\right|$。\n\n5. 应用于测试套件：\n   - 固定参数：$L = 100$ 天, $H = 30$ 天, $W_{\\mathrm{sbp}} = 60$ 天, $W_{\\mathrm{vis}} = 90$ 天, $\\lambda = 0.05$ 每天, $r_{\\mathrm{sbp}} = 120$ mmHg。\n   - 受试者1：$T_1 = 115$, $C_1 = 200$ 意味着符合资格，因为 $115 > 100$ 且 $200 > 100$。标签 $Y_1 = \\mathbb{1}\\{100 < 115 \\le 130\\} = 1$。收缩压窗口为 $[40, 100]$，因此时间 $[85, 95, 99]$ 及其值 $[140, 135, 138]$ 被包括在内。末次观测值 $x_{1,\\mathrm{last}} = 138$。指数加权平均值使用权重 $w = [\\exp(-0.05 \\cdot 15), \\exp(-0.05 \\cdot 5), \\exp(-0.05 \\cdot 1)]$，归一化后得到的值约为 $137.3$ 到 $137.4$ mmHg。用药区间 $[50, 120)$ 在 $L$ 时有效，所以 $m_{1,\\mathrm{active}} = 1$。窗口 $[10, 100]$ 内的就诊次数包括 $[30, 70, 80, 95]$，因此 $n_{1,\\mathrm{vis}} = 4$。\n   - 受试者2：$T_2 = 100$, $C_2 = 300$ 意味着不符合资格，因为 $T_2 = L$。按惯例设 $Y_2 = 0$，资格标志表示排除。收缩压窗口包括 $[40, 55, 100]$ 及其值 $[128, 132, 129]$。末次观测值 $x_{2,\\mathrm{last}} = 129$。指数加权平均值使用权重 $[\\exp(-0.05 \\cdot 60), \\exp(-0.05 \\cdot 45), 1]$，得到的值约为 $129.1$ 到 $129.2$ mmHg。用药区间 $[101, 200)$ 在 $L$ 时无效，所以 $m_{2,\\mathrm{active}} = 0$。就诊次数窗口 $[10, 100]$ 包括 $[99, 100]$，因此 $n_{2,\\mathrm{vis}} = 2$。\n   - 受试者3：将无事件视为 $T_3 = +\\infty$, $C_3 = 120$ 意味着符合资格 ($120 > 100$)。标签 $Y_3 = \\mathbb{1}\\{100 < +\\infty \\le \\min(120, 130)\\} = 0$。收缩压窗口 $[40, 100]$ 内没有测量值；使用参考值 $x_{3,\\mathrm{last}} = 120$ 和 $\\bar{x}_{3,\\mathrm{ewm}} = 120$。用药区间 $[0, 90)$ 在 $L$ 之前结束，所以 $m_{3,\\mathrm{active}} = 0$。就诊窗口 $[10, 100]$ 包括 $[15, 25, 35, 45]$，因此 $n_{3,\\mathrm{vis}} = 4$。\n   - 受试者4：$T_4 = 160$, $C_4 = 200$ 意味着符合资格 ($160 > 100$, $200 > 100$)。标签 $Y_4 = \\mathbb{1}\\{100 < 160 \\le 130\\} = 0$。收缩压窗口 $[40, 100]$ 仅包括时间点 $70$ 及其值 $150$；末次观测值 $x_{4,\\mathrm{last}} = 150$，指数加权平均值也等于 $150$（因为单个测量值归一化后等于其本身）。用药区间 $[20, 80)$ 和 $[95, 105)$ 中的第二个区间包含 $L$，所以 $m_{4,\\mathrm{active}} = 1$。就诊窗口 $[10, 100]$ 包括 $[40, 100]$，因此 $n_{4,\\mathrm{vis}} = 2$。\n\n6. 实现细节：\n   - 所有计算必须仅使用 $L$ 或之前的数据。\n   - 最终输出中的浮点数必须四舍五入到三位小数。\n   - 程序必须生成单行输出，其中包含受试者结果的列表：$[[\\text{eligible}_1, Y_1, x_{1,\\mathrm{last}}, \\bar{x}_{1,\\mathrm{ewm}}, m_{1,\\mathrm{active}}, n_{1,\\mathrm{vis}}], \\dots, [\\text{eligible}_4, Y_4, x_{4,\\mathrm{last}}, \\bar{x}_{4,\\mathrm{ewm}}, m_{4,\\mathrm{active}}, n_{4,\\mathrm{vis}}]]$。\n\n该设计将算法植根于生存分析原则，在地标时间强制执行延迟进入，将协变量限制在允许的地标前信息，并在固定观察期内定义结果，所有这些共同防止了永生时间偏倚。",
            "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_landmark_features(subject, params):\n    \"\"\"\n    Compute landmark features and label for one subject according to specified rules.\n    subject: dict with keys:\n        'event_time': float or None (None => no event, treated as +inf)\n        'censor_time': float\n        'sbp_times': list of floats\n        'sbp_values': list of floats (same length as sbp_times)\n        'med_intervals': list of [start, end) intervals\n        'visit_times': list of floats\n    params: dict with keys:\n        'L': landmark time\n        'H': horizon\n        'W_sbp': systolic BP lookback window\n        'W_vis': visit lookback window\n        'lambda': exponential decay per day\n        'r_sbp': reference sbp\n    Returns: list [eligible_bool, label_bool, last_sbp, ewm_sbp, med_active_int, visit_count_int]\n             floats rounded to 3 decimals as specified.\n    \"\"\"\n    L = params['L']\n    H = params['H']\n    W_sbp = params['W_sbp']\n    W_vis = params['W_vis']\n    lam = params['lambda']\n    r_sbp = params['r_sbp']\n\n    T = subject['event_time']\n    C = subject['censor_time']\n    # Treat None event time as +inf\n    T_eff = np.inf if T is None else T\n    X = min(T_eff, C)\n\n    # Eligibility: event-free and uncensored strictly after L\n    eligible = (X > L) and (C > L) and (T_eff > L)\n\n    # Window bounds\n    sbp_start = L - W_sbp\n    vis_start = L - W_vis\n\n    # Filter SBP measurements within [sbp_start, L]\n    sbp_times = subject['sbp_times']\n    sbp_values = subject['sbp_values']\n    sbp_in_window_indices = [i for i, t in enumerate(sbp_times) if (t >= sbp_start and t <= L)]\n    if sbp_in_window_indices:\n        # Last value carried forward: choose max t within window\n        # Determine index of max time within window\n        last_idx = max(sbp_in_window_indices, key=lambda i: sbp_times[i])\n        last_sbp = sbp_values[last_idx]\n        # Exponentially weighted mean\n        times = np.array([sbp_times[i] for i in sbp_in_window_indices], dtype=float)\n        values = np.array([sbp_values[i] for i in sbp_in_window_indices], dtype=float)\n        weights = np.exp(-lam * (L - times))\n        ewm_sbp = float(np.sum(weights * values) / np.sum(weights))\n    else:\n        last_sbp = float(r_sbp)\n        ewm_sbp = float(r_sbp)\n\n    # Medication active at L\n    med_active = 0\n    for interval in subject['med_intervals']:\n        a, b = float(interval[0]), float(interval[1])\n        if a <= L < b:\n            med_active = 1\n            break\n\n    # Visit count within [vis_start, L]\n    visit_times = subject['visit_times']\n    visit_count = sum(1 for t in visit_times if (t >= vis_start and t <= L))\n\n    # Label within horizon for eligible subjects: event in (L, L+H] before censoring\n    # If ineligible, set label to False by convention\n    if eligible:\n        # Event occurs if T_eff is finite and within horizon and before or at censor\n        label = (T_eff > L) and (T_eff <= min(C, L + H))\n    else:\n        label = False\n\n    # Round floats to 3 decimals\n    last_sbp_rounded = round(float(last_sbp), 3)\n    ewm_sbp_rounded = round(float(ewm_sbp), 3)\n\n    return [bool(eligible), bool(label), last_sbp_rounded, ewm_sbp_rounded, int(med_active), int(visit_count)]\n\ndef solve():\n    # Define parameters from the problem statement\n    params = {\n        'L': 100.0,      # days\n        'H': 30.0,       # days\n        'W_sbp': 60.0,   # days\n        'W_vis': 90.0,   # days\n        'lambda': 0.05,  # per day\n        'r_sbp': 120.0   # mmHg\n    }\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'event_time': 115.0,\n            'censor_time': 200.0,\n            'sbp_times': [20.0, 85.0, 95.0, 99.0],\n            'sbp_values': [130.0, 140.0, 135.0, 138.0],\n            'med_intervals': [(50.0, 120.0)],\n            'visit_times': [30.0, 70.0, 80.0, 95.0]\n        },\n        {\n            'event_time': 100.0,\n            'censor_time': 300.0,\n            'sbp_times': [40.0, 55.0, 100.0],\n            'sbp_values': [128.0, 132.0, 129.0],\n            'med_intervals': [(101.0, 200.0)],\n            'visit_times': [99.0, 100.0]\n        },\n        {\n            'event_time': None,  # No event observed\n            'censor_time': 120.0,\n            'sbp_times': [10.0, 20.0, 30.0],\n            'sbp_values': [125.0, 127.0, 126.0],\n            'med_intervals': [(0.0, 90.0)],\n            'visit_times': [5.0, 15.0, 25.0, 35.0, 45.0]\n        },\n        {\n            'event_time': 160.0,\n            'censor_time': 200.0,\n            'sbp_times': [70.0, 110.0],\n            'sbp_values': [150.0, 149.0],\n            'med_intervals': [(20.0, 80.0), (95.0, 105.0)],\n            'visit_times': [40.0, 100.0, 101.0]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_landmark_features(case, params)\n        results.append(result)\n\n    # Final print statement in the exact required format: single line, comma-separated list enclosed in brackets.\n    # We convert each sublist to its string representation and join them.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```"
        }
    ]
}