{
    "hands_on_practices": [
        {
            "introduction": "成本复杂度剪枝的核心在于生成一系列嵌套的、复杂度递减的子树。本练习将引导您深入该过程的底层机制：计算“最弱连接”参数 $\\alpha_t$ 。通过推导并计算这个临界值，您将掌握如何量化模型风险增加与复杂度降低之间的权衡，这是在实践中选择剪枝点的基础。",
            "id": "4615673",
            "problem": "一个医院系统使用分类与回归树（CART; Classification And Regression Trees）开发了一个用于预测$30$天再入院的预测模型。训练标签是二元结果$y_i \\in \\{0,1\\}$，树$T$的每个终端节点（叶节点）$\\ell$通过最大似然估计（MLE; Maximum Likelihood Estimation）来拟合一个伯努利均值。叶节点$\\ell$的经验风险定义为负对数似然\n$$\nR(\\ell) \\equiv -\\sum_{i \\in \\ell} \\big( y_i \\ln(\\hat{p}_\\ell) + (1-y_i)\\ln(1-\\hat{p}_\\ell) \\big),\n$$\n其中$\\hat{p}_\\ell$是$\\ell$中伯努利均值的最大似然估计，而树$T$的风险为 $R(T) \\equiv \\sum_{\\ell \\in \\mathcal{L}(T)} R(\\ell)$，其中$\\mathcal{L}(T)$是叶节点的集合。在成本复杂度剪枝中，我们评估目标函数\n$$\nC_\\alpha(T) \\equiv R(T) + \\alpha |\\mathcal{L}(T)|,\n$$\n其中$\\alpha \\ge 0$是一个复杂度参数， $|\\mathcal{L}(T)|$是叶节点的数量。考虑一个内部节点$t$，其子树$T_t$有$|\\mathcal{L}(T_t)|$个叶节点。将$T_t$折叠成单个叶节点$t$会使叶节点数量减少$|\\mathcal{L}(T_t)|-1$，并使风险从$R(T_t)$变为$R(t)$，其中$R(t)$是通过对$T_t$下的所有样本进行最大似然估计拟合单个伯努利叶节点而计算出的负对数似然。\n\n仅根据上述定义，通过令折叠$T_t$时风险的增加量等于叶节点数量的减少量，来推导节点$t$的最弱链接值$\\alpha_t$。然后，在一个位于$T_t$下的真实医疗队列中，假设子树$T_t$有$|\\mathcal{L}(T_t)| = 3$个叶节点，每个叶节点的患者总数$n_\\ell$和再入院人数$k_\\ell$的计数$(n_\\ell,k_\\ell)$如下：\n- 叶节点1：$(n_1,k_1) = (50,5)$，\n- 叶节点2：$(n_2,k_2) = (30,9)$，\n- 叶节点3：$(n_3,k_3) = (20,4)$。\n在每个叶节点内使用最大似然估计$\\hat{p}_\\ell = k_\\ell/n_\\ell$，在折叠后的节点$t$中使用$\\hat{p}_t = (\\sum_{\\ell} k_\\ell)/(\\sum_{\\ell} n_\\ell)$。将$\\alpha_t$的最终答案表示为仅含自然对数的单个闭式解析表达式，不进行任何数值近似。不包含任何单位。无需四舍五入。",
            "solution": "分类与回归树（CART）的成本复杂度剪枝原则为每个内部节点$t$定义了一个复杂度参数的临界值$\\alpha_t$。这个值被称为最弱链接值，它代表一个阈值，当复杂度参数达到该值时，剪掉以$t$为根的子树$T_t$的成本与不剪掉它的成本相等。我们通过令未剪枝子树的成本复杂度$C_\\alpha(T_t)$与剪枝后节点$t$的成本复杂度$C_\\alpha(t)$相等来求得$\\alpha_t$。\n\n成本复杂度定义为$C_\\alpha(T) \\equiv R(T) + \\alpha |\\mathcal{L}(T)|$，其中$R(T)$是树的风险， $|\\mathcal{L}(T)|$是叶节点的数量。\n对于未剪枝的子树$T_t$，成本为$C_\\alpha(T_t) = R(T_t) + \\alpha |\\mathcal{L}(T_t)|$。\n如果我们剪掉子树$T_t$，节点$t$就变成一个叶节点。生成的树与这个新叶节点相关的成本为$C_\\alpha(t) = R(t) + \\alpha \\cdot 1$。注意，由于折叠后的节点是单个叶节点，因此$|\\mathcal{L}(t)| = 1$。\n\n我们令这两个成本相等，以找到权衡达到平衡时的$\\alpha_t$值：\n$$R(T_t) + \\alpha_t |\\mathcal{L}(T_t)| = R(t) + \\alpha_t$$\n整理各项以求解$\\alpha_t$：\n$$\\alpha_t \\big( |\\mathcal{L}(T_t)| - 1 \\big) = R(t) - R(T_t)$$\n$$\\alpha_t = \\frac{R(t) - R(T_t)}{|\\mathcal{L}(T_t)| - 1}$$\n分子$R(t) - R(T_t)$是因剪枝导致的经验风险的增加量。分母$|\\mathcal{L}(T_t)| - 1$是叶节点数量的减少量。\n\n单个叶节点$\\ell$的风险是在该叶节点内的数据上拟合的伯努利模型的负对数似然。对于一个有$n_\\ell$个总样本和$k_\\ell$个正向结果（再入院）的叶节点，伯努利均值的最大似然估计（MLE）为$\\hat{p}_\\ell = k_\\ell / n_\\ell$。风险为：\n$$R(\\ell) \\equiv -\\sum_{i \\in \\ell} \\big( y_i \\ln(\\hat{p}_\\ell) + (1-y_i)\\ln(1-\\hat{p}_\\ell) \\big)$$\n通过计算正向结果（$y_i=1$）和负向结果（$y_i=0$）的数量，可以简化这个和：\n$$R(\\ell) = - \\big[ k_\\ell \\ln(\\hat{p}_\\ell) + (n_\\ell - k_\\ell) \\ln(1 - \\hat{p}_\\ell) \\big]$$\n$$R(\\ell) = - \\left[ k_\\ell \\ln\\left(\\frac{k_\\ell}{n_\\ell}\\right) + (n_\\ell - k_\\ell) \\ln\\left(\\frac{n_\\ell - k_\\ell}{n_\\ell}\\right) \\right]$$\n\n问题提供了一个有$|\\mathcal{L}(T_t)| = 3$个叶节点的子树$T_t$的数据。\n未剪枝子树$T_t$的风险是其叶节点风险的总和：$R(T_t) = R(\\ell_1) + R(\\ell_2) + R(\\ell_3)$。\n三个叶节点的数据如下：\n- 叶节点1：$(n_1, k_1) = (50, 5)$。因此，$\\hat{p}_1 = 5/50 = 1/10$。\n  $$R(\\ell_1) = - \\left[ 5 \\ln\\left(\\frac{5}{50}\\right) + (50 - 5) \\ln\\left(1 - \\frac{5}{50}\\right) \\right] = - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right]$$\n- 叶节点2：$(n_2, k_2) = (30, 9)$。因此，$\\hat{p}_2 = 9/30 = 3/10$。\n  $$R(\\ell_2) = - \\left[ 9 \\ln\\left(\\frac{9}{30}\\right) + (30 - 9) \\ln\\left(1 - \\frac{9}{30}\\right) \\right] = - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right]$$\n- 叶节点3：$(n_3, k_3) = (20, 4)$。因此，$\\hat{p}_3 = 4/20 = 1/5$。\n  $$R(\\ell_3) = - \\left[ 4 \\ln\\left(\\frac{4}{20}\\right) + (20 - 4) \\ln\\left(1 - \\frac{4}{20}\\right) \\right] = - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right]$$\n\n子树的总风险是：\n$$R(T_t) = - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right] - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right] - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right]$$\n\n对于剪枝后的节点$t$，我们聚合来自子树的所有样本。总样本数为$n_t = n_1 + n_2 + n_3 = 50 + 30 + 20 = 100$。总再入院人数为$k_t = k_1 + k_2 + k_3 = 5 + 9 + 4 = 18$。\n剪枝后节点的最大似然估计为$\\hat{p}_t = k_t / n_t = 18 / 100 = 9/50$。\n剪枝后节点$t$的风险是：\n$$R(t) = - \\left[ k_t \\ln(\\hat{p}_t) + (n_t - k_t) \\ln(1 - \\hat{p}_t) \\right]$$\n$$R(t) = - \\left[ 18 \\ln\\left(\\frac{18}{100}\\right) + (100 - 18) \\ln\\left(1 - \\frac{18}{100}\\right) \\right]$$\n$$R(t) = - \\left[ 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right]$$\n\n现在，我们可以计算$\\alpha_t$。叶节点数量的减少量为$|\\mathcal{L}(T_t)| - 1 = 3 - 1 = 2$。\n$$\\alpha_t = \\frac{R(t) - R(T_t)}{2} = \\frac{1}{2} \\big(R(t) - (R(\\ell_1) + R(\\ell_2) + R(\\ell_3))\\big)$$\n代入风险项的表达式：\n$$\\alpha_t = \\frac{1}{2} \\left( - \\left[ 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right] - \\left( - \\left[ 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right] - \\left[ 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right] - \\left[ 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right] \\right) \\right)$$\n简化符号后得到$\\alpha_t$的最终闭式表达式：\n$$\\alpha_t = \\frac{1}{2} \\left[ \\left( 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right) + \\left( 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right) + \\left( 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right) - \\left( 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right) \\right]$$\n该表达式即为所要求的$\\alpha_t$的精确解析值。",
            "answer": "$$\\boxed{\\frac{1}{2} \\left[ \\left( 5 \\ln\\left(\\frac{1}{10}\\right) + 45 \\ln\\left(\\frac{9}{10}\\right) \\right) + \\left( 9 \\ln\\left(\\frac{3}{10}\\right) + 21 \\ln\\left(\\frac{7}{10}\\right) \\right) + \\left( 4 \\ln\\left(\\frac{1}{5}\\right) + 16 \\ln\\left(\\frac{4}{5}\\right) \\right) - \\left( 18 \\ln\\left(\\frac{9}{50}\\right) + 82 \\ln\\left(\\frac{41}{50}\\right) \\right) \\right]}$$"
        },
        {
            "introduction": "在确定了剪枝路径后，我们需要根据给定的复杂度参数 $\\alpha$ 来决定是否执行剪枝。本练习提供了一个具体的计算场景，要求您应用成本复杂度准则来评估一次剪枝操作的净效果 。通过计算剪枝前后成本复杂度 $R_{\\alpha}(T)$ 的变化，您将学会如何量化决策，从而在模型的预测性能和简洁性之间做出明确的选择。",
            "id": "4615665",
            "problem": "考虑一个用于生物信息学和医学数据分析中的多分类决策树，它根据信使核糖核酸 (mRNA) 表达谱对急性白血病亚型进行分类。在一个内部节点 $\\tau$ 处，有一个小子树，它有 $3$ 个终端叶节点。这些叶节点总结了训练数据，其样本量 ($N_t$) 和三个亚型的类别比例 $(p_{t,1}, p_{t,2}, p_{t,3})$ 如下：\n- 叶节点 $\\mathcal{L}_1$：$N_{\\mathcal{L}_1} = 80$，$(0.55, 0.30, 0.15)$。\n- 叶节点 $\\mathcal{L}_2$：$N_{\\mathcal{L}_2} = 65$，$(0.20, 0.50, 0.30)$。\n- 叶节点 $\\mathcal{R}$：$N_{\\mathcal{R}} = 55$，$(0.60, 0.25, 0.15)$。\n\n假设采用分类与回归树 (CART) 框架，并使用代价复杂度剪枝。设叶节点 $t$ 的不纯度为基尼不纯度，定义为 $Q(t) = 1 - \\sum_{c=1}^{3} p_{t,c}^{2}$。对于一个具有终端叶节点集合 $\\mathcal{L}(T)$ 的树 $T$，其代价复杂度为\n$$\nR_{\\alpha}(T) = \\sum_{t \\in \\mathcal{L}(T)} N_{t} \\, Q(t) + \\alpha \\, |\\mathcal{L}(T)|,\n$$\n其中 $\\alpha$ 是一个非负惩罚参数， $|\\mathcal{L}(T)|$ 是终端叶节点的数量。假设我们考虑剪去以 $\\tau$ 为根的整个子树，并用一个单一叶节点替换它，该叶节点的类别比例等于当前子树中所有样本的聚合比例。设惩罚参数为 $\\alpha = 5$。\n\n计算在节点 $\\tau$ 处进行此剪枝决策所导致的代价复杂度变化量，\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前}),\n$$\n使用从给定叶节点计算出的聚合类别比例来评估剪枝后的单一叶节点不纯度。将您的最终数值答案四舍五入到四位有效数字。将最终答案表示为一个无量纲实数。",
            "solution": "该问题提法明确，科学上基于决策树算法（特别是 CART 框架）的原理，并为获得唯一解提供了所有必要信息。数据和定义是自洽且一致的。因此，我们开始进行计算。\n\n目标是计算剪枝一个子树所导致的代价复杂度变化量 $\\Delta R_{\\alpha}$。该变化量定义为：\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前})\n$$\n树 $T$ 的代价复杂度 $R_{\\alpha}(T)$ 由下式给出：\n$$\nR_{\\alpha}(T) = \\sum_{t \\in \\mathcal{L}(T)} N_{t} \\, Q(t) + \\alpha \\, |\\mathcal{L}(T)|\n$$\n其中 $N_t$ 是终端叶节点 $t$ 中的样本数量，$Q(t)$ 是该叶节点的基尼不纯度，$|\\mathcal{L}(T)|$ 是树中终端叶节点的数量，而 $\\alpha$ 是复杂度参数。对于一个有 $C$ 个类别的叶节点 $t$，其基尼不纯度为 $Q(t) = 1 - \\sum_{c=1}^{C} p_{t,c}^{2}$，其中 $p_{t,c}$ 是叶节点 $t$ 中类别 $c$ 的样本比例。在本问题中，我们有 $C=3$ 个类别。\n\n首先，我们计算剪枝前子树的代价复杂度，记为 $R_{\\alpha}(\\text{剪枝前})$。该子树有 $3$ 个终端叶节点：$\\mathcal{L}_1$、$\\mathcal{L}_2$ 和 $\\mathcal{R}$。因此，叶节点数量为 $|\\mathcal{L}(\\text{剪枝前})| = 3$。给定的惩罚参数为 $\\alpha = 5$。\n\n我们首先计算三个叶节点各自的基尼不纯度。\n对于叶节点 $\\mathcal{L}_1$，其类别比例为 $(0.55, 0.30, 0.15)$：\n$$\nQ(\\mathcal{L}_1) = 1 - (0.55^{2} + 0.30^{2} + 0.15^{2}) = 1 - (0.3025 + 0.09 + 0.0225) = 1 - 0.415 = 0.585\n$$\n对于叶节点 $\\mathcal{L}_2$，其类别比例为 $(0.20, 0.50, 0.30)$：\n$$\nQ(\\mathcal{L}_2) = 1 - (0.20^{2} + 0.50^{2} + 0.30^{2}) = 1 - (0.04 + 0.25 + 0.09) = 1 - 0.38 = 0.62\n$$\n对于叶节点 $\\mathcal{R}$，其类别比例为 $(0.60, 0.25, 0.15)$：\n$$\nQ(\\mathcal{R}) = 1 - (0.60^{2} + 0.25^{2} + 0.15^{2}) = 1 - (0.36 + 0.0625 + 0.0225) = 1 - 0.445 = 0.555\n$$\n接下来，我们计算剪枝前子树的总加权不纯度：\n$$\n\\sum_{t \\in \\{\\mathcal{L}_1, \\mathcal{L}_2, \\mathcal{R}\\}} N_t Q(t) = N_{\\mathcal{L}_1}Q(\\mathcal{L}_1) + N_{\\mathcal{L}_2}Q(\\mathcal{L}_2) + N_{\\mathcal{R}}Q(\\mathcal{R})\n$$\n使用给定的样本量 $N_{\\mathcal{L}_1} = 80$、$N_{\\mathcal{L}_2} = 65$ 和 $N_{\\mathcal{R}} = 55$：\n$$\n\\sum N_t Q(t) = 80(0.585) + 65(0.62) + 55(0.555) = 46.8 + 40.3 + 30.525 = 117.625\n$$\n剪枝前的代价复杂度为：\n$$\nR_{\\alpha}(\\text{剪枝前}) = 117.625 + \\alpha |\\mathcal{L}(\\text{剪枝前})| = 117.625 + 5 \\times 3 = 117.625 + 15 = 132.625\n$$\n\n其次，我们计算剪枝后的代价复杂度 $R_{\\alpha}(\\text{剪枝后})$。剪枝后，整个子树被一个我们称之为 $\\tau$ 的单一叶节点替换。因此，叶节点数量为 $|\\mathcal{L}(\\text{剪枝后})| = 1$。\n\n这个新叶节点 $\\tau$ 中的总样本数是其组成叶节点的样本数之和：\n$$\nN_{\\tau} = N_{\\mathcal{L}_1} + N_{\\mathcal{L}_2} + N_{\\mathcal{R}} = 80 + 65 + 55 = 200\n$$\n叶节点 $\\tau$ 的类别比例是聚合比例，计算方法是原始叶节点比例的加权平均，其中权重为样本量。对于每个类别 $c \\in \\{1, 2, 3\\}$：\n$$\np_{\\tau,c} = \\frac{N_{\\mathcal{L}_1} p_{\\mathcal{L}_1,c} + N_{\\mathcal{L}_2} p_{\\mathcal{L}_2,c} + N_{\\mathcal{R}} p_{\\mathcal{R},c}}{N_{\\tau}}\n$$\n$$\np_{\\tau,1} = \\frac{80(0.55) + 65(0.20) + 55(0.60)}{200} = \\frac{44 + 13 + 33}{200} = \\frac{90}{200} = 0.45\n$$\n$$\np_{\\tau,2} = \\frac{80(0.30) + 65(0.50) + 55(0.25)}{200} = \\frac{24 + 32.5 + 13.75}{200} = \\frac{70.25}{200} = 0.35125\n$$\n$$\np_{\\tau,3} = \\frac{80(0.15) + 65(0.30) + 55(0.15)}{200} = \\frac{12 + 19.5 + 8.25}{200} = \\frac{39.75}{200} = 0.19875\n$$\n新叶节点 $\\tau$ 的基尼不纯度为：\n$$\nQ(\\tau) = 1 - (p_{\\tau,1}^2 + p_{\\tau,2}^2 + p_{\\tau,3}^2) = 1 - (0.45^2 + 0.35125^2 + 0.19875^2)\n$$\n$$\nQ(\\tau) = 1 - (0.2025 + 0.1233765625 + 0.0395015625) = 1 - 0.365378125 = 0.634621875\n$$\n剪枝后的树（即单一叶节点 $\\tau$）的总加权不纯度为：\n$$\nN_{\\tau} Q(\\tau) = 200 \\times 0.634621875 = 126.924375\n$$\n剪枝后的代价复杂度为：\n$$\nR_{\\alpha}(\\text{剪枝后}) = N_{\\tau} Q(\\tau) + \\alpha |\\mathcal{L}(\\text{剪枝后})| = 126.924375 + 5 \\times 1 = 131.924375\n$$\n\n最后，我们计算代价复杂度的变化量：\n$$\n\\Delta R_{\\alpha} = R_{\\alpha}(\\text{剪枝后}) - R_{\\alpha}(\\text{剪枝前}) = 131.924375 - 132.625 = -0.700625\n$$\n题目要求答案四舍五入到四位有效数字。前四位有效数字是 $7, 0, 0, 6$。后一位数字是 $2$，所以我们舍去。\n$$\n\\Delta R_{\\alpha} \\approx -0.7006\n$$",
            "answer": "$$\\boxed{-0.7006}$$"
        },
        {
            "introduction": "在理论上，我们可以为树的每个节点计算出 $\\alpha$ 值，但在实践中，如何选择一个“最优”的 $\\alpha$ 以确保模型具有良好的泛化能力呢？本练习模拟了在生物信息学和临床数据分析中选择最优剪枝参数的典型工作流程 。您将运用K折交叉验证和“单标准误规则”，从一系列候选 $\\alpha$ 值中选出最佳参数，这对于构建既准确又不过拟合的预测模型至关重要。",
            "id": "4615670",
            "problem": "在一项结合电子健康记录 (EHR) 和全外显子组变异以预测$30$天再入院（$0$表示未再入院，$1$表示再入院）的临床基因组学研究中，训练了一个分类与回归树 (CART) 分类器，并使用成本复杂度剪枝法进行剪枝。成本复杂度剪枝参数表示为 $\\alpha \\geq 0$，增加 $\\alpha$ 会沿着一条嵌套的剪枝路径产生严格更简单的子树。为了估计泛化误差，使用 $K=10$ 进行 $K$ 折交叉验证 (CV)，并记录剪枝路径上每个 $\\alpha$ 对应的每折的误分类误差（以小数形式表示）。考虑了以下 $\\alpha$ 值及相应的子树大小（终端节点数）：\n- $\\alpha$：$0$、$0.005$、$0.01$、$0.02$、$0.03$、$0.05$。\n- 子树大小：$22$、$16$、$10$、$8$、$6$、$4$。\n\n对于每个 $\\alpha$，十折的误分类误差如下：\n- $\\alpha = 0$，子树大小 $22$：$(0.150,\\;0.130,\\;0.148,\\;0.132,\\;0.146,\\;0.134,\\;0.144,\\;0.136,\\;0.142,\\;0.138)$。\n- $\\alpha = 0.005$，子树大小 $16$：$(0.145,\\;0.125,\\;0.143,\\;0.127,\\;0.141,\\;0.129,\\;0.139,\\;0.131,\\;0.137,\\;0.133)$。\n- $\\alpha = 0.01$，子树大小 $10$：$(0.150,\\;0.118,\\;0.146,\\;0.122,\\;0.142,\\;0.126,\\;0.138,\\;0.130,\\;0.134,\\;0.134)$。\n- $\\alpha = 0.02$，子树大小 $8$：$(0.148,\\;0.126,\\;0.146,\\;0.128,\\;0.144,\\;0.130,\\;0.142,\\;0.132,\\;0.140,\\;0.134)$。\n- $\\alpha = 0.03$，子树大小 $6$：$(0.153,\\;0.129,\\;0.151,\\;0.131,\\;0.149,\\;0.133,\\;0.147,\\;0.135,\\;0.145,\\;0.137)$。\n- $\\alpha = 0.05$，子树大小 $4$：$(0.159,\\;0.129,\\;0.157,\\;0.131,\\;0.155,\\;0.133,\\;0.153,\\;0.135,\\;0.151,\\;0.137)$。\n\n从交叉验证误差估计和成本复杂度剪枝的基本定义出发，使用单一标准误规则选择剪枝参数 $\\alpha$ 并报告相应的子树大小。具体步骤如下：\n1. 对于每个 $\\alpha$，计算 $10$ 折的平均交叉验证误分类误差 $\\mu(\\alpha)$。\n2. 找出使 $\\mu(\\alpha)$ 最小化的 $\\alpha^{\\star}$，并计算 $\\mu(\\alpha^{\\star})$ 的标准误 $SE(\\alpha^{\\star}) = s(\\alpha^{\\star}) / \\sqrt{K}$，其中 $s(\\alpha^{\\star})$ 是在 $\\alpha^{\\star}$ 处各折误差的样本标准差，且 $K = 10$。\n3. 形成单一标准误阈值 $\\tau = \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$。\n4. 选择满足其平均误差 $\\mu(\\alpha)$ 小于或等于 $\\tau$ 的最大 $\\alpha$（即路径上最简单的子树）。\n将您的最终答案以包含所选 $\\alpha$ 和相应子树大小的行向量形式报告。请表示为精确值，无需四舍五入。最终答案中不应包含任何单位。",
            "solution": "问题要求使用单一标准误规则为 CART 分类器选择一个最优的成本复杂度剪枝参数 $\\alpha$ 及其对应的子树大小。该过程涉及分析为一组 $\\alpha$ 值提供的 $K$ 折交叉验证结果。此处 $K=10$。\n\n单一标准误规则是一种用于模型选择的启发式方法，旨在找到性能与表现最佳模型在统计上相当的最简单模型。步骤如下：\n\n1.  对于调优参数 $\\alpha$ 的每个值，计算平均交叉验证误分类误差 $\\mu(\\alpha)$。\n2.  找出导致最小平均交叉验证误差 $\\mu(\\alpha^{\\star})$ 的参数 $\\alpha^{\\star}$。\n3.  计算在 $\\alpha^{\\star}$ 处的平均误差的标准误，记为 $SE(\\alpha^{\\star})$。\n4.  找到平均误差在最小值的一个标准误范围内的最简单模型（在此情境下，即对应最大 $\\alpha$ 的模型）。也就是说，选择满足 $\\mu(\\alpha) \\leq \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$ 的最大 $\\alpha$。\n\n让我们用给定的数据执行这些步骤。\n\n**步骤 1：为每个 $\\alpha$ 计算平均交叉验证误差 $\\mu(\\alpha)$。**\n\n平均误差 $\\mu(\\alpha)$ 是每个 $\\alpha$ 对应的 $K=10$ 折的误分类误差的平均值。\n\n对于 $\\alpha = 0$：\n$\\mu(0) = \\frac{1}{10}(0.150+0.130+0.148+0.132+0.146+0.134+0.144+0.136+0.142+0.138) = \\frac{1.400}{10} = 0.140$\n\n对于 $\\alpha = 0.005$：\n$\\mu(0.005) = \\frac{1}{10}(0.145+0.125+0.143+0.127+0.141+0.129+0.139+0.131+0.137+0.133) = \\frac{1.350}{10} = 0.135$\n\n对于 $\\alpha = 0.01$：\n$\\mu(0.01) = \\frac{1}{10}(0.150+0.118+0.146+0.122+0.142+0.126+0.138+0.130+0.134+0.134) = \\frac{1.340}{10} = 0.134$\n\n对于 $\\alpha = 0.02$：\n$\\mu(0.02) = \\frac{1}{10}(0.148+0.126+0.146+0.128+0.144+0.130+0.142+0.132+0.140+0.134) = \\frac{1.370}{10} = 0.137$\n\n对于 $\\alpha = 0.03$：\n$\\mu(0.03) = \\frac{1}{10}(0.153+0.129+0.151+0.131+0.149+0.133+0.147+0.135+0.145+0.137) = \\frac{1.410}{10} = 0.141$\n\n对于 $\\alpha = 0.05$：\n$\\mu(0.05) = \\frac{1}{10}(0.159+0.129+0.157+0.131+0.155+0.133+0.153+0.135+0.151+0.137) = \\frac{1.480}{10} = 0.148$\n\n平均误差 $\\mu(\\alpha)$ 和子树大小 $|T_{\\alpha}|$ 的总结：\n- $\\alpha=0, |T_{\\alpha}|=22: \\mu(0) = 0.140$\n- $\\alpha=0.005, |T_{\\alpha}|=16: \\mu(0.005) = 0.135$\n- $\\alpha=0.01, |T_{\\alpha}|=10: \\mu(0.01) = 0.134$\n- $\\alpha=0.02, |T_{\\alpha}|=8: \\mu(0.02) = 0.137$\n- $\\alpha=0.03, |T_{\\alpha}|=6: \\mu(0.03) = 0.141$\n- $\\alpha=0.05, |T_{\\alpha}|=4: \\mu(0.05) = 0.148$\n\n**步骤 2：找出 $\\alpha^{\\star}$ 并计算 $SE(\\alpha^{\\star})$。**\n\n最小平均误差为 $\\mu_{\\min} = 0.134$，出现在 $\\alpha = 0.01$ 处。因此，$\\alpha^{\\star} = 0.01$。\n\n接下来，我们计算此 $\\alpha^{\\star}$ 对应的平均值的标准误。标准误由 $SE(\\alpha^{\\star}) = \\frac{s(\\alpha^{\\star})}{\\sqrt{K}}$ 给出，其中 $s(\\alpha^{\\star})$ 是 $\\alpha^{\\star}$ 对应的各折误差的样本标准差。样本方差 $s^2(\\alpha^{\\star})$ 计算如下：\n$$s^2(\\alpha^{\\star}) = \\frac{1}{K-1} \\sum_{k=1}^{K} (e_k - \\mu(\\alpha^{\\star}))^2$$\n对于 $\\alpha^{\\star}=0.01$，误差为 $e_k = (0.150, 0.118, 0.146, 0.122, 0.142, 0.126, 0.138, 0.130, 0.134, 0.134)$，均值为 $\\mu(0.01) = 0.134$。折数为 $K=10$。\n\n与均值的偏差 $(e_k - \\mu)$ 为：\n$(0.016, -0.016, 0.012, -0.012, 0.008, -0.008, 0.004, -0.004, 0, 0)$。\n\n偏差平方和为：\n$\\sum (e_k - \\mu)^2 = (0.016)^2 + (-0.016)^2 + (0.012)^2 + (-0.012)^2 + (0.008)^2 + (-0.008)^2 + (0.004)^2 + (-0.004)^2 + 0^2 + 0^2$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ (0.016)^2 + (0.012)^2 + (0.008)^2 + (0.004)^2 ]$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ 0.000256 + 0.000144 + 0.000064 + 0.000016 ]$\n$\\sum (e_k - \\mu)^2 = 2 \\times [ 0.000480 ] = 0.00096$\n\n样本方差为：\n$s^2(0.01) = \\frac{0.00096}{10-1} = \\frac{0.00096}{9}$\n\n平均值的标准误为：\n$SE(0.01) = \\sqrt{\\frac{s^2(0.01)}{K}} = \\sqrt{\\frac{0.00096/9}{10}} = \\sqrt{\\frac{0.00096}{90}} \\approx 0.003266$\n\n**步骤 3：形成单一标准误阈值 $\\tau$。**\n\n阈值为 $\\tau = \\mu(\\alpha^{\\star}) + SE(\\alpha^{\\star})$。\n$\\tau \\approx 0.134 + 0.003266 = 0.137266$。\n\n**步骤 4：选择满足 $\\mu(\\alpha) \\leq \\tau$ 的最大 $\\alpha$。**\n\n我们将每个 $\\mu(\\alpha)$ 与阈值 $\\tau \\approx 0.137266$ 进行比较。\n\n- $\\mu(0) = 0.140 > \\tau$\n- $\\mu(0.005) = 0.135 \\leq \\tau$\n- $\\mu(0.01) = 0.134 \\leq \\tau$\n- $\\mu(0.02) = 0.137 \\leq \\tau$\n- $\\mu(0.03) = 0.141 > \\tau$\n- $\\mu(0.05) = 0.148 > \\tau$\n\n满足条件 $\\mu(\\alpha) \\leq \\tau$ 的 $\\alpha$ 值为 $0.005$、$0.01$ 和 $0.02$。规则是从这个集合中选择最大的 $\\alpha$，它对应于最简单（剪枝最多）的模型。最大的 $\\alpha$ 是 $0.02$。\n\n对应于 $\\alpha = 0.02$ 的子树大小为 $8$。\n\n因此，选择的参数是 $\\alpha=0.02$，相应的子树大小是 $8$。最终答案应以行向量形式报告。",
            "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.02  8\n\\end{pmatrix}\n}\n$$"
        }
    ]
}