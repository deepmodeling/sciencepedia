{
    "hands_on_practices": [
        {
            "introduction": "在医学诊断中，评估一种生物标志物（biomarker）区分患病与健康人群的能力是一项核心任务。本练习  将引导您从最基本的概率密度函数和贝叶斯法则出发，完整推导受试者工作特征（ROC）曲线及其曲线下面积（AUC）—— 这是评估分类器性能的两个黄金标准。通过假设数据服从正态分布这一理想化场景，我们可以得到一个优美的解析解，从而深刻理解模型参数（如均值和方差）如何直接影响生物标志物的诊断效能。",
            "id": "4598803",
            "problem": "在一个临床队列中测量了一个连续的标量生物标志物 $X$，二元疾病状态 $Y \\in \\{0,1\\}$ 表示 $Y=1$ 为患病，$Y=0$ 为未患病。假设类条件正态分布：$X \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^{2})$，其中 $\\mu_{1} > \\mu_{0}$ 且 $\\sigma_{0} > 0$, $\\sigma_{1} > 0$。令 $\\pi \\in (0,1)$ 表示患病率 $P(Y=1)$， $1-\\pi$ 表示 $P(Y=0)$。令 $f_{k}(x)$ 表示 $X \\mid Y=k$ 的概率密度函数，其中 $k \\in \\{0,1\\}$。受试者工作特征（ROC）曲线是为阈值决策规则 $\\delta_{t}(x) = \\mathbf{1}\\{x \\ge t\\}$ 定义的，其假阳性率 $u(t) = P(X \\ge t \\mid Y=0)$ 和真阳性率 $v(t) = P(X \\ge t \\mid Y=1)$，其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。曲线下面积（AUC）定义为 ROC 曲线在 $0$ 到 $1$ 之间的积分。\n\n仅从正态密度、似然比、贝叶斯法则以及假阳性率和真阳性率的基本定义出发，进行以下推导：\n\n1. 推导明确的似然比 $L(x) = \\frac{f_{1}(x)}{f_{0}(x)}$。\n2. 使用贝叶斯法则，将后验比率 $\\frac{P(Y=1 \\mid X=x)}{P(Y=0 \\mid X=x)}$ 表示为先验比率 $\\frac{\\pi}{1-\\pi}$ 和似然比 $L(x)$ 的函数。\n3. 对于阈值规则 $\\delta_{t}(x)$，推导 $u(t)$ 和 $v(t)$，用 $\\mu_{0}$、$\\mu_{1}$、$\\sigma_{0}$、$\\sigma_{1}$ 和标准正态累积分布函数 $\\Phi(\\cdot)$ 表示。\n4. 消去阈值 $t$，得到 ROC 曲线 $v$ 作为 $u \\in [0,1]$ 的函数的闭式表达式，用 $\\mu_{0}$、$\\mu_{1}$、$\\sigma_{0}$、$\\sigma_{1}$ 和标准正态累积分布函数的反函数 $\\Phi^{-1}(\\cdot)$ 表示。\n5. 通过对 ROC 曲线在 $u \\in [0,1]$ 上积分来解析计算 AUC，并将结果简化为用 $\\mu_{0}$、$\\mu_{1}$、$\\sigma_{0}$、$\\sigma_{1}$ 表示的闭式表达式。\n\n将最终答案表示为单一的闭式解析表达式。不需要数值近似。",
            "solution": "该问题是有效的，因为它在科学上基于标准统计理论，问题陈述清晰且提供了所有必要信息，并且表述客观。我们按要求进行推导。\n\n正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 的概率密度函数 (PDF) 的基本定义由下式给出：\n$$f(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n给定类条件分布 $X \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$ 和 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^{2})$，各自的 PDF 分别为：\n$$f_{0}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_{0}^2}} \\exp\\left(-\\frac{(x-\\mu_{0})^2}{2\\sigma_{0}^2}\\right)$$\n$$f_{1}(x) = \\frac{1}{\\sqrt{2\\pi\\sigma_{1}^2}} \\exp\\left(-\\frac{(x-\\mu_{1})^2}{2\\sigma_{1}^2}\\right)$$\n\n**1. 似然比 $L(x)$ 的推导**\n\n似然比 $L(x)$ 定义为类条件 PDF 的比率，即 $L(x) = \\frac{f_{1}(x)}{f_{0}(x)}$。\n$$L(x) = \\frac{\\frac{1}{\\sqrt{2\\pi\\sigma_{1}^2}} \\exp\\left(-\\frac{(x-\\mu_{1})^2}{2\\sigma_{1}^2}\\right)}{\\frac{1}{\\sqrt{2\\pi\\sigma_{0}^2}} \\exp\\left(-\\frac{(x-\\mu_{0})^2}{2\\sigma_{0}^2}\\right)}$$\n这可以简化为：\n$$L(x) = \\frac{\\sigma_{0}}{\\sigma_{1}} \\exp\\left(-\\frac{(x-\\mu_{1})^2}{2\\sigma_{1}^2} + \\frac{(x-\\mu_{0})^2}{2\\sigma_{0}^2}\\right)$$\n指数中的表达式可以展开和重新整理，但此形式对于定义来说已经足够。\n\n**2. 后验比率的推导**\n\n贝叶斯法则指出，在给定观测值 $x$ 的情况下，类别 $k$ 的后验概率为：\n$$P(Y=k \\mid X=x) = \\frac{P(X=x \\mid Y=k) P(Y=k)}{P(X=x)}$$\n使用所给符号，即：\n$$P(Y=k \\mid X=x) = \\frac{f_{k}(x) P(Y=k)}{\\sum_{j=0}^{1} f_{j}(x) P(Y=j)}$$\n后验比率是 $Y=1$ 和 $Y=0$ 的后验概率之比：\n$$\\frac{P(Y=1 \\mid X=x)}{P(Y=0 \\mid X=x)} = \\frac{\\frac{f_{1}(x) P(Y=1)}{P(X=x)}}{\\frac{f_{0}(x) P(Y=0)}{P(X=x)}}$$\n公分母 $P(X=x)$ 被消去：\n$$\\frac{P(Y=1 \\mid X=x)}{P(Y=0 \\mid X=x)} = \\frac{f_{1}(x)}{f_{0}(x)} \\cdot \\frac{P(Y=1)}{P(Y=0)}$$\n先验概率给定为 $P(Y=1) = \\pi$ 和 $P(Y=0) = 1-\\pi$。比率 $\\frac{\\pi}{1-\\pi}$ 是先验比率。比率 $\\frac{f_{1}(x)}{f_{0}(x)}$ 是似然比 $L(x)$。因此，我们有以下关系：\n$$\\frac{P(Y=1 \\mid X=x)}{P(Y=0 \\mid X=x)} = L(x) \\cdot \\frac{\\pi}{1-\\pi}$$\n这表明后验比率是似然比与先验比率的乘积。\n\n**3. 假阳性率 $u(t)$ 和真阳性率 $v(t)$ 的推导**\n\n假阳性率 (FPR) 是 $u(t) = P(X \\ge t \\mid Y=0)$。由于 $X \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0}, \\sigma_{0}^{2})$，我们可以对变量进行标准化。令 $Z = \\frac{X-\\mu_{0}}{\\sigma_{0}}$，其中 $Z \\sim \\mathcal{N}(0,1)$。\n$$u(t) = P\\left(\\frac{X-\\mu_{0}}{\\sigma_{0}} \\ge \\frac{t-\\mu_{0}}{\\sigma_{0}} \\mid Y=0\\right) = P\\left(Z \\ge \\frac{t-\\mu_{0}}{\\sigma_{0}}\\right)$$\n用标准正态累积分布函数 $\\Phi(z) = P(Z \\le z)$ 表示，我们有 $P(Z \\ge z) = 1 - P(Z  z) = 1 - \\Phi(z)$。因此：\n$$u(t) = 1 - \\Phi\\left(\\frac{t-\\mu_{0}}{\\sigma_{0}}\\right)$$\n类似地，真阳性率 (TPR) 是 $v(t) = P(X \\ge t \\mid Y=1)$。由于 $X \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1}, \\sigma_{1}^{2})$，我们对这些参数进行标准化。令 $Z' = \\frac{X-\\mu_{1}}{\\sigma_{1}}$，其中 $Z' \\sim \\mathcal{N}(0,1)$。\n$$v(t) = P\\left(\\frac{X-\\mu_{1}}{\\sigma_{1}} \\ge \\frac{t-\\mu_{1}}{\\sigma_{1}} \\mid Y=1\\right) = P\\left(Z' \\ge \\frac{t-\\mu_{1}}{\\sigma_{1}}\\right)$$\n$$v(t) = 1 - \\Phi\\left(\\frac{t-\\mu_{1}}{\\sigma_{1}}\\right)$$\n\n**4. ROC 曲线 $v(u)$ 的推导**\n\nROC 曲线由阈值 $t$ 参数化。为了找到 $v$ 和 $u$ 之间的关系，我们必须消去 $t$。从 $u(t)$ 的表达式：\n$$u = 1 - \\Phi\\left(\\frac{t-\\mu_{0}}{\\sigma_{0}}\\right) \\implies \\Phi\\left(\\frac{t-\\mu_{0}}{\\sigma_{0}}\\right) = 1-u$$\n对两边应用标准正态累积分布函数的反函数 $\\Phi^{-1}(\\cdot)$：\n$$\\frac{t-\\mu_{0}}{\\sigma_{0}} = \\Phi^{-1}(1-u)$$\n使用标准正态分布的对称性质，$\\Phi^{-1}(1-u) = -\\Phi^{-1}(u)$：\n$$\\frac{t-\\mu_{0}}{\\sigma_{0}} = -\\Phi^{-1}(u) \\implies t = \\mu_{0} - \\sigma_{0}\\Phi^{-1}(u)$$\n现在，我们将 $t$ 的这个表达式代入 $v(t)$ 的方程中：\n$$v(u) = 1 - \\Phi\\left(\\frac{(\\mu_{0} - \\sigma_{0}\\Phi^{-1}(u)) - \\mu_{1}}{\\sigma_{1}}\\right)$$\n重新整理 $\\Phi$ 函数内部的项，得到 ROC 曲线的闭式表达式：\n$$v(u) = 1 - \\Phi\\left(\\frac{\\mu_{0}-\\mu_{1}}{\\sigma_{1}} - \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right)$$\n\n**5. AUC 的解析计算**\n\n曲线下面积 (AUC) 是 ROC 曲线 $v(u)$ 关于 $u$ 从 $0$ 到 $1$ 的积分：\n$$AUC = \\int_{0}^{1} v(u) \\, du = \\int_{0}^{1} \\left[1 - \\Phi\\left(\\frac{\\mu_{0}-\\mu_{1}}{\\sigma_{1}} - \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right)\\right] du$$\n使用对称性质 $\\Phi(-z) = 1-\\Phi(z)$，我们可以写出：\n$$1 - \\Phi\\left(\\frac{\\mu_{0}-\\mu_{1}}{\\sigma_{1}} - \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right) = \\Phi\\left(-\\left(\\frac{\\mu_{0}-\\mu_{1}}{\\sigma_{1}} - \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right)\\right) = \\Phi\\left(\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}} + \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right)$$\n所以积分变为：\n$$AUC = \\int_{0}^{1} \\Phi\\left(\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}} + \\frac{\\sigma_{0}}{\\sigma_{1}}\\Phi^{-1}(u)\\right) du$$\n为了解这个积分，我们进行变量替换。令 $z = \\Phi^{-1}(u)$。这意味着 $u = \\Phi(z)$，且微分为 $du = \\phi(z)dz$，其中 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\exp(-z^2/2)$ 是标准正态 PDF。积分限变化如下：当 $u \\to 0$ 时，$z \\to -\\infty$；当 $u \\to 1$ 时，$z \\to \\infty$。\n$$AUC = \\int_{-\\infty}^{\\infty} \\Phi\\left(\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}} + \\frac{\\sigma_{0}}{\\sigma_{1}}z\\right) \\phi(z) dz$$\n这个积分的形式为 $\\int_{-\\infty}^{\\infty} \\Phi(a+bz)\\phi(z)dz$，其中 $a = \\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}}$ 和 $b = \\frac{\\sigma_{0}}{\\sigma_{1}}$。此积分的计算结果为 $\\Phi\\left(\\frac{a}{\\sqrt{1+b^2}}\\right)$。让我们正式证明这一点。考虑两个独立的标准正态随机变量 $Z_{1}$ 和 $Z_{2}$。该积分表示概率 $P(Z_{2} \\le a+bZ_{1})$。我们定义一个新的随机变量 $W = Z_{2} - bZ_{1}$。作为独立正态变量的线性组合，$W$ 也服从正态分布。\n$$E[W] = E[Z_{2}] - bE[Z_{1}] = 0 - b \\cdot 0 = 0$$\n$$Var(W) = Var(Z_{2}) + (-b)^2Var(Z_{1}) = 1 + b^2 \\cdot 1 = 1+b^2$$\n所以，$W \\sim \\mathcal{N}(0, 1+b^2)$。概率 $P(Z_{2} \\le a+bZ_{1})$ 等价于 $P(W \\le a)$。\n$$P(W \\le a) = P\\left(\\frac{W - 0}{\\sqrt{1+b^2}} \\le \\frac{a - 0}{\\sqrt{1+b^2}}\\right)$$\n左边的项是一个标准正态变量，所以：\n$$P(W \\le a) = \\Phi\\left(\\frac{a}{\\sqrt{1+b^2}}\\right)$$\n将此结果应用于我们的 AUC 积分：\n$$AUC = \\Phi\\left( \\frac{\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}}}{\\sqrt{1 + \\left(\\frac{\\sigma_{0}}{\\sigma_{1}}\\right)^2}} \\right)$$\n现在，我们简化 $\\Phi$ 的参数：\n$$\\frac{\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}}}{\\sqrt{1 + \\frac{\\sigma_{0}^2}{\\sigma_{1}^2}}} = \\frac{\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}}}{\\sqrt{\\frac{\\sigma_{1}^2 + \\sigma_{0}^2}{\\sigma_{1}^2}}} = \\frac{\\frac{\\mu_{1}-\\mu_{0}}{\\sigma_{1}}}{\\frac{\\sqrt{\\sigma_{0}^2 + \\sigma_{1}^2}}{\\sigma_{1}}}$$\n由于 $\\sigma_{1}  0$，这可以简化为：\n$$\\frac{\\mu_{1}-\\mu_{0}}{\\sqrt{\\sigma_{0}^2 + \\sigma_{1}^2}}$$\n因此，AUC 的最终解析表达式为：\n$$AUC = \\Phi\\left(\\frac{\\mu_{1}-\\mu_{0}}{\\sqrt{\\sigma_{0}^2 + \\sigma_{1}^2}}\\right)$$",
            "answer": "$$\\boxed{\\Phi\\left(\\frac{\\mu_{1}-\\mu_{0}}{\\sqrt{\\sigma_{0}^{2}+\\sigma_{1}^{2}}}\\right)}$$"
        },
        {
            "introduction": "贝叶斯分层模型是现代生物信息学中处理复杂数据集的强大工具，它能够“借力”于样本间的共性信息，并对不确定性进行精确量化。本练习  将带您亲手推导吉布斯采样器（Gibbs sampler）的关键组件，这是一种用于拟合贝叶斯模型的经典算法。您将接触到两个生物信息学中的典型模型：用于处理过度离散计数数据（如变异读取数）的Beta-二项分布模型，以及用于分析定量数据（如qPCR表达量）且均值和方差均未知的正态模型。",
            "id": "4598789",
            "problem": "一个临床生物信息学小组正在使用概率层次模型对分子检测流程的两个独立组件进行建模，以量化不确定性并将其传播到下游的医疗决策中。\n\nA部分（Beta-二项过离散变异计数）。对于由 $i \\in \\{1,\\dots,I\\}$ 索引的 $I$ 个独立样本，令 $X_i$ 表示在样本 $i$ 中，于一个预先指定的位点上，从 $M_i$ 个总读数中观测到的支持某个变异的测序读数数量。为了捕捉真实变异流行率在样本间的异质性，假设以下层次模型：对于每个 $i$，给定一个潜在流行率参数 $\\theta_i \\in (0,1)$，$X_i \\mid \\theta_i \\sim \\mathrm{Binomial}(M_i,\\theta_i)$，并且 $\\theta_i \\sim \\mathrm{Beta}(\\alpha,\\beta)$，其中固定的已知超参数 $\\alpha  0$ 和 $\\beta  0$。在一项包含 $I=5$ 个样本的研究中，实现的数据为 $(X_1,M_1)=(27,50)$、$(X_2,M_2)=(45,80)$、$(X_3,M_3)=(38,60)$、$(X_4,M_4)=(22,40)$ 和 $(X_5,M_5)=(40,75)$，超参数为 $(\\alpha,\\beta)=(2.5,3.5)$。\n\n任务A。从贝叶斯法则以及Beta分布和二项分布的概率密度函数出发，推导每个 $\\theta_i$ 在给定所有其他未知量和所有数据的情况下的全条件分布，并证明该条件分布是共轭的。然后，使用这些全条件分布来指定一个有效的吉布斯抽样方案，该方案以所述模型下 $(\\theta_1,\\dots,\\theta_I)$ 的联合后验为目标。将吉布斯采样器呈现为一系列条件抽样，每个抽样都由一个命名的分布及其参数指定，参数以 $(\\alpha,\\beta)$ 和观测到的 $(X_i,M_i)$ 表示。\n\nB部分（用于定量聚合酶链式反应（qPCR）对数表达量的方差未知的正态-正态模型）。对于在固定条件下对 $n$ 个技术重复进行定量聚合酶链式反应（qPCR）测量的单个基因，令 $y_1,\\dots,y_n$ 表示对数尺度上的表达测量值。假设抽样模型为 $y_i \\mid \\mu,\\sigma^2 \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu,\\sigma^2)$，对于所有 $i \\in \\{1,\\dots,n\\}$，其中 $\\mu$ 和 $\\sigma^2$ 均为未知。设置共轭的正态-逆伽马先验\n- $\\mu \\mid \\sigma^2 \\sim \\mathcal{N}(m_0,\\sigma^2/\\kappa_0)$，其中 $m_0 \\in \\mathbb{R}$ 且 $\\kappa_0  0$，\n- $\\sigma^2 \\sim \\mathrm{Inverse-Gamma}(a_0,b_0)$，其中形状参数 $a_00$，尺度参数 $b_00$，密度函数为 $p(\\sigma^2) = \\dfrac{b_0^{a_0}}{\\Gamma(a_0)} (\\sigma^2)^{-a_0-1} \\exp\\!\\big(-b_0/\\sigma^2\\big)$，对于 $\\sigma^20$。\n\n在一个有 $n=6$ 个重复的实验中，实现的数据为 $y=(1.2,\\,0.9,\\,1.5,\\,1.1,\\,1.3,\\,0.8)$，先验超参数为 $(m_0,\\kappa_0,a_0,b_0)=(1.0,\\,2.0,\\,3.0,\\,0.5)$。\n\n任务B。从贝叶斯法则以及正态分布和逆伽马分布的概率密度函数出发，推导全条件分布 $p(\\mu \\mid \\sigma^2,y)$ 和 $p(\\sigma^2 \\mid \\mu,y)$，并展示一个交替从这两个条件分布中抽样的吉布斯抽样方案。然后，通过解析积分消去参数，得到闭合形式的后验超参数，并计算在所述先验和数据下的后验均值 $\\mathbb{E}[\\sigma^2 \\mid y]$。将您计算的 $\\mathbb{E}[\\sigma^2 \\mid y]$ 的数值答案四舍五入到四位有效数字。最终答案必须是这个经过四舍五入的单一数字，不带单位。",
            "solution": "该问题提出了贝叶斯层次建模中的两个独立任务，这两个任务在生物信息学和医学数据分析的背景下都是标准的且定义明确的。模型、数据和任务在科学上是合理的，在数学上是一致的，并包含了完整解答所需的所有信息。因此，该问题被认为是有效的。\n\nA部分：Beta-二项模型\n\n该模型是为 $I$ 个独立样本定义的。对于每个样本 $i \\in \\{1, \\dots, I\\}$：\n观测到的变异计数 $X_i$（总读数为 $M_i$）的似然由一个二项分布给出，条件是潜在流行率参数 $\\theta_i$：\n$$X_i \\mid \\theta_i \\sim \\mathrm{Binomial}(M_i, \\theta_i)$$\n潜在流行率 $\\theta_i$ 的先验分布是一个Beta分布：\n$$\\theta_i \\sim \\mathrm{Beta}(\\alpha, \\beta)$$\n样本是独立的，这意味着 $\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_I)$ 的联合先验是 $p(\\boldsymbol{\\theta}) = \\prod_{i=1}^I p(\\theta_i)$，而给定 $\\boldsymbol{\\theta}$ 时 $\\mathbf{X} = (X_1, \\dots, X_I)$ 的联合似然是 $p(\\mathbf{X} \\mid \\boldsymbol{\\theta}, \\mathbf{M}) = \\prod_{i=1}^I p(X_i \\mid \\theta_i, M_i)$。\n\n任务是找到每个 $\\theta_i$ 的全条件分布，即给定所有其他参数和所有数据下 $\\theta_i$ 的分布，表示为 $p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M})$，其中 $\\boldsymbol{\\theta}_{-i} = (\\theta_1, \\dots, \\theta_{i-1}, \\theta_{i+1}, \\dots, \\theta_I)$。\n\n根据贝叶斯法则，全条件分布与所有变量的联合分布成正比：\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(\\boldsymbol{\\theta}, \\mathbf{X} \\mid \\mathbf{M})$$\n联合分布由似然和先验的乘积给出：\n$$p(\\boldsymbol{\\theta}, \\mathbf{X} \\mid \\mathbf{M}) = p(\\mathbf{X} \\mid \\boldsymbol{\\theta}, \\mathbf{M}) p(\\boldsymbol{\\theta}) = \\left( \\prod_{j=1}^I p(X_j \\mid \\theta_j, M_j) \\right) \\left( \\prod_{j=1}^I p(\\theta_j \\mid \\alpha, \\beta) \\right)$$\n要找到 $\\theta_i$ 的全条件分布，我们可以将所有不依赖于 $\\theta_i$ 的项视为比例常数的一部分：\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(X_i \\mid \\theta_i, M_i) p(\\theta_i \\mid \\alpha, \\beta) \\times \\left( \\prod_{j \\neq i} p(X_j \\mid \\theta_j, M_j) p(\\theta_j \\mid \\alpha, \\beta) \\right)$$\n$$p(\\theta_i \\mid \\boldsymbol{\\theta}_{-i}, \\mathbf{X}, \\mathbf{M}) \\propto p(X_i \\mid \\theta_i, M_i) p(\\theta_i \\mid \\alpha, \\beta)$$\n这种简化源于模型的条件独立结构：给定 $\\theta_i$，$X_i$ 与所有其他的 $X_j$ 和 $\\theta_j$（对于 $j \\neq i$）是独立的，并且 $\\theta_i$ 上的先验是独立的。因此，$\\theta_i$ 的全条件分布仅取决于其对应的数据 $(X_i, M_i)$ 及其先验超参数 $(\\alpha, \\beta)$。\n\n二项似然的概率质量函数为 $p(X_i \\mid \\theta_i, M_i) = \\binom{M_i}{X_i} \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i}$。作为 $\\theta_i$ 的函数，它与以下项成正比：\n$$p(X_i \\mid \\theta_i, M_i) \\propto \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i}$$\nBeta先验的概率密度函数为 $p(\\theta_i \\mid \\alpha, \\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1}$。作为 $\\theta_i$ 的函数，它与以下项成正比：\n$$p(\\theta_i \\mid \\alpha, \\beta) \\propto \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1}$$\n将似然核与先验核相乘：\n$$p(\\theta_i \\mid X_i, M_i, \\alpha, \\beta) \\propto \\left( \\theta_i^{X_i} (1-\\theta_i)^{M_i-X_i} \\right) \\times \\left( \\theta_i^{\\alpha-1} (1-\\theta_i)^{\\beta-1} \\right)$$\n$$p(\\theta_i \\mid X_i, M_i, \\alpha, \\beta) \\propto \\theta_i^{X_i + \\alpha - 1} (1-\\theta_i)^{M_i - X_i + \\beta - 1}$$\n这是一个具有更新参数的Beta分布的核。具体来说，$\\theta_i$ 的全条件分布（在这种情况下是边际后验分布）是：\n$$\\theta_i \\mid X_i, M_i, \\alpha, \\beta \\sim \\mathrm{Beta}(X_i + \\alpha, M_i - X_i + \\beta)$$\n由于后验分布（Beta）与先验分布（Beta）属于同一族，因此Beta先验是二项似然的共轭先验。这一点已经通过推导得到证明。\n\n针对联合后验 $p(\\boldsymbol{\\theta} \\mid \\mathbf{X}, \\mathbf{M})$ 的吉布斯抽样方案涉及从每个参数的全条件分布中迭代抽样。由于每个 $\\theta_i$ 的全条件分布与所有其他的 $\\theta_j$（对于 $j \\neq i$）独立，因此吉布斯采样器特别简单。在每次迭代中，我们可以并行或顺序地抽取所有的 $\\theta_i$ 值。一个有效的方案如下：\n\n初始化 $\\boldsymbol{\\theta}^{(0)} = (\\theta_1^{(0)}, \\dots, \\theta_I^{(0)})$。对于迭代 $t=1, 2, \\dots$：\n1. 抽取 $\\theta_1^{(t)} \\sim \\mathrm{Beta}(X_1 + \\alpha, M_1 - X_1 + \\beta)$\n2. 抽取 $\\theta_2^{(t)} \\sim \\mathrm{Beta}(X_2 + \\alpha, M_2 - X_2 + \\beta)$\n3. $\\dots$\n4. 抽取 $\\theta_I^{(t)} \\sim \\mathrm{Beta}(X_I + \\alpha, M_I - X_I + \\beta)$\n\n使用给定的数据和超参数 $(X_i, M_i)$ 和 $(\\alpha, \\beta)=(2.5, 3.5)$：\n\\begin{itemize}\n    \\item 抽取 $\\theta_1 \\mid \\text{data} \\sim \\mathrm{Beta}(27 + 2.5, 50 - 27 + 3.5) = \\mathrm{Beta}(29.5, 26.5)$\n    \\item 抽取 $\\theta_2 \\mid \\text{data} \\sim \\mathrm{Beta}(45 + 2.5, 80 - 45 + 3.5) = \\mathrm{Beta}(47.5, 38.5)$\n    \\item 抽取 $\\theta_3 \\mid \\text{data} \\sim \\mathrm{Beta}(38 + 2.5, 60 - 38 + 3.5) = \\mathrm{Beta}(40.5, 25.5)$\n    \\item 抽取 $\\theta_4 \\mid \\text{data} \\sim \\mathrm{Beta}(22 + 2.5, 40 - 22 + 3.5) = \\mathrm{Beta}(24.5, 21.5)$\n    \\item 抽取 $\\theta_5 \\mid \\text{data} \\sim \\mathrm{Beta}(40 + 2.5, 75 - 40 + 3.5) = \\mathrm{Beta}(42.5, 38.5)$\n\\end{itemize}\n\nB部分：方差未知的正态-正态模型\n\n对于 $n$ 个对数表达测量值 $y=(y_1, \\dots, y_n)$ 的模型是：\n似然：$y_i \\mid \\mu, \\sigma^2 \\overset{\\mathrm{iid}}{\\sim} \\mathcal{N}(\\mu, \\sigma^2)$\n先验：$p(\\mu, \\sigma^2) = p(\\mu \\mid \\sigma^2) p(\\sigma^2)$，其中\n    $\\mu \\mid \\sigma^2 \\sim \\mathcal{N}(m_0, \\sigma^2/\\kappa_0)$\n    $\\sigma^2 \\sim \\mathrm{Inverse-Gamma}(a_0, b_0)$\n\n任务B涉及推导全条件分布，指定吉布斯采样器，并计算 $\\sigma^2$ 的后验均值。\n\n$\\mu$ 的全条件分布的推导：\n$p(\\mu \\mid \\sigma^2, y) \\propto p(y \\mid \\mu, \\sigma^2) p(\\mu \\mid \\sigma^2)$。\n似然核为 $p(y \\mid \\mu, \\sigma^2) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2\\right)$。\n先验核为 $p(\\mu \\mid \\sigma^2) \\propto \\exp\\left(-\\frac{1}{2(\\sigma^2/\\kappa_0)} (\\mu - m_0)^2\\right) = \\exp\\left(-\\frac{\\kappa_0}{2\\sigma^2} (\\mu - m_0)^2\\right)$。\n$\\mu$ 的后验核与乘积成正比，因此我们对指数中的项求和：\n$p(\\mu \\mid \\sigma^2, y) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\left[ \\sum_{i=1}^n (y_i - \\mu)^2 + \\kappa_0(\\mu - m_0)^2 \\right] \\right)$。\n方括号中的项是关于 $\\mu$ 的二次式：\n$\\sum(y_i^2 - 2y_i\\mu + \\mu^2) + \\kappa_0(\\mu^2 - 2\\mu m_0 + m_0^2) = (n+\\kappa_0)\\mu^2 - 2(n\\bar{y} + \\kappa_0 m_0)\\mu + C$，其中 C 不依赖于 $\\mu$。\n对 $\\mu$ 进行配方，该表达式揭示了一个正态分布的核。后验分布是 $\\mu \\mid \\sigma^2, y \\sim \\mathcal{N}(m_n, \\sigma^2/\\kappa_n)$，参数为：\n$\\kappa_n = \\kappa_0 + n$\n$m_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}$\n\n$\\sigma^2$ 的全条件分布的推导：\n$p(\\sigma^2 \\mid \\mu, y) \\propto p(y, \\mu, \\sigma^2) = p(y \\mid \\mu, \\sigma^2)p(\\mu \\mid \\sigma^2)p(\\sigma^2)$。\n我们收集所有涉及 $\\sigma^2$ 的项：\n$p(y \\mid \\mu, \\sigma^2) \\propto (\\sigma^2)^{-n/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum (y_i - \\mu)^2\\right)$\n$p(\\mu \\mid \\sigma^2) \\propto (\\sigma^2)^{-1/2} \\exp\\left(-\\frac{\\kappa_0}{2\\sigma^2} (\\mu-m_0)^2\\right)$\n$p(\\sigma^2) \\propto (\\sigma^2)^{-a_0-1} \\exp\\left(-\\frac{b_0}{\\sigma^2}\\right)$\n将这些相乘得到：\n$p(\\sigma^2 \\mid \\mu, y) \\propto (\\sigma^2)^{-(a_0 + n/2 + 1/2) - 1} \\exp\\left( -\\frac{1}{\\sigma^2} \\left[ b_0 + \\frac{1}{2}\\sum (y_i - \\mu)^2 + \\frac{\\kappa_0}{2}(\\mu - m_0)^2 \\right] \\right)$。\n这是一个逆伽马分布 $\\mathrm{IG}(a_n, b_n(\\mu))$ 的核，其参数为：\n$a_n = a_0 + \\frac{n+1}{2}$ （注意：某些约定可能不同，但对于指定的联合先验，此形式是正确的。然而，$\\sigma^2$ 的边际后验的标准共轭形式的形状参数为 $a_0+n/2$。让我们为吉布斯抽样重新检查。）对于吉布斯抽样，$\\sigma^2$ 的全条件分布以一个固定的 $\\mu$ 为条件。更仔细地重新推导：$p(\\sigma^2 \\mid \\mu, y) \\propto p(y, \\mu \\mid \\sigma^2) p(\\sigma^2) = p(y \\mid \\mu, \\sigma^2) p(\\mu \\mid \\sigma^2)p(\\sigma^2)$。上面的推导成立。形状参数是 $a_0 + (n+1)/2$。\n[更正说明：此模型中吉布斯抽样更常见的公式使用重新参数化。我们遵循问题陈述中先验结构的直接推导。全条件分布 $p(\\sigma^2 | \\mu, y)$ 确实如推导所示。]\n让我们找到计算期望所需的 $\\sigma^2$ 的边际后验。\n$p(\\mu, \\sigma^2 \\mid y) \\propto p(y \\mid \\mu, \\sigma^2) p(\\mu \\mid \\sigma^2) p(\\sigma^2)$。合并所有项表明，联合后验是一个正态-逆伽马分布，$p(\\mu, \\sigma^2 \\mid y) \\sim \\mathrm{N-IG}(m_n, \\kappa_n, a_n, b_n)$。\n后验超参数为：\n$\\kappa_n = \\kappa_0 + n$\n$m_n = \\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}$\n$a_n = a_0 + \\frac{n}{2}$\n$b_n = b_0 + \\frac{1}{2}\\left( \\sum_{i=1}^n(y_i-\\bar{y})^2 + \\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 \\right)$\n$\\sigma^2$ 的边际后验是 $\\sigma^2 \\mid y \\sim \\mathrm{Inverse-Gamma}(a_n, b_n)$。一个随机变量 $Z \\sim \\mathrm{Inverse-Gamma}(a, b)$ 的期望值是 $\\mathbb{E}[Z] = \\frac{b}{a-1}$（对于 $a1$）。\n因此，$\\mathbb{E}[\\sigma^2 \\mid y] = \\frac{b_n}{a_n - 1}$。\n\n吉布斯采样器规范：\n初始化 $\\mu^{(0)}$ 和 $\\sigma^{2,(0)}$。对于迭代 $t=1, 2, \\dots$：\n1. 抽取 $\\mu^{(t)} \\sim \\mathcal{N}\\left(\\frac{\\kappa_0 m_0 + n\\bar{y}}{\\kappa_0 + n}, \\frac{\\sigma^{2,(t-1)}}{\\kappa_0 + n}\\right)$。\n2. 抽取 $\\sigma^{2,(t)} \\sim \\mathrm{Inverse-Gamma}\\left(a_0 + \\frac{n}{2}, b_0 + \\frac{1}{2}\\sum_{i=1}^n (y_i - \\mu^{(t)})^2\\right)$。注意：吉布斯抽样中 $\\sigma^2$ 的全条件分布使用当前的 $\\mu$ 值。形式为 $p(\\sigma^2|\\mu,y) \\propto p(y|\\mu,\\sigma^2)p(\\sigma^2)$，因为我们固定了 $\\mu$。在这里，对于这个特定的抽样，$\\mu$ 上的先验是无关的，因为 $\\mu$ 是给定的。所以，$a_{n,Gibbs}=a_0+n/2$ 且 $b_{n,Gibbs}=b_0+\\frac{1}{2}\\sum(y_i-\\mu)^2$。\n\n计算 $\\mathbb{E}[\\sigma^2 \\mid y]$：\n数据：$y=(1.2,\\,0.9,\\,1.5,\\,1.1,\\,1.3,\\,0.8)$，$n=6$。\n超参数：$(m_0,\\kappa_0,a_0,b_0)=(1.0,\\,2.0,\\,3.0,\\,0.5)$。\n首先，计算样本统计量：\n$\\bar{y} = \\frac{1}{6}(1.2+0.9+1.5+1.1+1.3+0.8) = \\frac{6.8}{6} = \\frac{17}{15}$。\n$\\sum_{i=1}^n (y_i - \\bar{y})^2 = \\sum y_i^2 - n\\bar{y}^2$。\n$\\sum y_i^2 = 1.2^2 + 0.9^2 + 1.5^2 + 1.1^2 + 1.3^2 + 0.8^2 = 1.44 + 0.81 + 2.25 + 1.21 + 1.69 + 0.64 = 8.04$。\n$n\\bar{y}^2 = 6 \\left(\\frac{17}{15}\\right)^2 = 6 \\frac{289}{225} = 2 \\frac{289}{75} = \\frac{578}{75}$。\n$\\sum (y_i - \\bar{y})^2 = 8.04 - \\frac{578}{75} = \\frac{804}{100} - \\frac{578}{75} = \\frac{201}{25} - \\frac{578}{75} = \\frac{603 - 578}{75} = \\frac{25}{75} = \\frac{1}{3}$。\n\n接下来，计算后验超参数 $a_n$ 和 $b_n$：\n$a_n = a_0 + \\frac{n}{2} = 3.0 + \\frac{6}{2} = 6$。\n$b_n = b_0 + \\frac{1}{2}\\left( \\sum_{i=1}^n(y_i-\\bar{y})^2 + \\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 \\right)$。\n括号内的第二项是：\n$\\frac{n\\kappa_0}{n+\\kappa_0}(\\bar{y}-m_0)^2 = \\frac{6 \\times 2.0}{6+2.0} \\left(\\frac{17}{15} - 1.0\\right)^2 = \\frac{12}{8} \\left(\\frac{2}{15}\\right)^2 = \\frac{3}{2} \\times \\frac{4}{225} = \\frac{6}{225} = \\frac{2}{75}$。\n现在，将这些值代入 $b_n$：\n$b_n = 0.5 + \\frac{1}{2} \\left( \\frac{1}{3} + \\frac{2}{75} \\right) = \\frac{1}{2} + \\frac{1}{2} \\left( \\frac{25}{75} + \\frac{2}{75} \\right) = \\frac{1}{2} + \\frac{1}{2} \\left( \\frac{27}{75} \\right) = \\frac{1}{2} + \\frac{27}{150} = \\frac{75}{150} + \\frac{27}{150} = \\frac{102}{150} = \\frac{17}{25} = 0.68$。\n\n最后，计算后验均值：\n$\\mathbb{E}[\\sigma^2 \\mid y] = \\frac{b_n}{a_n - 1} = \\frac{17/25}{6 - 1} = \\frac{17/25}{5} = \\frac{17}{125}$。\n转换为小数：$\\frac{17}{125} = 0.136$。\n四舍五入到四位有效数字得到 $0.1360$。",
            "answer": "$$\n\\boxed{0.1360}\n$$"
        },
        {
            "introduction": "在机器学习的实际应用中，一个至关重要的问题是监控部署环境中的数据分布是否与训练数据发生了“偏移”（drift），因为这种偏移会严重影响模型性能。本练习  要求您将统计理论转化为代码，为来自电子健康记录（EHR）的分类数据实现一个标准的似然比检验（likelihood ratio test），以灵敏地检测分布偏移。这项实践旨在锻炼您将抽象的统计原理应用于解决现实世界问题，并编写出可靠分析代码的能力。",
            "id": "4598775",
            "problem": "您正在分析被聚合成有限个分类组的电子健康记录 (EHR) 事件代码。假设有 $k$ 个类别。一个大小为 $m$ 的训练集产生计数 $Y = (Y_1,\\dots,Y_k)$，一个大小为 $n$ 的部署集产生计数 $X = (X_1,\\dots,X_k)$。假设训练样本和部署样本分别独立地从多项分布中抽取，其概率质量函数分别为 $p = (p_1,\\dots,p_k)$ 和 $q = (q_1,\\dots,q_k)$，其中对所有 $i$ 都有 $p_i  0$ 且 $\\sum_{i=1}^k p_i = \\sum_{i=1}^k q_i = 1$。定义经验比例为 $\\hat{p}_i = Y_i/m$ 和 $\\hat{q}_i = X_i/n$。Kullback-Leibler 散度 (KL 散度) $D_{\\mathrm{KL}}(\\hat{q}\\,\\|\\,\\hat{p})$ 用于量化训练和部署之间的分布偏移。\n\n请仅从概率论的核心原理、多项模型的统计推断以及似然比检验的渐近分布结果出发，推导出一个使用 $D_{\\mathrm{KL}}(\\hat{q}\\,\\|\\,\\hat{p})$ 来量化漂移的规则，以及一个在零假设 $H_0: q = p$ 下，能在指定显著性水平 $ \\alpha $ 声明存在漂移且具有有效第一类错误控制的阈值检验。然后，将此推导实现为一个程序，该程序对每个测试用例输出：\n- 经验 KL 散度 $D_{\\mathrm{KL}}(\\hat{q}\\,\\|\\,\\hat{p})$，浮点数类型，\n- 似然比检验阈值 $t_\\alpha$，浮点数类型，\n- 使用推导的阈值检验得出的布尔型漂移决策，以及\n- 相应的 p 值，浮点数类型。\n\n请使用以下包含科学上合理的类别计数的测试套件。每个测试用例指定了 $k$、$m$、$n$、$Y$、$X$ 和 $ \\alpha $：\n- 测试用例 1（正常路径，无漂移，中等样本量）：$k=5$，$m=10000$，$n=4000$，$Y = [2000,3000,2500,1500,1000]$，$X = [800,1200,1000,600,400]$，$ \\alpha = 0.05 $。\n- 测试用例 2（明显漂移，中等样本量）：$k=5$，$m=10000$，$n=4000$，$Y = [2000,3000,2500,1500,1000]$，$X = [1200,1000,900,400,500]$，$ \\alpha = 0.05 $。\n- 测试用例 3（边界情况，部署样本量小）：$k=5$，$m=10000$，$n=50$，$Y = [2000,3000,2500,1500,1000]$，$X = [5,20,15,5,5]$，$ \\alpha = 0.05 $。\n- 测试用例 4（边缘情况，部署集中一个类别的计数为零）：$k=5$，$m=10000$，$n=4000$，$Y = [2000,3000,2500,1500,1000]$，$X = [900,1300,1100,700,0]$，$ \\alpha = 0.05 $。\n- 测试用例 5（更高维度，轻微漂移）：$k=10$，$m=15000$，$n=5000$，$Y = [1500,1800,1200,2100,900,1400,1700,1600,1300,1500]$，$X = [520,620,400,700,280,470,540,500,370,600]$，$ \\alpha = 0.05 $。\n\n您的程序应针对每个测试用例，计算经验 KL 散度 $D_{\\mathrm{KL}}(\\hat{q}\\,\\|\\,\\hat{p})$，并使用渐近似然比方法在水平 $ \\alpha $ 和零假设 $H_0: q = p$ 下执行统计上有效的同质性检验。最终输出必须是单行文本，其中包含一个按给定顺序排列的所有测试用例的结果列表，每个结果本身是包含四个元素的列表，顺序如上所述。格式必须是 $[r_1,r_2,\\dots,r_5]$ 形式的单行，其中每个 $r_i$ 本身是一个列表，例如 $[[\\text{float},\\text{float},\\text{boolean},\\text{float}],\\dots]$。此处不涉及物理单位或角度。请将任何比例或概率表示为小数。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[r_1,r_2,r_3,r_4,r_5]$）。",
            "solution": "用户提供了一个问题，要求推导并实现一个统计检验，用于检测两组分类数据之间的分布漂移，这两组数据在机器学习上下文中代表训练集和部署集。该问题被描述为对两个独立多项样本的同质性检验。\n\n### I. 问题阐述与验证\n问题在于检验零假设 $H_0: p = q$ 与备择假设 $H_1: p \\neq q$。其中 $p=(p_1, \\dots, p_k)$ 和 $q=(q_1, \\dots, q_k)$ 分别是训练总体和部署总体的分类分布的概率质量函数。数据包括从训练分布中抽取的样本量为 $m = \\sum_i Y_i$ 的计数 $Y = (Y_1, \\dots, Y_k)$，以及从部署分布中抽取的样本量为 $n = \\sum_i X_i$ 的计数 $X = (X_1, \\dots, X_k)$。建模假设是 $Y \\sim \\text{Multinomial}(m, p)$ 和 $X \\sim \\text{Multinomial}(n, q)$，并且两个样本是独立的。\n\n该问题在科学和数学上是适定的。它要求应用统计推断的标准基本原理，即似然比检验 (LRT) 及其在 Wilks 定理下的渐近性质。所有必要的数据和参数都已提供。问题要求两个与漂移相关的不同输出：一个量化度量和一个形式化的假设检验。度量被指定为经验 Kullback-Leibler 散度 $D_{\\mathrm{KL}}(\\hat{q} \\| \\hat{p})$。检验被指定为从 LRT 原理推导。这是一种标准且有效的方法。\n\n### II. 似然比检验的推导\n\n我们基于似然比原理推导同质性检验。\n\n#### A. 似然函数\n给定独立的多个项样本 $Y$ 和 $X$，联合对数似然函数 $\\ell(p, q | Y, X)$ 是各自对数似然函数的和：\n$$ \\ell(p, q) = \\log(L(p, q)) = C + \\sum_{i=1}^k Y_i \\log(p_i) + \\sum_{i=1}^k X_i \\log(q_i) $$\n其中 $C$ 是一个包含阶乘的常数，在似然比中会被抵消。\n\n#### B. 在备择假设 ($H_1$) 下的最大化\n在备择假设 $H_1: p \\neq q$ 下，参数 $p$ 和 $q$ 被独立估计。最大似然估计 (MLE) 是经验比例：\n$$ \\hat{p}_i = \\frac{Y_i}{m} \\quad \\text{和} \\quad \\hat{q}_i = \\frac{X_i}{n} $$\n将这些代入对数似然函数，得到在 $H_1$ 下的最大化对数似然值：\n$$ \\ell_1 = \\sup_{p, q} \\ell(p, q) = C + \\sum_{i=1}^k Y_i \\log(\\hat{p}_i) + \\sum_{i=1}^k X_i \\log(\\hat{q}_i) $$\n\n#### C. 在零假设 ($H_0$) 下的最大化\n在零假设 $H_0: p = q$ 下，存在一个共同的概率向量，我们称之为 $\\pi$。对数似然函数变为：\n$$ \\ell(\\pi) = C + \\sum_{i=1}^k Y_i \\log(\\pi_i) + \\sum_{i=1}^k X_i \\log(\\pi_i) = C + \\sum_{i=1}^k (Y_i + X_i) \\log(\\pi_i) $$\n这是一个大小为 $m+n$，计数为 $Z_i = Y_i + X_i$ 的单个多项样本的对数似然。$\\pi_i$ 的最大似然估计是合并比例：\n$$ \\hat{\\pi}_i = \\frac{Y_i + X_i}{m+n} $$\n我们将这个合并估计量表示为 $\\hat{p}_{\\text{pooled}}$。在 $H_0$ 下的最大化对数似然值为：\n$$ \\ell_0 = \\sup_{\\pi} \\ell(\\pi) = C + \\sum_{i=1}^k (Y_i + X_i) \\log(\\hat{p}_{\\text{pooled}, i}) $$\n\n#### D. 似然比检验统计量 ($G^2$)\n似然比检验统计量，通常表示为 $G^2$，定义为对数似然比的 -2 倍：\n$$ G^2 = -2 (\\ell_0 - \\ell_1) = 2(\\ell_1 - \\ell_0) $$\n$$ G^2 = 2 \\left[ \\left(\\sum_{i=1}^k Y_i \\log(\\hat{p}_i) + \\sum_{i=1}^k X_i \\log(\\hat{q}_i)\\right) - \\left(\\sum_{i=1}^k (Y_i + X_i) \\log(\\hat{p}_{\\text{pooled}, i})\\right) \\right] $$\n重新整理这些项，我们得到：\n$$ G^2 = 2 \\left[ \\sum_{i=1}^k Y_i \\log\\left(\\frac{\\hat{p}_i}{\\hat{p}_{\\text{pooled}, i}}\\right) + \\sum_{i=1}^k X_i \\log\\left(\\frac{\\hat{q}_i}{\\hat{p}_{\\text{pooled}, i}}\\right) \\right] $$\n该统计量也称为同质性 G 检验统计量。\n\n### III. 渐近分布和检验流程\n根据 Wilks 定理，对于大样本量 $m$ 和 $n$，在零假设 $H_0$ 下，检验统计量 $G^2$ 服从一个渐近的卡方 ($\\chi^2$) 分布。该分布的自由度 (df) 是 $H_1$ 和 $H_0$ 下模型自由参数数量的差值。\n-   在 $H_1$ 下，我们估计 $p$ 和 $q$。由于和为 1 的约束，每个都有 $k-1$ 个自由参数，总共有 $2(k-1)$ 个自由参数。\n-   在 $H_0$ 下，我们估计一个单一的合并向量 $\\hat{p}_{\\text{pooled}}$，它有 $k-1$ 个自由参数。\n-   自由度是 $df = 2(k-1) - (k-1) = k-1$。\n\n因此，在 $H_0$ 下，$G^2 \\stackrel{d}{\\to} \\chi^2_{k-1}$。\n\n在显著性水平 $\\alpha$ 下的假设检验结构如下：\n1.  **检验统计量**：根据观测到的计数 $Y$ 和 $X$ 计算 $G^2$。\n2.  **临界值（阈值）**：从卡方分布中找到临界值 $t_\\alpha$，即 $(1-\\alpha)$-分位数：$t_\\alpha = \\chi^2_{k-1, 1-\\alpha}$。\n3.  **决策规则**：如果 $G^2  t_\\alpha$，我们拒绝零假设 $H_0$，并声明存在显著的分布漂移。否则，我们不拒绝 $H_0$。\n4.  **P 值**：p 值是在假设 $H_0$ 为真的情况下，观测到与计算出的 $G^2$ 一样极端或更极端的检验统计量的概率。这是上尾概率：$p\\text{-值} = P(\\chi^2_{k-1} \\ge G^2)$。\n\n### IV. 使用 KL 散度进行漂移量化\n问题要求使用经验 KL 散度 $D_{\\mathrm{KL}}(\\hat{q} \\| \\hat{p})$ 来量化漂移。这是一个与 LRT 统计量分开的计算。它衡量的是经验部署分布 $\\hat{q}$ 与经验训练分布 $\\hat{p}$ 的不相似性。\n$$ D_{\\mathrm{KL}}(\\hat{q} \\| \\hat{p}) = \\sum_{i=1}^k \\hat{q}_i \\log \\left( \\frac{\\hat{q}_i}{\\hat{p}_i} \\right) = \\sum_{i=1}^k \\frac{X_i}{n} \\log \\left( \\frac{X_i/n}{Y_i/m} \\right) $$\n值为 $0$ 表示经验分布相同，而更大的正值表示更大的不相似性。对于计数为零的类别必须特别小心。如果一个计数 $X_i=0$，则相应的项 $\\hat{q}_i \\log (\\dots)$ 为 $0$，因为 $\\lim_{x\\to 0} x \\log x = 0$。如果一个计数 $Y_i=0$（意味着 $\\hat{p}_i=0$）而 $X_i  0$，则散度为无穷大；然而，所提供的测试用例中并未出现这种情况，因为所有的 $Y_i  0$。\n\n### V. 计算总结\n对于每个具有参数 $(k, m, n, Y, X, \\alpha)$ 的测试用例，所需的输出计算如下：\n1.  **经验 KL 散度**：$D_{\\mathrm{KL}} = \\sum_{i=1}^k \\frac{X_i}{n} \\log\\left(\\frac{X_i/n}{Y_i/m}\\right)$，并适当处理零计数 $X_i$。\n2.  **LRT 阈值**：$t_\\alpha = \\text{ppf}_{\\chi^2_{k-1}}(1-\\alpha)$，其中 $\\text{ppf}$ 是百分点函数（逆累积分布函数）。\n3.  **漂移决策**：一个布尔值，如果 $G^2  t_\\alpha$ 则为 `True`，否则为 `False`，其中 $G^2$ 按上述推导计算。\n4.  **P 值**：$p = \\text{sf}_{\\chi^2_{k-1}}(G^2)$，其中 $\\text{sf}$ 是生存函数（$1 - \\text{CDF}$）。",
            "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given suite of test cases.\n    For each case, it calculates:\n    1. The empirical Kullback-Leibler divergence D_KL(q_hat || p_hat).\n    2. The likelihood ratio test threshold for significance level alpha.\n    3. A boolean decision for drift based on the test.\n    4. The p-value of the test.\n    \"\"\"\n    test_cases = [\n        # k, m, n, Y, X, alpha\n        (5, 10000, 4000, [2000, 3000, 2500, 1500, 1000], [800, 1200, 1000, 600, 400], 0.05),\n        (5, 10000, 4000, [2000, 3000, 2500, 1500, 1000], [1200, 1000, 900, 400, 500], 0.05),\n        (5, 10000, 50, [2000, 3000, 2500, 1500, 1000], [5, 20, 15, 5, 5], 0.05),\n        (5, 10000, 4000, [2000, 3000, 2500, 1500, 1000], [900, 1300, 1100, 700, 0], 0.05),\n        (10, 15000, 5000, [1500, 1800, 1200, 2100, 900, 1400, 1700, 1600, 1300, 1500], [520, 620, 400, 700, 280, 470, 540, 500, 370, 600], 0.05),\n    ]\n\n    results = []\n    for k, m, n, Y_list, X_list, alpha in test_cases:\n        Y = np.array(Y_list, dtype=float)\n        X = np.array(X_list, dtype=float)\n\n        # 1. Empirical KL Divergence D_KL(q_hat || p_hat)\n        p_hat = Y / m\n        q_hat = X / n\n        \n        # Use np.where to handle q_i = 0 or p_i = 0\n        # The term q_i * log(q_i/p_i) is 0 if q_i is 0.\n        # The problem statement guarantees Y_i  0, so p_i  0.\n        kl_div_terms = np.where(q_hat  0, q_hat * np.log(q_hat / p_hat), 0)\n        kl_divergence = np.sum(kl_div_terms)\n\n        # 2. Likelihood Ratio Test (G-test)\n        # Suppress warnings for log(0) and 0/0, as we handle them.\n        with np.errstate(divide='ignore', invalid='ignore'):\n            # Calculate G^2 = 2 * sum(O * log(O/E))\n            # Pooled counts and proportions\n            Z = Y + X\n            N = m + n\n            \n            # Expected counts under H0\n            E1 = m * Z / N\n            E2 = n * Z / N\n            \n            # Calculate G-statistic terms\n            g_terms1 = Y * np.log(Y / E1)\n            g_terms2 = X * np.log(X / E2)\n            \n            # Replace NaN (from 0*log(0/0)) with 0\n            g_terms1 = np.nan_to_num(g_terms1)\n            g_terms2 = np.nan_to_num(g_terms2)\n            \n            g_squared = 2 * (np.sum(g_terms1) + np.sum(g_terms2))\n\n        # 3. Threshold, Decision, and p-value\n        df = k - 1\n        threshold = chi2.ppf(1 - alpha, df)\n        drift_decision = g_squared  threshold\n        p_value = chi2.sf(g_squared, df)\n\n        # Store results for this test case\n        results.append([\n            float(kl_divergence),\n            float(threshold),\n            bool(drift_decision),\n            float(p_value)\n        ])\n    \n    # Format the final output string without spaces inside each inner list\n    formatted_results = []\n    for r in results:\n        # str(r[2]) is 'True' or 'False' as required\n        formatted_results.append(f\"[{r[0]},{r[1]},{r[2]},{r[3]}]\")\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```"
        }
    ]
}