{
    "hands_on_practices": [
        {
            "introduction": "A fundamental task in biomedical research is comparing a continuous measurement between two independent groups, such as a treatment and control arm in a clinical trial. This exercise guides you through the process of performing a two-sample $t$-test and calculating Cohen's $d$, a standardized measure of effect size. Mastering this practice allows you to not only determine if a difference is statistically significant but also to quantify its magnitude in a clinically meaningful way .",
            "id": "4546742",
            "problem": "A clinical biomarker study assesses whether a new anti-inflammatory therapy reduces circulating interleukin-6 concentration compared with standard care. Two independent cohorts are analyzed: patients randomized to therapy (group $T$) and patients randomized to standard care (group $C$). The biomarker is measured as a continuous variable in the same laboratory protocol across patients. Exploratory checks suggest that within each group, the biomarker distribution is approximately Gaussian, and variability appears comparable between groups, so it is reasonable to assume equal population variances for the purpose of inference.\n\nYou are given the following summary statistics:\n- Therapy group: sample size $n_{T} = 48$, sample mean $\\bar{x}_{T} = 4.7$, sample standard deviation $s_{T} = 1.2$.\n- Control group: sample size $n_{C} = 52$, sample mean $\\bar{x}_{C} = 5.3$, sample standard deviation $s_{C} = 1.1$.\n\nStarting from first principles that define the two-sample comparison as a standardized difference of means under a common-variance model, and using the Student’s $t$ distribution for inference under the null hypothesis of equal population means, do the following:\n1. Derive the test statistic used for comparing two independent Gaussian samples under the equal-variance assumption and compute its numerical value and degrees of freedom for these data, then state whether the evidence supports a reduction of the biomarker in the therapy group at a two-sided significance level $\\alpha = 0.05$.\n2. Define Cohen’s $d$ for two independent samples under the equal-variance assumption as a standardized mean difference constructed from the observed data and the common-variance model, and derive how to compute it from the given summary statistics. Then compute its numerical value and interpret its sign and magnitude in the clinical context.\n\nReport only the numerical value of Cohen’s $d$ as your final answer. Round your answer to four significant figures. Do not include any units in your final answer.",
            "solution": "The problem as stated constitutes a well-posed question in applied statistics, specifically within the domain of biostatistical hypothesis testing. All necessary data, conditions, and definitions are provided, and the problem is scientifically grounded and objective. It is therefore deemed valid and a formal solution can be constructed.\n\nThe analysis involves two primary tasks: conducting a two-sample $t$-test under the assumption of equal variances and calculating Cohen's $d$ as a measure of effect size.\n\n**Part 1: Two-Sample t-Test for Independent Samples**\n\nThe fundamental objective is to test the null hypothesis ($H_0$) that the population means of the circulating interleukin-6 concentration are equal for the therapy group ($T$) and the control group ($C$), against the alternative hypothesis ($H_A$) that they are not.\n$$H_0: \\mu_T = \\mu_C \\quad \\text{vs.} \\quad H_A: \\mu_T \\neq \\mu_C$$\nUnder the assumptions that the samples are independent and drawn from populations with approximately Gaussian distributions and equal variance ($\\sigma_T^2 = \\sigma_C^2 = \\sigma^2$), the appropriate test statistic follows a Student's $t$-distribution.\n\nThe test statistic is constructed by standardizing the observed difference in sample means, $\\bar{x}_T - \\bar{x}_C$. The standardizing factor is the standard error of this difference. The variance of the difference of two independent sample means is the sum of their individual variances:\n$$\\text{Var}(\\bar{x}_T - \\bar{x}_C) = \\text{Var}(\\bar{x}_T) + \\text{Var}(\\bar{x}_C) = \\frac{\\sigma^2}{n_T} + \\frac{\\sigma^2}{n_C} = \\sigma^2 \\left( \\frac{1}{n_T} + \\frac{1}{n_C} \\right)$$\nSince the common population variance $\\sigma^2$ is unknown, it must be estimated from the sample data. The best unbiased estimator for $\\sigma^2$ is the pooled sample variance, $s_p^2$, which combines the variance information from both samples, weighted by their degrees of freedom. It is derived as:\n$$s_p^2 = \\frac{(n_T - 1)s_T^2 + (n_C - 1)s_C^2}{(n_T - 1) + (n_C - 1)} = \\frac{(n_T - 1)s_T^2 + (n_C - 1)s_C^2}{n_T + n_C - 2}$$\nThe estimated standard error of the mean difference, $SE(\\bar{x}_T - \\bar{x}_C)$, is then:\n$$SE(\\bar{x}_T - \\bar{x}_C) = \\sqrt{s_p^2 \\left( \\frac{1}{n_T} + \\frac{1}{n_C} \\right)} = s_p \\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}$$\nThe two-sample $t$-statistic is defined as the difference between the sample means, centered by the hypothesized population mean difference (which is $0$ under $H_0$), and scaled by the standard error:\n$$t = \\frac{(\\bar{x}_T - \\bar{x}_C) - (\\mu_T - \\mu_C)_0}{SE(\\bar{x}_T - \\bar{x}_C)} = \\frac{\\bar{x}_T - \\bar{x}_C}{s_p \\sqrt{\\frac{1}{n_T} + \\frac{1}{n_C}}}$$\nThis statistic follows a Student's $t$-distribution with degrees of freedom, $df$, equal to the denominator of the pooled variance formula:\n$$df = n_T + n_C - 2$$\nNow, let's compute these quantities using the provided data:\n- Therapy group ($T$): $n_{T} = 48$, $\\bar{x}_{T} = 4.7$, $s_{T} = 1.2$\n- Control group ($C$): $n_{C} = 52$, $\\bar{x}_{C} = 5.3$, $s_{C} = 1.1$\n\nFirst, we calculate the pooled variance $s_p^2$:\n$$s_p^2 = \\frac{(48-1)(1.2)^2 + (52-1)(1.1)^2}{48+52-2} = \\frac{47(1.44) + 51(1.21)}{98} = \\frac{67.68 + 61.71}{98} = \\frac{129.39}{98} \\approx 1.320306$$\nThe pooled standard deviation, $s_p$, is the square root of the pooled variance:\n$$s_p = \\sqrt{s_p^2} \\approx \\sqrt{1.320306} \\approx 1.149046$$\nNext, we compute the $t$-statistic:\n$$t = \\frac{4.7 - 5.3}{1.149046 \\sqrt{\\frac{1}{48} + \\frac{1}{52}}} = \\frac{-0.6}{1.149046 \\sqrt{0.020833... + 0.019230...}} = \\frac{-0.6}{1.149046 \\sqrt{0.040064...}} = \\frac{-0.6}{1.149046 \\times 0.200160...} \\approx \\frac{-0.6}{0.229986} \\approx -2.6088$$\nThe degrees of freedom for this test are:\n$$df = 48 + 52 - 2 = 98$$\nTo determine if the evidence supports a reduction at a significance level $\\alpha = 0.05$ for a two-sided test, we compare the absolute value of our calculated $t$-statistic to the critical value $t_{\\alpha/2, df} = t_{0.025, 98}$. For $df=98$, the critical value is approximately $t_{crit} \\approx 1.984$. Since $|t| = |-2.6088| \\approx 2.61 > 1.984$, we reject the null hypothesis $H_0$. The negative sign of the $t$-statistic indicates that the sample mean for the therapy group is lower than that of the control group. Therefore, at the $\\alpha = 0.05$ significance level, there is statistically significant evidence to support a reduction of the biomarker in the therapy group compared to the control group.\n\n**Part 2: Cohen's d for Effect Size**\n\nCohen's $d$ is a standardized effect size that measures the magnitude of the difference between two means. For two independent samples, under the same common-variance model used for the $t$-test, it is defined as the difference in sample means divided by the pooled standard deviation, $s_p$.\n$$d = \\frac{\\bar{x}_T - \\bar{x}_C}{s_p}$$\nThis formula naturally arises from the principle of expressing the mean difference in units of the common standard deviation, providing a scale-invariant measure of the effect's magnitude.\n\nUsing the values already computed:\n- Difference in means: $\\bar{x}_T - \\bar{x}_C = 4.7 - 5.3 = -0.6$\n- Pooled standard deviation: $s_p \\approx 1.149046$\n\nWe can now compute Cohen's $d$:\n$$d = \\frac{-0.6}{1.149046} \\approx -0.522168$$\nRounding this value to four significant figures as required gives $d \\approx -0.5222$.\n\nInterpretation:\n- The sign of Cohen's $d$ is negative, which indicates that the mean of the therapy group is lower than the mean of the control group. This aligns with the clinical hypothesis that the therapy reduces the biomarker concentration.\n- The magnitude, $|d| \\approx 0.52$, is typically interpreted as a \"medium\" effect size. This suggests that the difference in the mean biomarker concentration between the therapy and control groups is approximately half a pooled standard deviation, which is generally considered a meaningful-to-moderate effect in a clinical context.\n\nThe final answer required is the numerical value of Cohen's $d$.",
            "answer": "$$\\boxed{-0.5222}$$"
        },
        {
            "introduction": "Moving from continuous to categorical data, we often need to assess whether observed counts conform to a theoretical expectation. This problem uses the classic population genetics scenario of Hardy-Weinberg Equilibrium to demonstrate the application of the Pearson's $\\chi^2$ goodness-of-fit test. This practice is crucial for quality control in genetic studies and for understanding how to properly apply statistical models to count data .",
            "id": "4546664",
            "problem": "A cohort of $N=500$ unrelated individuals from a single ancestry cluster is genotyped at one bi-allelic locus, yielding observed counts for three mutually exclusive genotype categories $\\{AA, Aa, aa\\}$ as $O_{AA}=190$, $O_{Aa}=220$, and $O_{aa}=90$. Based on an external population reference panel, the Hardy–Weinberg equilibrium (HWE) model (no inbreeding, random mating) is specified with a known allele frequency, and the resulting expected counts are provided as $E_{AA}=180$, $E_{Aa}=240$, and $E_{aa}=80$. Treat the observed counts as arising from a single multinomial sample under the null hypothesis that the specified HWE model with the external allele frequency correctly describes the population.\n\nStarting from the first principles of hypothesis testing for categorical data and asymptotic distributional results for multinomial counts, derive the appropriate goodness-of-fit test statistic, the degrees of freedom, and the decision rule at significance level $\\alpha=0.05$. Compute the value of the test statistic using the provided observed and expected counts. State the decision rule in terms of a comparison to a reference distribution quantile and interpret the decision.\n\nReport the final numerical value of the test statistic and round it to four significant figures. No units are required in the final answer.",
            "solution": "The problem requires the validation and execution of a goodness-of-fit test for categorical data. The context is population genetics, specifically testing for Hardy-Weinberg equilibrium (HWE).\n\nFirst, the validity of the problem statement is established.\nGivens:\n- Total sample size: $N=500$.\n- Genotype categories: $\\{AA, Aa, aa\\}$.\n- Observed counts: $O_{AA}=190$, $O_{Aa}=220$, $O_{aa}=90$. The sum is $190+220+90=500$.\n- Expected counts under a specified HWE model: $E_{AA}=180$, $E_{Aa}=240$, $E_{aa}=80$. The sum is $180+240+80=500$.\n- The null hypothesis ($H_0$) is that the specified HWE model is correct.\n- The significance level is $\\alpha=0.05$.\n- The data are considered a single multinomial sample.\n\nValidation:\nThe problem is scientifically grounded, utilizing the standard Pearson's chi-squared test for HWE, a fundamental procedure in population genetics. It is well-posed, providing all necessary data (observed and expected counts, sample size, significance level) for a unique solution. The language is objective and precise. The provided counts are consistent, as $\\sum O_i = \\sum E_i = N$. The scenario is realistic. The problem is therefore deemed valid.\n\nDerivation of the Test Procedure:\n\n1.  **Test Statistic**: The appropriate goodness-of-fit test for multinomial count data is Pearson's chi-squared ($\\chi^2$) test. The null hypothesis, $H_0$, states that the observed frequencies are consistent with the frequencies predicted by the theoretical model. The alternative hypothesis, $H_A$, is that they are not. The test statistic measures the discrepancy between observed counts ($O_i$) and expected counts ($E_i$) across all $k$ categories. It is defined as:\n    $$ \\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i} $$\n    Here, the categories are the $k=3$ genotypes ($AA$, $Aa$, $aa$). Under the null hypothesis and for a sufficiently large sample size, this statistic asymptotically follows a chi-squared distribution.\n\n2.  **Degrees of Freedom ($df$)**: The degrees of freedom for the chi-squared goodness-of-fit test are given by the formula $df = k - 1 - p$, where $k$ is the number of categories and $p$ is the number of independent parameters estimated from the data to calculate the expected counts.\n    -   In this problem, there are $k=3$ genotype categories.\n    -   Crucially, the problem states that the HWE model's expected counts are based on a **known** allele frequency from an **external** reference panel. This means that no parameters were estimated from the observed sample data $\\{O_{AA}, O_{Aa}, O_{aa}\\}$ to derive the expected counts $\\{E_{AA}, E_{Aa}, E_{aa}\\}$. Therefore, the number of estimated parameters is $p=0$.\n    -   Substituting these values into the formula, the degrees of freedom are:\n        $$ df = 3 - 1 - 0 = 2 $$\n    Thus, the test statistic follows a $\\chi^2$ distribution with $2$ degrees of freedom, denoted $\\chi^2_2$.\n\n3.  **Calculation of the Test Statistic**: We use the provided observed and expected counts to compute the value of the $\\chi^2$ statistic.\n    -   Observed counts: $O_{AA}=190$, $O_{Aa}=220$, $O_{aa}=90$.\n    -   Expected counts: $E_{AA}=180$, $E_{Aa}=240$, $E_{aa}=80$.\n    \n    The calculation is as follows:\n    $$ \\chi^2_{obs} = \\frac{(O_{AA} - E_{AA})^2}{E_{AA}} + \\frac{(O_{Aa} - E_{Aa})^2}{E_{Aa}} + \\frac{(O_{aa} - E_{aa})^2}{E_{aa}} $$\n    $$ \\chi^2_{obs} = \\frac{(190 - 180)^2}{180} + \\frac{(220 - 240)^2}{240} + \\frac{(90 - 80)^2}{80} $$\n    $$ \\chi^2_{obs} = \\frac{(10)^2}{180} + \\frac{(-20)^2}{240} + \\frac{(10)^2}{80} $$\n    $$ \\chi^2_{obs} = \\frac{100}{180} + \\frac{400}{240} + \\frac{100}{80} $$\n    Simplifying the fractions:\n    $$ \\chi^2_{obs} = \\frac{10}{18} + \\frac{40}{24} + \\frac{10}{8} = \\frac{5}{9} + \\frac{5}{3} + \\frac{5}{4} $$\n    To sum the fractions, we find a common denominator, which is $36$:\n    $$ \\chi^2_{obs} = \\frac{5 \\times 4}{36} + \\frac{5 \\times 12}{36} + \\frac{5 \\times 9}{36} $$\n    $$ \\chi^2_{obs} = \\frac{20 + 60 + 45}{36} = \\frac{125}{36} $$\n    Converting this fraction to a decimal gives:\n    $$ \\chi^2_{obs} \\approx 3.47222... $$\n    Rounding to four significant figures, the value of the test statistic is $3.472$.\n\n4.  **Decision Rule and Interpretation**: The decision rule is to compare the observed test statistic, $\\chi^2_{obs}$, to a critical value from the $\\chi^2_2$ distribution at the specified significance level $\\alpha=0.05$. We reject the null hypothesis if $\\chi^2_{obs}$ is greater than the critical value.\n    -   The critical value, denoted $\\chi^2_{2, 0.05}$, is the value such that $P(\\chi^2_2 > \\chi^2_{2, 0.05}) = 0.05$. From standard statistical tables or software, this critical value is approximately $5.991$.\n    -   The decision rule is: Reject $H_0$ if $\\chi^2_{obs} > 5.991$.\n    -   Comparing our calculated value to the critical value:\n        $$ 3.472 < 5.991 $$\n    -   Since the observed test statistic is not greater than the critical value, we fail to reject the null hypothesis.\n\n    **Interpretation**: At a significance level of $\\alpha=0.05$, there is insufficient statistical evidence to conclude that the observed genotype counts in the cohort are inconsistent with the proportions expected under the specified external Hardy-Weinberg equilibrium model. The observed deviation from the model's predictions is not statistically significant and can reasonably be attributed to random sampling variation.",
            "answer": "$$\\boxed{3.472}$$"
        },
        {
            "introduction": "Not all comparisons involve independent groups; we often analyze data from the same subjects under two different conditions, creating a paired design. This exercise explores such a scenario by evaluating changes in a variant-calling pipeline using McNemar's test, which is specifically designed for paired categorical data by focusing on discordant pairs. Working through this problem will solidify your understanding of how to handle non-independent data structures, a common feature in longitudinal studies and methods validation .",
            "id": "4546672",
            "problem": "A clinical genomics laboratory evaluates whether an upgraded variant-calling pipeline changes the binary classification of \"pathogenic variant detected\" for a cohort of matched patients. For each patient, the pre-upgrade classification and the post-upgrade classification are recorded as either \"detected\" or \"not detected\". The matched $2 \\times 2$ table of paired responses is summarized as follows: $62$ patients were \"detected\" both pre-upgrade and post-upgrade, $18$ were \"detected\" pre-upgrade but \"not detected\" post-upgrade, $7$ were \"not detected\" pre-upgrade but \"detected\" post-upgrade, and $33$ were \"not detected\" both pre-upgrade and post-upgrade. Assume patients are independent and that pairing is valid.\n\nUsing the principle that, under the null hypothesis of marginal homogeneity (no change in detection probability pre- versus post-upgrade), the two types of discordant pairs are exchangeable, compute the McNemar test statistic without continuity correction and with continuity correction for the stated data. Then, interpret whether the upgrade changed detection probability at a significance level of $\\alpha = 0.05$ by referencing the appropriate large-sample distribution.\n\nRound both computed statistics to four significant figures. Report your final numeric results as a two-entry row vector $(T, T_{\\mathrm{cc}})$, where $T$ is the McNemar statistic without continuity correction and $T_{\\mathrm{cc}}$ is the statistic with continuity correction. Do not include any units in your final reported numbers.",
            "solution": "The problem requires the computation and interpretation of the McNemar test statistic for a set of paired categorical data. The first step is to formally validate the problem statement.\n\n### Step 1: Extract Givens\n- Data type: Paired binary classifications (\"detected\" vs. \"not detected\") for a cohort of matched patients.\n- Pre-upgrade vs. Post-upgrade counts are provided in a $2 \\times 2$ table format:\n  - Patients \"detected\" pre- and post-upgrade: $62$.\n  - Patients \"detected\" pre-upgrade and \"not detected\" post-upgrade: $18$.\n  - Patients \"not detected\" pre-upgrade and \"detected\" post-upgrade: $7$.\n  - Patients \"not detected\" pre- and post-upgrade: $33$.\n- Assumptions: Patients are independent; pairing is valid.\n- Null Hypothesis ($H_0$): Marginal homogeneity, meaning no change in detection probability pre- versus post-upgrade.\n- Statistical Principle: Under $H_0$, the two types of discordant pairs are exchangeable.\n- Required Computations:\n  1. McNemar test statistic without continuity correction ($T$).\n  2. McNemar test statistic with continuity correction ($T_{\\mathrm{cc}}$).\n- Interpretation: Determine if the upgrade changed detection probability at a significance level of $\\alpha = 0.05$, referencing the appropriate large-sample distribution.\n- Reporting Format: Round both statistics to four significant figures and report as a two-entry row vector $(T, T_{\\mathrm{cc}})$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is scientifically sound. McNemar's test is the standard statistical procedure for comparing paired dichotomous data, which is a frequent task in clinical and bioinformatics research, such as evaluating diagnostic tests or computational pipelines. The concept of marginal homogeneity and the exchangeability of discordant pairs under the null hypothesis are the correct theoretical foundations for this test.\n- **Well-Posed:** The problem is well-posed. It provides all necessary numerical data (the counts for the $2 \\times 2$ table) and specifies the exact calculations and the significance level for interpretation. The request for a large-sample approximation clearly points to the chi-squared distribution, which is standard practice. A unique solution is attainable.\n- **Objective:** The problem is stated in objective, quantitative terms, free from ambiguity or subjective claims.\n\nThe problem does not exhibit any of the flaws listed in the validation checklist (e.g., scientific unsoundness, incompleteness, contradiction, etc.). It is a standard and well-defined biostatistics problem.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nLet us organize the provided data into a standard $2 \\times 2$ contingency table. Let the pre-upgrade classification be the rows and the post-upgrade classification be the columns.\n\n|                  | Post-Upgrade: Detected | Post-Upgrade: Not Detected | Row Total |\n|------------------|:----------------------:|:--------------------------:|:---------:|\n| **Pre-Upgrade: Detected**    | $a = 62$               | $b = 18$                   | $a+b=80$  |\n| **Pre-Upgrade: Not Detected**  | $c = 7$                | $d = 33$                   | $c+d=40$  |\n| **Column Total** | $a+c=69$               | $b+d=51$                   | $n=120$   |\n\nThe cells $a$ and $d$ represent concordant pairs, where the classification did not change. The cells $b$ and $c$ represent discordant pairs, where the classification changed between the pre- and post-upgrade pipelines. McNemar's test focuses exclusively on these discordant pairs.\n- $b = 18$: Number of patients who switched from \"detected\" to \"not detected\".\n- $c = 7$: Number of patients who switched from \"not detected\" to \"detected\".\n\nThe total number of discordant pairs is $b + c = 18 + 7 = 25$.\n\nThe null hypothesis ($H_0$) of marginal homogeneity states that the probability of a \"detected\" result is the same for both pipelines. This implies that the expected number of subjects switching from \"detected\" to \"not detected\" is equal to the expected number of subjects switching from \"not detected\" to \"detected\". The test evaluates whether the observed counts, $b$ and $c$, deviate significantly from this expectation.\n\n**1. McNemar Test Statistic without Continuity Correction ($T$)**\n\nThe formula for the McNemar statistic is:\n$$ T = \\frac{(b - c)^2}{b + c} $$\nSubstituting the observed values $b=18$ and $c=7$:\n$$ T = \\frac{(18 - 7)^2}{18 + 7} = \\frac{11^2}{25} = \\frac{121}{25} = 4.84 $$\n\n**2. McNemar Test Statistic with Continuity Correction ($T_{\\mathrm{cc}}$)**\n\nThe Yates' continuity correction is applied to better approximate the discrete binomial distribution of discordant pairs with the continuous chi-squared distribution. The formula is:\n$$ T_{\\mathrm{cc}} = \\frac{(|b - c| - 1)^2}{b + c} $$\nSubstituting the observed values:\n$$ T_{\\mathrm{cc}} = \\frac{(|18 - 7| - 1)^2}{18 + 7} = \\frac{(11 - 1)^2}{25} = \\frac{10^2}{25} = \\frac{100}{25} = 4.00 $$\n\n**3. Interpretation**\n\nFor a large number of discordant pairs (typically $b+c > 20$), the McNemar test statistic under the null hypothesis follows a chi-squared distribution with $1$ degree of freedom ($\\chi^2_1$). In this case, $b+c = 25$, so the large-sample approximation is appropriate.\n\nWe need to compare our computed statistics to the critical value from the $\\chi^2_1$ distribution at the given significance level, $\\alpha = 0.05$. The critical value, $\\chi^2_{1, 0.05}$, is the value that a $\\chi^2_1$ random variable exceeds with probability $0.05$. This value is $3.841$.\n\n- For the statistic without continuity correction: $T = 4.84$. Since $T > 3.841$, the result is statistically significant. We reject the null hypothesis of marginal homogeneity.\n- For the statistic with continuity correction: $T_{\\mathrm{cc}} = 4.00$. Since $T_{\\mathrm{cc}} > 3.841$, this result is also statistically significant. We reject the null hypothesis.\n\nBoth tests lead to the same conclusion: at the $\\alpha = 0.05$ significance level, there is sufficient evidence to conclude that the upgrade to the variant-calling pipeline has resulted in a statistically significant change in the probability of detecting a pathogenic variant.\n\n**4. Final Answer Formatting**\n\nThe problem requires rounding both computed statistics to four significant figures and presenting them as a row vector.\n- $T = 4.84$ rounded to four significant figures is $4.840$.\n- $T_{\\mathrm{cc}} = 4.00$ rounded to four significant figures is $4.000$.\n\nThe final result is the row vector $(4.840, 4.000)$.",
            "answer": "$$\\boxed{\\begin{pmatrix}4.840 & 4.000\\end{pmatrix}}$$"
        }
    ]
}