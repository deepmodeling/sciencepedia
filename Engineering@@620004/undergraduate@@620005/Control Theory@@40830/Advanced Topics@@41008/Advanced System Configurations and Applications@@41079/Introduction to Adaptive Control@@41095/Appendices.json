{"hands_on_practices": [{"introduction": "At the core of adaptive control lies the principle of learning from mistakes. This first practice invites you to simulate the \"brain\" of a simple adaptive system. You will manually execute the gradient descent algorithm, one of the most fundamental tools in machine learning and control, to update a parameter estimate based on measured data [@problem_id:1582140]. This hands-on calculation will demystify how a system can iteratively refine its internal model to better match reality.", "problem": "A smart thermostat uses a simplified model to relate the steady-state temperature difference, $\\Delta T$ (in Kelvin, K), between the inside of a room and the outside environment, to the power, $P$ (in Watts, W), supplied by a heater. The model is given by the linear relationship $\\Delta T = R_{th} P$, where $R_{th}$ is the effective thermal resistance of the room, a parameter that the thermostat needs to learn.\n\nTo estimate this parameter, the thermostat's control algorithm updates an estimate, $\\hat{R}_{th,k}$, at discrete time steps $k=0, 1, 2, \\dots$. The update is based on a gradient descent method designed to minimize the squared prediction error from the current time step, which is formulated as a cost function $J_k = \\frac{1}{2} e_k^2$, where $e_k = \\Delta T_k - \\hat{R}_{th,k} P_k$. The update rule for the estimate is given by:\n$$ \\hat{R}_{th, k+1} = \\hat{R}_{th, k} - \\mu \\left. \\frac{\\partial J_k}{\\partial \\hat{R}_{th}} \\right|_{\\hat{R}_{th} = \\hat{R}_{th,k}} $$\nwhere $\\mu$ is a constant positive learning rate.\n\nYou are given the following experimental data and parameters:\n- The initial estimate for the thermal resistance is $\\hat{R}_{th,0} = 0.0500 \\text{ K/W}$.\n- The learning rate is $\\mu = 5.00 \\times 10^{-5} \\text{ W}^{-2}$.\n- At time step $k=0$, the heater power was $P_0 = 100.0 \\text{ W}$ and the measured temperature difference was $\\Delta T_0 = 6.00 \\text{ K}$.\n- At time step $k=1$, the heater power was $P_1 = 150.0 \\text{ W}$ and the measured temperature difference was $\\Delta T_1 = 9.00 \\text{ K}$.\n\nCalculate the value of the estimate $\\hat{R}_{th,2}$. Express your answer in K/W, rounded to three significant figures.", "solution": "We are given the linear thermal model $\\Delta T = R_{th} P$ and the instantaneous squared-error cost $J_{k} = \\frac{1}{2} e_{k}^{2}$ with $e_{k} = \\Delta T_{k} - \\hat{R}_{th,k} P_{k}$. The gradient of $J_{k}$ with respect to $\\hat{R}_{th}$ is computed using the chain rule:\n$$\n\\frac{\\partial J_{k}}{\\partial \\hat{R}_{th}} = \\frac{\\partial}{\\partial \\hat{R}_{th}} \\left( \\frac{1}{2} e_{k}^{2} \\right) = e_{k} \\frac{\\partial e_{k}}{\\partial \\hat{R}_{th}}, \\quad \\text{and} \\quad \\frac{\\partial e_{k}}{\\partial \\hat{R}_{th}} = -P_{k},\n$$\nhence\n$$\n\\frac{\\partial J_{k}}{\\partial \\hat{R}_{th}} = - e_{k} P_{k}.\n$$\nThe gradient descent update is\n$$\n\\hat{R}_{th,k+1} = \\hat{R}_{th,k} - \\mu \\left. \\frac{\\partial J_{k}}{\\partial \\hat{R}_{th}} \\right|_{\\hat{R}_{th} = \\hat{R}_{th,k}} = \\hat{R}_{th,k} + \\mu\\, e_{k} P_{k}.\n$$\nEquivalently,\n$$\n\\hat{R}_{th,k+1} = \\hat{R}_{th,k} + \\mu\\, P_{k} \\left( \\Delta T_{k} - \\hat{R}_{th,k} P_{k} \\right).\n$$\n\nStep k = 0:\nGiven $\\hat{R}_{th,0} = 0.0500$, $P_{0} = 100.0$, $\\Delta T_{0} = 6.00$, compute\n$$\ne_{0} = \\Delta T_{0} - \\hat{R}_{th,0} P_{0} = 6.00 - (0.0500)(100.0) = 6.00 - 5.00 = 1.00.\n$$\nUpdate:\n$$\n\\hat{R}_{th,1} = \\hat{R}_{th,0} + \\mu e_{0} P_{0} = 0.0500 + (5.00 \\times 10^{-5})(1.00)(100.0) = 0.0500 + 0.00500 = 0.0550.\n$$\n\nStep k = 1:\nGiven $P_{1} = 150.0$, $\\Delta T_{1} = 9.00$, compute\n$$\ne_{1} = \\Delta T_{1} - \\hat{R}_{th,1} P_{1} = 9.00 - (0.0550)(150.0) = 9.00 - 8.25 = 0.75.\n$$\nUpdate:\n$$\n\\hat{R}_{th,2} = \\hat{R}_{th,1} + \\mu e_{1} P_{1} = 0.0550 + (5.00 \\times 10^{-5})(0.75)(150.0).\n$$\nCompute the increment:\n$$\n(5.00 \\times 10^{-5})(0.75)(150.0) = 5.00 \\times 10^{-5} \\times 112.5 = 0.005625.\n$$\nTherefore,\n$$\n\\hat{R}_{th,2} = 0.0550 + 0.005625 = 0.060625.\n$$\nRounded to three significant figures, this is $0.0606$.", "answer": "$$\\boxed{0.0606}$$", "id": "1582140"}, {"introduction": "After seeing how parameters are updated, a natural assumption is that if a controller achieves its goal (e.g., driving the error to zero), then its parameter estimates must be correct. This exercise challenges that intuition with a carefully designed scenario where the control objective is met, but the parameter estimates fail to converge to their true values [@problem_id:1582114]. Solving this problem reveals the critical importance of the quality of information in the system's signals, a concept central to the success of any adaptive scheme.", "problem": "Consider a first-order dynamical system whose behavior is influenced by two unknown, constant parameters, $\\theta_1$ and $\\theta_2$. The system is governed by the differential equation:\n$$ \\dot{y}(t) = u(t) + \\theta_1 w_1(t) + \\theta_2 w_2(t) $$\nwhere $y(t)$ is the system output, $u(t)$ is the control input, and $w_1(t)$ and $w_2(t)$ are known periodic signals, often called regressor signals.\n\nTo regulate the output $y(t)$ to zero, an adaptive controller is implemented. The control law is defined as:\n$$ u(t) = -k y(t) - \\hat{\\theta}_1(t) w_1(t) - \\hat{\\theta}_2(t) w_2(t) $$\nwhere $\\hat{\\theta}_1(t)$ and $\\hat{\\theta}_2(t)$ are the online estimates of the unknown parameters $\\theta_1$ and $\\theta_2$. The parameter estimates are updated according to the following adaptation laws:\n$$ \\dot{\\hat{\\theta}}_1(t) = \\gamma_1 y(t) w_1(t) $$\n$$ \\dot{\\hat{\\theta}}_2(t) = \\gamma_2 y(t) w_2(t) $$\nwhere $\\gamma_1$ and $\\gamma_2$ are positive constants known as adaptation gains.\n\nYou are given the following specific values:\n- True (but unknown to the controller) parameters: $\\theta_1 = 3.0$, $\\theta_2 = 1.5$\n- Controller and adaptation gains: $k = 10.0$, $\\gamma_1 = 5.0$, $\\gamma_2 = 10.0$\n- Regressor signals: $w_1(t) = \\cos(3t)$, $w_2(t) = 2\\cos(3t)$\n- Initial conditions: $y(0) = 0$, $\\hat{\\theta}_1(0) = 1.0$, $\\hat{\\theta}_2(0) = 8.0$\n\nThis adaptive scheme guarantees that the output converges to zero, i.e., $\\lim_{t\\to\\infty} y(t) = 0$. Your task is to determine the final, steady-state values to which the parameter estimates converge. Let these be $\\hat{\\theta}_{1,\\infty} = \\lim_{t\\to\\infty} \\hat{\\theta}_1(t)$ and $\\hat{\\theta}_{2,\\infty} = \\lim_{t\\to\\infty} \\hat{\\theta}_2(t)$.\n\nExpress your answer as a pair of exact fractions $(\\hat{\\theta}_{1,\\infty}, \\hat{\\theta}_{2,\\infty})$.", "solution": "Define the parameter-estimation errors $\\tilde{\\theta}_{1}(t) \\triangleq \\theta_{1} - \\hat{\\theta}_{1}(t)$ and $\\tilde{\\theta}_{2}(t) \\triangleq \\theta_{2} - \\hat{\\theta}_{2}(t)$. Substituting the control law into the plant gives\n$$\n\\dot{y}(t) = -k\\,y(t) + \\tilde{\\theta}_{1}(t)\\,w_{1}(t) + \\tilde{\\theta}_{2}(t)\\,w_{2}(t).\n$$\nThe adaptation laws yield\n$$\n\\dot{\\tilde{\\theta}}_{1}(t) = -\\gamma_{1}\\,y(t)\\,w_{1}(t), \\qquad \\dot{\\tilde{\\theta}}_{2}(t) = -\\gamma_{2}\\,y(t)\\,w_{2}(t).\n$$\nWith the given regressors $w_{1}(t)=\\cos(3t)$ and $w_{2}(t)=2\\cos(3t)$, define $w(t)\\triangleq \\cos(3t)$ and the combination\n$$\ns(t) \\triangleq \\tilde{\\theta}_{1}(t) + 2\\,\\tilde{\\theta}_{2}(t).\n$$\nThen the closed-loop output dynamics and the $s$-dynamics become\n$$\n\\dot{y}(t) = -k\\,y(t) + w(t)\\,s(t), \\qquad \\dot{s}(t) = -\\left(\\gamma_{1} + 4\\gamma_{2}\\right)\\,y(t)\\,w(t).\n$$\nBy assumption, $\\lim_{t\\to\\infty} y(t)=0$. For $y(t)\\equiv 0$ to be invariant, we must have $\\dot{y}(t)\\equiv 0$ as $t\\to\\infty$. Since $w(t)=\\cos(3t)$ is not identically zero, invariance requires\n$$\ns_{\\infty} \\triangleq \\lim_{t\\to\\infty} s(t) = 0,\n$$\ni.e.,\n$$\n\\tilde{\\theta}_{1,\\infty} + 2\\,\\tilde{\\theta}_{2,\\infty} = 0.\n$$\nNext, construct a conserved quantity. Consider\n$$\nr(t) \\triangleq 2\\gamma_{2}\\,\\tilde{\\theta}_{1}(t) - \\gamma_{1}\\,\\tilde{\\theta}_{2}(t).\n$$\nIts time derivative, using the adaptation laws and $w_{2}(t)=2w(t)$, is\n$$\n\\dot{r}(t) = 2\\gamma_{2}\\left(-\\gamma_{1}y(t)w(t)\\right) - \\gamma_{1}\\left(-\\gamma_{2}y(t)\\,2w(t)\\right) = -2\\gamma_{1}\\gamma_{2}y(t)w(t) + 2\\gamma_{1}\\gamma_{2}y(t)w(t) = 0.\n$$\nHence $r(t)$ is constant:\n$$\nr(t) \\equiv r(0) = 2\\gamma_{2}\\,\\tilde{\\theta}_{1}(0) - \\gamma_{1}\\,\\tilde{\\theta}_{2}(0).\n$$\nWith the given values $\\theta_{1}=3$, $\\theta_{2}=\\frac{3}{2}$, $\\hat{\\theta}_{1}(0)=1$, $\\hat{\\theta}_{2}(0)=8$, $\\gamma_{1}=5$, $\\gamma_{2}=10$, the initial errors are\n$$\n\\tilde{\\theta}_{1}(0) = \\theta_{1} - \\hat{\\theta}_{1}(0) = 3 - 1 = 2, \\qquad \\tilde{\\theta}_{2}(0) = \\theta_{2} - \\hat{\\theta}_{2}(0) = \\frac{3}{2} - 8 = -\\frac{13}{2},\n$$\nso\n$$\nr(0) = 2\\gamma_{2}\\,\\tilde{\\theta}_{1}(0) - \\gamma_{1}\\,\\tilde{\\theta}_{2}(0) = 2\\cdot 10 \\cdot 2 - 5\\left(-\\frac{13}{2}\\right) = 40 + \\frac{65}{2} = \\frac{145}{2}.\n$$\nAt steady state, the pair $(\\tilde{\\theta}_{1,\\infty},\\tilde{\\theta}_{2,\\infty})$ must satisfy the linear system\n$$\n\\tilde{\\theta}_{1,\\infty} + 2\\,\\tilde{\\theta}_{2,\\infty} = 0, \\qquad 2\\gamma_{2}\\,\\tilde{\\theta}_{1,\\infty} - \\gamma_{1}\\,\\tilde{\\theta}_{2,\\infty} = \\frac{145}{2}.\n$$\nFrom the first equation, $\\tilde{\\theta}_{1,\\infty} = -2\\,\\tilde{\\theta}_{2,\\infty}$. Substituting into the second yields\n$$\n-4\\gamma_{2}\\,\\tilde{\\theta}_{2,\\infty} - \\gamma_{1}\\,\\tilde{\\theta}_{2,\\infty} = \\frac{145}{2} \\;\\;\\Rightarrow\\;\\; \\tilde{\\theta}_{2,\\infty} = -\\frac{145/2}{4\\gamma_{2}+\\gamma_{1}}.\n$$\nWith $\\gamma_{2}=10$, $\\gamma_{1}=5$, we have $4\\gamma_{2}+\\gamma_{1}=45$, hence\n$$\n\\tilde{\\theta}_{2,\\infty} = -\\frac{145}{90} = -\\frac{29}{18}, \\qquad \\tilde{\\theta}_{1,\\infty} = -2\\,\\tilde{\\theta}_{2,\\infty} = \\frac{29}{9}.\n$$\nFinally, the steady-state parameter estimates are\n$$\n\\hat{\\theta}_{1,\\infty} = \\theta_{1} - \\tilde{\\theta}_{1,\\infty} = 3 - \\frac{29}{9} = -\\frac{2}{9}, \\qquad \\hat{\\theta}_{2,\\infty} = \\theta_{2} - \\tilde{\\theta}_{2,\\infty} = \\frac{3}{2} + \\frac{29}{18} = \\frac{27}{18} + \\frac{29}{18} = \\frac{56}{18} = \\frac{28}{9}.\n$$\nAs a check, the identifiable combination satisfies $\\hat{\\theta}_{1,\\infty} + 2\\hat{\\theta}_{2,\\infty} = -\\frac{2}{9} + 2\\left(\\frac{28}{9}\\right) = \\frac{54}{9} = 6$. The true combination is $\\theta_{1} + 2\\theta_{2} = 3 + 2(1.5) = 6$. This is consistent with $s_{\\infty}=0$.", "answer": "$$\\boxed{\\begin{pmatrix}-\\frac{2}{9} & \\frac{28}{9}\\end{pmatrix}}$$", "id": "1582114"}, {"introduction": "The previous exercise demonstrated that parameter estimates can be misled by a lack of informational richness in the system's signals. This final practice explores a common and important scenario where this issue arises: regulation problems [@problem_id:1582173]. By analyzing the stabilization of an inverted pendulum, you will uncover a fundamental paradox of adaptive control, where the very success of the controller in holding the system steady causes the learning process to halt. This highlights the crucial concept of persistent excitation.", "problem": "An inverted pendulum's dynamics, when linearized around its unstable upright equilibrium, can be described by the differential equation:\n$$ \\ddot{\\theta}(t) = a\\theta(t) + b u(t) $$\nwhere $\\theta(t)$ is the angle of the pendulum from the vertical, $u(t)$ is the applied control torque, the parameter $a$ is a known positive constant related to gravity and pendulum length, and the parameter $b$ is an unknown positive constant inversely proportional to the pendulum's mass.\n\nAn adaptive controller is implemented to stabilize the pendulum at the upright position ($\\theta=0$). The control law is designed to cancel the known dynamics and impose a desired stable behavior:\n$$ u(t) = \\frac{1}{\\hat{b}(t)} \\left( -a\\theta(t) + v(t) \\right) $$\nwhere $\\hat{b}(t)$ is the real-time estimate of the unknown parameter $b$, and $v(t) = -k_p\\theta(t) - k_d\\dot{\\theta}(t)$ is a stabilizing term with known gains $k_p > 0$ and $k_d > 0$.\n\nTo update the parameter estimate, the following adaptation law, derived from Lyapunov stability analysis, is used:\n$$ \\dot{\\hat{b}}(t) = - \\gamma \\cdot \\theta(t) \\cdot \\left( -a\\theta(t) + v(t) \\right) = - \\gamma \\theta(t) (\\hat{b}(t) u(t)) $$\nwhere $\\gamma > 0$ is the adaptation gain.\n\nThe controller successfully achieves its objective: for any initial small displacement, the pendulum angle $\\theta(t)$ converges to zero as time goes to infinity. However, experimental results show that the parameter estimate $\\hat{b}(t)$ converges to a constant value $\\hat{b}_{\\text{final}}$ which is not necessarily equal to the true parameter value $b$.\n\nWhich of the following statements provides the most accurate explanation for why the estimate $\\hat{b}(t)$ may fail to converge to the true value $b$, even though the primary control objective of stabilization is met?\n\nA. As the system stabilizes, the signals that drive the adaptation mechanism, namely $\\theta(t)$ and $u(t)$, decay to zero. This causes the update term $\\dot{\\hat{b}}(t)$ to become zero, halting any further change in the estimate, regardless of the existing parameter error.\n\nB. The linearized model is only an approximation. As $\\theta(t)$ approaches zero, unmodeled nonlinear effects, though small, become significant relative to the signal, preventing the adaptation law from isolating the true value of $b$.\n\nC. The control effort $u(t)$ must counteract the instability term $a\\theta(t)$. This creates a permanent algebraic relationship between $u(t)$ and $\\theta(t)$ that makes it impossible for the adaptation algorithm to independently determine the scaling factor $b$.\n\nD. The adaptation gain $\\gamma$ is a fixed constant. A time-varying gain that increases as $\\theta(t)$ decreases is necessary to ensure convergence of the parameter estimate when the system is near equilibrium.\n\nE. The successful stabilization implies that the control law is effective. The discrepancy arises because the true value of $b$ makes the open-loop system more unstable than the value $\\hat{b}_{\\text{final}}$, and the controller naturally converges to an estimate that appears easier to control.", "solution": "Start from the plant and control law:\n$$\n\\ddot{\\theta}(t)=a\\theta(t)+b\\,u(t),\\qquad\nu(t)=\\frac{1}{\\hat{b}(t)}\\left(-a\\theta(t)+v(t)\\right),\\qquad\nv(t)=-k_{p}\\theta(t)-k_{d}\\dot{\\theta}(t),\n$$\nwith $a>0$, $k_{p}>0$, $k_{d}>0$, and $b>0$ unknown.\n\nClosed-loop dynamics under the control law are obtained by substitution:\n$$\n\\ddot{\\theta}(t)=a\\theta(t)+b\\cdot\\frac{1}{\\hat{b}(t)}\\left(-a\\theta(t)+v(t)\\right)\n=a\\theta(t)+\\frac{b}{\\hat{b}(t)}\\left(-a\\theta(t)-k_{p}\\theta(t)-k_{d}\\dot{\\theta}(t)\\right).\n$$\nIf $\\hat{b}(t)\\equiv b$, then $\\ddot{\\theta}(t)=v(t)=-k_{p}\\theta(t)-k_{d}\\dot{\\theta}(t)$, which is exponentially stable for $k_{p}>0$, $k_{d}>0$. Even if $\\hat{b}(t)\\neq b$ but $\\hat{b}(t)>0$, the closed loop becomes\n$$\n\\ddot{\\theta}(t)=\\Big(a-\\frac{b}{\\hat{b}(t)}a-\\frac{b}{\\hat{b}(t)}k_{p}\\Big)\\theta(t)-\\frac{b}{\\hat{b}(t)}k_{d}\\dot{\\theta}(t),\n$$\nand for appropriate gains the equilibrium $\\theta=0$ remains stable in the sense observed experimentally.\n\nThe parameter update is\n$$\n\\dot{\\hat{b}}(t)=-\\gamma\\,\\theta(t)\\,\\big(-a\\theta(t)+v(t)\\big),\n$$\nand, using the control law relation $-a\\theta(t)+v(t)=\\hat{b}(t)\\,u(t)$, equivalently\n$$\n\\dot{\\hat{b}}(t)=-\\gamma\\,\\hat{b}(t)\\,\\theta(t)\\,u(t).\n$$\nUnder successful stabilization, $\\theta(t)\\to 0$ and $\\dot{\\theta}(t)\\to 0$ as $t\\to\\infty$. Then $v(t)=-k_{p}\\theta(t)-k_{d}\\dot{\\theta}(t)\\to 0$, and from $u(t)=\\frac{1}{\\hat{b}(t)}\\big(-a\\theta(t)+v(t)\\big)$ it follows that $u(t)\\to 0$. Consequently,\n$$\n\\dot{\\hat{b}}(t)=-\\gamma\\,\\hat{b}(t)\\,\\theta(t)\\,u(t)\\to 0,\n$$\nso the integrand driving the adaptation vanishes and the estimate freezes:\n$$\n\\hat{b}(t)=\\hat{b}(t_{0})-\\gamma\\int_{t_{0}}^{t}\\hat{b}(\\tau)\\,\\theta(\\tau)\\,u(\\tau)\\,d\\tau,\n$$\nwith the integral converging to a finite value that depends on transients and initial conditions, not necessarily enforcing $\\hat{b}(t)\\to b$.\n\nIn standard adaptive control theory, convergence of parameter estimates to their true values requires a persistent excitation condition on the regressor. Here, the relevant products of signals that excite adaptation (such as $\\theta(t)$ and $u(t)$) decay to zero during regulation, violating persistent excitation. Therefore, there is no guarantee that $\\hat{b}(t)$ converges to $b$; instead, $\\hat{b}(t)$ converges to some constant $\\hat{b}_{\\text{final}}$ determined by the transient data. This is exactly the mechanism described in option A.\n\nOptions B, C, D, and E do not provide the fundamental reason: unmodeled nonlinearities (B) are not necessary to explain nonconvergence; an algebraic relation between $u$ and $\\theta$ (C) does not preclude identification if excitation is present; changing $\\gamma$ in time (D) cannot compensate for lack of excitation; and the heuristic in E is unrelated to the Lyapunov-based adaptation mechanism. The essential issue is the vanishing of the excitation signals as stabilization is achieved.", "answer": "$$\\boxed{A}$$", "id": "1582173"}]}