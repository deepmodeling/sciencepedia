{"hands_on_practices": [{"introduction": "The best way to demystify neural networks in control is to start with the most basic building block: a single neuron. This exercise shows how a simple neuron, equipped with a non-linear activation function, can be engineered to function as a complete controller for a physical system like a liquid tank. By working through this problem, you will learn to tune the neuron's weight and bias parameters to meet specific, practical performance criteria, such as eliminating steady-state error and achieving a desired controller sensitivity [@problem_id:1595357]. This provides a concrete link between the abstract parameters of a neural network and tangible control system behavior.", "problem": "An engineer is designing a simple neural controller to regulate the liquid level in a storage tank. The dynamics of the liquid level, $h(t)$, in a tank with a constant cross-sectional area are governed by the differential equation: $A \\frac{dh}{dt} = q_{in}(t) - q_{out}(t)$, where $A$ is the area, $q_{in}(t)$ is the inflow rate, and $q_{out}(t)$ is the outflow rate. The outflow is known to be a linear function of the liquid level: $q_{out}(t) = K_{out}h(t)$, where $K_{out}$ is a positive constant outflow coefficient.\n\nThe inflow $q_{in}(t)$ is determined by a single-neuron controller. This controller takes the error signal, $e(t) = h_{ref} - h(t)$, as its input, where $h_{ref}$ is the desired constant reference level. The controller's output, which sets the inflow rate, is given by the following equation featuring a hyperbolic tangent activation function:\n$$q_{in}(t) = \\frac{q_{max}}{2} \\left[ 1 + \\tanh(w \\cdot e(t) + b) \\right]$$\nHere, $q_{max}$ is the maximum possible inflow rate from the pump, while $w$ and $b$ are the neuron's tunable weight and bias, respectively.\n\nThe engineer's goal is to select the weight $w$ and bias $b$ to meet two specific performance criteria in the steady-state operating condition (as $t \\to \\infty$):\n1. The steady-state liquid level, $h_{ss}$, must be exactly equal to the reference level $h_{ref}$, ensuring zero steady-state error.\n2. At this steady-state point, the controller's sensitivity to small errors, defined as the proportional gain $K_P = \\left. \\frac{dq_{in}}{de} \\right|_{e=0}$, must be equal to a specified positive value $G$.\n\nDetermine the analytical expression for the required neural network weight $w$. Express your answer in terms of $h_{ref}$, $K_{out}$, $q_{max}$, and $G$.", "solution": "The tank dynamics are $A \\frac{dh}{dt} = q_{in}(t) - q_{out}(t)$ with $q_{out}(t) = K_{out} h(t)$. In steady state, $\\frac{dh}{dt} = 0$, so $q_{in,ss} = q_{out,ss} = K_{out} h_{ss}$. The first requirement imposes $h_{ss} = h_{ref}$, hence\n$$\nq_{in}(e=0) = K_{out} h_{ref}.\n$$\nThe controller is $q_{in}(t) = \\frac{q_{max}}{2}\\left[1 + \\tanh(w e(t) + b)\\right]$ with $e(t) = h_{ref} - h(t)$. At steady state, $e=0$, so\n$$\n\\frac{q_{max}}{2}\\left[1 + \\tanh(b)\\right] = K_{out} h_{ref}\n\\quad \\Rightarrow \\quad\n\\tanh(b) = \\frac{2 K_{out} h_{ref}}{q_{max}} - 1.\n$$\nThis requires $0 < K_{out} h_{ref} < q_{max}$ to keep $|\\tanh(b)| < 1$.\n\nThe proportional sensitivity is\n$$\nK_{P} = \\left.\\frac{dq_{in}}{de}\\right|_{e=0} = \\left.\\frac{q_{max}}{2}\\,\\frac{d}{de}\\tanh(w e + b)\\right|_{e=0} = \\frac{q_{max}}{2}\\,w\\,[1 - \\tanh^{2}(b)].\n$$\nImposing $K_{P} = G$ yields\n$$\n\\frac{q_{max}}{2}\\,w\\,[1 - \\tanh^{2}(b)] = G\n\\quad \\Rightarrow \\quad\nw = \\frac{2G}{q_{max}\\,[1 - \\tanh^{2}(b)]}.\n$$\nUsing $\\tanh(b) = \\frac{2 K_{out} h_{ref}}{q_{max}} - 1$, define $x = \\frac{2 K_{out} h_{ref}}{q_{max}}$ so that $1 - \\tanh^{2}(b) = 1 - (x - 1)^{2} = x(2 - x)$. Hence\n$$\n1 - \\tanh^{2}(b) = \\frac{4 K_{out} h_{ref}\\,(q_{max} - K_{out} h_{ref})}{q_{max}^{2}}.\n$$\nSubstituting into the expression for $w$ gives\n$$\nw = \\frac{2G}{q_{max}} \\cdot \\frac{q_{max}^{2}}{4 K_{out} h_{ref}\\,(q_{max} - K_{out} h_{ref})}\n= \\frac{G\\,q_{max}}{2 K_{out} h_{ref}\\,(q_{max} - K_{out} h_{ref})}.\n$$\nThis satisfies both steady-state zero error and the specified proportional sensitivity, provided $0 < K_{out} h_{ref} < q_{max}$ and $G > 0$.", "answer": "$$\\boxed{\\frac{G\\,q_{max}}{2\\,K_{out}\\,h_{ref}\\,\\left(q_{max}-K_{out}\\,h_{ref}\\right)}}$$", "id": "1595357"}, {"introduction": "While neural networks are valued for their ability to capture complex non-linear relationships, it is often essential to understand their behavior from a classical control perspective. This practice introduces the powerful technique of linearization, which allows us to approximate a sophisticated non-linear neural controller with a simple local gain matrix, $K$, around a specific operating point. This exercise [@problem_id:1595344] demonstrates how to use calculus to compute this gain matrix, effectively translating the network's complex internal workings into a familiar language that is indispensable for stability analysis and system integration.", "problem": "In modern robotics, a neural network is often used as a non-linear controller. Consider a simple feedforward neural network designed to control a single joint of a robotic arm. The network takes two inputs: the dimensionless position error $e_1$ and the dimensionless velocity error $e_2$. It produces a single output, $u$, which represents the corrective torque applied to the joint.\n\nThe network has a single hidden layer with two neurons. The activation function for the hidden layer neurons is the hyperbolic tangent, $\\tanh(x)$. The output neuron has a linear activation function (i.e., its output is equal to its input).\n\nThe computation within the network is defined as follows:\nFirst, the pre-activation values for the hidden neurons, $z_1$ and $z_2$, are calculated:\n$$z_1 = w_{11}e_1 + w_{12}e_2 + b_1$$\n$$z_2 = w_{21}e_1 + w_{22}e_2 + b_2$$\n\nNext, the activations of the hidden neurons, $a_1$ and $a_2$, are found:\n$$a_1 = \\tanh(z_1)$$\n$$a_2 = \\tanh(z_2)$$\n\nFinally, the output torque $u$ is computed:\n$$u = v_1 a_1 + v_2 a_2 + b_{\\text{out}}$$\n\nAfter a training process, the network parameters (weights and biases) have been determined to be:\n- Input-to-hidden weights: $w_{11} = 1.2$, $w_{12} = -0.8$, $w_{21} = 0.5$, $w_{22} = 1.5$\n- Hidden layer biases: $b_1 = 0.1$, $b_2 = -0.3$\n- Hidden-to-output weights: $v_1 = 2.0$, $v_2 = -1.0$\n- Output bias: $b_{\\text{out}} = 0.4$\n\nFor analysis and integration with classical control methods, it is necessary to linearize this non-linear controller around a specific operating point. Determine the local gain matrix $K = \\begin{bmatrix} K_1 & K_2 \\end{bmatrix}$ that approximates the controller's behavior as $\\delta u \\approx K_1 \\delta e_1 + K_2 \\delta e_2$ around the operating point $(e_{1,0}, e_{2,0}) = (0.5, -0.2)$.\n\nExpress your answer as a $1 \\times 2$ row matrix. Round the numerical values of the matrix elements to three significant figures.", "solution": "We linearize the nonlinear mapping $u(e_{1},e_{2})$ by computing the Jacobian of $u$ with respect to $(e_{1},e_{2})$ at the operating point $(e_{1,0},e_{2,0})=(0.5,-0.2)$. The local gain matrix is $K=\\begin{bmatrix}K_{1} & K_{2}\\end{bmatrix}$ with\n$$\nK_{1}=\\left.\\frac{\\partial u}{\\partial e_{1}}\\right|_{(e_{1,0},e_{2,0})},\\quad\nK_{2}=\\left.\\frac{\\partial u}{\\partial e_{2}}\\right|_{(e_{1,0},e_{2,0})}.\n$$\nGiven $z_{1}=w_{11}e_{1}+w_{12}e_{2}+b_{1}$ and $z_{2}=w_{21}e_{1}+w_{22}e_{2}+b_{2}$, with $a_{i}=\\tanh(z_{i})$ and $u=v_{1}a_{1}+v_{2}a_{2}+b_{\\text{out}}$, the chain rule and $\\frac{d}{dz}\\tanh(z)=1-\\tanh^{2}(z)$ give\n$$\n\\frac{\\partial u}{\\partial e_{1}}=v_{1}\\bigl(1-\\tanh^{2}(z_{1})\\bigr)\\frac{\\partial z_{1}}{\\partial e_{1}}+v_{2}\\bigl(1-\\tanh^{2}(z_{2})\\bigr)\\frac{\\partial z_{2}}{\\partial e_{1}}\n= v_{1}\\bigl(1-\\tanh^{2}(z_{1})\\bigr)w_{11}+v_{2}\\bigl(1-\\tanh^{2}(z_{2})\\bigr)w_{21},\n$$\n$$\n\\frac{\\partial u}{\\partial e_{2}}=v_{1}\\bigl(1-\\tanh^{2}(z_{1})\\bigr)\\frac{\\partial z_{1}}{\\partial e_{2}}+v_{2}\\bigl(1-\\tanh^{2}(z_{2})\\bigr)\\frac{\\partial z_{2}}{\\partial e_{2}}\n= v_{1}\\bigl(1-\\tanh^{2}(z_{1})\\bigr)w_{12}+v_{2}\\bigl(1-\\tanh^{2}(z_{2})\\bigr)w_{22}.\n$$\nEvaluate $z_{1}$ and $z_{2}$ at $(e_{1,0},e_{2,0})=(0.5,-0.2)$:\n$$\nz_{1}=1.2\\cdot 0.5+(-0.8)\\cdot(-0.2)+0.1=0.86,\\qquad\nz_{2}=0.5\\cdot 0.5+1.5\\cdot(-0.2)-0.3=-0.35.\n$$\nUsing $\\tanh(x)=\\frac{\\exp(2x)-1}{\\exp(2x)+1}$, we obtain numerically\n$$\n\\tanh(0.86)\\approx 0.6964\\;\\Rightarrow\\;1-\\tanh^{2}(0.86)\\approx 0.5150,\\qquad\n\\tanh(-0.35)\\approx -0.3364\\;\\Rightarrow\\;1-\\tanh^{2}(-0.35)\\approx 0.8869.\n$$\nSubstitute parameters $v_{1}=2.0$, $v_{2}=-1.0$, $w_{11}=1.2$, $w_{12}=-0.8$, $w_{21}=0.5$, $w_{22}=1.5$:\n$$\nK_{1}=2.0\\cdot 0.5150\\cdot 1.2+(-1.0)\\cdot 0.8869\\cdot 0.5\\approx 1.236-0.4435\\approx 0.7926,\n$$\n$$\nK_{2}=2.0\\cdot 0.5150\\cdot(-0.8)+(-1.0)\\cdot 0.8869\\cdot 1.5\\approx -0.8240-1.3304\\approx -2.1543.\n$$\nRounding each to three significant figures yields\n$$\nK=\\begin{bmatrix}0.793 & -2.15\\end{bmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix}0.793 & -2.15\\end{pmatrix}}$$", "id": "1595344"}, {"introduction": "Beyond acting as direct controllers, neural networks are frequently used to create data-driven models of complex systems. This practice explores such a scenario within the framework of Model Predictive Control (MPC), a highly effective modern control strategy. Here, a pre-trained neural network predicts the future state of a chemical reactor, and the controller uses this prediction to calculate the optimal control action by minimizing a cost function. This problem [@problem_id:1595312] will guide you through the core logic of one-step-ahead MPC, illustrating the critical trade-off between tracking a desired setpoint and conserving control energy.", "problem": "A chemical process involving a Continuous Stirred-Tank Reactor (CSTR) is monitored at discrete time steps $k$. The state of the system is characterized by the concentration of a reactant A, denoted as $C_A(k)$ in mol/L. The process is influenced by a single control input, the flow rate of a coolant, denoted as $u(k)$ in L/min.\n\nTo regulate the reactor, a simple form of Model Predictive Control (MPC) is implemented. This controller uses a pre-trained neural network to predict the concentration at the next time step, $C_A(k+1)$. The neural network's predictive model is given by the following affine function:\n$$C_A(k+1) = \\alpha C_A(k) - \\beta u(k) + \\delta$$\nwhere $\\alpha$, $\\beta$, and $\\delta$ are constant parameters learned by the network.\n\nThe goal of the controller is to drive the concentration $C_A$ towards a reference setpoint, $C_{A, \\text{ref}}$. At each time step $k$, the controller calculates the optimal control input $u(k)$ that minimizes a one-step-ahead cost function, $J$. This cost function penalizes both the predicted deviation from the setpoint and the magnitude of the control effort:\n$$J(u(k)) = \\left(C_{A, \\text{ref}} - C_A(k+1)\\right)^2 + \\lambda \\left(u(k)\\right)^2$$\nwhere $\\lambda$ is a positive weighting factor.\n\nAt a particular time step $k$, the system is observed to have a concentration $C_A(k) = 2.10$ mol/L. The system parameters are given as:\n- Reference setpoint, $C_{A, \\text{ref}} = 1.50$ mol/L\n- Model parameter, $\\alpha = 0.950$\n- Model parameter, $\\beta = 0.120$ (mol/L) / (L/min)\n- Model parameter, $\\delta = 0.250$ mol/L\n- Control weighting factor, $\\lambda = 0.0500$ ((mol/L)$^2$) / ((L/min)$^2$)\n\nDetermine the optimal coolant flow rate $u(k)$ that the controller should apply at this time step. Express your answer in L/min, rounded to three significant figures.", "solution": "We are to choose the control input $u(k)$ that minimizes the one-step quadratic cost\n$$J(u(k))=\\left(C_{A,\\text{ref}}-C_{A}(k+1)\\right)^{2}+\\lambda \\left(u(k)\\right)^{2},$$\nwith the affine model\n$$C_{A}(k+1)=\\alpha C_{A}(k)-\\beta u(k)+\\delta.$$\nFor compactness, define $u \\equiv u(k)$ and substitute the model into the cost. The predicted tracking error is\n$$C_{A,\\text{ref}}-C_{A}(k+1)=C_{A,\\text{ref}}-\\left(\\alpha C_{A}(k)-\\beta u+\\delta\\right)=\\left(C_{A,\\text{ref}}-\\alpha C_{A}(k)-\\delta\\right)+\\beta u.$$\nLet\n$$r \\equiv C_{A,\\text{ref}}-\\alpha C_{A}(k)-\\delta.$$\nThen the cost becomes\n$$J(u)=(r+\\beta u)^{2}+\\lambda u^{2}.$$\nThis is a strictly convex quadratic in $u$ because $\\beta^{2}+\\lambda>0$ for $\\lambda>0$. The unconstrained minimizer satisfies the first-order optimality condition $\\frac{dJ}{du}=0$. Differentiate:\n$$\\frac{dJ}{du}=2(r+\\beta u)\\beta+2\\lambda u=2\\beta r+2\\left(\\beta^{2}+\\lambda\\right)u.$$\nSet this to zero and solve for $u$:\n$$2\\beta r+2\\left(\\beta^{2}+\\lambda\\right)u=0 \\implies u^{\\star}=-\\frac{\\beta r}{\\beta^{2}+\\lambda}=-\\frac{\\beta\\left(C_{A,\\text{ref}}-\\alpha C_{A}(k)-\\delta\\right)}{\\beta^{2}+\\lambda}.$$\nThe second derivative is $\\frac{d^{2}J}{du^{2}}=2\\left(\\beta^{2}+\\lambda\\right)>0$, confirming a unique minimum.\n\nNow substitute the given numerical values:\n$$\\alpha=0.950,\\quad \\beta=0.120,\\quad \\delta=0.250,\\quad \\lambda=0.0500,\\quad C_{A}(k)=2.10,\\quad C_{A,\\text{ref}}=1.50.$$\nCompute\n$$r=C_{A,\\text{ref}}-\\alpha C_{A}(k)-\\delta=1.50-0.950\\cdot 2.10-0.250=1.50-1.995-0.250=-0.745,$$\nand\n$$\\beta^{2}+\\lambda=(0.120)^{2}+0.0500=0.0144+0.0500=0.0644.$$\nTherefore,\n$$u^{\\star}=-\\frac{\\beta r}{\\beta^{2}+\\lambda}=-\\frac{0.120\\cdot(-0.745)}{0.0644}=\\frac{0.0894}{0.0644}\\approx 1.3882.$$\nRounded to three significant figures, the optimal coolant flow rate is $1.39$ in L/min.", "answer": "$$\\boxed{1.39}$$", "id": "1595312"}]}