{"hands_on_practices": [{"introduction": "At the heart of any self-tuning regulator lies the certainty equivalence principle, where we design a controller as if our estimated model parameters were the true system parameters. This first exercise allows you to apply this core concept in its most direct form by designing a 'deadbeat' controller, which aims to bring the system output to its target setpoint in a single time step [@problem_id:1608454]. By working through this fundamental derivation, you will establish a solid understanding of how control actions are calculated within the adaptive control loop, a key building block for more complex designs.", "problem": "An engineer is developing a control system for a simple thermal process. The process can be modeled by the following first-order linear discrete-time difference equation:\n$$y(k+1) = a y(k) + b u(k)$$\nwhere $y(k)$ is the temperature of the system at discrete time step $k$, $u(k)$ is the control input (voltage applied to a heater) at time step $k$, and $a$ and $b$ are unknown, constant physical parameters of the system.\n\nA self-tuning regulator is implemented. It consists of two parts: a parameter estimator and a controller. At each time step $k$, a parameter estimation algorithm provides the most current estimates for $a$ and $b$, which are denoted by $\\hat{a}(k)$ and $\\hat{b}(k)$, respectively. For the purposes of this problem, you can treat these estimates as given constants for the calculation at step $k$, which we will simply call $\\hat{a}$ and $\\hat{b}$.\n\nThe control objective is to implement a 'deadbeat' control strategy. This strategy requires the controller to choose an input $u(k)$ that will cause the system's output at the next time step, $y(k+1)$, to be exactly equal to a desired constant setpoint, $y_{ref}$.\n\nAssuming the model is exact and the parameter estimates are perfect (i.e., $\\hat{a} = a$ and $\\hat{b} = b$), derive the control law for $u(k)$. The expression for $u(k)$ should be in terms of the current measured temperature $y(k)$, the setpoint $y_{ref}$, and the estimated parameters $\\hat{a}$ and $\\hat{b}$.", "solution": "We are given the discrete-time first-order model\n$$y(k+1) = a\\,y(k) + b\\,u(k).$$\nA deadbeat controller requires the next output to equal the setpoint, so we impose the condition\n$$y(k+1) = y_{ref}.$$\nAt time step $k$, the controller uses the current parameter estimates, which we treat as constants $\\hat{a}$ and $\\hat{b}$, with the assumption of perfect estimation, $\\hat{a} = a$ and $\\hat{b} = b$. Replacing the model parameters with their estimates for control design and enforcing the deadbeat requirement gives\n$$y_{ref} = \\hat{a}\\,y(k) + \\hat{b}\\,u(k).$$\nWe solve this linear equation for the control input $u(k)$ by isolating $u(k)$:\n$$\\hat{b}\\,u(k) = y_{ref} - \\hat{a}\\,y(k),$$\nand, assuming $\\hat{b} \\neq 0$,\n$$u(k) = \\frac{y_{ref} - \\hat{a}\\,y(k)}{\\hat{b}}.$$\nThis control law ensures $y(k+1) = y_{ref}$ in one step under the stated assumptions.", "answer": "$$\\boxed{\\frac{y_{ref} - \\hat{a}\\,y(k)}{\\hat{b}}}$$", "id": "1608454"}, {"introduction": "Real-world systems are invariably more complex than the models we use to control them. This practice explores the critical consequences of such model-plant mismatch, specifically investigating the case where a first-order regulator is applied to a true second-order process [@problem_id:1608473]. You will quantitatively analyze how this 'under-parameterization' affects the system's ultimate performance by calculating the final closed-loop poles, providing a concrete understanding of the stability risks involved in model simplification.", "problem": "A control systems engineer is tasked with designing a self-tuning regulator for a chemical process. Due to measurement limitations, the engineer decides to approximate the process dynamics using a first-order model structure. However, the true process is known to exhibit more complex, a second-order behavior.\n\nThe true discrete-time transfer function of the process from control input $U(z)$ to process output $Y(z)$ is given by:\n$$G_p(z) = \\frac{Y(z)}{U(z)} = \\frac{0.36 z^{-1} - 0.18 z^{-2}}{1 - 0.9 z^{-1} + 0.08 z^{-2}}$$\n\nThe self-tuning regulator is designed based on the following assumptions and specifications:\n1.  **Model Structure**: The regulator employs a first-order model representation of the plant, $\\hat{G}_p(z) = \\frac{\\hat{B}(z)}{\\hat{A}(z)} = \\frac{\\hat{b} z^{-1}}{1 + \\hat{a} z^{-1}}$, where $\\hat{a}$ and $\\hat{b}$ are the parameters to be estimated.\n2.  **Estimation**: The parameters are estimated using a Recursive Least Squares (RLS) algorithm. For the purpose of this analysis, you are to assume that the RLS estimator has converged to the unique parameter set $(\\hat{a}, \\hat{b})$ for which the first two non-zero terms of the impulse response of the model $\\hat{G}_p(z)$ exactly match the first two non-zero terms of the impulse response of the true plant $G_p(z)$.\n3.  **Control Design**: The control law is designed using the certainty equivalence principle, where the estimated parameters $(\\hat{a}, \\hat{b})$ are treated as the true plant parameters. The objective is pole placement, aiming for a closed-loop characteristic polynomial $A_m(z) = 1 - 0.5 z^{-1}$. The controller has the structure $R(z)U(z) = T(z)R_{ref}(z) - S(z)Y(z)$, where $R_{ref}(z)$ is the reference signal. The controller polynomials $R(z)$ and $S(z)$ are chosen to be of the lowest possible degree to satisfy the Diophantine equation $\\hat{A}(z)R(z) + \\hat{B}(z)S(z) = A_m(z)$, with $R(z)$ chosen to be a monic polynomial of degree zero.\n\nOnce the estimator converges, the parameters $\\hat{a}$ and $\\hat{b}$ become constant, and the self-tuning regulator effectively operates as a fixed linear time-invariant controller. This fixed controller is then interacting with the true second-order plant $G_p(z)$. Determine the location of the closed-loop pole with the largest magnitude for this final, true closed-loop system.\n\nRound your final answer to four significant figures.", "solution": "The true plant is given by the discrete transfer function\n$$G_{p}(z)=\\frac{0.36 z^{-1}-0.18 z^{-2}}{1-0.9 z^{-1}+0.08 z^{-2}}.$$\nIts corresponding difference equation under input $u[k]$ and output $y[k]$ is\n$$y[k]-0.9\\,y[k-1]+0.08\\,y[k-2]=0.36\\,u[k-1]-0.18\\,u[k-2].$$\nFor an impulse input $u[0]=1$ and $u[k]=0$ for $k\\geq 1$, with zero initial conditions, the first samples of the impulse response are obtained as follows:\n- At $k=0$: $y[0]=0$.\n- At $k=1$: $y[1]-0.9\\,y[0]+0.08\\,y[-1]=0.36\\,u[0]-0.18\\,u[-1]=0.36$, hence $y[1]=0.36$.\n- At $k=2$: $y[2]-0.9\\,y[1]+0.08\\,y[0]=0.36\\,u[1]-0.18\\,u[0]=-0.18$, hence $y[2]=-0.18+0.9\\cdot 0.36=0.144$.\n\nThus, the first two non-zero impulse response terms of $G_{p}(z)$ are $0.36$ and $0.144$.\n\nThe model used by the regulator is\n$$\\hat{G}_{p}(z)=\\frac{\\hat{b} z^{-1}}{1+\\hat{a} z^{-1}},$$\nwith corresponding difference equation\n$$y[k]+\\hat{a}\\,y[k-1]=\\hat{b}\\,u[k-1].$$\nFor an impulse input, this yields\n- $y[0]=0$,\n- $y[1]=\\hat{b}$,\n- $y[2]=-\\hat{a}\\,\\hat{b}$.\n\nMatching the first two non-zero terms to the true plant gives\n$$\\hat{b}=0.36,\\qquad -\\hat{a}\\hat{b}=0.144\\;\\Rightarrow\\;\\hat{a}=-\\frac{0.144}{0.36}=-0.4.$$\n\nThe controller is designed by certainty equivalence with the Diophantine equation\n$$\\hat{A}(z)R(z)+\\hat{B}(z)S(z)=A_{m}(z),$$\nwhere $\\hat{A}(z)=1+\\hat{a} z^{-1}=1-0.4 z^{-1}$, $\\hat{B}(z)=\\hat{b} z^{-1}=0.36 z^{-1}$, $A_{m}(z)=1-0.5 z^{-1}$, and $R(z)$ is monic of degree zero, so $R(z)=1$. Choosing the lowest possible degree for $S(z)$, take $S(z)=s_{0}$ (a constant). Then\n$$(1-0.4 z^{-1})+0.36 s_{0} z^{-1}=1-0.5 z^{-1},$$\nwhich gives the $z^{-1}$ coefficient equation\n$$-0.4+0.36 s_{0}=-0.5\\;\\Rightarrow\\;0.36 s_{0}=-0.1\\;\\Rightarrow\\;s_{0}=-\\frac{5}{18}.$$\n\nOnce fixed, the controller acts on the true plant. Writing the true plant in polynomial form $A_{\\text{t}}(z)Y(z)=B_{\\text{t}}(z)U(z)$ with\n$$A_{\\text{t}}(z)=1-0.9 z^{-1}+0.08 z^{-2},\\qquad B_{\\text{t}}(z)=0.36 z^{-1}-0.18 z^{-2},$$\nand using the regulation control law $U(z)=-S(z)Y(z)$ (the reference path does not affect the poles), the true closed-loop characteristic polynomial is\n$$A_{\\text{cl}}(z)=A_{\\text{t}}(z)+B_{\\text{t}}(z)S(z).$$\nWith $S(z)=s_{0}=-5/18$,\n$$B_{\\text{t}}(z)S(z)=\\left(0.36 z^{-1}-0.18 z^{-2}\\right)\\left(-\\frac{5}{18}\\right)=-0.1\\,z^{-1}+0.05\\,z^{-2}.$$\nTherefore,\n$$A_{\\text{cl}}(z)=1-\\left(0.9+0.1\\right)z^{-1}+\\left(0.08+0.05\\right)z^{-2}=1-1.0\\,z^{-1}+0.13\\,z^{-2}.$$\nMultiplying by $z^{2}$ gives the characteristic equation\n$$z^{2}-z+0.13=0.$$\nIts roots are\n$$z=\\frac{1\\pm\\sqrt{1-4\\cdot 0.13}}{2}=\\frac{1\\pm\\sqrt{0.48}}{2}.$$\nSince $\\sqrt{0.48}\\approx 0.692820323$, the poles are approximately $0.8464101615$ and $0.1535898385$. The pole with the largest magnitude is approximately $0.8464101615$, which rounded to four significant figures is $0.8464$.", "answer": "$$\\boxed{0.8464}$$", "id": "1608473"}, {"introduction": "A self-tuning regulator is a truly dynamic system where the estimation and control algorithms continuously interact. This final exercise provides a hands-on, step-by-step simulation of the complete adaptive loop, revealing the interplay between a Recursive Least Squares (RLS) estimator and the control law in the face of significant model mismatch [@problem_id:1608433]. Importantly, it introduces the practical concept of supervisory logic, demonstrating how to implement safeguards that freeze parameter updates to prevent instability when the model's predictive performance degrades.", "problem": "A self-tuning regulator is implemented for a process whose true dynamics are unknown to the controller designer. The regulator consists of a parameter estimator and a controller. The parameter estimator attempts to identify a first-order model for the process, while the process itself is known to be of a higher order, creating a structural model-plant mismatch.\n\nThe true process dynamics are described by the second-order discrete-time equation:\n$$y(k) = 0.8 y(k-1) + 0.1 y(k-2) + 0.5 u(k-1)$$\nwhere $y(k)$ is the process output and $u(k)$ is the control input at time step $k$. The initial conditions are $y(k) = 0$ and $u(k) = 0$ for all $k \\leq 0$.\n\nThe self-tuning regulator is based on an assumed first-order model:\n$$\\hat{y}(k|k-1) = \\hat{a}(k-1) y(k-1) + \\hat{b}(k-1) u(k-1) = \\phi^T(k-1) \\theta_e(k-1)$$\nwhere $\\hat{y}(k|k-1)$ is the one-step-ahead prediction of the output, $\\phi(k-1) = [y(k-1), u(k-1)]^T$ is the regressor vector, and $\\theta_e(k) = [\\hat{a}(k), \\hat{b}(k)]^T$ is the vector of estimated parameters.\n\nThe parameters in $\\theta_e(k)$ are updated at each step $k \\geq 1$ using a Recursive Least Squares (RLS) algorithm with a forgetting factor $\\lambda = 0.98$. The initial parameter estimates are $\\theta_e(0) = [0.9, 0.5]^T$, and the initial covariance matrix is $P(0) = 10I$, where $I$ is the $2 \\times 2$ identity matrix.\n\nThe control law is a direct adaptive controller designed to make the output $y(k)$ track a reference signal $r(k)$. The control input is calculated as:\n$$u(k) = \\frac{1}{\\hat{b}(k)} (r(k+1) - \\hat{a}(k) y(k))$$\nThe reference signal is a unit step, i.e., $r(k) = 1.0$ for all $k \\ge 1$.\n\nTo prevent parameter drift and instability when the model is clearly inadequate, a supervisory logic layer is added. This logic freezes the RLS parameter updates if the model's prediction performance degrades significantly. The condition for freezing the updates at time step $k_f$ is that the magnitude of the one-step-ahead prediction error, $\\epsilon(j) = y(j) - \\hat{y}(j|j-1)$, exceeds a threshold $\\epsilon_{max} = 0.05$ for $N=2$ consecutive time steps.\n\nDetermine the smallest integer time step $k_f \\geq N$ at which the parameter estimation is frozen.", "solution": "The true plant is\n$$y(k)=0.8\\,y(k-1)+0.1\\,y(k-2)+0.5\\,u(k-1),$$\nand the one-step predictor used by the estimator is\n$$\\hat{y}(k|k-1)=\\hat{a}(k-1)\\,y(k-1)+\\hat{b}(k-1)\\,u(k-1)=\\phi^{T}(k-1)\\,\\theta_{e}(k-1),\\quad \\phi(k-1)=\\begin{bmatrix}y(k-1)\\\\ u(k-1)\\end{bmatrix}.$$\nThe RLS with forgetting factor updates at each step are\n$$\\epsilon(k)=y(k)-\\phi^{T}(k-1)\\,\\theta_{e}(k-1),$$\n$$S(k)=\\lambda+\\phi^{T}(k-1)\\,P(k-1)\\,\\phi(k-1),\\quad K(k)=\\frac{P(k-1)\\,\\phi(k-1)}{S(k)},$$\n$$\\theta_{e}(k)=\\theta_{e}(k-1)+K(k)\\,\\epsilon(k),\\quad P(k)=\\frac{1}{\\lambda}\\left[P(k-1)-K(k)\\,\\phi^{T}(k-1)\\,P(k-1)\\right],$$\nwith $\\lambda=0.98$, $\\theta_{e}(0)=\\begin{bmatrix}0.9\\\\ 0.5\\end{bmatrix}$, $P(0)=10I$. The control law is\n$$u(k)=\\frac{1}{\\hat{b}(k)}\\left(r(k+1)-\\hat{a}(k)\\,y(k)\\right),\\quad r(k)=1\\ \\text{for}\\ k\\geq 1.$$\nBy construction, using $\\theta_{e}(k)$ in the control law yields $\\hat{y}(k+1|k)=\\hat{a}(k)\\,y(k)+\\hat{b}(k)\\,u(k)=r(k+1)=1$ for $k\\geq 0$.\n\nWe propagate from the initial conditions $y(k)=0$, $u(k)=0$ for $k\\leq 0$.\n\nStep k=0 to k=1:\n- Control: $u(0)=\\frac{1}{0.5}\\left(r(1)-0.9\\,y(0)\\right)=2$.\n- Plant: $y(1)=0.8\\,y(0)+0.1\\,y(-1)+0.5\\,u(0)=1$.\n- Prediction: $\\hat{y}(1|0)=0.9\\,y(0)+0.5\\,u(0)=1$.\n- Error: $\\epsilon(1)=y(1)-\\hat{y}(1|0)=0$.\n- RLS update with $\\phi(0)=\\begin{bmatrix}0\\\\ 2\\end{bmatrix}$:\n$$S(1)=\\lambda+\\phi^{T}(0)P(0)\\phi(0)=0.98+10\\cdot 4=40.98,$$\n$$K(1)=\\frac{P(0)\\phi(0)}{S(1)}=\\frac{10I\\,\\begin{bmatrix}0\\\\ 2\\end{bmatrix}}{40.98}=\\begin{bmatrix}0\\\\ 20/40.98\\end{bmatrix},$$\n$$\\theta_{e}(1)=\\theta_{e(0)}+K(1)\\epsilon(1)=\\begin{bmatrix}0.9\\\\ 0.5\\end{bmatrix},$$\n$$P(1)=\\frac{1}{0.98}\\left[10I-K(1)\\,\\phi^{T}(0)\\,10I\\right]=\\frac{1}{0.98}\\begin{bmatrix}10 & 0\\\\ 0 & 10-\\frac{400}{40.98}\\end{bmatrix}\\approx\\begin{bmatrix}10.20408 & 0\\\\ 0 & 0.24404\\end{bmatrix}.$$\n\nStep k=1 to k=2:\n- Control: $u(1)=\\frac{1}{0.5}(1-0.9\\,y(1))=0.2$.\n- Plant: $y(2)=0.8\\,y(1)+0.1\\,y(0)+0.5\\,u(1)=0.9$.\n- Prediction: $\\hat{y}(2|1)=0.9\\,y(1)+0.5\\,u(1)=1$.\n- Error: $\\epsilon(2)=y(2)-\\hat{y}(2|1)=-0.1$, so $|\\epsilon(2)|=0.1>\\epsilon_{\\max}=0.05$ (first exceedance).\n- RLS update with $\\phi(1)=\\begin{bmatrix}1\\\\ 0.2\\end{bmatrix}$:\n$$S(2)=0.98+\\phi^{T}(1)P(1)\\phi(1)=0.98+10.20408+0.24404\\cdot 0.04\\approx 11.1938416,$$\n$$K(2)=\\frac{P(1)\\phi(1)}{S(2)}=\\frac{\\begin{bmatrix}10.20408\\\\ 0.24404\\cdot 0.2\\end{bmatrix}}{11.1938416}\\approx\\begin{bmatrix}0.911464\\\\ 0.004362\\end{bmatrix},$$\n$$\\theta_{e}(2)=\\theta_{e}(1)+K(2)\\epsilon(2)\\approx\\begin{bmatrix}0.9\\\\ 0.5\\end{bmatrix}+\\begin{bmatrix}0.911464\\\\ 0.004362\\end{bmatrix}(-0.1)\\approx\\begin{bmatrix}0.808854\\\\ 0.499564\\end{bmatrix}.$$\n\nStep k=2 to k=3:\n- Control using $\\theta_{e}(2)$ and $y(2)=0.9$:\n$$u(2)=\\frac{1}{0.499564}\\left(1-0.808854\\cdot 0.9\\right)\\approx 0.54454.$$\n- Plant:\n$$y(3)=0.8\\,y(2)+0.1\\,y(1)+0.5\\,u(2)=0.8\\cdot 0.9+0.1\\cdot 1+0.5\\cdot 0.54454\\approx 1.09227.$$\n- Prediction: $\\hat{y}(3|2)=1$ (by the control law).\n- Error: $\\epsilon(3)=y(3)-\\hat{y}(3|2)\\approx 1.09227-1=0.09227$, so $|\\epsilon(3)|\\approx 0.09227>0.05$.\n\nThus, $|\\epsilon(2)|>0.05$ and $|\\epsilon(3)|>0.05$ occur at two consecutive time steps. The smallest $k_{f}\\geq N$ satisfying the supervisory condition is therefore $k_{f}=3$ (freezing occurs at the time the second consecutive exceedance is observed).", "answer": "$$\\boxed{3}$$", "id": "1608433"}]}