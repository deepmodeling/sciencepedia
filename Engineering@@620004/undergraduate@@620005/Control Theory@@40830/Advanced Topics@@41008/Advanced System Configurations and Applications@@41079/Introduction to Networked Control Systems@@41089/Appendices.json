{"hands_on_practices": [{"introduction": "This first exercise provides a concrete, step-by-step walkthrough of how a system's state evolves under the combined influence of communication delay and signal quantization. By manually calculating the state trajectory, you will gain a hands-on intuition for how these two fundamental network-induced impairments directly impact system behavior. This practice [@problem_id:1584097] is essential for understanding the tangible challenges faced in networked control.", "problem": "The evolution of a system's state $x_k$ at discrete time step $k$ is described by the following difference equation, which models a process with inherent feedback delay:\n$$x_{k+1} = a x_{k-1} + Q(u_{k-1})$$\nIn this model, $a$ is a constant system parameter. The term $u_{k-1}$ represents the controller command generated at time step $k-1$. The function $Q(\\cdot)$ models the effect of quantization that occurs when transmitting this command over a digital communication network.\n\nThe controller is a simple proportional type, generating a command $u_j = -c x_j$ at any given time step $j$, where $c$ is the controller gain. The quantization function is a uniform mid-tread quantizer with a step size $\\Delta$. Its mathematical definition is $Q(y) = \\Delta \\cdot \\lfloor y/\\Delta + 0.5 \\rfloor$, where $\\lfloor \\cdot \\rfloor$ is the floor function.\n\nYou are given the following parameters and initial conditions:\n- System parameter: $a = 0.8$\n- Controller gain: $c = 1.2$\n- Quantization step size: $\\Delta = 0.1$\n- Initial conditions: $x_{-1} = 0.3$ and $x_0 = 0.5$\n\nYour task is to determine the state of the system at time step $k=3$. Calculate the value of $x_3$ and provide your answer rounded to three significant figures.", "solution": "We use the given delayed difference equation and controller with quantization:\n$$x_{k+1} = a x_{k-1} + Q(u_{k-1}), \\quad u_{j} = -c x_{j}, \\quad Q(y) = \\Delta \\left\\lfloor \\frac{y}{\\Delta} + 0.5 \\right\\rfloor.$$\nParameters and initial conditions are $a=0.8$, $c=1.2$, $\\Delta=0.1$, $x_{-1}=0.3$, $x_{0}=0.5$.\n\nFirst, compute $x_{1}$ by setting $k=0$:\n$$u_{-1} = -c x_{-1} = -1.2 \\cdot 0.3 = -0.36,$$\n$$\\frac{u_{-1}}{\\Delta} + 0.5 = \\frac{-0.36}{0.1} + 0.5 = -3.6 + 0.5 = -3.1,$$\n$$\\left\\lfloor -3.1 \\right\\rfloor = -4 \\;\\Rightarrow\\; Q(u_{-1}) = 0.1 \\cdot (-4) = -0.4,$$\n$$x_{1} = a x_{-1} + Q(u_{-1}) = 0.8 \\cdot 0.3 + (-0.4) = 0.24 - 0.4 = -0.16.$$\n\nNext, compute $x_{2}$ by setting $k=1$:\n$$u_{0} = -c x_{0} = -1.2 \\cdot 0.5 = -0.6,$$\n$$\\frac{u_{0}}{\\Delta} + 0.5 = \\frac{-0.6}{0.1} + 0.5 = -6 + 0.5 = -5.5,$$\n$$\\left\\lfloor -5.5 \\right\\rfloor = -6 \\;\\Rightarrow\\; Q(u_{0}) = 0.1 \\cdot (-6) = -0.6,$$\n$$x_{2} = a x_{0} + Q(u_{0}) = 0.8 \\cdot 0.5 + (-0.6) = 0.4 - 0.6 = -0.2.$$\n\nFinally, compute $x_{3}$ by setting $k=2$:\n$$u_{1} = -c x_{1} = -1.2 \\cdot (-0.16) = 0.192,$$\n$$\\frac{u_{1}}{\\Delta} + 0.5 = \\frac{0.192}{0.1} + 0.5 = 1.92 + 0.5 = 2.42,$$\n$$\\left\\lfloor 2.42 \\right\\rfloor = 2 \\;\\Rightarrow\\; Q(u_{1}) = 0.1 \\cdot 2 = 0.2,$$\n$$x_{3} = a x_{1} + Q(u_{1}) = 0.8 \\cdot (-0.16) + 0.2 = -0.128 + 0.2 = 0.072.$$\n\nRounded to three significant figures, $x_{3} = 7.20 \\times 10^{-2}$.", "answer": "$$\\boxed{7.20 \\times 10^{-2}}$$", "id": "1584097"}, {"introduction": "Building on the idea of network imperfections, this problem introduces the uncertainty of packet loss, a defining characteristic of many networked systems. You will model this randomness using a probabilistic framework and analyze its effect on system stability through the lens of mean-square stability. This exercise [@problem_id:1584108] is crucial for learning how to provide robust stability guarantees for systems operating over unreliable communication channels.", "problem": "Consider a simple discrete-time integrator plant used to model the velocity of a lightweight autonomous agent. The state of the system is its velocity, $x_k \\in \\mathbb{R}$, at time step $k$. The system dynamics are described by the difference equation:\n$$x_{k+1} = x_k + T_s u_k$$\nwhere $T_s > 0$ is the constant sampling time and $u_k$ is the control input (proportional to acceleration) applied at time step $k$.\n\nThe control input is determined by a remote proportional controller using state feedback, according to the law $u_k = -K x_k$, where $K > 0$ is the controller gain. The control signal is transmitted to the agent over a wireless network, which is unreliable and may lose packets.\n\nThe success or failure of the packet transmission at each time step $k$ is modeled by an independent and identically distributed Bernoulli random variable, $\\gamma_k$. If the packet is successfully received, $\\gamma_k = 1$. If the packet is lost, $\\gamma_k = 0$. The probability of a successful transmission is $P(\\gamma_k = 1) = p$, where $0 < p \\leq 1$.\n\nThe agent's actuator is designed with a simple safety protocol: if a control packet is lost, it applies a zero control input. Otherwise, it applies the received control input. Therefore, the actually applied control input at time step $k$, denoted $u_{applied, k}$, is given by $u_{applied, k} = \\gamma_k u_k$.\n\nThe system is defined to be mean-square stable if the expected value of the squared state, $\\mathbb{E}[x_k^2]$, converges to zero as $k$ approaches infinity, for any non-zero initial state $x_0$. This is guaranteed if the condition $\\mathbb{E}[x_{k+1}^2] < \\mathbb{E}[x_k^2]$ holds for any $x_k \\neq 0$.\n\nDetermine the maximum value of the positive controller gain, $K_{max}$, beyond which the system is no longer guaranteed to be mean-square stable. Express your answer for $K_{max}$ in terms of the packet arrival probability $p$ and the sampling time $T_s$.", "solution": "The applied control due to packet drops is $u_{\\text{applied},k}=\\gamma_{k}u_{k}=\\gamma_{k}(-Kx_{k})$, so the closed-loop state update is\n$$\nx_{k+1}=x_{k}+T_{s}u_{\\text{applied},k}=\\bigl(1-\\gamma_{k}KT_{s}\\bigr)x_{k}.\n$$\nWith $\\gamma_{k}$ i.i.d. Bernoulli with $P(\\gamma_{k}=1)=p$ and independent of $x_{k}$, the conditional second moment evolves as\n$$\n\\mathbb{E}\\!\\left[x_{k+1}^{2}\\mid x_{k}\\right]=x_{k}^{2}\\,\\mathbb{E}\\!\\left[(1-\\gamma_{k}KT_{s})^{2}\\right]\n=x_{k}^{2}\\Bigl[p(1-KT_{s})^{2}+(1-p)\\cdot 1^{2}\\Bigr].\n$$\nTaking expectation over $x_{k}$,\n$$\n\\mathbb{E}[x_{k+1}^{2}]=\\alpha\\,\\mathbb{E}[x_{k}^{2}],\\qquad \\alpha:=p(1-KT_{s})^{2}+(1-p).\n$$\nThe given sufficient condition for mean-square stability is $\\mathbb{E}[x_{k+1}^{2}]<\\mathbb{E}[x_{k}^{2}]$ for any $x_{k}\\neq 0$, which here is equivalent to\n$$\n\\alpha<1 \\;\\;\\Longleftrightarrow\\;\\; p(1-KT_{s})^{2}+(1-p)<1 \\;\\;\\Longleftrightarrow\\;\\; p\\bigl((1-KT_{s})^{2}-1\\bigr)<0.\n$$\nSince $p>0$, this reduces to\n$$\n(1-KT_{s})^{2}<1 \\;\\;\\Longleftrightarrow\\;\\; |1-KT_{s}|<1 \\;\\;\\Longleftrightarrow\\;\\; 0<KT_{s}<2.\n$$\nThus the admissible gains are $0<K<\\frac{2}{T_{s}}$, and the largest gain at the stability boundary is\n$$\nK_{\\max}=\\frac{2}{T_{s}}.\n$$\nNotably, for any $p\\in(0,1]$, the threshold does not depend on $p$; when $p=0$ the condition cannot be satisfied, but $p=0$ is excluded by $0<p\\leq 1$.", "answer": "$$\\boxed{\\frac{2}{T_{s}}}$$", "id": "1584108"}, {"introduction": "When sensor data is lost due to packet drop, a remote estimator must still provide a state estimate. This practice [@problem_id:1584083] explores this critical scenario by having you quantitatively compare two intuitive strategies: holding the last known estimate versus predicting the state forward using the system model. By rigorously analyzing the mean squared estimation error for each approach, you will develop critical skills for designing and evaluating state estimation algorithms in the presence of intermittent data.", "problem": "A remote sensor is monitoring a physical process whose state, $x_k$, at discrete time step $k$ evolves according to the linear stochastic model:\n$$x_{k+1} = a x_k + w_k$$\nHere, $a$ is a constant system parameter with $|a| < 1$, and $w_k$ is a zero-mean, white process noise with variance $E[w_k^2] = Q$. The process is assumed to be wide-sense stationary.\n\nA remote estimator tracks this state. At time $k=0$, the estimate of the state is $\\hat{x}_0$, and the mean squared estimation error is $E[(x_0 - \\hat{x}_0)^2] = P_0$. The initial estimation error, $e_0 = x_0 - \\hat{x}_0$, has zero mean and is uncorrelated with both the estimate $\\hat{x}_0$ and the process noise sequence $w_k$.\n\nAt time step $k=1$, the sensor measurement is lost due to a network packet drop. The estimator must still produce an estimate $\\hat{x}_1$ for the state $x_1$ without the benefit of a new measurement. Two strategies are being considered:\n\n*   **Strategy A (Hold):** Set the new estimate equal to the previous estimate, $\\hat{x}_1^{(\\text{A})} = \\hat{x}_0$.\n*   **Strategy B (Predict):** Propagate the previous estimate through the system model, $\\hat{x}_1^{(\\text{B})} = a \\hat{x}_0$.\n\nDetermine the ratio of the true mean squared estimation errors for these two strategies, $\\frac{E[(x_1 - \\hat{x}_1^{(\\text{A})})^2]}{E[(x_1 - \\hat{x}_1^{(\\text{B})})^2]}$. Express your answer as a single closed-form analytic expression in terms of $a$, $Q$, and $P_0$.", "solution": "The state evolves as $x_{1} = a x_{0} + w_{0}$ with $E[w_{0}] = 0$, $E[w_{0}^{2}] = Q$, and $|a| < 1$. The initial estimation error is $e_{0} = x_{0} - \\hat{x}_{0}$ with $E[e_{0}] = 0$, $E[e_{0}^{2}] = P_{0}$, and $e_{0}$ uncorrelated with $\\hat{x}_{0}$ and with the process noise sequence $\\{w_{k}\\}$. As is standard for such models, $w_{0}$ is taken uncorrelated with $x_{0}$ and with any estimator based on data up to time $0$, hence with $\\hat{x}_{0}$.\n\nStrategy B (Predict): $\\hat{x}_{1}^{(\\text{B})} = a \\hat{x}_{0}$. The estimation error is\n$$\ne_{1}^{(\\text{B})} = x_{1} - \\hat{x}_{1}^{(\\text{B})} = a x_{0} + w_{0} - a \\hat{x}_{0} = a(x_{0} - \\hat{x}_{0}) + w_{0} = a e_{0} + w_{0}.\n$$\nUsing uncorrelatedness of $e_{0}$ and $w_{0}$, the mean squared error (MSE) is\n$$\nE[(e_{1}^{(\\text{B})})^{2}] = a^{2} E[e_{0}^{2}] + E[w_{0}^{2}] = a^{2} P_{0} + Q.\n$$\n\nStrategy A (Hold): $\\hat{x}_{1}^{(\\text{A})} = \\hat{x}_{0}$. The estimation error is\n$$\ne_{1}^{(\\text{A})} = x_{1} - \\hat{x}_{0} = a x_{0} + w_{0} - \\hat{x}_{0}.\n$$\nIts MSE is\n$$\nE[(e_{1}^{(\\text{A})})^{2}] = E[(a x_{0} - \\hat{x}_{0})^{2}] + 2 E[(a x_{0} - \\hat{x}_{0}) w_{0}] + E[w_{0}^{2}].\n$$\nSince $w_{0}$ is uncorrelated with $x_{0}$ and $\\hat{x}_{0}$, the cross term vanishes and\n$$\nE[(e_{1}^{(\\text{A})})^{2}] = E[(a x_{0} - \\hat{x}_{0})^{2}] + Q.\n$$\nExpand\n$$\nE[(a x_{0} - \\hat{x}_{0})^{2}] = a^{2} E[x_{0}^{2}] - 2 a E[x_{0} \\hat{x}_{0}] + E[\\hat{x}_{0}^{2}].\n$$\nFrom $e_{0} = x_{0} - \\hat{x}_{0}$ uncorrelated with $\\hat{x}_{0}$, $E[(x_{0} - \\hat{x}_{0}) \\hat{x}_{0}] = 0$, so\n$$\nE[x_{0} \\hat{x}_{0}] = E[\\hat{x}_{0}^{2}].\n$$\nAlso, by definition of $P_{0}$,\n$$\nP_{0} = E[(x_{0} - \\hat{x}_{0})^{2}] = E[x_{0}^{2}] - 2 E[x_{0} \\hat{x}_{0}] + E[\\hat{x}_{0}^{2}] = E[x_{0}^{2}] - E[\\hat{x}_{0}^{2}],\n$$\nhence $E[\\hat{x}_{0}^{2}] = E[x_{0}^{2}] - P_{0}$. Therefore,\n$$\nE[(a x_{0} - \\hat{x}_{0})^{2}] = a^{2} E[x_{0}^{2}] - 2 a \\big(E[x_{0}^{2}] - P_{0}\\big) + \\big(E[x_{0}^{2}] - P_{0}\\big)\n= (a - 1)^{2} E[x_{0}^{2}] - (1 - 2 a) P_{0}.\n$$\nThus\n$$\nE[(e_{1}^{(\\text{A})})^{2}] = (a - 1)^{2} E[x_{0}^{2}] - (1 - 2 a) P_{0} + Q.\n$$\nUsing wide-sense stationarity of $x_{k}$ for the AR(1) model, let $\\sigma_{x}^{2} = E[x_{k}^{2}]$. Then\n$$\n\\sigma_{x}^{2} = E[x_{k+1}^{2}] = E[(a x_{k} + w_{k})^{2}] = a^{2} \\sigma_{x}^{2} + 2 a E[x_{k} w_{k}] + E[w_{k}^{2}] = a^{2} \\sigma_{x}^{2} + Q,\n$$\nso $\\sigma_{x}^{2} = \\frac{Q}{1 - a^{2}}$. Hence\n$$\nE[(e_{1}^{(\\text{A})})^{2}] = (a - 1)^{2} \\frac{Q}{1 - a^{2}} - (1 - 2 a) P_{0} + Q.\n$$\nNote that\n$$\n\\frac{(a - 1)^{2}}{1 - a^{2}} = \\frac{(1 - a)^{2}}{(1 - a)(1 + a)} = \\frac{1 - a}{1 + a},\n$$\nso\n$$\nE[(e_{1}^{(\\text{A})})^{2}] = \\frac{1 - a}{1 + a} Q + Q - (1 - 2 a) P_{0} = \\frac{2 Q}{1 + a} - (1 - 2 a) P_{0}.\n$$\n\nTherefore, the required ratio is\n$$\n\\frac{E[(x_{1} - \\hat{x}_{1}^{(\\text{A})})^{2}]}{E[(x_{1} - \\hat{x}_{1}^{(\\text{B})})^{2}]} = \\frac{\\frac{2 Q}{1 + a} - (1 - 2 a) P_{0}}{a^{2} P_{0} + Q}.\n$$\nThis is a single closed-form analytic expression in terms of $a$, $Q$, and $P_{0}$.", "answer": "$$\\boxed{\\frac{\\frac{2Q}{1+a}-(1-2a)P_{0}}{a^{2}P_{0}+Q}}$$", "id": "1584083"}]}