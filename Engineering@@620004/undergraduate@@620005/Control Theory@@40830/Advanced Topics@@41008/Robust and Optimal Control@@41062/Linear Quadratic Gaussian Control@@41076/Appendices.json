{"hands_on_practices": [{"introduction": "This practice focuses on the \"G\" in LQG—the Gaussian state estimation performed by a Kalman filter. Before we can effectively control a system, we often need a reliable estimate of its state, especially when our sensors provide only noisy measurements. This exercise [@problem_id:1589190] explores the core mechanism of the Kalman filter, the estimation error covariance $P$, demonstrating how the filter quantifies its own uncertainty and how quickly this uncertainty can be reduced by processing measurements, which is fundamental to understanding its performance.", "problem": "Consider the problem of estimating a dimensionless scalar state, $x_k$, which represents a normalized temperature in a slow chemical process at discrete time steps $k$. The state evolves according to the linear stochastic difference equation:\n$$x_{k+1} = A x_k + w_k$$\nA sensor provides measurements, $z_k$, related to the state by:\n$$z_k = H x_k + v_k$$\nThe system parameters are given as $A=1$ and $H=1$. The process noise, $w_k$, and measurement noise, $v_k$, are independent, zero-mean, white Gaussian noise sequences with variances $Q=0.1$ and $R=0.5$, respectively.\n\nAt time $k=0$, there is an initial estimate of the state, $\\hat{x}_{0|0} = 10$. To investigate the impact of initial uncertainty on a Kalman filter's performance, we consider two scenarios for the initial estimate error covariance, $P_{0|0}$:\n- **Case A**: High initial uncertainty, $P_{0|0, A} = 100$.\n- **Case B**: Moderate initial uncertainty, $P_{0|0, B} = 1$.\n\nAt time step $k=1$, a measurement is received from the sensor, yielding $z_1 = 12$.\n\nYour task is to calculate the updated estimate error covariance, $P_{1|1}$, for both Case A and Case B after processing the measurement $z_1$. The final answer should be a row matrix with two elements, $[P_{1|1, A}, P_{1|1, B}]$, where the first element corresponds to Case A and the second to Case B. Round your numerical answers to three significant figures.", "solution": "We use the scalar Kalman filter covariance recursion. The time update (prediction) for the covariance is\n$$\nP_{k+1|k} = A P_{k|k} A^{\\top} + Q.\n$$\nWith $A=1$, this simplifies to\n$$\nP_{k+1|k} = P_{k|k} + Q.\n$$\nThe measurement update uses the innovation covariance\n$$\nS_{k+1} = H P_{k+1|k} H^{\\top} + R,\n$$\nthe Kalman gain\n$$\nK_{k+1} = P_{k+1|k} H^{\\top} S_{k+1}^{-1},\n$$\nand the posterior covariance\n$$\nP_{k+1|k+1} = (I - K_{k+1} H) P_{k+1|k}.\n$$\nFor the scalar case with $H=1$, these become\n$$\nS_{k+1} = P_{k+1|k} + R,\\quad K_{k+1} = \\frac{P_{k+1|k}}{P_{k+1|k} + R},\\quad P_{k+1|k+1} = \\left(1 - \\frac{P_{k+1|k}}{P_{k+1|k} + R}\\right) P_{k+1|k}.\n$$\nHence,\n$$\nP_{k+1|k+1} = \\frac{R\\,P_{k+1|k}}{P_{k+1|k} + R}.\n$$\n\nApply to $k=0 \\to 1$ with $Q=0.1$ and $R=0.5$.\n\nCase A: $P_{0|0,A} = 100$.\nPrediction:\n$$\nP_{1|0,A} = 100 + 0.1 = 100.1.\n$$\nUpdate:\n$$\nP_{1|1,A} = \\frac{0.5 \\times 100.1}{100.1 + 0.5} = \\frac{50.05}{100.6} = \\frac{1001}{2012} \\approx 0.497515 \\;\\Rightarrow\\; 0.498\\ \\text{to three significant figures}.\n$$\n\nCase B: $P_{0|0,B} = 1$.\nPrediction:\n$$\nP_{1|0,B} = 1 + 0.1 = 1.1.\n$$\nUpdate:\n$$\nP_{1|1,B} = \\frac{0.5 \\times 1.1}{1.1 + 0.5} = \\frac{0.55}{1.6} = 0.34375 \\;\\Rightarrow\\; 0.344\\ \\text{to three significant figures}.\n$$\n\nNote that the measurement value $z_{1}$ affects the state estimate but not the covariance; thus it does not enter the $P_{1|1}$ calculation.", "answer": "$$\\boxed{\\begin{pmatrix}0.498 & 0.344\\end{pmatrix}}$$", "id": "1589190"}, {"introduction": "Once we have a good state estimate, the next challenge is to compute an optimal control action. This is the domain of the \"LQ\" part of LQG: the Linear-Quadratic Regulator. This exercise [@problem_id:1589177] delves into the art of tuning an LQR controller for the classic inverted pendulum model. By manipulating the weighting matrix $Q$ in the cost function, you will see how an engineer can prioritize different control objectives, such as aggressively damping velocity versus minimizing position error, and directly influence the resulting feedback gains.", "problem": "A control engineer is designing a controller for a simplified model of an inverted pendulum on a cart. The linearized dynamics of the pendulum around its upright unstable equilibrium are given by the state-space model $\\dot{x} = Ax + Bu$, where the state vector is $x = [\\theta, \\dot{\\theta}]^T$, representing the angle from the vertical and the angular velocity, respectively. The control input $u$ is a scaled representation of the horizontal force applied to the cart. The system matrices are:\n$$ A = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\nThe engineer uses the Linear Quadratic Regulator (LQR) method to design the state feedback controller $u = -Kx = -[k_{\\theta}, k_{\\dot{\\theta}}]x$. The goal is to find the optimal gain matrix $K$ that minimizes the quadratic cost functional $J = \\int_{0}^{\\infty} (x^T Q x + u^T R u) dt$.\n\nThe engineer considers two different designs based on two different sets of weighting matrices:\n1.  **Design 1:** The weighting matrices are $Q_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ and $R_1 = 1$. This design results in an optimal gain matrix $K_1 = [k_{\\theta,1}, k_{\\dot{\\theta},1}]$.\n2.  **Design 2:** The weighting matrices are $Q_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 100 \\end{pmatrix}$ and $R_2 = 1$. This design results in an optimal gain matrix $K_2 = [k_{\\theta,2}, k_{\\dot{\\theta},2}]$.\n\nCalculate the ratio of the angular velocity feedback gain from Design 2 to that of Design 1, which is $k_{\\dot{\\theta},2} / k_{\\dot{\\theta},1}$. Round your final answer to three significant figures.", "solution": "We use the continuous-time LQR setup. For the system $\\dot{x}=Ax+Bu$ with $A=\\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}$, $B=\\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$, $Q=\\operatorname{diag}(q_{1},q_{2})$, and $R=1$, the optimal gain is $K=R^{-1}B^{T}P=B^{T}P$, where $P=P^{T}\\succeq 0$ solves the continuous-time algebraic Riccati equation\n$$\nA^{T}P+PA-PBR^{-1}B^{T}P+Q=0.\n$$\nLet $P=\\begin{pmatrix}p_{11} & p_{12} \\\\ p_{12} & p_{22}\\end{pmatrix}$. Compute each term:\n- $A^{T}P+PA=\\begin{pmatrix}2p_{12} & p_{11}+p_{22} \\\\ p_{11}+p_{22} & 2p_{12}\\end{pmatrix}$,\n- $PBR^{-1}B^{T}P=PB B^{T}P=(PB)(PB)^{T}$ with $PB=\\begin{pmatrix}p_{12} \\\\ p_{22}\\end{pmatrix}$, hence\n$$\nPBR^{-1}B^{T}P=\\begin{pmatrix}p_{12}^{2} & p_{12}p_{22} \\\\ p_{12}p_{22} & p_{22}^{2}\\end{pmatrix}.\n$$\nThe Riccati equation yields the elementwise system\n$$\n\\begin{aligned}\n& (1,1):\\quad 2p_{12}+q_{1}-p_{12}^{2}=0, \\\\\n& (1,2):\\quad p_{11}+p_{22}-p_{12}p_{22}=0, \\\\\n& (2,2):\\quad 2p_{12}+q_{2}-p_{22}^{2}=0.\n\\end{aligned}\n$$\nFrom $(1,1)$, solve the quadratic for $p_{12}$:\n$$\np_{12}^{2}-2p_{12}-q_{1}=0 \\;\\;\\Rightarrow\\;\\; p_{12}=1\\pm\\sqrt{1+q_{1}}.\n$$\nFor the stabilizing LQR solution with $P\\succeq 0$, we require $p_{11}=p_{22}(p_{12}-1)\\geq 0$, which selects $p_{12}=1+\\sqrt{1+q_{1}}$. Then from $(2,2)$,\n$$\np_{22}^{2}=2p_{12}+q_{2}=2\\bigl(1+\\sqrt{1+q_{1}}\\bigr)+q_{2},\n$$\nso with $p_{22}\\geq 0$ we have\n$$\np_{22}=\\sqrt{q_{2}+2+2\\sqrt{1+q_{1}}}.\n$$\nSince $K=B^{T}P=[p_{12},p_{22}]$, the angular velocity feedback gain is $k_{\\dot{\\theta}}=p_{22}$.\n\nApply this to the two designs:\n- Design 1: $q_{1}=1$, $q_{2}=1$ gives\n$$\nk_{\\dot{\\theta},1}=p_{22,1}=\\sqrt{1+2+2\\sqrt{2}}=\\sqrt{3+2\\sqrt{2}}=\\sqrt{2}+1.\n$$\n- Design 2: $q_{1}=1$, $q_{2}=100$ gives\n$$\nk_{\\dot{\\theta},2}=p_{22,2}=\\sqrt{100+2+2\\sqrt{2}}=\\sqrt{102+2\\sqrt{2}}.\n$$\nThus the ratio is\n$$\n\\frac{k_{\\dot{\\theta},2}}{k_{\\dot{\\theta},1}}=\\frac{\\sqrt{102+2\\sqrt{2}}}{\\sqrt{2}+1}=(\\sqrt{2}-1)\\sqrt{102+2\\sqrt{2}}.\n$$\nNumerically, this equals approximately $4.2409566$, which rounded to three significant figures is $4.24$.", "answer": "$$\\boxed{4.24}$$", "id": "1589177"}, {"introduction": "This final practice brings everything together, demonstrating the power of the complete LQG control architecture. We will tackle the challenge of stabilizing an inherently unstable system—a common task in fields like aerospace and robotics. By applying the celebrated separation principle, you will independently design a Kalman filter to estimate the hidden state from noisy data and an LQR to provide optimal feedback, synthesizing them into a single, powerful controller [@problem_id:1589180].", "problem": "An engineer is tasked with stabilizing a simple, yet inherently unstable, discrete-time process. The state of the process, denoted by $x_k$ at time step $k$, evolves according to the linear difference equation:\n$$x_{k+1} = 1.2 x_k + u_k + w_k$$\nwhere $u_k$ is the control input applied at time step $k$. The term $w_k$ represents process noise, modeled as a zero-mean Gaussian white noise sequence with a constant variance of $Q = 0.5$.\n\nThe state $x_k$ cannot be measured directly. Instead, a sensor provides a noisy measurement $y_k$, given by:\n$$y_k = x_k + v_k$$\nwhere $v_k$ is the measurement noise, modeled as a zero-mean Gaussian white noise sequence with a constant variance of $R = 0.2$. The noise sequences $w_k$ and $v_k$ are uncorrelated with each other and with the initial state $x_0$.\n\nThe control objective is to design a controller that stabilizes the system while minimizing the infinite-horizon quadratic cost function:\n$$J = \\sum_{k=0}^{\\infty} (q x_k^2 + r u_k^2)$$\nwith weighting factors $q=1$ and $r=1$. The resulting controller is a steady-state Linear-Quadratic-Gaussian (LQG) controller. This controller architecture uses a state estimator (a Kalman filter) to generate an estimate of the state, $\\hat{x}_{k|k}$, which is then used in a linear feedback law.\n\nThe steady-state controller is fully characterized by two constant gains:\n1. The state-feedback gain $K$, used in the control law $u_k = -K \\hat{x}_{k|k}$.\n2. The observer (Kalman) gain $L$, used in the state estimate update equation $\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + L(y_k - C\\hat{x}_{k|k-1})$, where $C=1$ for this system.\n\nDetermine the numerical values for the steady-state feedback gain $K$ and the steady-state Kalman gain $L$. Present your answers rounded to four significant figures. Your final answer should be a row matrix containing the value for $K$ followed by the value for $L$.", "solution": "We rewrite the system and cost in standard scalar LQG form. The plant is $x_{k+1} = a x_{k} + b u_{k} + w_{k}$ with $a=1.2$, $b=1$, and the output is $y_{k} = C x_{k} + v_{k}$ with $C=1$. The noise variances are $\\operatorname{Var}(w_{k})=Q=0.5$ and $\\operatorname{Var}(v_{k})=R=0.2$. The LQR cost is $J=\\sum_{k=0}^{\\infty} (q x_{k}^{2} + r u_{k}^{2})$ with $q=1$ and $r=1$.\n\nBy the separation principle, the steady-state LQG controller is obtained by independently solving:\n- the discrete-time LQR Algebraic Riccati Equation (DARE) for the state-cost matrix $S$ and feedback gain $K$, and\n- the steady-state Kalman filter Riccati equation for the prior error covariance $P$ and the Kalman gain $L$.\n\nLQR design (feedback gain K). For the scalar system, the DARE is\n$$\nS = a^{2} S - \\frac{a^{2} S^{2}}{r + b^{2} S} + q.\n$$\nMultiplying both sides by $(r + b^{2} S)$ and simplifying gives the quadratic in $S$:\n$$\nS^{2} + S\\big(r(1 - a^{2}) - q\\big) - q r = 0.\n$$\nWith $a=1.2$, $b=1$, $q=1$, $r=1$,\n$$\nS^{2} - 1.44 S - 1 = 0,\n$$\nwhose positive root is\n$$\nS = \\frac{1.44 + \\sqrt{1.44^{2} + 4}}{2} = \\frac{1.44 + \\sqrt{6.0736}}{2} \\approx 1.95223374.\n$$\nThe steady-state LQR gain is\n$$\nK = \\frac{b a S}{r + b^{2} S} = \\frac{a S}{r + S}.\n$$\nSubstituting $a=1.2$, $r=1$, $S\\approx 1.95223374$,\n$$\nK \\approx \\frac{1.2 \\times 1.95223374}{1 + 1.95223374} \\approx 0.7935 \\quad \\text{(four significant figures)}.\n$$\n\nKalman filter design (observer gain L). Let $P$ denote the steady-state prior error covariance $P_{k|k-1}$. The steady-state relations are\n$$\nP = a^{2} P^{+} + Q,\\quad P^{+} = (1 - L) P,\\quad L = \\frac{P}{P + R}.\n$$\nEliminating $P^{+}$ and $L$ gives\n$$\nP = a^{2} \\frac{P R}{P + R} + Q.\n$$\nMultiplying by $(P + R)$ and rearranging yields the quadratic in $P$:\n$$\nP^{2} + P\\big(R(1 - a^{2}) - Q\\big) - Q R = 0.\n$$\nWith $a=1.2$, $Q=0.5$, $R=0.2$,\n$$\nP^{2} - 0.588 P - 0.1 = 0,\n$$\nwhose positive root is\n$$\nP = \\frac{0.588 + \\sqrt{0.588^{2} + 0.4}}{2} = \\frac{0.588 + \\sqrt{0.745744}}{2} \\approx 0.725782345.\n$$\nThen the steady-state Kalman gain is\n$$\nL = \\frac{P}{P + R} \\approx \\frac{0.725782345}{0.725782345 + 0.2} \\approx 0.7840 \\quad \\text{(four significant figures)}.\n$$\n\nThus, the steady-state LQG gains are $K \\approx 0.7935$ and $L \\approx 0.7840$, as required to four significant figures.", "answer": "$$\\boxed{\\begin{pmatrix}0.7935 & 0.7840\\end{pmatrix}}$$", "id": "1589180"}]}