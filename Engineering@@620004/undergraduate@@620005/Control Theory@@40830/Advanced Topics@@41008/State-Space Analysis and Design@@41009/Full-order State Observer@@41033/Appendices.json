{"hands_on_practices": [{"introduction": "A primary challenge in control engineering is that not all state variables of a system are accessible for direct measurement. The full-order state observer, or Luenberger observer, provides an elegant solution by creating a mathematical model that estimates the entire state vector in real time. The core principle of observer design is to ensure that the estimation error, the difference between the true state $x$ and the estimated state $\\hat{x}$, converges to zero. This practice [@problem_id:1577274] walks you through the fundamental design procedure: calculating the observer gain matrix $L$ to place the poles of the error dynamics at specific locations, thereby dictating how quickly the observer's estimate converges to the true state of the system.", "problem": "A simplified model for the single-axis attitude dynamics of a small satellite is described by a linear time-invariant system. The state of the system is represented by the vector $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$, where $x_1$ is the angular position and $x_2$ is the angular velocity. The system dynamics are given by the state-space equations:\n\n$$\n\\dot{x} = Ax + Bu\n$$\n$$\ny = Cx\n$$\n\nThe system matrices are given as:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}\n$$\nThe matrix $B$ and the control input $u$ are part of the control system design and are not needed for this problem.\n\nDue to sensor limitations, only the angular position $x_1$ can be directly measured, as reflected by the output matrix $C$. To control the satellite effectively, an estimate of the full state vector $x$ is required. A Luenberger state observer is designed to provide this estimate, denoted by $\\hat{x}$. The performance of this observer is determined by the dynamics of the estimation error, $e = x - \\hat{x}$.\n\nYour task is to determine the observer gain matrix $L = \\begin{pmatrix} l_1 \\\\ l_2 \\end{pmatrix}$ that places the two eigenvalues (poles) of the estimation error dynamics at the desired locations $s_1 = -p_1$ and $s_2 = -p_2$, where $p_1$ and $p_2$ are distinct positive real constants that specify the desired speed of convergence for the observer.\n\nExpress the observer gain matrix $L$ as a column vector in terms of $p_1$ and $p_2$.", "solution": "A Luenberger observer for the system is defined by\n$$\n\\dot{\\hat{x}} = A \\hat{x} + B u + L\\big(y - C \\hat{x}\\big).\n$$\nDefine the estimation error $e = x - \\hat{x}$. Using the plant dynamics $\\dot{x} = A x + B u$ and the observer dynamics, the error dynamics are\n$$\n\\dot{e} = \\dot{x} - \\dot{\\hat{x}} = A x + B u - \\big(A \\hat{x} + B u + L(C x - C \\hat{x})\\big) = (A - L C)e.\n$$\nWith $A = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$, $C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$, and $L = \\begin{pmatrix} l_{1} \\\\ l_{2} \\end{pmatrix}$, we have\n$$\nA - L C = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} - \\begin{pmatrix} l_{1} \\\\ l_{2} \\end{pmatrix}\\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} -l_{1} & 1 \\\\ -l_{2} & 0 \\end{pmatrix}.\n$$\nThe characteristic polynomial of the error dynamics matrix is\n$$\n\\det\\big(s I - (A - L C)\\big) = \\det\\begin{pmatrix} s + l_{1} & -1 \\\\ l_{2} & s \\end{pmatrix} = s(s + l_{1}) + l_{2} = s^{2} + l_{1}s + l_{2}.\n$$\nThe desired error dynamics have eigenvalues at $s_{1} = -p_{1}$ and $s_{2} = -p_{2}$, so the desired characteristic polynomial is\n$$\n(s + p_{1})(s + p_{2}) = s^{2} + (p_{1} + p_{2})s + p_{1}p_{2}.\n$$\nMatching coefficients yields\n$$\nl_{1} = p_{1} + p_{2}, \\quad l_{2} = p_{1}p_{2}.\n$$\nTherefore, the observer gain is\n$$\nL = \\begin{pmatrix} p_{1} + p_{2} \\\\ p_{1}p_{2} \\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} p_{1}+p_{2} \\\\ p_{1}p_{2} \\end{pmatrix}}$$", "id": "1577274"}, {"introduction": "Simply ensuring that an observer's estimation error eventually converges to zero is often not enough; we also need to quantify its performance during the transient phase. How large can the error become before it settles? How does the total accumulated error depend on the initial mismatch between the true and estimated states? This exercise [@problem_id:1577282] moves beyond basic pole placement to a more rigorous performance analysis. By solving a Lyapunov equation, you will determine a bound on the integrated squared error, providing a concrete measure of the observer's effectiveness in suppressing initial estimation uncertainties.", "problem": "A second-order Linear Time-Invariant (LTI) system is described by the state-space model $\\dot{x}(t) = Ax(t)$ and $y(t) = Cx(t)$, where $x(t) \\in \\mathbb{R}^2$ is the state vector and $y(t) \\in \\mathbb{R}$ is the scalar output. The system matrices are given by:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}\n$$\nTo estimate the state vector $x(t)$, a Luenberger observer is implemented with the following dynamics:\n$$\n\\dot{\\hat{x}}(t) = A\\hat{x}(t) + L(y(t) - C\\hat{x}(t))\n$$\nwhere $\\hat{x}(t)$ is the estimated state. The observer gain matrix $L$ has been chosen as:\n$$\nL = \\begin{pmatrix} 6 \\\\ 0 \\end{pmatrix}\n$$\nThe estimation error is defined as $e(t) = x(t) - \\hat{x}(t)$. At time $t=0$, there is an initial mismatch between the true state and the estimated state, such that the 2-norm of the initial error vector is $\\|e(0)\\|_2 = \\delta$, where $\\delta$ is a positive real constant.\n\nA measure of the total observation error over time is the integrated squared error, defined as $J = \\int_0^\\infty \\|e(t)\\|_2^2 dt$. The maximum possible value of $J$ for any initial error $e(0)$ satisfying the given norm constraint can be written in the form $k \\delta^2$.\n\nDetermine the exact analytical expression for the coefficient $k$.", "solution": "The error dynamics for the Luenberger observer are given by the difference between the plant and observer dynamics. With $e(t) = x(t) - \\hat{x}(t)$, we compute\n$$\n\\dot{e}(t) = \\dot{x}(t) - \\dot{\\hat{x}}(t) = A x(t) - \\left(A \\hat{x}(t) + L\\left(y(t) - C \\hat{x}(t)\\right)\\right) = \\left(A - L C\\right) e(t).\n$$\nGiven $A = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix}$, $C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}$, and $L = \\begin{pmatrix} 6 \\\\ 0 \\end{pmatrix}$, we compute\n$$\nL C = \\begin{pmatrix} 6 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 6 & 0 \\\\ 0 & 0 \\end{pmatrix}, \\quad F \\coloneqq A - L C = \\begin{pmatrix} -6 & 1 \\\\ -2 & -3 \\end{pmatrix}.\n$$\nThe characteristic polynomial of $F$ is\n$$\n\\det(\\lambda I - F) = \\det\\begin{pmatrix} \\lambda + 6 & -1 \\\\ 2 & \\lambda + 3 \\end{pmatrix} = (\\lambda + 6)(\\lambda + 3) + 2 = \\lambda^{2} + 9 \\lambda + 20,\n$$\nwith roots $\\lambda = -4$ and $\\lambda = -5$, so $F$ is Hurwitz. Therefore,\n$$\ne(t) = \\exp(F t)\\, e(0).\n$$\nThe integrated squared error is\n$$\nJ = \\int_{0}^{\\infty} \\|e(t)\\|_{2}^{2} \\, dt = \\int_{0}^{\\infty} e(t)^{\\top} e(t) \\, dt = \\int_{0}^{\\infty} e(0)^{\\top} \\exp(F^{\\top} t) \\exp(F t)\\, e(0) \\, dt = e(0)^{\\top} P\\, e(0),\n$$\nwhere\n$$\nP \\coloneqq \\int_{0}^{\\infty} \\exp(F^{\\top} t) \\exp(F t)\\, dt\n$$\nis the unique positive definite solution of the continuous-time Lyapunov equation\n$$\nF^{\\top} P + P F = -I.\n$$\nLet $P = \\begin{pmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{pmatrix}$. With $F^{\\top} = \\begin{pmatrix} -6 & -2 \\\\ 1 & -3 \\end{pmatrix}$, we compute\n$$\nF^{\\top} P = \\begin{pmatrix} -6 p_{11} - 2 p_{12} & -6 p_{12} - 2 p_{22} \\\\ p_{11} - 3 p_{12} & p_{12} - 3 p_{22} \\end{pmatrix}, \\quad\nP F = \\begin{pmatrix} -6 p_{11} - 2 p_{12} & p_{11} - 3 p_{12} \\\\ -6 p_{12} - 2 p_{22} & p_{12} - 3 p_{22} \\end{pmatrix}.\n$$\nThus\n$$\nF^{\\top} P + P F = \\begin{pmatrix}\n-12 p_{11} - 4 p_{12} & p_{11} - 9 p_{12} - 2 p_{22} \\\\\np_{11} - 9 p_{12} - 2 p_{22} & 2 p_{12} - 6 p_{22}\n\\end{pmatrix} = - \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nEquating entries gives the linear system\n$$\n-12 p_{11} - 4 p_{12} = -1, \\quad p_{11} - 9 p_{12} - 2 p_{22} = 0, \\quad 2 p_{12} - 6 p_{22} = -1.\n$$\nSolving, from $2 p_{12} - 6 p_{22} = -1$ we get $p_{12} = \\frac{-1 + 6 p_{22}}{2}$. From $-12 p_{11} - 4 p_{12} = -1$ we get $p_{11} = \\frac{1 - 4 p_{12}}{12}$. Substituting into $p_{11} - 9 p_{12} - 2 p_{22} = 0$ yields\n$$\n\\frac{1 - 4 p_{12}}{12} - 9 p_{12} - 2 p_{22} = 0 \\;\\;\\Rightarrow\\;\\; 112 p_{12} + 24 p_{22} = 1.\n$$\nSubstitute $p_{12}$ to get\n$$\n112 \\cdot \\frac{-1 + 6 p_{22}}{2} + 24 p_{22} = 1 \\;\\;\\Rightarrow\\;\\; -56 + 360 p_{22} = 1 \\;\\;\\Rightarrow\\;\\; p_{22} = \\frac{19}{120}.\n$$\nThen\n$$\np_{12} = \\frac{-1 + 6 \\cdot \\frac{19}{120}}{2} = -\\frac{1}{40}, \\quad p_{11} = \\frac{1 - 4 \\left(-\\frac{1}{40}\\right)}{12} = \\frac{11}{120}.\n$$\nTherefore\n$$\nP = \\begin{pmatrix} \\frac{11}{120} & -\\frac{1}{40} \\\\ -\\frac{1}{40} & \\frac{19}{120} \\end{pmatrix}.\n$$\nThe maximum of $J = e(0)^{\\top} P e(0)$ over all $e(0)$ with $\\|e(0)\\|_{2} = \\delta$ is attained when $e(0)$ aligns with the eigenvector of $P$ corresponding to its largest eigenvalue. The eigenvalues of $P$ are\n$$\n\\lambda_{\\pm} = \\frac{\\operatorname{tr}(P) \\pm \\sqrt{\\operatorname{tr}(P)^{2} - 4 \\det(P)}}{2},\n$$\nwith $\\operatorname{tr}(P) = \\frac{1}{4}$ and $\\det(P) = \\frac{1}{72}$. Hence\n$$\n\\operatorname{tr}(P)^{2} - 4 \\det(P) = \\frac{1}{16} - \\frac{1}{18} = \\frac{1}{144}, \\quad \\sqrt{\\operatorname{tr}(P)^{2} - 4 \\det(P)} = \\frac{1}{12},\n$$\nso\n$$\n\\lambda_{\\max}(P) = \\frac{\\frac{1}{4} + \\frac{1}{12}}{2} = \\frac{1}{6}.\n$$\nTherefore the maximum value is $J_{\\max} = \\lambda_{\\max}(P) \\delta^{2}$, and the required coefficient is $k = \\frac{1}{6}$.", "answer": "$$\\boxed{\\frac{1}{6}}$$", "id": "1577282"}, {"introduction": "Theoretical models often assume perfect measurements, but real-world sensors have finite precision. For digital systems, this often manifests as quantization, where a continuous signal is mapped to a discrete set of values. This imperfection introduces a persistent, bounded error into the observer's input, preventing the estimation error from decaying completely to zero. This practice [@problem_id:1577300] explores the practical consequences of such non-ideal behavior, challenging you to determine the ultimate bounds on the steady-state estimation error. This analysis is crucial for understanding the robustness of an observer and predicting its real-world performance limits.", "problem": "Consider a linear time-invariant system described by the state-space equations:\n$$\n\\dot{x}(t) = Ax(t) + Bu(t) \\\\\ny(t) = Cx(t)\n$$\nwhere $x(t) = \\begin{pmatrix} x_1(t) \\\\ x_2(t) \\end{pmatrix}$ is the state vector, $u(t)$ is a scalar input, and $y(t)$ is the scalar output. The system matrices are given by:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}\n$$\nA full-order state observer is designed to estimate the state vector $x(t)$. The observer dynamics are given by:\n$$\n\\dot{\\hat{x}}(t) = A\\hat{x}(t) + Bu(t) + L(y_q(t) - C\\hat{x}(t))\n$$\nwhere $\\hat{x}(t)$ is the estimated state vector and $L = \\begin{pmatrix} l_1 \\\\ l_2 \\end{pmatrix}$ is the observer gain vector.\n\nThe sensor measuring the output $y(t)$ is subject to uniform quantization. The quantized measurement, $y_q(t)$, is related to the true output $y(t)$ by $y_q(t) = y(t) + e_q(t)$, where $e_q(t)$ is the quantization error. This error is bounded by $|e_q(t)| \\le \\frac{\\Delta}{2}$ for all time $t$, where $\\Delta$ is the quantization resolution.\n\nThe observer gain vector $L$ is chosen such that both eigenvalues of the observer error dynamics matrix are placed at $-p$, where $p$ is a given positive real constant.\n\nLet the state estimation error be $e(t) = x(t) - \\hat{x}(t) = \\begin{pmatrix} e_1(t) \\\\ e_2(t) \\end{pmatrix}$. Due to the persistent quantization error, the estimation error does not converge to zero but remains within a bounded region in the steady state. Let the ultimate bounds on the magnitudes of the individual error components be denoted by $E_1^{\\max}$ and $E_2^{\\max}$, representing the supremum of $|e_1(t)|$ and $|e_2(t)|$ respectively, as $t \\to \\infty$.\n\nDetermine the analytical expression for the ratio $\\frac{E_1^{\\max}}{E_2^{\\max}}$ in terms of the parameter $p$.", "solution": "The observer error dynamics with quantized measurement follow from\n$$\n\\dot{x} = A x + B u, \\quad \\dot{\\hat{x}} = A \\hat{x} + B u + L(y_{q} - C \\hat{x}), \\quad y_{q} = C x + e_{q},\n$$\nso, with $e = x - \\hat{x}$ and $M \\equiv A - L C$, we obtain\n$$\n\\dot{e} = M e - L e_{q}.\n$$\nPlacing both eigenvalues of $M$ at $-p$ means that the characteristic polynomial of $M$ equals $(s + p)^{2} = s^{2} + 2 p s + p^{2}$. For\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix}, \\quad L = \\begin{pmatrix} l_{1} \\\\ l_{2} \\end{pmatrix},\n$$\nwe have\n$$\nM = A - L C = \\begin{pmatrix} -l_{1} & 1 \\\\ -l_{2} & 0 \\end{pmatrix},\n$$\nwhose characteristic polynomial is $s^{2} + l_{1} s + l_{2}$. Matching coefficients gives\n$$\nl_{1} = 2 p, \\qquad l_{2} = p^{2}, \\qquad L = \\begin{pmatrix} 2 p \\\\ p^{2} \\end{pmatrix}, \\qquad M = \\begin{pmatrix} -2 p & 1 \\\\ -p^{2} & 0 \\end{pmatrix}.\n$$\n\nTreat $e_{q}$ as a bounded disturbance input with $|e_{q}(t)| \\le \\Delta/2$. The (vector) transfer function from $e_{q}$ to $e$ is\n$$\nG(s) = -(s I - M)^{-1} L.\n$$\nCompute\n$$\ns I - M = \\begin{pmatrix} s + 2 p & -1 \\\\ p^{2} & s \\end{pmatrix}, \\quad (s I - M)^{-1} = \\frac{1}{(s + p)^{2}} \\begin{pmatrix} s & 1 \\\\ -p^{2} & s + 2 p \\end{pmatrix},\n$$\nso\n$$\nG(s) = -\\frac{1}{(s + p)^{2}} \\begin{pmatrix} s & 1 \\\\ -p^{2} & s + 2 p \\end{pmatrix} \\begin{pmatrix} 2 p \\\\ p^{2} \\end{pmatrix} = -\\begin{pmatrix} \\dfrac{2 p s + p^{2}}{(s + p)^{2}} \\\\ \\dfrac{p^{2} s}{(s + p)^{2}} \\end{pmatrix}.\n$$\nHence the componentwise impulse responses $h_{1}(t)$ and $h_{2}(t)$ (from $e_{q}$ to $e_{1}$ and $e_{2}$) are\n$$\nh_{1}(t) = \\mathcal{L}^{-1}\\!\\left[-\\frac{2 p s + p^{2}}{(s + p)^{2}}\\right]\n= -2 p \\bigl(\\exp(-p t) - p t \\exp(-p t)\\bigr) - p^{2} \\bigl(t \\exp(-p t)\\bigr)\n= p \\exp(-p t)\\,(p t - 2),\n$$\n$$\nh_{2}(t) = \\mathcal{L}^{-1}\\!\\left[-\\frac{p^{2} s}{(s + p)^{2}}\\right]\n= -p^{2} \\bigl(\\exp(-p t) - p t \\exp(-p t)\\bigr)\n= p^{2} \\exp(-p t)\\,(p t - 1).\n$$\n\nFor a stable LTI system with scalar input $u(t)$ and impulse response $h_{i}(t)$, the output satisfies\n$$\n|e_{i}(t)| = \\left|\\int_{0}^{\\infty} h_{i}(\\tau)\\, u(t - \\tau)\\, d\\tau\\right|\n\\le \\|u\\|_{\\infty} \\int_{0}^{\\infty} |h_{i}(\\tau)|\\, d\\tau.\n$$\nThis bound is tight in the sense that, by choosing $u$ to align with the sign of $h_{i}$, the supremum over time approaches $\\|u\\|_{\\infty} \\int_{0}^{\\infty} |h_{i}(\\tau)|\\, d\\tau$. Therefore, with $|e_{q}(t)| \\le \\Delta/2$, the ultimate bounds are\n$$\nE_{i}^{\\max} = \\frac{\\Delta}{2} \\int_{0}^{\\infty} |h_{i}(t)|\\, dt,\n$$\nand the ratio is independent of $\\Delta$:\n$$\n\\frac{E_{1}^{\\max}}{E_{2}^{\\max}} = \\frac{\\int_{0}^{\\infty} |h_{1}(t)|\\, dt}{\\int_{0}^{\\infty} |h_{2}(t)|\\, dt}.\n$$\n\nCompute these integrals. With the change of variable $z = p t$ (so $dt = dz/p$), we have\n$$\n|h_{1}(t)| = p \\exp(-p t) |p t - 2|, \\quad |h_{2}(t)| = p^{2} \\exp(-p t) |p t - 1|.\n$$\nThus\n$$\n\\int_{0}^{\\infty} |h_{1}(t)|\\, dt = \\int_{0}^{\\infty} \\exp(-z) |z - 2|\\, dz\n= \\int_{0}^{2} \\exp(-z)(2 - z)\\, dz + \\int_{2}^{\\infty} \\exp(-z)(z - 2)\\, dz.\n$$\nUsing $\\int \\exp(-z) (z - c)\\, dz = (c - z - 1)\\exp(-z) + \\text{const}$, the two terms evaluate to\n$$\n\\int_{0}^{2} \\exp(-z)(2 - z)\\, dz = 1 + \\exp(-2), \\qquad\n\\int_{2}^{\\infty} \\exp(-z)(z - 2)\\, dz = \\exp(-2),\n$$\nso\n$$\n\\int_{0}^{\\infty} |h_{1}(t)|\\, dt = 1 + 2 \\exp(-2).\n$$\nSimilarly,\n$$\n\\int_{0}^{\\infty} |h_{2}(t)|\\, dt = p \\int_{0}^{\\infty} \\exp(-z) |z - 1|\\, dz\n= p \\left[\\int_{0}^{1} \\exp(-z)(1 - z)\\, dz + \\int_{1}^{\\infty} \\exp(-z)(z - 1)\\, dz\\right]\n= p \\left[\\exp(-1) + \\exp(-1)\\right]\n= 2 p \\exp(-1).\n$$\n\nTherefore,\n$$\n\\frac{E_{1}^{\\max}}{E_{2}^{\\max}} = \\frac{1 + 2 \\exp(-2)}{2 p \\exp(-1)} = \\frac{\\exp(1) + 2 \\exp(-1)}{2 p}.\n$$\nThis expression depends only on $p$ (as required), with all other quantities cancelling in the ratio.", "answer": "$$\\boxed{\\frac{\\exp(1)+2\\exp(-1)}{2p}}$$", "id": "1577300"}]}