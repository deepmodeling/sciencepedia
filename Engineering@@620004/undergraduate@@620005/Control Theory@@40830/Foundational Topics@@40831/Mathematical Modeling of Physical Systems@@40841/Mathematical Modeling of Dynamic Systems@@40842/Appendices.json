{"hands_on_practices": [{"introduction": "Understanding how to predict a system's future behavior is a cornerstone of control theory. This exercise guides you through the process of calculating the complete time response of a linear system from first principles, starting from its state-space representation [@problem_id:2723710]. By explicitly computing the matrix exponential and solving the convolution integral, you will solidify your understanding of how a system's internal dynamics ($e^{At}$) and external inputs combine to produce its output.", "problem": "Consider the linear time-invariant (LTI) system governed by the state-space equations $\\dot{x}(t)=A\\,x(t)+B\\,u(t)$ and $y(t)=C\\,x(t)+D\\,u(t)$, where $x(t)\\in\\mathbb{R}^{2}$, $u(t)\\in\\mathbb{R}$, and $y(t)\\in\\mathbb{R}$. The system matrices and data are\n$$\nA=\\begin{pmatrix}-1 & 1\\\\ 0 & -1\\end{pmatrix},\\quad\nB=\\begin{pmatrix}0\\\\ 1\\end{pmatrix},\\quad\nC=\\begin{pmatrix}2 & -1\\end{pmatrix},\\quad\nD=3,\\quad\nu(t)\\equiv u_{0},\\quad u_{0}=2,\\quad\nx(0)=x_{0}=\\begin{pmatrix}1\\\\ -2\\end{pmatrix}.\n$$\nStarting only from the fundamental definition of the matrix exponential and the fundamental solution concept for linear systems, do the following:\n- Derive the closed-form expressions for $x(t)$ and $y(t)$ for all $t\\ge 0$ by explicitly computing $\\exp(A t)$ and evaluating any required integrals, without invoking pre-memorized solution formulas.\n- Verify by direct differentiation and substitution that your $x(t)$ satisfies $\\dot{x}(t)=A\\,x(t)+B\\,u_{0}$ together with the initial condition $x(0)=x_{0}$, and that your $y(t)$ satisfies $y(t)=C\\,x(t)+D\\,u_{0}$.\n- As your final reported result, provide the exact value of $y(1)$ as a simplified closed-form analytic expression (no decimal approximation). Do not include units.\n\nYour final answer must be a single closed-form expression. If you choose to approximate at any intermediate step, do not round the final expression; instead, express it exactly.", "solution": "The problem as stated is a standard initial value problem for a linear time-invariant system. It is scientifically grounded in control theory, well-posed, objective, and contains all necessary information for a unique solution to be derived and verified. There are no logical contradictions, physical impossibilities, or ambiguities. Therefore, the problem is valid and we proceed to the solution.\n\nThe system is described by the state-space equations:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nThe problem requires a solution derived from first principles. We begin with the homogeneous equation $\\dot{x}(t) = A x(t)$. The solution to this is given by $x_h(t) = \\exp(A t) x(0)$, where $\\exp(A t)$ is the state-transition matrix, defined by the power series $\\exp(At) = \\sum_{k=0}^{\\infty} \\frac{(At)^k}{k!}$.\n\nFor the non-homogeneous equation $\\dot{x}(t) = A x(t) + B u(t)$, we use the method of variation of parameters. We propose a solution of the form $x(t) = \\exp(At) z(t)$ for some vector function $z(t)$. Differentiating with respect to time using the product rule gives:\n$$\n\\dot{x}(t) = \\frac{d}{dt}(\\exp(At)) z(t) + \\exp(At) \\dot{z}(t) = A\\exp(At)z(t) + \\exp(At)\\dot{z}(t)\n$$\nSubstituting this into the state equation:\n$$\nA\\exp(At)z(t) + \\exp(At)\\dot{z}(t) = A(\\exp(At)z(t)) + B u(t)\n$$\nThe terms involving $A\\exp(At)z(t)$ cancel, leaving:\n$$\n\\exp(At)\\dot{z}(t) = B u(t)\n$$\nMultiplying by the inverse of the state-transition matrix, $(\\exp(At))^{-1} = \\exp(-At)$, yields:\n$$\n\\dot{z}(t) = \\exp(-At) B u(t)\n$$\nIntegrating from $\\tau=0$ to $\\tau=t$ gives:\n$$\nz(t) - z(0) = \\int_{0}^{t} \\exp(-A\\tau) B u(\\tau) d\\tau\n$$\nFrom our proposed solution, $x(0) = \\exp(A \\cdot 0) z(0) = I z(0) = z(0)$, so $z(0) = x(0) = x_0$. Thus:\n$$\nz(t) = x_0 + \\int_{0}^{t} \\exp(-A\\tau) B u(\\tau) d\\tau\n$$\nSubstituting this back into $x(t) = \\exp(At) z(t)$, we obtain the fundamental solution for the state vector:\n$$\nx(t) = \\exp(At) x_0 + \\exp(At) \\int_{0}^{t} \\exp(-A\\tau) B u(\\tau) d\\tau = \\exp(At) x_0 + \\int_{0}^{t} \\exp(A(t-\\tau)) B u(\\tau) d\\tau\n$$\nThis is the convolution integral form of the solution. We must now compute the components.\n\nThe given matrices and data are:\n$$\nA=\\begin{pmatrix}-1 & 1\\\\ 0 & -1\\end{pmatrix},\\quad B=\\begin{pmatrix}0\\\\ 1\\end{pmatrix},\\quad C=\\begin{pmatrix}2 & -1\\end{pmatrix},\\quad D=3,\\quad u(t)=u_{0}=2,\\quad x(0)=x_{0}=\\begin{pmatrix}1\\\\ -2\\end{pmatrix}\n$$\nFirst, we compute the matrix exponential $\\exp(At)$. The matrix $A$ can be decomposed as $A = S+N$, where $S = -I = \\begin{pmatrix}-1 & 0\\\\ 0 & -1\\end{pmatrix}$ and $N = \\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix}$. Since $S$ is a scalar matrix, it commutes with any matrix, so $SN=NS$. This allows us to write $\\exp(At) = \\exp((S+N)t) = \\exp(St)\\exp(Nt)$.\nThe exponential of the scalar matrix is $\\exp(St) = \\exp(-It) = I\\exp(-t) = \\begin{pmatrix}\\exp(-t) & 0\\\\ 0 & \\exp(-t)\\end{pmatrix}$.\nThe matrix $N$ is nilpotent, with $N^2 = \\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix}\\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix} = \\begin{pmatrix}0 & 0\\\\ 0 & 0\\end{pmatrix}$. All higher powers are zero. From the definition of the matrix exponential series:\n$$\n\\exp(Nt) = I + Nt + \\frac{(Nt)^2}{2!} + \\dots = \\begin{pmatrix}1 & 0\\\\ 0 & 1\\end{pmatrix} + t\\begin{pmatrix}0 & 1\\\\ 0 & 0\\end{pmatrix} = \\begin{pmatrix}1 & t\\\\ 0 & 1\\end{pmatrix}\n$$\nCombining these results:\n$$\n\\exp(At) = \\exp(St)\\exp(Nt) = \\begin{pmatrix}\\exp(-t) & 0\\\\ 0 & \\exp(-t)\\end{pmatrix} \\begin{pmatrix}1 & t\\\\ 0 & 1\\end{pmatrix} = \\begin{pmatrix}\\exp(-t) & t\\exp(-t)\\\\ 0 & \\exp(-t)\\end{pmatrix}\n$$\nNow we compute the two parts of the solution for $x(t)$.\nThe zero-input response is:\n$$\nx_{zi}(t) = \\exp(At) x_0 = \\begin{pmatrix}\\exp(-t) & t\\exp(-t)\\\\ 0 & \\exp(-t)\\end{pmatrix} \\begin{pmatrix}1\\\\ -2\\end{pmatrix} = \\begin{pmatrix}\\exp(-t) - 2t\\exp(-t)\\\\ -2\\exp(-t)\\end{pmatrix} = \\begin{pmatrix}(1-2t)\\exp(-t)\\\\ -2\\exp(-t)\\end{pmatrix}\n$$\nThe zero-state response for a constant input $u(t)=u_0$ is:\n$$\nx_{zs}(t) = \\int_{0}^{t} \\exp(A(t-\\tau)) B u_0 d\\tau = u_0 \\int_{0}^{t} \\begin{pmatrix}\\exp(-(t-\\tau)) & (t-\\tau)\\exp(-(t-\\tau))\\\\ 0 & \\exp(-(t-\\tau))\\end{pmatrix} \\begin{pmatrix}0\\\\ 1\\end{pmatrix} d\\tau\n$$\n$$\nx_{zs}(t) = 2 \\int_{0}^{t} \\begin{pmatrix}(t-\\tau)\\exp(-(t-\\tau))\\\\ \\exp(-(t-\\tau))\\end{pmatrix} d\\tau = 2\\exp(-t) \\int_{0}^{t} \\begin{pmatrix}(t-\\tau)\\exp(\\tau)\\\\ \\exp(\\tau)\\end{pmatrix} d\\tau\n$$\nWe evaluate the integrals for each component.\nFor the second component:\n$$\n\\int_{0}^{t} \\exp(\\tau) d\\tau = [\\exp(\\tau)]_0^t = \\exp(t) - 1\n$$\nFor the first component, we use integration by parts for the term $\\int_0^t \\tau\\exp(\\tau)d\\tau$:\n$$\n\\int_0^t (t-\\tau)\\exp(\\tau) d\\tau = t\\int_0^t \\exp(\\tau)d\\tau - \\int_0^t \\tau\\exp(\\tau)d\\tau = t(\\exp(t)-1) - \\left( [\\tau\\exp(\\tau)]_0^t - \\int_0^t \\exp(\\tau)d\\tau \\right)\n$$\n$$\n= t\\exp(t) - t - (t\\exp(t) - (\\exp(t)-1)) = t\\exp(t) - t - t\\exp(t) + \\exp(t) - 1 = \\exp(t) - t - 1\n$$\nSubstituting these integral results back into the expression for $x_{zs}(t)$:\n$$\nx_{zs}(t) = 2\\exp(-t) \\begin{pmatrix}\\exp(t) - t - 1\\\\ \\exp(t)-1\\end{pmatrix} = \\begin{pmatrix}2 - 2(t+1)\\exp(-t)\\\\ 2 - 2\\exp(-t)\\end{pmatrix}\n$$\nThe total state vector $x(t) = x_{zi}(t) + x_{zs}(t)$ is:\n$$\nx(t) = \\begin{pmatrix}(1-2t)\\exp(-t)\\\\ -2\\exp(-t)\\end{pmatrix} + \\begin{pmatrix}2 - 2(t+1)\\exp(-t)\\\\ 2 - 2\\exp(-t)\\end{pmatrix} = \\begin{pmatrix}2 + (1-2t-2t-2)\\exp(-t)\\\\ 2 + (-2-2)\\exp(-t)\\end{pmatrix}\n$$\n$$\nx(t) = \\begin{pmatrix}2 - (4t+1)\\exp(-t)\\\\ 2 - 4\\exp(-t)\\end{pmatrix}\n$$\nNow, we derive the output $y(t)$:\n$$\ny(t) = C x(t) + D u_0 = \\begin{pmatrix}2 & -1\\end{pmatrix} \\begin{pmatrix}2 - (4t+1)\\exp(-t)\\\\ 2 - 4\\exp(-t)\\end{pmatrix} + 3(2)\n$$\n$$\ny(t) = 2(2 - (4t+1)\\exp(-t)) - (2 - 4\\exp(-t)) + 6\n$$\n$$\ny(t) = 4 - (8t+2)\\exp(-t) - 2 + 4\\exp(-t) + 6 = 8 + (-8t-2+4)\\exp(-t)\n$$\n$$\ny(t) = 8 + (2-8t)\\exp(-t)\n$$\nThe next step is verification. First, check the initial condition for $x(t)$:\n$$\nx(0) = \\begin{pmatrix}2 - (4(0)+1)\\exp(0)\\\\ 2 - 4\\exp(0)\\end{pmatrix} = \\begin{pmatrix}2-1\\\\ 2-4\\end{pmatrix} = \\begin{pmatrix}1\\\\ -2\\end{pmatrix} = x_0\n$$\nThe initial condition is satisfied. Now check the state differential equation $\\dot{x}(t) = A x(t) + B u_0$.\nWe compute the derivative of our solution $x(t)$:\n$$\n\\dot{x}(t) = \\frac{d}{dt} \\begin{pmatrix}2 - (4t+1)\\exp(-t)\\\\ 2 - 4\\exp(-t)\\end{pmatrix} = \\begin{pmatrix}-(4\\exp(-t) - (4t+1)\\exp(-t))\\\\ -4(-\\exp(-t))\\end{pmatrix} = \\begin{pmatrix}(4t-3)\\exp(-t)\\\\ 4\\exp(-t)\\end{pmatrix}\n$$\nNow we compute the right-hand side of the state equation:\n$$\nA x(t) + B u_0 = \\begin{pmatrix}-1 & 1\\\\ 0 & -1\\end{pmatrix} \\begin{pmatrix}2 - (4t+1)\\exp(-t)\\\\ 2 - 4\\exp(-t)\\end{pmatrix} + \\begin{pmatrix}0\\\\ 1\\end{pmatrix}(2)\n$$\n$$\n= \\begin{pmatrix}-(2 - (4t+1)\\exp(-t)) + (2 - 4\\exp(-t))\\\\ -(2 - 4\\exp(-t))\\end{pmatrix} + \\begin{pmatrix}0\\\\ 2\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix}-2 + (4t+1)\\exp(-t) + 2 - 4\\exp(-t)\\\\ -2 + 4\\exp(-t)\\end{pmatrix} + \\begin{pmatrix}0\\\\ 2\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix}(4t+1-4)\\exp(-t)\\\\ -2 + 4\\exp(-t) + 2\\end{pmatrix} = \\begin{pmatrix}(4t-3)\\exp(-t)\\\\ 4\\exp(-t)\\end{pmatrix}\n$$\nSince $\\dot{x}(t)$ equals $A x(t) + B u_0$, the state equation is satisfied. The verification of the output equation $y(t) = C x(t) + D u_0$ is shown by re-deriving it, which was already performed above and confirmed to be self-consistent. The solution is thus verified.\n\nFinally, we are required to provide the value of $y(1)$. Substituting $t=1$ into our expression for $y(t)$:\n$$\ny(1) = 8 + (2-8(1))\\exp(-1) = 8 + (2-8)\\exp(-1) = 8 - 6\\exp(-1)\n$$\nThis is the required exact, closed-form analytical expression.", "answer": "$$\\boxed{8 - 6\\exp(-1)}$$", "id": "2723710"}, {"introduction": "While transfer functions offer a powerful frequency-domain perspective, state-space models provide deep insights into a system's internal structure and are essential for modern control design. This practice focuses on the crucial skill of creating a state-space \"realization\" from a given transfer function, specifically the controllable canonical form [@problem_id:2723736]. Through this exercise, you will not only learn the mechanics of this conversion but also explore important concepts like non-minimal realizations that arise from pole-zero cancellations.", "problem": "Consider a single-input single-output, linear time-invariant system with strictly proper transfer function $G(s)=\\dfrac{s+2}{s^{2}+3s+2}$. Assume zero initial conditions. Starting only from fundamental definitions of transfer functions and state-space realizations, do the following:\n\n1) Construct a controllable canonical state-space realization $(A,B,C,D)$ of $G(s)$ with $D=0$ by selecting a companion-form matrix $A$ consistent with the monic denominator polynomial of $G(s)$ and a column vector $B$ that ensures controllability. Determine the row vector $C$ by matching the input-output map $G(s)=C\\,(sI-A)^{-1}B+D$.\n\n2) Using the state-space representation and the definition of the bilateral Laplace transform for linear time-invariant systems, compute the zero-state response $y_{\\mathrm{zs}}(t)$ to a unit step input $u(t)$ for $t\\ge 0$. Express the final answer as a single closed-form function of $t$.\n\nReport as your final answer the expression for $y_{\\mathrm{zs}}(t)$. No numerical rounding is required, and no physical units are needed.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- System type: Single-input single-output (SISO), linear time-invariant (LTI).\n- Transfer function: $G(s)=\\dfrac{s+2}{s^{2}+3s+2}$.\n- Properness: The transfer function is strictly proper.\n- Initial conditions: Zero, $x(0) = \\mathbf{0}$.\n- Task 1: Construct a controllable canonical state-space realization $(A,B,C,D)$.\n    - $D=0$.\n    - $A$ is a companion-form matrix from the monic denominator polynomial $s^2+3s+2$.\n    - $B$ is a column vector ensuring controllability.\n    - $C$ is a row vector determined by matching $G(s)=C\\,(sI-A)^{-1}B+D$.\n- Task 2: Compute the zero-state response $y_{\\mathrm{zs}}(t)$ for a unit step input $u(t)$ for $t\\ge 0$.\n    - Input: $u(t)$ is the unit step function.\n    - Method: Use the derived state-space representation and the Laplace transform.\n- Final Answer: A single closed-form function of $t$ for $y_{\\mathrm{zs}}(t)$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It is a standard problem in linear systems theory. The transfer function $G(s)$ has a denominator of degree $2$ and a numerator of degree $1$, which is consistent with the \"strictly proper\" description. The denominator polynomial $s^2+3s+2$ is monic, as required. The instructions to construct a controllable canonical form are clear and follow standard textbook procedures. The system has a pole-zero cancellation since $s^2+3s+2 = (s+1)(s+2)$, which means the transfer function simplifies to $G(s) = \\frac{1}{s+1}$. A second-order realization of this first-order system will necessarily be non-minimal (either not controllable or not observable). The problem explicitly asks for a *controllable* canonical realization based on the second-order denominator, which is a valid construction leading to a controllable but unobservable system. This does not represent a contradiction or flaw, but a specific case to be handled by formal procedure. The problem is thus internally consistent and solvable.\n\n**Step 3: Verdict and Action**\nThe problem is deemed **valid**. A solution will be provided.\n\nThe solution proceeds in two parts as requested.\n\n**Part 1: Construction of the State-Space Realization**\n\nThe given transfer function is $G(s) = \\dfrac{s+2}{s^2+3s+2}$. This is a second-order system, $n=2$. The general form for a strictly proper transfer function of order $n=2$ is:\n$$ G(s) = \\frac{b_1 s + b_0}{s^2 + a_1 s + a_0} $$\nBy comparing this with the given $G(s)$, we identify the coefficients:\n- Denominator coefficients: $a_1=3$, $a_0=2$.\n- Numerator coefficients: $b_1=1$, $b_0=2$.\n\nWe are instructed to construct the controllable canonical realization. For a general $n^{th}$-order system, this form is given by:\n$$ A = \\begin{pmatrix} 0 & 1 & 0 & \\dots & 0 \\\\ 0 & 0 & 1 & \\dots & 0 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\dots & 1 \\\\ -a_0 & -a_1 & -a_2 & \\dots & -a_{n-1} \\end{pmatrix}, \\quad B = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\end{pmatrix} $$\n$$ C = \\begin{pmatrix} b_0 & b_1 & \\dots & b_{n-1} \\end{pmatrix}, \\quad D = 0 $$\nFor our second-order system ($n=2$), we substitute the identified coefficients:\nThe companion matrix $A$ is:\n$$ A = \\begin{pmatrix} 0 & 1 \\\\ -a_0 & -a_1 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} $$\nThe input vector $B$ is:\n$$ B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\nThe output vector $C$ is:\n$$ C = \\begin{pmatrix} b_0 & b_1 \\end{pmatrix} = \\begin{pmatrix} 2 & 1 \\end{pmatrix} $$\nThe direct feedthrough term $D$ is given as $0$:\n$$ D = 0 $$\nThus, the controllable canonical state-space realization is $(A, B, C, D)$ with the matrices defined above. We can verify that this realization corresponds to the given transfer function:\n$G(s) = C(sI-A)^{-1}B+D$.\n$$ sI-A = s\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 0 & 1 \\\\ -2 & -3 \\end{pmatrix} = \\begin{pmatrix} s & -1 \\\\ 2 & s+3 \\end{pmatrix} $$\nThe inverse is:\n$$ (sI-A)^{-1} = \\frac{1}{\\det(sI-A)} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} = \\frac{1}{s(s+3) - (-1)(2)} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} = \\frac{1}{s^2+3s+2} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} $$\nNow, we compute the product $C(sI-A)^{-1}B$:\n$$ C(sI-A)^{-1}B = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2 & 1 \\end{pmatrix} \\begin{pmatrix} s+3 & 1 \\\\ -2 & s \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2(s+3)-2 & 2(1)+1(s) \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{1}{s^2+3s+2} \\begin{pmatrix} 2s+4 & s+2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} $$\n$$ = \\frac{(2s+4)(0) + (s+2)(1)}{s^2+3s+2} = \\frac{s+2}{s^2+3s+2} $$\nThis matches the original transfer function $G(s)$, confirming the correctness of the realization.\n\n**Part 2: Computation of the Zero-State Response**\n\nThe state-space representation of the LTI system is given by:\n$$ \\dot{x}(t) = Ax(t) + Bu(t) $$\n$$ y(t) = Cx(t) + Du(t) $$\nWe are asked to find the zero-state response, which means the initial state is zero: $x(0) = \\mathbf{0}$. The input is a unit step function, $u(t) = 1$ for $t \\ge 0$.\n\nWe apply the Laplace transform to the state equation, using the property $\\mathcal{L}\\{\\dot{x}(t)\\} = sX(s) - x(0)$:\n$$ sX(s) - x(0) = AX(s) + BU(s) $$\nWith $x(0)=\\mathbf{0}$, this simplifies to:\n$$ sX(s) = AX(s) + BU(s) \\implies (sI-A)X(s) = BU(s) $$\nSolving for the state vector in the frequency domain, $X(s)$:\n$$ X(s) = (sI-A)^{-1}BU(s) $$\nNow, we apply the Laplace transform to the output equation, with $D=0$:\n$$ Y(s) = CX(s) $$\nSubstituting the expression for $X(s)$:\n$$ Y(s) = C(sI-A)^{-1}BU(s) $$\nThe term $C(sI-A)^{-1}B$ is precisely the transfer function $G(s)$. The Laplace transform of the unit step input $u(t)=1$ is $U(s) = \\frac{1}{s}$.\nSo, the output $Y(s)$ is:\n$$ Y(s) = G(s)U(s) = \\left(\\frac{s+2}{s^2+3s+2}\\right) \\left(\\frac{1}{s}\\right) $$\nThe denominator can be factored: $s^2+3s+2 = (s+1)(s+2)$.\n$$ Y(s) = \\frac{s+2}{(s+1)(s+2)s} $$\nA pole at $s=-2$ is cancelled by a zero at $s=-2$. This simplification is valid for the input-output response.\n$$ Y(s) = \\frac{1}{s(s+1)} $$\nTo find the time-domain response $y_{\\mathrm{zs}}(t)$, we must compute the inverse Laplace transform of $Y(s)$. We use partial fraction expansion:\n$$ Y(s) = \\frac{1}{s(s+1)} = \\frac{K_1}{s} + \\frac{K_2}{s+1} $$\nThe coefficients $K_1$ and $K_2$ are found using the residue method:\n$$ K_1 = \\lim_{s \\to 0} s Y(s) = \\lim_{s \\to 0} \\frac{1}{s+1} = 1 $$\n$$ K_2 = \\lim_{s \\to -1} (s+1) Y(s) = \\lim_{s \\to -1} \\frac{1}{s} = -1 $$\nSo the expansion is:\n$$ Y(s) = \\frac{1}{s} - \\frac{1}{s+1} $$\nTaking the inverse Laplace transform term by term for $t \\ge 0$:\n$$ y_{\\mathrm{zs}}(t) = \\mathcal{L}^{-1}\\left\\{\\frac{1}{s}\\right\\} - \\mathcal{L}^{-1}\\left\\{\\frac{1}{s+1}\\right\\} $$\nUsing the standard transform pairs $\\mathcal{L}^{-1}\\{1/s\\} = 1$ and $\\mathcal{L}^{-1}\\{1/(s+a)\\} = \\exp(-at)$, we obtain:\n$$ y_{\\mathrm{zs}}(t) = 1 - \\exp(-t) $$\nThis is the closed-form expression for the zero-state response for $t \\ge 0$.", "answer": "$$\\boxed{1 - \\exp(-t)}$$", "id": "2723736"}, {"introduction": "The true power of mathematical modeling lies in its ability to describe and predict the behavior of complex, real-world systems. This advanced exercise challenges you to model a non-ideal DC-DC buck converter, a fundamental component in modern electronics that operates by switching between different circuit topologies [@problem_id:1591392]. You will apply the powerful technique of state-space averaging to derive a single linear, time-invariant model that approximates the converter's hybrid dynamics, a skill essential for designing controllers for switched-mode power supplies.", "problem": "Consider a non-ideal synchronous Direct Current to Direct Current (DC-DC) buck converter designed to step down a constant input voltage $V_{in}$. The converter circuit includes an inductor of inductance $L$ with a Direct Current Resistance (DCR) of $R_L$, and a capacitor of capacitance $C$ with an Equivalent Series Resistance (ESR) of $R_C$. The converter drives a purely resistive load $R$.\n\nThe switching elements are two MOSFETs arranged in a synchronous configuration. The high-side MOSFET, which connects the inductor to $V_{in}$, has an on-state resistance of $R_{ds1}$. The low-side MOSFET, which connects the inductor to ground during the freewheeling phase, has an on-state resistance of $R_{ds2}$. Both MOSFETs are treated as ideal switches otherwise.\n\nThe converter operates at a constant switching frequency high enough that the dynamics can be analyzed using averaging techniques. The control input is the duty cycle $D$, which represents the fraction of the switching period during which the high-side MOSFET is ON. The two MOSFETs operate in a complementary fashion, meaning when one is ON, the other is OFF.\n\nThe dynamic behavior of this converter can be approximated by a linear time-invariant system using the state-space averaging technique over one switching period. The resulting model takes the form $\\frac{d\\bar{x}(t)}{dt} = A\\bar{x}(t) + B\\bar{u}(t)$, where the state vector is defined as $\\bar{x}(t) = [\\bar{i}_L(t), \\bar{v}_C(t)]^T$, representing the averaged inductor current and averaged voltage across the capacitor's capacitance, respectively. The input vector is defined as $\\bar{u}(t) = [V_{in}]^T$.\n\nDetermine the analytical expression for the element in the first row and first column, $A_{11}$, of the averaged state matrix $A$.", "solution": "Define the state variables as $\\bar{x}(t) = [\\bar{i}_{L}(t), \\bar{v}_{C}(t)]^{T}$, where $\\bar{i}_{L}$ is the averaged inductor current and $\\bar{v}_{C}$ is the averaged voltage across the ideal capacitor. Let $v_{o}$ denote the output node voltage across the load.\n\nInductor voltage-current relation with inductor DCR $R_{L}$ gives\n$$\nL\\frac{d\\bar{i}_{L}}{dt} = v_{x} - v_{o} - \\bar{i}_{L} R_{L},\n$$\nwhere $v_{x}$ is the switch-node voltage. In the ON interval (high-side MOSFET on), $v_{x} = V_{in} - \\bar{i}_{L} R_{ds1}$. In the OFF interval (low-side MOSFET on, current flowing from ground to the switch node through $R_{ds2}$), $v_{x} = - \\bar{i}_{L} R_{ds2}$. Using state-space averaging over one period with duty ratio $D$ yields\n$$\nL\\frac{d\\bar{i}_{L}}{dt}\n= D\\left(V_{in} - \\bar{i}_{L} R_{ds1} - v_{o} - \\bar{i}_{L} R_{L}\\right)\n+ (1-D)\\left(- \\bar{i}_{L} R_{ds2} - v_{o} - \\bar{i}_{L} R_{L}\\right).\n$$\nSimplifying,\n$$\n\\frac{d\\bar{i}_{L}}{dt}\n= \\frac{D}{L}V_{in} - \\frac{1}{L}v_{o}\n- \\frac{1}{L}\\bar{i}_{L}\\left(R_{L} + D R_{ds1} + (1-D)R_{ds2}\\right).\n$$\n\nNext, relate $v_{o}$ to the states. The capacitor ESR $R_{C}$ is in series with $C$, so\n$$\nv_{o} = \\bar{v}_{C} + R_{C} \\bar{i}_{C}, \\quad \\bar{i}_{C} = C \\frac{d\\bar{v}_{C}}{dt}.\n$$\nKCL at the output node gives\n$$\n\\bar{i}_{L} = \\bar{i}_{C} + \\bar{i}_{R} = C \\frac{d\\bar{v}_{C}}{dt} + \\frac{v_{o}}{R}.\n$$\nEliminate $v_{o}$ via the two relations. First write\n$$\n\\bar{i}_{L} = C \\frac{d\\bar{v}_{C}}{dt} + \\frac{1}{R}\\left(\\bar{v}_{C} + R_{C} C \\frac{d\\bar{v}_{C}}{dt}\\right)\n= C \\frac{d\\bar{v}_{C}}{dt}\\left(1 + \\frac{R_{C}}{R}\\right) + \\frac{\\bar{v}_{C}}{R}.\n$$\nHence\n$$\n\\frac{d\\bar{v}_{C}}{dt}\n= \\frac{R}{C(R+R_{C})}\\bar{i}_{L} - \\frac{1}{C(R+R_{C})}\\bar{v}_{C}.\n$$\nThen\n$$\nv_{o} = \\bar{v}_{C} + R_{C} C \\frac{d\\bar{v}_{C}}{dt}\n= \\bar{v}_{C} + R_{C}\\left(\\frac{R}{R+R_{C}}\\bar{i}_{L} - \\frac{1}{R+R_{C}}\\bar{v}_{C}\\right)\n= \\frac{R}{R+R_{C}}\\bar{v}_{C} + \\frac{R R_{C}}{R+R_{C}}\\bar{i}_{L}.\n$$\n\nSubstitute this $v_{o}$ into the averaged inductor equation:\n$$\n\\frac{d\\bar{i}_{L}}{dt}\n= \\frac{D}{L}V_{in} - \\frac{1}{L}\\left(\\frac{R}{R+R_{C}}\\bar{v}_{C} + \\frac{R R_{C}}{R+R_{C}}\\bar{i}_{L}\\right)\n- \\frac{1}{L}\\bar{i}_{L}\\left(R_{L} + D R_{ds1} + (1-D)R_{ds2}\\right).\n$$\nCollecting the $\\bar{i}_{L}$ terms reveals the $A_{11}$ entry as the coefficient multiplying $\\bar{i}_{L}$:\n$$\nA_{11} = -\\frac{1}{L}\\left(R_{L} + D R_{ds1} + (1-D) R_{ds2} + \\frac{R R_{C}}{R + R_{C}}\\right).\n$$\nThis expression reflects the inductor current damping due to its DCR, the duty-cycle-weighted MOSFET on-resistances, and the effective resistive loading seen through the load and capacitor ESR combination.", "answer": "$$\\boxed{-\\frac{1}{L}\\left(R_{L}+D R_{ds1}+(1-D) R_{ds2}+\\frac{R R_{C}}{R+R_{C}}\\right)}$$", "id": "1591392"}]}