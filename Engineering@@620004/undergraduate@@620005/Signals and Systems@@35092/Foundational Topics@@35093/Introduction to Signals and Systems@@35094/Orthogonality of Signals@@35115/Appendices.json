{"hands_on_practices": [{"introduction": "Understanding orthogonality begins with its definition for continuous-time signals. This practice provides a direct application of the fundamental inner product, calculated via an integral, to ensure two signals are orthogonal over a specified interval. By determining the correct DC offset for an exponential signal, you will practice a core skill in constructing orthogonal basis sets, a common task in signal representation [@problem_id:1739468].", "problem": "In digital signal processing, it is often useful to represent complex signals as a linear combination of a set of simple, mutually orthogonal basis signals. Consider the task of constructing such a basis over the time interval from $t=0$ to $t=T$.\n\nLet the first basis signal be a constant function, $s_1(t) = 1$. Let the second basis signal be a decaying exponential with an adjustable Direct Current (DC) offset, given by $s_2(t) = a + \\exp(-t)$, where $a$ is a real constant.\n\nFor the system to function correctly, these two signals must be orthogonal over the interval $[0, T]$, where $T = 2$. Determine the exact value of the constant $a$ that ensures the orthogonality of $s_1(t)$ and $s_2(t)$ over this specified interval.", "solution": "Orthogonality over the interval requires the standard inner product to vanish:\n$$\n\\int_{0}^{2} s_{1}(t)\\,s_{2}(t)\\,\\mathrm{d}t=0.\n$$\nWith $s_{1}(t)=1$ and $s_{2}(t)=a+\\exp(-t)$, this becomes\n$$\n\\int_{0}^{2} \\left(a+\\exp(-t)\\right)\\,\\mathrm{d}t=0.\n$$\nBy linearity of the integral,\n$$\n\\int_{0}^{2} a\\,\\mathrm{d}t+\\int_{0}^{2} \\exp(-t)\\,\\mathrm{d}t=0.\n$$\nEvaluate each term:\n$$\n\\int_{0}^{2} a\\,\\mathrm{d}t=a\\int_{0}^{2}\\mathrm{d}t=a(2-0)=2a,\n$$\nand\n$$\n\\int_{0}^{2} \\exp(-t)\\,\\mathrm{d}t=\\left[-\\exp(-t)\\right]_{0}^{2}=-\\exp(-2)+\\exp(0)=1-\\exp(-2).\n$$\nThus the orthogonality condition is\n$$\n2a+1-\\exp(-2)=0.\n$$\nSolving for $a$,\n$$\n2a=\\exp(-2)-1 \\quad\\Rightarrow\\quad a=\\frac{\\exp(-2)-1}{2}.\n$$", "answer": "$$\\boxed{\\frac{\\exp(-2)-1}{2}}$$", "id": "1739468"}, {"introduction": "In the realm of digital signal processing, we work with discrete sequences rather than continuous functions. This exercise transitions the concept of orthogonality to the discrete domain, where the inner product is a summation. You will explore how to ensure orthogonality between complex-valued signals, a crucial property for powerful tools like the Discrete Fourier Transform (DFT), by correctly applying the complex conjugate in the inner product definition [@problem_id:1739447].", "problem": "In the study of signal representations, the concept of orthogonality is fundamental. Two signals are considered orthogonal if their inner product is zero. This property is crucial in applications like the Discrete Fourier Transform (DFT), where basis signals are mutually orthogonal.\n\nConsider two complex-valued discrete-time signals, $s_1[k]$ and $s_2[k]$, both of length $N=4$. The signals are defined for indices $k = 0, 1, 2, 3$.\nThe first signal is a constant sequence:\n$$s_1[k] = 1 \\quad \\text{for } k=0,1,2,3$$\nThe second signal is defined as the sequence:\n$$s_2[k] = \\{1, A, -1, j\\}$$\nwhere $A$ is an unknown complex constant and $j = \\sqrt{-1}$.\n\nThe inner product of two complex-valued signals $x[k]$ and $y[k]$ of length $N$ is defined as:\n$$\\langle x, y \\rangle = \\sum_{k=0}^{N-1} x[k] y^*[k]$$\nwhere $y^*[k]$ denotes the complex conjugate of $y[k]$.\n\nDetermine the value of the complex constant $A$ that makes the signals $s_1[k]$ and $s_2[k]$ orthogonal.", "solution": "Orthogonality requires the inner product to be zero:\n$$\\langle s_{1}, s_{2} \\rangle = \\sum_{k=0}^{3} s_{1}[k]\\,s_{2}^{*}[k] = 0.$$\nGiven $s_{1}[k]=1$ for all $k$, this becomes\n$$\\langle s_{1}, s_{2} \\rangle = \\sum_{k=0}^{3} s_{2}^{*}[k].$$\nWith $s_{2}[k] = \\{1, A, -1, j\\}$, we have\n$$s_{2}^{*}[k] = \\{1^{*}, A^{*}, (-1)^{*}, j^{*}\\} = \\{1, A^{*}, -1, -j\\},$$\nsince $1^{*}=1$, $(-1)^{*}=-1$, and $j^{*}=-j$. Therefore,\n$$\\langle s_{1}, s_{2} \\rangle = 1 + A^{*} - 1 - j = A^{*} - j.$$\nSetting this to zero for orthogonality gives\n$$A^{*} - j = 0 \\quad \\Rightarrow \\quad A^{*} = j \\quad \\Rightarrow \\quad A = j^{*} = -j.$$\nThus, the required value is $A=-j$.", "answer": "$$\\boxed{-j}$$", "id": "1739447"}, {"introduction": "The power of orthogonality extends beyond one-dimensional time signals into higher-dimensional spaces, such as in image processing. This problem generalizes the inner product to two-dimensional signals represented as matrices, using the trace operation. By finding the conditions for orthogonality between two simple matrix patterns, you will appreciate how this fundamental concept applies to diverse fields like computer vision and data analysis [@problem_id:1739448].", "problem": "In the analysis of two-dimensional signals, such as digital images, it is often useful to define an inner product to measure their similarity. For two real-valued $2 \\times 2$ matrices $X$ and $Y$, let the inner product be defined as $\\langle X, Y \\rangle = \\text{trace}(X^T Y)$, where $X^T$ is the transpose of $X$ and $\\text{trace}(\\cdot)$ is the trace of a matrix. Two matrices are considered orthogonal if their inner product is zero.\n\nConsider two such signals, $A$ and $B$. The signal $A$ represents a simple checkerboard pattern and is given by\n$$\nA = \\begin{pmatrix} c & -c \\\\ -c & c \\end{pmatrix}\n$$\nwhere $c$ is a non-zero real constant. The signal $B$ represents a simple horizontal gradient pattern and is given by\n$$\nB = \\begin{pmatrix} \\alpha & 2\\alpha \\\\ \\beta & 2\\beta \\end{pmatrix}\n$$\nwhere $\\alpha$ and $\\beta$ are real parameters.\n\nIf the signals $A$ and $B$ are orthogonal and it is also known that $\\alpha + \\beta = 5$, determine the value of $\\alpha$.", "solution": "The Frobenius inner product of two real matrices is defined by $\\langle X, Y \\rangle = \\text{trace}(X^{T}Y)$. Orthogonality requires $\\langle A, B \\rangle = 0$.\n\nGiven $A = \\begin{pmatrix} c & -c \\\\ -c & c \\end{pmatrix}$ with $c \\neq 0$ and $B = \\begin{pmatrix} \\alpha & 2\\alpha \\\\ \\beta & 2\\beta \\end{pmatrix}$, note that $A$ is symmetric, so $A^{T} = A$. Therefore,\n$$\n\\langle A, B \\rangle = \\text{trace}(A^{T}B) = \\text{trace}(AB).\n$$\nCompute $AB$:\n$$\nAB = \\begin{pmatrix} c & -c \\\\ -c & c \\end{pmatrix}\\begin{pmatrix} \\alpha & 2\\alpha \\\\ \\beta & 2\\beta \\end{pmatrix}\n= \\begin{pmatrix} c\\alpha - c\\beta & 2c\\alpha - 2c\\beta \\\\ -c\\alpha + c\\beta & -2c\\alpha + 2c\\beta \\end{pmatrix}\n= c(\\alpha - \\beta)\\begin{pmatrix} 1 & 2 \\\\ -1 & -2 \\end{pmatrix}.\n$$\nThe trace is the sum of diagonal entries:\n$$\n\\text{trace}(AB) = c(\\alpha - \\beta)\\left(1 + (-2)\\right) = -c(\\alpha - \\beta).\n$$\nOrthogonality $\\langle A, B \\rangle = 0$ implies\n$$\n-c(\\alpha - \\beta) = 0.\n$$\nSince $c \\neq 0$, it follows that\n$$\n\\alpha - \\beta = 0 \\quad \\Rightarrow \\quad \\alpha = \\beta.\n$$\nThe additional condition $\\alpha + \\beta = 5$ then gives\n$$\n\\alpha + \\alpha = 5 \\quad \\Rightarrow \\quad 2\\alpha = 5 \\quad \\Rightarrow \\quad \\alpha = \\frac{5}{2}.\n$$", "answer": "$$\\boxed{\\frac{5}{2}}$$", "id": "1739448"}]}