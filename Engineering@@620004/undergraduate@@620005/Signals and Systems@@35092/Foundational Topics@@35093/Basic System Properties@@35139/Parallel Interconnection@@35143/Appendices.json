{"hands_on_practices": [{"introduction": "Understanding parallel systems begins with the fundamental principle of superposition. This exercise provides a hands-on look at how the total output of a parallel system is simply the sum of the outputs from each individual branch when subjected to the same input. By working with basic building blocks like an amplifier and a delay unit, you will solidify your grasp of this additive property in the time domain [@problem_id:1739808].", "id": "1739808", "problem": "Consider a simple signal processing setup involving a parallel arrangement of two linear time-invariant (LTI) systems. In this configuration, an input signal $x(t)$ is applied to both systems simultaneously, and their respective outputs are summed together to create the final output signal $y(t)$.\n\nThe first system is a simple amplifier that scales the amplitude of its input signal by a factor of 2.\n\nThe second system is a pure delay unit that introduces a time delay of 3 seconds to its input signal.\n\nIf the input signal to this parallel configuration is the unit step function, denoted by $x(t) = u(t)$, determine the resulting output signal $y(t)$. Express your answer as a single analytic expression in terms of the time variable $t$ and the unit step function $u(t)$.\n\n", "solution": "In a parallel interconnection of linear time-invariant systems, the total output equals the sum of the outputs of the individual branches driven by the same input. Denote the input by $x(t)$ and the output by $y(t)$. Then\n$$\ny(t)=y_{1}(t)+y_{2}(t),\n$$\nwhere $y_{1}(t)$ is the output of the amplifier branch and $y_{2}(t)$ is the output of the delay branch.\n\nFor the amplifier with gain $2$, linearity gives\n$$\ny_{1}(t)=2\\,x(t).\n$$\nFor the pure delay of $T=3$ seconds, time invariance implies\n$$\ny_{2}(t)=x(t-3).\n$$\nGiven the input $x(t)=u(t)$, the unit step function, we substitute to obtain\n$$\ny(t)=2u(t)+u(t-3).\n$$\nAs a consistency check, this equals $0$ for $t<0$, equals $2$ for $0\\leq t<3$, and equals $3$ for $t\\geq 3$, which matches the expected sum of a step and its delayed version scaled appropriately.", "answer": "$$\\boxed{2u(t)+u(t-3)}$$"}, {"introduction": "Beyond basic analysis, the real power of system interconnections lies in design and synthesis. This problem challenges you to think like an engineer by using the additive nature of parallel transfer functions to create a system with specific properties. You will determine an unknown subsystem that, when combined in parallel with a known one, results in a desired all-pass filter, a common task in audio processing and communications [@problem_id:1739762].", "id": "1739762", "problem": "In a signal processing application, two stable, causal, continuous-time Linear Time-Invariant (LTI) systems are interconnected in a parallel configuration. The first system is characterized by the transfer function $H_1(s) = \\frac{s-1}{s+2}$. The second system has an unknown transfer function, $H_2(s)$.\n\nThe parallel combination of these two systems results in an equivalent system, $H_{eq}(s)$, which is designed to be an all-pass filter. An all-pass filter is defined as a system whose frequency response magnitude, $|H_{eq}(j\\omega)|$, is a constant value for all angular frequencies $\\omega$.\n\nFurthermore, the overall equivalent system is constrained to have a DC gain, defined as $H_{eq}(0)$, equal to $-3$.\n\nAssuming that the poles of the individual systems $H_1(s)$ and $H_2(s)$ are also the poles of the combined system $H_{eq}(s)$, determine the transfer function $H_2(s)$. Your final answer should be a single closed-form analytic expression in terms of $s$.\n\n", "solution": "For a parallel interconnection, the equivalent transfer function is the sum\n$$H_{eq}(s) = H_{1}(s) + H_{2}(s).$$\nAn all-pass filter with real coefficients and stability has the property that, for every pole at $p$ in the open left half-plane, there is a zero at $-p^{\\ast}$; for a real pole at $-a$ with $a>0$, a first-order all-pass section has the form\n$$A(s) = \\frac{s - a}{s + a}.$$\nA constant real gain factor $C$ scales the magnitude to a constant $|C|$ for all frequencies, so the general first-order real all-pass with constant magnitude is\n$$H_{eq}(s) = C \\frac{s - a}{s + a}.$$\nBy assumption, the poles of the individual systems are also poles of $H_{eq}(s)$. Since $H_{1}(s) = \\frac{s - 1}{s + 2}$ has a pole at $s = -2$, $H_{eq}(s)$ must have a pole at $s = -2$. Therefore, $a = 2$, and\n$$H_{eq}(s) = C \\frac{s - 2}{s + 2}.$$\nThe DC gain constraint $H_{eq}(0) = -3$ gives\n$$H_{eq}(0) = C \\frac{0 - 2}{0 + 2} = -C = -3 \\quad \\Rightarrow \\quad C = 3,$$\nhence\n$$H_{eq}(s) = 3 \\frac{s - 2}{s + 2}.$$\nUsing $H_{eq}(s) = H_{1}(s) + H_{2}(s)$, solve for $H_{2}(s)$:\n$$H_{2}(s) = H_{eq}(s) - H_{1}(s) = 3 \\frac{s - 2}{s + 2} - \\frac{s - 1}{s + 2} = \\frac{3(s - 2) - (s - 1)}{s + 2} = \\frac{2s - 5}{s + 2}.$$\nThis $H_{2}(s)$ is proper and has its pole at $s = -2$, so it is stable and causal, and the combined $H_{eq}(s)$ retains the pole at $s = -2$ without cancellation, satisfying the stated assumption. Moreover, for $s = \\mathrm{j}\\omega$,\n$$\\left| \\frac{\\mathrm{j}\\omega - 2}{\\mathrm{j}\\omega + 2} \\right| = 1,$$\nso $|H_{eq}(\\mathrm{j}\\omega)| = 3$ is constant for all $\\omega$, confirming the all-pass specification with constant magnitude.", "answer": "$$\\boxed{\\frac{2s - 5}{s + 2}}$$"}, {"introduction": "In many real-world scenarios, achieving an ideal system response is impossible due to constraints like causality. This advanced problem explores how parallel architectures can be used to find the best possible approximation of a desired, but non-causal, system. You will design a causal Finite Impulse Response (FIR) filter that minimizes the approximation error for a target signal, introducing the powerful concept of least-squares optimization in filter design [@problem_id:1739819].", "id": "1739819", "problem": "In the field of digital signal processing, designing systems to approximate a desired response is a fundamental task. Consider a discrete-time system, with overall impulse response $h[n]$, constructed to approximate a specific target non-causal impulse response, $h_d[n]$.\n\nThe approximating system $h[n]$ is composed of two subsystems connected in parallel. The first subsystem is a single-sample time advance unit, characterized by an impulse response $h_1[n] = \\delta[n+1]$, where $\\delta[n]$ is the Kronecker delta function. The second subsystem is a causal $N$-tap Finite Impulse Response (FIR) filter, with an impulse response denoted by $h_c[n]$. The causality and finite length constraints mean that $h_c[n]$ can be non-zero only for sample indices $n$ in the range $0 \\le n \\le N-1$.\n\nThe target impulse response to be approximated is given by the two-sided exponential sequence $h_d[n] = a^{|n|}$, where $a$ is a real-valued constant satisfying $0 < a < 1$.\n\nThe objective is to design the FIR filter $h_c[n]$ to minimize the total least-squares error, defined as $E = \\sum_{n=-\\infty}^{\\infty} (h_d[n] - h[n])^2$. Your task is to first determine the impulse response of the optimal filter $h_c[n]$ and then to calculate the resulting minimum value of this error, denoted as $E_{min}$.\n\nExpress your final answer for the minimum error $E_{min}$ as a single closed-form analytic expression in terms of the parameters $a$ and $N$.\n\n", "solution": "The problem asks for the minimum least-squares error $E_{min}$ when approximating a target impulse response $h_d[n]$ with a system $h[n]$. The system $h[n]$ is a parallel combination of a time advance unit $h_1[n]$ and a causal $N$-tap FIR filter $h_c[n]$.\n\nFirst, we write the impulse response of the total system. Since the subsystems are in parallel, their impulse responses add up:\n$h[n] = h_1[n] + h_c[n] = \\delta[n+1] + h_c[n]$.\n\nThe FIR filter $h_c[n]$ has $N$ taps and is causal, so it can be expressed as a weighted sum of delayed impulses:\n$h_c[n] = \\sum_{k=0}^{N-1} c_k \\delta[n-k]$,\nwhere $\\{c_k\\}$ for $k=0, 1, \\dots, N-1$ are the filter coefficients (taps) that we need to determine.\n\nThe total least-squares error $E$ is given by:\n$E = \\sum_{n=-\\infty}^{\\infty} (h_d[n] - h[n])^2 = \\sum_{n=-\\infty}^{\\infty} \\left(h_d[n] - \\left(\\delta[n+1] + \\sum_{k=0}^{N-1} c_k \\delta[n-k]\\right)\\right)^2$.\n\nOur goal is to minimize $E$ by choosing the optimal values for the coefficients $c_k$. We can analyze the sum term by term for different ranges of the index $n$:\n\n1.  For $n = -1$: The term in the sum is $(h_d[-1] - \\delta[-1+1] - 0)^2 = (h_d[-1] - 1)^2$. This term is independent of the coefficients $c_k$. With $h_d[n] = a^{|n|}$, this evaluates to $(a^{|-1|}-1)^2 = (a-1)^2$.\n\n2.  For $n$ in the range $\\{0, 1, \\dots, N-1\\}$: For any specific index $n=m$ in this range, the FIR filter term is $c_m$, while the $\\delta[n+1]$ term is zero. The term in the sum is $(h_d[m] - c_m)^2$.\n\n3.  For all other values of $n$ (i.e., $n < -1$ or $n \\ge N$): Both $\\delta[n+1]$ and $h_c[n]$ are zero. The term in the sum is $(h_d[n])^2$. These terms are also independent of the coefficients $c_k$.\n\nCombining these observations, we can rewrite the total error $E$ as:\n$E = (h_d[-1] - 1)^2 + \\sum_{m=0}^{N-1} (h_d[m] - c_m)^2 + \\sum_{n \\in \\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}} (h_d[n])^2$.\n\nTo minimize $E$ with respect to the coefficients $\\{c_m\\}$, we only need to minimize the part of the expression that depends on them, which is the sum $\\sum_{m=0}^{N-1} (h_d[m] - c_m)^2$. The other terms are constant with respect to $\\{c_m\\}$. This sum is a sum of non-negative squares. The minimum value of this sum is achieved when each individual term is minimized. The minimum value of $(h_d[m] - c_m)^2$ is zero, which occurs when $c_m = h_d[m]$.\n\nTherefore, the optimal coefficients for the FIR filter are:\n$c_m = h_d[m] = a^{|m|} = a^m$ for $m = 0, 1, \\dots, N-1$.\n\nWith these optimal coefficients, the term $\\sum_{m=0}^{N-1} (h_d[m] - c_m)^2$ becomes zero. The minimum error $E_{min}$ is then the sum of the remaining terms:\n$E_{min} = (h_d[-1] - 1)^2 + \\sum_{n \\in \\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}} (h_d[n])^2$.\n\nThe set of indices $\\mathbb{Z} \\setminus \\{-1, 0, \\dots, N-1\\}$ can be split into two disjoint sets: $\\{n \\in \\mathbb{Z} \\mid n \\le -2\\}$ and $\\{n \\in \\mathbb{Z} \\mid n \\ge N\\}$.\nSo, we can write $E_{min}$ as:\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} (h_d[n])^2 + \\sum_{n=N}^{\\infty} (h_d[n])^2$.\n\nNow, we substitute $h_d[n] = a^{|n|}$ and evaluate the sums.\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} (a^{|n|})^2 + \\sum_{n=N}^{\\infty} (a^{|n|})^2$.\n$E_{min} = (a-1)^2 + \\sum_{n=-\\infty}^{-2} a^{2|n|} + \\sum_{n=N}^{\\infty} a^{2|n|}$.\n\nFor the first sum, let $k = -n$. As $n$ goes from $-2$ to $-\\infty$, $k$ goes from $2$ to $\\infty$.\n$\\sum_{n=-\\infty}^{-2} a^{2|n|} = \\sum_{n=-\\infty}^{-2} a^{-2n} = \\sum_{k=2}^{\\infty} a^{2k}$.\nThis is a geometric series with first term $a^4$ and ratio $r = a^2$. Since $0 < a < 1$, we have $0 < a^2 < 1$, so the series converges. The sum is $\\frac{\\text{first term}}{1-\\text{ratio}} = \\frac{a^4}{1-a^2}$.\n\nFor the second sum, the indices $n$ are positive, so $|n|=n$.\n$\\sum_{n=N}^{\\infty} a^{2|n|} = \\sum_{n=N}^{\\infty} a^{2n}$.\nThis is a geometric series with first term $a^{2N}$ and ratio $r = a^2$. The sum is $\\frac{a^{2N}}{1-a^2}$.\n\nNow, we add all the parts of $E_{min}$ together:\n$E_{min} = (a-1)^2 + \\frac{a^4}{1-a^2} + \\frac{a^{2N}}{1-a^2}$.\n$E_{min} = a^2 - 2a + 1 + \\frac{a^4 + a^{2N}}{1-a^2}$.\n\nTo get a single fraction, we use the common denominator $1-a^2$:\n$E_{min} = \\frac{(a^2 - 2a + 1)(1-a^2)}{1-a^2} + \\frac{a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{(a^2 - a^4 - 2a + 2a^3 + 1 - a^2) + a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{1 - 2a + 2a^3 - a^4 + a^4 + a^{2N}}{1-a^2}$.\n$E_{min} = \\frac{1 - 2a + 2a^3 + a^{2N}}{1-a^2}$.\n\nThis is the final closed-form expression for the minimum least-squares error.", "answer": "$$\\boxed{\\frac{1 - 2a + 2a^{3} + a^{2N}}{1 - a^{2}}}$$"}]}