{"hands_on_practices": [{"introduction": "Understanding how correlation functions behave under basic arithmetic operations is a fundamental skill in signal analysis. This first practice explores the autocorrelation of a new process, $Z(t)$, formed by subtracting two jointly wide-sense stationary (WSS) processes. Mastering this elementary manipulation [@problem_id:1699346] provides the building blocks for analyzing more complex systems, such as those encountered in noise cancellation, where a signal of interest is estimated by subtracting a noise reference.", "problem": "Consider two jointly Wide-Sense Stationary (WSS) random processes, denoted by $X(t)$ and $Y(t)$. The statistical properties of these processes are characterized by their autocorrelation and cross-correlation functions. The autocorrelation function of $X(t)$ is defined as $R_{XX}(\\tau) = E[X(t+\\tau)X(t)]$, and similarly, the autocorrelation of $Y(t)$ is $R_{YY}(\\tau) = E[Y(t+\\tau)Y(t)]$. The cross-correlation functions between the two processes are given by $R_{XY}(\\tau) = E[X(t+\\tau)Y(t)]$ and $R_{YX}(\\tau) = E[Y(t+\\tau)X(t)]$.\n\nA new random process, $Z(t)$, is created by taking the difference between the original two processes: $Z(t) = X(t) - Y(t)$.\n\nDetermine the autocorrelation function of $Z(t)$, denoted as $R_{ZZ}(\\tau)$, expressed purely in terms of the functions $R_{XX}(\\tau)$, $R_{YY}(\\tau)$, $R_{XY}(\\tau)$, and $R_{YX}(\\tau)$.", "solution": "For a WSS process, the autocorrelation of any process $Z(t)$ is defined as $R_{ZZ}(\\tau) = E[Z(t+\\tau)Z(t)]$, which depends only on the lag $\\tau$. With $Z(t) = X(t) - Y(t)$, we write\n$$\nR_{ZZ}(\\tau) = E\\big[(X(t+\\tau) - Y(t+\\tau))(X(t) - Y(t))\\big].\n$$\nExpanding the product inside the expectation and using linearity of expectation gives\n$$\nR_{ZZ}(\\tau) = E[X(t+\\tau)X(t)] - E[X(t+\\tau)Y(t)] - E[Y(t+\\tau)X(t)] + E[Y(t+\\tau)Y(t)].\n$$\nBy the given definitions of the auto- and cross-correlation functions,\n$$\nE[X(t+\\tau)X(t)] = R_{XX}(\\tau), \\quad E[Y(t+\\tau)Y(t)] = R_{YY}(\\tau),\n$$\n$$\nE[X(t+\\tau)Y(t)] = R_{XY}(\\tau), \\quad E[Y(t+\\tau)X(t)] = R_{YX}(\\tau).\n$$\nTherefore,\n$$\nR_{ZZ}(\\tau) = R_{XX}(\\tau) - R_{XY}(\\tau) - R_{YX}(\\tau) + R_{YY}(\\tau) = R_{XX}(\\tau) + R_{YY}(\\tau) - R_{XY}(\\tau) - R_{YX}(\\tau).\n$$\nThis expresses $R_{ZZ}(\\tau)$ purely in terms of $R_{XX}(\\tau)$, $R_{YY}(\\tau)$, $R_{XY}(\\tau)$, and $R_{YX}(\\tau)$.", "answer": "$$\\boxed{R_{ZZ}(\\tau)=R_{XX}(\\tau)+R_{YY}(\\tau)-R_{XY}(\\tau)-R_{YX}(\\tau)}$$", "id": "1699346"}, {"introduction": "We now move from abstract properties to a concrete and vital application involving sinusoidal signals, the bedrock of communications and physics. This exercise examines two processes, a cosine and a sine wave, that share a random phase $\\Theta$, a common model for signals from oscillators where the initial phase is unknown. By calculating the cross-correlation function $R_{XY}(\\tau)$ [@problem_id:1699398], you will uncover the precise phase relationship between these so-called quadrature signals, a concept central to modulation schemes and phase-sensitive detection techniques.", "problem": "Consider two continuous-time random processes, $X(t)$ and $Y(t)$, which are generated by the same underlying physical phenomenon. These processes are described by the equations:\n$$X(t) = A \\cos(\\omega_0 t + \\Theta)$$\n$$Y(t) = A \\sin(\\omega_0 t + \\Theta)$$\nwhere $A$ and $\\omega_0$ are positive real constants representing the amplitude and angular frequency, respectively. The term $\\Theta$ is a random variable representing a phase shift, and it is uniformly distributed over the interval $[0, 2\\pi]$.\n\nThe cross-correlation between these two processes is a function of a time lag $\\tau$, defined as $R_{XY}(\\tau) = E[X(t+\\tau)Y(t)]$, where $E[\\cdot]$ denotes the expectation operator taken over the random variable $\\Theta$.\n\nDetermine the cross-correlation function $R_{XY}(\\tau)$. Your final answer should be a closed-form analytic expression in terms of $A$, $\\omega_0$, and $\\tau$.", "solution": "We are given\n$$X(t)=A\\cos(\\omega_{0}t+\\Theta),\\quad Y(t)=A\\sin(\\omega_{0}t+\\Theta),$$\nwith $\\Theta$ uniformly distributed on $[0,2\\pi]$. The cross-correlation is\n$$R_{XY}(\\tau)=E\\big[X(t+\\tau)Y(t)\\big]=E\\big[A\\cos(\\omega_{0}(t+\\tau)+\\Theta)\\cdot A\\sin(\\omega_{0}t+\\Theta)\\big].$$\nFactor out $A^{2}$ and define $\\phi=\\omega_{0}t+\\Theta$. Since $\\Theta$ is uniform on $[0,2\\pi]$, for any fixed $t$, the random variable $\\phi$ is also uniformly distributed over a $2\\pi$ interval. The expectation over $\\Theta$ can be calculated as an average over $\\phi$.\n$$R_{XY}(\\tau)=A^{2}E\\big[\\cos(\\phi+\\omega_{0}\\tau)\\;\\sin(\\phi)\\big]\n=\\frac{A^{2}}{2\\pi}\\int_{0}^{2\\pi}\\cos(\\phi+\\omega_{0}\\tau)\\;\\sin\\phi\\,d\\phi.$$\nUse the trigonometric identity $\\cos A \\sin B =\\tfrac{1}{2}\\big[\\sin(A+B)-\\sin(A-B)\\big]$ with $A=\\phi+\\omega_{0}\\tau$ and $B=\\phi$. Substituting gives\n$$R_{XY}(\\tau)=\\frac{A^{2}}{2\\pi}\\int_{0}^{2\\pi}\\frac{1}{2}\\big[\\sin(2\\phi+\\omega_{0}\\tau)-\\sin(\\omega_{0}\\tau)\\big]\\,d\\phi.$$\nThe first term integrates to zero: $\\int_{0}^{2\\pi}\\sin(2\\phi+\\omega_{0}\\tau)\\,d\\phi=0$, as it is an integral of a sinusoid over two full periods. For the second term, $\\sin(\\omega_{0}\\tau)$ is a constant with respect to $\\phi$, so $\\int_{0}^{2\\pi}(-\\sin(\\omega_{0}\\tau))\\,d\\phi=-2\\pi\\sin(\\omega_{0}\\tau)$. Therefore,\n$$R_{XY}(\\tau)=\\frac{A^2}{2\\pi} \\cdot \\frac{1}{2} \\left[ 0 - 2\\pi\\sin(\\omega_{0}\\tau) \\right] = -\\frac{A^{2}}{2}\\sin(\\omega_{0}\\tau).$$\nThis result is independent of $t$, consistent with the processes being jointly wide-sense stationary.", "answer": "$$\\boxed{-\\frac{A^{2}}{2}\\sin(\\omega_{0}\\tau)}$$", "id": "1699398"}, {"introduction": "Our final practice shifts focus to a different, yet equally important, class of random signals: discrete-event processes. The Poisson process is a powerful model for phenomena characterized by random point-like events, from photon arrivals in an optical detector to customer calls at a service center. This problem [@problem_id:1699352] leverages the defining quality of Poisson processes—that event counts in non-overlapping time intervals are statistically independent—to calculate their cross-correlation. This exercise provides direct, hands-on experience with the profound link between statistical independence and correlation, a cornerstone principle for analyzing event-based data across many scientific disciplines.", "problem": "In the field of quantum optics, a single-photon detector can sometimes register a \"click\" even in complete darkness due to thermal fluctuations or other background noise. This phenomenon is known as dark counts. The sequence of these dark counts can be modeled as a homogeneous Poisson process, $N(t)$, which represents the total number of counts registered up to time $t$. This process is characterized by a constant average rate of $\\lambda$ dark counts per second.\n\nA key property of a homogeneous Poisson process is that the number of events occurring in any interval of duration $T$ follows a Poisson distribution with a mean of $\\lambda T$. Furthermore, the numbers of events occurring in any two non-overlapping time intervals are statistically independent random variables.\n\nAn experiment is set up to characterize these dark counts. Two random variables are defined based on the number of counts in two distinct, non-overlapping time intervals. Let $X_1$ be the number of dark counts recorded in the time interval from $t_1$ to $t_2$, and $X_2$ be the number of dark counts recorded in the time interval from $t_3$ to $t_4$. These time points are ordered such that $0 \\le t_1 < t_2 \\le t_3 < t_4$. The random variables can thus be expressed as $X_1 = N(t_2) - N(t_1)$ and $X_2 = N(t_4) - N(t_3)$.\n\nDetermine the cross-correlation, defined as $R_{X_1 X_2} = E[X_1 X_2]$, between these two random variables. Express your answer as a symbolic expression in terms of the rate $\\lambda$ and the time points $t_1, t_2, t_3, \\text{ and } t_4$.", "solution": "The problem asks for the cross-correlation $R_{X_1 X_2}$ between the random variables $X_1 = N(t_2) - N(t_1)$ and $X_2 = N(t_4) - N(t_3)$. The cross-correlation is defined by the expectation of the product of the two random variables:\n$$R_{X_1 X_2} = E[X_1 X_2]$$\n\nThe random variable $X_1$ represents the number of events (dark counts) in the time interval $[t_1, t_2]$. The random variable $X_2$ represents the number of events in the time interval $[t_3, t_4]$.\n\nThe problem specifies the time ordering as $t_1 < t_2 \\le t_3 < t_4$. This ordering implies that the time interval $[t_1, t_2]$ and the time interval $[t_3, t_4]$ are non-overlapping.\n\nA fundamental property of the Poisson process, as stated in the problem, is that the number of events in non-overlapping intervals are independent random variables. Since $X_1$ and $X_2$ correspond to counts in non-overlapping intervals, they are statistically independent.\n\nFor any two independent random variables, the expectation of their product is equal to the product of their individual expectations. Therefore, we can write:\n$$E[X_1 X_2] = E[X_1] E[X_2]$$\n\nNow, we need to find the expectation of $X_1$ and $X_2$. The problem states that for a homogeneous Poisson process with rate $\\lambda$, the number of events in an interval of duration $T$ follows a Poisson distribution with mean $\\lambda T$.\n\nThe random variable $X_1$ is the number of counts in the interval $[t_1, t_2]$. The duration of this interval is $T_1 = t_2 - t_1$. Thus, $X_1$ is a Poisson random variable with a mean (expectation) given by:\n$$E[X_1] = \\lambda (t_2 - t_1)$$\n\nSimilarly, the random variable $X_2$ is the number of counts in the interval $[t_3, t_4]$. The duration of this interval is $T_2 = t_4 - t_3$. Thus, $X_2$ is a Poisson random variable with a mean (expectation) given by:\n$$E[X_2] = \\lambda (t_4 - t_3)$$\n\nFinally, we substitute these expectations back into the expression for the cross-correlation:\n$$R_{X_1 X_2} = E[X_1] E[X_2] = \\left( \\lambda (t_2 - t_1) \\right) \\left( \\lambda (t_4 - t_3) \\right)$$\n\nSimplifying this expression gives the final answer:\n$$R_{X_1 X_2} = \\lambda^2 (t_2 - t_1)(t_4 - t_3)$$", "answer": "$$\\boxed{\\lambda^{2}(t_2 - t_1)(t_4 - t_3)}$$", "id": "1699352"}]}