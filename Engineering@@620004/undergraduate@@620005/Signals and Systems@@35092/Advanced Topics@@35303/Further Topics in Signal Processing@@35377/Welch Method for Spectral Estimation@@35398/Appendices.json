{"hands_on_practices": [{"introduction": "Moving from theory to practice, our first hands-on exercise focuses on one of the most critical parameters in spectral analysis: frequency resolution. This calculation is the first step in ensuring your analysis is capable of distinguishing between different frequency components in a signal. This practice solidifies the direct relationship between the segment length chosen for Welch's method and the finest detail you can observe in the resulting power spectrum. [@problem_id:1773290]", "problem": "An engineer is analyzing the output signal from a Micro-Electro-Mechanical System (MEMS) gyroscope to characterize its noise profile. The gyroscope signal is sampled digitally at a sampling frequency of $f_s = 4096$ Hz for a total duration of $T = 12.0$ seconds. To estimate the Power Spectral Density (PSD) of the noise, the engineer employs Welch's method. This method involves partitioning the signal into overlapping segments, applying a window function to each segment, and averaging the periodograms of these windowed segments. The engineer chooses to use segments of length $L = 2048$ samples, with a 50% overlap between consecutive segments.\n\nCalculate the frequency resolution of the resulting PSD estimate. Express your answer in Hz, rounded to three significant figures.", "solution": "The problem asks for the frequency resolution of a Power Spectral Density (PSD) estimate calculated using Welch's method.\n\nThe fundamental principle underlying spectral analysis via the Discrete Fourier Transform (DFT) is that the frequency resolution, $\\Delta f$, is determined by the sampling frequency, $f_s$, and the number of samples, $N_{DFT}$, used in the DFT calculation. The formula is:\n$$\n\\Delta f = \\frac{f_s}{N_{DFT}}\n$$\n\nIn Welch's method, the original long signal is divided into shorter segments. A DFT is then computed for each of these individual segments. Therefore, the number of points in the DFT, $N_{DFT}$, is equal to the length of a single segment, $L$. The resulting spectra from all segments are then averaged to produce a final PSD estimate with reduced variance.\n\nThe parameters given in the problem are:\n- Sampling frequency: $f_s = 4096$ Hz\n- Total signal duration: $T = 12.0$ s\n- Segment length: $L = 2048$ samples\n- Overlap: 50%\n\nFor calculating the frequency resolution, the relevant parameters are the sampling frequency $f_s$ and the segment length $L$. The number of samples in the DFT for each segment is $N_{DFT} = L = 2048$.\n\nThe total signal duration $T$ and the overlap percentage are important for determining the total number of segments that are averaged, which in turn affects the statistical variance (or stability) of the final PSD estimate. However, they do not influence the frequency resolution, which is solely a function of the segment length and sampling rate.\n\nUsing the formula for frequency resolution with $N_{DFT} = L$:\n$$\n\\Delta f = \\frac{f_s}{L}\n$$\n\nNow, we substitute the given numerical values:\n$$\n\\Delta f = \\frac{4096 \\text{ Hz}}{2048}\n$$\n\nPerforming the calculation:\n$$\n\\Delta f = 2.00 \\text{ Hz}\n$$\n\nThe question asks for the answer to be rounded to three significant figures. The calculated value is exactly 2, so to express this with three significant figures, we write it as $2.00$.", "answer": "$$\\boxed{2.00}$$", "id": "1773290"}, {"introduction": "The power of Welch's method lies in its flexibility, but this requires making an informed decision about a fundamental trade-off. This conceptual exercise explores the dual impact of segment length on both frequency resolution and the statistical smoothness (or variance) of the final estimate. By reasoning through the qualitative descriptions of two Power Spectral Density plots, you will develop a strong intuition for this core compromise in practical spectral estimation. [@problem_id:1773291]", "problem": "An engineer is tasked with analyzing a discrete-time signal, $x[n]$, which is known to be the sum of two distinct sinusoidal components corrupted by additive white noise. To estimate the signal's frequency content, the engineer computes the Power Spectral Density (PSD) using Welch's method. Two separate estimates are generated from the exact same signal $x[n]$, and they are labeled Estimate A and Estimate B.\n\nThe only parameter that was altered between the two computations was the length of the individual segments used in the Welch algorithm. All other parameters, such as the choice of window function and the percentage of overlap between segments, were kept identical.\n\nThe following qualitative observations are made by comparing the two resulting PSD plots:\n\n*   **Estimate A:** The plot displays two distinct peaks, but they are very broad and somewhat smeared. The baseline of the plot, representing the noise floor, is very smooth and shows minimal random fluctuation.\n*   **Estimate B:** The plot shows two extremely sharp and well-defined peaks at the frequencies of the two sinusoids. However, the entire plot, including the noise floor, appears jagged and has a high degree of random, spiky variation from one frequency bin to the next.\n\nBased on these descriptions, what is the relationship between the segment length, $L_A$, used for Estimate A and the segment length, $L_B$, used for Estimate B?\n\nA. $L_A < L_B$\n\nB. $L_A > L_B$\n\nC. $L_A = L_B$\n\nD. The relationship cannot be determined without knowing the total signal length.\n\nE. The relationship cannot be determined without knowing the window function used.", "solution": "Welch’s method estimates the power spectral density by averaging windowed, overlapped periodograms computed on segments of length $L$. Let the total data length be $N$, the overlap be a fixed fraction $\\rho$ (identical in both estimates), and the window $w[n]$ be fixed.\n\n1) Definition of the Welch estimator:\nFor segment index $k=0,\\ldots,K-1$, form\n$$\nX_{k}[m] = \\sum_{n=0}^{L-1} x_{k}[n]\\,w[n]\\exp\\!\\left(-j\\frac{2\\pi mn}{L}\\right),\n$$\nand the per-segment periodogram\n$$\nI_{k}[m] = \\frac{1}{U L}\\,|X_{k}[m]|^{2}, \\quad U = \\frac{1}{L}\\sum_{n=0}^{L-1} w^{2}[n].\n$$\nThe Welch PSD estimate is\n$$\n\\hat{S}[m] = \\frac{1}{K}\\sum_{k=0}^{K-1} I_{k}[m].\n$$\n\n2) Frequency resolution versus segment length:\nThe spectral window is $W(\\omega)=\\sum_{n=0}^{L-1} w[n]\\exp(-j\\omega n)$. Its main-lobe width satisfies\n$$\n\\Delta\\omega_{\\text{ML}} = \\frac{c_{w}}{L},\n$$\nwhere $c_{w}$ depends only on the chosen window (identical in both estimates). Thus, larger $L$ yields smaller $\\Delta\\omega_{\\text{ML}}$, i.e., sharper, better-resolved spectral peaks; smaller $L$ yields broader peaks.\n\n3) Variance reduction by averaging and dependence on $L$:\nWith fixed window and overlap, the variance of the Welch estimator scales inversely with the effective number of averaged segments $K$:\n$$\n\\operatorname{var}\\{\\hat{S}[m]\\} \\propto \\frac{1}{K},\n$$\nup to a constant that depends only on the window and overlap (both fixed here). For fixed $N$ and overlap fraction $\\rho$, increasing $L$ decreases $K$ (fewer segments fit into $N$), while decreasing $L$ increases $K$ (more segments). Hence, larger $L$ implies a more “jagged” PSD (higher variance), and smaller $L$ implies a smoother PSD (lower variance).\n\n4) Mapping observations to $L$:\n- Estimate A: broad, smeared peaks (poor resolution) and a very smooth noise floor (low variance) imply small $L$ and large $K$.\n- Estimate B: extremely sharp peaks (good resolution) and a jagged, spiky noise floor (high variance) imply large $L$ and small $K$.\n\nTherefore, the segment lengths satisfy\n$$\nL_{A} < L_{B}.\n$$\nThis conclusion depends only on how $L$ affects resolution and variance under fixed window and overlap; it does not require knowledge of the total length $N$ or the specific window beyond being identical across estimates.\n\nHence, the correct choice is A.", "answer": "$$\\boxed{A}$$", "id": "1773291"}, {"introduction": "At the heart of the Welch method is the act of averaging to reduce noise, but what exactly should be averaged? This problem delves into the statistical foundation of the method by asking a crucial question: why do we average the *power* (the squared magnitude) of each segment's spectrum, instead of averaging the complex-valued spectra directly? This practice reveals the profound difference between \"incoherent\" and \"coherent\" averaging and justifies the standard procedure for obtaining a reliable power estimate from random signals. [@problem_id:1773260]", "problem": "An engineer is developing a custom signal processing routine to estimate the Power Spectral Density (PSD) of a stationary random signal. The standard approach, known as Welch's method, involves dividing the signal into segments, computing the Discrete Fourier Transform (DFT) for each segment, and averaging the squared magnitudes of these DFTs.\n\nThe engineer decides to investigate an alternative procedure. The long input signal is divided into $L$ non-overlapping segments of equal length. For each segment, the DFT is computed, resulting in a set of complex-valued spectra $\\{X_1[k], X_2[k], \\dots, X_L[k]\\}$ for each discrete frequency bin $k$.\n\nTwo different averaging procedures are proposed to obtain the final PSD estimate at a specific frequency bin $k$:\n\nProcedure A (Standard Incoherent Average): The estimate $P_A[k]$ is calculated by averaging the power (squared magnitude) of the individual DFTs.\n$$P_A[k] = \\frac{1}{L} \\sum_{i=1}^{L} |X_i[k]|^2$$\n\nProcedure B (Alternative Coherent Average): The estimate $P_B[k]$ is calculated by first averaging the complex DFT results and then computing the squared magnitude of this average.\n$$P_B[k] = \\left| \\frac{1}{L} \\sum_{i=1}^{L} X_i[k] \\right|^2$$\n\nTo analyze the performance of these estimators, assume the underlying signal is a zero-mean, wide-sense stationary random process. This implies that for any given frequency bin $k$ (not corresponding to the DC component), the complex DFT coefficients $X_i[k]$ across different segments $i = 1, \\dots, L$ can be modeled as independent and identically distributed (i.i.d.) complex random variables with an expected value of zero, i.e., $E[X_i[k]] = 0$.\n\nDetermine the theoretical ratio of the expected value of the estimate from Procedure B to the expected value of the estimate from Procedure A. That is, find an expression for $\\frac{E[P_B[k]]}{E[P_A[k]]}$.", "solution": "The goal is to compute the ratio $\\frac{E[P_B[k]]}{E[P_A[k]]}$. We will calculate the expected value of each estimator, $P_A[k]$ and $P_B[k]$, separately.\n\nFirst, let's analyze Procedure A, the standard incoherent average. The estimator is given by:\n$$P_A[k] = \\frac{1}{L} \\sum_{i=1}^{L} |X_i[k]|^2$$\nWe take the expected value of this expression. Due to the linearity of the expectation operator, we can move it inside the sum:\n$$E[P_A[k]] = E\\left[ \\frac{1}{L} \\sum_{i=1}^{L} |X_i[k]|^2 \\right] = \\frac{1}{L} \\sum_{i=1}^{L} E[|X_i[k]|^2]$$\nThe problem states that the complex DFT coefficients $X_i[k]$ are independent and identically distributed (i.i.d.) for $i=1, \\dots, L$. This means that the expected squared magnitude, $E[|X_i[k]|^2]$, is the same for all segments $i$. Let's denote this constant value as $\\sigma_X^2$, which represents the true power of the signal at frequency bin $k$.\n$$E[|X_1[k]|^2] = E[|X_2[k]|^2] = \\dots = E[|X_L[k]|^2] = \\sigma_X^2$$\nSubstituting this into the expression for $E[P_A[k]]$:\n$$E[P_A[k]] = \\frac{1}{L} \\sum_{i=1}^{L} \\sigma_X^2 = \\frac{1}{L} (L \\cdot \\sigma_X^2) = \\sigma_X^2$$\nThis shows that the estimator from Procedure A is an unbiased estimator of the true power $\\sigma_X^2$.\n\nNext, let's analyze Procedure B, the alternative coherent average. The estimator is:\n$$P_B[k] = \\left| \\frac{1}{L} \\sum_{i=1}^{L} X_i[k] \\right|^2$$\nTo find its expected value, $E[P_B[k]]$, we use the property that for any complex random variable $Z$, its expected squared magnitude is related to its variance and mean by $E[|Z|^2] = \\text{Var}(Z) + |E[Z]|^2$.\nLet's define the complex random variable $Z = \\frac{1}{L} \\sum_{i=1}^{L} X_i[k]$. Then $P_B[k] = |Z|^2$.\nWe first compute the mean of $Z$:\n$$E[Z] = E\\left[ \\frac{1}{L} \\sum_{i=1}^{L} X_i[k] \\right] = \\frac{1}{L} \\sum_{i=1}^{L} E[X_i[k]]$$\nThe problem states that the process is zero-mean, leading to $E[X_i[k]] = 0$ for all $i$. Therefore:\n$$E[Z] = \\frac{1}{L} \\sum_{i=1}^{L} 0 = 0$$\nNext, we compute the variance of $Z$. Since the $X_i[k]$ are independent, the variance of their sum is the sum of their variances.\n$$\\text{Var}(Z) = \\text{Var}\\left( \\frac{1}{L} \\sum_{i=1}^{L} X_i[k] \\right) = \\frac{1}{L^2} \\text{Var}\\left( \\sum_{i=1}^{L} X_i[k] \\right) = \\frac{1}{L^2} \\sum_{i=1}^{L} \\text{Var}(X_i[k])$$\nThe variance of a single complex random variable $X_i[k]$ is given by $\\text{Var}(X_i[k]) = E[|X_i[k]|^2] - |E[X_i[k]]|^2$. Since $E[X_i[k]] = 0$, this simplifies to:\n$$\\text{Var}(X_i[k]) = E[|X_i[k]|^2] - 0 = \\sigma_X^2$$\nSince the variables are i.i.d., the variance is the same for all $i$. Substituting this back into the expression for $\\text{Var}(Z)$:\n$$\\text{Var}(Z) = \\frac{1}{L^2} \\sum_{i=1}^{L} \\sigma_X^2 = \\frac{1}{L^2} (L \\cdot \\sigma_X^2) = \\frac{\\sigma_X^2}{L}$$\nNow we can compute the expected value of $P_B[k]$:\n$$E[P_B[k]] = E[|Z|^2] = \\text{Var}(Z) + |E[Z]|^2 = \\frac{\\sigma_X^2}{L} + |0|^2 = \\frac{\\sigma_X^2}{L}$$\nThis shows that the expected value of the estimate from Procedure B is biased and is smaller than the true power by a factor of $L$.\n\nFinally, we compute the desired ratio:\n$$\\frac{E[P_B[k]]}{E[P_A[k]]} = \\frac{\\sigma_X^2 / L}{\\sigma_X^2} = \\frac{1}{L}$$\nThe ratio shows that coherently averaging the complex DFTs before squaring the magnitude reduces the expected power estimate by a factor equal to the number of segments, $L$. This is because the random phases of the DFT coefficients from different segments tend to cancel each other out during the averaging process.", "answer": "$$\\boxed{\\frac{1}{L}}$$", "id": "1773260"}]}