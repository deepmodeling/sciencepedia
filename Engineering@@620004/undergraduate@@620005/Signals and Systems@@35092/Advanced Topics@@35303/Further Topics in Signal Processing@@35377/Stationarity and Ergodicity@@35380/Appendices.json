{"hands_on_practices": [{"introduction": "Understanding stationarity often begins with the most fundamental property: the ensemble mean. This first exercise [@problem_id:1755455] provides a hands-on look at a simple, intuitive model of a signal that starts at a random time. By calculating the mean function, you will directly test if the process's average behavior is constant over time, which is the first condition for wide-sense stationarity.", "problem": "Consider a random signal model that could represent the startup of a device at a random time. The process, denoted by $X(t)$, is defined as:\n$$\nX(t) = A u(t-T)\n$$\nwhere $A$ is a positive real constant, $u(t)$ is the Heaviside unit step function, and $T$ is a continuous random variable representing a time delay. The probability density function (PDF) for the random variable $T$ is given by a one-sided exponential distribution:\n$$\np_T(\\tau) =\n\\begin{cases}\n\\lambda \\exp(-\\lambda \\tau) & \\text{for } \\tau \\geq 0 \\\\\n0 & \\text{for } \\tau < 0\n\\end{cases}\n$$\nwhere $\\lambda$ is a positive real constant.\n\nYour task is to find the ensemble average, or mean function, $\\mu_X(t) = E[X(t)]$, for this random process and determine if the process is wide-sense stationary (WSS). Select the option that correctly provides both the mean function and the conclusion about its stationarity.\n\nA. The mean is $\\mu_X(t) = A(1 - \\exp(-\\lambda t))u(t)$, and the process is not WSS.\n\nB. The mean is $\\mu_X(t) = A(1 - \\exp(-\\lambda t))u(t)$, and the process is WSS.\n\nC. The mean is $\\mu_X(t) = A \\exp(-\\lambda t)u(t)$, and the process is not WSS.\n\nD. The mean is $\\mu_X(t) = A \\lambda \\exp(-\\lambda t)u(t)$, and the process is not WSS.\n\nE. The mean is $\\mu_X(t) = A/2$, and the process is WSS.", "solution": "We are given the random process $X(t) = A\\,u(t-T)$, where $A$ is a positive constant, $u(\\cdot)$ is the Heaviside unit step function, and $T$ is an exponential random variable with PDF $p_{T}(\\tau) = \\lambda \\exp(-\\lambda \\tau)$ for $\\tau \\geq 0$ and $0$ otherwise. The ensemble average is defined by\n$$\n\\mu_{X}(t) = E[X(t)] = E[A\\,u(t-T)] = A\\,E[u(t-T)] = A \\int_{-\\infty}^{\\infty} u(t-\\tau)\\,p_{T}(\\tau)\\,d\\tau.\n$$\nSubstituting the support of $p_{T}(\\tau)$, this becomes\n$$\n\\mu_{X}(t) = A \\int_{0}^{\\infty} u(t-\\tau)\\,\\lambda \\exp(-\\lambda \\tau)\\,d\\tau.\n$$\nThe step $u(t-\\tau)$ equals $1$ when $\\tau \\leq t$ and $0$ otherwise. Therefore:\n- If $t < 0$, there is no $\\tau \\geq 0$ such that $\\tau \\leq t$, so the integral is zero and $\\mu_{X}(t) = 0$.\n- If $t \\geq 0$, the integral runs from $\\tau = 0$ to $\\tau = t$, yielding\n$$\n\\mu_{X}(t) = A \\int_{0}^{t} \\lambda \\exp(-\\lambda \\tau)\\,d\\tau = A\\left[ -\\exp(-\\lambda \\tau) \\right]_{0}^{t} = A\\left(1 - \\exp(-\\lambda t)\\right).\n$$\nCombining both cases,\n$$\n\\mu_{X}(t) = A\\left(1 - \\exp(-\\lambda t)\\right) u(t).\n$$\nTo assess wide-sense stationarity (WSS), recall that a WSS process must have a mean that is constant in time and an autocorrelation that depends only on time differences. Since $\\mu_{X}(t)$ explicitly depends on $t$ (it rises from $0$ and approaches $A$ as $t \\to \\infty$), the mean is not constant. Therefore, the process is not WSS.\n\nThe correct option is the one giving $\\mu_{X}(t) = A\\left(1 - \\exp(-\\lambda t)\\right)u(t)$ and stating that the process is not WSS.", "answer": "$$\\boxed{A}$$", "id": "1755455"}, {"introduction": "While a constant mean is necessary for wide-sense stationarity, it is not sufficient; the second-order statistics must also be time-invariant. This practice [@problem_id:1755509] delves into a common model for communication signals and challenges you to find the specific conditions under which its autocorrelation function depends only on the time lag. You will see how adjusting the statistical properties of a signal's components can ensure it meets the full criteria for being wide-sense stationary.", "problem": "A random process $X(t)$ is generated as a model for a specific type of modulated signal in a communication system. The process is defined as:\n$$\nX(t) = 3 A_I \\cos(\\omega_0 t) + 5 A_Q \\sin(\\omega_0 t)\n$$\nwhere $t$ represents time, and $\\omega_0$ is a positive constant angular frequency. The amplitudes $A_I$ and $A_Q$ are statistically independent random variables. Both variables have a mean of zero. The variance of $A_I$ is denoted by $\\sigma_I^2 = \\text{Var}(A_I)$, and the variance of $A_Q$ is denoted by $\\sigma_Q^2 = \\text{Var}(A_Q)$. Assume both variances are non-zero.\n\nFor a random process to be classified as wide-sense stationary (WSS), two conditions must be satisfied:\n1.  The mean function of the process, $\\mu_X(t) = E[X(t)]$, must be a constant for all time $t$.\n2.  The autocorrelation function of the process, $R_X(t_1, t_2) = E[X(t_1)X(t_2)]$, must depend only on the time lag $\\tau = t_1 - t_2$.\n\nDetermine the numerical value of the ratio $r = \\frac{\\sigma_I^2}{\\sigma_Q^2}$ that is required for the process $X(t)$ to be wide-sense stationary. Express your answer as a fraction.", "solution": "We are given the random process\n$$\nX(t) = 3 A_{I} \\cos(\\omega_{0} t) + 5 A_{Q} \\sin(\\omega_{0} t),\n$$\nwith $A_{I}$ and $A_{Q}$ independent, zero-mean random variables with variances $\\sigma_{I}^{2} = \\text{Var}(A_{I})$ and $\\sigma_{Q}^{2} = \\text{Var}(A_{Q})$, both non-zero. For wide-sense stationarity (WSS), we require:\n1) The mean $\\mu_{X}(t) = E[X(t)]$ is constant in $t$.\n2) The autocorrelation $R_{X}(t_{1}, t_{2}) = E[X(t_{1}) X(t_{2})]$ depends only on $\\tau = t_{1} - t_{2}$.\n\nFirst, compute the mean. Using linearity of expectation and the given zero means,\n$$\n\\mu_{X}(t) = E\\!\\left[3 A_{I} \\cos(\\omega_{0} t) + 5 A_{Q} \\sin(\\omega_{0} t)\\right]\n= 3 \\cos(\\omega_{0} t) E[A_{I}] + 5 \\sin(\\omega_{0} t) E[A_{Q}] = 0,\n$$\nwhich is a constant (zero) for all $t$. Thus, condition 1 is satisfied.\n\nNext, compute the autocorrelation. Expand the product and take expectation:\n$$\n\\begin{aligned}\nR_{X}(t_{1}, t_{2}) &= E\\!\\left[X(t_{1}) X(t_{2})\\right] \\\\\n&= E\\!\\left[\\left(3 A_{I} \\cos(\\omega_{0} t_{1}) + 5 A_{Q} \\sin(\\omega_{0} t_{1})\\right)\n\\left(3 A_{I} \\cos(\\omega_{0} t_{2}) + 5 A_{Q} \\sin(\\omega_{0} t_{2})\\right)\\right] \\\\\n&= 9 E[A_{I}^{2}] \\cos(\\omega_{0} t_{1}) \\cos(\\omega_{0} t_{2})\n+ 15 E[A_{I} A_{Q}] \\left(\\cos(\\omega_{0} t_{1}) \\sin(\\omega_{0} t_{2}) + \\sin(\\omega_{0} t_{1}) \\cos(\\omega_{0} t_{2})\\right) \\\\\n&\\quad + 25 E[A_{Q}^{2}] \\sin(\\omega_{0} t_{1}) \\sin(\\omega_{0} t_{2}).\n\\end{aligned}\n$$\nIndependence and zero means imply $E[A_{I} A_{Q}] = E[A_{I}] E[A_{Q}] = 0$. Using $E[A_{I}^{2}] = \\sigma_{I}^{2}$ and $E[A_{Q}^{2}] = \\sigma_{Q}^{2}$, we obtain\n$$\nR_{X}(t_{1}, t_{2}) = 9 \\sigma_{I}^{2} \\cos(\\omega_{0} t_{1}) \\cos(\\omega_{0} t_{2})\n+ 25 \\sigma_{Q}^{2} \\sin(\\omega_{0} t_{1}) \\sin(\\omega_{0} t_{2}).\n$$\nApply the product-to-sum identities\n$$\n\\cos a \\cos b = \\frac{1}{2}\\left[\\cos(a-b) + \\cos(a+b)\\right], \\quad\n\\sin a \\sin b = \\frac{1}{2}\\left[\\cos(a-b) - \\cos(a+b)\\right],\n$$\nwith $a = \\omega_{0} t_{1}$ and $b = \\omega_{0} t_{2}$. This yields\n$$\n\\begin{aligned}\nR_{X}(t_{1}, t_{2})\n&= \\frac{9 \\sigma_{I}^{2}}{2}\\left[\\cos\\!\\left(\\omega_{0}(t_{1}-t_{2})\\right) + \\cos\\!\\left(\\omega_{0}(t_{1}+t_{2})\\right)\\right]\n+ \\frac{25 \\sigma_{Q}^{2}}{2}\\left[\\cos\\!\\left(\\omega_{0}(t_{1}-t_{2})\\right) - \\cos\\!\\left(\\omega_{0}(t_{1}+t_{2})\\right)\\right] \\\\\n&= \\frac{1}{2}\\left(9 \\sigma_{I}^{2} + 25 \\sigma_{Q}^{2}\\right) \\cos\\!\\left(\\omega_{0}(t_{1}-t_{2})\\right)\n+ \\frac{1}{2}\\left(9 \\sigma_{I}^{2} - 25 \\sigma_{Q}^{2}\\right) \\cos\\!\\left(\\omega_{0}(t_{1}+t_{2})\\right).\n\\end{aligned}\n$$\nFor WSS, $R_{X}(t_{1}, t_{2})$ must depend only on $\\tau = t_{1} - t_{2}$, so the coefficient of $\\cos\\!\\left(\\omega_{0}(t_{1}+t_{2})\\right)$ must be zero:\n$$\n9 \\sigma_{I}^{2} - 25 \\sigma_{Q}^{2} = 0 \\quad \\Longrightarrow \\quad \\frac{\\sigma_{I}^{2}}{\\sigma_{Q}^{2}} = \\frac{25}{9}.\n$$\nWith this ratio, the autocorrelation simplifies to\n$$\nR_{X}(t_{1}, t_{2}) = \\frac{1}{2}\\left(9 \\sigma_{I}^{2} + 25 \\sigma_{Q}^{2}\\right) \\cos\\!\\left(\\omega_{0}(t_{1}-t_{2})\\right),\n$$\nwhich depends only on $\\tau$, and the mean is constant, so $X(t)$ is WSS.\n\nTherefore, the required ratio is $\\sigma_{I}^{2}/\\sigma_{Q}^{2} = \\frac{25}{9}$.", "answer": "$$\\boxed{\\frac{25}{9}}$$", "id": "1755509"}, {"introduction": "Ergodicity connects the theoretical world of ensemble averages to the practical world of time-series measurements. This final exercise [@problem_id:1755454] explores a crucial question: when can a long measurement from a *single* system be used to estimate the average properties of an entire *collection* of similar systems? By analyzing a sensor model with a random but constant imperfection, you will discover the conditions under which a process fails to be mean-ergodic and what this implies for real-world signal analysis.", "problem": "In the quality control process for a new type of digital sensor, the output signal is modeled as a discrete-time random process $S[n]$. Each sensor manufactured has a slight, unpredictable imperfection, resulting in a random but constant Direct Current (DC) offset unique to that sensor. This offset is represented by a random variable $A$. Superimposed on this offset is a noise signal, $X[n]$, which is inherent to the sensor's operation. Thus, the signal from a randomly selected sensor is described by the process $S[n] = A + X[n]$.\n\nThe random DC offset $A$ for any given sensor is constant over time. For the entire batch of sensors, its value is governed by the probability distribution $P(A = V_0) = 0.5$ and $P(A = -V_0) = 0.5$, where $V_0$ is a non-negative real constant representing the magnitude of the offset.\n\nThe noise process $X[n]$ is a sequence of independent and identically distributed (i.i.d.) Bernoulli random variables. At each time step $n$, the noise follows the distribution $P(X[n] = 1) = p$ and $P(X[n] = 0) = 1-p$, where $0 < p < 1$. The random variable $A$ is statistically independent of the entire noise process $X[n]$.\n\nA key desirable property for this sensor model is mean-ergodicity, which implies that the ensemble mean (the average behavior over the entire batch of sensors) can be reliably estimated from a long-term time average of the signal from a single sensor. Under what condition on the parameters $p$ and $V_0$ is the process $S[n]$ mean-ergodic?\n\nA. The process is mean-ergodic for all values of $p$ and $V_0$.\n\nB. The process is mean-ergodic only if $p = 0.5$.\n\nC. The process is mean-ergodic only if $V_0 = 0$.\n\nD. The process is mean-ergodic only if $p = 0.5$ and $V_0 = 0$.\n\nE. The process is never mean-ergodic.", "solution": "We model the process as $S[n]=A+X[n]$ with $A$ independent of $\\{X[n]\\}$, where $A$ is constant over time for a given realization and takes values $\\pm V_{0}$ with equal probabilities, and $X[n]$ are i.i.d. Bernoulli with $P(X[n]=1)=p$ and $P(X[n]=0)=1-p$, with $0<p<1$.\n\nFirst compute the ensemble mean $m_{S}$:\n$$\nm_{S} \\triangleq \\mathbb{E}[S[n]]=\\mathbb{E}[A]+\\mathbb{E}[X[n]].\n$$\nUsing $P(A=V_{0})=P(A=-V_{0})=\\frac{1}{2}$,\n$$\n\\mathbb{E}[A]=\\frac{1}{2}V_{0}+\\frac{1}{2}(-V_{0})=0,\n$$\nand\n$$\n\\mathbb{E}[X[n]]=p.\n$$\nHence,\n$$\nm_{S}=p.\n$$\n\nConsider the time average over $N$ samples of one realization:\n$$\n\\overline{S}_{N}\\triangleq \\frac{1}{N}\\sum_{n=1}^{N}S[n]=A+\\frac{1}{N}\\sum_{n=1}^{N}X[n]\\equiv A+\\overline{X}_{N}.\n$$\nSince $\\{X[n]\\}$ are i.i.d. with variance $\\sigma_{X}^{2}=p(1-p)$, we have\n$$\n\\mathbb{E}\\big[(\\overline{X}_{N}-p)^{2}\\big]=\\operatorname{Var}(\\overline{X}_{N})=\\frac{1}{N^{2}}\\sum_{n=1}^{N}\\operatorname{Var}(X[n])=\\frac{N\\,\\sigma_{X}^{2}}{N^{2}}=\\frac{p(1-p)}{N}\\to 0 \\quad \\text{as } N\\to\\infty.\n$$\nTherefore,\n$$\n\\overline{X}_{N}\\xrightarrow{m.s.} p,\n$$\nand consequently\n$$\n\\overline{S}_{N}\\xrightarrow{m.s.} A+p.\n$$\n\nMean-ergodicity in the mean-square sense requires\n$$\n\\overline{S}_{N}\\xrightarrow{m.s.} m_{S}=p.\n$$\nFrom the limit above, this occurs if and only if $A=0$ almost surely. Under the given distribution $P(A=V_{0})=P(A=-V_{0})=\\frac{1}{2}$, this happens if and only if $V_{0}=0$. The value of $p$ does not affect this condition.\n\nTherefore, $S[n]$ is mean-ergodic only if $V_{0}=0$, which corresponds to option C.", "answer": "$$\\boxed{C}$$", "id": "1755454"}]}