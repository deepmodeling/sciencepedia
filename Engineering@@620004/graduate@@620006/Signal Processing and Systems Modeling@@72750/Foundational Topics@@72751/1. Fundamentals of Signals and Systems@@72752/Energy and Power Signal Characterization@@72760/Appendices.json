{"hands_on_practices": [{"introduction": "Real-world signals are rarely simple; they are often composite waveforms made up of different components. This exercise challenges you to apply the fundamental definitions of energy and power to a signal composed of a periodic (power) component and a transient (energy) component. By working through this problem [@problem_id:2869250], you will solidify your understanding of how to classify such composite signals and correctly calculate their total average power, reinforcing key principles of signal decomposition.", "problem": "Consider a deterministic real-valued signal defined for all real time $t$ as $x(t) = s(t) + r(t)$, where $s(t)$ is a periodic bipolar-rectangular waveform with a constant offset and $r(t)$ is an exponentially decaying transient. The periodic component $s(t)$ has fundamental period $T_{0} = 2$ and is given by\n$$\ns(t) = C + B\\,q(t),\n$$\nwhere $C = 1$, $B = 2$, and $q(t)$ is the $T_{0}$-periodic waveform defined for each integer $k$ by\n$$\nq(t) = \n\\begin{cases}\n+1, & t \\in [kT_{0},\\, kT_{0} + D T_{0}), \\\\\n-1, & t \\in [kT_{0} + D T_{0},\\, (k+1)T_{0}),\n\\end{cases}\n$$\nwith duty factor $D = \\frac{1}{3}$. The transient component is\n$$\nr(t) = A\\,\\exp(-\\alpha t)\\,u(t),\n$$\nwith $A = 3$, $\\alpha = 5$, and $u(t)$ the unit step defined by $u(t) = 1$ for $t \\ge 0$ and $u(t) = 0$ for $t < 0$.\n\nAssume $x(t)$ is the voltage across a $1\\,\\Omega$ resistor. Using only foundational definitions of signal energy and time-average power, first determine whether $x(t)$ is an energy signal, a power signal, or neither. Then compute the long-term average power delivered to the resistor by $x(t)$. Express the final power in watts (W) and round your answer to four significant figures. Your final numerical answer must be a single real number.", "solution": "The task is to classify the signal $x(t)$ and compute its long-term average power. We must use the foundational definitions. The total energy of a signal $x(t)$ is defined as\n$$E_x = \\int_{-\\infty}^{\\infty} |x(t)|^2 \\,dt$$\nand its time-average power is defined as\n$$P_x = \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} |x(t)|^2 \\,dt$$\nA signal is an energy signal if its energy $E_x$ is finite and non-zero ($0 < E_x < \\infty$), which implies its average power is zero ($P_x = 0$). A signal is a power signal if its average power $P_x$ is finite and non-zero ($0 < P_x < \\infty$), which implies its energy is infinite ($E_x = \\infty$).\n\nThe signal is given as a sum $x(t) = s(t) + r(t)$. We analyze each component separately.\n\nThe transient component is $r(t) = A\\,\\exp(-\\alpha t)\\,u(t)$, with $A=3$ and $\\alpha=5$. Its energy is\n$$E_r = \\int_{-\\infty}^{\\infty} |r(t)|^2 \\,dt = \\int_{0}^{\\infty} (A\\,\\exp(-\\alpha t))^2 \\,dt = A^2 \\int_{0}^{\\infty} \\exp(-2\\alpha t) \\,dt$$\nSince $\\alpha = 5 > 0$, the integral converges:\n$$E_r = A^2 \\left[ \\frac{\\exp(-2\\alpha t)}{-2\\alpha} \\right]_{0}^{\\infty} = A^2 \\left( 0 - \\frac{1}{-2\\alpha} \\right) = \\frac{A^2}{2\\alpha}$$\nSubstituting the given values, $E_r = \\frac{3^2}{2(5)} = \\frac{9}{10}$. Since $0 < E_r < \\infty$, $r(t)$ is an energy signal. The average power of an energy signal is zero, $P_r = 0$.\n\nThe periodic component is $s(t) = C + B\\,q(t)$, with $C=1$ and $B=2$. Since $s(t)$ is a non-zero periodic signal for all $t \\in (-\\infty, \\infty)$, its total energy is infinite. We compute its average power, which is finite for a periodic signal and can be calculated over a single period $T_0$:\n$$P_s = \\frac{1}{T_0} \\int_{0}^{T_0} |s(t)|^2 \\,dt$$\nTherefore, $s(t)$ is a power signal.\n\nNow, we analyze the composite signal $x(t) = s(t) + r(t)$. Its average power is\n$$P_x = \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} |s(t) + r(t)|^2 \\,dt$$\nExpanding the integrand:\n$$P_x = \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} (s(t)^2 + 2s(t)r(t) + r(t)^2) \\,dt$$\nBy linearity of limits and integrals, this becomes:\n$$P_x = \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} s(t)^2 \\,dt + \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} r(t)^2 \\,dt + \\lim_{T \\to \\infty} \\frac{1}{2T} \\int_{-T}^{T} 2s(t)r(t) \\,dt$$\nThe first term is the power of $s(t)$, which is $P_s$. The second term is the power of $r(t)$, which is $P_r = 0$. The third term is the cross-power term. Since $r(t)=0$ for $t<0$, the integral becomes an integral from $0$ to $T$:\n$$\\lim_{T \\to \\infty} \\frac{1}{T} \\int_{0}^{T} s(t)r(t) \\,dt$$\nThe signal $s(t)$ is periodic and thus bounded. Let its maximum absolute value be $S_{max} = |C|+|B| = 1+2=3$. The function $s(t)r(t)$ is absolutely integrable:\n$$\\int_{0}^{\\infty} |s(t)r(t)| \\,dt = \\int_{0}^{\\infty} |s(t) A \\exp(-\\alpha t)| \\,dt \\le S_{max} A \\int_{0}^{\\infty} \\exp(-\\alpha t) \\,dt = \\frac{S_{max} A}{\\alpha}$$\nThis integral converges to a finite value. Let $L = \\int_{0}^{\\infty} s(t)r(t) \\,dt$. The cross-power is then $\\lim_{T \\to \\infty} \\frac{1}{T} \\int_{0}^{T} s(t)r(t) \\,dt = \\lim_{T \\to \\infty} \\frac{L}{T} = 0$.\nThus, the total power is $P_x = P_s + P_r + 0 = P_s$.\n\nSince $P_s$ is finite and non-zero, $P_x$ is also finite and non-zero. This confirms that $x(t)$ is a power signal. Its total energy $E_x$ is infinite.\n\nTo compute the long-term average power, we calculate $P_s$. The signal $s(t)$ is defined over one period $T_0=2$ with duty factor $D=1/3$. The duration of the first part of the cycle is $D T_0 = \\frac{1}{3} \\times 2 = \\frac{2}{3}$.\nFor $t \\in [0, \\frac{2}{3})$, $q(t) = +1$, so $s(t) = C+B = 1+2=3$.\nFor $t \\in [\\frac{2}{3}, 2)$, $q(t) = -1$, so $s(t) = C-B = 1-2=-1$.\nThe power $P_s$ is the average of $s(t)^2$ over one period:\n$$P_s = \\frac{1}{T_0} \\left( \\int_{0}^{DT_0} (C+B)^2 \\,dt + \\int_{DT_0}^{T_0} (C-B)^2 \\,dt \\right)$$\n$$P_s = \\frac{1}{T_0} \\left( (C+B)^2 (DT_0) + (C-B)^2 (T_0 - DT_0) \\right)$$\n$$P_s = D(C+B)^2 + (1-D)(C-B)^2$$\nSubstituting the values $C=1$, $B=2$, and $D=1/3$:\n$$P_x = P_s = \\frac{1}{3}(1+2)^2 + \\left(1-\\frac{1}{3}\\right)(1-2)^2$$\n$$P_x = \\frac{1}{3}(3)^2 + \\frac{2}{3}(-1)^2 = \\frac{1}{3}(9) + \\frac{2}{3}(1) = 3 + \\frac{2}{3} = \\frac{11}{3}$$\nThe problem states that $x(t)$ is the voltage across a $1\\,\\Omega$ resistor. The average power delivered to the resistor is $P = \\langle \\frac{x(t)^2}{R} \\rangle = \\frac{1}{1\\,\\Omega} \\langle x(t)^2 \\rangle = P_x$. The units are watts (W).\nThe numerical value is $P_x = \\frac{11}{3} \\approx 3.6666...$ W.\nRounding to four significant figures, we get $3.667$.", "answer": "$$\\boxed{3.667}$$", "id": "2869250"}, {"introduction": "A fundamental principle in signal processing is that a signal's energy is conserved whether viewed in the time domain or the frequency domain. This practice [@problem_id:2869251] provides a rigorous, hands-on opportunity to prove and apply this concept, known as Parseval's theorem, for discrete-time signals. You will derive the total energy of a signal by connecting the continuous frequency representation (DTFT) with the limit of its discrete counterpart (DFT), deepening your intuition for the profound link between these essential transforms.", "problem": "Consider the discrete-time signal $x[n] = r^{|n|}$ with a real constant $r$ satisfying $0 < r < 1$. In this problem you will connect energy computations in the time domain with frequency-domain representations through both the Discrete-Time Fourier Transform (DTFT) and the Discrete Fourier Transform (DFT), starting only from foundational definitions and the orthogonality of complex exponentials.\n\nDefinitions to use:\n- The Discrete-Time Fourier Transform (DTFT) of $x[n]$ is $X(\\exp(j\\omega)) = \\sum_{n=-\\infty}^{\\infty} x[n] \\exp(-j\\omega n)$ for $\\omega \\in [-\\pi,\\pi]$.\n- For a positive odd integer $N = 2M+1$, define a length-$N$ windowed, time-centered sequence $y_N[n] = x[n-M]$ for $n = 0,1,\\dots,N-1$ (thus $y_N[n]$ captures $\\{x[-M],\\dots,x[M]\\}$). Its $N$-point Discrete Fourier Transform (DFT) is $Y_N[k] = \\sum_{n=0}^{N-1} y_N[n] \\exp\\!\\big(-j \\tfrac{2\\pi}{N}kn\\big)$ for $k=0,1,\\dots,N-1$.\n\nTasks:\n1. Using only the DTFT definition above and the orthogonality of complex exponentials over one period, express the total energy $E_x = \\sum_{n=-\\infty}^{\\infty} |x[n]|^2$ in terms of a frequency-domain integral involving $X(\\exp(j\\omega))$, and then evaluate that integral for the specific value $r = \\tfrac{2}{3}$ to obtain a closed-form result for $E_x$.\n2. Using only the DFT definition above and the orthogonality of the discrete complex exponentials on the finite grid, express the finite-segment energy $\\sum_{n=-M}^{M} |x[n]|^2$ in terms of a sum over $|Y_N[k]|^2$ for the same $N=2M+1$, and then take the limit as $N \\to \\infty$ (equivalently, $M \\to \\infty$) to recover $E_x$. Evaluate this limit explicitly for $r = \\tfrac{2}{3}$.\n\nYour final answer must be the exact value of $E_x$ as a single simplified real number. Do not include units. No rounding is required.", "solution": "The problem is divided into two parts, both aimed at calculating the total energy $E_x$ of the signal $x[n] = r^{|n|}$ for $0 < r < 1$. We will solve both parts and demonstrate that they yield the same result. The final numerical answer will be provided for the specific case $r = \\frac{2}{3}$.\n\n**Part 1: Energy Calculation using the Discrete-Time Fourier Transform (DTFT)**\n\nFirst, we must establish the relationship between the total energy in the time domain, $E_x = \\sum_{n=-\\infty}^{\\infty} |x[n]|^2$, and the signal's DTFT, $X(\\exp(j\\omega))$. This relationship is known as Parseval's theorem for aperiodic signals. As per the problem's constraint, we derive it from foundational principles.\n\nThe energy is $E_x = \\sum_{n=-\\infty}^{\\infty} x[n] x^*[n]$, where $x^*[n]$ is the complex conjugate of $x[n]$. The inverse DTFT allows us to express $x[n]$ in terms of its transform $X(\\exp(j\\omega))$:\n$$x[n] = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(\\exp(j\\omega)) \\exp(j\\omega n) d\\omega$$\nSubstituting this into the energy expression:\n$$E_x = \\sum_{n=-\\infty}^{\\infty} x^*[n] \\left( \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(\\exp(j\\omega')) \\exp(j\\omega' n) d\\omega' \\right)$$\nAssuming uniform convergence, which is justified for this signal as it is absolutely summable, we can interchange the summation and integration:\n$$E_x = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(\\exp(j\\omega')) \\left( \\sum_{n=-\\infty}^{\\infty} x^*[n] \\exp(j\\omega' n) \\right) d\\omega'$$\nThe summation term can be rewritten as:\n$$\\sum_{n=-\\infty}^{\\infty} \\left( x[n] \\exp(-j\\omega' n) \\right)^* = \\left( \\sum_{n=-\\infty}^{\\infty} x[n] \\exp(-j\\omega' n) \\right)^*$$\nThis is precisely the complex conjugate of the DTFT definition provided, so the term is $X^*(\\exp(j\\omega'))$. Substituting this back, we obtain Parseval's relation:\n$$E_x = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} X(\\exp(j\\omega')) X^*(\\exp(j\\omega')) d\\omega' = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |X(\\exp(j\\omega))|^2 d\\omega$$\nThis expresses the total energy in terms of a frequency-domain integral.\n\nNext, we compute the DTFT for the given signal $x[n] = r^{|n|}$:\n$$X(\\exp(j\\omega)) = \\sum_{n=-\\infty}^{\\infty} r^{|n|} \\exp(-j\\omega n)$$\nWe split the sum into two parts, for negative and non-negative $n$:\n$$X(\\exp(j\\omega)) = \\sum_{n=0}^{\\infty} r^{n} \\exp(-j\\omega n) + \\sum_{n=-\\infty}^{-1} r^{-n} \\exp(-j\\omega n)$$\nThe first sum is a geometric series $\\sum_{n=0}^{\\infty} (r \\exp(-j\\omega))^n$. Since $0 < r < 1$, the magnitude $|r \\exp(-j\\omega)| = r < 1$, so the series converges to:\n$$\\frac{1}{1 - r \\exp(-j\\omega)}$$\nFor the second sum, let $m = -n$. It becomes $\\sum_{m=1}^{\\infty} r^{m} \\exp(j\\omega m) = \\sum_{m=1}^{\\infty} (r \\exp(j\\omega))^m$. This is also a geometric series with sum:\n$$\\frac{r \\exp(j\\omega)}{1 - r \\exp(j\\omega)}$$\nCombining the two parts:\n$$X(\\exp(j\\omega)) = \\frac{1}{1 - r \\exp(-j\\omega)} + \\frac{r \\exp(j\\omega)}{1 - r \\exp(j\\omega)} = \\frac{1 - r \\exp(j\\omega) + r \\exp(j\\omega)(1 - r \\exp(-j\\omega))}{(1 - r \\exp(-j\\omega))(1 - r \\exp(j\\omega))}$$\nThe numerator simplifies to $1 - r \\exp(j\\omega) + r \\exp(j\\omega) - r^2 = 1 - r^2$. The denominator becomes $1 - r(\\exp(j\\omega) + \\exp(-j\\omega)) + r^2 = 1 - 2r\\cos(\\omega) + r^2$.\nThus, the DTFT is:\n$$X(\\exp(j\\omega)) = \\frac{1 - r^2}{1 - 2r\\cos(\\omega) + r^2}$$\nNote that for real $r$, $X(\\exp(j\\omega))$ is real-valued and positive.\n\nAccording to Parseval's theorem, the energy $E_x$ is given by the integral of $|X(\\exp(j\\omega))|^2$. However, the theorem itself guarantees that the energy calculated in the time domain must equal the result from the frequency domain. Calculating the energy directly in the time domain is algebraically simpler.\n$$E_x = \\sum_{n=-\\infty}^{\\infty} |x[n]|^2 = \\sum_{n=-\\infty}^{\\infty} |r^{|n|}|^2 = \\sum_{n=-\\infty}^{\\infty} (r^2)^{|n|}$$\nThis sum has the same form as the DTFT calculation, but with $r^2$ replacing $r$ and $\\omega=0$. Let $s = r^2$. Since $0 < r < 1$, we have $0 < s < 1$. The sum is:\n$$E_x = \\sum_{n=-\\infty}^{\\infty} s^{|n|} = \\sum_{n=0}^{\\infty} s^n + \\sum_{n=-\\infty}^{-1} s^{-n} = \\frac{1}{1-s} + \\frac{s}{1-s} = \\frac{1+s}{1-s}$$\nSubstituting back $s = r^2$, we have the closed-form expression for energy:\n$$E_x = \\frac{1+r^2}{1-r^2}$$\nFor the specific value $r = \\frac{2}{3}$:\n$$E_x = \\frac{1 + (\\frac{2}{3})^2}{1 - (\\frac{2}{3})^2} = \\frac{1 + \\frac{4}{9}}{1 - \\frac{4}{9}} = \\frac{\\frac{13}{9}}{\\frac{5}{9}} = \\frac{13}{5}$$\n\n**Part 2: Energy Calculation using the Discrete Fourier Transform (DFT)**\n\nThis part requires expressing the finite-segment energy $\\sum_{n=-M}^{M} |x[n]|^2$ using the DFT and then taking the limit as $N=2M+1 \\to \\infty$.\n\nFirst, we establish Parseval's theorem for the DFT. The problem defines a length-$N$ signal $y_N[n] = x[n-M]$ for $n=0, \\dots, N-1$. The energy of this finite signal is $E_N = \\sum_{n=0}^{N-1} |y_N[n]|^2$. The inverse DFT is $y_N[n] = \\frac{1}{N} \\sum_{k=0}^{N-1} Y_N[k] \\exp(j \\frac{2\\pi}{N}kn)$. Substituting this into the energy expression:\n$$E_N = \\sum_{n=0}^{N-1} y_N^*[n] \\left( \\frac{1}{N} \\sum_{k=0}^{N-1} Y_N[k] \\exp(j \\frac{2\\pi}{N}kn) \\right)$$\nInterchanging the sums:\n$$E_N = \\frac{1}{N} \\sum_{k=0}^{N-1} Y_N[k] \\left( \\sum_{n=0}^{N-1} y_N^*[n] \\exp(j \\frac{2\\pi}{N}kn) \\right)$$\nThe inner sum is the conjugate of the DFT definition, $(Y_N[k])^*$. Thus, we have Parseval's relation for the DFT:\n$$E_N = \\frac{1}{N} \\sum_{k=0}^{N-1} |Y_N[k]|^2$$\nThe energy of the signal segment is related to $E_N$. With $m=n-M$:\n$$\\sum_{n=-M}^{M} |x[n]|^2 = \\sum_{m=-M}^{M} |x[m]|^2 = \\sum_{n=0}^{N-1} |x[n-M]|^2 = \\sum_{n=0}^{N-1} |y_N[n]|^2 = E_N$$\nSo, we have established $\\sum_{n=-M}^{M} |x[n]|^2 = \\frac{1}{N} \\sum_{k=0}^{N-1} |Y_N[k]|^2$.\n\nThe total energy $E_x$ is the limit of the finite-segment energy as the segment size goes to infinity:\n$$E_x = \\lim_{M \\to \\infty} \\sum_{n=-M}^{M} |x[n]|^2 = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{k=0}^{N-1} |Y_N[k]|^2$$\nWe must now connect this limit to the DTFT integral from Part 1. The DFT $Y_N[k]$ is defined as:\n$$Y_N[k] = \\sum_{n=0}^{N-1} y_N[n] \\exp(-j \\tfrac{2\\pi}{N}kn) = \\sum_{n=0}^{2M} x[n-M] \\exp(-j \\tfrac{2\\pi k n}{2M+1})$$\nLet $m=n-M$, so $n=m+M$. The sum is over $m$ from $-M$ to $M$:\n$$Y_N[k] = \\sum_{m=-M}^{M} x[m] \\exp(-j \\tfrac{2\\pi k (m+M)}{N}) = \\exp(-j \\tfrac{2\\pi k M}{N}) \\sum_{m=-M}^{M} x[m] \\exp(-j \\tfrac{2\\pi k m}{N})$$\nSince $|\\exp(-j \\frac{2\\pi k M}{N})|=1$, the magnitude is:\n$$|Y_N[k]| = \\left| \\sum_{m=-M}^{M} x[m] \\exp(-j \\omega_k m) \\right|$$\nwhere $\\omega_k = \\frac{2\\pi k}{N}$ are the discrete frequency samples. The expression inside the magnitude is the DTFT of the windowed signal $x_N[m] = x[m]$ for $|m|\\le M$ and $0$ otherwise, evaluated at frequency $\\omega_k$. As $N \\to \\infty$, this windowed signal $x_N[m]$ converges to the original infinite signal $x[m]$, and its DTFT converges to $X(\\exp(j\\omega))$.\nThe limit of the sum can be interpreted as a Riemann sum. Let $\\Delta\\omega = \\frac{2\\pi}{N}$. Then $\\frac{1}{N} = \\frac{\\Delta\\omega}{2\\pi}$.\n$$E_x = \\lim_{N \\to \\infty} \\frac{1}{2\\pi} \\sum_{k=0}^{N-1} |Y_N[k]|^2 \\Delta\\omega$$\nIn the limit as $N \\to \\infty$, $\\Delta\\omega \\to 0$, the discrete frequencies $\\omega_k$ become a continuous variable $\\omega$, $|Y_N[k]|^2$ approaches $|X(\\exp(j\\omega))|^2$, and the sum converges to the definite integral over one period $[0, 2\\pi]$:\n$$E_x = \\frac{1}{2\\pi} \\int_{0}^{2\\pi} |X(\\exp(j\\omega))|^2 d\\omega$$\nSince the integrand is periodic with period $2\\pi$, this is equivalent to integrating over $[-\\pi, \\pi]$, which is precisely the expression for energy we derived in Part 1.\n$$E_x = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |X(\\exp(j\\omega))|^2 d\\omega$$\nTherefore, the limit must evaluate to the same value calculated previously. The task of evaluating the limit explicitly is fulfilled by showing this convergence to the integral that was already effectively evaluated. For $r = \\frac{2}{3}$, the result is:\n$$E_x = \\frac{13}{5}$$\n\nBoth methods, one based on the DTFT for infinite-duration signals and the other based on the limit of the DFT for finite-duration segments, correctly and consistently yield the same result for the total energy. This demonstrates the fundamental consistency between the Fourier representations for periodic and aperiodic signals.", "answer": "$$\\boxed{\\frac{13}{5}}$$", "id": "2869251"}, {"introduction": "While deterministic signals provide a clean theoretical foundation, most signals encountered in practice are inherently random. This exercise guides you through the essential generalization of power characterization from deterministic signals to wide-sense stationary (WSS) random processes. By deriving the Power Spectral Density (PSD) from a given autocorrelation function [@problem_id:2869243], you will directly apply the Wiener-Khinchin theorem, a cornerstone concept that reveals how a process's power is distributed across different frequencies.", "problem": "Consider a real-valued, wide-sense stationary continuous-time random process $x(t)$ with mean $0$ and autocorrelation function\n$$\nR_{x}(\\tau) \\;=\\; \\sigma^{2}\\,\\exp\\!\\big(-\\alpha\\,|\\tau|\\big)\\,\\cos\\!\\big(\\omega_{0}\\,\\tau\\big),\n$$\nwhere $\\sigma^{2} \\gt 0$, $\\alpha \\gt 0$, and $\\omega_{0} \\ge 0$ are constants. Using only foundational definitions from signal processing and systems modeling, derive the Power Spectral Density (PSD) $S_{x}(\\omega)$ of this process in the angular-frequency domain. In your derivation, start from the definitions of autocorrelation and Fourier transform appropriate for wide-sense stationary processes, and make your transform convention explicit. Express your final result as a single closed-form analytic expression in terms of $\\sigma^{2}$, $\\alpha$, $\\omega_{0}$, and $\\omega$. No numerical approximation or rounding is required.", "solution": "The Power Spectral Density (PSD) $S_{x}(\\omega)$ of a wide-sense stationary process $x(t)$ is defined by the Wiener-Khinchin theorem as the Fourier transform of the autocorrelation function $R_{x}(\\tau)$. We shall employ the following definition of the continuous-time Fourier transform $\\mathcal{F}$ for a function $g(\\tau)$:\n$$\n\\mathcal{F}\\{g(\\tau)\\} = G(\\omega) = \\int_{-\\infty}^{\\infty} g(\\tau) \\exp(-i\\omega\\tau) \\,d\\tau\n$$\nwhere $i$ is the imaginary unit.\n\nThe given autocorrelation function is\n$$\nR_{x}(\\tau) = \\sigma^{2}\\,\\exp(-\\alpha\\,|\\tau|)\\,\\cos(\\omega_{0}\\,\\tau)\n$$\nTo find the PSD $S_{x}(\\omega)$, we must compute the Fourier transform of $R_{x}(\\tau)$:\n$$\nS_{x}(\\omega) = \\mathcal{F}\\{R_{x}(\\tau)\\} = \\int_{-\\infty}^{\\infty} \\sigma^{2}\\,\\exp(-\\alpha\\,|\\tau|)\\,\\cos(\\omega_{0}\\,\\tau) \\exp(-i\\omega\\tau) \\,d\\tau\n$$\nWe begin by applying Euler's formula to the cosine term, $\\cos(\\omega_{0}\\,\\tau) = \\frac{1}{2}(\\exp(i\\omega_{0}\\tau) + \\exp(-i\\omega_{0}\\tau))$. Substituting this into the integral gives:\n$$\nS_{x}(\\omega) = \\sigma^{2} \\int_{-\\infty}^{\\infty} \\exp(-\\alpha\\,|\\tau|) \\left( \\frac{\\exp(i\\omega_{0}\\tau) + \\exp(-i\\omega_{0}\\tau)}{2} \\right) \\exp(-i\\omega\\tau) \\,d\\tau\n$$\nBy the linearity of the Fourier transform, we can separate the terms:\n$$\nS_{x}(\\omega) = \\frac{\\sigma^{2}}{2} \\left[ \\int_{-\\infty}^{\\infty} \\exp(-\\alpha\\,|\\tau|) \\exp(-i(\\omega - \\omega_{0})\\tau) \\,d\\tau + \\int_{-\\infty}^{\\infty} \\exp(-\\alpha\\,|\\tau|) \\exp(-i(\\omega + \\omega_{0})\\tau) \\,d\\tau \\right]\n$$\nThese two integrals represent the Fourier transform of the function $g(\\tau) = \\exp(-\\alpha\\,|\\tau|)$ evaluated at frequencies $(\\omega - \\omega_{0})$ and $(\\omega + \\omega_{0})$, respectively. This is an application of the frequency-shifting property of the Fourier transform, which states that $\\mathcal{F}\\{g(\\tau)\\exp(i\\omega_{c}\\tau)\\} = G(\\omega - \\omega_{c})$.\n\nLet us first compute the Fourier transform of $g(\\tau) = \\exp(-\\alpha\\,|\\tau|)$, denoted as $G(\\omega)$:\n$$\nG(\\omega) = \\int_{-\\infty}^{\\infty} \\exp(-\\alpha\\,|\\tau|) \\exp(-i\\omega\\tau) \\,d\\tau\n$$\nWe must split the integral at $\\tau=0$ to handle the absolute value function $|\\tau|$:\n$$\nG(\\omega) = \\int_{-\\infty}^{0} \\exp(\\alpha\\tau) \\exp(-i\\omega\\tau) \\,d\\tau + \\int_{0}^{\\infty} \\exp(-\\alpha\\tau) \\exp(-i\\omega\\tau) \\,d\\tau\n$$\n$$\nG(\\omega) = \\int_{-\\infty}^{0} \\exp((\\alpha - i\\omega)\\tau) \\,d\\tau + \\int_{0}^{\\infty} \\exp(-(\\alpha + i\\omega)\\tau) \\,d\\tau\n$$\nThese integrals are evaluated as follows. Since $\\alpha > 0$, the real parts of the exponents ensure convergence.\n$$\n\\int_{-\\infty}^{0} \\exp((\\alpha - i\\omega)\\tau) \\,d\\tau = \\left[ \\frac{\\exp((\\alpha - i\\omega)\\tau)}{\\alpha - i\\omega} \\right]_{-\\infty}^{0} = \\frac{\\exp(0)}{\\alpha - i\\omega} - 0 = \\frac{1}{\\alpha - i\\omega}\n$$\n$$\n\\int_{0}^{\\infty} \\exp(-(\\alpha + i\\omega)\\tau) \\,d\\tau = \\left[ \\frac{\\exp(-(\\alpha + i\\omega)\\tau)}{-(\\alpha + i\\omega)} \\right]_{0}^{\\infty} = 0 - \\frac{\\exp(0)}{-(\\alpha + i\\omega)} = \\frac{1}{\\alpha + i\\omega}\n$$\nCombining these results gives the transform $G(\\omega)$:\n$$\nG(\\omega) = \\frac{1}{\\alpha - i\\omega} + \\frac{1}{\\alpha + i\\omega} = \\frac{(\\alpha + i\\omega) + (\\alpha - i\\omega)}{(\\alpha - i\\omega)(\\alpha + i\\omega)} = \\frac{2\\alpha}{\\alpha^{2} - (i\\omega)^{2}} = \\frac{2\\alpha}{\\alpha^{2} + \\omega^{2}}\n$$\nThis is a standard Fourier transform pair. Now we can substitute this result back into our expression for $S_{x}(\\omega)$:\n$$\nS_{x}(\\omega) = \\frac{\\sigma^{2}}{2} \\left[ G(\\omega - \\omega_{0}) + G(\\omega + \\omega_{0}) \\right]\n$$\n$$\nS_{x}(\\omega) = \\frac{\\sigma^{2}}{2} \\left[ \\frac{2\\alpha}{\\alpha^{2} + (\\omega - \\omega_{0})^{2}} + \\frac{2\\alpha}{\\alpha^{2} + (\\omega + \\omega_{0})^{2}} \\right]\n$$\nCanceling the factor of $2$, we arrive at the final expression for the Power Spectral Density:\n$$\nS_{x}(\\omega) = \\sigma^{2} \\alpha \\left( \\frac{1}{\\alpha^{2} + (\\omega - \\omega_{0})^{2}} + \\frac{1}{\\alpha^{2} + (\\omega + \\omega_{0})^{2}} \\right)\n$$\nThis expression represents the sum of two Lorentzian functions centered at frequencies $\\omega = \\omega_{0}$ and $\\omega = -\\omega_{0}$. Since $\\sigma^{2} > 0$ and $\\alpha > 0$, and the denominators are always positive, the PSD $S_x(\\omega)$ is strictly positive for all $\\omega$, as required for a non-trivial random process.", "answer": "$$\n\\boxed{\\sigma^{2} \\alpha \\left( \\frac{1}{\\alpha^{2} + (\\omega - \\omega_{0})^{2}} + \\frac{1}{\\alpha^{2} + (\\omega + \\omega_{0})^{2}} \\right)}\n$$", "id": "2869243"}]}