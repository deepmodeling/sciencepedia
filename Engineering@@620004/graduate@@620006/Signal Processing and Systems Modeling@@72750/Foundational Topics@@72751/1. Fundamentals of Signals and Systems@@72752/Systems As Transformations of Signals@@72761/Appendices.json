{"hands_on_practices": [{"introduction": "A cornerstone of systems theory is analyzing the response of a Linear Time-Invariant (LTI) system to a given input. This exercise provides an opportunity to connect the powerful frequency-domain perspective with direct time-domain computation. By first deriving the system's impulse response $h(t)$ from its transfer function $H(s)$ and then calculating the output using the convolution integral, you will reinforce your understanding of how a system transforms a signal [@problem_id:2910739]. This practice emphasizes the importance of rigorous justification, particularly concerning the Region of Convergence (ROC), which links the mathematical formalism of the Laplace transform to the physical property of causality.", "problem": "Consider a causal Linear Time-Invariant (LTI) continuous-time system with zero initial conditions, whose transfer function in the Laplace domain is\n$$\nH(s) \\;=\\; \\frac{s + 2}{(s + 1)\\,(s + 3)^{2}} \\, .\n$$\nThe input is\n$$\nx(t) \\;=\\; \\exp(a t)\\,u(t) \\, ,\n$$\nwhere $a \\in \\mathbb{R}$ and $a \\neq -1$, $a \\neq -3$, and $u(t)$ is the unit step. Work in the unilateral Laplace transform domain, starting from the core definitions of the Laplace transform and convolution for right-sided signals. Treat the system as a transformation of signals: $y(t) = (h * x)(t)$, where $h(t)$ is the impulse response of the system. \n\nYour tasks:\n- Determine the impulse response $h(t)$ by performing a partial fraction expansion of $H(s)$ and inverting each term. For each inversion step, justify the corresponding Region of Convergence (ROC) based on causality.\n- Using $h(t)$ and the convolution integral with $x(t)$, derive a closed-form expression for the output $y(t)$ in the time domain. At every step where an inverse Laplace transform is invoked (explicitly or implicitly via convolution), justify the ROC choice.\n\nExpress your final answer as a single closed-form analytic expression $y(t)$ in terms of $a$ and $t$ (include $u(t)$ explicitly). No numerical evaluation is required. If any intermediate integrals are needed, evaluate them symbolically. Do not assume any special values of $a$ beyond the exclusions stated above.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens\n- System Type: Causal Linear Time-Invariant (LTI) continuous-time system.\n- Initial Conditions: Zero.\n- Transfer Function: $H(s) = \\frac{s + 2}{(s + 1)(s + 3)^{2}}$.\n- Input Signal: $x(t) = \\exp(at) u(t)$, where $u(t)$ is the unit step function.\n- Constraints: $a \\in \\mathbb{R}$, $a \\neq -1$, $a \\neq -3$.\n- Analysis Method: Unilateral Laplace transform, convolution integral $y(t) = (h * x)(t)$.\n- Task 1: Determine the impulse response $h(t)$ via partial fraction expansion and inverse Laplace transform, justifying the Region of Convergence (ROC) based on causality.\n- Task 2: Determine the output $y(t)$ via the convolution integral of $h(t)$ and $x(t)$, justifying any ROC choices.\n\nStep 2: Validate Using Extracted Givens\n- The problem is **scientifically grounded**. It is a standard problem in the analysis of LTI systems, a core topic in signal processing and control theory, relying on fundamental principles of the Laplace transform and convolution.\n- The problem is **well-posed**. The system and input are clearly defined. The constraints on the parameter $a$ prevent indeterminate forms and ensure that the poles of the input do not coincide with the poles of the system, guaranteeing a unique solution structure.\n- The problem is **objective** and uses precise mathematical language.\n- The problem is **self-contained and consistent**. All necessary information, including the transfer function, input signal, and system properties (causality, LTI), is provided. There are no contradictions.\n\nStep 3: Verdict and Action\n- The problem is deemed **valid**. A solution will be derived.\n\nThe solution proceeds in two parts as required.\n\nPart 1: Determination of the Impulse Response $h(t)$\n\nThe impulse response $h(t)$ is the inverse Laplace transform of the transfer function $H(s)$.\n$$\nh(t) = \\mathcal{L}^{-1}\\{H(s)\\} = \\mathcal{L}^{-1}\\left\\{\\frac{s + 2}{(s + 1)(s + 3)^{2}}\\right\\}\n$$\nThe system is specified as causal. For a rational transfer function, causality implies that the Region of Convergence (ROC) is the right half-plane to the right of the rightmost pole. The poles of $H(s)$ are at $s = -1$ and $s = -3$. The rightmost pole is at $s = -1$. Therefore, the ROC for $H(s)$ is $\\text{Re}(s) > -1$.\n\nTo find $h(t)$, we perform a partial fraction expansion of $H(s)$.\n$$\nH(s) = \\frac{A}{s + 1} + \\frac{B}{s + 3} + \\frac{C}{(s + 3)^{2}}\n$$\nThe coefficients are determined as follows:\nThe coefficient $A$ is the residue of $H(s)$ at the simple pole $s = -1$.\n$$\nA = \\left[(s + 1)H(s)\\right]_{s=-1} = \\left[\\frac{s + 2}{(s + 3)^{2}}\\right]_{s=-1} = \\frac{-1 + 2}{(-1 + 3)^{2}} = \\frac{1}{2^{2}} = \\frac{1}{4}\n$$\nThe coefficient $C$ is found by evaluating $(s+3)^2 H(s)$ at the double pole $s = -3$.\n$$\nC = \\left[(s + 3)^{2}H(s)\\right]_{s=-3} = \\left[\\frac{s + 2}{s + 1}\\right]_{s=-3} = \\frac{-3 + 2}{-3 + 1} = \\frac{-1}{-2} = \\frac{1}{2}\n$$\nThe coefficient $B$ is found from the derivative of $(s+3)^2 H(s)$ at $s = -3$.\n$$\nB = \\frac{d}{ds}\\left[(s + 3)^{2}H(s)\\right]_{s=-3} = \\frac{d}{ds}\\left[\\frac{s + 2}{s + 1}\\right]_{s=-3}\n$$\nUsing the quotient rule for differentiation:\n$$\n\\frac{d}{ds}\\left(\\frac{s + 2}{s + 1}\\right) = \\frac{(1)(s + 1) - (s + 2)(1)}{(s + 1)^{2}} = \\frac{-1}{(s + 1)^{2}}\n$$\nEvaluating at $s = -3$:\n$$\nB = \\frac{-1}{(-3 + 1)^{2}} = \\frac{-1}{(-2)^{2}} = -\\frac{1}{4}\n$$\nThus, the partial fraction expansion of $H(s)$ is:\n$$\nH(s) = \\frac{1/4}{s + 1} - \\frac{1/4}{s + 3} + \\frac{1/2}{(s + 3)^{2}}\n$$\nWe now take the inverse Laplace transform of each term. The overall ROC, $\\text{Re}(s) > -1$, dictates that each individual inverse transform must correspond to a causal (right-sided) time-domain signal.\n- For the term $\\frac{1}{s + 1}$, the pole is at $s=-1$. The causal inverse transform is $\\exp(-t)u(t)$, which has an ROC of $\\text{Re}(s) > -1$. This is consistent.\n- For the term $\\frac{1}{s + 3}$, the pole is at $s=-3$. The causal inverse transform is $\\exp(-3t)u(t)$, which has an ROC of $\\text{Re}(s) > -3$. This is consistent with the overall ROC $\\text{Re}(s) > -1$.\n- For the term $\\frac{1}{(s + 3)^{2}}$, this corresponds to the transform pair $\\mathcal{L}\\{t \\exp(-\\alpha t)u(t)\\} = \\frac{1}{(s+\\alpha)^2}$. The pole is at $s=-3$. The causal inverse transform is $t \\exp(-3t)u(t)$, which has an ROC of $\\text{Re}(s) > -3$, also consistent.\n\nCombining the inverse transforms gives the impulse response $h(t)$:\n$$\nh(t) = \\left(\\frac{1}{4}\\exp(-t) - \\frac{1}{4}\\exp(-3t) + \\frac{1}{2}t\\exp(-3t)\\right)u(t)\n$$\n\nPart 2: Determination of the Output $y(t)$ via Convolution\n\nThe output $y(t)$ is the convolution of the impulse response $h(t)$ and the input $x(t)$:\n$$\ny(t) = (h * x)(t) = \\int_{-\\infty}^{\\infty} h(\\tau)x(t - \\tau) d\\tau\n$$\nSince both $h(t)$ and $x(t)$ are causal (i.e., zero for $t  0$), the integrand $h(\\tau)x(t - \\tau)$ is non-zero only for $0 \\le \\tau \\le t$. Thus, for $t \\ge 0$, the convolution integral is:\n$$\ny(t) = \\int_{0}^{t} h(\\tau)x(t - \\tau) d\\tau\n$$\nSubstituting the expressions for $h(\\tau)$ and $x(t-\\tau)$:\n$$\nh(\\tau) = \\frac{1}{4}\\exp(-\\tau) - \\frac{1}{4}\\exp(-3\\tau) + \\frac{1}{2}\\tau\\exp(-3\\tau)\n$$\n$$\nx(t - \\tau) = \\exp(a(t - \\tau)) = \\exp(at)\\exp(-a\\tau)\n$$\nThe integral becomes:\n$$\ny(t) = \\int_{0}^{t} \\left(\\frac{1}{4}\\exp(-\\tau) - \\frac{1}{4}\\exp(-3\\tau) + \\frac{1}{2}\\tau\\exp(-3\\tau)\\right) \\exp(at)\\exp(-a\\tau) d\\tau\n$$\nWe can factor out $\\exp(at)$ from the integral:\n$$\ny(t) = \\exp(at) \\int_{0}^{t} \\left(\\frac{1}{4}\\exp(-(a+1)\\tau) - \\frac{1}{4}\\exp(-(a+3)\\tau) + \\frac{1}{2}\\tau\\exp(-(a+3)\\tau)\\right) d\\tau\n$$\nLet's evaluate the integral term by term. The constraints $a \\neq -1$ and $a \\neq -3$ ensure the denominators are non-zero.\n1. First term:\n$$\n\\int_{0}^{t} \\frac{1}{4}\\exp(-(a+1)\\tau) d\\tau = \\frac{1}{4}\\left[\\frac{\\exp(-(a+1)\\tau)}{-(a+1)}\\right]_{0}^{t} = \\frac{1}{4(a+1)}\\left(1 - \\exp(-(a+1)t)\\right)\n$$\n2. Second term:\n$$\n\\int_{0}^{t} -\\frac{1}{4}\\exp(-(a+3)\\tau) d\\tau = -\\frac{1}{4}\\left[\\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} = -\\frac{1}{4(a+3)}\\left(1 - \\exp(-(a+3)t)\\right)\n$$\n3. Third term (using integration by parts, $\\int u dv = uv - \\int v du$): let $u = \\frac{1}{2}\\tau$ and $dv = \\exp(-(a+3)\\tau)d\\tau$. Then $du = \\frac{1}{2}d\\tau$ and $v = \\frac{\\exp(-(a+3)\\tau)}{-(a+3)}$.\n\\begin{align*}\n\\int_{0}^{t} \\frac{1}{2}\\tau\\exp(-(a+3)\\tau) d\\tau = \\left[\\frac{1}{2}\\tau \\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} - \\int_{0}^{t} \\frac{1}{-(a+3)}\\exp(-(a+3)\\tau) \\frac{1}{2} d\\tau \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} + \\frac{1}{2(a+3)} \\int_{0}^{t} \\exp(-(a+3)\\tau) d\\tau \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} + \\frac{1}{2(a+3)} \\left[\\frac{\\exp(-(a+3)\\tau)}{-(a+3)}\\right]_{0}^{t} \\\\\n= -\\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{1}{2(a+3)^{2}}\\left(\\exp(-(a+3)t) - 1\\right) \\\\\n= \\frac{1}{2(a+3)^{2}} - \\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{\\exp(-(a+3)t)}{2(a+3)^{2}}\n\\end{align*}\nCombining all three results inside the integral:\n$$\n\\frac{1-\\exp(-(a+1)t)}{4(a+1)} - \\frac{1-\\exp(-(a+3)t)}{4(a+3)} + \\frac{1}{2(a+3)^{2}} - \\frac{t\\exp(-(a+3)t)}{2(a+3)} - \\frac{\\exp(-(a+3)t)}{2(a+3)^{2}}\n$$\nNow, multiply by $\\exp(at)$ to obtain $y(t)$:\n\\begin{align*}\ny(t) = \\exp(at)\\left( \\frac{1}{4(a+1)} - \\frac{1}{4(a+3)} + \\frac{1}{2(a+3)^{2}} \\right) \\\\\n\\quad - \\frac{\\exp(at)\\exp(-(a+1)t)}{4(a+1)} \\\\\n\\quad + \\frac{\\exp(at)\\exp(-(a+3)t)}{4(a+3)} - \\frac{\\exp(at)\\exp(-(a+3)t)}{2(a+3)^{2}} \\\\\n\\quad - \\frac{t\\exp(at)\\exp(-(a+3)t)}{2(a+3)}\n\\end{align*}\nSimplifying each group of terms:\n- The coefficient of $\\exp(at)$ is $\\frac{1}{4(a+1)} - \\frac{1}{4(a+3)} + \\frac{1}{2(a+3)^{2}} = \\frac{(a+3)^2 - (a+1)(a+3) + 2(a+1)}{4(a+1)(a+3)^2} = \\frac{(a^2+6a+9) - (a^2+4a+3) + (2a+2)}{4(a+1)(a+3)^2} = \\frac{4a+8}{4(a+1)(a+3)^2} = \\frac{a+2}{(a+1)(a+3)^2}$.\n- The term with $\\exp(-t)$ is $-\\frac{\\exp(-t)}{4(a+1)}$.\n- The terms with $\\exp(-3t)$ and $t\\exp(-3t)$ are:\n  $$ \\left(\\frac{1}{4(a+3)} - \\frac{1}{2(a+3)^2}\\right)\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) $$\n  $$ = \\left(\\frac{a+3-2}{4(a+3)^2}\\right)\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) = \\frac{a+1}{4(a+3)^2}\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) $$\nAssembling the final expression for $y(t)$ and including the unit step $u(t)$ to indicate causality:\n$$\ny(t) = \\left( \\frac{a+2}{(a+1)(a+3)^{2}}\\exp(at) - \\frac{1}{4(a+1)}\\exp(-t) + \\frac{a+1}{4(a+3)^{2}}\\exp(-3t) - \\frac{t}{2(a+3)}\\exp(-3t) \\right) u(t)\n$$\nThe convolution of two causal signals results in a causal signal, $y(t)$. The Laplace transform $Y(s)$ has poles at $s=a$, $s=-1$, and $s=-3$. The causality of $y(t)$ implies its ROC is the right half-plane to the right of its rightmost pole, which is $\\text{Re}(s) > \\max\\{a, -1\\}$. This is consistent with the operation $Y(s) = H(s)X(s)$, where the ROC of $Y(s)$ is the intersection of the ROCs of $H(s)$ ($\\text{Re}(s)-1$) and $X(s)$ ($\\text{Re}(s)a$).", "answer": "$$\n\\boxed{\\left( \\frac{a+2}{(a+1)(a+3)^{2}} \\exp(at) - \\frac{1}{4(a+1)} \\exp(-t) + \\frac{a+1}{4(a+3)^{2}} \\exp(-3t) - \\frac{t}{2(a+3)} \\exp(-3t) \\right) u(t)}\n$$", "id": "2910739"}, {"introduction": "To deepen our understanding of systems as transformations, we must extend our toolkit beyond ordinary functions to include generalized functions, or distributions. This practice explores a system whose behavior is described by a purely theoretical but conceptually powerful impulse response: the second derivative of the Dirac delta distribution, $h(t) = \\delta''(t)$. Working through this problem will require you to use the formal rules of distributional derivatives and convolution to determine the output, revealing how these mathematical tools provide a rigorous way to analyze ideal systems like perfect differentiators [@problem_id:2910770].", "problem": "Consider a continuous-time linear time-invariant system whose impulse response is the second distributional derivative of the Dirac delta, namely $h(t)=\\delta''(t)$. The input is the causal exponential $x(t)=\\exp(-t)\\,u(t)$, where $u(t)$ is the Heaviside unit step. Using only the definition of convolution for linear time-invariant systems, the definition of the distributional derivative, and standard properties of tempered distributions, determine the output $y(t)=(h*x)(t)$ in the sense of distributions. Express your final result as a closed-form analytic expression in terms of $\\exp(-t)u(t)$, $\\delta(t)$, and $\\delta'(t)$, separating the regular component for $t0$ and the singular components supported at $t=0$. No numerical approximation is required, and no physical units are involved. Provide the final answer as a single expression.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- System Type: Continuous-time linear time-invariant (LTI) system.\n- Impulse Response: $h(t) = \\delta''(t)$, where $\\delta(t)$ is the Dirac delta distribution and $\\delta''(t)$ is its second distributional derivative.\n- Input Signal: $x(t) = \\exp(-t)u(t)$, where $u(t)$ is the Heaviside unit step function.\n- Task: Determine the output $y(t) = (h * x)(t)$.\n- Methodology: Use the definition of convolution for LTI systems, the definition of the distributional derivative, and properties of tempered distributions.\n- Required Output Format: A closed-form analytic expression for $y(t)$ in terms of $\\exp(-t)u(t)$, $\\delta(t)$, and $\\delta'(t)$, separating the regular and singular components.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientific Grounding**: The problem is formulated within the standard mathematical framework of signal processing and distribution theory. The Dirac delta distribution and its derivatives, along with their convolution properties, are fundamental concepts in this field. The system with impulse response $h(t) = \\delta''(t)$ corresponds to an ideal second-order differentiator, which is a standard theoretical construct. The problem is scientifically sound.\n- **Well-Posedness**: The convolution of a tempered distribution (such as $\\delta''(t)$) with a function of slow growth (such as $x(t) = \\exp(-t)u(t)$) is a well-defined operation in the theory of distributions. The problem is specified with sufficient information to yield a unique solution in the space of distributions.\n- **Objectivity**: The problem is stated using precise mathematical language, free of ambiguity or subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem is valid. It is scientifically grounded, well-posed, objective, and contains sufficient information for a unique solution. I will proceed with the derivation.\n\nThe output $y(t)$ of a linear time-invariant system is given by the convolution of the input signal $x(t)$ with the system's impulse response $h(t)$.\n$$y(t) = (x * h)(t) = (h * x)(t)$$\nGiven $h(t) = \\delta''(t)$ and $x(t) = \\exp(-t)u(t)$, the output is:\n$$y(t) = (\\delta'' * x)(t)$$\nA fundamental property of convolution involving the Dirac delta distribution and its derivatives states that for a sufficiently well-behaved function $f(t)$, the convolution with the $n$-th derivative of the delta distribution yields the $n$-th derivative of the function:\n$$(\\delta^{(n)} * f)(t) = f^{(n)}(t)$$\nThe differentiation on the right-hand side must be interpreted in the sense of distributions. In this problem, $n=2$ and $f(t) = x(t)$. Therefore, the output $y(t)$ is the second distributional derivative of the input $x(t)$.\n$$y(t) = x''(t) = \\frac{d^2}{dt^2} \\left[ \\exp(-t)u(t) \\right]$$\nWe must proceed by calculating the derivatives step-by-step. First, we compute the first distributional derivative, $x'(t)$. The function $x(t) = \\exp(-t)u(t)$ is discontinuous at $t=0$. For a function $f(t)$ that is differentiable everywhere except for a finite jump discontinuity at $t=c$, its distributional derivative is given by:\n$$f'(t) = \\{f'(t)\\} + [f(c^+) - f(c^-)]\\delta(t-c)$$\nwhere $\\{f'(t)\\}$ is the classical derivative, which exists for $t \\neq c$. For our input $x(t)$, the discontinuity is at $t=0$. The classical derivative for $t \\neq 0$ is:\n$$\\{x'(t)\\} = \\frac{d}{dt}(\\exp(-t))u(t) = -\\exp(-t)u(t)$$\nThe jump at $t=0$ is:\n$$x(0^+) - x(0^-) = \\lim_{\\epsilon \\to 0^+} \\exp(-\\epsilon) - \\lim_{\\epsilon \\to 0^-} 0 = 1 - 0 = 1$$\nTherefore, the first distributional derivative is:\n$$x'(t) = -\\exp(-t)u(t) + \\delta(t)$$\nNext, we compute the second derivative, $y(t) = x''(t)$, by differentiating $x'(t)$ in the distributional sense. Using the linearity of the differentiation operator:\n$$y(t) = x''(t) = \\frac{d}{dt} \\left( -\\exp(-t)u(t) + \\delta(t) \\right) = \\frac{d}{dt}\\left( -\\exp(-t)u(t) \\right) + \\frac{d}{dt}\\left( \\delta(t) \\right)$$\nThe second term is, by definition, the derivative of the Dirac delta distribution, $\\delta'(t)$.\nFor the first term, we apply the same rule for distributional differentiation to the function $g(t) = -\\exp(-t)u(t)$. The classical derivative of $g(t)$ for $t \\neq 0$ is:\n$$\\{g'(t)\\} = \\frac{d}{dt}(-\\exp(-t))u(t) = \\exp(-t)u(t)$$\nThe jump of $g(t)$ at $t=0$ is:\n$$g(0^+) - g(0^-) = \\lim_{\\epsilon \\to 0^+} (-\\exp(-\\epsilon)) - 0 = -1$$\nThus, the derivative of the first term is:\n$$\\frac{d}{dt}\\left( -\\exp(-t)u(t) \\right) = \\exp(-t)u(t) - 1 \\cdot \\delta(t) = \\exp(-t)u(t) - \\delta(t)$$\nCombining the results, the second distributional derivative of $x(t)$ is:\n$$y(t) = x''(t) = \\left( \\exp(-t)u(t) - \\delta(t) \\right) + \\delta'(t)$$\nThis gives the final expression for the output signal $y(t)$.\n$$y(t) = \\exp(-t)u(t) - \\delta(t) + \\delta'(t)$$\nThis result correctly separates the regular component for $t0$, which is $\\exp(-t)$ (represented by $\\exp(-t)u(t)$), and the singular components supported at the origin, which are $-\\delta(t)$ and $\\delta'(t)$. The expression is in the required form.", "answer": "$$\n\\boxed{\\exp(-t)u(t)-\\delta(t)+\\delta'(t)}\n$$", "id": "2910770"}, {"introduction": "While much of introductory systems analysis focuses on LTI systems, the broader field is populated by a vast array of linear operators that may not be time-invariant. This exercise challenges you to step into the more abstract realm of functional analysis to rigorously test a time-warping operator, $(Tx)(t) = x(t^{2})$, for its most basic properties. By determining from first principles whether this transformation consistently maps finite-energy signals to finite-energy signals, you will gain hands-on experience in verifying if an operator is well-defined and bounded on the Hilbert space $L^{2}(\\mathbb{R})$—a crucial skill for advanced system design and theory [@problem_id:2910789].", "problem": "A time-warping system is defined on energy signals by the transformation $(T x)(t) = x(t^{2})$, where $x \\in L^{2}(\\mathbb{R})$ and $L^{2}(\\mathbb{R})$ denotes the space of (equivalence classes of) measurable functions whose squared magnitude is Lebesgue integrable over $\\mathbb{R}$. Using only the definitions of $L^{2}(\\mathbb{R})$, the $L^{2}$ norm, and the change-of-variables theorem for Lebesgue integrals, analyze whether $T$ is a well-defined and bounded linear operator from $L^{2}(\\mathbb{R})$ to $L^{2}(\\mathbb{R})$. Your analysis must explicitly derive the expression for $\\|T x\\|_{2}^{2}$ in terms of $\\|x\\|_{2}^{2}$ via an appropriate change of variables.\n\nTo ground your reasoning, consider the test family $x_{\\alpha}(t) = t^{-\\alpha}\\,\\mathbf{1}_{(0,1)}(t)$, where $\\alpha \\in \\mathbb{R}$ and $\\mathbf{1}_{(0,1)}$ is the indicator function of the interval $(0,1)$. Determine for which values of $\\alpha$ the signal $x_{\\alpha}$ lies in $L^{2}(\\mathbb{R})$, and for which values of $\\alpha$ the transformed signal $T x_{\\alpha}$ lies in $L^{2}(\\mathbb{R})$.\n\nState, as your final answer, the largest real $\\alpha$ such that $T x_{\\alpha} \\in L^{2}(\\mathbb{R})$. The final answer must be a single number. No rounding is required.", "solution": "The problem requires an analysis of the operator $T$ defined by $(T x)(t) = x(t^{2})$ for signals $x \\in L^{2}(\\mathbb{R})$. We must determine if $T$ is a well-defined and bounded linear operator from $L^{2}(\\mathbb{R})$ to $L^{2}(\\mathbb{R})$. The analysis will be grounded by a specific family of test signals, $x_{\\alpha}(t) = t^{-\\alpha}\\,\\mathbf{1}_{(0,1)}(t)$.\n\nFirst, we examine the linearity of the operator $T$. Let $x_{1}, x_{2} \\in L^{2}(\\mathbb{R})$ and let $c_{1}, c_{2} \\in \\mathbb{C}$ be arbitrary constants. By definition of the operator $T$:\n$$\n(T(c_{1}x_{1} + c_{2}x_{2}))(t) = (c_{1}x_{1} + c_{2}x_{2})(t^{2})\n$$\nUsing the definition of linear combination of functions:\n$$\n(c_{1}x_{1} + c_{2}x_{2})(t^{2}) = c_{1}x_{1}(t^{2}) + c_{2}x_{2}(t^{2})\n$$\nBy applying the definition of $T$ to $x_{1}$ and $x_{2}$ individually, we have:\n$$\nc_{1}x_{1}(t^{2}) + c_{2}x_{2}(t^{2}) = c_{1}(Tx_{1})(t) + c_{2}(Tx_{2})(t) = (c_{1}Tx_{1} + c_{2}Tx_{2})(t)\n$$\nSince this holds for all $t \\in \\mathbb{R}$, we conclude that $T(c_{1}x_{1} + c_{2}x_{2}) = c_{1}Tx_{1} + c_{2}Tx_{2}$. The operator $T$ is therefore linear.\n\nNext, we investigate if $T$ is a well-defined operator from $L^{2}(\\mathbb{R})$ to $L^{2}(\\mathbb{R})$. This requires that for any $x \\in L^{2}(\\mathbb{R})$, the transformed function $Tx$ must also be in $L^{2}(\\mathbb{R})$. We analyze the squared $L^{2}$-norm of $Tx$:\n$$\n\\|Tx\\|_{2}^{2} = \\int_{-\\infty}^{\\infty} |(Tx)(t)|^{2} dt = \\int_{-\\infty}^{\\infty} |x(t^{2})|^{2} dt\n$$\nThe domain of integration can be split at $t=0$:\n$$\n\\|Tx\\|_{2}^{2} = \\int_{-\\infty}^{0} |x(t^{2})|^{2} dt + \\int_{0}^{\\infty} |x(t^{2})|^{2} dt\n$$\nWe apply the change of variables $u = t^{2}$ to each integral.\nFor the integral over $(0, \\infty)$, we have $t = \\sqrt{u}$ and $dt = \\frac{1}{2\\sqrt{u}} du$. The integration limits remain $(0, \\infty)$.\n$$\n\\int_{0}^{\\infty} |x(t^{2})|^{2} dt = \\int_{0}^{\\infty} |x(u)|^{2} \\frac{1}{2\\sqrt{u}} du\n$$\nFor the integral over $(-\\infty, 0)$, we have $t = -\\sqrt{u}$ and $dt = -\\frac{1}{2\\sqrt{u}} du$. The integration limits for $t$ from $-\\infty$ to $0$ correspond to limits for $u$ from $\\infty$ to $0$.\n$$\n\\int_{-\\infty}^{0} |x(t^{2})|^{2} dt = \\int_{\\infty}^{0} |x(u)|^{2} \\left(-\\frac{1}{2\\sqrt{u}}\\right) du = \\int_{0}^{\\infty} |x(u)|^{2} \\frac{1}{2\\sqrt{u}} du\n$$\nCombining these results, we obtain the expression for the squared norm of the transformed signal:\n$$\n\\|Tx\\|_{2}^{2} = \\int_{0}^{\\infty} |x(u)|^{2} \\frac{1}{2\\sqrt{u}} du + \\int_{0}^{\\infty} |x(u)|^{2} \\frac{1}{2\\sqrt{u}} du = \\int_{0}^{\\infty} \\frac{|x(u)|^{2}}{\\sqrt{u}} du\n$$\nFor $T$ to be a well-defined map from $L^{2}(\\mathbb{R})$ to $L^{2}(\\mathbb{R})$, the condition $\\|x\\|_{2}^{2} = \\int_{-\\infty}^{\\infty} |x(u)|^{2} du  \\infty$ must imply $\\|Tx\\|_{2}^{2}  \\infty$. The derived expression $\\|Tx\\|_{2}^{2} = \\int_{0}^{\\infty} u^{-1/2} |x(u)|^{2} du$ shows that the integrability of $|x(u)|^{2}$ is not sufficient, due to the weighting factor $u^{-1/2}$ which diverges at $u=0$.\n\nTo demonstrate this explicitly, we use the provided test family, $x_{\\alpha}(t) = t^{-\\alpha}\\,\\mathbf{1}_{(0,1)}(t)$.\nFirst, we determine the values of $\\alpha$ for which $x_{\\alpha} \\in L^{2}(\\mathbb{R})$.\n$$\n\\|x_{\\alpha}\\|_{2}^{2} = \\int_{-\\infty}^{\\infty} |x_{\\alpha}(t)|^{2} dt = \\int_{0}^{1} |t^{-\\alpha}|^{2} dt = \\int_{0}^{1} t^{-2\\alpha} dt\n$$\nThis is a standard p-integral. It converges if and only if the exponent is greater than $-1$:\n$$\n-2\\alpha  -1 \\implies 2\\alpha  1 \\implies \\alpha  \\frac{1}{2}\n$$\nThus, $x_{\\alpha} \\in L^{2}(\\mathbb{R})$ if and only if $\\alpha  1/2$.\n\nNext, we determine the values of $\\alpha$ for which the transformed signal, $Tx_{\\alpha}$, is in $L^{2}(\\mathbb{R})$.\nFirst, we find the expression for $(Tx_{\\alpha})(t)$:\n$$\n(Tx_{\\alpha})(t) = x_{\\alpha}(t^{2}) = (t^{2})^{-\\alpha} \\mathbf{1}_{(0,1)}(t^{2}) = t^{-2\\alpha} \\mathbf{1}_{(0,1)}(t^{2})\n$$\nThe condition $0  t^{2}  1$ is equivalent to $t \\in (-1, 0) \\cup (0, 1)$. So, $(Tx_{\\alpha})(t) = t^{-2\\alpha}$ for $t \\in (-1, 1), t \\neq 0$, and is $0$ otherwise.\nNow we compute the squared norm of $Tx_{\\alpha}$:\n$$\n\\|Tx_{\\alpha}\\|_{2}^{2} = \\int_{-\\infty}^{\\infty} |(Tx_{\\alpha})(t)|^{2} dt = \\int_{-1}^{1} |t^{-2\\alpha}|^{2} dt = \\int_{-1}^{1} t^{-4\\alpha} dt\n$$\nThe integrand $t^{-4\\alpha}$ is an even function, so the integral is:\n$$\n\\|Tx_{\\alpha}\\|_{2}^{2} = 2 \\int_{0}^{1} t^{-4\\alpha} dt\n$$\nThis integral converges if and only if the exponent is greater than $-1$:\n$$\n-4\\alpha  -1 \\implies 4\\alpha  1 \\implies \\alpha  \\frac{1}{4}\n$$\nTherefore, $Tx_{\\alpha} \\in L^{2}(\\mathbb{R})$ if and only if $\\alpha  1/4$.\n\nWe showed that for $T$ to map $L^2(\\mathbb{R})$ to $L^2(\\mathbb{R})$, for any $x \\in L^2(\\mathbb{R})$ we must have $Tx \\in L^2(\\mathbb{R})$. Let us select a value for $\\alpha$ such that $x_{\\alpha} \\in L^{2}(\\mathbb{R})$ but $Tx_{\\alpha} \\notin L^{2}(\\mathbb{R})$. Any $\\alpha$ in the interval $[1/4, 1/2)$ will serve as a counterexample. For instance, let $\\alpha = 1/3$. Since $1/3  1/2$, $x_{1/3} \\in L^{2}(\\mathbb{R})$. However, since $1/3 \\ge 1/4$, $Tx_{1/3} \\notin L^{2}(\\mathbb{R})$.\nThis demonstrates that $T$ is not a well-defined operator from $L^{2}(\\mathbb{R})$ to $L^{2}(\\mathbb{R})$. Consequently, $T$ cannot be a bounded linear operator on $L^{2}(\\mathbb{R})$.\n\nThe final question asks for the largest real $\\alpha$ such that $T x_{\\alpha} \\in L^{2}(\\mathbb{R})$. The condition for this is $\\alpha  1/4$. The set of all such $\\alpha$ is the open interval $(-\\infty, 1/4)$. This set does not contain a largest element (a maximum). The question must be interpreted as asking for the supremum of this set, which is the least upper bound. The supremum of the set $\\{\\alpha \\in \\mathbb{R} \\mid \\alpha  1/4\\}$ is precisely $1/4$.", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "2910789"}]}