{"hands_on_practices": [{"introduction": "The cornerstone of digital signal processing is the ability to perfectly reconstruct a continuous-time signal from its discrete samples. This practice bridges the theoretical foundation of the Nyquist-Shannon sampling theorem with a concrete computational task. By first deriving the ideal interpolation formula from fundamental principles [@problem_id:2904292], you will solidify your understanding of how spectral replication is managed by a reconstruction filter. You will then implement this sinc interpolation to see the theory in action, recreating continuous signal values from discrete data, a skill essential for countless applications.", "problem": "You are given a continuous-time signal $x(t)$ that is strictly bandlimited to angular frequency $|\\omega| \\le \\Omega_{\\mathrm{b}}$ with $\\Omega_{\\mathrm{b}} < \\pi/T$, where $T > 0$ is a fixed sampling period. Ideal impulse sampling at rate $1/T$ produces the discrete-time samples $x[n] = x(nT)$ for all integers $n$, and the impulse train $s(t) = \\sum_{n\\in\\mathbb{Z}} x[n] \\,\\delta(t - nT)$. You feed $s(t)$ into a stable linear time-invariant (LTI) reconstruction system with impulse response $h(t)$ to produce an output $y(t)$.\n\nTask 1 (derivation from fundamentals). Starting from the following foundational bases:\n- the definition of the continuous-time Fourier transform (CTFT): $X(\\omega) = \\int_{-\\infty}^{\\infty} x(t) e^{-j\\omega t}\\, dt$ and its inverse $x(t) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} X(\\omega) e^{j\\omega t}\\, d\\omega$,\n- the spectrum of an impulse-sampled signal: $S(\\omega) = \\frac{1}{T}\\sum_{k\\in\\mathbb{Z}} X(\\omega - \\frac{2\\pi k}{T})$,\n- the LTI input-output relation in the frequency domain: $Y(\\omega) = H(\\omega) S(\\omega)$,\n\nderive, without assuming any interpolation shortcut formulas, the unique ideal lowpass $H(\\omega)$ that yields perfect reconstruction $Y(\\omega) = X(\\omega)$ for all $|\\omega| \\le \\Omega_{\\mathrm{b}}$ under the no-aliasing condition $\\Omega_{\\mathrm{b}} < \\pi/T$. Then, derive the corresponding time-domain interpolation kernel $h(t)$ and show that the reconstructed signal can be written as a convolutional superposition\n$$\ny(t) = \\sum_{n\\in\\mathbb{Z}} x[n]\\, h(t - nT).\n$$\nYou must arrive at a closed-form $h(t)$ in terms of a normalized sinc function $\\operatorname{sinc}(u) = \\frac{\\sin(\\pi u)}{\\pi u}$.\n\nTask 2 (numerical evaluation of the reconstruction). Using the result of Task 1, numerically evaluate $y(t)$ at specified time instants by replacing the infinite sum with a symmetric truncation $|n| \\le N$ for a sufficiently large integer $N$. Use the normalized sinc definition in Task 1. For all computations below, set $N = 2000$ and round every reported $y(t)$ value to $9$ decimal places using standard rounding to nearest, breaking ties to even.\n\nAngle quantities must be interpreted in radians. There are no physical units in this problem.\n\nTest suite. For each test case, the discrete-time sequence $x[n]$ is specified directly in terms of $n$, $T$, and fixed real parameters. All frequency parameters are strictly within the Nyquist limit $1/(2T)$, ensuring $\\Omega_{\\mathrm{b}} < \\pi/T$. For each test case, compute and report the list of reconstructed values $[y(t_1),\\dots,y(t_m)]$ at the given times using the truncated interpolation sum with $N = 2000$.\n\n- Test case A (multi-tone, unit sampling period):\n  - Parameters: $T = 1$, $\\phi = \\pi/7$.\n  - Sequence: $x[n] = \\cos(2\\pi \\cdot 0.2 \\cdot nT) + 0.5 \\,\\sin(2\\pi \\cdot 0.3 \\cdot nT + \\phi)$.\n  - Evaluation times: $t \\in \\{0, 0.25, 0.5, 1.25, 2\\}$.\n\n- Test case B (near-Nyquist single tone, unit sampling period):\n  - Parameters: $T = 1$.\n  - Sequence: $x[n] = \\cos(2\\pi \\cdot 0.49 \\cdot nT)$.\n  - Evaluation times: $t \\in \\{0, 0.5, 1, 1.5, 2\\}$.\n\n- Test case C (non-unit sampling period, composite with direct current (DC) component and phase):\n  - Parameters: $T = 0.8$, $\\theta = -\\pi/5$.\n  - Sequence: $x[n] = 0.1 + 0.7 \\cos\\!\\big(2\\pi \\cdot 0.25 \\cdot (nT)\\big) + 0.4 \\sin\\!\\big(2\\pi \\cdot 0.6 \\cdot (nT) + \\theta\\big)$.\n  - Evaluation times: $t \\in \\{0, 0.8, 1.6, 2.4, 4.0\\}$.\n\nComputational prescription. Implement\n$$\ny(t) \\approx \\sum_{n=-N}^{N} x[n]\\, h(t - nT), \\quad h(t) = \\operatorname{sinc}\\!\\left(\\frac{t}{T}\\right),\n$$\nwith $N = 2000$. Use vectorized computation where possible to avoid unnecessary numerical error and to ensure computational efficiency. Ensure stable evaluation of $\\operatorname{sinc}(0)$ using the continuous extension $\\operatorname{sinc}(0) = 1$.\n\nAnswer specification and output format. Your program should produce a single line of output containing the results as a comma-separated nested list with no spaces, of the form\n$[[y\\_A(t\\_1),\\dots,y\\_A(t\\_5)],[y\\_B(t\\_1),\\dots,y\\_B(t\\_5)],[y\\_C(t\\_1),\\dots,y\\_C(t\\_5)]]$,\nwhere each inner list corresponds to the test cases A, B, and C respectively, and each numeric entry is a decimal string rounded to $9$ digits after the decimal point. For example, an output line of the correct shape would look like $[[0.000000000,1.234000000],[...],[...]]$ but with the actual computed values for the three test cases.", "solution": "The problem is valid as it is scientifically grounded in the principles of signal processing, well-posed, and objective. It provides all necessary information for both the theoretical derivation and the numerical computation. We will proceed with the solution.\n\n**Task 1: Derivation of the Ideal Reconstruction Filter and Interpolation Formula**\n\nThe objective is to find a linear time-invariant (LTI) system with impulse response $h(t)$ that perfectly reconstructs a continuous-time signal $x(t)$ from its samples $x[n] = x(nT)$. The input to this reconstruction system is an impulse train $s(t) = \\sum_{n\\in\\mathbb{Z}} x[n] \\delta(t-nT)$.\n\nThe foundation for this derivation rests upon the given frequency-domain relationships:\n1.  The output spectrum $Y(\\omega)$ is related to the input spectrum $S(\\omega)$ and the system's frequency response $H(\\omega)$ by $Y(\\omega) = H(\\omega) S(\\omega)$.\n2.  The spectrum of the impulse train, $S(\\omega)$, is a periodic replication of the original signal's spectrum $X(\\omega)$:\n    $$S(\\omega) = \\frac{1}{T}\\sum_{k\\in\\mathbb{Z}} X\\left(\\omega - \\frac{2\\pi k}{T}\\right)$$\n    where $T$ is the sampling period. Let $\\omega_s = 2\\pi/T$ be the sampling angular frequency. The relation is thus $S(\\omega) = \\frac{1}{T}\\sum_{k\\in\\mathbb{Z}} X(\\omega - k\\omega_s)$.\n\nThe signal $x(t)$ is strictly bandlimited to $|\\omega| \\le \\Omega_{\\mathrm{b}}$, meaning its continuous-time Fourier transform (CTFT), $X(\\omega)$, is zero for all $|\\omega| > \\Omega_{\\mathrm{b}}$. The problem states the no-aliasing condition $\\Omega_{\\mathrm{b}} < \\pi/T$, which is equivalent to $\\Omega_{\\mathrm{b}} < \\omega_s/2$. This condition ensures that the spectral replicas in $S(\\omega)$ do not overlap. The spectral support of the $k$-th replica, $X(\\omega - k\\omega_s)$, is the interval $[k\\omega_s - \\Omega_{\\mathrm{b}}, k\\omega_s + \\Omega_{\\mathrm{b}}]$. Due to the no-aliasing condition, the baseband spectrum (for $k=0$, centered at $\\omega=0$) and the first harmonic replicas (for $k=\\pm 1$, centered at $\\omega=\\pm\\omega_s$) are disjoint. Specifically, the baseband spectrum ends at $\\Omega_{\\mathrm{b}}$, and the first replica begins at $\\omega_s - \\Omega_{\\mathrm{b}}$. Since $\\Omega_{\\mathrm{b}} < \\omega_s/2$, we have $\\omega_s - \\Omega_{\\mathrm{b}} > \\omega_s - \\omega_s/2 = \\omega_s/2 > \\Omega_{\\mathrm{b}}$.\n\nPerfect reconstruction requires that the output signal $y(t)$ is identical to the original signal $x(t)$, which implies their spectra must be equal: $Y(\\omega) = X(\\omega)$ for all $\\omega$.\n\nCombining the given relations, we require:\n$$X(\\omega) = H(\\omega) S(\\omega) = H(\\omega) \\left[ \\frac{1}{T}\\sum_{k\\in\\mathbb{Z}} X(\\omega - k\\omega_s) \\right]$$\n\nTo satisfy this equality, we design the filter $H(\\omega)$ to perform two functions:\n1.  Isolate the baseband component of $S(\\omega)$ (the $k=0$ term).\n2.  Scale this component to recover the original spectrum $X(\\omega)$.\n\nLet us define an ideal low-pass filter with a cutoff frequency $\\omega_c$. To isolate the baseband component, which is non-zero only for $|\\omega| \\le \\Omega_{\\mathrm{b}}$, while completely rejecting all higher-frequency replicas (the first of which starts at $\\omega_s - \\Omega_{\\mathrm{b}}$), we must choose a cutoff frequency $\\omega_c$ such that $\\Omega_{\\mathrm{b}} \\le \\omega_c \\le \\omega_s - \\Omega_{\\mathrm{b}}$. A canonical choice that is independent of the specific $\\Omega_{\\mathrm{b}}$ is the Nyquist frequency, $\\omega_c = \\omega_s/2 = \\pi/T$.\n\nFor frequencies within the passband, $|\\omega| \\le \\omega_c$, the sum $\\sum_{k\\in\\mathbb{Z}} X(\\omega - k\\omega_s)$ reduces to a single term, $X(\\omega)$, because all other terms with $k \\neq 0$ are zero in this range due to the no-aliasing condition. Thus, for $|\\omega| \\le \\pi/T$, the reconstruction equation becomes:\n$$X(\\omega) = H(\\omega) \\left( \\frac{1}{T} X(\\omega) \\right)$$\nFor this to hold for any non-trivial $X(\\omega)$, the filter's response in this band must be $H(\\omega) = T$.\n\nFor all frequencies outside this passband, $|\\omega| > \\pi/T$, the filter must have zero gain to eliminate the unwanted spectral replicas. Therefore, the unique ideal low-pass filter frequency response is:\n$$H(\\omega) = \\begin{cases} T & \\text{if } |\\omega| \\le \\pi/T \\\\ 0 & \\text{if } |\\omega| > \\pi/T \\end{cases}$$\nThis is a rectangular function of width $2\\pi/T$ and height $T$.\n\nNext, we derive the corresponding impulse response $h(t)$ by taking the inverse CTFT of $H(\\omega)$:\n$$h(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} H(\\omega) e^{j\\omega t} \\,d\\omega$$\nSubstituting the expression for $H(\\omega)$:\n$$h(t) = \\frac{1}{2\\pi} \\int_{-\\pi/T}^{\\pi/T} T e^{j\\omega t} \\,d\\omega = \\frac{T}{2\\pi} \\left[ \\frac{e^{j\\omega t}}{jt} \\right]_{-\\pi/T}^{\\pi/T}$$\nFor $t \\neq 0$:\n$$h(t) = \\frac{T}{2\\pi j t} \\left( e^{j\\pi t/T} - e^{-j\\pi t/T} \\right)$$\nUsing Euler's formula, $e^{j\\theta} - e^{-j\\theta} = 2j\\sin(\\theta)$:\n$$h(t) = \\frac{T}{2\\pi j t} \\left( 2j \\sin\\left(\\frac{\\pi t}{T}\\right) \\right) = \\frac{T}{\\pi t} \\sin\\left(\\frac{\\pi t}{T}\\right)$$\nTo express this in terms of the normalized sinc function, $\\operatorname{sinc}(u) = \\frac{\\sin(\\pi u)}{\\pi u}$, we rearrange the expression for $h(t)$:\n$$h(t) = \\frac{\\sin\\left(\\pi \\frac{t}{T}\\right)}{\\frac{\\pi t}{T}} = \\operatorname{sinc}\\left(\\frac{t}{T}\\right)$$\nFor $t=0$, the value is found by taking the limit or from the integral: $h(0) = \\frac{1}{2\\pi}\\int_{-\\pi/T}^{\\pi/T} T \\,d\\omega = \\frac{T}{2\\pi} \\left( \\frac{2\\pi}{T} \\right) = 1$. This corresponds to $\\operatorname{sinc}(0)=1$.\n\nFinally, we show that the reconstructed signal $y(t)$ can be expressed as a convolutional superposition. The output $y(t)$ is the convolution of the input impulse train $s(t)$ and the filter's impulse response $h(t)$:\n$$y(t) = s(t) * h(t) = \\int_{-\\infty}^{\\infty} s(\\tau) h(t - \\tau) \\,d\\tau$$\nSubstituting the definition of $s(t) = \\sum_{n\\in\\mathbb{Z}} x[n] \\delta(t - nT)$:\n$$y(t) = \\int_{-\\infty}^{\\infty} \\left( \\sum_{n\\in\\mathbb{Z}} x[n] \\delta(\\tau - nT) \\right) h(t - \\tau) \\,d\\tau$$\nBy linearity, we can interchange the summation and integration:\n$$y(t) = \\sum_{n\\in\\mathbb{Z}} x[n] \\int_{-\\infty}^{\\infty} \\delta(\\tau - nT) h(t - \\tau) \\,d\\tau$$\nUsing the sifting property of the Dirac delta function, $\\int_{-\\infty}^{\\infty} f(\\tau) \\delta(\\tau - a) \\,d\\tau = f(a)$, with $f(\\tau) = h(t-\\tau)$ and $a=nT$:\n$$y(t) = \\sum_{n\\in\\mathbb{Z}} x[n] h(t - nT)$$\nThis completes the derivation of the Whittaker-Shannon interpolation formula.\n\n**Task 2: Numerical Evaluation**\n\nThe formula derived above is implemented by truncating the infinite sum to a symmetric window of $|n| \\le N$, where $N=2000$. The reconstructed signal at time $t$ is approximated by:\n$$y(t) \\approx \\sum_{n=-N}^{N} x[n] \\operatorname{sinc}\\left(\\frac{t - nT}{T}\\right)$$\nThe provided test cases are evaluated using this formula. The implementation utilizes vectorized operations for efficiency and `numpy.sinc` for a stable and accurate computation of the normalized sinc function.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the signal reconstruction problem for the three given test cases.\n    \"\"\"\n    N = 2000\n    n_range = np.arange(-N, N + 1)\n\n    # --- Test Case A ---\n    T_A = 1.0\n    phi_A = np.pi / 7.0\n    times_A = [0.0, 0.25, 0.5, 1.25, 2.0]\n    \n    # Generate the samples x[n] for case A\n    nT_A = n_range * T_A\n    x_n_A = np.cos(2 * np.pi * 0.2 * nT_A) + 0.5 * np.sin(2 * np.pi * 0.3 * nT_A + phi_A)\n    \n    results_A = []\n    for t in times_A:\n        # Calculate kernel values h(t - nT)\n        sinc_arg_A = (t - nT_A) / T_A\n        h_vals_A = np.sinc(sinc_arg_A)\n        # Compute y(t) as the dot product (sum of products)\n        y_t = np.dot(x_n_A, h_vals_A)\n        results_A.append(y_t)\n\n    # --- Test Case B ---\n    T_B = 1.0\n    times_B = [0.0, 0.5, 1.0, 1.5, 2.0]\n    \n    # Generate the samples x[n] for case B\n    nT_B = n_range * T_B\n    x_n_B = np.cos(2 * np.pi * 0.49 * nT_B)\n    \n    results_B = []\n    for t in times_B:\n        # Calculate kernel values h(t - nT)\n        sinc_arg_B = (t - nT_B) / T_B\n        h_vals_B = np.sinc(sinc_arg_B)\n        # Compute y(t)\n        y_t = np.dot(x_n_B, h_vals_B)\n        results_B.append(y_t)\n\n    # --- Test Case C ---\n    T_C = 0.8\n    theta_C = -np.pi / 5.0\n    times_C = [0.0, 0.8, 1.6, 2.4, 4.0]\n\n    # Generate the samples x[n] for case C\n    nT_C = n_range * T_C\n    x_n_C = 0.1 + 0.7 * np.cos(2 * np.pi * 0.25 * nT_C) + 0.4 * np.sin(2 * np.pi * 0.6 * nT_C + theta_C)\n\n    results_C = []\n    for t in times_C:\n        # Calculate kernel values h(t - nT)\n        sinc_arg_C = (t - nT_C) / T_C\n        h_vals_C = np.sinc(sinc_arg_C)\n        # Compute y(t)\n        y_t = np.dot(x_n_C, h_vals_C)\n        results_C.append(y_t)\n\n    all_results = [results_A, results_B, results_C]\n\n    # Format the output string according to the specification.\n    # The f-string format specifier .9f rounds to 9 decimal places using\n    # standard rounding (round half to even), as required.\n    output_str = f\"[{','.join([f'[{\",\".join([f\"{val:.9f}\" for val in res_list])}]' for res_list in all_results])}]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "2904292"}, {"introduction": "While the ideal \"brick-wall\" filter is a powerful theoretical tool, real-world reconstruction must rely on physically realizable filters, which are always imperfect. This exercise moves from the ideal to the practical by challenging you to analyze the consequences of using a simple first-order RC filter for reconstruction [@problem_id:1728147]. By calculating the normalized mean-squared error, you will learn to distinguish between in-band distortion and out-of-band energy from aliased spectral images, providing a quantitative understanding of the trade-offs inherent in practical system design.", "problem": "A real-valued continuous-time, wide-sense stationary (WSS) random signal, $x_c(t)$, is known to be band-limited to a maximum angular frequency of $\\omega_M$. Its power spectral density is constant, $\\Phi_{xx}(\\omega) = N_0$, for $|\\omega| \\leq \\omega_M$ and is zero otherwise. This signal is sampled at the Nyquist rate, $T_s = \\pi/\\omega_M$, to produce the discrete-time sequence $x_d[n] = x_c(nT_s)$.\n\nAn attempt is made to reconstruct the original signal from its samples. The reconstruction filter is a scaled first-order Resistor-Capacitor (RC) low-pass filter, instead of an ideal brick-wall filter. The transfer function of the basic RC filter is $H(j\\omega) = \\frac{1}{1+j\\omega\\tau}$, where $\\tau$ is the time constant. For this specific application, two modifications are made:\n1. The filter's 3-dB cutoff frequency, $\\omega_c = 1/\\tau$, is set to be a fraction of the signal's maximum frequency, such that $\\omega_c = \\frac{1}{\\sqrt{3}} \\omega_M$.\n2. The filter is scaled by a gain constant $K$ so that its DC gain, $K H(0)$, matches the required DC gain of an ideal reconstruction filter, which is the sampling period $T_s$. The resulting reconstruction filter is $G(j\\omega) = K H(j\\omega)$.\n\nThe reconstructed signal, $x_r(t)$, is the output of this filter when its input is an impulse train weighted by the sample values, i.e., $x_s(t) = \\sum_{n=-\\infty}^{\\infty} x_d[n] \\delta(t - nT_s)$.\n\nDetermine the Normalized Mean-Squared Error (NMSE) of the reconstruction. The NMSE is defined as the ratio of the mean power of the error signal, $e(t) = x_r(t) - x_c(t)$, to the mean power of the original signal, $x_c(t)$. Your answer should be a single, closed-form analytic expression.", "solution": "The continuous-time WSS input has power spectral density $\\Phi_{xx}(\\omega)=N_{0}$ for $|\\omega|\\leq \\omega_{M}$ and zero otherwise. The sampling period is $T_{s}=\\pi/\\omega_{M}$, so the sampling angular frequency is $\\omega_{s}=2\\pi/T_{s}=2\\omega_{M}$. The sampled signal spectrum is\n$$\nX_{s}(j\\omega)=\\frac{1}{T_{s}}\\sum_{k=-\\infty}^{\\infty}X_{c}\\!\\left(j(\\omega-k\\omega_{s})\\right).\n$$\nThe reconstruction filter is $G(j\\omega)=K H(j\\omega)$ with $H(j\\omega)=\\frac{1}{1+j\\omega\\tau}$, $\\omega_{c}=\\frac{1}{\\tau}=\\frac{1}{\\sqrt{3}}\\omega_{M}$ so $\\tau=\\frac{\\sqrt{3}}{\\omega_{M}}$, and $K$ chosen so that $K H(0)=T_{s}$, which gives $K=T_{s}$. Therefore\n$$\nG(j\\omega)=\\frac{T_{s}}{1+j\\omega\\tau}.\n$$\nThe reconstructed spectrum is\n$$\nX_{r}(j\\omega)=G(j\\omega)X_{s}(j\\omega)=\\frac{G(j\\omega)}{T_{s}}\\sum_{k=-\\infty}^{\\infty}X_{c}\\!\\left(j(\\omega-k\\omega_{s})\\right).\n$$\nFor $|\\omega|\\leq \\omega_{M}$ there is no aliasing (since $\\omega_{s}=2\\omega_{M}$), hence only the $k=0$ term contributes and\n$$\nX_{r}(j\\omega)=\\frac{G(j\\omega)}{T_{s}}X_{c}(j\\omega)=\\frac{1}{1+j\\omega\\tau}X_{c}(j\\omega),\\quad |\\omega|\\leq \\omega_{M}.\n$$\nThus the in-band error spectrum is\n$$\nE(j\\omega)=X_{r}(j\\omega)-X_{c}(j\\omega)=\\left(\\frac{1}{1+j\\omega\\tau}-1\\right)X_{c}(j\\omega)=-\\frac{j\\omega\\tau}{1+j\\omega\\tau}X_{c}(j\\omega),\n$$\nso the in-band error PSD is\n$$\n\\Phi_{ee}^{\\text{in}}(\\omega)=\\left|\\frac{j\\omega\\tau}{1+j\\omega\\tau}\\right|^{2}\\Phi_{xx}(\\omega)=\\frac{\\omega^{2}\\tau^{2}}{1+\\omega^{2}\\tau^{2}}\\,N_{0},\\quad |\\omega|\\leq \\omega_{M}.\n$$\nFor $|\\omega|>\\omega_{M}$ the original signal has no content, but the reconstructed output contains filtered images. Because $\\omega_{s}=2\\omega_{M}$, the image bands for $k\\neq 0$ tile the regions $|\\omega|\\geq \\omega_{M}$ without overlap. In these regions the error equals the output, and its PSD is\n$$\n\\Phi_{ee}^{\\text{out}}(\\omega)=\\left|\\frac{G(j\\omega)}{T_{s}}\\right|^{2}N_{0}=\\frac{1}{1+\\omega^{2}\\tau^{2}}\\,N_{0},\\quad |\\omega|\\geq \\omega_{M}.\n$$\nTherefore the mean-squared error power is\n$$\nP_{e}=\\frac{1}{2\\pi}\\left[\\int_{-\\omega_{M}}^{\\omega_{M}}\\frac{\\omega^{2}\\tau^{2}}{1+\\omega^{2}\\tau^{2}}\\,N_{0}\\,d\\omega+\\int_{|\\omega|\\geq \\omega_{M}}\\frac{1}{1+\\omega^{2}\\tau^{2}}\\,N_{0}\\,d\\omega\\right].\n$$\nUsing the identities\n$$\n\\frac{\\omega^{2}\\tau^{2}}{1+\\omega^{2}\\tau^{2}}=1-\\frac{1}{1+\\omega^{2}\\tau^{2}},\\quad \\int\\frac{d\\omega}{1+\\omega^{2}\\tau^{2}}=\\frac{1}{\\tau}\\arctan(\\omega\\tau),\\quad \\int_{-\\infty}^{\\infty}\\frac{d\\omega}{1+\\omega^{2}\\tau^{2}}=\\frac{\\pi}{\\tau},\n$$\nwe obtain\n$$\n\\int_{-\\omega_{M}}^{\\omega_{M}}\\frac{\\omega^{2}\\tau^{2}}{1+\\omega^{2}\\tau^{2}}\\,d\\omega=2\\omega_{M}-\\frac{2}{\\tau}\\arctan(\\omega_{M}\\tau),\n$$\n$$\n\\int_{|\\omega|\\geq \\omega_{M}}\\frac{d\\omega}{1+\\omega^{2}\\tau^{2}}=\\frac{\\pi}{\\tau}-\\frac{2}{\\tau}\\arctan(\\omega_{M}\\tau).\n$$\nHence\n$$\nP_{e}=\\frac{N_{0}}{2\\pi}\\left[2\\omega_{M}+\\frac{\\pi}{\\tau}-\\frac{4}{\\tau}\\arctan(\\omega_{M}\\tau)\\right].\n$$\nThe original signal power is\n$$\nP_{x}=\\frac{1}{2\\pi}\\int_{-\\omega_{M}}^{\\omega_{M}}N_{0}\\,d\\omega=\\frac{N_{0}\\omega_{M}}{\\pi}.\n$$\nThus the normalized mean-squared error is\n$$\n\\text{NMSE}=\\frac{P_{e}}{P_{x}}=\\frac{1}{2\\omega_{M}}\\left[2\\omega_{M}+\\frac{\\pi}{\\tau}-\\frac{4}{\\tau}\\arctan(\\omega_{M}\\tau)\\right].\n$$\nWith $\\tau=\\sqrt{3}/\\omega_{M}$, we have $\\omega_{M}\\tau=\\sqrt{3}$ and $\\arctan(\\sqrt{3})=\\pi/3$, which yields\n$$\n\\text{NMSE}=1+\\frac{1}{2\\omega_{M}\\tau}\\left[\\pi-4\\arctan(\\omega_{M}\\tau)\\right]=1+\\frac{1}{2\\sqrt{3}}\\left[\\pi-\\frac{4\\pi}{3}\\right]=1-\\frac{\\pi}{6\\sqrt{3}}.\n$$\nThis is a closed-form analytic expression, independent of $N_{0}$ and $\\omega_{M}$.", "answer": "$$\\boxed{1-\\frac{\\pi}{6\\sqrt{3}}}$$", "id": "1728147"}, {"introduction": "The theory of uniform sampling is elegant, but many modern signal acquisition scenarios involve non-uniform sampling patterns. A common misconception is that stable reconstruction is guaranteed as long as the average sampling rate exceeds the Nyquist rate. This advanced problem shatters that myth by guiding you through the construction of a powerful counterexample [@problem_id:2904357]. Using the tools of frame theory, you will prove that sample clustering, even with a high average density, can lead to instability, revealing that the geometric distribution of samples is just as critical as their quantity for stable signal recovery.", "problem": "Let $B>0$ be fixed and consider the Paley–Wiener space $PW_{B}$ of all functions $f \\in L^{2}(\\mathbb{R})$ whose Fourier transform (with frequency measured in Hertz) is supported in the interval $\\left[-B,B\\right]$. The evaluation functional at $t \\in \\mathbb{R}$ is continuous on $PW_{B}$, so $PW_{B}$ is a reproducing kernel Hilbert space with reproducing kernel $K_{\\lambda}(t)$ at $\\lambda \\in \\mathbb{R}$ that satisfies $f(\\lambda)=\\langle f,K_{\\lambda}\\rangle_{PW_{B}}$ for all $f \\in PW_{B}$. \n\nDefine a nonuniform sampling set $\\Lambda \\subset \\mathbb{R}$ by the following rule. Let $M$ be the integer $M=\\lceil 2B\\rceil+1$. For each $n\\in\\mathbb{Z}$, place $M$ sampling points inside the unit interval $\\left[n,n+1\\right)$ clustered near its left endpoint:\n$$\n\\Lambda \\cap \\left[n,n+1\\right) \\,=\\, \\left\\{\\, n + j\\,\\varepsilon_{|n|} \\;:\\; j=0,1,\\dots,M-1 \\,\\right\\},\n$$\nwhere $\\varepsilon_{m}=\\min\\!\\left\\{\\tfrac{1}{2},\\,\\tfrac{1}{4B\\,(m+1)^{2}}\\right\\}$ for $m\\in\\mathbb{N}\\cup\\{0\\}$.\n\nAnswer the following, starting from first principles and core definitions.\n\n1. Derive the reproducing kernel $K_{\\lambda}(t)$ for $PW_{B}$ from the Fourier characterization, and determine the norm $\\|K_{\\lambda}\\|_{PW_{B}}$ and the inner product $\\langle \\phi_{\\lambda},\\phi_{\\mu}\\rangle$ of the unit-norm kernels $\\phi_{\\lambda}=K_{\\lambda}/\\|K_{\\lambda}\\|_{PW_{B}}$.\n2. Show that the average sampling rate of $\\Lambda$ equals $M$ samples per unit time, and therefore exceeds $2B$ samples per second.\n3. Using only the Hilbert space frame inequality definition (no shortcut theorems), analyze the sampling operator $S:PW_{B}\\to\\ell^{2}$, $Sf=\\{f(\\lambda)\\}_{\\lambda\\in\\Lambda}$. Interpret stable reconstruction in terms of frame bounds for the family $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$ and relate the sampling inequality $A'\\|f\\|_{PW_{B}}^{2}\\leq\\sum_{\\lambda\\in\\Lambda}|f(\\lambda)|^{2}\\leq B'\\|f\\|_{PW_{B}}^{2}$ to the frame bounds $A,B$ for $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$.\n4. Prove that the lower frame bound for $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$ is zero by estimating the smallest eigenvalue of the Gram matrix on clusters $\\Lambda\\cap[n,n+1)$ as $|n|\\to\\infty$, and conclude that the sampling lower bound $A'$ for $S$ must also be zero. Explain the mechanism by which clustering drives the lower frame bound to zero in terms of near-linear dependence of $\\{\\phi_{\\lambda}\\}$ within increasingly tight clusters.\n\nGive the exact value of the lower sampling bound $A'$ (the constant in the left sampling inequality for $Sf$) for this construction. Your final answer must be a single real number. No approximation or rounding is required.", "solution": "The problem is evaluated as valid as it is scientifically grounded in the theory of signal processing and functional analysis, is well-posed with precise definitions, and is expressed in objective mathematical language. We may proceed with the solution.\n\nThe solution is presented in four parts as requested by the problem statement.\n\n1. Derivation of the Reproducing Kernel and Related Properties\n\nThe Paley-Wiener space $PW_{B}$ consists of functions $f \\in L^{2}(\\mathbb{R})$ whose Fourier transform $\\hat{f}(\\xi) = \\int_{-\\infty}^{\\infty} f(t) \\exp(-2\\pi i \\xi t) dt$ has its support within the interval $[-B, B]$. The inner product on $PW_{B}$ is inherited from $L^{2}(\\mathbb{R})$, and by Plancherel's theorem, it can be expressed in the frequency domain as:\n$$\n\\langle f, g \\rangle_{PW_{B}} = \\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) \\overline{\\hat{g}(\\xi)} d\\xi = \\int_{-B}^{B} \\hat{f}(\\xi) \\overline{\\hat{g}(\\xi)} d\\xi\n$$\nThe space $PW_{B}$ is a Reproducing Kernel Hilbert Space (RKHS), which means for each $\\lambda \\in \\mathbb{R}$, there exists a function $K_{\\lambda} \\in PW_{B}$ such that $f(\\lambda) = \\langle f, K_{\\lambda} \\rangle_{PW_{B}}$ for all $f \\in PW_{B}$.\n\nTo find the kernel $K_{\\lambda}(t)$, we use the inverse Fourier transform representation of $f(\\lambda)$:\n$$\nf(\\lambda) = \\int_{-\\infty}^{\\infty} \\hat{f}(\\xi) \\exp(2\\pi i \\xi \\lambda) d\\xi = \\int_{-B}^{B} \\hat{f}(\\xi) \\exp(2\\pi i \\xi \\lambda) d\\xi\n$$\nComparing this with the reproducing property $f(\\lambda) = \\int_{-B}^{B} \\hat{f}(\\xi) \\overline{\\hat{K}_{\\lambda}(\\xi)} d\\xi$, we can identify $\\overline{\\hat{K}_{\\lambda}(\\xi)} = \\exp(2\\pi i \\xi \\lambda)$. Therefore, the Fourier transform of the reproducing kernel is $\\hat{K}_{\\lambda}(\\xi) = \\exp(-2\\pi i \\xi \\lambda)$ for $\\xi \\in [-B, B]$ and $0$ otherwise.\n\nWe find $K_{\\lambda}(t)$ by taking the inverse Fourier transform of $\\hat{K}_{\\lambda}(\\xi)$:\n$$\nK_{\\lambda}(t) = \\int_{-B}^{B} \\hat{K}_{\\lambda}(\\xi) \\exp(2\\pi i \\xi t) d\\xi = \\int_{-B}^{B} \\exp(-2\\pi i \\xi \\lambda) \\exp(2\\pi i \\xi t) d\\xi = \\int_{-B}^{B} \\exp(2\\pi i \\xi (t-\\lambda)) d\\xi\n$$\nEvaluating the integral gives:\n$$\nK_{\\lambda}(t) = \\left[ \\frac{\\exp(2\\pi i \\xi (t-\\lambda))}{2\\pi i (t-\\lambda)} \\right]_{-B}^{B} = \\frac{\\exp(2\\pi i B (t-\\lambda)) - \\exp(-2\\pi i B (t-\\lambda))}{2\\pi i (t-\\lambda)} = \\frac{2i\\sin\\left(2\\pi B(t-\\lambda)\\right)}{2\\pi i(t-\\lambda)}\n$$\nThus, the reproducing kernel is:\n$$\nK_{\\lambda}(t) = \\frac{\\sin\\left(2\\pi B(t-\\lambda)\\right)}{\\pi(t-\\lambda)}\n$$\nThis can be written using the normalized sinc function, $\\operatorname{sinc}(x) = \\frac{\\sin(\\pi x)}{\\pi x}$, as $K_{\\lambda}(t) = 2B\\,\\operatorname{sinc}(2B(t-\\lambda))$.\n\nThe norm of the kernel, $\\|K_{\\lambda}\\|_{PW_{B}}$, can be calculated using the reproducing property: $\\|K_{\\lambda}\\|^2 = \\langle K_{\\lambda}, K_{\\lambda} \\rangle = K_{\\lambda}(\\lambda)$.\n$$\n\\|K_{\\lambda}\\|_{PW_{B}}^2 = \\lim_{t\\to\\lambda} \\frac{\\sin(2\\pi B(t-\\lambda))}{\\pi(t-\\lambda)} = \\lim_{u\\to 0} \\frac{\\sin(2\\pi B u)}{\\pi u} = 2B\n$$\nAlternatively, using the frequency domain inner product:\n$$\n\\|K_{\\lambda}\\|_{PW_{B}}^2 = \\int_{-B}^{B} |\\hat{K}_{\\lambda}(\\xi)|^2 d\\xi = \\int_{-B}^{B} |\\exp(-2\\pi i \\xi \\lambda)|^2 d\\xi = \\int_{-B}^{B} 1 d\\xi = 2B\n$$\nSo, the norm is $\\|K_{\\lambda}\\|_{PW_{B}} = \\sqrt{2B}$.\n\nThe unit-norm kernel is $\\phi_{\\lambda}(t) = \\frac{K_{\\lambda}(t)}{\\|K_{\\lambda}\\|_{PW_{B}}} = \\frac{1}{\\sqrt{2B}} K_{\\lambda}(t)$.\nThe inner product of two unit-norm kernels $\\phi_{\\lambda}$ and $\\phi_{\\mu}$ is:\n$$\n\\langle \\phi_{\\lambda}, \\phi_{\\mu} \\rangle_{PW_{B}} = \\left\\langle \\frac{K_{\\lambda}}{\\sqrt{2B}}, \\frac{K_{\\mu}}{\\sqrt{2B}} \\right\\rangle = \\frac{1}{2B} \\langle K_{\\lambda}, K_{\\mu} \\rangle_{PW_{B}}\n$$\nUsing the reproducing property, $\\langle K_{\\lambda}, K_{\\mu} \\rangle = K_{\\mu}(\\lambda)$.\n$$\n\\langle \\phi_{\\lambda}, \\phi_{\\mu} \\rangle_{PW_{B}} = \\frac{1}{2B} K_{\\mu}(\\lambda) = \\frac{1}{2B} \\frac{\\sin(2\\pi B(\\lambda-\\mu))}{\\pi(\\lambda-\\mu)} = \\frac{\\sin(2\\pi B(\\lambda-\\mu))}{2\\pi B(\\lambda-\\mu)} = \\operatorname{sinc}(2B(\\lambda-\\mu))\n$$\n\n2. Average Sampling Rate\n\nThe set of sampling points is $\\Lambda = \\bigcup_{n \\in \\mathbb{Z}} \\Lambda_n$, where $\\Lambda_n = \\Lambda \\cap [n, n+1) = \\{n + j\\varepsilon_{|n|} : j=0, 1, \\dots, M-1\\}$.\nFor each integer $n$, the interval $[n, n+1)$ contains exactly $M$ sampling points. The length of this interval is $1$.\nThe average sampling rate (or density) of $\\Lambda$ is defined as $D(\\Lambda) = \\lim_{T\\to\\infty} \\frac{|\\Lambda \\cap [-T, T]|}{2T}$.\nFor any large positive integer $N$, the interval $[-N, N)$ is a union of $2N$ unit intervals, $[-N, -N+1), \\dots, [N-1, N)$. The number of points in this interval is:\n$$\n|\\Lambda \\cap [-N, N)| = \\sum_{n=-N}^{N-1} |\\Lambda \\cap [n, n+1)| = \\sum_{n=-N}^{N-1} M = 2NM\n$$\nThe length of the interval $[-N, N)$ is $2N$. The density is therefore:\n$$\nD(\\Lambda) = \\lim_{N\\to\\infty, N\\in\\mathbb{Z}} \\frac{2NM}{2N} = M\n$$\nThe limit holds for $T\\to\\infty$ over real numbers as well. Thus, the average sampling rate is $M$ samples per unit time.\nWe are given $M = \\lceil 2B \\rceil + 1$.\nIf $2B$ is an integer, $\\lceil 2B \\rceil = 2B$, so $M = 2B+1 > 2B$.\nIf $2B$ is not an integer, then $\\lceil 2B \\rceil > 2B$, so $M = \\lceil 2B \\rceil + 1 > 2B+1 > 2B$.\nIn all cases, the average sampling rate $M$ is strictly greater than $2B$, the Nyquist rate.\n\n3. Sampling Operator and Frame Bounds\n\nThe family of unit-norm kernels $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$ constitutes a frame for $PW_{B}$ if there exist constants $A > 0$ and $B < \\infty$ (the frame bounds) such that for all $f \\in PW_{B}$:\n$$\nA\\,\\|f\\|_{PW_{B}}^2 \\le \\sum_{\\lambda\\in\\Lambda} |\\langle f, \\phi_{\\lambda} \\rangle_{PW_{B}}|^2 \\le B\\,\\|f\\|_{PW_{B}}^2\n$$\nFrom Part 1, we have the relationship between the inner product and the function evaluation:\n$$\n\\langle f, \\phi_{\\lambda} \\rangle_{PW_{B}} = \\left\\langle f, \\frac{K_{\\lambda}}{\\sqrt{2B}} \\right\\rangle = \\frac{1}{\\sqrt{2B}} \\langle f, K_{\\lambda} \\rangle_{PW_{B}} = \\frac{f(\\lambda)}{\\sqrt{2B}}\n$$\nSubstituting this into the frame inequality:\n$$\nA\\,\\|f\\|_{PW_{B}}^2 \\le \\sum_{\\lambda\\in\\Lambda} \\left| \\frac{f(\\lambda)}{\\sqrt{2B}} \\right|^2 \\le B\\,\\|f\\|_{PW_{B}}^2\n$$\n$$\nA\\,\\|f\\|_{PW_{B}}^2 \\le \\frac{1}{2B} \\sum_{\\lambda\\in\\Lambda} |f(\\lambda)|^2 \\le B\\,\\|f\\|_{PW_{B}}^2\n$$\nMultiplying the inequality by $2B$ (which is positive) yields:\n$$\n(2BA) \\|f\\|_{PW_{B}}^2 \\le \\sum_{\\lambda\\in\\Lambda} |f(\\lambda)|^2 \\le (2BB) \\|f\\|_{PW_{B}}^2\n$$\nThe problem defines the sampling operator $S: PW_{B} \\to \\ell^2(\\Lambda)$ as $Sf = \\{f(\\lambda)\\}_{\\lambda\\in\\Lambda}$. The sum $\\sum_{\\lambda\\in\\Lambda} |f(\\lambda)|^2$ is the squared norm $\\|Sf\\|_{\\ell^2}^2$. The sampling inequality is given as $A'\\|f\\|_{PW_B}^{2}\\leq\\sum_{\\lambda\\in\\Lambda}|f(\\lambda)|^{2}\\leq B'\\|f\\|_{PW_{B}}^{2}$.\nBy direct comparison, we find the relationship between the sampling bounds $A', B'$ and the frame bounds $A, B$ for the family $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$:\n$$\nA' = 2BA \\quad \\text{and} \\quad B' = 2BB\n$$\nStable reconstruction of $f$ from its samples $\\{f(\\lambda)\\}_{\\lambda\\in\\Lambda}$ is possible if and only if the sampling operator $S$ is bounded and has a bounded inverse on its range (i.e., is bounded below). This requires $A' > 0$, which is equivalent to the lower frame bound $A$ being strictly positive. If $A' = 0$, stable reconstruction is not possible because small errors in the samples can correspond to arbitrarily large errors in the reconstructed function.\n\n4. Proof of Zero Lower Bound\n\nWe will prove that the lower frame bound $A$ for the family $\\{\\phi_{\\lambda}\\}_{\\lambda\\in\\Lambda}$ is zero. This implies the lower sampling bound $A'$ is also zero.\nThe lower frame bound $A$ is given by the infimum of the spectrum of the frame operator. This is also equal to the infimum of the lowest eigenvalues of all finite Gram matrices associated with the frame vectors. Specifically, $A = \\inf_{J \\subset \\Lambda, |J|<\\infty} \\lambda_{\\min}(G_J)$, where $(G_J)_{\\lambda,\\mu} = \\langle \\phi_{\\lambda}, \\phi_{\\mu} \\rangle$.\nLet us analyze the Gram matrices $G_n$ corresponding to the clusters of sampling points $\\Lambda_n = \\Lambda \\cap [n, n+1) = \\{\\lambda_{n,j}\\}_{j=0}^{M-1}$. The size of each $G_n$ is $M \\times M$. The entries are given by:\n$$\n(G_n)_{j,k} = \\langle \\phi_{\\lambda_{n,j}}, \\phi_{\\lambda_{n,k}} \\rangle = \\operatorname{sinc}(2B(\\lambda_{n,j} - \\lambda_{n,k}))\n$$\nwhere $j, k \\in \\{0, 1, \\dots, M-1\\}$. The difference in sampling points is $\\lambda_{n,j} - \\lambda_{n,k} = (j-k)\\varepsilon_{|n|}$. So,\n$$\n(G_n)_{j,k} = \\operatorname{sinc}(2B(j-k)\\varepsilon_{|n|})\n$$\nWe examine the behavior of $G_n$ as $|n| \\to \\infty$. The spacing parameter is $\\varepsilon_{m} = \\min\\{\\tfrac{1}{2},\\,\\tfrac{1}{4B\\,(m+1)^{2}}\\}$. For large $m=|n|$, we have $\\varepsilon_{|n|} = \\frac{1}{4B(|n|+1)^2}$, which tends to $0$.\nAs $\\varepsilon_{|n|} \\to 0$, the argument of the sinc function $2B(j-k)\\varepsilon_{|n|} \\to 0$. Since $\\operatorname{sinc}(x) \\to 1$ as $x \\to 0$, each entry of the matrix $G_n$ converges to $1$:\n$$\n\\lim_{|n|\\to\\infty} (G_n)_{j,k} = \\operatorname{sinc}(0) = 1\n$$\nThus, the matrix $G_n$ converges to the $M \\times M$ matrix $J_M$ whose entries are all $1$.\nThe matrix $J_M$ has rank $1$. Its eigenvalues are $M$ (with multiplicity $1$) and $0$ (with multiplicity $M-1$). The smallest eigenvalue of $J_M$ is $0$.\nSince the eigenvalues of a matrix are continuous functions of its entries, the eigenvalues of $G_n$ must converge to the eigenvalues of $J_M$ as $|n|\\to\\infty$. In particular, the smallest eigenvalue of $G_n$, denoted $\\lambda_{\\min}(G_n)$, must converge to the smallest eigenvalue of $J_M$:\n$$\n\\lim_{|n|\\to\\infty} \\lambda_{\\min}(G_n) = 0\n$$\nThe global lower frame bound $A$ must be less than or equal to the smallest eigenvalue of any finite sub-Gramian. Therefore, $0 \\le A \\leq \\lambda_{\\min}(G_n)$ for all $n \\in \\mathbb{Z}$. Taking the limit as $|n| \\to \\infty$, we get $0 \\le A \\le 0$, which forces $A=0$.\n\nThe mechanism driving the lower frame bound to zero is the increasing near-linear dependence of the functions $\\{\\phi_\\lambda\\}$ within clusters as they become tighter. As $|n|\\to\\infty$, the points in $\\Lambda_n$ cluster together. The inner product $\\langle \\phi_{\\lambda_{n,j}}, \\phi_{\\lambda_{n,k}} \\rangle \\to 1$, meaning these functions become almost identical (i.e., parallel) in the Hilbert space $PW_B$. A set of nearly parallel vectors is nearly linearly dependent. This means there exist non-trivial linear combinations of these functions that have an arbitrarily small norm. The existence of such combinations for any energy level is precisely the condition for the lower frame bound being zero, indicating instability.\n\nFinally, we determine the exact value of the lower sampling bound $A'$. From Part 3, we have the relation $A' = 2BA$. Since we have rigorously proven that $A=0$, it follows that:\n$$\nA' = 2B \\cdot 0 = 0\n$$", "answer": "$$\\boxed{0}$$", "id": "2904357"}]}