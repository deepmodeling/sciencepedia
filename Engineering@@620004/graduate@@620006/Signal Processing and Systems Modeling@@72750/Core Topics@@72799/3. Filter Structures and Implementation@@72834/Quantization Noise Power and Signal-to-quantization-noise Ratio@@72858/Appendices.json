{"hands_on_practices": [{"introduction": "Understanding the relationship between signal power and quantization noise is fundamental to analyzing any digital signal processing system. This first practice explores the Signal-to-Quantization-Noise Ratio ($SQNR$) for a sinusoidal input, a standard benchmark signal. By deriving the $SQNR$ from first principles and then analyzing how it changes when the signal does not use the full dynamic range of the quantizer [@problem_id:2898438], you will build a crucial intuition for the performance limitations imposed by quantization.", "problem": "An analog-to-digital converter (ADC) employs a uniform mid-tread quantizer with resolution $B$ bits and symmetric full-scale range $\\left[-A_{\\mathrm{FS}},\\,A_{\\mathrm{FS}}\\right]$. The quantizer uses rounding and is not overloaded. Assume the classical additive, white, signal-independent quantization-noise model with quantization error uniformly distributed over a single quantization step. A single-tone sinusoid $x(t)=A\\cos(\\omega_{0}t)$ is applied at the input.\n\nDefine the Signal-to-Quantization-Noise Ratio (SQNR) as the ratio of the input signal’s average power to the quantization error power, and define its decibel (dB) measure via $10\\log_{10}(\\cdot)$. Let $\\mathrm{SQNR}_{\\mathrm{dB,ref}}$ be the decibel-valued SQNR when the sinusoid uses the full available peak amplitude, $A=A_{\\mathrm{FS}}$, and let $\\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma)$ be the decibel-valued SQNR when the sinusoid amplitude is backed off to $A=\\gamma A_{\\mathrm{FS}}$ to provide a crest factor margin, where $\\gamma\\in(0,1)$.\n\nWorking from first principles of uniform quantization, sinusoidal average power, and the stated noise model, derive the decibel offset\n$$\\Delta_{\\mathrm{dB}}=\\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma)-\\mathrm{SQNR}_{\\mathrm{dB,ref}}$$\nas a closed-form expression that depends only on $\\gamma$. Express the final answer in decibels. No numerical evaluation is required, and no rounding is needed. The final answer must be a single closed-form analytic expression.", "solution": "The problem as stated is valid. It is scientifically grounded, well-posed, objective, and contains all necessary information for a rigorous derivation. It is a standard problem in the analysis of analog-to-digital conversion. I will proceed with the solution from first principles as required.\n\nThe problem asks for the decibel offset $\\Delta_{\\mathrm{dB}} = \\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma) - \\mathrm{SQNR}_{\\mathrm{dB,ref}}$. We must first derive an expression for the Signal-to-Quantization-Noise Ratio (SQNR).\n\nFirst, we determine the quantization step size, $\\Delta$. The quantizer has a resolution of $B$ bits, which corresponds to $L = 2^B$ quantization levels. The full-scale range is specified as $[-A_{\\mathrm{FS}}, A_{\\mathrm{FS}}]$, so the total span is $A_{\\mathrm{FS}} - (-A_{\\mathrm{FS}}) = 2A_{\\mathrm{FS}}$. For a uniform quantizer, the step size $\\Delta$ is the total range divided by the number of levels:\n$$\n\\Delta = \\frac{2A_{\\mathrm{FS}}}{L} = \\frac{2A_{\\mathrm{FS}}}{2^B}\n$$\n\nNext, we calculate the quantization noise power, $P_q$. The problem states that the quantization error, which we denote by $e$, is modeled as a random variable uniformly distributed over a single quantization step. For a mid-tread quantizer using rounding, the error for any given sample lies in the interval $[-\\frac{\\Delta}{2}, \\frac{\\Delta}{2}]$. The probability density function (PDF) of the error $e$ is therefore:\n$$\np_e(x) = \\begin{cases} \\frac{1}{\\Delta} & \\text{for } -\\frac{\\Delta}{2} \\le x \\le \\frac{\\Delta}{2} \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nThe noise power $P_q$ is the variance of the quantization error, $\\sigma_e^2 = E[e^2] - (E[e])^2$. Due to the symmetry of the PDF about zero, the mean error is $E[e] = 0$. Thus, the power is equal to the mean-square value $E[e^2]$:\n$$\nP_q = E[e^2] = \\int_{-\\infty}^{\\infty} x^2 p_e(x) \\,dx = \\int_{-\\Delta/2}^{\\Delta/2} x^2 \\frac{1}{\\Delta} \\,dx\n$$\nEvaluating the integral:\n$$\nP_q = \\frac{1}{\\Delta} \\left[ \\frac{x^3}{3} \\right]_{-\\Delta/2}^{\\Delta/2} = \\frac{1}{3\\Delta} \\left( \\left(\\frac{\\Delta}{2}\\right)^3 - \\left(-\\frac{\\Delta}{2}\\right)^3 \\right) = \\frac{1}{3\\Delta} \\left( \\frac{\\Delta^3}{8} + \\frac{\\Delta^3}{8} \\right) = \\frac{1}{3\\Delta} \\left( \\frac{2\\Delta^3}{8} \\right) = \\frac{\\Delta^2}{12}\n$$\nThis is the well-known result for the power of uniformly distributed quantization noise.\n\nNow, we determine the average power of the input signal, $P_x$. The signal is a single-tone sinusoid $x(t) = A\\cos(\\omega_0 t)$. The average power is the mean-square value of the signal, calculated over one period $T_0 = 2\\pi/\\omega_0$:\n$$\nP_x = \\frac{1}{T_0} \\int_{0}^{T_0} x^2(t) \\,dt = \\frac{1}{T_0} \\int_{0}^{T_0} \\left( A\\cos(\\omega_0 t) \\right)^2 \\,dt = \\frac{A^2}{T_0} \\int_{0}^{T_0} \\cos^2(\\omega_0 t) \\,dt\n$$\nUsing the trigonometric identity $\\cos^2(\\theta) = \\frac{1}{2}(1 + \\cos(2\\theta))$:\n$$\nP_x = \\frac{A^2}{T_0} \\int_{0}^{T_0} \\frac{1}{2}(1 + \\cos(2\\omega_0 t)) \\,dt = \\frac{A^2}{2T_0} \\left[ t + \\frac{\\sin(2\\omega_0 t)}{2\\omega_0} \\right]_{0}^{T_0}\n$$\nThe sine term evaluates to zero at both $t=0$ and $t=T_0$. Therefore, the expression simplifies to:\n$$\nP_x = \\frac{A^2}{2T_0} (T_0) = \\frac{A^2}{2}\n$$\n\nThe SQNR is defined as the ratio of signal power to quantization noise power:\n$$\n\\mathrm{SQNR} = \\frac{P_x}{P_q} = \\frac{A^2 / 2}{\\Delta^2 / 12} = \\frac{6A^2}{\\Delta^2}\n$$\nWe substitute the expression for $\\Delta$:\n$$\n\\mathrm{SQNR} = \\frac{6A^2}{\\left( \\frac{2A_{\\mathrm{FS}}}{2^B} \\right)^2} = \\frac{6A^2 \\cdot (2^B)^2}{4A_{\\mathrm{FS}}^2} = \\frac{3}{2} \\left( \\frac{A}{A_{\\mathrm{FS}}} \\right)^2 2^{2B}\n$$\nThis is the general expression for the SQNR of a sinusoidal signal in a uniform quantizer.\n\nNow we convert to decibels (dB) and evaluate for the two specified cases. The dB measure is given by $10\\log_{10}(\\cdot)$.\n$$\n\\mathrm{SQNR}_{\\mathrm{dB}} = 10\\log_{10}(\\mathrm{SQNR}) = 10\\log_{10}\\left( \\frac{3}{2} \\left( \\frac{A}{A_{\\mathrm{FS}}} \\right)^2 2^{2B} \\right)\n$$\nUsing properties of logarithms:\n$$\n\\mathrm{SQNR}_{\\mathrm{dB}} = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 10\\log_{10}\\left(\\left(\\frac{A}{A_{\\mathrm{FS}}}\\right)^2\\right) + 10\\log_{10}\\left(2^{2B}\\right)\n$$\n$$\n\\mathrm{SQNR}_{\\mathrm{dB}} = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20\\log_{10}\\left(\\frac{A}{A_{\\mathrm{FS}}}\\right) + 20B\\log_{10}(2)\n$$\n\nFor the reference case, the sinusoid uses the full peak amplitude, $A = A_{\\mathrm{FS}}$.\n$$\n\\mathrm{SQNR}_{\\mathrm{dB,ref}} = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20\\log_{10}\\left(\\frac{A_{\\mathrm{FS}}}{A_{\\mathrm{FS}}}\\right) + 20B\\log_{10}(2)\n$$\nSince $\\log_{10}(1)=0$, this becomes:\n$$\n\\mathrm{SQNR}_{\\mathrm{dB,ref}} = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20B\\log_{10}(2)\n$$\n\nFor the backed-off case, the amplitude is $A = \\gamma A_{\\mathrm{FS}}$, where $\\gamma \\in (0,1)$.\n$$\n\\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma) = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20\\log_{10}\\left(\\frac{\\gamma A_{\\mathrm{FS}}}{A_{\\mathrm{FS}}}\\right) + 20B\\log_{10}(2)\n$$\n$$\n\\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma) = 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20\\log_{10}(\\gamma) + 20B\\log_{10}(2)\n$$\n\nFinally, we compute the required decibel offset, $\\Delta_{\\mathrm{dB}}$:\n$$\n\\Delta_{\\mathrm{dB}} = \\mathrm{SQNR}_{\\mathrm{dB}}(\\gamma) - \\mathrm{SQNR}_{\\mathrm{dB,ref}}\n$$\n$$\n\\Delta_{\\mathrm{dB}} = \\left( 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20\\log_{10}(\\gamma) + 20B\\log_{10}(2) \\right) - \\left( 10\\log_{10}\\left(\\frac{3}{2}\\right) + 20B\\log_{10}(2) \\right)\n$$\nAll terms except the one involving $\\gamma$ cancel out.\n$$\n\\Delta_{\\mathrm{dB}} = 20\\log_{10}(\\gamma)\n$$\nThis expression depends only on $\\gamma$, as required. Since $\\gamma \\in (0,1)$, $\\log_{10}(\\gamma)$ is negative, correctly indicating that backing off the signal amplitude reduces the SQNR.", "answer": "$$\n\\boxed{20\\log_{10}(\\gamma)}\n$$", "id": "2898438"}, {"introduction": "While the standard model of quantization noise as a zero-mean, uniformly distributed process is powerful, real-world quantizers can have imperfections. This exercise investigates the effect of a systematic offset in the quantizer's decision thresholds, a common type of non-ideality [@problem_id:2898425]. By analyzing how this offset impacts the mean and variance of the quantization error, you will gain a deeper understanding of the distinction between quantization noise power and deterministic error biases.", "problem": "A real-valued, discrete-time, stationary input process $x[n]$ with finite variance $\\sigma_{x}^{2}$ is processed by an infinite, uniform, mid-tread quantizer of step size $\\Delta \\gt 0$ and reconstruction levels $\\{k\\Delta : k \\in \\mathbb{Z}\\}$ that has all of its decision thresholds shifted by a fixed offset $\\theta \\in \\mathbb{R}$ relative to the origin. Concretely, the decision threshold between the reconstruction levels $k\\Delta$ and $(k+1)\\Delta$ is located at $(k+\\tfrac{1}{2})\\Delta + \\theta$ for every integer $k$, while the reconstruction levels remain at $\\{k\\Delta\\}$. Assume there is no overload.\n\nLet $q[n]$ denote the quantizer output and define the quantization error $e[n] \\triangleq q[n] - x[n]$.\n\nAdopt the high-resolution model (also known as Bennett’s approximation): for a uniform mid-tread quantizer with zero offset (i.e., thresholds at $(k+\\tfrac{1}{2})\\Delta$) applied to a sufficiently smooth stationary input with no overload, the resulting quantization error $e_{0}[n]$ is approximately independent of the input and approximately uniformly distributed on the interval $[-\\Delta/2,\\,+\\Delta/2]$.\n\nUsing only the foregoing definitions and assumptions, derive closed-form expressions for the following quantities as functions of $\\Delta$, $\\theta$, and $\\sigma_{x}^{2}$:\n- the mean $\\mathbb{E}\\{e[n]\\}$,\n- the variance $\\operatorname{Var}\\{e[n]\\}$,\n- and the signal-to-quantization-noise ratio (SQNR), defined here in linear scale as $\\mathrm{SQNR} \\triangleq \\sigma_{x}^{2} / \\operatorname{Var}\\{e[n]\\}$.\n\nProvide your final answer as a single row vector containing these three expressions in the order listed above. No numerical evaluation or rounding is required.", "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, and objective. It presents a standard problem in signal processing theory with a specific variation (threshold offset) that is solvable using the provided assumptions.\n\nLet the quantizer function with offset $\\theta$ be denoted by $Q_{\\theta}(x)$. The input $x$ is mapped to the reconstruction level $k\\Delta$ if it falls into the quantization interval corresponding to that level. The decision thresholds are given at $(k+\\frac{1}{2})\\Delta + \\theta$. Therefore, the quantizer mapping is defined as:\n$$Q_{\\theta}(x) = k\\Delta \\quad \\text{for} \\quad (k-\\frac{1}{2})\\Delta + \\theta < x \\le (k+\\frac{1}{2})\\Delta + \\theta$$\nwhere $k$ is any integer from $\\mathbb{Z}$.\n\nLet us compare this to a standard uniform mid-tread quantizer with zero offset, denoted by $Q_{0}(y)$. Its mapping is:\n$$Q_{0}(y) = k\\Delta \\quad \\text{for} \\quad (k-\\frac{1}{2})\\Delta < y \\le (k+\\frac{1}{2})\\Delta$$\nBy examining the inequalities, we can establish a relationship between the two quantizers. The condition for $Q_{\\theta}(x)$ can be rewritten by subtracting $\\theta$ from all parts of the inequality:\n$$(k-\\frac{1}{2})\\Delta < x - \\theta \\le (k+\\frac{1}{2})\\Delta$$\nThis is precisely the condition for applying the zero-offset quantizer $Q_{0}$ to the input $y = x - \\theta$. This leads to the fundamental identity:\n$$Q_{\\theta}(x) = Q_{0}(x - \\theta)$$\n\nThe quantization error for the given system is defined as $e[n] \\triangleq q[n] - x[n]$, where $q[n] = Q_{\\theta}(x[n])$. Using the derived identity, we can express the error as:\n$$e[n] = Q_{0}(x[n] - \\theta) - x[n]$$\nTo relate this to the error of the standard quantizer, we add and subtract $\\theta$:\n$$e[n] = \\left( Q_{0}(x[n] - \\theta) - (x[n] - \\theta) \\right) - \\theta$$\nLet us define $e'[n]$ as the quantization error that would result from applying the standard zero-offset quantizer $Q_{0}$ to a shifted input signal $x[n] - \\theta$:\n$$e'[n] \\triangleq Q_{0}(x[n] - \\theta) - (x[n] - \\theta)$$\nThis allows us to write the error of the offset quantizer in a simple form:\n$$e[n] = e'[n] - \\theta$$\nThe problem states that under the high-resolution approximation, the error $e_{0}[n]$ from a zero-offset quantizer is approximately uniformly distributed on the interval $[-\\frac{\\Delta}{2}, +\\frac{\\Delta}{2}]$. The input to our standard quantizer component is $x[n] - \\theta$. Since $x[n]$ is a stationary process, the shifted process $x[n] - \\theta$ is also stationary and satisfies the conditions for the approximation (e.g., smoothness, no overload). Therefore, the error term $e'[n]$ follows this model. The random variable representing $e'[n]$ is uniformly distributed on $[-\\frac{\\Delta}{2}, +\\frac{\\Delta}{2}]$.\n\nThe probability density function (PDF) of $e'[n]$, denoted $f_{e'}(u)$, is:\n$$f_{e'}(u) = \\begin{cases} \\frac{1}{\\Delta} & \\text{if } u \\in [-\\frac{\\Delta}{2}, +\\frac{\\Delta}{2}] \\\\ 0 & \\text{otherwise} \\end{cases}$$\nThe error of our system, $e[n]$, is simply a shifted version of $e'[n]$. Thus, $e[n]$ is uniformly distributed on the interval $[-\\frac{\\Delta}{2} - \\theta, +\\frac{\\Delta}{2} - \\theta]$.\n\nWe can now compute the required statistical properties.\n\n1.  Mean of the quantization error, $\\mathbb{E}\\{e[n]\\}$:\n    Using the linearity of the expectation operator and the relation $e[n] = e'[n] - \\theta$:\n    $$\\mathbb{E}\\{e[n]\\} = \\mathbb{E}\\{e'[n] - \\theta\\} = \\mathbb{E}\\{e'[n]\\} - \\mathbb{E}\\{\\theta\\}$$\n    The mean of $e'[n]$, which is uniformly distributed on a symmetric interval about zero, is $\\mathbb{E}\\{e'[n]\\} = 0$. The expected value of the constant $\\theta$ is $\\theta$.\n    Therefore, the mean of the error is:\n    $$\\mathbb{E}\\{e[n]\\} = 0 - \\theta = -\\theta$$\n\n2.  Variance of the quantization error, $\\operatorname{Var}\\{e[n]\\}$:\n    The variance of a random variable is not affected by adding a constant.\n    $$\\operatorname{Var}\\{e[n]\\} = \\operatorname{Var}\\{e'[n] - \\theta\\} = \\operatorname{Var}\\{e'[n]\\}$$\n    The variance of a random variable uniformly distributed on an interval $[a, b]$ is given by the formula $\\frac{(b-a)^2}{12}$. For $e'[n]$, the interval is $[-\\frac{\\Delta}{2}, \\frac{\\Delta}{2}]$, so the length is $b-a = \\frac{\\Delta}{2} - (-\\frac{\\Delta}{2}) = \\Delta$.\n    Thus, the variance of the error is:\n    $$\\operatorname{Var}\\{e[n]\\} = \\frac{\\Delta^2}{12}$$\n    Notably, the variance of the error is independent of the offset $\\theta$.\n\n3.  Signal-to-Quantization-Noise Ratio (SQNR):\n    The problem provides an explicit definition for the SQNR in linear scale:\n    $$\\mathrm{SQNR} \\triangleq \\frac{\\sigma_{x}^{2}}{\\operatorname{Var}\\{e[n]\\}}$$\n    where $\\sigma_{x}^{2}$ is the variance of the input signal, and $\\operatorname{Var}\\{e[n]\\}$ is the variance of the quantization error, often termed the quantization noise power. Substituting the expressions for the signal power and the noise power:\n    $$\\mathrm{SQNR} = \\frac{\\sigma_{x}^{2}}{\\frac{\\Delta^2}{12}} = \\frac{12\\sigma_{x}^{2}}{\\Delta^2}$$\n    The SQNR, as defined, is also independent of the offset $\\theta$.\n\nThe three derived quantities are $\\mathbb{E}\\{e[n]\\} = -\\theta$, $\\operatorname{Var}\\{e[n]\\} = \\frac{\\Delta^2}{12}$, and $\\mathrm{SQNR} = \\frac{12\\sigma_{x}^{2}}{\\Delta^2}$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n-\\theta & \\frac{\\Delta^2}{12} & \\frac{12\\sigma_{x}^{2}}{\\Delta^2}\n\\end{pmatrix}\n}\n$$", "id": "2898425"}, {"introduction": "The deterministic biases explored in the previous practice can have significant consequences in multi-stage signal processing systems. This problem examines a practical scenario where a signal undergoes repeated multiplication and truncation—a common operation in fixed-point arithmetic—before being filtered [@problem_id:2898430]. You will trace how the small, negative bias introduced at each truncation step propagates and accumulates through the system, illustrating a critical challenge in the design of high-precision digital filters.", "problem": "A discrete-time signal chain is built to investigate how deterministic bias from truncation after multiplication propagates through a linear filter. The input is a zero-mean, wide-sense stationary process with finite second moments, denoted by $x[n]$ and satisfying $\\mathbb{E}\\{x[n]\\}=0$. The processing chain is as follows.\n\n1) First multiplication and truncation: the signal is multiplied by a real coefficient $c_{1}$ to form $w[n]=c_{1}x[n]$, then passed through a uniform mid-tread truncation quantizer $Q_{\\Delta_{1}}$ of step size $\\Delta_{1}$ defined by\n$$\nQ_{\\Delta}(u) \\triangleq \\Delta \\left\\lfloor \\frac{u}{\\Delta} \\right\\rfloor,\n$$\nso that the truncated signal is $w_{t}[n]=Q_{\\Delta_{1}}(w[n])$ and the truncation error is $e_{1}[n]=w_{t}[n]-w[n]$.\n\n2) Second multiplication and truncation: the signal is then multiplied by a real coefficient $c_{2}$ to form $v[n]=c_{2}w_{t}[n]$, and passed through a second uniform truncation quantizer $Q_{\\Delta_{2}}$ with step size $\\Delta_{2}$, yielding $v_{t}[n]=Q_{\\Delta_{2}}(v[n])$ and truncation error $e_{2}[n]=v_{t}[n]-v[n]$.\n\n3) Linear time-invariant filtering: finally, $v_{t}[n]$ is processed by a length-$3$ finite impulse response filter (a Linear Time-Invariant (LTI) system) with impulse response coefficients $h[0],h[1],h[2]$, giving the output\n$$\ny[n] \\triangleq \\sum_{k=0}^{2} h[k]\\, v_{t}[n-k].\n$$\n\nAssume that no saturation occurs. Assume further that, due to either high-resolution modeling or the use of independent subtractive dither, each truncation error $e_{i}[n]$ is statistically independent of its input and is uniformly distributed on the interval $[-\\Delta_{i},0)$ for $i\\in\\{1,2\\}$, for all $n$.\n\nGiven the numerical values $c_{1}=0.9$, $c_{2}=1.1$, $\\Delta_{1}=2^{-12}$, $\\Delta_{2}=2^{-10}$, and $h[0]=0.8$, $h[1]=0.7$, $h[2]=0.5$, determine the exact steady-state output mean $\\mathbb{E}\\{y[n]\\}$.\n\nProvide your final answer as a single exact rational number in simplest terms. Do not round. Do not include units.", "solution": "The objective is to determine the exact steady-state mean of the output signal, $\\mathbb{E}\\{y[n]\\}$. The output $y[n]$ is the result of applying a finite impulse response (FIR) filter to the signal $v_t[n]$. The relationship is given by the convolution sum:\n$$\ny[n] = \\sum_{k=0}^{2} h[k]\\, v_{t}[n-k].\n$$\nDue to the linearity of the expectation operator, we can write the mean of the output as:\n$$\n\\mathbb{E}\\{y[n]\\} = \\mathbb{E}\\left\\{\\sum_{k=0}^{2} h[k]\\, v_{t}[n-k]\\right\\} = \\sum_{k=0}^{2} h[k]\\, \\mathbb{E}\\{v_{t}[n-k]\\}.\n$$\nThe signal chain leading to $v_t[n]$ involves operations on a wide-sense stationary input $x[n]$, and the quantization error models are assumed to be stationary processes. This implies that the mean of $v_t[n]$ is constant over time, i.e., $\\mathbb{E}\\{v_t[n-k]\\} = \\mathbb{E}\\{v_t[n]\\} = \\mu_{v_t}$ for all integers $n$ and $k$. Thus, the expression for the output mean simplifies to:\n$$\n\\mathbb{E}\\{y[n]\\} = \\mu_{v_t} \\sum_{k=0}^{2} h[k].\n$$\nOur task reduces to finding the mean $\\mu_{v_t}$ and the sum of the filter coefficients.\n\nWe trace the signal path to determine $\\mu_{v_t}$. The signal $v_t[n]$ is the output of the second quantizer, and it is related to its input $v[n]$ by the additive error model:\n$$\nv_t[n] = v[n] + e_2[n].\n$$\nTaking the expectation gives:\n$$\n\\mu_{v_t} = \\mathbb{E}\\{v_t[n]\\} = \\mathbb{E}\\{v[n]\\} + \\mathbb{E}\\{e_2[n]\\}.\n$$\nThe problem states that the truncation error $e_2[n]$ is uniformly distributed on the interval $[-\\Delta_2, 0)$. The mean of a uniform random variable on an interval $[a, b]$ is $\\frac{a+b}{2}$. Therefore, the mean of the second error is:\n$$\n\\mathbb{E}\\{e_2[n]\\} = \\frac{-\\Delta_2 + 0}{2} = -\\frac{\\Delta_2}{2}.\n$$\nNext, we find the mean of $v[n]$. This signal is generated by scaling $w_t[n]$ by the coefficient $c_2$:\n$$\nv[n] = c_2 w_t[n].\n$$\nIts mean is:\n$$\n\\mathbb{E}\\{v[n]\\} = \\mathbb{E}\\{c_2 w_t[n]\\} = c_2 \\mathbb{E}\\{w_t[n]\\}.\n$$\nSimilarly, $w_t[n]$ is the output of the first quantizer:\n$$\nw_t[n] = w[n] + e_1[n],\n$$\nwhere $w[n] = c_1 x[n]$. The mean of $w_t[n]$ is:\n$$\n\\mathbb{E}\\{w_t[n]\\} = \\mathbb{E}\\{w[n]\\} + \\mathbb{E}\\{e_1[n]\\} = \\mathbb{E}\\{c_1 x[n]\\} + \\mathbb{E}\\{e_1[n]\\}.\n$$\nThe input signal $x[n]$ is a zero-mean process, so $\\mathbb{E}\\{x[n]\\} = 0$. This implies $\\mathbb{E}\\{c_1 x[n]\\} = c_1 \\mathbb{E}\\{x[n]\\} = c_1 \\cdot 0 = 0$.\nThe first truncation error $e_1[n]$ is uniformly distributed on $[-\\Delta_1, 0)$. Its mean is:\n$$\n\\mathbb{E}\\{e_1[n]\\} = \\frac{-\\Delta_1 + 0}{2} = -\\frac{\\Delta_1}{2}.\n$$\nTherefore, the mean of $w_t[n]$ is:\n$$\n\\mathbb{E}\\{w_t[n]\\} = 0 + \\left(-\\frac{\\Delta_1}{2}\\right) = -\\frac{\\Delta_1}{2}.\n$$\nSubstituting this back, we find the mean of $v[n]$:\n$$\n\\mathbb{E}\\{v[n]\\} = c_2 \\left(-\\frac{\\Delta_1}{2}\\right) = -\\frac{c_2\\Delta_1}{2}.\n$$\nNow we can compute the mean of $v_t[n]$:\n$$\n\\mu_{v_t} = \\mathbb{E}\\{v[n]\\} + \\mathbb{E}\\{e_2[n]\\} = -\\frac{c_2\\Delta_1}{2} - \\frac{\\Delta_2}{2} = -\\frac{1}{2}(c_2\\Delta_1 + \\Delta_2).\n$$\nFinally, we compute the output mean $\\mathbb{E}\\{y[n]\\}$ by multiplying $\\mu_{v_t}$ with the sum of the filter impulse response coefficients, which represents the DC gain of the filter:\n$$\n\\sum_{k=0}^{2} h[k] = h[0] + h[1] + h[2].\n$$\n$$\n\\mathbb{E}\\{y[n]\\} = \\left( -\\frac{1}{2}(c_2\\Delta_1 + \\Delta_2) \\right) \\left( h[0] + h[1] + h[2] \\right).\n$$\nWe substitute the given numerical values: $c_1=0.9$, $c_2=1.1$, $\\Delta_{1}=2^{-12}$, $\\Delta_{2}=2^{-10}$, and $h[0]=0.8$, $h[1]=0.7$, $h[2]=0.5$. Writing these as rational numbers gives $c_2 = \\frac{11}{10}$, $\\Delta_1 = \\frac{1}{4096}$, $\\Delta_2 = \\frac{1}{1024}$, $h[0]=\\frac{8}{10}$, $h[1]=\\frac{7}{10}$, $h[2]=\\frac{5}{10}$.\n\nFirst, calculate the sum of the filter coefficients:\n$$\n\\sum_{k=0}^{2} h[k] = 0.8 + 0.7 + 0.5 = 2.0.\n$$\nNow, substitute this into the expression for the mean:\n$$\n\\mathbb{E}\\{y[n]\\} = \\left( -\\frac{1}{2}(c_2\\Delta_1 + \\Delta_2) \\right) \\cdot 2 = -(c_2\\Delta_1 + \\Delta_2).\n$$\nWe compute the term in parentheses using rational arithmetic to maintain precision:\n$$\nc_2\\Delta_1 + \\Delta_2 = \\frac{11}{10} \\cdot \\frac{1}{4096} + \\frac{1}{1024} = \\frac{11}{40960} + \\frac{1}{1024}.\n$$\nTo add these fractions, we find a common denominator, which is $40960$:\n$$\n\\frac{1}{1024} = \\frac{40}{40 \\cdot 1024} = \\frac{40}{40960}.\n$$\nSo, the sum is:\n$$\nc_2\\Delta_1 + \\Delta_2 = \\frac{11}{40960} + \\frac{40}{40960} = \\frac{51}{40960}.\n$$\nTherefore, the exact steady-state output mean is:\n$$\n\\mathbb{E}\\{y[n]\\} = -\\frac{51}{40960}.\n$$\nThis fraction is in simplest terms because the prime factors of the numerator are $51 = 3 \\times 17$, and the prime factors of the denominator are $40960 = 4096 \\times 10 = 2^{12} \\times 2 \\times 5 = 2^{13} \\times 5$. There are no common prime factors.", "answer": "$$\n\\boxed{-\\frac{51}{40960}}\n$$", "id": "2898430"}]}