{"hands_on_practices": [{"introduction": "Any complex LTI system described by a proper rational transfer function can be broken down into a parallel connection of simpler subsystems. This practice explores this fundamental principle of parallel decomposition, focusing on the important case of systems with repeated poles. By performing a partial fraction expansion on a transfer function with a third-order pole, you will not only calculate the coefficients of the parallel branches but also gain insight into how higher-order terms translate into a specific block diagram structure [@problem_id:2856865].", "problem": "A linear time-invariant (LTI) single-input single-output system with transfer function in the Laplace domain is defined by the rational function $H(s)$. A parallel form structure represents $H(s)$ as a sum of subsystem transfer functions connected in parallel, and when the poles are repeated, the partial fraction expansion includes higher-order terms associated with those repeated poles. Consider the transfer function\n$$\nH(s) = \\frac{2s+3}{(s+1)^{3}}.\n$$\nStarting from the foundational definitions of the Laplace transform, the definition of a transfer function as $H(s)=Y(s)/X(s)$, and the principle that any proper rational transfer function can be expressed as a sum of simpler rational functions through partial fraction expansion, perform the following:\n- Derive the partial fraction expansion of $H(s)$ that explicitly accounts for the repeated pole at $s=-1$ up to its multiplicity.\n- Justify how each term in this expansion corresponds to a branch in a parallel form realization built from first-order building blocks, and explain the role of repeated poles in this mapping based on first principles of LTI system decomposition.\n\nYour final answer must be the explicit partial fraction expansion of $H(s)$ expressed as a single closed-form analytic expression. No numerical rounding is required. Do not include units.", "solution": "The problem presented is a standard exercise in the analysis of linear time-invariant (LTI) systems and is found to be valid. It is scientifically grounded, well-posed, objective, and contains no logical or factual flaws. We may therefore proceed with a rigorous solution.\n\nThe core principle is the decomposition of a complex system into a set of simpler subsystems. For an LTI system described by a proper rational transfer function $H(s)$, this decomposition is realized through partial fraction expansion. The resulting structure, where the total output is the sum of the outputs of subsystems driven by the same input, is known as a parallel form realization. The transfer function is given as\n$$\nH(s) = \\frac{2s+3}{(s+1)^{3}}\n$$\nThis function has a single pole at $s = -1$ with multiplicity $m=3$. For a pole at $s=p$ with multiplicity $m$, the partial fraction expansion must include terms for all powers of $(s-p)^{-k}$ from $k=1$ to $k=m$. Therefore, the expansion for the given $H(s)$ must take the form:\n$$\nH(s) = \\frac{A_1}{s+1} + \\frac{A_2}{(s+1)^2} + \\frac{A_3}{(s+1)^3}\n$$\nThe coefficients $A_k$ for a repeated pole at $s=p$ of multiplicity $m$ are determined by the general formula:\n$$\nA_{m-k} = \\frac{1}{k!} \\frac{d^k}{ds^k} \\left[ (s-p)^m H(s) \\right] \\bigg|_{s=p}\n$$\nIn this specific problem, $p=-1$ and $m=3$. Let us define the function $\\Phi(s)$ as:\n$$\n\\Phi(s) = (s+1)^3 H(s) = (s+1)^3 \\left( \\frac{2s+3}{(s+1)^3} \\right) = 2s+3\n$$\nWe can now calculate the coefficients $A_3$, $A_2$, and $A_1$.\n\nFor $A_3$, we set $k=m-3=0$:\n$$\nA_3 = A_{3-0} = \\frac{1}{0!} \\frac{d^0}{ds^0} [\\Phi(s)] \\bigg|_{s=-1} = \\Phi(s) \\bigg|_{s=-1} = (2s+3) \\bigg|_{s=-1} = 2(-1) + 3 = 1\n$$\nFor $A_2$, we set $k=m-2=1$:\n$$\nA_2 = A_{3-1} = \\frac{1}{1!} \\frac{d}{ds} [\\Phi(s)] \\bigg|_{s=-1} = \\frac{d}{ds} (2s+3) \\bigg|_{s=-1} = 2 \\bigg|_{s=-1} = 2\n$$\nFor $A_1$, we set $k=m-1=2$:\n$$\nA_1 = A_{3-2} = \\frac{1}{2!} \\frac{d^2}{ds^2} [\\Phi(s)] \\bigg|_{s=-1} = \\frac{1}{2} \\frac{d^2}{ds^2} (2s+3) \\bigg|_{s=-1} = \\frac{1}{2} \\frac{d}{ds}(2) \\bigg|_{s=-1} = \\frac{1}{2}(0) = 0\n$$\nSubstituting these coefficients back into the expansion gives the complete partial fraction form for $H(s)$:\n$$\nH(s) = \\frac{0}{s+1} + \\frac{2}{(s+1)^2} + \\frac{1}{(s+1)^3}\n$$\nThis expression is the explicit expansion that accounts for the repeated pole up to its full multiplicity of $3$.\n\nNow, we justify the parallel form realization based on first principles. The transfer function $H(s)$ relates the Laplace-transformed output $Y(s)$ to the input $X(s)$ via the relation $Y(s) = H(s)X(s)$. Using our derived expansion:\n$$\nY(s) = \\left( \\frac{0}{s+1} + \\frac{2}{(s+1)^2} + \\frac{1}{(s+1)^3} \\right) X(s)\n$$\nBy the property of linearity, this is equivalent to:\n$$\nY(s) = \\left(\\frac{0}{s+1}\\right)X(s) + \\left(\\frac{2}{(s+1)^2}\\right)X(s) + \\left(\\frac{1}{(s+1)^3}\\right)X(s)\n$$\nLet us define the subsystem transfer functions $H_1(s)$, $H_2(s)$, and $H_3(s)$ as the individual terms in the expansion:\n$$\nH_1(s) = \\frac{0}{s+1}, \\quad H_2(s) = \\frac{2}{(s+1)^2}, \\quad H_3(s) = \\frac{1}{(s+1)^3}\n$$\nThe total system transfer function is the sum $H(s) = H_1(s) + H_2(s) + H_3(s)$. Correspondingly, the output is the sum of the outputs from each subsystem when driven by the common input $X(s)$:\n$$\nY(s) = Y_1(s) + Y_2(s) + Y_3(s), \\quad \\text{where } Y_k(s) = H_k(s)X(s)\n$$\nThis structure, where a single input drives multiple subsystems and their outputs are summed, is precisely the definition of a parallel form realization.\n\nThe role of the repeated pole is critical in defining the nature of these parallel branches.\n- For a simple, non-repeated pole at $s=p$, the corresponding branch is a first-order system with transfer function $\\frac{A}{s-p}$.\n- For a repeated pole, terms of the form $\\frac{A}{(s-p)^k}$ with $k1$ appear. A subsystem with transfer function $H_k(s) = \\frac{1}{(s-p)^k}$ is not a first-order system. Instead, it is equivalent to a cascade of $k$ identical first-order systems, each having the transfer function $\\frac{1}{s-p}$. This is evident from the relationship:\n$$\n\\frac{1}{(s-p)^k} = \\left(\\frac{1}{s-p}\\right) \\times \\left(\\frac{1}{s-p}\\right) \\times \\cdots \\times \\left(\\frac{1}{s-p}\\right) \\quad (k \\text{ times})\n$$\nIn our case, the parallel branches are:\n1. $H_1(s) = \\frac{0}{s+1}$: A first-order system with zero gain, contributing nothing to the output.\n2. $H_2(s) = \\frac{2}{(s+1)^2}$: A subsystem equivalent to a cascade of two first-order building blocks $\\frac{1}{s+1}$, followed by a gain of $2$.\n3. $H_3(s) = \\frac{1}{(s+1)^3}$: A subsystem equivalent to a cascade of three first-order building blocks $\\frac{1}{s+1}$.\n\nThus, the presence of a repeated pole of multiplicity $m$ necessitates the inclusion of $m$ parallel branches, where each branch $k$ (for $k=1, \\dots, m$) is itself a cascade of $k$ basic first-order integrators associated with that pole location, scaled by the coefficient $A_k$. This demonstrates how the algebraic structure of the partial fraction expansion for repeated poles maps directly to a physical or block-diagram realization consisting of parallel combinations of cascaded first-order elements.", "answer": "$$\n\\boxed{\\frac{0}{s+1} + \\frac{2}{(s+1)^{2}} + \\frac{1}{(s+1)^{3}}}\n$$", "id": "2856865"}, {"introduction": "While parallel forms are elegant, cascade structures are often preferred for implementing high-order filters due to their superior numerical properties. This hands-on practice delves into a critical real-world challenge in fixed-point digital filter design: managing the internal signal dynamic range to prevent overflow. You will design power-of-two scaling factors for a cascade of second-order sections (biquads) to ensure that all internal signals remain within the system's representational limits, a technique known as $L_{\\infty}$-norm scaling [@problem_id:2856870].", "problem": "Consider a discrete-time linear time-invariant (LTI) digital filter implemented as a cascade of three second-order sections (biquads) in Direct Form II Transposed. Let the input signal be bounded in amplitude by $|x[n]| \\leq X_{\\max}$ with $X_{\\max} = 0.2$ in normalized full-scale units, where full-scale saturation occurs at magnitude $1$. For each biquad $k \\in \\{1,2,3\\}$, you are given two induced $\\ell_{\\infty}$-norms (also known as the $H_{\\infty}$ norm): \n- $\\,\\beta_k\\,$, the worst-case input-to-output gain bound for the section,\n- $\\,\\alpha_k\\,$, the worst-case input-to-largest-internal-state gain bound for the section,\nso that for any bounded input amplitude $U$, the section output amplitude is bounded by $\\beta_k U$, and the largest internal state magnitude inside the section is bounded by $\\alpha_k U$.\n\nThe sections have the following parameters:\n- Section $1$: $\\alpha_1 = 2.7$, $\\beta_1 = 1.6$,\n- Section $2$: $\\alpha_2 = 1.8$, $\\beta_2 = 1.2$,\n- Section $3$: $\\alpha_3 = 3.0$, $\\beta_3 = 0.9$.\n\nYou are allowed to insert, around each section $k$, a symmetric power-of-two scaling of the form: a pre-scale factor $c_k = 2^{m_k}$ ($m_k \\in \\mathbb{Z}$) at the section input and a post-scale factor $1/c_k$ at the section output. This preserves the overall end-to-end transfer function magnitude but changes the internal state magnitudes within the section. The wordlength is such that any internal node (including all interstage junctions and internal states) must remain strictly below full-scale magnitude $1$ to avoid overflow.\n\nDesign the per-section scaling factors $c_k$ to prevent overflow at all internal nodes. Then, under your design, determine the maximum worst-case magnitude attained by any internal node in the entire cascade (including interstage junctions and internal states), assuming the input bound $|x[n]| \\leq 0.2$. Round your final answer to four significant figures and express it in normalized full-scale units (no unit symbol).", "solution": "The problem statement has been validated and is deemed scientifically grounded, well-posed, and objective. It is a standard problem in the analysis of fixed-point digital filter implementations. We shall proceed with the solution.\n\nLet the discrete-time LTI system be a cascade of $N=3$ second-order sections. Let $u_k[n]$ be the input to the $k$-th scaled section for $k \\in \\{1, 2, 3\\}$, and let $y_k[n]$ be its output. The input to the entire filter is $x[n]$, so $u_1[n] = x[n]$. The sections are in cascade, so $u_{k+1}[n] = y_k[n]$. The input signal is bounded by $|x[n]| \\le X_{\\max}$, where $X_{\\max} = 0.2$. Let $U_k$ be the worst-case amplitude (the $\\ell_{\\infty}$-norm of the signal) at the input to the $k$-th scaled section, $U_k = \\sup_{n} |u_k[n]|$. Thus, $U_1 = X_{\\max} = 0.2$.\n\nWithin each scaled section $k$, the input signal $u_k[n]$ is first multiplied by a scaling factor $c_k = 2^{m_k}$ where $m_k \\in \\mathbb{Z}$. The input to the biquad itself is therefore $c_k u_k[n]$. The problem provides two gain parameters for each biquad:\n1. $\\alpha_k$: the worst-case gain from the biquad's input to its largest internal state magnitude.\n2. $\\beta_k$: the worst-case gain from the biquad's input to its output.\n\nThe worst-case magnitude of the internal states in biquad $k$, denoted $S_k$, is bounded by the amplitude of the biquad's input multiplied by $\\alpha_k$.\n$$\nS_k = \\alpha_k \\sup_{n} |c_k u_k[n]| = \\alpha_k c_k U_k\n$$\nThe worst-case magnitude of the biquad's output is $\\beta_k c_k U_k$. This signal is then scaled by $1/c_k$ to produce the output of the scaled section, $y_k[n]$. The worst-case amplitude of $y_k[n]$ is therefore:\n$$\nU_{k+1} = \\sup_{n} |y_k[n]| = \\frac{1}{c_k} (\\beta_k c_k U_k) = \\beta_k U_k\n$$\nThis establishes a recurrence relation for the worst-case amplitudes at the interstage junctions. Using the given values $\\beta_1 = 1.6$, $\\beta_2 = 1.2$, and $\\beta_3 = 0.9$:\n$$\nU_1 = X_{\\max} = 0.2\n$$\n$$\nU_2 = \\beta_1 U_1 = 1.6 \\times 0.2 = 0.32\n$$\n$$\nU_3 = \\beta_2 U_2 = 1.2 \\times 0.32 = 0.384\n$$\n$$\nU_4 = \\beta_3 U_3 = 0.9 \\times 0.384 = 0.3456\n$$\n$U_4$ is the worst-case amplitude of the final output signal. The internal nodes of the filter consist of the internal states within each biquad and the interstage junctions. To prevent overflow, the magnitude at every internal node must be strictly less than $1$.\n\nThe constraints are:\n1. For internal states: $S_k  1 \\implies \\alpha_k c_k U_k  1$ for $k \\in \\{1, 2, 3\\}$.\n2. For interstage junctions: $U_k  1$ for $k \\in \\{2, 3, 4\\}$.\n\nThe interstage junction magnitudes are $U_2=0.32$, $U_3=0.384$, and $U_4=0.3456$. All are less than $1$, so these nodes are safe from overflow regardless of scaling.\n\nWe must choose the scaling factors $c_k$ to satisfy the internal state constraints. The optimal choice for each $c_k$ is the largest power of two that satisfies the inequality, as this maximizes the use of the available dynamic range. The constraint for each $c_k$ is:\n$$\nc_k  \\frac{1}{\\alpha_k U_k}\n$$\n\nFor section $k=1$:\nGiven $\\alpha_1 = 2.7$.\n$$\nc_1  \\frac{1}{\\alpha_1 U_1} = \\frac{1}{2.7 \\times 0.2} = \\frac{1}{0.54} \\approx 1.85185\n$$\nThe largest power of two, $2^{m_1}$, less than $1.85185$ is $2^0 = 1$. So, we choose $c_1 = 1$.\n\nFor section $k=2$:\nGiven $\\alpha_2 = 1.8$.\n$$\nc_2  \\frac{1}{\\alpha_2 U_2} = \\frac{1}{1.8 \\times 0.32} = \\frac{1}{0.576} \\approx 1.73611\n$$\nThe largest power of two, $2^{m_2}$, less than $1.73611$ is $2^0 = 1$. So, we choose $c_2 = 1$.\n\nFor section $k=3$:\nGiven $\\alpha_3 = 3.0$.\n$$\nc_3  \\frac{1}{\\alpha_3 U_3} = \\frac{1}{3.0 \\times 0.384} = \\frac{1}{1.152} \\approx 0.86805\n$$\nThe largest power of two, $2^{m_3}$, less than $0.86805$ is $2^{-1} = 0.5$. So, we choose $c_3 = 0.5$.\n\nWith the scaling factors $c_1 = 1$, $c_2 = 1$, and $c_3 = 0.5$, we now determine the maximum worst-case magnitude across all internal nodes. We must evaluate all $S_k$ and $U_k$ (for $k1$).\nThe worst-case magnitudes are:\n- Internal states of section $1$: $S_1 = \\alpha_1 c_1 U_1 = 2.7 \\times 1 \\times 0.2 = 0.54$.\n- Interstage junction after section $1$: $U_2 = 0.32$.\n- Internal states of section $2$: $S_2 = \\alpha_2 c_2 U_2 = 1.8 \\times 1 \\times 0.32 = 0.576$.\n- Interstage junction after section $2$: $U_3 = 0.384$.\n- Internal states of section $3$: $S_3 = \\alpha_3 c_3 U_3 = 3.0 \\times 0.5 \\times 0.384 = 1.5 \\times 0.384 = 0.576$.\n- Final output node: $U_4 = 0.3456$.\n\nWe must find the maximum of these values:\n$$\n\\max\\{S_1, U_2, S_2, U_3, S_3, U_4\\} = \\max\\{0.54, 0.32, 0.576, 0.384, 0.576, 0.3456\\} = 0.576\n$$\nThe maximum worst-case magnitude attained by any internal node is $0.576$. The problem requires rounding the final answer to four significant figures, which gives $0.5760$.", "answer": "$$\n\\boxed{0.5760}\n$$", "id": "2856870"}, {"introduction": "Beyond scaling, the performance of a cascade filter is highly dependent on how poles and zeros are paired to form the individual biquad sections and how these sections are ordered. This exercise transforms the heuristic of 'pairing nearby poles and zeros' into a rigorous computational task, demonstrating how design decisions can be framed as formal optimization problems. By implementing a defined cost function and using an assignment algorithm, you will find the optimal pole-zero pairing that minimizes a proxy for numerical sensitivity, a key step in robust IIR filter implementation [@problem_id:2856941].", "problem": "You are given a discrete-time, stable, rational transfer function in terms of its zeros and poles, to be implemented as a cascade of second-order sections (biquads). The input to your program will be a small set of self-contained test cases, each providing the complex zeros and poles already grouped into pairs, where each pair is either a complex-conjugate pair or a real-valued pair. Your task is to compute, for each test case, an optimal pairing that assigns each pole pair to one zero pair to form a biquad, in order to minimize a global cost that proxies sensitivity or dynamic-range stress. Angles must be treated in radians.\n\nFundamental basis: A rational transfer function can be written as\n$$\nH(z) \\;=\\; k \\,\\frac{\\prod_{m=1}^{M} \\left(1 - z_m z^{-1}\\right)}{\\prod_{n=1}^{N} \\left(1 - p_n z^{-1}\\right)} \\,,\n$$\nwhere $k$ is a constant gain, $\\{z_m\\}$ are zeros, and $\\{p_n\\}$ are poles. When implementing $H(z)$ as a cascade of biquads, the zeros and poles are partitioned into pairs, and each second-order section has numerator and denominator given by two zeros and two poles respectively. It is well tested in fixed-point implementations that pairing a pole pair with a nearby zero pair in the complex $z$-plane reduces peak section gain and sensitivity to coefficient perturbations. Your objective is to formalize this pairing as a combinatorial optimization problem.\n\nDefine the following cost for pairing a single pole pair $P_i = \\left(p_{i1}, p_{i2}\\right)$ to a single zero pair $Z_j = \\left(z_{j1}, z_{j2}\\right)$:\n- For any complex numbers $a$ and $b$ with polar representations $a = r_a e^{\\mathrm{j}\\theta_a}$ and $b = r_b e^{\\mathrm{j}\\theta_b}$, define the wrapped angle difference\n$$\n\\Delta\\theta(a,b) \\;=\\; \\mathrm{wrap}_{[-\\pi,\\pi)}\\!\\left(\\theta_a - \\theta_b\\right)\\,,\n$$\nwhere $\\mathrm{wrap}_{[-\\pi,\\pi)}(\\cdot)$ wraps an angle to the interval $[-\\pi,\\pi)$, and if $r_a = 0$ or $r_b = 0$, take $\\Delta\\theta(a,b) = 0$.\n- Define the pairwise point cost\n$$\nd(a,b) \\;=\\; |a - b|^2 \\;+\\; \\lambda \\left(|\\,|a| - |b|\\,|\\right)^2 \\;+\\; \\mu \\left(\\Delta\\theta(a,b)\\right)^2 \\,,\n$$\nwith constants $\\lambda = 1$ and $\\mu = 0.25$.\n- Define the pole-pair to zero-pair cost\n$$\nc\\!\\left(P_i, Z_j\\right) \\;=\\; \\min\\!\\Big\\{\\, d\\!\\left(p_{i1}, z_{j1}\\right) + d\\!\\left(p_{i2}, z_{j2}\\right),\\; d\\!\\left(p_{i1}, z_{j2}\\right) + d\\!\\left(p_{i2}, z_{j1}\\right) \\,\\Big\\}.\n$$\n\nGiven $N$ pole pairs $\\{P_i\\}_{i=0}^{N-1}$ and $N$ zero pairs $\\{Z_j\\}_{j=0}^{N-1}$, find the assignment $\\pi$ over the $N!$ permutations that minimizes the total cost\n$$\nJ(\\pi) \\;=\\; \\sum_{i=0}^{N-1} c\\!\\left(P_i, Z_{\\pi(i)}\\right).\n$$\nReturn, for each test case, the list $[\\pi(0), \\pi(1), \\ldots, \\pi(N-1)]$ of zero-based indices corresponding to the chosen zero-pair index for each pole pair, in the given input order of pole pairs.\n\nAngle unit: radians. There are no physical units to report. Your program must use the exact cost definition above.\n\nTest suite:\n- Test Case A (complex pairs with similar angles):\n  - Poles as two conjugate pairs:\n    - $P_0 = \\big\\{ 0.9 e^{\\mathrm{j}\\pi \\cdot 0.3},\\; 0.9 e^{-\\mathrm{j}\\pi \\cdot 0.3} \\big\\}$,\n    - $P_1 = \\big\\{ 0.88 e^{\\mathrm{j}\\pi \\cdot 0.6},\\; 0.88 e^{-\\mathrm{j}\\pi \\cdot 0.6} \\big\\}$.\n  - Zeros as two conjugate pairs:\n    - $Z_0 = \\big\\{ 0.95 e^{\\mathrm{j}\\pi \\cdot 0.32},\\; 0.95 e^{-\\mathrm{j}\\pi \\cdot 0.32} \\big\\}$,\n    - $Z_1 = \\big\\{ 0.90 e^{\\mathrm{j}\\pi \\cdot 0.58},\\; 0.90 e^{-\\mathrm{j}\\pi \\cdot 0.58} \\big\\}$.\n\n- Test Case B (one complex pair and one real pair):\n  - Poles:\n    - $P_0 = \\big\\{ 0.85 + \\mathrm{j}\\,0.05,\\; 0.85 - \\mathrm{j}\\,0.05 \\big\\}$,\n    - $P_1 = \\big\\{ -0.70,\\; -0.60 \\big\\}$.\n  - Zeros:\n    - $Z_0 = \\big\\{ 0.90 + \\mathrm{j}\\,0.02,\\; 0.90 - \\mathrm{j}\\,0.02 \\big\\}$,\n    - $Z_1 = \\big\\{ -0.65,\\; -0.75 \\big\\}$.\n\n- Test Case C (dynamic-range-oriented pairing with zeros at the origin):\n  - Poles:\n    - $P_0 = \\big\\{ 0.95 e^{\\mathrm{j}\\pi \\cdot 0.20},\\; 0.95 e^{-\\mathrm{j}\\pi \\cdot 0.20} \\big\\}$,\n    - $P_1 = \\big\\{ 0.30 e^{\\mathrm{j}\\pi \\cdot 0.40},\\; 0.30 e^{-\\mathrm{j}\\pi \\cdot 0.40} \\big\\}$.\n  - Zeros:\n    - $Z_0 = \\big\\{ 0,\\; 0 \\big\\}$,\n    - $Z_1 = \\big\\{ 0.98 e^{\\mathrm{j}\\pi \\cdot 0.22},\\; 0.98 e^{-\\mathrm{j}\\pi \\cdot 0.22} \\big\\}$.\n\n- Test Case D (cross-pairing preference due to angle proximity):\n  - Poles:\n    - $P_0 = \\big\\{ 0.92 e^{\\mathrm{j}\\pi \\cdot 0.75},\\; 0.92 e^{-\\mathrm{j}\\pi \\cdot 0.75} \\big\\}$,\n    - $P_1 = \\big\\{ 0.92 e^{\\mathrm{j}\\pi \\cdot 0.25},\\; 0.92 e^{-\\mathrm{j}\\pi \\cdot 0.25} \\big\\}$.\n  - Zeros:\n    - $Z_0 = \\big\\{ 0.93 e^{\\mathrm{j}\\pi \\cdot 0.26},\\; 0.93 e^{-\\mathrm{j}\\pi \\cdot 0.26} \\big\\}$,\n    - $Z_1 = \\big\\{ 0.93 e^{\\mathrm{j}\\pi \\cdot 0.74},\\; 0.93 e^{-\\mathrm{j}\\pi \\cdot 0.74} \\big\\}$.\n\nRequirements:\n- Implement the exact cost function $d(\\cdot,\\cdot)$, $c(\\cdot,\\cdot)$, and the total assignment objective $J(\\pi)$ as given.\n- Use an optimal assignment method to minimize $J(\\pi)$ over all permutations.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes one list of integers $[\\pi(0),\\ldots,\\pi(N-1)]$. For the four test cases above, the final format must be\n\"[ [mapping for Test Case A], [mapping for Test Case B], [mapping for Test Case C], [mapping for Test Case D] ]\" with no spaces outside the outermost brackets. For example, a valid output with two test cases would look like \"[[0,1],[1,0]]\". For this problem with four test cases, your program must output something like \"[[...],[...],[...],[...]]\" where each \"...\" is a comma-separated list of integers.", "solution": "The problem presented is a well-defined exercise in digital signal processing, specifically concerning the implementation of infinite impulse response (IIR) filters. The task is to find an optimal pairing of poles and zeros to form second-order sections (biquads) in a cascade structure. This optimization is crucial for minimizing numerical errors and maintaining a good dynamic range in fixed-point arithmetic implementations. The problem is scientifically sound and can be formalized as a classic optimization problem.\n\nThe problem is to find a permutation $\\pi$ of the indices $\\{0, 1, \\ldots, N-1\\}$ that minimizes the total cost function:\n$$\nJ(\\pi) \\;=\\; \\sum_{i=0}^{N-1} c\\!\\left(P_i, Z_{\\pi(i)}\\right)\n$$\nwhere $\\{P_i\\}_{i=0}^{N-1}$ are the given pole pairs and $\\{Z_j\\}_{j=0}^{N-1}$ are the zero pairs. This is known as the **linear assignment problem**, or minimum weight perfect matching in a bipartite graph. The problem can be solved by first constructing a cost matrix and then applying a suitable optimization algorithm.\n\nThe procedure is as follows:\n\n1.  **Construct the Cost Matrix**: An $N \\times N$ cost matrix, let us call it $\\mathbf{C}$, is constructed. The element $C_{ij}$ of this matrix represents the cost of pairing the $i$-th pole pair, $P_i$, with the $j$-th zero pair, $Z_j$. This cost is defined as $c(P_i, Z_j)$.\n\n2.  **Calculate Individual Pairing Costs**: The cost $c(P_i, Z_j)$ for a pole pair $P_i = (p_{i1}, p_{i2})$ and a zero pair $Z_j = (z_{j1}, z_{j2})$ is given by:\n    $$\n    c(P_i, Z_j) \\;=\\; \\min\\Big\\{ d(p_{i1}, z_{j1}) + d(p_{i2}, z_{j2}), \\; d(p_{i1}, z_{j2}) + d(p_{i2}, z_{j1}) \\Big\\}\n    $$\n    This formulation considers the two possible ways to pair the individual poles with the individual zeros within their respective pairs and selects the one with the minimum cost.\n\n3.  **Calculate Point-to-Point Distance**: The function $d(a,b)$ serves as a metric of \"distance\" or \"dissimilarity\" between two points $a$ and $b$ in the complex $z$-plane. It is defined as:\n    $$\n    d(a,b) \\;=\\; |a - b|^2 \\;+\\; \\lambda \\left(|\\,|a| - |b|\\,|\\right)^2 \\;+\\; \\mu \\left(\\Delta\\theta(a,b)\\right)^2\n    $$\n    with the given constants $\\lambda = 1$ and $\\mu = 0.25$. This cost function is a weighted sum of three components:\n    -   The squared Euclidean distance $|a - b|^2$.\n    -   The squared difference of their magnitudes $(|\\,|a| - |b|\\,|)^2$, weighted by $\\lambda$.\n    -   The squared wrapped angle difference $(\\Delta\\theta(a,b))^2$, weighted by $\\mu$.\n\n    The wrapped angle difference, $\\Delta\\theta(a,b)$, for two complex numbers $a = r_a e^{\\mathrm{j}\\theta_a}$ and $b = r_b e^{\\mathrm{j}\\theta_b}$, is defined as:\n    $$\n    \\Delta\\theta(a,b) \\;=\\; \\mathrm{wrap}_{[-\\pi,\\pi)}\\!\\left(\\theta_a - \\theta_b\\right)\n    $$\n    The function $\\mathrm{wrap}_{[-\\pi,\\pi)}(\\phi)$ maps an angle $\\phi$ to the interval $[-\\pi, \\pi)$. By definition, if either $a$ or $b$ is at the origin (magnitude zero), their angle difference is taken to be $0$.\n\n4.  **Solve the Assignment Problem**: Once the cost matrix $\\mathbf{C}$ is fully populated, the task reduces to finding the permutation $\\pi$ that minimizes the sum $\\sum_{i=0}^{N-1} C_{i, \\pi(i)}$. This is a standard problem that can be solved efficiently by algorithms such as the Hungarian algorithm. For implementation, the function `scipy.optimize.linear_sum_assignment` is perfectly suited for this purpose. It takes the cost matrix as input and returns the row and column indices of the optimal assignment. The output directly provides the permutation $\\pi$ that maps each pole pair index $i$ to a zero pair index $\\pi(i)$.\n\n5.  **Final Result**: For each test case, we compute the cost matrix as described, solve the assignment problem to obtain the optimal permutation $\\pi = [\\pi(0), \\pi(1), \\ldots, \\pi(N-1)]$, and report this list of indices. The indices $\\pi(i)$ correspond to the zero-pair indices assigned to the pole pairs, which are ordered by their input index $i=0, 1, \\ldots, N-1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Solves the pole-zero pairing problem for a suite of test cases.\n    \"\"\"\n    \n    # Define constants given in the problem statement.\n    LAMBDA = 1.0\n    MU = 0.25\n\n    def wrap_angle(theta):\n        \"\"\"Wraps an angle to the interval [-pi, pi).\"\"\"\n        return (theta + np.pi) % (2 * np.pi) - np.pi\n\n    def d_cost(a, b):\n        \"\"\"\n        Calculates the pairwise point cost d(a, b) between two complex numbers.\n        \"\"\"\n        mag_a, mag_b = np.abs(a), np.abs(b)\n        \n        # Term 1: Squared Euclidean distance\n        term1 = np.abs(a - b)**2\n        \n        # Term 2: Squared magnitude difference\n        term2 = LAMBDA * (mag_a - mag_b)**2\n        \n        # Term 3: Squared wrapped angle difference\n        if mag_a == 0 or mag_b == 0:\n            delta_theta = 0.0\n        else:\n            delta_theta = wrap_angle(np.angle(a) - np.angle(b))\n        term3 = MU * delta_theta**2\n        \n        return term1 + term2 + term3\n\n    def c_cost(pole_pair, zero_pair):\n        \"\"\"\n        Calculates the pole-pair to zero-pair cost c(P_i, Z_j).\n        \"\"\"\n        p1, p2 = pole_pair\n        z1, z2 = zero_pair\n        \n        # Cost of direct pairing: (p1, z1) and (p2, z2)\n        cost1 = d_cost(p1, z1) + d_cost(p2, z2)\n        \n        # Cost of swapped pairing: (p1, z2) and (p2, z1)\n        cost2 = d_cost(p1, z2) + d_cost(p2, z1)\n        \n        return min(cost1, cost2)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case A\n        (\n            [\n                (0.9 * np.exp(1j * np.pi * 0.3), 0.9 * np.exp(-1j * np.pi * 0.3)),\n                (0.88 * np.exp(1j * np.pi * 0.6), 0.88 * np.exp(-1j * np.pi * 0.6)),\n            ],\n            [\n                (0.95 * np.exp(1j * np.pi * 0.32), 0.95 * np.exp(-1j * np.pi * 0.32)),\n                (0.90 * np.exp(1j * np.pi * 0.58), 0.90 * np.exp(-1j * np.pi * 0.58)),\n            ]\n        ),\n        # Test Case B\n        (\n            [\n                (0.85 + 0.05j, 0.85 - 0.05j),\n                (-0.70, -0.60),\n            ],\n            [\n                (0.90 + 0.02j, 0.90 - 0.02j),\n                (-0.65, -0.75),\n            ]\n        ),\n        # Test Case C\n        (\n            [\n                (0.95 * np.exp(1j * np.pi * 0.20), 0.95 * np.exp(-1j * np.pi * 0.20)),\n                (0.30 * np.exp(1j * np.pi * 0.40), 0.30 * np.exp(-1j * np.pi * 0.40)),\n            ],\n            [\n                (0.0 + 0.0j, 0.0 + 0.0j),\n                (0.98 * np.exp(1j * np.pi * 0.22), 0.98 * np.exp(-1j * np.pi * 0.22)),\n            ]\n        ),\n        # Test Case D\n        (\n            [\n                (0.92 * np.exp(1j * np.pi * 0.75), 0.92 * np.exp(-1j * np.pi * 0.75)),\n                (0.92 * np.exp(1j * np.pi * 0.25), 0.92 * np.exp(-1j * np.pi * 0.25)),\n            ],\n            [\n                (0.93 * np.exp(1j * np.pi * 0.26), 0.93 * np.exp(-1j * np.pi * 0.26)),\n                (0.93 * np.exp(1j * np.pi * 0.74), 0.93 * np.exp(-1j * np.pi * 0.74)),\n            ]\n        ),\n    ]\n\n    results = []\n    for pole_pairs, zero_pairs in test_cases:\n        N = len(pole_pairs)\n        cost_matrix = np.zeros((N, N))\n        \n        for i in range(N):\n            for j in range(N):\n                cost_matrix[i, j] = c_cost(pole_pairs[i], zero_pairs[j])\n        \n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        \n        # The returned row_ind and col_ind give the optimal assignment.\n        # We need to create the permutation array pi where pi[i] is the\n        # column index assigned to row i.\n        permutation = np.zeros_like(col_ind)\n        permutation[row_ind] = col_ind\n        \n        results.append(permutation.tolist())\n\n    # Final print statement in the exact required format.\n    # The format [[...],[...]] without spaces is achieved by this print statement.\n    print(str(results).replace(' ', ''))\n\nsolve()\n```", "id": "2856941"}]}