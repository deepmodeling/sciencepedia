{"hands_on_practices": [{"introduction": "This first practice provides a foundational exercise in analyzing quantization noise. We will examine a common Finite Impulse Response (FIR) filter implementation to learn how to distinguish between different noise sourcesâ€”those from intermediate multiplications and those from final accumulation [@problem_id:2872520]. This exercise is crucial for understanding how choices in hardware architecture, such as the bit-widths $B_p$ and $B_a$ allocated at different stages, directly impact the overall noise performance of a digital filter.", "problem": "Consider a finite impulse response (FIR) filter of length $M$ with impulse response coefficients $\\{h_k\\}_{k=0}^{M-1}$ operating on a real-valued input sequence $\\{x[n]\\}$. The ideal output is $y[n] = \\sum_{k=0}^{M-1} h_k x[n-k]$. The implementation is fixed-point and proceeds as follows: each product $h_k x[n-k]$ is computed and then rounded to a signed, symmetric, mid-tread, uniform quantizer with $B_p$ bits, after which all rounded products are accumulated exactly, and finally the accumulated sum is rounded once more by a signed, symmetric, mid-tread, uniform quantizer with $B_a$ bits to produce the output. Assume the following.\n\n- The input satisfies a known bound $|x[n]| \\leq X_{\\max}$ for all $n$, and the implementation uses per-multiplier full-scale normalization such that the $k$-th product quantizer spans the symmetric range $\\pm X_{\\max} |h_k|$, while the final output quantizer spans the symmetric range $\\pm X_{\\max} \\sum_{k=0}^{M-1} |h_k|$, thereby avoiding overflow in worst-case signal combinations.\n- Each uniform quantizer is modeled by an additive, white, signal-uncorrelated quantization noise with zero mean and variance $\\Delta^2/12$, where $\\Delta$ is the quantization step. Quantization noises from different quantizers and different time indices are mutually uncorrelated.\n- All arithmetic other than the two stated roundings is exact.\n\nDefine the output noise due to product quantization as the component at the filter output that originates solely from the individual product roundings, and define the output noise due to adder quantization as the component originating solely from the final rounding after accumulation. Starting from the stated assumptions and fundamental properties of uniform quantization noise and linear systems, derive the closed-form expression for the ratio $R$ of the output noise power due to product quantization to that due to adder quantization as a function of $M$, the coefficient magnitudes $\\{|h_k|\\}$, $B_p$, and $B_a$. Your final answer must be a single analytic expression in terms of $M$, $\\{|h_k|\\}$, $B_p$, and $B_a$. Do not introduce any additional approximations beyond the given modeling assumptions. The answer is dimensionless; do not include units.", "solution": "The problem requires the derivation of the ratio of two distinct quantization noise powers in a fixed-point Finite Impulse Response (FIR) filter implementation. The analysis will proceed from the fundamental principles of quantization error modeling as specified in the problem statement.\n\nFirst, we formalize the filter's operation. The ideal output $y[n]$ is given by\n$$y[n] = \\sum_{k=0}^{M-1} h_k x[n-k]$$\nThe implemented output, which we denote as $\\hat{y}[n]$, is subject to two stages of quantization. The first stage is the rounding of each product $p_k[n] = h_k x[n-k]$, and the second is the rounding of the final accumulated sum.\n\nLet $Q_{p,k}(\\cdot)$ denote the quantizer for the $k$-th product, and let $Q_a(\\cdot)$ denote the quantizer for the final sum. The implemented output $\\hat{y}[n]$ is given by\n$$\\hat{y}[n] = Q_a\\left(\\sum_{k=0}^{M-1} Q_{p,k}(h_k x[n-k])\\right)$$\nWe model each quantizer $Q(\\cdot)$ by an additive noise source $e$, such that $Q(z) = z + e$. The noise $e$ is assumed to be a zero-mean random process with variance $\\sigma_e^2 = \\frac{\\Delta^2}{12}$, where $\\Delta$ is the quantization step size.\n\nThe quantization step size $\\Delta$ for a signed, symmetric, $B$-bit quantizer over a range $\\pm F$ is determined by the full-scale range $2F$ and the number of quantization levels, $2^B$. Thus,\n$$\\Delta = \\frac{2F}{2^B} = F \\cdot 2^{1-B}$$\n\nNow, we analyze the two sources of noise as defined in the problem.\n\n1.  **Output Noise Power due to Product Quantization ($\\sigma_{p,\\text{out}}^2$)**\n\nThis noise arises from the rounding of the $M$ individual products. Let $e_{p,k}[n]$ be the quantization error from rounding the $k$-th product:\n$$Q_{p,k}(h_k x[n-k]) = h_k x[n-k] + e_{p,k}[n]$$\nThe total contribution from these product quantization errors at the input to the final accumulator is the sum:\n$$e_p[n] = \\sum_{k=0}^{M-1} e_{p,k}[n]$$\nSince the accumulation is exact, this sum represents the total product quantization noise component present at the system output before the final rounding. The power of this noise is its variance, $\\sigma_{p,\\text{out}}^2 = \\text{Var}(e_p[n])$.\nAccording to the problem statement, the quantization noises $e_{p,k}[n]$ from different multipliers (different $k$) are uncorrelated. Therefore, the variance of the sum is the sum of the variances:\n$$\\sigma_{p,\\text{out}}^2 = \\text{Var}\\left(\\sum_{k=0}^{M-1} e_{p,k}[n]\\right) = \\sum_{k=0}^{M-1} \\text{Var}(e_{p,k}[n])$$\nThe variance of each individual product noise, $\\text{Var}(e_{p,k}[n])$, is $\\frac{\\Delta_{p,k}^2}{12}$, where $\\Delta_{p,k}$ is the step size of the $k$-th product quantizer. This quantizer has $B_p$ bits and its range is specified as $\\pm X_{\\max} |h_k|$. So, its full-scale value is $F_k = X_{\\max} |h_k|$. The step size is:\n$$\\Delta_{p,k} = F_k \\cdot 2^{1-B_p} = X_{\\max} |h_k| 2^{1-B_p}$$\nThe variance of the $k$-th product noise is:\n$$\\text{Var}(e_{p,k}[n]) = \\frac{\\Delta_{p,k}^2}{12} = \\frac{(X_{\\max} |h_k| 2^{1-B_p})^2}{12} = \\frac{X_{\\max}^2 |h_k|^2 2^{2(1-B_p)}}{12}$$\nSubstituting this into the sum for the total product noise power, we get:\n$$\\sigma_{p,\\text{out}}^2 = \\sum_{k=0}^{M-1} \\frac{X_{\\max}^2 |h_k|^2 2^{2(1-B_p)}}{12} = \\frac{X_{\\max}^2 2^{2(1-B_p)}}{12} \\sum_{k=0}^{M-1} |h_k|^2$$\n\n2.  **Output Noise Power due to Adder Quantization ($\\sigma_{a,\\text{out}}^2$)**\n\nThis noise, which we denote $e_a[n]$, is introduced by the final rounding operation $Q_a(\\cdot)$. The input to this quantizer is the exact sum of the rounded products. The output is:\n$$\\hat{y}[n] = Q_a\\left(\\sum_{k=0}^{M-1} Q_{p,k}(h_k x[n-k])\\right) = \\left(\\sum_{k=0}^{M-1} Q_{p,k}(h_k x[n-k])\\right) + e_a[n]$$\nThe problem defines the \"output noise due to adder quantization\" as the component originating solely from this final rounding. This is precisely $e_a[n]$. Its power is the variance $\\sigma_{a,\\text{out}}^2 = \\text{Var}(e_a[n])$.\nThis variance is given by $\\frac{\\Delta_a^2}{12}$, where $\\Delta_a$ is the step size of the final accumulator quantizer. This quantizer has $B_a$ bits, and its range is specified as $\\pm X_{\\max} \\sum_{k=0}^{M-1} |h_k|$. The full-scale value is $F_a = X_{\\max} \\sum_{k=0}^{M-1} |h_k|$. The step size is:\n$$\\Delta_a = F_a \\cdot 2^{1-B_a} = \\left(X_{\\max} \\sum_{k=0}^{M-1} |h_k|\\right) 2^{1-B_a}$$\nThe variance of the adder quantization noise is therefore:\n$$\\sigma_{a,\\text{out}}^2 = \\frac{\\Delta_a^2}{12} = \\frac{\\left(\\left(X_{\\max} \\sum_{k=0}^{M-1} |h_k|\\right) 2^{1-B_a}\\right)^2}{12} = \\frac{X_{\\max}^2 \\left(\\sum_{k=0}^{M-1} |h_k|\\right)^2 2^{2(1-B_a)}}{12}$$\n\n3.  **Ratio of Noise Powers ($R$)**\n\nThe problem asks for the ratio $R$ of the output noise power due to product quantization to that due to adder quantization.\n$$R = \\frac{\\sigma_{p,\\text{out}}^2}{\\sigma_{a,\\text{out}}^2}$$\nSubstituting the expressions derived above:\n$$R = \\frac{\\frac{X_{\\max}^2 2^{2(1-B_p)}}{12} \\sum_{k=0}^{M-1} |h_k|^2}{\\frac{X_{\\max}^2 \\left(\\sum_{k=0}^{M-1} |h_k|\\right)^2 2^{2(1-B_a)}}{12}}$$\nThe common term $\\frac{X_{\\max}^2}{12}$ cancels out from the numerator and denominator. We are left with:\n$$R = \\frac{2^{2(1-B_p)} \\sum_{k=0}^{M-1} |h_k|^2}{2^{2(1-B_a)} \\left(\\sum_{k=0}^{M-1} |h_k|\\right)^2}$$\nSimplifying the exponential term:\n$$\\frac{2^{2(1-B_p)}}{2^{2(1-B_a)}} = 2^{2(1-B_p) - 2(1-B_a)} = 2^{2-2B_p - 2+2B_a} = 2^{2B_a - 2B_p} = 2^{2(B_a - B_p)}$$\nThus, the final expression for the ratio $R$ is:\n$$R = 2^{2(B_a - B_p)} \\frac{\\sum_{k=0}^{M-1} |h_k|^2}{\\left(\\sum_{k=0}^{M-1} |h_k|\\right)^2}$$\nThis expression is a function of $M$ (implicit in the summations), the coefficient magnitudes $\\{|h_k|\\}$, and the bit depths $B_p$ and $B_a$, as required.", "answer": "$$ \\boxed{ 2^{2(B_a-B_p)} \\frac{\\sum_{k=0}^{M-1} |h_k|^2}{\\left(\\sum_{k=0}^{M-1} |h_k|\\right)^2} } $$", "id": "2872520"}, {"introduction": "While the direct summation approach works well for FIR filters, systems with feedback, like Infinite Impulse Response (IIR) filters, require more powerful tools. This practice introduces the state-space representation with matrices $A$ and $C$ to analyze how quantization noise propagates through a recursive structure [@problem_id:2872507]. By solving the discrete-time Lyapunov equation for the state covariance matrix $P$, you will compute the steady-state output noise variance $\\sigma_y^2$ and see its fundamental connection to the system's $\\mathcal{H}_2$ norm, providing a deeper insight into noise amplification in feedback systems.", "problem": "Consider the discrete-time, linear time-invariant state-space system modeling finite word length roundoff in the state update:\n$x[n+1] = A x[n] + w[n]$ and $y[n] = C x[n]$,\nwith $A \\in \\mathbb{R}^{2 \\times 2}$ and $C \\in \\mathbb{R}^{1 \\times 2}$ given by\n$A = \\begin{bmatrix} \\tfrac{3}{5} & \\tfrac{1}{5} \\\\[4pt] 0 & \\tfrac{1}{2} \\end{bmatrix}$ and $C = \\begin{bmatrix} 1 & -1 \\end{bmatrix}$.\nThe signal $w[n] \\in \\mathbb{R}^{2}$ is a zero-mean, white disturbance modeling quantization noise due to finite word length in the state computation, with covariance $\\mathbb{E}\\{w[n] w[n]^{\\top}\\} = \\sigma_{w}^{2} I_{2}$ and $\\sigma_{w}^{2} = \\frac{\\Delta^{2}}{12}$, where $\\Delta$ is the quantizer step size. Assume $x[0]$ is zero-mean, independent of $w[n]$, and the system is asymptotically stable.\n\nStarting only from the definitions of second-order moments for linear systems with white inputs and the uniqueness of the stationary covariance for stable linear time-invariant recursions, do the following:\n- Derive the steady-state state covariance matrix $P = \\mathbb{E}\\{x[n] x[n]^{\\top}\\}$ by solving the appropriate discrete-time Lyapunov equation implied by the dynamics and whiteness of $w[n]$.\n- Using $P$, compute the steady-state output variance $\\sigma_{y}^{2} = \\mathbb{E}\\{y[n]^{2}\\}$.\n- Using the definition of the Hardy space two ($\\mathcal{H}_{2}$) norm for stable, strictly proper discrete-time systems, relate $\\sigma_{y}^{2}$ to the squared $\\mathcal{H}_{2}$ norm of the transfer function from $w[n]$ to $y[n]$, and identify the corresponding constant of proportionality in terms of $\\sigma_{w}^{2}$.\n\nProvide your final answer as a single, simplified, closed-form expression for the steady-state output variance $\\sigma_{y}^{2}$ in terms of $\\Delta$ only. Do not approximate or round your answer; no units are required.", "solution": "The first step is to derive the equation governing the steady-state state covariance matrix $P$. By definition, $P = \\mathbb{E}\\{x[n] x[n]^{\\top}\\}$. Since the system is in steady state, $P$ is constant. We consider the time evolution of the covariance.\nThe state at time $n+1$ is $x[n+1] = A x[n] + w[n]$. The covariance at time $n+1$ is $P_{n+1} = \\mathbb{E}\\{x[n+1] x[n+1]^{\\top}\\}$.\nSubstituting the state equation:\n$$ P_{n+1} = \\mathbb{E}\\{(A x[n] + w[n])(A x[n] + w[n])^{\\top}\\} $$\n$$ P_{n+1} = \\mathbb{E}\\{A x[n] x[n]^{\\top} A^{\\top} + A x[n] w[n]^{\\top} + w[n] x[n]^{\\top} A^{\\top} + w[n] w[n]^{\\top}\\} $$\nBy linearity of expectation:\n$$ P_{n+1} = A \\mathbb{E}\\{x[n] x[n]^{\\top}\\} A^{\\top} + A \\mathbb{E}\\{x[n] w[n]^{\\top}\\} + \\mathbb{E}\\{w[n] x[n]^{\\top}\\} A^{\\top} + \\mathbb{E}\\{w[n] w[n]^{\\top}\\} $$\nThe state $x[n]$ is a function of past noise inputs $\\{w[k]\\}_{k<n}$ and the initial state $x[0]$. Since $w[n]$ is a white noise sequence and is independent of $x[0]$, it is uncorrelated with $x[n]$. Thus, $\\mathbb{E}\\{x[n] w[n]^{\\top}\\} = \\mathbb{E}\\{x[n]\\} \\mathbb{E}\\{w[n]^{\\top}\\} = 0$, as both signals are zero-mean. The noise covariance is given as $Q = \\mathbb{E}\\{w[n] w[n]^{\\top}\\} = \\sigma_{w}^{2} I_{2}$.\nThe covariance update equation is therefore $P_{n+1} = A P_{n} A^{\\top} + Q$.\nIn steady-state, $P_{n+1} = P_{n} = P$, which leads to the discrete-time algebraic Lyapunov equation:\n$$ P = A P A^{\\top} + Q $$\nWe must solve this equation for the symmetric matrix $P = \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix}$.\nGiven $A = \\begin{bmatrix} \\frac{3}{5} & \\frac{1}{5} \\\\ 0 & \\frac{1}{2} \\end{bmatrix}$ and $Q = \\sigma_{w}^{2} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$, the equation is:\n$$ \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} = \\begin{bmatrix} \\frac{3}{5} & \\frac{1}{5} \\\\ 0 & \\frac{1}{2} \\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} \\frac{3}{5} & 0 \\\\ \\frac{1}{5} & \\frac{1}{2} \\end{bmatrix} + \\sigma_{w}^{2} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix} $$\nThe matrix product is computed:\n$$ A P A^{\\top} = \\begin{bmatrix} \\frac{9}{25}p_{11} + \\frac{6}{25}p_{12} + \\frac{1}{25}p_{22} & \\frac{3}{10}p_{12} + \\frac{1}{10}p_{22} \\\\ \\frac{3}{10}p_{12} + \\frac{1}{10}p_{22} & \\frac{1}{4}p_{22} \\end{bmatrix} $$\nEquating the components of $P = A P A^{\\top} + Q$ gives a system of linear equations for the elements of $P$:\n1. $p_{11} = \\frac{9}{25}p_{11} + \\frac{6}{25}p_{12} + \\frac{1}{25}p_{22} + \\sigma_{w}^{2}$\n2. $p_{12} = \\frac{3}{10}p_{12} + \\frac{1}{10}p_{22}$\n3. $p_{22} = \\frac{1}{4}p_{22} + \\sigma_{w}^{2}$\n\nWe solve this system, starting from the last equation.\nFrom (3): $(1 - \\frac{1}{4})p_{22} = \\sigma_{w}^{2} \\implies \\frac{3}{4}p_{22} = \\sigma_{w}^{2} \\implies p_{22} = \\frac{4}{3}\\sigma_{w}^{2}$.\nFrom (2): $(1 - \\frac{3}{10})p_{12} = \\frac{1}{10}p_{22} \\implies \\frac{7}{10}p_{12} = \\frac{1}{10}p_{22} \\implies p_{12} = \\frac{1}{7}p_{22}$. Substituting $p_{22}$ yields $p_{12} = \\frac{1}{7}(\\frac{4}{3}\\sigma_{w}^{2}) = \\frac{4}{21}\\sigma_{w}^{2}$.\nFrom (1): $(1 - \\frac{9}{25})p_{11} = \\frac{6}{25}p_{12} + \\frac{1}{25}p_{22} + \\sigma_{w}^{2} \\implies \\frac{16}{25}p_{11} = \\frac{6}{25}p_{12} + \\frac{1}{25}p_{22} + \\sigma_{w}^{2}$.\nMultiply by $25$: $16 p_{11} = 6 p_{12} + p_{22} + 25 \\sigma_{w}^{2}$.\nSubstitute the expressions for $p_{12}$ and $p_{22}$:\n$$ 16 p_{11} = 6(\\frac{4}{21}\\sigma_{w}^{2}) + \\frac{4}{3}\\sigma_{w}^{2} + 25\\sigma_{w}^{2} = (\\frac{24}{21} + \\frac{28}{21} + 25 \\cdot \\frac{21}{21})\\sigma_{w}^{2} $$\n$$ 16 p_{11} = (\\frac{52}{21} + \\frac{525}{21})\\sigma_{w}^{2} = \\frac{577}{21}\\sigma_{w}^{2} $$\n$$ p_{11} = \\frac{577}{16 \\cdot 21}\\sigma_{w}^{2} = \\frac{577}{336}\\sigma_{w}^{2} $$\nThe steady-state state covariance matrix is $P = \\sigma_{w}^{2} \\begin{bmatrix} \\frac{577}{336} & \\frac{4}{21} \\\\ \\frac{4}{21} & \\frac{4}{3} \\end{bmatrix}$.\n\nNext, we compute the steady-state output variance, $\\sigma_{y}^{2} = \\mathbb{E}\\{y[n]^{2}\\}$. Since $w[n]$ and $x[0]$ are zero-mean, $x[n]$ and consequently $y[n]=Cx[n]$ are zero-mean. Thus, the variance is the second moment.\n$$ \\sigma_{y}^{2} = \\mathbb{E}\\{y[n] y[n]^{\\top}\\} = \\mathbb{E}\\{(C x[n])(C x[n])^{\\top}\\} = \\mathbb{E}\\{C x[n] x[n]^{\\top} C^{\\top}\\} $$\n$$ \\sigma_{y}^{2} = C \\, \\mathbb{E}\\{x[n] x[n]^{\\top}\\} \\, C^{\\top} = C P C^{\\top} $$\nWith $C = \\begin{bmatrix} 1 & -1 \\end{bmatrix}$ and $C^{\\top} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$:\n$$ \\sigma_{y}^{2} = \\begin{bmatrix} 1 & -1 \\end{bmatrix} \\begin{bmatrix} p_{11} & p_{12} \\\\ p_{12} & p_{22} \\end{bmatrix} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} = p_{11} - 2p_{12} + p_{22} $$\nSubstituting the solved values:\n$$ \\sigma_{y}^{2} = \\left(\\frac{577}{336} - 2 \\cdot \\frac{4}{21} + \\frac{4}{3}\\right) \\sigma_{w}^{2} $$\nTo combine these terms, we use a common denominator of $336$:\n$$ \\sigma_{y}^{2} = \\left(\\frac{577}{336} - \\frac{8 \\cdot 16}{21 \\cdot 16} + \\frac{4 \\cdot 112}{3 \\cdot 112}\\right) \\sigma_{w}^{2} = \\left(\\frac{577 - 128 + 448}{336}\\right) \\sigma_{w}^{2} $$\n$$ \\sigma_{y}^{2} = \\left(\\frac{449 + 448}{336}\\right) \\sigma_{w}^{2} = \\frac{897}{336}\\sigma_{w}^{2} $$\nThe fraction simplifies by dividing the numerator and denominator by $3$:\n$$ \\sigma_{y}^{2} = \\frac{299}{112}\\sigma_{w}^{2} $$\n\nThe problem requires a relation to the $\\mathcal{H}_{2}$ norm. The system from the noise input $w[n]$ to the output $y[n]$ has a state-space representation $(A, B, C, D) = (A, I_{2}, C, 0)$. The transfer function is $H(z) = C(zI - A)^{-1}I_{2}$. The squared $\\mathcal{H}_{2}$ norm of this system is defined via its impulse response $h[n] = CA^{n-1}I_2$ for $n \\ge 1$ as $\\|H\\|_{\\mathcal{H}_2}^{2} = \\sum_{n=0}^{\\infty} \\text{tr}(h[n]h[n]^{\\top})$. A fundamental result of linear systems theory states that this norm is also computable from the controllability Gramian $W_{c}$, which solves the Lyapunov equation $W_{c} = A W_{c} A^{\\top} + B B^{\\top}$. In our case, $B=I_2$, so $W_{c} = A W_{c} A^{\\top} + I_{2}$. The norm is then $\\|H\\|_{\\mathcal{H}_2}^{2} = \\text{tr}(C W_{c} C^{\\top})$.\nComparing the Lyapunov equation for $W_c$ with the one for our state covariance $P = A P A^{\\top} + \\sigma_{w}^{2} I_{2}$, we see by linearity that $P = \\sigma_{w}^{2} W_{c}$.\nThe output variance is $\\sigma_{y}^{2} = C P C^{\\top} = C (\\sigma_{w}^{2} W_{c}) C^{\\top} = \\sigma_{w}^{2} (C W_{c} C^{\\top})$.\nSince $C W_{c} C^{\\top}$ is a scalar, it equals its trace. Thus, $\\sigma_{y}^{2} = \\sigma_{w}^{2} \\text{tr}(C W_{c} C^{\\top}) = \\sigma_{w}^{2} \\|H\\|_{\\mathcal{H}_2}^{2}$.\nThis establishes the relation. The constant of proportionality between the output variance $\\sigma_{y}^{2}$ and the squared $\\mathcal{H}_{2}$ norm is $\\sigma_{w}^{2}$.\n\nFinally, we express $\\sigma_{y}^{2}$ in terms of $\\Delta$. Using the given relation $\\sigma_{w}^{2} = \\frac{\\Delta^{2}}{12}$:\n$$ \\sigma_{y}^{2} = \\frac{299}{112} \\left(\\frac{\\Delta^{2}}{12}\\right) = \\frac{299}{112 \\cdot 12}\\Delta^{2} = \\frac{299}{1344}\\Delta^{2} $$\nThis expression cannot be further simplified, as $299 = 13 \\cdot 23$ and $1344 = 112 \\cdot 12 = (16 \\cdot 7) \\cdot (3 \\cdot 4) = 2^6 \\cdot 3 \\cdot 7$ share no common factors.", "answer": "$$\\boxed{\\frac{299}{1344}\\Delta^{2}}$$", "id": "2872507"}, {"introduction": "The additive white noise (AWN) model is a powerful approximation, but it is not universally valid. This final practice presents a crucial counterexample where this statistical model leads to a completely incorrect prediction for a simple first-order IIR filter [@problem_id:2872516]. By tracing the system's deterministic, step-by-step behavior, you will uncover a \"limit cycle\"â€”a non-decaying, periodic output that arises purely from the interaction of feedback and quantizationâ€”and learn the importance of recognizing the limitations of our analytical models.", "problem": "Consider a first-order feedback Infinite Impulse Response (IIR) recursion with an in-loop uniform mid-tread quantizer defined by the deterministic difference equation\n$$\ny[n] \\;=\\; Q\\!\\big(\\alpha\\, y[n-1]\\big),\n$$\nwhere $Q(\\cdot)$ is a rounding-to-nearest quantizer with step size $\\Delta = 1$ and a tie-breaking rule of rounding half away from zero, the initial condition is $y[-1]=1$, the input is identically zero, and the feedback gain is $\\alpha = \\tfrac{1}{2}$. Assume the quantizer has no saturation (i.e., unbounded dynamic range).\n\nThe additive white noise (AWN) quantization model replaces the quantizer by an adder $y[n] = \\alpha\\,y[n-1] + e[n]$, where $e[n]$ is modeled as a sequence of independent and identically distributed random variables, independent of $y[n-1]$, each uniformly distributed on the interval $[-\\Delta/2,\\Delta/2]$, and hence of variance $\\frac{\\Delta^{2}}{12}$. Using only fundamental definitions and widely accepted facts (such as the variance of a uniform distribution and the definition of variance for linear recursions), proceed as follows:\n\n1) Under the AWN model, derive the steady-state output variance $\\,\\sigma^{2}_{\\text{AWN}}\\,$ of $\\,y[n]\\,$.\n\n2) For the actual quantized feedback system $\\,y[n] = Q(\\alpha y[n-1])\\,$ with the stated rounding rule and initial condition, determine the true steady-state output variance $\\,\\sigma^{2}_{\\text{true}}\\,$ of $\\,y[n]\\,$.\n\n3) Using your results in parts 1) and 2), compute the discrepancy\n$$\n\\delta \\;=\\; \\sigma^{2}_{\\text{AWN}} \\;-\\; \\sigma^{2}_{\\text{true}}.\n$$\n\nProvide your final answer for $\\,\\delta\\,$ as a single exact number. Do not round.", "solution": "The problem requires the calculation and comparison of output variance for two different models of a quantized feedback system.\n\nFirst, we analyze the additive white noise (AWN) model to determine $\\sigma^{2}_{\\text{AWN}}$. The model is given by the linear difference equation:\n$$\ny[n] = \\alpha y[n-1] + e[n]\n$$\nwhere $\\alpha = \\frac{1}{2}$ is the feedback gain and $e[n]$ is a stochastic process representing the quantization error. The error $e[n]$ is modeled as a sequence of independent and identically distributed (i.i.d.) random variables, each uniformly distributed on the interval $[-\\frac{\\Delta}{2}, \\frac{\\Delta}{2}]$. The problem states that the quantization step size is $\\Delta = 1$, so $e[n]$ is uniform on $[-\\frac{1}{2}, \\frac{1}{2}]$. The variance of such a uniform distribution is given as $\\sigma_e^2 = \\frac{\\Delta^2}{12}$. For $\\Delta=1$, this is $\\sigma_e^2 = \\frac{1}{12}$.\n\nThe AWN model assumes that the error sequence $e[n]$ is independent of the signal sequence $y[n-1]$. To find the steady-state output variance, denoted $\\sigma^{2}_{\\text{AWN}}$, we take the variance of both sides of the difference equation:\n$$\n\\text{Var}(y[n]) = \\text{Var}(\\alpha y[n-1] + e[n])\n$$\nDue to the independence of $y[n-1]$ and $e[n]$, the variance of the sum is the sum of the variances:\n$$\n\\text{Var}(y[n]) = \\text{Var}(\\alpha y[n-1]) + \\text{Var}(e[n])\n$$\nUsing the property $\\text{Var}(cX) = c^2 \\text{Var}(X)$, we have:\n$$\n\\text{Var}(y[n]) = \\alpha^2 \\text{Var}(y[n-1]) + \\sigma_e^2\n$$\nIn steady state, the output variance is constant, i.e., $\\text{Var}(y[n]) = \\text{Var}(y[n-1]) = \\sigma^{2}_{\\text{AWN}}$. Substituting this into the equation yields:\n$$\n\\sigma^{2}_{\\text{AWN}} = \\alpha^2 \\sigma^{2}_{\\text{AWN}} + \\sigma_e^2\n$$\nSolving for $\\sigma^{2}_{\\text{AWN}}$:\n$$\n\\sigma^{2}_{\\text{AWN}}(1 - \\alpha^2) = \\sigma_e^2\n$$\n$$\n\\sigma^{2}_{\\text{AWN}} = \\frac{\\sigma_e^2}{1 - \\alpha^2}\n$$\nNow, we substitute the given values $\\alpha = \\frac{1}{2}$ and $\\sigma_e^2 = \\frac{1}{12}$:\n$$\n\\sigma^{2}_{\\text{AWN}} = \\frac{\\frac{1}{12}}{1 - \\left(\\frac{1}{2}\\right)^2} = \\frac{\\frac{1}{12}}{1 - \\frac{1}{4}} = \\frac{\\frac{1}{12}}{\\frac{3}{4}} = \\frac{1}{12} \\times \\frac{4}{3} = \\frac{4}{36} = \\frac{1}{9}\n$$\nThis completes the first part of the problem.\n\nSecond, we analyze the actual deterministic system to find the true steady-state output variance, $\\sigma^{2}_{\\text{true}}$. The system is described by the nonlinear difference equation:\n$$\ny[n] = Q\\big(\\alpha\\, y[n-1]\\big)\n$$\nThe parameters are $\\alpha = \\frac{1}{2}$ and $\\Delta=1$. The quantizer $Q(\\cdot)$ rounds its argument to the nearest integer, with the tie-breaking rule of rounding a value of the form $k + 0.5$ (for integer $k$) away from zero. The initial condition is $y[-1] = 1$. We trace the output sequence $y[n]$ for $n \\ge 0$:\nFor $n=0$:\n$$\ny[0] = Q\\left(\\alpha y[-1]\\right) = Q\\left(\\frac{1}{2} \\cdot 1\\right) = Q(0.5)\n$$\nAccording to the \"round half away from zero\" rule, $Q(0.5) = 1$.\nFor $n=1$:\n$$\ny[1] = Q\\left(\\alpha y[0]\\right) = Q\\left(\\frac{1}{2} \\cdot 1\\right) = Q(0.5) = 1\n$$\nBy induction, if $y[k-1] = 1$ for any $k \\ge 0$, then $y[k] = Q(\\frac{1}{2} \\cdot 1) = 1$. The sequence is $y[n]=1$ for all $n \\ge 0$.\nThe system enters a steady state immediately, producing a constant output sequence $\\{1, 1, 1, \\dots\\}$. This is a DC limit cycle of period $1$.\nThe steady-state output is a deterministic, constant value: $y_{ss}[n] = 1$. The mean of this steady-state signal is $\\mu_y = 1$. The variance of any constant value is, by definition, zero.\n$$\n\\sigma^{2}_{\\text{true}} = \\text{E}\\left[(y_{ss}[n] - \\mu_y)^2\\right] = \\text{E}\\left[(1 - 1)^2\\right] = \\text{E}[0] = 0\n$$\nThus, the true steady-state variance is $\\sigma^{2}_{\\text{true}} = 0$.\n\nThird, we compute the discrepancy $\\delta$:\n$$\n\\delta = \\sigma^{2}_{\\text{AWN}} - \\sigma^{2}_{\\text{true}}\n$$\nSubstituting the values derived in the previous parts:\n$$\n\\delta = \\frac{1}{9} - 0 = \\frac{1}{9}\n$$\nThis result highlights a case where the widely used linear AWN model fails to capture the true nonlinear behavior of the system, which in this case is a deterministic limit cycle with zero variance.", "answer": "$$\\boxed{\\frac{1}{9}}$$", "id": "2872516"}]}