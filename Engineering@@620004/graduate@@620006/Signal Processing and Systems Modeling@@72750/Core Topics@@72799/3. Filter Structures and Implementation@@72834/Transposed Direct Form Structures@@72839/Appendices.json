{"hands_on_practices": [{"introduction": "The theoretical elegance of the transposition theorem has practical implications for hardware implementation. A primary concern when choosing a filter structure is its cost in terms of components. This practice guides you through a fundamental accounting exercise to verify a key consequence of the transposition theorem: that a Transposed Direct Form II (TDF-II) realization requires the exact same number of multipliers, adders, and delay elements as its Direct Form II (DF-II) counterpart, despite their different topologies [@problem_id:2915276].", "problem": "Consider a causal, linear time-invariant (LTI) discrete-time system with transfer function\n$$\nH(z)=\\frac{B(z)}{A(z)}=\\frac{b_{0}+b_{1}z^{-1}+\\cdots+b_{M}z^{-M}}{1+a_{1}z^{-1}+\\cdots+a_{N}z^{-N}},\n$$\nwhere $A(z)$ is monic, $M$ and $N$ are nonnegative integers, and all coefficients $b_{k}$ for $0\\leq k\\leq M$ and $a_{k}$ for $1\\leq k\\leq N$ are generic nonzero real numbers (no structural cancellations). Assume ideal signal splitters (no cost), each summation is implemented using only $2$-input adders, and unary sign changes are absorbed into multipliers. No structural optimizations beyond the canonical forms are allowed.\n\nUsing only the core facts that (i) a causal LTI system described by a linear constant-coefficient difference equation can be realized by interconnecting multipliers, adders, and unit delays, (ii) a sum of $K$ signals requires $K-1$ two-input adders, and (iii) the transposition theorem for linear signal-flow graphs preserves the transfer function and the counts of linear elements while reversing interconnections, do the following:\n\n1. Realize $H(z)$ conceptually in Direct Form II (DF-II) canonical structure, and count the total number of real multipliers, two-input adders, and unit delays required, expressed in terms of $M$ and $N$.\n\n2. Apply the transposition theorem to obtain the Transposed Direct Form II (TDF-II) structure, and again count the total number of real multipliers, two-input adders, and unit delays required, expressed in terms of $M$ and $N$.\n\n3. Explain whether these totals are equal between DF-II and TDF-II and why this is the case, even though the placements of elements differ.\n\nProvide your final answer as the common totals, in the form of a single row matrix $[n_{\\text{mult}},\\,n_{\\text{add}},\\,n_{\\text{delay}}]$ whose entries are symbolic expressions in $M$ and $N$. No numerical evaluation is required, and no units are involved.", "solution": "The problem statement is a well-posed exercise in the analysis of canonical digital filter structures. It is scientifically grounded in established principles of linear systems and digital signal processing. All premises and constraints are clearly defined and consistent. The problem is valid. We proceed with the solution.\n\nThe system is described by the transfer function $H(z)$:\n$$\nH(z) = \\frac{Y(z)}{X(z)} = \\frac{B(z)}{A(z)} = \\frac{\\sum_{k=0}^{M} b_k z^{-k}}{1 + \\sum_{k=1}^{N} a_k z^{-k}}\n$$\nwhere $Y(z)$ and $X(z)$ are the Z-transforms of the output and input signals, respectively. This transfer function can be decomposed into an all-pole section $H_1(z) = 1/A(z)$ and an all-zero section $H_2(z) = B(z)$.\n\n1.  **Direct Form II (DF-II) Realization**\n\nThe Direct Form II structure realizes the system by cascading the all-pole section followed by the all-zero section, $H(z) = H_2(z)H_1(z)$, and sharing the delay elements between the two sections to achieve a canonical implementation. Let $w[n]$ be the intermediate signal at the output of the all-pole section, such that its Z-transform is $W(z) = X(z)/A(z)$, and the system output is $Y(z) = B(z)W(z)$.\n\nThe corresponding difference equations are:\n$$\nA(z)W(z) = X(z) \\implies \\left(1 + \\sum_{k=1}^{N} a_k z^{-k}\\right)W(z) = X(z)\n$$\nIn the time domain, this gives the recursive equation for the intermediate signal $w[n]$:\n$$\nw[n] = x[n] - \\sum_{k=1}^{N} a_k w[n-k]\n$$\nAnd for the output signal $y[n]$:\n$$\nY(z) = B(z)W(z) \\implies Y(z) = \\left(\\sum_{k=0}^{M} b_k z^{-k}\\right)W(z)\n$$\nIn the time domain, this gives the non-recursive equation for the output:\n$$\ny[n] = \\sum_{k=0}^{M} b_k w[n-k]\n$$\nWe now count the required components based on these two equations.\n\n*   **Multipliers:** The recursive equation for $w[n]$ involves multiplying the $N$ delayed signals $w[n-1], \\dots, w[n-N]$ by the coefficients $a_1, \\dots, a_N$. Since the problem states that unary sign changes are absorbed into the multiplier, this requires $N$ real multipliers. The non-recursive equation for $y[n]$ involves multiplying the signals $w[n], w[n-1], \\dots, w[n-M]$ by the coefficients $b_0, \\dots, b_M$. This requires $M+1$ real multipliers. The total number of multipliers is $n_{\\text{mult}} = N + (M+1) = M+N+1$.\n\n*   **Two-Input Adders:** The calculation of $w[n]$ is a summation of $N+1$ terms: $x[n]$ and the $N$ products $-a_k w[n-k]$. Based on the given rule that a sum of $K$ signals requires $K-1$ two-input adders, this computation requires $(N+1)-1 = N$ adders. The calculation of $y[n]$ is a summation of $M+1$ terms. This requires $(M+1)-1 = M$ adders. The total number of adders is $n_{\\text{add}} = N+M = M+N$.\n\n*   **Unit Delays:** The DF-II structure uses a single shared delay line for the intermediate signal $w[n]$. The recursive part requires delays up to $w[n-N]$ and the non-recursive part requires delays up to $w[n-M]$. To satisfy both, the delay line must have a length equal to the greater of the two orders. The total number of unit delay elements is $n_{\\text{delay}} = \\max(M, N)$.\n\nIn summary, for the Direct Form II realization, the component counts are:\n$n_{\\text{mult}} = M+N+1$\n$n_{\\text{add}} = M+N$\n$n_{\\text{delay}} = \\max(M, N)$\n\n2.  **Transposed Direct Form II (TDF-II) Realization**\n\nThe Transposed Direct Form II structure is derived by applying the transposition theorem to the signal-flow graph of the Direct Form II structure. The problem states as a given fact that this theorem \"(iii) preserves the transfer function and the counts of linear elements while reversing interconnections.\" The linear elements are the multipliers, adders, and delay elements.\n\nTherefore, the transposition operation, which involves reversing the direction of all signal paths and interchanging summation nodes with pick-off nodes, does not alter the total number of each type of component. It only reconfigures their connectivity.\n\nBased on this principle, the component counts for the TDF-II structure must be identical to those of the DF-II structure.\n\n*   **Multipliers:** $n_{\\text{mult}} = M+N+1$\n*   **Two-Input Adders:** $n_{\\text{add}} = M+N$\n*   **Unit Delays:** $n_{\\text{delay}} = \\max(M, N)$\n\n3.  **Equality of Totals and Explanation**\n\nThe total counts for real multipliers, two-input adders, and unit delays are indeed equal for the Direct Form II and Transposed Direct Form II structures.\n\nThe fundamental reason for this equality is the transposition theorem for linear signal-flow graphs. A signal-flow graph is a collection of nodes interconnected by directed branches. The branches represent linear operations, which in this context are multiplication by a constant (multiplier) or multiplication by $z^{-1}$ (unit delay). The nodes represent either the splitting of a signal (pick-off node) or the summation of multiple signals (summer node).\n\nWhen a graph is transposed, all branch directions are reversed. A summer node with $K$ inputs and $1$ output becomes a pick-off node with $1$ input and $K$ outputs. Conversely, a pick-off node becomes a summer. The branches themselves, representing multipliers and delays, remain in place with their inputs and outputs swapped.\n\nCrucially, as stated in the problem's premises, the total number of each type of linear element is invariant under this transformation. Since the TDF-II structure is by definition the transpose of the DF-II structure, they are guaranteed to have the same inventory of components. The difference lies not in the *what* or *how many*, but in the *where*â€”the topological arrangement of these components, which alters the flow of signals and the numerical properties of the filter implementation (such as its sensitivity to coefficient quantization and round-off noise), but not the fundamental component count required for the realization.\n\nThe common totals for both structures are therefore $[n_{\\text{mult}},\\,n_{\\text{add}},\\,n_{\\text{delay}}] = [M+N+1,\\, M+N,\\, \\max(M,N)]$.", "answer": "$$\n\\boxed{\\begin{pmatrix} M+N+1 & M+N & \\max(M,N) \\end{pmatrix}}\n$$", "id": "2915276"}, {"introduction": "While component counts are identical, the ultimate test of equivalence is identical input-output behavior. This hands-on programming exercise moves from abstract block diagrams to concrete state-space representations to prove this equivalence numerically. You will simulate a Linear Time-Invariant (LTI) system and its correctly transposed version, verifying that their impulse responses are identical down to machine precision, providing tangible proof that transposition preserves the system's external characteristics [@problem_id:2915280].", "problem": "You are given discrete-time Linear Time-Invariant (LTI) state-space realizations of order $2$, each specified by a quadruple $(A,B,C,D)$ with $A \\in \\mathbb{R}^{2 \\times 2}$, $B \\in \\mathbb{R}^{2 \\times 1}$, $C \\in \\mathbb{R}^{1 \\times 2}$, and $D \\in \\mathbb{R}$. The system dynamics are defined by the state and output equations\n$$\nx[k+1] = A\\,x[k] + B\\,u[k], \\quad y[k] = C\\,x[k] + D\\,u[k],\n$$\nwith zero initial state $x[0] = 0$. For the transposed direct form structure, define the transposed realization by $(\\tilde{A},\\tilde{B},\\tilde{C},\\tilde{D}) = (A^{T},C^{T},B^{T},D^{T})$, where the superscript $T$ denotes the matrix transpose. Consider the unit impulse input $u[k]$ defined by $u[0] = 1$ and $u[k] = 0$ for all $k \\ge 1$.\n\nTask:\n1) For each given test case $(A,B,C,D)$, compute $(\\tilde{A},\\tilde{B},\\tilde{C},\\tilde{D}) = (A^{T},C^{T},B^{T},D^{T})$.\n2) For both the original and the transposed realizations, simulate the response to the unit impulse input with zero initial state $x[0]=0$ and compute the output sequences $\\{y[k]\\}_{k=0}^{N-1}$ and $\\{\\tilde{y}[k]\\}_{k=0}^{N-1}$ for $N$ time steps.\n3) Verify numerically that the impulse responses are identical by checking whether\n$$\n\\max_{0 \\le k \\le N-1} \\left| y[k] - \\tilde{y}[k] \\right| \\le \\tau,\n$$\nwhere $\\tau$ is a small nonnegative tolerance. The verification result for each test case should be a boolean value that is $\\,\\mathrm{True}\\,$ if the inequality holds and $\\,\\mathrm{False}\\,$ otherwise.\n\nUse the following test suite of four second-order Single-Input Single-Output (SISO) realizations, with $N=12$ and tolerance $\\tau = 10^{-11}$:\n- Test case $1$ (strictly proper, stable): \n$$\nA = \\begin{bmatrix} 0.7 & 0.2 \\\\ -0.1 & 0.9 \\end{bmatrix},\\;\nB = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\;\nC = \\begin{bmatrix} 0.3 & -0.4 \\end{bmatrix},\\;\nD = 0.0.\n$$\n- Test case $2$ (nonzero direct feedthrough $D$):\n$$\nA = \\begin{bmatrix} 0.5 & -0.3 \\\\ 0.1 & 0.4 \\end{bmatrix},\\;\nB = \\begin{bmatrix} 0.0 \\\\ 1.0 \\end{bmatrix},\\;\nC = \\begin{bmatrix} 1.0 & 0.2 \\end{bmatrix},\\;\nD = 0.25.\n$$\n- Test case $3$ (repeated eigenvalue, Jordan form):\n$$\nA = \\begin{bmatrix} 0.6 & 1.0 \\\\ 0.0 & 0.6 \\end{bmatrix},\\;\nB = \\begin{bmatrix} 0.2 \\\\ 0.3 \\end{bmatrix},\\;\nC = \\begin{bmatrix} -0.5 & 0.7 \\end{bmatrix},\\;\nD = 0.0.\n$$\n- Test case $4$ (edge case with zero input-to-state coupling):\n$$\nA = \\begin{bmatrix} 0.8 & 0.0 \\\\ 0.0 & 0.8 \\end{bmatrix},\\;\nB = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix},\\;\nC = \\begin{bmatrix} 0.9 & -0.1 \\end{bmatrix},\\;\nD = -0.3.\n$$\n\nYour program must:\n- Internally construct these four test cases.\n- For each test case, compute the transposed realization $(A^{T},C^{T},B^{T},D^{T})$ and simulate the impulse responses for $N=12$ samples.\n- Compare the two output sequences elementwise and compute the maximum absolute difference.\n- Return a boolean result for each test case indicating whether the maximum difference is at most $\\tau = 10^{-11}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$), where each $result_i$ is either $\\mathrm{True}$ or $\\mathrm{False}$.", "solution": "The problem as stated is valid. It is scientifically grounded in the principles of linear systems theory, is well-posed with a complete and consistent set of givens, and is expressed in objective mathematical language. We shall proceed with a solution.\n\nThe fundamental principle to be verified is the invariance of the input-output behavior of a Single-Input Single-Output (SISO) Linear Time-Invariant (LTI) system under a specific state-space transformation known as transposition. The impulse response of a system is a unique characterization of its input-output properties. If two systems have identical impulse responses, they are externally equivalent.\n\nA discrete-time LTI system is given by the state-space realization $(A, B, C, D)$:\n$$\nx[k+1] = A x[k] + B u[k]\n$$\n$$\ny[k] = C x[k] + D u[k]\n$$\nwhere $x[k] \\in \\mathbb{R}^n$ is the state vector at time $k$, $u[k] \\in \\mathbb{R}$ is the input, $y[k] \\in \\mathbb{R}$ is the output, and the matrices have dimensions $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times 1}$, $C \\in \\mathbb{R}^{1 \\times n}$, and $D \\in \\mathbb{R}$.\n\nThe transfer function $H(z)$ from the input $U(z)$ to the output $Y(z)$ in the Z-domain is given by:\n$$\nH(z) = C(zI - A)^{-1}B + D\n$$\nwhere $I$ is the $n \\times n$ identity matrix.\n\nThe problem defines the transposed realization as $(\\tilde{A}, \\tilde{B}, \\tilde{C}, \\tilde{D}) = (A^T, C^T, B^T, D^T)$. This is a standard definition in systems theory, where $D^T=D$ since $D$ is a scalar. The state equations for the transposed system are:\n$$\n\\tilde{x}[k+1] = \\tilde{A} \\tilde{x}[k] + \\tilde{B} u[k] = A^T \\tilde{x}[k] + C^T u[k]\n$$\n$$\n\\tilde{y}[k] = \\tilde{C} \\tilde{x}[k] + \\tilde{D} u[k] = B^T \\tilde{x}[k] + D u[k]\n$$\nThe transfer function $\\tilde{H}(z)$ of the transposed system is:\n$$\n\\tilde{H}(z) = \\tilde{C}(zI - \\tilde{A})^{-1}\\tilde{B} + \\tilde{D} = B^T(zI - A^T)^{-1}C^T + D\n$$\nUsing the matrix identity $(M^{-1})^T = (M^T)^{-1}$, we can write $(zI - A^T)^{-1} = ((zI - A)^T)^{-1} = ((zI - A)^{-1})^T$. Substituting this into the expression for $\\tilde{H}(z)$:\n$$\n\\tilde{H}(z) = B^T((zI - A)^{-1})^T C^T + D\n$$\nUsing the identity $(MNP)^T = P^T N^T M^T$, we can recognize the term $B^T((zI - A)^{-1})^T C^T$ as the transpose of a product:\n$$\nB^T((zI - A)^{-1})^T C^T = (C(zI - A)^{-1}B)^T\n$$\nTherefore, the transfer function of the transposed system is:\n$$\n\\tilde{H}(z) = (C(zI - A)^{-1}B)^T + D\n$$\nFor a SISO system, the term $C(zI - A)^{-1}B$ is a $1 \\times 1$ matrix, i.e., a scalar. A scalar is equal to its own transpose. Thus, $(C(zI - A)^{-1}B)^T = C(zI - A)^{-1}B$. This leads to the conclusion:\n$$\n\\tilde{H}(z) = H(z)\n$$\nSince the transfer functions of the original and transposed systems are identical, their impulse responses must also be identical. The impulse response, $\\{h[k]\\}_{k=0}^{\\infty}$, is the inverse Z-transform of the transfer function $H(z)$. The problem requires a numerical verification of this theoretical fact, $y[k] = \\tilde{y}[k]$ for a unit impulse input, by direct simulation over a finite time horizon $N=12$.\n\nThe simulation procedure is as follows for each test case $(A, B, C, D)$:\n$1$. Define the simulation parameters: number of steps $N=12$ and tolerance $\\tau=10^{-11}$.\n$2$. Construct the original system matrices $(A, B, C, D)$ and the transposed system matrices $(\\tilde{A}, \\tilde{B}, \\tilde{C}, \\tilde{D}) = (A^T, C^T, B^T, D)$.\n$3$. Initialize the state vectors for both systems to zero: $x[0] = \\mathbf{0}$ and $\\tilde{x}[0] = \\mathbf{0}$. These are vectors in $\\mathbb{R}^2$.\n$4$. Define the unit impulse input: $u[0] = 1$ and $u[k] = 0$ for $k \\in \\{1, 2, \\dots, N-1\\}$.\n$5$. Simulate both systems iteratively for $k$ from $0$ to $N-1$:\n   a. Compute the outputs at step $k$:\n      - $y[k] = C x[k] + D u[k]$\n      - $\\tilde{y}[k] = \\tilde{C} \\tilde{x}[k] + \\tilde{D} u[k]$\n   b. Store $y[k]$ and $\\tilde{y}[k]$ in their respective output sequences.\n   c. Compute the next states for step $k+1$:\n      - $x[k+1] = A x[k] + B u[k]$\n      - $\\tilde{x}[k+1] = \\tilde{A} \\tilde{x}[k] + \\tilde{B} u[k]$\n$6$. After completing the simulation for $N$ steps, compute the maximum absolute difference between the two output sequences:\n$$\n\\Delta_{\\max} = \\max_{0 \\le k \\le N-1} |y[k] - \\tilde{y}[k]|\n$$\n$7$. The verification is successful if $\\Delta_{\\max} \\le \\tau$. The result for the test case is $\\mathrm{True}$ if this condition holds, and $\\mathrm{False}$ otherwise. Any observed non-zero difference is attributable to floating-point numerical errors, which are expected to be well below the specified tolerance $\\tau$.\n\nThis procedure is applied to all four specified test cases. Based on the theory, the expected result for all four cases is $\\mathrm{True}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate(A, B, C, D, N, u_seq):\n    \"\"\"\n    Simulates the output of a discrete-time LTI state-space system.\n\n    Args:\n        A (np.ndarray): State matrix (n x n).\n        B (np.ndarray): Input matrix (n x 1).\n        C (np.ndarray): Output matrix (1 x n).\n        D (float): Direct feedthrough scalar.\n        N (int): Number of time steps to simulate.\n        u_seq (np.ndarray): Input signal sequence of length N.\n\n    Returns:\n        np.ndarray: The output sequence y[k] for k=0 to N-1.\n    \"\"\"\n    n = A.shape[0]\n    x = np.zeros((n, 1))\n    y_seq = np.zeros(N)\n\n    for k in range(N):\n        # Calculate output y[k]\n        y_k = C @ x + D * u_seq[k]\n        y_seq[k] = y_k.item()\n        \n        # Update state to x[k+1]\n        x = A @ x + B * u_seq[k]\n        \n    return y_seq\n\n\ndef solve():\n    \"\"\"\n    Solves the problem by verifying the equivalence of impulse responses for\n    four LTI systems and their transpositions.\n    \"\"\"\n    # Define problem parameters\n    N = 12\n    tau = 1e-11\n\n    # Define the unit impulse input sequence\n    u_impulse = np.zeros(N)\n    u_impulse[0] = 1.0\n\n    # Define the four test cases\n    test_cases = [\n        # Test case 1 (strictly proper, stable)\n        {\n            \"A\": np.array([[0.7, 0.2], [-0.1, 0.9]]),\n            \"B\": np.array([[1.0], [0.5]]),\n            \"C\": np.array([[0.3, -0.4]]),\n            \"D\": 0.0,\n        },\n        # Test case 2 (nonzero direct feedthrough D)\n        {\n            \"A\": np.array([[0.5, -0.3], [0.1, 0.4]]),\n            \"B\": np.array([[0.0], [1.0]]),\n            \"C\": np.array([[1.0, 0.2]]),\n            \"D\": 0.25,\n        },\n        # Test case 3 (repeated eigenvalue, Jordan form)\n        {\n            \"A\": np.array([[0.6, 1.0], [0.0, 0.6]]),\n            \"B\": np.array([[0.2], [0.3]]),\n            \"C\": np.array([[-0.5, 0.7]]),\n            \"D\": 0.0,\n        },\n        # Test case 4 (edge case with zero input-to-state coupling)\n        {\n            \"A\": np.array([[0.8, 0.0], [0.0, 0.8]]),\n            \"B\": np.array([[0.0], [0.0]]),\n            \"C\": np.array([[0.9, -0.1]]),\n            \"D\": -0.3,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        A, B, C, D = case[\"A\"], case[\"B\"], case[\"C\"], case[\"D\"]\n\n        # 1. Compute the transposed realization\n        At = A.T\n        Bt = C.T\n        Ct = B.T\n        Dt = D  # D is a scalar, so D.T = D\n\n        # 2. Simulate impulse response for both systems\n        y_original = simulate(A, B, C, D, N, u_impulse)\n        y_transposed = simulate(At, Bt, Ct, Dt, N, u_impulse)\n\n        # 3. Verify that the impulse responses are identical\n        max_diff = np.max(np.abs(y_original - y_transposed))\n        verification_result = max_diff <= tau\n        results.append(verification_result)\n\n    # Final print statement in the exact required format.\n    # The map(str,...) correctly converts Python's True/False to strings \"True\"/\"False\".\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2915280"}, {"introduction": "The power of state-space representation is matched by the subtlety of its manipulations. A frequent point of confusion is how to correctly apply the transposition theorem within the state-space framework $(A,B,C,D)$. This exercise is designed to eliminate this ambiguity by contrasting the correct transposed system $(A^T, C^T, B^T, D^T)$ with a naively modified system that only transposes the $A$ matrix, demonstrating mathematically why the former preserves the transfer function while the latter does not [@problem_id:2915308].", "problem": "A common misconception when implementing transposed direct form structures is to treat transposition of the signal flow graph (SFG) as mere matrix transposition of only the state transition matrix. To clarify the distinction, consider the single-input single-output (SISO) discrete-time linear time-invariant (LTI) state-space system\n$$\nx[n+1] = A x[n] + B u[n], \\quad y[n] = C x[n] + D u[n],\n$$\nwith\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ -\\frac{9}{25} & \\frac{6}{5} \\end{pmatrix},\\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix},\\quad D = 0.\n$$\nStarting from the fundamental definition that the transfer function is the ratio of the unilateral $Z$-transforms of the output and input under zero initial conditions, derive the transfer function $H(z)$ of the given system. Then, using only the definition of SFG transposition (reverse all directed edges and interchange summing and branching nodes, while exchanging the external input and output), determine the corresponding state-space quadruple produced by SFG transposition and show that it realizes the same $H(z)$.\n\nNow construct the naive realization that replaces only the state transition matrix by its transpose while keeping the other matrices unchanged, namely\n$$\n\\tilde{A} = A^{T},\\quad \\tilde{B} = B,\\quad \\tilde{C} = C,\\quad \\tilde{D} = D,\n$$\nand derive its transfer function $\\tilde{H}(z)$ from first principles.\n\nExpress your final answer as a single rational function of $z$ with integer coefficients in the numerator and denominator. No rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and contains all necessary information for a unique mathematical solution. It is based on established principles of linear time-invariant (LTI) systems theory, specifically state-space representation, transfer functions, and signal flow graph (SFG) transposition. The problem is therefore deemed valid and a solution will be provided.\n\nThe problem asks for the derivation of several transfer functions from discrete-time LTI state-space representations. The fundamental relationship between a state-space representation $(A, B, C, D)$ and its transfer function $H(z)$ is given by the formula:\n$$\nH(z) = C(zI - A)^{-1}B + D\n$$\nwhere $I$ is the identity matrix of appropriate dimension. This formula is derived by taking the unilateral $Z$-transform of the state and output equations under the assumption of zero initial conditions.\n\nFirst, we derive the transfer function $H(z)$ for the given system:\n$$\nA = \\begin{pmatrix} 0 & 1 \\\\ -\\frac{9}{25} & \\frac{6}{5} \\end{pmatrix},\\quad B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\\quad C = \\begin{pmatrix} 1 & 0 \\end{pmatrix},\\quad D = 0.\n$$\nWe begin by computing the matrix $(zI - A)$:\n$$\nzI - A = z\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 0 & 1 \\\\ -\\frac{9}{25} & \\frac{6}{5} \\end{pmatrix} = \\begin{pmatrix} z & -1 \\\\ \\frac{9}{25} & z - \\frac{6}{5} \\end{pmatrix}.\n$$\nThe determinant of this matrix is:\n$$\n\\det(zI - A) = z\\left(z - \\frac{6}{5}\\right) - (-1)\\left(\\frac{9}{25}\\right) = z^2 - \\frac{6}{5}z + \\frac{9}{25}.\n$$\nThe inverse matrix $(zI-A)^{-1}$ is then:\n$$\n(zI - A)^{-1} = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} z - \\frac{6}{5} & 1 \\\\ -\\frac{9}{25} & z \\end{pmatrix}.\n$$\nNow, we can compute the transfer function $H(z)$:\n$$\nH(z) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\left( \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} z - \\frac{6}{5} & 1 \\\\ -\\frac{9}{25} & z \\end{pmatrix} \\right) \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} + 0\n$$\n$$\nH(z) = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} (z - \\frac{6}{5})(0) + (1)(1) \\\\ (-\\frac{9}{25})(0) + (z)(1) \\end{pmatrix}\n$$\n$$\nH(z) = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ z \\end{pmatrix} = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}}.\n$$\nNext, we consider the system obtained by correct SFG transposition. The state-space quadruple $(A_t, B_t, C_t, D_t)$ of a transposed system is related to the original system $(A, B, C, D)$ by $A_t = A^T$, $B_t = C^T$, $C_t = B^T$, and $D_t = D$.\nFor the given system, this yields:\n$$\nA_t = A^T = \\begin{pmatrix} 0 & -\\frac{9}{25} \\\\ 1 & \\frac{6}{5} \\end{pmatrix}, \\quad B_t = C^T = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad C_t = B^T = \\begin{pmatrix} 0 & 1 \\end{pmatrix}, \\quad D_t = D = 0.\n$$\nThe transfer function of this transposed system, let us call it $H_t(z)$, is given by $H_t(z) = C_t(zI - A_t)^{-1}B_t + D_t$. We have $\\det(zI - A_t) = \\det((zI - A)^T) = \\det(zI - A) = z^2 - \\frac{6}{5}z + \\frac{9}{25}$.\n$$\n(zI - A_t)^{-1} = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} z - \\frac{6}{5} & -\\frac{9}{25} \\\\ 1 & z \\end{pmatrix}.\n$$\n$$\nH_t(z) = \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\left( \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} z - \\frac{6}{5} & -\\frac{9}{25} \\\\ 1 & z \\end{pmatrix} \\right) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n$$\n$$\nH_t(z) = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\begin{pmatrix} z - \\frac{6}{5} \\\\ 1 \\end{pmatrix} = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}}.\n$$\nAs expected, $H_t(z) = H(z)$, confirming that SFG transposition preserves the transfer function.\n\nFinally, we analyze the \"naive\" realization, denoted by the quadruple $(\\tilde{A}, \\tilde{B}, \\tilde{C}, \\tilde{D})$, where:\n$$\n\\tilde{A} = A^{T} = \\begin{pmatrix} 0 & -\\frac{9}{25} \\\\ 1 & \\frac{6}{5} \\end{pmatrix},\\quad \\tilde{B} = B = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix},\\quad \\tilde{C} = C = \\begin{pmatrix} 1 & 0 \\end{pmatrix},\\quad \\tilde{D} = D = 0.\n$$\nWe derive its transfer function $\\tilde{H}(z) = \\tilde{C}(zI - \\tilde{A})^{-1}\\tilde{B} + \\tilde{D}$. The matrix $(zI - \\tilde{A})^{-1}$ is the same as $(zI - A_t)^{-1}$ calculated previously.\n$$\n\\tilde{H}(z) = \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\left( \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} z - \\frac{6}{5} & -\\frac{9}{25} \\\\ 1 & z \\end{pmatrix} \\right) \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\tilde{H}(z) = \\frac{1}{z^2 - \\frac{6}{5}z + \\frac{9}{25}} \\begin{pmatrix} 1 & 0 \\end{pmatrix} \\begin{pmatrix} -\\frac{9}{25} \\\\ z \\end{pmatrix}\n$$\n$$\n\\tilde{H}(z) = \\frac{-\\frac{9}{25}}{z^2 - \\frac{6}{5}z + \\frac{9}{25}}.\n$$\nThis clearly differs from $H(z)$, demonstrating the fallacy of the naive approach. To express this result as a rational function with integer coefficients, we multiply the numerator and denominator by $25$:\n$$\n\\tilde{H}(z) = \\frac{25 \\times (-\\frac{9}{25})}{25 \\times (z^2 - \\frac{6}{5}z + \\frac{9}{25})} = \\frac{-9}{25z^2 - 25(\\frac{6}{5})z + 25(\\frac{9}{25})} = \\frac{-9}{25z^2 - 30z + 9}.\n$$\nThis is the transfer function of the naively constructed system.", "answer": "$$\n\\boxed{\\frac{-9}{25z^2 - 30z + 9}}\n$$", "id": "2915308"}]}