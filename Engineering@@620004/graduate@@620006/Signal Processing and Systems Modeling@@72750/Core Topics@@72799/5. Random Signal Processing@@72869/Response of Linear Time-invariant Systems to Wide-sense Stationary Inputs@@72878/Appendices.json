{"hands_on_practices": [{"introduction": "Understanding how a linear time-invariant (LTI) system transforms a random signal is a cornerstone of signal processing. This first exercise guides you through the fundamental derivation of the output power spectral density (PSD), $S_y(\\omega)$, when the input is idealized white noise—a common model for thermal noise and other random phenomena. By deriving the relationship $S_y(\\omega) = \\sigma_w^2 |H(\\omega)|^2$ from first principles and then calculating the total output power, you will solidify your understanding of the link between a system's frequency response, $H(\\omega)$, and the statistical properties of its output [@problem_id:2901260].", "problem": "Consider a continuous-time, linear time-invariant system with impulse response $h(t)$ and frequency response $H(\\omega)$ defined by the Fourier transform convention\n$$\nH(\\omega) \\triangleq \\int_{-\\infty}^{\\infty} h(t)\\,\\exp(-j\\omega t)\\,dt,\\quad\nh(t) \\triangleq \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} H(\\omega)\\,\\exp(j\\omega t)\\,d\\omega.\n$$\nLet the system be strictly stable and proper with\n$$\nH(\\omega)=\\frac{1}{\\bigl(1+j\\,\\omega/\\omega_{1}\\bigr)\\bigl(1+j\\,\\omega/\\omega_{2}\\bigr)},\n$$\nwhere $\\omega_{1}>0$ and $\\omega_{2}>0$ are distinct real constants. The input $w(t)$ is a zero-mean wide-sense stationary process with constant power spectral density $S_{w}(\\omega)=\\sigma_{w}^{2}$ for all real $\\omega$, where $\\sigma_{w}^{2}>0$. The output is $y(t)=(h*w)(t)$.\n\nUsing only the definitions of autocorrelation $R_{x}(\\tau)\\triangleq \\mathbb{E}\\{x(t)\\,x(t+\\tau)\\}$, power spectral density $S_{x}(\\omega)\\triangleq \\int_{-\\infty}^{\\infty} R_{x}(\\tau)\\,\\exp(-j\\omega\\tau)\\,d\\tau$, the above Fourier transform convention, and linear time-invariance, perform the following:\n\n- Derive from first principles an expression for $S_{y}(\\omega)$ in terms of $H(\\omega)$ and $\\sigma_{w}^{2}$, without invoking pre-stated filtering theorems.\n- Then, compute the output variance $\\sigma_{y}^{2}\\triangleq R_{y}(0)$ exactly by evaluating\n$$\n\\sigma_{y}^{2}=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} S_{y}(\\omega)\\,d\\omega\n$$\nvia direct integration of $\\lvert H(\\omega)\\rvert^{2}$. Express your final answer as a closed-form analytic expression in terms of $\\sigma_{w}^{2}$, $\\omega_{1}$, and $\\omega_{2}$.", "solution": "The problem as stated is subjected to validation.\n\nGivens are extracted verbatim:\n- System: Continuous-time, linear time-invariant (LTI).\n- Impulse response: $h(t)$.\n- Frequency response: $H(\\omega) \\triangleq \\int_{-\\infty}^{\\infty} h(t)\\,\\exp(-j\\omega t)\\,dt$.\n- Inverse Fourier transform: $h(t) \\triangleq \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} H(\\omega)\\,\\exp(j\\omega t)\\,d\\omega$.\n- System properties: Strictly stable and proper.\n- Specific $H(\\omega)$: $H(\\omega)=\\frac{1}{\\bigl(1+j\\,\\omega/\\omega_{1}\\bigr)\\bigl(1+j\\,\\omega/\\omega_{2}\\bigr)}$, where $\\omega_{1}>0$, $\\omega_{2}>0$ are distinct real constants.\n- Input: $w(t)$ is a zero-mean, wide-sense stationary (WSS) process.\n- Input power spectral density (PSD): $S_{w}(\\omega)=\\sigma_{w}^{2}$ for all real $\\omega$, where $\\sigma_{w}^{2}>0$.\n- Output: $y(t)=(h*w)(t)$.\n- Autocorrelation definition: $R_{x}(\\tau)\\triangleq \\mathbb{E}\\{x(t)\\,x(t+\\tau)\\}$.\n- PSD definition: $S_{x}(\\omega)\\triangleq \\int_{-\\infty}^{\\infty} R_{x}(\\tau)\\,\\exp(-j\\omega\\tau)\\,d\\tau$.\n- Task 1: Derive from first principles an expression for $S_{y}(\\omega)$ in terms of $H(\\omega)$ and $\\sigma_{w}^{2}$.\n- Task 2: Compute the output variance $\\sigma_{y}^{2}\\triangleq R_{y}(0)$ by evaluating $\\sigma_{y}^{2}=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} S_{y}(\\omega)\\,d\\omega$ via direct integration of $\\lvert H(\\omega)\\rvert^{2}$.\n- Task 3: Express the final answer as a closed-form analytic expression in terms of $\\sigma_{w}^{2}$, $\\omega_{1}$, and $\\omega_{2}$.\n\nValidation verdict:\nThe problem is scientifically grounded, well-posed, and objective. It is based on fundamental principles of linear systems theory and stochastic processes. The input model of white noise, while physically an idealization, is a standard and valid construct in this academic context. All definitions, constraints, and objectives are clearly stated and consistent. The problem is therefore deemed **valid** and a solution will be provided.\n\nThe solution proceeds in two parts as requested.\n\nPart 1: Derivation of the output power spectral density $S_{y}(\\omega)$.\n\nThe output $y(t)$ of the LTI system is the convolution of the impulse response $h(t)$ and the input signal $w(t)$:\n$$\ny(t) = (h*w)(t) = \\int_{-\\infty}^{\\infty} h(\\alpha)\\,w(t-\\alpha)\\,d\\alpha\n$$\nThe autocorrelation of the output process $y(t)$ is defined as $R_{y}(\\tau) \\triangleq \\mathbb{E}\\{y(t)\\,y(t+\\tau)\\}$. We substitute the convolution integral for $y(t)$ and $y(t+\\tau)$:\n$$\ny(t+\\tau) = \\int_{-\\infty}^{\\infty} h(\\beta)\\,w(t+\\tau-\\beta)\\,d\\beta\n$$\nThen, the autocorrelation is:\n$$\nR_{y}(\\tau) = \\mathbb{E}\\left\\{ \\left( \\int_{-\\infty}^{\\infty} h(\\alpha)\\,w(t-\\alpha)\\,d\\alpha \\right) \\left( \\int_{-\\infty}^{\\infty} h(\\beta)\\,w(t+\\tau-\\beta)\\,d\\beta \\right) \\right\\}\n$$\nAssuming the impulse response $h(t)$ is deterministic, we can move the expectation operator inside the integrals:\n$$\nR_{y}(\\tau) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(\\alpha)\\,h(\\beta)\\,\\mathbb{E}\\{w(t-\\alpha)\\,w(t+\\tau-\\beta)\\}\\,d\\alpha\\,d\\beta\n$$\nThe expectation term is the autocorrelation of the input process $w(t)$, which is wide-sense stationary. Thus, its autocorrelation depends only on the time difference $(t+\\tau-\\beta) - (t-\\alpha) = \\tau - \\beta + \\alpha$.\n$$\n\\mathbb{E}\\{w(t-\\alpha)\\,w(t+\\tau-\\beta)\\} = R_{w}(\\tau - \\beta + \\alpha)\n$$\nSubstituting this into the expression for $R_{y}(\\tau)$:\n$$\nR_{y}(\\tau) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(\\alpha)\\,h(\\beta)\\,R_{w}(\\tau - \\beta + \\alpha)\\,d\\alpha\\,d\\beta\n$$\nThe output power spectral density $S_{y}(\\omega)$ is the Fourier transform of $R_{y}(\\tau)$:\n$$\nS_{y}(\\omega) = \\int_{-\\infty}^{\\infty} R_{y}(\\tau)\\,\\exp(-j\\omega\\tau)\\,d\\tau = \\int_{-\\infty}^{\\infty} \\left( \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(\\alpha)\\,h(\\beta)\\,R_{w}(\\tau - \\beta + \\alpha)\\,d\\alpha\\,d\\beta \\right) \\exp(-j\\omega\\tau)\\,d\\tau\n$$\nWe interchange the order of integration:\n$$\nS_{y}(\\omega) = \\int_{-\\infty}^{\\infty} h(\\alpha) \\int_{-\\infty}^{\\infty} h(\\beta) \\left( \\int_{-\\infty}^{\\infty} R_{w}(\\tau - \\beta + \\alpha)\\,\\exp(-j\\omega\\tau)\\,d\\tau \\right) d\\beta\\,d\\alpha\n$$\nLet us analyze the innermost integral. We perform a change of variable $u = \\tau - \\beta + \\alpha$, which implies $\\tau = u + \\beta - \\alpha$.\n$$\n\\int_{-\\infty}^{\\infty} R_{w}(u)\\,\\exp(-j\\omega(u+\\beta-\\alpha))\\,du = \\exp(j\\omega\\alpha)\\,\\exp(-j\\omega\\beta) \\int_{-\\infty}^{\\infty} R_{w}(u)\\,\\exp(-j\\omega u)\\,du\n$$\nThe integral on the right is the definition of the input power spectral density, $S_{w}(\\omega)$. So, the expression becomes $\\exp(j\\omega\\alpha)\\,\\exp(-j\\omega\\beta)\\,S_{w}(\\omega)$.\nSubstituting this back into the expression for $S_{y}(\\omega)$:\n$$\nS_{y}(\\omega) = \\int_{-\\infty}^{\\infty} h(\\alpha) \\int_{-\\infty}^{\\infty} h(\\beta) \\, \\exp(j\\omega\\alpha)\\,\\exp(-j\\omega\\beta)\\,S_{w}(\\omega) \\,d\\beta\\,d\\alpha\n$$\nWe can factor out terms not dependent on the variables of integration:\n$$\nS_{y}(\\omega) = S_{w}(\\omega) \\left( \\int_{-\\infty}^{\\infty} h(\\alpha)\\,\\exp(j\\omega\\alpha)\\,d\\alpha \\right) \\left( \\int_{-\\infty}^{\\infty} h(\\beta)\\,\\exp(-j\\omega\\beta)\\,d\\beta \\right)\n$$\nThe second integral is the definition of the frequency response $H(\\omega)$. The first integral is $\\int_{-\\infty}^{\\infty} h(\\alpha)\\,\\exp(-j(-\\omega)\\alpha)\\,d\\alpha = H(-\\omega)$.\nTherefore, we obtain the general relation:\n$$\nS_{y}(\\omega) = S_{w}(\\omega)\\,H(-\\omega)\\,H(\\omega)\n$$\nFor a physical system, the impulse response $h(t)$ is real-valued. For a real function, its Fourier transform exhibits conjugate symmetry, i.e., $H(-\\omega) = H^{*}(\\omega)$, where the asterisk denotes the complex conjugate. Thus, $H(-\\omega)H(\\omega) = H^{*}(\\omega)H(\\omega) = |H(\\omega)|^{2}$.\nThe input is given as white noise with $S_{w}(\\omega) = \\sigma_{w}^{2}$. The output PSD is:\n$$\nS_{y}(\\omega) = \\sigma_{w}^{2}\\,|H(\\omega)|^{2}\n$$\nThis completes the first part of the problem.\n\nPart 2: Calculation of the output variance $\\sigma_{y}^{2}$.\n\nThe output variance is given by $\\sigma_{y}^{2} = R_{y}(0)$. Using the inverse Fourier transform relation for the autocorrelation function, $R_{y}(\\tau) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} S_{y}(\\omega)\\,\\exp(j\\omega\\tau)\\,d\\omega$, we set $\\tau=0$:\n$$\n\\sigma_{y}^{2} = R_{y}(0) = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} S_{y}(\\omega)\\,d\\omega\n$$\nSubstituting the derived expression for $S_{y}(\\omega)$:\n$$\n\\sigma_{y}^{2} = \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\sigma_{w}^{2}\\,|H(\\omega)|^{2}\\,d\\omega = \\frac{\\sigma_{w}^{2}}{2\\pi}\\int_{-\\infty}^{\\infty} |H(\\omega)|^{2}\\,d\\omega\n$$\nWe must now calculate $|H(\\omega)|^{2}$ from the given $H(\\omega)$:\n$$\nH(\\omega) = \\frac{1}{\\bigl(1+j\\,\\omega/\\omega_{1}\\bigr)\\bigl(1+j\\,\\omega/\\omega_{2}\\bigr)}\n$$\n$$\n|H(\\omega)|^{2} = H(\\omega)H^{*}(\\omega) = \\frac{1}{\\bigl(1+j\\,\\omega/\\omega_{1}\\bigr)\\bigl(1+j\\,\\omega/\\omega_{2}\\bigr)} \\cdot \\frac{1}{\\bigl(1-j\\,\\omega/\\omega_{1}\\bigr)\\bigl(1-j\\,\\omega/\\omega_{2}\\bigr)}\n$$\n$$\n|H(\\omega)|^{2} = \\frac{1}{\\left(1 + \\frac{\\omega^{2}}{\\omega_{1}^{2}}\\right)\\left(1 + \\frac{\\omega^{2}}{\\omega_{2}^{2}}\\right)} = \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{(\\omega_{1}^{2}+\\omega^{2})(\\omega_{2}^{2}+\\omega^{2})}\n$$\nThe integral to be computed is $I = \\int_{-\\infty}^{\\infty} \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{(\\omega_{1}^{2}+\\omega^{2})(\\omega_{2}^{2}+\\omega^{2})}\\,d\\omega$. We use partial fraction expansion for the integrand with respect to the variable $\\omega^2$. Let the integrand be $f(\\omega)$.\n$$\nf(\\omega) = \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{(\\omega_{1}^{2}+\\omega^{2})(\\omega_{2}^{2}+\\omega^{2})} = \\frac{A}{\\omega_{1}^{2}+\\omega^{2}} + \\frac{B}{\\omega_{2}^{2}+\\omega^{2}}\n$$\nMultiplying by the common denominator yields:\n$$\n\\omega_{1}^{2}\\omega_{2}^{2} = A(\\omega_{2}^{2}+\\omega^{2}) + B(\\omega_{1}^{2}+\\omega^{2}) = (A+B)\\omega^{2} + (A\\omega_{2}^{2}+B\\omega_{1}^{2})\n$$\nBy comparing coefficients of powers of $\\omega^{2}$, we get a system of linear equations:\n1. $A+B = 0 \\implies B = -A$\n2. $A\\omega_{2}^{2}+B\\omega_{1}^{2} = \\omega_{1}^{2}\\omega_{2}^{2}$\nSubstituting $B=-A$ into the second equation:\n$A\\omega_{2}^{2}-A\\omega_{1}^{2} = \\omega_{1}^{2}\\omega_{2}^{2} \\implies A(\\omega_{2}^{2}-\\omega_{1}^{2}) = \\omega_{1}^{2}\\omega_{2}^{2}$.\nSince $\\omega_{1}$ and $\\omega_{2}$ are distinct, $\\omega_{1}^{2} \\neq \\omega_{2}^{2}$.\n$$\nA = \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{2}^{2}-\\omega_{1}^{2}} \\quad \\text{and} \\quad B = -A = \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{1}^{2}-\\omega_{2}^{2}}\n$$\nThe integral $I$ is now:\n$$\nI = \\int_{-\\infty}^{\\infty} \\left( \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{2}^{2}-\\omega_{1}^{2}} \\frac{1}{\\omega_{1}^{2}+\\omega^{2}} + \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{1}^{2}-\\omega_{2}^{2}} \\frac{1}{\\omega_{2}^{2}+\\omega^{2}} \\right) d\\omega\n$$\nWe use the standard integral formula $\\int_{-\\infty}^{\\infty} \\frac{dx}{a^{2}+x^{2}} = \\left[\\frac{1}{a}\\arctan\\left(\\frac{x}{a}\\right)\\right]_{-\\infty}^{\\infty} = \\frac{1}{a}(\\frac{\\pi}{2} - (-\\frac{\\pi}{2})) = \\frac{\\pi}{a}$ for $a>0$.\nHere, $\\omega_{1}>0$ and $\\omega_{2}>0$.\n$$\nI = \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{2}^{2}-\\omega_{1}^{2}} \\left( \\frac{\\pi}{\\omega_{1}} \\right) + \\frac{\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{1}^{2}-\\omega_{2}^{2}} \\left( \\frac{\\pi}{\\omega_{2}} \\right)\n$$\n$$\nI = \\frac{\\pi\\omega_{1}^{2}\\omega_{2}^{2}}{\\omega_{1}^{2}-\\omega_{2}^{2}} \\left( \\frac{1}{\\omega_{2}} - \\frac{1}{\\omega_{1}} \\right) = \\frac{\\pi\\omega_{1}^{2}\\omega_{2}^{2}}{(\\omega_{1}-\\omega_{2})(\\omega_{1}+\\omega_{2})} \\left( \\frac{\\omega_{1}-\\omega_{2}}{\\omega_{1}\\omega_{2}} \\right)\n$$\nCanceling the common terms $(\\omega_{1}-\\omega_{2})$ and $\\omega_{1}\\omega_{2}$:\n$$\nI = \\frac{\\pi\\omega_{1}\\omega_{2}}{\\omega_{1}+\\omega_{2}}\n$$\nFinally, we substitute this result into the expression for the output variance $\\sigma_{y}^{2}$:\n$$\n\\sigma_{y}^{2} = \\frac{\\sigma_{w}^{2}}{2\\pi} I = \\frac{\\sigma_{w}^{2}}{2\\pi} \\left( \\frac{\\pi\\omega_{1}\\omega_{2}}{\\omega_{1}+\\omega_{2}} \\right)\n$$\nThis simplifies to the final closed-form expression:\n$$\n\\sigma_{y}^{2} = \\frac{\\sigma_{w}^{2}\\omega_{1}\\omega_{2}}{2(\\omega_{1}+\\omega_{2})}\n$$\nThis expression is the exact output variance, as required.", "answer": "$$\n\\boxed{\\frac{\\sigma_{w}^{2}\\omega_{1}\\omega_{2}}{2(\\omega_{1}+\\omega_{2})}}\n$$", "id": "2901260"}, {"introduction": "Moving from analysis to synthesis is a critical step in engineering design. This practice problem challenges you to create an LTI filter that shapes the power spectrum of a given input signal, $S_x(\\omega)$, into a desired output spectrum, $S_y(\\omega)$. This task, central to fields like equalization and signal modeling, requires you to apply the design equation $|H(\\omega)|^2 = S_y(\\omega) / S_x(\\omega)$ and the technique of spectral factorization while adhering to physical constraints of causality and stability [@problem_id:2901273]. The exercise also prompts a crucial discussion on feasibility, illuminating the fundamental limitations of linear filtering.", "problem": "Consider a continuous-time wide-sense stationary (WSS) random process $x(t)$ with two-sided power spectral density $S_{x}(\\omega)$ given by\n$$\nS_{x}(\\omega) \\;=\\; \\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)},\n$$\nwhere $N_{0}>0$ is a constant. The signal is passed through a real, linear time-invariant (LTI), causal, stable filter with frequency response $H(\\omega)$ to produce an output $y(t)$. The design goal is that the output be WSS with the two-sided power spectral density\n$$\nS_{y}(\\omega) \\;=\\; \\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}.\n$$\n\nStarting from the definitions of autocorrelation and the Wiener–Khinchin theorem (which states that the power spectral density is the Fourier transform of the autocorrelation function), derive the relationship linking the input and output power spectral densities of an LTI system and use it to design a real-rational, causal, stable, minimum-phase $H(\\omega)$ that achieves the stated $S_{y}(\\omega)$ when driven by $x(t)$ with $S_{x}(\\omega)$ above. Provide $H(\\omega)$ explicitly.\n\nThen, suppose the desired output power spectral density were instead\n$$\n\\widetilde{S}_{y}(\\omega) \\;=\\; \\frac{N_{0}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}.\n$$\nDiscuss, using first principles, whether there exists any LTI filter with bounded frequency response magnitude that can achieve $\\widetilde{S}_{y}(\\omega)$ from the same input $S_{x}(\\omega)$, and articulate a necessary feasibility condition involving the zeros of $S_{x}(\\omega)$ and $\\widetilde{S}_{y}(\\omega)$. Your final answer must be the single closed-form expression of the designed $H(\\omega)$ corresponding to the original target $S_{y}(\\omega)$. No rounding is required, and no physical units should be included in the final answer.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n-   Input is a continuous-time wide-sense stationary (WSS) random process $x(t)$.\n-   Two-sided power spectral density (PSD) of the input: $S_{x}(\\omega) = \\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)}$, where $N_{0}>0$.\n-   The system is a real, linear time-invariant (LTI), causal, stable filter with frequency response $H(\\omega)$.\n-   The output process is $y(t)$.\n-   The desired two-sided PSD of the output is $S_{y}(\\omega) = \\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}$.\n-   The task is to design a real-rational, causal, stable, minimum-phase $H(\\omega)$ that achieves this transformation.\n-   A secondary problem considers an alternative desired output PSD $\\widetilde{S}_{y}(\\omega) = \\frac{N_{0}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}$ and asks for a feasibility analysis for a filter with a bounded frequency response magnitude.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded:** The problem uses standard concepts from stochastic processes and LTI systems theory, including WSS processes, power spectral densities, the Wiener–Khinchin theorem, and filter design principles (causality, stability, minimum-phase). The forms of the PSDs are physically realistic (real, even, non-negative functions of $\\omega$).\n-   **Well-Posed:** The problem is clearly defined. It provides all necessary information to determine a unique filter $H(\\omega)$ under the specified constraints (causal, stable, minimum-phase). The questions are structured and lead to a determinate solution and a logical discussion.\n-   **Objective:** The problem statement is formulated with precise, objective mathematical language.\n\n### Step 3: Verdict and Action\nThe problem is scientifically sound, well-posed, objective, and complete. It is deemed **valid**. A full solution will be provided.\n\nThe analysis proceeds in three parts as requested by the problem statement. First, we establish the fundamental relationship between the input and output power spectral densities for an LTI system. Second, we utilize this relationship to design the specified filter $H(\\omega)$. Third, we analyze the feasibility of achieving the alternative output PSD $\\widetilde{S}_{y}(\\omega)$.\n\nThe output $y(t)$ of an LTI system with impulse response $h(t)$ to an input $x(t)$ is given by the convolution integral:\n$$y(t) = \\int_{-\\infty}^{\\infty} h(\\alpha) x(t-\\alpha) \\,d\\alpha$$\nThe autocorrelation function of the output process, $R_{y}(\\tau)$, is defined as $R_{y}(\\tau) = E[y(t+\\tau)y^{*}(t)]$. Since the filter is real, the impulse response $h(t)$ is real, and the complex conjugate is not necessary.\n$$R_{y}(\\tau) = E\\left[ \\left( \\int_{-\\infty}^{\\infty} h(\\alpha) x(t+\\tau-\\alpha) \\,d\\alpha \\right) \\left( \\int_{-\\infty}^{\\infty} h(\\beta) x(t-\\beta) \\,d\\beta \\right) \\right]$$\nAssuming stochastic integrals converge appropriately, we can interchange expectation and integration:\n$$R_{y}(\\tau) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(\\alpha) h(\\beta) E[x(t+\\tau-\\alpha)x(t-\\beta)] \\,d\\alpha \\,d\\beta$$\nThe expectation term is the autocorrelation of the input process, $R_{x}(\\tau - \\alpha + \\beta)$, since $x(t)$ is WSS.\n$$R_{y}(\\tau) = \\int_{-\\infty}^{\\infty} h(\\beta) \\left( \\int_{-\\infty}^{\\infty} h(\\alpha) R_{x}((\\tau+\\beta)-\\alpha) \\,d\\alpha \\right) \\,d\\beta$$\nThe inner integral is the convolution of $h(\\tau)$ with $R_{x}(\\tau)$, evaluated at $\\tau+\\beta$. Let $g(\\tau) = (h * R_{x})(\\tau) = \\int_{-\\infty}^{\\infty} h(\\alpha) R_{x}(\\tau-\\alpha) \\,d\\alpha$. Then:\n$$R_{y}(\\tau) = \\int_{-\\infty}^{\\infty} h(\\beta) g(\\tau+\\beta) \\,d\\beta$$\nThis is the convolution of $g(\\tau)$ with $h(-\\tau)$. Thus, $R_{y}(\\tau) = (h(-\\tau) * g(\\tau)) = (h(-\\tau) * (h(\\tau) * R_{x}(\\tau)))$. Using the associative property of convolution, we have:\n$$R_{y}(\\tau) = (h(\\tau) * h(-\\tau)) * R_{x}(\\tau)$$\nThe Wiener–Khinchin theorem states that the power spectral density is the Fourier transform of the autocorrelation function. Taking the Fourier transform of the above equation and using the convolution theorem, we get:\n$$S_{y}(\\omega) = \\mathcal{F}\\{h(\\tau) * h(-\\tau)\\} \\cdot \\mathcal{F}\\{R_{x}(\\tau)\\}$$\nThe Fourier transform of $R_{x}(\\tau)$ is $S_{x}(\\omega)$. The Fourier transform of $h(\\tau)$ is $H(\\omega)$. The Fourier transform of $h(-\\tau)$ is $H(-\\omega)$. For a real impulse response $h(t)$, the frequency response has conjugate symmetry, $H(-\\omega) = H^{*}(\\omega)$. Therefore:\n$$\\mathcal{F}\\{h(\\tau) * h(-\\tau)\\} = H(\\omega) H(-\\omega) = H(\\omega) H^{*}(\\omega) = |H(\\omega)|^{2}$$\nThis establishes the required relationship:\n$$S_{y}(\\omega) = |H(\\omega)|^{2} S_{x}(\\omega)$$\nFrom this, we can determine the squared magnitude of the filter's frequency response:\n$$|H(\\omega)|^{2} = \\frac{S_{y}(\\omega)}{S_{x}(\\omega)}$$\nSubstituting the given expressions for $S_{x}(\\omega)$ and $S_{y}(\\omega)$:\n$$|H(\\omega)|^{2} = \\frac{\\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}}{\\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)}} = \\frac{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}$$\nNote that the factor $N_{0}\\omega^2$ cancels, which is valid for $\\omega \\neq 0$. The value at $\\omega=0$ is found by taking the limit, which is finite.\n\nTo find $H(\\omega)$, we perform spectral factorization. We relate the frequency response $H(\\omega)$ to the transfer function $H(s)$ via the substitution $s = j\\omega$, so $\\omega^2 = -s^2$. The squared magnitude response is given by $H(s)H(-s)$.\n$$H(s)H(-s) = \\frac{\\left(-s^{2}+1\\right)\\left(-s^{2}+9\\right)}{\\left(-s^{2}+4\\right)\\left(-s^{2}+16\\right)} = \\frac{\\left(s^{2}-1\\right)\\left(s^{2}-9\\right)}{\\left(s^{2}-4\\right)\\left(s^{2}-16\\right)}$$\n$$H(s)H(-s) = \\frac{(s-1)(s+1)(s-3)(s+3)}{(s-2)(s+2)(s-4)(s+4)}$$\nThe poles and zeros of $H(s)H(-s)$ are symmetrically located with respect to the $j\\omega$-axis.\n-   Poles are at $s = \\pm 2, \\pm 4$.\n-   Zeros are at $s = \\pm 1, \\pm 3$.\n\nThe filter must be causal and stable, which requires all its poles to be in the strict left-half of the s-plane (LHP). Therefore, the poles of $H(s)$ must be at $s = -2$ and $s = -4$.\nThe filter must also be minimum-phase, which requires all its zeros to be in the LHP. Therefore, the zeros of $H(s)$ must be at $s = -1$ and $s = -3$.\nBy combining these LHP poles and zeros, we construct the transfer function $H(s)$:\n$$H(s) = K \\frac{(s+1)(s+3)}{(s+2)(s+4)}$$\nwhere $K$ is a constant. The product $H(s)H(-s)$ becomes $K^2 \\frac{(s+1)(s-1)(s+3)(s-3)}{(s+2)(s-2)(s+4)(s-4)}$, which matches the derived expression if $K^2 = 1$. We select $K=1$ for a positive DC gain ($H(0) = 3/8 > 0$).\n$$H(s) = \\frac{(s+1)(s+3)}{(s+2)(s+4)}$$\nThe frequency response $H(\\omega)$ is obtained by substituting $s = j\\omega$:\n$$H(\\omega) = \\frac{(j\\omega+1)(j\\omega+3)}{(j\\omega+2)(j\\omega+4)}$$\nThis is the explicit expression for the required real-rational, causal, stable, and minimum-phase filter.\n\nFinally, we consider the feasibility of achieving the alternative output PSD:\n$$\\widetilde{S}_{y}(\\omega) = \\frac{N_{0}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}$$\nThe required squared magnitude response would be:\n$$|H(\\omega)|^{2} = \\frac{\\widetilde{S}_{y}(\\omega)}{S_{x}(\\omega)} = \\frac{\\frac{N_{0}}{\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}}{\\frac{N_{0}\\,\\omega^{2}}{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)}} = \\frac{\\left(\\omega^{2}+1\\right)\\left(\\omega^{2}+9\\right)}{\\omega^{2}\\left(\\omega^{2}+4\\right)\\left(\\omega^{2}+16\\right)}$$\nWe investigate the behavior of $|H(\\omega)|^{2}$ as $\\omega \\to 0$:\n$$\\lim_{\\omega \\to 0} |H(\\omega)|^{2} = \\lim_{\\omega \\to 0} \\frac{(1)(9)}{\\omega^{2}(4)(16)} = \\lim_{\\omega \\to 0} \\frac{9}{64\\omega^{2}} = \\infty$$\nSince $|H(\\omega)|$ is unbounded as $\\omega \\to 0$, no LTI filter with a bounded frequency response magnitude can achieve this transformation.\n\nThe underlying principle can be articulated as a necessary feasibility condition. The relation $S_{y}(\\omega) = |H(\\omega)|^{2} S_{x}(\\omega)$ implies that if a filter has a bounded frequency response, $|H(\\omega)| \\leq M  \\infty$ for all $\\omega$, then any frequency $\\omega_0$ at which the input PSD is zero ($S_{x}(\\omega_0) = 0$) must also be a frequency at which the output PSD is zero ($S_{y}(\\omega_0) = |H(\\omega_0)|^2 \\cdot 0 = 0$).\nIn formal terms, a necessary condition for a bounded-response LTI filter to transform an input PSD $S_x(\\omega)$ to an output PSD $S_y(\\omega)$ is that the set of zeros of $S_y(\\omega)$ must be a superset of the set of zeros of $S_x(\\omega)$.\nIn this specific case, the input PSD $S_{x}(\\omega)$ has a zero of order $2$ at $\\omega=0$, as evidenced by the $\\omega^2$ term. However, the desired alternative output PSD $\\widetilde{S}_{y}(\\omega)$ is non-zero at $\\omega=0$: $\\widetilde{S}_{y}(0) = N_{0}/64 > 0$. The filter would need to create energy at a frequency where the input possesses none, which is impossible for an LTI system with a finite gain at that frequency. Therefore, no such filter exists.", "answer": "$$\n\\boxed{\\frac{(j\\omega+1)(j\\omega+3)}{(j\\omega+2)(j\\omega+4)}}\n$$", "id": "2901273"}, {"introduction": "This computational exercise bridges the gap between theoretical equations and practical implementation. While the relationship $|H(\\omega)|^2 = S_y(\\omega) / S_x(\\omega)$ is straightforward, its direct numerical application is fraught with peril, especially when the input signal has very little energy at certain frequencies. This hands-on coding task will demonstrate the instability of naive spectral division and introduce regularization as a robust, practical solution for system identification, a technique vital for obtaining meaningful results from real-world data [@problem_id:2901279].", "problem": "You are given a scenario involving the response of a linear time-invariant (LTI) system to a wide-sense stationary (WSS) input. Let the input process be denoted by $x(t)$ with power spectral density (PSD) $S_{x}(\\omega)$, the impulse response of the system by $h(t)$ with frequency response $H(\\omega)$, and the output process by $y(t)$ with PSD $S_{y}(\\omega)$. Starting from first principles, use the definitions of autocorrelation and the Fourier transform relationship between autocorrelation and power spectral density to derive an expression for the magnitude of the frequency response $|H(\\omega)|$ in terms of $S_{x}(\\omega)$ and $S_{y}(\\omega)$ at frequencies where $S_{x}(\\omega)$ is strictly positive. Then, design a numerically stable algorithm to estimate $|H(\\omega)|$ when $S_{x}(\\omega)$ contains deep notches (very small values) that can cause numerical instability during spectral division.\n\nYour program must implement the following tasks:\n\n- Derive and justify a method to estimate $|H(\\omega)|$ from $S_{x}(\\omega)$ and $S_{y}(\\omega)$ using a principle-based path starting from the definitions of autocorrelation and linear time-invariance, without relying on any unstated assumptions. Provide a clear stability argument when $S_{x}(\\omega)$ has deep notches.\n- Implement two estimators on a common angular frequency grid $\\omega \\in [-\\Omega_{\\max}, \\Omega_{\\max}]$ with $N$ uniformly spaced samples:\n  - A naive estimator based on direct spectral division.\n  - A regularized estimator that avoids instability by adding a stabilizing term to the denominator and optionally smoothing the result in frequency.\n- Use the following test suite of synthetic cases. In each case, construct $S_{x}(\\omega)$ and a true nonnegative magnitude $|H_{\\text{true}}(\\omega)|$; then produce $S_{y}(\\omega)$ in a manner consistent with the foundational definitions relating WSS inputs and LTI system outputs. Frequencies are in radians per second; no other physical units are needed and no other unit conversions are required. The angular frequency grid is defined by $N = 4096$ and $\\Omega_{\\max} = 50$.\n\n  Let $\\omega$ denote the vector of $N$ equally spaced samples in $[-\\Omega_{\\max}, \\Omega_{\\max}]$.\n\n  Common building blocks:\n  - Smooth input spectrum baseline:\n    $$S_{x,\\text{base}}(\\omega) = 1 + 0.5\\cos\\!\\left(\\frac{\\omega}{5}\\right) + 0.25\\,e^{-(\\omega/20)^2}.$$\n  - Second-order low-pass magnitude:\n    $$|H_{\\text{LP}}(\\omega)| = \\frac{1}{\\sqrt{1 + (\\omega/10)^4}}.$$\n  - Gaussian band-pass magnitude:\n    $$|H_{\\text{BP}}(\\omega)| = \\exp\\!\\left(-\\frac{(|\\omega| - 15)^2}{2\\cdot 3^2}\\right).$$\n  - Gaussian notch multiplier of depth $\\delta \\in (0,1)$ centered at $\\omega_n$ with width $\\sigma_n$:\n    $$N(\\omega;\\omega_n,\\sigma_n,\\delta) = 1 - (1 - \\delta)\\exp\\!\\left(-\\frac{(\\omega - \\omega_n)^2}{2\\sigma_n^2}\\right).$$\n\n  Test cases:\n  - Case A (happy path): $S_{x}^{(A)}(\\omega) = S_{x,\\text{base}}(\\omega)$ and $|H_{\\text{true}}^{(A)}(\\omega)| = |H_{\\text{LP}}(\\omega)|$. Construct $S_{y}^{(A)}(\\omega)$ accordingly.\n  - Case B (deep notch): $S_{x}^{(B)}(\\omega) = S_{x,\\text{base}}(\\omega)\\cdot N(\\omega; 10, 0.2, 10^{-10})$ and $|H_{\\text{true}}^{(B)}(\\omega)| = |H_{\\text{LP}}(\\omega)|$. Construct $S_{y}^{(B)}(\\omega)$ accordingly.\n  - Case C (noisy spectral estimate): $S_{x}^{(C)}(\\omega) = S_{x,\\text{base}}(\\omega)$ and $|H_{\\text{true}}^{(C)}(\\omega)| = |H_{\\text{BP}}(\\omega)|$. Construct $S_{y}^{(C)}(\\omega)$ accordingly, then add an artificial, nonnegative perturbation that mimics finite-sample spectral estimation variability by adding a smoothed, nonnegative noise floor whose overall scale is specified below.\n  - Case D (zero at a frequency): $S_{x}^{(D)}(\\omega) = \\omega^2 \\exp\\!\\left(-(\\omega/30)^2\\right)$ and $|H_{\\text{true}}^{(D)}(\\omega)| = |H_{\\text{LP}}(\\omega)|$. Construct $S_{y}^{(D)}(\\omega)$ accordingly.\n\n- Estimation specifics to implement for comparability:\n  - Naive estimator: for any case with spectra $(S_x(\\omega), S_y(\\omega))$, define the naive estimate where $S_x(\\omega)$ is strictly positive, and ignore (do not include in any error metric) frequency samples where $S_x(\\omega)$ is nonpositive.\n  - Regularized estimator: use an additive stabilization in the denominator with\n    $$\\varepsilon = \\epsilon_{\\text{rel}}\\cdot \\operatorname{median}_{\\omega} \\left\\{ S_x(\\omega) \\right\\},$$\n    and estimate using spectral division with $S_x(\\omega) + \\varepsilon$ in the denominator. Use the following relative stabilization values for the cases:\n    - Case B: $\\epsilon_{\\text{rel}} = 10^{-3}$.\n    - Case C: $\\epsilon_{\\text{rel}} = 5\\times 10^{-3}$ and apply frequency-domain smoothing to the estimated magnitude using a centered moving average of odd length $L = 41$ samples.\n    - Case D: $\\epsilon_{\\text{rel}} = 10^{-2}$.\n  - No smoothing is required for Case B and Case D. For Case C only, apply smoothing to the regularized estimate using the specified moving average length $L$.\n\n- Noise construction for Case C:\n  - After constructing the ideal $S_{y}^{(C)}(\\omega)$, add nonnegative perturbation\n    $$\\nu(\\omega) = \\alpha\\cdot \\operatorname{median}_{\\omega}\\{S_{y}^{(C)}(\\omega)\\}\\cdot u(\\omega),$$\n    where $u(\\omega)$ is obtained by taking the absolute value of a zero-mean, unit-variance Gaussian sequence of length $N$ and convolving it with a symmetric length-$21$ moving-average kernel normalized to unit sum. Use $\\alpha = 0.2$ and a fixed random seed to ensure reproducibility.\n\n- Error metrics to report:\n  - Let $\\widehat{|H|}_{\\text{naive}}(\\omega)$ denote the naive estimate and $\\widehat{|H|}_{\\text{reg}}(\\omega)$ denote the regularized (and smoothed, if applicable) estimate.\n  - For any case with true magnitude $|H_{\\text{true}}(\\omega)|$, compute the root-mean-square error (RMSE) over the set of frequencies where the estimate is defined and finite:\n    $$\\operatorname{RMSE} = \\sqrt{\\frac{1}{M}\\sum_{k=1}^{M}\\left(\\widehat{|H|}(\\omega_k) - |H_{\\text{true}}(\\omega_k)|\\right)^2}.$$\n\n- Required outputs:\n  - Compute the following floating-point values, in this order:\n    $$\n    \\begin{aligned}\n    r_1 := \\text{RMSE of } \\widehat{|H|}_{\\text{naive}} \\text{ for Case A},\\\\\n    r_2 := \\text{RMSE of } \\widehat{|H|}_{\\text{naive}} \\text{ for Case B},\\\\\n    r_3 := \\text{RMSE of } \\widehat{|H|}_{\\text{reg}} \\text{ for Case B},\\\\\n    r_4 := \\text{RMSE of } \\widehat{|H|}_{\\text{reg}} \\text{ for Case C},\\\\\n    r_5 := \\text{RMSE of } \\widehat{|H|}_{\\text{reg}} \\text{ for Case D}.\n    \\end{aligned}\n    $$\n  - Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, $[r_1,r_2,r_3,r_4,r_5]$).\n\nImplementation constraints:\n\n- Use $N = 4096$, $\\Omega_{\\max} = 50$.\n- Frequencies are in radians per second; all outputs are dimensionless.\n- The random seed for the noise in Case C must be fixed so that the results are reproducible.\n\nNote: The program must be self-contained, must not read input, and must not access external files or the network. It must use only the specified language and libraries. The final results must be numeric floats printed in the exact required format.", "solution": "The problem requires the derivation of an estimator for the magnitude of the frequency response, $|H(\\omega)|$, of a linear time-invariant (LTI) system, and a subsequent numerical implementation to compare a naive estimator with a regularized one under various conditions. The problem is well-posed and scientifically sound, pertaining to a fundamental concept in signal processing. We shall proceed with the derivation from first principles, followed by an analysis of the numerical algorithm.\n\nFirst, let us establish the relationship between the input and output power spectral densities (PSDs) of an LTI system. The output signal $y(t)$ of an LTI system with impulse response $h(t)$ to an input signal $x(t)$ is given by the convolution integral:\n$$\ny(t) = (h * x)(t) = \\int_{-\\infty}^{\\infty} h(\\alpha) x(t-\\alpha) d\\alpha\n$$\nThe input $x(t)$ is a wide-sense stationary (WSS) random process with autocorrelation function $R_{xx}(\\tau) = E[x(t)x(t+\\tau)]$. The output process $y(t)$ will also be WSS. Its autocorrelation function, $R_{yy}(\\tau)$, is defined as:\n$$\nR_{yy}(\\tau) = E[y(t)y(t+\\tau)]\n$$\nSubstituting the convolution integral for $y(t)$ and $y(t+\\tau)$:\n$$\nR_{yy}(\\tau) = E\\left[ \\left( \\int_{-\\infty}^{\\infty} h(\\alpha) x(t-\\alpha) d\\alpha \\right) \\left( \\int_{-\\infty}^{\\infty} h(\\beta) x(t+\\tau-\\beta) d\\beta \\right) \\right]\n$$\nBy linearity of the expectation operator, we can move it inside the integrals:\n$$\nR_{yy}(\\tau) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} h(\\alpha) h(\\beta) E[x(t-\\alpha)x(t+\\tau-\\beta)] d\\alpha d\\beta\n$$\nThe expectation term is the autocorrelation of $x(t)$ evaluated at a time lag of $(t+\\tau-\\beta) - (t-\\alpha) = \\tau - \\beta + \\alpha$. Thus, $E[x(t-\\alpha)x(t+\\tau-\\beta)] = R_{xx}(\\tau - \\beta + \\alpha)$.\n$$\nR_{yy}(\\tau) = \\int_{-\\infty}^{\\infty} h(\\beta) \\left( \\int_{-\\infty}^{\\infty} h(\\alpha) R_{xx}(\\tau + \\alpha - \\beta) d\\alpha \\right) d\\beta\n$$\nThis expression represents a series of convolutions. Let $g(t) = h(-t)$. The inner integral is equivalent to $(h*R_{xx})(\\tau-\\beta)$. The outer integral is then a convolution of this result with $g(\\beta) = h(-\\beta)$. Therefore, we can write the relationship in terms of convolution operations:\n$$\nR_{yy}(\\tau) = h(\\tau) * R_{xx}(\\tau) * h(-\\tau)\n$$\nTo find the relationship between the PSDs, we apply the Fourier transform, denoted by $\\mathcal{F}\\{\\cdot\\}$, to both sides. The power spectral density is defined as the Fourier transform of the autocorrelation function, so $S_x(\\omega) = \\mathcal{F}\\{R_{xx}(\\tau)\\}$ and $S_y(\\omega) = \\mathcal{F}\\{R_{yy}(\\tau)\\}$. Using the convolution theorem, which states that convolution in the time domain corresponds to multiplication in the frequency domain, we get:\n$$\nS_y(\\omega) = \\mathcal{F}\\{h(\\tau)\\} \\cdot \\mathcal{F}\\{R_{xx}(\\tau)\\} \\cdot \\mathcal{F}\\{h(-\\tau)\\}\n$$\nThe Fourier transform of the impulse response is the frequency response, $H(\\omega) = \\mathcal{F}\\{h(\\tau)\\}$. The time-reversal property of the Fourier transform states that $\\mathcal{F}\\{h(-\\tau)\\} = H^*(\\omega)$, where $H^*(\\omega)$ is the complex conjugate of $H(\\omega)$. Substituting these relations, we obtain the fundamental result:\n$$\nS_y(\\omega) = H(\\omega) S_x(\\omega) H^*(\\omega) = |H(\\omega)|^2 S_x(\\omega)\n$$\nThis is the Wiener-Khinchin theorem for LTI systems. From this equation, we can derive an expression for the magnitude of the frequency response, $|H(\\omega)|$. Provided that the input power spectral density $S_x(\\omega)$ is strictly positive, we can rearrange the equation:\n$$\n|H(\\omega)|^2 = \\frac{S_y(\\omega)}{S_x(\\omega)}\n$$\nSince $|H(\\omega)|$ must be a non-negative quantity, and the PSDs $S_x(\\omega)$ and $S_y(\\omega)$ are non-negative properties, we can take the square root of both sides to obtain the desired estimator:\n$$\n|H(\\omega)| = \\sqrt{\\frac{S_y(\\omega)}{S_x(\\omega)}}, \\quad \\text{for } S_x(\\omega)  0\n$$\nThis constitutes the \"naive\" estimator. Its validity is restricted to frequencies where there is power in the input signal.\n\nThe numerical instability of this naive estimator arises precisely at or near frequencies where $S_x(\\omega)$ is close to zero. In any practical scenario, the measured or estimated PSDs are subject to noise and finite precision errors. Let us model the measured output PSD as $\\hat{S}_y(\\omega) = S_y(\\omega) + \\nu(\\omega)$, where $\\nu(\\omega)$ is a non-negative noise term. The naive estimate becomes:\n$$\n\\widehat{|H|}(\\omega) = \\sqrt{\\frac{|H(\\omega)|^2 S_x(\\omega) + \\nu(\\omega)}{S_x(\\omega)}} = \\sqrt{|H(\\omega)|^2 + \\frac{\\nu(\\omega)}{S_x(\\omega)}}\n$$\nAs $S_x(\\omega) \\to 0$, the term $\\nu(\\omega)/S_x(\\omega)$ diverges, causing the estimate $\\widehat{|H|}(\\omega)$ to blow up. This is catastrophic for frequencies within a \"deep notch\" of the input spectrum.\n\nTo mitigate this, we introduce a regularized estimator. The principle is to prevent the denominator from reaching zero or very small values by adding a small positive constant, $\\varepsilon$. The regularized estimator for $|H(\\omega)|^2$ is:\n$$\n\\widehat{|H|^2}_{\\text{reg}}(\\omega) = \\frac{S_y(\\omega)}{S_x(\\omega) + \\varepsilon}\n$$\nThe corresponding magnitude estimate is $\\widehat{|H|}_{\\text{reg}}(\\omega) = \\sqrt{\\widehat{|H|^2}_{\\text{reg}}(\\omega)}$. In the presence of noise, this becomes:\n$$\n\\widehat{|H|}_{\\text{reg}}(\\omega) = \\sqrt{\\frac{|H(\\omega)|^2 S_x(\\omega) + \\nu(\\omega)}{S_x(\\omega) + \\varepsilon}}\n$$\nNow, as $S_x(\\omega) \\to 0$, the estimate approaches $\\sqrt{\\nu(\\omega)/\\varepsilon}$, which is a finite value. This regularization introduces a bias, as the estimate is systematically smaller than the true value, especially for small $S_x(\\omega)$. However, it drastically reduces the variance and avoids catastrophic failure, a classic example of the bias-variance tradeoff. The choice of $\\varepsilon$ is critical: if too large, it introduces excessive bias; if too small, it fails to stabilize the division. The problem suggests a data-driven choice $\\varepsilon = \\epsilon_{\\text{rel}} \\cdot \\operatorname{median}_{\\omega}\\{S_x(\\omega)\\}$, which scales the regularization strength to the overall power of the input signal.\n\nFor cases with significant noise in the spectral estimates (like Case C), the regularized estimate, while stable, will still be noisy. Applying a low-pass filter, such as a moving average, in the frequency domain can further improve the estimate by smoothing out high-frequency fluctuations caused by noise. This is justified if the true $|H(\\omega)|$ is smooth compared to the noise variations.\n\nThe implementation will proceed as follows:\n1.  Define the frequency grid $\\omega$ from $-\\Omega_{\\max}$ to $\\Omega_{\\max}$ with $N$ points.\n2.  For each test case (A, B, C, D), construct the true $|H_{\\text{true}}(\\omega)|$ and input spectrum $S_x(\\omega)$ using the provided formulas.\n3.  Calculate the ideal output spectrum $S_y(\\omega) = |H_{\\text{true}}(\\omega)|^2 S_x(\\omega)$.\n4.  For Case C, generate and add the specified non-negative noise term $\\nu(\\omega)$ to $S_y(\\omega)$.\n5.  Implement the naive estimator. Calculate its estimate $\\widehat{|H|}_{\\text{naive}}(\\omega)$ only for frequencies where $S_x(\\omega)  0$. Compute the Root-Mean-Square Error (RMSE) against $|H_{\\text{true}}(\\omega)|$ on this valid domain.\n6.  Implement the regularized estimator. Calculate the stabilization term $\\varepsilon$ based on the specified $\\epsilon_{\\text{rel}}$ and the median of $S_x(\\omega)$. Compute the estimate $\\widehat{|H|}_{\\text{reg}}(\\omega)$ for all frequencies. For Case C, apply an additional moving average filter of length $L=41$.\n7.  Compute the RMSE for the regularized estimator against $|H_{\\text{true}}(\\omega)|$ across all frequencies.\n8.  The final output will be a list of five specific RMSE values as requested: $\\text{RMSE}_{\\text{naive,A}}$, $\\text{RMSE}_{\\text{naive,B}}$, $\\text{RMSE}_{\\text{reg,B}}$, $\\text{RMSE}_{\\text{reg,C}}$, and $\\text{RMSE}_{\\text{reg,D}}$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LTI system identification problem by deriving and implementing\n    estimators for the magnitude of the frequency response.\n    \"\"\"\n    #\n    # === Problem Parameters ===\n    #\n    N = 4096\n    Omega_max = 50.0\n    # Fixed random seed for reproducibility of noise in Case C\n    RANDOM_SEED = 42\n\n    #\n    # === Frequency Grid ===\n    #\n    omega = np.linspace(-Omega_max, Omega_max, N)\n\n    #\n    # === Common Building Blocks ===\n    #\n    def S_x_base(w):\n        return 1.0 + 0.5 * np.cos(w / 5.0) + 0.25 * np.exp(-(w / 20.0)**2)\n\n    def H_LP(w):\n        return 1.0 / np.sqrt(1.0 + (w / 10.0)**4)\n\n    def H_BP(w):\n        return np.exp(-((np.abs(w) - 15.0)**2) / (2.0 * 3.0**2))\n\n    def notch_multiplier(w, w_n, sigma_n, delta):\n        return 1.0 - (1.0 - delta) * np.exp(-((w - w_n)**2) / (2.0 * sigma_n**2))\n\n    #\n    # === Error Metric ===\n    #\n    def calculate_rmse(h_est, h_true, mask):\n        \"\"\"\n        Calculates Root-Mean-Square Error on a masked subset of frequencies.\n        Args:\n            h_est: Estimated magnitude response.\n            h_true: True magnitude response.\n            mask: A boolean array indicating which frequency samples to include.\n        Returns:\n            The RMSE value.\n        \"\"\"\n        if not np.any(mask):\n            return np.nan # Avoid division by zero if mask is all False\n        \n        valid_est = h_est[mask]\n        valid_true = h_true[mask]\n        \n        # Filter out any non-finite values that might arise\n        finite_mask = np.isfinite(valid_est)  np.isfinite(valid_true)\n        if not np.any(finite_mask):\n            return np.nan\n        \n        return np.sqrt(np.mean((valid_est[finite_mask] - valid_true[finite_mask])**2))\n\n    #\n    # === Estimator Functions ===\n    #\n    def naive_estimator(Sx, Sy):\n        \"\"\"Calculates the naive estimate |H(w)| = sqrt(Sy(w) / Sx(w)).\"\"\"\n        mask = Sx  0\n        h_hat = np.full_like(Sx, np.nan)\n        h_hat[mask] = np.sqrt(Sy[mask] / Sx[mask])\n        return h_hat, mask\n\n    def regularized_estimator(Sx, Sy, eps_rel, smooth_len=0):\n        \"\"\"Calculates the regularized estimate for |H(w)|.\"\"\"\n        epsilon = eps_rel * np.median(Sx)\n        h_hat_sq = Sy / (Sx + epsilon)\n        h_hat = np.sqrt(h_hat_sq)\n        \n        if smooth_len  0:\n            if smooth_len % 2 == 0:\n                raise ValueError(\"Smoothing length must be odd.\")\n            kernel = np.ones(smooth_len) / smooth_len\n            h_hat = np.convolve(h_hat, kernel, mode='same')\n            \n        return h_hat\n\n    results = []\n\n    #\n    # === Case A: Happy Path ===\n    #\n    H_true_A = H_LP(omega)\n    Sx_A = S_x_base(omega)\n    Sy_A = H_true_A**2 * Sx_A\n    \n    H_naive_A, mask_A = naive_estimator(Sx_A, Sy_A)\n    r1 = calculate_rmse(H_naive_A, H_true_A, mask_A)\n    results.append(r1)\n\n    #\n    # === Case B: Deep Notch ===\n    #\n    H_true_B = H_LP(omega)\n    Sx_B = S_x_base(omega) * notch_multiplier(omega, w_n=10.0, sigma_n=0.2, delta=1e-10)\n    Sy_B = H_true_B**2 * Sx_B\n    \n    # Naive estimator\n    H_naive_B, mask_B = naive_estimator(Sx_B, Sy_B)\n    r2 = calculate_rmse(H_naive_B, H_true_B, mask_B)\n    results.append(r2)\n\n    # Regularized estimator\n    eps_rel_B = 1e-3\n    H_reg_B = regularized_estimator(Sx_B, Sy_B, eps_rel_B)\n    r3 = calculate_rmse(H_reg_B, H_true_B, np.ones_like(omega, dtype=bool))\n    results.append(r3)\n\n    #\n    # === Case C: Noisy Spectral Estimate ===\n    #\n    H_true_C = H_BP(omega)\n    Sx_C = S_x_base(omega)\n    Sy_ideal_C = H_true_C**2 * Sx_C\n\n    # Generate non-negative noise\n    alpha = 0.2\n    noise_smooth_len = 21\n    rng = np.random.default_rng(RANDOM_SEED)\n    \n    raw_noise = rng.standard_normal(N)\n    u_omega = np.abs(raw_noise)\n    \n    noise_kernel = np.ones(noise_smooth_len) / noise_smooth_len\n    smoothed_u = np.convolve(u_omega, noise_kernel, mode='same')\n    \n    median_Sy_C = np.median(Sy_ideal_C)\n    nu = alpha * median_Sy_C * smoothed_u\n    Sy_noisy_C = Sy_ideal_C + nu\n\n    # Regularized and smoothed estimator\n    eps_rel_C = 5e-3\n    smooth_len_C = 41\n    H_reg_C = regularized_estimator(Sx_C, Sy_noisy_C, eps_rel_C, smooth_len=smooth_len_C)\n    r4 = calculate_rmse(H_reg_C, H_true_C, np.ones_like(omega, dtype=bool))\n    results.append(r4)\n\n    #\n    # === Case D: Zero at a Frequency ===\n    #\n    H_true_D = H_LP(omega)\n    Sx_D = omega**2 * np.exp(-(omega/30.0)**2)\n    Sy_D = H_true_D**2 * Sx_D\n    \n    # Regularized estimator\n    eps_rel_D = 1e-2\n    H_reg_D = regularized_estimator(Sx_D, Sy_D, eps_rel_D)\n    r5 = calculate_rmse(H_reg_D, H_true_D, np.ones_like(omega, dtype=bool))\n    results.append(r5)\n\n    #\n    # === Final Output ===\n    #\n    print(f\"[{','.join(f'{r:.7g}' for r in results)}]\")\n\nsolve()\n```", "id": "2901279"}]}