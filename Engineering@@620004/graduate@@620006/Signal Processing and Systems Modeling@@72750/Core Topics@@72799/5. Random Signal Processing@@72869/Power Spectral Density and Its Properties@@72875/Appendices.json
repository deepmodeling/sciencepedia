{"hands_on_practices": [{"introduction": "We begin by grounding our understanding of the Power Spectral Density ($PSD$) in first principles. This exercise guides you through deriving the PSD for a canonical stochastic process, the random telegraph signal, directly from its statistical description. By first calculating the autocorrelation function and then applying the Wiener–Khinchin theorem, you will solidify the fundamental link between a process's time-domain correlation structure and its frequency-domain power distribution.", "problem": "Consider a stationary random telegraph process defined as follows. Let $x(t)$ be a $2$-state continuous-time process taking values in $\\{ -A, +A \\}$ with $A>0$. The sign process $s(t) \\coloneqq x(t)/A \\in \\{ -1, +1 \\}$ evolves as a time-homogeneous continuous-time Markov chain (CTMC) with symmetric switching rate $\\lambda>0$: in any small interval of length $\\Delta t$, the probability of a switch is $\\lambda \\Delta t + o(\\Delta t)$, independently of the past given the current state. Assume the process is in statistical steady state so that $\\mathbb{P}\\{ s(t)=+1 \\} = \\mathbb{P}\\{ s(t)=-1 \\} = \\tfrac{1}{2}$ and $\\mathbb{E}[x(t)] = 0$.\n\nUsing only fundamental definitions and first principles:\n- Start from the definition of the autocorrelation function $R_{x}(\\tau) \\coloneqq \\mathbb{E}[x(t)\\,x(t+\\tau)]$ for a wide-sense stationary process and derive an explicit closed-form expression for $R_{x}(\\tau)$ for all $\\tau \\in \\mathbb{R}$.\n- Then, starting from the Wiener–Khinchin theorem, which defines the power spectral density (PSD) $S_{x}(\\omega)$ of a wide-sense stationary process as the Fourier transform of its autocorrelation function,\n$$\nS_{x}(\\omega) \\coloneqq \\int_{-\\infty}^{\\infty} R_{x}(\\tau)\\,\\exp(-\\mathrm{j}\\,\\omega \\tau)\\,\\mathrm{d}\\tau,\n$$\nderive a closed-form expression for $S_{x}(\\omega)$.\n- Finally, compute $R_{x}(0)$ directly from $S_{x}(\\omega)$ using the inverse relation for wide-sense stationary processes,\n$$\nR_{x}(0) \\coloneqq \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} S_{x}(\\omega)\\,\\mathrm{d}\\omega,\n$$\nand verify that this value coincides with the value obtained from the process definition.\n\nExpress your final answer as a pair consisting of the PSD and the zero-lag autocorrelation in the order $\\big(S_{x}(\\omega),\\,R_{x}(0)\\big)$. No numerical approximation is required; provide exact closed-form expressions. No units are required in the final answer.", "solution": "**Derivation of the Autocorrelation Function $R_{x}(\\tau)$**\n\nThe autocorrelation function of the process $x(t)$ is defined as $R_{x}(\\tau) \\coloneqq \\mathbb{E}[x(t)\\,x(t+\\tau)]$. Since the process is wide-sense stationary, this function depends only on the time lag $\\tau$. Substituting $x(t) = A s(t)$, we obtain:\n$$R_{x}(\\tau) = \\mathbb{E}[A s(t) \\cdot A s(t+\\tau)] = A^2 \\mathbb{E}[s(t)s(t+\\tau)]$$\nLet us compute the autocorrelation of the sign process, $R_s(\\tau) = \\mathbb{E}[s(t)s(t+\\tau)]$. The transitions between states $\\{+1, -1\\}$ occur with rate $\\lambda$. This implies that the number of state transitions, $N(\\tau')$, in a time interval of duration $\\tau' \\ge 0$ follows a Poisson distribution with parameter $\\lambda \\tau'$, i.e., $\\mathbb{P}\\{N(\\tau') = k\\} = \\frac{(\\lambda \\tau')^k}{k!} \\exp(-\\lambda \\tau')$.\n\nFor a given time lag $\\tau$, the value of $s(t+\\tau)$ is related to $s(t)$ by the number of switches that have occurred in the interval $(t, t+\\tau]$. Specifically, $s(t+\\tau) = s(t) \\cdot (-1)^{N(|\\tau|)}$, where $N(|\\tau|)$ is the number of switches in a time interval of length $|\\tau|$. The absolute value $|\\tau|$ is used to handle both positive and negative lags, as the number of events depends on the duration of the interval.\n\nWe can now compute $R_s(\\tau)$:\n$$R_s(\\tau) = \\mathbb{E}[s(t) \\cdot s(t) (-1)^{N(|\\tau|)}] = \\mathbb{E}[s(t)^2 \\cdot (-1)^{N(|\\tau|)}]$$\nSince $s(t)$ can only be $+1$ or $-1$, $s(t)^2$ is always $1$. Therefore:\n$$R_s(\\tau) = \\mathbb{E}[(-1)^{N(|\\tau|)}]$$\nThe expectation is computed over the Poisson distribution of $N(|\\tau|)$:\n$$ \\mathbb{E}[(-1)^{N(|\\tau|)}] = \\sum_{k=0}^{\\infty} (-1)^k \\mathbb{P}\\{N(|\\tau|) = k\\} = \\sum_{k=0}^{\\infty} (-1)^k \\frac{(\\lambda|\\tau|)^k}{k!} \\exp(-\\lambda|\\tau|) $$\n$$ = \\exp(-\\lambda|\\tau|) \\sum_{k=0}^{\\infty} \\frac{(-\\lambda|\\tau|)^k}{k!} $$\nRecognizing the series expansion for the exponential function, $\\sum_{k=0}^{\\infty} \\frac{z^k}{k!} = \\exp(z)$, we have:\n$$ R_s(\\tau) = \\exp(-\\lambda|\\tau|) \\exp(-\\lambda|\\tau|) = \\exp(-2\\lambda|\\tau|) $$\nThus, the autocorrelation function for $x(t)$ is:\n$$ R_{x}(\\tau) = A^2 \\exp(-2\\lambda|\\tau|) $$\n\n**Derivation of the Power Spectral Density $S_{x}(\\omega)$**\n\nThe power spectral density $S_{x}(\\omega)$ is the Fourier transform of the autocorrelation function $R_{x}(\\tau)$, as defined by the Wiener-Khinchin theorem:\n$$ S_{x}(\\omega) = \\int_{-\\infty}^{\\infty} R_{x}(\\tau) \\exp(-\\mathrm{j}\\omega\\tau) \\,\\mathrm{d}\\tau = \\int_{-\\infty}^{\\infty} A^2 \\exp(-2\\lambda|\\tau|) \\exp(-\\mathrm{j}\\omega\\tau) \\,\\mathrm{d}\\tau $$\nWe can split the integral over the real line into two parts:\n$$ S_{x}(\\omega) = A^2 \\left( \\int_{-\\infty}^{0} \\exp(2\\lambda\\tau) \\exp(-\\mathrm{j}\\omega\\tau) \\,\\mathrm{d}\\tau + \\int_{0}^{\\infty} \\exp(-2\\lambda\\tau) \\exp(-\\mathrm{j}\\omega\\tau) \\,\\mathrm{d}\\tau \\right) $$\nCombining the exponents:\n$$ S_{x}(\\omega) = A^2 \\left( \\int_{-\\infty}^{0} \\exp((2\\lambda-\\mathrm{j}\\omega)\\tau) \\,\\mathrm{d}\\tau + \\int_{0}^{\\infty} \\exp(-(2\\lambda+\\mathrm{j}\\omega)\\tau) \\,\\mathrm{d}\\tau \\right) $$\nWe compute the definite integrals. Since $\\lambda > 0$, the real parts of the exponents ensure convergence.\n$$ S_{x}(\\omega) = A^2 \\left( \\left[ \\frac{\\exp((2\\lambda-\\mathrm{j}\\omega)\\tau)}{2\\lambda-\\mathrm{j}\\omega} \\right]_{-\\infty}^{0} + \\left[ \\frac{\\exp(-(2\\lambda+\\mathrm{j}\\omega)\\tau)}{-(2\\lambda+\\mathrm{j}\\omega)} \\right]_{0}^{\\infty} \\right) $$\nEvaluating at the limits:\n$$ S_{x}(\\omega) = A^2 \\left( \\left( \\frac{1}{2\\lambda-\\mathrm{j}\\omega} - 0 \\right) + \\left( 0 - \\frac{1}{-(2\\lambda+\\mathrm{j}\\omega)} \\right) \\right) $$\n$$ S_{x}(\\omega) = A^2 \\left( \\frac{1}{2\\lambda-\\mathrm{j}\\omega} + \\frac{1}{2\\lambda+\\mathrm{j}\\omega} \\right) $$\nCombining the terms using a common denominator:\n$$ S_{x}(\\omega) = A^2 \\left( \\frac{(2\\lambda+\\mathrm{j}\\omega) + (2\\lambda-\\mathrm{j}\\omega)}{(2\\lambda-\\mathrm{j}\\omega)(2\\lambda+\\mathrm{j}\\omega)} \\right) = A^2 \\left( \\frac{4\\lambda}{(2\\lambda)^2 - (\\mathrm{j}\\omega)^2} \\right) $$\n$$ S_{x}(\\omega) = A^2 \\left( \\frac{4\\lambda}{4\\lambda^2 + \\omega^2} \\right) = \\frac{4A^2\\lambda}{\\omega^2 + 4\\lambda^2} $$\nThis expression for the PSD is a Lorentzian function, which is characteristic of processes with exponential autocorrelation.\n\n**Verification of $R_{x}(0)$**\n\nThe problem requires a verification of the total power, or mean square value, $R_x(0)$, by integrating the PSD.\n$$ R_{x}(0) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} S_{x}(\\omega) \\,\\mathrm{d}\\omega = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{4A^2\\lambda}{\\omega^2 + 4\\lambda^2} \\,\\mathrm{d}\\omega $$\nWe factor out the constants:\n$$ R_{x}(0) = \\frac{4A^2\\lambda}{2\\pi} \\int_{-\\infty}^{\\infty} \\frac{1}{\\omega^2 + (2\\lambda)^2} \\,\\mathrm{d}\\omega $$\nThe integral of $\\frac{1}{u^2+c^2}$ is $\\frac{1}{c}\\arctan(\\frac{u}{c})$.\n$$ \\int_{-\\infty}^{\\infty} \\frac{1}{\\omega^2 + (2\\lambda)^2} \\,\\mathrm{d}\\omega = \\left[ \\frac{1}{2\\lambda} \\arctan\\left(\\frac{\\omega}{2\\lambda}\\right) \\right]_{-\\infty}^{\\infty} $$\n$$ = \\frac{1}{2\\lambda} \\left( \\lim_{\\omega\\to\\infty} \\arctan\\left(\\frac{\\omega}{2\\lambda}\\right) - \\lim_{\\omega\\to-\\infty} \\arctan\\left(\\frac{\\omega}{2\\lambda}\\right) \\right) $$\n$$ = \\frac{1}{2\\lambda} \\left( \\frac{\\pi}{2} - \\left(-\\frac{\\pi}{2}\\right) \\right) = \\frac{1}{2\\lambda}(\\pi) = \\frac{\\pi}{2\\lambda} $$\nSubstituting this result back into the expression for $R_{x}(0)$:\n$$ R_{x}(0) = \\frac{4A^2\\lambda}{2\\pi} \\cdot \\frac{\\pi}{2\\lambda} = \\frac{4\\pi A^2\\lambda}{4\\pi\\lambda} = A^2 $$\nNow we verify this from the process definition. $R_x(0)$ is the mean square value of the process:\n$$ R_{x}(0) = \\mathbb{E}[x(t)^2] $$\nThe process $x(t)$ takes values $-A$ and $+A$. In either case, $x(t)^2 = A^2$. Thus, the expected value is constant:\n$$ \\mathbb{E}[x(t)^2] = A^2 $$\nThe value of $R_{x}(0)$ obtained by integrating the derived PSD is consistent with the value obtained directly from the process definition. This concludes the verification.\nThe requested quantities are the power spectral density $S_x(\\omega)$ and the zero-lag autocorrelation $R_x(0)$.\nThe final answer is the pair $\\big(S_{x}(\\omega),\\,R_{x}(0)\\big)$.", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{4A^2\\lambda}{\\omega^2 + 4\\lambda^2} & A^2 \\end{pmatrix} } $$", "id": "2892488"}, {"introduction": "Moving from continuous-time theory to discrete-time practice, we confront the challenge that real-world signals are observed for a finite duration, a constraint that introduces estimation artifacts. This practice provides a quantitative look at spectral leakage, a primary artifact of using the Discrete Fourier Transform (DFT), by analyzing a single sinusoid whose frequency falls between DFT bins. You will derive the exact leakage pattern and quantify the resulting \"scalloping loss\" in terms of detectability, offering a crucial lesson in the practical limitations of DFT-based analysis.", "problem": "Consider a discrete-time complex sinusoid of unknown phase immersed in additive noise. You observe a finite-length record and compute its Discrete Fourier Transform (DFT), using a rectangular window. Your goal is to characterize the spectral leakage pattern when the sinusoid’s frequency is not exactly on a DFT bin and to quantify the resulting detectability loss.\n\nLet the observed time series be\n$$\nx[n] = A \\exp(\\mathrm{j}\\,\\omega_{0} n) + w[n], \\quad n \\in \\{0,1,\\ldots,N-1\\},\n$$\nwhere $A \\in \\mathbb{C}$ is a nonzero constant, $\\omega_{0} \\in \\mathbb{R}$ is the angular frequency (in radians per sample), and $\\{w[n]\\}$ is zero-mean Additive White Gaussian Noise (AWGN) with variance $\\sigma^{2}$ per sample. You apply a length-$N$ rectangular window $w_{\\mathrm{R}}[n]$ defined by $w_{\\mathrm{R}}[n]=1$ for $n \\in \\{0,1,\\ldots,N-1\\}$ and $w_{\\mathrm{R}}[n]=0$ otherwise, and compute the $N$-point Discrete Fourier Transform (DFT)\n$$\nX[k] = \\sum_{n=0}^{N-1} x[n] \\exp\\!\\left(-\\mathrm{j}\\,\\frac{2\\pi k}{N} n\\right), \\quad k \\in \\{0,1,\\ldots,N-1\\}.\n$$\n\nAssume the sinusoid frequency is not exactly on a DFT bin. Parameterize it as\n$$\n\\omega_{0} = \\frac{2\\pi}{N}\\big(k_{0}+\\delta\\big),\n$$\nwhere $k_{0} \\in \\{0,1,\\ldots,N-1\\}$ is an integer and $\\delta \\in (-\\tfrac{1}{2},\\tfrac{1}{2})\\setminus\\{0\\}$ is the fractional-bin offset. Define the bin offset $m = k - k_{0} \\in \\mathbb{Z}$.\n\nTasks:\n- Starting from the definitions of the DFT, rectangular window, and the properties of independent Gaussian random variables under linear transforms, derive the exact spectral leakage pattern for the noiseless component, namely an expression for the expected periodogram sample due to the sinusoid alone in bin $k$,\n$$\n\\mathbb{E}\\!\\left[\\,|X[k]|^{2}\\,\\middle|\\,A \\exp(\\mathrm{j}\\,\\omega_{0} n)\\,\\right],\n$$\nas a function of $A$, $N$, $\\delta$, and $m$.\n- Model detectability in a single-bin detector by the ratio of the expected signal power in the strongest DFT bin to the variance of the noise contribution in that bin, that is, a single-bin signal-to-noise ratio (SNR). Using your leakage result, identify the strongest bin for $\\delta \\in (-\\tfrac{1}{2},\\tfrac{1}{2})$ and derive the detectability loss factor\n$$\nL(N,\\delta),\n$$\ndefined as the ratio of this single-bin SNR at fractional offset $\\delta$ to the single-bin SNR when $\\delta=0$ (that is, on-bin sinusoid), under the same $A$, $N$, and $\\sigma^{2}$. Provide $L(N,\\delta)$ in closed form as a simplified analytic expression.\n\nReport only the expression for $L(N,\\delta)$ as your final answer. No numerical evaluation is required. If you introduce any acronym such as Discrete Fourier Transform (DFT), Additive White Gaussian Noise (AWGN), Power Spectral Density (PSD), or signal-to-noise ratio (SNR), define it upon first use. The angle $\\omega_{0}$ is measured in radians per sample.", "solution": "The observed time series is given as $x[n] = s[n] + w[n]$, where $s[n] = A \\exp(\\mathrm{j}\\,\\omega_{0} n)$ is the complex sinusoidal signal and $w[n]$ is zero-mean Additive White Gaussian Noise (AWGN) with variance $\\sigma^{2}$. The $N$-point Discrete Fourier Transform (DFT), being a linear operation, allows us to analyze the signal and noise components independently. The DFT of $x[n]$ is $X[k] = S[k] + W[k]$, where $S[k]$ is the DFT of the signal component $s[n]$ and $W[k]$ is the DFT of the noise component $w[n]$.\n\nFirst, we derive the expression for $S[k]$, the DFT of the noiseless signal, which represents the spectral leakage pattern. The signal frequency is parameterized as $\\omega_{0} = \\frac{2\\pi}{N}(k_{0}+\\delta)$.\n$$\nS[k] = \\sum_{n=0}^{N-1} s[n] \\exp\\left(-\\mathrm{j}\\,\\frac{2\\pi k}{N} n\\right) = \\sum_{n=0}^{N-1} A \\exp(\\mathrm{j}\\,\\omega_{0} n) \\exp\\left(-\\mathrm{j}\\,\\frac{2\\pi k}{N} n\\right)\n$$\nSubstituting the expression for $\\omega_{0}$:\n$$\nS[k] = A \\sum_{n=0}^{N-1} \\exp\\left(\\mathrm{j}\\,\\frac{2\\pi}{N}(k_{0}+\\delta) n\\right) \\exp\\left(-\\mathrm{j}\\,\\frac{2\\pi k}{N} n\\right) = A \\sum_{n=0}^{N-1} \\exp\\left(\\mathrm{j}\\,\\frac{2\\pi}{N}(k_{0}+\\delta-k) n\\right)\n$$\nThis is a geometric series of the form $\\sum_{n=0}^{N-1} r^{n}$, with $r = \\exp\\left(\\mathrm{j}\\,\\frac{2\\pi}{N}(k_{0}+\\delta-k)\\right)$. Since $\\delta \\in (-\\tfrac{1}{2}, \\tfrac{1}{2})\\setminus\\{0\\}$, the term $k_{0}+\\delta-k$ is never an integer, so $r \\neq 1$. Applying the formula for the sum of a finite geometric series, $\\sum_{n=0}^{N-1} r^{n} = \\frac{1-r^{N}}{1-r}$:\n$$\nS[k] = A \\frac{1 - \\exp\\left(\\mathrm{j}\\,2\\pi(k_{0}+\\delta-k)\\right)}{1 - \\exp\\left(\\mathrm{j}\\,\\frac{2\\pi}{N}(k_{0}+\\delta-k)\\right)}\n$$\nSince $k$ and $k_{0}$ are integers, $\\exp(-\\mathrm{j}\\,2\\pi(k-k_{0})) = 1$. The numerator simplifies to $1 - \\exp(\\mathrm{j}\\,2\\pi\\delta)$.\nTo find the magnitude, we use the identity $|1-\\exp(\\mathrm{j}\\,\\theta)| = | \\exp(\\mathrm{j}\\,\\theta/2) (\\exp(-\\mathrm{j}\\,\\theta/2) - \\exp(\\mathrm{j}\\,\\theta/2)) | = | -2\\mathrm{j}\\,\\sin(\\theta/2) | = 2|\\sin(\\theta/2)|$.\nApplying this to the numerator and denominator:\n$$\n|S[k]| = |A| \\frac{|\\sin(\\pi(k_0+\\delta-k))|}{|\\sin(\\frac{\\pi}{N}(k_0+\\delta-k))|}\n$$\nGiven that $k-k_0$ is an integer, let $m = k-k_0$. Then $\\sin(\\pi(k_0-k+\\delta)) = \\sin(-\\pi m + \\pi\\delta) = \\sin(\\pi\\delta)\\cos(\\pi m) - \\cos(\\pi\\delta)\\sin(\\pi m) = (-1)^{m}\\sin(\\pi\\delta)$. The magnitude is unaffected by the sign, so $|\\sin(\\pi(k_0-k+\\delta))| = |\\sin(\\pi\\delta)|$.\nThus, the magnitude of the signal's DFT is:\n$$\n|S[k]| = |A| \\frac{|\\sin(\\pi\\delta)|}{|\\sin(\\frac{\\pi}{N}(\\delta-m))|}\n$$\nThe expected periodogram sample due to the signal alone is simply the squared magnitude of $S[k]$, as the signal is deterministic:\n$$\n\\mathbb{E}\\!\\left[\\,|X[k]|^{2}\\,\\middle|\\,A \\exp(\\mathrm{j}\\,\\omega_{0} n)\\,\\right] = |S[k]|^2 = |A|^2 \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi}{N}(\\delta-m)\\right)} \\right)^2\n$$\nThis expression characterizes the spectral leakage pattern as a function of $A$, $N$, $\\delta$, and the bin offset $m = k-k_0$.\n\nNext, we analyze the noise contribution. The DFT of the noise is $W[k] = \\sum_{n=0}^{N-1} w[n] \\exp(-\\mathrm{j}\\,\\frac{2\\pi k n}{N})$. Since $\\mathbb{E}[w[n]]=0$, it follows that $\\mathbb{E}[W[k]]=0$. The variance of the noise contribution in bin $k$ is:\n$$\n\\text{Var}(W[k]) = \\mathbb{E}[|W[k]|^2] = \\mathbb{E}\\left[ \\left(\\sum_{n=0}^{N-1} w[n] e^{-\\mathrm{j}\\frac{2\\pi kn}{N}}\\right) \\left(\\sum_{l=0}^{N-1} w^*[l] e^{\\mathrm{j}\\frac{2\\pi kl}{N}}\\right) \\right]\n$$\n$$\n\\text{Var}(W[k]) = \\sum_{n=0}^{N-1}\\sum_{l=0}^{N-1} \\mathbb{E}[w[n]w^*[l]] \\exp\\left(-\\mathrm{j}\\frac{2\\pi k(n-l)}{N}\\right)\n$$\nFor AWGN, the samples are uncorrelated, so $\\mathbb{E}[w[n]w^*[l]] = \\sigma^2 \\delta_{nl}$, where $\\delta_{nl}$ is the Kronecker delta.\n$$\n\\text{Var}(W[k]) = \\sum_{n=0}^{N-1}\\sum_{l=0}^{N-1} \\sigma^2 \\delta_{nl} \\exp\\left(-\\mathrm{j}\\frac{2\\pi k(n-l)}{N}\\right) = \\sum_{n=0}^{N-1} \\sigma^2 = N\\sigma^2\n$$\nThe noise power is constant across all DFT bins.\n\nThe detectability is modeled by the single-bin signal-to-noise ratio (SNR), defined as the ratio of the expected signal power in the strongest DFT bin to the noise variance in that bin. To find the strongest bin, we must maximize $|S[k]|^2$, which is equivalent to minimizing the denominator term $|\\sin(\\frac{\\pi}{N}(\\delta-m))|$. Since $\\delta \\in (-\\frac{1}{2}, \\frac{1}{2})$, the value $|\\delta-m|$ for integer $m$ is minimized when $m=0$. This corresponds to bin $k=k_0$. The strongest bin is therefore $k_0$.\n\nThe signal power in the strongest bin $(m=0)$ is:\n$$\n|S[k_0]|^2 = |A|^2 \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^2\n$$\nThe single-bin SNR for a fractional offset $\\delta$ is:\n$$\n\\text{SNR}(\\delta) = \\frac{|S[k_0]|^2}{\\text{Var}(W[k_0])} = \\frac{|A|^2}{N\\sigma^2} \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^2\n$$\nNow, we must find the reference SNR for an on-bin sinusoid, where $\\delta=0$. In this case, $\\omega_0 = \\frac{2\\pi k_0}{N}$. The signal DFT becomes $S[k] = A \\sum_{n=0}^{N-1} \\exp(\\mathrm{j}\\frac{2\\pi(k_0-k)n}{N})$. Due to the orthogonality of the DFT basis functions, this sum is $A N$ for $k=k_0$ and $0$ otherwise. All signal power is concentrated in bin $k_0$.\nThe signal power is $|S[k_0]|^2 = |A|^2 N^2$. The noise power remains $N\\sigma^2$.\nThe on-bin SNR is therefore:\n$$\n\\text{SNR}(0) = \\frac{|A|^2 N^2}{N\\sigma^2} = \\frac{|A|^2 N}{\\sigma^2}\n$$\nThis result can also be obtained by taking the limit of $\\text{SNR}(\\delta)$ as $\\delta \\to 0$, using the approximation $\\sin(x) \\approx x$ for small $x$:\n$$\n\\lim_{\\delta\\to 0} \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^2 = \\lim_{\\delta\\to 0} \\left( \\frac{\\pi\\delta}{\\frac{\\pi\\delta}{N}} \\right)^2 = N^2\n$$\nHence, $\\lim_{\\delta\\to 0} \\text{SNR}(\\delta) = \\frac{|A|^2}{N\\sigma^2} N^2 = \\text{SNR}(0)$.\n\nFinally, the detectability loss factor $L(N, \\delta)$ is the ratio of $\\text{SNR}(\\delta)$ to $\\text{SNR}(0)$:\n$$\nL(N, \\delta) = \\frac{\\text{SNR}(\\delta)}{\\text{SNR}(0)} = \\frac{\\frac{|A|^2}{N\\sigma^2} \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^2}{\\frac{|A|^2 N}{\\sigma^2}}\n$$\nCanceling common terms, we obtain the final expression:\n$$\nL(N,\\delta) = \\frac{1}{N^2} \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^2\n$$\nThis is the required closed-form analytic expression for the detectability loss factor.", "answer": "$$\n\\boxed{\n\\frac{1}{N^{2}} \\left( \\frac{\\sin(\\pi\\delta)}{\\sin\\left(\\frac{\\pi\\delta}{N}\\right)} \\right)^{2}\n}\n$$", "id": "2892490"}, {"introduction": "Ultimately, practical spectral estimation involves choosing from a toolbox of methods, each with its own strengths and weaknesses. This final exercise challenges you to navigate the fundamental bias-variance trade-off by comparing three cornerstone techniques: the Bartlett, Welch, and multitaper methods. By analyzing how each method uses windowing and averaging to achieve a specified resolution, you will develop the critical judgment needed to select the most appropriate spectral estimator for a given scientific or engineering problem.", "problem": "You are given a single real-valued, zero-mean, wide-sense stationary discrete-time record of duration $T = 10\\,\\mathrm{s}$ sampled at $F_s = 1000\\,\\mathrm{Hz}$, so the sample count is $N = 10{,}000$. You wish to estimate its power spectral density (PSD), defined as the Fourier transform of the autocorrelation function, with an effective resolution bandwidth of approximately $B_{\\mathrm{res}} = 2\\,\\mathrm{Hz}$, meaning that the estimator should resolve features on the order of $2\\,\\mathrm{Hz}$ while controlling spectral leakage and estimation variance. Consider three estimators tuned so that each achieves approximately the same effective resolution bandwidth: (i) a Bartlett estimator formed by averaging non-overlapping periodograms of equal-length rectangularly windowed segments, (ii) a Welch estimator formed by averaging overlapped, tapered (e.g., Hann) periodograms, and (iii) a multitaper estimator using $K$ orthogonal Discrete Prolate Spheroidal Sequences (DPSS) with time-halfbandwidth $W$ chosen commensurate with the desired resolution. Starting from core definitions of the periodogram, PSD (as the Fourier transform of the autocorrelation), and the effects of windowing and averaging on expectation (via convolution with a spectral window) and variance (via averaging of approximately independent estimates), determine which statement best compares the bias and variance trade-offs among these three methods at the fixed resolution bandwidth and specifies realistic conditions that favor each method, given the finite record length.\n\nChoose the single best option.\n\nA. When each method is tuned to the same effective resolution bandwidth, Bartlett and multitaper typically achieve comparable effective degrees of freedom (hence similar variance reduction) for this record length, whereas Welch yields somewhat fewer effective degrees of freedom than its raw segment count due to dependence from overlap and tapering. For bias, Bartlett’s rectangular segments have narrow mainlobes but high sidelobes, producing larger leakage bias for colored spectra or off-bin sinusoids; Welch’s tapering reduces leakage bias but requires longer segments to keep the same resolution; multitaper minimizes leakage for the prescribed bandwidth by concentrating energy within the target band, thus offering the lowest bias for spectra that are locally smooth within the chosen bandwidth. Bartlett is favored when the spectrum is near-white or tones are bin-centered and computational simplicity is paramount; Welch is favored when leakage control is needed with modest variance reduction from a single record; multitaper is favored when near-minimum mean-squared error at a prescribed resolution is required, especially for short-to-moderate records or mixed line/continuous spectra.\n\nB. At the same effective resolution bandwidth, Welch always attains the largest number of independent averages because overlap increases independence, so its variance is the lowest among the three; multitaper has the highest variance because the tapers are not independent, and its bias is larger than Bartlett’s due to a wider equivalent noise bandwidth. Welch should be used whenever strong lines are present, while multitaper is mainly useful for very long, white spectra.\n\nC. If the effective resolution bandwidth is matched, Bartlett has the lowest bias because its mainlobe is the narrowest, while Welch and multitaper both incur larger bias due to tapering; multitaper only reduces leakage for discrete lines and otherwise increases bias for continuous spectra. Therefore, Bartlett should be preferred for colored spectra, Welch only when segments can be made very long, and multitaper only when the record is extremely long.\n\nD. With the same effective resolution bandwidth, the three estimators have essentially identical bias and variance, so the choice among Bartlett, Welch, and multitaper is arbitrary and independent of record length, overlap, or taper properties; overlap always increases degrees of freedom proportionally to the overlap percentage and does not affect bias because window shape is irrelevant at fixed resolution.", "solution": "The problem requires a critical comparison of three power spectral density (PSD) estimation methods: Bartlett, Welch, and multitaper. The comparison is to be performed under the constraint that all three are tuned to achieve the same effective resolution bandwidth, $B_{\\mathrm{res}} \\approx 2 \\, \\mathrm{Hz}$, for a given discrete-time signal record of length $N=10,000$ samples, sampled at $F_s = 1000 \\, \\mathrm{Hz}$. The analysis must focus on the trade-offs between bias and variance.\n\nFirst, we establish the theoretical basis for the comparison. The PSD, $S_{xx}(f)$, of a wide-sense stationary (WSS) process is the Fourier transform of its autocorrelation function, $R_{xx}[m]$. An elementary estimator for the PSD is the periodogram, $I(f)$, which is the squared magnitude of the Discrete Fourier Transform (DFT) of the data record, scaled by its length. For a record $x[n]$ of length $L$, the periodogram is $I(f) = \\frac{1}{L} \\left| \\sum_{n=0}^{L-1} w[n] x[n] e^{-j2\\pi f n/F_s} \\right|^2$, where $w[n]$ is a window function.\n\nThe statistical properties of a PSD estimator are characterized by its bias and variance.\n1.  **Bias**: The expected value of the estimator, $E[\\hat{S}_{xx}(f)]$, is related to the true PSD, $S_{xx}(f)$, by convolution with the spectral window, $|W(f)|^2$, where $W(f)$ is the Fourier transform of the window function $w[n]$.\n    $$ E[\\hat{S}_{xx}(f)] \\approx S_{xx}(f) * \\frac{1}{L} |W(f)|^2 $$\n    Bias has two components: smearing/resolution bias from the mainlobe width of $|W(f)|^2$, and leakage bias from its sidelobes. Since the problem fixes the effective resolution bandwidth, $B_{\\mathrm{res}}$, for all methods, we are essentially matching their mainlobe widths. The key differentiator for bias is therefore the sidelobe leakage.\n2.  **Variance**: For a Gaussian process, the variance of a raw periodogram is high, $\\text{var}(I(f)) \\approx (E[I(f)])^2$. To reduce this variance, averaging is employed. If an estimator is formed by averaging $K_{\\mathrm{eff}}$ effectively independent periodograms, its variance is reduced by a factor of $K_{\\mathrm{eff}}$:\n    $$ \\mathrm{var}(\\hat{S}_{xx}(f)) \\approx \\frac{1}{K_{\\mathrm{eff}}} (E[\\hat{S}_{xx}(f)])^2 $$\n    The quantity $2K_{\\mathrm{eff}}$ is known as the effective degrees of freedom.\n\nLet us tune each method to the specified resolution, $B_{\\mathrm{res}} = 2 \\, \\mathrm{Hz}$, using the given data record properties ($N=10,000$, $F_s=1000 \\, \\mathrm{Hz}$).\n\n**Method (i): Bartlett Estimator**\nThis method divides the record of length $N$ into $K$ non-overlapping segments of length $L$, computes a periodogram for each, and averages the results. The window is rectangular. The resolution is approximately $B_{\\mathrm{res}} \\approx F_s/L$.\n- To achieve $B_{\\mathrm{res}} = 2 \\, \\mathrm{Hz}$, the segment length must be $L \\approx F_s / B_{\\mathrm{res}} = 1000 / 2 = 500$ samples.\n- The number of non-overlapping segments is $K_{\\mathrm{avg}} = \\lfloor N/L \\rfloor = \\lfloor 10,000 / 500 \\rfloor = 20$.\n- **Bias**: The rectangular window has high sidelobes (first sidelobe at $-13.3 \\, \\mathrm{dB}$). This leads to significant spectral leakage, causing high bias, particularly for spectra with large dynamic range (e.g., strong sinusoids mixed with weak noise).\n- **Variance**: Since the segments are non-overlapping, they are approximately independent. Thus, $K_{\\mathrm{eff}} \\approx K_{\\mathrm{avg}} = 20$. The variance is reduced by a factor of $20$.\n\n**Method (ii): Welch Estimator**\nThis method uses overlapping, tapered segments. A common choice is a Hann window with $50\\%$ overlap. The mainlobe of a Hann window is wider than that of a rectangular window. The resolution is approximately $B_{\\mathrm{res}} \\approx 1.5 F_s/L$.\n- To achieve $B_{\\mathrm{res}} = 2 \\, \\mathrm{Hz}$, the segment length must be $L \\approx 1.5 F_s / B_{\\mathrm{res}} = 1.5 \\times 1000 / 2 = 750$ samples.\n- With $50\\%$ overlap, the stride is $L/2 = 375$. The number of segments is $K_{\\mathrm{avg}} = \\lfloor(N - L) / (L/2)\\rfloor + 1 = \\lfloor (10000 - 750) / 375 \\rfloor + 1 = 25$.\n- **Bias**: The Hann window has much lower sidelobes than the rectangular window (first sidelobe at $-31.5 \\, \\mathrm{dB}$). This drastically reduces spectral leakage, resulting in significantly lower bias compared to the Bartlett method. To match the a priori fixed resolution, we had to use a longer segment, which is a key part of the trade-off.\n- **Variance**: The overlapping segments are not independent. For a Hann window and $50\\%$ overlap, the variance reduction is less than the raw count of segments. The effective number of independent segments is approximately $K_{\\mathrm{eff}} \\approx \\frac{9}{16} K_{\\mathrm{avg}} = \\frac{9}{16} \\times 25 \\approx 14.1$. The variance is reduced by a factor of about $14$.\n\n**Method (iii): Multitaper Estimator**\nThis method applies a set of $K$ orthogonal tapers—the Discrete Prolate Spheroidal Sequences (DPSS), or Slepian sequences—to the entire data record. The resolution is determined by the time-halfbandwidth product, $p = TW$, where $T$ is the record duration in seconds ($10 \\, \\mathrm{s}$) and $2W$ is the resolution bandwidth in Hz.\n- To achieve $B_{\\mathrm{res}} = 2W = 2 \\, \\mathrm{Hz}$, the half-bandwidth parameter is $W=1 \\, \\mathrm{Hz}$.\n- The time-halfbandwidth product is $p = T \\times W = 10 \\, \\mathrm{s} \\times 1 \\, \\mathrm{Hz} = 10$.\n- The number of useful tapers (with eigenvalues close to $1$) is $K \\approx 2p - 1 = 2(10) - 1 = 19$. We average the $K=19$ resulting eigenspectra.\n- **Bias**: The DPSS tapers are designed to be optimally concentrated within the frequency band $[-W, W]$, thus minimizing leakage outside this band. This method provides the lowest possible leakage bias for the specified resolution.\n- **Variance**: The eigenspectra from orthogonal tapers are approximately independent. Thus, $K_{\\mathrm{eff}} \\approx K = 19$. The variance is reduced by a factor of $19$.\n\n**Comparison Summary for $B_{\\mathrm{res}} \\approx 2 \\, \\mathrm{Hz}$:**\n- **Bias (Leakage)**: Multitaper (Lowest) $<$ Welch (Low) $\\ll$ Bartlett (High).\n- **Variance Reduction ($K_{\\mathrm{eff}}$)**: Bartlett ($\\approx 20$) $\\approx$ Multitaper ($\\approx 19$) $>$ Welch ($\\approx 14$).\n\nThis analysis shows that at the same resolution, Bartlett has the worst bias. Welch improves bias at the cost of some variance reduction compared to Bartlett. Multitaper offers the best bias reduction (lowest leakage) with a variance reduction comparable to Bartlett's.\n\nNow, we evaluate each provided option based on this analysis.\n\n**A. When each method is tuned to the same effective resolution bandwidth, Bartlett and multitaper typically achieve comparable effective degrees of freedom (hence similar variance reduction) for this record length, whereas Welch yields somewhat fewer effective degrees of freedom than its raw segment count due to dependence from overlap and tapering. For bias, Bartlett’s rectangular segments have narrow mainlobes but high sidelobes, producing larger leakage bias for colored spectra or off-bin sinusoids; Welch’s tapering reduces leakage bias but requires longer segments to keep the same resolution; multitaper minimizes leakage for the prescribed bandwidth by concentrating energy within the target band, thus offering the lowest bias for spectra that are locally smooth within the chosen bandwidth. Bartlett is favored when the spectrum is near-white or tones are bin-centered and computational simplicity is paramount; Welch is favored when leakage control is needed with modest variance reduction from a single record; multitaper is favored when near-minimum mean-squared error at a prescribed resolution is required, especially for short-to-moderate records or mixed line/continuous spectra.**\n\nThis statement is entirely consistent with our derivation.\n- It correctly states that Bartlett and multitaper have comparable variance reduction ($K_{\\mathrm{eff}} \\approx 20$ and $K_{\\mathrm{eff}} \\approx 19$, respectively).\n- It correctly notes that Welch's effective degrees of freedom are less than its raw segment count.\n- It accurately describes Bartlett's high leakage bias from rectangular window sidelobes.\n- It correctly explains that Welch's tapering reduces leakage but requires longer segments for the same resolution.\n- It correctly identifies multitaper as minimizing leakage bias by design.\n- The summary of use cases is standard and correct: Bartlett for simple cases, Welch as a general-purpose compromise, and multitaper for high-performance applications, especially on challenging or short datasets.\n**Verdict: Correct.**\n\n**B. At the same effective resolution bandwidth, Welch always attains the largest number of independent averages because overlap increases independence, so its variance is the lowest among the three; multitaper has the highest variance because the tapers are not independent, and its bias is larger than Bartlett’s due to a wider equivalent noise bandwidth. Welch should be used whenever strong lines are present, while multitaper is mainly useful for very long, white spectra.**\n\nThis statement contains multiple fundamental errors.\n- Overlap introduces dependence, it does not increase independence.\n- In our calculation, Welch had the highest variance (lowest $K_{\\mathrm{eff}}$).\n- Multitaper tapers (DPSS) are orthogonal, and the resulting estimates are approximately independent, leading to good variance reduction, not the highest variance.\n- Multitaper bias is the lowest, not larger than Bartlett's.\n- Multitaper is superior for spectra with strong lines due to its low leakage; its main advantages are for short/moderate records, not very long ones where simpler methods suffice.\n**Verdict: Incorrect.**\n\n**C. If the effective resolution bandwidth is matched, Bartlett has the lowest bias because its mainlobe is the narrowest, while Welch and multitaper both incur larger bias due to tapering; multitaper only reduces leakage for discrete lines and otherwise increases bias for continuous spectra. Therefore, Bartlett should be preferred for colored spectra, Welch only when segments can be made very long, and multitaper only when the record is extremely long.**\n\nThis statement is factually wrong.\n- Bartlett has the highest leakage bias, not the lowest. The narrow mainlobe for a given $L$ is a different concept from bias at a fixed resolution.\n- Tapering is the primary method for *reducing* leakage bias.\n- Multitaper is excellent for both continuous and discrete spectra.\n- Bartlett is the worst choice for colored spectra. Multitaper's advantage is most pronounced on short records.\n**Verdict: Incorrect.**\n\n**D. With the same effective resolution bandwidth, the three estimators have essentially identical bias and variance, so the choice among Bartlett, Welch, and multitaper is arbitrary and independent of record length, overlap, or taper properties; overlap always increases degrees of freedom proportionally to the overlap percentage and does not affect bias because window shape is irrelevant at fixed resolution.**\n\nThis statement negates the entire field of advanced spectral estimation.\n- The estimators have vastly different bias-variance profiles.\n- The choice is not arbitrary and depends critically on the data and goals.\n- Window shape is the single most important factor determining leakage bias.\n- The effect of overlap on degrees of freedom is not proportional.\n**Verdict: Incorrect.**\n\nBased on the thorough analysis, option A is the only one that provides a scientifically sound and detailed comparison of the three methods.", "answer": "$$\\boxed{A}$$", "id": "2892460"}]}