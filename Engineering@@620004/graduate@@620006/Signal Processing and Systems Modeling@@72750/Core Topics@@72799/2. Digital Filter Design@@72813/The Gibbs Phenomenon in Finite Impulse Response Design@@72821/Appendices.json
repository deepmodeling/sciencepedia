{"hands_on_practices": [{"introduction": "Practical FIR filters are fundamentally finite-length approximations of ideal, infinite-length archetypes. This exercise delves into the mathematical roots of the Gibbs phenomenon by analyzing what happens when we simply truncate the impulse response of an ideal lowpass filter. By deriving the frequency response as a finite Fourier series, you will analytically observe the characteristic oscillatory behavior and fixed-percentage overshoot that arise near the cutoff frequency, providing a rigorous foundation for understanding why this effect occurs [@problem_id:2912668].", "problem": "Consider the ideal discrete-time lowpass filter of unit gain and cutoff frequency $\\,\\omega_c \\in (0,\\pi)\\,$ with impulse response $\\,h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}\\,$ for $\\,n \\neq 0\\,$ and $\\,h_d[0] = \\frac{\\omega_c}{\\pi}\\,$. Form a symmetric, length-$N$ ($N$ odd) finite impulse response by rectangular truncation about the origin:\n- Let $\\,N = 2M+1\\,$ with $\\,M \\in \\mathbb{N}\\,$.\n- Define $\\,h_N[n] = h_d[n]\\,$ for $\\,n \\in \\{-M,-M+1,\\dots,0,\\dots,M-1,M\\}\\,$ and $\\,h_N[n] = 0\\,$ otherwise.\n\nUsing only the definitions of the discrete-time Fourier transform (DTFT), the ideal lowpass frequency response, and the rectangular window, derive the DTFT $\\,H_N(\\omega)\\,$ of $\\,h_N[n]\\,$ and simplify it to a real cosine series in $\\,\\omega\\,$ and $\\,N\\,$. Then, by interpreting $\\,H_N(\\omega)\\,$ as a finite Fourier-series approximation to the ideal rectangular frequency response, express:\n- the passband deviation $\\,\\Delta_p(\\omega;N) := H_N(\\omega) - 1\\,$ for $\\,|\\omega| < \\omega_c\\,$, and\n- the stopband magnitude $\\,E_s(\\omega;N) := |H_N(\\omega)|\\,$ for $\\,|\\omega| > \\omega_c\\,$,\n\nexplicitly in terms of $\\,N\\,$ and $\\,\\omega\\,$, and state their leading-order dependence on $\\,N\\,$ and $\\,\\omega\\,$ away from the transition edges $\\,\\pm \\omega_c\\,$, commenting on the Gibbs phenomenon at $\\,\\omega = \\pm \\omega_c\\,$. Angles must be in radians. Report your final answer as the single closed-form expression of $\\,H_N(\\omega)\\,$ you derived. No numerical rounding is required.", "solution": "The problem statement is subjected to validation.\n\nStep 1: Extract Givens\n- Ideal discrete-time lowpass filter impulse response: $h_d[n] = \\frac{\\sin(\\omega_c n)}{\\pi n}$ for $n \\neq 0$, and $h_d[0] = \\frac{\\omega_c}{\\pi}$.\n- Cutoff frequency: $\\omega_c \\in (0,\\pi)$.\n- Filter gain: Unit ($1$).\n- Finite Impulse Response (FIR) filter length: $N$, where $N$ is an odd integer.\n- Relation between $N$ and $M$: $N = 2M+1$, where $M \\in \\mathbb{N}$.\n- FIR impulse response definition: $h_N[n] = h_d[n]$ for $n \\in \\{-M, \\dots, M\\}$ and $h_N[n]=0$ otherwise.\n\nStep 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in digital signal processing concerning the design of FIR filters using the window method. The definitions of the ideal lowpass filter, its impulse response (a sinc function), and the process of truncation by a rectangular window are all fundamental and correct concepts in the field. The requested analysis pertains to the Gibbs phenomenon, a well-established mathematical and physical effect. The problem is scientifically sound.\n- **Well-Posed:** The problem is clearly stated. It asks for the derivation of the frequency response of the truncated filter, an analysis of its deviation from the ideal, and a commentary on the Gibbs phenomenon. All required information is provided to derive a unique and meaningful solution.\n- **Objective:** The problem is formulated with precise mathematical language, free from any subjectivity or ambiguity.\n\nStep 3: Verdict and Action\nThe problem is valid. A rigorous solution will be constructed.\n\nThe frequency response $H_N(\\omega)$ of the finite impulse response filter $h_N[n]$ is given by its discrete-time Fourier transform (DTFT):\n$$H_N(\\omega) = \\sum_{n=-\\infty}^{\\infty} h_N[n] \\exp(-j\\omega n)$$\nBy definition, $h_N[n]$ is non-zero only for $|n| \\le M$, where $N=2M+1$. Thus, the summation is over a finite range:\n$$H_N(\\omega) = \\sum_{n=-M}^{M} h_N[n] \\exp(-j\\omega n)$$\nSubstituting the definition $h_N[n] = h_d[n]$ for this range, we have:\n$$H_N(\\omega) = \\sum_{n=-M}^{M} h_d[n] \\exp(-j\\omega n)$$\nWe separate the $n=0$ term from the sum:\n$$H_N(\\omega) = h_d[0] + \\sum_{n=-M, n \\neq 0}^{M} h_d[n] \\exp(-j\\omega n)$$\nSubstituting the given expressions for $h_d[n]$:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\sum_{n=-M, n \\neq 0}^{M} \\frac{\\sin(\\omega_c n)}{\\pi n} \\exp(-j\\omega n)$$\nWe can split the summation into positive and negative indices:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n)}{\\pi n} \\exp(-j\\omega n) + \\sum_{n=-M}^{-1} \\frac{\\sin(\\omega_c n)}{\\pi n} \\exp(-j\\omega n)$$\nIn the second summation, let $k = -n$. As $n$ goes from $-M$ to $-1$, $k$ goes from $M$ to $1$:\n$$\\sum_{k=1}^{M} \\frac{\\sin(\\omega_c (-k))}{\\pi (-k)} \\exp(-j\\omega (-k)) = \\sum_{k=1}^{M} \\frac{-\\sin(\\omega_c k)}{-\\pi k} \\exp(j\\omega k) = \\sum_{k=1}^{M} \\frac{\\sin(\\omega_c k)}{\\pi k} \\exp(j\\omega k)$$\nReplacing $k$ with $n$ as the dummy index and substituting back:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n)}{\\pi n} \\exp(-j\\omega n) + \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n)}{\\pi n} \\exp(j\\omega n)$$\nFactoring out the common terms:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n)}{\\pi n} (\\exp(-j\\omega n) + \\exp(j\\omega n))$$\nUsing Euler's identity, $\\exp(j\\theta) + \\exp(-j\\theta) = 2\\cos(\\theta)$, we obtain the simplified real cosine series expression for $H_N(\\omega)$:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\frac{2}{\\pi} \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n}$$\nSince $M = (N-1)/2$, the expression in terms of $N$ is:\n$$H_N(\\omega) = \\frac{\\omega_c}{\\pi} + \\frac{2}{\\pi} \\sum_{n=1}^{(N-1)/2} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n}$$\nThis function is the truncated Fourier series of the ideal frequency response $H_d(\\omega)$, which is a periodic rectangular wave.\n\nNext, we analyze the filter's performance. The ideal response is $H_d(\\omega)=1$ for $|\\omega| < \\omega_c$ and $H_d(\\omega)=0$ for $\\omega_c < |\\omega| \\le \\pi$.\n\nThe passband deviation for $|\\omega| < \\omega_c$ is $\\Delta_p(\\omega;N) = H_N(\\omega) - 1$.\n$$\\Delta_p(\\omega;N) = \\left( \\frac{\\omega_c}{\\pi} + \\frac{2}{\\pi} \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n} \\right) - 1$$\nThis deviation represents the error from truncating the infinite Fourier series of the ideal response. The infinite series converges to $1$ in this region. The error term is thus the tail of the series:\n$$\\Delta_p(\\omega;N) = - \\frac{2}{\\pi} \\sum_{n=M+1}^{\\infty} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n}$$\nAway from the transition edges (i.e., for $|\\omega_c - |\\omega|| \\gg 2\\pi/N$), the magnitude of this deviation decays as $O(1/N)$.\n\nThe stopband magnitude for $|\\omega| > \\omega_c$ is $E_s(\\omega;N) = |H_N(\\omega)|$.\n$$E_s(\\omega;N) = \\left| \\frac{\\omega_c}{\\pi} + \\frac{2}{\\pi} \\sum_{n=1}^{M} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n} \\right|$$\nThis represents the leakage into the stopband. The infinite series converges to $0$ in this region. Thus, $H_N(\\omega)$ is the error itself. Away from the transition edges, the magnitude of these stopband ripples also decays as $O(1/N)$.\n\nFinally, we address the Gibbs phenomenon. The truncation of the Fourier series at $n=M$ causes characteristic oscillations, particularly near the points of discontinuity at $\\omega = \\pm \\omega_c$. The convolution of the ideal rectangular frequency response with the sinc-like spectrum of the rectangular window results in these oscillations. As $N$ increases, the transition band of the filter becomes narrower, and the ripples become more compressed towards the discontinuities. However, the amplitude of the first ripple adjacent to the discontinuity does not decrease. This is the Gibbs phenomenon. In the passband, the frequency response overshoots the target value of $1$ to a peak value of approximately $1.09$. In the stopband, it undershoots the target value of $0$ to a minimum of approximately $-0.09$. The magnitude of this overshoot/undershoot, about $9\\%$ of the jump height at the discontinuity, is a constant independent of the filter length $N$. The phenomenon illustrates the non-uniform convergence of a Fourier series at a jump discontinuity.", "answer": "$$\\boxed{\\frac{\\omega_c}{\\pi} + \\frac{2}{\\pi} \\sum_{n=1}^{(N-1)/2} \\frac{\\sin(\\omega_c n) \\cos(\\omega n)}{n}}$$", "id": "2912668"}, {"introduction": "This computational exercise translates the abstract frequency-domain ripples derived previously into tangible time-domain overshoot and ringing. You will filter a signal with a sharp discontinuity—a step input—and directly observe the Gibbs phenomenon's effects on the output [@problem_id:2436691]. By writing code to measure these artifacts with different window functions, you will develop an intuitive understanding of the classic trade-off between ripple suppression and transition band sharpness in practical FIR filter design.", "problem": "Design a family of linear-phase Finite Impulse Response (FIR) low-pass filters, apply each to a discrete-time unit-step input, and quantify the ripples that appear near the step discontinuity. The task is to formalize and measure the Gibbs phenomenon using well-defined metrics computed directly from first principles. Use the following definitions and requirements.\n\nLet the sampling frequency be $f_s$ in hertz, the filter length (number of taps) be $N$ in samples, and the cutoff frequency be $f_c$ in hertz. Consider a discrete-time unit step input $u[n]$ of amplitude $A=1$ defined by $u[n]=0$ for $n  0$ and $u[n]=1$ for $n \\ge 0$. Implement a finite-length sequence of length $L$ samples that approximates $u[n]$ by placing a single step at index $n_0=\\lfloor L/2 \\rfloor$ so that $x[n]=0$ for $0 \\le n  n_0$ and $x[n]=1$ for $n_0 \\le n \\le L-1$. Use $L=32768$ samples and $A=1$ (dimensionless). Angles are not involved.\n\nFor each test case below, design a causal, real, linear-phase FIR low-pass filter $h[n]$ of length $N$ that approximates the ideal low-pass response with cutoff $f_c$ using the standard windowed-sinc method with the specified window. Denote the discrete-time convolution by $y[n]=(x*h)[n]$. Let the steady-state value be $y_{\\mathrm{ss}}=\\sum_{k=0}^{N-1} h[k]\\cdot A$, which is the output value after transients for a unit-step input.\n\nDefine the following quantitative measures computed directly from $y[n]$:\n- Overshoot ratio $r_{\\mathrm{over}}=\\max\\left(0,\\dfrac{\\max_{n\\in\\mathcal{I}} y[n]-y_{\\mathrm{ss}}}{y_{\\mathrm{ss}}}\\right)$, where the analysis index set is $\\mathcal{I}=\\{n_0,n_0+1,\\dots,n_0+4N-1\\}$ truncated to the valid output index range.\n- Undershoot ratio $r_{\\mathrm{under}}=\\max\\left(0,\\dfrac{y_{\\mathrm{ss}}-\\min_{n\\in\\mathcal{I}} y[n]}{y_{\\mathrm{ss}}}\\right)$.\n- Ripple zero-crossing count $Z$, defined as the number of sign changes in the sequence $w[n]=y[n]-y_{\\mathrm{ss}}$ for $n\\in\\mathcal{I}$ when scanning in increasing $n$ and ignoring any indices where $w[n]=0$ exactly; that is, $Z$ is the count of indices where the sign of $w[n]$ differs from the immediately preceding nonzero-sign sample in $\\mathcal{I}$.\n\nAll frequencies must be interpreted and used in hertz. The output metrics $r_{\\mathrm{over}}$ and $r_{\\mathrm{under}}$ must be reported as decimals (no percent sign), and $Z$ as an integer.\n\nTest suite (each item is one independent case):\n- Case $1$: $N=129$, $f_s=1000$ hertz, $f_c=100$ hertz, window type \"hamming\".\n- Case $2$: $N=129$, $f_s=1000$ hertz, $f_c=100$ hertz, window type \"boxcar\" (rectangular).\n- Case $3$: $N=513$, $f_s=1000$ hertz, $f_c=100$ hertz, window type \"boxcar\" (rectangular).\n- Case $4$: $N=129$, $f_s=1000$ hertz, $f_c=225$ hertz, window type \"boxcar\" (rectangular).\n- Case $5$: $N=31$, $f_s=1000$ hertz, $f_c=100$ hertz, window type \"boxcar\" (rectangular).\n\nProgram input: none. Program operation: implement the definitions as stated for each case, with $x[n]$ defined using $L=32768$ and $n_0=\\lfloor L/2 \\rfloor$, compute $y[n]=(x*h)[n]$ by discrete-time convolution, and then compute $r_{\\mathrm{over}}$, $r_{\\mathrm{under}}$, and $Z$ as defined.\n\nFinal output format: your program should produce a single line containing a top-level list with one sub-list per test case, ordered as given above. Each sub-list must be of the form $[r_{\\mathrm{over}},r_{\\mathrm{under}},Z]$. The two ratios must be rounded to exactly $6$ decimal places, and $Z$ must be an integer. The line must contain no extra characters or spaces beyond commas, brackets, digits, and decimal points. For example, a syntactically valid output with two cases would look like $[[0.012345,0.006789,42],[0.000000,0.000000,0]]$.", "solution": "The problem as stated is subjected to rigorous validation and is found to be valid. It is scientifically grounded in the established principles of digital signal processing, specifically the design of Finite Impulse Response (FIR) filters and the analysis of their transient behavior. It is well-posed, providing all necessary definitions, parameters, and constraints to compute a unique and meaningful solution for each test case. The language is objective and precise, leaving no room for ambiguity. All definitions for signals, filters, and metrics are formal and computationally implementable.\n\nThe task is to design a set of linear-phase FIR low-pass filters using the windowed-sinc method and to quantify the Gibbs phenomenon observed in their step response. The Gibbs phenomenon manifests as persistent overshoot and undershoot (ripples) near a step discontinuity when a signal is reconstructed from a truncated set of its frequency components. This is precisely what occurs when an ideal step input is passed through a practical, non-ideal low-pass filter.\n\nThe design and analysis will proceed in three stages: $1$) FIR filter design, $2$) system response computation, and $3$) metric evaluation.\n\n**1. Linear-Phase FIR Filter Design via the Windowed-Sinc Method**\n\nAn ideal low-pass filter has a rectangular frequency response, which is unity for frequencies below the cutoff frequency $f_c$ and zero above it. The corresponding impulse response $h_{ideal}[n]$ in the discrete-time domain is obtained via the inverse Discrete-Time Fourier Transform (DTFT). For a normalized cutoff frequency $\\omega_c = 2\\pi f_c / f_s$, the ideal impulse response is a sinc function:\n$$h_{ideal}[n] = \\frac{\\sin(\\omega_c n)}{\\pi n} \\quad \\text{for } n \\neq 0$$\nAt $n=0$, the limit of this expression is $h_{ideal}[0] = \\omega_c / \\pi = 2 f_c / f_s$. This impulse response is non-causal (it exists for $n  0$) and has infinite length, making it physically unrealizable.\n\nTo create a practical FIR filter of length $N$, we must truncate $h_{ideal}[n]$. A simple truncation is equivalent to multiplying $h_{ideal}[n]$ by a rectangular window (specified as \"boxcar\"). This abrupt truncation in the time domain leads to significant ripples in the frequency domain (the Gibbs phenomenon's spectral manifestation). To mitigate this, a smoother window function $w[n]$, such as the Hamming window, is applied. The windowed impulse response is:\n$$h_{w}[n] = h_{ideal}[n] \\cdot w[n]$$\nFor a length-$N$ filter, where $N$ is specified as an odd integer in all test cases, this operation is performed over a symmetric interval around zero, typically $n \\in \\{-(N-1)/2, \\dots, (N-1)/2\\}$. The resulting filter $h_w[n]$ is non-causal but has zero phase.\n\nTo make the filter causal, its impulse response is shifted by $M = (N-1)/2$ samples. The final, causal, linear-phase FIR filter $h[n]$ has coefficients:\n$$h[n] = h_{w}[n - M] \\quad \\text{for } n \\in \\{0, 1, \\dots, N-1\\}$$\nThis delay of $M$ samples ensures the filter is physically realizable, and because the original unshifted impulse response was symmetric, the phase response of the causal filter is linear.\n\nFinally, the filter coefficients are normalized to ensure unity gain at DC (zero frequency), meaning $\\sum_{k=0}^{N-1} h[k] = 1$. This guarantees that the steady-state response to a unit-amplitude step input is unity, i.e., $y_{\\mathrm{ss}} = A \\sum_{k=0}^{N-1} h[k] = 1 \\cdot 1 = 1$. This normalization provides a stable baseline for quantifying overshoot and undershoot. The `scipy.signal.firwin` function provides a canonical implementation of this entire windowed-sinc design process.\n\n**2. System Response to a Step Input**\n\nThe input signal $x[n]$ is a finite-length approximation of a discrete-time unit step, defined over $L = 32768$ samples. The step occurs at index $n_0 = \\lfloor L/2 \\rfloor = 16384$. Thus, $x[n] = 0$ for $n  n_0$ and $x[n] = 1$ for $n \\ge n_0$.\n\nThe output signal $y[n]$ is the result of the discrete-time convolution of the input signal $x[n]$ with the filter's impulse response $h[n]$:\n$$y[n] = (x * h)[n] = \\sum_{k=0}^{N-1} h[k] x[n-k]$$\nThe length of the resulting output sequence $y[n]$ is $L + N - 1$. The convolution operation effectively applies the filter to the input signal.\n\n**3. Quantitative Analysis of Ripples**\n\nThe problem requires the computation of three metrics to quantify the Gibbs phenomenon in the filter's step response. These are computed over an analysis index set $\\mathcal{I}=\\{n_0, n_0+1, \\dots, n_0+4N-1\\}$, which focuses on the region immediately following the step discontinuity where transients are most prominent.\n\n- **Steady-State Value ($y_{\\mathrm{ss}}$)**: As per the definition and our filter normalization, $y_{\\mathrm{ss}} = \\sum_{k=0}^{N-1} h[k] \\cdot A = 1.0$, where $A=1$.\n\n- **Overshoot Ratio ($r_{\\mathrm{over}}$)**: This metric measures the maximum positive deviation from the steady-state value, normalized by the steady-state value itself.\n$$r_{\\mathrm{over}} = \\max\\left(0, \\frac{\\max_{n \\in \\mathcal{I}} y[n] - y_{\\mathrm{ss}}}{y_{\\mathrm{ss}}}\\right)$$\n\n- **Undershoot Ratio ($r_{\\mathrm{under}}$)**: This metric measures the maximum negative deviation (dip below the baseline before the step or initial ripple trough after the step), also normalized.\n$$r_{\\mathrm{under}} = \\max\\left(0, \\frac{y_{\\mathrm{ss}} - \\min_{n \\in \\mathcal{I}} y[n]}{y_{\\mathrm{ss}}}\\right)$$\n\n- **Ripple Zero-Crossing Count ($Z$)**: This metric counts how many times the ripple waveform $w[n] = y[n] - y_{\\mathrm{ss}}$ crosses the steady-state value within the analysis interval $\\mathcal{I}$. It is calculated by counting the sign changes in the sequence $w[n]$ after removing any samples where $w[n]$ is exactly zero. This gives an indication of the ripple frequency.\n\nThe implementation will systematically execute these steps for each test case, providing a quantitative comparison of filter performance and a clear demonstration of the Gibbs phenomenon. For example, comparing Case $1$ (Hamming) and Case $2$ (boxcar) will demonstrate the superior ripple suppression of the Hamming window. Comparing Cases $2$, $3$, and $5$ (all boxcar) will show how filter length $N$ affects the transition sharpness and ripple characteristics. Specifically, the overshoot for the boxcar window is expected to be approximately $9\\%$ of the step height, regardless of $N$, illustrating a fundamental property of the Gibbs phenomenon.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import firwin, get_window\n\ndef solve():\n    \"\"\"\n    Designs FIR filters, computes their step response, and quantifies Gibbs phenomenon.\n    \"\"\"\n    # Define problem constants\n    L = 32768\n    A = 1.0\n    n_0 = L // 2\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, fs, fc, window_type)\n        (129, 1000, 100, \"hamming\"),\n        (129, 1000, 100, \"boxcar\"),\n        (513, 1000, 100, \"boxcar\"),\n        (129, 1000, 225, \"boxcar\"),\n        (31, 1000, 100, \"boxcar\"),\n    ]\n\n    results = []\n    \n    # Generate the discrete-time step input signal x[n]\n    x = np.zeros(L)\n    x[n_0:] = A\n\n    for case in test_cases:\n        N, fs, fc, window_type = case\n\n        # --- 1. FIR Filter Design (Windowed-Sinc Method) ---\n        # The firwin function implements the windowed-sinc method.\n        # It requires the cutoff frequency to be normalized by the Nyquist frequency.\n        nyquist_freq = fs / 2.0\n        normalized_cutoff = fc / nyquist_freq\n        \n        # Design the causal, linear-phase FIR filter.\n        # firwin automatically normalizes the filter for unity gain at DC.\n        h = firwin(N, normalized_cutoff, window=window_type, pass_zero='lowpass')\n\n        # --- 2. System Response Computation ---\n        # Convolve the input signal x[n] with the filter impulse response h[n]\n        y = np.convolve(x, h, mode='full')\n\n        # --- 3. Metric Computation ---\n        # The analysis index set is I = {n_0, n_0+1, ..., n_0 + 4N - 1}\n        # The problem statement guarantees this is within the valid output range.\n        analysis_start = n_0\n        analysis_end = n_0 + 4 * N\n        y_analysis = y[analysis_start:analysis_end]\n        \n        # Calculate the steady-state value. Since A=1 and firwin normalizes\n        # the filter, y_ss = sum(h), which is approximately 1.0.\n        y_ss = np.sum(h) * A\n\n        # Calculate overshoot ratio\n        y_max = np.max(y_analysis)\n        r_over = np.maximum(0.0, (y_max - y_ss) / y_ss)\n\n        # Calculate undershoot ratio\n        y_min = np.min(y_analysis)\n        r_under = np.maximum(0.0, (y_ss - y_min) / y_ss)\n        \n        # Calculate ripple zero-crossing count Z\n        # w[n] = y[n] - y_ss\n        w = y_analysis - y_ss\n        \n        # Ignore indices where w[n] is exactly zero, as per problem definition\n        w_nonzero = w[w != 0]\n        \n        # Count sign changes\n        signs = np.sign(w_nonzero)\n        sign_changes = signs[:-1] * signs[1:]\n        Z = np.sum(sign_changes  0)\n\n        # Append formatted results\n        results.append([\n            round(r_over, 6),\n            round(r_under, 6), \n            int(Z)\n        ])\n    \n    # Format the results into the required string format\n    # Example: [[0.012345,0.006789,42],[0.000000,0.000000,0]]\n    result_str = str(results).replace(\" \", \"\")\n\n    # Final print statement in the exact required format.\n    print(result_str)\n\nsolve()\n```", "id": "2436691"}, {"introduction": "Moving beyond standard, predefined window functions, this final practice introduces an optimization-based approach, a cornerstone of modern filter design. You will formulate the design task as a linear program, creating a custom polynomial \"summability factor\" that explicitly minimizes the Gibbs overshoot while satisfying other critical performance constraints on ripple and transition width [@problem_id:2912649]. This exercise demonstrates how to achieve superior performance by directly tailoring a filter's characteristics to meet precise specifications.", "problem": "You are asked to formalize, analyze, and implement an optimization-based design of a finite impulse response (FIR) low-pass approximation that reduces the Gibbs phenomenon by applying a polynomial summability factor to Fourier coefficients. The design targets the ideal discrete-time low-pass frequency response with a jump discontinuity, and uses summability to trade off overshoot against transition width.\n\nAssume the following foundational definitions, which you may take as given:\n\n- For an ideal low-pass of cutoff frequency $\\,\\omega_c \\in (0,\\pi)\\,$ (radians), the $\\,2\\pi$-periodic frequency response $\\,H^\\star(\\omega)\\,$ equals $\\,1\\,$ for $\\,|\\omega| \\le \\omega_c\\,$ and $\\,0\\,$ for $\\,|\\omega|  \\omega_c\\,$. Its complex Fourier series coefficients $\\,\\{c_n\\}_{n \\in \\mathbb{Z}}\\,$ are\n  - $\\,c_0 = \\omega_c/\\pi\\,$,\n  - $\\,c_n = \\dfrac{\\sin(n\\omega_c)}{\\pi n}\\,$ for $\\,n \\ne 0\\,$,\n  and satisfy $\\,c_{-n} = c_n\\,$ so the truncated reconstruction is real-valued.\n- For a fixed truncation order $\\,N \\in \\mathbb{N}\\,$, define a polynomial sigma factor $\\,\\sigma(x) = \\sum_{k=0}^{p} a_k x^k\\,$ for $\\,x \\in [0,1]\\,$, where $\\,p \\in \\mathbb{N}\\,$ is the polynomial degree and $\\,\\{a_k\\}\\,$ are real coefficients.\n- The sigma-weighted partial Fourier sum is\n  $$ H_{N,\\sigma}(\\omega) \\;=\\; \\sum_{n=-N}^{N} \\sigma\\!\\left(\\frac{|n|}{N}\\right) c_n \\, e^{i n \\omega}\n  \\;=\\; \\sigma(0)c_0 + 2\\sum_{n=1}^{N} \\sigma\\!\\left(\\frac{n}{N}\\right) c_n \\cos(n\\omega), $$\n  which approximates $\\,H^\\star(\\omega)\\,$ and exhibits Gibbs-type ringing around $\\,\\omega = \\pm \\omega_c\\,$.\n\nFor specified $\\,\\Delta \\in (0,\\pi)\\,$, define passband and stopband edges by\n- $\\,\\omega_p = \\omega_c - \\Delta\\,$,\n- $\\,\\omega_s = \\omega_c + \\Delta\\,$,\ninterpreting $\\,\\Delta\\,$ as a transition half-width in radians. Let $\\,\\rho \\in (0,1)\\,$ denote a fixed bound used for in-band and out-of-band magnitude constraints.\n\nYour tasks are:\n\n1) Formulate, from first principles, a programmatic method to choose the polynomial coefficients $\\,\\{a_k\\}_{k=0}^{p}\\,$ that minimizes the maximum overshoot in the passband away from the transition region. Specifically, define the overshoot objective as\n$$ t \\;=\\; \\sup_{\\omega \\in [0,\\omega_p]} \\max\\!\\big(H_{N,\\sigma}(\\omega) - 1, \\, 0\\big). $$\n\n2) Impose the following constraints in your formulation:\n- Coefficient-side sigma constraints evaluated on the discrete grid $\\,x_m = m/N\\,$ for $\\,m = 0,1,\\dots,N$:\n  - $\\,\\sigma(0) = 1\\,$,\n  - $\\,0 \\le \\sigma(x_m) \\le 1\\,$ for all $\\,m\\,$,\n  - $\\,\\sigma(x_{m+1}) \\le \\sigma(x_m)\\,$ for all $\\,m \\in \\{0,\\dots,N-1\\}$ (monotone non-increasing).\n- Frequency-side constraints away from the transition band:\n  - $\\,H_{N,\\sigma}(\\omega) \\ge 1 - \\rho\\,$ for all $\\,\\omega \\in [0,\\omega_p]\\,$,\n  - $\\,H_{N,\\sigma}(\\omega) \\le \\rho\\,$ for all $\\,\\omega \\in [\\omega_s,\\pi]\\,$.\n\n3) Show how to reduce this problem, using only the above fundamental definitions of Fourier series and linearity of summation, to a finite-dimensional optimization problem on a discrete frequency grid and coefficient grid. Your objective should be to express the constraints and the overshoot objective in a form that is linear in the unknown polynomial coefficients $\\,\\{a_k\\}\\,$ and an auxiliary scalar $\\,t\\,$.\n\n4) Implement a complete program that:\n- Constructs the truncated coefficients $\\,\\{c_n\\}\\,$ from $\\,\\omega_c\\,$ and $\\,N\\,$.\n- Builds discrete grids for frequencies and coefficient arguments sufficient to enforce the constraints.\n- Solves the resulting finite-dimensional optimization to obtain the minimized $\\,t\\,$.\n- Reports the optimized overshoot $\\,t\\,$ for each test case below.\n\nAll angles are in radians. No other physical units are involved. Numeric results should be returned as floats.\n\nUse the following test suite, each test case being the tuple $\\,(\\,N,\\,p,\\,\\omega_c,\\,\\Delta,\\,\\rho\\,)$:\n- Test 1: $\\,(\\,32,\\,4,\\,1.7,\\,0.25,\\,0.10\\,)$\n- Test 2: $\\,(\\,32,\\,2,\\,2.1,\\,0.20,\\,0.12\\,)$\n- Test 3: $\\,(\\,12,\\,3,\\,1.3,\\,0.30,\\,0.10\\,)$\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each entry being the minimized overshoot $\\,t\\,$ for the corresponding test case, rounded to six decimal places (for example, \"[0.012345,0.067890,0.001234]\").", "solution": "The problem posed is to design a finite impulse response (FIR) low-pass filter by optimizing the coefficients of a polynomial summability factor, $\\sigma(x)$, applied to the truncated Fourier series of an ideal low-pass filter. The objective is to minimize the passband overshoot (part of the Gibbs phenomenon) subject to several constraints on the factor $\\sigma$ and the resulting frequency response $H_{N,\\sigma}(\\omega)$. This problem will be shown to be equivalent to a finite-dimensional linear program.\n\nThe frequency response of the sigma-weighted approximation is given by\n$$ H_{N,\\sigma}(\\omega) = \\sum_{n=-N}^{N} \\sigma\\left(\\frac{|n|}{N}\\right) c_n \\, e^{i n \\omega} $$\nwhere $N$ is the truncation order, $\\{c_n\\}$ are the Fourier coefficients of the ideal low-pass filter, and $\\sigma(x)$ is a polynomial of degree $p$:\n$$ \\sigma(x) = \\sum_{k=0}^{p} a_k x^k. $$\nThe variables to be optimized are the polynomial coefficients $\\{a_k\\}_{k=0}^p$.\n\nWe substitute the polynomial form of $\\sigma(x)$ into the expression for $H_{N,\\sigma}(\\omega)$:\n$$ H_{N,\\sigma}(\\omega) = \\sum_{n=-N}^{N} \\left( \\sum_{k=0}^{p} a_k \\left(\\frac{|n|}{N}\\right)^k \\right) c_n \\, e^{i n \\omega}. $$\nBy linearity, we can interchange the order of summation:\n$$ H_{N,\\sigma}(\\omega) = \\sum_{k=0}^{p} a_k \\left( \\sum_{n=-N}^{N} c_n \\left(\\frac{|n|}{N}\\right)^k e^{i n \\omega} \\right). $$\nThis demonstrates that $H_{N,\\sigma}(\\omega)$ is a linear function of the coefficients $\\{a_k\\}$. We define the basis functions $B_k(\\omega)$ for $k \\in \\{0, \\dots, p\\}$ as\n$$ B_k(\\omega) = \\sum_{n=-N}^{N} c_n \\left(\\frac{|n|}{N}\\right)^k e^{i n \\omega}. $$\nSince the ideal response $H^\\star(\\omega)$ is real and even, its Fourier coefficients are real and satisfy $c_{-n} = c_n$. The basis functions are therefore also real and even:\n$$ B_k(\\omega) = c_0 \\left(\\frac{0}{N}\\right)^k + 2 \\sum_{n=1}^{N} c_n \\left(\\frac{n}{N}\\right)^k \\cos(n\\omega). $$\nFor $k=0$, $(0/N)^0 = 1$. For $k0$, $(0/N)^k=0$. Thus,\n$$ B_0(\\omega) = c_0 + 2 \\sum_{n=1}^{N} c_n \\cos(n\\omega), $$\n$$ B_k(\\omega) = 2 \\sum_{n=1}^{N} c_n \\left(\\frac{n}{N}\\right)^k \\cos(n\\omega) \\quad \\text{for } k \\in \\{1, \\dots, p\\}. $$\nThe frequency response is then expressed as a linear combination of these pre-computable basis functions:\n$$ H_{N,\\sigma}(\\omega) = \\sum_{k=0}^{p} a_k B_k(\\omega). $$\n\nThe problem is to minimize the overshoot $t = \\sup_{\\omega \\in [0,\\omega_p]} \\max(H_{N,\\sigma}(\\omega) - 1, 0)$ subject to a set of constraints. We can formulate this as a linear program by introducing $t$ as an optimization variable. The problem becomes:\nMinimize $t$\nSubject to:\n1. $t \\ge H_{N,\\sigma}(\\omega) - 1$ for all $\\omega \\in [0, \\omega_p]$.\n2. $t \\ge 0$.\n3. Coefficient-side constraints on $\\sigma(x)$.\n4. Frequency-side constraints on $H_{N,\\sigma}(\\omega)$.\n\nThe constraints involving continuous domains (e.g., \"for all $\\omega \\in [0, \\omega_p]$\") are rendered finite by discretizing the frequency and coefficient evaluation points. A sufficiently dense grid of frequencies $\\Omega = \\{\\omega_j\\}$ on $[0, \\pi]$ and the specified grid $x_m = m/N$ for the sigma factor are used.\n\nLet us detail the constraints and formulate the linear program. The optimization variables are $\\mathbf{x} = [t, a_1, \\dots, a_p]^T$. The constraint $\\sigma(0)=1$ implies $a_0 = 1$, which simplifies the problem by fixing one coefficient. The remaining $p$ coefficients $\\{a_k\\}_{k=1}^p$ and $t$ constitute the $p+1$ variables.\n\nObjective Function: Minimize $t$. This corresponds to an objective vector $\\mathbf{c} = [1, 0, \\dots, 0]^T$ such that we minimize $\\mathbf{c}^T \\mathbf{x}$.\n\nConstraints in Linear Form ($\\mathbf{A}\\mathbf{x} \\le \\mathbf{b}$):\n\n1.  **Overshoot Constraint**: $t \\ge H_{N,\\sigma}(\\omega) - 1$ for $\\omega \\in [0, \\omega_p]$.\n    This is equivalent to $H_{N,\\sigma}(\\omega) - t \\le 1$. Substituting the linear form of $H_{N,\\sigma}(\\omega)$ and $a_0=1$:\n    $$ \\left( B_0(\\omega) + \\sum_{k=1}^{p} a_k B_k(\\omega) \\right) - t \\le 1 \\implies \\sum_{k=1}^{p} a_k B_k(\\omega) - t \\le 1 - B_0(\\omega). $$\n    For each frequency $\\omega_j$ on a discrete grid in $[0, \\omega_p]$, this yields a linear inequality in the variables.\n\n2.  **Sigma Factor Value Constraints**: $0 \\le \\sigma(x_m) \\le 1$ for $m \\in \\{0, \\dots, N\\}$.\n    Since $\\sigma(x_m) = 1 + \\sum_{k=1}^{p} a_k (m/N)^k$, this becomes two sets of inequalities:\n    - $\\sigma(x_m) \\ge 0 \\implies 1 + \\sum_{k=1}^{p} a_k (m/N)^k \\ge 0 \\implies \\sum_{k=1}^{p} a_k (-(m/N)^k) \\le 1$.\n    - $\\sigma(x_m) \\le 1 \\implies 1 + \\sum_{k=1}^{p} a_k (m/N)^k \\le 1 \\implies \\sum_{k=1}^{p} a_k (m/N)^k \\le 0$.\n    These must hold for each $m \\in \\{1, \\dots, N\\}$ (the case $m=0$ is trivial).\n\n3.  **Sigma Factor Monotonicity Constraint**: $\\sigma(x_{m+1}) \\le \\sigma(x_m)$ for $m \\in \\{0, \\dots, N-1\\}$.\n    $$ 1 + \\sum_{k=1}^{p} a_k \\left(\\frac{m+1}{N}\\right)^k \\le 1 + \\sum_{k=1}^{p} a_k \\left(\\frac{m}{N}\\right)^k \\implies \\sum_{k=1}^{p} a_k \\left[ \\left(\\frac{m+1}{N}\\right)^k - \\left(\\frac{m}{N}\\right)^k \\right] \\le 0. $$\n    This provides a linear inequality for each $m$.\n\n4.  **Passband Ripple Constraint**: $H_{N,\\sigma}(\\omega) \\ge 1 - \\rho$ for $\\omega \\in [0, \\omega_p]$, with $\\rho \\in (0,1)$.\n    $$ B_0(\\omega) + \\sum_{k=1}^{p} a_k B_k(\\omega) \\ge 1 - \\rho \\implies \\sum_{k=1}^{p} a_k (-B_k(\\omega)) \\le B_0(\\omega) - (1-\\rho). $$\n    This is applied for each discrete frequency $\\omega_j$ in the passband.\n\n5.  **Stopband Attenuation Constraint**: $H_{N,\\sigma}(\\omega) \\le \\rho$ for $\\omega \\in [\\omega_s, \\pi]$.\n    $$ B_0(\\omega) + \\sum_{k=1}^{p} a_k B_k(\\omega) \\le \\rho \\implies \\sum_{k=1}^{p} a_k B_k(\\omega) \\le \\rho - B_0(\\omega). $$\n    This is applied for each discrete frequency $\\omega_j$ in the stopband.\n\n6.  **Non-negativity of Overshoot**: The variable $t$ must be non-negative, $t \\ge 0$. This can be handled as a bound in the LP solver.\n\nBy collecting all these linear inequalities, we construct a large system of the form $\\mathbf{A}_{\\text{ub}}\\mathbf{x} \\le \\mathbf{b}_{\\text{ub}}$, where $\\mathbf{x} = [t, a_1, \\dots, a_p]^T$. This is a standard Linear Programming problem that can be solved using numerical algorithms, such as the simplex method, to find the optimal values of $t$ and $\\{a_k\\}$. The provided program implements this procedure.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linprog\n\ndef solve():\n    \"\"\"\n    Solves the FIR filter design optimization problem for a suite of test cases.\n    \"\"\"\n    test_cases = [\n        # (N, p, omega_c, Delta, rho)\n        (32, 4, 1.7, 0.25, 0.10),\n        (32, 2, 2.1, 0.20, 0.12),\n        (12, 3, 1.3, 0.30, 0.10),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, p, omega_c, Delta, rho = case\n        min_overshoot = run_optimization_case(N, p, omega_c, Delta, rho)\n        results.append(min_overshoot)\n\n    # Format the output as specified.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\ndef run_optimization_case(N, p, omega_c, Delta, rho):\n    \"\"\"\n    Formulates and solves the linear program for a single test case.\n\n    Args:\n        N (int): Truncation order.\n        p (int): Polynomial degree of the sigma factor.\n        omega_c (float): Cutoff frequency in radians.\n        Delta (float): Transition half-width in radians.\n        rho (float): In-band and out-of-band magnitude constraint bound.\n\n    Returns:\n        float: The minimized overshoot value 't'.\n    \"\"\"\n    omega_p = omega_c - Delta\n    omega_s = omega_c + Delta\n\n    # Step 1: Pre-computation of basis functions and grids\n    n_series = np.arange(1, N + 1)\n    c0 = omega_c / np.pi\n    cn = np.sin(n_series * omega_c) / (np.pi * n_series)\n\n    # A dense frequency grid is necessary to approximate continuous constraints\n    M = 2048 \n    omega_grid = np.linspace(0, np.pi, M, endpoint=True)\n    \n    passband_indices = np.where(omega_grid = omega_p)[0]\n    stopband_indices = np.where(omega_grid >= omega_s)[0]\n\n    # Pre-calculate cos(n*omega) matrix for vectorization\n    # Shape: (M, N)\n    cos_mat = np.cos(np.outer(omega_grid, n_series))\n\n    # B_k(omega) basis functions, evaluated on the frequency grid\n    B0_grid = c0 + 2 * cos_mat @ cn\n    \n    # Bk_grids will have shape (p, M)\n    Bk_grids_list = []\n    for k in range(1, p + 1):\n        n_pow_k = (n_series / N)**k\n        Bk_grid = 2 * cos_mat @ (cn * n_pow_k)\n        Bk_grids_list.append(Bk_grid)\n    Bk_grids = np.array(Bk_grids_list)\n\n    # Step 2: Construct the Linear Program matrices and vectors\n    # Optimization variables x = [t, a_1, ..., a_p], total p+1 variables\n    c = np.zeros(p + 1)\n    c[0] = 1.0  # Objective: minimize t\n\n    A_ub_list, b_ub_list = [], []\n\n    # Constraint 1: Overshoot (H - 1 = t over passband)\n    # Becomes: sum(ak*Bk) - t = 1 - B0\n    A_row_part = Bk_grids[:, passband_indices].T\n    A_rows = np.hstack([-np.ones((len(passband_indices), 1)), A_row_part])\n    b_rows = 1.0 - B0_grid[passband_indices]\n    A_ub_list.append(A_rows)\n    b_ub_list.append(b_rows)\n\n    # Constraint 2: Sigma factor value (0 = sigma(x_m) = 1)\n    m_series = np.arange(1, N + 1)\n    xm_series = m_series / N\n    # poly_terms_mat has shape (N, p) where entry (m-1, k-1) is (m/N)^k\n    poly_terms_mat = np.power.outer(xm_series, np.arange(1, p + 1))\n    \n    # sigma >= 0  => -sum(ak * xm^k) = 1\n    A_rows_ge0 = np.hstack([np.zeros((N, 1)), -poly_terms_mat])\n    b_rows_ge0 = np.ones(N)\n    A_ub_list.append(A_rows_ge0)\n    b_ub_list.append(b_rows_ge0)\n\n    # sigma = 1  => sum(ak * xm^k) = 0\n    A_rows_le1 = np.hstack([np.zeros((N, 1)), poly_terms_mat])\n    b_rows_le1 = np.zeros(N)\n    A_ub_list.append(A_rows_le1)\n    b_ub_list.append(b_rows_le1)\n\n    # Constraint 3: Sigma factor monotonicity (sigma(x_{m+1}) = sigma(x_m))\n    m_mono = np.arange(0, N)\n    xm_mono = m_mono / N\n    xm1_mono = (m_mono + 1) / N\n    # shape (N, p)\n    diff_poly_terms = np.power.outer(xm1_mono, np.arange(1, p + 1)) - \\\n                      np.power.outer(xm_mono, np.arange(1, p + 1))\n    A_rows = np.hstack([np.zeros((N, 1)), diff_poly_terms])\n    b_rows = np.zeros(N)\n    A_ub_list.append(A_rows)\n    b_ub_list.append(b_rows)\n\n    # Constraint 4: Passband ripple (H >= 1-rho)\n    # Becomes: -sum(ak*Bk) = B0 - (1-rho)\n    A_row_part = -Bk_grids[:, passband_indices].T\n    A_rows = np.hstack([np.zeros((len(passband_indices), 1)), A_row_part])\n    b_rows = B0_grid[passband_indices] - (1.0 - rho)\n    A_ub_list.append(A_rows)\n    b_ub_list.append(b_rows)\n    \n    # Constraint 5: Stopband attenuation (H = rho)\n    # Becomes: sum(ak*Bk) = rho - B0\n    A_row_part = Bk_grids[:, stopband_indices].T\n    A_rows = np.hstack([np.zeros((len(stopband_indices), 1)), A_row_part])\n    b_rows = rho - B0_grid[stopband_indices]\n    A_ub_list.append(A_rows)\n    b_ub_list.append(b_rows)\n\n    A_ub = np.vstack(A_ub_list)\n    b_ub = np.concatenate(b_ub_list)\n\n    # Bounds: t >= 0, a_k are unbounded\n    bounds = [(0, None)] + [(None, None)] * p\n\n    # Step 3: Solve the Linear Program\n    res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n    \n    if not res.success or res.fun is None:\n        # Fallback for robustness or if problem is dual-infeasible\n        res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs-ds')\n    \n    if res.success and res.fun is not None:\n        return res.fun\n    else:\n        # This case suggests the problem is infeasible or unbounded,\n        # which shouldn't occur for the given test cases.\n        return np.nan\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2912649"}]}