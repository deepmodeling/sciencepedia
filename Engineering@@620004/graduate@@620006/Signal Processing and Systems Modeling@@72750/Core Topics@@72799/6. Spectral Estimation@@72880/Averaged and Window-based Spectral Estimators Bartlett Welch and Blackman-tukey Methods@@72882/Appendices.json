{"hands_on_practices": [{"introduction": "The performance of window-based spectral estimators is fundamentally determined by the properties of the chosen data window. This practice [@problem_id:2853923] guides you through the derivation of key performance metrics—Coherent Gain, Noise Gain, and Equivalent Noise Bandwidth—for several standard windows. Completing this exercise will provide a first-principles understanding of how different window shapes influence the trade-off between spectral resolution and leakage suppression.", "id": "2853923", "problem": "A discrete-time spectral estimator within the averaged periodogram family (e.g., the method of Peter Welch) applies a deterministic data window to each data segment prior to the Discrete Fourier Transform (DFT). Let a real-valued length-$L$ data taper be denoted by $w[n]$ for $n \\in \\{0,1,\\dots,L-1\\}$. Define the following baseline quantities from first principles:\n- The coherent gain (CG): $\\,\\mathrm{CG} \\triangleq \\frac{1}{L}\\sum_{n=0}^{L-1} w[n]$.\n- The noise gain (NG): $\\,\\mathrm{NG} \\triangleq \\frac{1}{L}\\sum_{n=0}^{L-1} w[n]^2$.\n- The equivalent noise bandwidth (ENBW, in DFT bins): $\\,\\mathrm{ENBW} \\triangleq \\frac{L\\,\\sum_{n=0}^{L-1} w[n]^2}{\\left(\\sum_{n=0}^{L-1} w[n]\\right)^2}$.\n\nStarting only from these definitions and elementary trigonometric sum identities, derive closed-form expressions in $L$ for $\\mathrm{CG}$, $\\mathrm{NG}$, and $\\mathrm{ENBW}$ for each of the following standard windows (with the usual end-point convention based on $L-1$ in the cosine arguments), then specialize your expressions to $L=256$:\n1. Rectangular: $w[n]=1$.\n2. Hann: $w[n]=\\frac{1}{2}-\\frac{1}{2}\\cos\\!\\left(\\frac{2\\pi n}{L-1}\\right)$.\n3. Hamming: $w[n]=0.54-0.46\\cos\\!\\left(\\frac{2\\pi n}{L-1}\\right)$.\n4. Blackman: $w[n]=0.42-0.5\\cos\\!\\left(\\frac{2\\pi n}{L-1}\\right)+0.08\\cos\\!\\left(\\frac{4\\pi n}{L-1}\\right)$.\n\nNext, interpret $\\mathrm{ENBW}$ in terms of the power spectral window $|W(\\mathrm{e}^{\\mathrm{j}\\omega})|^2$ via Parseval’s relation, and explain qualitatively why, at fixed $\\mathrm{ENBW}$ (i.e., equal mainlobe width), generalized-cosine windows with more cosine terms tend to exhibit stronger sidelobe suppression (reduced spectral leakage) than those with fewer terms. Based on this reasoning, provide an ordering (from best to worst) of the four windows by leakage suppression at equal $\\mathrm{ENBW}$, and justify your ordering without invoking any unpublished or ad hoc facts.\n\nFinally, report a single scalar: the $\\mathrm{ENBW}$ (in DFT bins) of the Blackman window at $L=256$. Express this final number in DFT bins (dimensionless) and round your answer to six significant figures.", "solution": "The problem is well-posed, scientifically grounded, and provides all necessary information for a complete solution. We shall proceed with the derivation.\n\nThe core task is to compute the Coherent Gain ($\\mathrm{CG}$), Noise Gain ($\\mathrm{NG}$), and Equivalent Noise Bandwidth ($\\mathrm{ENBW}$) for four different window functions of length $L$. The definitions are given as:\n$$ \\mathrm{CG} \\triangleq \\frac{1}{L}\\sum_{n=0}^{L-1} w[n] $$\n$$ \\mathrm{NG} \\triangleq \\frac{1}{L}\\sum_{n=0}^{L-1} w[n]^2 $$\n$$ \\mathrm{ENBW} \\triangleq \\frac{L\\,\\sum_{n=0}^{L-1} w[n]^2}{\\left(\\sum_{n=0}^{L-1} w[n]\\right)^2} $$\n\nTo evaluate these quantities for the generalized cosine windows, we must first evaluate the sums of the cosine terms and their powers over the interval $n \\in \\{0, 1, \\dots, L-1\\}$. Let $\\theta_k = \\frac{2\\pi k}{L-1}$. We need to compute sums of the form $\\sum_{n=0}^{L-1} \\cos(n\\theta_k)$. This is a geometric series sum:\n$$ \\sum_{n=0}^{L-1} \\exp(j n \\theta_k) = \\sum_{n=0}^{L-1} (\\exp(j \\theta_k))^n $$\nFor integer $k$ not a multiple of $L-1$, $\\exp(j \\theta_k) \\neq 1$. The sum is:\n$$ \\frac{\\exp(j L \\theta_k) - 1}{\\exp(j \\theta_k) - 1} = \\frac{\\exp\\left(j \\frac{2\\pi k L}{L-1}\\right) - 1}{\\exp\\left(j \\frac{2\\pi k}{L-1}\\right) - 1} = \\frac{\\exp\\left(j 2\\pi k \\frac{L-1+1}{L-1}\\right) - 1}{\\exp(j \\theta_k) - 1} = \\frac{\\exp(j 2\\pi k) \\exp(j \\theta_k) - 1}{\\exp(j \\theta_k) - 1} = \\frac{\\exp(j \\theta_k) - 1}{\\exp(j \\theta_k) - 1} = 1 $$\nTaking the real part, we find a crucial identity for our derivations:\n$$ S_c(k) = \\sum_{n=0}^{L-1} \\cos\\left(\\frac{2\\pi k n}{L-1}\\right) = 1 \\quad (\\text{for integer } k \\text{ not a multiple of } L-1) $$\nWe also need sums of products of cosines. Using the identity $\\cos^2(x) = \\frac{1}{2}(1+\\cos(2x))$:\n$$ \\sum_{n=0}^{L-1} \\cos^2\\left(\\frac{2\\pi k n}{L-1}\\right) = \\sum_{n=0}^{L-1} \\frac{1}{2}\\left(1 + \\cos\\left(\\frac{4\\pi k n}{L-1}\\right)\\right) = \\frac{1}{2} \\sum_{n=0}^{L-1} 1 + \\frac{1}{2} \\sum_{n=0}^{L-1} \\cos\\left(\\frac{2\\pi (2k) n}{L-1}\\right) $$\nAssuming $2k$ is not a multiple of $L-1$ (which is true for $k=1,2$ and $L > 5$):\n$$ \\sum_{n=0}^{L-1} \\cos^2\\left(\\frac{2\\pi k n}{L-1}\\right) = \\frac{L}{2} + \\frac{1}{2} S_c(2k) = \\frac{L+1}{2} $$\nUsing $\\cos(x)\\cos(y) = \\frac{1}{2}(\\cos(x-y)+\\cos(x+y))$ for $k_1 \\neq k_2$:\n$$ \\sum_{n=0}^{L-1} \\cos\\left(\\frac{2\\pi k_1 n}{L-1}\\right)\\cos\\left(\\frac{2\\pi k_2 n}{L-1}\\right) = \\frac{1}{2} \\left[ S_c(k_1-k_2) + S_c(k_1+k_2) \\right] = \\frac{1}{2}(1+1) = 1 $$\n(assuming $k_1 \\pm k_2$ are not multiples of $L-1$).\n\nNow we compute the quantities for each window. Let $\\sum w = \\sum_{n=0}^{L-1} w[n]$ and $\\sum w^2 = \\sum_{n=0}^{L-1} w[n]^2$.\n\n**1. Rectangular Window: $w[n]=1$**\n$$ \\sum w = \\sum_{n=0}^{L-1} 1 = L $$\n$$ \\sum w^2 = \\sum_{n=0}^{L-1} 1^2 = L $$\n$$ \\mathrm{CG} = \\frac{L}{L} = 1 $$\n$$ \\mathrm{NG} = \\frac{L}{L} = 1 $$\n$$ \\mathrm{ENBW} = \\frac{L \\cdot L}{L^2} = 1 $$\nThese results are exact for any $L$. For $L=256$, they are $1, 1, 1$.\n\n**2. Hann Window: $w[n]=\\frac{1}{2}-\\frac{1}{2}\\cos(\\frac{2\\pi n}{L-1})$**\n$$ \\sum w = \\sum_{n=0}^{L-1} \\left(\\frac{1}{2} - \\frac{1}{2}\\cos\\left(\\frac{2\\pi n}{L-1}\\right)\\right) = \\frac{1}{2}L - \\frac{1}{2}S_c(1) = \\frac{1}{2}(L-1) $$\n$$ \\sum w^2 = \\sum_{n=0}^{L-1} \\left(\\frac{1}{4} - \\frac{1}{2}\\cos\\left(\\frac{2\\pi n}{L-1}\\right) + \\frac{1}{4}\\cos^2\\left(\\frac{2\\pi n}{L-1}\\right)\\right) $$\n$$ \\sum w^2 = \\frac{1}{4}L - \\frac{1}{2}S_c(1) + \\frac{1}{4}\\left(\\frac{L+1}{2}\\right) = \\frac{L}{4} - \\frac{1}{2} + \\frac{L+1}{8} = \\frac{3L-3}{8} = \\frac{3}{8}(L-1) $$\n$$ \\mathrm{CG} = \\frac{\\frac{1}{2}(L-1)}{L} = \\frac{L-1}{2L} $$\n$$ \\mathrm{NG} = \\frac{\\frac{3}{8}(L-1)}{L} = \\frac{3(L-1)}{8L} $$\n$$ \\mathrm{ENBW} = \\frac{L \\cdot \\frac{3}{8}(L-1)}{(\\frac{1}{2}(L-1))^2} = \\frac{\\frac{3}{8}L(L-1)}{\\frac{1}{4}(L-1)^2} = \\frac{3}{2} \\frac{L}{L-1} $$\nFor $L=256$: $\\mathrm{CG} = \\frac{255}{512} \\approx 0.4980$, $\\mathrm{NG} = \\frac{3 \\cdot 255}{8 \\cdot 256} \\approx 0.3735$, $\\mathrm{ENBW} = 1.5 \\frac{256}{255} \\approx 1.5059$.\n\n**3. Hamming Window: $w[n]=0.54-0.46\\cos(\\frac{2\\pi n}{L-1})$**\nLet $a_0 = 0.54, a_1 = -0.46$. $w[n] = a_0 + a_1\\cos(\\frac{2\\pi n}{L-1})$.\n$$ \\sum w = a_0 L + a_1 S_c(1) = a_0 L + a_1 = 0.54L - 0.46 $$\n$$ \\sum w^2 = \\sum (a_0 + a_1\\cos(\\cdot))^2 = \\sum (a_0^2 + 2a_0 a_1 \\cos(\\cdot) + a_1^2 \\cos^2(\\cdot)) $$\n$$ \\sum w^2 = a_0^2 L + 2a_0 a_1 S_c(1) + a_1^2 \\left(\\frac{L+1}{2}\\right) = (a_0^2 + \\frac{a_1^2}{2})L + 2a_0 a_1 + \\frac{a_1^2}{2} $$\nWith $a_0 = 0.54$ and $a_1=-0.46$: $a_0^2=0.2916$, $a_1^2=0.2116$.\n$$ \\sum w^2 = (0.2916 + \\frac{0.2116}{2})L + 2(0.54)(-0.46) + \\frac{0.2116}{2} = 0.3974L - 0.4968 + 0.1058 = 0.3974L - 0.391 $$\n$$ \\mathrm{CG} = \\frac{0.54L - 0.46}{L} $$\n$$ \\mathrm{NG} = \\frac{0.3974L - 0.391}{L} $$\n$$ \\mathrm{ENBW} = \\frac{L(0.3974L - 0.391)}{(0.54L - 0.46)^2} $$\nFor $L=256$: $\\mathrm{CG} = \\frac{0.54(256) - 0.46}{256} \\approx 0.5382$, $\\mathrm{NG} = \\frac{0.3974(256) - 0.391}{256} \\approx 0.3959$, $\\mathrm{ENBW} = \\frac{256(101.3434)}{137.78^2} \\approx 1.3667$.\n\n**4. Blackman Window: $w[n]=0.42-0.5\\cos(\\frac{2\\pi n}{L-1})+0.08\\cos(\\frac{4\\pi n}{L-1})$**\nLet $c_0=0.42$, $c_1=-0.5$, $c_2=0.08$. $w[n] = c_0 + c_1\\cos(\\frac{2\\pi n}{L-1}) + c_2\\cos(\\frac{4\\pi n}{L-1})$.\n$$ \\sum w = c_0 L + c_1 S_c(1) + c_2 S_c(2) = c_0 L + c_1 + c_2 = 0.42L - 0.5 + 0.08 = 0.42(L-1) $$\n$$ \\sum w^2 = \\sum (c_0 + c_1 C_1 + c_2 C_2)^2 = \\sum(c_0^2 + c_1^2 C_1^2 + c_2^2 C_2^2 + 2c_0 c_1 C_1 + 2c_0 c_2 C_2 + 2c_1 c_2 C_1 C_2) $$\n$$ \\sum w^2 = c_0^2 L + c_1^2(\\frac{L+1}{2}) + c_2^2(\\frac{L+1}{2}) + 2c_0 c_1(1) + 2c_0 c_2(1) + 2c_1 c_2(1) $$\n$$ \\sum w^2 = L(c_0^2 + \\frac{c_1^2}{2} + \\frac{c_2^2}{2}) + (\\frac{c_1^2}{2} + \\frac{c_2^2}{2} + 2c_0c_1 + 2c_0c_2 + 2c_1c_2) $$\nCoefficients: $c_0^2=0.1764$, $c_1^2=0.25$, $c_2^2=0.0064$.\n$L$-term coefficient: $0.1764 + 0.125 + 0.0032 = 0.3046$.\nConstant term: $0.125 + 0.0032 + 2(0.42)(-0.5) + 2(0.42)(0.08) + 2(-0.5)(0.08) = 0.1282 - 0.42 + 0.0672 - 0.08 = -0.3046$.\n$$ \\sum w^2 = 0.3046L - 0.3046 = 0.3046(L-1) $$\n$$ \\mathrm{CG} = \\frac{0.42(L-1)}{L} $$\n$$ \\mathrm{NG} = \\frac{0.3046(L-1)}{L} $$\n$$ \\mathrm{ENBW} = \\frac{L \\cdot 0.3046(L-1)}{(0.42(L-1))^2} = \\frac{0.3046 L}{0.42^2 (L-1)} = \\frac{0.3046}{0.1764}\\frac{L}{L-1} $$\nFor $L=256$: $\\mathrm{CG} = \\frac{0.42(255)}{256} \\approx 0.4184$, $\\mathrm{NG} = \\frac{0.3046(255)}{256} \\approx 0.3034$, $\\mathrm{ENBW} = \\frac{0.3046}{0.1764}\\frac{256}{255} \\approx 1.7335$.\n\n**Interpretation of ENBW and Parseval's Relation**\nThe Discrete-Time Fourier Transform (DTFT) of the window is $W(\\mathrm{e}^{\\mathrm{j}\\omega}) = \\sum_{n=0}^{L-1} w[n] \\mathrm{e}^{-\\mathrm{j}\\omega n}$.\nThe peak of the transform's magnitude is at $\\omega=0$: $|W(\\mathrm{e}^{\\mathrm{j}0})| = |\\sum_{n=0}^{L-1} w[n]|$. We assume $w[n] \\ge 0$, so this is $\\sum w[n]$.\nParseval's theorem for discrete-time signals states: $\\sum_{n=-\\infty}^{\\infty} |x[n]|^2 = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |X(\\mathrm{e}^{\\mathrm{j}\\omega})|^2 \\mathrm{d}\\omega$.\nFor our finite-length window $w[n]$, this gives: $\\sum_{n=0}^{L-1} w[n]^2 = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |W(\\mathrm{e}^{\\mathrm{j}\\omega})|^2 \\mathrm{d}\\omega$.\nSubstituting these into the definition of $\\mathrm{ENBW}$:\n$$ \\mathrm{ENBW} = \\frac{L \\sum w[n]^2}{(\\sum w[n])^2} = \\frac{L \\cdot \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |W(\\mathrm{e}^{\\mathrm{j}\\omega})|^2 \\mathrm{d}\\omega}{|W(\\mathrm{e}^{\\mathrm{j}0})|^2} = \\left(\\frac{L}{2\\pi}\\right) \\frac{\\int_{-\\pi}^{\\pi} |W(\\mathrm{e}^{\\mathrm{j}\\omega})|^2 \\mathrm{d}\\omega}{|W(\\mathrm{e}^{\\mathrm{j}0})|^2} $$\nThe term $\\frac{\\int_{-\\pi}^{\\pi} |W(\\mathrm{e}^{\\mathrm{j}\\omega})|^2 \\mathrm{d}\\omega}{|W(\\mathrm{e}^{\\mathrm{j}0})|^2}$ is the equivalent rectangular bandwidth in radians/sample. It is the width of a hypothetical rectangular filter with the same peak power gain that would pass the same total amount of white noise power. The factor $\\frac{L}{2\\pi}$ converts this bandwidth from radians/sample to units of DFT bins (since the bin spacing for a length-$L$ DFT is $\\frac{2\\pi}{L}$). Thus, $\\mathrm{ENBW}$ is a measure of the effective width of the window's main spectral lobe.\n\n**Qualitative Analysis of Sidelobe Suppression**\nA generalized cosine window is of the form $w[n] = \\sum_{k=0}^{M} a_k \\cos(\\frac{2\\pi k n}{L-1})$. Its DTFT is a superposition of shifted Dirichlet kernels (the DTFT of the implicit rectangular window). The coefficients $a_k$ are chosen to make these kernels interfere destructively in the sidelobe regions.\nIncreasing the number of cosine terms ($M$) provides more degrees of freedom for spectral shaping. With a fixed mainlobe width (fixed $\\mathrm{ENBW}$), a window designer can use these extra degrees of freedom to introduce more nulls in the spectral response or otherwise optimize the coefficient set $\\{a_k\\}$ to achieve a more rapid decay or a lower overall level of the sidelobes. This reduces spectral leakage.\nThe windows can be categorized by the number of cosine terms ($M$):\n- Rectangular: $M=0$.\n- Hann and Hamming: $M=1$.\n- Blackman: $M=2$.\nBased on the principle that more terms allow for better sidelobe control, the order of leakage suppression from best to worst should correspond to decreasing $M$. Thus, Blackman should be superior to Hann and Hamming, which in turn are far superior to the Rectangular window.\nBetween Hann and Hamming, both are single-cosine windows, but their coefficients are chosen with different optimization goals. The Hann window coefficients ($0.5, 0.5$) are mathematically simple and result in placing zeros that cancel the main sidelobes of the underlying rectangular window response. The Hamming window coefficients ($0.54, 0.46$) are optimized to minimize the height of the highest sidelobe, achieving better peak sidelobe suppression than Hann at the cost of a slower far-sidelobe decay rate. For most applications concerned with resolving a weak tone near a strong one, peak sidelobe level is paramount.\nTherefore, the ordering of the four windows from best to worst leakage suppression is: Blackman, Hamming, Hann, Rectangular.\n\n**Final Calculation**\nThe problem asks for the $\\mathrm{ENBW}$ of the Blackman window at $L=256$, rounded to six significant figures.\n$$ \\mathrm{ENBW}_{\\text{Blackman}} = \\frac{0.3046}{0.1764} \\times \\frac{256}{255} \\approx 1.7267573696 \\times 1.0039215686 \\approx 1.73353457 $$\nRounding to six significant figures yields $1.73353$.", "answer": "$$\n\\boxed{1.73353}\n$$"}, {"introduction": "A key requirement for any Power Spectral Density (PSD) estimate is that it must possess a physically meaningful scale. This exercise [@problem_id:2853921] challenges you to derive the precise normalization constant for the Welch estimator that ensures energy conservation, linking the integrated power in the frequency domain to the signal's variance in the time domain. Mastering this derivation, which relies on Parseval’s theorem, is essential for producing and interpreting quantitative spectral estimates.", "id": "2853921", "problem": "Consider a real, discrete-time, zero-mean data record $x[n]$, $n=0,\\dots,N-1$, modeled as one realization of a wide-sense stationary process. You estimate its Power Spectral Density (PSD) using Welch’s averaged, windowed, periodogram method. The data are divided into $K$ segments of length $L$ samples with hop size $D$ samples between adjacent segment starts (so the $m$-th segment starts at sample index $mD$), where $m=0,\\dots,K-1$, and $0 \\leq mD \\leq N-L$. Each segment is multiplied by a deterministic window $w[n]$, $n=0,\\dots,L-1$. For the $m$-th segment, define the Discrete Fourier Transform (DFT) of the windowed data as\n$$\nY_m[k] \\triangleq \\sum_{n=0}^{L-1} \\big(x[n+mD]\\,w[n]\\big)\\,\\exp\\!\\left(-j\\frac{2\\pi}{L}kn\\right),\\quad k=0,\\dots,L-1,\n$$\ncomputed efficiently via an $L$-point Fast Fourier Transform (FFT). The Welch PSD estimate on the DFT grid is defined by averaging $K$ modified periodograms of the form $\\alpha\\,|Y_m[k]|^{2}$, i.e.,\n$$\n\\widehat{S}_W[k] \\triangleq \\frac{1}{K}\\sum_{m=0}^{K-1}\\alpha\\,|Y_m[k]|^{2},\\quad k=0,\\dots,L-1,\n$$\nwhere $\\alpha$ is a real, positive normalization constant to be determined.\n\nYour task is to derive, from first principles, the exact analytic expression for the normalization $\\alpha$ that enforces the following energy conservation requirement on the two-sided PSD estimate in normalized rad/sample:\n$$\n\\frac{1}{2\\pi}\\int_{-\\pi}^{\\pi}\\widehat{S}_W(\\omega)\\,d\\omega \\equiv \\frac{1}{L}\\sum_{k=0}^{L-1}\\widehat{S}_W[k] \\;=\\; \\widehat{\\sigma}_x^{2},\n$$\nwhere $\\widehat{\\sigma}_x^{2}$ is the sample variance of $x[n]$ and satisfies $\\widehat{\\sigma}_x^{2}=\\frac{1}{N}\\sum_{n=0}^{N-1}x[n]^2$ because $x[n]$ is zero-mean. Your derivation must start only from core definitions and well-tested facts such as the definitions of the DFT, the Discrete-Time Fourier Transform (DTFT), and Parseval’s theorem. Do not assume any pre-known Welch scaling. Clearly justify each step that links the frequency-domain averaging to the time-domain quadratic form.\n\nThen, specify how to implement the resulting normalization in practice using an $L$-point FFT per segment: precisely state the discrete formula for $\\widehat{S}_W[k]$, $k=0,\\dots,L-1$, that must be coded so that the discrete-frequency average $(1/L)\\sum_{k=0}^{L-1}\\widehat{S}_W[k]$ equals $\\widehat{\\sigma}_x^{2}$ under rectangular, non-overlapping segmentation ($D=L$) for any finite record and, for general windows and overlaps, equals $\\widehat{\\sigma}_x^{2}$ in expectation for a wide-sense stationary, zero-mean process.\n\nExpress your final answer as a single, closed-form analytic expression for $\\alpha$ in terms of $L$ and $w[n]$. No numerical approximation is required; do not round. No units are to be included in the final answer.", "solution": "The problem requires the derivation of the normalization constant $\\alpha$ for the Welch power spectral density (PSD) estimator, such that the total power estimated from the spectrum is equal to the sample variance of the time-domain signal. This is a fundamental energy conservation constraint. The derivation will proceed from first principles, based on the provided definitions and Parseval's theorem for the Discrete Fourier Transform (DFT).\n\nThe central requirement is given by the identity:\n$$\n\\frac{1}{L}\\sum_{k=0}^{L-1}\\widehat{S}_W[k] = \\widehat{\\sigma}_x^{2}\n$$\nwhere $\\widehat{S}_W[k]$ is the Welch PSD estimate and $\\widehat{\\sigma}_x^2$ is the sample variance of the zero-mean signal $x[n]$. We begin by substituting the definition of $\\widehat{S}_W[k]$ into the left-hand side (LHS) of this equation:\n$$\n\\text{LHS} = \\frac{1}{L}\\sum_{k=0}^{L-1} \\left( \\frac{1}{K}\\sum_{m=0}^{K-1}\\alpha\\,|Y_m[k]|^{2} \\right)\n$$\nThe constant $\\alpha$ and the averaging factors $\\frac{1}{L}$ and $\\frac{1}{K}$ can be reordered due to the linearity of summation:\n$$\n\\text{LHS} = \\frac{\\alpha}{LK} \\sum_{k=0}^{L-1} \\sum_{m=0}^{K-1} |Y_m[k]|^{2} = \\frac{\\alpha}{LK} \\sum_{m=0}^{K-1} \\left( \\sum_{k=0}^{L-1} |Y_m[k]|^{2} \\right)\n$$\nThe inner sum, $\\sum_{k=0}^{L-1} |Y_m[k]|^{2}$, involves the DFT coefficients of the $m$-th windowed segment. This structure permits the application of Parseval's theorem for the DFT. For any length-$L$ sequence $z[n]$ with an $L$-point DFT $Z[k]$, the theorem states:\n$$\n\\sum_{k=0}^{L-1} |Z[k]|^2 = L \\sum_{n=0}^{L-1} |z[n]|^2\n$$\nIn our context, for the $m$-th segment, the time-domain sequence is $z_m[n] = x[n+mD]w[n]$ for $n=0, \\dots, L-1$, and its DFT is $Y_m[k]$. Applying Parseval's theorem, we obtain:\n$$\n\\sum_{k=0}^{L-1} |Y_m[k]|^2 = L \\sum_{n=0}^{L-1} |x[n+mD]w[n]|^2\n$$\nSince the data $x[n]$ and the window $w[n]$ are real-valued, this simplifies to:\n$$\n\\sum_{k=0}^{L-1} |Y_m[k]|^2 = L \\sum_{n=0}^{L-1} x[n+mD]^2 w[n]^2\n$$\nSubstituting this result back into the expression for the LHS:\n$$\n\\text{LHS} = \\frac{\\alpha}{LK} \\sum_{m=0}^{K-1} \\left( L \\sum_{n=0}^{L-1} x[n+mD]^2 w[n]^2 \\right) = \\frac{\\alpha}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} x[n+mD]^2 w[n]^2\n$$\nNow, we equate this with the right-hand side (RHS) of the initial requirement, which is $\\widehat{\\sigma}_x^{2} = \\frac{1}{N}\\sum_{n=0}^{N-1}x[n]^2$:\n$$\n\\frac{\\alpha}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} x[n+mD]^2 w[n]^2 = \\frac{1}{N}\\sum_{n=0}^{N-1}x[n]^2\n$$\nThis identity cannot hold for an arbitrary signal realization $x[n]$ with a general window and overlap, because the left side applies a non-uniform weighting ($w[n]^2$) to the samples $x[n]^2$ while the right side does not. However, the problem specifies that this relationship must hold in expectation for a wide-sense stationary (WSS) process. Therefore, we must equate the statistical expectations of both sides.\n\nThe expectation of the LHS is:\n$$\nE[\\text{LHS}] = E\\left[ \\frac{\\alpha}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} x[n+mD]^2 w[n]^2 \\right] = \\frac{\\alpha}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} E[x[n+mD]^2] w[n]^2\n$$\nFor a zero-mean WSS process, the expectation of the squared value is the process variance, $\\sigma_x^2$, which is constant for all time indices: $E[x[i]^2] = \\sigma_x^2$ for any $i$.\n$$\nE[\\text{LHS}] = \\frac{\\alpha}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} \\sigma_x^2 w[n]^2 = \\frac{\\alpha \\sigma_x^2}{K} \\sum_{m=0}^{K-1} \\left( \\sum_{n=0}^{L-1} w[n]^2 \\right)\n$$\nThe inner sum over $n$ is the energy of the window, a constant value which does not depend on the segment index $m$. The outer sum over $m$ consists of $K$ identical terms.\n$$\nE[\\text{LHS}] = \\frac{\\alpha \\sigma_x^2}{K} \\cdot K \\left( \\sum_{n=0}^{L-1} w[n]^2 \\right) = \\alpha \\sigma_x^2 \\sum_{n=0}^{L-1} w[n]^2\n$$\nThe expectation of the RHS is:\n$$\nE[\\text{RHS}] = E[\\widehat{\\sigma}_x^2] = E\\left[ \\frac{1}{N}\\sum_{n=0}^{N-1}x[n]^2 \\right] = \\frac{1}{N}\\sum_{n=0}^{N-1}E[x[n]^2] = \\frac{1}{N}\\sum_{n=0}^{N-1}\\sigma_x^2 = \\frac{N \\sigma_x^2}{N} = \\sigma_x^2\n$$\nEquating the expectations, $E[\\text{LHS}] = E[\\text{RHS}]$, yields:\n$$\n\\alpha \\sigma_x^2 \\sum_{n=0}^{L-1} w[n]^2 = \\sigma_x^2\n$$\nAssuming the process is not trivial ($\\sigma_x^2 > 0$), we can divide by $\\sigma_x^2$ to solve for $\\alpha$:\n$$\n\\alpha = \\frac{1}{\\sum_{n=0}^{L-1} w[n]^2}\n$$\nThis is the required normalization constant. Let us verify this for the specific case of a rectangular window ($w[n]=1$ for all $n$) with non-overlapping segments ($D=L$, which implies $N=KL$ for $K$ full segments). In this case, the formula gives $\\alpha = \\frac{1}{\\sum_{n=0}^{L-1} 1^2} = \\frac{1}{L}$. The exact (non-expected) identity becomes:\n$$\n\\frac{1/L}{K} \\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} x[n+mL]^2 (1)^2 = \\frac{1}{KL} \\sum_{i=0}^{KL-1} x[i]^2\n$$\nThe double summation $\\sum_{m=0}^{K-1} \\sum_{n=0}^{L-1} x[n+mL]^2$ is simply a sum over all samples $x[i]^2$ from $i=0$ to $i=KL-1$. Thus, the equation simplifies to an identity, confirming the correctness of our derived $\\alpha$ for this specific case.\n\nTo implement this normalization in practice, we first pre-compute the energy of the window, $U = \\sum_{n=0}^{L-1} w[n]^2$. The Welch PSD estimate is then calculated according to the formula:\n$$\n\\widehat{S}_W[k] = \\frac{1}{K} \\left( \\frac{1}{\\sum_{l=0}^{L-1} w[l]^2} \\right) \\sum_{m=0}^{K-1} |Y_m[k]|^2 = \\frac{1}{K \\cdot U} \\sum_{m=0}^{K-1} \\left| \\sum_{n=0}^{L-1} x[n+mD]w[n]\\exp\\left(-j\\frac{2\\pi}{L}kn\\right) \\right|^2\n$$\nThe computational procedure is:\n1. Divide the data $x[n]$ into $K$ segments of length $L$.\n2. For each segment $m$, multiply by the window $w[n]$ and compute the $L$-point FFT, $Y_m[k]$.\n3. Compute the squared magnitude, $|Y_m[k]|^2$, for each segment.\n4. Average these squared magnitudes over the $K$ segments.\n5. Normalize the result by dividing by the window energy, $U = \\sum_{n=0}^{L-1} w[n]^2$. The division by $K$ is already part of the averaging step. The combined normalization factor is thus $\\frac{1}{K \\cdot U}$.\nThis procedure ensures that the total power in the estimated spectrum corresponds to the total power of the signal, satisfying the energy conservation principle in expectation.", "answer": "$$\\boxed{\\frac{1}{\\sum_{n=0}^{L-1} w[n]^2}}$$"}, {"introduction": "Designing a spectral estimator involves navigating a fundamental trade-off between statistical stability and spectral detail. This hands-on problem [@problem_id:2853903] places you in the role of a system designer, tasked with selecting the optimal parameters for Bartlett's method to meet specific constraints on both variance and resolution. By solving for the number of segments $K$ and their length $L$, you will directly confront and quantify the core compromise between variance reduction and mainlobe width.", "id": "2853903", "problem": "A zero-mean, wide-sense stationary, real-valued discrete-time process with power spectral density (PSD) $S_{x}(\\omega)$ is observed over $N$ contiguous samples. You will estimate the PSD using Bartlett’s method: partition the record into $K$ non-overlapping segments of equal length $L$ (so that $N=K L$), apply a rectangular data taper on each segment, form a periodogram on each segment, and average the $K$ periodograms to obtain the estimator $\\widehat{S}_{x}(\\omega)$. For performance, impose two requirements: (i) the estimator’s variance at a fixed frequency $\\omega$ must not exceed a specified fraction of $S_{x}(\\omega)^{2}$, and (ii) the spectral resolution must exceed a specified minimum in the sense of the mainlobe width of the segment’s spectral window, defined as the separation in $\\omega$ between the first spectral zeros of the discrete-time Fourier transform (DTFT) of the rectangular taper. Assume segments are sufficiently long that inter-segment dependence can be neglected for variance calculations and that bias due to leakage is negligible compared to the variance at the design frequency.\n\nYou are given $N=4096$ samples, a maximum allowable relative variance $\\epsilon=0.1$ (that is, the variance requirement is $\\operatorname{var}\\{\\widehat{S}_{x}(\\omega)\\} \\leq \\epsilon\\, S_{x}(\\omega)^{2}$), and a minimum required resolution expressed as an upper bound on the mainlobe width $\\Delta\\omega_{\\min}=0.06$ in radians per sample. Choose positive integers $(K,L)$ such that $N=K L$, the variance requirement is met at the design frequency, and the mainlobe width requirement is met. Among all such feasible pairs that use all $N$ samples, select the pair that maximizes $K$. Report your final answer as the ordered pair $(K,L)$. State your answer with exact integers; no rounding is required. Angles are in radians per sample, and no physical units are needed for $K$ or $L$.", "solution": "The problem requires the determination of an optimal pair of parameters $(K,L)$ for Bartlett's method of power spectral density (PSD) estimation, subject to constraints on estimator variance and spectral resolution. The parameters $K$ and $L$ represent the number of non-overlapping segments and the length of each segment, respectively, from a total data record of $N=KL$ samples. The objective is to maximize $K$ while satisfying all constraints.\n\nFirst, we formalize the given constraints.\n\nThe total number of samples is $N=4096$. The relationship between the number of segments $K$, segment length $L$, and total samples $N$ for non-overlapping segments is:\n$$KL = N = 4096$$\nwhere $K$ and $L$ must be positive integers.\n\nThe first performance requirement is on the variance of the PSD estimator, $\\widehat{S}_{x}(\\omega)$. For Bartlett's method, the variance is approximately given by:\n$$ \\operatorname{var}\\{\\widehat{S}_{x}(\\omega)\\} \\approx \\frac{1}{K} S_{x}(\\omega)^{2} $$\nThis approximation is valid for frequencies not equal to $0$ or $\\pi$ and holds under the problem's assumption that the segments are long enough for their statistical dependence to be negligible. The problem specifies a maximum allowable relative variance $\\epsilon = 0.1$, such that:\n$$ \\operatorname{var}\\{\\widehat{S}_{x}(\\omega)\\} \\leq \\epsilon S_{x}(\\omega)^{2} $$\nSubstituting the approximation for the variance into this inequality yields:\n$$ \\frac{1}{K} S_{x}(\\omega)^{2} \\leq \\epsilon S_{x}(\\omega)^{2} $$\nFor $S_{x}(\\omega) > 0$, this simplifies to a lower bound on the number of segments $K$:\n$$ \\frac{1}{K} \\leq \\epsilon \\implies K \\geq \\frac{1}{\\epsilon} $$\nUsing the given value $\\epsilon = 0.1$:\n$$ K \\geq \\frac{1}{0.1} \\implies K \\geq 10 $$\n\nThe second performance requirement is on the spectral resolution. The resolution of a spectral estimator is determined by the mainlobe width of the Fourier transform of the window function applied to the data segments. In this case, a rectangular window of length $L$ is used. The window function is $w[n]=1$ for $n=0, 1, \\dots, L-1$ and $w[n]=0$ otherwise. Its discrete-time Fourier transform (DTFT), $W(\\omega)$, is:\n$$ W(\\omega) = \\sum_{n=0}^{L-1} (1) \\cdot \\exp(-j\\omega n) = \\frac{1 - \\exp(-j\\omega L)}{1 - \\exp(-j\\omega)} = \\exp\\left(-j\\omega\\frac{L-1}{2}\\right) \\frac{\\sin(\\omega L/2)}{\\sin(\\omega/2)} $$\nThe problem defines the mainlobe width, $\\Delta\\omega$, as the distance between the first spectral zeros of $W(\\omega)$ on either side of the central peak at $\\omega=0$. The zeros of $W(\\omega)$ are determined by its numerator, $\\sin(\\omega L/2)$, being zero while its denominator, $\\sin(\\omega/2)$, is non-zero. The condition $\\sin(\\omega L/2) = 0$ implies $\\omega L/2 = k\\pi$ for any non-zero integer $k$. The first zeros flanking the mainlobe correspond to $k = \\pm 1$.\n$$ \\frac{\\omega L}{2} = \\pm\\pi \\implies \\omega = \\pm\\frac{2\\pi}{L} $$\nThe mainlobe width is thus the separation between these two frequencies:\n$$ \\Delta\\omega = \\frac{2\\pi}{L} - \\left(-\\frac{2\\pi}{L}\\right) = \\frac{4\\pi}{L} $$\nThe resolution requirement states that this width must not exceed a specified maximum value, $\\Delta\\omega_{\\min} = 0.06$ radians per sample.\n$$ \\Delta\\omega \\leq \\Delta\\omega_{\\min} \\implies \\frac{4\\pi}{L} \\leq \\Delta\\omega_{\\min} $$\nThis imposes a lower bound on the segment length $L$:\n$$ L \\geq \\frac{4\\pi}{\\Delta\\omega_{\\min}} $$\nSubstituting the given value $\\Delta\\omega_{\\min}=0.06$:\n$$ L \\geq \\frac{4\\pi}{0.06} \\approx 209.4395 $$\nSince $L$ must be an integer, the constraint becomes:\n$$ L \\geq 210 $$\n\nWe are tasked with finding the integer pair $(K, L)$ that satisfies the following conditions and maximizes $K$:\n1. $KL = 4096$\n2. $K \\geq 10$\n3. $L \\geq 210$\n\nTo maximize $K$, we must minimize $L$, since $L = 4096/K$. Therefore, we seek the smallest integer $L$ that satisfies $L \\geq 210$ and is also a divisor of $4096$.\nThe total number of samples is $N = 4096 = 2^{12}$. The divisors of $4096$ are powers of $2$, specifically $\\{2^0, 2^1, 2^2, \\dots, 2^{12}\\}$.\nThe divisors are: $1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096$.\nWe must find the smallest divisor in this list that is greater than or equal to $210$.\nComparing $210$ with the list of divisors:\n- $128 < 210$\n- $256 > 210$\nThe smallest divisor of $4096$ that meets the condition $L \\geq 210$ is $L=256$.\n\nThis choice of $L$ minimizes the segment length while satisfying the resolution constraint and the condition that $L$ must divide $N$. Consequently, this choice maximizes $K$. We now calculate the corresponding value of $K$:\n$$ K = \\frac{N}{L} = \\frac{4096}{256} = \\frac{2^{12}}{2^8} = 2^4 = 16 $$\nWe must verify that this value of $K$ satisfies its constraint, $K \\geq 10$. Indeed, $16 \\geq 10$.\nThus, the pair $(K,L) = (16, 256)$ satisfies all stated conditions and maximizes $K$.\nThe final answer is the ordered pair $(16, 256)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n16 & 256\n\\end{pmatrix}\n}\n$$"}]}