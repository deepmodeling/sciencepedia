{"hands_on_practices": [{"introduction": "The effectiveness of a dictionary in representing signals sparsely depends critically on its geometric structure. This exercise delves into two fundamental concepts: mutual coherence, a measure of the worst-case similarity between atoms, and the spark of the dictionary, which governs the uniqueness of sparse solutions. You will gain hands-on practice calculating the coherence and using it to establish a lower bound on the spark, directly linking the dictionary's geometry to its performance guarantees [@problem_id:2865192].", "problem": "Consider a dictionary matrix $D \\in \\mathbb{R}^{3 \\times 4}$ whose columns are unit-norm atoms $D = [\\, d_{1}\\; d_{2}\\; d_{3}\\; d_{4}\\,]$ given by\n$$\nd_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix},\\quad\nd_{2} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix},\\quad\nd_{3} = \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix},\\quad\nd_{4} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\nStart from the core definitions of mutual coherence and spark. The mutual coherence $\\mu(D)$ is defined as $\\mu(D) = \\max_{i \\neq j} \\left| d_{i}^{\\top} d_{j} \\right|$ for unit-norm columns, and the spark $\\operatorname{spark}(D)$ is defined as the cardinality of the smallest subset of columns of $D$ that is linearly dependent. Using only these definitions and well-tested facts about Gram matrices and eigenvalue bounds (e.g., the Gershgorin circle theorem), compute $\\mu(D)$ and derive a coherence-based lower bound on $\\operatorname{spark}(D)$, then evaluate that bound for the given $D$.\n\nExpress your final answer as a row matrix $\\big(\\, \\mu(D)\\;\\; \\text{lower bound on }\\operatorname{spark}(D)\\, \\big)$ with entries in exact form. Do not round. Do not include units.", "solution": "The problem is first validated and found to be well-posed, scientifically grounded, and self-contained. The provided data and definitions are standard in the field of signal processing and linear algebra. The atoms are confirmed to be of unit norm as stated.\n\nThe first objective is to compute the mutual coherence $\\mu(D)$ of the dictionary matrix $D \\in \\mathbb{R}^{3 \\times 4}$. The mutual coherence is defined as the maximum absolute inner product between distinct atoms:\n$$\n\\mu(D) = \\max_{i \\neq j} \\left| d_{i}^{\\top} d_{j} \\right|\n$$\nThe columns of $D$ are given as:\n$$\nd_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix},\\quad\nd_{2} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix},\\quad\nd_{3} = \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix},\\quad\nd_{4} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}.\n$$\nWe compute all pairwise inner products for $i \\neq j$:\n$$\nd_{1}^{\\top} d_{2} = (1)\\left(\\frac{1}{2}\\right) + (0)\\left(\\frac{\\sqrt{3}}{2}\\right) + (0)(0) = \\frac{1}{2}\n$$\n$$\nd_{1}^{\\top} d_{3} = (1)\\left(\\frac{1}{2}\\right) + (0)\\left(-\\frac{\\sqrt{3}}{2}\\right) + (0)(0) = \\frac{1}{2}\n$$\n$$\nd_{1}^{\\top} d_{4} = (1)(0) + (0)(0) + (0)(1) = 0\n$$\n$$\nd_{2}^{\\top} d_{3} = \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + \\left(\\frac{\\sqrt{3}}{2}\\right)\\left(-\\frac{\\sqrt{3}}{2}\\right) + (0)(0) = \\frac{1}{4} - \\frac{3}{4} = -\\frac{1}{2}\n$$\n$$\nd_{2}^{\\top} d_{4} = \\left(\\frac{1}{2}\\right)(0) + \\left(\\frac{\\sqrt{3}}{2}\\right)(0) + (0)(1) = 0\n$$\n$$\nd_{3}^{\\top} d_{4} = \\left(\\frac{1}{2}\\right)(0) + \\left(-\\frac{\\sqrt{3}}{2}\\right)(0) + (0)(1) = 0\n$$\nThe absolute values of these inner products are $\\frac{1}{2}$, $\\frac{1}{2}$, $0$, $\\frac{1}{2}$, $0$, and $0$. The maximum among these is $\\frac{1}{2}$.\nTherefore, the mutual coherence is:\n$$\n\\mu(D) = \\frac{1}{2}\n$$\nThe second objective is to derive a coherence-based lower bound on the spark of $D$, denoted $\\operatorname{spark}(D)$, and evaluate it. The spark is defined as the cardinality of the smallest linearly dependent subset of columns of $D$.\n\nLet $D_S$ be a submatrix of $D$ consisting of $k$ columns indexed by the set $S$. The columns of $D_S$ are linearly dependent if and only if there exists a non-zero vector $x \\in \\mathbb{R}^k$ such that $D_S x = 0$. This is equivalent to the Gram matrix $G_S = D_S^{\\top} D_S$ being singular, i.e., having a zero eigenvalue.\n\nWe seek a condition on $k$ that guarantees that any set of $k$ columns is linearly independent. This is equivalent to finding a condition on $k$ that ensures any such Gram matrix $G_S$ is non-singular.\n\nThe Gram matrix $G_S$ is a $k \\times k$ matrix. Since the columns $d_i$ are unit-norm, the diagonal entries of $G_S$ are $(G_S)_{ii} = d_i^{\\top} d_i = 1$. The off-diagonal entries are $(G_S)_{ij} = d_i^{\\top} d_j$ for $i \\neq j$. By the definition of mutual coherence, we have $|(G_S)_{ij}| \\le \\mu(D)$ for all $i \\neq j$.\n\nWe apply the Gershgorin circle theorem to the matrix $G_S$. This theorem states that every eigenvalue $\\lambda$ of $G_S$ lies in at least one of the Gershgorin discs centered at the diagonal entries. For any row $i$, the disc is centered at $(G_S)_{ii} = 1$ with radius $R_i = \\sum_{j \\neq i} |(G_S)_{ij}|$.\nUsing the coherence bound, the radius is bounded by:\n$$\nR_i = \\sum_{j=1, j \\neq i}^{k} |(G_S)_{ij}| \\le \\sum_{j=1, j \\neq i}^{k} \\mu(D) = (k-1)\\mu(D)\n$$\nSince $G_S$ is real and symmetric, its eigenvalues $\\lambda$ are real. The Gershgorin theorem implies that for any eigenvalue $\\lambda$, it must satisfy $|\\lambda - 1| \\le \\max_i R_i$. Thus,\n$$\n1 - \\max_i R_i \\le \\lambda \\le 1 + \\max_i R_i\n$$\nUsing our bound on the radii, we have:\n$$\n\\lambda \\ge 1 - (k-1)\\mu(D)\n$$\nFor $G_S$ to be non-singular, all its eigenvalues must be non-zero. If we can ensure that $1 - (k-1)\\mu(D) > 0$, then all eigenvalues will be positive, making $G_S$ positive definite and thus invertible. The condition is:\n$$\n1 - (k-1)\\mu(D) > 0 \\implies 1 > (k-1)\\mu(D) \\implies \\frac{1}{\\mu(D)} > k-1 \\implies k  1 + \\frac{1}{\\mu(D)}\n$$\nThis result shows that any set of $k$ columns of $D$ is guaranteed to be linearly independent if $k  1 + 1/\\mu(D)$. Consequently, for a set of columns to be linearly dependent, its size $k$ must be at least $1 + 1/\\mu(D)$. Since $\\operatorname{spark}(D)$ is the size of the smallest such set, we obtain the lower bound:\n$$\n\\operatorname{spark}(D) \\ge 1 + \\frac{1}{\\mu(D)}\n$$\nNow, we evaluate this bound for the given dictionary $D$. We found $\\mu(D) = \\frac{1}{2}$.\n$$\n\\operatorname{spark}(D) \\ge 1 + \\frac{1}{1/2} = 1 + 2 = 3\n$$\nThe lower bound on the spark is $3$. The two requested quantities are $\\mu(D)$ and the lower bound on $\\operatorname{spark}(D)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2}  3 \\end{pmatrix}}\n$$", "id": "2865192"}, {"introduction": "Theoretical guarantees in sparse recovery, such as those based on mutual coherence, define a 'safe zone' for algorithms, but what happens outside this zone? This practice problem challenges you to construct a specific scenario where the coherence condition for the Orthogonal Matching Pursuit (OMP) algorithm is violated, leading to its failure [@problem_id:2865197]. Analyzing this failure provides critical insight into the limitations of greedy approaches and the fundamental trade-offs in dictionary design.", "problem": "Consider a finite dictionary matrix $D \\in \\mathbb{R}^{m \\times n}$ with unit-norm columns (atoms). The mutual coherence $\\mu(D)$ is defined as $\\mu(D) \\triangleq \\max_{i \\neq j} \\left| \\langle d_i, d_j \\rangle \\right|$, where $d_i$ denotes the $i$-th column of $D$. In Orthogonal Matching Pursuit (OMP), given a measurement $y = D x^{\\star}$ where $x^{\\star}$ is $s$-sparse, the algorithm initializes the residual as $r^{(0)} = y$ and, in the first iteration, selects the atom index $j^{(1)} \\in \\arg\\max_{j} \\left| \\langle d_j, r^{(0)} \\rangle \\right|$. A first-iteration failure means that $j^{(1)} \\notin \\mathrm{supp}(x^{\\star})$.\n\nYour task is to identify a valid counterexample to the coherence-based OMP success regime by constructing a dictionary $D$ and an $s$-sparse vector $x^{\\star}$ with $s = 2$ such that $\\mu(D) \\ge \\tfrac{1}{2s - 1}$ and OMP fails to select a correct atom in the first iteration. In your selection, prefer a construction whose analysis explicitly explains, from first principles (definitions of mutual coherence and the OMP selection rule), why the failure occurs.\n\nWhich option below correctly constructs such a counterexample and provides a correct analysis?\n\nA. Take $m = 2$, $n = 3$, and define\n$$\nd_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad\nd_2 = \\begin{bmatrix} \\tfrac{4}{5} \\\\ \\tfrac{3}{5} \\end{bmatrix}, \\quad\nd_3 = \\begin{bmatrix} \\tfrac{4}{5} \\\\ -\\tfrac{3}{5} \\end{bmatrix},\n$$\nso that $D = [\\, d_1 \\; d_2 \\; d_3 \\,]$ has unit-norm columns. Let $s = 2$ and $x^{\\star} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$. Then $y = D x^{\\star} = d_2 + d_3 = \\begin{bmatrix} \\tfrac{8}{5} \\\\ 0 \\end{bmatrix}$. The first-iteration OMP correlations are\n$$\n\\langle d_1, y \\rangle = \\tfrac{8}{5}, \\quad\n\\langle d_2, y \\rangle = 2 \\left( \\tfrac{4}{5} \\right)^2 = \\tfrac{32}{25}, \\quad\n\\langle d_3, y \\rangle = \\tfrac{32}{25},\n$$\nso OMP selects $d_1$ (since $\\tfrac{8}{5} > \\tfrac{32}{25}$), which is not in $\\mathrm{supp}(x^{\\star}) = \\{ 2, 3 \\}$. The mutual coherence satisfies\n$$\n\\langle d_1, d_2 \\rangle = \\langle d_1, d_3 \\rangle = \\tfrac{4}{5}, \\quad\n\\langle d_2, d_3 \\rangle = \\left( \\tfrac{4}{5} \\right)^2 - \\left( \\tfrac{3}{5} \\right)^2 = \\tfrac{7}{25},\n$$\nhence $\\mu(D) = \\tfrac{4}{5} \\ge \\tfrac{1}{3} = \\tfrac{1}{2s - 1}$. Failure occurs because the two true atoms add constructively along the first coordinate, making $y$ align with $d_1$; by the OMP selection rule, the spurious atom $d_1$ has larger correlation with $y$ than either true atom, i.e., $\\tfrac{8}{5} > \\tfrac{32}{25}$.\n\nB. Use the same $D$ as in Option A. Let $s = 2$ and $x^{\\star} = \\begin{bmatrix} 0 \\\\ 1 \\\\ -1 \\end{bmatrix}$. Then $y = d_2 - d_3 = \\begin{bmatrix} 0 \\\\ \\tfrac{6}{5} \\end{bmatrix}$. The first-iteration OMP correlations are\n$$\n\\langle d_1, y \\rangle = 0, \\quad\n\\langle d_2, y \\rangle = \\tfrac{18}{25}, \\quad\n\\langle d_3, y \\rangle = -\\tfrac{18}{25}.\n$$\nTherefore OMP selects either $d_2$ or $d_3$, both in $\\mathrm{supp}(x^{\\star})$, while $\\mu(D) = \\tfrac{4}{5} \\ge \\tfrac{1}{3}$. This shows that violating $\\tfrac{1}{2s-1}$ forces failure in the first iteration.\n\nC. Take $m = 2$, $n = 3$, and set\n$$\n\\tilde d_1 = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}, \\quad\n\\tilde d_2 = \\begin{bmatrix} 1 \\\\ \\sqrt{3} \\end{bmatrix}, \\quad\n\\tilde d_3 = \\begin{bmatrix} 1 \\\\ -\\sqrt{3} \\end{bmatrix},\n$$\nwith $D = [\\, \\tilde d_1 \\; \\tilde d_2 \\; \\tilde d_3 \\,]$ and $x^{\\star} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$. Then $y = \\tilde d_2 + \\tilde d_3 = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$. Since $\\mu(D) = \\tfrac{1}{4}  \\tfrac{1}{3}$ and $\\langle \\tilde d_1, y \\rangle = 4$ is largest in magnitude, OMP fails in the first iteration due to large non-normalized correlation.\n\nD. Let $m = 3$, $n = 3$, and define the orthonormal dictionary $D = [\\, e_1 \\; e_2 \\; e_3 \\,]$, where $e_i$ are the standard basis vectors in $\\mathbb{R}^3$. Take $s = 2$ and $x^{\\star} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix}$. Then $y = e_2 + e_3$, the mutual coherence is $\\mu(D) = 0  \\tfrac{1}{3}$, and the OMP correlations are $\\langle e_2, y \\rangle = 1$, $\\langle e_3, y \\rangle = 1$, $\\langle e_1, y \\rangle = 0$, so OMP must succeed in the first iteration. This demonstrates a valid counterexample because it shows selection succeeds even when $\\mu(D)  \\tfrac{1}{2s - 1}$.", "solution": "The task is to validate the problem statement and, if valid, identify a correct counterexample among the given options. The counterexample must consist of a dictionary $D \\in \\mathbb{R}^{m \\times n}$ with unit-norm columns, and a $2$-sparse vector $x^{\\star}$ (i.e., $s=2$), such that the mutual coherence $\\mu(D)$ satisfies $\\mu(D) \\ge \\tfrac{1}{2s-1}$, and the Orthogonal Matching Pursuit (OMP) algorithm fails in its first iteration.\n\n### Step 1: Problem Validation\n\n**Extraction of Givens:**\n*   Dictionary $D \\in \\mathbb{R}^{m \\times n}$ has columns $d_i$ constrained by $\\|d_i\\|_2 = 1$.\n*   Mutual coherence is defined as $\\mu(D) \\triangleq \\max_{i \\neq j} |\\langle d_i, d_j \\rangle|$.\n*   The signal model is $y = D x^{\\star}$, where $x^{\\star}$ is an $s$-sparse vector.\n*   OMP's first iteration: Initialize residual $r^{(0)} = y$, then select atom index $j^{(1)} \\in \\arg\\max_{j} |\\langle d_j, r^{(0)} \\rangle|$.\n*   First-iteration failure is defined as the selected index $j^{(1)}$ not being in the support of the true sparse vector, i.e., $j^{(1)} \\notin \\mathrm{supp}(x^{\\star})$.\n*   The specific case to construct is for sparsity $s=2$.\n*   The construction must satisfy $\\mu(D) \\ge \\tfrac{1}{2s - 1}$.\n*   The construction must result in a first-iteration failure for OMP.\n\n**Validation using Extracted Givens:**\nThe problem statement is scientifically grounded in the well-established field of sparse signal representation and compressed sensing. The definitions provided for mutual coherence and the OMP selection rule are standard. The task is to construct a specific example that demonstrates a known limitation of coherence-based recovery guarantees. The condition $\\mu(D)  \\tfrac{1}{2s-1}$ is a sufficient condition for the successful recovery of *any* $s$-sparse vector by OMP. The problem asks to construct a case where this condition is violated (i.e., $\\mu(D) \\ge \\tfrac{1}{2s-1}$) and OMP indeed fails for a *specific* $s$-sparse vector. This is a well-posed and meaningful task that tests the understanding of why the guarantee fails. The problem is objective, self-contained, and free from any listed flaws.\n\n**Verdict:** The problem is valid.\n\n### Step 2: Solution Derivation and Option Analysis\n\nWe are given $s=2$. The coherence threshold is $\\tfrac{1}{2s-1} = \\tfrac{1}{2(2)-1} = \\tfrac{1}{3}$. We need to find an option where $\\mu(D) \\ge \\tfrac{1}{3}$ and OMP fails at the first step. A first-step failure means that the selected atom $d_{j^{(1)}}$ with $j^{(1)} = \\arg\\max_j |\\langle d_j, y \\rangle|$ is not in the support of $x^{\\star}$. Let $\\mathcal{I} = \\mathrm{supp}(x^\\star)$. Failure occurs if $\\max_{j \\notin \\mathcal{I}} |\\langle d_j, y \\rangle|  \\max_{k \\in \\mathcal{I}} |\\langle d_k, y \\rangle|$.\n\n**Analysis of Option A:**\n\n*   **Dictionary and Sparsity:** $D = [d_1, d_2, d_3]$ with $d_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$, $d_2 = \\begin{bmatrix} 4/5 \\\\ 3/5 \\end{bmatrix}$, $d_3 = \\begin{bmatrix} 4/5 \\\\ -3/5 \\end{bmatrix}$. $s=2$ and $x^{\\star} = [0, 1, 1]^T$.\n*   **Check Dictionary Properties:**\n    *   $\\|d_1\\|_2 = \\sqrt{1^2+0^2} = 1$.\n    *   $\\|d_2\\|_2 = \\sqrt{(4/5)^2+(3/5)^2} = \\sqrt{16/25+9/25} = 1$.\n    *   $\\|d_3\\|_2 = \\sqrt{(4/5)^2+(-3/5)^2} = 1$.\n    All columns are unit-norm as required.\n*   **Check Sparsity:** $x^{\\star}$ has two non-zero entries. Thus, it is $2$-sparse. The support is $\\mathrm{supp}(x^{\\star}) = \\{2, 3\\}$.\n*   **Compute Mutual Coherence:**\n    *   $|\\langle d_1, d_2 \\rangle| = |1 \\cdot (4/5) + 0 \\cdot (3/5)| = 4/5$.\n    *   $|\\langle d_1, d_3 \\rangle| = |1 \\cdot (4/5) + 0 \\cdot (-3/5)| = 4/5$.\n    *   $|\\langle d_2, d_3 \\rangle| = |(4/5)(4/5) + (3/5)(-3/5)| = |16/25 - 9/25| = 7/25$.\n    The mutual coherence is $\\mu(D) = \\max\\{4/5, 4/5, 7/25\\} = 4/5$.\n*   **Check Coherence Condition:** We must have $\\mu(D) \\ge 1/3$. Since $4/5 = 0.8$ and $1/3 \\approx 0.333$, the condition $4/5 \\ge 1/3$ is satisfied.\n*   **Simulate OMP First Iteration:**\n    *   The signal is $y = D x^{\\star} = 1 \\cdot d_2 + 1 \\cdot d_3 = \\begin{bmatrix} 4/5 \\\\ 3/5 \\end{bmatrix} + \\begin{bmatrix} 4/5 \\\\ -3/5 \\end{bmatrix} = \\begin{bmatrix} 8/5 \\\\ 0 \\end{bmatrix}$.\n    *   The initial residual is $r^{(0)} = y$. We compute the correlations:\n        *   $|\\langle d_1, y \\rangle| = |\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}^T \\begin{bmatrix} 8/5 \\\\ 0 \\end{bmatrix}| = 8/5$.\n        *   $|\\langle d_2, y \\rangle| = |\\begin{bmatrix} 4/5 \\\\ 3/5 \\end{bmatrix}^T \\begin{bmatrix} 8/5 \\\\ 0 \\end{bmatrix}| = (4/5)(8/5) = 32/25$.\n        *   $|\\langle d_3, y \\rangle| = |\\begin{bmatrix} 4/5 \\\\ -3/5 \\end{bmatrix}^T \\begin{bmatrix} 8/5 \\\\ 0 \\end{bmatrix}| = (4/5)(8/5) = 32/25$.\n    *   Compare the magnitudes: $8/5 = 40/25$. So we have $\\{40/25, 32/25, 32/25\\}$.\n    *   The maximum correlation is $|\\langle d_1, y \\rangle| = 40/25$. OMP selects the index $j^{(1)}=1$.\n*   **Check for Failure:** The support of $x^{\\star}$ is $\\{2, 3\\}$. The selected index is $1$. Since $1 \\notin \\{2, 3\\}$, OMP fails in the first iteration.\n*   **Analysis:** The explanation provided is that the true atoms, $d_2$ and $d_3$, add constructively in a way that makes the resultant signal $y$ highly aligned with the spurious atom $d_1$. Indeed, $y = [8/5, 0]^T = (8/5)d_1$. This perfect alignment leads to a larger correlation with $d_1$ than with the true atoms $d_2$ and $d_3$, causing the failure. This analysis is correct and based on first principles.\n\n**Verdict for Option A:** Correct.\n\n**Analysis of Option B:**\n\n*   **Setup:** Uses the same $D$ as in A, so $\\mu(D) = 4/5 \\ge 1/3$. The vector is $x^{\\star} = [0, 1, -1]^T$. This is $2$-sparse with $\\mathrm{supp}(x^{\\star}) = \\{2, 3\\}$.\n*   **Simulate OMP:**\n    *   $y = D x^{\\star} = d_2 - d_3 = \\begin{bmatrix} 4/5 \\\\ 3/5 \\end{bmatrix} - \\begin{bmatrix} 4/5 \\\\ -3/5 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 6/5 \\end{bmatrix}$.\n    *   Correlations:\n        *   $|\\langle d_1, y \\rangle| = |\\langle [1,0]^T, [0, 6/5]^T \\rangle| = 0$.\n        *   $|\\langle d_2, y \\rangle| = |\\langle [4/5, 3/5]^T, [0, 6/5]^T \\rangle| = (3/5)(6/5) = 18/25$.\n        *   $|\\langle d_3, y \\rangle| = |\\langle [4/5, -3/5]^T, [0, 6/5]^T \\rangle| = |(-3/5)(6/5)| = 18/25$.\n    *   The maximum correlation magnitude is $18/25$, corresponding to atoms $d_2$ and $d_3$. OMP will select either index $2$ or $3$. Both are in $\\mathrm{supp}(x^{\\star})$.\n*   **Conclusion:** OMP succeeds in the first iteration. This is not a counterexample of failure. The option's conclusion that \"[this] shows that violating $\\tfrac{1}{2s-1}$ forces failure\" is logically flawed; violating a sufficient condition for success does not guarantee failure.\n\n**Verdict for Option B:** Incorrect.\n\n**Analysis of Option C:**\n\n*   **Setup:** The dictionary atoms are given as $\\tilde d_1 = [2, 0]^T$, $\\tilde d_2 = [1, \\sqrt{3}]^T$, $\\tilde d_3 = [1, -\\sqrt{3}]^T$.\n*   **Check Dictionary Properties:**\n    *   $\\|\\tilde d_1\\|_2 = 2$.\n    *   $\\|\\tilde d_2\\|_2 = \\sqrt{1^2 + (\\sqrt{3})^2} = 2$.\n    *   $\\|\\tilde d_3\\|_2 = \\sqrt{1^2 + (-\\sqrt{3})^2} = 2$.\n    The columns are not unit-norm, which violates a fundamental premise of the problem statement, where mutual coherence $\\mu(D)$ is defined for dictionaries with unit-norm columns.\n*   **Analysis:** The option proceeds with these non-normalized vectors and makes an unsubstantiated claim that $\\mu(D) = 1/4  1/3$. If we were to normalize the atoms, the coherence would be $\\mu(D)=1/2  1/3$. The option is built on a faulty premise and incorrect values.\n\n**Verdict for Option C:** Incorrect.\n\n**Analysis of Option D:**\n\n*   **Setup:** The dictionary is the identity matrix $D = I_3$, whose columns are orthonormal. $x^{\\star}=[0,1,1]^T$ is $2$-sparse.\n*   **Compute Mutual Coherence:** For an orthonormal dictionary, $\\langle e_i, e_j \\rangle = 0$ for $i \\neq j$, so $\\mu(D) = 0$.\n*   **Check Coherence Condition:** The condition to test is $\\mu(D) \\ge 1/3$. Here, $0  1/3$, so the condition is not met. The problem asks for a case where the condition is violated, i.e., $\\mu(D) \\ge 1/3$. This option presents a case where the sufficient condition for success, $\\mu(D)  1/3$, is satisfied.\n*   **Simulate OMP:** With $y=e_2+e_3$, OMP correctly selects $e_2$ or $e_3$. It succeeds.\n*   **Conclusion:** The option shows an example of success, not failure. Its reasoning that this is a \"valid counterexample because it shows selection succeeds even when $\\mu(D)  \\tfrac{1}{2s-1}$\" is misguided. A success case when a sufficient condition for success is met is an affirming example, not a counterexample.\n\n**Verdict for Option D:** Incorrect.\n\n**Final Conclusion:**\nOption A is the only one that correctly constructs a scenario meeting all the requirements: a dictionary with unit-norm columns, mutual coherence $\\mu(D) \\ge 1/(2s-1)$ for $s=2$, and a specific $2$-sparse vector $x^\\star$ for which OMP fails in the first iteration. Its analysis of the failure mechanism is also correct and illustrative.", "answer": "$$\\boxed{A}$$", "id": "2865197"}, {"introduction": "While analyzing fixed dictionaries is foundational, much of the power of this field lies in learning dictionaries adapted to data. The K-SVD algorithm is a seminal method for this task that iteratively refines dictionary atoms and sparse codes. This exercise offers a hands-on calculation of a single atom update, revealing how it leverages the Singular Value Decomposition (SVD) to find an optimal rank-1 approximation to the error residual [@problem_id:2865198]. Completing this problem solidifies the mechanical understanding of how dictionary learning algorithms operate.", "problem": "Consider a single atom update step in the K-Singular Value Decomposition (K-SVD) algorithm within a dictionary learning model for sparse representations. Let the current residual submatrix associated with atom $j$ and its support set $\\Omega_{j}$ be given as\n$$\nE_{j}^{\\Omega_{j}} \\in \\mathbb{R}^{2 \\times 2}, \\quad E_{j}^{\\Omega_{j}} = \\begin{pmatrix} 1  2 \\\\ 2  1 \\end{pmatrix}.\n$$\nAssume that all dictionary atoms are constrained to have unit Euclidean norm, and that only the columns indexed by $\\Omega_{j}$ contribute to the update of atom $j$ and its nonzero coefficient row.\n\nStarting from the definitions of the singular value decomposition (SVD) and the optimality of the best rank-$1$ approximation with respect to the Frobenius norm, perform one K-SVD atom update for atom $j$ using $E_{j}^{\\Omega_{j}}$. That is, compute the rank-$1$ SVD of $E_{j}^{\\Omega_{j}}$, set the updated atom to the leading left singular vector, and set the updated nonzero coefficients (restricted to $\\Omega_{j}$) to the leading singular value times the leading right singular vector transposed.\n\nFinally, compute the squared Frobenius norm of the post-update residual\n$$\n\\left\\| E_{j}^{\\Omega_{j}} - d_{j} \\, \\alpha_{j,\\Omega_{j}} \\right\\|_{F}^{2},\n$$\nwhere $d_{j}$ is the updated atom and $\\alpha_{j,\\Omega_{j}}$ is the updated coefficient row restricted to $\\Omega_{j}$. Express your final answer as an exact real number with no rounding.", "solution": "The problem requires performing a single atom update step of the K-Singular Value Decomposition (K-SVD) algorithm and then computing the squared Frobenius norm of the resulting approximation error. The problem is well-posed and scientifically sound, as it is a direct application of fundamental principles of linear algebra to a standard algorithm in signal processing.\n\nThe core of the K-SVD atom update step is to find an updated atom $d_{j}$ and a corresponding sparse coefficient row $\\alpha_{j,\\Omega_{j}}$ that minimize the Frobenius norm of the residual. The problem is stated as finding the rank-$1$ approximation of the residual submatrix $E_{j}^{\\Omega_{j}}$ that is optimal in the sense of the Frobenius norm. We are given the residual submatrix:\n$$\nE_{j}^{\\Omega_{j}} = \\begin{pmatrix} 1  2 \\\\ 2  1 \\end{pmatrix}\n$$\nThe optimization problem for the update of atom $j$ and its associated coefficients is:\n$$\n\\min_{d_{j}, \\alpha_{j,\\Omega_{j}}} \\| E_{j}^{\\Omega_{j}} - d_{j} \\alpha_{j,\\Omega_{j}} \\|_{F}^{2} \\quad \\text{subject to} \\quad \\|d_{j}\\|_{2} = 1\n$$\nwhere $d_{j} \\in \\mathbb{R}^{2 \\times 1}$ and $\\alpha_{j,\\Omega_{j}} \\in \\mathbb{R}^{1 \\times 2}$. The product $d_{j} \\alpha_{j,\\Omega_{j}}$ forms a rank-$1$ matrix.\n\nAccording to the Eckart-Young-Mirsky theorem, the best rank-$k$ approximation of a matrix $A$ with respect to the Frobenius norm is given by its truncated Singular Value Decomposition (SVD). For a rank-$1$ approximation, this is:\n$$\nA_1 = \\sigma_1 u_1 v_1^T\n$$\nwhere $\\sigma_1$ is the largest singular value of $A$, and $u_1$ and $v_1$ are the corresponding left and right singular vectors, respectively.\n\nThe K-SVD update rule implements this solution by setting the updated atom $d_{j}$ to the leading left singular vector $u_1$ of $E_{j}^{\\Omega_{j}}$, and the updated coefficient row $\\alpha_{j,\\Omega_{j}}$ to the product of the leading singular value $\\sigma_1$ and the transpose of the leading right singular vector $v_1^T$. That is:\n$$\nd_{j} = u_1\n$$\n$$\n\\alpha_{j,\\Omega_{j}} = \\sigma_{1} v_{1}^{T}\n$$\nWith these choices, the term $d_{j} \\alpha_{j,\\Omega_{j}}$ becomes precisely the best rank-$1$ approximation of $E_{j}^{\\Omega_{j}}$:\n$$\nd_{j} \\alpha_{j,\\Omega_{j}} = u_1 (\\sigma_1 v_1^T) = \\sigma_1 u_1 v_1^T\n$$\nThe problem asks for the squared Frobenius norm of the post-update residual, which is the error of this optimal rank-$1$ approximation. The Eckart-Young-Mirsky theorem also states that the squared Frobenius norm of this error is equal to the sum of the squares of the remaining singular values. If the full SVD of $E_{j}^{\\Omega_{j}}$ is $U \\Sigma V^T = \\sum_{i=1}^{r} \\sigma_i u_i v_i^T$, where $r$ is the rank of the matrix, then:\n$$\n\\| E_{j}^{\\Omega_{j}} - \\sigma_1 u_1 v_1^T \\|_{F}^{2} = \\left\\| \\sum_{i=2}^{r} \\sigma_i u_i v_i^T \\right\\|_{F}^{2} = \\sum_{i=2}^{r} \\sigma_i^2\n$$\nTo find this value, we must compute the singular values of $E_{j}^{\\Omega_{j}}$. The squared singular values, $\\sigma_i^2$, are the eigenvalues of the matrix $(E_{j}^{\\Omega_{j}})^T E_{j}^{\\Omega_{j}}$. Let us denote $E = E_{j}^{\\Omega_{j}}$.\n$$\nE^T E = \\begin{pmatrix} 1  2 \\\\ 2  1 \\end{pmatrix} \\begin{pmatrix} 1  2 \\\\ 2  1 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 2 \\cdot 2  1 \\cdot 2 + 2 \\cdot 1 \\\\ 2 \\cdot 1 + 1 \\cdot 2  2 \\cdot 2 + 1 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 5  4 \\\\ 4  5 \\end{pmatrix}\n$$\nThe eigenvalues $\\lambda$ of this matrix are found by solving the characteristic equation $\\det(E^T E - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} 5-\\lambda  4 \\\\ 4  5-\\lambda \\end{pmatrix} = 0\n$$\n$$\n(5-\\lambda)^2 - 4^2 = 0\n$$\n$$\n(5-\\lambda)^2 = 16\n$$\n$$\n5-\\lambda = \\pm \\sqrt{16} = \\pm 4\n$$\nThis gives two eigenvalues:\n$$\n\\lambda_1 = 5 - (-4) = 9\n$$\n$$\n\\lambda_2 = 5 - 4 = 1\n$$\nThe singular values are the square roots of these eigenvalues, so $\\sigma_1 = \\sqrt{9} = 3$ and $\\sigma_2 = \\sqrt{1} = 1$. The rank of the matrix $E_{j}^{\\Omega_{j}}$ is $2$, as it has two non-zero singular values. The squared norm of the approximation error is the sum of the squares of all singular values except the first one. In this case, it is simply $\\sigma_2^2$.\n$$\n\\| E_{j}^{\\Omega_{j}} - d_{j} \\alpha_{j,\\Omega_{j}} \\|_{F}^{2} = \\sigma_2^2 = \\lambda_2 = 1\n$$\nThus, the squared Frobenius norm of the post-update residual is exactly $1$.", "answer": "$$\\boxed{1}$$", "id": "2865198"}]}