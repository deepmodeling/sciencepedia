{"hands_on_practices": [{"introduction": "This first exercise serves as a fundamental building block, guiding you through the implementation of the conventional Bartlett (delay-and-sum) beamformer from first principles. You will translate the theoretical concept of coherent summation into a working model, allowing you to quantitatively assess its performance. By computing the output Signal-to-Interference-plus-Noise Ratio ($SINR$) and interference attenuation, you will gain direct insight into how spatial filtering enhances a target signal and suppresses unwanted energy from other directions [@problem_id:2853623].", "problem": "Consider a narrowband plane-wave signal model impinging on a Uniform Linear Array (ULA) of $M$ sensors with inter-element spacing $d$ and propagation speed $c$ at temporal frequency $f_0$. Let the wavenumber be $k = \\frac{2\\pi}{\\lambda}$ where $\\lambda = \\frac{c}{f_0}$, and define the array steering vector for an azimuth look angle $\\theta$ (measured from broadside, in degrees) as\n$$\n\\mathbf{a}(\\theta) = \\begin{bmatrix}\n1 & e^{-j k d \\sin(\\theta\\,\\pi/180)} & \\cdots & e^{-j k d (M-1) \\sin(\\theta\\,\\pi/180)}\n\\end{bmatrix}^{\\mathsf{T}} \\in \\mathbb{C}^{M}.\n$$\nAssume a narrowband array data model\n$$\n\\mathbf{x} = \\mathbf{a}(\\theta_0)\\, s + \\mathbf{a}(\\theta_i)\\, u + \\mathbf{n},\n$$\nwhere $s$ and $u$ are zero-mean, circularly symmetric, complex Gaussian random variables with powers $\\sigma_s^2$ and $\\sigma_u^2$, respectively, and $\\mathbf{n} \\sim \\mathcal{CN}(\\mathbf{0}, \\sigma_n^2 \\mathbf{I}_M)$ is spatially and temporally white noise with power $\\sigma_n^2$. Angles are in degrees, and trigonometric functions use radians internally.\n\nYou are to implement the Bartlett (conventional delay-and-sum) beamformer for a desired look direction $\\theta_0$ by constructing a weight vector $\\mathbf{w}$ that enforces a distortionless response toward $\\theta_0$, i.e., $\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0) = 1$. Start from the narrowband plane-wave model and the distortionless constraint, and use only these foundational principles to construct $\\mathbf{w}$.\n\nDefine the output Signal-to-Interference-plus-Noise Ratio (SINR) of the beamformer as\n$$\n\\mathrm{SINR}_{\\text{out}} = \\frac{\\text{output signal power}}{\\text{output interference power} + \\text{output noise power}},\n$$\ncomputed directly from second-order moments of $s, u, \\mathbf{n}$ and the linear form $y = \\mathbf{w}^{\\mathsf{H}} \\mathbf{x}$. Also define the interference attenuation in decibels (dB) as the negative of the beamformer power gain in the interferer direction,\n$$\nA_i \\text{ (dB)} = -10 \\log_{10}\\!\\left(\\left|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_i)\\right|^2\\right).\n$$\nReport $\\mathrm{SINR}_{\\text{out}}$ in decibels (dB) and $A_i$ in decibels (dB). Angles are in degrees. All logarithms are base $10$. Round all reported numbers to exactly four decimal places.\n\nImplement a program that, for each test case below, computes and outputs in order the pair $\\left[\\mathrm{SINR}_{\\text{out}}\\ \\text{(dB)},\\ A_i\\ \\text{(dB)}\\right]$. Aggregate all results from all cases into a single flat list printed on one line as specified in the final output format.\n\nUse half-wavelength inter-element spacing $d = \\lambda/2$ for every test case.\n\nTest suite (angles in degrees; $c$ in meters per second; $f_0$ in hertz; powers in linear units):\n- Case $1$: $M=8$, $f_0=1500$, $c=1500$, $\\theta_0=20$, $\\theta_i=-30$, $\\sigma_s^2=1.0$, $\\sigma_u^2=10.0$, $\\sigma_n^2=1.0$.\n- Case $2$: $M=8$, $f_0=1500$, $c=1500$, $\\theta_0=10$, $\\theta_i=10$, $\\sigma_s^2=1.0$, $\\sigma_u^2=1.0$, $\\sigma_n^2=1.0$.\n- Case $3$: $M=1$, $f_0=1500$, $c=1500$, $\\theta_0=0$, $\\theta_i=30$, $\\sigma_s^2=2.0$, $\\sigma_u^2=3.0$, $\\sigma_n^2=4.0$.\n- Case $4$: $M=16$, $f_0=3000$, $c=1500$, $\\theta_0=0$, $\\theta_i=60$, $\\sigma_s^2=1.0$, $\\sigma_u^2=100.0$, $\\sigma_n^2=1.0$.\n\nFinal output format: Your program should produce a single line of output containing a comma-separated list of numbers enclosed in square brackets, flattening the per-case pairs in the given order. That is, the output must be of the form\n$[\\mathrm{SINR}_{1},A_{i,1},\\mathrm{SINR}_{2},A_{i,2},\\mathrm{SINR}_{3},A_{i,3},\\mathrm{SINR}_{4},A_{i,4}]$,\nwith each number rounded to exactly four decimal places and expressed in decibels (dB).", "solution": "The problem requires the derivation and implementation of a Bartlett beamformer for a Uniform Linear Array (ULA) and the calculation of its performance, specifically the output Signal-to-Interference-plus-Noise Ratio ($\\mathrm{SINR}_{\\text{out}}$) and interference attenuation ($A_i$). The analysis will be based on the provided narrowband plane-wave signal model.\n\nFirst, we derive the weight vector $\\mathbf{w} \\in \\mathbb{C}^{M}$ for the Bartlett beamformer. A Bartlett beamformer is designed to have a maximal response in the desired look direction $\\theta_0$, subject to certain constraints. The problem specifies a distortionless response constraint in this direction, which is formulated as $\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0) = 1$. The conventional, or Bartlett, beamformer can be derived by maximizing the signal-to-noise ratio (SNR) at the output for a signal from the desired direction $\\theta_0$ in the presence of spatially white noise.\n\nThe signal component of the array data from direction $\\theta_0$ is $\\mathbf{x}_s = \\mathbf{a}(\\theta_0)s$. The beamformer output due to this signal is $y_s = \\mathbf{w}^{\\mathsf{H}} \\mathbf{x}_s = \\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)s$. The output signal power is $P_s^{\\text{out}} = E[|y_s|^2] = |\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)|^2 E[|s|^2] = |\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)|^2 \\sigma_s^2$. The noise component is $\\mathbf{n} \\sim \\mathcal{CN}(\\mathbf{0}, \\sigma_n^2 \\mathbf{I}_M)$, and the corresponding output noise is $y_n = \\mathbf{w}^{\\mathsf{H}} \\mathbf{n}$. The output noise power is $P_n^{\\text{out}} = E[|y_n|^2] = E[\\mathbf{w}^{\\mathsf{H}} \\mathbf{n} \\mathbf{n}^{\\mathsf{H}} \\mathbf{w}] = \\mathbf{w}^{\\mathsf{H}} E[\\mathbf{n} \\mathbf{n}^{\\mathsf{H}}] \\mathbf{w} = \\mathbf{w}^{\\mathsf{H}} (\\sigma_n^2 \\mathbf{I}_M) \\mathbf{w} = \\sigma_n^2 \\|\\mathbf{w}\\|_2^2$.\n\nThe output SNR is thus $\\mathrm{SNR} = \\frac{P_s^{\\text{out}}}{P_n^{\\text{out}}} = \\frac{|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)|^2 \\sigma_s^2}{\\sigma_n^2 \\|\\mathbf{w}\\|_2^2}$. To maximize this SNR, we must maximize the term $\\frac{|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)|}{\\|\\mathbf{w}\\|_2}$. By the Cauchy-Schwarz inequality, $|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0)| \\leq \\|\\mathbf{w}\\|_2 \\|\\mathbf{a}(\\theta_0)\\|_2$. The maximum is achieved when $\\mathbf{w}$ is collinear with $\\mathbf{a}(\\theta_0)$, i.e., $\\mathbf{w} = \\alpha \\mathbf{a}(\\theta_0)$ for some scalar $\\alpha$.\n\nWe apply the distortionless response constraint $\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_0) = 1$ to determine $\\alpha$.\n$$ (\\alpha \\mathbf{a}(\\theta_0))^{\\mathsf{H}} \\mathbf{a}(\\theta_0) = \\bar{\\alpha} \\mathbf{a}(\\theta_0)^{\\mathsf{H}} \\mathbf{a}(\\theta_0) = \\bar{\\alpha} \\|\\mathbf{a}(\\theta_0)\\|_2^2 = 1 $$\nThe steering vector elements are $a_m(\\theta_0) = e^{-j k d (m-1) \\sin(\\theta_0\\pi/180)}$, which have unit magnitude. Thus, $\\|\\mathbf{a}(\\theta_0)\\|_2^2 = \\sum_{m=0}^{M-1} |a_m(\\theta_0)|^2 = \\sum_{m=0}^{M-1} 1 = M$.\nThis gives $\\bar{\\alpha} M = 1$, so $\\alpha = 1/M$. The Bartlett weight vector is therefore:\n$$ \\mathbf{w} = \\frac{1}{M} \\mathbf{a}(\\theta_0) $$\n\nNext, we compute the output SINR. The beamformer output is $y = \\mathbf{w}^{\\mathsf{H}}\\mathbf{x}$. Given the data model $\\mathbf{x} = \\mathbf{a}(\\theta_0)s + \\mathbf{a}(\\theta_i)u + \\mathbf{n}$, the output is:\n$$ y = \\mathbf{w}^{\\mathsf{H}}(\\mathbf{a}(\\theta_0)s + \\mathbf{a}(\\theta_i)u + \\mathbf{n}) = (\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_0))s + (\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_i))u + \\mathbf{w}^{\\mathsf{H}}\\mathbf{n} $$\nSince $s$, $u$, and $\\mathbf{n}$ are zero-mean and uncorrelated, the total output power is the sum of the powers of the signal, interference, and noise components.\nThe output signal power, using the distortionless constraint, is $P_s^{\\text{out}} = |\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_0)|^2 \\sigma_s^2 = 1^2 \\cdot \\sigma_s^2 = \\sigma_s^2$.\nThe output interference power is $P_u^{\\text{out}} = |\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 \\sigma_u^2$.\nThe output noise power is $P_n^{\\text{out}} = \\sigma_n^2 \\|\\mathbf{w}\\|_2^2$. Substituting $\\mathbf{w} = \\frac{1}{M}\\mathbf{a}(\\theta_0)$, we get $P_n^{\\text{out}} = \\sigma_n^2 \\|\\frac{1}{M}\\mathbf{a}(\\theta_0)\\|_2^2 = \\frac{\\sigma_n^2}{M^2}\\|\\mathbf{a}(\\theta_0)\\|_2^2 = \\frac{\\sigma_n^2}{M^2}M = \\frac{\\sigma_n^2}{M}$.\n\nThe output SINR is defined as $\\mathrm{SINR}_{\\text{out}} = \\frac{P_s^{\\text{out}}}{P_u^{\\text{out}} + P_n^{\\text{out}}}$. Substituting the derived terms:\n$$ \\mathrm{SINR}_{\\text{out}} = \\frac{\\sigma_s^2}{|\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 \\sigma_u^2 + \\frac{\\sigma_n^2}{M}} $$\nSubstituting $\\mathbf{w} = \\frac{1}{M}\\mathbf{a}(\\theta_0)$:\n$$ |\\mathbf{w}^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 = \\left|\\left(\\frac{1}{M}\\mathbf{a}(\\theta_0)\\right)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)\\right|^2 = \\frac{1}{M^2}|\\mathbf{a}(\\theta_0)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 $$\nSo, the SINR expression becomes:\n$$ \\mathrm{SINR}_{\\text{out}} = \\frac{\\sigma_s^2}{\\frac{\\sigma_u^2}{M^2}|\\mathbf{a}(\\theta_0)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 + \\frac{\\sigma_n^2}{M}} = \\frac{M^2 \\sigma_s^2}{\\sigma_u^2 |\\mathbf{a}(\\theta_0)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2 + M \\sigma_n^2} $$\nThe value is converted to decibels (dB) via $\\mathrm{SINR}_{\\text{out}} \\text{ (dB)} = 10 \\log_{10}(\\mathrm{SINR}_{\\text{out}})$.\n\nThe interference attenuation $A_i$ is defined as $A_i \\text{ (dB)} = -10 \\log_{10}(|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_i)|^2)$. Substituting the expression for the gain term $|\\mathbf{w}^{\\mathsf{H}} \\mathbf{a}(\\theta_i)|^2$:\n$$ A_i \\text{ (dB)} = -10 \\log_{10}\\left(\\frac{1}{M^2}|\\mathbf{a}(\\theta_0)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2\\right) $$\n\nFor all test cases, the inter-element spacing is $d = \\lambda/2$. The wavenumber is $k = 2\\pi/\\lambda$. Thus, the product $kd = (2\\pi/\\lambda)(\\lambda/2) = \\pi$. The $m$-th element (0-indexed) of the steering vector $\\mathbf{a}(\\theta)$ is $e^{-j \\pi m \\sin(\\theta\\pi/180)}$. The term $|\\mathbf{a}(\\theta_0)^{\\mathsf{H}}\\mathbf{a}(\\theta_i)|^2$ is computed by first constructing the vectors $\\mathbf{a}(\\theta_0)$ and $\\mathbf{a}(\\theta_i)$ and then calculating the squared magnitude of their vector inner product. The final results are obtained by substituting the parameters from each test case into these derived formulas.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the output SINR and interference attenuation for a Bartlett beamformer\n    for a set of test cases.\n    \"\"\"\n    # Test cases defined as tuples:\n    # (M, f0, c, theta0_deg, thetai_deg, sigma_s2, sigma_u2, sigma_n2)\n    test_cases = [\n        (8, 1500, 1500, 20, -30, 1.0, 10.0, 1.0),\n        (8, 1500, 1500, 10, 10, 1.0, 1.0, 1.0),\n        (1, 1500, 1500, 0, 30, 2.0, 3.0, 4.0),\n        (16, 3000, 1500, 0, 60, 1.0, 100.0, 1.0),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        M, f0, c, theta0_deg, thetai_deg, sigma_s2, sigma_u2, sigma_n2 = case\n        \n        # The problem specifies half-wavelength spacing d = lambda/2.\n        # Wavelength lambda = c / f0.\n        # Wavenumber k = 2*pi/lambda.\n        # The term kd in the steering vector exponent becomes:\n        # kd = (2*pi/lambda) * (lambda/2) = pi.\n        # This holds true for all cases where M > 1.\n        kd = np.pi\n        \n        # Steering vector is a(theta) = [1, exp(-j*kd*sin(theta)), ..., exp(-j*kd*(M-1)*sin(theta))]\n        # We compute the inner product term |a(theta0)^H a(theta_i)|^2\n        m_indices = np.arange(M)\n        \n        # Angles need to be in radians for numpy's trigonometric functions.\n        theta0_rad = np.deg2rad(theta0_deg)\n        thetai_rad = np.deg2rad(thetai_deg)\n        \n        # Construct steering vectors\n        a_theta0 = np.exp(-1j * kd * m_indices * np.sin(theta0_rad))\n        a_thetai = np.exp(-1j * kd * m_indices * np.sin(thetai_rad))\n        \n        # Calculate a(theta0)^H * a(thetai) using numpy's vdot for hermitian dot product.\n        inner_product = np.vdot(a_theta0, a_thetai)\n        inner_product_sq = np.abs(inner_product)**2\n        \n        # Calculate output SINR in linear scale\n        # SINR_out = (M^2 * sigma_s^2) / (sigma_u^2 * |a_h^H a_i|^2 + M * sigma_n^2)\n        numerator_sinr = (M**2) * sigma_s2\n        denominator_sinr = sigma_u2 * inner_product_sq + M * sigma_n2\n        sinr_linear = numerator_sinr / denominator_sinr\n        \n        # Convert SINR to dB\n        sinr_db = 10 * np.log10(sinr_linear)\n        \n        # Calculate Interference Attenuation in dB\n        # A_i = -10 * log10(|w^H a_i|^2)\n        # |w^H a_i|^2 = |(1/M * a_0^H) a_i|^2 = (1/M^2) * |a_0^H a_i|^2\n        interferer_gain_sq = inner_product_sq / (M**2)\n        Ai_db = -10 * np.log10(interferer_gain_sq)\n\n        # Append rounded results to the list\n        results.append(sinr_db)\n        results.append(Ai_db)\n\n    # Format the final output string as per requirements\n    # Each number must be represented with exactly four decimal places.\n    output_str = \"[\" + \",\".join(f\"{x:.4f}\" for x in results) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "2853623"}, {"introduction": "Moving beyond fixed beamformers, we now explore the powerful Minimum Variance Distortionless Response (MVDR) algorithm, which is designed to optimally null interference sources. However, its theoretical optimality can be fragile in practice; this exercise confronts the critical issue of numerical instability that arises when estimating the data covariance matrix from a finite number of snapshots [@problem_id:2853647]. Through a critical analysis of various stabilization techniques, you will learn why regularization is not just an academic curiosity but an essential tool for robust, real-world adaptive beamforming.", "problem": "A uniform linear array with $M$ sensors collects $N$ temporal snapshots of complex narrowband data. The goal is to design the Minimum Variance Distortionless Response (MVDR) beamformer, which minimizes the output power subject to a distortionless response in the look direction. The sample covariance matrix is $\\hat{R} = \\tfrac{1}{N} X X^{H}$, where $X \\in \\mathbb{C}^{M \\times N}$ stacks the $N$ array snapshots. In a scenario with $M=16$ sensors and $N=40$ snapshots, the presence of coherent interferers results in an estimated condition number $\\kappa(\\hat{R}) \\approx 10^{10}$, and numerical issues are observed when attempting to invert $\\hat{R}$ directly. You are asked to assess the numerical stability of computing the MVDR solution under these conditions, compare Cholesky factorization, orthogonal-triangular (QR) factorization, and eigenvalue decomposition (EVD) approaches for solving the required linear systems, and recommend regularization strategies that improve stability without violating the distortionless constraint.\n\nSelect all statements that are correct.\n\nA. In this setting, attempting to compute the beamformer via Cholesky factorization of the sample covariance without regularization is likely to be unstable or fail numerically; adding diagonal loading $\\lambda I$ with $\\lambda$ comparable to the noise variance produces a strictly positive definite system and, after enforcing the constraint by normalization, preserves the distortionless response exactly.\n\nB. Solving the required linear systems using the orthogonal-triangular (QR) factorization of the data matrix $X$ (thus avoiding explicit formation and inversion of $\\hat{R}=\\tfrac{1}{N} X X^{H}$) mitigates conditioning from $\\kappa(\\hat{R})$ to about $\\kappa(X)=\\sqrt{\\kappa(\\hat{R})}$, which improves numerical stability.\n\nC. Eigenvalue decomposition (EVD) with eigenvalue flooring, i.e., replacing $\\Lambda$ by $\\tilde{\\Lambda}$ with $\\tilde{\\Lambda}_{ii}=\\max(\\Lambda_{ii},\\lambda)$, implements a form of Tikhonov regularization; alternatively, shrinkage $\\hat{R}_{\\text{shr}}=(1-\\alpha)\\hat{R}+\\alpha \\sigma^{2} I$ with data-driven $\\alpha \\in (0,1)$ yields an invertible, well-conditioned estimator even when $N<M$.\n\nD. Because the sample covariance is always Hermitian positive semidefinite in exact arithmetic, Cholesky with symmetric pivoting can factor any such matrix even if it is indefinite in floating-point; hence pivoted Cholesky eliminates the need for regularization.\n\nE. Truncating the EVD by zeroing the smallest eigenvalues (discarding the noise subspace) always improves the Minimum Variance Distortionless Response beamformer, since it reduces the contribution of white noise while keeping the constraint intact.", "solution": "The problem at hand concerns the numerical stability of the Minimum Variance Distortionless Response (MVDR) beamformer. I shall first state the problem formally and then proceed to a rigorous evaluation of each statement.\n\nThe objective of the MVDR beamformer is to find a weight vector $w \\in \\mathbb{C}^{M}$ that solves the following optimization problem:\n$$ \\min_{w} w^H \\hat{R} w \\quad \\text{subject to} \\quad w^H a(\\theta_0) = 1 $$\nHere, $w^H \\hat{R} w$ is the output power, $\\hat{R} = \\frac{1}{N} X X^{H}$ is the $M \\times M$ sample covariance matrix (SCM) derived from $N$ snapshots of data $X \\in \\mathbb{C}^{M \\times N}$, and $a(\\theta_0)$ is the steering vector corresponding to the desired look direction $\\theta_0$. The constraint $w^H a(\\theta_0) = 1$ ensures a distortionless response for a signal arriving from $\\theta_0$.\n\nThe analytical solution to this problem is given by the method of Lagrange multipliers:\n$$ w_{MVDR} = \\frac{\\hat{R}^{-1} a(\\theta_0)}{a(\\theta_0)^H \\hat{R}^{-1} a(\\theta_0)} $$\nThe core numerical task is the computation of the vector $y = \\hat{R}^{-1} a(\\theta_0)$, which is equivalent to solving the linear system of equations $\\hat{R} y = a(\\theta_0)$.\n\nThe problem states that for $M=16$ sensors and $N=40$ snapshots, the SCM is severely ill-conditioned, with a condition number $\\kappa(\\hat{R}) \\approx 10^{10}$. Since $N > M$, $\\hat{R}$ is, in theory, a full-rank matrix. However, the presence of coherent interferers causes some eigenvalues of $\\hat{R}$ to be extremely small, leading to the observed ill-conditioning. A condition number of $10^{10}$ is problematic for standard double-precision floating-point arithmetic, which has approximately $16$ decimal digits of precision. Direct inversion of $\\hat{R}$ is therefore unstable and will amplify numerical errors.\n\nNow, I will analyze each statement.\n\nA. In this setting, attempting to compute the beamformer via Cholesky factorization of the sample covariance without regularization is likely to be unstable or fail numerically; adding diagonal loading $\\lambda I$ with $\\lambda$ comparable to the noise variance produces a strictly positive definite system and, after enforcing the constraint by normalization, preserves the distortionless response exactly.\n\nThe Cholesky factorization, $\\hat{R} = L L^H$, where $L$ is a lower triangular matrix, is only defined for Hermitian positive definite matrices. While the exact SCM is positive semidefinite, in finite precision arithmetic, an ill-conditioned matrix with $\\kappa(\\hat{R}) \\approx 10^{10}$ can easily lose its numerical positive definiteness due to rounding errors, causing the algorithm to fail (e.g., by attempting to compute the square root of a negative diagonal element). Thus, the first part of the statement is correct.\nAdding a diagonal loading term, $\\lambda I$, where $I$ is the identity matrix and $\\lambda > 0$, results in a regularized matrix $\\hat{R}_{reg} = \\hat{R} + \\lambda I$. Let the eigenvalues of $\\hat{R}$ be $\\sigma_i \\ge 0$. The eigenvalues of $\\hat{R}_{reg}$ are $\\sigma_i + \\lambda$. Since $\\lambda > 0$, all eigenvalues of $\\hat{R}_{reg}$ are strictly positive. Therefore, $\\hat{R}_{reg}$ is strictly positive definite and well-suited for Cholesky factorization. The choice of $\\lambda$ being comparable to the noise variance is a common and effective heuristic, often referred to as Tikhonov regularization or robust Capon beamforming.\nThe regularized weight vector is computed as $w_{reg} = \\frac{\\hat{R}_{reg}^{-1} a(\\theta_0)}{a(\\theta_0)^H \\hat{R}_{reg}^{-1} a(\\theta_0)}$. The denominator is a scalar normalization factor. The response of this beamformer in the look direction is $w_{reg}^H a(\\theta_0) = \\frac{a(\\theta_0)^H (\\hat{R}_{reg}^{-1})^H a(\\theta_0)}{a(\\theta_0)^H \\hat{R}_{reg}^{-1} a(\\theta_0)}$. Since $\\hat{R}_{reg}$ is Hermitian, $(\\hat{R}_{reg}^{-1})^H = \\hat{R}_{reg}^{-1}$, and the expression simplifies to $1$. The distortionless constraint is preserved exactly by the normalization. The statement is correct in all its assertions.\n**Verdict: Correct**\n\nB. Solving the required linear systems using the orthogonal-triangular (QR) factorization of the data matrix $X$ (thus avoiding explicit formation and inversion of $\\hat{R}=\\tfrac{1}{N} X X^{H}$) mitigates conditioning from $\\kappa(\\hat{R})$ to about $\\kappa(X)=\\sqrt{\\kappa(\\hat{R})}$, which improves numerical stability.\n\nThe sample covariance matrix is $\\hat{R} = \\frac{1}{N} X X^H$. The condition number of a matrix product of this form is related to the condition number of the original matrix $X$ by $\\kappa(\\hat{R}) = \\kappa(X X^H) = (\\kappa(X))^2$. The problem states $\\kappa(\\hat{R}) \\approx 10^{10}$, which implies $\\kappa(X) \\approx \\sqrt{10^{10}} = 10^5$. A condition number of $10^5$ is far more manageable than $10^{10}$.\nThe statement claims that using a QR-based method on the data matrix $X$ avoids the \"squaring\" of the condition number. This is a fundamental principle of numerical linear algebra. Solving the normal equations $A^H A x = A^H b$ is less stable than solving the least-squares problem $\\min \\|Ax-b\\|$ using QR factorization of $A$. In our context, the MVDR problem is equivalent to the linearly constrained least-squares problem $\\min_{w} \\|X^H w\\|^2$ subject to $w^H a(\\theta_0) = 1$. Such problems can be solved using methods based on QR factorization of matrices derived from $X$ and $a(\\theta_0)$, without ever forming the explicit product $X X^H$. These methods operate on matrices whose condition numbers are related to $\\kappa(X)$, not $\\kappa(X)^2$. Therefore, this approach indeed mitigates the ill-conditioning and provides a much more stable numerical solution.\n**Verdict: Correct**\n\nC. Eigenvalue decomposition (EVD) with eigenvalue flooring, i.e., replacing $\\Lambda$ by $\\tilde{\\Lambda}$ with $\\tilde{\\Lambda}_{ii}=\\max(\\Lambda_{ii},\\lambda)$, implements a form of Tikhonov regularization; alternatively, shrinkage $\\hat{R}_{\\text{shr}}=(1-\\alpha)\\hat{R}+\\alpha \\sigma^{2} I$ with data-driven $\\alpha \\in (0,1)$ yields an invertible, well-conditioned estimator even when $N<M$.\n\nLet the EVD of the SCM be $\\hat{R} = U \\Lambda U^H$. Standard Tikhonov regularization yields $\\hat{R} + \\lambda I = U(\\Lambda + \\lambda I)U^H$, which adds $\\lambda$ to all eigenvalues. Eigenvalue flooring, which produces a new matrix $\\tilde{R} = U \\tilde{\\Lambda} U^H$ with $\\tilde{\\Lambda}_{ii} = \\max(\\Lambda_{ii}, \\lambda)$, achieves a similar goal: it lifts small eigenvalues to at least $\\lambda$, thus bounding the condition number and making the matrix positive definite. It is a valid regularization technique, closely related to Tikhonov regularization, and sometimes considered a variant of it.\nThe second part of the statement describes linear shrinkage. The shrinkage estimator $\\hat{R}_{\\text{shr}} = (1-\\alpha)\\hat{R} + \\alpha \\sigma^2 I$ is a convex combination of the SCM and a scaled identity matrix. For $\\alpha \\in (0,1)$, this estimator is guaranteed to be positive definite because it is the sum of a positive semidefinite matrix $(1-\\alpha)\\hat{R}$ and a positive definite matrix $\\alpha \\sigma^2 I$. Furthermore, shrinkage is particularly valuable in the \"small $N$, large $M$\" regime. When $N < M$, the SCM $\\hat{R}$ is rank-deficient and thus singular (not invertible). The shrinkage estimator $\\hat{R}_{\\text{shr}}$ remains positive definite and invertible even in this case, a crucial advantage. There exist data-driven methods (e.g., Ledoit-Wolf) to find an optimal $\\alpha$. The statement is entirely correct.\n**Verdict: Correct**\n\nD. Because the sample covariance is always Hermitian positive semidefinite in exact arithmetic, Cholesky with symmetric pivoting can factor any such matrix even if it is indefinite in floating-point; hence pivoted Cholesky eliminates the need for regularization.\n\nThe SCM $\\hat{R} = \\frac{1}{N} XX^H$ is indeed Hermitian positive semidefinite in exact arithmetic, as for any vector $v$, $v^H \\hat{R} v = \\frac{1}{N} \\|X^H v\\|_2^2 \\ge 0$. While pivoted Cholesky factorization ($P^T \\hat{R} P = LL^H$) is more robust than the standard version for semidefinite matrices, it cannot proceed if the matrix becomes indefinite. An indefinite matrix has at least one negative eigenvalue. The matrix $LL^H$ is, by construction, positive semidefinite, so it cannot be equal to a permuted indefinite matrix. If rounding errors cause $\\hat{R}$ to become numerically indefinite, pivoted Cholesky will fail. The claim that it can factor an indefinite matrix is false. For indefinite matrices, one must use factorizations like Bunch-Kaufman $LDL^H$.\nMost importantly, even if a factorization is successfully computed for a nearly singular matrix, this does not eliminate the need for regularization. The ill-conditioning of the problem itself means the solution $y = \\hat{R}^{-1} a(\\theta_0)$ is extremely sensitive to perturbations. Regularization is not merely a tool to enable factorization; it is a fundamental technique to stabilize the solution of an ill-posed inverse problem by introducing a small, controlled bias. This statement is fundamentally flawed.\n**Verdict: Incorrect**\n\nE. Truncating the EVD by zeroing the smallest eigenvalues (discarding the noise subspace) always improves the Minimum Variance Distortionless Response beamformer, since it reduces the contribution of white noise while keeping the constraint intact.\n\nThis technique is known as Principal Component (PC) or eigenspace-based beamforming. It involves creating a low-rank approximation of the covariance matrix, $\\hat{R}_{trunc} = \\sum_{i=1}^K \\sigma_i u_i u_i^H$, where $\\sigma_i$ and $u_i$ are the $K$ largest eigenvalues and corresponding eigenvectors. The \"inverse\" is computed using the pseudoinverse: $\\hat{R}_{trunc}^{\\dagger} = \\sum_{i=1}^K \\frac{1}{\\sigma_i} u_i u_i^H$. The weights are then $w \\propto \\hat{R}_{trunc}^{\\dagger} a(\\theta_0)$.\nThe word \"always\" renders this statement incorrect. This method works well only if the true steering vector $a(\\theta_0)$ lies entirely or almost entirely within the subspace spanned by the first $K$ eigenvectors (the principal subspace). If there is any signal model mismatch or if the signal is weak, the vector $a(\\theta_0)$ may have significant components in the discarded subspace (the so-called \"noise subspace\"). In such a case, projecting $a(\\theta_0)$ onto the principal subspace results in a vector that is a poor representation of the signal. If $a(\\theta_0)$ is nearly orthogonal to the principal subspace, $\\hat{R}_{trunc}^{\\dagger} a(\\theta_0)$ will be close to the zero vector. The subsequent normalization to enforce the distortionless constraint will cause the norm of the weight vector $\\|w\\|$ to become enormous, leading to extreme amplification of white noise and disastrous performance. This method lacks robustness, which is a critical property for practical beamformers. Therefore, it does not \"always\" improve performance.\n**Verdict: Incorrect**", "answer": "$$\\boxed{ABC}$$", "id": "2853647"}, {"introduction": "In this final practice, we elevate our perspective from individual algorithms to system-level architecture and design trade-offs. You will analyze and compare two dominant paradigms in modern sensing: the traditional phased-array and the more recent Multiple-Input Multiple-Output (MIMO) virtual array [@problem_id:2853580]. By deriving and applying fundamental performance metrics—the Signal-to-Noise Ratio ($SNR$) for detection and the Cramér-Rao Bound ($CRB$) for estimation accuracy—you will learn how to make quantitative, engineering-driven decisions between competing system designs based on mission requirements.", "problem": "A colocated radar receiver uses linear arrays to estimate the direction of arrival of a single, far-field, narrowband source at broadside. Two spatial processing modes are available:\n\n- Phased-array coherent mode: All $M$ transmitters emit the same waveform with phases chosen to focus at broadside. The $N$ receivers form a coherent spatial beam at broadside.\n- Multiple-Input Multiple-Output (MIMO) diversity mode: All $M$ transmitters emit mutually orthogonal waveforms sharing the same total transmit energy equally. The receiver separates the $M$ waveforms by matched filtering and forms a virtual Uniform Linear Array (ULA) of size $M N$ for angle estimation.\n\nAssume the following physical model and constraints.\n\n- Both transmit and receive arrays are Uniform Linear Arrays (ULAs) with inter-element spacing $d=\\lambda/2$ and are broadside to the source.\n- The received baseband signal at each receive element is corrupted by Additive White Gaussian Noise (AWGN) with variance $\\sigma^{2}$ per complex dimension and is independent across elements and snapshots.\n- The total transmit energy per snapshot is fixed and equal across modes. Define the per-snapshot, per-transmit, per-receive, single-antenna input Signal-to-Noise Ratio (SNR) (i.e., the SNR that would be observed at one receiver if a single transmitter used the entire energy) as $\\rho$. Thus, any redistribution of energy across transmitters and any coherent combining will scale the effective SNRs relative to $\\rho$.\n- Angle-of-arrival estimation uses $K$ statistically independent temporal snapshots of the narrowband signal in each mode.\n- Detection is performed at broadside after spatial processing. In the phased-array coherent mode the effective output SNR scales with the coherent transmit-receive gain, while in the Multiple-Input Multiple-Output (MIMO) diversity mode it scales with receive-only combining under the orthogonality and equal-power assumptions.\n- Two performance requirements must be met simultaneously:\n  1. A detection SNR constraint: the post-spatial-processing SNR must satisfy $\\mathrm{SNR}_{\\mathrm{out}} \\geq \\Gamma$, where $\\Gamma$ is a given positive constant.\n  2. A resolution (estimation) constraint: the variance of any unbiased broadside direction-of-arrival estimator must satisfy the Cramér–Rao bound (CRB) at broadside being no greater than a required bound $V_{\\mathrm{req}}$ (in radians squared). Angles are measured in radians.\n\nTasks:\n\n1. Starting from the narrowband array manifold for a ULA, the Gaussian likelihood under AWGN, and the Fisher Information for a deterministic mean with unknown amplitude, derive the output SNR scaling for each mode in terms of $\\rho$, $M$, and $N$, and derive the broadside Cramér–Rao bound (CRB) on the direction-of-arrival variance for each mode as a function of $\\rho$, $K$, $M$, and $N$. Your derivations must explicitly use the derivative of the ULA steering vector at broadside and the centered second-moment of the sensor indices.\n2. Using your results from part 1, determine the minimum input SNR $\\rho$ required so that the MIMO diversity mode simultaneously satisfies both the detection SNR constraint and the CRB-based resolution constraint. Express your final answer for this minimum $\\rho$ as a single closed-form analytic expression in terms of $M$, $N$, $K$, $\\Gamma$, and $V_{\\mathrm{req}}$ only. Do not include any units in the final expression.\n\nYour final answer must be a single closed-form analytic expression. If you introduce any approximations, clearly state and justify them in your derivation. No rounding is required, and the final expression must not include units.", "solution": "The problem statement is first subjected to validation.\n\nGivens are extracted verbatim as follows:\n- A colocated radar receiver with linear arrays.\n- A single, far-field, narrowband source at broadside.\n- Two modes: Phased-array coherent mode (Mode 1) and Multiple-Input Multiple-Output (MIMO) diversity mode (Mode 2).\n- Mode 1: $M$ transmitters emit the same waveform, phased to focus at broadside. $N$ receivers form a coherent spatial beam at broadside.\n- Mode 2: $M$ transmitters emit mutually orthogonal waveforms with equal energy. The receiver uses matched filtering to separate waveforms and forms a virtual Uniform Linear Array (ULA) of size $M N$.\n- Both transmit and receive arrays are ULAs with inter-element spacing $d=\\lambda/2$ and are broadside to the source.\n- Received signal at each element is corrupted by Additive White Gaussian Noise (AWGN) with variance $\\sigma^{2}$ per complex dimension, independent across elements and snapshots.\n- Total transmit energy per snapshot is fixed and equal across modes.\n- The per-snapshot, per-transmit, per-receive, single-antenna input Signal-to-Noise Ratio (SNR) is defined as $\\rho$, this being the SNR if a single transmitter used the entire energy.\n- Angle-of-arrival estimation uses $K$ statistically independent temporal snapshots.\n- Constraint 1: Post-processing SNR must satisfy $\\mathrm{SNR}_{\\mathrm{out}} \\geq \\Gamma$.\n- Constraint 2: The variance of any unbiased broadside direction-of-arrival estimator must satisfy the Cramér–Rao bound (CRB) at broadside being no greater than $V_{\\mathrm{req}}$ (in radians squared).\n\nThe problem is evaluated against validation criteria. It is scientifically grounded in established principles of array signal processing and radar systems. It is well-posed, asking for a minimum value of a parameter subject to clear, quantitative constraints. The terminology used is standard and objective, and the provided information is internally consistent and sufficient for a solution, given the explicit instruction to model the MIMO system as a virtual ULA of size $M N$. The problem is therefore deemed valid.\n\nThe solution proceeds first by deriving the general expressions for output SNR and the CRB, then applying them to the two specified modes, and finally solving for the minimum required input SNR for the MIMO mode.\n\nFirst, we establish the signal model and the general form of the CRB. For a ULA with $L$ elements and inter-element spacing $d=\\lambda/2$, the steering vector towards an angle $\\theta$ (measured from broadside) is\n$$ \\mathbf{a}(\\theta) = [1, \\exp(-j\\pi\\sin\\theta), \\dots, \\exp(-j\\pi(L-1)\\sin\\theta)]^T $$\nAt broadside, $\\theta=0$, the steering vector is $\\mathbf{a}(0) = \\mathbf{1}_{L}$, a vector of $L$ ones.\n\nThe received signal vector for a single snapshot at an $L$-element array is\n$$ \\mathbf{y} = s \\mathbf{a}(\\theta) + \\mathbf{n} $$\nwhere $s$ is the complex amplitude of the signal at the first element, and $\\mathbf{n}$ is a vector of i.i.d. complex Gaussian noise samples with $E[\\mathbf{n}\\mathbf{n}^H] = \\sigma^2 \\mathbf{I}_L$.\n\nThe CRB on the variance of any unbiased estimator of $\\theta$, for $K$ independent snapshots and an unknown signal amplitude $s$, is given by the inverse of the Fisher Information, $J(\\theta)$:\n$$ \\mathrm{CRB}(\\theta) = [J(\\theta)]^{-1} = \\left( \\frac{2K|s|^2}{\\sigma^2} \\mathrm{Re}\\left\\{ (\\mathbf{a}'(\\theta))^H \\mathbf{P}_{\\mathbf{a}(\\theta)}^{\\perp} \\mathbf{a}'(\\theta) \\right\\} \\right)^{-1} $$\nwhere $\\mathbf{a}'(\\theta) = \\frac{d\\mathbf{a}(\\theta)}{d\\theta}$ and $\\mathbf{P}_{\\mathbf{a}(\\theta)}^{\\perp} = \\mathbf{I} - \\frac{\\mathbf{a}(\\theta)\\mathbf{a}(\\theta)^H}{\\|\\mathbf{a}(\\theta)\\|^2}$ is the projection matrix onto the subspace orthogonal to $\\mathbf{a}(\\theta)$.\n\nAt broadside ($\\theta=0$), the derivative of the steering vector is\n$$ \\mathbf{a}'(0) = \\frac{d}{d\\theta} \\mathbf{a}(\\theta) |_{\\theta=0} = -j\\pi\\cos(0) [0, 1, \\dots, L-1]^T = -j\\pi \\mathbf{p} $$\nwhere $\\mathbf{p} = [0, 1, \\dots, L-1]^T$ is the vector of sensor indices.\nThe term in the Fisher Information simplifies to:\n$$ (\\mathbf{a}'(0))^H \\mathbf{P}_{\\mathbf{a}(0)}^{\\perp} \\mathbf{a}'(0) = \\| \\mathbf{P}_{\\mathbf{a}(0)}^{\\perp} \\mathbf{a}'(0) \\|^2 = \\| -j\\pi (\\mathbf{I} - \\frac{\\mathbf{1}\\mathbf{1}^T}{L})\\mathbf{p} \\|^2 $$\n$$ = \\pi^2 \\| \\mathbf{p} - \\frac{\\mathbf{1}^T\\mathbf{p}}{L}\\mathbf{1} \\|^2 = \\pi^2 \\| \\mathbf{p} - \\bar{p}\\mathbf{1} \\|^2 = \\pi^2 \\sum_{l=0}^{L-1}(l-\\bar{p})^2 $$\nwhere $\\bar{p} = \\frac{1}{L}\\sum_{l=0}^{L-1}l = \\frac{L-1}{2}$ is the mean sensor index. The summation is $L$ times the centered second-moment of the sensor indices, which for a ULA is $\\frac{L^2-1}{12}$.\nThus, the term becomes $\\pi^2 L \\frac{L^2-1}{12}$.\nThe broadside CRB is therefore\n$$ \\mathrm{CRB}(0) = \\left( \\frac{2K|s|^2}{\\sigma^2} \\pi^2 L \\frac{L^2-1}{12} \\right)^{-1} = \\frac{6\\sigma^2}{K\\pi^2 |s|^2 L(L^2-1)} $$\nThe input SNR, $\\rho$, is defined as the SNR at a single receiver if a single transmitter used the total energy, $E_{tx, tot}$. Let the channel gain be $s_0$. Then $|s_0|^2 E_{tx, tot}$ is the received signal energy.\n$$ \\rho = \\frac{|s_0|^2 E_{tx, tot}}{\\sigma^2} $$\nWe now analyze the two modes.\n\nMode 1: Phased-Array (PA) Coherent Mode\nThe $M$ transmitters coherently form a beam, resulting in constructive interference. The signal amplitude at each of the $N$ receiving elements is thus scaled by $M$ over a single transmitter, but since the energy is divided among $M$ transmitters ($E_{tx,tot}/M$ per Tx), the amplitude scales by $\\sqrt{M}$. The total amplitude scaling is $M \\times 1/\\sqrt{M} = \\sqrt{M}$.\nThe received signal amplitude $s_{PA}$ at each element of the $N$-element receive array satisfies $|s_{PA}|^2 = M |s_0|^2 E_{tx, tot}$, so the per-element SNR is $|s_{PA}|^2/\\sigma^2 = M \\rho$.\nThe receive array has $N$ elements. Beamingforming at broadside involves summing the outputs, which corresponds to pre-multiplying the received vector $\\mathbf{y}$ by $\\mathbf{a}(0)^H = \\mathbf{1}_N^T$.\nThe output signal power is $|\\mathbf{1}_N^T (s_{PA} \\mathbf{1}_N)|^2 = |s_{PA}|^2 N^2 = M |s_0|^2 E_{tx, tot} N^2$.\nThe output noise power is $E[|\\mathbf{1}_N^T \\mathbf{n}|^2] = \\mathbf{1}_N^T E[\\mathbf{n}\\mathbf{n}^H] \\mathbf{1}_N = \\sigma^2 \\|\\mathbf{1}_N\\|^2 = \\sigma^2 N$.\nThe output SNR for the PA mode is:\n$$ \\mathrm{SNR}_{\\mathrm{out, PA}} = \\frac{M |s_0|^2 E_{tx, tot} N^2}{\\sigma^2 N} = MN \\frac{|s_0|^2 E_{tx, tot}}{\\sigma^2} = MN\\rho $$\nFor the CRB, we use the general formula with array size $L=N$ and per-element signal power $|s|^2=|s_{PA}|^2$:\n$$ \\mathrm{CRB}_{\\mathrm{PA}}(0) = \\frac{6\\sigma^2}{K\\pi^2 |s_{PA}|^2 N(N^2-1)} = \\frac{6\\sigma^2}{K\\pi^2 (M\\rho\\sigma^2) N(N^2-1)} = \\frac{6}{K\\pi^2 \\rho M N(N^2-1)} $$\n\nMode 2: MIMO Diversity Mode\nThe $M$ transmitters use orthogonal waveforms, each with energy $E_{tx, tot}/M$. The receiver separates these, forming a virtual ULA of size $L_{eff}=MN$. The signal power associated with each virtual element corresponds to a single transmit-receive path, so $|s_{MIMO}|^2 = |s_0|^2 (E_{tx, tot}/M)$. The per-element SNR for the virtual array is $|s_{MIMO}|^2/\\sigma^2 = \\frac{|s_0|^2 E_{tx, tot}}{M \\sigma^2} = \\rho/M$.\nThe output SNR is obtained by coherently combining the $MN$ virtual elements. This yields a processing gain of $MN$.\nThe output SNR for the MIMO mode is:\n$$ \\mathrm{SNR}_{\\mathrm{out, MIMO}} = (\\text{per-element SNR}) \\times (\\text{array gain}) = (\\rho/M) \\times (MN) = N\\rho $$\nFor the CRB, we use the general formula with effective array size $L=L_{eff}=MN$ and per-element signal power $|s|^2=|s_{MIMO}|^2$:\n$$ \\mathrm{CRB}_{\\mathrm{MIMO}}(0) = \\frac{6\\sigma^2}{K\\pi^2 |s_{MIMO}|^2 L_{eff}(L_{eff}^2-1)} = \\frac{6\\sigma^2}{K\\pi^2 (\\rho\\sigma^2/M) MN((MN)^2-1)} $$\n$$ \\mathrm{CRB}_{\\mathrm{MIMO}}(0) = \\frac{6M}{K\\pi^2 \\rho \\sigma^2} \\frac{\\sigma^2}{MN(M^2N^2-1)} = \\frac{6}{K\\pi^2 \\rho N(M^2N^2-1)} $$\n\nNow, for Task 2, we determine the minimum $\\rho$ for the MIMO mode to satisfy both constraints.\nConstraint 1 (Detection SNR): $\\mathrm{SNR}_{\\mathrm{out, MIMO}} \\geq \\Gamma$\n$$ N\\rho \\geq \\Gamma \\implies \\rho \\geq \\frac{\\Gamma}{N} $$\nConstraint 2 (Resolution): $\\mathrm{CRB}_{\\mathrm{MIMO}}(0) \\leq V_{\\mathrm{req}}$\n$$ \\frac{6}{K\\pi^2 \\rho N(M^2N^2-1)} \\leq V_{\\mathrm{req}} \\implies \\rho \\geq \\frac{6}{K\\pi^2 V_{\\mathrm{req}} N(M^2N^2-1)} $$\nTo satisfy both constraints simultaneously, $\\rho$ must be greater than or equal to the maximum of these two lower bounds. The minimum required $\\rho$ is therefore:\n$$ \\rho_{\\mathrm{min}} = \\max\\left( \\frac{\\Gamma}{N}, \\frac{6}{K\\pi^2 V_{\\mathrm{req}} N(M^2N^2-1)} \\right) $$\nThis expression is the final answer. It is a single closed-form analytic expression in terms of the required parameters $M$, $N$, $K$, $\\Gamma$, and $V_{\\mathrm{req}}$.", "answer": "$$\n\\boxed{\\max\\left( \\frac{\\Gamma}{N}, \\frac{6}{K\\pi^2 V_{\\mathrm{req}} N(M^2N^2-1)} \\right)}\n$$", "id": "2853580"}]}