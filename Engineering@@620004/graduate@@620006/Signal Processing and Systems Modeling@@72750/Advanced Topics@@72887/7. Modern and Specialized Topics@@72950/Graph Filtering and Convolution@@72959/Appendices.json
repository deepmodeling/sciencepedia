{"hands_on_practices": [{"introduction": "The power of graph spectral filtering lies in its ability to shape signals based on their relationship to the underlying network structure. This practice provides a foundational, hands-on opportunity to build a graph filter from first principles. By manually computing a filter matrix entry for a simple cycle graph, you will directly apply the spectral theorem to translate a desired frequency response into a tangible node-domain operator, demystifying the core mechanism of spectral functional calculus [@problem_id:2874957].", "problem": "Consider the undirected, unweighted cycle graph on $4$ vertices labeled $1,2,3,4$ arranged in cyclic order, with edges $\\{(1,2),(2,3),(3,4),(4,1)\\}$. Let $A$ denote the adjacency matrix and $D$ the degree matrix. The combinatorial Laplacian is $L = D - A$. Because $L$ is real symmetric, it admits an orthonormal eigenbasis and a real spectrum.\n\nDefine a spectral kernel $f(\\lambda)$ by\n- $f(\\lambda) = \\alpha$ for $\\lambda \\in [0,1]$,\n- $f(\\lambda) = \\beta$ for $\\lambda \\in (1,3]$,\n- $f(\\lambda) = \\gamma$ for $\\lambda \\in (3,\\infty)$,\n\nwhere $\\alpha,\\beta,\\gamma$ are fixed real constants. Consider the graph filter defined by the spectral functional calculus $H = f(L)$.\n\nUsing only the definition of the combinatorial Laplacian, the spectral theorem for real symmetric matrices, and the definition of a function of a matrix via the spectral functional calculus, determine the single matrix entry $H_{1,3}$ as an exact symbolic expression in terms of $\\alpha,\\beta,\\gamma$. No numerical rounding is required and no units are involved. Your final answer must be a single closed-form expression.", "solution": "The posed problem is scientifically grounded, well-posed, and objective. It is a standard exercise in spectral graph theory and contains all necessary information for a unique, verifiable solution. We proceed with the derivation.\n\nThe problem requires the calculation of the matrix entry $H_{1,3}$ for a graph filter $H = f(L)$, where $L$ is the combinatorial Laplacian of a cycle graph $C_4$. The solution proceeds by first constructing the Laplacian matrix, then computing its spectral decomposition (eigenvalues and eigenvectors), and finally applying the definition of a function of a matrix via spectral calculus.\n\nFirst, we establish the matrices associated with the undirected, unweighted cycle graph on $4$ vertices, which are labeled $1, 2, 3, 4$ in sequence. The edge set is $\\{(1,2), (2,3), (3,4), (4,1)\\}$.\n\nThe adjacency matrix $A$, with entries $A_{ij}=1$ if an edge connects vertex $i$ and vertex $j$ and $A_{ij}=0$ otherwise, is:\n$$ A = \\begin{pmatrix} 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 0 \\end{pmatrix} $$\nEach vertex has a degree of $2$. The degree matrix $D$ is a diagonal matrix with vertex degrees on the diagonal. Thus, $D = 2I$, where $I$ is the $4 \\times 4$ identity matrix:\n$$ D = \\begin{pmatrix} 2 & 0 & 0 & 0 \\\\ 0 & 2 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 2 \\end{pmatrix} $$\nThe combinatorial Laplacian $L$ is defined as $L = D - A$:\n$$ L = \\begin{pmatrix} 2 & -1 & 0 & -1 \\\\ -1 & 2 & -1 & 0 \\\\ 0 & -1 & 2 & -1 \\\\ -1 & 0 & -1 & 2 \\end{pmatrix} $$\nThe next step is to find the spectral decomposition of $L$. Since $L$ is a real symmetric matrix, it is guaranteed to have an orthonormal basis of eigenvectors and real eigenvalues. The eigenvalues $\\lambda_k$ of the Laplacian for a cycle graph $C_n$ are given by the formula $\\lambda_k = 2 - 2\\cos(\\frac{2\\pi k}{n})$ for $k \\in \\{0, 1, \\dots, n-1\\}$. For $n=4$, the eigenvalues are:\n- $\\lambda_0 = 2 - 2\\cos(0) = 0$\n- $\\lambda_1 = 2 - 2\\cos(\\frac{\\pi}{2}) = 2$\n- $\\lambda_2 = 2 - 2\\cos(\\pi) = 4$\n- $\\lambda_3 = 2 - 2\\cos(\\frac{3\\pi}{2}) = 2$\n\nThe set of eigenvalues is $\\{0, 2, 2, 4\\}$. We must find a corresponding set of orthonormal eigenvectors $\\{u_k\\}$.\n- For the eigenvalue $\\lambda=0$, the eigenvector equation $(L-0I)v=0$ yields $v_1=v_2=v_3=v_4$. The normalized eigenvector is $u_1 = \\frac{1}{\\sqrt{4}}(1, 1, 1, 1)^T = \\frac{1}{2}(1, 1, 1, 1)^T$.\n- For the eigenvalue $\\lambda=4$, the equation $(L-4I)v=0$ yields $v_1=v_3$ and $v_2=v_4=-v_1$. The normalized eigenvector is $u_2 = \\frac{1}{\\sqrt{4}}(1, -1, 1, -1)^T = \\frac{1}{2}(1, -1, 1, -1)^T$.\n- For the degenerate eigenvalue $\\lambda=2$, the eigenspace is defined by the equations $v_1+v_3=0$ and $v_2+v_4=0$. This is a two-dimensional space. We select an orthonormal basis for this eigenspace. A valid choice is $u_3 = \\frac{1}{\\sqrt{2}}(1, 0, -1, 0)^T$ and $u_4 = \\frac{1}{\\sqrt{2}}(0, 1, 0, -1)^T$. These two vectors are orthogonal to each other and to $u_1$ and $u_2$.\n\nSo, we have a complete orthonormal set of eigenvectors. Let us assign them to eigenvalues as follows:\n- $\\lambda_1 = 0$, with eigenvector $u_1 = \\frac{1}{2}(1, 1, 1, 1)^T$.\n- $\\lambda_2 = 4$, with eigenvector $u_2 = \\frac{1}{2}(1, -1, 1, -1)^T$.\n- $\\lambda_3 = 2$, with eigenvector $u_3 = \\frac{1}{\\sqrt{2}}(1, 0, -1, 0)^T$.\n- $\\lambda_4 = 2$, with eigenvector $u_4 = \\frac{1}{\\sqrt{2}}(0, 1, 0, -1)^T$.\n\nThe graph filter $H = f(L)$ is defined by the spectral functional calculus as $H = \\sum_{k=1}^4 f(\\lambda_k) u_k u_k^T$. An entry $H_{ij}$ of this matrix is given by $H_{ij} = \\sum_{k=1}^4 f(\\lambda_k) u_{ik} u_{jk}$, where $u_{ik}$ is the $i$-th component of the eigenvector $u_k$.\n\nWe need to evaluate the given spectral kernel function $f(\\lambda)$ at each eigenvalue:\n- For $\\lambda_1=0$: $0 \\in [0,1]$, so $f(0) = \\alpha$.\n- For $\\lambda_2=4$: $4 \\in (3,\\infty)$, so $f(4) = \\gamma$.\n- For $\\lambda_3=2$ and $\\lambda_4=2$: $2 \\in (1,3]$, so $f(2) = \\beta$.\n\nWe now compute the specific entry $H_{1,3}$:\n$$ H_{1,3} = f(\\lambda_1) u_{11} u_{31} + f(\\lambda_2) u_{12} u_{32} + f(\\lambda_3) u_{13} u_{33} + f(\\lambda_4) u_{14} u_{34} $$\nThe required eigenvector components are:\n- $u_1$: $(u_{11}, u_{31}) = (\\frac{1}{2}, \\frac{1}{2})$\n- $u_2$: $(u_{12}, u_{32}) = (\\frac{1}{2}, \\frac{1}{2})$\n- $u_3$: $(u_{13}, u_{33}) = (\\frac{1}{\\sqrt{2}}, -\\frac{1}{\\sqrt{2}})$\n- $u_4$: $(u_{14}, u_{34}) = (0, 0)$\nSubstituting these values into the expression for $H_{1,3}$:\n$$ H_{1,3} = f(0) \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + f(4) \\left(\\frac{1}{2}\\right)\\left(\\frac{1}{2}\\right) + f(2) \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(-\\frac{1}{\\sqrt{2}}\\right) + f(2) (0)(0) $$\n$$ H_{1,3} = \\alpha \\left(\\frac{1}{4}\\right) + \\gamma \\left(\\frac{1}{4}\\right) + \\beta \\left(-\\frac{1}{2}\\right) + 0 $$\n$$ H_{1,3} = \\frac{\\alpha}{4} + \\frac{\\gamma}{4} - \\frac{\\beta}{2} $$\nCombining the terms gives the final symbolic expression for $H_{1,3}$.\n$$ H_{1,3} = \\frac{\\alpha - 2\\beta + \\gamma}{4} $$\nThis result is exact and derived directly from the provided definitions and established theorems.", "answer": "$$\\boxed{\\frac{\\alpha - 2\\beta + \\gamma}{4}}$$", "id": "2874957"}, {"introduction": "In classical signal processing, a key property of a filter is shift-invariance. On graphs, this concept translates to an operator that commutes with the graph shift operator. This exercise sharpens our understanding of this crucial property by presenting a counterexample [@problem_id:2874976]. You will demonstrate that a simple, intuitive operator—scaling a signal by node degree—is a local operation but fails the test of shift-invariance, thereby clarifying the precise definition of a graph filter.", "problem": "Consider the following setup in Graph Signal Processing (GSP). Let the graph shift operator be the symmetric adjacency matrix of the undirected path graph on three nodes. That is, let the graph have nodes $\\{1,2,3\\}$ and edges $\\{(1,2),(2,3)\\}$, with shift operator $S \\in \\mathbb{R}^{3 \\times 3}$ given by\n$$\nS \\;=\\; \\begin{pmatrix}\n0 & 1 & 0 \\\\\n1 & 0 & 1 \\\\\n0 & 1 & 0\n\\end{pmatrix}.\n$$\nRecall that a linear operator $H:\\mathbb{R}^{3}\\to\\mathbb{R}^{3}$ is said to be $r$-hop local if there exists a nonnegative integer $r$ such that $H_{ij}=0$ for all node pairs $(i,j)$ whose shortest-path distance in the graph exceeds $r$, and that shift-invariance on this graph means $H$ commutes with $S$, i.e., $HS=SH$. Define the operator $H$ to be the node-degree scaling (degree matrix) on this graph:\n$$\nH \\;=\\; D \\;=\\; \\mathrm{diag}(d_{1},d_{2},d_{3}),\n$$\nwhere $d_{i}$ is the degree of node $i$ in the given graph.\n\nStarting from these definitions:\n- Show that $H$ is linear and $0$-hop local.\n- Verify that $H$ is not shift-invariant with respect to $S$ by explicitly computing the commutator $[H,S] \\triangleq HS - SH$ and showing it is nonzero.\n- Finally, compute the squared Frobenius norm of the commutator,\n$$\n\\|[H,S]\\|_{F}^{2} \\;=\\; \\sum_{i=1}^{3}\\sum_{j=1}^{3} \\left([H,S]_{ij}\\right)^{2},\n$$\nand report its value.\n\nYour final answer must be a single real number (no units, no additional symbols). No rounding is required.", "solution": "The problem statement is submitted for validation.\n\nFirst, the givens are extracted.\n- A graph is defined with node set $V = \\{1, 2, 3\\}$ and edge set $E = \\{(1,2), (2,3)\\}$.\n- The graph shift operator is the symmetric adjacency matrix $S \\in \\mathbb{R}^{3 \\times 3}$ given by:\n$$\nS = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\n- An operator $H:\\mathbb{R}^{3} \\to \\mathbb{R}^{3}$ is defined as $r$-hop local if $H_{ij}=0$ for all node pairs $(i,j)$ whose shortest-path distance in the graph exceeds a non-negative integer $r$.\n- An operator $H$ is defined as shift-invariant if it commutes with $S$, i.e., $HS = SH$.\n- The operator $H$ is defined as the degree matrix $D = \\mathrm{diag}(d_{1}, d_{2}, d_{3})$, where $d_{i}$ is the degree of node $i$.\n- The tasks are to:\n  1. Show that $H$ is a linear operator and is $0$-hop local.\n  2. Verify that $H$ is not shift-invariant by computing the commutator $[H,S] = HS - SH$ and showing it is non-zero.\n  3. Compute the squared Frobenius norm of the commutator, $\\|[H,S]\\|_{F}^{2} = \\sum_{i=1}^{3}\\sum_{j=1}^{3} ([H,S]_{ij})^{2}$.\n\nNow, the validation of the problem is performed. The problem is set within the standard framework of Graph Signal Processing. All definitions provided—shift operator, $r$-hop locality, shift-invariance, degree matrix, and Frobenius norm—are standard and mathematically precise. The problem is self-contained, providing all necessary information to perform the requested computations. There are no contradictions, ambiguities, or scientific inaccuracies. The problem is well-posed, objective, and scientifically grounded.\n\nVerdict: The problem is valid. The solution will now be presented.\n\nFirst, we determine the operator $H$, which is the degree matrix $D$. The degrees of the nodes in the path graph are:\n- Node $1$: connected only to node $2$, so its degree is $d_{1} = 1$.\n- Node $2$: connected to nodes $1$ and $3$, so its degree is $d_{2} = 2$.\n- Node $3$: connected only to node $2$, so its degree is $d_{3} = 1$.\nThus, the operator $H$ is the diagonal matrix:\n$$\nH = D = \\mathrm{diag}(1, 2, 1) = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n\nThe first task is to show that $H$ is linear and $0$-hop local.\n- **Linearity**: Any operator that can be represented by a matrix is a linear operator. For any vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^{3}$ and scalars $\\alpha, \\beta \\in \\mathbb{R}$, matrix multiplication is distributive and associative with scalar multiplication. That is, $H(\\alpha\\mathbf{x} + \\beta\\mathbf{y}) = D(\\alpha\\mathbf{x} + \\beta\\mathbf{y}) = \\alpha(D\\mathbf{x}) + \\beta(D\\mathbf{y}) = \\alpha H\\mathbf{x} + \\beta H\\mathbf{y}$. So, $H$ is linear.\n- **$0$-hop locality**: An operator is $0$-hop local if its corresponding matrix $H$ has $H_{ij} = 0$ for all pairs $(i,j)$ where the shortest-path distance $d_G(i,j) > 0$. The condition $d_G(i,j) > 0$ is equivalent to $i \\neq j$. The matrix $H=D$ is a diagonal matrix, meaning its off-diagonal entries are all zero: $H_{ij} = 0$ for all $i \\neq j$. This satisfies the definition of $0$-hop locality precisely.\n\nThe second task is to verify that $H$ is not shift-invariant by computing the commutator $[H,S] = HS - SH$. We have the matrices:\n$$\nH = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\quad \\text{and} \\quad S = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nWe compute the product $HS$:\n$$\nHS = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 1 & 0 \\\\ 2 & 0 & 2 \\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nNext, we compute the product $SH$:\n$$\nSH = \\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 0 & 2 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 2 & 0 \\end{pmatrix}\n$$\nNow we compute the commutator, $[H,S]$:\n$$\n[H,S] = HS - SH = \\begin{pmatrix} 0 & 1 & 0 \\\\ 2 & 0 & 2 \\\\ 0 & 1 & 0 \\end{pmatrix} - \\begin{pmatrix} 0 & 2 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 2 & 0 \\end{pmatrix} = \\begin{pmatrix} 0-0 & 1-2 & 0-0 \\\\ 2-1 & 0-0 & 2-1 \\\\ 0-0 & 1-2 & 0-0 \\end{pmatrix} = \\begin{pmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & -1 & 0 \\end{pmatrix}\n$$\nSince $[H,S]$ is not the zero matrix, $H$ and $S$ do not commute, and thus $H$ is not shift-invariant.\n\nThe third and final task is to compute the squared Frobenius norm of the commutator, $\\|[H,S]\\|_{F}^{2}$. The Frobenius norm is the square root of the sum of the absolute squares of the matrix elements. The squared Frobenius norm is simply the sum of the squares of the elements.\n$$\n[H,S] = \\begin{pmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & -1 & 0 \\end{pmatrix}\n$$\nThe squared Frobenius norm is calculated as:\n$$\n\\|[H,S]\\|_{F}^{2} = \\sum_{i=1}^{3}\\sum_{j=1}^{3} ([H,S]_{ij})^{2} = (0)^{2} + (-1)^{2} + (0)^{2} + (1)^{2} + (0)^{2} + (1)^{2} + (0)^{2} + (-1)^{2} + (0)^{2}\n$$\n$$\n\\|[H,S]\\|_{F}^{2} = 0 + 1 + 0 + 1 + 0 + 1 + 0 + 1 + 0 = 4\n$$\nThe result is a single real number, as required.", "answer": "$$\\boxed{4}$$", "id": "2874976"}, {"introduction": "Theoretical models are powerful, but their real-world utility often depends on their robustness to small changes. This exercise bridges the gap between abstract filter design and practical application by exploring filter sensitivity [@problem_id:2874967]. You will numerically simulate how a minor perturbation to a single edge weight in a network impacts the output of a low-pass graph filter, providing tangible insight into how local structural changes can have non-local effects on graph signals.", "problem": "You are given a fixed undirected weighted graph with $N=6$ nodes indexed by $\\{0,1,2,3,4,5\\}$ and a real-valued graph signal defined on its nodes. Let the adjacency matrix be $\\mathbf{A}\\in\\mathbb{R}^{6\\times 6}$ with the following nonzero symmetric weights:\n- $\\mathbf{A}_{0,1}=\\mathbf{A}_{1,0}=1.0$, $\\mathbf{A}_{1,2}=\\mathbf{A}_{2,1}=0.5$, $\\mathbf{A}_{2,3}=\\mathbf{A}_{3,2}=0.7$,\n- $\\mathbf{A}_{3,4}=\\mathbf{A}_{4,3}=0.9$, $\\mathbf{A}_{4,5}=\\mathbf{A}_{5,4}=0.6$, $\\mathbf{A}_{5,0}=\\mathbf{A}_{0,5}=0.8$,\n- $\\mathbf{A}_{0,2}=\\mathbf{A}_{2,0}=0.4$, $\\mathbf{A}_{1,3}=\\mathbf{A}_{3,1}=0.3$, $\\mathbf{A}_{2,4}=\\mathbf{A}_{4,2}=0.2$, $\\mathbf{A}_{3,5}=\\mathbf{A}_{5,3}=0.5$,\nand all other entries equal to $0$. The combinatorial graph Laplacian is $\\mathbf{L}=\\mathbf{D}-\\mathbf{A}$, where $\\mathbf{D}$ is the diagonal matrix of node degrees, $\\mathbf{D}_{n,n}=\\sum_{m=0}^{5}\\mathbf{A}_{n,m}$. The input graph signal is the fixed vector $\\mathbf{s}=[1.0,\\,0.5,\\,-0.5,\\,-1.0,\\,0.2,\\,0.8]^\\top\\in\\mathbb{R}^{6}$.\n\nConsider the linear time-invariant graph filter defined by the resolvent operator $\\mathbf{H}_\\alpha=(\\mathbf{I}+\\alpha\\,\\mathbf{L})^{-1}$ for a given smoothing parameter $\\alpha>0$. The filtered signal is $\\mathbf{y}=\\mathbf{H}_\\alpha\\,\\mathbf{s}$.\n\nA rank-one edge perturbation that changes the weight of an undirected edge between nodes $i$ and $j$ by an amount $\\delta\\in\\mathbb{R}$ modifies the Laplacian by\n$$\n\\Delta\\mathbf{L}=\\delta\\,\\mathbf{u}\\,\\mathbf{u}^\\top,\\quad \\text{where } \\mathbf{u}=\\mathbf{e}_i-\\mathbf{e}_j,\n$$\nand $\\mathbf{e}_k$ denotes the $k$-th canonical basis vector. The perturbed Laplacian is $\\mathbf{L}'=\\mathbf{L}+\\Delta\\mathbf{L}$, and the perturbed filter is $\\mathbf{H}'_\\alpha=(\\mathbf{I}+\\alpha\\,\\mathbf{L}')^{-1}$. The corresponding perturbed filtered signal is $\\mathbf{y}'=\\mathbf{H}'_\\alpha\\,\\mathbf{s}$. Define the change in the filtered output as $\\Delta\\mathbf{y}=\\mathbf{y}'-\\mathbf{y}$. You must:\n- Compute $\\mathbf{y}$ and $\\mathbf{y}'$ by solving the linear systems with $\\mathbf{I}+\\alpha\\,\\mathbf{L}$ and $\\mathbf{I}+\\alpha\\,\\mathbf{L}'$.\n- Quantify the global change by the Euclidean norm $\\|\\Delta\\mathbf{y}\\|_2$.\n- Identify the two nodes with the largest absolute entries of $\\Delta\\mathbf{y}$; order these two nodes by descending absolute change, breaking ties by the smaller node index.\n\nYour program must implement the above definitions from first principles of graph signal processing. Do not diagonalize the Laplacian explicitly; compute the filter action by solving the linear systems. Use zero-based node indexing.\n\nTest suite:\n- Case $1$: $\\alpha=0.9$, $(i,j)=(1,4)$, $\\delta=0.25$.\n- Case $2$: $\\alpha=0.9$, $(i,j)=(2,5)$, $\\delta=0.0$.\n- Case $3$: $\\alpha=2.0$, $(i,j)=(3,5)$, $\\delta=-0.3$.\n- Case $4$: $\\alpha=0.5$, $(i,j)=(0,4)$, $\\delta=0.15$.\n\nFor each case, output a list $[\\|\\Delta\\mathbf{y}\\|_2,\\,n_1,\\,n_2]$, where $n_1$ and $n_2$ are the two node indices as specified above. Round $\\|\\Delta\\mathbf{y}\\|_2$ to six decimal places.\n\nFinal output format:\n- Your program should produce a single line containing a comma-separated list of the four case results, enclosed in square brackets, with no whitespace. For example: \n- $[[v_1,n_{1,1},n_{1,2}],[v_2,n_{2,1},n_{2,2}],[v_3,n_{3,1},n_{3,2}],[v_4,n_{4,1},n_{4,2}]]$\nwhere each $v_k$ is the rounded value of $\\|\\Delta\\mathbf{y}\\|_2$ for case $k$.", "solution": "The problem statement is scientifically sound, self-contained, and well-posed. We may therefore proceed with its solution. The task is to analyze the sensitivity of a graph filter's output to a rank-one perturbation of an edge weight. This requires a systematic application of principles from graph signal processing and numerical linear algebra.\n\nThe first step is to construct the fundamental matrices describing the graph topology. The number of nodes is $N=6$. The adjacency matrix $\\mathbf{A} \\in \\mathbb{R}^{6 \\times 6}$ is constructed from the specified non-zero symmetric weights:\n$$\n\\mathbf{A} = \\begin{pmatrix}\n0 & 1.0 & 0.4 & 0 & 0 & 0.8 \\\\\n1.0 & 0 & 0.5 & 0.3 & 0 & 0 \\\\\n0.4 & 0.5 & 0 & 0.7 & 0.2 & 0 \\\\\n0 & 0.3 & 0.7 & 0 & 0.9 & 0.5 \\\\\n0 & 0 & 0.2 & 0.9 & 0 & 0.6 \\\\\n0.8 & 0 & 0 & 0.5 & 0.6 & 0\n\\end{pmatrix}\n$$\nThe degree matrix $\\mathbf{D}$ is a diagonal matrix where each diagonal element $\\mathbf{D}_{n,n}$ is the sum of weights of edges connected to node $n$, i.e., $\\mathbf{D}_{n,n} = \\sum_{m=0}^{5} \\mathbf{A}_{n,m}$. This yields:\n$$\n\\mathbf{D} = \\text{diag}(2.2, 1.8, 1.8, 2.4, 1.7, 1.9)\n$$\nThe combinatorial graph Laplacian $\\mathbf{L}$ is defined as $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$, resulting in:\n$$\n\\mathbf{L} = \\begin{pmatrix}\n2.2 & -1.0 & -0.4 & 0 & 0 & -0.8 \\\\\n-1.0 & 1.8 & -0.5 & -0.3 & 0 & 0 \\\\\n-0.4 & -0.5 & 1.8 & -0.7 & -0.2 & 0 \\\\\n0 & -0.3 & -0.7 & 2.4 & -0.9 & -0.5 \\\\\n0 & 0 & -0.2 & -0.9 & 1.7 & -0.6 \\\\\n-0.8 & 0 & 0 & -0.5 & -0.6 & 1.9\n\\end{pmatrix}\n$$\nThe input graph signal is the vector $\\mathbf{s}=[1.0,\\,0.5,\\,-0.5,\\,-1.0,\\,0.2,\\,0.8]^\\top$. For each test case defined by a parameter set $(\\alpha, (i,j), \\delta)$, we perform the following sequence of calculations.\n\nFirst, we compute the original filtered signal $\\mathbf{y}$. The filter is defined as the operator $\\mathbf{H}_\\alpha=(\\mathbf{I}+\\alpha\\,\\mathbf{L})^{-1}$. Applying this filter to the signal $\\mathbf{s}$ gives $\\mathbf{y} = (\\mathbf{I}+\\alpha\\,\\mathbf{L})^{-1} \\mathbf{s}$. As specified, instead of computing the inverse matrix, we solve the equivalent and numerically superior linear system of equations:\n$$\n(\\mathbf{I}+\\alpha\\,\\mathbf{L})\\mathbf{y} = \\mathbf{s}\n$$\nwhere $\\mathbf{I}$ is the $6 \\times 6$ identity matrix.\n\nNext, we introduce the perturbation. An edge weight change of $\\delta$ between nodes $i$ and $j$ modifies the Laplacian by $\\Delta\\mathbf{L} = \\delta\\,\\mathbf{u}\\,\\mathbf{u}^\\top$, where $\\mathbf{u} = \\mathbf{e}_i - \\mathbf{e}_j$ and $\\mathbf{e}_k$ is the $k$-th canonical basis vector. The matrix $\\mathbf{u}\\,\\mathbf{u}^\\top$ is a rank-one matrix with entries $(\\mathbf{u}\\,\\mathbf{u}^\\top)_{k,l} = u_k u_l$. This results in a matrix with four non-zero entries: $1$ at positions $(i,i)$ and $(j,j)$, and $-1$ at positions $(i,j)$ and $(j,i)$. The perturbed Laplacian is then $\\mathbf{L}' = \\mathbf{L} + \\Delta\\mathbf{L}$.\n\nWith the perturbed Laplacian $\\mathbf{L}'$, we compute the perturbed filtered signal $\\mathbf{y}'$. This is accomplished by solving a second linear system involving the perturbed filter operator $\\mathbf{H}'_\\alpha=(\\mathbf{I}+\\alpha\\,\\mathbf{L}')^{-1}$:\n$$\n(\\mathbf{I}+\\alpha\\,\\mathbf{L}')\\mathbf{y}' = \\mathbf{s}\n$$\n\nThe change in the filtered signal is the vector difference $\\Delta\\mathbf{y} = \\mathbf{y}' - \\mathbf{y}$. To quantify the global magnitude of this change, we compute its Euclidean norm, $\\|\\Delta\\mathbf{y}\\|_2 = \\sqrt{\\sum_{k=0}^{5} (\\Delta y_k)^2}$. This value is to be rounded to six decimal places.\n\nFinally, we identify the two nodes most affected by the perturbation. This requires finding the indices $n_1$ and $n_2$ corresponding to the two largest entries in the vector of absolute changes, $|\\Delta\\mathbf{y}|$. The nodes are ordered first by descending absolute change. Any ties in value are resolved by selecting the smaller node index first. This is achieved by sorting the node indices $k \\in \\{0, 1, \\dots, 5\\}$ based on the primary key $-|\\Delta y_k|$ and secondary key $k$. The first two indices in the sorted list are the required $n_1$ and $n_2$.\n\nThis procedure is repeated for each of the four test cases provided. For the special case where $\\delta=0$, it follows that $\\Delta\\mathbf{L}=\\mathbf{0}$, $\\mathbf{L}'=\\mathbf{L}$, $\\mathbf{y}'=\\mathbf{y}$, and thus $\\Delta\\mathbf{y}=\\mathbf{0}$. The norm is $0$, and the tie-breaking rule will determine the top two nodes as indices $0$ and $1$. The computational implementation will follow these steps directly.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the graph signal processing problem as defined.\n    1.  Constructs the graph Laplacian from the given adjacency matrix.\n    2.  For each test case, computes the original and perturbed filtered signals\n        by solving linear systems.\n    3.  Calculates the change in the filtered signal, its norm, and identifies\n        the two most affected nodes.\n    4.  Formats the output as a list of lists.\n    \"\"\"\n    \n    # Define the graph structure and signal\n    A = np.zeros((6, 6))\n    weights = {\n        (0, 1): 1.0, (1, 0): 1.0,\n        (1, 2): 0.5, (2, 1): 0.5,\n        (2, 3): 0.7, (3, 2): 0.7,\n        (3, 4): 0.9, (4, 3): 0.9,\n        (4, 5): 0.6, (5, 4): 0.6,\n        (5, 0): 0.8, (0, 5): 0.8,\n        (0, 2): 0.4, (2, 0): 0.4,\n        (1, 3): 0.3, (3, 1): 0.3,\n        (2, 4): 0.2, (4, 2): 0.2,\n        (3, 5): 0.5, (5, 3): 0.5,\n    }\n    for (i, j), w in weights.items():\n        A[i, j] = w\n    \n    D = np.diag(np.sum(A, axis=1))\n    L = D - A\n    \n    s = np.array([1.0, 0.5, -0.5, -1.0, 0.2, 0.8])\n    I = np.identity(6)\n    \n    test_cases = [\n        (0.9, (1, 4), 0.25),\n        (0.9, (2, 5), 0.0),\n        (2.0, (3, 5), -0.3),\n        (0.5, (0, 4), 0.15),\n    ]\n    \n    all_results = []\n    \n    for alpha, (i, j), delta in test_cases:\n        # 1. Compute original filtered signal y\n        M = I + alpha * L\n        y = np.linalg.solve(M, s)\n        \n        # 2. Compute perturbed Laplacian L' and filtered signal y'\n        u = np.zeros(6)\n        u[i] = 1.0\n        u[j] = -1.0\n        \n        delta_L = delta * np.outer(u, u)\n        L_prime = L + delta_L\n        \n        M_prime = I + alpha * L_prime\n        y_prime = np.linalg.solve(M_prime, s)\n        \n        # 3. Calculate the change delta_y and its norm\n        delta_y = y_prime - y\n        norm_delta_y = np.linalg.norm(delta_y)\n        \n        # 4. Find the two nodes with the largest absolute change\n        abs_delta_y = np.abs(delta_y)\n        node_indices = np.arange(6)\n        \n        # Sort by descending absolute change, then by ascending node index for ties\n        sorted_indices = sorted(node_indices, key=lambda k: (-abs_delta_y[k], k))\n        n1, n2 = sorted_indices[0], sorted_indices[1]\n        \n        # 5. Store the result for this case\n        result_string = f\"[{norm_delta_y:.6f},{n1},{n2}]\"\n        all_results.append(result_string)\n        \n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2874967"}]}