{"hands_on_practices": [{"introduction": "A Hidden Markov Model allows us to answer two fundamental questions: \"What is the most likely sequence of hidden states?\" and \"What is the overall probability of the observed data?\". This exercise [@problem_id:2875864] challenges you to apply the two core dynamic programming algorithms—Viterbi and Forward—that answer these respective questions. By numerically computing and comparing the probability of the single Viterbi path to the marginal likelihood of the observation sequence, you will gain a tangible sense of the crucial difference between maximizing over a single path and summing over all possible paths.", "problem": "Consider a discrete-time Hidden Markov Model (HMM) with two hidden states $s_1$ and $s_2$, an observation alphabet $\\mathcal{X} = \\{0,1\\}$, and the following parameters:\n- Initial distribution $\\pi$: $\\pi_1 = 0.55$, $\\pi_2 = 0.45$.\n- State transition matrix $A = [a_{ij}]$ with $a_{11} = 0.65$, $a_{12} = 0.35$, $a_{21} = 0.25$, $a_{22} = 0.75$.\n- Emission probabilities $b_i(x) = p(x \\mid s_i)$:\n  - For state $s_1$: $b_1(0) = 0.60$, $b_1(1) = 0.40$.\n  - For state $s_2$: $b_2(0) = 0.20$, $b_2(1) = 0.80$.\n\nYou observe the length-$4$ sequence $x_{1:4} = (1,0,1,1)$. Using only the fundamental definitions of a Hidden Markov Model (HMM) and the independence assumptions implied by the Markov property and conditional emission model (and without employing any scaling), do the following:\n- Construct the Viterbi trellis numerically for $x_{1:4}$ and backtrack to obtain the most likely hidden-state path and its probability (the Viterbi path probability).\n- Separately, compute the marginal likelihood $p(x_{1:4})$ by summing over all hidden-state paths via the forward recursion derived from the model’s foundational definitions.\n- Compute the ratio $R = \\dfrac{\\text{Viterbi path probability}}{p(x_{1:4})}$.\n\nReport only the value of $R$ as your final answer. Round your final answer to five significant figures. No units are required.", "solution": "We begin by validating the problem statement.\n\nStep 1: Extract Givens.\nThe problem provides the following parameters for a discrete-time Hidden Markov Model (HMM):\n- Hidden states: $s_1$, $s_2$.\n- Observation alphabet: $\\mathcal{X} = \\{0,1\\}$.\n- Initial distribution $\\pi$: $\\pi_1 = 0.55$, $\\pi_2 = 0.45$.\n- State transition matrix $A = [a_{ij}]$: $a_{11} = 0.65$, $a_{12} = 0.35$, $a_{21} = 0.25$, $a_{22} = 0.75$.\n- Emission probabilities $b_i(x) = p(x \\mid s_i)$:\n  - $b_1(0) = 0.60$, $b_1(1) = 0.40$.\n  - $b_2(0) = 0.20$, $b_2(1) = 0.80$.\n- Observation sequence: $x_{1:4} = (1,0,1,1)$.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded, well-posed, and objective. All parameters are provided for a standard HMM. The initial probabilities sum to $1$: $\\pi_1 + \\pi_2 = 0.55 + 0.45 = 1$. The transition probabilities for each state, representing the rows of matrix $A$, sum to $1$: $a_{11} + a_{12} = 0.65 + 0.35 = 1$ and $a_{21} + a_{22} = 0.25 + 0.75 = 1$. The emission probabilities for each state sum to $1$: $b_1(0) + b_1(1) = 0.60 + 0.40 = 1$ and $b_2(0) + b_2(1) = 0.20 + 0.80 = 1$. The problem is self-contained, consistent, and poses a standard set of computational tasks (Viterbi decoding, forward algorithm) for an HMM. It does not violate any of the invalidity criteria.\n\nStep 3: Verdict and Action.\nThe problem is valid. We proceed to the solution.\n\nThe solution requires three sequential computations: the Viterbi path probability for the given observation sequence, the marginal likelihood of the sequence, and the ratio of these two values.\n\nPart 1: Viterbi Path Probability\nThe Viterbi algorithm finds the most likely sequence of hidden states $q_{1:T} = (q_1, \\dots, q_T)$ for an observation sequence $x_{1:T} = (x_1, \\dots, x_T)$. It does this by finding the single state path with the maximum probability. Let $\\delta_t(i)$ be the maximum probability of any path of length $t$ that ends in state $s_i$ and generates the observations $x_{1:t}$.\nThe recursion is defined as:\n- Initialization ($t=1$): $\\delta_1(i) = \\pi_i b_i(x_1)$\n- Recursion ($t > 1$): $\\delta_t(j) = \\left( \\max_{i} [\\delta_{t-1}(i) a_{ij}] \\right) b_j(x_t)$\nWe apply this recursion to the observation sequence $x_{1:4} = (1,0,1,1)$.\n\nTime $t=1$, observation $x_1=1$:\n- $\\delta_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\delta_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\nTime $t=2$, observation $x_2=0$:\n- $\\delta_2(1) = \\max(\\delta_1(1)a_{11}, \\delta_1(2)a_{21}) \\times b_1(0) = \\max(0.22 \\times 0.65, 0.36 \\times 0.25) \\times 0.60 = \\max(0.143, 0.09) \\times 0.60 = 0.143 \\times 0.60 = 0.0858$\n- $\\delta_2(2) = \\max(\\delta_1(1)a_{12}, \\delta_1(2)a_{22}) \\times b_2(0) = \\max(0.22 \\times 0.35, 0.36 \\times 0.75) \\times 0.20 = \\max(0.077, 0.27) \\times 0.20 = 0.27 \\times 0.20 = 0.054$\n\nTime $t=3$, observation $x_3=1$:\n- $\\delta_3(1) = \\max(\\delta_2(1)a_{11}, \\delta_2(2)a_{21}) \\times b_1(1) = \\max(0.0858 \\times 0.65, 0.054 \\times 0.25) \\times 0.40 = \\max(0.05577, 0.0135) \\times 0.40 = 0.05577 \\times 0.40 = 0.022308$\n- $\\delta_3(2) = \\max(\\delta_2(1)a_{12}, \\delta_2(2)a_{22}) \\times b_2(1) = \\max(0.0858 \\times 0.35, 0.054 \\times 0.75) \\times 0.80 = \\max(0.03003, 0.0405) \\times 0.80 = 0.0405 \\times 0.80 = 0.0324$\n\nTime $t=4$, observation $x_4=1$:\n- $\\delta_4(1) = \\max(\\delta_3(1)a_{11}, \\delta_3(2)a_{21}) \\times b_1(1) = \\max(0.022308 \\times 0.65, 0.0324 \\times 0.25) \\times 0.40 = \\max(0.0145002, 0.0081) \\times 0.40 = 0.0145002 \\times 0.40 = 0.00580008$\n- $\\delta_4(2) = \\max(\\delta_3(1)a_{12}, \\delta_3(2)a_{22}) \\times b_2(1) = \\max(0.022308 \\times 0.35, 0.0324 \\times 0.75) \\times 0.80 = \\max(0.0078078, 0.0243) \\times 0.80 = 0.0243 \\times 0.80 = 0.01944$\n\nThe probability of the most likely path is the maximum value at the final time step:\n$$P(\\text{Viterbi path}) = \\max_i \\delta_4(i) = \\max(0.00580008, 0.01944) = 0.01944$$\n\nPart 2: Marginal Likelihood using Forward Recursion\nThe marginal likelihood $p(x_{1:T})$ is the sum of probabilities of all possible hidden-state paths that could generate the observation sequence. It is computed using the forward algorithm. Let $\\alpha_t(i) = p(x_{1:t}, q_t=s_i)$ be the forward variable, which is the joint probability of observing the first $t$ outputs and being in state $s_i$ at time $t$.\nThe recursion is defined as:\n- Initialization ($t=1$): $\\alpha_1(i) = \\pi_i b_i(x_1)$\n- Recursion ($t > 1$): $\\alpha_t(j) = \\left( \\sum_{i} \\alpha_{t-1}(i) a_{ij} \\right) b_j(x_t)$\n- Termination: $p(x_{1:T}) = \\sum_i \\alpha_T(i)$\n\nWe apply this recursion to the same sequence $x_{1:4} = (1,0,1,1)$.\n\nTime $t=1$, observation $x_1=1$:\n- $\\alpha_1(1) = \\pi_1 b_1(1) = 0.55 \\times 0.40 = 0.22$\n- $\\alpha_1(2) = \\pi_2 b_2(1) = 0.45 \\times 0.80 = 0.36$\n\nTime $t=2$, observation $x_2=0$:\n- $\\alpha_2(1) = (\\alpha_1(1)a_{11} + \\alpha_1(2)a_{21}) \\times b_1(0) = (0.22 \\times 0.65 + 0.36 \\times 0.25) \\times 0.60 = (0.143 + 0.09) \\times 0.60 = 0.233 \\times 0.60 = 0.1398$\n- $\\alpha_2(2) = (\\alpha_1(1)a_{12} + \\alpha_1(2)a_{22}) \\times b_2(0) = (0.22 \\times 0.35 + 0.36 \\times 0.75) \\times 0.20 = (0.077 + 0.27) \\times 0.20 = 0.347 \\times 0.20 = 0.0694$\n\nTime $t=3$, observation $x_3=1$:\n- $\\alpha_3(1) = (\\alpha_2(1)a_{11} + \\alpha_2(2)a_{21}) \\times b_1(1) = (0.1398 \\times 0.65 + 0.0694 \\times 0.25) \\times 0.40 = (0.09087 + 0.01735) \\times 0.40 = 0.10822 \\times 0.40 = 0.043288$\n- $\\alpha_3(2) = (\\alpha_2(1)a_{12} + \\alpha_2(2)a_{22}) \\times b_2(1) = (0.1398 \\times 0.35 + 0.0694 \\times 0.75) \\times 0.80 = (0.04893 + 0.05205) \\times 0.80 = 0.10098 \\times 0.80 = 0.080784$\n\nTime $t=4$, observation $x_4=1$:\n- $\\alpha_4(1) = (\\alpha_3(1)a_{11} + \\alpha_3(2)a_{21}) \\times b_1(1) = (0.043288 \\times 0.65 + 0.080784 \\times 0.25) \\times 0.40 = (0.0281372 + 0.020196) \\times 0.40 = 0.0483332 \\times 0.40 = 0.01933328$\n- $\\alpha_4(2) = (\\alpha_3(1)a_{12} + \\alpha_3(2)a_{22}) \\times b_2(1) = (0.043288 \\times 0.35 + 0.080784 \\times 0.75) \\times 0.80 = (0.0151508 + 0.060588) \\times 0.80 = 0.0757388 \\times 0.80 = 0.06059104$\n\nThe total marginal likelihood is the sum of the forward variables at the final time step:\n$$p(x_{1:4}) = \\sum_i \\alpha_4(i) = \\alpha_4(1) + \\alpha_4(2) = 0.01933328 + 0.06059104 = 0.07992432$$\n\nPart 3: Compute the Ratio $R$\nThe final step is to compute the ratio $R$ of the Viterbi path probability to the total marginal likelihood.\n$$R = \\frac{P(\\text{Viterbi path})}{p(x_{1:4})} = \\frac{0.01944}{0.07992432} \\approx 0.24322900$$\nRounding to five significant figures as required by the problem statement yields:\n$$R \\approx 0.24323$$\nThis ratio quantifies the dominance of the single most probable path relative to the total probability mass of all possible paths.", "answer": "$$\\boxed{0.24323}$$", "id": "2875864"}, {"introduction": "While inference on a known HMM is a foundational skill, the real power of these models comes from their ability to be learned directly from data. This practice [@problem_id:2875785] provides a detailed, hands-on walkthrough of a single iteration of the Baum-Welch algorithm, the cornerstone Expectation-Maximization (EM) procedure for HMM training. You will manually compute the forward ($\\alpha_t$) and backward ($\\beta_t$) variables in the E-step and use the resulting posterior probabilities to re-estimate model parameters in the M-step, demystifying the mechanics of this iterative learning process.", "problem": "A binary sensor in a discrete-time system is modeled by a two-state ($2$) discrete Hidden Markov Model (HMM). The two hidden states are denoted $S_1$ and $S_2$, and the observation alphabet is $\\{0,1\\}$. The HMM parameters are the initial state distribution $\\boldsymbol{\\pi}$, the state transition matrix $\\boldsymbol{A}$, and the observation (emission) probabilities $\\boldsymbol{B}$, where the conditional independence of emissions given the hidden state and the Markov property hold by definition. Specifically, the model is\n$$\n\\boldsymbol{\\pi} = \\begin{pmatrix}0.6 & 0.4\\end{pmatrix},\\quad\n\\boldsymbol{A} = \\begin{pmatrix}0.7 & 0.3\\\\ 0.4 & 0.6\\end{pmatrix},\\quad\n\\boldsymbol{B} =\n\\begin{pmatrix}\nP(O=0\\mid S_1) & P(O=1\\mid S_1)\\\\\nP(O=0\\mid S_2) & P(O=1\\mid S_2)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n0.5 & 0.5\\\\\n0.8 & 0.2\n\\end{pmatrix}.\n$$\nYou observe the length-$3$ sequence $\\boldsymbol{O}=(1,0,1)$ at times $t=1,2,3$.\n\nUsing only the foundational definitions of the discrete Hidden Markov Model (HMM), the forward-backward recursions derived from the Markov property and conditional independence, Bayes’ rule, and the standard Expectation-Maximization (EM) framework, perform one complete Baum–Welch EM iteration as follows:\n\n1. Compute the forward probabilities $\\alpha_t(i)=P(O_1,\\dots,O_t,X_t=S_i)$ and the backward probabilities $\\beta_t(i)=P(O_{t+1},\\dots,O_T\\mid X_t=S_i)$ for all $t\\in\\{1,2,3\\}$ and $i\\in\\{1,2\\}$, and the sequence likelihood $P(\\boldsymbol{O})$.\n\n2. From these, compute the state posteriors $\\gamma_t(i)=P(X_t=S_i\\mid \\boldsymbol{O})$ and the two-slice posteriors $\\xi_t(i,j)=P(X_t=S_i,X_{t+1}=S_j\\mid \\boldsymbol{O})$ for $t\\in\\{1,2\\}$ and $i,j\\in\\{1,2\\}$.\n\n3. Use the EM maximization step under the normalization constraints to obtain the reestimated parameters $\\boldsymbol{\\pi}'$, $\\boldsymbol{A}'$, and $\\boldsymbol{B}'$.\n\nReport only the reestimated transition probability from state $S_1$ to state $S_2$, denoted $a'_{12}$, as a single simplified fraction. Provide no units. Do not round; express the answer as a reduced fraction.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- A discrete Hidden Markov Model (HMM) with $N=2$ hidden states, $S_1$ and $S_2$.\n- Observation alphabet is $\\{0,1\\}$.\n- The length of the observation sequence is $T=3$.\n- The observation sequence is $\\boldsymbol{O}=(O_1, O_2, O_3) = (1,0,1)$.\n- The initial state distribution is $\\boldsymbol{\\pi} = \\begin{pmatrix} \\pi_1 & \\pi_2 \\end{pmatrix} = \\begin{pmatrix} 0.6 & 0.4 \\end{pmatrix}$.\n- The state transition probability matrix is $\\boldsymbol{A} = \\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix} = \\begin{pmatrix} 0.7 & 0.3\\\\ 0.4 & 0.6 \\end{pmatrix}$.\n- The observation (emission) probability matrix is $\\boldsymbol{B}$, where $b_j(k) = P(O_t=k \\mid X_t=S_j)$. Given as $\\boldsymbol{B} = \\begin{pmatrix} b_1(0) & b_1(1) \\\\ b_2(0) & b_2(1) \\end{pmatrix} = \\begin{pmatrix} 0.5 & 0.5\\\\ 0.8 & 0.2 \\end{pmatrix}$.\n- The task is to perform one iteration of the Baum-Welch algorithm to re-estimate the model parameters and report the single value $a'_{12}$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard application of the Baum-Welch algorithm for Hidden Markov Models, a cornerstone of signal processing and machine learning. It is scientifically and mathematically sound.\n- **Well-Posed:** The problem is well-posed. All necessary parameters ($\\boldsymbol{\\pi}, \\boldsymbol{A}, \\boldsymbol{B}$) and the observation sequence $\\boldsymbol{O}$ are provided. The objective is clearly stated. A unique solution for one iteration exists. The provided probability distributions are correctly normalized (rows of $\\boldsymbol{\\pi}$, $\\boldsymbol{A}$, and $\\boldsymbol{B}$ sum to $1$).\n- **Objective:** The problem is stated in objective, mathematical terms, free of ambiguity or subjective content.\n- **Completeness and Consistency:** The problem is self-contained and free of contradictions.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A solution will be derived.\n\nThe Baum-Welch algorithm is an instance of the Expectation-Maximization (EM) algorithm. One iteration consists of an Expectation (E) step and a Maximization (M) step.\n\n**E-Step: Calculation of Forward, Backward, and Posterior Probabilities**\n\nThe model parameters in fractional form are:\n$\\boldsymbol{\\pi} = \\begin{pmatrix} \\frac{3}{5} & \\frac{2}{5} \\end{pmatrix}$, $\\boldsymbol{A} = \\begin{pmatrix} \\frac{7}{10} & \\frac{3}{10}\\\\ \\frac{2}{5} & \\frac{3}{5} \\end{pmatrix}$, $\\boldsymbol{B} = \\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2}\\\\ \\frac{4}{5} & \\frac{1}{5} \\end{pmatrix}$.\nThe observation sequence is $\\boldsymbol{O}=(1,0,1)$.\n\n**1. Forward Probabilities $\\alpha_t(i) = P(O_1, \\dots, O_t, X_t=S_i \\mid \\boldsymbol{\\lambda})$**\nThe forward variable $\\alpha_t(i)$ is computed recursively.\n- **Initialization ($t=1$):** $\\alpha_1(i) = \\pi_i b_i(O_1)$. Here $O_1 = 1$.\n$$ \\alpha_1(1) = \\pi_1 b_1(1) = \\frac{3}{5} \\times \\frac{1}{2} = \\frac{3}{10} $$\n$$ \\alpha_1(2) = \\pi_2 b_2(1) = \\frac{2}{5} \\times \\frac{1}{5} = \\frac{2}{25} $$\n- **Recursion ($t=2$):** $\\alpha_2(j) = \\left[ \\sum_{i=1}^2 \\alpha_1(i) a_{ij} \\right] b_j(O_2)$. Here $O_2 = 0$.\n$$ \\alpha_2(1) = \\left[ \\alpha_1(1)a_{11} + \\alpha_1(2)a_{21} \\right] b_1(0) = \\left[ \\frac{3}{10}\\frac{7}{10} + \\frac{2}{25}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{21}{100} + \\frac{4}{125} \\right] \\frac{1}{2} = \\left[ \\frac{105+16}{500} \\right] \\frac{1}{2} = \\frac{121}{1000} $$\n$$ \\alpha_2(2) = \\left[ \\alpha_1(1)a_{12} + \\alpha_1(2)a_{22} \\right] b_2(0) = \\left[ \\frac{3}{10}\\frac{3}{10} + \\frac{2}{25}\\frac{3}{5} \\right] \\frac{4}{5} = \\left[ \\frac{9}{100} + \\frac{6}{125} \\right] \\frac{4}{5} = \\left[ \\frac{45+24}{500} \\right] \\frac{4}{5} = \\frac{69}{500}\\frac{4}{5} = \\frac{276}{2500} = \\frac{69}{625} $$\n- **Recursion ($t=3$):** $\\alpha_3(j) = \\left[ \\sum_{i=1}^2 \\alpha_2(i) a_{ij} \\right] b_j(O_3)$. Here $O_3 = 1$.\n$$ \\alpha_3(1) = \\left[ \\alpha_2(1)a_{11} + \\alpha_2(2)a_{21} \\right] b_1(1) = \\left[ \\frac{121}{1000}\\frac{7}{10} + \\frac{69}{625}\\frac{2}{5} \\right] \\frac{1}{2} = \\left[ \\frac{847}{10000} + \\frac{138}{3125} \\right] \\frac{1}{2} = \\left[ \\frac{4235+2208}{50000} \\right] \\frac{1}{2} = \\frac{6443}{100000} $$\n$$ \\alpha_3(2) = \\left[ \\alpha_2(1)a_{12} + \\alpha_2(2)a_{22} \\right] b_2(1) = \\left[ \\frac{121}{1000}\\frac{3}{10} + \\frac{69}{625}\\frac{3}{5} \\right] \\frac{1}{5} = \\left[ \\frac{363}{10000} + \\frac{207}{3125} \\right] \\frac{1}{5} = \\left[ \\frac{1815+3312}{50000} \\right] \\frac{1}{5} = \\frac{5127}{50000}\\frac{1}{5} = \\frac{5127}{250000} $$\n- **Probability of the sequence $P(\\boldsymbol{O})$:** This is the sum of the final forward variables.\n$$ P(\\boldsymbol{O}) = \\alpha_3(1) + \\alpha_3(2) = \\frac{6443}{100000} + \\frac{5127}{250000} = \\frac{32215+10254}{500000} = \\frac{42469}{500000} $$\n\n**2. Backward Probabilities $\\beta_t(i) = P(O_{t+1}, \\dots, O_T \\mid X_t=S_i, \\boldsymbol{\\lambda})$**\nThe backward variable $\\beta_t(i)$ is computed by a backward recursion.\n- **Initialization ($t=3$):**\n$$ \\beta_3(1) = 1, \\quad \\beta_3(2) = 1 $$\n- **Recursion ($t=2$):** $\\beta_2(i) = \\sum_{j=1}^2 a_{ij} b_j(O_3) \\beta_3(j)$. Here $O_3=1$.\n$$ \\beta_2(1) = a_{11}b_1(1)\\beta_3(1) + a_{12}b_2(1)\\beta_3(2) = \\frac{7}{10}\\frac{1}{2}(1) + \\frac{3}{10}\\frac{1}{5}(1) = \\frac{7}{20} + \\frac{3}{50} = \\frac{35+6}{100} = \\frac{41}{100} $$\n$$ \\beta_2(2) = a_{21}b_1(1)\\beta_3(1) + a_{22}b_2(1)\\beta_3(2) = \\frac{2}{5}\\frac{1}{2}(1) + \\frac{3}{5}\\frac{1}{5}(1) = \\frac{1}{5} + \\frac{3}{25} = \\frac{5+3}{25} = \\frac{8}{25} $$\n- **Recursion ($t=1$):** $\\beta_1(i) = \\sum_{j=1}^2 a_{ij} b_j(O_2) \\beta_2(j)$. Here $O_2=0$.\n$$ \\beta_1(1) = a_{11}b_1(0)\\beta_2(1) + a_{12}b_2(0)\\beta_2(2) = \\frac{7}{10}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{10}\\frac{4}{5}\\frac{8}{25} = \\frac{287}{2000} + \\frac{96}{1250} = \\frac{1435+768}{10000} = \\frac{2203}{10000} $$\n$$ \\beta_1(2) = a_{21}b_1(0)\\beta_2(1) + a_{22}b_2(0)\\beta_2(2) = \\frac{2}{5}\\frac{1}{2}\\frac{41}{100} + \\frac{3}{5}\\frac{4}{5}\\frac{8}{25} = \\frac{41}{500} + \\frac{96}{625} = \\frac{205+384}{2500} = \\frac{589}{2500} $$\nAs a consistency check, $P(\\boldsymbol{O})$ can also be computed at $t=1$:\n$$ P(\\boldsymbol{O}) = \\sum_{i=1}^2 \\alpha_1(i)\\beta_1(i) = \\frac{3}{10}\\frac{2203}{10000} + \\frac{2}{25}\\frac{589}{2500} = \\frac{6609}{100000} + \\frac{1178}{62500} = \\frac{33045+9424}{500000} = \\frac{42469}{500000} $$\nThe result matches, confirming the correctness of the forward and backward computations.\n\n**3. Posterior Probabilities**\nThe state posterior probability $\\gamma_t(i)$ and two-slice posterior $\\xi_t(i,j)$ are:\n$$ \\gamma_t(i) = P(X_t=S_i \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i)\\beta_t(i)}{P(\\boldsymbol{O})} $$\n$$ \\xi_t(i,j) = P(X_t=S_i, X_{t+1}=S_j \\mid \\boldsymbol{O}, \\boldsymbol{\\lambda}) = \\frac{\\alpha_t(i) a_{ij} b_j(O_{t+1}) \\beta_{t+1}(j)}{P(\\boldsymbol{O})} $$\n\n**M-Step: Re-estimation of Parameters**\nThe re-estimation formula for the transition probability $a'_{ij}$ is:\n$$ a'_{ij} = \\frac{\\text{Expected number of transitions from } S_i \\text{ to } S_j}{\\text{Expected number of transitions from } S_i} = \\frac{\\sum_{t=1}^{T-1} \\xi_t(i,j)}{\\sum_{t=1}^{T-1} \\gamma_t(i)} $$\nFor $a'_{12}$, with $T=3$:\n$$ a'_{12} = \\frac{\\xi_1(1,2) + \\xi_2(1,2)}{\\gamma_1(1) + \\gamma_2(1)} $$\nThe common denominator $P(\\boldsymbol{O})$ will cancel, so we can work with the numerators of $\\xi$ and $\\gamma$.\nLet $Num = (\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2)) + (\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2))$.\nLet $Den = (\\alpha_1(1) \\beta_1(1)) + (\\alpha_2(1) \\beta_2(1))$.\nThen $a'_{12} = \\frac{Num}{Den}$.\n\n- **Calculate the numerator sum:**\nTerm 1 ($t=1$): $\\alpha_1(1) a_{12} b_2(O_2) \\beta_2(2) = \\frac{3}{10} \\times \\frac{3}{10} \\times \\frac{4}{5} \\times \\frac{8}{25} = \\frac{288}{12500} = \\frac{72}{3125}$.\nTerm 2 ($t=2$): $\\alpha_2(1) a_{12} b_2(O_3) \\beta_3(2) = \\frac{121}{1000} \\times \\frac{3}{10} \\times \\frac{1}{5} \\times 1 = \\frac{363}{50000}$.\n$$ Num = \\frac{72}{3125} + \\frac{363}{50000} = \\frac{72 \\times 16 + 363}{50000} = \\frac{1152+363}{50000} = \\frac{1515}{50000} $$\n\n- **Calculate the denominator sum:**\nTerm 1 ($t=1$): $\\alpha_1(1) \\beta_1(1) = \\frac{3}{10} \\times \\frac{2203}{10000} = \\frac{6609}{100000}$.\nTerm 2 ($t=2$): $\\alpha_2(1) \\beta_2(1) = \\frac{121}{1000} \\times \\frac{41}{100} = \\frac{4961}{100000}$.\n$$ Den = \\frac{6609}{100000} + \\frac{4961}{100000} = \\frac{11570}{100000} = \\frac{1157}{10000} $$\n\n- **Calculate the final ratio for $a'_{12}$:**\n$$ a'_{12} = \\frac{Num}{Den} = \\frac{1515/50000}{1157/10000} = \\frac{1515}{50000} \\times \\frac{10000}{1157} = \\frac{1515}{5 \\times 1157} = \\frac{303}{1157} $$\nThe fraction is simplified by dividing numerator and denominator by $5$. To check if $\\frac{303}{1157}$ can be reduced further, we find their prime factors.\n$303 = 3 \\times 101$.\n$1157$ is not divisible by $3$ (sum of digits is $14$) or $101$.\n$1157 = 13 \\times 89$.\nSince there are no common prime factors, the fraction is irreducible.", "answer": "$$\\boxed{\\frac{303}{1157}}$$", "id": "2875785"}, {"introduction": "The task of decoding a hidden state sequence has important subtleties, as the \"best\" sequence can be defined in more than one way. This problem [@problem_id:2875854] illuminates the critical distinction between finding the single most probable path globally (Viterbi decoding) and constructing a path from the most probable state at each individual time step (posterior decoding). By working through a carefully constructed hypothetical scenario, you'll discover how these two different but valid optimization criteria can lead to different decoded sequences, deepening your understanding of sequence estimation.", "problem": "Consider a discrete-time Hidden Markov Model (HMM) with two hidden states $S_1$ and $S_2$ and discrete observation alphabet $\\{x,y\\}$. The model is specified by the initial distribution $\\boldsymbol{\\pi}$, the state transition matrix $A$, and the emission probabilities $B$. By the Markov property and conditional independence of emissions, the joint distribution of a hidden path $z_{1:T}=(z_1,\\dots,z_T)$ and observations $o_{1:T}=(o_1,\\dots,o_T)$ factors as\n$$\np(z_{1:T},o_{1:T}) \\;=\\; \\pi_{z_1}\\, b_{z_1}(o_1)\\, \\prod_{t=2}^{T} a_{z_{t-1},z_t}\\, b_{z_t}(o_t),\n$$\nwhere $a_{i,j}=\\mathbb{P}(z_t=S_j\\mid z_{t-1}=S_i)$ and $b_i(o)=\\mathbb{P}(o_t=o\\mid z_t=S_i)$. The Viterbi decoding is a maximum a posteriori sequence estimator of the hidden trajectory, while posterior decoding chooses, at each time $t$, a state that maximizes the marginal posterior of $z_t$ given the entire observation sequence, which can be obtained via the forward-backward recursions used in the expectation step of the Baum–Welch estimation algorithm.\n\nYou are given the following model parameters:\n- Initial distribution: $\\boldsymbol{\\pi}=[\\pi_{S_1},\\pi_{S_2}] = [\\,0.4,\\,0.6\\,]$.\n- Transition matrix:\n$$\nA=\\begin{bmatrix}\na_{11} & a_{12}\\\\\na_{21} & a_{22}\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0.99 & 0.01\\\\\n0.01 & 0.99\n\\end{bmatrix}.\n$$\n- Emissions:\n$$\nb_{S_1}(x)=0.99,\\quad b_{S_1}(y)=0.01,\\qquad b_{S_2}(x)=0.01,\\quad b_{S_2}(y)=0.99.\n$$\nFor the observation sequence of length $T=2$, $o_{1:2}=(x,y)$, select the option that correctly and precisely distinguishes Viterbi decoding from posterior decoding and correctly identifies the two decoded state sequences for this example.\n\nA. Viterbi decoding finds the most probable entire hidden trajectory given the sequence of observations, while posterior decoding selects, at each time index, the state with the largest marginal posterior given the full sequence. For $o_{1:2}=(x,y)$ under the specified model, Viterbi returns $(S_2,S_2)$, whereas posterior decoding returns $(S_1,S_2)$.\n\nB. Viterbi decoding and posterior decoding optimize the same criterion and therefore always agree. For $o_{1:2}=(x,y)$, both return $(S_2,S_2)$.\n\nC. Posterior decoding maximizes the posterior of the entire hidden trajectory, while Viterbi decoding maximizes the marginal posterior at each time. For $o_{1:2}=(x,y)$, Viterbi returns $(S_1,S_2)$, whereas posterior decoding returns $(S_2,S_2)$.\n\nD. Viterbi decoding finds the most probable entire hidden trajectory and posterior decoding the per-time maximizers, but for $o_{1:2}=(x,y)$, Viterbi returns $(S_1,S_1)$ and posterior decoding returns $(S_1,S_2)$.", "solution": "The problem statement is subjected to validation.\n\n### Step 1: Extract Givens\n- **Model Type**: Discrete-time Hidden Markov Model (HMM).\n- **Hidden States**: $S_1$, $S_2$.\n- **Observation Alphabet**: $\\{x, y\\}$.\n- **Model Parameters**:\n    - Initial distribution: $\\boldsymbol{\\pi} = [\\pi_{S_1}, \\pi_{S_2}] = [0.4, 0.6]$.\n    - State transition matrix:\n    $$\n    A = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{bmatrix} = \\begin{bmatrix} 0.99 & 0.01 \\\\ 0.01 & 0.99 \\end{bmatrix}.\n    $$\n    - Emission probabilities:\n    $b_{S_1}(x) = 0.99$, $b_{S_1}(y) = 0.01$.\n    $b_{S_2}(x) = 0.01$, $b_{S_2}(y) = 0.99$.\n- **Observation Sequence**: $o_{1:2} = (o_1, o_2) = (x, y)$, with length $T=2$.\n- **Decoding Definitions**:\n    - **Viterbi decoding**: Finds the most probable entire hidden trajectory, i.e., $\\arg\\max_{z_{1:T}} p(z_{1:T} | o_{1:T})$.\n    - **Posterior decoding**: Selects the state that maximizes the marginal posterior at each time $t$, i.e., $z_t^* = \\arg\\max_{z_t} p(z_t | o_{1:T})$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is based on the standard theory of Hidden Markov Models, a core topic in signal processing, statistics, and machine learning. All definitions and formulas are standard and correct.\n2.  **Well-Posed**: The model is fully specified. All necessary parameters ($\\boldsymbol{\\pi}, A, B$) and the observation sequence are provided. The task is to apply two well-defined algorithms, Viterbi and posterior decoding, to this specific instance. A unique solution for each decoding method exists.\n3.  **Objective**: The problem is stated with precise mathematical and numerical definitions, free from ambiguity or subjective interpretation.\n4.  **No Flaws**: The problem does not violate any scientific principles. The probabilities are non-negative and sum to one where required (rows of $A$, emissions from each state). The setup is complete, consistent, and scientifically sound.\n\n### Step 3: Verdict and Action\nThe problem is valid. A rigorous solution will be derived.\n\n### Solution Derivation\n\nThe problem requires us to compute the results of two different decoding methods for the given HMM and observation sequence $o_{1:2}=(x,y)$.\n\n**1. Viterbi Decoding**\n\nViterbi decoding finds the single most probable sequence of hidden states $z_{1:2}^* = (z_1^*, z_2^*)$ that maximizes the joint probability $p(z_{1:2}, o_{1:2})$. This is equivalent to maximizing $p(z_{1:2}|o_{1:2})$, as $p(o_{1:2})$ is a constant factor for all paths. The formula for the joint probability for a sequence of length $T=2$ is:\n$$p(z_1, z_2, o_1, o_2) = \\pi_{z_1} b_{z_1}(o_1) a_{z_1, z_2} b_{z_2}(o_2)$$\nWe must compute this value for all four possible paths $z_{1:2} \\in \\{(S_1,S_1), (S_1,S_2), (S_2,S_1), (S_2,S_2)\\}$, given $o_1=x$ and $o_2=y$.\n\n-   Path $z_{1:2} = (S_1, S_1)$:\n    $p(S_1, S_1, x, y) = \\pi_{S_1} b_{S_1}(x) a_{11} b_{S_1}(y) = (0.4)(0.99)(0.99)(0.01) = 0.0039204$.\n\n-   Path $z_{1:2} = (S_1, S_2)$:\n    $p(S_1, S_2, x, y) = \\pi_{S_1} b_{S_1}(x) a_{12} b_{S_2}(y) = (0.4)(0.99)(0.01)(0.99) = 0.0039204$.\n\n-   Path $z_{1:2} = (S_2, S_1)$:\n    $p(S_2, S_1, x, y) = \\pi_{S_2} b_{S_2}(x) a_{21} b_{S_1}(y) = (0.6)(0.01)(0.01)(0.01) = 0.0000006$.\n\n-   Path $z_{1:2} = (S_2, S_2)$:\n    $p(S_2, S_2, x, y) = \\pi_{S_2} b_{S_2}(x) a_{22} b_{S_2}(y) = (0.6)(0.01)(0.99)(0.99) = 0.0058806$.\n\nComparing the probabilities:\n$p(S_2, S_2, x, y) = 0.0058806$ is the maximum value.\nTherefore, the Viterbi decoding result is the path $(S_2, S_2)$.\n\n**2. Posterior Decoding**\n\nPosterior decoding finds the sequence of states $(z_1^*, z_2^*)$ where each state $z_t^*$ is the individually most probable state at time $t$, given the entire observation sequence.\n$$z_t^* = \\arg\\max_{z_t \\in \\{S_1, S_2\\}} p(z_t | o_1, o_2)$$\nTo find this, we must compute the marginal posterior probabilities $p(z_t=S_i | o_1, o_2) = \\frac{p(z_t=S_i, o_1, o_2)}{p(o_1, o_2)}$.\n\nFirst, we compute the total probability of the observation sequence, $p(o_1, o_2)$, by summing the joint probabilities of all possible paths:\n$$p(x, y) = \\sum_{z_1, z_2} p(z_1, z_2, x, y) = 0.0039204 + 0.0039204 + 0.0000006 + 0.0058806 = 0.013722$$\n\nNow, we compute the marginal posteriors for each time step.\n\n-   For $t=1$:\n    We need to compare $p(z_1=S_1 | x, y)$ and $p(z_1=S_2 | x, y)$.\n    The joint probability $p(z_1=S_1, x, y)$ is the sum over all paths starting with $S_1$:\n    $p(z_1=S_1, x, y) = p(S_1, S_1, x, y) + p(S_1, S_2, x, y) = 0.0039204 + 0.0039204 = 0.0078408$.\n    The joint probability $p(z_1=S_2, x, y)$ is the sum over all paths starting with $S_2$:\n    $p(z_1=S_2, x, y) = p(S_2, S_1, x, y) + p(S_2, S_2, x, y) = 0.0000006 + 0.0058806 = 0.0058812$.\n    Since $p(z_1=S_1, x, y) > p(z_1=S_2, x, y)$, the corresponding posterior probability is also greater. So, $z_1^* = S_1$.\n\n-   For $t=2$:\n    We need to compare $p(z_2=S_1 | x, y)$ and $p(z_2=S_2 | x, y)$.\n    The joint probability $p(z_2=S_1, x, y)$ is the sum over all paths ending with $S_1$:\n    $p(z_2=S_1, x, y) = p(S_1, S_1, x, y) + p(S_2, S_1, x, y) = 0.0039204 + 0.0000006 = 0.003921$.\n    The joint probability $p(z_2=S_2, x, y)$ is the sum over all paths ending with $S_2$:\n    $p(z_2=S_2, x, y) = p(S_1, S_2, x, y) + p(S_2, S_2, x, y) = 0.0039204 + 0.0058806 = 0.009801$.\n    Since $p(z_2=S_2, x, y) > p(z_2=S_1, x, y)$, the corresponding posterior probability is also greater. So, $z_2^* = S_2$.\n\nTherefore, the posterior decoding result is the path $(S_1, S_2)$.\n\n### Option-by-Option Analysis\n\n-   **A.** This option correctly states the definitions: Viterbi finds the most probable sequence, while posterior decoding finds the sequence of state-wise maximizers. It also correctly reports the calculated sequences: Viterbi returns $(S_2, S_2)$ and posterior decoding returns $(S_1, S_2)$.\n    **Verdict: Correct.**\n\n-   **B.** This option incorrectly claims that the two decoding methods optimize the same criterion and always agree. Our calculation provides a direct counterexample. It also incorrectly states that both methods return $(S_2, S_2)$.\n    **Verdict: Incorrect.**\n\n-   **C.** This option incorrectly swaps the definitions of Viterbi and posterior decoding. It also incorrectly reports the results for both methods.\n    **Verdict: Incorrect.**\n\n-   **D.** This option provides a correct description of the two methods but incorrectly reports the Viterbi decoding result as $(S_1, S_1)$. Although it correctly identifies the posterior decoding result, the error in the Viterbi result invalidates the option as a whole.\n    **Verdict: Incorrect.**\n\nThe analysis confirms that only option A is entirely correct in its definitions and calculations.", "answer": "$$\\boxed{A}$$", "id": "2875854"}]}