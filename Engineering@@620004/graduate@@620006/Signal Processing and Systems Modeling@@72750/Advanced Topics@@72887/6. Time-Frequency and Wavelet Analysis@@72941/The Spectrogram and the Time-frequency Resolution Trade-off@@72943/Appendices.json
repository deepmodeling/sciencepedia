{"hands_on_practices": [{"introduction": "Understanding the time-frequency resolution trade-off in practice begins with a crucial distinction: the difference between the sampling grid of the Discrete Fourier Transform (DFT) and the true spectral resolution of the analysis. This exercise [@problem_id:2914032] challenges a common misconception that increasing the Fast Fourier Transform (FFT) size through zero-padding can improve our ability to distinguish closely spaced frequencies. By working through a concrete scenario, you will solidify your understanding that spectral resolution is fundamentally governed by the analysis window's length and shape, not the density of the FFT grid.", "problem": "A discrete-time signal is sampled at sampling rate $F_{s} = 48000$ Hz. A spectrogram based on the Short-Time Fourier Transform (STFT) is computed using a Hann window of length $L = 1024$ samples, an $N = 8192$-point Fast Fourier Transform (FFT) per frame (i.e., zero-padding with $N - L$ zeros), and sufficiently large overlap so that windowing dominates time resolution. Consider a frame that contains two equal-amplitude pure tones at $f_{1} = 10000$ Hz and $f_{2} = 10050$ Hz. \n\nUsing only fundamental definitions about the Discrete Fourier Transform (DFT) frequency sampling grid and the effect of finite windowing on spectral concentration, answer the following:\n\n1) Compute the discrete frequency bin spacing of the $N$-point DFT used in each STFT frame.\n\n2) Evaluate the following statements about frequency resolution and the time-frequency trade-off. Select all that are correct.\n\nA. The discrete frequency bin spacing equals $F_{s}/N$, which here evaluates numerically to $5.859375$ Hz.\n\nB. Because the bin spacing is smaller than the $50$ Hz separation of the tones, the two tones will be clearly resolved in the Hann-window spectrogram with zero-padding.\n\nC. For a Hann window of length $L$, the first spectral zero of the window’s mainlobe occurs at approximately $\\pm 2 F_{s}/L$ from the tone frequency, so the smallest practically resolvable separation for equal-amplitude tones is on the order of $2 F_{s}/L$. With $L = 1024$ and $F_{s} = 48000$, this is about $93.75$ Hz, implying the $50$ Hz-separated tones will not be resolved despite zero-padding.\n\nD. Increasing $N$ while keeping $L$ fixed reduces the mainlobe width of the window’s spectrum and therefore increases the true spectral resolution.\n\nE. Increasing $L$ (with the window type fixed) improves frequency resolution while worsening time resolution, because the effective temporal support $T = L/F_{s}$ increases.\n\nF. The discrete frequency bin spacing equals the Equivalent Noise Bandwidth (ENBW) of the window for any $L$ and any window type.\n\nG. If instead of a Hann window one uses a rectangular window with the same $L$, the Rayleigh separation (first-zero criterion) is approximately $F_{s}/L \\approx 46.875$ Hz, so two equal-amplitude tones separated by $50$ Hz are near the Rayleigh limit and may be marginally resolvable in noise-free conditions.", "solution": "The problem statement is scientifically sound, well-posed, and contains all necessary information to proceed with a rigorous analysis. We shall first address the computation of the frequency bin spacing and then evaluate each statement in turn.\n\nThe analysis is based on the following givens:\n- Sampling rate: $F_{s} = 48000$ Hz\n- Hann window length: $L = 1024$ samples\n- FFT size: $N = 8192$ points\n- Tone frequencies: $f_{1} = 10000$ Hz and $f_{2} = 10050$ Hz, with a separation of $\\Delta f = f_{2} - f_{1} = 50$ Hz.\n\n**Part 1: Computation of Discrete Frequency Bin Spacing**\n\nThe Discrete Fourier Transform (DFT) of length $N$ provides samples of the frequency spectrum over the range from $0$ up to (but not including) the sampling frequency $F_{s}$. The frequency axis is divided into $N$ equally spaced points, known as frequency bins. The spacing, or resolution, of this DFT grid, which we denote as $\\Delta f_{bin}$, is given by the fundamental formula:\n$$ \\Delta f_{bin} = \\frac{F_{s}}{N} $$\nSubstituting the given values:\n$$ \\Delta f_{bin} = \\frac{48000 \\text{ Hz}}{8192} = 5.859375 \\text{ Hz} $$\nThis value represents the distance between adjacent frequency samples computed by the Fast Fourier Transform (FFT).\n\n**Part 2: Evaluation of Statements**\n\nWe will now evaluate each statement based on the principles of digital signal processing.\n\n**A. The discrete frequency bin spacing equals $F_{s}/N$, which here evaluates numerically to $5.859375$ Hz.**\nThis statement is a direct application of the definition of the DFT frequency grid. As calculated above, the formula $\\Delta f_{bin} = F_{s}/N$ is correct, and the numerical evaluation $\\frac{48000}{8192} = 5.859375 \\text{ Hz}$ is also correct.\n**Verdict: Correct.**\n\n**B. Because the bin spacing is smaller than the $50$ Hz separation of the tones, the two tones will be clearly resolved in the Hann-window spectrogram with zero-padding.**\nThis statement reveals a common but critical misunderstanding. The ability to resolve two closely spaced frequencies is determined by the **mainlobe width of the window function's spectrum**, which is in turn determined by the window's type and its length $L$. The DFT bin spacing $\\Delta f_{bin}$ only determines the sampling density of the resulting spectrum. Using a large $N$ (zero-padding) provides a finely interpolated view of the spectrum dictated by the window, but it does not intrinsically improve the \"true\" resolution. The condition $\\Delta f > \\Delta f_{bin}$ is necessary but far from sufficient for resolution.\n**Verdict: Incorrect.**\n\n**C. For a Hann window of length $L$, the first spectral zero of the window’s mainlobe occurs at approximately $\\pm 2 F_{s}/L$ from the tone frequency, so the smallest practically resolvable separation for equal-amplitude tones is on the order of $2 F_{s}/L$. With $L = 1024$ and $F_{s} = 48000$, this is about $93.75$ Hz, implying the $50$ Hz-separated tones will not be resolved despite zero-padding.**\nThe resolution limit is dictated by the window's properties. For a Hann window of length $L$, the mainlobe is wider than that of a rectangular window. The first zeros of its spectral response are located at a frequency offset of $\\pm 2/L$ cycles/sample from the center frequency. In Hertz, this corresponds to a frequency of $\\Delta f_{res} = \\frac{2 F_{s}}{L}$. This value represents the Rayleigh resolution criterion for a Hann window.\nLet us compute this value:\n$$ \\Delta f_{res} = \\frac{2 \\times 48000 \\text{ Hz}}{1024} = \\frac{96000}{1024} \\text{ Hz} = 93.75 \\text{ Hz} $$\nThe frequency separation of the two tones is $\\Delta f = 50$ Hz. Since $\\Delta f < \\Delta f_{res}$ ($50 \\text{ Hz} < 93.75 \\text{ Hz}$), the mainlobes of the two tones will overlap to such a degree that they merge into a single, broader peak. They will not be resolved into two distinct peaks. The statement correctly concludes this and correctly notes that zero-padding does not alter this fact.\n**Verdict: Correct.**\n\n**D. Increasing $N$ while keeping $L$ fixed reduces the mainlobe width of the window’s spectrum and therefore increases the true spectral resolution.**\nThis is factually incorrect. The spectral characteristics, including the mainlobe width, are determined by the window function $w[n]$ and its length $L$. The operation of increasing the FFT size $N$ beyond $L$ is known as zero-padding. Zero-padding is equivalent to interpolating between the existing points of the underlying Discrete-Time Fourier Transform (DTFT) of the windowed signal segment. It does not change the shape or width of the lobes of this DTFT. Therefore, increasing $N$ does not improve true spectral resolution.\n**Verdict: Incorrect.**\n\n**E. Increasing $L$ (with the window type fixed) improves frequency resolution while worsening time resolution, because the effective temporal support $T = L/F_{s}$ increases.**\nThis statement correctly describes the fundamental time-frequency uncertainty principle as it applies to the STFT.\n- **Frequency Resolution**: The width of the window's mainlobe is inversely proportional to its length $L$. For example, for a Hann window, the resolution is on the order of $2F_s/L$. Increasing $L$ makes this value smaller, meaning finer frequency details can be resolved.\n- **Time Resolution**: The STFT analysis effectively localizes a spectral estimate within a time interval of duration $T = L/F_{s}$. A larger $L$ means a longer time interval, thus smearing out temporal events over a wider duration and worsening the ability to pinpoint when a frequency event occurs.\nThe statement is a precise articulation of this trade-off.\n**Verdict: Correct.**\n\n**F. The discrete frequency bin spacing equals the Equivalent Noise Bandwidth (ENBW) of the window for any $L$ and any window type.**\nThis is incorrect. The discrete frequency bin spacing is $\\Delta f_{bin} = F_{s}/N$. The Equivalent Noise Bandwidth (ENBW) is a property of the window of length $L$, not the FFT size $N$. The ENBW in Hz is proportional to the resolution bandwidth $F_s/L$. For a Hann window, the ENBW is approximately $1.5 \\times (F_s/L)$. This is clearly not equal to the bin spacing $F_s/N$. The claim that this holds for \"any\" window type is false.\n**Verdict: Incorrect.**\n\n**G. If instead of a Hann window one uses a rectangular window with the same $L$, the Rayleigh separation (first-zero criterion) is approximately $F_{s}/L \\approx 46.875$ Hz, so two equal-amplitude tones separated by $50$ Hz are near the Rayleigh limit and may be marginally resolvable in noise-free conditions.**\nFor a rectangular window of length $L$, the mainlobe is narrower than for a Hann window. The first zero of its spectrum (a Dirichlet kernel) is at a frequency offset of $1/L$ cycles/sample, which corresponds to a frequency of $\\Delta f_{res} = F_{s}/L$ in Hz. This is the Rayleigh criterion for a rectangular window.\nLet us compute this value:\n$$ \\Delta f_{res} = \\frac{48000 \\text{ Hz}}{1024} = 46.875 \\text{ Hz} $$\nThe separation of the tones is $\\Delta f = 50$ Hz. Since $\\Delta f > \\Delta f_{res}$ ($50 \\text{ Hz} > 46.875 \\text{ Hz}$), the peak of one tone's spectral response falls just beyond the first null of the other's. This condition allows for the two tones to be distinguished as two separate peaks with a visible dip between them, hence they are \"marginally resolvable.\" The statement is accurate in its calculation and conclusion.\n**Verdict: Correct.**", "answer": "$$\\boxed{ACEG}$$", "id": "2914032"}, {"introduction": "Having established that the analysis window governs resolution, we now take a more critical look at how we quantify this resolution mathematically. This practice [@problem_id:2914043] invites you to compute the variance-based time and frequency spreads for the canonical rectangular window, a task that reveals a surprising and insightful result. By demonstrating that the frequency variance is infinite, this exercise highlights why variance can be a misleading metric for windows with strong spectral sidelobes and motivates the need for more robust, practical measures of resolution like main-lobe width.", "problem": "Consider the rectangular analysis window used in the Short-Time Fourier Transform (STFT). Let the window be\n$$\ng(t) \\triangleq \\begin{cases}\n\\frac{1}{\\sqrt{T}}, & |t|\\le \\frac{T}{2},\\\\\n0,& \\text{otherwise},\n\\end{cases}\n$$\nwith duration parameter $T>0$ measured in seconds, so that $\\int_{-\\infty}^{\\infty} |g(t)|^{2}\\,dt = 1$. Adopt the Fourier transform convention\n$$\nG(f) \\triangleq \\int_{-\\infty}^{\\infty} g(t)\\,\\exp\\!\\big(-j\\,2\\pi f t\\big)\\,dt,\n$$\nwith $f$ in hertz, for which Parseval’s theorem reads $\\int_{-\\infty}^{\\infty} |g(t)|^{2}\\,dt=\\int_{-\\infty}^{\\infty} |G(f)|^{2}\\,df$.\n\nUsing only these definitions and fundamental properties of integrable functions and the Fourier transform (no pre-stated closed-form uncertainty formulas), do the following:\n\n1. Compute the exact time mean $\\mu_{t}$ and the variance-based time spread\n$$\n\\sigma_{t}^{2} \\triangleq \\int_{-\\infty}^{\\infty} (t-\\mu_{t})^{2}\\,|g(t)|^{2}\\,dt.\n$$\n\n2. Compute the exact frequency mean $\\mu_{f}$ and assess the finiteness of the variance-based frequency spread\n$$\n\\sigma_{f}^{2} \\triangleq \\int_{-\\infty}^{\\infty} (f-\\mu_{f})^{2}\\,|G(f)|^{2}\\,df.\n$$\nIf it is finite, derive its exact value; if it is not finite, justify precisely why it diverges.\n\n3. Briefly explain why variance-based spreads can be misleading for strongly sidelobed windows such as the rectangular window when interpreting spectrogram time-frequency resolution, and name at least one robust alternative metric for frequency resolution that remains meaningful for such windows.\n\nFor the purposes of grading, report only the exact expression you obtained for the time variance $\\sigma_{t}^{2}$ as your final answer. Express the final answer in seconds squared, and do not round; provide an exact expression in terms of $T$.", "solution": "The problem as stated is subjected to validation before a solution is attempted.\n\nStep 1: Extract Givens\n-   Rectangular window function: $g(t) \\triangleq \\begin{cases} \\frac{1}{\\sqrt{T}}, & |t|\\le \\frac{T}{2},\\\\ 0,& \\text{otherwise}, \\end{cases}$\n-   Duration parameter: $T > 0$ seconds.\n-   Normalization: $\\int_{-\\infty}^{\\infty} |g(t)|^{2}\\,dt = 1$.\n-   Fourier transform convention: $G(f) \\triangleq \\int_{-\\infty}^{\\infty} g(t)\\,\\exp(-j\\,2\\pi f t)\\,dt$.\n-   Parseval’s theorem: $\\int_{-\\infty}^{\\infty} |g(t)|^{2}\\,dt=\\int_{-\\infty}^{\\infty} |G(f)|^{2}\\,df$.\n-   Time mean $\\mu_{t}$ and time variance $\\sigma_{t}^{2} \\triangleq \\int_{-\\infty}^{\\infty} (t-\\mu_{t})^{2}\\,|g(t)|^{2}\\,dt$.\n-   Frequency mean $\\mu_{f}$ and frequency variance $\\sigma_{f}^{2} \\triangleq \\int_{-\\infty}^{\\infty} (f-\\mu_{f})^{2}\\,|G(f)|^{2}\\,df$.\n\nStep 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, rooted in the fundamental principles of signal processing and Fourier analysis. The definitions provided for the window, its transform, and its statistical moments are standard. The problem is well-posed, with all necessary information supplied to perform the required calculations. The normalization condition is consistent with the window definition, as $\\int_{-T/2}^{T/2} |\\frac{1}{\\sqrt{T}}|^2 dt = \\frac{1}{T} \\int_{-T/2}^{T/2} dt = \\frac{1}{T}[t]_{-T/2}^{T/2} = \\frac{1}{T}(\\frac{T}{2} - (-\\frac{T}{2})) = 1$. The language is objective and unambiguous. No flaws from the checklist are present.\n\nStep 3: Verdict and Action\nThe problem is deemed valid. A complete solution will now be provided.\n\nThe analysis proceeds in three parts as requested.\n\nPart 1: Time Domain Analysis\nFirst, we compute the time mean $\\mu_{t}$. The quantity $|g(t)|^2$ acts as a probability density function for time.\n$$\n|g(t)|^2 = \\begin{cases} \\frac{1}{T}, & |t|\\le \\frac{T}{2},\\\\ 0,& \\text{otherwise}. \\end{cases}\n$$\nThe mean time $\\mu_t$ is the first moment of time with respect to this density.\n$$\n\\mu_{t} = \\int_{-\\infty}^{\\infty} t\\,|g(t)|^{2}\\,dt = \\int_{-T/2}^{T/2} t \\cdot \\frac{1}{T}\\,dt\n$$\nThe integrand $t/T$ is an odd function of $t$, and the interval of integration $[-T/2, T/2]$ is symmetric about the origin. The integral of an odd function over a symmetric interval is zero.\n$$\n\\mu_{t} = \\frac{1}{T} \\left[ \\frac{t^2}{2} \\right]_{-T/2}^{T/2} = \\frac{1}{2T} \\left( \\left(\\frac{T}{2}\\right)^2 - \\left(-\\frac{T}{2}\\right)^2 \\right) = \\frac{1}{2T} \\left( \\frac{T^2}{4} - \\frac{T^2}{4} \\right) = 0\n$$\nThus, the time mean is $\\mu_t = 0$.\n\nNext, we compute the time variance $\\sigma_t^2$. With $\\mu_t = 0$, the definition simplifies to the second moment.\n$$\n\\sigma_{t}^{2} = \\int_{-\\infty}^{\\infty} (t-0)^{2}\\,|g(t)|^{2}\\,dt = \\int_{-T/2}^{T/2} t^2 \\cdot \\frac{1}{T}\\,dt\n$$\nThe integrand $t^2/T$ is an even function of $t$.\n$$\n\\sigma_{t}^{2} = \\frac{1}{T} \\int_{-T/2}^{T/2} t^2\\,dt = \\frac{1}{T} \\left[ \\frac{t^3}{3} \\right]_{-T/2}^{T/2} = \\frac{1}{3T} \\left( \\left(\\frac{T}{2}\\right)^3 - \\left(-\\frac{T}{2}\\right)^3 \\right)\n$$\n$$\n\\sigma_{t}^{2} = \\frac{1}{3T} \\left( \\frac{T^3}{8} - \\left(-\\frac{T^3}{8}\\right) \\right) = \\frac{1}{3T} \\left( \\frac{2T^3}{8} \\right) = \\frac{1}{3T} \\frac{T^3}{4} = \\frac{T^2}{12}\n$$\nThe time variance is finite and is equal to $\\frac{T^2}{12}$.\n\nPart 2: Frequency Domain Analysis\nFirst, we compute the Fourier transform $G(f)$ of the window $g(t)$.\n$$\nG(f) = \\int_{-\\infty}^{\\infty} g(t)\\,\\exp(-j\\,2\\pi f t)\\,dt = \\int_{-T/2}^{T/2} \\frac{1}{\\sqrt{T}} \\exp(-j\\,2\\pi f t)\\,dt\n$$\nFor $f \\neq 0$:\n$$\nG(f) = \\frac{1}{\\sqrt{T}} \\left[ \\frac{\\exp(-j\\,2\\pi f t)}{-j\\,2\\pi f} \\right]_{-T/2}^{T/2} = \\frac{1}{\\sqrt{T}(-j\\,2\\pi f)} \\left( \\exp(-j\\pi f T) - \\exp(j\\pi f T) \\right)\n$$\nUsing the identity $\\sin(x) = \\frac{\\exp(jx) - \\exp(-jx)}{2j}$, we have $\\exp(-j\\pi f T) - \\exp(j\\pi f T) = -2j\\sin(\\pi f T)$.\n$$\nG(f) = \\frac{1}{\\sqrt{T}(-j\\,2\\pi f)} (-2j\\sin(\\pi f T)) = \\frac{\\sin(\\pi f T)}{\\pi f \\sqrt{T}}\n$$\nThis expression can be written using the unnormalized sinc function, $\\text{sinc}(x) \\triangleq \\frac{\\sin(\\pi x)}{\\pi x}$, as $G(f) = \\sqrt{T} \\text{sinc}(fT)$. For $f=0$, we evaluate the integral directly: $G(0) = \\int_{-T/2}^{T/2} \\frac{1}{\\sqrt{T}} dt = \\frac{T}{\\sqrt{T}} = \\sqrt{T}$, which is consistent with the limit of $\\sqrt{T} \\text{sinc}(fT)$ as $f \\rightarrow 0$.\n\nNext, we compute the frequency mean $\\mu_f$. The window $g(t)$ is a real and even function. Its Fourier transform $G(f)$ must also be real and even. Therefore, $|G(f)|^2 = G(f)^2$ is an even function. The integrand for the frequency mean is $f|G(f)|^2$, which is an odd function of $f$. The integral over the symmetric domain $(-\\infty, \\infty)$ is zero.\n$$\n\\mu_f = \\int_{-\\infty}^{\\infty} f\\,|G(f)|^2\\,df = 0\n$$\n\nNow, we assess the finiteness of the frequency variance $\\sigma_f^2$. With $\\mu_f = 0$, the definition becomes:\n$$\n\\sigma_{f}^{2} = \\int_{-\\infty}^{\\infty} f^2\\,|G(f)|^2\\,df = \\int_{-\\infty}^{\\infty} f^2 \\left( \\frac{\\sin(\\pi f T)}{\\pi f \\sqrt{T}} \\right)^2 df\n$$\n$$\n\\sigma_{f}^{2} = \\int_{-\\infty}^{\\infty} f^2 \\frac{\\sin^2(\\pi f T)}{\\pi^2 f^2 T}\\,df = \\frac{1}{\\pi^2 T} \\int_{-\\infty}^{\\infty} \\sin^2(\\pi f T)\\,df\n$$\nTo assess this integral, consider the change of variable $u = \\pi f T$, which gives $df = \\frac{du}{\\pi T}$. The limits remain $(-\\infty, \\infty)$.\n$$\n\\sigma_{f}^{2} = \\frac{1}{\\pi^2 T} \\int_{-\\infty}^{\\infty} \\sin^2(u) \\frac{du}{\\pi T} = \\frac{1}{\\pi^3 T^2} \\int_{-\\infty}^{\\infty} \\sin^2(u)\\,du\n$$\nThe integrand $\\sin^2(u)$ is a non-negative, periodic function. Its average value over any period is $\\frac{1}{2}$, as $\\sin^2(u) = \\frac{1-\\cos(2u)}{2}$. The integral of a function with a constant non-zero average value over an infinite domain diverges.\n$$\n\\int_{-\\infty}^{\\infty} \\sin^2(u)\\,du = \\infty\n$$\nTherefore, the frequency variance $\\sigma_f^2$ is infinite. This divergence is a direct consequence of the discontinuities in the time-domain window $g(t)$ at $t=\\pm T/2$. These discontinuities cause the spectral magnitude $|G(f)|$ to decay slowly, as $1/|f|$, resulting in spectral power $|G(f)|^2$ that decays as $1/f^2$. The $f^2$ weighting in the variance integral then leads to an integrand that does not decay to zero at infinity, causing the integral to diverge.\n\nPart 3: Interpretation and Alternative Metrics\nThe variance-based spread is a misleading metric for the frequency resolution of a rectangular window because its value is infinite. This infinite result arises from the heavy weighting the variance calculation gives to the energy in the far-out spectral sidelobes. The rectangular window's spectrum, a sinc function, possesses sidelobes whose energy decays slowly (proportional to $1/f^2$). While the variance correctly indicates a poor spectral energy concentration, the infinite value provides no practical information about the window's ability to distinguish two nearby frequency components, which is primarily determined by the width of the central main lobe.\n\nA robust alternative metric that remains meaningful is the **main-lobe width**. A common definition is the **null-to-null width**, which is the distance between the first zeros of the spectrum on either side of the center frequency. For $G(f) = \\sqrt{T} \\text{sinc}(fT)$, the first nulls occur when the argument of the sinc function is $\\pm 1$, i.e., $fT = \\pm 1$. This corresponds to frequencies $f = \\pm \\frac{1}{T}$. The null-to-null width is therefore $\\Delta f = \\frac{1}{T} - (-\\frac{1}{T}) = \\frac{2}{T}$. This metric is finite, directly relates to the window duration $T$, and better reflects the practical resolving power of the window. Another valid metric is the Equivalent Noise Bandwidth (ENBW).", "answer": "$$\n\\boxed{\\frac{T^{2}}{12}}\n$$", "id": "2914043"}, {"introduction": "The inherent time-frequency trade-off implies that no single, fixed window length is optimal for signals with time-varying characteristics. This final practice [@problem_id:2914058] moves from analyzing the trade-off to actively managing it by tasking you with the implementation of a simple adaptive spectrogram algorithm. You will design a test for local signal stationarity and use it to switch between short windows for transient events and long windows for stationary components, providing a hands-on introduction to the powerful concept of adaptive time-frequency analysis.", "problem": "You are tasked with specifying and implementing an adaptive spectrogram algorithm that switches between a short window and a long window based on a local stationarity test. Your design must begin from the definitions of the Short-Time Fourier Transform (STFT) and the spectrogram, the definition of sample variance, and the principle that time-frequency resolution is constrained by the time-bandwidth uncertainty relation. You must define a dimensionless test statistic using the ratio of a within-frame spectral variance to an across-frame spectral variance, formulate a decision rule, and then empirically estimate the detection error for several synthetic signals with known ground truth.\n\nDefinitions to use as the fundamental base:\n- The Short-Time Fourier Transform (STFT) of a discrete-time signal $x[n]$ with window $w[n]$ and hop $H$ is the sequence of complex spectra $X[m,k]$ computed on frames $x[n] w[n-mH]$ and the spectrogram is $S[m,k] = \\lvert X[m,k] \\rvert^{2}$.\n- For any finite list of real numbers $\\{ u_{j} \\}_{j=1}^{J}$, the sample mean is $\\bar{u} = \\frac{1}{J} \\sum_{j=1}^{J} u_{j}$ and the unbiased sample variance is $\\widehat{\\mathrm{var}}(u) = \\frac{1}{J-1} \\sum_{j=1}^{J} (u_{j} - \\bar{u})^{2}$.\n- The time-frequency resolution trade-off: for a window of effective duration $\\Delta t$ and effective bandwidth $\\Delta f$, one has an uncertainty constraint of the form $\\Delta t \\, \\Delta f \\gtrsim \\frac{1}{4 \\pi}$, motivating that longer windows yield finer frequency resolution but coarser time resolution, and vice versa.\n\nAlgorithm specification to implement:\n- Let the short window length be $N_{s}$ and the long window length be $N_{\\ell}$, both measured in samples. Use a Hann window for all periodogram computations.\n- Partition the signal into non-overlapping analysis contexts of $K$ short frames each, so that one context comprises exactly $K$ frames of length $N_{s}$ samples with hop $N_{s}$ (no overlap inside a context). For context index $i$, let $P_{i}[f,t]$ denote the periodogram magnitude-squared at frequency bin $f$ for short frame $t$ within the context, computed from a discrete Fourier transform length equal to $N_{s}$. Use only the nonnegative-frequency bins produced by a real-input discrete Fourier transform (from bin $f = 0$ to bin $f = N_{s}/2$ inclusive).\n- Define the within-frame spectral variance (variance across frequency) for frame $t$ in context $i$ as\n$$\nV_{\\mathrm{within}}(i,t) \\triangleq \\widehat{\\mathrm{var}}_{f} \\!\\left( P_{i}[f,t] \\right).\n$$\nDefine the across-frame spectral variance (variance across frames) at frequency bin $f$ in context $i$ as\n$$\nV_{\\mathrm{across}}(i,f) \\triangleq \\widehat{\\mathrm{var}}_{t} \\!\\left( P_{i}[f,t] \\right).\n$$\nAggregate these into\n$$\nW(i) \\triangleq \\frac{1}{K} \\sum_{t=1}^{K} V_{\\mathrm{within}}(i,t), \\quad\nA(i) \\triangleq \\frac{1}{F} \\sum_{f=1}^{F} V_{\\mathrm{across}}(i,f),\n$$\nwhere $F \\triangleq \\frac{N_{s}}{2} + 1$ is the number of nonnegative-frequency bins.\n- Define the local stationarity ratio\n$$\nR(i) \\triangleq \\frac{W(i)}{A(i) + \\varepsilon},\n$$\nwith a small regularization constant $\\varepsilon > 0$ to avoid division by zero. Use $\\varepsilon = 10^{-12}$.\n- Decision rule for window switching at context $i$: If $R(i) \\ge \\tau$ for threshold $\\tau > 0$, declare context $i$ locally stationary and choose the long window length $N_{\\ell}$ for that context; otherwise declare it locally nonstationary and choose the short window length $N_{s}$.\n\nDetection error analysis:\n- For a collection of contexts with known ground-truth stationarity labels, compute the empirical false positive rate (FPR) and empirical false negative rate (FNR) as follows. Let $\\mathcal{I}_{\\mathrm{stat}}$ be the index set of contexts that are truly stationary according to the ground truth, and let $\\mathcal{I}_{\\mathrm{nonstat}}$ be the index set of contexts that are truly nonstationary. Let $\\widehat{y}(i) \\in \\{ 0, 1 \\}$ be the detected label for context $i$ with $\\widehat{y}(i) = 1$ meaning stationary and $\\widehat{y}(i) = 0$ meaning nonstationary. The empirical false positive rate is\n$$\n\\mathrm{FPR} \\triangleq \\frac{1}{\\lvert \\mathcal{I}_{\\mathrm{stat}} \\rvert} \\sum_{i \\in \\mathcal{I}_{\\mathrm{stat}}} \\mathbb{1}\\{ \\widehat{y}(i) = 0 \\},\n$$\nand the empirical false negative rate is\n$$\n\\mathrm{FNR} \\triangleq \\frac{1}{\\lvert \\mathcal{I}_{\\mathrm{nonstat}} \\rvert} \\sum_{i \\in \\mathcal{I}_{\\mathrm{nonstat}}} \\mathbb{1}\\{ \\widehat{y}(i) = 1 \\}.\n$$\nIf a denominator is zero (no contexts of that type), define the corresponding error as $0$.\n\nSignal models and ground truth:\n- Stationary context: a sum of two sinusoids at fixed frequencies plus additive white Gaussian noise, which has a time-invariant second-order structure within the context. This is treated as locally stationary for the purpose of this test.\n- Nonstationary context: a linear chirp whose instantaneous frequency sweeps across the band within the context duration, plus additive white Gaussian noise; this has time-varying second-order structure and is treated as locally nonstationary.\n- For additive noise control, define the signal-to-noise ratio (SNR) in decibels as $\\mathrm{SNR}_{\\mathrm{dB}} = 10 \\log_{10}(P_{\\mathrm{sig}} / P_{\\mathrm{noise}})$, and scale the noise to achieve the requested SNR relative to the deterministic component power within each context. All error-rate outputs must be expressed as decimals (not percentages).\n\nTest suite:\nImplement your program to evaluate the algorithm on the following four parameter sets. In each case, use a sampling frequency $f_{s}$ in hertz and generate exactly $C = 24$ contexts, each context being $K$ short frames long with frame length $N_{s}$ and hop $N_{s}$. For mixed cases, alternate stationary and nonstationary contexts starting with a stationary context at context index $i = 0$.\n- Case $1$: $f_{s} = 8000$, $N_{s} = 256$, $N_{\\ell} = 2048$, $K = 8$, $\\tau = 1.0$, $\\mathrm{SNR}_{\\mathrm{dB}} = 10$, mode = mixed (alternating stationary and nonstationary contexts).\n- Case $2$: $f_{s} = 8000$, $N_{s} = 128$, $N_{\\ell} = 1024$, $K = 6$, $\\tau = 0.9$, $\\mathrm{SNR}_{\\mathrm{dB}} = 0$, mode = mixed.\n- Case $3$: $f_{s} = 8000$, $N_{s} = 256$, $N_{\\ell} = 2048$, $K = 8$, $\\tau = 1.05$, $\\mathrm{SNR}_{\\mathrm{dB}} = 10$, mode = stationary-only.\n- Case $4$: $f_{s} = 8000$, $N_{s} = 256$, $N_{\\ell} = 2048$, $K = 8$, $\\tau = 0.9$, $\\mathrm{SNR}_{\\mathrm{dB}} = 10$, mode = nonstationary-only.\n\nImplementation details to observe:\n- Use a Hann window for all periodogram computations.\n- Use the real-input discrete Fourier transform to obtain nonnegative-frequency bins only.\n- For reproducibility, fix a random seed of your choice at the start of the program.\n- For each test case, build the signal as the concatenation of $C$ contexts, and compute one decision per context using the ratio test. Then compute the empirical $\\mathrm{FPR}$ and $\\mathrm{FNR}$ as decimals.\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case contributes a two-element list $[\\mathrm{FPR}, \\mathrm{FNR}]$. The final line must therefore look like\n$[ [r_{1}, s_{1}], [r_{2}, s_{2}], [r_{3}, s_{3}], [r_{4}, s_{4}] ]$\nwith each $r_{j}$ and $s_{j}$ a decimal number.", "solution": "The problem statement is evaluated to be **valid**. It presents a self-contained, scientifically grounded, and well-posed problem in the domain of digital signal processing. All necessary definitions, parameters, and procedures are provided, allowing for a unique and verifiable implementation. The core idea of using a ratio of spectral variances to test for local stationarity is a reasonable heuristic rooted in the fundamental properties of stationary and nonstationary processes.\n\nWhile the problem is valid, it is noted that the terminology used for the error metrics, specifically \"False Positive Rate\" ($\\mathrm{FPR}$) and \"False Negative Rate\" ($\\mathrm{FNR}$), is unconventional. Standardly, if the \"positive\" class is the detection of an event (e.g., non-stationarity), then a false positive is incorrectly declaring a negative case (stationarity) as positive. The problem's formula for $\\mathrm{FNR}$ actually calculates this quantity. Conversely, the problem's formula for $\\mathrm{FPR}$ calculates what would conventionally be the false negative rate (or miss rate). However, because the problem provides explicit and unambiguous mathematical definitions for $\\mathrm{FPR}$ and $\\mathrm{FNR}$, these definitions will be strictly followed. The implementation is based on the provided formulas, not on conventional terminological interpretations.\n\nThe algorithm is designed to address the fundamental time-frequency resolution trade-off in signal analysis, a consequence of the uncertainty principle ($\\Delta t \\, \\Delta f \\gtrsim \\frac{1}{4 \\pi}$). For a signal whose statistical properties are not constant, a single choice of analysis window length is suboptimal. A long window provides good frequency resolution but poor time resolution, smearing transient events over its duration. A short window provides good time resolution but poor frequency resolution. An adaptive spectrogram attempts to mitigate this by selecting a window length appropriate for the local characteristics of the signal.\n\nThe proposed method hinges on a test for local stationarity. A signal is locally stationary if its spectral content is approximately constant over a given analysis context.\nThe quantity $P_{i}[f,t]$, the periodogram for frame $t$ in context $i$, represents the signal's power distribution across frequency bins $f$.\n\nThe core of the stationarity test is the ratio $R(i) \\triangleq \\frac{W(i)}{A(i) + \\varepsilon}$. The rationale is as follows:\n$1$. The term $W(i)$ is the average of the within-frame spectral variances, $V_{\\mathrm{within}}(i,t) = \\widehat{\\mathrm{var}}_{f} ( P_{i}[f,t] )$. This quantity measures the structural complexity or \"peakedness\" of the spectrum within a single frame. A signal composed of a few strong sinusoids will have a spectrum with high-energy peaks and low-energy valleys, resulting in a large variance across frequency bins $f$.\n$2$. The term $A(i)$ is a scaled sum of the across-frame spectral variances, $V_{\\mathrm{across}}(i,f) = \\widehat{\\mathrm{var}}_{t} ( P_{i}[f,t] )$. This quantity measures how much the power at each frequency bin $f$ changes over the frames $t$ within the context. For a truly stationary signal, the spectrum is time-invariant, so this variance should be low, ideally attributable only to the additive noise. For a nonstationary signal, such as a chirp where the dominant frequency sweeps through the band, the energy at any given frequency bin will change significantly over time, resulting in a large across-frame variance.\n\nTherefore, for a stationary signal context (e.g., sinusoids in noise), we expect a large $W(i)$ and a small $A(i)$, leading to a large ratio $R(i)$.\nFor a nonstationary signal context (e.g., a chirp), we expect a large $A(i)$, which will make the ratio $R(i)$ small.\nThe decision rule, `if $R(i) \\ge \\tau$, declare stationary`, directly formalizes this principle. A large value of the test statistic $R(i)$ provides evidence for stationarity.\n\nBased on this decision, the algorithm selects the window length for that context. A stationary context is analyzed with a long window $N_{\\ell}$ to achieve fine frequency resolution, which is permissible as the signal's properties are stable over this longer duration. A nonstationary context is analyzed with a short window $N_{s}$ to maintain temporal localization, accepting the coarser frequency resolution.\n\nThe implementation proceeds by first synthesizing the signal for each test case by concatenating $C=24$ contexts according to the specified mode (`mixed`, `stationary-only`, or `nonstationary-only`) and ground-truth labels. The signal is then processed context-by-context. For each context, a matrix of periodograms $P_i$ is computed, from which $W(i)$ and $A(i)$ are determined. The ratio $R(i)$ is compared against the threshold $\\tau$ to yield a decision $\\widehat{y}(i)$. Finally, the predicted labels $\\widehat{y}(i)$ are compared against the ground-truth labels to compute the empirical error rates $\\mathrm{FPR}$ and $\\mathrm{FNR}$ precisely according to their given formulas. A fixed random seed ensures the reproducibility of the noise component in the signals and thus the final results.\n\nThe calculation of the unbiased sample variance, $\\widehat{\\mathrm{var}}(u) = \\frac{1}{J-1} \\sum_{j=1}^{J} (u_{j} - \\bar{u})^{2}$, requires a degrees-of-freedom correction of $1$, which is handled by setting `ddof=1` in the variance computation. The aggregation of the across-frame variance, $A(i) \\triangleq \\frac{1}{F} \\sum_{f=1}^{F} V_{\\mathrm{across}}(i,f)$, is implemented by summing the variances for frequency bins indexed $f=1$ to $f=F-1$ (i.e., excluding the DC component at index $0$) and dividing by the total number of non-negative frequency bins, $F = N_s/2 + 1$, as prescribed. This implementation detail correctly interprets the likely intent of the summation notation, which is to average over non-DC frequency bins.", "answer": "```python\nimport numpy as np\nfrom scipy.signal import chirp\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the signal generation, analysis,\n    and error calculation for the specified test cases.\n    \"\"\"\n    np.random.seed(42)  # For reproducibility\n\n    test_cases = [\n        {'fs': 8000, 'Ns': 256, 'Nl': 2048, 'K': 8, 'tau': 1.0, 'snr_db': 10, 'mode': 'mixed'},\n        {'fs': 8000, 'Ns': 128, 'Nl': 1024, 'K': 6, 'tau': 0.9, 'snr_db': 0, 'mode': 'mixed'},\n        {'fs': 8000, 'Ns': 256, 'Nl': 2048, 'K': 8, 'tau': 1.05, 'snr_db': 10, 'mode': 'stationary-only'},\n        {'fs': 8000, 'Ns': 256, 'Nl': 2048, 'K': 8, 'tau': 0.9, 'snr_db': 10, 'mode': 'nonstationary-only'},\n    ]\n\n    total_contexts = 24\n    epsilon = 1e-12\n\n    def generate_context_signal(length_samples, fs, snr_db, is_stationary):\n        \"\"\"Generates a single signal context (stationary or nonstationary).\"\"\"\n        t = np.arange(length_samples) / fs\n        \n        if is_stationary:\n            # Sum of two sinusoids\n            f1, f2 = 500.0, 1500.0\n            signal_det = np.sin(2 * np.pi * f1 * t) + np.sin(2 * np.pi * f2 * t)\n        else:\n            # Linear chirp\n            f_start, f_end = 200.0, fs / 2 - 200.0\n            signal_det = chirp(t, f0=f_start, f1=f_end, t1=t[-1], method='linear')\n\n        # Calculate signal power and add noise\n        power_sig = np.mean(signal_det**2)\n        if power_sig == 0: # Should not happen with current signals\n            power_sig = 1e-10\n\n        snr_linear = 10**(snr_db / 10.0)\n        power_noise = power_sig / snr_linear\n        noise_std = np.sqrt(power_noise)\n        noise = np.random.normal(0, noise_std, length_samples)\n        \n        return signal_det + noise\n\n    def analyze_signal(full_signal, Ns, K, fs, tau):\n        \"\"\"Analyzes the full signal context by context to make stationarity decisions.\"\"\"\n        context_len_samples = Ns * K\n        num_contexts = len(full_signal) // context_len_samples\n        y_pred = []\n        \n        window = np.hanning(Ns)\n        F = Ns // 2 + 1\n\n        for i in range(num_contexts):\n            context_signal = full_signal[i * context_len_samples : (i + 1) * context_len_samples]\n            \n            periodograms = np.zeros((K, F))\n            \n            for t_idx in range(K):\n                frame = context_signal[t_idx * Ns : (t_idx + 1) * Ns]\n                frame_windowed = frame * window\n                spectrum = np.fft.rfft(frame_windowed)\n                periodograms[t_idx, :] = np.abs(spectrum)**2\n            \n            # Calculate W(i)\n            V_within_per_frame = np.var(periodograms, axis=1, ddof=1)\n            W = np.mean(V_within_per_frame)\n            \n            # Calculate A(i)\n            V_across_per_freq = np.var(periodograms, axis=0, ddof=1)\n            # Implements the formula from the spec, interpreting the sum from f=1..F\n            # as excluding the DC component at index 0.\n            A = np.sum(V_across_per_freq[1:]) / F\n            \n            # Calculate ratio and make decision\n            R = W / (A + epsilon)\n            \n            # stationary if R >= tau. y_hat = 1 for stationary, 0 for nonstationary.\n            decision = 1 if R >= tau else 0\n            y_pred.append(decision)\n            \n        return np.array(y_pred)\n\n    def calculate_errors(y_true, y_pred):\n        \"\"\"Calculates FPR and FNR based on the problem's explicit definitions.\"\"\"\n        y_true = np.array(y_true)\n        y_pred = np.array(y_pred)\n        \n        # Indices of true stationary and nonstationary contexts\n        I_stat = np.where(y_true == 1)[0]\n        I_nonstat = np.where(y_true == 0)[0]\n        \n        # Calculate FPR as defined: fraction of true stationaries misclassified as nonstationary\n        if len(I_stat) == 0:\n            FPR = 0.0\n        else:\n            misclassified_stat = np.sum(y_pred[I_stat] == 0)\n            FPR = misclassified_stat / len(I_stat)\n            \n        # Calculate FNR as defined: fraction of true nonstationaries misclassified as stationary\n        if len(I_nonstat) == 0:\n            FNR = 0.0\n        else:\n            misclassified_nonstat = np.sum(y_pred[I_nonstat] == 1)\n            FNR = misclassified_nonstat / len(I_nonstat)\n            \n        return [FPR, FNR]\n\n    final_results = []\n    for params in test_cases:\n        Ns, K, fs, mode = params['Ns'], params['K'], params['fs'], params['mode']\n        \n        context_len = Ns * K\n        full_signal = np.array([])\n        y_true = []\n\n        for i in range(total_contexts):\n            if mode == 'mixed':\n                is_stationary = (i % 2 == 0)\n            elif mode == 'stationary-only':\n                is_stationary = True\n            else: # nonstationary-only\n                is_stationary = False\n            \n            # y=1 for stationary, y=0 for nonstationary\n            y_true.append(1 if is_stationary else 0)\n            \n            context_sig = generate_context_signal(context_len, fs, params['snr_db'], is_stationary)\n            full_signal = np.concatenate((full_signal, context_sig))\n            \n        y_pred = analyze_signal(full_signal, Ns, K, fs, params['tau'])\n        \n        errors = calculate_errors(y_true, y_pred)\n        final_results.append(errors)\n\n    # Format the final output string exactly as required.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "2914058"}]}