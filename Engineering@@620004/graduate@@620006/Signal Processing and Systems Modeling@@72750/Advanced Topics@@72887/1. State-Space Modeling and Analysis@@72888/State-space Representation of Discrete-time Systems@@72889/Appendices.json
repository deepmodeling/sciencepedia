{"hands_on_practices": [{"introduction": "Understanding system stability is the first step in analyzing any dynamic model. This practice focuses on the concept of marginal stability, a critical case where a system's state remains bounded but does not converge to an equilibrium point. By working through a canonical example of a discrete-time rotational system, you will connect the eigenvalues of the state matrix $A$ directly to the oscillatory, non-decaying nature of the system's trajectory [@problem_id:2908001].", "problem": "Consider the autonomous discrete-time linear time-invariant (LTI) state-space system\n$$\nx[k+1] = A\\,x[k],\\qquad y[k] = C\\,x[k],\n$$\nwhere $x[k] \\in \\mathbb{R}^{2}$, $y[k] \\in \\mathbb{R}$, and\n$$\nA = \\begin{bmatrix}\n\\cos(\\theta) & -\\sin(\\theta)\\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{bmatrix},\\qquad C = \\begin{bmatrix}1 & 0\\end{bmatrix},\\qquad \\theta = \\frac{\\pi}{3},\n$$\nwith initial condition $x[0] = \\begin{bmatrix}2\\\\0\\end{bmatrix}$. Angles must be interpreted in radians.\n\na) Provide a precise definition of marginal stability for such an autonomous discrete-time LTI system in terms of the boundedness of state trajectories and asymptotic behavior, grounded in fundamental definitions of stability and the behavior of matrix powers.\n\nb) Starting only from core definitions for discrete-time systems (that is, repeated substitution of the state equation and the algebraic properties of plane rotations), determine whether the given system is marginally stable and derive a closed-form analytic expression for $y[k]$ as a function of $k \\in \\mathbb{Z}_{\\ge 0}$. Express your final answer for $y[k]$ as a single closed-form expression in $k$ with angles in radians. No numerical rounding is required, and no transform-domain shortcuts are permitted.", "solution": "The problem as stated is subjected to validation.\n\nStep 1: Extract Givens.\nThe autonomous discrete-time linear time-invariant system is described by the equations:\n$x[k+1] = A\\,x[k]$\n$y[k] = C\\,x[k]$\nThe state vector is $x[k] \\in \\mathbb{R}^{2}$, and the output is $y[k] \\in \\mathbb{R}$.\nThe system matrices are:\n$A = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta)\\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix}$\n$C = \\begin{bmatrix}1 & 0\\end{bmatrix}$\nThe parameter $\\theta$ is given as $\\theta = \\frac{\\pi}{3}$.\nThe initial condition is $x[0] = \\begin{bmatrix}2\\\\0\\end{bmatrix}$.\nThe time index $k$ belongs to the set of non-negative integers, $k \\in \\mathbb{Z}_{\\ge 0}$.\nThe problem requires:\na) A precise definition of marginal stability for such a system.\nb) A determination of the system's stability and the derivation of a closed-form expression for $y[k]$ using only repeated substitution and algebraic properties.\n\nStep 2: Validate Using Extracted Givens.\nThe problem is scientifically grounded, situated squarely within the fundamental theory of linear discrete-time systems. It is a canonical example of analyzing system dynamics. The problem is well-posed, completely specified, and contains no contradictions. All data ($A$, $C$, $x[0]$) are provided and are dimensionally consistent. The language is objective and unambiguous. The constraints on the solution method (no transform-domain shortcuts) are clear and serve to test foundational understanding.\n\nStep 3: Verdict and Action.\nThe problem is deemed valid. A solution will be provided.\n\nThe response is structured to address parts (a) and (b) in sequence.\n\na) Definition of Marginal Stability\nFor an autonomous discrete-time LTI system described by $x[k+1] = A\\,x[k]$, stability concerns the behavior of the state trajectory $x[k]$ as $k \\to \\infty$. The system's stability is completely determined by the eigenvalues of the state matrix $A$. Let the eigenvalues of $A$ be $\\lambda_i$.\n\nA system is defined as **marginally stable** if, for any bounded initial condition $x[0]$, the state trajectory $x[k]$ remains bounded for all $k \\ge 0$, but the system is not asymptotically stable.\nThis behavior corresponds to specific conditions on the eigenvalues of the matrix $A$:\n$1$. All eigenvalues must have a magnitude less than or equal to one: $|\\lambda_i| \\le 1$ for all $i$.\n$2$. At least one eigenvalue must have a magnitude exactly equal to one: $|\\lambda_j| = 1$ for some $j$.\n$3$. Any eigenvalue $\\lambda_m$ with magnitude $|\\lambda_m| = 1$ must be a simple root of the minimal polynomial of $A$. This condition is equivalent to stating that the geometric multiplicity of such an eigenvalue must equal its algebraic multiplicity. If this condition is not met (i.e., if there is a Jordan block of size greater than $1$ associated with an eigenvalue on the unit circle), the state trajectory will contain terms of the form $k^p |\\lambda_m|^k = k^p$, which are unbounded, and the system would be unstable.\n\nIn summary, a marginally stable system's state does not decay to the origin for all initial conditions (unlike an asymptotically stable system), but it also does not grow without bound (unlike an unstable system). It typically exhibits sustained oscillations or constant-magnitude behavior.\n\nb) Stability Analysis and Derivation of $y[k]$\nFirst, we analyze the stability of the given system. The state matrix is $A = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta)\\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix}$ with $\\theta = \\frac{\\pi}{3}$.\nTo determine stability, we find the eigenvalues of $A$ by solving the characteristic equation $\\det(A - \\lambda I) = 0$.\n$$\n\\det \\begin{pmatrix} \\cos(\\theta) - \\lambda & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) - \\lambda \\end{pmatrix} = (\\cos(\\theta) - \\lambda)^2 + \\sin^2(\\theta) = 0\n$$\n$$\n\\lambda^2 - 2\\lambda\\cos(\\theta) + \\cos^2(\\theta) + \\sin^2(\\theta) = 0\n$$\n$$\n\\lambda^2 - 2\\lambda\\cos(\\theta) + 1 = 0\n$$\nUsing the quadratic formula, the eigenvalues are:\n$$\n\\lambda = \\frac{2\\cos(\\theta) \\pm \\sqrt{4\\cos^2(\\theta) - 4}}{2} = \\cos(\\theta) \\pm \\sqrt{\\cos^2(\\theta) - 1} = \\cos(\\theta) \\pm \\sqrt{- \\sin^2(\\theta)}\n$$\n$$\n\\lambda = \\cos(\\theta) \\pm i\\sin(\\theta)\n$$\nThese are the complex conjugates $e^{i\\theta}$ and $e^{-i\\theta}$.\nFor $\\theta = \\frac{\\pi}{3}$, the eigenvalues are $\\lambda_1 = e^{i\\pi/3}$ and $\\lambda_2 = e^{-i\\pi/3}$.\nThe magnitudes of these eigenvalues are $|\\lambda_1| = |e^{i\\pi/3}| = 1$ and $|\\lambda_2| = |e^{-i\\pi/3}| = 1$.\nSince $\\theta = \\frac{\\pi}{3} \\ne n\\pi$ for an integer $n$, the eigenvalues are distinct.\nThe conditions for marginal stability are met: all eigenvalues have magnitude equal to $1$, and they are distinct (hence, they are simple roots of the minimal polynomial). Therefore, the system is **marginally stable**.\n\nNext, we derive the closed-form expression for $y[k]$. The problem requires using repeated substitution. The solution to the state equation $x[k+1] = A x[k]$ is found by recursion:\n$x[1] = A x[0]$\n$x[2] = A x[1] = A(A x[0]) = A^2 x[0]$\n...\n$x[k] = A^k x[0]$\nThe matrix $A$ is a rotation matrix $R(\\theta)$. The product of two rotation matrices $R(\\theta_1)R(\\theta_2)$ is $R(\\theta_1 + \\theta_2)$. By induction, one can rigorously prove that $(R(\\theta))^k = R(k\\theta)$.\nLet us formally demonstrate this.\nBase case ($k=1$): $A^1 = A = R(\\theta) = R(1 \\cdot \\theta)$. The property holds.\nInductive step: Assume $A^n = R(n\\theta)$ for some integer $n \\ge 1$.\nThen $A^{n+1} = A^n A = R(n\\theta) R(\\theta)$.\n$$\nA^{n+1} = \\begin{pmatrix} \\cos(n\\theta) & -\\sin(n\\theta) \\\\ \\sin(n\\theta) & \\cos(n\\theta) \\end{pmatrix} \\begin{pmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} \\cos(n\\theta)\\cos(\\theta) - \\sin(n\\theta)\\sin(\\theta) & -\\cos(n\\theta)\\sin(\\theta) - \\sin(n\\theta)\\cos(\\theta) \\\\ \\sin(n\\theta)\\cos(\\theta) + \\cos(n\\theta)\\sin(\\theta) & -\\sin(n\\theta)\\sin(\\theta) + \\cos(n\\theta)\\cos(\\theta) \\end{pmatrix}\n$$\nUsing the trigonometric angle addition identities:\n$$\nA^{n+1} = \\begin{pmatrix} \\cos(n\\theta+\\theta) & -\\sin(n\\theta+\\theta) \\\\ \\sin(n\\theta+\\theta) & \\cos(n\\theta+\\theta) \\end{pmatrix} = \\begin{pmatrix} \\cos((n+1)\\theta) & -\\sin((n+1)\\theta) \\\\ \\sin((n+1)\\theta) & \\cos((n+1)\\theta) \\end{pmatrix} = R((n+1)\\theta)\n$$\nThe induction is complete. Thus, for any $k \\in \\mathbb{Z}_{\\ge 0}$, we have:\n$$\nA^k = \\begin{bmatrix} \\cos(k\\theta) & -\\sin(k\\theta) \\\\ \\sin(k\\theta) & \\cos(k\\theta) \\end{bmatrix}\n$$\nNow we compute the state vector $x[k]$ with the given initial condition $x[0] = \\begin{bmatrix}2\\\\0\\end{bmatrix}$:\n$$\nx[k] = A^k x[0] = \\begin{bmatrix} \\cos(k\\theta) & -\\sin(k\\theta) \\\\ \\sin(k\\theta) & \\cos(k\\theta) \\end{bmatrix} \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 2\\cos(k\\theta) \\\\ 2\\sin(k\\theta) \\end{bmatrix}\n$$\nFinally, we compute the output $y[k]$ using the output equation $y[k] = C x[k]$:\n$$\ny[k] = \\begin{bmatrix} 1 & 0 \\end{bmatrix} \\begin{bmatrix} 2\\cos(k\\theta) \\\\ 2\\sin(k\\theta) \\end{bmatrix} = 1 \\cdot (2\\cos(k\\theta)) + 0 \\cdot (2\\sin(k\\theta)) = 2\\cos(k\\theta)\n$$\nSubstituting the value $\\theta = \\frac{\\pi}{3}$, we obtain the final closed-form expression for the output:\n$$\ny[k] = 2\\cos\\left(\\frac{k\\pi}{3}\\right)\n$$\nThis expression describes a discrete-time sinusoid with amplitude $2$ and discrete frequency $\\frac{\\pi}{3}$ radians per sample, consistent with the behavior of a marginally stable system representing pure rotation.", "answer": "$$\n\\boxed{2\\cos\\left(\\frac{k\\pi}{3}\\right)}\n$$", "id": "2908001"}, {"introduction": "A transfer function provides an input-output perspective of a system, but it may not tell the whole story about the internal state dynamics. This exercise explores the concept of minimality by examining a system with pole-zero cancellations in its transfer function [@problem_id:2908024]. You will learn how these cancellations correspond to uncontrollable or unobservable modes and why identifying them is essential for finding the most efficient, or minimal, state-space representation.", "problem": "Consider a single-input single-output, linear time-invariant, discrete-time system with complex variable $z$ and transfer function\n$$\nH(z) \\;=\\; \\frac{\\left(z - 1\\right)\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{3}\\right)}{\\left(z - 1\\right)^{2}\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)} \\, .\n$$\nYou are tasked with deriving a state-space realization starting from the foundational definitions for discrete-time linear systems. Use only the following base concepts: the definition of a state-space realization, the definition of the transfer function $H(z)$ as $H(z) = C\\left(zI - A\\right)^{-1}B + D$, and the definition of minimality in terms of reachability and observability.\n\nExplain, from these principles, how non-coprime numerator and denominator polynomials are handled when deriving a realization, and why common factors impact minimality. Your explanation should make precise how common factors in the numerator and denominator manifest as uncontrollable or unobservable modes in a non-minimal realization and how they are eliminated to obtain a minimal realization.\n\nCompute the minimal achievable state dimension $n_{\\min}$ for any realization that exactly reproduces $H(z)$. Express your final answer as a single integer. No rounding is needed.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and self-contained. It presents a standard task in linear systems theory, requiring an understanding of the relationship between a system's external description (transfer function) and its internal description (state-space realization), with a specific focus on the concept of minimality. The problem is valid and permits a rigorous, unique solution.\n\nWe begin from first principles. A single-input single-output (SISO) linear time-invariant (LTI) discrete-time system can be described by the state-space equations:\n$$\n\\mathbf{x}[k+1] = A\\mathbf{x}[k] + B u[k]\n$$\n$$\ny[k] = C\\mathbf{x}[k] + D u[k]\n$$\nwhere $\\mathbf{x}[k] \\in \\mathbb{R}^n$ is the state vector at time step $k$, $u[k] \\in \\mathbb{R}$ is the input, and $y[k] \\in \\mathbb{R}$ is the output. The matrices $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times 1}$, $C \\in \\mathbb{R}^{1 \\times n}$, and $D \\in \\mathbb{R}$ constitute the state-space realization. The dimension of the realization is $n$.\n\nThe transfer function $H(z)$ of the system is defined as the Z-transform of the output divided by the Z-transform of the input, under zero initial conditions. Applying the Z-transform to the state-space equations yields:\n$$\nz\\mathbf{X}(z) = A\\mathbf{X}(z) + B U(z)\n$$\n$$\nY(z) = C\\mathbf{X}(z) + D U(z)\n$$\nFrom the first equation, we solve for $\\mathbf{X}(z)$:\n$$\n(zI - A)\\mathbf{X}(z) = B U(z) \\implies \\mathbf{X}(z) = (zI - A)^{-1} B U(z)\n$$\nSubstituting this into the second equation gives:\n$$\nY(z) = C(zI - A)^{-1} B U(z) + D U(z) = \\left( C(zI - A)^{-1}B + D \\right) U(z)\n$$\nThus, the transfer function is given by the expression $H(z) = \\frac{Y(z)}{U(z)}$:\n$$\nH(z) = C(zI - A)^{-1}B + D\n$$\nUsing the identity for the inverse of a matrix, $(zI-A)^{-1} = \\frac{\\text{adj}(zI-A)}{\\det(zI-A)}$, we can write:\n$$\nH(z) = \\frac{C \\, \\text{adj}(zI-A) \\, B}{\\det(zI-A)} + D\n$$\nThe characteristic polynomial of the matrix $A$ is $p_A(z) = \\det(zI-A)$. Its roots are the eigenvalues of $A$, which are the modes of the system. The poles of the transfer function $H(z)$ are a subset of the eigenvalues of $A$.\n\nA state-space realization is said to be **minimal** if its dimension $n$ is the smallest possible among all realizations that produce the given transfer function $H(z)$. A fundamental theorem of linear systems theory states that a realization is minimal if and only if it is both **completely reachable** and **completely observable**.\n- **Reachability** means that any state $\\mathbf{x} \\in \\mathbb{R}^n$ can be reached from the zero state in a finite number of steps by applying an appropriate input sequence.\n- **Observability** means that the initial state $\\mathbf{x}[0]$ can be uniquely determined from a finite sequence of future outputs $y[k]$ and inputs $u[k]$.\n\nThe transfer function $H(z)$ only describes the input-output behavior of a system. This behavior is determined exclusively by the subsystem that is both reachable and observable. Any modes of the system (eigenvalues of $A$) that are either unreachable or unobservable are \"hidden\" from the input-output perspective and do not appear in the poles of the simplified transfer function.\n\nThe given transfer function is:\n$$\nH(z) \\;=\\; \\frac{\\left(z - 1\\right)\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{3}\\right)}{\\left(z - 1\\right)^{2}\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)}\n$$\nThe numerator polynomial $N(z)$ and denominator polynomial $D(z)$ are not coprime. We can identify common factors by inspection. The zeros are at $z=1$, $z=\\frac{1}{2}$, and $z=-\\frac{1}{3}$. The poles are at $z=1$ (with multiplicity $2$), $z=\\frac{1}{2}$, $z=-\\frac{1}{4}$, and $z=\\frac{2}{3}$.\n\nIf one were to construct a realization directly from this un-simplified form, for example using a controllable or observable canonical form, the dimension of the resulting state-space model would be equal to the degree of the denominator polynomial, which is $2+1+1+1 = 5$. Let this non-minimal realization be $(A_5, B_5, C_5, D_5)$. The characteristic polynomial of $A_5$ would be $\\det(zI-A_5) = \\left(z - 1\\right)^{2}\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)$, and the eigenvalues of $A_5$ would be $\\{1, 1, \\frac{1}{2}, -\\frac{1}{4}, \\frac{2}{3}\\}$.\n\nHowever, the transfer function has pole-zero cancellations. The factors $(z-1)$ and $(z-\\frac{1}{2})$ appear in both the numerator and the denominator. A pole-zero cancellation in the transfer function $H(z) = C(zI-A)^{-1}B+D$ implies that the corresponding mode (eigenvalue of $A$) is either unreachable or unobservable. For a mode at $z=\\lambda$ to be cancelled, the numerator term $C \\, \\text{adj}(zI-A) \\, B$ must also be zero at $z=\\lambda$, effectively masking the pole that arises from $\\det(zI-A)=0$. This masking signifies a loss of either reachability or observability for that specific mode.\n\nTo obtain a minimal realization, we must first simplify the transfer function by canceling all common factors. This process isolates the part of the system dynamics that is both reachable and observable.\nThe greatest common divisor of the numerator and denominator is $\\gcd(N(z), D(z)) = \\left(z-1\\right)\\left(z-\\frac{1}{2}\\right)$.\nDividing the numerator and denominator by this GCD yields the simplified transfer function, $H_{min}(z)$:\n$$\nH_{min}(z) = \\frac{\\frac{\\left(z - 1\\right)\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{3}\\right)}{\\left(z - 1\\right)\\left(z - \\frac{1}{2}\\right)}}{\\frac{\\left(z - 1\\right)^{2}\\left(z - \\frac{1}{2}\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)}{\\left(z - 1\\right)\\left(z - \\frac{1}{2}\\right)}} = \\frac{z + \\frac{1}{3}}{\\left(z - 1\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)}\n$$\nThis simplified transfer function $H_{min}(z)$ represents the purely reachable and observable part of any system having the original transfer function $H(z)$. A minimal state-space realization is one that realizes $H_{min}(z)$.\n\nThe minimal achievable state dimension, $n_{min}$, for any realization of a given rational transfer function is equal to the degree of the denominator of the transfer function after it has been reduced to a coprime fraction.\nThe denominator of $H_{min}(z)$ is:\n$$\nD_{min}(z) = \\left(z - 1\\right)\\left(z + \\frac{1}{4}\\right)\\left(z - \\frac{2}{3}\\right)\n$$\nThe degree of this polynomial is $3$. Therefore, the minimal dimension of any state-space realization that exactly reproduces the input-output behavior described by $H(z)$ is $3$. The modes corresponding to the canceled poles (one at $z=1$ and one at $z=\\frac{1}{2}$) would be present as either unreachable or unobservable states in any non-minimal realization of dimension greater than $3$.\n\nThe minimal achievable state dimension $n_{min}$ is therefore $3$.", "answer": "$$\n\\boxed{3}\n$$", "id": "2908024"}, {"introduction": "For state estimation to be feasible, must we be able to determine the initial state with perfect precision? This problem introduces detectability, a crucial relaxation of the strict requirement of observability. You will investigate a system where some states are 'hidden' from the output, yet their behavior is stable, ensuring that any estimation error will eventually vanish [@problem_id:2908028]. Understanding this distinction is fundamental to designing robust state estimators for real-world applications where perfect observability is rare.", "problem": "Consider a discrete-time linear time-invariant (LTI) system in state-space form with state dimension $n$, input dimension $m$, and output dimension $p$, described by\n$$\nx[k+1] = A x[k] + B u[k], \\quad y[k] = C x[k] + D u[k],\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times m}$, $C \\in \\mathbb{R}^{p \\times n}$, and $D \\in \\mathbb{R}^{p \\times m}$. Using only the foundational definitions of observability and detectability for discrete-time systems, perform the following tasks:\n\n1) Provide a precise definition of detectability for the pair $(A,C)$ in discrete time, formulated in terms of unobservable modes and their stability (do not use any frequency-domain characterizations). Your definition should be logically derivable from the definition of observability.\n\n2) Consider the following specific system with $n = 4$ and $p = 2$:\n$$\nA = \\begin{bmatrix}\n1.25 & 0.20 & 0 & 0 \\\\\n0.10 & -0.70 & 0 & 0 \\\\\n0 & 0 & 0.50 & 0 \\\\\n0 & 0 & 0 & -0.40\n\\end{bmatrix}, \n\\quad\nC = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0\n\\end{bmatrix}.\n$$\nWithout invoking any unproven shortcut results, justify from first principles whether $(A,C)$ is observable. Then, justify whether $(A,C)$ is detectable by identifying the unobservable subspace and characterizing the corresponding state transition restricted to that subspace.\n\n3) Identify the unobservable but stable modes of $(A,C)$ for the system above. Report only the eigenvalues of these unobservable modes, ordered increasingly by their real values, and express them as a single row matrix using the $\\text{pmatrix}$ environment. No rounding is required, and no units are involved.\n\nYour final answer must be only the requested row matrix of eigenvalues, with no additional text or units inside the answer box.", "solution": "We begin from the foundational definitions for discrete-time linear time-invariant state-space models. The pair $(A,C)$ is said to be observable if, for any initial state $x[0] \\in \\mathbb{R}^{n}$, the output sequence $\\{y[k]\\}_{k=0}^{n-1}$ uniquely determines $x[0]$. Equivalently, the observability matrix\n$$\n\\mathcal{O} \\triangleq \\begin{bmatrix}\nC \\\\\nC A \\\\\n\\vdots \\\\\nC A^{n-1}\n\\end{bmatrix} \\in \\mathbb{R}^{np \\times n}\n$$\nhas full column rank $n$. If $\\operatorname{rank}(\\mathcal{O}) < n$, then there exists a nontrivial unobservable subspace $\\mathcal{N} \\subset \\mathbb{R}^{n}$ defined by\n$$\n\\mathcal{N} \\triangleq \\{x \\in \\mathbb{R}^{n} : C A^{k} x = 0 \\text{ for all } k = 0,1,\\dots,n-1\\},\n$$\nand one can verify that $\\mathcal{N}$ is $A$-invariant, meaning $A \\mathcal{N} \\subseteq \\mathcal{N}$.\n\nDetectability for discrete-time systems is defined in terms of the asymptotic behavior of unobservable modes. Specifically, $(A,C)$ is detectable if every unobservable mode is stable in the discrete-time sense. Using the $A$-invariant unobservable subspace $\\mathcal{N}$ as above, let $A|_{\\mathcal{N}}$ denote the restriction of $A$ to $\\mathcal{N}$ (that is, the state transition induced by $A$ on $\\mathcal{N}$). Then $(A,C)$ is detectable if and only if all eigenvalues of $A|_{\\mathcal{N}}$ lie strictly inside the unit disk, i.e., if $\\rho(A|_{\\mathcal{N}}) < 1$, where $\\rho(\\cdot)$ denotes the spectral radius. Equivalently stated, every eigenvalue $\\lambda$ of $A$ with $|\\lambda| \\ge 1$ is observable.\n\nWe now analyze the given system with\n$$\nA = \\begin{bmatrix}\n1.25 & 0.20 & 0 & 0 \\\\\n0.10 & -0.70 & 0 & 0 \\\\\n0 & 0 & 0.50 & 0 \\\\\n0 & 0 & 0 & -0.40\n\\end{bmatrix},\n\\quad\nC = \\begin{bmatrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0\n\\end{bmatrix}.\n$$\nObserve that $A$ is block diagonal with respect to the partition of the state $x = \\begin{bmatrix}x_{o} \\\\ x_{u}\\end{bmatrix}$ where $x_{o} \\in \\mathbb{R}^{2}$ corresponds to the first two states and $x_{u} \\in \\mathbb{R}^{2}$ corresponds to the last two states:\n$$\nA = \\begin{bmatrix}\nA_{o} & 0 \\\\\n0 & A_{u}\n\\end{bmatrix}, \\quad\nA_{o} = \\begin{bmatrix} 1.25 & 0.20 \\\\ 0.10 & -0.70 \\end{bmatrix}, \\quad\nA_{u} = \\begin{bmatrix} 0.50 & 0 \\\\ 0 & -0.40 \\end{bmatrix}.\n$$\nThe output matrix is\n$$\nC = \\begin{bmatrix} I_{2} & 0 \\end{bmatrix},\n$$\nso $y[k] = x_{o}[k]$. In particular, the last two state components are not measured directly, and because $A$ is block diagonal with a zero upper-right block, the unmeasured states do not dynamically feed into the measured states. To test observability, consider the observability matrix\n$$\n\\mathcal{O} = \\begin{bmatrix}\nC \\\\\nC A \\\\\nC A^{2} \\\\\nC A^{3}\n\\end{bmatrix} \n= \n\\begin{bmatrix}\nI_{2} & 0 \\\\\nA_{o} & 0 \\\\\nA_{o}^{2} & 0 \\\\\nA_{o}^{3} & 0\n\\end{bmatrix}.\n$$\nBy block-diagonal structure, for every nonnegative integer $k$, $A^{k} = \\operatorname{diag}(A_{o}^{k}, A_{u}^{k})$, hence $C A^{k} = \\begin{bmatrix} A_{o}^{k} & 0 \\end{bmatrix}$. Consequently, the third and fourth columns of $\\mathcal{O}$ are zero for every block row, and therefore $\\operatorname{rank}(\\mathcal{O}) \\le 2 < 4 = n$. Hence $(A,C)$ is not observable. The unobservable subspace is precisely\n$$\n\\mathcal{N} = \\operatorname{span}\\{ e_{3}, e_{4} \\} = \\left\\{ \\begin{bmatrix} 0 \\\\ 0 \\\\ \\xi_{3} \\\\ \\xi_{4} \\end{bmatrix} : \\xi_{3}, \\xi_{4} \\in \\mathbb{R} \\right\\},\n$$\nwhich is invariant under $A$, and the restriction $A|_{\\mathcal{N}}$ is exactly the block $A_{u}$.\n\nTo decide detectability, we examine the eigenvalues of $A|_{\\mathcal{N}} = A_{u}$. Because $A_{u}$ is diagonal,\n$$\n\\operatorname{eig}(A_{u}) = \\{ 0.50, -0.40 \\}.\n$$\nBoth eigenvalues satisfy $|0.50| < 1$ and $| -0.40 | < 1$. Therefore, all unobservable modes are discrete-time stable, which implies $(A,C)$ is detectable by definition.\n\nFinally, the unobservable but stable modes are the eigenvalues of $A_{u}$. Ordered increasingly by their real values, they are $-0.40$ and $0.50$. The requested final answer is the row matrix containing these values.", "answer": "$$\\boxed{\\begin{pmatrix}-0.40 & 0.50\\end{pmatrix}}$$", "id": "2908028"}]}