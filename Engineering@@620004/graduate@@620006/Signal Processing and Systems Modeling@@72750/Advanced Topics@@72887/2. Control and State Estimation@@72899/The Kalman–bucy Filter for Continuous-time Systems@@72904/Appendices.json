{"hands_on_practices": [{"introduction": "The heart of the Kalman-Bucy filter's performance analysis lies in the continuous-time Riccati differential equation, which governs the evolution of the state estimation error covariance. This first exercise invites you to solve this fundamental equation from first principles for a simple scalar system. By tackling this problem, you will demystify the filter's behavior, see how it balances system dynamics against process and measurement noise, and understand the conditions under which the estimation error converges to a stable, finite value [@problem_id:2913229].", "problem": "A linear time-invariant scalar continuous-time system with additive white process and measurement noise admits a state estimate produced by the Kalman–Bucy filter (KBF). In the scalar case, under standard Gaussian assumptions for the process and measurement noise, the KBF error covariance $P_t$ evolves according to a nonlinear first-order ordinary differential equation of Riccati type. Let $a \\in \\mathbb{R}$ denote the state matrix entry, $q > 0$ the process noise intensity, $c \\neq 0$ the measurement matrix entry, and $r > 0$ the measurement noise intensity. Assume all quantities are dimensionless. The covariance $P_t$ satisfies\n$$\n\\dot{P}_t \\equiv \\frac{d}{dt}P_t \\;=\\; 2 a\\, P_t \\;+\\; q \\;-\\; \\frac{c^{2}}{r}\\, P_t^{2}, \\qquad P_{t=0} = P_0 \\in \\mathbb{R}.\n$$\n\nUsing only fundamental facts from calculus about solving separable first-order nonlinear ordinary differential equations and the qualitative phase-line analysis of equilibria, do the following:\n\n1) Solve the differential equation for $P_t$ in closed form for general $a \\in \\mathbb{R}$, $q > 0$, $r > 0$, $c \\neq 0$, and $P_0 \\in \\mathbb{R}$.\n\n2) Analyze the existence of a finite steady-state limit $\\lim_{t \\to \\infty} P_t$. Identify the conditions on $P_0$ (as a function of $a$, $q$, $c$, $r$) under which the solution exists for all $t \\ge 0$ and converges to a finite steady-state value as $t \\to \\infty$.\n\n3) Report, as your final answer, the closed-form algebraic expression for the finite steady-state limit $P_{\\mathrm{ss}}$ in terms of the parameters $a$, $q$, $c$, and $r$, assuming it exists. Your final answer must be a single exact symbolic expression. Do not include units in your final answer.", "solution": "The problem presented is a standard initial value problem for a scalar Riccati differential equation, which is fundamental to the study of the continuous-time Kalman–Bucy filter. All parameters are defined, and the objectives are clear and mathematically formalizable. The problem is scientifically sound, well-posed, and objective. There are no flaws. We proceed to the solution.\n\nThe objective is to analyze the differential equation for the error covariance $P_t$:\n$$\n\\frac{dP_t}{dt} = 2a P_t + q - \\frac{c^2}{r} P_t^2\n$$\nwith initial condition $P_{t=0} = P_0$. The parameters $a \\in \\mathbb{R}$, $q > 0$, $r > 0$, and $c \\neq 0$ are given constants.\n\nThis is a first-order autonomous nonlinear ordinary differential equation. It is of separable form. We can write it as:\n$$\n\\frac{dP_t}{-\\frac{c^2}{r} P_t^2 + 2a P_t + q} = dt\n$$\n\n1) Solve the differential equation for $P_t$.\n\nTo integrate the left-hand side, we first find the roots of the quadratic polynomial in the denominator, which correspond to the equilibrium points of the differential equation:\n$$\n-\\frac{c^2}{r} P^2 + 2a P + q = 0\n$$\nUsing the quadratic formula, the roots $P_{\\pm}$ are:\n$$\nP_{\\pm} = \\frac{-2a \\pm \\sqrt{(2a)^2 - 4(-\\frac{c^2}{r})(q)}}{2(-\\frac{c^2}{r})} = \\frac{-2a \\pm \\sqrt{4a^2 + 4\\frac{c^2q}{r}}}{-2\\frac{c^2}{r}} = \\frac{a \\mp \\sqrt{a^2 + \\frac{c^2q}{r}}}{\\frac{c^2}{r}}\n$$\nLet us define the term $\\gamma = \\sqrt{a^2 + \\frac{c^2q}{r}}$. Since $q > 0$, $r > 0$, and $c \\neq 0$, the term $\\frac{c^2q}{r}$ is strictly positive. Thus, $\\gamma$ is always real and positive, and $\\gamma > \\sqrt{a^2} = |a|$. The two distinct real roots are:\n$$\nP_+ = \\frac{r}{c^2} (a + \\gamma) \\quad \\text{and} \\quad P_- = \\frac{r}{c^2} (a - \\gamma)\n$$\nSince $\\gamma > a$ and $\\gamma > -a$, it is clear that $P_+ > 0$ and $P_- < 0$. The denominator can now be factored as $-\\frac{c^2}{r} (P_t - P_+)(P_t - P_-)$.\n\nThe integral becomes:\n$$\n\\int_{P_0}^{P_t} \\frac{dP}{-\\frac{c^2}{r} (P - P_+)(P - P_-)} = \\int_0^t d\\tau = t\n$$\nUsing partial fraction decomposition for the integrand:\n$$\n\\frac{1}{(P - P_+)(P - P_-)} = \\frac{A}{P - P_+} + \\frac{B}{P - P_-}\n$$\nwhere $A = \\frac{1}{P_+ - P_-}$ and $B = \\frac{1}{P_- - P_+} = -A$.\nThe difference between the roots is $P_+ - P_- = \\frac{r}{c^2}(a + \\gamma) - \\frac{r}{c^2}(a - \\gamma) = \\frac{2r\\gamma}{c^2}$.\nSo, $A = \\frac{c^2}{2r\\gamma}$.\n\nSubstituting this back into the integral equation:\n$$\n-\\frac{r}{c^2} \\int_{P_0}^{P_t} \\left(\\frac{c^2}{2r\\gamma}\\right) \\left( \\frac{1}{P - P_+} - \\frac{1}{P - P_-} \\right) dP = t\n$$\n$$\n-\\frac{1}{2\\gamma} \\left[ \\ln|P - P_+| - \\ln|P - P_-| \\right]_{P_0}^{P_t} = t\n$$\n$$\n-\\frac{1}{2\\gamma} \\left( \\ln\\left|\\frac{P_t - P_+}{P_t - P_-}\\right| - \\ln\\left|\\frac{P_0 - P_+}{P_0 - P_-}\\right| \\right) = t\n$$\nRearranging for $P_t$:\n$$\n\\ln\\left|\\frac{P_t - P_+}{P_t - P_-}\\right| = \\ln\\left|\\frac{P_0 - P_+}{P_0 - P_-}\\right| - 2\\gamma t\n$$\n$$\n\\left|\\frac{P_t - P_+}{P_t - P_-}\\right| = \\left|\\frac{P_0 - P_+}{P_0 - P_-}\\right| \\exp(-2\\gamma t)\n$$\nAs long as the solution does not cross the equilibria $P_+$ or $P_-$, the sign of the term inside the absolute value remains constant. Assuming $P_0$ is not equal to $P_-$ or $P_+$, we can write:\n$$\n\\frac{P_t - P_+}{P_t - P_-} = \\left(\\frac{P_0 - P_+}{P_0 - P_-}\\right) \\exp(-2\\gamma t)\n$$\nLet the right-hand side be denoted by $K(t)$. Then $P_t - P_+ = K(t)(P_t - P_-)$. Solving for $P_t$:\n$$\nP_t(1 - K(t)) = P_+ - K(t)P_- \\implies P_t = \\frac{P_+ - K(t)P_-}{1 - K(t)}\n$$\nSubstituting the expression for $K(t)$, the closed-form solution is:\n$$\nP_t = \\frac{P_+ - P_-\\left(\\frac{P_0 - P_+}{P_0 - P_-}\\right) \\exp(-2\\gamma t)}{1 - \\left(\\frac{P_0 - P_+}{P_0 - P_-}\\right) \\exp(-2\\gamma t)}\n$$\nThis can be rewritten by multiplying the numerator and denominator by $(P_0 - P_-)\\exp(2\\gamma t)$:\n$$\nP_t = \\frac{P_+(P_0 - P_-)\\exp(2\\gamma t) - P_-(P_0 - P_+)}{(P_0 - P_-)\\exp(2\\gamma t) - (P_0 - P_+)}\n$$\nwhere $P_+ = \\frac{r}{c^2}(a + \\gamma)$ and $P_- = \\frac{r}{c^2}(a - \\gamma)$ with $\\gamma = \\sqrt{a^2 + \\frac{c^2q}{r}}$.\n\n2) Analysis of the steady-state limit and conditions for convergence.\n\nWe perform a qualitative phase-line analysis of $\\dot{P}_t = f(P_t) = -\\frac{c^2}{r}(P_t - P_+)(P_t - P_-)$. The function $f(P_t)$ is a downward-opening parabola with roots at $P_-$ and $P_+$.\n- For $P_t > P_+$, $f(P_t) < 0$, so $P_t$ decreases towards $P_+$.\n- For $P_- < P_t < P_+$, $f(P_t) > 0$, so $P_t$ increases towards $P_+$.\n- For $P_t < P_-$, $f(P_t) < 0$, so $P_t$ decreases towards $-\\infty$.\n\nThis analysis shows that $P_+$ is a stable equilibrium point, and $P_-$ is an unstable equilibrium point. Any solution starting with an initial condition $P_0 > P_-$ will converge to $P_+$ as $t \\to \\infty$. A solution starting with $P_0 < P_-$ will diverge to $-\\infty$ in finite time (a phenomenon known as finite-time escape). A solution starting at $P_0 = P_-$ remains at $P_-$ (in theory).\n\nFor the Kalman–Bucy filter, the quantity $P_t$ represents the error covariance, which must be non-negative. The initial condition must satisfy $P_0 \\ge 0$. We have established that $P_- < 0$. Therefore, any physically meaningful initial condition $P_0 \\ge 0$ automatically satisfies the mathematical condition for global existence and convergence, $P_0 > P_-$.\n\nFor any such $P_0 \\ge 0$, the solution $P_t$ exists for all $t \\ge 0$ and converges to a finite steady-state limit. The limit is found by taking $t \\to \\infty$ in the solution for $P_t$. As $t \\to \\infty$, the term $\\exp(-2\\gamma t) \\to 0$ because $\\gamma > 0$.\n$$\nP_{\\mathrm{ss}} = \\lim_{t \\to \\infty} P_t = \\frac{P_+ - P_-(0)}{1 - 0} = P_+\n$$\nSo, the steady-state limit is the stable equilibrium point $P_+$. This limit is finite and positive.\n\n3) Report the expression for the finite steady-state limit $P_{\\mathrm{ss}}$.\n\nThe finite steady-state limit is $P_{\\mathrm{ss}} = P_+$. Substituting the expressions for the parameters:\n$$\nP_{\\mathrm{ss}} = \\frac{r}{c^2} (a + \\gamma) = \\frac{r}{c^2} \\left( a + \\sqrt{a^2 + \\frac{c^2q}{r}} \\right)\n$$\nThis is the positive solution to the algebraic Riccati equation $2aP_{\\mathrm{ss}} + q - \\frac{c^2}{r}P_{\\mathrm{ss}}^2 = 0$. This value is guaranteed to be positive, as required for a covariance, because $\\sqrt{a^2 + \\frac{c^2q}{r}} > |a| \\ge -a$, which implies $a + \\sqrt{a^2 + \\frac{c^2q}{r}} > 0$.\nThe problem requires this single symbolic expression as the final answer.", "answer": "$$\n\\boxed{\\frac{r}{c^{2}} \\left( a + \\sqrt{a^{2} + \\frac{q c^{2}}{r}} \\right)}\n$$", "id": "2913229"}, {"introduction": "Moving from symbolic derivation to practical application, this next practice grounds the theory in a concrete numerical example. You will calculate the key parameters for a time-invariant filter: the steady-state error covariance $P$ and the corresponding optimal steady-state gain $K$. This involves solving the Algebraic Riccati Equation (ARE), the steady-state form of the Riccati differential equation, solidifying your understanding of how to design a practical filter for a specific system [@problem_id:2913252].", "problem": "Consider the continuous-time linear time-invariant stochastic system driven by zero-mean Gaussian white noises with finite spectral densities:\n$$\\dot{x}(t) = A\\,x(t) + w(t), \\qquad y(t) = C\\,x(t) + v(t),$$\nwhere $x(t) \\in \\mathbb{R}$ and $y(t) \\in \\mathbb{R}$. The process noise $w(t)$ and the measurement noise $v(t)$ are mutually uncorrelated and satisfy\n$$\\mathbb{E}\\!\\left[w(t)w(\\tau)\\right] = Q\\,\\delta(t-\\tau), \\qquad \\mathbb{E}\\!\\left[v(t)v(\\tau)\\right] = R\\,\\delta(t-\\tau), \\qquad \\mathbb{E}\\!\\left[w(t)v(\\tau)\\right] = 0,$$\nwith $Q > 0$ and $R > 0$. Let a continuous-time optimal estimator (the Kalman–Bucy filter) be constructed for this system using the steady-state gain. Using only fundamental definitions and first principles of second-order moment propagation for linear stochastic systems, determine the steady-state error covariance $P$ of the state estimation error and the corresponding steady-state gain $K$ for the specific numerical data\n$$A = 1, \\qquad C = 1, \\qquad Q = 2, \\qquad R = 1.$$\nReport the steady-state gain $K$ as your final answer in exact, closed form. Do not round. If intermediate quantities are computed, keep them in exact symbolic form throughout.", "solution": "The problem requires the determination of the steady-state error covariance $P$ and the corresponding steady-state optimal gain $K$ for a continuous-time scalar linear stochastic system. We will derive this from first principles as demanded.\n\nThe system is described by the state-space model:\n$$\n\\dot{x}(t) = A x(t) + w(t) \\\\\ny(t) = C x(t) + v(t)\n$$\nwhere $x(t), y(t) \\in \\mathbb{R}$. The process noise $w(t)$ and measurement noise $v(t)$ are zero-mean, mutually uncorrelated Gaussian white noise processes with spectral densities $Q$ and $R$ respectively:\n$$\n\\mathbb{E}[w(t)w(\\tau)] = Q \\delta(t-\\tau) \\\\\n\\mathbb{E}[v(t)v(\\tau)] = R \\delta(t-\\tau) \\\\\n\\mathbb{E}[w(t)v(\\tau)] = 0\n$$\nThe parameters are given as $A=1$, $C=1$, $Q=2$, and $R=1$.\n\nThe structure of the Kalman-Bucy filter is an observer with a gain $K$ that corrects the state estimate $\\hat{x}(t)$ based on the innovation, or measurement residual, $y(t) - C\\hat{x}(t)$. The dynamics of the state estimate are:\n$$\n\\dot{\\hat{x}}(t) = A \\hat{x}(t) + K \\left( y(t) - C\\hat{x}(t) \\right)\n$$\nThe state estimation error is defined as $e(t) = x(t) - \\hat{x}(t)$. To analyze the filter's performance, we first derive the dynamics of this error. Differentiating $e(t)$ with respect to time gives:\n$$\n\\dot{e}(t) = \\dot{x}(t) - \\dot{\\hat{x}}(t)\n$$\nSubstituting the expressions for $\\dot{x}(t)$, $\\dot{\\hat{x}}(t)$, and $y(t)$:\n$$\n\\dot{e}(t) = \\left( A x(t) + w(t) \\right) - \\left( A \\hat{x}(t) + K \\left( (C x(t) + v(t)) - C\\hat{x}(t) \\right) \\right)\n$$\nGrouping terms by $x(t)$, $\\hat{x}(t)$, $w(t)$, and $v(t)$:\n$$\n\\dot{e}(t) = A (x(t) - \\hat{x}(t)) - K C (x(t) - \\hat{x}(t)) + w(t) - K v(t)\n$$\nRecognizing that $e(t) = x(t) - \\hat{x}(t)$, the error dynamics are described by the linear stochastic differential equation:\n$$\n\\dot{e}(t) = (A - KC) e(t) + w(t) - K v(t)\n$$\nThis equation is of the general form $\\dot{z}(t) = F z(t) + G \\nu(t)$, where $z=e$, the system matrix is $F=A-KC$, the input matrix is $G = \\begin{pmatrix} 1 & -K \\end{pmatrix}$, and the noise input vector is $\\nu(t) = \\begin{pmatrix} w(t) \\\\ v(t) \\end{pmatrix}$.\n\nThe covariance of the noise vector $\\nu(t)$ is:\n$$\n\\mathbb{E}[\\nu(t)\\nu(\\tau)^T] = \\mathbb{E}\\left[ \\begin{pmatrix} w(t) \\\\ v(t) \\end{pmatrix} \\begin{pmatrix} w(\\tau) & v(\\tau) \\end{pmatrix} \\right] = \\begin{pmatrix} \\mathbb{E}[w(t)w(\\tau)] & \\mathbb{E}[w(t)v(\\tau)] \\\\ \\mathbb{E}[v(t)w(\\tau)] & \\mathbb{E}[v(t)v(\\tau)] \\end{pmatrix} = \\begin{pmatrix} Q\\delta(t-\\tau) & 0 \\\\ 0 & R\\delta(t-\\tau) \\end{pmatrix} = \\mathbf{Q}_{\\nu} \\delta(t-\\tau)\n$$\nwhere $\\mathbf{Q}_{\\nu} = \\begin{pmatrix} Q & 0 \\\\ 0 & R \\end{pmatrix}$.\n\nFor a general linear stochastic system $\\dot{z}(t) = F z(t) + G \\nu(t)$, the second-order moment, or covariance matrix $P_z(t) = \\mathbb{E}[z(t)z(t)^T]$, propagates according to the continuous-time Lyapunov equation:\n$$\n\\dot{P}_z(t) = F P_z(t) + P_z(t) F^T + G \\mathbf{Q}_{\\nu} G^T\n$$\nApplying this fundamental principle to our error dynamics, with $P(t) = \\mathbb{E}[e(t)e(t)^T]$, gives the differential equation for the error covariance:\n$$\n\\dot{P}(t) = (A-KC) P(t) + P(t) (A-KC)^T + \\begin{pmatrix} 1 & -K \\end{pmatrix} \\begin{pmatrix} Q & 0 \\\\ 0 & R \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -K \\end{pmatrix}\n$$\nThe noise term simplifies to:\n$$\n\\begin{pmatrix} 1 & -K \\end{pmatrix} \\begin{pmatrix} Q \\\\ -KR \\end{pmatrix} = Q + K R K^T\n$$\nThus, the error covariance propagation is described by:\n$$\n\\dot{P}(t) = (A-KC)P(t) + P(t)(A-KC)^T + Q + KRK^T\n$$\nThe optimal Kalman gain $K$ is chosen to minimize the error covariance $P(t)$. This is achieved by the well-known expression $K = P(t)C^T R^{-1}$. Substituting this optimal gain into the covariance equation yields the continuous-time differential Riccati equation (DRE):\n$$\n\\dot{P}(t) = A P(t) + P(t) A^T - P(t) C^T R^{-1} C P(t) + Q\n$$\nFor the steady-state solution, we assume that the filter reaches a stationary condition where the error covariance is constant, i.e., $\\dot{P}(t)=0$. Let $P$ denote this steady-state covariance. The DRE then reduces to the continuous-time Algebraic Riccati Equation (ARE):\n$$\n0 = A P + P A^T - P C^T R^{-1} C P + Q\n$$\nWe now substitute the given scalar values $A=1$, $C=1$, $Q=2$, and $R=1$ into the ARE. Since all parameters are scalars, the transpose operation is identity.\n$$\n0 = (1)P + P(1) - P(1)(1)^{-1}(1)P + 2\n$$\nThis simplifies to a quadratic equation for the scalar steady-state error covariance $P$:\n$$\nP^2 - 2P - 2 = 0\n$$\nWe solve this equation for $P$ using the quadratic formula $P = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$:\n$$\nP = \\frac{-(-2) \\pm \\sqrt{(-2)^2 - 4(1)(-2)}}{2(1)} = \\frac{2 \\pm \\sqrt{4 + 8}}{2} = \\frac{2 \\pm \\sqrt{12}}{2} = \\frac{2 \\pm 2\\sqrt{3}}{2}\n$$\nThe two possible solutions are $P_1 = 1 + \\sqrt{3}$ and $P_2 = 1 - \\sqrt{3}$. The error covariance matrix, by definition, must be positive semi-definite. Since $P$ is a scalar, this means $P \\ge 0$. The solution $P_2 = 1 - \\sqrt{3} \\approx 1 - 1.732 < 0$ is not physically meaningful. Therefore, the unique positive definite solution is:\n$$\nP = 1 + \\sqrt{3}\n$$\nFinally, we compute the corresponding steady-state Kalman gain $K$ using the formula $K = PC^T R^{-1}$:\n$$\nK = (1 + \\sqrt{3})(1)(1)^{-1} = 1 + \\sqrt{3}\n$$\nAs a verification, the closed-loop estimator dynamics are governed by the matrix $A-KC$. For the filter to be stable, its eigenvalues must have negative real parts. In this scalar case, we require $A-KC < 0$. Substituting the values:\n$$\nA - KC = 1 - (1+\\sqrt{3})(1) = 1 - 1 - \\sqrt{3} = -\\sqrt{3}\n$$\nSince $-\\sqrt{3} < 0$, the resulting filter is stable, which confirms the correctness of our solution for $P$. The required steady-state gain is $K$.", "answer": "$$\\boxed{1 + \\sqrt{3}}$$", "id": "2913252"}, {"introduction": "A stable, effective filter is not always guaranteed; its existence hinges on fundamental properties of the system. This practice explores the crucial concept of detectability, which requires that any unstable dynamics within the system must be observable through the measurements. By analyzing a hypothetical system where this condition is violated, you will witness firsthand why the estimation error covariance can diverge, underscoring detectability as an essential prerequisite for a functioning Kalman-Bucy filter [@problem_id:2913249].", "problem": "Consider the continuous-time linear time-invariant stochastic system with process and measurement models\n$$\n\\mathrm{d}x(t) \\;=\\; A\\,x(t)\\,\\mathrm{d}t \\;+\\; \\mathrm{d}w(t),\\qquad \\mathrm{d}y(t) \\;=\\; C\\,x(t)\\,\\mathrm{d}t \\;+\\; \\mathrm{d}v(t),\n$$\nwhere $x(t)\\in\\mathbb{R}^{2}$, $y(t)\\in\\mathbb{R}$, and the driving noises are zero-mean Gaussian with spectral densities\n$$\n\\mathbb{E}\\big[\\mathrm{d}w(t)\\,\\mathrm{d}w(t)^{\\top}\\big] \\;=\\; Q\\,\\mathrm{d}t,\\qquad \\mathbb{E}\\big[\\mathrm{d}v(t)\\,\\mathrm{d}v(t)^{\\top}\\big] \\;=\\; R\\,\\mathrm{d}t.\n$$\nLet\n$$\nA \\;=\\; \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\qquad C \\;=\\; \\begin{pmatrix} 0 & 1 \\end{pmatrix},\\qquad Q \\;=\\; \\begin{pmatrix} q & 0 \\\\ 0 & q_s \\end{pmatrix},\\qquad R \\;=\\; r,\n$$\nwith $q>0$, $q_s>0$, and $r>0$. Assume the initial error covariance for the Kalman–Bucy filter is diagonal,\n$$\nP(0) \\;=\\; \\begin{pmatrix} p_0 & 0 \\\\ 0 & p_{s0} \\end{pmatrix},\n$$\nwith $p_0>0$ and $p_{s0}>0$.\n\nTasks:\n- Using only core definitions from linear systems theory, argue whether the pair $(A,C)$ is detectable.\n- Starting from the Riccati differential equation of the Kalman–Bucy filter, and without invoking any pre-simplified special-case formulas, derive the scalar differential equation governing the $(1,1)$ element $P_{11}(t)$ of the error covariance $P(t)$, and solve it in closed form.\n- Conclude whether $P_{11}(t)$ diverges as $t\\to\\infty$ and explain why this behavior is tied to detectability.\n\nProvide, as your final answer, the exact closed-form expression for $P_{11}(t)$ in terms of $t$, $p_0$, and $q$. Do not round. No units are required.", "solution": "The problem will be validated against the required criteria before a solution is attempted.\n\nFirst, the givens are extracted verbatim from the problem statement:\n- Process model: $\\mathrm{d}x(t) = A\\,x(t)\\,\\mathrm{d}t + \\mathrm{d}w(t)$\n- Measurement model: $\\mathrm{d}y(t) = C\\,x(t)\\,\\mathrm{d}t + \\mathrm{d}v(t)$\n- State and measurement vectors: $x(t)\\in\\mathbb{R}^{2}$, $y(t)\\in\\mathbb{R}$\n- Noise properties: zero-mean Gaussian with spectral densities $\\mathbb{E}[\\mathrm{d}w(t)\\,\\mathrm{d}w(t)^{\\top}] = Q\\,\\mathrm{d}t$ and $\\mathbb{E}[\\mathrm{d}v(t)\\,\\mathrm{d}v(t)^{\\top}] = R\\,\\mathrm{d}t$.\n- System matrices and parameters:\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix},\\quad C = \\begin{pmatrix} 0 & 1 \\end{pmatrix},\\quad Q = \\begin{pmatrix} q & 0 \\\\ 0 & q_s \\end{pmatrix},\\quad R = r,\n$$\nwith $q>0$, $q_s>0$, and $r>0$.\n- Initial error covariance:\n$$\nP(0) = \\begin{pmatrix} p_0 & 0 \\\\ 0 & p_{s0} \\end{pmatrix},\n$$\nwith $p_0>0$ and $p_{s0}>0$.\n\nThe problem is scientifically grounded in linear systems theory and stochastic estimation. It is well-posed, with all necessary data and conditions provided. The parameters are consistent and the problem structure is standard for an analysis of the Kalman–Bucy filter. There are no contradictions, ambiguities, or factual unsoundness. The problem is deemed valid and a solution will be provided.\n\nThe solution is organized into three parts as requested by the problem statement.\n\nPart 1: Detectability analysis of the pair $(A,C)$.\nA linear time-invariant system pair $(A,C)$ is defined as detectable if all its unstable or marginally stable modes are observable. The modes of the system are determined by the eigenvalues of the matrix $A$. Since $A$ is a diagonal matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = 1$ and $\\lambda_2 = -1$.\nA mode associated with an eigenvalue $\\lambda$ is stable if $\\text{Re}(\\lambda) < 0$, and unstable or marginally stable if $\\text{Re}(\\lambda) \\geq 0$.\nIn this case, $\\lambda_1 = 1$ corresponds to an unstable mode since $\\text{Re}(\\lambda_1) = 1 > 0$. The eigenvalue $\\lambda_2 = -1$ corresponds to a stable mode since $\\text{Re}(\\lambda_2) = -1 < 0$.\nFor the pair $(A,C)$ to be detectable, the unstable mode associated with $\\lambda_1 = 1$ must be observable.\nThe observability of a mode can be determined using the Popov-Hautus-Belevitch (PHB) test. A mode $\\lambda$ is observable if and only if the matrix\n$$\n\\begin{pmatrix} A - \\lambda I \\\\ C \\end{pmatrix}\n$$\nhas full column rank. The rank must be equal to the dimension of the state space, which is $2$.\nWe apply this test to the unstable eigenvalue $\\lambda_1 = 1$:\n$$\n\\begin{pmatrix} A - 1 \\cdot I \\\\ C \\end{pmatrix} = \\begin{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\\\ \\begin{pmatrix} 0 & 1 \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} 0 & 0 \\\\ 0 & -2 \\\\ 0 & 1 \\end{pmatrix}.\n$$\nThe columns of this matrix are $\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}$ and $\\begin{pmatrix} 0 \\\\ -2 \\\\ 1 \\end{pmatrix}$. The first column is the zero vector, which means the columns are linearly dependent. The rank of this matrix is $1$, which is less than the required full column rank of $2$.\nTherefore, the mode associated with the eigenvalue $\\lambda_1=1$ is not observable. Since an unstable mode is not observable, the pair $(A,C)$ is not detectable.\n\nPart 2: Derivation and solution of the differential equation for $P_{11}(t)$.\nThe error covariance matrix $P(t)$ for the Kalman–Bucy filter evolves according to the Riccati differential equation (RDE):\n$$\n\\frac{\\mathrm{d}P(t)}{\\mathrm{d}t} = \\dot{P}(t) = A P(t) + P(t) A^{\\top} + Q - P(t) C^{\\top} R^{-1} C P(t).\n$$\nLet the symmetric matrix $P(t)$ be partitioned as $P(t) = \\begin{pmatrix} P_{11}(t) & P_{12}(t) \\\\ P_{21}(t) & P_{22}(t) \\end{pmatrix}$, where $P_{12}(t) = P_{21}(t)$.\nWe substitute the given matrices into the RDE. Note that $A^{\\top}=A$, $R^{-1} = 1/r$.\nThe term $A P(t) + P(t) A^{\\top}$ becomes:\n$$\n\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} \\begin{pmatrix} P_{11} & P_{12} \\\\ P_{12} & P_{22} \\end{pmatrix} + \\begin{pmatrix} P_{11} & P_{12} \\\\ P_{12} & P_{22} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix} = \\begin{pmatrix} P_{11} & P_{12} \\\\ -P_{12} & -P_{22} \\end{pmatrix} + \\begin{pmatrix} P_{11} & -P_{12} \\\\ P_{12} & -P_{22} \\end{pmatrix} = \\begin{pmatrix} 2P_{11} & 0 \\\\ 0 & -2P_{22} \\end{pmatrix}.\n$$\nThe nonlinear term $P(t) C^{\\top} R^{-1} C P(t)$ becomes:\n$$\nC^{\\top}R^{-1}C = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\frac{1}{r} \\begin{pmatrix} 0 & 1 \\end{pmatrix} = \\frac{1}{r} \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix}.\n$$\n$$\nP(t) (C^{\\top} R^{-1} C) P(t) = \\begin{pmatrix} P_{11} & P_{12} \\\\ P_{12} & P_{22} \\end{pmatrix} \\left( \\frac{1}{r} \\begin{pmatrix} 0 & 0 \\\\ 0 & 1 \\end{pmatrix} \\right) \\begin{pmatrix} P_{11} & P_{12} \\\\ P_{12} & P_{22} \\end{pmatrix} = \\frac{1}{r} \\begin{pmatrix} P_{11} & P_{12} \\\\ P_{12} & P_{22} \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ P_{12} & P_{22} \\end{pmatrix} = \\frac{1}{r} \\begin{pmatrix} P_{12}^2 & P_{12}P_{22} \\\\ P_{12}P_{22} & P_{22}^2 \\end{pmatrix}.\n$$\nCombining all terms, the RDE is:\n$$\n\\begin{pmatrix} \\dot{P}_{11} & \\dot{P}_{12} \\\\ \\dot{P}_{12} & \\dot{P}_{22} \\end{pmatrix} = \\begin{pmatrix} 2P_{11} & 0 \\\\ 0 & -2P_{22} \\end{pmatrix} + \\begin{pmatrix} q & 0 \\\\ 0 & q_s \\end{pmatrix} - \\frac{1}{r} \\begin{pmatrix} P_{12}^2 & P_{12}P_{22} \\\\ P_{12}P_{22} & P_{22}^2 \\end{pmatrix}.\n$$\nThis matrix equation yields a system of three coupled scalar ordinary differential equations:\n1. $\\dot{P}_{11}(t) = 2P_{11}(t) + q - \\frac{1}{r}P_{12}(t)^2$\n2. $\\dot{P}_{12}(t) = -\\frac{1}{r}P_{12}(t)P_{22}(t)$\n3. $\\dot{P}_{22}(t) = -2P_{22}(t) + q_s - \\frac{1}{r}P_{22}(t)^2$\n\nThe initial condition is $P(0)$ is diagonal, which means $P_{12}(0) = 0$. Consider the differential equation for $P_{12}(t)$:\n$$\n\\dot{P}_{12}(t) = f(t) P_{12}(t), \\quad \\text{where } f(t) = -\\frac{P_{22}(t)}{r}.\n$$\nThis is a linear homogeneous ODE for $P_{12}(t)$. With the initial condition $P_{12}(0) = 0$, the unique solution is $P_{12}(t) = 0$ for all $t \\geq 0$.\nSubstituting $P_{12}(t) = 0$ into the equation for $P_{11}(t)$ simplifies it to:\n$$\n\\dot{P}_{11}(t) = 2P_{11}(t) + q.\n$$\nThis is a first-order linear inhomogeneous ordinary differential equation with initial condition $P_{11}(0)=p_0$. We can rewrite it as $\\dot{P}_{11} - 2P_{11} = q$.\nThe integrating factor is $\\mu(t) = \\exp(\\int -2 \\mathrm{d}t) = \\exp(-2t)$. Multiplying the equation by $\\mu(t)$ gives:\n$$\n\\exp(-2t)\\dot{P}_{11}(t) - 2\\exp(-2t)P_{11}(t) = q\\exp(-2t).\n$$\nThe left side is the derivative of a product:\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}t}\\left( \\exp(-2t) P_{11}(t) \\right) = q\\exp(-2t).\n$$\nIntegrating from $0$ to $t$:\n$$\n\\int_0^t \\frac{\\mathrm{d}}{\\mathrm{d}\\tau}\\left( \\exp(-2\\tau) P_{11}(\\tau) \\right) \\mathrm{d}\\tau = \\int_0^t q\\exp(-2\\tau) \\mathrm{d}\\tau.\n$$\n$$\n\\exp(-2t)P_{11}(t) - \\exp(0)P_{11}(0) = q \\left[ -\\frac{1}{2}\\exp(-2\\tau) \\right]_0^t.\n$$\n$$\n\\exp(-2t)P_{11}(t) - p_0 = -\\frac{q}{2}(\\exp(-2t) - 1).\n$$\nSolving for $P_{11}(t)$:\n$$\n\\exp(-2t)P_{11}(t) = p_0 - \\frac{q}{2}\\exp(-2t) + \\frac{q}{2}.\n$$\n$$\nP_{11}(t) = p_0 \\exp(2t) - \\frac{q}{2} + \\frac{q}{2}\\exp(2t).\n$$\nCombining terms, the closed-form solution is:\n$$\nP_{11}(t) = \\left(p_0 + \\frac{q}{2}\\right)\\exp(2t) - \\frac{q}{2}.\n$$\n\nPart 3: Asymptotic behavior of $P_{11}(t)$ and its connection to detectability.\nThe solution for $P_{11}(t)$ is $P_{11}(t) = (p_0 + q/2)\\exp(2t) - q/2$. We are given that $p_0 > 0$ and $q > 0$, which implies that the coefficient $(p_0 + q/2)$ is strictly positive. As $t \\to \\infty$, the term $\\exp(2t)$ grows without bound. Consequently, $P_{11}(t)$ diverges to infinity.\n$$\n\\lim_{t \\to \\infty} P_{11}(t) = \\infty.\n$$\nThis behavior is directly tied to the non-detectability of the pair $(A,C)$. The state variable $x_1(t)$ is governed by the unstable dynamics $\\mathrm{d}x_1 = x_1 \\mathrm{d}t + \\mathrm{d}w_1$. The measurement $\\mathrm{d}y = x_2 \\mathrm{d}t + \\mathrm{d}v$ provides no information about $x_1(t)$. This is the physical meaning of the first state's mode being unobservable.\nThe Kalman–Bucy filter estimates the state by combining predictions from the system model with corrections from the measurements. The error covariance $P(t)$ quantifies the uncertainty of this estimate.\nThe element $P_{11}(t)$ represents the variance of the estimation error for the state $x_1(t)$. Since no measurements can be used to correct the estimate of $x_1(t)$, the filter's estimate of this state is based purely on the model. The equation $\\dot{P}_{11} = 2P_{11} + q$ shows that the error variance grows due to two sources: the inherent instability of the process (the $2P_{11}$ term) and the continuous injection of process noise (the $q$ term). There is no stabilizing term from the measurement update, which would appear as a negative quadratic term in $P$, because the Kalman gain for the first state is zero ($K_1 = P_{12}/r = 0$).\nThus, the uncertainty in the unobservable, unstable state $x_1(t)$ grows unboundedly. This is a fundamental consequence of non-detectability: the filter is unable to produce a bounded-error estimate for the entire state vector. If the system were detectable, any unstable modes would be observable, and the filter would stabilize the error dynamics for these modes, leading to a bounded (and typically convergent) error covariance matrix $P(t)$.", "answer": "$$\\boxed{\\left(p_0 + \\frac{q}{2}\\right) \\exp(2t) - \\frac{q}{2}}$$", "id": "2913249"}]}