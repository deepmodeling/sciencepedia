{"hands_on_practices": [{"introduction": "The separation principle is a cornerstone of modern control theory, enabling a modular approach to designing controllers for stochastic systems. However, its powerful result—that an optimal estimator and an optimal state-feedback controller can be designed independently—rests on a specific set of assumptions. This first practice challenges you to precisely identify these foundational requirements for the standard Linear Quadratic Gaussian (LQG) problem, ensuring you can confidently determine when this elegant principle is guaranteed to apply. [@problem_id:2913855]", "problem": "Consider a discrete-time Linear Time-Invariant (LTI) stochastic system\n$$\nx_{k+1} = A x_k + B u_k + w_k, \\quad y_k = C x_k + v_k,\n$$\nwhere $x_k \\in \\mathbb{R}^{n}$ is the state, $u_k \\in \\mathbb{R}^{m}$ is the control input, and $y_k \\in \\mathbb{R}^{p}$ is the measurement. The random vectors $w_k$ and $v_k$ are zero-mean noise processes with time-invariant second moments, and the initial state $x_0$ is a random vector with finite second moments. Consider the partially observed infinite-horizon quadratic cost\n$$\nJ = \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\big(x_k^{\\top} Q x_k + u_k^{\\top} R u_k\\big)\\Bigg],\n$$\nwith $Q \\succeq 0$ and $R \\succ 0$. Suppose we use the output-feedback control law\n$$\nu_k = -K \\,\\hat x_k,\n$$\nwhere $\\hat x_k$ is produced by the (steady-state) Kalman filter and $K$ is a constant state-feedback gain designed for the fully observed Linear Quadratic Regulator (LQR) problem.\n\nFrom first principles of stochastic optimal control and estimation theory, select the complete set of assumptions under which the above controller is optimal in the sense of minimizing $J$ over all admissible output-feedback control laws. Your answer should identify which option(s) give sufficient conditions that are both necessary in standard formulations and scientifically minimal for the Linear Quadratic Gaussian (LQG) separation principle to hold in the infinite-horizon setting.\n\nOptions:\n- A. The system is linear time-invariant; $w_k$ and $v_k$ are zero-mean white Gaussian processes with known covariances, mutually independent and independent of $x_0$; $Q \\succeq 0$, $R \\succ 0$, and the pairs $(A,B)$ and $(A,C)$ are, respectively, stabilizable and detectable so that the associated algebraic Riccati equations admit stabilizing solutions; the Kalman filter uses the correct covariances and the LQR gain $K$ is the stabilizing state-feedback gain computed for the fully observed problem. Under these, $u_k=-K\\hat x_k$ is optimal.\n\n- B. The system is linear time-invariant; $w_k$ and $v_k$ are zero-mean, finite-variance (but not necessarily Gaussian) white noises; $Q \\succeq 0$, $R \\succ 0$, and $(A,B)$ is stabilizable. Even if $(A,C)$ is not detectable and the noise is non-Gaussian, $u_k=-K\\hat x_k$ remains globally optimal among all measurable output-feedback laws by the separation principle.\n\n- C. The system is linear time-invariant; the measurement matrix $C$ has full column rank; $Q \\succeq 0$, $R \\succ 0$. As long as $K$ stabilizes $A-BK$, the controller $u_k=-K\\hat x_k$ is optimal regardless of the noise statistics because the closed loop is stable.\n\n- D. The system is linear time-invariant; $(w_k, v_k)$ are jointly zero-mean white Gaussian with known second-order statistics that may include nonzero cross-covariance $\\mathbb{E}[w_k v_k^{\\top}]\\neq 0$, and are independent of $x_0$; $Q \\succeq 0$, $R \\succ 0$; the problem data are such that the steady-state Kalman filter (accounting for the cross-covariance) and the LQR both admit stabilizing algebraic Riccati solutions; the Kalman filter and $K$ are designed with the true covariances. Under these, $u_k=-K\\hat x_k$ is optimal.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n-   Discrete-time Linear Time-Invariant (LTI) stochastic system:\n    $$x_{k+1} = A x_k + B u_k + w_k$$\n    $$y_k = C x_k + v_k$$\n-   State vector: $x_k \\in \\mathbb{R}^{n}$\n-   Control input: $u_k \\in \\mathbb{R}^{m}$\n-   Measurement output: $y_k \\in \\mathbb{R}^{p}$\n-   Process noise $w_k$ and measurement noise $v_k$ are zero-mean random vectors with time-invariant second moments.\n-   Initial state $x_0$ is a random vector with finite second moments.\n-   Cost function: Infinite-horizon quadratic cost\n    $$J = \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\big(x_k^{\\top} Q x_k + u_k^{\\top} R u_k\\big)\\Bigg]$$\n-   Cost matrices properties: $Q \\succeq 0$ and $R \\succ 0$.\n-   Proposed control law: $u_k = -K \\,\\hat x_k$, which is an output-feedback law.\n-   State estimate $\\hat x_k$ is the output of a steady-state Kalman filter.\n-   State-feedback gain $K$ is a constant gain from the fully observed Linear Quadratic Regulator (LQR) problem.\n-   Question: Identify the complete set of assumptions under which this controller is optimal for minimizing $J$ over all admissible output-feedback control laws, specifically focusing on conditions that are sufficient, necessary in standard formulations, and scientifically minimal for the LQG separation principle.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientifically Grounded:** The problem describes the canonical Linear Quadratic Gaussian (LQG) control problem for a discrete-time LTI system. This is a cornerstone of modern stochastic control theory and is based on well-established mathematical principles. The problem is scientifically sound.\n-   **Well-Posed:** The problem is well-posed. It asks for the standard assumptions underpinning the celebrated separation principle of stochastic optimal control, which provides a unique and meaningful solution to the LQG problem.\n-   **Objective:** The problem is stated using precise, objective mathematical language, free of any subjectivity.\n-   **Completeness and Consistency:** The problem provides the general framework of an LTI system with a quadratic cost and asks for the specific assumptions necessary to ensure the optimality of a certain controller structure. This framing is valid and does not suffer from incompleteness or contradiction.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It is a standard, well-posed problem in control theory. I will proceed to derive the solution.\n\n**Derivation from First Principles**\n\nThe problem is to find a control sequence $\\{u_k\\}_{k=0}^\\infty$, where each $u_k$ is a causal function of the measurement history $Y_k = \\{y_0, y_1, \\dots, y_k\\}$, that minimizes the cost $J$. This is the Linear Quadratic Gaussian (LQG) problem. The solution is famously given by the **separation principle**.\n\nThe principle states that the optimal controller can be designed in two separate stages:\n1.  **Optimal State Estimation:** Design an optimal estimator for the state $x_k$ based on the measurements $Y_k$. The optimal estimate, in the sense of minimizing the mean squared error of each state component, is the conditional mean $\\hat{x}_k = \\mathbb{E}[x_k | Y_k]$. For a linear system with Gaussian noise, this optimal estimate is generated by the Kalman filter.\n2.  **Optimal State-Feedback Control:** Solve the deterministic LQR problem, assuming the state $x_k$ is known perfectly. This yields the optimal state-feedback control law $u_k = -K x_k$.\n\nThe separation principle asserts that the optimal stochastic controller is obtained by simply replacing the true state $x_k$ in the deterministic optimal control law with its optimal estimate $\\hat{x}_k$, resulting in $u_k = -K \\hat{x}_k$.\n\nThe mathematical justification relies on the decomposition of the cost function. Let the estimation error be $\\tilde{x}_k = x_k - \\hat{x}_k$. The cost function can be rewritten as:\n$$J = \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\left( (\\hat{x}_k + \\tilde{x}_k)^{\\top} Q (\\hat{x}_k + \\tilde{x}_k) + u_k^{\\top} R u_k \\right)\\Bigg]$$\nExpanding this gives:\n$$J = \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\left( \\hat{x}_k^{\\top} Q \\hat{x}_k + u_k^{\\top} R u_k + \\tilde{x}_k^{\\top} Q \\tilde{x}_k + 2\\hat{x}_k^{\\top} Q \\tilde{x}_k \\right)\\Bigg]$$\nA key property of the Kalman filter (when noise is Gaussian) is that the estimation error $\\tilde{x}_k$ is zero-mean and orthogonal to the space of all functions of the measurement history $Y_k$. Since $\\hat{x}_k$ is a function of $Y_k$, the cross-term's expectation is zero: $\\mathbb{E}[\\hat{x}_k^{\\top} Q \\tilde{x}_k] = 0$.\nThe cost function separates into two independent parts:\n$$J = \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\big(\\hat{x}_k^{\\top} Q \\hat{x}_k + u_k^{\\top} R u_k \\big)\\Bigg] + \\mathbb{E}\\Bigg[\\sum_{k=0}^{\\infty} \\big(\\tilde{x}_k^{\\top} Q \\tilde{x}_k \\big)\\Bigg]$$\nThe first term is the control cost, which depends on the control law $u_k$. The second term is the estimation cost, which depends only on the system noise, initial state uncertainty, and the filter design, but is *independent* of the control law $u_k$.\n\nTo minimize $J$, we only need to minimize the first term. The dynamics of the state estimate $\\hat{x}_k$ are given by the Kalman filter equations, which can be viewed as a system driven by the innovations process. Minimizing the first term is an LQR problem for the state estimate $\\hat{x}_k$, whose solution is indeed $u_k = -K \\hat{x}_k$, where $K$ is the gain from the deterministic LQR problem.\n\nFor this entire framework to be valid for the infinite-horizon case, the following conditions are necessary:\n1.  **Linear System, Quadratic Cost**: This is the \"LQ\" part. (Given).\n2.  **Gaussian Noise**: The process noise $w_k$, measurement noise $v_k$, and initial state $x_0$ must be (jointly) Gaussian. This is the \"G\" part. This ensures the Kalman filter is the true conditional mean estimator and not just the best linear estimator, which is critical for the cost separation via orthogonality. The noises must also be white processes with known covariances.\n3.  **Existence of Steady-State Solutions**: For the infinite-horizon problem, we need steady-state controller and estimator gains. This requires that the respective algebraic Riccati equations (AREs) have unique, positive-semidefinite, stabilizing solutions. Sufficient conditions for this are:\n    *   For the LQR controller: The pair $(A, B)$ must be stabilizable. (The condition on $(A, Q^{1/2})$ being detectable is also needed but often implicitly assumed through problem formulation ensuring finite cost).\n    *   For the Kalman filter: The pair $(A, C)$ must be detectable. (The condition on $(A, W^{1/2})$ being stabilizable, where $W$ is the covariance of $w_k$, is also needed to ensure the error covariance remains bounded).\n\n**Option-by-Option Analysis**\n\n- **A. The system is linear time-invariant; $w_k$ and $v_k$ are zero-mean white Gaussian processes with known covariances, mutually independent and independent of $x_0$; $Q \\succeq 0$, $R \\succ 0$, and the pairs $(A,B)$ and $(A,C)$ are, respectively, stabilizable and detectable so that the associated algebraic Riccati equations admit stabilizing solutions; the Kalman filter uses the correct covariances and the LQR gain $K$ is the stabilizing state-feedback gain computed for the fully observed problem. Under these, $u_k=-K\\hat x_k$ is optimal.**\n  This option correctly lists all the assumptions of the classic, standard formulation of the discrete-time infinite-horizon LQG problem. It includes linearity, quadratic cost, Gaussian white noise (with independence), and the correct stabilizability/detectability conditions for the existence of a stable, optimal, steady-state solution. The statement that the controller is optimal under these conditions is a fundamental theorem of stochastic control.\n  **Verdict: Correct.**\n\n- **B. The system is linear time-invariant; $w_k$ and $v_k$ are zero-mean, finite-variance (but not necessarily Gaussian) white noises; $Q \\succeq 0$, $R \\succ 0$, and $(A,B)$ is stabilizable. Even if $(A,C)$ is not detectable and the noise is non-Gaussian, $u_k=-K\\hat x_k$ remains globally optimal among all measurable output-feedback laws by the separation principle.**\n  This option contains multiple severe errors. First, if the noise is not Gaussian, the Kalman filter is only the best *linear* estimator. The separation principle does not hold in general, and the controller $u_k=-K\\hat{x}_k$ is not optimal among all (possibly nonlinear) controllers. Second, if the pair $(A,C)$ is not detectable, there are unobservable modes of the system. If any of these modes are unstable, the state estimation error will be unbounded, the steady-state Kalman filter does not exist or is not stable, and the overall closed-loop system cannot be stabilized. The cost $J$ would become infinite.\n  **Verdict: Incorrect.**\n\n- **C. The system is linear time-invariant; the measurement matrix $C$ has full column rank; $Q \\succeq 0$, $R \\succ 0$. As long as $K$ stabilizes $A-BK$, the controller $u_k=-K\\hat x_k$ is optimal regardless of the noise statistics because the closed loop is stable.**\n  This option is also flawed. The condition that $C$ has full column rank is a strong condition related to observability, but it is neither necessary (detectability is) nor sufficient on its own. The claim that optimality holds \"regardless of the noise statistics\" is false, as explained for Option B. The Gaussian assumption is essential. Furthermore, stability of the closed-loop system is a necessary outcome of an optimal solution for this problem, but it is not a sufficient condition for optimality. Many stable controllers exist that are not optimal with respect to minimizing the quadratic cost $J$.\n  **Verdict: Incorrect.**\n\n- **D. The system is linear time-invariant; $(w_k, v_k)$ are jointly zero-mean white Gaussian with known second-order statistics that may include nonzero cross-covariance $\\mathbb{E}[w_k v_k^{\\top}]\\neq 0$, and are independent of $x_0$; $Q \\succeq 0$, $R \\succ 0$; the problem data are such that the steady-state Kalman filter (accounting for the cross-covariance) and the LQR both admit stabilizing algebraic Riccati solutions; the Kalman filter and $K$ are designed with the true covariances. Under these, $u_k=-K\\hat x_k$ is optimal.**\n  This option describes a standard and important generalization of the LQG problem where the process and measurement noises are correlated. The separation principle still holds under these conditions. The LQR portion of the design remains unchanged, while the Kalman filter equations are modified to account for the cross-covariance term $\\mathbb{E}[w_k v_k^{\\top}]$. The assumptions listed (jointly Gaussian noise, existence of stabilizing Riccati solutions) are sufficient for the optimality of the $u_k=-K\\hat{x}_k$ controller, where $\\hat{x}_k$ is now from the modified Kalman filter. This option correctly states a more general case where the LQG controller is optimal. It is a more \"scientifically minimal\" set of assumptions than in Option A, as it does not require the unnecessary constraint of noise independence.\n  **Verdict: Correct.**\n\nBoth options A and D describe valid, sufficient sets of conditions under which the given controller is optimal. Option D is a generalization of Option A. The question asks to \"select the complete set of assumptions\" and to \"identify which option(s)\" are correct. Both A and D are factually correct statements describing a scenario where the separation principle holds. Therefore, both are correct answers.", "answer": "$$\\boxed{AD}$$", "id": "2913855"}, {"introduction": "Having established the conditions under which the separation principle holds, we now explore its limitations. A common misconception is that if one can design a stabilizing state-feedback controller and a stable state observer, combining them will always work. This exercise forces a deeper look at the structural properties of the system, demonstrating why the separation architecture cannot overcome fundamental limitations imposed by unstable modes that are either uncontrollable or unobservable. [@problem_id:2913880]", "problem": "Consider a continuous-time Linear Time-Invariant (LTI) Single-Input Single-Output (SISO) plant given by\n$$\\dot{x}(t)=A x(t)+B u(t),\\qquad y(t)=C x(t),$$\nwhere $x(t)\\in\\mathbb{R}^n$, $u(t)\\in\\mathbb{R}$, and $y(t)\\in\\mathbb{R}$. An output-feedback controller is implemented via the separation architecture: a Luenberger observer feeding a state-feedback law that uses the state estimate,\n$$u(t)=-K\\,\\hat{x}(t),\\qquad \\dot{\\hat{x}}(t)=A \\hat{x}(t)+B u(t)+L\\big(y(t)-C \\hat{x}(t)\\big),$$\nwhere $K\\in\\mathbb{R}^{1\\times n}$ and $L\\in\\mathbb{R}^{n\\times 1}$ are constant gains. Use only the fundamental definitions of controllability, observability, stabilizability, detectability, and the plant/controller interconnection given above. In particular:\n- The pair $(A,B)$ is controllable if and only if every state is reachable by suitable inputs, and stabilizable if and only if every eigenvalue $\\lambda$ of $A$ with $\\operatorname{Re}(\\lambda)\\ge 0$ is controllable.\n- The pair $(C,A)$ is observable if and only if every state is reconstructible from outputs, and detectable if and only if every eigenvalue $\\lambda$ of $A$ with $\\operatorname{Re}(\\lambda)\\ge 0$ is observable.\n\nSuppose there exists at least one eigenvalue $\\lambda_u$ of $A$ with $\\operatorname{Re}(\\lambda_u)>0$ that is either uncontrollable (with respect to $B$) or unobservable (with respect to $C$). All other modes may be controllable or observable, so the plant may be partially stabilizable or detectable, but not fully stabilizable or detectable. You attempt to perform output-feedback pole placement via the separation principle by choosing $K$ and $L$.\n\nWhich of the following statements correctly explain why arbitrary output-feedback pole placement via this separation architecture may be impossible in this situation?\n\nA. Even with partial stabilizability or detectability, any eigenvalues of $A$ in the open right half-plane that are uncontrollable or unobservable necessarily persist as closed-loop eigenvalues under the separation architecture, so arbitrary pole placement is impossible.\n\nB. Choosing $L$ with sufficiently large gain can move unobservable unstable modes of $A$ to the open left half-plane because the observer dynamics can overpower a lack of observability.\n\nC. If $(A,B)$ is stabilizable and $(C,A)$ is detectable, then for any desired multiset of closed-loop poles there exist $K$ and $L$ such that output feedback via separation assigns all closed-loop poles arbitrarily, including those associated with uncontrollable or unobservable subspaces.\n\nD. In the Kalman controllability/observability decomposition, any uncontrollable or unobservable unstable blocks evolve autonomously and their eigenvalues must appear in the closed-loop characteristic polynomial of the separated design, precluding arbitrary pole placement by separation when such blocks lie in the open right half-plane.\n\nE. Introducing strictly proper frequency-dependent dynamics into $K$ or $L$ within the same separation structure can relocate a plant eigenvalue corresponding to an uncontrollable right-half-plane mode to the open left half-plane, thereby restoring arbitrary pole placement.", "solution": "The problem statement shall first be subjected to rigorous validation.\n\n**Step 1: Extract Givens**\n- Plant Dynamics: A continuous-time Linear Time-Invariant (LTI) Single-Input Single-Output (SISO) system.\n- State Equation: $\\dot{x}(t)=A x(t)+B u(t)$, where $x(t)\\in\\mathbb{R}^n$, $u(t)\\in\\mathbb{R}$.\n- Output Equation: $y(t)=C x(t)$, where $y(t)\\in\\mathbb{R}$.\n- Controller Architecture: Separation principle with a Luenberger observer and state-feedback.\n- Control Law: $u(t)=-K\\,\\hat{x}(t)$, where $K\\in\\mathbb{R}^{1\\times n}$.\n- Observer Dynamics: $\\dot{\\hat{x}}(t)=A \\hat{x}(t)+B u(t)+L\\big(y(t)-C \\hat{x}(t)\\big)$, where $L\\in\\mathbb{R}^{n\\times 1}$.\n- Definitions Provided:\n  - Controllability of $(A,B)$: every state is reachable.\n  - Stabilizability of $(A,B)$: every eigenvalue $\\lambda$ of $A$ with $\\operatorname{Re}(\\lambda)\\ge 0$ is controllable.\n  - Observability of $(C,A)$: every state is reconstructible.\n  - Detectability of $(C,A)$: every eigenvalue $\\lambda$ of $A$ with $\\operatorname{Re}(\\lambda)\\ge 0$ is observable.\n- Central Hypothesis: There exists at least one eigenvalue $\\lambda_u$ of $A$ such that $\\operatorname{Re}(\\lambda_u)>0$ and this mode is either uncontrollable with respect to $B$ or unobservable with respect to $C$. Consequently, the plant is neither stabilizable nor detectable.\n- Objective: Identify the correct statement(s) that explain the impossibility of arbitrary output-feedback pole placement under these conditions.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is well-defined and scientifically grounded. It presents a canonical problem in modern control theory: the limitations of the separation principle when the plant is not stabilizable and detectable. The system equations, controller structure, definitions, and the central hypothesis are all standard, precise, and internally consistent. The problem does not violate any physical or mathematical principles. It is not ambiguous, incomplete, or based on subjective claims.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. It poses a standard, verifiable question based on fundamental principles of linear systems theory. A full analysis may proceed.\n\n**Derivation of Closed-Loop Dynamics**\n\nThe separation principle for controller design is predicated on analyzing the dynamics of the system state and the observer error separately. Let the observer error be defined as $e(t) = x(t) - \\hat{x}(t)$.\n\nThe time derivative of the error is $\\dot{e}(t) = \\dot{x}(t) - \\dot{\\hat{x}}(t)$. Substituting the given dynamics:\n$\\dot{x}(t) = A x(t) + B u(t)$\n$\\dot{\\hat{x}}(t) = A \\hat{x}(t) + B u(t) + L(y(t) - C \\hat{x}(t)) = A \\hat{x}(t) + B u(t) + L(C x(t) - C \\hat{x}(t))$\n$\\dot{\\hat{x}}(t) = A \\hat{x}(t) + B u(t) + L C e(t)$\n\nThus, the error dynamics are:\n$\\dot{e}(t) = (A x(t) + B u(t)) - (A \\hat{x}(t) + B u(t) + L C e(t)) = A(x(t) - \\hat{x}(t)) - L C e(t)$\n$$ \\dot{e}(t) = (A - L C)e(t) $$\nThe eigenvalues of the observer error dynamics are the eigenvalues of the matrix $A - L C$.\n\nNext, we analyze the dynamics of the state $x(t)$ under feedback. The control law is $u(t) = -K \\hat{x}(t) = -K (x(t) - e(t)) = -K x(t) + K e(t)$.\nSubstituting this into the state equation:\n$\\dot{x}(t) = A x(t) + B(-K x(t) + K e(t)) = (A - B K)x(t) + B K e(t)$\n\nWe combine the dynamics for $x(t)$ and $e(t)$ into a single system:\n$$\n\\begin{pmatrix} \\dot{x}(t) \\\\ \\dot{e}(t) \\end{pmatrix}\n=\n\\underbrace{\n\\begin{pmatrix} A - B K & B K \\\\ 0 & A - L C \\end{pmatrix}\n}_{A_{cl}}\n\\begin{pmatrix} x(t) \\\\ e(t) \\end{pmatrix}\n$$\nThe matrix $A_{cl}$ governs the complete closed-loop dynamics. As it is a block upper triangular matrix, its set of eigenvalues is the union of the eigenvalues of its diagonal blocks:\n$\\text{eig}(A_{cl}) = \\text{eig}(A - B K) \\cup \\text{eig}(A - L C)$.\n\nThe principle of arbitrary pole placement relies on two conditions:\n1.  The eigenvalues of $A - B K$ can be placed arbitrarily in the complex plane by choosing the state-feedback gain $K$ if and only if the pair $(A,B)$ is completely controllable.\n2.  The eigenvalues of $A - L C$ can be placed arbitrarily by choosing the observer gain $L$ if and only if the pair $(C,A)$ is completely observable.\n\nThe problem states that there exists an eigenvalue $\\lambda_u$ of $A$ with $\\operatorname{Re}(\\lambda_u)>0$ which is either uncontrollable or unobservable.\n- If $\\lambda_u$ corresponds to an uncontrollable mode, it is a fundamental theorem that $\\lambda_u$ remains an eigenvalue of $A - B K$ for any choice of $K$. Thus, $\\lambda_u \\in \\text{eig}(A_{cl})$.\n- If $\\lambda_u$ corresponds to an unobservable mode, it is a fundamental theorem (by duality) that $\\lambda_u$ remains an eigenvalue of $A - L C$ for any choice of $L$. Thus, $\\lambda_u \\in \\text{eig}(A_{cl})$.\n\nIn either scenario, the unstable eigenvalue $\\lambda_u$ from the original plant matrix $A$ persists as an eigenvalue of the closed-loop system $A_{cl}$. Since $\\operatorname{Re}(\\lambda_u)>0$, the closed-loop system is unstable. This makes it impossible to place all closed-loop poles in arbitrary locations (e.g., all in the open left half-plane). Therefore, arbitrary pole placement is impossible.\n\n**Evaluation of Options**\n\n**A. Even with partial stabilizability or detectability, any eigenvalues of $A$ in the open right half-plane that are uncontrollable or unobservable necessarily persist as closed-loop eigenvalues under the separation architecture, so arbitrary pole placement is impossible.**\nThis statement is a direct and correct conclusion from the analysis above. The essence of the separation principle's limitation is that the closed-loop spectrum contains $\\text{eig}(A - B K)$ and $\\text{eig}(A - L C)$. An uncontrollable eigenvalue of $A$ is immune to placement by $K$, and an unobservable eigenvalue of $A$ is immune to placement by $L$. If such an eigenvalue is in the open right half-plane, it remains there in the closed-loop system, precluding stabilization, let alone arbitrary pole placement.\n**Verdict: Correct.**\n\n**B. Choosing $L$ with sufficiently large gain can move unobservable unstable modes of $A$ to the open left half-plane because the observer dynamics can overpower a lack of observability.**\nThis statement is fundamentally false. The property of a mode being unobservable means precisely that it is decoupled from the output $y(t)$ and therefore immune to any feedback action based on the output, which is what the observer gain $L$ mediates via the term $L(y - \\hat{y})$. No magnitude of gain $L$ can alter an unobservable eigenvalue of $A$. The notion of \"overpowering\" a lack of observability is scientifically meaningless.\n**Verdict: Incorrect.**\n\n**C. If $(A,B)$ is stabilizable and $(C,A)$ is detectable, then for any desired multiset of closed-loop poles there exist $K$ and $L$ such that output feedback via separation assigns all closed-loop poles arbitrarily, including those associated with uncontrollable or unobservable subspaces.**\nThis statement is incorrect on multiple grounds. First, the condition for arbitrary pole placement is controllability and observability, not the weaker conditions of stabilizability and detectability. Stabilizability and detectability guarantee only that the closed-loop system can be stabilized (i.e., all poles placed in the open left half-plane), not that they can be placed arbitrarily. Second, if a system is merely stabilizable and not controllable, it possesses stable, uncontrollable modes whose eigenvalues cannot be moved. Similarly for detectable systems. The claim that one can assign poles \"associated with uncontrollable or unobservable subspaces\" is a direct contradiction of what these terms mean. Finally, this option discusses a stabilizable/detectable system, whereas the problem is explicitly about a system that is not.\n**Verdict: Incorrect.**\n\n**D. In the Kalman controllability/observability decomposition, any uncontrollable or unobservable unstable blocks evolve autonomously and their eigenvalues must appear in the closed-loop characteristic polynomial of the separated design, precluding arbitrary pole placement by separation when such blocks lie in the open right half-plane.**\nThis statement provides a deeper, structural explanation for the phenomenon. The Kalman decomposition formally separates a linear system's state-space into four subspaces: controllable-observable, controllable-unobservable, uncontrollable-observable, and uncontrollable-unobservable. The eigenvalues associated with the uncontrollable ($A_{\\bar{c}}$) or unobservable ($A_{\\bar{o}}$) blocks are invariant under state feedback or output injection, respectively. As shown in the derivation, these fixed eigenvalues will appear in the closed-loop characteristic polynomial. If any of these fixed eigenvalues correspond to unstable modes ($\\operatorname{Re}(\\lambda)>0$), they cannot be moved, and arbitrary pole placement is impossible. This is a rigorous and correct explanation. The phrasing \"evolve autonomously\" is a slight simplification, as these blocks can be driven by other states, but their eigenvalues are indeed fixed.\n**Verdict: Correct.**\n\n**E. Introducing strictly proper frequency-dependent dynamics into $K$ or $L$ within the same separation structure can relocate a plant eigenvalue corresponding to an uncontrollable right-half-plane mode to the open left half-plane, thereby restoring arbitrary pole placement.**\nThis statement is incorrect. Replacing static gains $K$ or $L$ with dynamic transfer functions $K(s)$ or $L(s)$ amounts to using a general dynamic compensator. However, an uncontrollable mode is a fundamental property of the plant $(A,B)$—it represents a dynamic mode that cannot be influenced by the input $u(t)$, regardless of how $u(t)$ is generated. Similarly, an unobservable mode is a property of $(C,A)$ and is invisible to the output $y(t)$, making it impossible for any controller that uses $y(t)$ to affect it. A dynamic controller cannot circumvent these fundamental structural limitations of the plant.\n**Verdict: Incorrect.**\n\nBoth options A and D are correct. Option A is a direct statement of the result, while Option D provides the underlying structural reason via the Kalman decomposition. Both correctly explain the phenomenon.", "answer": "$$\\boxed{AD}$$", "id": "2913880"}, {"introduction": "This final practice bridges the gap between control theory and real-world implementation, where finite-precision arithmetic can undermine theoretically sound designs. When an aggressive controller (fast poles) is combined with a high-gain observer (also fast poles), the resulting system can suffer from severe numerical ill-conditioning due to a large separation of timescales. This problem guides you through practical strategies, such as coordinate scaling, to mitigate these numerical issues while preserving the essential structure of the separated controller, a crucial skill for designing high-performance systems that are also robust and reliable. [@problem_id:2913857]", "problem": "Consider a continuous-time Linear Time-Invariant (LTI) Single-Input Single-Output (SISO) plant described by the state-space model\n$$\n\\dot{x}(t) \\,=\\, A x(t) \\,+\\, B u(t),\\qquad y(t) \\,=\\, C x(t),\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$, $B \\in \\mathbb{R}^{n \\times 1}$, $C \\in \\mathbb{R}^{1 \\times n}$, and assume $(A,B)$ is stabilizable and $(A,C)$ is detectable. A standard dynamic output-feedback controller is built by combining state-feedback and a Luenberger observer:\n$$\nu(t) \\,=\\, -K \\,\\hat{x}(t), \\qquad\n\\dot{\\hat{x}}(t) \\,=\\, A \\hat{x}(t) \\,+\\, B u(t) \\,+\\, L\\big(y(t) - C \\hat{x}(t)\\big),\n$$\nwhere $K \\in \\mathbb{R}^{1 \\times n}$ and $L \\in \\mathbb{R}^{n \\times 1}$. In exact arithmetic, letting $e(t) \\,=\\, x(t) - \\hat{x}(t)$ yields the closed-loop error-coordinate dynamics\n$$\n\\begin{bmatrix}\n\\dot{x}(t) \\\\\n\\dot{e}(t)\n\\end{bmatrix}\n=\n\\underbrace{\\begin{bmatrix}\nA - B K & B K \\\\\n0 & A - L C\n\\end{bmatrix}}_{\\mathcal{A}_{\\mathrm{cl}}}\n\\begin{bmatrix}\nx(t) \\\\\ne(t)\n\\end{bmatrix},\n$$\nwhich is block upper-triangular and embodies the separation principle: the spectrum of $\\mathcal{A}_{\\mathrm{cl}}$ is the union of the spectra of $A - B K$ and $A - L C$.\n\nNow suppose an aggressive state-feedback is chosen so that the eigenvalues of $A - B K$ are placed far to the left of the imaginary axis (large closed-loop bandwidth), and a high-gain observer is used with $L \\,=\\, \\tfrac{1}{\\epsilon} \\tilde{L}$ for some small $0 < \\epsilon \\ll 1$ and fixed $\\tilde{L}$, so that the eigenvalues of $A - L C$ are also far left. In finite-precision implementation, numerical conditioning problems can arise due to:\n- vastly different time scales between $x(t)$ and $e(t)$ dynamics,\n- large norms of $K$ and $L$ amplifying floating-point roundoff and sensor noise,\n- poorly scaled state coordinates making $\\mathcal{A}_{\\mathrm{cl}}$ ill-conditioned.\n\nA researcher proposes to mitigate numerical conditioning while preserving the separation property by appropriate state and observer scalings. Which of the following statements correctly identify a scaling strategy that reduces numerical conditioning problems and preserves the separation structure of the closed loop under implementation? Select all that apply.\n\nA. Introduce a similarity transformation $z \\,=\\, S x$ with $S \\in \\mathbb{R}^{n \\times n}$ invertible (for example, chosen to approximately balance controllability and observability), and redesign gains in the $z$-coordinates:\n$$\n\\dot{\\hat{z}} \\,=\\, S A S^{-1} \\hat{z} \\,+\\, S B u \\,+\\, L_z\\big(y - C S^{-1} \\hat{z}\\big), \\quad u \\,=\\, -K_z \\hat{z},\n$$\nthen implement $K \\,=\\, K_z S$ and $L \\,=\\, S^{-1} L_z$. This improves scaling because coefficients in $S A S^{-1}$, $S B$, and $C S^{-1}$ can be moderated, and it preserves separation since the augmented closed-loop in $(z,e_z)$ with $e_z \\,=\\, z - \\hat{z}$ is similar to the original augmented closed-loop.\n\nB. Increase the observer gain magnitude further (make $\\epsilon$ even smaller) so that the observer error dynamics numerically dominate the plant dynamics, thereby making the numerical effect of $B K$ negligible. This numerically decouples the loops and thus regularizes the conditioning without any coordinate changes.\n\nC. Apply a high-gain scaling only inside the observer by defining $\\hat{z} \\,=\\, S \\hat{x}$ with a diagonal $S$ chosen for high-gain normalization, but leave the controller as $u \\,=\\, -K \\hat{x}$ with the original $K$. This reduces the magnitude of observer signals and preserves separation because the controller and observer are still designed independently.\n\nD. Pre-scale the measured output as $\\tilde{y} \\,=\\, \\alpha \\, y$ with $\\alpha \\in \\mathbb{R}$ small to prevent noise amplification by $L$, but leave the plant model and controller/observer gains otherwise unchanged. This reduces numerical issues without affecting the separation property.\n\nE. For a single-output system in observable canonical form, use the singular-perturbation high-gain scaling $z \\,=\\, D(\\epsilon) x$ with $D(\\epsilon) \\,=\\, \\mathrm{diag}\\big(1, \\epsilon, \\epsilon^{2}, \\dots, \\epsilon^{n-1}\\big)$, design $K_z$ and $L_z$ for the scaled model\n$$\n\\dot{z} \\,=\\, D(\\epsilon) A D(\\epsilon)^{-1} z \\,+\\, D(\\epsilon) B u,\\qquad y \\,=\\, C D(\\epsilon)^{-1} z,\n$$\nimplement $u \\,=\\, -K_z \\hat{z}$ and $\\dot{\\hat{z}} \\,=\\, D(\\epsilon) A D(\\epsilon)^{-1} \\hat{z} \\,+\\, D(\\epsilon) B u \\,+\\, L_z\\big(y - C D(\\epsilon)^{-1} \\hat{z}\\big)$, and map back $K \\,=\\, K_z D(\\epsilon)$, $L \\,=\\, D(\\epsilon)^{-1} L_z$. This normalizes fast/slow coordinates, reduces dynamic range disparities, and preserves separation because the augmented closed-loop is related by a block-diagonal similarity transformation.\n\nChoose all that apply.", "solution": "The problem asks to identify correct scaling strategies to mitigate numerical conditioning issues in a high-gain observer-based controller, while preserving the separation principle. The system is a continuous-time LTI SISO plant given by:\n$$\n\\dot{x}(t) = A x(t) + B u(t), \\qquad y(t) = C x(t)\n$$\nwith an observer-based controller:\n$$\nu(t) = -K \\hat{x}(t), \\qquad \\dot{\\hat{x}}(t) = A \\hat{x}(t) + B u(t) + L\\big(y(t) - C \\hat{x}(t)\\big)\n$$\nThe problem arises when both the controller gain $K$ and the observer gain $L$ are large, leading to numerical ill-conditioning. The separation principle is embodied by the block upper-triangular structure of the closed-loop dynamics matrix $\\mathcal{A}_{\\mathrm{cl}}$ in the coordinates $(x, e)$, where $e(t) = x(t) - \\hat{x}(t)$ is the estimation error.\n$$\n\\mathcal{A}_{\\mathrm{cl}} = \\begin{bmatrix} A - B K & B K \\\\ 0 & A - L C \\end{bmatrix}\n$$\nThe eigenvalues of $\\mathcal{A}_{\\mathrm{cl}}$ are the union of the eigenvalues of the regulator block, $\\sigma(A-BK)$, and the observer error block, $\\sigma(A-LC)$. A strategy preserves the separation property if the new closed-loop dynamics matrix retains this structural property, ensuring its eigenvalues are similarly decoupled.\n\nLet us analyze each option.\n\n### Option A Analysis\n\nThis option proposes a general similarity transformation of the state, $z(t) = S x(t)$, where $S$ is an invertible matrix. A new controller is designed in the $z$-coordinates.\nThe plant dynamics in $z$-coordinates are:\n$$\n\\dot{z}(t) = (S A S^{-1}) z(t) + (S B) u(t) = A_z z(t) + B_z u(t)\n$$\n$$\ny(t) = (C S^{-1}) z(t) = C_z z(t)\n$$\nThe proposed controller is designed for this new representation:\n$$\n\\dot{\\hat{z}}(t) = A_z \\hat{z}(t) + B_z u(t) + L_z\\big(y(t) - C_z \\hat{z}(t)\\big), \\quad u(t) = -K_z \\hat{z}(t)\n$$\nThis is a standard observer-based controller for the system in $z$-coordinates. The corresponding closed-loop dynamics in the coordinates $(z, e_z)$, where $e_z(t) = z(t) - \\hat{z}(t)$, will have the matrix:\n$$\n\\mathcal{A}_{z} = \\begin{bmatrix} A_z - B_z K_z & B_z K_z \\\\ 0 & A_z - L_z C_z \\end{bmatrix}\n$$\nThis matrix is block upper-triangular, so the separation principle is preserved in the new coordinates. The eigenvalues are $\\sigma(A_z - B_z K_z) \\cup \\sigma(A_z - L_z C_z)$.\n\nThe statement says this implementation is equivalent to using gains $K = K_z S$ and $L = S^{-1} L_z$ in the original coordinates. Let's verify this.\nThe control law is $u = -K_z \\hat{z}$. Since $\\hat{z}$ is an estimate of $z=Sx$, it is natural to define the estimate of the original state as $\\hat{x} = S^{-1}\\hat{z}$. Then, $u = -K_z (S\\hat{x}) = -(K_zS)\\hat{x}$, which implies $K=K_zS$.\nThe observer gain transformation relates the observer for $\\hat{x}$ with gain $L$ to the one for $\\hat{z}$ with gain $L_z$. Differentiating $\\hat{z}=S\\hat{x}$ gives $\\dot{\\hat{z}} = S\\dot{\\hat{x}}$.\nSubstituting the standard $\\hat{x}$ observer dynamics:\n$\\dot{\\hat{z}} = S\\big(A \\hat{x} + B u + L(y - C \\hat{x})\\big) = (SAS^{-1})(S\\hat{x}) + (SB)u + SL(y - (CS^{-1})(S\\hat{x})) = A_z \\hat{z} + B_z u + (SL)(y - C_z \\hat{z})$.\nComparing this to the $\\hat{z}$ observer equation, we identify $L_z = SL$, which means $L = S^{-1} L_z$.\nThe relationships for gains are correct.\n\nThe central claim is that this strategy improves numerical conditioning. By choosing the similarity transformation $S$ appropriately (e.g., using balancing algorithms that make rows and columns of the transformed matrices have similar norms), the derived matrices $A_z, B_z, C_z$ can be made much better conditioned than the original $A, B, C$. Subsequent design steps (e.g., pole placement) and the final implementation of the controller with state $\\hat{z}$ will be numerically more robust.\nThe augmented closed-loop matrix $\\mathcal{A}_z$ is related to the original one $\\mathcal{A}_{cl}$ by the block-diagonal similarity transformation $\\mathcal{S} = \\text{diag}(S, S)$, since $z=Sx$ and $e_z = S e_x$. Thus, $\\mathcal{A}_z = \\mathcal{S} \\mathcal{A}_{cl} \\mathcal{S}^{-1}$. This confirms again that the separation structure is preserved.\nThe strategy is a standard and sound method in control engineering for improving numerical robustness.\n\nVerdict: **Correct**.\n\n### Option B Analysis\n\nThis option suggests making the observer gain $L$ even larger (i.e., making $\\epsilon$ smaller in $L = \\tfrac{1}{\\epsilon}\\tilde{L}$). The rationale given is that the fast observer dynamics will dominate, making the effect of the coupling term $BK$ negligible and thus regularizing the problem.\nThis reasoning is fundamentally flawed. The numerical conditioning problem is *caused* by large gains $K$ and $L$. The matrix $\\mathcal{A}_{\\mathrm{cl}}$ becomes ill-conditioned partly because entries related to $BK$ and $LC$ have very large magnitudes compared to entries of $A$. Increasing the magnitude of $L$ will further increase the magnitude of the entries in the block $A-LC$ and potentially the condition number of $\\mathcal{A}_{\\mathrm{cl}}$. It aggravates the problem of time-scale separation and large coefficient spread, which is the source of ill-conditioning. This strategy makes the numerical problem worse, not better.\n\nVerdict: **Incorrect**.\n\n### Option C Analysis\n\nThis option proposes a hybrid approach: define a scaled observer state $\\hat{z} = S \\hat{x}$ but keep the controller law as $u = -K \\hat{x}$ with the original high-gain $K$. This description is ambiguous. A controller is a single dynamical system. It cannot have two different state representations ($\\hat{x}$ and $\\hat{z}$) used partially.\nLet's interpret it as a controller with internal state $\\hat{z}$ which produces an output $\\hat{x} = S^{-1} \\hat{z}$ that is then used in the control law $u = -K\\hat{x}$. The controller would be:\n$$ \\dot{\\hat{z}} = A_z \\hat{z} + B_z u + L_z(y - C_z \\hat{z}), \\quad u = -K(S^{-1}\\hat{z}) $$\nThis is a standard controller structure in $z$-coordinates, as in Option A, with a controller gain $K_z = KS^{-1}$. The argument that one should \"leave the controller as $u=-K\\hat{x}$ with the original $K$\" is misguided. If a scaling is introduced to fix a system-wide numerical problem arising from large gains, it should be applied consistently. Leaving the large gain $K$ as is and only scaling the observer side does not address the full problem. The term $BK$ in the closed-loop matrix, which contributes to ill-conditioning, involves this unmitigated large gain $K$.\nFurthermore, the justification \"preserves separation because the controller and observer are still designed independently\" is a non-sequitur. The separation principle is a mathematical property of the resulting closed-loop system's structure, not the design philosophy. While the structure does preserve separation, the proposed strategy is not a coherent method for improving conditioning and is poorly described.\n\nVerdict: **Incorrect**.\n\n### Option D Analysis\n\nThis option proposes to scale the measured output by a small factor $\\alpha$ before it enters the observer: the innovation term becomes $L(\\alpha y - C\\hat{x})$.\nLet us analyze the resulting error dynamics for $e(t) = x(t)-\\hat{x}(t)$.\n$$\n\\dot{e}(t) = \\dot{x}(t) - \\dot{\\hat{x}}(t) = \\big(A x(t) + B u(t)\\big) - \\big(A \\hat{x}(t) + B u(t) + L(\\alpha y(t) - C \\hat{x}(t))\\big)\n$$\n$$\n\\dot{e}(t) = A e(t) - L(\\alpha C x(t) - C \\hat{x}(t)) = A e(t) - L C (\\alpha x(t) - \\hat{x}(t))\n$$\nWe can write $\\alpha x - \\hat{x} = \\alpha x - (x - e) = (\\alpha-1)x + e$.\n$$\n\\dot{e}(t) = A e(t) - L C ((\\alpha-1)x(t) + e(t)) = (A-LC)e(t) - (\\alpha-1)LC x(t)\n$$\nThe state equation for the closed-loop system in $(x,e)$ coordinates is:\n$$\n\\begin{bmatrix} \\dot{x}(t) \\\\ \\dot{e}(t) \\end{bmatrix} = \\begin{bmatrix} A - B K & B K \\\\ -(\\alpha-1)LC & A - L C \\end{bmatrix} \\begin{bmatrix} x(t) \\\\ e(t) \\end{bmatrix}\n$$\nThe system matrix is block upper-triangular only if the $(2,1)$ block, $-(\\alpha-1)LC$, is zero. This requires $\\alpha=1$ (the original system), or $L=0$ or $C=0$ (trivial cases). For any $\\alpha \\neq 1$, the matrix is not block triangular, and the separation principle is destroyed. The eigenvalues of the regulator and the observer become coupled. The proposed modification is fundamentally incorrect because it makes the observer inconsistent with the plant model (it compares a scaled measurement $\\alpha y$ with an unscaled prediction $C\\hat{x}$).\n\nVerdict: **Incorrect**.\n\n### Option E Analysis\n\nThis option describes a specific, sophisticated scaling strategy for systems in observable canonical form, which is a common setting for high-gain observer theory. It uses a state transformation $z=D(\\epsilon)x$ with a diagonal matrix $D(\\epsilon) = \\mathrm{diag}\\big(1, \\epsilon, \\epsilon^{2}, \\dots, \\epsilon^{n-1}\\big)$. This is a well-known technique from singular perturbation theory.\n1.  **Scaling**: The transformation $z = D(\\epsilon)x$ is a special case of the general similarity transformation $z=Sx$ from Option A, with $S=D(\\epsilon)$. This transformation is specifically designed to handle the multi-time-scale nature of high-gain systems. It \"stretches\" the state-space coordinates to make the magnitudes of the transformed state variables $z_i$ more uniform, thereby improving the numerical conditioning of the transformed system matrices $(A_\\epsilon, B_\\epsilon, C_\\epsilon) = (DAD^{-1}, DB, CD^{-1})$.\n2.  **Controller Design**: A controller is then designed in these well-behaved $z$-coordinates. The structure is the standard one:\n    $$\n    \\dot{\\hat{z}} = A_\\epsilon \\hat{z} + B_\\epsilon u + L_z(y - C_\\epsilon \\hat{z}), \\quad u = -K_z \\hat{z}\n    $$\n3.  **Preservation of Separation**: As established in the analysis of Option A, using a similarity transformation and redesigning the controller entirely in the new coordinates preserves the separation property. The closed-loop matrix in $(z, e_z)$ coordinates is block triangular. The statement that the augmented closed-loop is related by a block-diagonal similarity transformation $\\text{diag}(D(\\epsilon), D(\\epsilon))$ is also correct, as shown in the analysis for A.\n4.  **Gain Mapping**: The relations $K = K_z D(\\epsilon)$ and $L = D(\\epsilon)^{-1}L_z$ are the correct transformations for the gains, matching the general formulas $K=K_zS$ and $L=S^{-1}L_z$ with $S=D(\\epsilon)$.\n\nThis option correctly describes a valid and powerful technique for improving numerical conditioning in high-gain observer-based control, which is an advanced and specific application of the general principle laid out in Option A. All claims made in this option are correct.\n\nVerdict: **Correct**.\n\n### Summary\nOptions A and E both describe correct scaling strategies. Option A presents the general principle of using similarity transformations, while Option E details a specific, well-established instance of this principle tailored for high-gain observers. Options B, C, and D contain fundamental conceptual errors.", "answer": "$$\\boxed{AE}$$", "id": "2913857"}]}