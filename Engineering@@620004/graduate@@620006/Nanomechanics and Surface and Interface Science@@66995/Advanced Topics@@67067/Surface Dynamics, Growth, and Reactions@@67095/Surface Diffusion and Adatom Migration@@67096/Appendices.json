{"hands_on_practices": [{"introduction": "The migration of an adatom across a surface is fundamentally a series of discrete \"hops\" between stable adsorption sites. This process is thermally activated, and its rate is governed by the height of the energy barrier separating the sites and the surface temperature. This foundational exercise allows you to apply the Arrhenius relationship, a cornerstone of chemical kinetics, to calculate the characteristic hop rate and the corresponding mean residence time an adatom spends in a potential well before migrating [@problem_id:2791158].", "problem": "An adatom on a crystalline surface resides in a periodic potential with equivalent adsorption sites separated by a migration barrier. Consider a single adatom that performs thermally activated hops between nearest-neighbor sites. Assume the following physically motivated bases: (i) the adatom’s local vibration in a binding well provides an attempt frequency, interpreted as the characteristic rate of uncorrelated trials to cross the barrier; (ii) the canonical Boltzmann distribution governs the probability that thermal fluctuations supply sufficient energy to reach the barrier; and (iii) barrier-crossing events are memoryless, so the waiting-time distribution for hops is exponential.\n\nStarting from these bases, derive an expression for the hop rate as a function of the migration energy barrier $E_m$, the attempt frequency $\\nu$, the Boltzmann constant $k_B$, and the temperature $T$. From the memoryless property, relate the mean residence time to the hop rate. Then evaluate both the hop rate and the mean residence time numerically for an adatom characterized by $E_m=0.35\\,\\mathrm{eV}$, $\\nu=1.0\\times 10^{13}\\,\\mathrm{s^{-1}}$, and $T=500\\,\\mathrm{K}$. Use $k_B=8.617333262\\times 10^{-5}\\,\\mathrm{eV\\,K^{-1}}$.\n\nExpress the hop rate in $\\mathrm{s^{-1}}$ and the mean residence time in $\\mathrm{s}$. Round both numerical results to three significant figures.", "solution": "The problem statement is scientifically sound and well-posed. It describes a classic scenario of thermally activated surface diffusion, formulated using fundamental principles of statistical mechanics and kinetics. We shall proceed with the derivation and calculation.\n\nFirst, we derive the expression for the hop rate, $\\Gamma$. The problem provides three physical bases. Basis (i) gives the attempt frequency, $\\nu$, which is the rate at which the adatom attempts to cross the energy barrier from its local potential well. Basis (ii) uses the canonical Boltzmann distribution to define the probability of a successful attempt. A successful attempt requires the adatom to possess thermal energy equal to or greater than the migration energy barrier, $E_m$. The probability, $P_{\\text{success}}$, for such an event is given by the Boltzmann factor:\n$$ P_{\\text{success}} = \\exp\\left(-\\frac{E_m}{k_B T}\\right) $$\nwhere $k_B$ is the Boltzmann constant and $T$ is the absolute temperature. The total hop rate $\\Gamma$ is the product of the number of attempts per unit time and the probability of success per attempt.\n$$ \\Gamma = \\nu \\times P_{\\text{success}} = \\nu \\exp\\left(-\\frac{E_m}{k_B T}\\right) $$\nThis is the standard Arrhenius expression for the rate of a thermally activated process.\n\nNext, we relate the mean residence time, $\\tau$, to the hop rate, $\\Gamma$. Basis (iii) states that the barrier-crossing events are memoryless. A process composed of memoryless events is a Poisson process. For such a process with a constant average rate $\\Gamma$, the time interval $t$ between consecutive events follows an exponential probability distribution with the probability density function $p(t)$:\n$$ p(t) = \\Gamma \\exp(-\\Gamma t) \\quad \\text{for } t \\ge 0 $$\nThe mean residence time, $\\tau$, is the expected value of the waiting time $t$. It is calculated by integrating $t \\cdot p(t)$ over all possible times from $0$ to $\\infty$:\n$$ \\tau = \\langle t \\rangle = \\int_{0}^{\\infty} t \\, p(t) \\, dt = \\int_{0}^{\\infty} t \\, \\Gamma \\exp(-\\Gamma t) \\, dt $$\nWe solve this integral using integration by parts, with $u=t$ and $dv = \\Gamma \\exp(-\\Gamma t) \\, dt$. This gives $du=dt$ and $v = -\\exp(-\\Gamma t)$.\n$$ \\tau = \\left[ -t \\exp(-\\Gamma t) \\right]_{0}^{\\infty} - \\int_{0}^{\\infty} (-\\exp(-\\Gamma t)) \\, dt $$\nThe boundary term $\\left[ -t \\exp(-\\Gamma t) \\right]_{0}^{\\infty}$ evaluates to $0$ at both $t=0$ and as $t \\to \\infty$. The expression simplifies to:\n$$ \\tau = \\int_{0}^{\\infty} \\exp(-\\Gamma t) \\, dt = \\left[ -\\frac{1}{\\Gamma}\\exp(-\\Gamma t) \\right]_{0}^{\\infty} = \\left(0\\right) - \\left(-\\frac{1}{\\Gamma}\\exp(0)\\right) = \\frac{1}{\\Gamma} $$\nThus, the mean residence time in an adsorption site is the reciprocal of the hop rate.\n\nFinally, we perform the numerical evaluation using the given values: $E_m = 0.35\\,\\mathrm{eV}$, $\\nu = 1.0 \\times 10^{13}\\,\\mathrm{s^{-1}}$, $T = 500\\,\\mathrm{K}$, and $k_B = 8.617333262 \\times 10^{-5}\\,\\mathrm{eV\\,K^{-1}}$.\nFirst, we calculate the dimensionless term in the exponent:\n$$ \\frac{E_m}{k_B T} = \\frac{0.35}{(8.617333262 \\times 10^{-5}) \\times 500} \\approx 8.12321 $$\nNow we calculate the hop rate $\\Gamma$:\n$$ \\Gamma = (1.0 \\times 10^{13}) \\times \\exp(-8.12321) \\approx (1.0 \\times 10^{13}) \\times (2.9653 \\times 10^{-4}) \\approx 2.9653 \\times 10^{9}\\,\\mathrm{s^{-1}} $$\nRounding to three significant figures, the hop rate is:\n$$ \\Gamma \\approx 2.97 \\times 10^{9}\\,\\mathrm{s^{-1}} $$\nThe mean residence time $\\tau$ is the reciprocal of $\\Gamma$:\n$$ \\tau = \\frac{1}{\\Gamma} \\approx \\frac{1}{2.9653 \\times 10^{9}\\,\\mathrm{s^{-1}}} \\approx 3.3723 \\times 10^{-10}\\,\\mathrm{s} $$\nRounding to three significant figures, the mean residence time is:\n$$ \\tau \\approx 3.37 \\times 10^{-10}\\,\\mathrm{s} $$", "answer": "$$\\boxed{\\begin{pmatrix} 2.97 \\times 10^{9} & 3.37 \\times 10^{-10} \\end{pmatrix}}$$", "id": "2791158"}, {"introduction": "While the previous exercise used a given migration barrier, a central task in computational materials science is to determine this barrier from the underlying potential energy surface. This practice guides you through implementing the Nudged Elastic Band (NEB) method, a powerful algorithm used to find the minimum energy path and locate the saddle point for a diffusion event. By applying it to a realistic model potential for graphene, you will gain hands-on experience with a state-of-the-art technique for predicting kinetic parameters from first principles [@problem_id:2791194].", "problem": "Construct a program that computes the diffusion barrier for a carbon adatom migrating between neighboring hollow sites on graphene by minimizing a discrete minimum-energy path using a chain-of-states method consistent with the Nudged Elastic Band (NEB). The force field to be used represents the forces obtained from Density Functional Theory (DFT) but is provided here by a surrogate Fourier-synthesized potential energy surface over the graphene lattice. The task assesses sensitivity of the barrier to the choice of exchange–correlation functional through a set of parameterized potentials.\n\nStart from the following fundamental bases and core definitions:\n\n1. The potential energy of the adatom at in-plane position $\\mathbf{r} = (x,y)$ is $U(\\mathbf{r})$. The conservative force is $\\mathbf{F}(\\mathbf{r}) = -\\nabla U(\\mathbf{r})$.\n\n2. A minimum energy path is a curve $\\mathbf{r}(s)$ connecting two local minima of $U(\\mathbf{r})$ such that at each point the force component perpendicular to the path vanishes and the tangent direction follows the path of steepest ascent toward a saddle point. In a discrete chain-of-states representation, the path is approximated by a finite sequence of images $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$, with endpoints fixed at the two minima.\n\n3. An elastic regularization is applied along the path to maintain an approximately uniform distribution of images, while only the physical force component perpendicular to the path is used to drive relaxation. A climbing-image refinement is applied to the highest-energy interior image to converge to the saddle point.\n\nSurface energy model and geometry:\n\n- Use a triangular-lattice Fourier model for the graphene hollow-site energy landscape. Let the graphene lattice constant be $a = 2.46\\,\\text{\\AA}$. Define the reciprocal lattice vectors\n$$\n\\mathbf{b}_1 = \\left(\\frac{2\\pi}{a},\\; -\\frac{2\\pi}{a\\sqrt{3}}\\right),\\quad\n\\mathbf{b}_2 = \\left(0,\\; \\frac{4\\pi}{a\\sqrt{3}}\\right),\\quad\n\\mathbf{b}_3 = -(\\mathbf{b}_1+\\mathbf{b}_2).\n$$\n- For parameters $(A,B)$, define the potential energy surface in electronvolts as\n$$\nU(\\mathbf{r};A,B) = A\\sum_{i=1}^{3}\\cos\\!\\big(\\mathbf{b}_i\\cdot\\mathbf{r}\\big)\\;+\\;B\\sum_{i=1}^{3}\\cos\\!\\big(2\\,\\mathbf{b}_i\\cdot\\mathbf{r}\\big),\n$$\nwith $\\mathbf{r}$ in $\\text{\\AA}$ and $U$ in $\\mathrm{eV}$. Interpret $\\mathbf{F}(\\mathbf{r})=-\\nabla U(\\mathbf{r})$ as the DFT force corresponding to a given exchange–correlation choice through $(A,B)$.\n\nBoundary conditions and path:\n\n- Take the initial and final hollow sites to be $\\mathbf{r}_\\mathrm{start}=(0,0)$ and $\\mathbf{r}_\\mathrm{end}=(a,0)$, respectively. These are symmetry-equivalent minima.\n\nAlgorithmic requirements:\n\n- Implement a discrete chain of $N$ images including endpoints, with $N$ to be chosen as an integer that ensures reasonable resolution. Use a constant scalar spring constant $k_\\mathrm{spr}$ with units $\\mathrm{eV}/\\text{\\AA}^2$ to regularize image spacing along the path.\n- Apply a relaxation scheme that, at each step, uses only the perpendicular component of the physical force together with the parallel spring force to update interior images, and uses a climbing-image modification on the highest-energy interior image. Endpoints are fixed.\n- Use a fixed number of relaxation iterations and a constant step factor with units $\\text{\\AA}^2/\\mathrm{eV}$; ensure numerical stability and reproducibility.\n\nQuantity to compute:\n\n- For each parameter set $(A,B)$ in the test suite below, compute the diffusion barrier as the energy difference in $\\mathrm{eV}$ between the maximum along the converged discrete path and the minimum energy at the endpoints. Express all barriers in $\\mathrm{eV}$ as floating-point numbers rounded to six decimals.\n\nTest suite:\n\nUse the following parameter sets $(A,B)$, in $\\mathrm{eV}$, representing different exchange–correlation functional choices and an edge case:\n\n1. LDA-like: $A=-0.1125$, $B=0.0500$.\n2. PBE-like: $A=-0.0825$, $B=0.0400$.\n3. SCAN-like: $A=-0.1000$, $B=0.0550$.\n4. r2SCAN-like: $A=-0.0925$, $B=0.0500$.\n5. vdW-DF-like: $A=-0.0725$, $B=0.0800$.\n6. Flat-limit edge case: $A=-0.0100$, $B=0.0100$.\n\nFixed numerical parameters:\n\n- Use $N=16$ images including endpoints.\n- Use $k_\\mathrm{spr}=5.0\\,\\mathrm{eV}/\\text{\\AA}^2$.\n- Use a relaxation step factor $\\alpha=0.02\\,\\text{\\AA}^2/\\mathrm{eV}$.\n- Use $n_\\mathrm{iter}=4000$ iterations.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the six diffusion barriers, in the order listed above, as a comma-separated list enclosed in square brackets, each rounded to six decimals, for example, $[x_1,x_2,x_3,x_4,x_5,x_6]$, where each $x_i$ is in $\\mathrm{eV}$.", "solution": "The problem statement is valid. It is a well-defined computational physics problem grounded in the principles of surface science and statistical mechanics. The objective is to compute the diffusion barrier for a carbon adatom on a graphene substrate using a specified numerical method, the Climbing-Image Nudged Elastic Band (CI-NEB), on a surrogate potential energy surface. All parameters, equations, and boundary conditions are provided, allowing for a unique and reproducible solution.\n\nThe solution proceeds by first establishing the theoretical and computational framework of the CI-NEB method as applied to the given potential energy surface, and then implementing this framework algorithmically.\n\n**1. Potential Energy Surface and Force Field**\n\nThe potential energy $U$ of the adatom at position $\\mathbf{r}=(x,y)$ on the graphene surface is described by a Fourier series, which respects the threefold rotational symmetry of the hexagonal lattice:\n$$\nU(\\mathbf{r};A,B) = A\\sum_{i=1}^{3}\\cos\\!\\big(\\mathbf{b}_i\\cdot\\mathbf{r}\\big)\\;+\\;B\\sum_{i=1}^{3}\\cos\\!\\big(2\\,\\mathbf{b}_i\\cdot\\mathbf{r}\\big)\n$$\nHere, $\\mathbf{r}$ is in units of Ångströms ($\\text{\\AA}$) and $U$ is in electronvolts ($\\mathrm{eV}$). The parameters $A$ and $B$ modulate the shape of the potential, representing different approximations in Density Functional Theory. The reciprocal lattice vectors $\\mathbf{b}_i$ are defined with respect to the graphene lattice constant $a = 2.46\\,\\text{\\AA}$:\n$$\n\\mathbf{b}_1 = \\left(\\frac{2\\pi}{a},\\; -\\frac{2\\pi}{a\\sqrt{3}}\\right),\\quad\n\\mathbf{b}_2 = \\left(0,\\; \\frac{4\\pi}{a\\sqrt{3}}\\right),\\quad\n\\mathbf{b}_3 = -(\\mathbf{b}_1+\\mathbf{b}_2)\n$$\nThe conservative force on the adatom is the negative gradient of the potential, $\\mathbf{F}(\\mathbf{r}) = -\\nabla U(\\mathbf{r})$. Its analytical form is essential for the simulation:\n$$\n\\mathbf{F}(\\mathbf{r}) = A\\sum_{i=1}^{3}\\mathbf{b}_i\\sin(\\mathbf{b}_i\\cdot\\mathbf{r}) + 2B\\sum_{i=1}^{3}\\mathbf{b}_i\\sin(2\\mathbf{b}_i\\cdot\\mathbf{r})\n$$\n\n**2. The Nudged Elastic Band (NEB) Method**\n\nA Minimum Energy Path (MEP) is a continuous path connecting two energy minima that passes through a first-order saddle point. The NEB method finds this path by discretizing it into a chain of $N$ states, or \"images,\" $\\{\\mathbf{r}_i\\}_{i=0}^{N-1}$. The endpoints, $\\mathbf{r}_0 = \\mathbf{r}_\\mathrm{start}=(0,0)$ and $\\mathbf{r}_{N-1} = \\mathbf{r}_\\mathrm{end}=(a,0)$, are fixed at the initial and final minima. The $N-2$ interior images are relaxed iteratively.\n\nThe force driving the relaxation of each interior image $i$ is a combination of two components:\n\n1.  **Perpendicular Component of the True Force ($\\mathbf{F}_i^\\perp$):** The true physical force $\\mathbf{F}_i = -\\nabla U(\\mathbf{r}_i)$ is projected onto the direction perpendicular to the path. This \"nudging\" prevents the images from sliding down the potential surface back to the minima and ensures they converge to the MEP.\n    $$\n    \\mathbf{F}_i^\\perp = \\mathbf{F}_i - (\\mathbf{F}_i \\cdot \\hat{\\tau}_i)\\hat{\\tau}_i\n    $$\n    where $\\hat{\\tau}_i$ is the normalized local tangent to the path at image $i$. A common and stable definition for the tangent is derived from the positions of adjacent images: $\\hat{\\tau}_i = \\frac{\\mathbf{r}_{i+1}-\\mathbf{r}_{i-1}}{|\\mathbf{r}_{i+1}-\\mathbf{r}_{i-1}|}$.\n\n2.  **Parallel Component of the Spring Force ($\\mathbf{F}_i^{S,\\parallel}$):** An artificial spring force is applied parallel to the path to maintain a roughly uniform distribution of images.\n    $$\n    \\mathbf{F}_i^{S,\\parallel} = k_\\mathrm{spr} (|\\mathbf{r}_{i+1}-\\mathbf{r}_i| - |\\mathbf{r}_i - \\mathbf{r}_{i-1}|) \\hat{\\tau}_i\n    $$\n    where $k_\\mathrm{spr} = 5.0\\,\\mathrm{eV}/\\text{\\AA}^2$ is the spring constant. This force is zero when the image is equidistant from its neighbors.\n\nThe total force on a standard NEB image is $\\mathbf{F}_i^\\mathrm{NEB} = \\mathbf{F}_i^\\perp + \\mathbf{F}_i^{S,\\parallel}$.\n\n**3. Climbing-Image (CI) Refinement**\n\nThe standard NEB method can struggle to converge precisely to the saddle point due to the influence of the spring forces. The CI-NEB modification addresses this by altering the force on the single highest-energy interior image (the \"climbing image\"), let its index be $i_m$. For this image, the component of the true force parallel to the path is inverted, and the spring force is removed. This drives the image uphill along the MEP to converge exactly at the saddle point.\n\nThe force on the climbing image is:\n$$\n\\mathbf{F}_{i_m}^\\mathrm{CI} = \\mathbf{F}_{i_m} - 2(\\mathbf{F}_{i_m} \\cdot \\hat{\\tau}_{i_m})\\hat{\\tau}_{i_m} = \\mathbf{F}_{i_m}^\\perp - \\mathbf{F}_{i_m}^\\parallel\n$$\n\n**4. Algorithmic Procedure**\n\nThe diffusion barrier is computed through the following steps for each parameter set $(A,B)$:\n\n1.  **Initialization:** The path is initialized as a chain of $N=16$ images by linear interpolation between the start point $\\mathbf{r}_0=(0,0)$ and the end point $\\mathbf{r}_{N-1}=(a,0)$.\n    $$\n    \\mathbf{r}_i = \\mathbf{r}_0 + \\frac{i}{N-1}(\\mathbf{r}_{N-1} - \\mathbf{r}_0) \\quad \\text{for } i \\in \\{0, 1, \\dots, N-1\\}\n    $$\n\n2.  **Iterative Relaxation:** The positions of the $N-2$ interior images are updated for a fixed number of $n_\\mathrm{iter}=4000$ iterations. In each iteration:\n    a. The potential energy $U(\\mathbf{r}_i)$ is calculated for each interior image to identify the climbing image index, $i_m = \\mathrm{argmax}_{i \\in \\{1, \\dots, N-2\\}} U(\\mathbf{r}_i)$.\n    b. For each interior image $i \\in \\{1, \\dots, N-2\\}$, the appropriate update force $\\mathbf{F}^{\\mathrm{update_i}}$ is calculated: $\\mathbf{F}_{i_m}^\\mathrm{CI}$ if $i=i_m$, and $\\mathbf{F}_i^\\mathrm{NEB}$ otherwise.\n    c. The positions of all interior images are updated simultaneously using a simple Euler integration scheme with a step factor $\\alpha = 0.02\\,\\text{\\AA}^2/\\mathrm{eV}$:\n    $$\n    \\mathbf{r}_i \\leftarrow \\mathbf{r}_i + \\alpha \\mathbf{F}^{\\mathrm{update}}_i\n    $$\n\n3.  **Barrier Calculation:** After $n_\\mathrm{iter}$ iterations, the potential energy is calculated for all images on the final, converged path. The diffusion barrier $\\Delta E$ is the difference between the maximum energy along the path, $E_\\mathrm{max} = \\max_i U(\\mathbf{r}_i)$, and the energy of the initial (and final) minimum, $E_\\mathrm{min} = U(\\mathbf{r}_0)$.\n    $$\n    \\Delta E = E_\\mathrm{max} - E_\\mathrm{min}\n    $$\nThe entire process is automated in the provided program, which computes $\\Delta E$ for each of the six test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the diffusion barrier for a carbon adatom on graphene using a\n    Climbing-Image Nudged Elastic Band (CI-NEB) method on a surrogate\n    potential energy surface.\n    \"\"\"\n    # Define physical and numerical constants from the problem statement.\n    a = 2.46  # Graphene lattice constant in Angstroms\n    N = 16  # Number of images in the chain\n    k_spr = 5.0  # Spring constant in eV/A^2\n    alpha = 0.02  # Relaxation step factor in A^2/eV\n    n_iter = 4000  # Number of relaxation iterations\n\n    # Test cases: parameters (A, B) in eV, representing different\n    # exchange-correlation functional choices.\n    test_cases = [\n        (-0.1125, 0.0500),  # 1. LDA-like\n        (-0.0825, 0.0400),  # 2. PBE-like\n        (-0.1000, 0.0550),  # 3. SCAN-like\n        (-0.0925, 0.0500),  # 4. r2SCAN-like\n        (-0.0725, 0.0800),  # 5. vdW-DF-like\n        (-0.0100, 0.0100),  # 6. Flat-limit edge case\n    ]\n\n    # Pre-calculate reciprocal lattice vectors for efficiency.\n    b1 = np.array([2 * np.pi / a, -2 * np.pi / (a * np.sqrt(3))])\n    b2 = np.array([0, 4 * np.pi / (a * np.sqrt(3))])\n    b3 = -(b1 + b2)\n    b_vectors = np.array([b1, b2, b3])\n\n    def get_potential(r, A, B):\n        \"\"\"Calculates the potential energy U(r) for one or more positions.\"\"\"\n        # Ensure r is 2D for consistent matrix operations.\n        if r.ndim == 1:\n            r = r.reshape(1, -1)\n        # dot_products will be a (3, num_points) array.\n        dot_products = np.dot(b_vectors, r.T)\n        cos_term1 = np.cos(dot_products)\n        cos_term2 = np.cos(2 * dot_products)\n        # Sum over the 3 reciprocal vectors for each point.\n        potential = A * np.sum(cos_term1, axis=0) + B * np.sum(cos_term2, axis=0)\n        return potential[0] if potential.size == 1 else potential\n\n    def get_force(r, A, B):\n        \"\"\"Calculates the force F(r) = -grad(U) at a single position.\"\"\"\n        dot_products = np.dot(b_vectors, r)  # shape (3,)\n        sin_term1 = np.sin(dot_products)\n        sin_term2 = np.sin(2 * dot_products)\n        # b_vectors.T is (2,3). Broadcasting with (3,) sin arrays.\n        force_vec_contribs = A * b_vectors.T * sin_term1 + 2 * B * b_vectors.T * sin_term2\n        # Sum over contributions from the 3 reciprocal vectors.\n        return np.sum(force_vec_contribs, axis=1) # shape (2,)\n\n    results = []\n    for A, B in test_cases:\n        # 1. Initialize the path via linear interpolation.\n        r_start = np.array([0.0, 0.0])\n        r_end = np.array([a, 0.0])\n        path = np.array([r_start + i / (N - 1) * (r_end - r_start) for i in range(N)])\n\n        # 2. Perform iterative relaxation.\n        for _ in range(n_iter):\n            # Calculate energies of interior images to find the one to climb.\n            interior_energies = get_potential(path[1:-1], A, B)\n            # Add 1 to map from interior index to full path index.\n            climbing_image_idx = np.argmax(interior_energies) + 1\n\n            forces_update = np.zeros_like(path[1:-1])\n            \n            # Calculate tangents for all interior images.\n            tangents = path[2:] - path[:-2]  # r_{i+1} - r_{i-1}\n            norms = np.linalg.norm(tangents, axis=1)\n            # Avoid division by zero, though unlikely with spring forces.\n            safe_norms = np.where(norms == 0, 1.0, norms)\n            tau_hats = tangents / safe_norms[:, np.newaxis]\n\n            for i in range(1, N - 1):\n                # Tangent for image i (path index) is at tau_hats[i-1].\n                tau_hat = tau_hats[i-1]\n                true_force = get_force(path[i], A, B)\n\n                if i == climbing_image_idx:\n                    # Apply climbing-image force modification.\n                    force_parallel_comp = np.dot(true_force, tau_hat)\n                    update_force = true_force - 2 * force_parallel_comp * tau_hat\n                else:\n                    # Apply standard NEB force.\n                    force_perp = true_force - np.dot(true_force, tau_hat) * tau_hat\n                    len_after = np.linalg.norm(path[i+1] - path[i])\n                    len_before = np.linalg.norm(path[i] - path[i-1])\n                    force_spring_parallel = k_spr * (len_after - len_before) * tau_hat\n                    update_force = force_perp + force_spring_parallel\n                \n                forces_update[i-1] = update_force\n\n            # Update all interior image positions simultaneously.\n            path[1:-1] += alpha * forces_update\n        \n        # 3. Calculate the diffusion barrier from the converged path.\n        final_energies = get_potential(path, A, B)\n        energy_min = get_potential(r_start, A, B)\n        energy_max = np.max(final_energies)\n        barrier = energy_max - energy_min\n        results.append(round(barrier, 6))\n\n    # Print results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2791194"}, {"introduction": "This final practice bridges the gap between theoretical models and experimental reality, where measurements are always subject to noise and uncertainty. You will first simulate an adatom's random walk using a kinetic Monte Carlo (KMC) algorithm and then tackle the inverse problem: estimating the diffusion coefficient $D$ from a noisy time-series of positions. This exercise introduces the powerful framework of Bayesian inference, enabling you to not only extract the most probable value for $D$ but also to rigorously quantify the confidence in your estimate, a crucial skill for interpreting experimental data [@problem_id:2791218].", "problem": "You are given the task of estimating the surface diffusion coefficient $D$ of a single adatom undergoing two-dimensional migration on a crystalline surface by fitting kinetic Monte Carlo (KMC) simulated trajectories to synthetic experimental time-series data, and quantifying uncertainty via Bayesian inference with appropriate priors. The adatom resides on a square lattice with lattice spacing $a$ and performs a continuous-time nearest-neighbor random walk: the waiting time between jumps is exponentially distributed with a rate $k$ that is constant in time, and each jump changes the position by $\\pm a$ along either the $x$ or $y$ axis with equal probability. Measurements are made at discrete times and are corrupted by independent Gaussian noise in each coordinate with known standard deviation $\\sigma_{\\text{obs}}$.\n\nStarting from fundamental principles for continuous-time random walks and diffusion, derive a likelihood for the observed increments and use it within a Bayesian framework to infer $D$ with an appropriate prior that reflects scale invariance. Implement the inference numerically on a logarithmically spaced grid for $D$ and report the posterior mean and a $95\\%$ equal-tailed credible interval for $D$.\n\nRequirements:\n\n1. Physical model and inference target\n   - Model the underlying adatom dynamics as a continuous-time nearest-neighbor random walk (a continuous-time Markov chain) on a square lattice of spacing $a$ with jump rate $k$.\n   - The effective two-dimensional diffusion coefficient $D$ is related to the microscopic parameters by a relationship that must be derived from first principles in your solution.\n   - Observations: at times $0 = t_0 &lt; t_1 &lt; \\dots &lt; t_N$, the measured positions $\\mathbf{Z}_i = (Z^x_i,Z^y_i)$ satisfy $\\mathbf{Z}_i = \\mathbf{X}(t_i) + \\boldsymbol{\\varepsilon}_i$, where $\\mathbf{X}(t)$ is the true trajectory and $\\boldsymbol{\\varepsilon}_i$ are independent zero-mean Gaussian errors with covariance $\\sigma_{\\text{obs}}^2 \\mathbf{I}_2$.\n\n2. Likelihood construction\n   - Starting from the definition of a continuous-time random walk and the central limit behavior for many jumps, derive a tractable likelihood for the observed increments $\\Delta \\mathbf{Z}_i = \\mathbf{Z}_{i+1} - \\mathbf{Z}_i$ given $D$, the sampling intervals $\\Delta t_i = t_{i+1} - t_i$, and the known $\\sigma_{\\text{obs}}$.\n   - Your derivation must begin from core definitions (Poisson jump counting, independence of jumps, additivity of variances) and not from shortcut formulas, and it must clearly justify any Gaussian approximation used.\n\n3. Prior and posterior\n   - Use a prior for $D$ that is invariant to the choice of unit scale for $D$ over a physically reasonable bounded domain $[D_{\\min},D_{\\max}]$. State and justify your choice.\n   - Compute the posterior over $D$ numerically on a grid that is uniform in $\\log D$.\n   - From this posterior, compute the posterior mean and the equal-tailed $95\\%$ credible interval for $D$.\n\n4. Data generation via Kinetic Monte Carlo (for test reproducibility)\n   - For each test case below, generate a synthetic “experimental” trajectory by KMC using the underlying true diffusion coefficient $D_{\\text{true}}$ of that test. Use the derived relationship between $D$ and $k$ to parameterize the KMC jump process. Simulate the piecewise-constant trajectory $\\mathbf{X}(t)$ exactly by sampling exponential waiting times and jump directions, then sample the observed positions at the specified times and add independent Gaussian noise with standard deviation $\\sigma_{\\text{obs}}$ in each coordinate.\n   - Use a fixed random seed of $1729$ to ensure reproducibility across all tests.\n\n5. Units and output\n   - All diffusion coefficients must be expressed in $\\mathrm{m}^2/\\mathrm{s}$.\n   - Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a three-element list $[m,\\ell,u]$ containing the posterior mean $m$, the lower bound $\\ell$, and the upper bound $u$ of the $95\\%$ credible interval for $D$, all in $\\mathrm{m}^2/\\mathrm{s}$. Use standard floating-point formatting; scientific notation is acceptable.\n\n6. Test suite\n   - Use the following four test cases. For each case, generate observation times, simulate a KMC trajectory with the specified parameters, add measurement noise, and then infer $D$ from the noisy time series.\n   - Common settings: set the Jeffreys prior bounds to $D_{\\min} = 10^{-24}\\ \\mathrm{m}^2/\\mathrm{s}$ and $D_{\\max} = 10^{-14}\\ \\mathrm{m}^2/\\mathrm{s}$, and the lattice spacing to $a = 2.5 \\times 10^{-10}\\ \\mathrm{m}$.\n   - Case A (happy path): $D_{\\text{true}} = 5.0 \\times 10^{-19}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1000$ increments with uniform sampling interval $\\Delta t = 0.1\\ \\mathrm{s}$, measurement noise $\\sigma_{\\text{obs}} = 2.0 \\times 10^{-11}\\ \\mathrm{m}$.\n   - Case B (low-$D$ boundary): $D_{\\text{true}} = 1.0 \\times 10^{-21}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1000$ increments with uniform sampling interval $\\Delta t = 0.1\\ \\mathrm{s}$, measurement noise $\\sigma_{\\text{obs}} = 1.0 \\times 10^{-11}\\ \\mathrm{m}$.\n   - Case C (uneven sampling): $D_{\\text{true}} = 2.0 \\times 10^{-18}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 800$ increments with independently drawn sampling intervals $\\Delta t_i$ uniformly distributed between $0.05\\ \\mathrm{s}$ and $0.2\\ \\mathrm{s}$, measurement noise $\\sigma_{\\text{obs}} = 3.0 \\times 10^{-11}\\ \\mathrm{m}$.\n   - Case D (high observation noise): $D_{\\text{true}} = 1.0 \\times 10^{-19}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1500$ increments with uniform sampling interval $\\Delta t = 0.05\\ \\mathrm{s}$, measurement noise $\\sigma_{\\text{obs}} = 1.0 \\times 10^{-10}\\ \\mathrm{m}$.\n\n7. Final output format\n   - Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order [Case A, Case B, Case C, Case D]. Each case should be a list with three floats $[m,\\ell,u]$ giving the posterior mean and $95\\%$ credible interval bounds for $D$ in $\\mathrm{m}^2/\\mathrm{s}$. For example: [[m_A,l_A,u_A],[m_B,l_B,u_B],[m_C,l_C,u_C],[m_D,l_D,u_D]].\n\nYour final answer must be a complete, runnable program that performs all steps without any user input and prints only the specified single-line output.", "solution": "We start from the continuous-time random walk model for adatom migration on a crystalline surface. The adatom resides on a two-dimensional square lattice with lattice spacing $a$, and undergoes nearest-neighbor jumps. The waiting time $\\tau$ between jumps is exponentially distributed with rate $k$, so that the number of jumps $N(t)$ in time interval $[0,t]$ is a Poisson random variable with mean $\\mathbb{E}[N(t)] = k t$. Each jump is independent and changes the position by one of the four vectors $\\{(\\pm a,0),(0,\\pm a)\\}$ with equal probability $1/4$.\n\nRelation between $D$ and $k$. Consider the displacement after $n$ jumps. Let $\\Delta \\mathbf{r}_j$ be the $j$-th jump vector. The net displacement after $n$ jumps is $\\mathbf{R}_n = \\sum_{j=1}^n \\Delta \\mathbf{r}_j$. Because the jumps are independent, centered, and isotropic on the lattice, we have $\\mathbb{E}[\\Delta \\mathbf{r}_j] = \\mathbf{0}$ and $\\mathbb{E}[\\|\\Delta \\mathbf{r}_j\\|^2] = a^2$. Cross terms vanish in expectation by independence and zero mean, so $\\mathbb{E}[\\|\\mathbf{R}_n\\|^2] = \\sum_{j=1}^n \\mathbb{E}[\\|\\Delta \\mathbf{r}_j\\|^2] = n a^2$. In continuous time, the number of jumps $N(t)$ is Poisson with mean $k t$, and the mean-squared displacement becomes\n$$\n\\mathbb{E}\\left[\\|\\mathbf{X}(t) - \\mathbf{X}(0)\\|^2\\right] = \\mathbb{E}\\left[\\|\\mathbf{R}_{N(t)}\\|^2\\right] = a^2 \\, \\mathbb{E}[N(t)] = a^2 k t.\n$$\nFor a two-dimensional diffusive process with diffusion coefficient $D$, the Einstein relation gives $\\mathbb{E}[\\|\\mathbf{X}(t) - \\mathbf{X}(0)\\|^2] = 4 D t$. Equating the two expressions yields the fundamental relationship between the microscopic jump rate and the macroscopic diffusion coefficient:\n$$\nD = \\frac{a^2 k}{4}.\n$$\nThis derivation used only the core definitions of the continuous-time Markov jump process and the well-tested Einstein relation for diffusion.\n\nObservation model and likelihood. Observations are made at strictly increasing times $0 = t_0 &lt; t_1 &lt; \\dots &lt; t_N$. The measured positions are\n$$\n\\mathbf{Z}_i = \\mathbf{X}(t_i) + \\boldsymbol{\\varepsilon}_i,\n$$\nwhere $\\boldsymbol{\\varepsilon}_i \\sim \\mathcal{N}(\\mathbf{0}, \\sigma_{\\text{obs}}^2 \\mathbf{I}_2)$ are independent across $i$, and independent of the dynamical process. Consider the observed increments $\\Delta \\mathbf{Z}_i = \\mathbf{Z}_{i+1} - \\mathbf{Z}_i$ over intervals $\\Delta t_i = t_{i+1} - t_i$. We can write\n$$\n\\Delta \\mathbf{Z}_i = \\Delta \\mathbf{X}_i + \\boldsymbol{\\eta}_i,\n$$\nwhere $\\Delta \\mathbf{X}_i = \\mathbf{X}(t_{i+1}) - \\mathbf{X}(t_i)$ and $\\boldsymbol{\\eta}_i = \\boldsymbol{\\varepsilon}_{i+1} - \\boldsymbol{\\varepsilon}_i$. The noise differences satisfy $\\boldsymbol{\\eta}_i \\sim \\mathcal{N}(\\mathbf{0}, 2 \\sigma_{\\text{obs}}^2 \\mathbf{I}_2)$ and are independent across $i$ because the $\\boldsymbol{\\varepsilon}_i$ are independent. For the dynamics, over short intervals $\\Delta t_i$ containing many jumps on average, the central limit theorem for the random walk increments implies that $\\Delta \\mathbf{X}_i$ is approximately Gaussian with zero mean and covariance $2 D \\Delta t_i \\, \\mathbf{I}_2$ in each coordinate. This follows from additivity of independent jump increments and the convergence of the compound Poisson process to Brownian motion in the diffusive limit.\n\nTherefore, the increment $\\Delta \\mathbf{Z}_i$ is the sum of two independent centered Gaussians and is itself Gaussian:\n$$\n\\Delta \\mathbf{Z}_i \\sim \\mathcal{N}\\!\\left(\\mathbf{0}, \\left(2 D \\Delta t_i + 2 \\sigma_{\\text{obs}}^2\\right)\\mathbf{I}_2\\right).\n$$\nDenote the squared increment magnitude by $r_i^2 = (\\Delta Z^x_i)^2 + (\\Delta Z^y_i)^2$ and the per-coordinate variance by $v_i(D) = 2 D \\Delta t_i + 2 \\sigma_{\\text{obs}}^2$. The likelihood contribution from interval $i$ is the density of a two-dimensional isotropic Gaussian evaluated at $\\Delta \\mathbf{Z}_i$:\n$$\np(\\Delta \\mathbf{Z}_i \\mid D) = \\frac{1}{2 \\pi v_i(D)} \\exp\\!\\left(-\\frac{r_i^2}{2 v_i(D)}\\right).\n$$\nAssuming independence of increments given $D$ (which holds for both Brownian motion and independent observation noise), the full likelihood is the product over $i=0,\\dots,N-1$, and the log-likelihood is\n$$\n\\log p(\\{\\Delta \\mathbf{Z}_i\\} \\mid D) = - \\sum_{i=0}^{N-1} \\left[ \\log\\!\\left(2 \\pi v_i(D)\\right) + \\frac{r_i^2}{2 v_i(D)} \\right].\n$$\n\nPrior and posterior. The diffusion coefficient $D$ is a positive scale parameter. A standard choice that is invariant under changes of measurement scale is the Jeffreys prior, which for a scale parameter takes the form $p(D) \\propto 1/D$ over a bounded domain to make it proper. We adopt\n$$\np(D) = \\frac{1}{Z} \\cdot \\frac{1}{D} \\cdot \\mathbf{1}\\{D_{\\min} \\le D \\le D_{\\max}\\},\n$$\nwith $D_{\\min} = 10^{-24}\\ \\mathrm{m}^2/\\mathrm{s}$ and $D_{\\max} = 10^{-14}\\ \\mathrm{m}^2/\\mathrm{s}$, where $Z$ is the normalizing constant. Equivalently, this is a uniform prior on $\\theta = \\log D$ over $[\\log D_{\\min}, \\log D_{\\max}]$. Numerically, it is convenient to discretize $\\theta$ on an evenly spaced grid, compute the unnormalized posterior $p(\\theta \\mid \\text{data}) \\propto p(\\theta)\\, p(\\text{data}\\mid D(\\theta)) \\propto p(\\text{data}\\mid D(\\theta))$, normalize it by summation, and then compute posterior summaries by numerical quadrature over $\\theta$. Specifically, if $\\{\\theta_j\\}_{j=1}^G$ is a uniform grid on $[\\log D_{\\min}, \\log D_{\\max}]$ with spacing $\\Delta \\theta$, and $D_j = e^{\\theta_j}$, we set\n$$\nw_j \\propto \\exp\\!\\left(\\log p(\\{\\Delta \\mathbf{Z}_i\\} \\mid D_j)\\right),\n$$\nnormalize $p_j = w_j / \\sum_{m=1}^G w_m$, and then compute the posterior mean as\n$$\n\\mathbb{E}[D \\mid \\text{data}] \\approx \\sum_{j=1}^G D_j\\, p_j,\n$$\nand the equal-tailed $95\\%$ credible interval endpoints by the cumulative sums of $p_j$ reaching cumulative probabilities $0.025$ and $0.975$, respectively, both interpreted over the $\\theta$-grid (uniform prior on $\\theta$).\n\nData generation by Kinetic Monte Carlo. For each test case, we first construct the observation time grid. Then, given the specified $D_{\\text{true}}$ and lattice spacing $a$, we compute $k = 4 D_{\\text{true}} / a^2$ from the derived relation. We simulate a continuous-time random walk trajectory by drawing exponential waiting times with rate $k$ and, at each jump, selecting one of the four lattice directions with equal probability, accumulating the jump times and positions. The true position $\\mathbf{X}(t)$ is piecewise constant between jump times. To obtain the true positions at observation times $\\{t_i\\}$, we advance through the jump times and record the current lattice site at each $t_i$. Finally, we add independent Gaussian noise with standard deviation $\\sigma_{\\text{obs}}$ in each coordinate to form $\\mathbf{Z}_i$.\n\nTest suite specifics. We use the following four cases, all with lattice spacing $a = 2.5 \\times 10^{-10}\\ \\mathrm{m}$ and Jeffreys prior bounds $D_{\\min} = 10^{-24}\\ \\mathrm{m}^2/\\mathrm{s}$, $D_{\\max} = 10^{-14}\\ \\mathrm{m}^2/\\mathrm{s}$. Random seed is fixed at $1729$.\n\n- Case A: $D_{\\text{true}} = 5.0 \\times 10^{-19}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1000$ increments with uniform $\\Delta t = 0.1\\ \\mathrm{s}$, $\\sigma_{\\text{obs}} = 2.0 \\times 10^{-11}\\ \\mathrm{m}$.\n- Case B: $D_{\\text{true}} = 1.0 \\times 10^{-21}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1000$ increments with uniform $\\Delta t = 0.1\\ \\mathrm{s}$, $\\sigma_{\\text{obs}} = 1.0 \\times 10^{-11}\\ \\mathrm{m}$.\n- Case C: $D_{\\text{true}} = 2.0 \\times 10^{-18}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 800$ increments with $\\Delta t_i \\sim \\text{Uniform}(0.05, 0.2)\\ \\mathrm{s}$ independently, $\\sigma_{\\text{obs}} = 3.0 \\times 10^{-11}\\ \\mathrm{m}$.\n- Case D: $D_{\\text{true}} = 1.0 \\times 10^{-19}\\ \\mathrm{m}^2/\\mathrm{s}$, $N = 1500$ increments with uniform $\\Delta t = 0.05\\ \\mathrm{s}$, $\\sigma_{\\text{obs}} = 1.0 \\times 10^{-10}\\ \\mathrm{m}$.\n\nAlgorithmic implementation. The program proceeds as follows for each case:\n- Construct observation times $\\{t_i\\}$ by cumulative summation of the specified sampling intervals.\n- Generate a KMC trajectory with rate $k = 4 D_{\\text{true}} / a^2$, record true positions at $\\{t_i\\}$, and add Gaussian measurement noise with standard deviation $\\sigma_{\\text{obs}}$ to obtain observations.\n- Form observed increments $\\Delta \\mathbf{Z}_i$ and intervals $\\Delta t_i$.\n- On a grid $\\{\\theta_j\\}$ uniform in $\\log D$ over $[ \\log D_{\\min}, \\log D_{\\max}]$, evaluate the log-likelihood for each $D_j = e^{\\theta_j}$ using\n$$\n\\log p(\\{\\Delta \\mathbf{Z}_i\\} \\mid D_j) = - \\sum_{i=0}^{N-1} \\left[ \\log\\!\\left( 2 \\pi \\left( 2 D_j \\Delta t_i + 2 \\sigma_{\\text{obs}}^2 \\right) \\right) + \\frac{r_i^2}{2 \\left( 2 D_j \\Delta t_i + 2 \\sigma_{\\text{obs}}^2 \\right)} \\right].\n$$\n- Normalize the posterior on the $\\theta$-grid, compute the posterior mean $\\mathbb{E}[D \\mid \\text{data}]$ and the $2.5\\%$ and $97.5\\%$ quantiles for the equal-tailed $95\\%$ credible interval by summation and interpolation over the cumulative distribution on $\\theta$.\n\nAll reported diffusion coefficients must be expressed in $\\mathrm{m}^2/\\mathrm{s}$, and the program must print a single line containing a list of four lists, one per test case, each list being $[m,\\ell,u]$ with $m$ the posterior mean and $\\ell,u$ the lower and upper bounds of the $95\\%$ credible interval, respectively, all as floating-point numbers.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef kmc_generate_observations(D_true, a, t_obs, sigma_obs, rng):\n    \"\"\"\n    Generate a 2D KMC trajectory observed at times t_obs with Gaussian measurement noise.\n    Continuous-time nearest-neighbor random walk on square lattice with spacing a\n    and jump rate k = 4 D_true / a^2.\n    \"\"\"\n    k = 4.0 * D_true / (a * a)\n    # Handle k=0 edge case (immobile): just zeros\n    x, y = 0.0, 0.0\n    positions = np.zeros((len(t_obs), 2), dtype=float)\n\n    if k <= 0.0:\n        true_positions = positions.copy()\n    else:\n        # Simulate jump times and positions, then sample at t_obs\n        t = 0.0\n        # Iterator over observation times\n        idx_obs = 0\n        # Directions: (+a,0), (-a,0), (0,+a), (0,-a)\n        dirs = np.array([[a, 0.0], [-a, 0.0], [0.0, a], [0.0, -a]], dtype=float)\n        # Record positions at each observation time\n        while idx_obs < len(t_obs):\n            # Fill positions at current time before any new jump that exceeds current observation time\n            if t >= t_obs[idx_obs]:\n                positions[idx_obs, 0] = x\n                positions[idx_obs, 1] = y\n                idx_obs += 1\n                continue\n            # Generate next waiting time\n            wait = rng.exponential(1.0 / k)\n            # If next jump occurs after next observation, hold position until that obs time\n            if t + wait > t_obs[idx_obs]:\n                # No jump before next observation; just advance time to that obs time\n                t = t_obs[idx_obs]\n                positions[idx_obs, 0] = x\n                positions[idx_obs, 1] = y\n                idx_obs += 1\n            else:\n                # A jump occurs; update time and position\n                t += wait\n                step = dirs[rng.integers(0, 4)]\n                x += step[0]\n                y += step[1]\n        true_positions = positions\n\n    # Add Gaussian measurement noise\n    noisy_positions = true_positions + rng.normal(loc=0.0, scale=sigma_obs, size=true_positions.shape)\n    return noisy_positions\n\ndef compute_loglikelihood(D, dx, dy, dt, sigma_obs):\n    \"\"\"\n    Compute the log-likelihood of observed increments given D, under the Gaussian increment model:\n    Delta Z_i ~ N(0, (2 D dt_i + 2 sigma_obs^2) I_2).\n    \"\"\"\n    # Per-coordinate variance for each interval\n    var = 2.0 * D * dt + 2.0 * (sigma_obs ** 2)\n    # Avoid numerical issues if var is extremely small\n    # Clip at a small positive minimum\n    var = np.clip(var, 1e-300, None)\n    r2 = dx * dx + dy * dy\n    # For 2D isotropic Gaussian: density = (1 / (2*pi*var)) * exp(-r2 / (2*var))\n    # Log-likelihood sum over intervals\n    loglik = -np.sum(np.log(2.0 * np.pi * var) + r2 / (2.0 * var))\n    return loglik\n\ndef bayes_posterior_stats(dx, dy, dt, sigma_obs, D_min=1e-24, D_max=1e-14, ngrid=1600):\n    \"\"\"\n    Compute posterior over D using a Jeffreys prior (uniform in log D) on [D_min, D_max].\n    Return posterior mean and equal-tailed 95% credible interval.\n    \"\"\"\n    theta_grid = np.linspace(np.log(D_min), np.log(D_max), ngrid)\n    D_grid = np.exp(theta_grid)\n\n    # Vectorized log-likelihood evaluation\n    # For numerical stability, subtract the maximum log-likelihood before exponentiating.\n    loglik_vals = np.array([compute_loglikelihood(D, dx, dy, dt, sigma_obs) for D in D_grid])\n    max_ll = np.max(loglik_vals)\n    weights_unnorm = np.exp(loglik_vals - max_ll)\n\n    # Posterior over theta is proportional to weights_unnorm (since prior over theta is uniform)\n    weights_sum = np.sum(weights_unnorm)\n    if not np.isfinite(weights_sum) or weights_sum <= 0.0:\n        # Fallback: if degenerate, return nan\n        return float('nan'), float('nan'), float('nan')\n\n    p_theta = weights_unnorm / weights_sum\n\n    # Posterior mean E[D] = ∫ e^theta p(theta|data) dtheta ≈ sum(D_j * p_theta_j)\n    post_mean = float(np.sum(D_grid * p_theta))\n\n    # Compute equal-tailed 95% credible interval from CDF over theta\n    cdf = np.cumsum(p_theta)\n    # Ensure last element is exactly one\n    cdf[-1] = 1.0\n\n    def quantile_from_cdf(prob):\n        # Find first index where cdf >= prob\n        idx = np.searchsorted(cdf, prob, side='left')\n        if idx == 0:\n            return float(D_grid[0])\n        elif idx >= len(cdf):\n            return float(D_grid[-1])\n        else:\n            # Linear interpolation on the theta-grid CDF\n            cdf_lo = cdf[idx - 1]\n            cdf_hi = cdf[idx]\n            theta_lo = theta_grid[idx - 1]\n            theta_hi = theta_grid[idx]\n            if cdf_hi == cdf_lo:\n                theta_q = theta_lo\n            else:\n                frac = (prob - cdf_lo) / (cdf_hi - cdf_lo)\n                theta_q = theta_lo + frac * (theta_hi - theta_lo)\n            return float(np.exp(theta_q))\n\n    lower = quantile_from_cdf(0.025)\n    upper = quantile_from_cdf(0.975)\n\n    return post_mean, lower, upper\n\ndef prepare_test_cases():\n    # Common parameters\n    a = 2.5e-10  # meters\n    rng = np.random.default_rng(1729)\n\n    test_cases = []\n\n    # Case A\n    D_true_A = 5.0e-19\n    N_A = 1000\n    dt_A = np.full(N_A, 0.1)\n    t_obs_A = np.concatenate(([0.0], np.cumsum(dt_A)))\n    sigma_A = 2.0e-11\n    Z_A = kmc_generate_observations(D_true_A, a, t_obs_A, sigma_A, rng)\n    test_cases.append((Z_A, t_obs_A, sigma_A))\n\n    # Case B\n    D_true_B = 1.0e-21\n    N_B = 1000\n    dt_B = np.full(N_B, 0.1)\n    t_obs_B = np.concatenate(([0.0], np.cumsum(dt_B)))\n    sigma_B = 1.0e-11\n    Z_B = kmc_generate_observations(D_true_B, a, t_obs_B, sigma_B, rng)\n    test_cases.append((Z_B, t_obs_B, sigma_B))\n\n    # Case C (uneven sampling)\n    D_true_C = 2.0e-18\n    N_C = 800\n    dt_C = rng.uniform(0.05, 0.2, size=N_C)\n    t_obs_C = np.concatenate(([0.0], np.cumsum(dt_C)))\n    sigma_C = 3.0e-11\n    Z_C = kmc_generate_observations(D_true_C, a, t_obs_C, sigma_C, rng)\n    test_cases.append((Z_C, t_obs_C, sigma_C))\n\n    # Case D (high observation noise)\n    D_true_D = 1.0e-19\n    N_D = 1500\n    dt_D = np.full(N_D, 0.05)\n    t_obs_D = np.concatenate(([0.0], np.cumsum(dt_D)))\n    sigma_D = 1.0e-10\n    Z_D = kmc_generate_observations(D_true_D, a, t_obs_D, sigma_D, rng)\n    test_cases.append((Z_D, t_obs_D, sigma_D))\n\n    return test_cases\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = prepare_test_cases()\n\n    results = []\n    for Z, t_obs, sigma_obs in test_cases:\n        # Compute increments and time intervals\n        dZ = Z[1:] - Z[:-1]\n        dx = dZ[:, 0]\n        dy = dZ[:, 1]\n        dt = t_obs[1:] - t_obs[:-1]\n        # Bayesian inference for D\n        mean_D, lo_D, hi_D = bayes_posterior_stats(dx, dy, dt, sigma_obs,\n                                                   D_min=1e-24, D_max=1e-14, ngrid=2000)\n        # Format as scientific notation with 6 significant digits for readability\n        results.append([f\"{mean_D:.6e}\", f\"{lo_D:.6e}\", f\"{hi_D:.6e}\"])\n\n    # Final print statement in the exact required format.\n    # Print nested list with each inner list corresponding to a case [mean, lower, upper]\n    inner = [f\"[{','.join(case)}]\" for case in results]\n    print(f\"[{','.join(inner)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2791218"}]}