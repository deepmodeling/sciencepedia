{"hands_on_practices": [{"introduction": "This exercise provides a direct application of interfacial thermodynamics, connecting the experimentally measurable temperature dependence of surface tension to the fundamental concepts of surface excess entropy and enthalpy. By performing a numerical differentiation on provided data for water, you will gain practical experience in calculating these key thermodynamic quantities, $s^{\\sigma}$ and $h^{\\sigma}$. This practice reinforces the physical meaning of surface excess properties as measures of disorder and energy cost at the interface [@problem_id:2792430].", "problem": "A planar waterâ€“air interface at atmospheric pressure is considered. Let the surface tension be denoted by $\\gamma(T)$ and the surface excess entropy per unit area and surface excess enthalpy per unit area be denoted by $s^{\\sigma}(T)$ and $h^{\\sigma}(T)$, respectively. Assume a single-component system (water) and use the Gibbs construction of the dividing surface such that the surface excess volume and surface excess number of molecules vanish for the planar interface.\n\nUsing first-principles thermodynamics for surfaces of pure substances, derive expressions relating $s^{\\sigma}(T)$ and $h^{\\sigma}(T)$ to $\\gamma(T)$ and its temperature derivative at fixed pressure. Then, using the following tabulated values of $\\gamma(T)$ for water near room temperature, numerically evaluate $s^{\\sigma}(298.15\\,\\mathrm{K})$ and $h^{\\sigma}(298.15\\,\\mathrm{K})$:\n- $T = 293.15\\,\\mathrm{K}$, $\\gamma = 72.77\\,\\mathrm{mN}\\,\\mathrm{m}^{-1}$\n- $T = 298.15\\,\\mathrm{K}$, $\\gamma = 71.97\\,\\mathrm{mN}\\,\\mathrm{m}^{-1}$\n- $T = 303.15\\,\\mathrm{K}$, $\\gamma = 71.17\\,\\mathrm{mN}\\,\\mathrm{m}^{-1}$\n\nApproximate $\\left.\\partial \\gamma / \\partial T\\right|_{T=298.15\\,\\mathrm{K}}$ by a central difference using the neighbors at $293.15\\,\\mathrm{K}$ and $303.15\\,\\mathrm{K}$. Comment on the sign and order of magnitude of $s^{\\sigma}$ and $h^{\\sigma}$ relative to representative bulk values for liquid water near room temperature, $s_{\\mathrm{bulk}} \\approx 3.9 \\times 10^{6}\\,\\mathrm{J}\\,\\mathrm{m}^{-3}\\,\\mathrm{K}^{-1}$ and $\\rho c_{p} T \\approx 1.2 \\times 10^{9}\\,\\mathrm{J}\\,\\mathrm{m}^{-3}$, and explain the physical meaning of your comparison.\n\nReport as your final answer only the numerical value of $h^{\\sigma}(298.15\\,\\mathrm{K})$ in $\\mathrm{J}\\,\\mathrm{m}^{-2}$, rounded to three significant figures. Do not include units in the final reported number.", "solution": "The problem as stated is scientifically grounded, well-posed, and self-contained. It is a standard exercise in the thermodynamics of interfaces based on the Gibbs model. All data and conditions are provided and are physically consistent. Therefore, we proceed with the solution.\n\nThe fundamental thermodynamic properties of a surface are described by surface excess quantities. For a single-component system, the change in surface tension, $\\gamma$, which is the surface excess Gibbs free energy per unit area ($g^{\\sigma}$), is given by the Gibbs adsorption equation:\n$$d\\gamma = -s^{\\sigma} dT + \\tau dP - \\Gamma d\\mu$$\nHere, $s^{\\sigma}$ is the surface excess entropy per unit area, $T$ is the absolute temperature, $\\tau$ is the surface thickness (related to surface excess volume), $P$ is the pressure, $\\Gamma$ is the surface excess concentration, and $\\mu$ is the chemical potential.\n\nThe problem specifies the use of the Gibbs dividing surface such that the surface excess number of molecules (and thus concentration $\\Gamma$) is zero. For a planar interface, this choice also results in a zero surface excess volume, and by extension, $\\tau=0$. The experiment is conducted at constant atmospheric pressure, so $dP=0$. Under these specific and standard conditions for a pure substance, the equation simplifies significantly to:\n$$d\\gamma = -s^{\\sigma} dT$$\nFrom this, we directly obtain the expression for the surface excess entropy per unit area at constant pressure:\n$$s^{\\sigma}(T) = -\\left(\\frac{\\partial \\gamma}{\\partial T}\\right)_{P}$$\nThis is the first required relation.\n\nNext, we derive the expression for the surface excess enthalpy per unit area, $h^{\\sigma}(T)$. The surface excess enthalpy is related to the surface excess Gibbs free energy and surface excess entropy by the standard thermodynamic definition:\n$$g^{\\sigma} = h^{\\sigma} - T s^{\\sigma}$$\nRecognizing that the surface tension $\\gamma$ is the surface excess Gibbs free energy per unit area, $\\gamma = g^{\\sigma}$, we can write:\n$$h^{\\sigma} = \\gamma + T s^{\\sigma}$$\nSubstituting the previously derived expression for $s^{\\sigma}$ into this equation gives the second required relation, which is the Gibbs-Helmholtz equation for the surface:\n$$h^{\\sigma}(T) = \\gamma(T) - T \\left(\\frac{\\partial \\gamma}{\\partial T}\\right)_{P}$$\n\nNow, we proceed to the numerical evaluation. The problem requires the evaluation of $(\\partial \\gamma / \\partial T)_{P}$ at $T = 298.15\\,\\mathrm{K}$ using a central difference approximation with the provided data.\nThe data are:\n$T_1 = 293.15\\,\\mathrm{K}$, $\\gamma_1 = 72.77\\,\\mathrm{mN}\\,\\mathrm{m}^{-1} = 72.77 \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$\n$T_2 = 298.15\\,\\mathrm{K}$, $\\gamma_2 = 71.97\\,\\mathrm{mN}\\,\\mathrm{m}^{-1} = 71.97 \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$\n$T_3 = 303.15\\,\\mathrm{K}$, $\\gamma_3 = 71.17\\,\\mathrm{mN}\\,\\mathrm{m}^{-1} = 71.17 \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$\n\nThe central difference approximation for the derivative at $T_2$ is:\n$$\\left.\\frac{\\partial \\gamma}{\\partial T}\\right|_{T=298.15\\,\\mathrm{K}} \\approx \\frac{\\gamma_3 - \\gamma_1}{T_3 - T_1} = \\frac{(71.17 - 72.77) \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}}{(303.15 - 293.15)\\,\\mathrm{K}}$$\n$$\\left.\\frac{\\partial \\gamma}{\\partial T}\\right|_{T=298.15\\,\\mathrm{K}} \\approx \\frac{-1.60 \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}}{10\\,\\mathrm{K}} = -1.60 \\times 10^{-4}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}$$\n\nUsing this derivative, we can now calculate $s^{\\sigma}$ and $h^{\\sigma}$ at $T=298.15\\,\\mathrm{K}$.\n$$s^{\\sigma}(298.15\\,\\mathrm{K}) = -\\left(\\frac{\\partial \\gamma}{\\partial T}\\right)_{P} \\approx -(-1.60 \\times 10^{-4}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}) = 1.60 \\times 10^{-4}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}$$\nFor the surface excess enthalpy:\n$$h^{\\sigma}(298.15\\,\\mathrm{K}) = \\gamma(298.15\\,\\mathrm{K}) - T \\left(\\frac{\\partial \\gamma}{\\partial T}\\right)_{P}$$\n$$h^{\\sigma}(298.15\\,\\mathrm{K}) \\approx (71.97 \\times 10^{-3}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}) - (298.15\\,\\mathrm{K})(-1.60 \\times 10^{-4}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1})$$\n$$h^{\\sigma}(298.15\\,\\mathrm{K}) \\approx 0.07197\\,\\mathrm{J}\\,\\mathrm{m}^{-2} + 0.047704\\,\\mathrm{J}\\,\\mathrm{m}^{-2} = 0.119674\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$$\n\nFinally, we comment on these results.\nThe surface excess entropy $s^{\\sigma}$ is positive. This signifies that the interfacial region is more disordered than the bulk liquid. Molecules at the surface have fewer nearest neighbors and weaker intermolecular interactions compared to molecules in the bulk, leading to greater motional freedom and thus higher entropy.\nThe surface excess enthalpy $h^{\\sigma}$ is also positive. Enthalpy is the energy required to form the system. A positive $h^{\\sigma}$ indicates that it costs energy to create the surface, which is physically consistent with the need to break cohesive bonds to bring molecules from the bulk to the surface. Note that $h^{\\sigma}$ is the total energy supplied to create the surface, comprising the work done, $\\gamma$, and the heat absorbed from the surroundings, $T s^{\\sigma}$. As $h^{\\sigma} \\approx 0.120\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$ is greater than $\\gamma \\approx 0.072\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$, the process of forming a water surface isothermally is endothermic.\n\nFor comparison with bulk properties, we must introduce a characteristic length scale for the interface thickness, $\\delta$, typically on the order of a few molecular diameters, e.g., $\\delta \\approx 1\\,\\mathrm{nm} = 10^{-9}\\,\\mathrm{m}$.\nWe compare the surface excess entropy $s^{\\sigma}$ to the entropy of a bulk layer of this thickness, $s_{\\mathrm{bulk}} \\times \\delta$:\n$$\\frac{s^{\\sigma}}{s_{\\mathrm{bulk}} \\times \\delta} \\approx \\frac{1.60 \\times 10^{-4}\\,\\mathrm{J}\\,\\mathrm{m}^{-2}\\,\\mathrm{K}^{-1}}{(3.9 \\times 10^{6}\\,\\mathrm{J}\\,\\mathrm{m}^{-3}\\,\\mathrm{K}^{-1}) \\times (10^{-9}\\,\\mathrm{m})} = \\frac{1.60 \\times 10^{-4}}{3.9 \\times 10^{-3}} \\approx 0.041$$\nThe surface excess entropy is about $4\\%$ of the entropy of a nanometer-thick layer of bulk water. This indicates that while the surface is indeed more disordered, the excess is a small fraction of the total entropy of the interfacial region.\n\nWe compare the surface excess enthalpy $h^{\\sigma}$ to the characteristic thermal energy density of the bulk, $(\\rho c_{p} T)$, over the same thickness $\\delta$:\n$$\\frac{h^{\\sigma}}{(\\rho c_{p} T) \\times \\delta} \\approx \\frac{0.119674\\,\\mathrm{J}\\,\\mathrm{m}^{-2}}{(1.2 \\times 10^{9}\\,\\mathrm{J}\\,\\mathrm{m}^{-3}) \\times (10^{-9}\\,\\mathrm{m})} = \\frac{0.119674}{1.2} \\approx 0.10$$\nThe surface excess enthalpy is approximately $10\\%$ of the characteristic thermal energy of a nanometer-thick layer of the bulk liquid. This demonstrates that the energy associated with creating the surface is significant at the molecular scale but constitutes a small, albeit non-trivial, fraction of the total energy of the region when viewed on a slightly larger scale.\n\nThe value of $h^{\\sigma}(298.15\\,\\mathrm{K})$ rounded to three significant figures is $0.120\\,\\mathrm{J}\\,\\mathrm{m}^{-2}$.", "answer": "$$\\boxed{1.20 \\times 10^{-1}}$$", "id": "2792430"}, {"introduction": "Moving from simple thermodynamics to the complex behavior near a critical point, this computational exercise explores how to model the vanishing of surface tension. You will compare a simple linear model against a physically-grounded power-law model derived from scaling theory, learning a valuable lesson in the limitations of analytic approximations near a singularity. This hands-on coding practice demonstrates the predictive power of critical scaling laws and develops crucial skills in model validation and data analysis [@problem_id:2792417].", "problem": "You are to implement a program that evaluates the predictive accuracy of two phenomenological models for the temperature dependence of surface tension in a simple fluid at the nanoscale (a Lennard-Jones-like fluid in reduced units), over the range where a stable liquid-vapor interface exists close to the critical point. The scenario is to generate synthetic observations that mimic a physically realistic near-critical decay of surface tension with temperature, and then compare two models on the same data: a linear-in-temperature model and a critical-scaling power-law model consistent with the empirical Guggenheim scaling framework. All symbols and temperatures are in reduced Lennard-Jones units, and therefore dimensionless.\n\nThe fundamental base to be used is as follows: (i) surface tension is the reversible work per unit area to create an interface and thus a free-energy density, (ii) the surface tension of simple fluids decreases with increasing temperature and vanishes at the critical temperature, (iii) generic analytic models away from singular points can be approximated to first order by a linear expansion in temperature, and (iv) near the critical point, experimentally observed and theoretically supported scaling laws describe non-analytic power-law decay of interfacial properties for simple fluids. The temperature range of interest is strictly between $0.6 T_c$ and $T_c$, where $T_c$ is the critical temperature.\n\nYou will do the following for each test case:\n\n1. Synthetic data generation.\n   - A ground-truth functional dependence of surface tension on temperature is constructed to vanish at the critical temperature $T_c$ with a non-analytic algebraic singularity characterized by an exponent $\\mu_{\\text{true}}$ and an amplitude $A_{\\text{true}}$. Independent and identically distributed Gaussian noise with standard deviation $\\sigma$ is added to the training labels only.\n   - Training temperatures are sampled independently and uniformly from the open interval $(0.6 T_c,\\, 0.98 T_c)$ using a specified integer random seed for reproducibility. The number of training samples is $N_{\\text{train}}$.\n   - The test temperatures are placed deterministically on a uniform grid in the closed interval $[0.6 T_c,\\, 0.99 T_c]$ with $N_{\\text{test}}$ points. The test target values are the noise-free ground-truth values at these temperatures.\n\n2. Model fitting on the training set.\n   - Model L (linear-in-temperature): an affine dependence of surface tension on temperature is fitted by ordinary least squares to the noisy training data. This corresponds to the first-order analytic approximation in temperature relative to a reference.\n   - Model G (critical-scaling/Guggenheim-like): a power-law dependence with a fixed exponent $\\mu_g$ is fitted by ordinary least squares for the amplitude only, consistent with the vanishing of surface tension at $T=T_c$.\n\n3. Accuracy evaluation on the test set.\n   - For each model, compute the root-mean-square error (RMSE) on the test grid against the noise-free ground-truth values. By construction, this evaluates how well each model recovers the underlying physics, not the particular noise realization.\n   - Report a single float per test case equal to $\\mathrm{RMSE}_{\\mathrm{L}} - \\mathrm{RMSE}_{\\mathrm{G}}$. A positive value indicates that the critical-scaling model outperforms the linear model on that test case.\n\nPrecise details to enforce reproducibility and coverage:\n\n- Use reduced Lennard-Jones units (dimensionless), so no physical unit conversion is needed.\n- Use the following fixed exponent for the Guggenheim-like model: $\\mu_g = 11/9$.\n- For the ground-truth generator, the exponent $\\mu_{\\text{true}}$ may equal $\\mu_g$ or differ slightly, depending on the test case.\n- For each test case, denote by $A_{\\text{true}}$ the amplitude, $T_c$ the critical temperature, $\\sigma$ the training noise standard deviation, $N_{\\text{train}}$ the number of training samples, $N_{\\text{test}}$ the number of test samples, and $\\text{seed}$ the integer random seed.\n\nTest suite to implement:\n\n- Case 1 (happy path, low noise):\n  - $T_c = 1.312$, $A_{\\text{true}} = 1.0$, $\\mu_{\\text{true}} = 11/9$, $\\sigma = 0.01$, $N_{\\text{train}} = 50$, $N_{\\text{test}} = 200$, $\\text{seed} = 0$.\n- Case 2 (increased noise):\n  - $T_c = 1.312$, $A_{\\text{true}} = 1.0$, $\\mu_{\\text{true}} = 11/9$, $\\sigma = 0.05$, $N_{\\text{train}} = 50$, $N_{\\text{test}} = 200$, $\\text{seed} = 1$.\n- Case 3 (small-sample training):\n  - $T_c = 1.312$, $A_{\\text{true}} = 1.0$, $\\mu_{\\text{true}} = 11/9$, $\\sigma = 0.01$, $N_{\\text{train}} = 8$, $N_{\\text{test}} = 200$, $\\text{seed} = 2$.\n- Case 4 (exponent mismatch to test robustness):\n  - $T_c = 1.312$, $A_{\\text{true}} = 1.0$, $\\mu_{\\text{true}} = 1.26$, $\\sigma = 0.01$, $N_{\\text{train}} = 50$, $N_{\\text{test}} = 200$, $\\text{seed} = 3$.\n- Case 5 (different amplitude and moderate noise):\n  - $T_c = 1.312$, $A_{\\text{true}} = 0.8$, $\\mu_{\\text{true}} = 11/9$, $\\sigma = 0.02$, $N_{\\text{train}} = 50$, $N_{\\text{test}} = 200$, $\\text{seed} = 4$.\n\nImplementation details to be followed by your program:\n\n- For the training set:\n  - Draw $T_{\\text{train},i} \\sim \\mathrm{Uniform}(0.6 T_c,\\, 0.98 T_c)$, $i=1,\\dots,N_{\\text{train}}$, using the specified seed.\n  - Compute noise-free ground truth surface tension values at $T_{\\text{train},i}$ from the near-critical algebraic decay with $A_{\\text{true}}$ and $\\mu_{\\text{true}}$, and then add independent Gaussian noise with standard deviation $\\sigma$.\n- For the test set:\n  - Construct $T_{\\text{test},j}$ as a uniform grid in $[0.6 T_c,\\, 0.99 T_c]$ with $N_{\\text{test}}$ points.\n  - Use the noise-free ground-truth model with $A_{\\text{true}}$ and $\\mu_{\\text{true}}$ to compute the target at $T_{\\text{test},j}$.\n- Fit Model L by ordinary least squares on $(T_{\\text{train},i}, \\gamma_{\\text{train},i})$ with an intercept term.\n- Fit Model G by ordinary least squares on $(x_i, \\gamma_{\\text{train},i})$ through the origin, where $x_i$ is the critical-scaling regressor constructed from $T_{\\text{train},i}$ using $\\mu_g$ and $T_c$.\n- Compute $\\mathrm{RMSE}_{\\mathrm{L}}$ and $\\mathrm{RMSE}_{\\mathrm{G}}$ on the test set against the noise-free ground truth, then output $\\mathrm{RMSE}_{\\mathrm{L}} - \\mathrm{RMSE}_{\\mathrm{G}}$ for each case.\n\nFinal output format:\n\n- Your program should produce a single line of output containing the $5$ real-valued results as a comma-separated list enclosed in square brackets, with each float rounded to exactly six decimal places (e.g., [$0.001234$,$0.056789$,$-0.012300$,$\\dots$]).", "solution": "The problem is subjected to validation.\n\n**Step 1: Extract Givens**\n\n- **Physical System:** A simple fluid (Lennard-Jones-like) in reduced units, exhibiting a liquid-vapor interface.\n- **Phenomenon:** Temperature dependence of surface tension, $\\gamma(T)$, near the critical temperature, $T_c$.\n- **Ground-Truth Model:** The true surface tension follows a non-analytic scaling law: $\\gamma_{\\text{true}}(T) = A_{\\text{true}}(1 - T/T_c)^{\\mu_{\\text{true}}}$.\n- **Synthetic Data Generation:**\n    - Training temperatures: $T_{\\text{train},i}$ for $i=1, \\dots, N_{\\text{train}}$ are sampled from $\\mathrm{Uniform}(0.6 T_c, 0.98 T_c)$ using a specified integer `seed`.\n    - Training surface tension values: $\\gamma_{\\text{train},i} = \\gamma_{\\text{true}}(T_{\\text{train},i}) + \\epsilon_i$, where $\\epsilon_i$ are i.i.d. samples from a Gaussian distribution $\\mathcal{N}(0, \\sigma^2)$.\n    - Test temperatures: $T_{\\text{test},j}$ for $j=1, \\dots, N_{\\text{test}}$ form a uniform grid on the closed interval $[0.6 T_c, 0.99 T_c]$.\n    - Test surface tension values: $\\gamma_{\\text{test},j}$ are the noise-free ground-truth values at $T_{\\text{test},j}$.\n- **Models for Comparison:**\n    - **Model L (Linear):** $\\gamma_L(T) = aT + b$. The parameters $a$ and $b$ are fitted to the training data using ordinary least squares (OLS).\n    - **Model G (Guggenheim-like):** $\\gamma_G(T) = A_G (1 - T/T_c)^{\\mu_g}$. The exponent is fixed at $\\mu_g = 11/9$. The amplitude $A_G$ is fitted to the training data using OLS for a regression through the origin.\n- **Evaluation Metric:** The root-mean-square error (RMSE) for each model is computed on the test set against the noise-free ground truth.\n- **Final Output:** Report the value of $\\mathrm{RMSE}_{\\mathrm{L}} - \\mathrm{RMSE}_{\\mathrm{G}}$ for each test case.\n- **Test Cases:** Five cases are defined with specific parameters for $T_c, A_{\\text{true}}, \\mu_{\\text{true}}, \\sigma, N_{\\text{train}}, N_{\\text{test}},$ and `seed`.\n    - Case 1: $T_c = 1.312, A_{\\text{true}} = 1.0, \\mu_{\\text{true}} = 11/9, \\sigma = 0.01, N_{\\text{train}} = 50, N_{\\text{test}} = 200, \\text{seed} = 0$.\n    - Case 2: $T_c = 1.312, A_{\\text{true}} = 1.0, \\mu_{\\text{true}} = 11/9, \\sigma = 0.05, N_{\\text{train}} = 50, N_{\\text{test}} = 200, \\text{seed} = 1$.\n    - Case 3: $T_c = 1.312, A_{\\text{true}} = 1.0, \\mu_{\\text{true}} = 11/9, \\sigma = 0.01, N_{\\text{train}} = 8, N_{\\text{test}} = 200, \\text{seed} = 2$.\n    - Case 4: $T_c = 1.312, A_{\\text{true}} = 1.0, \\mu_{\\text{true}} = 1.26, \\sigma = 0.01, N_{\\text{train}} = 50, N_{\\text{test}} = 200, \\text{seed} = 3$.\n    - Case 5: $T_c = 1.312, A_{\\text{true}} = 0.8, \\mu_{\\text{true}} = 11/9, \\sigma = 0.02, N_{\\text{train}} = 50, N_{\\text{test}} = 200, \\text{seed} = 4$.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is firmly rooted in the statistical mechanics of phase transitions and interfacial phenomena. The Guggenheim scaling law, $\\gamma(T) \\propto (1 - T/T_c)^\\mu$, where $\\mu$ is a universal critical exponent, is a cornerstone of this field. For simple fluids (like those described by the Lennard-Jones potential), the theoretical value from renormalization group theory is $\\mu \\approx 1.26$, and the empirical value is often cited as $\\mu \\approx 11/9$. The use of reduced units is standard practice. The problem is scientifically sound.\n- **Well-Posed:** The problem provides a complete and unambiguous description of the task. All constants, functional forms, data generation procedures, fitting methods, and evaluation metrics are explicitly defined for each test case. The use of a random seed ensures that the \"random\" data generation is deterministic and reproducible, leading to a unique solution.\n- **Objective:** The problem is stated with objective and precise language. It requires a quantitative comparison of two models based on a standard statistical error metric, free of subjective interpretation.\n\nAll other validation criteria are met. The problem is not unsound, incomplete, contradictory, unrealistic, ill-posed, or trivial.\n\n**Step 3: Verdict and Action**\n\nThe problem is valid. A reasoned solution will be provided.\n\n**Solution**\n\nThe objective is to implement a numerical experiment to compare the predictive accuracy of two competing models for the surface tension, $\\gamma$, of a simple fluid as a function of temperature, $T$, in the vicinity of the critical point, $T_c$. The two models are a generic linear approximation and a physically-motivated critical scaling law. All quantities are expressed in dimensionless reduced units.\n\n**Theoretical Framework**\nThe surface tension of a liquid is a measure of the excess free energy at its interface with a vapor phase. In accord with the second law of thermodynamics, this free energy must decrease as temperature increases, vanishing at the critical temperature $T_c$, where the distinction between liquid and vapor phases disappears.\n\nThe ground-truth behavior for the synthetic data is based on the well-established Guggenheim scaling law:\n$$\n\\gamma_{\\text{true}}(T) = A_{\\text{true}} \\left(1 - \\frac{T}{T_c}\\right)^{\\mu_{\\text{true}}}\n$$\nwhere $A_{\\text{true}}$ is the critical amplitude and $\\mu_{\\text{true}}$ is the critical exponent. This functional form captures the non-analytic nature of thermodynamic properties near a critical point.\n\nWe compare two models fitted to noisy data generated from this ground truth:\n1. **Model L (Linear):** $\\gamma_L(T) = aT + b$. This model represents a first-order Taylor series expansion of $\\gamma(T)$ around some reference temperature. While simple, it fails to capture the correct singular behavior as $T \\to T_c$, as it predicts a non-zero surface tension $\\gamma_L(T_c) = aT_c + b \\neq 0$.\n2. **Model G (Guggenheim-like):** $\\gamma_G(T) = A_G \\left(1 - \\frac{T}{T_c}\\right)^{\\mu_g}$. This model correctly incorporates the physical constraint that $\\gamma(T_c) = 0$ and assumes the correct functional form of the singularity. The exponent is fixed to the empirical value $\\mu_g = 11/9$, which is a constant close to the theoretical value for the universality class of simple fluids.\n\n**Algorithmic Procedure**\nFor each test case, we execute the following steps:\n\n**1. Data Generation**\n- We define the parameters for the given test case: $T_c, A_{\\text{true}}, \\mu_{\\text{true}}, \\sigma, N_{\\text{train}}, N_{\\text{test}},$ and `seed`.\n- Using a random number generator initialized with the specified `seed`, we draw $N_{\\text{train}}$ training temperatures, $T_{\\text{train},i}$, from a uniform distribution over the interval $(0.6 T_c, 0.98 T_c)$.\n- We generate the corresponding noisy training labels for surface tension:\n  $$\n  \\gamma_{\\text{train},i} = A_{\\text{true}}\\left(1 - \\frac{T_{\\text{train},i}}{T_c}\\right)^{\\mu_{\\text{true}}} + \\epsilon_i, \\quad \\text{where } \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n  $$\n- We create a deterministic grid of $N_{\\text{test}}$ test temperatures, $T_{\\text{test},j}$, linearly spaced in the interval $[0.6 T_c, 0.99 T_c]$.\n- The target values for the test set are the noise-free ground-truth values:\n  $$\n  \\gamma_{\\text{test},j} = A_{\\text{true}}\\left(1 - \\frac{T_{\\text{test},j}}{T_c}\\right)^{\\mu_{\\text{true}}}\n  $$\n\n**2. Model Fitting**\nThe models are fitted to the training set $(T_{\\text{train},i}, \\gamma_{\\text{train},i})$. Both fits are performed using ordinary least squares (OLS).\n\n- **For Model L:** We seek parameters $\\hat{a}$ and $\\hat{b}$ that minimize the sum of squared residuals: $\\sum_{i=1}^{N_{\\text{train}}} (\\gamma_{\\text{train},i} - (aT_{\\text{train},i} + b))^2$. This is a standard linear regression problem. The design matrix for this problem is $\\mathbf{X}_L \\in \\mathbb{R}^{N_{\\text{train}} \\times 2}$, with rows $[T_{\\text{train},i}, 1]$.\n- **For Model G:** We seek the parameter $\\hat{A}_G$ that minimizes $\\sum_{i=1}^{N_{\\text{train}}} (\\gamma_{\\text{train},i} - A_G x_i)^2$, where the regressor is $x_i = (1 - T_{\\text{train},i}/T_c)^{\\mu_g}$. This is a linear regression through the origin. The OLS estimator for the single parameter $A_G$ has a closed-form solution:\n  $$\n  \\hat{A}_G = \\frac{\\sum_{i=1}^{N_{\\text{train}}} x_i \\gamma_{\\text{train},i}}{\\sum_{i=1}^{N_{\\text{train}}} x_i^2}\n  $$\n\n**3. Model Evaluation**\nAfter fitting, we use the estimated parameters to make predictions on the test temperature grid, $T_{\\text{test},j}$.\n- Predictions from Model L: $\\hat{\\gamma}_{L,j} = \\hat{a} T_{\\text{test},j} + \\hat{b}$.\n- Predictions from Model G: $\\hat{\\gamma}_{G,j} = \\hat{A}_G (1 - T_{\\text{test},j}/T_c)^{\\mu_g}$.\n\nWe then compute the Root-Mean-Square Error (RMSE) for each model against the noise-free test targets, $\\gamma_{\\text{test},j}$.\n$$\n\\mathrm{RMSE}_{\\mathrm{L}} = \\sqrt{\\frac{1}{N_{\\text{test}}} \\sum_{j=1}^{N_{\\text{test}}} (\\hat{\\gamma}_{L,j} - \\gamma_{\\text{test},j})^2}\n$$\n$$\n\\mathrm{RMSE}_{\\mathrm{G}} = \\sqrt{\\frac{1}{N_{\\text{test}}} \\sum_{j=1}^{N_{\\text{test}}} (\\hat{\\gamma}_{G,j} - \\gamma_{\\text{test},j})^2}\n$$\nThe final reported value for each case is the difference $\\mathrm{RMSE}_{\\mathrm{L}} - \\mathrm{RMSE}_{\\mathrm{G}}$. A positive value signifies that Model G, the physically-motivated power law, provides a more accurate representation of the underlying physics than the generic linear model. This is expected, particularly as the temperature range approaches the critical point where the function's curvature becomes pronounced and its behavior is singular.\n\nThe implementation will now proceed to execute this procedure for the five specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are permitted.\n\ndef solve():\n    \"\"\"\n    Evaluates the predictive accuracy of a linear model vs. a critical-scaling model\n    for the temperature dependence of surface tension near a critical point.\n    \"\"\"\n    \n    # Test suite to implement:\n    # (Tc, A_true, mu_true, sigma, N_train, N_test, seed)\n    test_cases = [\n        # Case 1 (happy path, low noise)\n        (1.312, 1.0, 11/9, 0.01, 50, 200, 0),\n        # Case 2 (increased noise)\n        (1.312, 1.0, 11/9, 0.05, 50, 200, 1),\n        # Case 3 (small-sample training)\n        (1.312, 1.0, 11/9, 0.01, 8, 200, 2),\n        # Case 4 (exponent mismatch to test robustness)\n        (1.312, 1.0, 1.26, 0.01, 50, 200, 3),\n        # Case 5 (different amplitude and moderate noise)\n        (1.312, 0.8, 11/9, 0.02, 50, 200, 4)\n    ]\n    \n    results = []\n    mu_g = 11/9 # Fixed exponent for the Guggenheim-like model\n\n    for case in test_cases:\n        Tc, A_true, mu_true, sigma, N_train, N_test, seed = case\n        \n        # 1. Synthetic data generation\n        \n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n        \n        # Training set generation\n        T_train_min, T_train_max = 0.6 * Tc, 0.98 * Tc\n        T_train = rng.uniform(T_train_min, T_train_max, size=N_train)\n        \n        # Ground-truth function\n        def gamma_true(T, A, mu):\n            # The term (1 - T/Tc) can become negative if T > Tc, which is not\n            # expected in this temperature range, but handle for safety.\n            # Using np.maximum to avoid nan from negative bases in power.\n            base = np.maximum(0, 1 - T / Tc)\n            return A * (base ** mu)\n\n        # Generate noisy training labels\n        gamma_train_true_vals = gamma_true(T_train, A_true, mu_true)\n        noise = rng.normal(0, sigma, size=N_train)\n        gamma_train_noisy = gamma_train_true_vals + noise\n        \n        # Test set generation\n        T_test_min, T_test_max = 0.6 * Tc, 0.99 * Tc\n        T_test = np.linspace(T_test_min, T_test_max, N_test)\n        \n        # Generate noise-free test labels (ground truth)\n        gamma_test_true = gamma_true(T_test, A_true, mu_true)\n        \n        # 2. Model fitting on the training set\n        \n        # Model L (Linear): y = a*T + b\n        # Using np.linalg.lstsq for stable OLS solution\n        X_L = np.vstack([T_train, np.ones(N_train)]).T\n        a, b = np.linalg.lstsq(X_L, gamma_train_noisy, rcond=None)[0]\n        \n        # Model G (Guggenheim-like): y = A_G * (1 - T/Tc)^mu_g\n        # This is a regression through the origin.\n        x_G_train = (1 - T_train / Tc)**mu_g\n        # OLS estimator for regression through origin: sum(xy) / sum(x^2)\n        A_G = (x_G_train @ gamma_train_noisy) / (x_G_train @ x_G_train)\n        \n        # 3. Accuracy evaluation on the test set\n        \n        # Predictions on the test set\n        gamma_pred_L = a * T_test + b\n        \n        x_G_test = (1 - T_test / Tc)**mu_g\n        gamma_pred_G = A_G * x_G_test\n        \n        # Compute RMSE against noise-free ground truth\n        rmse_L = np.sqrt(np.mean((gamma_pred_L - gamma_test_true)**2))\n        rmse_G = np.sqrt(np.mean((gamma_pred_G - gamma_test_true)**2))\n        \n        # Calculate the difference\n        diff_rmse = rmse_L - rmse_G\n        results.append(diff_rmse)\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2792417"}, {"introduction": "This advanced computational practice delves into the microscopic origins of surface tension by exploring capillary-wave theory. You will implement a numerical experiment to derive the surface tension, $\\gamma$, from the statistical fluctuations of an interface, grounding the macroscopic property in the equipartition theorem of statistical mechanics. By then calculating the surface entropy from the temperature derivative of your simulated $\\gamma(T)$, this exercise provides a powerful demonstration of how microscopic dynamics give rise to macroscopic thermodynamic quantities [@problem_id:2792442].", "problem": "You are asked to implement a complete, reproducible numerical experiment that infers the surface entropy per unit area, denoted by $s^{\\sigma}$, from interfacial height fluctuations and verifies its consistency against a finite-difference estimate of the temperature derivative of the surface tension. Your experiment must be derived from first principles suitable for nanomechanics and surface and interface science.\n\nStart from the following fundamental base and core definitions:\n- Consider a liquid interface described by a small-slope height field $h(x,y)$ above a flat reference plane of projected area $A = L^2$, with periodic boundary conditions on a square of side $L$. In the small-slope regime, the capillary-wave Hamiltonian for long-wavelength modes is quadratic in $h$ and given by\n$$\nE[h] = \\frac{\\gamma}{2} \\int_A \\lvert \\nabla h \\rvert^2 \\, \\mathrm{d}^2 r \\;+\\; \\frac{\\kappa}{2} \\int_A \\lvert \\nabla^2 h \\rvert^2 \\, \\mathrm{d}^2 r,\n$$\nwhere $\\gamma$ is the surface tension (with units $\\mathrm{N/m}$) and $\\kappa$ is a small stiffness setting a microscopic cutoff (with units $\\mathrm{J}$). This quadratic form is a well-accepted continuum model for capillary-wave fluctuations of liquid interfaces at long wavelengths; the $\\kappa$ term regularizes ultraviolet divergences and mimics microscopic structure at high wave number $k$.\n- Use the definition of surface entropy per unit area,\n$$\ns^{\\sigma} = -\\left( \\frac{\\partial \\gamma}{\\partial T} \\right),\n$$\nevaluated at fixed chemical potential and pressure.\n- Use the equipartition theorem of classical statistical mechanics: every independent quadratic degree of freedom contributes an average energy of $\\frac{1}{2} k_{\\mathrm{B}} T$, where $k_{\\mathrm{B}}$ is the Boltzmann constant. For independent Fourier modes $h_{\\mathbf{k}}$ of a real field with periodic boundary conditions, the total energy is a sum of quadratic contributions in $\\lvert h_{\\mathbf{k}} \\rvert^2$.\n\nYour task is to:\n1. Derive from the above base a statistically consistent estimator of $\\gamma$ from an ensemble of interfacial height fluctuations at temperature $T$. Your derivation must use only the stated principles (quadratic Hamiltonian, mode-wise equipartition, and the properties of Fourier modes for a real field). Do not assume any additional phenomenological shortcut formulas not implied by those principles.\n2. Design a synthetic-data generator that draws independent samples of modal amplitudes sufficient to estimate $\\gamma(T)$ at a set of temperatures. For realism, use that the squared magnitude of a complex Gaussian mode is exponentially distributed, and ensure that your sampling procedure respects the independence structure of modes in the half-plane of wave vectors. Use a square domain of side $L$ and restrict the analysis to modes with wave number magnitude in a band that avoids the zero mode and limits ultraviolet contamination by the $\\kappa$ term.\n3. For each test case below, estimate $s^{\\sigma}$ by two independent numerical routes:\n   - A local linear regression of $\\gamma(T)$ in a temperature window around a target temperature $T_0$, and then $s^{\\sigma}$ as the negative slope.\n   - A central finite-difference estimate of the temperature derivative of $\\gamma$, evaluated at $T_0$ with step size $\\Delta T$, and then $s^{\\sigma}$ as the negative of that finite difference.\n4. Report, for each test case, whether the two estimates of $s^{\\sigma}$ agree within a specified relative tolerance and whether the regression-based estimate is accurate relative to the ground-truth model used to generate the synthetic data.\n\nSynthetic data model and physical constants:\n- Use a linear temperature dependence for the ground-truth surface tension in the synthetic generator,\n$$\n\\gamma_{\\mathrm{true}}(T) = \\gamma_{\\mathrm{ref}} - a \\left( T - T_{\\mathrm{ref}} \\right),\n$$\nwith $\\gamma_{\\mathrm{ref}} = 0.072\\ \\mathrm{N/m}$, $T_{\\mathrm{ref}} = 300\\ \\mathrm{K}$, and $a = 1.5 \\times 10^{-4}\\ \\mathrm{N/(m\\cdot K)}$. This is consistent with typical slopes observed for common liquids over moderate temperature ranges. The exact target to be recovered is therefore $s^{\\sigma}_{\\mathrm{true}} = a$ in units of $\\mathrm{N/(m\\cdot K)}$.\n- Boltzmann constant: $k_{\\mathrm{B}} = 1.380649 \\times 10^{-23}\\ \\mathrm{J/K}$.\n- Use a square domain with side $L$ (specified per test case) and area $A = L^2$; allowed wave vectors are $\\mathbf{k} = \\frac{2\\pi}{L}(n_x,n_y)$ with integers $n_x,n_y$ and the independent half-plane constraint appropriate to a real field: include only modes with $n_y > 0$ or $\\left( n_y = 0 \\text{ and } n_x > 0 \\right)$, excluding $\\mathbf{k}=\\mathbf{0}$. Restrict modes to integer components $\\lvert n_x \\rvert,\\lvert n_y \\rvert \\le n_{\\max}$ and a lower bound that excludes the zero mode.\n\nTest suite:\nImplement three test cases, each specifying the domain size, sampling depth, and temperature window. For each case, generate temperatures $T_j = T_0 + j\\,\\Delta T$ for $j \\in \\{-3,-2,-1,0,1,2,3\\}$, estimate $\\gamma(T_j)$ from fluctuations by your derived estimator, and then compute both the local-regression and finite-difference estimates of $s^{\\sigma}$ at $T_0$.\n- Case 1 (happy path): $T_0 = 298\\ \\mathrm{K}$, $\\Delta T = 8\\ \\mathrm{K}$, $L = 2.0 \\times 10^{-7}\\ \\mathrm{m}$, $n_{\\max} = 6$, $M = 1500$ independent samples per mode and temperature, $\\kappa = 0\\ \\mathrm{J}$.\n- Case 2 (higher temperature window): $T_0 = 360\\ \\mathrm{K}$, $\\Delta T = 15\\ \\mathrm{K}$, $L = 2.5 \\times 10^{-7}\\ \\mathrm{m}$, $n_{\\max} = 8$, $M = 2000$, $\\kappa = 0\\ \\mathrm{J}$.\n- Case 3 (ultraviolet regularization nonzero): $T_0 = 320\\ \\mathrm{K}$, $\\Delta T = 10\\ \\mathrm{K}$, $L = 2.0 \\times 10^{-7}\\ \\mathrm{m}$, $n_{\\max} = 8$, $M = 2500$, $\\kappa = 5.0 \\times 10^{-19}\\ \\mathrm{J}$.\n\nNumerical and statistical details to respect:\n- Use independent draws of $\\lvert h_{\\mathbf{k}} \\rvert^2$ that are exponentially distributed with mean consistent with the modal variance implied by your derivation at temperature $T$ and parameters $\\gamma_{\\mathrm{true}}(T)$ and $\\kappa$. Average over $M$ samples to form a consistent estimator of the mode-wise second moment. Combine many modes in a regression against the appropriate powers of $k$ to estimate $\\gamma(T)$ without assuming a priori whether $\\kappa$ is nonzero.\n- For each $T$, estimate $\\gamma(T)$ by a linear least-squares fit of a transformed observable that leads to a linear relationship in $\\gamma$ and $\\kappa$ with no intercept term, as implied by your derivation from equipartition and the quadratic Hamiltonian. Explicitly state this transformation and the fitted features in your solution.\n- For the local slope estimate of $s^{\\sigma}$ at $T_0$, fit a straight line to $\\gamma(T_j)$ versus $T_j$ for $j \\in \\{-3,-2,-1,0,1,2,3\\}$ and take the negative of the fitted slope.\n- For the finite-difference estimate at $T_0$, compute the central difference using $T_0 \\pm \\Delta T$ and take the negative of that difference divided by $2\\Delta T$.\n\nUnits, tolerances, and output:\n- Report all surface entropy per unit area values $s^{\\sigma}$ in $\\mathrm{N/(m\\cdot K)}$.\n- For each case, evaluate two conditions:\n  1. The regression-based and finite-difference estimates agree within $10\\%$ relative difference with respect to $s^{\\sigma}_{\\mathrm{true}}$.\n  2. The regression-based estimate deviates by less than $10\\%$ relative error from $s^{\\sigma}_{\\mathrm{true}}$.\n  Let the boolean result for a case be the logical conjunction of these two conditions.\n- Your program should produce a single line of output containing the results for the three test cases as a comma-separated list of booleans enclosed in square brackets, for example, $[\\text{True},\\text{False},\\text{True}]$.\n\nAll numerical choices must be scientifically plausible and consistent with the stated physical model. Use $k_{\\mathrm{B}}$ in $\\mathrm{J/K}$, lengths in $\\mathrm{m}$, surface tensions in $\\mathrm{N/m}$, and temperatures in $\\mathrm{K}$. The code must be fully self-contained and reproducible with a fixed random seed. No user input is permitted.", "solution": "The user has requested a numerical experiment to infer surface entropy per unit area, $s^{\\sigma}$, from interfacial height fluctuations. This requires deriving a statistical estimator for surface tension, $\\gamma$, designing a synthetic data generator based on first principles, and implementing two independent methods for estimating the temperature derivative of $\\gamma$. The problem is well-posed, scientifically grounded, and provides all necessary parameters. I will proceed with a complete solution.\n\nThe solution is structured as follows:\n1.  Derivation of the estimator for surface tension $\\gamma$ from the capillary-wave Hamiltonian using the equipartition theorem.\n2.  Formulation of the numerical experiment, including synthetic data generation and the least-squares fitting procedure.\n3.  Specification of the two methods for calculating the surface entropy per unit area, $s^{\\sigma}$.\n\n**1. Derivation of the Surface Tension Estimator**\n\nThe analysis begins with the provided capillary-wave Hamiltonian for a liquid interface of height $h(\\mathbf{r})$ over a projected area $A = L^2$:\n$$\nE[h] = \\frac{\\gamma}{2} \\int_A \\lvert \\nabla h \\rvert^2 \\, \\mathrm{d}^2 r \\;+\\; \\frac{\\kappa}{2} \\int_A \\lvert \\nabla^2 h \\rvert^2 \\, \\mathrm{d}^2 r\n$$\nwhere $\\mathbf{r} = (x,y)$. The height field $h(\\mathbf{r})$ is a real function defined on a square domain with periodic boundary conditions. It can be represented by its complex Fourier series:\n$$\nh(\\mathbf{r}) = \\sum_{\\mathbf{k}} h_{\\mathbf{k}} e^{i \\mathbf{k} \\cdot \\mathbf{r}}\n$$\nThe wave vectors $\\mathbf{k}$ are discrete due to the periodic boundary conditions: $\\mathbf{k} = \\frac{2\\pi}{L}(n_x, n_y)$ for integer indices $n_x, n_y$. Since $h(\\mathbf{r})$ is real, its Fourier coefficients must satisfy the hermiticity condition $h_{-\\mathbf{k}} = h_{\\mathbf{k}}^*$.\n\nTo express the energy in terms of the Fourier modes $h_{\\mathbf{k}}$, we apply Parseval's theorem. The Fourier transforms of the gradient and Laplacian are:\n$$\n\\mathcal{F}[\\nabla h](\\mathbf{k}) = i \\mathbf{k} h_{\\mathbf{k}}\n$$\n$$\n\\mathcal{F}[\\nabla^2 h](\\mathbf{k}) = -k^2 h_{\\mathbf{k}}\n$$\nwhere $k = |\\mathbf{k}|$. Parseval's theorem for an integral over the area $A$ states that $\\int_A |f(\\mathbf{r})|^2 \\, \\mathrm{d}^2 r = A \\sum_{\\mathbf{k}} |f_{\\mathbf{k}}|^2$. Applying this to the energy terms yields:\n$$\n\\int_A \\lvert \\nabla h \\rvert^2 \\, \\mathrm{d}^2 r = A \\sum_{\\mathbf{k}} |i \\mathbf{k} h_{\\mathbf{k}}|^2 = A \\sum_{\\mathbf{k}} k^2 |h_{\\mathbf{k}}|^2\n$$\n$$\n\\int_A \\lvert \\nabla^2 h \\rvert^2 \\, \\mathrm{d}^2 r = A \\sum_{\\mathbf{k}} |-k^2 h_{\\mathbf{k}}|^2 = A \\sum_{\\mathbf{k}} k^4 |h_{\\mathbf{k}}|^2\n$$\nSubstituting these back into the Hamiltonian gives the total energy as a sum over modal contributions:\n$$\nE = \\sum_{\\mathbf{k}} \\frac{A}{2} (\\gamma k^2 + \\kappa k^4) |h_{\\mathbf{k}}|^2\n$$\nThe hermiticity condition $h_{-\\mathbf{k}} = h_{\\mathbf{k}}^*$ implies that the modes at $\\mathbf{k}$ and $-\\mathbf{k}$ are not independent. To work with independent degrees of freedom, we write the sum over an independent half-plane of wave vectors (e.g., $n_y > 0$, or $n_y=0$ and $n_x > 0$), which excludes the $\\mathbf{k}=\\mathbf{0}$ mode. For each such $\\mathbf{k}$ (assuming $\\mathbf{k} \\neq -\\mathbf{k}$), the energy contribution from the pair $(\\mathbf{k}, -\\mathbf{k})$ is:\n$$\nE_{\\mathbf{k}, \\text{pair}} = \\frac{A}{2} (\\gamma k^2 + \\kappa k^4) |h_{\\mathbf{k}}|^2 + \\frac{A}{2} (\\gamma k^2 + \\kappa k^4) |h_{-\\mathbf{k}}|^2 = A (\\gamma k^2 + \\kappa k^4) |h_{\\mathbf{k}}|^2\n$$\nWriting $h_{\\mathbf{k}} = u_{\\mathbf{k}} + i v_{\\mathbf{k}}$, we have $|h_{\\mathbf{k}}|^2 = u_{\\mathbf{k}}^2 + v_{\\mathbf{k}}^2$. The variables $u_{\\mathbf{k}}$ and $v_{\\mathbf{k}}$ represent two independent real quadratic degrees of freedom. According to the equipartition theorem of classical statistical mechanics, each such degree of freedom contributes an average energy of $\\frac{1}{2} k_{\\mathrm{B}} T$. Thus, the total average energy for the pair is $k_{\\mathrm{B}} T$:\n$$\n\\langle E_{\\mathbf{k}, \\text{pair}} \\rangle = \\left\\langle A (\\gamma k^2 + \\kappa k^4) (u_{\\mathbf{k}}^2 + v_{\\mathbf{k}}^2) \\right\\rangle = k_{\\mathrm{B}} T\n$$\nThis allows us to find the thermal average of the squared mode amplitude:\n$$\n\\left\\langle |h_{\\mathbf{k}}|^2 \\right\\rangle = \\frac{k_{\\mathrm{B}} T}{A (\\gamma k^2 + \\kappa k^4)}\n$$\nThis fundamental relationship connects the observable quantity $\\langle |h_{\\mathbf{k}}|^2 \\rangle$ to the physical parameters $\\gamma$ and $\\kappa$.\n\n**2. Numerical Experiment and Least-Squares Estimation**\n\nTo estimate $\\gamma$ and $\\kappa$ from fluctuation data, we rearrange the derived equation into a linear form. For each mode $\\mathbf{k}$, we have:\n$$\n\\gamma k^2 + \\kappa k^4 = \\frac{k_{\\mathrm{B}} T}{A \\left\\langle |h_{\\mathbf{k}}|^2 \\right\\rangle}\n$$\nThis equation is in the form of a linear model $y = \\beta_1 x_1 + \\beta_2 x_2$, where the coefficients are $\\beta_1 = \\gamma$ and $\\beta_2 = \\kappa$. The variables for the linear regression are:\n-   Dependent variable: $Y_{\\mathbf{k}} = \\frac{k_{\\mathrm{B}} T}{A \\left\\langle |h_{\\mathbf{k}}|^2 \\right\\rangle_{\\text{sim}}}$\n-   Independent variables: $X_{1,\\mathbf{k}} = k^2$ and $X_{2,\\mathbf{k}} = k^4$\n\nThe numerical experiment proceeds as follows for each specified temperature $T_j$:\n1.  **Generate Modes**: A set of independent wave vectors $\\mathbf{k}_i$ is generated according to the rules: $\\mathbf{k}_i = \\frac{2\\pi}{L}(n_x, n_y)$ with integer indices $|n_x|, |n_y| \\le n_{\\max}$, subject to the half-plane constraint ($n_y > 0$ or ($n_y = 0$ and $n_x > 0$)).\n2.  **Generate Synthetic Data**: For each mode $\\mathbf{k}_i$, the true surface tension $\\gamma_{\\text{true}}(T_j)$ is computed. The theoretical mean fluctuation $\\mu_{\\mathbf{k}_i} = \\langle |h_{\\mathbf{k}_i}|^2 \\rangle$ is calculated using the formula derived above. As specified, the squared magnitude of a complex Gaussian mode, $|h_{\\mathbf{k}}|^2$, follows an exponential distribution. We draw $M$ samples of $|h_{\\mathbf{k}_i}|^2$ from an exponential distribution with scale (mean) parameter $\\mu_{\\mathbf{k}_i}$. The sample mean of these $M$ draws provides the simulated average, $\\left\\langle |h_{\\mathbf{k}_i}|^2 \\right\\rangle_{\\text{sim}}$.\n3.  **Linear Least-Squares Fit**: A linear system is constructed with data points from all modes $\\{\\mathbf{k}_i\\}$. The matrix of independent variables $X$ has rows $[k_i^2, k_i^4]$, and the vector of dependent variables $Y$ has elements $Y_{\\mathbf{k}_i}$. The system $Y = X \\beta$ is solved for $\\beta = [\\gamma, \\kappa]^T$ using linear least squares. This yields the estimate $\\gamma_{\\text{est}}(T_j)$.\n\nThis process is repeated for a set of temperatures $T_j = T_0 + j\\,\\Delta T$ for $j \\in \\{-3, \\dots, 3\\}$.\n\n**3. Calculation of Surface Entropy Per Unit Area, $s^{\\sigma}$**\n\nThe surface entropy per unit area is defined as $s^{\\sigma} = -(\\frac{\\partial \\gamma}{\\partial T})$. We estimate this quantity from the computed discrete set of points $(\\gamma_{\\text{est}}(T_j), T_j)$ using two independent methods as required.\n\n1.  **Local Linear Regression**: A straight line, $\\gamma(T) = \\gamma_0 - s^{\\sigma}_{\\text{reg}} T$, is fitted to the seven $(\\gamma_{\\text{est}}(T_j), T_j)$ data points using ordinary least squares. The estimated surface entropy, $s^{\\sigma}_{\\text{reg}}$, is the negative of the fitted slope. This method uses all the data in the temperature window, providing a robust estimate.\n\n2.  **Central Finite Difference**: This method provides a local estimate of the derivative at the central temperature $T_0$. It uses the estimated $\\gamma$ values at $T_0 + \\Delta T$ and $T_0 - \\Delta T$:\n    $$\n    s^{\\sigma}_{\\text{fd}} = - \\frac{\\gamma_{\\text{est}}(T_0 + \\Delta T) - \\gamma_{\\text{est}}(T_0 - \\Delta T)}{2 \\Delta T}\n    $$\nThis estimate is more sensitive to noise in the individual $\\gamma$ estimates but is a direct implementation of the derivative definition.\n\nThe program will implement this full procedure for each test case, verify the results against the specified tolerances, and report a boolean outcome.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\n# Define physical constants and ground truth model parameters\nKB_CONST = 1.380649e-23  # Boltzmann constant in J/K\nGAMMA_REF = 0.072       # Reference surface tension in N/m at T_ref\nT_REF = 300.0           # Reference temperature in K\nA_PARAM = 1.5e-4        # Temperature coefficient of surface tension in N/(m.K)\nS_SIGMA_TRUE = A_PARAM  # Ground truth for surface entropy per unit area\n\n# Define a named tuple for holding test case parameters for clarity\nTestCase = collections.namedtuple('TestCase', ['T0', 'delta_T', 'L', 'n_max', 'M', 'kappa'])\n\ndef gamma_true_model(T):\n    \"\"\"Computes the ground-truth surface tension at temperature T.\"\"\"\n    return GAMMA_REF - A_PARAM * (T - T_REF)\n\ndef estimate_gamma_at_temp(T, L, n_max, M, kappa):\n    \"\"\"\n    Performs a numerical experiment to estimate gamma at a single temperature T.\n    \"\"\"\n    area = L**2\n    \n    # 1. Generate wave vectors and their squared magnitudes\n    k_squared_vals = []\n    # Loop over integer indices to generate wave vectors k = (2*pi/L)*(nx, ny)\n    # The selection rule ensures we cover an independent half-plane of modes\n    for nx in range(-n_max, n_max + 1):\n        for ny in range(-n_max, n_max + 1):\n            if ny > 0 or (ny == 0 and nx > 0):\n                k_sq = ((2 * np.pi / L)**2) * (nx**2 + ny**2)\n                k_squared_vals.append(k_sq)\n    \n    k_squared_vals = np.array(k_squared_vals)\n    k_fourth_vals = k_squared_vals**2\n\n    # 2. Generate synthetic fluctuation data\n    # Calculate true gamma at this temperature to find theoretical mode variance\n    gamma_T_true = gamma_true_model(T)\n    \n    # Calculate the theoretical mean of |h_k|^2 for each mode\n    # <|h_k|^2> = k_B * T / (A * (gamma*k^2 + kappa*k^4))\n    denominator = area * (gamma_T_true * k_squared_vals + kappa * k_fourth_vals)\n    # Avoid division by zero if any k or the entire denominator is zero\n    denominator[denominator == 0] = 1e-99\n    mean_h_k_sq = (KB_CONST * T) / denominator\n    \n    # Simulate the measurement of <|h_k|^2> by averaging M samples\n    # |h_k|^2 is exponentially distributed with the mean calculated above\n    simulated_h_k_sq_mean = np.array([\n        np.mean(np.random.exponential(scale=mean_val, size=M))\n        for mean_val in mean_h_k_sq\n    ])\n\n    # 3. Formulate and solve the linear least-squares problem\n    # The model is: gamma*k^2 + kappa*k^4 = k_B*T / (A * <|h_k|^2>)\n    # We solve for [gamma, kappa]\n    Y = (KB_CONST * T) / (area * simulated_h_k_sq_mean)\n    X = np.vstack([k_squared_vals, k_fourth_vals]).T\n    \n    # Solve Y = X * [gamma, kappa]^T\n    coeffs, _, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n    \n    gamma_est = coeffs[0]\n    return gamma_est\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    # Set a fixed random seed for reproducibility of the numerical experiment\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        TestCase(T0=298.0, delta_T=8.0, L=2.0e-7, n_max=6, M=1500, kappa=0.0),\n        TestCase(T0=360.0, delta_T=15.0, L=2.5e-7, n_max=8, M=2000, kappa=0.0),\n        TestCase(T0=320.0, delta_T=10.0, L=2.0e-7, n_max=8, M=2500, kappa=5.0e-19)\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # Generate the list of temperatures for the current test case\n        temperatures = [case.T0 + j * case.delta_T for j in range(-3, 4)]\n        \n        # Estimate gamma for each temperature in the window\n        estimated_gammas = [\n            estimate_gamma_at_temp(T, case.L, case.n_max, case.M, case.kappa)\n            for T in temperatures\n        ]\n        \n        # Estimate surface entropy s_sigma using two methods\n        \n        # 1. Local Linear Regression\n        # Fit a line to the (T, gamma) data points: gamma = slope * T + intercept\n        slope, _ = np.polyfit(temperatures, estimated_gammas, 1)\n        # s_sigma = -d(gamma)/dT, so it is the negative of the slope\n        s_sigma_reg = -slope\n        \n        # 2. Central Finite Difference\n        # Access the gamma estimates at T0 - delta_T and T0 + delta_T\n        # The list 'temperatures' has 7 elements, indexed 0..6\n        # j=-1 -> T0-delta_T -> index 2\n        # j=1  -> T0+delta_T -> index 4\n        gamma_minus = estimated_gammas[2]\n        gamma_plus = estimated_gammas[4]\n        s_sigma_fd = -(gamma_plus - gamma_minus) / (2 * case.delta_T)\n\n        # Verification against the specified conditions\n        # Condition 1: agreement between the two estimation methods\n        rel_diff_methods = abs(s_sigma_reg - s_sigma_fd) / S_SIGMA_TRUE\n        cond1 = rel_diff_methods <= 0.10\n        \n        # Condition 2: accuracy of the regression-based estimate\n        rel_err_reg = abs(s_sigma_reg - S_SIGMA_TRUE) / S_SIGMA_TRUE\n        cond2 = rel_err_reg <= 0.10\n        \n        # Final boolean result for the case is the logical AND of the two conditions\n        all_results.append(cond1 and cond2)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2792442"}]}