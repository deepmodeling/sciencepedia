{"hands_on_practices": [{"introduction": "Before diving into the Hilber-Hughes-Taylor method, it is crucial to understand the landscape of classical time integration schemes and the motivations for developing more advanced techniques. This practice explores the fundamental trade-off between numerical accuracy and stability by comparing two common variants of the Newmark method. By analyzing their period error and stability limits, you will see firsthand why a method with tunable, user-defined numerical dissipation is a powerful tool in computational dynamics [@problem_id:2564542].", "problem": "Consider the undamped single-degree-of-freedom semi-discrete structural dynamics model obtained from the finite element method: $m \\ddot{u}(t) + k u(t) = 0$, with natural circular frequency $\\omega = \\sqrt{k/m}$. Time integration is performed by the Newmark family with parameters $(\\beta,\\gamma)$ in the standard form\n- $u_{n+1} = u_n + \\Delta t\\, v_n + \\Delta t^2 \\left[\\left(\\tfrac{1}{2} - \\beta\\right) a_n + \\beta a_{n+1}\\right]$,\n- $v_{n+1} = v_n + \\Delta t \\left[(1 - \\gamma) a_n + \\gamma a_{n+1}\\right]$,\nwhere $a_n = \\ddot{u}_n$. For the undamped oscillator, $a_n = -\\omega^2 u_n$.\n\nFocus on the case $\\gamma = 1/2$ and compare the two choices $(\\beta, \\gamma) = (1/4, 1/2)$ and $(\\beta, \\gamma) = (1/6, 1/2)$. Let $h := \\omega \\Delta t$. Define the numerical (discrete) frequency $\\Omega$ by seeking nontrivial solutions of the form $u_n = \\Re\\{\\hat{u}\\, r^n\\}$ with $r = e^{i \\Omega \\Delta t}$.\n\nFrom the governing equation and the Newmark update, derive from first principles the leading-order small-$h$ behavior of the numerical period error for each scheme, i.e., the relative error in $T = 2\\pi/\\omega$ versus $T_{\\text{num}} = 2\\pi/\\Omega$, and then use it to estimate the relative period error at $h = 1$. Based on your analysis, as well as the stability and dissipation properties that follow from the amplification relation for $r$, determine which of the following statements are correct. Select all that apply.\n\nA. At $h = 1$, both $(\\beta, \\gamma) = (1/4, 1/2)$ and $(\\beta, \\gamma) = (1/6, 1/2)$ are non-dissipative for the undamped oscillator, and $(\\beta, \\gamma) = (1/6, 1/2)$ exhibits roughly half the period elongation of $(1/4, 1/2)$.\n\nB. The choice $(\\beta, \\gamma) = (1/6, 1/2)$ introduces algorithmic damping (amplitude decay) even for the undamped oscillator.\n\nC. The leading-order relative period error scales like $\\mathcal{O}(h^4)$ for $(\\beta, \\gamma) = (1/6, 1/2)$, whereas it is $\\mathcal{O}(h^2)$ for $(1/4, 1/2)$.\n\nD. The Hilber–Hughes–Taylor method (often denoted the $\\alpha$-method) achieves second-order accuracy with tunable high-frequency numerical dissipation by taking $\\alpha \\in (-1/3, 0]$ together with $\\gamma = 1/2 - \\alpha$ and $\\beta = \\tfrac{1}{4}(1 - \\alpha)^2$.\n\nE. Both $(\\beta, \\gamma) = (1/4, 1/2)$ and $(\\beta, \\gamma) = (1/6, 1/2)$ are unconditionally stable for any $h$ because $\\gamma = 1/2$ eliminates instabilities.\n\nF. For $h = 4$, $(\\beta, \\gamma) = (1/6, 1/2)$ is unstable, while $(\\beta, \\gamma) = (1/4, 1/2)$ remains stable.\n\nDiscuss, in particular, the tradeoff between period accuracy and numerical dissipation, and how introducing Hilber–Hughes–Taylor parameters affects high-frequency content while preserving low-frequency accuracy.", "solution": "The problem statement is scientifically sound, self-contained, and well-posed. It presents a standard analysis of the Newmark time integration family for a single-degree-of-freedom undamped oscillator, which is a fundamental topic in computational structural dynamics. All provided definitions and equations are standard. We may proceed with the solution.\n\nThe problem requires analyzing the Newmark integration scheme for the semi-discrete equation of motion:\n$$m \\ddot{u}(t) + k u(t) = 0$$\nLet $\\omega = \\sqrt{k/m}$ be the natural circular frequency. The equation becomes $\\ddot{u}(t) + \\omega^2 u(t) = 0$. For a numerical scheme, we enforce this equation at the discrete time steps, so $a_n = -\\omega^2 u_n$ and $a_{n+1} = -\\omega^2 u_{n+1}$, where $u_n = u(t_n)$ and $a_n = \\ddot{u}(t_n)$.\n\nThe Newmark update rules are given by:\n$$u_{n+1} = u_n + \\Delta t\\, v_n + \\Delta t^2 \\left[\\left(\\tfrac{1}{2} - \\beta\\right) a_n + \\beta a_{n+1}\\right]$$\n$$v_{n+1} = v_n + \\Delta t \\left[(1 - \\gamma) a_n + \\gamma a_{n+1}\\right]$$\n\nWe substitute $a_n = -\\omega^2 u_n$ and $a_{n+1} = -\\omega^2 u_{n+1}$ into the update rules. Let $h = \\omega \\Delta t$.\n$$u_{n+1} = u_n + \\Delta t\\, v_n - \\Delta t^2 \\omega^2 \\left(\\tfrac{1}{2} - \\beta\\right) u_n - \\Delta t^2 \\omega^2 \\beta u_{n+1}$$\n$$u_{n+1}(1 + \\beta h^2) = u_n(1 - (\\tfrac{1}{2} - \\beta)h^2) + \\Delta t v_n$$\n$$v_{n+1} = v_n - \\Delta t \\omega^2 (1 - \\gamma) u_n - \\Delta t \\omega^2 \\gamma u_{n+1}$$\n$$\\Delta t v_{n+1} = \\Delta t v_n - h^2 (1 - \\gamma) u_n - h^2 \\gamma u_{n+1}$$\n\nLet the state vector be $\\mathbf{d}_n = \\{u_n, \\Delta t v_n\\}^T$. The update can be written in matrix form $\\mathbf{M}_L \\mathbf{d}_{n+1} = \\mathbf{M}_R \\mathbf{d}_n$:\n$$\n\\begin{pmatrix} 1 + \\beta h^2 & 0 \\\\ \\gamma h^2 & 1 \\end{pmatrix}\n\\begin{pmatrix} u_{n+1} \\\\ \\Delta t v_{n+1} \\end{pmatrix}\n=\n\\begin{pmatrix} 1 - (\\tfrac{1}{2} - \\beta)h^2 & 1 \\\\ -h^2(1 - \\gamma) & 1 \\end{pmatrix}\n\\begin{pmatrix} u_n \\\\ \\Delta t v_n \\end{pmatrix}\n$$\nThe amplification matrix $\\mathbf{A}$ is given by $\\mathbf{A} = \\mathbf{M}_L^{-1} \\mathbf{M}_R$.\n$$\n\\mathbf{M}_L^{-1} = \\frac{1}{1 + \\beta h^2} \\begin{pmatrix} 1 & 0 \\\\ -\\gamma h^2 & 1 + \\beta h^2 \\end{pmatrix}\n$$\n$$\n\\mathbf{A} = \\frac{1}{1 + \\beta h^2} \\begin{pmatrix} 1 & 0 \\\\ -\\gamma h^2 & 1 + \\beta h^2 \\end{pmatrix}\n\\begin{pmatrix} 1 - (\\tfrac{1}{2} - \\beta)h^2 & 1 \\\\ -h^2(1 - \\gamma) & 1 \\end{pmatrix}\n= \\frac{1}{D}\n\\begin{pmatrix}\n1 - (\\tfrac{1}{2} - \\beta)h^2 & 1 \\\\\n-\\gamma h^2(1 - (\\tfrac{1}{2} - \\beta)h^2) - (1-\\gamma)h^2(1 + \\beta h^2) & -\\gamma h^2 + 1 + \\beta h^2\n\\end{pmatrix}\n$$\nwhere $D = 1 + \\beta h^2$. The bottom-left entry simplifies to $-h^2(1+(\\beta-\\frac{\\gamma}{2})h^2)$.\nSo,\n$$\n\\mathbf{A} = \\frac{1}{1+\\beta h^2}\n\\begin{pmatrix}\n1 - (\\tfrac{1}{2} - \\beta)h^2 & 1 \\\\\n-h^2(1+(\\beta-\\tfrac{\\gamma}{2})h^2) & 1+(\\beta-\\gamma)h^2\n\\end{pmatrix}\n$$\nThe eigenvalues $r$ of $\\mathbf{A}$ govern the numerical solution characteristics. They are the roots of the characteristic equation $r^2 - (\\text{tr}\\mathbf{A})r + \\det\\mathbf{A} = 0$.\n\nThe problem states to focus on $\\gamma = 1/2$.\nFor $\\gamma=1/2$, the trace is:\n$$ \\text{tr}\\mathbf{A} = \\frac{1 - (\\tfrac{1}{2} - \\beta)h^2 + 1 + (\\beta - \\tfrac{1}{2})h^2}{1 + \\beta h^2} = \\frac{2 - (1 - 2\\beta)h^2}{1 + \\beta h^2} $$\nThe determinant is:\n$$ \\det\\mathbf{A} = \\frac{(1 - (\\tfrac{1}{2} - \\beta)h^2)(1 - (\\tfrac{1}{2} - \\beta)h^2) + h^2(1+(\\beta-\\tfrac{1}{4})h^2)}{(1+\\beta h^2)^2} $$\nWith $\\gamma=1/2$, the term $(\\beta-\\gamma)$ becomes $(\\beta-1/2) = - (1/2-\\beta)$.\n$$ \\det\\mathbf{A} = \\frac{(1 - (\\tfrac{1}{2} - \\beta)^2 h^4) + h^2 + (\\beta-\\tfrac{1}{4})h^4}{(1+\\beta h^2)^2} = \\frac{1 + h^2 + h^4(-\\frac{1}{4}+\\beta-\\beta^2+\\beta-\\frac{1}{4})}{(1+\\beta h^2)^2} $$\nThis seems too complicated. Let's re-examine my first derivation of $\\det(\\mathbf{A})$. For $\\gamma=1/2$, $D^2 \\det(\\mathbf{A}) = 1 + h^2(2\\beta) + h^4(\\beta^2)=(1+\\beta h^2)^2=D^2$. Thus, for $\\gamma=1/2$, $\\det(\\mathbf{A}) = 1$. This means the method is non-dissipative (it preserves energy in the discrete sense, so amplitude is constant).\n\nThe eigenvalues are $r = e^{\\pm i \\Omega \\Delta t}$, where $\\Omega$ is the numerical frequency. From the characteristic equation, $r+\\bar{r} = 2\\cos(\\Omega \\Delta t) = \\text{tr}\\mathbf{A}$.\n$$ \\cos(\\Omega \\Delta t) = \\frac{1}{2}\\text{tr}\\mathbf{A} = \\frac{1 - \\frac{1}{2}(1 - 2\\beta)h^2}{1 + \\beta h^2} $$\nFor stability, the eigenvalues must be on or inside the unit circle. Since for $\\gamma=1/2$ they are on the unit circle (if the roots are complex), stability requires $|\\text{tr}\\mathbf{A}| \\le 2$. This condition leads to unconditional stability if $4\\beta \\ge 1$ and conditional stability with $h^2(1-4\\beta) < 4$ if $4\\beta < 1$.\n\nNow we analyze the two specific schemes with $\\gamma=1/2$.\n\nCase 1: $(\\beta, \\gamma) = (1/4, 1/2)$ (Average acceleration/Trapezoidal rule)\nSince $\\beta=1/4$, the condition $4\\beta \\ge 1$ is met ($1 \\ge 1$), so this method is unconditionally stable.\n$$ \\cos(\\Omega \\Delta t) = \\frac{1 - \\frac{1}{2}(1 - 2/4)h^2}{1 + h^2/4} = \\frac{1 - h^2/4}{1 + h^2/4} $$\nTo find the period error, we use the identity $\\tan^2(x/2) = (1-\\cos x)/(1+\\cos x)$.\n$$ \\tan^2\\left(\\frac{\\Omega \\Delta t}{2}\\right) = \\frac{1 - \\frac{1 - h^2/4}{1 + h^2/4}}{1 + \\frac{1 - h^2/4}{1 + h^2/4}} = \\frac{(1+h^2/4) - (1-h^2/4)}{(1+h^2/4)+(1-h^2/4)} = \\frac{h^2/2}{2} = \\frac{h^2}{4} $$\nTaking the square root, $\\tan(\\frac{\\Omega \\Delta t}{2}) = \\frac{h}{2}$.\nExpanding $\\arctan(x) = x - x^3/3 + \\dots$:\n$$ \\frac{\\Omega \\Delta t}{2} = \\arctan\\left(\\frac{h}{2}\\right) = \\frac{h}{2} - \\frac{1}{3}\\left(\\frac{h}{2}\\right)^3 + O(h^5) = \\frac{h}{2} - \\frac{h^3}{24} + O(h^5) $$\n$$ \\frac{\\Omega}{\\omega} = \\frac{\\Omega \\Delta t}{h} = 1 - \\frac{h^2}{12} + O(h^4) $$\nThe relative period error is $\\frac{T_{\\text{num}} - T}{T} = \\frac{\\omega}{\\Omega} - 1 = \\left(1 - \\frac{h^2}{12}\\right)^{-1} - 1 = 1 + \\frac{h^2}{12} + O(h^4) - 1 = \\frac{h^2}{12} + O(h^4)$.\nThe error is $\\mathcal{O}(h^2)$ and positive, indicating numerical period elongation.\n\nCase 2: $(\\beta, \\gamma) = (1/6, 1/2)$ (Linear acceleration method)\nSince $\\beta=1/6$, $4\\beta=4/6=2/3 < 1$. This method is conditionally stable. The stability limit is $h^2(1-2/3) < 4$, or $h^2 < 12$, so $h < \\sqrt{12} \\approx 3.46$.\n$$ \\cos(\\Omega \\Delta t) = \\frac{1 - \\frac{1}{2}(1 - 2/6)h^2}{1 + h^2/6} = \\frac{1 - h^2/3}{1 + h^2/6} $$\n$$ \\tan^2\\left(\\frac{\\Omega \\Delta t}{2}\\right) = \\frac{1 - \\frac{1 - h^2/3}{1 + h^2/6}}{1 + \\frac{1 - h^2/3}{1 + h^2/6}} = \\frac{(1+h^2/6) - (1-h^2/3)}{(1+h^2/6) + (1-h^2/3)} = \\frac{h^2/2}{2 - h^2/6} = \\frac{h^2}{4 - h^2/3} $$\nFor small $h$, $\\tan(\\frac{\\Omega \\Delta t}{2}) \\approx \\frac{h/2}{\\sqrt{1-h^2/12}} \\approx \\frac{h}{2}(1 + \\frac{h^2}{24})$.\n$$ \\frac{\\Omega \\Delta t}{2} = \\arctan\\left(\\frac{h}{2}\\left(1 + \\frac{h^2}{24}\\right)\\right) = \\left(\\frac{h}{2}+\\frac{h^3}{48}\\right) - \\frac{1}{3}\\left(\\frac{h}{2}\\right)^3 + O(h^5) = \\frac{h}{2} - \\frac{h^3}{48} + O(h^5) $$\n$$ \\frac{\\Omega}{\\omega} = \\frac{\\Omega \\Delta t}{h} = 1 - \\frac{h^2}{24} + O(h^4) $$\nThe relative period error is $\\frac{T_{\\text{num}} - T}{T} = \\frac{\\omega}{\\Omega} - 1 = \\frac{h^2}{24} + O(h^4)$.\nThe error is also $\\mathcal{O}(h^2)$ and indicates period elongation, but the leading error coefficient is half that of the average acceleration method.\n\nNow we evaluate each statement.\n\nA. At $h = 1$, both $(\\beta, \\gamma) = (1/4, 1/2)$ and $(\\beta, \\gamma) = (1/6, 1/2)$ are non-dissipative for the undamped oscillator, and $(\\beta, \\gamma) = (1/6, 1/2)$ exhibits roughly half the period elongation of $(1/4, 1/2)$.\n- As shown, $\\gamma=1/2$ implies $\\det\\mathbf{A}=1$, so both schemes are non-dissipative.\n- The leading-order period error for $(\\beta, \\gamma)=(1/6, 1/2)$ is $h^2/24$, which is exactly half of $h^2/12$ for $(\\beta, \\gamma)=(1/4, 1/2)$. For $h=1$, the small-$h$ approximation suggests the error for the former is half that of the latter. Let's compute directly:\n  - For $(\\beta, \\gamma)=(1/4, 1/2)$, error is $\\frac{1}{\\arccos(3/5)}-1 \\approx \\frac{1}{0.9273}-1 \\approx 0.0784$.\n  - For $(\\beta, \\gamma)=(1/6, 1/2)$, error is $\\frac{1}{\\arccos(4/7)}-1 \\approx \\frac{1}{0.9626}-1 \\approx 0.0388$.\n  The ratio $0.0388/0.0784 \\approx 0.495$, which is indeed \"roughly half\".\n- **Verdict: Correct.**\n\nB. The choice $(\\beta, \\gamma) = (1/6, 1/2)$ introduces algorithmic damping (amplitude decay) even for the undamped oscillator.\n- This is false. Algorithmic damping is controlled by the determinant of the amplification matrix, or more generally the spectral radius $\\rho(\\mathbf{A})$. For $\\gamma=1/2$, $\\det(\\mathbf{A})=1$ and within the stability limit, the eigenvalues lie on the unit circle, meaning $\\rho(\\mathbf{A})=1$. There is no amplitude decay. Damping requires $\\gamma > 1/2$.\n- **Verdict: Incorrect.**\n\nC. The leading-order relative period error scales like $\\mathcal{O}(h^4)$ for $(\\beta, \\gamma) = (1/6, 1/2)$, whereas it is $\\mathcal{O}(h^2)$ for $(1/4, 1/2)$.\n- This is false. As derived above, the leading-order relative period error for both schemes scales as $\\mathcal{O}(h^2)$. The constant factors are different ($1/24$ vs $1/12$). A method with fourth-order period accuracy is the Fox-Goodwin method, which has $(\\beta, \\gamma) = (1/12, 1/2)$.\n- **Verdict: Incorrect.**\n\nD. The Hilber–Hughes–Taylor method (often denoted the $\\alpha$-method) achieves second-order accuracy with tunable high-frequency numerical dissipation by taking $\\alpha \\in (-1/3, 0]$ together with $\\gamma = 1/2 - \\alpha$ and $\\beta = \\tfrac{1}{4}(1 - \\alpha)^2$.\n- This is a statement of fact about the HHT-$\\alpha$ method. The method is designed to introduce numerical dissipation to damp high-frequency modes while retaining second-order accuracy for low-frequency modes. The parameter relations $\\gamma = 1/2 - \\alpha$ and $\\beta = \\frac{1}{4}(1 - \\alpha)^2$ are precisely those required to achieve this. With $\\alpha \\in [-1/3, 0]$, decreasing $\\alpha$ from $0$ increases high-frequency dissipation. $\\alpha=0$ recovers the non-dissipative trapezoidal rule. The statement is a correct summary of the properties of this widely used method.\n- **Verdict: Correct.**\n\nE. Both $(\\beta, \\gamma) = (1/4, 1/2)$ and $(\\beta, \\gamma) = (1/6, 1/2)$ are unconditionally stable for any $h$ because $\\gamma = 1/2$ eliminates instabilities.\n- This is false. While $(\\beta, \\gamma)=(1/4, 1/2)$ is unconditionally stable, $(\\beta, \\gamma)=(1/6, 1/2)$ is only conditionally stable for $h < \\sqrt{12}$. The reason given is also false; $\\gamma=1/2$ eliminates numerical dissipation, it does not guarantee stability. Stability for $\\gamma=1/2$ is governed by $\\beta$.\n- **Verdict: Incorrect.**\n\nF. For $h = 4$, $(\\beta, \\gamma) = (1/6, 1/2)$ is unstable, while $(\\beta, \\gamma) = (1/4, 1/2)$ remains stable.\n- The scheme $(\\beta, \\gamma)=(1/4, 1/2)$ is unconditionally stable, so it is stable for any $h$, including $h=4$.\n- The scheme $(\\beta, \\gamma)=(1/6, 1/2)$ has a stability limit of $h < \\sqrt{12} \\approx 3.46$. Since $h=4 > 3.46$, the method is unstable.\n- The statement is therefore true.\n- **Verdict: Correct.**\n\nDiscussion on tradeoffs and HHT method:\nThe analysis reveals a fundamental tradeoff in numerical time integration. Comparing the two primary schemes here, the linear acceleration method $(\\beta=1/6, \\gamma=1/2)$ offers superior period accuracy over the average acceleration method $(\\beta=1/4, \\gamma=1/2)$, with half the leading-order error. However, this comes at the cost of unconditional stability. The average acceleration method is robustly stable for any time step size $\\Delta t$, but less accurate in period. In many applications, especially those involving stiff systems with a wide range of frequencies, unconditional stability is paramount.\n\nNeither of these schemes provides numerical dissipation, which is often desirable to damp out spurious high-frequency oscillations arising from spatial discretization in multi-degree-of-freedom systems. The HHT-$\\alpha$ method (and similar methods like the generalized-$\\alpha$ method) provides a solution. By choosing $\\alpha < 0$, we get $\\gamma = 1/2-\\alpha > 1/2$, introducing dissipation. The specific choice of parameters ensures that this dissipation primarily affects high frequencies (large $h$) while preserving second-order accuracy, which means low-frequency response (small $h$) remains highly accurate. This allows engineers to obtain accurate solutions for the dominant structural modes while filtering out non-physical high-frequency noise. This represents a more sophisticated trade-off, balancing accuracy, stability, and dissipation.", "answer": "$$\\boxed{ADF}$$", "id": "2564542"}, {"introduction": "Advanced integration schemes like the generalized-$\\alpha$ method are not black boxes; they are carefully engineered algorithms whose properties can be precisely controlled. This exercise takes you under the hood, guiding you through the derivation of the method's parameters from a specific performance target: the desired amount of high-frequency damping, quantified by the spectral radius $\\rho_{\\infty}$. Completing this problem will empower you to see these methods as designable tools, connecting a high-level numerical goal to the underlying mathematical formulation [@problem_id:2564628].", "problem": "Consider the undamped single-degree-of-freedom structural dynamics model governed by $m \\,\\ddot{u}(t) + k \\,u(t) = 0$, with natural frequency $\\omega = \\sqrt{k/m}$. A single-step time integrator of generalized-$\\alpha$ type is defined by enforcing the discrete equilibrium at a weighted time, together with Newmark-type kinematic updates:\n- Weighted equilibrium (no external force): \n$$m\\,a_{n+\\alpha_m} + k\\,u_{n+\\alpha_f} = 0,$$\nwith $a_{n+\\alpha_m} = (1-\\alpha_m)\\,a_{n+1} + \\alpha_m\\,a_n$ and $u_{n+\\alpha_f} = (1-\\alpha_f)\\,u_{n+1} + \\alpha_f\\,u_n$.\n- Newmark kinematic updates:\n$$u_{n+1} = u_n + \\Delta t\\,v_n + \\Delta t^2\\left(\\left(\\frac{1}{2} - \\beta\\right)a_n + \\beta\\,a_{n+1}\\right),$$\n$$v_{n+1} = v_n + \\Delta t\\left((1-\\gamma)\\,a_n + \\gamma\\,a_{n+1}\\right).$$\n\nYou are asked to determine the mapping from a desired high-frequency spectral radius $\\rho_{\\infty} \\in [0,1]$ to the parameters of the generalized-$\\alpha$ method $(\\alpha_m,\\alpha_f,\\beta,\\gamma)$ under the following requirements:\n1. The method is second-order accurate.\n2. The method is unconditionally stable and achieves an algorithmic dissipation characterized by the high-frequency spectral radius $\\rho_{\\infty}$, defined as the limit of the spectral radius of the amplification matrix as $\\omega\\,\\Delta t \\to \\infty$.\n\nDerive, from first principles starting with the statements above (dynamic equilibrium, kinematic updates, and the definition of high-frequency spectral radius), explicit expressions for $\\alpha_m(\\rho_{\\infty})$, $\\alpha_f(\\rho_{\\infty})$, $\\beta(\\rho_{\\infty})$, and $\\gamma(\\rho_{\\infty})$. Then, identify the corresponding Hilber–Hughes–Taylor-$\\alpha$ (HHT-$\\alpha$) parameter under the convention that the HHT-$\\alpha$ method is the special case $\\alpha_m = 0$ of the generalized-$\\alpha$ method, with $\\alpha_{\\mathrm{HHT}} := \\alpha_f$. Report the value of $\\alpha_{\\mathrm{HHT}}$ at the value of $\\rho_{\\infty}$ implied by $\\alpha_m = 0$.\n\nProvide your final result as a single row matrix containing $\\alpha_m(\\rho_{\\infty})$, $\\alpha_f(\\rho_{\\infty})$, $\\beta(\\rho_{\\infty})$, $\\gamma(\\rho_{\\infty})$, and $\\alpha_{\\mathrm{HHT}}$ for the case $\\alpha_m=0$ described above. No numerical rounding is required; give exact analytical expressions.", "solution": "The problem requires the derivation of the parameters $(\\alpha_m, \\alpha_f, \\beta, \\gamma)$ of the generalized-$\\alpha$ time integration method as functions of a specified high-frequency spectral radius $\\rho_{\\infty}$, under the constraint of second-order accuracy.\n\nFirst, we establish the recursive relationship for the state vector $\\mathbf{x}_n = [u_n, \\Delta t\\,v_n, \\Delta t^2 a_n]^T$. The update is of the form $\\mathbf{x}_{n+1} = \\mathbf{A} \\mathbf{x}_n$, where $\\mathbf{A}$ is the amplification matrix.\n\nThe discrete equation of motion is:\n$m\\,a_{n+\\alpha_m} + k\\,u_{n+\\alpha_f} = 0$.\nUsing the definitions $a_{n+\\alpha_m} = (1-\\alpha_m)a_{n+1} + \\alpha_m a_n$ and $u_{n+\\alpha_f} = (1-\\alpha_f)u_{n+1} + \\alpha_f u_n$, this becomes:\n$m((1-\\alpha_m)a_{n+1} + \\alpha_m a_n) + k((1-\\alpha_f)u_{n+1} + \\alpha_f u_n) = 0$.\nDividing by $m$ and using $\\omega^2 = k/m$, we get:\n$(1-\\alpha_m)a_{n+1} + \\alpha_m a_n + \\omega^2((1-\\alpha_f)u_{n+1} + \\alpha_f u_n) = 0$.\nLet $\\Omega = \\omega \\Delta t$. Multiplying by $\\Delta t^2$:\n$(1-\\alpha_m)\\Delta t^2 a_{n+1} + \\alpha_m \\Delta t^2 a_n + \\Omega^2((1-\\alpha_f)u_{n+1} + \\alpha_f u_n) = 0$.\n\nNow, substitute the Newmark update for displacement, $u_{n+1} = u_n + \\Delta t v_n + \\Delta t^2((\\frac{1}{2}-\\beta)a_n + \\beta a_{n+1})$, into the equation of motion:\n$$\n(1-\\alpha_m)\\Delta t^2 a_{n+1} + \\alpha_m \\Delta t^2 a_n + \\Omega^2(1-\\alpha_f)\\left[u_n + \\Delta t v_n + \\Delta t^2\\left(\\left(\\frac{1}{2}-\\beta\\right)a_n + \\beta a_{n+1}\\right)\\right] + \\Omega^2 \\alpha_f u_n = 0\n$$\nWe can solve this for $a_{n+1}$ in terms of the state at time $t_n$:\n$$\n\\left[ (1-\\alpha_m) + \\beta(1-\\alpha_f)\\Omega^2 \\right] \\Delta t^2 a_{n+1} = -\\Omega^2 u_n - \\Omega^2(1-\\alpha_f)\\Delta t v_n - \\left[\\alpha_m + \\left(\\frac{1}{2}-\\beta\\right)(1-\\alpha_f)\\Omega^2\\right]\\Delta t^2 a_n\n$$\nLet $D = (1-\\alpha_m) + \\beta(1-\\alpha_f)\\Omega^2$. Then:\n$$\n\\Delta t^2 a_{n+1} = -\\frac{\\Omega^2}{D} u_n - \\frac{\\Omega^2(1-\\alpha_f)}{D} \\Delta t v_n - \\frac{\\alpha_m + (\\frac{1}{2}-\\beta)(1-\\alpha_f)\\Omega^2}{D} \\Delta t^2 a_n\n$$\nThe other components of the state vector at $t_{n+1}$ are given by the Newmark updates:\n$u_{n+1} = u_n + \\Delta t v_n + (\\frac{1}{2}-\\beta)\\Delta t^2 a_n + \\beta \\Delta t^2 a_{n+1}$.\n$\\Delta t v_{n+1} = \\Delta t v_n + (1-\\gamma)\\Delta t^2 a_n + \\gamma \\Delta t^2 a_{n+1}$.\nSubstituting the expression for $\\Delta t^2 a_{n+1}$ gives the rows of the amplification matrix $\\mathbf{A}$.\n\nOur interest lies in the high-frequency behavior, i.e., the limit $\\Omega \\to \\infty$. In this limit, the denominator $D \\approx \\beta(1-\\alpha_f)\\Omega^2$. The components of the limit amplification matrix $\\mathbf{A}_{\\infty}$ are found by evaluating the coefficients of $u_n$, $\\Delta t v_n$, and $\\Delta t^2 a_n$ in the expressions for $u_{n+1}$, $\\Delta t v_{n+1}$, and $\\Delta t^2 a_{n+1}$ as $\\Omega \\to \\infty$.\nThe analysis yields:\n$$\n\\mathbf{A}_{\\infty} = \\lim_{\\Omega \\to \\infty} \\mathbf{A} = \\begin{pmatrix} -\\frac{\\alpha_f}{1-\\alpha_f} & 0 & 0 \\\\ -\\frac{\\gamma}{\\beta(1-\\alpha_f)} & 1 - \\frac{\\gamma}{\\beta} & 1 - \\frac{\\gamma}{2\\beta} \\\\ -\\frac{1}{\\beta(1-\\alpha_f)} & -\\frac{1}{\\beta} & 1 - \\frac{1}{2\\beta} \\end{pmatrix}\n$$\nThis matrix is block lower triangular. Its eigenvalues are the eigenvalues of its diagonal blocks. One eigenvalue is immediately apparent:\n$\\lambda_1 = -\\frac{\\alpha_f}{1-\\alpha_f}$.\nThe other two eigenvalues, $\\lambda_2$ and $\\lambda_3$, are the eigenvalues of the lower-right $2 \\times 2$ sub-matrix:\n$$\nM = \\begin{pmatrix} 1 - \\frac{\\gamma}{\\beta} & 1 - \\frac{\\gamma}{2\\beta} \\\\ -\\frac{1}{\\beta} & 1 - \\frac{1}{2\\beta} \\end{pmatrix}\n$$\nThe characteristic equation for this sub-matrix is $\\det(M - \\lambda I) = 0$, which simplifies to:\n$$\n\\lambda^2 - \\left(2 - \\frac{2\\gamma+1}{2\\beta}\\right)\\lambda + \\left(1 - \\frac{2\\gamma-1}{2\\beta}\\right) = 0\n$$\nTo achieve optimal numerical dissipation, we impose that all eigenvalues have a magnitude equal to the desired high-frequency spectral radius $\\rho_{\\infty}$. To ensure damping, we set the eigenvalues to be $-\\rho_{\\infty}$.\n1.  From $\\lambda_1 = -\\rho_{\\infty}$:\n    $-\\frac{\\alpha_f}{1-\\alpha_f} = -\\rho_{\\infty} \\implies \\alpha_f = \\rho_{\\infty}(1-\\alpha_f) \\implies \\alpha_f(1+\\rho_{\\infty})=\\rho_{\\infty}$.\n    This gives: $\\alpha_f = \\frac{\\rho_{\\infty}}{1+\\rho_{\\infty}}$.\n\n2.  For the other two eigenvalues, we require the quadratic equation to be equivalent to $(\\lambda + \\rho_{\\infty})^2 = \\lambda^2 + 2\\rho_{\\infty}\\lambda + \\rho_{\\infty}^2 = 0$. By comparing coefficients:\n    $2\\rho_{\\infty} = -\\left(2 - \\frac{2\\gamma+1}{2\\beta}\\right) \\implies \\frac{2\\gamma+1}{2\\beta} = 2 + 2\\rho_{\\infty} = 2(1+\\rho_{\\infty})$.\n    $\\rho_{\\infty}^2 = 1 - \\frac{2\\gamma-1}{2\\beta} \\implies \\frac{2\\gamma-1}{2\\beta} = 1-\\rho_{\\infty}^2$.\n    We now have a system of two linear equations for $\\gamma$ and $\\beta$:\n    (i) $2\\gamma+1 = 4\\beta(1+\\rho_{\\infty})$\n    (ii) $2\\gamma-1 = 2\\beta(1-\\rho_{\\infty}^2)$\n    Subtracting (ii) from (i) gives: $2 = (4\\beta(1+\\rho_{\\infty})) - (2\\beta(1-\\rho_{\\infty}^2)) = 2\\beta(1+\\rho_{\\infty})[2 - (1-\\rho_{\\infty})] = 2\\beta(1+\\rho_{\\infty})^2$.\n    This yields: $\\beta = \\frac{1}{(1+\\rho_{\\infty})^2}$.\n    Substituting this result for $\\beta$ into equation (i):\n    $2\\gamma+1 = 4\\frac{1}{(1+\\rho_{\\infty})^2}(1+\\rho_{\\infty}) = \\frac{4}{1+\\rho_{\\infty}}$.\n    $2\\gamma = \\frac{4}{1+\\rho_{\\infty}}-1 = \\frac{3-\\rho_{\\infty}}{1+\\rho_{\\infty}}$.\n    This yields: $\\gamma = \\frac{3-\\rho_{\\infty}}{2(1+\\rho_{\\infty})}$.\n\n3.  The condition for second-order accuracy of the generalized-$\\alpha$ method relates the parameters by $\\gamma = \\frac{1}{2} - \\alpha_m + \\alpha_f$. We use this to find $\\alpha_m$:\n    $\\alpha_m = \\frac{1}{2} + \\alpha_f - \\gamma = \\frac{1}{2} + \\frac{\\rho_{\\infty}}{1+\\rho_{\\infty}} - \\frac{3-\\rho_{\\infty}}{2(1+\\rho_{\\infty})}$.\n    $\\alpha_m = \\frac{(1+\\rho_{\\infty}) + 2\\rho_{\\infty} - (3-\\rho_{\\infty})}{2(1+\\rho_{\\infty})} = \\frac{1+\\rho_{\\infty}+2\\rho_{\\infty}-3+\\rho_{\\infty}}{2(1+\\rho_{\\infty})} = \\frac{4\\rho_{\\infty}-2}{2(1+\\rho_{\\infty})}$.\n    This yields: $\\alpha_m = \\frac{2\\rho_{\\infty}-1}{1+\\rho_{\\infty}}$.\n    The set of parameters is now fully determined as a function of $\\rho_{\\infty}$. Another condition for optimal second-order accuracy, $\\beta = \\frac{1}{4}(1-\\alpha_m+\\alpha_f)^2$, can be verified to be consistent with our derived expressions.\n\nFinally, we address the Hilber–Hughes–Taylor-$\\alpha$ (HHT-$\\alpha$) method, which is the special case of the generalized-$\\alpha$ method where $\\alpha_m = 0$.\nSetting our expression for $\\alpha_m$ to zero:\n$\\alpha_m = \\frac{2\\rho_{\\infty}-1}{1+\\rho_{\\infty}} = 0 \\implies 2\\rho_{\\infty}-1 = 0 \\implies \\rho_{\\infty} = \\frac{1}{2}$.\nThe problem defines the HHT-$\\alpha$ parameter as $\\alpha_{\\mathrm{HHT}} := \\alpha_f$. We must evaluate $\\alpha_f$ at $\\rho_{\\infty} = 1/2$:\n$\\alpha_{\\mathrm{HHT}} = \\alpha_f\\left(\\rho_{\\infty}=\\frac{1}{2}\\right) = \\frac{1/2}{1+1/2} = \\frac{1/2}{3/2} = \\frac{1}{3}$.\n\nThe required expressions are:\n$\\alpha_m(\\rho_{\\infty}) = \\frac{2\\rho_{\\infty}-1}{\\rho_{\\infty}+1}$\n$\\alpha_f(\\rho_{\\infty}) = \\frac{\\rho_{\\infty}}{\\rho_{\\infty}+1}$\n$\\beta(\\rho_{\\infty}) = \\frac{1}{(1+\\rho_{\\infty})^2}$\n$\\gamma(\\rho_{\\infty}) = \\frac{3-\\rho_{\\infty}}{2(1+\\rho_{\\infty})}$\n$\\alpha_{\\mathrm{HHT}} = \\frac{1}{3}$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2\\rho_{\\infty}-1}{\\rho_{\\infty}+1} & \\frac{\\rho_{\\infty}}{\\rho_{\\infty}+1} & \\frac{1}{(1+\\rho_{\\infty})^2} & \\frac{3-\\rho_{\\infty}}{2(1+\\rho_{\\infty})} & \\frac{1}{3}\n\\end{pmatrix}\n}\n$$", "id": "2564628"}, {"introduction": "The ultimate test of understanding a numerical method is to build it from the ground up and observe its behavior. This capstone practice synthesizes the concepts of accuracy, stability, and numerical dissipation by challenging you to implement a variable-damping HHT-$\\alpha$ scheme in code. By deriving the algorithm, writing the program, and testing it on various scenarios, you will gain a robust and practical mastery of how HHT methods are used to solve real-world dynamics problems [@problem_id:2564526].", "problem": "Consider the second-order linear initial value problem arising in structural dynamics and the finite element method, governed by the balance of linear momentum,\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{u}}(t) + \\mathbf{C}\\,\\dot{\\mathbf{u}}(t) + \\mathbf{K}\\,\\mathbf{u}(t) = \\mathbf{f}(t),\n$$\nwhere $\\mathbf{M}$ is a symmetric positive-definite mass matrix, $\\mathbf{C}$ is a symmetric positive-semidefinite damping matrix, $\\mathbf{K}$ is a symmetric positive-semidefinite stiffness matrix, and $\\mathbf{u}(t)$ is the displacement vector. The Hilber-Hughes-Taylor (HHT-$\\alpha$) method is a one-step implicit time integration scheme that enforces the equilibrium equation at a shifted time $t_{n+\\alpha}$ and uses Newmark-type kinematic relations. In the classical scheme, a constant numerical damping parameter $\\alpha \\in [-\\frac{1}{3}, 0]$ is used to control high-frequency dissipation while retaining second-order accuracy and unconditional stability for linear systems.\n\nYour tasks are as follows.\n\n1) Starting from the fundamental definitions of kinematics,\n$$\n\\dot{\\mathbf{u}} = \\frac{d\\mathbf{u}}{dt}, \\quad \\ddot{\\mathbf{u}} = \\frac{d^2\\mathbf{u}}{dt^2},\n$$\nand the linear momentum balance above, derive a one-step HHT-type algorithm for advancing from $(\\mathbf{u}_n, \\dot{\\mathbf{u}}_n, \\ddot{\\mathbf{u}}_n)$ at time $t_n$ to $(\\mathbf{u}_{n+1}, \\dot{\\mathbf{u}}_{n+1}, \\ddot{\\mathbf{u}}_{n+1})$ at time $t_{n+1} = t_n + \\Delta t$. Your derivation must enforce the weighted equilibrium at the shifted time\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{u}}_{n+\\alpha} + \\mathbf{C}\\,\\dot{\\mathbf{u}}_{n+\\alpha} + \\mathbf{K}\\,\\mathbf{u}_{n+\\alpha} = \\mathbf{f}_{n+\\alpha},\n$$\nwith the affine averaging $\\mathbf{x}_{n+\\alpha} = (1-\\alpha)\\,\\mathbf{x}_{n+1} + \\alpha\\,\\mathbf{x}_n$ applied to $\\mathbf{u}, \\dot{\\mathbf{u}}, \\ddot{\\mathbf{u}}$, and $\\mathbf{f}$. Combine this with Newmark-type kinematics for $\\mathbf{u}_{n+1}$ and $\\dot{\\mathbf{u}}_{n+1}$ in terms of $\\ddot{\\mathbf{u}}_{n+1}$, $\\Delta t$, and $(\\mathbf{u}_n,\\dot{\\mathbf{u}}_n,\\ddot{\\mathbf{u}}_n)$. Derive the algebraic conditions relating the Newmark parameters to $\\alpha$ that are necessary and sufficient for consistency up to local truncation error of order $O(\\Delta t^3)$ (that is, global second-order accuracy) and for unconditional stability on linear systems with $\\mathbf{C}\\succeq \\mathbf{0}$. Do not assume any specific forms of these relations; obtain them from Taylor expansions and the enforced weighted equilibrium.\n\n2) Propose a variable-$\\alpha$ construction that depends on a modal content estimator. For a single-degree-of-freedom system with scalar $m>0$, $c\\ge 0$, and $k\\ge 0$, define the estimator using the Rayleigh frequency\n$$\n\\omega_n = \\sqrt{\\frac{k}{m}},\n$$\nand normalize it by the numerical Nyquist frequency\n$$\n\\omega_N = \\frac{\\pi}{\\Delta t}.\n$$\nDefine a smooth mapping\n$$\n\\phi = \\tanh\\!\\left(\\left(\\frac{\\omega_n}{\\omega_N}\\right)^p\\right), \\quad p = 4,\n$$\nand set the per-step numerical damping as\n$$\n\\alpha = -\\alpha_{\\max}\\,\\phi, \\quad \\alpha_{\\max} = 0.30,\n$$\nchosen at the beginning of the step and held fixed within that step. Select the Newmark parameters consistently with your derivation in task $1$ to retain second-order accuracy when $\\alpha$ varies stepwise in time. Justify the conditions under which second-order accuracy is retained and unconditional stability persists for the resulting variable-$\\alpha$ HHT scheme.\n\n3) Implement the resulting variable-$\\alpha$ HHT scheme for the single-degree-of-freedom case with zero external load $\\mathbf{f}(t) = 0$, using the above estimator and mapping. Use the International System of Units (SI): mass in kilograms, stiffness in newtons per meter, damping in newton-seconds per meter, displacements in meters, and time in seconds. Your implementation must be a complete and runnable program, and must not require any user input.\n\n4) Use your implementation to evaluate the following test suite. For every simulation, use the stated units and initial conditions. The external force is zero. For accuracy assessment, when an analytical reference is needed, use the exact undamped harmonic oscillator solution. The final outputs must be:\n- For stability checks, a boolean defined as true if the maximum absolute displacement over the simulated time interval does not exceed the provided bound.\n- For order checks, a float estimating the observed order $p_{\\mathrm{obs}}$ computed as $\\log(e_{\\Delta t}/e_{\\Delta t/2})/\\log(2)$, where $e_{\\Delta t}$ is the absolute error in displacement at the final time using step size $\\Delta t$.\n\nTest cases:\n- Test $1$ (happy path stability under modest damping and moderate resolution): $m=1$, $c=0.02$, $k=(2\\pi\\cdot 20)^2$, $\\Delta t = 0.0025$, total time $T=0.5$, initial conditions $u(0)=1$, $\\dot{u}(0)=0$. Output a boolean indicating whether $\\max_{0\\le t\\le T} |u(t)| \\le 1.5$.\n- Test $2$ (large time step stability edge): same $m$, $c$, and $k$ as Test $1$, but with $\\Delta t = 0.02$, total time $T=0.5$, initial conditions $u(0)=1$, $\\dot{u}(0)=0$. Output a boolean indicating whether $\\max_{0\\le t\\le T} |u(t)| \\le 5.0$.\n- Test $3$ (second-order accuracy verification at low frequency): undamped oscillator with $m=1$, $c=0$, $k=(2\\pi)^2$, initial conditions $u(0)=1$, $\\dot{u}(0)=0$, final time $T=1$. Compute the displacement error at $t=T$ for $\\Delta t_1=0.02$ and $\\Delta t_2=0.01$ and output the estimated order $p_{\\mathrm{obs}}$ as a float. The analytical reference is $u_{\\mathrm{exact}}(T)=\\cos(\\omega T)$ with $\\omega=\\sqrt{k/m}$.\n- Test $4$ (adaptive numerical damping effectiveness): high-frequency system with $m=1$, $c=0.02$, $k=(2\\pi\\cdot 50)^2$, $\\Delta t=0.01$, total time $T=0.2$, initial conditions $u(0)=0$, $\\dot{u}(0)=1$. Compute two simulations: one with variable $\\alpha$ as defined, and one with $\\alpha=0$ (the average-acceleration Newmark method). Output a boolean indicating whether the root-mean-square displacement over the interval $[0,T]$ produced by the variable-$\\alpha$ scheme is less than or equal to that from $\\alpha=0$.\n\nFinal output format requirement: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases: $[b_1,b_2,p_3,b_4]$. The booleans $b_1$, $b_2$, and $b_4$ must be printed as literal true or false in Python’s default formatting, and the float $p_3$ must be printed rounded to six decimal places. No other text should be printed.", "solution": "The problem presented is a standard, well-posed exercise in the field of computational structural dynamics. It asks for the derivation, specialization, implementation, and testing of the Hilber-Hughes-Taylor (HHT-$\\alpha$) time integration method, or more specifically, a form often known as the WBZ-$\\alpha$ method, for a second-order linear system. All parameters and objectives are clearly defined, scientifically grounded, and computationally feasible. The problem is valid.\n\nWe proceed with the solution in four parts as requested.\n\n### Part 1: Derivation of the HHT-type Algorithm\n\nThe governing equation of motion for a linear structural system is given by:\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{u}}(t) + \\mathbf{C}\\,\\dot{\\mathbf{u}}(t) + \\mathbf{K}\\,\\mathbf{u}(t) = \\mathbf{f}(t)\n$$\nwhere $\\mathbf{M}$, $\\mathbf{C}$, and $\\mathbf{K}$ are the mass, damping, and stiffness matrices, respectively, and $\\mathbf{u}(t)$ is the displacement vector.\n\nThe HHT-$\\alpha$ method is a one-step implicit scheme that numerically integrates this equation. It belongs to the family of Newmark methods. We start by defining the Newmark kinematic relations, which approximate the displacement $\\mathbf{u}_{n+1}$ and velocity $\\dot{\\mathbf{u}}_{n+1}$ at time $t_{n+1} = t_n + \\Delta t$:\n$$\n\\mathbf{u}_{n+1} = \\mathbf{u}_n + \\Delta t\\,\\dot{\\mathbf{u}}_n + \\frac{\\Delta t^2}{2} \\left[ (1 - 2\\beta) \\ddot{\\mathbf{u}}_n + 2\\beta \\ddot{\\mathbf{u}}_{n+1} \\right]\n$$\n$$\n\\dot{\\mathbf{u}}_{n+1} = \\dot{\\mathbf{u}}_n + \\Delta t \\left[ (1 - \\gamma) \\ddot{\\mathbf{u}}_n + \\gamma \\ddot{\\mathbf{u}}_{n+1} \\right]\n$$\nHere, $\\beta$ and $\\gamma$ are the Newmark integration parameters that determine the stability and accuracy of the method. These equations can be rearranged to express $\\mathbf{u}_{n+1}$ and $\\dot{\\mathbf{u}}_{n+1}$ in terms of the yet unknown acceleration $\\ddot{\\mathbf{u}}_{n+1}$ and quantities from time $t_n$.\n\nThe HHT-$\\alpha$ method, as defined in the problem, enforces the equation of motion at a weighted-average point between $t_n$ and $t_{n+1}$:\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{u}}_{n+\\alpha} + \\mathbf{C}\\,\\dot{\\mathbf{u}}_{n+\\alpha} + \\mathbf{K}\\,\\mathbf{u}_{n+\\alpha} = \\mathbf{f}_{n+\\alpha}\n$$\nwhere a generic quantity $\\mathbf{x}_{n+\\alpha}$ is defined by the affine average:\n$$\n\\mathbf{x}_{n+\\alpha} = (1-\\alpha)\\,\\mathbf{x}_{n+1} + \\alpha\\,\\mathbf{x}_n\n$$\napplied to $\\mathbf{u}, \\dot{\\mathbf{u}}, \\ddot{\\mathbf{u}}$, and $\\mathbf{f}$. The parameter $\\alpha \\in [-\\frac{1}{3}, 0]$ controls numerical dissipation of high-frequency modes.\n\nSubstituting the affine averaging into the weighted equilibrium equation gives:\n$$\n(1-\\alpha)(\\mathbf{M}\\ddot{\\mathbf{u}}_{n+1} + \\mathbf{C}\\dot{\\mathbf{u}}_{n+1} + \\mathbf{K}\\mathbf{u}_{n+1}) + \\alpha(\\mathbf{M}\\ddot{\\mathbf{u}}_{n} + \\mathbf{C}\\dot{\\mathbf{u}}_{n} + \\mathbf{K}\\mathbf{u}_{n}) = (1-\\alpha)\\mathbf{f}_{n+1} + \\alpha\\mathbf{f}_{n}\n$$\nNow, substitute the Newmark relations for $\\mathbf{u}_{n+1}$ and $\\dot{\\mathbf{u}}_{n+1}$ into this equation. This leads to an equation solely for the unknown acceleration $\\ddot{\\mathbf{u}}_{n+1}$:\n$$\n(1-\\alpha)\\left(\\mathbf{M}\\ddot{\\mathbf{u}}_{n+1} + \\mathbf{C}(\\dot{\\mathbf{u}}_n + \\Delta t (1 - \\gamma) \\ddot{\\mathbf{u}}_n + \\gamma \\Delta t \\ddot{\\mathbf{u}}_{n+1}) + \\mathbf{K}(\\mathbf{u}_n + \\Delta t\\,\\dot{\\mathbf{u}}_n + \\frac{\\Delta t^2}{2} ((1 - 2\\beta) \\ddot{\\mathbf{u}}_n + 2\\beta \\ddot{\\mathbf{u}}_{n+1}))\\right) + \\alpha(\\mathbf{M}\\ddot{\\mathbf{u}}_{n} + \\mathbf{C}\\dot{\\mathbf{u}}_{n} + \\mathbf{K}\\mathbf{u}_{n}) = (1-\\alpha)\\mathbf{f}_{n+1} + \\alpha\\mathbf{f}_{n}\n$$\nRearranging to group terms involving $\\ddot{\\mathbf{u}}_{n+1}$ on the left-hand side:\n$$\n\\left[ (1-\\alpha)\\mathbf{M} + (1-\\alpha)\\gamma\\Delta t\\,\\mathbf{C} + (1-\\alpha)\\beta\\Delta t^2\\,\\mathbf{K} \\right] \\ddot{\\mathbf{u}}_{n+1} = (1-\\alpha)\\mathbf{f}_{n+1} + \\alpha\\mathbf{f}_{n} - \\alpha(\\mathbf{M}\\ddot{\\mathbf{u}}_{n} + \\mathbf{C}\\dot{\\mathbf{u}}_{n} + \\mathbf{K}\\mathbf{u}_{n}) - (1-\\alpha)\\left( \\mathbf{C}(\\dot{\\mathbf{u}}_n + \\Delta t(1-\\gamma)\\ddot{\\mathbf{u}}_n) + \\mathbf{K}(\\mathbf{u}_n + \\Delta t\\dot{\\mathbf{u}}_n + \\Delta t^2(\\frac{1}{2}-\\beta)\\ddot{\\mathbf{u}}_n) \\right)\n$$\nThis is a linear system of equations of the form $\\hat{\\mathbf{M}}\\,\\ddot{\\mathbf{u}}_{n+1} = \\hat{\\mathbf{f}}_n$, where $\\hat{\\mathbf{M}}$ is the effective mass matrix and $\\hat{\\mathbf{f}}_n$ is the effective force vector. Once $\\ddot{\\mathbf{u}}_{n+1}$ is computed, $\\mathbf{u}_{n+1}$ and $\\dot{\\mathbf{u}}_{n+1}$ are found from the Newmark relations.\n\n**Conditions for Accuracy and Stability:**\nThe derivation of these conditions is based on analyzing the method's behavior on an unforced, undamped single-degree-of-freedom (SDOF) system, $\\ddot{u} + \\omega^2 u = 0$. The analysis involves writing the one-step algorithm as $\\mathbf{y}_{n+1} = \\mathbf{A}\\,\\mathbf{y}_n$, where $\\mathbf{y}_n = [u_n, \\Delta t \\dot{u}_n, \\Delta t^2 \\ddot{u}_n]^T$ and $\\mathbf{A}$ is the amplification matrix.\n\n1.  **Second-Order Accuracy:** To achieve second-order accuracy (i.e., local truncation error of order $O(\\Delta t^3)$), the method must not introduce artificial numerical damping in the low-frequency limit ($\\omega \\Delta t \\rightarrow 0$) and must have a period error of $O(\\Delta t^2)$. This analysis, performed by comparing the characteristic roots of the amplification matrix to the exact solution $e^{\\pm i\\omega\\Delta t}$, yields the condition:\n    $$\n    \\gamma = \\frac{1}{2} - \\alpha\n    $$\n\n2.  **Unconditional Stability:** For unconditional stability, the spectral radius of the amplification matrix, $\\rho(\\mathbf{A})$, must be less than or equal to one for all values of $\\omega \\Delta t$. For the method to be dissipative in the high-frequency limit ($\\omega \\Delta t \\rightarrow \\infty$), we require $\\rho(\\mathbf{A}) < 1$. These constraints lead to the following necessary and sufficient conditions:\n    $$\n    \\gamma \\ge \\frac{1}{2}, \\quad \\beta \\ge \\frac{1}{4}(1-\\alpha+\\gamma)^2\n    $$\n    Combining the accuracy and stability requirements, we substitute $\\gamma = 1/2 - \\alpha$. The condition $\\gamma \\ge 1/2$ requires $1/2 - \\alpha \\ge 1/2$, which implies $\\alpha \\le 0$. The problem states $\\alpha \\in [-1/3, 0]$, which satisfies this. The most common choice to maximize high-frequency dissipation for a given $\\alpha$ is:\n    $$\n    \\beta = \\frac{(1-\\alpha)^2}{4}\n    $$\n    This choice fulfills the general stability conditions for $\\alpha \\in [-1/3, 0]$. Specifically, for $\\alpha=0$, we recover the Newmark average acceleration method with $\\gamma=1/2, \\beta=1/4$, which is non-dissipative and unconditionally stable. For $\\alpha=-1/3$, we get $\\gamma=5/6$ and $\\beta=4/9$, which provides strong numerical damping.\n\n### Part 2: Variable-$\\alpha$ Construction\n\nWe are asked to propose a variable-$\\alpha$ scheme where $\\alpha$ is adjusted at each time step based on modal content. For an SDOF system, the modal content is defined by the natural frequency $\\omega_n = \\sqrt{k/m}$.\n\nThe scheme is defined as:\n$$\n\\alpha_n = -\\alpha_{\\max}\\,\\phi_n, \\quad \\text{with} \\quad \\alpha_{\\max} = 0.30\n$$\nwhere $\\phi_n$ is a mapping based on the ratio of the system's frequency to the numerical Nyquist frequency, $\\omega_N = \\pi/\\Delta t$:\n$$\n\\phi_n = \\tanh\\left(\\left(\\frac{\\omega_n}{\\omega_N}\\right)^p\\right), \\quad \\text{with} \\quad p = 4\n$$\nAt the beginning of each step $n$, we compute $\\alpha_n$ and hold it fixed for the duration of that step. To maintain second-order accuracy and unconditional stability, we must select the Newmark parameters consistently at each step. Following the derivation in Part 1, we set:\n$$\n\\gamma_n = \\frac{1}{2} - \\alpha_n\n$$\n$$\n\\beta_n = \\frac{(1-\\alpha_n)^2}{4}\n$$\n\n**Justification of Properties:**\n\n1.  **Second-Order Accuracy:** For a scheme with time-varying parameters, second-order accuracy is retained if the parameters for step $n \\to n+1$ are determined based on the state at time $t_n$ (or are otherwise independent of the state at $t_{n+1}$) and satisfy the accuracy condition for a constant-parameter scheme. In our case, $\\omega_n$ is constant for an LTI system, so $\\alpha_n$, $\\beta_n$, and $\\gamma_n$ are constant throughout the simulation (though dependent on $\\Delta t$). Even if $k$ or $m$ were changing slowly, the principle of determining parameters at the start of the step preserves accuracy. The relation $\\gamma_n = 1/2 - \\alpha_n$ is satisfied by construction, ensuring the local truncation error is $O(\\Delta t^3)$, which integrates to a global error of $O(\\Delta t^2)$.\n\n2.  **Unconditional Stability:** For a linear system, stability can be analyzed on a per-step basis. At each step $n$, the algorithm proceeds with a fixed set of parameters $(\\alpha_n, \\beta_n, \\gamma_n)$. We must check if these parameters satisfy the unconditional stability conditions.\n    -   The mapping $\\phi_n$ produces values in $[0, 1)$, since $\\omega_n/\\omega_N \\ge 0$.\n    -   Therefore, $\\alpha_n = -0.30\\,\\phi_n$ lies in the range $(-0.30, 0]$. This is within the range $[-1/3, 0]$ for which the HHT method is known to be unconditionally stable with the chosen parameter relations.\n    -   The parameters are chosen as $\\gamma_n = 1/2 - \\alpha_n$ and $\\beta_n = (1-\\alpha_n)^2/4$. As established in Part 1, these choices ensure that the stability conditions $\\gamma_n \\ge 1/2$ and the more general conditions are met for $\\alpha_n \\le 0$.\n    -   Since the method is unconditionally stable for the parameters chosen at every individual step, the overall variable-parameter scheme remains unconditionally stable for linear problems. The amount of numerical damping is adapted based on how well the time step resolves the system's natural period.\n\n### Part 3: Implementation Algorithm\n\nFor a single-degree-of-freedom system with $f(t)=0$, the algorithm to advance from step $n$ to $n+1$ is as follows:\n\n1.  **Initialization**: Given $m, c, k$ and initial conditions $u_0, \\dot{u}_0$. Calculate the initial acceleration by enforcing the equation of motion at $t=0$:\n    $$\n    \\ddot{u}_0 = -(c\\dot{u}_0 + k u_0) / m\n    $$\n\n2.  **For each time step $n=0, 1, 2, ...$**:\n    a. **Compute adaptive parameters**:\n       -   $\\omega_n = \\sqrt{k/m}$\n       -   $\\omega_N = \\pi/\\Delta t$\n       -   $\\phi_n = \\tanh((\\omega_n/\\omega_N)^4)$\n       -   $\\alpha_n = -0.30\\,\\phi_n$\n       -   $\\gamma_n = 1/2 - \\alpha_n$\n       -   $\\beta_n = (1-\\alpha_n)^2/4$\n       For the specific fixed-parameter test case ($\\alpha=0$), these are simply set to $\\alpha_n=0, \\gamma_n=1/2, \\beta_n=1/4$.\n\n    b. **Solve for $\\ddot{u}_{n+1}$**:\n       The linear system from Part 1 simplifies to a scalar equation $A\\ddot{u}_{n+1} = B$, where:\n       $$\n       A = (1-\\alpha_n)m + (1-\\alpha_n)\\gamma_n\\Delta t\\,c + (1-\\alpha_n)\\beta_n\\Delta t^2\\,k\n       $$\n       $$\n        B = -(1-\\alpha_n)\\left[ c(\\dot{u}_n + \\Delta t(1-\\gamma_n)\\ddot{u}_n) + k(u_n + \\Delta t\\dot{u}_n + \\Delta t^2(\\frac{1}{2}-\\beta_n)\\ddot{u}_n) \\right] - \\alpha_n(m\\ddot{u}_n + c\\dot{u}_n + ku_n)\n       $$\n       $$\n       \\ddot{u}_{n+1} = B/A\n       $$\n\n    c. **Update state (corrector step)**:\n       $$\n       u_{n+1} = \\left(u_n + \\Delta t\\dot{u}_n + \\Delta t^2(\\frac{1}{2}-\\beta_n)\\ddot{u}_n\\right) + \\beta_n\\Delta t^2 \\ddot{u}_{n+1}\n       $$\n       $$\n       \\dot{u}_{n+1} = \\left(\\dot{u}_n + \\Delta t(1-\\gamma_n)\\ddot{u}_n\\right) + \\gamma_n\\Delta t \\ddot{u}_{n+1}\n       $$\n    The terms in parentheses are the \"predictor\" values.\n\n### Part 4: Test Suite Evaluation\n\nThe implementation described in Part 3 is used to run the specified test cases. The results are computed as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing the variable-alpha HHT scheme and running the specified test cases.\n    \"\"\"\n\n    def run_hht_simulation(m, c, k, u0, v0, dt, T, alpha_mode='variable'):\n        \"\"\"\n        Runs a single-degree-of-freedom HHT simulation.\n\n        Args:\n            m (float): mass\n            c (float): damping\n            k (float): stiffness\n            u0 (float): initial displacement\n            v0 (float): initial velocity\n            dt (float): time step\n            T (float): total simulation time\n            alpha_mode (str): 'variable' for adaptive alpha, 'zero' for alpha=0.\n\n        Returns:\n            A tuple (t_hist, u_hist, v_hist, a_hist) with time histories.\n        \"\"\"\n        n_steps = int(round(T / dt))\n        t_hist = np.linspace(0, n_steps * dt, n_steps + 1)\n        u_hist = np.zeros(n_steps + 1)\n        v_hist = np.zeros(n_steps + 1)\n        a_hist = np.zeros(n_steps + 1)\n\n        # Initial conditions\n        u_hist[0] = u0\n        v_hist[0] = v0\n        # Enforce EOM at t=0 to find a0, assuming f(0)=0\n        if m > 0:\n            a_hist[0] = -(c * v0 + k * u0) / m\n        else: # m=0 case not expected but handle\n            a_hist[0] = 0\n\n        # Pre-calculate frequency terms for variable alpha\n        if alpha_mode == 'variable':\n            if m > 0 and k >= 0:\n                omega_n = np.sqrt(k / m)\n            else:\n                omega_n = 0.0\n            omega_N = np.pi / dt\n            ratio = omega_n / omega_N if omega_N > 0 else 0\n            # Use p=4 as specified\n            phi = np.tanh(ratio**4)\n            # Use alpha_max = 0.30 as specified\n            alpha = -0.30 * phi\n        else: # alpha_mode == 'zero'\n            alpha = 0.0\n\n        gamma = 0.5 - alpha\n        beta = (1 - alpha)**2 / 4\n\n        for n in range(n_steps):\n            u_n, v_n, a_n = u_hist[n], v_hist[n], a_hist[n]\n\n            # Solve for a_{n+1}. Equation is A*a_{n+1} = B\n            # A = (1-a)m + (1-a)g*dt*c + (1-a)b*dt^2*k\n            # B = -(1-a)[c(v_n+dt(1-g)a_n) + k(u_n+dt*v_n+dt^2(0.5-b)a_n)] - a(m*a_n+c*v_n+k*u_n)\n            \n            A = (1 - alpha) * (m + gamma * dt * c + beta * dt**2 * k)\n            \n            # Predictor terms needed for B\n            v_tilde_np1 = v_n + dt * (1 - gamma) * a_n\n            u_tilde_np1 = u_n + dt * v_n + dt**2 * (0.5 - beta) * a_n\n\n            B = -(1-alpha)*(c * v_tilde_np1 + k * u_tilde_np1) - alpha * (m * a_n + c * v_n + k * u_n)\n            \n            if A != 0:\n                a_np1 = B / A\n            else:\n                a_np1 = 0\n\n            # Corrector step\n            u_np1 = u_tilde_np1 + beta * dt**2 * a_np1\n            v_np1 = v_tilde_np1 + gamma * dt * a_np1\n\n            u_hist[n + 1] = u_np1\n            v_hist[n + 1] = v_np1\n            a_hist[n + 1] = a_np1\n\n        return t_hist, u_hist, v_hist, a_hist\n\n    results = []\n\n    # Test 1: Stability under modest damping and moderate resolution\n    m1, c1, k1 = 1.0, 0.02, (2 * np.pi * 20)**2\n    dt1, T1 = 0.0025, 0.5\n    u01, v01 = 1.0, 0.0\n    _, u_hist1, _, _ = run_hht_simulation(m1, c1, k1, u01, v01, dt1, T1)\n    b1 = np.max(np.abs(u_hist1)) <= 1.5\n    results.append(b1)\n\n    # Test 2: Large time step stability edge\n    m2, c2, k2 = 1.0, 0.02, (2 * np.pi * 20)**2\n    dt2, T2 = 0.02, 0.5\n    u02, v02 = 1.0, 0.0\n    _, u_hist2, _, _ = run_hht_simulation(m2, c2, k2, u02, v02, dt2, T2)\n    b2 = np.max(np.abs(u_hist2)) <= 5.0\n    results.append(b2)\n    \n    # Test 3: Second-order accuracy verification\n    m3, c3, k3 = 1.0, 0.0, (2 * np.pi)**2\n    T3 = 1.0\n    u03, v03 = 1.0, 0.0\n    dt3a, dt3b = 0.02, 0.01\n\n    _, u_hist3a, _, _ = run_hht_simulation(m3, c3, k3, u03, v03, dt3a, T3)\n    u_final_3a = u_hist3a[-1]\n\n    _, u_hist3b, _, _ = run_hht_simulation(m3, c3, k3, u03, v03, dt3b, T3)\n    u_final_3b = u_hist3b[-1]\n    \n    omega_3 = np.sqrt(k3 / m3)\n    u_exact_T3 = np.cos(omega_3 * T3)\n\n    e_dta = np.abs(u_final_3a - u_exact_T3)\n    e_dtb = np.abs(u_final_3b - u_exact_T3)\n\n    if e_dta > 0 and e_dtb > 0:\n        p_obs = np.log(e_dta / e_dtb) / np.log(2)\n    else: # Fallback if error is zero (unlikely but possible)\n        p_obs = 2.0\n        \n    results.append(f\"{p_obs:.6f}\")\n    \n    # Test 4: Adaptive numerical damping effectiveness\n    m4, c4, k4 = 1.0, 0.02, (2 * np.pi * 50)**2\n    dt4, T4 = 0.01, 0.2\n    u04, v04 = 0.0, 1.0\n\n    # Variable alpha simulation\n    _, u_hist4_var, _, _ = run_hht_simulation(m4, c4, k4, u04, v04, dt4, T4, alpha_mode='variable')\n    rms_var = np.sqrt(np.mean(u_hist4_var**2))\n\n    # Alpha=0 simulation (Newmark average acceleration)\n    _, u_hist4_zero, _, _ = run_hht_simulation(m4, c4, k4, u04, v04, dt4, T4, alpha_mode='zero')\n    rms_zero = np.sqrt(np.mean(u_hist4_zero**2))\n\n    b4 = rms_var <= rms_zero\n    results.append(b4)\n    \n    # Final print statement\n    result_str = \",\".join(map(str, results)).lower()\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2564526"}]}