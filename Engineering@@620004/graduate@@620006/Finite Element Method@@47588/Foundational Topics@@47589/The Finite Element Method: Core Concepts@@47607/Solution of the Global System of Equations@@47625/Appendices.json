{"hands_on_practices": [{"introduction": "The global stiffness matrices generated by the Finite Element Method are typically large, sparse, and banded. The efficiency of both direct and iterative solvers is highly dependent on the matrix's structure, specifically its bandwidth or profile. This practice provides a hands-on exercise in applying the Cuthill–McKee algorithm, a fundamental graph-based technique used to reorder matrix rows and columns to reduce its bandwidth, thereby improving computational performance and memory efficiency [@problem_id:2596891].", "problem": "Consider a symmetric positive definite global stiffness matrix $K$ arising from a scalar diffusion problem discretized by linear triangular finite elements on a regular $3 \\times 3$ grid of mesh nodes. The nonzero pattern of $K$ is identical to the adjacency of the undirected mesh graph with vertex set $\\{1,2,3,4,5,6,7,8,9\\}$ and edges encoding nodal coupling (an edge between two vertices if and only if the corresponding stiffness matrix entry is nonzero). The mesh is obtained by connecting horizontal and vertical grid neighbors and adding one diagonal per square cell from the lower-left corner to the upper-right corner. The resulting undirected adjacency is given by the following neighbor lists (each line lists the neighbors of the indicated node):\n- Node $1$: $\\{2,4\\}$.\n- Node $2$: $\\{1,3,5,4\\}$.\n- Node $3$: $\\{2,6,5\\}$.\n- Node $4$: $\\{1,5,7,2\\}$.\n- Node $5$: $\\{2,4,6,8,3,7\\}$.\n- Node $6$: $\\{3,5,9,8\\}$.\n- Node $7$: $\\{4,8,5\\}$.\n- Node $8$: $\\{5,7,9,6\\}$.\n- Node $9$: $\\{6,8\\}$.\n\nYou are to reduce the envelope of $K$ by applying the Cuthill–McKee (CM) algorithm. Use the following fundamental definitions and rules:\n- The degree of a vertex is the number of its neighbors.\n- Breadth-First Search (BFS) level sets are constructed starting from a chosen start vertex $s$: level $L_{0}=\\{s\\}$, and $L_{k+1}$ is the set of all previously unvisited neighbors of $L_{k}$.\n- In CM, when expanding a vertex, unvisited neighbors are enqueued in nondecreasing order of their current degrees, with ties broken by increasing vertex index. The visit order is the order in which vertices are dequeued.\n- The start vertex $s$ is chosen as one with minimum degree; if there are multiple, choose the one with the smallest index.\n- The bandwidth $b$ of the permuted matrix induced by an ordering $r$ is defined by $b=\\max\\{|p(i)-p(j)|:K_{ij}\\neq 0\\}$, where $p(i)$ is the position of vertex $i$ in the ordering $r$ (positions counted from $1$).\n\nTasks:\n1. Determine the degree of each node and identify the start vertex $s$ according to the rule above.\n2. Construct the BFS level sets $L_{0},L_{1},\\dots$ used by CM from $s$ for this graph.\n3. Using the CM neighbor-ordering rule, produce the CM vertex ordering $r$ (the sequence in which vertices are dequeued).\n4. Compute the bandwidth $b$ of $K$ under the permutation defined by $r$.\n\nState the final bandwidth $b$ as a single integer. No rounding is necessary. No units are required.", "solution": "The problem statement has been critically evaluated and is deemed valid. It presents a well-posed problem in computational graph theory, specifically the application of the Cuthill–McKee algorithm for sparse matrix reordering. All necessary data, including the graph's adjacency list and the specific rules for the algorithm's execution, are provided unambiguously. The problem is scientifically grounded, objective, and contains no internal contradictions. We may proceed with the solution.\n\nThe solution requires a systematic application of the Cuthill–McKee (CM) algorithm, which involves four main tasks as outlined.\n\n**Task 1: Determine Node Degrees and Start Vertex**\n\nFirst, we must compute the degree of each vertex in the graph, which is the number of neighbors for each node as given by the adjacency lists.\n- Degree of node $1$: $\\text{deg}(1) = |\\{2, 4\\}| = 2$\n- Degree of node $2$: $\\text{deg}(2) = |\\{1, 3, 5, 4\\}| = 4$\n- Degree of node $3$: $\\text{deg}(3) = |\\{2, 6, 5\\}| = 3$\n- Degree of node $4$: $\\text{deg}(4) = |\\{1, 5, 7, 2\\}| = 4$\n- Degree of node $5$: $\\text{deg}(5) = |\\{2, 4, 6, 8, 3, 7\\}| = 6$\n- Degree of node $6$: $\\text{deg}(6) = |\\{3, 5, 9, 8\\}| = 4$\n- Degree of node $7$: $\\text{deg}(7) = |\\{4, 8, 5\\}| = 3$\n- Degree of node $8$: $\\text{deg}(8) = |\\{5, 7, 9, 6\\}| = 4$\n- Degree of node $9$: $\\text{deg}(9) = |\\{6, 8\\}| = 2$\n\nThe minimum degree among all vertices is $2$. The vertices with this minimum degree are $\\{1, 9\\}$. According to the specified rule, we break this tie by choosing the vertex with the smallest index. Therefore, the start vertex $s$ for the CM algorithm is $s=1$.\n\n**Task 2: Construct Breadth-First Search (BFS) Level Sets**\n\nStarting from $s=1$, we construct the level sets $L_k$. $L_0$ contains the start vertex. $L_{k+1}$ contains all unvisited neighbors of vertices in $L_k$.\n- $L_0 = \\{1\\}$\n- The neighbors of node $1$ are $\\{2, 4\\}$. Both are unvisited. Thus, $L_1 = \\{2, 4\\}$.\n- The neighbors of nodes in $L_1$ are found. Neighbors of $2$ are $\\{1, 3, 5, 4\\}$; unvisited are $\\{3, 5\\}$. Neighbors of $4$ are $\\{1, 5, 7, 2\\}$; unvisited are $\\{5, 7\\}$. The set of all unvisited neighbors of $L_1$ is $\\{3, 5\\} \\cup \\{5, 7\\} = \\{3, 5, 7\\}$. Thus, $L_2 = \\{3, 5, 7\\}$.\n- The neighbors of nodes in $L_2$ are examined. Neighbors of $3$ are $\\{2, 6, 5\\}$; unvisited is $\\{6\\}$. Neighbors of $5$ are $\\{2, 4, 6, 8, 3, 7\\}$; unvisited are $\\{6, 8\\}$. Neighbors of $7$ are $\\{4, 8, 5\\}$; unvisited is $\\{8\\}$. The set of all unvisited neighbors of $L_2$ is $\\{6\\} \\cup \\{6, 8\\} \\cup \\{8\\} = \\{6, 8\\}$. Thus, $L_3 = \\{6, 8\\}$.\n- The neighbors of nodes in $L_3$ are examined. Neighbors of $6$ are $\\{3, 5, 9, 8\\}$; unvisited is $\\{9\\}$. Neighbors of $8$ are $\\{5, 7, 9, 6\\}$; unvisited is $\\{9\\}$. The set of all unvisited neighbors of $L_3$ is $\\{9\\} \\cup \\{9\\} = \\{9\\}$. Thus, $L_4 = \\{9\\}$.\n- The neighbor of node $9$ in $L_4$ is $\\{6, 8\\}$, both of which are already visited. The process terminates.\n\nThe BFS level sets are:\n$L_0 = \\{1\\}$\n$L_1 = \\{2, 4\\}$\n$L_2 = \\{3, 5, 7\\}$\n$L_3 = \\{6, 8\\}$\n$L_4 = \\{9\\}$\n\n**Task 3: Produce the Cuthill–McKee Vertex Ordering**\n\nWe now generate the ordering $r$ by performing a BFS starting from $s=1$. We use a queue $Q$ and a result list $R$. When adding neighbors of a dequeued vertex to the queue, they are sorted by nondecreasing degree, with ties broken by increasing vertex index.\n\n1.  Initialize: $R = \\emptyset$, $Q = \\emptyset$. Add start vertex $s=1$ to $Q$. $Q = (1)$.\n2.  Dequeue $1$. Add $1$ to $R$. $R = (1)$. Neighbors of $1$ are $\\{2, 4\\}$. Both are unvisited.\n    Their degrees are $\\text{deg}(2) = 4$ and $\\text{deg}(4) = 4$. There is a tie in degree. Break tie by vertex index: $2 < 4$. The sorted order is $(2, 4)$. Enqueue them. $Q = (2, 4)$.\n3.  Dequeue $2$. Add $2$ to $R$. $R = (1, 2)$. Unvisited neighbors of $2$ are $\\{3, 5\\}$.\n    Their degrees are $\\text{deg}(3) = 3$ and $\\text{deg}(5) = 6$. The sorted order is $(3, 5)$. Enqueue them. $Q = (4, 3, 5)$.\n4.  Dequeue $4$. Add $4$ to $R$. $R = (1, 2, 4)$. The only unvisited neighbor of $4$ is $\\{7\\}$.\n    Its degree is $\\text{deg}(7) = 3$. Enqueue it. $Q = (3, 5, 7)$.\n5.  Dequeue $3$. Add $3$ to $R$. $R = (1, 2, 4, 3)$. The only unvisited neighbor of $3$ is $\\{6\\}$.\n    Its degree is $\\text{deg}(6) = 4$. Enqueue it. $Q = (5, 7, 6)$.\n6.  Dequeue $5$. Add $5$ to $R$. $R = (1, 2, 4, 3, 5)$. The only unvisited neighbor of $5$ is $\\{8\\}$.\n    Its degree is $\\text{deg}(8) = 4$. Enqueue it. $Q = (7, 6, 8)$.\n7.  Dequeue $7$. Add $7$ to $R$. $R = (1, 2, 4, 3, 5, 7)$. Node $7$ has no unvisited neighbors. $Q = (6, 8)$.\n8.  Dequeue $6$. Add $6$ to $R$. $R = (1, 2, 4, 3, 5, 7, 6)$. The only unvisited neighbor of $6$ is $\\{9\\}$.\n    Its degree is $\\text{deg}(9) = 2$. Enqueue it. $Q = (8, 9)$.\n9.  Dequeue $8$. Add $8$ to $R$. $R = (1, 2, 4, 3, 5, 7, 6, 8)$. Node $8$ has no unvisited neighbors. $Q = (9)$.\n10. Dequeue $9$. Add $9$ to $R$. $R = (1, 2, 4, 3, 5, 7, 6, 8, 9)$. Node $9$ has no unvisited neighbors. $Q = ()$.\n\nThe queue is empty. The final CM ordering is $r = (1, 2, 4, 3, 5, 7, 6, 8, 9)$.\n\n**Task 4: Compute the Bandwidth of the Permuted Matrix**\n\nThe bandwidth $b$ is given by $b = \\max\\{|p(i) - p(j)| : K_{ij} \\neq 0\\}$, where $p(i)$ is the new position (from $1$ to $9$) of vertex $i$ in the ordering $r$.\nThe ordering $r$ gives us the permutation map $p$:\n- $p(1)=1$\n- $p(2)=2$\n- $p(4)=3$\n- $p(3)=4$\n- $p(5)=5$\n- $p(7)=6$\n- $p(6)=7$\n- $p(8)=8$\n- $p(9)=9$\n\nWe now compute the absolute difference in permuted positions for every edge $(i, j)$ in the graph:\n- Edge $(1,2)$: $|p(1)-p(2)| = |1-2| = 1$\n- Edge $(1,4)$: $|p(1)-p(4)| = |1-3| = 2$\n- Edge $(2,3)$: $|p(2)-p(3)| = |2-4| = 2$\n- Edge $(2,4)$: $|p(2)-p(4)| = |2-3| = 1$\n- Edge $(2,5)$: $|p(2)-p(5)| = |2-5| = 3$\n- Edge $(3,5)$: $|p(3)-p(5)| = |4-5| = 1$\n- Edge $(3,6)$: $|p(3)-p(6)| = |4-7| = 3$\n- Edge $(4,5)$: $|p(4)-p(5)| = |3-5| = 2$\n- Edge $(4,7)$: $|p(4)-p(7)| = |3-6| = 3$\n- Edge $(5,6)$: $|p(5)-p(6)| = |5-7| = 2$\n- Edge $(5,7)$: $|p(5)-p(7)| = |5-6| = 1$\n- Edge $(5,8)$: $|p(5)-p(8)| = |5-8| = 3$\n- Edge $(6,8)$: $|p(6)-p(8)| = |7-8| = 1$\n- Edge $(6,9)$: $|p(6)-p(9)| = |7-9| = 2$\n- Edge $(7,8)$: $|p(7)-p(8)| = |6-8| = 2$\n- Edge $(8,9)$: $|p(8)-p(9)| = |8-9| = 1$\n\nThe set of all position differences is $\\{1, 2, 3\\}$. The maximum value in this set is $3$.\nThus, the bandwidth $b$ of the matrix permuted according to the CM ordering is $3$.", "answer": "$$\n\\boxed{3}\n$$", "id": "2596891"}, {"introduction": "While direct solvers are effective for smaller systems, iterative methods are often essential for the large-scale problems common in FEM. This exercise delves into the foundational theory of classical stationary iterative methods, including the Jacobi, Gauss–Seidel, and Successive Over-Relaxation (SOR) techniques. By deriving their respective iteration matrices from first principles and analyzing the spectral radius condition for convergence, you will build a core understanding of how these algorithms incrementally approach the solution to $K u = f$ [@problem_id:2596855].", "problem": "A finite element method (FEM) discretization of a symmetric, coercive elliptic boundary value problem yields a linear system of the form $K u = f$, where $K \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite (SPD) and $f \\in \\mathbb{R}^{n}$. Stationary iterative methods for solving $K u = f$ can be constructed from a matrix splitting $K = M - N$, with $M$ nonsingular, leading to a fixed-point iteration of the form $u^{(k+1)} = M^{-1} N u^{(k)} + M^{-1} f$. The associated iteration matrix is $T = M^{-1} N$, and the method converges from any initial guess if and only if the spectral radius of $T$ is strictly less than one.\n\nUsing only these foundational facts and the canonical decomposition $K = D - L - U$, where $D$ is the diagonal part of $K$, $-L$ is the strictly lower triangular part of $K$, and $-U$ is the strictly upper triangular part of $K$, perform the following:\n\n- Derive, from first principles, the iteration matrices $T_{\\text{J}}$, $T_{\\text{GS}}$, and $T_{\\text{SOR}}$ corresponding to the Jacobi method, the Gauss–Seidel method, and the Successive Over-Relaxation (SOR) method, respectively.\n- State the convergence condition for each method in terms of the spectral radius and explain it in terms of the eigenvalues of the iteration matrix.\n\nFinally, consider the global stiffness matrix $K \\in \\mathbb{R}^{2 \\times 2}$ obtained by a standard linear FEM discretization on a uniform mesh with $2$ interior nodes for the model problem $-u'' = f$ on $[0,1]$ with homogeneous Dirichlet boundary conditions. This yields\n$$\nK = \\begin{pmatrix}\n2 & -1 \\\\\n-1 & 2\n\\end{pmatrix}.\n$$\nFor this $K$, explicitly compute the Gauss–Seidel iteration matrix $T_{\\text{GS}}$ and its spectral radius. Report, as your final answer, the spectral radius of $T_{\\text{GS}}$. No rounding is required.", "solution": "The problem statement is parsed and found to be valid. It is scientifically grounded, well-posed, and contains no ambiguities or contradictions. It presents a standard exercise in numerical linear algebra, specifically concerning the analysis of stationary iterative methods for linear systems arising from a finite element discretization. We shall proceed with the solution.\n\nThe problem requires the derivation of iteration matrices for several classical stationary methods, a discussion of their convergence, and a specific calculation for a given matrix $K$. The general form of the iteration is given by $u^{(k+1)} = T u^{(k)} + c$, where $T$ is the iteration matrix and $c = M^{-1} f$. The method converges if and only if the spectral radius of the iteration matrix, $\\rho(T)$, is strictly less than $1$. The spectral radius is defined as $\\rho(T) = \\max_i |\\lambda_i(T)|$, where $\\lambda_i(T)$ are the eigenvalues of $T$. We are given the linear system $K u = f$ and the canonical splitting of the matrix $K$ into its diagonal ($D$), strictly lower triangular ($-L$), and strictly upper triangular ($-U$) parts, such that $K = D - L - U$.\n\nFirst, we derive the iteration matrices $T_{\\text{J}}$, $T_{\\text{GS}}$, and $T_{\\text{SOR}}$. The iteration matrix $T$ is derived from a splitting of $K$ into $K = M - N$, where $M$ is nonsingular. The iteration is $M u^{(k+1)} = N u^{(k)} + f$, which is equivalent to $u^{(k+1)} = M^{-1} N u^{(k)} + M^{-1} f$. Thus, the iteration matrix is $T = M^{-1} N$. Since $N = M - K$, this can also be expressed as $T = M^{-1}(M - K) = I - M^{-1}K$.\n\nFor the Jacobi method, the splitting is chosen such that $M$ is the diagonal part of $K$.\n- Splitting: $M_{\\text{J}} = D$ and $N_{\\text{J}} = L + U$.\n- Iteration Matrix: $T_{\\text{J}} = M_{\\text{J}}^{-1} N_{\\text{J}} = D^{-1}(L + U)$.\nThe convergence condition for the Jacobi method is that the spectral radius of its iteration matrix is less than $1$: $\\rho(T_{\\text{J}}) < 1$. This means the eigenvalue of $T_{\\text{J}}$ with the largest magnitude must be strictly less than $1$.\n\nFor the Gauss-Seidel method, the splitting is chosen such that $M$ is the lower triangular part of $K$, including the diagonal.\n- Splitting: $M_{\\text{GS}} = D - L$ and $N_{\\text{GS}} = U$.\n- Iteration Matrix: $T_{\\text{GS}} = M_{\\text{GS}}^{-1} N_{\\text{GS}} = (D - L)^{-1} U$.\nThe convergence condition for the Gauss-Seidel method is $\\rho(T_{\\text{GS}}) < 1$, which requires the largest-magnitude eigenvalue of $(D-L)^{-1}U$ to be strictly less than $1$.\n\nFor the Successive Over-Relaxation (SOR) method, a relaxation parameter $\\omega$ is introduced. The iteration is constructed as a weighted average of the previous iterate and the Gauss-Seidel update. This leads to the splitting:\n- Splitting: $M_{\\text{SOR}} = \\frac{1}{\\omega}(D - \\omega L)$ and $N_{\\text{SOR}} = \\frac{1}{\\omega}((1-\\omega)D + \\omega U)$.\nTo verify this, we check $M_{\\text{SOR}} - N_{\\text{SOR}} = \\frac{1}{\\omega}(D - \\omega L) - \\frac{1}{\\omega}((1-\\omega)D + \\omega U) = \\frac{1}{\\omega}(D - \\omega L - D + \\omega D - \\omega U) = D - L - U = K$.\n- Iteration Matrix: $T_{\\text{SOR}} = M_{\\text{SOR}}^{-1} N_{\\text{SOR}} = \\left(\\frac{1}{\\omega}(D - \\omega L)\\right)^{-1} \\left(\\frac{1}{\\omega}((1-\\omega)D + \\omega U)\\right) = (D - \\omega L)^{-1}((1-\\omega)D + \\omega U)$.\nThe convergence condition for the SOR method is $\\rho(T_{\\text{SOR}}) < 1$, which depends on the choice of the relaxation parameter $\\omega$.\n\nNext, we address the specific case for the given matrix:\n$$\nK = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix}\n$$\nWe must first compute the Gauss-Seidel iteration matrix $T_{\\text{GS}}$ and its spectral radius. We decompose $K$ into $D$, $L$, and $U$.\n- The diagonal part is $D = \\begin{pmatrix} 2 & 0 \\\\ 0 & 2 \\end{pmatrix}$.\n- The strictly lower triangular part is $-L = \\begin{pmatrix} 0 & 0 \\\\ -1 & 0 \\end{pmatrix}$, which implies $L = \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix}$.\n- The strictly upper triangular part is $-U = \\begin{pmatrix} 0 & -1 \\\\ 0 & 0 \\end{pmatrix}$, which implies $U = \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix}$.\n\nThe Gauss-Seidel iteration matrix is $T_{\\text{GS}} = (D-L)^{-1}U$. First, we compute $D-L$:\n$$\nD - L = \\begin{pmatrix} 2 & 0 \\\\ 0 & 2 \\end{pmatrix} - \\begin{pmatrix} 0 & 0 \\\\ 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & 0 \\\\ -1 & 2 \\end{pmatrix}\n$$\nNext, we find the inverse of this matrix, $(D-L)^{-1}$. For a generic $2 \\times 2$ matrix $\\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}$, the inverse is $\\frac{1}{ad-bc}\\begin{pmatrix} d & -b \\\\ -c & a \\end{pmatrix}$.\nThe determinant of $D-L$ is $(2)(2) - (0)(-1) = 4$.\n$$\n(D - L)^{-1} = \\frac{1}{4} \\begin{pmatrix} 2 & 0 \\\\ 1 & 2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ \\frac{1}{4} & \\frac{1}{2} \\end{pmatrix}\n$$\nNow we compute $T_{\\text{GS}}$ by multiplying $(D-L)^{-1}$ by $U$:\n$$\nT_{\\text{GS}} = (D-L)^{-1}U = \\begin{pmatrix} \\frac{1}{2} & 0 \\\\ \\frac{1}{4} & \\frac{1}{2} \\end{pmatrix} \\begin{pmatrix} 0 & 1 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} (\\frac{1}{2})(0) + (0)(0) & (\\frac{1}{2})(1) + (0)(0) \\\\ (\\frac{1}{4})(0) + (\\frac{1}{2})(0) & (\\frac{1}{4})(1) + (\\frac{1}{2})(0) \\end{pmatrix} = \\begin{pmatrix} 0 & \\frac{1}{2} \\\\ 0 & \\frac{1}{4} \\end{pmatrix}\n$$\nFinally, we compute the spectral radius of $T_{\\text{GS}}$. We find the eigenvalues $\\lambda$ by solving the characteristic equation $\\det(T_{\\text{GS}} - \\lambda I) = 0$.\n$$\n\\det\\left(\\begin{pmatrix} 0 & \\frac{1}{2} \\\\ 0 & \\frac{1}{4} \\end{pmatrix} - \\begin{pmatrix} \\lambda & 0 \\\\ 0 & \\lambda \\end{pmatrix}\\right) = \\det\\begin{pmatrix} -\\lambda & \\frac{1}{2} \\\\ 0 & \\frac{1}{4} - \\lambda \\end{pmatrix} = 0\n$$\nThe determinant is $(-\\lambda)(\\frac{1}{4} - \\lambda) - (\\frac{1}{2})(0) = -\\lambda(\\frac{1}{4} - \\lambda) = 0$.\nThe eigenvalues are the roots of this equation: $\\lambda_1 = 0$ and $\\lambda_2 = \\frac{1}{4}$.\nThe spectral radius is the maximum of the absolute values of the eigenvalues:\n$$\n\\rho(T_{\\text{GS}}) = \\max(|\\lambda_1|, |\\lambda_2|) = \\max\\left(|0|, \\left|\\frac{1}{4}\\right|\\right) = \\max\\left(0, \\frac{1}{4}\\right) = \\frac{1}{4}\n$$\nThe spectral radius of the Gauss-Seidel iteration matrix for the given $K$ is $\\frac{1}{4}$.", "answer": "$$\n\\boxed{\\frac{1}{4}}\n$$", "id": "2596855"}, {"introduction": "In practice, an iterative solver must be terminated when the solution is 'good enough,' a decision typically based on the norm of the residual. However, our true goal is to reduce the error, not just the residual. This hands-on coding exercise challenges you to implement a damped Jacobi solver and quantitatively investigate the relationship between the commonly used residual-based stopping criterion and the actual reduction in the solution's error, measured in the physically significant energy norm [@problem_id:2596884].", "problem": "You are given a symmetric positive definite global stiffness matrix $A \\in \\mathbb{R}^{n \\times n}$ arising from a one-dimensional uniform mesh of linear finite elements on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions. The stiffness matrix is the standard tridiagonal form with diagonal entries $2/h$ and off-diagonal entries $-1/h$, where $h = 1/(n+1)$. Consider the linear system $A x = b$.\n\nYou must implement a stationary iteration of damped Jacobi type defined by the diagonal splitting $A = D + R$, where $D = \\mathrm{diag}(A)$, and the iteration\n$x^{k+1} = x^{k} + \\omega D^{-1} (b - A x^{k})$\nfor a given relaxation parameter $\\omega \\in (0,1]$, starting from $x^{0} = 0$.\n\nDefine the residual $r^{k} = b - A x^{k}$ and the error $e^{k} = x^{\\star} - x^{k}$, where $x^{\\star}$ is the exact solution of the linear system. The energy norm of the error is $\\|e^{k}\\|_{A} = \\sqrt{(e^{k})^{\\top} A e^{k}}$, and the Euclidean norm of the residual is $\\|r^{k}\\|_{2} = \\sqrt{(r^{k})^{\\top} r^{k}}$.\n\nYour task is to:\n- Implement a stopping criterion based on the relative decrease of the residual norm: stop at the first iteration index $k$ such that $\\|r^{k}\\|_{2} / \\|r^{0}\\|_{2} \\le \\tau$, where $\\tau \\in (0,1]$ is a prescribed threshold. If the criterion is satisfied at $k = 0$, the iteration terminates immediately.\n- Quantitatively assess how this residual-based stopping criterion relates to the actual error in the energy norm by computing, at termination, the ratio\n$Q = \\dfrac{\\|e^{k}\\|_{A} / \\|e^{0}\\|_{A}}{\\|r^{k}\\|_{2} / \\|r^{0}\\|_{2}}$.\nThis scalar $Q$ compares the realized relative decrease of the error in the energy norm to the enforced relative decrease of the residual in the Euclidean norm.\n\nTo make the exact solution $x^{\\star}$ available without numerical round-off from solving the system, use a manufactured solution. Let $u_{i}^{\\star} = \\sin(\\pi i h)$ for $i = 1, 2, \\dots, n$ with $h = 1/(n+1)$, and define $b = A u^{\\star}$. With the initial guess $x^{0} = 0$, both $e^{0}$ and $r^{0}$ are nonzero vectors.\n\nImplement the above for the following test suite of parameter values $(n,\\omega,\\tau)$:\n- Test $1$: $n = 20$, $\\omega = 2/3$, $\\tau = 10^{-6}$.\n- Test $2$: $n = 5$, $\\omega = 1$, $\\tau = 10^{-2}$.\n- Test $3$: $n = 50$, $\\omega = 1/2$, $\\tau = 10^{-4}$.\n- Test $4$ (edge case): $n = 30$, $\\omega = 1$, $\\tau = 1$.\n\nYour program must:\n- Construct $A$ for each $n$, construct $u^{\\star}$, set $b = A u^{\\star}$, and run the damped Jacobi iteration with the stopping rule described above. Use a sufficiently large cap on the number of iterations to avoid infinite loops.\n- For each test, produce the scalar $Q$ at the termination iteration.\n- Output a single line containing a list of the four $Q$ values, in order of Tests $1$ to $4$, as a comma-separated list enclosed in square brackets, for example $[\\dots]$.\n\nNo physical units or angle units are required in this problem. The final outputs for each test are real numbers, and the program must aggregate them into a single line: a list in the form $[q_{1},q_{2},q_{3},q_{4}]$ with each $q_{j}$ equal to the value of $Q$ for Test $j$.", "solution": "The problem statement has been subjected to rigorous validation and is found to be scientifically grounded, well-posed, and complete. It describes a standard numerical experiment for analyzing the convergence properties of an iterative solver, the damped Jacobi method, on a model problem derived from the finite element method. The use of a manufactured solution, where the initial error aligns with an eigenvector of the system matrix, is a valid and insightful technique for analyzing convergence behavior. We shall proceed with a formal solution.\n\nThe problem requires the implementation of a damped Jacobi iteration for the linear system $A x = b$, where $A \\in \\mathbb{R}^{n \\times n}$ is the stiffness matrix for a $1$-dimensional finite element problem on a uniform mesh. The matrix $A$ is tridiagonal with entries $A_{ii} = 2/h$ and $A_{i,i\\pm 1} = -1/h$, where $h = 1/(n+1)$. The system is defined such that the exact solution $x^{\\star}$ is a known vector $u^{\\star}$ with components $u_{i}^{\\star} = \\sin(\\pi i h)$. The right-hand side is therefore manufactured as $b = A u^{\\star}$.\n\nThe damped Jacobi iteration is given by\n$$ x^{k+1} = x^{k} + \\omega D^{-1} (b - A x^{k}) $$\nwhere $x^0=0$, $D = \\mathrm{diag}(A)$ is the diagonal part of $A$, and $\\omega \\in (0,1]$ is a relaxation parameter. Since all diagonal entries of $A$ are $2/h$, $D$ is the scalar matrix $D = (2/h)I$, where $I$ is the identity matrix. Its inverse is $D^{-1} = (h/2)I$. The iteration can be expressed in terms of the residual $r^k = b - A x^k$ as:\n$$ x^{k+1} = x^{k} + \\omega \\frac{h}{2} r^{k} $$\n\nA key insight arises from analyzing the error propagation. The error at step $k$ is $e^k = x^{\\star} - x^k$. The error propagation formula is derived as follows:\n$$ e^{k+1} = x^{\\star} - x^{k+1} = x^{\\star} - (x^k + \\omega D^{-1}(b - A x^k)) = (x^{\\star} - x^k) - \\omega D^{-1}(A x^{\\star} - A x^k) $$\n$$ e^{k+1} = e^k - \\omega D^{-1} A e^k = (I - \\omega D^{-1} A) e^k $$\nThe matrix $M = I - \\omega D^{-1} A$ is the iteration matrix.\n\nThe initial guess is $x^0 = 0$, so the initial error is $e^0 = x^{\\star} - 0 = u^{\\star}$. The vector $u^{\\star}$ with components $u_i^{\\star} = \\sin(\\pi i h) = \\sin\\left(\\frac{i\\pi}{n+1}\\right)$ is a discrete sine function. It is a known property of the given matrix $A$ that such vectors are its eigenvectors. Specifically, $u^{\\star}$ is the eigenvector corresponding to the smallest eigenvalue of $A$, which we denote $\\lambda_1$.\nThus, $A u^{\\star} = \\lambda_1 u^{\\star}$.\n\nSince $e^0 = u^{\\star}$ is an eigenvector of $A$, it is also an eigenvector of $D^{-1}A$ and consequently of the iteration matrix $M$:\n$$ M e^0 = (I - \\omega D^{-1} A) e^0 = e^0 - \\omega D^{-1} (A e^0) = e^0 - \\omega D^{-1} (\\lambda_1 e^0) $$\nAs $D^{-1} = (h/2)I$, we have $D^{-1}e^0 = (h/2)e^0$.\n$$ M e^0 = (1 - \\omega (h/2) \\lambda_1) e^0 $$\nThis shows that $e^0$ is an eigenvector of $M$ with eigenvalue $\\mu_1 = 1 - \\omega (h/2) \\lambda_1$.\nThe error at any subsequent step is given by $e^k = M^k e^0 = \\mu_1^k e^0$. This means that in exact arithmetic, the error vector $e^k$ at every iteration remains in the direction of the initial error $e^0$.\n\nThe problem asks for the quantity $Q$ at the termination iteration $k$:\n$$ Q = \\dfrac{\\|e^{k}\\|_{A} / \\|e^{0}\\|_{A}}{\\|r^{k}\\|_{2} / \\|r^{0}\\|_{2}} $$\nwhere $\\|v\\|_A = \\sqrt{v^\\top A v}$ and $\\|v\\|_2$ is the Euclidean norm.\nLet us analyze the numerator and denominator separately.\nThe relationship $r^k = A e^k$ holds for all $k$. For our specific case, $e^k = \\mu_1^k e^0$.\nNumerator:\n$$ \\frac{\\|e^k\\|_A}{\\|e^0\\|_A} = \\frac{\\sqrt{(e^k)^\\top A e^k}}{\\sqrt{(e^0)^\\top A e^0}} = \\frac{\\sqrt{(\\mu_1^k e^0)^\\top A (\\mu_1^k e^0)}}{\\|e^0\\|_A} = \\frac{|\\mu_1^k| \\sqrt{(e^0)^\\top A e^0}}{\\|e^0\\|_A} = |\\mu_1^k| $$\nDenominator:\n$$ \\frac{\\|r^k\\|_2}{\\|r^0\\|_2} = \\frac{\\|A e^k\\|_2}{\\|A e^0\\|_2} = \\frac{\\|A (\\mu_1^k e^0)\\|_2}{\\|A e^0\\|_2} = \\frac{\\|\\mu_1^k (A e^0)\\|_2}{\\|A e^0\\|_2} = \\frac{|\\mu_1^k| \\|A e^0\\|_2}{\\|A e^0\\|_2} = |\\mu_1^k| $$\nTherefore, in exact arithmetic, $Q = |\\mu_1^k| / |\\mu_1^k| = 1$. This holds for any termination iteration $k > 0$. For the edge case $k=0$ (as in Test 4 where $\\tau=1$), the ratios are trivially $\\|e^0\\|_A / \\|e^0\\|_A = 1$ and $\\|r^0\\|_2 / \\|r^0\\|_2 = 1$, so $Q=1$.\n\nThe task is to perform a numerical simulation. The computed value of $Q$ will be a quantitative assessment of how this theoretical identity holds in finite-precision arithmetic, where rounding errors may introduce components from other eigenspaces into the error vector over many iterations.\n\nThe algorithm for each test case $(n, \\omega, \\tau)$ is as follows:\n$1$. Construct matrix $A \\in \\mathbb{R}^{n \\times n}$ and the vector $u^{\\star} \\in \\mathbb{R}^n$.\n$2$. Compute $b = A u^{\\star}$.\n$3$. Initialize $k=0$ and $x^0=0$.\n$4$. Compute initial error $e^0 = u^{\\star}$ and initial residual $r^0 = b$. Calculate their norms $\\|e^0\\|_A$ and $\\|r^0\\|_2$.\n$5$. Check the stopping criterion: $\\|r^k\\|_2 / \\|r^0\\|_2 \\le \\tau$. If satisfied, terminate at $k$.\n$6$. If not satisfied, enter the iteration loop. For each subsequent step, update the solution vector $x^{k+1} = x^k + \\omega(h/2)r^k$, compute the new residual $r^{k+1} = b - A x^{k+1}$, and check the stopping criterion.\n$7. A maximum iteration count is used to prevent infinite execution.\n$8$. Upon termination at iteration $k$, compute the final error $e^k = u^{\\star} - x^k$, its A-norm $\\|e^k\\|_A$, and the L2-norm of the final residual $\\|r^k\\|_2$.\n$9$. Calculate the final quantity $Q$.\nThis procedure will be implemented for each of the four test cases specified.", "answer": "[1.0, 1.0, 1.0, 1.0]", "id": "2596884"}]}