{"hands_on_practices": [{"introduction": "This practice builds your foundational understanding of stress singularities by deriving their mathematical form from first principles. You will analyze the anti-plane shear problem for a classic L-shaped domain, a canonical case for a re-entrant corner singularity. Completing this exercise will clarify how the geometry dictates the singular exponent and why the solution, despite its singular nature, possesses finite strain energy, a condition for membership in the $H^1$ Sobolev space which underpins the finite element method. [@problem_id:2602467]", "id": "2602467", "problem": "Consider anti-plane shear in a two-dimensional L-shaped elastic domain with a single re-entrant corner at the origin. In a sufficiently small neighborhood of the corner, introduce polar coordinates $\\left(r,\\theta\\right)$ centered at the corner so that the domain locally coincides with a wedge $\\left\\{(r,\\theta): r>0,\\ 0<\\theta<\\omega\\right\\}$ of interior angle $\\omega = \\frac{3\\pi}{2}$ radians. Assume no body forces and assume the two wedge faces $\\theta=0$ and $\\theta=\\omega$ are traction-free. Let the out-of-plane displacement be $w(r,\\theta)$, which satisfies the equilibrium equations of linear elasticity for anti-plane shear.\n\n1. Starting from first principles for anti-plane shear, derive the local leading-order singular behavior near the corner by seeking a separated form $w_{\\text{sing}}(r,\\theta)=r^{\\lambda} f(\\theta)$ and imposing the governing partial differential equation and boundary conditions. Use this to obtain the characteristic equation that determines the admissible exponents $\\lambda$ and compute the smallest positive exponent.\n\n2. Using the value of the smallest positive exponent, reason about the local integrability of the strain energy density and state the implication for membership of $w$ in the Sobolev space $H^{1}$ in a neighborhood of the corner.\n\nGive as your final answer only the exact value of the dominant singular exponent $\\lambda$ (no units, no rounding). Any discussion about $H^{1}$-regularity should be included in your solution, not in the final answer.", "solution": "In anti-plane shear, the displacement has the form $u_{x}=0$, $u_{y}=0$, $u_{z}=w(x,y)$, and the only nonzero Cauchy stress components are the shear stresses $\\tau_{xz}$ and $\\tau_{yz}$. For a homogeneous, isotropic, linear elastic material with shear modulus $G$, the constitutive relations give $\\tau_{xz}=G\\,\\partial w/\\partial x$ and $\\tau_{yz}=G\\,\\partial w/\\partial y$. Static equilibrium in the absence of body forces requires $\\nabla\\cdot\\boldsymbol{\\sigma}=\\boldsymbol{0}$, which reduces to\n$$\n\\frac{\\partial \\tau_{xz}}{\\partial x}+\\frac{\\partial \\tau_{yz}}{\\partial y}=0.\n$$\nSubstituting the constitutive relations and using the fact that $G$ is constant yields the Laplace equation for the out-of-plane displacement:\n$$\n\\Delta w=0.\n$$\nIn polar coordinates $\\left(r,\\theta\\right)$, the Laplacian becomes\n$$\n\\Delta w=\\frac{\\partial^{2}w}{\\partial r^{2}}+\\frac{1}{r}\\frac{\\partial w}{\\partial r}+\\frac{1}{r^{2}}\\frac{\\partial^{2}w}{\\partial \\theta^{2}}.\n$$\nThe traction-free boundary condition on the wedge faces $\\theta=0$ and $\\theta=\\omega$ implies vanishing normal shear stress there. For anti-plane shear, the traction-free condition on a ray $\\theta=\\text{const}$ reduces locally to\n$$\n\\frac{\\partial w}{\\partial n}=0\\quad\\Longleftrightarrow\\quad \\frac{1}{r}\\frac{\\partial w}{\\partial \\theta}=0\\quad\\text{on}\\ \\theta=0,\\ \\theta=\\omega.\n$$\nHence the boundary conditions become\n$$\n\\frac{\\partial w}{\\partial \\theta}(r,0)=0,\\qquad \\frac{\\partial w}{\\partial \\theta}(r,\\omega)=0,\\qquad r>0.\n$$\nWe seek a leading-order singular term of the form\n$$\nw_{\\text{sing}}(r,\\theta)=r^{\\lambda}f(\\theta),\\quad \\lambda>0.\n$$\nSubstituting into the Laplace equation gives\n\\begin{align*}\n\\frac{\\partial w}{\\partial r}&=\\lambda r^{\\lambda-1}f(\\theta),\\\\\n\\frac{\\partial^{2}w}{\\partial r^{2}}&=\\lambda(\\lambda-1)r^{\\lambda-2}f(\\theta),\\\\\n\\frac{\\partial^{2}w}{\\partial \\theta^{2}}&=r^{\\lambda}f''(\\theta).\n\\end{align*}\nThus\n$$\n\\Delta w_{\\text{sing}}=r^{\\lambda-2}\\left[\\lambda(\\lambda-1)f(\\theta)+\\lambda f(\\theta)+f''(\\theta)\\right]=r^{\\lambda-2}\\left[f''(\\theta)+\\lambda^{2}f(\\theta)\\right]=0,\n$$\nso $f$ satisfies the ordinary differential equation\n$$\nf''(\\theta)+\\lambda^{2}f(\\theta)=0.\n$$\nThe general solution is\n$$\nf(\\theta)=A\\cos(\\lambda \\theta)+B\\sin(\\lambda \\theta).\n$$\nThe traction-free boundary conditions translate to\n$$\n\\frac{\\partial w_{\\text{sing}}}{\\partial \\theta}(r,\\theta)=r^{\\lambda}f'(\\theta)=0\\quad \\text{at}\\ \\theta=0,\\ \\theta=\\omega.\n$$\nCompute $f'(\\theta)=-A\\lambda \\sin(\\lambda \\theta)+B\\lambda \\cos(\\lambda \\theta)$. Imposing $f'(0)=0$ yields\n$$\nf'(0)=B\\lambda=0\\quad\\Longrightarrow\\quad B=0.\n$$\nThen $f'(\\omega)=-A\\lambda \\sin(\\lambda \\omega)=0$. For a nontrivial angular shape $A\\neq 0$, this implies the characteristic equation\n$$\n\\sin(\\lambda \\omega)=0\\quad\\Longleftrightarrow\\quad \\lambda \\omega = m\\pi,\\quad m\\in \\mathbb{N}.\n$$\nTherefore, the admissible singular exponents are\n$$\n\\lambda_{m}=\\frac{m\\pi}{\\omega},\\quad m=1,2,\\dots\n$$\nThe dominant singular exponent is the smallest positive one:\n$$\n\\lambda=\\frac{\\pi}{\\omega}.\n$$\nFor the given re-entrant angle $\\omega=\\frac{3\\pi}{2}$,\n$$\n\\lambda=\\frac{\\pi}{\\frac{3\\pi}{2}}=\\frac{2}{3}.\n$$\n\nTo discuss the implication for $H^{1}$-regularity, note that the stress components are proportional to the gradient of $w$, and the gradient magnitude associated with the singular term behaves as\n$$\n|\\nabla w_{\\text{sing}}|\\sim r^{\\lambda-1}\\quad\\text{as}\\ r\\to 0.\n$$\nThe local strain energy density is proportional to $|\\nabla w|^{2}$, so the energy near the corner (up to a constant factor) scales like\n$$\n\\int_{0}^{\\varepsilon}\\int_{0}^{\\omega}|\\nabla w_{\\text{sing}}|^{2}\\, r\\, d\\theta\\, dr\\ \\sim\\ \\int_{0}^{\\varepsilon}\\int_{0}^{\\omega} r^{2(\\lambda-1)}\\, r\\, d\\theta\\, dr\\ =\\ \\omega\\int_{0}^{\\varepsilon} r^{2\\lambda-1}\\, dr.\n$$\nThis integral converges at $r=0$ if and only if $2\\lambda-1>-1$, i.e., $\\lambda>0$. Since $\\lambda=\\frac{2}{3}>0$, the energy is finite and the displacement $w$ belongs to $H^{1}$ locally around the corner. However, because $\\lambda<1$, the stress $|\\nabla w|$ is unbounded like $r^{-1/3}$ as $r\\to 0$, which precludes higher regularity such as $H^{2}$ in a neighborhood of the corner. From the finite element method perspective, the finite energy implies well-posedness in the $H^{1}$ framework, but the stress singularity necessitates mesh refinement or enrichment to accurately compute stresses near the corner.", "answer": "$$\\boxed{\\frac{2}{3}}$$"}, {"introduction": "Building an accurate computational model requires choosing the right tools for the job, especially when singularities are present. This exercise challenges you to critically evaluate several popular techniques in the finite element toolkit, from specialized quarter-point elements to advanced enrichment strategies like the Extended Finite Element Method (XFEM). By analyzing the strengths and weaknesses of each method, you will develop the critical judgment needed to select an appropriate numerical approach for different types of singular problems. [@problem_id:2602499]", "id": "2602499", "problem": "Consider a two-dimensional ($2$D) linear elastic body containing a sharp singular point at polar radius $r = 0$ (e.g., a crack tip or a re-entrant corner). Near the singularity, the exact displacement field $u(r,\\theta)$ is known to be non-smooth and may exhibit either an algebraic singularity with an exponent $\\lambda \\neq 1/2$ (e.g., a wedge corner), or an oscillatory behavior with a logarithmic modulation (e.g., a bimaterial interface crack), leading to stress fields that are unbounded as $r \\to 0$ but remain square-integrable in the strain energy norm under standard assumptions of linear elasticity and material stability. A common finite element method remedy is to use isoparametric singular elements with mid-side nodes shifted to the quarter-point to induce a $1/\\sqrt{r}$-type strain singularity in the approximation.\n\nUsing only the fundamental variational formulation of linear elasticity (weak form derived from the principle of minimum potential energy), the definition of isoparametric mappings, and approximation properties of polynomial shape functions, analyze whether quarter-point elements are consistent for the above classes of singularities and what modifications or alternatives are appropriate if they are not. Select all statements that are correct.\n\nA. Quarter-point elements are asymptotically optimal for any algebraic singularity exponent $\\lambda \\in (0,1)$ because the isoparametric mapping automatically produces the exact stress blow-up rate, independent of $\\lambda$.\n\nB. If the singularity exponent satisfies $\\lambda \\neq 1/2$, then quarter-point elements are inconsistent with the exact local behavior and may induce pollution errors and spurious oscillations; using a generalized singular mapping with a tunable exponent (e.g., shifting nodes to positions other than the quarter-point to enforce $r \\sim \\xi^{1/\\lambda}$) or a tailored singular element restores optimal convergence provided $\\lambda$ is known or can be estimated.\n\nC. For bimaterial interface cracks, the leading singular fields are oscillatory with logarithmic modulation in $r$, which quarter-point elements cannot represent; adding enrichment functions that contain the oscillatory tip behavior via a partition-of-unity framework, such as the extended finite element method (XFEM), is an effective alternative.\n\nD. Uniform $p$-refinement with standard polynomial bases (without mesh grading, singular mappings, or enrichment) always eliminates the need for special treatments near singularities because sufficiently high polynomial degree can approximate any local behavior to optimal accuracy.\n\nE. Geometrically graded meshes with element sizes decreasing like $h_k \\sim q^k$, where $0<q<1$, can recover optimal algebraic convergence in the energy norm for non-oscillatory algebraic singularities even with standard elements; however, such grading alone does not capture oscillatory logarithmic features, which require suitable enrichment or tailored singular functions in addition to grading.", "solution": "The problem statement is subjected to validation.\n\n**Step 1: Extract Givens**\n- The system is a two-dimensional ($2$D) linear elastic body.\n- A singularity exists at the origin of a polar coordinate system ($r=0$).\n- Two classes of singularities are considered:\n    1. An algebraic singularity with an exponent $\\lambda \\neq 1/2$.\n    2. An oscillatory singularity with logarithmic modulation, characteristic of bimaterial interface cracks.\n- The stress fields are unbounded as $r \\to 0$ but remain square-integrable in the strain energy norm.\n- A proposed finite element method (FEM) technique is the use of isoparametric singular elements with mid-side nodes shifted to the quarter-point.\n- The effect of this technique is stated to be the induction of a $1/\\sqrt{r}$-type strain singularity.\n- The task is to analyze the consistency of quarter-point elements for these singularities and evaluate alternatives based on the variational formulation, isoparametric mapping, and polynomial approximation theory.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem statement is scientifically sound and well-posed.\n- **Scientific Groundedness:** The problem is constructed from canonical concepts in computational solid mechanics and the finite element method. The description of singularities (algebraic for corners, oscillatory for bimaterial cracks), the properties of the stress fields, and the methods for their treatment (quarter-point elements, enrichment, mesh grading) are all standard and factual elements of the discipline.\n- **Well-Posedness and Objectivity:** The problem is structured as a conceptual analysis task, requiring the evaluation of several technical statements against established theory. The terminology is precise and objective. The question is answerable and does not suffer from ambiguity. It provides sufficient information to proceed with a rigorous analysis.\n- **Flaw Checklist:** The problem statement does not violate any criteria for invalidity. It is not based on false premises, is formalizable, is complete, and poses a meaningful, non-trivial question in computational engineering.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A full analysis will be performed.\n\n**Derivation of Principles**\n\nThe foundation of the analysis is the principle of minimum potential energy, which leads to the weak (variational) form of the linear elasticity problem. The goal is to find a displacement field $u$ from a suitable Sobolov space, typically $H^1(\\Omega)$, that satisfies the variational equation. The convergence of the finite element approximation $u_h$ to the exact solution $u$ depends critically on the regularity of $u$.\n\nNear a singular point at $r=0$, the exact displacement field admits an asymptotic expansion of the form:\n$$ u(r, \\theta) = u_{regular}(r, \\theta) + \\sum_{i=1}^{\\infty} K_i r^{\\lambda_i} f_i(\\theta) $$\nwhere $u_{regular}$ is a smooth function, $K_i$ are generalized stress intensity factors, and $\\lambda_i>0$ are singularity exponents with associated angular functions $f_i(\\theta)$. The strain tensor $\\boldsymbol{\\varepsilon}$, being the symmetric gradient of $u$, behaves as $\\boldsymbol{\\varepsilon} \\sim r^{\\lambda_{min}-1}$, where $\\lambda_{min}$ is the smallest positive exponent. For a finite energy norm ($||\\boldsymbol{\\varepsilon}||_{L^2} < \\infty$), we must have $\\lambda_{min} > 0$.\n\nFor a crack in a homogeneous, isotropic material, $\\lambda_{min} = 1/2$. For a re-entrant corner (wedge problem), $\\lambda_{min}$ is a function of the corner angle and boundary conditions, and generally $\\lambda_{min} \\neq 1/2$. For a crack at a bimaterial interface, the exponents are complex, $\\lambda_{min} = 1/2 \\pm i\\epsilon$, leading to an oscillatory singularity in stresses of the form $\\sigma \\sim r^{-1/2} \\cos(\\epsilon \\ln r)$.\n\nThe standard quarter-point element is an isoparametric quadratic element where the mid-side node is moved from the half-way point to the quarter-way point closest to the singularity. For a one-dimensional element of length $L$ with nodes at $x=0$, $x=L/4$, and $x=L$, the mapping from the parent coordinate $\\xi \\in [-1, 1]$ to the physical coordinate $x$ (with $x=0$ at $\\xi=-1$) is:\n$$ x(\\xi) = N_1(\\xi) \\cdot 0 + N_2(\\xi) \\cdot \\frac{L}{4} + N_3(\\xi) \\cdot L $$\nwhere $N_1$, $N_2$, $N_3$ are the standard quadratic shape functions. This simplifies to:\n$$ x(\\xi) = (1-\\xi^2)\\frac{L}{4} + \\frac{1}{2}\\xi(1+\\xi)L = \\frac{L}{4}(1+\\xi)^2 $$\nLetting $r=x$ be the distance from the singularity, we find the relationship $r \\propto (1+\\xi)^2$, which implies $(1+\\xi) \\propto \\sqrt{r}$. Since the displacement approximation $u_h$ on the element is a quadratic polynomial in $\\xi$, it can be written as a polynomial in $(1+\\xi)$: $u_h(\\xi) = A_0 + A_1(1+\\xi) + A_2(1+\\xi)^2$. Substituting the relation for $r$, the displacement approximation in physical coordinates is:\n$$ u_h(r) = A_0 + A_1' \\sqrt{r} + A_2' r $$\nThe corresponding strain approximation is $\\epsilon_h(r) = \\frac{du_h}{dr} = \\frac{A_1'}{2\\sqrt{r}} + A_2'$. This mapping thus hard-codes a strain singularity of type $r^{-1/2}$, which corresponds precisely to the case where $\\lambda = 1/2$.\n\n**Option-by-Option Analysis**\n\nA. Quarter-point elements are asymptotically optimal for any algebraic singularity exponent $\\lambda \\in (0,1)$ because the isoparametric mapping automatically produces the exact stress blow-up rate, independent of $\\lambda$.\n\nThis statement is patently false. As derived above, the quarter-point element is specifically constructed to produce an $r^{-1/2}$ strain singularity, which corresponds to $\\lambda=1/2$. It does not \"automatically\" adapt to any other exponent $\\lambda$. If the true singularity exponent is $\\lambda \\neq 1/2$, the quarter-point element imposes an incorrect singular behavior on the approximation, leading to a suboptimal representation of the solution field and a loss of accuracy. The method is correct for one specific exponent, not independent of it.\nVerdict: **Incorrect**.\n\nB. If the singularity exponent satisfies $\\lambda \\neq 1/2$, then quarter-point elements are inconsistent with the exact local behavior and may induce pollution errors and spurious oscillations; using a generalized singular mapping with a tunable exponent (e.g., shifting nodes to positions other than the quarter-point to enforce $r \\sim \\xi^{1/\\lambda}$) or a tailored singular element restores optimal convergence provided $\\lambda$ is known or can be estimated.\n\nThis statement is correct. The first part correctly identifies that using a quarter-point element for a problem with $\\lambda \\neq 1/2$ is inconsistent with the physics and leads to pollution error, which degrades the solution quality globally. The second part presents the correct remedy. To match a singularity of type $r^{\\lambda}$, one can construct a special mapping where $r \\propto (1+\\xi)^{1/\\lambda}$. This can be achieved by placing the mid-side node at a specific position that depends on $\\lambda$, or more generally, by constructing specialized singular elements whose shape functions explicitly contain the $r^{\\lambda}$ term. If the leading singular behavior is correctly embedded in the finite element basis, the solution becomes \"smoother\" in the eyes of the approximant, and the optimal convergence rate of the finite element method can be restored.\nVerdict: **Correct**.\n\nC. For bimaterial interface cracks, the leading singular fields are oscillatory with logarithmic modulation in $r$, which quarter-point elements cannot represent; adding enrichment functions that contain the oscillatory tip behavior via a partition-of-unity framework, such as the extended finite element method (XFEM), is an effective alternative.\n\nThis statement is correct. The displacement field near a bimaterial crack tip involves terms like $\\sqrt{r}\\cos(\\epsilon \\ln r)$ and $\\sqrt{r}\\sin(\\epsilon \\ln r)$. A quarter-point element's approximation basis consists of polynomials in $\\sqrt{r}$, which are non-oscillatory and fundamentally incapable of representing the infinitely rapid oscillations of the logarithmic terms as $r \\to 0$. The stated alternative, XFEM, resolves this by using a partition of unity to multiply the standard polynomial basis by these known oscillatory functions. This enriches the approximation space, allowing it to accurately capture the true asymptotic behavior without requiring an impractically fine mesh. This is the state-of-the-art method for such problems.\nVerdict: **Correct**.\n\nD. Uniform $p$-refinement with standard polynomial bases (without mesh grading, singular mappings, or enrichment) always eliminates the need for special treatments near singularities because sufficiently high polynomial degree can approximate any local behavior to optimal accuracy.\n\nThis statement is incorrect. While the $p$-version of FEM is very powerful, it does not \"eliminate the need for special treatments\" for singularities when applied uniformly. For a solution with regularity $u \\in H^{1+\\lambda}$, the convergence rate of uniform $p$-refinement is algebraic, typically $\\|u-u_h\\|_{E} \\le C p^{-2\\lambda}$. This is suboptimal compared to the exponential convergence rate, $\\|u-u_h\\|_{E} \\le C e^{-\\gamma p}$, that the $p$-method achieves for smooth ($C^\\infty$) solutions. The singularity pollutes the approximation and prevents the method from reaching its full potential. To recover exponential convergence rates with $p$-FEM, one must use a geometric mesh refinement towards the singularity. The claim that uniform refinement is sufficient is a common misconception.\nVerdict: **Incorrect**.\n\nE. Geometrically graded meshes with element sizes decreasing like $h_k \\sim q^k$, where $0<q<1$, can recover optimal algebraic convergence in the energy norm for non-oscillatory algebraic singularities even with standard elements; however, such grading alone does not capture oscillatory logarithmic features, which require suitable enrichment or tailored singular functions in addition to grading.\n\nThis statement is correct and presents a nuanced view. It is a classic result from the theory of $h$-version FEM that for non-oscillatory singularities (e.g., $r^\\lambda$), a geometric mesh grading towards the singular point allows standard polynomial elements to achieve the optimal algebraic rate of convergence, i.e., $\\|u-u_h\\|_{E} \\le C h^{p}$, where $p$ is the polynomial degree and $h$ is the characteristic size of the largest elements. The second part of the statement is also correct. While grading the mesh helps localize and control the error from the singularity, the standard polynomial shape functions on these small elements are still ill-suited to approximate the highly oscillatory nature of a function like $\\cos(\\epsilon \\ln r)$. To capture this behavior correctly, the basis functions themselves must contain this oscillatory component, which is precisely what enrichment methods (as in option C) provide. Therefore, grading alone is insufficient for oscillatory singularities.\nVerdict: **Correct**.", "answer": "$$\\boxed{BCE}$$"}, {"introduction": "Finite element analysis is not just for forward prediction; it is also a powerful tool for inverse analysis, where numerical data is used to infer underlying physical parameters. This hands-on coding practice guides you through the process of estimating the strength of a singularity directly from a series of simulation results. Mastering this technique allows you to use FEA as a virtual experiment to characterize complex mechanical behavior from convergence studies. [@problem_id:2602428]", "id": "2602428", "problem": "Consider a two-dimensional scalar elliptic boundary value problem modeled by the Poisson equation on a polygonal domain with a single re-entrant corner of interior angle greater than $\\pi$. Classical regularity theory implies that the exact solution exhibits a singularity of the form $u(r,\\theta) \\sim r^{\\lambda}\\phi(\\theta)$ near the corner, where $r$ is the distance to the corner and $\\lambda \\in (0,1)$ is the corner exponent determined by the geometry and boundary conditions. In the Finite Element (FE, Finite Element) method with continuous piecewise polynomial shape functions of polynomial degree $p$, the energy norm error is governed by this singularity. On geometrically graded meshes toward the corner with grading exponent $\\beta > 0$ (meaning that the effective resolution near the corner scales faster than uniform refinement), well-tested a priori error estimates state that the energy norm error behaves as\n$$\n\\| \\nabla(u - u_h) \\|_{L^2(\\Omega)} \\approx C\\, h^{\\alpha}, \\quad \\alpha = \\min(p, \\beta \\lambda),\n$$\nfor sufficiently small characteristic mesh size $h$ near the corner and some mesh-independent constant $C>0$. For linear elements, $p = 1$. The target is to estimate the unknown corner exponent $\\lambda$ from a sequence of measured energy norm errors on successively refined graded meshes.\n\nTask. Design and implement a robust numerical procedure that, given:\n- a sequence of characteristic mesh sizes $h_k$ near the corner,\n- the corresponding measured energy norm errors $e_k \\approx \\| \\nabla(u - u_h) \\|_{L^2(\\Omega)}$,\n- the known mesh grading exponent $\\beta$,\nreturns an estimate $\\widehat{\\lambda}$ of the corner exponent. Your method must:\n1) Start from the fundamental model $e_k \\approx C\\, h_k^{\\alpha}$ with $\\alpha = \\min(1, \\beta \\lambda)$ for linear elements ($p = 1$),\n2) Transform to logarithmic coordinates to identify the convergence rate $\\alpha$ as the slope in the linear relation $\\log(e_k) \\approx \\log C + \\alpha \\log(h_k)$,\n3) Use a statistically reasonable and numerically robust strategy to mitigate pre-asymptotic contamination and mild noise. Specifically, among all suffixes (last $m$ levels with $m \\ge 3$), select a suffix that both minimizes the residual of the least-squares linear fit in $(\\log h, \\log e)$ and exhibits stable pairwise slopes, then use the slope $\\widehat{\\alpha}$ from this suffix,\n4) Enforce the polynomial-degree saturation by setting $\\widehat{\\alpha}_{\\text{clip}} = \\min(\\widehat{\\alpha}, 1)$,\n5) Return $\\widehat{\\lambda} = \\widehat{\\alpha}_{\\text{clip}}/\\beta$.\n\nYour program must implement this procedure and apply it to the following test suite. Each test case supplies $(\\beta, \\{h_k\\}, \\{e_k\\})$ as follows. All numbers are dimensionless, and there are no physical units.\n\nTest case $1$ (happy path, clear asymptotic regime):\n- $\\beta = 1.5$,\n- $h = (0.2, 0.1, 0.05, 0.025, 0.0125)$,\n- $e = C h^{\\alpha}$ with $C = 2.0$ and $\\alpha = 0.75$.\n\nTest case $2$ (saturation at polynomial degree, i.e., $\\beta \\lambda > 1$ so observed rate is $1$):\n- $\\beta = 2.5$,\n- $h = (0.4, 0.2, 0.1, 0.05, 0.025)$,\n- $e = C h^{1}$ with $C = 0.5$.\n\nTest case $3$ (pre-asymptotic contamination at coarse levels, then clean power law):\n- $\\beta = 1.0$,\n- $h = (0.4, 0.2, 0.1, 0.05, 0.025)$,\n- $e = C h^{\\alpha}$ with $C = 1.3$ and $\\alpha = 0.33$, but the first two values are inflated by a factor $1.6$, i.e., the reported sequence is $(1.6 C h_1^{\\alpha}, 1.6 C h_2^{\\alpha}, C h_3^{\\alpha}, C h_4^{\\alpha}, C h_5^{\\alpha})$.\n\nTest case $4$ (mild measurement noise):\n- $\\beta = 1.2$,\n- $h = (0.3, 0.15, 0.075, 0.0375, 0.01875, 0.009375)$,\n- $e = C h^{\\alpha}$ with $C = 0.8$ and $\\alpha = 0.84$, multiplied by fixed perturbation factors $(1.02, 0.98, 1.01, 0.99, 1.00, 1.03)$ elementwise.\n\nImplementation Requirements:\n- Compute $\\widehat{\\lambda}$ for each test case independently.\n- To ensure robustness, when selecting the suffix, balance small least-squares residual in $(\\log h, \\log e)$ with stability of pairwise slopes; you may, for example, penalize large variability of local slopes within the candidate suffix.\n- Express the final outputs rounded to $3$ decimals.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases $1$ through $4$. For example: $[0.123,0.456,0.789,0.321]$.", "solution": "The problem posed is to design a numerical procedure for estimating the corner singularity exponent, denoted $\\lambda$, in the context of the Finite Element Method (FEM) applied to a Poisson problem on a domain with a re-entrant corner. The estimation is to be performed using a sequence of measured energy norm errors, $e_k$, corresponding to a sequence of characteristic mesh sizes, $h_k$, on geometrically graded meshes. The procedure must be robust against pre-asymptotic effects and measurement noise.\n\nThis problem is valid. It is scientifically grounded in the well-established theory of finite element analysis for singular problems. The premises are factually sound, the objective is clearly defined, and the provided test cases are numerically plausible scenarios. We shall proceed with the derivation and implementation of the required procedure.\n\nThe theoretical foundation is the a priori error estimate for the energy norm of the error, which, for linear finite elements ($p=1$) on a geometrically graded mesh with grading exponent $\\beta$, is given by:\n$$\ne_h \\equiv \\| \\nabla(u - u_h) \\|_{L^2(\\Omega)} \\approx C h^{\\alpha}\n$$\nHere, $u$ is the exact solution, $u_h$ is the FE approximation, $h$ is the characteristic mesh size near the singularity, and $C$ is a constant independent of $h$. The rate of convergence, $\\alpha$, is determined by the minimum of the polynomial degree of the shape functions and the singularity-adjusted mesh grading:\n$$\n\\alpha = \\min(p, \\beta \\lambda) = \\min(1, \\beta \\lambda)\n$$\nOur objective is to estimate $\\lambda$ from discrete data pairs $(h_k, e_k)$ for $k=1, \\dots, N$.\n\nTo extract the exponent $\\alpha$ from the power-law relationship, we transform the equation into a linear form by taking the natural logarithm of both sides:\n$$\n\\ln(e_k) \\approx \\ln(C) + \\alpha \\ln(h_k)\n$$\nThis equation is of the form $y_k \\approx c + \\alpha x_k$, where $y_k = \\ln(e_k)$, $x_k = \\ln(h_k)$, and the intercept $c = \\ln(C)$. The convergence rate $\\alpha$ is the slope of the line in the log-log plot of error versus mesh size.\n\nDirectly applying linear regression to all data points $(x_k, y_k)$ is naive, as numerical data is often contaminated. Coarser meshes (larger $h_k$) may not be in the asymptotic regime where the theory holds, and all measurements can be subject to small perturbations. The problem mandates a robust procedure to mitigate these issues.\n\nThe prescribed robust strategy involves analyzing suffixes of the data序列. The rationale is that the asymptotic error estimate is more accurate for smaller $h_k$, which correspond to the final entries in a sequence of progressively refined meshes. We consider all suffixes of length $m \\geq 3$, where a minimum of 3 points is required for a minimally robust statistical analysis (e.g., to compute a standard deviation of pairwise slopes).\n\nFor each candidate suffix, consisting of the last $m$ data points, we evaluate its quality using two metrics:\n1.  **Goodness of Fit**: This measures how well the points in the suffix adhere to a linear model. We perform a linear least-squares regression on the $(\\ln h, \\ln e)$ data for the suffix to find an estimated slope $\\widehat{\\alpha}_m$ and intercept $\\widehat{c}_m$. The quality of this fit is quantified by the Root Mean Squared Error (RMSE):\n    $$\n    R_m = \\sqrt{\\frac{1}{m} \\sum_{i=N-m+1}^{N} \\left( \\ln(e_i) - (\\widehat{\\alpha}_m \\ln(h_i) + \\widehat{c}_m) \\right)^2}\n    $$\n2.  **Stability of Convergence Rate**: This measures the consistency of the convergence rate within the suffix. We compute the local, pairwise slopes between consecutive points:\n    $$\n    s_i = \\frac{\\ln(e_{i+1}) - \\ln(e_i)}{\\ln(h_{i+1}) - \\ln(h_i)}\n    $$\n    for points $i$ and $i+1$ within the suffix. The stability is then measured by the standard deviation, $V_m$, of these pairwise slopes. A small $V_m$ indicates that the convergence rate is stable across the refinement levels included in the suffix.\n\nTo select the \"best\" suffix, we must balance these two criteria. A smaller RMSE and a smaller standard deviation of slopes are both desirable. We define a simple, unweighted cost function, $J_m$, for each suffix of length $m$:\n$$\nJ_m = R_m + V_m\n$$\nThe suffix that minimizes this cost function is deemed the most reliable representation of the asymptotic behavior. The slope $\\widehat{\\alpha}$ from the linear fit on this optimal suffix is selected as our best estimate of the convergence rate.\n\nOnce the optimal rate $\\widehat{\\alpha}$ is determined, we must account for the saturation effect imposed by the polynomial degree of the basis functions. The true rate $\\alpha$ cannot exceed $p=1$. Therefore, we clip our estimated rate:\n$$\n\\widehat{\\alpha}_{\\text{clip}} = \\min(\\widehat{\\alpha}, 1.0)\n$$\nFinally, we invert the relation $\\widehat{\\alpha}_{\\text{clip}} = \\beta \\widehat{\\lambda}$ to find the estimate for the singularity exponent:\n$$\n\\widehat{\\lambda} = \\frac{\\widehat{\\alpha}_{\\text{clip}}}{\\beta}\n$$\nThis completes the design of the robust estimation procedure. The following implementation will apply this logic to the provided test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not strictly necessary as numpy covers the needs.\n\ndef estimate_lambda(beta, h_values, e_values):\n    \"\"\"\n    Estimates the corner singularity exponent lambda from FE error data.\n\n    Args:\n        beta (float): The mesh grading exponent.\n        h_values (np.ndarray): A sequence of characteristic mesh sizes.\n        e_values (np.ndarray): A sequence of corresponding energy norm errors.\n\n    Returns:\n        float: The estimated singularity exponent lambda_hat.\n    \"\"\"\n    if len(h_values) < 3:\n        raise ValueError(\"At least 3 data points are required.\")\n\n    log_h = np.log(h_values)\n    log_e = np.log(e_values)\n\n    best_suffix_info = {\n        'cost': np.inf,\n        'alpha': np.nan,\n        'length': 0\n    }\n\n    n_points = len(h_values)\n    min_suffix_len = 3\n\n    # Iterate through all possible suffixes of length m >= 3\n    for m in range(min_suffix_len, n_points + 1):\n        # Extract the current suffix (last m points)\n        x_suffix = log_h[-m:]\n        y_suffix = log_e[-m:]\n\n        # 1. Perform linear least-squares regression\n        # np.polyfit(x, y, 1) returns [slope, intercept]\n        slope, intercept = np.polyfit(x_suffix, y_suffix, 1)\n\n        # 2. Calculate the Root Mean Squared Error (RMSE) of the fit\n        predictions = slope * x_suffix + intercept\n        residuals = y_suffix - predictions\n        rmse = np.sqrt(np.mean(residuals**2))\n\n        # 3. Calculate the stability of pairwise slopes\n        # Pairwise slopes are (y2-y1)/(x2-x1)\n        pairwise_slopes = (y_suffix[1:] - y_suffix[:-1]) / (x_suffix[1:] - x_suffix[:-1])\n        \n        # Standard deviation of pairwise slopes\n        slope_std_dev = np.std(pairwise_slopes)\n\n        # 4. Define and compute the cost function\n        cost = rmse + slope_std_dev\n        \n        # 5. Check if this is the best suffix found so far\n        if cost < best_suffix_info['cost']:\n            best_suffix_info['cost'] = cost\n            best_suffix_info['alpha'] = slope\n            best_suffix_info['length'] = m\n\n    # Extract the best estimate for alpha from the optimal suffix\n    alpha_hat = best_suffix_info['alpha']\n\n    # Enforce the polynomial-degree saturation: alpha <= p=1\n    alpha_clip = min(alpha_hat, 1.0)\n\n    # Compute the final estimate for lambda\n    lambda_hat = alpha_clip / beta\n\n    return lambda_hat\n\ndef solve():\n    \"\"\"\n    Defines the test cases, runs the estimation for each, and prints the results.\n    \"\"\"\n    # Test case 1: Happy path, clear asymptotic regime\n    h1 = np.array([0.2, 0.1, 0.05, 0.025, 0.0125])\n    e1 = 2.0 * h1**0.75\n    case1 = (1.5, h1, e1)\n\n    # Test case 2: Saturation at polynomial degree\n    h2 = np.array([0.4, 0.2, 0.1, 0.05, 0.025])\n    e2 = 0.5 * h2**1.0\n    case2 = (2.5, h2, e2)\n\n    # Test case 3: Pre-asymptotic contamination\n    h3 = np.array([0.4, 0.2, 0.1, 0.05, 0.025])\n    e3_base = 1.3 * h3**0.33\n    e3_base[:2] *= 1.6  # Inflate the first two error values\n    case3 = (1.0, h3, e3_base)\n\n    # Test case 4: Mild measurement noise\n    h4 = np.array([0.3, 0.15, 0.075, 0.0375, 0.01875, 0.009375])\n    e4_base = 0.8 * h4**0.84\n    perturbations = np.array([1.02, 0.98, 1.01, 0.99, 1.00, 1.03])\n    e4 = e4_base * perturbations\n    case4 = (1.2, h4, e4)\n\n    test_cases = [case1, case2, case3, case4]\n\n    results = []\n    for beta, h, e in test_cases:\n        lambda_estimate = estimate_lambda(beta, h, e)\n        results.append(lambda_estimate)\n\n    # Format the final output string as required.\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```"}]}