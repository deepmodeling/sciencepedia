{"hands_on_practices": [{"introduction": "A cornerstone of developing reliable numerical simulations is verification against known analytical solutions. This practice guides you through a rigorous comparison between the continuous and discrete worlds of transient heat diffusion. By deriving the analytical solution for a 1D heat problem and then analyzing the spectral properties of its finite element and time-discretized counterpart, you will gain a deep understanding of how numerical schemes approximate the true physical damping of thermal modes [@problem_id:2607785]. This exercise is fundamental for building confidence in the predictive capabilities of your numerical methods.", "problem": "Consider one-dimensional transient heat conduction in a homogeneous rod of length $L>0$ with thermal diffusivity $\\alpha>0$. The temperature field $u(x,t)$ satisfies homogeneous Dirichlet boundary conditions $u(0,t)=0$ and $u(L,t)=0$ for all $t\\ge 0$. The initial condition is a single sine mode $u(x,0)=\\sin\\!\\left(\\frac{m\\pi x}{L}\\right)$ with mode index $m\\in\\mathbb{N}$. \n\nStarting from the principles of local energy conservation and Fourier’s law, derive the governing partial differential equation (PDE) for $u(x,t)$ and justify that the continuous eigenfunctions under these boundary conditions are spatial sine modes. By separation of variables and orthogonality, derive the analytical time evolution of the mode amplitude for the given initial condition.\n\nNext, discretize the spatial domain uniformly with $N\\in\\mathbb{N}$ elements of size $h=L/N$ and approximate $u(x,t)$ in the standard piecewise-linear finite element method (FEM) with a consistent mass matrix. Let $M$ and $K$ denote the resulting mass and stiffness matrices. Show that the interior grid sine vectors with components $\\sin\\!\\left(\\frac{jm\\pi}{N}\\right)$ at interior node indices $j=1,2,\\dots,N-1$ are generalized eigenvectors of the matrix pencil $(K,M)$, and derive the corresponding generalized eigenvalue in closed form as a function of $N$, $L$, and $m$. \n\nDiscretize the semi-discrete system $M \\dot{\\boldsymbol{U}}(t)+\\alpha K \\boldsymbol{U}(t)=\\boldsymbol{0}$ in time using the backward Euler (BE) method with time step $\\Delta t>0$, and specialize the resulting one-step update to a single discrete eigenmode. Define the per-step amplification factor of this discrete mode, and compare it to the exact per-step amplification factor obtained from the continuous analytical solution for the same mode over a time interval of length $\\Delta t$.\n\nFinally, taking $m$ in the continuous problem to match the discrete mode index and assuming $1\\le m \\le N-1$, derive a single closed-form analytic expression for the ratio $\\mathcal{R}$ of the discrete one-step amplification factor to the exact one-step amplification factor, expressed in terms of $\\alpha$, $L$, $N$, $m$, and $\\Delta t$. State your final result as a single closed-form expression. No units are required for $\\mathcal{R}$, and no rounding is needed.", "solution": "The problem as stated is scientifically grounded, well-posed, objective, and self-contained. It presents a standard, albeit multipart, exercise in the analysis of numerical methods for partial differential equations. All parameters are clearly defined, and the task requires a rigorous derivation based on established principles of mathematical physics and numerical analysis. The problem is therefore valid, and a solution will be provided.\n\nFirst, we derive the governing partial differential equation (PDE) for one-dimensional heat conduction. We consider an infinitesimal segment of the rod from $x$ to $x+\\Delta x$. The local energy conservation principle states that the time rate of change of internal energy within this volume is equal to the net heat flux across its boundaries. Let $A$ be the cross-sectional area, $\\rho$ the density, and $c$ the specific heat capacity. The internal energy is $\\int_x^{x+\\Delta x} c \\rho A u(x',t) dx'$. The heat flux is given by Fourier's law, $q(x,t) = -k \\frac{\\partial u}{\\partial x}$, where $k$ is the thermal conductivity. The energy balance equation is:\n$$ \\frac{d}{dt} \\int_x^{x+\\Delta x} c \\rho A u(x',t) dx' = A q(x,t) - A q(x+\\Delta x, t) $$\nAssuming $c, \\rho, A$ are constant, we have:\n$$ \\int_x^{x+\\Delta x} c \\rho A \\frac{\\partial u}{\\partial t} dx' = A \\left( -k \\frac{\\partial u}{\\partial x} \\bigg|_x - \\left( -k \\frac{\\partial u}{\\partial x} \\bigg|_{x+\\Delta x} \\right) \\right) $$\nDividing by $A \\Delta x$ and taking the limit as $\\Delta x \\to 0$, we invoke the fundamental theorem of calculus on the left and the definition of the derivative on the right:\n$$ c \\rho \\frac{\\partial u}{\\partial t} = \\frac{\\partial}{\\partial x} \\left( k \\frac{\\partial u}{\\partial x} \\right) $$\nFor a homogeneous rod, $k$ is constant. Defining the thermal diffusivity $\\alpha = k/(c\\rho)$, we obtain the heat equation:\n$$ \\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2} $$\nTo find the analytical solution, we use the method of separation of variables, assuming a solution of the form $u(x,t) = X(x)T(t)$. Substituting into the PDE yields $X(x)T'(t) = \\alpha X''(x)T(t)$. Separating variables gives:\n$$ \\frac{T'(t)}{\\alpha T(t)} = \\frac{X''(x)}{X(x)} = -\\lambda^2 $$\nThe separation constant must be negative to satisfy the homogeneous Dirichlet boundary conditions $u(0,t)=u(L,t)=0$ with a non-trivial solution. The spatial problem is an eigenvalue problem for the operator $-\\frac{d^2}{dx^2}$:\n$$ X''(x) + \\lambda^2 X(x) = 0, \\quad X(0)=0, \\quad X(L)=0 $$\nThe general solution is $X(x) = C_1 \\cos(\\lambda x) + C_2 \\sin(\\lambda x)$. The condition $X(0)=0$ implies $C_1=0$. The condition $X(L)=0$ implies $C_2 \\sin(\\lambda L) = 0$. For a non-trivial solution ($C_2 \\neq 0$), we must have $\\sin(\\lambda L)=0$, which requires $\\lambda L = m\\pi$ for an integer $m \\in \\mathbb{N}$. The eigenvalues are $\\lambda_m^2 = \\left(\\frac{m\\pi}{L}\\right)^2$ and the corresponding eigenfunctions are $X_m(x) = \\sin\\left(\\frac{m\\pi x}{L}\\right)$. These are the spatial sine modes.\n\nThe temporal problem is $T'(t) + \\alpha \\lambda_m^2 T(t) = 0$, with solution $T_m(t) = T_m(0) \\exp(-\\alpha \\lambda_m^2 t)$. The full solution is a superposition of these modes. Given the initial condition $u(x,0) = \\sin\\left(\\frac{m\\pi x}{L}\\right)$, we see that only one mode is present. The analytical solution is:\n$$ u(x,t) = \\sin\\left(\\frac{m\\pi x}{L}\\right) \\exp\\left(-\\alpha \\left(\\frac{m\\pi}{L}\\right)^2 t\\right) $$\nThe exact per-step amplification factor over a time interval $\\Delta t$ is the factor by which the amplitude decays, which is:\n$$ G_{\\text{exact}} = \\exp\\left(-\\alpha \\left(\\frac{m\\pi}{L}\\right)^2 \\Delta t\\right) $$\nNow we proceed to the finite element discretization. The weak form of the PDE is to find $u \\in H^1_0([0,L])$ such that for all test functions $v \\in H^1_0([0,L])$:\n$$ \\int_0^L \\frac{\\partial u}{\\partial t} v \\,dx + \\alpha \\int_0^L \\frac{\\partial u}{\\partial x} \\frac{\\partial v}{\\partial x} \\,dx = 0 $$\nUsing a piecewise-linear finite element basis $\\{\\phi_j(x)\\}_{j=1}^{N-1}$ on a uniform mesh with element size $h=L/N$, we approximate $u(x,t) \\approx u_h(x,t) = \\sum_{j=1}^{N-1} U_j(t) \\phi_j(x)$. This leads to the semi-discrete system $M \\dot{\\boldsymbol{U}}(t)+\\alpha K \\boldsymbol{U}(t)=\\boldsymbol{0}$, where the entries of the consistent mass matrix $M$ and stiffness matrix $K$ are:\n$$ M_{ij} = \\int_0^L \\phi_i \\phi_j \\,dx, \\quad K_{ij} = \\int_0^L \\frac{d\\phi_i}{dx}\\frac{d\\phi_j}{dx} \\,dx $$\nFor hat functions on a uniform 1D mesh, these matrices are tridiagonal with entries: $M_{ii} = \\frac{2h}{3}$, $M_{i,i\\pm 1} = \\frac{h}{6}$, $K_{ii} = \\frac{2}{h}$, and $K_{i,i\\pm 1} = -\\frac{1}{h}$.\n\nWe must show that the discrete sine vectors $\\boldsymbol{v}_m$ with components $(v_m)_j = \\sin\\left(\\frac{jm\\pi}{N}\\right)$ for $j=1, \\dots, N-1$ are generalized eigenvectors of $(K,M)$ and find the eigenvalue $\\Lambda_m$ satisfying $K\\boldsymbol{v}_m = \\Lambda_m M\\boldsymbol{v}_m$. We compute the action of $K$ and $M$ on $\\boldsymbol{v}_m$. For the $j$-th component:\n$$ (K\\boldsymbol{v}_m)_j = \\frac{1}{h}\\left[-\\sin\\left(\\frac{(j-1)m\\pi}{N}\\right) + 2\\sin\\left(\\frac{jm\\pi}{N}\\right) - \\sin\\left(\\frac{(j+1)m\\pi}{N}\\right)\\right] $$\nUsing the identity $\\sin(A-B)+\\sin(A+B) = 2\\sin(A)\\cos(B)$, this simplifies to:\n$$ (K\\boldsymbol{v}_m)_j = \\frac{1}{h}\\left[2\\sin\\left(\\frac{jm\\pi}{N}\\right) - 2\\sin\\left(\\frac{jm\\pi}{N}\\right)\\cos\\left(\\frac{m\\pi}{N}\\right)\\right] = \\frac{2}{h}\\left(1 - \\cos\\left(\\frac{m\\pi}{N}\\right)\\right)(v_m)_j $$\nFor the mass matrix:\n$$ (M\\boldsymbol{v}_m)_j = \\frac{h}{6}\\left[\\sin\\left(\\frac{(j-1)m\\pi}{N}\\right) + 4\\sin\\left(\\frac{jm\\pi}{N}\\right) + \\sin\\left(\\frac{(j+1)m\\pi}{N}\\right)\\right] $$\n$$ (M\\boldsymbol{v}_m)_j = \\frac{h}{6}\\left[2\\sin\\left(\\frac{jm\\pi}{N}\\right)\\cos\\left(\\frac{m\\pi}{N}\\right) + 4\\sin\\left(\\frac{jm\\pi}{N}\\right)\\right] = \\frac{h}{3}\\left(2 + \\cos\\left(\\frac{m\\pi}{N}\\right)\\right)(v_m)_j $$\nThe sine vectors are indeed eigenvectors for both matrices. The generalized eigenvalue $\\Lambda_m$ is the ratio of their respective eigenvalues:\n$$ \\Lambda_m = \\frac{\\frac{2}{h}\\left(1 - \\cos\\left(\\frac{m\\pi}{N}\\right)\\right)}{\\frac{h}{3}\\left(2 + \\cos\\left(\\frac{m\\pi}{N}\\right)\\right)} = \\frac{6}{h^2}\\frac{1 - \\cos\\left(\\frac{m\\pi}{N}\\right)}{2 + \\cos\\left(\\frac{m\\pi}{N}\\right)} $$\nSubstituting $h=L/N$, the generalized eigenvalue is:\n$$ \\Lambda_m = \\frac{6N^2}{L^2} \\frac{1 - \\cos\\left(\\frac{m\\pi}{N}\\right)}{2 + \\cos\\left(\\frac{m\\pi}{N}\\right)} $$\nNext, we discretize the semi-discrete system in time using the backward Euler method. For a single eigenmode, the system reduces to the scalar ordinary differential equation $c'(t) + \\alpha \\Lambda_m c(t) = 0$ for the modal amplitude $c(t)$. Applying backward Euler with step size $\\Delta t$ to an equation of the form $\\dot{y}=-\\lambda y$ yields $y^{n+1} = y^n - \\lambda \\Delta t y^{n+1}$, which gives the update $y^{n+1} = (1+\\lambda\\Delta t)^{-1} y^n$. Here, $\\lambda = \\alpha \\Lambda_m$. The discrete one-step amplification factor is:\n$$ G_{\\text{discrete}} = \\frac{1}{1 + \\alpha \\Lambda_m \\Delta t} = \\frac{1}{1 + \\alpha \\Delta t \\frac{6N^2}{L^2} \\frac{1 - \\cos(m\\pi/N)}{2 + \\cos(m\\pi/N)}} $$\nFinally, we compute the ratio $\\mathcal{R}$ of the discrete to the exact amplification factor.\n$$ \\mathcal{R} = \\frac{G_{\\text{discrete}}}{G_{\\text{exact}}} = \\frac{\\left(1 + \\alpha \\Delta t \\frac{6N^2}{L^2} \\frac{1 - \\cos(m\\pi/N)}{2 + \\cos(m\\pi/N)}\\right)^{-1}}{\\exp\\left(-\\alpha \\left(\\frac{m\\pi}{L}\\right)^2 \\Delta t\\right)} $$\nThis simplifies to the final expression:\n$$ \\mathcal{R} = \\frac{\\exp\\left(\\alpha \\left(\\frac{m\\pi}{L}\\right)^2 \\Delta t\\right)}{1 + \\alpha \\Delta t \\frac{6N^2}{L^2} \\frac{1 - \\cos(m\\pi/N)}{2 + \\cos(m\\pi/N)}} $$\nThis is the required closed-form analytic expression for the ratio $\\mathcal{R}$.", "answer": "$$\n\\boxed{\\frac{\\exp\\left(\\alpha \\left(\\frac{m\\pi}{L}\\right)^2 \\Delta t\\right)}{1 + \\alpha \\Delta t \\frac{6N^2}{L^2} \\frac{1 - \\cos\\left(\\frac{m\\pi}{N}\\right)}{2 + \\cos\\left(\\frac{m\\pi}{N}\\right)}}}\n$$", "id": "2607785"}, {"introduction": "While the Crank-Nicolson method is celebrated for its second-order accuracy and unconditional stability, it harbors a subtle but critical flaw: it can produce non-physical oscillations when solving problems with sharp gradients or non-smooth data. This hands-on coding challenge requires you to implement a finite element solver to witness this phenomenon firsthand [@problem_id:2607746]. By observing the violation of the positivity principle, you will develop a crucial intuition for the limitations of numerical schemes and the importance of properties beyond simple stability, such as L-stability.", "problem": "You are to implement a transient heat diffusion solver using the finite element method with continuous, piecewise linear basis functions over an acute triangulation. The goal is to design a test case with strong gradients and evaluate whether the Crank–Nicolson time discretization preserves the positivity of the finite element solution on an acute triangulation, and to explain any observed oscillations. Your program must assemble the spatial operators from first principles and time-step the solution directly.\n\nStart from the following fundamental physical and mathematical base:\n- Conservation of energy in a continuum: for temperature field $u(\\boldsymbol{x},t)$, thermal conductivity $\\kappa$, density $\\rho$, and heat capacity $c$, the energy balance with no source reads $\\rho c\\, \\partial_t u - \\nabla \\cdot (\\kappa \\nabla u) = 0$.\n- Fourier’s law of heat conduction: the heat flux is $\\boldsymbol{q} = -\\kappa \\nabla u$.\n- Assume nondimensionalization yielding $\\rho c = 1$ and $\\kappa = 1$, so that the governing equation reduces to $\\partial_t u - \\Delta u = 0$ in a domain $\\Omega$, with homogeneous Dirichlet boundary condition $u=0$ on $\\partial \\Omega$.\n\nYou must:\n- Derive the weak form of the initial boundary value problem on an equilateral triangular domain $\\Omega$ with vertices at $(0,0)$, $(1,0)$, and $(\\tfrac{1}{2},\\tfrac{\\sqrt{3}}{2})$. Use continuous, piecewise linear trial and test functions on a conforming, shape-regular, acute triangulation obtained by subdividing the equilateral triangle into $N \\times N$ uniform sub-triangles (all interior angles strictly less than $90^\\circ$). Use a consistent mass matrix.\n- Discretize in time by the Crank–Nicolson method with time step $\\Delta t$ and zero source, i.e., by the trapezoidal rule applied to the semidiscrete system. Enforce Dirichlet boundary conditions strongly at every time step by eliminating boundary degrees of freedom.\n- Use the initial condition $u(\\boldsymbol{x},0) = \\exp\\!\\big(-\\|\\boldsymbol{x}-\\boldsymbol{x}_c\\|^2/(2\\sigma^2)\\big)$, where $\\boldsymbol{x}_c$ is the top vertex $(\\tfrac{1}{2},\\tfrac{\\sqrt{3}}{2})$, and set $u=0$ at boundary nodes to be consistent with the boundary condition. This choice produces strong spatial gradients for small $\\sigma$.\n- Evaluate the positivity of the numerical solution over time by tracking the minimum and maximum nodal values across all time steps and computing a boolean indicating whether the solution remained nonnegative up to a tolerance $\\varepsilon = 10^{-12}$. Also compute an undershoot ratio defined as $r = \\max(0,-\\min u)/\\max u$ using the global minimum and maximum encountered during the simulation, where the maximum is taken over all nodes and all time steps. If $\\max u$ is zero within tolerance, define $r=0$ to avoid division by zero.\n\nYour program must implement the following from first principles:\n- The weak form for the heat equation after integration by parts on $\\Omega$ with $u=0$ on $\\partial \\Omega$.\n- The assembly of the global consistent mass matrix and stiffness matrix using the linear shape functions on triangles.\n- The Crank–Nicolson update for the semidiscrete system.\n- The identification of boundary nodes for the equilateral triangulation using the lattice description of the mesh.\n\nYou must run the solver on the following test suite of parameter values $(N,\\Delta t, n_{\\text{steps}}, \\sigma)$:\n- Case $1$: $(12, 5\\times 10^{-4}, 40, 0.04)$.\n- Case $2$: $(12, 5\\times 10^{-3}, 4, 0.02)$.\n- Case $3$: $(8, 1\\times 10^{-2}, 3, 0.015)$.\n- Case $4$: $(20, 1\\times 10^{-3}, 20, 0.04)$.\n\nFor each case, you must:\n- Assemble the mesh with $N$ subdivisions per edge as described above.\n- Initialize $u^0$ from the Gaussian and enforce $u=0$ at boundary nodes.\n- Advance $n_{\\text{steps}}$ steps with the Crank–Nicolson method using time step $\\Delta t$.\n- Record the global minimum $m$ and maximum $M$ over all nodes and time steps, compute the boolean $\\text{nonneg} = (m \\ge -\\varepsilon)$ with $\\varepsilon = 10^{-12}$, and compute the undershoot ratio $r$ as defined above.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output a list of the form $[m, M, \\text{nonneg}, r]$ in this order, where $m$ and $M$ are floating-point numbers, $\\text{nonneg}$ is a boolean, and $r$ is a floating-point number. The overall output must be a list of these per-case lists, for example:\n\"[ [m1,M1,nonneg1,r1], [m2,M2,nonneg2,r2], [m3,M3,nonneg3,r3], [m4,M4,nonneg4,r4] ]\"\nAll numbers are nondimensional; no physical units are required.\n\nYour implementation must be a complete, runnable program as specified. No user input is allowed; all parameters are as specified above. Your code must rely only on the allowed libraries and must conform to the execution environment stated elsewhere in this task.", "solution": "The problem presented is a well-posed, scientifically grounded exercise in the numerical solution of partial differential equations. It requires the implementation of a finite element method (FEM) solver for the transient heat equation on a specific domain geometry. All necessary physical laws, mathematical formulations, and numerical parameters are provided. The problem asks for an analysis of a key numerical property, the preservation of positivity, for the Crank–Nicolson time-stepping scheme on an acute triangulation, a classic topic in numerical analysis. The premise that the acuteness of the mesh and the size of the time step relative to the mesh spacing are crucial for this property is correct. The problem is valid, and I shall proceed with a full solution.\n\nThe derivation and implementation will follow these steps:\n1.  **Weak Formulation**: The governing equation is the nondimensionalized heat equation, $\\partial_t u - \\Delta u = 0$ in a domain $\\Omega$, with a homogeneous Dirichlet boundary condition $u=0$ on $\\partial\\Omega$. To derive the weak form, we multiply by a test function $v$ from the Sobolev space $H_0^1(\\Omega)$ (the space of functions with square-integrable first derivatives that are zero on the boundary $\\partial\\Omega$) and integrate over $\\Omega$:\n    $$ \\int_{\\Omega} (\\partial_t u) v \\, d\\boldsymbol{x} - \\int_{\\Omega} (\\Delta u) v \\, d\\boldsymbol{x} = 0 $$\n    Applying Green's first identity (integration by parts) to the second term yields:\n    $$ \\int_{\\Omega} (\\Delta u) v \\, d\\boldsymbol{x} = - \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, d\\boldsymbol{x} + \\int_{\\partial\\Omega} (\\nabla u \\cdot \\boldsymbol{n}) v \\, dS $$\n    Since the test function $v \\in H_0^1(\\Omega)$, $v=0$ on the boundary $\\partial\\Omega$, which causes the boundary integral to vanish. The weak formulation is then: find $u(\\cdot, t) \\in H_0^1(\\Omega)$ such that for all $v \\in H_0^1(\\Omega)$:\n    $$ \\int_{\\Omega} (\\partial_t u) v \\, d\\boldsymbol{x} + \\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, d\\boldsymbol{x} = 0 $$\n\n2.  **Spatial Discretization (FEM)**: We seek an approximate solution $u_h(\\boldsymbol{x}, t)$ in a finite-dimensional subspace $V_h \\subset H_0^1(\\Omega)$. We define $u_h$ as a linear combination of basis functions $\\phi_j(\\boldsymbol{x})$ associated with the interior nodes of the mesh:\n    $$ u_h(\\boldsymbol{x}, t) = \\sum_{j \\in \\mathcal{I}} U_j(t) \\phi_j(\\boldsymbol{x}) $$\n    where $\\mathcal{I}$ is the set of indices for interior nodes and $U_j(t)$ are the unknown time-dependent coefficients representing the temperature at these nodes. By selecting the test functions $v$ to be the basis functions $\\phi_i$ for $i \\in \\mathcal{I}$ (the Galerkin method), we obtain a system of ordinary differential equations (ODEs):\n    $$ \\sum_{j \\in \\mathcal{I}} \\left(\\int_{\\Omega} \\phi_i \\phi_j \\, d\\boldsymbol{x}\\right) \\frac{dU_j}{dt} + \\sum_{j \\in \\mathcal{I}} \\left(\\int_{\\Omega} \\nabla\\phi_i \\cdot \\nabla\\phi_j \\, d\\boldsymbol{x}\\right) U_j(t) = 0, \\quad \\forall i \\in \\mathcal{I} $$\n    This is the semi-discrete system, written in matrix form as:\n    $$ M \\frac{d\\boldsymbol{U}}{dt} + K \\boldsymbol{U} = \\boldsymbol{0} $$\n    where $\\boldsymbol{U}(t)$ is the vector of nodal values $\\{U_j(t)\\}_{j \\in \\mathcal{I}}$. The matrices $M$ and $K$ are the consistent mass matrix and stiffness matrix, respectively, restricted to the interior degrees of freedom. Their entries are:\n    $$ M_{ij} = \\int_{\\Omega} \\phi_i \\phi_j \\, d\\boldsymbol{x}, \\quad K_{ij} = \\int_{\\Omega} \\nabla\\phi_i \\cdot \\nabla\\phi_j \\, d\\boldsymbol{x} $$\n\n3.  **Temporal Discretization (Crank–Nicolson)**: We discretize the time derivative using the trapezoidal rule (Crank–Nicolson scheme) with a time step $\\Delta t$, where $\\boldsymbol{U}^n \\approx \\boldsymbol{U}(n\\Delta t)$:\n    $$ M \\frac{\\boldsymbol{U}^{n+1} - \\boldsymbol{U}^n}{\\Delta t} + K \\frac{\\boldsymbol{U}^{n+1} + \\boldsymbol{U}^n}{2} = \\boldsymbol{0} $$\n    Rearranging the terms to solve for the unknown state $\\boldsymbol{U}^{n+1}$ at the next time step gives the linear system:\n    $$ \\left(M + \\frac{\\Delta t}{2} K\\right) \\boldsymbol{U}^{n+1} = \\left(M - \\frac{\\Delta t}{2} K\\right) \\boldsymbol{U}^n $$\n    This system must be solved at each time step. The matrix on the left-hand side is constant, so its factorization can be pre-computed for efficiency.\n\n4.  **Element Matrices**: The global matrices $M$ and $K$ are assembled by summing up contributions from local element matrices, $M^e$ and $K^e$. For a uniform triangulation using equilateral triangles of side length $h = 1/N$, all element matrices are identical. The area of each element is $A = \\frac{\\sqrt{3}}{4}h^2$. For piecewise linear ($\\mathbb{P}_1$) basis functions, the element stiffness and mass matrices are:\n    $$ K^e = \\frac{1}{2\\sqrt{3}} \\begin{pmatrix} 2 & -1 & -1 \\\\ -1 & 2 & -1 \\\\ -1 & -1 & 2 \\end{pmatrix}, \\quad M^e = \\frac{A}{12} \\begin{pmatrix} 2 & 1 & 1 \\\\ 1 & 2 & 1 \\\\ 1 & 1 & 2 \\end{pmatrix} = \\frac{\\sqrt{3}h^2}{48} \\begin{pmatrix} 2 & 1 & 1 \\\\ 1 & 2 & 1 \\\\ 1 & 1 & 2 \\end{pmatrix} $$\n    The stiffness matrix $K^e$ has non-positive off-diagonal entries, and its assembly results in a global stiffness matrix $K$ that is an M-matrix for an acute triangulation. This property is crucial for the discrete maximum principle. However, the Crank-Nicolson update matrix, $(M + \\frac{\\Delta t}{2} K)^{-1} (M - \\frac{\\Delta t}{2} K)$, does not guarantee positivity unless a condition on $\\Delta t$ is met. Specifically, positivity is maintained if the matrix $M - \\frac{\\Delta t}{2} K$ is non-negative, which imposes a CFL-like condition of the form $\\Delta t \\le C h^2$. The problem cases are designed to probe this condition: cases with larger $\\Delta t$ are expected to violate it and produce spurious oscillations (undershoots), leading to negative temperature values, even with an initial condition that is non-negative everywhere.\n\n5.  **Implementation Strategy**:\n    - **Mesh**: An equilateral triangle domain with vertices $(0,0)$, $(1,0)$, and $(\\frac{1}{2},\\frac{\\sqrt{3}}{2})$ is triangulated into $N^2$ smaller equilateral triangles. The nodes are generated using a barycentric coordinate system. A node $\\boldsymbol{x}_{ijk}$ is defined by $\\boldsymbol{x}_{ijk} = \\frac{i}{N}(0,0) + \\frac{j}{N}(1,0) + \\frac{k}{N}(\\frac{1}{2},\\frac{\\sqrt{3}}{2})$ where $i,j,k$ are non-negative integers with $i+j+k=N$. We can use $(j,k)$ as independent indices ($j,k \\ge 0$, $j+k \\le N$).\n    - **Assembly**: global $M$ and $K$ matrices are assembled by iterating through all elements and adding the local element matrix contributions to the corresponding global indices.\n    - **Boundary Conditions**: Dirichlet boundary conditions ($u=0$) are enforced by identifying all boundary nodes ($i=0$ or $j=0$ or $k=0$ in the barycentric indexing) and restricting the linear system to only the interior nodes.\n    - **Time Marching**: The initial condition vector $\\boldsymbol{U}^0$ is constructed by evaluating the Gaussian function at all interior node coordinates and setting boundary nodes to $0$. The simulation then proceeds for $n_{\\text{steps}}$ by repeatedly solving the Crank-Nicolson linear system.\n    - **Analysis**: During the simulation, the minimum and maximum nodal values across all nodes (interior and boundary) are tracked at every time step from $t=0$ to $t_{final}$. These are used to compute the final required metrics: global minimum $m$, global maximum $M$, a boolean `nonneg` for positivity, and the undershoot ratio $r$.\n\nThe following program implements this entire procedure from first principles.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import lu_factor, lu_solve\n\ndef solve():\n    \"\"\"\n    Main function to run the FEM solver for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (N, dt, n_steps, sigma)\n        (12, 5e-4, 40, 0.04),\n        (12, 5e-3, 4, 0.02),\n        (8, 1e-2, 3, 0.015),\n        (20, 1e-3, 20, 0.04),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        N, dt, n_steps, sigma = params\n        result = run_simulation(N, dt, n_steps, sigma)\n        all_results.append(result)\n\n    # Format the final output string\n    # E.g., [[-2.3e-05, 0.9, False, 2.5e-05], ...]\n    # using f-strings for demonstration of format. The exact values will be computed.\n    result_str = \"[\" + \", \".join([\n        f\"[{m:.8e}, {M:.8e}, {str(nonneg).lower()}, {r:.8e}]\"\n        for m, M, nonneg, r in all_results\n    ]) + \"]\"\n    print(result_str)\n\ndef run_simulation(N, dt, n_steps, sigma):\n    \"\"\"\n    Runs a single simulation for the transient heat equation using FEM.\n    \n    Args:\n        N (int): Number of subdivisions along each edge of the domain.\n        dt (float): Time step size.\n        n_steps (int): Number of time steps to perform.\n        sigma (float): Standard deviation of the initial Gaussian pulse.\n\n    Returns:\n        tuple: A tuple containing (m, M, nonneg, r) for the simulation.\n    \"\"\"\n    TOL = 1.0e-12\n\n    # 1. Mesh Generation\n    # Vertices of the main equilateral triangle\n    v1 = np.array([0.0, 0.0])\n    v2 = np.array([1.0, 0.0])\n    v3 = np.array([0.5, np.sqrt(3.0) / 2.0])\n\n    # Generate nodes using barycentric coordinates\n    nodes = []\n    node_map = {}  # maps (j, k) -> node_idx\n    idx_counter = 0\n    for k in range(N + 1):\n        for j in range(N - k + 1):\n            i = N - j - k\n            coord = (j / N) * v2 + (k / N) * v3  # v1 is origin\n            nodes.append(coord)\n            node_map[(j, k)] = idx_counter\n            idx_counter += 1\n    nodes = np.array(nodes)\n    num_nodes = len(nodes)\n\n    # Generate elements (triangles)\n    elements = []\n    # \"Up\" pointing triangles\n    for k in range(N):\n        for j in range(N - k):\n            v_idx1 = node_map[(j, k)]\n            v_idx2 = node_map[(j + 1, k)]\n            v_idx3 = node_map[(j, k + 1)]\n            elements.append([v_idx1, v_idx2, v_idx3])\n    # \"Down\" pointing triangles\n    for k in range(N - 1):\n        for j in range(N - k - 1):\n            v_idx1 = node_map[(j + 1, k)]\n            v_idx2 = node_map[(j + 1, k + 1)]\n            v_idx3 = node_map[(j, k + 1)]\n            elements.append([v_idx1, v_idx2, v_idx3])\n    \n    # Identify interior and boundary nodes\n    interior_nodes_indices = []\n    boundary_nodes_indices = []\n    for k in range(N + 1):\n        for j in range(N - k + 1):\n            i = N - j - k\n            idx = node_map[(j, k)]\n            if i > 0 and j > 0 and k > 0:\n                interior_nodes_indices.append(idx)\n            else:\n                boundary_nodes_indices.append(idx)\n\n    # 2. Assemble Matrices\n    h = 1.0 / N\n    area = np.sqrt(3.0) / 4.0 * h**2\n    \n    # Element stiffness matrix for equilateral triangle\n    K_e = (1.0 / (2.0 * np.sqrt(3.0))) * np.array([[2, -1, -1], [-1, 2, -1], [-1, -1, 2]])\n    # Element mass matrix\n    M_e = (area / 12.0) * np.array([[2, 1, 1], [1, 2, 1], [1, 1, 2]])\n\n    M = np.zeros((num_nodes, num_nodes))\n    K = np.zeros((num_nodes, num_nodes))\n\n    for el in elements:\n        for i in range(3):\n            for j in range(3):\n                gi, gj = el[i], el[j]\n                M[gi, gj] += M_e[i, j]\n                K[gi, gj] += K_e[i, j]\n    \n    # Extract submatrices for interior nodes\n    ix = np.ix_(interior_nodes_indices, interior_nodes_indices)\n    M_int = M[ix]\n    K_int = K[ix]\n    \n    # 3. Initial Condition\n    u0 = np.zeros(num_nodes)\n    xc = v3\n    for i in range(num_nodes):\n        if i in interior_nodes_indices:\n            dist_sq = np.sum((nodes[i] - xc)**2)\n            u0[i] = np.exp(-dist_sq / (2.0 * sigma**2))\n    \n    global_min = np.min(u0)\n    global_max = np.max(u0)\n\n    u_int = u0[interior_nodes_indices]\n\n    # 4. Time Stepping\n    A = M_int + (dt / 2.0) * K_int\n    B = M_int - (dt / 2.0) * K_int\n    \n    # Pre-factorize A\n    lu, piv = lu_factor(A)\n    \n    u_current_full = np.copy(u0)\n\n    for step in range(n_steps):\n        rhs = B @ u_int\n        u_int = lu_solve((lu, piv), rhs)\n        \n        # Update full solution vector and track min/max\n        u_current_full[interior_nodes_indices] = u_int\n        step_min = np.min(u_current_full)\n        step_max = np.max(u_current_full)\n        \n        if step_min  global_min:\n            global_min = step_min\n        if step_max > global_max:\n            global_max = step_max\n\n    # 5. Compute final metrics\n    m = global_min\n    M = global_max\n    \n    nonneg = m >= -TOL\n    \n    if M  TOL:\n        r = 0.0\n    else:\n        r = max(0.0, -m) / M\n        \n    return m, M, nonneg, r\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2607746"}, {"introduction": "The heart of any implicit time-stepping scheme is the solution of a large linear system, $A U^{n+1} = b$, at each step. This final practice elevates the discussion to computational performance, analyzing the best strategies for this critical task [@problem_id:2607774]. You will compare the trade-offs between sparse direct solvers and preconditioned iterative methods, exploring how the effectiveness of a preconditioner changes as the system matrix $A = M + \\theta \\Delta t K$ shifts from being mass-dominated (small $\\Delta t$) to stiffness-dominated (large $\\Delta t$). Mastering this topic is essential for designing efficient and scalable finite element solvers for real-world applications.", "problem": "Consider the transient heat diffusion equation on a bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^d$ with $d \\in \\{2,3\\}$, thermal conductivity $\\kappa(\\boldsymbol{x})0$, heat capacity $c(\\boldsymbol{x})0$, and source $f(\\boldsymbol{x},t)$,\n$$\nc(\\boldsymbol{x})\\,\\partial_t u(\\boldsymbol{x},t) - \\nabla \\cdot \\left(\\kappa(\\boldsymbol{x}) \\nabla u(\\boldsymbol{x},t)\\right) = f(\\boldsymbol{x},t),\n$$\nsubject to either homogeneous Dirichlet or pure Neumann boundary conditions, and appropriate initial data. Let a conforming finite element space $V_h \\subset H^1(\\Omega)$ be given, and denote by $M \\in \\mathbb{R}^{N \\times N}$ the consistent mass matrix and by $K \\in \\mathbb{R}^{N \\times N}$ the stiffness matrix associated with the standard symmetric bilinear forms. Using a uniform time step $\\Delta t0$ and the $\\theta$-method with $\\theta \\in (0,1]$, the fully discrete scheme at time level $n+1$ requires the solution of the linear system\n$$\n\\left(M + \\theta\\,\\Delta t\\,K\\right) U^{n+1} = b^{n+1},\n$$\nwhere $U^{n+1} \\in \\mathbb{R}^N$ is the vector of unknown coefficients. You are asked to compare, from first principles, sparse direct Cholesky factorization and Preconditioned Conjugate Gradient (PCG) iteration for this linear system, and to assess how preconditioners such as Algebraic Multigrid (AMG) behave as $\\Delta t$ varies.\n\nSelect all statements that are correct.\n\nA. For $\\theta \\in (0,1]$ with homogeneous Dirichlet boundary conditions, the matrix $A := M + \\theta\\,\\Delta t\\,K$ is symmetric positive definite (SPD), so both sparse Cholesky and Conjugate Gradient (CG) are applicable. As $\\Delta t$ increases, an AMG preconditioner constructed for $K$ tends to become more effective (fewer PCG iterations), whereas as $\\Delta t \\to 0$ it tends to become less effective unless it is augmented by a mass-based component.\n\nB. For very small $\\Delta t$, the system is dominated by $M$, hence an AMG preconditioner targeting $K$ yields iteration counts that are essentially independent of the mesh size and of $\\Delta t$.\n\nC. In $3$ spatial dimensions, sparse Cholesky factorization has superlinear cost in the number of unknowns $N$ (e.g., factorization time scaling like $O(N^2)$ under nested dissection), while well-implemented PCG with AMG has near-linear $O(N)$ cost per iteration and mesh-independent iteration counts when the preconditioner matches the dominant operator. Therefore, for very large $N$ and moderate-to-large $\\Delta t$, PCG with AMG is typically more scalable than sparse Cholesky.\n\nD. For $\\theta = 1/2$ (Crank–Nicolson), the matrix $A$ is non-symmetric, hence CG cannot be applied.\n\nE. Under pure Neumann boundary conditions, $K$ has a one-dimensional nullspace, but for any $\\Delta t0$ the matrix $A$ remains SPD, so PCG converges. In this case, an AMG preconditioner designed for $K$ is again more effective for large $\\Delta t$ than for small $\\Delta t$.\n\nF. Let $\\{(\\lambda_i,\\phi_i)\\}$ be the generalized eigenpairs of $K$ with respect to $M$, i.e., $K\\phi_i = \\lambda_i\\,M\\phi_i$ with $0 \\le \\lambda_1 \\le \\lambda_2 \\le \\cdots$. Then the eigenvalues of the $M^{-1}$-preconditioned operator $M^{-1}A$ are $\\{1 + \\theta\\,\\Delta t\\,\\lambda_i\\}$; thus an $M^{-1}$-based preconditioner yields a condition number that approaches $1$ as $\\Delta t \\to 0$ and approaches the condition number of $M^{-1}K$ as $\\Delta t \\to \\infty$.\n\nG. If coefficients are time-independent and both $\\theta$ and $\\Delta t$ are fixed, then $A$ is the same at every time step; a single sparse Cholesky factorization can be reused across all steps, reducing each subsequent solve to $2$ triangular substitutions and often outperforming iterative methods when the number of time steps is large, provided sufficient memory is available.", "solution": "The problem statement must first be validated for scientific soundness, self-consistency, and clarity.\n\n**Step 1: Extract Givens**\n- **Governing Equation:** $c(\\boldsymbol{x})\\,\\partial_t u(\\boldsymbol{x},t) - \\nabla \\cdot \\left(\\kappa(\\boldsymbol{x}) \\nabla u(\\boldsymbol{x},t)\\right) = f(\\boldsymbol{x},t)$\n- **Domain:** Bounded Lipschitz domain $\\Omega \\subset \\mathbb{R}^d$ with $d \\in \\{2,3\\}$.\n- **Coefficients:** $\\kappa(\\boldsymbol{x})0$ (thermal conductivity), $c(\\boldsymbol{x})0$ (heat capacity).\n- **Boundary Conditions (BCs):** Homogeneous Dirichlet or pure Neumann.\n- **Initial Conditions:** Appropriate initial data.\n- **Finite Element Discretization:** A conforming finite element space $V_h \\subset H^1(\\Omega)$.\n- **Matrices:** $M$ is the consistent mass matrix, $K$ is the stiffness matrix.\n- **Time Discretization:** The $\\theta$-method with uniform time step $\\Delta t0$ and parameter $\\theta \\in (0,1]$.\n- **Resulting Linear System:** $\\left(M + \\theta\\,\\Delta t\\,K\\right) U^{n+1} = b^{n+1}$, where $A := M + \\theta\\,\\Delta t\\,K$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded. The transient heat equation is a fundamental model in physics and engineering. The use of the finite element method (FEM) for spatial discretization and the $\\theta$-method for time discretization are standard, well-established numerical techniques. The resulting linear system is correctly formulated.\n\nThe problem is well-posed. It asks for an analysis of the properties of the linear system and a comparison of standard numerical linear algebra solution techniques (sparse Cholesky and PCG with AMG). All terms—mass matrix, stiffness matrix, $\\theta$-method, Cholesky factorization, CG, AMG—are well-defined concepts in numerical analysis.\n\nThe problem is objective and self-contained. The provided information is sufficient to analyze the spectral properties of the matrix $A$ and the performance characteristics of the proposed solvers. There are no contradictions, ambiguities, or pseudo-scientific claims.\n\n**Step 3: Verdict and Action**\nThe problem statement is valid. I will proceed with the analysis.\n\n**Core Principles and Derivations**\n\nLet $\\{\\psi_i\\}_{i=1}^N$ be the basis functions of the finite element space $V_h$.\nThe consistent mass matrix $M$ has entries $M_{ij} = \\int_\\Omega c(\\boldsymbol{x})\\,\\psi_j(\\boldsymbol{x})\\,\\psi_i(\\boldsymbol{x})\\,d\\boldsymbol{x}$. Since $c(\\boldsymbol{x})  0$ and the basis functions are linearly independent, $M$ is symmetric positive definite (SPD).\nThe stiffness matrix $K$ has entries $K_{ij} = \\int_\\Omega \\kappa(\\boldsymbol{x})\\,\\nabla\\psi_j(\\boldsymbol{x})\\cdot\\nabla\\psi_i(\\boldsymbol{x})\\,d\\boldsymbol{x}$. Since $\\kappa(\\boldsymbol{x})  0$, $K$ is symmetric positive semi-definite (SPSD).\n- With homogeneous Dirichlet BCs on at least a part of the boundary, the Poincaré inequality holds, making $K$ SPD.\n- With pure Neumann BCs, the constant function lies in the kernel, so $K$ has a one-dimensional nullspace and is only SPSD.\n\nThe system matrix is $A = M + \\theta\\,\\Delta t\\,K$. Since $M$ and $K$ are symmetric, $A$ is symmetric.\nFor any non-zero vector $v \\in \\mathbb{R}^N$, the quadratic form is $v^T A v = v^T M v + \\theta\\,\\Delta t\\,v^T K v$.\nSince $M$ is SPD, $v^T M v  0$. Since $K$ is SPSD and $\\theta\\,\\Delta t  0$, we have $\\theta\\,\\Delta t\\,v^T K v \\ge 0$.\nTherefore, $v^T A v  0$, which proves that $A$ is SPD for any $\\theta \\in (0,1]$, any $\\Delta t  0$, and for both specified types of boundary conditions.\n\n**Option-by-Option Analysis**\n\n**A. For $\\theta \\in (0,1]$ with homogeneous Dirichlet boundary conditions, the matrix $A := M + \\theta\\,\\Delta t\\,K$ is symmetric positive definite (SPD), so both sparse Cholesky and Conjugate Gradient (CG) are applicable. As $\\Delta t$ increases, an AMG preconditioner constructed for $K$ tends to become more effective (fewer PCG iterations), whereas as $\\Delta t \\to 0$ it tends to become less effective unless it is augmented by a mass-based component.**\n\n- **Analysis:** As derived above, with homogeneous Dirichlet BCs, both $M$ and $K$ are SPD. Thus $A = M + \\theta\\,\\Delta t\\,K$ is SPD for $\\theta, \\Delta t  0$. For an SPD system, both Cholesky factorization and the CG method are standard and appropriate choices. This first part of the statement is correct.\nFor the second part, consider an AMG preconditioner $P_{amg}$ designed for $K$, meaning $P_{amg} \\approx K^{-1}$.\n- As $\\Delta t \\to \\infty$, the system matrix $A$ is dominated by the stiffness term: $A \\approx \\theta\\,\\Delta t\\,K$. The preconditioned operator is $P_{amg} A \\approx \\theta\\,\\Delta t\\,P_{amg} K$. The condition number of this operator, $\\kappa(P_{amg} A)$, will be close to $\\kappa(P_{amg} K)$. Since $P_{amg}$ is a good preconditioner for $K$, $\\kappa(P_{amg} K)$ is small and independent of mesh size, leading to few PCG iterations. The preconditioner is effective.\n- As $\\Delta t \\to 0$, the system matrix is dominated by the mass term: $A \\approx M$. The preconditioned operator is $P_{amg} A \\approx P_{amg} M \\approx K^{-1} M$. The condition number of $K^{-1}M$ is equal to the condition number of $M^{-1/2} K^{-1} M^{1/2}$ which is spectrally equivalent to $M^{-1}K$ and scales as $O(h^{-2})$ where $h$ is the mesh size. This large condition number leads to slow convergence (many iterations). The preconditioner is ineffective.\nThe entire statement is consistent with the theory of preconditioning for parabolic problems.\n- **Verdict:** Correct.\n\n**B. For very small $\\Delta t$, the system is dominated by $M$, hence an AMG preconditioner targeting $K$ yields iteration counts that are essentially independent of the mesh size and of $\\Delta t$.**\n\n- **Analysis:** This statement contradicts the conclusion from the analysis of option A. For very small $\\Delta t$, $A \\approx M$. Applying a preconditioner designed for $K$ means we are trying to solve $M u = b$ using a preconditioner for $K$. As shown above, the condition number of the preconditioned system $K^{-1}M$ grows quadratically with the inverse mesh size, i.e., $\\kappa(K^{-1}M) = O(h^{-2})$. The number of CG iterations is proportional to the square root of the condition number, so it scales as $O(h^{-1})$, which is strongly dependent on the mesh size. Therefore, the iteration counts are not independent of the mesh size.\n- **Verdict:** Incorrect.\n\n**C. In $3$ spatial dimensions, sparse Cholesky factorization has superlinear cost in the number of unknowns $N$ (e.g., factorization time scaling like $O(N^2)$ under nested dissection), while well-implemented PCG with AMG has near-linear $O(N)$ cost per iteration and mesh-independent iteration counts when the preconditioner matches the dominant operator. Therefore, for very large $N$ and moderate-to-large $\\Delta t$, PCG with AMG is typically more scalable than sparse Cholesky.**\n\n- **Analysis:** This statement correctly summarizes the asymptotic complexity of the two methods for large $3$D problems.\n- Sparse Cholesky factorization for a $3$D grid-based problem using an optimal ordering like nested dissection has a time complexity of $O(N^2)$ and requires storage for $O(N^{4/3})$ non-zeros in the factor. This is superlinear scaling.\n- A single PCG iteration involves sparse matrix-vector products, vector additions, and dot products, all of which cost $O(N)$. A good AMG preconditioner (one V-cycle) also has a computational cost of $O(N)$. For moderate-to-large $\\Delta t$, the problem is stiffness-dominated, and a standard AMG for $K$ is effective, yielding a number of iterations that is bounded independently of $N$. The total cost for PCG-AMG is therefore approximately $k \\times O(N) = O(N)$, which is near-linear.\n- Comparing $O(N^2)$ for Cholesky to $O(N)$ for PCG-AMG, it is clear that for very large $N$, the iterative method is superior in terms of both computational time and memory scalability.\n- **Verdict:** Correct.\n\n**D. For $\\theta = 1/2$ (Crank–Nicolson), the matrix $A$ is non-symmetric, hence CG cannot be applied.**\n\n- **Analysis:** The system matrix is $A = M + \\theta\\,\\Delta t\\,K$. $M$ and $K$ are symmetric matrices, as established from their definitions in the Galerkin FEM framework. Since $\\theta$ and $\\Delta t$ are scalars, the matrix $A$ is a linear combination of symmetric matrices and is therefore symmetric for any value of $\\theta$, including $\\theta=1/2$. As shown previously, $A$ is also positive definite. Since $A$ is SPD, the Conjugate Gradient (CG) method is not only applicable but is often the iterative method of choice. The statement is baseless.\n- **Verdict:** Incorrect.\n\n**E. Under pure Neumann boundary conditions, $K$ has a one-dimensional nullspace, but for any $\\Delta t0$ the matrix $A$ remains SPD, so PCG converges. In this case, an AMG preconditioner designed for $K$ is again more effective for large $\\Delta t$ than for small $\\Delta t$.**\n\n- **Analysis:** For pure Neumann BCs, the stiffness matrix $K$ is singular; its nullspace is the space of constant functions, which is one-dimensional. This is correct. The system matrix is $A = M + \\theta\\,\\Delta t\\,K$. As established in the preliminary derivation, since $M$ is SPD and $K$ is SPSD, their sum $A$ is SPD for any $\\theta\\,\\Delta t  0$. Since $A$ is SPD, PCG is guaranteed to converge. The second part of the statement concerns the effectiveness of an AMG for $K$. The logic is identical to that presented in the analysis of option A. For large $\\Delta t$, $A \\approx \\theta\\,\\Delta t\\,K$, and the AMG is effective. For small $\\Delta t$, $A \\approx M$, and the AMG is ineffective. The singularity of $K$ is a technical point that must be handled in the construction of the AMG (e.g., in the coarse-grid solver), but it does not invalidate the general conclusion about its varying effectiveness with $\\Delta t$.\n- **Verdict:** Correct.\n\n**F. Let $\\{(\\lambda_i,\\phi_i)\\}$ be the generalized eigenpairs of $K$ with respect to $M$, i.e., $K\\phi_i = \\lambda_i\\,M\\phi_i$ with $0 \\le \\lambda_1 \\le \\lambda_2 \\le \\cdots$. Then the eigenvalues of the $M^{-1}$-preconditioned operator $M^{-1}A$ are $\\{1 + \\theta\\,\\Delta t\\,\\lambda_i\\}$; thus an $M^{-1}$-based preconditioner yields a condition number that approaches $1$ as $\\Delta t \\to 0$ and approaches the condition number of $M^{-1}K$ as $\\Delta t \\to \\infty$.**\n\n- **Analysis:** Let us verify the eigenvalues of the preconditioned operator $M^{-1}A = M^{-1}(M + \\theta\\,\\Delta t\\,K) = I + \\theta\\,\\Delta t\\,M^{-1}K$.\nApplying this to a generalized eigenvector $\\phi_i$ gives:\n$(I + \\theta\\,\\Delta t\\,M^{-1}K)\\phi_i = \\phi_i + \\theta\\,\\Delta t\\,M^{-1}(K\\phi_i) = \\phi_i + \\theta\\,\\Delta t\\,M^{-1}(\\lambda_i M\\phi_i) = \\phi_i + \\theta\\,\\Delta t\\,\\lambda_i \\phi_i = (1 + \\theta\\,\\Delta t\\,\\lambda_i)\\phi_i$.\nSo, the eigenvalues are indeed $\\mu_i = 1 + \\theta\\,\\Delta t\\,\\lambda_i$.\nThe condition number of the preconditioned system is $\\kappa(M^{-1}A) = \\frac{\\max_i \\mu_i}{\\min_i \\mu_i} = \\frac{1 + \\theta\\,\\Delta t\\,\\lambda_{max}}{1 + \\theta\\,\\Delta t\\,\\lambda_{min}}$.\nAs $\\Delta t \\to 0$, we have $\\kappa(M^{-1}A) \\to \\frac{1+0}{1+0} = 1$.\nAs $\\Delta t \\to \\infty$, the constant $1$ becomes negligible, and $\\kappa(M^{-1}A) \\approx \\frac{\\theta\\,\\Delta t\\,\\lambda_{max}}{\\theta\\,\\Delta t\\,\\lambda_{min}} = \\frac{\\lambda_{max}}{\\lambda_{min}} = \\kappa(M^{-1}K)$.\nThe entire mathematical derivation and conclusion are correct.\n- **Verdict:** Correct.\n\n**G. If coefficients are time-independent and both $\\theta$ and $\\Delta t$ are fixed, then $A$ is the same at every time step; a single sparse Cholesky factorization can be reused across all steps, reducing each subsequent solve to $2$ triangular substitutions and often outperforming iterative methods when the number of time steps is large, provided sufficient memory is available.**\n\n- **Analysis:** The PDE coefficients $\\kappa(\\boldsymbol{x})$ and $c(\\boldsymbol{x})$ are independent of time, so the matrices $M$ and $K$ are constant. With fixed $\\theta$ and $\\Delta t$, the system matrix $A = M + \\theta\\,\\Delta t\\,K$ is also constant throughout the time-stepping procedure.\nThis allows for a \"factorize-once, solve-many\" strategy with a direct solver. The computationally expensive factorization $A = LL^T$ is performed once. Each subsequent time step requires only the solution of $LL^T U^{n+1} = b^{n+1}$, which involves one forward and one backward substitution. The cost of these substitutions is significantly lower than the cost of the initial factorization.\nWhen the number of time steps is large, the high initial factorization cost is amortized, and the per-step cost can be very competitive against an iterative solver, which must perform iterations at every single step. The primary limitations of this direct approach are the high memory requirement for the factor $L$ and the high upfront cost of factorization, especially in $3$D. The statement correctly identifies these key practical considerations (\"often outperforming\" and \"provided sufficient memory is available\").\n- **Verdict:** Correct.", "answer": "$$\\boxed{ACEFG}$$", "id": "2607774"}]}