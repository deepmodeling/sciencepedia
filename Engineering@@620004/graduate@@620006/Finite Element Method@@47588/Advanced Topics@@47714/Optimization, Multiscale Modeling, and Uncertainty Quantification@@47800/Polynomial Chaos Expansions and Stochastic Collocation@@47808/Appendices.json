{"hands_on_practices": [{"introduction": "Before applying a Polynomial Chaos Expansion (PCE), one must first decide which polynomial terms to include in the basis. This choice directly determines the computational cost of the method and represents a fundamental trade-off between accuracy and tractability. This exercise provides direct, hands-on experience in quantifying the so-called \"curse of dimensionality\" by comparing the size of different basis truncation schemes—total-degree, tensor-product, and hyperbolic-cross—for a given dimension $d$ and polynomial degree $p$ [@problem_id:2589483].", "problem": "Consider a stochastic parametric model solved by the finite element method, where the parametric dependence is represented by a Polynomial Chaos Expansion (PCE) in terms of orthonormal multivariate polynomials in $d$ independent random variables. Let the multivariate basis be indexed by multi-indices $\\boldsymbol{\\alpha}=(\\alpha_{1},\\dots,\\alpha_{d}) \\in \\mathbb{N}_{0}^{d}$, where $\\mathbb{N}_{0}$ denotes the set of nonnegative integers. Three common truncation index sets for PCE and stochastic collocation are defined as follows:\n- The total-degree set $\\mathcal{A}_{\\mathrm{TD}}(p)$ contains all $\\boldsymbol{\\alpha}$ such that $\\sum_{i=1}^{d} \\alpha_{i} \\leq p$.\n- The hyperbolic-cross set with quasi-norm parameter $q \\in (0,1]$, denoted $\\mathcal{A}_{\\mathrm{HC},q}(p)$, contains all $\\boldsymbol{\\alpha}$ such that $\\left(\\sum_{i=1}^{d} \\alpha_{i}^{q}\\right)^{1/q} \\leq p$.\n- The tensor-product set $\\mathcal{A}_{\\mathrm{TP}}(p)$ contains all $\\boldsymbol{\\alpha}$ such that $0 \\leq \\alpha_{i} \\leq p$ for all $i \\in \\{1,\\dots,d\\}$.\n\nThese truncations determine the number of multivariate basis functions and hence the computational complexity of associated stochastic collocation rules.\n\nFor dimension $d=5$, polynomial truncation level $p=3$, and hyperbolic-cross quasi-norm parameter $q=0.5$, compute the cardinalities $\\left|\\mathcal{A}_{\\mathrm{TD}}(p)\\right|$, $\\left|\\mathcal{A}_{\\mathrm{HC},q}(p)\\right|$, and $\\left|\\mathcal{A}_{\\mathrm{TP}}(p)\\right|$. Report your final answer as a single row matrix in the order $\\left(\\left|\\mathcal{A}_{\\mathrm{TD}}(p)\\right|,\\left|\\mathcal{A}_{\\mathrm{HC},q}(p)\\right|,\\left|\\mathcal{A}_{\\mathrm{TP}}(p)\\right|\\right)$. No rounding is required and no units are involved.", "solution": "The problem requires the computation of the cardinalities of three distinct types of index sets used for truncating Polynomial Chaos Expansions. The given parameters are the number of stochastic dimensions $d=5$, the maximum polynomial degree $p=3$, and the quasi-norm parameter for the hyperbolic-cross set $q=0.5$. We shall compute the cardinality for each set based on its mathematical definition.\n\nFirst, we analyze the total-degree index set, $\\mathcal{A}_{\\mathrm{TD}}(p)$, defined by:\n$$ \\mathcal{A}_{\\mathrm{TD}}(p) = \\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d} \\mid \\sum_{i=1}^{d} \\alpha_{i} \\leq p \\} $$\nThe cardinality of this set, $\\left|\\mathcal{A}_{\\mathrm{TD}}(p)\\right|$, corresponds to the number of non-negative integer solutions to the Diophantine inequality $\\alpha_{1} + \\dots + \\alpha_{d} \\leq p$. This is a classic combinatorial problem that can be solved by introducing a slack variable $\\alpha_{d+1} \\in \\mathbb{N}_{0}$ to transform the inequality into an equality: $\\alpha_{1} + \\dots + \\alpha_{d} + \\alpha_{d+1} = p$. The number of solutions is given by the multiset coefficient, or \"stars and bars\" formula, $\\binom{p+d}{d}$.\nWith the given values $d=5$ and $p=3$, the cardinality is:\n$$ \\left|\\mathcal{A}_{\\mathrm{TD}}(3)\\right| = \\binom{3+5}{5} = \\binom{8}{5} $$\nThe value of this binomial coefficient is:\n$$ \\binom{8}{5} = \\frac{8!}{5!(8-5)!} = \\frac{8!}{5!3!} = \\frac{8 \\times 7 \\times 6}{3 \\times 2 \\times 1} = 56 $$\n\nSecond, we analyze the tensor-product index set, $\\mathcal{A}_{\\mathrm{TP}}(p)$, defined by:\n$$ \\mathcal{A}_{\\mathrm{TP}}(p) = \\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d} \\mid 0 \\leq \\alpha_{i} \\leq p \\text{ for all } i \\in \\{1,\\dots,d\\} \\} $$\nFor each of the $d$ components $\\alpha_{i}$ of the multi-index $\\boldsymbol{\\alpha}$, there are $p+1$ possible integer values (from $0$ to $p$). Since the choices for each component are independent, the total number of combinations is the product of the number of choices for each component. Therefore, the cardinality is:\n$$ \\left|\\mathcal{A}_{\\mathrm{TP}}(p)\\right| = (p+1)^{d} $$\nSubstituting the given values $d=5$ and $p=3$, we obtain:\n$$ \\left|\\mathcal{A}_{\\mathrm{TP}}(3)\\right| = (3+1)^{5} = 4^{5} = 1024 $$\n\nThird, we analyze the hyperbolic-cross index set, $\\mathcal{A}_{\\mathrm{HC},q}(p)$, defined by:\n$$ \\mathcal{A}_{\\mathrm{HC},q}(p) = \\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d} \\mid \\left(\\sum_{i=1}^{d} \\alpha_{i}^{q}\\right)^{1/q} \\leq p \\} $$\nWith $d=5$, $p=3$, and $q=0.5 = \\frac{1}{2}$, the defining inequality becomes:\n$$ \\left(\\sum_{i=1}^{5} \\alpha_{i}^{0.5}\\right)^{1/0.5} \\leq 3 $$\nThis simplifies to:\n$$ \\left(\\sum_{i=1}^{5} \\sqrt{\\alpha_i}\\right)^{2} \\leq 3 $$\nSince the sum of square roots of non-negative integers is non-negative, we can take the square root of both sides to get:\n$$ \\sum_{i=1}^{5} \\sqrt{\\alpha_i} \\leq \\sqrt{3} $$\nWe must enumerate all multi-indices $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4, \\alpha_5)$ with $\\alpha_i \\in \\mathbb{N}_0$ satisfying this condition. Note that $\\sqrt{3} \\approx 1.732$.\nIf any two or more components of $\\boldsymbol{\\alpha}$ are non-zero, say $\\alpha_j \\geq 1$ and $\\alpha_k \\geq 1$ for $j \\neq k$, the sum of their square roots would be at least $\\sqrt{1} + \\sqrt{1} = 2$. Since $2 > \\sqrt{3}$, no such multi-index can satisfy the condition. Therefore, at most one component of $\\boldsymbol{\\alpha}$ can be non-zero. We analyze the two possible cases:\n\nCase 1: Exactly zero non-zero components.\nThis corresponds to the trivial multi-index $\\boldsymbol{\\alpha} = (0,0,0,0,0)$. The sum is $0$, which satisfies $0 \\leq \\sqrt{3}$. This gives $1$ solution.\n\nCase 2: Exactly one non-zero component.\nLet one component $\\alpha_k$ be a positive integer, while all other components are zero. The condition reduces to $\\sqrt{\\alpha_k} \\leq \\sqrt{3}$, which implies $\\alpha_k \\leq 3$. The possible integer values for $\\alpha_k$ are thus $1$, $2$, and $3$. There are $\\binom{5}{1} = 5$ choices for the position $k$ of the non-zero component. For each choice of position, there are $3$ possible values for $\\alpha_k$. The total number of solutions in this case is $5 \\times 3 = 15$.\n\nCombining the disjoint cases, the total cardinality of the hyperbolic-cross set is:\n$$ \\left|\\mathcal{A}_{\\mathrm{HC},0.5}(3)\\right| = 1 + 15 = 16 $$\n\nThe final results for the cardinalities are $56$, $16$, and $1024$, for the total-degree, hyperbolic-cross, and tensor-product sets, respectively.", "answer": "$$\n\\boxed{\\begin{pmatrix} 56 & 16 & 1024 \\end{pmatrix}}\n$$", "id": "2589483"}, {"introduction": "Once a basis is chosen, the next challenge is to compute the expansion coefficients. Non-intrusive methods like stochastic collocation are popular because they treat the computational model as a \"black box,\" but this convenience can hide a significant pitfall known as aliasing. This exercise guides you through a crucial theoretical derivation to reveal how higher-order modes can contaminate the estimates of lower-order coefficients and establishes the minimal quadrature accuracy $r$ required to guarantee alias-free projections for a given PCE degree $p$ [@problem_id:2589464].", "problem": "A parametric elliptic boundary value problem is solved by the Finite Element Method (FEM) for each realization of a random input vector $\\boldsymbol{\\xi} \\in \\mathbb{R}^{d}$ with joint probability density $\\rho(\\boldsymbol{\\xi})$. Let $u(\\boldsymbol{\\xi})$ denote a scalar Quantity of Interest (QoI) extracted from the FEM solution. Consider an expansion of $u(\\boldsymbol{\\xi})$ in a generalized Polynomial Chaos Expansion (PCE) with orthonormal basis $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})\\}_{\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d}}$ with respect to $\\rho(\\boldsymbol{\\xi})$, and truncate this expansion to the total-degree $p$ multi-index set $\\Lambda_{p} := \\{\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d} : |\\boldsymbol{\\alpha}| \\le p\\}$, where $|\\boldsymbol{\\alpha}| := \\sum_{i=1}^{d} \\alpha_{i}$. The coefficient of mode $\\boldsymbol{\\alpha} \\in \\Lambda_{p}$ is defined by the orthogonal projection $c_{\\boldsymbol{\\alpha}} := \\int_{\\mathbb{R}^{d}} u(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) \\rho(\\boldsymbol{\\xi}) \\,\\mathrm{d}\\boldsymbol{\\xi}$.\n\nIn a non-intrusive stochastic collocation setting, one estimates $c_{\\boldsymbol{\\alpha}}$ using a quadrature rule $\\{(\\boldsymbol{\\xi}^{(q)}, w^{(q)})\\}_{q=1}^{Q}$ that is exact for all multivariate polynomials of total degree up to an integer $r \\ge 0$. That is, for any polynomial $p(\\boldsymbol{\\xi})$ of total degree $\\le r$,\n$\\int_{\\mathbb{R}^{d}} p(\\boldsymbol{\\xi}) \\rho(\\boldsymbol{\\xi}) \\,\\mathrm{d}\\boldsymbol{\\xi} = \\sum_{q=1}^{Q} w^{(q)} p(\\boldsymbol{\\xi}^{(q)})$.\nThe non-intrusive estimator is $\\widehat{c}_{\\boldsymbol{\\alpha}} := \\sum_{q=1}^{Q} w^{(q)} u(\\boldsymbol{\\xi}^{(q)}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}^{(q)})$.\n\nStarting from the definitions of orthogonality and projection, explain the mechanism by which aliasing arises in $\\widehat{c}_{\\boldsymbol{\\alpha}}$ when the quadrature exactness parameter $r$ is insufficient. Then, by requiring that the discrete inner products mimic the continuous orthogonality for all products $\\Psi_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\beta}}$ with $|\\boldsymbol{\\alpha}| \\le p$ and $|\\boldsymbol{\\beta}| \\le p$, derive the minimal total polynomial degree $r$ (expressed as a function of $p$) that guarantees no aliasing in the non-intrusive estimation of all coefficients $c_{\\boldsymbol{\\alpha}}$ with $|\\boldsymbol{\\alpha}| \\le p$.\n\nExpress your final answer as a single closed-form expression in terms of $p$. No units are required.", "solution": "The problem requires an explanation of the aliasing mechanism in non-intrusive Polynomial Chaos Expansion (PCE) coefficient estimation and the derivation of a minimal quadrature exactness to prevent it under specific conditions.\n\nFirst, we analyze the source of aliasing error. The exact coefficient $c_{\\boldsymbol{\\alpha}}$ for the mode $\\boldsymbol{\\alpha}$ is given by the orthogonal projection of the Quantity of Interest (QoI) $u(\\boldsymbol{\\xi})$ onto the basis polynomial $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$. This projection is defined by the inner product with respect to the probability measure $\\rho(\\boldsymbol{\\xi})\\mathrm{d}\\boldsymbol{\\xi}$:\n$$c_{\\boldsymbol{\\alpha}} := \\langle u, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\int_{\\mathbb{R}^{d}} u(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) \\rho(\\boldsymbol{\\xi}) \\,\\mathrm{d}\\boldsymbol{\\xi}$$\nThe non-intrusive estimator, $\\widehat{c}_{\\boldsymbol{\\alpha}}$, replaces this continuous integral with a discrete sum based on a quadrature rule $\\{(\\boldsymbol{\\xi}^{(q)}, w^{(q)})\\}_{q=1}^{Q}$:\n$$\\widehat{c}_{\\boldsymbol{\\alpha}} := \\sum_{q=1}^{Q} w^{(q)} u(\\boldsymbol{\\xi}^{(q)}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}^{(q)})$$\nThis estimator can be viewed as a discrete inner product, which we denote by $\\langle f, g \\rangle_Q := \\sum_{q=1}^{Q} w^{(q)} f(\\boldsymbol{\\xi}^{(q)}) g(\\boldsymbol{\\xi}^{(q)})$. Thus, $\\widehat{c}_{\\boldsymbol{\\alpha}} = \\langle u, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$.\n\nTo understand the error, we substitute the full PCE representation of the QoI, $u(\\boldsymbol{\\xi}) = \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})$, into the expression for $\\widehat{c}_{\\boldsymbol{\\alpha}}$:\n$$\\widehat{c}_{\\boldsymbol{\\alpha}} = \\sum_{q=1}^{Q} w^{(q)} \\left( \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi}^{(q)}) \\right) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}^{(q)})$$\nBy interchanging the order of summation, which is permissible, we obtain:\n$$\\widehat{c}_{\\boldsymbol{\\alpha}} = \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\left( \\sum_{q=1}^{Q} w^{(q)} \\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi}^{(q)}) \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}^{(q)}) \\right) = \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$$\nFor comparison, the exact coefficient $c_{\\boldsymbol{\\alpha}}$ is recovered from the full expansion using the *continuous* orthogonality of the basis, $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$:\n$$c_{\\boldsymbol{\\alpha}} = \\langle u, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\left\\langle \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\right\\rangle = \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\sum_{\\boldsymbol{\\beta} \\in \\mathbb{N}_{0}^{d}} c_{\\boldsymbol{\\beta}} \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}} = c_{\\boldsymbol{\\alpha}}$$\nThe discrepancy between $\\widehat{c}_{\\boldsymbol{\\alpha}}$ and $c_{\\boldsymbol{\\alpha}}$ arises when the discrete inner product $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$ does not equal the continuous inner product $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$. The quadrature rule is exact for any polynomial integrand of total degree up to $r$. The integrand for the inner product $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle$ is the product $\\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi})$. Since $\\Psi_{\\boldsymbol{\\gamma}}$ is a polynomial of total degree $|\\boldsymbol{\\gamma}|$, the degree of this product is $|\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}|$.\nIf $|\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}| > r$, the quadrature rule may not be exact, and consequently $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$ may not equal $\\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$. In this case, the expression for the estimated coefficient becomes:\n$$\\widehat{c}_{\\boldsymbol{\\alpha}} = c_{\\boldsymbol{\\alpha}} \\langle \\Psi_{\\boldsymbol{\\alpha}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q + \\sum_{\\boldsymbol{\\beta} \\neq \\boldsymbol{\\alpha}} c_{\\boldsymbol{\\beta}} \\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$$\nEven if $|\\boldsymbol{\\alpha}|+|\\boldsymbol{\\alpha}| \\le r$ (ensuring $\\langle \\Psi_{\\boldsymbol{\\alpha}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q = 1$), a non-zero value for $\\langle \\Psi_{\\boldsymbol{\\beta}}, \\Psi_{\\boldsymbol{\\alpha}} \\rangle_Q$ where $\\boldsymbol{\\beta} \\neq \\boldsymbol{\\alpha}$ means that the coefficient $c_{\\boldsymbol{\\beta}}$ erroneously contributes to the estimate of $c_{\\boldsymbol{\\alpha}}$. This phenomenon is called aliasing: higher-order or different-order modes \"fold over\" and contaminate the estimation of the target mode due to the insufficiency of the discrete sampling.\n\nNext, we derive the minimal quadrature exactness $r$ required to prevent aliasing under the conditions specified. The problem defines \"no aliasing\" for the coefficients $\\{c_{\\boldsymbol{\\alpha}}\\}_{|\\boldsymbol{\\alpha}| \\le p}$ by the strict requirement that the discrete inner products mimic continuous orthogonality for all basis functions within the truncated expansion of degree $p$. That is, we must enforce:\n$$\\langle \\Psi_{\\boldsymbol{\\alpha}}, \\Psi_{\\boldsymbol{\\beta}} \\rangle_Q = \\langle \\Psi_{\\boldsymbol{\\alpha}}, \\Psi_{\\boldsymbol{\\beta}} \\rangle = \\delta_{\\boldsymbol{\\alpha}\\boldsymbol{\\beta}}$$\nfor all multi-indices $\\boldsymbol{\\alpha}$ and $\\boldsymbol{\\beta}$ in the set $\\Lambda_p = \\{\\boldsymbol{\\gamma} \\in \\mathbb{N}_0^d : |\\boldsymbol{\\gamma}| \\le p\\}$.\nFor the quadrature rule to exactly compute the integral defining the continuous inner product, the total degree of the integrand polynomial must not exceed the quadrature's degree of exactness, $r$. The integrand is $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\xi}) \\Psi_{\\boldsymbol{\\beta}}(\\boldsymbol{\\xi})$. The total degree of this polynomial is:\n$$\\text{deg}(\\Psi_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\beta}}) = \\text{deg}(\\Psi_{\\boldsymbol{\\alpha}}) + \\text{deg}(\\Psi_{\\boldsymbol{\\beta}}) = |\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}|$$\nTo satisfy the no-aliasing condition for all specified pairs $(\\boldsymbol{\\alpha}, \\boldsymbol{\\beta})$, the quadrature degree $r$ must be greater than or equal to the maximum possible degree of these integrand products. We must therefore find the maximum value of $|\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}|$ over the allowed range for the multi-indices:\n$$\\max \\{|\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}| \\;\\; | \\;\\; |\\boldsymbol{\\alpha}| \\le p \\text{ and } |\\boldsymbol{\\beta}| \\le p \\}$$\nThis maximum is achieved when $|\\boldsymbol{\\alpha}|$ and $|\\boldsymbol{\\beta}|$ are individually maximized. The maximum value for $|\\boldsymbol{\\alpha}|$ in the set $\\Lambda_p$ is $p$, and similarly, the maximum value for $|\\boldsymbol{\\beta}|$ is $p$.\nTherefore, the maximum value of the sum of the degrees is:\n$$\\max (|\\boldsymbol{\\alpha}| + |\\boldsymbol{\\beta}|) = p + p = 2p$$\nTo guarantee that the quadrature is exact for all products $\\Psi_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\beta}}$ with $|\\boldsymbol{\\alpha}| \\le p$ and $|\\boldsymbol{\\beta}| \\le p$, we must require the degree of exactness $r$ to satisfy $r \\ge 2p$.\nThe minimal integer value for $r$ that satisfies this condition is $2p$. This choice of $r$ ensures that for any two basis functions in the degree-$p$ expansion, their discrete inner product correctly evaluates to the Kronecker delta, thereby preventing aliasing from other modes *within the same degree-$p$ expansion*. It is important to note that this does not prevent aliasing from modes $\\boldsymbol{\\beta}$ with $|\\boldsymbol{\\beta}| > p$, as those could produce products $\\Psi_{\\boldsymbol{\\alpha}}\\Psi_{\\boldsymbol{\\beta}}$ of degree higher than $2p$. However, based on the problem's explicit requirement, this is the minimal value.", "answer": "$$\\boxed{2p}$$", "id": "2589464"}, {"introduction": "Many real-world problems involve uncertainties that are functions of space or time, such as a random material property field, which are technically infinite-dimensional. To make such problems tractable for PCE, we must first represent the random field using a finite number of random variables. This computational practice guides you through implementing the Nyström method to numerically solve for the eigenvalues of the Karhunen-Loève (KL) expansion, the standard technique for optimal dimensionality reduction of random fields [@problem_id:2589474].", "problem": "Consider a zero-mean Gaussian random field over the one-dimensional spatial domain $[0,1]$ with stationary covariance kernel $C(x,y)=\\sigma^2 \\exp(-|x-y|/\\ell)$, where $\\sigma^2>0$ is the variance and $\\ell>0$ is the correlation length. In uncertainty quantification for the Finite Element Method (FEM), it is common to parameterize such a random field via the Karhunen–Loève (KL) expansion and then build a Polynomial Chaos Expansion (PCE) or a Stochastic Collocation (SC) surrogate in the reduced stochastic space spanned by the dominant KL modes.\n\nYour tasks are as follows:\n\n1) Start from the definition of the KL expansion as the spectral decomposition of the covariance integral operator: find eigenpairs $\\{\\lambda_n,\\phi_n(x)\\}$ solving the integral equation\n$$\n\\int_0^1 C(x,y)\\,\\phi_n(y)\\,\\mathrm{d}y=\\lambda_n\\,\\phi_n(x),\\quad x\\in[0,1],\n$$\nwith eigenfunctions $\\{\\phi_n\\}$ that are orthonormal in $L^2([0,1])$. The truncated KL expansion of the field is then\n$$\nX_M(x,\\omega)=\\sum_{n=1}^M \\sqrt{\\lambda_n}\\,\\phi_n(x)\\,\\xi_n(\\omega),\n$$\nwhere $\\{\\xi_n\\}$ are independent standard normal random variables. The total integrated variance of the field equals the trace of the covariance operator:\n$$\n\\sum_{n=1}^\\infty \\lambda_n=\\int_0^1 C(x,x)\\,\\mathrm{d}x=\\sigma^2.\n$$\n\n2) Devise and implement a numerical Nyström discretization of the integral eigenvalue problem using Gauss–Legendre quadrature with $N=200$ nodes on $[0,1]$. Map the standard Gauss–Legendre nodes and weights from $[-1,1]$ to $[0,1]$ to obtain nodes $\\{x_i\\}_{i=1}^N$ and positive weights $\\{w_i\\}_{i=1}^N$. Form the symmetric matrix\n$$\nA_{ij}=\\sqrt{w_i}\\,C(x_i,x_j)\\,\\sqrt{w_j},\n$$\nwhose eigenvalues approximate the KL eigenvalues $\\{\\lambda_n\\}$ of the covariance operator. Ensure that numerical round-off does not produce negative eigenvalues by setting negative values that are smaller in magnitude than machine tolerance to zero.\n\n3) For each parameter pair $(\\sigma^2,\\ell)$ in the test suite below, compute:\n- The first $5$ largest eigenvalues, ordered non-increasingly.\n- The minimal integer $M$ such that the cumulative fraction of the total integrated variance captured by the first $M$ eigenvalues is at least $0.95$, i.e.,\n$$\n\\frac{\\sum_{n=1}^M \\lambda_n}{\\sum_{n=1}^\\infty \\lambda_n}\\ge 0.95.\n$$\nTreat the denominator as the numerically computed sum over all $N$ discrete eigenvalues. Report $M$ as an integer and report eigenvalues as real numbers rounded to $10$ decimal places.\n\n4) Interpret $M$ as the minimal KL truncation dimension required to parameterize the random field for a surrogate based on Polynomial Chaos Expansion (PCE) or Stochastic Collocation (SC) in an FEM-based uncertainty quantification workflow.\n\nUse the following test suite of parameter values:\n- Case $1$: $(\\sigma^2,\\ell)=(1.0,\\,0.2)$.\n- Case $2$: $(\\sigma^2,\\ell)=(1.0,\\,0.05)$.\n- Case $3$: $(\\sigma^2,\\ell)=(2.0,\\,0.3)$.\n- Case $4$: $(\\sigma^2,\\ell)=(0.5,\\,1.0)$.\n\nYour program must:\n- Implement the Gauss–Legendre Nyström method with $N=200$ nodes on $[0,1]$ to build and diagonalize the matrix $A$ for each case.\n- For each case, compute the minimal $M$ satisfying the $0.95$ threshold and the first $5$ eigenvalues.\n- Produce a single line of output containing the results for all cases as a comma-separated list of lists, each inner list in the form $[M,\\lambda_1,\\lambda_2,\\lambda_3,\\lambda_4,\\lambda_5]$ with eigenvalues rounded to $10$ decimal places.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is an inner list of $6$ numbers as specified above. For example, an admissible format is\n$[[M_1,\\lambda_{1,1},\\ldots,\\lambda_{1,5}],[M_2,\\lambda_{2,1},\\ldots,\\lambda_{2,5}],\\ldots]$.\n- No additional text should be printed.", "solution": "The problem requires the numerical solution of a Fredholm integral eigenvalue equation of the second kind, which arises in the Karhunen-Loève (KL) expansion of a Gaussian random field. The objective is to determine the principal eigenvalues of the covariance operator and to find the necessary truncation order $M$ of the KL expansion to capture a specified fraction of the total variance. This is a foundational step in uncertainty quantification, particularly for constructing surrogate models like Polynomial Chaos Expansions (PCE) or using Stochastic Collocation (SC) methods.\n\nThe governing integral equation is:\n$$\n\\int_0^1 C(x,y)\\,\\phi_n(y)\\,\\mathrm{d}y=\\lambda_n\\,\\phi_n(x),\\quad x\\in[0,1]\n$$\nwhere the covariance kernel is given by $C(x,y)=\\sigma^2 \\exp(-|x-y|/\\ell)$. This kernel is symmetric and, for $\\sigma^2>0$ and $\\ell>0$, positive definite. The corresponding integral operator is therefore a compact, self-adjoint, and positive-definite operator on the Hilbert space $L^2([0,1])$. From the spectral theorem for such operators, there exists a countable set of positive eigenvalues $\\{\\lambda_n\\}_{n=1}^{\\infty}$ that converge to zero, and the corresponding eigenfunctions $\\{\\phi_n(x)\\}_{n=1}^{\\infty}$ form a complete orthonormal basis for $L^2([0,1])$.\n\nTo solve this equation numerically, we employ the Nyström method. The integral is approximated using a numerical quadrature rule. The problem specifies Gauss-Legendre quadrature with $N=200$ points. The integral equation is thus transformed into a system of linear equations at the quadrature nodes $\\{x_i\\}_{i=1}^N$:\n$$\n\\sum_{j=1}^N w_j C(x_i,x_j)\\,\\phi_n(x_j) \\approx \\lambda_n\\,\\phi_n(x_i), \\quad i=1, \\dots, N\n$$\nHere, $\\{x_j\\}_{j=1}^N$ and $\\{w_j\\}_{j=1}^N$ are the quadrature nodes and weights, respectively, mapped to the interval $[0,1]$. This system represents a matrix eigenvalue problem. However, the matrix with entries $D_{ij} = w_j C(x_i,x_j)$ is not symmetric. To restore symmetry, which is a crucial property of the original operator, we introduce a change of variables. Let $v_{nj} = \\sqrt{w_j}\\,\\phi_n(x_j)$. Substituting $\\phi_n(x_j) = v_{nj}/\\sqrt{w_j}$ into the discretized equation yields:\n$$\n\\sum_{j=1}^N w_j C(x_i,x_j)\\,\\frac{v_{nj}}{\\sqrt{w_j}} \\approx \\lambda_n \\, \\frac{v_{ni}}{\\sqrt{w_i}}\n$$\nMultiplying both sides by $\\sqrt{w_i}$ gives a symmetric eigenvalue problem:\n$$\n\\sum_{j=1}^N \\left(\\sqrt{w_i}\\,C(x_i,x_j)\\,\\sqrt{w_j}\\right)\\,v_{nj} \\approx \\lambda_n \\, v_{ni}\n$$\nThis is in the standard form $A\\mathbf{v}_n = \\lambda_n\\mathbf{v}_n$, with the symmetric matrix $A$ defined by its entries\n$$\nA_{ij} = \\sqrt{w_i}\\,C(x_i,x_j)\\,\\sqrt{w_j}\n$$\nThe eigenvalues of this $N \\times N$ matrix $A$ are our numerical approximations for the eigenvalues $\\{\\lambda_n\\}$ of the original covariance operator.\n\nThe Gauss-Legendre quadrature nodes $\\{\\hat{x}_i\\}$ and weights $\\{\\hat{w}_i\\}$ are conventionally defined on the interval $[-1,1]$. A linear affine transformation is used to map them to the domain $[0,1]$:\n$$\nx_i = \\frac{1}{2}(\\hat{x}_i+1), \\quad w_i = \\frac{1}{2}\\hat{w}_i\n$$\n\nThe computational procedure for each pair of parameters $(\\sigma^2, \\ell)$ is as follows:\n1.  Generate $N=200$ Gauss-Legendre nodes and weights on $[-1,1]$ using a standard library function.\n2.  Map these nodes and weights to the interval $[0,1]$ using the transformation above.\n3.  Construct the $N \\times N$ covariance matrix $K$ with entries $K_{ij} = C(x_i, x_j)$.\n4.  Construct the symmetric Nyström matrix $A$ as $A_{ij} = \\sqrt{w_i} K_{ij} \\sqrt{w_j}$.\n5.  Solve the eigenvalue problem for $A$ to obtain the numerical eigenvalues $\\{\\lambda_n\\}_{n=1}^N$. As the theoretical operator is positive definite, any computed negative eigenvalues are numerical artifacts. We set any eigenvalue $\\lambda < 0$ to $0$.\n6.  The eigenvalues are sorted in non-increasing order: $\\lambda_1 \\ge \\lambda_2 \\ge \\dots \\ge \\lambda_N \\ge 0$.\n7.  The total integrated variance is approximated by the sum of all numerical eigenvalues, $V_{total} = \\sum_{n=1}^N \\lambda_n$. This sum is a discrete analogue of $\\int_0^1 C(x,x)\\,\\mathrm{d}x = \\sigma^2$ and, due to the properties of Gauss-Legendre quadrature, provides a highly accurate estimate of it.\n8.  The minimal truncation dimension $M$ is determined. It is the smallest integer for which the cumulative sum of eigenvalues captures at least $95\\%$ of the total variance:\n$$\nM = \\min \\left\\{ k \\in \\mathbb{Z}^+ \\, \\Big| \\, \\frac{\\sum_{n=1}^k \\lambda_n}{\\sum_{n=1}^N \\lambda_n} \\ge 0.95 \\right\\}\n$$\nThis value $M$ dictates the number of stochastic dimensions required for an accurate and efficient representation of the random field in PCE or SC frameworks. A smaller correlation length $\\ell$ implies that the field is more \"rough\" or decorrelated, leading to a slower decay of eigenvalues and thus requiring a larger $M$. Conversely, a larger $\\ell$ results in a smoother field, faster eigenvalue decay, and a smaller required $M$.\n\nThe program provided implements this procedure to compute $M$ and the first five largest eigenvalues, $\\{\\lambda_n\\}_{n=1}^5$, for each specified test case.", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes the Karhunen-Loève eigenvalues for a given covariance kernel\n    using the Nyström method with Gauss-Legendre quadrature.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1.0, 0.2),   # Case 1: (sigma^2, ell)\n        (1.0, 0.05),  # Case 2\n        (2.0, 0.3),   # Case 3\n        (0.5, 1.0),   # Case 4\n    ]\n    N = 200\n\n    results = []\n    for sigma2, ell in test_cases:\n        # Step 1: Generate Gauss-Legendre nodes and weights mapped to [0, 1]\n        # roots_legendre returns nodes and weights on [-1, 1]\n        nodes_std, weights_std = roots_legendre(N)\n        # Map nodes and weights to [0, 1]\n        nodes = 0.5 * (nodes_std + 1)\n        weights = 0.5 * weights_std\n\n        # Step 2: Construct the covariance matrix C(x_i, x_j)\n        # Use broadcasting to efficiently compute the distance matrix |x_i - x_j|\n        dist_matrix = np.abs(nodes[:, np.newaxis] - nodes[np.newaxis, :])\n        cov_matrix = sigma2 * np.exp(-dist_matrix / ell)\n\n        # Step 3: Construct the symmetric Nyström matrix A\n        sqrt_w = np.sqrt(weights)\n        # A_ij = sqrt(w_i) * C_ij * sqrt(w_j). This can be done via an outer product.\n        A = np.outer(sqrt_w, sqrt_w) * cov_matrix\n\n        # Step 4: Compute and process eigenvalues\n        # np.linalg.eigh is for symmetric matrices and returns eigenvalues in ascending order.\n        eigvals = np.linalg.eigh(A)[0]\n        \n        # As per problem, set small negative numerical artifacts to zero.\n        eigvals[eigvals  0] = 0.0\n        \n        # Sort eigenvalues in descending order for analysis.\n        eigvals_desc = np.sort(eigvals)[::-1]\n\n        # Step 5: Compute the minimal truncation dimension M for 95% variance\n        total_variance_numerical = np.sum(eigvals_desc)\n        M = 1\n        if total_variance_numerical > 1e-15: # Avoid division by zero\n            cumulative_variance_fraction = np.cumsum(eigvals_desc) / total_variance_numerical\n            # Find the first index where the cumulative fraction is >= 0.95.\n            # np.searchsorted finds this index efficiently.\n            # M is a 1-based count, so add 1 to the 0-based index.\n            M = np.searchsorted(cumulative_variance_fraction, 0.95, side='left') + 1\n\n        # Step 6: Get the top 5 eigenvalues and round them to 10 decimal places\n        top_5_eigvals = eigvals_desc[:5]\n        rounded_top_5 = np.round(top_5_eigvals, 10).tolist()\n        \n        # Store the case result [M, lambda_1, ..., lambda_5]\n        case_result = [int(M)] + rounded_top_5\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # The format is a string representation of a list of lists.\n    result_str = \",\".join(map(str, results))\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "2589474"}]}