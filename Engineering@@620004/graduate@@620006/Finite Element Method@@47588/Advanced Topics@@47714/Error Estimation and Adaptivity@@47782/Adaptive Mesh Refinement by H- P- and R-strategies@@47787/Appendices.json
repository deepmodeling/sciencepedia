{"hands_on_practices": [{"introduction": "To effectively refine a mesh, we must first identify where the numerical error is largest. This practice delves into the core of adaptive algorithms: a posteriori error estimation. You will implement and compare a standard residual-based error estimator against a more sophisticated one based on solving local Neumann problems, providing insight into the construction and performance of these crucial tools [@problem_id:2540490]. This exercise will give you a concrete understanding of how we can computationally gauge the accuracy of a finite element solution.", "problem": "Consider the scalar Poisson problem in one spatial dimension: find $u \\in H_0^1(0,1)$ such that $-u'' = f$ in $(0,1)$ with homogeneous Dirichlet boundary conditions $u(0)=0$ and $u(1)=0$. The energy norm is defined by $\\lVert v \\rVert_E := \\left(\\int_0^1 \\lvert v'(x)\\rvert^2\\,dx\\right)^{1/2}$. Let $V_h$ denote the space of continuous, piecewise linear functions on a uniform mesh of $N$ elements on $[0,1]$ with nodes $x_i = i h$ for $i=0,\\dots,N$ and $h=1/N$. The finite element method seeks $u_h\\in V_h\\cap H_0^1(0,1)$ such that $\\int_0^1 u_h'(x)v'(x)\\,dx=\\int_0^1 f(x)v(x)\\,dx$ for all $v\\in V_h\\cap H_0^1(0,1)$.\n\nYour tasks are:\n\n1) Implement the computation of the energy error $\\lVert u' - u_h'\\rVert_{L^2(0,1)}$ using numerical quadrature, where $u$ is the exact solution corresponding to selected right-hand sides $f$ given below.\n\n2) Implement the standard residual-type a posteriori error estimator in one dimension for piecewise linear finite elements. For each element $K=[x_{i},x_{i+1}]$ of length $h_K$, define the interior residual contribution by $h_K^2 \\int_K f(x)^2\\,dx$ and at each interior node $x_i$ for $i=1,\\dots,N-1$ define the jump of the discrete flux $\\llbracket u_h'\\rrbracket_i := u_h'(x_i^-)-u_h'(x_i^+)$. Define the jump contribution at node $x_i$ by $\\frac{h_{i-1}+h_{i}}{2}\\,\\llbracket u_h'\\rrbracket_i^2$, where $h_{i-1}=x_i-x_{i-1}$ and $h_{i}=x_{i+1}-x_i$. The total standard estimator is\n$$\n\\eta_{\\mathrm{std}}^2 := \\sum_{K} h_K^2 \\int_K f(x)^2\\,dx \\;+\\;\\sum_{i=1}^{N-1} \\frac{h_{i-1}+h_i}{2}\\,\\llbracket u_h'\\rrbracket_i^2.\n$$\n\n3) Implement an alternative computable bound that replaces the divergence residual term by solutions of local Neumann problems on vertex patches. For each interior node $x_i$ with $i=1,\\dots,N-1$, consider the patch $\\omega_i := (x_{i-1},x_{i+1})$ and the discrete local Neumann problem: find $w_i \\in V_h(\\omega_i)$ such that\n$$\n\\int_{\\omega_i} w_i'(x) v'(x)\\,dx = \\int_{\\omega_i} f(x) v(x)\\,dx \\quad \\text{for all } v \\in V_h(\\omega_i),\n$$\nwith the side constraint $\\int_{\\omega_i} w_i(x)\\,dx = 0$ to fix the Neumann nullspace, where $V_h(\\omega_i)$ denotes the restriction of the global piecewise linear space to $\\omega_i$. Define the local patch energy by\n$$\n\\eta_{i,\\mathrm{div}}^2 := \\int_{\\omega_i} \\lvert w_i'(x)\\rvert^2\\,dx,\n$$\nand the Neumann-patch estimator by\n$$\n\\eta_{\\mathrm{neu}}^2 := \\sum_{i=1}^{N-1} \\eta_{i,\\mathrm{div}}^2 \\;+\\;\\sum_{i=1}^{N-1} \\frac{h_{i-1}+h_i}{2}\\,\\llbracket u_h'\\rrbracket_i^2.\n$$\nCompute $w_i$ in the discrete patch space by assembling the $3\\times 3$ patch stiffness matrix on nodes $\\{x_{i-1},x_i,x_{i+1}\\}$, the corresponding patch load vector, and enforcing the side constraint via a single Lagrange multiplier.\n\n4) For each test case, compute the reliability constants $C_{\\mathrm{std}} := \\eta_{\\mathrm{std}} / \\lVert u' - u_h'\\rVert_{L^2(0,1)}$ and $C_{\\mathrm{neu}} := \\eta_{\\mathrm{neu}} / \\lVert u' - u_h'\\rVert_{L^2(0,1)}$ as floating-point numbers.\n\nUse the following right-hand sides $f$ and exact solutions $u$:\n- $f_1(x) := \\pi^2 \\sin(\\pi x)$ with $u_1(x) := \\sin(\\pi x)$, so that $u_1'(x) := \\pi \\cos(\\pi x)$.\n- $f_2(x) := 1$ with $u_2(x) := \\tfrac{1}{2}x(1-x)$, so that $u_2'(x) := \\tfrac{1}{2}(1-2x)$.\n- $f_3(x) := \\begin{cases} 1, & x < \\tfrac{1}{2}, \\\\ 2, & x \\ge \\tfrac{1}{2},\\end{cases}$ with the corresponding exact solution satisfying $-u_3''=f_3$ and $u_3(0)=0$, $u_3(1)=0$, which yields\n$$\nu_3(x) := \\begin{cases}\n-\\tfrac{1}{2}x^2 + \\tfrac{5}{8}x, & 0 \\le x \\le \\tfrac{1}{2},\\\\\n-x^2 + \\tfrac{9}{8}x - \\tfrac{1}{8}, & \\tfrac{1}{2} < x \\le 1,\n\\end{cases}\n\\quad\nu_3'(x) := \\begin{cases}\n-x + \\tfrac{5}{8}, & 0 \\le x \\le \\tfrac{1}{2},\\\\\n-2x + \\tfrac{9}{8}, & \\tfrac{1}{2} < x \\le 1.\n\\end{cases}\n$$\n\nTest Suite:\n- Case A: $N=4$, use $f_1$.\n- Case B: $N=16$, use $f_1$.\n- Case C: $N=3$, use $f_2$.\n- Case D: $N=20$, use $f_3$.\n- Case E: $N=2$, use $f_3$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output first $C_{\\mathrm{std}}$ and then $C_{\\mathrm{neu}}$, in the order of the cases A through E. For example, the output must have the form $[C_{\\mathrm{std},A},C_{\\mathrm{neu},A},C_{\\mathrm{std},B},C_{\\mathrm{neu},B},C_{\\mathrm{std},C},C_{\\mathrm{neu},C},C_{\\mathrm{std},D},C_{\\mathrm{neu},D},C_{\\mathrm{std},E},C_{\\mathrm{neu},E}]$.", "solution": "The problem presented is a well-defined exercise in the a posteriori error analysis of the finite element method for a one-dimensional Poisson equation. It is scientifically sound, mathematically consistent, and all required components are specified unambiguously. The problem is therefore deemed valid. I will proceed with its solution.\n\nThe core of the problem is to compute and compare two a posteriori error estimators for the finite element solution of $-u'' = f$ on $(0,1)$ with $u(0)=u(1)=0$.\n\n**1. Finite Element Solution**\n\nWe use a uniform mesh with $N$ elements of size $h = 1/N$ and nodes $x_i = i h$ for $i=0, \\dots, N$. The finite element solution $u_h$ is sought in the space of continuous piecewise linear functions $V_h$ that are zero at $x=0$ and $x=1$. We can express $u_h$ in terms of the standard \"hat\" basis functions $\\phi_i(x)$ as $u_h(x) = \\sum_{j=1}^{N-1} U_j \\phi_j(x)$, where $U_j = u_h(x_j)$ are the unknown nodal values.\n\nThe Galerkin formulation leads to a linear system of equations $A \\mathbf{U} = \\mathbf{b}$, where $\\mathbf{U} = (U_1, \\dots, U_{N-1})^T$. The entries of the stiffness matrix $A$ and load vector $\\mathbf{b}$ are:\n$$\nA_{ij} = \\int_0^1 \\phi_j'(x) \\phi_i'(x) \\,dx \\quad \\text{and} \\quad b_i = \\int_0^1 f(x) \\phi_i(x) \\,dx\n$$\nFor a uniform 1D mesh, the stiffness matrix is an $(N-1) \\times (N-1)$ symmetric tridiagonal matrix:\n$$\nA = \\frac{1}{h}\n\\begin{pmatrix}\n2 & -1 & 0 & \\dots & 0 \\\\\n-1 & 2 & -1 & \\dots & 0 \\\\\n0 & \\ddots & \\ddots & \\ddots & 0 \\\\\n0 & \\dots & -1 & 2 & -1 \\\\\n0 & \\dots & 0 & -1 & 2\n\\end{pmatrix}\n$$\nThe entries of the load vector $b_i$ must be computed via numerical quadrature, especially for non-polynomial $f(x)$. Once the system $A \\mathbf{U} = \\mathbf{b}$ is solved for $\\mathbf{U}$, the approximate solution $u_h$ is fully determined. Its derivative, $u_h'$, is piecewise constant on each element $K_i = [x_i, x_{i+1}]$:\n$$\nu_h'(x) = \\frac{U_{i+1} - U_i}{h} \\quad \\text{for } x \\in (x_i, x_{i+1}),\n$$\nwhere we define $U_0 = U_N = 0$.\n\n**2. Energy Error**\n\nThe exact energy error is given by $\\lVert u' - u_h' \\rVert_{L^2(0,1)}$. Its square is computed by summing the contributions from each element:\n$$\n\\lVert u' - u_h' \\rVert_{L^2(0,1)}^2 = \\int_0^1 (u'(x) - u_h'(x))^2 \\,dx = \\sum_{i=0}^{N-1} \\int_{x_i}^{x_{i+1}} \\left(u'(x) - \\frac{U_{i+1}-U_i}{h}\\right)^2 \\,dx\n$$\nThis integral is computed using high-order numerical quadrature for accuracy.\n\n**3. Standard Residual Estimator ($\\eta_{\\mathrm{std}}$)**\n\nThe estimator is defined as $\\eta_{\\mathrm{std}}^2 = \\eta_{\\mathrm{res}}^2 + \\eta_{\\mathrm{jump}}^2$.\nThe first term is the element residual contribution:\n$$\n\\eta_{\\mathrm{res}}^2 = \\sum_{K} h_K^2 \\int_K f(x)^2\\,dx = \\sum_{i=0}^{N-1} h^2 \\int_{x_i}^{x_{i+1}} f(x)^2\\,dx\n$$\nThe integral of $f^2$ is computed element-wise using numerical quadrature.\n\nThe second term involves the jump in the derivative of the discrete solution at interior nodes:\n$$\n\\eta_{\\mathrm{jump}}^2 = \\sum_{i=1}^{N-1} \\frac{h_{i-1}+h_i}{2}\\,\\llbracket u_h'\\rrbracket_i^2 = \\sum_{i=1}^{N-1} h\\,\\llbracket u_h'\\rrbracket_i^2\n$$\nwhere $\\llbracket u_h'\\rrbracket_i = u_h'(x_i^-) - u_h'(x_i^+)$. A fundamental result of the Galerkin method is that this jump term is equal to the corresponding entry in the load vector. For each interior basis function $\\phi_i$, the weak formulation gives:\n$$\n\\int_0^1 u_h'(x)\\phi_i'(x)\\,dx = \\int_0^1 f(x)\\phi_i(x)\\,dx = b_i\n$$\nIntegrating the left-hand-side by parts over each element in the support of $\\phi_i$ yields:\n$$\n\\int_0^1 u_h'(x)\\phi_i'(x)\\,dx = u_h'(x_i^-) - u_h'(x_i^+) = \\llbracket u_h'\\rrbracket_i\n$$\nThus, $\\llbracket u_h'\\rrbracket_i = b_i$. This simplifies the jump term calculation significantly:\n$$\n\\eta_{\\mathrm{jump}}^2 = \\sum_{i=1}^{N-1} h\\, b_i^2\n$$\n\n**4. Neumann-Patch Estimator ($\\eta_{\\mathrm{neu}}$)**\n\nThis estimator replaces the element residual term with a sum of energies of solutions to local Neumann problems. Its form is:\n$$\n\\eta_{\\mathrm{neu}}^2 = \\sum_{i=1}^{N-1} \\eta_{i,\\mathrm{div}}^2 + \\eta_{\\mathrm{jump}}^2\n$$\nThe jump term $\\eta_{\\mathrm{jump}}^2$ is identical to that in the standard estimator. We focus on computing the patch divergence term $\\eta_{i,\\mathrm{div}}^2$ for each interior node $x_i$, $i \\in \\{1, \\dots, N-1\\}$.\n\nFor each patch $\\omega_i = (x_{i-1}, x_{i+1})$, we solve a local Neumann problem for $w_i(x)$ on the local three-node finite element space spanned by $\\{\\phi_{i-1}, \\phi_{i}, \\phi_{i+1}\\}$ restricted to $\\omega_i$. Let $\\mathbf{w} = (w_{i-1}, w_i, w_{i+1})^T$ be the nodal values of the local solution $w_i$. The local problem is defined by the stiffness matrix $A_p$ and load vector $\\mathbf{b}_p$:\n$$\nA_p \\mathbf{w} = \\mathbf{b}_p \\quad \\text{with} \\quad A_p = \\frac{1}{h}\\begin{pmatrix} 1 & -1 & 0 \\\\ -1 & 2 & -1 \\\\ 0 & -1 & 1 \\end{pmatrix}, \\quad (\\mathbf{b}_p)_j = \\int_{\\omega_i} f(x)\\phi_j(x)\\,dx\n$$\nfor $j \\in \\{i-1, i, i+1\\}$. The matrix $A_p$ is singular, reflecting the nullspace of constant functions for the Neumann problem. The unique solution is fixed by the constraint $\\int_{\\omega_i} w_i(x)\\,dx=0$, which translates to a linear constraint on the nodal values:\n$$\n\\int_{x_{i-1}}^{x_{i+1}} \\sum_{j=i-1}^{i+1} w_j \\phi_j(x)\\,dx = w_{i-1}\\frac{h}{2} + w_i h + w_{i+1}\\frac{h}{2} = 0 \\implies \\mathbf{C}^T \\mathbf{w} = 0\n$$\nwhere $\\mathbf{C} = (h/2, h, h/2)^T$. We solve this constrained system using a Lagrange multiplier $\\lambda$, which leads to the augmented $4 \\times 4$ system:\n$$\n\\begin{pmatrix} A_p & \\mathbf{C} \\\\ \\mathbf{C}^T & 0 \\end{pmatrix} \\begin{pmatrix} \\mathbf{w} \\\\ \\lambda \\end{pmatrix} = \\begin{pmatrix} \\mathbf{b}_p \\\\ 0 \\end{pmatrix}\n$$\nAfter solving for $\\mathbf{w}$, the local energy contribution is $\\eta_{i,\\mathrm{div}}^2 = \\int_{\\omega_i} \\lvert w_i'(x)\\rvert^2\\,dx$. From the weak form of the local problem, by setting the test function to be $w_i$ itself, we find:\n$$\n\\eta_{i,\\mathrm{div}}^2 = \\int_{\\omega_i} w_i'(x)w_i'(x)\\,dx = \\int_{\\omega_i} f(x) w_i(x)\\,dx = \\sum_{j=i-1}^{i+1} w_j \\int_{\\omega_i} f(x)\\phi_j(x)\\,dx = \\mathbf{w}^T \\mathbf{b}_p\n$$\nThis provides an efficient way to compute the patch energy.\n\n**5. Reliability Constants**\n\nFinally, for each test case, we compute the ratios of the estimated error to the true error, known as the reliability constants (or effectivity indices):\n$$\nC_{\\mathrm{std}} = \\frac{\\eta_{\\mathrm{std}}}{\\lVert u' - u_h'\\rVert_{L^2(0,1)}}, \\quad C_{\\mathrm{neu}} = \\frac{\\eta_{\\mathrm{neu}}}{\\lVert u' - u_h'\\rVert_{L^2(0,1)}}\n$$\nThese constants are computed for each specified configuration of $N$ and $f(x)$.", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Solves the 1D Poisson problem using FEM and computes error estimators for specified test cases.\n    \"\"\"\n\n    class TestCase:\n        def __init__(self, N, f_func, u_prime_func, f_discontinuity=None):\n            self.N = N\n            self.f = f_func\n            self.u_prime = u_prime_func\n            self.f_discontinuity = f_discontinuity\n\n    # Define test functions\n    f1 = lambda x: np.pi**2 * np.sin(np.pi * x)\n    u1_prime = lambda x: np.pi * np.cos(np.pi * x)\n\n    f2 = lambda x: 1.0\n    u2_prime = lambda x: 0.5 * (1.0 - 2.0 * x)\n    \n    def f3(x):\n        if hasattr(x, '__iter__'):\n            return np.piecewise(x, [x < 0.5], [1.0, 2.0])\n        return 1.0 if x < 0.5 else 2.0\n\n    def u3_prime(x):\n        if hasattr(x, '__iter__'):\n            return np.piecewise(x, [x < 0.5],\n                                [lambda v: -v + 5/8, lambda v: -2*v + 9/8])\n        return -x + 5/8 if x < 0.5 else -2*x + 9/8\n\n    test_cases = [\n        TestCase(N=4, f_func=f1, u_prime_func=u1_prime),\n        TestCase(N=16, f_func=f1, u_prime_func=u1_prime),\n        TestCase(N=3, f_func=f2, u_prime_func=u2_prime),\n        TestCase(N=20, f_func=f3, u_prime_func=u3_prime, f_discontinuity=0.5),\n        TestCase(N=2, f_func=f3, u_prime_func=u3_prime, f_discontinuity=0.5),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N = case.N\n        h = 1.0 / N\n        nodes = np.linspace(0, 1, N + 1)\n        \n        # --- 1. Global FEM solution ---\n        if N > 1:\n            A = np.zeros((N - 1, N - 1))\n            main_diag = 2.0 / h * np.ones(N - 1)\n            off_diag = -1.0 / h * np.ones(N - 2)\n            A += np.diag(main_diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1)\n\n            b = np.zeros(N - 1)\n            for i in range(1, N):\n                # Hat function phi_i\n                phi_i = lambda x, i_node=i: np.maximum(0, 1 - np.abs(x - nodes[i_node]) / h)\n                integrand = lambda x: case.f(x) * phi_i(x)\n                \n                points = [case.f_discontinuity] if case.f_discontinuity and nodes[i-1] < case.f_discontinuity < nodes[i+1] else None\n                b[i - 1] = quad(integrand, nodes[i - 1], nodes[i + 1], points=points)[0]\n\n            U_internal = np.linalg.solve(A, b)\n            U = np.concatenate(([0], U_internal, [0]))\n        else: # N=1 case, only boundary nodes\n            U = np.zeros(2)\n            b = np.array([])\n\n        # --- 2. Energy Error ---\n        error_sq = 0.0\n        for i in range(N):\n            u_h_prime_val = (U[i + 1] - U[i]) / h\n            integrand = lambda x: (case.u_prime(x) - u_h_prime_val)**2\n            \n            points = [case.f_discontinuity] if case.f_discontinuity and nodes[i] < case.f_discontinuity < nodes[i+1] else None\n            error_sq += quad(integrand, nodes[i], nodes[i+1], points=points)[0]\n\n        energy_error = np.sqrt(error_sq)\n\n        # --- 3. Standard Estimator ---\n        # Residual term\n        eta_res_sq = 0.0\n        for i in range(N):\n            integrand = lambda x: case.f(x)**2\n            points = [case.f_discontinuity] if case.f_discontinuity and nodes[i] < case.f_discontinuity < nodes[i+1] else None\n            integral_f_sq = quad(integrand, nodes[i], nodes[i+1], points=points)[0]\n            eta_res_sq += h**2 * integral_f_sq\n        \n        # Jump term\n        eta_jump_sq = h * np.sum(b**2)\n        eta_std = np.sqrt(eta_res_sq + eta_jump_sq)\n\n        # --- 4. Neumann-Patch Estimator ---\n        eta_div_sq_sum = 0.0\n        if N > 1:\n            for i in range(1, N): # Loop over interior nodes\n                # Local patch stiffness matrix\n                A_p = (1.0 / h) * np.array([[1, -1, 0], [-1, 2, -1], [0, -1, 1]])\n                C = np.array([h/2, h, h/2])\n                \n                # Augmented system matrix\n                M = np.zeros((4,4))\n                M[:3,:3] = A_p\n                M[:3, 3] = C\n                M[3, :3] = C.T\n\n                # Local load vector b_p\n                b_p = np.zeros(3)\n                patch_nodes_idx = [i - 1, i, i + 1]\n                for j_local, j_global in enumerate(patch_nodes_idx):\n                    phi_j = lambda x, j_node=j_global: np.maximum(0, 1 - np.abs(x - nodes[j_node]) / h)\n                    integrand = lambda x: case.f(x) * phi_j(x)\n                    \n                    points = [case.f_discontinuity] if case.f_discontinuity and nodes[i-1] < case.f_discontinuity < nodes[i+1] else None\n                    b_p[j_local] = quad(integrand, nodes[i - 1], nodes[i + 1], points=points)[0]\n\n                # RHS for augmented system\n                F_aug = np.concatenate((b_p, [0]))\n\n                # Solve for (w, lambda)\n                sol_aug = np.linalg.solve(M, F_aug)\n                w = sol_aug[:3]\n\n                # Compute local patch energy\n                eta_i_div_sq = np.dot(w, b_p)\n                eta_div_sq_sum += eta_i_div_sq\n\n        eta_neu = np.sqrt(eta_div_sq_sum + eta_jump_sq)\n\n        # --- 5. Reliability Constants ---\n        C_std = eta_std / energy_error if energy_error > 1e-15 else 0.0\n        C_neu = eta_neu / energy_error if energy_error > 1e-15 else 0.0\n        results.extend([C_std, C_neu])\n\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "2540490"}, {"introduction": "With a method to estimate error, the next step is to choose a strategy for mesh adaptation. This problem contrasts two fundamental approaches—$h$-adaptivity (inserting new elements) and $r$-adaptivity (relocating existing nodes)—in the context of a 1D boundary layer, a classic challenge for numerical methods. By analytically deriving the minimal number of elements needed to achieve a desired accuracy, you will develop a quantitative framework for deciding when simple node movement is sufficient and when adding degrees of freedom is necessary [@problem_id:2540459].", "problem": "Consider the one-dimensional boundary layer prototype on the unit interval $[0,1]$ given by the smooth function $u(x) = 1 - \\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right)$, where $\\varepsilon \\in (0,1]$ controls the layer thickness near $x=1$. We analyze adaptive mesh refinement for piecewise linear finite elements by two strategies: $h$-adaptivity (element insertion, i.e., increasing the number of elements) and $r$-adaptivity (element relocation with a fixed number of elements) while keeping the polynomial degree fixed. Assume the usual finite element interpolation error theory applies for $C^2$ functions in the essential supremum norm $L^\\infty$.\n\nStarting from the following accepted foundation:\n- The piecewise linear interpolation error on an element of length $h$ satisfies the bound $\\|u - I_h u\\|_{L^\\infty(\\text{element})} \\le C_I \\,\\max_{x \\text{ in element}} |u''(x)|\\, h^2$ with a constant $C_I = \\dfrac{1}{8}$, where $I_h u$ denotes the local linear interpolant.\n- The $r$-adaptivity principle of equidistribution of a scalar monitor function says that, to minimize the maximum interpolation error over all elements under a fixed element budget, one chooses a mesh density inversely proportional to the square root of the second derivative magnitude, i.e., element sizes $h(x)$ satisfying $|u''(x)|\\, h(x)^2 \\approx \\text{constant}$.\n- The boundary layer function satisfies $u''(x) = \\dfrac{1}{\\varepsilon^2}\\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right)$, which is positive and decays exponentially away from $x=1$.\n\nYour tasks are:\n1. Derive, from the interpolation error bound and the equidistribution principle, an estimate for the minimal number of elements $n_\\star$ required to ensure that the global $L^\\infty$ interpolation error does not exceed a target tolerance $\\tau > 0$ under optimally adapted meshes. Express $n_\\star$ in terms of $\\varepsilon$, $\\tau$, and $C_I$.\n2. For $r$-adaptivity with a fixed element budget $n_0 \\in \\mathbb{N}$, determine whether mere node movement (without changing connectivity or the element count) can meet the tolerance $\\tau$. This is true precisely when $n_0 \\ge n_\\star$.\n3. Quantify the concentration of elements that optimal equidistribution demands near the boundary layer by computing the fraction $f_{\\Lambda}$ of elements that should lie within the terminal subinterval $[1 - \\Lambda \\varepsilon, 1]$ for a specified positive parameter $\\Lambda$. Interpret this as the ratio of the integrated optimal mesh density over $[1 - \\Lambda \\varepsilon, 1]$ to that over $[0,1]$.\n\nYou must implement a program that: \n- Computes $n_\\star$ using your derived expression (round up to the nearest integer).\n- Determines the boolean indicator of $r$-adaptivity success as $1$ if $n_0 \\ge n_\\star$ and $0$ otherwise.\n- Computes $f_{\\Lambda}$ and rounds it to $6$ decimal places.\n\nYour implementation should specialize to the given $u(x)$ and use only the data specified below. For this $u(x)$, the equidistribution-based optimal element density is proportional to $\\sqrt{|u''(x)|}$, and your program should use this fact to evaluate $f_{\\Lambda}$ exactly. Answers must be unitless.\n\nTest suite:\n- Case $1$: $(\\varepsilon, \\tau, n_0, \\Lambda) = (0.05, 10^{-2}, 40, 4)$.\n- Case $2$: $(\\varepsilon, \\tau, n_0, \\Lambda) = (0.005, 10^{-4}, 50, 5)$.\n- Case $3$: $(\\varepsilon, \\tau, n_0, \\Lambda) = (0.5, 10^{-2}, 5, 1)$.\n- Case $4$: $(\\varepsilon, \\tau, n_0, \\Lambda) = (0.001, 5\\times 10^{-3}, 8, 3)$.\n- Case $5$: $(\\varepsilon, \\tau, n_0, \\Lambda) = (0.02, 2\\times 10^{-3}, 30, 4)$.\n\nFinal output format:\n- Your program should produce a single line of output containing a list with one entry per test case, in the same order as above.\n- Each entry must be a list of the form $[n_\\star, s, f_{\\Lambda}]$, where $n_\\star$ is an integer, $s \\in \\{0,1\\}$ indicates whether $r$-adaptivity alone succeeds, and $f_{\\Lambda}$ is a float rounded to $6$ decimal places.\n- The output must be printed as a single line with no extra text, and entries must be comma-separated inside square brackets. For example, a valid shape is $[[n_\\star^{(1)},s^{(1)},f_{\\Lambda}^{(1)}],[n_\\star^{(2)},s^{(2)},f_{\\Lambda}^{(2)}],\\dots]$.", "solution": "We work with the specific boundary layer profile $u(x) = 1 - \\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right)$ on $[0,1]$ with $\\varepsilon \\in (0,1]$. Its derivatives are\n$$\nu'(x) = \\dfrac{1}{\\varepsilon}\\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right),\\quad\nu''(x) = \\dfrac{1}{\\varepsilon^2}\\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right).\n$$\nThe piecewise linear interpolation error bound on an element $K$ of length $h_K$ is\n$$\n\\|u - I_h u\\|_{L^\\infty(K)} \\le C_I \\big(\\max_{x\\in K} |u''(x)|\\big)\\, h_K^2,\n$$\nwith $C_I = \\dfrac{1}{8}$, which is a classical result derivable from the Peano kernel for linear interpolation. The optimality principle for $r$-adaptivity (equidistribution) seeks to choose element sizes $\\{h_K\\}$ so that the elemental contributions to the error are equalized. In one dimension, with a continuous mesh size function $h(x)$ over the domain, this corresponds to enforcing\n$$\nC_I\\, |u''(x)|\\, h(x)^2 \\approx \\tau_e,\n$$\nwhere $\\tau_e$ is the target equalized elemental error such that the global $L^\\infty$ error does not exceed a prescribed tolerance $\\tau > 0$. When all elements share the same bound $C_I |u''| h^2 = \\tau_e$, the global maximum over the mesh does not exceed $\\tau_e$, so we can set $\\tau_e = \\tau$ for a conservative design. Solving for $h(x)$ yields\n$$\nh(x) = \\sqrt{\\dfrac{\\tau}{C_I}}\\, |u''(x)|^{-1/2}.\n$$\nThe total number of elements $n$ associated with this continuous mesh size is the path length of the domain divided by the local size:\n$$\nn \\approx \\int_{0}^{1} \\dfrac{dx}{h(x)} = \\sqrt{\\dfrac{C_I}{\\tau}} \\int_{0}^{1} \\sqrt{|u''(x)|}\\, dx.\n$$\nThus, an estimate for the minimal element count capable of achieving the tolerance is\n$$\nn_\\star = \\left\\lceil \\sqrt{\\dfrac{C_I}{\\tau}} \\int_{0}^{1} \\sqrt{|u''(x)|}\\, dx \\right\\rceil.\n$$\nFor our $u(x)$, we have $|u''(x)| = \\dfrac{1}{\\varepsilon^2}\\exp\\!\\left(-\\dfrac{1-x}{\\varepsilon}\\right)$ and hence\n$$\n\\sqrt{|u''(x)|} = \\dfrac{1}{\\varepsilon}\\exp\\!\\left(-\\dfrac{1-x}{2\\varepsilon}\\right).\n$$\nThe integral can be evaluated exactly:\n$$\n\\int_{0}^{1} \\sqrt{|u''(x)|}\\, dx = \\int_{0}^{1} \\dfrac{1}{\\varepsilon}\\exp\\!\\left(-\\dfrac{1-x}{2\\varepsilon}\\right) dx.\n$$\nWith the substitution $y = 1-x$, $dy = -dx$, the integral becomes\n$$\n\\int_{y=1}^{0} \\dfrac{1}{\\varepsilon} \\exp\\!\\left(-\\dfrac{y}{2\\varepsilon}\\right) (-dy) = \\int_{0}^{1} \\dfrac{1}{\\varepsilon} \\exp\\!\\left(-\\dfrac{y}{2\\varepsilon}\\right) dy = \\left[-2 \\exp\\!\\left(-\\dfrac{y}{2\\varepsilon}\\right)\\right]_{0}^{1} = 2\\left(1 - \\exp\\!\\left(-\\dfrac{1}{2\\varepsilon}\\right)\\right).\n$$\nTherefore,\n$$\nn_\\star = \\left\\lceil \\sqrt{\\dfrac{C_I}{\\tau}} \\cdot 2\\left(1 - \\exp\\!\\left(-\\dfrac{1}{2\\varepsilon}\\right)\\right) \\right\\rceil,\n$$\nwith $C_I = \\dfrac{1}{8}$. This $n_\\star$ is the benchmark for both $h$-adaptivity and $r$-adaptivity under optimal redistribution: $h$-adaptivity can meet the tolerance by increasing the element count until at least $n_\\star$, while $r$-adaptivity can meet the tolerance without changing the element count if and only if the available number of elements $n_0$ satisfies $n_0 \\ge n_\\star$.\n\nTo quantify the mesh concentration near the boundary layer, note that the optimal element density is proportional to $\\sqrt{|u''(x)|}$. Let $\\rho(x) = \\sqrt{|u''(x)|}$ and define\n$$\nI_{\\text{tot}}(\\varepsilon) = \\int_{0}^{1} \\rho(x)\\, dx = 2\\left(1 - \\exp\\!\\left(-\\dfrac{1}{2\\varepsilon}\\right)\\right).\n$$\nThe fraction of elements expected in the terminal subinterval $[1 - \\Lambda \\varepsilon, 1]$ is\n$$\nf_{\\Lambda} = \\dfrac{\\int_{1-\\Lambda \\varepsilon}^{1} \\rho(x)\\, dx}{\\int_{0}^{1} \\rho(x)\\, dx}.\n$$\nUsing the same substitution $y=1-x$ and noting that the subinterval corresponds to $y \\in [0, \\min(1,\\Lambda \\varepsilon)]$, we find\n$$\n\\int_{1-\\Lambda \\varepsilon}^{1} \\rho(x)\\, dx = \\int_{0}^{\\min(1,\\Lambda \\varepsilon)} \\dfrac{1}{\\varepsilon}\\exp\\!\\left(-\\dfrac{y}{2\\varepsilon}\\right) dy = 2\\left(1 - \\exp\\!\\left(-\\min\\!\\left(\\dfrac{1}{2\\varepsilon}, \\dfrac{\\Lambda}{2}\\right)\\right)\\right).\n$$\nHence,\n$$\nf_{\\Lambda}(\\varepsilon,\\Lambda) = \\dfrac{1 - \\exp\\!\\left(-\\min\\!\\left(\\dfrac{1}{2\\varepsilon}, \\dfrac{\\Lambda}{2}\\right)\\right)}{1 - \\exp\\!\\left(-\\dfrac{1}{2\\varepsilon}\\right)}.\n$$\nThis gives an exact, unitless fraction that a perfectly equidistributed mesh would allocate to the layer neighborhood.\n\nAlgorithmic steps for each test case $(\\varepsilon, \\tau, n_0, \\Lambda)$:\n1. Compute $I_{\\text{tot}}(\\varepsilon) = 2\\left(1 - \\exp\\!\\left(-\\dfrac{1}{2\\varepsilon}\\right)\\right)$.\n2. Compute $n_\\star = \\left\\lceil \\sqrt{\\dfrac{C_I}{\\tau}} \\cdot I_{\\text{tot}}(\\varepsilon) \\right\\rceil$ with $C_I=\\dfrac{1}{8}$.\n3. Set $s = 1$ if $n_0 \\ge n_\\star$, else $s = 0$.\n4. Compute $f_{\\Lambda}$ using the exact formula above and round to $6$ decimal places.\n\nApplying this to the specified test suite yields deterministic integer and float outputs. The program must print a single line containing a list of $5$ entries, each entry of the form $[n_\\star, s, f_{\\Lambda}]$, with $f_{\\Lambda}$ rounded to $6$ decimal places, and no additional text.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef n_star(eps: float, tol: float, C_I: float = 1.0/8.0) -> int:\n    # I_tot = integral of sqrt(|u''|) over [0,1] for u'' = exp(-(1-x)/eps)/eps^2\n    # sqrt(|u''|) = exp(-(1-x)/(2 eps))/eps\n    # Integral = 2 * (1 - exp(-1/(2 eps)))\n    I_tot = 2.0 * (1.0 - np.exp(-1.0 / (2.0 * eps)))\n    val = np.sqrt(C_I / tol) * I_tot\n    return int(np.ceil(val))\n\ndef fraction_in_layer(eps: float, Lam: float) -> float:\n    # f_Lambda = (1 - exp(-min(1/(2 eps), Lam/2))) / (1 - exp(-1/(2 eps)))\n    denom = 1.0 - np.exp(-1.0 / (2.0 * eps))\n    m = min(1.0 / (2.0 * eps), Lam / 2.0)\n    numer = 1.0 - np.exp(-m)\n    # Handle potential numerical issues if denom is extremely small (shouldn't happen in given tests)\n    if denom <= 0.0:\n        return 1.0  # degenerate smooth limit: all density uniform\n    f = numer / denom\n    # Clamp to [0,1] due to rounding\n    return max(0.0, min(1.0, f))\n\ndef solve():\n    # Define the test cases from the problem statement: (eps, tau, n0, Lambda)\n    test_cases = [\n        (0.05, 1e-2, 40, 4.0),\n        (0.005, 1e-4, 50, 5.0),\n        (0.5, 1e-2, 5, 1.0),\n        (0.001, 5e-3, 8, 3.0),\n        (0.02, 2e-3, 30, 4.0),\n    ]\n\n    results = []\n    for eps, tau, n0, Lam in test_cases:\n        n_req = n_star(eps, tau, C_I=1.0/8.0)\n        r_success = 1 if n0 >= n_req else 0\n        frac = fraction_in_layer(eps, Lam)\n        frac_rounded = round(frac, 6)\n        results.append([n_req, r_success, float(f\"{frac_rounded:.6f}\")])\n\n    # Format as a single-line list of lists with no spaces for exactness\n    def format_entry(entry):\n        # entry is [int, int, float]\n        return f\"[{entry[0]},{entry[1]},{entry[2]}]\"\n    print(f\"[{','.join(format_entry(e) for e in results)}]\")\n\nsolve()\n```", "id": "2540459"}, {"introduction": "Many real-world phenomena involve features, such as boundary layers or shear bands, that are highly stretched in one direction. In these cases, refining the mesh uniformly in all directions is computationally wasteful. This final practice moves into two dimensions to explore the power of anisotropic $h$-refinement, guiding you to implement an algorithm that selectively refines elements in the direction of largest error [@problem_id:2540498]. By comparing your results to a standard isotropic approach, you will directly quantify the substantial savings in computational cost that make anisotropic methods essential for complex simulations.", "problem": "Consider the square domain $\\Omega = [0,1]^2$ and the target field $u_{\\sigma_x,\\sigma_y}:\\Omega\\to\\mathbb{R}$ defined by\n$$\nu_{\\sigma_x,\\sigma_y}(x,y) = \\exp\\!\\left(-\\frac{(x-\\tfrac{1}{2})^2}{2\\sigma_x^2} - \\frac{(y-\\tfrac{1}{2})^2}{2\\sigma_y^2}\\right),\n$$\nwhere $\\sigma_x \\in (0,1)$ and $\\sigma_y \\in (0,1)$ control the axial widths of a stretched Gaussian feature. Consider adaptive $h$-refinement for continuous bilinear (also called $\\mathbb{Q}_1$) finite elements on axis-aligned rectangular meshes. You will compare isotropic versus anisotropic element marking and refinement strategies with respect to a proxy for the number of degrees of freedom.\n\nUse the following fundamental base and definitions.\n\n- The bilinear interpolation remainder depends on second derivatives of the target field. Motivated by this and standard anisotropic mesh adaptation practice, define a local elementwise error indicator on a rectangular element $K = [x_0,x_1]\\times[y_0,y_1]$ with $h_x = x_1-x_0$, $h_y = y_1-y_0$, area $|K|=h_x h_y$, and center $c_K=(\\tfrac{x_0+x_1}{2},\\tfrac{y_0+y_1}{2})$ as\n$$\n\\eta_K = |K|\\left(|u_{xx}(c_K)|\\,h_x^2 + |u_{yy}(c_K)|\\,h_y^2 + 2\\,|u_{xy}(c_K)|\\,h_x h_y\\right),\n$$\nwhere $u_{xx}$, $u_{yy}$, and $u_{xy}$ are the second partial derivatives of $u_{\\sigma_x,\\sigma_y}$.\n\n- The global error indicator is $\\eta = \\sum_{K\\in\\mathcal{T}} \\eta_K$ for a mesh $\\mathcal{T}$.\n\n- Use Dörfler marking: given a bulk parameter $\\theta\\in(0,1)$, select a minimal cardinality subset $\\mathcal{M}\\subset\\mathcal{T}$ such that $\\sum_{K\\in\\mathcal{M}} \\eta_K \\ge \\theta\\,\\eta$. In practice, this is achieved by sorting $\\{\\eta_K\\}$ in nonincreasing order and accumulating until the threshold is met.\n\n- Two refinement strategies are compared on the same initial mesh $\\mathcal{T}_0$:\n  1. Isotropic refinement: every marked element $K\\in\\mathcal{M}$ is refined into $4$ children by halving both directions, i.e., bisect at $x=\\tfrac{x_0+x_1}{2}$ and $y=\\tfrac{y_0+y_1}{2}$.\n  2. Anisotropic refinement (directional): for each marked element $K\\in\\mathcal{M}$, choose a single split direction based on the relative contribution of the principal curvatures to $\\eta_K$. Specifically, split $K$ into $2$ children by halving only in the $y$-direction if $|u_{yy}(c_K)|\\,h_y \\ge |u_{xx}(c_K)|\\,h_x$, otherwise halve only in the $x$-direction.\n\n- Stopping criterion: iterate marking and refinement until $\\eta \\le \\mathrm{TOL}$, or until a hard cap on the total number of elements $N_{\\max}$ is reached, or until a hard cap on the number of refinement iterations $I_{\\max}$ is reached. The hard caps ensure termination even in extreme parameter regimes.\n\n- Degrees-of-freedom proxy: for $\\mathbb{Q}_1$ meshes with local hanging-node constraints, the number of global degrees of freedom is proportional to the number of leaf elements up to a mesh-dependent constant. To obtain a robust, implementation-independent metric, use the number of leaf elements $N_\\mathrm{elem}$ as the proxy for the degrees of freedom. Report this proxy for each strategy.\n\nImplement a program that:\n- Constructs the initial mesh $\\mathcal{T}_0$ as a uniform $N_0\\times N_0$ partition of $\\Omega$ into rectangles.\n- Computes $\\eta_K$ using the element center $c_K$.\n- Applies Dörfler marking with the given $\\theta$.\n- Refines according to the specified isotropic or anisotropic rule.\n- Repeats until the stopping criterion is met.\n- Returns, for each test case, a triple $[N_\\mathrm{iso}, N_\\mathrm{ani}, S]$, where $N_\\mathrm{iso}$ is the final number of elements for isotropic refinement, $N_\\mathrm{ani}$ is the final number of elements for anisotropic refinement, and $S = N_\\mathrm{iso}/N_\\mathrm{ani}$ is the degrees-of-freedom savings ratio achieved by anisotropic refinement (values $S>1$ indicate savings).\n\nAnalytical expressions for the second derivatives of $u_{\\sigma_x,\\sigma_y}$ must be used:\n$$\nu_{xx}(x,y) = \\left(\\frac{(x-\\tfrac{1}{2})^2}{\\sigma_x^4} - \\frac{1}{\\sigma_x^2}\\right) u_{\\sigma_x,\\sigma_y}(x,y),\\quad\nu_{yy}(x,y) = \\left(\\frac{(y-\\tfrac{1}{2})^2}{\\sigma_y^4} - \\frac{1}{\\sigma_y^2}\\right) u_{\\sigma_x,\\sigma_y}(x,y),\n$$\n$$\nu_{xy}(x,y) = \\frac{(x-\\tfrac{1}{2})(y-\\tfrac{1}{2})}{\\sigma_x^2 \\sigma_y^2}\\,u_{\\sigma_x,\\sigma_y}(x,y).\n$$\n\nUse the following test suite, which exercises typical, near-isotropic, and highly anisotropic features. The constants $N_{\\max}$ and $I_{\\max}$ are safety limits common to all tests.\n\n- Test $1$: $(\\sigma_x, \\sigma_y, \\theta, \\mathrm{TOL}, N_0) = (0.25, 0.05, 0.6, 0.02, 8)$.\n- Test $2$: $(\\sigma_x, \\sigma_y, \\theta, \\mathrm{TOL}, N_0) = (0.25, 0.025, 0.6, 0.02, 8)$.\n- Test $3$: $(\\sigma_x, \\sigma_y, \\theta, \\mathrm{TOL}, N_0) = (0.15, 0.15, 0.6, 0.02, 8)$.\n- Test $4$: $(\\sigma_x, \\sigma_y, \\theta, \\mathrm{TOL}, N_0) = (0.30, 0.02, 0.6, 0.02, 8)$.\n\nUse $N_{\\max}=40000$ and $I_{\\max}=200$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is itself a bracketed triple for one test, in the same order as above. For example, the output must have the form\n$[[N_\\mathrm{iso,1},N_\\mathrm{ani,1},S_1],[N_\\mathrm{iso,2},N_\\mathrm{ani,2},S_2],[N_\\mathrm{iso,3},N_\\mathrm{ani,3},S_3],[N_\\mathrm{iso,4},N_\\mathrm{ani,4},S_4]]$,\nwith all numbers written in decimal notation. No physical units or angles are involved in this problem, and any quantity that might otherwise be a percentage must be expressed as a decimal number in $[0,1]$.", "solution": "We start from the fundamental property that for continuous bilinear elements on axis-aligned rectangles, the interpolation error can be related to second derivatives of the target field. Specifically, the Taylor expansion remainder in each coordinate implies that the elementwise interpolation error scales like a linear combination of $|u_{xx}|h_x^2$, $|u_{yy}|h_y^2$, and a mixed term involving $|u_{xy}|h_x h_y$, with proportionality to the element area $|K|$. This motivates the anisotropy-aware indicator\n$$\n\\eta_K = |K|\\left(|u_{xx}(c_K)|\\,h_x^2 + |u_{yy}(c_K)|\\,h_y^2 + 2\\,|u_{xy}(c_K)|\\,h_x h_y\\right).\n$$\nThis indicator is not a shortcut formula for the unknown true error but a computable surrogate that is consistent with the second-derivative structure of the interpolation error. Summing $\\eta_K$ over all elements yields a global indicator $\\eta$.\n\nWe prescribe Dörfler marking (bulk chasing) with parameter $\\theta\\in(0,1)$, which is a well-tested mechanism for targeting the largest contributions to the error estimate. Specifically, if the local indicators are sorted in nonincreasing order as $\\eta_{K_1}\\ge\\eta_{K_2}\\ge\\cdots$, then the minimal index $m$ satisfying $\\sum_{i=1}^m \\eta_{K_i}\\ge \\theta \\sum_{K}\\eta_K$ determines the marked set $\\mathcal{M}=\\{K_1,\\dots,K_m\\}$. This ensures that a fixed fraction of the global indicator is addressed at every iteration, which in turn leads to convergence under reasonable estimator properties.\n\nTwo refinement rules are compared:\n\n- Isotropic refinement: each marked rectangle is halved in both axes, producing $4$ children with $(h_x,h_y)$ each divided by $2$. This strategy does not exploit directional information.\n\n- Anisotropic refinement: for a marked element $K$, we assess which term contributes more strongly to $\\eta_K$ in the sense of $|u_{yy}(c_K)|\\,h_y$ versus $|u_{xx}(c_K)|\\,h_x$. If $|u_{yy}(c_K)|\\,h_y \\ge |u_{xx}(c_K)|\\,h_x$, we split only along $y$, halving $h_y$ and producing $2$ children. Otherwise, we split only along $x$, halving $h_x$ and producing $2$ children. This rule aims to reduce the dominant curvature contribution most efficiently.\n\nThe target field is a separable Gaussian ridge:\n$$\nu_{\\sigma_x,\\sigma_y}(x,y) = \\exp\\!\\left(-\\frac{(x-\\tfrac{1}{2})^2}{2\\sigma_x^2} - \\frac{(y-\\tfrac{1}{2})^2}{2\\sigma_y^2}\\right),\n$$\nwhose Hessian is available in closed form:\n$$\nu_{xx}(x,y) = \\left(\\frac{(x-\\tfrac{1}{2})^2}{\\sigma_x^4} - \\frac{1}{\\sigma_x^2}\\right) u_{\\sigma_x,\\sigma_y}(x,y),\\quad\nu_{yy}(x,y) = \\left(\\frac{(y-\\tfrac{1}{2})^2}{\\sigma_y^4} - \\frac{1}{\\sigma_y^2}\\right) u_{\\sigma_x,\\sigma_y}(x,y),\n$$\n$$\nu_{xy}(x,y) = \\frac{(x-\\tfrac{1}{2})(y-\\tfrac{1}{2})}{\\sigma_x^2 \\sigma_y^2}\\,u_{\\sigma_x,\\sigma_y}(x,y).\n$$\nNotably, the principal curvature magnitudes scale like $|u_{xx}|\\sim \\sigma_x^{-2}$ and $|u_{yy}|\\sim \\sigma_y^{-2}$ near the center, which implies a potentially large anisotropy when $\\sigma_y\\ll\\sigma_x$.\n\nAlgorithmic design:\n\n- Initialize a uniform $N_0\\times N_0$ mesh on $\\Omega$. Each element $K$ is represented by its bounds $[x_0,x_1]\\times[y_0,y_1]$.\n\n- At each iteration:\n  1. For every element $K$, compute $h_x$, $h_y$, center $c_K$, evaluate $u_{xx}(c_K)$, $u_{yy}(c_K)$, and $u_{xy}(c_K)$, and then compute $\\eta_K$.\n  2. Sum to obtain $\\eta$. If $\\eta \\le \\mathrm{TOL}$, stop. Otherwise, sort $\\{\\eta_K\\}$ in nonincreasing order and mark by Dörfler with parameter $\\theta$.\n  3. Refine marked elements according to the chosen strategy. For isotropic refinement, replace each marked element by $4$ children. For anisotropic refinement, use the directional rule and produce $2$ children per marked element.\n  4. Repeat until $\\eta \\le \\mathrm{TOL}$ or the safety caps on the number of elements $N_{\\max}$ or the number of iterations $I_{\\max}$ are reached.\n\n- The degree-of-freedom proxy is $N_\\mathrm{elem}$, the number of leaf elements, reported at termination.\n\nWhy anisotropic refinement saves degrees of freedom on a stretched feature:\n\n- Consider resolving a layer of width $\\sigma_y$ in the $y$-direction and width $\\sigma_x$ in the $x$-direction. Isotropic refinement reduces $h_x$ and $h_y$ simultaneously. To reduce the dominant term $|u_{yy}|\\,h_y^2$ to a target tolerance, isotropic refinement also unnecessarily reduces $h_x$, causing extra elements by a factor comparable to the aspect ratio of the feature. In contrast, the anisotropic rule selectively reduces $h_y$ when $|u_{yy}|\\,h_y$ dominates, leading to an asymptotic savings factor on the order of $\\sigma_x/\\sigma_y$ when $\\sigma_y\\ll\\sigma_x$.\n\n- The Dörfler marking ensures that the algorithm focuses refinement near the feature and along the most offending direction, leading to faster decay of the global indicator per new element for the anisotropic strategy in anisotropic scenarios.\n\nComputational considerations and edge cases:\n\n- The indicator uses the element center; this is a computationally efficient sampling consistent with smooth Hessians.\n\n- Safety caps $N_{\\max}$ and $I_{\\max}$ prevent runaway refinement in extreme parameter regimes. If a cap is reached before $\\eta\\le \\mathrm{TOL}$, the algorithm returns the current $N_\\mathrm{elem}$, which is still informative for comparing strategies.\n\n- In near-isotropic cases (e.g., $\\sigma_x\\approx\\sigma_y$), both strategies should yield similar $N_\\mathrm{elem}$ and the ratio $S$ close to $1$. In highly anisotropic cases (e.g., $\\sigma_y\\ll\\sigma_x$), we expect $S>1$, indicating degrees-of-freedom savings by the anisotropic strategy.\n\nThe program implements the above algorithm, applies it to the specified test suite:\n- Test $1$: $(\\sigma_x,\\sigma_y,\\theta,\\mathrm{TOL},N_0) = (0.25, 0.05, 0.6, 0.02, 8)$.\n- Test $2$: $(\\sigma_x,\\sigma_y,\\theta,\\mathrm{TOL},N_0) = (0.25, 0.025, 0.6, 0.02, 8)$.\n- Test $3$: $(\\sigma_x,\\sigma_y,\\theta,\\mathrm{TOL},N_0) = (0.15, 0.15, 0.6, 0.02, 8)$.\n- Test $4$: $(\\sigma_x,\\sigma_y,\\theta,\\mathrm{TOL},N_0) = (0.30, 0.02, 0.6, 0.02, 8)$.\n\nIt outputs a single line with a list of four triples $[N_\\mathrm{iso},N_\\mathrm{ani},S]$, one for each test. The results quantify the degrees-of-freedom savings attributable to anisotropic marking. While the algorithm focuses on $h$-refinement, the conceptual comparison to $p$- and $r$-strategies is as follows: $p$-refinement would increase polynomial degree where the solution is smooth (which a Gaussian is), potentially reducing degrees of freedom without mesh changes, but it is less effective than anisotropy when the error is dominated by geometric stretching requiring directional resolution at fixed degree. $r$-refinement (node relocation) could adapt element shapes to the Hessian metric without changing connectivity; however, in the presence of strong anisotropy, $r$-moves alone may be insufficient if aspect ratios must exceed stability bounds, hence $h$-anisotropy remains critical. The implemented indicator and refinement rules reflect these principles by encoding curvature-driven directionality directly into the mesh via $h$-splits.", "answer": "```python\nimport numpy as np\n\n# Adaptive h-refinement comparison: isotropic vs anisotropic marking on a stretched Gaussian feature.\n# Environment: Python 3.12, numpy 1.23.5, scipy 1.11.4 (not used). No external input/output.\n\ndef u_and_hessian(x, y, sigx, sigy):\n    # Gaussian value and second derivatives at (x,y)\n    cx = 0.5\n    cy = 0.5\n    dx = x - cx\n    dy = y - cy\n    invsx2 = 1.0 / (sigx * sigx)\n    invsy2 = 1.0 / (sigy * sigy)\n    # Value\n    u = np.exp(-0.5 * (dx * dx * invsx2 + dy * dy * invsy2))\n    # Second derivatives\n    u_xx = ((dx * dx) * (invsx2 ** 2) - invsx2) * u\n    u_yy = ((dy * dy) * (invsy2 ** 2) - invsy2) * u\n    u_xy = (dx * dy) * (invsx2 * invsy2) * u\n    return u, u_xx, u_yy, u_xy\n\ndef element_indicator(rect, sigx, sigy):\n    x0, x1, y0, y1 = rect\n    hx = x1 - x0\n    hy = y1 - y0\n    xc = 0.5 * (x0 + x1)\n    yc = 0.5 * (y0 + y1)\n    _, u_xx, u_yy, u_xy = u_and_hessian(xc, yc, sigx, sigy)\n    area = hx * hy\n    eta = area * (abs(u_xx) * (hx ** 2) + abs(u_yy) * (hy ** 2) + 2.0 * abs(u_xy) * hx * hy)\n    return eta, abs(u_xx), abs(u_yy)\n\ndef dorfler_mark(indices, etas, theta):\n    # indices: list of element indices, etas: list of corresponding indicators\n    # return a list of indices to mark according to Dörfler with parameter theta\n    order = sorted(indices, key=lambda i: etas[i], reverse=True)\n    total = sum(etas)\n    if total <= 0.0:\n        return []\n    target = theta * total\n    acc = 0.0\n    marked = []\n    for i in order:\n        marked.append(i)\n        acc += etas[i]\n        if acc >= target:\n            break\n    return marked\n\ndef refine_mesh(mesh, marked_set, strategy, sigx, sigy):\n    # strategy: 'iso' or 'ani'\n    new_mesh = []\n    for idx, rect in enumerate(mesh):\n        if idx not in marked_set:\n            new_mesh.append(rect)\n        else:\n            x0, x1, y0, y1 = rect\n            xm = 0.5 * (x0 + x1)\n            ym = 0.5 * (y0 + y1)\n            if strategy == 'iso':\n                # split into 4 children\n                new_mesh.append((x0, xm, y0, ym))\n                new_mesh.append((xm, x1, y0, ym))\n                new_mesh.append((x0, xm, ym, y1))\n                new_mesh.append((xm, x1, ym, y1))\n            else:\n                # anisotropic: decide direction based on |u_yy|*hy vs |u_xx|*hx at center\n                hx = x1 - x0\n                hy = y1 - y0\n                xc = 0.5 * (x0 + x1)\n                yc = 0.5 * (y0 + y1)\n                _, u_xx, u_yy, _ = u_and_hessian(xc, yc, sigx, sigy)\n                if abs(u_yy) * hy >= abs(u_xx) * hx:\n                    # split along y only\n                    new_mesh.append((x0, x1, y0, ym))\n                    new_mesh.append((x0, x1, ym, y1))\n                else:\n                    # split along x only\n                    new_mesh.append((x0, xm, y0, y1))\n                    new_mesh.append((xm, x1, y0, y1))\n    return new_mesh\n\ndef adaptive_refine(sigx, sigy, theta, TOL, N0, strategy, Nmax=40000, Imax=200):\n    # Build initial uniform mesh\n    xs = np.linspace(0.0, 1.0, N0 + 1)\n    ys = np.linspace(0.0, 1.0, N0 + 1)\n    mesh = []\n    for i in range(N0):\n        for j in range(N0):\n            mesh.append((xs[i], xs[i+1], ys[j], ys[j+1]))\n    # Adaptive loop\n    for it in range(Imax):\n        n = len(mesh)\n        etas = [0.0] * n\n        # Compute indicators\n        total_eta = 0.0\n        for i, rect in enumerate(mesh):\n            eta, _, _ = element_indicator(rect, sigx, sigy)\n            etas[i] = eta\n            total_eta += eta\n        if total_eta <= TOL:\n            break\n        # Mark with Dörfler\n        indices = list(range(n))\n        marked = dorfler_mark(indices, etas, theta)\n        marked_set = set(marked)\n        # Refine\n        mesh = refine_mesh(mesh, marked_set, strategy, sigx, sigy)\n        if len(mesh) > Nmax:\n            break\n    return len(mesh)\n\ndef run_case(sigx, sigy, theta, TOL, N0):\n    N_iso = adaptive_refine(sigx, sigy, theta, TOL, N0, 'iso')\n    N_ani = adaptive_refine(sigx, sigy, theta, TOL, N0, 'ani')\n    ratio = float(N_iso) / float(N_ani) if N_ani > 0 else float('inf')\n    # Format: integers for counts, ratio as float with reasonable precision\n    return [int(N_iso), int(N_ani), float(f\"{ratio:.6f}\")]\n\ndef solve():\n    # Test suite as specified in the problem statement\n    test_cases = [\n        (0.25, 0.05, 0.6, 0.02, 8),\n        (0.25, 0.025, 0.6, 0.02, 8),\n        (0.15, 0.15, 0.6, 0.02, 8),\n        (0.30, 0.02, 0.6, 0.02, 8),\n    ]\n    results = []\n    for sigx, sigy, theta, TOL, N0 in test_cases:\n        res = run_case(sigx, sigy, theta, TOL, N0)\n        results.append(res)\n    # Print single-line output exactly as required: a list of lists, comma-separated, no extra text\n    # Ensure no spaces for strict formatting\n    def list_to_str(lst):\n        if isinstance(lst, list):\n            return \"[\" + \",\".join(list_to_str(x) for x in lst) + \"]\"\n        else:\n            return str(lst)\n    print(list_to_str(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2540498"}]}