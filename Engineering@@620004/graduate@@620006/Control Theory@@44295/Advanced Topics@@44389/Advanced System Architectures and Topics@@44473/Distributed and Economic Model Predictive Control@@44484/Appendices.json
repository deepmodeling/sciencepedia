{"hands_on_practices": [{"introduction": "In traditional control, the goal is often to steer a system to a stable, economically optimal steady state. This exercise [@problem_id:2701639] challenges that paradigm, prompting you to explore a scenario where the best long-term economic performance is achieved not at a fixed point, but through periodic operation. By deriving the conditions under which a dynamic policy outperforms any feasible steady state, you will gain a profound insight into the core principle of Economic Model Predictive Control (eMPC).", "problem": "Consider a single-input discrete-time linear time-invariant process governed by the state dynamics $x_{k+1} = a x_{k} + b u_{k}$, where $x_{k} \\in \\mathbb{R}$ is the scalar state, $u_{k} \\in \\mathbb{R}$ is the scalar input, $0 < a < 1$, and $b > 0$. The operating constraints are:\n- a pointwise input constraint $u_{k} \\in \\{0, u_{\\max}\\}$ with $u_{\\max} > 0$,\n- an actuator cooldown constraint: whenever $u_{k} = u_{\\max}$, it must be followed by at least $m \\in \\mathbb{N}$ consecutive time steps with $u = 0$ (i.e., $u_{k+1} = \\cdots = u_{k+m} = 0$).\n\nThe economic stage cost is $l(x,u) = c_{u} u - r x$, with $c_{u} > 0$ and $r > 0$, and the long-run performance of a policy is evaluated by the time-average cost. Assume the process is initialized on the corresponding periodic orbit when periodic control is considered.\n\nStart from the definitions of time-average cost and steady-state feasibility, and from the system dynamics. Derive, from first principles and using only these definitions, conditions under which the following holds: the unconstrained economically optimal steady state (i.e., a steady state computed without enforcing the cooldown and $\\{0,u_{\\max}\\}$ restrictions) is infeasible under the given constraints, yet there exists a periodic input sequence that satisfies the constraints and achieves strictly lower long-run average cost than any feasible steady state.\n\nFocus on the fastest admissible periodic policy that repeats a cycle consisting of one input pulse $u_{\\max}$ followed by exactly $m$ zeros. Compute the exact analytical expression for the unique critical value $r^{\\star}$ of the economic reward coefficient $r$ such that, for $r > r^{\\star}$, this periodic policy has strictly lower time-average cost than any feasible steady state. Express your final answer as a closed-form symbolic expression in terms of $a$, $b$, and $c_{u}$. Do not round or approximate your result. The final answer must be a single analytic expression with no units.", "solution": "The problem asks for the critical value of the economic reward coefficient, denoted $r^{\\star}$, such that for any $r > r^{\\star}$, a specific periodic control policy yields a strictly lower time-average cost than any feasible steady-state operation. The derivation must proceed from first principles.\n\nFirst, we analyze the possible steady-state operations that are feasible under the given constraints. A steady state $(x_{ss}, u_{ss})$ must satisfy the system dynamics at equilibrium, $x_{ss} = a x_{ss} + b u_{ss}$, which implies $(1-a)x_{ss} = b u_{ss}$. Since $0 < a < 1$, we have $1-a \\neq 0$, so the steady state is given by $x_{ss} = \\frac{b}{1-a} u_{ss}$. The input $u_{ss}$ must be constant for all time steps $k$. The constraints on the input are $u_{k} \\in \\{0, u_{\\max}\\}$ and a cooldown dynamic.\n\nFor a steady state, we must choose a constant input from the allowed set. The two possibilities are $u_{ss} = 0$ and $u_{ss} = u_{\\max}$.\n1.  If we choose $u_{ss} = 0$, then $x_{ss} = \\frac{b}{1-a} \\cdot 0 = 0$. The input is always $0$, so the cooldown constraint (which is triggered only when $u_k = u_{\\max}$) is never violated. Thus, $(x_{ss}, u_{ss}) = (0, 0)$ is a feasible steady state.\n2.  If we choose $u_{ss} = u_{\\max}$, this implies $u_k = u_{\\max}$ for all $k$. However, the cooldown constraint states that an input $u_k = u_{\\max}$ must be followed by $m$ steps of zero input, i.e., $u_{k+1} = 0$. This contradicts the requirement that $u_{k+1} = u_{\\max}$ for a steady state. Therefore, a steady state with $u_{ss} = u_{\\max}$ is not feasible.\n\nThe only feasible steady state is $(x_{ss}, u_{ss}) = (0, 0)$. The time-average cost for this steady state is the constant stage cost $l(0, 0) = c_u (0) - r (0) = 0$. Let this be $J_{ss}$. So, $J_{ss} = 0$.\n\nNext, we analyze the specified periodic policy. The policy has a period of $N = m+1$ time steps. The input sequence over one period is $u_0 = u_{\\max}$ and $u_k = 0$ for $k \\in \\{1, 2, \\dots, m\\}$. This policy is admissible by construction, as the pulse of $u_{\\max}$ is followed by $m$ zero-input steps.\n\nThe time-average cost for any policy is given by $J = \\lim_{T \\to \\infty} \\frac{1}{T} \\sum_{k=0}^{T-1} l(x_k, u_k)$. For a periodic policy with period $N$ where the system operates on a periodic orbit, this simplifies to the average over one period:\n$$J_{p} = \\frac{1}{N} \\sum_{k=0}^{N-1} l(x_k, u_k) = \\frac{1}{N} \\sum_{k=0}^{N-1} (c_u u_k - r x_k)$$\nThis can be written in terms of the average input $\\bar{u} = \\frac{1}{N} \\sum_{k=0}^{N-1} u_k$ and average state $\\bar{x} = \\frac{1}{N} \\sum_{k=0}^{N-1} x_k$ as $J_p = c_u \\bar{u} - r \\bar{x}$.\n\nA crucial relationship exists between the average state and average input for any periodic trajectory. Summing the state dynamics $x_{k+1} = a x_k + b u_k$ over one full period from $k=0$ to $k=N-1$:\n$$\\sum_{k=0}^{N-1} x_{k+1} = a \\sum_{k=0}^{N-1} x_k + b \\sum_{k=0}^{N-1} u_k$$\nOn a periodic orbit, $x_N = x_0$. The sum on the left is $\\sum_{j=1}^{N} x_j = x_N + \\sum_{j=1}^{N-1} x_j = x_0 + \\sum_{j=1}^{N-1} x_j = \\sum_{k=0}^{N-1} x_k$.\nTherefore, the equation becomes:\n$$\\sum_{k=0}^{N-1} x_k = a \\sum_{k=0}^{N-1} x_k + b \\sum_{k=0}^{N-1} u_k$$\n$$(1-a) \\sum_{k=0}^{N-1} x_k = b \\sum_{k=0}^{N-1} u_k$$\nDividing by the period $N$, we obtain the relation between the average values:\n$$(1-a) \\bar{x} = b \\bar{u} \\implies \\bar{x} = \\frac{b}{1-a} \\bar{u}$$\nThis elegant result holds for any periodic orbit of the system.\n\nNow, we substitute this into the expression for the average cost $J_p$:\n$$J_p = c_u \\bar{u} - r \\left( \\frac{b}{1-a} \\bar{u} \\right) = \\left( c_u - \\frac{rb}{1-a} \\right) \\bar{u}$$\nFor the specific periodic policy with period $N = m+1$ and input sequence $\\{u_{\\max}, 0, \\dots, 0\\}$, the average input is:\n$$\\bar{u} = \\frac{1}{m+1} (u_{\\max} + 0 + \\dots + 0) = \\frac{u_{\\max}}{m+1}$$\nThe average cost of this periodic policy is thus:\n$$J_p = \\left( c_u - \\frac{rb}{1-a} \\right) \\frac{u_{\\max}}{m+1}$$\nThe problem asks for the condition under which this periodic policy is strictly superior to any feasible steady state. As we found, the best (and only) feasible steady-state policy has a cost of $J_{ss} = 0$. The condition is thus $J_p < J_{ss}$, which translates to $J_p < 0$.\n$$\\left( c_u - \\frac{rb}{1-a} \\right) \\frac{u_{\\max}}{m+1} < 0$$\nGiven that $u_{\\max} > 0$ and $m+1 > 0$, the sign of the expression is determined entirely by the term in parentheses. The inequality simplifies to:\n$$c_u - \\frac{rb}{1-a} < 0$$\nWe seek to find the condition on $r$. Rearranging the inequality:\n$$c_u < \\frac{rb}{1-a}$$\nSince $b > 0$ and $1-a > 0$ (because $0 < a < 1$), we can multiply both sides by $\\frac{1-a}{b}$ without changing the inequality direction:\n$$c_u \\frac{1-a}{b} < r$$\nThis inequality, $r > c_u \\frac{1-a}{b}$, defines the range of the reward coefficient $r$ for which the periodic policy is strictly more economical than the zero steady state. The critical value $r^{\\star}$ is the value at which this transition occurs.\n\nTherefore, the critical value is:\n$$r^{\\star} = c_u \\frac{1-a}{b}$$\nFor $r > r^{\\star}$, the periodic policy achieves a negative average cost, making it strictly better than the zero-cost steady state. The unconstrained economically optimal steady state, which would seek to maximize $x$ by using a large $u$ when $c_u - \\frac{rb}{1-a} < 0$, is indeed infeasible, as required by the problem statement for $r > r^{\\star}$.", "answer": "$$\\boxed{c_{u} \\frac{1-a}{b}}$$", "id": "2701639"}, {"introduction": "Once we accept that the optimal operation of a complex system may be dynamic, the question becomes how to coordinate multiple subsystems to achieve this. This practice [@problem_id:2701668] introduces a powerful answer through dual ascent, an algorithm that mimics a market mechanism. You will perform one iteration of this price-based coordination, where a dual variable, or 'price' $\\lambda$, signals the scarcity of a shared resource to guide independent agents toward a system-wide optimal solution.", "problem": "Consider a single coordination step in a distributed economic Model Predictive Control (MPC) scheme for two subsystems with scalar inputs. At a given prediction step, the centralized stage problem is to minimize the sum of local economic costs under a shared resource balance. The local economic stage costs are strictly convex quadratics given by $J_{1}(u_{1})=\\tfrac{1}{2} q_{1} u_{1}^{2}+r_{1} u_{1}$ and $J_{2}(u_{2})=\\tfrac{1}{2} q_{2} u_{2}^{2}+r_{2} u_{2}$, with individual input constraints $u_{1} \\in [u_{1}^{\\min},u_{1}^{\\max}]$ and $u_{2} \\in [u_{2}^{\\min},u_{2}^{\\max}]$. The agents are coupled by the resource-balance equality constraint $u_{1}+u_{2}=\\bar{u}$.\n\nStarting from the definition of the Lagrangian for the equality-constrained convex program and the subgradient ascent on the dual function using the coupling constraint residual as subgradient, carry out one iteration of dual ascent as follows:\n- For a given current price (dual variable) $\\lambda_{k}$, compute the local optimal inputs by minimizing the local Lagrangians with respect to $u_{1}$ and $u_{2}$ subject to their respective box constraints.\n- Update the price using a constant step size $\\alpha$.\n\nUse the following data for this step:\n- $q_{1}=2$, $r_{1}=-3$, $u_{1}^{\\min}=0$, $u_{1}^{\\max}=2$.\n- $q_{2}=1$, $r_{2}=2$, $u_{2}^{\\min}=-3$, $u_{2}^{\\max}=1$.\n- Coupling parameter $\\bar{u}=-\\tfrac{3}{2}$.\n- Current price $\\lambda_{k}=\\tfrac{6}{5}$.\n- Step size $\\alpha=\\tfrac{1}{2}$.\n\nReport the result of this one dual-ascent iteration as the row vector $\\big(u_{1,k}^{\\star},\\,u_{2,k}^{\\star},\\,\\lambda_{k+1}\\big)$.\n\nYour final answer must be a single row matrix. No rounding is required, and you must present exact values (fractions are acceptable). Do not include any units.", "solution": "The problem presented is a valid, well-posed exercise in convex optimization, specifically an application of dual decomposition to a distributed economic model predictive control scenario. All necessary parameters are provided, and the problem is scientifically sound. We shall proceed with the solution.\n\nThe centralized optimization problem is to minimize the total economic cost, which is the sum of the local costs $J_{1}(u_{1})$ and $J_{2}(u_{2})$, subject to local and coupling constraints.\nThe problem is formulated as:\n$$\n\\min_{u_{1}, u_{2}} \\quad J_{1}(u_{1}) + J_{2}(u_{2}) = \\left(\\frac{1}{2} q_{1} u_{1}^{2} + r_{1} u_{1}\\right) + \\left(\\frac{1}{2} q_{2} u_{2}^{2} + r_{2} u_{2}\\right)\n$$\nsubject to:\n$$\nu_{1} + u_{2} = \\bar{u} \\\\\nu_{1} \\in [u_{1}^{\\min}, u_{1}^{\\max}] \\\\\nu_{2} \\in [u_{2}^{\\min}, u_{2}^{\\max}]\n$$\nThis is a convex optimization problem because the objective function is a sum of strictly convex quadratic functions (since $q_{1} > 0$ and $q_{2} > 0$), and the constraints define a convex set.\n\nTo solve this in a distributed manner using dual decomposition, we relax the coupling constraint $u_{1} + u_{2} - \\bar{u} = 0$ by introducing a Lagrange multiplier, or dual variable, $\\lambda$. The Lagrangian function $L(u_{1}, u_{2}, \\lambda)$ is:\n$$\nL(u_{1}, u_{2}, \\lambda) = J_{1}(u_{1}) + J_{2}(u_{2}) + \\lambda(u_{1} + u_{2} - \\bar{u})\n$$\nThe Lagrangian can be separated into components corresponding to each subsystem:\n$$\nL(u_{1}, u_{2}, \\lambda) = \\left( J_{1}(u_{1}) + \\lambda u_{1} \\right) + \\left( J_{2}(u_{2}) + \\lambda u_{2} \\right) - \\lambda \\bar{u}\n$$\nLet us define the local Lagrangians for each subsystem $i \\in \\{1, 2\\}$:\n$$\nL_{i}(u_{i}, \\lambda) = J_{i}(u_{i}) + \\lambda u_{i}\n$$\nThe dual ascent algorithm proceeds in two steps at each iteration $k$:\n$1$. For a given price $\\lambda_{k}$, each subsystem independently solves its local optimization problem to find the optimal inputs $u_{1,k}^{\\star}$ and $u_{2,k}^{\\star}$:\n$$\nu_{i,k}^{\\star} = \\arg\\min_{u_{i} \\in [u_{i}^{\\min}, u_{i}^{\\max}]} L_{i}(u_{i}, \\lambda_{k})\n$$\n$2$. The price $\\lambda_{k}$ is updated using subgradient ascent, where the subgradient is the residual of the relaxed coupling constraint. The update rule is:\n$$\n\\lambda_{k+1} = \\lambda_{k} + \\alpha (u_{1,k}^{\\star} + u_{2,k}^{\\star} - \\bar{u})\n$$\nwhere $\\alpha > 0$ is the step size.\n\nWe now perform one iteration with the given data:\n- $q_{1}=2$, $r_{1}=-3$, $u_{1}^{\\min}=0$, $u_{1}^{\\max}=2$.\n- $q_{2}=1$, $r_{2}=2$, $u_{2}^{\\min}=-3$, $u_{2}^{\\max}=1$.\n- $\\bar{u}=-\\frac{3}{2}$.\n- Initial price $\\lambda_{k}=\\frac{6}{5}$.\n- Step size $\\alpha=\\frac{1}{2}$.\n\nFirst, we solve the local minimization problems for $u_{1}$ and $u_{2}$.\nFor subsystem $1$:\n$$\nL_{1}(u_{1}, \\lambda_{k}) = \\frac{1}{2} q_{1} u_{1}^{2} + r_{1} u_{1} + \\lambda_{k} u_{1} = \\frac{1}{2} (2) u_{1}^{2} + (-3) u_{1} + \\frac{6}{5} u_{1} = u_{1}^{2} - \\frac{9}{5} u_{1}\n$$\nTo find the unconstrained minimum, we set the derivative with respect to $u_{1}$ to zero:\n$$\n\\frac{\\partial L_{1}}{\\partial u_{1}} = 2 u_{1} - \\frac{9}{5} = 0 \\implies u_{1}^{\\text{unc}} = \\frac{9}{10}\n$$\nThe local constraint for $u_{1}$ is $[0, 2]$. Since $0 \\le \\frac{9}{10} \\le 2$, the unconstrained minimum is feasible. Thus, the optimal local input is:\n$$\nu_{1,k}^{\\star} = \\frac{9}{10}\n$$\n\nFor subsystem $2$:\n$$\nL_{2}(u_{2}, \\lambda_{k}) = \\frac{1}{2} q_{2} u_{2}^{2} + r_{2} u_{2} + \\lambda_{k} u_{2} = \\frac{1}{2} (1) u_{2}^{2} + (2) u_{2} + \\frac{6}{5} u_{2} = \\frac{1}{2} u_{2}^{2} + \\frac{16}{5} u_{2}\n$$\nTo find the unconstrained minimum, we set the derivative with respect to $u_{2}$ to zero:\n$$\n\\frac{\\partial L_{2}}{\\partial u_{2}} = u_{2} + \\frac{16}{5} = 0 \\implies u_{2}^{\\text{unc}} = -\\frac{16}{5} = -3.2\n$$\nThe local constraint for $u_{2}$ is $[-3, 1]$. Since $u_{2}^{\\text{unc}} = -3.2 < -3$, the minimum of the convex function $L_{2}$ over the interval is at the lower bound. Thus, the optimal local input is:\n$$\nu_{2,k}^{\\star} = u_{2}^{\\min} = -3\n$$\n\nNext, we update the price $\\lambda$. The residual of the coupling constraint is:\n$$\ns_{k} = u_{1,k}^{\\star} + u_{2,k}^{\\star} - \\bar{u} = \\frac{9}{10} + (-3) - \\left(-\\frac{3}{2}\\right) = \\frac{9}{10} - \\frac{30}{10} + \\frac{15}{10} = \\frac{9 - 30 + 15}{10} = -\\frac{6}{10} = -\\frac{3}{5}\n$$\nThe updated price $\\lambda_{k+1}$ is calculated as:\n$$\n\\lambda_{k+1} = \\lambda_{k} + \\alpha s_{k} = \\frac{6}{5} + \\frac{1}{2} \\left(-\\frac{3}{5}\\right) = \\frac{6}{5} - \\frac{3}{10} = \\frac{12}{10} - \\frac{3}{10} = \\frac{9}{10}\n$$\n\nThe result of this single dual-ascent iteration is the row vector $(u_{1,k}^{\\star}, u_{2,k}^{\\star}, \\lambda_{k+1})$.\nSubstituting the calculated values, we have:\n$$\n\\left( \\frac{9}{10}, -3, \\frac{9}{10} \\right)\n$$", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{9}{10} & -3 & \\frac{9}{10} \\end{pmatrix}}$$", "id": "2701668"}, {"introduction": "While dual ascent provides an intuitive entry into distributed optimization, many modern applications rely on more robust algorithms like the Alternating Direction Method of Multipliers (ADMM). The key to using ADMM is often in the problem formulation itself, which is the focus of this exercise [@problem_id:2701699]. You will learn to transform a centrally coupled problem into a consensus-based structure by creating local variable copies, a critical step in preparing complex systems for distributed control.", "problem": "Consider a distributed Model Predictive Control (MPC) problem with $N \\in \\mathbb{N}$ agents. For each agent $i \\in \\{1,\\dots,N\\}$, let the local decision variable be $x_i \\in \\mathbb{R}^{n_i}$, with a convex local stage cost $f_i(x_i)$ and a convex feasible set $\\mathcal{X}_i \\subseteq \\mathbb{R}^{n_i}$. The agents are coupled through a shared economic variable $z \\in \\mathbb{R}^{m}$ that aggregates a linear image of each agent’s decision via a known matrix $C_i \\in \\mathbb{R}^{m \\times n_i}$. The global economic cost is $g(z)$, and $z$ is constrained to a convex set $\\mathcal{Z} \\subseteq \\mathbb{R}^{m}$. The finite-horizon convex optimization problem defining the centralized economic MPC (eMPC) coordination is\n$$\n\\min_{\\{x_i\\}_{i=1}^{N},\\, z} \\;\\; \\sum_{i=1}^{N} f_i(x_i) \\;+\\; g(z)\n$$\nsubject to the coupling constraints $C_i x_i = z$ for all $i \\in \\{1,\\dots,N\\}$ and the feasibility constraints $x_i \\in \\mathcal{X}_i$, $z \\in \\mathcal{Z}$.\n\nTo obtain a consensus formulation suitable for the Alternating Direction Method of Multipliers (ADMM), introduce local copies $z_i \\in \\mathbb{R}^{m}$ for each agent and enforce the constraints $C_i x_i - z_i = 0$ and $z_i - z = 0$ for all $i \\in \\{1,\\dots,N\\}$. Use the indicator function $\\iota_{\\mathcal{S}}(y)$, defined as $\\iota_{\\mathcal{S}}(y) = 0$ if $y \\in \\mathcal{S}$ and $\\iota_{\\mathcal{S}}(y) = +\\infty$ otherwise, to encode the set constraints $x_i \\in \\mathcal{X}_i$ and $z \\in \\mathcal{Z}$ directly in the objective.\n\nLet $\\rho > 0$ be a given penalty parameter. Let $\\lambda_i \\in \\mathbb{R}^{m}$ and $\\mu_i \\in \\mathbb{R}^{m}$ denote the Lagrange multipliers associated with the constraints $C_i x_i - z_i = 0$ and $z_i - z = 0$, respectively. Write the unscaled augmented Lagrangian $L_{\\rho}(\\{x_i\\}, \\{z_i\\}, z, \\{\\lambda_i\\}, \\{\\mu_i\\})$ for this ADMM consensus formulation as a single analytic expression. Your final answer must be this expression only, with no additional text or derivations.", "solution": "The problem statement is assessed to be valid. It is a well-posed question within the established mathematical framework of control theory and distributed optimization. All components are clearly defined, scientifically sound, and internally consistent, permitting a direct and unambiguous solution.\n\nThe task is to construct the unscaled augmented Lagrangian for a distributed economic model predictive control problem, reformulated for the Alternating Direction Method of Multipliers (ADMM).\n\nFirst, we formalize the optimization problem according to the given consensus formulation. The original centralized problem is:\n$$\n\\min_{\\{x_i\\}_{i=1}^{N},\\, z} \\;\\; \\sum_{i=1}^{N} f_i(x_i) \\;+\\; g(z)\n$$\nsubject to the constraints $C_i x_i = z$, $x_i \\in \\mathcal{X}_i$, and $z \\in \\mathcal{Z}$.\n\nThe ADMM formulation introduces local copies $z_i \\in \\mathbb{R}^{m}$ for the shared economic variable $z$. The single coupling constraint $C_i x_i = z$ is decomposed into two sets of equality constraints:\n$1$. $C_i x_i - z_i = 0$ for each agent $i \\in \\{1, \\dots, N\\}$.\n$2$. $z_i - z = 0$ for each agent $i \\in \\{1, \\dots, N\\}$, which enforces the consensus $z_1 = z_2 = \\dots = z_N = z$.\n\nThe set membership constraints $x_i \\in \\mathcal{X}_i$ and $z \\in \\mathcal{Z}$ are incorporated into the objective function using the indicator function $\\iota_{\\mathcal{S}}(y)$, where $\\iota_{\\mathcal{S}}(y) = 0$ if $y \\in \\mathcal{S}$ and $\\iota_{\\mathcal{S}}(y) = +\\infty$ if $y \\notin \\mathcal{S}$.\n\nTherefore, the optimization problem for which the augmented Lagrangian must be constructed is:\n$$\n\\min_{\\{x_i\\}, \\{z_i\\}, z} \\quad \\sum_{i=1}^{N} \\left(f_i(x_i) + \\iota_{\\mathcal{X}_i}(x_i)\\right) + g(z) + \\iota_{\\mathcal{Z}}(z)\n$$\nsubject to:\n$$\n\\begin{cases}\nC_i x_i - z_i = 0, & \\forall i \\in \\{1, \\dots, N\\} \\\\\nz_i - z = 0, & \\forall i \\in \\{1, \\dots, N\\}\n\\end{cases}\n$$\n\nThe augmented Lagrangian $L_{\\rho}$ for a generic problem $\\min_{w} \\mathcal{F}(w)$ subject to $Aw - b = 0$ is given by:\n$$\nL_{\\rho}(w, \\nu) = \\mathcal{F}(w) + \\nu^T (Aw - b) + \\frac{\\rho}{2} \\|Aw - b\\|_2^2\n$$\nwhere $\\nu$ is the vector of Lagrange multipliers (dual variables) and $\\rho > 0$ is the penalty parameter.\n\nWe apply this definition to our specific problem.\nThe objective function is $\\mathcal{F}(\\{x_i\\}, \\{z_i\\}, z) = \\sum_{i=1}^{N} \\left(f_i(x_i) + \\iota_{\\mathcal{X}_i}(x_i)\\right) + g(z) + \\iota_{\\mathcal{Z}}(z)$.\nThe equality constraints are $C_i x_i - z_i = 0$ with dual variables $\\lambda_i \\in \\mathbb{R}^m$, and $z_i - z = 0$ with dual variables $\\mu_i \\in \\mathbb{R}^m$.\n\nThe augmented Lagrangian $L_{\\rho}(\\{x_i\\}, \\{z_i\\}, z, \\{\\lambda_i\\}, \\{\\mu_i\\})$ is the sum of the objective function and the Lagrangian and quadratic penalty terms for each set of constraints.\n\nThe term for the first set of constraints, summed over all agents, is:\n$$\n\\sum_{i=1}^{N} \\left( \\lambda_i^T (C_i x_i - z_i) + \\frac{\\rho}{2} \\|C_i x_i - z_i\\|_2^2 \\right)\n$$\nThe term for the second set of constraints, summed over all agents, is:\n$$\n\\sum_{i=1}^{N} \\left( \\mu_i^T (z_i - z) + \\frac{\\rho}{2} \\|z_i - z\\|_2^2 \\right)\n$$\nCombining all components yields the complete unscaled augmented Lagrangian. The expression is structured by grouping terms that are dependent on the central variable $z$ and those that can be collected under a summation over the agents $i$:\n$$\nL_{\\rho}(\\{x_i\\}, \\{z_i\\}, z, \\{\\lambda_i\\}, \\{\\mu_i\\}) = g(z) + \\iota_{\\mathcal{Z}}(z) + \\sum_{i=1}^{N} \\left[ f_i(x_i) + \\iota_{\\mathcal{X}_i}(x_i) + \\lambda_i^T(C_i x_i - z_i) + \\mu_i^T(z_i - z) + \\frac{\\rho}{2} \\left( \\|C_i x_i - z_i\\|_2^2 + \\|z_i - z\\|_2^2 \\right) \\right]\n$$\nThis is the required single analytic expression.", "answer": "$$\n\\boxed{g(z) + \\iota_{\\mathcal{Z}}(z) + \\sum_{i=1}^{N} \\left[ f_i(x_i) + \\iota_{\\mathcal{X}_i}(x_i) + \\lambda_i^T(C_i x_i - z_i) + \\mu_i^T(z_i - z) + \\frac{\\rho}{2} \\left( \\|C_i x_i - z_i\\|_2^2 + \\|z_i - z\\|_2^2 \\right) \\right]}\n$$", "id": "2701699"}]}