{"hands_on_practices": [{"introduction": "Real-world systems, from chemical plants to aircraft, are inherently multi-input multi-output (MIMO) and are often viewed as interconnections of smaller subsystems. This exercise provides foundational practice in translating this physical structure into a mathematical one. By starting with a partitioned state-space model, you will derive the corresponding block structure of the system's transfer function matrix, $G(s)$, from first principles [@problem_id:2713773]. This skill is essential for understanding how specific input groups influence specific output groups and forms the basis for decentralized control and interaction analysis.", "problem": "Consider a continuous-time linear time-invariant (LTI) multi-input multi-output (MIMO) system with state, input, and output described by\n$$\\dot{x}(t) = A x(t) + B u(t), \\quad y(t) = C x(t) + D u(t),$$\nwhere $x(t) \\in \\mathbb{R}^{n}$, $u(t) \\in \\mathbb{R}^{m}$, and $y(t) \\in \\mathbb{R}^{p}$. The inputs and outputs are grouped into two subsystems each, so that\n$$u(t) = \\begin{pmatrix} u_{1}(t) \\\\ u_{2}(t) \\end{pmatrix}, \\quad y(t) = \\begin{pmatrix} y_{1}(t) \\\\ y_{2}(t) \\end{pmatrix},$$\nwith $u_{1}(t) \\in \\mathbb{R}^{m_{1}}$, $u_{2}(t) \\in \\mathbb{R}^{m_{2}}$, $y_{1}(t) \\in \\mathbb{R}^{p_{1}}$, $y_{2}(t) \\in \\mathbb{R}^{p_{2}}$, and $m_{1} + m_{2} = m$, $p_{1} + p_{2} = p$. The matrices $B$, $C$, and $D$ are conformably partitioned as\n$$B = \\begin{pmatrix} B_{1} & B_{2} \\end{pmatrix}, \\quad C = \\begin{pmatrix} C_{1} \\\\ C_{2} \\end{pmatrix}, \\quad D = \\begin{pmatrix} D_{11} & D_{12} \\\\ D_{21} & D_{22} \\end{pmatrix},$$\nwhere $B_{j} \\in \\mathbb{R}^{n \\times m_{j}}$, $C_{i} \\in \\mathbb{R}^{p_{i} \\times n}$, and $D_{ij} \\in \\mathbb{R}^{p_{i} \\times m_{j}}$ for $i \\in \\{1,2\\}$ and $j \\in \\{1,2\\}$.\n\nStarting from first principles using the Laplace transform of the state equations under zero initial conditions and the definition of the transfer matrix as the mapping between the Laplace transforms $U(s)$ and $Y(s)$, derive the input-output transfer matrix $G(s)$ and show how the grouping of inputs and outputs induces a $2 \\times 2$ block structure. Express $G(s)$ explicitly in terms of $A$, $B_{1}$, $B_{2}$, $C_{1}$, $C_{2}$, $D_{ij}$, and the complex Laplace variable $s$, as a single $2 \\times 2$ block matrix. Your derivation should make clear which sub-block maps each input group to each output group, and why.\n\nProvide your final result as a single closed-form analytic expression for the $2 \\times 2$ block transfer matrix $G(s)$. No numerical evaluation is required, and no rounding is necessary. Do not include units.", "solution": "The problem statement is examined for validity before any attempt at a solution is made.\n\nFirst, we extract the givens of the problem.\nThe system is a continuous-time linear time-invariant (LTI) multi-input multi-output (MIMO) system described by the state-space equations:\n$$\n\\dot{x}(t) = A x(t) + B u(t)\n$$\n$$\ny(t) = C x(t) + D u(t)\n$$\nThe state, input, and output vectors have dimensions $x(t) \\in \\mathbb{R}^{n}$, $u(t) \\in \\mathbb{R}^{m}$, and $y(t) \\in \\mathbb{R}^{p}$.\nThe initial conditions are specified as zero: $x(0) = 0$.\nThe input and output vectors are partitioned as:\n$$\nu(t) = \\begin{pmatrix} u_{1}(t) \\\\ u_{2}(t) \\end{pmatrix}, \\quad y(t) = \\begin{pmatrix} y_{1}(t) \\\\ y_{2}(t) \\end{pmatrix}\n$$\nThe dimensions of these partitions are $u_{1}(t) \\in \\mathbb{R}^{m_{1}}$, $u_{2}(t) \\in \\mathbb{R}^{m_{2}}$, $y_{1}(t) \\in \\mathbb{R}^{p_{1}}$, $y_{2}(t) \\in \\mathbb{R}^{p_{2}}$, with $m_{1} + m_{2} = m$ and $p_{1} + p_{2} = p$.\nThe system matrices $B$, $C$, and $D$ are partitioned conformably:\n$$\nB = \\begin{pmatrix} B_{1} & B_{2} \\end{pmatrix}, \\quad C = \\begin{pmatrix} C_{1} \\\\ C_{2} \\end{pmatrix}, \\quad D = \\begin{pmatrix} D_{11} & D_{12} \\\\ D_{21} & D_{22} \\end{pmatrix}\n$$\nThe dimensions of the matrix partitions are $B_{j} \\in \\mathbb{R}^{n \\times m_{j}}$, $C_{i} \\in \\mathbb{R}^{p_{i} \\times n}$, and $D_{ij} \\in \\mathbb{R}^{p_{i} \\times m_{j}}$ for $i \\in \\{1,2\\}$ and $j \\in \\{1,2\\}$.\nThe task is to derive the input-output transfer matrix $G(s)$ from first principles, expressing it as a $2 \\times 2$ block matrix in terms of the given partitioned matrices and the Laplace variable $s$.\n\nNext, we validate the problem statement.\nThe problem is scientifically grounded, rooted in the fundamental principles of linear systems and control theory. The state-space representation and the derivation of a transfer function via Laplace transform are standard, well-established procedures. The problem is well-posed, providing all necessary information (equations, partitions, zero initial conditions) to derive a unique mathematical expression for the transfer matrix. The language is objective and mathematically precise. The setup is complete and internally consistent, with all matrix and vector dimensions being conformable for the specified operations. The problem is a formalizable and relevant exercise in the analysis of MIMO systems. It does not violate any criteria for invalidity.\n\nThe problem is deemed valid. We proceed with the solution.\n\nThe derivation begins by applying the Laplace transform to the state-space equations. Let $X(s)$, $U(s)$, and $Y(s)$ be the Laplace transforms of $x(t)$, $u(t)$, and $y(t)$, respectively. Applying the transform to the state equation yields:\n$$\n\\mathcal{L}\\{\\dot{x}(t)\\} = \\mathcal{L}\\{A x(t) + B u(t)\\}\n$$\nUsing the differentiation property of the Laplace transform, $\\mathcal{L}\\{\\dot{x}(t)\\} = sX(s) - x(0)$. Given the condition of zero initial state, $x(0)=0$, this simplifies to $sX(s)$. The equation becomes:\n$$\nsX(s) = AX(s) + BU(s)\n$$\nThis is an algebraic equation in the Laplace domain. We must solve for the state vector transform, $X(s)$, in terms of the input transform, $U(s)$.\n$$\nsX(s) - AX(s) = BU(s)\n$$\nFactoring $X(s)$ requires the use of the identity matrix $I$ of dimension $n \\times n$:\n$$\n(sI - A)X(s) = BU(s)\n$$\nAssuming that $s$ is not an eigenvalue of $A$, the matrix $(sI - A)$ is invertible. We can pre-multiply by its inverse, $(sI - A)^{-1}$, which is the resolvent of matrix $A$.\n$$\nX(s) = (sI - A)^{-1} B U(s)\n$$\nNow, we apply the Laplace transform to the output equation:\n$$\n\\mathcal{L}\\{y(t)\\} = \\mathcal{L}\\{C x(t) + D u(t)\\}\n$$\n$$\nY(s) = CX(s) + DU(s)\n$$\nSubstitute the expression for $X(s)$ into the transformed output equation:\n$$\nY(s) = C(sI - A)^{-1} B U(s) + D U(s)\n$$\nBy factoring out $U(s)$ on the right, we obtain the relationship between the input and output transforms:\n$$\nY(s) = \\left[ C(sI - A)^{-1} B + D \\right] U(s)\n$$\nBy definition, the transfer matrix $G(s)$ is the matrix that relates the input transform $U(s)$ to the output transform $Y(s)$ as $Y(s) = G(s)U(s)$. Therefore, we identify the transfer matrix as:\n$$\nG(s) = C(sI - A)^{-1} B + D\n$$\nTo reveal the $2 \\times 2$ block structure induced by the partitioning of inputs and outputs, we substitute the partitioned forms of the matrices $B$, $C$, and $D$ into this expression.\n$$\nG(s) = \\begin{pmatrix} C_{1} \\\\ C_{2} \\end{pmatrix} (sI - A)^{-1} \\begin{pmatrix} B_{1} & B_{2} \\end{pmatrix} + \\begin{pmatrix} D_{11} & D_{12} \\\\ D_{21} & D_{22} \\end{pmatrix}\n$$\nThe product of the block matrices $C$ and $B_j$ with the central matrix $(sI-A)^{-1}$ is carried out according to the rules of block matrix multiplication:\n$$\n\\begin{pmatrix} C_{1} \\\\ C_{2} \\end{pmatrix} (sI - A)^{-1} \\begin{pmatrix} B_{1} & B_{2} \\end{pmatrix} = \\begin{pmatrix} C_{1}(sI - A)^{-1}B_{1} & C_{1}(sI - A)^{-1}B_{2} \\\\ C_{2}(sI - A)^{-1}B_{1} & C_{2}(sI - A)^{-1}B_{2} \\end{pmatrix}\n$$\nNow, we add the partitioned feedthrough matrix $D$:\n$$\nG(s) = \\begin{pmatrix} C_{1}(sI - A)^{-1}B_{1} & C_{1}(sI - A)^{-1}B_{2} \\\\ C_{2}(sI - A)^{-1}B_{1} & C_{2}(sI - A)^{-1}B_{2} \\end{pmatrix} + \\begin{pmatrix} D_{11} & D_{12} \\\\ D_{21} & D_{22} \\end{pmatrix}\n$$\nThe sum of two conformably partitioned block matrices is the block-wise sum of their corresponding entries. This results in the final $2 \\times 2$ block structure for the transfer matrix $G(s)$:\n$$\nG(s) = \\begin{pmatrix} C_{1}(sI - A)^{-1}B_{1} + D_{11} & C_{1}(sI - A)^{-1}B_{2} + D_{12} \\\\ C_{2}(sI - A)^{-1}B_{1} + D_{21} & C_{2}(sI - A)^{-1}B_{2} + D_{22} \\end{pmatrix}\n$$\nThis expression shows the explicit $2 \\times 2$ block form of the system transfer matrix. If we denote $G(s)$ as $G(s) = \\begin{pmatrix} G_{11}(s) & G_{12}(s) \\\\ G_{21}(s) & G_{22}(s) \\end{pmatrix}$, then the input-output relationship $Y(s) = G(s)U(s)$ can be written as:\n$$\n\\begin{pmatrix} Y_{1}(s) \\\\ Y_{2}(s) \\end{pmatrix} = \\begin{pmatrix} G_{11}(s) & G_{12}(s) \\\\ G_{21}(s) & G_{22}(s) \\end{pmatrix} \\begin{pmatrix} U_{1}(s) \\\\ U_{2}(s) \\end{pmatrix}\n$$\nFrom this, it is evident that each sub-block $G_{ij}(s)$ maps the input group $j$ to the output group $i$. Specifically:\n$G_{11}(s) = C_{1}(sI - A)^{-1}B_{1} + D_{11}$ maps $U_{1}(s)$ to $Y_{1}(s)$.\n$G_{12}(s) = C_{1}(sI - A)^{-1}B_{2} + D_{12}$ maps $U_{2}(s)$ to $Y_{1}(s)$.\n$G_{21}(s) = C_{2}(sI - A)^{-1}B_{1} + D_{21}$ maps $U_{1}(s)$ to $Y_{2}(s)$.\n$G_{22}(s) = C_{2}(sI - A)^{-1}B_{2} + D_{22}$ maps $U_{2}(s)$ to $Y_{2}(s)$.\nThis completes the derivation as requested. The final expression is a single closed-form analytic expression for the $2 \\times 2$ block transfer matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nC_{1}(sI - A)^{-1}B_{1} + D_{11} & C_{1}(sI - A)^{-1}B_{2} + D_{12} \\\\\nC_{2}(sI - A)^{-1}B_{1} + D_{21} & C_{2}(sI - A)^{-1}B_{2} + D_{22}\n\\end{pmatrix}\n}\n$$", "id": "2713773"}, {"introduction": "Once a plant model $G(s)$ is established, the next step in control design is to place it within a feedback loop. This practice focuses on the fundamental algebraic building blocks of multivariable feedback theory: the loop transfer matrix $L(s) = G(s)K(s)$ and the return difference matrix $I+L(s)$ [@problem_id:2713799]. Deriving these matrices for a specific system and controller is a critical first step that connects the open-loop components to the closed-loop system's behavior, paving the way for the analysis of stability and performance.", "problem": "Consider a two-input two-output linear time-invariant plant with transfer matrix\n$$\nG(s)=\\begin{pmatrix}\n\\dfrac{1}{s+1} & \\dfrac{1}{s+2} \\\\\n0 & \\dfrac{2}{s+3}\n\\end{pmatrix},\n$$\nand a static multivariable controller\n$$\nK=\\begin{pmatrix}\nk_{1} & 0\\\\\nk_{2} & k_{3}\n\\end{pmatrix},\n$$\nwhere $k_{1}$, $k_{2}$, and $k_{3}$ are real constants. The plant and controller are interconnected in standard negative feedback, where the controller acts on the tracking error $e=r-y$ to produce the control input $u=K e$, the plant output is $y=G u$, and the measurement is subtracted from the reference.\n\nStarting from the foundational block-diagram relations for negative feedback and the definition of loop transfer in multivariable feedback, do the following:\n\n- Derive the loop transfer matrix $L(s)$ and the return difference matrix $I+L(s)$.\n- Evaluate both at $s=0$.\n- Then, using only matrix algebra, compute the determinant of the return difference at $s=0$ and simplify it to a closed-form analytic expression in terms of $k_{1}$, $k_{2}$, and $k_{3}$.\n\nAdditionally, explain (qualitatively, without appealing to any unintroduced shortcut formulas) why the loop transfer and return difference play a central role in quantifying multivariable gain and phase margins, in particular via their connection to sensitivity and complementary sensitivity.\n\nYour final reported answer must be the simplified closed-form expression for $\\det(I+L(0))$ in terms of $k_{1}$, $k_{2}$, and $k_{3}$. No numerical substitution is required, and no rounding is needed. Do not include units in your final answer.", "solution": "The problem as stated is well-posed, scientifically grounded, and contains all necessary information for a complete solution. It is a standard exercise in multivariable control theory. We shall proceed with the derivation.\n\nThe fundamental relations for the negative feedback system are given as:\n$$\n\\mathbf{y}(s) = \\mathbf{G}(s) \\mathbf{u}(s)\n$$\n$$\n\\mathbf{u}(s) = \\mathbf{K} \\mathbf{e}(s)\n$$\n$$\n\\mathbf{e}(s) = \\mathbf{r}(s) - \\mathbf{y}(s)\n$$\nwhere $\\mathbf{y}(s)$ is the plant output, $\\mathbf{u}(s)$ is the control input, $\\mathbf{e}(s)$ is the tracking error, and $\\mathbf{r}(s)$ is the reference signal.\n\nFirst, we derive the loop transfer matrix, $\\mathbf{L}(s)$. The loop transfer matrix is the transfer function matrix from the error signal $\\mathbf{e}(s)$ to the plant output $\\mathbf{y}(s)$ which is then fed back to the summing junction. Combining the first two equations, we have:\n$$\n\\mathbf{y}(s) = \\mathbf{G}(s) (\\mathbf{K} \\mathbf{e}(s)) = (\\mathbf{G}(s)\\mathbf{K}) \\mathbf{e}(s)\n$$\nTherefore, the loop transfer matrix is defined as $\\mathbf{L}(s) = \\mathbf{G}(s)\\mathbf{K}$.\n\nWe are given the plant transfer matrix $\\mathbf{G}(s)$ and the controller matrix $\\mathbf{K}$:\n$$\n\\mathbf{G}(s)=\\begin{pmatrix}\n\\frac{1}{s+1} & \\frac{1}{s+2} \\\\\n0 & \\frac{2}{s+3}\n\\end{pmatrix}, \\quad \\mathbf{K}=\\begin{pmatrix}\nk_{1} & 0\\\\\nk_{2} & k_{3}\n\\end{pmatrix}\n$$\nWe compute the product $\\mathbf{L}(s) = \\mathbf{G}(s)\\mathbf{K}$:\n$$\n\\mathbf{L}(s) = \\begin{pmatrix}\n\\frac{1}{s+1} & \\frac{1}{s+2} \\\\\n0 & \\frac{2}{s+3}\n\\end{pmatrix} \\begin{pmatrix}\nk_{1} & 0\\\\\nk_{2} & k_{3}\n\\end{pmatrix} = \\begin{pmatrix}\n\\frac{1}{s+1} \\cdot k_{1} + \\frac{1}{s+2} \\cdot k_{2} & \\frac{1}{s+1} \\cdot 0 + \\frac{1}{s+2} \\cdot k_{3} \\\\\n0 \\cdot k_{1} + \\frac{2}{s+3} \\cdot k_{2} & 0 \\cdot 0 + \\frac{2}{s+3} \\cdot k_{3}\n\\end{pmatrix}\n$$\n$$\n\\mathbf{L}(s) = \\begin{pmatrix}\n\\frac{k_{1}}{s+1} + \\frac{k_{2}}{s+2} & \\frac{k_{3}}{s+2} \\\\\n\\frac{2k_{2}}{s+3} & \\frac{2k_{3}}{s+3}\n\\end{pmatrix}\n$$\nThe return difference matrix is defined as $\\mathbf{I}+\\mathbf{L}(s)$, where $\\mathbf{I}$ is the $2 \\times 2$ identity matrix.\n$$\n\\mathbf{I}+\\mathbf{L}(s) = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{pmatrix} + \\begin{pmatrix}\n\\frac{k_{1}}{s+1} + \\frac{k_{2}}{s+2} & \\frac{k_{3}}{s+2} \\\\\n\\frac{2k_{2}}{s+3} & \\frac{2k_{3}}{s+3}\n\\end{pmatrix} = \\begin{pmatrix}\n1 + \\frac{k_{1}}{s+1} + \\frac{k_{2}}{s+2} & \\frac{k_{3}}{s+2} \\\\\n\\frac{2k_{2}}{s+3} & 1 + \\frac{2k_{3}}{s+3}\n\\end{pmatrix}\n$$\nThe next step is to evaluate these matrices at $s=0$. First, we evaluate $\\mathbf{L}(0)$:\n$$\n\\mathbf{L}(0) = \\begin{pmatrix}\n\\frac{k_{1}}{0+1} + \\frac{k_{2}}{0+2} & \\frac{k_{3}}{0+2} \\\\\n\\frac{2k_{2}}{0+3} & \\frac{2k_{3}}{0+3}\n\\end{pmatrix} = \\begin{pmatrix}\nk_{1} + \\frac{k_{2}}{2} & \\frac{k_{3}}{2} \\\\\n\\frac{2k_{2}}{3} & \\frac{2k_{3}}{3}\n\\end{pmatrix}\n$$\nAnd the return difference matrix at $s=0$:\n$$\n\\mathbf{I}+\\mathbf{L}(0) = \\begin{pmatrix}\n1 + k_{1} + \\frac{k_{2}}{2} & \\frac{k_{3}}{2} \\\\\n\\frac{2k_{2}}{3} & 1 + \\frac{2k_{3}}{3}\n\\end{pmatrix}\n$$\nNow, we compute the determinant of the return difference matrix at $s=0$ as requested.\n$$\n\\det(\\mathbf{I}+\\mathbf{L}(0)) = \\left(1 + k_{1} + \\frac{k_{2}}{2}\\right) \\left(1 + \\frac{2k_{3}}{3}\\right) - \\left(\\frac{k_{3}}{2}\\right) \\left(\\frac{2k_{2}}{3}\\right)\n$$\nWe expand the product:\n$$\n\\det(\\mathbf{I}+\\mathbf{L}(0)) = 1\\left(1 + \\frac{2k_{3}}{3}\\right) + k_{1}\\left(1 + \\frac{2k_{3}}{3}\\right) + \\frac{k_{2}}{2}\\left(1 + \\frac{2k_{3}}{3}\\right) - \\frac{2k_{2}k_{3}}{6}\n$$\n$$\n\\det(\\mathbf{I}+\\mathbf{L}(0)) = 1 + \\frac{2k_{3}}{3} + k_{1} + \\frac{2k_{1}k_{3}}{3} + \\frac{k_{2}}{2} + \\frac{2k_{2}k_{3}}{6} - \\frac{k_{2}k_{3}}{3}\n$$\nNoticing that $\\frac{2k_{2}k_{3}}{6} = \\frac{k_{2}k_{3}}{3}$, the last two terms cancel each other. This leaves the simplified expression:\n$$\n\\det(\\mathbf{I}+\\mathbf{L}(0)) = 1 + k_{1} + \\frac{k_{2}}{2} + \\frac{2k_{3}}{3} + \\frac{2k_{1}k_{3}}{3}\n$$\nThis is the required closed-form analytic expression.\n\nAdditionally, a qualitative explanation is required. The stability of the closed-loop system is determined by the locations of its poles, which are the roots of the characteristic equation $\\det(\\mathbf{I}+\\mathbf{L}(s)) = 0$. For the SISO case, this reduces to $1+L(s)=0$. The Nyquist stability criterion examines the encirclements of the critical point $-1$ by the frequency response $L(j\\omega)$. The distance $|1+L(j\\omega)|$ is a measure of robustness; a small value indicates proximity to instability.\n\nIn the MIMO case, the return difference matrix $\\mathbf{I}+\\mathbf{L}(s)$ plays an analogous role. The generalized Nyquist criterion states that for a stable open-loop system, closed-loop stability is guaranteed if the locus of $\\det(\\mathbf{I}+\\mathbf{L}(j\\omega))$ for $\\omega \\in [-\\infty, \\infty]$ does not encircle the origin. The value of $\\det(\\mathbf{I}+\\mathbf{L}(j\\omega))$ is the multivariable equivalent of the scalar distance $1+L(j\\omega)$ from the critical point. A value close to zero indicates that the system is approaching a condition of instability. Thus, quantities like the minimum singular value of $\\mathbf{I}+\\mathbf{L}(j\\omega)$, $\\sigma_{\\min}(\\mathbf{I}+\\mathbf{L}(j\\omega))$, provide a robust measure of the multivariable gain and phase margins by quantifying how close the matrix $\\mathbf{I}+\\mathbf{L}(j\\omega)$ is to being singular.\n\nFurthermore, the return difference is fundamentally linked to system performance through the sensitivity function $\\mathbf{S}(s) = (\\mathbf{I}+\\mathbf{L}(s))^{-1}$ and the complementary sensitivity function $\\mathbf{T}(s) = \\mathbf{L}(s)(\\mathbf{I}+\\mathbf{L}(s))^{-1}$. The sensitivity function $\\mathbf{S}(s)$ maps reference commands and output disturbances to the tracking error. For good performance (tracking and disturbance rejection), $\\mathbf{S}(s)$ must be small at low frequencies, which requires $\\mathbf{L}(s)$ to be \"large\". The complementary sensitivity function $\\mathbf{T}(s)$ maps sensor noise to the plant output. For robustness against noise and model uncertainty, $\\mathbf{T}(s)$ must be small at high frequencies, which requires $\\mathbf{L}(s)$ to be \"small\". The behavior of $\\mathbf{I}+\\mathbf{L}(s)$ across all frequencies therefore governs the fundamental trade-offs between performance and robustness, with its determinant dictating the absolute stability of the closed-loop system.", "answer": "$$\n\\boxed{1 + k_{1} + \\frac{k_{2}}{2} + \\frac{2k_{3}}{3} + \\frac{2k_{1}k_{3}}{3}}\n$$", "id": "2713799"}, {"introduction": "Assessing the performance and robustness of a MIMO feedback system requires tools that can capture its directional nature. This computational practice moves beyond simple stability checks to the quantitative analysis of performance using the sensitivity, $S(s)$, and complementary sensitivity, $T(s)$, functions [@problem_id:2713822]. By computing the singular values of these matrices, you will uncover how interactions between control loops can lead to performance degradation—a phenomenon known as \"peaking\"—even when individual loops seem well-behaved, highlighting the power of singular value analysis in modern control.", "problem": "Consider a standard negative-feedback interconnection of a two-input two-output plant and a diagonal controller. Let the plant be given in the Laplace domain by the transfer matrix $G(s) \\in \\mathbb{C}^{2 \\times 2}$ with entries\n- $g_{11}(s) = \\dfrac{2}{(s+1)(0.5\\,s+1)}$,\n- $g_{22}(s) = \\dfrac{3}{(s+2)(0.2\\,s+1)}$,\n- $g_{12}(s) = c \\cdot \\dfrac{0.5}{s+1}$,\n- $g_{21}(s) = -c \\cdot \\dfrac{0.4}{s+0.2}$,\nwhere $c \\in \\mathbb{R}$ is a scalar that controls the off-diagonal interaction level. The controller is diagonal,\n$K(s) = \\mathrm{diag}(k_1, k_2)$,\nwith $k_1 = 1.5$ and $k_2 = 1.2$. Assume unity negative feedback and that all interconnections are well-posed.\n\nUsing only foundational closed-loop definitions for negative feedback and frequency-response evaluation, do the following:\n- Derive expressions for the sensitivity matrix $S(j\\omega)$ and the complementary sensitivity matrix $T(j\\omega)$ in terms of $G(j\\omega)$ and $K(j\\omega)$, starting from block-diagram equations and algebraic elimination. Do not assume any special structure beyond that stated, and do not start from pre-memorized closed-loop formulas.\n- For each frequency $\\omega$, interpret $S(j\\omega)$ and $T(j\\omega)$ as complex matrices and quantify their largest singular value, defined as the induced $2$-norm, which is the square root of the largest eigenvalue of $M(j\\omega)^{*} M(j\\omega)$ for $M \\in \\{S, T\\}$, where $(\\cdot)^{*}$ denotes conjugate transpose.\n\nDefine the analysis grid of angular frequencies to be logarithmically spaced as $\\omega \\in [10^{-2}, 10^{3}]$ in radians per second, using $N = 2000$ points. For each specified value of $c$ below, compute:\n- The peak (maximum over $\\omega$) of the largest singular value of $S(j\\omega)$, denoted $\\max_{\\omega}\\,\\bar{\\sigma}(S(j\\omega))$.\n- The peak (maximum over $\\omega$) of the largest singular value of $T(j\\omega)$, denoted $\\max_{\\omega}\\,\\bar{\\sigma}(T(j\\omega))$.\n\nTo analyze interaction-induced peaking, use the diagonal-only reference plant $G_{\\mathrm{diag}}(s)$ obtained by setting $c = 0$ while keeping the same diagonal entries and the same controller. For each $c$, define the ratios\n- $R_S(c) = \\dfrac{\\max_{\\omega}\\,\\bar{\\sigma}(S_{\\mathrm{MIMO}}(j\\omega;c))}{\\max_{\\omega}\\,\\bar{\\sigma}(S_{\\mathrm{diag}}(j\\omega))}$,\n- $R_T(c) = \\dfrac{\\max_{\\omega}\\,\\bar{\\sigma}(T_{\\mathrm{MIMO}}(j\\omega;c))}{\\max_{\\omega}\\,\\bar{\\sigma}(T_{\\mathrm{diag}}(j\\omega))}$,\nand report boolean flags\n- $\\text{peakS}(c) = \\text{True}$ if $R_S(c) > \\tau$, else $\\text{False}$,\n- $\\text{peakT}(c) = \\text{True}$ if $R_T(c) > \\tau$, else $\\text{False}$,\nwith threshold $\\tau = 1.05$.\n\nTest suite:\n- Use the three values $c \\in \\{0.0, 0.3, 0.8\\}$.\n\nNumerical and output requirements:\n- Evaluate $G(j\\omega)$ by substituting $s = j\\omega$ into each scalar entry.\n- Express the two peak values per test case as real numbers rounded to six decimal places.\n- The boolean flags must be computed against the ratios above with $\\tau = 1.05$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must concatenate, for each $c$ in the order $c = 0.0$, $c = 0.3$, $c = 0.8$, the four items\n$[\\max_{\\omega}\\,\\bar{\\sigma}(S), \\max_{\\omega}\\,\\bar{\\sigma}(T), \\text{peakS}, \\text{peakT}]$,\neach peak rounded to six decimals and each boolean as an unquoted literal, resulting in a flat list of length $12$. For example, the output format must be\n$[\\text{val}_{1},\\text{val}_{2},\\text{bool}_{1},\\text{bool}_{2},\\ldots]$,\nwith no additional text.", "solution": "The problem is subjected to validation. All givens, including the plant transfer matrix $G(s)$, the diagonal controller $K(s)$, feedback configuration, and analysis tasks, are explicitly stated. The problem is scientifically grounded in standard multi-input multi-output (MIMO) control theory, utilizing concepts such as sensitivity functions, frequency response, and singular value analysis. It is well-posed, objective, and contains sufficient information for a unique solution. No contradictions, ambiguities, or factual inaccuracies are present. The problem is therefore deemed **valid**, and I will proceed with a solution.\n\nThe foundation of this problem lies in the algebraic analysis of a linear time-invariant (LTI) negative feedback system. The system's behavior is described by the interconnections of the plant $G(s)$ and the controller $K(s)$. We are given the vector signals for reference $R(s)$, error $E(s)$, controller output $U(s)$, and plant output $Y(s)$, all in the Laplace domain. The system dynamics are governed by the following equations:\n$$Y(s) = G(s)U(s) \\quad (\\text{Plant})$$\n$$U(s) = K(s)E(s) \\quad (\\text{Controller})$$\n$$E(s) = R(s) - Y(s) \\quad (\\text{Negative Feedback Error})$$\nThe task requires the derivation of the closed-loop transfer matrices from first principles.\n\nFirst, we derive the complementary sensitivity matrix, $T(s)$, which is the closed-loop transfer function from the reference input $R(s)$ to the plant output $Y(s)$. We achieve this by algebraic substitution to eliminate the internal signals $E(s)$ and $U(s)$:\n$$Y(s) = G(s)U(s) = G(s)K(s)E(s)$$\nSubstituting the expression for the error $E(s)$:\n$$Y(s) = G(s)K(s)(R(s) - Y(s))$$\nWe expand this expression and group terms involving $Y(s)$:\n$$Y(s) = G(s)K(s)R(s) - G(s)K(s)Y(s)$$\n$$IY(s) + G(s)K(s)Y(s) = G(s)K(s)R(s)$$\nHere, $I$ is the identity matrix of appropriate dimension, which is $2 \\times 2$ in this case. Factoring out $Y(s)$ gives:\n$$(I + G(s)K(s))Y(s) = G(s)K(s)R(s)$$\nTo isolate $Y(s)$, we pre-multiply by the inverse of $(I + G(s)K(s))$:\n$$Y(s) = (I + G(s)K(s))^{-1}G(s)K(s)R(s)$$\nBy definition, $Y(s) = T(s)R(s)$, so the complementary sensitivity matrix is:\n$$T(s) = (I + L(s))^{-1}L(s)$$\nwhere $L(s) = G(s)K(s)$ is the loop transfer matrix.\n\nNext, we derive the sensitivity matrix, $S(s)$, which is the closed-loop transfer function from the reference $R(s)$ to the error signal $E(s)$. Starting from the error definition:\n$$E(s) = R(s) - Y(s)$$\nSubstituting $Y(s) = T(s)R(s)$:\n$$E(s) = R(s) - T(s)R(s) = (I - T(s))R(s)$$\nThus, we find the identity $S(s) = I - T(s)$. We can express $S(s)$ in terms of the loop matrix $L(s)$ by substituting the expression for $T(s)$:\n$$S(s) = I - (I + L(s))^{-1}L(s)$$\nTo simplify, we write $I$ as $(I + L(s))^{-1}(I + L(s))$:\n$$S(s) = (I + L(s))^{-1}(I + L(s)) - (I + L(s))^{-1}L(s)$$\n$$S(s) = (I + L(s))^{-1}(I + L(s) - L(s))$$\nThis simplifies to the canonical form for the sensitivity matrix:\n$$S(s) = (I + L(s))^{-1}$$\n\nThe analysis is performed in the frequency domain by setting $s = j\\omega$, where $j$ is the imaginary unit and $\\omega$ is the angular frequency. The \"size\" of the resulting complex matrices $S(j\\omega)$ and $T(j\\omega)$ at each frequency is quantified by their largest singular value, $\\bar{\\sigma}(\\cdot)$, which corresponds to the induced $2$-norm. The largest singular value is defined as $\\bar{\\sigma}(M) = \\sqrt{\\lambda_{\\max}(M^*M)}$, where $M^*$ is the conjugate transpose of $M$ and $\\lambda_{\\max}$ denotes the largest eigenvalue.\n\nThe numerical procedure is as follows. We are given the plant:\n$$G(s) = \\begin{pmatrix} \\frac{2}{(s+1)(0.5s+1)} & c \\cdot \\frac{0.5}{s+1} \\\\ -c \\cdot \\frac{0.4}{s+0.2} & \\frac{3}{(s+2)(0.2s+1)} \\end{pmatrix}$$\nand the controller:\n$$K(s) = \\begin{pmatrix} 1.5 & 0 \\\\ 0 & 1.2 \\end{pmatrix}$$\nA grid of $N=2000$ frequencies $\\omega_k$ is created, logarithmically spaced from $10^{-2}$ to $10^3$ rad/s. For each value of $c \\in \\{0.0, 0.3, 0.8\\}$, and for each frequency $\\omega_k$ in the grid:\n1. The complex value $s_k = j\\omega_k$ is calculated.\n2. The complex matrix $G(j\\omega_k)$ is assembled by substituting $s_k$.\n3. The loop transfer matrix $L(j\\omega_k) = G(j\\omega_k)K$ is computed.\n4. The sensitivity matrices $S(j\\omega_k) = (I + L(j\\omega_k))^{-1}$ and $T(j\\omega_k) = S(j\\omega_k)L(j\\omega_k)$ are calculated using numerically stable methods for matrix inversion.\n5. The largest singular values $\\bar{\\sigma}(S(j\\omega_k))$ and $\\bar{\\sigma}(T(j\\omega_k))$ are computed via Singular Value Decomposition (SVD).\n6. The maximum of these singular values across all frequencies is recorded as $\\max_{\\omega} \\bar{\\sigma}(S)$ and $\\max_{\\omega} \\bar{\\sigma}(T)$.\n\nThe case $c=0$ establishes the baseline performance for the decoupled system, yielding $\\max_{\\omega}\\bar{\\sigma}(S_{\\text{diag}})$ and $\\max_{\\omega}\\bar{\\sigma}(T_{\\text{diag}})$. For each $c$, the performance degradation due to coupling is assessed via the ratios:\n$$R_S(c) = \\frac{\\max_{\\omega}\\bar{\\sigma}(S_{\\mathrm{MIMO}}(j\\omega; c))}{\\max_{\\omega}\\bar{\\sigma}(S_{\\mathrm{diag}}(j\\omega))}, \\quad R_T(c) = \\frac{\\max_{\\omega}\\bar{\\sigma}(T_{\\mathrm{MIMO}}(j\\omega; c))}{\\max_{\\omega}\\bar{\\sigma}(T_{\\mathrm{diag}}(j\\omega))}$$\nThese ratios are compared to a threshold $\\tau = 1.05$ to generate boolean flags, $\\text{peakS}(c)$ and $\\text{peakT}(c)$, indicating significant peaking. The final results are collected and formatted as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MIMO sensitivity analysis problem.\n    \"\"\"\n    # Define system parameters and analysis grid\n    k1 = 1.5\n    k2 = 1.2\n    K = np.diag([k1, k2])\n    N = 2000\n    omega_grid = np.logspace(-2, 3, N)\n    c_values = [0.0, 0.3, 0.8]\n    tau = 1.05\n    I = np.identity(2)\n    \n    test_cases = c_values\n    \n    # Dictionary to store the peak singular values for each c\n    peak_results = {}\n\n    # Iterate over each test case for the coupling parameter c\n    for c in test_cases:\n        max_sigma_S = 0.0\n        max_sigma_T = 0.0\n        \n        # Iterate over each frequency in the grid\n        for w in omega_grid:\n            s = 1j * w\n            \n            # Evaluate the plant transfer matrix G(jw)\n            g11 = 2 / ((s + 1) * (0.5 * s + 1))\n            g22 = 3 / ((s + 2) * (0.2 * s + 1))\n            g12 = c * 0.5 / (s + 1)\n            g21 = -c * 0.4 / (s + 0.2)\n            G = np.array([[g11, g12], [g21, g22]], dtype=complex)\n            \n            # Compute the loop transfer matrix L(jw)\n            L = G @ K\n            \n            # Compute sensitivity S(jw) and complementary sensitivity T(jw)\n            # Using np.linalg.solve for numerical stability (solves (I+L)X = I for X)\n            S = np.linalg.solve(I + L, I)\n            T = S @ L\n            \n            # Compute singular values using SVD. svd returns them in descending order.\n            sigma_S = np.linalg.svd(S, compute_uv=False)\n            sigma_T = np.linalg.svd(T, compute_uv=False)\n            \n            # The largest singular value is the first element\n            current_max_sigma_S = sigma_S[0]\n            current_max_sigma_T = sigma_T[0]\n            \n            # Update the peak values found so far\n            if current_max_sigma_S > max_sigma_S:\n                max_sigma_S = current_max_sigma_S\n            \n            if current_max_sigma_T > max_sigma_T:\n                max_sigma_T = current_max_sigma_T\n                \n        # Store the peak values for the current c\n        peak_results[c] = (max_sigma_S, max_sigma_T)\n\n    # Get the baseline (diagonal) results from c = 0.0\n    peak_S_diag, peak_T_diag = peak_results[0.0]\n\n    all_results = []\n    # Process each test case to compute ratios and flags\n    for c in test_cases:\n        peak_S_mimo, peak_T_mimo = peak_results[c]\n        \n        # Calculate ratios relative to the diagonal case\n        # Guard against division by zero, although not expected in this problem\n        if peak_S_diag != 0:\n            R_S = peak_S_mimo / peak_S_diag\n        else:\n            R_S = float('inf') if peak_S_mimo > 0 else 1.0\n\n        if peak_T_diag != 0:\n            R_T = peak_T_mimo / peak_T_diag\n        else:\n            R_T = float('inf') if peak_T_mimo > 0 else 1.0\n\n        # Determine boolean flags based on the threshold tau\n        peakS_flag = R_S > tau\n        peakT_flag = R_T > tau\n        \n        # Append formatted results to the final list\n        all_results.extend([\n            f\"{peak_S_mimo:.6f}\",\n            f\"{peak_T_mimo:.6f}\",\n            str(peakS_flag),\n            str(peakT_flag)\n        ])\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "2713822"}]}