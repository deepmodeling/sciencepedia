{"hands_on_practices": [{"introduction": "Model reduction techniques must be applied with care to systems containing unstable modes, as a naive removal of states can lead to a dangerously inaccurate model. This exercise provides hands-on practice with a crucial and robust workflow: separating a system into its stable and unstable parts before applying balanced truncation only to the stable portion. By following the steps of decomposition, Gramian calculation, and re-assembly, you will learn how to reduce a system's order while rigorously preserving its essential unstable dynamics [@problem_id:2725571].", "problem": "Consider the continuous-time, single-input single-output linear time-invariant (LTI) system with state-space realization\n$$\n\\dot{x}(t)=A x(t)+B u(t), \\quad y(t)=C x(t),\n$$\nwhere\n$$\nA=\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & -5\n\\end{pmatrix}, \\quad\nB=\\begin{pmatrix}\n1\\\\\n2\\\\\n1\n\\end{pmatrix}, \\quad\nC=\\begin{pmatrix}\n3 & 2 & 1\n\\end{pmatrix}.\n$$\nThis system has one unstable mode at $s=1$ and two stable modes at $s=-2$ and $s=-5$. Using an unstable-friendly model reduction workflow that exactly preserves the unstable dynamics and reduces only the stable portion by balanced truncation, construct a reduced-order model of order $2$.\n\nStart from first principles as follows:\n- Use a real Schur-based unstable/stable decomposition to justify separating the unstable and stable subspaces.\n- For the stable block alone, define the reachability (controllability) and observability Gramians via the continuous-time Lyapunov equations and solve them explicitly.\n- Use the definition of Hankel singular values as the square roots of the eigenvalues of the product of the reachability and observability Gramians to identify the dominant stable mode.\n- Argue why, under the present coordinates and data, the stable block is already balanced and how this simplifies the balanced truncation step.\n- Assemble the reduced-order model that preserves the unstable block exactly and retains only the dominant stable mode.\n\nFinally, compute the transfer function of the reduced model, $G_{r}(s)$, as a single simplified rational function of $s$, and verify within your derivation that the unstable pole is reproduced exactly with the same residue. Provide $G_{r}(s)$ as your final answer. No rounding is required, and no physical units are involved. Express angles, if any, in radians.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It presents a standard exercise in control theory, specifically concerning model order reduction for linear systems with unstable modes. All necessary data are provided, the tasks are clearly defined, and the premises are consistent with established principles of system theory. The problem is therefore valid, and we may proceed to its solution.\n\nThe objective is to construct a reduced-order model of order $r=2$ for a given third-order system by preserving its unstable dynamics and applying balanced truncation to its stable part.\n\nThe system is given by $\\dot{x}(t) = A x(t) + B u(t)$, $y(t) = C x(t)$, with matrices:\n$$\nA=\\begin{pmatrix}\n1 & 0 & 0\\\\\n0 & -2 & 0\\\\\n0 & 0 & -5\n\\end{pmatrix}, \\quad\nB=\\begin{pmatrix}\n1\\\\\n2\\\\\n1\n\\end{pmatrix}, \\quad\nC=\\begin{pmatrix}\n3 & 2 & 1\n\\end{pmatrix}\n$$\nThe eigenvalues of $A$ are $\\lambda_1 = 1$, $\\lambda_2 = -2$, and $\\lambda_3 = -5$. The mode associated with $\\lambda_1 = 1$ is unstable, while the modes associated with $\\lambda_2 = -2$ and $\\lambda_3 = -5$ are stable.\n\nFirst, we perform a decomposition of the system into its unstable and stable components. Since the state-space realization is given in a modal form where the matrix $A$ is diagonal, it is already in a real Schur form that separates the unstable and stable subspaces. We can partition the state vector $x$ as $x = \\begin{pmatrix} x_u \\\\ x_s \\end{pmatrix}$, where $x_u$ is the state of the unstable subsystem and $x_s$ contains the states of the stable subsystem.\n\nThis partitioning leads to the following block-diagonal structure:\n$$\nA = \\begin{pmatrix} A_{uu} & 0 \\\\ 0 & A_{ss} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\begin{pmatrix} -2 & 0 \\\\ 0 & -5 \\end{pmatrix} \\end{pmatrix}\n$$\n$$\nB = \\begin{pmatrix} B_u \\\\ B_s \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} \\end{pmatrix}\n$$\n$$\nC = \\begin{pmatrix} C_u & C_s \\end{pmatrix} = \\begin{pmatrix} 3 & \\begin{pmatrix} 2 & 1 \\end{pmatrix} \\end{pmatrix}\n$$\nThe total output is the sum of the outputs from the unstable and stable parts: $y(t) = C_u x_u(t) + C_s x_s(t)$. The model reduction procedure will be applied only to the stable subsystem $(A_{ss}, B_s, C_s)$, which is defined by:\n$$\nA_{ss} = \\begin{pmatrix} -2 & 0 \\\\ 0 & -5 \\end{pmatrix}, \\quad B_s = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}, \\quad C_s = \\begin{pmatrix} 2 & 1 \\end{pmatrix}\n$$\nWe proceed by analyzing this stable subsystem. The reachability Gramian $W_{c,s}$ is found by solving the continuous-time Lyapunov equation:\n$$\nA_{ss} W_{c,s} + W_{c,s} A_{ss}^T + B_s B_s^T = 0\n$$\nSince $A_{ss}$ is diagonal, $W_{c,s}$ must also be diagonal. Let $W_{c,s} = \\text{diag}(w_{c1}, w_{c2})$.\nThe equation for the diagonal elements becomes $2 \\lambda_i w_{ci} + (b_{si})^2 = 0$, which gives $w_{ci} = -\\frac{(b_{si})^2}{2 \\lambda_i}$.\nFor the first stable state: $w_{c1} = -\\frac{2^2}{2(-2)} = 1$.\nFor the second stable state: $w_{c2} = -\\frac{1^2}{2(-5)} = \\frac{1}{10}$.\nThus, the reachability Gramian for the stable part is:\n$$\nW_{c,s} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}\n$$\nSimilarly, the observability Gramian $W_{o,s}$ is found by solving:\n$$\nA_{ss}^T W_{o,s} + W_{o,s} A_{ss} + C_s^T C_s = 0\n$$\nAgain, $W_{o,s}$ must be diagonal, $W_{o,s} = \\text{diag}(w_{o1}, w_{o2})$. The equation for its elements is $2 \\lambda_i w_{oi} + (c_{si})^2 = 0$, which gives $w_{oi} = -\\frac{(c_{si})^2}{2 \\lambda_i}$.\nFor the first stable state: $w_{o1} = -\\frac{2^2}{2(-2)} = 1$.\nFor the second stable state: $w_{o2} = -\\frac{1^2}{2(-5)} = \\frac{1}{10}$.\nThe observability Gramian is:\n$$\nW_{o,s} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}\n$$\nThe Hankel singular values (HSVs) of the stable subsystem, denoted $\\sigma_i$, are the square roots of the eigenvalues of the product $W_{c,s} W_{o,s}$.\n$$\nW_{c,s} W_{o,s} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{100} \\end{pmatrix}\n$$\nThe eigenvalues are $\\lambda(W_{c,s} W_{o,s}) = \\{1, \\frac{1}{100}\\}$. The HSVs are:\n$$\n\\sigma_1 = \\sqrt{1} = 1, \\quad \\sigma_2 = \\sqrt{\\frac{1}{100}} = \\frac{1}{10}\n$$\nThe HSV $\\sigma_1 = 1$ is associated with the stable mode at $s=-2$, and $\\sigma_2 = \\frac{1}{10}$ is associated with the mode at $s=-5$. Since $\\sigma_1 \\gg \\sigma_2$, the first stable mode is energetically dominant.\n\nNow, we must argue why the stable block is already balanced. A realization is called balanced if its reachability and observability Gramians are equal and diagonal, $W_c = W_o = \\Sigma$, where $\\Sigma$ is the diagonal matrix of Hankel singular values. For our stable subsystem:\n$$\nW_{c,s} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}, \\quad W_{o,s} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}, \\quad \\Sigma_s = \\text{diag}(\\sigma_1, \\sigma_2) = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\frac{1}{10} \\end{pmatrix}\n$$\nWe observe that $W_{c,s} = W_{o,s} = \\Sigma_s$. Therefore, the stable subsystem $(A_{ss}, B_s, C_s)$ is already in a balanced realization. This is a direct consequence of the system being in modal coordinates (diagonal $A_{ss}$) and the input/output vector components for each mode being equal, i.e., $|[B_s]_i| = |[C_s]_i|$. The simplification is that no balancing coordinate transformation is required. Truncation is achieved by simply removing the state(s) corresponding to the smallest HSV(s).\n\nTo obtain a reduced-order model of total order $2$, we must preserve the unstable mode (order $1$) and reduce the stable subsystem from order $2$ to order $1$. We keep the stable mode with the largest HSV, which is the first one ($\\sigma_1=1$), and discard the second one ($\\sigma_2=\\frac{1}{10}$). This means we keep the first state of the stable subsystem.\nThe reduced stable subsystem $(\\hat{A}_{ss}, \\hat{B}_s, \\hat{C}_s)$ is formed by taking the top-left $1 \\times 1$ blocks of the partitioned matrices:\n$$\n\\hat{A}_{ss} = -2, \\quad \\hat{B}_s = 2, \\quad \\hat{C}_s = 2\n$$\nThe final reduced-order model $(A_r, B_r, C_r)$ is constructed by combining the original unstable block with the reduced stable block:\n$$\nA_r = \\begin{pmatrix} A_{uu} & 0 \\\\ 0 & \\hat{A}_{ss} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & -2 \\end{pmatrix}\n$$\n$$\nB_r = \\begin{pmatrix} B_u \\\\ \\hat{B}_s \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\n$$\n$$\nC_r = \\begin{pmatrix} C_u & \\hat{C}_s \\end{pmatrix} = \\begin{pmatrix} 3 & 2 \\end{pmatrix}\n$$\nThe transfer function of this reduced model, $G_r(s)$, is given by $C_r(sI - A_r)^{-1}B_r$:\n$$\nG_r(s) = \\begin{pmatrix} 3 & 2 \\end{pmatrix} \\begin{pmatrix} s-1 & 0 \\\\ 0 & s+2 \\end{pmatrix}^{-1} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\n$$\n$$\nG_r(s) = \\begin{pmatrix} 3 & 2 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{s-1} & 0 \\\\ 0 & \\frac{1}{s+2} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} = \\frac{3}{s-1} \\cdot 1 + \\frac{2}{s+2} \\cdot 2 = \\frac{3}{s-1} + \\frac{4}{s+2}\n$$\nTo verify the preservation of the unstable pole and its residue, we compute the original transfer function $G(s)$:\n$$\nG(s) = C(sI-A)^{-1}B = \\frac{3}{s-1} + \\frac{4}{s+2} + \\frac{1}{s+5}\n$$\nThe residue of the unstable pole at $s=1$ in the original system is $\\lim_{s \\to 1} (s-1)G(s) = 3$.\nThe residue of the unstable pole at $s=1$ in the reduced system is $\\lim_{s \\to 1} (s-1)G_r(s) = 3$.\nThe unstable pole and its residue are perfectly preserved, as expected.\n\nFinally, we express $G_r(s)$ as a single rational function:\n$$\nG_r(s) = \\frac{3(s+2) + 4(s-1)}{(s-1)(s+2)} = \\frac{3s+6+4s-4}{s^2+s-2} = \\frac{7s+2}{s^2+s-2}\n$$\nThis is the transfer function of the second-order reduced model.", "answer": "$$\\boxed{\\frac{7s+2}{s^{2}+s-2}}$$", "id": "2725571"}, {"introduction": "Once a system is transformed into a balanced realization, the 'truncation' step itself can be performed in different ways with important consequences for the reduced model's properties. This problem challenges you to compare two canonical methods: Balanced Truncation (BT) and Balanced Singular Perturbation (BSP). By deriving their respective effects on the system’s steady-state gain, you will uncover a fundamental difference and understand the mechanism by which BSP achieves exact matching at zero frequency, a critical feature for many control applications [@problem_id:2725584].", "problem": "Consider a minimal, asymptotically stable, strictly proper continuous-time Linear Time-Invariant (LTI) system with state-space realization $\\left(A,B,C,D\\right)$, where $D=0$, and transfer function $G(s)=C\\left(sI-A\\right)^{-1}B$. Let a balanced realization be available and be partitioned conformably with a target reduced order $r$ as\n$$\nA=\\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix},\\quad\nB=\\begin{bmatrix} B_{1} \\\\ B_{2} \\end{bmatrix},\\quad\nC=\\begin{bmatrix} C_{1} & C_{2} \\end{bmatrix},\n$$\nwith the upper-left block of dimension $r$. Two standard reduced models are constructed:\n- Balanced Truncation (BT): retain the $r$-state block and discard the remaining block.\n- Balanced Singular Perturbation (BSP): eliminate the $(n-r)$-state block via a singular perturbation argument that treats the truncated states as fast and imposes an algebraic constraint obtained by setting their time derivatives to zero.\n\nUsing only fundamental definitions (transfer function as $G(s)=C(sI-A)^{-1}B+D$, steady-state gain $G(0)$ for stable strictly proper systems, and linear-algebraic block inversion), reason about how these two reductions compare in terms of steady-state (Direct Current (DC)) gain matching and low-frequency behavior (near $s=0$).\n\nWhich of the following statements are correct?\n\nA. For a stable, strictly proper system with $D=0$, BSP yields a reduced model whose transfer function matches the original at $s=0$ exactly, while BT generally does not.\n\nB. Because the original is strictly proper ($D=0$), both BT and BSP reduced models necessarily have zero steady-state gain.\n\nC. BT preserves the low-frequency (near $s=0$) Taylor expansion of $G(s)$ up to first order by construction, whereas BSP does not.\n\nD. In BSP, even if $D=0$ initially, the reduced model may acquire a nonzero direct feedthrough $D_{r}\\neq 0$ that enforces exact matching at $s=0$.\n\nE. If the truncated Hankel singular values correspond exclusively to fast modes, BT is guaranteed to match the original steady-state gain exactly.", "solution": "The problem statement shall first be subjected to rigorous validation.\n\n### Step 1: Extract Givens\n- The system is a minimal, asymptotically stable, strictly proper, continuous-time Linear Time-Invariant (LTI) system.\n- The state-space realization is given by $(A, B, C, D)$, with the direct feedthrough matrix $D=0$.\n- The transfer function is $G(s) = C(sI-A)^{-1}B$.\n- A balanced realization is partitioned for a reduced order $r$:\n$$ A = \\begin{bmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{bmatrix}, \\quad B = \\begin{bmatrix} B_{1} \\\\ B_{2} \\end{bmatrix}, \\quad C = \\begin{bmatrix} C_{1} & C_{2} \\end{bmatrix} $$\nwhere $A_{11}$ is an $r \\times r$ matrix.\n- **Balanced Truncation (BT)**: The reduced model is $(A_r, B_r, C_r, D_r) = (A_{11}, B_1, C_1, 0)$.\n- **Balanced Singular Perturbation (BSP)**: The reduced model is obtained by setting the derivatives of the truncated states to zero, $\\dot{x}_2 = 0$.\n- The analysis must use only fundamental definitions: $G(s)=C(sI-A)^{-1}B+D$, steady-state gain $G(0)$, and linear-algebraic block inversion.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is based on established and fundamental concepts in control theory, specifically model reduction techniques for LTI systems. Balanced realization, balanced truncation, and singular perturbation are standard methods. All premises are factually sound.\n- **Well-Posed:** The problem is clearly defined. It asks for a comparison of two standard reduction techniques based on their behavior at zero frequency ($s=0$). The provided definitions and constraints are sufficient to derive a unique and meaningful solution.\n- **Objective:** The language is formal, precise, and devoid of subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem statement is valid. It is a well-posed, scientifically grounded question in control theory. The derivation of the solution may proceed.\n\n### Derivation\n\nThe original system is described by the state-space equations:\n$$ \\dot{x}(t) = Ax(t) + Bu(t) $$\n$$ y(t) = Cx(t) $$\nThe transfer function is $G(s) = C(sI-A)^{-1}B$. Since the system is asymptotically stable, the matrix $A$ is Hurwitz, which implies that $A$ is invertible. The steady-state (DC) gain is the value of the transfer function at $s=0$:\n$$ G(0) = C(0 \\cdot I - A)^{-1}B = C(-A)^{-1}B = -CA^{-1}B $$\n\nWe will now analyze the two reduction methods.\n\n**1. Balanced Truncation (BT)**\n\nBy definition, the BT reduced model is $(A_{r}, B_{r}, C_{r}, D_{r}) = (A_{11}, B_1, C_1, 0)$. The transfer function of the reduced model is:\n$$ G_{BT}(s) = C_1(sI_r - A_{11})^{-1}B_1 $$\nFor a stable system, a balanced truncation results in a stable reduced model, so $A_{11}$ is also Hurwitz and thus invertible. The steady-state gain of the BT model is:\n$$ G_{BT}(0) = -C_1A_{11}^{-1}B_1 $$\nTo compare this with the original gain $G(0) = -CA^{-1}B$, we must examine the structure of $A^{-1}$. Using the formula for the inverse of a block matrix, the top-left block of $A^{-1}$ is $(A_{11} - A_{12}A_{22}^{-1}A_{21})^{-1}$, not $A_{11}^{-1}$. Furthermore, $G(0)$ depends on all blocks of $A$, $B$, and $C$. It is evident that, in general,\n$$ -C_1A_{11}^{-1}B_1 \\neq -CA^{-1}B $$\nTherefore, balanced truncation does not preserve the steady-state gain, except in special cases.\n\n**2. Balanced Singular Perturbation (BSP)**\n\nThis method is derived from the partitioned state equations:\n$$ \\dot{x}_1 = A_{11}x_1 + A_{12}x_2 + B_1 u $$\n$$ \\dot{x}_2 = A_{21}x_1 + A_{22}x_2 + B_2 u $$\n$$ y = C_1x_1 + C_2x_2 $$\nThe singular perturbation approximation assumes the dynamics of $x_2$ are infinitely fast, which corresponds to setting $\\dot{x}_2 = 0$.\n$$ 0 = A_{21}x_1 + A_{22}x_2 + B_2 u $$\nA property of a balanced realization of a stable system is that the diagonal blocks $A_{11}$ and $A_{22}$ are also Hurwitz, which means $A_{22}$ is invertible. We can solve for $x_2$:\n$$ x_2 = -A_{22}^{-1}(A_{21}x_1 + B_2 u) $$\nSubstituting this algebraic relation back into the equations for $\\dot{x}_1$ and $y$ defines the reduced system:\n$$ \\dot{x}_1 = A_{11}x_1 + A_{12}(-A_{22}^{-1}(A_{21}x_1 + B_2 u)) + B_1 u $$\n$$ \\dot{x}_1 = (A_{11} - A_{12}A_{22}^{-1}A_{21})x_1 + (B_1 - A_{12}A_{22}^{-1}B_2)u $$\n$$ y = C_1x_1 + C_2(-A_{22}^{-1}(A_{21}x_1 + B_2 u)) $$\n$$ y = (C_1 - C_2A_{22}^{-1}A_{21})x_1 + (-C_2A_{22}^{-1}B_2)u $$\nFrom this, we identify the matrices of the reduced system $(A_r, B_r, C_r, D_r)$:\n$$ A_r = A_{11} - A_{12}A_{22}^{-1}A_{21} $$\n$$ B_r = B_1 - A_{12}A_{22}^{-1}B_2 $$\n$$ C_r = C_1 - C_2A_{22}^{-1}A_{21} $$\n$$ D_r = -C_2A_{22}^{-1}B_2 $$\nThe steady-state gain of the BSP model is $G_{BSP}(0) = -C_rA_r^{-1}B_r + D_r$. We will now prove this is identical to $G(0)$.\nLet's use the block matrix inversion formula for $A^{-1}$ where the Schur complement of $A_{22}$ is $S_c = A_{11} - A_{12}A_{22}^{-1}A_{21} = A_r$. The formula is:\n$$ A^{-1} = \\begin{bmatrix} S_c^{-1} & -S_c^{-1}A_{12}A_{22}^{-1} \\\\ -A_{22}^{-1}A_{21}S_c^{-1} & A_{22}^{-1} + A_{22}^{-1}A_{21}S_c^{-1}A_{12}A_{22}^{-1} \\end{bmatrix} = \\begin{bmatrix} A_r^{-1} & -A_r^{-1}A_{12}A_{22}^{-1} \\\\ -A_{22}^{-1}A_{21}A_r^{-1} & A_{22}^{-1} + A_{22}^{-1}A_{21}A_r^{-1}A_{12}A_{22}^{-1} \\end{bmatrix} $$\nNow we compute $G(0) = -CA^{-1}B$:\n$$ G(0) = -\\begin{bmatrix} C_1 & C_2 \\end{bmatrix} A^{-1} \\begin{bmatrix} B_1 \\\\ B_2 \\end{bmatrix} = -\\left( \\begin{bmatrix} C_1 & C_2 \\end{bmatrix} \\begin{bmatrix} A_r^{-1} B_1 - A_r^{-1}A_{12}A_{22}^{-1} B_2 \\\\ -A_{22}^{-1}A_{21}A_r^{-1}B_1 + (A_{22}^{-1} + A_{22}^{-1}A_{21}A_r^{-1}A_{12}A_{22}^{-1})B_2 \\end{bmatrix} \\right) $$\n$$ G(0) = - \\left( C_1(A_r^{-1} B_1 - A_r^{-1}A_{12}A_{22}^{-1} B_2) + C_2(-A_{22}^{-1}A_{21}A_r^{-1}B_1 + A_{22}^{-1}B_2 + A_{22}^{-1}A_{21}A_r^{-1}A_{12}A_{22}^{-1}B_2) \\right) $$\nLet's group terms by $A_r^{-1}$:\n$$ G(0) = - \\left( (C_1 - C_2A_{22}^{-1}A_{21})A_r^{-1}B_1 - (C_1 - C_2A_{22}^{-1}A_{21})A_r^{-1}A_{12}A_{22}^{-1}B_2 + C_2A_{22}^{-1}B_2 \\right) $$\nRecognizing the definitions of $C_r$ and $B_r$:\n$$ G(0) = - \\left( C_r A_r^{-1} B_1 - C_r A_r^{-1} A_{12}A_{22}^{-1}B_2 + C_2A_{22}^{-1}B_2 \\right) $$\n$$ G(0) = - \\left( C_r A_r^{-1} (B_1 - A_{12}A_{22}^{-1}B_2) + C_2A_{22}^{-1}B_2 \\right) $$\n$$ G(0) = - ( C_r A_r^{-1} B_r + C_2A_{22}^{-1}B_2 ) $$\nSubstituting $D_r = -C_2A_{22}^{-1}B_2$:\n$$ G(0) = - (C_r A_r^{-1} B_r - D_r) = -C_rA_r^{-1}B_r + D_r $$\nThis last expression is precisely the definition of the steady-state gain of the BSP reduced model, $G_{BSP}(0)$. We have thus proven that $G_{BSP}(0) = G(0)$.\n\n### Option-by-Option Analysis\n\n**A. For a stable, strictly proper system with D=0, BSP yields a reduced model whose transfer function matches the original at s=0 exactly, while BT generally does not.**\nOur derivation shows $G_{BSP}(0) = G(0)$, meaning the steady-state gain is perfectly matched. Our analysis of BT shows that $G_{BT}(0) = -C_1A_{11}^{-1}B_1$, which in general is not equal to $G(0)$. This statement is a direct conclusion of the derivation.\n**Verdict: Correct**\n\n**B. Because the original is strictly proper (D=0), both BT and BSP reduced models necessarily have zero steady-state gain.**\nThis statement contains a fundamental error. A system is strictly proper if its transfer function approaches zero as $s \\to \\infty$, which is guaranteed if $D=0$. The steady-state gain is $G(0)$. There is no principle that requires $G(0)=0$ for a strictly proper system. For a simple counterexample, $G(s) = \\frac{1}{s+1}$ is strictly proper ($D=0$) with a steady-state gain of $G(0)=1$.\n**Verdict: Incorrect**\n\n**C. BT preserves the low-frequency (near s=0) Taylor expansion of G(s) up to first order by construction, whereas BSP does not.**\nTo preserve the Taylor expansion up to first order means matching both the zeroth-order term ($G(0)$) and the first-order term ($G'(0)$). As established, BT does not even match the zeroth-order term in general ($G_{BT}(0) \\neq G(0)$). Therefore, the first part of the statement is false. BSP matches the zeroth order, but not generally higher orders. The statement is entirely reversed from reality.\n**Verdict: Incorrect**\n\n**D. In BSP, even if D=0 initially, the reduced model may acquire a nonzero direct feedthrough D_r != 0 that enforces exact matching at s=0.**\nOur derivation of the BSP model yielded a feedthrough matrix $D_r = -C_2A_{22}^{-1}B_2$. Since the original system is assumed minimal and partitioned, it is generally the case that $C_2 \\neq 0$ and $B_2 \\neq 0$. Thus, $D_r$ is generally non-zero. Our final proof for the DC gain match, $G(0) = -C_rA_r^{-1}B_r + D_r$, shows that this $D_r$ term is an essential component in achieving the exact match. This statement correctly describes the mechanism of BSP.\n**Verdict: Correct**\n\n**E. If the truncated Hankel singular values correspond exclusively to fast modes, BT is guaranteed to match the original steady-state gain exactly.**\nThis statement conflates two different concepts. Balanced truncation truncates states with the smallest Hankel singular values ($\\sigma_i$), which measure input-output energy contribution. \"Fast modes\" refers to poles with large negative real parts, representing rapid decay. There is no guaranteed one-to-one correspondence between small $\\sigma_i$ and fast modes. A mode can be slow (pole near origin) but weakly coupled, resulting in a small $\\sigma_i$. Conversely, a fast mode can have a large energy contribution and a large $\\sigma_i$. The premise is not well-founded in a rigorous sense. BT is designed to minimize an $H_{\\infty}$ error norm, not to match DC gain. While it is true that in the limit of infinite time-scale separation the BSP model converges to the BT model, the statement's premise is too informal to constitute a \"guarantee\".\n**Verdict: Incorrect**", "answer": "$$\\boxed{AD}$$", "id": "2725584"}, {"introduction": "This practice pivots from the energy-based balancing methods to frequency-domain interpolation using Krylov subspaces, a powerful alternative for model reduction. The goal is to construct a reduced model that perfectly matches the full model's behavior at specific frequencies ($s=\\sigma_i$) and along chosen input ($r_i$) and output ($l_i$) directions. You will build the rational Krylov projection matrices and apply a Petrov-Galerkin condition, gaining direct experience with this powerful moment-matching technique [@problem_id:2725567].", "problem": "Consider a continuous-time, linear time-invariant state-space system with realization matrices $A \\in \\mathbb{R}^{3 \\times 3}$, $B \\in \\mathbb{R}^{3 \\times 2}$, and $C \\in \\mathbb{R}^{2 \\times 3}$ given by\n$$\nA = \\begin{pmatrix}\n0 & 0 & 0 \\\\\n0 & -3 & 0 \\\\\n0 & 0 & -5\n\\end{pmatrix},\\quad\nB = \\begin{pmatrix}\n1 & 0 \\\\\n1 & 1 \\\\\n0 & 1\n\\end{pmatrix},\\quad\nC = \\begin{pmatrix}\n1 & 0 & 1 \\\\\n0 & 1 & 1\n\\end{pmatrix}.\n$$\nThe transfer function is $G(s) = C(sI - A)^{-1} B$. You are to construct a reduced-order model of order $r=2$ using tangential rational Krylov subspaces so that the reduced model interpolates $G(s)$ at the interpolation points $\\sigma_{1} = -1$ and $\\sigma_{2} = -2$ along the specified input directions $r_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ and $r_{2} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$, and output directions $l_{1} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$ and $l_{2} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$.\n\nStarting from the definitions of the transfer function and the resolvent $(sI - A)^{-1}$, set up the tangential rational Krylov subspaces\n$$\n\\mathcal{K}_{V} = \\operatorname{span}\\left\\{(A - \\sigma_{1} I)^{-1} B r_{1},\\; (A - \\sigma_{2} I)^{-1} B r_{2}\\right\\},\\quad\n\\mathcal{K}_{W} = \\operatorname{span}\\left\\{(A^{\\top} - \\sigma_{1} I)^{-1} C^{\\top} l_{1},\\; (A^{\\top} - \\sigma_{2} I)^{-1} C^{\\top} l_{2}\\right\\}.\n$$\nForm projection matrices $V \\in \\mathbb{R}^{3 \\times 2}$ and $W \\in \\mathbb{R}^{3 \\times 2}$ with columns given by the above generators, and enforce the Petrov–Galerkin condition $W^{\\top} V = I$ by appropriately rescaling $V$ by $(W^{\\top} V)^{-1}$. Then define the reduced matrices $A_{r} = W^{\\top} A V$, $B_{r} = W^{\\top} B$, and $C_{r} = C V$.\n\nFinally, let $G_{r}(s) = C_{r}(sI - A_{r})^{-1} B_{r}$ be the transfer matrix of the reduced model. Provide the single-input/single-output reduced transfer function along the first input and first output, namely the $(1,1)$ entry of $G_{r}(s)$, as a single simplified rational expression in the complex variable $s$. No numerical rounding is required; leave your answer in exact form as an analytic expression in $s$.", "solution": "The problem statement is validated as being self-contained, scientifically grounded in the field of control theory, and well-posed. All necessary matrices, interpolation points, and tangential directions are provided. The eigenvalues of the matrix $A$ are $0$, $-3$, and $-5$, none of which match the specified interpolation points $\\sigma_{1} = -1$ and $\\sigma_{2} = -2$. Therefore, the resolvent matrices $(A - \\sigma_i I)^{-1}$ are well-defined. We proceed with the solution as prescribed.\n\nThe first step is to compute the basis vectors for the tangential rational Krylov subspaces $\\mathcal{K}_{V}$ and $\\mathcal{K}_{W}$. The basis vectors for the initial right projection matrix, which we denote $\\tilde{V}$, are $v_1 = (A - \\sigma_1 I)^{-1} B r_1$ and $v_2 = (A - \\sigma_2 I)^{-1} B r_2$.\n\nFor the first vector $v_1$, with $\\sigma_1 = -1$ and $r_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$:\n$$ (A - \\sigma_1 I) = A + I = \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & -3 & 0 \\\\ 0 & 0 & -5 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & -2 & 0 \\\\ 0 & 0 & -4 \\end{pmatrix} $$\n$$ (A - \\sigma_1 I)^{-1} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & -\\frac{1}{2} & 0 \\\\ 0 & 0 & -\\frac{1}{4} \\end{pmatrix} $$\nThe input vector is $B r_1 = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix}$.\nThus, $v_1 = (A - \\sigma_1 I)^{-1} B r_1 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & -\\frac{1}{2} & 0 \\\\ 0 & 0 & -\\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -\\frac{1}{2} \\\\ 0 \\end{pmatrix}$.\n\nFor the second vector $v_2$, with $\\sigma_2 = -2$ and $r_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$:\n$$ (A - \\sigma_2 I) = A + 2I = \\begin{pmatrix} 2 & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & -3 \\end{pmatrix} \\implies (A - \\sigma_2 I)^{-1} = \\begin{pmatrix} \\frac{1}{2} & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & -\\frac{1}{3} \\end{pmatrix} $$\nThe input vector is $B r_2 = \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\nThus, $v_2 = (A - \\sigma_2 I)^{-1} B r_2 = \\begin{pmatrix} \\frac{1}{2} & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -1 \\\\ -\\frac{1}{3} \\end{pmatrix}$.\nThe initial right projection matrix is $\\tilde{V} = \\begin{pmatrix} 1 & 0 \\\\ -\\frac{1}{2} & -1 \\\\ 0 & -\\frac{1}{3} \\end{pmatrix}$.\n\nNext, we compute the basis vectors for the left projection matrix $W$. Since $A$ is diagonal, $A^{\\top} = A$. The vectors are $w_1 = (A^{\\top} - \\sigma_1 I)^{-1} C^{\\top} l_1$ and $w_2 = (A^{\\top} - \\sigma_2 I)^{-1} C^{\\top} l_2$. The matrix $C^{\\top}$ is $\\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{pmatrix}$.\n\nFor the first vector $w_1$, with $\\sigma_1 = -1$ and $l_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$:\nThe output vector is $C^{\\top} l_1 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix}$.\nThus, $w_1 = (A - \\sigma_1 I)^{-1} C^{\\top} l_1 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & -\\frac{1}{2} & 0 \\\\ 0 & 0 & -\\frac{1}{4} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ -\\frac{1}{4} \\end{pmatrix}$.\n\nFor the second vector $w_2$, with $\\sigma_2 = -2$ and $l_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$:\nThe output vector is $C^{\\top} l_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix}$.\nThus, $w_2 = (A - \\sigma_2 I)^{-1} C^{\\top} l_2 = \\begin{pmatrix} \\frac{1}{2} & 0 & 0 \\\\ 0 & -1 & 0 \\\\ 0 & 0 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -1 \\\\ -\\frac{1}{3} \\end{pmatrix}$.\nThe left projection matrix is $W = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\\\ -\\frac{1}{4} & -\\frac{1}{3} \\end{pmatrix}$.\n\nTo enforce the Petrov-Galerkin condition $W^{\\top}V = I$, we first compute $W^{\\top}\\tilde{V}$:\n$$ W^{\\top}\\tilde{V} = \\begin{pmatrix} 1 & 0 & -\\frac{1}{4} \\\\ 0 & -1 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ -\\frac{1}{2} & -1 \\\\ 0 & -\\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{12} \\\\ \\frac{1}{2} & 1+\\frac{1}{9} \\end{pmatrix} = \\begin{pmatrix} 1 & \\frac{1}{12} \\\\ \\frac{1}{2} & \\frac{10}{9} \\end{pmatrix} $$\nThe determinant is $\\det(W^{\\top}\\tilde{V}) = 1 \\cdot \\frac{10}{9} - \\frac{1}{12} \\cdot \\frac{1}{2} = \\frac{10}{9} - \\frac{1}{24} = \\frac{80-3}{72} = \\frac{77}{72}$.\nThe inverse is $(W^{\\top}\\tilde{V})^{-1} = \\frac{72}{77} \\begin{pmatrix} \\frac{10}{9} & -\\frac{1}{12} \\\\ -\\frac{1}{2} & 1 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 80 & -6 \\\\ -36 & 72 \\end{pmatrix}$.\nWe define the corrected right projection matrix $V = \\tilde{V} (W^{\\top}\\tilde{V})^{-1}$:\n$$ V = \\frac{1}{77} \\begin{pmatrix} 1 & 0 \\\\ -\\frac{1}{2} & -1 \\\\ 0 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 80 & -6 \\\\ -36 & 72 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 80 & -6 \\\\ -40+36 & 3-72 \\\\ 12 & -24 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 80 & -6 \\\\ -4 & -69 \\\\ 12 & -24 \\end{pmatrix} $$\nNow we compute the reduced system matrices $A_r = W^{\\top}AV$, $B_r = W^{\\top}B$, $C_r = CV$.\n$$ B_r = W^{\\top}B = \\begin{pmatrix} 1 & 0 & -\\frac{1}{4} \\\\ 0 & -1 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & -\\frac{1}{4} \\\\ -1 & -1-\\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix} 1 & -\\frac{1}{4} \\\\ -1 & -\\frac{4}{3} \\end{pmatrix} $$\n$$ C_r = CV = \\begin{pmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{pmatrix} \\frac{1}{77} \\begin{pmatrix} 80 & -6 \\\\ -4 & -69 \\\\ 12 & -24 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 80+12 & -6-24 \\\\ -4+12 & -69-24 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 92 & -30 \\\\ 8 & -93 \\end{pmatrix} $$\n$$ A_r = W^{\\top}AV = W^{\\top} \\left( \\begin{pmatrix} 0 & 0 & 0 \\\\ 0 & -3 & 0 \\\\ 0 & 0 & -5 \\end{pmatrix} \\frac{1}{77} \\begin{pmatrix} 80 & -6 \\\\ -4 & -69 \\\\ 12 & -24 \\end{pmatrix} \\right) = W^{\\top} \\frac{1}{77} \\begin{pmatrix} 0 & 0 \\\\ 12 & 207 \\\\ -60 & 120 \\end{pmatrix} $$\n$$ A_r = \\frac{1}{77} \\begin{pmatrix} 1 & 0 & -\\frac{1}{4} \\\\ 0 & -1 & -\\frac{1}{3} \\end{pmatrix} \\begin{pmatrix} 0 & 0 \\\\ 12 & 207 \\\\ -60 & 120 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 15 & -30 \\\\ -12+20 & -207-40 \\end{pmatrix} = \\frac{1}{77} \\begin{pmatrix} 15 & -30 \\\\ 8 & -247 \\end{pmatrix} $$\nThe reduced transfer function is $G_r(s) = C_r(sI - A_r)^{-1}B_r$. We need its $(1,1)$ entry: $[G_r(s)]_{11} = C_{r,1\\bullet}(sI - A_r)^{-1}B_{r,\\bullet 1}$.\n$$ sI - A_r = \\begin{pmatrix} s - \\frac{15}{77} & \\frac{30}{77} \\\\ -\\frac{8}{77} & s + \\frac{247}{77} \\end{pmatrix} $$\n$$ \\det(sI - A_r) = \\left(s - \\frac{15}{77}\\right)\\left(s + \\frac{247}{77}\\right) + \\frac{240}{77^2} = s^2 + \\frac{232}{77}s - \\frac{3705}{77^2} + \\frac{240}{77^2} = s^2 + \\frac{232}{77}s - \\frac{3465}{77^2} $$\nSince $3465 = 45 \\times 77$, the determinant is $D(s) = s^2 + \\frac{232}{77}s - \\frac{45}{77}$.\n$$ (sI - A_r)^{-1} = \\frac{1}{D(s)} \\begin{pmatrix} s + \\frac{247}{77} & -\\frac{30}{77} \\\\ \\frac{8}{77} & s - \\frac{15}{77} \\end{pmatrix} $$\nThe first row of $C_r$ is $C_{r,1\\bullet} = \\frac{1}{77} \\begin{pmatrix} 92 & -30 \\end{pmatrix}$, and the first column of $B_r$ is $B_{r,\\bullet 1} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$.\n$$ [G_r(s)]_{11} = \\frac{1}{77 D(s)} \\begin{pmatrix} 92 & -30 \\end{pmatrix} \\begin{pmatrix} s + \\frac{247}{77} & -\\frac{30}{77} \\\\ \\frac{8}{77} & s - \\frac{15}{77} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} $$\nFirst, we compute the row vector $C_{r,1\\bullet}(sI - A_r)^{-1}$:\n$$ \\frac{1}{77 D(s)} \\left( \\begin{matrix} 92(s + \\frac{247}{77}) - \\frac{240}{77} & -92(\\frac{30}{77}) - 30(s - \\frac{15}{77}) \\end{matrix} \\right) = \\frac{1}{77^2 D(s)} \\begin{pmatrix} 92 \\cdot 77 s + 22724 - 240 & -2760 - 30 \\cdot 77 s + 450 \\end{pmatrix} $$\n$$ = \\frac{1}{77^2 D(s)} \\begin{pmatrix} 7084s + 22484 & -2310s - 2310 \\end{pmatrix} = \\frac{1}{77D(s)} \\begin{pmatrix} 92s + 292 & -30s - 30 \\end{pmatrix} $$\nMultiplying by $B_{r,\\bullet 1}$:\n$$ [G_r(s)]_{11} = \\frac{1}{77D(s)} ((92s + 292)(1) + (-30s - 30)(-1)) = \\frac{92s + 292 + 30s + 30}{77D(s)} = \\frac{122s + 322}{77D(s)} $$\nSubstituting $D(s) = s^2 + \\frac{232}{77}s - \\frac{45}{77}$:\n$$ [G_r(s)]_{11} = \\frac{122s + 322}{77(s^2 + \\frac{232}{77}s - \\frac{45}{77})} = \\frac{122s + 322}{77s^2 + 232s - 45} $$\nThe numerator is $2(61s + 161)$ and its root is $s = -161/61$. The denominator does not have this root, so the fraction is irreducible. This is the final simplified rational expression.", "answer": "$$\n\\boxed{\\frac{122s + 322}{77s^{2} + 232s - 45}}\n$$", "id": "2725567"}]}